{
  "id": "http://arxiv.org/abs/1806.01756v1",
  "title": "Concept-Oriented Deep Learning",
  "authors": [
    "Daniel T Chang"
  ],
  "abstract": "Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning.",
  "text": "Concept-Oriented Deep Learning \n \nDaniel T. Chang (张遵) \n \nIBM (Retired) dtchang43@gmail.com \nAbstract:  Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. We \npropose concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and \nconceptual understanding capability. CODL addresses some of the major limitations of deep learning: interpretability, \ntransferability, contextual adaptation, and requirement for lots of labeled training data. We discuss the major aspects of \nCODL including concept graph, concept representations, concept exemplars, and concept representation learning systems \nsupporting incremental and continual learning.   \n1 Introduction \n1.1 Human Deep Learning \nIn human learning, deep learning [1] is an approach that involves the critical analysis of new topics and facts, linking \nthem to already known concepts or forming new concepts, and leads to long term retention of concepts so that they can be \nused for problem solving in new situations. Deep learning promotes understanding and application for life. This is in contrast \nto surface learning which is the rote acceptance of facts and memorization as isolated and unlinked facts. It leads to \nsuperficial retention of facts and does not promote understanding or long term retention of knowledge. \nThe major characteristics of deep learning are: aiming for understanding, focusing on concepts, and relating new and \nprevious knowledge. According to the Bloom’s taxonomy [2], there are four types of knowledge: factual, conceptual, \nprocedural and metacognitive, and six levels of cognitive processes: remember, understand, apply, analyze, evaluate and \ncreate. Factual knowledge, such as topics and facts, is locked in time, place, and/or situation. Factual knowledge does not \npromote understanding. Concepts [3] (e.g., dog) are general ideas derived or inferred from facts. They are abstract and broad, \nrepresented by different instances that share common attributes, universal in application, and timeless. Conceptual knowledge \nis required for  understanding and provides the framework for relating new and previous knowledge. \nThe ultimate goal of learning is knowledge transfer [2]. Factual knowledge doesn't transfer, but conceptual \nunderstanding does. Conceptual understanding is built by abstracting “up” from factual knowledge or examples to understand \nconcepts and the relationships among concepts. Whenever we try to apply our insights from one situation to another we are \nalways abstracting to the conceptual level before our knowledge helps us unlock the new situation. When tasks remain \nsimilar to one another, this is known as low-road transfer. To transfer knowledge to dissimilar tasks requires high-road \n2 \n \ntransfer which involves highly generalized concepts. A deep foundation of facts or surface learning is key for deep learning \nand knowledge transfer. Synergistic thinking, which involves the interaction between the factual and conceptual levels of \nthinking, is essential for deep learning. \n1.2 Machine Deep Learning \nIn machine learning, deep learning has more than one definition. A useful, though narrow, definition [4] is: deep learning \nis neural networks with a large number of layers and parameters in one of four fundamental network architectures: \nunsupervised pretrained networks, convolutional neural networks, recurrent neural networks, and recursive neural networks \nAutomatic feature extraction is one of the major facets, and great advantages, that deep learning has.  \nDeep learning is more broadly defined as feature representation learning in [5, 6]. It uses machine learning to discover \nnot only the mapping from feature representations to output but also the feature representations themselves. To learn features \nthat best represent data, the goal is to separate the factors of variation that explain the data. Deep learning does this by \nlearning successive layers of increasingly meaningful feature representations. The ‘deep’ in deep learning stands for this idea \nof deep layers of feature representations. Deep learning is therefore layered feature representation learning. These layered \nfeature representations are generally learned via neural networks. \nDeep learning has achieved near-human accuracy levels in various types of classification and prediction tasks including \nimages, text, speech, and video data. However, the current technology of deep learning is largely at the level of surface \nlearning, not deep learning, in human learning, focusing on rote memorization of factual knowledge in the form of feature \nrepresentations. A deep-learning model [6, 7] is just a chain of simple, continuous geometric transformations mapping one \ndata manifold into another. Anything that needs reasoning is out of reach for deep-learning models. There are other major \nlimitations as well. Firstly, the knowledge learned using deep-learning models cannot be transferred because, as discussed \nearlier, factual knowledge (feature representations) doesn't transfer, but conceptual understanding does. Secondly, deep-\nlearning models are difficult to understand or interpret [8]. This is to be expected since, as discussed earlier, factual \nknowledge (feature representations) does not promote understanding. Conceptual knowledge is required for understanding. \nAs a result of the first two limitations, deep-learning models cannot leverage contextual knowledge. They are developed in \nisolation, within the narrow confine of the specific training data used, and do not support contextual adaptation [7]. Lastly, \nbut not the least, deep-learning models require lots of labeled data for training, which can be hard to come by. This is not \n3 \n \nsurprising since deep learning relies on rote memorization of feature representations to perform classification and prediction \ntasks. It has no conceptual understanding of the data. \n1.3 Goal and Outline \nFrom the above discussions it should be apparent that conceptual knowledge learning and conceptual understanding are \nneeded to elevate machine deep learning toward the level of human deep learning. We propose Concept-Oriented Deep \nLearning (CODL) as a general approach to achieve that goal. CODL is an extension of (machine) deep learning. It extends \nfeature representation learning with concept representation learning and it adds the conceptual understanding capability to \ndeep learning. The major aspects of CODL include: concept graph, concept representations, concept exemplars, and concept \nrepresentation learning systems. These are discussed in the following sections. The last section provides the summary and \nconclusion.  \n2 Concept Graph \nThe Big Book of Concepts [9] states that “Concepts are the glue that holds our mental world together.” Without \nconcepts, there would be no mental world. As discussed earlier, concepts [3] (e.g., dog) are general ideas derived or inferred \nfrom facts. They are abstract and broad, represented by different instances that share common attributes. A concept may \ncontain a set of attributes that describe the concept and a set of sub-concepts that are components of the concept. Concepts \nmay also be related by relationships. The most common relationships include isA relationships.  \nConcepts and categories go together [9]. That is, whatever the concept is, there is a category of things that would be \ndescribed by it. For material things (objects), ‘category’ is usually referred to as ‘class’; for abstract things (entities), \n‘category’ is commonly referred to as ‘type’. Thus, concepts denote categories, classes or types, and instances denote things, \nobjects or entities. \nMicrosoft Concept Graph [10, 11] aims to give machines \"common-sense computing capabilities\" and an awareness of a \nhuman's mental world, which is underpinned by concepts. Microsoft Concept Graph is built upon Probase, which uses the \nworld as its model. The concept graph in Probase is automatically learned from billions of web pages and years' worth of \nsearch logs. The core taxonomy of Microsoft Concept Graph contains over 5.4 million concepts. Microsoft Concept Graph \nalso has a large data space (each concept contains a set of instances or sub-concepts), a large attribute space (each concept is \ndescribed by a set of attributes), and a large relationship space (e.g., \"isA\", \"locatedIn\"). \n4 \n \nThe Microsoft Concept Tagging Model [11 – 16], a part of Microsoft Concept Graph, maps text entities into concepts \nwith some probabilities, which may depend on the context texts of the entities. Given an input text entity, it returns a ranked \nlist of concepts. Each concept on the list has a probability denoting the possibility of the text entity belonging to this concept. \nBesides, some common measures for conceptualization (e.g., Typicality) are provided simultaneously. \nCODL uses Microsoft Concept Graph as the common / background conceptual knowledge base and the framework for \nconceptual understanding, due to its probabilistic nature and extensive scope. Microsoft Concept Graph plays an important \nrole in CODL. Its usage in CODL is discussed in the following sections. However, CODL is not limited to using Microsoft \nConcept Graph as the common / background conceptual knowledge base. Other comparable system can be used as such. \n3 Concept Representations \nIn deep learning, feature representations are generally learned as a blob of ungrouped features. However, an increasing \nnumber of visual applications nourish from inferring knowledge from imagery which requires scene understanding. Semantic \nsegmentation is a task that paves the way towards scene understanding. Deep semantic segmentation [17] uses deep learning \nfor semantic segmentation.  \nDeep semantic segmentation makes dense predictions inferring labels for every pixel. It can be carried out at three \ndifferent levels: \n \nClass segmentation: each pixel is labeled with the class of its enclosing object or region \n \nInstance segmentation: separate labels for different instances of the same class \n \nPart segmentation: decomposition of already segmented classes into their component sub-classes \nCODL extends and generalizes deep semantic segmentation. In CODL, feature representations are always learned \nsemantically segmented in a concept-oriented manner. Concept orientation means that each feature representation is \nassociated with a concept, an instance or an attribute. These concepts, instances and attributes form a concept graph. In \naddition, the concept graph are generally linked to Microsoft Concept Graph, thus leveraging and integrating with the \ncommon conceptual knowledge and conceptual understanding capability provided by Microsoft Concept Graph. \nA concept representation consists of a concept, its instances and attributes, and all the feature representations associated \nwith the concept and its instances and attributes. If a concept has sub-concepts, its concept representation also consists of the \n5 \n \nconcept representations of its sub-concepts. Concept representations, therefore, are the same as concept-oriented feature \nrepresentations, but provide a different view. The latter is data driven and provides a bottom-up view starting from feature \nrepresentations; the former is concept driven and provides a top-down view starting from concepts. Due to the focus on \nconcepts instead of low-level feature representations, concept representations provide the proper view to work with in CODL.  \n3.1 Supervised Concept Representation Learning \nConcept representations can be learned using supervised learning. Similar to deep semantic segmentation [17], discussed \nabove, it can be carried out at different levels: \n \nConcept level: each feature representation is labeled with the concept that owns the feature \n \nInstance level: separate labels for different instances of the same concept \n \nAttribute level: separate labels for different attributes of the same concept \n \nComponent level: decomposition of already learned concept representations into their sub-concept \nrepresentations \nThe concept, instance and attribute names used for labeling should be taken from Microsoft Concept Graph, if available. \nThis provides direct link to Microsoft Concept Graph to leverage its common conceptual knowledge and conceptual \nunderstanding capability. \n4 Concept Exemplars \nAs is the case for deep semantic segmentation, it can be difficult to gather and create labeled concept representation \ndatasets to use for training in supervised learning. Due to the semantically-segmented nature of concepts, a good alternative is \nto use concept exemplars.  \nA concept exemplar set is a set of one or more typical instances of a concept, possibly augmented with instances \ngenerated from the typical instances using identity-preserving transformations. As an example, for image objects the identity-\npreserving transformations [18] typically include: scaling, translation, rotation, contrast and color. Each concept is associated \nwith at most one concept exemplar set. \n6 \n \nWith concept exemplars one can use supervised concept representation learning, as discussed earlier, or unsupervised \nconcept representation learning, as discussed below. Concept exemplars can facilitate incremental and continual learning, to \nbe discussed later. \n4.1 Unsupervised Concept Representation Learning \nExemplar-CNN [18] is an approach for training a convolutional network using only unlabeled data. It trains the network \nto discriminate between a set of surrogate classes. Each surrogate class is formed by applying a set of transformations to a \nrandomly sampled ’seed’ image patch. The resulting feature representations are not task specific. They are generic and \nprovide robustness to the transformations that have been applied during training. The applied transformations thus define the \ninvariance properties that are to be learned by the network. \nUnsupervised concept representation learning uses the same approach as Exemplar-CNN. In CODL, concept exemplars \nplay the role of surrogate classes, and identity-preserving transformations that of applied transformations, in Exemplar-CNN. \nWhereas surrogate classes are based on randomly sampled ’seed’ image patches, concept exemplars are based on \nsemantically distinct, typical instances of concepts. Therefore, we expect unsupervised concept representation learning based \non concept exemplars to result in generic, transferable concept representations. \n5 Concept Representation Learning Systems \nConcept representation learning systems provide the platforms and tools for use in CODL. They support supervised \nconcept representation learning as well as unsupervised concept representation learning based on concept exemplars. They \nalso provide access to the common / background conceptual knowledge base, such as Microsoft Concept Graph. The \nfollowing are major aspects of concept representation learning systems which are important for the success of CODL and its \napplication. \n5.1 Incremental and Continual Learning \nIn real-world scenarios, concepts and their associated data are almost always collected in an incremental manner. As \nsuch, incremental and continual learning [19] is a critical aspect of CODL. A good concept representation learning system \nmust accommodate new concepts and their associated data that it is exposed to and gradually expands its capacity to predict \nincreasing number of new concepts. \n7 \n \nDoing incremental learning using deep neural network faces inherent technical challenges. Neural networks embed \nfeature extraction and classification within the same model. This gives rise to the so-called “catastrophic forgetting / \ninterference\" problem [20] which refers to the destruction / modification of existing feature representations learned from \nearlier data, when the model is exclusively trained with data of new concepts.  \nTherefore, the challenge is to be able to incrementally and continually learn over time by accommodating new concepts \nand their data while retaining previously learned concept representations. There are various approaches [19] for incremental \nand continual learning that mitigate, to different extents, catastrophic interference.  The regularization approaches alleviate \ncatastrophic interference by imposing constraints on the update of the neural weights. The dynamic architecture approaches \nchange architectural properties in response to new concepts and their data, either by dynamically accommodating novel \nneural resources or by re-training with an increased number of neurons or network layers. \nA good approach to use in CODL is that of iCaRL [21] (incremental classifier and representation learning), which is a \ndynamic architecture approach. The approach allows learning in a concept-incremental way: only the training data for a small \nnumber of concepts has to be present at the same time and new concepts can be added progressively. Concept-incremental \nlearning has the following properties:  \n \nit is trainable from a data stream in which examples of different concepts appear at intermittent times, \n \nat any time it provides a competitive multi-concept classifier for all the concepts learned so far, and \n \nit does not require storing all training data or retraining already-learned concepts whenever new data becomes \navailable. \nThe main components [21] that enable simultaneous learning of concept representations and concept classifiers in the \nconcept-incremental manner are: \n \nconcept representation learning using knowledge distillation and prototype rehearsal, \n \nconcept exemplar selection / learning based on herding, and \n \nconcept classification by the nearest mean of concept exemplars. \nThese are discussed below. \n8 \n \nPrior to that we note that the deep learning network is used only for concept representation learning and concept \nexemplar selection, not for classifying new data, which is done using concept classifiers based on concept exemplars. The \nconcept representation learning scheme, using knowledge distillation, addresses the “catastrophic forgetting / interference” \nproblem of incremental and continual learning. The use of concept exemplars, for concept classifiers, avoids the other \nproblem: storing of all training data. \nConcept Representation Learning \nWhenever data for new concepts arrive, the concept representations and concept exemplar sets are updated. Firstly, the \nnetwork outputs for the existing concepts are stored. Secondly, an augmented training set is constructed, consisting of the \n(newly available) training examples for the new concepts together with the concepts exemplar sets for the existing concepts. \nFinally, the deep learning network is trained / updated by minimizing a loss function to output the correct concept indicators \nfor new concepts (classification loss), and for old concepts, to reproduce the scores stored in the first step (distillation loss). \nThe classification loss enables improvements of the concept representations that allow classifying the new concepts well; the \ndistillation loss ensures that the discriminative information learned for existing concepts is not lost while training for the new \nconcepts. \nConcept Exemplars Selection / Learning \nConcept exemplars selection is required for each concept only once, when it is first learned and its training data is \navailable. For each concept, concept exemplars are selected and stored iteratively until the target number is met. In each step \nof the iteration, one more example of the training set is added to the concept exemplar set, namely the one that causes the \naverage feature vector over all concept exemplars to best approximate the average feature vector over all training examples. \nThus, the concept exemplar set is a prioritized list, with concept exemplars earlier in the list being more important. The \nconcept exemplar set may be augmented using identity-preserving transformations, as discussed earlier. \nConcept Classification Based on Concept Exemplars \nFor concept classification, a nearest-mean-of-concept-exemplars classification strategy is used. To predict a concept \nlabel for a new sample, it first computes a prototype vector for each concept by computing the average feature vector of all \nconcept exemplars for the concept. It then computes the feature vector of the sample that should be classified and assigns the \nconcept label with the most similar prototype. The concept prototypes automatically change whenever the concept \n9 \n \nrepresentations change, making the classifier robust against changes of the concept representations (as new concepts are \nlearned) \n5.2 Concept Taxonomy and Basic-Level Concepts \nConcept taxonomy [9] is one particular kind of concept organization: the hierarchical structure of concepts with each \nbranch being a sequence of progressively larger concepts in which each concept includes all the previous ones. Different \nlevels of concepts reflect different levels of abstraction, which associate with different attributes. These taxonomic concepts \nare important for thought and communication. \nIn a concept taxonomy, the concepts that are higher in the hierarchy are superordinate to the lower-level concepts; the \nlower-level concepts are subordinate to the higher-level ones. The only relationship allowed between concepts in the \nhierarchy is the set inclusion relationship: the set of instances of  a superordinate concept (e.g., dog) includes the set of \ninstances of its subordinate concept (e.g., bull dog). The set inclusion relationship is called the ‘‘isA’’ relationship, which is \nasymmetric and transitive. The transitivity of concept relationship in the hierarchy leads to a similar transitivity of attribute \nascription, called attribute inheritance. Every attribute of a concept is also an attribute of the concept’s subordinates. \nBy being able to locate a concept in its proper place in the concept taxonomy, one can learn a considerable amount about \nthe concept, e.g., its superordinates and inherited attributes. In CODL, this is achieved by accessing Microsoft Concept \nGraph, as discussed near the beginning. Clearly, this is an important ability, since it allows one to immediately access \nknowledge (concepts) about new objects or entities without the need to directly learn. \nBasic-Level Concepts \nThe objects and entities that we encounter every day do not each fit into a single concept, but can be classified with a \nlarge number of different concepts. It is important to know the preferred concept by which people think about any one object \nor entity.  \nAny object or entity can be thought of as being in a set of hierarchically organized concepts, i.e., a concept taxonomy, \nranging from extremely general (e.g., animal) to extremely specific (e.g., bull dog). Classification at the most general level \nmaximizes accuracy of classification. Most specific concepts, on the other hand, allow for greater accuracy in prediction. Of \nall the possible concepts in a concept taxonomy to which a concept belongs, a middle level of specificity, the basic level [9], \n10 \n \nis the most natural, preferred level at which to conceptually carve up the world. The basic level (e.g., dog) can be seen as a \ncompromise between the accuracy of classification at a most general level and the predictive power of a most specific level.  \nSuperordinate concepts (e.g., animal) are distinctive but not informative. Subordinate concepts (e.g., bull dog) are \ninformative but not distinctive. It is only basic-level concepts (e.g., dog) that are both informative and distinctive. Basic-level \nconcept is important because it provides rich information with little cognitive efforts. When a person obtains the basic-level \nconcept of an unfamiliar object or entity, she will associate the object or entity with the known attributes of the basic-level \nconcept. \nTherefore, to be effective, in CODL one should focus on learning and using concept representations for basic-level \nconcepts [11]. Superordinate concepts are automatically “learned” by accessing Microsoft Concept Graph, as discussed \nearlier. When needed, this can be supplemented by learning and using concept representations for selective subordinate \nconcepts. \n6 Summary and Conclusion \n \nConcepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. The current \ntechnology of machine deep learning is largely at the level of surface learning in human learning, focusing on rote \nmemorization of factual knowledge in the form of feature representations. To elevate machine deep learning toward the level \nof human deep learning, we proposed concept-oriented deep learning (CODL) which extends (machine) deep learning with \nconcept representations and conceptual understanding capability. \nCODL leverages Microsoft Concept Graph, or something comparable, as the common / background conceptual \nknowledge base and the framework for conceptual understanding. In particular, concept names and concept taxonomies (isA \nrelationships) originate from Microsoft Concept Graph. In CODL, feature representations are always learned semantically \nsegmented in a concept-oriented manner. Concept representations are the same as concept-oriented feature representations, \nbut from a top-down, concept-driven perspective which is the focus of CODL. It can be difficult to gather and create labeled \nconcept representation datasets to use for training. Due to the semantically-segmented nature of concepts, a good alternative \nis to use concept exemplars. \nConcept representation learning systems provide the platforms and tools for use in CODL. They support supervised \nconcept representation learning as well as unsupervised concept representation learning based on concept exemplars. Since, \n11 \n \nin real-world scenarios, concepts and their associated data are almost always collected in an incremental manner, a good \nconcept representation learning system must support incremental and continual learning (using concept exemplars). Also, to \nbe effective, in CODL one should focus on learning and using concept representations for basic-level concepts. \nBy focusing on learning and using concept representations and concept exemplars, CODL is able to address some of the \nmajor limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled \ntraining data.  \nReferences \n \n[1] W. Houghton, Engineering Subject Centre Guide: Learning and Teaching Theory for Engineering Academics \n(Loughborough: HEA Engineering Subject Centre, 2004). \n[2] Julie Stern, Krista Ferraro and Juliet Mohnkern, Tools for Teaching Conceptual Understanding, Secondary: Designing \nLessons and Assessments for Deep Learning (Corwin, 2017). \n[3] Jean Donham, “Deep Learning through Concept-based Inquiry,” School Library Monthly, Volume XXVII, Number 1, 8 \n(2010). \n[4] Josh Patterson and Adam Gibson, Deep Learning A Practitioner’s Approach (O’Reilley, 2017). \n[5] Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning (MIT Press, 2016) \n[6] Francois Chollet, Deep Learning with Python (Manning, 2018) \n[7] John Launchbury, A DARPA Perspective on Artificial Intelligence (DARPA, 2017). \n[8] Z. C. Lipton, “The mythos of model interpretability,” arXiv preprint arXiv:1606.03490 (2017). \n[9] G. L. Murphy, The Big Book of Concepts (MIT Press, 2002). \n[10] Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Zhu, “Probase: A Probabilistic Taxonomy for Text \nUnderstanding,”  in ACM International Conference on Management of Data (SIGMOD), May 2012. \n[11] Zhongyuan Wang, Haixun Wang, Ji-Rong Wen, and Yanghua Xiao, “An Inference Approach to Basic Level of \nCategorization,”  in ACM International Conference on Information and Knowledge Management (CIKM), ACM – \nAssociation for Computing Machinery, October 2015. \n[12] Yangqiu Song, Haixun Wang, Zhongyuan Wang, Hongsong Li, and Weizhu Chen, “Short Text Conceptualization using \na Probabilistic Knowledgebase,” in IJCAI, 2011. \n[13] Zhongyuan Wang, Haixun Wang, and Zhirui Hu, “Head, Modifier, and Constraint Detection in Short Texts,” in \nInternational Conference on Data Engineering (ICDE), 2014. \n[14] Zhongyuan Wang, Kejun Zhao, Haixun Wang, Xiaofeng Meng, and Ji-Rong Wen, “Query Understanding through \nKnowledge-Based Conceptualization,”  in IJCAI, July 2015. \n[15] Wen Hua, Zhongyuan Wang, Haixun Wang, Kai Zheng, and Xiaofang Zhou, “Short Text Understanding Through \nLexical-Semantic Analysis,” in International Conference on Data Engineering (ICDE), April 2015.  \n[16] Zhongyuan Wang and Haixun Wang, “Understanding Short Texts,” in the Association for Computational Linguistics \n(ACL) (Tutorial), August 2016. \n[17]  A. Garcia-Garcia, S. Orts-Escolano, S. Oprea, V. Villena-Martinez, and J. Garcia-Rodriguez, “A Review on Deep \nLearning Techniques Applied to Semantic Segmentation,” arXiv preprint arXiv:1704.06857 (2017). \n[18] Alexey Dosovitskiy, Philipp Fischer, Jost Tobias Springenberg, Martin Riedmiller, and Thomas Brox, “Discriminative \nUnsupervised Feature Learning with Exemplar Convolutional Neural Networks,” arXiv preprint arXiv: 1406.6909 (2015). \n[19] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, and Stefan Wermter, “Continual Lifelong Learning \nwith Neural Networks: A Review,” arXiv preprint arXiv:1802.07569 (2018) \n[20] I. J. Goodfellow, M. Mirza, X. Da, A. Courville, and Y. Bengio, “An Empirical Investigation of Catastrophic Forgeting \nin Gradient-Based Neural Networks,” arXiv preprint arXiv:1312.6211 (2015). \n[21] S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, “iCaRL: Incremental Classifier and Representation \nLearning,” CVPR’14, pages 2001–2010 (2017). \n \n",
  "categories": [
    "cs.AI"
  ],
  "published": "2018-06-05",
  "updated": "2018-06-05"
}