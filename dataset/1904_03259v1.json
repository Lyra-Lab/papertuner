{
  "id": "http://arxiv.org/abs/1904.03259v1",
  "title": "Is 'Unsupervised Learning' a Misconceived Term?",
  "authors": [
    "Stephen G. Odaibo"
  ],
  "abstract": "Is all of machine learning supervised to some degree? The field of machine\nlearning has traditionally been categorized pedagogically into\n$supervised~vs~unsupervised~learning$; where supervised learning has typically\nreferred to learning from labeled data, while unsupervised learning has\ntypically referred to learning from unlabeled data. In this paper, we assert\nthat all machine learning is in fact supervised to some degree, and that the\nscope of supervision is necessarily commensurate to the scope of learning\npotential. In particular, we argue that clustering algorithms such as k-means,\nand dimensionality reduction algorithms such as principal component analysis,\nvariational autoencoders, and deep belief networks are each internally\nsupervised by the data itself to learn their respective representations of its\nfeatures. Furthermore, these algorithms are not capable of external inference\nuntil their respective outputs (clusters, principal components, or\nrepresentation codes) have been identified and externally labeled in effect. As\nsuch, they do not suffice as examples of unsupervised learning. We propose that\nthe categorization `supervised vs unsupervised learning' be dispensed with, and\ninstead, learning algorithms be categorized as either\n$internally~or~externally~supervised$ (or both). We believe this change in\nperspective will yield new fundamental insights into the structure and\ncharacter of data and of learning algorithms.",
  "text": "Is ‘Unsupervised Learning’ a Misconceived\nTerm?\nStephen G. Odaibo,\nM.D.,M.S.(Math),M.S.(Comp. Sci.)\n.\nRETINA-AI Health, Inc.\nApril 9, 2019\nAbstract\nIs all of machine learning supervised to some degree? The ﬁeld\nof machine learning has traditionally been categorized pedagogically\ninto supervised vs unsupervised learning; where supervised learning\nhas typically referred to learning from labeled data, while unsuper-\nvised learning has typically referred to learning from unlabeled data.\nIn this paper, we assert that all machine learning is in fact supervised\nto some degree, and that the scope of supervision is necessarily com-\nmensurate to the scope of learning potential. In particular, we argue\nthat clustering algorithms such as k-means, and dimensionality re-\nduction algorithms such as principal component analysis, variational\nautoencoders, and deep belief networks are each internally supervised\nby the data itself to learn their respective representations of its fea-\ntures. Furthermore, these algorithms are not capable of external in-\nference until their respective outputs (clusters, principal components,\nor representation codes) have been identiﬁed and externally labeled\nin eﬀect. As such, they do not suﬃce as examples of unsupervised\nlearning. We propose that the categorization ‘supervised vs unsuper-\nvised learning’ be dispensed with, and instead, learning algorithms be\ncategorized as either internally or externally supervised (or both). We\nbelieve this change in perspective will yield new fundamental insights\ninto the structure and character of data and of learning algorithms.\nCorrespondence Email:\nstephen.odaibo@retina-ai.com\narXiv:1904.03259v1  [cs.LG]  5 Apr 2019\n1\nIntroduction\nFigure 1: Prototypical Illustration of Supervised vs Unsupervised Learning\nTraditional thinking has been to pedagogically divide machine learn-\ning into supervised vs unsupervised learning, as depicted in Figure(1). In\nthis paper, we challenge that scheme by arguing that all machine learn-\ning is supervised to some degree.\nIn the literature, the methods which\nhave typically been referred to as unsupervised learning include methods\nsuch as kmeans [MacQueen et al., 1967,Wagstaﬀet al., 2001,Coates et al.,\n2011,Coates and Ng, 2012] which cluster data based on some distance metric,\nand methods which attempt to derive some representation code of the data\nin terms of the algorithm’s individual architecture. This latter class of meth-\nods can be thought of on the one hand as dimensionality reducers, and they\ninclude autoencoders [Le et al., 2011, Hinton and Salakhutdinov, 2006, Lee\net al., 2009, Vincent et al., 2010, Ngiam et al., 2011], principal component\nanalysis [Jolliﬀe, 2011], deep belief networks [Hinton et al., 2006], and adver-\nsarial generative models such as predictability minimization [Schmidhuber,\n1992] and generative adversarial networks [Goodfellow et al., 2014,Radford\net al., 2015, Mirza and Osindero, 2014]. Another interpretation for these is\nas density estimators which eﬀectively maximize the likelihood of the input\ndata. In other words, they attempt to derive a distribution estimate, Q(x),\nfor the native probability distribution, P(x), of the data, χ, by minimizing\nthe Kullback-Liebler or related distance:\nDKL(P||Q) = −\nX\nx∈χ\nP(x) log\n\u0012Q(x)\nP(x)\n\u0013\n(1)\n2\nEach of the above mentioned algorithms are guided strongly by the data,\nwhich is in every sense their supervisor. In the case of kmeans clustering,\nthe location of the data point is the label and the loss is its distance to the\nk centroids. In the case of deep neural autoencoders, the input image is the\nlabel and the loss is a function of the distance between the original and the\nreconstructed image. And in the case of principal component analysis, the\nmultivariate data points are the labels, and they contain all the information\nneeded to select the mutually orthogonal set of principal component vectors.\nIn the above examples, this direct supervision by the data itself con-\nstrains the learning potential to things intrinsic to the data, e.g. internal\nfeature representations of the data. If on the other hand, one wanted to\nlearn things externally ascribed to the data, i.e labels, then external supervi-\nsion via implicit or explicit labeling will be necessary. Prior to such labeling,\nthese algorithms are not directly useful for inference of externally deﬁned\nmeaning. For example, without some form of feature identiﬁcation and la-\nbeling, an image autoencoder’s output cannot be used to directly infer things\nsuch as ‘cat,’ ‘dog,’ or ‘face.’ Therefore one must recognize these methods\nas supervised learning algorithms where the supervision is by the data itself\nand the learning is of a representation of the data’s internal features.\nWe propose that the categorization ‘supervised vs unsupervised learning’\nbe dispensed with, and instead, learning algorithms be categorized as either\ninternally or externally supervised (or both). We believe this change in per-\nspective will yield new fundamental insights into the structure and character\nof data and of learning algorithms.\n2\nSupervision, Learning, and Inference Scope\nHere, we propose the concept of scope in regards to supervision, learning,\nand inference. We conjecture that all machine learning is supervised to some\ndegree.\nAnd the level and scope of supervision determines the level and\nscope of learning potential. This in turn determines the level and scope of\ninference potential of which the algorithm’s output is capable. An algorithm\ncannot learn beyond the scope of its supervision, and cannot infer beyond\nthe scope of what it has learned. For instance, when the only supervisor is\nthe data itself and there is no external supervision in the form of labels, such\nan algorithm will only be capable of learning things intrinsic to the data;\nthings such as internal feature representation codes. By the same token, the\ninference which such an algorithm will be capable of will be restricted to what\nit has learned, for example it will be able to represent new unseen data in the\nlearned representation code. This can be considered an intrinsic data-level\n3\nFigure 2: Kmeans-to-kNN: Internal-to-External Supervision\nscope of supervision, learning, and inference. On the other hand, if externally\ndeﬁned meaning is ascribed to the learned features codes or some algebraic\ncombination of them like an image, then the scope of learning and inference\nwill similarly go beyond intrinsic features of the data. In this instance, there\nwill be a mapping into the corresponding semantic space.\n3\nData as Supervisor\nWhen there are no labels, i.e. no external supervision to guide the learning\nprocess, one is limited to internal supervision by the data itself. Under this\ncircumstance, the range of admissible learning processes can be summarized\nas basis feature selection. This may include a change of basis feature opera-\n4\nAlgorithm\nSupervision\nKmeans clustering\nInternal\nVariational autoencoders\nInternal\nDeep belief networks\nInternal\nPrincipal component analysis\nInternal\nK nearest neighbor (kNN)\nExternal\nCNN image classiﬁcation\nExternal\nGenerative adversarial nets\nExternal\nKmeans-to-kNN\nBoth\nTable 1: Supervision type of some algorithms\ntion; or a reduction in span, i.e. a dimensionality reduction. The entire range\nof data-supervised examples such as kmeans clustering, principal component\nanalysis, autoencoding, deep belief nets, and generative adversarial nets can\nall be described as basis feature selection operations. The possible inference\nin this case is essentially limited to expressing new data in the learned feature\nbasis.\n4\nSome Examples\nTable 1 shows some examples of algorithms and their associated supervision\ntype. The table assumes the standard implementation of the algorithms.\nThe previously mentioned examples where the data itself is the supervisor\nare all internally supervised. The examples on the table are externally super-\nvised. Notably, the external labeling is not always obvious. GANs are such\nan example. For most machine learning applications, some form of external\ninference capability is ultimately desired. To enable this, the internally su-\npervised output will need to be converted to externally supervised method\nas exempliﬁed by kmeans-to-kNN illustrated in Figure (2). In such cases,\nthe composite process is therefore both internally and externally supervised.\n4.1\nGANs are Externally Supervised\nGenerative adversarial networks (GANs) are an interesting example of an al-\ngorithm that is surprisingly externally supervised, but have often been called\n‘unsupervised’ [Radford et al., 2015]. Their individual modules such as the\ndiscriminator or the generator considered in isolation, are externally super-\nvised. The Discriminator in a GAN is a binary classiﬁcation convolutional\nneural network with clearly labeled outputs: real vs synthesized; real if the\n5\nimage source is the training data and synthesized if the image source is the\nGenerator.\nSimilarly, the Generator is a deconvolutional neural network\nwhose weights are updated based on the Discriminator’s assessment of the\nGenerator’s clearly labeled output. This clearly labeled output are what di-\nrectly constitute the loss function and guide the training, as exempliﬁed by\nthe stochastic gradient of the Shannon-Jensen loss:\n∇θd\n1\nm\nm\nX\ni=1\n\u0002\nlog D\n\u0000x(i)\u0001\n+ log\n\u00001 −D\n\u0000G\n\u0000z(i)\u0001\u0001\u0001 \u0003\n(2)\nThe entire process of training a GAN is guided by the algorithm designer’s\nknowledge and labeling of the training data as real and the generator’s output\nas synthesized.\n5\nDiscussion\nNo algorithms in existence are truly unsupervised.\nInstead, the scope of\nsupervision of algorithms determine the learning potential, which in turn\ndetermines the inference potential of resulting trained model.\nWe found\nthat most algorithms that have been termed ‘unsupervised’ in the literature\nare supervised by the data, i.e. they they are internally supervised. The\nlearning potential of such data-level scope algorithms is to determine a ‘basis’\nfeature set to represent the data. The speciﬁc mechanisms of data-level scope\nsupervision varied between algorithms, but each presented the data as the\nstandard against which the resulting basis feature set was evaluated.\nAn algorithm can be termed unsupervised if it is able to learn outside of\nthe scope of its supervision. We however conjecture that this is impossible.\nFor instance, while there is a representation for face, dog, cat, or any other\nvisual object in terms of any appropriately deep neural network architec-\nture, one does not have semblance of intelligence till the representations are\nmapped to meaning. In other words, one can not make useful and meaningful\ninference until the derived basis features are mapped to meaningful objects\nsuch as ‘face’, ‘cat’, and ‘dog’. This is labeling and makes it an externally\nsupervised problem.\nNeural networks learn so many more features that we can currently track\nor be aware of. For instance, in a standard convolutional neural network\nimage classiﬁcation problem, our labels are based on certain salient discrimi-\nnative features, yet the network may utilize other and more (or less) features\nfor discrimination. This makes it clear that the designation of supervision\ntype is based on the intended task. For instance, assigning class labels in\n6\nan image classiﬁcation problem suﬃces to designate the algorithm as ‘super-\nvised’ regardless of how exactly the neural network makes its determination,\nwhich may be via a feature diﬀerent from the label. By the same token, when\nthe task is to ﬁnd an internal representation of a dataset, then presenting\nthe algorithm with a representative sample of that dataset clearly qualiﬁes as\nsupervision, and in this work we have termed such supervision internal. This\nis in contrast to external supervision in which the internal ‘basis’ feature are\nmapped to an external label.\nIn contrast to previous thinking which categorized supervision as either\npresent (supervised) or absent (unsupervised); in this work, we have argued\nthat supervision is always present in learning algorithms and is either inter-\nnal, external, or both. We have also pointed out how the scope of supervi-\nsion determines the scope of learning potential, which in turn determines the\nscope of inference potential. We anticipate that this change in perspective\nwill yield new fundamental insights into the structure and character of data\nand of learning algorithms.\nAcknowledgement\nI initially posted this idea on Linkedin on Friday March 29th 2019, where\nit generated good discussion. I’m thankful to discussion participants such\nas Emml Asimadi, Adebayo Aderibigbe, Idris Azeez, Busayo Coker, Oden\nVangelis, and Busayo Olukunle amongst others.\nReferences\n[Coates et al., 2011] Coates, A., Ng, A., and Lee, H. (2011). An analysis of\nsingle-layer networks in unsupervised feature learning. In Proceedings of\nthe fourteenth international conference on artiﬁcial intelligence and statis-\ntics, pages 215–223.\n[Coates and Ng, 2012] Coates, A. and Ng, A. Y. (2012). Learning feature\nrepresentations with k-means. In Neural networks: Tricks of the trade,\npages 561–580. Springer.\n[Goodfellow et al., 2014] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu,\nB., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014).\nGenerative adversarial nets. In Advances in neural information processing\nsystems, pages 2672–2680.\n7\n[Hinton et al., 2006] Hinton, G. E., Osindero, S., and Teh, Y.-W. (2006).\nA fast learning algorithm for deep belief nets.\nNeural computation,\n18(7):1527–1554.\n[Hinton and Salakhutdinov, 2006] Hinton, G. E. and Salakhutdinov, R. R.\n(2006). Reducing the dimensionality of data with neural networks. science,\n313(5786):504–507.\n[Jolliﬀe, 2011] Jolliﬀe, I. (2011). Principal component analysis. Springer.\n[Le et al., 2011] Le, Q. V., Ranzato, M., Monga, R., Devin, M., Chen, K.,\nCorrado, G. S., Dean, J., and Ng, A. Y. (2011). Building high-level features\nusing large scale unsupervised learning. arXiv preprint arXiv:1112.6209.\n[Lee et al., 2009] Lee, H., Grosse, R., Ranganath, R., and Ng, A. Y. (2009).\nConvolutional deep belief networks for scalable unsupervised learning of hi-\nerarchical representations. In Proceedings of the 26th annual international\nconference on machine learning, pages 609–616. ACM.\n[MacQueen et al., 1967] MacQueen, J. et al. (1967). Some methods for clas-\nsiﬁcation and analysis of multivariate observations. In Proceedings of the\nﬁfth Berkeley symposium on mathematical statistics and probability, vol-\nume 1, pages 281–297. Oakland, CA, USA.\n[Mirza and Osindero, 2014] Mirza, M. and Osindero, S. (2014). Conditional\ngenerative adversarial nets. arXiv preprint arXiv:1411.1784.\n[Ngiam et al., 2011] Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., and\nNg, A. Y. (2011). Multimodal deep learning. In Proceedings of the 28th\ninternational conference on machine learning (ICML-11), pages 689–696.\n[Radford et al., 2015] Radford, A., Metz, L., and Chintala, S. (2015). Un-\nsupervised representation learning with deep convolutional generative ad-\nversarial networks. arXiv preprint arXiv:1511.06434.\n[Schmidhuber, 1992] Schmidhuber, J. (1992).\nLearning factorial codes by\npredictability minimization. Neural Computation, 4(6):863–879.\n[Vincent et al., 2010] Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., and\nManzagol, P.-A. (2010). Stacked denoising autoencoders: Learning useful\nrepresentations in a deep network with a local denoising criterion. Journal\nof machine learning research, 11(Dec):3371–3408.\n8\n[Wagstaﬀet al., 2001] Wagstaﬀ, K., Cardie, C., Rogers, S., Schr¨odl, S., et al.\n(2001). Constrained k-means clustering with background knowledge. In\nIcml, volume 1, pages 577–584.\nFigure 3: About the Author: Dr. Stephen G. Odaibo is Founder, CEO,\nand Chief Software Architect of RETINA-AI Health Inc, a company using\nArtiﬁcial Intelligence to improve Healthcare. He is a Retina specialist, Math-\nematician, Computer Scientist, and Full-Stack AI Engineer. Dr. Odaibo is\nthe only Ophthalmologist in the world with advanced degrees in both Math-\nematics and Computer Science. In 2017 UAB College of Arts and Sciences\nawarded Dr. Odaibo its highest honor, the Distinguished Alumni Achieve-\nment Award. In 2005 he won the Barrie Hurwitz Award for Excellence in\nClinical Neurology at Duke Univ. School of Medicine where he topped the\nclass in Neurology and in Pediatrics.\nIn 2016 Dr.\nOdaibo delivered the\nOpening Keynote address at the Global Ophthalmologists Meeting in Osaka\nJapan. And he delivered the inaugural Special Guest Lecture in Ophthal-\nmology at the University of Ilorin, Nigeria. In 2018, Dr. Odaibo delivered\nthe keynote address at the National Medical Association’s New Innovations\nin Ophthalmology Session. And he delivered a Plenary Keynote address on\nAI in Healthcare at AI Expo Africa in Cape town, South Africa. He is au-\nthor of the book ”Quantum Mechanics and the MRI Machine” (2012), and\nof the book ”The Form of Finite Groups: A Course on Finite Group Theory”\n(2016). Clinically, Dr. Odaibo focuses on caring for patients with macular\ndegeneration, diabetic retinopathy, retinal vascular occlusions, retinal tears,\nand localized retinal detachments.\n9\n",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CV",
    "stat.ML"
  ],
  "published": "2019-04-05",
  "updated": "2019-04-05"
}