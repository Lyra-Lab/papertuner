{
  "id": "http://arxiv.org/abs/2108.01468v1",
  "title": "Quantum Neural Networks: Concepts, Applications, and Challenges",
  "authors": [
    "Yunseok Kwak",
    "Won Joon Yun",
    "Soyi Jung",
    "Joongheon Kim"
  ],
  "abstract": "Quantum deep learning is a research field for the use of quantum computing\ntechniques for training deep neural networks. The research topics and\ndirections of deep learning and quantum computing have been separated for long\ntime, however by discovering that quantum circuits can act like artificial\nneural networks, quantum deep learning research is widely adopted. This paper\nexplains the backgrounds and basic principles of quantum deep learning and also\nintroduces major achievements. After that, this paper discusses the challenges\nof quantum deep learning research in multiple perspectives. Lastly, this paper\npresents various future research directions and application fields of quantum\ndeep learning.",
  "text": "Quantum Neural Networks: Concepts, Applications,\nand Challenges\n◦Yunseok Kwak, ◦Won Joon Yun, ◦Soyi Jung, and ◦Joongheon Kim\n◦Department of Electrical and Computer Engineering, Korea University, Seoul 02841, Republic of Korea\nE-mails: yskwak6937@gmail.com, ywjoon95@korea.ac.kr,\njungsoyi@korea.ac.kr, joongheon@korea.ac.kr\nAbstract—Quantum deep learning is a research ﬁeld for the\nuse of quantum computing techniques for training deep neural\nnetworks. The research topics and directions of deep learning and\nquantum computing have been separated for long time, however\nby discovering that quantum circuits can act like artiﬁcial neural\nnetworks, quantum deep learning research is widely adopted.\nThis paper explains the backgrounds and basic principles of\nquantum deep learning and also introduces major achievements.\nAfter that, this paper discusses the challenges of quantum deep\nlearning research in multiple perspectives. Lastly, this paper\npresents various future research directions and application ﬁelds\nof quantum deep learning.\nI. INTRODUCTION\nAs quantum computing and deep learning have recently\nbegun to draw attentions, notable research achievements have\nbeen pouring over past decades. In the ﬁeld of deep learn-\ning, the problems which were considered as their inherent\nlimitations like gradient vanishing, local minimum, learning\ninefﬁciencies in large-scale parameter training are gradually\nbeing conquered [1]. On the one hand, innovative new deep\nlearning algorithms such as quantum neural network (QNN),\nconvolutional neural network (CNN), and recurrent neural\nnetwork (RNN) are completely changing the way various\nkinds of data are processed. Meanwhile, the ﬁeld of quantum\ncomputing has also undergone rapid developments in recent\nyears. Quantum computing, which has been recognized only\nfor its potential for a long time, has opened up a new era\nof enormous potentials with the recent advances of variational\nquantum circuits (VQC). The surprising potentials of the varia-\ntional quantum algorithms were made clear by solving various\ncombinatorial optimization problems and the intrinsic energy\nproblems of molecules, which were difﬁcult to solve using\nconventional methods, and further extensions are considered\nto design machine learning algorithms using quantum comput-\ning. Among them, quantum deep learning ﬁelds are growing\nrapidly, inheriting the achievements of existing deep learning\nresearch. Accordingly, numerous notable achievements related\nto quantum deep learning have been published, and active\nfollow-up studies are being conducted at this time. In this pa-\nper, we ﬁrst brieﬂy introduce the background knowledge, basic\nprinciples of quantum deep learning, and look at the current\nresearch directions. We then discuss the various directions and\nchallenges of future research in quantum deep learning.\nA. Quantum Computing\nQuantum computers use qubits as the basic units of com-\nputation, which represent a superposition state between |0⟩\nand |1⟩[2]–[5]. A single qubit state can be represented as a\nnormalized two-dimensional complex vector, i.e.,\n|ψ⟩= α|0⟩+ β|1⟩, ∥α∥2 + ∥β∥2 = 1\n(1)\nand ∥α∥2 and ∥β∥2 are the probabilities of observing |0⟩and\n|1⟩from the qubit, respectively. This can be also geometrically\nrepresented using polar coordinates θ and φ,\n|ψ⟩= cos(θ/2)|0⟩+ eiφ sin(θ/2)|1⟩,\n(2)\nwhere 0 ≤θ ≤π and 0 ≤φ ≤π. This representation maps a\nsingle qubit state into the surface of 3-dimensional unit sphere,\nwhich is called Bloch sphere. A multi qubit system can be\nrepresented as the tensor product of n single qubits, which\nexists as a superposition of 2n basis states from |00...00⟩\nto |11...11⟩. Quantum entanglement appears as a correlation\nbetween different qubits in this system. For example, in a 2-\nqubit system\n1\n√\n2|00⟩+ 1\n√\n2|11⟩, the observation of the ﬁrst qubit\ndirectly determines that of the second qubit. Those systems are\ncontrolled by quantum gates in a quantum circuit to perform\na quantum computation on its purpose [6], [7].\nQuantum gates are unitary operators mapping a qubit system\ninto another one, and as classical computing, it is known that\nevery quantum gate can be factorized into the combination\nof several basic operators like rotation operator gates and CX\ngate [8]. Rotation operator gates Rx(θ), Ry(θ), Rz(θ) rotates\na qubit state in Bloch sphere around corresponding axis by θ\nand CX gate entangles two qubits by ﬂipping a qubit state if\nthe other is |1⟩. Those quantum gates utilizes quantum super-\nposition and entanglement to take an advantage over classical\ncomputing, and it is well known that quantum algorithms\ncan obtain an exponential computational gain over existing\nalgorithms in certain tasks such as prime factorization [9].\nII. QUANTUM DEEP LEARNING\nA. Variational Quantum Circuits (VQC)\nA variational quantum circuit (VQC) is a quantum circuit\nusing rotation operator gates with free parameters to perform\nvarious numerical tasks, such as approximation, optimization,\nclassiﬁcation. An algorithm using a variational quantum circuit\nis called variational quantum algorithm (VQA), which is\narXiv:2108.01468v1  [quant-ph]  2 Aug 2021\na classical-quantum hybrid algorithm because its parameter\noptimization is often performed by a classical computer.\nSince its universal function approximating property [10], many\nalgorithms using VQC [11] are designed to solve various\nnumerical problems [2], [8], [12]–[14]. This ﬂow led to many\napplications of VQA in machine learning and is also for re-\nplacing the artiﬁcial neural network of the existing model with\nVQC [15]–[18]. VQC is similar to artiﬁcial neural networks in\nthat it approximates functions through parameter learning, but\nhas differences due to the several characteristics of quantum\ncomputing. Since all quantum gate operations are reversible\nlinear operations, quantum circuits use entanglement layers\ninstead of activation functions to have multilayer structures.\nThese VQCs are called quantum neural networks, and this\npaper will look at them through classiﬁcation according to\ntheir structure and characteristics.\nB. Quantum Neural Networks\nFig. 1. Illustration of QNN with the input |ψ⟩, the parameter θ and linear\nentanglement structure.\nIn this section, we try to demonstrate how a basic quantum\nneural network(QNN) works with a simple example described\nin the Fig. 1. The way a QNN processes data is as follows.\nFirst, the input data is encoded into the corresponding qubit\nstate of an appropriate number of qubits. Then, the qubit state\nis transformed through the parameterized rotation gates and\nentangling gates for a given number of layers. The transformed\nqubit state is then measured by obtaining expected value of a\nhamiltonian operator, such as Pauli gates. These measurements\nare decoded back into the form of appropriate output data.\nThe parameters are then updated by an optimizer like Adam\noptimizer. A neural network constructed in the form of VQC\ncan perform various roles in various forms, which will be\nexplored as quantum neural networks.\nFig. 2. Illustration of QCNN with the input |ψ⟩, the parameter θ with single\nconvolution and pooling layer.\n1) Quantum Convolutional Neural Networks:\nQuantum\nconvolutional neural network (QCNN) was proposed in [16],\nimplementing the convolution layer and pooling layer on the\nquantum circuits. According to the previous research results in\n[5], [19], the QCNN circuit computation proceeds as follows.\nThe ﬁrst step is same as any other QNN models, encoding\ninput data into a qubit state with rotation operator gates. Then\nthe convolution layer with quasi-local unitary gates ﬁlters\nthe input data into a feature map. The pooling layer with\ncontrolled rotation operators then downsizes the feature map.\nBy repeating this process sufﬁciently, the fully connected layer\nacts on the qubit state as classical CNN models. Finally, the\nmeasurement of the qubit state is decoded into an output data\nwith desired sizes. The circuit parameters are updated with\ngradient descent based optimizer after each measurements.\nUnfortunaltely, in the current quantum computing envi-\nronment [20], QCNN is difﬁcult to perform better than the\nexisting classical CNN. However, it is expected that the QCNN\nwill be able to obtain sufﬁcient computational gains over\nthe classical ones in future quantum computing environment\nwhere larger-size quantum calculations are possible [5], [16].\nIII. FUTURE WORK DIRECTIONS AND CHALLENGES\nA. Applications of Quantum Deep Learning to Reinforcement\nLearning\nThere are many research results applying deep learning to\nreinforcement learning to derive optimal actions from a com-\nplex state space [21]–[24]. However, reinforcement learning\nresearch using quantum deep learning [18], [25], [26] is still\nin its infancy. The current approach step is to replace the policy\ntraining network with a quantum neural network from the\nexisting deep neural network, but there remains the possibility\nof many algorithms applying various ideas of classical deep\nreinforcement learning researches. In particular, if it is proved\nthat quantum computational gains can be obtained through\nQNN in a situation of high computational complexity due to\nthe complex Markov decision process environment, quantum\nreinforcement learning will open a new horizon for reinforce-\nment learning research.\nB. Applications of Quantum Deep Learning to Communica-\ntion Networks\nThe QNN and quantum reinforcement learning algorithms\ncan be used in various research ﬁelds, and this paper considers\nthe applications in terms of communications and networks. In\nterms of the acceleration of computation in fully distributed\nplatforms, e.g., blockchain [27], [28], QNN can be used.\nIn addition, various advanced communication technologies\nsuch as Internet of Things (IoT) [29], [30], millimeter-wave\nnetworks [31], [32], caching networks [33]–[36], and video\nstreaming/scheduling [37]–[40] are good applications of QNN\nand quantum reinforcement learning algorithms.\nC. Challenges\n1) Gradient Vanishing: Vanishing gradient is a crucial\nproblem in quantum deep learning as of classical deep learn-\ning. The problem of gradient disappearance while backprop-\nagating many hidden layers has been considered a chronic\nproblem in deep neural network computation. Since quantum\nneural networks also use gradient descent method training\ntheir parameters as classical ones, they have to solve the same\nproblem. Classical deep learning models solve this problem by\nutilizing an appropriate activation function, but quantum deep\nlearning does not use an activation function, thus eventually, a\ndifferent solution is needed. A former research [41] called this\nquantum gradient vanishing pheonomena as barren plateaus,\nwhile proving that when the number of qubits increases, the\nprobability of occurring barren plateaus increases exponen-\ntially. This can be avoided by setting good initial parameters\nin small-scale QNN, but it is unavoidable to deal with this\nproblem when designing large-scale QNN. This is an open\nproblem for which a solution is not yet clear.\n2) Near-Term Device Compatibility: Noisy intermediate\nscale quantum (NISQ) [20], which means fewer qubits and a\nlot of computational error of near-term quantum devices, has\nalready become a familiar term to quantum researchers. Many\nalgorithms designed to implement quantum computational\ngains do not work at all in this NISQ environment, and are\nexpected to be implemented at least several decades later. For\nexample, a practical implementation of the Shor’s algorithm\nrequires at least thousand of qubits even without an error\ncorrection processes, current quantum devices have only a few\ntens of qubits with non-negligible computational error rate of\nseveral percent. However, due to the relatively small circuit\ndepth and qubit requirements, VQA and QNN based on them\nare tolerant to these environmental constraints. Nevertheless,\nin order to increase the data processing capability of quantum\nneural network, it is necessary to consider near-term device\ncompatibility. For example, using many multi-qubit controlling\ngates for quantum entanglement is theoretically thought to\nincrease the performance of QNN, but it entails a large error\nrate and a complicated error correction process. Therefore, it\nis essential to design an algorithm regarding these tradeoffs in\nquantum deep learning research.\n3) The Quantum Advantage: The term quantum supremacy\nmay lead to the illusion that quantum algorithms are always\nbetter than classical algorithms performing the same function.\nHowever, given the inherent limitations of quantum comput-\ning, quantum computing beneﬁts can only be realized through\nwell-thought-out algorithms under certain circumstances. In\nfact, especially among variational quantum-based algorithms,\nonly a few of them have proven their quantum advantage in a\nlimited situation.\nDue to the universal approximation property of QNN, it\nis known that quantum deep learning can perform most of\nthe computations performed in classical deep learning [10].\nNevertheless, if one approaches simply based on this fact\nwithout the consideration of quantum gain, the result may be\nmuch inefﬁcient compared to the existing classical algorithm.\nTherefore, in designing a new QNN-based deep learning algo-\nrithm, it is necessary to justify it by articulating its advantages\nover the corresponding classical models.\nIV. CONCLUSION\nThis paper introduces the basic concepts of quantum neural\nnetworks and their applications scenarios in various ﬁelds. Fur-\nthermore, this paper presents research challenges and potential\nsolutions of quantum neural network computation.\nACKNOWLEDGMENT\nThis work was supported by the National Research Foun-\ndation of Korea (2019M3E4A1080391). Joongheon Kim is a\ncorresponding author of this paper.\nREFERENCES\n[1] J. Park, S. Samarakoon, A. Elgabli, J. Kim, M. Bennis, S.-L. Kim,\nand M. Debbah, “Communication-efﬁcient and distributed learning over\nwireless networks: Principles and applications,” Proceedings of the\nIEEE, vol. 109, no. 5, pp. 796–819, May 2021.\n[2] J. Choi, S. Oh, and J. Kim, “Quantum approximation for wireless\nscheduling,” Applied Sciences, vol. 10, no. 20, 2020.\n[3] J. Choi and J. Kim, “A tutorial on quantum approximate optimization\nalgorithm (QAOA): Fundamentals and applications,” in Proceedings of\nthe IEEE International Conference on Information and Communication\nTechnology Convergence (ICTC), 2019, pp. 138–142.\n[4] J. Choi, S. Oh, and J. Kim, “The useful quantum computing techniques\nfor artiﬁcial intelligence engineers,” in Proceedings of the IEEE Interna-\ntional Conference on Information Networking (ICOIN), 2020, pp. 1–3.\n[5] S. Oh, J. Choi, and J. Kim, “A tutorial on quantum convolutional neural\nnetworks (QCNN),” in Proceedings of the IEEE International Con-\nference on Information and Communication Technology Convergence\n(ICTC), 2020, pp. 236–239.\n[6] J. Choi, S. Oh, and J. Kim, “A tutorial on quantum graph recurrent\nneural network (QGRNN),” in Proceedings of the IEEE International\nConference on Information Networking (ICOIN), 2021, pp. 46–49.\n[7] S. Oh, J. Choi, J.-K. Kim, and J. Kim, “Quantum convolutional\nneural network for resource-efﬁcient image classiﬁcation: A quantum\nrandom access memory (QRAM) approach,” in Proceedings of the IEEE\nInternational Conference on Information Networking (ICOIN), 2021, pp.\n50–52.\n[8] J. Choi, S. Oh, and J. Kim, “Energy-efﬁcient cluster head selection via\nquantum approximate optimization,” Electronics, vol. 9, no. 10, 2020.\n[9] P. W. Shor, “Polynomial-time algorithms for prime factorization and\ndiscrete logarithms on a quantum computer,” SIAM review, vol. 41, no. 2,\npp. 303–332, 1999.\n[10] J. Biamonte, “Universal variational quantum computation,” Physical\nReview A, vol. 103, no. 3, p. L030401, 2021.\n[11] M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin, S. Endo, K. Fujii,\nJ. R. McClean, K. Mitarai, X. Yuan, L. Cincio et al., “Variational\nquantum algorithms,” arXiv preprint arXiv:2012.09265, 2020.\n[12] E. Farhi, J. Goldstone, and S. Gutmann, “A quantum approximate\noptimization algorithm,” arXiv preprint arXiv:1411.4028, 2014.\n[13] A. Kandala, A. Mezzacapo, K. Temme, M. Takita, M. Brink, J. M.\nChow, and J. M. Gambetta, “Hardware-efﬁcient variational quantum\neigensolver for small molecules and quantum magnets,” Nature, vol.\n549, no. 7671, pp. 242–246, 2017.\n[14] J. Kim, Y. Kwak, S. Jung, and J.-H. Kim, “Quantum scheduling\nfor millimeter-wave observation satellite constellation,” in Proceedings\nof the IEEE VTS Asia Paciﬁc Wireless Communications Symposium\n(APWCS), 2021, pp. 1–1.\n[15] M. Schuld and N. Killoran, “Quantum machine learning in feature\nhilbert spaces,” Physical review letters, vol. 122, no. 4, p. 040504, 2019.\n[16] I. Cong, S. Choi, and M. D. Lukin, “Quantum convolutional neural\nnetworks,” Nature Physics, vol. 15, no. 12, pp. 1273–1278, 2019.\n[17] J. Bausch, “Recurrent quantum neural networks,” Advances in Neural\nInformation Processing Systems, vol. 33, 2020.\n[18] D. Dong, C. Chen, H. Li, and T.-J. Tarn, “Quantum reinforcement\nlearning,” IEEE Transactions on Systems, Man, and Cybernetics, Part\nB (Cybernetics), vol. 38, no. 5, pp. 1207–1220, 2008.\n[19] S. Garg and G. Ramakrishnan, “Advances in quantum deep learning:\nAn overview,” arXiv preprint arXiv:2005.04316, 2020.\n[20] J. Preskill, “Quantum computing in the nisq era and beyond,” Quantum,\nvol. 2, p. 79, 2018.\n[21] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wier-\nstra, and M. Riedmiller, “Playing atari with deep reinforcement learn-\ning,” arXiv preprint arXiv:1312.5602, 2013.\n[22] M. Choi, A. No, M. Ji, and J. Kim, “Markov decision policies for dy-\nnamic video delivery in wireless caching networks,” IEEE Transactions\non Wireless Communications, vol. 18, no. 12, pp. 5705–5718, December\n2019.\n[23] M. Shin, J. Kim, and M. Levorato, “Auction-based charging scheduling\nwith deep learning framework for multi-drone networks,” IEEE Trans-\nactions on Vehicular Technology, vol. 68, no. 5, pp. 4235–4248, May\n2019.\n[24] S. Jung, W. J. Yun, M. Shin, J. Kim, and J.-H. Kim, “Orchestrated\nscheduling and multi-agent deep reinforcement learning for cloud-\nassisted multi-UAV charging systems,” IEEE Transactions on Vehicular\nTechnology, vol. 70, no. 6, pp. 5362–5377, June 2021.\n[25] S. Y.-C. Chen, C.-H. H. Yang, J. Qi, P.-Y. Chen, X. Ma, and H.-S.\nGoan, “Variational quantum circuits for deep reinforcement learning,”\nIEEE Access, vol. 8, pp. 141 007–141 024, 2020.\n[26] S. Jerbi, C. Gyurik, S. Marshall, H. J. Briegel, and V. Dunjko, “Vari-\national quantum policies for reinforcement learning,” arXiv preprint\narXiv:2103.05577, 2021.\n[27] M. Saad, J. Choi, D. Nyang, J. Kim, and A. Mohaisen, “Toward\ncharacterizing blockchain-based cryptocurrencies for highly accurate\npredictions,” IEEE Systems Journal, vol. 14, no. 1, pp. 321–332, March\n2020.\n[28] E. Boo, J. Kim, and J. Ko, “LiteZKP: Lightening zero-knowledge proof-\nbased blockchains for IoT and edge platforms,” IEEE Systems Journal,\npp. 1–12, 2021.\n[29] N.-N. Dao, D.-N. Vu, W. Na, J. Kim, and S. Cho, “SGCO: Stabilized\ngreen crosshaul orchestration for dense IoT ofﬂoading services,” IEEE\nJournal on Selected Areas in Communications, vol. 36, no. 11, pp. 2538–\n2548, November 2018.\n[30] N.-N. Dao, T. V. Phan, U. Sa’ad, J. Kim, T. Bauschert, D.-T. Do,\nand S. Cho, “Securing heterogeneous IoT with intelligent DDoS attack\nbehavior learning,” IEEE Systems Journal, pp. 1–10, 2021.\n[31] S.\nJung,\nJ.\nKim,\nM.\nLevorato,\nC.\nCordeiro,\nand\nJ.-H.\nKim,\n“Infrastructure-assisted on-driving experience sharing for millimeter-\nwave connected vehicles,” IEEE Transactions on Vehicular Technology,\npp. 1–1, 2021.\n[32] J. Kim and A. F. Molisch, “Fast millimeter-wave beam training with re-\nceive beamforming,” Journal of Communications and Networks, vol. 16,\nno. 5, pp. 512–522, October 2014.\n[33] A. Malik, J. Kim, K. S. Kim, and W.-Y. Shin, “A personalized preference\nlearning framework for caching in mobile networks,” IEEE Transactions\non Mobile Computing, vol. 20, no. 6, pp. 2124–2139, June 2021.\n[34] M. Choi, J. Kim, and J. Moon, “Dynamic power allocation and user\nscheduling for power-efﬁcient and delay-constrained multiple access\nnetworks,” IEEE Transactions on Wireless Communications, vol. 18,\nno. 10, pp. 4846–4858, October 2019.\n[35] M. Choi, A. F. Molisch, and J. Kim, “Joint distributed link scheduling\nand power allocation for content delivery in wireless caching networks,”\nIEEE Transactions on Wireless Communications, vol. 19, no. 12, pp.\n7810–7824, December 2020.\n[36] M. Choi, A. F. Molisch, D.-J. Han, D. Kim, J. Kim, and J. Moon,\n“Probabilistic caching and dynamic delivery policies for categorized\ncontents and consecutive user demands,” IEEE Transactions on Wireless\nCommunications, vol. 20, no. 4, pp. 2685–2699, April 2021.\n[37] J. Kim, G. Caire, and A. F. Molisch, “Quality-aware streaming and\nscheduling for device-to-device video delivery,” IEEE/ACM Transactions\non Networking, vol. 24, no. 4, pp. 2319–2331, August 2016.\n[38] M. Choi, J. Kim, and J. Moon, “Wireless video caching and dynamic\nstreaming under differentiated quality requirements,” IEEE Journal on\nSelected Areas in Communications, vol. 36, no. 6, pp. 1245–1257, June\n2018.\n[39] J. Koo, J. Yi, J. Kim, M. A. Hoque, and S. Choi, “Seamless dynamic\nadaptive streaming in LTE/Wi-Fi integrated network under smartphone\nresource constraints,” IEEE Transactions on Mobile Computing, vol. 18,\nno. 7, pp. 1647–1660, July 2019.\n[40] J. Yi, S. Kim, J. Kim, and S. Choi, “Supremo: Cloud-assisted low-\nlatency super-resolution in mobile devices,” IEEE Transactions on\nMobile Computing, pp. 1–1, 2021.\n[41] J. R. McClean, S. Boixo, V. N. Smelyanskiy, R. Babbush, and H. Neven,\n“Barren plateaus in quantum neural network training landscapes,” Nature\ncommunications, vol. 9, no. 1, pp. 1–6, 2018.\n",
  "categories": [
    "quant-ph",
    "cs.LG"
  ],
  "published": "2021-08-02",
  "updated": "2021-08-02"
}