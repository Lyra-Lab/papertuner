{
  "id": "http://arxiv.org/abs/2207.08309v1",
  "title": "CULT: Continual Unsupervised Learning with Typicality-Based Environment Detection",
  "authors": [
    "Oliver Daniels-Koch"
  ],
  "abstract": "We introduce CULT (Continual Unsupervised Representation Learning with\nTypicality-Based Environment Detection), a new algorithm for continual\nunsupervised learning with variational auto-encoders. CULT uses a simple\ntypicality metric in the latent space of a VAE to detect distributional shifts\nin the environment, which is used in conjunction with generative replay and an\nauxiliary environmental classifier to limit catastrophic forgetting in\nunsupervised representation learning. In our experiments, CULT significantly\noutperforms baseline continual unsupervised learning approaches. Code for this\npaper can be found here: https://github.com/oliveradk/cult",
  "text": "CULT: Continual Unsupervised Learning with\nTypicality-Based Environment Detection\nOliver Daniels-Koch1\n1Brandeis University\nMay 2022\nAbstract\nWe introduce CULT (Continual Unsupervised Representation Learn-\ning with Typicality-Based Environment Detection), a new algorithm for\ncontinual unsupervised learning with variational auto-encoders.\nCULT\nuses a simple typicality metric in the latent space of a VAE to detect dis-\ntributional shifts in the environment, which is used in conjunction with\ngenerative replay and an auxiliary environmental classiﬁer to limit catas-\ntrophic forgetting in unsupervised representation learning. In our exper-\niments, CULT signiﬁcantly outperforms baseline continual unsupervised\nlearning approaches. 1\n1\nIntroduction\nDeep neural networks often suﬀer from catastrophic forgetting - when learning\na new task, their performance on previously learned tasks rapidly degrades.\nContinual learning is the problem of overcoming catastrophic forgetting. While\nmuch of the continual learning literature focused on supervised tasks, here we are\ninterested in unsupervised continual learning, that is, learning a task-agnostic\nrepresentations of multiple environments.\nWhen learning such task-agnostic\nrepresentations, it is often useful to detect environmental shifts, which in turn\nrequires some anomaly detection method. Variational Autencoders [8] provide\none possible method. Since VAE’s parameterize a likelihood function on the\ndata, we can detect new environments (anomalies) by monitoring whether the\nlikelihood function exceed some threshold. However, multiple studies [11], [6],\n[4] have found that likelihood is not a reliable metric for out-of-distribution\ndetection - out of distribution samples will often be assigned a higher likeli-\nhood than in-distribution samples. We produce similar results, ﬁnding that a\nVAE trained on FashionMNIST [15] assigns higher likelihood to out of distri-\nbution MNIST samples than to in distribution FashionMNIST samples. As [4]\n1code for this paper can be found here: https://github.com/oliveradk/cult\n1\narXiv:2207.08309v1  [cs.LG]  17 Jul 2022\nnotes, this defect of likelihood may be caused by the diﬀerent between likeli-\nhood and typicality. Typical samples (those that have information value close\nto the expected information) are diﬀerent from the maximally likely samples,\nand while any given sample in the typical set is less likely than the maximally\nlikely sample, a sequence of samples from the typical set is more likely than\na sequence of maximally likely samples.\nInspired by [2], we use this insight\nfor a new typicality-based environmental detection algorithm, monitoring the\nKL divergence between a normal distribution parameterized by the mean and\nstandard deviation of a given batch of latent variables. This method reliably\ndetects environmental shifts from FashionMNIST to MNIST in both directions.\nWhen coupled with generative replay [14], atypicality based anomoly detectoin\nprovides a simple, eﬀective solution to unsupervised continual learning with\nvariational auto encoders.\n2\nRelated Work\n2.1\nContinual Learning\nContinual learning can roughly be split into three categories: rehearsal, gradi-\nent ﬂow, and architecture expansion. Rehearsal (or replay) methods use past\nexamples (either stored [10], or generated [14]) to train on while learning new\ntasks. Gradient based methods [9], [16] avoid updating parameters were im-\nportant for previous tasks. Architectural expansions dynamically allocate new\nmodel capacity for new tasks and environments [13] [5].\n2.2\nContinual Unsupervised Learning\nWhile much of the continual learning literature focused on continuously learning\ntasks, like classiﬁcation and game-playing, there is also work focused on learning\nrepresentations continually on unlabeled data. CURL [12] used dynamic expan-\nsion on a VAE, allocating more capacity when the likelihood of samples falls\nbelow some threshold. VASE[2] also relies on a variational auto-encoder, but\nuses generative replay and latent masking to prevent catastrophic forgetting,\nwith latent masks determined by a typicality metric on each latent. We use a\nsimilar metric to detect new environments, as described below.\n2.3\nAnomaly Detection with Generative Models\nIntuitively, likelihood should be a useful metric for anomaly/out-of-distribution\ndetection for probabilistic generative models.\nHowever, a mounting body of\nwork [11], [6], [4] has shown that likelihood metrics often assign higher likeli-\nhoods to out of distribution samples. [4] hypothesizes that this failure is due to\nthe diﬀerence between likelihood and typicality, but shows that their method is\nalso does not promote typical points as more ”in-distribution”. We are aware of\nonly one work ([2]) that directly uses a typicality-based metric for unsupervised\n2\ncontinual learning, but this metric was used in the context of latent masking,\nrather than ”pure” anomaly detection for environment inference.\n3\nTypicality\n3.1\nFormal Deﬁnition\nFor an i.i.d sequence x1, x2, ..., xn drawn from an alphabet X, the typical set\nT (n)\nϵ\nis given by all such sequences satisfying the following inequality:\nH(x) −ϵ ≤−1\nn log p(x1, x2, ..., xn) ≤H(X) + ϵ\nsuch that in the limit the average information of elements in the typical set\nconverges to the entropy of the distribution.\nUsing this deﬁnition, we deﬁne the ”most typical” set T (n)\n0\nas all such se-\nquences exactly satisfying the equality\n−1\nn log p(x1, x2, ..., xn) = H(x)\n3.2\nVolume in High Dimensional Space\nTo get an intuitive sense for why typicality-based metrics are favorable in com-\nparison to likelihood, we need to review on how volume operates in high dimen-\nsional space. Following the work of [1], for a neighborhood N in Rd, the relative\nvolume of N decreases as a function of d. When considering a density function\nπ deﬁned on Rd, then as d increases, most of the mass of π will be concentrated\nwhere the density function and the volume are suﬃciently large. Notably, the\nmass does not necessarily concentrate at the mode.\n3.3\nThe Typical Set of the Isotropic Gaussian\nThis interplay between density and volume is made clear in the case of the\nmultivariate isotropic gaussian, where the distance of the ”most typical” samples\nto the mean is a monotonically increasing function of the dimensional of the\nsample space. Given x ∼N(0 ∈Rd, I ∈Rdxd), the most typical set is given by\nT (n)\n0\n(N(0, 1)) = {x| −log p(x) = H[N(0, 1)]}\nwhich reduces to\nT (n)\n0\n(N(0, 1)) = {x|∥x∥=\n√\nd}\nSee A for the computation. As the example above shows, drawing samples close\nto the mean of a multivariate gaussian becomes less likely as the dimensional of\nthe sample space increases. So, if our distribution is approximated by a neural\nnetwork, samples which are far from the most typical set (either close to the\n3\nmean or very far from the mean), should be treated as anomalies. As stated\nbelow, we approximate this typicality ”distance” using KL divergence from the\nisotropic gaussian prior.\n4\nCULT\n4.1\nProblem Formalism\nWe assume a distribution s ∼Cat(π1, ..., K) over a set of K environments\nS = {s1, s2, ..., sK}, which share N latent generative factors from the setZ =\n{z1, z2, ..., zN}. z is assumed to be standard normal, that is z ∼N(0, 1). A\ndataset xs ∼p(·|zs, s) can be synthesized from latents conditioned on the envi-\nronment. Together, we have the following generative process:\nz ∼N(0, 1),\ns ∼Cat(π1, ..., K),\nxs ∼p(·|zs, s)\nThis setup is a simpliﬁed version of that in [2], doing away with latent masking.\n4.2\nInferring the Generative Factors\nWe use standard variational inference [8] to infer the generative factors, maxi-\nmizing the ELBO and using the re parameterization trick to eﬃciently compute\ngradients through the sampling of the normally distributed latents. This ELBO\nloss is given by:\nLELBO = Ezs∼qφ(·|xs)[−log pθ(x|zs, s)] + DKL(qφ(zs|xs)||p(z))\nNote that unlike [2], we do not promote disentanglement by scaling the KL-\nDivergence term [7], [3].\n4.3\nInitializing and Inferring the Environment\nTo detect new environments, we use a typicality metric taken over each batch.\nFor each batch xs\nB, we compute the latent features zs\nB. We then compute the\nempirical mean and standard deviation of the latent batch, use these statistics\nto ﬁt a diagonal gaussian, and take the KL Divergence of this gaussian and the\nstandard normal distribution: α = PN\ni=1 DKL(N(¯µn, ¯σn)||N(0, 1))\nWe maintain an environment index m and a boolean learning, and deﬁne\ntwo hyperparameters λ0, λ1.\nIf alpha > λ1 and learning is false, then we\ninitialize a new environment, setting learning to true and incrementing m. If\nlearning is true and α < λ0, then we set learning to false. Else, we use an\nenvironment inference network qψ(s|xB) to determine the environment sB of the\nbatch. The intuition here is that we want to capture spikes in the atypically\nmetric when entering a new environment, without allocating multiple indices to\nthe same environment. See Algorithm 1 for the psuedo-code.\n4\nAlgorithm 1 Typicality-Based Environment Detection and Inference\nλ0, λ1\nm ←0\nlearning ←True\nfor xB in X do\nˆs ←qψ(·|xB)\nzB ←qφ(·|xB)\nα ←PN\ni=1 DKL(N(¯µn, ¯σn)||N(0, 1))\nif α > λ1 and learning = False then\nm ←m + 1\nlearning ←True\ns ←m\nelse if α < λ0 and learning = True then\nlearning ←False\ns ←ˆs\nelse\ns ←ˆs\nend if\nend for\n4.4\nPreventing Catastrophic Forgetting\nWe use generative replay to mitigate catastrophic, leveraging the accurate en-\nvironment detector by copying and freezing the current model after an envi-\nronment is initialized. On each training iterations, ”hallucinated” samples are\ngenerated from the frozen model via Monte-Carlo sampling. These samples are\npassed through the frozen model and current model, with a loss penalizing the\nencoder and decoder proximity of the current model to the frozen model on the\nsamples.\nLpast(φ, θ) = Ez,s′,x′\u0002\nD[qφ(z|x′), qφ′(z′|x′)] + D[qθ(x|z, s′), qθ′(x′|z, s′)\n\u0003\n4.5\nEnvironment Inference Network\nThe environment inference network is a linear layer added to the ﬁnal layer of\nthe encoder network, trained to predict the environment index. The training\ntarget on the current environment is given by the current environment index. To\nprevent catastrophic forgetting, the network is also trained on the hallucinated\nsamples:\nLenv = Ex[−log qφ(ˆs|x)] + Eˆs̸=s<mEx′∼pθ′(x′|z′,s)[−log qφ(s|x′)]\n5\n5\nExperiments\n5.1\nContinual Unsupervised Learning with CULT\nWe trained CULT on FashionMNIST to MNIST and MNIST to FashionMNIST\nfor 10 epochs on each environment. The encoder and decoder were fully con-\nnected networks with one hidden layer of size 50, and a latent bottleneck of\n16 variables. We set λ1 = 1.4, λ0 = 0.25. Adam was used with a learning\nrate of 1e-3 for the main network and 1e-4 for the environment network. The\nenvironment network also uses dropout with a dropout rate of .5.\n5.2\nEvaluating Catastrophic Forgetting\nTo evaluate catastrophic forgetting, we measure the reconstruction loss of a\ntrained model on a dataset seen earlier in training. To test how well the model\nhas preserved representations useful for downstream tasks, we also train classi-\nﬁers with 1 hidden layer of size 50 on the latent representations.\n5.3\nBaseline\nTo compare the performance of CULT to relevant baselines, we ran FashionM-\nNIST to MNIST while updating the replay network at a ﬁxed interval of 500\nsteps, and FashionMNIST to MNIST with no generative replay.\n5.4\nResults\n5.4.1\nReconstruction Loss\nCULT dramatically outperforms baseline generative replay, more than halv-\ning reconstruction loss on FashionMNIST. In fact, the CULT model trained\non FashionMNIST then MNIST has only slightly higher reconstruction loss on\nFashionMNIST then the CULT model trained on MNIST then FashionMNIST.\nA similar result holds on MNIST reconstruction loss, with the MNIST to Fash-\nionMNIST CULT model achieving an only slightly higher reconstruction loss on\nMNIST then the FashionMNIST to MNIST CULT model (See ﬁgure 1).\nFigure 1: Reconstruction Losses\n6\n5.4.2\nLatent Classiﬁcation\nFigure 2: Classiﬁcation Accuracy\nClassiﬁers trained on CULT’s latent representations of FashionMNIST achieve\na higher accuracy then classiﬁers trained on the latent representations produced\nby generative replay and no generative replay models. On MNIST, the CULT\nmodel trained on MNIST to FashionMNIST achieves rough parity with the other\nFashionMNIST to MNIST models, even out performing the no replay Fashion-\nMNIST to MNIST model. Figure 2 illustrates these training dynamics. Note\nhow after the datasets switch (indicated by the blue dotted line), classiﬁcation\naccuracy rapidly degrades for the generative replay and non generative replay\nmodels, but only slightly decreases and then stabilizes for the CULT Fashion-\nMNIST to MNIST model.\n5.4.3\nAnomaly Detection Metrics\nTracing the KL divergence, reconstruction loss, and atypicality training curves\nin ﬁgure 3 validates the hypothesis that typicality based anomaly detection\nmethods overcome outstanding issues with likelihood based metrics. In particu-\nlar, note that in the transition from FashionMNIST to MNIST (again indicated\nby the dotted blue line), the KL divergence and reconstruction loss decrease,\nwhile the atypicality score increases.\nMNIST samples are assigned a higher\nlikelihood, but are atypical - thus using atypicality based anomaly detection is\nmore successful than likelihood based anomaly detection.\n6\nConclusion\nWe presented CULT, a simple framework for using typicality-based environ-\nmental detection to facilitate continual learning with variational autoencoders\nand generative replay. Potential avenues for future work include running ex-\nperiments on larger models and more complex datasets, experimenting with\n7\nFigure 3: Anomaly Detection Metrics\n8\ndiﬀerent typicality metrics, and performing a more rigorous analysis of typical-\nity in generative probabilistic models.\nReferences\n[1]\nA Conceptual Introduction to Hamiltonian Monte Carlo. arXiv:1701.02434\n[stat]. July 2018. doi: 10.48550/arXiv.1701.02434. url: http://\narxiv.org/abs/1701.02434 (visited on 07/16/2022).\n[2]\nAlessandro Achille et al. “Life-Long Disentangled Representation Learn-\ning with Cross-Domain Latent Homologies”. en. In: (Aug. 2018). doi:\n10.48550/arXiv.1808.06508. url: https://arxiv.org/abs/1808.\n06508v1 (visited on 03/23/2022).\n[3]\nChristopher P. Burgess et al. “Understanding disentangling in $\\beta$-\nVAE”. In: arXiv:1804.03599 [cs, stat] (Apr. 2018). arXiv: 1804.03599.\nurl: http://arxiv.org/abs/1804.03599 (visited on 05/12/2022).\n[4]\nHyunsun Choi, Eric Jang, and Alexander A. Alemi. “WAIC, but Why?\nGenerative Ensembles for Robust Anomaly Detection”. In: arXiv:1810.01392\n[cs, stat] (May 2019). arXiv: 1810.01392. url: http://arxiv.org/abs/\n1810.01392 (visited on 05/12/2022).\n[5]\nTimothy J. Draelos et al. “Neurogenesis deep learning: Extending deep\nnetworks to accommodate new classes”. In: 2017 International Joint Con-\nference on Neural Networks (IJCNN). ISSN: 2161-4407. May 2017, pp. 526–\n533. doi: 10.1109/IJCNN.2017.7965898.\n[6]\nDan Hendrycks, Mantas Mazeika, and Thomas Dietterich. “Deep Anomaly\nDetection with Outlier Exposure”. In: arXiv:1812.04606 [cs, stat] (Jan.\n2019). arXiv: 1812.04606. url: http://arxiv.org/abs/1812.04606\n(visited on 05/12/2022).\n[7]\nIrina Higgins et al. “Early Visual Concept Learning with Unsupervised\nDeep Learning”. In: arXiv:1606.05579 [cs, q-bio, stat] (Sept. 2016). arXiv:\n1606.05579. url: http : / / arxiv . org / abs / 1606 . 05579 (visited on\n03/28/2022).\n[8]\nDiederik P. Kingma and Max Welling. “Auto-Encoding Variational Bayes”.\nen. In: (Dec. 2013). doi: 10.48550/arXiv.1312.6114. url: https:\n//arxiv.org/abs/1312.6114v10 (visited on 03/23/2022).\n[9]\nJames Kirkpatrick et al. “Overcoming catastrophic forgetting in neural\nnetworks”. In: arXiv:1612.00796 [cs, stat] (Jan. 2017). arXiv: 1612.00796.\nurl: http://arxiv.org/abs/1612.00796 (visited on 05/12/2022).\n[10]\nVolodymyr Mnih et al. “Playing Atari with Deep Reinforcement Learn-\ning”. In: arXiv:1312.5602 [cs] (Dec. 2013). arXiv: 1312.5602. url: http:\n//arxiv.org/abs/1312.5602 (visited on 05/12/2022).\n9\n[11]\nEric Nalisnick et al. “Do Deep Generative Models Know What They Don’t\nKnow?” In: arXiv:1810.09136 [cs, stat] (Feb. 2019). arXiv: 1810.09136.\nurl: http://arxiv.org/abs/1810.09136 (visited on 05/12/2022).\n[12]\nDushyant Rao et al. “Continual Unsupervised Representation Learning”.\nIn: arXiv:1910.14481 [cs, stat] (Oct. 2019). arXiv: 1910.14481. url: http:\n//arxiv.org/abs/1910.14481 (visited on 05/12/2022).\n[13]\nAndrei A. Rusu et al. “Progressive Neural Networks”. In: arXiv:1606.04671\n[cs] (Sept. 2016). arXiv: 1606.04671. url: http://arxiv.org/abs/1606.\n04671 (visited on 05/12/2022).\n[14]\nHanul Shin et al. “Continual Learning with Deep Generative Replay”.\nIn: arXiv:1705.08690 [cs] (Dec. 2017). arXiv: 1705.08690. url: http :\n//arxiv.org/abs/1705.08690 (visited on 03/28/2022).\n[15]\nHan Xiao, Kashif Rasul, and Roland Vollgraf. “Fashion-MNIST: a Novel\nImage Dataset for Benchmarking Machine Learning Algorithms”. In: arXiv:1708.07747\n[cs, stat] (Sept. 2017). arXiv: 1708.07747. url: http://arxiv.org/abs/\n1708.07747 (visited on 05/12/2022).\n[16]\nFriedemann Zenke, Ben Poole, and Surya Ganguli. “Continual Learn-\ning Through Synaptic Intelligence”. In: arXiv:1703.04200 [cs, q-bio, stat]\n(June 2017). arXiv: 1703.04200. url: http://arxiv.org/abs/1703.\n04200 (visited on 05/12/2022).\nA\nTypicality Derivation\nFirst note that the entropy (in nats) of a multivariate gaussian N(µ, Σ) is given\nby\nH[N(µ, Σ)] = 1\n2 ln |Σ| + D\n2 (1 + ln 2π)\nwhich, in the case of Σ = I, reduced to\nH[N(0, I)] = D\n2 (1 + ln 2π)\nNext, we compute the negative log probability of a sample x ∼N(0, I)\n−ln p(x) = −ln\n\u0014\n(2π)−d\n2 Σ−1\n2 exp(−1\n2(x −µ)T Σ−1(x −µ))\n\u0015\n= −ln\n\u0014\n(2π)−d\n2 exp(−1\n2∥x∥2)\n\u0015\n= D\n2 ln(2π) + 1\n2∥x∥2\nSetting these expressions equal and canceling like terms, we have\n10\n1\n2∥x∥2 = D\n2\n∥x∥=\n√\nD\n11\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2022-07-17",
  "updated": "2022-07-17"
}