{
  "id": "http://arxiv.org/abs/cmp-lg/9507009v1",
  "title": "Specifying Logic Programs in Controlled Natural Language",
  "authors": [
    "Norbert E. Fuchs",
    "Rolf Schwitter"
  ],
  "abstract": "Writing specifications for computer programs is not easy since one has to\ntake into account the disparate conceptual worlds of the application domain and\nof software development. To bridge this conceptual gap we propose controlled\nnatural language as a declarative and application-specific specification\nlanguage. Controlled natural language is a subset of natural language that can\nbe accurately and efficiently processed by a computer, but is expressive enough\nto allow natural usage by non-specialists. Specifications in controlled natural\nlanguage are automatically translated into Prolog clauses, hence become formal\nand executable. The translation uses a definite clause grammar (DCG) enhanced\nby feature structures. Inter-text references of the specification, e.g.\nanaphora, are resolved with the help of discourse representation theory (DRT).\nThe generated Prolog clauses are added to a knowledge base. We have implemented\na prototypical specification system that successfully processes the\nspecification of a simple automated teller machine.",
  "text": "CLNLP 95, WORKSHOP ON COMPUTATIONAL LOGIC FOR NATURAL LANGUAGE PROCESSING, EDINBURGH, APRIL 3-5, 1995\nSpecifying Logic Programs in Controlled Natural Language\nNorbert E. Fuchs, Rolf Schwitter\nDepartment of Computer Science, University of Zurich\n{fuchs, schwitter}@ifi.unizh.ch\nAbstract\nWriting specifications for computer programs is not easy since one has to take into account the disparate\nconceptual worlds of the application domain and of software development. To bridge this conceptual gap we\npropose controlled natural language as a declarative and application-specific specification language. Controlled\nnatural language is a subset of natural language that can be accurately and efficiently processed by a computer,\nbut is expressive enough to allow natural usage by non-specialists. Specifications in controlled natural language\nare automatically translated into Prolog clauses, hence become formal and executable. The translation uses a\ndefinite clause grammar (DCG) enhanced by feature structures. Inter-text references of the specification, e.g.\nanaphora, are resolved with the help of discourse representation theory (DRT). The generated Prolog clauses are\nadded to a knowledge base. We have implemented a prototypical specification system that successfully processes\nthe specification of a simple automated teller machine.\n1\nDeclarative Specifications\nThe derivation of formal software specifications from informal requirements is\nnot easy and cannot be formalised. However, the derivation process can be made\neasier by the deliberate choice of a specification language that allows users to\nexpress concepts of an application domain concisely and directly, and to convince\nthem of the adequacy of the specification without undue difficulty.\nThough Prolog has been recommended as a general high-level specification\nlanguage, and has often been used as such, application-specific specification\nlanguages seem to be a better choice since they allow users to express the concepts\nof the application domain directly, and still can be mapped to Prolog [Sterling 92].\nBy making \"true statements about the intended domain of discourse\" [Kramer &\nMylopoulos 92] and \"expressing basic concepts directly, without encoding, taking\nthe objects of the language as abstract entities\" [Börger & Rosenzweig 94],\napplication-specific specification languages are – in the true sense of the word –\ndeclarative, and have all the advantages of declarative programming [Lloyd 94].\nIn a previous phase of our project we have already shown that graphical and\ntextual views of logic programs can be considered as application-specific\nspecification languages [Fuchs & Fromherz 94]. Graphical views include\ntransition networks for finite state automata and window-oriented user-\ninterfaces, while textual views comprise formal specification languages.\nEach view has an associated editor that allows to compose specifications from\npredefined and reusable elements of a repository. Furthermore, there is an\nautomatic bi-directional mapping between a program and its views.\nBoth these features have important consequences.\n•\nWith the help of the view editors we can compose programs by means of\napplication-specific concepts.\n•\nThe mapping of a view to a program in a logic language assigns a formal\nsemantics to the view. Thus, though views give the impression of being\ninformal and have no intrinsic meaning, they are in fact formal and have the\nsemantics of their associated program.\n– 2 –\n•\nThe executability of the logic program and the semantics-preserving bi-\ndirectional mapping between a program and its views enable us to simulate\nthe execution of the program on the level of the views. Thus validation and\nprototyping in concepts close to the application domain become possible.\n•\nBy providing semantically equivalent representations, we can reduce the gap\nbetween the different conceptual worlds of the application domain specialist\nand of the software developer. In addition, the dual-faced informal/formal\nappearance of the views provides an effective solution for the critical\ntransition from informal to formal representations.\nAltogether, the characteristics of the views let us call them specifications of the\nprogram. Furthermore, since the views are semantically equivalent to the\nprogram, they can even be considered as executable specifications.\nIn the following, we describe an approach using controlled natural language – a\nsubset of natural language characterised by a restricted grammar and an\napplication-specific vocabulary – as a further view of a logic program. Users\ncompose specifications for logic programs in controlled natural language that are\nautomatically translated into Prolog clauses. As pointed out above, this\ntranslation makes seemingly informal specifications in controlled natural\nlanguage formal, assigns them a semantics, and gives them the combined\nadvantages of informality and formality. The generated Prolog knowledge base\ncan be queried and executed. Its clauses can also be paraphrased in controlled\nnatural language. However – contrary to the system described in [Fuchs &\nFromherz 94] – the exact original cannot be reproduced since the controlled\nnatural language system uses a finely-grained lexicon instead of a repository of\nlarger chunks of interrelated information.\nWe have implemented a specification system offering the following\nfunctionality. The user enters interactively specification text in controlled\nnatural language that is parsed by a DCG enhanced by feature structures, analysed\nfor discourse references, and translated into Prolog clauses that are added to a\nknowledge base. The user can ask questions that are processed as Prolog queries\nand answered with the help of the knowledge base. Our main specification\nexample is a simple automated teller machine.\nSection of this paper 2 describes the motivation for controlled natural language\nand delineates its syntactical constructs. In section 3 we briefly introduce phrase\nstructure grammars and GULP, a linearised notation for feature structures.\nSection 4 summarises discourse representation theory and gives examples of\nsimple and complex discourse representation structures. Furthermore, we show\nhow eventualities – events and states – can be represented by discourse\nrepresentation structures in a natural way. In section 5 we give an overview of\nthe prototypical specification system that we have been implementing. Section 6\nshows the translation of an example sentence in controlled natural language\ninto a discourse representation structure, and then into Prolog. This section also\naddresses the paraphrasing of specifications, query answering, and the execution\nof a specification. In section 7 we conclude and outline future research.\n– 3 –\n2\nControlled Natural Language\nA software specification is a statement of the services a software system is\nexpected to provide to its users. It should be written in a concise way that is\nunderstandable by all potential users of the system [Sommerville 92]. Strangely\nenough, this goal is hard to achieve if specifications are expressed in full natural\nlanguage. Natural language terminology tends to be ambiguous, imprecise and\nunclear. Also, there is considerable room for errors and misunderstandings since\npeople may have different views of the role of the software system.\nFurthermore, requirements vary and new requirements arise so that the\nspecification is subject to frequent change. All these factors can lead to\nincomplete and inconsistent specifications that are difficult to validate against\nthe requirements. People have advocated the use of formal specification\nlanguages to eliminate some of the problems associated with natural language,\nbut formal languages have a grave disadvantage: they are not easily understood\nby untrained users.\nThough it may seem that we are stuck between the over-flexibility of natural\nlanguage and the potential incomprehensibility of formal languages, there is a\nsolution. To improve the quality of specifications without loosing their\nreadability we propose to restrict the use of natural language in specifications to a\ncontrolled subset with a well-defined syntax and semantics. On the one hand this\nsubset should be expressive enough to allow natural usage by non-specialists,\nand on the other hand the language should be accurately and efficiently\nprocessable by a computer.\nWe suggest that the basic model of controlled natural language should cover the\nfollowing constructs:\n•\nsimple declarative sentences of the form subject – predicate – object\n•\nrelative clauses, both subject and object modifying\n•\ncomparative constructions like bigger than, smaller than and equal to\n•\ncompound phrases like and-lists, or-lists, and-then-lists\n•\nif ... then sentences\n•\nnegation like does not, is not and has not\n•\nyes/no queries, wh-queries\nSimilar constructs have been proposed for the computer-processable natural\nlanguage of Pulman and collaborators [Macias & Pulman 92, Pulman 94].\nFurthermore, the controlled language is characterised by a vocabulary that\ncomprises the usual closed word classes – prepositions, determiners etc. – and\napplication-specific subsets of the open classes – e.g. nouns and verbs.\nUsers seem to be able to construct sentences in controlled natural language, and\nto avoid constructions that fall outside the bounds of the language, particularly\nwhen the system gives feedback of the analysed sentences in a paraphrased form\n[Epstein 85, Capindale & Crawford 89]. We are convinced that employing\ncontrolled natural language for specifications will be most successful when users\nare trained and willing to strive for clear writing.\n– 4 –\nAn additional benefit of controlled natural language is that it may help finding\nan agreement concerning the correct interpretation of a specification. This is of\nutmost importance because a software specification will be read, interpreted,\ncriticised, and rewritten, many times until a result is produced that is satisfactory\nto all participants.\n3\nUnification-Based Phrase Structure Grammars (PSGs)\nThe framework of phrase structure grammars builds the theoretical background\nfor the syntactic and semantic processing of controlled language texts [Borsley 91].\nFor our implementation we are using Definite Clause Grammars enhanced by\nfeature structures. These feature structures are written in GULP (Graph\nUnification Logic Programming) – a syntactic extension of Prolog that supports\nthe implementation of unification-based PSGs by adding a notation for\nlinearised feature structures [Covington 94], e.g.\ncase:nom .. agr:( person:third .. number:sg )\nGULP adds to Prolog two operators and a number of system predicates. The first\noperator ':' binds a feature name to its value that can be a category. The second\noperator '..' joins one feature-value pair to the next.\nGULP feature structures can be combined with the DCG formalism to yield a\npowerful lingua franca for natural language processing. Technically, this means\nintroducing GULP feature structures as arguments into nodes of DCGs. Thus we\ncan write\nsentence -->\nnoun_phrase(case:nom .. agr:Person_Number),\nverb_phrase(agr:Person_Number).\nThe GULP translator accepts a Prolog program, scans it for linearised feature\nstructures and converts them – by means of automatically built translation\nschemata – into an internal term representation called value list. Grammar rules\nare parsed top-down by the Prolog interpreter.\n4\nDiscourse Representation Theory (DRT)\nCorrect understanding of a specification requires not only processing of\nindividual sentences and their constituents, but also taking into account the way\nsentences are interrelated to express complex propositional structures. It has been\nrecognised that aspects such as pronominal reference, tense and propositional\nattitudes cannot be successfully handled without taking the preceding discourse\ninto consideration. We do this by employing discourse representation theory\n[Kamp & Reyle 93], and by extending our parser to extract the semantic structure\nof a sentence in the context of the preceding sentences.\nDRT represents a multisentential natural language discourse in a single logical\nunit called a discourse representation structure (DRS). In general, a DRS K is\ndefined as an ordered pair <U, Con> where U is a set of discourse referents\n(discourse variables) and Con is a set of conditions. The conditions Con are\neither atomic (of the form P(u1, ..., un) or u1 = u2), or complex (negation,\nimplication, or disjunction). A DRS is obtained through the application of a set\nof syntax-driven DRS construction rules R. These rules do not only examine the\n– 5 –\nsentence under construction, but also the DRS that has been built so far. Thus we\ncan define the meaning of a sentence S as the function M from a given DRS K to\nan extended K´ induced by R.\nSimple DRSs\nThe specification of the automated teller machine contains the two sentences\nSimpleMat is a simple money dispenser.\nIt has a user interface.\nStarting from the empty DRS K0, the discourse representation structure for the\ntwo sentences is constructed by processing each sentence in turn. A first DRS K1\ncorresponds to the processing of the first sentence. While the sentence is parsed\ntop-down, the DRS K1 is composed simultaneously, eventually yielding the\nfollowing result.\nnamed(X1,simplemat)\nmoney_dispenser(X2)\nsimple(X2)\nis(X1,X2)\nX1 X2 \nThe DRS K1 says that the bearer of the name SimpleMat is identical with the\nobject that was indicated by the noun phrase a simple money dispenser. This\nindefinite noun phrase contributes two conditions to the DRS: one condition for\nthe compound noun money dispenser and one for the descriptive adjective\nsimple. The function of the verb to be in the above discourse is to express that\nthe two noun phrases have the same referent. To reflect this relation in the DRS\na condition of the form is(X1,X2) has been introduced, which asserts that the\nobjects represented by X1 and X2 coincide.\nAt this point, we will incorporate the second sentence into the established DRS\nK 1 by extending it to K 2. In order to do it, we have to find a suitable\nrepresentation of the relation which holds between the anaphoric pronoun it\nand its antecedent in the first sentence. We will represent this information in\nthe form of an equation, with the new referent on the left and the referent that is\nchosen as antecedent on the right of the equality sign. The referent chosen is the\nclosest antecedent that agrees in case, number and gender.\nIncorporating the whole information of the second sentence, we get three new\nconditions and obtain DRS K2:\nnamed(X1,simplemat)\nmoney_dispenser(X2)\nsimple(X2)\nis(X1,X2)\nX1 X2 X3 X4\nuser_interface(X4)\nhave(X3,X4)\nX3 = X1\n– 6 –\nComplex DRSs\nDRSs that represent conditional, universal or negative sentences are complex,\ni.e. they contain sub-DRSs.\nSentences in which a subordinate if-clause combines with a main then-clause are\nusually referred to as conditional sentences. Such sentences serve the purpose of\nmaking hypothetical claims. The supposed if-clause is called the antecedent and\nthe hypothetically asserted then-clause the consequent of the conditional.\nIntuitively, the consequent provides a situational description which extends that\ngiven by the antecedent.\nIn general, a conditional sentence of the form if A then B contributes to a DRS K0\na condition of the form K1 => K2, where K1 is a sub-DRS corresponding to A and\nK2 is the sub-DRS resulting from extending K1 through the incorporation of B.\nFor instance, the conditional sentence of our specification\nIf the trap-door-algorithm calculates a number\nthen the number equals the check code.\nis represented in DRT as:\n \n=>\n \n \nX1 X2\ntrap_door_algorithm(X1)\nnumber(X2)\ncalculate(X1,X2)\nnumber(X3)\nX3 = X2\ncheck_code(X4)\nequal(X3,X4)\nX3 X4\nIn terms of truth conditions, the above conditional K1 => K2 is satisfied if and\nonly if there are individuals X1 and X2 that make the sub-DRS K1 and the sub-\nDRS K2 true simultaneously. This definition contrasts with classical logic where\nthe implication is also true in the situation when the antecedent is false.\nNote the unique reference use and the anaphoric use of the definite noun\nphrases. A unique reference X1 of the definite noun phrase the trap-door-\nalgorithm is created in the if-sub-DRS because no antecedent can be found in\nthe superordinate DRS. The definite noun phrase the number is used\nanaphorically in the then-sub-DRS. Consequently, an equation of the form X3 =\nX2 is generated, where X2 is the discourse referent of the antecedent object noun\nphrase in the if-sub-DRS.\nDRT claims that an anaphor can only refer to a discourse referent in the current\nDRS or in a DRS superordinate to it. Though this restriction makes correct\npredictions about the accessibility of antecedents to anaphors, it needs to be\nrelaxed in practical applications to avoid contrived sentences.\n– 7 –\nAs mentioned above DRSs are restricted formulas of predicate calculus, and\nresemble Horn clauses. All conditions in the antecedent are implicitly\nuniversally quantified and each condition in the consequent has an implicit\nexistential quantifier contingent on the antecedent. The sub-DRS K1 – on the left\nof the arrow – is called the restrictor of the quantifier, the one on the right – K2 –\nits scope. In formalisms like predicate logic the semantic contributions of the\nwords if ... then would have to be simulated by appropriate combinations of the\nuniversal quantifier and the implication connector. DRT seems to offer a much\nmore natural representation for the systematic correlation between syntactic\nform and linguistic meaning of conditional sentences. This reflects the\ncontextual role that a DRS was intended to play, namely mainly as a context for\nwhat is to be processed next, and not only as a representation of what has been\nprocessed already.\nDRT with Eventualities (DRT-E)\nDRT-E investigates further details of the semantics of verbs, taking into account\nthe theory of underlying eventualities (events or states) and handling temporal\nand aspectual information [Kamp & Reyle 93, Reichenbach 47]. A prototypical\nimplementation of DRT-E is described in [Brown 94].\nInvestigating sentences like\nThe customer enters the card.\nSimpleMat checks the card.\nand\nEvery customer has a personal code.\nwe recognise that the first two sentences are naturally understood as a report of\ntemporally ordered events, while the second sentence describes something like a\ncondition or state.\nVerbs like enter or check introduce the existence of an event in much the same\nway as a noun phrase introduces the existence of an object. Events involve some\nkind of change in the universe of discourse, they persist through a certain\ninterval of time and come eventually to a culmination point. They imply that\nsome non-temporal condition, which is true when the event starts, is\nterminated by the event, and is replaced by further events.\nStates differ from events. A state verb such as have expresses a quality that is true\nindefinitely – it involves the continuation of a condition.\nSometimes the distinction between state-sentences and event-sentences is\nrecognisable from the syntactic form of the verb, but it is well known that it is\nnot the verb alone which decides about the eventuality introduced by a new\nsentence. The different thematic roles may exert a major influence.\nIn our approach, we represent the statement that E1 is the event of X1 entering\nX2 as enter(E1,X1,X2) and use the special predicate cul(E1,T1) to express\nthat the event E1 culminates at time T1. The relation between the reference time\nT1 of E1 and the speech time N is established with the help of the additional\npredicate at(T1,N). With these notational changes, the DRS looks like\n– 8 –\nnamed(X3,simplemat)\ncard(X4)\ncheck(E2,X3,X4)\nX4 = X2\ncul(E2,T2)\nat(T2,N)\ncustomer(X1)\ncard(X2)\nenter(E1,X1,X2)\ncul(E1,T1)\nat(T1,N)\nN  E1  T1  X1  X2  E2  T2  X3  X4\nAs mentioned above, a state is temporally extended and homogenous. It\ndescribes a static situation S that holds or does not hold at a given time T. The\nfunction of the verb have is twofold: it introduces a discourse referent S which\nrepresents a state of affair and it provides a descriptive characterisation of this\nstate represented by S. We will retain this information as a predicate of the form\nhave(S,X1,X2). The additional predicate hold(S,T) asserts that S holds at T\nand the condition at(T,N) indicates that the eventuality described is located at\nthe same time as the utterance time of the discourse that the DRS is taken to\nrepresent.\n \n=>\ncustomer(X1)\nX1\npersonal_code(X2)\nhave(S,X1,X2)\nhold(S,T)\nat(T,N)\nN  S  T  X2\nWays to Investigate DRSs\nIt is important to realise that a DRS can be investigated in several different ways.\nFirst, it can be given a model-theoretic semantics by embedding it in a model.\nSecond, a DRS can be manipulated deductively to infer further information\nusing rules which operate only upon the structural content of the logical\nexpressions. Third, a DRS can be investigated from a more psychological point of\nview as a contribution of building up a mental model of a language user.\nThe second and the third ways lead to the concept of knowledge assimilation\n[Kowalski 93]. According to this proof theoretic approach a DRS is processed by\nresource-constrained deduction and tested whether it can be added to a\ncontinuously changing theory. The terms truth and falsity of DRSs in model\n– 9 –\ntheory are replaced by the proof of consistency and inconsistency in the process of\nknowledge assimilation.\nFrom DRSs to Prolog\nTranslating DRSs into Prolog clauses poses a problem – free variables in Prolog\nclauses have implicit universal quantifiers. It is not possible to translate the DRS\nfor\nSimpleMat is a simple money dispenser.\nnamely\nnamed(X1,simplemat)\nmoney_dispenser(X2)\nsimple(X2)\nis(X1,X2)\nX1 X2 \ninto Prolog as\nnamed(X1,simplemat).\nmoney_dispenser(X2).\nsimple(X2).\nis(X1,X2).\nThe first fact would mean \"Anything is named SimpleMat\". We would not even\nbe able to say that the money dispenser is the same thing as the object named\nSimpleMat, because variables in different clauses are distinct even if they have\nthe same name. What we need is a discourse marker for each existentially\nquantified entity. For that reason, a constant (integer) is randomly chosen to\nrepresent the individual X1. Then the DRS conditions – with the constants\ninstantiated for the discourse referents – would be asserted in the knowledge\nbase\nnamed(1,simplemat).\nmoney_dispenser(1).\nsimple(1).\nTwo additional problems arise when we translate conditions which use sub-\nDRSs. First, Prolog clauses cannot have two predicates in its consequent, i.e.\nclauses of the form\na,b :- c,d.\nare not permitted. To deal with this problem, Covington and his collaborators\nintroduce a special operator (::-) as intermediate representation for clauses with\nmore than one consequent [Covington et al. 88]. Now we can write\na,b ::- c,d.\nSince this rule cannot be asserted directly into the knowledge base it is split up\ninto several Prolog clauses by distributing the consequents:\na :- c,d.\nb :- c,d.\n– 10 –\nSecond, if the consequent of a conditional sentence introduces new variables,\nthese variables have implicit existential quantifiers which depend on the\nantecedent. Since Prolog cannot represent this dependence directly, we have to\nsimulate it by a form of skolemisation as\ncard([2,X1]), have(X1,[2,X1]) ::- customer(X1).\nrespectively as the two Prolog clauses\ncard([2,X1])    :- customer(X1).\nhave(X1,[2,X1]) :- customer(X1).\nThe Prolog term [2,X1] can be interpreted as a value that is a function of the\nvalue of X1.\n5\nOverview of the Specification System\nIn this section we briefly describe the components of our specification system,\nmost of which have already been implemented in a prototypical form.\nThe user enters specification text in controlled natural language which the\nDialog Component forwards to the parser in tokenised form. Parsing errors and\nambiguities to be resolved by the user are reported back by the dialog component.\nThe user can also query the knowledge base in controlled natural language.\nThe Parser uses a predefined definite clause grammar with feature structures and\na predefined linguistic lexicon to check sentences for syntactical correctness, and\nto generate syntax trees and sets of nested discourse representation structures.\n \nText\nDialog \nComponent\nLinguistic\nLexicon\nKnowledge \nBase\nParser\nDiscourse \nHandler\nTranslator\nto Prolog\nKnowledge\nAssimilator\nAnswer\nGenerator\nInference\nEngine\n– 11 –\nThe Linguistic Lexicon contains an application-specific vocabulary. The lexicon\ncan be modified by an editor invokable from the dialog component. This editor\nwill be called automatically when the parser finds an undefined word.\nThe Discourse Handler analyses and resolves inter-text references and updates\nthe discourse representation structures generated by the parser.\nThe Translator translates discourse representation structures into Prolog clauses.\nThese Prolog clauses are either passed to the knowledge assimilator, or – in case\nof queries – to the inference engine.\nThe Knowledge Assimilator adds new knowledge to the knowledge base in a\nway that avoids inconsistency and redundancy.\nThe Inference Engine answers user queries with the help of the knowledge base.\nIn a preliminary version the inference engine is just the Prolog interpreter.\nThe Answer Generator takes the answers of the inference engine, reformulates\nthem in restricted natural language, and forwards them to the dialog\ncomponent.\n6\nUsing the Specification System\nAn Example Translation\nAs a simple example we will demonstrate the translation of the sentence\nEvery customer has a card.\ninto Prolog. The discourse representation structure is built up by the parser and\nrepresented by a Prolog term of the form drs(U,Con). U is a list of discourse\nreferents represented by unique Prolog variables and Con is a list of terms\ncontaining these variables. For the example sentence the DRS becomes\ndrs([],\n    [ ifthen(\n    drs([X1],   [gender(X1,[m,f]), number(X1,sg), customer(X1)]),\n    drs([X2,X1],[gender(X2,n), number(X2,sg), card(X2), have(X1,X2)]))\n    ])\nThis initial DRS contains gender and number conditions that are employed for\nthe resolution of anaphoric references. The discourse handler simplifies the DRS\nby eliminating the gender and number information, and by unifying terms. We\nget\ndrs([],\n    [ ifthen(\n    drs([X1],   [customer(X1)]),\n    drs([X2,X1],[card(X2), have(X1,X2)]))\n    ])\nwhich is finally translated into the two Prolog clauses\ncard([2,X1])    :- customer(X1).\nhave(X1,[2,X1]) :- customer(X1).\nthat are added to the knowledge base. The Prolog term [2,X1] can be interpreted\nas a Skolem function assigning each customer his/her individual card.\n– 12 –\nQuerying the Knowledge Base\nLike any other Prolog program the knowledge base can be queried by standard\nProlog queries. But doing so would defy our tacit assumption that the user need\nnot look at the internal representations of the specifications. Thus we allow\ncertain classes of queries to be formulated in controlled natural language.\nYes/No Queries\nThe first class of queries just examines the factual information in the knowledge\nbase. Let us assume that the user entered the text\nSimpleMat is a simple money dispenser.\nIt has a user interface.\nNow we can ask\nIs SimpleMat a money dispenser?\nThis query will be translated into the Prolog query\nnamed(1, simplemat), money_dispenser(1)\nand the system will respond with\nyes\nSimilarly\nDoes SimpleMat have a simple user interface?\nno\nWh-Queries\nAnother class of queries contains pronouns like who and what. These pronouns\nare represented internally as variables that can be instantiated by Prolog terms\nduring the inference process. The query\nWho is a money dispenser?\nis answered by the system in a form that shows the instantiation\n[SimpleMat] is a money dispenser.\nParaphrasing\nTo hide the internal representations of specifications, paraphrasing of analysed\nsentences in natural language is necessary in two situations – when the system\ngives feedback to the user, and when the user wants to examine the knowledge\nbase.\nFeedback\nLet us assume that the user entered the text\nSimpleMat is a simple money dispenser.\nIt has a user interface.\nIn this situation the system could reply like CLE [Alshawi 92] by\n[SimpleMat] has a user interface.\nto inform the user how the anaphoric reference was resolved. Similarly, for an\nambiguous input\nEvery customer has a card.\n– 13 –\nthe system could reply\nEvery customer has [an individual] card.\nto tell the user which of the possible interpretations was chosen.\nExamining the Knowledge Base\nProlog clauses of the knowledge base can be paraphrased in a simple way with\nthe help of predefined schemata that access the linguistic lexicon. Here is an\nexample schema.\nnamed(X, <proper noun>)\n<adjective>(Y)\n<noun>(Y)\nis(X,Y)\n<proper noun>g is a/an <adjective>g <noun>g.\nTerms in angular brackets are schema variables that denote the relation names\nof preterminals. In the paraphrased sentence schema variables are replaced by\nthe pertinent graphemes as indicated by the g superscript. With the help of this\nschema the Prolog clauses\nnamed(1, john).\nknown(2).\ncustomer(2).\nis(1,2).\ncan be paraphrased as\nJohn is a known customer.\nSince the specification language is controlled and the translation into Prolog is\nvery regular, paraphrasing schemata can be readily derived though they may not\nbe as simple as in the example. Paraphrasing schemata can either be represented\nas Prolog terms or as simple grammars.\nExecuting the Specification\nIn the preceding discussion we have regarded the knowledge base only as a data\nbase to be queried or examined. However, the knowledge base can also be used\nfor simulation or prototyping by executing it. In our example specification, this\nmeans executing/running the specification of the automated teller machine. As\nit stands the specification does not provide all the necessary information and\nneeds to be enhanced in three ways.\n•\nMost importantly, an order of events has to be established, e.g. we have to\nmake sure that during the simulation the event of entering a card has to\nprecede the event of checking it. [Ishihara et al. 92] who translate natural\nlanguage specifications into algebraic ones use contextual dependency and\nproperties of data types to establish the correct order of events. In our\napproach based on discourse representation theory the order of events is to a\ngreat extent established when we introduce eventualities (events and states)\ninto the processing of our controlled natural language. Following Kamp we\ninterpret the sentences\nThe customer enters the card.\nSimpleMat checks the card.\n– 14 –\nas an entering event temporally followed by a checking event, and the\nsentences\nThe customer enters the card.\nSimpleMat is checking the card.\nas an entering event that temporally overlaps with a checking state. This leads\nto an ordering of events or times, respectively. On the basis of this\ninformation a simple forward chaining meta-interpreter can execute the\nProlog clauses in their correct order.\n•\nMany relations representing events are not only truth-functional, but also\ncause side-effects, e.g. I/O operations. The required side-effects can be defined\nby interface predicates, e.g.\nenter(X, Y) :- prompt_read(['Enter your card'], Y).\nthat depend on the simulation environment. One could, for example,\nenvisage that the interface predicates do not simply simulate the automated\nteller machine but cause the execution of a real automated teller machine.\n•\nFinally, the execution needs some situation specific information. For\nexample, to execute the Prolog clauses\ncard([2,X1])    :- customer(X1).\nhave(X1,[2,X1]) :- customer(X1).\nderived from the input\nEvery customer has a card.\nthe goal customer(X1) must be provable. We can either provide the relevant\nProlog facts, or more conveniently, get the information by querying the user.\n7\nConclusion and Future Research\nThe present prototypical implementation of our system proves that controlled\nnatural language can be used for the non-trivial specification of an automated\nteller machine, and that the specification can be translated as coherent text into\nProlog clauses.\nMore work needs to be done, however, to turn the prototype into a useful tool.\nBesides extending the functionality of the existing system, we plan to enhance it\nin at least two ways. To specify time-dependencies explicitly, we will add\nconstructs like before, after and when to the controlled natural language, and\nintroduce event semantics into the DRSs. Though natural language – even in a\ncontrolled form – is a universal specification notation, we believe that it is not\nalways the optimal one. Thus we will add graphical notations, e.g. for window-\noriented user interfaces, and specific notations for algorithms.\nAcknowledgements\nWe would like to thank Jaume Agusti, Michael Hess, David Robertson,\nWamberto Vasconcelos and Martin Volk for many stimulating discussions, and\nthe anonymous reviewers of the extended abstract of this paper for valuable\nadvice.\n– 15 –\nReferences\n[Alshawi 92]\nH. Alshawi, The Core Language Engine, MIT Press, 1992\n[Borsley 91] \nR. D. Borsley, Syntactic Theory, Edward Arnold, London, 1991\n[Börger & Rosenzweig 94]\nE. Börger, D. Rosenzweig, A Mathematical Definition of Full\nProlog, Science of Computer Programming, 1994 (to appear)\n[Brown 94] \nD. W. Brown, A Natural Language Querying System Based on\nDiscourse Representation Theory and Incorporating Event\nSemantics, Report AI-1994-03, Artificial Intelligence Center,\nUniversity of Georgia, 1994\n[Capindale & Crawford 89]\nR. A. Capindale, R. G. Crawford, Using a natural language\ninterface with casual users, International Journal Man-Machine\nStudies, 32, pp. 341-362, 1989\n[Covington et al. 88]\nM. A. Covington, D. Nute, N. Schmitz, D. Goodman, From\nEnglish to Prolog via Discourse Representation Theory, Research\nReport 01-0024, Artificial Intelligence Programs, University of\nGeorgia, 1988\n[Covington 94 ]\nM. A. Covington, GULP 3.1: An Extension of Prolog for\nUnification-Based Grammar, Research Report AI-1994-06,\nArtificial Intelligence Center, University of Georgia, 1994\n[Epstein 85]\nS. S. Epstein, Transportable Natural Language Processing\nThrough Simplicity - the PRE System, ACM Transactions on\nOffice Automation Systems, 3(2), pp. 107-120, 1985\n[Fuchs & Fromherz 94]\nN. E. Fuchs, M. P. J. Fromherz, Transformational Development of\nLogic Programs from Executable Specifications – Schema-Based\nVisual and Textual Composition of Logic Programs, in C.\nBeckstein, U. Geske (eds.), Entwicklung, Test und Wartung\ndeklarativer KI-Programme, GMD Studien Nr. 238, Gesellschaft\nfür Informatik und Datenverarbeitung, 1994\n[Ishihara et al. 92] \nY. Ishihara, H. Seki, T. Kasami, A Translation Method from\nNatural Language Specifications into Formal Specifications\nUsing Contextual Dependencies, in: Proceedings of IEEE\nInternational Symposium on Requirements Engineering, 4-6 Jan.\n1993, San Diego, IEEE Computer Society Press, pp. 232 - 239, 1992\n[Kamp & Reyle 93]\nH. Kamp, U. Reyle, From Discourse to Logic, Introduction to\nModeltheoretic Semantics of Natural Language, Formal Logic\nand Discourse Representation Theory, Kluwer Academic\nPublishers, Dordrecht, 1993\n[Kowalski 93]\nR. A. Kowalski, Logic without Model Theory, Technical Report,\nImperial College, 1993\n[Kramer & Mylopoulos 92]\nB. Kramer, J. Mylopoulos, Knowledge Representation, in: S. C.\nShapiro (ed.), Encyclopedia of Artificial Intelligence, Wiley,\n1992\n[Lloyd 94]\nJ. Lloyd, Practical Advantages of Declarative Programming,\nInvited Lecture, GULP-PRODE '94, Peñiscola (Spain), September\n1994\n[Macias & Pulman 92]\nB. Macias, S. Pulman, Natural Language Processing for\nRequirements Specifications, in: F. Redmill, T. Anderson (eds.),\nSafety-Critical Systems, Current Issues, Techniques and\nStandards, Chapman & Hall, pp. 67-89, 1993\n– 16 –\n[Pulman 94]\nS. G. Pulman, Natural Language Processing and Requirements\nSpecification, Presentation at the Prolog Forum, Department of\nComputer Science, University of Zurich, February 1994\n[Reichenbach 47] \nH. Reichenbach, Elements of Symbolic Logic, Macmillan, 1947\n[Sommerville 92]\nI. Sommerville, Software Engineering, Fourth Edition, Addison-\nWesley, Wokingham, 1992\n[Sterling 92]\nL. Sterling, A Role for Prolog in Software Engineering, Computer\nScience Colloquium, Department of Computer Science,\nUniversity of Zurich, 1992\n",
  "categories": [
    "cmp-lg",
    "cs.CL"
  ],
  "published": "1995-07-21",
  "updated": "1995-07-21"
}