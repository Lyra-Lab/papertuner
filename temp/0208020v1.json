{
  "id": "http://arxiv.org/abs/cs/0208020v1",
  "title": "Using the DIFF Command for Natural Language Processing",
  "authors": [
    "Masaki Murata",
    "Hitoshi Isahara"
  ],
  "abstract": "Diff is a software program that detects differences between two data sets and\nis useful in natural language processing. This paper shows several examples of\nthe application of diff. They include the detection of differences between two\ndifferent datasets, extraction of rewriting rules, merging of two different\ndatasets, and the optimal matching of two different data sets. Since diff comes\nwith any standard UNIX system, it is readily available and very easy to use.\nOur studies showed that diff is a practical tool for research into natural\nlanguage processing.",
  "text": "arXiv:cs/0208020v1  [cs.CL]  13 Aug 2002\nUsing the DIFF Command\nfor Natural Language Processing\nMasaki Murata and Hitoshi Isahara\nCommunications Research Laboratory,\n2-2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan,\n{murata,isahara}@crl.go.jp,\nWWW home page: http://www.crl.go.jp/khn/nlp/members/murata/index.html\nAbstract. Diﬀis a software program that detects diﬀerences between\ntwo data sets and is useful in natural language processing. This paper\nshows several examples of the application of diﬀ. They include the detec-\ntion of diﬀerences between two diﬀerent datasets, extraction of rewriting\nrules, merging of two diﬀerent datasets, and the optimal matching of two\ndiﬀerent data sets. Since diﬀcomes with any standard UNIX system, it\nis readily available and very easy to use. Our studies showed that diﬀis\na practical tool for research into natural language processing.\n1\nIntroduction\nDiﬀ, a software program that detects diﬀerences between two sets of data, has\nnumerous applications in natural language processing. In this paper, we ﬁrst\ndescribe diﬀand then give several examples of how diﬀcan be used in natural\nlanguage processing. These examples include the detection of diﬀerences, the\nmerging of two sets of diﬀerent data, the extraction of rewriting rules, and the\nbest matching of two diﬀerent sets of data.1\nWe summarize the value of this paper below.\n– Since diﬀis one of the basic programs that comes with UNIX systems, it is\nreadily available and very easy to use. As this paper shows, diﬀis also appli-\ncable to various kinds of studies in the ﬁeld of natural language processing.\nThis combination makes the program particularly valuable.\n– Paraphrasing has been become an active area of study [2]. Section 3.2 shows\nthat we can use diﬀto examine the diﬀerences between a spoken language\nand the corresponding written language and in acquiring the rules for the\ntransformations between the spoken and written languages. Diﬀis not only\nuseful for such studies, but is also applicable to other kinds of studies in\nthe ﬁeld of paraphrasing. This paper will provide a basis for such further\napplication of diﬀ.\n– In general, diﬀis used to detect diﬀerences between two data. However, it\ncan also be used to merge data and to match data optimally. Section 4 covers\n1 This papar is an English rough translation of our papers [1,3].\nseveral interesting studies of the use of diﬀin merging and best-matching\ntasks. These examples are the alignment of a paper and a corresponding pre-\nsentation and a question-answering system. This paper thus has originality\nin terms of topics researched and approach to the research.\n2\nDiﬀand Mdiﬀ\nIn this section, we describe diﬀ. Diﬀis a software program of Unix systems that\nis used to compare ﬁles. The program displays line-by-line diﬀerences between a\npair of text ﬁles while retaining the order of the data. For example, suppose we\nhave the following two ﬁles:\nFile 1:\nFile 2:\nI\nI\ngo\ngo\nto\nto\nschool.\nuniversity.\nWhen we give these data to diﬀ, the diﬀerence is displayed in the following way.\n< school.\n> university.\nDiﬀhas a -D option, which is very useful. When we use diﬀwith this option,\ncommon parts as well as diﬀerences are displayed. That is, ﬁles can be merged\nby using this option. However, the output of diﬀ-D is in a form which is used for\nC preprocessor such as “Ifdef” and this is diﬃcult for people to read. Therefore,\nin this paper, we give the diﬀerences in the following way:\n;===== begin =====\n(The parts which only exist in the first file)\n;-----------------\n(The parts which only exist in the second file)\n;=====\nend\n=====\nwhere, “;===== begin =====” indicates the beginning of the diﬀerences, “;====\n=\nend\n=====” indicates the end of the diﬀerences, and “;-----------------”\nindicates the boundary between the two sets of data. In this paper, we refer to\ndiﬀin the case where the ﬁles are merged by using the -D option and the diﬀer-\nences are displayed in the above form as mdiﬀ.\nWhen we give our earlier pair of ﬁles to mdiﬀ, we obtain the following result.\nI\ngo\nto\n;===== begin =====\nschool.\n;-----------------\nuniversity.\n;=====\nend\n=====\n“I go to” matchs while “school” and “university” are diﬀerences. The output of\nmdiﬀis easy to examine and understand because it also displays, unlike diﬀ, the\ncommon parts.\nWe can reproduce the two original ﬁles from the output of mdiﬀ. When we\ntake the common part and the upper part of the diﬀerences, we obtain the\ncontent of the ﬁrst ﬁle. When we take the common part and the lower part of\nthe diﬀerences, we obtain the content of the second ﬁle. We can reproduce all of\nthe original data in this way.\nSince mdiﬀonly displays the common part of the data once, it is able to\nreduce the amount of data. Since it is possible to fully reproduce the original\ndata from mdiﬀ’s output, we are able to say that mdiﬀcompresses the data\nwhile retaining the original information.\nSince the output of diﬀis diﬃcult to read and the output of mdiﬀcontains\nall information output by diﬀ, we use mdiﬀfor our explanations in the following\nsections. In the following sections, let’s look at some actual examples of the\napplication of mdiﬀto natural language processing.\n3\nDetecting diﬀerences and acquiring transformation\nrules\nIn this section, we describe the studies where we used mdiﬀto detect diﬀerences\nand then acquired transformation rules from the diﬀerences. In more concrete\nterms, we give the following two examples.\n– Detection of diﬀerences between the outputs of multiple systems\n– Examination of diﬀerences to acquire transformation rules\n3.1\nDetection of diﬀerences between the outputs of multiple\nsystems\nWe have been using multiple morphological analyzers to improve the quality of\nthe results of morphological analysis.\nSuppose that we use two morphological analyzers to analyze “We like ap-\nples.”; the results are as follows.\nSystem 1\nSystem 2\nWe\nNoun\nWe\nNoun\nlike\nVerb\nlike\nPreposition\napples\nNoun\napples\nNoun\nThe word, “like” is ambiguous in terms of part of speech (POS) and can take\n“Verb” or “Preposition”. The POS of “like” in the above sentence is “Verb” and\nthe analysis by System 2 was wrong. Here, when we give the two results to mdiﬀ,\nwe obtain the following results.\nWe\nNoun\n;===== begin =====\nlike\nVerb\n;-----------------\nlike\nPreposition\n;=====\nend\n=====\napples\nNoun\nMdiﬀmakes it easy for us to detect diﬀerences between the results produced by\nmultiple systems. In this case, we notice that there are diﬀerences in the line for\n“like”. Here, we determine beforehand that a worker corrects the outputs and\njudges which is correct when such diﬀerences are detected. When the output of\nthe ﬁrst system is correct he does nothing and when the output of the second\nsystem is correct he marks the beginning of “;—————–” with an “x”. When\nwe do so, we can automatically select the better result of each diﬀerence from the\nresults marked by the worker. We simply delete the lower part of the diﬀerence\nwhere there is no “x” and delete the upper part of the diﬀerence when there is\nan “x”. As a result, we produce a more accurate overall result than either of the\ntwo original results. There are many cases when both parts of a diﬀerence are\nincorrect. In such cases, we manually rewrite the data correctly above “;———\n——–”.\nWhen we use this method, the only incorrect data that is not corrected are\nthe data on which both the systems have performed exactly the same wrong\nanalysis. Many errors can thus be corrected. What we want to say here is that\nwe must prepare multiple systems that have diﬀerent characteristics. If we use\ntwo systems that often produce the same wrong analysis, we will fail to correct\na large number of errors.\nDiﬀ3, which is another unix program, is available for analysing the outpus\nof three systems. Diﬀ3 detects diﬀerences among three ﬁles.\nAlthough we have given an example of morphological analysis, we can also\nuse mdiﬀto detect diﬀerences between the results of other forms of analysis as\nlong as the results are expressed in a line-by-line form.\nAlthough we have described a study where we detected diﬀerences between\nthe outputs of multiple systems, we are also able to detect and correct errors in\ntagged corpora by comparing the tagged corpora and the results of analysis of\nthe corpora by a certain system.2\n3.2\nExamining diﬀerences and acquiring transformation rules\nIn this section, we describe our study of the use of mdiﬀto detect diﬀerences be-\ntween a spoken language and the corresponding written language. In this study,\nwe used the alignment between data on the spoken language and on the written\nlanguage to examine the diﬀerences between the spoken and written languages\non the basis of the results of mdiﬀ. We thus acquired rules for transforming the\n2 There are studies on the correction of errors in tagged corpora [5].\nTable 1. Examples of written data and the corresponding data in spoken form\nThe written-language sample\nIn\nthis\npaper,\nwe\ndescribe\nthe\nmeaning\nsort.\nIn\ngeneral,\nsorting\nis\nperformed\nby\nusing\nThe spoken-language sample\nToday\nI’d\nlike\nto\ndescribe\nuh\nthe\nmeaning\nsort.\nIn\ngeneral,\nsorting\nis\ndone\nby\nspoken language to the written language along with the inverse transformation\nrules. We used presentations at academic conferences as examples of the spoken\nlanguage and used papers which had the same content as the presentations as\nexamples of the writtten language.\nFor example, we supposed that data in the spoken and written languages are\ngiven as in Table 1.3 The data in the table are transformed so that each line has\none word before we apply mdiﬀ. Applying mdiﬀto the data produces the results\nshown in Table 2. By extracting the diﬀerences from these results, we obtain the\nresults shown in Table 3.\nThe results show us that “uh” is inserted in the spoken language and that\n“performed” can, in this case, be paraphrased as “done”. We can use mdiﬀto\ndetect diﬀerences between the spoken language and the written language and\nthen examine them linguistically. We can also consider the detected diﬀerences as\nrules for the transformation between written and spoken languages. For example,\nthe occurrence of “uh” can be regarded as indicating a rule that we may insert\n“uh” into the written-language data as part of transforming it into the spoken\nlanguage. The diﬀerence in terms of whether “performed” or “done” is used\ncan be regarded as a rule that we transform “performed” to “done” when we\ntransform data from the written to the spoken language. We thus ﬁnd that we\nare able to use mdiﬀto detect the transformation rules.\nIn this section, we used data in the written and spoken language. However, we\ncan study a variety of data in a similar way. For example, when we apply mdiﬀto\nwritten texts before and after spelling and grammar are checked, we can ﬁnd out\n3 Although we have given English sentences in the table, we actually performed these\nexperiments on Japanese-language materials.\nTable 2. The result of applying mdiﬀto the written-language sample and the\ncorresponding spoken-language sample\n;===== begin =====\nIn\nthis\npaper,\nwe\n;—————–\nToday\nI’d\nlike\nto\n;===== end =====\ndescribe\n;===== begin =====\n;—————–\n(Contined in the right-hand column)\nuh\n;===== end =====\nthe\nmeaning\nsort.\nIn\ngeneral,\nsorting\nis\n;===== begin =====\nperformed\n;—————–\ndone\n;===== end =====\nby\nTable 3. Extraction of diﬀerences\nThe written-language data The spoken-language data\nIn this paper, we\nToday I’d like to\nuh\nperformed\ndone\nhow we should modify the sentences to eliminate spelling and grammatical errors\nand thus acquire rules for checking spelling and grammar. When we use mdiﬀon\ntexts and the results of their automatic summarization, we can clearly see how\nthe texts were summarized and can thus acquire the rules used in automatic\nsummarization. In other cases of paired textual data, too, we will be able to\napply mdiﬀto examine the data in the various ways that such pairs can be\nobtained and to obtain the rules for transformation.\n4\nThe merging and best matching of two diﬀerent sets of\ndata\nIn this section, we describe studies of the use of diﬀ’s function of optimally\nmerging data.4 We describe the following two examples.\n– The alignment of presentations and corresponding papers\n– A question-answering system using the function of ﬁnding the the best match\n4 In diﬀ, best matching is performed by maximizing the extent of the common parts.\n<Chapter 1>\n(the contents of Chapter 1)\n</Chapter 1>\n<Chapter 2>\n(the contents of Chapter 2)\n</Chapter 2>\n<Chapter 3>\n(the contents of Chapter 3)\n</Chapter 3>\nFig. 1. Structure in the paper\n;===== begin =====\n<Chapter 1>\n(content of the paper only)\n;—————–\n(content of the presentation only)\n;===== end =====\n(content of the paper and presentation)\n;===== begin =====\n(content of the paper only)\n;—————–\n(Contined in the right-hand column)\n(content of the presentation only)\n;===== end =====\n(content of the paper and presentation)\n;===== begin =====\n</Chapter 1>\n<Chapter 2>\n(content of the paper only)\n;—————–\n(content of the presentation only)\n;===== end =====\nFig. 2. Results of applying mdiﬀto a paper and a corresponding presentation\n4.1\nAlignment of a paper with the corresponding presentation\nIn this section, we align a paper with the corresponding presentation [6]. The pa-\nper and corresponding presentation is the same example as was used in describing\nthe acquisition of the rules for transformation from written to spoken-language\ndata (Section 3.2). The presentation was made at an academic conference and\nthe paper corresponds to this presentation. When we are able to align each part\nof a presentation with a corresponding part of the paper, this form of alignment\nis very useful. For example, when we listen to a presentation, we are able to refer\nto the part of the paper that corresponds to the part of we are now listening.\nWhen we read a paper, we are able to refer to the part of the presentation that\ncorresponds to the part of the paper we are now reading [6]. In this section, we\nconsider the use of mdiﬀto align a paper with the corresponding presentation.\nHere, let’s try to determine the parts of the presentation to which each chap-\nter of the paper corresponds by using mdiﬀ. We suppose that the content is laid\nout in the same order in the paper and in the presentation. In advance, we place\nsymbols such as <Chapter 1>, as shown in Figure 1, into the paper. This is so\nthat we are easily able to recognize the chapters of the paper. By applying mdiﬀ\nto the data set that consists of a presentation after both have been transformed\nso that each line has one word, we obtained the results shown in Figure 2. Next,\n<Chapter 1>\n(content of the presentation only)\n(content of the paper and presentation)\n(content of the presentation only)\n</Chapter 1>\n<Chapter 2>\n(content of the presentation only)\nFig. 3. Results of insertion of information on sections in a presentation\nwe obtained the results shown in Figure 3 by eliminating the upper parts of the\ndiﬀerences, i.e., those that correspond to the paper, and leaving symbols such\nas <Chapter 1> in place. The symbols such as <Chapter 1> are only inserted\nin the data of the presentation. We are then able to recognize the chapter of the\npaper that corresponds with a given part of the presentation.\nTo put this simply, we place information to indicate chapters in the data of\npresentations. We then use the merging function of mdiﬀto match the parts of\nthe paper and presentation. Then, by eliminating the content of the paper, we\nare left with information on the chapters. We can easily align a paper with a\ncorresponding presentation at the level of chapters by using mdiﬀ.\n4.2\nA question-answering system using best matching\nIn this section, we describe our question-answering system that utilizes mdiﬀ’s\nbest-matching function [2,4].\nA question-answering system receives a question and outputs an answer. For\nexample, when “Where is the capital of Japan?” is given, it returns “Tokyo”.\nWhen we consider now much knowledge is in written natural language form,\nwe see that the system only has to match a given question with a sentence (a\nknowledge sentence) that includes the knowledge then select the word in the\nsentence that corresponds to the interrogative pronoun of the question sentence.\nFor example, in the case of the previous question, the system detects this knowl-\nedge sentence in a knowledge database: “Tokyo is the capital of Japan.” “Tokyo”\nis output as the answer since corresponds to the interrogative pronoun in the\nsentence. Here, we consider the use of mdiﬀin answering questions.\nFirstly, we transform the interrogative pronoun in the question sentence into\nX and change “?” into “.” at the end of the sentence. We then obtain “X is the\ncapital of Japan.”. We thus obtain “Tokyo is the capital of Japan.” from the\nknowledge base. We obtain the results in Figure 4 (a) by applying mdiﬀto the\ntwo sentences. We consider the part that is paired with X in the diﬀerences as\nthe answer and correctly obtain “Tokyo”.\nEven if there are diﬀerences between the compared sentences, we can still use\nmdiﬀto correctly extract the answer. For example, suppose that the knowledge\nsentence is “Tokyo is the capital in Japan.” In this case, the result of mdiﬀis\n;===== begin =====\nX\n;-----------------\nTokyo\n;=====\nend\n=====\nis\nthe\ncapital\nof\nJapan.\n(a) Case 1\n;===== begin =====\nX\n;-----------------\nTokyo\n;=====\nend\n=====\nis\nthe\ncapital\n;===== begin =====\nof\n;-----------------\nin\n;=====\nend\n=====\nJapan.\n(b) Case 2\nFig. 4. Results of mdiﬀin the question-answering system\nas in Figure 4 (b). Although the number of diﬀerences increased, the part that\ncorresponds to X remains “Tokyo” and the correct answer has been detected.\nThe question-answering system we have proposed repeats to transform the\nquestion sentence and knowledge sentence so that the two sentences are as similar\nas possible. It then extracts the answer by matching the sentences when they\nare at this point. Since we use the similarity between two sentences in that\ntime, we have to deﬁne the degree of the similarity between sentences. Since we\ncan recognize the common parts and the diﬀerent parts by using mdiﬀ, we can\ncalculate the degree of similarity as (the number of characters in the common\npart)/(the number of all characters).5 Here, if we suppose that we have a rule\nfor transforming “in” to “of”, we match the data after transforming “Tokyo is\nthe capital in Japan.” to “Tokyo is the capital of Japan.” and we are able to\nobtain the answer more reliably by decreasing the number of diﬀerences.\n5\nConclusion\nIn this paper, we describe a lot of examples of the use of diﬀin various problems\nof natural language processing. In Section 3.1, we describe how we apply diﬀto\na system that combines multiple systems and thus obtain higher precisions than\nfrom any of individual systems. Studies on combination of systems are very well\nknown. We describe how such combination can easily be performed by diﬀ. In\nSection 3.2, we showed that diﬀis easily able to examine the diﬀerences between\na spoken and written language and acquire rules for the transformation between\n5 Here, we use mdiﬀto calculate the degree of similarity of the sentences. Mdiﬀis also\nuseful in this way.\nthe spoken and written language. We handled the paraphrasing of written lan-\nguage into spoken language. However, the study on paraphrasing covers a wide\nrange: automatic extraction of compressed sentences, sentence polishing-up to\nmodify sentences correctly, and transformations from diﬃcult sentences to plain\nsentences. In these studies, too, it will be easy to apply diﬀto various forms of\nexamination and to the extraction of various transformation rules. This paper\nwill become a basis for studies of paraphrasing, an area in which there has been\nincreasing activity. In Section 4, we showed examples of the merging of data and\nthe optimal matching of data. Since diﬀis generally used to detect diﬀerences,\nSection 4, which shows applications of diﬀto merging and matching, presents a\nnew and original approach. In the section, we showed that it is easy to apply diﬀ\nto interesting studies of two kinds, the alignment of a paper with a corresponding\npresentation and a question-answering system.\nIn this paper, we have described many examples of the application of diﬀ\nto natural language processing. We hope that diﬀwill be applied to an ever-\nwidening range of studies.\nAcknowlegement\nWe were given data for the experiments on alignment of a paper with a corre-\nsponding presentation by Kiyotaka Uchimoto of the Communications Research\nLaboratory.\nReferences\n1. Masaki Murata and Hitoshi Isahara. Nlp using diﬀ. IPSJ-WGNL 2001-NL-144,\n2001. (in Japanese).\n2. Masaki Murata and Hitoshi Isahara. Universal model for paraphrasing: Using trans-\nformation based on a deﬁned criteria.\nIn NLPRS’2001 Workshop on Automatic\nParaphrasing: Theories and Applications, 2001.\n3. Masaki Murata and Hitoshi Isahara. NLP using DIFF — use of convenient tool\nfor detecting diﬀerences, MDIFF —. Journal of Natural Language Processing, 9(2),\n2002. (in Japanese).\n4. Masaki Murata, Masao Utiyama, and Hitoshi Isahara. Question answering system\nusing syntactic information. 1999. http://xxx.lanl.gov/abs/ cs.CL/9911006.\n5. Masaki Murata, Masao Utiyama, Kiyotaka Uchimoto, Qing Ma, and Hitoshi Isa-\nhara. Correction of the modality corpus for machine translation based on machine-\nlearning method.\n7th Annual Meeting of the Association for Natural Language\nProcessing, 2001. (in Japanese; an English translation of this paper is available at\nhttp://arXiv.org/abs/cs/0105001).\n6. Kiyotaka Uchimoto, Chikashi Nobata, Kimiko Ohta, Masaki Murata, Qing Ma, and\nHitoshi Isahara. Segmenting the transcription of a talk by aligning the transcription\nwith its corresponding paper. 7th Annual Meeting of the Association for Natural\nLanguage Processing, pages 317–321, 2001.\n",
  "categories": [
    "cs.CL",
    "H.3.3; I.2.7"
  ],
  "published": "2002-08-13",
  "updated": "2002-08-13"
}