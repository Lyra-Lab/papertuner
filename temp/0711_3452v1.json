{
  "id": "http://arxiv.org/abs/0711.3452v1",
  "title": "In memoriam Maurice Gross",
  "authors": [
    "Eric Laporte"
  ],
  "abstract": "Maurice Gross (1934-2001) was both a great linguist and a pioneer in natural\nlanguage processing. This article is written in homage to his memory",
  "text": "1 \nIn memoriam Maurice Gross \nÉric Laporte \nInstitut Gaspard-Monge, University of Marne-la-Vallée/CNRS \n5, bd Descartes, F 77454 Marne-la-Vallée CEDEX 2 \neric.laporte@univ-mlv.fr \n \n \nPhoto: Jacques Labelle \n \nMaurice Gross (1934-2001) was both a great linguist and \na pioneer in natural language processing. This article is \nwritten in homage to his memory1. \nMaurice Gross is remembered as a vital man surrounded \nby a lively group, constituted by his laboratory, the \nLADL2, and by his international network, RELEX. He \nand his group always resolutely steered away from any \nkind of abstemiousness or abstinence. He selected three \nof his first collaborators in 1968 from among his bistrot \npals of longstanding. Judging by their later scientific \nproduction, the selection was done with sharp judgment \n(e.g. Guillet, Leclère, 1992; Meunier, 1999). A convivial \natmosphere, picnics, drinks at the lab and other revelries \nwere the hallmarks of his group — though he has been \nperceived, on other occasions, as a tyrannical father. \nAs a linguist, Maurice Gross contributed to the revival of \nformal linguistics in the 1960s, and he created and \nimplemented an efficient methodology for descriptive \nlexicology. As specialist of natural language processing \n(NLP), he was also a pioneer of linguistics-based \nprocessing. \n                                                      \n1 I thank Christian Leclère for our discussions and his \nsuggestions, that make up a substantial part of this article. \n2 Laboratoire d'automatique documentaire et linguistique, \nUniversity of Paris 7 and CNRS. \n1. Linguistics \nThe best-known theory of Maurice Gross is that the \ndescription \nof \nidiosyncratic \nproperties \nof \nlexical \nelements, i.e. the description of the lexicon, is an \nessential part of the description of the syntax and \nsemantics of a language. He undertook to implement \nZellig Harris’ theory of syntax, which in fact also \nincludes a good deal of semantics, within a well-crafted \ndescription.3 \n1.1. Results: lexicons and grammars \nHis work comprises not only a vast array of books and \narticles, among the most significant being those of 1975 \nand 1981, but also a large data set: tables of syntactico-\nsemantic properties of thousands of lexical entries in \nFrench — not a common achievement among linguists. \nAs an illustration of this type of resource, we reproduce \nan excerpt of a table of English verbs (Fig. 1). \n \n                                                      \n3 There is a smooth continuum from the thought and work of \nZellig Harris to that of Maurice Gross, and it is sometimes \ndifficult to differentiate between their respective contributions. \n2 \n \nFig. 1. A Lexicon-Grammar table (Salkoff, 2002). \n \nSuch tables are known as Lexicon-Grammar tables or as \nLADL tables. The first tables were constructed around \n1970, long before comparable lexicons (Gross, 1975). \nSome are now available on the web (http://infolingu.univ-\nmlv.fr/english: follow Linguistic Resources). Intimately \nassociated with the name of Maurice Gross, they are an \nexample of the originality, creativity and fecundity of his \nscientific thought. \nFirstly, they are rich repositories of fact. As compared to \nother syntactico-semantic lexicons, Lexicon-Grammar \ntables have three salient features: \n- senses of verbs are distinguished and represented in \nseparate lexical entries, for example for John missed his \ndaughter and John missed the target; \n- inside a verb entry, different constructions are \nrepresented, for example John missed his daughter and \nMary was missed by her father; in that sense, the tables \ncontain the essential elements of a grammar;  \n- the number of entries is quite comprehensive, e.g. \n15,000 French verbs. \nSecondly, these tables are also a means of linguistic \ninvestigation. During the construction, they are an \nabundant source of discovery. Once complete, the tables \nare readable and constitute a tool for further research by \nthe international community of linguists, including for \nresearchers that do not share the theoretical assumptions \nof their authors. \nAnd they were designed as such. This is an example of \nthe generosity of Maurice Gross. He also used to pass \nideas on to students and colleagues, happy when they \nwere developed in publications, and never caring whether \nhe was acknowledged as their originator. \nThe work completed under his supervision includes a set \nof morpho-syntactic lexicons called DELA (Courtois, \n1990, 2004). We illustrate this resource with a sentence \nautomaton, which is automatically derived from these \nlexicons and displays the lexical tags of a sequence of \nwords (Fig. 2). \n \nFig. 2. A sentence automaton with lexical tags in the \nDELA format. \n \nThus, the work of Maurice Gross and the RELEX \nnetwork includes lexicons and grammars encompassing \nmorpho-syntactic and syntactico-semantic levels. Viewed \nas a whole, it describes both Indo-European languages \n(French, Italian, Portuguese, Spanish; English, German, \nNorwegian; Polish, Czech, Russian, Bulgarian; Greek) \nand others (Arabic; Korean; Malagasy; Chinese; Thai...) \n1.2. Predicative nouns \nThe analysis of sentences with a predicative noun and a \nsupport verb is a well-known aspect of the theory of \nZellig Harris and Maurice Gross (Harris, 1957). Many \nnouns can function as sentence predicates, playing the \nsame part as verbs, like in \nHuman language technologies have an increasing \nimportance \nIn such constructions, the noun is accompanied by a \nsupport verb, later termed ‘light verb’ by some writers \n(e.g. Grimshaw, Mester, 1988). The importance of \npredicative nouns for natural language processing comes \nfrom the fact that most technical nouns are predicative \nand that in technical texts, many predicates are nouns.  \nMaurice Gross directed studies on predicative nouns in \nFrench and other languages. Large-scale results emerged \nin the 1970s (Giry-Schneider, 1978) and generally \nvalidated the theory. Nonetheless, this theory was felt to \nbe iconoclastic and faced fierce scientific opposition for \nyears. It eventually gained greater acceptance during the \n1990s4. Resistance to the theory did not influence his \nopinion because Gross was aware that his opponents’ \narguments did not stand up to analysis. He knew better \nthan they did which details of the predicative \nnouns/support verbs model did not work. \nMaurice Gross could be obstinate; he liked contradiction, \nand his critical mind was developed to an uncommon \ndegree. As regards the combination of wine with food — \na far weightier issue than predicative nouns — Maurice \nGross appreciated some red wines with fish and some \nwhite wines with cheese, and he enjoyed demonstrating \nhis irritation and amusement when he received slighted \nremarks from wine waiters in classier restaurants. \n1.3. Compounds and idioms \nGross set up a series of studies on compound lexical units \n(e.g. Freckleton, 1985; Machonis, 1985), breaking with a \nlong tradition that holds that such phrases are exceptions, \nworth only of anecdotal remarks. Compound lexical units \nare phrases described as lexical units (Gross, 1986a), as \nin: \nCell phones have antennas \nThey can be defined by their lack of compositionality and \nthe distributional frozenness of their elements. The \nfindings showed that languages have a large number of \n                                                      \n4 The same can be said for predicative adjectives, as in Human \nlanguage technologies are increasingly important. \n3 \ncompound predicates such as make ends meet, and that \ncompound entries are often more numerous than the \nsimple-word entries for the same part of speech. In \nFrench, for instance, Maurice Gross indexed 26,000 \nverbal idioms5 (Gross, 1982) and 12,000 adverbial idioms \n(Gross, 1986b). \nHe devised the notion of local grammars (Gross, 1997) \nfor semi-frozen phrases and for sequences with frozen \nbehaviour inside a specific domain, like cloudy with \nsunny periods. \nThe term ‘multi-word units’ (Glass, Hazen, 1998) is more \nrecent. It groups support-verb constructions, compound \nlexical units, semi-frozen phrases and collocations.  \n1.4. Methodological legacy \nMaurice Gross contributed centrally to the construction \nof rigorous empirical methods for syntactic and semantic \ndescription, \nborrowing \nfundamental \nnotions \nfrom \nexperimental sciences like biology and physics. This is \nprobably his greatest achievement, but it obviously \naccrued still further weight from his parallel descriptive \nwork, which showed that his methods were applicable to \nreal, unrestricted data. Historically, this methodological \nwork was part of the international movement in scientific, \nformalised linguistics that took place in the 1960s. In \n1968, Maurice Gross also contributed to the foundation \nof the Linguistics Department of the University of \nVincennes, and was the editor of Langages 9, a volume \nof articles by major contemporary players such as \nYehoshua Bar-Hillel, Noam Chomsky, Maurice Gross, \nZellig Harris and Marcel-Paul Schützenberger. \nResorting to experimental sciences for linguistic \nmethodology may sound strange to many linguists, even \ntoday, but it is justified by the fact that the only possible \nsource of knowledge in descriptive linguistics is \nempirical observation. The central epistemological notion \nthere is the reproducibility of experiments, i.e. that the \nresults of observation should not depend on the \nobservers. Obviously, the objective of reproducibility is \nparticularly difficult to attain in linguistics. In addition, \nany steps taken in order to ensure reproducibility should \nbe compatible with the objective of actual large-scale \ndescription. Maurice Gross advocated a subjective \nmethod with a collective control: empirical observations \nare performed through introspection by a team of native-\nspeaker linguists. This is how the Lexicon-Grammar \ntables of French verbs were constructed. \nSome argue that sufficient reproducibility can only be \nensured by way of total objectivity. However, whatever \nprecautions can be taken in order to ensure the objectivity \nof results (blind experimentation, exclusive resort to \nattested language productions…), they are in practice \nincompatible with the large-scale description of a \nlanguage. \n2. Natural language processing \n2.1. Construction of language resources \n                                                      \n5 Idioms with support verbs, such as to be heavy-handed, \nnot included. \nMaurice Gross designed and implemented a set of \nmethods and tools for the manual elaboration of language \nresources of quality. \nAs compared to common practices in language resource \nconstruction and management, the quality of resources \nconstructed with these methods can be characterised by \nfour features: \n- Coverage is large, which is obtained by systematic \nbrowsing of segments of the language (parts of speech, \nfor instance) \n- Representation is formal, e.g. encoded, to permit \ncomputational \nexploitation \nfor \nnatural \nlanguage \nprocessing purposes \n- Models for different languages are parallel \n- Information is particularly accurate, since it is based on \nmanual analyses of introspective or attested data by \ntrained linguists, and errors are corrected directly when \ndiscovered. (In resources automatically derived from \nrules \nor \ncorpora, \nthe \ninformation \nprovided \nis \napproximate; when an error in a resource is discovered, \nmethods to correct it are not sure to be successful and can \nbring about further errors.) \nThis level of quality is obtained, as said, through \nessentially manual construction and maintenance. This \nimplies two additional features: \n- Resources are readable to a high degree, as is \nexemplified by the two figures above (the relevant \ninformation is dense; when necessary, as in the second \nfigure, the display is graphical). \n- The accumulation of resources is gradual, thus allowing \nfor the progressive, collaborative construction of large \nresources from independent elements. \nIn the application of these methods, Maurice Gross kept a \nwatchful eye on the level of formalization. In complete \nagreement with Zellig Harris’s objective of a formally \nminimal theory6, he was very keen on minimalism in \nabstract complexity. He avoided giving new names to \nalready named notions, as computational linguists usually \ndo7. He carefully avoided creating new abstract notions or \nmodels, or building complex abstract representations, \nunless they were really useful. For example, the VP node \nin syntactic trees is useless, and so is the distinction \nbetween PP and NP nodes (the presence/absence and \nlexical value of the preposition can perfectly be specified \nwithout two distinct nodes). Such nodes introduce \nunnecessary complexity into syntactic trees (Fig. 3), \nwhereas the complexity of the phenomena themselves \ncalls for the simplest possible tools (Fig. 4). \n                                                      \n6 This difference between Zellig Harris and Noam Chomsky \nshows even in their respective conceptions of transformations: \nfor Harris, a transformation relates observable sentence forms; \nfor Chomsky, it is a device to transform a deep structure into a \nsurface structure. \n7 For example, morpho-syntax has been called syntax by so \nmany writers that now they have to call syntax ‘deep syntax’. \n4 \n \nFig. 3. A syntactic tree with useless nodes. \n \n \nFig. 4. A simpler syntactic tree. \n \nThis position was consistent with his own character. \nPragmatic, Maurice Gross liked simplicity and had good \nsense. He was not easy fooled by apparently attractive \nand brilliant but poor ideas. He was delighted by the \nSokal (1996) hoax against fashionable intellectual \ndiscourse. \n2.2. Linguistics-based language processing \nRight from the beginning, Maurice Gross was aware that \nformal descriptions of natural languages could be applied \nto language processing. The first opportunity to study \nlinguistics had been offered to him in the 1950s in a \nmachine translation laboratory, during the first period of \nenthusiasm for machine translation. In the 1960s, he \nfounded and pioneered the concept of linguistics-based \nNLP, long before the international interest for language \nresources. In this approach, the construction of NLP \nprograms is based on language resources (lexicons and \ngrammars), which are, in turn, based on descriptive \nlinguistics. He began to apply this concept in the 1960s \nand 1970s. \nHowever, statistics-based NLP developed and became \ndominant in the 1980s: the only language resources \nrequired for this approach to NLP are corpora. While \nspecialists of linguistics-based NLP were developing \ntheir methods, the bulk of the NLP community was \ndiscouraged by the difficulty and cost of such work, but \naware that language resources were required for the \nfulfilment of their objectives. This paradox was called the \n‘bottleneck of NLP’. The international academic \ncommunity eventually got an interest for language \nresources, but only in the 2000s. \nIn spite of the difficulty and cost of linguistics-based \nconstruction of language resources, Maurice Gross \nlargely attained his objectives of quality: coverage, \nformalisation, \nstandardisation \nand \naccuracy. \nThe \nresources developed by him and under his supervision are \nused by many laboratories and companies, some of them \nfounded by his followers, and their exploitation still \noffers huge potential for future research and applications.  \n2.3. Finite-state processing \nMaurice Gross’s approach to the use of the finite \nautomaton \nmodel \nfor \nNLP \nwas \npragmatic \nand \nconstructive. Soon after the creation of this model, the \nfamous article by Chomsky (1956) was interpreted as a \nban on its use in linguistics. There were few \ntransgressions (Woods, 1970). Much later, Maurice Gross \n(1989a) gave examples indicating that the finite \nautomaton would be a convenient, invaluable tool for \nsyntactic description. Groups related to the University of \nHelsinki and Rank Xerox were of the same opinion, and \nit came to be one of the most popular models. The \nRELEX network began to use finite automata with the \ngraphical editor developed by Silberztein (1993). \nEmpirical studies led to the design of a model of \nlexicalised syntactic grammar in the form of a large \nnetwork of finite automata, or ‘recursive transition \nnetwork’. \n2.4. Rules vs. idiosyncrasies \nI myself often heard that Maurice Gross was ‘pessimistic’ \nbecause he did not have confidence in rules where \nlanguage is concerned. \nThe notions of rule and idiosyncrasy are symmetrical. \nRules are generic statements, such as ‘nouns in -s are \nplural’, whereas idiosyncrasies are particular facts, \nusually about lexical items, such as ‘beans is plural’ or \n‘means is singular’. Both forms can express formal \nknowledge, which raises interesting issues: when a rule is \nright, what is the use of the corresponding idiosyncrasies? \nand vice versa; should language resources be based on \nrules or on idiosyncrasies? \nIn practice, rules tend to be inaccurate because of the \nubiquity of chaotic behaviour and exceptions in language, \nas our example ‘nouns in -s are plural’ suggests. When \nwe devise rules manually, we have a natural tendency to \nover-estimate their predictive power; when they are \nautomatically \nderived \nfrom \ncorpora, \nresults \nare \napproximate. When idiosyncratic data are available, they \nare more often accurate, i.e. in conformity with \nobservable reality. \nOn the other hand, rules can be automatically inferred, \nwhereas accounts of idiosyncratic facts have to be \nrecorded manually, a work which obviously requires \ntime, skill and effort, and is therefore more costly. \nIn this trade-off between accuracy and cost, software \nengineers tend to prefer rules, even if slightly inaccurate, \nbecause they feel that rules achieve a higher level of \nautomation than collections of particular facts. In \naddition, they unanimously say that the manual \nconstruction of language resources is difficult, and often \nthat it is tedious. However, this is not a specialist’s \nopinion, since they seldom have the opportunity to \nengage in such tasks. On the contrary, Maurice Gross \n5 \ntook evident pleasure in assembling and disassembling \nmechanisms of language. \nLinguists are obviously interested in discovering rules. In \ngood scientific practice, such discovery requires \nobserving facts as completely as possible, but most \nlinguists do not check large numbers of idiosyncratic \nfacts, and they never say explicitly why: do they also \nconsider studies on lexis as tedious? or as a second-rate \nor shameful work? In any case, such studies have been \nconsistently neglected. \nBack to the 1960s, when Maurice Gross undertook his \nwork on lexis, issues about rules and idiosyncrasies were \nbeing discussed among linguists. Harris (1951) admitted \nthe necessity of representing lexical restrictions: ‘We now \nhave sets of morphemic components (and residues), so set \nup that as nearly as possible all sequences and \ncombinations of them occur (...) It may not be convenient \nto represent by means of components such limitations of \noccurrence among morphemes as do not intersect with \nother limitations involving the same morphemes, or as do \nnot lead to the division of a class into sub-classes clearly \ndifferentiated on that basis (...) This is frequently the case \nfor morphemes classes which are grouped together into a \ngeneral class on the basis of major similarities, but which \nhave small and unpatterned differences in distribution.’ \nSo did Chomsky (1962): ‘There are in fact exceptions to \nmany rules given above, perhaps all. These will have to \nbe separately listed, unless some more general \nformulation can be found to account for them as well. \n(…) But discovery of exceptions to grammatical \ngeneralizations is of no consequence in itself, except \nwhen it leads to an alternative more comprehensive \ngeneralization.’ \nAnd again (Chomsky 1965): ‘Much of lexical structure \nis, in fact, simply a classification induced by the system of \nphonological and syntactic rules. Postal has suggested, \nfurthermore, that there should be a general lexical \nanalysis of lexical items with respect to each rule R, into \nthose which must, those which may, and those which \ncannot be subject to R, and has investigated some of the \nconsequences of this assumption. I mention these \npossibilities simply to indicate that there remain \nnumerous relatively unexplored ways to deal with the \nproblems that arise when the structure of a lexicon is \nconsidered seriously. (...) For the present, one can barely \ngo beyond mere taxonomic arrangement of data. Whether \nthese limitations are intrinsic, or whether a deeper \nanalysis can succeed in unraveling some of these \ndifficulties, remains an open question’. \nBut none of them shifted from such theoretical \nobservations to the empirical description of a language, \nincluding its lexis. \nMaurice Gross was the first to consider such a \nprogramme as a priority, to draw the consequences and to \ntake up the challenge. His Transformational Grammar of \nFrench (1968, 1977, 1986b) is a scientific milestone. As \nAmr Ibrahim (2002) puts it, it clearly shows the limits of \nrule-based formal accounts of a language, highlighting \ninsurmountable obstacles to the representation of \nnumerous apparently insignificant phenomena, even \nlimited to the scope of simple sentence. \nZellig Harris’s theory was a sound basis for such a \nresearch programme and he supported Maurice Gross. \nMeanwhile, \nNoam \nChomsky \nwas \ninsisting \nthat \nidiosyncratic facts were not worth investigating; Gross \n(1973, in French, and the famous 1979 version in \nEnglish) criticised the practices of generative grammar on \nthese grounds. \nMaurice Gross’ programme is ambitious, because it \nrequires the meticulousness of an entomologist, but he \nimplemented it in a remarkably practical way, because he \nhad the wisdom to recognise priorities and leave the rest \nfor later generations. For example, restrictions on verb \ntenses are not represented in the present state of Lexicon-\nGrammar tables of French: \n*Une récompense est promise à Luc par Marie \n« A reward is being promised to Luke by Mary » \nUne récompense a été promise à Luc par Marie \n« A reward was promised to Luke by Mary » \nNeither are productive pronominal constructions such as: \nUne telle récompense se promet facilement \n« Such a reward is easily promised » \nMaurice Gross’ decision to launch his programme \nrequired \naudacity, \npracticality, \ngood \nsense, \nand  \nintellectual honesty. He was not afraid of data. He \nprobably described the situation calmly, in such terms as: \n‘One has to study all sentence types and all types of \nverbs. Well, let’s see what we find.’ This indicates his \nability to go to the heart of a problem with precision and \nlucidity, and to express his conclusions with a brutality \nand provocation that gave him some Voltairian sense of \nhumour. \nHe exercised the same humour in his ferocious comments \non scientific adversaries, with no regard for political \ncorrectness, and through a collection of favoured put-\ndowns such as ‘They are all illiterates.’ ‘He’s lightly \nmentally handicapped.’ ‘He’s a sick man.’ ‘Their \narrogance is equalled only by their incompetence’ and so \non. \n2.5. Corpora vs. lexicons and grammars \nIn the currently dominant model of NLP, more or less \nlanguage-independent programs infer information on \ninput text from rules acquired by frequency-based corpus \nprocessing. \nIn practical terms, the extensive use of this model makes \nlanguage resource management cheaper. The corpora \nused by the world’s programs make up a largely stable \nset: operations to enhance or extend them or to create \nnew ones are much less frequent than operations making \nuse of them. In addition, constructing corpora, and even \ntagged corpora, is a smaller investment than constructing \nlexicons and grammars. The information in state-of-the-\nart tagged corpora is less complete than the information \nin state-of-the-art lexicons and grammars. Coverage of \nlexical elements is poorer. Structural complexity is kept \nsmaller because of the computational limitations of \nfrequency-based inference programs. The annotation of \nmulti-word units (e.g. make ends meet) is poorer. Sense \ndistinctions (e.g. between John missed his daughter and \n6 \nJohn missed the target) are not made. Indirectly, this \npolicy limits the number of linguists to be educated by \nuniversities and hired by companies. \nBut the price to be paid for this limitation of costs is a \nlower quality of product. Maurice Gross worked much \nmore on lexicons and grammars than on corpora. \nInference-based \nor \nstatistics-based \nprograms \ncan \ncompensate for part of the difference of information \ncontent, but cannot compete with manually constructed \nlexicons and grammars, because the automatically \ninferred information is only approximate. \nThere are two alternative approaches: linguistics-based \nprocessing making use of manually constructed lexicons \nand grammars, and hybrid processing. In the present \nsituation, they are perceived as factors of quality and \nprogress, as is illustrated by the increasing use of \ncompound-word lexicons by language engineering \ncompanies and search engines. \nThis debate is connected to the controversy between \ncorpus linguistics and introspective linguistics. \nIntrospective linguists use introspection, a subjective \nhuman faculty, as one of the sources of linguistic \nknowledge. Corpus linguists, in contrast, are usually \nantipathetic to the use of introspective data. Some of \nthem use the term armchair linguistics to suggest that \nintrospective linguistics fails to deal with the reality of \nlanguage, and that this reality is accessible only through \nattested linguistic productions. However, negative \ninformation, such as the inacceptability of some linguistic \nforms, is also an aspect of the reality of languages, \nwhereas it is accessible only through introspection, and \nnot through corpus exploration. In addition, there is no \nexample of a large-coverage formalized lexicon or \ngrammar constructed on the basis of corpus linguistics. \nMaurice Gross was not opposed to the use of corpora, but \nhis practice evolved with time. He began to use corpora \nonly when a professional tool (Silberztein, 1993) was \navailable to explore them. And this tool was based on the \nlexicons constructed under his supervision. In fact, no \nwork is more inadequately described by the term \narmchair linguistics than his.  \nHis position on the respective potential of corpora, \nlexicons and grammars conflicted both with the statistics-\nbased approach to NLP and with the positions of strict \ncorpus linguists. Among the reasons why his scientific \narguments could not persuade them, we find a number of \nextra-scientific reasons, and in particular, sociological \nexplanations. The opposition between statistics-based and \nlinguistics-based NLP is founded on the division between \nengineers and linguists, a very strong cultural gap; and \nthe opposition between introspective and corpus \nlinguistics had many features of a generation gap. Human \nfactors like these can have such a power on people’s (and \neven scholars’) minds that they can prevent them from \naccepting perfectly rational argument. As an independent \nthinker, Gross was not impressed by a consensus based \npartly on non-scientific reasoning. \nThis particular personal trait showed in the way he \neducated his students. When he talked with them ― and \nhe invested a lot of time in the education of some of them \n― he focused on scientific matters, leaving them to find \nthemselves training in more mundane skills or political \nstrategies. \n2.6. A few scientific fashions \nNeedless to say, Maurice Gross did not make concessions \nto unjustified scientific fads and fashions. His positions \nindicate a remarkably long-term view and intuition. Here \nare three examples of scientific fashions he struggled \nagainst, with solid scientific arguments on his side. \n2.6.1. Machine translation without a lexicon \nNot only did Maurice Gross (1972) insist that lexicons \nare required for machine translation, but also that the \nlexicon is the first element that should be constructed, \nbecause virtually all other components depend on it. \nMachine translation is now regularly taken as an example \nof a field that requires lexicons. The modern notion of \ntranslation memories is just a variant of the notion of \nlexicon. \n2.6.2. Deriving lexicons from conventional dictionaries \nThe idea of deriving lexical resources from conventional \ndictionaries \n(called \nmachine-readable \ndictionaries, \nMRDs) became amazingly popular in the end of the \n1980s. It appeared as an alternative to the costly task of \nmanually constructing lexical resources. Maurice Gross \n(1989b) denounced this trend as an illusion and a wrong \nanswer to a real problem, showing that information is \nmuch less formal and systematic in dictionaries written \nfor human readers than in the resources required for NLP. \nThis prediction was confirmed years later: the results of \nthese researches were disappointing (Ide, Véronis, 1993). \n2.6.3. Small tagsets \nThe most commonly used tagsets are small: they have \nbetween 15 to 100 tags, which is what is needed to \nencode morpho-syntax, lemma excluded, in many \nlanguages. The most basic operations on tags are word \nannotation (assigning tags to words) and ambiguity \nresolution (removing wrong tags). The latter problem is \nfar more challenging than the former. Both depend \nheavily on the size of the tagset. \nMaurice Gross used to warn that larger tagsets are \nrequired for handling lemmata or syntactico-semantic \ninformation. However, since the 1990s, most of the field \nseems to have considered that one should keep on using \nsmall tagsets as long as technology to solve lexical \nambiguity is not available. This view aims at limiting the \ncomplexity of tagged text, which is used as input for \nfurther operations. But it also severely limits the \ninvestigation of approaches to annotation as well as \napproaches to ambiguity removal. \nInternational interest for larger tagsets has progressively \nincreased during the last 5 years. \n2.6.4. Comment \nSuperficial scientific fashions appear from time to time, \nand can endure, even though not always a sign of \nprogress. They may lead research in wrong directions, \nand thus cause waste. This is likely, because research \noutcomes are not known beforehand. But it is interesting \n7 \nto notice cases where failure could have been avoided by \npaying attention to scientific arguments presented by an \noutstanding scholar. \nThe current mechanisms of scientific democracy, and in \nparticular peer review, regulate research agendas and \nundoubtedly represent progress, but they cannot prevent \nundesirable \nfashions: \nthese \nchecks \nand \nbalances \ndeveloped progressively during the career of Maurice \nGross, and were quite well installed even 20 years ago, \nbut they failed to prevent short-sighted views from \ninvading the field for years after. \n3. Institutional legacy \nIn addition to his works, Maurice Gross’s legacy includes \nan enduring research infrastructure, made up of the \nfollowing elements: \n- an informal network of specialists of linguistics-based \nlanguage resources, RELEX. \n- a series of International Conferences on Lexis and \nGrammar, held since 1981 (Liverpool 2005, Palermo \n2006). \n- an international journal with a selection committee, \nLingvisticæ Investigationes, published by Benjamins. \n- a model and a format for lexical resources implemented \nin numerous languages: the DELA format (Courtois, \n1990). The model, the format and the resources were the \nmain source of inspiration for the development of \nstandards in lexical resources by the Genelex project, and \nindirectly for later standards. \nConclusion \nThrough the originality of his legacy and his long-term \nvision, Maurice Gross is an impressive scientist. Most of \nhis innovations, even those dating back to the 1960s and \n1970s, are now becoming increasingly accepted by the \nscientific community around the world. It is all the more \ninteresting to notice how much and for how long they met \nwith resistance when he first expressed them. \nMaurice Gross is worth reading now and for some time to \ncome. His work is more innovative than that presented at \nmany high-profile conferences and journals this year. \nAnd it will be so next year. \nReferences  \nChomsky, Noam (1956). Three models for the \ndescription of language. I.R.E. Transactions on \ninformation theory, vol. 2, pp. 113-124. \nChomsky, Noam (1962). Explanatory Models in \nLinguistics. Logic, Methodology and Philosophy of \nScience, E. Nagel, P. Suppes and A. Tarski (eds.), \nStanford University Press. \nChomsky, Noam (1965). Aspects of the theory of syntax. \nCambridge, MA: MIT Press, 251 p. \nCourtois, Blandine (1990). Un système de dictionnaires \nélectroniques pour les mots simples du français, \nLangue Française 87, \"Dictionnaires électroniques du \nfrançais\", Paris : Larousse, pp. 11-22. \nCourtois, Blandine (2004). Dictionnaires électroniques \nDELAF anglais et français. Lexique, Syntaxe et \nLexique-Grammaire/Syntax, \nLexis \n& \nLexicon-\nGrammar, Ch. Leclère, É. Laporte, M. Piot and \nM.Silberztein (eds.), pp.113-. \nFreckleton, Peter (1985). Sentence idioms in English. \nWorking Papers in Linguistics 11, University of \nMelbourne, pp. 153-168 + appendix (196 p.), ISSN \n1443-6914. \nGiry-Schneider, Jacqueline (1978). Les nominalisations \nen français. L’opérateur faire dans le lexique. Genève: \nDroz. \nGlass, James R., Timothy J. Hazen (1998). Telephone-\nbased conversational speech recognition in the Jupiter \ndomain, Proceedings of the International Conference \non Spoken Language Processing, Sydney, Australia. \nGrimshaw, Jane, Armin Mester (1988). Light Verbs and \nTheta-Marking. LinguisticInquiry 19, pp. 205-232. \nGross, Maurice (1968). Grammaire transformationelle du \nfrançais. Vol. 1, Syntaxe du verbe. Paris: Larousse. \nGross, Maurice, ed. (1968). Les modèles en linguistique. \nLangages 9, Paris: Larousse. \nGross, Maurice (1972). Notes sur l'histoire de la \ntraduction automatique. Langages 28, p. 40-48, Paris: \nLarousse. \nGross, Maurice (1973). Remarques sur la méthodologie \nde la grammaire générative transformationnelle. The \nFormal Analysis of Natural Languages, The Hague: \nMouton, pp. 251-264. \nGross, Maurice (1975). Méthodes en syntaxe, Paris: \nHermann.  \nGross, Maurice (1977). Grammaire transformationelle du \nfrançais. Vol. 2, Syntaxe du nom. Paris: Larousse. \nGross, Maurice (1979). On the failure of generative \ngrammar. Language 55:4, pp. 859-885. \nGross, Maurice (1981). Les bases empiriques de la notion \nde prédicat sémantique, Langages 63, Paris: Larousse. \nGross, Maurice (1982). Une classification des phrases \n\"figées\" du français, Revue Québécoise de Linguistique \n11.2, pp. 151-185, Montréal: UQAM. \nGross, \nMaurice \n(1986a). \nLexicon-Grammar. \nThe \nRepresentation of Compound Words. COLING, Bonn, \npp. 1-6. \nGross, Maurice (1986b). Grammaire transformationelle \ndu français. Vol. 3, Syntaxe de l’adverbe. Paris: \nASSTRIL. \nGross, Maurice (1989a). The Use of Finite Automata in \nthe Lexical Representation of Natural Language. \nElectronic \nDictionaries \nand \nAutomata \nin \nComputational Linguistics, Lecture Notes in Computer \nScience, p. 34-50, Berlin/New York : Springer Verlag. \nGross, Maurice (1989b). La construction de dictionnaires \nélectroniques, Annales des Télécommunications 44(1-\n2):4-19, Issy-les-Moulineaux/Lannion: CNET. \nGross, Maurice (1997). The Construction of Local \nGrammars. \nFinite \nState \nLanguage \nProcessing, \nCambridge, Mass., The MIT Press, pp. 329-352. \nGuillet, Alain, Christian Leclère (1992). La structure des \nphrases simples en français. Les constructions \ntransitives locatives, Genève, Droz, 446 p. \nHarris, Zellig (1951). Structural Linguistics, University \nof Chicago Press, 384 p. \nHarris, Zellig (1957). Co-occurrence and transformation \nin linguistic structure. Language 33, pp. 293-340. \n8 \nIde, N., Véronis, J. (1993). Extracting knowledge bases \nfrom machine-readable dictionaries: Have we wasted \nour time?, KB&KS Workshop, Tokyo. \nIbrahim, Amr (2002). Maurice Gross, Romaneske \n2002(1), Catholic University of Leuven. \nMachonis, Peter A. (1985). Transformations of verb \nphrase idioms: passivization, particle movement, dative \nshift. American Speech 60:4, pp. 291-308. \nMeunier, Annie (1999). Une construction complexe \nNhum être Adj de V0-inf W caractéristique de certains \nadjectifs à sujet humain, Langages 133, Paris : \nLarousse. \nSalkoff, Morris (2002). Verbs with a sentential subject: A \nlexical examination of a sub-set of psych verbs, \nLingvisticæ Investigationes 25:1, Benjamins, pp. 97-\n147. \nSilberztein, Max (1993). Dictionnaires électroniques et \nanalyse automatique de textes. Le système INTEX, \nParis, Masson, 234 p. \nSokal, Alan (1996). Transgressing the Boundaries: \nToward a Transformative Hermeneutics of Quantum \nGravity, Social Text 46-47, pp. 217-252. \nWoods, W.A. (1970). Transition network grammars for \nnatural language analysis, Communications of the ACM \n13:10, pp. 591-606. \n \n",
  "categories": [
    "cs.CL"
  ],
  "published": "2007-11-21",
  "updated": "2007-11-21"
}