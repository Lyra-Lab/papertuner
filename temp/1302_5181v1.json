{
  "id": "http://arxiv.org/abs/1302.5181v1",
  "title": "Basic Classes of Grammars with Prohibition",
  "authors": [
    "Mark Burgin"
  ],
  "abstract": "A practical tool for natural language modeling and development of\nhuman-machine interaction is developed in the context of formal grammars and\nlanguages. A new type of formal grammars, called grammars with prohibition, is\nintroduced. Grammars with prohibition provide more powerful tools for natural\nlanguage generation and better describe processes of language learning than the\nconventional formal grammars. Here we study relations between languages\ngenerated by different grammars with prohibition based on conventional types of\nformal grammars such as context-free or context sensitive grammars. Besides, we\ncompare languages generated by different grammars with prohibition and\nlanguages generated by conventional formal grammars. In particular, it is\ndemonstrated that they have essentially higher computational power and\nexpressive possibilities in comparison with the conventional formal grammars.\nThus, while conventional formal grammars are recursive and subrecursive\nalgorithms, many classes of grammars with prohibition are superrecursive\nalgorithms. Results presented in this work are aimed at the development of\nhuman-machine interaction, modeling natural languages, empowerment of\nprogramming languages, computer simulation, better software systems, and theory\nof recursion.",
  "text": " \n \n \nBasic Classes of Grammars with Prohibition  \n \nMark Burgin \nUniversity of California, Los Angeles \nLos Angeles, CA 90095, USA \n \n \n \n \n \nABSTRACT \nA practical tool for natural language modeling and development of human-machine \ninteraction is developed in the context of formal grammars and languages. A new type of \nformal grammars, called grammars with prohibition, is introduced. Grammars with \nprohibition provide more powerful tools for natural language generation and better describe \nprocesses of language learning than the conventional formal grammars. Here we study \nrelations between languages generated by different grammars with prohibition based on \nconventional types of formal grammars such as context-free or context sensitive grammars. \nBesides, we compare languages generated by different grammars with prohibition and \nlanguages generated by conventional formal grammars. In particular, it is demonstrated that \nthey have essentially higher computational power and expressive possibilities in comparison \nwith the conventional formal grammars. Thus, while conventional formal grammars are \nrecursive and subrecursive algorithms, many classes of grammars with prohibition are \nsuperrecursive algorithms. Results presented in this work are aimed at the development of \nhuman-machine interaction, modeling natural languages, empowerment of programming \nlanguages, computer simulation, better software systems, and theory of recursion. \n \n \nKeywords: formal grammar, formal language, grammar with prohibition, human-computer \ninteraction, hierarchy, natural language, programming language \n \n \n \n1. Introduction \nAn important problem of computer technology is organization of convenient, flexible and \nefficient interaction with computers. It is important for many types of software systems in \ndifferent areas: computer simulation, learning, decision-making, etc. Natural language is a \ntool for human-machine interaction that has several desirable properties. First, it provides an \nimmediate vocabulary for talking about the contents of the computer. Second, it gives means \nof accessing information in the computer independently of its structure and encoding. Third, \nit shields the user from the formal access language of the underlying system. Fourth, it is \navailable with a minimum of training. This is especially important for business and industry \nwhere natural language is the most preferable. As a result natural language comprehension \nand modeling is one of the central problems in artificial intelligence. Researchers have \ndeveloped a quantity of different techniques to solve this problem. \nFormal grammars were introduced by Chomsky (1956) in his paper on the syntactic \nstructure of a natural language to the goal of representing natural languages by formal \nstructures. In verbal communication, an utterance is characterized by the surface \nmanifestation of a \"deeper\" structure representing \"meaning\" of the utterance. The deep \nstructure can undergo a variety of transformations of form (e.g., changes of the word order, \nof endings, etc.) on its way up, while retaining its essential meaning. These transformations \nare performed by transformational grammars, which work with syntax. They have three \ncomponents. The first component is a phrase-structure grammar generating strings of \nmorphemes representing simple, declarative, active sentences, each with an associated phrase \nmarker or derivation tree. The second component is a set of transformational rules for \nrearranging these strings and adding or deleting morphemes to form correct representations \nof the full variety of authorized sentences. Finally, a sequence of morphophonemic rules \nmaps each sentence representation to a string of phonemes. Formal grammars are capable of \ndescribing much of the grammar, or syntax, of natural languages such as English or Spanish \n(Martin, 1991). \nLater formal grammars were used to describe programming languages and build \ncompilers. In this area, formal grammars became even more useful than in the province of \nnatural languages. For instance, most of the syntax of such popular programming language as \nPascal is described by Backus-Naur forms (Backus, 1959), which are equivalent to context-\nfree grammars. Thus, formal grammars have played a central role in compiler technology and \nparser design since 1960’s. More recently, these grammars have been intensively used to \ndescribe document formats for information exchange on the Web.  \nFormal grammars proved to be very efficient for generating various linguistic structures, \nbut only for modeling small fragments of natural languages. Their generative and expressive \npower appeared insufficient for large linguistic systems, not speaking about such developed \nnatural languages as English or Spanish. As Martin (1991) writes, it is unrealistic to expect to \narrive at a complete description of natural languages using these grammars. As a result, the \nprincipal limitation of existing programs that perform natural language generation is that they \nfail to realize a sufficiently broad range of requirements to demonstrate convincing linguistic \ncapability (Jacobs, 1986). All this brings us to the problem of achieving higher efficiency for \nformal grammars. \nIn this work, we further develop a new approach to this problem based on formal \ngrammars with prohibition introduced and studied in (Burgin, 2005a; 2005b). Here we study \nrelations between languages generated by different grammars with prohibition based on \nconventional types of grammars such as context-free or context sensitive grammars. Besides, \nwe compare languages generated by different grammars with prohibition and languages \ngenerated by conventional formal grammars. In particular, it is demonstrated (cf., for \nexample, Theorems 4, 6 and Corollary 2) that they have essentially higher computational \npower and expressive possibilities in comparison with the conventional formal grammars. As \na result, they provide more means for human-machine interaction, modeling natural \nlanguages, empowerment of programming languages, computer simulation, developing better \nsoftware, and theory of recursion. \nThe obtained results are summarized in the tables given in the Appendix, which represent \nrelations between classes of languages generated by grammars with prohibition, as well as \nbetween languages generated by different grammars with prohibition and languages \ngenerated by conventional formal grammars. \nIt is necessary to remark that grammars with prohibition.were also studied by Carlucci, \nCase and Jain (2007), who called them correction grammars and used for learning in the limit \nof classes of recursively enumerable languages. Case and Jain (2011) proved the Rice and \nRice-Shapiro theorems for transfinite correction grammars. \n \n \n2. Grammars with Prohibition \nTo define formal grammars with prohibition, we fix some alphabet Σ and consider \nlanguages and formal grammars that use only this alphabet. \nDefinition 1. A formal grammar G with prohibition consists of rules that are divided into \ntwo parts: positive PG and negative NG.  \nThese rules generate in a conventional manner, i.e., by derivation or recursive inference \n(cf., for example, (Hopcroft et al, 2001)), two languages L(PG) and L(NG).  \nRemark 1.  It is usually assumed that alphabet Σ and systems of rules are finite.  \nDefinition 2. We define the language of the grammar G with prohibition as L(G) = \nL(PG) \\ L(NG). \nPositive rules are used for generation (acceptation) words from the language, while \nnegative rules are used for exclusion of incorrect forms. \nRemark 2.  When there are no negative rules, we obtain conventional formal grammars \nand their languages.  \nConstruction of languages by means of grammars with prohibition correlates with the \ntechnique used by people for natural language text generation. At first, general rules for \ngenerating words and texts are given. Then exclusions from these general rules are described. \nSuch exclusions mean prohibition of application of definite general rules in some cases. For \ninstance, one of the simplest forms of a basic English sentence is \n<subject> <verb> <object> \nwhich is illustrated by the example \nSam wears a shirt. \nHowever, there is a prohibition to use \nA shirt wears Sam. \nIn some cases, it is possible to give all possible kinds of permitted sentences by positive \nrules. Yet often this becomes inefficient and it is more potent not to give all cases when a \ngeneral rule may be applied, but to present those instances when application of the rule is \nprohibited. The same is true for generation of words. Irregular verbs give an example of such \nsituation. Verbs in English and in many other languages come in two groups. Regular verbs \nsuch as “adopt”, “behave”, and “call” form their simple past tense and its past participle \nforms by adding the inflectional ending -ed (or in some cases -d or -t); this means that the \npast tense and the past participle of regular verbs are always identical in form. English has \nthousand of existing regular verbs, and new ones are being added all the time. The number of \nthe irregular verbs is much smaller. About 180 verbs are irregular in standard English, and \nthere have not been any recent new ones. In contrast to the regular verbs, past forms of the \nirregular verbs are unpredictable and demand remembering. Nevertheless, they have some \npatterns such as: “keep, kept”, sleep, slept”, “feel, felt”, and “dream, dreamed”; “wear, \nwore”, “bear, bore”, “tear, tore”, and “swear, swore”; “string, strung”, “swing, swung”, \n“sting, stung”, and “fling, flung”. \nAs the number of the irregular verbs is much smaller than the number of the regular \nverbs, it is much more efficient to keep in mind exclusion (or prohibition) rules for irregular \nverbs than to remember all regular verbs. In a formal way, at first all regular forms are \ngenerated for all verbs. Then these forms for irregular verbs are excluded from the language \nby negative rules. After this specific rules for irregular verbs fill the gap. \nConstruction of languages by means of grammars with prohibition is also adequate to \nlearning processes. When an individual, a child or adult, learns some natural language, she/he \nreceives information not only what is possible to do with words, but also what operations and \nconstructions are forbidden. This situation is partially reflected in the general learning theory \nby the concept of co-learning (cf., for example, (Freivalds et al, 1994)) and learning with \npositive and negative examples. Procedures of co-learning are described by such grammars \nwith prohibition in which positive rules generate the set of all words in the given alphabet, \nwhile negative rules allow one in an inductive mode (Burgin, 2003) to get the solution of the \nproblem, i.e., to learn a given computable function.  \nHere, we consider classes of grammars with prohibition related to the Chomsky hierarchy \n(Chomsky, 1956; 1959). \n \n \n3. Chomsky hierarchy of grammars and languages \nThe Chomsky hierarchy consists of the following levels:  \n1. Type-0 grammars (unrestricted or phrase structure grammars) include all conventional \nformal grammars and generate recursively enumerable languages, i.e., languages that are \naccepted by a Turing machine. We denote the class of unrestricted grammars by G0 and \nthe class of corresponding languages by L(G0), i.e., of languages generated (computed or \nrecognized) by grammars from G0 . \n2. Type-1 grammars (context-sensitive grammars) generate the context-sensitive languages, \nwhich are exactly all languages that are accepted by a non-deterministic Turing machine \nwhose tape is bounded by a constant times the length of the input. We denote the class of \ncontext-sensitive grammars by G1 and the class of corresponding languages by L(G1). \n3. Type-2 grammars (context-free grammars) generate the context-free languages, which are \nexactly all languages that are accepted by a non-deterministic pushdown automaton. \nContext free languages are the theoretical basis for the syntax of most programming \nlanguages. We denote the class of context-free grammars by G2 and the class of \ncorresponding languages by L(G2). \n4. Type-3 grammars (regular grammars) generate the regular languages, which are exactly \nall languages that can be decided by a finite state automaton. Additionally, this family of \nformal languages can be obtained by regular expressions. Regular languages are \ncommonly used to define search patterns and the lexical structure of programming \nlanguages. We denote the class of regular grammars by G3 and the class of corresponding \nlanguages by L(G3). \nEvery regular language is context-free, every context-free language is context-sensitive \nand every context-sensitive language is recursively enumerable. All inclusions are proper. \n \n \n \n4. Grammars with prohibition related to Chomsky hierarchy \nThe class of grammars with prohibition in which the poitive grammar belongs to the class \nGi and the negaitive grammar belongs to the class Gj is denoted by Gij , while the class of \ncorresponding languages, i.e., languages generated (computed or recognized) by grammars \nfrom Gij , is denoted by L(Gij). \nThus, four types of conventional formal grammars give us 16 types of formal grammars \nwith prohibition: G00, G01, G02, G03, G10, G11, G12, G13, G20, G21, G22, G23, G30, G31, G32, G33 . \nThis gives us 16 classes of formal languages: L(G00), L(G01), L(G02), L(G03), L(G10), L(G11), \nL(G12), L(G13), L(G20), L(G21), L(G22), L(G23), L(G30), L(G31), L(G32), L(G33) . For \ninstance, L(G03) consists of all formal languages that have the form L1 \\ L2 where L1 is an \narbitrary recursively enumerable language and L2 is an arbitrary regular language. A \ngrammar G that belongs to G03 is called unrestricted\\regular grammar and the corresponding \nlanguage L(G) is called enumerable\\regular language. A grammar G that belongs to G12 is \ncalled context-sensitive\\context-free grammar and the corresponding language L(G) is called \ncontext-sensitive\\context-free language. Our goal is to find relations between these classes. \nTheorem 1.  a) For all i, j ∈ {0, 1, 2, 3}, we have L(Gij) ⊇ L(Gi). \nb) If  k > i , then L(Gij) ⊇ L(Gkj) and L(Gji) ⊇ L(Gjk). \nCorollary 1. For all i ∈ {0, 1, 2, 3}, we have L(Gii) ⊇ L(Gi). \nMany of these inclusions are proper (cf., Theorem 7) but not all. \nTheorem 2. L(G33) = L(G3). \nTo describe and compare expresional power of grammars with prohibition, we use \narithmetical hierarchy (Rogers, 1987). In it, the lowest level ΣΣΣΣ0 = ΠΠΠΠ0  consists of all \nrecursively decidable (recursive) formal languages (sets). The next level has two parts: ΣΣΣΣ1 \nconsists of all recursively computable (recursively enumerable) formal languages (sets) and  \nΠΠΠΠ1 consists of all complements of recursively computable (recursively enumerable) formal \nlanguages (sets). \nLemma 1. If LD is a decidable and LE is an enumerable language, then L = LD \\ LE is a \ncomplement to an enumerable language. \nIndeed, by properties of set-theoretical operations, L = LD \\ LE = Σ* \\ ((Σ* \\ LD) ∪ LE ). \nThen L1 = Σ* \\ LD is a decidable language and the union of two enumerable languages is an \nenumerable language, i.e. L2 = (Σ* \\ LD) ∪ LE is an enumerable language. Thus, L = Σ* \\ L2 is \na complement to the enumerable language L2. \nLemma 2. If LD is a decidable and LE is an enumerable language, then L = LE \\ LD is an \nenumerable language. \nProof is similar to the proof of Lemma1. \nTheorem 3. L(G03) = ΣΣΣΣ1 . \nProof is based on Lemma 2. \nTheorem 4. L(G30) = ΠΠΠΠ1 . \nProof is based on Lemma 1. \nThis result shows that in contrast to conventional formal grammars, formal grammars \nwith prohibition can generate non-enumerable languages. Thus, the class G30 and as we see \nbelow, G20, G10, and G00 are classes of super-recursive algorithms (Burgin, 2005). \nTheorems 1, 3, and 4 imply the following result. \nCorollary 2. L(G00) = ΣΣΣΣ1  ∪  ΠΠΠΠ1 . \nThis result shows that formal grammars with prohibition have higher expressive \n(generative) power than conventional formal grammars and Turing machines. However, \ninductive Turing machines (Burgin, 2005) can compute or accept any language generated by \na grammar with prohibition. \nCorollary 3. L(G00) = L(G03) ∪ L(G30). \nCorollary 4. L(G01) ∪ L(G10) = L(G02) ∪ L(G20) = L(G03) ∪ L(G30) . \nTheorem 5. L(G01) = ΣΣΣΣ1 . \nProof is based on Lemma 2 as all context-sensitive languages are decidable. \nTheorems 1 and 5 imply the following result. \nCorollary 5. L(G02) = L(G01) = L(G03) = L(G0) =  ΣΣΣΣ1. \nTheorem 6. L(G10) = ΠΠΠΠ1 . \nProof is based on Lemma 1 as all context-sensitive languages are decidable.. \nTheorems 1 and 6 imply the following result. \nCorollary  5. L(G20) = L(G10) = L(G30) = ΠΠΠΠ1 . \nTheorem 7.  a) L(G00) ⊃ L(G0), L(G10) ≠  L(G0), L(G20) ≠ L(G0) and L(G30) ≠ L(G0); \nb) L(G10) ≠ L(G1), L(G20) ≠  L(G2), and L(G30) ≠ L(G3); \nc) L(G32) ≠ L(G2), L(G22) ≠  L(G2), and L(G12) ≠ L(G2); \nIndeed, inequalities and inclusions from parts a and b follow from previous results and \nrelations between classes from the arithmetical hierarchy (Rogers, 1987). For c), we have \nL(G32) ⊃ Σ* \\ L(G2) and the class L(G2) of context-free languages is not closed under \noperation of difference. \nAt the same time, as the class L(G1) of context-sensitive languages is closed under \noperations of complement and intersection (Du and Ko, 2001), we have the following result. \nTheorem 8. L(G11) = L(G1). \nTheorem 9. L(G23) = L(G2). \nIndeed, if LCF is a context-free and LR is a regular language, then L = LCF \\ LR = LCF  ∩ \n(Σ* \\ LR). Here (Σ* \\ LR) is a regular language and the class L(G2) of context-free languages \nis closed under operation of intersection with regular languages (Hopcroft, et al, 2001). \nProposition 1. L(G32) is the complement of L(G2). \nProof. Let LCF be a context-free and LR be a regular language. For a subset X of Σ*, its \ncomplement is denoted by CX. Then L = LR \\ LCF  = LR ∩ (Σ* \\ LCF) = (Σ* \\ CLR ) ∩ (Σ* \\ \nLCF) = C(C(Σ* \\ CLR ) ∪ C(Σ* \\ LCF)) = C(LR  ∪ LCF) = Σ* \\ L1 where L1 is a context-free \nlanguage because the class L(G2) of context-free languages is closed under operation of \nunion (Du and Ko, 2001). \nProposition 1 is proved. \nTheorem 2. L(G32) ≠ L(G1). \nProof. Let us assume that an arbitrary context-sensitive language LCS is equal to a \ncomplement CLCF of some context-free language LCF . Then LCF  = CLCS . However, CLCS is \nalso a context-sensitive language as the class L(G1) of context-free languages is closed under \noperation of complement (Du and Ko, 2001). Moreover, as LCS is an arbitrary context-\nsensitive language, CLCS is also an arbitrary context-sensitive language. As there are context-\nsensitive languages that are not context-free, our assumption is false and theorem is proved. \n \n \nConclusion \nWe have considered grammars with prohibition that work with conventional data – \nstrings of symbols or words – and generate traditional formal languages. Relations between \nclasses of languages generated by grammars with prohibition obtained in this work, as well \nas relations between classes of languages generated by grammars with prohibition and \nclasses of languages generated by conventional formal grammars are summarized in the \ntables from the Appendix. \nHowever, grammars that work with more general objects than strings of symbols have \nbeen studied and found useful. For instance in (Murata, et al, 2001), grammars that work \nwith trees are studied and applied to formal description of XML scheme languages. Formal \ngrammars can work with arbitrary graphs and even with such complex objects as \nKolmogorov complexes (Kolmogorov, 1953). Thus, it is interesting to investigate the \nfollowing problem. \nProblem 1. Consider grammars with prohibition that work with objects that are not \nstrings and study their generative and expressive power. \nAn important peculiarity of formal grammars is that there is a correspondence between \ndefinite classes of grammars and types of abstract automata. For instance, regular grammars \ncorrespond to finite automata as they generate the class of languages. Context-free grammars \ncorrespond to pushdown automata, while unrestricted or phrase structure grammars \ncorrespond to Turing machines. This brings us to the following problem. \nProblem 2. Develop correspondence between classes of grammars with prohibition and \nclasses of automata. \nWhen classes of languages are studied and used, it is useful to know their closure \nproperties, i.e., with respect to what operations with languages they are closed and with \nrespect to what operations with languages they are not closed. This brings us to the following \nproblem.for grammars with prohibition. \nProblem 3. Study closure properties of grammars with prohibition. \nBesides, utilization of languages usually demands solving different algorithmic problems, \ne.g., whther the given language is empty or if the given word belong to the given language. \nThis brings us to the following problem.for grammars with prohibition. \nProblem 4. Study algorithmic problems of grammars with prohibition. \nHere we considered only grammars with prohibition that correspond to the Chomsky \nhierarchy. However, there are many other types and kinds of formal grammars. \nProblem 5. Study other types of grammars with prohibition, i.e., when positive and/or \nnegative part of the grammar with prohibition does not belong to the Chomsky hierarchy. \nFor instance, the most noteworthy class of grammars lying properly between context-free \nand context-sensitive grammars is the class of indexed grammars (Aho, 1968; Parchmann \nand Duske, 1986). Consequently, the languages describable by indexed grammars - namely, \nthe indexed languages - are a natural class of formal languages that form a proper superset of \nthe context-free languages and a proper subset of the context-sensitive languages. Thus, we \nhave the following problem. \nProblem 6. Study grammars with prohibition when positive and/or negative part of the \ngrammar with prohibition is an indexed grammar. \nIt is interesting to find, in particular whether the set of all indexed\\indexed languages \ncoincides with the set of all context-sensitive languages. \nIt would be also appealing to consider grammars and languages with prohibition when, at \nleast, one of the grammars is a determistic context-free grammar (Hopcroft, et al, 2001). \nAnother popular class consists of programmed grammars. When a programmed grammar \nis used to derive a string, rule order is intrinsically predetermined by the availability of \nvariables in the string under derivation. This process is generally non-deterministic because \nthere may be several candidate rules. The idea of a programmed grammar is to impose an \nextrinsic ordering of rules reflecting a certain manner in which the generation process is \nenvisaged by the composer. Thus, we have the following problem. \nProblem 7. Study grammars with prohibition when positive and/or negative part of the \ngrammar with prohibition is a programmed grammar. \nAn important class of formal grammars is formed by Boolean grammars and their \ngeneralizations (Okhotin, 2004). Thus, we have the following problem. \nProblem 8. Study grammars with prohibition when positive and/or negative part of the \ngrammar with prohibition is a Boolean grammar. \nTables in the Appendix, which represent relations between classes of languages generated \nby grammars with prohibition, leave two open problems. \nProblem 9. Is the equality L(G22) = L(G11) true? \nProblem 10. Is the equality L(G22) = L(G1) true? \n \n \nReferences \n1. Aho, A. (1968) Indexed Grammars, Journal of the ACM, 15:4, pp. 647-671 \n2. Backus, J.W. (1959) The Syntax and Semantics of the Proposed International \nAlgebraic Language, in Proceedings of the International Conference on Information \nProcessing, UNESCO, pp. 125-132 \n3. Burgin M. (2003) Nonlinear Phenomena in Spaces of Algorithms, International \nJournal of Computer Mathematics, v. 80, No. 12, pp. 1449-1476       \n4. Burgin, M. Super-recursive Algorithms, Springer, New York/Heidelberg/Berlin, 2005  \n5. Burgin, M. (2005a) Grammars with Prohibition and Human-Computer Interaction,  in \nProceedings of the Business and Industry Simulation Symposium, Society for Modeling and \nSimulation International, San Diego, California, pp. 143-147       \n6. Burgin, M. (2005b) Complexity of grammars with prohibition, Abstracts of papers \npresented to the American Mathematical Society, v.26, No. 3, pp. 459-460   \n7. Carlucci, L., Case, J. and Jain, S. (2007) Learning Correction Grammars, COLT, pp. \n203-217 \n8. Case, J. and Jain, S. Rice and Rice-Shapiro Theorems for Transfinite Correction \nGrammars, Mathematical Logic Quarterly, 28 October 2011, pp. 1-13 \n9. Chomsky, N. (1956) Three models for the description of language, IRE Transactions \non Information Theory, v. 2, pp. 113-124  \n10. Chomsky, N. (1959) On certain formal properties of grammars, Information and \nControl, v. 1, pp. 91-112 \n11. Du, D.-Z. and Ko, K.-I. Problem Solving in Automata, Languages, and Complexity, \nJohn Wiley&Sons, New York/Singapore/Toronto, 2001 \n12. Freivalds, R. Karpinski, M. and Smith, C. H. Co-Learning of Total Recursive \nFunctions, COLT, 1994, pp. 190-197 \n13. Hopcroft, J.E.,  Motwani, R., and Ullman, J.D. Introduction to Automata Theory, \nLanguages, and Computation, Addison Wesley, Boston/San Francisco/New York, \n2001 \n14. Jacobs, P.S. (1986) Knowledge structures for natural language generation, in \nProceedings of the 11th Conference on Computational Linguistics, Bonn, Germany, \npp. 554 - 559    \n15. Kolmogorov, A.N. (1953) On the Concept of Algorithm, Russian Mathematical \nSurveys, v. 8, No. 4, pp. 175-176 \n16. Martin, J. C. Introduction to Languages and the Theory of Computation, McGrow \nHill, New York/San Francisco/London, 1991 \n17. Murata, M., Lee, D. and Mani, M. Taxonomy of XML Schema Languages using \nFormal Language Theory, in Extreme Markup Languages, Montreal, Canada, August \n2001 \n18. Nowak, M., Komarova, N., and Niogi, P. (2002) Computational and Evolutionary \nAspects of Language, Nature, v. 41716, , pp. 611-617 \n19. Okhotin, A. (2004) Boolean grammars, Inf. Comput., v. 194, pp. 19-48 \n20. Parchmann, R. and Duske, J. (1986) Self-Embedding Indexed Grammars, Theor. \nComput. Sci., v. 47, No. 3, pp. 219-223  \n21. Rogers, H. Theory of Recursive Functions and Effective Computability, MIT Press, \nCambridge, Massachusetts, 1987 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAppendix \nTable 1. Relations between languages of the grammars with prohibition \n \ntype  01\n02\n03\n10\n11\n12\n13\n20\n21\n22\n23\n30\n31\n32\n33\n00 \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n⊃ \n01 \n= \n= \n= \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n02 \n= \n= \n= \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n03 \n= \n= \n= \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n10 \n≠ \n≠ \n≠ \n= \n⊃ \n⊃ \n⊃ \n=\n⊃ \n⊃ \n⊃ \n=\n⊃ \n⊃ \n⊃ \n11 \n⊂ \n⊂ \n⊂ \n⊂ \n= \n= \n= \n⊂ \n= \n⊇ \n⊃ \n⊂ \n= \n⊃ \n⊃ \n12 \n⊂ \n⊂ \n⊂ \n⊂ \n= \n= \n= \n⊂ \n= \n⊇ \n⊃ \n⊂ \n= \n⊃ \n⊃ \n13 \n⊂ \n⊂ \n⊂ \n⊂ \n= \n= \n= \n⊂ \n= \n⊇ \n⊃ \n⊂ \n= \n⊃ \n⊃ \n20 \n≠ \n≠ \n≠ \n= \n⊃ \n⊃ \n⊃ \n= \n⊃ \n⊃ \n⊃ \n= \n⊃ \n⊃ \n⊃ \n21 \n⊂ \n⊂ \n⊂ \n⊂ \n= \n= \n= \n⊂ \n= \n⊇ \n⊃ \n⊂ \n= \n⊃ \n⊃ \n22 \n⊂ \n⊂ \n⊂ \n⊂ \n⊆ \n⊆ \n⊆ \n⊂ \n⊆ \n= \n⊃ \n⊂ \n⊃ \n⊃ \n⊃ \n23 \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n= \n⊂ \n⊂ \n≠ \n⊃ \n30 \n≠ \n≠ \n≠ \n= \n⊃ \n⊃ \n⊃ \n= \n⊃ \n⊃ \n⊃ \n= \n⊃ \n⊃ \n⊃ \n31 \n⊂ \n⊂ \n⊂ \n⊂ \n= \n= \n= \n⊂ \n= \n⊃ \n⊃ \n⊂ \n= \n⊃ \n⊃ \n32 \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n≠ \n⊂ \n⊂ \n= \n⊃ \n33 \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n= \n \n \nIn this table, the pair ij means the class L(Gij) of languages generated by the grammar Gij , that is by the \ngrammar with prohibition in which the positive part is equal to Gi and the negative part is equal to Gj. The \nsymbol ⊂ (⊆) in the row ij and column kh means that the class of languages L(Gij) is included in (included \nin or equal to) the class of languages L(Gkh), while the symbol ⊃ (⊇) in the row ij and column kh means that \nthe class of languages L(Gkh) is included in (included in or equal to) the class of languages L(Gij). \n \nTable 2. Relations between languages of the grammars with prohibition and languages of the \nconventional formal grammars \n \n \n \ntype \n00 01\n02\n03\n10\n11\n12\n13\n20\n21\n22 \n23 \n30 \n31 \n32 \n33 \n0 \n⊂ \n= \n= \n= \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n≠ \n⊃ \n⊃ \n⊃ \n1 \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n= \n= \n= \n⊂ \n= \n⊇ \n⊃ \n⊂ \n= \n⊃ \n⊃ \n2 \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n= \n⊂ \n⊂ \n≠ \n⊃ \n3 \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n⊂ \n= \n \n \nIn this table, the pair ij means the class L(Gij) of languages generated by the grammar Gij , \nthat is by the grammar with prohibition in which the positive part is equal to Gi and the \nnegative part is equal to Gj.  \n \n \n \n \n \n",
  "categories": [
    "cs.FL",
    "cs.CL"
  ],
  "published": "2013-02-21",
  "updated": "2013-02-21"
}