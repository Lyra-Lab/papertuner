{
  "id": "http://arxiv.org/abs/1310.1425v1",
  "title": "A State of the Art of Word Sense Induction: A Way Towards Word Sense Disambiguation for Under-Resourced Languages",
  "authors": [
    "Mohammad Nasiruddin"
  ],
  "abstract": "Word Sense Disambiguation (WSD), the process of automatically identifying the\nmeaning of a polysemous word in a sentence, is a fundamental task in Natural\nLanguage Processing (NLP). Progress in this approach to WSD opens up many\npromising developments in the field of NLP and its applications. Indeed,\nimprovement over current performance levels could allow us to take a first step\ntowards natural language understanding. Due to the lack of lexical resources it\nis sometimes difficult to perform WSD for under-resourced languages. This paper\nis an investigation on how to initiate research in WSD for under-resourced\nlanguages by applying Word Sense Induction (WSI) and suggests some interesting\ntopics to focus on.",
  "text": "A State of the Art of Word Sense Induction: A Way Towards Word \nSense Disambiguation for Under-Resourced Languages \nMohammad Nasiruddin \nLaboratoire d’Informatique de Grenoble-Groupe d’Étude pour la Traduction Automatique/Traitement \nAutomatisé des Langues et de la Parole \nUniv. Grenoble Alpes \nmohammad.nasiruddin@imag.fr \nABSTRACT _______________________________________________________________________________________________  \nWord Sense Disambiguation (WSD), the process of automatically identifying the meaning of a \npolysemous word in a sentence, is a fundamental task in Natural Language Processing (NLP). \nProgress in this approach to WSD opens up many promising developments in the field of NLP \nand its applications. Indeed, improvement over current performance levels could allow us to \ntake a first step towards natural language understanding. Due to the lack of lexical resources it \nis sometimes difficult to perform WSD for under-resourced languages. This paper is an \ninvestigation on how to initiate research in WSD for under-resourced languages by applying \nWord Sense Induction (WSI) and suggests some interesting topics to focus on. \nRÉSUMÉ _________________________________________________________________________________________________  \nÉtat de l'art de l'induction de sens: une voie vers la désambiguïsation lexicale pour les langues \npeu dotées \nLa désambiguïsation lexicale, le processus qui consiste à automatiquement identifier le ou les \nsens possible d'un mot polysémique dans un contexte donné, est une tâche fondamentale pour \nle Traitement Automatique des Langues (TAL). Le développement et l'amélioration des \ntechniques de désambiguïsation lexicale ouvrent de nombreuses perspectives prometteuses \npour le TAL. En effet, cela pourrait conduire à un changement paradigmatique en permettant \nde réaliser un premier pas vers la compréhension des langues naturelles. En raison du \nmanque de ressources langagières, il est parfois difficile d'appliquer des techniques de \ndésambiguïsation à des langues peu dotées. C'est pourquoi, nous nous intéressons ici, à \nenquêter sur comment avoir un début de recherche sur la désambiguïsation lexicale pour les \nlangues peu dotées, en particulier en exploitant des techniques d'induction des sens de mots, \nainsi que quelques suggestions de pistes intéressantes à explorer. \nKEYWORDS: Word Sense Disambiguation, Word Sense Induction, under-resourced languages, \nlexical resources. \nMOTS-CLÉS: désambiguïsation lexicale, induction de sens, langues peu dotées, ressources \nlangagières. \n1 \nIntroduction \nWord Sense Disambiguation (WSD) is a core and open research problem in Computational \nLinguistics and Natural Language Processing (NLP), which was recognized at the beginning of \nthe scientific interest in Machine Translation (MT) and Artificial Intelligence (AI). On a variety \nof word types and ambiguities research has progressed steadily to the point where WSD \nsystems achieve relatively high levels of accuracy. \nThe goal of a WSD is to computationally assign the correct sense of a word (i.e. meaning) in \ncontext (phrase, sentence, paragraph, text) from a predefined sense inventory, when the word \nhas multiple meanings. It is a pervasive characteristic of natural language. The problem is that \nwords often have more than one meaning, sometimes fairly similar and sometimes completely \ndifferent. For example, the word bank has several senses and may refer to the edge of a river, \na building, or a financial institution. The specific sense intended is determined by the textual \ncontext in which an instance of the ambiguous word appears. In “The boy leapt from the bank \ninto the cold water.” the edge of a river is intended, whereas in “The van pulled up outside the \nbank and three masked men got out.” the building sense is meant, while in “The bank sent me \na letter.” implies the financial institution sense. \nHuman readers have the capability to understand the meaning of a word from its context, but \nmachines need to process textual information and transform it into data structures, which \nmust then be analyzed in order to determine the underlying meaning. To perform WSD, a \nsense inventory must be available, which lists possible senses for the word of a text. A sense \ninventory is a lexical resource, which contains list of senses of a given word like the traditional \ndictionaries – knowledge resources. Manually annotated corpora with either word senses or \ninformation from knowledge sources is also an important resource for WSD. \nInitially, WSD was mainly applied and developed on English texts, because of the broad \navailability and the prevalence of lexical resources compared to other languages. Due to the \nlack of lexical resources i.e. sense inventories (dictionaries, lexical databases, wordnets, etc.) \nand sense-tagged corpora it is difficult to start working on WSD for under-resourced \nlanguages (Bangla, Assamese, Oriya, Kannada, etc.). To account for under-resourced \nlanguages, one can easily adopt techniques aimed at the automatic discovery of word senses \nfrom text, a task called Word Sense Induction (WSI). \nLanguages with large amounts of data, or funding, or political interests can be interpreted as \n‘well-resourced’ languages, whereas, a lot of languages in the world do not enjoy this status, \nwhich is referred to in this article as ‘under-resourced’ languages. This paper presents the \nstate of the art of WSD and WSI in an under-resourced language perspective. In the following \nsections the paper is organized as follows: firstly, Sections 2 and 3 illustrate the main topics of \ninterest in WSD and WSI respectively; then, Section 4 briefly describes WSI from an under-\nresourced language view; and finally, Section 5 concludes the article and discusses some \nperspectives for future work. \n2 \nWord Sense Disambiguation \nDepending on the degree of polysemy, there can be many different senses for a word and WSD \nalgorithms aim at choosing the most appropriate sense combination among all possible senses \nfor all words in a text unit (sentence, paragraph, etc.). It is essentially a task of classification \nfor word of a text: word senses are the possible classes, the context provides evidence \n(features), and each occurrence of a word is assigned to one or more of its possible classes \nbased on the evidence. There are many methods to perform WSD. In this section, various \ntypes of approaches and algorithms for WSD will be briefly presented. \nThe reader can refer to (Ide and Véronis, 1998) for works before 1998 and (Agirre and \nEdmonds, 2006), (Navigli, 2009) or (McCarthy, 2009) for a complete and current state of the \nart of WSD. \n2.1 \nApproaches \nWSD approaches can be categorized into supervised WSD and unsupervised WSD, and a \nfurther distinction can be made between knowledge-rich and knowledge-poor approaches \n(Navigli, 2009). Knowledge-rich methods involve the use of external knowledge sources \nwhereas knowledge-poor methods do not. Based on machine learning techniques, researchers \ndistinguish between supervised methods and unsupervised methods. There are three \nmainstream approaches to WSD, namely: Supervised WSD, Minimally-supervised WSD, and \nUnsupervised WSD. Figure 1 presents various WSD methods according to two axis: the \nquantity of annotated corpora required vertically and the amount of static knowledge \nhorizontally. \n \n \n \n \n \n \n \n \nFIGURE 1 – Word Sense Disambiguation systems – Data versus Knowledge (Schwab, 2013 \n[personal notes]). \n2.1.1 \nSupervised WSD \nSupervised WSD uses supervised machine learning techniques. These approaches use a set of \nmanually labeled training examples (i.e., sets of examples encoded as vectors whose elements \nrepresent features) to train a classifier for each target word. Support Vector Machines (SVMs), \nand memory-based learning have been shown to be the most successful approaches (Hoste et \nal., 2002; Decadt et al., 2004; Mihalcea et al., 2004; Grozea, 2004; Chan et al., 2007; Zhong and \nNg, 2010), to date, probably because they can cope with the high-dimensionality of the feature \nspace. \nSupervised algorithms are progressively losing ground to the other methods. Moreover, they \ncannot easily be adapted to other languages without retraining (requires annotated data from \nthat particular language). Furthermore, reusing models from one language for another leads \nat best to a poor classification performance (Khapra et al., 2009). \n2.1.2 \n Minimally-supervised WSD \nMinimally supervised methods use a sense inventory, a few sense-annotated example \ninstances, and raw corpora. From the sense-annotated examples, the system induces the \nsenses or categories of senses for the non-annotated data, and then it functions exactly as an \nunsupervised clustering approach. The most prominent Minimally supervised method \n(Yarowsky, 1995), however, to our knowledge, has not been evaluated on SemEval WSD tasks. \n2.1.2.1 \nKnowledge-based WSD \nKnowledge-based WSD algorithms are similar to Minimally-supervised WSD approaches. The \nobjective of Knowledge-based methods is to exploit static knowledge resources, such as \ndictionaries, thesauri, glossaries, ontologies, collocation etc., to infer the senses of words in \ncontext. Degree (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010) or Personalized \nPageRank (Agirre and Soroa, 2009) are among the latest knowledge-based systems in the \nliterature that exploits WordNet (Fellbaum, 1998) or other resources like BabelNet (Navigli \nand Ponzetto, 2010) to build a semantic graph and use the structural properties of the graph. \nIn order to choose the appropriate senses of words knowledge-based systems use the \nstructural properties of the graph in context either locally to the input sentence or globally. \n2.1.3 \nUnsupervised WSD \nUnsupervised learning is the greatest challenge for WSD researchers. Unsupervised WSD \napproaches are composed of Word Sense Induction or discrimination techniques aimed at \ndiscovering senses automatically based on unlabeled corpora and then applying them for \nWSD. By opposition to Supervised WSD, these approaches use machine learning techniques on \nnon-sense-tagged corpora with no a priori knowledge about the task at all (see Section 4). \n2.2 \nEvaluation \nThe evaluation of previous WSD algorithms is expressed in terms of the number of “correctly” \ndisambiguated words as evaluated through a Gold Standard (GS). Since 1998, there have been \nseveral follow-up evaluation campaigns (Senseval-1 (Kilgarriff, 1998), Senseval-2 (Edmonds \nand Cotton, 2001), Senseval-3 (Mihalcea and Edmonds, 2004), SemEval-2007 (Navigli et al., \n2007), SemEval-2010 (Agirre et al., 2010), SemEval-2012 (Manandhar and Yuret, 2012), and \nrecently SemEval-2013 (Navigli et al., 2013)) with various disambiguation and semantic \nanalysis tasks, which have been very successful and beneficial to the progress of the field. \nIn the evaluation task, a reference corpus is given with the lemmatized and part of speech \n(PoS) tagged instances (i.e. words), which will have to be disambiguated. The results are \nmatched with the GS through Precision (P), Recall (R), and F1 score, which are the standard-\nmeasures for evaluating WSD algorithms (Navigli, 2009). The evaluation tools provided \ncalculate: \n- P, the number of correct answers provided over the total number of answers provided; \n- R, the number of correct answers provided over the total number of expected answers; \n- F1 measure, the harmonic mean between the two: (2.P.R)/(P+R). \nWhen all words are annotated by a WSD algorithm, then P=R=F1. \n3 \nWord Sense Induction \nWord sense induction (WSI) is the task of automatically identifying the senses of words in \ntexts, without the need of handcrafted resources or manually annotated data. It is an \nunsupervised WSD technique use machine learning methods on raw corpora without relying \non any external resources such as dictionaries or sense-tagged data. During the learning \nphase, algorithms induce words senses from raw text by clustering word occurrences \nfollowing the Distributional Hypothesis (Harris, 1954; Curran, 2004). This hypothesis was \npopularized with the phrase “a word is characterized by the company it keeps” (Firth, 1957). \nTwo words are considered semantically close if they co-occur with the same neighboring \nwords. As a result, shifting the focus away from how to select the most suitable senses from an \ninventory towards how to automatically discover senses from a text. By applying WSI it is \npossible to mitigate the Knowledge Acquisition Bottleneck (Wagner, 2008) problem. The \nsingle common thread to WSI methods is the reliance on clustering algorithms used on the \nwords in the unannotated corpus. Although the role of WSI, in a disambiguation context is to \nbuild a sense inventory that can be used subsequently for WSD, therefore WSI can be \nconsidered as part of WSD. Of course, WSI can have many more applications than building \nsense inventories and thus WSD. \n3.1 \nApproaches \nWSI algorithms extract the different senses of word following two approaches – locally and \nglobally. Local algorithms discover senses of a word per-word basis i.e. by clustering its \ninstances in contexts according to their semantic similarity, whereas global algorithms \ndiscovers senses in a global manner i.e. by comparing and determining them from the senses \nof other words in a full-blown word space model (Apidianaki and Van de Cruys, 2011). Based \non the type of clustering algorithms used, will be reviewed various WSI proposed in the \nliterature in the following subsections. \n3.1.1 \nClustering Approaches \nReturning to the idea of (Harris, 1954; Curran, 2004) that word meaning can be derived from \ncontext, (Pantel and Lin, 2002) discover word senses from text. The underlying hypothesis of \nthis approach is that words are semantically similar if they appear in similar documents, \nwithin similar context windows, or in similar syntactic contexts (Van de Cruys, 2010). Lin’s \nalgorithm (Lin, 1998) is a prototypical example of word clustering, which is based on \nsyntactic dependency statistics between words that occur in a corpus to produce sets for each \ndiscovered sense of a target word (Van de Cruys and Apidianaki, 2011). By using a similarity \nfunction, the following clustering algorithms are applied to a test set of word feature vectors \n(Pantel and Lin, 2002): K-means, Bisecting K-means (Steinbatch et al., 2000), Average-link, \nBuckshot, and UNICON (Lin and Pantel, 2001). Clustering By Committee (CBC) (Pantel and \nLin, 2002) also uses syntactic contexts intended for the task of sense induction, but exploits a \nsimilarity matrix to encode the similarities between words. It relies on the notion of \ncommittees to output the different senses of the word of interest. However, These approaches \nare hard to apply on a large scale for many domains and languages. \n3.1.2 \nExtended-clustering Approaches \nConsidering the observation that words tend to manifest one sense per collocation (Yarowsky, \n1995), (Bordag, 2006) uses word triplets instead of word pairs. A well-known approach to \nextended-clustering is the Context-group Discrimination algorithm (Schütze, 1998) based on \nlarge matrix computation methods. Another approach, presented by (Pinto et al., 2007), \nattempts to improve the usability of small, narrow-domain corpora through self-term \nexpansion. (Brody and Lapata, 2009) shows that the task of word sense induction can also be \nframed in a Bayesian context by considering contexts of ambiguous words to be samples from \na multinomial distribution. There are other extended-clustering approaches, that include the \nbi-gram clustering technique proposed by (Schütze, 1998), the clustering technique using \nphrasal co-occurrences presented by (Dorow and Widdows, 2003), the technique for word \nclustering using a context window presented by (Ferret, 2004) and the method applying the \nInformation Bottleneck algorithm for sense induction proposed by (Niu et al., 2007). These \nadditional clustering techniques can be broadly categorized as either improving feature \nselection and enriching features or introducing more effective and efficient clustering \nalgorithms. \n3.1.3 \nGraph-based Approaches \nThe main hypothesis of co-occurrence graphs is assuming that the semantic of a word is \nrepresented by means of co-occurrence graph, whose vertices are co-occurrences and edges \nare co-occurrence relations. These approaches are related to word clustering methods, where \nco-occurrences between words can be obtained on the basis of grammatical (Widdows and \nDorow, 2002) or collocational relations (Véronis, 2004). (Klapaftis and Manandhar, 2007) \npropose the idea of the Hypergraph model for such WSI approaches. HyperLex (Véronis, \n2004) is a successful graph based algorithm, based on the identification of hubs in co-\noccurrence graphs that have to cope with the need to tune a large number of parameters \n(Agirre et al., 2006b). To deal with this issue several graph-based algorithms have been \nproposed, which are based on simple graph patterns, namely Curvature Clustering (Dorow et \nal., 2005), Squares, Triangles and Diamonds (SquaT++) (Navigli, 2010), and Balanced \nMaximum Spanning Tree Clustering (B-MST) (Di Marco et al., 2011). The patterns aim at \nidentifying word meanings using the local structural properties of the co-occurrence graph. A \nrandomized algorithm which partitions the graph vertices by iteratively transferring the \nmainstream message (i.e. word sense) to neighboring vertices proposed by (Biemann, 2006) \nis Chinese Whispers. By applying co-occurrence graph approaches, (Agirre et al., 2006a; \nAgirre and Soroa, 2007; Korkontzelos and Manandhar, 2010) have been able to achieve state \nof the art performance in standard evaluation tasks. (Jurgens, 2011) reinterpret the challenge \nof identifying sense speciﬁc information in a co-occurrence graph as one of community \ndetection, where a community is deﬁned as a group of connected nodes that are more \ninterconnected than to the rest of the graph (Fortunato, 2010). Recently, (Hope and Keller, \n2013) introduced a linear time graph-based soft clustering algorithm for WSI named MaxMax, \nwhich obtains comparable results with those of systems based on existing, state of the art \nmethods. \nTABLE 1 – Overview of Techniques for Word Sense Induction (Denkowski, 2009). \n Latent Semantic Analysis (LSA) (Landauer and Dumais, 1997; Landauer et al., 1998) is \ncurrently a very popular approach to WSI that operates on word spaces (Van de Cruys and \nApidianaki, 2011). LAS aims at finding and extract latent dimensions of meaning using NMF \n(Non-negative Matrix Factorization), PCA (Principal Component Analysis) or SVD (Singular \nValue Decomposition). The extracted latent dimensions are then used to distinguish between \n \nBasic Word Co-occurrence \nAdditional Features \nClassical Clustering Algorithms \nClassical Clustering \nTriplet Clustering \nSelf-term Expansion \nContext Clustering \nTranslation Features \nNovel Algorithms for WSI \nClustering by Committee (CBC) \nInformation Bottleneck \nHypergraph \nCollocation Graph \nBayesian Model \ndifferent senses of a target word that are in turn used to disambiguate each given instance of \nthat word. \n3.1.4 \nTranslation-oriented Approaches \nWSI approaches described above cover only monolingual data; in the context of Machine \nTranslation (MT), recent work has been done to incorporate bilingual data into the sense \ninduction task. Translation-oriented WSI approaches involve augmenting the source language \ncontext with target language equivalents. (Apidianaki, 2008) describes this process by using a \nbilingual corpus that has been word aligned by type and token to construct two bilingual \ndictionaries, where each word type is associated with its translation equivalent. The lexicon is \nfiltered such a way that words and their translation equivalents have matching PoS tags and \nwords appear in the translation lexicons for both directions. \n3.2 \nEvaluation \nThe evaluation of WSI approaches is one of the key challenges for researchers. As the sense \nclusters derived by these algorithms may not match the actual senses deﬁned in lexical \nresources like dictionaries, lexical databases, wordnets, etc., the evaluation of these \nalgorithms needs to be carried out manually, by asking language experts to corroborate the \nresults. However, it is hard to evaluate the results of WSI, as the resulting clustered senses can \nvary from algorithm to algorithm or even for various parameter values for a single algorithm, \nas even determining the number of clusters a difficult matter. From the very beginning of WSI, \ndepending on different approaches researchers have developed various evaluation \nmethodologies that can be separated into three main categories. \n3.2.1 \nSupervised Evaluation \nIn this evaluation method, the target word corpus is divided into two parts – a testing and a \ntraining part. Firstly, the training part is used to map the automatically induced clusters to \nGold Standard (GS) senses. In the next step, the test corpus is used to evaluate WSI \napproaches in a WSD (Agirre and Soroa, 2007) setting. Finally, the usual Precision (P) and \nRecall (R) are used to determine the quality of the resulting WSD. \n3.2.2 \nUnsupervised Evaluation \nIn this evaluation setting, the induced senses are evaluated as clusters of examples, and \ncompared to sets of examples that have been tagged with sense labels from a Gold Standard. \nThe V-measure (Rosenberg and Hirschberg, 2007) is used to determine the quality of clusters \nby combining metrics such as the Paired F-Score (Manandhar et al., 2010), the RandIndex \n(Rand, 1971; Navigli, 2010) and others. They measure both the coverage and the homogeneity \nof a clustering output as opposed to the traditional clustering measure of F-Score (Zhao et al., \n2005) that is most commonly used to assess the performance of WSI systems. \n3.2.3 \nEvaluation as an Application \nRecently, (Navigli and Crisafulli, 2010; Di Marco and Navigli, 2013) proposed to evaluate WSI \napproaches as part of a specific application, where WSI techniques have been shown to \nconsistently surpass symbolic state of the art systems (See section 4.3). The evaluation of WSI \nand WSD systems was performed in the context of Web search result clustering. \n3.3 \nSemEval WSI Evaluation Tasks \nThis section briefly describes the different SemEval workshops (from 2007 to 2013) with WSI \nevaluation tasks that focus on the evaluation of semantic analysis systems. \n3.3.1 \nSemEval-2007 Task 2 \nThe goal of SemEval-2007 Task 2 (Agirre and Soroa, 2007) is to allow for the comparison \nacross sense-induction and discrimination systems, and also to compare these systems to \nother supervised and knowledge-based systems. This task evaluates WSI systems on 33 nouns \nand 65 verbs (lexical sample), where the corpus consists of texts of the Wall Street Journal \n(WSJ) corpus, and is hand-tagged with OntoNotes senses (Hovy et al., 2006). For each tagged-\nword, the task consists of first identifying the senses of target words (e.g. as clusters of target \nword instances, co-occurring words, etc.), and secondly tagging the instances of the target \nword using the automatically induced clusters. This double evaluation methodology (i.e. \nsupervised evaluation and unsupervised evaluation) has been attempted by (Agirre et al., \n2006a). \n3.3.2 \nSemEval-2010 Task 14 \nSemEval-2010 Task 14 is a continuation of the WSI SemEval-2007 Task 2 with some \nsignificant changes to the evaluation setting. The main difference in this task compared to the \nSemEval-2007 WSI task, is that the training and testing data are treated separately, which \nallows for a more realistic evaluation of the clustering models. Readers may refer to (Klapaftis \nand Manandhar, 2013) for a detailed analysis of the SemEval-2010 WSI task evaluation result \nand new evaluation settings. \n3.3.3 \nSemEval-2013 Task 11 \nFor the evaluation in SemEval-2013: Task 11, WSI and WSD systems are applied to web \nsearch result clustering, where the test data consists of 100 topics (all nouns), each with a list \nof 64 top-ranking documents. The topics were selected from the list of ambiguous Wikipedia \nentries (i.e., those with \"disambiguation\" in the title) among queries of lengths ranging \nbetween 1 and 4 words. The 64 snippets associated with each topic were collected from the \nresults provided by the Google search engine. Three annotators tagged each snippet with the \nmost appropriate meaning from Wikipedia, with adjudication in the case of disagreement. For \na detailed description of the SemEval-2013: Task 11 evaluations please refer to (Di Marco and \nNavigli, 2013; Navigli and Vannella, 2013). \n4 \nWSI for Under-Resourced Languages \nGiven the above-mentioned difficulties, WSI is an attractive alternative to WSD, especially for \nunder-resourced languages. \nThe Figure 2 shows an overview of the state of freely available resources for a certain number \nof representative languages and the aim of the diagram is to give the reader an idea of the \ncurrent situation. Making a highly precise diagram would be prohibitively complex and \nfurthermore, the position of the various languages must be interpreted relatively to each \nother rather than in an absolute manner (except for English that we placed in the top right-\nhand corner as a reference). \n \n \n \n \n \n \n \n \n \nFIGURE 2 – Computationally language richness – Data versus Knowledge (Schwab, 2013 \n[personal notes]). \nAs described previously, two kinds of resources are difficult/expensive to build: annotated \ncorpora and lexical databases (static versus dynamic knowledge). While lexical databases can \nbe used directly in many applications or by humans, sense-annotated corpora have less \napplications and are much more expensive to build. An automatic procedure can extract the \nsenses that are objectively present in a particular corpus and allows for the sense inventory to \nbe straightforwardly adapted to a new domain. By applying WSI, it is practical to \ndisambiguate particular word instances using the automatically extracted sense inventory. \nWords and contexts are mapped to a limited number of topic dimensions (depending on the \ntopic of the words and contexts) in a latent semantic word space. A particular sense is \nassociated with a particular topic and different senses can be discriminated through their \nassociation with particular topic dimensions. (Van de Cruys and Apidianaki, 2011) describe \nthe induction step and disambiguation step as being based on the same principle. \nCurrently, Wikipedia contains 285 languages, anyone can generate corpus from a Wikipedia \ndump, or blogs, forums, newspaper articles in any language. As WSI is a kind of clustering \nproblem, the evaluation of the clusters is normally difficult, however if the evaluation process \nis followed, it becomes rather straightforward. Though semantic evaluation campaigns are \nbased on some dominant languages, progress for under-resourced languages is still ongoing. \nIn this regard, Crowdsourcing (Sabou et al., 2012), especially Games With A Purpose (von \nAhn, 2006) are considered as an attractive alternative for collecting annotated data (Wang et \nal., 2010), which can be subsequently used as a GS for evaluating the systems. \n5 \nConclusion and Discussions \nThe state of the art of Word Sense Disambiguation followed by Word Sense Induction \ntechniques for under-resourced languages are provided in this article, and also tries to \nprovide a basic idea of the essentials of the field. Here, the authors show a way to work on \nWSD by using WSI approaches in an unsupervised way, where very few resources (like \ncorpora) are available. Basically, the performance of WSD systems depends heavily on which \nsense inventory is chosen, here WSI overcomes this issue by allowing unrestrained sets of \nsenses. Besides, its evaluation is particularly hard because there is no easy way of comparing \nand ranking different representations of senses. \nAcknowledgements \nThe work presented in this paper was conducted in the context of the VideoSense project, \nfunded by the French National Research Agency (ANR) under its CONTINT 2009 program \n(grant ANR-09-CORD-026). \nReferences \nAGIRRE, E., LOPEZ DE LACALLE, O., AND SOROA, A. (2009). Knowledge-Based WSD on Specific \nDomains: Performing Better than Generic Supervised WSD. In Proceedings of the 21st Int’l \nJoint Conference on Artificial Intelligence (IJCAI), pp. 1501– 1506. California. \nAGIRRE, E., MARTINEZ, D., LOPEZ DE LACALLE, O., AND SOROA, A. (2006a). Two Graph-Based \nAlgorithms for State of the Art WSD. In Proceedings of the Conference on EMNLP, pp. 585-593. \nAGIRRE, E., MARTÍNEZ, D., LÓPEZ DE LACALLE, O. AND SOROA, A. (2006b). Evaluating and Optimizing \nthe Parameters of an Unsupervised Graph-Based WSD Algorithm. In Proceedings of \nTextGraphs: the 2nd Workshop on Graph Based Methods for NLP, pp. 89–96. New York, USA. \nAGIRRE, E. AND SOROA, A. (2007). SemEval-2007 Task 2: Evaluating Word Sense Induction and \nDiscrimination Systems. In Proceedings of the 4th Int’l Workshop on SemEval-2007, pp. 7–12. \nAGIRRE, E. AND SOROA, A. (2009). Personalizing PageRank for Word Sense Disambiguation. In \nProceedings of the 12th Conference of the EACL 2009, pp. 33–41. Athens, Greece. \nAGIRRE, E., LOPEZ DE LACALLE, O., FELLBAUM, C., HSIEH, S.K., TESCONI, M., MONACHINI, M., VOSSEN, P. \nAND SEGERS, R. (2010). SemEval-2010 Task 17: All-Words Word Sense Disambiguation on a \nSpecific Domain. In Proceedings of the 5th Int’l Workshop on Semantic Evaluation, pp. 75–80. \nAPIDIANAKI, M. (2008). Translation-Oriented Word Sense Induction Based on Parallel Corpora. \nIn Proceedings of the 6th Int’l Conference on Language Resources and Evaluation. Morocco. \nAPIDIANAKI, M. AND VAN DE CRUYS, T. (2011). A Quantitative Evaluation of Global Word Sense \nInduction. In Proceedings of the 12th Int’l Conference on Intelligent Text Processing and \nComputational Linguistics (CICLing-2011), pp. 253–264. Tokyo, Japan. \nBALDWIN, T., KIM, S., BOND, F., FUJITA, S., MARTINEZ, D. AND TANAKA, T. (2010). A Reexamination of \nMRD-Based Word Sense Disambiguation. In ACM Transactions on Asian Language Information \nProcessing (TALIP) 9, pp. 4:1–4:21. ACM. \nBIEMANN, C. (2006). Chinese Whispers – An Efﬁcient Graph Clustering Algorithm and Its \nApplication to Natural Language Processing Problems. In Proceedings of the TextGraphs: the \nFirst Workshop on Graph Based Methods for Natural Language Processing, pp. 73–80, USA. \nBORDAG, S. (2006). Word Sense Induction: Triplet-Based Clustering and Automatic Evaluation. \nIn Proceedings of the 11th Conference of the EACL 2006, pp. 137–144. Trento, Italy. \nBRODY, S. AND LAPATA, M. (2009). Bayesian Word Sense Induction. In Proceedings of the 12th \nConference of the EACL 2009, pp. 103–111. Athens, Greece. \nCHAN, Y.S., NG, H.T. AND ZHONG, Z. (2007). NUS-PT: Exploiting Parallel Texts for Word Sense \nDisambiguation in the English All-Words Tasks. In Proceedings of the 4th Int’l Workshop on \nSemantic Evaluations (SemEval-2007), pp. 253–256. Prague, Czech Republic. \nCURRAN, J. R. (2004). PhD Thesis: From distributional to semantic similarity. University of \nEdinburgh. Edinburg, UK. \nDECADT, B., HOSTE, V., DAELEMANS, W. AND VAN DEN BOSCH, A. (2004). GAMBL, Genetic Algorithm \nOptimization of Memory-Based WSD. In Proceedings of the 3rd Int’l Workshop on the \nEvaluation of Systems for the Semantic Analysis of Text, pp. 108–112. Barcelona, Spain. \nDENKOWSKI, M. (2009). A Survey of Techniques for Unsupervised Word Sense Induction. In \nLanguage & Statistics II Literature Review. \nDI MARCO, A. AND NAVIGLI, R. (2011). Clustering Web Search Results With Maximum Spanning \nTrees. In Proceedings of the 12th Int’l Conference of the Italian Association for AI, pp.201–212. \nDI MARCO, A. AND NAVIGLI, R. (2013). Clustering and Diversifying Web Search Results with \nGraph-Based Word Sense Induction. In Computational Linguistics 39(4), pp. 201–212. MIT. \nDOROW, B. AND WIDDOWS, D. (2003). Discovering Corpus-Specific Word Senses. In Proceedings \nof the 10th Conference of the European Chapter of the Association for Computational \nLinguistics (EACL 2003), pp. 79–82. Budapest, Hungary. \nDOROW, B., WIDDOWS, D., LING, K., ECKMANN, J., SERGI, D. AND MOSES, E. (2005). Using Curvature and \nMarkov Clustering in Graphs for Lexical Acquisition and Word Sense Discrimination. In \nProceedings of the MEANING-2005 Workshop. \nEDMONDS, P. AND COTTON, S. (2001). SENSEVAL-2: Overview. In Proceedings of the 2nd Int’l \nWorkshop on Evaluating Word Sense Disambiguation Systems, pp. 1-5. France. \nFELLBAUM, C. (ED.) (1998). WordNet: An Electronic Database. MIT Press. Cambridge, M.A, USA. \nFERRET, O. (2004). Discovering Word Senses from a Network of Lexical Cooccurrences. In \nProceedings of the 20th Int’l Conference on Computational Linguistics, pp. 1326–1332. \nFIRTH, J.R. (1957). A synopsis of linguistic theory 1930-1955. In Studies in Linguistic Analysis \n(Oxford: Philological Society), pp. 1–32. Reprinted in Palmer, F.R., (ed.) (1968). Selected \nPapers of J.R. Firth 1952-1959. London: Longman. \nFORTUNATO, S. (2010). Community Detection in Graphs. In Physics Reports 486, pp. 75–174. \nGROZEA, C. (2004). Finding Optimal Parameter Settings for High Performance Word Sense \nDisambiguation. In Proceedings of the 3rd Int’l Workshop on the Senseval-3, pp. 125–128. \nHARRIS, Z. (1954). Distributional Structure. In Papers in Structural and Transformational \nLinguistics, pp. 775–794. \nHOPE, D. AND KELLER, B. (2013). MaxMax: A Graph-Based Soft Clustering Algorithm Applied to \nWord Sense Induction. In Proceedings of the Int’l Conference on Intelligent Text Processing \nand Computational Linguistics (CICLing-2013), pp. 368–381. Samos, Greece. \nHOSTE, V., HENDRICKX, I., DAELEMANS, W. AND VAN DEN BOSCH, A. (2002). Parameter Optimization \nfor Machine-Learning of Word Sense Disambiguation. In Natural Language Engineering 8(04), \npp. 311–325. Cambridge University Press. \nHOVY, E., MARCUS, M., PALMER, M., RAMSHAW, L. AND WEISCHEDEL, R. (2006). OntoNotes: The 90% \nSolution. In Proceedings of the Human Language Technology Conference of the North \nAmerican Chapter of the Association for Computational Linguistics, pp. 57–60. USA. \nIDE, N. AND VÉRONIS, J. (1998). Introduction to the special issue on word sense disambiguation: \nthe state of the art. In Computational Linguistics 24(1), pp. 02–40. Cambridge, MA, USA. \nIDE, N., ERJAVEC, T. AND TUFIS, D. (2002). Sense Discrimination with Parallel Corpora. In \nProceedings of ACL-02 Workshop on Word Sense Disambiguation, pp. 61–66. USA. \nJABBARI, S., HEPPLE, M. AND GUTHRIE, L. (2010). Evaluation Metrics for the Lexical Substitution \nTask. In Proceedings of the Human Language Technology Conference of the North American \nChapter of the Association for Computational Linguistics, pp. 289–292. California, USA. \nJIN, P., WU, Y. AND YU, S. (2007). SemEval-2007 Task 05: Multilingual Chinese-English Lexical \nSample. In Proceedings of the 4th Int’l Workshop on Semantic Evaluations (SemEval-2007), \npp. 19–23. Prague, Czech Republic. \nJURGENS, D. (2011). Word Sense Induction by Community Detection. In Proceedings of the 49th \nAnnual Meeting of the Association for Computational Linguistics Human Language \nTechnologies (ACL HLT 2011), pp. 24–28. Portland, Oregon, USA. \nKHAPRA, M.M., SHAH, S., KEDIA, P., AND BHATTACHARYYA, P. (2009). Projecting Parameters for \nMultilingual Word Sense Disambiguation. In Proceedings of the Conference on Empirical \nMethods in Natural Language Processing (EMNLP-09), pp. 459—467. Singapore. \nKHAPRA, M.M., KULKARNI, A., SOHONEY, S. AND BHATTACHARYYA, P. (2010). All Words Domain \nAdapted WSD: Finding a Middle Ground Between Supervision and Supervision. In Proceedings \nof the 48th Annual Meeting of the Association for Computational Linguistics, pp. 1532–1541. \nKILGARRIFF, A. (1998). SENSEVAL: An Exercise in Evaluating Word Sense Disambiguation \nPrograms. In Proceeding of the 1st Int’l Conference on Language Resources and Evaluation \n(LREC 1998), pp. 581—588. Granada, Spain. \nKLAPAFTIS, I.P. AND MANANDHAR, S. (2007). UoY: A Hypergraph Model for Word Sense Induction \nand Disambiguation. In Proceedings of the 4th Int’l Workshop on Semantic Evaluations \n(SemEval-2007), pp. 414–417. Prague, Czech Republic. \nKLAPAFTIS, I.P. \nAND MANANDHAR, S. (2013). Evaluating Word Sense Induction and \nDisambiguation Methods. In Language Resources and Evaluation, pp. 1–27.  Springer. \nKOELING, R., MCCARTHY, D. AND CARROLL, J. (2005). Domain-Specific Sense Distributions and \nPredominant Sense Acquisition. In Proceedings of the Human Language Technology \nConference and the Conference on Empirical Methods in NLP, pp. 419–426. B.C., Canada. \nKORKONTZELOS, I. AND MANANDHAR, S. (2010). UoY: Graphs of Unambiguous Vertices for Word \nSense Induction and Disambiguation. In Proceedings of the 5th Int’l Workshop on Semantic \nEvaluation (SemEval-2010), pp. 355–358, Uppsala, Sweden. \nLANDAUER, T.K. AND DUMAIS, S.T. (1997). A Solution to Plato’s Problem: The Latent Semantic \nAnalysis Theory of Acquisition, Induction, and Representation of Knowledge. In Psychology \nReview (104), pp. 211–240. \nLANDAUER, T., FOLTZ, P. AND LAHAM, D. (1998). An Introduction to Latent Semantic Analysis. In \nDiscourse Processes, pp. 25: 284–295. \nLIN, D. (1998). Automatic Retrieval and Clustering of Similar Words. In Proceedings of the \n17th Int’l Conference on Computational Linguistics, pp. 768–774. Quebec, Canada. \nLIN, D. AND PANTEL, P. (2001). DIRT–Discovery of Inference Rules from Text. In Proceedings of \nthe 7th ACM SIGKDD Int’l Conference on Knowledge Discovery and Data Mining, pp. 323–328. \nMANANDHAR, S., KLAPAFTIS, I.P., DLIGACH, D. AND PRADHAN, S.S. (2010). SemEval-2010 Task 14: \nWord Sense Induction & Disambiguation. In Proceedings of the 5th Int’l Workshop on \nSemantic Evaluation (SemEval-2010), pp. 63–68. Uppsala, Sweden. \nMANANDHAR, S. AND YURET, D. (2012). SemEval-2012: Semantic Evaluation Exercises. In \nProceedings of the SemEval-2012: Semantic Evaluation Exercises. Montreal, Canada. \nMCCARTHY, D. AND NAVIGLI, R. (2009). The English Lexical Substitution Task. In Language \nResources and Evaluation 43(2), pp. 139–159. Springer. \nMIHALCEA, R. AND EDMONDS, P. (2004). Senseval-3: The Third Int’l Workshop on the Evaluation \nof Systems for the Semantic Analysis of Text. In Proceedings of Senseval-3: The 3rd Int’l \nWorkshop on the Evaluation of Systems for the Semantic Analysis of Text. \nMIHALCEA, R. AND FARUQUE, E. (2004). Senselearner: Minimally Supervised Word Sense \nDisambiguation for All Words in Open Text. In Proceedings of ACL/SIGLEX, pp. 155–158. \nNAVIGLI, R. (2009). Word Sense Disambiguation: A Survey. In ACM Computing Surveys (CSUR) \n41(2), pp. 1–69. ACM. \nNAVIGLI, R. AND CRISAFULLI, G. (2010). Inducing Word Senses to Improve Web Search Result \nClustering. In Proceedings of the Conference on Empirical Methods in Natural Language \nProcessing (EMNLP-10), pp. 116–126. Boston, USA. \nNAVIGLI R., JURGENS, D. AND VANNELLA, D. (2013). SemEval-2013 Task 12: Multilingual Word \nSense Disambiguation. In Proceedings of the 7th Int’l Workshop on Semantic Evaluation, the \n2nd Joint Conference on Lexical and Computational Semantics, pp. 116–126. Atlanta, GA, USA. \nNAVIGLI, R. AND LAPATA, M. (2010). An Experimental Study on Graph Connectivity for \nUnsupervised Word Sense Disambiguation. In IEEE Transactions on Pattern Analysis and \nMachine Intelligence 32(4), pp. 678–692. IEEE. \nNAVIGLI, R., LITKOWSKI, K.C. AND HARGRAVES, O. (2007). SemEval-2007 Task 07: Coarse-Grained \nEnglish All-Words Task. In Proceedings of 4th Int’l Workshop on SemEval-2007, pp. 30–35. \nNAVIGLI, R. AND PONZETTO, S.P. (2010). BabelNet: Building a Very Large Multilingual Semantic \nNetwork. In Proceedings of the 48th Annual Meeting of the Association for Computational \nLinguistics (ACL 2010), pp. 216–225. Uppsala, Sweden. \nNAVIGLI, R. AND VANNELLA, D. (2013). SemEval-2013 Task 11: Word Sense Induction & \nDisambiguation within an End-User Application. In Proceedings of the 7th Int’l Workshop on \nSemantic Evaluations (SemEval-2013). Atlanta, GA, USA. \nNIU, Z., JI, D. AND TAN, C. (2007). I2R: Three Systems for Word Sense Discrimination Chinese \nWord Sense Disambiguation and English Word Sense Disambiguation. In Proceedings of the \n4th Int’l Workshop on Semantic Evaluations, pp. 177–182. Prague, Czech Republic. \nPANTEL, P. AND LIN, D. (2002). Discovering Word Senses from Text. In Proceedings of the 8th \nInt’l Conference on Knowledge Discovery and Data Mining, pp. 613–619. Canada. \nPINTO, D., ROSSO, P. AND JIMENEZ-SALAZAR, H. (2007). UPV-SI: Word Sense Induction Using Self-\nTerm Expansion. In Proceedings of 4th Int’l Workshop on Semantic Evaluations, pp. 430–433. \nPONZETTO, S.P. AND NAVIGLI, R. (2010). Knowledge-Rich Word Sense Disambiguation Rivaling \nSupervised System. In Proceedings of the 48th Annual Meeting of the Association for \nComputational Linguistics (ACL 2010), pp. 1522–1531. Uppsala, Sweden. \nRAND, W. M. (1971). Objective Criteria for the Evaluation of Clustering Methods. In Journal of \nthe American Statistical Association 66(336), pp. 846–850. Taylor & Francis. \nROSENBERG, A. AND HIRSCHBERG, J. (2007). V-Measure: A Conditional Entropy-Based External \nCluster Evaluation Measure. In Proceedings of the Conference on Empirical Methods in \nNatural Language Processing and Computational Natural Language Learning, pp. 410–420. \nSABOU, M., BONTCHEVA, K. AND SCHARL, A. (2012). Crowdsourcing Research Opportunities: \nLessons from Natural Language Processing. In Proceedings of the 12th Int’l Conference on \nKnowledge Management and Knowledge Technologies, pp. 17:1–17:8. \nSCHÜTZE, H. (1998). Automatic Word Sense Discrimination. In Computational Linguistics 24(1), \npp. 97–124. MIT Press. \nSTEINBACH, M., KARYPIS, G., AND KUMAR, V. (2000). A Comparison of Document Clustering \nTechniques. In Proceedings of the 6th ACM SIGKDD Int’l Conference on Knowledge Discovery \nand Data Mining, pp. 525–526. Boston, USA. \nVAN DE CRUYS, T. AND APIDIANAKI, M. (2011). Latent Semantic Word Sense Induction and \nDisambiguation. In Proceedings of the 49th Annual Meeting of the Association for \nComputational Linguistics: Human Language Technologies, pp. 1476– 1485. Oregon, USA. \nVAN DE CRUYS, T. (2010). PhD Thesis: Mining for Meaning – the Extraction of Lexico-Semantic \nKnowledge from Text. University of Groningen, pp. 12–18. The Netherlands. \nVÉRONIS, J. (2004). Hyperlex: Lexical Cartography for Information Retrieval. In Computer \nSpeech and Language 18(3), pp. 223–252. \nVON AHN, L. (2006). Games With A Purpose. In Computer 6(39), pp. 92–94. IEEE Computer \nSociety Press. \nWAGNER, C. (2006). Breaking the knowledge acquisition bottleneck through conversational \nknowledge management. In Information Resources Management Journal (IRMJ) 19(1), pp. \n70–83. IGI Global. \nWANG, A., HOANG, C.D.V. AND KAN, M.Y. (2004). Perspectives on Crowdsourcing Annotations for \nNatural Language Processing. In Language Resources and Evaluation, pp. 1–23. Springer. \nWIDDOWS, D. AND DOROW, B. (2002). A Graph Model for Unsupervised Lexical Acquisition. In \nProceedings of the 19th Int’l Conference on Computational Linguistics, pp. 1–7. \nYAROWSKY, D. (1995). Unsupervised Word Sense Disambiguation Rivaling Supervised Methods. \nIn Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics \n(ACL 1995), pp. 189–196. Cambridge, Massachusetts, USA. \nZHAO, Y., KARYPIS, G., AND FAYYAD, U. (2005). Hierarchical Clustering Algorithms for Document \nDatasets. In Data Mining and Knowledge Discovery, 10(2), pp. 141–168. The Netherlands. \nZHONG, Z. AND NG, H.T. (2010). It Makes Sense: A Wide-Coverage Word Sense Disambiguation \nSystem for Free Text. In Proceedings of the 48th Annual Meeting of the Association for \nComputational Linguistics (ACL 2010), pp. 78–83. Uppsala, Sweden. \n",
  "categories": [
    "cs.CL",
    "68T50",
    "I.2.7"
  ],
  "published": "2013-10-05",
  "updated": "2013-10-05"
}