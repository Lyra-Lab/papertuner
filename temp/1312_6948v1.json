{
  "id": "http://arxiv.org/abs/1312.6948v1",
  "title": "Description Logics based Formalization of Wh-Queries",
  "authors": [
    "Sourish Dasgupta",
    "Rupali KaPatel",
    "Ankur Padia",
    "Kushal Shah"
  ],
  "abstract": "The problem of Natural Language Query Formalization (NLQF) is to translate a\ngiven user query in natural language (NL) into a formal language so that the\nsemantic interpretation has equivalence with the NL interpretation.\nFormalization of NL queries enables logic based reasoning during information\nretrieval, database query, question-answering, etc. Formalization also helps in\nWeb query normalization and indexing, query intent analysis, etc. In this paper\nwe are proposing a Description Logics based formal methodology for wh-query\nintent (also called desire) identification and corresponding formal\ntranslation. We evaluated the scalability of our proposed formalism using\nMicrosoft Encarta 98 query dataset and OWL-S TC v.4.0 dataset.",
  "text": "Description Logics based Formalization of Wh-Queries \nSourish Dasgupta \nDA-IICT, India \nsourish_dasgupta \n@daiict.ac.in \n \n       Rupali KaPatel \n        DA-IICT, India \n       rupali.it.08 \n      @gmail.com \n \n   Ankur Padia \n     DA-IICT, India \n  padiaankur \n    @gmail.com \n \n \n \nKushal Shah  \nDA-IICT, India \nkushalshah40 \n@daiict.ac.in  \nABSTRACT \nThe problem of Natural Language Query Formalization (NLQF) is \nto translate a given user query in natural language (NL) into a \nformal language ( ) so that the   semantic interpretation has \nequivalence with the NL interpretation. Formalization of NL \nqueries enables logic based reasoning during information \nretrieval, database query, question-answering, etc. Formalization \nalso helps in Web query normalization and indexing, query intent \nanalysis, etc. In this paper we are proposing a Description Logics \nbased formal methodology for wh-query intent (also called desire) \nidentification and corresponding formal translation. We evaluated \nthe scalability of our proposed formalism using Microsoft Encarta \n98 query dataset and OWL-S TC v.4.0 dataset.  \nCategories and Subject Descriptors \nI.2.4 [Knowledge Representation Formalism and Methods]: \nRepresentation (procedural and rule-based)  \nGeneral Terms \nTheory, Measurement, Performance. \nKeywords \nQuery Formalization, Description Logics, Semantic Web. \n1. INTRODUCTION \nNatural Language Query Formalization (NLQF) is a formal and \nsystematic procedure of translating a user query in natural \nlanguage into an expression in a formal language without losing \nthe semantics of the user query. The choice of a formal language \ncan range from SQL used in conventional DBMS to more \nadvanced SPARQL for RDF graph based databases designed to \nsupport the Semantic Web. However, any translation process \ninvolves rigorous linguistic analysis of NL queries and \nconstructing a formal semantic interpretation that is equivalent to \nthe original query semantics. NLQF has a twofold effect. First, it \nhelps in proper identification of the query intent (also called \ndesire). Secondly, it formally defines the query intent in relation \nto other linguistic constituents of the query thereby providing a \nplatform for logical reasoning based semantic information \nretrieval and question answering [1-2]. The biggest challenge \ninvolved in NLQF is to efficiently and accurately identify the \ninnate desire and to understand the linguistic nuances during a \ntranslation process. A query may bear the same semantic content \nbut may be structurally different. For an example, the query: \"Who \nis the greatest crime novel writer?\" is semantically equivalent to \nthe query: \"What is the name of the greatest author of crime \nnovel?\". It may also have the same grammatical structure but bear \ndifferent semantics.  \nNLQF has been a topic of intensive research in the database \ncommunity. Most of the effort was concentrated in translating NL \nqueries into formal representations suitable for database retrieval \nsuch as SQL [3-4]. More recent researches have shown a growing \ninterest in mining graph databases represented in RDF-like \nformat. As a result several works have been proposed to translate \nNL query into SPARQL-like formalism [5-7, 18]. However, many \nof these works support at the most shallow lexico-syntactic query \nanalysis extracting heuristic patterns which are then translated into \nSPARQL like queries. Many other approaches are ontology based \nwhere an external set of ontologies are required for mapping \nquery tokens to the most probable formal concept (mostly \nRDF/RDFS/OWL represented) so as to link together the mapped \ntokens into a formal semantic graph structure (such as SPARQL, \nnRQL) [5-6, 18]. The graph structure is then matched with similar \ngraphical representations of document content for query \nanswering. However, ontology assisted NLQF heavily depends on \nthe correctness and completeness of the external ontologies and \nmay not be very accurate if the target information source is \nindependent of the imported ontology set. Moreover, such RDF \ndatabases are nothing more than very  light-weight knowledge \nbases with no high-end reasoning support required for knowledge \ndiscovery. Hence, if the target corpus is a formal knowledge base \nthen SPARQL cannot serve as a suitable formal query language. \nOther distributional hypothesis [8] based purely statistical \napproaches has also been proposed mostly for NL query \nprocessing which can hardly fall under NLQF [9-11]. One of the \nintrinsic problems of statistical approaches is that query goal (or \ndesire/intention) detection is very difficult if linguistic analysis is \nignored. Also information retrieval largely depends on similarity \nmeasure models that are mostly token co-occurrence based [12-\n13]. Such co-occurrence analysis cannot guarantee semantic \nsimilarity with the query goal. \nIn this paper we propose a deep linguistic analysis based semantic \nformalization framework for NL wh-queries in English. DL \nrepresentation of queries provides the support to perform formal \nsubsumption based reasoning over DL based knowledgebase for \nknowledge discovery. We show that such queries can be neatly \ncharacterized \ninto \na \nsyntactic \nstructure, \ncalled \nQuery \nCharacterization Template (QCT), covering most possible \nlinguistically valid query variations. The primary aim of QCT is \nto identify the query desire and the relationship of the desire with \nthe query input. This leads to the next step of accurate query \nformalization. However, such characterization is non-trivial and \ninvolves capturing positional nuances of query tokens correctly. \nWe also show that a Description Logic (DL) [25] sub-language \nexists that has semantic equivalency with that of wh-queries. We \nhave presented the salient rules for NL query to DL query \ntranslation. The proposed methodology is independent of any \nexternal ontology assistance. The scope of this paper is limited to \nwh- queries of six kinds: (i) what, (ii) which, (iii) who, (iv) when, \n(v) where, and (vi) non-procedural how. Our contribution in this \npaper is as follows: \nTable 11 \n \n1. \nA novel query desire-input dependency analysis theory, \ntermed QCT, is proposed. \n2. \nProposing DL has a suitable candidate formal semantic \ntheory for query formalization. \n3. \nEvaluation in terms of characterization accuracy using \nMicrosoft Encarta query dataset and query dataset built on \nOWL-S TC v.4.0 dataset. \nThe paper is organized into the following sections: (i) related \nwork outlining some of the major contributions in NL query \nprocessing, (ii) problem statement defining the problem of NLQF \nformally, (iii) Approach where query characterization and DL \n                                                                 \n1 NLQP: Natural Language Query Processing; FL: Formal \nLanguage; L-SPL: Lexico-Syntactic Pattern Learning; C. Voc.: \nControlled Vocabulary; PTr.: Parse Tree; Ann.: Annotation; \nDB: Database; Ont.: Ontology; Lex: Lexicon; Corps: Corpus; \nL.A.: Linguistic Analysis; Sem.: Semantic \n2 proposed DL based framework \nformalization has been discussed at length, and (iv) Evaluation in \nterms of characterization accuracy. \n2. RELATED WORKS \nVarious approaches for NL Query Formalization can be broadly \nclassified into two main categories: (i) statistical learning based \nanalysis, and (iii) lexico-syntactic analysis. Table 1 is an overview \nof various approaches for developing NLQP systems. We have \ncategorized them on the basis of various parameters which \ndifferentiate them. One of those parameters is query nature which \ncan be of two types: (i) restricted (R NL), and (ii) unrestricted \n(UR NL). Restricted NL based systems cannot accept queries of \nall linguistics forms and hence, provide query formulation only \nfor NL queries that can be given through some sort of controlled \nvocabulary. Ontology aided systems import external ontologies as \ninput for aiding NL queries into their respective formal \nrepresentations. Lexicon aided systems use lexicons (or thesauri) \nfor enriching NL query vocabulary which in turn aids in \nnormalized query formalization. By target corpus we mean the \nresource from which the answer is expected. We see that systems \nin this respect can be either NL document corpus based or \nontology based.  \nIn [10] author has tried to detect goal (i.e. desire) from the user’s \nNL query using Tree-Augmented Naive Bayes networks (TANs) \nfor goal detection but this work is domain specific and semantic \nvalues are compromised here. In [14] a conversion tool which \ntakes queries expressed in NL and an ontology as input and \nreturns the appropriate formal queries. It uses WordNet to \ndisambiguate the words and triple based model for formalization.  \nThe generated queries are then sent to the reasoner for querying \nthe knowledge bases. In this work ontology to be queried is \nrequired to be chosen by user and it doesn’t support complex \nquery formulation. In [15] an approach to Semantic Information \nRetrieval of semantically annotated documents, based on NL \nunderstanding of query, has been proposed. This work \nincorporates an OWL query ontology for SPARQL based \ninference. In [16] a nested CG (Conceptual Graph) language for \nformal representations of natural language queries has been \nproposed. In [17] a formal semantic analysis of object queries  \nrequired for the modern object-oriented databases has been \nproposed. Unlike other object query languages, a number of \nrealistic features including object identity, object creation and \ninvocation of methods that need not terminate has been covered. \nA translation procedure from NL query into a formal language \nquery such as SPARQL has been described in [18]. In this paper a \nuser query is translated into SPARQL by choosing the most \nappropriate query from the prepared queries. Queries for the \nknowledge base and a set of corresponding normalized queries for \nthe problem has been prepared beforehand and user’s query is \nmapped to one of query which is obtainable from the knowledge \nbase. For relatively large knowledge base such WWW this may \nnot be scalable approach. In [19] models of DP services as RDF \nviews over a mediated (domain) ontology has been proposed. \nEach RDF view contains concepts and relations from the \nmediated ontology to capture the semantic relationships between \ninput and output parameters. Query rewriting algorithms for \nprocessing queries over DP services and query mediator which \nautomatically transforms a user’s query (during the query \nrewriting stage) into a composition of DP services. \nSTART [20] was the first online question-answering system which \nuses statistical NLP techniques and lexico-syntactic pattern \nmatching. Another system called NLP-Reduce [21] was proposed \nwhich is also based on lexico-syntactic pattern matching. In this \nNLQP \nSystem \nNLQ \nType \nFL \nOnt. \nAided \nLex. \nAided \nTarget \nCorps \nL.A. \n[10] \nUR  \nNo \nNo \nNo \nATIS  \nTAN \nLASSO \n[9] \nUR  \nKey-\nword \nbased \npatter\nns \nNo \nWord \nNet \nNL docs \nL-\nSPL \nAquaLog \n[7] \nR  \nC.Voc \nTriple \nbased \n \nYes \nWord \nNet \nSem. \nmark-up \ndocs \nNo \nPower-\nAqua \n[24] \nUR  \nTriple \nbased \n \nYes \nmany \nWord \nNet \nDistr. \nsem. \ndocs \nNo \nQuerix \n[6] \nUR  \nTriple \nbased \nSPAR\nQL \nYes \nWord \nNet \nSelected \nset of \nOnt. \nL-\nSPL \nPANTO \n[5] \nUR  \nTriple \nbased \nSPAR\nQL \nYes \nWord \nNet \nOnt. \nPOS \nTAG \n \n[23] \nUR  \n     \nDL \nbased \nYes \nNA \nOnt. \nPOS \nTAG \nMasque/ \nSQL \n[3] \nR  \nSQL  \nNo \nNo \nRDBMS \nPTr. \nPRECISE \n[4] \nUR  \nSQL  \nNo \nfrom \nDB \nATIS  \nPTr. \nSTART \n[21] \nUR  \nNL \nAnn. \nbased \nNo \nMIT \nLexico\nn \nWeb  \ncorpus \nL-\nSPL \nQCT \nbased2 \nUR  \nDL \nbased \nNo \n     \nWord \nNet \nNL docs \nPOS \nTAG \nsystem query keywords are mapped with synonym enhanced triple \nstores in the target corpus. A key feature was that user queries can \nbe phrases or complete queries and also need not be \ngrammatically correct. A domain-independent system, called \nQuerix, was proposed in [6] where full English questions had to \nbe given which were then parsed for extracting triple patterns. \nThese triples are extracted out of a prior query skeleton which is \ngenerated based on word categories. These triple patterns are then \nmapped onto the target knowledge base for match. A guided input \nNL search engine, called Ginseng, was proposed in [22].  \n3. PROBLEM OVERVIEW  \n \nThe problem of NLQF involves 3 core tasks: \nTask 1: To choose a formal grammar   that can generate the \ndependency structure (ex: parse tree) of the linguistic components \nof a given NL query accurately. \nTask 2: To select a formal language    that has an \ninterpretation    such \nthat \nthere \nexists \na \none \nto \none \ncorrespondence with the semantic interpretation of the formal \ngrammar  . \nTask 3: To model a representational equivalence function \n    that takes in a query Q in     and maps it to an expression   \nin    such that maximum semantic preservation is achieved. Such \nsemantic preservation can be achieved through model-theoretic \nsemantic constructions.      should be consistent and should not \ngenerate expressions that are mutually inconsistent. \nTask 1 involves syntactic parsing of all valid NL queries. This is a \nchallenging task since NL queries can be of varied forms with (a) \nsimilar syntactic structures but different semantics (ex: \"Where is \nthe capital of Florida?\" - Answer: \"28.5N, 81.3W\" vs. \"What is \nthe capital of Florida?\" - Answer: \"Orlando\") and (b) similar \nsemantics but different syntactic structures (ex: \"Where is the \ncapital of Florida?\" vs. \"What is Orlando's location?\" - Answer \nfor both: \"28.5N, 81.3W\"). In the former case the queries should \nbe characterized such that they have their corresponding formal \nlanguage translation unique while in the latter case both the \nqueries should have the same normalized formal language \ntranslation. Moreover, queries may not always be simple (i.e. no \nclausal constraint; ex: \"Who are Alexandar's favorite Greek \nmythological heroes?\") but can be complex (ex: \"Who are the \nheroes of Greek mythology who were Alexander's favorite?\") and \ncompound (\"Who are the heroes of Greek mythology and \nAlexander?\"). Although structurally the queries are simple, \ncomplex and compound yet semantically they are the equivalent. \nHence, they should have the same answer: \"Achilles\". This \nrequires accurate part-of-speech tagging (POS tagger) and parse \ntree generation based on which a given NL query is fitted into a \nchosen characterization grammar.  \nTask 2 consists of translation of the parsed queries into a formal \nlanguage representation (usually the model-theoretic style). Just \nlike task 1 formal translation is also not trivial since it involves: (i) \nresolution of several ambiguities and linguistic nuances including \nre-formulation and normalization of semantically equivalent NL \nqueries having different structures, (ii) computational query \nresolution (ex: \"How far is New York from Orlando?\"), (iii) \ncomparative/superlative query resolution (ex: \"What is the highest \nmountain in Asia?\"). The scope of this paper is limited to the wh-\nqueries of the kinds: (i) what/which, (ii) who/whom/whose, (iii) \nwhere, (iv) when, and (v) how much.  \n3.1 Problem Definition \nGiven an NL wh-query    \n    in English model a transformation \nfunction     such that: \n \n        \n      \n   \n \n    \n   \n        \n   \n    \nwhere: \n \n   \n   is the formalization of    \n   in the formal language   \n \n    is the linguistic reading of English \n \n    is the semantic interpretation function of    \n4. APPROACH \n4.1 Characterization (Task 1) \nAny user query has two primary linguistic components - (i) desire \n(or intent) of the query and (ii) input of the query. While the query \ndesire is essentially what an answer needs to satisfy, the query \ninput provides the satisfiability constraint on the desire. For an \nexample, in the query: \"What is the capital of USA?\" while the \ndesire is an instance of the entity Capital, the input is USA acts as \na constraint imposed on the instance relating it to USA (and not \njust any other country/province). For task 1 (described in section \n3.1) choosing a formal grammar theory serves as a basis for \ngenerating the parse tree of a query. Constructing semantics by \napplying a particular semantic theory over complicated (although \nsophisticated) parse trees is computationally expensive. We \nobserved that since our chosen semantic theory is Description \nLogics (DL), where concepts are defined in terms of roles and \ntheir associations with other concepts (thus, forming subject-\npredicate-object triples), the primary objective of query parsing \nshould be to identify the desire (which is the subject of the query), \npredicate, and input (which is the object of the query). Hence, a \nfull-fledged parse tree is not necessary for the case. We developed \na pseudo-grammar structure, called Query Characterization \nTemplate (QCT), that captures the intrinsic desire-input \ndependency structure in all forms of English factual queries \n(simple, complex, and compound). This dependency generates a \nunique QCT for each of the three forms. QCT is a pseudo-\ngrammar in several senses: (i) the sequence of the lexicons of the \noriginal query can get changed after the characterization process, \n(ii) lexicons can get normalized into a standard form after \ncharacterization, and (iii) it does not give a generic set of rules to \ncombine or split phrase structures but rather \"fits in\" queries of \nequivalent grammatical structure into one fixed template. We \nhereby define the wh-query and its three forms of as follows: \nDefinition 1 (Wh-Query): A Wh-Query is a query that contains at \nleast one of the following query tokens (or their equivalent lexical \nvariations): what, which, who, whose, whom, when, where, how, \nwhy.  \nWhat query can be: (i) definitional such as \"What is a cat?\" \n(expected answer: class definition), (ii) inclusion such as \"What \nanimals are mammals?\" (expected answer: sub classes of \nmammal); (iii) instance retrieval such as \"What is the capital of \nUSA?\" (expected answer: a city instance), (iv) class retrieval such \nas \"What is Taj Mahal?\" (expected answer: class of instance Taj \nMahal), and (v) instance associated concept retrieval such as \n\"What does John drink in the morning?\" (expected answer: sub \nclasses of drink that John has for morning).  \nWhich query is similar to What queries except that such queries \ncannot be definitional.  \nWho query behaves sometimes as a Which query and sometimes \nas a What query with the special underpinning that the expected \nanswer is related to either a named animal, or a person (or person \ngroup/organization).  \nWhen query can be: (i) absolute temporal such as \"When is \nThanksgiving?\" (expected answer: a particular day of a month), \nand (ii) relative temporal such as \"When will John arrive?\" \n(expected answer can be: after/before some event).  \nWhere query can be: (i) absolute spatial such as \"Where is the \nleaning tower of Pisa?\" (expected answer: geographical location), \nand (ii) relative spatial such as \"Where is the ball?\" (expected \nanswer can be: on/under/below/at some object).  \nHow query can be: (i) procedural such as \"How is a flan \nmade?\"(expected answer: recipe or step-wise set of actions), (ii) \nstate based such as \"How is Joe?\" (expected answer: current \nhealth status of Joe), (iii) quantitative such as \"How much does the \nbag cost?\" (expected answer: price), or (iv) computational such as \n\"How far is Tampa from Miami?\" (expected answer: computed \ndistance). We do not consider procedural how in the scope of this \npaper. \nWhy query is causal in nature such as \"Why is the grass green?\". \nWe also leave out why queries from the scope of this paper.  \nDefinition 2 (Simple Wh-Query): A Simple Wh-Query is a wh-\nquery that consists of a single and non-clausal query desire \n(explicit or implicit) and a single, unconstrained, and explicit \nquery input. \nExample simple wh-query is \"What is the capital of USA?\". In this \ncase the desire (Capital) is explicit, single, and unconstrained by \nany clausal phrase. The input (USA) is also explicit, single, and \nunconstrained by any clausal phrase. It should be noted that, as \nremarked earlier, the input is an implied constraint over the desire \nwhich is different than clausal constraint. Also, the desire may be \nimplicit sometimes. For an example, in the query: \"What is a \ntomb?\" the implicit desire is the definition of Tomb (i.e. \ndescription of the class Tomb) while the unconstrained and single \ninput is Tomb.  \nDefinition 3 (Complex Wh-Query): A Complex Wh-Query is a \nwh-query that consists of a single query desire (explicit or \nimplicit) and multiple explicit query input. \nDefinition 4 (Complex Non-Clausal Wh-Query): A Complex \nNon-Clausal Wh-Query is a complex wh-query that is clausal \nconstraint free on both the query desire and the multiple query \ninput. \nExample complex non-clausal query is \"In which country is the \nstate capital of Missouri located?\". In this query the desire \nCountry is unconstrained. There are two input (State Capital and \nMissouri) each of which is also unconstrained.  \nDefinition 5 (Complex Clausal Wh-Query): A Complex Clausal \nWh-Query is a complex wh-query that consists of at least one \nclausal constraint on either the query desire or query input or both. \nExample complex clausal wh-query is \"Who was the British Prime \nMinister who was elected two times one of which was during \nWorld War II?\". In this query the single explicit desire is the \n(instance of the) class British Prime Minister having no clausal \nconstraint. There are two query input: two times and World War \nII. Also, the first input two times has a clausal constraint \"one of \nwhich was during …\".  \nDefinition 6 (Compound Query Wh-Query ): A Compound Wh-\nQuery is a wh-query that consists of conjunctive/disjunctive \nlexicons between one or more simple wh-queries or complex wh-\nqueries.  \nExample of compound wh-query is “What are the available car \nmodels of Volkswagen and their respective prices?”. In the \nfollowing sub-sections the QCT of each of the three forms of \nsentences has been discussed at length.  \n4.1.1 QCT of Simple Wh-Query \nA simple wh-query can be characterized according to the \nfollowing structure:  \n                                                        \n where: \n  \n  : second square bracket indicates optional component \n   : Query desire class/instance - value restricted to {NN, NNP, \nJJ, RB, VBG}3 \n   : Query input class/instance - value restricted to {NN, NNP, JJ, \nRB, VBG} \n    : Auxiliary relation - includes variations of the set {is, is kind \nof, much, might be, does} \n    :  Relation that acts as (i) predicate of D as the subject and I \nas the object or (ii) action role of I as the actor - value restricted to \n{VB, PP, VB-PP}1 \n      : Quantifier of D or I - values restricted to {DT}1. The * \nindicates that Q can recur before D or I. \n      : Modifier of D or I - value restricted to set {NN, JJ, RB, \nVBG}. The * indicates that M can recur before D or I. \nWe can observe that this QCT can cover all the linguistically valid \n180 questions (excluding quantifiers and modifiers) according to \nthe given definition of simple wh-query.    is auxiliary role in the \nsense that it cannot act as a predicate of either the D or the I. \nHowever,    serves as a good indicator for resolving several \nlinguistic ambiguities. For an example, in a how query if    is \nmuch (or its lexical variations) then it is a quantitative query while \nin a who query if    is does (or its lexical variations) then the \nassociated verb is an activity (i.e. Gerund; ex: \"Who does \nsinging?\" - Singing is an activity in this case). \n   is a relation that can either be associated with D as the subject \nor I as the subject but not both. If    is positioned after D in the \noriginal query then    s subject is D. For an example, in the \nsimple query \"What is the capital of USA?\" the subject of    (of) \nis D (Capital) and the object is I (USA). If    is positioned after I \nin the original query then its subject is I. For an example, in the \nquery \"Which country is California located in?\" the subject of    \n(located in) is I (California) and object is D (Country). Table 2 \nlists some of the important simple wh-query characterization.  \n4.1.1.1 Implicit Desire Identification \nImplicit query desire implies that D is empty. This can happen if \nand only if the following query structures are found: \n1. \n               \n   \n                    \n                                                                 \n3 Abbreviations follow the conventions of Penn Treebank POS \ntags. [30] \nTable 2 \nNatural Language \nWh-Simple Query \nWh-Simple Query Characterization \nWhat is the capital \nof Gujarat? \n     = 'What',     = 'is',     = 'the \ncapital',      = 'of',     = 'Gujarat', [?] \nWhich is the highest \nmountain in world? \n     = 'Which',     = 'is',     = 'the \nhighest mountain',     = 'in',     = \n'world', [?] \nHow many legs does \na millipede have? \n    ='How many',     = count('legs'), \n    = 'does have',     = 'millipede', [?] \nWhat \nare \nsome \ndangerous plants? \n     = \n'What', \n     = \n'are',    = \n'dangerous plants', [?] \nWhere \nis \nCalifornia? \n     = 'Where',      = 'is',     = \n'California', [?] \n \nTable 3 \nWhat is most populous \ndemocracy \nin \nthe \nCaribbean \nwhich \nis \ngeographically \nthe \nlargest as well? \n    =what,    =is,   =the_most_p\nopulous_democracy, \n    =in,   \n   =the_Caribbean, \n       =which, \n      =is,    \n    = \ngeographically_the_largest? \nWhat is the distance \nbetween Missouri and \nTexas? \n    =what,    =is    =the_distance\n,     =null,  =between, \n   \n   =Misssouri, \n    =and,    \n   =Texas? \n \n2. \n     \n   \n                            \n3. \n          \n                            \nIf    does not exist then D is empty. If    does not exist while \n   exists then D is empty. For an example, in the query: \"What is \nconverted into diamond?\"    is identified to be is by default and \n   is detected to be is converted into. However, there is no \nlexicon in between    and    (structure 3). Therefore, D is empty. \nAnother case in which D always remains empty is when the wh-\nquery is a where or a when query. This also holds true for \ncomplex and compound queries. For an example, in the query: \n\"When is the next solar eclipse?\" the query characterization is as: \n                                                            \n4.1.1.2 Explicit Desire Identification \nAs an extension to the observation the previous section we can \nconclude that any lexicon between    and    is D. For an \nexample, in the simple query \"What is the capital of USA?\"    is \nidentified to be is and    is detected to be of. Therefore, D is \nCapital. After D is identified the remaining lexicon is I.    \n4.1.2 QCT of Complex Wh-Query \nA complex Wh-query can be characterized according to4:  \n                                    \n             \n        \n                   \n             \n        \n                        \n             \n           \n                                                                 \n4 Modifiers and quantifiers are not associated with D and I. They \nare associated in exactly the same way as QCT of simple \nqueries. \nTable 4 \nNatural \nlanguage \nCompound  Wh-Query \nCompound \nWh-Query \nCharacterization \nWhat happens when you \nmix \npotassium \npermanganate \nand \nglycerin? \n     =what,   \n  =null,   \n  =happ\nens(implicit \nactivity),    \n  =when,    \n  =mix,\n    \n  =potassium \npermanganate,    =and,   \n  = \nglycerine,      =null?  \nHow long will an electric \ncar run and how fast can it \ngo? \n     =Howlong,   \n  =will,   \n  =c\nount(implicit), \n    \n  =null,    \n  =mix,    \n  =potassi\num permanganate,    =and,   \n  = \nglycerine? \nWhat is shape and size of \nbaloon when air comes \nout? \n     =What,   \n  =is,   \n  =shape,\n    =and,   \n  =size, \n    \n  =null,   \n  =of,   \n  =baloon,\n     \n  =when, \n    \n  =comes_out,   \n  =air,     =\nnull? \nWhat \nis \nthe \ntravelling \ncharge to Bombay and \nhotel_rent in Bombay? \n     =What,   \n  =is,   \n  =the_tra\nvelling_charge, \n    =and,   \n  =hotel_rent,    \n  =n\null,   \n  =in,   \n  =bombay \n,     =null? \nWho were the foremost \nauthorities in discovering \nalgebraic \nformulas, \ntheorems, \nand/or \nexpressions? \n     =Who,   \n  =were,   \n  =the_f\noremost_authorities, \n    \n  =null,   \n  =in_discoverying,\n   \n  =,algebraic_formulas,      \n       \n   theorems      \n   ,    \n  = \nexpressions,     =null? \nWhich volcanoes are active \nand which is which ones \nare dormant? \n     =Which   \n  =null,   \n  =volc\nanoes, \n    \n  =null,   \n  =are_active,   \n  =,n\null,         \n     =Which   \n  =null,   \n  =volc\nanoes, \n    \n  =null,   \n  =dormant,   \n  =,nul\nl? \n \nwhere: \n   : clausal lexicon (constraining D) \n   : second clausal lexicon (constraining I1)  \n   : clausal lexicon associated with structure     \n             \n       \n     : conjunctive/disjunctive lexicon for I \n    : query desire - value restricted to {NN, NNP, JJ, RB, VBG} \n   \n   : l-th query input k-th  structure - value restricted to {NN, \nNNP, JJ, RB, VBG} \n      : relation associated with the k-th clause that acts as (i) \npredicate of D as the subject and I as the object or (ii) action role \nof I as the actor - value restricted to {VB, PP, VB-PP} \n      : modifier of the D or the I - value restricted to set {NN, JJ, \nRB, VBG}. The * indicates that M can recur before D or I. \nIn this QCT we see  the possible repetition of the structure \n    \n             \n     . Within this structure there is an optional sub-\nstructure           \n      that may add to the number of input \nwithin each of such structures. A clausal lexicon in a complex \nclausal wh-query is always associated with such a structure. The \nnumber of clausal lexicons is the same as the number of such \nstructures in a given query. It should be noted that there must be at \nleast two such structures for a query to qualify as complex. Also, \nclausal lexicons in the general case is optional and hence, the \nQCT also holds true for complex non-clausal wh-query. We name \nthe following structure as clausal structure (CS): \n                  \n             \n        \n                   \n             \n        \n                        \n             \n          \nExample complex query characterization is given in table 3. The \ngiven QCT can cover 1800 linguistically valid complex queries \n(excluding quantifiers and modifiers). \n4.1.3 QCT of Compound Wh-Query \nA compound Wh-query can be characterized according to:  \n          \n       \n            \n                \n     \n            \n       \n            \n                \n     \n              \n       \n            \n                  \nwhere: \n      : Conjunctive/disjunctive lexicon for D  \n      : Conjunctive/disjunctive lexicon for wh-sub-query \nCompound query characterization example has been given in table \n4. \n4.2 DL as Formal Query Language (Task 2) \nIn our approach we choose the formal language   to be \nDescription Logics (DL). As mentioned earlier we argue that most \nfactual IS-A sentences have expressive equivalency in the DL \nlanguage:                      where: \n    Attributive Language – supports atomic concept definition, \nconcept intersection, full value restriction, limited role restriction, \nand atomic concept negation. \n     Union – supports concept union \n     Existential – supports full role restriction \n     Complement – supports concept negation \n     Role Hierarchy – supports inclusion axioms of roles \n   : Nominal – supports concept creation of unrecognized Named \nEntity \n   : Role Inversion - supports inverse roles  \n( ): Data Type – supports range concepts to be data type \nThe choice of DL over other semantic theories has several \nreasons: (i) DL is equivalent to the guarded    fragment of FOPL \nand hence, is decidable [25], (ii) DL representation is compact and \nvariable-free as compared to representations such as DRS [26] \nand LFT [27] making it comparatively easy to parse, (iii) the DL \nsub-language                      is tractable since we \nobserved that most IS-A sentence interpretation is covered by \n              , (iv) highly optimized semantic tableau based \nDL reasoners [28] are available as compared to slower hyper-\nresolution based theorem provers used in DRS or LFT based \nreasoning, (v) DL has direct mapping with the W3C \nrecommended OWL format for web ontology5. Expressions in DL \ncan represent two types of queries: (i) general queries such as \n\"What is a synagogue?\" (answer is a T-Box definition or inclusion \naxiom in the knowledgebase), and (ii) specific queries such as \n\"What is the name of the highest mountain in Australia?\" (the \nanswer is an A-Box assertion in the knowledgebase).  \n4.3 DL Formalization (Task 3) \nAs mentioned in the previous section, NL queries can be of two \ntypes in the context of DL: (i) T-Box queries and (ii) A-Box \nqueries. T-Box queries can be: (i) definitional (ex: \"What is a \ncat?\", (ii) inclusion (ex: \"What animals are mammals?\"), and (iii) \nsuper class retrieval (ex: \"What kind of animal is lion?\". A-Box \nqueries on the other hand can be: (i) instance retrieval (\"Who \nresides in 221B Baker Street?\", (ii) class retrieval (ex: \"Who is \nAgatha Christie?\", and (iii) instance associated concept retrieval \n(\"What does John drink in the morning?\"). Some queries are \nambiguous and the linguistic reading may imply either T-Box \ndefinitional or A-Box instance retrieval (ex: \"Who is a student?\" - \nAnswer 1: \"John and Joe are students\"; Answer 2: \"A student is a \nperson who studies in an educational institution.\") We argue that \ncorrect and complete DL formalization of query implies that \nquery processing (and hence, question-answering) can be \nformulated as either a T-Box subsumption reasoning or an A-Box \nretrieval reasoning over a knowledgebase. We do not include     \n(i.e. concept negation) in this work since we exclude from the \nscope of this paper formalization of queries with negative clauses \n(such as \"What is an animal called that cannot lay egg?\"). \n4.3.1 Base Translation Rules \nAs discussed in section 4.1 we model any wh-query to have two \ncomponents - desire and input. We also mentioned that QCT helps \nto establish desire-input dependency. From a DL formalization \npoint of view such dependency identification naturally culminates \nto the DL definition of the desire in terms of the input. By \ndefinition we mean the model theoretic semantic interpretation of \nthe description of a desire as constrained by the input. Given any \nsimple wh-query Q having D, I, R2 the following translation rules \nalways holds true: \nBase Rule 1.1: If    is empty and I is not NNP or quantified then \n  \n        \n     \nBase Rule 1.2: If    is empty and I is NNP then  \n  \n                        \n                      \notherwise: \n  \n          \n        \nBase Rule 2.1: If subject of    is   and    is not empty then \n              \n                                                                 \n5 OWL DL is equivalent to          while OWL 2 is \nequivalent         . \nBase Rule 2.2: If subject of    is   and    is not empty then \n        \n       \nBase Rule 3.1: If subject of    is   and I is NNP then  \n                            otherwise: \n               \nBase Rule 3.2: If subject of    is   and I is NNP then  \n        \n                      otherwise: \n        \n         \nwhere: \n    Formalized desire  \n  \n   Strongly formalized desire  \n  \n   Weakly formalized desire  \n   Desire component identified in QCT \n   Input component identified in QCT \n    Relation component identified in QCT that is associated with \nD and I \nWordNet.getMSP: A method developed to get the most specific \nparent class from WordNet v 2.1.  \nBase rule 1.1 is meant for T-Box queries in general except when \nthe input is quantified (ex: \"Who is the student?\"). Strongly \nformalized desire (  \n ) is an inclusion/definitional T-Box query \nand requires more specific answers (i.e. sub-classes of I). Weakly \nformalized desire (  \n ) is an generic T-Box query and can allow \nless specific answers (i.e. super-classes of I is allowed).  \nBase rules 2.1 and 2.2 are meant for A-Box queries. At an A-Box \nlevel the query formalism for rules 2.1 and 2.2 is:         where \n?x is the variable that belongs to the class   . Rules 3.1 and 3.2 \nare meant for class retrieval queries and instance associated \nconcept retrieval. Also rule 1.2 is class retrieval as well.  \nAll the above base rules can be extended automatically for \ncomplex and compound queries as well. The core extension rules \nare discussed in the next section. \n4.3.2 Extension Translation Rules \nIn this paper we discuss extension rules: (i) effect of modifiers, \n(ii) effect of clausal phrases, and (iii) effect of conjunctive and \ndisjunctive phrases. \n4.3.2.1 Effect of Modifier \nNormally, if a modifier in wh-query is a JJ or an NN then it \nmodifies either an NN or an NNP. For an example, in the query: \n“Who are the tall students?” the JJ Tall modifies the input concept \nStudent which is an NN. In such general cases it is evident that the \nconcept TallStudent is a sub concept of the concept Student. An \ninteresting phenomenon that can be observed for desire/input \nmodification is what we term as recursive nested modification. In \nsentences where the subject modification is by a sequence of \nmodifiers such as                   then a nested structure is \nassumed as:                        Here '( )' denotes scope of \nthe modifier. Therefore, the scope of the inner most nested \nmodifier M3 is the concept D. The scope of the modifier M2 is the \nsub-concept M3D formed as a result of the M3 modifying D. At \nthe same time M2 also recursively modifies D to form the sub-\nconcept M2D. Similarly M1 has the sub-concept M2M3D as scope \nof modification while in recursion modifies M3D and D. The T-\nBox rule for such recursive nested modification is as follows: \nExtension Rule (Recursive Nested Modification: 3-level nesting): \n     ;           ;             \n4.3.2.2 Effect of Clausal Phrases \nComplex wh-queries can be formalized by extending the base rule \nand extended rules of simple wh-queries. While formalization it is \nimportant to identify that whether the clausal constraint(s) is \napplied to desire or inputs. If it is an input constraint then which \nof the multiple inputs it is applied. This leads to a very important \nissue called query dependency problem. Query dependencies can \nbe broadly classified as: \nDesire Dependency: In some clausal complex wh-query constraint \nis applied on the desire. For example, in the query “Which atomic \nbomb was dropped in Japan which had caused million people to \ndie?” the desire is name or type of atomic bomb with constraint: \nthe bomb caused million people to die and was dropped in Japan. \nIf clausal phrase contains an attribute of the desire then we \nassume it is constraint on desire. The given example query is \ncharacterized as: \n                                         \n                                       \n                                            . \nHere type of atomic bomb is desire and clausal constraint (i.e. \natomic bomb causing millions people to die). Therefore, \nconstraint is considered to be applied on desire, not on input. \nAttributes are associated with relations of lexical variations of the \nstructure {'DESIRE which has', 'DESIRE which includes', \n'DESIRE which is a'}. \nInput Dependency: If clausal phrase contains an attribute of the \ninput then we assume it is constraint on input. For example, in the \nquery “What is the price of SLR camera which has 3.2 megapixel \nresolution?” is characterized as: \n                                              \n                                     \n                            \nHere, “3.2 megapixel resolution” is a constraint input which is \nattribute of input “SLR camera”. Attributes are associated with \nrelations of lexical variations of the structure {'INPUT which has', \n'INPUT which includes', 'INPUT which is a'}. In this section \ngeneric DL transformation rule for all complex wh-queries are \ngiven. All constraints can be formulated as intersection of \nconcepts/instance given in the query.  \nExtension Rule 1 (Complex Query: Inclusion T-Box): \n  \n    \n \n \n      \nAn example query that requires this rule for translation is: \"What \nare the kinds of animals which are vegetarians?\". The \ncorresponding equivalent DL is                       .    \nExtension Rule 2 (Complex Query: Input Dependency): \n                                   \nExtension Rule 3.1 (Complex Query: Desire Dependency): \n                         \nAn interesting observation that we make is that if    is empty \nwhile D is non empty and constrained then   's subject is D. For \nan example, in the query \"What country which is in Europe has \nthe largest population?\"    (has) has subject D (country) since \n   is empty. In this case the extension rule is as follows: \nExtension Rule 3.2 (Complex Query: Empty   ): \n                  ; \n4.3.2.3 Effect of Conjunctive/Disjunctive Phrases \nTo formalize the compound wh-queries, after the characterization \nprocess it is important to identify whether conjunctive/disjunctive \nphrase is applied on desire, input or relation. Compound queries \ncan sometimes be split into simple queries and/or complex \nqueries. They can then be formalized using simple query and \ncomplex query translation rules. We have defined the rules for \ncases when a given compound query            can be split into \nconjunction of simple wh-queries.We have also done exhastive \nanalysis of all possible structure of compound query structure by \napplying conjunctive/disjunctive lexicons between inputs, desires,  \nrelation. We concluded on 14 different forms of compound query.  \nThe main motivation to break the compound query into simple \nquery is to increase the precision and recall of the knowledge \ndiscovery system. If we can break the  compound query into \nseparated simple queries then later on all separated queries can be \nfired in parallel and answer of all separated queires can be \nreturned by applying union operation between them. We have also \ndefined the cases where splitting is not possible and separate \nformalization rules have been defined for them. More details on \nthis topic is beyond the scope of this paper due to lack of space. \n4.3.3 Non-Trivial Translation Rules \nThere are some queries whose semantic interpretation cannot be \ncompletely and correctly constructed in a straightforward way by \napplying a formal semantic theory. This is because of certain \ninnate linguistic nuances that these queries carry that demand \nadditional modification in the formal semantic representations. In \nthe following sub sections we look into a few of such cases. \n4.3.3.1 Problem of Empty Input \nIn some queries the input can be empty. For an example, in the \nquery \"Who barks?\"    is a non-transitive verb with no explicit \ninput as object. In such situation we need to do a reification of \n   into its corresponding gerund sense and normalize the given \nNL query to the form             \n   \n             where fr is \nthe reification function. In the given example we can reformulate \nthe query as \"Who does barking?\" and the corresponding DL rule \nis: \nExtension Rule (Empty Input):                 \n4.3.3.2 Problem of Desire Inclusion \nSome inclusion queries may have desire that have may have an \nintersection with input. For an example, in the query \"What kind \nof a water vehicle is also an air vehicle?\". In such cases the base \nrule 1.1 is modified as: \nExtension Rule (Desire Inclusion):           \n4.3.3.3 Problem of Quantitative how-Query \nIn how queries that are quantitative in nature (i.e. R1 = {much, \nmany, etc}) we need to introduce a primitive concept Count and a \nprimitive role hasCount where for any arbitrary satisfiable \nconcept    the following axiom holds:                   . \nThe hasCount is mapped to a function called fcount that calculates \nthe size of the instances of    at any given point of time. For an \nexample, in the query \"How many people live in New York?\" the \ncount operator works on the desire people living in New York. \nThe corresponding rule is: \nExtension Rule (Quantitative how): \n                                   \n4.3.3.4 Problem of Temporal Adverbial Modifier \nSome queries have temporal adverbial tokens such as in the query \n\"What can be sometimes observed in the morning sky?\" where R2 \n(observed in) is associated with a temporal adverbial modifier \n(sometimes). The problem with formalizing such queries is that \nthe ontological validity of the desire is essentially temporal in \nnature. In other words, for the given example, if a particular planet \nis observed in the morning sky it is not so that it will always be \nobserved (like the sun which we can observe every day). Hence, \nsun cannot be a candidate answer in this case. The rule for such \nqueries is as follows: \nExtension Rule (Temporal Adverbial: sometimes): \n                     \n                               \n                                         \n4.3.3.5 Problem of Superlative Modifier \nIn some queries superlative tokens are included such as in \"What \nis the tallest mountain in Europe?\". In such queries the desire is \nfor a specific instance that has the optimal (maximal or minimal) \ndegree of measurable modifier of the desire class. In the example \ntall is a measurable modifier whose superlative form is maximal \nheight of all instances of the desire class Mountain. The height \nattribute of mountain is implicit in the given query. Keywords \nsuch as most and least are good indicators of deciding whether the \ncomputation has to be maximal or minimal. However, for suffix \nbased superlative tokens (i.e. est) it is not so evident. The problem \nis how to know that tall+est has to maximized while low+est has \nto be minimized. We take a bootstrapping based approach with a \nseed bag of measurable modifiers (such as tall, long, big, low, \nhigh, large, wide, etc) and then mapped the bootstrapped \nkeywords with corresponding plausible attributes (denoted AM). \nFor an example we get pairs such as:                   \n                                            \n                    ). Based on such pairing we then classify \nthe modifiers into positive modifiers (those that requires \nmaximization such as tall, wide, etc.) and negative modifiers \n(those that requires minimization such as low). The corresponding \nextension rule is: \nExtension Rule (Superlative Queries):                    \n                       \n                \n where: \n         Optimality function that returns Integer Datatype ( ).  \n5. EVALUATION \n5.1 Evaluation Goal and Metric  \nOur evaluation aim was to observe the accuracy of the proposed \nQCT. We leave the accuracy evaluation of the DL formalization \nas a future work since that requires indirect comparative testing in \nterms of mean average precision and recall on some of the \ncutting-edge knowledge discovery systems. However, it is to be \nunderstood that the accuracy of the DL formalization is \nintrinsically dependent on the accuracy of QCT.  \nTo evaluate QCT we decided on a simple Characterization \nCoverage (CC) measure. The measure is modeled to understand \nhow many different linguistic forms of simple, complex and \ncompound wh-queries in English can be identified correctly by \nQCT. We measure CC in three perspectives: (i) CC-Precision, (ii) \nCC-Recall, and (iii) CC-F1 score. We define them as follows: \nCC-Precision: Given a test set of NL queries the CC-Precision is \ncalculated as the ratio of the number of correctly identified queries \n(NCI) and the total number of identified queries in the test set (NI).  \nCC-Recall: Given a test set of NL queries the CC-Recall is \ncalculated as the ratio of the number of correctly identified queries \n(NCI) and the total number of queries in the test set (N).  \nCC-F1: The Simple Harmonic Mean of CC-Precision and CC-\nRecall is the CC-F1.  \n5.2 Experimental Results \nTo evaluate CC of proposed work we have used the Microsoft \nEncarta 98 query test set [29] and OWL-S TC dataset. The \nMicrosoft Question Answering Corpus (MSQA), which is aimed \nat querying documents belonging to the Encarta-98 encyclopedia. \nThe test set contains 1365 usable English wh-queries. We \nexcluded the queries of procedural how and why from this dataset. \nWe have categorized simple, complex and compound queries \nfrom the dataset. There are total 473 queries of procedural how \nand why which are excluded. The reduced dataset consist of total \n982 queries, which is distributed among 676 simple, 147 complex \nand 69 compound wh-queries. The accuracy statistics is given in \ntable 5. We observe that the CC-Precision is 100% for all types of \nwh-queries while the overall CC-Recall is 94.50. The perfect \nprecision shows that the QCT is theoretically sound. \nTo validate our results with Encarta 98 dataset we also tested \nQCT on custom query dataset built on top of OWL-S TC v.4.0 \ndataset6. The OWL-S TC dataset consists of service descriptions \nof 1083 web services from 9 different domains. A service \ndescription is a formal specification of the behavior of a web \nservice in terms of its required input parameters, given output \nparameters, and other binding parametric details for runtime \nexecution. The description also contains a short NL narrative of \nthe overall behavior. A query dataset for this corpus was \ndeveloped by three research assistants. The task for each of these \nthree assistants was to formulate a wh-query for every service \nsuch that the query desire matches the given output of the service \nand query input matches the required input of the service. Since \nthis task was done independently we observed that almost in all \ncases the syntactic structuring of the query for a given service by \neach assistant was different. The queries were simple, complex, \nand compound with an average of 90% query of the form complex \nand compound. Ideally, the extracted query desire by QCT should \nbe semantically equivalent the output parameter of the \ncorresponding web service specification. Based on this notion we \nhave calculated CC-precision, CC-recall and CC-F1 measure for \neach of the three query datasets. From table 6 we observed that \nthe average recall was 98.77%, average precision 100% and \naverage F1 was 98.92%. The results clearly validate the earlier \nresults with Microsoft Encarta 98.  \n6. CONCLUSION \nIn this paper we have a Description Logic based NL query \nformalization methodology. The motivation is to improve  \n                                                                 \n6 http://projects.semwebcentral.org/projects/owls-tc/ \nTable 5.1 \n \nTable 5.2 \n \nTable 6 \n \naccuracy of answer extraction from NL documents using formal \nlogic based reasoning. We have proposed the basic DL translation \nrules along with some of the important derived rules that cover \ndifferent kinds of linguistic nuances. We found promising results \nwhile evaluating DLQS-WhM with MS Encarta query test set and a \nquery dataset built on top of OWL-S TC v.4.0 dataset. \n7. REFERENCES \n[1] Pejtersen, A. M. 1998. Semantic information retrieval. \nCommunications of the ACM. 41, 4 (April,1998) 90 – 92. \n[2] Moldovan, D., Clark, C., and Bowden, M. 2007. Lymba's \nPowerAnswer 4 In TREC-2007, Association for \nComputational Linguistics. \n[3] Androutsopoulos, I. , Ritchie, G. D. and Thanisch, P. 1993 \nMASQUE/SQL-An Efficient and Portable Natural Language \nQuery Interface for Relational Databases. in Proceedings of \nthe Sixth International Conference on Industrial and \nEngineering Applications of Artificial Intelligence and \nExpert Systems - IEA/AIE  (Edinburgh, Scotland, 1993). \n \nQuery \nTypes \n \nNwh \n \nNI-wh \n \nNCI-wh \nCC-\nRe. \n(%) \nCC-\nPr. \n(%) \nCC-\nF1 \n(%) \nSimple \nWh-Query \n676 \n642 \n642 \n94.97 \n100 \n97.42 \nComplex \nWh-Query \n147 \n140 \n140 \n95.23 \n100 \n97.55 \nCompound  \nWh-Query \n69 \n64 \n64 \n92.75 \n100 \n96.23 \nTotal \n892 \n843 \n843 \n94.50 \n100 \n97.17 \n \nQuery \nTypes \n \nNwh \n \nNI-wh \n \nNCI-wh \nCC-\nRe. \n(%) \nCC-\nPr. \n(%) \nCC-\nF1 \n(%) \nHow \n165 \n158 \n158 \n96.68 \n100 \n98.31 \nWhat \n406 \n392 \n392 \n95.75 \n100 \n97.83 \nWhen \n39 \n35 \n35 \n96.55 \n100 \n98.24 \nWhere \n85 \n82 \n82 \n89.74 \n100 \n94.59 \nWhich \n5 \n5 \n5 \n96.47 \n100 \n98.20 \nWho \n143 \n143 \n143 \n100 \n100 \n100 \nTotal \n843  \n815 \n815 \n96.68 \n100 \n98.31 \n \nQuery \nTypes \n \nNwh \n \nNI-wh \n \nNCI-wh \nCC-\nRe. \n(%) \nCC-\nPr. \n(%) \nCC-\nF1 \n(%) \n             \n1083 \n1000 \n1000 \n97.65 \n100 \n98.81 \n             \n1083 \n997 \n997 \n97.36 \n100 \n98.66 \n             \n1083 \n1010 \n1010 \n98.63 \n100 \n99.31 \nTotal \n3249 \n3007 \n3007 \n97.88 \n100 \n98.92 \n[4] Popescu, A-M. and Etzioni, O. and Kautz, H. 2003Towards a \ntheory of natural language interfaces to databases. in \nProceedings of the 8th international conference on \nIntelligent user interfaces (Miami, USA, January 12 - 15, \n2003). \n[5] Wang, C., Xiong, M., Zhou, Q. and Yu, Y. 2007. Panto: A \nportable natural language interface to ontologies. in \nProceedings of the 4th European conference on the Semantic \nWeb: Research and Applications (Innsbruck, Austria, June, \n2007). \n[6] Kaufmann, E., Bernstein, A. and Zumstein, R. Querix. 2006. \nA Natural Language Interface to Query Ontologies Based on \nClarification Dialogs. in International Symposium on \nWearable Computers - ISWC (Montreux, Switzerland, \nOctober 11 - 14, 2006). \n[7] Lopez, V. Pasin, M. and Motta, E. 2005. AquaLog: An \nOntology-Portable Question Answering System for the \nSemantic Web. in European Semantic Web Symposium \n/Conference - ESWS (Heraklion, Crete, May 29 - June 1, \n2005) \n[8] Sahlgren. M.  2008 The distributional hypothesis. Italian \nJournal of Linguistics. 20, 1 (June, 2008) 33 – 54. \n[9] Moldovan, D., Harabagiu, S., Pasca, M., Mihalcea, R., \nGoodrum, R., Girju, R. and Rus, V. 1999. LASSO: A Tool \nfor Surfing the Answer Net. in TREC 1999, National \nInstitute of Standards and Technology (NIST) (November, \n1999) \n[10] Yuhan He. 2010. Goal Detection from Natural Language \nQueries. In 15th International Conference on Applications of \nNatural Language to Information Systems (Cardiff, UK, \nJune, 2010).  \n[11] Dumais, S., Banko, M., Brill, E., Lin, J. and Ng, A. 2002. \nWeb Question Answering: Is More Always Better?. in \nProceedings of ACM SIGIR’02 (Tampere, Finland, August, \n2002). \n[12] Deerwester, S. C. , Dumais, S. T.,Landauer, T. K.,  Furnas, \nG. W.  and Harshman, R. A. 1990. Indexing by latent \nsemantic analysis. JASIS. 41, 6 (September, 1990) 391 – 407. \n[13] Hofmann, T. 1999 Probabilistic latent semantic indexing. In \nProceedings of the 22nd International ACM SIGIR \nconference on Research and development in information \nretrieval (Berkeley, USA, 1999). \n[14] Boumechaal, H. and Boufaida, Z. Formalization of natural \nlanguage queries. in IEEE International Symposium on \nInnovations in Intelligent Systems and Applications (IN-\nISTA) (Istanbul, June 15 - 18, 2011). \n[15] B. Di Martino. 2010. An approach to semantic information \nretrieval based on natural language query understanding. in \nCurrent Trends in Web Engineering, ICWE Workshop \n(Vienna, Austria, July 5 - 6, 2010). \n[16] Cao, T. H. and Mai, A. H. 2010. Ontology-based \nunderstanding of natural language queries using nested \nconceptual graphs. in Proceedings of 18th International \nConference on Conceptual Structures: From Information to \nIntelligence (Kuching, Malaysia, July 26 - 30, 2010). \n[17] Bierman, G.M.. 2003. Formal semantics and analysis of \nobject queries. in Proceedings of the 2003 ACM SIGMOD \ninternational conference on Management of data (San Diego, \nUSA, June 9 - 12, 2003). \n[18] Han, Y-J., Noh, T-G., Park, S-B., Park, S. Y. and Lee, S-J. \n2010. A natural language interface of thorough coverage by \nconcordance with knowledge bases. in Proceedings of the \n15th international conference on Intelligent user interfaces \n(HongKong, China, February 7 - 10, 2010). \n[19] Barhamgi, M., Benslimane, D. and Medjahed, B. 2010. A \nquery rewriting approach for web service composition. IEEE \nTransactions on Services Computing. 3, 3 (July, 2010) 206-\n222. \n[20] Katz, B., Borchardt, G. and Felshin, S. 2006. Natural \nLanguage Annotations for Question Answering. in \nProceedings of the 19th International FLAIRS Conference \n(Melbourne Beach, USA, May 2006). \n[21] Kaufmann, E., Bernstein, A. and Fischer, L. 2007. NLP-\nReduce: A \"naive\" but Domain-independent Natural \nLanguage Interface for Querying Ontologies. in Proceedings \nof the 4th European Semantic Web Conference (Innsbruck, \nAustria, June, 2007). \n[22] Bernstein, A., Kaufmann, E. , Kaiser, C. and Kiefer, C. 2006. \nGinseng: A Guided Input Natural Language Search Engine \nfor Querying Ontologies. in 2006 Jena User Conference \n(Bristol, UK, May 2006). \n[23] Linckels, S. and Meinel, C. 2006. Resolving Ambiguities in \nthe Semantic Interpretation of Natural Language Questions. \nin Proceedings of 7th International Conference on Intelligent \nData Engineering and Automated Learning - IDEAL \n(Burgos, Spain, September 20 - 23, 2006). \n[24] Lopez, V., Fernández, M., Motta, E., Sabou, M. and Uren, V. \n2007. Question Answering on the Real Semantic Web. in \nProceedings of International Semantic Web Conference \n(Busan, Korea, November 11 - 15, 2007). \n[25] Baader, F.  2003 The description logic handbook: theory, \nimplementation, and applications. Cambridge university \npress. \n[26] Kamp, H. 1981 A theory of truth and semantic \nrepresentation. Linguistis: Formal semantics-the essential \nreadings, 7:189 - 222, 1981.  \n[27] Moldovan D.  and Rus V. 2001 Logic form transformation of \nwordnet and its applicability to question answering. In ACL, \n402 – 409. \n[28] Tsarkov D. and Horrocks I. 2006. Fact++ description logic \nreasoner: System description. In Proceedings of 3rd Joint \nConference on Automated reasoning (Seattle, USA, August \n17 - 20, 2006) \n[29] Microsoft Research Question-Answering Corpus - Encarta \n98, v 1.0.0, November 2008 \n[30] Marcus, M. P., Marcinkiewicz, M. A., and Santorini, B. 1993 \nBuilding a large annotated corpus of English: The Penn \nTreebank. Computational linguistics. 19, 2 (June, 1993) 313 \n– 330. \n \n \n \n",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "published": "2013-12-25",
  "updated": "2013-12-25"
}