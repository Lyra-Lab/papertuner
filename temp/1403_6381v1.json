{
  "id": "http://arxiv.org/abs/1403.6381v1",
  "title": "An efficiency dependency parser using hybrid approach for tamil language",
  "authors": [
    "K. Sureka",
    "K. G. Srinivasagan",
    "S. Suganthi"
  ],
  "abstract": "Natural language processing is a prompt research area across the country.\nParsing is one of the very crucial tool in language analysis system which aims\nto forecast the structural relationship among the words in a given sentence.\nMany researchers have already developed so many language tools but the accuracy\nis not meet out the human expectation level, thus the research is still exists.\nMachine translation is one of the major application area under Natural Language\nProcessing. While translation between one language to another language, the\nstructure identification of a sentence play a key role. This paper introduces\nthe hybrid way to solve the identification of relationship among the given\nwords in a sentence. In existing system is implemented using rule based\napproach, which is not suited in huge amount of data. The machine learning\napproaches is suitable for handle larger amount of data and also to get better\naccuracy via learning and training the system. The proposed approach takes a\nTamil sentence as an input and produce the result of a dependency relation as a\ntree like structure using hybrid approach. This proposed tool is very helpful\nfor researchers and act as an odd-on improve the quality of existing\napproaches.",
  "text": "AN EFFICIENT DEPENDENCY PARSER USING HYBRID APPROACH FOR TAMIL \nLANGUAGE \n \nK.Sureka \nStudent,Dept. of CSE-PG, \nNational Engineering College, \nKovilpatti, Tamilnadu,India. \nsurekakrishcs@rediffmail.com \nDr.K.G.Srinivasagan \nProf. & Head, Dept. of CSE-PG, \nNational Engineering College, \nKovilpatti, Tamilnadu,India. \nkgsnec@rediffmail.com \nS.Suganth \nAsst.Prof. Dept. of CSE-PG, \nNational Engineering College, \nKovilpatti, Tamilnadu,India. \nKrish.sugi1@gmail.com \n \n \nAbstract—Natural language processing is a prompt research \narea across the country. Parsing is one of the very crucial tool in \nlanguage analysis system which aims to forecast the structural \nrelationship among the words in a given sentence. Many researchers \nhave already developed so many language tools but the accuracy is \nnot meet out the human expectation level, thus the research is still \nexists. Machine translation is one of the major application area under \nNatural Language Processing. While translation between one \nlanguage to another language, the structure identification of a \nsentence play a key role. This paper introduces the hybrid way to \nsolve the identification of relationship among the given words in a \nsentence. In existing system is implemented using rule based \napproach, which is not suited in huge amount of data. The machine \nlearning approaches is suitable for handle larger amount of data and \nalso to get better accuracy via learning and training the system. The \nproposed approach takes a Tamil sentence as an  input and  produce \nthe result of a dependency relation  as a tree like structure using \nhybrid approach. This proposed tool is very helpful for researchers \nand act as an odd-on improve the quality of existing approaches. \n \nKeywords—Natural \nlanguage \nprocessing; \nPOS \nTagging;   \nMorphological \nAnalyzer; \nClause \nboundary \nidentification;  \nDependency parsing. \nI. \nINTRODUCTION  \nNatural Language Processing (NLP) is an area of research \nand application that explores how computers can be used to \nunderstand and manipulate natural language text or speech to \ndo useful things. The Origin of Natural Language Processing  \nlie in a number of disciplines such as, computer and \ninformation sciences, linguistics, mathematics, electrical and \nelectronic engineering, artificial intelligence and robotics, \npsychology, etc. Machine translation is one of the major \napplication area under language processing. The ideal aim of \nmachine translation systems is to produce the best possible \ntranslation without human aid. The structural order might vary \nfrom language to language. During the translation of English-\nTamil, the structural order might be a difficult task because the \norder of words may affect the original meaning of a sentence. \nIn order to translate correct interpretation of a sentence, the \nword structure order is very essential. The syntactic rules are \nused to predict the correct sentence translation based on the \ntarget language structure and these are also used to improve \nthe optimization of translation process. The machine \ntranslation requires the parsed output to be translated. Parsing \ngives the structural analysis of the sentence. There exist tools \nlike Stanford parser which gives the dependency information \nabout the sentence. But, the tool gives the dependency \nstructure only for the English. There are no such efficient tools \nfor the Tamil language. Dependency parsing suits the best to \nget the structural information about the sentence.  \n \nDependency parsing is a very useful tool in the sentence \nstructure identification. For languages like English, it can be \neasily told that the sentence structure is in the form of SVO \n(Subject Verb Object). Though the sentence structure for the \nTamil is SOV (Subject Object Verb) form, it is not necessary \nthat the sentences should follow the same format as the target \nlanguage. Generally Tamil language can accept to write the \nsentence in any pattern because Tamil sentence structure is \nchanged, then the exact meaning of the sentence also is \nchanged. So, in these cases of free word order language, \ndependency parsing gives the correct sentence structure.  \n \nThe clause boundary identification is a vital task in \nlanguage generation and understanding. Parsing gives the best \nway to solve the clause boundary identification. If the source \nsentence length is too long, it can be split based on the clauses \nwhich make the translation very easy. The clauses in the \nsentences may be joined using the connectives or the clauses \nmay be embedded within the other clauses. Sometimes, the \ntwo clauses are separated only by commas, in those cases, the \ntranslation is easy. Identifying the clauses in the sentences \nitself becomes a complex task. Dependency parsing gives the \ninformation about the relation extraction as how the words in \nthe sentence are related and what type of relationship exists \nbetween the words in the sentence. So, considering the various \nuses of the parsing, an efficient tool needs to be developed.  \n \nIn proposed work, a hybrid approach is proposed that uses \nboth techniques i.e. rule based and machine learning to build \nan identifier for different clause boundaries of Tamil language. \nThe POS tagger and Chunker are used to prepare the parts of \nspeech and chunked tagged data as the inputs, where linguistic \nrules are taken as features. The rest of the paper is organized \nas follows, the related works are discussed in section 2, and \nframework and proposed algorithm presented in section 3, \nimplementation methodology in section 4, experimental \nresults and discussion are reported in section 5 and followed \nby concluding remarks. \nII. \nRELATED WORK \nThe researchers are reported the different levels of \naccuracy as result. The results may not fulfill the scenario of \nusers need various dependency parsing works has been \nexperimented for different languages. Some of the work has \nbeen focused as follows. \n \n \nThe Tamil Shallow Parser was developed using the new \nand state of the art machine learning approach [1]. The \nShallow Parser system developed for Tamil is an important \ntool for Machine Translation between Tamil and other \nlanguages. A shallow parsing approach is compared with PP-\nattachment [2] with a state of the art full parser. It is used a flat \nrepresentation of prepositional phrases and their associated \nattachment sites to train a machine learner for the PP \nattachment task. A memory-based approach can obtain results \nfor the PP attachment task comparable to a state-of-the art full \nparser. A phrase structured Treebank has been developed with \n326 Tamil sentences which covers more than 5000 words. A \nhybrid language model has been trained with the phrase \nstructured Treebank using immediate head parsing technique. \nLexicalized and statistical parser which employs this hybrid \nlanguage model and immediate head parsing technique gives \nbetter results than pure grammar and trigram based model [3].  \n \nThe data-driven dependency parsing [4] have shown that \nthe distribution of parsing errors are correlated with theoretical \nproperties of the models used for learning and inference. This \nexperimental results show that both models consistently \nimprove their accuracy when given access to features \ngenerated by the other model, which leads to a significant \nadvancement of the state of the art in data-driven dependency \nparsing. The clause markers play the role to detect the type of \nsub-ordinate clause, which is with or within the main clause. \nLimitation with CRFs is that it is highly dependent on \nlinguistic rules. Missing of these rules may lead to wrongly \nclassified data [5].  \n \nIII. FRAME WORK OF DEPENDENCY TAMIL \nPARSER \nThe implementation of dependency parsing involves a \nsequence of several steps.  \n \n \nFig 1. Framework of Dependency Parser \n \nThe input sentence is initially be tokenized, the tokenized \nwords are sent it to the pos tagger to get the grammatical label \nof each data. It is the process of automatically assigning the \nlabel based on the grammatical category or lexical class to \neach and every word in a sentence. It is considered to be \nimportant process in speech synthesis, speech recognition, \nnatural language processing, information retrieval and \nmachine translation, etc. During POS tagging, there is a \npossibility for ambiguity because the same word has different \nmeaning in different contexts. It includes verbs, nouns, \nadjectives, adverbs, and determiner and so on. The Fig 2 \nrepresents the Parts of speech tagging. \n \n \nFig 2. POS Tagging \n \nSome of the words are formed in untagged. The untagged \nwords are passed to the morphological analyzer to get the root \nword with appropriate tagged data. Tamil language is \nmorphologically \nrich \nand \nagglutinative. \nSuch \na \nmorphologically rich language needs deep analysis on the \nword level to capture the meaning of the word from its \nmorphemes and its categories. Each root is affixed with \nseveral morphemes to generate a word. In general, Tamil \nlanguage is postpositionally inflected to the root word. The \nFig 3 represents the Morphological analysis of each untagged \nword in the parts of speech. Tamil is one of the classical \nIndian languages which has very strong linguistic base with \nwell defined set of morpho syntactic rules. Generally suffixes \nare used to mark class, numerals and cases attached to noun or \nverb root. \n \n \nFig 3. Morphological Analyzer \n \nTamil is one of the classical Indian languages which \nhas very strong linguistic base with well defined set of morpho \nsyntactic rules. Generally suffixes are used to mark class, \nnumerals and cases attached to noun or verb root. \n Chunking is an efficient and robust method for \nidentifying short phrases in text, or ―chunks‖. Chunking is \nconsidered as an intermediate step towards full parsing. A \nchunker finds adjacent, non-overlapping spans of related \ntokens and groups them together into chunks. Chunkers often \noperate on tagged texts, and use the tags to make chunking \ndecisions. A subsequent step after tagging focuses on the \nidentification of basic structural relations between groups of \nwords. This is usually referred to as phrase chunking. It \nsegments of a sentence with syntactic constituents such as \nnoun or verb phrase (NP or VP). Each word is assigned only \none unique tag, often encoded as a begin-chunk (e.g. B-NP) or \ninside-chunk tag (e.g. INP) and outside-chunk tag(e.g. ONP).  \n \nThere is no standard sentence structure for tamil \nlanguage . The sentence structure are obtained based on this \ngrammar rules.  \n \nNP -> (Det) (Adj) N (PP) \nVP -> V (NP) (PP) (Adv) \nPP -> P (NP) \nADJP -> (CRD) (ADJ) \nADVP -> (ADV) (INT) (CRD) \nNP ->   (NP) conj (NP) \nS  ->  (NP)* (VP) \n \nThe tagged sentence is passed to the chunker process, this \nis used to get the chunked data. The Fig 4 represents the group \nthe words in the sentence. \n \n \nFig 4. Chunking \nAt present the words includes the pos tag and chunk tag of \neach word.  \nDependency parsing assigns head-dependent relations \nbetween the words in a sentence. Whenever two words are \nconnected by a dependency relation, that one of them is the \nhead and the other is the dependent, and that there is a link \nconnecting them. In general, the dependent is in the form of \nmodifier, object or complement. The head plays the larger role \nin determining the behavior of the pair. In our dependency \nrepresentation the source of the edge represents the modifier \nand destination points to the head word. Fig 5 represents \ndependency relationship between words in the sentence. Here \nis the root word and it is the head of the other words. \nAnd the remaining word indicates dependent on head. \n \n \n \n \nFig 5. Dependency Relationship structure \nThis project mainly focused to create a parser tool based on \nthe \ndependency \npriority \nof \na \nword.  \nThe \nDependency \nParsing \nassigns \nhead-dependency \nrelations between them. The Root word of the tree is \nAnd \nare dependent on root \nword. The result of dependency priority is to directly to \nmake a manual tree structure of a sentence. In a \ncomputational way, the tree viewer is used to bring manual \ntree and to remake the computationally graphics structure \nof a words in a sentence. This resultant tree format is \nuseful to identify the grammatical relationship of the words \nand also to make doing further research in a language. The \nFollowing Fig 7 illustrates the Parse Tree structure \n \nFig 7. Parse Tree \nIV. \nHYBRID APPROACH \nThe Parser System using hybrid approach this approach \ncombine with Rule based and Machine learning approaches. \nThe Machine learning approach used for conditional random \nfield (CRF). To achieve a better morphological analyzer using \n―Rule Based Forward Algorithm” \n                                                                                                 \nAlgorithm: \nInput:  \nData Set D={(W1,P1), (W2,P2)……(Wn,Pn)}; \nProcess: \nLet the sentence be ―S‖ and split into ―W1‖  \n―W2‖………… ―Wn‖; \nFor i=1 to n; \n{W1 ,W2………… Wn } _ { ({Wi }If({Wi }_{D}) then \nGoto Stemming: \nStemming: \nLet {Wi } as a string; \nRoot Word R; \nVerb Root VBR; \nNoun Root NR; \nTake {Wi } split into {C1, C2…….. Cn } \nArrayList Ai; \nStore {C1, C2…….. Cn } into Ai ; \nUse Pattern Match; \nIf(Matcher.find()) then \n{C1, C2…….. Cn } add (Matcher.group()) _ R \n{R _ VBR} \nElse \n{R _ NR} \nNR _ {Case Marker Rules}; \nOutput: \n {Wi} = {R}+ {VB/N Suffixes} \n \nConditional Random Field \n \n \nThe CRF techniques as modeling in the learning phase and \ninference in the classification. CRF uses the conditional \nprobability P (label sequence y | observation sequence x) \nrather than the joint probability P(y, x) as in case of HMM. It \nspecifies the probability of possible label sequences y for a \ngiven observation sequence x. CRF allows arbitrary, non-\nindependent features on x while HMM does not. Probability of \ntransitions between labels may depend on past and future \nobservations. This technique has two phases for clause \nboundary identification: \n \n1. Learning: Given a sample set X containing features {X1 \n, … ,Xn } along with the set of values for hidden labels Y i.e. \nclause boundaries{Y1 , ... ,Yn }, learn the best possible    \npotential functions. \n \n2. Inference: For a given word there is some new \nobservable x, find the most likely clause boundary y*  for x, \ni.e. compute (exactly or approximately). \n \nIn this CRF technique linguistic rules are used as features \nfor which different length of windows, comprises of words, \nare formed that depend on these linguistic rules. For example, \nin case of relative clause identification in Tamil language, \nclause beginning and ending are identified via rule1 and rule2 \nrespectively. \n \nRULE_1:  \n \nIf the current word is any relative clause marker and next \nword is any of the POS tags verb, pronoun, adjective, noun \nthen the next word is marked as beginning of clause boundary \nas shown below \n \nPosition 0: Relative clause marker \nPosition 1: Verb or Adjective or noun or pronoun \n \nThen 0 should be marked as beginning of subordinate \nclause of type relative. Where position 0 indicates the current \nword and position 1 is the next word. \n \nRULE_2: \n \nIf the current word is any verb auxiliary and next word is \nany symbol then current word is end of corresponding \nsubordinate clause boundary as shown below \n \nPosition 0: Verb phrase or Verb auxiliary \nPosition 1: any symbol or phrase \n \nThen 0 should be marked as end of above subordinate \nclause. \n \nV. \nRESULTS AND DISCUSSION \nThe Proposed frame work and algorithm is experimented \nwith 150 sentences of text from the news papers and articles. \nAll the sentences are used for training. In order to evaluate the \nsystem, we applied 150 test sentences, in that 120 sentences \nare correctly parsed. Moreover, Precision and Recall of words \nare widely used metrics to evaluate the efficiency of \ndependency relation between the words in the sentences. \nPrecision is the percentage of generated words that are \nactually correct. The recall stands for the percentage of words \nthat are generated and that are actually found in the reference \ntranslation. F-Measure is the harmonic mean of recall and \nprecision. \n \nTable 1. Relationship Analysis \nInput \nWithout \ndependency \nrelation(MT) \nWith dependency \nrelation(MT) \n. \nHe temple to went  \nHe went to temple.  \n. \nHe English for ten \nyears studied  \nHe studied English \nfor ten years \n \nThe Cow milk gives \nThe cow gives milk. \n \nI  a boy in hall saw. \nI saw a boy in the \nhall. \n \nBombay \nindia \ngateway. \nBombay \nis \nthe \ngateway of india. \n \nIt is a beautiful \nbaby. \nIt is a beautiful \nbaby. \n \nTable 2. Experimental analysis of various metrics \n \nRelation \nbetween the \nwords \n \n*P(%) \n \n*R(%) \n \n*F(%) \nWithout \ndependency  \n63.78 \n \n56.32 \n \n59.82 \nWith dependency  82.78 \n93.67 \n87.89 \n  *P-Precision, *R-Recall, *F-F-Measure \n \nThe comparative study is made with Dependency relation. \nThe same set of data are used with dependency relation, out of \nwhich 120 sentences are correct, the main reason is semantic \nanalyzed of prepositions and reordering error. We obtained the \nprecision, recall and F-measure as 82.78 %, 93.67 %, 87.89 % \nrespectively is as shown in table 2. The Fig. 8 emphasizes very \nclearly that the proposed system performance is better with \nrespect to all the metric. \n \n \nFig 8. Comparative study of dependency relation \n \nVI. CONCLUSION \n \nIn this paper Conditional Random Fields are used for \nclassification of clause boundary beginning and ending and \nalso identify the type of subordinate clause. Limitation with \nCRFs is that it is highly dependent on linguistic rules. Missing \nof these rules may lead to wrongly classified data. An \nimprovement can be achieved in this proposed clause markers \nfor different subordinate clauses and also for those clauses \nwhich are embedded in the main clause. The proposed model \nwill give good accuracy for all the sentences if the training \ndata is increased. More complex sentence structures can be \nadded to the training data. Also, the sentence in passive voice \ncan be added to get good results.  \n \nREFERENCE \n[1] \nDhanalakshmi V and Anand Kumar M, (2011),   \"Tamil \nshallow parser using machine leaning Approach\" , \nTamil Internet.  \n[2]    Selvam M, Natarajan. A M, and Thangarajan R(2008), \n\"Structural Parsing of Natural Language Text in Tamil \nUsing Phrase Structure Hybrid Language Model\" , \nInternational Journal of Computer and Information \nEngineering. \n[3]    Loganathan Ramasamy and ZdenZabokrtsky , (2011), \n\"Tamil Dependency Parsing: Results Using Rule Based \nand \nCorpus \nBased \nApproaches\", \nComputational \nLinguistics and Intelligent Text Processing.  Lecture \nNotes in Computer Science Volume 6608, pp 82-95. \n[4]      Jisha P Jayan and Rajeev R R ,(2003), \"Parts Of Speech \nTagger and Chunker for Malayalam \n           – Statistical Approach\" Computer Engineering and \nIntelligent Systems , ISSN 2222-1719 . \n[5]      Kenji Sagae, Brian Macwhinney, Alon Lavie ,( 2004), \n\"Automatic parsing of parental verbal input\" , Behavior \nResearch Methods, Instruments, & Computers, Volume \n36, Issue1, pp 113-126. \n[6] \nDhanalakshmi  V1, Anand Kumar1, Shivapratap G1, \nSoman KP1 and Rajendran S2 (2009 ) Tamil POS \nTagging using Linear Programming , International \nJournal of Recent Trends in Engineering, Vol. 1, No. 2. \n[7]    Anand Kumar M,Dhanalakshmi V, Rekha R U,Soman K \nP and Rajendran(2010), ―A Novel data driven algorithm \nfor \nTamil \nmorphological \ngenerator‖,IJCA,Vol.6,No.12,Pages:52-56.  \n[8] \nAnand Kumar M, Dhanalakshmi V, Soman K.P , \nRajendran S,(2010), ― A Sequence Labeling Approach \nto Morphological Analyzer for Tamil Language‖ , \nIJCSE , Vol. 02, No. 06,, 1944-1951. \n[9] \nHassan Mohameda, Nazlia Omara, Mohd Juzaidin Ab \nAziza, Suhaimi Ab Rahmanb ,(2011), ―Statistical \nMalay Dependency Parser for Knowledge Acquisition \nBased on Word Dependency Relation‖,Elsevier- Pacific \nAssociation for Computational Linguistics. \n[10] Nathan Green, Loganathan Ramasamy and Zdenekˇ \nZabokrtsk ˇ y´,(2012), ― Using an SVM Ensemble \nSystem for Improved Tamil Dependency Parsing ‖, \nAssociation for Computational Linguistics, pages:72–\n77. \n[11] Antony P J Nandini ,J. Warrier, Dr. Soman K P,(2010) \n―Penn Treebank-Based Syntactic Parsers for South \nDravidian Languages using a Machine Learning \nApproach‖ \nInternational \nJournal \nof \nComputer \nApplications (0975 – 8887) Volume 7– No.8. \n[12] D.Chandrakanth, \nM.Anand \nKumar \nand \nS.Gunasekaran(2012),―Parts-of-Speech \ntagging \nfor \nTamil language‖,IJCSE,Vol.6,No.6,Pages:88-93. \n \n \n",
  "categories": [
    "cs.CL"
  ],
  "published": "2014-03-21",
  "updated": "2014-03-21"
}