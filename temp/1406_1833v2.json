{
  "id": "http://arxiv.org/abs/1406.1833v2",
  "title": "Unsupervised Feature Learning through Divergent Discriminative Feature Accumulation",
  "authors": [
    "Paul A. Szerlip",
    "Gregory Morse",
    "Justin K. Pugh",
    "Kenneth O. Stanley"
  ],
  "abstract": "Unlike unsupervised approaches such as autoencoders that learn to reconstruct\ntheir inputs, this paper introduces an alternative approach to unsupervised\nfeature learning called divergent discriminative feature accumulation (DDFA)\nthat instead continually accumulates features that make novel discriminations\namong the training set. Thus DDFA features are inherently discriminative from\nthe start even though they are trained without knowledge of the ultimate\nclassification problem. Interestingly, DDFA also continues to add new features\nindefinitely (so it does not depend on a hidden layer size), is not based on\nminimizing error, and is inherently divergent instead of convergent, thereby\nproviding a unique direction of research for unsupervised feature learning. In\nthis paper the quality of its learned features is demonstrated on the MNIST\ndataset, where its performance confirms that indeed DDFA is a viable technique\nfor learning useful features.",
  "text": "Unsupervised Feature Learning through Divergent\nDiscriminative Feature Accumulation\nPaul A. Szerlip, Gregory Morse, Justin K. Pugh, and Kenneth O. Stanley\nDepartment EECS (Computer Science Divison)\nUniversity of Central Florida\nOrlando, FL 32816 USA\n{pszerlip,jpugh,kstanley}@eecs.ucf.edu, gregorymorse07@gmail.com\nAbstract\nUnlike unsupervised approaches such as autoencoders that learn to reconstruct\ntheir inputs, this paper introduces an alternative approach to unsupervised feature\nlearning called divergent discriminative feature accumulation (DDFA) that instead\ncontinually accumulates features that make novel discriminations among the train-\ning set. Thus DDFA features are inherently discriminative from the start even\nthough they are trained without knowledge of the ultimate classiﬁcation problem.\nInterestingly, DDFA also continues to add new features indeﬁnitely (so it does not\ndepend on a hidden layer size), is not based on minimizing error, and is inherently\ndivergent instead of convergent, thereby providing a unique direction of research\nfor unsupervised feature learning. In this paper the quality of its learned features is\ndemonstrated on the MNIST dataset, where its performance conﬁrms that indeed\nDDFA is a viable technique for learning useful features.\n1\nIntroduction\nThe increasing realization in recent years that artiﬁcial neural networks (ANNs) can learn many\nlayers of features (Bengio et al., 2007; Cires¸an et al., 2010; Hinton et al., 2006; Marc’Aurelio et al.,\n2007) has reinvigorated the study of representation learning in ANNs (Bengio et al., 2013). While\nthe beginning of this renaissance focused on the sequential unsupervised training of individual layers\none upon another (Bengio et al., 2007; Hinton et al., 2006), the number of approaches and varia-\ntions that have proven effective at training in such deep learning has since exploded (Bengio et al.,\n2013; Schmidhuber et al., 2011). This explosion has in turn raised the question of what makes a\ngood representation, and how it is best learned (Bengio et al., 2013). The main contribution of this\npaper is to advance our understanding of good representation learning by suggesting a new princi-\nple for obtaining useful representations that is accompanied by a practical algorithm embodying the\nprinciple.\nThe feature representation obtained through learning algorithms is often impacted by the nature of\nthe training. For example, supervised approaches such as stochastic gradient descent (Cires¸an et al.,\n2010) that aim to minimize the error in a classiﬁcation problem in effect encourage the exclusive\ndiscovery of features that help to discriminate among the target classiﬁcations. In contrast, unsu-\npervised approaches, which include both generative representations such as restricted Boltzmann\nmachines (RBMs) (Hinton et al., 2006) and autoencoders that are trained to reproduce their inputs\n(Bengio et al., 2007), yield a more general feature set that captures dimensions of variation that may\nor may not be essential to the classiﬁcation objective. The hope of course is that such a set would\nnevertheless be useful for classiﬁcation in any case, and the pros and cons of e.g. generative versus\ndiscriminative features have proven both subtle and complex (Jaakkola et al., 1999; Ng and Jordan,\n2002). Nevertheless, one beneﬁt of unsupervised training is that it does not require labeled data to\ngain traction.\n1\narXiv:1406.1833v2  [cs.NE]  10 Jun 2014\nAn important insight in this paper is that there is an unrecognized option outside this usual unsuper-\nvised versus supervised (or generative versus discriminative) dichotomy. In particular, there is an\nalternative kind of discriminative learning that is unsupervised rather than supervised. In this pro-\nposed alternative approach, called divergent discriminative feature accumulation (DDFA), instead of\nsearching for features constrained by the objective of solving the discriminative classiﬁcation prob-\nlem, a learning algorithm can instead attempt to collect as many features that discriminate strongly\namong training examples as possible, without regard to any particular classiﬁcation problem.\nThe approach in such unsupervised discriminative learning is thus to search continually for novel\nfeatures that discriminate among training examples in new ways. Interestingly, unlike conventional\nalgorithms in deep learning, such a search is explicitly divergent by design and therefore continues\nto accumulate new features without converging. In effect, a high-scoring feature is therefore rele-\nvant to discriminating among the examples, even though the ultimate discrimination problem is not\nknown. A comprehensive set of such features that discriminate among the training set in fundamen-\ntal ways is thereby suitable in principle for later supervised training from those collected features\nfor any particular discrimination task. This idea is intuitive in the sense that even for humans, dis-\ntinctions among experiences can be learned before we know how we will apply such distinctions.\nFurthermore, as the results will show, if the search gradually shifts from simple to more complex\ndistinctions, only a small subset of all possible distinctions (many of which are obscure) needs to be\ndiscovered.\nIn fact, this perspective on feature learning has the advantage over more conventional approaches\nin deep learning that learning does not depend on a ﬁxed a priori number of features. Rather, it\nsimply continues to accumulate new features as long as the algorithm is run. Furthermore, unlike in\nother unsupervised approaches, the accumulated features are known explicitly to be discriminative,\nsuiting them well to later discriminative learning. Another potentially advantageous property of\nsuch a feature accumulator is its lack of convergence (thereby avoiding the problem of local optima),\nwhich stems from the fact that it is inherently divergent because it is not based on minimizing an\nerror. In these ways DDFA is uniquely ﬂexible and autonomous.\nThe driving force behind the feature accumulator is the imperative of ﬁnding novel features. Thus\na well-suited algorithm for implementing this idea in practice is the recent novelty search algorithm\n(Lehman and Stanley, 2011), which is a divergent evolutionary algorithm that is rewarded for mov-\ning away in the search space of candidate behaviors (such as discriminations) from where it has\nalready visited to where it has not. By accumulating features that are themselves ANNs, novelty\nsearch in this paper enables DDFA. As with other unsupervised pretraining approaches such as au-\ntoencoders, once DDFA determines that sufﬁcient features are collected, a classiﬁer is trained above\nthem for the classiﬁcation task (through backpropagation in this paper). To demonstrate the potential\nof DDFA to collect useful features, it is tested in this paper by collecting single-layer features for\nthe MNIST digital handwriting recognition benchmark (LeCun and Cortes, 1998). Even with the\nconsequent two-layer shallow classiﬁer network, its testing performance rivals more conventional\ntraining techniques.\nThis initial proof of concept establishes the efﬁcacy of accumulating features as a basis for rep-\nresentation learning. While the simple one-layer accumulated discriminative features from DDFA\nperform well, DDFA can conceivably improve further through layering (e.g. accumulating multi-\nlayer features or searching for novel features that are built above already-discovered features) and\nconvolution (LeCun and Bengio, 1995), just like other deep learning algorithms. Most importantly,\nbased on the novel representational principle that discriminators make good features for classiﬁca-\ntion problems, DDFA opens up a new class of learning approaches.\n2\nBackground\nThis section reviews the two algorithms, novelty search and HyperNEAT, that underpin the DDFA\napproach.\n2.1\nNovelty Search\nThe problem of collecting novel instances of a class is different from the more familiar problem of\nminimizing error. While error minimization aims at converging towards minima in the search space,\n2\ncollecting novelty requires diverging away from past discoveries and fanning out across the search\nspace in all directions that appear to lead towards further novelty. This fanning-out process is thus\nwell-suited to a population-based approach that accumulates and remembers novel discoveries to\nhelp push the search continually to even more novelty as it progresses. The novelty search algo-\nrithm (Lehman and Stanley, 2011) implements such a process in practice through an evolutionary\napproach, which naturally provides the population-driven context appropriate for ﬁnding novelty.\nHowever, it is important to note that novelty search is unlike even traditional evolutionary algo-\nrithms (EAs), which themselves are usually driven to converge to higher ﬁtness. In fact, while EAs\nare often viewed as an alternative approach to optimization, their natural capacity to diversify and\ncollect may instead better capture their practical potential to contribute to problems in learning.\nThe idea in novelty search is to reward candidates (by increasing their probability of reproduction)\nwho are behaviorally novel. If the candidates are ANNs as in the present study, then the word\n“behaviorally” becomes critical because it refers to what the discovered ANNs actually do (e.g.\nhow they discriminate) as opposed to just their underlying genetic representations (i.e. genomes),\nwhich may or may not do anything interesting. Thus discovering novel behaviors requires search\n(as opposed to just enumerating random sets of genes), thereby instantiating a nontrivial alternative\nto the traditional objective gradient.\nThis point is particularly important in the context of deep learning, where researchers have com-\nmented on the potential long-term limitations of optimization gradients and the need for a broader\nand less convergent approaches for learning representations. For example, when discussing the fu-\nture of representation learning, Bengio (2013) notes:\nThe basic idea is that humans (and current learning algorithms) are limited to\n“local descent” optimization methods, that make small changes in the parameter\nvalues with the effect of reducing the expected loss in average. This is clearly\nprone to the presence of local minima, while a more global search (in the spirit of\nboth genetic and cultural evolution) could potentially reduce this difﬁculty.\nNovelty search (Lehman and Stanley, 2011) can be viewed as an embodiment of just such a “genetic\nevolution” that is suited to accumulating discoveries free from the pitfalls of “local descent.” In\nfact, while novelty search was originally shown sometimes to ﬁnd the objective of an optimization\nproblem more effectively than objective-based optimization (Lehman and Stanley, 2011), Cully and\nMouret (2013) recently raised the intriguing notion of novelty search as a repertoire collector. That\nis, instead of searching for a solution to a problem, novelty search can collect a set of novel skills\n(each one a point in the search space) intended for later aggregation by a higher-level mechanism.\nThis repertoire-collecting idea aligns elegantly with the problem of accumulating features for deep\nlearning, wherein each feature detector can be viewed as a “skill” within the repertoire of a classiﬁer.\nIn practice, novelty search maintains an archive of previously novel discoveries as part of the algo-\nrithm. Future candidates are then compared to the archive to determine whether they too are novel.\nA random sampling of candidates is entered into the archive, which implies that more frequently-\nvisited areas will be more densely covered. Intuitively, if the average distance to the nearest neigh-\nbors of a given behavior b is large then it is in a sparse area; it is in a dense region if the average\ndistance is small. The sparseness ρ at point b is given by\nρ(x) = 1\nk\nk\nX\ni=0\ndist(b, µi),\n(1)\nwhere µi is the ith-nearest neighbor of b with respect to the distance metric dist, which is a domain-\ndependent measure of behavioral difference between two individuals in the search space. The nearest\nneighbors calculation must take into consideration individuals from the current population and from\nthe permanent archive of novel individuals. Candidates from more sparse regions of this behavioral\nsearch space then receive higher novelty scores, which lead to a higher chance of reproduction. It is\nimportant to note that this novelty space cannot be explored purposefully, that is, it is not known a\npriori how to enter areas of low density just as it is not known a priori how to construct a solution\nclose to the objective. Thus, moving through the space of novel behaviors requires exploration.\nThe gradient of novelty is interesting in particular because novel discoveries lead to other novel\ndiscoveries, which means that a search algorithm following gradients of novelty is likely to make\nmany interesting discoveries.\n3\n(a) Original Weight Pattern\n(b) HyperNEAT Mutation\n(c) Uniform Mutation\nFigure 1: Systematic Deformation in HyperNEAT-style Mutation. Each image depicts the pattern\nof weights projecting from a single 28 × 28 input ﬁeld to a single output node. The weight of a\nhypothetical feature (a) exhibits contiguity and some symmetry. The HyperNEAT style of mutation\n(b) perturbs the pattern of weights while still preserving the geometric regularities of the original\nfeature. In contrast, simply randomly mutating weights with uniform probability (c) leads to an\nincoherent corruption of the original feature.\nNovelty search in effect runs as a regular EA wherein novelty replaces ﬁtness as the criterion for\nselection, and an expanding archive of past novel discoveries is maintained. This simple idea will\nempower DDFA in this paper to accumulate a collection of novel features.\n2.2\nHyperNEAT\nThe term for algorithms that search for ANNs through an evolutionary process is neuroevolution\n(Floreano et al., 2008; Stanley and Miikkulainen, 2002). It is important to note that modern neu-\nroevolution algorithms are not like conventional EAs based on bit strings, but instead implement\na variety of sophisticated heuristics and encodings that enable the discovery of large and well-\norganized networks. This section is designed to introduce the particular neuroevolution algorithm\n(called HyperNEAT) that is combined with novelty search to search for features in this paper. Be-\ncause neuroevolution is an independent ﬁeld that may be unfamiliar to many in deep learning, this\nsection is written to emphasize the main ideas that make it appealing for the purpose of feature\nlearning, without including details that are unnecessary to understand the operation of the proposed\nDDFA algorithm. The complete details of HyperNEAT can be found in its primary sources (Gauci\nand Stanley, 2008, 2010; Stanley et al., 2009; Verbancsics and Stanley, 2010).\nIn a domain like visual recognition, the pattern of weights in useful features can be expected to\nexhibit a degree of contiguity and perhaps regularity. For example, it is unlikely that an entirely\nrandom pattern of largely unconnected pixels corresponds to a useful or interesting feature. It has\naccordingly long been recognized in neuroevolution that entirely random perturbations of weight\npatterns, which are likely to emerge for example from random mutations, are unlikely to maintain\ncontiguity or regularity. While stochastic gradient descent (SGD) algorithms at least justify their\ntrajectory through the search space through descent, a completely random perturbation of weights\nis arguably less principled and therefore perhaps less effective. Nevertheless, SGD still suffers to\nsome extent from the same problem that even a step that reduces error may not maintain contiguity\nor regularity in the feature geometry. Neuroevolution algorithms have responded to this concern\nwith a class of representations called indirect encodings (Stanley and Miikkulainen, 2003), wherein\nthe weight pattern is generated by an evolving genetic encoding that is biased towards contiguity\nand regularity by design. That way, when a mutation is applied to a feature, the feature deforms in a\nsystematic though still randomized fashion (ﬁgure 1).\nHyperNEAT, which stands for Hypercube-based NeuroEvolution of Augmenting Topologies (Gauci\nand Stanley, 2008, 2010; Stanley et al., 2009; Verbancsics and Stanley, 2010) is a contemporary\nneuroevolution algorithm based on such an indirect encoding. In short, HyperNEAT evolves an\nencoding network called a compositional pattern producing network (CPPN; Stanley 2007) that de-\nscribes the pattern of connectivity within the ANN it encodes. Therefore, mutations in HyperNEAT\nhappen to the CPPN, which then transfers their effects to the encoded ANN. In this way the CPPN\nis like DNA, which transfers the effects of its own mutations to the structures it encodes, such as the\nbrain. Because the CPPN encoding is designed to describe patterns of weights across the geometry\nof the encoded network, the weights in HyperNEAT ANNs tend to deform in contiguity-preserving\nand regularity-preserving ways (as seen in ﬁgure 1), thereby providing a useful bias (Gauci and\nStanley, 2010; Stanley et al., 2009). Furthermore, CPPNs in HyperNEAT grow over evolution (i.e.\ntheir structure is augmented over learning), which means that the pattern of weights in the ANN they\ndescribe (which is ﬁxed in size) can become more intricate and complex over time. For unfamiliar\nreaders, it is worth noting that this HyperNEAT style of representation for ANNs is well-established\n4\nand has appeared in mainstream venues such as AAAI (Gauci and Stanley, 2008), Neural Compu-\ntation (Gauci and Stanley, 2010), and JMLR (Verbancsics and Stanley, 2010).\nAn important observation is that HyperNEAT’s tendency to preserve geometric properties in its\nweights means that it is not invariant to permutations in the input vector. In effect (in e.g. the case of\nMNIST) it is exploiting the known two-dimensional geometry of the problem. However, at the same\ntime, while it does exploit geometry, its use in this paper is not convolutional either: its input ﬁeld\nis never broken into receptive ﬁelds and is rather projected in whole directly (without intervening\nlayers) to a single-feature output node. Thus the powerful advantage of convolution for visual prob-\nlems is not available in this investigation, making the problem more challenging. As a consequence,\nthe DDFA implementation in this paper does not ﬁt neatly into the permutation-invariant-or-not di-\nchotomy, and may be considered somewhere closer to typical permutation-invariant scenarios.\nThis overview of HyperNEAT is left brief because its other details (which are widely disseminated\nin the venues above) are not essential to the main idea in this paper, which is to accumulate feature\ndetectors through novelty search.\n3\nApproach: Divergent Discriminative Feature Accumulation (DDFA)\nUnsupervised pretraining in deep learning has historically focused on approaches such as autoen-\ncoders and RBMs (Bengio et al., 2007; Hinton et al., 2006) that attempt to reconstruct training\nexamples by ﬁrst translating them into a basis of features different from the inputs, and then from\nthose features regenerating the inputs. This idea is appealing because the imperative of reconstruc-\ntion demands that the learned features must ultimately reﬂect some aspect of the underlying structure\nof the training set. Of course, one potential problem with this approach is that there is no assurance\nthat the learned features actually align with any particular classiﬁcation or discrimination problem\nfor which they might be used in the future. Yet this conventional approach to learning features also\nraises some interesting deeper questions. For example, is there any other way to extract meaningful\nfeatures and thereby learn representations from a set of examples without explicit supervision?\nThere are some well-known simple alternatives, though they are not usually characterized as feature-\nlearning algorithms. For example clustering algorithms such as K-means or Gaussian mixture mod-\nels in effect extract structure from data that can then assist in classiﬁcation; in fact at least one study\nhas shown that such clustering algorithms can yield features as effective or more so for classiﬁcation\nthan autoencoders or RBMs (Coates et al., 2011). This result highlights that reconstruction is not\nthe only effective incentive for extracting useful structure from the world.\nThe approach introduced here goes beyond simple clustering by emphasizing the general ability to\nlearn diverse distinctions. That is, while one can learn how to describe the world, one can also learn\nhow different aspects of the world relate to each other. Importantly, there is no single “correct” view\nof such relations. Rather, a rich set of learned relationships can support drawing important distinc-\ntions later. For example, in one view palm trees and “regular” trees share properties that distinguish\nthem from other plants. However, in another view, palm trees are in fact distinct from regular trees.\nBoth such views can be useful in understanding nature, and one can hold both simultaneously with\nno contradiction. When an appropriate question comes up, such as which plants are tall and decora-\ntive, the feature tall becomes available because it was learned to help make such general distinctions\nabout the world in the past.\nThe idea in DDFA is to continually accumulate such distinctions systematically through novelty\nsearch, thereby building an increasingly rich repertoire of features that help divide and relate obser-\nvations of the world. Speciﬁcally, suppose there are n training examples {x(1), ..., x(n)}; whether or\nnot they are labeled will not matter because feature learning will be unsupervised. Suppose also that\nany single feature detector hi (i.e. a single hidden node that detects a particular feature) outputs a\nreal number whose intensity represents the degree to which that feature is present in the input. It fol-\nlows that hi will assign a real number h(t)\ni\nto every example x(t) depending on the degree to which\nx(t) contains the feature of interest for hi. The output of hi for all features x(t) where t = 1, . . . , n\nthereby forms a vector {h(1)\ni , . . . , h(n)\ni\n} that can be interpreted as the signature of feature detector\nhi across the entire training set. In effect the aim is to continually discover new such signatures.\nThis problem of continually discovering novel signatures is naturally captured by novelty search,\nwhich can be set up explicitly to evolve feature detectors hi, each of which takes a training example\n5\nas input and returns a single output. The signature {h(1)\ni , ..., h(n)\ni\n} of hi over all training examples is\nthen its behavior characterization for novelty search. The novelty of the signature is then measured\nby comparing it to the k-nearest signatures in the novelty archive, following equation 1. Novelty\nsearch then dictates that more novel features are more likely to reproduce, which means that gra-\ndients of novel signatures will be followed in parallel by the evolving population. Those features\nwhose sparseness ρ (i.e. novelty) exceeds a minimum threshold ρmin are stored in the growing novel\nfeature collection for later classiﬁer training.\nA likely source of confusion is the question of whether DDFA is a kind of exhaustive search over\nsignatures, which would not tend to discover useful features in a reasonable runtime. After all,\nthe number of theoretically possible distinctions is exponential in the number of training examples.\nHowever, a critical facet of novelty-based searches that are combined with HyperNEAT-based neu-\nroevolution is that the complexity of features (and hence distinctions) tends to increase over the run\n(Lehman and Stanley, 2011). As a result, the initial features discovered encompass simple principles\n(e.g. is the left side of the image dark?) that gradually increase in complexity. For this reason, the\nmost arbitrary and incoherent features (e.g. are there 17 particular dots at speciﬁc non-contiguous\ncoordinates in the image?) are possible to discover only late in the search. Furthermore, because the\nnovelty signature is measured over the training set, features that make broad separations relevant to\nthe training set itself are more likely to be discovered early. In effect, over the course of DDFA, the\nfeature discoveries increasingly shift from simple principles to intricate minutia. Somewhere along\nthis road are likely diminishing returns, well before all possible signatures are discovered. Empirical\nresults reported here support this point.\nInterestingly, because DDFA does not depend on the minimization of error, in principle it can con-\ntinue to collect features virtually indeﬁnitely, but in practice at some point its features are fed into a\nclassiﬁer that is trained from the collected discriminative features.\n4\nExperiment\nThe key question addressed in this paper is whether a divergent discriminative feature accumulator\ncan learn useful features, which means they should aid in effective generalization on the test set. If\nthat is possible, the implication is that DDFA is a viable alternative to other kinds of unsupervised\npretraining. To investigate this question DDFA is trained and tested on the MNIST handwritten digit\nrecognition dataset (LeCun and Cortes, 1998), which consists of 60,000 training images and 10,000\ntest images. Therefore, the signature of each candidate feature discovered by DDFA during training\nis a vector of 60,000 real values.\nBecause the structure of the networks that are produced by HyperNEAT can include as many hidden\nlayers as the user chooses, the question arises how many hidden layers should be allowed in indi-\nvidual features hi learned by HyperNEAT. This consideration is substantive because in principle\nDDFA can learn arbitrarily-deep individual features all at once, which is unlike e.g. the layer-by-\nlayer training of a deep stack of autoencoders. However, the explicit choice was made in this intro-\nductory experiment to limit DDFA to single-layer features (i.e. without hidden nodes) to disentangle\nthe key question of whether the DDFA process represents a useful principle from other questions\nof representation such as the implications of greater depth. Therefore, feature quality is addressed\nstraightforwardly in this study by observing the quality of classiﬁer produced based only on single-\nlayer DDFA features. As a result, the ﬁnal classiﬁer ANN has just two layers: the layer of collected\nfeatures and the ten-unit output layer for classifying MNIST digits.\nThe single-layer DDFA approach with novelty search and HyperNEAT is difﬁcult to align directly\nwith common deep learning approaches in part because of its lack of permutation invariance even\nthough it is not convolutional in any sense (thereby lacking the representational power of such net-\nworks), and its lack of depth in this initial test. Thus to get a fair sense of whether DDFA learns\nuseful features it is most illuminating to contrast it with the leading result on an equivalently shallow\ntwo-layer architecture (which are rare in recent years) that similarly avoided special preprocessing\nlike elastic distortions or deskewing. In particular, Simard et al. (2003) obtained one of the best such\nresults of 1.6% test error performance. Thus a signiﬁcant improvement on that result would suggest\nthat DDFA generates useful features that help to stretch the capacity of such a shallow network to\ngeneralize. DDFA’s further ability to approach the performance of conventional vanilla deep net-\nworks, such as the original 1.2% result from Hinton et al. (2006) on a four-layer network pretrained\nby a RBM, would hint at DDFA’s potential utility in the future for pretraining deeper networks.\n6\nFeatures\nDDFA Test Error\nRandom CPPNs Control\nRandom Weights Control\n1,500\n1.42%\n1.63%\n2.21%\n3,000\n1.25%\n1.61%\n2.00%\nTable 1: MNIST Testing Error Rates of DDFA and Controls.\nFigure 2: Example Collected Features. Each square is a weight pattern for an actual feature\ndiscovered by DDFA in which white is negative and black is positive. As these examples show,\nfeatures range from simple line orientation detectors reminiscent of those found in the lower levels\nof conventional deep networks (towards left) to more complex shapes (towards right).\nDuring the course of evolution, features are selected for reproduction based on their signature’s nov-\nelty score (sparseness ρ) calculated as the sum of the distances to the k-nearest neighbors (k = 20),\nwhere neighbors include other members of the population as well as the historical novelty archive.\nAt the end of each generation, each individual in the population (size = 100) has a 1% chance of be-\ning added to the novelty archive, resulting in an average of 1 individual added to the novelty archive\non each generation. Separately, a list of individuals called the feature list is maintained. At the end\nof each generation, each member of the population is scored against the current feature list by ﬁnd-\ning the distance to the nearest neighbor (k = 1), where neighbors are members of the feature list.\nThose individuals that score above a threshold ρmin = 2,000 are added to the feature list. In effect,\nthe feature list is constructed in such a way that all collected features have signatures that differ by\nat least ρt from all others in the collection. This threshold-based collection process protects against\ncollecting redundant features. A simple variant of HyperNEAT called HyperNEAT-LEO (Verbanc-\nsics and Stanley, 2011) (which leads to less connectivity) was the main neuroevolution engine. The\nHyperNEAT setup and parameters can be easily reproduced in full because they are simply the\ndefault parameters of the SharpNEAT 2.0 publicly-available package (Green, 2003–2014).\nTo observe the effect of collecting different numbers of features, DDFA was run separately until\nboth 1,500 and 3,000 features were collected. After collection concludes, a set of ten classiﬁcation\nnodes is added on top of the collected features, and simple backpropagation training commences.\nThe training and validation procedure mirrors that followed by Hinton et al. (2006): ﬁrst training is\nrun on 50,000 examples for 50 epochs to ﬁnd the network that performs best on a 10,000-example\nvalidation set. Then training shifts to the full 60,000-example set, which is trained until it reaches\nthe same training error as in the best validation epoch. The resulting network is ﬁnally tested on the\nfull 10,000-example test set. This whole procedure is similar to how autoencoders are trained before\ngradient descent in deep learning (Bengio et al., 2007).\n5\nResults\nThe main results are shown in Table 1. DDFA was able to achieve test errors of 1.42% and 1.25%\nfrom collections of 1,500 and 3,000 features, respectively, which are both well below the 1.6% error\nof the similar shallow network trained without preprocessing from Simard et al. (2003). In fact,\nthe result for the 3,000-feature network even approaches the 1.2% error of the signiﬁcantly deeper\nnetwork of Hinton et al. (2006), showing that shallow networks can generalize surprisingly well by\nﬁnding sufﬁciently high-quality feature sets, even despite a lack of exposure to distortions during\ntraining. It also appears that more collected features lead to better generalization, at least at these\nsizes. It took 338 and 676 generations of feature collection to obtain the 1,500 and 3,000 features,\nrespectively. Collecting 3,000 features took about 36 hours of computation on 12 3.0 GHz cores.\nFigure 2 shows a typical set of features collected by DDFA. Interestingly, unlike the bottom layer of\ndeep learning networks that typically exhibit various line-orientation detectors, DDFA also collects\nmore complex features because newer features of increasing complexity evolve from older features.\n7\nTo rule out the possibility that the reason for the testing performance is simply the HyperNEAT-\nbased encoding of features, a random CPPN control was also run. It follows an identical procedure\nfor training and testing, except that novelty scores and adding to the feature list during the feature\naccumulation phase are decided randomly, which means the ﬁnal collection in effect contained ran-\ndom features with a range of CPPN complexity similar to the normal run. To further investigate the\nvalue of the HyperNEAT representation, an additional random weights control was tested whose\nweights were assigned from a uniform random distribution, bypassing HyperNEAT entirely. As the\nresults in Table 1 show, the CPPN encoding in HyperNEAT provides a surprisingly good basis for\ntraining even when the features are entirely randomly-generated. However, they are still inferior to\nthe features collected by normal DDFA. As shown in the last column, without HyperNEAT, test-\ning performance with a collection of random features is unsurprisingly poor. In sum these controls\nshow that the pretraining in DDFA is essential to priming the later classiﬁer for the best possible\nperformance.\n6\nDiscussion and Future Work\nThe results suggest that DDFA can indeed collect useful features and thereby serve as an alternative\nunsupervised feature learner. While it may ultimately lead to better training performance in some\ncutting-edge problems, future work with more layers and on larger problems is clearly necessary to\ninvestigate its full potential for exceeding top results.\nHowever, it is important to recognize that signiﬁcantly more than performance is at stake in the dis-\nsemination of alternative unsupervised training techniques based on new principles. Deep learning\nfaces several fundamental challenges that are not only about testing performance. For example, re-\ncent surprising results from Szegedy et al. (2013) show that very small yet anomalous perturbations\nof training images that are imperceptible to the human eye can fool several different kinds of deep\nnetworks that nevertheless ominously score well on the test set. The implications of these anomalies\nare not yet understood. At the same time, as Bengio (2013) points out, local descent on its own will\nnot ultimately be enough to tackle the most challenging problems, suggesting the need for radical\nnew kinds of optimization that are more global. These kinds of considerations suggest that simply\nscoring well on a test set in the short run may not necessarily foreshadow continuing success for the\nﬁeld in the long run.\nTherefore, the expanded possibilities that a validated new principle can inspire are essential to the\nhealth of an evolving ﬁeld, whether or not it ultimately breaks a particular benchmark record. For\nexample, DDFA shows that unsupervised discriminative learning is possible and can be effective,\nbringing with it several intriguing corrollaries. Among those, it is possible to conceive training\nmethods that act as continual feature accumulators that do not require a ﬁxed “hidden layer size.”\nFurthermore, it is possible to learn useful features without any kind of error minimization (which is\neven used in conventional unsupervised techniques). Relatedly, an interesting question is whether\nanomalous results are sometimes a side effect of the very idea that all useful knowledge ultimately\nmust come from minimizing error. The divergent dynamics of novelty search also mean that the\nsearch is inherently more global than local descent for the very reason that it is continually diverging,\nthereby offering a hint of how more expansive feature sets can be collected. Thus, in addition to the\nmany possibilities for training multilayer deep features in DDFA, another important path for future\nwork is to investigate the long-term implications of these more subtle differences from conventional\ntechniques, and to determine whether similar such unique properties can be introduced to deep\nlearning through non-evolutionary techniques that follow gradients other than error.\nReferences\nBengio, Y. (2013). Deep learning of representations: Looking forward. In Statistical Language and\nSpeech Processing, 1–37. Springer.\nBengio, Y., Courville, A., and Vincent, P. (2013).\nRepresentation learning: A review and new\nperspectives. IEEE transactions on pattern analysis and machine intelligence, 1798–1928.\nBengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007). Greedy layer-wise training of deep\nnetworks. In Advances in Neural Information Processing Systems 19 (NIPS). Cambridge, MA:\nMIT Press.\n8\nCires¸an, D., Meier, U., Gambardella, L., and Schmidhuber, J. (2010). Deep, big, simple neural nets\nfor handwritten digit recognition. Neural computation, 22(12):3207–3220.\nCoates, A., Ng, A. Y., and Lee, H. (2011). An analysis of single-layer networks in unsupervised\nfeature learning. In International Conference on Artiﬁcial Intelligence and Statistics, 215–223.\nCully, A., and Mouret, J.-B. (2013). Behavioral repertoire learning in robotics. In Proceeding of the\nﬁfteenth annual conference on Genetic and evolutionary computation conference, GECCO ’13,\n175–182. New York, NY, USA: ACM.\nFloreano, D., D¨urr, P., and Mattiussi, C. (2008). Neuroevolution: from architectures to learning.\nEvolutionary Intelligence, 1:47–62.\nGauci, J., and Stanley, K. O. (2008). A case study on the critical role of geometric regularity in\nmachine learning. In Proceedings of the Twenty-Third AAAI Conference on Artiﬁcial Intelligence\n(AAAI-2008). Menlo Park, CA: AAAI Press.\nGauci, J., and Stanley, K. O. (2010). Autonomous evolution of topographic regularities in artiﬁcial\nneural networks. Neural Computation, 22(7):1860–1898.\nGreen, C. (2003–2014). SharpNEAT homepage. http://sharpneat.sourceforge.net/.\nHinton, G. E., Osindero, S., and Teh, Y.-W. (2006). A fast learning algorithm for deep belief nets.\nNeural Computation, 18(7):1527–1554.\nJaakkola, T., Haussler, D., et al. (1999). Exploiting generative models in discriminative classiﬁers.\nAdvances in neural information processing systems, 487–493.\nLeCun, Y., and Bengio, Y. (1995). Convolutional networks for images, speech, and time-series. In\nArbib, M. A., editor, The Handbook of Brain Theory and Neural Networks. MIT Press.\nLeCun, Y., and Cortes, C. (1998). The mnist database of handwritten digits.\nLehman, J., and Stanley, K. O. (2011). Abandoning objectives: Evolution through the search for\nnovelty alone. Evolutionary Computation, 19(2):189–223.\nMarc’Aurelio, R., Boureau, L., and LeCun, Y. (2007). Sparse feature learning for deep belief net-\nworks. In Advances in Neural Information Processing Systems 20 (NIPS), 1185–1192. Cam-\nbridge, MA: MIT Press.\nNg, A. Y., and Jordan, M. I. (2002). On discriminative vs. generative classiﬁers: A comparison of\nlogistic regression and naive bayes. Advances in neural information processing systems, 2:841–\n848.\nSchmidhuber, J., Cires¸an, D., Meier, U., Masci, J., and Graves, A. (2011). On fast deep nets for agi\nvision. In The Fourth Conference on Artiﬁcial General Intelligence (AGI), 243–246. New York,\nNY: Springer.\nSimard, P., Steinkraus, D., and Platt, J. C. (2003). Best practices for convolutional neural networks\napplied to visual document analysis. In International Conference on Document Analysis and\nRecogntion (ICDAR), vol. 3, 958–962.\nStanley, K. O. (2007). Compositional pattern producing networks: A novel abstraction of develop-\nment. Genetic Programming and Evolvable Machines Special Issue on Developmental Systems,\n8(2):131–162.\nStanley, K. O., D’Ambrosio, D. B., and Gauci, J. (2009). A hypercube-based indirect encoding for\nevolving large-scale neural networks. Artiﬁcial Life, 15(2):185–212.\nStanley, K. O., and Miikkulainen, R. (2002). Evolving neural networks through augmenting topolo-\ngies. Evolutionary Computation, 10:99–127.\nStanley, K. O., and Miikkulainen, R. (2003). A taxonomy for artiﬁcial embryogeny. Artiﬁcial Life,\n9(2):93–130.\nSzegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. J., and Fergus, R.\n(2013). Intriguing properties of neural networks. CoRR, abs/1312.6199.\nVerbancsics, P., and Stanley, K. O. (2010). Evolving static representations for task transfer. Journal\nof Machine Learning Research (JMLR), 11:1737–1769.\nVerbancsics, P., and Stanley, K. O. (2011).\nConstraining connectivity to encourage modularity\nin HyperNEAT. In GECCO ’11: Proceedings of the 13th annual conference on Genetic and\nevolutionary computation, 1483–1490. Dublin, Ireland: ACM.\n9\n",
  "categories": [
    "cs.NE",
    "cs.LG"
  ],
  "published": "2014-06-06",
  "updated": "2014-06-10"
}