{
  "id": "http://arxiv.org/abs/1408.2466v1",
  "title": "Controlled Natural Language Processing as Answer Set Programming: an Experiment",
  "authors": [
    "Rolf Schwitter"
  ],
  "abstract": "Most controlled natural languages (CNLs) are processed with the help of a\npipeline architecture that relies on different software components. We\ninvestigate in this paper in an experimental way how well answer set\nprogramming (ASP) is suited as a unifying framework for parsing a CNL, deriving\na formal representation for the resulting syntax trees, and for reasoning with\nthat representation. We start from a list of input tokens in ASP notation and\nshow how this input can be transformed into a syntax tree using an ASP grammar\nand then into reified ASP rules in form of a set of facts. These facts are then\nprocessed by an ASP meta-interpreter that allows us to infer new knowledge.",
  "text": "arXiv:1408.2466v1  [cs.CL]  15 Jul 2014\nControlled Natural Language Processing as\nAnswer Set Programming: an Experiment\nRolf Schwitter\nDepartment of Computing\nMacquarie University\nSydney NSW 2109, Australia\nRolf.Schwitter@mq.edu.au\nAbstract. Most controlled natural languages (CNLs) are processed with\nthe help of a pipeline architecture that relies on diﬀerent software com-\nponents. We investigate in this paper in an experimental way how well\nanswer set programming (ASP) is suited as a unifying framework for\nparsing a CNL, deriving a formal representation for the resulting syntax\ntrees, and for reasoning with that representation. We start from a list\nof input tokens in ASP notation and show how this input can be trans-\nformed into a syntax tree using an ASP grammar and then into reiﬁed\nASP rules in form of a set of facts. These facts are then processed by an\nASP meta-interpreter that allows us to infer new knowledge.\nKeywords: Answer Set Programming, Controlled Natural Language\nProcessing, Meta-programming\n1\nIntroduction\nControlled natural languages (CNLs) are subsets of natural languages whose\ngrammars and vocabularies have been restricted in order to eliminate ambiguity\nand complexity of natural languages for automated reasoning [11,17]. These\nCNLs are engineered for a speciﬁc purpose and look seemingly informal like\nnatural languages, but they have by design the same properties as their formal\ntarget languages. Typically, the writing process of a CNL is supported by an\nauthoring tool that guides the writing of a text or a question by a feedback\nmechanism [4,10,14,16].\nMost existing CNLs are processed with the help of a pipeline architecture\nthat relies on diﬀerent software components for parsing and translating the CNL\ninput into a formal representation before this representation can be processed by\nan automated reasoning service [2,5]. In this paper, we investigate in an experi-\nmental way whether answer set programming (ASP) can be used as a unifying\nframework for CNL processing, knowledge representation and automated rea-\nsoning. After a brief introduction to the ASP paradigm in Section 2, we show\nin Section 3 how grammar rules for a CNL can be written in ASP and how\nCNL sentences can be parsed into a syntax tree. In Section 4, we discuss how a\nformal representation can be generated for these syntax trees. In Section 5, we\n2\nRolf Schwitter\nillustrate how this representation can be used for reasoning in ASP with the help\nof a meta-interpreter. In Section 6, we summarise our ﬁndings and conclude.\n2\nAnswer Set Programming (ASP)\nASP is a form of declarative programming that has its roots in logic program-\nming, disjunctive databases and non-monotonic reasoning [1,13]. ASP provides\nan expressive formal language for knowledge representation and automated rea-\nsoning and is based on the answer set semantics for logic programs [7,8]. In ASP,\nproblems are represented in terms of ﬁnite logic theories and these problems are\nsolved by reducing them to ﬁnding answer sets which declaratively describe the\nsolutions to these problems. An ASP program consists of a set of rules of the\nform:\n1.\nh1 ;...; hm :- b1,..., bn, not bn+1,..., not bo.\nwhere hi and bi are classical literals (li). A classical literal l is either an atom\na or a negated atom -a. A literal of the form not l is a negation as failure literal.\nThe disjunction (;) is interpreted as epistemic disjunction [9]. The part on the\nleft of the implication (:-) is the head of the rule and the part on the right is the\nbody of the rule. If the body is empty (o=0), then we omit the symbol for the\nimplication and end up with a fact. If the head is empty (m=0), then we keep the\nsymbol for the implication and end up with an integrity constraint. Note that\nASP distinguishes between strong negation (-) and weak negation (not); these\ntwo forms of negation build the prerequisites for non-monotonic reasoning [9].\nFor example, the ASP program in (2) consists of two rules, six facts and one\nintegrity constraint:\n2. successful(X) :- student(X), work(X), not absent(X).\n-work(X) :- student(X), not work(X).\nstudent(john). work(john). student(sue). work(sue).\nstudent(mary_ann). absent(mary_ann).\n:- student(X), cheat(X), successful(X).\nThis program can be processed by an ASP tool such as clingo [6] that computes\nthe following answer set:\n3. { student(john) work(john) student(sue) work(sue) student(mary_ann)\nabsent(mary_ann) successful(sue) successful(john) -work(mary_ann) }\nWe call an ASP program satisﬁable, if it has at least one answer set. Through\ninspection of the above answer set, we can immediately see that John and Sue\nare successful and that Mary Ann does not work. Note that the second rule in\n(2) speciﬁes the closed world assumption [15] for the literal work/1. If we add\nthe following facts to our program:\n4. student(ray). work(ray). cheat(ray).\nthen we end up with an unsatisﬁable program since the situation in (4) is ex-\ncluded by the constraint in (2).\nCNL Processing as Answer Set Programming: an Experiment\n3\n3\nWriting a CNL Grammar in ASP\nThe CNL that we will use in the following discussion is similar to Processable\nEnglish (PENG) [18] and to Attempto Controlled English (ACE) [5], but the lan-\nguage is less expressive since ASP does not support full ﬁrst-order logic (FOL).\nHowever, ASP is still expressive enough to represent function-free FOL formulas\nof the ∃∗∀∗preﬁx class in form of a logic program [12]. The following text (5) is\nwritten in CNL and expresses the same information as the ASP program in (2):\n5. Every student who works and who is not provably absent is successful.\nIf a student does not provably work then the student does not work.\nJohn is a student who works.\nSue is a student and works.\nMary Ann who is a student is absent.\nExclude that a student who cheats is successful.\nIn order to process this text in ASP, we split it into a sequence of sentences\nand each sentence into a sequence of tokens. Each token is represented in ASP\nas a fact (token/4) with four arguments: the ﬁrst argument holds the string, the\nsecond argument holds the sentence number, and the third and fourth argument\nrepresent the start and the end position of the string, for example:\n6. token(\"Every\", 1, 1, 2). token(\"student\", 1, 2, 3).\n...\nEach string is stored as a fact (lexicon/5) in the ASP lexicon that distin-\nguishes between function words and content words. Function words (e.g., and,\nevery, who) deﬁne the structure of the CNL and content words (e.g., student,\nworks, successful) are used to express the domain knowledge. These lexical en-\ntries contain information about the category, the string, the base form, as well\nas syntactic and semantic constraints (n stands for nil):\n7. lexicon(cnj, \"and\", n, n, n).\nlexicon(det, \"Every\", n, sg, forall).\nlexicon(rp, \"who\", n, n, n).\nlexicon(noun, \"student\", student, sg, n).\nlexicon(iv, \"works\", work, sg, n).\nlexicon(adj, \"successful\", successful, n, n).\nWe can write the grammar for the CNL directly as a set of ASP rules that\ngenerate a syntax tree bottom-up, starting from the tokens up to the root. Let\nus have a look at the grammar rules that process the ﬁrst sentence in (5). This\nsentence is interesting, since it contains a coordinated relative clause that is em-\nbedded in the main sentence. The ﬁrst relative clause who works is positive, and\nthe second relative clause who is not provably absent contains a weak negation.\nIt is important to note that this form of negation can only occur in a univer-\nsally quantiﬁed CNL sentence or in a CNL sentence that results in an integrity\nconstraint.\nThe grammar rule (rule/7) speciﬁes in a declarative way that a sentence (s)\nstarts at position P1 and ends at position P4, if there is a noun phrase (np) that\nstarts at P1 and ends at P2, followed by a verb phrase (vp) that starts at P2 and\nends at P3, followed by a punctuation mark (pm) between position P3 and P4:\n4\nRolf Schwitter\n8. rule(s, s(T1, T2, T3), n, n, N, P1, P4)\n:-\nrule(np, T1, Y, n, N, P1, P2),\nrule(vp, T2, Y, n, N, P2, P3),\nrule(pm, T3, n, n, N, P3, P4).\nThe second argument position of this rule is used to build up a syntax tree,\nthe third argument position is used for syntactic constraints, the fourth for\nsemantic constraints, and the ﬁfth for the sentence number. The variable Y in\n(8) is used to enforce number agreement between the np and the vp.\nThe following grammar rule in (9) further describes the noun phrase of our\nexample sentence. This noun phrase (np) consists of a determiner (det), followed\nby a nominal expression (n1). The variable M holds a quantiﬁer that controls –\nas we will see later – the use of weak negation in our example sentence:\n9. rule(np, np(T1, T2), Y, n, N, P1, P3) :-\nrule(det, T1, Y, M, N, P1, P2),\nrule(n1, T2, Y, M, N, P2, P3).\nThe nominal expression (n1) expands in our case into a noun (noun) and a\nrelative clause (rcl):\n10. rule(n1, n1(T1, T2), Y, M, N, P1, P3) :-\nrule(noun, T1, Y, n,\nN, P1, P2),\nrule(rcl, T2, Y, M, N, P2, P3).\nThe noun (noun) is a preterminal category and processes the input token\n(token/4) with the help of the lexical information (lexicon/5):\n11. rule(noun, noun(S), Y, n, N, P1, P2) :-\ntoken(S, N, P1, P2),\nlexicon(noun, S, B, Y, n).\nNote that the relative clause in our example sentence is coordinated and\nconsists of a positive and a negative part. The grammar rule in (12) for relative\nclauses (rcl) deals with this coordinated structure. In contrast to the positive\npart, we use the variable M in the negative part of the coordinated structure to\nenforce that this form of negation occurs under universal quantiﬁcation (addi-\ntional grammar rules exist that deal with relative clauses where the order of the\npositive and negative part is diﬀerent):\n12. rule(rcl, rcl(T1, T2, T3), Y, M, N, P1, P4) :-\nrule(rcl, T1, Y, n, N, P1, P2),\nrule(cnj, T2, n, n, N, P2, P3),\nrule(rcl, T3, Y, M, N, P3, P4).\nAs the following two grammar rules in (13) illustrate, the relative clause\nexpands in both cases into a relative pronoun (rp) followed by a verb phrase\n(vp): the ﬁrst vp occurs without a variable (n) at the fourth argument position\nand the second vp occurs with a variable (M) that holds the quantiﬁer:\n13. rule(rcl, rcl(T1, T2), Y, n, N, P1, P3) :-\nrule(rp, T1, n, n, N, P1, P2),\nrule(vp, T2, Y, n, N, P2, P3).\nCNL Processing as Answer Set Programming: an Experiment\n5\nrule(rcl, rcl(T1, T2), Y, M, N, P1, P3) :-\nrule(rp, T1, n, n, N, P1, P2),\nrule(vp, T2, Y, M, N, P2, P3).\nThe ﬁrst verb phrase (vp) in (13) expands into an intransitive verb (iv):\n14. rule(vp, vp(T1), Y, n, N, P1, P2) :-\nrule(iv, T1, Y, n, N, P1, P2).\nand the second verb phrase (vp) expands into a copula (cop), followed by a weak\nnegation (naf) and an adjective (adj):\n15. rule(vp, vp(T1, T2, T3), Y, M, N, P1, P4) :-\nrule(cop, T1, Y, n, N, P1, P2),\nrule(naf, T2, n, M, N, P2, P3),\nrule(adj, T3, n, n, N, P3, P4).\nAs we have seen, weak negation is expressed on the surface level of the CNL\nwith the help of the key phrase not provably. The rule (naf) in (16) processes\nthis key phrase if it occurs in the scope of a universal quantiﬁer (forall):\n16. rule(naf, naf(T1, adv(\"provably\")), n, forall, N, P1, P3) :-\nrule(neg, T1, n, n, N, P1, P2),\nrule(adv, adv(\"provably\"), n, n, N, P2, P3).\nWe still have to deal with the verb phrase (vp) on the sentence level that is\npart of rule (8). This verb phrase expands into a copula (cop), followed by an\nadjective (adj):\n17. rule(vp, vp(T1, T2), Y, n, N, P1, P3) :-\nrule(cop, T1, Y, n, N, P1, P2),\nrule(adj, T2, n, n, N, P2, P3).\nIn ASP, these grammar rules are processed bottom-up and during this model\ngeneration process the following syntax tree is produced for our example sen-\ntence:\n18. s(np(det(\"Every\"),\nn1(noun(\"student\"),\nrcl(rcl(rp(\"who\"),\nvp(iv(\"works\"))),\ncnj(\"and\"),\nrcl(rp(\"who\"),\nvp(cop(\"is\"),\nnaf(neg(\"not\"),\nadv(\"provably\")),\nadj(\"absent\")))))),\nvp(cop(\"is\"),\nadj(\"successful\")),\npm(\".\"))\n6\nRolf Schwitter\nThis syntax tree needs to be translated into a suitable ASP representation for\nautomated reasoning as we will see in Section 4.\nBefore we do this, please note that it is relatively straightforward to generate\nlook-ahead information that informs the author about the admissible input. To\ngenerate look-ahead information, we add one or more dummy tokens that contain\na special string ($lah$) to the last input token, for example:\n19. token(\"Every\", 1, 1, 2).\ntoken(\"student\", 1, 2, 3).\ntoken(\"$lah$\", 1, 3, 4).\nAdditionally, we add for each category a lexical entry that contains this special\nstring, for example:\n20. lexicon(iv, \"$lah$\", n, sg, n).\nThe following ASP rules in (21) are then used to collect those syntax tree\nfragments that span the input string and contain look-ahead information. The\nlast rule in (21) is a constraint and makes sure that the entire input string is\nconsidered:\n21. lah(C, T, Y, M, N, 1, P2) :-\nrule(C, T, Y, M, N, 1, P2),\nend_pos(P2, N).\nlah :-\nlah(C, T, Y, M, N, 1, P2),\nend_pos(P2, N).\n-end_pos(P2, N1) :-\ntoken(\"$lah$\", N1, P1, P2),\ntoken(\"$lah$\", N2, P3, P4),\nN1 <= N2, P2 < P4.\nend_pos(P2, N) :-\ntoken(\"$lah$\", N, P1, P2),\nnot -end_pos(P2, N).\n:- not lah.\nIn our example, the addition of the ﬁrst token (token(\"$lah$\", 1, 3, 4))\nin (19) results in an unsatisﬁable program. The addition of a further token\n(token(\"$lah$\", 1, 4, 5)) results in two tree fragments that span the input\nstring. From these trees, we can extract the relevant look-ahead information.\n4\nFrom Syntax Trees to Reiﬁed ASP Rules\nWe choose an indirect encoding for ASP rules where rules are reiﬁed as facts. This\nkind of encoding is necessary since there exists no mechanism within ASP that\nwould allow us to assert new rules. The reiﬁed rules are then further processed\nCNL Processing as Answer Set Programming: an Experiment\n7\nby an ASP meta-interpreter as we will see in Section 5. A reiﬁed rule consists\nof up to four diﬀerent fact types: a fact type (rule/1) for the identiﬁcation of\nthe rule, a fact type (head/2) for the head of the rule, a fact type (pbl/2) for\npositive body literals (if any), and a fact type (nbl/2) for negative body literals\n(if any). For example, the translation of the syntax tree in (18) will result in the\nfollowing encoding:\n22. rule(1).\nhead(1, lit(func(successful), arg(sk(1)))).\npbl(1, lit(func(work), arg(sk(1)))).\npbl(1, lit(func(student), arg(sk(1)))).\nnbl(1, lit(func(absent), arg(sk(1)))).\nThe fact type (rule/1) stores the rule number (1). This rule number occurs as\nﬁrst argument in the other fact types and speciﬁes rule membership. The actual\nliterals that belong to a rule are encoded with the help of the term lit/2 where\nthe ﬁrst argument (e.g., func(successful)) is the functor name of the literal and\nthe second argument (arg(sk(1))) represents a Skolem constant1 that replaces\nthe variable in the literal. Note that all facts that have been derived from rules\nneed to be grounded and cannot contain any variables.\nIn the following, we will show in detail how the syntax tree in (18) is trans-\nlated into the proposed ASP notation for rules in (22). The syntax tree is ﬁrst\nsplit into three main parts: a part (to qnt/3) to be translated into a quantiﬁer, a\npart (to body/3) to be translated into a rule body, and a part (to head/3) to be\ntranslated into a rule head. In our case, these parts correspond to the determiner\n(det), the nominal expression (n1), and the verb phrase (vp) of the ﬁrst sentence\nin (5):\n23. to_qnt(N, det(\"Every\"), M) :-\nrule(det, det(\"Every\"), Y, M, N, P1, P2),\nrule(n1, T2, Y, M, N, P2, P3),\nrule(vp, T3, Y, n, N, P3, P4).\nto_body(N, T2, M) :-\nrule(det, det(\"Every\"), Y, M, N, P1, P2),\nrule(n1, T2, Y, M, N, P2, P3),\nrule(vp, T3, Y, n, N, P3, P4).\nto_head(N, T3, M) :-\nrule(det, det(\"Every\"), Y, M, N, P1, P2),\nrule(n1, T2, Y, M, N, P2, P3),\nrule(vp, T3, Y, n, N, P3, P4).\nIn the next step, the determiner (\"Every\") is processed and this results in a\nnew predicate (qnt/4) that stores a rule number (R), the universal quantiﬁer (M),\nthe sentence number (N), and a Skolem constant (K) for the universal quantiﬁer.\nNote that the rule number and the number for the Skolem constant are generated\nwith the help of Lua2 and assigned (:=) to the variables (R) and (K):\n1 The number i in sk(i), represents the ith Skolem constant.\n2 Lua (http://www.lua.org) is available as integrated scripting language in clingo.\n8\nRolf Schwitter\n24. qnt(R, M, N, sk(K)) :-\nto_qnt(N, det(\"Every\"), M),\nR := @rule_num(),\nK := @sk_num().\nGiven the new predicate (qnt/4) for the universal quantiﬁer, the syntax tree\nfragments for constructing the head of a rule and the body of a rule can be\nfurther split up:\n25. to_head(R, adj(S2), K)\n:-\nto_head(N, vp(cop(S1), adj(S2)), M),\nqnt(R, forall, N, K).\nto_body(R, noun(S), K)\n:-\nto_body(N, n1(noun(S), RCL), M),\nqnt(R, forall, N, K).\nto_body(R, RCL, K)\n:-\nto_body(N, n1(noun(S), RCL), M),\nqnt(R, forall, N, K).\nIn the case of the head (to head/3), this process results in a preterminal\ncategory (adj(S2)) that can be used to generate the head literal of the rule.\nIn the case of the body (to body/3), only the ﬁrst rule generates a preterminal\ncategory (noun(S)) that can directly be used to generate a positive body literal.\nThe second rule is used to split the relative clause (RCL) into its basic constituents\nin order to extract the relevant preterminal categories:\n26. to_body(R, RCL1, K)\n:-\nto_body(R, rcl(RCL1, cnj(and), RCL2), K).\nto_body(R, RCL2, K) :-\nto_body(R, rcl(RCL1, cnj(and), RCL2), K).\nto_body(R, iv(S2), K) :-\nto_body(R, rcl(rp(S1), vp(iv(S2))), K).\nto_body(R, naf(adj(S3)), K)\n:-\nto_body(R, rcl(rp(S1), vp(cop(S2), naf(T1, T2), adj(S3))), K).\nThe preterminal categories for content words together with the Skolem con-\nstant (K) and the rule number (R) are then used to generate the head literal, the\npositive and negative body literals. During this process the string (S) of these\npreterminal categories is replaced by the base form (B) via a lexicon lookup. The\nrule identiﬁer (rule/1) is generated with the help of the head literal (head/2):\n27. rule(R) :- head(R, L).\nhead(R, lit(func(B), arg(K))) :-\nto_head(R, adj(B), K),\nlexicon(adj, S, B, _, _).\nCNL Processing as Answer Set Programming: an Experiment\n9\npbl(R, lit(func(B), arg(K))) :-\nto_body(R, noun(S), K),\nlexicon(noun, S, B, _, _).\npbl(R, lit(func(B), arg(K))) :-\nto_body(R, iv(S), K),\nlexicon(iv, S, B, _, _).\nnbl(R, lit(func(B), arg(K))) :-\nto_body(R, naf(adj(S)), K),\nlexicon(adj, S, B, _, _).\nNote that checking for anaphoric references can be done over the existing\nmodel during the translation process of the syntax tree into rules. For example,\nthe second sentence of (5) contains a deﬁnite noun phrase (the student) that is\nanaphorically linked to an indeﬁnite noun phrase (a student). Depending on the\ncontext in which an anaphoric expression occurs, we either check the body of\nthe current rule for an antecedent or the heads of all existing rules that don’t\nhave a body and give preference to the closest match in terms of rule numbers.\n5\nReasoning with Reiﬁed ASP Rules\nIn order to process these reiﬁed ASP rules, we use a meta-interpreter that is\nbased on the work of Eiter et al. [3]. We substantially extended this meta-\ninterpreter so that it can deal with variables that occur as Skolem constants\nin the reiﬁed notation. On the meta-level we represent answer sets with the help\nof the predicate in AS/1 and use the following two rules to add literals to an\nanswer set:\n28. in_AS(lit(F, A2)) :-\nhead(R, lit(F, A1)),\npos_body_true(R, A1, A2),\nnot neg_body_false(R, A1, A2).\nin_AS(lit(F, A)) :-\nhead(R, lit(F, A)),\nrule(R),\nnot pos_body_exists(R).\nThe ﬁrst rule speciﬁes that a literal (lit/2) is in an answer set (in AS/1),\nif it occurs in the head (head/2) of a rule with number R whose positive body\n(pos body true/3) is true and whose negative body (neg body false/3) is not false\nand if the Skolem constant that occurs as argument (A1) of that literal can be\nreplaced by other constants that occur as argument (A2) of a corresponding\nliteral in the answer set. The second rule speciﬁes that if no positive body literal\n(pbl/3) for a rule exists, then we can directly process the head (head/2) of a rule.\nThe positive body (pos body true/3) of the ﬁrst rule in (28) is true up to\nsome positive body literal with respect to a built-in order. If the positive body\n10\nRolf Schwitter\nis true up to the last positive body literal then the whole positive body is true.\nThe ﬁrst rule in (29) deals with this case; the second rule takes care of the ﬁrst\npositive body literal, and the third rule makes sure that the positive body literals\nfollow the speciﬁed order:\n29. pos_body_true(R, A1, A2) :-\npos_body_true_up_to(R, F, A1, A2),\nnot pbl_not_last(R, F).\npos_body_true_up_to(R, F, A1, A2) :-\npbl_in_AS(R, F, A1, A2),\nnot pbl_not_first(R, F).\npos_body_true_up_to(R, F1, A1, A2) :-\npbl_in_AS(R, F1, A1, A2),\nF2 < F1,\nnot pbl_in_between(R, F2, F1),\npos_body_true_up_to(R, F2, A1, A2).\nThe rule (pbl in AS/4) in (30) checks if a positive body literal (pbl/2) for a\nrule (R) exists, looks in the current answer set (in AS/1) for a literal that has the\nsame functor name (F) as the body literal but shows a diﬀerent argument (A2)\nand returns that argument:\n30. pbl_in_AS(R, F, A1, A2) :-\npbl(R, lit(F, A1)),\nin_AS(lit(F, A2)),\nA1 != A2.\nThere exist similar rules that deal with cases where the positive body literal\nhas more than one argument. The successor relation on positive body literals of\neach rule is deﬁned with the help of the following auxiliary rules:\n31. pbl_in_between(R, F1, F3) :-\npbl(R, lit(F1, A1)),\npbl(R, lit(F2, A2)),\npbl(R, lit(F3, A3)),\nF1 < F2, F2 < F3.\npbl_not_last(R, F1) :-\npbl(R, lit(F1, A1)),\npbl(R, lit(F2, A2)),\nF1 < F2.\npbl_not_first(R, F1) :-\npbl(R, lit(F1, A1)),\npbl(R, lit(F2, A2)),\nF2 < F1.\nThe negative part of the body (neg body false/3) in the ﬁrst rule of (28) is\nfalse, if it can be shown that one of its literals is in the answer set (in AS/1).\nThe rule in (32) checks this condition for literals with one argument (other rules\ndeal with literals that have more than one argument):\nCNL Processing as Answer Set Programming: an Experiment\n11\n32. neg_body_false(R, A1, A2) :-\nnbl(R, lit(F, A1)),\nin_AS(lit(F, A2)).\nFinally, the rule pos body exists/1 in (33) is used as part of the second rule\nin (28) and simply checks if a positive body literal (pbl/2) exists:\n33. pos_body_exists(R) :- pbl(R, L).\nAfter parsing and translating the CNL text in (5) into reiﬁed rules repre-\nsented as a set of facts, the ASP meta-interpreter will generate the following\nanswer set as solution:\n34. { in_AS(lit(func(student), arg(john)))\nin_AS(lit(func(work), arg(john)))\nin_AS(lit(func(student), arg(sue)))\nin_AS(lit(func(work), arg(sue)))\nin_AS(lit(func(student), arg(mary_ann)))\nin_AS(lit(func(absent), arg(mary_ann)))\nin_AS(lit(func(successful), arg(sue)))\nin_AS(lit(func(successful), arg(john)))\nin_AS(lit(func(neg(work)), arg(mary_ann))) }\nThis answer set contains the same information as the answer set in (3) and can\nbe used for question answering.\n6\nConclusion\nIn this paper, we investigated in an experimental way if it is possible to process\na controlled natural language entirely in ASP and if ASP can serve as a uni-\nﬁed framework for parsing, knowledge representation and automated reasoning.\nASP is a powerful declarative knowledge representation language that provides\nsupport for non-monotonic reasoning and this makes the language particularly\nattractive for controlled natural language processing. We showed in detail how a\ngrammar for a controlled natural language can be written as an ASP program.\nThis grammar is processed bottom-up and the syntax trees are constructed start-\ning from the leaves up to the root. The resulting syntax trees are translated into\nreiﬁed rules that consist of a set of facts. These facts are then used by a meta-\ninterpreter written in ASP for automated reasoning. The translation into reiﬁed\nrules is necessary because ASP does not provide a mechanism that would allow\nus to generate and assert normal ASP rules in the same program. Alternatively,\nwe could take the resulting syntax trees and translate them outside of the ASP\nprogram into normal ASP rules and then generate a new ASP program that\nexecutes these rules. With the help of the presented ASP grammar it is possible\nto generate look-ahead information to guide the writing process of the author.\nIt is also possible in ASP to perform anaphora resolution over the reiﬁed rules\nduring the translation process using the standard constraints on anaphoric ac-\ncessibility. We believe that ASP is an interesting paradigm for controlled natural\nlanguage processing and plan to extend the presented approach or aspects of it\nand integrate them into a controlled language authoring system.\n12\nRolf Schwitter\nReferences\n1. Brewka, G., Eiter, T. and Truszczy´nski M.: Answer Set Programming at a Glance.\nIn: Communications of the ACM, Vol. 54, No. 12, December (2011)\n2. Clark, P., Harrison, P., Jenkins, T., Thompson, J. and Wojcik, R.H.: Acquiring\nand using world knowledge using a restricted subset of English. In: Proceedings of\nFLAIRS 2005, AAAI Press, pp. 506–511, (2005)\n3. Eiter, T., Faber, W., Leone, N. and Pfeifer, G.: Computing Preferred Answer Sets\nby Meta-Interpretation in Answer Set Programming. in: INFSYS Research Report\n1843-02-01, Technische Universit¨at Wien, January, (2002)\n4. Franconi, E., Guagliardo, P., Trevisan, M. and Tessaris S.: Quelo: an ontology-driven\nquery interface. In: Proceedings of the 24th International Workshop on Description\nLogics (DL 2011), (2011)\n5. Fuchs, N.E., Kaljurand, K. and Kuhn, T.: Attempto Controlled English for knowl-\nedge representation. In: Reasoning Web – 4th International Summer School 2008,\nLNCS 5224, Springer, pp. 104–124, (2008)\n6. Gebser, M., Kaminski, R., Kaufmann, B., Ostrowski, M., Schaub, T. and Schneider,\nM.: Potassco: The Potsdam Answer Set Solving Collection. In: AI Communications,\nVol. 24, No. 2, pp. 105–124, (2011)\n7. Gelfond, M. and Lifschitz V.: The stable model semantics for logic programming.\nIn: Proceedings of ICLP-88, pp. 1070–1080, (1988)\n8. Gelfond, M. and Lifschitz V.: Classical negation in logic programs and disjunctive\ndatabases. In: New Generation Computing, Vol. 9, No. 34, pp. 365–386, (1991)\n9. Gelfond, M. and Kahl, Y.: Knowledge Representation, Reasoning, and the Design\nof Intelligent Agents. Cambridge University Press, (2014)\n10. Kuhn, T.: Controlled English for Knowledge Representation. Doctoral thesis, Fac-\nulty of Economics, Business Administration and Information Technology of the Uni-\nversity of Zurich, (2010)\n11. Kuhn, T.: A Survey and Classiﬁcation of Controlled Natural Languages. In: Com-\nputational Linguistics, Vol. 40, No. 1, pp. 121–170, (2014)\n12. Lierler, Y. and Lifschitz, V.: Logic Programs vs. First-Order Formulas in Textual\nInference. In: Proceedings of the 10th International Conference on Computational\nSemantics (IWCS 2013), Potsdam, Germany, pp. 340–346, (2013)\n13. Lifschitz, V.: What is Answer Set Programming? In: Proceedings of AAAI 2008,\npp. 1594–1597, (2008)\n14. Power R.: OWL Simpliﬁed English: a ﬁnite-state language for ontology editing.\nIn: Kuhn, T. and Fuchs, N.E. (eds): Proceedings of CNL 2012, Zurich, Springer,\nHeidelberg, pp. 44–60, (2012)\n15. Reiter, R.: On closed world data bases. In: Gallaire, H. and J. Minker, J. (eds):\nLogic and Data Bases, pp. 119–140, Plenum Publ. Co., New York, (1978)\n16. Schwitter, R., Ljungberg, A. and Hood, D.: ECOLE – A Look-ahead Editor for a\nControlled Language. In: Proceedings of EAMT-CLAW03, May 15-17, Dublin City\nUniversity, Ireland, pp. 141–150, (2003)\n17. Schwitter, R.: Controlled Natural Languages for Knowledge Representation. In:\nProceedings of COLING 2010, Beijing, China, pp. 1113–1121, (2010)\n18. White, C. and Schwitter, R.: An Update on PENG Light. In: L. Pizzato and R.\nSchwitter (eds.), Proceedings of ALTA 2009, Sydney, Australia, pp. 80–88, (2009)\n",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "published": "2014-07-15",
  "updated": "2014-07-15"
}