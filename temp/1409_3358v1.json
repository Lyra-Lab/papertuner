{
  "id": "http://arxiv.org/abs/1409.3358v1",
  "title": "Building Program Vector Representations for Deep Learning",
  "authors": [
    "Lili Mou",
    "Ge Li",
    "Yuxuan Liu",
    "Hao Peng",
    "Zhi Jin",
    "Yan Xu",
    "Lu Zhang"
  ],
  "abstract": "Deep learning has made significant breakthroughs in various fields of\nartificial intelligence. Advantages of deep learning include the ability to\ncapture highly complicated features, weak involvement of human engineering,\netc. However, it is still virtually impossible to use deep learning to analyze\nprograms since deep architectures cannot be trained effectively with pure back\npropagation. In this pioneering paper, we propose the \"coding criterion\" to\nbuild program vector representations, which are the premise of deep learning\nfor program analysis. Our representation learning approach directly makes deep\nlearning a reality in this new field. We evaluate the learned vector\nrepresentations both qualitatively and quantitatively. We conclude, based on\nthe experiments, the coding criterion is successful in building program\nrepresentations. To evaluate whether deep learning is beneficial for program\nanalysis, we feed the representations to deep neural networks, and achieve\nhigher accuracy in the program classification task than \"shallow\" methods, such\nas logistic regression and the support vector machine. This result confirms the\nfeasibility of deep learning to analyze programs. It also gives primary\nevidence of its success in this new field. We believe deep learning will become\nan outstanding technique for program analysis in the near future.",
  "text": "Building Program Vector Representations\nfor Deep Learning\nLili Mou, Ge Li∗, Yuxuan Liu, Hao Peng, Zhi Jin, Yan Xu, Lu Zhang\nSoftware Institute, School of EECS, Peking University\nBeijing, 100871, P. R. China\nEmail: {moull12, lige, zhijin, zhanglu}@sei.pku.edu.cn\n{liuyuxuan, penghao.pku, alandroxu}@gmail.com\nAbstract—Deep learning has made signiﬁcant breakthroughs\nin various ﬁelds of artiﬁcial intelligence. Advantages of deep\nlearning include the ability to capture highly complicated fea-\ntures, weak involvement of human engineering, etc. However,\nit is still virtually impossible to use deep learning to analyze\nprograms since deep architectures cannot be trained effectively\nwith pure back propagation. In this pioneering paper, we propose\nthe “coding criterion” to build program vector representations,\nwhich are the premise of deep learning for program analysis. Our\nrepresentation learning approach directly makes deep learning a\nreality in this new ﬁeld. We evaluate the learned vector represen-\ntations both qualitatively and quantitatively. We conclude, based\non the experiments, the coding criterion is successful in building\nprogram representations. To evaluate whether deep learning\nis beneﬁcial for program analysis, we feed the representations\nto deep neural networks, and achieve higher accuracy in the\nprogram classiﬁcation task than “shallow” methods, such as\nlogistic regression and the support vector machine. This result\nconﬁrms the feasibility of deep learning to analyze programs. It\nalso gives primary evidence of its success in this new ﬁeld. We\nbelieve deep learning will become an outstanding technique for\nprogram analysis in the near future.\nI. INTRODUCTION\nMachine learning-based program analysis has been studied\nlong in the literature [1], [2], [3]. Hindle et al. compare\nprogramming languages to natural languages and conclude\nthat programs also have rich statistical properties [4]. These\nproperties are difﬁcult for human to capture, but they justify\nusing learning-based approaches to analyze programs.\nThe deep neural network, also known as deep learning, has\nbecome one of the prevailing machine learning approaches\nsince 2006 [5]. It has made signiﬁcant breakthroughs in a\nvariety of ﬁelds, such as natural language processing [6], [7],\nimage processing [8], [9], speech recognition [10], [11], etc.\nCompared with traditional machine learning approaches, deep\nlearning has the following major advantages:\n• The deep architecture can capture highly complicated\n(non-linear) features efﬁciently. They are crucial to most\nreal-world applications.\n• Very little human engineering and prior knowledge is\nrequired. Interestingly, with even a uniﬁed model, deep\nlearning achieves better performance than state-of-the-art\napproaches in many heterogeneous tasks [12].\n∗Corresponding author.\nSuch striking results raise the interest of its applications in the\nﬁeld of program analysis. Using deep learning to automatically\ncapture program features is an interesting and prospective\nresearch area.\nUnfortunately, it has been practically infeasible for deep\nlearning to analyze programs up till now. Since no proper\n“pretraining” method is proposed for programs, deep neural\nnetworks cannot be trained effectively with pure back propa-\ngation [13], [14], [15] because gradients would either vanish or\nblow up through the deep architecture [16]. No useful features\ncan be extracted, and it results in very poor performance.\nIn this paper, we propose a novel “coding criterion” to build\nprogram vector representations based on abstract syntax trees\n(ASTs). The vector representations are the premise of deep\narchitectures, and our method directly makes deep learning\na reality in the new ﬁeld—program analysis. In such vector\nrepresentations, each node in ASTs (e.g. ID, Constant) is\nmapped to a real-valued vector, with each element indicating\na certain feature of the node. The vector representations\nserve as a “pretraining” method. They can emerge, through\na deep architecture, high-level abstract features, and thus\nbeneﬁt ultimate tasks. We analyze the learned representations\nboth qualitatively and quantitatively. We conclude from the\nexperiments that the coding criterion is successful in building\nprogram vector representations.\nTo evaluate whether deep learning can be used to analyze\nprograms, we feed the learned representations to a deep neural\nnetwork in the program classiﬁcation task. We achieve higher\naccuracy than “shallow” methods. The result conﬁrms the\nfeasibility of neural program analysis. It also sheds some light\non the future of this new area.\nWe publish all of our source codes, datasets, and learned\nrepresentations on our project website1 to promote future\nstudies. The AST node representations can be used for further\nresearches in various applications of program analysis. The\nsource codes contain a versatile infrastructure of the feed-\nforward neural network, based on which one can build one’s\nown deep neural architectures.\nTo our best knowledge, this paper is the ﬁrst to propose\nrepresentation learning algorithms for programs. It is also the\nﬁrst to analyze programs by deep learning. This study is a\n1 https://sites.google.com/site/learnrepresent/\narXiv:1409.3358v1  [cs.SE]  11 Sep 2014\npioneering research in the new ﬁeld. To sum up, the main\ncontributions of this paper include:\n1) Introducing the techniques of deep learning and repre-\nsentation learning to the ﬁeld of program analysis;\n2) Proposing the novel “coding criterion” to build program\nrepresentations, which are the premise of deep learning;\n3) Exploring the feasibility to analyze programs by deep\nneural networks, shedding some light on the future;\n4) Publishing all of our source codes, datasets, and learned\nrepresentations online to promote further researches.\nIn the rest of this paper, we ﬁrst motivate our research in\nSection II. The background of deep learning and representation\nlearning is introduced in Section III. Then we explain our\napproach in detail in Section IV. Experimental results are\nshown in Section V. In Section VI, we look forward to the\nfuture of deep learning in the ﬁeld of program analysis. Last,\nwe draw our conclusion in Section VII.\nII. MOTIVATION\nA. From Machine Learning to Deep Learning\nTraditional machine learning approaches largely depend\non human feature engineering, e.g., [17] for bug detection,\n[18] for clone detection. Such feature engineering is label-\nconsuming and ad hoc to a speciﬁc task. Further, evidence\nin the literature suggests that human-engineered features may\nbe even worse than automatically learned ones. Mnih et al.\nreport—for example, in the ﬁeld of natural language pro-\ncessing (NLP)—the automatically learned taxonomy of words\n[19] is better in their application than the famous WordNet\nconstructed by experts [20] used in [21].\nSuch results pose increasing demands on highly automated\nlearning approaches, such as deep learning with very little\nhuman engineering.\nWith deep neural networks, program analysis may be eas-\nier with statistical methods. For example, in the task of\nprogram classiﬁcation, deep neural networks automatically\nextract program features of interest. Features can be organized\nhierarchically, from local to abstract. Based on these abstract\nfeatures, we may determine the category of a program. Such\ndeep learning architectures require less human engineering\nthan existing methods like [22]. Moreover, the feature rep-\nresentation nature also makes it easy for multi-task learning.\nAs pointed out in [23], “many decision problems can be\nreduced to classiﬁcation.” Such deep learning architecture is\nalso applicable to other program analysis tasks, including\n• bug detection as [17], to which the deep learning ap-\nproach is to automatically extract features of bugs;\n• clone detection as [24], to automatically match the fea-\ntures of two programs;\n• code retrieval as [25], to automatically match program\nfeatures with that of the queries; and\n• code recommendation as [26], to automatically predict\nthe probability of the next possible codes, e.g. APIs,\naccording to previous ones based on the features (like\n[27] in NLP).\nIn short, deep neural networks are capable of capturing\nhighly complicated features with little human involvement.\nAnalyzing programs with deep learning is an interesting and\npromising research topic.\nB. Barriers of Deep Learning for Program Analysis\nAlthough deep neural networks are powerful enough to cap-\nture complicated features, there are still barriers to overcome\nbefore they can be practically used to analyze programs.\nSince all program symbols (e.g. nodes in ASTs) are “dis-\ncrete,” no order is deﬁned on these symbols. Such discrete\nsymbols cannot be fed directly to a neural network. A possible\nsolution is to map each symbol to a real-valued vector in some\ndimension. Each element in the vector characterizes a certain\nfeature of the symbol spontaneously. Hence, it is also referred\nto as distributed representation. By “distributed,” it is contrary\nto one-of-all coding, such as k-means clustering results.\nA direct mapping approach is to randomly initialize these\nvector representations and train with pure back propagation\n(like shallow networks). Chances are that we end up with\nboth poor optimization and poor generalization if the network\nis deep [13], [14], [15]. An alternative is to ﬁrst learn the\nrepresentations unsupervisedly regardless of the speciﬁc task\nlike clone detection, bug detection, etc. Then they are fed to\na neural network for supervised training. The vector repre-\nsentations specify meaningful features of the symbols, and\nbeneﬁt the ultimate tasks. Hence, many researches focus on\nthe problem of representation learning per se, such as [27],\n[28], [5], [7], [29] in ﬁelds like NLP.\nHowever, due to the structural differences between natural\nlanguages and programming languages [30], existing represen-\ntation learning algorithms in NLP are improper for programs.\nAs we know, natural languages are always written/spoken in\none dimension as time ﬂows. By contrast, programmers always\norganize their source codes with proper indentation, indicating\nbranches, loops or even nested structures. It will be extremely\ndifﬁcult to read source codes if they are written in one line\n(like natural languages). The formal grammar rules of the\nprogramming language alias the notion of neighborhood. To\nbe concrete, physically neighboring stuffs in a program source\ncode are not necessarily near to each other, but those in one\ngrammar rule are.\nFurther, if we want to build the representations for abstract\ncomponents of a program (e.g., function declaration/call nodes\nin ASTs), existing NLP representation learning algorithms are\ninapplicable since all of them are “ﬂat.”\nTherefore, new approaches are needed to build program\nvector representations, which are unfortunately not studied.\nThe above facts motivate our research of representation\nlearning for programs. This eventually makes deep learning\na reality to analyze programs. Considering current evidence\nin the literature, we believe deep learning will make great\nprogress in heterogenous tasks of program analysis.\nIII. BACKGROUND OF DEEP LEARNING AND\nREPRESENTATION LEARNING\nA. Deep Neural Networks\nNowadays, the deep neural network is a widely-used tech-\nnique in artiﬁcial intelligence. Comprehensive reviews include\n[31], [32].\nA single layer of neurons, the building block for deep neural\nnetworks, takes a vector x ∈Rn as input and outputs a vector\ny ∈Rm (Part A in Figure 1). Typically y is computed as\ny = f(W ·x + b)\n(1)\nwhere W ∈Rm×n, b ∈Rm are model parameters, which are\nﬁrst randomly initialized and then trained by gradient descent,\ni.e., W ←W −α ∂J\n∂W and b ←b−α ∂J\n∂b . (α is the learning rate;\nJ is the cost function.) f is the activation function, usually\nnon-linear, such as sigmoid, tanh, etc. The power of a single-\nlayer neural network is limited: the decision boundary is linear,\nand it is insufﬁcient for most real-world applications.\nMulti-layer neural networks (Part B in Figure 1) stack\nmultiple layers of neurons. The parameters can also be trained\nby gradient descent with back propagation algorithm [33].\nDue to the stacking of multiple non-linear layers, multi-layer\nneural networks gain much more power. It can be proved\nthat a 2-layer2 neural network with sufﬁcient hidden units\ncan approximate arbitrary Boolean or continuous functions,\nand that a 3-layer network can approximate any function [34].\nHowever, the shallow architecture is inefﬁcient because the\nnumber of hidden units may grow exponentially in order to\nlearn complicated (highly non-linear) features of data [35].\nSuch exponentiation of hidden layer units, and hence param-\neters, raises the VC-dimension of the model, leading to very\npoor generalization [36].\nThe theory of circuits suggests deep architectures would be\nmore efﬁcient to capture complicated features [31]. In such\ndeep architectures, features can be organized hierarchically,\nwith local features at lower layers and abstract features at\nhigher layers (Figure 1). However, while deep architectures\ncapture abstract features efﬁciently, they also make the net-\nworks very difﬁcult to train. Few successful researches were\nreported in early years using deep architectures (except con-\nvolutional neural networks [37]).\nIn 2006, Hinton et al. proposed stacked restricted Boltz-\nmann machine (RBM) as a greedy layer-wise pretraining\nmethod for deep neural networks [5]. During the pretraining\nphase, the stacked RBM is learning underlying data features\nunsupervisedly by minimizing the energy function deﬁned\non the unlabeled data (i.e., maximizing the likelihood of\nthe data). Shortly after that, stacked autoencoders are used\nfor pretraining [13], the criterion of which is to minimize\nthe reconstruction error. During the pretraining phase with\neither stacked RBMs or autoencoders, the weights for neuron\nconnections are learned, which extract underlying features of\n2 The input layer is not counted to the number of layers in our terminology\nas there is no weight associated with it.\nInput\nOutput\n(A) A single layer of neurons\nInput layer\nOutput layer\n. . .\nHidden layers\n. . .\n.\n.\n.\nLower level\n(local features)\nHigher level\n(abstract features)\n(B) A deep neural network\nFig. 1.\nA deep neural network (B) is composed of multiple layers of neurons\n(A).\nthe data. Then, for supervised learning, the neural weights are\ninitialized as that have been learned in the pretraining phase\ninstead of random initialization. Standard back propagation\nalgorithm can be used for ﬁne-tuning the weights so as to be\nspeciﬁc to the task.\nThe pretraining phase plays a vital role in deep learning. It\nlearns the features of data unsupervisedly, and as a result, the\nweights are much more meaningful than just chosen randomly.\nAccording to the experiments reported in [13], [14], [15],\npretraining helps optimization (minimizing the training error)\nas well as generalization (minimizing the test error).\nHowever, the advantages of deep neural networks are not\nexploited in the ﬁeld of program analysis. We believe deep\nlearning will also exhibit its power in this new ﬁeld.\nB. Existing Representation Learning Approaches in NLP\nNeural networks and the pretraining approaches like RBMs,\nautoencoders work well with image data, speech data, etc.\nBut they cannot be applied directly to the ﬁeld like NLP\nand program analysis because words and program symbols\nare “discrete.”\nIn data like images, a total order is deﬁned on the value.\nFor example, a gray-scale pixel with value 0 is black. If the\nvalue increases, it becomes brighter accordingly. If the value\nis 255, the pixel becomes white. However, in ﬁelds like NLP, a\nword with index 20 is by no means twice as large as the word\nwith index 10 for any meaningful feature. Therefore, unlike\ntraditional approaches in NLP, where each words is treated as\nan atomic unit, it is meaningless to feed the indexes of words\nto neural networks. (Note the multiplication W·x in Equation\n1.)\nReal-valued vector representations come to our rescue. With\nsuch representations, each word is mapped to a k-dimensional\nvector (k = 30, 100, 300, etc), representing certain (anony-\nmous) features of the word. The value reﬂects the degree that\na feature is satisﬁed. These word representations can be fed\nforward to standard neural networks, and every routine of deep\nlearning works.\nEarly word representation learning is related to language\nmodeling, the objective of which is to maximize the joint\nprobability of a linguistic corpus. In [27], they predict the\nprobability of each word given n−1 previous words. By max-\nimizing the conditional probability of the n-th word, useful\nword features are learned. Hinton et al. introduce 3 energy-\nbased models in [28], where they learn word representations\nby minimizing the energy (maximizing the likelihood) deﬁned\non neighboring words. In [21], [19], hierarchical architectures\nare proposed to reduce the computational cost in calculating\nthe probabilities. Later, researchers realized the normalization\nof probability is not essential if we merely want to learn feature\nvectors. Fast algorithms are then proposed in [38], [39].\nAll the above approaches adopt the Markovian assumption,\nwhere each word is related to ﬁnite many previous words.\nSuch approaches take into consideration only local patterns\nof physically nearing words. Recurrent neural network (RNN)\nis introduced in order to capture long-term dependencies [40].\nHowever, RNN may be very difﬁcult to train since the gradient\nwould either vanish or blow up during back propagation [16].\nBesides, the time-delaying nature of RNN treats data as a one-\ndimensional signal, where structural information is also lost.\nAs we have discussed in Section I, programming languages\nare different from natural languages in that the former contain\nricher and more explicit structural information. Therefore, new\nrepresentation learning algorithms are needed. To solve this\nproblem, we propose the “coding criterion” based on ASTs.\nThe detail of our approach is explained in the following\nsection.\nIV. THE CODING CRITERION FOR PROGRAM\nREPRESENTATION LEARNING\nIn this section, we ﬁrst discuss the granularities of program\nrepresentation. We settle for the granularity of nodes in ab-\nstract syntax trees (ASTs).\nIn Subsection IV-B, we formalize our approach and give\nthe learning objective. In Subsection IV-C, we present the\nstochastic gradient descent algorithm for training.\nA. The Granularity\nWe should ﬁrst answer a fundamental question of program\nrepresentation learning—the granularity of representation. As\nwe have introduced in previous sections, vector representations\nmap a symbol to a real-valued, distributed vector. Possible\ngranularities of the symbol include character-level, token-level,\netc. We analyze each case as follows.\n• Character-level. Characters are the most atomic units\nof programming languages. At this level, we treat each\ncharacter in source codes as a symbol. This means that\nwe should learn the representations for characters like\ndouble doubles(double doublee){\nreturn 2 * doublee;\n}\n(A) A C code snippet\nFuncDef\nDecl\nCompound\nFuncDecl\nReturn\nParameterList\nTypeDecl\nBinaryOp\nDecl\nIdentifierType\nConstant\nID\nTypeDecl\nIdentifierType\n(B) The corresponding AST\nFig. 2.\nA C code snippet (A) and its corresponding AST (B). Each node\nin AST corresponds to an abstract component (e.g., a function declaration, a\nbinary operator) in the program.\na-z, A-Z, 0-9 and all punctuation marks. Although some\nresearches explore character-level modeling for NLP [41],\nit is improper for programming languages. In NLP, the\nknowledge of word morphology can be explored to\nsome extent by character-level modeling, but the situation\nchanges in programs. For example, the token double\nin a C code refers to a data type. But if one writes\ndoubles, it is an identiﬁer (e.g., a function name),\ncompletely different from double. However, double\nand doubles share most characters, which leads to\nsimilar vector representations.\n• Token-level. This level is most similar to NLP rep-\nresentation learning. We learn representations for all\ntokens (analogous to words in NLP), including types\nlike int, double, identiﬁers like doubles, func, etc.\nUnfortunately, the identiﬁer representations bring severe\nproblems. Unlike natural languages, where the number\nof words is generally ﬁxed, programmers can declare\ntheir own identiﬁers in their source codes, e.g., func1,\nfunc2, func3, so on and so forth. Therefore, the\nnumber of tokens is unlimited. Because some identiﬁers\nmay appear only a few times (e.g., tmp), we will suffer\nfrom the problem of undesired data sparseness. Hence, it\nis improper for representation learning at this level.\nAnother problem of token-level representation is that\ninformation is not encoded efﬁciently. For example, we\nneed two tokens to represent a pair of parentheses,\nindicating the priority of different stuffs. In fact, such\ninformation need not to be expressed explicitly in a more\ncompressed representation like ASTs.\n• Nodes in ASTs. The abstract syntax tree is a structural\nrepresentation of a program. Figure 2 shows a C code\nsnippet and its corresponding AST, parsed by pycparser3.\nAt this level, we learn the representations for nodes in\nASTs, e.g., FuncDef, ID, Constant. As is stated, the\nAST is more compressed compared with token-level rep-\nresentation. Furthermore, there are only ﬁnite many types\nof nodes in ASTs, which makes it feasible to learn. The\ntree structural nature of ASTs also provides opportunities\nto capture structural information of programs.\nDespite the above facts, the AST representation also\nhas its drawback since we regard all identiﬁers as a\nsame symbol. Such codes as a*b and c*d cannot be\ndistinguished between each other. We hypothesize that\nstructural information captures the semantics of programs\nto a large extent. For example, if we see two nested\nfor-loops, inside of which is a branch of comparison\nfollowed by three assignments, the code snippet is likely\nto be an implementation of bubble sort. This level is\nalso used in traditional program analysis like code clone\ndetection [42], [43], vulnerability extrapolation [44], etc.\nThe experimental results in Section V-B also suggest high\naccuracy in the program classiﬁcation task at this level.\n• Statement-level, function-level or higher. Theoretically,\na statement, a function or even a program can also be\nmapped to a real-valued vector. However, such represen-\ntations cannot be trained directly. A possible approach\nof modeling such complex stuff is by composition, i.e.,\nthe representation of a complex stuff is composited by\nthat of atomic ones. Such researches in NLP is often\nreferred to as compositional semantics [45]. The state-of-\nthe-art approaches in NLP compositional semantics can\nonly model sentences, paragraphs roughly. It is very hard\nto capture the precise semantics; the “semantic barrier”\nis still not overcome.\nTo sum up, we have analyzed in this part different granular-\nities of program representations. We think the representation\nfor nodes in ASTs has theoretical foundations, and is feasible\nto learn and useful in applications. In the following subsection,\nwe formalize our coding criterion to build program vector\nrepresentations.\nB. Formalization\nThe basic criterion of representation learning is that similar\nsymbols should have similar representations. Further, symbols\nthat are similar in some aspects should have similar values\nin corresponding feature dimensions. This is referred to as\n“disentangling the underlying factors of variation” in [32].\nIn our scenario of representation learning for AST nodes,\nsimilarity is deﬁned based on the following intuition. We\nthink such symbols as ID, Constant are similar because\nboth of them are related to data reference; For, While are\nsimilar because both are related to loops. The observation is\nthat similar symbols have similar usages in the programming\nlanguage: both ID and Constant can be an operand of a\n3 https://pypi.python.org/pypi/pycparser/\nunay/binary operator; both For and While are a block of\ncodes, etc.\nTo capture such similarity using AST structural informa-\ntion, we propose the “coding criterion”. The idea is that the\nrepresentation of a node in ASTs should be “coded” by its\nchildren’s representations via a single neural layer.\nWe denote the vector of node x as vec(x). vec(·) ∈RNf ,\nwhere Nf is the dimension of features. (Nf is set to 30\nempirically in our experimental setting.) For each non-leaf\nnode p in ASTs and its direct children c1, · · · , cn, their\nrepresentations are vec(p), vec(c1), · · · , vec(cn). The primary\nobjective is that\nvec(p) ≈tanh\n n\nX\ni=1\nliWi · vec(ci) + b\n!\n(2)\nwhere Wi ∈RNf ×Nf is the weight matrix for node ci; b ∈\nRNf is the bias term. The weights (Wi’s) are weighted by the\nnumber of leaves under ci and the coefﬁcients are\nli = #leaves under ci\n#leaves under p\n(3)\nAs we have noticed in Figure 2, different nodes in ASTs\nmay have different numbers of children, and thus the number\nof Wi’s is hard to determine. To solve this problem, one\nextreme is to apply dynamic pooling [46], [47]. In this method,\nwe take the summed or maximal value over vec(ci) for each\nfeature dimension, and thus only one weight matrix is needed.\nThis is also mathematically equivalent to the continuous bag-\nof-words model [38]. However, when pooling is applied,\nposition information of c’s will be totally lost and therefore it is\nnot satisfactory. Another extreme is to assign a different matrix\nparameter for each different position [45]. This method works\nin the original application with dependency trees, but may fail\nin our scenario because there will be too many weights.\nWhat we propose is a model called continuous binary tree,\nwhere there are two weight matrices as parameters, namely Wl\nand Wr. Any weight Wi is a linear combination of the two\nmatrices. That is, regardless the number of children, we treat\nit as a “binary” tree. Formally, if p has n (n ≥2) children,\nthen for child ci,\nWi = n −i\nn −1Wl + i −1\nn −1Wr\n(4)\nIf n = 1, Wi = 1\n2Wl + 1\n2Wr.\nThis process is illustrated in Figure 3, where the gray-scale\nvalues in the two bars represent the weight coefﬁcients for\nthe node at the corresponding position. With this model, the\nrelative position information of a node can be coded into the\nnetwork.\nNow that we are able to calculate the weight Wi for each\nnode and thus the right-hand side of Equation 2, we measure\ncloseness by the square of Euclidean distance, as below:\nd =\n\r\r\r\r\rvec(p) −tanh\n n\nX\ni=1\nliWi · vec(ci) + b\n!\r\r\r\r\r\n2\n2\n(5)\np\nWl\nWr\nc1\nc2\n. . .\ncn\nFig. 3.\nIllustration of continuous binary tree. There are two weight matrices\nWl and Wr. The gray-scale bars at the bottom indicate the coefﬁcients of the\nweight parameters (Wl and Wr respectively) at the corresponding position.\nAccording to our “coding criterion,” d needs to be as\nsmall as possible. However, we cannot directly minimize\nEquation 5. Otherwise, the network is likely to output trivial\nrepresentations like vec(·) = 0, W = 0, b = 0. Such result\ngives zero distance but is meaningless.\nTo solve the problem, negative sampling can be applied\n[12], [45], [48]. The idea is that for each data sample x,\na new negative sample xc is generated. Since xc violates\nthe patterns of valid data, it needs to have a larger distance\n(denoted as dc) than d. Hence, negative sampling method is\nalso sometimes referred to as the pairwise ranking criterion\n[49]. In our program representation learning, we randomly\nselect a symbol (one of p, c1, c2, · · · , cn) in each training\nsample and substitute it with a different random symbol. The\nobjective is that dc should be at least as large as d+∆, where\n∆is the margin and often set to 1. The error function of\ntraining sample x(i) and its negative sample x(i)\nc\nis then\nJ(d(i), d(i)\nc ) = max\nn\n0, ∆+ d(i) −d(i)\nc\no\n(6)\nTo prevent our model from over-ﬁtting, we can add ℓ2\nregularization to weights (Wl and Wr). The overall training\nobjective is then\nminimize\nWl,Wr,b\n1\n2N\nN\nX\ni=1\nJ(d(i), d(i)\nc )\n+ λ\n2M\n\u0010\n∥Wl ∥2\nF + ∥Wr ∥2\nF\n\u0011\n(7)\nwhere N is the number of training samples; M = 2N 2\nf is\nthe number of weights (number of elements in Wl and Wr);\n∥· ∥F refers to Frobenius norm; λ is the hyperparameter that\nstrikes the balance between coding error and ℓ2 penalty.\nC. Training\nThe numerical optimization algorithm we use is stochas-\ntic gradient descent with momentum. The model parameters\nΘ =\n\u0010\nvec(·), Wl, Wr, b\n\u0011\nare ﬁrst initialized randomly. Then,\nfor each data sample x(i) and its negative sample x(i)\nc , we\ncompute the cost function according to Formula 7. Back\npropagation algorithm is then applied to compute the partial\nderivatives and the parameters are updated accordingly. This\nprocess is looped until convergence. The coding criterion\nof vector representation learning—as a pretraining phase for\nneural program analysis—is “shallow,” through which error\nAlgorithm 1: StochasticGradientDescentWithMomentum\nInput: Data samples x(i), i = 1..N;\nMomentum ϵ;\nLearning rate α\nOutput: Model parameters Θ =\n\u0010\nvec(·), Wl, Wr, b\n\u0011\nRandomly initialize Θ;\nwhile not converged do\nfor i = 1..N do\nGenerate a negative sample x(i)\nc\nfor x(i);\nPropagate forward and backward to compute J(i)\nand the partial derivative ∂J(i)\n∂Θ ;\n∂J(i)\n∂Θ\n←ϵ∂J(i−1)\n∂Θ\n+ ∂J(i)\n∂Θ ;\n// momentum\nΘ ←Θ −α∂J(i)\n∂Θ ;\n// gradient descent\nend\nend\ncan back propagate. Thus, useful features are learned for AST\nnodes.\nTo speed up training, we adopt the momentum method,\nwhere the partial derivatives of the last iteration is added to the\ncurrent ones with decay ϵ. Algorithm 1 shows the pseudo-code\nof the training process.\nV. EXPERIMENTS\nWe ﬁrst evaluate our learned representations by nearest\nneighbor querying and k-means clustering. These qualitative\nevaluations give an intuitive idea about our vector represen-\ntations. We then perform supervised learning in the program\nclassiﬁcation task. We feed the learned representations forward\nto deep neural networks. The experimental results show that\nmeaningful representations, as a means of pretraining, make\nthe network much easier to train in deep architectures. We\nalso achieve higher accuracy with the deep, tree-based con-\nvolutional neural network compared with baseline methods.\nWe consider this as primary evidence of the success of deep\nlearning for program analysis.\nThe dataset, source codes and learned representations can\nbe downloaded at our project website.\nA. Qualitative Evaluation: Nearest Neighbor Queries and k-\nmeans Clustering\nAs we have stated in Section IV-B, similar nodes in ASTs\n(like ID, Constant) should have similar representations.\nTo evaluate whether our coding criterion for representation\nlearning has accomplished this goal, we perform nearest\nneighbor queries.\nFor each query of a symbol, we sort all other symbols by\ndistance (measured in Euclidean space). Examples are pre-\nsented in Table I. As we can see, ID and Constant are the\nTABLE I\nEXAMPLES OF THE NEAREST NEIGHBOR QUERY RESULTS.\nQuery\nResults\nMost Similar\nMost Dissimilar\nID\nBinaryOp, Constant, ArrayRef, Assignment, StructRef · · ·\nPtrDecl, Compound, Root, Decl, TypeDecl\nConstant\nID, UnaryOp, StructRef, ArrayRef, Cast\n· · · EnumeratorList, ExprList, If, FuncDef, Compound\nBinaryOp\nArrayRef, Assignment, StructRef, UnaryOp, ID\n· · ·\nPtrDecl, Compound, FuncDecl, Decl, TypeDecl\nArrayRef\nBinaryOp, StructRef, UnaryOp, Assignment, Return\n· · ·\nCompound, PtrDecl, FuncDecl, Decl, TypeDecl\nIf\nFor, Compound, Break, While, Case\n· · ·\nBinaryOp, TypeDecl, Constant, Decl, ID\nFor\nIf, While, Case, Break, Struct\n· · ·\nBinaryOp, Constant, ID, TypeDecl, Decl\nBreak\nWhile, Case, Continue, Switch, InitList\n· · ·\nBinaryOp, Constant, TypeDecl, Decl, ID\nWhile\nSwitch , Continue , Label , Goto\n· · ·\nBinaryOp, Constant, Decl, TypeDecl, ID\nFuncDecl\nArrayDecl, PtrDecl, FuncDef, Typename, Root\n· · · ArrayRef, FuncCall, IdentiﬁerType, BinaryOp, ID\nArrayDecl\nFuncDecl, PtrDecl, Typename, FuncDef, While\n· · ·\nBinaryOp, Constant, FuncCall, IdentiﬁerType, ID\nPtrDecl\nFuncDecl, Typename, FuncDef, ArrayDecl\n· · ·\nFuncCall, ArrayRef, Constant, BinaryOp, ID\nnearest neighbor of each other. This seems meaningful since\nboth of them are related to data reference. Similar symbols\nalso include ArrayRef, BinaryOp, which are related to\ndata manipulating. Symbols like If, For, While, Break\nare similar as they are related to control ﬂow. FuncDecl,\nArrayDecl, PtrDecl are similar as they are declarations.\nMoreover, these three groups are dissimilar with each other.\n(See most dissimilar part in Table I.)\nTo further conﬁrm the above potential clusters with vec-\ntor representations, we perform k-means clustering, where\nk is set to 3. The result is shown in Table II. As we\nsee, almost all the symbols in Cluster 1 are related to data\nreference/manipulating. Cluster 2 is mainly about declarations.\nCluster 3 contains more symbols, the majority of which are\nrelated to control ﬂow. This result conﬁrms our conjecture\nthat similar symbols can be clustered into groups with the\ndistributed vector representations that are learned by our\napproach.\nAs the qualitative evaluations show, the learned representa-\ntions are meaningful as they can characterize the relationships\nbetween different symbols effectively. The results are consis-\ntent with human understanding of programs.\nIt should also be reminded that similarity is not the only\ngoal of representation learning. Even though heuristic metrics\ncan also be used to measure similarity—like [50] in NLP and\n[18], [24] in program analysis, which may be useful for code\nclone detection [51], code retrieval [25]—they fail to capture\ndifferent aspects of the relationships between different symbols\nbecause the similarity is the only outcome of these metrics.\nThus, they are not suitable for highly-automated learning algo-\nrithms, e.g., deep neural networks. On the contrary, real-valued\nrepresentations are distributed. As each dimension captures\na feature in a certain aspect spontaneously, the distributed\nvector representations can emerge high-level abstract features\nand beneﬁt various tasks. Therefore, representation learning is\ncrucial to program analysis with deep learning approaches.\nTABLE II\nTHE RESULT OF k-MEANS CLUSTERING. k IS SET TO 3.\nCluster\nSybmols\n1\nUnaryOp, FuncCall, Assignment, ExprList,\nStructRef, BinaryOp, ID, Constant, ArrayRef\n2\nFuncDef, TypeDecl, FuncDecl, Compound,\nArrayDecl, PtrDecl, Decl, Root\n3\nTypedef, Struct, For, Union, CompoundLiteral,\nTernaryOp, Label, InitList, IdentiﬁerType,\nReturn, Enum, Break, DoWhile, Case,\nDeclList, Default, While, Continue,\nParamList, Enumerator, Typename, Goto,\nCast, Switch, EmptyStatement,\nEnumeratorList, If\nB. Quantitative\nEvaluation:\nImprovement\nfor\nSupervised\nLearning\nWe now evaluate whether building program vector repre-\nsentations is beneﬁcial for real-world tasks, i.e., whether they\nwill improve optimization and/or generalization for supervised\nlearning of interest. We feed the representations to the Tree-\nbased Convolutional Neural Network (TCNN) for program\nclassiﬁcation.\nThe dataset comes from an online Open Judge (OJ) system4,\nwhich contains a large number of programming problems for\nstudents. Students solve the problems and submit their source\ncodes to the system. The OJ system automatically compiles,\nruns and judges the validity of the source codes. We select\nfour problems for our program classiﬁcation task. Source\ncodes (in C programming language) of the four problems are\ndownloaded along with their labels (problem IDs). We split\nthe dataset by 3 : 1 : 1 for training, cross-validating (CV) and\ntesting.\nFigure 4 plots the learning curves for training and CV in\nﬁrst 40 epochs. (One epoch is an iteration over all training\n4 http://programming.grids.cn/\n0\n5\n10\n15\n20\n25\n30\n35\n40\nEpochs (iterations over all training samples)\n (A) Learning curve of training\n0.6\n0.7\n0.8\n0.9\n1.0\n1.1\n1.2\n1.3\n1.4\nTraining error\nPretrained\nRandom Initialization\n0\n5\n10\n15\n20\n25\n30\n35\n40\nEpochs (iterations over all training samples)\n (B) Learning curve of CV\n0.8\n0.9\n1.0\n1.1\n1.2\n1.3\n1.4\nCV error\nPretrained\nRandom Initialization\nFig. 4.\nLearning curves of training (A) and CV (B). The learned program\nvector representations improve supervised learning in terms of both general-\nization and optimization.\nsamples.) The X axis is the number of epochs during training.\nThe Y axis is the cross-entropy error, computed as\nJ = −1\nN\nN\nX\ni=1\nM\nX\nj=1\nt(i)\nj log y(i)\nj\n(8)\nwhere N is the number of data samples (training or CV\nrespectively); M\n= 4 is the number of labels (different\nprogramming problems); yj is the probability for label j\nestimated by the TCNN model; t is the actual label (one-of-all\ncoding), with tj indicating whether data sample i belongs to\nlabel j.\nSince no effective program representation existed before,\nthe deep TCNN model could not be trained at all, as the blue\ncurve demonstrates at the top of Part A in Figure 4. (Here, all\nmodel parameters are initialized randomly, which is a prevalent\nsetting in “shallow” architectures.) The reason is that gradients\nwill vanish or blow up during back propagation through a\ndeep network. No useful features are learned, and as a result,\nTCNN also performs poorly on the CV set, indicated by the\ncyan curve at the top of Part B in Figure 4.\nOn the contrary, the program representation serves as a\npretraining method. If the vector representations and the cod-\nTABLE III\nACCURACY OF PROGRAM CLASSIFICATION.\nMethod\nAccuracy\nRandom guess\n25.00%\nLogistic regression\n81.16%\nSVM with RBF kernel\n91.14%\nTDNN (a deep learning approach)\n95.33%\ning parameters, namely vec(·), Wl, Wr and b, are initialized\nas are learned by our coding criterion, the training and CV\nerrors decrease drastically (the red and magenta curves) after\na plateaux of about 15 epochs, which leads to the high\nperformance of TCNN.\nThe fact that unsupervised pretraining improves supervised\nlearning is also reported in [13], [14], [15], where RBMs and\nautoencoders are used as pretraining methods for generic data\n(mainly the MNIST handwritten digit dataset in these papers).\nAs pretraining explores underlying data features unsupervised,\nit gives a much more meaningful initialization of parameters.\nTherefore, the deep neural networks can be trained much faster\nand more effectively. Our experimental results in program\nanalysis are consistent with these reports in the literature in\nother ﬁelds.\nTo evaluate whether deep learning may be helpful for\nprogram analysis, we compare TCNN to baseline methods\nin the program classiﬁcation task. In these baseline methods,\nwe adopt the bag-of-words model, which is a widely-used\napproach in text classiﬁcation [52]. As shown in Table 4,\nlogistic regression, as a linear classiﬁer, achieves 81.16%\naccuracy. The support vector machine (SVM) with radial basis\nfunction (RBF) kernel explores non-linearity, and improves\nthe result by 10%. By automatically exploring the underlying\nfeatures and patterns of programs, TCNN further improves\nthe accuracy by more than 4%. This experiment suggests the\npromising future of deep leaning approaches in the ﬁeld of\nprogram analysis.\nTo sum up, we evaluate the learned representations empir-\nically by nearest neighbor querying and k-means clustering.\nProgram classiﬁcation experiment shows the learned represen-\ntations are greatly beneﬁcial for supervised learning.\nBased on the above experiments, we conclude that the\nproposed “coding criterion” based on ASTs is a successful\nrepresentation learning algorithm for programs.\nOur experimental result in program classiﬁcation conﬁrms\nthe feasibility of using deep learning to analyze programs. It\nalso shows primary evidence of its success in the new ﬁeld.\nVI. LOOKING FORWARD TO THE FUTURE\nAs evidence in the literature show, deep learning is making\nbreakthroughs in many ﬁelds of artiﬁcial intelligence. We\nbelieve it will also become an important method in various\ntasks in the ﬁeld of program analysis. As a pioneering study,\nwe address the following promising research topics in this new\narea.\nA. Different Perspectives for Program Modeling\nIn this paper, we treat a program as a tree, where each\nnode corresponds to an “abstract” component of the program.\nWe hypothesize in this paper that structural information is\nimportant to programs to a large extent, and our experiments\nconﬁrm our conjecture. However, the AST is not the only\nperspective of program modeling.\nAnother possible perspective is treating a program as a\nsequence of statements. Such perspective is also adopted in\ntraditional program analysis, e.g., API usage pattern mining\n[53], [54]. As the representations can be composited by atomic\nsymbols (e.g., AST nodes), we can also apply deep learning\napproaches to sequences of statements. Although some struc-\ntural information may be lost, the neighboring information are\ncaptured and local patterns can be extracted.\nTreating a program as a 2-dimensional signal is an interest-\ning, novel and also meaningful perspective, which is bionics-\ninspired. As we, human beings, always read source codes\non a 2-D screen, it is also possible for neural networks to\nmodel programs in this perspective. Indents and linefeeds on\nthe 2-D screen are useful features because they suggest strong\nsemantics of programs. Existing techniques in computer vision\ncan be applied, e.g. the convolutional neural network (CNN).\nCNN is analogous to visual cortex of human brains, and thus\nit has the solid biological foundation in cognitive science.\nInterestingly, as a bionics-inspired model, deep CNN achieved\nunexpected high performance [37] before pretraining methods\nwere invented.\nB. Integrating Prior about Programs to Network Architectures\nDespite the fact that a uniﬁed architecture of deep neural\nnetworks is applicable to various tasks with high performance,\nwe can also integrate human priors to the networks.\nCNN is an example that speciﬁes explicitly the physically\nneighborhood information of an image. Physically neighboring\npixels form local patterns (e.g. a circle, a line), which can be\ndetected by convolution kernels. Being fed forward to higher\nlayers in the network, the local patterns emerge high-level\nabstract features. Such abstract features are beneﬁcial for the\nultimate task (e.g., object recognition). Another widely-used\ndomain speciﬁc prior in deep learning is slowness [55], [56].\nAs it is not desired that features of image/acoustic data are\nchanging too fast, penalties of variation are added to the cost\nfunction, so that the learned features are “slow.”\nFor program analysis, priors can also be integrated to the\nneural networks. In one of our undergoing research, we would\nlike to capture the local features of ASTs. A tree-based\nconvolutional neural network (TCNN) is proposed and studied.\nPrimary results have been reported in Section V-B.\nAnother prior is that we can integrate formal methods of\nprogram analysis to neural networks (or vise versa). [57] is\nan example of neural reasoning for knowledge base. For pro-\ngrams, even though all non-trivial properties are undecidable,\nformal methods can be viewed as an approximation with pure\nmathematical deduction, often giving the guarantee of either\nno false-positive, or no false-negative, which may be important\nto program analysis [58]. For now, it seems hard to combine\nthese two techniques, but once they were combined, it would\nbe beneﬁcial for both.\nC. Various Applications\nThe application of deep learning in the ﬁeld of program\nanalysis is another promising research topic, which is at least\nas important as, if not more important than, the theory of deep\nlearning. Some are pointed out in Section I, including code\nclone detection, bug detection, and code retrieval.\nIn short, as deep learning is brand new to program analysis,\nthe questions addressed in this part still remain unknown to\nthe literature. It is not clear which perspective is most proper\nto model programs, or which is most suitable for what appli-\ncation. It is also not very clear how to integrate human priors\nabout programs to the neural network architecture. These are\namong the fundamental questions of deep learning when it is\napplied to the new ﬁeld. Besides, real-world applications of\ndeep learning are also important for program analysis.\nVII. CONCLUSION\nIn this paper, we study deep learning and representation\nlearning in the ﬁeld of program analysis. We propose a novel\n“coding criterion” to build vector representations of nodes\nin ASTs, which make deep learning a reality for program\nanalysis. We also feed the learned representations to a deep\nneural network to classify programs.\nThe experimental results show that our representations suc-\ncessfully capture the similarity and relationships among differ-\nent nodes in ASTs. The learned representations signiﬁcantly\nimprove supervised training for deep neural networks in terms\nof both optimization and generalization. We conclude that\nthe coding criterion is successful in building program vector\nrepresentations. The experiments also conﬁrm the feasibility of\ndeep learning to analyze programs, and show primary evidence\nof its success in the new ﬁeld.\nAs a pioneering study, we address several fundamental\nproblems, including the perspectives of program modeling,\nthe integration of human priors and the applications of deep\nlearning.\nTo promote further researches in the new ﬁeld, we publish\nall of our datasets, source codes, and learned representations\nonline.\nWe believe, considering the fact that deep learning has\nmade breakthroughs in many ﬁelds of artiﬁcial intelligence,\nalong with the primary evidence reported in this paper, deep\nlearning will become an outstanding approach of program\nanalysis in the near future. We call for more studies in this\nnew, prospective ﬁeld.\nREFERENCES\n[1] H. Lu, B. Cukic, and M. Culp, “Software defect prediction using\nsemi-supervised learning with dimension reduction,” in Proceedings of\nthe 27th IEEE/ACM International Conference on Automated Software\nEngineering, 2012.\n[2] S. Lee, C. Jung, and S. Pande, “Detecting memory leaks through\nintrospective dynamic behavior modelling using machine learning,” in\nProceedings of 36th International Conference on Software Engineering,\n2014.\n[3] K. Canavera, N. Esfahani, and S. Malek, “Mining the execution history\nof a software system to infer the best time for its adaptation,” in\nProceedings of the ACM SIGSOFT 20th International Symposium on\nthe Foundations of Software Engineering, 2012.\n[4] A. Hindle, E. Barr, Z. Su, M. Gabel, and P. Devanbu, “On the natural-\nness of software,” in Proceedings of 34th International Conference on\nSoftware Engineering, 2012.\n[5] G. Hinton, S. Osindero, and Y. Teh, “A fast learning algorithm for deep\nbelief nets,” Neural Computation, vol. 18, no. 7, pp. 1527–1554, 2006.\n[6] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and\nP. Kuksa, “Natural language processing (almost) from scratch,” The\nJournal of Machine Learning Research, vol. 12, pp. 2493–2537, 2011.\n[7] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. Manning, A. Ng, and\nC. Potts, “Recursive deep models for semantic compositionality over\na sentiment treebank,” in Proceedings of Conference on Empirical\nMethods in Natural Language Processing, 2013.\n[8] A. Krizhevsky, I. Sutskever, and G. Hinton, “ImageNet classiﬁcation\nwith deep convolutional neural networks,” in Advances in Neural Infor-\nmation Processing Systems, 2012.\n[9] D. Ciresan, U. Meier, and J. Schmidhuber, “Multi-column deep neural\nnetworks for image classiﬁcation,” in IEEE Conference on Computer\nVision and Pattern Recognition, 2012.\n[10] G. Dahl, A. Mohamed, and G. E. Hinton, “Phone recognition with the\nmean-covariance restricted Boltzmann machine,” in Advances in Neural\nInformation Processing Systems, 2010.\n[11] A. Mohamed, G. Dahl, and G. Hinton, “Acoustic modeling using deep\nbelief networks,” IEEE Transactions on Audio, Speech, and Language\nProcessing, vol. 20, no. 1, pp. 14–22, 2012.\n[12] R. Collobert and J. Weston, “A uniﬁed architecture for natural language\nprocessing: Deep neural networks with multitask learning,” in Proceed-\nings of the 25th International Conference on Machine learning, 2008.\n[13] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle, “Greedy layer-\nwise training of deep networks,” in Advances in Neural Information\nProcessing Systems, 2007.\n[14] D. Erhan, P. Manzagol, Y. Bengio, S. Bengio, and P. Vincent, “The\ndifﬁculty of training deep architectures and the effect of unsupervised\npre-training,” in Proceedings of International Conference on Artiﬁcial\nIntelligence and Statistics, 2009.\n[15] H. Larochelle, Y. Bengio, J. Louradour, and P. Lamblin, “Exploring\nstrategies for training deep neural networks,” The Journal of Machine\nLearning Research, vol. 10, pp. 1–40, 2009.\n[16] Y. Bengio, P. Simard, and P. Frasconi, “Learning long-term dependen-\ncies with gradient descent is difﬁcult,” IEEE Transactions on Neural\nNetworks, vol. 5, no. 2, pp. 157–166, 1994.\n[17] D. Steidl and N. Gode, “Feature-based detection of bugs in clones,” in\n7th International Workshop on Software Clones, 2013.\n[18] M. Chilowicz, E. Duris, and G. Roussel, “Syntax tree ﬁngerprinting\nfor source code similarity detection,” in Proceedings of IEEE 17th\nInternational Conference on Program Comprehension, 2009.\n[19] A. Mnih and G. Hinton, “A scalable hierarchical distributed language\nmodel,” in Advances in Neural Information Processing Systems, 2009.\n[20] G. Miller, “WordNet: a lexical database for English,” Communications\nof the ACM, vol. 38, no. 11, pp. 39–41, 1995.\n[21] F. Morin and Y. Bengio, “Hierarchical probabilistic neural network lan-\nguage model,” in Proceedings of International Conference on Artiﬁcial\nIntelligence and Statistics, 2005.\n[22] S. Ugurel, R. Krovetz, and L. Giles, “What’s the code?: Automatic\nclassiﬁcation of source code archives,” in Proceedings of the 8th ACM\nSIGKDD International Conference on Knowledge Discovery and Data\nMining, 2002.\n[23] K. Murphy, Machine Learning: A Probabilistic Perspective. MIT press,\n2012.\n[24] R. Kaur and S. Singh, “Clone detection in software source code\nusing operational similarity of statements,” ACM SIGSOFT Software\nEngineering Notes, vol. 39, no. 3, pp. 1–5, 2014.\n[25] Y. Udagawa, “Source code retrieval using sequence based similarity,” In-\nternational Journal of Data Mining & Knowledge Management Process,\nno. 4, 2013.\n[26] N. Murakami and H. Masuhara, “Optimizing a search-based code recom-\nmendation system,” in 3rd International Workshop on Recommendation\nSystems for Software Engineering, 2012.\n[27] Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin, “A neural proba-\nbilistic language model,” Journal of Machine Learning Research, vol. 3,\npp. 1137–1155, 2003.\n[28] A. Mnih and G. Hinton, “Three new graphical models for statistical lan-\nguage modelling,” in Proceedings of the 24th International Conference\non Machine learning, 2007.\n[29] E. Huang, R. Socher, C. Manning, and A. Ng, “Improving word\nrepresentations via global context and multiple word prototypes,” in\nProceedings of the 50th Annual Meeting of the Association for Com-\nputational Linguistics, 2012.\n[30] J. Pane, C. Ratanamahatana, and B. Myers, “Studying the language\nand structure in non-programmers’ solutions to programming problems,”\nInternational Journal of Human-Computer Studies, vol. 54, no. 2, pp.\n237–264, 2001.\n[31] Y. Bengio, “Learning deep architectures for AI,” Foundations and Trends\nin Machine Learning, vol. 2, no. 1, pp. 1–127, 2009.\n[32] Y. Bengio, A. Courville, and P. Vincent, “Representation learning: A\nreview and new perspectives,” IEEE Transactions on Pattern Analysis\nand Machine Intelligence, vol. 35, no. 8, pp. 1798–1828, 2013.\n[33] T. Mitchell, Machine Learning.\nMcGraw Hill, 1997.\n[34] G. Cybenko, “Approximation by superpositions of a sigmoidal function,”\nMathematics of Control, Signals and Systems, vol. 2, no. 4, pp. 303–314,\n1989.\n[35] J. Hastad and M. Goldmann, “On the power of small-depth threshold\ncircuits,” Computational Complexity, vol. 1, no. 2, pp. 113–129, 1991.\n[36] V. N. Vapnik and V. Vapnik, Statistical learning theory.\nWiley New\nYork, 1998.\n[37] Y. LeCun, L. Jackel, L. Bottou, A. Brunot, C. Cortes, J. Denker,\nH. Drucker, I. Guyon, U. Muller, and E. Sackinger, “Comparison of\nlearning algorithms for handwritten digit recognition,” in Proceedings\nof International Conference on Artiﬁcial Neural Networks, 1995.\n[38] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, “Distributed\nrepresentations of words and phrases and their compositionality,” in\nAdvances in Neural Information Processing Systems, 2013.\n[39] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efﬁcient estimation of\nword representations in vector space,” in ICLR Workshop, 2013.\n[40] T. Mikolov, M. Karaﬁat, L. Burget, J. Cernocky, and S. Khudanpur,\n“Recurrent neural network based language model,” in INTERSPEECH,\n2010.\n[41] I. Sutskever, J. Martens, and G. Hinton, “Generating text with recurrent\nneural networks,” in Proceedings of the 28th International Conference\non Machine Learning, 2011.\n[42] I. Baxter, A. Yahin, L. Moura, M. Sant’Anna, and L. Bier, “Clone\ndetection using abstract syntax trees,” in Proceedings of the International\nConference on Software Maintenance, 1998.\n[43] F. Lazar and O. Banias, “Clone detection algorithm based on the Abstract\nSyntax Tree approach,” in Proceedings of 9th IEEE International Sym-\nposium on Applied Computational Intelligence and Informatic, 2014.\n[44] F. Yamaguchi, M. Lottmann, and K. Rieck, “Generalized vulnerability\nextrapolation using abstract syntax trees,” in Proceedings of 28th Annual\nComputer Security Applications Conference, 2012.\n[45] R. Socher, Q. Le, C. Manning, and A. Ng, “Grounded compositional\nsemantics for ﬁnding and describing images with sentences,” in NIPS\nDeep Learning Workshop, 2013.\n[46] R. Socher, E. Huang, J. Pennin, C. Manning, and A. Ng, “Dynamic\npooling and unfolding recursive autoencoders for paraphrase detection,”\nin Advances in Neural Information Processing Systems, 2011.\n[47] K. Hermann and P. Blunsom, “Multilingual models for compositional\ndistributed semantics,” in Proceedings of the 52nd Annual Meeting of\nthe Association for Computational Linguistics, 2014.\n[48] R. Socher, D. Chen, C. Manning, and A. Ng, “Reasoning with neural\ntensor networks for knowledge base completion,” in Advances in Neural\nInformation Processing Systems, 2013.\n[49] W. Cohen, R. Schapire, and Y. Singer, “Learning to order things,” in\nAdvances in Neural Information Processing Systems, 1998.\n[50] E. Gabrilovich and S. Markovitch, “Computing semantic relatedness\nusing Wikipedia-based explicit semantic analysis.” in Proceedings of\nthe 20th International Joint Conference on Artiﬁcial Intelligence, 2007.\n[51] C. Roy, J. Cordy, and R. Koschke, “Comparison and evaluation of code\nclone detection techniques and tools: A qualitative approach,” Science\nof Computer Programming, vol. 74, no. 7, pp. 470–495, 2009.\n[52] R. Feldman and J. Sanger, The Text Mining Handbook: Advanced\nApproaches in Analyzing Unstructured Data.\nCambridge University\nPress, 2007.\n[53] J. Wang, Y. Dang, H. Zhang, K. Chen, T. Xie, and D. Zhang, “Mining\nsuccinct and high-coverage API usage patterns from source code,” in\nProceedings of IEEE Working Conference on Mining Software Reposi-\ntories, 2013.\n[54] M. Acharya, T. Xie, J. Pei, and J. Xu, “Mining API patterns as partial\norders from source code: From usage scenarios to speciﬁcations,” in\nProc. of ESEC/SIGSOFT FSE, 2007.\n[55] C. Cadieu and B. Olshausen, “Learning transformational invariants from\nnatural movies,” in Advances in Neural Information Processing Systems,\n2008.\n[56] J. Bergstra and Y. Bengio, “Slow, decorrelated features for pretraining\ncomplex cell-like networks,” in Advances in Neural Information Pro-\ncessing Systems, 2009.\n[57] R. Socher, D. Chen, and A. N. C. Manning, “reasoning with neural\ntensor networks for knowledge base completion,” in Advances in Neural\nInformation Processing Systems, 2013.\n[58] M. Pradel and T. Gross, “Leveraging test generation and speciﬁcation\nmining for automated bug detection without false positives,” in Procee-\nings of 24th International Conference on Software Engineering, 2012.\n",
  "categories": [
    "cs.SE",
    "cs.LG",
    "cs.NE"
  ],
  "published": "2014-09-11",
  "updated": "2014-09-11"
}