{
  "id": "http://arxiv.org/abs/1505.06800v1",
  "title": "Boosting-like Deep Learning For Pedestrian Detection",
  "authors": [
    "Lei Wang",
    "Baochang Zhang"
  ],
  "abstract": "This paper proposes boosting-like deep learning (BDL) framework for\npedestrian detection. Due to overtraining on the limited training samples,\noverfitting is a major problem of deep learning. We incorporate a boosting-like\ntechnique into deep learning to weigh the training samples, and thus prevent\novertraining in the iterative process. We theoretically give the details of\nderivation of our algorithm, and report the experimental results on open data\nsets showing that BDL achieves a better stable performance than the\nstate-of-the-arts. Our approach achieves 15.85% and 3.81% reduction in the\naverage miss rate compared with ACF and JointDeep on the largest Caltech\nbenchmark dataset, respectively.",
  "text": "BOOSTING-LIKE DEEP LEARNING FOR PEDESTRIAN \nDETECTION \nLei Wang1,1, Baochang Zhang 1 \n1School of Automation Science and Electrical Engineering \nBeihang University, Beijing, China \nwtiffanyl@163.com; bczhang@buaa.edu.cn \nAbstract. This paper proposes boosting-like deep learning (BDL) framework for pedestrian \ndetection. Due to overtraining on the limited training samples, overfitting is a major problem of \ndeep learning. We incorporate a boosting-like technique into deep learning to weigh the training \nsamples, and thus prevent overtraining in the iterative process. We theoretically give the details of \nderivation of our algorithm, and report the experimental results on open data sets showing that \nBDL achieves a better stable performance than the state-of-the-arts. Our approach achieves 15.85% \nand 3.81% reduction in the average miss rate compared with ACF and JointDeep on the largest \nCaltech benchmark dataset, respectively. \nKey words: pedestrian detection   boosting-like   feature learning   feedback propagation \n1   Introduction \nPedestrian detection has an important significance in real life, which has been widely used in \nintelligent control systems, traffic safety assist systems, robotics research and other fields. It has \nattracted more and more attention, and a variety of feature extraction and classification methods have \nbeen proposed. The main feature extracting methods are divided into two categories: handcrafted \nextraction and automatic learning. The famous handcrafted extraction methods are HOG [1]. HOG \nportrays the local gradient magnitude and direction of the image, which normalizes vector feature \nblocks based on gradient features. It allows overlap between blocks, thus it is not sensitive to the light \nchanges and a small amount shift. Therefore, it can effectively depict the human body edge feature. \nOther commonly used methods are Haar-like [2], SIFT [3], covariance descriptors [4], integral channel \nfeatures [5], 3D geometric characteristic [6] and so on. With the computer development and data \nvolumes grow, automatic learning methods are gradually put forward. Sermanet et al. [7] proposed the \nConvNet structure, which uses the original pixel values as the input. It combines unsupervised and \nsupervised methods to train multi-stage automatic sparse convolution encoder. It shows a relatively \nimpressive result on INRIA pedestrian database, but does not give test results on Caltech. UDN [8] is a \njoint deep neural network model combined with deformation and occlusion model, which achieves a \nlower miss rate than the conventional human detection HOGCSS SVM algorithm on Caltech and ETH \ndataset. Lim J et al. [9] use a supervised training mode to extract middle class feature based on contour \ninformation, and train random forest classifier to improve performance.  \nThe manual feature extraction has a good description for pedestrians, but it can’t learn the essential \ncharacteristics and has poor adaptability. The latter can automatically extract pedestrian features by \nmethods such as feedback propagation. But it requires a lot of training samples and takes a lot of time. \nWhat’s more, it has higher hardware requirement. Based on the characteristics of the two kinds of \nfeature extraction methods, we propose a novel pedestrian detection framework. It combines manual \nfeature extraction method with the deep learning model, and incorporates the boost ideas into our \nframework. We gradually adjust the sample weight in feedback training process. Our method can not \nonly improve pedestrian detection performance, but also strengthen the stability of the convolution \nneural network. In addition, our input features are inspired by integral channel features [10], but we \nregularize them in order to improve the detection rate. Our deep structure only uses a simple convoluti- \nonal neural network [11] which consists of two convolutional layers to gain a higher level feature \nexpression. The final classifier we use is only a simple single neural network. \nThe main contributions of this paper are described as follows: firstly, the combination of modified \nintegral channel features and simple CNN network, using the back-propagation algorithm for training; \nsecondly, the introduction of boosting-like structure in the deep learning network, gradually adjusting \nthe training sample weights in the feedback propagation to improve the detection structure stability and \nconvergence speed. \nThe remainder of this paper is arranged as follows: in section 2, our pedestrian detection structure is \ndescribed, including the input channel features and deep learning structure. In section 3, the \nboosting-like algorithm that we proposed is elaborated. In section 4, experimental results are presented \nand analyzed, and in section 5, we conclude the paper. \n2   Pedestrian Detection Framework \n2. 1   Input channel features \nChannel features can be gained through making different output functions in response to input image \n  which may be linear or non-linear transformation, such as the Gabor filters belonging to the linear \ntransformation, and canny edge detection non-linear transformation. Assume channel response function \nis  , the channel output is  , the image   respond is given as follows: \n                  \n \n \n \n \n                                           (1) \nwhere   denotes a simple first-order feature function as a sum of pixels in a fixed rectangular area. \nHigh-order features can be obtained by combining several first-order functions via a variety of \nstrategies. In addition, the combination of different channels is denoted the aggregate channel features. \nIn this paper, we extract low-level pedestrian features in order to improve the training speed by \nreducing the number layers of deep learning network, and then extract the high-level features through \nour deep network. Specific steps are as follows: \nStep one: In this paper, we use color and gradient feature as input channels. In concrete terms, we \nchange the RGB input image into LUV three-channel image, then one gradient magnitude channel (| G \n|) and six histogram of gradient oriented channels(G1-G6) are gained through conversion processing on \ninput images. \nStep two: Since pedestrian images are influenced seriously by illumination, the data in each channel \nis processed to be zero mean and unit variance. Since our network activation function is Sigmoid, this \nprocessing can also increase the convergence rate in the gradient descent process [12]. \n \nFig. 1. Comparison of channel features \nThe first column is the original input image, then the second column to the tenth column correspond \nto LUV, | G | and the G1-G6 channel features. The first row is the original ACF feature, and the second \nrow is the one after normalization. The results show that regularization not only enhances the image \nresolution significantly, but also highlights the pedestrian details. \n2.2   CNN structure \nCNN is the neural network including multilayer, and each layer includes a plurality of two dimensi- \nonal planes. Each plane also includes multiple neurons. The two-dimensional image data can be direc- \ntly as input channels. Furthermore, feature extraction step has been embedded in the structure of CNN.  \nCNN mainly achieves deformation, shift and scale invariance [13] by local receptive fields, shared \nweights and down-sampling. The local receptive fields of two dimensional -space can make neural \nnetwork extract primary visual features from the input image, such as edge, endpoint, corner and so on. \nSubsequent layers obtain higher level features through combining these primary characteristics. Neuro- \nns can detect the same characteristics in different locations on the input image by shared weights. Then \nthe input translation changes will be appeared in the output in the same direction and distance, but it \ndoesn’t cause other forms of change. At the same time, the weight sharing also significantly reduces \nthe training weights number. Sub-sampling not only filters out the noisy characteristics, but also \nenhances features which are crucial to image recognition. CNN model in this paper is shown in Figure \n2: \n \nFig. 2. CNN structure \nAs Figure 2 shown, there are total five layers in addition to input layer. The input image size is 84 x \n28 pixels. A1 layer consists of 10 feature maps, which size is the same as the input one 84 x 28. C2 lay- \ner contains 64 filter kernels, and each kernel includes 9 x 9 = 81 weight parameters. It’s multiplied by \n10 and adding a bias, so there are (9x9 x 10 +1 ) x 64 = 61904 parameters. The 10 input channels \nrespectively convolution with 64 filters, then add a bias. All of them are entered into an excitation \nfunction. It is calculated by the following formula: \n                                  \n     \n         \n    \n                                (2) \nWhere   \n  denotes the  -th feature map of the  -th layer, and    represents all the feature maps of \nthe  -th channel.     indicates learning parameter that corresponds to convolutional kernel, and   \n  \nrepresents the bias of the n-th input image in the  -th layer. S (∙) is the activation function, such as \nsigmoid function. S3 is the down-sampling layer, wherein each neuron in the feature map corresponds \nto 4 x 4 neighborhood of C2 layer. 16 units are summed in S3 layer, and multiplied by a training \nparameter with a training bias. Finally, they are transferred by an excitation function to obtain 64 \nfeature maps with size 21x7. It is calculated as follows: \n                                 \n      \n     \n    \n                             (3) \nHere   represents scalar training parameters which values vary with the sub-sampling methods, \nsuch as using Mean-Poo ing, β = 1 / m, m represents down sample in m × m pixels (common size of 2 \n× 2). So the output image size is reduced to m times of original image. The output map has a bias \ndenoted by   \n , then it is transferred into a nonlinear function (such as Sigmoid function). \nC4 is also a convolutional layer, and we use 20 filter kernels with different size, and gain 20 \ndifferent size feature maps. When cascading all of them, we obtain a final fully connected layer. The \nnumber is 565 in the full connection layer of our network. Finally, it is the recognition classifier, which \nshould be differentiable on weights. Only in this case, you can use BP algorithm to train the network. \nCNN classifier used in this paper is a single fully connected neural network, other commonly used \nfunction such as logistic regression polynomial or radial basis function. \n \nFig. 3. Visualization of convolution kernel maps  \nThe first row is the visual maps of the second layer convolution kernels, and the second row is the \nvisual maps of the fourth layer convolution kernels. It can be seen that the filter kernels of the second \nlayer mostly contain edges, lines features, and the fourth layer mainly consists of corner, point features. \nDeep network extracts more and more essential features with layers increasing, which can describe the \npedestrian nature characteristics. \n3   Boosting-like  \nAs we all know, the training method of the convolutional neural network is mostly back \npropagation, and the network stability and convergence speed is a common problem in the process of \ntraining the model. If the learning rate is too large to gain a fast convergence speed it’s easy to fall into \nlocal minimum. Otherwise, slow updating could result in time-consuming [14]. Therefore, we consider \nthe boost algorithm, which adjusts the update rate according to the samples classification situation in \nthe training process. It ensures the convergence speed and prevents network overfitting, which makes \nthe network more stable. Generally, the cost function of convolution neural network is square error \nfunction. Assuming the samples are divided into C classes, the individual error for n-th samples is \ngiven by: \n                               \n \n  \n   \n    \n    \n \n   \n.                        (4) \nHere   \n  denotes the k-th dimension of the n-th sample label, and   \n  is similarly the k-th output \nlayer unit in response to the n-th sample. In the practical application, we always sum the square error of \nall samples. The input    of the     layer and output       of         layer have the \nfollowing linear relationship: \n                                                                        (5) \nWhere    denotes output layer weight and    denotes the bias. They are constantly adjusted in \nthe training process.      is the     layer output, and   is a penalty weight.   is the excitation \nfunction for the output layer, which is commonly chosen to be the sigmoid function or hyperbolic \ntangent function. Then the output layer sensitivity by the derivation is: \n                                                                       (6) \nThe derivative of error   against weight    is as follows:      \n                     \n  \n                                                  (7) \nFinally, the delta updating rule is applied to each neuron to gain the new weights. The formula is \ngiven by: \n                            \n  \n                                      (8) \nHere   is the learning rate, thus we can obtain the weight   updating method. Actually, the \nconvolution neural network itself can be seen as several cascaded feature extractors, and each layer can \nbe considered as a feature extractor. The features extracted are from low-level to high-level, and the \nresults have a mutual suppression, which is to say that a classifier output not only has a relationship \nwith the previous layer but also the next one. According to the formula (8), we distribute the feedback \nweights of right and wrong classification samples, which is feedback propagated from the last layer to \nthe beginning layer. \n                                               \n                  \n  .                      (9) \nWhere      is the output error,    is the actual detection value of the network, and    is the \nsample target value. Meanwhile     is the output layer sensitivity   in our network.    and    are \nrespectively the penalty coefficients of right and wrong classified samples. When the sample output \nvalue is different with its label, the penalty weight should be increased; on the contrary, when the same, \nit should be decreased. This idea is similar to the boost algorithm, which trains different classifier by \nconstantly updating the weights of training samples. It can avoid overfitting, thus making the network \nperformance more stable. In this paper, the overall pedestrian detection framework is shown in \nFigure 4. \n \nFig. 4. Our pedestrian detection framework \nOverview of our pedestrian detection structure, original image is extracted with ACF features \nand regularized. Then through the two layer convolution operations higher level pedestrian features are \nobtained. According to the output value of sample, the boost theory is merged into convolutional neural \nnetwork over feedback propagation. This method not only enhances the network stability, but \nalso greatly improves the detection performance. \n4   Experimental results \nOur pedestrian detection framework is evaluated on the Caltech dataset, which is currently the \ncommonly \nused \npedestrian dataset. \nIt contains \nmany complicated \nscenes including occlusion, \nillumination, deformation, and so on. In the experiment we use set00~set05 to train our model. There \nare about 60000 training samples, which include about 4000 positive ones. Set06~set10 are adopted as \ntest sets. Usually sliding windows are used to traverse the pedestrian image in the detection stage. It is \nwell known that the feedback process in the deep learning network structure takes a lot of \ntime. Therefore, we use the strategy which is similar to UDN [8]. The detector using HOG+CSS and \nlinear SVM is utilized for pruning candidate detection windows to save computation, and then the \ncandidate windows are detected by deep network structure. These candidate windows have a high \nrecall rate, and certainly contain a lot of false positive windows. This approach not only improves the \ntraining speed, but also meets the needs on testing the performance of our pedestrian detection \nstructure. \n4.1   Comparison of boosting-like stability \nFigure 5 shows the comparison of using boosting-like algorithm or not in pedestrian detection struc- \nture. The abscissa represents training iterations, and the ordinate denotes the average miss rate which is \ntested by every trained model on Caltech-test dataset. This log-average miss rate is evaluated by the u- \nnified criteria proposed in [15]. Furthermore, the experiments are carried out on Caltech database. \n \n \nFig. 5. Comparison of Boosting-like in terms of stability and detection performance  \nWe can see from the comparison results: firstly, the curve is relatively stable when using boosting-l- \nike method in the feedback propagation, and volatility is smaller. Whi e it’s poor in stability without \nthe boosting-like, volatility is large. Secondly, the boosting-like algorithm achieves 0.48% pedestrian \ndetection performance gain. Therefore, this method not only improves the network stability, but also sl- \nightly improves the system detection accuracy while it doesn’t reduce the convergence speed. \n4.2   Results of the Caltech dataset \nThe evaluation method proposed in [15] is used to check detection performance of our pedestrian \ndetection framework which gains the curve between the log-average miss rate and false positive \nrate of each image. In the experiment, we evaluate the detection performance in the reasonable subset \nwhich is a commonly used pedestrian detection collection. It consists of pedestrians who are more than \n49 pixels in height, and whose occluded portions are less than 35%. We compared with the popular \napproaches related to our method: VJ [16], HOG, ConvNet [17], ACF [18], JointDeep [8], HOGCSS. \nThese methods use various features, deformation models and different classifiers. Our experimental \nmethod is denoted by BDL. \n \nFig. 6. Comparison of log-average miss rate vs. false positives per image (FPPI) between our approach \nBDL and related methods on Caltech dataset. \nFigure 6 shows that the log-average miss rate of the pedestrian detection method we propose is \n35.51%. It can be seen that our approach gets 15.85% and 3.81% performance gains compared with the \nACF [10] and JointDeep [8] respectively on Caltech test. It should be noted that complicated   methods \nsuch as deformation model, occlusion model, context information and joint training are not employed \nin our framework. Figure 7 shows some of pedestrian detection results on Caltech dataset. \n \nFig. 7. Samples of pedestrian detection results on Caltech dataset \n5   Conclusion \nIn this paper, we propose a simple but effective pedestrian detection framework. We use a similar b- \noost idea to train the network structure which not only improves the system stability but also reduces \nthe average miss rate of pedestrian detection. Through interaction, it achieves 15.85% and 3.81% perf- \normance gains compared with the corresponding methods on the largest Caltech dataset, respectively. \nFinally the experimental results demonstrate the validity and stability of our model. Through the exper- \niments we can get the following conclusions: boosting-like method that we propose can improve detec- \ntion stability and performance. The deep model is more time-consuming while training process, while \nthe traditional handcrafted feature extraction owns poor adaptability. When we use low- level handcar- \nfted features as input channels, less layers of deep structure can effectively improve the classification \nperformance, meanwhile it can improve the training speed.  We are certain that if the pedestrian detect- \nion measures such as momentum [19], dropout [20] or multi-scale [21] techniques are carried out by \nour structure, the system performance will further enhance. \nReferences  \n1. Dalal N, Triggs B: Histograms of Oriented Gradients for Human Detection[C]. //IEEE Conference on Computer \nVision & Pattern Recognition. IEEE Computer Society, 886--893 (2005) \n2. P. Viola, M. J. Jones, and D. Snow: Detecting pedestrians using patterns of motion and appearance. IJCV, \n63(2):153--161(2005) \n3. A. Vedaldi, V. Gulshan, M. Varma, and A. Zisserman: Multiple kernels for object detection. IEEE 12th \nInternational Conference, 606--613(2009) \n4. O Tuzel, F Porikli, P Meer: Pedestrian detection via classification on riemannian manifolds. IEEE Trans.PAMI, \n30(10):1713--1727(2008) \n5. P. Doll´ar, Z. Tu, P. Perona, and S. Belongie: Integral channel features. In: BMVC, 2009, vol. 2, p.(2009)  \n6. Hoiem D, Efros A A, Hebert M: Putting objects in perspective[J]. International Journal of Computer Vision, \n80(1):2137--2144(2006) \n7. Sermanet P, Soumithchintala K, Lecun Y: Pedestrian Detection with Unsupervised Multi-Stage Feature \nLearning[J]. IEEE Conference on Computer Vision & Pattern Recognition, 3626--3633(2012)   \n8. Wanli Ouyang,Xiaogang Wang: Joint Deep Learning for Pedestrian Detection[C]. ICCV,266--274(2013) \n9. Lim J J, Lawrence Zitnick C, Dollár P. Sketch Tokens: A Learned Mid-level Representation for Contour and \nObject Detection[J]. IEEE Conference on Computer Vision & Pattern Recognition, 9(4):3158--3165(2013) \n10. Dollar P, Appel R, Belongie S, et al: Fast Feature Pyramids for Object Detection[J]. IEEE Transactions on \nPattern Analysis & Machine Intelligence, 36(8):1532--1545(2014) \n11．LeCun Y,Bottou L, Bengio Y, et al: Gradient-based learning applied to document recognition[J]. Proc of the \nIEEE,86(11): 2278—2324(1998) \n12. Bouvrie J, Bouvrie J: Notes on Convolutional Neural Networks[J]. Neural Nets(2006)  \n13. HUBEL D H, WUESEK T N. Receptive fields, binocular interaction and functiona  architecture in the cat’s \nvisual cortex[J]. J. Physiol, 1962, 160(12), 106--154(1962) \n14. CHEN Y N, HAN C C, WANG C T, et al.:The application of a convolution neural network on face and license \nplate detection[C]. Proc. 18th Int. Conf. Pattern Recognition (ICPR’06), 552--555(2006) \n15. P. Doll´ar, C. Wojek, B. Schiele, P. Perona: Pedestrian detection: An evaluation of the state of the art. IEEE \nTransactions on Software Engineering, 34(4):743--761(2012) \n16. P. Viola, M. J. Jones, and D. Snow: Detecting pedestrians using patterns of motion and appearance. IJCV, \n63(2):153--161(2005) \n17. Sermanet P, Kavukcuoglu K, Chintala S, et al.: Pedestrian Detection with Unsupervised Multi-Stage Feature \nLearning[J]. IEEE Conference on Computer Vision & Pattern Recognition, 3626--3633(2012) \n18. Nam W, Dollr P, Han J H: Local Decorrelation For Improved Detection[J]. Eprint Arxiv(2014)  \n19. Sutskever I, Martens J, Dahl G, et al: On the importance of initialization and momentum in deep learning[J]. \nProceedings of International Conference on Machine Learning (2013) \n20. Baldi P, Sadowski P: The Dropout Learning Algorithm.[J]. Artificial Intelligence, 210(3):78--122 (2014) \n21. Ye Q, Jiao J, Zhang B: Fast pedestrian detection with multi-scale orientation features and two-stage \nclassifiers[C]. IEEE International Conference on Image Processing, 881--884(2010) \n \n",
  "categories": [
    "cs.CV",
    "cs.LG",
    "cs.NE"
  ],
  "published": "2015-05-26",
  "updated": "2015-05-26"
}