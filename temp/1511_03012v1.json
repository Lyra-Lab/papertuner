{
  "id": "http://arxiv.org/abs/1511.03012v1",
  "title": "Information retrieval in folktales using natural language processing",
  "authors": [
    "Adrian Groza",
    "Lidia Corde"
  ],
  "abstract": "Our aim is to extract information about literary characters in unstructured\ntexts. We employ natural language processing and reasoning on domain\nontologies. The first task is to identify the main characters and the parts of\nthe story where these characters are described or act. We illustrate the system\nin a scenario in the folktale domain. The system relies on a folktale ontology\nthat we have developed based on Propp's model for folktales morphology.",
  "text": "Information retrieval in folktales using natural\nlanguage processing\nAdrian Groza and Lidia Corde∗\n∗Intelligent Systems Group,\nDepartment of Computer Science,\nTechnical University of Cluj-Napoca, Romania\nAdrian.Groza@cs.utcluj.ro,Lidia.Corde@cs-gw.utcluj.ro\nAbstract—Our aim is to extract information about literary\ncharacters in unstructured texts. We employ natural language\nprocessing and reasoning on domain ontologies. The ﬁrst task is\nto identify the main characters and the parts of the story where\nthese characters are described or act. We illustrate the system in\na scenario in the folktale domain. The system relies on a folktale\nontology that we have developed based on Propp’s model for\nfolktales morphology.\nIndex Terms—Natural language processing, ontologies, literary\ncharacter, folktales.\nI. INTRODUCTION\nRecognising literary characters in various narrative texts\nis challenging both from the literary and technical perspec-\ntive. From the literary viewpoint, the meaning of the term\n“character” leaves space to various interpretations. From the\ntechnical perspective, literary texts contain a lot of data about\nemotions, social life or inner life of the characters, while they\nare very thin on technical, straight-forward messages. To infer\nthe character type from literary texts might pose problems even\nto the human readers [4].\nInteractions between literary characters contain rich social\nnetworks. Extracting these social networks from narrative text\nhas gained much attention [13] in different domains such as\nliterary ﬁction [6], screenplays [1], or novels [9], [2].\nOur aim is to correctly determine the relationships of a\ncharacter in a tale and to ﬁnd its role upon the development\nof the story. In line with [16], the ﬁrst task is to identify\nthe parts of the story where that character is involved. Our\napproach relies on interleaving natural language processing\nand ontology-based reasoning. We enact our method in the\nfolktale domain.\nInformation extraction systems usually have three compo-\nnents responsible for: named entity recognition, co-reference\nresolution and relationship extraction. These modules are\nintegrated in a pipeline, in a layered manner, given that each\ntask will use information provided by the previous neighbor.\nNatural language processing has been applied in the domain\nof folktales [14], [8]. Formal models for folktales have been\nproposed in [12], [15]. Character identiﬁcation in folktales\nhave been approached in [17], [19].\nThe remaining of the paper is organized as follows: Sec-\ntion II presents the ontology that we developed for modeling\nTABLE I\nMAIN CHARACTERS IN THE PROPP’S MODEL.\nName\nDescription\nVillain\nThe opponent of the hero - often the representation\nof evil.\nDispatcher\nThe person that sends the hero into the journey, or\nthe person that informs the hero about the villainy.\n(Magical) Helper\nThe one that helps the hero into its journey.\nPrincess or Prize\nIt represents what the hero receives when it is\nvictorious.\nDonor\nPrepares the hero for the battle.\nHero\nThe main character in a story - often the represen-\ntation of good.\nFalse hero\nThe one that tries to steal the prize from the hero,\nor tries to marry the princess.\nthe domain of folktales. Section III depicts the architecture\nof our system. Section IV illustrates our method to extract\nknowledge about characters. Section V presents the experi-\nmental results on seven folktales. Section VI browses related\nwork, while section VII concludes the paper.\nII. ENGINEERING THE FOLKTALE ONTOLOGY\nTo support reasoning in the folktale domain, we developed\nan ontology used to extract knowledge regarding characters.\nWe assume the reader is familiarised with the syntax of\nDescription Logic (DL). For a detailed explanation about\nfamilies of description logics, the reader is referred to [3].\nTo support character identiﬁcation and reasoning on these\ncharacters we need structured domain knowledge. Hence, we\ndeveloped an ontology for the folktale domain as shown in\nFig. 3. Our folktale ontology formalizes knowledge from\nthree sources: 1) the folktale morphology as described by the\nPropp model [15]; 2) various entities speciﬁc to folktales (i.e.,\nanimals, witch, dragons); and 3) common family relations (i.e.,\nchild, ﬁancee, groom). In the following, these three knowledge\nsources are detailed:\na) Folktale morphology: Firstly, we rely on the Propp’s\nmodel [15] of the folktale domain. In the Propp’s model the\nstory broke down into several sections. Propp demonstrated\nthat the sequence of sections appears in the same chronological\norder in Russian folktales. Propp identiﬁed a set of character\ntypes that appear in most of the folktales (see Table I).\nThe corresponding formalization in Description Logic ap-\npears in Fig. 1, where the characters are divided in nine types\n978-1-4673-8200-7/15 $31.00 c⃝2015 IEEE\narXiv:1511.03012v1  [cs.CL]  10 Nov 2015\nA1\nAgent ⊔Donor ⊔FalseHero ⊔Hero ⊔Prisoner ⊔Villain ⊔Dis-\npatcher ⊔MagicalHelper ⊔Princess ⊑Character\nA2\nHero ⊓Villain ⊑FalseHero\nA3\nPositiveCharacter ⊔NegativeCharacter ⊑Character\nA4\nVillain ⊔FalseHero ⊔Prisoner ⊑NegativeCharacter\nA5\nHero ⊔MagicalHelper ⊔Agent ⊔Donor ⊔Prisoner ⊔Dispatcher ⊑\nPositiveCharacter\nFig. 1. Formalising the Propp’s model of folktales.\nA21 Bear ⊔Bird ⊔Dog ⊔Duck ⊔Frog ⊔Horse ⊔Lion ⊑SingleAnimal\nA22 Enchantress ≡Witch\nA23 Enchantress ⊑Woman ⊓SingleSocialStatus\nA24 Giant ⊑Supernatural\nA25 Goldsmith ⊔Helmsman ⊑SingleSocialStatus\nA26 King ⊑SingleSocialStatus\nA27 Oven ⊑Object\nA28 Prince ≡Son ⊓∃hasParent.King ⊔∃hasParent.Queen\nA29 Prince ⊑SingleSocialStatus\nA30 Princess ≡Daughter ⊓∃hasParent.King ⊔∃hasParent.Queen\nFig. 2. Common entities in the folktale domain.\n(axiom 1). In axiom 2, a false hero is a hero who is also\na villain. Axiom 3 divides the characters into negative and\npositive ones. Note that positive and negative characters are\nnot disjoint, as for instance the concept Prisoner belongs to\nboth sets.\nb) Folktale main entities: Secondly, the common entities\nappearing in folktales were formalized in Fig. 2. The axioms\ndepict the animals (axiom 21), witches or enchantresses which\nare women with a single social status (axioms 22 and 23),\nand supernatural characters like Giant in axiom 24. Speciﬁc\ncharacters like Goldsmith or King, and various objects (i.e.\noven) are also modeled. A prince is deﬁned in axiom 28 as a\nson that have a parent either a king or a queen. Similarly, the\nprincess is a daughter with at least on parent of type king or\nqueen (axiom 30).\nc) Family relationships in folktale: Fig. 4 lists part of the\nfamily relationships adapted to reason in the folktale domain.\nA signiﬁcant part of these relationships are correlated with the\nrecurrent theme of the main character who is ﬁnding his bride\nor ﬁancee.\nTo facilitate reasoning on the ontology, we allow several\nextensions of the ALC version of description logics [3]. Using\nrole inheritance we can specify that the role hasFather is more\nspeciﬁc than the role hasParent. Hence, if we ﬁnd in the folk-\ntale that a character has a father, the system deduces based on\nrole inheritance that the character has also a parent. Similarly,\ninverse roles like hasChild and hasParent are used to infer\nnew knowledge based on the partial knowledge extracted by\nnatural language processing. If we identify that two individuals\nare related by the role hasChild, the system deduces that those\nindividuals are also related by the role hasParent. The domain\nrestriction speciﬁes that only persons can have brothers. The\nrange restriction constraints the range of the role hasGender\nto the concept Gender.\nFig. 3. Folktale ontology.\nA50 Boy ⊑SinglePerson\nA51 Boys ⊑MultiplePerson\nA52 Bride ≡Fiancee\nA53 Bride ⊑UnmarriedCoupleMember\nA54 Brother ⊑Sibling ⊓Male\nA55 Daughter ≡Girl ⊓⊓Child ∃hasParent.Parent\nA56 Father ≡Man ⊓∃hasChild.Child\nA57 Fiance ≡Groom\nA58 Fiance ⊑UnmarriedCoupleMember\nA59 Fiancee ≡Bride\nA60 Fiancee ⊑UnmarriedCoupleMember\nA61 Girl ≡Maiden\nA62 Girl ⊑SinglePerson\nA63 Husband ⊑Consort\nFig. 4. Family relationships in the folktale domain.\nTABLE II\nEXPLOITING ROLE CONSTRAINTS TO REASON ON THE ONTOLOGY.\nExtensios of ALC\nFolktale examples\nRole inheritance\nhasBrother ⊑hasSibling, hasFather ⊑hasParent,\nhasHusband ⊑hasConsort\nInverse roles\nhasHusband ≡hasWife−, hasChild ≡hasParent−\nTransitive roles\nhasSiblingt\nDomain restriction\n∃hasBrother.⊤⊑Person\nRange restriction\n⊤⊑∀hasBrother.Person, ⊤⊑∀hasGender.Gender\nsymmetric roles\nhasConsort ≡hasConsort−\ncardinality\nconstraints\n⊤⊑≤1 hasGender.Thing\nFig. 5. The System Architecture\nIII. SYSTEM ARCHITECTURE\nExtracting knowledge about characters is obtained by inter-\nleaving natural language processing (NLP) and reasoning on\nontologies. The NLP component is based on GATE text engi-\nneering tool [5], while reasoning in DL on the OWLAPI [10],\nas depicted by the architecture in Fig. 5.\nFirstly, the folktale ontology is processed using OWLAPI to\ngenerate classes of characters from the ontology into GATE.\nThe folktale corpus is analysed aiming to populate the ontol-\nogy and to annotate each folktale with the identiﬁed named\nentities. In parallel to the annotation process, the Stanford\nparser creates the coreference information ﬁles. The task is\nchallenging, as even a human might have a problem in decoref-\nerencing some of the sentences, as example 1 illustrates.\nExample 1. ”The Smiths went to visit the Robertsons. After\nthat, they stayed home, watching tv.”, where ”they” might be\ntied to the Smiths, or the Robertsons, or to both of the families.\nFor de-coreferencing, the following pipeline was designed\n(left part of Fig. 5). The tokenizer groups all the letters into\nwords. Next, the sentence splitter (Ssplit) groups the sequence\nof tokens obtained in the previous step into sentences. The\npart of speech (POS) annotation labels all the tokens from\na sentence with their POS tags. Lemma annotation generates\nthe word lemmas for all the tokens in the corpus. The next\nstep is to apply named entity recognition (NER) so that the\nnumerical and temporal entities are recognized. This is done\nusing a conditional random ﬁelds (CRF) sequence taggers\ntrained on various corpora. The parse function provides a full\nsyntactic analysis for each sentence in the corpora. Finally,\nthe coreference chain annotation (Dcoref) obtains both the\npronominal and nominal coreference resolution. After coref-\nerence resolution, the stories are updated with the coreference\ninformation.\nThe Reverb information extraction tool [7] is used to\ngenerate triplets containing the following structure: ⟨nominal\nphrase, verb phrase, nominal phrase⟩. For the sentence ”Good\nheavens, said the girl, no strawberries grow in winter”, the\noutput of Reverb is exempliﬁed in Table III. In order to obtain\nthe triplets, each sentence has to be POS-tagged and NP-\nchunked.\nIV. INTERLEAVING NATURAL LANGUAGE PROCESSING\nWITH REASONING ON ONTOLOGIES\nThis section details three algorithms used to identify knowl-\nedge about characters. Algorithm 1 identiﬁes characters in the\nfolktale. Algorithm 3 is used for anaphora resolution of the\nnamed entities recognized as characters. Algorithm 2 extracts\nknowledge about characters from the de-coreferences. The\nexecution ﬂow of this pipeline, is presented in Fig. 6.\nNatural language processing is enacted to populate the\nfolktale ontology. The extraction Algorithm 1 is performed\nrepetitively on a document, each time using the newly pop-\nulated ontology ﬁle. In this way, the algorithm interleaves\nreasoning on ontology with natural language processing based\non Japes rules [18]. The ﬁrst step is to apply the Jape rules\nJN on the folktale corpus aiming to identify all the deﬁnite\nand indeﬁnite nominal phrases. Given that the characters are\nnominal phrases, this ﬁrst step returns all the information\nneeded, plus some extra phrases that have to be ﬁltered out.\nNext, the Jape rules JC are enacted to select candidate char-\nacters from the set of nominal phrases previously identiﬁed.\nFor each character found, a set of rules JR is used to match\nthe character against a concept in the ontology.\nTABLE III\nEXTRACTING TRIPLETS FROM FOLKTALES USING REVERB.\nOriginal Sentence\nNominal\nPhrase\n(arg1)\nVerb\nPhrase\n(arg2)\nNominal\nPhrase\n(arg3)\nExtraction\nConﬁ-\ndence\nPOS tags\nChunk tags\n10\n3\n4\n5\n9\n11\n12\nGood heavens, said the girl, no\nstrawberries grow in winter.\nno\nstraw-\nberries\ngrow in\nwinter\n0.505\nJJ NNS , VBD DT NN , DT\nNNS VB IN NN .\nB-NP I-NP O B-VP B-NP I-NP\nO B-NP I-NP\nThe king’s daughter began to cry\n, for daughter was afraid of the\ncold frog which daughter did not\nlike to touch, and which was\nnow to sleep in daughter pretty,\nclean little bed.\ndaughter\nwas\nafraid of\nthe cold\nfrog\n0.691\nDT NN POS NN VBD TO VB\n, IN NN VBD JJ IN DT JJ NN\nWDT NN VBD RB IN TO VB ,\nCC WDT VBD RB TO VB RP\nNN RB , JJ JJ NN .\nB-NP I-NP I-NP I-NP B-VP I-\nVP I-VP O B-PP B-NP B-VP B-\nADJP B-PP B-NP I-NP I-NP B-\nNP I-NP B-VP O O B-VP I-VP\nO O B-NP B-VP B-ADVP B-VP\nI-VP B-NP I-NP B-ADVP O B-\nNP I-NP I-NP O\nWhen everything was stowed on\nboard a ship, faithful John put\non the dress of a merchant, and\nthe king was forced to do the\nsame in order to make king quite\nunrecognizable.\nJohn\nput on\nthe\ndress of\na\nmer-\nchant\n0.876\nWRB NN VBD VBN IN NN\nDT NN , NN NNP VBD IN DT\nNN IN DT NN , CC DT NN\nVBD VBN TO VB DT JJ IN\nNN TO VB NN RB JJ .\nB-ADVP B-NP B-VP I-VP B-\nPP B-NP B-NP I-NP O B-NP B-\nNP B-VP B-PP B-NP I-NP I-NP\nI-NP I-NP O O B-NP I-NP B-\nVP I-VP I-VP I-VP B-NP I-NP\nB-SBAR O B-VP I-VP B-NP B-\nADJP I-ADJP O\nSons each kept watch in turn,\nand sat on the highest oak and\nlooked towards the tower.\neach\nkept\nwatch in\nturn\n0.880\nNNPS DT VBD NN IN NN ,\nCC VBD IN DT JJS NN CC\nVBD IN DT NN .\nO B-NP B-VP B-NP B-PP B-\nNP O O B-VP B-PP B-NP I-NP\nI-NP O B-VP B-PP B-NP I-NP\nO\nRapunzel grew into the most\nbeautiful child under the sun.\nRapunzel\ngrew\ninto\nthe most\nbeautiful\nchild\n0.830\nNNP VBD IN DT RBS JJ NN\nIN DT NN .\nB-NP B-VP B-PP B-NP I-NP I-\nNP I-NP B-PP B-NP I-NP O\nThe king’s son ascended, but\ninstead of ﬁnding son dearest\nrapunzel,\nson\nfound\nthe\nen-\nchantress, who gazed at son with\nwicked and venomous looks.\nthe\nen-\nchantress\ngazed at\nson\n0.586\nDT NN POS NN VBD , CC RB\nIN VBG NN NN NN , NN VBD\nDT NN , WP VBD IN NN IN\nJJ CC JJ NNS .\nB-NP I-NP I-NP I-NP B-VP O\nO B-PP I-PP B-VP B-NP I-NP\nI-NP O B-NP B-VP B-NP I-NP\nO B-NP B-VP B-PP B-NP B-PP\nB-NP I-NP I-NP I-NP O\nInput : Of - Folktale ontology;\nS - Corpus of folktales;\nJN - Jape rules to identify deﬁnite and indeﬁnite\nnominal phrases;\nJC - Jape rules to identify candidate characters;\nJR - Jape rules to identify character’s relation to\nthe ontology;\nResult: C: Set of annotated characters;\nC ←∅;\nNP ←applyRules(JN, S);\nwhile applyRules(JC, S, NP) ̸= null do\nNC ←applyRules(JC, S, NP);\nRel ←applyRules(JR, S, NC);\nforeach r ∈Rel do\nforeach concept from r do\nif checkCast(NC, concept) then\ncast(NC, concept);\nend\nend\nend\nwhile is referred(S, NC) do\nRef = getReference();\nlink(NC, Ref);\nend\nC ←C ∪NC;\nend\nAlgorithm 1: Character extraction algorithm.\nAfter identifying a concept for which the character is an\ninstance, the algorithm exploits reasoning on ontology to\nidentify all atomic concepts to which the character belongs.\nFor instance, a character identiﬁed as Daughter will be\nan instance of Girl, Child, Maiden, SinglePerson (recall\nFig. 4). For each concept to which the character belongs, the\nalgorithm looks again in the corpus to see if there are other\nmentions of the newly introduced character. If this is the case,\nthe character is related with the new knowledge.\nInput : S: Corpus of folktales; P: Pipeline conﬁguration\nfor decoreferencing;\nFN: List with ﬁlenames for each S;\nSC: Stanford-CoreNLP command;\nResult: D: Decoreferenced texts of ﬁles from FN;\nFiles = run(SC, P, FN);\nforeach file in Files do\nD ←S;\nforeach coref group ∈file do\nrep ←ﬁndRepresentative(coref group);\nforeach coref word ∈coref group do\nreplace(D, coref word, rep );\nend\nend\nend\nAlgorithm 2: Decoreference algorithm.\nFig. 6. Main execution phases.\nThe decoreferencing algorithm (Alg. 2) uses as input the\nprocessing pipeline and the folktale corpus. The basic pro-\ncessing steps needed are the following: tokenize, ssplit, pos,\nlemma, ner, parse, dcoref. The decoreferencing algorithm is\nrun on all stories at once, but it generates different output ﬁle\nfor each story represented by the ﬁlename. In the ﬁrst step, the\nStanford parser applies the execution pipeline on the corpora\nof folktales. For each resulted ﬁle, the algorithm searches for\ncoreference groups. In order to be able to return the modiﬁed\ntext, the original text has to be stored in the returning argument\nof the algorithm. For each coreference group found, ﬁrstly\nthe referenced word has to be processed and kept into a\nvariable and then, each coreferenced word found, belonging\nto the group, has to be replaced in the original text with the\nreferenced variable. In the end, the decoreferenced text for\neach corpus ﬁle is obtained.\nAlgorithm 3 takes as input the result of algorithms 1 and\n(alg 2. The set of characters is used as the input, while the\ndecoreferenced texts are used as an environment from which\nthe algorithm extracts the perspective. For each character in the\nset of characters resulted from the extraction algorithm (alg 1),\neach line that resulted from reverb execution is processed.\nFrom each line, the sentence is extracted based on the output\nInput : R: Reverb command;\nV : The version indicator. True if long version, false\notherwise;\nC: Set of characters resulted from algorithm 1;\nD: Decoreferenced text resulted from algorithm 2;\nResult: P: String containing character’s perspective in S;\nRR = run(R, D);\nif V = true then\nforeach c ∈C do\nforeach line ∈RR do\nsentence ←getSentence(line);\nif c ∈sentence then\nP ←P ∪sentence;\nend\nend\nend\nelse\nforeach c ∈C do\nforeach line ∈RR do\ntriplet ←getTriplet(line);\nif c ∈triplet then\nP ←P ∪triplet;\nend\nend\nend\nend\nAlgorithm 3: Finding character’s perspective.\nformat of the Reverb service presented in Table III. If the\ncharacter, from the character set, is mentioned in the sentence,\nthen the sentence is appended to the output variable. These\ncolumns are combined in a triplet, and it is checked to see\nwhether the current character appears is present in this triplet.\nIn this case, the triplet is appended to the output variable. This\nalgorithms score is represented by a subunitary number that\nrepresents the conﬁdence that the extraction was correct.\nV. EXPERIMENTAL RESULTS\nA. Running scenario\nThe system was tested against seven stories (Table V). This\nsection illustrates the results of this pipeline for the secondary\ncharacter Henry from the story “The frog king”. The fragment\non which the algorithms were applied is listed in Example 2.\nExample 2. ”Then they went to sleep, and next morning when\nthe sun awoke them, a carriage came driving up with eight\nwhite horses, which had white ostrich feathers on their heads,\nand were harnessed with golden chains, and behind stood the\nyoung king’s servant Faithful Henry. Faithful Henry had been\nso unhappy when his master was changed into a frog, that\nhe had caused three iron bands to be laid round his heart,\nlest it should burst with grief and sadness. The carriage was\nto conduct the young king into his kingdom. Faithful Henry\nhelped them both in, and placed himself behind again, and\nwas full of joy because of this deliverance. And when they\nhad driven a part of the way the king’s son heard a cracking\nbehind him as if something had broken. So he turned round\nTABLE IV\nELICITING KNOWLEDGE ABOUT HENRY.\nCharacter: Henry\n1\nHenry master was changed into a frog\n2\nHenry had caused three iron bands\n3\nfaithful Henry helped bands\n4\nbands placed Henry\n5\nHenry was full of joy\n6\nthe bands were springing from the heart of faithful Henry\nand cried, ”Henry, the carriage is breaking.” ”No, master, it\nis not the carriage. It is a band from my heart, which was put\nthere in my great pain when you were a frog and imprisoned\nin the well.” Again and once again while they were on their\nway something cracked, and each time the king’s son thought\nthe carriage was breaking, but it was only the bands which\nwere springing from the heart of Faithful Henry because his\nmaster was set free and was happy.”\nThe method has two kind of results - one for the long\nversion, and one for the short version. Firstly, the results for\nthe short version are listed in Table IV. Note that the output\ntext is the decoreferenced one - this is the reason why the\ncharacter might talk about itself in third person. Because of the\nde-coreferenced version of the stories part of text might not be\ncorrect from the human reader perspective. But it is the easiest\nway to understand the context of a character. Otherwise, it\nwould be hard to see that when the text says ”his master”,\nthat ”his” refers to Henry, as Example 3 bears out.\nExample 3. 1. Then companion went to sleep, and next\nmorning when the sun awoke companion, a band came driving\nup with eight white horses, which had white ostrich feathers\non companion heads, and were harnessed with golden chains,\nand behind stood the young king’s servant faithful Henry.\n2. Faithful Henry had been so unhappy when henry master\nwas changed into a frog, that Henry had caused three iron\nbands to be laid round henry heart, lest heart should burst\nwith grief and sadness.\n3. Faithful Henry helped bands both in, and placed Henry\nbehind again, and was full of joy because of this deliverance.\n4. Again and once again while you were on you way\nsomething cracked, and each time the king’s son thought the\nband was breaking , but it was only the bands which were\nspringing from the heart of faithful Henry because Henry\nmaster was set free and was happy.”\nThere are some cases in which there will be no result for a\ncharacter (Example 4). Given that the character was extracted\nfrom the original ﬁle, by using Algorithm 1, there is a certainty\nthat the character exists in the story.\nExample 4. When trying to search for the perspective of\ncharacter ”waiting-maid” in the story ”Faithful John”, the\napplication will not be able to ﬁnd any solution. In the un-\nmodiﬁed text, the son character is introduced in the following\nway: ”She took him by the hand and led him upstairs, for she\nwas the waiting-maid.”\nTABLE V\nACCURACY OF THE ALGORITHMS.\nStory\nAccuracy\nThe Magic Swan-Geese\n75%\nThe Frog King\n62%\nThe King’s Son who Feared Nothing\n76%\nFaithful John\n63%\nThe Twelve Brothers\n65%\nRapunzel\n74%\nThe Three Little Men in the Woods\n73%\nAverage\n70%\nThis happens because, when the anaphoric decoreference is\nrun (Algorithm 2), the ﬁle is changed in the following way:\n”Girl took oh by the hand and led oh upstairs , for girl was the\ngirl .”. The change happened because the decoreferencing tool\ninterpreted ”the waiting-maid” as being tied up to the word\n”she”, and, which is tied to ”the girl” from the following\nphrase ”Then said the girl ‘ the princess must see these ,\ngirl has such great pleasure in golden things , that girl will\nbuy all you have . ’”. In this way, this character’s part will\nbe attributed to the ”girl”, which is the main character of\nthe story. This situation in which the story is talking about a\ngeneral character, but only after the main events, the character\nis ﬁnally revealed, is called cataphora [11].\nB. Accuracy of the method\nThe accuracy of our method is inﬂuenced by: 1) accuracy\nof character identiﬁcation; 2) accuracy of identifying co-\nreferences; 3) accuracy of Reverb when extracting triplets (the\nconﬁdence indicator). Each of this services has an accuracy\nerror that will be propagated from one component to another.\nWe performed various tests on the corpus used for character\nidentiﬁcation, and we obtained an average accuracy of 70%\n(Table V). When calculating the accuracy, 20 characters were\ntaken into consideration, meaning that for each story, about\n3 characters were chosen. These characters were manually\nselected from the set of characters output by the character\nextraction system presented in [17], [19]. The characters were\nselected by choosing 2 main characters and a secondary\ncharacter for each story.\nThe testing was performed on seven different stories, and\nfor each story, a set of main characters was chosen. The\nobtained overall accuracy is 74%, having an overall precision\nof 90% and a recall of 60%. The results are presented in\nFig. 7. Figure 8 depicts the distribution of precision, recall and\naccuracy over the stories. The values were calculated using the\nfollowing formulas:\nprecision =\ntp\ntp+fp\nrecall =\ntp\ntp+fn\naccuracy =\ntp+tn\ntp+fp+tn+fn\nwhere tp means true positive, and represents the number\nof sentences that are found both in the manually annotated\nset and the test set, tn means true negative and represents the\nnumber of sentences that are neither in the manually annotated\nFig. 7. Precision, recall, and accuracy for the seven folktales analyzed.\nFig. 8. Comparing precision, recall and accuracy for each story.\nset, nor in the test set, fp means false positive and represents\nthe number of sentences that are in the test set and not in\nthe manually annotated set, and fn means false negative and\nrepresents the number of sentences that are in the manually\nannotated set, but not in the test set. In the folktale context,\nthe tp represents the number of sentences that belong to the\ncharacter’s perspective, all those sentences that involve the\ncharacter in any way.\nThe average F-score for the Stanford-CoreNLP of 59.5\ninﬂuences greatly the performance of the algorithm, as the\ncharacters perspective cannot be extracted, given that the\ncharacter is not seen as being part of the sentence. The\naccuracy can be improved if a better decoreferencing tool\nwill be used. Other coreference tools are For the anaphoric\ndecoreference, there are several other tools (BART, JAVARAP,\nGuiTar and ARKref), but, from all, the Stanford-CoreNLP has\nbe highest accuracy percentage.\nThere is ongoing research in the coreference resolution\ndomain, When calculating the performance scores, the ex-\ntraction of the correct sentence was considered, and not on\nthe correctness of the extracted sentence. Even though the\nright sentence was extracted, the information in the sentence\nwill be according to the coreference resolution result. Hence,\nan error might be observed when reviewing the structure of\nthe sentences. The algorithms performance is also inﬂuenced\nby the scores obtained by the Reverb tool. Also, the named\nentity recognition has an average precision of 79% and a\nrecall of 72%. These scores do not inﬂuence directly the\nalgorithms performance, but they have an effect on the number\nof characters for which the algorithm will try to ﬁnd the roles\nthey have on the development of the story. Together, all these\nscores combined, give the performance scores of the characters\nperspective in texts.\nThe current version does not extract information about the\ncharacters’ roles. The information extracted consists of the\ncharacter identiﬁcation, that is presented in\n[17], [19], and\nthe story involving the character. The story can be presented\nin a standardized version.\nVI. DISCUSSION\nWe can enact our solution in other domains instead of folk-\ntales. We exemplify he following three domains: a) software\nrequirements, b) marketing and c) medical domain.\nConsider the domain of software requirements, where these\nrequirements are written in natural language. Our system will\nsupport the identiﬁcation of various actors appearing in the\nrequirements document. First, one needs to replace the folktale\nontology with a requirement ontology that provides knowledge\non use cases, actors, their roles, etc. The same pipeline will\nbe used to: 1) identify main actors (admin, various users, etc)\nand 2) extract knowledge about various actions these actors\nare supposed to perform.\nAnother domain that could beneﬁt from the same pipeline of\nexecution, would be the marketing domain. Consider a dataset\nof product reviews or accommodation places in the tourism\ndomain [20]. The system would extract only the sentences\nthat reference the mentioned item. By having access to all\nthe sentences of interest, further analysis is facilitated without\nhaving to process the entire text.\nSimilar extraction systems have been proposed for the med-\nical domain to extract information from clinical narratives. In\nthis line, the MedEx system [21] aims to extract the medication\ninformation from clinical narratives. Similarly, there is also the\nOpenClinical system for assisting health care providers.\nIn our approach, the extraction algorithm part is separated\nfrom the perspective searching part. Therefore, any ontology\nand any document can be used in order to ﬁnd the character’s\nor object’s perspective in the document.\nWe tested our method only on seven stories. With a com-\nplexity of O(n3) in sentence length of syntactic parsing, our\nsyntactic based on Stanford parser might be too slow for large\ncorpus as the one of 15099 narratives analysed in [4].\nVII. CONCLUSIONS\nOur method is able to extract knowledge on various char-\nacters. Our current accuracy for information extraction in\nthe folktale domain is 74%. The experimental results were\nobtained for seven stories in the folktale domain. The precision\nscore is above 90%, With an overall recall of only 60%,\nthere are high chances that not all the information regarding\na product was extracted.\nThe developed algorithms aggregate three different services:\nFirstly, the named entity recognition was implemented by\nusing an ontology based on Propps formal model. Based of\nthis ontology, and some implemented Jape rules, the characters\nare extracted from a given story. Secondly, a coreference reso-\nlution tool was implemented by enacting anaphoric resolution\nto eliminate co-referenced words and to replace them with\ntheir representative, Thirdly, ﬁnding relationships between\ncharacters was integrated in order to link two noun phrases\nwith a verbal phrase.\nACKNOWLEDGMENTS\nWe thank the reviewers for their valuable comments. Part\nof this work was supported by the Department of Computer\nScience of Technical University of Cluj-Napoca, Romania.\nREFERENCES\n[1] A. Agarwal, S. Balasubramanian, J. Zheng, and S. Dash, “Parsing\nscreenplays for extracting social networks from movies,” EACL 2014,\npp. 50–58, 2014.\n[2] A. Agarwal, A. Corvalan, J. Jensen, and O. Rambow, “Social network\nanalysis of Alice in Wonderland,” in Workshop on Computational\nLinguistics for Literature, 2012, pp. 88–96.\n[3] F. Baader, The description logic handbook: theory, implementation, and\napplications.\nCambridge university press, 2003.\n[4] D. Bamman, T. Underwood, and N. A. Smith, “A bayesian mixed effects\nmodel of literary character,” in Proceedings of the 52st Annual Meeting\nof the Association for Computational Linguistics (ACL14), 2014.\n[5] K. Bontcheva, V. Tablan, D. Maynard, and H. Cunningham, “Evolv-\ning GATE to meet new challenges in language engineering,” Natural\nLanguage Engineering, vol. 10, no. 3-4, pp. 349–373, 2004.\n[6] D. K. Elson, N. Dames, and K. R. McKeown, “Extracting social\nnetworks from literary ﬁction,” in Proceedings of the 48th annual\nmeeting of the association for computational linguistics.\nAssociation\nfor Computational Linguistics, 2010, pp. 138–147.\n[7] A. Fader, S. Soderland, and O. Etzioni, “Identifying relations for\nopen information extraction,” in Proceedings of the Conference on\nEmpirical Methods in Natural Language Processing.\nAssociation for\nComputational Linguistics, 2011, pp. 1535–1545.\n[8] B. Fisseni, A. Kurji, and B. L¨owe, “Annotating with Propp’s morphology\nof the folktale: reproducibility and trainability,” Literary and Linguistic\nComputing, vol. 29, no. 4, pp. 488–510, 2014.\n[9] H. He, D. Barbosa, and G. Kondrak, “Identiﬁcation of speakers in\nnovels.” in ACL (1), 2013, pp. 1312–1320.\n[10] M. Horridge and S. Bechhofer, “The OWL API: A Java API for OWL\nontologies.” Semantic Web, vol. 2, no. 1, pp. 11–21, 2011.\n[11] N. Kazanina and C. Phillips, “Differential effects of constraints in the\nprocessing of Russian cataphora,” The Quarterly Journal of Experimen-\ntal Psychology, vol. 63, no. 2, pp. 371–400, 2010.\n[12] R. Lang, “A declarative model for simple narratives,” in Proceedings of\nthe AAAI fall symposium on narrative intelligence, 1999, pp. 134–141.\n[13] G.-M. Park, S.-H. Kim, and H.-G. Cho, “Structural analysis on social\nnetwork constructed from characters in literature texts,” Journal of\nComputers, vol. 8, no. 9, pp. 2442–2447, 2013.\n[14] F. Peinado, P. Gerv´as, and B. D´ıaz-Agudo, “A description logic ontology\nfor fairy tale generation,” in Procs. of the Workshop on Language\nResources for Linguistic Creativity, LREC, vol. 4, 2004, pp. 56–61.\n[15] V. I. Propp, Morphology of the Folktale.\nAmerican Folklore Society,\n1958, vol. 9.\n[16] N. Reiter, A. Frank, and O. Hellwig, “An NLP-based cross-document\napproach to narrative structure discovery,” Literary and Linguistic Com-\nputing, vol. 29, no. 4, pp. 583–605, 2014.\n[17] D. Suciu and A. Groza, “Interleaving ontology-based reasoning and\nnatural language processing for character identiﬁcation in folktales,” in\nIEEE 10th International Conference on Intelligent Computer Communi-\ncation and Processing (ICCP2014), Cluj-Napoca, Romania, 2014, pp.\n67–74.\n[18] D. Thakker, T. Osman, and P. Lakin, “Gate Jape grammar tutorial,”\nNottingham Trent University, UK, Phil Lakin, UK, Version, vol. 1, 2009.\n[19] K. van Dalen-Oskam, J. de Does, M. Marx, I. Sijaranamual, K. Depuydt,\nB. Verheij, and V. Geirnaert, “Named entity recognition and resolution\nfor literary studies.”\n[20] B. Varga and A. Groza, “Integrating DBpedia and SentiWordNet for a\ntourism recommender system,” in Intelligent Computer Communication\nand Processing (ICCP), 2011 IEEE International Conference on. IEEE,\n2011, pp. 133–136.\n[21] H. Xu, S. P. Stenner, S. Doan, K. B. Johnson, L. R. Waitman, and J. C.\nDenny, “Medex: a medication information extraction system for clinical\nnarratives,” Journal of the American Medical Informatics Association,\nvol. 17, no. 1, pp. 19–24, 2010.\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.IR"
  ],
  "published": "2015-11-10",
  "updated": "2015-11-10"
}