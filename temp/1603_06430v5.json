{
  "id": "http://arxiv.org/abs/1603.06430v5",
  "title": "Deep Learning in Bioinformatics",
  "authors": [
    "Seonwoo Min",
    "Byunghan Lee",
    "Sungroh Yoon"
  ],
  "abstract": "In the era of big data, transformation of biomedical big data into valuable\nknowledge has been one of the most important challenges in bioinformatics. Deep\nlearning has advanced rapidly since the early 2000s and now demonstrates\nstate-of-the-art performance in various fields. Accordingly, application of\ndeep learning in bioinformatics to gain insight from data has been emphasized\nin both academia and industry. Here, we review deep learning in bioinformatics,\npresenting examples of current research. To provide a useful and comprehensive\nperspective, we categorize research both by the bioinformatics domain (i.e.,\nomics, biomedical imaging, biomedical signal processing) and deep learning\narchitecture (i.e., deep neural networks, convolutional neural networks,\nrecurrent neural networks, emergent architectures) and present brief\ndescriptions of each study. Additionally, we discuss theoretical and practical\nissues of deep learning in bioinformatics and suggest future research\ndirections. We believe that this review will provide valuable insights and\nserve as a starting point for researchers to apply deep learning approaches in\ntheir bioinformatics studies.",
  "text": "Deep Learning in Bioinformatics \nSeonwoo Min1, Byunghan Lee1, and Sungroh Yoon1,2* \n1Department of Electrical and Computer Engineering, Seoul National University, Seoul 08826, Korea \n2Interdisciplinary Program in Bioinformatics, Seoul National University, Seoul 08826, Korea \n \nAbstract \nIn the era of big data, transformation of biomedical big data into valuable knowledge has been \none of the most important challenges in bioinformatics. Deep learning has advanced rapidly \nsince the early 2000s and now demonstrates state-of-the-art performance in various fields. \nAccordingly, application of deep learning in bioinformatics to gain insight from data has been \nemphasized in both academia and industry. Here, we review deep learning in bioinformatics, \npresenting examples of current research. To provide a useful and comprehensive perspective, \nwe categorize research both by the bioinformatics domain (i.e., omics, biomedical imaging, \nbiomedical signal processing) and deep learning architecture (i.e., deep neural networks, \nconvolutional neural networks, recurrent neural networks, emergent architectures) and present \nbrief descriptions of each study. Additionally, we discuss theoretical and practical issues of \ndeep learning in bioinformatics and suggest future research directions. We believe that this \nreview will provide valuable insights and serve as a starting point for researchers to apply deep \nlearning approaches in their bioinformatics studies. \n \n \n                                           \n*Corresponding author. Mailing address: 301-908, Department of Electrical and Computer Engineering, Seoul \nNational University, Seoul 08826, Korea. E-mail: sryoon@snu.ac.kr. Phone: +82-2-880-1401. \nKeywords  \nDeep learning, neural network, machine learning, bioinformatics, omics, biomedical imaging, \nbiomedical signal processing  \n \nKey Points \n \nAs a great deal of biomedical data have been accumulated, various machine algorithms \nare now being widely applied in bioinformatics to extract knowledge from big data. \n Deep learning, which has evolved from the acquisition of big data, the power of \nparallel and distributed computing, and sophisticated training algorithms, has \nfacilitated major advances in numerous domains such as image recognition, speech \nrecognition, and natural language processing. \n We review deep learning for bioinformatics and present research categorized by \nbioinformatics domain (i.e., omics, biomedical imaging, biomedical signal processing) \nand deep learning architecture (i.e., deep neural networks, convolutional neural \nnetworks, recurrent neural networks, emergent architectures).  \n Furthermore, we discuss the theoretical and practical issues plaguing the applications \nof deep learning in bioinformatics, including imbalanced data, interpretation, \nhyperparameter optimization, multimodal deep learning, and training acceleration. \n \nAs a comprehensive review of existing works, we believe that this paper will provide \nvaluable insight and serve as a launching point for researchers to apply deep learning \napproaches in their bioinformatics studies. \n \n \nAuthor Description \nSeonwoo Min is a M.S./Ph.D. candidate at Department of Electrical and Computer \nEngineering, Seoul National University, Korea. His research areas include high-performance \nbioinformatics, machine learning for biomedical big data, and deep learning. \nByunghan Lee is a Ph.D. candidate at Department of Electrical and Computer Engineering, \nSeoul National University, Korea. His research areas include high-performance bioinformatics, \nmachine learning for biomedical big data, and data mining.  \nSungroh Yoon is an associate professor at Department of Electrical and Computer Engineering, \nSeoul National University, Seoul, Korea. He received his Ph.D. and postdoctoral training from \nStanford University, Stanford, USA. His research interests include machine learning and deep \nlearning for bioinformatics, and high-performance bioinformatics.  \n \n \nIntroduction \nTABLE 1: Abbreviations in alphabetical order \n \n  \nAbbreviation \nFull word \nAE \n \nAuto-Encoder \nAI \n \nArtificial Intelligence \nAUC \n \nArea Under the Receiver Operation Characteristics Curve \nAUC-PR \n \nArea Under the Precision-Recall Curve \nBRNN \n \nBidirectional Recurrent Neural Network \nCAE \n \nConvolutional Auto-Encoder \nCNN \n \nConvolutional Neural Network \nDBN \n \nDeep Belief Network \nDNN \n \nDeep Neural Network \nDST-NN \n \nDeep Spatio-Temporal Neural Network \nECG \n \nElectrocardiography \nECoG \n \nElectrocorticography \nEEG \n \nElectroencephalography \nEMG \n \nElectromyography \nEOG \n \nElectrooculography \nGRU \n \nGated Recurrent Unit \nLSTM \n \nLong Short-Term Memory \nMD-RNN \n \nMulti-dimensional Recurrent Neural Network \nMLP \n \nMultilayer Perceptron \nMRI \n \nMagnetic Resonance Image \nPCA \n \nPrincipal Component Analysis \nPET \n \nPositron Emission Tomography \nPSSM \n \nPosition Specific Scoring Matrix \nRBM \n \nRestricted Boltzmann Machine \nReLU \n \nRectified Linear Unit \nRNN \n \nRecurrent Neural Network \nSAE \n \nStacked Auto-Encoder \nSGD \n \nStochastic Gradient Descent \n \nIn the era of “big data,” transformation of large quantities of data into valuable knowledge has \nbecome increasingly important in various domains [1], and bioinformatics is no exception. \nSignificant amounts of biomedical data, including omics, image, and signal data, have been \naccumulated, and the resulting potential for applications in biological and healthcare research \nhas caught the attention of both industry and academia. For instance, IBM developed Watson \nfor Oncology, a platform analyzing patients’ medical information and assisting clinicians with \ntreatment options [2, 3]. In addition, Google DeepMind, having achieved great success with \nAlphaGo in the game of Go, recently launched DeepMind Health to develop effective \nhealthcare technologies [4, 5]. \nTo extract knowledge from big data in bioinformatics, machine learning has been a widely used \nand successful methodology. Machine learning algorithms use training data to uncover \nunderlying patterns, build models, and make predictions based on the best fit model. Indeed, \nsome well-known algorithms (i.e., support vector machines, random forests, hidden Markov \nmodels, Bayesian networks, Gaussian networks) have been applied in genomics, proteomics, \nsystems biology, and numerous other domains [6]. \n \n[FIGURE 1] \nThe proper performance of conventional machine learning algorithms relies heavily on data \nrepresentations called features [7]. However, features are typically designed by human \nengineers with extensive domain expertise, and identifying which features are more appropriate \nfor the given task remains difficult. Deep learning, a branch of machine learning, has recently \nemerged based on big data, the power of parallel and distributed computing, and sophisticated \nalgorithms. Deep learning has overcome previous limitations, and academic interest has \nincreased rapidly since the early 2000s (Figure 1). Furthermore deep learning is responsible for \nmajor advances in diverse fields where the artificial intelligence (AI) community has struggled \nfor many years [8]. One of the most important advancements thus far has been in image and \nspeech recognition [9-15], although promising results have been disseminated in natural \nlanguage processing [16, 17] and language translation [18, 19]. Certainly, bioinformatics can \nalso benefit from deep learning (Figure 2): splice junctions can be discovered from DNA \nsequences, finger joints can be recognized from X-ray images, lapses can be detected from \nelectroencephalography (EEG) signals, and so on.   \n \n[FIGURE 2] \nPrevious reviews have addressed machine learning in bioinformatics [6, 20] and the \nfundamentals of deep learning [7, 8, 21]. In addition, although recently published reviews by \nLeung et al. [22], Mamoshina et al. [23], and Greenspan et al. [24] discussed deep learning \napplications in bioinformatics research, the former two are limited to applications in genomic \nmedicine, and the latter to medical imaging. In this article, we provide a more comprehensive \nreview of deep learning for bioinformatics and research examples categorized by \nbioinformatics domain (i.e., omics, biomedical imaging, biomedical signal processing) and \ndeep learning architecture (i.e., deep neural networks, convolutional neural networks, recurrent \nneural networks, emergent architectures). The goal of this article is to provide valuable insight \nand to serve as a starting point to facilitate the application of deep learning in bioinformatics \nstudies. To the best of our knowledge, we are one of the first groups to review deep learning \napplications in bioinformatics. \n \nDeep learning: a brief overview \n \n[FIGURE 3] \nEfforts to create AI systems have a long history. Figure 3 illustrates the relationships and high-\nlevel schematics of different disciplines. Early approaches attempted to explicitly program the \nrequired knowledge for given tasks; however, these faced difficulties in dealing with complex \nreal-world problems because designing all the detail required for an AI system to accomplish \nsatisfactory results by hand is such a demanding job [7]. Machine learning provided more \nviable solutions with the capability to improve through experience and data. Although machine \nlearning can extract patterns from data, there are limitations in raw data processing, which is \nhighly dependent on hand-designed features. To advance from hand-designed to data-driven \nfeatures, representation learning, particularly deep learning has shown great promise. \nRepresentation learning can discover effective features as well as their mappings from data for \ngiven tasks. Furthermore, deep learning can learn complex features by combining simpler \nfeatures learned from data. In other words, with artificial neural networks of multiple nonlinear \nlayers, referred to as deep learning architectures, hierarchical representations of data can be \ndiscovered with increasing levels of abstraction [25].  \nKey elements of deep learning \nThe successes of deep learning are built on a foundation of significant algorithmic details and \ngenerally can be understood in two parts: construction and training of deep learning \narchitectures. Deep learning architectures are basically artificial neural networks of multiple \nnonlinear layers and several types have been proposed according to input data characteristics \nand research objectives. Here, we categorized deep learning architectures into four groups (i.e., \ndeep neural networks (DNNs) [26-30], convolutional neural networks (CNNs) [31-33], \nrecurrent neural networks (RNNs) [34-37], emergent architectures [38-41]) and explained each \ngroup in detail (Table 2). Some papers have used “DNNs” to encompass all deep learning \narchitectures [7, 8]; however, in this review, we use “DNNs” to refer specifically to multilayer \nperceptron (MLP) [26], stacked auto-encoder (SAE) [27, 28], and deep belief networks (DBNs) \n[29, 30], which use perceptrons [42], auto-encoders (AEs) [43], and restricted Boltzmann \nmachines (RBMs) [44, 45] as the building blocks of neural networks, respectively. CNNs are \narchitectures that have succeeded particularly in image recognition and consist of convolution \nlayers, nonlinear layers, and pooling layers. RNNs are designed to utilize sequential \ninformation of input data with cyclic connections among building blocks like perceptrons, long \nshort-term memory units (LSTMs) [36, 37], or gated recurrent units (GRUs) [19]. In addition, \nmany other emergent deep learning architectures have been suggested, such as deep spatio-\ntemporal neural networks (DST-NNs) [38], multi-dimensional recurrent neural networks (MD-\nRNNs) [39], and convolutional auto-encoders (CAEs) [40, 41].  \nTABLE 2: Categorization of deep learning applied research in bioinformatics \n  \n \nOmics \n  \n \nBiomedical imaging \n  \n \nBiomedical signal processing \n  \n \nResearch topics \nReference \n \nResearch topics \nReference \n \nResearch topics \nReference \nDeep  \nneural networks \n \nProtein structure \n[84-87] \n \nAnomaly classification \n[122-124] \n \nBrain decoding \n[158-163] \n \nGene expression regulation \n[93-98] \n \nSegmentation \n[133] \n \nAnomaly classification \n[171-175] \n \nProtein classification \n[108] \n \nRecognition \n[142, 143] \n \n \n \n \nAnomaly classification \n[111] \n \nBrain decoding \n[149, 150] \n \n \n \nConvolutional  \nneural networks \n \nGene expression regulation \n[99-104] \n \nAnomaly classification \n[125-132] \n \nBrain decoding \n[164-167] \n \n \n \n \nSegmentation \n[134-140] \n \nAnomaly classification \n[176] \n \n \n \n \nRecognition \n[144-147] \n \n \n \n \n  \n  \n \n  \n  \n \n  \n  \nRecurrent  \nneural networks \n \nProtein structure \n[88-90] \n \n  \n  \n \nBrain decoding \n[168] \n \nGene expression regulation \n[105-107] \n \n \n \n \nAnomaly classification \n[177, 178] \n \nProtein classification \n[109, 110] \n \n \n \n \n \n \n \n  \n  \n \n  \n  \n \n  \n  \nEmergent \narchitectures \n \nProtein structure \n[91, 92] \n \nSegmentation \n[141] \n \nBrain decoding \n[169, 170] \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n  \n  \n \n  \n  \nThe goal of training deep learning architectures is optimization of the weight parameters in \neach layer, which gradually combines simpler features into complex features so that the most \nsuitable hierarchical representations can be learned from data. A single cycle of the \noptimization process is organized as follows [8]. First, given a training dataset, the forward \npass sequentially computes the output in each layer and propagates the function signals forward \nthrough the network. In the final output layer, an objective loss function measures error \nbetween the inferenced outputs and the given labels. To minimize the training error, the \nbackward pass uses the chain rule to backpropagate error signals and compute gradients with \nrespect to all weights throughout the neural network [46]. Finally, the weight parameters are \nupdated using optimization algorithms based on stochastic gradient descent (SGD) [47]. \nWhereas batch gradient descent performs parameter updates for each complete dataset, SGD \nprovides stochastic approximations by performing the updates for each small set of data \nexamples. Several optimization algorithms stem from SGD. For example, Adagrad [48] and \nAdam [49] perform SGD while adaptively modifying learning rates based on update frequency \nand moments of the gradients for each parameter, respectively. \nAnother core element in the training of deep learning architectures is regularization, which \nrefers to strategies intended to avoid overfitting and thus achieve good generalization \nperformance. For example, weight decay [50], a well-known conventional approach, adds a \npenalty term to the objective loss function so that weight parameters converge to smaller \nabsolute values. Currently, the most widely used regularization approach is dropout [51]. \nDropout randomly removes hidden units from neural networks during training and can be \nconsidered an ensemble of possible subnetworks [52]. To enhance the capabilities of dropout, \na new activation function, maxout [53], and a variant of dropout for RNNs called rnnDrop [54], \nhave been proposed. Furthermore, recently proposed batch normalization [55] provides a new \nregularization method through normalization of scalar features for each activation within a \nmini-batch and learning each mean and variance as parameters.  \nDeep learning libraries \nTo actually implement deep learning algorithms, a great deal of attention to algorithmic \ndetails is required. Fortunately, many open source deep learning libraries are available online \n(Table 3). There are still no clear front-runners, and each library has its own strengths [56]. \nAccording to benchmark test results of CNNs, specifically AlexNet [33] implementation in \nBaharampour et al. [57], Python-based Neon [58] shows a great advantage in the processing \nspeed. C++ based Caffe [59] and Lua-based Torch [60] offer great advantages in terms of \npre-trained models and functional extensionality, respectively. Python-based Theano [61, 62] \nprovides a low-level library to define and optimize mathematical expressions; moreover, \nnumerous higher-level wrappers such as Keras [63], Lasagne [64], and Blocks [65] have been \ndeveloped on top of Theano to provide more intuitive interfaces. Google recently released \nthe C++-based TensorFlow [66] with a Python interface. This library currently shows limited \nperformance but is undergoing continuous improvement, as heterogeneous distributed \ncomputing is now supported. In addition, TensorFlow can also take advantage of Keras, \nwhich provides an additional model-level interface.  \nTABLE 3: Comparison of deep learning libraries \n  \n \nCore \n \nSpeed for batch* (ms) \n \nMulti-GPU \n \nDistributed \n \nStrengths [56, 57] \nCaffe \n \nC++ \n \n651.6  \n \nO \n \nX \n \nPre-trained models supported \nNeon \n \nPytho\nn \n \n386.8  \n \nO \n \nX \n \nSpeed \nTensorFlow \n \nC++ \n \n962.0  \n \nO \n \nO \n \nHeterogeneous distributed computing \nTheano \n \nPytho\nn \n \n733.5  \n \nX \n \nX \n \nEase of use with higher-level wrappers \nTorch \n \nLua \n \n506.6  \n \nO \n \nX \n \nFunctional extensionality \nNotes. Speed for batch* is based on the averaged processing times for AlexNet [33] with batch size of 256 on a single GPU [57];  \nCaffe, Neon, Theano, Torch was utilized with cuDNN v.3 while TensorFlow was utilized with cuDNN v.2 \n \nDeep neural networks \nThe basic structure of DNNs consists of an input layer, multiple hidden layers, and an output \nlayer (Figure 4). Once input data are given to the DNNs, output values are computed \nsequentially along the layers of the network. At each layer, the input vector comprising the \noutput values of each unit in the layer below is multiplied by the weight vector for each unit in \nthe current layer to produce the weighted sum. Then, a nonlinear function, such as a sigmoid, \nhyperbolic tangent, or rectified linear unit (ReLU) [67], is applied to the weighted sum to \ncompute the output values of the layer. The computation in each layer transforms the \nrepresentations in the layer below into slightly more abstract representations [8]. Based on the \ntypes of layers used in DNNs and the corresponding learning method, DNNs can be classified \nas MLP, SAE, or DBN. \n \n \n \n[FIGURE 4] \nMLP has a similar structure to the usual neural networks but includes more stacked layers. It is \ntrained in a purely supervised manner that uses only labeled data. Since the training method is \na process of optimization in high-dimensional parameter space, MLP is typically used when a \nlarge number of labeled data are available [25].  \n \n[FIGURE 5] \nSAE and DBN use AEs and RBMs as building blocks of the architectures, respectively. The \nmain difference between these and MLP is that training is executed in two phases: unsupervised \npre-training and supervised fine-tuning. First, in unsupervised pre-training (Figure 5), the \nlayers are stacked sequentially and trained in a layer-wise manner as an AE or RBM using \nunlabeled data. Afterwards, in supervised fine-tuning, an output classifier layer is stacked, and \nthe whole neural network is optimized by retraining with labeled data. Since both SAE and \nDBN exploit unlabeled data and can help avoid overfitting, researchers are able to obtain fairly \nregularized results, even when labeled data are insufficient as is common in the real world [68]. \nDNNs are renowned for their suitability in analyzing high-dimensional data. Given that \nbioinformatics data are typically complex and high-dimensional, DNNs have great promise for \nbioinformatics research. We believe DNNs, as hierarchical representation learning methods, \ncan discover previously unknown highly abstract patterns and correlations to provide insight \nto better understand the nature of the data. However, it has occurred to us that the capabilities \nof DNNs have not yet fully been exploited. Although the key characteristic of DNNs is that \nhierarchical features are learned solely from data, human designed features have often been \ngiven as inputs instead of raw data forms. We expect that the future progress of DNNs in \nbioinformatics will come from investigations into proper ways to encode raw data and learn \nsuitable features from them.  \n \nConvolutional neural networks \n \n [FIGURE 6] \nCNNs are designed to process multiple data types, especially two-dimensional images, and are \ndirectly inspired by the visual cortex of the brain. In the visual cortex, there is a hierarchy of \ntwo basic cell types: simple cells and complex cells [69]. Simple cells react to primitive patterns \nin sub-regions of visual stimuli, and complex cells synthesize the information from simple cells \nto identify more intricate forms. Since the visual cortex is such a powerful and natural visual \nprocessing system, CNNs are applied to imitate three key ideas: local connectivity, invariance \nto location, and invariance to local transition [8]. \nThe basic structure of CNNs consists of convolution layers, nonlinear layers, and pooling layers \n(Figure 6). To use highly correlated sub-regions of data, groups of local weighted sums, called \nfeature maps, are obtained at each convolution layer by computing convolutions between local \npatches and weight vectors called filters. Furthermore, since identical patterns can appear \nregardless of the location in the data, filters are applied repeatedly across the entire dataset, \nwhich also improves training efficiency by reducing the number of parameters to learn. Then \nnonlinear layers increase the nonlinear properties of feature maps. At each pooling layer, \nmaximum or average subsampling of non-overlapping regions in feature maps is performed. \nThis non-overlapping subsampling enables CNNs to handle somewhat different but \nsemantically similar features and thus aggregate local features to identify more complex \nfeatures. \nCurrently, CNNs are one of the most successful deep learning architectures owing to their \noutstanding capacity to analyze spatial information. Thanks to their developments in the field \nof object recognition, we believe the primary research achievements in bioinformatics will \ncome from the biomedical imaging domain. Despite the different data characteristics between \nnormal and biomedical imaging, CNN will nonetheless offer straightforward applications \ncompared to other domains. Indeed, CNNs also have great potential in omics and biomedical \nsignal processing. The three keys ideas of CNNs can be applied not only in a one-dimensional \ngrid to discover meaningful recurring patterns with small variance, such as genomic sequence \nmotifs, but also in two-dimensional grids, such as interactions within omics data and in time-\nfrequency matrices of biomedical signals. Thus, we believe the popularity and promise of \nCNNs in bioinformatics applications will continue in the years ahead.  \n \nRecurrent neural networks \n \n [FIGURE 7] \nRNNs, which are designed to utilize sequential information, have a basic structure with a cyclic \nconnection (Figure 7). Since input data are processed sequentially, recurrent computation is \nperformed in the hidden units where cyclic connection exists. Therefore, past information is \nimplicitly stored in the hidden units called state vectors, and output for the current input is \ncomputed considering all previous inputs using these state vectors [8]. Since there are many \ncases where both past and future inputs affect output for the current input (e.g., in speech \nrecognition), bidirectional recurrent neural networks (BRNNs) [70] have also been designed \nand used widely (Figure 8). \n \n[FIGURE 8] \nAlthough RNNs do not seem to be deep as DNNs or CNNs in terms of the number of layers, \nthey can be regarded as an even deeper structure if unrolled in time (Figure 7). Therefore, for \na long time, researchers struggled against vanishing gradient problems while training RNNs, \nand learning long-term dependency among data was difficult [35]. Fortunately, substituting the \nsimple perceptron hidden units with more complex units such as LSTM [36, 37] or GRU [19], \nwhich function as memory cells, significantly helps to prevent the problem. More recently, \nRNNs have been used successfully in many areas including natural language processing [16, \n17] and language translation [18, 19]. \nEven though RNNs have been explored less than DNNs and CNNs, they still provide very \npowerful analysis methods for sequential information. Since omics data and biomedical signals \nare typically sequential and often considered languages of nature, the capabilities of RNNs for \nmapping a variable-length input sequence to another sequence or fixed-size prediction are \npromising for bioinformatics research. With regard to biomedical imaging, RNNs are currently \nnot the first choice of many researchers. Nevertheless, we believe that dissemination of \ndynamic CT and MRI [71, 72] would lead to the incorporation of RNNs and CNNs and elevate \ntheir importance in the long term. Furthermore, we expect that their successes in natural \nlanguage processing will lead RNNs to be applied in biomedical text analysis [73] and that \nemploying an attention mechanism [74-77] will improve performance and extract more \nrelevant information from bioinformatics data.  \n \nEmergent architectures  \nEmergent architectures refer to deep learning architectures besides DNNs, CNNs, and RNNs. \nIn this review, we introduce three emergent architectures (i.e., DST-NNs, MD-RNNs, and \nCAEs) and their applications in bioinformatics. \n \n[FIGURE 9] \nDST-NNs [38] are designed to learn multi-dimensional output targets through progressive \nrefinement. The basic structure of DST-NNs consists of multi-dimensional hidden layers \n(Figure 9). The key aspect of the structure, progressive refinement, considers local correlations \nand is performed via input feature compositions in each layer: spatial features and temporal \nfeatures. Spatial features refer to the original inputs for the whole DST-NN and are used \nidentically in every layer. However, temporal features are gradually altered so as to progress to \nthe upper layers. Except for the first layer, to compute each hidden unit in the current layer, \nonly the adjacent hidden units of the same coordinate in the layer below are used so that local \ncorrelations are reflected progressively. \n \n[FIGURE 10] \nMD-RNNs [39] are designed to apply the capabilities of RNNs to non-sequential multi-\ndimensional data by treating them as groups of sequential data. For instance, two-dimensional \ndata are treated as groups of horizontal and vertical sequence data. Similar to BRNNs which \nuse contexts in both directions in one-dimensional data, MD-RNNs use contexts in all possible \ndirections in the multi-dimensional data (Figure 10). In the example of a two-dimensional \ndataset, four contexts that vary with the order of data processing are reflected in the \ncomputation of four hidden units for each position in the hidden layer. The hidden units are \nconnected to a single output layer, and the final results are computed with consideration of all \npossible contexts.  \n \n[FIGURE 11]  \nCAEs [40, 41] are designed to utilize the advantages of both AE and CNNs so that it can learn \ngood hierarchical representations of data reflecting spatial information and be well regularized \nby unsupervised training (Figure 11). In training of AEs, reconstruction error is minimized \nusing an encoder and decoder, which extract feature vectors from input data and recreate the \ndata from the feature vectors, respectively. In CNNs, convolution and pooling layers can be \nregarded as a type of encoder. Therefore, the CNN encoder and decoder consisting of \ndeconvolution and unpooling layers are integrated to form a CAE and are trained in the same \nmanner as in AE.  \nDeep learning is a rapidly growing research area, and a plethora of new deep learning \narchitecture is being proposed but awaits wide applications in bioinformatics. Newly proposed \narchitectures have different advantages from existing architectures, so we expect them to \nproduce promising results in various research areas. For example, the progressive refinement \nof DST-NNs fits the dynamic folding process of proteins and can be effectively utilized in \nprotein structure prediction [38]; the capabilities of MD-RNNs are suitable for segmentation \nof biomedical images since segmentation requires interpretation of local and global contexts; \nthe unsupervised representation learning with consideration of spatial information in CAEs can \nprovide great advantages in discovering recurring patterns in limited and imbalanced \nbioinformatics data. \n \n \n \n \n \n \n \n \n \n \nTABLE 4: Deep learning applied bioinformatics research avenues and input data \n  \nInput data \nResearch avenues \nOmics \nsequencing data (DNA-seq, RNA-seq, ChIP-seq, DNase-seq) \nfeatures from genomic sequence \n       position specific scoring matrix (PSSM) \n       physicochemical properties (steric parameter, volume) \n       Atchley factors (FAC) \n       1-dimensional structural properties \ncontact map (distance of amino acid pairs in 3D structure) \nmicroarray gene expression \nProtein structure prediction [84-92] \n       1-dimensional structural properties \n       contact map \n       structure model quality assessment \nGene expression regulation [93-107] \n       splice junction \n       genetic variants affecting splicing \n       sequence specificity \nProtein classification [108-110] \n       super family \n       subcellular localization \nAnomaly classification [111] \n       Cancer \nBiomedical \nimaging \nmagnetic resonance image (MRI) \nradiographic image \npositron emission tomography (PET) \nhistopathology image \nvolumetric electron microscopy image \nretinal image \nin situ hybridization (ISH) image  \nAnomaly classification [122-132] \n       gene expression pattern \n       cancer \n       Alzheimer's disease \n       schizophrenia \nSegmentation [133-141] \n       cell structure \n       neuronal structure \n       vessel map \n       brain tumor \nRecognition [142-147] \n       cell nuclei \n       finger joint \n       anatomical structure \nBrain decoding [149-150] \n       behavior \nBiomedical  \nsignal processing \nECoG, ECG, EMG, EOG \nEEG (raw, wavelet, frequency, differential entropy) \nextracted features from EEG \n       normalized decay \n       peak variation \nBrain decoding [158-170] \n       behavior \n       emotion \nAnomaly classification [171-178] \n       Alzheimer's disease \n       seizure \n       sleep stage \n \nOmics \nIn omics research, genetic information such as genome, transcriptome, and proteome data is \nused to approach problems in bioinformatics. Some of the most common input data in omics \nare raw biological sequences (i.e., DNA, RNA, amino acid sequences) which have become \nrelatively affordable and easy to obtain with next-generation sequencing technology. In \naddition, extracted features from sequences such as a position specific scoring matrices (PSSM) \n[78], physicochemical properties [79, 80], Atchley factors [81], and one-dimensional structural \nproperties [82, 83] are often used as inputs for deep learning algorithms to alleviate difficulties \nfrom complex biological data and improve results. In addition, protein contact maps, which \npresent distances of amino acid pairs in their three-dimensional structure, and microarray gene \nexpression data are also used according to the characteristics of interest. We categorized the \ntopics of interest in omics into four groups (Table 4). One of the most researched problems is \nprotein structure prediction, which aims to predict the secondary structure or contact map of a \nprotein [84-92]. Gene expression regulation [93-107], including splice junctions or RNA \nbinding proteins, and protein classification [108-110], including super family or subcellular \nlocalization, are also actively investigated. Furthermore, anomaly classification [111] \napproaches have been used with omics data to detect cancer. \nDeep neural networks \nDNNs have been widely applied in protein structure prediction [84-87] research. Since \ncomplete prediction in three-dimensional space is complex and challenging, several studies \nhave used simpler approaches, such as predicting the secondary structure or torsion angles of \nprotein. For instance, Heffernan et al. [85] applied SAE to protein amino acid sequences to \nsolve prediction problems for secondary structure, torsion angle, and accessible surface area. \nIn another study, Spencer et al. [86] applied DBN to amino acid sequences along with PSSM \nand Atchley factors to predict protein secondary structure. DNNs have also shown great \ncapabilities in the area of gene expression regulation [93-98]. For example, Lee et al. [94] \nutilized DBN in splice junction prediction, a major research avenue in understanding gene \nexpression [112], and proposed a new DBN training method called boosted contrastive \ndivergence for imbalanced data and a new regularization term for sparsity of DNA sequences; \ntheir work showed not only significantly improved performance but also the ability to detect \nsubtle non-canonical splicing signals. Moreover, Chen et al. [96] applied MLP to both \nmicroarray and RNA-seq expression data to infer expression of up to 21000 target genes from \nonly 1000 landmark genes. In terms of protein classification, Asgari et al. [108] adopted the \nskip-gram model, a widely known method in natural language processing, that can be \nconsidered a variant of MLP, and showed that it could effectively learn a distributed \nrepresentation of biological sequences with general use for many omics applications, including \nprotein family classification. For anomaly classification, Fakoor et al. [111] used principal \ncomponent analysis (PCA) [113] to reduce the dimensionality of microarray gene expression \ndata and applied SAE to classify various cancers, including acute myeloid leukemia, breast \ncancer, and ovarian cancer. \nConvolutional neural networks \nRelatively few studies have used CNNs to solve problems involving biological sequences, \nspecifically gene expression regulation problems [99-104]; nevertheless, those have introduced \nthe strong advantages of CNNs, showing their great promise for future research. First, an initial \nconvolution layer can powerfully capture local sequence patterns and can be considered a motif \ndetector for which PSSMs are solely learned from data instead of hard-coded. The depth of \nCNNs enables learning more complex patterns and can capture longer motifs, integrate \ncumulative effects of observed motifs, and eventually learn sophisticated regulatory codes \n[114]. Moreover, CNNs are suited to exploit the benefits of multitask joint learning. By training \nCNNs to simultaneously predict closely related factors, features with predictive strengths are \nmore efficiently learned and shared across different tasks.  \nFor example, as an early approach, Denas et al. [99] preprocessed ChIP-seq data into a two-\ndimensional matrix with the rows as transcription factor activity profiles for each gene and \nexploited a two-dimensional CNN similar to its use in image processing. Recently, more studies \nfocused on directly using one-dimensional CNNs with biological sequence data. Alipanahi et \nal. [100] and Kelley et al. [103] proposed CNN-based approaches for transcription factor \nbinding site prediction and 164 cell-specific DNA accessibility multitask prediction, \nrespectively; both groups presented downstream applications for disease-associated genetic \nvariant identification. Furthermore, Zeng et al. [102] performed a systematic exploration of \nCNN architectures for transcription factor binding site prediction and showed that the number \nof convolutional filters is more important than the number of layers for motif-based tasks. Zhou \net al. [104] developed a CNN-based algorithmic framework, DeepSEA, that performs multitask \njoint learning of chromatin factors (i.e., transcription factor binding, DNase I sensitivity, \nhistone-mark profile) and prioritizes expression quantitative trait loci and disease-associated \ngenetic variants based on the predictions. \nRecurrent neural networks \nRNNs are expected to be an appropriate deep learning architecture because biological \nsequences have variable lengths, and their sequential information has great importance. Several \nstudies have applied RNNs to protein structure prediction [88-90], gene expression regulation \n[105-107], and protein classification [109, 110]. In early studies, Baldi et al. [88] used BRNNs \nwith perceptron hidden units in protein secondary structure prediction. Thereafter, the \nimproved performance of LSTM hidden units became widely recognized, so Sønderby et al. \n[110] applied BRNNs with LSTM hidden units and a one-dimensional convolution layer to \nlearn representations from amino acid sequences and classify the subcellular locations of \nproteins. Furthermore, Park et al. [105] and Lee et al. [107] exploited RNNs with LSTM hidden \nunits in microRNA identification and target prediction and obtained significantly improved \naccuracy relative to state-of-the-art approaches demonstrating the high capacity of RNNs to \nanalyze biological sequences. \nEmergent architectures \nEmergent architectures have been used in protein structure prediction research [91, 92], \nspecifically in contact map prediction. Di Lena et al. [91] applied DST-NNs using spatial \nfeatures including protein secondary structure, orientation probability, and alignment \nprobability. Additionally, Baldi et al. [92] applied MD-RNNs to amino acid sequences, \ncorrelated profiles, and protein secondary structures. \n \nBiomedical imaging \nBiomedical imaging [115] is another an actively researched domain with wide application of \ndeep learning in general image-related tasks. Most biomedical images used for clinical \ntreatment of patients—magnetic resonance imaging (MRI) [116, 117], radiographic imaging \n[118, 119], positron emission tomography (PET) [120], and histopathology imaging [121]—\nhave been used as input data for deep learning algorithms. We categorized the research avenues \nin biomedical imaging into four groups (Table 4). One of the most researched problems is \nanomaly classification [122-132] to diagnose diseases such as cancer or schizophrenia. As in \ngeneral image-related tasks, segmentation [133-141] (i.e., partitioning specific structures such \nas cellular structures or a brain tumor) and recognition [142-147] (i.e., detection of cell nuclei \nor a finger joint) are studied frequently in biomedical imaging. Studies of popular high content \nscreening [148], which involves quantifying microscopic images for cell biology, are covered \nin the former groups [128, 134, 137]. Additionally, cranial MRIs have been used in brain \ndecoding [149, 150] to interpret human behavior or emotion.  \nDeep neural networks \nIn terms of biomedical imaging, DNNs have been applied in several research areas, including \nanomaly classification [122-124], segmentation [133], recognition [142, 143], and brain \ndecoding [149, 150]. Plis et al. [122] classified schizophrenia patients from brain MRIs using \nDBN, and Xu et al. [142] used SAE to detect cell nuclei from histopathology images. \nInterestingly, similar to handwritten digit image recognition, Van Gerven et al. [149] classified \nhandwritten digit images with DBN not by analyzing the images themselves but by indirectly \nanalyzing indirectly functional MRIs of participants who are looking at the digit images. \nConvolutional neural networks \nThe largest number of studies have been conducted in biomedical imaging, since these avenues \nare similar to general image-related tasks. In anomaly classification [125-132], Roth et al. [125] \napplied CNNs to three different CT image datasets to classify sclerotic metastases, lymph nodes, \nand colonic polyps. Additionally, Ciresan et al. [128] used CNNs to detect mitosis in breast \ncancer histopathology images, a crucial approach for cancer diagnosis and assessment. PET \nimages of esophageal cancer were used by Ypsilantis et al. [129] to predict responses to \nneoadjuvant chemotherapy. Other applications of CNNs can be found in segmentation [134-\n140] and recognition [144-147]. For example, Ning et al. [134] studied pixel-wise segmentation \npatterns of the cell wall, cytoplasm, nuclear membrane, nucleus, and outside media using \nmicroscopic image, and Havaei et al. [139] proposed a cascaded CNN architecture exploiting \nboth local and global contextual features and performed brain tumor segmentation from MRIs. \nFor recognition, Cho et al. [144] researched anatomical structure recognition among CT images, \nand Lee et al. [145] proposed a CNN-based finger joint detection system, FingerNet, which is \na crucial step for medical examinations of bone age, growth disorders, and rheumatoid arthritis \n[151]. \nRecurrent neural networks \nTraditionally, images are considered data that involve internal correlations or spatial \ninformation rather than sequential information. Treating biomedical images as non-sequential \ndata, most studies in biomedical imaging have chosen approaches involving DNNs or CNNs \ninstead of RNNs.  \nEmergent architectures \nAttempts to apply the unique capabilities of RNNs to image data using augmented RNN \nstructures have continued. MD-RNNs [39] have been applied beyond two-dimensional images \nto three-dimensional images. For example, Stollenga et al. [141] applied MD-RNNs to three-\ndimensional electron microscopy images and MRIs to segment neuronal structures. \n \nBiomedical signal processing \nBiomedical signal processing [115] is a domain where researchers use recorded electrical \nactivity from the human body to solve problems in bioinformatics. Various data from EEG \n[152], \nelectrocorticography \n(ECoG) \n[153], \nelectrocardiography \n(ECG) \n[154], \nelectromyography (EMG) [155], and electrooculography (EOG) [156, 157] have been used, \nwith most studies focusing on EEG activity so far. Because recorded signals are usually noisy \nand include many artifacts, raw signals are often decomposed into wavelet or frequency \ncomponents before they are used as input in deep learning algorithms. In addition, human-\ndesigned features like normalized decay and peak variation are used in some studies to improve \nthe results. We categorized the research avenues in biomedical signal processing into two \ngroups (Table 4): brain decoding [158-170] using EEG signals and anomaly classification [171-\n178] to diagnose diseases. \nDeep neural networks \nSince biomedical signals usually contain noise and artifacts, decomposed features are more \nfrequently used than raw signals. In brain decoding [158-163], An et al. [159] applied DBN to \nthe frequency components of EEG signals to classify left- and right-hand motor imagery skills. \nMoreover, Jia et al. [161] and Jirayucharoensak et al. [163] used DBN and SAE, respectively, \nfor emotion classification. In anomaly classification [171-175], Huanhuan et al. [171] \npublished one of the few studies applying DBN to ECG signals and classified each beat into \neither a normal or abnormal beat. A few studies have used raw EEG signals. Wulsin et al. [172] \nanalyzed individual second-long waveform abnormalities using DBN with both raw EEG \nsignals and extracted features as inputs, whereas Zhao et al. [174] used only raw EEG signals \nas inputs for DBN to diagnose Alzheimer’s disease.  \nConvolutional neural networks \nRaw EEG signals have been analyzed in brain decoding [164-167] and anomaly classification \n[176] via CNNs, which perform one-dimensional convolutions. For instance, Stober et al. [165] \nclassified the rhythm type and genre of music that participants listened to, and Cecotti et al. \n[167] classified characters that the participants viewed. Another approach to apply CNNs to \nbiomedical signal processing was reported by Mirowski et al. [176], who extracted features \nsuch as phase-locking synchrony and wavelet coherence and coded them as pixel colors to \nformulate two-dimensional patterns. Then, ordinary two-dimensional CNNs, like the one used \nin biomedical imaging, were used to predict seizures. \nRecurrent neural networks \nSince biomedical signals represent naturally sequential data, RNNs are an appropriate deep \nlearning architecture to analyze data and are expected to produce promising results. To present \nsome of the studies in brain decoding [168] and anomaly classification [177, 178], Petrosian et \nal. [177] applied perceptron RNNs to raw EEG signals and corresponding wavelet decomposed \nfeatures to predict seizures. In addition, Davidson et al. [178] used LSTM RNNs on EEG log-\npower spectra features to detect lapses. \nEmergent architectures \nCAE has been applied in a few brain decoding studies [169, 170]. Wang et al. [169] performed \nfinger flex and extend classifications using raw ECoG signals. In addition, Stober et al. [170] \nclassified musical rhythms that participants listened to with raw EEG signals.  \n \nDiscussion \nLimited and imbalanced data \nConsidering the necessity of optimizing a tremendous number of weight parameters in neural \nnetworks, most deep learning algorithms have assumed sufficient and balanced data. \nUnfortunately, however, this is usually not true for problems in bioinformatics. Complex and \nexpensive data acquisition processes limit the size of bioinformatics datasets. In addition, such \nprocesses often show significantly unequal class distributions, where an instance from one class \nis significantly higher than instances from other classes [179]. For example in clinical or \ndisease-related cases, there is inevitably less data from treatment groups than from the normal \n(control) group. The former are also rarely disclosed to the public due to privacy restrictions \nand ethical requirements creating a further imbalance in available data [180].  \nA few assessment metrics have been used to clearly observe how limited and imbalanced data \nmight compromise the performance of deep learning [181]. While accuracy often gives \nmisleading results, the F-measure, the harmonic mean of precision and recall, provides more \ninsightful performance scores. To measure performance over different class distributions, the \narea under the receiver operating characteristic curve (AUC) and the area under the precision-\nrecall curve (AUC-PR) are commonly used. These two measures are strongly correlated such \nthat a curve dominates in one measure if and only if it dominates in the other. Nevertheless, in \ncontrast with AUC-PR, AUC might present a more optimistic view of performance, since false \npositive rates in the receiver operating characteristic curve fail to capture large changes of false \npositives if classes are negatively skewed [182].   \nSolutions to limited and imbalanced data can be divided into three major groups [181, 183] : \ndata preprocessing, cost-sensitive learning and algorithmic modification. Data preprocessing \ntypically provides a better dataset through sampling or basic feature extraction. Sampling \nmethods balance the distribution of imbalanced data, and several approaches have been \nproposed, including informed undersampling [184], the synthetic minority oversampling \ntechnique [185], and cluster-based sampling [186]. For example, Li et al. [127] and Roth et al. \n[146] performed enrichment analyses of CT images through spatial deformations such as \nrandom shifting and rotation. Although basic feature extraction methods deviate from the \nconcept of deep learning, they are occasionally used to lessen the difficulties of learning from \nlimited and imbalanced data. Research in bioinformatics using human designed features as \ninput data such as PSSM from genomics sequences or wavelet energy from EEG signals can \nbe understood in the same context [86, 92, 172, 176]. \nCost-sensitive learning methods define different costs for misclassifying data examples from \nindividual classes to solve the limited and imbalanced data problems. Cost sensitivity can be \napplied in an objective loss function of neural networks either explicitly or implicitly [187]. \nFor example, we can explicitly replace the objective loss function to reflect class imbalance or \nimplicitly modify the learning rates according to data instance classes during training.  \nAlgorithmic modification methods accommodate learning algorithms to increase their \nsuitability for limited and imbalanced data. A simple and effective approach is adoption of pre-\ntraining. Unsupervised pre-training can be a great help to learn representation for each class \nand to produce more regularized results [68]. In addition, transfer learning, which consists of \npre-training with sufficient data from similar but different domains and fine-tuning with real \ndata, has great advantages [24, 188]. For instance, Lee et al. [107] proposed a microRNA target \nprediction method, which exploits unsupervised pre-training with RNN based AE, and \nachieved a >25% increase in F-measure compared to the existing alternatives. Bar et al. [132] \nperformed transfer learning using natural images from the ImageNet database [189] as pre-\ntraining data and fine-tuned with chest X-ray images to identify chest pathologies and to \nclassify healthy and abnormal images. In addition to pre-training, sophisticated training \nmethods have also been executed. Lee et al. [94] suggested DBN with boosted categorical \nRBM, and Havaei et al. [139] suggested CNNs with two-phase training, combining ideas of \nundersampling and pre-training. \nChanging the black-box into the white-box \nA main criticism against deep learning is that it is used as a black-box: even though it produces \noutstanding results, we know very little about how such results are derived internally. In \nbioinformatics, particularly in biomedical domains, it is not enough to simply produce good \noutcomes. Since many studies are connected to patients’ health, it is crucial to change the black-\nbox into the white-box providing logical reasoning just as clinicians do for medical treatments.  \nTransformation of deep learning from the black-box into the white-box is still in the early \nstages. One of the most widely used approaches is interpretation through visualizing a trained \ndeep learning model. In terms of image input, a deconvolutional network has been proposed to \nreconstruct and visualize hierarchical representations for a specific input of CNNs [190]. In \naddition, to visualize a generalized class representative image rather than being dependent on \na particular input, gradient ascent optimization in input space through backpropagation-to-\ninput (cf. backpropagation-to-weights) has provided another effective methodology [191, 192]. \nRegarding genomic sequence input, several approaches have been proposed to infer PSSMs \nfrom a trained model and to visualize the corresponding motifs with heat maps or sequence \nlogos. For example, Lee et al. [94] extracted motifs by choosing the most class discriminative \nweight vector among those in the first layer of DBN; DeepBind [100] and DeMo [101] \nextracted motifs from trained CNNs by counting nucleotide frequencies of positive input \nsubsequences with high activation values and backpropagation-to-input for each feature map, \nrespectively.  \nSpecifically for transcription factor binding site prediction, Alipanahi et al. [100] developed a \nvisualization method, a mutation map, for illustrating the effects of genetic variants on binding \nscores predicted by CNNs. A mutation map consists of a heat map, which shows how much \neach mutation alters the binding score, and the input sequence logo, where the height of each \nbase is scaled as the maximum decrease of binding score among all possible mutations. \nMoreover, Kelley et al. [103] further complemented the mutation map with a line plot to show \nthe maximum increases as well as the maximum decreases of prediction scores. In addition to \ninterpretation through visualization, attention mechanisms [74-77] designed to focus explicitly \non salient points and the mathematical rationale behind deep learning [193, 194] are being \nstudied. \nSelection of an appropriate deep learning architecture and hyperparameters \nChoosing the appropriate deep learning architecture is crucial to proper applications of deep \nlearning. To obtain robust and reliable results, awareness of the capabilities of each deep \nlearning architecture and selection according to capabilities in addition to input data \ncharacteristics and research objectives are essential. However, to date, the advantages of each \narchitecture are only roughly understood; for example, DNNs are suitable for analysis of \ninternal correlations in high-dimensional data, CNNs are suitable for analysis of spatial \ninformation, and RNNs are suitable for analysis of sequential information [7]. Indeed, a \ndetailed methodology for selecting the most appropriate or “best fit” deep learning architecture \nremains a challenge to be studied in the future.  \nEven once a deep learning architecture is selected, there are many hyperparameters—the \nnumber of layers, the number of hidden units, weight initialization values, learning iterations, \nand even the learning rate—for researchers to set, all of which can influence the results \nremarkably [195]. For many years, hyperparameter tuning was rarely systematic and left up to \nhuman machine learning experts. Nevertheless, automation of machine learning research, \nwhich aims to automatically optimize hyperparameters is growing constantly [196]. A few \nalgorithms have been proposed including sequential model based global optimization [197], \nBayesian optimization with Gaussian process priors [198], and random search approaches \n[199].  \nMultimodal deep learning \nMultimodal deep learning [200], which exploits information from multiple input sources, is a \npromising avenue for the future of deep learning research. In particular, bioinformatics is \nexpected to benefit greatly, as it is a field where various types of data can be assimilated \nnaturally [201]. For example, not only are omics data, images, signals, drug responses, and \nelectronic medical records available as input data, but X-ray, CT, MRI, and PET forms are also \navailable from a single image.  \nA few bioinformatics studies have already begun to use multimodal deep learning. For example, \nSuk et al. [124] studied Alzheimer’s disease classification using cerebrospinal fluid and brain \nimages in the forms of MRI and PET scan and Soleymani et al. [168] conducted an emotion \ndetection study with both EEG signal and face image data.  \nAccelerating deep learning \nAs more deep learning model parameters and training data become available, better learning \nperformances can be achieved. However, at the same time, this inevitably leads to a drastic \nincrease in training time, emphasizing the necessity for accelerated deep learning [7, 25].  \nApproaches to accelerating deep learning can be divided into three groups: advanced \noptimization algorithms, parallel and distributed computing, and specialized hardware. Since \nthe main reason for long training times is that parameter optimization through plain SGD takes \ntoo long, several studies have focused on advanced optimization algorithms [202]. To this end, \nsome widely employed algorithms include Adagrad [48], Adam [49], batch normalization [55], \nand Hessian-free optimization [203]. Parallel and distributed computing can significantly \naccelerate the time to completion and have enabled many deep learning studies [204-208]. \nThese approaches exploit both scale-up methods, which use a graphic processing unit, and \nscale-out methods, which use large-scale clusters of machines in a distributed environment. A \nfew deep learning frameworks, including the recently released DeepSpark [209] and \nTensorFlow [210] provide parallel and distributed computing abilities. Although development \nof specialized hardware for deep learning is still in its infancy, it will provide major \naccelerations and become far more important in the long term [211]. Currently, field \nprogrammable gate array based processors are under development, and neuromorphic chips \nmodeled from the brain are greatly anticipated as promising technologies [212-214]. \nFuture trends of deep learning \nIncorporation of traditional deep learning architectures is a promising future trend. For instance, \njoint networks of CNNs and RNNs integrated with attention models have been applied in image \ncaptioning [75], video summarization [215], and image question answering [216]. A few \nstudies toward augmenting the structures of RNNs have been conducted as well. Neural Turing \nmachines [217] and memory networks [218] have adopted addressable external memory in \nRNNs and shown great results for tasks requiring intricate inferences, such as algorithm \nlearning and complex question answering. Recently, adversarial examples, which degrade \nperformance with small human-imperceptible perturbations, have received increased attention \nfrom the machine learning community [219, 220]. Since adversarial training of neural networks \ncan result in regularization to provide higher performance, we expect additional studies in this \narea, including those involving adversarial generative networks [221] and manifold regularized \nnetworks [222].  \nIn terms of learning methodology, semi-supervised learning and reinforcement learning are \nalso receiving attention. Semi-supervised learning exploits both unlabeled and labeled data, \nand a few algorithms have been proposed. For example, ladder networks [223] add skip \nconnections to MLP or CNNs, and simultaneously minimize the sum of supervised and \nunsupervised cost functions to denoise representations at every level of the model. \nReinforcement learning leverages reward outcome signals resulting from actions rather than \ncorrectly labeled data. Since reinforcement learning most closely resembles how humans \nactually learn, this approach has great promise for artificial general intelligence [224]. \nCurrently, its applications are mainly focused on game playing [4] and robotics [225].  \n \nConclusion \nAs we enter the major era of big data, deep learning is taking center stage for international \nacademic and business interests. In bioinformatics, where great advances have been made with \nconventional machine learning, deep learning is anticipated to produce promising results. In \nthis review, we provided an extensive review of bioinformatics research applying deep learning \nin terms of input data, research objectives, and the characteristics of established deep learning \narchitectures. We further discussed limitations of the approach and promising directions of \nfuture research. \nAlthough deep learning holds promise, it is not a silver bullet and cannot provide great results \nin ad hoc bioinformatics applications. There remain many potential challenges, including \nlimited or imbalanced data, interpretation of deep learning results, and selection of an \nappropriate architecture and hyperparameters. Furthermore, to fully exploit the capabilities of \ndeep learning, multimodality and acceleration of deep learning require further study. Thus, we \nare confident that prudent preparations regarding the issues discussed herein are key to the \nsuccess of future deep learning approaches in bioinformatics. We believe that this review will \nprovide valuable insight and serve as a starting point for application of deep learning to advance \nbioinformatics in future research. \n \n \nFunding \nThis work was supported by the National Research Foundation (NRF) of Korea grants funded \nby the Korean Government (Ministry of Science, ICT and Future Planning) [No. 2011-0009963, \nNo. 2014M3C9A3063541]; the ICT R&D program of MSIP/ITP [14-824-09-014, Basic \nSoftware Research in Human-level Lifelong Machine Learning (Machine Learning Center)]; \nand SNU ECE Brain Korea 21+ project in 2016. \n \nAcknowledgements \nThe authors would like to thank Prof. Russ Altman and Prof. Tsachy Weissman at Stanford \nUniversity, Prof. Honglak Lee at University of Michigan, Prof. V. Narry Kim and Prof. \nDaehyun Baek at Seoul National University, and Prof. Young-Han Kim at University of \nCalifornia, San Diego for helpful discussions on applying artificial intelligence and machine \nlearning to bioinformatics. \n \nFigure captions \nFigure 1: Approximate number of published deep learning articles by year. The number of \narticles is based on the search results on http://www.scopus.com with the two queries: “Deep \nlearning,” “Deep learning” AND “bio*”. \nFigure 2: Application of deep learning in bioinformatics research. (A) Overview diagram with \ninput data and research objectives. (B) A research example in the omics domain. Prediction of \nsplice junctions in DNA sequence data with a deep neural network [94]. (C) A research example \nin biomedical imaging. Finger joint detection from X-ray images with a convolutional neural \nnetwork [145]. (D) A research example in biomedical signal processing. Lapse detection from \nEEG signal with a recurrent neural network [178]. \nFigure 3: Relationships and high-level schematics of artificial intelligence, machine learning, \nrepresentation learning, and deep learning [7].  \nFigure 4: Basic structure of DNNs with input units x, three hidden units h1, h2, and h3, in each \nlayer and output units y [26]. At each layer, the weighted sum and nonlinear function of its \ninputs are computed so that the hierarchical representations can be obtained. \nFigure 5: Unsupervised layer-wise pre-training process in SAE and DBN [29]. First, weight \nvector W1 is trained between input units x and hidden units h1 in the first hidden layer as an \nRBM or AE. After the W1 is trained, another hidden layer is stacked, and the obtained \nrepresentations in h1 are used to train W2 between hidden units h1 and h2 as another RBM or \nAE. The process is repeated for the desired number of layers. \nFigure 6: Basic structure of CNNs consisting of a convolution layer, a nonlinear layer, and a \npooling layer [32]. The convolution layer of CNNs uses multiple learned filters to obtain \nmultiple filter maps detecting low-level filters, and then the pooling layer combines them into \nhigher-level features. \nFigure 7: Basic structure of RNNs with an input unit x, a hidden unit h, and an output unit y \n[8]. A cyclic connection exists so that the computation in the hidden unit receives inputs from \nthe hidden unit at the previous time step and from the input unit at the current time step. The \nrecurrent computation can be expressed more explicitly if the RNNs are unrolled in time. The \nindex of each symbol represents the time step. In this way, ht receives input from xt and ht-1 and \nthen propagates the computed results to yt and ht+1. \nFigure 8: Basic structure of BRNNs unrolled in time [70]. There are two hidden units ℎሬ⃗𝑡𝑡 and \nℎ⃖ሬ𝑡𝑡 for each time step. ℎሬ⃗𝑡𝑡 receives input from xt and ℎሬ⃗𝑡𝑡−1 to reflect past information; ℎ⃖ሬ𝑡𝑡 \nreceives input from xt and ℎ⃖ሬ𝑡𝑡+1 to reflect future information. The information from both \nhidden units is propagated to yt. \nFigure 9: Basic structure of DST-NNs [38]. The notation ℎ𝑖𝑖,𝑗𝑗\n𝑘𝑘 represents the hidden unit at (i, \nj) coordinate of the k-th hidden layer. To conduct the progressive refinement, the neighborhood \nunits of ℎ𝑖𝑖,𝑗𝑗\n𝑘𝑘 and input units x are used in the computation of ℎ𝑖𝑖,𝑗𝑗\n𝑘𝑘+1. \nFigure 10: Basic structure of MD-RNNs for two-dimensional data [39]. There are four groups \nof two-dimensional hidden units, each reflecting different contexts. For example, the (i, j) \nhidden unit in context 1 receives input from the (i–1, j) and (i, j–1) hidden units in context 1 \nand the (i, j) unit from the input layer so that the upper-left information is reflected. The hidden \nunits from all four contexts are propagated to compute the (i, j) unit in the output layer. \nFigure 11: Basic structure of CAEs consisting of a convolution layer and a pooling layer \nworking as an encoder and a deconvolution layer and an unpooling layer working as a decoder \n[41]. The basic idea is similar to the AE, which learns hierarchical representations through \nreconstructing its input data, but CAE additionally utilizes spatial information by integrating \nconvolutions. \n \n \nReferences \n1. \nManyika J, Chui M, Brown B et al. Big data: The next frontier for innovation, competition, and \nproductivity 2011. \n2. \nFerrucci D, Brown E, Chu-Carroll J et al. Building Watson: An overview of the DeepQA project. \nAI magazine 2010;31(3):59-79. \n3. \nIBM Watson for Oncology. IBM. http://www.ibm.com/smarterplanet/us/en/ibmwatson/watson-\noncology.html, 2016. \n4. \nSilver D, Huang A, Maddison CJ et al. Mastering the game of Go with deep neural networks \nand tree search. Nature 2016;529(7587):484-9. \n5. \nDeepMind Health. Google DeepMind. https://www.deepmind.com/health, 2016. \n6. \nLarrañaga P, Calvo B, Santana R et al. Machine learning in bioinformatics. Briefings in \nbioinformatics 2006;7(1):86-112. \n7. \nGoodfellow I, Bengio Y, Courville A. Deep Learning. Book in preparation for MIT Press, 2016. \n8. \nLeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521(7553):436-44. \n9. \nFarabet C, Couprie C, Najman L et al. Learning hierarchical features for scene labeling. Pattern \nAnalysis and Machine Intelligence, IEEE Transactions on 2013;35(8):1915-29. \n10. Szegedy C, Liu W, Jia Y et al. Going deeper with convolutions. arXiv preprint arXiv:1409.4842 \n2014. \n11. Tompson JJ, Jain A, LeCun Y et al. Joint training of a convolutional network and a graphical \nmodel for human pose estimation. In: Advances in neural information processing systems. 2014. p. \n1799-807. \n12. Liu N, Han J, Zhang D et al. Predicting eye fixations using convolutional neural networks. In: \nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. p. 362-70. \n13. Hinton G, Deng L, Yu D et al. Deep neural networks for acoustic modeling in speech recognition: \nThe shared views of four research groups. Signal Processing Magazine, IEEE 2012;29(6):82-97. \n14. Sainath TN, Mohamed A-r, Kingsbury B et al. Deep convolutional neural networks for LVCSR. In: \nAcoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. 2013. p. \n8614-8. IEEE. \n15. Chorowski JK, Bahdanau D, Serdyuk D et al. Attention-based models for speech recognition. In: \nAdvances in neural information processing systems. 2015. p. 577-85. \n16. Kiros R, Zhu Y, Salakhutdinov RR et al. Skip-thought vectors. In: Advances in neural information \nprocessing systems. 2015. p. 3276-84. \n17. Li J, Luong M-T, Jurafsky D. A hierarchical neural autoencoder for paragraphs and documents. \narXiv preprint arXiv:1506.01057 2015. \n18. Luong M-T, Pham H, Manning CD. Effective approaches to attention-based neural machine \ntranslation. arXiv preprint arXiv:1508.04025 2015. \n19. Cho K, Van Merriënboer B, Gulcehre C et al. Learning phrase representations using RNN \nencoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 2014. \n20. Libbrecht MW, Noble WS. Machine learning applications in genetics and genomics. Nature \nReviews Genetics 2015;16(6):321-32. \n21. Schmidhuber J. Deep learning in neural networks: An overview. Neural networks 2015;61:85-\n117. \n22. Leung MK, Delong A, Alipanahi B et al. Machine Learning in Genomic Medicine: A Review of \nComputational Problems and Data Sets 2016. \n23. Mamoshina P, Vieira A, Putin E et al. Applications of deep learning in biomedicine. Molecular \nPharmaceutics 2016. \n24. Greenspan H, van Ginneken B, Summers RM. Guest Editorial Deep Learning in Medical Imaging: \nOverview and Future Promise of an Exciting New Technique. IEEE Transactions on Medical Imaging \n2016;35(5):1153-9. \n25. LeCun Y, Ranzato M. Deep learning tutorial. In: Tutorials in International Conference on Machine \nLearning (ICML’13). 2013. Citeseer. \n26. Svozil D, Kvasnicka V, Pospichal J. Introduction to multi-layer feed-forward neural networks. \nChemometrics and intelligent laboratory systems 1997;39(1):43-62. \n27. Vincent P, Larochelle H, Bengio Y et al. Extracting and composing robust features with denoising \nautoencoders. In: Proceedings of the 25th international conference on Machine learning. 2008. p. \n1096-103. ACM. \n28. Vincent P, Larochelle H, Lajoie I et al. Stacked denoising autoencoders: Learning useful \nrepresentations in a deep network with a local denoising criterion. The Journal of Machine Learning \nResearch 2010;11:3371-408. \n29. Hinton G, Osindero S, Teh Y-W. A fast learning algorithm for deep belief nets. Neural \nComputation 2006;18(7):1527-54. \n30. Hinton G, Salakhutdinov RR. Reducing the dimensionality of data with neural networks. Science \n2006;313(5786):504-7. \n31. LeCun Y, Boser B, Denker JS et al. Handwritten digit recognition with a back-propagation \nnetwork. In: Advances in neural information processing systems. 1990. Citeseer. \n32. Lawrence S, Giles CL, Tsoi AC et al. Face recognition: A convolutional neural-network approach. \nNeural Networks, IEEE Transactions on 1997;8(1):98-113. \n33. Krizhevsky A, Sutskever I, Hinton G. Imagenet classification with deep convolutional neural \nnetworks. In: Advances in neural information processing systems. 2012. p. 1097-105. \n34. Williams RJ, Zipser D. A learning algorithm for continually running fully recurrent neural \nnetworks. Neural Computation 1989;1(2):270-80. \n35. Bengio Y, Simard P, Frasconi P. Learning long-term dependencies with gradient descent is \ndifficult. Neural Networks, IEEE Transactions on 1994;5(2):157-66. \n36. Hochreiter S, Schmidhuber J. Long short-term memory. Neural Computation 1997;9(8):1735-80. \n37. Gers FA, Schmidhuber J, Cummins F. Learning to forget: Continual prediction with LSTM. Neural \nComputation 2000;12(10):2451-71. \n38. Lena PD, Nagata K, Baldi PF. Deep spatio-temporal architectures and learning for protein \nstructure prediction. In: Advances in neural information processing systems. 2012. p. 512-20. \n39. Graves A, Schmidhuber J. Offline handwriting recognition with multidimensional recurrent \nneural networks. In: Advances in neural information processing systems. 2009. p. 545-52. \n40. Hadsell R, Sermanet P, Ben J et al. Learning long‐range vision for autonomous off‐road driving. \nJournal of Field Robotics 2009;26(2):120-44. \n41. Masci J, Meier U, Cireşan D et al. Stacked convolutional auto-encoders for hierarchical feature \nextraction.  Artificial Neural Networks and Machine Learning–ICANN 2011. Springer, 2011, 52-9. \n42. Minsky M, Papert S. Perceptron: an introduction to computational geometry. The MIT Press, \nCambridge, expanded edition 1969;19(88):2. \n43. Fukushima K. Cognitron: A self-organizing multilayered neural network. Biological cybernetics \n1975;20(3-4):121-36. \n44. Hinton G, Sejnowski TJ. Learning and releaming in Boltzmann machines. Parallel distributed \nprocessing: Explorations in the microstructure of cognition 1986;1:282-317. \n45. Hinton G. A practical guide to training restricted Boltzmann machines. Momentum 2010;9(1):926. \n46. Hecht-Nielsen R. Theory of the backpropagation neural network. In: Neural Networks, 1989. \nIJCNN., International Joint Conference on. 1989. p. 593-605. IEEE. \n47. Bottou L. Stochastic gradient learning in neural networks. Proceedings of Neuro-Nımes \n1991;91(8). \n48. Duchi J, Hazan E, Singer Y. Adaptive subgradient methods for online learning and stochastic \noptimization. The Journal of Machine Learning Research 2011;12:2121-59. \n49. Kingma D, Ba J. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 \n2014. \n50. Moody J, Hanson S, Krogh A et al. A simple weight decay can improve generalization. Advances \nin neural information processing systems 1995;4:950-7. \n51. Srivastava N, Hinton G, Krizhevsky A et al. Dropout: A simple way to prevent neural networks \nfrom overfitting. The Journal of Machine Learning Research 2014;15(1):1929-58. \n52. Baldi P, Sadowski PJ. Understanding dropout. In: Advances in neural information processing \nsystems. 2013. p. 2814-22. \n53. Goodfellow IJ, Warde-Farley D, Mirza M et al. Maxout networks. arXiv preprint arXiv:1302.4389 \n2013. \n54. Moon T, Choi H, Lee H et al. RnnDrop: A Novel Dropout for RNNs in ASR. Automatic Speech \nRecognition and Understanding (ASRU) 2015. \n55. Ioffe S, Szegedy C. Batch normalization: Accelerating deep network training by reducing internal \ncovariate shift. arXiv preprint arXiv:1502.03167 2015. \n56. Deeplearning4j Development Team. Deeplearning4j: Open-source distributed deep learning for \nthe JVM. Apache Software Foundation License 2.0. http://deeplearning4j.org, 2016. \n57. Bahrampour S, Ramakrishnan N, Schott L et al. Comparative Study of Deep Learning Software \nFrameworks. arXiv preprint arXiv:1511.06435 2015. \n58. Nervana Systems. Neon. https://github.com/NervanaSystems/neon, 2016. \n59. Jia Y. Caffe: An open source convolutional architecture for fast feature embedding. In: ACM \nInternational Conference on Multimedia. ACM. 2014. \n60. Collobert R, Kavukcuoglu K, Farabet C. Torch7: A matlab-like environment for machine learning. \nIn: BigLearn, NIPS Workshop. 2011. \n61. Bergstra J, Breuleux O, Bastien F et al. Theano: a CPU and GPU math expression compiler. In: \nProceedings of the Python for scientific computing conference (SciPy). 2010. p. 3. Austin, TX. \n62. Bastien F, Lamblin P, Pascanu R et al. Theano: new features and speed improvements. arXiv \npreprint arXiv:1211.5590 2012. \n63. Chollet F. Keras: Theano-based Deep Learning library. Code: https://github. com/fchollet. \nDocumentation: http://keras. io 2015. \n64. Dieleman S, Heilman M, Kelly J et al. Lasagne: First release 2015. \n65. van Merriënboer B, Bahdanau D, Dumoulin V et al. Blocks and fuel: Frameworks for deep \nlearning. arXiv preprint arXiv:1506.00619 2015. \n66. Abadi M, Agarwal A, Barham P et al. TensorFlow: Large-Scale Machine Learning on \nHeterogeneous Distributed Systems. arXiv preprint arXiv:1603.04467 2016. \n67. Nair V, Hinton G. Rectified linear units improve restricted boltzmann machines. In: Proceedings \nof the 27th International Conference on Machine Learning (ICML-10). 2010. p. 807-14. \n68. Erhan D, Bengio Y, Courville A et al. Why does unsupervised pre-training help deep learning? \nThe Journal of Machine Learning Research 2010;11:625-60. \n69. Hubel DH, Wiesel TN. Receptive fields and functional architecture of monkey striate cortex. The \nJournal of physiology 1968;195(1):215-43. \n70. Schuster M, Paliwal KK. Bidirectional recurrent neural networks. Signal Processing, IEEE \nTransactions on 1997;45(11):2673-81. \n71. Cenic A, Nabavi DG, Craen RA et al. Dynamic CT measurement of cerebral blood flow: a \nvalidation study. American Journal of Neuroradiology 1999;20(1):63-73. \n72. Tsao J, Boesiger P, Pruessmann KP. k‐t BLAST and k‐t SENSE: Dynamic MRI with high frame rate \nexploiting spatiotemporal correlations. Magnetic Resonance in Medicine 2003;50(5):1031-42. \n73. Cohen AM, Hersh WR. A survey of current work in biomedical text mining. Briefings in \nbioinformatics 2005;6(1):57-71. \n74. Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and \ntranslate. arXiv preprint arXiv:1409.0473 2014. \n75. Xu K, Ba J, Kiros R et al. Show, attend and tell: Neural image caption generation with visual \nattention. arXiv preprint arXiv:1502.03044 2015. \n76. Cho K, Courville A, Bengio Y. Describing multimedia content using attention-based encoder-\ndecoder networks. Multimedia, IEEE Transactions on 2015;17(11):1875-86. \n77. Mnih V, Heess N, Graves A. Recurrent models of visual attention. In: Advances in neural \ninformation processing systems. 2014. p. 2204-12. \n78. Jones DT. Protein secondary structure prediction based on position-specific scoring matrices. \nJournal of molecular biology 1999;292(2):195-202. \n79. Ponomarenko JV, Ponomarenko MP, Frolov AS et al. Conformational and physicochemical DNA \nfeatures specific for transcription factor binding sites. Bioinformatics 1999;15(7):654-68. \n80. Cai Y-d, Lin SL. Support vector machines for predicting rRNA-, RNA-, and DNA-binding proteins \nfrom amino acid sequence. Biochimica et Biophysica Acta (BBA)-Proteins and Proteomics \n2003;1648(1):127-33. \n81. Atchley WR, Zhao J, Fernandes AD et al. Solving the protein sequence metric problem. \nProceedings of the National Academy of Sciences of the United States of America \n2005;102(18):6395-400. \n82. Branden CI. Introduction to protein structure. Garland Science, 1999. \n83. Richardson JS. The anatomy and taxonomy of protein structure. Advances in protein chemistry \n1981;34:167-339. \n84. Lyons J, Dehzangi A, Heffernan R et al. Predicting backbone Cα angles and dihedrals from \nprotein sequences by stacked sparse auto‐encoder deep neural network. Journal of computational \nchemistry 2014;35(28):2040-6. \n85. Heffernan R, Paliwal K, Lyons J et al. Improving prediction of secondary structure, local backbone \nangles, and solvent accessible surface area of proteins by iterative deep learning. Scientific reports \n2015;5. \n86. Spencer M, Eickholt J, Cheng J. A Deep Learning Network Approach to ab initio Protein \nSecondary Structure Prediction. Computational Biology and Bioinformatics, IEEE/ACM Transactions \non 2015;12(1):103-12. \n87. Nguyen SP, Shang Y, Xu D. DL-PRO: A novel deep learning method for protein model quality \nassessment. In: Neural Networks (IJCNN), 2014 International Joint Conference on. 2014. p. 2071-8. \nIEEE. \n88. Baldi P, Brunak S, Frasconi P et al. Exploiting the past and the future in protein secondary \nstructure prediction. Bioinformatics 1999;15(11):937-46. \n89. Baldi P, Pollastri G, Andersen CA et al. Matching protein beta-sheet partners by feedforward \nand recurrent neural networks. In: Proceedings of the 2000 Conference on Intelligent Systems for \nMolecular Biology (ISMB00), La Jolla, CA. 2000. p. 25-36. \n90. Sønderby SK, Winther O. Protein Secondary Structure Prediction with Long Short Term Memory \nNetworks. arXiv preprint arXiv:1412.7828 2014. \n91. Lena PD, Nagata K, Baldi P. Deep architectures for protein contact map prediction. Bioinformatics \n2012;28(19):2449-57. \n92. Baldi P, Pollastri G. The principled design of large-scale recursive neural network architectures-\n-dag-rnns and the protein structure prediction problem. The Journal of Machine Learning Research \n2003;4:575-602. \n93. Leung MK, Xiong HY, Lee LJ et al. Deep learning of the tissue-regulated splicing code. \nBioinformatics 2014;30(12):i121-i9. \n94. Lee T, Yoon S. Boosted Categorical Restricted Boltzmann Machine for Computational Prediction \nof Splice Junctions. In: International Conference on Machine Learning. Lille, France, 2015. p. 2483–\n92. \n95. Zhang S, Zhou J, Hu H et al. A deep learning framework for modeling structural features of \nRNA-binding protein targets. Nucleic acids research 2015:gkv1025. \n96. Chen Y, Li Y, Narayan R et al. Gene expression inference with deep learning. Bioinformatics \n2016(btw074). \n97. Li Y, Shi W, Wasserman WW. Genome-Wide Prediction of cis-Regulatory Regions Using \nSupervised Deep Learning Methods. bioRxiv 2016:041616. \n98. Liu F, Ren C, Li H et al. De novo identification of replication-timing domains in the human \ngenome by deep learning. Bioinformatics 2015:btv643. \n99. Denas O, Taylor J. Deep modeling of gene expression regulation in an Erythropoiesis model. In: \nInternational Conference on Machine Learning workshop on Representation Learning. Atlanta, \nGeorgia, USA, 2013. \n100. Alipanahi B, Delong A, Weirauch MT et al. Predicting the sequence specificities of DNA-and \nRNA-binding proteins by deep learning. Nature biotechnology 2015. \n101. Lanchantin J, Singh R, Lin Z et al. Deep motif: Visualizing genomic sequence classifications. arXiv \npreprint arXiv:1605.01133 2016. \n102. Zeng H, Edwards MD, Liu G et al. Convolutional neural network architectures for predicting \nDNA–protein binding. Bioinformatics 2016;32(12):i121-i7. \n103. Kelley DR, Snoek J, Rinn J. Basset: Learning the regulatory code of the accessible genome with \ndeep convolutional neural networks. bioRxiv 2015:028399. \n104. Zhou J, Troyanskaya OG. Predicting effects of noncoding variants with deep learning-based \nsequence model. Nature methods 2015;12(10):931-4. \n105. Park S, Min S, Choi H-s et al. deepMiRGene: Deep Neural Network based Precursor microRNA \nPrediction. arXiv preprint arXiv:1605.00017 2016. \n106. Lee B, Lee T, Na B et al. DNA-Level Splice Junction Prediction using Deep Recurrent Neural \nNetworks. arXiv preprint arXiv:1512.05135 2015. \n107. Lee B, Baek J, Park S et al. deepTarget: End-to-end Learning Framework for microRNA Target \nPrediction using Deep Recurrent Neural Networks. arXiv preprint arXiv:1603.09123 2016. \n108. Asgari E, Mofrad MR. Continuous Distributed Representation of Biological Sequences for Deep \nProteomics and Genomics. PloS one 2015;10(11):e0141287. \n109. Hochreiter S, Heusel M, Obermayer K. Fast model-based protein homology detection without \nalignment. Bioinformatics 2007;23(14):1728-36. \n110. Sønderby SK, Sønderby CK, Nielsen H et al. Convolutional LSTM Networks for Subcellular \nLocalization of Proteins. arXiv preprint arXiv:1503.01919 2015. \n111. Fakoor R, Ladhak F, Nazi A et al. Using deep learning to enhance cancer diagnosis and \nclassification. In: Proceedings of the International Conference on Machine Learning. 2013. \n112. Nilsen TW, Graveley BR. Expansion of the eukaryotic proteome by alternative splicing. Nature \n2010;463(7280):457-63. \n113. Jolliffe I. Principal component analysis. Wiley Online Library, 2002. \n114. Park Y, Kellis M. Deep learning for regulatory genomics. Nature biotechnology 2015;33(8):825-\n6. \n115. Najarian K, Splinter R. Biomedical signal and image processing. CRC press, 2005. \n116. Edelman RR, Warach S. Magnetic resonance imaging. New England Journal of Medicine \n1993;328(10):708-16. \n117. Ogawa S, Lee T-M, Kay AR et al. Brain magnetic resonance imaging with contrast dependent \non blood oxygenation. Proceedings of the National Academy of Sciences 1990;87(24):9868-72. \n118. Hsieh J. Computed tomography: principles, design, artifacts, and recent advances. SPIE \nBellingham, WA, 2009. \n119. Chapman D, Thomlinson W, Johnston R et al. Diffraction enhanced x-ray imaging. Physics in \nmedicine and biology 1997;42(11):2015. \n120. Bailey DL, Townsend DW, Valk PE et al. Positron emission tomography. Springer, 2005. \n121. Gurcan MN, Boucheron LE, Can A et al. Histopathological image analysis: a review. Biomedical \nEngineering, IEEE Reviews in 2009;2:147-71. \n122. Plis SM, Hjelm DR, Salakhutdinov R et al. Deep learning for neuroimaging: a validation study. \nFrontiers in neuroscience 2014;8. \n123. Hua K-L, Hsu C-H, Hidayati SC et al. Computer-aided classification of lung nodules on computed \ntomography images via deep learning technique. OncoTargets and therapy 2015;8. \n124. Suk H-I, Shen D. Deep learning-based feature representation for AD/MCI classification.  Medical \nImage Computing and Computer-Assisted Intervention–MICCAI 2013. Springer, 2013, 583-90. \n125. Roth HR, Lu L, Liu J et al. Improving Computer-aided Detection using Convolutional Neural \nNetworks and Random View Aggregation. arXiv preprint arXiv:1505.03046 2015. \n126. Roth HR, Yao J, Lu L et al. Detection of sclerotic spine metastases via random aggregation of \ndeep convolutional neural network classifications.  Recent Advances in Computational Methods and \nClinical Applications for Spine Imaging. Springer, 2015, 3-12. \n127. Li Q, Cai W, Wang X et al. Medical image classification with convolutional neural network. In: \nControl Automation Robotics & Vision (ICARCV), 2014 13th International Conference on. 2014. p. \n844-8. IEEE. \n128. Cireşan DC, Giusti A, Gambardella LM et al. Mitosis detection in breast cancer histology images \nwith deep neural networks.  Medical Image Computing and Computer-Assisted Intervention–\nMICCAI 2013. Springer, 2013, 411-8. \n129. Ypsilantis P-P, Siddique M, Sohn H-M et al. Predicting Response to Neoadjuvant Chemotherapy \nwith PET Imaging Using Convolutional Neural Networks. PloS one 2015;10(9):e0137036. \n130. Zeng T, Li R, Mukkamala R et al. Deep convolutional neural networks for annotating gene \nexpression patterns in the mouse brain. BMC bioinformatics 2015;16(1):1-10. \n131. Cruz-Roa AA, Ovalle JEA, Madabhushi A et al. A deep learning architecture for image \nrepresentation, visual interpretability and automated basal-cell carcinoma cancer detection.  \nMedical Image Computing and Computer-Assisted Intervention–MICCAI 2013. Springer, 2013, 403-\n10. \n132. Bar Y, Diamant I, Wolf L et al. Deep learning with non-medical training used for chest pathology \nidentification. In: SPIE Medical Imaging. 2015. p. 94140V-V-7. International Society for Optics and \nPhotonics. \n133. Li Q, Feng B, Xie L et al. A Cross-modality Learning Approach for Vessel Segmentation in Retinal \nImages. IEEE Transactions on Medical Imaging 2015;35(1):109 - 8. \n134. Ning F, Delhomme D, LeCun Y et al. Toward automatic phenotyping of developing embryos \nfrom videos. Image Processing, IEEE Transactions on 2005;14(9):1360-71. \n135. Turaga SC, Murray JF, Jain V et al. Convolutional networks can learn to generate affinity graphs \nfor image segmentation. Neural Computation 2010;22(2):511-38. \n136. Helmstaedter M, Briggman KL, Turaga SC et al. Connectomic reconstruction of the inner \nplexiform layer in the mouse retina. Nature 2013;500(7461):168-74. \n137. Ciresan D, Giusti A, Gambardella LM et al. Deep neural networks segment neuronal membranes \nin electron microscopy images. In: Advances in neural information processing systems. 2012. p. \n2843-51. \n138. Prasoon A, Petersen K, Igel C et al. Deep feature learning for knee cartilage segmentation using \na triplanar convolutional neural network.  Medical Image Computing and Computer-Assisted \nIntervention–MICCAI 2013. Springer, 2013, 246-53. \n139. Havaei M, Davy A, Warde-Farley D et al. Brain Tumor Segmentation with Deep Neural Networks. \narXiv preprint arXiv:1505.03540 2015. \n140. Roth HR, Lu L, Farag A et al. Deeporgan: Multi-level deep convolutional networks for automated \npancreas segmentation.  Medical Image Computing and Computer-Assisted Intervention–MICCAI \n2015. Springer, 2015, 556-64. \n141. Stollenga MF, Byeon W, Liwicki M et al. Parallel Multi-Dimensional LSTM, With Application to \nFast Biomedical Volumetric Image Segmentation. arXiv preprint arXiv:1506.07452 2015. \n142. Xu J, Xiang L, Liu Q et al. Stacked Sparse Autoencoder (SSAE) for Nuclei Detection on Breast \nCancer Histopathology images. IEEE Transactions on Medical Imaging 2015;35(1):119 - 30. \n143. Chen CL, Mahjoubfar A, Tai L-C et al. Deep Learning in Label-free Cell Classification. Scientific \nreports 2016;6. \n144. Cho J, Lee K, Shin E et al. Medical Image Deep Learning with Hospital PACS Dataset. arXiv \npreprint arXiv:1511.06348 2015. \n145. Lee S, Choi M, Choi H-s et al. FingerNet: Deep learning-based robust finger joint detection \nfrom radiographs. In: Biomedical Circuits and Systems Conference (BioCAS), 2015 IEEE. 2015. p. 1-4. \nIEEE. \n146. Roth HR, Lee CT, Shin H-C et al. Anatomy-specific classification of medical images using deep \nconvolutional nets. arXiv preprint arXiv:1504.04003 2015. \n147. Roth HR, Lu L, Seff A et al. A new 2.5 D representation for lymph node detection using random \nsets of deep convolutional neural network observations.  Medical Image Computing and Computer-\nAssisted Intervention–MICCAI 2014. Springer, 2014, 520-7. \n148. Kraus OZ, Frey BJ. Computer vision for high content screening. Critical reviews in biochemistry \nand molecular biology 2016;51(2):102-9. \n149. Gerven MAV, De Lange FP, Heskes T. Neural decoding with hierarchical generative models. \nNeural Computation 2010;22(12):3127-42. \n150. Koyamada S, Shikauchi Y, Nakae K et al. Deep learning of fMRI big data: a novel approach to \nsubject-transfer decoding. arXiv preprint arXiv:1502.00093 2015. \n151. Duryea J, Jiang Y, Countryman P et al. Automated algorithm for the identification of joint space \nand phalanx margin locations on digitized hand radiographs. Medical Physics 1999;26(3):453-61. \n152. Niedermeyer E, da Silva FL. Electroencephalography: basic principles, clinical applications, and \nrelated fields. Lippincott Williams & Wilkins, 2005. \n153. Buzsáki G, Anastassiou CA, Koch C. The origin of extracellular fields and currents—EEG, ECoG, \nLFP and spikes. Nature reviews neuroscience 2012;13(6):407-20. \n154. Marriott HJL, Wagner GS. Practical electrocardiography. Williams & Wilkins Baltimore, 1988. \n155. De Luca CJ. The use of surface electromyography in biomechanics. Journal of applied \nbiomechanics 1997;13:135-63. \n156. Young LR, Sheena D. Eye-movement measurement techniques. American Psychologist \n1975;30(3):315. \n157. Barea R, Boquete L, Mazo M et al. System for assisted mobility using eye movements based on \nelectrooculography. Neural Systems and Rehabilitation Engineering, IEEE Transactions on \n2002;10(4):209-18. \n158. Freudenburg ZV, Ramsey NF, Wronkeiwicz M et al. Real-time naive learning of neural correlates \nin ECoG Electrophysiology. Int. Journal of Machine Learning and Computing 2011. \n159. An X, Kuang D, Guo X et al. A Deep Learning Method for Classification of EEG Data Based on \nMotor Imagery.  Intelligent Computing in Bioinformatics. Springer, 2014, 203-10. \n160. Li K, Li X, Zhang Y et al. Affective state recognition from EEG with deep belief networks. In: \nBioinformatics and Biomedicine (BIBM), 2013 IEEE International Conference on. 2013. p. 305-10. IEEE. \n161. Jia X, Li K, Li X et al. A Novel Semi-Supervised Deep Learning Framework for Affective State \nRecognition on EEG Signals. In: Bioinformatics and Bioengineering (BIBE), 2014 IEEE International \nConference on. 2014. p. 30-7. IEEE. \n162. Zheng W-L, Guo H-T, Lu B-L. Revealing critical channels and frequency bands for emotion \nrecognition from EEG with deep belief network. In: Neural Engineering (NER), 2015 7th International \nIEEE/EMBS Conference on. 2015. p. 154-7. IEEE. \n163. Jirayucharoensak S, Pan-Ngum S, Israsena P. EEG-based emotion recognition using deep \nlearning network with principal component based covariate shift adaptation. The Scientific World \nJournal 2014;2014. \n164. Stober S, Cameron DJ, Grahn JA. Classifying EEG recordings of rhythm perception. In: 15th \nInternational Society for Music Information Retrieval Conference (ISMIR’14). 2014. p. 649-54. \n165. Stober S, Cameron DJ, Grahn JA. Using Convolutional Neural Networks to Recognize Rhythm. \nIn: Advances in neural information processing systems. 2014. p. 1449-57. \n166. Cecotti H, Graeser A. Convolutional neural network with embedded Fourier transform for EEG \nclassification. In: Pattern Recognition, 2008. ICPR 2008. 19th International Conference on. 2008. p. \n1-4. IEEE. \n167. Cecotti H, Gräser A. Convolutional neural networks for P300 detection with application to brain-\ncomputer interfaces. Pattern Analysis and Machine Intelligence, IEEE Transactions on 2011;33(3):433-\n45. \n168. Soleymani M, Asghari-Esfeden S, Pantic M et al. Continuous emotion detection using EEG \nsignals and facial expressions. In: Multimedia and Expo (ICME), 2014 IEEE International Conference \non. 2014. p. 1-6. IEEE. \n169. Wang Z, Lyu S, Schalk G et al. Deep feature learning using target priors with applications in \nECoG signal decoding for BCI. In: Proceedings of the Twenty-Third international joint conference on \nArtificial Intelligence. 2013. p. 1785-91. AAAI Press. \n170. Stober S, Sternin A, Owen AM et al. Deep Feature Learning for EEG Recordings. arXiv preprint \narXiv:1511.04306 2015. \n171. Huanhuan M, Yue Z. Classification of Electrocardiogram Signals with Deep Belief Networks. In: \nComputational Science and Engineering (CSE), 2014 IEEE 17th International Conference on. 2014. p. \n7-12. IEEE. \n172. Wulsin D, Gupta J, Mani R et al. Modeling electroencephalography waveforms with semi-\nsupervised deep belief nets: fast classification and anomaly measurement. Journal of neural \nengineering 2011;8(3):036015. \n173. Turner J, Page A, Mohsenin T et al. Deep belief networks used on high resolution multichannel \nelectroencephalography data for seizure detection. In: 2014 AAAI Spring Symposium Series. 2014. \n174. Zhao Y, He L. Deep Learning in the EEG Diagnosis of Alzheimer’s Disease. In: Computer Vision-\nACCV 2014 Workshops. 2014. p. 340-53. Springer. \n175. Längkvist M, Karlsson L, Loutfi A. Sleep stage classification using unsupervised feature learning. \nAdvances in Artificial Neural Systems 2012;2012:5. \n176. Mirowski P, Madhavan D, LeCun Y et al. Classification of patterns of EEG synchronization for \nseizure prediction. Clinical neurophysiology 2009;120(11):1927-40. \n177. Petrosian A, Prokhorov D, Homan R et al. Recurrent neural network based prediction of epileptic \nseizures in intra-and extracranial EEG. Neurocomputing 2000;30(1):201-18. \n178. Davidson PR, Jones RD, Peiris MT. EEG-based lapse detection with high temporal resolution. \nBiomedical Engineering, IEEE Transactions on 2007;54(5):832-9. \n179. Oh S, Lee MS, Zhang B-T. Ensemble learning with active example selection for imbalanced \nbiomedical data classification. IEEE/ACM Transactions on Computational Biology and Bioinformatics \n(TCBB) 2011;8(2):316-25. \n180. Malin BA, El Emam K, O'Keefe CM. Biomedical data privacy: problems, perspectives, and recent \nadvances. Journal of the American medical informatics association 2013;20(1):2-6. \n181. He H, Garcia EA. Learning from imbalanced data. Knowledge and Data Engineering, IEEE \nTransactions on 2009;21(9):1263-84. \n182. Davis J, Goadrich M. The relationship between Precision-Recall and ROC curves. In: Proceedings \nof the 23rd international conference on Machine learning. 2006. p. 233-40. ACM. \n183. López V, Fernández A, García S et al. An insight into classification with imbalanced data: \nEmpirical results and current trends on using data intrinsic characteristics. Information Sciences \n2013;250:113-41. \n184. Liu X-Y, Wu J, Zhou Z-H. Exploratory undersampling for class-imbalance learning. Systems, Man, \nand Cybernetics, Part B: Cybernetics, IEEE Transactions on 2009;39(2):539-50. \n185. Chawla NV, Bowyer KW, Hall LO et al. SMOTE: synthetic minority over-sampling technique. \nJournal of artificial intelligence research 2002:321-57. \n186. Jo T, Japkowicz N. Class imbalances versus small disjuncts. ACM Sigkdd Explorations Newsletter \n2004;6(1):40-9. \n187. Kukar M, Kononenko I. Cost-Sensitive Learning with Neural Networks. In: ECAI. 1998. p. 445-9. \nCiteseer. \n188. Pan SJ, Yang Q. A survey on transfer learning. Knowledge and Data Engineering, IEEE \nTransactions on 2010;22(10):1345-59. \n189. Deng J, Dong W, Socher R et al. Imagenet: A large-scale hierarchical image database. In: \nComputer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. 2009. p. 248-55. \nIEEE. \n190. Zeiler MD, Fergus R. Visualizing and understanding convolutional networks.  Computer Vision–\nECCV 2014. Springer, 2014, 818-33. \n191. Erhan D, Bengio Y, Courville A et al. Visualizing higher-layer features of a deep network. \nUniversity of Montreal 2009;1341. \n192. Simonyan K, Vedaldi A, Zisserman A. Deep inside convolutional networks: Visualising image \nclassification models and saliency maps. arXiv preprint arXiv:1312.6034 2013. \n193. Choromanska A, Henaff M, Mathieu M et al. The loss surfaces of multilayer networks. arXiv \npreprint arXiv:1412.0233 2014. \n194. Dauphin YN, Pascanu R, Gulcehre C et al. Identifying and attacking the saddle point problem \nin high-dimensional non-convex optimization. In: Advances in neural information processing \nsystems. 2014. p. 2933-41. \n195. Bengio Y. Practical recommendations for gradient-based training of deep architectures.  Neural \nNetworks: Tricks of the Trade. Springer, 2012, 437-78. \n196. Bergstra J, Bardenet R, Bengio Y et al. Algorithms for hyper-parameter optimization. In: Advances \nin neural information processing systems. 2011. p. 2546-54. \n197. Hutter F, Hoos HH, Leyton-Brown K. Sequential model-based optimization for general algorithm \nconfiguration.  Learning and Intelligent Optimization. Springer, 2011, 507-23. \n198. Snoek J, Larochelle H, Adams RP. Practical bayesian optimization of machine learning algorithms. \nIn: Advances in neural information processing systems. 2012. p. 2951-9. \n199. Bergstra J, Bengio Y. Random search for hyper-parameter optimization. The Journal of Machine \nLearning Research 2012;13(1):281-305. \n200. Ngiam J, Khosla A, Kim M et al. Multimodal deep learning. In: Proceedings of the 28th \ninternational conference on machine learning (ICML-11). 2011. p. 689-96. \n201. Cao Y, Steffey S, He J et al. Medical Image Retrieval: A Multimodal Approach. Cancer informatics \n2014;13(Suppl 3):125. \n202. Ngiam J, Coates A, Lahiri A et al. On optimization methods for deep learning. In: Proceedings \nof the 28th International Conference on Machine Learning (ICML-11). 2011. p. 265-72. \n203. Martens J. Deep learning via Hessian-free optimization. In: Proceedings of the 27th International \nConference on Machine Learning (ICML-10). 2010. p. 735-42. \n204. Raina R, Madhavan A, Ng AY. Large-scale deep unsupervised learning using graphics processors. \nIn: Proceedings of the 26th annual international conference on machine learning. 2009. p. 873-80. \nACM. \n205. Ho Q, Cipar J, Cui H et al. More effective distributed ml via a stale synchronous parallel \nparameter server. In: Advances in neural information processing systems. 2013. p. 1223-31. \n206. Bengio Y, Schwenk H, Senécal J-S et al. Neural probabilistic language models.  Innovations in \nMachine Learning. Springer, 2006, 137-86. \n207. Li M, Andersen DG, Park JW et al. Scaling distributed machine learning with the parameter \nserver. In: 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 14). \n2014. p. 583-98. \n208. Dean J, Corrado G, Monga R et al. Large scale distributed deep networks. In: Advances in neural \ninformation processing systems. 2012. p. 1223-31. \n209. Kin H, Park J, Jang J et al. DeepSpark: Spark-Based Deep Learning Supporting Asynchronous \nUpdates and Caffe Compatibility. arXiv preprint arXiv:1602.08191 2016. \n210. Abadi M, Agarwal A, Barham P et al. TensorFlow: Large-scale machine learning on \nheterogeneous systems, 2015. Software available from tensorflow. org 2015. \n211. Simonite T. Thinking in Silicon. MIT Technology Review, 2013. \n212. Ovtcharov K, Ruwase O, Kim J-Y et al. Accelerating deep convolutional neural networks using \nspecialized hardware. Microsoft Research Whitepaper 2015;2. \n213. Farabet C, Poulet C, Han JY et al. Cnp: An fpga-based processor for convolutional networks. In: \nField Programmable Logic and Applications, 2009. FPL 2009. International Conference on. 2009. p. \n32-7. IEEE. \n214. Hof RD. Neuromorphic Chips. MIT Technology Review, 2014. \n215. Yao L, Torabi A, Cho K et al. Describing videos by exploiting temporal structure. In: Proceedings \nof the IEEE International Conference on Computer Vision. 2015. p. 4507-15. \n216. Noh H, Seo PH, Han B. Image Question Answering using Convolutional Neural Network with \nDynamic Parameter Prediction. arXiv preprint arXiv:1511.05756 2015. \n217. Graves A, Wayne G, Danihelka I. Neural turing machines. arXiv preprint arXiv:1410.5401 2014. \n218. Weston J, Chopra S, Bordes A. Memory networks. arXiv preprint arXiv:1410.3916 2014. \n219. Szegedy C, Zaremba W, Sutskever I et al. Intriguing properties of neural networks. arXiv preprint \narXiv:1312.6199 2013. \n220. Goodfellow IJ, Shlens J, Szegedy C. Explaining and harnessing adversarial examples. arXiv \npreprint arXiv:1412.6572 2014. \n221. Goodfellow I, Pouget-Abadie J, Mirza M et al. Generative adversarial nets. In: Advances in neural \ninformation processing systems. 2014. p. 2672-80. \n222. Lee T, Choi M, Yoon S. Manifold Regularized Deep Neural Networks using Adversarial Examples. \narXiv preprint arXiv:1511.06381 2015. \n223. Rasmus A, Berglund M, Honkala M et al. Semi-Supervised Learning with Ladder Networks. In: \nAdvances in neural information processing systems. 2015. p. 3532-40. \n224. Arel I. Deep Reinforcement Learning as Foundation for Artificial General Intelligence.  \nTheoretical Foundations of Artificial General Intelligence. Springer, 2012, 89-102. \n225. Cutler M, How JP. Efficient reinforcement learning for robots using informative simulated priors. \nIn: Robotics and Automation (ICRA), 2015 IEEE International Conference on. 2015. p. 2605-12. IEEE. \n \n",
  "categories": [
    "cs.LG",
    "q-bio.GN"
  ],
  "published": "2016-03-21",
  "updated": "2016-06-19"
}