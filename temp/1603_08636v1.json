{
  "id": "http://arxiv.org/abs/1603.08636v1",
  "title": "Towards an Automated Requirements-driven Development of Smart Cyber-Physical Systems",
  "authors": [
    "Jiri Vinarek",
    "Petr Hnetynka"
  ],
  "abstract": "The Invariant Refinement Method for Self Adaptation (IRM-SA) is a design\nmethod targeting development of smart Cyber-Physical Systems (sCPS). It allows\nfor a systematic translation of the system requirements into the system\narchitecture expressed as an ensemble-based component system (EBCS). However,\nsince the requirements are captured using natural language, there exists the\ndanger of their misinterpretation due to natural language requirements'\nambiguity, which could eventually lead to design errors. Thus, automation and\nvalidation of the design process is desirable. In this paper, we (i) analyze\nthe translation process of natural language requirements into the IRM-SA model,\n(ii) identify individual steps that can be automated and/or validated using\nnatural language processing techniques, and (iii) propose suitable methods.",
  "text": "J. Kofroˇn, J. Tumova, B. Buhnova (Eds.): Formal Engineering\nApproaches to Software Components and Architectures (FESCA’16)\nEPTCS 205, 2016, pp. 59–68, doi:10.4204/EPTCS.205.5\nc⃝J. Vinarek, P. Hnetynka\nThis work is licensed under the\nCreative Commons Attribution License.\nTowards an Automated Requirements-driven Development of\nSmart Cyber-Physical Systems\nPosition paper\nJiri Vinarek\nPetr Hnetynka\nCharles University in Prague, Faculty of Mathematics and Physics,\nDepartment of Distributed and Dependable Systems,\nMalostranske namesti 25, Prague, Czech Republic\nvinarek@d3s.mff.cuni.cz\nhnetynka@d3s.mff.cuni.cz\nThe Invariant Reﬁnement Method for Self Adaptation (IRM-SA) is a design method targeting de-\nvelopment of smart Cyber-Physical Systems (sCPS). It allows for a systematic translation of the\nsystem requirements into the system architecture expressed as an ensemble-based component sys-\ntem (EBCS). However, since the requirements are captured using natural language, there exists the\ndanger of their misinterpretation due to natural language requirements’ ambiguity, which could even-\ntually lead to design errors. Thus, automation and validation of the design process is desirable. In\nthis paper, we (i) analyze the translation process of natural language requirements into the IRM-SA\nmodel, (ii) identify individual steps that can be automated and/or validated using natural language\nprocessing techniques, and (iii) propose suitable methods.\n1\nIntroduction\nSmart Cyber-Physical Systems (sCPS) are complex distributed decentralized systems of cooperating\nmobile and stationary devices closely interacting with the physical environment. Examples of sCPS\ninclude systems like smart home, smart trafﬁc management, etc.\nDesigning and developing such a system is a quite complex task with many challenges. Mobility\nand distribution bring the high level of dynamism to the system, which has to be aware of changes in\nits environment. Openness and open-endness are other challenging issues resulting in needs that the\ndesigned system has to be able to tackle unanticipated changes and participants unknown at design time.\nThe traditional software design and development techniques have been shown unsuitable for such\nsystems and novel approaches [8, 13, 14] have been proposed to tackle with the challenges. One of these\npromising approaches is Ensemble-Based Component Systems (EBCS) [1]. Using EBCS, the system is\nmodeled and developed as a set of ensembles, i.e., dynamic cooperation groups of software components.\nComponents are speciﬁed by their knowledge (i.e., component’s attributes) and by a set of processes\nmanipulating the knowledge.\nThe Invariant Reﬁnement Method for Self Adaptation (IRM-SA) [2] is a design method targeting de-\nvelopment of sCPS using EBCS. IRM-SA allows for a systematic translation of the system requirements\nwritten in natural language into the system architecture expressed as components and ensembles. Using\nIRM-SA, a designer gradually reﬁnes the initial requirements and iteratively builds a model that con-\nsists of so-called invariants. Invariants are then hierarchically decomposed and at the lowest level, they\ndirectly correspond to an implementation (in the DEECo component model [1], with which IRM-SA is\ncurrently tied).\n60\nTowards an Automated Requirements-driven Development of sCPS\nTo speedup and ease the design process with IRM-SA, the guide 1 and graphical editor 2 have been\ncreated. The editor allows for editing of the constraints and performing several basic validations of the\ndesigned IRM-SA model. Additionally, skeletons of the implementation can be generated directly from\nthe designed model. Even though the guide and editor exist, the whole process, i.e., translation of re-\nquirements into the IRM-SA model, is manual and it can be time-consuming and laborious. Additionally,\nas the requirements are expressed as a text in natural language, there is a danger of ambiguity and misin-\nterpretation of them, which can result in a suboptimal design. Even more, designers can unintentionally\nmiss important requirements.\nThe goal of this paper is to analyze the IRM-SA design process and identify particular steps, which\ncan be, fully or at least partially, automated with the help of natural language processing tools. To achieve\nthe goal, we use our experience gained with automated processing of textual use-cases, their veriﬁcation\nand transformation into an implementation ([15, 16, 18]).\nThe paper is structured as follows: Section 2 explains the IRM-SA method and its inputs and outputs.\nSection 3 discusses steps of the IRM-SA method from the perspective of their automation and proposes\nsolutions for them. Finally, Section 4 discusses related work while Section 5 concludes the paper.\n2\nIRM-SA explained by example\nIn this section, we brieﬂy describe the IRM-SA method and its usage on an example (for a detailed\ndescription, please see the IRM-SA guide).\nThe experiment described in [6] proved that usage of IRM-SA represents a signiﬁcant help in EBCS\ndesign and development. Participants of this experiment designed using IRM-SA an EBCS architecture\nwith less errors than participants using another design method. Even though, the resulting architectures\nwere not completely without errors, especially thank to different understanding of the input requirements\nprovided as a text in natural language and thus, there is still space for improvements.\nThis is even more important, as one of the outputs of the IRM-SA method – the IRM-SA model – can\nbe used not only at design time, but also during development and maintenance of the developed system.\nIn particular, the IRM-SA model allows for traceability between purpose of each invariant (requirement)\nand its realization and therefore it is ideal for documentation and maintenance. Plus, as stated in [10],\nit is a mistake to understand requirements speciﬁcations as ﬁnal and unchangeable and thus keeping\nup-to-date traceability links to requirements is quite important.\nAdditionally, the IRM-SA model is in the DEECo implementation employed for controlling self-\nadaptation of the system, i.e., the model captures multiple alternatives of the system architecture and the\nappropriate one is chosen based on actual situation.\nTo sum up, the IRM-SA model is one of the key artifacts of the developed system and its correctness\nis essential. Therefore, designers/developers would beneﬁt from a tool which not only allows for easy\ncreation of the model (the currently available editor allows for this) but also which would be able to\n(semi)automatically parse the textual requirements, generate parts of the model from the requirements,\nand validate individual actions performed by the designer/developer. To provide such a tool, natural\nlanguage processing methods and tools have to be incorporated in the process.\n1http://svn.pst.ifi.lmu.de/ascens/guide/irm/\n2https://github.com/d3scomp/IRM-SA\nJ. Vinarek, P. Hnetynka\n61\n2.1\nIRM-SA method and model\nThe IRM-SA design method is an iterative top-down design approach. A designer has to perform the\nfollowing steps in order to built the IRM-SA model from the requirement speciﬁcation:\n1. Find the top-level goals of the system and specify the top-level (abstract) invariants.\n2. Find the components of the system (and their ﬁelds) by asking “which knowledge does each in-\nvariant involve and where is this knowledge obtained from?”\n3. Decompose each invariant by asking “how can this invariant be satisﬁed?”\n4. Separate the concerns of the abstract invariants into sub-invariants that correspond to (abstract)\nactivities that can be done in isolation.\n5. Compose invariants together by asking “why do I need to satisfy these invariants?”\n6. In case of situation-speciﬁc requirements, try ﬁrst to accurately capture the condition of being in\none situation or another. Use the assumptions to do that. Then use OR decomposition to specify\nwhich invariants to satisfy in each situation.\n+ id\n+availability\nParking\n+ id\n+ POI\n+position\n+plan\n+planFeasibility\n+energy\n+availabilityMap\nE-car\nINV-13 Distance of e-car \nfrom POI > 5km\nINV-2 Up-to-date V::plan is available\nINV-5 V::planFeasibility is checked\nINV-9 V::energy is monitored \nwithin 60 secs\nP\nTakes-role\nrelation\nInvariant\nProcess \ninvariant\nExchange \ninvariant\nAssumption\nAND\ndecomposition\nComponent\n \n \nP\nX\nINV-6 Up-to-date V::plan \nw.r.t. P::availability and \nV::planFeasibility is available\nINV-7 V::position is determined \nwithin 60 secs\nINV-8 V::planFeasibility w.r.t. V::energy,\nV::position, V::POI is determined\nwithin 60 secs\nP\nP\nOR\ndecomposition\nINV-12 V::availabilityMap of \nparking lots within a 100m distance \nfrom POI is up-to-date within 60 \nsecs\nX\nINV-11 Up-to-date V::plan \nw.r.t. V:availabilityMap and \nV::planFeasibility is available \nwithin 60 secs\nP\nINV-16 Distance of e-car \nfrom POI <= 5km\nINV-15 V::availabilityMap of \nparking lots within a 100m distance \nfrom POI is up-to-date within 10 \nsecs\nX\nINV-14 Up-to-date V::plan \nw.r.t. V:availabilityMap and \nV::planFeasibility is available \nwithin 10 secs\nP\nINV-10 P::availability is \nmonitored within 10 secs\nP\nFigure 1: IRM-SA model for e-cars system\nFigure 1 shows the IRM-SA model created for the electric car (e-car) navigation and parking system\nexample; its requirement speciﬁcation is in Figure 2. Both the speciﬁcation and model are overtaken\n62\nTowards an Automated Requirements-driven Development of sCPS\nfrom the IRM-SA guide (and they were also employed in the experiment mentioned above). The model\nwas created manually with the help of the IRM-SA model editor.\nThe highlighting and underlining in the requirements speciﬁcation is included solely for the purpose\nof this paper and would not appear in an actual speciﬁcation. Meaning of the highlighting/underlining is\nas follows:\n• Underlined text refers to components and their attributes (double line for components, single line\nfor attributes). Red color is used for the “E-car” component, blue one for the “Parking” component)\n• Highlighted text is related to a particular invariant; colors correspond with colors in ﬁgure 1.\n• Purple numbers in the requirements speciﬁcation refer to corresponding invariants in the model.\nElectric Car Navigation and Parking (ECNP)\nSummary:\nThe main objective of this system is to allow e-cars to coordinate with parking stations and have an adequately up-to-date view of the\navailability of parking spaces at each time point. At the same time, e-cars should monitor their battery level and choose a different\ntrip plan (e.g., which involves picking a parking place which is closer to the e-car) if the existing plan is not possible to follow any more.\nRequirements:\nThe general requirements for the ECNP are:\n1. Every e-car has to arrive to its place of interest (POI) and park within a radius of 100 meters. [2] In order to do that, every\ncar\nneeds to :\n(a) Continuously monitor its energy level (battery) ;[9]\n(b) Continuously monitor its position) ;[7]\n(c) Continuously\nassess whether its energy level would be enough to complete the trip based on the distance left to cover;\n[8]\n(d) Have a plan to follow, which is based on its energy level and on the available parking slots in the parking places near the\nPOI .[11, 14]\n2. Every parking place has to continuously monitor its availability level (e.g., in terms of available parking slots per time slot .[10]\n3. The information regarding the availability of the parking slots has to be exchanged with the appropriate e-cars .[12, 15]\nThe situation-speciﬁc requirements of the ECNP are:\n4. When an e-car is more than 5km far from the POI [16], it should update its plan at least once per 60 seconds .[14]\n5. When an e-car is equal to or less than 5km far from the POI [13], it should update its plan at least every 10 seconds [11].\nFigure 2: e-cars system requirements\n3\nAutomation of IRM-SA\nIn this section, we analyze the IRM-SA method from the perspective of its automation. We identify in-\ndividual steps that can be automated using natural language processing techniques, and propose suitable\nmethods.\nThe individual goals of such an automation are: (i) (semi)automatically generate invariants in the\nIRM-SA model from the requirements document (and thus make synchronization and traceability be-\ntween the requirements and IRM-SA model more robust and faster to obtain), (ii) (semi)automatically\nvalidate the resulting IRM-SA model.\nJ. Vinarek, P. Hnetynka\n63\n3.1\nComponent identiﬁcation\nComponents in EBCS design represent “smart” entities of the system. In our example, there are two\ntypes of components – E-Car and Parking. Both components and also their attributes are several times\nmentioned in the requirements as well as in the summary. Based on our experience with derivation of the\ndomain model from textual speciﬁcation [17], it seems possible to obtain a list of potential components\nin an automated fashion. Also, a similar approach is employed in [5], where authors retrieve UML class\nmodels from test cases.\nBoth names of the components and their attributes are in the requirement texts almost always repre-\nsented as noun phrases, which in simple sentences appear as subjects or objects (either direct or indirect).\nTo parse a sentence and identify its elements, the Stanford CoreNLP toolkit [11] is an ideal tool. For\nexample, with the usage of the Stanford dependency parser on the sentence ”Every car needs to contin-\nuously monitor its energy level (battery).”, we get the dependency graph showed in Figure 3. The parser\nreturns a part-of-speech (POS) tag for each word (e.g., VB for verb in base form, NN for singular noun)\nand dependency relations between the words (e.g., nsubj for nominal subject or dobj for direct object).\nThe resulting list of potential names of components and attributes contains car (nominal subject) and\nenergy level (direct object). Unfortunately, this might not be sufﬁcient (not all of the subjects/objects\nare components/attributes). A possible way to overcome this issue is to employ statistical classiﬁcation\ntechniques to learn the patterns from training data. Similarly, we have employed these techniques in [18].\nEvery/DT\ncar/NN\nneeds/VBZ\nto/TO\nmonitor/VB\ncontinuously/RB\nlevel/NN\nenergy/NN\nits/PRP$\ndet\nnsubj\nxcomp\nmark\nadvmod\ndobj\nnmod:poss\ncompound\nbattery/NN\nappos\nFigure 3: Dependencies and POS tags obtained from Stanford dependency parser\n3.2\nComponent disambiguation\nAnother issue with the list of candidates for component/attribute names is that it may be ambiguous.\nMultiple noun phrases may refer to the same component, e.g., in our e-cars system speciﬁcation the\nwords “e-car” and “car” refer to the same component. Similarly, “parking station” and “parking place”\nor “energy level” and “battery”. These ambiguities can be a sign of a poorly written speciﬁcation and\ntheir replacement with the same word or phrase is advisable. On the other hand, such a situation may\nhappen (especially if the speciﬁcation is prepared by multiple authors and/or it evolves over time) and\neven more, in some cases, the use of different words for the same entity may be intentional, e.g., in a case\nof abbreviations and noun phrase shortenings (“place of interest” and “POI” or “trip plan” and “plan”,\netc.).\nA distinction of these cases is not always clear and we expect that user will have to be involved in a\ndecision about these ambiguities.\nFor example, the requirement in Figure 3 is written in a way which suggest that the phrase “energy\nlevel” and “battery” can be used interchangeably. This relation can be deduced automatically, as the\n64\nTowards an Automated Requirements-driven Development of sCPS\nword “battery” has been marked as appositional modiﬁer (appos) of the word “level”. Another option for\ndisambiguation might be employment of string distance metrics [4]3 to identify corresponding entities\n(e.g., “car” and “e-car”).\n3.3\nInvariant type identiﬁcation\nDuring applying the IRM-SA method, sentences in the Requirements section of the speciﬁcation are\nrather directly translated into invariants of the IRM-SA model. However, the issue is to identify whether\nthe particular sentence relates to the abstract, process, exchange or assumption invariant. It would be\nhelpful, if the IRM-SA editor could automatically propose the invariant type.\nAssumption invariants should be included only in the situation-speciﬁc section of the requirements\nspeciﬁcation and thus is easier to locate them (see the yellow highlighting in Figure 2 and the yellow\ninvariants in Figure 1). Additionally, the particular sentences express a condition, which is necessary\nto detect and extract. To extract it, the dependency parser can be again utilized. To support it, tools\nfor information extraction like Ollie4 or OpenIE5 can also be used as they are able to detect enabling\nconditions.\nTo distinguish between process and exchange invariants, it is necessary to analyze the main verb\nof the sentence (see the blue and green highlighting in Figure 2 and the blue and green invariants in\nFigure 1). With verbs such as “exchange” or “propagate”, there is a high chance that the sentence\ncorresponds to exchange invariant, while verbs “have”, “monitor”, “assess”, “obtain”, “acquire” or “de-\ntermine” usually denote a process invariant. A direct solution would be a simple comparison of the\nparticular verb with a predeﬁned set of verbs but it would be rather limiting. Instead, a suitable approach\nis to classify verbs according to their meaning, which is taken from WordNet[12]. WordNet is a large\nlexical database of English nouns, verbs, adjectives and adverbs. In the database, synonyms are grouped\ntogether forming so-called synsets. The synsets are interlinked according to their relations, forming net-\nwork of related words and concepts. Multiple WordNet similarity measures were proposed and their\nimplementation is available6 and can be used for the process and exchange invariants identiﬁcation.\nFinally, sentences containing additional sub-requirements can be marked as abstract invariants (the\ngray highlighting and the gray invariants in Figures 1 and 2).\n3.4\nKnowledge ﬂow recognition\nOne of the key IRM-SA ideas is that each invariant (with the exception of assumption ones) represents\na computation that produces output knowledge given a particular input knowledge such that the invariant\nis satisﬁed (as stated in [2]).\nFor example, in the invariant deduced from the requirement 1(d) in Figure 2, the energy level and POI\nof the vehicle and the available parking slots from the parking places serve as the input parameters for\ncomputation of the vehicle’s plan (all possible parameters, i.e., component attributes, are already known\nas they were identiﬁed in the previous phases). Schematically, it can be written\nV::energy, V::POI, P::availability -> V::plan.\n3an implementation available at http://secondstring.sourceforge.net/\n4https://github.com/knowitall/ollie\n5https://github.com/knowitall/openie\n6http://search.cpan.org/dist/WordNet-Similarity/\nJ. Vinarek, P. Hnetynka\n65\nSuch an abstraction of the requirements to input and output parameters allows for easier reasoning about\nthe invariants and it is employed in subsequent sections.\nHowever, an issue is how to identify which parameters are input and which output. A straightforward\nautomatic approach for distinguishing input parameters from the output ones is an iteration starting\nfrom the simple invariants and taking into account types of parameters already distinguished from the\nprevious iterations. The approach starts with the process invariants having only single parameter. Such\na parameter must be an output one (otherwise the invariant would not produce any knowledge and the\nabove mentioned IRM-SA idea would not hold). Examples of such invariants are requirements 1(a) and\n1(b). Next, if a single attribute is present in multiple invariants, it can be assumed that it serves as an\ninput parameter. Nevertheless, this is only an assumption and thus a fully automated approach is hard to\nachieve. A possible solution is to use an assisted iterative approach, in which a tool identiﬁes input and\noutput parameters and the human designer conﬁrms/reverts the decisions.\nIn some cases, computation associated with an abstract invariant may not have all the parameters\nprecisely speciﬁed, as the particular parameters are unknown yet. They may be speciﬁed in the child\ninvariants and from the view of the higher-level invariant, they can be seen as an implementation detail.\nIn such cases, we use the notation V::? to mark that the component V participates in the invariant, but\nthe speciﬁc attribute is speciﬁed later in a child invariant. The ﬁnal assignment of the parameter is up to\nthe designer.\n3.5\nInvariant reﬁnement and composition\nIn EBCS, communication between components is implicit via their knowledge sharing, which is con-\nveyed via ensembles. An ensemble is thus speciﬁed via a condition determining when components are\npart of the particular ensemble and via knowledge that has to be interchanged.\nLet us again assume the requirement 1(d) with the parameter abstraction\nV::energy, V::POI, P::availability -> V::plan.\nAs the parameters come from different components (V and P) but the computation can be performed only\nin a single component, it is clear that the invariant has to be reﬁned as a composition of several invariants,\nfrom which at least one is an exchange invariant (in the implementation, the exchange invariants results\nin the ensemble deﬁnition). Such situations can be rather easily detected automatically based on the\nparameters’ owners.\nNevertheless, reﬁnement and composition of the abstract invariants is more difﬁcult as they repre-\nsent high-level goals and can intentionally abstract from some “implementation details”, i.e., omit some\nattributes. For example, in Figure 1, composition of the invariants 5 and 6 means that the trip plan\nis computed ﬁrst without any knowledge about availability of the parking places (the output parame-\nter V::planFeasibility in the invariant 5) and then it is made more speciﬁc with information about\nthe availability (the invariant 6). Different composition of the lower-level invariants would lead to a\ncompletely different behavior.\nAnother issue in the automatic composition of invariants is a reasoning about situation-speciﬁc re-\nquirements, which have to be grouped together according to a requirement they belong to. The grouping\nis performed based on their output parameters and can result in duplication of invariant subtrees. How-\never, identiﬁcation of the right subtree to be duplicated is not straightforward. Both these issues are very\nhard to solve automatically and we plan to further investigate possibilities of their automation in more\ndetail.\n66\nTowards an Automated Requirements-driven Development of sCPS\n3.6\nModel validation\nWith the abstraction of invariants described in 3.4, the IRM-SA model can be automatically validated\naccording to the knowledge ﬂow. In particular, following checks can be performed:\n• Conﬁgurations with missing input parameters can be discovered (i.e., an invariant producing the\nparticular attribute is not included in the conﬁguration due to a missing dependency relation).\n• Conﬁgurations with multiple invariants writing to the same attribute can be detected.\n• Also, detection of unused output parameters or unused attributes can be performed.\nAll of these checks may point to ﬂaws in the model and/or speciﬁcation and discover them early.\n4\nRelated work\nAs far as we know, there are no attempts to automatize requirements processing for EBCS design. Never-\ntheless, a related approach is described in [3], in which authors propose an approach called NPL-KAOS\nthat can automatically obtain a KAOS model from large volume of literature (KAOS [9] is a goal-oriented\nrequirement engineering method and it was one of inspirations for the IRM-SA method). With the use\nof natural language processing tools and text mining techniques they process abstracts of scientiﬁc pub-\nlications. First, they detect goal-oriented keywords and then they use the Stanford parser to tag semantic\nstructures. From obtained semantic trees they extract goals and ﬁnally organize them into taxonomies.\nThe taxonomies are used to deﬁne relations between goals and this way they simulate the process of\nreﬁnement. Similarly to our approach, the authors try to automatically derive a model from textual data\nwhich would serve for purposes of requirements engineering. However, their problem is different. Their\nmain goal is to help requirements engineer during the early stages of goal elicitation by extraction of main\nconcepts from the large body of research abstracts. Although the extraction process may miss some goals\nin the single abstract, with large number of abstracts they can count on the fact that the goal will be at\nthe end noticed. Contrary, our method is intended to process a single speciﬁcation and therefore cannot\nreckon on this effect.\nIn [5], the authors (semi-)automatically derive a UML model and OCL constraints from a speciﬁca-\ntion and test cases, which are both written in natural language. They employ formal methods to verify\ncorrectness of the derived design. First, grammatical analysis is used to derive UML class diagrams from\nthe test cases. Then, the behavior of test cases is inspected and the UML sequence diagrams are derived.\nIn the next step, OCL constraints are deduced from the requirements and test cases. Finally, veriﬁcation\nof static aspects (UML class diagrams and OCL invariants) and dynamic aspects (satisfaction of speci-\nﬁed method pre-conditions and post-conditions) is checked. As in our approach, authors use the Stanford\nparser to get dependencies from the sentences. They also employ WordNet (in their case, to distinguish\ncomponents of the system and actors). The main difference is that we directly target sCPS design and\nEBCS and therefore include an identiﬁcation of process and exchange invariants, adaptability, etc.\n5\nConclusion\nIn the paper, we have analyzed the IRM-SA design method with respect to its possible automation with\nthe help of natural language processing methods and tools. We have identiﬁed steps that can be automated\nand sketched solutions. As the automated natural language understanding is generally still a challenging\nJ. Vinarek, P. Hnetynka\n67\nissue, the full automation is hard (and in many cases impossible) to achieve. Thus, we target a semi-\nautomated system that guides the human designer, recommends solutions and validates the designers\nactions.\nCurrently, we plan to implement all the identiﬁed proposed solutions, to integrate them to the existing\nIRM-SA editor and to validate the resulting system on a real-life case-study.\nEven though the proposed approaches are tailored to IRM-SA (which is currently tied with the\nDEECo component model), they can be reused in different contexts. The IRM-SA method itself can\nbe without changes applied to another ensemble-based component model (e.g., Helena [7]) and the ap-\nproaches proposed in this paper can be applied in tools for the KAOS method or similar ones.\n6\nAcknowledgement\nThis work was partially supported by the project no. LD15051 from COST CZ (LD) programme by\nthe Ministry of Education, Youth and Sports of the Czech Republic and partially supported by Charles\nUniversity institutional funding SVV-2016-260331.\nReferences\n[1] Tomas Bures, Ilias Gerostathopoulos, Petr Hnetynka, Jaroslav Keznikl, Michal Kit & Frantisek Plasil (2013):\nDEECO: An Ensemble-based Component System. In: Proceedings of CBSE 2013, Vancouver, Canada, ACM,\npp. 81–90, doi:10.1145/2465449.2465462.\n[2] Tomas Bures, Ilias Gerostathopoulos, Petr Hnetynka, Jaroslav Keznikl, Michal Kit & Frantisek Plasil (2015):\nThe Invariant Reﬁnement Method. In: Software Engineering for Collective Autonomic Systems, LNCS 8998,\nSpringer, pp. 405–428, doi:10.1007/978-3-319-16310-9 12.\n[3] E. Casagrande, S. Woldeamlak, W.L. Woon, H.H. Zeineldin & D. Svetinovic (2014): NLP-KAOS for Systems\nGoal Elicitation: Smart Metering System Case Study. IEEE Transactions on Software Engineering 40(10),\npp. 941–956, doi:10.1109/TSE.2014.2339811.\n[4] William W. Cohen, Pradeep Ravikumar & Stephen E. Fienberg (2003): A comparison of string distance\nmetrics for name-matching tasks. In: Proceedings of IIWeb-03, Acapulco, Mexico, pp. 73–78.\n[5] Rolf Drechsler, Mathias Soeken & Robert Wille (2012): Formal Speciﬁcation Level: Towards veriﬁcation-\ndriven design based on natural language processing. In: Proceedings of FDL 2012, Vienna, Austria, IEEE,\npp. 53–58.\n[6] Ilias Gerostathopoulos, Tomas Bures, Petr Hnetynka, Jaroslav Keznikl, Michal Kit, Frantisek Plasil & No¨el\nPlozeau (2015): Self-Adaptation in Cyber-Physical Systems: from System Goals to Architecture Conﬁgura-\ntions. Technical Report D3S-TR-2015-02, Charles University in Prague, Faculty of Mathematics and Physics,\nDepartment of Distributed and Dependable Systems.\n[7] Rolf Hennicker & Annabelle Klarl (2014): Foundations for Ensemble Modeling — The Helena Approach.\nIn: Speciﬁcation, Algebra, and Software, LNCS 8373, Springer, pp. 359–381, doi:10.1007/978-3-642-54624-\n2 18.\n[8] Matthias H¨olzl, Axel Rauschmayer & Martin Wirsing (2008): Software Engineering for Ensembles. In:\nSoftware-Intensive Systems and New Computing Paradigms, LNCS 5380, Springer Berlin Heidelberg, pp.\n45–63, doi:10.1007/978-3-540-89437-7 2.\n[9] Axel van Lamsweerde (2008): Requirements Engineering: From Craft to Discipline. In: Proceedings of\nSIGSOFT’08/FSE-16, Atlanta, USA, ACM, pp. 238–249, doi:10.1145/1453101.1453133.\n[10] Craig Larman (2004): Applying UML and patterns: an introduction to object-oriented analysis and design\nand the uniﬁed proces, 3rd edition. Prentice-Hall.\n68\nTowards an Automated Requirements-driven Development of sCPS\n[11] Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard & David McClosky\n(2014): The Stanford CoreNLP Natural Language Processing Toolkit. In: Proceedings of 52nd Annual\nMeeting of the Association for Computational Linguistics: System Demonstrations, Baltimore, Maryland,\npp. 55–60, doi:10.3115/v1/P14-5010.\n[12] George A. Miller (1995): WordNet: A Lexical Database for English. Communications of the ACM 38(11),\npp. 39–41, doi:10.1145/219717.219748.\n[13] Brice Morin, Franck Fleurey & Olivier Barais (2015): Taming Heterogeneity and Distribution in sCPS. In:\nProceedings of SEsCPS 2015, Firenze, Italy, ACM, pp. 40–43, doi:10.1109/SEsCPS.2015.15.\n[14] Ivan Ruchkin, Bradley Schmerl & David Garlan (2015): Architectural Abstractions for Hybrid Programs.\nIn: Proceedings of CBSE 2015, Montreal, Canada, ACM, pp. 65–74, doi:10.1145/2737166.2737167.\n[15] Viliam Simko, David Hauzar, Petr Hnetynka, Tomas Bures & Frantisek Plasil (2014): Formal Veriﬁcation of\nAnnotated Textual Use-Cases. The Computer Journal 58(7), pp. 1495–1529, doi:10.1093/comjnl/bxu068.\n[16] Viliam Simko, Petr Hnetynka & Tomas Bures (2010): From Textual Use-Cases to Component-Based Appli-\ncations. In: In proceedings of SNPD 2010, London, UK, SCI 295, Springer, pp. 23–37, doi:10.1007/978-3-\n642-13265-0 3.\n[17] Viliam Simko, Petr Kroha & Petr Hnetynka (2013): Implemented Domain Model Generation. Technical\nReport D3S-TR-2013-03, Charles University in Prague, Faculty of Mathematics and Physics, Department of\nDistributed and Dependable Systems.\n[18] Jiri Vinarek, Petr Hnetynka, Viliam Simko & Petr Kroha (2014): Recovering Traceability Links Between\nCode and Speciﬁcation Through Domain Model Extraction. In: Proceedings of EOMAS 2014, Thessaloniki,\nGreece, LNBIP 191, Springer, pp. 187–201, doi:10.1007/978-3-662-44860-1 11.\n",
  "categories": [
    "cs.SE",
    "cs.CL"
  ],
  "published": "2016-03-29",
  "updated": "2016-03-29"
}