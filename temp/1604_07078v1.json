{
  "id": "http://arxiv.org/abs/1604.07078v1",
  "title": "Unsupervised Representation Learning of Structured Radio Communication Signals",
  "authors": [
    "Timothy J. O'Shea",
    "Johnathan Corgan",
    "T. Charles Clancy"
  ],
  "abstract": "We explore unsupervised representation learning of radio communication\nsignals in raw sampled time series representation. We demonstrate that we can\nlearn modulation basis functions using convolutional autoencoders and visually\nrecognize their relationship to the analytic bases used in digital\ncommunications. We also propose and evaluate quantitative met- rics for quality\nof encoding using domain relevant performance metrics.",
  "text": "Unsupervised Representation Learning of Structured\nRadio Communication Signals\nTimothy J. O’Shea\nBradley Department of Electrical\nand Computer Engineering\nVirginia Tech\nArlington, VA\nhttp://www.oshearesearch.com\nJohnathan Corgan\nCorgan Labs\nSan Jose, CA\nhttp://corganlabs.com/\nT. Charles Clancy\nBradley Department of Electrical\nand Computer Engineering\nVirginia Tech\nArlington, VA\nhttp://www.stochasticresearch.com/\nAbstract—We explore unsupervised representation learning\nof radio communication signals in raw sampled time series\nrepresentation. We demonstrate that we can learn modulation\nbasis functions using convolutional autoencoders and visually\nrecognize their relationship to the analytic bases used in digital\ncommunications. We also propose and evaluate quantitative met-\nrics for quality of encoding using domain relevant performance\nmetrics.\nIndex Terms—Radio communications, Software Radio, Cogni-\ntive Radio, Deep Learning, Convolutional Autoencoders, Neural\nNetworks, Machine Learning\nI. INTRODUCTION\nRadio signals are all around us and serve as a key enabler\nfor both communications and sensing as our world grows\nincreasingly reliant on both in a heavily interconnected and\nautomated world. Much effort has gone into expert system\ndesign and optimization for both radio and radar systems over\nthe past 75 years considering exactly how to represent, shape,\nadapt, and recover these signals through a lossy, non-linear,\ndistorted, and often interference heavy channel environment.\nMeanwhile, in recent years, heavily expert-tuned basis func-\ntions such as Gabor ﬁlters in the vision domain have been\nlargely discarded due to the speed at which they can be naively\nlearned and adapted using feature learning approaches in deep\nneural networks.\nHere we explore making the same transition from using rel-\natively simple expert-designed representation and coding to us-\ning emergent, learned encoding. We expect to better optimize\nfor channel capacity, to be able to translate information to and\nfrom channel and compact representations, and to better reason\nabout what kind of information is in the radio spectrum–\nallowing less-supervised classiﬁcation, anomaly detection, and\nnumerous other applications.\nThis paper provides the ﬁrst step towards that goal by\ndemonstrating that common radio communications signal\nbases emerge relatively easily using existing unsupervised\nlearning methods. We outline a number of techniques which\nenable this to work to provide insight for continued investi-\ngation into this domain. This work extends promising prior\nsupervised feature learning work in the domain we have\nalready begun in [12].\nA. Basis Functions for Radio Data\nWidely used single-carrier radio signal time series mod-\nulations schemes today still use a relatively simple set of\nsupporting basis functions to modulate information into the\nradio spectrum. Digital modulations typically use a set of sine\nwave basis functions with orthogonal or pseudo-orthogonal\nproperties in phase, amplitude, and/or frequency. Information\nbits can then be used to map a symbol value si to a location\nin this space φj, φk, .... In ﬁgure 1 we show three potential\nbasis functions where φ0 and φ1 form phase-orthogonal bases\nused in Phase Shift Keying (PSK) and Quadrature Ampli-\ntude Modulation (QAM), while φ0 and φ2 show frequency-\northogonal bases used in Frequency Shit Keying (FSK). In the\nﬁnal ﬁgure of 1 we show a common mapping of constellation\npoints into this space as typically used in Quadrature Phase\nShift Keying (QPSK) where each symbol value encodes two\nbits of information.\nDigital modulation theory in communications is a rich\nsubject explored in much greater depth in numerous great texts\nsuch as [3].\nFigure 1.\nExample Radio Communications Basis Functions\narXiv:1604.07078v1  [cs.LG]  24 Apr 2016\nB. Radio Signal Structure\nOnce basis functions have been selected, data to transmit is\ndivided into symbols and each symbol period for transmission\noccupies a sequential time slot. To avoid creating wideband\nsignal energy associated with rapid transitions in symbols,\na pulse shaping envelope such as a root-raised cosine or\nsinc ﬁlter is typically used to provide a smoothed transition\nbetween discrete symbol values in adjacent time-slots [1].\nThree such adjacent symbol time slots can be seen in ﬁgure 2.\nUltimately a sequence of pulse shaped symbols with different\nvalues are summed together to form the transmit signal time-\nseries, s(t).\nFigure 2.\nDiscrete Symbols Envelopes in Time\nC. Radio Channel Effects\nThe transmitted signal, s(t), passes through a number of\nchannel effects over the air before being received as r(t) at the\nreceiver. This includes time-delay, time-scaling, phase rotation,\nfrequency offset, additive thermal noise, and channel impulse\nresponses being convolved with the signal, all as random\nunknown time-varying processes. A closed form of all these\neffects might take the form of something roughly like this:\nr(t) = ej∗nLo(t)\nZ τ0\nτ=0\ns(nClk(t −τ))h(τ) + nAdd(t)\n(1)\nThis signiﬁcantly complicates the data representation from\nits original straightforward encoding at the transmitter when\nconsidering the effects of wireless channels as they exist in\nthe real world.\nII. LEARNING FROM RADIO SIGNALS\nWe focus initially on attempting to learn symbol basis\nfunctions from existing modulation schemes in wide use\ntoday. We focus on Quadrature Phase-Shift Keying (QPSK)\nand Gaussian Binary Frequency Shift Keying (GFSK) as our\nmodulation of interest in this work and hope to demonstrate\nlearning the analytical basis functions for these naively.\nA. Building a Dataset\nWe leverage the dataset from [12] and focus on learning\nonly a single modulation basis set at a time in this work.\nThis dataset includes the QPSK and GFSK modulations passed\nthrough realistic, but relatively benign wireless channels, sam-\npled in 88 complex-valued sample times per training example.\nB. Unsupervised Learning\nAutoencoders [2] have become a powerful and widely\nused unsupervised learning tool. We review the autoencoder\nand several relevant improvements on the autoencoder with\napplication to this domain which we leverage.\n1) Autoencoder Architectures: Autoencoders (AE) learn an\nintermediate, possibly lower dimensional encoding of an input\nby using reconstruction cost as their optimization criteria,\ntypically attempting to minimize Mean Squared-Error (MSE).\nThey consist of an encoder which encodes raw inputs into a\nlower-dimension hidden sparse representation, and a decoder\nwhich reconstructs an estimate for the input vector as the\noutput.\nA number of improvements have been made on autoen-\ncoders which we leverage below.\n2) Denoising Autoencoders: By introducing noise into the\ninput of an AE training, but evaluating its reconstruction of\nthe unmodiﬁed input, Denoising Autoencoders [6] perform an\nadditional input noise regularization effect which is extremely\nwell suited in the communications domain where we always\nhave additive Gaussian thermal noise applied to our input\nvectors.\n3) Convolutional Autoencoders:\nConvolutional Autoen-\ncoders [7] are simply autoencoders leveraging convolutional\nweight conﬁgurations in their encoder and decoder stages.\nBy leveraging convolutional layers rather than fully connected\nlayers, we force time-shift invariance learning in our features\nand reduce the number of parameters required to ﬁt. Since\nour channel model involves random time shifting of the input\nsignal, this is an important property to the radio application\ndomain which we feel is extremely well suited for this task.\n4) Regularization: We leverage heavy L2 = ∥W∥2 weight\nregularization and L1 = ∥h∥1 activity regularization in our\nAE to attempt to force it to learn orthogonal basis functions\nwith minimal energy. [4] Strong L1 activation regularization\nis especially important in the narrow hidden layer represen-\ntation between encoder and decoder where we would like\nto learn a maximally sparse compact basis representation of\nthe signal through symbols of interest occurring at speciﬁc\ntimes. Dropout [10] is also used as a form of regularization\nbetween intermediate layers, forcing the network to leverage\nall available weight bases to span the representation space.\nC. Test Neural Network Architecture\nOur goal in this effort was to obtain a minimum complexity\nnetwork which allows us to convincingly reconstruct the\nsignals of interest with a signiﬁcant amount of information\ncompression. By using convolutional layers with only one\nor two ﬁlters, we seek to achieve a maximally matched\nsmall set of time-basis ﬁlters with some equivalence to the\nexpert features used to construct the signal. Dense layers with\nnon-linear activations then sit in between these to provide\nsome estimation of the logic for what the representation and\nreconstruction should be for those basis ﬁlters occurring at\ndifferent times. The basic network architecture is shown below\nin ﬁgure 3.\nFigure 3.\nConvolutional Autoencoder Architecture Used\nD. Evaluation Methods for Reconstruction\nFor the scope of this work we use MSE as our reconstruction\nmetric for optimization. We seek to evaluate reconstructed\nsignals from BER and SNR, but plan to defer this for later\nwork in the interest of space.\nE. Visual Inspection of Learned Representations\nGiven a relatively informed view of what a smooth band-\nlimited QPSK signal looks like in reality, visual inspection\nof the reconstruction vs the noisy input signal is an impor-\ntant way to consider the quality of the representation and\nreconstruction we have learned. The sparse representation is\nespecially interesting as by selecting hard-sigmoid dense layer\nactivations we have effectively forced the network to learn a\nbinary representation of the continuous signal. Ideally there\nexists a direct GF(2) relationship between the encoded bits\nand the coded symbol bits of interest here. Figures 4 and 5\nillustrate this reconstruction and sparse binary representation\nlearned.\nFor GFSK, we show reconstructions and sparse representa-\ntions in ﬁgure 6. In this case, the AE architecture converges\neven faster to a low reconstruction error, but unfortunately the\nsparse representations are not saturated into discrete values as\nwas the case for the constant modulus signal.\nIII. RESULTS\nWe consider the signiﬁcance of these results below in the\ncontext of the network complexity required for representation\nand the compression ratio obtained.\nFigure 4.\nQPSK Reconstruction 1 through Conv-AE\nFigure 5.\nQPSK Reconstruction 2 through Conv-AE\nFigure 6.\nGFSK Reconstruction 1 through Conv-AE\nA. Learned Network Parameters\nWe use Adam [9] (a momentum method of SGD) to train\nour network parameters as implemented in the Keras [11]\nlibrary. Evaluating our weight complexity, we have two 2D\nconvolutional layers, 2x1x1x40 and 1x1x1x81, making a total\nof only 161 parameters learned in these layers to ﬁt the\ntranslation invariant ﬁlter features which form the primary\ninput and output for our network. The Dense layers which\nprovide mappings from occurrences of these ﬁlter weights to\na sparse code and back to a wide representation, consist of\nweight matrices of 516x44 and 44x176 respectively, making\na total of 30448 dense ﬂoating point weight values.\nTraining is relatively trivial with this size network and\ndataset, we converge on a solution after about 2 minutes of\ntraining, 25 epochs on 20,000 training examples using a Titan\nX GPU.\nFigure 7.\nQPSK Encoder Convolutional Weights\nFigure 8.\nQPSK Decoder Convolutional Weights\nIn ﬁgure 7 we show the learned convolutional weight vectors\nin the encoder ﬁrst layer. We can clearly see a sinusoid\noccurs at varying time offests to form detections, and a second\nsinusoid at double the frequency, both with some minimal\npulse shaping apparent on them.\nIn the decoder convolutional weight vector in ﬁgure 8 we\ncan clearly see the pulse shaping ﬁlter shape emerge in the\nIn ﬁgure 9 we display the learned dense layer weights\nmappings of various symbol value and offset areas as rep-\nresented by the convolutional ﬁlters. It is important to note\nFigure 9.\nFirst Four Sparse Representation Dense Weights\nthat the 1x516 input is a linearized dimension of zero-padded\nI and Q inputs through two separate ﬁlters (2x2x129). We see\nthat a single sparse hidden layer value equates to two pulses\nrepresenting sinusoidal convolutional ﬁlter occurrences in time\nin the I and the Q channel, with roughly a sinc or root raised\ncosine window roll-off visibly represented in this time-scale.\nB. Radio Signal Representation Complexity\nTo measure the compression we have achieved, we compare\nthe effective number of bits required to represent the dynamic\nrange in the input and output continuous signal domains with\nthat of the number of bits required to store the signal in the\nhidden layer. [8]\nIf we consider that our input signal contains roughly 20dB\nof signal-to-noise ratio, we can approximate the number of\nbits required to represent each continuous value as follows.\nNeff = ⌈20dB −1.76\n6.02\n⌉= 4 bits\n(2)\nGiven that we have 88*2 inputs of 4 bit resolution, com-\npressed to 44 intermediate binary values, we get a compression\nratio of 16x = 88*2*4/44.\nGiven that we are learning roughly 4 to 5 symbols per\nexample, with 4 samples per symbol, this equates to something\nlike 10 bits being the most compact possible form of data-\ninformation representation. However in the current encoder,\nwe are also encoding timing offset information, phase error,\nand generally all channel information needed to reconstruct\nthe data symbols in their speciﬁc arrival mode. Given this is\non the order of 4x the most compact representation possible\nfor the data symbols alone, this is not a bad starting point.\nIV. CONCLUSIONS\nWe are able to obtain relatively good compression with\nautoencoders for radio communications signals, however these\nmust encode both the data bits and the channel state informa-\ntion which limits attainable compression.\nHard-sigmoid activations surrounding the hidden layer, for\nconstant modulus modulations, seem effective in saturating\nrepresentation into compact binary vectors, allowing us to\nencode 88 x 64 bit complex values into 44 bits of information\nwithout signiﬁcant degradation.\nConvolutional autoencoders are well suited for reducing\nparameter space, forcing time-invariance features, and forming\na compact front-end for radio data. We look forward to evaluat-\ning more quantitative metrics on reconstructed data, evaluating\nadditional multi-level binary or hard-sigmoid representation\nfor multi-level non-constant-modulus signals and investigating\nthe use of attention models to remove channel variance from\ncompact data representation requirements.\nACKNOWLEDGMENTS\nThe authors would like to thank the Bradley Department\nof Electrical and Computer Engineering at the Virginia Poly-\ntechnic Institute and State University, the Hume Center, and\nDARPA all for their generous support in this work.\nThis research was developed with funding from the Defense\nAdvanced Research Projects Agency’s (DARPA) MTO Ofﬁce\nunder grant HR0011-16-1-0002. The views, opinions, and/or\nﬁndings expressed are those of the author and should not be\ninterpreted as representing the ofﬁcial views or policies of the\nDepartment of Defense or the U.S. Government.\nREFERENCES\n[1]\nE. S. Sousa and S. Pasupathy, “Pulse shape design\nfor teletext data transmission”, Communications, IEEE\nTransactions on, vol. 31, no. 7, pp. 871–878, 1983.\n[2]\nG. E. Hinton and R. S. Zemel, “Autoencoders, min-\nimum description length, and helmholtz free energy”,\nAdvances in neural information processing systems,\npp. 3–3, 1994.\n[3]\nB. Sklar, Digital communications. Prentice Hall NJ,\n2001, vol. 2.\n[4]\nH. Lee, A. Battle, R. Raina, and A. Y. Ng, “Efﬁcient\nsparse coding algorithms”, in Advances in neural infor-\nmation processing systems, 2006, pp. 801–808.\n[5]\nC. Clancy, J. Hecker, E. Stuntebeck, and T. O’Shea,\n“Applications of machine learning to cognitive radio\nnetworks”, Wireless Communications, IEEE, vol. 14,\nno. 4, pp. 47–52, 2007.\n[6]\nP. Vincent, H. Larochelle, Y. Bengio, and P.-A. Man-\nzagol, “Extracting and composing robust features with\ndenoising autoencoders”, in Proceedings of the 25th\ninternational conference on Machine learning, ACM,\n2008, pp. 1096–1103.\n[7]\nJ. Masci, U. Meier, D. Cires¸an, and J. Schmidhu-\nber, “Stacked convolutional auto-encoders for hierar-\nchical feature extraction”, in Artiﬁcial Neural Networks\nand Machine Learning–ICANN 2011, Springer, 2011,\npp. 52–59.\n[8]\nT. M. Cover and J. A. Thomas, Elements of information\ntheory. John Wiley & Sons, 2012.\n[9]\nD. Kingma and J. Ba, “Adam: a method for stochastic\noptimization”, arXiv preprint arXiv:1412.6980, 2014.\n[10]\nN. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever,\nand R. Salakhutdinov, “Dropout: a simple way to pre-\nvent neural networks from overﬁtting”, The Journal of\nMachine Learning Research, vol. 15, no. 1, pp. 1929–\n1958, 2014.\n[11]\nF. Chollet, Keras, https://github.com/fchollet/keras,\n2015.\n[12]\nT.\nJ.\nO’Shea\nand\nJ.\nCorgan,\n“Convolutional\nra-\ndio modulation recognition networks”, CoRR, vol.\nabs/1602.04105, 2016. [Online]. Available: http://arxiv.\norg/abs/1602.04105.\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2016-04-24",
  "updated": "2016-04-24"
}