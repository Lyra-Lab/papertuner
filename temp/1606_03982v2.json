{
  "id": "http://arxiv.org/abs/1606.03982v2",
  "title": "A Chomsky-Schützenberger representation for weighted multiple context-free languages",
  "authors": [
    "Tobias Denkinger"
  ],
  "abstract": "We prove a Chomsky-Sch\\\"utzenberger representation theorem for multiple\ncontext-free languages weighted over complete commutative strong bimonoids.",
  "text": "arXiv:1606.03982v2  [cs.FL]  28 Nov 2016\nA Chomsky-Sch¨utzenberger representation\nfor weighted multiple context-free\nlanguages∗\nTobias Denkinger\nFaculty of Computer Science\nTechnische Universit¨at Dresden\n01062 Dresden, Germany\ntobias.denkinger@tu-dresden.de\n2018-09-11\nAbstract\nWe prove a Chomsky-Sch¨utzenberger representation theorem for multiple context-\nfree languages weighted over complete commutative strong bimonoids.\nContents\n1\nIntroduction\n2\n2\nPreliminaries\n2\n3\nMultiple Dyck languages\n8\n3.1\nThe original deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n3.2\nCongruence multiple Dyck languages . . . . . . . . . . . . . . . . . . . . .\n9\n3.3\nMembership in a congruence multiple Dyck language . . . . . . . . . . . .\n12\n4\nCS theorem for weighted MCFLs\n15\n4.1\nSeparating the weights . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n4.2\nStrengthening the unweighted CS representation\n. . . . . . . . . . . . . .\n19\n4.3\nComposing the homomorphisms . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.4\nThe weighted CS representation . . . . . . . . . . . . . . . . . . . . . . . .\n22\n5\nConclusion and outlook\n22\n∗This is an extended version of a paper with the same title presented at the 12th International Confer-\nence on Finite-State Methods and Natural Language Processing (FSMNLP 2015), [Den15].\n1\n1 Introduction\nMildly context-sensitive languages receive much attention in the natural language pro-\ncessing community [Kal10].\nMany classes of mildly context-sensitive languages are\nsubsumed by the multiple context-free languages, e.g.\nthe languages of head gram-\nmars, linear context-free rewriting systems [SMFK91], combinatory categorial gram-\nmars [VSWJ86, WJ88], linear indexed grammars [VS87], minimalist grammars, [Mic01b,\nMic01a], and ﬁnite-copying lexical functional grammars [SNK+93].\nThe Chomsky-Sch¨utzenberger (CS) representation for context-free languages [CS63,\nProposition 2] has been generalised to a variety of unweighted and weighted settings,\ne.g. context-free languages weighted with commutative semirings [SS78, Theorem 4.5],\ntree adjoining languages [Wei88, Lemma 3.5.2], multiple context-free languages [YKS10,\nTheorem 3], context-free languages weighted with unital valuation monoids [DV13, The-\norem 2], yields of simple context-free tree languages [Kan14, Theorem 8.3], indexed\nlanguages ([DPS79, Theorems 1 and 2]; [FV15, Theorem 4]; and [FV16, Theorem 18]),\nand automata with storage weighted with unital valuation monoids [HV15, Theorem 11].\nWe give a generalisation to the case of multiple context-free languages weighted with a\ncomplete commutative strong bimonoid. Sections 3 and 4 contain the main contributions\nof this paper. The outline of these sections is:\n• In order to obtain a CS representation for multiple context-free languages, Yosh-\ninaka, Kaji, and Seki [YKS10] introduce multiple Dyck languages. We give a more\nalgebraic deﬁnition of multiple Dyck languages using congruence relations together\nwith a decision algorithm for membership that is strongly related to these congru-\nence relations (Section 3).\n• In Section 4 we provide a CS representation for weighted multiple context-free\nlanguages by means of a modular proof that ﬁrst separates the weights from the\ngiven grammar and then employs the result for the unweighted case (using the\nsame overall idea as in Droste and Vogler [DV13]).\nSince our proofs do not require distributivity, we can be slightly more general than\ncomplete commutative semirings. The weight algebras considered here are therefore the\ncomplete commutative strong bimonoids.\n2 Preliminaries\nIn this section we recall formalisms used in this paper and ﬁx some notation: We denote\nby N the set of natural numbers (including zero).\nFor every n ∈N we abbreviate\n{1, . . . , n} by [n]. Let A be a set. The power set of A is denoted by P(A). Let B be a\nﬁnite set. A partition of B is a set P ⊆P(B) where the elements of P are non-empty,\npairwise disjoint, and S\np∈P p = B.\nLet A and B be sets and A′ ⊆A. The set of functions from A to B is denoted by\nA →B, we still write f : A →B rather then f ∈A →B. Let f and g be functions. The\ndomain and range of f are denoted by dom(f) and rng(f), respectively. The restriction\n2\nof f to A′, denoted by f|A′, is a function from A′ to B such that f|A′(a′) = f(a′) for\nevery a′ ∈A′. We denote the function obtained by applying g after f by g ◦f. Let F\nbe a set of functions and B ⊆T\nf∈F dom(f). The set {f(B) | f ∈F} ⊆P(rng(f)) is\ndenoted by F(B). Let G and H be sets of functions. The set {h ◦g | h ∈H, g ∈G} of\nfunctions is denoted by H ◦G.\nLet A be a set and ≈⊆A×A a binary relation on A. We call ≈an equivalence relation\n(on A) if it is reﬂexive, symmetric, and transitive. Let a ∈A and ≈be an equivalence\nrelation. The equivalence class of a in ≈, denoted by [a]≈, is {b ∈A | a ≈b}. Let\nf : Ak →A be a function. We say that ≈respects f if for every (a1, b1), . . . , (ak, bk) ∈≈\nholds f(a1, . . . , ak) ≈f(b1, . . . , bk). Now let A be an algebra with underlying set A. We\ncall ≈a congruence relation (on A) if ≈is an equivalence relation and respects every\noperation of A.\nSorts\nWe will use the concept of sorts to formalise restrictions on building terms (or trees),\ne.g. derivation trees or terms over functions. One can think of sorts as data types in\na programming language: Every concrete value has a sort (type) and every function\nrequires its arguments to be of ﬁxed sorts (types) and returns a value of some ﬁxed sort\n(type).\nLet S be a countable set (of sorts) and s ∈S. An S-sorted set is a tuple (B, sort) where\nB is a set and sort is a function from B to S. We denote the preimage of s under sort by\nBs and abbreviate (B, sort) by B; sort will always be clear from the context. Let A be\nan (S∗×S)-sorted set. The set of terms over A, denoted by TA, is the smallest S-sorted\nset T where ξ = a(ξ1, . . . , ξk) ∈Ts if there are s, s1, . . . , sk ∈S such that a ∈A(s,s1···sk)\nand ξi ∈Tsi for every i ∈[k]. Let ξ = a(ξ1, . . . , ξk) ∈TA. The set of positions in ξ is\ndeﬁned as pos(ξ) = {ε} ∪{iu | i ∈[k], u ∈pos(ξi)} and for every π ∈pos(ξ) the symbol\nin ξ at position π is deﬁned as ξ(π) = a if π = ε and as ξ(π) = ξi(u) if π = iu for some\ni ∈[k] and u ∈pos(ξi).\nWeight algebras\nA monoid is an algebra (A, ·, 1) where · is associative and 1 is neutral with respect to ·.\nA bimonoid is an algebra (A, +, ·, 0, 1) where (A, +, 0) and (A, ·, 1) are monoids. We call\na bimonoid strong if (A, +, 0) is commutative and for every a ∈A we have 0·a = 0 = a·0.\nIntuitively, a strong bimonoid is a semiring without distributivity. A strong bimonoid\nis called commutative if (A, ·, 1) is commutative.\nA commutative strong bimonoid is\ncomplete if there is an inﬁnitary sum operation P that maps every indexed family of\nelements of A to A, extends +, and satisﬁes inﬁnitary associativity and commutativity\nlaws [DV13, Section 2]:\n(i) P\ni∈∅a(i) = 0;\n(ii) for every j ∈I : P\ni∈{j} a(i) = a(j);\n(iii) for every j, k ∈I with j ̸= k : P\ni∈{j,k} a(i) = a(j) + a(k); and\n3\n(iv) for every countable set J and family ¯I : J →P(I) with I = S\nj∈J ¯I(j) and for every\nj, j′ ∈J with j ̸= j′ =⇒¯I(j) ∩¯I(j′) = ∅, we have P\nj∈J\nP\ni∈I(j) a(i) = P\ni∈I a(i).\nFor the rest of this paper let (A, +, ·, 0, 1), abbreviated by A, be a complete commutative\nstrong bimonoid.\nExample 2.1. We provide a list of complete commutative strong bimonoids [DSV10,\nExample 1] some of which are relevant for natural language processing:\n• Any complete commutative semiring, e.g.\n– the Boolean semiring B =\n\u0000{0, 1}, ∨, ∧, 0, 1\n\u0001\n,\n– the probability semiring Pr =\n\u0000R≥0, +, ·, 0, 1\n\u0001\n,\n– the Viterbi semiring\n\u0000[0, 1], max, ·, 0, 1\n\u0001\n,\n– the tropical semiring\n\u0000R ∪{∞}, min, +, ∞, 0\n\u0001\n,\n– the arctic semiring\n\u0000R ∪{−∞}, max, +, −∞, 0\n\u0001\n,\n• any complete lattice, e.g.\n– any non-empty ﬁnite lattice\n\u0000L, ∨, ∧, 0, 1\n\u0001\nwhere L is a non-empty ﬁnite set,\n– the lattice (P(A), ∪, ∩, ∅, A) where A is an arbitrary set,\n– the lattice (N, lcm, gcd, 1, 0),\n• the tropical bimonoid\n\u0000R≥0 ∪{∞}, +, min, 0, ∞\n\u0001\n,\n• the arctic bimonoid\n\u0000R≥0 ∪{−∞}, +, max, 0, −∞\n\u0001\n, and\n• the algebras Pr1 = ([0, 1], ⊕1, ·, 0, 1) and Pr2 = ([0, 1], ⊕2, ·, 0, 1) where a ⊕1 b =\na + b −a · b and a ⊕2 b = min{a + b, 1} for every a, b ∈[0, 1].\nwhere R and R≥0 denote the set of reals and the set of non-negative reals, respectively;\n+, ·, max, min denote the usual operations; ∧, ∨denote disjunction and conjunction,\nrespectively, for the boolean semiring and join and meet, respectively, for any non-empty\nﬁnite lattice; and lcm and gcd are binary functions that calculate the least common\nmultiple and the greatest common divisor, respectively.\nAlso, there are some bimonoids that are interesting for natural language processing\nbut are not complete commutative strong bimonoids. E.g.\n• the semiring of formal languages\n\u0000P(Σ∗), ∪, ·, ∅, {ε}\n\u0001\nwhere Σ is an alphabet and\n· is language concatenation, i.e.\nL1 · L2 = {uv | u ∈L1, v ∈L2} for every\nL1, L2 ⊆Σ∗; and\n• the semiring\n\u0000Σ∗∪{∞}, ∧, ·, ∞, ε\n\u0001\nwhere Σ is an alphabet, · is concatenation, ∧\ncalculates the longest common preﬁx of its arguments, and ∞is a new element\nthat is neutral with respect to ∧and annihilating with respect to · [Moh00].\nBoth examples are not commutative.\n□\nAn A-weighted language (over ∆) is a function L : ∆∗→A. The support of L, denoted\nby supp(L), is {w ∈∆∗| L(w) ̸= 0}. If |supp(L)| ≤1, we call L a monomial. We write\nµ.w for L if L(w) = µ and for every w′ ∈∆∗\\ {w} we have L(w′) = 0.\n4\nRecognisable languages\nFor the many known results concerning ﬁnite state automata and regular languages, we\nwill rely on [HU69] and [HU79]. We nevertheless recall the basic deﬁnitions:\nDeﬁnition 2.2. A ﬁnite state automaton, for short: FSA, is a tuple M = (Q, ∆, q0, F, T)\nwhere ∆is an alphabet (terminals), Q is a ﬁnite set (states) disjoint from ∆, q0 ∈Q\n(initial state), F ⊆Q (ﬁnal states), and T ⊆Q × ∆∗× Q is a ﬁnite set (transitions).\n□\nA run in M is a string κ ∈(Q ∪∆)∗where for every substring of κ of the form quq′\n(for some q, q′ ∈Q and u ∈∆∗) we have that (q, u, q′) ∈T, we say that the transition\n(q, u, q′) occurs in κ, the ﬁrst symbol of κ is q0, and the last symbol of κ is in F. The\nword corresponding to κ is obtained by removing the elements of Q from κ. The language\nof M is denoted by L(M). The set of recognisable languages, denoted by REG, is the\nset of languages L for which there is an FSA M with L = L(M).\nWeighted string homomorphisms\nDeﬁnition 2.3. Let ∆and Γ be alphabets and g : ∆→(Γ ∗→A) (i.e. a function\nthat takes an element of ∆and returns a function that takes an element of Γ ∗and\nreturns an element of A) such that g(δ) is a monomial for every δ ∈∆. We deﬁne\nbg : ∆∗→(Γ ∗→A) where for every k ∈N, δ1, . . . , δk ∈∆, and u ∈Γ ∗we have\nbg(δ1 · · · δk)(u) =\nX\nu1,...,uk∈Γ ∗\nu=u1···uk\ng\n\u0000δ1\n\u0001\u0000u1\n\u0001\n· . . . · g\n\u0000δk\n\u0001\u0000uk\n\u0001\n.\nWe call bg an A-weighted (string) homomorphism.\n□\nClearly, bg(u) is a monomial for every u ∈∆∗.\nWe call bg alphabetic if there is a\nfunction h : ∆→(Γ ∪{ε} →A) with bg = bh. If bg(u) = µ.w for u ∈∆∗, then we\nwill sometimes say “bg maps u to w” (leaving out the weight µ) or “bg weights u with\nµ” (leaving out the word w). Now assume that A = B and we have |supp(g(δ))| = 1\nfor every δ ∈∆. Then g can be construed as a function from ∆to Γ ∗and bg can be\nconstrued as a function from ∆∗to Γ ∗. In this case we call bg a (string) homomorphism.\nThe sets of all A-weighted homomorphisms, A-weighted alphabetic homomorphisms,\nhomomorphisms, and alphabetic homomorphisms are denoted by HOM(A), αHOM(A),\nHOM, and αHOM, respectively.\nWeighted multiple context-free languages\nWe ﬁx a set X = {xj\ni | i, j ∈N+} of variables. Let ∆be an alphabet. The set of\ncomposition representations over ∆is the (N∗× N)-sorted set RF∆where for every\ns1, . . . , sℓ, s ∈N we deﬁne X(s1···sℓ,s) = {xj\ni | i ∈[ℓ], j ∈[si]} ⊆X and (RFΣ)(s1···sℓ,s)\nas the set that contains [u1, . . . , us](s1···sℓ,s) for every u1, . . . , us ∈(∆∪X(s1···sℓ,s))∗. We\nwill often write Xf instead of X(s1···sℓ,s).\nLet f = [u1, . . . , us](s1···sℓ,s) ∈RFΣ.\nThe\nstring function of f, also denoted by f, is the function from (∆∗)s1 × · · · × (∆∗)sℓ\n5\nto (∆∗)s such that f((w1\n1, . . . , ws1\n1 ), . . . , (w1\nℓ, . . . , wsℓ\nℓ)) = (u′\n1, . . . , u′\ns) where (u′\n1, . . . , u′\ns)\nis obtained from (u1, . . . , us) by replacing each occurrence of xj\ni by wj\ni for every i ∈\n[ℓ] and j ∈[sℓ]. The set of all string functions for some composition representation\nover ∆is denoted by F∆. From here on we no longer distinguish between composition\nrepresentations and string functions. We deﬁne the rank of f, denoted by rank(f), and\nthe fan-out of f, denoted by fan-out(f), as ℓand s, respectively. The string function\nf is called linear if in u1 · · · us every element of Xf occurs at most once, f is called\nnon-deleting if in u1 · · · us every element of Xf occurs at least once, and f is called\nterminal-free if u1, . . . , us ∈X∗\nf. The subscript is dropped from the string function if its\nsort is clear from the context.\nNote that for every s′ ∈N∗× N, the set of linear terminal-free string functions of sort\ns′ is ﬁnite.\nDeﬁnition 2.4. A multiple context-free grammar (over ∆), for short: (∆-)MCFG, is\na tuple (N, ∆, S, P) where N is a ﬁnite N-sorted set (non-terminals), S ∈N1 (initial\nnon-terminal), and P is a ﬁnite set (productions) such that\nP ⊆ﬁn\n\b\n(A, f, A1 · · · Aℓ) ∈N × F∆× N ℓ| sort(f) = (sort(A1) · · · sort(Aℓ), sort(A)),\nf is linear, ℓ∈N\n\t\n.\nWe construe P as an (N ∗× N)-sorted set where for every ρ = (A, f, A1 · · · Aℓ) ∈P we\nhave sort(ρ) = (A, A1 · · · Aℓ).\n□\nLet G = (N, ∆, S, P) be an MCFG and w ∈∆∗. A production (A, f, A1 · · · Aℓ) ∈P\nis usually written as A →f(A1, . . . , Aℓ); it inherits rank and fan-out from f. Also,\nrank(G) = maxρ∈P rank(ρ) and fan-out(G) = maxρ∈P fan-out(ρ). MCFGs of fan-out at\nmost k are called k-MCFGs.\nThe function yield : TP →(Σ∗)∗assigns to every tree d ∈TP the string obtained by\nprojecting every production in d to the contained function (i.e. the second component)\nand then interpreting the resulting term over F∆.\nLet A ∈N. The set of subderivations in G from A, denoted by DG(A), is the set\nof all terms over P with sort A, i.e. DG(A) = (TP )A. The set of derivations in G is\nDG = DG(S). Let w ∈Σ∗. The set of derivations of w in G is DG(w) = {d ∈DG |\nyield(d) = (w)}.\nThe language of G is L(G) = {w ∈∆∗| DG(w) ̸= ∅}. A language L is called multiple\ncontext-free if there is an MCFG G with L = L(G). The set of multiple context-free\nlanguages (for which a k-MCFG exists) is denoted by MCFL (k-MCFL, respectively).\nThe language class k-MCFL is a substitution-closed full abstract family of languages\n[SMFK91, Theorem 3.9]. In particular, k-MCFL is closed under intersection with regular\nlanguages and under homomorphisms.\nDeﬁnition 2.5. An A-weighted MCFG (over ∆) is a tuple (N, ∆, S, P, µ) such that\n(N, ∆, S, P) is an MCFG and µ : P →A \\ {0} (weight assignment).\n□\nLet G = (N, ∆, S, P, µ) be an A-weighted MCFG and w ∈∆∗. The set of deriva-\ntions of w in G is the set of derivations of w in (N, ∆, S, P). G inherits fan-out from\n6\nS →[x1\n1x1\n2x2\n1x2\n2](A, B)\nA →[ax1\n1, cx2\n1](A)\nA →[ε, ε]()\nB →[ε, ε]()\nFigure 1: Only derivation of ac in G (Example 2.6)\n(N, ∆, S, P); A-weighted MCFGs of fan-out at most k are called A-weighted k-MCFGs.\nWe deﬁne a function bµ : DG →A that applies µ at every position of a given derivation\nand then multiplies the resulting values (in any order, since · is commutative).\nThe A-weighted language induced by G is the function JGK : ∆∗→A where for every\nw ∈∆∗we have JGK(w) = P\nd∈DG(w) bµ(d). Two (A-weighted) MCFGs are equivalent\nif they induce the same (A-weighted) language. An A-weighted language L is called\nmultiple context-free (of fan-out k) if there is an A-weighted k-MCFG G such that\nL = JGK; k-MCFL(A) denotes the set of multiple context-free A-weighted languages of\nfan-out k.\nExample 2.6. Consider the Pr2-weighted MCFG G =\n\u0000N, ∆, S, P, µ\n\u0001\nwhere N1 = {S},\nN2 = {A, B}, N = N1 ∪N2, ∆= {a, b, c, d}, and P and µ are given by\nP : ρ1 = S →[x1\n1x1\n2x2\n1x2\n2](A, B)\nµ : µ(ρ1) = 1\nρ2 = A →[ax1\n1, cx2\n1](A)\nµ(ρ2) = 1/2\nρ3 = B →[bx1\n1, dx2\n1](B)\nµ(ρ3) = 1/3\nρ4 = A →[ε, ε]()\nµ(ρ4) = 1/2\nρ5 = B →[ε, ε]()\nµ(ρ5) = 2/3 .\nWe observe that supp(JGK) = {ambncmdn | m, n ∈N} and for every m, n ∈N we have\nJGK(ambncmdn) = µ(ρ1) ·\n\u0000µ(ρ2)\n\u0001m · µ(ρ4) ·\n\u0000µ(ρ3)\n\u0001m · µ(ρ5)\n= 1/(2m · 3n+1).\nThe only derivation of w = ac in G is shown in Figure 1, its weight and hence also the\nweight of w is 1/(21 · 30+1) = 1/6.\n□\nA non-terminal is called productive in an (A-weighted) MCFG if there is at least one\nsubderivation starting from this non-terminal.\nIt is obvious that every (A-weighted)\nk-MCFL can be recognised by an (A-weighted) k-MCFG that only has productive non-\nterminals.\nNon-deleting normal form\nAn (A-weighted) MCFG is called non-deleting if the string function in every production\nis linear and non-deleting. Seki, Matsumura, Fujii, and Kasami [SMFK91, Lemma 2.2]\n7\nproved that for every k-MCFG there is an equivalent non-deleting k-MCFG. We gener-\nalise this to A-weighted MCFGs.\nLemma 2.7. For every A-weighted k-MCFG there is an equivalent non-deleting A-\nweighted k-MCFG.\nProof idea. We modify the construction for the unweighted case [SMFK91, Lemma 2.2]\nsuch that it preserves the structure of derivations. Then a weight assignment can be\ndeﬁned in an obvious manner.\nProof. Let G = (N, ∆, S, P, µ) be an A-weighted k-MCFG. When examining the proof of\nSeki, Matsumura, Fujii, and Kasami [SMFK91, Lemma 2.2], we notice that only step 2\nof Procedure 1 deals with non-deletion. We construct N ′ and P ′ from (N, ∆, S, P) by\nstep 2 of Procedure 1, but drop the restriction that Ψ ̸= [sort(A)].1\nLet g : P ′ →P assign to every ρ′ ∈P ′ the production in G it has been constructed\nfrom. Furthermore, let bg : DG′ →DG be the function obtained by applying g point-wise.\nWe show the following hypothesis by induction on the structure of subderivations:\nInduction hypothesis:\nFor every A ∈N and Ψ ∈M(A) : bg is a bijection between\nDG′(A[Ψ]) and DG(A).\nInduction step: Let d ∈DG(A) and Ψ ∈M(A) with d = ρ(d1, . . . , dk) for some produc-\ntion ρ ∈P and derivations d1 ∈DG(A1), . . ., dk ∈DG(Ak). The construction deﬁnes\nΨ1 ∈M(A1), . . ., Ψk ∈M(Ak) and a production ρ′ which is unique for every ρ and Ψ.\nBy the induction hypothesis, we know that there are derivations d′\n1, . . . , d′\nk which are\nunique for (d1, Ψ1), . . . , (dk, Ψk), respectively. Therefore, d′ = ρ(d′\n1, . . . , d′\nk) is unique for\nd and Ψ. Hence for every Ψ, bg induces a bijection between DG′(A[Ψ]) and DG(A).\nBy construction, the new start symbol is S[∅]; hence for the elements of DG′, we\nset Ψ = ∅and by induction hypothesis we obtain that bg is bijective.\nSince bg pre-\nserves the structure of derivations and is a bijection we obtain [\nµ ◦g = bµ ◦bg. Hence\nJ(N ′, ∆, S[∅], P ′, µ ◦g)K = JGK. The fan-out is not increased by this construction.\n■\n3 Multiple Dyck languages\nAccording to Kanazawa [Kan14, Section 1] there is no deﬁnition of multiple Dyck lan-\nguages using congruence relations. We close this gap by giving such a deﬁnition (Deﬁn-\nition 3.3).\n3.1 The original deﬁnition\nWe recall the deﬁnition of multiple Dyck languages [YKS10, Deﬁnition 1]:\nDeﬁnition 3.1. Let ∆be a ﬁnite N-sorted set,2 (·) be a bijection between ∆and some\nalphabet ∆, k = maxδ∈∆sort(δ), and r ≥k. The multiple Dyck grammar with respect\n1This construction may therefore create productions of fan-out 0.\n2In Yoshinaka, Kaji, and Seki [YKS10], N-sorted sets are called indexed sets and sort is denoted as\ndim.\n8\nto ∆is the k-MCFG G∆=\n\u0000{A1, . . . , Ak}, b\n∆, A1, P\n\u0001\nwhere b\n∆= {δ[i], ¯δ[i] | δ ∈∆, i ∈\n[sort(δ)]}, sort(Ai) = i for every i ∈[k], and P is the smallest set such that\n(i) for every linear non-deleting3 terminal-free string function f ∈(F∆)(s1···sℓ,s) with\nℓ∈[r] and s1, . . . , sℓ, s ∈[k] we have\nAs →f(As1, . . . , Asℓ) ∈P ,\n(ii) for every δ ∈∆with sort s we have\nAs →\n\u0002\nδ[1]x1\n1¯δ[1], . . . , δ[s]xs\n1¯δ[s]\u0003\n(As) ∈P , and\n(iii) for every s ∈[k] we have\nAs →[u1, . . . , us](As) ∈P\nwhere ui ∈\n\b\nxi, xiδ[1]¯δ[1], δ[1]¯δ[1]xi | δ ∈∆1\n\t\nfor every i ∈[s].\nThe multiple Dyck language with respect to ∆, denoted by mD(∆), is L(G∆). We call\nmaxδ∈∆sort(δ) the dimension of mD(∆). The set of multiple Dyck languages of dimen-\nsion at most k is denoted by k-mDYCK.\n□\n3.2 Congruence multiple Dyck languages\nFor the rest of this section let Σ be an alphabet. Also let Σ be a set (disjoint from Σ)\nand (·) be a bijection between Σ and Σ. Intuitively Σ and Σ are sets of opening and\nclosing parentheses and (·) matches an opening to its closing parenthesis.\nWe deﬁne ≡Σ as the smallest congruence relation on the free monoid (Σ ∪Σ)∗where\nfor every σ ∈Σ the cancellation rule σσ ≡Σ ε holds. The Dyck language with respect to\nΣ, denoted by D(Σ), is [ε]≡Σ. The set of Dyck languages is denoted by DYCK.\nExample 3.2. Let Σ = {(, ⟨, [, J}.\nWe abbreviate ¯(, ¯⟨, ¯[, and ¯J by ), ⟩, ], and K,\nrespectively. Then we have for example J()K⟨⟩() ≡Σ JK⟨⟩≡Σ JK ≡Σ ε and (J)K⟨⟩() ≡Σ\n(J)K() ≡Σ (J)K ̸≡Σ ε.\n□\nLet P be a partition of Σ. We deﬁne ≡Σ,P as the smallest congruence relation on\nthe free monoid (Σ ∪Σ)∗such that if v1 · · · vℓ≡Σ,P ε with v1, . . . , vℓ∈D(Σ), then the\ncancellation rule\nu0σ1v1σ1u1 · · · σℓvℓσℓuℓ≡Σ,P u0 · · · uℓ\nholds for every {σ1, . . . , σℓ} ∈P and u0, . . . , uℓ∈D(Σ). Intuitively, every element of\nP denotes a set of linked opening parentheses, i.e. parentheses that must be consumed\nsimultaneously by ≡Σ,P.\n3We add the restriction “non-deleting” in comparison to the original deﬁnition since the proof of\nLemma 1 in Yoshinaka, Kaji, and Seki [YKS10] only uses non-deleting rules.\n9\nDeﬁnition 3.3. The congruence multiple Dyck language with respect to Σ and P, de-\nnoted by mDc(Σ, P), is [ε]≡Σ,P.\n□\nExample 3.4. Let Σ = {(, ⟨, [, J} and P = {p1, p2} where p1 = {(, ⟨} and p2 = {[, J}.\nWe abbreviate ¯(, ¯⟨, ¯[, and ¯J by ), ⟩, ], and K, respectively. Then we have for example\nJ()K[⟨⟩] ≡Σ,P ε since p2 = {[, J} ∈P, ()⟨⟩≡Σ,P ε, and u0 = u1 = u2 = ε.\nBut\nJ()K⟨[]⟩̸≡Σ,P ε since when instantiating the cancellation rule with any of the two elements\nof P, we can not reduce J()K⟨[]⟩:\n(i) If we choose {σ1, σ2} = {J, [} then we would need to set u1 = ⟨and u2 = ⟩, but\nthey are not in D(Σ), also () ̸≡Σ,P ε;\n(ii) If we choose {σ1, σ2} = {(, ⟨} then we would need to set u0 = J and u1 = K, but\nthey are not in D(Σ), also [] ̸≡Σ,P ε.\nHence J()K[⟨⟩], ()⟨⟩∈mDc(Σ, P) and J()K⟨[]⟩/∈mDc(Σ, P).\n□\nObservation 3.5. From the deﬁnition of ≡Σ,P it is easy to see that for every u1, . . . , uk ∈\nD(Σ) and v1, . . . , vℓ∈D(Σ) we have that u1 · · · uk, v1 · · · vℓ∈mDc(Σ, P) implies that\nevery permutation of u1, . . . , uk, v1, . . . , vℓis in mDc(Σ, P).\n■\nThe dimension of mDc(Σ, P) is maxp∈P|p|.\nThe set of congruence multiple Dyck\nlanguages (of at most dimension k) is denoted by mDYCKc (k-mDYCKc, respectively).\nProposition 3.6. k-mDYCK ⊆k-mDYCKc\nProof. We show that a tuple (w1, . . . , wm) can be generated in G∆from non-terminal\nAm if and only if w1, . . . , wm are all Dyck words and w1 · · · wm is a multiple Dyck\nword. The “only if” we prove by induction on the structure of derivations in G∆. For\n“if” we construct derivations in G∆by induction on the number of applications of the\ncancellation rule (including the number of applications to reduce the word v1 · · · vℓfrom\nthe deﬁnition on the cancellation rule to ε).\nLet mD ∈k-mDYCK. Then there is an N-sorted set ∆such that mD = mD(∆) and\nk ≥maxδ∈∆sort(δ). We deﬁne pδ = {δ[i] | i ∈[sort(δ)]} for every δ ∈∆, Σ = S\nδ∈∆pδ,\nand P = {pδ | δ ∈∆}. Clearly maxp∈P|p| ≤k. Thus mDc(Σ, P) ∈k-mDYCK. Let\nTup(G∆, A) denote the set of tuples generated in G∆when starting with non-terminal\nA where A is not necessarily initial.\nIn the following we show that for every m ∈\n[maxδ∈∆sort(δ)] and w1, . . . , wm ∈(Σ ∪¯Σ)∗:\n(w1, . . . , wm) ∈Tup(G∆, Am) ⇐⇒w1 · · · wm ∈mDc(Σ, P) ∧w1, . . . , wm ∈D(Σ) (*)\n(⇒)\nIt follows from the deﬁnitions of Tup and G∆that (w1, . . . , wm) ∈Tup(G∆, Am)\nimplies that there are a rule Am →f(Am1, . . . , Amℓ) in G∆and a tuple ⃗ui = (u1\ni , . . . , umi\ni )\nin Tup(G∆, Ami) for every i ∈[ℓ] such that f(⃗u1, . . . , ⃗uℓ) = (w1, . . . , wm). By applying\nthe induction hypothesis ℓtimes, we also have that u1\n1, . . . , um1\n1 , . . . , u1\nℓ, . . . , umℓ\nℓ\n∈D(Σ)\nand u1\n1 · · · um1\n1 , . . . , u1\nℓ· · · umℓ\nℓ\n∈mD(Σ, P). We distinguish three cases (each correspond-\ning to one type of rule in G∆):\n10\n(i) f is linear, non-deleting, and terminal-free. Then we have for every i ∈[m] that\nwi ∈{u1\n1, . . . , um1\n1 , . . . , u1\nℓ, . . . , umℓ\nℓ}∗and therefore also wi ∈D(Σ). Furthermore,\nby applying Observation 3.5 (ℓ−1) times, we have that w1 · · · wm ∈mDc(Σ, P).\n(ii) f = [δ[1]x1\n1¯δ[1], . . . , δ[m]xm\n1 ¯δ[m]]; then ℓ= 1, m1 = m, and for every i ∈[m] we have\nwi = δ[i]ui\n1¯δ[i] and since ui\n1 ∈D(Σ) also wi ∈D(Σ). Furthermore, w1 · · · wm =\nδ[1]u1\n1¯δ[1] · · · δ[m]um\n1 ¯δ[m] ∈mDc(Σ, P) due to the cancellation rule.\n(iii) f = [u1, . . . , um] where ui ∈\n\b\nx1\ni , x1\ni δ[1]¯δ[1], δ[1]¯δ[1]x1\ni | δ ∈∆1\n\t\nfor every i ∈[m];\nthen wi ∈\n\b\nu1\ni , u1\ni δ[1]¯δ[1], δ[1]¯δ[1]u1\ni | δ ∈∆1\n\t\nfor every i ∈[m], ℓ= 1, and m1 = m.\nSince ≡Σ is a congruence relation (in particular, ≡Σ respects composition), we\nhave that w1, . . . , wm ∈D(Σ). By applying Observation 3.5 m times, we have\nthat w1 · · · wm ∈mDc(Σ, P).\n(⇐)\nIf the cancellation rule is applied zero times in order to reduce w1 · · · wm to ε then\nw1 = . . . = wm = ε. The rule Am →[ε, . . . , ε]() in GD clearly derives (w1, . . . , wm). If the\ncancellation rule is applied i + 1 times in order to reduce w1 · · · wm to ε then w1 · · · wm\nhas the form u0σ1v1σ1u1 · · · σℓvℓσℓuℓfor some u0, . . . , uℓ∈D(Σ), v1, . . . , vℓ∈D(Σ),\nand {σ1, . . . , σℓ} ∈P with v1 · · · vℓ≡Σ,P ε. Then we need to apply the cancellation rule\nat most i times to reduce v1 · · · vℓto ε, hence, by induction hypothesis, there is some\nd ∈DG∆that derives (v1, . . . , vℓ). We use an appropriate rule ρ of type (ii) such that ρ(d)\nderives (σ1v1σ1, . . . , σℓvℓσℓ). Also, we need to apply the cancellation rule at most i times\nin order to reduce u0 · · · uℓto ε, hence, by induction hypothesis, there are derivations\nd1, . . . , dn that derive tuples containing exactly u0, . . . , uℓas components. Then there is\na rule ρ′ of type (iii) such that ρ′(ρ(d), d1, . . . , dn) ∈DG∆derives the tuple (w1, . . . , wm).\nFrom (*) with m = 1 and the fact “w1 ∈mDc(Σ, P) implies w1 ∈D(Σ)” we get that\nmDc(Σ, P) = mD.\n■\nLemma 3.7. k-mDYCKc ⊆k-MCFL\nProof idea. For a given congruence multiple Dyck language L, we construct a multiple\nDyck grammar that is equivalent up to a homomorphism g. We then use the closure of\nk-MCFL under homomorphisms.\nProof. Let L ∈k-mDYCKc. Then there are an alphabet Σ and a partition P of Σ such\nthat mDc(Σ, P) = L. Consider P as an N-sorted set where the sort of an element is its\ncardinality. Then b\n∆= {p[i], ¯p[i] | p ∈P, i ∈[|p|]}. For every p ∈P assume some ﬁxed\nenumeration of the elements of p. We deﬁne a bijection g : b\n∆→Σ ∪Σ such that every\np[i] (for some p and i) is assigned the i-th element of p and g(¯p[i]) = g(p[i]).\nLet Tupg(GP) denote the set of tuples obtained by interpreting the terms correspond-\ning to every subderivation in GP and then applying g to every component. We show the\nfollowing claim by induction:\nw ∈mD(P) ⇐⇒∀ℓ∈N, u0, . . . , uℓ, w1, . . . , wℓ∈D(Σ)\nwith w = u0w1u1 · · · wℓuℓ:\n(u0, w1, u1, · · · , wℓ, uℓ) ∈Tupg(GP)\n(IH)\n11\nNote that in the following the indices of the elements of p = {σ1, . . . , σℓ} are chosen such\nthat they respect the previously ﬁxed enumeration of p, i.e. for every i ∈[ℓ] : g(p[i]) = σi.\nWe derive\nw ∈mD(P)\n⇐⇒∀ℓ∈N, u0, . . . , uℓ, v1, . . . , vℓ∈D(Σ), p = {σ1, . . . , σℓ} ∈P with\nw = u0σ1v1σ1u1 · · · σℓvℓσℓuℓ: u0v1u1 · · · vℓuℓ∈mD(P)\n(by def. of mD(P))\n⇐⇒∀ℓ∈N, u0, . . . , uℓ, v1, . . . , vℓ∈D(Σ), p = {σ1, . . . , σℓ} ∈P with\nw = u0σ1v1σ1u1 · · · σℓvℓσℓuℓ: (u0, v1, u1, . . . , vℓ, uℓ) ∈Tupg(GP)\n(by (IH))\n⇐⇒∀ℓ∈N, u0, . . . , uℓ, v1, . . . , vℓ∈D(Σ), p = {σ1, . . . , σℓ} ∈P with\nw = u0σ1v1σ1u1 · · · σℓvℓσℓuℓ:\n(u0, σ1v1σ1, u1, . . . , σℓvℓσℓ, uℓ) ∈Tupg(GP)\n(by def. of GP)\n⇐⇒∀ℓ∈N, u0, . . . , uℓ, w1, . . . , wℓ∈D(Σ) with w = u0w1u1 · · · wℓuℓ:\n(u0, w1, u0, . . . , wℓ, uℓ) ∈Tupg(GP)\n(using permuting productions in GP)\ng(L(GP)) = L follows by instantiating (IH) for ℓ= 0 and discovering that {t | (t) ∈\nTupg(GP)} = g(L(GP)).\nSince k-MCFLs are closed under homomorphisms [SMFK91, Theorem 3.9], we know\nthat L ∈k-MCFL.4\n■\nObservation 3.8. Examining the deﬁnition of multiple Dyck grammars, we observe\nthat some production in Item (ii) has fan-out k for at least one δ ∈∆. Then, using Seki,\nMatsumura, Fujii, and Kasami [SMFK91, Theorem 3.4], we have for every k ≥1 that\n(k + 1)-mDYCKc \\ k-MCFL ̸= ∅.\n■\nProposition 3.9. DYCK = 1-mDYCKc ⊊2-mDYCKc ⊊. . .\nProof. We get ‘⊆’ from the deﬁnition of k-mDYCKc and ‘̸=’ from Observation 3.8. We\nhave the equality since the dimension of some partition P of Σ is 1 if and only if\nP = {{σ} | σ ∈Σ}. Then we have ≡Σ = ≡Σ,P and thus D(Σ) = mDc(Σ, P). Hence\nDYCK = 1-mDYCKc.\n■\n3.3 Membership in a congruence multiple Dyck language\nWe provide a recursive algorithm (Algorithm 3) to decide whether a word w is in a given\ncongruence multiple Dyck language mDc(Σ, P).\nThis amounts to checking whether\nw ≡Σ,P ε, and it suﬃces to only apply the cancellation rule from left to right.\nIn order for Algorithm 3 to decide the membership in a multiple Dyck language it\nmust consider all decompositions of the input string into Dyck words. For this purpose\nwe deﬁne a function split that decomposes a given Dyck word into shortest, non-empty\nDyck words.\n4This construction shows that congruence multiple Dyck languages (Deﬁnition 3.3) are equivalent to\nmultiple Dyck languages [YKS10, Deﬁnition 1] up to the application of g.\n12\nThe function split\nAs Dyck languages are recognisable by pushdown automata, we deﬁne a data structure\npushdown and two functions with side-eﬀects on pushdowns. A pushdown is a string\nover some alphabet Γ. Let Γ be an alphabet, γ ∈Γ, and pd ⊆Γ ∗be a pushdown.\n• pop(pd) returns the left-most symbol of pd and removes it from pd.\n• push(pd, γ) prepends γ to pd.\nNote that pop() is only a partial function, it is undeﬁned for pd = ε. But since the input\nword w is required to be in D(Σ) by Algorithm 2, the expression on line 6 is always\ndeﬁned.\nAlgorithm 2 Algorithm to split a word in D(Σ) into shortest non-empty strings from\nD(Σ)\nInput: alphabet Σ, Dyck word w ∈D(Σ)\nOutput: sequence (u1, . . . , uℓ) of shortest, non-empty Dyck words with w = u1 · · · uℓ\n1: function split(Σ, w)\n2:\nlet pd = ε, j = 1, and uj = ε\n3:\nfor 0 ≤i ≤|w| do\n4:\nappend wi to uj\n5:\nif wi ∈Σ then\n6:\npop(pd)\n7:\nif pd = ε then\n8:\nincrease j by 1 and let uj = ε\n9:\nend if\n10:\nelse\n11:\npush(pd, wi)\n12:\nend if\n13:\nend for\n14:\nreturn (u1, . . . , uj−1)\n15: end function\nOne can easily see that split is bijective (the inverse function is concatenation). We\ntherefore say that w and (u1, . . . , uℓ) correspond to each other, and for every operation\non either of them there is a corresponding operation on the other. In particular the\nempty string corresponds to the empty tuple.\nOutline of the function isMember\nIf w is the empty word, we return 1 on line 2 since the empty word is in mDc(Σ, P). Then\nwe check if w is in D(Σ), e.g. with the context-free grammar in (7.6) in Salomaa [Sal73].\nIf w is not in D(Σ), it is also not in mDc(Σ, P) and we return 0. Otherwise, we split w\ninto shortest non-empty Dyck words (on line 4) using the function split. Since each of\n13\nAlgorithm 3 Function isMember to decide membership in mDc(Σ, P)\nInput: Σ, P, and w ∈(Σ ∪Σ)∗\nOutput: 1 if w ∈mDc(Σ, P), 0 otherwise\n1: function isMember(Σ, P, w)\n2:\nif w = ε then\nreturn 1\nend if\n3:\nif w ̸∈D(Σ) then\nreturn 0\nend if\n4:\n(σ1u1σ1, . . . , σℓuℓσℓ) ←split(Σ, w)\n⊲such that σ1, . . . , σℓ∈Σ\n5:\nI ←{I ⊆P([ℓ]) | I partition of [ℓ], ∀{i1, . . . , ik} ∈I : {σi1, . . . , σik} ∈P}\n6:\nfor I ∈I do\n7:\nb ←1\n8:\nfor {i1, . . . , ik} ∈I do\n⊲such that i1 < . . . < ik\n9:\nb ←b · isMember(Σ, P, ui1 · · · uik)\n10:\nend for\n11:\nif b = 1 then\nreturn 1\nend if\n12:\nend for\n13:\nreturn 0\n14: end function\nthose shortest non-empty Dyck words has the form σuσ for some σ ∈Σ and u ∈(Σ∪Σ)∗,\nwe write (σ1u1σ1, . . . , σℓuℓσℓ) for the left-hand side of the assignment on line 4. On line 5\nwe calculate the set I of all partitions I such that each element of I speciﬁes a set of\ncomponents of the tuple (σ1u1σ1, . . . , σℓuℓσℓ) whose outer parentheses can be removed\nwith one application of the cancellation rule. Since I is a partition, we know that the\nouter parentheses of every component can be removed via the cancellation rule. Then it\nremains to be shown that there is a partition I such that for each element {i1, . . . , ik} of\nI the word ui1 · · · uik is an element of mDc(Σ, P); this is done on lines 6 to 12. If there\nis no such partition, then we return 0 on line 13.\nExample 3.10 (Example 3.4 continued). Table 4 shows a run of Algorithm 3 on the\nword J()K[⟨⟩] where we report return values and a subset of the variable assignment\nwhenever we reach the end of lines 4, 5, 6, 8, 9. The recursive calls to isMember are\nindented. Table 5 shows the run of Algorithm 3 on the word J()K[]JK[⟨⟩].\n□\nIn light of the close link between Algorithm 3 and the relation ≡Σ,P we omit the proof\nof correctness.\nProof of termination for Algorithm 3. If w = ε, the algorithm terminates on line 2. If\nw ̸∈D(Σ), the algorithm terminates on line 3. Since I is ﬁnite and each element I ∈I is\nalso ﬁnite, there are only ﬁnitely many calls to isMember on line 9 for each recursion. In\neach of those calls, the length of the third argument is strictly smaller then the length of\nw. Therefore, after a ﬁnite number of recursions, the third argument passed to isMember\nis either the empty word, then the algorithm terminates on line 2, or not an element of\nD(Σ), then the algorithm terminates on line 2.\n■\n14\nTable 4: Run of Algorithm 3 on the word J()K[⟨⟩], cf. Examples 3.4 and 3.10.\nisMember(Σ, P, J()K[⟨⟩])\nl. 4:\nσ1 = J, σ2 = [, u1 = (), u2 = ⟨⟩\nl. 5:\nI =\n\b\b\n{1, 2}\n\t\t\nl. 6:\nI =\n\b\n{1, 2}\n\t\nl. 8:\nk = 2, i1 = 1, i2 = 2\nl. 9:\nb = 1 · isMember(Σ, P, ()⟨⟩)\nl. 4:\nσ1 = (, σ2 = ⟨, u1 = ε = u2\nl. 5:\nI =\n\b\b\n{1, 2}\n\t\t\nl. 6:\nI =\n\b\n{1, 2}\n\t\nl. 8:\nk = 2, i1 = 1, i2 = 2\nl. 9:\nb = 1 · isMember(Σ, P, ε)\nl. 2: return 1\nl. 9:\nb = 1 · 1 = 1\nl. 11: return 1\nl. 9:\nb = 1 · 1\nl. 11: return 1\n4 CS theorem for weighted MCFLs\nIn this section we generalise the CS representation of (unweighted) MCFLs [YKS10,\nTheorem 3] to the weighted case. We prove that an A-weighted MCFL L can be de-\ncomposed into an A-weighted alphabetic homomorphism h, a regular language R and a\ncongruence multiple Dyck language mDc such that L = h(R ∩mDc).\nTo show this, we use the proof idea from Droste and Vogler [DV13]: We separate the\nweight from our grammar formalism and then use the unweighted CS representation on\nthe unweighted part. The outline of our proof is as follows:\n(i) We separate the weights from L (Lemma 4.3), obtaining an MCFL L′ and a\nweighted alphabetic homomorphism.\n(ii) We use a corollary of the CS representation of (unweighted) MCFLs (Corollary 4.6)\nto obtain a CS representation of L′.\n(iii) Using the two previous points and a lemma for the composition of weighted and un-\nweighted alphabetic homomorphisms (Lemma 4.8), we obtain a CS representation\nof L (Theorem 4.10).\nFigure 6 outlines the proof of Theorem 4.10. The boxes represent sub-diagrams for\nwhich the corresponding lemma proofs existence of the arrows and commutativity.\n15\nTable 5: Run of Algorithm 3 on the word J()K[]JK[⟨⟩].\nisMember(Σ, P, J()K[]JK[⟨⟩])\nl. 4:\nσ1 = J = σ3, σ2 = [ = σ4, u1 = (), u2 = ε = u3, u4 = ⟨⟩\nl. 5:\nI =\n\b\b\n{1, 2}, {3, 4}\n\t\n,\n\b\n{1, 4}, {2, 3}\n\t\t\nl. 6:\nI =\n\b\n{1, 2}, {3, 4}\n\t\nl. 8:\nk = 2, i1 = 1, i2 = 2\nl. 9:\nb = 1 · isMember(Σ, P, ())\nl. 4:\nσ1 = (, u1 = ε\nl. 5:\nI = ∅\nl. 13: return 0\nl. 9:\nb = 1 · 0 = 0\nl. 8:\nk = 2, i1 = 3, i2 = 4\nl. 9:\nb = 0 · isMember(Σ, P, ⟨⟩)\nl. 4:\nσ1 = ⟨, u1 = ε\nl. 5:\nI = ∅\nl. 13: return 0\nl. 9:\nb = 0 · 0 = 0\nl. 6:\nI =\n\b\n{1, 4}, {2, 3}\n\t\nl. 8:\nk = 2, i1 = 1, i2 = 4\nl. 9:\nb = 1 · isMember(Σ, P, ()⟨⟩)\nl. 4:\nσ1 = (, σ2 = ⟨, u1 = ε = u2\nl. 5:\nI =\n\b\b\n{1, 2}\n\t\t\nl. 6:\nI =\n\b\n{1, 2}\n\t\nl. 8:\nb = 1 · isMember(Σ, P, ε)\nl. 2: return 1\nl. 8:\nb = 1 · 1\nl. 11: return 1\nl. 9:\nb = 1 · 1\nl. 8:\nk = 2, i1 = 2, i2 = 3\nl. 9:\nb = 1 · isMember(Σ, P, ε)\nl. 2:\nreturn 1\nl. 9:\nb = 1 · 1\nl. 11: return 1\n16\n∆∗→A\nΓ ∗\n(Σ ∪¯Σ)∗\nL(G)\nL(GB)\nR(GB) ∩mD(GB)\nDG\nDGB\nweightsG\nhomGB\nh\nweightsG\ntoDeriv\nhomGB\nfromBrackets\n(yield, ˆµ)\nf\nyield\ntoBrackets\n⊆\n⊆\n∈\nLemma 4.3\nCorollary 4.6 and Lemma 4.7\nLemma 4.8\nFigure 6: Outline of the proof of Theorem 4.10\n4.1 Separating the weights\nWe split a given weighted MCFG G into an unweighted MCFG GB and a weighted\nhomomorphism weightsG such that JGK = weightsG(L(GB)).\nDeﬁnition 4.1. Let G = (N, ∆, S, P, µ) be a non-deleting A-weighted k-MCFG. The\nunweighted MCFG for G is the non-deleting k-MCFG GB = (N, Γ, S, P ′) where Γ =\n∆∪{ρi | ρ ∈P, i ∈[fan-out(ρ)]} and P ′ is the smallest set such that for every production\nρ = A →[u1, . . . , us](A1, . . . , Am) ∈P there is a production\nA →[ρ1u1, . . . , ρsus](A1, . . . , Am) ∈P ′.\n□\nDeﬁnition 4.2. Let G = (N, ∆, S, P, µ) be a non-deleting A-weighted MCFG. The\nweight homomorphism for G is the A-weighted alphabetic homomorphism weightsG :\nΓ ∗→(∆∗→A) where weightsG(δ) = 1.δ, weightsG(ρ1) = µ(ρ).ε, and weightsG(ρi) =\n1.ε for every δ ∈∆, ρ ∈P and i ∈{2, . . . , fan-out(ρ)}.\n□\nL(GB) stands in bijection to DG via the function toDeriv given in Algorithm 7.\nLemma 4.3. k-MCFL(A) = αHOM(A)\n\u0000k-MCFL\n\u0001\nProof. (⊆)\nLet L ∈k-MCFL(A). By Lemma 2.7 there is a non-deleting A-weighted\nk-MCFG G = (N, ∆, S, P, µ) such that JGK = L. Let f be the function obtained by\napplying the construction of the rules in GB position-wise to a derivation in DG. For\nevery w ∈L(GB) we can calculate the corresponding derivation t in G (as a function with\ndomain dom(t) and labelling function t) using toDeriv (Algorithm 7), hence yield ◦f is\nbijective. We derive for every w ∈∆∗:\nL(w) = JGK(w)\n= P\nd∈DG(w) µ(d)\n17\nAlgorithm 7 Function toDeriv to calculate for every word in L(GB) the corresponding\nderivation in DG, cf. Lemma 4.3\nInput: w ∈L(GB)\nOutput: derivation tree t ∈DG corresponding to w (represented as a partial function\nfrom N∗to P)\n1: function toDeriv(w)\n2:\nlet t be the empty function\n3:\ndescend(t, ε, 1)\n4:\nreturn t\n5: end function\n6: procedure descend(t : N∗→P, π ∈N∗, j ∈N)\n7:\nlet ρ = A →[u1, . . . , us](A1, . . . , Ak) ∈P and u such that ρju = w\n8:\nadd the assignment π 7→ρ to t\n9:\nremove ρj from the beginning of w\n10:\nfor every symbol δ′ in uj do\n11:\nif δ′ ∈∆then\n12:\nremove δ′ from the beginning of w\n13:\nelse\n14:\nlet i, j′ such that xj′\ni = δ′\n15:\ndescend(t, πi, j′)\n16:\nend if\n17:\nend for\n18: end procedure\n= P\nd∈DG(weightsG ◦yield ◦f)(d)(w)\n(by †)\n= P\nd∈DG,u∈L(GB)\nu=(yield ◦f)(d)\nweightsG(u)(w)\n= P\nu∈L(GB) weightsG(u)(w)\n(L(GB) and DG are in bijection)\n= weightsG(L(GB))(w)\nFor †, one can immediately see from the deﬁnitions of f, yield, and weightsG that for\nevery w ∈∆∗we have (weightsG ◦yield ◦f)(d)(w) = µ(d) if d ∈DG(w) and (weightsG ◦\nyield ◦f)(d)(w) = 0 otherwise. Hence L = weightsG(L(GB)).\n(⊇)\nLet L ∈k-MCFL and h : Γ ∗→(∆∗→A) be an A-weighted alphabetic homo-\nmorphism. By Seki, Matsumura, Fujii, and Kasami [SMFK91, Lemma 2.2] there is a non-\ndeleting k-MCFG G = (N, Γ, S, P) such that L(G) = L. We construct the A-weighted\nk-MCFG G′ = (N, ∆, S, P ′, µ) as follows: We extend h to h′ : (Γ ∪X)∗→((∆∪X)∗→A)\nwhere h′(x) = 1.x for every x ∈X and h′(γ) = h(γ) for every γ ∈Γ. We deﬁne P ′ as\nthe smallest set such that for every ρ = A →[u1, . . . , us](A1, . . . , Am) ∈P(s1···sm,s) and\n(u′\n1, . . . , u′\ns) ∈supp(h′(u1)) × . . . × supp(h′(us)) we have that P ′ contains the production\nρ′ = A →[u′\n1, . . . , u′\ns](A1, . . . , Am) and µ(ρ′) = h′(u1)(u′\n1) · . . . · h′(us)(u′\ns). Since · is\ncommutative and G is non-deleting, we obtain JG′K = h(L(G)).\n■\n18\nBy setting k = 1 in the above lemma we reobtain the equivalence of 1 and 3 in\nTheorem 2 of Droste and Vogler [DV13] for the case of complete commutative strong\nbimonoids.\nExample 4.4. Recall the Pr2-weighted MCFG G from Example 2.6. By Deﬁnitions 4.1\nand 4.2 we obtain the MCFG GB =\n\u0000N, Γ, S, P ′\u0001\nwhere\nΓ = {a, b, c, d, ρ1\n1, ρ1\n2, ρ2\n2, ρ1\n3, ρ2\n3, ρ1\n4, ρ2\n4, ρ1\n5, ρ2\n5}\nand P ′ is given by\nP ′ : ρ′\n1 = S →[ρ1\n1x1\n1x1\n2x2\n1x2\n2](A, B)\nρ′\n2 = A →[ρ1\n2ax1\n1, ρ2\n2cx2\n1](A)\nρ′\n4 = A →[ρ1\n4, ρ2\n4]()\nρ′\n3 = B →[ρ1\n3bx1\n1, ρ2\n3dx2\n1](B)\nρ′\n5 = B →[ρ1\n5, ρ2\n5](),\nand the A-weighted alphabetic homomorphism weightsG : Γ ∗→(∆∗→A) where\nweightsG is given for every γ ∈Γ and ω ∈∆∪{ε} by\nweightsG(γ)(ω) =\n\n\n\n\n\n\n\n\n\n\n\nµ(ρi)\nif γ = ρ1\ni and ω = ε for 1 ≤i ≤5\n1\nif γ = ρ2\ni and ω = ε for 2 ≤i ≤5\n1\nif γ ∈∆and ω = γ\n0\notherwise,\nNow consider the (only) derivation d = ρ1\n\u0000ρ2(ρ4), ρ5\n\u0001\nof w = ac. Then\nf(d) = ρ′\n1\n\u0000ρ′\n2(ρ′\n4), ρ′\n5\n\u0001\n=: d′,\ng(d′) = ρ1\n1 ρ1\n2 a ρ1\n4 ρ1\n5 ρ2\n2 c ρ2\n4 ρ2\n5\n=: w′, and\nweightsG(w′) = (1 · 1/2 · 1 · 1/2 · 2/3 · 1 · 1 · 1 · 1).w\n= (1/6).w .\n□\n4.2 Strengthening the unweighted CS representation\nYoshinaka, Kaji, and Seki [YKS10] deﬁne (in Section 3.2) an indexed alphabet ∆, a right-\nlinear regular grammar R, and a homomorphism h for some given non-deleting MCFG\nG that has no rule with at least two identical non-terminals on the right-hand side. We\nwill sometimes write homG instead of h to highlight the connection to G. Let S be the\ninitial non-terminal of G. Then R can be viewed as an automaton M(G) by setting S\nas the initial state, T as ﬁnal state, and having for every rule A →wB in R (where A\nand B are non-terminals and w is a terminal string) a transition (A, w, B) in M(G). For\nevery MCFG G with the above three properties we deﬁne the generator automaton with\nrespect to G as M(G) and the generator language with respect to G as R(G) = L(M(G)).\nNote that M(G) is deterministic. We call b\n∆the generator alphabet with respect to G.\nBy Proposition 3.6 we know that L(D∆) [YKS10, Deﬁnition 1] is a congruence multiple\nDyck language, we will denote it by mD(G) to highlight its connection to the MCFG G.\nFor every terminal symbol γ ∈Γ, let ˜γ abbreviate the string J[1]\nγ K[1]\nγ . We give an example\nto show how the above considerations are used.\n19\nExample 4.5 (Examples 4.4 and 2.6 continued). Figure 8 shows the FSA M(G′). An\nedge labelled with a set L of words denotes a set of transitions each reading a word in\nL. Note that R(G′) is not ﬁnite. Let Σ be the generator alphabet with respect to G′\nThe homomorphism homGB : Σ →Γ ∗is given by\nhomGB(σ) =\n(\nγ\nif σ = Jγ for some γ ∈Γ\nε\notherwise.\n□\nThe following is a corollary to Yoshinaka, Kaji, and Seki [YKS10, Theorem 3] where\n“homomorphism” is replaced by an “alphabetic homomorphism” and “multiple Dyck\nlanguage” is replaced by “congruence multiple Dyck language”.\nCorollary 4.6. Let L be a language and k ∈N. Then the following are equivalent:\n(i) L ∈k-MCFL\n(ii) there are an alphabetic homomorphism h2, a regular language R, and a congruence\nmultiple Dyck language mDc of at most dimension k with L = h2(R ∩mDc).\nProof. The construction of the homomorphism in Yoshinaka, Kaji, and Seki [YKS10,\nSection 3.2] already satisﬁes the deﬁnition of an alphabetic homomorphism. We may\nuse a congruence multiple Dyck language instead of a multiple Dyck language since, for\n(i) ⇒(ii), k-mDYCK ⊆k-mDYCKc (Proposition 3.6) and, for (ii) ⇒(i), k-mDYCKc ⊆\nk-MCFL (Lemma 3.7) and k-MCFL is closed under intersection with regular languages\nand under homomorphisms [SMFK91, Theorem 3.9].\n■\nLemma 4.7. For every MCFG G, there is a bijection between DG and R(G) ∩mD(G).\nProof. The constructions in Lemmas 1 and 3 in Yoshinaka, Kaji, and Seki [YKS10]\nalready hint on the bijection between R(G) ∩mD(G) and DG, we will merely point\nout the respective functions toBrackets : DG →R(G) ∩mD(G) and fromBrackets :\nR(G) ∩mD(G) →DG here.\nWe examine the proof of Lemma 1 in Yoshinaka, Kaji, and Seki [YKS10].\nThey\nconstruct for every rule A →f(B1, . . . , Bk) in G and all tuples ¯u1, . . . , ¯uk that are\ngenerated by B1, . . . , Bk, respectively, a new tuple ¯u = (u1, . . . , um) such that ¯u ∈L(G∆),\nfor each i ∈[m], M(G) recognises ui on the way from A[i] to T, and homG(¯u) =\nf(homG(τ1), . . . , homG(τk)), where homG is applied to tuples component-wise.\nNow\nwe only look at the initial non-terminal S. Then ¯u has only one component and this\nconstruction can be conceived as a function toBrackets : DG →R(G) ∩mD(G) such\nthat homG ◦toBrackets = yield.\nIn Lemma 3, Yoshinaka, Kaji, and Seki [YKS10] give a construction for the opposite\ndirection by recursion on the structure of derivations in G∆. In a similar way as above,\nwe view this construction as a function fromBrackets : R(G) ∩mD(G) →DG such that\nyield ◦fromBrackets = homG. Then homG ◦toBrackets ◦fromBrackets = homG, and\nhence toBrackets ◦fromBrackets is the identity on R(G) ∩mD(G).\n■\n20\nS[1]\nstart\nA[1]\nJ[1]\nρ′\n1 ˜ρ1\n1J[1]\nρ′\n1,1\nJ[1]\nρ′\n2 ˜ρ1\n2˜aJ[1]\nρ′\n2,1\nT\nJ[1]\nρ′\n4 ˜ρ1\n4K[1]\nρ′\n4\n\b\nK[2]\nρ′\n1,2K[1]\nρ1, K[1]\nρ′\n2,1K[1]\nρ′\n2,\nK[2]\nρ′\n2,1K[2]\nρ′\n2, K[1]\nρ′\n3,1K[1]\nρ′\n3, K[2]\nρ′\n3,1K[2]\nρ′\n3\n\t\nA[2]\nJ[2]\nρ′\n4 ˜ρ2\n4K[2]\nρ′\n4\nK[1]\nρ′\n1,2J[2]\nρ′\n1,1\nJ[2]\nρ′\n2 ˜ρ2\n2˜cJ[2]\nρ′\n2,1\nB[1]\nJ[1]\nρ′\n5 ˜ρ1\n5K[1]\nρ′\n5\nK[1]\nρ′\n1,1J[1]\nρ′\n1,2\nJ[1]\nρ′\n3 ˜ρ1\n3˜bJ[1]\nρ′\n3,1\nB[2]\nJ[2]\nρ′\n5 ˜ρ2\n5K[2]\nρ′\n5\nK[2]\nρ′\n1,1J[2]\nρ′\n1,2\nJ[2]\nρ′\n3 ˜ρ2\n3 ˜dJ[2]\nρ′\n3,1\nFigure 8: Automaton M(GB) (cf. Example 4.5)\n4.3 Composing the homomorphisms\nLemma 4.8. αHOM(A) ◦αHOM = αHOM(A)\nProof. (⊆)\nLet h1 : Γ ∗→(∆∗→A) be an alphabetic A-weighted homomorphism\nand h2 : Σ∗→Γ ∗be an alphabetic homomorphism. By the deﬁnitions of αHOM(A)\nand αHOM there must exist h′\n1 : Γ →(∆∪{ε} →A) and h′\n2 : Σ →Γ ∪{ε} such that\nc\nh′\n1 = h1 and c\nh′\n2 = h2. Since h1(rng(h′\n2)) ⊆(∆∪{ε} →A) there is some h ∈αHOM(A)\nsuch that h = h1 ◦h2; hence h1 ◦h2 ∈αHOM(A).\n(⊇)\nLet h : Σ →(Γ ∗→A) be an alphabetic A-weighted homomorphism. Clearly\ni : Σ∗→Σ∗with i(w) = w for every w ∈Σ∗is an alphabetic homomorphism. Then we\nhave h ◦i = h.\n■\nExample 4.9 (Examples 4.4 and 4.5 continued). The homomorphism h : (Σ ∪¯Σ)∗→\n(∆∗→A) obtained from weightsG : Γ ∗→(∆∗→A) and homGB : (Σ ∪¯Σ)∗→Γ ∗by\nthe construction for ⊆in Lemma 4.8 is given for every σ ∈Σ and ω ∈∆∪{ε} by\nh(σ)(ω) =\n\n\n\n\n\n\n\n\n\n\n\nµ(ρi)\nif σ = Jρ1\ni and ω = ε for some i ∈[5]\n1\nif σ /∈{Jρ1\ni | i ∈[5]} ∪{Jδ | δ ∈∆} and ω = ε\n1\nif σ = Jδ and ω = δ for some δ ∈∆\n0\notherwise.\n□\n21\n4.4 The weighted CS representation\nTheorem 4.10. Let L be an A-weighted language over Σ and k ∈N. The following\nare equivalent:\n(i) L ∈k-MCFL(A)\n(ii) there are an A-weighted alphabetic homomorphism h, a regular language R, and\na congruence multiple Dyck language mD of dimension at most k with L = h(R ∩\nmD).\nProof. (i) ⇒(ii)\nThere are some L′ ∈k-MCFL, h, h1 ∈αHOM(A), h2 ∈αHOM,\nmD ∈k-mDYCKc, and R ∈REG such that\nL = h1(L′)\n(by Lemma 4.3)\n= h1(h2(R ∩mD))\n(by Corollary 4.6)\n= h(R ∩mD)\n(by Lemma 4.8)\n(ii) ⇒(i)\nWe use Lemmas 4.3 and 3.7, and the closure of k-MCFG under intersection\nwith regular languages and application of homomorphisms.\n■\nProposition 4.11. For every A-weighted MCFG G, there is a bijection between DG\nand R(GB) ∩mD(GB).\nProof. There are bijections between DG and L(GB) by claims in the proof of Lemma 4.3,\nbetween L(GB) and DGB by claims in the proof of Lemma 4.3, and between DGB and\nR(GB) ∩mD(GB) by Lemma 4.7.\n■\n5 Conclusion and outlook\nWe deﬁned multiple Dyck languages using congruence relations in Deﬁnition 3.3, gave an\nalgorithm to decide whether a word is in a given multiple Dyck language in Algorithm 3,\nand established that multiple Dyck languages with increasing maximal dimension form\na hierarchy in Proposition 3.9.\nWe obtained a weighted version of the CS representation of MCFLs for complete com-\nmutative strong bimonoids (Theorem 4.10) by separating the weights from the weighted\nMCFG and using Yoshinaka, Kaji, and Seki [YKS10, Theorem 3] for the unweighted\npart.\nTheorem 4.10 and Proposition 4.11 may be used to derive a parsing algorithm for\nweighted multiple context-free grammars in the spirit of Hulden [Hul11].\nReferences\n[CS63]\nN. Chomsky and M. P. Sch¨utzenberger. The algebraic theory of context-free\nlanguages. Computer Programming and Formal Systems, Studies in Logic,\npages 118 – 161, 1963. DOI: 10.1016/S0049-237X(09)70104-1.\n22\n[Den15]\nT. Denkinger. A Chomsky-Sch¨utzenberger representation for weighted mul-\ntiple context-free languages. In Proceedings of the 12th International Confer-\nence on Finite-State Methods and Natural Language Processing (FSMNLP\n2015), 2015. URL: http://aclweb.org/anthology/W15-4803.\n[DPS79]\nJ. Duske, R. Parchmann, and J. Specht. A homomorphic characterization of\nindexed languages. Elektronische Informationsverarbeitung und Kybernetik,\n15(4):187–195, 1979.\n[DSV10]\nM. Droste, T. St¨uber, and H. Vogler.\nWeighted ﬁnite automata over\nstrong bimonoids.\nInformation Sciences, 180(1):156–166, 2010.\nDOI:\n10.1016/j.ins.2009.09.003.\n[DV13]\nM. Droste and H. Vogler.\nThe Chomsky-Sch¨utzenberger theorem for\nquantitative context-free languages.\nIn M.-P. B´eal and O. Carton, ed-\nitors, Proceedings of the 17th International Conference on Developments\nin Language Theory (DLT 2013), volume 7907 of Lecture Notes in Com-\nputer Science, pages 203–214. Springer Berlin Heidelberg, 2013.\nDOI:\n10.1007/978-3-642-38771-5_19.\n[FV15]\nS. Fratani and E. M. Voundy. Context-free characterization of indexed lan-\nguages. CoRR, abs/1409.6112, 2015. arXiv: 1409.6112.\n[FV16]\nS. Fratani and E. M. Voundy. Homomorphic characterizations of indexed\nlanguages.\nIn A.-H. Dediu, J. Janouˇsek, C. Mart´ın-Vide, and B. Truthe,\neditors, Proceedings of the 10th International Conference on Language and\nAutomata Theory and Applications (LATA 2015), pages 359–370. Springer\nScience + Business Media, 2016. DOI: 10.1007/978-3-319-30000-9_28.\n[HU69]\nJ. E. Hopcroft and J. D. Ullman. Formal languages and their relation to\nautomata. Addison-Wesley Longman Publishing Co., Inc., 1969.\n[HU79]\nJ. E. Hopcroft and J. D. Ullman. Introduction to automata theory, languages\nand computation. Addison-Wesley, 1st edition, 1979.\n[Hul11]\nM. Hulden.\nParsing CFGs and PCFGs with a Chomsky-Sch¨utzenberger\nrepresentation. In Z. Vetulani, editor, Human Language Technology. Chal-\nlenges for Computer Science and Linguistics, volume 6562 of Lecture Notes\nin Computer Science, pages 151–160. Springer Berlin Heidelberg, 2011. DOI:\n10.1007/978-3-642-20095-3_14.\n[HV15]\nL. Herrmann and H. Vogler.\nA Chomsky-Sch¨utzenberger theorem for\nweighted automata with storage.\nIn A. Maletti, editor, Proceedings of\nthe 6th International Conference on Algebraic Informatics (CAI 2015),\nvolume 9270, pages 90–102. Springer International Publishing, 2015. DOI:\n10.1007/978-3-319-23021-4_11.\n23\n[Kal10]\nL. Kallmeyer. Parsing beyond context-free grammars. Springer, 2010. DOI:\n10.1007/978-3-642-14846-0.\n[Kan14]\nM. Kanazawa. Multidimensional trees and a Chomsky-Sch¨utzenberger-weir\nrepresentation theorem for simple context-free tree grammars. Journal of\nLogic and Computation, Jun 2014. DOI: 10.1093/logcom/exu043.\n[Mic01a]\nJ. Michaelis.\nDerivational minimalism is mildly context-sensitive.\nIn\nM. Moortgat, editor, Logical Aspects of Computational Linguistics, volume\n2014 of Lecture Notes in Computer Science, pages 179–198. Springer Berlin\nHeidelberg, 2001. DOI: 10.1007/3-540-45738-0_11.\n[Mic01b]\nJ. Michaelis. Transforming linear context-free rewriting systems into min-\nimalist grammars.\nIn P. Groote, G. Morrill, and C. Retor´e, editors, Lo-\ngical Aspects of Computational Linguistics, volume 2099 of Lecture Notes in\nComputer Science, pages 228–244. Springer Berlin Heidelberg, 2001. DOI:\n10.1007/3-540-48199-0_14.\n[Moh00]\nM. Mohri.\nMinimization algorithms for sequential transducers.\nThe-\noretical\nComputer\nScience,\n234(1–2):177–201,\nMar\n2000.\nDOI:\n10.1016/s0304-3975(98)00115-7.\n[Sal73]\nA. Salomaa. Formal languages. Academic Press, 1973.\n[SMFK91] H. Seki, T. Matsumura, M. Fujii, and T. Kasami.\nOn multiple context-\nfree grammars. Theoretical Computer Science, 88(2):191–229, 1991. DOI:\n10.1016/0304-3975(91)90374-B.\n[SNK+93] H. Seki, R. Nakanishi, Y. Kaji, S. Ando, and T. Kasami. Parallel multiple\ncontext-free grammars, ﬁnite-state translation systems, and polynomial-time\nrecognizable subclasses of lexical-functional grammars. In Proceedings of the\n31st Annual Meeting of the Association for Computational Linguistics (ACL\n1993), ACL ’93, pages 130–139, Stroudsburg, PA, USA, 1993. Association for\nComputational Linguistics. DOI: 10.3115/981574.981592.\n[SS78]\nA. Salomaa and M. Soittola. Automata-Theoretic Aspects of Formal Power\nSeries. Springer New York, 1978. DOI: 10.1007/978-1-4612-6264-0.\n[VS87]\nK. Vijay-Shanker. A study of tree adjoining grammars. PhD thesis, 1987.\n[VSWJ86] K. Vijay-Shanker, D. J. Weir, and A. K. Joshi. Tree adjoining and head wrap-\nping. In Proceedings of the 11th Conference on Computational Linguistics\n(COLING 1986), pages 202–207. Association for Computational Linguistics,\n1986. DOI: 10.3115/991365.991425.\n[Wei88]\nD. J. Weir.\nCharacterizing mildly context-sensitive grammar formalisms.\nPhD thesis, 1988.\n24\n[WJ88]\nD. J. Weir and A. K. Joshi. Combinatory categorial grammars: Generat-\nive power and relationship to linear context-free rewriting systems. In Pro-\nceedings of the 26th Annual Meeting of the Association for Computational\nLinguistics (ACL 1988), pages 278–285. Association for Computational Lin-\nguistics, 1988. DOI: 10.3115/982023.982057.\n[YKS10]\nR. Yoshinaka, Y. Kaji, and H. Seki. Chomsky-Sch¨utzenberger-type charac-\nterization of multiple context-free languages. In A.-H. Dediu, H. Fernau, and\nC. Mart´ın-Vide, editors, Language and Automata Theory and Applications,\npages 596–607. Springer, 2010. DOI: 10.1007/978-3-642-13089-2_50.\n25\n",
  "categories": [
    "cs.FL"
  ],
  "published": "2016-06-13",
  "updated": "2016-11-28"
}