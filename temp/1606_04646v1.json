{
  "id": "http://arxiv.org/abs/1606.04646v1",
  "title": "Unsupervised Learning of Predictors from Unpaired Input-Output Samples",
  "authors": [
    "Jianshu Chen",
    "Po-Sen Huang",
    "Xiaodong He",
    "Jianfeng Gao",
    "Li Deng"
  ],
  "abstract": "Unsupervised learning is the most challenging problem in machine learning and\nespecially in deep learning. Among many scenarios, we study an unsupervised\nlearning problem of high economic value --- learning to predict without costly\npairing of input data and corresponding labels. Part of the difficulty in this\nproblem is a lack of solid evaluation measures. In this paper, we take a\npractical approach to grounding unsupervised learning by using the same success\ncriterion as for supervised learning in prediction tasks but we do not require\nthe presence of paired input-output training data. In particular, we propose an\nobjective function that aims to make the predicted outputs fit well the\nstructure of the output while preserving the correlation between the input and\nthe predicted output. We experiment with a synthetic structural prediction\nproblem and show that even with simple linear classifiers, the objective\nfunction is already highly non-convex. We further demonstrate the nature of\nthis non-convex optimization problem as well as potential solutions. In\nparticular, we show that with regularization via a generative model, learning\nwith the proposed unsupervised objective function converges to an optimal\nsolution.",
  "text": "Unsupervised Learning of Predictors from Unpaired\nInput-Output Samples\nJianshu Chen, Po-Sen Huang, Xiaodong He, Jianfeng Gao and Li Deng\nMicrosoft Research, Redmond, WA 98052, USA\n{jianshuc, pshuang, xiaohe, jfgao, deng}@microsoft.com\nAbstract\nUnsupervised learning is the most challenging problem in machine learning and\nespecially in deep learning. Among many scenarios, we study an unsupervised\nlearning problem of high economic value — learning to predict without costly\npairing of input data and corresponding labels. Part of the difﬁculty in this problem\nis a lack of solid evaluation measures. In this paper, we take a practical approach\nto grounding unsupervised learning by using the same success criterion as for\nsupervised learning in prediction tasks but we do not require the presence of paired\ninput-output training data. In particular, we propose an objective function that aims\nto make the predicted outputs ﬁt well the structure of the output while preserving\nthe correlation between the input and the predicted output. We experiment with a\nsynthetic structural prediction problem and show that even with simple linear clas-\nsiﬁers, the objective function is already highly non-convex. We further demonstrate\nthe nature of this non-convex optimization problem as well as potential solutions.\nIn particular, we show that with regularization via a generative model, learning with\nthe proposed unsupervised objective function converges to an optimal solution.\n1\nIntroduction\nUnsupervised learning, one major branch of machine learning involving learning without labeled\ndata or without costly pairing input-output training data, has been a long standing research over\ndecades. But it has achieved much less success compared with supervised learning that requires\npaired training data. Part of the difﬁculty in unsupervised learning is a lack of solid evaluation\nmeasures in the past. In this paper, we take a practical approach to grounding unsupervised learning\nusing the same evaluation measure as that for supervised learning in prediction tasks without requiring\npaired input-output training samples. If successful, the beneﬁt of such unsupervised learning would\nbe tremendous. For example, in large scale commercial speech recognition systems, the currently\ndominant supervised learning methods typically require a few thousand hours of training material\nwhere each utterance in the acoustic form needs to be explicitly labeled with the corresponding word\nsequence by human. Although there are millions of hours of natural speech data available for training,\nlabeling all of such acoustic data followed by supervised learning is simply not feasible. To make\neffective use of such huge amounts of acoustic data in speech recognition, the practical unsupervised\nlearning approach outlined above would be called for.\nIn recent years, supervised learning has shown great successes in several major prediction tasks\nincluding speech recognition [13, 8], image recognition [20, 33], machine translation [28, 1], spoken\nlanguage understanding [23, 22], and image captioning [10, 17, 30, 31]. These successes rely heavily\non training highly expressive deep learning models using large amounts of labeled training data. That\nis, the training examples are input-output pairs, where the outputs are labels obtained typically by\ncostly manual annotations. Unsupervised learning, however, is not as successful on these prediction\ntasks, although it has found other useful applications such as clustering [32], text analysis [5], etc.\nThe majority of the work on unsupervised learning for prediction tasks in the past has been to\narXiv:1606.04646v1  [cs.LG]  15 Jun 2016\nexploit the learned representations of the input data as feature vectors which are subsequently fed\nto a separate classiﬁer; e.g., [21]. This approach, albeit widely used, is usually less effective than\nend-to-end learning with labeled data [6]. Another important line of work on using unsupervised\nlearning to help prediction is pre-training, where an unsupervised model trained using unlabeled data\nis used to initialize a separate supervised learning algorithm [15, 3, 2, 24, 9]. Pre-training is shown\nto be effective only when there is a small amount of labeled data available [13]. In prediction tasks\nwith large amounts of paired training data, all the above unsupervised methods have played only an\nauxiliary role in helping supervised learning.\nIn this paper, we consider the unsupervised learning problem from a new and practical perspective.\nThat is, instead of using unsupervised learning as an auxiliary step for supervised learning, we aim\nto develop an unsupervised learning algorithm that learns the input-to-output mapping (i.e., the\npredictor) from unpaired input-output training samples. Our approach has tremendous economic\nvalue in that it allows us to use a large amount of unlabeled data directly for prediction tasks. As\nwe proceed to show in the paper, this is a very challenging problem since no clear and effective\ncost function has been established for such a problem in the literature. This paper represents our\ninitial attempt to address this challenge by exploiting the sequence structure of the output samples\nto learn the predictor. This is dramatically different from most previous work which often exploits\nthe structure of the input samples. The objective function we deﬁned aims to make the predicted\noutputs ﬁt well the structure of the output (e.g., a sequence structure that is learned separately using\nonly output samples), while preserving the correlation between the input data and the predicted\noutput labels. We will give a detailed study of this objective function on a predictive task in order to\nunderstand the nature and difﬁculties of the problem, as well as its potential solutions.\n2\nRelated Work\nFor unsupervised learning applied to prediction and related tasks, several main approaches have\nbeen taken in the past. An important line of research has been to focus on exploiting the structure\nof input data by learning the data distribution using maximum likelihood rule. The most successful\nexamples in this category include the restricted Boltzmann machine (RBM) [26, 15], the deep belief\nnetwork [14], topic models [5], etc. The main technical challenge of these methods is the difﬁculty\nof computing the gradient of the likelihood function exactly. For this reason, various approximate\nmethods have been developed, such as variational inference [16] and Monte Carlo methods [12].\nAnother important development is the methods that avoid the difﬁculties that arise in using maximum\nlikelihood rule as the direct learning objective. These methods include autoencoder [2], denoising\nautoencoder [29], variational autoencoder [18], and generative adversarial network (GAN) [11].\nHowever, these methods have been developed also aiming to model the input data distribution instead\nof learning the input-to-output mapping from unpaired input-output data.\nA recent study that is more closely related to what we describe in this paper is [27], which proposes\nthe output distribution matching (ODM) as an alternative unsupervised learning objective to the\nlikelihood function of the data. The ODM cost function measures how well the distribution of each\npredicted output sample matches the distribution of target output samples. Dual autoencoder and\nGAN are used to implement the learning algorithm approximately. However, ODM does not exploit\nthe structure of the output samples. In contrast, in the study reported in this paper, we explicitly\nexploit the sequence prior, a type of structure commonly found in speech and natural language data,\nof the output samples in the form of joint probability distribution of the outputs. We believe that\nthe stronger the prior is, the better chance there is for this approach to work that exploits output\ndistributions as the prior. The sequence prior is very strong, and in many possible applications such\nas speech recognition, machine translation, and image/video captioning, this sequence prior can be\nobtained from language models trained using a very large amount of text data freely available. The\npower of such a strong prior of language models in unsupervised learning has been demonstrated in\nan earlier study reported in [19].\nIn addition to exploiting output distributions as the structured prior, our approach further exploits\nother sources of prior information including the correlation between input and output. The latter is\nimplemented in our work as a regularization term of the objective function, which is derived from a\ngenerative model with information ﬂow from output to input. The use of generative models in our\nwork is similar to an earlier study reported in [4] and to a more recent study reported in [25]. Finally,\n2\nour proposed unsupervised learning cost can be directly optimized using stochastic gradient descent\nin an end-to-end manner.\n3\nProblem Formulation\nIn this section, we ﬁrst formulate the unsupervised learning problem. Let xt be t-th input vector,\nwhich is an M-dimensional real-valued vector, and let yt be the t-th output vector. In this paper, we\nconsider the classiﬁcation problem so that yt is a C-dimensional one-hot vector that represents one\nof the C classes. In prediction tasks, the objective is to learn the conditional probability p(yt|xt, Wd)\nfrom training samples, where Wd represents the model parameter. p(yt|xt, Wd) can be any parametric\nmodel such as neural networks.\nIn supervised learning problems, the training algorithm is presented with paired data (xt, yt), which\nare assumed to be generated from a ground truth distribution p(x1, . . . , xT , y1, . . . , yT ). A common\nsupervised training objective is\nmax\nWd\nT\nX\nt=1\nln p(yt|xt, Wd)\n(1)\nwhere T is the number of training examples. It is clear that the supervised learning problem requires\nus to label each xt with an output (label) yt in order to solve the above optimization problem (1).\nIn this paper, we consider the unsupervised learning of p(yt|xt, Wd) from unpaired training se-\nquences {xt, t = 1, . . . , T} and {yt, t = 1, . . . , T}. The input samples {xt} and the output\nsamples {yt} are unpaired in that they are not necessarily generated from the true joint distri-\nbution p(x1, . . . , xT , y1, . . . , yT ) that we are trying to learn, and they are only required to be\ndistributed according to the respective marginal distributions, i.e., {xt} ∼p(x1, . . . , xT ) and\n{yt} ∼p(y1, . . . , yT ). Therefore, {xt} and {yt} could be collected from two completely inde-\npendent sources. In the rest of the paper, we assume that the probability distribution p(y1, . . . , yT )\nof the output samples has a sequence structure, i.e., there is temporal dependency over y1, . . . , yT .\nFurthermore, we assume that p(y1, . . . , yT ) is known a priori, which, as we pointed out earlier, could\nbe estimated from a different data source that has the same distribution of p(y1, . . . , yT ).\nMore formally, our objective in this paper is to learn the posterior probability p(yt|xt, Wd) (i.e., the\npredictor) from the input sequence {xt} by exploiting the distribution p(y1, . . . , yT ) on the output\nsequence, where p(y1, . . . , yT ) is learned from another totally unpaired sequence {y1, . . . , yT }.\nTherefore, this is an unsupervised learning problem, which we will proceed to solve and analyze in\nthe rest of the paper.\n4\nLearning to Predict from Unpaired Samples\nWe now develop a novel cost function for learning the predictor p(yt|xt, Wd) in an unsupervised\nmanner. The cost function is designed based on the following two key insights. First, given a predictor\np(yt|xt, Wd), we want the predicted output sequence ˆy1, . . . , ˆyT from the input sequence x1, . . . , xT\nto be consistent with the output distribution p(y1, . . . , yT ), with the deﬁnition of consistency to be\nexplained later. Second, we want the predicted output ˆyt to be based on the input xt; that is the output\nˆyt should be correlated with the input xt rather than completely independent of it. Therefore, our\nproposed cost function will have two terms. The ﬁrst term measures how well the predicted output\nﬁt into the output distribution, and the second condition is a regularization term, which prevents the\nlearning algorithm from overﬁtting into p(y1, . . . , yT ) and obtaining trivial solutions that generate ˆyt\ncompletely independently of the input xt. Below, we formalize these ideas by developing these two\nterms in the cost function.\nWe ﬁrst establish the ﬁrst term in the novel unsupervised learning cost function. Note that, for each\ninput sample xt, the parametric conditional distribution p(yt|xt, Wd) deﬁnes a probability of the\ncorresponding output sample yt. When the predictor p(yt|xt, Wd) is applied to each sample in the\ninput sequence x1, . . . , xT , and generates the output according to this distribution, we will generate a\nrandom output sequence ˆy1, . . . , ˆyT . Then, the log-likelihood ln p(ˆy1, . . . , ˆyT ) measures how well\nthe generated sequence ﬁt into the distribution p(y1, . . . , yT ). Motivated by this observation, we\ndeﬁne the following term to measure the expected ﬁtness of the predicted output with the current\n3\npredictor:\nE\n\u0002\nln p(y1, . . . , yT )\n\f\fx1, . . . , xT\n\u0003\n= E\n\" T\nX\nt=1\nln p(yt|yt−1, . . . , y1)\n\f\f\fxt, . . . , x1\n#\n=\nX\n(yt,yt−1,...,y1)\nT\nY\nt=1\np(yt|xt, Wd)\nT\nX\nt=1\nln p(yt|yt−1, . . . , y1)\n=\nT\nX\nt=1\nt−1\nY\nτ=1\np(yτ|xτ)\nX\nyt\np(yt|xt) ln p(yt|yt−1, . . . , y1)\n=\nT\nX\nt=1\nE\n\"X\nyt\np(yt|xt) ln p(yt|yt−1, . . . , y1)\n\f\f\fxt−1, . . . , x1\n#\n(2)\nwhere the last expectation is evaluated with respect to Qt−1\nτ=1 p(yτ|xτ, Wd). The learning algorithm\nseeks to maximize the above objective function (2) in order to make the predicted output sequence\nﬁt well into the prior distribution p(y1, . . . , yT ). We will further show in the next section that the\nglobal optimal solution to (2) is indeed the ground truth solution if the parametric model p(yt|xt, Wd)\nincludes the ground truth as one of its solution.\nHowever, we will further reveal in the next section that this objective function has many local optima\nthat are badly behaved. These local optima lead to trivial solutions, which completely ignore the\ninput data and produce outputs that ﬁt into p(y1, . . . , yT ). To address this issue, we introduce the\nsecond term in the cost function, which penalizes the solution that decouples the inputs and outputs.\nSpeciﬁcally, we propose to use the following term\nT\nX\nt=1\nE\nh\nln p(xt|yt, Wg)|xt\ni\n=\nT\nX\nt=1\nX\nyt\np(yt|xt, Wd) ln p(xt|yt, Wg)\n(3)\nwhere p(xt|yt, Wg) is a generative model parameterized by Wg for characterizing the information\nﬂow from output to input. The expression (3) has the following interpretation. For a given input\nsample xt, we generate an output sample yt according to the distribution p(yt|xt, Wd). Then for this\nparticular sample yt, the score ln p(xt|yt, Wg) measures how well the generative model p(xt|yt, Wg)\ncan predict the input xt. During the learning process, we seek to maximize this term with respect to\nWg to maximize the generative model’s ability to reconstruct the input from the output. That is, the\nlearning process also learns the best generative model that can reconstruct the input from the output.\nPutting these two terms together, we have the following cost function for learning the predictor from\nunpaired data:\nmax\nWd,Wg\nT\nX\nt=1\n(\nE\n\"X\nyt\np(yt|xt) ln p(yt|yt−1, . . . , y1)\n\f\f\fxt−1, . . . , x1\n#\n+λ\nX\nyt\np(yt|xt, Wd) ln p(xt|yt, Wg)\n)\n(4)\nwhere λ is a positive hyper-parameter that controls the relative ratio between the two terms. In the\nabove optimization problem, we maximize the objective function with respect to both Wd and Wg.\nAs we discussed earlier, the maximization with respect to Wg learns the best generative model to\nmeasure the “correlation” between the input and the predicted output from the discriminative model.\nExpression (3) shows that this term also depends on Wd, which means that by maximizing (4) with\nrespect to Wd, we are also maximizing the correlation between the input and the predicted output,\nthereby regularizing the learning of the discriminative model p(yt|xt, Wd) to avoid trivial solutions.\nThe above learning problem (4) can be solved by using stochastic gradient, and the gradients can be\ncomputed by back propagation if the discriminative model p(yt|xt, Wd) and the generative model\np(xt|yt, Wd) are (deep) neural networks.\n5\nExperiments and Analysis\nIn this section, we use a simpliﬁed prediction task on a synthetic dataset to study the effectiveness\nof the proposed approach. We will also analyze the behaviors of the proposed objective function in\n4\nClass 1\nClass 2\n0.5\nClass 3\n0.5\n1.0\n0.5\n0.5\nClass 4\n0.5\n0.5\nFigure 1: The transition probability of output observation.\n-10\n-5\n0\n5\n10\nt\n0\n2\n4\n6\n8\n10\nExpected Perplexity\nUnsupervised expected perplexity (6 = 0)\nUnsupervised optimal solution\nSupervised expected perplexity\nSupervised optimal solution\n(a) Unsupervised vs supervised costs\n-10\n-5\n0\n5\n10\nt\n0\n2\n4\n6\n8\n10\nUnsupervised Expected Perplexity\n0\n50\n100\n150\n200\n250\n300\nExpected perplexity (6 = 0)\nExpected perplexity (6 = 30)\nOptimal solution\n(b) The importance of regularization\nSupervised\nUnsupervised, \u0001 = 0, \u0002= 10\nUnsupervised, \u0001 = 30, \u0002= 10\n(c) The local and global optima\nFigure 2: The landscape of supervised cost function, unsupervised cost functions (with different\nlevels of regularizations), the local and global optimal solutions. Repeated experiments show similar\nresults.\norder to understand the nature and difﬁculties of the unsupervised learning problem for prediction\nalong with its potential solutions.\n5.1\nExperimental setup\nThe synthetic data we use to evaluate the algorithm are generated in the following manner. We ﬁrst gen-\nerate the output sequence y1, . . . , yT according to the distribution p(y1, . . . , yT ) = QT\nt=1 p(yt|yt−1),\ni.e., a Markov chain, which is described by Figure 1. And we consider a four-class classiﬁcation\nproblem so that yt is a 4-dimensional one-hot vector. After the sequence y1, . . . , yT is generated,\nwe randomly generate a permutation matrix Q and ﬁx it over time. For each yt, we generate xt by\nmultiplying Q to the left of xt, i.e., xt = Qyt. Therefore, the inputs {xt} are also a 4-dimensional\none-hot vectors except that each of them is transformed from the output yt according to an unknown\npermutation. Our objective is to learn p(yt|xt, Wd) from the input sequence x1, . . . , xT without the\npaired output sequence y1, . . . , yT . Instead, we only have a sequence of unpaired samples y1, . . . , yT\nthat is generated according to the same distribution p(y1, . . . , yT ), from which we could estimate\np(y1, . . . , yT ). In our study below, we choose p(yt|xt, Wd) and p(xt|yt, Wg) to be the softmax\nfunctions:\np(yt|xt, Wd) = softmax(γWdxt)\np(xt|yt, Wd) = softmax(γWgyt)\n(5)\nwhere γ is a positive number that controls the sharpness of the softmax function. Even though we are\nusing simple linear classiﬁers, as we proceed to reveal, the unsupervised learning cost is still highly\nnon-convex and the problem remains difﬁcult.\n5.2\nThe landscape of the proposed unsupervised cost function\nWe ﬁrst plot the landscape of the cost function (4) for λ = 0 case and compare it with the supervised\ncost (cross-entropy) in Figure 2(a). Speciﬁcally, we plot the negative of the objective function (4)\nalong the line tWd,0 + (1 −t)Wd,1, where t is a real scalar, Wd,0 is the ground truth (obtained\nfrom the permutation matrix) and Wd,1 is the ﬁnally converged solution by optimizing (4) without\nregularization (λ = 0). Obviously, the objective function is highly-nonconvex. On the other hand, the\ncost function for supervised learning is convex since the classiﬁer is linear. An important observation\n5\n-10\n-5\n0\n5\n10\nt\n0\n50\n100\n150\n200\nExpected Perplexity\nUnsupervised expected perplexity ( 6 = 0)\nUnsupervised optimal solution\nSupervised expected perplexity\nSupervised optimal solution\n(a) Unsupervised vs supervised costs (along ran-\ndom line 1)\n-10\n-5\n0\n5\n10\nt\n0\n5\n10\n15\n20\n25\n30\nUnsupervised Expected Perplexity\n0\n50\n100\n150\n200\n250\n300\n350\nExpected perplexity (6 = 0)\nExpected perplexity (6 = 30)\nOptimal solution\n(b) The importance of regularization (along ran-\ndom line 1)\n-10\n-5\n0\n5\n10\nt\n0\n50\n100\n150\nExpected Perplexity\nUnsupervised expected perplexity ( 6 = 0)\nUnsupervised optimal solution\nSupervised expected perplexity\nSupervised optimal solution\n(c) Unsupervised vs supervised costs (along ran-\ndom line 2)\n-10\n-5\n0\n5\n10\nt\n0\n5\n10\n15\n20\n25\n30\nUnsupervised Expected Perplexity\n0\n200\n400\n600\n800\nExpected perplexity (6 = 0)\nExpected perplexity (6 = 30)\nOptimal solution\n(d) The importance of regularization (along ran-\ndom line 2)\nFigure 3: The landscape of supervised cost function and unsupervised cost functions (with different\nlevels of regularizations) along random lines that pass through the ground truth solution.\nwe can make from Figure 2(a) is that the global optimal solution to (2) (i.e., the ﬁrst term in (4))\ncoincides with the global optimal solution of the supervised learning problem. On the other hand,\nthere is a local optimal solution, which the algorithm could easily get stuck in, as shown in the ﬁgure.\nWe also note that the cost function of the local optimal solution seems to be very close to that of the\nglobal optimal solution. There are two important questions to ask: (i) how good is this local optimal\nsolution in compare with the global optimal solution, and (ii) how does the regularization term (second\nterm in (4)) help the algorithm escape from local optima. To answer the ﬁrst question, we visualize\nthe weight matrix Wd in the middle part of Figure 2(c). We observe that the columns of the matrix\nare linearly dependent and the matrix is almost rank one by computing its singular values. With Wd\nbeing rank-1 (e.g., Wd ≈abT ), the probability p(yt|xt, Wd) = softmax(γabT xt) = softmax(a),\nwhich is independent of xt. Therefore, this local optimal solution is a trivial solution which totally\nignores the inputs, although its cost is close to that of the global optimal solution. We repeated the\nexperiments many times and all the local optimal solutions end up with rank-1. In Figures 3(a) and\n3(b), we plot more landscapes of the supervised and unsupervised cost functions along other random\nlines that pass through the ground truth solution. From the ﬁgures, we note similar behaviors as in\nFigure 2.\n5.3\nThe importance of regularization\nWe now address the second question on the importance of regularization. In Figure 2(b), we plot the\nlandscapes of the unsupervised cost function (4) for λ = 0 and λ = 30. The landscapes show the\nvalues of the cost function along a random line that passes through the ground truth (global optimal\nsolution). We observe that the regularization term creates a “slope” at the original position of the\nlocal optimal solution, which allows the algorithm to escape from the trivial solution. In Figures 3(b)\nand 3(d), we plot more landscapes for the unsupervised cost with different levels of regularization\n6\nFigure 4: Sensitivity of the performance with respect to the estimation accuracy of p(y1, . . . , yT ).\nand note similar behaviors, where the local optima are smoothed out by the regularization term. In\nthe end, the obtained solution with λ = 30 is shown in the right part of Figure 2(c). As a reference,\nwe also put the global optimal solution to the supervised problem in the left part of Figure 2(c). We\nsee that the solution obtained from unsupervised learning problem (4) with λ = 30 is very close to\nthe supervised solution.\n5.4\nThe impact of imperfect p(y1, . . . , yT )\nSo far we have only considered the case where the probability p(y1, . . . , yT ) is precisely known. In\npractice, this prior probability is estimated from a separate data sequence, which would always have\nestimation error. To examine the robustness of the algorithm with respect to the estimation error\nof p(y1, . . . , yT ) (in this synthetic data case, p(y1, . . . , yT ) is represented by the transition matrix\nP of the Markov chain in Figure 1), we add different levels of noise to the transition matrix be\nP ←P + N(0, σ2\nP ) (and normalize the columns of P so that they sum up to one) and evaluate the\nperformance of the unsupervised learning algorithm. The test error for different variance of noise\n(σ2\nP ) and different λ are shown in Figure 4. As the estimation error of p(y1, . . . , yT ) increases, the\nperformance of the unsupervised learning algorithm degrades. Furthermore, it is also noticeable that\nthe regularization parameter λ has to be set to a reasonable value to achieve the best performance.\nThis is not surprising because if λ is too small, the “slope” created by the regularization is not steep\nenough. On the other hand, if λ is too large, the regularization term will overwhelm the ﬁrst term\n(which contains the information regarding p(yt|xt)) in (4) so that the algorithm is not able to learn\nmeaningful information.\n6\nConclusions\nIn this paper we study the important problem of unsupervised learning for prediction tasks, which\nis to learn to predict without using input-label paired data. We address this challenging problem by\nexploiting the sequence structure of the output samples to learn the predictor. That is, we proposed\nan objective function that aims to make the predicted outputs ﬁt into the structure of the output while\npreserving the correlation between the input and the predicted output. On a synthetic structural\nprediction problem, we show that, even with simple linear classiﬁers, the objective function is already\nhighly non-convex. On the other hand, this objective function converges to an optimal solution. We\nare currently investigating the behavior of more complicated and realistic models with real-world\ndata.\nAlong this line of research, a recent work [7] shows that the local optima during supervised learning\nof the deep neural networks are well behaved. However, as we have demonstrated in our paper, this is\nnot the case in the unsupervised learning problem, where the other local optimal solutions represent\ntrivial solutions, although the values of the cost function are close to the global optimum. This leads\nto a further question on how to design even better objective functions to eliminate the trivial solutions\nfrom the set of local optima.\n7\nReferences\n[1] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning\nto align and translate. arXiv preprint arXiv:1409.0473, 2014.\n[2] Yoshua Bengio. Learning deep architectures for AI. Foundations and Trends in Machine Learning,\n2(1):1–127, January 2009.\n[3] Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. Greedy layer-wise training of\ndeep networks. In Proceedings of the Advances in Neural Information Processing Systems (NIPS), pages\n153–160, 2007.\n[4] Taylor Berg-Kirkpatrick, Greg Durrett, and Dan Klein. Unsupervised transcription of historical documents.\nIn Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages\n207–217, 2013.\n[5] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent dirichlet allocation. The Journal of Machine\nLearning Research, 3:993–1022, March 2003.\n[6] Jianshu Chen, Ji He, Yelong Shen, Lin Xiao, Xiaodong He, Jianfeng Gao, Xinying Song, and Li Deng.\nEnd-to-end learning of lda by mirror-descent back propagation over a deep architecture. In Proceedings of\nthe Advances in Neural Information Processing Systems (NIPS), pages 1765–1773, 2015.\n[7] Anna Choromanska, Mikael Henaff, Michael Mathieu, Gérard Ben Arous, and Yann LeCun. The loss\nsurfaces of multilayer networks. In Proceedings of AISTATS, 2015.\n[8] George E Dahl, Dong Yu, Li Deng, and Alex Acero. Context-dependent pre-trained deep neural networks\nfor large-vocabulary speech recognition. Audio, Speech, and Language Processing, IEEE Transactions on,\n20(1):30–42, 2012.\n[9] Andrew M Dai and Quoc V Le. Semi-supervised sequence learning. In Proceedings of the Advances in\nNeural Information Processing Systems (NIPS), pages 3079–3087, 2015.\n[10] Hao Fang, Saurabh Gupta, Forrest Iandola, Rupesh Srivastava, Li Deng, Piotr Dollar, Jianfeng Gao,\nXiaodong He, Margaret Mitchell, John Platt, Lawrence Zitnick, and Geoffrey Zweig. From captions\nto visual concepts and back. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), June 2015.\n[11] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. Generative adversarial nets. In Proceedings of the Advances in Neural\nInformation Processing Systems (NIPS), pages 2672–2680, 2014.\n[12] W Keith Hastings. Monte carlo sampling methods using markov chains and their applications. Biometrika,\n57(1):97–109, 1970.\n[13] Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-Rahman Mohamed, Navdeep Jaitly, Andrew\nSenior, Vincent Vanhoucke, Patrick Nguyen, Tara N. Sainath, and B. Kingsbury. Deep neural networks\nfor acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal\nProcessing Magazine, 29(6):82–97, November 2012.\n[14] Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning algorithm for deep belief nets.\nNeural computation, 18(7):1527–1554, 2006.\n[15] Geoffrey E Hinton and Ruslan R Salakhutdinov. Reducing the dimensionality of data with neural networks.\nScience, 313(5786):504–507, 2006.\n[16] Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to\nvariational methods for graphical models. Machine learning, 37(2):183–233, 1999.\n[17] Andrej Karpathy and Li Fei-Fei. Deep visual-semantic alignments for generating image descriptions. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3128–3137,\n2015.\n[18] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114,\n2013.\n[19] Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Yamada. Unsupervised analysis for decipherment\nproblems. In Proceedings of the COLING/ACL, pages 499–506, 2006.\n[20] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. ImageNet classiﬁcation with deep convolutional\nneural networks. In Proceedings of the Advances in Neural Information Processing Systems (NIPS), pages\n1097–1105, 2012.\n[21] Quoc Le, Marc’Aurelio Ranzato, Rajat Monga, Matthieu Devin, Kai Chen, Greg Corrado, Jeff Dean,\nand Andrew Ng. Building high-level features using large scale unsupervised learning. In International\nConference in Machine Learning, 2012.\n8\n[22] Grégoire Mesnil, Yann Dauphin, Kaisheng Yao, Yoshua Bengio, Li Deng, Dilek Hakkani-Tur, Xiaodong He,\nLarry Heck, Gokhan Tur, Dong Yu, et al. Using recurrent neural networks for slot ﬁlling in spoken language\nunderstanding. Audio, Speech, and Language Processing, IEEE/ACM Transactions on, 23(3):530–539,\n2015.\n[23] Grégoire Mesnil, Xiaodong He, Li Deng, and Yoshua Bengio. Investigation of recurrent-neural-network\narchitectures and learning methods for spoken language understanding. In Interspeech, 2013.\n[24] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient estimation of word representations\nin vector space. arXiv preprint arXiv:1301.3781, 2013.\n[25] Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-supervised\nlearning with ladder networks. In Proceedings of the Advances in Neural Information Processing Systems\n(NIPS), pages 3532–3540, 2015.\n[26] P. Smolensky. Parallel distributed processing: Explorations in the microstructure of cognition, vol. 1.\nchapter Information Processing in Dynamical Systems: Foundations of Harmony Theory, pages 194–281.\n1986.\n[27] Ilya Sutskever, Rafal Jozefowicz, Karol Gregor, Danilo Rezende, Tim Lillicrap, and Oriol Vinyals. Towards\nprincipled unsupervised learning. arXiv preprint arXiv:1511.06440, 2015.\n[28] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In\nProceedings of the Advances in Neural Information Processing Systems (NIPS), pages 3104–3112, 2014.\n[29] Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol. Stacked\ndenoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.\nThe Journal of Machine Learning Research, 11:3371–3408, 2010.\n[30] Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. Show and tell: A neural image\ncaption generator. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,\npages 3156–3164, 2015.\n[31] Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard\nZemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention.\narXiv preprint arXiv:1502.03044, 2015.\n[32] Rui Xu and Donald Wunsch. Survey of clustering algorithms. IEEE Transactions on Neural Networks,\n16(3):645–678, 2005.\n[33] Matthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In Proceedings\nof the European Conference on Computer Vision (ECCV), pages 818–833, 2014.\n9\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2016-06-15",
  "updated": "2016-06-15"
}