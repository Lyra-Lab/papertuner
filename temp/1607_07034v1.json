{
  "id": "http://arxiv.org/abs/1607.07034v1",
  "title": "Impact of Physical Activity on Sleep:A Deep Learning Based Exploration",
  "authors": [
    "Aarti Sathyanarayana",
    "Shafiq Joty",
    "Luis Fernandez-Luque",
    "Ferda Ofli",
    "Jaideep Srivastava",
    "Ahmed Elmagarmid",
    "Shahrad Taheri",
    "Teresa Arora"
  ],
  "abstract": "The importance of sleep is paramount for maintaining physical, emotional and\nmental wellbeing. Though the relationship between sleep and physical activity\nis known to be important, it is not yet fully understood. The explosion in\npopularity of actigraphy and wearable devices, provides a unique opportunity to\nunderstand this relationship. Leveraging this information source requires new\ntools to be developed to facilitate data-driven research for sleep and activity\npatient-recommendations.\n  In this paper we explore the use of deep learning to build sleep quality\nprediction models based on actigraphy data. We first use deep learning as a\npure model building device by performing human activity recognition (HAR) on\nraw sensor data, and using deep learning to build sleep prediction models. We\ncompare the deep learning models with those build using classical approaches,\ni.e. logistic regression, support vector machines, random forest and adaboost.\nSecondly, we employ the advantage of deep learning with its ability to handle\nhigh dimensional datasets. We explore several deep learning models on the raw\nwearable sensor output without performing HAR or any other feature extraction.\n  Our results show that using a convolutional neural network on the raw\nwearables output improves the predictive value of sleep quality from physical\nactivity, by an additional 8% compared to state-of-the-art non-deep learning\napproaches, which itself shows a 15% improvement over current practice.\nMoreover, utilizing deep learning on raw data eliminates the need for data\npre-processing and simplifies the overall workflow to analyze actigraphy data\nfor sleep and physical activity research.",
  "text": "1\nImpact of Physical Activity on Sleep:\nA Deep Learning Based Exploration\nAarti Sathyanarayana, Member, IEEE, Shaﬁq Joty, Member, IEEE, Luis Fernandez-Luque, Member, IEEE,\nFerda Oﬂi, Member, IEEE, Jaideep Srivastava, Fellow, IEEE, Ahmed Elmagarmid, Fellow, IEEE,\nShahrad Taheri, Teresa Arora\nAbstract—The importance of sleep is paramount for main-\ntaining physical, emotional and mental wellbeing. Though the\nrelationship between sleep and physical activity is known to\nbe important, it is not yet fully understood. The explosion\nin popularity of actigraphy and wearable devices, provides a\nunique opportunity to understand this relationship. Leveraging\nthis information source requires new tools to be developed to\nfacilitate data-driven research for sleep and activity patient-\nrecommendations.\nIn this paper we explore the use of deep learning to build sleep\nquality prediction models based on actigraphy data. We ﬁrst use\ndeep learning as a pure model building device by performing\nhuman activity recognition (HAR) on raw sensor data, and using\ndeep learning to build sleep prediction models. We compare the\ndeep learning models with those build using classical approaches,\ni.e. logistic regression, support vector machines, random forest\nand adaboost. Secondly, we employ the advantage of deep\nlearning with its ability to handle high dimensional datasets. We\nexplore several deep learning models on the raw wearable sensor\noutput without performing HAR or any other feature extraction.\nOur results show that using a convolutional neural network on\nthe raw wearables output improves the predictive value of sleep\nquality from physical activity, by an additional 8% compared\nto state-of-the-art non-deep learning approaches [1], which itself\nshows a 15% improvement over current practice [2]. Moreover,\nutilizing deep learning on raw data eliminates the need for data\npre-processing and simpliﬁes the overall workﬂow to analyze\nactigraphy data for sleep and physical activity research.\nIndex Terms—Sleep Research, Actigraphy, Body Sensor Net-\nworks, Wearable, Mobile Health, Connected Health, Accelerom-\neter, Physical Activity, Pervasive Health, Consumer Health In-\nformatics, Deep Learning.\nI. INTRODUCTION\nT\nHE importance of sleep is paramount to health and per-\nformance. Poor sleep habits impede physical, emotional\nand mental wellbeing [2]–[4]. Insufﬁcient sleep can lead to\na multitude of health complications such as insulin resistance\n[5]–[7], high blood pressure [8], cardiovascular disease [9],\n[10], a compromised immune or metabolic system [11], [12],\nmood disorders (such as depression or anxiety) [13], [14], and\ndecreased cognitive function for memory and judgement [15]–\n[17]. After decades of exploration, research is still under way\nA. Sathyanarayana and J. Srivastava are with the Department of Computer\nScience at the University of Minnesota-Twin Cities.\nA. Sathyanarayana, S. Joty, L. Fernandez-Luque, F. Oﬂi, J. Srivastava, A.\nElmagarmid are researchers employed by Qatar Computing Research Institute,\nDoha, Qatar\nS. Taheri and T. Arora are clinical researchers with Weill Cornell Medical\nCollege - Qatar.\nThis work was supported by WCMC-Q and QCRI under IRB 14-00104.\nto uncover the long-term consequences of inadequate sleep\nand sleep disorders.\nDiagnostic sleep studies (called polysomnography) are per-\nformed daily in thousands of hospitals to diagnose major\nsleep disorders such as obstructive sleep apnea, restless leg\nsyndrome, insomnia and more [18]. Current processes are\ncumbersome and require manual interpretation by clinicians.\nMoreover, patient referral for polysomnography (PSG) is\nbased on self-reported needs; and hence exacerbation often\nprecedes diagnosis.\nSleep researchers work towards improving PSG tests to\nbetter understand the overall impact of sleep on an individual’s\nquality of life and well-being. Formally funded, large-cohort\nclinical research studies have been a primary resource for data\ncollection to date. However, the recent widespread adoption of\nwearable devices is now producing a rapidly growing amount\nof human activity data. Improved analytic tools can leverage\nthis data for clinical practice and advanced health research.\nIn this paper we explore a deep learning approach to mod-\neling the relationship between sleep and physical activity. We\nﬁrst compare deep learning models with classical models, i.e.\nlogistic regression, support vector machines, random forest,\nadaboost, on data pre-processed to create a feature space of\nhuman activity by an automated human activity recognition\n(HAR) algorithm. However, deep learning has the advantage\nthat it is robust to high dimensional data. We leverage this\ncharacteristic by building models using a range of deep learn-\ning methods on raw accelerometer data. This eliminates the\nneed for data pre-processing and feature space construction,\nand simpliﬁes the overall workﬂow for clinical practice and\nsleep researchers.\nA. Activity and Sleep Research\nPolysomnography (PSG) involves the use of multiple sen-\nsors, such as EEG (electroencephalogram), motion sensors,\nbreathing sensors, SpO2 (oxygen saturation), etc. These com-\nbined techniques observe a patient overnight in a clinical\nsetting [18]. A restriction of PSG is its lack of easy portability.\nPortable solutions would allow the performance of diagnostics\nin the home of the patient, decreasing costs and inconvenience,\nand improving the overall evaluation by observing a patient\nin their natural setting [19]. Currently, only a few portable\nsleep study solutions are approved and available on the market.\nAlthough many studies have shown that they are effective [20],\nlimited recording channels make home studies less accurate for\ninvestigating complex sleep disorders [21].\narXiv:1607.07034v1  [cs.LG]  24 Jul 2016\n2\nPSG is usually limited to one overnight observation. It\ndoesn’t observe a patient over time and it does not take into\nconsideration the relationship between sleep quality and an\nindividual’s daily physical activity. Although the relationship\nbetween physical activity and sleep is not yet fully understood\n[22], it is thought to have a strong and complex correlation\nand contribute to multiple lifestyle diseases such as type II\ndiabetes mellitus and obesity [23].\nIn the 1990’s, researchers developed a technique called\nactigraphy to study physical activity and sleep interactions.\nActigraphy uses motions sensors in wearable devices to mea-\nsure human behaviours, such as sleep and physical activity.\nThere are hundreds of quantiﬁed self-applications syncing with\nsuch devices to help individual’s self-monitor their physical\nﬁtness and well-being. Actigraphy has become a widely used\ntool as it has been found to be much more reliable than sub-\njective or self-reported sleep diaries and behaviour logs [24].\nThis has been especially inﬂuential for large cohort studies\nabout physical activity and sleep where PSG is not feasible\n[25]. Moreover, actigraphy allows for the continuous longitu-\ndinal monitoring of a patient/participant. This is particularly\nimpactful for the study of diseases such as Chronic Obstructive\nPulmonary Disease (COPD) where sleep disturbances can be a\npredictor of exarcebation of the disease [26]. In this example,\nit is the long term evolution of the disease that can reveal\npotential health decline. In such settings, actigraphy is the best\nand only tool to study sleep and physical activity over long\nperiods.\nB. Research challenges of Actigraphy\nIn sleep research, there is a major bottleneck for the analysis\nof actigraphy data. The process involves sleep experts manu-\nally conﬁguring parameters prior to performing analysis. In our\nprevious study [1] we automated this process by developing a\nrobust automated human activity recognition algorithm (called\nRAHAR). RAHAR automatically pre-processes accelerometer\ndata into meaningful activity levels. The dimensionality reduc-\ntion caused by RAHAR’s feature construction creates a dataset\nsuitable for effective classical model building, and leads to an\nimprovement of the predictive value for sleep quality by 15%.\nHowever, this approach has some limitations. Firstly, RA-\nHAR is an unsupervised algorithm, meaning it does not\nexploit task labels for feature construction, and thus can be\nlimited in its ability to learn task speciﬁc features. Secondly,\nit is a pre-processing feature-reduction step. RAHAR adds\nto the evaluation workﬂow and summarizes the data through\naggregation, rather than exploiting its richness.\nAn alternative approach that has become popular recently is\nto use the automatic feature learning capability offered by deep\nlearning methods. Deep learning models have achieved state-\nof-the-art results in a wide variety of tasks in computer vision,\nnatural language processing and speech recognition. The fact\nthat deep learning models automatically learn abstract feature\nrepresentations from raw features, while also optimizing on\nthe target prediction tasks, makes them an attractive solution\nfor sleep and health research.\nII. DEEP LEARNING WITH ACTIVITY DATA\nAs explained before, sleep is highly affected by physical\nactivity during the day. Therefore, it is of special importance\nto consider how deep learning can be used to study activity\ndata acquired from sensors such as actigraphy.\nOver the past decade deep learning has gained signiﬁcant\nmomentum in areas such as speech recognition, natural lan-\nguage processing and computer vision. This trend has recently\nexpanded into various other areas including human activity\nrecognition from sensor data. In this sub-section, we limit\nour deep learning review to studies that employ techniques\nto analyses of physical activity data, and refer the reader to\nChen et al. [27] and Bulling et al. [28] for more comprehensive\nreviews of sensor-based human activity recognition literature.\nAlso, Langkvist et al. provided a review of deep learning for\ntime-series modeling [29].\nEarly adopters of deep learning for wearable sensor data,\nfocus on adapting the raw input signal to the desired deep\nlearning architecture [30]. Inspired from speech recognition,\nAlsheikh et al. [30], for example, used the spectrogram repre-\nsentation to convert one-dimensional accelerometer data into\ntwo-dimensional data input of a deep restricted Boltzmann\nmachine (RBM) architecture.\nInstead of resizing the data to meet the input format of\na conventional convolutional neural network (CNN), Chen\nand Xue [31] suggested resizing the convolutional kernels to\ndeal with the original tri-axial acceleration data with different\nlengths in order to preserve the temporal information between\nadjacent acceleration values.\nSimilarly, Yang et al. [32] employed a deep CNN archi-\ntecture to automate feature learning from raw multi-sensor\ninputs in a systematic way in which the convolution and\npooling ﬁlters were applied along the temporal dimension\nfor each sensor, and the resulting feature maps for different\nsensors were uniﬁed as a common input for the neural network\nclassiﬁer.\nConsidering recurrent neural networks (RNN) model the\nlong-term contextual information of temporal sequences well,\nDu et al. [33] proposed a hierarchical RNN for action recog-\nnition from skeletal movement data. Instead of taking the\nwhole skeleton as input, they considered dividing the skeleton\ninto ﬁve parts which were then fed into ﬁve bidirectional-\nRNNs. The representations extracted by the subnets were\nhierarchically fused as the inputs of higher layers. A fully\nconnected layer and a softmax layer were performed on the\nﬁnal representation to classify the actions, achieving state-of-\nthe-art results in skeleton-based action recognition.\nLefebvre et al. [34] developed a gesture recognition method\nbased on bidirectional long short-term RNN (BLSTM-RNN)\nfrom raw input data, which outperformed the classical methods\nsuch as those based on hidden Markov models (HMM),\ndynamic time warping (DTW), or support vector machines\n(SVM), on a common dataset for 14-class gesture classiﬁca-\ntion.\nSome of the latest studies in this domain have introduced\nmore sophisticated deep learning architectures. For instance,\nNeverova et al. [35] proposed an optimized shift-invariant\n3\ndense convolutional mechanism, and incorporated the discrim-\ninatively trained dynamic features in a probabilistic generative\nframework, taking into account temporal characteristics of\nthe input physical activity data at multiple scales. Their\nmethod proved successful at learning human identity from\ndaily motion patterns, potentially allowing for active biometric\nauthentication with mobile inertial sensors.\nInspired by recent advances in speech recognition, Ordonez\nand Roggen recently proposed an architecture comprising\nboth convolutional and LSTM recurrent neural networks for\nactivity recognition from multimodal wearable sensor data\n[36]. The convolutional layers in this architecture acted as\nfeature extractors and provided abstract representations of the\ninput sensor data in feature maps while the recurrent layers\nmodeled the temporal dynamics of the activation of the feature\nmaps.\nMost recently, Hammerla et al. [37] provided the ﬁrst sys-\ntematic exploration of the performance of several state-of-the-\nart deep learning architectures such as deep feed forward, con-\nvolutional and recurrent neural networks, on three representa-\ntive physical activity datasets captured with wearable sensors.\nIn more than 4,000 recognition experiments with randomly\nsampled model conﬁgurations, they investigated the suitability\nof each model for different tasks in human activity recognition,\nexplored the impact each model’s hyper-parameters had on\nperformance using the fANOVA framework, and provided\nguidelines for those who wanted to apply deep learning in their\napplication scenarios. Over the course of these experiments\nthey discovered that recurrent networks outperformed the\nstate-of-the-art, and that they allowed novel types of real-time\napplications through sample-by-sample prediction of physical\nactivities.\nIII. PRELIMINARIES\nIn this section we present the terminology used and a\ndescription of how the dataset for our experiments were\ncollected.\nA. Sleep Science Terminology\nFor our model there are two key types of vocabulary used:\nthose pertaining to time series segmentation, and those for\ndeﬁning sleep quality.\nIn a person’s activity time series, i.e. the continuous data\ncollected from a wearable device, there are moments when\nan individual is awake and when they are asleep. The latter is\nreferred to as the sleep period. The boundary of the time awake\nto time asleep is called sleep onset time, and the boundary of\nthe time asleep to time awake, is called the sleep awakening\ntime. All time extending between a sleep awakening time and\nthe following sleep onset time, is referred to as awake time.\nTo measure quality of sleep we use a metric called sleep\nefﬁciency, which is the ratio of total minutes asleep to total\nminutes in bed.\nSleep Efﬁciency =\nTotalSleepTime\nTotalMinutesinBed\n= length(SleepPeriod) −WASO\nlength(SleepPeriod) + Latency\n(1)\nTotal minutes in bed represents the amount of time that an\nindividual spends sleeping and the amount of time it takes for\nthem to fall asleep, called latency. Total sleep time represents\nthe amount of time that an individual spends actually sleep.\nThis is calculated by subtracting all moments of wakefulness,\nWASO, from the duration of the sleep period.\nWASO =\nX\nSleepP eriod\nlength(WakefulnessPeriod)\n(2)\nB. Data Collection\nThe deidentiﬁed data used in this study which was col-\nlected by Weill Cornell Medical College - Qatar for a re-\nsearch study called Qatar’s Ultimate Education for Sleep\nin Teenagers (QUEST). The study aimed to examine the\nrelationship between sleep and physical activity. The selected\ncohort was chosen from student volunteers attending two\ndifferent high schools. The students were provided with an\nActiGraph GT3X+ device, to wear on their non-dominant\nwrist throughout the day and night for seven consecutive\ndays/nights. The dataset used in our experiments contains the\nactigraphy data from a subset of 92 adolescents over 1 week.\nThe ActiGraph GT3X+ is a clinical-grade wearable device\nthat samples a users activity at 30-100 Hertz. The effectivness\nof this device has been successfully validated against clinical\npolysomnography [38]. The device has an accompanying soft-\nware called ActiLife. This software is used by sleep experts to\nevaluate a patient’s sleep period, and interpret the accelerom-\neter output. We evaluate the performance improvement of\nour methodology against results from the ActiLife software\nversion 6.\nIV. METHODOLOGY\nA. Data Representation\nOur experiments fall into two categories. The ﬁrst uses\noutput from a human activity recognition algorithm called\nRAHAR, and the second uses accelerometer triaxial data from\nthe actigraph. In this subsection, we start by describing the\ndetails that apply to both data types, and then we discuss the\ndataset speciﬁc components.\nIn traditional sleep science, sleep onset time and sleep\nawakening time are metrics that deﬁne the sleep period [39].\nWe interpret and expand these values for accelerometer data\naccording to Sadeh’s actigraphy deﬁnitions [40]. Sleep onset\ntime is deﬁned as the ﬁrst minute of 15 continuous minutes of\nsleep, after a self-reported bedtime, and the sleep awakening\ntime is the last minute of 15 continuous minutes of sleep\nthat is followed by 30 minutes of activity [40]. To automate\nthis interpretation directly from the accelerometer output, we\n4\nreverse engineer the self-reported bedtime as the start time\nof sedentary activity immediately preceding and adjacent to\nthe sleep-period. The sleep period itself is designated by\nobserving epochs that contain no triaxial movement, and then\nﬁne tuned with the formal boundaries of sleep onset and sleep\nawakening. Sleep onset time is the ﬁrst candidate boundary of\nthe sleep period that is followed by 15 minutes of continuous\nsleep. Sleep awakening time is the last candidate boundary\nof 15 minutes of continuous sleep followed by 30 minutes of\nactivity.\nThe classiﬁcation label of each record is based on the sleep\nquality. Sleep quality is measured by the sleep efﬁciency\nequation in section III-A. With the sleep period boundaries\ndeﬁned as mentioned above, WASO can be computed by\nsumming up the total minutes during the sleep period that\na person has some movement for more than 5 consecutive\nminutes. Latency can be computed as the length of time before\nthe sleep onset time, that a person is sedentary. Overall, if\nsleep efﬁciency is above 85%, the sleep is labeled as ”Good”,\notherwise as ”Poor”.\nThe RAHAR algorithm uses the raw accelerometer data to\ncompute the percentage of awake time spent in 1 of 4 activity\nintensity levels: sedentary, light, moderate, vigorous. Thus the\nfeature set is ﬁxed at 4. In order to handle class imbalance,\nsynthetic minority oversampling technique [41] was run on the\ndata.\nThe raw accelerometer data was aggregated into minute-\nby-minute epochs. The sleep period was used to classify the\nawake time, and it was detached from each time series to pre-\nvent auto-correlation. The vertical axis from the accelerometer\nwas used to represent the summary of movement. The raw data\nwas thus one-dimensional.\nB. Deep Learning Models\nLet xt ∈RD be a vector representing a person’s activity\nmeasured at time t. Given a series of such input feature\nvectors X = (x1, · · · , xT ) representing a person’s physical\nactivity in an awake time period, the deep neural models ﬁrst\ncompute compressed representations with multiple levels of\nabstraction by passing the inputs through one or more non-\nlinear hidden layers. The abstract representations of the raw\nactivity measures are then used in the output layer of the neural\nnetwork to predict the sleep quality. Formally, the output layer\ndeﬁnes a Bernoulli distribution over the sleep quality y ∈\n{good, poor}:\np(y|X, θ) = Ber(y| sig(wTφ(X) + b))\n(3)\nwhere sig refers to the sigmoid function, φ(X) deﬁnes the\ntransformations of the input X through non-linear hidden\nlayers, w are the output layer weights and b is a bias term.\nWe train the models by minimizing the cross-entropy be-\ntween the predicted distributions ˆynθ = p(yn|Xn, θ) and the\ntarget distributions yn (i.e., the gold labels).1\nJ(θ) = −\nX\nn\nyn log ˆynθ + (1 −yn) log (1 −ˆynθ)\n(4)\n1Other loss functions (e.g., hinge) yielded similar results.\n!!!!\n!!!!\n!!!!\n.!.!\n!!!!!!!!!!!!!\n!!\nx1!\nx2!\nxT!\nV!\nw!\ny!\nInput!\nDense \nhidden!\nlayer!\nFig. 1: A multi-layer perceptron with one hidden layer.\nMinimizing cross-entropy is same as minimizing the neg-\native log-likelihood (NLL) of the data (or maximizing log-\nlikelihood). Unlike generalized linear models (e.g., logistic\nregression), the NLL of a deep neural model is a non-convex\nfunction of its parameters. Nevertheless, we can ﬁnd a locally\noptimal maximum likelihood (ML) or maximum a posterior\n(MAP) estimate using gradient-based optimization methods.\nThe main difference between the models, as we describe\nbelow, is how they compute the abstract representation φ(X).\n1) Multi-Layer\nPerceptrons:\nMulti-Layer\nPerceptrons\n(MLP), also known as Feed-forward Neural Networks, are\nthe simplest models in the deep learning family. As shown in\nﬁg. 1, the transformation of input φ(X) in MLP is deﬁned\nby one or more fully-connected hidden layers of the form\nφ(X) = f(V x1:T) = [f(vT\n1 x1:T), · · · , f(vT\nNx1:T)]\n(5)\nwhere x1:T is the concatenation of the feature vectors\nx1, · · · , xT , V is the weight matrix from the inputs to the hid-\nden units, f is a non-linear activation function (e.g., sig, tanh)\napplied element-wise, and N is the number of hidden units.\nMLP without any hidden layer (i.e., non-linear activations)\nboils down to a logistic regression (LR) or maximum entropy\n(MaxEnt) model. The hidden layers give MLP representational\npower to model complex dependencies between the input\nand the output.2 By transforming a large and diverse set\nof raw activity measures into a more compressed abstract\nrepresentation through its hidden layer, MLP can improve the\nprediction accuracy over linear models like LR.\n2) Convolutional Neural Network:\nThe fully-connected\nMLP described above has two main properties: (i) it composes\neach higher level feature from the entire input, and (ii) it is\ntime variant, meaning it uses separate (non-shared) weight\nparameter for each input dimension to predict the overall sleep\n2In fact, MLP has been shown to be a universal approximator, meaning that\nit can model any suitably smooth function to any desired level of accuracy,\ngiven the required hidden units [42].\n5\nquality. However, a person’s sleep quality may be determined\nby his activity over certain (local) time periods in the awake\ntime as opposed to the entire awake time, and this can\nbe invariant to speciﬁc timings. For example, high intensity\nexercises or games over certain period of time can lead to good\nsleep, no matter when the activities are exactly performed in\nthe awake time. Furthermore, each person has his own habit\nof activities, e.g., some run in the morning while others run\nin the afternoon. A fully-connected structure would require a\nlot of data to effectively learn these speciﬁc activity patterns,\nwhich is rarely the case in health domain. Convolutional neural\nnetworks (CNN) address these issues of a fully-connected\nMLP by having repetitive ﬁlters or kernels that are applied\nto local time slots to compose higher level abstract features.\nThe weights for these ﬁlters are shared across time slots.\nAs shown in Fig. 2, the hidden layers in a CNN are\nformed by a sequence of convolution and pooling operations.\nA convolution operation involves applying a ﬁlter u ∈RL.D\nto a window of L feature vectors to produce a new feature ht\nht = f(u.xt:t+L−1)\n(6)\nwhere xt:t+L−1 denotes the concatenation of L input vectors\nand f is a non-linear activation function as deﬁned before.\nWe apply this ﬁlter to each possible L-word window in the\nsequence X to generate a feature map hi = [h1, · · · , hT +L−1].\nWe repeat this process N times with N different ﬁlters to get\nN different feature maps [h1, · · · , hN]. Note that we use a\nwide convolution rather than a narrow one, which ensures that\nthe ﬁlters reach the entire sentence, including the boundary\nwords [43]. This is done by performing zero-padding, where\nout-of-range (t<1 or t>T) vectors are assumed to be zero.\nAfter the convolution, we apply a max-pooling operation3\nto each feature map\nm = [µp(h1), · · · , µp(hN)]\n(7)\nwhere µp(hi) refers to the max operation applied to each\nwindow of p features in the feature map hi. For p = 2, this\npooling gives the same number of features as in the feature\nmap (because of the zero padding).\nIntuitively, the ﬁlters compose activity measures in local\ntime slots into higher-level representations in the feature maps,\nand max-pooling reduces the output dimensionality while\nkeeping the most important aspects from each feature map.\nSince each convolution-pooling operation is performed inde-\npendently, the features extracted become invariant in locations,\ni.e., where they occur in the awake time. This design of CNNs\nyields fewer parameters than its fully-connected counterpart,\ntherefore, generalizes well for target prediction tasks.\n3) Recurrent Neural Network: In CNN, features are con-\nsidered in a bag-of-words fashion disregarding the order\ninformation. The order in which the activities were performed\nin an awake time could be important. Recurrent neural net-\nworks (RNN) compose abstract features by processing activity\nmeasures in an awake time sequentially, at each time step\n3Other pooling operations are possible. In our experiments, we found max-\npooling giving better results than mean-pooling.\n!!!!!!!\n!!\nU!\nw!\ny!\n!!!!\n.!.!\nx1!\nx2!\nxT!\n!!!!\n!!!!\nxT#1!\n!!!!\n!!!!!!!\n!!!!!!!\n!!!! !!!!\n!!!!\nh1!\nh2!\nhN!\n..!\nInput!\nFeature!\nmaps!\nConvolu'on(with((\nN(ﬁlters(of(length(2(\nPooling(with((\nlength(4(\nMax!\npooling!\nm1!\nm2!\nmN!\n..!\nFig. 2: A convolutional neural network. Each colored box\nin the second hidden layer represents a feature map, which\nis obtained by sliding its corresponding ﬁlter over the entire\ninput. Pooling is independently done over feature maps.\ncombining the current input with the previous hidden state.\nMore speciﬁcally, as depicted in Fig. 3(a), RNN computes\nthe output of the hidden layer ht at time t from a nonlinear\ntransformation of the current input xt and the output of the\nprevious hidden layer ht−1. More formally,\nht = f(Uht−1 + V xt)\n(8)\nwhere f is a nonlinear activation function as before, and U and\nV are compositional weight matrices. RNNs create internal\nstates by remembering previous hidden layer, which allows\nthem to exhibit dynamic temporal behavior. We can interpret\nht as an intermediate representation summarizing the past.\nThe representation for the entire sequence can be obtained\nby performing a pooling operation (e.g., mean-pooling, max-\npooling) over the sequence of hidden layers or simply by\npicking the last hidden layer hT . In our experiments, we found\nmean-pooling to be more effective than other methods.\nRNNs are generally trained with the backpropagation\nthrough time (BPTT) algorithm, where errors (i.e., gradients)\nare propagated back through the edges over time. One common\nissue with BPTT is that as the errors get propagated, they\nmay soon become very small or very large that can lead\nto undesired values in weight matrices, causing the training\nto fail. This is known as the vanishing and the exploding\ngradients problem [44]. One simple way to overcome this\nissue is to use a truncated BPTT [45] for restricting the\nbackpropagation to only few steps like 4 or 5. However,\nthis solution limits the simple RNN to capture long-range\ndependencies. Below we describe an elegant RNN architecture\nto address this problem.\n6\n!!\nU!\nw!\ny!\n!!!!\nx1!\nx2!\nxT!\n!!!!\n!!!!\nxT#1!\n!!!!\n!!!!!!!\n!\nInput!\nRecurrent!\nlayer!\nPooling!\nlayer!\n..\"\n!!!!!!!\nh1!\nh2!\n!!!!!!!\nhT-1!\n!!!!!!!\nhT!\n!!!!!!!\n..\"\nmean(pooling(\nV!\n(a)\n(b)\nFig. 3: (a) A recurrent neural network with one recurrent layer, and (b) an LSTM memory block, which represents a hidden\nunit in an LSTM-RNN.\nLong Short-Term Memory RNN: Long short-term mem-\nory or LSTM [46] is speciﬁcally designed to capture long\nrange dependencies in RNNs. The recurrent layer in a standard\nLSTM is constituted with special units called memory blocks\n(Fig. 3(a) and 3(b)). A memory block is composed of four el-\nements: (i) a memory cell c (a neuron) with a self-connection,\n(ii) an input gate i to control the ﬂow of input signal into the\nneuron, (iii) an output gate o to control the effect of the neuron\nactivation on other neurons, and (iv) a forget gate f to allow\nthe neuron to adaptively reset its current state through the self-\nconnection. The following sequence of equations describe how\nthe memory blocks are updated at every time step t:\nit\n=\nsigh(Uiht−1 + Vixt + bi)\n(9)\nft\n=\nsigh(Ufht−1 + Vfxt + bf)\n(10)\nct\n= it ⊙tanh(Ucht−1 + Vcxt) + ft ⊙ct−1\n(11)\not\n=\nsigh(Uoht−1 + Voxt + bo)\n(12)\nht\n=\not ⊙tanh(ct)\n(13)\nwhere Uk and Vk are the weight matrices between two con-\nsecutive hidden layers, and between the input and the hidden\nlayers, respectively, which are associated with gate k (input,\noutput, forget and cell); and and bk is the corresponding bias\nvector. The symbols sigh and tanh denote hard sigmoid and\nhard tan, respectively, and the symbol ⊙denotes a element-\nwise product of two vectors. LSTM by means of its speciﬁcally\ndesigned gates (as opposed to simple RNNs) is capable of\ncapturing long range dependencies.\nV. EXPERIMENTS AND RESULTS\nIn this section we present the experimental settings and\nresults. The data is partitioned into a 70%:15%:15% split\nfor training, testing and validation, respectively. Although two\ndifferent types of data were used, the partitions for each\ncontained the same subjects data, i.e. the training set from the\nhuman activity recognition data contained the same subject\ndata as the training set from the raw accelerometer data. All\nreported results are based on model predictions on the test set.\nA. Settings for Deep Learning Models\nWe train our neural models by optimizing the cross entropy\nin Eq. 4 using the gradient-based online learning algorithm\nRMSprop [47].4 The learning rate and other parameters (ρ and\nϵ) were set to their default values as suggested by the authors.\nMaximum number of epochs for all models was set to 50. We\nuse rectiﬁed linear units (ReLU) for the activation functions\n(f). To avoid overﬁtting, we use dropout [50] of hidden units\nand early stopping based on the loss on the development set.5\nWe experimented with DR ∈{0.0, 0.1, 0.2, 0.3, 0.4, 0.5} for\ndropout rates and MB ∈{5, 10, 15, 20} for minibatch sizes.\nSince the size of the training data is small, the network weights\nare initialized with zero to start the training with the simplest\nmodel.\n4Other adaptive algorithms (ADAM [48], ADADELTA [49]) gave similar\nresults.\n5Regularization on weights such as l1 and l2 did not improve the results.\n7\nMLP Settings: In our MLP, we experimented with one\nhidden layer containing N ∈{2, 3, 5, 10, 15, 20} units. In-\ncreasing the number of hidden layers worsened the results\nbecause of small amount of training data.\nCNN Settings: For CNN, we experimented with N ∈\n{25, 50, 75, 100, 125, 150} number of ﬁlters with ﬁlter lengths\nFL ∈{2, 3, 4, 5} and pooling lengths PL ∈{2, 3, 4, 5}.\nRNN Settings: For simple RNN and LSTM RNN, we ex-\nperiment with N ∈{25, 50, 75, 85, 100} units in the recurrent\nlayer and S ∈{25, 50, 75, 100} time-slots for constructing\npseudo-sequences.\nB. Human Activity Recognition Data Results\nIn our previous study, accelerometer data processed by\nRAHAR, produced a 15% improvement over current sleep\nexpert methodology. RAHAR plus random forests performed\nthe best, with linear regression performing similarily well. Due\nto the dimensionality reduction caused by RAHAR, the dataset\ncontained 4 features. RAHAR also aggregates the data over\nthe time series, which loses the time component. As a result,\nCNN, RNN, and LSTM are not suitable, and we apply a multi\nlayer perceptron (MLP).\n1) Multi Layer Perceptron: The best conﬁguration for a\nsingle layered MLP used a hidden layer size of 15, mini-\nbatch size of 5, and a dropout ratio of 0.3. MLP showed\nan improvement to the performance of LR, and marginally\nsurpassed the performance of random forest (Table I).\nC. Raw Accelerometer Data Results\nRAHAR is essentially a pre-processing algorithm that cre-\nates features for improving the performance of classical meth-\nods. With deep learning this is not necessary. High dimensional\ndata requires latent compressed abstract feature representation.\nTo leverage the power of deep learning, we test the raw\naccelerometer data aggregated into epochs of one minute\nas input. This eliminates the need for pre-processing, and\nprovides a richer input data set for model building.\nCNN and MLP performed the best with AUC scores show-\ning an improvement from LR by 46%.\n1) Logistic Regression: For logistic regression, the conﬁg-\nuration utilizes mini-batch size and dropout ratio. The optimal\nsettings were with a mini-batch size set to 5, and a dropout\nratio of 0.5.\n2) Multi Layer Perceptron: For a multi layer percepton\nwith 1 hidden layer, the size of the hidden layer is also\nnecessaary. The optimal settings were with a mini-batch size\nof 20, dropout ratio of 0.1 and a higgen layer size of 15.\n3) Convolutional Neural Network: Convolution networks\ninstead require the number of ﬁlters, the size of the ﬁlters\nand a max pool length, in addition to the mini-batch size and\ndropout ratio. The best results were obtained with 25, 5, 4, 5,\n0.0 respectively.\n4) Recurrent Neural Network: An RNN requires the size\nof the mini-batch, dropout ratio and hidden layer size. It\nperformed best with a mini-batch size of 5, a dropout ratio\nof 0.1 and a hidden layersize of 75.\n5) Long-Short Term Memory Cell: Lastly, LSTM requires\nthe same as RNNs. A mini-batch size of 5, dropout ratio of\n0.5 and a hidden layer size of 100 were optimal.\nVI. DISCUSSION\nThe objectives of our study were to (i) evaluate deep\nlearning as a prediction model for sleep quality, following the\nstate-of-the-art methodology, and (ii) to leverage deep learning\ncharacterstics to test its overall predictive power.\nTable I shows results on pre-processed, feature-reduced\ndata and illustrates that using deep learning as an alternative\nto traditional classiﬁcation models shows a moderate AUC\nimprovement. Although the improvement is small, the success\nof MLP on a dataset with highly limited features shows its\npotential to work on smaller, more limited datasets.\nTable II, shows the results of several deep learning models\non the raw accelerometer data. Linear regression was not able\nto perform as well given the raw data, proving the limitations\nof classical classiﬁcation models. MLP performed 7% better\nwith the expanded feature set, i.e. the raw data versus RAHAR\ndata. Although RNN and LSTM saw an overall improvement\nto LR, they were limited in their effectivness. The granularity\nand sequential dependencies of the data lead to a vanishing\ngradient. Preliminary exploration into aggregating the data into\nlonger duration epochs indicated a potential improvement in\nboth RNN and LSTM. This idea needs further exploration and\nis beyond the scope of this paper.\nThe sensitivity (also known as recall) and speciﬁcity of each\nof the models is reported in Table III. The high sensitivity\nvalues of each of the models indicate that deep learning has\na strong capability of correctly identifying individuals with\ngood sleep patterns from their preceeding awake activity. The\nspeciﬁcity is high for both MLP and CNN, indicating that\nthese models were also able to successfully identify those with\npoor sleep patterns.\nOverall, CNN performed the best. It scored an AUC of\n0.9456, with an F1 Score and Accuracy of 0.9444 and 0.9286,\nrespectivley.\nVII. DISCUSSION ON CLINICAL AND HEALTH\nINFORMATICS IMPORTANCE\nActigraphy can lead to a paradigm shift in the study of\ntwo key lifestyle behaviours (sleep and physical activity), just\nas ECG (electrocardiography) became crucial for cardiology\nand clinical research. To achieve that paradigm shift it is\nnecessary to develop new algorithms and tools to analyze this\ntype of data. Furthermore, huge data sets of actigraphy data are\nemerging from health research, including the study of patients,\nhealthy populations, and epidemiological studies. Furthermore,\nmillions of consumers are buying wearables that incorporate\nactivity sensors. This burst of human activity data is a great\nopportunity for health research but it requires the development\nof new tools and approaches. This paper has explored how\nDeep Learning is one of the most promising technologies for\nthe study of human activity data.\nFinally, systematic research on the use of wearables is\nbecoming crucially important with the current boom of sleep\n8\n(a) ROC curve for RAHAR data\n(b) ROC Curve for Raw Data\nTABLE I: Results from RAHAR Output\nAU-ROC\nF1 Score\nRecall\nPrecision\nAccuracy\nSE+AL\nRAHAR\nSE+AL\nRAHAR\nSE+AL\nRAHAR\nSE+AL\nRAHAR\nSE+AL\nRAHAR\nAda\n0.7489\n0.8132\n0.5574\n0.6885\n0.5484\n0.5526\n0.5667\n0.9130\n0.6966\n0.7206\nRF\n0.8115\n0.8746\n0.6885\n0.7500\n0.6774\n0.6316\n0.7000\n0.9231\n0.7865\n0.7647\nSVM\n0.7497\n0.7895\n0.3721\n0.7077\n0.2581\n0.6053\n0.6667\n0.8519\n0.6966\n0.7206\nLR\n-*\n0.8649\n-*\n0.6875\n-*\n0.5789\n-*\n0.8462\n-*\n0.7059\nMLP\n-*\n0.8781\n-*\n0.5385\n-*\n0.3684\n-*\n1.0000\n-*\n0.6471\n* Metrics are not included for models producing uniform classiﬁcation predictions.\nTABLE II: Results from Raw Accelerometer Data\nAU-ROC\nF1-Score\nPrecision\nRecall\nAccuracy\nLR\n0.6463\n0.8193\n0.7083\n0.9714\n0.7321\nMLP\n0.9449\n0.9118\n0.9394\n0.8857\n0.8929\nCNN\n0.9456\n0.9444\n0.9189\n0.9714\n0.9286\nRNN\n0.7143\n0.7711\n0.6667\n0.9143\n0.6607\nLSTM\n0.8680\n0.8831\n0.8095\n0.9714\n0.8393\nTABLE III: Sensitivity and Speciﬁcity\nSensitivity\nSpeciﬁcity\nLR\n0.9714\n0.3333\nMLP\n0.8857\n0.9048\nCNN\n0.9714\n0.8571\nRNN\n0.9143\n0.2381\nLSTM\n0.9714\n0.6190\napps [51]. There are serious concerns about the quality of\nsome of those apps [52]. Although we can assume that sleep\napps relying on activity sensors are becoming more reliable,\nwe cannot be certain since there is scant quantiﬁcation of this.\nIn this context it becomes more important to promote research\nin actigraphy data analysis.\nVIII. CONCLUSION\nOur results show using a convolutional neural network\n(CNN) on the raw wearables output improves the predictive\nvalue by an additional 8% compared with the state-of-the-art\nmethodology using classical classiﬁcation approaches. These\npositive results in a small data set, show the potential of\ndeep learning for analyzing actigraphy data for sleep research.\nThey also illustrate the potential value of integrating these\nalgorithms into clinical and research practice.\nOur study shows the feasibility of deep learning in sleep\nresearch using actigraphy. This is of paramount importance be-\ncause deep learning eliminates the need for data pre-processing\nand simpliﬁes the overall workﬂow in sleep research.\nREFERENCES\n[1] A. Sathyanarayana, F. Oﬂi, L. Luque, J. Srivastava, A. Elmagarmid,\nT. Arora, and S. Taheri, “Robust automated human activity recognition\nand its application to sleep research,” CoRR, vol. Pending Assignment,\n2016.\n[2] T. Arora, personal communication.\n[3] T. W. Strine and D. P. Chapman, “Associations of frequent sleep\ninsufﬁciency with health-related quality of life and health behaviors,”\nSleep medicine, vol. 6, no. 1, pp. 23–27, 2005.\n[4] H. R. Colten, B. M. Altevogt et al., Sleep disorders and sleep depri-\nvation: an unmet public health problem.\nNational Academies Press,\n2006.\n9\n[5] K. L. Knutson, A. M. Ryden, B. A. Mander, and E. Van Cauter, “Role\nof sleep duration and quality in the risk and severity of type 2 diabetes\nmellitus,” Archives of internal medicine, vol. 166, no. 16, pp. 1768–1774,\n2006.\n[6] G. DJ, P. NM, N. AB, and et al, “Association of sleep time with\ndiabetes mellitus and impaired glucose tolerance,” Archives of Internal\nMedicine, vol. 165, no. 8, pp. 863–867, 2005. [Online]. Available:\n+http://dx.doi.org/10.1001/archinte.165.8.863\n[7] P. M. Nilsson, M. R¨o¨ost, G. Engstr¨om, B. Hedblad, and G. Berglund,\n“Incidence of diabetes in middle-aged men is related to sleep distur-\nbances,” Diabetes Care, vol. 27, no. 10, pp. 2464–2469, 2004.\n[8] M. Oakland, “How sleep loss affects your heart,” TIME, 2016.\n[9] E. Kasasbeh, D. S. Chi, and G. Krishnaswamy, “Inﬂammatory aspects\nof sleep apnea and their cardiovascular consequences,” SOUTHERN\nMEDICAL JOURNAL-BIRMINGHAM ALABAMA-, vol. 99, no. 1, p. 58,\n2006.\n[10] H. K. Meier-Ewert, P. M. Ridker, N. Rifai, M. M. Regan, N. J. Price,\nD. F. Dinges, and J. M. Mullington, “Effect of sleep loss on c-reactive\nprotein, an inﬂammatory marker of cardiovascular risk,” Journal of the\nAmerican College of Cardiology, vol. 43, no. 4, pp. 678–683, 2004.\n[11] C.\nS,\nD.\nWJ,\nA.\nCM,\nJ.-D.\nD,\nand\nT.\nRB,\n“Sleep\nhabits\nand\nsusceptibility\nto\nthe\ncommon\ncold,”\nArchives\nof\nInternal\nMedicine, vol. 169, no. 1, pp. 62–67, 2009. [Online]. Available:\n+http://dx.doi.org/10.1001/archinternmed.2008.505\n[12] M. R. Opp and L. A. Toth, “Neural-immune interactions in the regulation\nof sleep,” Front Biosci, vol. 8, no. 2, pp. 768–779, 2003.\n[13] J. S. Peterman, M. M. Carper, and P. C. Kendall, “Anxiety disorders\nand comorbid sleep problems in school-aged youth: review and future\nresearch directions,” Child Psychiatry & Human Development, vol. 46,\nno. 3, pp. 376–392, 2015.\n[14] M. J. Murphy and M. J. Peterson, “Sleep disturbances in depression,”\nSleep medicine clinics, vol. 10, no. 1, pp. 17–23, 2015.\n[15] A. M. Williamson and A.-M. Feyer, “Moderate sleep deprivation pro-\nduces impairments in cognitive and motor performance equivalent to\nlegally prescribed levels of alcohol intoxication,” Occupational and\nenvironmental medicine, vol. 57, no. 10, pp. 649–655, 2000.\n[16] H. P. Van Dongen, G. Maislin, J. M. Mullington, and D. F. Dinges,\n“The cumulative cost of additional wakefulness: dose-response effects\non neurobehavioral functions and sleep physiology from chronic sleep\nrestriction and total sleep deprivation,” SLEEP-NEW YORK THEN\nWESTCHESTER-, vol. 26, no. 2, pp. 117–129, 2003.\n[17] J. M. Ellenbogen, J. D. Payne, and R. Stickgold, “The role of sleep in\ndeclarative memory consolidation: passive, permissive, active or none?”\nCurrent opinion in neurobiology, vol. 16, no. 6, pp. 716–722, 2006.\n[18] M. Hirshkowitz, “The history of polysomnography: Tool of scientiﬁc\ndiscovery,” Sleep Medicine: A Comprehensive Guide to Its Development,\nClinical Milestones, and Advances in Treatment, pp. 91–100, 2015.\n[19] M. Bruyneel, S. Van den Broecke, W. Libert, and V. Ninane, “Real-\ntime attended home-polysomnography with telematic data transmission,”\nInternational journal of medical informatics, vol. 82, no. 8, pp. 696–701,\n2013.\n[20] D. Hwang, “Home sleep testing versus in-lab polysomnography,” Sleep\nReview, 2013.\n[21] M. Borazio and B. Schiele, “Toward sustained logging in sleep studies\nthrough energy-efﬁcient actigraphy.”\n[22] H. S. Driver and S. R. Taylor, “Exercise and sleep,” Sleep medicine\nreviews, vol. 4, no. 4, pp. 387–402, 2000.\n[23] M. Chennaoui, P. J. Arnal, F. Sauvet, and D. L´eger, “Sleep and exercise:\na reciprocal issue?” Sleep medicine reviews, vol. 20, pp. 59–72, 2015.\n[24] T. Arora, E. Broglia, D. Pushpakumar, T. Lodhi, and S. Taheri, “An\ninvestigation into the strength of the association and agreement levels\nbetween subjective and objective sleep duration in adolescents,” PloS\none, vol. 8, no. 8, p. e72406, 2013.\n[25] I.-M. Lee and E. J. Shiroma, “Using accelerometers to measure physical\nactivity in large-scale epidemiological studies: issues and challenges,”\nBritish journal of sports medicine, vol. 48, no. 3, pp. 197–201, 2014.\n[26] M. Ehsan, R. Khan, D. Wakeﬁeld, A. Qureshi, L. Murray, R. ZuWal-\nlack, and N. K. Leidy, “A longitudinal study evaluating the effect of\nexacerbations on physical activity in patients with chronic obstructive\npulmonary disease,” Annals of the American Thoracic Society, vol. 10,\nno. 6, pp. 559–564, 2013.\n[27] L. Chen, J. Hoey, C. D. Nugent, D. J. Cook, and Z. Yu, “Sensor-\nbased activity recognition,” IEEE Transactions on Systems, Man, and\nCybernetics, Part C (Applications and Reviews), vol. 42, no. 6, pp. 790–\n808, Nov 2012.\n[28] A. Bulling, U. Blanke, and B. Schiele, “A tutorial on human activity\nrecognition using body-worn inertial sensors,” ACM Comput. Surv.,\nvol. 46, no. 3, pp. 33:1–33:33, Jan. 2014. [Online]. Available:\nhttp://doi.acm.org/10.1145/2499621\n[29] M. Lngkvist, L. Karlsson, and A. Loutﬁ, “A review of unsupervised\nfeature learning and deep learning for time-series modeling,” Pattern\nRecognition Letters, vol. 42, pp. 11 – 24, 2014. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0167865514000221\n[30] M. A. Alsheikh, A. Selim, D. Niyato, L. Doyle, S. Lin, and H.-P. Tan,\n“Deep activity recognition models with triaxial accelerometers,” 2016.\n[Online]. Available: http://www.aaai.org/ocs/index.php/WS/AAAIW16/\npaper/view/12627\n[31] Y. Chen and Y. Xue, “A deep learning approach to human activity\nrecognition based on single accelerometer,” in Systems, Man, and\nCybernetics (SMC), 2015 IEEE International Conference on, Oct 2015,\npp. 1488–1492.\n[32] J. B. Yang, M. N. Nguyen, P. P. San, X. L. Li, and S. Krishnaswamy,\n“Deep convolutional neural networks on multichannel time series for\nhuman activity recognition,” in Proceedings of the 24th International\nConference on Artiﬁcial Intelligence, ser. IJCAI’15.\nAAAI Press,\n2015, pp. 3995–4001. [Online]. Available: http://dl.acm.org/citation.\ncfm?id=2832747.2832806\n[33] Y. Du, W. Wang, and L. Wang, “Hierarchical recurrent neural network\nfor skeleton based action recognition,” in 2015 IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR), June 2015, pp. 1110–\n1118.\n[34] G. Lefebvre, S. Berlemont, F. Mamalet, and C. Garcia, Inertial\nGesture Recognition with BLSTM-RNN.\nCham: Springer International\nPublishing, 2015, pp. 393–410. [Online]. Available: http://dx.doi.org/\n10.1007/978-3-319-09903-3 19\n[35] N. Neverova, C. Wolf, G. Lacey, L. Fridman, D. Chandra, B. Barbello,\nand G. Taylor, “Learning human identity from motion patterns,” IEEE\nAccess, vol. 4, pp. 1810–1820, 2016.\n[36] F. J. Ordez and D. Roggen, “Deep convolutional and lstm recurrent\nneural\nnetworks\nfor\nmultimodal\nwearable\nactivity\nrecognition,”\nSensors, vol. 16, no. 1, p. 115, 2016. [Online]. Available: http:\n//www.mdpi.com/1424-8220/16/1/115\n[37] N. Y. Hammerla, S. Halloran, and T. Pl¨otz, “Deep, convolutional, and\nrecurrent models for human activity recognition using wearables,” in\nProceedings of the 25th International Conference on Artiﬁcial Intelli-\ngence, ser. IJCAI’16.\nAAAI Press, 2016.\n[38] P. S. Freedson, E. Melanson, and J. Sirard, “Calibration of the computer\nscience and applications, inc. accelerometer.” Medicine and science in\nsports and exercise, vol. 30, no. 5, pp. 777–781, 1998.\n[39] R. B. Berry, R. Brooks, C. E. Gamaldo, S. M. Harding, C. Marcus,\nand B. Vaughn, “The aasm manual for the scoring of sleep and\nassociated events,” Rules, Terminology and Technical Speciﬁcations,\nDarien, Illinois, American Academy of Sleep Medicine, 2012.\n[40] A. Sadeh, A. Raviv, and R. Gruber, “Sleep patterns and sleep disruptions\nin school-age children.” Developmental psychology, vol. 36, no. 3, p.\n291, 2000.\n[41] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “Smote:\nsynthetic minority over-sampling technique,” Journal of artiﬁcial intel-\nligence research, vol. 16, pp. 321–357, 2002.\n[42] K. Hornik, “Approximation capabilities of multilayer feedforward\nnetworks,” Neural Netw., vol. 4, no. 2, pp. 251–257, Mar. 1991.\n[Online]. Available: http://dx.doi.org/10.1016/0893-6080(91)90009-T\n[43] N. Kalchbrenner, E. Grefenstette, and P. Blunsom, “A convolutional neu-\nral network for modelling sentences,” in Proceedings of the 52nd Annual\nMeeting of the Association for Computational Linguistics (Volume 1:\nLong Papers).\nBaltimore, Maryland: Association for Computational\nLinguistics, June 2014, pp. 655–665.\n[44] Y. Bengio, P. Simard, and P. Frasconi, “Learning long-term dependen-\ncies with gradient descent is difﬁcult,” IEEE Transactions on Neural\nNetworks, vol. 5, no. 2, pp. 157–166, 1994.\n[45] T. Mikolov, Statistical Language Models based on Neural Networks.\nPhD thesis, Brno University of Technology, 2012.\n[46] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural\ncomputation, vol. 9, no. 8, pp. 1735–1780, 1997.\n[47] T. Tieleman and G. Hinton, RMSprop.\nCOURSERA: Neural Networks\n[48] D.\nP.\nKingma\nand\nJ.\nBa,\n“Adam:\nA\nmethod\nfor\nstochastic\noptimization,” CoRR, vol. abs/1412.6980, 2014. [Online]. Available:\nhttp://arxiv.org/abs/1412.6980\n[49] M. D. Zeiler, “ADADELTA: an adaptive learning rate method,” CoRR,\nvol. abs/1212.5701, 2012. [Online]. Available: http://arxiv.org/abs/1212.\n5701\n10\n[50] N.\nSrivastava,\nG.\nHinton,\nA.\nKrizhevsky,\nI.\nSutskever,\nand\nR.\nSalakhutdinov,\n“Dropout:\nA\nsimple\nway\nto\nprevent\nneural\nnetworks\nfrom\noverﬁtting,”\nJournal\nof\nMachine\nLearning\nResearch,\nvol.\n15,\npp.\n1929–1958,\n2014.\n[Online].\nAvailable:\nhttp://jmlr.org/papers/v15/srivastava14a.html\n[51] J. Behar, A. Roebuck, J. S. Domingos, E. Gederi, and G. D. Clifford,\n“A review of current sleep screening applications for smartphones,”\nPhysiological measurement, vol. 34, no. 7, p. R29, 2013.\n[52] S. Bhat, A. Ferraris, D. Gupta, M. Mozafarian, V. A. DeBari,\nN. Gushway-Henry, S. P. Gowda, P. G. Polos, M. Rubinstein, H. Seidu\net al., “Is there a clinical role for smartphone sleep apps? comparison of\nsleep cycle detection by a smartphone application to polysomnography.”\nJournal of clinical sleep medicine: JCSM: ofﬁcial publication of the\nAmerican Academy of Sleep Medicine, vol. 11, no. 7, pp. 709–715,\n2014.\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2016-07-24",
  "updated": "2016-07-24"
}