{
  "id": "http://arxiv.org/abs/1609.02549v3",
  "title": "Learning Lexical Entries for Robotic Commands using Crowdsourcing",
  "authors": [
    "Junjie Hu",
    "Jean Oh",
    "Anatole Gershman"
  ],
  "abstract": "Robotic commands in natural language usually contain various spatial\ndescriptions that are semantically similar but syntactically different. Mapping\nsuch syntactic variants into semantic concepts that can be understood by robots\nis challenging due to the high flexibility of natural language expressions. To\ntackle this problem, we collect robotic commands for navigation and\nmanipulation tasks using crowdsourcing. We further define a robot language and\nuse a generative machine translation model to translate robotic commands from\nnatural language to robot language. The main purpose of this paper is to\nsimulate the interaction process between human and robots using crowdsourcing\nplatforms, and investigate the possibility of translating natural language to\nrobot language with paraphrases.",
  "text": "Learning Lexical Entries for Robotic Commands using Crowdsourcing\nJunjie Hu, Jean Oh, Anatole Gershman\nSchool of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213\njunjieh@cs.cmu.edu, jeanoh@nrec.ri.cmu.edu, anatoleg@cs.cmu.edu\nAbstract\nRobotic commands in natural language usually contain vari-\nous spatial descriptions that are semantically similar but syn-\ntactically different. Mapping such syntactic variants into se-\nmantic concepts that can be understood by robots is challeng-\ning due to the high ﬂexibility of natural language expressions.\nTo tackle this problem, we collect robotic commands for nav-\nigation and manipulation tasks using crowdsourcing. We fur-\nther deﬁne a robot language and use a generative machine\ntranslation model to translate robotic commands from nat-\nural language to robot language. The main purpose of this\npaper is to simulate the interaction process between human\nand robots using crowdsourcing platforms, and investigate\nthe possibility of translating natural language to robot lan-\nguage with paraphrases.\nIntroduction\nNatural language provides an efﬁcient way for untrained\nhuman to instruct a robot to perform collaborative tasks,\ne.g., navigation and manipulation. However, learning to\ninterpret the meaning of natural language commands is\na challenging task (Dukes 2014; Perera and Allen 2013;\nChen and Mooney 2011), especially when the robot has little\nor no prior knowledge of the phrasal expressions in natural\nlanguage. Due to high ﬂexibility of natural language, it is\nnon-trivial for a robot to cover all the phrasal expressions in\nnatural language when its interpretation module is initially\nbuilt.\nPopular crowdsourcing platforms such as Amazon Me-\nchanical Turk, provide a fast and cheap way to collect in-\nteractive data from participants in a wide range of different\ncommunities. Hence, simulating the human machine inter-\naction process for information extraction on crowdsourcing\nplatforms has attracted lots of research interests (Nguyen,\nWallace, and Lease 2015; Hladk´a, Hana, and Luksov´a 2014;\nGoldberg, Wang, and Kraska 2013). To encourage the diver-\nsity of robotic commands, we simulate the interactive pro-\ncess between a robot and various untrained users on Ama-\nzon Mechanical Turk, and collect robotic commands dur-\ning the process. We further apply a phrase-based machine\ntranslation model to mapping natural language command to\na robotic language that can be understood by a robot.\nCopyright c⃝2016, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nPhrase-based Machine Translation Model\nTo tackle the problem of translating natural language com-\nmands to language that can be understood by robots, we ﬁrst\ndeﬁne a robot language that consists of predeﬁned key con-\ncepts in the robotic task domains. For example, in the navi-\ngation task domain, we deﬁne the following key concepts.\n• Action:= navigate\n• Object:= trafﬁc barrel | building | car\n• Relation:= left | right | front | back\nEach robot language command can be deterministically con-\nstructed by a combination of key concepts in the task do-\nmains. See Figure 1 for an illustration. We then adapt a\nphrase-based machine translation model to translate robotic\ncommands from natural language to the robot language. For\nthe phrase-based machine translation model, the key com-\nponent is the extracted phrase table that stores several lex-\nical entries. For a particular input (source-language) sen-\ntence s = s1 · · · sn, each lexical entry is deﬁned as a tu-\nple (b, e, r), specifying that the span sb · · · se in the source-\nlanguage sentence can be translated as the target-language\nstring r. For each lexical entry p = (b, e, r), we estimate a\nscore g(p) ∈R that measures the likelihood of translating\nthe span to the target language string by relative frequency\nunder the translation model. For a given lexicon entry p,\nb(p), e(p), r(p) denote its three components respectively. A\nderivation y of a source-language sentence is deﬁned as a\nﬁnite sequence of phrases, p1, p2 · · · pL. For any derivation\ny, r(y) refers to the translation sentence constructed by con-\ncatenating the strings r(p1), r(p2), · · · r(pL). For a source-\nlanguage sentence s, we denote Y(s) as a set of possible\nderivations of s.\nBased on the above notations, we aim to extract lexical en-\ntries from parallel textual corpus collected on crowdsourcing\nplatforms, and seek the optimal derivation y∗using beam\nsearch for the maximum derivation score f(y∗) among all\npossible derivations Y(s) under a phrase-based translation\nmodel.\nIn Equation 1, the score f(y) of a derivation y consists\nof three parts: (1) h(r(y)) is the log-probability of the tar-\nget string r(y) under a smoothed trigram language model;\n(2) g(pk) is the score of pk under a translation model; (3)\n|e(pk)+1−b(pk+1)| is the distortion penalty for reordering\narXiv:1609.02549v3  [cs.CL]  1 Nov 2016\nword alignments between source and target languages.\nf(y) = whh(r(y)) + wg\nL\nX\nk=1\ng(pk) + wd\nL−1\nX\nk=1\n|e(pk) + 1 −b(pk+1)|\n(1)\nwhere wh, wg and wd are the weights of the scores given\nby the language model, the translation model and the\ndistortion penalty respectively. Hence the optimal deriva-\ntion of a source-language sentence s can be obtained by\narg maxy∈Y(s) f(y).\nExperiment\nWe present the process of collecting experimental data on\nAmazon Mechanical Turk, a popular crowdsourcing plat-\nform, and extract parallel lexical entries using Moses (Koehn\net al. 2007), a machine translation tool.\nStimulation and Data Collection\nBy showing an image that depicts the behaviour of a robot,\na turker is ﬁrst asked to give a command in English (denoted\nas s) that clearly indicates the spatial information between\nobjects in the environment for a robot. Next, the turker is\nshown some robotic concepts in several drop-down lists, and\nasked to select the correct robotic concepts that can be used\nto construct a robotic command (denoted as r) for the same\nimage. Finally we simulate the scenario where the robot can\nactively ask for a paraphrase sentence (denoted as t) of the\nrobotic command r in order to help it understand s. Totally\nwe collect 88 tuples of (s, t, r) for navigation task and 120\ntuples of (s, t, r) tuples for manipulation task.\nPhrasal Lexicon Extraction and Translation\nTo investigate the possibility of using paraphrase sentences\nto enhance the phrase-based machine translation, we ﬁrst\nuse Moses to extract parallel phrases between s and r. Then\nwe use Moses to extract parallel phrases between t and r.\nTable 1 shows the total number of extracted lexical entries\nwhen we translate from s to r and from t to r. Compar-\ning the second column with the third one in Table 1, we\nobserve that more lexical entries are extracted from paral-\nlel sentences between t and r than those between s and r.\nThis convinces our idea that turkers usually paraphrase nat-\nural language commands that are more semantically closed\nto the robot language commands after the robotic concepts\nare shown to them. Table 2 shows some lexical entries ex-\ntracted from natural language commands t paired with robot\nlanguage commands r. We observe that the extracted lex-\nical entries capture the similarity between source-language\nphrases and target-language phrases, thus enabling many-to-\none mapping from syntactic variants in natural language to\nunique robotic concepts.\nTable 1: Number of extracted lexical entries\n#phrase from (s, r)\n#phrase from (t, r)\nNavigation\n160\n748\nManipulation\n128\n298\nBy optimizing the objective function in Equation 1, we\ngenerate the translated robot language sentence using the\nTable 2: Examples of extracted lexical entries\nNavigation Task\nNatural Language\nRobot Language\ngo straight until you reach a car\nnavigate to the car\nbackyard of the building\nbehind the building\nﬁnd the car\nto the car\nwhich stands before\nthat is in front\nmove forward to\nnavigate to\nlocated at the right hand side of\nis on the right of\n(a)\n(b)\nFigure 1: Navigation examples: (a) navigate (Action) to the\ntrafﬁc barrel (Object) that is on the right (Relation) of the\nbuilding (Object); (b) navigate (Action) to the car (Ob-\nject) that is on the back (Relation) of the building (Object)\nextracted lexical entries. In Table 3, we show two transla-\ntion results of the examples used in Figure 1. In the ﬁrst\nresult, the machine translation model can successfully trans-\nlate the natural language command to the correct robot lan-\nguage command. While in the second result, the translation\nis not completely correct because the natural language com-\nmand contains the detail steps for the navigation task. Map-\nping detail descriptions to highly abstract robot concepts re-\nquires more sophisticated semantic reasoning over the natu-\nral language. We leave it as our future work.\nConclusion\nIn this paper, we simulate the human robot communication\non Amazon Mechanical Turk and collect robotic commands\nfor navigation and manipulation tasks using crowdsourcing.\nWe further investigate the possibility of bridging the gap be-\ntween natural language command and robot language com-\nmand using paraphrasing. We will conduct our future work\nin several challenging aspects. First, lexical entries extracted\nfrom different but similar robotic tasks can be shared across\ntasks. Second, machine teaching by paraphrasing can be in-\ntegrated with active learning techniques. Robots can perform\nreasoning over the confusing phrases and actively ask their\nhuman partners for paraphrasing.\nTable 3: Examples of phrase-based translation\nNavigation Task\nNatural Language\nTranslated Robot Language\ngo to the trafﬁc barrel that\nis located on the right hand\nside of the building\nnavigate (Action) to the\ntrafﬁc barrel (Object) that\nis on the right (Relation)\nof the building (Object)\ngo straight forward until you\nreach the building. go to the\ncar behind the building.\nnavigate (Action) to the\nbuilding (Object) that is\nnavigate (Action) to the\ncar (Object) that is behind\n(Relation) the building\n(Object)\nAcknowledgments\nThis work was conducted in part through collaborative\nparticipation in the Robotics Consortium sponsored by\nthe U.S Army Research Laboratory under the Collabora-\ntive Technology Alliance Program, Cooperative Agreement\nW911NF-10-2-0016, and in part by ONR under MURI grant\n“Reasoning in Reduced Information Spaces” (no. N00014-\n09-1-1052). The views and conclusions contained in this\ndocument are those of the authors and should not be inter-\npreted as representing the ofﬁcial policies, either expressed\nor implied, of the Army Research Laboratory of the U.S.\nGovernment. The U.S. Government is authorized to re-\nproduce and distribute reprints for Government purposes\nnotwithstanding any copyright notation herein.\nReferences\n[Chen and Mooney 2011] Chen, D. L., and Mooney, R. J.\n2011. Learning to interpret natural language navigation in-\nstructions from observations. In Proceedings of the Twenty-\nFifth AAAI Conference on Artiﬁcial Intelligence, AAAI 2011,\nSan Francisco, California, USA, August 7-11, 2011.\n[Dukes 2014] Dukes, K. 2014. Semeval-2014 task 6: Su-\npervised semantic parsing of robotic spatial commands. Se-\nmEval 2014 45.\n[Goldberg, Wang, and Kraska 2013] Goldberg, S. L.; Wang,\nD. Z.; and Kraska, T.\n2013.\nCASTLE: crowd-assisted\nsystem for text labeling and extraction.\nIn Proceedings\nof the First AAAI Conference on Human Computation and\nCrowdsourcing, HCOMP 2013, November 7-9, 2013, Palm\nSprings, CA, USA.\n[Hladk´a, Hana, and Luksov´a 2014] Hladk´a, B.; Hana, J.; and\nLuksov´a, I. 2014. Crowdsourcing in language classes can\nhelp natural language processing. In Proceedings of the Sec-\nonf AAAI Conference on Human Computation and Crowd-\nsourcing, HCOMP 2014, November 2-4, 2014, Pittsburgh,\nPennsylvania, USA.\n[Koehn et al. 2007] Koehn,\nP.;\nHoang,\nH.;\nBirch,\nA.;\nCallison-Burch, C.; Federico, M.; Bertoldi, N.; Cowan, B.;\nShen, W.; Moran, C.; Zens, R.; et al. 2007. Moses: Open\nsource toolkit for statistical machine translation. In Proceed-\nings of the 45th annual meeting of the ACL on interactive\nposter and demonstration sessions, 177–180. Association\nfor Computational Linguistics.\n[Nguyen, Wallace, and Lease 2015] Nguyen, A. T.; Wallace,\nB. C.; and Lease, M. 2015. Combining crowd and expert la-\nbels using decision theoretic active learning. In Proceedings\nof the Third AAAI Conference on Human Computation and\nCrowdsourcing, HCOMP 2015, November 8-11, 2015, San\nDiego, California., 120–129.\n[Perera and Allen 2013] Perera, I. E., and Allen, J. F. 2013.\nSALL-E: situated agent for language learning. In Proceed-\nings of the Twenty-Seventh AAAI Conference on Artiﬁcial\nIntelligence, July 14-18, 2013, Bellevue, Washington, USA.\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2016-09-08",
  "updated": "2016-11-01"
}