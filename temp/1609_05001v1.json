{
  "id": "http://arxiv.org/abs/1609.05001v1",
  "title": "Stamp processing with examplar features",
  "authors": [
    "Yash Bhalgat",
    "Mandar Kulkarni",
    "Shirish Karande",
    "Sachin Lodha"
  ],
  "abstract": "Document digitization is becoming increasingly crucial. In this work, we\npropose a shape based approach for automatic stamp verification/detection in\ndocument images using an unsupervised feature learning. Given a small set of\ntraining images, our algorithm learns an appropriate shape representation using\nan unsupervised clustering. Experimental results demonstrate the effectiveness\nof our framework in challenging scenarios.",
  "text": "Stamp processing with examplar features\nYash Bhalgat\nMandar Kulkarni\nShirish Karande\nSachin Lodha\nTCS Innovation Labs, Pune, India\nAbstract—Document digitization is becoming increasingly cru-\ncial. In this work, we propose a shape based approach for\nautomatic stamp veriﬁcation/detection in document images using\nan unsupervised feature learning. Given a small set of training\nimages, our algorithm learns an appropriate shape representation\nusing an unsupervised clustering. Experimental results demon-\nstrate the effectiveness of our framework in challenging scenarios.\nI. INTRODUCTION\nIn developing countries, several transactions take place on\npaper. In countries like India, there is a strong recent initiative\nto reduce paper based transaction [1]. Detecting and verifying\nstamps in documents is an important problem since stamps\ncan be indicators of authenticity.\nIn this paper, we propose a shape based stamp veriﬁca-\ntion/detection approach for Indian document stamps. We resort\nto an unsupervised feature learning approach for learning an\nappropriate representation for stamp shapes. Recently, there\nhas been a study that the single layer of convolution ﬁlters\nlearned with an unsupervised dictionary learning method such\nas K-means clustering performs well on object recognition\n[2]. The accuracy of object recognition improves with more\nnumber of dictionary atoms. However, the signiﬁcance or con-\ntribution of each dictionary atom towards the ﬁnal recognition\nrate is not reported. We demonstrate that the high recognition\nrates can be obtained even with less number of dictionary\natoms chosen carefully. We propose an atom ranking scheme\nwhich then automatically selects the dictionary atoms which\nare indeed useful for good performance.\nWe performed experiments on our propriety dataset of\nscanned caste certiﬁcate documents. Due to no restriction\nenforced on scanning type, a document may or may not\ncontain color which renders color based approaches not usable.\nFig. 1 shows example stamp images from our dataset. Our\nstamp dataset suffers from issues such as faded/poorly im-\nprinted stamps, stamp-text overlap, poor scanning quality, low\nresolution, time degradations which renders recognition non-\ntrivial. High recognition rates reported in experimental results\ndemonstrate efﬁcacy of our method. Our approach also out-\nperforms off-the-shelf shape descriptors such as Gabor ﬁlters.\nFig. 1.\nExample images from our scanned document dataset.\nII. OUR METHODOLOGY\nA. Training data generation\nTraining data for stamp images was obtained through a\ncrowd-sourcing experiment where each worker was asked to\ndraw a box around stamp. Due to inter-worker variability,\nthe box markings were non-uniform. Stamp data thus suffers\nfrom issues such as partial markings, translation and margin\nvariations as can be seen in Fig. 1.\nB. Feature learning and extraction\nFeature representation for stamp is learned as following.\n• Randomly sample patches of size m × m from stamp\nimages\n• Perform ZCA whitening on patches\n• Perform K-means clustering to obtain dictionary atoms\n• Rank dictionary atoms as described in section II-C\nUsing the learned dictionary atoms, from an image, features\nare extracted as following.\n• Convolve an image with learned dictionary atoms\n• Use 1-of-K, max-assignment for encoding as follows\nfK(x) =\n(\nfK(x),\nif K = arg max f(x)\n0,\notherwise\n• Perform 4×4 - quadrant max pooling on the feature maps\n• Form a feature vector by concatenating features\nFig. 2(a) shows the learned dictionary (D) where K = 64.\n(a)\n(b)\nFig. 2.\nK-means clustering result: (a) Learned dictionary, (b) ranked\ndictionary atoms. Red marking shows the subset of ranked dictionary atoms\npicked.\nNote that most of the dictionary atoms exhibit the direc-\ntional nature, however, there are atoms which portrays almost\na ﬂat region and are less informative. This can happen because\nof random sampling of patches where not only stamp regions\nbut also patches from the background get picked. To identify\nthe dictionary elements which are most useful for recognition,\nwe propose a dictionary atom ranking scheme.\narXiv:1609.05001v1  [cs.CV]  16 Sep 2016\nC. Ranking dictionary atoms\nWe randomly pick a stamp image from our training set.\nFrom the training image, overlapping patches of size m × m\nare obtained from all pixel locations (i.e. stride is set to 1).\nLet Y denotes the patch set. We project Y on the obtained K\natoms and perform thresholding using a Rectiﬁed Linear unit\n(ReLu) as follows\nRij = (1 −yic) max(0, DT\nj yi) i ∈[1, n]\n(1)\nwhere Rij denotes the response of jth atom for ith patch\nand n denotes the number of patches in Y . yic denotes the\nintensity value at the center of the patch. Since stamps are on\na lighter background, post multiplication by (1 −yic) assigns\nmore weight to the patch response if it contains a part of\nstamp. The above operation is equivalent to convolving K\nﬁlters with the training image, performing rectiﬁcation on the\nresult and pixel-wise multiplying by an inverted input image.\nResponse for a dictionary atom is calculated as the maximum\nof an overall response.\nSj = max\ni\nRij\n(2)\nwhere Sj denotes the maximum response attained by jth atom.\nWe rank the atoms in the descending order of their responses.\nFig. 2(b) shows the ranked atoms. Note that the atoms which\npartly represent the circular shape are ranked higher than the\nrest. An interesting observation: it may appear that the ﬁfth\natom in the ﬁrst row of Fig. 2(b) does not show directional\nnature. We note that it actually represents an emblem which\nappears at the center of most of the stamps. We then chose top\nv atoms to be used for sub-sequent processing. The value for\nv is chosen based on a pre-deﬁned threshold on the maximum\nresponse. The red boundary in Fig. 2(b) shows the atoms\nwhich are picked in the process.\nIII. EXPERIMENTAL RESULTS\nIn this section, we demonstrate results of our method for\nstamp veriﬁcation and stamp detection.\nA. Stamp veriﬁcation\nGiven a test image, our aim is to classify it as a stamp or\nnon-stamp. For obtaining the dataset for non-stamp images,\nwe use the fact that stamps in our documents always lie in\nthe lower half side. We, therefore, randomly sample patches\nfrom the upper half only. Our non-stamp set mainly consisted\nof text regions, background regions or document borders. Our\ntraining data thus consist of 882 stamp and 957 non-stamp\nimages. Prior to feature extraction, all the images are converted\nto grayscale, resized to a ﬁxed dimension and normalized in\nthe range 0 to 1. We use the patch size of 16 × 16 for our\nexperiments. The feature set is randomly divided in 70%-30%\nfor training and testing respectively. We train a binary linear\nSVM classiﬁer on training features and compute classiﬁcation\naccuracy on the test set. For comparison, we performed\nthe classiﬁcation with following settings: subset of ranked\ndictionary atoms (v = 21), use all dictionary atoms (v = 64),\n64 Gabor ﬁlters (8 scale and 8 orientations), 64 Random Filters\n(RF). Table I shows our classiﬁcation results. Note that, a\nsmall set (approx. 1\n3rd) of ranked dictionary atoms produces\na slightly superior performance as compared to the full set\n(with less testing time). Testing time reported here is with\nMATLAB implementation. We also observe that our approach\nsigniﬁcantly outperforms off-the-shelf shape descriptor such\nas Gabor ﬁlters and a single layer of random ﬁlter based\nrecognition.\nMethod\n# of ﬁlters\nAcc.\nPrec.\nRecall\nTest\ntime (s)\nK-means\n21\n94.57\n100\n90.57\n0.88\nK-means\n64\n94.2\n99.57\n88.3\n2.414\nGabor\n64\n90.22\n100\n82.26\n2.54\nRF\n64\n76.09\n96.5\n52.08\n2.66\nTABLE I\nEXPERIMENTAL RESULTS.\nB. Stamp detection\nThe subset of ranked ﬁlters can also be used to locate\n(segment) stamps from images. We convolve the top v ﬁlters\nwith the input image and perform rectiﬁcation as per Eq. 1.\nWe compute an average of the responses from the ﬁlters.\nIt is observed that, we get a relatively high response at the\nstamp locations and a low response at non-stamp locations.\nUsing a moving window sum method, a region of maximum\nresponse is located. Bounding box of the stamp is then decided\nby local threshold based heuristic method. Stamp detection\nperformance is measured as an average Intersection over\nUnion (IoU) overlap between the box markings obtained from\nthe crowd-sourcing experiment and ones which are estimated\nalgorithmically. We get an average IoU overlap of 74.81%\nwhich underlines efﬁciency of our method. Fig. 3 shows\nexamples of our detection results.\nFig. 3.\nStamp detection results: Blue box shows the ground truth while red\nbox shows the estimated bounding box.\nIV. CONCLUSION\nIn this paper, we proposed an unsupervised feature learn-\ning based approach for stamp detection and veriﬁcation. We\nhave demonstrated that the subset of ranked dictionary atoms\nprovides a better performance with less computing. We also\nproposed a scheme to rank and choose the subset. Experimen-\ntal results showed an effectiveness of our method.\nREFERENCES\n[1] www.digitalindia.gov.in\n[2] Adam Coates, Andrew Ng and Honglak Lee, G.An Analysis of Single-\nLayer Networks in Unsupervised Feature Learning, Journal of Machine\nLearning Research (JMLR W-CP), 15:215-223, 2011.\n",
  "categories": [
    "cs.CV"
  ],
  "published": "2016-09-16",
  "updated": "2016-09-16"
}