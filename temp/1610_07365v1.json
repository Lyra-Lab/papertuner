{
  "id": "http://arxiv.org/abs/1610.07365v1",
  "title": "Introduction: Cognitive Issues in Natural Language Processing",
  "authors": [
    "Thierry Poibeau",
    "Shravan Vasishth"
  ],
  "abstract": "This special issue is dedicated to get a better picture of the relationships\nbetween computational linguistics and cognitive science. It specifically raises\ntwo questions: \"what is the potential contribution of computational language\nmodeling to cognitive science?\" and conversely: \"what is the influence of\ncognitive science in contemporary computational linguistics?\"",
  "text": "arXiv:1610.07365v1  [cs.CL]  24 Oct 2016\nIntroduction: Cognitive Issues in Natural\nLanguage Processing\nThierry Poibeau* — Shravan Vasishth**\n* Laboratoire LATTICE — CNRS, École normale supérieure and Université Sor-\nbonne Nouvelle, France\n** University of Potsdam, Germany\n1. Introduction\nFrom the very beginning, pioneers in computer sciences have tried to establish a\nlink between practical issues and more fundamental ones, like language processing\nin the brain, knowledge representation or the nature of communication. Modeling\nlanguage was supposed to open a window on the brain, or at least give an idea of\nhow things can be processed by the brain. The famous Turing Test (?; ?) itself was\nnot directly about language modeling, but mimicking a conversation through a com-\nputer that was considered as a proof of intelligence, i.e. the fact that computers could\ninterpret utterances, infer new information and produce relevant responses.\nThese concerns never disappeared but the ﬁeld quickly moved towards more ap-\nplied research interests. It was especially the case for machine translation, as soon as\nin the 1950s, since it was important then to show that usable results could be obtained\nrapidly (?; ?). However, there has been a continuous interest since the Second World\nWar for what could be called “cognitive issues”. Even the deception about the poor\nperformances of machine translation systems in the 1960s led to reﬂections about lan-\nguage complexity and whether it was possible to model this complexity or not. In the\n1960s and 1970s, Robert Dreyfus’ works have for example been largely inﬂuenced by\nthe results of programmes dealing with computers and languages (?; ?).\nDreyfus advocates, among other things, that a large part of language production is\nunconscious or, at least, cannot be modeled via explicit rule-based systems. Neural\nTAL. Volume 55 – n˚ 3/2014, pages 7 à 19\n8\nTAL. Volume 55 – n˚ 3/2014\nnetworks have then been seen as a possible solution to model unconscious reasoning:\nthe architecture of natural language processing was supposed to offer a more sensible\nrepresentation of the problem (?). It is now generally assumed that neural networks\ndo not directly simulate the human brain but they allow to implement processes that\nare required to model language and other complex tasks.\nIt seems that this interest for cognitive issues decreased in the late 1980s and more\ndramatically during the 1990s. The need for practical and real world applications\npushed forward more applied and engineering approaches, with a decreasing interest\nfor cognitive issues, even if of course some researchers have always been active in this\nﬁeld. One sign of this situation is for example that even if recent conferences like the\nConference on Natural Language Learning (CoNLL) or Empirical Methods in Natural\nLanguage Processing (EMNLP) always had a track on cognitive and psycholinguistic\nissues, very few submissions were generally received and even less accepted 1. The\ntwo domains have then largely evolved separately, cognitive science researchers being\nmaybe overwhelmed by the high technicality of NLP nowadays, while natural lan-\nguage processing researchers do not always see the added value of taking cognitive\naspects into account for their problems.\nHowever, things seem to be changing. Several workshops are now regularly held\non these topics (see for example the “Cognitive Aspects of Computational Language\nLearning” workshop regularly held since 2007 (?) or the “Cognitive Modeling and\nComputational Linguistics” workshop during NAACL 2015). Natural language pro-\ncessing would beneﬁt from a better understanding of human processes: as it has been\nsaid by several researchers recently, traditional machine learning approaches have\nbrought rapid and important improvements in different natural language processing\ntasks but these successes may be “low hanging fruits” (?), which means the ﬁeld may\nhave to face from now on more difﬁcult problems (e.g. discourse planning, argumen-\ntative analysis, etc.) that would beneﬁt from a better understanding of the processes\ninvolved in the brain.\nAdditionally, researchers are again interested in evaluating the relevance of their\nmodels according to a cognitive dimension. Many of the existing computational mod-\nels attempt to study language tasks under cognitively plausible criteria (such as mem-\nory and processing limitations) that humans face (?). New machine learning tech-\nniques, especially deep learning, bring back to the front scene a new version of neural\nnetworks that seems both more powerful and more sound, from a technical as well\nas a cognitive point of view (?). Last but not least, cognitive science also beneﬁt and\nsometimes takes inspiration from computational models.\n1. One should however note that more established conferences like ACL or COLING never had\na cognitive track per se, even in the 1960s or 1970s. However, each year several papers were\ndealing with issues related to cognitive science, like the structure of the mental lexicon or the\npsychological plausibility of parsing algorithms.\nIntroduction\n9\n2. Current research trends\nIn this section, we examine some recent research trends concerning language com-\nprehension, language acquisition, language pathologies and language evolution. There\nare of course other domains where computational linguistics meets cognitive science\nbut we think that these four areas have seen important improvements recently.\n2.1. Language comprehension\nCognitive science has a strong tradition of developing models of cognitive pro-\ncesses using tools that originated in the natural language processing world. One of\nthe early examples in sentence comprehension research is the work by Joshi and col-\nleagues (?; ?), who developed an explanation of the differences in processing between\ncrossed and nested dependencies in Dutch and German (?) by explicitly linking a type\nof pushdown automaton, the Bottom-up Embedded Pushdown Automaton (BEPDA),\nto Tree Adjoining Grammar (TAG) (?). A unique aspect of their work was that they\ndid not directly use TAG to develop a processing model, but deﬁned an equivalence\nrelationship between the automaton and TAG grammars.\nOver the last ﬁfteen years, an information-theoretic approach to language com-\nprehension processes, led by (?; ?; ?) and Roger Levy (?), has generated a lot of\ninterest, especially because it was able to explain certain empirical ﬁndings (?; ?) that\nneeded additional assumptions to account for using classical working memory-based\naccounts (?; ?). The Hale and Levy approach relied on large-scale probabilistic con-\ntext free grammars derived from treebanks, and consists of computing a complexity\nmetric, such as surprisal or entropy reduction, to characterize processing difﬁculty.\nThe distinguishing feature of this body of work is that it formalizes the effect that the\nfrequency of grammatical continuations has on expectations about upcoming words\nand phrases. The surprisal idea had already been investigated decades earlier, and\nhas a rich tradition in EEG research (?), but the Hale and Levy approach provided a\nformal basis for computing surprisal on a moment-by-moment basis. The Levy paper\ndirectly led to attempts to experimentally evaluate the predictions of the surprisal and\nentropy reduction ideas using large-scale grammars and eyetracking corpora or other\nreading data (?; ?; ?; ?). In addition, planned experiments also tested speciﬁc predic-\ntions of the surprisal account, with mixed results. Several studies have found evidence\nlargely consistent with surprisal and related metrics (?; ?; ?; ?), but other research has\nshown mixed evidence consistent with both the surprisal and the classical working\nmemory-based accounts (?; ?; ?; ?). As Levy pointed out in his 2008 paper, it is likely\nthat both classes of explanation play a role in determining comprehension difﬁculty.\nNevertheless, a major contribution of the probabilistic grammar-based approach has\nbeen to give a formal foundation to the idea of expectation driving parsing processes.\nFuture work would proﬁt from building probabilistic parsing frameworks that include\nboth kinds of constraints; this has been attempted in the past (?), but the ﬁeld would\ngreatly beneﬁt from more principled model development and model evaluation over\n10\nTAL. Volume 55 – n˚ 3/2014\ncross-linguistic data. A cross-linguistic investigation is necessary as a corrective to\nthe tendency to focus on English as the target language. A further gap in the ﬁeld\nis the apparent lack of connection between the Hale and Levy formalization of ex-\npectation, and the rich body of work on surprisal in the EEG literature. Testing the\ndetailed predictions of surprisal and related ideas using EEG is an important empirical\ntest that is yet to be conducted. Another area where proposals such as surprisal and\nentropy reduction can make important contributions is individual-level variability in\nexpectations, arising from differences in working memory capacity and the varying\ngrammatical knowledge of the comprehender (?).\nTen years ago, it seemed that two areas where probabilistic models needed most\nwork was to (i) demonstrate that moment-by-moment processing can be explained\nin terms of probabilistic expectation, and to (ii) attempt to model a broader range of\nphenomena. In the last few years, excellent progress has been made regarding the\nﬁrst point, but the empirical coverage of the probabilistic parsing account remains\nrather limited. For example, there is a large literature—and a great deal of empirical\nevidence—on interference effects arising in agreement attraction conﬁgurations (?),\nand antecedent-reﬂexive constructions where principles of the binding theory play\na role (?). Probabilistic models obviously have little to say about phenomena that\ninvolve linguistic as opposed to probabilistic constraints. This highlights the need\nfor developing more comprehensive models of cognitive processes such as sentence\ncomprehension that take a broader view of the constraints that act on cognition.\n2.2. Language acquisition\nLanguage acquisition is another domain where computation models and cognitive\nsciences have a fruitful dialogue. To a certain extent, neuro-imaging has renewed the\nstudy of language by making it possible to directly observe processes in the brain\n(?) but for the rest, language is only known through direct production, i.e. language\nutterances. Therefore, the study of language acquisition by children is crucial, since it\ngives an overview on what vocabulary and structures are mastered ﬁrst, what untypical\nconstructions (when compared to adult speech) are used by children during learning,\netc.\nThe study of language acquisition has seen important developments recently\nthanks to the development of automatic approaches. The main reason for these new\napproaches is the availability of large amont of data in the Childes database (?), es-\npecially for English, but also for other languages, French being especially well rep-\nresented here (?). Most recordings concern discussions between children and adults\nin real life situations (during dinner, bath, play, etc.). Videos are generally available\nso as to allow a multimodal approach to the study of language acquisition. Most\ncorpora are annotated with morphosyntactic information (?), and parts of the corpus\nhave received other kinds of annotation, including syntactic tags (?) and more rarely\nsemantic or multimodal annotations (concerning gestures for example) (?). The Talk-\nbank project has accumulated multimodal information in a more systematic way (?).\nIntroduction\n11\nOne should also mention Roy, who has systematically recorded the ﬁrst years of his\nson, producing thousands of hours of videos (?). However, this mass of data is not\nstructured and not tagged, making it hard to be used by researchers, on top of the\nethic problem that this kind of recordings may pose. One speciﬁcity of most of these\ncorpora is to provide longitudinal data. They generally make it possible to follow\nlanguage development of a single child over several months.\nLanguage acquisition studies concern mainly the development of the language\nability in young children, the complexity of their speech in accordance with their age,\nand the comparison of children productions with adult ones (?). Corpora make it pos-\nsible to observe statistical properties in children speech: size of the vocabulary used,\naverage length of the utterances, constructions effectively used, etc. (?). Some other\nvariables can be observed like the inﬂuence of adult speech on children production\nas well as social and gender inﬂuence. Corpora make observation more direct but do\nnot provide a direct answer to more theoretical questions like the famous “poverty of\nstimulus” (?; ?; ?). Lastly, researchers also tried to develop computational models that\nreproduce speciﬁc parts of the language acquisition process itself, like the acquisition\nof subcatgorization frames or of semantic categories (?; ?; ?).\nMost data included in Childes concern on average one hour of recording per month\nper child or more rarely per week, which means only a very small fractions of the\nchild production is available. Not all the situations are represented so that mixing\ndifferent corpora together does not always solve the problem: data may still be biased,\nquite unbalanced and unrepresentative. The project from Roy mentioned above (?)\nwas precisely supposed to overcome some of these limitations by providing a nearly\nexhaustive recording of the child input, but we have seen that this massive set of data\nis unstructured and therefore hard to process.\n2.3. Language pathologies\nThe study of the production of people with language pathologies has also attracted\na high interest in the last decades, see for one example among many others (?). This\nﬁeld can be compared, to a certain extent, to the research done in language acquisition:\nthe idea is to get an accurate description of the production of people with languages\npathologies so as to ﬁnd what is deﬁcient in their speech and then propose relevant\ntreatments or relevant measures to help them overcome their difﬁculties (?; ?). Ad-\nditionally cognitive science has of course a long tradition of mapping language deﬁ-\nciencies with speciﬁc areas in the brain.\nOne of the main challenges for studies in language pathologies is to access large\nand representative corpora that are still lacking in the ﬁeld (?). Most studies are based\non small size data that may not be representative enough. Gathering large corpora\nis possible but pause multiple problems, from ﬁnding enough people with a similar\npathology to ethical issues that are especially high here.\n12\nTAL. Volume 55 – n˚ 3/2014\n2.4. Language evolution\nAt ﬁrst sight, language evolution can be seen more as a social process than as a\ncognitive one. However, language evolution has to take into account how a group of\nindividuals master a language and transmit this knowledge to their infants. This is the\ncore of social cognition, that aims at studying how individual knowledge interacts so\nas to give birth to social processes. Language evolution can thus be seen as one of the\ncentral topics of social cognition (?; ?). It is our position here.\nResearch on language evolution has been booming in the late 1990s and early\n2000s giving birth to a series of important conference called Evolang (held every\nother year since 1996). Computational models play a major role in this ﬁeld since\nthey make it possible to observe the inﬂuence of various parameters in the evolution\nof languages. Christiansen and Kirby (?) propose to categorize research in this ﬁeld\nin three broad categories:\n1) evaluation: computational models require to make explicit all the variables and\nparameters used and can thus be seen as a “rigorous check” of model hypotheses and\nhelp identify hidden variables;\n2) exploration: simulations can be used to see how a population of agents evolve\nfrom a particular initial situation, materialized in the computational model through a\nparticular settings of its parameters;\n3) exempliﬁcation: computational models can be used as a tool to demonstrate\n“how an explanation works”, especially for pedagogical purposes.\nIn fact, these different categories are not exclusive, and nearly all simulations serve\nat the same time as a proof, as an illustration, and provide new ideas for further exper-\niments. Most simulations are based on multi-agent systems, where large populations\nof agents give birth to new generations of agents at regular intervals. They transmit\ntheir language to new generations according to various parameters as said above. The\nevolution of different linguistic features (addressing phonology, morphology, syntax\nor even semantics) can thus be studied in this framework, see for example (?; ?; ?)\namong many other references.\nIt should ﬁnally be noted that most simulations with multi-agent systems offer a\nquite abstract representation of the evolution of real languages (these simulations can\neven be completely abstract and related to populations of robots for example (?)). This\nis probably one of the main reasons of the apparent recent decrease of interest towards\nthis ﬁeld of research: computational models proposed so far were quite abstract and\nare hard to prove or justify against real world data. One of the challenge is thus now\nto better connect these models with real world data, which is a long term and highly\nchallenging task (see (?) for a recent example).\nIntroduction\n13\n3. Content of this special issue\nThis special issue is dedicated to get a better picture of the relationships between\ncomputational linguistics and cognitive science. It speciﬁcally raises two questions:\n“what is the potential contribution of computational language modeling to cognitive\nscience?” and conversely: “what is the inﬂuence of cognitive science in contemporary\ncomputational linguistics?”\nThe call for papers speciﬁcally targeted contributions on actual applications of\nmethods from computational linguistics aiming at modeling cognitively motivated\nphenomena, as well as applications of cognitive theories to the computational model-\ning of language.\nThe following topics were proposed:\n– Computational models of natural language acquisition, word clustering and word\nsegmentation\n– Psycholinguistically motivated phonetic, phonological, morphological syntactic,\nsemantic, pragmatic studies of language\n– Statistical and probabilistic modeling of factors encouraging one production or\ninterpretation over its competitors\n– Models of language emergence, change and evolution\n– Models of language processing and surprisal\n– Experimental or corpus driven modeling and analysis of language\nWe have received seven submissions, and four of them have been selected for\npublication (two of them written in English and two in French). We think they give\na good overview of some recent research trends: the four articles cover very different\nareas of the ﬁeld, although they of course do not represent the whole ﬁeld.\nThe ﬁrst paper, by Maxime Amblard, Karën Fort, Caroline Demily, Nicolas Franck\nand Michel Musiol is entitled “Analyse lexicale outillée de la parole transcrite de pa-\ntients schizophrènes” (“Machine-assisted lexical analysis of speech transcripts from\nschizophrenic patients”). The paper reports some recent results obtained from the\nanalysis of transcriptions of audio recordings of people suffering from schizophrenia.\nThe corpus at stake contains 375.000 tokens, which is considerably larger than previ-\nous similar corpora and makes it necessary to use natural language processing tools for\nthe analysis. The paper mainly investigates disﬂuencies and the use of lexical forms.\nThe main conclusion is that although people with schizophrenia produce more dis-\nﬂuencies, their discourse does not seem speciﬁc concerning the use of lexical forms,\ncontrary to a commonly held hypothesis. This paper illustrates how natural language\nprocessing now plays a major role in understanding language pathologies.\nThe second paper, by Quentin Feltgen, Benjamin Fagard and Jean-Pierre Nadal\nis entitled “Représentation et évolution du langage dans les modèles numériques :\nla grammaticalisation comme perspective” (“Language representation and models of\nlanguage evolution: A grammaticalization perspective”). The authors investigate the\n14\nTAL. Volume 55 – n˚ 3/2014\nnotion of “grammaticalization”, a well known linguistic phenomenon where some\nwords or expressions become gradually frozen so as to play a grammatical role (the\nmost well known example in French is the noun “pas” that has completely lost its orig-\ninal meaning when the word is used as a negation in contemporary French). Even if\na large number of recent projects in computational linguistics have explored language\nevolution, phenomena such as grammaticalization seem to have been put aside in the\ncomputational community, despite the high success of this notion among historical\nlinguists. Within this context, the authors propose a new model illustrating, among\nother things, the loss of semantic content, known as “semantic bleaching” (?) (often\ntranslated as “javellisation sémantique” in French).\nThe third paper, by Ákos Kádár, Afra Alishahi and Grzegorz Chrupała is entitled\n“Learning word meanings from images of natural scenes”. The paper investigates how\nto associate word meanings with objects (through images) in noisy environments. To\naddress this question, the authors use a large collection of images with natural lan-\nguage descriptions. The idea is to detect regularities and gradually create associations\nbetween words and image features. The authors show that their model correlates with\nhuman similarity judgments of word pairs when taking into account ambiguity and\nreferential uncertainty. A parallel can be drawn with learning words in real life en-\nvironments where children need to identify which aspects of the scenes are related to\nwhich parts of the perceived utterances.\nThe last paper, from Bruno Gaume, Karine Duvignau, Emmanuel Navarro, Yann\nDesalle, Hintat Cheung, Shu-Kai Hsieh, Pierre Magistry and Laurent Prévot is en-\ntitled “Skillex: a graph-based lexical score for measuring the semantic efﬁciency of\nused verbs by human subjects describing actions”. The authors are interested in the\nconceptual organization of lexical networks. They describe a technique to derive a\nsemantic network from a dictionary and show that, despite surface disagreements,\nnetworks derived from different dictionaries all share the same topological structure.\nThey assume that this structure is meaningful from a cognitive point of view and they\nshow how this assumption can be used to evaluate action labelling tasks. They present\na technique for the evaluation of what they call “naming efﬁciency” and detail a com-\nparison involving children and adults.\nAcknowledgements\nWe thank the journal editors Éric de la Clergerie, Yves Lepage, Jean-Luc Minel\nand Pascale Sébillot, as well as the following reviewers, for their efforts in making\nthis special issue possible:\n– F. Alario (LPC, Univ. Aix-Marseille, France),\n– A. Alishahi (Tilburg University, The Netherlands),\n– M. Amblard (LORIA, Univ. de Lorraine, France),\n– P. Blache (LPL, Aix-en-Provence, France),\nIntroduction\n15\n– A. Christophe (LSCP, Paris, France),\n– S. Colonna (SFL, Univ. Paris-VIII, France),\n– I. Dautriche (LSCP, Paris, France),\n– E. Dupoux (LSCP, Paris, France),\n– T. Francois (Cental, UCL, Belgium),\n– B. Gaume (CLLE-ERSS, Toulouse, France),\n– J. Ginzburg (CLILLAC, Univ. Paris-VII, France),\n– M. Grant (McGill University, Canada),\n– J. Hale (Cornell University, USA),\n– B. Hemforth (LLF, Univ. Paris-VII, France),\n– P. Logacev (Potsdam University, Germany),\n– F. Pellegrino (DDL, Lyon, France),\n– D. Reitter (Penn State University, USA),\n– E. Shutova (U. Berkeley, USA),\n– J. Thuilier (CLLE-ERSS, Univ. Toulouse Jean-Jaurès, France),\n– A. Villavicencio (UFRGS, Brazil),\n– T. von der Malsburg (UC San Diego, USA),\n– M. Zock (LIF, Marseille, France).\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.HC"
  ],
  "published": "2016-10-24",
  "updated": "2016-10-24"
}