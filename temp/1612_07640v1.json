{
  "id": "http://arxiv.org/abs/1612.07640v1",
  "title": "Deep Learning and Its Applications to Machine Health Monitoring: A Survey",
  "authors": [
    "Rui Zhao",
    "Ruqiang Yan",
    "Zhenghua Chen",
    "Kezhi Mao",
    "Peng Wang",
    "Robert X. Gao"
  ],
  "abstract": "Since 2006, deep learning (DL) has become a rapidly growing research\ndirection, redefining state-of-the-art performances in a wide range of areas\nsuch as object recognition, image segmentation, speech recognition and machine\ntranslation. In modern manufacturing systems, data-driven machine health\nmonitoring is gaining in popularity due to the widespread deployment of\nlow-cost sensors and their connection to the Internet. Meanwhile, deep learning\nprovides useful tools for processing and analyzing these big machinery data.\nThe main purpose of this paper is to review and summarize the emerging research\nwork of deep learning on machine health monitoring. After the brief\nintroduction of deep learning techniques, the applications of deep learning in\nmachine health monitoring systems are reviewed mainly from the following\naspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and\nits variants including Deep Belief Network (DBN) and Deep Boltzmann Machines\n(DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN).\nFinally, some new trends of DL-based machine health monitoring methods are\ndiscussed.",
  "text": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n1\nDeep Learning and Its Applications to Machine\nHealth Monitoring: A Survey\nRui Zhao, Ruqiang Yan, Zhenghua Chen, Kezhi Mao, Peng Wang, and Robert X. Gao\nAbstract—Since 2006, deep learning (DL) has become a rapidly\ngrowing research direction, redeﬁning state-of-the-art perfor-\nmances in a wide range of areas such as object recognition,\nimage segmentation, speech recognition and machine translation.\nIn modern manufacturing systems, data-driven machine health\nmonitoring is gaining in popularity due to the widespread\ndeployment of low-cost sensors and their connection to the\nInternet. Meanwhile, deep learning provides useful tools for\nprocessing and analyzing these big machinery data. The main\npurpose of this paper is to review and summarize the emerging\nresearch work of deep learning on machine health monitoring.\nAfter the brief introduction of deep learning techniques, the\napplications of deep learning in machine health monitoring\nsystems are reviewed mainly from the following aspects: Auto-\nencoder (AE) and its variants, Restricted Boltzmann Machines\nand its variants including Deep Belief Network (DBN) and Deep\nBoltzmann Machines (DBM), Convolutional Neural Networks\n(CNN) and Recurrent Neural Networks (RNN). Finally, some\nnew trends of DL-based machine health monitoring methods are\ndiscussed.\nIndex Terms—Deep learning, machine health monitoring, big\ndata\nI. INTRODUCTION\nI\nNDUSTRIAL Internet of Things (IoT) and data-driven\ntechniques have been revolutionizing manufacturing by\nenabling computer networks to gather the huge amount of\ndata from connected machines and turn the big machinery data\ninto actionable information [1], [2], [3]. As a key component\nin modern manufacturing system, machine health monitoring\nhas fully embraced the big data revolution. Compared to\ntop-down modeling provided by the traditional physics-based\nmodels [4], [5], [6] , data-driven machine health monitoring\nsystems offer a new paradigm of bottom-up solution for\ndetection of faults after the occurrence of certain failures\n(diagnosis) and predictions of the future working conditions\nand the remaining useful life (prognosis) [1], [7]. As we\nknow, the complexity and noisy working condition hinder the\nconstruction of physical models. And most of these physics-\nbased models are unable to be updated with on-line measured\ndata, which limits their effectiveness and ﬂexibility. On the\nother hand, with signiﬁcant development of sensors, sensor\nnetworks and computing systems, data-driven machine health\nmonitoring models have become more and more attractive.\nTo extract useful knowledge and make appropriate decisions\nfrom big data, machine learning techniques have been regarded\nas a powerful solution. As the hottest subﬁeld of machine\nR. Yan is the corresponding author. E-mail: ruqiang@seu.edu.cn\nThis manuscript has been submitted to IEEE Transactions on Neural Networks\nand Learning Systems\nlearning, deep learning is able to act as a bridge connecting\nbig machinery data and intelligent machine health monitoring.\nAs a branch of machine learning, deep learning attempts\nto model high level representations behind data and clas-\nsify(predict) patterns via stacking multiple layers of informa-\ntion processing modules in hierarchical architectures. Recently,\ndeep learning has been successfully adopted in various areas\nsuch as computer vision, automatic speech recognition, natural\nlanguage processing, audio recognition and bioinformatics [8],\n[9], [10], [11]. In fact, deep learning is not a new idea, which\neven dates back to the 1940s [12], [13]. The popularity of deep\nlearning today can be contributed to the following points:\n* Increasing Computing Power: the advent of graphics\nprocessor unit (GPU), the lowered cost of hardware,\nthe better software infrastructure and the faster network\nconnectivity all reduce the required running time of\ndeep learning algorithms signiﬁcantly. For example, as\nreported in [14], the time required to learn a four-layer\nDBN with 100 million free parameters can be reduced\nfrom several weeks to around a single day.\n* Increasing Data Size: there is no doubt that the era\nof Big Data is coming. Our activities are almost all\ndigitized, recorded by computers and sensors, connected\nto Internet, and stored in cloud. As pointed out in [1]\nthat in industry-related applications such as industrial\ninformatics and electronics, almost 1000 exabytes are\ngenerated per year and a 20-fold increase can be ex-\npected in the next ten years. The study in [3] predicts\nthat 30 billion devices will be connected by 2020.\nTherefore, the huge amount of data is able to offset the\ncomplexity increase behind deep learning and improve\nits generalization capability.\n* Advanced Deep Learning Research: the ﬁrst break-\nthrough of deep learning is the pre-training method in\nan unsupervised way [15], where Hinton proposed to\npre-train one layer at a time via restricted Boltzmann\nmachine (RBM) and then ﬁne-tune using backpropaga-\ntion. This has been proven to be effective to train multi-\nlayer neural networks.\nConsidering the capability of deep learning to address large-\nscale data and learn high-level representation, deep learn-\ning can be a powerful and effective solution for machine\nhealth monitoring systems (MHMS). Conventional data-driven\nMHMS usually consists of the following key parts: hand-\ncrafted feature design, feature extraction/selection and model\ntraining. The right set of features are designed, and then pro-\nvided to some shallow machine learning algorithms including\narXiv:1612.07640v1  [cs.LG]  16 Dec 2016\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n2\nSupport Vector Machines (SVM), Naive Bayes (NB), logistic\nregression [16], [17], [18]. It is shown that the representation\ndeﬁnes the upper-bound performances of machine learning\nalgorithms [19]. However, it is difﬁcult to know and determine\nwhat kind of good features should be designed. To alleviate\nthis issue, feature extraction/selection methods, which can be\nregarded as a kind of information fusion, are performed be-\ntween hand-crafted feature design and classiﬁcation/regression\nmodels [20], [21], [22]. However, manually designing features\nfor a complex domain requires a great deal of human labor\nand can not be updated on-line. At the same time, feature\nextraction/selection is another tricky problem, which involves\nprior selection of hyperparameters such as latent dimension.\nAt last, the above three modules including feature design,\nfeature extraction/selection and model training can not be\njointly optimized which may hinder the ﬁnal performance of\nthe whole system. Deep learning based MHMS (DL-based\nMHMS) aim to extract hierarchical representations from input\ndata by building deep neural networks with multiple layers of\nnon-linear transformations. Intuitively, one layer operation can\nbe regarded as a transformation from input values to output\nvalues. Therefore, the application of one layer can learn a\nnew representation of the input data and then, the stacking\nstructure of multiple layers can enable MHMS to learn com-\nplex concepts out of simpler concepts that can be constructed\nfrom raw input. In addition, DL-based MHMS achieve an\nend-to-end system, which can automatically learn internal\nrepresentations from raw input and predict targets. Compared\nto conventional data driven MHMS, DL-based MHMS do\nnot require extensive human labor and knowledge for hand-\ncrafted feature design. All model parameters including feature\nmodule and pattern classiﬁcation/regression module can be\ntrained jointly. Therefore, DL-based models can be applied\nto addressing machine health monitoring in a very general\nway. For example, it is possible that the model trained for\nfault diagnosis problem can be used for prognosis by only\nreplacing the top softmax layer with a linear regression layer.\nThe comparison between conventional data-driven MHMS and\nDL-based MHMS is given in Table I. A high-level illustration\nof the principles behind these three kinds of MHMS discussed\nabove is shown in Figure 1.\nDeep learning models have several variants such as Auto-\nDncoders [23], Deep Belief Network [24], Deep Boltzmann\nMachines [25], Convolutional Neural Networks [26] and Re-\ncurrent Neural Networks [27]. During recent years, various\nresearchers have demonstrated success of these deep learn-\ning models in the application of machine health monitoring.\nThis paper attempts to provide a wide overview on these\nlatest DL-based MHMS works that impact the state-of-the\nart technologies. Compared to these frontiers of deep learning\nincluding Computer Vision and Natural Language Processing,\nmachine health monitoring community is catching up and\nhas witnessed an emerging research. Therefore, the purpose\nof this survey article is to present researchers and engineers\nin the area of machine health monitoring system, a global\nview of this hot and active topic, and help them to acquire\nbasic knowledge, quickly apply deep learning models and\ndevelop novel DL-based MHMS. The remainder of this paper\nis organized as follows. The basic information on these above\ndeep learning models are given in section II. Then, section\nIII reviews applications of deep learning models on machine\nhealth monitoring. Finally, section IV gives a brief summary\nof the recent achievements of DL-based MHMS and discusses\nsome potential trends of deep learning in machine health\nmonitoring.\nII. DEEP LEARNING\nOriginated from artiﬁcial neural network, deep learning is a\nbranch of machine learning which is featured by multiple non-\nlinear processing layers. Deep learning aims to learn hierarchy\nrepresentations of data. Up to date, there are various deep\nlearning architectures and this research topic is fast-growing,\nin which new models are being developed even per week.\nAnd the community is quite open and there are a number\nof deep learning tutorials and books of good-quality [28],\n[29]. Therefore, only a brief introduction to some major deep\nlearning techniques that have been applied in machine health\nmonitoring is given. In the following, four deep architectures\nincluding Auto-encoders, RBM, CNN and RNN and their\ncorresponding variants are reviewed, respectively.\nA. Auto-encoders (AE) and its variants\nAs a feed-forward neural network, auto-encoder consists of\ntwo phases including encoder and decoder. Encoder takes an\ninput x and transforms it to a hidden representation h via a\nnon-linear mapping as follows:\nh = ϕ(Wx + b)\n(1)\nwhere ϕ is a non-linear activation function. Then, decoder\nmaps the hidden representation back to the original represen-\ntation in a similar way as follows:\nz = ϕ(W\n′h + b\n′)\n(2)\nModel parameters including θ = [W, b, W\n′, b\n′] are optimized\nto minimize the reconstruction error between z = fθ(x)\nand x. One commonly adopted measure for the average\nreconstruction error over a collection of N data samples is\nsquared error and the corresponding optimization problem can\nbe written as follows:\nmin\nθ\n1\nN\nN\nX\ni\n(xi −fθ(xi))2\n(3)\nwhere xi is the i-th sample. It is clearly shown that AE can be\ntrained in an unsupervised way. And the hidden representation\nh can be regarded as a more abstract and meaningful repre-\nsentation for data sample x. Usually, the hidden size should\nbe set to be larger than the input size in AE, which is veriﬁed\nempirically [30].\nAddition of Sparsity: To prevent the learned transformation\nis the identity one and regularize auto-encoders, the sparsity\nconstraint is imposed on the hidden units [31]. The corrspond-\ning optimization function is updated as:\nmin\nθ\n1\nN\nN\nX\ni\n(xi −fθ(xi))2 +\nm\nX\nj\nKL(p||pj)\n(4)\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n3\nMonitored Machines\nHand-designed Features\nData Acquisition\nModel Training\n2\n4\n6\n8\n10\n12\n14\n16\nx 10\n4\n-5\n0\n5\n10\nFx/N\nSample Data\nRMS /Variance/ \nMaximum /Minimum/ \nSkewness /Kurtosis/ \nPeak/ Kurtosis Index/ \nWavelet Energy \nSupport Vector \nMachines \nRandom Forest\nNeural \nNetworks\nMonitored Machines\nHand-designed Physical \nModels\nTargets\nData Acquisition\n2\n4\n6\n8\n10\n12\n14\n16\nx 10\n4\n-5\n0\n5\n10\nFx/N\nSample Data\nMonitored Machines\nData Acquisition\n2\n4\n6\n8\n10\n12\n14\n16\nx 10\n4\n-5\n0\n5\n10\nFx/N\nSample Data\nFeature Selection/\nExtraction Methods\nLDA\nICA\nPCA\nTargets\nFrom Simple Features to Abstract Features\nTargets\nPhysical-based \nMHMS \nConventional Data-driven \nMHMS \nDeep Learning based \nMHMS \nSoftmax/\nRegression\nFig. 1.\nFrameworks showing three different MHMS including Physical Model, Conventional Data-driven Model and Deep Learning Models. Shaded boxes\ndenote data-driven components.\nTABLE I\nSUMMARY ON COMPARISON BETWEEN CONVENTIONAL DATA-DRIVEN MHMS AND DL-BASED MHMS.\nMHMS\nConventional Data-driven Methods\nDeep Learning Methods\nExpert knowledge and extensive human labor required for Hand-crafted features\nEnd-to-end structure without hand-crafted features\nIndividual modules are trained step-by-step\nAll parameters are trained jointly\nUnable to model large-scale data\nSuitable for large-scale data\nwhere m is the hidden layer size and the second term is the\nsummation of the KL-divergence over the hidden units. The\nKL-divergence on j-th hidden neuron is given as:\nKL(p||pj) = plog( p\npj\n) + (1 −p)log( 1 −p\n1 −pj\n)\n(5)\nwhere p is the predeﬁned mean activation target and pj is the\naverage activation of the j-th hidden neuron over the whole\ndatasets. Given a small p, the addition of sparsity constraint\ncan lead the learned hidden representation to be a sparse\nrepresentation. Therefore, the variant of AE is named sparse\nauto-encoder.\nAddition of Denoising: Different from conventional AE,\ndenoising AE takes a corrupted version of data as input and\nis trained to reconstruct/denoise the clean input x from its\ncorrupted sample ˜x. The most common adopted noise is\ndropout noise/binary masking noise, which randomly sets a\nfraction of the input features to be zero [23]. The variant of\nAE is denoising auto-encoder (DA), which can learn more\nrobust representation and prevent it from learning the identity\ntransformation.\nStacking Structure: Several DA can be stacked together to\nform a deep network and learn high-level representations by\nfeeding the outputs of the l-th layer as inputs to the (l + 1)-th\nlayer [23]. And the training is done one layer greedily at a\ntime.\nSince auto-encoder can be trained in an unsupervised\nway, auto-encoder, especially stacked denoising auto-encoder\n(SDA), can provide an effective pre-training solution via\ninitializing the weights of deep neural network (DNN) to\ntrain the model. After layer-wise pre-training of SDA, the\nparameters of auto-encoders can be set to the initialization for\nall the hidden layers of DNN. And then, the supervised ﬁne-\ntuning is performed to minimize prediction error on a labeled\ntraining data. Usually, a softmax/regression layer is added on\ntop of the network to map the output of the last layer in AE\nto targets. The whole process is shown in Figure 2. The pre-\ntraining protocol based on SDA can make DNN models have\nbetter convergence capability compared to arbitrary random\ninitialization.\nB. RBM and its variants\nAs a special type of Markov random ﬁeld, restricted Boltz-\nmann machine (RBM) is a two-layer neural network forming a\nbipartite graph that consists of two groups of units including\nvisible units v and hidden units h under the constrain that\nthere exists a symmetric connection between visible units and\nhidden units and there are no connections between nodes with\na group.\nGiven the model parameters θ = [W, b, a], the energy\nfunction can be given as:\nE(v, h; θ) = −\nI\nX\ni=1\nJ\nX\nj=1\nwijvihj −\nI\nX\ni=1\nbivi −\nJ\nX\nj=1\najhj\n(6)\nthat wij is the connecting weight between visible unit vi,\nwhose total number is I and hidden unit hj whose total\nnumber is J, bi and aj denote the bias terms for visible units\nand hidden units, respectively. The joint distribution over all\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n4\nx\nh1\nh1\nx\nh2\nx\nh1\nh2\ny\nUnsupervised Layer-wise Pretraining    \nSupervised Fine-tuning\nx\nh1\nh1\nx\nh2\nUnsupervised Layer-wise Pretraining    \nSupervised Fine-tuning\nh1\nx\nh2\ny\n(a) SDA-based DNN\n(b) DBN-based DNN\nFig. 2.\nIllustrations for Unsupervised Pre-training and Supervised Fine-tuning of SAE-DNN (a) and DBN-DNN (b).\nthe units is calculated based on the energy function E(v, h; θ)\nas:\np(v, h; θ) = exp(−E(v, h; θ))\nZ\n(7)\nwhere Z = P\nh;v exp(−E(v, h; θ)) is the partition function\nor normalization factor. Then, the conditional probabilities of\nhidden and visible units h and v can be calculated as:\np(hj = 1|v; θ) = δ(\nI\nX\ni=1\nwijvi + aj)\n(8)\np(vi = 1|v; θ) = δ(\nJ\nX\nj=1\nwijhj + bi)\n(9)\nwhere δ is deﬁned as a logistic function i.e., δ(x) =\n1\n1+exp(x).\nRBM are trained to maximize the joint probability. The\nlearning of W is done through a method called contrastive\ndivergence (CD).\nDeep Belief Network: Deep belief networks (DBN) can be\nconstructed by stacking multiple RBMs, where the output of\nthe l-th layer (hidden units) is used as the input of the (l+1)-\nth layer (visible units). Similar to SDA, DBN can be trained in\na greedy layer-wise unsupervised way. After pre-training, the\nparameters of this deep architecture can be further ﬁne-tuned\nwith respect to a proxy for the DBN log- likelihood, or with\nrespect to labels of training data by adding a softmax layer as\nthe top layer, which is shown in Figure 2.(b).\nDeep Boltzmann Machine: Deep Boltzmann machine (DBM)\ncan be regarded as a deep structured RMBs where hidden\nunits are grouped into a hierarchy of layers instead of a single\n…\n…\nRBM\n…\n…\n…\n…\n…\n…\n…\n…\nDBN\nDBM\nFig. 3.\nFrameworks showing RBM, DBN and DBM. Shaded boxes denote\nhidden untis.\nlayer. And following the RMB’s connectivity constraint, there\nis only full connectivity between subsequent layers and no\nconnections within layers or between non-neighbouring layers\nare allowed. The main difference between DBN and DBM lies\nthat DBM is fully undirected graphical model, while DBN\nis mixed directed/undirected one. Different from DBN that\ncan be trained layer-wisely, DBM is trained as a joint model.\nTherefore, the training of DBM is more computationally\nexpensive than that of DBN.\nC. Convolutioanl Neural Network\nConvolutional neural networks (CNNs) were ﬁrstly pro-\nposed by LeCun [32] for image processing, which is featured\nby two key properties: spatially shared weights and spatial\npooling. CNN models have shown their success in various\ncomputer vision applications [32], [33], [34] where input data\nare usually 2D data. CNN has also been introduced to address\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n5\nsequential data including Natural Language Processing and\nSpeech Recognition [35], [36].\nCNN aims to learn abstract features by alternating and\nstacking convolutional kernels and pooling operation. In CNN,\nthe convolutional layers (convolutional kernels) convolve mul-\ntiple local ﬁlters with raw input data and generate invariant\nlocal features and the subsequent pooling layers extract most\nsigniﬁcant features with a ﬁxed-length over sliding windows of\nthe raw input data. Considering 2D-CNN have been illustrated\nextensively in previous research compared to 1D-CNN, here,\nonly the mathematical details behind 1D-CNN is given as\nfollows:\nFirstly, we assume that the input sequential data is x =\n[x1, . . . , xT ] that T is the length of the sequence and xi ∈Rd\nat each time step.\nConvolution: the dot product between a ﬁlter vector u ∈Rmd\nand an concatenation vector representation xi:i+m−1 deﬁnes\nthe convolution operation as follows:\nci = ϕ(uT xi:i+m−1 + b)\n(10)\nwhere ∗T represents the transpose of a matrix ∗, b and ϕ\ndenotes bias term and non-linear activation function, respec-\ntively. xi:i+m−1 is a m-length window starting from the i-th\ntime step, which is described as:\nxi:i+m−1 = xi ⊕xi+1 ⊕· · · ⊕xi+m−1\n(11)\nAs deﬁned in Eq. (10), the output scale ci can be regarded as\nthe activation of the ﬁlter u on the corresponding subsequence\nxi:i+m−1. By sliding the ﬁltering window from the beginning\ntime step to the ending time step, a feature map as a vector\ncan be given as follows:\ncj = [c1, c2, . . . , cl−m+1]\n(12)\nwhere the index j represents the j-th ﬁlter. It corresponds to\nmulti-windows as {x1:m, x2:m+1, . . . , xl−m+1:l}.\nMax-pooling: Pooling layer is able to reduce the length of the\nfeature map, which can further minimize the number of model\nparameters. The hyper-parameter of pooling layer is pooling\nlength denoted as s. MAX operation is taking a max over the\ns consecutive values in feature map cj.\nThen, the compressed feature vector can be obtained as:\nh =\nh\nh1, h2, . . . , h l−m\ns\n+1\ni\n(13)\nwhere hj = max(c(j−1)s, c(j−1)s+1, . . . , cjs−1). Then, via\nalternating the above two layers: convolution and max-pooling\nones, fully connected layers and a softmax layer are usually\nadded as the top layers to make predictions. To give a clear\nillustration, the framework for a one-layer CNN has been\ndisplayed in Figure. 4.\nD. Recurrent Neural Network\nAs stated in [12], recurrent neural networks (RNN) are the\ndeepest of all neural networks, which can generate and address\nmemories of arbitrary-length sequences of input patterns. RNN\nis able to build connections between units from a directed\ncycle. Different from basic neural network: multi-layer per-\nceptron that can only map from input data to target vectors,\nRNN is able to map from the entire history of previous inputs\nto target vectors in principal and allows a memory of previous\ninputs to be kept in the network’s internal state. RNNs can be\ntrained via backpropagation through time for supervised tasks\nwith sequential input data and target outputs [37], [27], [38].\nRNN can address the sequential data using its internal\nmemory, as shown in Figure 5. (a). The transition function\ndeﬁned in each time step t takes the current time information\nxt and the previous hidden output ht−1 and updates the current\nhidden output as follows:\nht = H(xt, ht−1)\n(14)\nwhere H deﬁnes a nonlinear and differentiable transformation\nfunction. After processing the whole sequence, the hidden\noutput at the last time step i.e. hT is the learned representation\nof the input sequential data whose length is T. A conventional\nMultilayer perceptron (MLP) is added on top to map the\nobtained representation hT to targets.\nVarious transition functions can lead to various RNN mod-\nels. The most simple one is vanilla RNN that is given as\nfollows:\nht = ϕ(Wxt + Hht−1 + b)\n(15)\nwhere W and H denote transformation matrices and b is the\nbias vector. And ϕ denote the nonlinear activation function\nsuch as sigmoid and tanh functions. Due to the vanishing\ngradient problem during backpropagation for model training,\nvanilla RNN may not capture long-term dependencies. There-\nfore, Long-short term memory (LSTM) and gated recurrent\nneural networks (GRU) were presented to prevent backprop-\nagated errors from vanishing or exploding [39], [40], [41],\n[42], [43]. The core idea behind these advanced RNN variants\nis that gates are introduced to avoid the long-term dependency\nproblem and enable each recurrent unit to adaptively capture\ndependencies of different time scales.\nBesides these proposed advanced transition functions such\nas LSTMs and GRUs, multi-layer and bi-directional recurrent\nstructure can increase the model capacity and ﬂexibility. As\nshown in Figure 5.(b), multi-layer structure can enable the\nhidden output of one recurrent layer to be propagated through\ntime and used as the input data to the next recurrent layer.\nAnd the bidirectional recurrent structure is able to process\nthe sequence data in two directions including forward and\nbackward ways with two separate hidden layers, which is\nillustrated in Figure 5.(c). The following equations deﬁne the\ncorresponding hidden layer function and the →and ←denote\nforward and backward process, respectively.\n−→\nh t = −→\nH(xt, −→\nh t−1),\n←−\nh t = ←−\nH(xt, ←−\nh t+1).\n(16)\nThen, the ﬁnal vector hT is the concatenated vector of the\noutputs of forward and backward processes as follows:\nhT = −→\nh T ⊕←−\nh 1\n(17)\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n6\nConvolutional Layer\nFeature\nMap 1\nFeature\nMap 2\nFeature\nMap k\nMax-pooling Layer\nTime Steps\nTargets\nFlatten\nSoftmax Layer\nFully-Connected Layer\nFig. 4.\nIllustrations for one-layer CNN that contains one convolutional layer, one pooling layer, one fully-connected layer, and one softmax layer.\n1\nX\n2\nX\n3\nX\n1\nT\nX \nT\nX\nT\nh\nTime Series \n1\nX\n2\nX\n3\nX\n1\nT\nX \nT\nX\n3\nTh\nTime Series \n2\n1h\n1\n1\nh\n1\nT\nh\n1\n2\nh\n2\n2h\n2\nTh\n(a) Basic RNN\n(b) Stacked RNN\n(c) Bidirectional RNN\n1\nX\n2\nX\n3\nX\n1\nT\nX \nT\nX\nT\nh\nConcatenated\nT\nh\nTime Series \nFig. 5.\nIllustrations of normal RNN, stacked RNN and bidirectional RNN.\nIII. APPLICATIONS OF DEEP LEARNING IN MACHINE\nHEALTH MONITORING\nThe conventional multilayer perceptron (MLP) has been\napplied in the ﬁeld of machine health monitoring for many\nyears [44], [45], [46], [47]. The deep learning techniques have\nrecently been applied to a large number of machine health\nmonitoring systems. The layer-by-layer pretraining of deep\nneural network (DNN) based on Auto-encoder or RBM can\nfacilitate the training of DNN and improve its discriminative\npower to characterize machinery data. Convolution neural\nnetwork and recurrent neural networks provide more advanced\nand complex compositions mechanism to learn representation\nfrom machinery data. In these DL-based MHMS systems,\nthe top layer normally represents the targets. For diagnosis\nwhere targets are discrete values, softmax layer is applied.\nFor prognosis with continuous targets, liner regression layer\nis added. What is more, the end-to-end structure enables DL-\nbased MHMS to be constructed with less human labor and\nexpert knowledge, therefore these models are not limited to\nspeciﬁc machine speciﬁc or domain. In the following, a brief\nsurvey of DL-based MHMS are presented in these above four\nDL architectures: AE, RBM, CNN and RNN.\nA. AE and its variants for machine health monitoring\nAE models, especially stacked DA, can learn high-level\nrepresentations from machinery data in an automatic way. Sun\net al. proposed a one layer AE-based neural network to classify\ninduction motor faults [48]. Due to the limited size of training\ndata, they focused on how to prevent overﬁting. Not only\nthe number of hidden layer was set to 1, but also dropout\ntechnique that masks portions of output neurons randomly\nwas applied on the hidden layer. However, most of proposed\nmodels are based on deep architectures by stacking multiple\nauto-encoders. Lu et al. presented a detailed empirical study\nof stacked denoising autoencoders with three hidden layers for\nfault diagnosis of rotary machinery components [49]. Speciﬁ-\ncally, in their experiments including single working condition\nand cross working conditions, the effectiveness of the receptive\ninput size, deep architecture, sparsity constraint and denosing\noperation in the SDA model were evaluated. In [50], different\nstructures of a two-layer SAE-based DNN were designed by\nvarying hidden layer size and its masking probability, and\nevaluated for their performances in fault diagnosis.\nIn these above works, the input features to AE models are\nraw sensory time-series. Therefore, the input dimensionality\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n7\nis always over hundred, even one thousand. The possible\nhigh dimensionality may lead to some potential concerns such\nas heavy computation cost and overﬁting caused by huge\nmodel parameters. Therefore, some researchers focused on\nAE models built upon features extracted from raw input.\nJia et al. fed the frequency spectra of time-series data into\nSAE for rotating machinery diagnosis [51], considering the\nfrequency spectra is able to demonstrate how their constitutive\ncomponents are distributed with discrete frequencies and may\nbe more discriminative over the health conditions of rotating\nmachinery. The corresponding framework proposed by Jia et\nal. is shown in Figure 6. Tan et al. used digital wavelet frame\nand nonlinear soft threshold method to process the vibration\nsignal and built a SAE on the preprocessed signal for roller\nbearing fault diagnosis [52]. Zhu et al. proposed a SAE-\nbased DNN for hydraulic pump fault diagnosis with input\nas frequency domain features after Fourier transform [53].\nIn experiments, ReLU activation and dropout technique were\nanalyzed and experimental results have shown to be effective\nin preventing gradient vanishing and overﬁting. In the work\npresented in [54], the normalized spectrogram generated by\nSTFT of sound signal was fed into two-layers SAE-based\nDNN for rolling bearing fault diagnosis. Galloway et al. built\na two layer SAE-based DNN on spectrograms generated from\nraw vibration data for tidal turbine vibration fault diagnosis\n[55]. A SAE-based DNN with input as principal components\nof data extracted by principal component analysis was pro-\nposed for spacecraft fault diagnosis in [56]. Multi-domain\nstatistical features including time domain features, frequency\ndomain features and time-frequency domain features were fed\ninto the SAE framework, which can be regarded as one kind\nof feature fusion [57]. Similarly, Verma et al. also used these\nthree domains features to fed into a SAE-based DNN for fault\ndiagnosis of air compressors [58].\nExcept that these applied multi-domain features, multi-\nsensory data are also addressed by SAE models. Reddy\nutilized SAE to learn representation on raw time series data\nfrom multiple sensors for anomaly detection and fault dis-\nambiguation in ﬂight data. To address multi-sensory data,\nsynchronized windows were ﬁrstly traversed over multi-modal\ntime series with overlap, and then windows from each sensor\nwere concatenated as the input to the following SAE [59]. In\n[60], SAE was leveraged for multi-sensory data fusion and the\nfollowed DBN was adopted for bearing fault diagnosis, which\nachieved promising results. The statistical features in time\ndomain and frequency domain extracted from the vibration\nsignals of different sensors were adopted as input to a two-\nlayer SAE with sparsity constraint neural networks. And the\nlearned representation were fed into a deep belief network for\npattern classiﬁcation.\nIn addition, some variants of the conventional SAE were\nproposed or introduced for machine health monitoring. In\n[61], Thirukovalluru et al. proposed a two-phase framework\nthat SAE only learn representation and other standard classi-\nﬁers such as SVM and random forest perform classiﬁcation.\nSpeciﬁcally, in SAE module, handcrafted features based on\nFFT and WPT were fed into SAE-based DNN. After pre-\ntraining and supervised ﬁne-tuning which includes two sepa-\nrated procedures: softmax-based and Median-based ﬁne-tuning\nmethods, the extensive experiments on ﬁve datasets including\nair compressor monitoring, drill bit monitoring, bearing fault\nmonitoring and steel plate monitoring have demonstrated the\ngeneralization capability of DL-based machine health monitor-\ning systems. Wang et al. proposed a novel continuous sparse\nauto-encoder (CSAE) as an unsupervised feature learning for\ntransformer fault recognition [62]. Different from conventional\nsparse AE, their proposed CSAE added the stochastic unit into\nactivation function of each visible unit as:\nsj = ϕj(\nX\ni\nwijxi + ai + σNj(0, 1))\n(18)\nwhere sj is the output corresponding to the input xi, wij and ai\ndenote model parameters, ϕj represents the activation function\nand the last term σNj(0, 1)) is the added stochastic unit, which\nis a zero-mean Gaussian with variance σ2. The incorporation\nof stochastic unit is able to change the gradient direction and\nprevent over-ﬁtting. Mao et al. adopted a variant of AE named\nExtreme Learning Machine-based auto-encoder for bearing\nfault diagnosis, which is more efﬁcient than conventional SAE\nmodels without sacriﬁcing accuracies in fault diagnosis [63].\nDifferent from AE that is trained via back-propagation, the\ntransformation in encoder phase is randomly generated and\nthe one in decoder phase is learned in a single step via least-\nsquares ﬁt [64].\nIn addition, Lu et al. focused on the visualization of learned\nrepresentation by a two-layer SAE-based DNN, which pro-\nvides a novel view to evaluate the DL-based MHMS [65]. In\ntheir paper, the discriminative power of learned representation\ncan be improved with the increasing of layers.\nB. RBM and its variants for machine health monitoring\nIn the section, some work focused on developing RBM\nand DBM to learn representation from machinery data. Most\nof works introduced here are based on deep belief networks\n(DBN) that can pretrain a deep neural network (DNN).\nIn [66], a RBM based method for bearing remaining useful\nlife (RUL) prediction was proposed. Linear regression layer\nwas added at the top of RBM after pretraining to predict\nthe future root mean square (RMS) based on a lagged time\nseries of RMS values. Then, RUL was calculated by using\nthe predicted RMS and the total time of the bearing’s life.\nLiao et al. proposed a new RBM for representation learning\nto predict RUL of machines [67]. In their work, a new\nregularization term modeling the trendability of the hidden\nnodes was added into the training objective function of RBM.\nThen, unsupervised self-organizing map algorithm (SOM) was\napplied to transforming the representation learned by the\nenhanced RBM to one scale named health value. Finally, the\nhealth value was used to predict RUL via a similarity-based\nlife prediction algorithm. In [68], a multi-modal deep support\nvector classiﬁcation approach was proposed for fault diagnosis\nof gearboxes. Firstly, three modalities features including time,\nfrequency and time-frequency ones were extracted from vibra-\ntion signals. Then, three Gaussian-Bernoulli deep Boltzmann\nmachines (GDBMS) were applied to addressing the above\nthree modalities, respectively. In each GDBMS, the softmax\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n8\n \nFig. 6.\nIllustrations of the proposed SAE-DNN for rotating machinery\ndiagnosis in [51].\nlayer was used at the top. After the pretraining and the ﬁne-\ntuning processes, the probabilistic outputs of the softmax lay-\ners from these three GDBMS were fused by a support vector\nclassiﬁcation (SVC) framework to make the ﬁnal prediction.\nLi et al. applied one GDBMS directly on the concatenation\nfeature consisting of three modalities features including time,\nfrequency and time-frequency ones and stacked one softmax\nlayer on top of GDBMS to recognize fault categories [69]. Li\net al. adopted a two-layers DBM to learn deep representations\nof the statistical parameters of the wavelet packet transform\n(WPT) of raw sensory signal for gearbox fault diagnosis\n[70]. In this work focusing on data fusion, two DBMs were\napplied on acoustic and vibratory signals and random forest\nwas applied to fusing the representations learned by these two\nDBMs.\nMaking use of DBN-based DNN, Ma et al. presented this\nframework for degradation assessment under a bearing accel-\nerated life test [71]. The statistical feature, root mean square\n(RMS) ﬁtted by Weibull distribution that can avoid areas\nof ﬂuctuation of the statistical parameter and the frequency\ndomain features were extracted as raw input. To give a clear\nillustration, the framework in [71] is shown in Figure 7. Shao\net al. proposed DBN for induction motor fault diagnosis with\nthe direct usage of vibration signals as input [72]. Beside\nthe evaluation of the ﬁnal classiﬁcation accuracies, t-SNE\nalgorithm was adopted to visualize the learned representation\nof DBN and outputs of each layer in DBN. They found\nthe addition of hidden layer can increase the discriminative\npower in the learned representation. Fu et al. employed deep\nbelief networks for cutting states monitoring [73]. In the\npresented work, three different feature sets including raw\nvibration signal, Mel-frequency cepstrum coefﬁcient (MFCC)\nand wavelet features were fed into DBN as three corresponding\ndifferent inputs, which were able to achieve robust comparative\nperformance on the raw vibration signal without too much fea-\nture engineering. Tamilselvan et al. proposed a multi-sensory\nDBN-based health state classiﬁcation model. The model was\nveriﬁed in benchmark classiﬁcation problems and two health\ndiagnosis applications including aircraft engine health diag-\nnosis and electric power transformer health diagnosis [74],\n[75]. Tao et al. proposed DBN based multisensor information\nfusion scheme for bearing fault diagnosis [76]. Firstly, 14\ntime-domain statistical features extracted from three vibration\nsignals acquired by three sensors were concatenated together\nas an input vector to DBM model. During pre-training, a\npredeﬁned threshold value was introduced to determine its\niteration number. In [77], a feature vector consisting of load\nand speed measure, time domain features and frequency do-\nmain features was fed into DBN-based DNN for gearbox\nfault diagnosis. In the work of [78], Gan et al. built a\nhierarchical diagnosis network for fault pattern recognition of\nrolling element bearings consisting of two consecutive phases\nwhere the four different fault locations (including one health\nstate) were ﬁrstly identiﬁed and then discrete fault severities\nin each fault condition were classiﬁed. In each phases, the\nfrequency-band energy features generated by WPT were fed\ninto DBN-based DNN for pattern classiﬁcation. In [79], raw\nvibration signals were pre-processed to generate 2D image\nbased on omnidirectional regeneration (ODR) techniques and\nthen, histogram of original gradients (HOG) descriptor was\napplied on the generated image and the learned vector was\nfed into DBN for automatic diagnosis of journal bearing rotor\nsystems. Chen et al. proposed an ensemble of DBNs with\nmulti-objective evolutionary optimization on decomposition\nalgorithm (MOEA/D) for fault diagnosis with multivariate\nsensory data [80]. DBNs with different architectures can be\nregarded as base classiﬁers and MOEA/D was introduced to\nadjust the ensemble weights to achieve a trade-off between\naccuracy and diversity. Chen et al. then extended this above\nframework for one speciﬁc prognostics task: the RUL estima-\ntion of the mechanical system [81].\nC. CNN for machine health monitoring\nIn some scenarios, machinery data can be presented in a\n2D format such as time-frequency spectrum, while in some\nscenarios, they are in a 1D format, i.e., time-series. There-\nfore, CNNs models are able to learn complex and robust\nrepresentation via its convolutional layer. Intuitively, ﬁlters in\nconvolutional layers can extract local patterns in raw data and\nstacking these convolutional layers can further build complex\npatterns. Janssens et al. utilized a 2D-CNN model for four\ncategories rotating machinery conditions recognition, whose\ninput is DFT of two accelerometer signals from two sensors\nthat are placed perpendicular to each other. Therefore, the\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n9\n \nFig. 7.\nIllustrations of the proposed DBN-DNN for assessment of bearing\ndegration in [71].\nheight of input is the number of sensors. The adopted CNN\nmodel contains one convolutional layer and a fully connected\nlayer. Then, the top softmax layer is adopted for classiﬁcation\n[82]. In [83], Babu et al. built a 2D deep convolution neural\nnetwork to predict the RUL of system based on normalized-\nvariate time series from sensor signals, in which one dimension\nof the 2D input is number of sensors as the setting reported\nin [82]. In their model, average pooling is adopted instead\nof max pooling. Since RUL is a continuous value, the top\nlayer was linear regression layer. Ding et al. proposed a\ndeep Convolutional Network (ConvNet) where wavelet packet\nenergy (WPE) image were used as input for spindle bear-\ning fault diagnosis [84]. To fully discover the hierarchical\nrepresentation, a multiscale layer was added after the last\nconvolutional layer, which concatenates the outputs of the last\nconvolutional layer and the ones of the previous pooling layer.\nGuo et al. proposed a hierarchical adaptive deep convolution\nneural network (ADCNN) [85]. Firstly, the input time series\ndata as a signal-vector was transformed into a 32×32 matrix,\nwhich follows the typical input format adopted by LeNet\n[86]. In addition, they designed a hierarchical framework to\nrecognize fault patterns and fault size. In the fault pattern\ndecision module, the ﬁrst ADCNN was adopted to recognize\nfault type. In the fault size evaluation layer, based on each\nfault type, ADCNN with the same structure was used to predict\nfault size. Here, the classiﬁcation mechanism is still used. The\npredicted value f is deﬁned as the probability summation of\nthe typical fault sizes as follows:\nf =\nc\nX\nj=1\najpj\n(19)\nwhere [p1, . . . , pc] is produced by the top softmax layer, which\ndenote the probability score that each sample belongs to each\nclass size and aj is the fault size corresponding to the j-th fault\nsize. In [87], an enhanced CNN was proposed for machinery\nfault diagnosis. To pre-process vibration data, morlet wavelet\nwas used to decompose the vibration signal and obtain wavelet\nscaleogram. Then, bilinear interpolation was used to rescale\nthe scaleogram into a grayscale image with a size of 32 × 32.\nIn addition, the adaptation of ReLU and dropout both boost\nthe model’s diagnosis performance. Chen et al. adopted a\n2D-CNN for gearbox fault diagnosis, in which the input\nmatrix with a size of 16 × 16 for CNN is reshaped by a\nvector containing 256 statistic features including RMS values,\nstandard deviation, skewness, kurtosis, rotation frequency, and\napplied load [88]. In addition, 11 different structures of CNN\nwere evaluated empirically in their experiments. Weimer et al.\ndid a comprehensive study of various design conﬁgurations of\ndeep CNN for visual defect detection [89]. In one speciﬁc\napplication: industrial optical inspection, two directions of\nmodel conﬁgurations including depth (addition of conv-layer)\nand width (increase of number ﬁlters) were investigated. The\noptimal conﬁguration veriﬁed empirically has been presented\nin Table II. In [90], CNN was applied in the ﬁeld of diagnosing\nthe early small faults of front-end controlled wind generator\n(FSCWG) that the 784×784 input matrix consists of vibration\ndata of generator input shaft (horizontal) and vibration data of\ngenerator output shaft (vertical) in time scale.\nAs reviewed in our above section II-C, CNN can also\nbe applied to 1D time series signal and the corresponding\noperations have been elaborated. In [91], the 1D CNN was\nsuccessfully developed on raw time series data for motor\nfault detection, in which feature extraction and classiﬁcation\nwere integrated together. The corresponding framework has\nbeen shown in Figure 8. Abdeljaber et al. proposed 1D CNN\non normalized vibration signal, which can perform vibration-\nbased damage detection and localization of the structural\ndamage in real-time. The advantage of this approach is its\nability to extract optimal damage-sensitive features automati-\ncally from the raw acceleration signals, which does not need\nany additional preporcessing or signal processing approaches\n[92].\nTo present an overview about all these above CNN models\nthat have been successfully applied in the area of MHMS, their\narchitectures have been summarized in Table II. To explain the\nused abbreviation, the structure of CNN applied in Weimer’s\nwork [89] is denoted as Input[32×32]−64C[3×3]2−64P[2×\n2]−128C[3×3]3−128P[2×2]−FC[1024−1024]2. It means\nthe input 2D data is 32 × 32 and the CNN ﬁrstly applied\n2 convolutional layers with the same design that the ﬁlter\nnumber is 64 and the ﬁlter size is 3 × 3, then stacked one\nmax-pooling layer whose pooling size is 2 × 2, then applied\n3 convolutional layers with the same design that the ﬁlter\nnumber is 128 and the ﬁler size is 3×3, then applied a pooling\nlayer whose pooling size is 2 × 2, and ﬁnally adopted two\nfully-connected layers whose hidden neuron numbers are both\n1024. It should be noted that the size of output layer is not\ngiven here, considering it is task-speciﬁc and usually set to be\nthe number of categories.\nD. RNN for machine health monitoring\nThe majority of machinery data belong to sensor data, which\nare in nature time series. RNN models including LSTM and\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n10\nTABLE II\nSUMMARY ON CONFIGURATIONS OF CNN-BASED MHMS. THE SYMBOL Input, C, P AND FC DENOTE THE RAW INPUT, CONVOLUTIONAL LAYER,\nPOOLING LAYER AND FULLY-CONNECTED LAYER, RESPECTIVELY.\nProposed Models\nConﬁgurations of CNN Structures\n2D CNN\nJanssens’s work [82]\nInput[5120 × 2] −32C[64 × 2] −FC[200]\nBabu’s work [83]\nInput[27 × 15] −8C[27 × 4] −8P[1 × 2] −14C[1 × 3] −14P[1 × 2]\nDing’s work [84]\nInput[32 × 32] −20C[7 × 7] −20P[2 × 2] −10C[6 × 6] −10P[2 × 2] −6P[2 × 2] −FC[185 −24]\nGuo’s work [85]\nInput[32 × 32] −5C[5 × 5] −5P[2 × 2] −10C[5 × 5] −10P[2 × 2] −10C[2 × 2] −10P[2 × 2] −FC[100] −FC[50]\nWang’s work [87]\nInput[32 × 32] −64C[3 × 3] −64P[2 × 2] −64C[4 × 4] −64P[2 × 2] −128C[3 × 3] −128P[2 × 2] −FC[512]\nChen’s work [88]\nInput[16 × 16] −8C[5 × 5] −8P[2 × 2]\nWeimer’s work [89]\nInput[32 × 32] −64C[3 × 3]2 −64P[2 × 2] −128C[3 × 3]3 −128P[2 × 2] −FC[1024 −1024]\nDong’s work [90]\nInput[784 × 784] −12C[10 × 10] −12P[2 × 2] −24C[10 × 10] −24P[2 × 2] −FC[200]\n1D CNN\nInce’s work [91]\nInput[240] −60C[9] −60P[4] −40C[9] −40P[4] −40C[9] −40P[4] −FC[20]\nAbdeljaber’s work [92]\nInput[128] −64C[41] −64P[2] −32C[41] −32P[2] −FC[10 −10]\nFig. 8.\nIllustrations of the proposed 1D-CNN for real-time motor Fault\nDetection in [91].\nGRU have emerged as one kind of popular architectures to\nhandle sequential data with its ability to encode temporal\ninformation. These advanced RNN models have been proposed\nto relief the difﬁculty of training in vanilla RNN and applied\nin machine health monitoring recently. In [93], Yuan et al.\ninvestigated three RNN models including vanilla RNN, LSTM\nand GRU models for fault diagnosis and prognostics of aero\nengine. They found these advanced RNN models LSTM and\nGRU models outperformed vanilla RNN. Another interesting\nobservation was the ensemble model of the above three RNN\nvariants did not boost the performance of LSTM. Zhao et\nal. presented an empirical evaluation of LSTMs-based ma-\nchine health monitoring system in the tool wear test [94].\nThe applied LSTM model encoded the raw sensory data\ninto embeddings and predicted the corresponding tool wear.\nZhao et al. further designed a more complex deep learning\nmodel combining CNN and LSTM named Convolutional Bi-\ndirectional Long Short-Term Memory Networks (CBLSTM)\n[95]. As shown in Figure 9, CNN was used to extract robust\nlocal features from the sequential input, and then bi-directional\nLSTM was adopted to encode temporal information on the\nsequential output of CNN. Stacked fully-connected layers and\nlinear regression layer were ﬁnally added to predict the target\nvalue. In tool wear test, the proposed model was able to\noutperform several state-of-the-art baseline methods including\nconventional LSTM models. In [96], Malhotra proposed a\nvery interesting structure for RUL prediction. They designed\na LSTM-based encoder-decoder structure, which LSTM-based\nencoder ﬁrstly transforms a multivariate input sequence to a\nﬁxed-length vector and then, LSTM decoder uses the vector\nto produce the target sequence. When it comes to RUL\nprediction, their assumptions lies that the model can be ﬁrstly\ntrained in raw signal corresponding to normal behavior in an\nunsupervised way. Then, the reconstruction error can be used\nto compute health index (HI), which is then used for RUL\nestimation. It is intuitive that the large reconstruction error\ncorresponds to a more unhealthy machine condition.\nIV. SUMMARY AND FUTURE DIRECTIONS\nIn this paper, we have provided a systematic overview of\nthe state-of-the-art DL-based MHMS. Deep learning, as a sub-\nﬁeld of machine learning, is serving as a bridge between big\nmachinery data and data-driven MHMS. Therefore, within the\npast four years, they have been applied in various machine\nhealth monitoring tasks. These proposed DL-based MHMS are\nsummarized according to four categories of DL architecture\nas: Auto-encoder models, Restricted Boltzmann Machines\nmodels, Convolutional Neural Networks and Recurrent Neural\nNetworks. Since the momentum of the research of DL-based\nMHMS is growing fast, we hope the messages about the\ncapabilities of these DL techniques, especially representation\nlearning for complex machinery data and target prediction for\nvarious machine health monitoring tasks, can be conveyed to\nreaders. Through these previous works, it can be found that\nDL-based MHMS do not require extensive human labor and\nexpert knowledge, i.e., the end-to-end structure is able to map\nraw machinery data to targets. Therefore, the application of\ndeep learning models are not restricted to speciﬁc kinds of\nmachines, which can be a general solution to address the\nmachine health monitoring problems. Besides, some research\ntrends and potential future research directions are given as\nfollows:\n* Open-source Large Dataset: Due to the huge model\ncomplexity behind DL methods, the performance of\nDL-based MHMS heavily depends on the scale and\nquality of datasets. On other hand, the depth of DL\nmodel is limited by the scale of datasets. As a re-\nsult, the benchmark CNN model for image recognition\nhas 152 layers, which can be supported by the large\ndataset ImageNet containing over ten million annotated\nimages [97], [98]. In contrast, the proposed DL models\nfor MHMS may stack up to 5 hidden layers. And\nthe model trained in such kind of large datasets can\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n11\nRaw Sensory Signal\nLocal Feature Extractor\nConvolutional Neural Network\nTemporal Encoder\nDeep Bi-directional LSTM\nConvolutional\nReLu\nPooling\nOutput \nRepresentation\nTwo Fully-connected Layers \nand Linear Regression Layer\nDropout\nDropout\nFig. 9.\nIllustrations of the proposed Convolutional Bi-directional Long Short-Term Memory Networks in [95].\nbe the model initialization for the following speciﬁc\ntask/dataset. Therefore, it is meaningful to design and\npublish large-scale machinery datasets.\n* Utilization of Domain Knowledge: deep learning is\nnot a skeleton key to all machine health monitoring\nproblems. Domain knowledge can contribute to the\nsuccess of applying DL models on machine health mon-\nitoring. For example, extracting discriminative features\ncan reduce the size of the followed DL models and\nappropriate task-speciﬁc regularization term can boost\nthe ﬁnal performance [67].\n* Model and Data Visualization: deep learning tech-\nniques, especially deep neural networks, have been re-\ngarded as black boxes models, i.e., their inner compu-\ntation mechanisms are unexplainable. Visualization of\nthe learned representation and the applied model can\noffer some insights into these DL models, and then\nthese insights achieved by this kind of interaction can\nfacilitate the building and conﬁguration of DL models\nfor complex machine health monitoring problems. Some\nvisualization techniques have been proposed including t-\nSNE model for high dimensional data visualization [99]\nand visualization of the activations produced by each\nlayer and features at each layer of a DNN via regularized\noptimization [100].\n* Transferred Deep Learning: Transfer learning tries to\napply knowledge learned in one domain to a different\nbut related domain [101]. This research direction is\nmeaningful in machine health monitoring, since some\nmachine health monitoring problems have sufﬁcient\ntraining data while other areas lack training data. The\nmachine learning models including DL models trained\nin one domain can be transferred to the other domain.\nSome previous works focusing on transferred feature ex-\ntraction/dimensionality reduction have been done [102],\n[103]. In [104], a Maximum Mean Discrepancy (MMD)\nmeasure evaluating the discrepancy between source and\ntarget domains was added into the target function of deep\nneural networks.\n* Imbalanced Class: The class distribution of machinery\ndata in real life normally follows a highly-skewed one, in\nwhich most data samples belong to few categories. For\nexample, the number of fault data is much less than the\none of health data in fault diagnosis. Some enhanced\nmachine learning models including SVM and ELM\nhave been proposed to address this imbalanced issue\nin machine health monitoring [105], [106]. Recently,\nsome interesting methods investigating the application\nof deep learning in imbalanced class problems have been\ndeveloped, including CNN models with class resampling\nor cost-sensitive training [107] and the integration of\nboot strapping methods and CNN model [108].\nIt is believed that deep learning will have a more and\nmore prospective future impacting machine health monitoring,\nespecially in the age of big machinery data.\nACKNOWLEDGMENT\nThis work has been supported in part by the National\nNatural Science Foundation of China (51575102).\nREFERENCES\n[1] S. Yin, X. Li, H. Gao, and O. Kaynak, “Data-based techniques focused\non modern industry: An overview,” IEEE Transactions on Industrial\nElectronics, vol. 62, no. 1, pp. 657–667, Jan 2015.\n[2] S. Jeschke, C. Brecher, H. Song, and D. B. Rawat, “Industrial internet\nof things.”\n[3] D. Lund, C. MacGillivray, V. Turner, and M. Morales, “Worldwide and\nregional internet of things (iot) 2014–2020 forecast: A virtuous circle\nof proven value and demand,” International Data Corporation (IDC),\nTech. Rep, 2014.\n[4] Y. Li, T. Kurfess, and S. Liang, “Stochastic prognostics for rolling\nelement bearings,” Mechanical Systems and Signal Processing, vol. 14,\nno. 5, pp. 747–762, 2000.\n[5] C. H. Oppenheimer and K. A. Loparo, “Physically based diagnosis and\nprognosis of cracked rotor shafts,” in AeroSense 2002.\nInternational\nSociety for Optics and Photonics, 2002, pp. 122–132.\n[6] M. Yu, D. Wang, and M. Luo, “Model-based prognosis for hybrid\nsystems with mode-dependent degradation behaviors,” Industrial Elec-\ntronics, IEEE Transactions on, vol. 61, no. 1, pp. 546–554, 2014.\n[7] A. K. Jardine, D. Lin, and D. Banjevic, “A review on machinery diag-\nnostics and prognostics implementing condition-based maintenance,”\nMechanical systems and signal processing, vol. 20, no. 7, pp. 1483–\n1510, 2006.\n[8] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-\ntime object detection with region proposal networks,” in Advances in\nneural information processing systems, 2015, pp. 91–99.\n[9] R. Collobert and J. Weston, “A uniﬁed architecture for natural lan-\nguage processing: Deep neural networks with multitask learning,” in\nProceedings of the 25th international conference on Machine learning.\nACM, 2008, pp. 160–167.\n[10] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed, N. Jaitly,\nA. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath et al., “Deep neural\nnetworks for acoustic modeling in speech recognition: The shared\nviews of four research groups,” IEEE Signal Processing Magazine,\nvol. 29, no. 6, pp. 82–97, 2012.\n[11] M. K. Leung, H. Y. Xiong, L. J. Lee, and B. J. Frey, “Deep learning\nof the tissue-regulated splicing code,” Bioinformatics, vol. 30, no. 12,\npp. i121–i129, 2014.\n[12] J. Schmidhuber, “Deep learning in neural networks: An overview,”\nNeural Networks, vol. 61, pp. 85–117, 2015, published online 2014;\nbased on TR arXiv:1404.7828 [cs.NE].\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n12\n[13] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol.\n521, no. 7553, pp. 436–444, 2015.\n[14] R. Raina, A. Madhavan, and A. Y. Ng, “Large-scale deep unsupervised\nlearning using graphics processors,” in Proceedings of the 26th annual\ninternational conference on machine learning.\nACM, 2009, pp. 873–\n880.\n[15] G. E. Hinton, “Learning multiple layers of representation,” Trends in\ncognitive sciences, vol. 11, no. 10, pp. 428–434, 2007.\n[16] A. Widodo and B.-S. Yang, “Support vector machine in machine\ncondition monitoring and fault diagnosis,” Mechanical systems and\nsignal processing, vol. 21, no. 6, pp. 2560–2574, 2007.\n[17] J. Yan and J. Lee, “Degradation assessment and fault modes classiﬁca-\ntion using logistic regression,” Journal of manufacturing Science and\nEngineering, vol. 127, no. 4, pp. 912–914, 2005.\n[18] V. Muralidharan and V. Sugumaran, “A comparative study of na¨ıve\nbayes classiﬁer and bayes net classiﬁer for fault diagnosis of\nmonoblock centrifugal pump using wavelet analysis,” Applied Soft\nComputing, vol. 12, no. 8, pp. 2023–2029, 2012.\n[19] Y. Bengio, A. Courville, and P. Vincent, “Representation learning: A\nreview and new perspectives,” IEEE transactions on pattern analysis\nand machine intelligence, vol. 35, no. 8, pp. 1798–1828, 2013.\n[20] A. Malhi and R. X. Gao, “Pca-based feature selection scheme for\nmachine defect classiﬁcation,” IEEE Transactions on Instrumentation\nand Measurement, vol. 53, no. 6, pp. 1517–1525, 2004.\n[21] J. Wang, J. Xie, R. Zhao, L. Zhang, and L. Duan, “Multisensory fusion\nbased virtual tool wear sensing for ubiquitous manufacturing,” Robotics\nand Computer-Integrated Manufacturing, 2016.\n[22] J. Wang, J. Xie, R. Zhao, K. Mao, and L. Zhang, “A new probabilistic\nkernel factor analysis for multisensory data fusion: Application to\ntool condition monitoring,” IEEE Transactions on Instrumentation and\nMeasurement, vol. 65, no. 11, pp. 2527–2537, Nov 2016.\n[23] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, “Extracting\nand composing robust features with denoising autoencoders,” in Pro-\nceedings of the 25th international conference on Machine learning.\nACM, 2008, pp. 1096–1103.\n[24] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm\nfor deep belief nets,” Neural computation, vol. 18, no. 7, pp. 1527–\n1554, 2006.\n[25] R. Salakhutdinov and G. E. Hinton, “Deep boltzmann machines.” in\nAISTATS, vol. 1, 2009, p. 3.\n[26] P. Sermanet, S. Chintala, and Y. LeCun, “Convolutional neural net-\nworks applied to house numbers digit classiﬁcation,” in Pattern Recog-\nnition (ICPR), 2012 21st International Conference on.\nIEEE, 2012,\npp. 3288–3291.\n[27] K.-i. Funahashi and Y. Nakamura, “Approximation of dynamical sys-\ntems by continuous time recurrent neural networks,” Neural networks,\nvol. 6, no. 6, pp. 801–806, 1993.\n[28] L. Deng and D. Yu, “Deep learning: Methods and applications,”\nFound. Trends Signal Process., vol. 7, no. 3&#8211;4, pp. 197–387,\nJun. 2014. [Online]. Available: http://dx.doi.org/10.1561/2000000039\n[29] I. Goodfellow, Y. Bengio, and A. Courville, “Deep learning,” 2015,\n2016.\n[30] Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle et al., “Greedy\nlayer-wise training of deep networks,” Advances in neural information\nprocessing systems, vol. 19, p. 153, 2007.\n[31] A. Ng, “Sparse autoencoder,” CS294A Lecture notes, vol. 72, pp. 1–19,\n2011.\n[32] B. B. Le Cun, J. S. Denker, D. Henderson, R. E. Howard, W. Hub-\nbard, and L. D. Jackel, “Handwritten digit recognition with a back-\npropagation network,” in Advances in neural information processing\nsystems.\nCiteseer, 1990.\n[33] K. Jarrett, K. Kavukcuoglu, Y. Lecun et al., “What is the best\nmulti-stage architecture for object recognition?” in 2009 IEEE 12th\nInternational Conference on Computer Vision. IEEE, 2009, pp. 2146–\n2153.\n[34] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation\nwith deep convolutional neural networks,” in Advances in neural\ninformation processing systems, 2012, pp. 1097–1105.\n[35] O. Abdel-Hamid, A.-r. Mohamed, H. Jiang, and G. Penn, “Applying\nconvolutional neural networks concepts to hybrid nn-hmm model\nfor speech recognition,” in 2012 IEEE international conference on\nAcoustics, speech and signal processing (ICASSP).\nIEEE, 2012, pp.\n4277–4280.\n[36] Y. Kim, “Convolutional neural networks for sentence classiﬁcation,”\narXiv preprint arXiv:1408.5882, 2014.\n[37] H. Jaeger, Tutorial on training recurrent neural networks, covering\nBPPT, RTRL, EKF and the” echo state network” approach.\nGMD-\nForschungszentrum Informationstechnik, 2002.\n[38] C. L. Giles, C. B. Miller, D. Chen, H.-H. Chen, G.-Z. Sun, and Y.-C.\nLee, “Learning and extracting ﬁnite state automata with second-order\nrecurrent neural networks,” Neural Computation, vol. 4, no. 3, pp. 393–\n405, 1992.\n[39] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural\ncomputation, vol. 9, no. 8, pp. 1735–1780, 1997.\n[40] F. A. Gers, J. Schmidhuber, and F. Cummins, “Learning to forget:\nContinual prediction with lstm,” Neural computation, vol. 12, no. 10,\npp. 2451–2471, 2000.\n[41] F. A. Gers, N. N. Schraudolph, and J. Schmidhuber, “Learning precise\ntiming with lstm recurrent networks,” Journal of machine learning\nresearch, vol. 3, no. Aug, pp. 115–143, 2002.\n[42] K. Cho, B. Van Merri¨enboer, C. Gulcehre, D. Bahdanau, F. Bougares,\nH. Schwenk, and Y. Bengio, “Learning phrase representations using\nrnn encoder-decoder for statistical machine translation,” arXiv preprint\narXiv:1406.1078, 2014.\n[43] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evaluation of\ngated recurrent neural networks on sequence modeling,” arXiv preprint\narXiv:1412.3555, 2014.\n[44] H. Su and K. T. Chong, “Induction machine condition monitoring\nusing neural network modeling,” IEEE Transactions on Industrial\nElectronics, vol. 54, no. 1, pp. 241–249, Feb 2007.\n[45] B. Li, M.-Y. Chow, Y. Tipsuwan, and J. C. Hung, “Neural-network-\nbased motor rolling bearing fault diagnosis,” IEEE transactions on\nindustrial electronics, vol. 47, no. 5, pp. 1060–1069, 2000.\n[46] B. Samanta and K. Al-Balushi, “Artiﬁcial neural network based fault\ndiagnostics of rolling element bearings using time-domain features,”\nMechanical systems and signal processing, vol. 17, no. 2, pp. 317–\n328, 2003.\n[47] M. Aminian and F. Aminian, “Neural-network based analog-circuit\nfault diagnosis using wavelet transform as preprocessor,” IEEE Trans-\nactions on Circuits and Systems II: Analog and Digital Signal Pro-\ncessing, vol. 47, no. 2, pp. 151–156, 2000.\n[48] W. Sun, S. Shao, R. Zhao, R. Yan, X. Zhang, and X. Chen, “A sparse\nauto-encoder-based deep neural network approach for induction motor\nfaults classiﬁcation,” Measurement, vol. 89, pp. 171–178, 2016.\n[49] C. Lu, Z.-Y. Wang, W.-L. Qin, and J. Ma, “Fault diagnosis of rotary\nmachinery components using a stacked denoising autoencoder-based\nhealth state identiﬁcation,” Signal Processing, vol. 130, pp. 377–388,\n2017.\n[50] S. Tao, T. Zhang, J. Yang, X. Wang, and W. Lu, “Bearing fault diag-\nnosis method based on stacked autoencoder and softmax regression,”\nin Control Conference (CCC), 2015 34th Chinese.\nIEEE, 2015, pp.\n6331–6335.\n[51] F. Jia, Y. Lei, J. Lin, X. Zhou, and N. Lu, “Deep neural networks: A\npromising tool for fault characteristic mining and intelligent diagnosis\nof rotating machinery with massive data,” Mechanical Systems and\nSignal Processing, vol. 72, pp. 303–315, 2016.\n[52] T. Junbo, L. Weining, A. Juneng, and W. Xueqian, “Fault diagnosis\nmethod study in roller bearing based on wavelet transform and stacked\nauto-encoder,” in The 27th Chinese Control and Decision Conference\n(2015 CCDC).\nIEEE, 2015, pp. 4608–4613.\n[53] Z. Huijie, R. Ting, W. Xinqing, Z. You, and F. Husheng, “Fault diag-\nnosis of hydraulic pump based on stacked autoencoders,” in 2015 12th\nIEEE International Conference on Electronic Measurement Instruments\n(ICEMI), vol. 01, July 2015, pp. 58–62.\n[54] H. Liu, L. Li, and J. Ma, “Rolling bearing fault diagnosis based on\nstft-deep learning and sound signals,” Shock and Vibration, vol. 2016,\n2016.\n[55] G. S. Galloway, V. M. Catterson, T. Fay, A. Robb, and C. Love, “Di-\nagnosis of tidal turbine vibration data through deep neural networks,”\n2016.\n[56] K. Li and Q. Wang, “Study on signal recognition and diagnosis for\nspacecraft based on deep learning method,” in Prognostics and System\nHealth Management Conference (PHM), 2015.\nIEEE, 2015, pp. 1–5.\n[57] L. Guo, H. Gao, H. Huang, X. He, and S. Li, “Multifeatures fusion\nand nonlinear dimension reduction for intelligent bearing condition\nmonitoring,” Shock and Vibration, vol. 2016, 2016.\n[58] N. K. Verma, V. K. Gupta, M. Sharma, and R. K. Sevakula, “Intelligent\ncondition based monitoring of rotating machines using sparse auto-\nencoders,” in Prognostics and Health Management (PHM), 2013 IEEE\nConference on.\nIEEE, 2013, pp. 1–7.\n[59] v. v. kishore k. reddy, soumalya sarkar and michael giering, “Anomaly\ndetection and fault disambiguation in large ﬂight data: A multi-modal\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n13\ndeep auto-encoder approach,” in Annual conference of the prognostics\nand health management society, Denver, Colorado, 2016.\n[60] Z. Chen and W. Li, “Multi-sensor feature fusion for bearing fault\ndiagnosis using sparse auto encoder and deep belief network,” IEEE\nTransactions on IM, 2017.\n[61] R. Thirukovalluru, S. Dixit, R. K. Sevakula, N. K. Verma, and\nA. Salour, “Generating feature sets for fault diagnosis using denois-\ning stacked auto-encoder,” in Prognostics and Health Management\n(ICPHM), 2016 IEEE International Conference on.\nIEEE, 2016, pp.\n1–7.\n[62] L. Wang, X. Zhao, J. Pei, and G. Tang, “Transformer fault diagnosis\nusing continuous sparse autoencoder,” SpringerPlus, vol. 5, no. 1, p. 1,\n2016.\n[63] W. Mao, J. He, Y. Li, and Y. Yan, “Bearing fault diagnosis with auto-\nencoder extreme learning machine: A comparative study,” Proceedings\nof the Institution of Mechanical Engineers, Part C: Journal of Mechan-\nical Engineering Science, pp. 1–19, 2016.\n[64] E. Cambria, G. B. Huang, L. L. C. Kasun, H. Zhou, C. M. Vong, J. Lin,\nJ. Yin, Z. Cai, Q. Liu, K. Li, V. C. M. Leung, L. Feng, Y. S. Ong,\nM. H. Lim, A. Akusok, A. Lendasse, F. Corona, R. Nian, Y. Miche,\nP. Gastaldo, R. Zunino, S. Decherchi, X. Yang, K. Mao, B. S. Oh,\nJ. Jeon, K. A. Toh, A. B. J. Teoh, J. Kim, H. Yu, Y. Chen, and J. Liu,\n“Extreme learning machines [trends controversies],” IEEE Intelligent\nSystems, vol. 28, no. 6, pp. 30–59, Nov 2013.\n[65] W. Lu, X. Wang, C. Yang, and T. Zhang, “A novel feature extraction\nmethod using deep neural network for rolling bearing fault diagnosis,”\nin The 27th Chinese Control and Decision Conference (2015 CCDC).\nIEEE, 2015, pp. 2427–2431.\n[66] J. Deutsch and D. He, “Using deep learning based approaches for\nbearing remaining useful life prediction,” 2016.\n[67] L. Liao, W. Jin, and R. Pavel, “Enhanced restricted boltzmann machine\nwith prognosability regularization for prognostics and health assess-\nment,” IEEE Transactions on Industrial Electronics, vol. 63, no. 11,\n2016.\n[68] C. Li, R.-V. Sanchez, G. Zurita, M. Cerrada, D. Cabrera, and R. E.\nV´asquez, “Multimodal deep support vector classiﬁcation with ho-\nmologous features and its application to gearbox fault diagnosis,”\nNeurocomputing, vol. 168, pp. 119–127, 2015.\n[69] C. Li, R.-V. S´anchez, G. Zurita, M. Cerrada, and D. Cabrera, “Fault\ndiagnosis for rotating machinery using vibration measurement deep\nstatistical feature learning,” Sensors, vol. 16, no. 6, p. 895, 2016.\n[70] C. Li, R.-V. Sanchez, G. Zurita, M. Cerrada, D. Cabrera, and R. E.\nV´asquez, “Gearbox fault diagnosis based on deep random forest fusion\nof acoustic and vibratory signals,” Mechanical Systems and Signal\nProcessing, vol. 76, pp. 283–293, 2016.\n[71] M. Ma, X. Chen, S. Wang, Y. Liu, and W. Li, “Bearing degradation\nassessment based on weibull distribution and deep belief network,” in\nProceedings of 2016 International Symposium of Flexible Automation\n(ISFA), 2016, pp. 1–4.\n[72] S. Shao, W. Sun, P. Wang, R. X. Gao, and R. Yan, “Learning\nfeatures from vibration signals for induction motor fault diagnosis,” in\nProceedings of 2016 International Symposium of Flexible Automation\n(ISFA), 2016, pp. 1–6.\n[73] Y. Fu, Y. Zhang, H. Qiao, D. Li, H. Zhou, and J. Leopold, “Analysis of\nfeature extracting ability for cutting state monitoring using deep belief\nnetworks,” Procedia CIRP, vol. 31, pp. 29–34, 2015.\n[74] P. Tamilselvan and P. Wang, “Failure diagnosis using deep belief\nlearning based health state classiﬁcation,” Reliability Engineering &\nSystem Safety, vol. 115, pp. 124–135, 2013.\n[75] P. Tamilselvan, Y. Wang, and P. Wang, “Deep belief network based state\nclassiﬁcation for structural health diagnosis,” in Aerospace Conference,\n2012 IEEE.\nIEEE, 2012, pp. 1–11.\n[76] J. Tao, Y. Liu, and D. Yang, “Bearing fault diagnosis based on\ndeep belief network and multisensor information fusion,” Shock and\nVibration, vol. 2016, 2016.\n[77] Z. Chen, C. Li, and R.-V. S´anchez, “Multi-layer neural network\nwith deep belief network for gearbox fault diagnosis.” Journal of\nVibroengineering, vol. 17, no. 5, 2015.\n[78] M. Gan, C. Wang et al., “Construction of hierarchical diagnosis\nnetwork based on deep learning and its application in the fault pattern\nrecognition of rolling element bearings,” Mechanical Systems and\nSignal Processing, vol. 72, pp. 92–104, 2016.\n[79] H. Oh, B. C. Jeon, J. H. Jung, and B. D. Youn, “Smart diagnosis of\njournal bearing rotor systems: Unsupervised feature extraction scheme\nby deep learning,” 2016.\n[80] C. Zhang, J. H. Sun, and K. C. Tan, “Deep belief networks ensemble\nwith multi-objective optimization for failure diagnosis,” in Systems,\nMan, and Cybernetics (SMC), 2015 IEEE International Conference\non.\nIEEE, 2015, pp. 32–37.\n[81] C. Zhang, P. Lim, A. Qin, and K. C. Tan, “Multiobjective deep belief\nnetworks ensemble for remaining useful life estimation in prognostics,”\nIEEE Transactions on Neural Networks and Learning Systems, 2016.\n[82] O. Janssens, V. Slavkovikj, B. Vervisch, K. Stockman, M. Loccuﬁer,\nS. Verstockt, R. Van de Walle, and S. Van Hoecke, “Convolutional\nneural network based fault detection for rotating machinery,” Journal\nof Sound and Vibration, 2016.\n[83] G. S. Babu, P. Zhao, and X.-L. Li, “Deep convolutional neural\nnetwork based regression approach for estimation of remaining useful\nlife,” in International Conference on Database Systems for Advanced\nApplications.\nSpringer, 2016, pp. 214–228.\n[84] X. Ding and Q. He, “Energy-ﬂuctuated multiscale feature learning\nwith deep convnet for intelligent spindle bearing fault diagnosis,” IEEE\nTransactions on IM, 2017.\n[85] X. Guo, L. Chen, and C. Shen, “Hierarchical adaptive deep convo-\nlution neural network and its application to bearing fault diagnosis,”\nMeasurement, vol. 93, pp. 490–502, 2016.\n[86] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based\nlearning applied to document recognition,” Proceedings of the IEEE,\nvol. 86, no. 11, pp. 2278–2324, 1998.\n[87] J. Wang, j. Zhuang, L. Duan, and W. Cheng, “A multi-scale convolution\nneural network for featureless fault diagnosis,” in Proceedings of 2016\nInternational Symposium of Flexible Automation (ISFA), 2016, pp. 1–6.\n[88] Z. Chen, C. Li, and R.-V. Sanchez, “Gearbox fault identiﬁcation and\nclassiﬁcation with convolutional neural networks,” Shock and Vibration,\nvol. 2015, 2015.\n[89] D. Weimer, B. Scholz-Reiter, and M. Shpitalni, “Design of deep convo-\nlutional neural network architectures for automated feature extraction in\nindustrial inspection,” CIRP Annals-Manufacturing Technology, 2016.\n[90] H.-Y. DONG, L.-X. YANG, and H.-W. LI, “Small fault diagnosis of\nfront-end speed controlled wind generator based on deep learning.”\n[91] T. Ince, S. Kiranyaz, L. Eren, M. Askar, and M. Gabbouj, “Real-time\nmotor fault detection by 1-d convolutional neural networks,” IEEE\nTransactions on Industrial Electronics, vol. 63, no. 11, pp. 7067–7075,\n2016.\n[92] O. Abdeljaber, O. Avci, S. Kiranyaz, M. Gabbouj, and D. J. Inman,\n“Real-time vibration-based structural damage detection using one-\ndimensional convolutional neural networks,” Journal of Sound and\nVibration, vol. 388, pp. 154–170, 2017.\n[93] M. Yuan, Y. Wu, and L. Lin, “Fault diagnosis and remaining useful life\nestimation of aero engine using lstm neural network,” in 2016 IEEE\nInternational Conference on Aircraft Utility Systems (AUS), Oct 2016,\npp. 135–140.\n[94] R. Zhao, J. Wang, R. Yan, and K. Mao, “Machine helath monitoring\nwith lstm networks,” in 2016 10th International Conference on Sensing\nTechnology (ICST).\nIEEE, 2016, pp. 1–6.\n[95] R. Zhao, R. Yan, J. Wang, and K. Mao, “Learning to monitor machine\nhealth with convolutional bi-directional lstm networks,” Sensors, 2016.\n[96] P. Malhotra, A. Ramakrishnan, G. Anand, L. Vig, P. Agarwal, and\nG. Shroff, “Multi-sensor prognostics using an unsupervised health in-\ndex based on lstm encoder-decoder,” arXiv preprint arXiv:1608.06154,\n2016.\n[97] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” arXiv preprint arXiv:1512.03385, 2015.\n[98] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei,\n“ImageNet: A Large-Scale Hierarchical Image Database,” in CVPR09,\n2009.\n[99] L. v. d. Maaten and G. Hinton, “Visualizing data using t-sne,” Journal\nof Machine Learning Research, vol. 9, no. Nov, pp. 2579–2605, 2008.\n[100] J. Yosinski, J. Clune, A. Nguyen, T. Fuchs, and H. Lipson, “Under-\nstanding neural networks through deep visualization,” arXiv preprint\narXiv:1506.06579, 2015.\n[101] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Transac-\ntions on knowledge and data engineering, vol. 22, no. 10, pp. 1345–\n1359, 2010.\n[102] F. Shen, C. Chen, R. Yan, and R. X. Gao, “Bearing fault diagnosis\nbased on svd feature extraction and transfer learning classiﬁcation,” in\nPrognostics and System Health Management Conference (PHM), 2015.\nIEEE, 2015, pp. 1–6.\n[103] J. Xie, L. Zhang, L. Duan, and J. Wang, “On cross-domain feature\nfusion in gearbox fault diagnosis under various operating conditions\nbased on transfer component analysis,” in 2016 IEEE International\nConference on Prognostics and Health Management (ICPHM), June\n2016, pp. 1–6.\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n14\n[104] W. Lu, B. Liang, Y. Cheng, D. Meng, J. Yang, and T. Zhang, “Deep\nmodel based domain adaptation for fault diagnosis,” IEEE Transactions\non Industrial Electronics, 2016.\n[105] W. Mao, L. He, Y. Yan, and J. Wang, “Online sequential prediction\nof bearings imbalanced fault diagnosis by extreme learning machine,”\nMechanical Systems and Signal Processing, vol. 83, pp. 450–473, 2017.\n[106] L. Duan, M. Xie, T. Bai, and J. Wang, “A new support vector data\ndescription method for machinery fault diagnosis with unbalanced\ndatasets,” Expert Systems with Applications, vol. 64, pp. 239–246,\n2016.\n[107] C. Huang, Y. Li, C. Change Loy, and X. Tang, “Learning deep\nrepresentation for imbalanced classiﬁcation,” in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, 2016,\npp. 5375–5384.\n[108] Y. Yan, M. Chen, M.-L. Shyu, and S.-C. Chen, “Deep learning for\nimbalanced multimedia data classiﬁcation,” in 2015 IEEE International\nSymposium on Multimedia (ISM).\nIEEE, 2015, pp. 483–488.\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2016-12-16",
  "updated": "2016-12-16"
}