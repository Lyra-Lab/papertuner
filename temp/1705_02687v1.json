{
  "id": "http://arxiv.org/abs/1705.02687v1",
  "title": "Finding Bottlenecks: Predicting Student Attrition with Unsupervised Classifier",
  "authors": [
    "Seyed Sajjadi",
    "Bruce Shapiro",
    "Christopher McKinlay",
    "Allen Sarkisyan",
    "Carol Shubin",
    "Efunwande Osoba"
  ],
  "abstract": "With pressure to increase graduation rates and reduce time to degree in\nhigher education, it is important to identify at-risk students early. Automated\nearly warning systems are therefore highly desirable. In this paper, we use\nunsupervised clustering techniques to predict the graduation status of declared\nmajors in five departments at California State University Northridge (CSUN),\nbased on a minimal number of lower division courses in each major. In addition,\nwe use the detected clusters to identify hidden bottleneck courses.",
  "text": "1 | Page \n \nFinding Bottlenecks: Predicting Student Attrition with \nUnsupervised Classifier \nSeyed Sajjadi, Bruce Shapiro, Christopher McKinlay, Allen Sarkisyan, Carol Shubin, Efunwande Osoba \nCalifornia State University, Northridge \nseyed.sajjadi.947@my.csun.edu, bruce.e.shapiro@gmail.com, chris.mckinlay@gmail.com, programminglinguist@gmail.com, \ncarol.shubin@csun.edu, eosoba@gmail.com \n \n \nAbstract—With pressure to increase graduation rates and \nreduce time to degree in higher education, it is important to \nidentify at-risk students early. Automated early warning systems \nare therefore highly desirable. In this paper, we use unsupervised \nclustering techniques to predict the graduation status of declared \nmajors in five departments at California State University \nNorthridge (CSUN), based on a minimal number of lower \ndivision courses in each major. In addition, we use the detected \nclusters to identify hidden bottleneck courses. \nAuthor Keywords—Machine learning; Educational data mining; \nunsupervised methods; classifier; K-means; clustering  \nI. INTRODUCTION \nPolicy makers, the public, university administrators, \nstudents and their families are concerned about low graduation \nrates and lengthy times to degree in higher education. The \nmedian time to graduation is six years at CSUN (1). The four-\nyear and the six-year graduation rates are 13% and 50%, \nrespectively (2). With an enrollment of over 6000 \nundergraduate students, CoBaE is one of largest business \nschools in the nation. CoBaE confers the second most \nundergraduate degrees at CSUN (behind the College of Social \nand Behavioral Science), and it has three of the top ten most \npopular majors (Management, Finance, and Marketing) at \nCSUN. We focused our analysis on three departments within \nthe CoBaE because of the commonality of core curriculum. \nWe also studied two departments from the College of \nEngineering because of pre-requisite curriculum. \nWe trained K-means classifiers on grade data from \nundergraduate majors in Business Law, Management, \nMarketing, Civil and Electrical Engineering. We found \nstrongly predictive clusters in each of the five departments. \nCluster separation was driven disproportionately by a small \nnumber of courses which we consider the bottlenecks to \ngraduation. In fact, the first three classes of the graduation \npathway give an effective early indication of student success \nor failure. \nII. RELATED WORK \nEducational data mining is an emerging discipline, \nconcerned with developing methods for exploring the unique \ntypes of data that come from the educational sphere. The field \nencompasses various subdomains such as modeling student \nlearning to better optimize performance, to detecting outliers, \nto developing automated tutoring systems that intelligently \nadapt lesson plans to the individual learning styles (11). \nLuan (9) studied clustering aspects of data mining and \noffers comprehensive characteristic analysis of students and \nlikelihood estimates for a variety of outcomes such as \ntransferability, persistence, retention, and success in classes. \nAl-Radaideh et al. (3) applied classification techniques to \ndetermine the main attributes that may affect student \nperformance. Tair and El- Halees (13), used K-means to \npredict graduate students’ performance, and overcome the \nproblem of low grades of graduate students. Ayesha, Mustafa, \nSattar and Khan (4) have also used K- means clustering to \npredict student performance in a particular course. Romero, \nVentura and Garca (12) described the full process of \nclustering, classification, visualization and statistics in the \ncontext of mining Moodle (e-learning) data. Our current work \nuses unsupervised clustering methods to address the issue of \nlarge scale student behavior, and attempts to identify student \nsuccesses and failure through predictive clustering. \nIII. METHOD \nA. Data Collection and Preprocessing \nWe \nobtained \nacademic \nrecords \ncontaining \ngrade \ninformation from declared majors in five departments in the \nCollege of Business and Economics and College of \nEngineering at CSUN. The majors we inspected were \nManagement, Marketing and Business Law, Civil and \nElectrical Engineering. The data spans a ten-year period \nbetween 2004 and 2014 containing 9,088 student records in \ntotal and contains only the courses required for each major. \nThe grade data for each course were encoded with the \nfollowing normalized GPA scale prior to statistical analysis: \nTABLE I. GRADE ENCODING SCHEME \n \nNot taking a required course for a specific major will \nprevent students from graduating. This has the same effect as \nfailing the course; therefore, such a course was assigned a \ngrade of ‘F’.  The datasets were separated by majors, with \ncolumns for graduation, number of semesters in the major, \nnumber of credits for the major, number of transfer credits \nearned, followed by the course names. \n2 | Page \n \nB. Cluster Analysis \nThere are a few fundamental issues involved in cluster \nanalysis, notably determining whether discrete clusters are \npresent (8) and choosing the appropriate number of clusters \n(7) (6). We applied the K-means algorithm (10) to the grade \ndata and used the Calinski-Harabasz (CH) index (5) to \ndetermine the optimal number of clusters on fivefold cross-\nvalidated datasets (Figure 1). \nWe then established the predictive power of the clusters by \ntesting them on a classification task. We compared the cluster-\nbased classifiers with logistic regression classifiers in \npredicting the graduation status of held-out samples for each \ndepartment. A very common technique to measure the \nclassifier performance is Receiver Operating Characteristic \n(ROC) curves which display the sensitivity of the model by \nplotting the true positive rate versus the false positive \npredictions and depicting their relative trade-offs. We then \nused ROC curves to evaluate and compare predictive \nperformance of clustering and logistic regression methods for \neach department (Table 2). Finally, we performed the same \nsteps to predict graduation status based on the first three \ncourses in each major. \n \nFig. 1. \nCalinski-Harabasz indices for all three datasets \nTABLE II. \nROC PLOTS FOR BOTH CLASSIFIERS ON THE FULL \nCOURSE SET AND THE FIRST THREE COURSES FOR BUSINESS \nMAJORS AND ENGINEERING MAJORS \n \n \n \n \nTABLE III. \nACCURACY, PRECISION, RECALL, \nAND F1 SCORES \n3 | Page \n \n \nIV. RESULTS \nThe optimal number of clusters was two in all \ndepartments, s determined by CH-index (Figure 1). The \nManagement and Marketing departments showed better \nbetween-cluster separation than Economics and Business Law. \nWe applied the same approach to the first three classes that \nstudents would normally take within their first year at school. \n(Table 3) shows the Accuracy, Precision, Recall and F1 \nScores resulting from the two classifiers when trained on the \nfull feature set (approximately 113 courses) and on the first \nthree courses in each major. \nWe expected that a predictive model trained on the full \nfeature set of course grades would be more effective than a \nmodel using cluster labels from unsupervised clustering. To \ntest this hypothesis, we compared the performance of a \nlogistic regression classifier trained on the full feature set to \nthe performance of a classifier that used co-membership \ninformation from the clusters on a classification task: to \npredict whether the student had in fact graduated with that \nmajor. The cluster-based classifier estimated the probability \nthat a student belonged to a particular category using the \nfraction of co-clustered samples that also belonged to the \ncategory of interest. \nIn each case we identified strongly predictive clusters. \nThough outperformed, the cluster- based classifiers compared \nsurprisingly well with the logistic regression models (Table 2). \nHeuristically speaking, students in the same cluster tended to \ndrop out at the same times after getting the same grades in the \nsame courses. \nV. DISCUSSION \nCluster analysis can also help to identify common traits \namong students within each cluster. For each department the \nsecond cluster spends on average four semesters enrolled with \nthat major declared (Table 4). However, the probability of \nthese students graduating with the major is quite low (Table \n3). Bottlenecks can be visually depicted as courses which are \nmost well separated by predictive clusters. The average course \ngrades seen in (Table 5) are further apart between clusters for \nupper division courses, as expected due to their requirement \nfor graduation. Examination of the lower division course work \ncan be seen as the beginning of the bottleneck for each major. \nLower division coursework with relatively high separation in \naverage grades between clusters are the best indicators for the \nseparation between students that graduate and those which do \nnot, and therefore act as bottlenecks in the major. These \ncourses are excellent features to include into an early-warning \nsystem classifier as they are the most well separated vectors. \nVI. LIMITATIONS AND FUTURE WORK \nStudents may fail to graduate in CoBaE because they \neither change majors or discontinue their education at CSUN. \nHierarchical clustering methods could provide more detailed \ninformation on student outcomes, such as predicting which \ndepartment a student might change their major to. \nCollaborative filtering methods could also give departmental \nrecommendations to students considering a change of major. \nThese methods could be used to develop early warning and \nrecommendation systems for automated advisement, which \nwould be especially beneficial to over-taxed advisement \nsystems at comprehensive state universities such as CSUN. \nAnother related issue is the incidence of major-switching \nis an important factor, since re-declaring a major is time-\nconsuming and costly. Approximately 24% of CSUN students \nre-declare their major, and the plurality of these changes \ninvolve departments in the David Nazarian College of \nBusiness and Economics (CoBaE) (1). \nOur results can be further refined by adding student \nmetadata, for example: college year the major was declared, \nnumber of transfer credits, number of classes per term, \nfinancial aid, student demographics (such as age, gender, \nethnicity, zip code) and various measures of student \npreparedness like SAT scores. With a more detailed feature \nspace, our methods might be able to identify patterns and \nmore well defined clusters. \nVII. CONCLUSION \nWe trained unsupervised classifiers on grade data from \nfour undergraduate majors at CSUN. In each case we found \nstrongly predictive clusters, and found that cluster separation \nwas driven disproportionately by a small number of bottleneck \ncourses. We also found that training classifiers on the first \nthree classes on the graduation pathway was an effective early \ndetection method. We argue that reforming, or at the very least \ninvestigating, these bottleneck courses are crucial to \nunderstanding student attrition \nACKNOWLEDGMENTS \nWe gratefully acknowledge support from CSUN’s Office \nof the Provost and Academic Affairs. We thank Provost Harry \nHellenbrand and Vice-Provost Michael Neubauer for their \ninstitutional support, and Bettina Huber, CSUN Director of \nInstitutional Research, for making the data available. We also \nthank Yauheniya (Gina) Lahoda and Dr. Bruce Shapiro for \nnumerous conversations during the Spring 2015 Machine \nLearning seminar. \nREFERENCES \n[1] Csun colleges: \"Changes and grades.\" \n[2] Csun \noffice \nof \ninstitutional \nresearch \nreport. \n4 | Page \n \nhttp://www.csun.edu/institutional-research \n[3] Al-Radaideh, Q. A., Al-Shawakfa, E. M., and Al-Najjar, M. I. Mining \nstudent data using decision trees. In International Arab Conference on \nInformation Technology (ACIT 2006), Yarmouk University, Jordan \n(2006). \n[4] Ayesha, S., Mustafa, T., Sattar, A. R., and Khan, M. I. Data mining \nmodel for higher education system.Europen Journal of Scientific \nResearch 43, 1 (2010), 24–29. \n[5] Cali ́nski, T., and Harabasz, J. A dendrite method for cluster analysis. \nCommunications in Statistics-theory and Methods 3, 1 (1974), 1–27. \n[6] Duda, R. O., Hart, P. E., and Stork, D. G. Pattern classification. John \nWiley & Sons, 2012. \n[7] Gordon, A. Classification, 2nd Edition. Chapman & Hall/CRC \nMonographs on Statistics & Applied Probability. CRC Press, 1999. \n[8] Knights, D., Ward, T. L., McKinlay, C. E., Miller, H., Gonzalez, A., \nMcDonald, D., and Knight, R.Rethinking enterotypes. Cell host & \nmicrobe 16, 4 (2014), 433–437. \n[9] Luan, J. Data mining and knowledge management in higher education-\npotential applications. \n[10] MacQueen, J., et al. Some methods for classification and analysis of \nmultivariate observations. In Proceedings of the fifth Berkeley \nsymposium on mathematical statistics and probability (1967), vol. 1, \nOakland, CA, USA., pp. 281–297.7 \n[11] Romero, C., and Ventura, S. Educational data mining: A review of the \nstate-of-the-art. Systems, Man,and Cybernetics, Part C: Applications and \nReviews, IEEE Transactions on 40, 6 (2010), 601–618.  \n[12] Romero, C., Ventura, S., and Garc ́ıa, E. Data mining in course \nmanagement systems: Moodle case study and tutorial. Computers & \nEducation 51, 1 (2008), 368–384. \n[13] Tair, M. M. A., and El-Halees, A. M. Mining educational data to \nimprove students performance: A case study. International Journal of \nInformation 2, 2 (2012). \nTABLE IV. \nNUMBER OF SEMESTERS AND UNITS SPENT AT CSUN ACROSS THREE MAJORS OF BUSINESS LAW, MARKETING AND \nMANAGEMENT, ALSO SHOWING TRANSFER CREDITS FROM OTHER INSTITUTES WITH CLUSTER “1” REFERS TO THE STUDENTS WHO GRADUATED \nAND CLUSTER “2” TO THOSE WHO DID NOT \n \n \n \n5 | Page \n \n \nTABLE V. \nAVERAGES GRADES FOR EACH CLASS BY CLUSTER FOR BUSINESS AND ENGINEERING MAJORS \n \n6 | Page \n \n \n \n7 | Page \n \n \n \n",
  "categories": [
    "stat.ML",
    "cs.AI",
    "cs.CY",
    "cs.LG",
    "stat.AP"
  ],
  "published": "2017-05-07",
  "updated": "2017-05-07"
}