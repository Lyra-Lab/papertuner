{
  "id": "http://arxiv.org/abs/1705.09837v2",
  "title": "On the relation between dependency distance, crossing dependencies, and parsing. Comment on \"Dependency distance: a new perspective on syntactic patterns in natural languages\" by Haitao Liu et al",
  "authors": [
    "Carlos Gómez-Rodríguez"
  ],
  "abstract": "Liu et al. (2017) provide a comprehensive account of research on dependency\ndistance in human languages. While the article is a very rich and useful report\non this complex subject, here I will expand on a few specific issues where\nresearch in computational linguistics (specifically natural language\nprocessing) can inform DDM research, and vice versa. These aspects have not\nbeen explored much in the article by Liu et al. or elsewhere, probably due to\nthe little overlap between both research communities, but they may provide\ninteresting insights for improving our understanding of the evolution of human\nlanguages, the mechanisms by which the brain processes and understands\nlanguage, and the construction of effective computer systems to achieve this\ngoal.",
  "text": "On the relation between dependency distance, crossing\ndependencies, and parsing.\nComment on “Dependency distance: a new perspective\non syntactic patterns in natural languages” by Haitao\nLiu et al.\nCarlos G´omez-Rodr´ıguez\nUniversidade da Coru˜na. FASTPARSE Lab, LyS Research Group, Departamento de\nComputaci´on, Facultade de Inform´atica, Elvi˜na, 15071 A Coru˜na, Spain\nKeywords:\ndependency distance, natural language parsing, dependency\nparsing, crossing dependencies, non-projectivity\nc⃝2017. This manuscript version is made available under the CC-BY-NC-\nND 4.0 license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\ncbnd\nThis is the accepted manuscript (ﬁnal peer-reviewed manuscript) accepted\nfor publication in Physics of Life Reviews, and may not reﬂect subse-\nquent changes resulting from the publishing process such as copy-editing,\nformatting or pagination.\nThe published journal article can be found at\nhttps://doi.org/10.1016/j.plrev.2017.05.007.\nLiu et al. [1] provide a comprehensive account of research on dependency\ndistance in human languages. While the article is a very rich and useful re-\nport on this complex subject, here I will expand on a few speciﬁc issues where\nEmail address: carlos.gomez@udc.es ()\nURL: http://www.grupolys.org/~cgomezr ()\nPreprint submitted to Physics of Life Reviews\nJune 6, 2017\narXiv:1705.09837v2  [cs.CL]  3 Jun 2017\nresearch in computational linguistics (speciﬁcally natural language process-\ning) can inform DDM research, and vice versa. These aspects have not been\nexplored much in [1] or elsewhere, probably due to the little overlap be-\ntween both research communities, but they may provide interesting insights\nfor improving our understanding of the evolution of human languages, the\nmechanisms by which the brain processes and understands language, and the\nconstruction of eﬀective computer systems to achieve this goal.\n1. Crossings, dependency distance and the parallelism between ex-\nceptions to projectivity and exceptions to DDM\nAs mentioned in [1], there is a close relation between DDM and the\nscarcity of crossing dependencies in natural languages. This low frequency\nof crossings has long been observed [2], later quantiﬁed [3, 4, 5], and recently\nstatistically tested [6], in a wide range of human languages.\nIt is worth noting, however, that strict projectivity (a prohibition of cross-\ning dependencies) is not an adequate model of the syntax of real sentences.\nOne the one hand, it fails to explain a number of relevant linguistic phenom-\nena present in various languages [7, 8]. On the other hand, an overwhelming\nmajority of syntactic corpora in recent multilingual collections have been ob-\nserved to contain non-projectivity [4, 5]: crossing dependencies are scarce,\nbut far from absent [6]. For these reasons, while projectivity can be useful\nfrom an engineering point of view, in the context of a tradeoﬀbetween cover-\nage and eﬃciency in natural language parsers [5]; taking it for granted when\ninvestigating DDM or using it as an assumption of models to explain DDM\n[9, 10] can lead to a methodological pitfall: the scarcity of crossing depen-\ndencies is likely not an independent constraint of language that contributes\nto DDM, but rather a consequence of it [11, 12].\nTo account for the limited amount of crossing dependencies that arise in\nlanguage and to be able to build parsers that can handle non-projective syn-\ntactic phenomena in an eﬃcient manner, researchers have explored various\nclasses of so-called mildly non-projective dependency structures [13, 14, 15, 4,\n16, 5]. These are sets of trees that allow a limited degree of non-projectivity,\npermitting crossing dependencies only if they follow certain conditions or\npatterns. Various such classes have been deﬁned that claim very high cov-\nerage over the trees in a variety of corpora, allowing a large majority of the\nnon-projective dependencies that appear in practice. However, the reasons\nfor this success (and especially, the reasons why some of the proposed sets\n2\nhave more coverage than others) are currently not very well known. Namely,\nthe reasons for the high coverage of each given mildly non-projective class\ncould include either being an adequate description of the particular situa-\ntions where crossing dependencies can arise, or yielding a large enough class\nof syntactic trees to provide high coverage by sheer brute force, or a mix\nof both. The observation that a given class can be more or less adequate\ndepending on the criteria used to annotate the syntactic dependencies [5]\nsuggests at least some inﬂuence of the ﬁrst factor.\nThe research on syntactic patterns involving long-distance dependencies,\nreviewed by Liu et al.\nin Section 5 of [1], could help clarify this ques-\ntion.\nDDM and the scarcity of crossing dependencies are closely related,\nas the latter is motivated by short dependency distance [12]. Furthermore,\nin both cases, there is a predominant trend (the majority of dependencies are\nshort and do not cross) but there are exceptions that escape the trend (long-\ndistance dependencies and crossing dependencies), which are in turn related\n(longer dependencies are more likely to cross [17]). Liu et al. [1] review\nsome possible reasons for the minority of long dependencies observed in lan-\nguage, and explanations of how they can survive the pressure for DDM. This\nraises two questions: (1) do these explanations also apply to the presence of\ncrossing dependencies, and are they related with the adequacy of mildly non-\nprojective classes of trees? (e.g., do the most eﬀective such classes work well\nbecause they favor crossing dependencies from words at peripheral positions,\nor structures that can be easily chunked?); and (2) can we in turn re-use some\nof what we know about long dependencies for crossing dependencies and their\nparsing, and employ it to deﬁne classes of mildly non-projective structures\nthat will more closely adjust to the kinds of non-projectivity found in lan-\nguage? Both questions are interesting avenues for research, and can advance\nour knowledge both on DDM and natural language parsing.\n2. The surprising eﬀectiveness of transition-based parsers and their\nbias towards DDM\nLiu et al. [1] cite some work in computational linguistics that achieved\nimprovements in parsing accuracy by purposefully introducing dependency\ndistance as a constraint in a parser [18]. Additionally, it is worth noting that\nmany state-of-the-art natural language parsers use algorithms with an im-\nplicit bias towards short dependency distances, even if they do not introduce\nit as an explicit restriction.\n3\nIn particular, a popular framework for dependency parsers is the transition-\nbased (or shift-reduce) approach [19], under which a parser is deﬁned with\na non-deterministic state machine, a statistical or machine-learning-based\nmodel to score transitions, and a search strategy to obtain the optimal se-\nquence of transitions that will yield a parse.\nMany, if not most, of the\ncurrent state-of-the-art parsing systems are based on this framework [20, 21,\n22, 23, 24], and all the diﬀerent algorithm variants that are at its core have\nin common that they build short dependencies before (and requiring fewer\ntransitions than) long ones, be it because building a long dependency requires\nremoving intervening nodes from a stack (as in the popular arc-standard and\narc-eager [19], arc-hybrid [25] or swap [26] algorithms) or because it requires\nto navigate a list (as in the systems based on the Covington [27] algorithm).\nThis bias towards favoring short dependencies can be part of the reason why\nthese systems are so eﬀective in practice, and is an example of the trend\npointed out in [28] by which purely engineering-oriented parsing models are\nconverging with cognitive theories of language understanding, even when\nthey do not have psycholinguistic modeling among their goals.\nA quick veriﬁcation and quantiﬁcation of the mentioned bias can be un-\ndertaken by implementing transition systems and obtaining random trees by\ntaking a random transition at each state. Focusing on sentences of length\n20 as an example, the expected mean dependency distance for a uniformly\nrandom tree is 7 [29], contrasting with real averages observed in corpora, e.g.\n2.52 for Arabic, 3.18 for German, 2.59 for English or 2.51 for Spanish in the\nsentences of length 20 of the Stanford HamleDT 2.0 treebanks [30]. On the\nother hand, by simulating 105 random parses of sentences of length 20, we\nobtain an average distance of 2.44 with the arc-standard algorithm, and 2.06\nwith the arc-eager parser with the tree constraint [31]. These two parsers are\nprojective, but using an algorithm that can generate arbitrary non-projective\ntrees (the swap parser), the obtained average is 2.38, even smaller than for\narc-standard. While further investigation is needed that would be outside\nthe scope of this comment, the data seem to suggest that transition-based\nparsers implicitly favor dependency lengths that are equal, or even smaller,\nthan the natural ones that appear in language as a consequence of DDM; and\nthis could be an important factor in the practical adequacy of these parsers.\n4\nAcknowledgements\nThis research has received funding from the European Research Coun-\ncil (ERC) under the European Union’s Horizon 2020 research and innova-\ntion programme (grant agreement No 714150 - FASTPARSE), and from the\nTELEPARES-UDC project (FFI2014-51978-C2-2-R) from MINECO. I thank\nRamon Ferrer-i-Cancho for helpful comments.\nReferences\n[1] H. Liu, C. Xu, J. Liang, Dependency distance: A new perspective on\nsyntactic patterns in natural languages, Physics of Life Reviews (in this\nissue). doi:http://dx.doi.org/10.1016/j.plrev.2017.03.002.\nURL\nhttp://www.sciencedirect.com/science/article/pii/\nS1571064517300532\n[2] I. Mel’ˇcuk, Dependency Syntax: Theory and Practice, State University\nof New York Press, 1988.\n[3] J. Havelka, Beyond projectivity: Multilingual evaluation of constraints\nand measures on non-projective structures, in: ACL 2007: Proceedings\nof the 45th Annual Meeting of the Association for Computational Lin-\nguistics, 2007, pp. 608–615.\n[4] C. G´omez-Rodr´ıguez, J. Nivre, Divisible transition systems and multi-\nplanar dependency parsing, Comput. Linguist. 39 (4) (2013) 799–845.\ndoi:10.1162/COLI\\_a\\_00150.\nURL http://dx.doi.org/10.1162/COLI_a_00150\n[5] C. G´omez-Rodr´ıguez, Restricted non-projectivity:\nCoverage vs. eﬃ-\nciency, Computational Linguistics 42 (4) (2016) 809–817. doi:10.1162/\nCOLI\\_a\\_00267.\nURL http://dx.doi.org/10.1162/COLI_a_00267\n[6] R. Ferrer-i-Cancho, C. G´omez-Rodr´ıguez, J. L. Esteban, Are crossing\ndependencies really scarce?, arXiv 1703.08324 [physics.soc-ph].\nURL https://arxiv.org/abs/1703.08324\n[7] R. Levy, E. Fedorenko, M. Breen, T. Gibson, The processing of extra-\nposed structures in English, Cognition 122 (1) (2012) 12 – 36.\n5\n[8] Y. Versley, Experiments with easy-ﬁrst nonprojective constituent pars-\ning, in: Proceedings of the First Joint Workshop on Statistical Pars-\ning of Morphologically Rich Languages and Syntactic Analysis of Non-\nCanonical Languages, Dublin City University, Dublin, Ireland, 2014, pp.\n39–53.\nURL http://www.aclweb.org/anthology/W14-6104\n[9] H. Liu, Dependency distance as a metric of language comprehension\ndiﬃculty, Journal of Cognitive Science 9 (2008) 159–191.\n[10] R.\nFutrell,\nK.\nMahowald,\nE.\nGibson,\nLarge-scale\nevidence\nof\ndependency\nlength\nminimization\nin\n37\nlanguages,\nProceedings\nof\nthe\nNational\nAcademy\nof\nSciences\n112\n(33)\n(2015)\n10336–\n10341.\narXiv:http://www.pnas.org/content/112/33/10336.full.\npdf, doi:10.1073/pnas.1502134112.\nURL http://www.pnas.org/content/112/33/10336.abstract\n[11] C. G´omez-Rodr´ıguez, R. Ferrer-i-Cancho, The scarcity of crossing de-\npendencies: a direct outcome of a speciﬁc constraint?, arXiv 1601.03210\n[cs.CL].\nURL http://arxiv.org/abs/1601.03210\n[12] R. Ferrer-i-Cancho, C. G´omez-Rodr´ıguez, Crossings as a side eﬀect of\ndependency lengths, Complexity 21 (S2) (2016) 320–328. doi:10.1002/\ncplx.21810.\nURL http://dx.doi.org/10.1002/cplx.21810\n[13] M. Kuhlmann, J. Nivre, Mildly non-projective dependency structures,\nin: Proceedings of the COLING/ACL 2006 Main Conference Poster\nSessions, 2006, pp. 507–514.\n[14] C. G´omez-Rodr´ıguez, J. A. Carroll, D. J. Weir, Dependency parsing\nschemata and mildly non-projective dependency parsing, Computational\nLinguistics 37 (3) (2011) 541–586. doi:10.1162/COLI\\_a\\_00060.\nURL http://dx.doi.org/10.1162/COLI_a_00060\n[15] E. Pitler, S. Kannan, M. Marcus, Dynamic programming for higher\norder parsing of gap-minding trees, in: Proceedings of the 2012 Joint\nConference on Empirical Methods in Natural Language Processing and\n6\nComputational Natural Language Learning, Association for Computa-\ntional Linguistics, Jeju Island, Korea, 2012, pp. 478–488.\nURL http://www.aclweb.org/anthology/D12-1044\n[16] E. Pitler, S. Kannan, M. Marcus, Finding optimal 1-endpoint-crossing\ntrees, Transactions of the Association of Computational Linguistics 1\n(2013) 13–24.\nURL http://aclweb.org/anthology/Q13-1002\n[17] R. Ferrer-i-Cancho, Non-crossing dependencies: least eﬀort, not gram-\nmar, in: A. Mehler, A. L¨ucking, S. Banisch, P. Blanchard, B. Job (Eds.),\nTowards a theoretical framework for analyzing complex linguistic net-\nworks, Springer, Berlin, 2016, pp. 203–234.\n[18] J. Eisner, N. A. Smith, Favor short dependencies: Parsing with soft\nand hard constraints on dependency length, in: H. Bunt, P. Merlo,\nJ. Nivre (Eds.), Trends in Parsing Technology, Dependency Parsing,\nDomain Adaptation, and Deep Parsing, Springer, 2010, pp. 121–150.\ndoi:10.1007/978-90-481-9352-3\\_8.\nURL http://dx.doi.org/10.1007/978-90-481-9352-3_8\n[19] J.\nNivre,\nAlgorithms\nfor\nDeterministic\nIncremental\nDepen-\ndency Parsing, Computational Linguistics 34 (4) (2008) 513–553.\ndoi:10.1162/coli.07-056-R1-07-027.\nURL\nhttp://www.mitpressjournals.org/doi/abs/10.1162/coli.\n07-056-R1-07-027\n[20] D. Chen, C. Manning, A fast and accurate dependency parser using\nneural networks, in: Proceedings of the 2014 Conference on Empirical\nMethods in Natural Language Processing (EMNLP), Doha, Qatar, 2014,\npp. 740–750.\nURL http://www.aclweb.org/anthology/D14-1082\n[21] C. Dyer, M. Ballesteros, W. Ling, A. Matthews, N. A. Smith, Transition-\nbased dependency parsing with stack long short-term memory, in: Pro-\nceedings of the 53rd Annual Meeting of the Association for Computa-\ntional Linguistics and the 7th International Joint Conference on Natural\nLanguage Processing (Volume 1: Long Papers), Association for Com-\nputational Linguistics, Beijing, China, 2015, pp. 334–343.\nURL http://www.aclweb.org/anthology/P15-1033\n7\n[22] D. Andor, C. Alberti, D. Weiss, A. Severyn, A. Presta, K. Ganchev,\nS. Petrov, M. Collins, Globally normalized transition-based neural net-\nworks, in: Proceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers), Association for\nComputational Linguistics, Berlin, Germany, 2016, pp. 2442–2452.\nURL http://www.aclweb.org/anthology/P16-1231\n[23] E. Kiperwasser, Y. Goldberg, Simple and accurate dependency parsing\nusing bidirectional lstm feature representations, Transactions of the\nAssociation for Computational Linguistics 4 (2016) 313–327.\nURL\nhttps://transacl.org/ojs/index.php/tacl/article/view/\n885\n[24] C. Alberti, D. Andor, I. Bogatyy, M. Collins, D. Gillick, L. Kong,\nT. Koo, J. Ma, M. Omernick, S. Petrov, C. Thanapirom, Z. Tung,\nD. Weiss, Syntaxnet models for the conll 2017 shared task, CoRR\nabs/1703.04929.\nURL http://arxiv.org/abs/1703.04929\n[25] M. Kuhlmann, C. G´omez-Rodr´ıguez, G. Satta, Dynamic programming\nalgorithms for transition-based dependency parsers, in: Proceedings of\nthe 49th Annual Meeting of the Association for Computational Lin-\nguistics: Human Language Technologies (ACL 2011), Association for\nComputational Linguistics, Portland, Oregon, USA, 2011, pp. 673–682.\nURL http://www.aclweb.org/anthology/P11-1068\n[26] J. Nivre, Non-projective dependency parsing in expected linear time, in:\nProceedings of the Joint Conference of the 47th Annual Meeting of the\nACL and the 4th International Joint Conference on Natural Language\nProcessing of the AFNLP (ACL-IJCNLP), 2009, pp. 351–359.\n[27] M. A. Covington, A fundamental algorithm for dependency parsing, in:\nProceedings of the 39th Annual ACM Southeast Conference, 2001, pp.\n95–102.\n[28] C. G´omez-Rodr´ıguez, Natural language processing and the Now-\nor-Never bottleneck, Behavioral and Brain Sciences 39 (2016) e74.\ndoi:10.1017/S0140525X15000795.\nURL\nhttp://journals.cambridge.org/article_\nS0140525X15000795\n8\n[29] R. Ferrer-i-Cancho, Euclidean distance between syntactically linked\nwords, Physical Review E 70 (2004) 056135.\n[30] R. Rosa, J. Maˇsek, D. Mareˇcek, M. Popel, D. Zeman, Z. ˇZabokrtsk´y,\nHamleDT 2.0: Thirty dependency treebanks stanfordized, in: N. C. C.\nChair), K. Choukri, T. Declerck, H. Loftsson, B. Maegaard, J. Mariani,\nA. Moreno, J. Odijk, S. Piperidis (Eds.), Proceedings of the Ninth Inter-\nnational Conference on Language Resources and Evaluation (LREC’14),\nEuropean Language Resources Association (ELRA), Reykjavik, Iceland,\n2014.\n[31] J. Nivre, D. Fern´andez-Gonz´alez, Arc-eager parsing with the tree con-\nstraint, Computational Linguistics 40 (2) (2014) 259–267.\nURL http://www.aclweb.org/anthology/J/J14/J14-2002.pdf\n9\n",
  "categories": [
    "cs.CL",
    "68T50, 91F20, 97C30",
    "I.2.7; J.5; F.4.2"
  ],
  "published": "2017-05-27",
  "updated": "2017-06-03"
}