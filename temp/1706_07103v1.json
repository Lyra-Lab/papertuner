{
  "id": "http://arxiv.org/abs/1706.07103v1",
  "title": "A hybrid supervised/unsupervised machine learning approach to solar flare prediction",
  "authors": [
    "Federico Benvenuto",
    "Michele Piana",
    "Cristina Campi",
    "Anna Maria Massone"
  ],
  "abstract": "We introduce a hybrid approach to solar flare prediction, whereby a\nsupervised regularization method is used to realize feature importance and an\nunsupervised clustering method is used to realize the binary flare/no-flare\ndecision. The approach is validated against NOAA SWPC data.",
  "text": "Draft version June 23, 2017\nTypeset using LATEX manuscript style in AASTeX61\nA HYBRID SUPERVISED/UNSUPERVISED MACHINE LEARNING APPROACH TO SOLAR\nFLARE PREDICTION\nFederico Benvenuto,1 Michele Piana,2 Cristina Campi,3 and Anna Maria Massone3\n1Dipartimento di Matematica Universit`a di Genova, via Dodecaneso 35 16146 Genova, Italy\n2Dipartimento di Matematica Universit`a di Genova and CNR - SPIN Genova, via Dodecaneso 35 16146 Genova, Italy\n3CNR - SPIN Genova, via Dodecaneso 33 16146 Genova, Italy\nSubmitted to ApJ\nABSTRACT\nWe introduce a hybrid approach to solar ﬂare prediction, whereby a supervised regularization\nmethod is used to realize feature importance and an unsupervised clustering method is used to\nrealize the binary ﬂare/no-ﬂare decision. The approach is validated against NOAA SWPC data.\nKeywords: Methods: data analysis – Methods: statistical – Sun: ﬂares – sunspots\nCorresponding author: Michele Piana\npiana@dima.unige.it\narXiv:1706.07103v1  [astro-ph.SR]  21 Jun 2017\n2\nBenvenuto et al.\n1. INTRODUCTION\nSolar ﬂares are the most energetic events in the solar system. Over a typical duration of ∼(10\n- 1000) s, they can release up to 1032 erg of energy — stored in stressed active region magnetic\nﬁelds — into directed mass motions, heating, and acceleration of supra-thermal charged particles,\nincluding electrons, protons and heavier ions (Kontar et al. 2011). Solar ﬂares, together with Coronal\nMass Ejections (CMEs), are the main drivers of space weather at Earth and can sometimes even\nsigniﬁcantly aﬀect Earth- and space-based technology systems like power grids, ﬂight navigation,\nsatellite communications. Predicting solar ﬂares requires, ﬁrst of all, the determination of parameters\nsuch as properties of sunspot groups or of the coronal magnetic ﬁeld conﬁguration, that are thought\nto be important for the understanding of fundamental processes in solar plasma physics. Second,\nat a more technological level, these parameters are used as input values for algorithms that realize\npredictions providing, for example (but not exclusively), a binary ﬂare/no-ﬂare outcome (Bloomﬁeld\net al. 2012; Wheatland 2004; Gallagher et al. 2002).\nMost recent ﬂare prediction algorithms belong to the machine learning framework (Bobra & Cou-\nvidat 2015; Colak & Qahwaji 2009; Li et al. 2007; Yu et al. 2009; Yuan et al. 2010). In this setting,\ndata properties utilized for prediction are named features. In the case of supervised learning, a set of\nhistorical data is at disposal where features are tagged by means of labels representing the observa-\ntion outcome, and the prediction task consists in determining the label associated to the incoming\nfeatures’ set. On the other hand, unsupervised methods do not use any training set and data are\nclustered in diﬀerent groups according to similarity criteria involving data features.\nA crucial aspect of ﬂare prediction, characterized by notable physical implications, is to provide\nhints on which data features mostly correlate with the labels. In statistical learning theory this\npractice is known as feature selection although applications often refer to it as feature importance,\nwhich better points out the fact that at the end of the process features are ranked according to their\nimportance in the prediction task (in the following we will use the two terms equivalently). Feature\nselection can be realized by using advanced implementations of standard neural network approaches\n(Olden et al. 2004; Garson 1991) or by means of regularization methods. This second approach aims\nAASTEX A hybrid machine learning approach to flare prediction\n3\nto optimize a functional made of two terms: the discrepancy term measures the distance between\nprediction and data in the training set, while the penalty term imposes a constraint on the number of\nfeatures that signiﬁcantly contribute to the prediction itself. Two examples of regularization methods\nfor feature selection are LASSO (Tibshirani 1996) and l1-penalized logit (l1-logit in the following)\n(Wu et al. 2009). Both approaches utilize an l1-norm penalty term to reduce the complexity; on the\nother hand, LASSO measures the discrepancy assuming that the noise on the data is Gaussian, while\nl1-logit relies on a maximum likelihood procedure in which the probability function to maximize\nis the binomial distribution. In the framework of ﬂare prediction, each one of these two methods\npresents a speciﬁc limitation. In fact, LASSO is intrinsically a regression method and therefore it\nis not naturally appropriate for applications like ﬂare prediction that may require a binary yes/no\nresponse. On the other hand, l1-logit is a classiﬁcation method, but it predicts the binary condition\nby applying a ﬁxed threshold on the ﬂare occurrence probability, i.e., the applied threshold is the\nsame whatever the dataset used for training is.\nThe present paper introduces a novel approach to ﬂare prediction with feature importance whose\naim is to overtake both previous limitations. The perspective of such approach is hybrid and rather\ngeneral: ﬁrst, a regularization method for regression is applied to the training set with an l1 penalty\nterm that promotes sparsity, thus realizing feature importance (more speciﬁcally, this regularization\nstep reconstructs the vector of weights, with which each feature contributes to the prediction in the\ntraining set). Then, the set of the real values obtained by multiplying the weights times the feature\nvalues in the training set is automatically clustered in two classes by means of a clustering technique.\nClustering is an unsupervised learning approach that organizes a set of samples into meaningful\nclusters based on data similarity. Data partition is obtained through the minimization of a cost\nfunction involving distances between data and cluster prototypes. Optimal partitions are obtained\nthrough iterative optimization: starting from a random initial partition, samples are moved from\none cluster to another until no further improvement in the cost function optimization is noticed.\nTherefore, in the second step of the hybrid approach, clustering performs an automatic thresholding,\nwhich depends on the historical set used for the training phase and is, therefore, intrinsically data\n4\nBenvenuto et al.\ndependent. The resulting algorithm presents several advantages with respect to standard one-step\napproaches: it selects the most signiﬁcant features, since, in the ﬁrst step, it relies on a regularization\ntechnique that promotes sparsity; it is a classiﬁcation method, since at the end it produces two\nclusters, each one corresponding to a speciﬁc outcome of the prediction; it performs classiﬁcation in\na ﬂexible, data-adaptive way, which makes it signiﬁcantly eﬃcient in providing good performances\nwith respect to standard skill scores. The hybrid approach in this paper utilized LASSO in the\nregularization step and Fuzzy C-means (Bezdek 1981) to cluster the LASSO outcome, although\nother feature selection and clustering algorithms can be applied.\nIn order to corroborate the eﬀectiveness of this hybrid approach we utilized a set of data from\nthe National Oceanic and Atmospheric Administration (NOAA) Space Weather Prediction Center\n(SWPC) and compared our results with the ones provided by l1-logit, as far as both the classiﬁcation\nand feature importance abilities are concerned, and with some of the most used machine learning\napproaches in ﬂare forecasting, as far as just the prediction eﬀectiveness is concerned.\nThe plan of the paper is as follows. Section 2 illustrates the kind of data, prediction algorithms\nwill deal with. Section 3 introduces our hybrid approach for ﬂare prediction with feature importance.\nSection 4 applies the hybrid approach to the set of SWPC data described in Section 2 and compares\nits performances to the ones obtained by l1-logit and by other machine learning methods.\nOur\nconclusions are oﬀered in Section 5.\n2. CATEGORICAL DATA\nSolar Active Regions (ARs) are classiﬁed according to magnetic ﬁeld complexity indicators. For\nexample, ARs tracked by the National Oceanic and Atmospheric Administration (NOAA) Space\nWeather Prediction Center (SWPC) are typically classiﬁed by using the following 5 indicators (fea-\ntures): the area, the McIntosh indices (McIntosh 1990), and the Mount Wilson index (Hale et al.\n1919). The area index is computed in fractions (millionths) of a solar hemisphere. The McIntosh\nscheme uses white light emissions to represent sunspot structure and is composed by three indepen-\ndent variables: the Zurich class Z of leading/trailing spot size and separation, which may assume 7\ncategorical values; the penumbral class p of primary spot regularity, which may assume 6 categorical\nAASTEX A hybrid machine learning approach to flare prediction\n5\nvalues; the compactness class c of internal spot distribution, which may assume 4 categorical values.\nFinally, the Mount Wilson scheme groups sunspots into classes based on the complexity of magnetic\nﬂux distribution in associated active regions, according to rules set by the Mount Wilson Observatory\nin California; this feature may assume 8 categorical data.\nIn order to apply machine learning algorithms, either supervised or unsupervised, we need to\ntransform the categorical information contained in the above sunspot classiﬁcations (speciﬁcally, the\nMcIntosh and Mount Wilson indices) into numerical data. This can be done by either transforming\nthe categorical variables into dummy variables (Hardy 1993) or computing occurrence frequencies in\na historical database. In this paper we used this second approach, which preserves the dimension of\nthe space where to perform the data analysis. Speciﬁcally, we have considered the SWPC database\ncovering the December 1988 to June 1996 time range and we have computed the frequency with\nwhich a sunspot classiﬁed by a speciﬁc value of a ﬁxed indicator produces a ﬂare greater than a\ngiven class. Anyhow, we have veriﬁed that the use of the dummy variables does not improve the\neﬀectiveness of the prediction for all methods considered in this paper. On the other hand, we are\nalso aware that the use of frequencies requires the availability of a labelled dataset whose content, in\nprinciple, may increase while new data are at disposal.\nMore formally, and focusing on the speciﬁc case of the value A for the Zurich class in the McIntosh\nclassiﬁcation, we denoted by N (C1→C9)\nZ=A\n, N (M1→M9)\nZ=A\n, and N (≥X1)\nZ=A\nthe occurrences of ﬂaring events of\nclass C, M and X, respectively, and computed the frequencies associated to ﬂaring events of class\ngreater or equal to a speciﬁc class as\nf (≥C1)\nZ=A\n= N (C1→C9)\nZ=A\n+ N (M1→M9)\nZ=A\n+ N (≥X1)\nZ=A\n# A occurrences\n(1)\n(with the corresponding no-ﬂare-event frequency deﬁned as f (noflare)\nZ=A\n:= 1 −f (≥C1)\nZ=A );\nf (≥M1)\nZ=A\n= N (M1→M9)\nZ=A\n+ N (≥X1)\nZ=A\n# A occurrences\n(2)\n(with the corresponding no-ﬂare-event frequency deﬁned as f (noflare)\nZ=A\n:= 1 −f (≥M1)\nZ=A );\nf (≥X1)\nZ=A\n=\nN (≥X1)\nZ=A\n# A occurrences\n(3)\n6\nBenvenuto et al.\n(with the corresponding no-ﬂare-event frequency deﬁned as f (noflare)\nZ=A\n:= 1−f (≥X1)\nZ=A ). Similar formulas\ncan be written for each one of the other categorical predictors.\nWe ﬁnally notice that the same dataset used for computing these frequencies has been used as\ntraining set for the supervised machine learning algorithms utilized in the following. On the other\nhand, the database of SWPC indicators covering the time range between August 1996 and December\n2010 has been used as test set for both the supervised and unsupervised machine learning methods.\n3. THE HYBRID APPROACH\nWe denote with X the matrix with dimension N (number of active regions) × F (number of\nfeatures) whose columns contain the feature values for each speciﬁc active region in the training set;\nβ is the F ×1 vector containing the F model parameters to determine and y is the N ×1 data vector\nused in the training set and made of 0 and 1 values. l1-logit has been designed ’ad hoc’ to perform\nclassiﬁcation with feature importance (Wu et al. 2009). This is a constrained maximum-likelihood\nmethod that allows the estimation of the model parameters while best-ﬁtting the data. The logit\nparameter estimation method solves the minimum problem\nˆβ = arg min\nβ [−\nN\nX\ni=1\nlog(1 + e−yi(Xi·β+c))] ,\n(4)\ni.e., it searches for the maximum likelihood of the model parameter vector β when one assumes that\neach component yi of the vector y is the realization of a random variable described by the Bernoulli\ndistribution. In equation (4) Xi is the i-th row of matrix X and c is a positive constant. In order to\nrealize feature selection, l1-logit adds the condition that ∥β∥1 is small, which mathematically points\nout the few parameters that most signiﬁcantly contribute to the classiﬁcation. When a new active\nregion x is at disposal (x is a vector of F components), then ˆy = PF\nk=1 xk ˆβk is computed and its sign\ndenotes the outcome of the prediction. This implies that the classiﬁcation threshold here is ﬁxed and\nequal to zero independently of the dataset used for training.\nWe now introduce an approach to ﬂare prediction with feature selection which, diﬀerently than\nl1-logit, is hybrid and data-dependent.\nThe ﬁrst step of this two-step approach utilizes LASSO\n(Tibshirani 1996) to perform feature selection. Speciﬁcally, we look for the solution of the minimum\nAASTEX A hybrid machine learning approach to flare prediction\n7\nproblem\nˆβ = arg min\nβ (∥y −Xβ∥2\n2 + λ∥β∥1) ,\n(5)\nwhere the regularization parameter λ is optimized by means of a Cross Validation procedure (Stone\n1974). Then, in the second step, we apply a clustering method for partitioning the output of ˆy = X ˆβ.\nIn a classical clustering approach like Hard C-Means (HCM) (Jain et al. 1999), each sample may\nbelong to a unique cluster, while in a fuzzy clustering formulation a diﬀerent degree of membership\nis assigned to each sample with respect to each cluster, which implies a much higher ﬂexibility in\naccounting for data characteristics. Therefore, in the second step of our hybrid approach, we used\nFuzzy C-Means (FCM) (Bezdek 1981), which is the fuzzy extension of HCM. In this framework, the\nFCM functional is given by\nJm(ˆy, ˆz, U) =\nN\nX\nk=1\nC\nX\nj=1\n(ujk)md2\njk ,\n(6)\nwhere ˆz = {ˆzj|ˆzj ∈R , j = 1, . . . , C} is the set of the C centroids of the clusters, the component\nujk ∈[0, 1] of the C × N matrix U represents the membership of the k-th sample to the j-th cluster,\ndjk is the distance between the j-th centroid and the k-th sample, and m is the fuzziﬁer parameter.\nThe FCM optimization problem is the one to (iteratively) determine the components of the matrix\nU and of the vectors ˆz given the components of the vector ˆy.\n4. APPLICATION TO SWPC DATA AND ANALYSIS OF RESULTS\nIn this Section we have compared the performances of l1-logit and our hybrid approach during\nthe analysis of the SWPC test set covering the time range between August 1996 and December\n2010 (the cardinality of such set is 22222); for both methods we used the data collected between\nDecember 1988 and June 1996 as training set (the cardinality of this second set is 17600). Further,\nwe have also analyzed the same test set by means of other four classical machine learning methods:\nthe (unsupervised) clustering HCM and FCM algorithms, a standard Multi Layer Perceptron (MLP)\n(Rumelhart et al. 1986) and a Support Vector Machine (SVM) (Cortes & Vapnik 1995). For the\nlatest two methods, which are supervised, we used the same training set as in the case of l1-logit and\nthe hybrid method. All these prediction algorithms have been applied to predict ﬂares with class\n8\nBenvenuto et al.\nabove C1 and M1, respectively. From now on, for sake of brevity, we will indicate with ≥C1 and\n≥M1 all ﬂares with class above C1 and M1, respectively. We have not considered ﬂares with class\nabove X1 since they are rare in this dataset (less than 1% in the training set and around 0.5% in\nthe test set).\nBy means of the frequency matching process described in Section 2, each sample is transformed\ninto a 5-dimensional vector. Note that the ﬁrst four components range from 0 to 1, while the ﬁfth\none, i.e., the sunspot area, goes from 0 up to 102. Since the diﬀerences between component variances\ncan aﬀect the ﬂare prediction performances, a standardization step preceded the application of the\nmachine learning algorithms. We also note that frequency matching must be performed for each\ncase of interest, i.e, separately for the ≥C1- and ≥M1-ﬂare predictions; therefore, for both the\ntraining set and the test set, we have constructed two subsets: the ﬁrst subset, indicated with #1, is\nconstructed using the frequencies of ﬂares of class at least C1 (i.e., by applying (1) and analogous);\nthe second subset, indicated with #2, to the frequencies of ﬂares of class at least M1 (i.e., by applying\n(2) and analogous).\nAs explained in the previous section, the main advantage of the hybrid approach is in the fact that\nthe way it partitions the set of LASSO outcomes is driven by the input data. This is clearly described\nin Figure 1, showing how FCM automatically identiﬁes the probability threshold. It is interesting to\nnote that this threshold depends on the ﬂare class under consideration and in any case is diﬀerent\nthan the ﬁxed value provided by l1-logit, which splits the regressions values at 0.5.\nThe threshold value determines the prediction, whose performance can be measured by means of\nspeciﬁc scores. Many skill scores can be found in literature for the assessment of ﬂare prediction\nperformances (Bloomﬁeld et al. 2012). All these scores are linked to the forecast contingency tables\nmade up of four elements:\n• The number of ﬂares predicted and observed (true positives, TP).\n• The number of ﬂares not predicted but observed (false negatives, FN).\n• The number of ﬂares predicted but not observed (false positives, FP).\nAASTEX A hybrid machine learning approach to flare prediction\n9\n• The number of ﬂares not predicted and not observed (true negatives, TN).\nWe have validated the six ﬂare prediction algorithms by means of the following skill scores deﬁned\nin terms of the above elements. Speciﬁcally, the probability of detection\nPOD =\nTP\nTP + FN ;\n(7)\nthe accuracy\nACC =\nTP + TN\nTP + TN + FP + FN ;\n(8)\nthe false alarm ratio\nFAR =\nFP\nTP + FP .\n(9)\nThese scores range from 0 to 1 and best predictions correspond to small FAR values and high values\nfor the other scores. We also utilized two scores with values ranging from −1 to 1: the Heidke skill\nscore\nHSS =\n2 · (TP · TN −FN · FP)\n(TP + FN) · (FN + TN) + (TP + FP) · (FP + TN) ;\n(10)\nand the true skill statistics\nTSS =\nTP\nTP + FN −\nFP\nFP + TN .\n(11)\nAlso in this case good prediction performances correspond to high values of the scores. Figure 2 and\nFigure 3 present the values of all ﬁve skill scores for the ≥C1 ﬂare prediction and the ≥M1 ﬂare\nprediction, respectively. Moreover, Table 1 and Table 2 provide the results of the feature selection\nprocesses preformed by l1-logit and the hybrid technique. Speciﬁcally, the tables contain the weights\nβ with which the sunspot area, the McIntosh indices, and the Mount Wilson index contribute to the\nﬂare prediction process for the two methods.\n10\nBenvenuto et al.\nTable 1. Feature importance in ≥C class ﬂare prediction computed from the\ntraining set. For each method, the values correspond to the weights associated\nto the features divided by the sum of the weights, i.e. ¯βk := ˆβk/ PF\nj=1 ˆβj.\nMtWilson\nMcIntosh Z\nMcIntosh p\nMcIntosh c\nArea\nhybrid\n0.198\n0.268\n0.222\n0.164\n0.147\nl1-logit\n0.189\n0.332\n0.219\n0.154\n0.104\nTable 2. Feature importance in ≥M class ﬂare prediction computed from\nthe training set. See caption of Table 1 for the meaning of table entries.\nMtWilson\nMcIntosh Z\nMcIntosh p\nMcIntosh c\nArea\nhybrid\n0.281\n0.117\n0.047\n0.146\n0.407\nl1-logit\n0.181\n0.264\n0.217\n0.142\n0.194\n5. DISCUSSION AND CONCLUSIONS\nThis paper introduces a novel approach to ﬂare prediction, which utilizes indices associated to ARs\ndata and which is also able to automatically indicate the ones, among such features, that mostly\ncontribute to prediction. The approach is intrinsically hybrid, in the sense that it is based on the\ncombination of the ability of regularization to perform feature selection with the ability of clustering\nto classify in a data-adaptive fashion. In the present implementation we have used LASSO in the\nfeature selection step and FCM in the clustering step. In fact, LASSO guarantees a notable degree of\ngenerality in regularization while FCM guarantees a notable degree of ﬂexibility in data adaptation.\nAASTEX A hybrid machine learning approach to flare prediction\n11\n(a)\n(b)\nFigure 1. (a) ≥C class ﬂare prediction. Split of the Lasso regression output by means of the Fuzzy\nC-means algorithm. The x-axis shows the values of the regression outcomes provided by the cross validated\nLasso algorithm. Blue and green colors represent the two clusters identiﬁed by the Fuzzy C-means algorithm.\nBlue (resp. green) cluster is the set of all the events for which the hybrid method returns a no-ﬂare (resp.\nﬂare) prediction. (b) The same as in (a) but for ≥M class ﬂares.\nAnyhow, we have tested the hybrid approach using diﬀerent combinations of feature selection and\nclustering methods involving l1-logit and HCM: the results of both feature importance ranking and\nprediction were comparable.\nWe validated the approach against a NOAA SWPC dataset and by comparing the results with\nthe ones provided by l1-logit and other standard machine learning ﬂare prediction algorithms. This\ncomparison showed that the hybrid approach outperforms l1-logit in the case of HSS and TSS, that\n12\nBenvenuto et al.\nFigure 2. Comparison of performance between the six ﬂare prediction algorithms in terms of skill scores.\nThe bar plots represent the skill score values obtained by applying each method to the test set for the\nprediction of ≥C1 ﬂares.\nAASTEX A hybrid machine learning approach to flare prediction\n13\nFigure 3. The same as in Figure 2 but for the prediction of ≥M1 ﬂares.\n14\nBenvenuto et al.\nare often considered (Bloomﬁeld et al. 2012) the most reliable skill scores in the game (for example,\nACC tends to reach its maximum when the threshold is 0.5, which is not fully appropriate in the\ncase of unfrequent events such as M and X class ﬂares). This is particularly true for TSS and for the\nprediction of ﬂares belonging to class M or higher. More in general, the hybrid method predicts with a\nperformance rate which is very similar to the one of the other two unsupervised clustering algorithms,\nwhile, coherently, l1-logit works similarly to the other two supervised regularization methods. The\nhigher forecasting eﬀectiveness of the hybrid approach with respect to l1-logit is due to the fact\nthat it performs classiﬁcation with a thresholding procedure which is data adaptive, while l1-logit\nutilizes a ﬁxed negative/positive threshold. We note that the threshold in l1-logit could be tuned\nheuristically, searching ‘a posteriori’ for the values that provide the maximum for TSS and HSS and\nthat the advantage of fuzzy clustering is that it realizes such search ‘a priori’ and in an automatic\nway.\nThe hybrid approach and l1-logit can be compared also as far as their feature selection power is\nconcerned. Table 1 clearly shows that, in forecasting ≥C1 ﬂares, the two methods indicate the same\nfeatures as the ones that mostly contribute to the prediction. Results are diﬀerent when predicting\n≥M1 ﬂares, since LASSO gives the highest emphasis to the AR area, while l1-logit points out\nmore signiﬁcantly two of the three McIntosh indices as mostly signiﬁcant. A clariﬁcation of this\ncontradictory outcome shall be obtained by means of a systematic application of these two methods\nagainst either several SWPC datasets or features extracted from SDO/HMI images; this activity\nis part of the tasks currently addressed by the H2020 project FLARECAST, which will provide a\ntechnological platform for the testing of ﬂare prediction algorithms and for the validation of the\nforecasting and feature selection results.\nThe authors have been supported by the H2020 grant Flare Likelihood And Region Eruption fore-\nCASTing (FLARECAST), project number 640216. The authors kindly thank Prof. Shaun Bloomﬁeld\nfor providing the SWPC data and Dr. Annalisa Perasso for useful discussion.\nAASTEX A hybrid machine learning approach to flare prediction\n15\nREFERENCES\nBezdek, J. C. 1981, Pattern Recognition with\nFuzzy Objective Function Algorithms (Norwell,\nMA, USA: Kluwer Academic Publishers)\nBloomﬁeld, D. S., Higgins, P. A., McAteer, R.\nT. J., & Gallagher, P. T. 2012, Astrophysical\nJournal Letters, 747, L41\nBobra, M. G., & Couvidat, S. 2015, Astrophysical\nJournal, 798, 135\nColak, T., & Qahwaji, R. 2009, Space Weather, 7,\nS06001\nCortes, C., & Vapnik, V. 1995, Machine learning,\n20, 273. http://www.springerlink.com/\nindex/K238JX04HM87J80G.pdf\nGallagher, P. T., Moon, Y. J., & Wang, H. 2002,\nSolar Physics, 209, 171\nGarson, G. D. 1991, Artiﬁcial Intelligence Expert,\n6, 47\nHale, G. E., Ellerman, F., Nicholson, S. B., & Joy,\nA. H. 1919, The Astrophysical Journal, 49, 153.\nhttp://adsabs.harvard.edu/full/1919ApJ.\n...49..153H\nHardy, M. A. 1993, Regression with Dummy\nVariables (SAGE)\nJain, A. K., Murty, N. M., & Flynn, P. J. 1999,\nACM Computing Surveys, 31, 264\nKontar, E. P., Brown, J. C., Emslie, A. G., et al.\n2011, Space Science Reviews, 159, 301\nLi, R., Wang, H. N., He, H., Cui, Y. M., & Du,\nZ. L. 2007, Chinese Journal of Astronomy and\nAstrophysics, 7, 441\nMcIntosh, P. S. 1990, Solar Physics, 125, 251.\nhttps://link.springer.com/article/10.\n1007/BF00158405\nOlden, J. D., Joy, M. K., & Death, R. G. 2004,\nEcological Modeling, 178, 389\nRumelhart, D. E., Hinton, G. E., & Williams,\nR. J. 1986, Nature, 323, 533\nStone, M. 1974, Journal of the Royal Statistical\nSociety B, 36, 111\nTibshirani, R. 1996, Journal of the Royal\nStatistical Society. Series B (Methodological),\n267. http://www.jstor.org/stable/2346178\nWheatland, M. S. 2004, Astrophysical Journal,\n609, 1134\nWu, T. T., Chen, Y. F., Hastie, T., Sobel, E., &\nLange, K. 2009, Bioinformatics, 25, 714.\nhttps://academic.oup.com/bioinformatics/\narticle/25/6/714/251234/\nGenome-wide-association-analysis-by-lasso\nYu, D., Huang, X., Wang, H., & Cui, Y. 2009,\nSolar Physics, 255, 91\nYuan, Y., Shih, F. Y., Jing, J., & Wang, H. M.\n2010, Research in Astronomy and Astrophysics,\n10, 8\n",
  "categories": [
    "astro-ph.SR",
    "cs.LG",
    "85-08"
  ],
  "published": "2017-06-21",
  "updated": "2017-06-21"
}