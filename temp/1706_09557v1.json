{
  "id": "http://arxiv.org/abs/1706.09557v1",
  "title": "Machine listening intelligence",
  "authors": [
    "C. E. Cella"
  ],
  "abstract": "This manifesto paper will introduce machine listening intelligence, an\nintegrated research framework for acoustic and musical signals modelling, based\non signal processing, deep learning and computational musicology.",
  "text": "Machine listening intelligence\nCarmine-Emanuele Cella1\n1Ircam, Paris, France\nThis manifesto paper will introduce machine listening intelligence, an integrated\nresearch framework for acoustic and musical signals modelling, based on signal\nprocessing, deep learning and computational musicology.\nKeywords: deep unsupervised learning, computational musicology, representation theory.\n1 Introduction\n1.1 Motivation\nThe relation between signals and symbols is a central problem for acoustic signal processing.\nAmong diﬀerent kind of signals, musical signals are speciﬁc examples in which there is some\ninformation regarding the underlying symbolic structure.\nWhile an impressive amount of\nresearch has been done in this domain in the past thirty years, the symbolic processing of\nacoustic and musical signals is still only partially possible.\nThe aim of this paper, grounded on our previous work [Cella, 2009], is to propose a manifesto\nfor a generalised approach for the representation of acoustic and musical signals\ncalled machine listening intelligence (MLI), by integrating cognitive musicology in-\nsights, hand-crafted signal processing and deep learning methods in a general mathematical\nframework.\nAmong existing approaches that share similarities with ours, there are the multiple viewpoint\nsystem [Conklin, 2013] and IDyOM [Pearce and Wiggins, 2013]. While comparing diﬀerences\nand similiarities with these approaches could be interesting, we will not do this here and we\nmention them only for reference.\n1.2 Scientiﬁc assessment\nIn the past twenty years, with the improvement of computers and the advancements in ma-\nchine learning techniques, a whole ﬁeld called music information retrieval (MIR) developed\nmassively. This important domain of research brought impressive results and had been able\nto tackle problems that appeared to be unsolvable, such as the classiﬁcation of very com-\nplex signals. Nonetheless, tasks that are relatively easy for humans are still hard and there\nare not general solutions. Apparently, these kind of tasks are often ill-deﬁned or lack proper\ninformation to be correctly represented.\nC.E. Cella. 2017. Machine listening intelligence. Proceedings of the First International Workshop on Deep\nLearning and Music joint with IJCNN. Anchorage, US. May, 2017. 1(1). pp 50-55\narXiv:1706.09557v1  [cs.SD]  29 Jun 2017\nMore recently, the uprise of deep learning techniques in computer vision created a real revolu-\ntion in machine learning given the advancements they provided [Krizhevsky et al., 2012]. Deep\nconvolutional networks, for example, provide state of the art classiﬁcations and regressions\nresults over many high-dimensional problems [Le Cun et al., 2015]. Their general architecture\nis based on a cascade of linear ﬁlter weights and non-linearities [Mallat, 2016]; the weights\nare learned from massive training phases and generally outperform hand-crafted features. The\nswitch to large scale problems that happened in the past few years in the computer vision\ncommunity, moreover, proved the fact that we need to address more general problems for\nacoustic signals, where the domain of research is not deﬁned by a single sample but by a whole\npopulation.\nHowever, these complex programmable machines bring us to a very diﬃcult and partially\nunknown mathematical world. We believe that representation theory is good candidate for\nsuch mathematical model. Signal representation methods can be thought as linear operators\nin vector space and representation theory studies abstract algebraic structures by representing\ntheir elements as linear transformations of vector spaces [Fulton and Harris, 2004].\nNext sections will be as follows: section 2 will show some problems and applications that\nwe would like to address with our approach. From section 3 we will go more into technical\ndetails describing what are representations for signals and reviewing their properties both from\ncognitive and mathematical standpoints. This will serve a background for section 4, that will\npresent the general research approach for MLI.\n2 Problems and outcomes\nAmong the large number of open problems in the ﬁeld of signal processing, we would like\nto present here some interesting examples that could be treated in the context of machine\nlistening intelligence. These problems refer particularly to music and creative applications,\nbut we think that the developed methodology could be further used in diﬀerent domains. As\nsuch, they must be considered just as examples of possible outcomes.\n2.1 Semantic signal processing\nA signal transformation is, in a general sense, any process that changes or alter a signal\nin a signiﬁcant way. Transformations are closely related to representations: each action is,\nindeed, performed in a speciﬁc representation level. For example, an elongation performed\nin time domain gives inferior results (perceptually) to the same transformation performed in\nfrequency domain, where you have access to phases. In the same way, a pitch shift operated\nin frequency domain gives inferior results to the same operation performed using a spectral\nenvelope representation, where you have access to dominant regions in the signal. In the two\ncases discussed above we passed from a low-level representation (waveform) to a middle-level\nrepresentation (spectral envelope). We could, ideally, iterate this process by increasing the\nlevel of abstraction in a representation thus giving access to speciﬁc properties of sound that\nare perceptually relevant; by means of a powerful representation it could therefore be possible\nto access a semantic level for transformations. We envision, therefore, the possibility in the\nfuture to have such kind of semantic transformations by accessing representations given by\ndeep learning models.\nC.E. Cella. 2017. Machine listening intelligence. Proceedings of the First International Workshop on Deep\nLearning and Music joint with IJCNN. Anchorage, US. May, 2017. 1(1). pp 50-55\n2.2 High-level acoustic features\nOne of the most impressive example of creative application of deep learning is, in our opinion,\nstyle transfer. In a paper published in 2016 [Gatys et al., 2016], for example, the authors\nshowed how it is possible, using the latent space of a deep network, to transfer high level\nfeatures from one image to another. It is interesting to remark that the transferred features\nare not simple eﬀects but real traits of the style of the image.\nUnfortunately, such an impressive process is not possible on acoustic signals for the moment.\nIn 2013 we achieved the construction of an advanced hybridisation system for sounds [Cella\nand Burred, 2013]. The basic idea of our approach was to represent sounds in term of classes\nof equivalences and probabilities, then mix the classes of one sound with the probabilities\nof another one.\nWhile the perceptual results were satisfying for us, the limitation of the\nrepresentation method used, didn’t permit to access high-level acoustic features.\nWe believe that deep musical style transfer can be considered as a generalisation of hybridi-\nsation and we strongly believe that this kind of processing could be achieved by MLI.\n3 Signal representations\nDeﬁning a representation for music and musical signals involves the establishment of essential\nproperties that must be satisﬁed. Many years of research have been devoted to such a complex\ntask in the ﬁeld of cognitive musicology, a branch of cognitive sciences focused on the modelling\nof musical knowledge by means of computational methods [Laske and al., 1992].\nAmong important properties for musical representations found from the literature in the\nﬁeld, there are milestones such as multiple abstraction levels, multi-scale and generativity.\nInterestingly enough, these properties are not only speciﬁc to music but can be applicable to\ndiﬀerent kind of acoustic signals, as we will see.\nUsually, the description of acoustic signals select a particular degree of abstraction in the\ndomain of the representation. In general, low-level representations are generic and have very\nhigh dimensionality. These representations evolve fast and the only transformations that are\npossible at this level are geometric (translations, rotations, etc.) and are mostly deﬁned on\ncontinuous (Lie) groups [Mallat, 2016]. In the middle, there are families of representations\n(often related to perceptual concepts) that have a medium level of abstraction and a not so huge\ndimensionality and allow for transformations on speciﬁc concept (variables), usually deﬁned on\ndiscrete groups [Lostanlen and Cella, 2016]. On the other end, very abstract representations\nare pretty much expressive and have a low dimensionality; in a sense, these representations deal\nwith almost-stationary entities such as musical ideas and unfortunately it is very diﬃcult to\nknow which mathematical structure stays behind. As an example, we could think to low-level\nrepresentations as signals (used by listeners), to middle-level as scores (used by performers)\nand to high-level as musical ideas (used by composers). Figure 1 depicts the outlined concepts.\nRepresentations can be considered linear operators that need to be invariant to sources of\nunimportant variability, while being able to capture discriminative information from signals.\nAs such, they must respect four basic properties; being x a signal and Φx its representation:\n• discriminability: Φx ̸= Φy =⇒x ̸= y;\n• stability: ∥Φx −Φy∥2 ≤C∥x −y∥2;\n• invariance (to group of transformations G): ∀g ∈G, Φg.x = Φx;\nC.E. Cella. 2017. Machine listening intelligence. Proceedings of the First International Workshop on Deep\nLearning and Music joint with IJCNN. Anchorage, US. May, 2017. 1(1). pp 50-55\nideas\nscores\nsignals\ncomposers\nperformers + \ninstruments\nlisteners\nfast\ngeometric transformations\n(translations, rotations, ...)\ncontinuous (Lie) groups\ndiscrete ﬁnite groups\n??\ntransformations on speciﬁc \nvariables (known or discovered)\n(symmetry in Z12)\nunknown transformations \nexpressive\ngeneric\nslow\nalmost\nstationary\nhigh dimensionality,\nlow abstraction\nmedium dimensionality,\nmedium abstraction\nlow dimensionality,\nhigh abstraction\nrepresentations\nFigure 1: Diﬀerent abstraction degrees in representations.\n• reconstruction: y = Φx ⇐⇒˜x = Φ−1y.\nDiscriminability means that if the representations of two signals are diﬀerent than the two sig-\nnals must be diﬀerent. Stability means that a small modiﬁcation of a signal should be reﬂected\nin a small modiﬁcation in the representation and vice-versa. Invariance to a group of transfor-\nmation G, means that if a member of the group is applied to a signal, than the representation\nmust not change; reconstruction, ﬁnally, is the possibility to go back to a signal that is equiv-\nalent to the original (in the sense of a group of transformations) from the representation. It is\npossible to divide representations in two major categories: prior and learned.\n3.1 Prior and learned representations\nIn prior representations, signals are decomposed using a basis that has been deﬁned mathemat-\nically, in order to respect (some of) the properties given above. The general model of a prior\nrepresentation is a decomposition of a signal x into a linear combination of expansion functions:\nx = PK\nk=1 αkgk, where K is the dimensionality, the coeﬃcients αk are weights derived from an\nanalysis stage an functions gk are ﬁxed beforehand and are used during a synthesis stage. The\nchoice of the decomposition functions is dependent on the particular type of application needed\nand the more compact (sparse) the representation is, the more the functions are correlated to\nthe signal.\nIn learned representations, the decomposition functions used to describe a signal are learned\nby a training on some examples that belong to a speciﬁc problem. The training can be done\nin two diﬀerent ways: supervised or unsupervised.\nSupervised learning is a high-dimensional interpolation problem. We approximate a function\nf(x) from q training samples {xi, f(xi)}i≤q, where x is a data vector of very high dimension d.\nA powerful example of supervised learned representation are convolutional neural networks.\nIn unsupervised training, on the other hand, there is not a target function to approximate\nand other mathematical constraints are applied, such as sparsity or variance reduction. Typical\nC.E. Cella. 2017. Machine listening intelligence. Proceedings of the First International Workshop on Deep\nLearning and Music joint with IJCNN. Anchorage, US. May, 2017. 1(1). pp 50-55\nexamples of unsupervised representations are sparse coding and auto-encoders.\n3.2 Importance of unsupervised learning\nRecent advancements showed that supervised learning is able, if given the right conditions, to\noutperform both unsupervised and prior representations. There are problems, however, where\nthis family of representations cannot be applied and the only possible approach for learning a\nrepresentation is using unsupervised methods:\n• lack of labeled data: copyright issues can make impossible to deploy a database of labeled\nmusic of a signiﬁcative size to be used a reference case for reproducible research;\n• cost of data gathering: some real-life problems are related to contexts in which is impos-\nsible to gather large amount of data (such as biomedical recordings);\n• conceptual disagreement: in some cases, it is very diﬃcult or even impossible to assign\nlabels to acoustic signals given their inherent ambiguity (music is often such a case).\n4 Research approach\nThe discussion given above outlines, in our opinion, the necessity of a general framework able\nto integrate the diﬀerent approaches to the representation of musical and acoustical signals\ninto a common perspective.\nMachine listening intelligence aims at being such a framework, by integrating cognitive\nmusicology insights, established signal processing techniques and more recent advancements in\ndeep learning in the context of representation theory.\nPrior representations are deﬁned by mathematical models but fail to achieve the same ex-\npressivity of learned representations. On the contrary, deep learning proved to be valuable\nin incredibly diﬀerent domains and showed that some learning techniques are indeed general.\nOne of the issues, in the case of acoustic and musical signals, is that there is not a common\nand established mathematical model for this kind of methods. Moreover, supervised learning\nis not always possible for the reasons outlined in section 3.2. Therefore, we envision a research\napproach based on the following main factors:\n• deep unsupervised learning methods: only with deep architectures it is possible to\ncreate multi-scale representations that have diﬀerent abstraction levels; using unsuper-\nvised learning, it is possible to address diﬃcult problems that lack labelled data;\n• representation theory: by interpreting learning with linear operators, it is possible to\ncreate a common mathematical language to compare and study its properties;\n• large scale problems: using large datasets (that usually embody diﬃcult problems)\nwill impose the research of scalable and general learning methods, that can be transferred\nto many diﬀerent domains;\n• multi-disciplinarity: putting together several sources of knowledge such as psychoa-\ncoustics, cognitive musicology, computational neurobiology, signal processing and ma-\nchine learning is the key for future development of the so-called intelligent machines.\nC.E. Cella. 2017. Machine listening intelligence. Proceedings of the First International Workshop on Deep\nLearning and Music joint with IJCNN. Anchorage, US. May, 2017. 1(1). pp 50-55\nWhile prior representations formally deﬁne the level of abstraction, they cannot reach the\nsame level of aggregate information gathered by deep learning networks. These networks, on\nthe other hand, are not capable of explaining the concepts they discover. For such reasons,\nit is interesting to make a bridge between these two approaches by immersing both in a more\ngeneral framework that could be found in representation theory. Machine listening intelligence\naims at ﬁlling this gap.\nReferences\nC. E. Cella. Towards a symbolic approach to sound analysis. In proceedings of MCM. Yale,\nUSA, 2009.\nC. E. Cella and J. J. Burred. Advanced sound hybridization by means of the theory of sound-\ntypes. In proceedings of ICMC. Perth, Australia, 2013.\nD. Conklin. Multiple viewpoint systems for music classiﬁcation. In Journal of New Music\nResearch, volume 42, no. 1, pages 19–26, 2013.\nW. Fulton and J. Harris. Representation theory. In proceedings of MCM, volume 129. NY:\nSpringer New York, 2004.\nL. Gatys, A. Ecker, and M. Bethge. Style transfer using convolutional neural networks. In\nproceedings of CVPR, 2016.\nA. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classiﬁcation with deep convolutional\nneural networks. In proceedings of NIPS, pages 1090–1098, 2012.\nO. Laske and al. Understanding music with a.i.: perspectives on music cognition. AAAI Press,\n1992.\nY. Le Cun, Y. Bengio, and G. Hinton. Deep learning. In Nature. 215, 2015.\nV. Lostanlen and C. E. Cella. Deep convolutional networks on the pitch spiral for musical\ninstrument recognition. In proceedings of ISMIR. New York, USA, 2016.\nS. Mallat. Understanding deep convolutional networks. In Philosophical transactions A, 2016.\nM. T. Pearce and G. A. Wiggins. Auditory expectation: The information dynamics of music\nperception and cognition. In Topics in Cognitive Science, volume 4, no. 4, pages 625–652,\n2013.\nC.E. Cella. 2017. Machine listening intelligence. Proceedings of the First International Workshop on Deep\nLearning and Music joint with IJCNN. Anchorage, US. May, 2017. 1(1). pp 50-55\n",
  "categories": [
    "cs.SD",
    "cs.LG",
    "68Txx",
    "C.1.3; H.5.1"
  ],
  "published": "2017-06-29",
  "updated": "2017-06-29"
}