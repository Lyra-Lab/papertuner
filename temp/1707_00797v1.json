{
  "id": "http://arxiv.org/abs/1707.00797v1",
  "title": "Learning Deep Energy Models: Contrastive Divergence vs. Amortized MLE",
  "authors": [
    "Qiang Liu",
    "Dilin Wang"
  ],
  "abstract": "We propose a number of new algorithms for learning deep energy models and\ndemonstrate their properties. We show that our SteinCD performs well in term of\ntest likelihood, while SteinGAN performs well in terms of generating realistic\nlooking images. Our results suggest promising directions for learning better\nmodels by combining GAN-style methods with traditional energy-based learning.",
  "text": "Learning Deep Energy Models: Contrastive Divergence vs. Amortized MLE\nQiang Liu\nDilin Wang\nComputer Science, Dartmouth College, Hanover, NH 03755\nAbstract\nWe propose a number of new algorithms for\nlearning deep energy models from data motivated\nby a recent Stein variational gradient descent\n(SVGD) algorithm, including a Stein contrastive\ndivergence (SteinCD) that integrates CD with\nSVGD based on their theoretical connections,\nand a SteinGAN that trains an auxiliary gener-\nator to generate the negative samples in maxi-\nmum likelihood estimation (MLE). We demon-\nstrate that our SteinCD trains models with good\ngeneralization (high test likelihood), while Stein-\nGAN can generate realistic looking images com-\npetitive with GAN-style methods. We show that\nby combing SteinCD and SteinGAN, it is possi-\nble to inherent the advantage of both approaches.\n1\nIntroduction\nEnergy-based models (EBMs) capture dependencies be-\ntween variables by associating a scalar energy to each con-\nﬁguration of the variables. Learning EBMs consists in ﬁnd-\ning an energy function that assigns low energy to correct\nvalues, and high energy to incorrect values. Energy-based\nlearning provides a uniﬁed framework for many learning\nmodels, such as undirected graphical models (LeCun et al.,\n2006), deep generative models (Ngiam et al., 2011; Xie\net al., 2016).\nMaximum likelihood estimator (MLE) provides a funda-\nmental approach for learning energy-based probabilistic\nmodels from data. Unfortunately, exact MLE is intractable\nto calculate due to the difﬁculty of evaluating the normal-\nization constant and its gradient. This problem has attracted\na vast literature in the last few decades, based on either ap-\nproximating the likelihood objective, or developing alter-\nnative surrogate loss functions (see e.g., Koller & Fried-\nman, 2009; Goodfellow et al., 2016, for reviews). Con-\ntrastive divergence (CD) (Hinton, 2002) is one of the most\nimportant algorithms, which avoids estimating the normal-\nization constant by optimizing a contrastive objective that\nmeasures how much KL divergence can be improved by\nrunning a small numbers of Markov chain steps towards\nthe intractable energy model. CD has been widely used\nfor learning models like restricted Boltzmann machines and\nMarkov random ﬁelds (Carreira-Perpinan & Hinton, 2005;\nHinton & Salakhutdinov, 2006).\nAlthough being able to train models that have high testing\nlikelihood, CD and other traditional energy-based learning\nalgorithms can not generate high quality samples that re-\nsemble real-world instances, such as realistic-looking im-\nages. This is because the real world instances live a rela-\ntively low manifold which the the energy-based models can\nnot capture. This problem has been addressed by the recent\ngenerative adversarial networks (GAN) (e.g., Goodfellow\net al., 2014; Radford et al., 2015; Salimans et al., 2016; Ar-\njovsky et al., 2017, to name only a few), which, instead of\ntraining energy models, directly train generative networks\nthat output random samples to match the observed data by\nframing the divergence minimization problem into a mini-\nmax game. By designing the generator using deep convolu-\ntional networks (Radford et al., 2015), the prior knowledge\nof the real-world manifold can be incorporated into learn-\ning. However, GAN does not explicitly assign an energy\nscore for each data point, and can over-ﬁt on a subset of the\ntraining data, and ignore the remaining ones. A promising\ndirection is to combine GAN-type methods with traditional\nenergy-based learning to integrate the advantages of both.\nBased on a recent Stein variational gradient descent\n(SVGD) algorithm for approximate inference (Liu &\nWang, 2016), we propose a number of new algorithms for\ntraining deep energy models, including a Stein contrastive\ndivergence (SteinCD) that combines CD with SVGD based\non their theoretical connections, and a SteinGAN algorithm\nthat approximates MLE using a sampler (generator) that\namortizes the negative sample approximation. We show\nthat SteinCD and SteinGAN exhibit opposite properties,\nSteinCD tends to learn models with high testing likelihood\nbut can not generate high quality images, while SteinGAN\narXiv:1707.00797v1  [stat.ML]  4 Jul 2017\ngenerates realistic looking images but does not generalize\nwell. Our SteinGAN approach suggests that it is possible to\ngenerate high quality images comparable with GAN-type\nmethods using energy-based models, opening the possibil-\nity of combining the traditional energy-based learning tech-\nniques with GAN approaches. In experiments, we show\nevidence that by simply mixing SteinCD and SteinGAN\nupdates it is possible to obtain algorithms that combine the\nadvantage of both.\nOutline\nSection 2 introduces background on Stein vari-\national gradient descent and energy-based models. Sec-\ntion 3 and 4 discuss our SteinCD and SteinGAN methods\nfor training energy-based models, respectively. Empirical\nresults are shown in Section 5. Section 6 concludes the\npaper.\n2\nBackground\nIn this section, we ﬁrst introduce the background of Stein\nvariational gradient descent (SVGD) which forms the foun-\ndation of our work, and then review energy-based proba-\nbilistic models and contrastive divergence (CD). Our intro-\nduction highlights the connection between SVGD and CD\nwhich motivates us to propose SteinCD in Section 3.\n2.1\nStein Variational Gradient Descent (SVGD)\nStein variational gradient descent (SVGD) (Liu & Wang,\n2016) is a general purpose deterministic approximate sam-\npling method. The idea is to iteratively evolve a set of par-\nticles to yield the fastest decrease of KL divergence locally.\nLet p(x) be a positive density function in Rd that we want\nto approximate. Assume we start with a set of particles\n{xi}n\ni=1 whose empirical distribution is q0(x) = P\ni δ(x−\nxi)/n, and want to move {xi}n\ni=1 closer to the target dis-\ntribution p(x) to improve the approximation quality. To do\nso, assume we update the particles by a transform of form\nx′\ni ←xi + ϵφ(xi),\n∀i = 1, · · · , n,\nwhere ϵ is a small step size and φ is a velocity ﬁeld that de-\ncides the perturbation direction of the particles. Ideally, φ\nshould be chosen to maximally decrease the KL divergence\nwith p; this can be framed as the following optimization\nproblem:\nφ∗= arg max\nφ∈F\n\u001a\nKL(q0 || p) −KL(q[ϵφ] || p)\n\u001b\n,\n(1)\nwhere q[ϵφ] is the (empirical) distribution of x′ = x+ϵφ(x)\nwhen x ∼q0, and F is a predeﬁned function space that we\noptimize over. Note that although KL(q0 || p) can be inﬁ-\nnite (or illy deﬁned) when q0 is an empirical delta measure,\nthe difference of KL divergence in Eq. (1) can be ﬁnite be-\ncause the inﬁnite parts cancel out with each other. This can\nbe checked by ﬁrst approximating q0 by a Gaussian mixture\nwith variance σ, and then show that the limit exists and is\nﬁnite when taking σ to zero.\nEquation (1) deﬁnes a challenging nonlinear functional op-\ntimization problem. It can be simpliﬁed by assuming the\nstep size ϵ →0, in which case the decreasing rate of KL\ndivergence can be approximated by the gradient of the KL\ndivergence w.r.t. ϵ at ϵ = 0, that is,\nφ∗= arg max\nφ∈F\n\u001a\n−d\ndϵKL(q[ϵφ] ∥p)\n\f\f\nϵ=0\n\u001b\n.\n(2)\nFurther, Liu & Wang (2016) showed that the gradient ob-\njective in (2) can be expressed as a linear functional of φ,\n−d\ndϵKL(q[ϵφ] || p)\n\f\f\nϵ=0 = Ex∼q0[Tpφ(x)]\nwith Tpφ(x)\ndef\n= ⟨∇x log p(x), φ(x)⟩+ ⟨∇x, φ(x)⟩,\nwhere Tp is a linear operator acting on a d×1 vector-valued\nfunction φ and returns a scalar-valued function, and Tp is\ncalled the Stein operator in connection with the so called\nStein’s identity, which says that Ex∼q[Tpφ(x)] = 0 when\nq = p as a result of integration by parts.\nTherefore, the optimization in (2) reduces to\nD(q0 || p)\ndef\n=\nmax\nφ∈F\n\u001a\nEx∼q0[Tpφ(x)]\n\u001b\n,\n(3)\nwhere D(q0 || p) provides a notation of discrepancy mea-\nsure between q0 and p and is known as the Stein discrep-\nancy. If F is taken to be rich enough, D(q0 || p) = 0 only\nif there exists no velocity ﬁeld φ that can decrease the KL\ndivergence between p and q0, which must imply p = q0.\nThe problem can be further simpliﬁed by taking a set F\nto have “simple” structures, but still remain to be inﬁ-\nnite dimensional to catch all the possible useful veloc-\nity ﬁelds.\nA natural choice, motivated by kernel meth-\nods (e.g., Scholkopf & Smola, 2001), is to take F to be\nthe unit ball of a vector-valued reproducing kernel Hilbert\nspace (RKHS) H = H0 × · · · × H0, where each H0 is\na scalar-valued RKHS associated with a positive deﬁnite\nkernel k(x, x′), that is,\nF = {φ ∈H: ||φ||H ≤1}.\nBrieﬂy speaking, H is the closure of functions of form\nφ(x) = P\ni aik(x, xi), ∀ai ∈Rd, xi ∈Rd, equipped\nwith norm ||φ||2\nH = P\nij a⊤\ni ajk(xi, xj). With this choice,\nLiu et al. (2016) showed the optimal solution of (3) is\nφ∗/||φ∗||, where\nφ∗(x′) = Ex∼q0[Tp ⊗k(x, x′)]\n= Ex∼q0[∇x log p(x)k(x, x′) + ∇xk(x, x′)]. (4)\nwhere Tp ⊗f\ndef\n= ∇log p(x)f(x) + ∇xf(x) denotes the\nouter product version of Stein operator, which acts on a\nscalar-valued function f and outputs a d × 1 vector-valued\nfunction (velocity ﬁeld).\nTherefore, φ∗provides the best update direction within\nRKHS H. By repeatedly applying this update starting with\na set of initial particles, we obtain the SVGD algorithm:\nxi ←xi + ϵφ∗(xi),\n∀i = 1, . . . , n,\n(5)\nφ∗(xi) = 1\nn\nn\nX\ni=1\n[∇xj log p(xj)k(xj, xi) + ∇xjk(xj, xi)].\nUpdate (5) mimics a gradient dynamics at the particle level,\nwhere the two terms in φ∗(xi) play different roles: the term\nwith the gradient ∇x log p(x) drives the particles toward\nthe high probability regions of p(x), while the term with\n∇xk(x, xi) serves as a repulsive force to encourage diver-\nsity as shown in Liu & Wang (2016).\nIt is easy to see from (5) that φ∗(xi) reduces to the typical\ngradient ∇x log p(xi) when there is only a single particle\n(n = 1) and ∇xk(x, xi) = 0 when x = xi, in which cases\nSVGD reduces to the standard gradient ascent for maxi-\nmizing log p(x) (i.e., maximum a posteriori (MAP)).\n2.2\nLearning Energy Models\nSVGD is an inference process in which we want to ﬁnd a\nset of particles (or “data”) {xi}n\ni=1 to approximate a given\ndistribution p(x). The goal of this paper is to investigate\nthe learning problem, the opposite of inference, in which\nwe are given a set of observed data {xi}n\ni=1 and we want to\nconstruct a distribution p, found in a predeﬁned distribution\nfamily, to best approximate the data.\nIn particular, we assume the observed data {xi}n\ni=1 is i.i.d.\ndrawn from an unknown distribution pθ = p(x | θ) indexed\nby a parameter θ, of form\np(x | θ) =\n1\nZ(θ) exp(f(x; θ)),\nwith Z(θ) =\nZ\nx\nexp(f(x; θ))dx,\n(6)\nwhere f(x; θ) is a scalar-valued function that represents\nthe negative energy of the distribution, and Z(θ) is the par-\ntition function which normalizes the distribution. A fun-\ndamental approach for estimating θ is the maximum likeli-\nhood estimation (MLE):\nˆθ = arg max\nθ\n\u001a\nL(θ | X) ≡1\nn\nn\nX\ni=1\nlog p(xi | θ)\n\u001b\n,\n(7)\nwhere L(θ | X) is the log-likelihood function.\nFor the\nenergy-based model in (6), the gradient of L(θ | X) can\nbe shown to be\n∇θL(θ | X) = Eq0[∇θf(x; θ)] −Epθ[∇θf(x; θ)],\n(8)\nwhere we still use q0(x) = 1\nn\nPn\ni=1 δ(x−xi) to denote the\nempirical distribution of data {xi}n\ni=1. This gives a gradi-\nent ascent update for solving MLE:\nθ ←θ + µ(Eq0[∇θf(x; θ)] −Epθ[∇θf(x; θ)]),\nwhere µ is the step size. Intuitively, this update rule itera-\ntively decreases the energy of the observed data (or the pos-\nitive samples), while increases the energy of the negative\nsamples, drawn from the hypothesized model pθ. When\nthe algorithm converges, we should have ∇θL(θ | X) = 0,\nwhich is a moment matching condition between the empir-\nical and the model-based averages of ∇θf(x; θ).\nHowever, critical computational challenges arise, because\nit is intractable to exactly calculate the model-based ex-\npectation Epθ[∇θf(x; θ)] and efﬁcient approximation is\nneeded.\nOne way is to use Markov chain Monte Carlo\n(MCMC) to approximate the expectation (e.g., Geyer,\n1991; Snijders, 2002). Unfortunately, MCMC-MLE is of-\nten too slow in practice, given that we need to approximate\nthe expectation repeatedly at each gradient update step.\nContrastive Divergence\nMaximum likelihood estima-\ntion can be viewed as ﬁnding the optimal θ to minimize\nthe KL divergence between the empirical data distribution\nq0 and the assumed model pθ:\nmin\nθ\nKL(q0 || pθ).\n(9)\nContrastive divergence (Hinton, 2002) is an alternative\nmethod that optimizes a different objective function:\nmin\nθ\n\b\nCDk\ndef\n= KL(q0 || pθ) −KL(qk || pθ)\n\t\n,\n(10)\nwhere qk is a distribution obtained by moving q0 towards pθ\nfor k steps, more precisely, by running k steps of Markov\ntransitions whose equilibrium distribution pθ, starting from\nthe empirical distribution q0. CDk is always non-negative\nbecause running Markov chain forward can only decrease\nthe KL divergence (Cover & Thomas, 2012), and equals\nzero only if q0 matches pθ. Observe that Eq. (10) and (1)\nshare a similar objective function, but optimize different\nvariables (φ vs. θ). Their similarity is the main motivation\nof our Stein contrastive divergence algorithm (Section 3).\nTaking gradient descent on the CDk objective (without dif-\nferentiating through qk) gives the following update rule:\nθ ←θ + µ(Eq0[∇θf(x; θ)] −Eqk[∇θf(x; θ)]).\n(11)\nCompared with the MLE update (8), the CD-k update re-\nplaces the “ideal” negative sample drawn from pθ with a\nlocal k-step perturbation of the observed data. Although\nCD-∞can be viewed as MLE, the key observation of Hin-\nton (2002) is that even by using a small k, such as k = 1,\nwe obtain useful contrastive information about how the pa-\nrameter θ should be improved.\nAlgorithm 1 Stein Contrastive Divergence (SteinCD)\nGoal: Learn energy model (6) from data {xi}n\ni=1.\nwhile no Converged do\n1. Draw a minibatch of positive sample {x+\ni }m\ni=1 from\nthe training set.\n2. Perform one step of SVGD update (Eq.\n5) on\n{x+\ni }m\ni=1 to get negative samples x−\ni by\nx−\ni ←x+\ni + ϵφ∗(x+\ni ),\n∀i = 1, . . . , m.\n3. Update θ by\nθ ←θ + µ\nm\nm\nX\ni=1\n(∇θf(x+\ni ; θ) −∇θf(x−\ni ; θ)).\nend while\n3\nStein Contrastive Divergence\nThe performance of CD depends on the choice of Markov\nchain it uses; it is clear that we should select the Markov\nchain to minimize KL(qk || pθ) and hence maximize the\ncontrastive objective (10), bringing it closer to the MLE\nobjective (9). However, it is unclear how to frame the op-\ntimal choice of Markov chains into an solvable optimiza-\ntion problem. SVGD provides a natural solution for this,\ngiven that it explicitly provides the best perturbation direc-\ntion that maximizes the very same contrastive objective.\nTo be more speciﬁc, assume we perturb the observed data\n{xi}n\ni=1 with a deterministic transform x′ ←x + ϵφ(x) as\nin SVGD, where the velocity ﬁeld φ is decided jointly with\nthe model parameter θ by solving the following minimax\nproblem:\nmin\nθ\nmax\nφ∈F\n\b1\nϵ (KL(q0 || pθ) −KL(q[ϵφ] || pθ))\n\t\n.\n(12)\nWe then solve this problem by alternating between mini-\nmizing θ and maximizing φ. Following the derivation of\nSVGD, with small step size ϵ, φ has a closed form solution\nshown in (4), and the gradient update of θ is\nθ ←θ + µ(Eq0[∇θf(x; θ)] −Eq[ϵφ∗][∇θf(x; θ)]), (13)\nwhere we update θ using the result of one step of SVGD\nupdate on the observed data as the negative samples. This\ngives our Stein contrastive divergence shown in Algo-\nrithm 1, which replaces the k-step Markov chain pertur-\nbation in typical CD with a SVGD update.\nStein Score Matching\nWe should keep the step size ϵ\nsmall to make the derivation valid. If we explicitly take ϵ →\n0, then the minimax problem in (12) reduces to minimizing\nthe Stein discrepancy between the data distribution q0 and\nmodel pθ, that is,\nmin\nθ\nD2(q0 || pθ),\n(14)\nwhich is the result of Eq. (2) and (3). From this perspective,\nit is possible to take (14) and directly derive a gradient de-\nscent algorithm for minimizing the Stein discrepancy (14).\nFrom D2(q0 || p) = Eq0[Tpφ∗], we can derive that\n∇θD2(q0 || pθ) = 2Ex∼q0[∇θ∇xf(x; θ)φ∗(x)],\nwhere ∇θ∇xf(x; θ) is the (m×d)-valued cross derivative\nof log p(x|θ), where m and d are the dimensions of θ and\nx, respectively. This gives the following update:\nθ ←θ −µEq0[∇θ∇xf(x; θ)φ∗(x)].\n(15)\nWe call this update rule Stein score matching in connec-\ntion with the score matching algorithm (Hyv¨arinen, 2005)\nwhich minimizes Fisher divergence.\nIn practice, it can be cumbersome to calculate the cross\nderivative ∇θ∇xf(x; θ). It turns out the SteinCD update\n(13) can be viewed as approximating ∇θ∇xf(x; θ) in (15)\nwith a ﬁnite difference approximation:\n∇θ∇xf(x; θ)φ∗(x)\n≈−1\nϵ\n\u0002\n∇θf(x; θ) −∇θf(x + ϵφ∗(x); θ))\n\u0003\n.\n(16)\nPlugging the above approximation into (15) gives (13).\nAlternatively, it is also possible to use a symmetric ﬁnite\ndifference formula:\n∇θ∇xf(x; θ)φ∗(x)\n≈−1\n2ϵ((∇θf(x −ϵφ∗(x); θ) −∇θf(x + ϵφ∗(x); θ)).\nThis corresponds to\nθ ←θ + µ(Eq[−ϵφ∗][∇θf(x; θ)] −Eq[ϵφ∗][∇θf(x; θ)]),\n(17)\nwhich perturbs the data on both opposite directions and\nuses the difference to guild the update of θ.\nIn practice, we prefer the original update (13) because of\nits simplicity. Note that unlike SVGD, there is no cost in\nusing a small step size beyond the error caused by numeri-\ncal rounding, since we just need to obtain a correct moving\ndirection, do not need to actually move the particles (the\nobserved data) to pθ. Therefore, we can use a relatively\nsmall ϵ, in which case (13), (15) and (17) are all close to\neach other.\nIt is worth comparing Stein score matching (15) with the\n(Fisher) score matching (Hyv¨arinen, 2005), which esti-\nmates θ by minimizing the Fisher divergence:\nmin\nθ\n\b\nF(q0 || pθ)\ndef\n= Eq0[||∇x log q0 −∇x log pθ||2\n2]\n\t\n.\n(18)\nFisher divergence is a stronger divergence measure than\nStein discrepancy, which equals inﬁnite (like KL di-\nvergence) if q0 is an empirical delta measure, because\n∇x log q0 does not exist for delta measures. In contrast,\nStein discrepancy remains to be ﬁnite for empirical mea-\nsure q0 because it depends on q0 only through the empirical\naveraging Eq0[·].\nNevertheless, like the case of KL divergence, the inﬁnite\npart of Fisher divergence does not depend on θ, and it is still\npossible to minimize (18) as shown in Hyv¨arinen (2005),\nby using integration by parts. The main disadvantage of\nFisher score matching is that it has a relatively complex\nformula, and involves calculating a third order derivative\n∂3 log p(x|θ)/∂θ∂x2 that makes it difﬁcult to implement.\nIn contrast, SteinCD only involves calculating the ﬁrst or-\nder derivatives and is straightforward to implement.\n4\nAmortized MLE\nCD-type algorithms have been widely used for learning\nenergy-based models, and can often train models with good\ntest likelihood. However, models trained by CD can not\ngenerate realistic looking images (when pθ is used to model\nimage pixels). This is because CD learns the models based\non a local perturbation in the neighborhood of the observed\ndata, and does not explicitly train the model to create im-\nages from scratch. This problem has been addressed re-\ncently by generative adversarial networks (GAN) (Good-\nfellow et al., 2014; Radford et al., 2015), which explicitly\ntrain a generator, a deep neural network that takes random\nnoise and outputs images, to match the observed data with\nthe help of a discriminator that acts adversarially, to distin-\nguish the generated data from the observed ones. Motivated\nby GAN, we modify the MLE and CD idea to explicitly in-\ncorporate a generator into the training process.\nOur idea is based on “amortizing” the sampling process of\npθ with a generator and use the simulated samples as the\nnegative samples to update θ. To be speciﬁc, let G(ξ; η)\nbe a neural network that takes a random noise ξ as input\nand outputs a sample x, with a parameter η which we shall\nadjust adaptively to make the distribution of x = G(ξ; η)\napproximates the model pθ = p(x|θ), and we update θ by\nθ ←θ + µ(Ep0[∇f(x; θ)] −EGη[∇f(x; θ)]),\n(19)\nwhere EGη[·] denotes the average on random variable x =\nG(ξ; η). The key question here is how to update η so that\nthe distribution of x = G(ξ; η) closely approximates the\ntarget distribution pθ. This problem is addressed by a re-\ncent amortized SVGD algorithm (Wang & Liu, 2016), as\nwe introduce as follows.\nAmortized SVGD\nThe idea of amortized SVGD is to\nleverage the Stein variational gradient direction (2) to guid\nthe update of the generator G(ξ; η), in order to match its\noutput distribution with pθ. To be speciﬁc, at each itera-\ntion of amortized SVGD, we generate a batch of random\noutputs {xi} where xi = G(ξi; η), based on the current\nparameter η. The Stein variational gradient φ∗(xi) in (5)\nwould then ensure that x′\ni = xi + ϵφ∗(xi) forms a better\napproximation of the target distribution pθ. Therefore, we\nshould adjust η to make the output of the generator match\nthe updated points x′\ni. This can be done by updating η via\nη ←arg min\nη\nn\nX\ni=1\n||G(ξi; η) −xi −ϵφ∗(xi)||2\n2.\n(20)\nEssentially, this projects the non-parametric perturbation\ndirection φ∗(xi) to the change of the ﬁnite dimensional\nnetwork parameter η. Assume the step size ϵ is taken to\nbe small, so that a single step of gradient descent provides\na good approximation of Eq. (20). This gives a simpler\nupdate rule:\nη ←η + ϵ\nX\ni\n∂ηG(ξi; η)φ∗(xi),\n(21)\nwhich can be intuitively interpreted as a form of chain\nrule that back-propagates the SVGD gradient to the net-\nwork parameter η. In fact, when there is only one par-\nticle, (21) reduces to the standard gradient ascent for\nmaxη log pθ(G(ξ; η)), in which Gη is trained to “learn\nto optimize” (e.g., Andrychowicz et al., 2016), instead of\n“learn to sample” pθ. Importantly, as there are more than\none particles, the repulsive term ∇xk(x, xi) in φ∗(xi) be-\ncomes active, and enforces an amount of diversity on the\nnetwork output that is consistent with the variation in pθ.\nAmortized MLE\nUpdating θ and η alternatively with\n(19) and (20) or (21) allows us to simultaneously train an\nenergy model together with a generator (sampler). This ap-\nproach is presented as Algorithm 2. Compared with the\ntraditional methods based on MCMC-MLE or contrastive\ndivergence, we amortize the sampler as we train, which\nsaves computation in long term and simultaneously pro-\nvides a high quality generative neural network that can gen-\nerate realistic-looking images.\nFormally, our method can be viewed as approximately\nsolving the following minimax objective function based on\nKL divergence:\nmin\nθ\nmax\nη\n\b\nKL(q0 || pθ) −KL(q[Gη] || pθ)\n\t\n,\n(22)\nwhere q[Gη] denotes the distribution of the output of the\ngenerator x = G(ξ; η). Here the energy model pθ, serving\nas a discriminator, attempts to get closer to the observed\ndata q0, and keep away from the “fake” data distribution\nq[Gη], both in terms of KL divergence, while the genera-\ntor Gη attempts to get closer to the energy model pθ using\namortized SVGD. We call our method SteinGAN to reﬂect\nthis interpretation. It can be viewed as a KL-divergence\nvariant of the GAN-style adversarial game (Goodfellow\net al., 2014).\nAlgorithm 2 Amortized MLE (also called SteinGAN)\nGoal: Learn energy model (6) from data {xi}n\ni=1.\nwhile not converged do\n1. Draw minibatch {x+\ni }m\ni=1 from the training data.\n2. Draw {ξi}m\ni=1 from the noise prior. Calculate the\nnegative sample x−\ni = G(ξi; η), i = 1, . . . , m.\n3. Update the generator parameter η by\nη ←η + ϵ\nm\nm\nX\ni=1\n[∂ηG(ξi; η)φ∗(x−\ni )],\nwhere\nφ∗(·) = 1\nm\nm\nX\nj=1\n[∇x−\nj f(x−\nj ; θ)k(x−\nj , ·)+∇x−\nj k(x−\nj , ·)].\n4. Update the parameter θ\nθ ←θ + µ\nm\nm\nX\ni=1\n(∇θf(x+\ni ; θ) −∇θf(x−\ni ; θ)). (23)\nend while\nRelated Work\nThe idea of training energy models with\nneural samplers was also discussed by Kim & Bengio\n(2016); Zhai et al. (2016); one of the key differences is that\nthe neural samplers in Kim & Bengio (2016); Zhai et al.\n(2016) are trained with the help of heuristic diversity regu-\nlarizers, while SVGD enforces the diversity in a more prin-\ncipled way. Another method by Zhao et al. (2016) also\ntrains an energy function to distinguish real and simulated\nsamples, but within a non-probabilistic framework.\nGenerative adversarial network (GAN) and its variants\nhave recently gained remarkable success in generating\nrealistic-looking images (Goodfellow et al., 2014; Sali-\nmans et al., 2016; Radford et al., 2015; Li et al., 2015; Dz-\niugaite et al., 2015; Nowozin et al., 2016; Arjovsky et al.,\n2017, to name a few). All these methods are set up to train\nimplicit models speciﬁed by the generators, and are differ-\nent from the energy model assumption. The main motiva-\ntion of SteinGAN is to show the possibility of obtaining\ncomparable image generation results using energy-based\nlearning, allowing us to combine the advantages of these\ntwo types of approaches.\n5\nExperiments\nWe evaluated SteinCD and SteinGAN on four datasets,\nincluding MNIST, CIFAR-10, CelebA (Liu et al., 2015),\nand Large-scale Scene Understanding (LSUN) (Yu et al.,\n2015). We observe: 1) SteinCD tends to outperform typical\nCD equipped with Langevin dynamics; 2) SteinCD tends to\nprovide better test likelihood than SteinGAN, while Stein-\nGAN generates better images; 3) by interleaving SteinCD\nand SteinGAN updates, it is possible to combine advan-\ntages of both, obtaining both good testing likelihood and\nimages. We will provide code to reproduce our experi-\nments.\n5.1\nRestricted Boltzmann Machine on MNIST\nIn this section, we evaluate our methods on MNIST and\nuse a simple Gaussian-Bernoulli Restricted Boltzmann Ma-\nchines (RBM) as our energy-based model, which allows\nus to accurately evaluate the test likelihood.\nGaussian-\nBernoulli RBM is a hidden variable model of form\np(x, h) = 1\nZ exp(1\n2x⊤Bh + b⊤x + c⊤h −1\n2||x||2\n2),\nwhere x ∈Rd is a continuous observed variable and h ∈\n{±1}ℓis a binary hidden variable; Z is the normalization\nconstant. By marginalizing out the hidden variable h, we\nobtain p(x) = exp(f(x))/Z with negative energy\nf(x) = b⊤x −1\n2||x||2 + σ(B⊤x + c),\nwhere σ(h) = Pℓ\ni=1 log(exp(hi) + exp(−hi)). To eval-\nuate the test likelihood exactly, we use a small model with\nonly ℓ= 10 hidden units which allows us to calculate log Z\nusing exact variable elimination. We use mini-batches of\nsize 100 and Adam (Kingma & Ba, 2014) for our gradi-\nent updates. Following Liu & Wang (2016), we use a RBF\nkernel k(x, x′) = exp(−||x −x′||2\n2/h) in SVGD, with the\nbandwidth h selected to be med2/ log m (med is the me-\ndian of the pairwise distance of {xi} and m is the minibatch\nsize). For SteinGAN, the generator consists of 2 fully con-\nnected layers, followed by 2 deconvolution layers with 5×5\nﬁlters.\nFigure 1(a) shows the test likelihood of the CD-type meth-\nods, where we can ﬁnd that SteinCD (with a single step of\nSVGD) outperforms both CD-1 and CD-10 equipped with\nLangevin dynamics. We also evaluated the test likelihood\nof SteinGAN but ﬁnd it gives worse test likelihood (not\nshown in the ﬁgure). The advantage of SteinGAN, how-\never, is that it trains a generator G(ξ; η) that produces high\nquality and diverse images (Figure 1(c)), which SteinCD\ncan not generate (even when we train another generator\nG(ξ; η) on the energy model obtained by SteinCD, which\nhas better test likelihood).\nMixing SteinCD and SteinGAN\nIt seems that SteinCD\nand SteinGAN have opposite properties in terms of test\nlikelihood and image quality. This motivates us to inte-\ngrate SteinCD and SteinGAN to combine their advantages.\nIn order to do this, we replace the neural-simulated sam-\nple x = G(ξ; η) (step 4 in Algorithm 2) with the SVGD-\nupdated sample in SteinCD (step 2 of Algorithm 1) with a\nprobability α. We use SteinCD-GAN(α) to denote this al-\ngorithm, which reduces to SteinCD with α = 1 and Stein-\nGAN with α = 0.\ntest data log likelihood\n20\n22\n24\n26\n28\n-765\n-760\n-755\n-750\n-745\nCD-1\nCD-10\nSteinCD-1\ninception score\n0\n25\n50\n75\n100\n5.5\n6\n6.5\n7\n7.5\n-765\n-760\n-755\n-750\n-745\n-740\nInception Score\nTesting LL\ntest data log likelihood\n(a) Iterations (×10)\n(b) CD update ratio (100α%)\n(c)\nSteinGAN\n(d) SteinGAN w/o kernel\nFigure 1: Results of RBM on MNIST. (a) test data log likelihood of SteinCD and typical CD-1 and CD-10 with Langevin dynamics.\n(b) Inception score and test data log likelihood of SteinGAN-CD(α) with different α, which reduces to SteinGAN when α = 0 and\nSteinCD when α = 0. (c) Samples generated by SteinGAN; (d) Samples generated by SteinGAN when the kernel is turned off.\nThe performance of SteinCD-GAN(α) with different α-\nvalues is shown in Figure 1(b), where we ﬁnd that mix-\ning even a small percentage of CD-updates (e.g., ≤25%)\ncan signiﬁcantly improve the test likelihood, even slightly\nhigher than the pure SteinCD algorithm.\nWe also evaluate the inception score of the images gen-\nerated by SteinCD-GAN(α), using an inception model\ntrained on the MNIST training set (result averaged on\n50,000 generated images). As shown in Figure 1(b), we\nﬁnd that adding CD updates seems to deteriorate the im-\nage quality, but only slightly unless we use 100% CD up-\ndates (α = 1). Overall, Figure 1(b) suggests that by mix-\ning SteinGAN with a small percentage of CD updates (e.g.,\nα = 25%), we obtain results that perform well both in\nterms of test likelihood and image quality.\nEffect of the Repulsive Force\nAs it is discussed in Sec-\ntion 2.1, the repulsive term ∇xk(x, x′) in SVGD (5) en-\nforces the particles to be different from each other and pro-\nduces an amount of variability required for generating sam-\nples from p(x). In order to investigate the effect of the re-\npulsive term ∇xk(x, x′). We test a variant of SteinGAN\nin which the Stein variational gradient φ∗(x) is replaced\nby the typical gradient ∇x log p(x|θ) (or, effectively, use a\nconstant kernel k(x, x′) = 1 in φ∗(x)); this corresponds to\nan amortized variant of Viterbi learning (Koller & Fried-\nman, 2009), or Herding algorithm (Welling, 2009) that\nmaximizes Eq0[log p(x|θ)]−maxη Eξ[log p(G(ξ; η)|θ)], as\nthe learning objective function.\nAs shown in Figure 1(d), SteinGAN without the kernel\ntends to produce much less diverse images. This suggests\nthat the repulsive term is responsible for generating diverse\nimages in SteinGAN.\n5.2\nDeep Autoencoder-based SteinGAN\nIn order to obtain better results on realistic datasets, we test\na more complex energy model based on deep autoencoder:\np(x|θ) ∝exp(−||x −D(E(x; θ); θ)||),\n(24)\nwhere x denotes the image and E(·), D(·) is a pair of\nencoder/decoder function, indexed by parameter θ. This\nchoice is motivated by Energy-based GAN (Zhao et al.,\n2016) in which the autoencoder is used as a discrimina-\ntor but without a probabilistic interpretation. We assume\nG(ξ; η) to be a neural network whose input ξ is a 100-\ndimensional random vector drawn by Uniform([−1, 1]).\nLeveraging the latent representation of the autoencoder,\nwe ﬁnd it useful to deﬁne the kernel k(x, x′) on the en-\ncoder function, that is, k(x, x′) = exp(−1\nh2 ||E(x; θ) −\nE(x′; θ)||2). We take the bandwidth to be h = 0.5 ×\nmed/ log m, where med is the median of the pairwise dis-\ntances between E(x) on the image simulated by f(η; ξ).\nThis makes the kernel change adaptively based on both θ\n(through E(x; θ)) and η (through bandwidth h). Note that\nthe theory of SVGD does not put constraints on the choice\nof positive deﬁnite kernels, and it allows us to obtain better\nresults by changing the kernel adaptively during the algo-\nrithm.\nSome datasets include both images x and their associated\ndiscrete labels y. In these cases, we train a joint energy\nmodel on (x, y) to capture both the inner structure of the\nimages and its predictive relation with the label, which al-\nlows us to simulate images with a control on the category\nwhich it belongs to. Our joint energy model is deﬁned by\np(x, y|θ) ∝exp\n\b\n−||x −D(E(x; θ); θ)||\n−max[m, σ(y, E(x; θ))]\n\t\n,\n(25)\nwhere σ(·, ·) is the cross entropy loss function of a fully\nconnected output layer. In this case, our neural sampler\nﬁrst draws a label y randomly according to the empirical\ncounts in the dataset, and then passes y into a neural net-\nwork together with a 100 × 1 random vector ξ to generate\nimage x. This allows us to generate images for particular\ncategories by controlling the value of input y.\nWe compare our algorithm with DCGAN. We use the same\ngenerator architecture as DCGAN. To be fair, our energy\nmodel has comparable or less parameters than the discrim-\ninator in the DCGAN. The number of parameters used are\nsummarized in Table 1.\nairplane\nautomobile\nbird\ncat\ndeer\ndog\nfrog\nhorse\nship\ntruck\nDCGAN\nSteinGAN\nSteinGAN w/o kernel\nReal Training Set\n500 Duplicate\nDCGAN\nSteinGAN\nSteinGAN w/o kernel\nInception Score\n11.237\n11.100\n6.581\n6.711\n6.243\nTesting Accuracy\n92.58 %\n44.96 %\n44.78 %\n61.09 %\n60.50 %\nFigure 2: Results on CIFAR-10. “500 Duplicate” denotes 500 images randomly subsampled from the training set, each duplicated 100\ntimes. Upper: images simulated by DCGAN and SteinGAN (based on joint model (25)) conditional on each category; Lower: Inception\nscores for samples generated by various methods (all with 50,000 images) on inception models trained on ImageNet (Salimans et al.,\n2016), and testing accuracies on the real testing set when train ResNet classiﬁers (He et al., 2016) on 1) Real Training Set, 2) 100 copies\nof 500 examples taken at random from the real training set, 3) 50,000 samples from DCGAN, 4) 50,000 samples from SteinGAN, and\n5) 50,000 samples from SteingGAN w/o kernel, respectively. We set m = 1 in Eq.(25).\nStabilization\nIn practice, we ﬁnd it is useful to modify\n(23) in Algorithm 2 to be\nθ ←θ + µ\nm\nm\nX\ni=1\n(∇θf(x+\ni ; θ) −(1 −γ)∇θf(x−\ni ; θ)),\nwhere γ is a discount factor (which we take to be γ = 0.7).\nThis is equivalent to maximizing a regularized likelihood:\nmax\nθ {log p(x|θ) + γΦ(θ)}.\nwhere Φ(θ) = log Z(θ) is the log-partition function (see\n(6)); note that exp(γΦ(θ)) is a conjugate prior of p(x|θ).\nWe initialize the weights of both the generator and discrim-\ninator from Gaussian distribution N(0, 0.02), and train\nthem using Adam (Kingma & Ba, 2014) with a learning\nrate of 0.001 for the generator and 0.0005 for the energy\nmodel (the discriminator). To keep the generator and dis-\ncriminator approximately aligned during training, we speed\nup the θ-update (by increasing the discount factor to 0.9)\nwhen the energy of the real data batch is larger than the\nenergy of the simulated images. We used the architecture\nguidelines for stable training suggested in DCGAN (Rad-\nford et al., 2015).\nDiscussion\nCIFAR-10 includes diverse objects, but has\nonly 50,000 training examples. Figure 2 shows examples\nof simulated images by DCGAN and SteinGAN gener-\nated conditional on each category, which look equally well\nvisually.\nIt is still an open question on how to quanti-\ntively evaluate the quantities of simulated images. In order\nCifar10\nCelebA & LSUN\nDCGAN\n∼17m\n∼17m\nSteinGAN\n∼10m\n∼2.5m\nTable 1: Comparison of number of parameters used in discrimi-\nnator networks. We use the same generator network as DCGAN\nthrough out our experiments.\nto gain some understanding, here we report two different\nscores, including the inception score proposed by Salimans\net al. (2016), and the classiﬁcation accuracy when training\nResNet using 50, 000 simulated images as train sets, eval-\nuated on a separate held-out testing set never seen by the\nGAN models. Besides DCGAN and SteinGAN, we also\nevaluate another simple baseline obtained by subsampling\n500 real images from the training set and duplicating them\n100 times. We observe that these scores capture rather dif-\nferent perspectives of image generation: the inception score\nfavors images that look realistic individually and have uni-\nformly distributed labels; as a result, the inception score of\nthe duplicated 500 images is almost as high as the real train-\ning set. We ﬁnd that the inception score of SteinGAN is\ncomparable with DCGAN. On the other hand, the classiﬁ-\ncation accuracy measures the amount information (in terms\nof classiﬁcation using ResNet) captured in the simulated\nimage sets; we ﬁnd that SteinGAN achieves higher clas-\nsiﬁcation accuracy, suggesting that it captures, at least in\nsome perspective, more information in the training set.\nFigure 3 and 4 visualize the results on CelebA (with more\nthan 200k face images) and LSUN (with nearly 3M bed-\nroom images), respectively. We cropped and resized both\nDCGAN\nSteinGAN\nFigure 3: Results on CelebA. Upper: images generated by DCGAN and our SteinGAN. Lower: images generated by SteinGAN when\nperforming a random walk ξ ←ξ + 0.01 × Uniform([−1, 1]) on the random input ξ; we can see that a man with glasses and black hair\ngradually changes to a woman with blonde hair.\nDCGAN\nSteinGAN\nFigure 4: Images generated by DCGAN and our SteinGAN on LSUN.\ndataset images into 64 × 64.\n6\nConclusion\nWe propose a number of new algorithms for learning deep\nenergy models, and demonstrate their properties. We show\nthat our SteinCD performs well in term of test likelihood,\nwhile SteinGAN performs well in terms of generating real-\nistic looking images. Our results suggest promising direc-\ntions for learning better models by combining GAN-style\nmethods with traditional energy-based learning.\nReferences\nAndrychowicz, Marcin, Denil, Misha, Gomez, Sergio,\nHoffman, Matthew W, Pfau, David, Schaul, Tom, and\nde Freitas, Nando. Learning to learn by gradient descent\nby gradient descent. arXiv preprint arXiv:1606.04474,\n2016.\nArjovsky, Martin, Chintala, Soumith, and Bottou, L´eon.\nWasserstein gan.\narXiv preprint arXiv:1701.07875,\n2017.\nCarreira-Perpinan, Miguel A and Hinton, Geoffrey E. On\ncontrastive divergence learning. In AISTATS, volume 10,\npp. 33–40. Citeseer, 2005.\nCover, Thomas M and Thomas, Joy A. Elements of infor-\nmation theory. John Wiley & Sons, 2012.\nDziugaite, Gintare Karolina, Roy, Daniel M., and Ghahra-\nmani, Zoubin.\nTraining generative neural networks\nvia maximum mean discrepancy optimization. In Con-\nference on Uncertainty in Artiﬁcial Intelligence (UAI),\n2015.\nGeyer, Charles J.\nMarkov chain monte carlo maximum\nlikelihood. 1991.\nGoodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu,\nBing, Warde-Farley, David, Ozair, Sherjil, Courville,\nAaron, and Bengio, Yoshua. Generative adversarial nets.\nIn Advances in Neural Information Processing Systems,\npp. 2672–2680, 2014.\nGoodfellow, Ian, Bengio, Yoshua, and Courville, Aaron.\nDeep learning. MIT Press, 2016.\nHe, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun,\nJian. Deep residual learning for image recognition. In\nProceedings of the IEEE Conference on Computer Vi-\nsion and Pattern Recognition, pp. 770–778, 2016.\nHinton, Geoffrey E. Training products of experts by min-\nimizing contrastive divergence. Neural computation, 14\n(8):1771–1800, 2002.\nHinton, Geoffrey E and Salakhutdinov, Ruslan R. Reduc-\ning the dimensionality of data with neural networks. sci-\nence, 313(5786):504–507, 2006.\nHyv¨arinen, Aapo. Estimation of non-normalized statisti-\ncal models by score matching. In Journal of Machine\nLearning Research, pp. 695–709, 2005.\nKim, Taesup and Bengio, Yoshua. Deep directed generative\nmodels with energy-based probability estimation. arXiv\npreprint arXiv:1606.03439, 2016.\nKingma,\nDiederik\nand\nBa,\nJimmy.\nAdam:\nA\nmethod for stochastic optimization.\narXiv preprint\narXiv:1412.6980, 2014.\nKoller, Daphne and Friedman, Nir. Probabilistic graphical\nmodels: principles and techniques. MIT press, 2009.\nLeCun, Yann, Chopra, Sumit, Hadsell, Raia, Ranzato, M,\nand Huang, F. A tutorial on energy-based learning. Pre-\ndicting structured data, 1:0, 2006.\nLi, Yujia, Swersky, Kevin, and Zemel, Richard. Generative\nmoment matching networks.\nIn International Confer-\nence on Machine Learning, pp. 1718–1727, 2015.\nLiu, Qiang and Wang, Dilin. Stein variational gradient de-\nscent: A general purpose bayesian inference algorithm.\nIn Advances In Neural Information Processing Systems,\npp. 2370–2378, 2016.\nLiu, Qiang, Lee, Jason D, and Jordan, Michael I. A ker-\nnelized Stein discrepancy for goodness-of-ﬁt tests. In\nProceedings of the International Conference on Machine\nLearning (ICML), 2016.\nLiu, Ziwei, Luo, Ping, Wang, Xiaogang, and Tang, Xiaoou.\nDeep learning face attributes in the wild. In Proceedings\nof International Conference on Computer Vision (ICCV),\n2015.\nNgiam, Jiquan, Chen, Zhenghao, Koh, Pang W, and Ng,\nAndrew Y. Learning deep energy models. In Proceed-\nings of the 28th International Conference on Machine\nLearning (ICML-11), pp. 1105–1112, 2011.\nNowozin, Sebastian, Cseke, Botond, and Tomioka, Ry-\nota.\nf-gan: Training generative neural samplers us-\ning variational divergence minimization. arXiv preprint\narXiv:1606.00709, 2016.\nRadford, Alec, Metz, Luke, and Chintala, Soumith. Un-\nsupervised representation learning with deep convolu-\ntional generative adversarial networks. arXiv preprint\narXiv:1511.06434, 2015.\nSalimans, Tim, Goodfellow, Ian, Zaremba, Wojciech, Che-\nung, Vicki, Radford, Alec, and Chen, Xi. Improved tech-\nniques for training gans. In Advances in Neural Informa-\ntion Processing Systems, pp. 2226–2234, 2016.\nScholkopf, Bernhard and Smola, Alexander J. Learning\nwith kernels: support vector machines, regularization,\noptimization, and beyond. MIT press, 2001.\nSnijders, Tom AB. Markov chain monte carlo estimation\nof exponential random graph models. Journal of Social\nStructure, 3(2):1–40, 2002.\nWang, Dilin and Liu, Qiang. Learning to draw samples:\nWith application to amortized mle for generative adver-\nsarial learning. arXiv preprint arXiv:1611.01722, 2016.\nWelling, Max. Herding dynamical weights to learn. In Pro-\nceedings of the 26th Annual International Conference on\nMachine Learning, pp. 1121–1128. ACM, 2009.\nXie, Jianwen, Lu, Yang, Zhu, Song-Chun, and Wu,\nYing Nian.\nA theory of generative convnet.\narXiv\npreprint arXiv:1602.03264, 2016.\nYu, Fisher, Seff, Ari, Zhang, Yinda, Song, Shuran,\nFunkhouser, Thomas, and Xiao, Jianxiong.\nLsun:\nConstruction of a large-scale image dataset using deep\nlearning with humans in the loop.\narXiv preprint\narXiv:1506.03365, 2015.\nZhai, Shuangfei, Cheng, Yu, Feris, Rogerio, and Zhang,\nZhongfei.\nGenerative adversarial networks as varia-\ntional training of energy based models. arXiv preprint\narXiv:1611.01799, 2016.\nZhao, Junbo, Mathieu, Michael, and LeCun, Yann. Energy-\nbased generative adversarial network.\narXiv preprint\narXiv:1609.03126, 2016.\n",
  "categories": [
    "stat.ML",
    "cs.LG"
  ],
  "published": "2017-07-04",
  "updated": "2017-07-04"
}