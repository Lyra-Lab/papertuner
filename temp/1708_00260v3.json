{
  "id": "http://arxiv.org/abs/1708.00260v3",
  "title": "Deep Asymmetric Multi-task Feature Learning",
  "authors": [
    "Hae Beom Lee",
    "Eunho Yang",
    "Sung Ju Hwang"
  ],
  "abstract": "We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can\nlearn deep representations shared across multiple tasks while effectively\npreventing negative transfer that may happen in the feature sharing process.\nSpecifically, we introduce an asymmetric autoencoder term that allows reliable\npredictors for the easy tasks to have high contribution to the feature learning\nwhile suppressing the influences of unreliable predictors for more difficult\ntasks. This allows the learning of less noisy representations, and enables\nunreliable predictors to exploit knowledge from the reliable predictors via the\nshared latent features. Such asymmetric knowledge transfer through shared\nfeatures is also more scalable and efficient than inter-task asymmetric\ntransfer. We validate our Deep-AMTFL model on multiple benchmark datasets for\nmultitask learning and image classification, on which it significantly\noutperforms existing symmetric and asymmetric multitask learning models, by\neffectively preventing negative transfer in deep feature learning.",
  "text": "Deep Asymmetric Multi-task Feature Learning\nHae Beom Lee 1 2 Eunho Yang 3 2 Sung Ju Hwang 3 2\nAbstract\nWe propose Deep Asymmetric Multitask Feature\nLearning (Deep-AMTFL) which can learn deep\nrepresentations shared across multiple tasks while\neffectively preventing negative transfer that may\nhappen in the feature sharing process. Speciﬁ-\ncally, we introduce an asymmetric autoencoder\nterm that allows reliable predictors for the easy\ntasks to have high contribution to the feature learn-\ning while suppressing the inﬂuences of unreliable\npredictors for more difﬁcult tasks. This allows\nthe learning of less noisy representations, and\nenables unreliable predictors to exploit knowl-\nedge from the reliable predictors via the shared\nlatent features. Such asymmetric knowledge trans-\nfer through shared features is also more scalable\nand efﬁcient than inter-task asymmetric transfer.\nWe validate our Deep-AMTFL model on multi-\nple benchmark datasets for multitask learning and\nimage classiﬁcation, on which it signiﬁcantly out-\nperforms existing symmetric and asymmetric mul-\ntitask learning models, by effectively preventing\nnegative transfer in deep feature learning.\n1. Introduction\nMulti-task learning (Caruana, 1997) aims to improve the\ngeneralization performance of the multiple task predictors\nby jointly training them, while allowing some kinds of\nknowledge transfer between them. One of the crucial chal-\nlenges in multi-task learning is tackling the problem of\nnegative transfer, which describes the situation where ac-\ncurate predictors for easier tasks are negatively affected\nby inaccurate predictors for more difﬁcult tasks. A re-\ncently introduced method, Asymmetric Multi-task Learning\n(AMTL) (Lee et al., 2016), proposes to solve this nega-\n*Equal contribution\n1UNIST, Ulsan, South Korea 2AItrics,\nSeoul, South Korea\n3KAIST, Daejeon, South Korea.\nCor-\nrespondence\nto:\nHae\nBeom\nLee\n<hblee@unist.ac.kr>,\nEunho Yang <eunhoy@kaist.ac.kr>, Sung Ju Hwang <sjh-\nwang82@kaist.ac.kr>.\nProceedings of the 35 th International Conference on Machine\nLearning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018\nby the author(s).\ntive transfer problem by allowing asymmetric knowledge\ntransfer between tasks through inter-task parameter regular-\nization. Speciﬁcally, AMTL enforces the task parameters\nfor each task to be also represented as a sparse combination\nof the parameters for other tasks, which results in learn-\ning a directed graph that decides the amount of knowledge\ntransfer between tasks.\nHowever, such inter-task transfer model based on param-\neter regularization is limited in several aspects. First of\nall, in most cases, the tasks exhibit relatedness to certain\ndegree, but the model parameter for a task might not be\nreconstructed as a combination of the parameter for other\ntasks, because the tasks are only partly related. Consider the\nexample in Fig. 1(b), where the task is to predict whether\nthe given image has any of the three animal classes. Here,\nthe three animal classes are obviously related as they share\na common visual attribute, stripe. Yet, we will not be able\nto reconstruct the model parameter for class hyena by com-\nbining the model parameters for class tiger and zebra, as\nthere are other important attributes that deﬁne the hyena\nclass, and the stripe is merely a single attribute among them\nthat is also shared by other classes. Thus, it is more nat-\nural to presume that the related tasks leverage a common\nset of latent representations, rather than considering that a\ntask parameter is generated from the parameters for a set of\nrelevant tasks, as assume in inter-task transfer models.\nMoreover, AMTL does not scale well with the increasing\nnumber of tasks since the inter-task knowledge transfer\ngraph grows quadratically, and thus will become both inefﬁ-\ncient and prone to overﬁtting when there are large number\nof tasks, such as in large-scale classiﬁcation. While sparsity\ncan help reduce the number of parameters, it does not reduce\nthe intrinsic complexity of the problem.\nFinally, the inter-task transfer models only store the knowl-\nedge in the means of learned model parameters and their\nrelationship graph. However, at times, it might be beneﬁcial\nto store what has been learned, in the form of explicit repre-\nsentations which can be used later for other tasks, such as\ntransfer learning.\nThus, we resort to the multi-task feature learning approach\nthat aims to learn latent features, which is one of the most\npopular ways of sharing knowledge between tasks in the\nmulti-task learning framework (Argyriou et al., 2008; Ku-\narXiv:1708.00260v3  [cs.LG]  30 Jun 2018\nDeep Asymmetric Multi-task Feature Learning\n(a) Symmetric Feature Sharing MTL\n(b) Asymmetric MTL\n(c) Asymmetric Multi-task Feature Learning\nFigure 1. Concept. (a) Feature-sharing multi-task learning models such as Go-MTL suffers from negative transfer from unreliable\npredictors, which can result in learning noisy representations. (b) AMTL, an inter-task transfer asymmetric multi-task learning model that\nenforces the parameter of each task predictor to be generated as a linear combination of the parameters of relevant task predictors, may\nnot make sense when the tasks are only partially related. (c) Our asymmetric multi-task feature learning enforces the learning of shared\nrepresentations to be affected only by reliable predictors, and thus the learned features can transfer knowledge to unreliable predictors.\nmar & Daume III, 2012), and aim to prevent negative trans-\nfer under this scenario by enforcing asymmetric knowledge\ntransfer. Speciﬁcally, we allow reliable task predictors to\naffect the learning of the shared features more, while down-\nweighting the inﬂuences of unreliable task predictors, such\nthat they have less or no contributions to the feature learning.\nFigure 1 illustrates the concept of our model, which we refer\nto as asymmetric multi-task feature learning (AMTFL).\nAnother important advantage of our AMTFL, is that it natu-\nrally extends to the feature learning in deep neural networks,\nin which case the top layer of the network contains addi-\ntional weight matrix for feed-back connection, along with\nthe original feed-forward connections, that allows asymmet-\nric transfer from each task predictor to the bottom layer.\nThis allows our model to leverage state-of-the-art deep neu-\nral network models to beneﬁt from recent advancement in\ndeep learning.\nWe extensively validate our method on a synthetic dataset\nas well as eight benchmark datasets for multi-task learning\nand image classiﬁcation using both the shallow and the deep\nneural network models, on which our models obtain supe-\nrior performances over existing symmetric feature-sharing\nmulti-task learning model as well as the inter-task parameter\nregularization based asymmetric multi-task learning model.\nOur contributions are threefold:\n• We propose a novel multi-task learning model that pre-\nvents negative transfer by allowing asymmetric transfer\nbetween tasks, through latent shared features, which is\nmore natural when tasks are correlated but not cause\nand effect relationships, and is more scalable than ex-\nisting inter-task knowledge transfer model.\n• We extend our asymmetric multi-task learning model\nto deep learning setting, where our model obtains even\nlarger performance improvements over the base net-\nwork and linear multi-task models.\n• We leverage learned deep features for knowledge trans-\nfer in a transfer learning scenarios, which demonstrates\nthat our model learns more useful features than the base\ndeep networks.\n2. Related Work\nMultitask learning\nMulti-task Learning (Caruana, 1997)\nis a learning framework that jointly trains a set of task pre-\ndictors while sharing knowledge among them, by exploiting\nrelatedness between participating tasks. Such task related-\nness is the main idea on which multi-task learning is based,\nand there are several assumptions on how the tasks are re-\nlated. Probably the most common assumption is that the\ntask parameters lie in a low-dimensional subspace. One\nexample of a model based on this assumption is multi-task\nfeature learning (MTFL) (Argyriou et al., 2008), where a set\nof related tasks learns common features (or representations)\nshared across multiple tasks. Speciﬁcally, they propose to\ndiscard features that are not used by most tasks by impos-\ning the (2, 1)-norm regularization on the coefﬁcient matrix,\nand solved the regularized objective with an equivalent con-\nvex optimization problem. The assumption in MTFL is\nrather strict, in that the (2, 1)-norm requires the features to\nbe shared across all tasks, regardless of whether the tasks\nare related or not. To overcome this shortcoming, (Kang\net al., 2011) suggest a method that also learns to group tasks\nbased on their relatedness, and enforces sharing only within\neach group. However, since such strict grouping might\nnot exist between real-world tasks, (Kumar & Daume III,\n2012) and (Maurer et al., 2012) suggest to learn overlapping\ngroups by learning latent parameter bases that are shared\nDeep Asymmetric Multi-task Feature Learning\nacross multiple tasks. Multi-task learning on neural net-\nworks is fairly straightforward simply by sharing a single\nnetwork for all tasks. Recently, there has been some effort\non ﬁnding more meaningful sharing structures between tasks\ninstead of sharing between all tasks (Yang & Hospedales,\n2016; 2017; Ruder et al., 2017). Yet, while these models\nconsider task relatedness, they do not consider asymmetry\nin knowledge transfer direction between the related tasks.\nAsymmetric Multitask learning\nThe main limitation in\nthe multi-task learning models based on common bases\nassumption is that they cannot prevent negative transfer as\nshared bases are trained without consideration of the quality\nof the predictors. To tackle the problem, asymmetric multi-\ntask learning (AMTL) (Lee et al., 2016) suggests to break\nthe symmetry in the knowledge transfer direction between\ntasks. It assumes that each task parameter can be represented\nas a sparse linear combination of other task parameters, in\nwhich the knowledge ﬂows from task predictors with low\nloss to predictors with high loss. Then, hard tasks could\nexploit more reliable information from easy tasks, whereas\neasy tasks do not have to rely on hard tasks when it has\nenough amount of information to be accurately predicted.\nThis helps prevent performance degradation on easier tasks\nfrom negative transfer. However, in AMTL, knowledge\nis transferred from one task to another, rather than from\ntasks to some common feature spaces. Thus the model\nis not scalable and also it is not straightforward to apply\nthis model to deep learning. On the contrary, our model\nis scalable and straightforward to implement into a deep\nnetwork as it learns to transfer from tasks to shared features.\nAutoencoders\nOur asymmetric multi-task learning formu-\nlation has a sparse nonlinear autoencoder term for feature\nlearning. The speciﬁc role of the term is to reconstruct\nlatent features from the model parameters using sparse non-\nlinear feedback connections, which results in the denoising\nof the latent features. Autoencoders were ﬁrst introduced\nin (Rumelhart et al., 1986) for unsupervised learning, where\nthe model is given the input features as the output and learns\nto transform the input features into a latent space and then\ndecode them back to the original features. While there exist\nvarious autoencoder models, our reconstruction term closely\nresembles the sparse autoencoder (Ranzato et al., 2007),\nwhere the transformation onto and from the latent feature\nspace is sparse. (Hinton & Salakhutdinov, 2006) introduce\na deep autoencoder architecture in the form of restricted\nBoltzmann machine, along with an efﬁcient learning algo-\nrithm that trains each layer in a bottom-up fashion. (Vincent\net al., 2008) propose a denoising autoencoder, which is\ntrained with the corrupted data as the input and the clean\ndata as output, to make the internal representations to be\nrobust from corruption. Our regularizer in some sense can\nbe also considered as a denoising autoencoder, since its goal\nis to reﬁne the features through the autoencoder form such\nthat the reconstructed latent features reﬂect the loss of more\nreliable predictors, thus obtaining cleaner representations.\n3. Asymmetric Multi-task Feature Learning\nIn our multi-task learning setting, we have T different\ntasks with varying degree of difﬁculties. For each task\nt ∈{1, . . . , T}, we have an associated training dataset\nDt = {(Xt, yt)|Xt ∈RNt×d, yt ∈RNt×1} where Xt\nand yt respectively represent the d-dimensional feature vec-\ntor and the corresponding labels for Nt data instances. The\ngoal of multi-task learning is then to jointly train models\nfor all T tasks simultaneously via the following generic\nlearning objective:\nmin.\nW\nT\nX\nt=1\nL(wt; Xt, yt) + Ω(W ).\n(1)\nwhere L is the loss function applied across the tasks, wt ∈\nRd is the model parameter for task t and W ∈Rd×T is the\ncolumn-wise concatenated matrix of w deﬁned as W =\n[w1 w2 · · · wT ]. Here, the penalty Ωenforces certain prior\nassumption on sharing properties across tasks in terms of\nW .\nOne of the popular assumptions is that there exists a com-\nmon set of latent bases across tasks (Argyriou et al., 2008;\nKumar & Daume III, 2012), in which case the matrix W\ncan be decomposed as W = LS. Here, L ∈Rd×k is the\ncollection of k latent bases while S ∈Rk×T is the coefﬁ-\ncient matrix for linearly combining those bases. Then, with\na regularization term depending on L and S, we build the\nfollowing multi-task learning formulation:\nmin.\nL,S\nT\nX\nt=1\nL(Lst; Xt, yt) + Ω(L, S).\n(2)\nwhere st is tth column of S to represent wt as the linear\ncombination of shared latent bases L, that is, wt = Lst.\nAs a special case of (2), Go-MTL(Kumar & Daume III,\n2012), for example, encourages L to be element-wisely ℓ2\nregularized and each st sparse:\nmin.\nL,S\nT\nX\nt=1\nn\nL(Lst; Xt, yt) + µ ∥st∥1\no\n+ λ ∥L∥2\nF . (3)\nOn the other hand, it is possible to exploit a task related-\nness without the explicit assumption on shared latent bases.\nAMTL (Lee et al., 2016) is such an instance of multi-task\nlearning, based on the assumption that each task parameter\nwt ∈Rd is reconstructed as a sparse combination of other\ntask parameters {ws}s̸=t. In other words, it encourages that\nwt ≈P\ns̸=t Bstws where the weight Bst of ws in recon-\nstructing wt, can be interpreted as the amount of knowledge\nDeep Asymmetric Multi-task Feature Learning\n(a)\n(b)\n(c)\n(d)\nFigure 2. (a) An illustration of negative transfer in common latent bases model. (b) The effects of inter-task ℓ2 regularization on top of\ncommon latent bases model. (c) Asymmetric task-to-basis transfer. (d) An illustration of ReLU transformation with a bias term.\ntransfer from task s to t. Since there is no symmetry con-\nstraint on the matrix B, AMTL learns asymmetric knowl-\nedge transfer from easier tasks to harder ones. Towards this\ngoal, AMTL solves the multi-task learning problem via the\nfollowing optimization problem:\nmin.\nW ,B\nT\nX\nt=1\n(1 + α ∥bo\nt∥1)L(wt; Xt, yt) + γ ∥W −W B∥2\nF .\n(4)\nwhere Btt = 0 for t = 1, ..., T and B’s row vector bo\nt ∈\nR1×T controls the amount of outgoing transfer from task t\nto other tasks s ̸= t. The sparsity parameter α is multiplied\nby the amount of training loss L(wt; Xt, yt), making the\noutgoing transfer from hard tasks more sparse than those\nof easy tasks. The second Frobenius norm based penalty is\non the inter-task regularization term for reconstructing each\ntask parameter wt.\n3.1. Asymmetric Transfer from Task to Bases\nOne critical drawback of (3) is on the severe negative trans-\nfer from unreliable models to reliable ones since all task\nmodels equally contribute to the construction of latent bases.\nOn the other hand, (4) is not scalable to large number of\ntasks, and does not learn explicit features. In this section,\nwe provide a novel framework for asymmetric multi-task\nfeature learning that overcomes the limitations of these two\nprevious approaches, and ﬁnd an effective way to achieve\nasymmetric knowledge transfer in deep neural networks\nwhile preventing negative transfers.\nWe start our discussion with the observation of how negative\ntransfer occurs in a common latent bases multi-task learning\nmodels as in (3). Suppose that we train a multi-task learning\nmodel for three tasks, where the model parameters of each\ntask is generated from the bases {l1, l2, l3}. Speciﬁcally,\nw1 is generated from {l1, l3}, w2 from {l1, l2}, and w3\nfrom {l2, l3}. Further, we assume that the predictor for task\n3 is unreliable and noisy, while the predictors for task 1\nand 2 are reliable, as illustrated in Figure 2(a). In such a\ncase, when we train the task predictors in a multi-task learn-\ning framework, w3 will transfer noise to the shared bases\n{l2, l3}, which will in turn negatively affect the models\nparameterized by w1 and w2.\nOne might consider the naive combination of the shared\nbasis model (3) and AMTL (4) to prevent negative transfer\namong latent features where the task parameter matrix is\ndecomposed into LS in (4):\nmin.\nL,S,B\nT\nX\nt=1\nn\n(1 + α ∥bo\nt∥1)L(Lst; Xt, yt) + µ ∥st∥1\no\n+ γ ∥LS −LSB∥2\nF + λ ∥L∥2\nF\n(5)\nwhere Btt = 0 for t = 1, .., T. However, this simple\ncombination cannot resolve the issue mainly due to two\nlimitations. First, the inter-task transfer matrix B still grows\nquadratically with respect to T as in AMTL, which is not\nscalable for large T. Second and more importantly, this\napproach would induce additional negative transfer. In the\nprevious example in Figure 2(b), the unreliable model w3 is\nenforced to be a linear combination of other reliable models\nvia the matrix B (the purple dashed lines in the ﬁgure). In\nother words, w3 can now affect the clean basis l1 that is\nonly trained by the reliable models in Figure 2(a). As a\nresult, the noise will be transferred to l1, and consequently,\nto the reliable models based on it. As shown in this simple\nexample, the introduction of inter-task asymmetric transfer\nin the shared basis MTL (3) leads to more severe negative\ntransfer, which is in contrast to the original intention.\nTo resolve this issue, we propose a completely new type\nof regularization in order to prevent the negative transfer\nfrom the task predictors to the shared latent features, which\nwe refer to as asymmetric task-to-basis transfer. Speciﬁ-\ncally, we encourage the latent features to be reconstructed\nby the task predictors’ parameters in an asymmetric man-\nner, where we enforce the reconstruction to be done by\nthe parameters of reliable predictors only, as shown in Fig-\nure 2(c). Since the parameters for the task predictors are\nreconstructed from the bases, this regularization can be con-\nsidered as an autoencoder framework. The difference here\nDeep Asymmetric Multi-task Feature Learning\nFigure 3. Deep-AMTFL. The green lines denote feedback connec-\ntions with ℓ2 constraints on the features. Different color scales\ndenote different amount of reliabilities (blue) and knowledge trans-\nfers from task predictions to features (green).\nis that the consideration of predictor loss result in learning\ndenoising of the representations. We describe the details of\nour asymmetric framework of task-to-basis transferring in\nthe following subsection.\n3.2. Feature Reconstruction with Nonlinearity\nThere are two main desiderata in our construction of asym-\nmetric feature learning framework. First, the reconstruction\nshould be achieved in a non-linear manner. Suppose that\nwe perform linear reconstruction of the bases as shown in\nFigure 2(c). In this case, the linear span of {w1, w2} does\nnot cover any of {l1, l2, l3}. Thus we need a nonlinearity to\nsolve the problem. Second, the reconstruction needs to be\ndone in the feature space, not on the bases of the parameters,\nin order to directly apply it to a deep learning framework.\nWe ﬁrst deﬁne notations before introducing our framework.\nLet X be the row-wise concatenation of {X1, .., XT }. We\nassume a neural network with a single hidden layer, where\nL and S are the parameters for the ﬁrst and the second\nlayer respectively. As for the nonlinearity in the hidden\nlayer, we use rectiﬁed linear unit (ReLU), denoted as σ(·).\nThe nonnegative feature matrix is denoted as Z = σ(XL),\nor zi = σ(Xli) for each column i = 1, .., k. The task-\nto-feature transfer matrix is A ∈RT ×k. Using the above\nnotations, our asymmetric multi-task feature learning frame-\nwork is deﬁned as follows:\nmin.\nL,S,A\nT\nX\nt=1\nn\n(1 + α||ao\nt||1) L(L, st; Xt, yt) + µ ∥st∥1\no\n+ γ∥Z −σ(ZSA)∥2\nF + λ ∥L∥2\nF .\n(6)\nThe goal of the autoencoder term is to reconstruct features Z\nwith model outputs ZS with the nonlinear transformation\nσ(·; A).\nWe also use ReLU nonlinearity for the reconstruction term\nas in the original network, since this will allow the recon-\nstruction bZ to explore the same manifold of Z, thus making\nit easier to ﬁnd an accurate reconstruction. In Fig.2(d), for\nexample, the linear span of task output vectors {y1, y2}\nforms the blue hyperplane. Transforming this hyperplane\nwith ReLU and a bias term will result in the manifold col-\nored as gray and yellow, which includes the original feature\nvectors {z1, z2, z3}.\nSince our framework considers the asymmetric transfer\nin the feature space, we can seamlessly generalize (6) to\ndeep networks with multiple layers. Speciﬁcally, the auto-\nencoding regularization term is formulated at the penulti-\nmate layer to achieve the asymmetric transfer. We name this\napproach Deep-AMTFL:\nmin.\nA,{W (l)}L\nl=1\nT\nX\nt=1\nn\n(1 + α||ao\nt||1) Lt + µ\n\r\r\rw(L)\nt\n\r\r\r\n1\no\n+ γ\n\r\r\rσ\n\u0000ZW (L)A\n\u0001\n−Z\n\r\r\r\n2\nF + λ\nL−1\nX\nl=1\n\r\r\rW (l)\r\r\r\n2\nF ,\n(7)\nwhere W (l) is the weight matrix for the lth layer, with w(L)\nt\ndenoting the tth column vector of W (L), and\nZ = σ(W (L−1)σ(W (L−2) . . . σ(XW (1))))\nLt := L(w(L)\nt\n, W (L−1), .., W (1); Xt, yt),\nare the hidden representations at layer L −1 and the loss\nfor each task t. See Figure (3) for the description.\nLoss functions\nThe loss function L(w; X, y) could be\nany generic loss function. We mainly consider the two\nmost popular instances.\nFor regression tasks, we use\nthe squared loss: L(wt; Xt, yt) =\n1\nNt ∥yt −Xtwt∥2\n2 +\nδ/√Nt.\nFor classiﬁcation tasks, we use the logistic\nloss: L(wt; Xt, yt) =\n1\nNt\nPNt\ni=1{yti log σ(xtiwt) + (1 −\nyti) log (1 −σ(xtiwt))}+δ/√Nt, where σ is the sigmoid\nfunction. Note that we augment the loss terms with δ/√Nt\nto express the imbalance for the training instances for each\ntask. As for δ, we roughly tune δ/√Nt to have similar scale\nto the ﬁrst term of L(wt; Xt, yt).\n4. Experiments\nWe validate AMTFL on both synthetic and real datasets\nagainst relevant baselines, using both shallow and deep\nneural networks as base models.\n4.1. Shallow models - Feedforward Networks\nWe ﬁrst validate our shallow AMTFL model (6) on synthetic\nand real datasets with shallow neural networks. Note that\nwe use one-vs-all logistic loss for multi-class classiﬁcation.\nBaselines and our models\n1) STL. A linear single-task learning model.\n2) GO-MTL. A feature-sharing MTL model from (Kumar\n& Daume III, 2012), where different task predictors share a\ncommon set of latent bases (3).\nDeep Asymmetric Multi-task Feature Learning\n(a) true L\n(b) true LS\n(c) W ′′\n(d) L′\n(e) (LS)′\n(f) L\n(g) LS\n(h) AS\nFigure 4. Visualization of the learned features and paramters on the synthetic dataset. (a-b) True parameters that generated the data.\n(c) Reconstructed parameters from AMTL (d-e) Reconstructed parameters from Go-MTL. (f-h) Reconstructed parameters from AMTFL.\n3) AMTL. Asymmetric multi-task learning model (Lee\net al., 2016), with inter-task knowledge transfer through\na parameter-based regularization (4).\n4) NN. A simple feedforward neural network with a single\nhidden layer.\n5) MT-NN. Same as NN, but with each task loss divided by\nNt, for balancing the task loss. Note that this model applies\nℓ1-regularization at the last fully connected layer.\n6) AMTFL. Our asymmetric multi-task feature learning\nmodel with feedback connections (6).\nSynthetic dataset experiment\nWe ﬁrst check the validity\nof AMTFL on a synthetic dataset. We ﬁrst generate six\n30-dimensional true bases in Figure 4(a). Then, we generate\nparameters for 12 tasks from them with noise ϵ ∼N(0, σ).\nWe vary σ to create two groups based on the noise level:\neasy and hard. Easy tasks have noise level of σ = 1 and\nhard tasks have σ = 2. Each predictor for easy task wt\ncombinatorially picks two out of four bases - {l1, .., l4}\nto linearly combine wt ∈R30, while each predictor for\nhard task selects among {l3, .., l6}. Thus the bases {l3, l4}\noverlap both easy and hard tasks, while other bases are used\nexclusive by each group in Figure 4(b). We generate ﬁve\nrandom train/val/test splits for each group - 50/50/100 for\neasy tasks and 25/25/100 for hard tasks.\nFor this dataset, we implement all base models as neural\nnetworks to better compare with AMTFL. We add in ℓ1 to\nL for all models for better reconstruction of L. We remove\nReLU at the hidden layer in AMTFL since the features are\nlinear1. All the hyper-parameters are found with separate\nvalidation set. For AMTL, we remove the nonnegative\nconstraint on B due to the characteristic of this dataset.\nWe ﬁrst check whether AMTFL can accurately reconstruct\nthe true bases in Figure 4(a). We observe that L learned by\nAMTFL in Figure 4(f) more closely resembles the true bases\n1We avoid adding nonlinearity to features to make qualitative\nanalysis much easier.\nthan L′ reconstructed using Go-MTL in Figure 4(d)), which\nis more noisy. The reconstructed W = LS from AMTFL\nin Figure 4(g), in turn, is closer to the true parameters than\nW ′ = (LS)′ generated with Go-MTL in Figure 4(e) and\nW ′′ from AMTL in Figure 4(c) for both easy and hard\ntasks. Further analysis of the inter-task transfer matrix AS\nin Figure 4(h) reveals that this accurate reconstruction is due\nto the asymmetric inter-task transfer, as it shows no transfer\nfrom hard to easy tasks, while we see signiﬁcant amount of\ntransfers from easy to hard tasks.\nQuantitative evaluation result in Figure 5(a) further shows\nthat AMTFL signiﬁcantly outperforms existing MTL meth-\nods. AMTFL obtains lower errors on both easy and hard\ntasks to STL, while Go-MTL results in even higher errors\nthan those obtained by STL on hard tasks. We attribute\nthis result to the negative transfer from other hard tasks.\nAMTFL also outperforms AMTL by signiﬁcant margin,\nmaybe because it is hard for AMTL to ﬁnd meaningful\nrelation between tasks in case of this particular synthetic\ndataset, where data for each task is assumed to be generated\nfrom the same set of latent bases. Also, a closer look at\nthe per-task error reduction over STL in Figure 5(b) shows\nthat AMTFL effectively prevents negative transfer while\nGO-MTL suffers from negative transfer, and make larger\nimprovements than AMTL. Further, Figure 5(c) shows that\nAMTFL is more scalable than AMTL, both in terms of error\nreduction and training time, especially when we have large\nnumber of tasks. One thing to note is that, for AMTFL, the\nerror goes down as the number of tasks increases. This is\na reasonable result, since the feature reconstruction using\nthe task-speciﬁc model parameters will become increasingly\naccurate with larger number of tasks.\nReal dataset experiment\nWe further test our model on\none binary classiﬁcation, one regression, and two multi-\nclass classiﬁcation datasets, which are the ones used for\nexperiments in (Kumar & Daume III, 2012; Lee et al., 2016).\nWe report averaged performance of each model on ﬁve\nrandom splits for all datasets.\nDeep Asymmetric Multi-task Feature Learning\nClean\nNoisy\nAll\n1\n1.5\n2\n2.5\n3\n3.5\nSTL\nGO-MTL\nAMTL\nAMTFL\n(a) RMSE\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\nTasks\n-0.6\n-0.4\n-0.2\n0\n0.2\n0.4\n0.6\n0.8\nGOMTL\nAMTL\nAMTFL\n(b) RMSE reduction over STL\n12\n120\n1200\n12000\nNumber of Tasks\n1.5\n2\n2.5\n3\n3.5\nRMSE\n0\n200\n400\n600\n800\nTime(s)\nRMSE-AMTL\nRMSE-AMTFL\nTime-AMTL\nTime-AMTFL\n(c) Scalability\nFigure 5. Results of synthetic dataset experiment. (a) Average RMSE for clean/noisy/all tasks. (a) Per-task RMSE reduction over STL.\n(b) RMSE and training time for increasing number of tasks.\n1) AWA-A: This is a classiﬁcation dataset (Lampert et al.,\n2009) that consists of 30, 475 images, where the task is to\npredict 85 binary attributes for each image describing a\nsingle animal. The feature dimension is reduced from 4096\n(Decaf) to 500 by using PCA. The number of instances for\ntrain, validation, and test set for each task is 1080, 60, and\n60, respectively. We set the number of hidden neurons to\n1000 which is tuned on the base NN.\n2) MNIST: This is a standard dataset for classiﬁcation (Le-\nCun et al., 1998) that consists of 60, 000 training and 10, 000\ntest images of 28×28 that describe 10 handwritten digits (0-\n9). Following the procedure of (Kumar & Daume III, 2012),\nfeature dimension is reduced to 64 by using PCA, and 5\nrandom 100/50/50 splits are used for each train/val/test. We\nset the number of hidden neurons to 500.\n3) School: This is a regression dataset where the task is\nto predict the exam scores of 15, 362 student’s from 139\nschools. Prediction of the exam score for each school is con-\nsidered as a single task. The splits used are from (Argyriou\net al., 2008) and we use the ﬁrst 5 splits among 10. We set\nthe number of hidden neurons to 10 or 15.\n4) Room: This is a subset of the ImageNet dataset (Deng\net al., 2009) from (Lee et al., 2016), where the task is to\nclassify 14, 140 images of 20 different indoor scene classes.\nThe number of train/val instances varies from 30 to over\n1000, while test set has 20 per each class. The feature\ndimension is reduced from 4096 (Decaf) to 500 by using\nPCA. We set the number of hidden neurons to 1000.\nTable 1 shows the results on the real datasets. As expected,\nthe AMTFL (6) outperforms the baselines on most datasets.\nThe only exception is the School dataset, on which GO-MTL\nobtains the best performance, but as mentioned in (Lee et al.,\n2016) this is due to the strong homogeneity among the tasks\nin this particular dataset.\n4.2. Deep models - Convolutional Networks\nNext, we validate our Deep-AMTFL (7) using CNN as base\nnetworks for end-to-end image classiﬁcation. Note that we\nTable 1. Performance of the linear and shallow baselines and our\nasymmetric multi-task feature learning model. We report the\nRMSE for regression and mean classiﬁcation error(%) for classiﬁ-\ncation, along with the standard error for 95% conﬁdence interval.\nAWA-A\nMNIST\nSchool\nRoom\nSTL\n37.6±0.5\n14.8±0.6\n10.16±0.08\n45.9±1.4\nGO-MTL\n35.6±0.2\n14.4±1.3\n9.87±0.06\n47.1±1.4\nAMTL\n33.4±0.3\n12.9±1.4\n10.13±0.08\n40.8±1.5\nNN\n26.3±0.3\n8.96±0.9\n9.89±0.03\n44.5±2.0\nMT-NN\n26.2±0.3\n8.76±1.0\n9.91±0.04\n41.7±1.7\nAMTFL\n25.2±0.3\n8.68±0.9\n9.89±0.09\n40.4±2.4\nTable 2. Classiﬁcation performance of the deep learning baselines\nand Deep-AMTFL. The reported numbers for MNIST-Imbalanced\nand CUB datasets are averages over 5 runs.\nMNIST-Imbal.\nCUB\nAWA-C\nSmall\nCNN\n8.13\n46.18\n33.36\n66.54\nMT-CNN\n8.72\n43.92\n32.80\n65.69\nDeep-AMTL\n8.52\n45.26\n32.32\n65.61\nDeep-AMTFL\n5.82\n43.75\n31.88\n64.49\nuse one-vs-all classiﬁer instead of softmax, since we want\nto consider the classiﬁcation of each class as a separate task.\nBaselines and our models\n1) CNN: The base convolutional neural network.\n2) MT-CNN: The base CNN with ℓ1-regularization on the\nparameters for the last fully connected layer W (L) instead\nof ℓ2-regularization, similarly to (7).\n3) Deep-AMTL: Base CNN with the asymmetric multi-task\nlearning objective in (Lee et al., 2016) replacing the original\nloss. Note that the model is deep version of (5), where LS\ncorresponds to the last fully connected layer W (L).\n4) Deep-AMTFL: Our deep asymmetric multi-task feature\nlearning model with the asymmetric autoencoder based on\ntask loss. (7).\nDeep Asymmetric Multi-task Feature Learning\nDatasets and base networks\n1) MNIST-Imbalanced:\nThis is an imbalanced ver-\nsion of MNIST dataset. Among 6, 000 training samples for\neach class 0, 1, . . . , 9, we used 200, 180, . . . , 20 samples\nfor training respectively, and the rest for validation. For\ntest, we use 1, 000 instances per class as with the standard\nMNIST dataset. As the base network, we used Lenet-Conv.\n2) CUB-200: This dataset consists of images describing 200\nbird classes including Cardinal, Tree Sparrow, and Gray\nCatbird, of which 5, 994 images are used for training and\n5, 794 are used for test. As for the base network, we used\nResNet-18 (He et al., 2016).\n3) AWA-C: This is the same AWA dataset used in the shal-\nlow model experiments, but we used the class labels for 50\nanimals instead of binary attribute labels. Among 30, 475\nimages, we randomly sampled 50 instances per each class\nto use as the test set, and used the rest of them for train-\ning, which results in an imbalanced training set (42-1118\nsamples per class). As with the CUB dataset, we used\nResNet-18 as the base network.\n4) ImageNet-Small: This is a subset of the ImageNet 22K\ndataset (Deng et al., 2009), which contains 352 classes. We\ndeliberately created the dataset to be largely imbalanced,\nwith the number of images per class ranging from 2 to 1, 044.\nWe used ResNet-50 for the base network.\nExperimental Setup\nFor the implementation of all the\nbaselines and our deep models, we use Tensorﬂow (Abadi\net al., 2016) and Caffe (Jia, 2013) framework. For AWA-C\nand Small datasets, we ﬁrst train Base model from scratch,\nand ﬁnetune the the other models based on it for expedited\ntraining. We trained from scratch for other datasets. Note\nthat we simply use the weight decay λ provided by the code\nof the base networks, and set µ = λ to reduce the effective\nnumber of hyperparameters to tune. We searched for α\nand γ in the range of {1, 0.1, 10−2, 10−3, 10−4}. For CUB\ndataset, we gradually increase α and γ from 0, which helps\nwith stability of learning at the initial stage of the training.\nQuantitative evaluation\nWe report the average per-class\nclassiﬁcation performances of baselines and our models in\nTable 2. Our Deep-AMTFL outperforms all baselines, in-\ncluding MT-CNN and Deep-AMTL, which shows the effec-\ntiveness of our asymmetric knowledge transfer from tasks\nto features, and back to tasks in deep learning frameworks.\nTo see where the performance improvement comes from, we\nfurther examine the per-task (class) performance improve-\nment of baselines and our Deep-AMTFL over the base CNN\non MNIST-Imbalanced dataset along with average per-task\nloss (Figure 6(a)). We see that MT-CNN improves the per-\nformance over CNN on half of the tasks (5 out of 10) while\n-2\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n1\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\n5\n5.5\n6\n0 1 2 3 4 5 6 7 8 9\nAccuracy Improvements\nover CNN (%)\nCross Entropy (x 1E-4)\nTasks\n MT-CNN\n Deep-AMTL\n Deep-AMTFL\n Cross Entropy\n(a) Per-task Improvements\n(b) Inter-task Transfer\nFigure 6. Results of experiments on the MNIST-Imbalanced\ndataset. (a) Accuracy improvements over the CNN and the per-\ntask losses. (b) The inter-task transfer matrkx AS. We remove the\nsign of values for better visualization.\ndegenerating performance on the remainders. Deep-AMTL\nobtains larger performance gains on later tasks with large\nloss (task 8 and 9) due to its asymmetric inter-task knowl-\nedge transfer, but still suffers from performance degradation\n(task 6 and 7). Our Deep-AMTFL, on the other hand, does\nnot suffer from accuracy loss on any tasks and shows signif-\nicantly improved performances on all tasks, especially on\nthe tasks with large loss (task 9). This result suggests that\nthe performance gain mostly comes from the suppression of\nnegative transfer.\nQuanlitative analysis\nAs further qualitative analysis, we\nexamine how inter-task knowledge transfer is done in Deep-\nAMTFL in Figure 6(b). Although Deep-AMTFL does not\nexplicitly model inter-task knowledge transfer graph, we can\nobtain one by computing AS, as in Figure 6(b). We see that\neach task transfers to later tasks (upper triangular subma-\ntrix) that comes with fewer training instances but does not\nreceive knowledge transfer from them, which demonstrates\nthat Deep-AMTFL is performing asymmetric knowledge\ntransfer in correct directions implicitly via the latent fea-\nture space. The only exception is the tansfer from task 5 to\ntask 2, which is reasonable since they have similar losses\n(Figure 6(a)).\n5. Conclusion\nWe propose a novel deep asymmetric multi-task feature\nlearning framework that can effectively prevent negative\ntransfer resulting from symmetric inﬂuences of each task in\nfeature learning. By introducing an asymmetric feedback\nconnections in the form of autoencoder, our AMTFL en-\nforces the participating task predictors to asymmetrically\naffect the learning of shared representations based on task\nloss. We perform extensive experimental evaluation of our\nmodel on various types of tasks on multiple public datasets.\nThe experimental results show that our model signiﬁcantly\noutperforms both the symmetric multi-task feature learn-\ning and asymmetric multi-task learning based on inter-task\nknowledge transfer, for both shallow and deep frameworks.\nDeep Asymmetric Multi-task Feature Learning\nAcknowledgements\nThis research was supported by Samsung Research Funding\nCenter of Samsung Electronics (SRFC-IT150203), Basic\nScience Research Program through the National Research\nFoundation of Korea (NRF) funded by the Ministry of Ed-\nucation (2015R1D1A1A01061019), a Machine Learning\nand Statistical Inference Framework for Explainable Arti-\nﬁcial Intelligence (No.2017-0-01779) and Development of\nAutonomous IoT Collaboration Framework for Space Intel-\nligence (2017-0-00537) supervised by the IITP(Institute for\nInformation & communications Technology Promotion).\nReferences\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z.,\nCitro, C., Corrado, G. S., Davis, A., Dean, J., Devin,\nM., et al. Tensorﬂow: Large-scale Machine Learning on\nHeterogeneous Distributed Systems. arXiv:1603.04467,\n2016.\nArgyriou, A., Evgeniou, T., and Pontil, M. Convex Multi-\ntask Feature Learning. Machine Learning, 73(3):243–\n272, 2008.\nCaruana, R. Multitask Learning. Machine Learning, 1997.\nDeng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and ei,\nL. F.-F. Imagenet: A Large-Scale Hierarchical Image\nDatabase. In CVPR, 2009.\nHe, K., Zhang, X., Ren, S., and Sun, J. Deep Residual\nLearning for Image Recognition. In CVPR, 2016.\nHinton, G. E. and Salakhutdinov, R. R.\nReducing the\ndimensionality of data with neural networks. Science,\n313(5786):504–507, 2006.\nISSN 0036-8075.\ndoi:\n10.1126/science.1127647.\nJia, Y. Caffe: An open source convolutional architecture for\nfast feature embedding, 2013.\nKang, Z., Grauman, K., and Sha, F. Learning with whom\nto share in multi-task feature learning. In ICML, pp. 521–\n528, 2011.\nKingma, D. P. and Ba, J. Adam: A method for stochastic\noptimization. In ICLR, 2014.\nKumar, A. and Daume III, H. Learning task grouping and\noverlap in multi-task learning. In ICML, 2012.\nLampert, C., Nickisch, H., and Harmeling, S. Learning\nto Detect Unseen Object Classes by Between-Class At-\ntribute Transfer. In CVPR, 2009.\nLeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. Gradient-\nbased learning applied to document recognition. Proceed-\nings of the IEEE, 86(11):2278–2324, 1998.\nLee, G., Yang, E., and Hwang, S. Asymmetric multi-task\nlearning based on task relatedness and conﬁdence. In\nICML. ICML, 2016.\nMaurer, A., Pontil, M., and Romera-Paredes, B. Sparse\ncoding for multitask and transfer learning. In ICML,\n2012.\nRanzato, M. A., Poultney, C., Chopra, S., and Cun, Y. L. Ef-\nﬁcient learning of sparse representations with an energy-\nbased model. pp. 1137–1144. MIT Press, 2007.\nRuder, S., Bingel, J., Augenstein, I., and Søgaard, A. Learn-\ning what to share between loosely related tasks. ArXiv\ne-prints, May 2017.\nRumelhart, D. E., Hinton, G. E., and Williams, R. J. Parallel\ndistributed processing: Explorations in the microstructure\nof cognition, vol. 1. chapter Learning Internal Represen-\ntations by Error Propagation, pp. 318–362. MIT Press,\nCambridge, MA, USA, 1986.\nVincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A.\nExtracting and composing robust features with denoising\nautoencoders. pp. 1096–1103, New York, NY, USA, 2008.\nACM.\nYang, Y. and Hospedales, T. Deep Multi-task Representation\nLearning: A Tensor Factorisation Approach. ICLR, 2017.\nYang, Y. and Hospedales, T. M. Trace Norm Regularised\nDeep Multi-Task Learning. ArXiv e-prints, June 2016.\nA. Application to Transfer Learning\nTable 3. Classiﬁcation error(%) of the baselines and our model\non the transfer learning task. Source networks denote types of\nnetworks that is trained on the source dataset with 40 classes, and\nTarget accuracy is the accuracy of the softmax classiﬁer on 10\ntarget classes trained on the representations obtained at the layer\njust below the softmax layer of the source network.\nSource Network\nTarget Accuracy\nCNN\n5.00\nDeep-AMTL\n5.00\nDeep-AMTFL\n4.33\nFor this experiment, we use the AWA dataset, which is a stan-\ndard dataset for transfer learning that provides source/target\ntask class split. The source dataset contains 40 animal\nclasses including grizzly bear, hamster, blue whale, and\ntiger, and the target dataset contains 10 animal classes, in-\ncluding giant panda, rat, humpback whale, and leopard.\nThus the tasks in two datasets exhibit large degree of relat-\nedness. We train baseline networks and our Deep-AMTFL\nmodel on the source dataset, and trained the last fully con-\nnected layer of the original network while maintaining all\nother layers to be ﬁxed, for the classiﬁcation of the target\ndataset.\nDeep Asymmetric Multi-task Feature Learning\nB. Other Baselines\nIn the below table, we show the performances of the two\nrecently proposed multi-task learning models (Yang &\nHospedales, 2017; 2016) on two datasets used in the shal-\nlow model experiments. The results show that our AMTFL\nsigniﬁcantly ouperforms those models.\nMNIST\nRoom\nDMTRL\n11.9 ± 0.8\n47.2 ± 2.9\nTNRDMTL\n11.0 ± 1.3\n49.4 ± 1.4\nAMTFL\n8.68±0.9\n40.4 ± 2.4\nC. Experimental Setup\nSynthetic dataset experiment\nAll the hyperparameters\nare found with separate validation sets. For the latent bases\nmodels (Go-MTL, AMTFL), we use one hidden layer with\nsix neurons, while other models (STL and AMTL) do not\nhave any hidden layer. The base learning rate is 0.1, and is\nmultiplied by 0.2 every 500 iterations. The batch size is set\nas 100. The total number of iterations is 2500. RMSProp is\nused for the latent bases models (Go-MTL, AMTFL), and\nSGD is used for the other models (STL, AMTL), which\nhas been empirically found to be optimal for each model.\nWeight decay is set as 0.02. The weights are initialized\nwith gaussian distribution with 0.01 standard deviation. For\nGo-MTL, the sparsity for L is 0.3 and µ is 0.2. For AMTL,\nλ and µ are set as 0.3 and 0.0001 each. For AMTFL, the\nsparsity for L is 0.5, µ is 0.3, α is 0.2, and γ is 0.003.\nReal dataset experiment (shallow models)\nHere we\nmention a few important settings for the experiments. The\nbase learning rate varying from 10−1 to 10−4, and step-\nwisely decreases when training loss saturates. Batch size\nalso varies from 102 to 103, which is jointly controlled with\nlearning rate. The number of hidden neurons is set via cross\nvalidation, along with other hyperparameters. The weights\nare initialized with zero-mean gaussian with 0.01 stddev.\nReal dataset experiment (deep models)\nFor MNIST-\nImbalanced dataset, we ran total 200 epochs with batchsize\n100. We used the Adam (Kingma & Ba, 2014) optimizer,\nwith the learning rate starts from 10−4 and is multiplied\nby 0.1 after 100 epochs. We set λ = µ = 10−4, α = 0.1,\nand γ = 0.01. For CUB dataset, we ran total 400 epochs\nwith batchsize 125. We used SGD optimizer with 0.9 mo-\nmentum. Learning rate starts from 10−2 and is multiplied\nby 0.1 after 200 and 300 epochs. We set λ = µ = 10−3,\nα = 1 and γ = 10−3. For AWA-C dataset, we ran total 300\nepochs with batchsize 125. We used SGD optimizer with\n0.9 momentum. Learning rate starts from 10−2, and is mul-\ntiplied by 0.1 at 150 and 250 epochs. We set λ = µ = 10−4,\nα = 0.1 and γ = 10−4. For ImageNet-Small dataset, we\nran total 40, 000 iterations with batchsize 30. The base\nlearning rate is 10−4 and multiplied by 0.1 at every 4, 500\niteration.\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2017-08-01",
  "updated": "2018-06-30"
}