{
  "id": "http://arxiv.org/abs/1709.01574v1",
  "title": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced Attentive Response Approach for Explaining and Visualizing Deep Learning-Driven Stock Market Prediction",
  "authors": [
    "Devinder Kumar",
    "Graham W Taylor",
    "Alexander Wong"
  ],
  "abstract": "Deep learning has been shown to outperform traditional machine learning\nalgorithms across a wide range of problem domains. However, current deep\nlearning algorithms have been criticized as uninterpretable \"black-boxes\" which\ncannot explain their decision making processes. This is a major shortcoming\nthat prevents the widespread application of deep learning to domains with\nregulatory processes such as finance. As such, industries such as finance have\nto rely on traditional models like decision trees that are much more\ninterpretable but less effective than deep learning for complex problems. In\nthis paper, we propose CLEAR-Trade, a novel financial AI visualization\nframework for deep learning-driven stock market prediction that mitigates the\ninterpretability issue of deep learning methods. In particular, CLEAR-Trade\nprovides a effective way to visualize and explain decisions made by deep stock\nmarket prediction models. We show the efficacy of CLEAR-Trade in enhancing the\ninterpretability of stock market prediction by conducting experiments based on\nS&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can\nprovide significant insight into the decision-making process of deep\nlearning-driven financial models, particularly for regulatory processes, thus\nimproving their potential uptake in the financial industry.",
  "text": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced Attentive Response\nApproach for Explaining and Visualizing Deep Learning-Driven Stock Market Prediction\nDevinder Kumar\nUniversity of Waterloo, ON, Canada\nGraham W. Taylor\nUniversity of Guelph, CIFAR and Vector Institute, ON, Canada\nAlexander Wong\nUniversity of Waterloo & Waterloo AI Institute, ON, Canada\nAbstract\nDeep learning have been shown to outperform traditional machine\nlearning algorithms across a wide range of problem domains. How-\never, current deep learning algorithms are essentially uninterpretable\n\"black-boxes\" without any explanations associated with their deci-\nsion making processes. This is a major shortcoming that prevents\nwidespread use of deep learning to be used in scenarios with reg-\nulatory processes such as ﬁnance. As such, industries such as\nﬁnance have to rely on traditional models like decision trees that\nare much more interpretable but less effective than deep learning\nfor complex problems. In this paper, we propose CLEAR-Trade, a\nnovel ﬁnancial AI visualization framework for deep learning-driven\nstock market prediction that mitigates the interpretability issue of\ndeep learning. In particular, CLEAR-Trade provides a effective way\nto visualize and explain decisions made by deep stock market pre-\ndiction models. We show the efﬁcacy of CLEAR-Trade in enhanc-\ning the interpretability of stock market prediction by conducting ex-\nperiments based on S&P 500 stock index prediction. The results\nclearly demonstrate that CLEAR-Trade can provide signiﬁcant in-\nsight into the decision-making process of the deep learning-driven\nﬁnancial models, particularly for regulatory processes, thus improv-\ning their potential widespread adoption in ﬁnance.\n1\nIntroduction\nDo machine learning algorithms need to be explainable? This is an\nimportant question in today’s world where machine learning algo-\nrithms, especially those based on deep learning are being used at\na wide range of tasks and have shown tremendous efﬁcacy in per-\nforming these tasks. Deep learning has touted as being very dis-\nruptive to many sectors, particularly the ﬁnance sector. However,\ndeep learning, to large extent, have essentially been unexplainable\n\"black boxes\", with no clear explanation as to how they reach par-\nticular decisions [6]. This is a major hindrance to the widespread\nadoption of deep learning in industries like ﬁnance, where regula-\ntions are very tight. In such industries with strict regulatory pro-\ncesses, the AI models used are required to be transparent, inter-\npretable, and explainable. Many experts in these sectors believe\nthat relying on such ’black box’ methods is a growing problem that\nis already very relevant due to regulatory processes in these sec-\ntors, and it is going to be increasingly more relevant in the future.\nFor example, in ﬁnance, law requires companies to explain the rea-\nson behind every decision to its perspective customer [3]. As such,\ncurrent approaches for leveraging deep learning are not feasible\nsuch in these scenarios.\nThe limitation of deep learning in terms of transparency and\ninterpretability have forced industries dealing with regulatory sce-\nnarios to use comparatively simple machine learning algorithms\nsuch as linear or logistic regression, decision trees, or ensem-\nble methods such as random forests which are signiﬁcantly more\nexplainable and quite effective in simple cases. However, as the\ncomplexity of the problem increases, which is very true in ﬁnance,\ndeep learning algorithms have been shown to outperform such tra-\nditional algorithms by a wide margin across a wide range of prob-\nlem domains [2]. As such, strategies for explaining the decisions\nmade by deep learning algorithms are highly desired to enable their\nwidespread use in sectors that have strong regulatory processes.\nMore recently, a number of methods were proposed to mitigate\nthis issue of interpretability and transparency in deep learning. For\nexample, Zeiler & Fergus [7] proposed the formation of a parallel\ndeconvolutional network to peer into different units of the network.\nRibeiro [4] introduced a method to build trust in models that are\nlocally accurate, i.e., it is correct near the input data sample. Sel-\nvaraju et.al. [5] proposed a method called Grad-CAM that enables\nusers to discern \"strong\" networks from the weaker ones. While\npromising, all of the aforementioned approaches are restricted to\nidentifying regions of interest and their inﬂuence in the decision\nUn-interpretable Black Box Binary Stock Market Prediction\nStock will \ngo up\n100\n110\n120\n130\nS&P 500 Stock Data\n100\n110\n120\n130\nS&P 500 Stock Data\nStock will \ngo up \nbecause of: \nExplanation from \nCLEAR-Trade \nvisualization\nInterpretable Stock Market Prediction with CLEAR-Trade Visualization\nBlack box AI Model\nI know the \nreason why!\n104\n106\n108\n110\n112\n114\n116\n118\n120\n(a)\n(b)\nFig. 1: Two different scenarios for stock market prediction using\ndeep learning-driven ﬁnancial AI models: a) Stock market pre-\ndiction without interpretability, b)interpretable stock market pre-\ndiction via CLEAR-Trade. The proposed CLEAR-Trade visualiza-\ntion framework improves ﬁnancial model interpretability by provid-\ning effective visual interpretations of the decision-making process.\nCLEAR-Trade allows for the visualization of i) the attentive time\nwindows responsible for stock market prediction decisions based\non the ﬁnancial AI model (marked in red and green), ii) their level\nof contribution to the stock market prediction decision (in this case,\nstock market index rise (green) or stock market index fall (red)), as\nwell as iii) the dominant state (rise or fall) associated with each at-\ntentive time window. This visualization enables ﬁnancial analysts\nto better understand the rationale behind the stock market predic-\ntion decisions made based by the deep learning-driven ﬁnancial AI\nmodel.\nmade by the deep neural network only, thus restricting their util-\nity for gaining a more detailed understanding of the decision pro-\ncess. To address this issue, Kumar et. al. [1] recently proposed\na CLass Enhanced Attentive Response (CLEAR) approach that\nnot only identiﬁes attentive regions of interest and their inﬂuence\non the decision made, but more important provides the dominant\nclasses associated with the attentive regions of interest. This ad-\nditional information about the dominant classes and their inﬂuence\non the decision making progress leads to a higher degree of hu-\nman interpretability, which makes it very well suited for scenarios\nthat necessitate regulatory processes such as in ﬁnance.\nMotivated by this, in this paper, we propose CLEAR-Trade, a\nCLass Enhanced Attentive Response approach to explaining and\nvisualizing deep learning-driven stock market prediction. In par-\nticular, CLEAR-Trade is designed in this paper to provide detailed\nexplanations for the prediction decisions made by a deep learning-\ndriven binary stock market prediction network, as shown in Fig. 1.\nOur aim is to create a powerful tool for peering into the minds of\nthese otherwise uninterpretable ’black box’ ﬁnancial AI models to\nbetter visualize and understand why they are making the decisions\nthe way they do. Doing this will have a tremendous impact on day-\nto-day work of ﬁnancial analysts in helping them better understand\nthese deep learning-driven ﬁnancial AI models, thus potentially en-\nabling the widespread adoption of transparent ﬁnancial AI.\n2\nMethodology\nWith the goal of enabling transparent and interpretable deep learning-\ndriven stock market prediction, the proposed CLEAR-Trade visual-\narXiv:1709.01574v1  [cs.AI]  5 Sep 2017\n100\n110\n120\n130\nS&P 500 Stock Data\n100\n110\n120\n105\n110\n115\n120\n100\n110\n120\n105\n110\n115\n120\n104\n106\n108\n110\n112\n114\n116\n118\n120\nStock will go up \nbecause of \nfeatures shown \nin CLEAR-Trade \nvisualization\nDominant Class \nAttentive Map\nDominant \nResponse  Map\nIndividual Response  Map\nCLEAR-Trade Visualization\nDeconvolution\nFig. 2: An overview of the proposed CLEAR-Trade visualization\nframework for explaining and visualizing deep learning-driven stock\nmarket prediction. As an illustrative case in this paper, for predict-\ning whether a stock market index will rise or fall (two states), the\nindex’s past 30 days of trade data is fed into the deep learning-\ndriven ﬁnancial AI model and individual attentive response maps\nare computed for each state (stock market index rise or stock mar-\nket index down) based on the last layer of the deep learning-driven\nﬁnancial AI model. Based on this set of attentive response maps,\ntwo different maps are computed: 1) a dominant attentive response\nmap, which shows the level of contribution of each time point to the\ndecision-making process, and 2) a dominant state attentive map,\nwhich shows the dominant state associated with each time point\ninﬂuencing the decision-making process. Finally, the dominant at-\ntentive response map and the dominant attentive state map are\ncombined to produce the ﬁnal CLEAR-Trade visualization, thus en-\nabling the ﬁnancial analyst to visualize the factors leveraged by the\ndeep learning-driven ﬁnancial AI model in predicting whether the\nstock market index will rise (green) or fall (red).\nization framework presents the ﬁnancial analyst with the following\ninformation pertaining to the decision-making process:\n1. the attentive time windows responsible for the decision made\nby the ﬁnancial AI model;\n2. the attentive levels at these attentive time windows so that\ntheir level of inﬂuence over the decision made by the ﬁnancial\nAI model can be understood; and\n3. the dominant state (in this paper, stock market index rise or\nfall) associated with these attentive time windows so that we\ncan better understand why a decision was made.\nThe procedure for obtaining the CLEAR-Trade visualization for\nstock market prediction (in this case, predicting stock market in-\ndices but can also be applied to individual stocks) is shown in Fig. 2\nand can be explained as follows.\nFirst, a forward pass with a time-series input of historical trade\ninformation about a particular stock market index (in this case, an\nindex’s 30 days worth of open, close, highs, lows, and trade vol-\numes) is performed through the deep learning-driven ﬁnancial AI\nmodel and a stock market prediction decision output is obtained.\nTo create a CLEAR-Trade visualization associated with this par-\nticular stock market prediction decision, we ﬁrst compute a set of\nindividual response maps {R(x|s)|1 ≤s ≤K}, where K is the total\nnumber of states present for stock market prediction (in this case,\nthere are two states: stock market index rise and fall). The deep\nlearning-driven ﬁnancial AI model is set up such that it contains\nsimilar number of kernels in the last layer as the number of states.\nTo elaborate the process, ﬁrst consider the response for all the ker-\nnels at the the last layer l of the ﬁnancial AI model which can be\ncalculated as:\nˆhl =\nK\n∑\nk=1\nzk,l ∗wk,l.\n(1)\nN:16\nF:3x3\nN:8\nF:3x3\nN:32\nF:1x1\nN:5\nF:1x1\nGAP\nsoftmax\nConvolutional \nblock\nLeaky Relu: \nalpha:0.3\nDeep convolutional Financial AI model\nFig. 3: Architecture of the deep convolutional ﬁnancial AI model\nused for stock market prediction process. The ﬁnancial AI model is\nembedded in the CLEAR-Trade visualization process, which aug-\nments a set of fully convolutional layers, a leaky rectiﬁed linear unit\nlayer, global average pooling (GAP) and a softmax layer at the end\nof the model for the learning process.\nwhere ∗denotes the convolution operation. To calculate the re-\nsponse of last layer in the input domain, we can extend this for-\nmulation for response of the speciﬁc kernel sε{1...K} of the deep\nlearning-driven ﬁnancial AI model with Un-pooling layer P′ as:\nR(x|s) = H1P′\n1H2P′\n2....HL−1P′\nL−1Hs\nLzL.\n(2)\nwhere H denotes the combined operation of convolutional and sum-\nmation, for notation brevity. Hs\nL represents the convolution matrix\noperation in which the kernel weights wL are all zero except that at\nthe sth time point.\nGiven the set of individual attentive response maps, we then\ncompute the dominant attentive state map, ˆS(x), by ﬁnding the\nstate that maximizes the attentive response level, R(x|s), across\nall states:\nˆS(x) = argmax\ns\nR(x|s).\n(3)\nGiven the dominant attentive state map, ˆS(x), we can now com-\npute the dominant attentive response map, D ˆS(x), by selecting the\nattentive response level at a particular time point based on the\nidentiﬁed dominant state, which can be expressed as follows:\nD ˆS(x) = R(x| ˆS).\n(4)\nTo form the ﬁnal CLEAR-Trade visualization, we map the domi-\nnant state attentive map and the dominant attentive response map\nin the HSV (S in HSV is indicated as S’ below to avoid confusion\nwith state S) color space as follows:\nH = F( ˆS(x)),\nS′ = 1,\nV = D ˆS(x).\n(5)\nwhere F(.) is the color map dictionary that assigns an individual\ncolor to each dominant attentive state, s. Fig. 2 shows an example\nof the CLEAR-Trade visualization.\n3\nExperiments and Results\nThis section explains the experimental setup, the deep learning-\ndriven ﬁnancial AI model built for performing binary stock market\nprediction on the S&P 500 stock market index, and the experimen-\ntal results for obtaining the efﬁcacy of the CLEAR-Trade visualiza-\ntion in creating interpretable and transparent deep learning-driven\nﬁnancial AI models for stock market prediction.\n3.1\nExperimental Setup\nFor training purposes, we selected the last three years worth of\ntrade data of the S&P 500 stock market index to train a deep con-\nvolutional neural network, shown in Fig. 3, as the deep learning-\ndriven AI ﬁnancial model used in this study. For preparing this data\nfor training the ﬁnancial model, we divided the data into 30-day time\nsegments and treated the state (index rise or index fall) on the 31st\nday as ’1’ if the index was higher than previous day or ’0’ if the index\nwas lower. We used 90% of the data as training set and consider\n10% for evaluation purposes. The trained deep learning-driven ﬁ-\nnancial AI model achieved a prediction accuracy of 61.22%, though\nCorrect Binary Stock Prediction\n104\n106\n108\n110\n112\n114\n116\n118\n120\n11/7/2015 11/12/2015 11/17/2015 11/22/2015 11/27/2015 12/2/2015\n12/7/2015 12/12/2015 12/17/2015 12/22/2015 12/27/2015\n108\n110\n112\n114\n116\n118\n120\n122\n124\n9/18/2015\n9/23/2015\n9/28/2015\n10/3/2015\n10/8/2015 10/13/2015 10/18/2015 10/23/2015 10/28/2015 11/2/2015\n11/7/2015\nGround Truth: \nPredicted: \nGround Truth: \nPredicted: \n104\n106\n108\n110\n112\n114\n116\n118\n120\n11/12/201511/17/201511/22/201511/27/201512/2/2015 12/7/201512/12/201512/17/201512/22/201512/27/2015 1/1/2016\n1/6/2016\nGround Truth: \nPredicted: \n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n8/24/2015 8/29/2015\n9/3/2015\n9/8/2015\n9/13/2015 9/18/2015 9/23/2015 9/28/2015 10/3/2015 10/8/2015 10/13/2015\nGround Truth: \nPredicted: \nWrong Binary Stock Prediction\nFig. 4: Correctly and mis-classiﬁed binary stock market prediction\nfor predicting the S&P 500 stock market index as visualized and\nexplained using CLEAR-Trade for a deep learning-driven ﬁnancial\nAI model trained for experimental purposes. For both cases, the\nCLEAR-Trade visualizations (left) pinpoint the attentive time win-\ndows that are responsible for the particular stock market prediction\ndecision made by the ﬁnancial AI model (green for index rise and\nred for index fall). In the CLEAR-Trade visualizations, the thickness\nof color lines indicate the inﬂuence of the attentive time windows\non the prediction decision output. On the right hand side, the time-\nwise stock data information sheet (open, high, low, close, and trade\nvolume) of one of the graphs is shown in the descending order from\nthe day on which decision is being made. Here also, the attentive\nlevels (transparency of color) and the dominant state (green or red)\nassociated with these attentive time windows is shown so that we\ncan better understand why a decision was made.\nit is important to note that the focus of this paper is on the ability\nto visualize and understanding the decision-making process of the\nﬁnancial AI model, not in attaining the best possible accuracy, and\ntherefore improving the accuracy of the reference model are plans\nfor future work.\n3.2\nStock Market Prediction Results\nTo present the effectiveness of the CLEAR-Trade visualization (as\nexplained in Section 2) to enable interpretable deep learning-driven\nﬁnancial AI, we used the trained stock market predictive model and\nobtained the CLEAR-Trade visualization results as shown in Fig. 4.\nIn Fig. 4, for both cases (correct and wrong predictions), it can be\nclearly observed from the CLEAR-Trade visualizations which time\nwindows are most crucial to the decision-making process of the\nﬁnancial AI model for reaching a particular stock market prediction.\nSpeciﬁcally, in the correctly predicted cases, it can be observed\nthat the deep learning-driven ﬁnancial AI model primarily leveraged\nthe past four days of trade data for correctly predicting whether the\nS&P 500 stock market index will rise or fall. This is intuitive as the\npast few days are more likely to have a major effect on the index’s\nbehavior compared to data from a couple of weeks back. In the\ncase whether the ﬁnancial AI model gets the stock market predic-\ntion incorrect, we can observe that the model primarily leverages\ntrade data for nearly 3 weeks ago to making its decision. Another\nobservation that can be made in both cases is that in the cases\nwhere the stock market prediction is correct, the deep learning-\ndriven ﬁnancial AI model leverages only open, high and low values\nto make a decision. This trend if leveraging only open, high, and\nlow values is observed across the majority of correct predictions\nmade by ﬁnancial AI model. This is again intuitive as unless there\nis a signiﬁcant change in trade volume, knowledge of trade volume\ngenerally does not have a signiﬁcant impact on either index rise or\nfall. Conversely, it can be seen that when making incorrect deci-\nsions, the ﬁnancial AI model strongly takes into account the trade\nvolume as well, which is not a strong predictive feature as indicate\nabove and as such can incorrectly inﬂuence its decisions. Finally, it\ncan be observed that the conﬁdence of the stock market prediction\nin this case is low when it makes incorrect predictions, as indicated\nby the color transparency in the data-sheet, while in correct predic-\ntions the conﬁdence of the stock market prediction is high.\nHence, based on the above mentioned observations, it is evi-\ndent that CLEAR-Trade visualization not only provides a justiﬁca-\ntion for particular stock market prediction decision output, it can\nalso provide considerable insights that ﬁnancial analysts can taken\ninto account while making trading decisions.\n4\nConclusion\nIn this paper, we proposed CLEAR-Trade, a visualization frame-\nwork that provides insight into the minds of deep learning-driven\nﬁnancial AI models used for stock market prediction by visualizing\nand explaining the decision-making process of the model. Experi-\nments pertaining to stock market prediction for the S&P 500 index\nshowed that CLEAR-Trade visualization leads to a higher degree\nof human interpretability and transparency in predictions made us-\ning deep learning-driven ﬁnancial AI models, hence paving a way\nfor their use in regulatory settings. The proposed visualization ap-\nproach has tremendous potential to create industry-wide effect by\nfacilitating the use of state-of-the art deep learning models for ar-\neas in ﬁnance that are under signiﬁcant regulations.\nAcknowledgments\nThis research has been supported by Canada Research Chairs\nprograms, Natural Sciences Engineering Research Council of Canada\n(NSERC), and Canada Foundation for Innovation (CFI).\nReferences\n[1] Devinder Kumar, Alexander Wong, and Graham W Taylor. Explaining\nthe unexplained: A class-enhanced attentive response (clear) approach\nto understanding deep neural networks. IEEE Computer Vision and\nPattern Recognition (CVPR) Workshop, 2017.\n[2] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Na-\nture, 521(7553):436–444, 2015.\n[3] MIT Technology Review.\nThe Financial World Wants to Open AI’s\nBlack Boxes. https://www.technologyreview.com/s/604122/\nthe-financial-world-wants-to-open-ais-black-boxes/,\n2015. [Online; accessed 28-08-2017].\n[4] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Why should i\ntrust you?: Explaining the predictions of any classiﬁer. In Proceedings\nof the 22nd ACM SIGKDD International Conference on Knowledge Dis-\ncovery and Data Mining, pages 1135–1144. ACM, 2016.\n[5] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakr-\nishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: Visual ex-\nplanations from deep networks via gradient-based localization. IEEE\nInternational Conference on Computer Vision (ICCV), 2017.\n[6] Daniel LK Yamins and James J DiCarlo.\nUsing goal-driven deep\nlearning models to understand sensory cortex. Nature neuroscience,\n19(3):356, 2016.\n[7] Matthew D Zeiler and Rob Fergus. Visualizing and understanding con-\nvolutional networks. In European conference on computer vision, pages\n818–833. Springer, 2014.\n",
  "categories": [
    "cs.AI",
    "cs.CV",
    "cs.NE"
  ],
  "published": "2017-09-05",
  "updated": "2017-09-05"
}