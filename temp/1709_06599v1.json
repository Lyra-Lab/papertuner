{
  "id": "http://arxiv.org/abs/1709.06599v1",
  "title": "Unsupervised Machine Learning for Networking: Techniques, Applications and Research Challenges",
  "authors": [
    "Muhammad Usama",
    "Junaid Qadir",
    "Aunn Raza",
    "Hunain Arif",
    "Kok-Lim Alvin Yau",
    "Yehia Elkhatib",
    "Amir Hussain",
    "Ala Al-Fuqaha"
  ],
  "abstract": "While machine learning and artificial intelligence have long been applied in\nnetworking research, the bulk of such works has focused on supervised learning.\nRecently there has been a rising trend of employing unsupervised machine\nlearning using unstructured raw network data to improve network performance and\nprovide services such as traffic engineering, anomaly detection, Internet\ntraffic classification, and quality of service optimization. The interest in\napplying unsupervised learning techniques in networking emerges from their\ngreat success in other fields such as computer vision, natural language\nprocessing, speech recognition, and optimal control (e.g., for developing\nautonomous self-driving cars). Unsupervised learning is interesting since it\ncan unconstrain us from the need of labeled data and manual handcrafted feature\nengineering thereby facilitating flexible, general, and automated methods of\nmachine learning. The focus of this survey paper is to provide an overview of\nthe applications of unsupervised learning in the domain of networking. We\nprovide a comprehensive survey highlighting the recent advancements in\nunsupervised learning techniques and describe their applications for various\nlearning tasks in the context of networking. We also provide a discussion on\nfuture directions and open research issues, while also identifying potential\npitfalls. While a few survey papers focusing on the applications of machine\nlearning in networking have previously been published, a survey of similar\nscope and breadth is missing in literature. Through this paper, we advance the\nstate of knowledge by carefully synthesizing the insights from these survey\npapers while also providing contemporary coverage of recent advances.",
  "text": "1\nUnsupervised Machine Learning for Networking:\nTechniques, Applications and Research Challenges\nMuhammad Usama1, Junaid Qadir1, Aunn Raza2, Hunain Arif2, Kok-Lim Alvin Yau3,\nYehia Elkhatib4, Amir Hussain5, Ala Al-Fuqaha6\n1Information Technology University (ITU)-Punjab, Lahore, Pakistan\n2School of EE and CS, National University of Sciences and Technology (NUST), Pakistan\n2Sunway University, Malaysia\n4MetaLab, School of Computing and Communications, Lancaster University, UK\n5University of Stirling, United Kingdom\n6Western Michigan University, United States of America\nAbstract—While machine learning and artiﬁcial intelligence\nhave long been applied in networking research, the bulk of such\nworks has focused on supervised learning. Recently there has\nbeen a rising trend of employing unsupervised machine learn-\ning using unstructured raw network data to improve network\nperformance and provide services such as trafﬁc engineering,\nanomaly detection, Internet trafﬁc classiﬁcation, and quality\nof service optimization. The interest in applying unsupervised\nlearning techniques in networking emerges from their great\nsuccess in other ﬁelds such as computer vision, natural language\nprocessing, speech recognition, and optimal control (e.g., for\ndeveloping autonomous self-driving cars). Unsupervised learning\nis interesting since it can unconstrain us from the need of\nlabeled data and manual handcrafted feature engineering thereby\nfacilitating ﬂexible, general, and automated methods of machine\nlearning. The focus of this survey paper is to provide an overview\nof the applications of unsupervised learning in the domain of\nnetworking. We provide a comprehensive survey highlighting\nthe recent advancements in unsupervised learning techniques\nand describe their applications for various learning tasks in\nthe context of networking. We also provide a discussion on\nfuture directions and open research issues, while also identifying\npotential pitfalls. While a few survey papers focusing on the\napplications of machine learning in networking have previously\nbeen published, a survey of similar scope and breadth is missing\nin literature. Through this paper, we advance the state of\nknowledge by carefully synthesizing the insights from these survey\npapers while also providing contemporary coverage of recent\nadvances.\nI.\nINTRODUCTION\nNetworks—such\nas\nthe\nInternet\nand\nmobile\ntelecom\nnetworks—serve the function of the central hub of modern\nhuman societies, which the various threads of modern life\nweave around. With networks becoming increasingly dynamic,\nheterogeneous, and complex, the management of such net-\nworks has become less amenable to manual administration,\nand can beneﬁt from leveraging support from methods for\noptimization and automated decision-making from the ﬁelds of\nartiﬁcial intelligence (AI) and machine learning (ML). Such AI\nand ML techniques have already transformed multiple ﬁelds—\ne.g., computer vision, natural language processing (NLP),\nspeech recognition, and optimal control (e.g., for developing\nautonomous self-driving vehicles)—with the success of these\ntechniques mainly attributed to ﬁrstly, signiﬁcant advances in\nunsupervised ML techniques such as deep learning, secondly,\nthe ready availability of large amounts of unstructured raw data\namenable to processing by unsupervised learning algorithms,\nand ﬁnally, advances in computing technologies through ad-\nvances such as cloud computing, graphics processing unit\n(GPU) technology and other hardware enhancements. It is\nanticipated that AI and ML will also make a similar impact\non the networking ecosystem and will help realize a future\nvision of cognitive networks [1] [2], in which networks will\nself-organize and will autonomously implement intelligent\nnetwork-wide behavior to solve problems such as routing,\nscheduling, resource allocation, and anomaly detection.\nThe initial attempts towards creating cognitive or intelligent\nnetworks have relied mostly on supervised ML methods, which\nare efﬁcient and powerful, but are limited in scope by their\nneed for labeled data. With network data becoming increas-\ningly voluminous (with a disproportionate rise in unstructured\nunlabeled data), there is a groundswell of interest in leveraging\nunsupervised ML methods to utilize unlabeled data, in addition\nto labeled data where available, to optimize network perfor-\nmance [12]. The rising interest in applying unsupervised ML\nin networking applications also stems from the need to liberate\nML applications from restrictive demands of supervised ML\nfor labeled networking data, which is expensive to curate\nat scale (since labeled data may be unavailable and manual\nannotation prohibitively inconvenient) in addition to being\nsuspect to being outdated quickly (due to the highly dynamic\nnature of computer networks) [13].\nWe are already witnessing the failure of human network\nadministrators to manage and monitor all bits and pieces of\nnetwork [14], and the problem will only exacerbate with fur-\nther growth in the size of networks with paradigms such as the\nInternet of things (IoT). An ML-based network management\nsystem (NMS) is desirable in such large networks so that\nfaults/bottlenecks/anomalies may be predicted in advance with\nreasonable accuracy. In this regard, networks already have\nample amount of untapped data, which can provide us with\ndecision-making insights making networks more efﬁcient and\nself-adapting. With unsupervised ML, the pipe dream is that\narXiv:1709.06599v1  [cs.NI]  19 Sep 2017\n2\nSurvey paper\nPublished In\nYear\n#\nRefer-\nences\nAreas Focused\nUnsupervised\nML\nDeep\nLearning\nPitfalls\nFuture\nChallenges\nPatcha et al. [3]\nElsevier\nComputer Networks\n2007\n100\nML for Network Intrusion Detec-\ntion\n≈\n×\n×\n√\nNguyen et al. [4]\nIEEE COMST\n2008\n68\nML for Internet Trafﬁc Classiﬁca-\ntion\n≈\n×\n×\n×\nBkassiny et al. [5]\nIEEE COMST\n2013\n177\nML for Cognitive Radios\n≈\n×\n×\n×\nAlsheikh et al. [6]\nIEEE COMST\n2015\n152\nML for WSNs\n≈\n×\n×\n√\nBuczak et al. [7]\nIEEE COMST\n2016\n113\nML for Cyber Security Intrusion\nDetection\n≈\n×\n×\n√\nKlaine et al. [8]\nIEEE COMST\n2017\n269\nML in SONs\n≈\n×\n×\n√\nMeshram et al. [9]\nSpringer\nBook Chapter\n2017\n16\nML for Anomaly Detection in In-\ndustrial Networks\n≈\n×\n×\n√\nFadlullah et al. [10]\nIEEE COMST\n2017\n260\nML for Network Trafﬁc Control\n≈\n√\n×\n√\nHodo et al. [11]\nArXiv\n2017\n154\nML Network Intrusion Detection\n≈\n√\n×\n×\nThis Paper\n-\n2017\n323\nUnsupervised ML in Networking\n√\n√\n√\n√\nTABLE I: Comparison of our paper with existing survey and review papers. (Legend: √means covered; × means not covered;\n≈means partially covered.)\nevery algorithm for adjusting network parameters (be it, TCP\ncongestion window or rerouting network trafﬁc in peak time)\nwill optimize itself in a self-organizing fashion according to\nthe environment and application, user, and network’s Quality of\nService (QoS) requirements and constraints [15]. Unsupervised\nML methods, in concert with existing supervised ML methods,\ncan provide a more efﬁcient method that lets a network\nmanage, monitor, and optimize itself, while keeping the human\nadministrators in the loop with the provisioning of timely\nactionable information.\nUnsupervised ML techniques facilitate the analysis of raw\ndatasets, thereby helping in generating analytic insights from\nunlabeled data. Recent advances in hierarchical learning, clus-\ntering algorithms, factor analysis, latent models, and outlier\ndetection, have helped signiﬁcantly advance the state of the\nart in unsupervised ML techniques. Unsupervised ML has\nmany applications such as feature learning, data clustering,\ndimensionality reduction, anomaly detection, etc. In particular,\nrecent unsupervised ML advances—such as the development\nof “deep learning” techniques [16]—have however signiﬁ-\ncantly advanced the ML state of the art by facilitating the\nprocessing of raw data without requiring careful engineering\nand domain expertise for feature crafting. The versatility of\ndeep learning and distributed ML can be seen in the diversity\nof their applications that range from self-driving cars to the\nreconstruction of brain circuits [16]. Unsupervised learning is\nalso often used in conjunction with supervised learning in a\nsemi-supervised learning setting to preprocess the data before\nanalysis and thereby help in crafting a good feature represen-\ntation and in ﬁnding patterns and structures in unlabeled data.\nThe rapid advances in deep neural networks, the democrati-\nzation of enormous computing capabilities through cloud com-\nputing and distributed computing, and the ability to store and\nprocess large swathes of data, have motivated a surging interest\nin applying unsupervised ML techniques in the networking\nﬁeld. The ﬁeld of networking also appears to be well suited\nto, and amenable to applications of unsupervised ML tech-\nniques, due to the largely distributed decision-making nature\nof its protocols, the availability of large amounts of network\ndata, and the urgent need for intelligent/cognitive networking.\nConsider the case of routing in networks. Networks these days\nhave evolved to be very complex, and they incorporate multiple\nphysical paths for redundancy and utilize complex routing\nmethodologies to direct the trafﬁc. Our application trafﬁc does\nnot always take the optimal path we would expect, leading to\nunexpected and inefﬁcient routing performance. To tame such\ncomplexity, unsupervised ML techniques can autonomously\nself-organize the network taking into account a number of\nfactors such as real-time network congestion statistics as well\nas application QoS requirements [17].\nThe purpose of this paper is to highlight the important\nadvances in unsupervised learning, and after providing a\ntutorial introduction to these techniques, to review how such\ntechniques have been, or could be, used for various tasks in\nmodern next-generation networks comprising both computer\nnetworks as well as mobile telecom networks.\nContribution of the paper: To the best of our knowledge,\nthere does not exist a survey that speciﬁcally focuses on\nthe important applications of unsupervised ML techniques in\nnetworks, even though a number of surveys exist that focus\non speciﬁc ML applications pertaining to networking—for\ninstance, surveys on using ML for cognitive radios [5], trafﬁc\nidentiﬁcation and classiﬁcation [4], anomaly detection [3] [9].\nPrevious survey papers have either focused on speciﬁc unsu-\npervised learning techniques (e.g., Ahad et al. [18] provided\na survey of the applications of neural networks in wireless\nnetworks) or on some speciﬁc applications of computer net-\nworking (Buczak and Guven [7] have provided a survey of\nthe applications of ML in cyber intrusion detection). Our\nsurvey paper is timely since there is great interest in deploying\nautomated and self-taught unsupervised learning models in the\nindustry and academia. Due to relatively limited applications\nof unsupervised learning in networking—in particular, the\ndeep learning trend has not yet impacted networking in a\nmajor way—unsupervised learning techniques hold a lot of\npromises for advancing the state of the art in networking in\nterms of adaptability, ﬂexibility, and efﬁciency. The novelty\nof this survey is that it covers many different important\napplications of unsupervised ML techniques in computer net-\nworks and provides readers with a comprehensive discussion\n3\nFig. 1: Outline of the Paper\nof the unsupervised ML trends, as well as the suitability of\nvarious unsupervised ML techniques. A tabulated comparison\nof our paper with other existing survey and review articles is\npresented in Table I.\nOrganization of the paper: The organization of this paper\nis depicted in Figure 1. Section II provides a discussion\non various unsupervised ML techniques (namely, hierarchi-\ncal learning, data clustering, latent variable models, outlier\ndetection and reinforcement learning). Section III presents a\nsurvey of the applications of unsupervised ML speciﬁcally in\nthe domain of computer networks. Section IV describes future\nwork and opportunities with respect to the use of unsupervised\nML in future networking. Section V discusses a few major\npitfalls of the unsupervised ML approach and its models.\nFinally, Section VI concludes this paper. For the reader’s\nfacilitation, Table II shows all the acronyms used in this survey\nfor convenient referencing.\nII.\nTECHNIQUES FOR UNSUPERVISED LEARNING\nIn this section, we will introduce some widely used unsuper-\nvised learning techniques and their applications in computer\nnetworks. We have divided unsupervised learning techniques\ninto ﬁve major categories: hierarchical learning, data cluster-\ning, latent variable models, outlier detection, and reinforcement\nlearning. Figure 2 depicts a taxonomy of unsupervised learning\ntechniques and also notes the relevant sections in which these\ntechniques are discussed.\nA. Hierarchical Learning\nHierarchical learning is deﬁned as learning simple and com-\nplex features from a hierarchy of multiple linear and nonlinear\nactivations. In learning models, a feature is a measurable\nproperty of the input data. Desired features are ideally infor-\nmative, discriminative, and independent. In statistics, features\nare also known as explanatory (or independent) variables [19].\nFeature learning (also known as data representation learning)\nis a set of techniques that can learn one or more features\nfrom input data [20]. It involves the transformation of raw\ndata into a quantiﬁable and comparable representation, which\nis speciﬁc to the property of the input but general enough\nfor comparison to similar inputs. Conventionally, features are\nhandcrafted speciﬁc to the application on hand. It relies on\ndomain knowledge but even then they do not generalize well to\nthe variation of real world data, which gives rise to automated\nlearning of generalized features from the underlying structure\nof the input data. Like other learning algorithms, feature\nlearning is also divided among domains of supervised and\nunsupervised learning depending on the type of available data.\nAlmost all unsupervised learning algorithms undergo a stage\nof feature extraction in order to learn data representation from\n4\nFig. 2: Taxonomy of Unsupervised Learning Techniques\nunlabeled data and generate a feature vector on the basis of\nwhich further tasks are performed.\nHierarchical learning is intimately related to two strongly\ncorrelated areas: deep learning and neural networks. In partic-\nular, deep learning techniques beneﬁts from the fundamental\nconcept of artiﬁcial neural networks (ANNs), a deep structure\nconsists of multiple hidden layers with multiple neurons in\neach layer, a nonlinear activation function, a cost function\nand a back-propagation algorithm. Deep learning [21] is a\nhierarchical technique that models high level abstraction in\ndata using many layers of linear and nonlinear transformations.\nWith deep enough stack of these transformation layers, a\nmachine can self-learn a very complex model or representation\nof data. Learning takes place in hidden layers and the optimal\nweights and biases of the neurons are updated in two passes,\nnamely, feed forward and back-propagation. A typical ANN\nand typical cyclic and acyclic topologies of interconnection\nbetween neurons are shown in Figure 3. A brief taxonomy of\nUnsupervised NNs is presented in Figure 4.\nAn ANN has three types of layers (namely input, hidden and\noutput, each having different activation parameters). Learning\nis the process of assigning optimal activation parameters\nenabling ANN to perform input to output mapping. For a\ngiven problem, an ANN may require multiple hidden layers\ninvolving long chain of computations, i.e., its depth [34]. Deep\nlearning has revolutionized ML and is now increasingly being\nused in diverse settings—e.g., object identiﬁcation in images,\nspeech transcription into text, matching user’s interests with\nitems (such as news items, movies, products) and making\nrecommendations, etc. But until 2006, relatively few people\nwere interested in deep learning due to the high computational\ncost of deep learning procedures. It was widely believed that\ntraining deep learning architectures in an unsupervised manner\nwas intractable, and supervised training of deep NNs (DNN)\nalso showed poor performance with large generalization errors\n[35]. However, recent advances [36]–[38] have shown that\ndeep learning can be performed efﬁciently by separate unsuper-\nvised pre-training of each layer with the results revolutionizing\nthe ﬁeld of ML. Starting from the input (observation) layer,\nwhich acts as an input to the subsequent layers, pre-training\ntends to learn data distributions while the usual supervised\nstage performs local search for ﬁne-tuning.\n1) Unsupervised Multilayer Feed Forward NN: Unsuper-\nvised multilayer feed forward NN, with reference to graph\ntheory, has a directed graph topology as shown in Figure 3. It\nconsists of no cycles, i.e., does not have feedback path in input\npropagation through NN. Such kind of NN is often used to\napproximate a nonlinear mapping between inputs and required\noutputs. Autoencoders are the prime examples of unsupervised\nmultilayer feed forward NNs.\na) Autoencoders:\nAn autoencoder is an unsupervised\nlearning algorithm for ANN used to learn compressed and\nencoded representation of data, mostly for dimensionality\nreduction and for unsupervised pre-training of feed forward\nNNs. Autoencoders are generally designed using approxima-\n5\nFig. 3: Illustration of an ANN (Left); Different types of ANN topologies (Right)\nFig. 4: Taxonomy of Unsupervised Neural Networks\ntion function and trained using backpropagation and stochastic\ngradient decent (SGD) techniques. Autoencoders are the ﬁrst\nof their kind to use back-propagation algorithm to train with\nunlabeled data. Autoencoders aim to learn compact represen-\ntation of the function of input using the same number of input\nand output units with usually less hidden units to encode a\nfeature vector. They learn the input data function by recreating\nthe input at the output, which is called encoding/decoding, to\nlearn at the time of training NN. In short, a simple autoencoder\nlearns low-dimensional representation of the input data by\nexploiting similar recurring patterns.\nAutoencoders have different variants [39] such as varia-\ntional autoencoders, sparse autoencoders, and denoising au-\ntoencoders. Variational autoencoder is an unsupervised learn-\ning technique used clustering, dimensionality reduction and\nvisualization, and for learning complex distributions [40]. In\na sparse autoencoder, a sparse penalty on the latent layer is\napplied for extracting unique statistical feature from unlabeled\ndata. Finally, denoising autoencoders are used to learn the\nmapping of a corrupted data point to its original location in\nthe data space in unsupervised manner for manifold learning\nand reconstruction distribution learning.\n2) Unsupervised Competitive Learning NN: Unsupervised\ncompetitive learning NNs is a winner-take-all neuron scheme,\nwhere each neuron competes for the right of the response to a\nsubset of the input data. This scheme is used to remove the re-\ndundancies from the unstructured data. Two major techniques\nof unsupervised competitive learning NNs are self-organizing\nmaps and adaptive resonance theory NNs.\nSelf-Organizing/ Kohonen Maps: Self-Organizing Maps\n(SOM), also known as Kohonen’s maps [41] [42], are a special\nclass of NNs that uses the concept of competitive learning,\nin which output neurons compete amongst themselves to be\n6\nTABLE II: List of common acronyms used\nADS\nAnomaly Detection System\nA-NIDS\nAnomaly & Network Intrusion Detection System\nAI\nArtiﬁcial Intelligence\nANN\nArtiﬁcial Neural Network\nART\nAdaptive Resonance Theory\nBSS\nBlind Signal Separation\nBIRCH\nBalanced Iterative Reducing and Clustering Using Hierarchies\nCDBN\nConvolutional Deep Belief Network\nCNN\nConvolutional Neural Network\nCRN\nCognitive Radio Network\nDBN\nDeep Belief Network\nDDoS\nDistributed Denial of Service\nDNN\nDeep Neural Network\nDNS\nDomain Name Service\nDPI\nDeep Packet Inspection\nEM\nExpectation-Maximization\nGTM\nGenerative Topographic Model\nGPU\nGraphics Processing Unit\nGMM\nGaussian Mixture Model\nHMM\nHidden Markov Model\nICA\nIndependent Component Analysis\nIDS\nIntrusion Detection System\nIoT\nInternet of Things\nLSTM\nLong Short-Term Memory\nLLE\nLocally Linear Embedding\nLRD\nLow Range Dependencies\nMARL\nMulti-Agent Reinforcement Learning\nML\nMachine Learning\nMLP\nMulti-Layer Perceptron\nMRL\nModel-based Reinforcement Learning\nMDS\nMulti-Dimensional Scaling\nMCA\nMinor Component Analysis\nNMF\nNon-Negative Matrix Factorization\nNMS\nNetwork Management System\nNN\nNeural Network\nNMDS\nNonlinear Multi-dimensional Scaling\nOSPF\nOpen Shortest Path First\nPU\nPrimary User\nPCA\nPrincipal Component Analysis\nPGM\nProbabilistic Graph Model\nQoE\nQuality of Experience\nQoS\nQuality of Service\nRBM\nRestricted Boltzmann Machine\nRL\nReinforcement Learning\nRLFA\nReinforcement Learning with Function Approximation\nRNN\nRecurrent Neural Network\nSDN\nSoftware Deﬁned Network\nSOM\nSelf-Organizing Map\nSON\nSelf-Organizing Network\nSVM\nSupport Vector Machine\nSON\nSelf Organizing Network\nSSAE\nShrinking Sparse Autoencoder\nTCP\nTransmission Control Protocol\nt-SNE\nt-Distributed Stochastic Neighbor Embedding\nTL\nTransfer Learning\nVoIP\nVoice over IP\nVoQS\nVariation of Quality Signature\nVAE\nVariational Autoencoder\nWSN\nWireless Sensor Network\nactivated in a real-valued output, results having only single\nneuron (or group of neurons), called winning neuron. This is\nachieved by creating lateral inhibition connections (negative\nfeedback paths) between neurons [43]. In this orientation, the\nnetwork determines the winning neuron within several itera-\ntions; subsequently it is forced to reorganize itself based on the\ninput data distribution (hence they are called Self-Organizing\nMaps). They were initially inspired by the human brain, which\nhas specialized regions in which different sensory inputs are\nrepresented/processed by topologically ordered computational\nmaps. In SOM, neurons are arranged on vertices of a lattice\n(commonly one or two dimensions). The network is forced to\nrepresent higher-dimensional data in lower-dimensional rep-\nresentation by preserving the topological properties of input\ndata by using neighborhood function while transforming the\ninput into a topological space in which neuron positions in the\nspace are representatives of intrinsic statistical features that tell\nus about the inherent nonlinear nature of SOMs.\nTraining a network comprising SOM is essentially a three-\nstage process after random initialization of weighted connec-\ntions. The three stages are as follow [44].\n•\nCompetition: Each neuron in the network computes its\nvalue using a discriminant function, which provides the\nbasis of competition among the neurons. Neuron with\nthe largest discriminant value in the competition group\nis declared the winner.\n•\nCooperation: The winner neuron then locates the center\nof the topological neighborhood of excited neurons in\nthe previous stage, providing a basis for cooperation\namong excited neighboring neurons.\n•\nAdaption: The excited neurons in the neighborhood\nincrease/decrease their individual values of discriminant\nfunction in regard to input data distribution through\nsubtle adjustments such that the response of the win-\nning neuron is enhanced for similar subsequent input.\nAdaption stage is distinguishable into two sub-stages: (1)\nthe ordering or self-organizing phase, in which weight\nvectors are reordered according to topological space;\nand (2) the convergence phase, in which the map is\nﬁne-tuned and declared accurate to provide statistical\nquantiﬁcation of the input space. This is the phase in\nwhich the map is declared to be converged and hence\ntrained.\nOne essential requirement in training a SOM is the redun-\ndancy of the input data to learn about the underlying structure\nof neuron activation patterns. Moreover, sufﬁcient quantity of\ndata is required for creating distinguishable clusters; with-\nstanding enough data for classiﬁcation problem, there exist a\nproblem of gray area between clusters and creation of inﬁnitely\nsmall clusters where input data has minimal patterns.\nAdaptive Resonance Theory: Adaptive Resonance Theory\n(ART) is another different category of NN models that is based\non the theory of human cognitive information processing. It\ncan be explained as an algorithm of incremental clustering\nwhich aims at forming multi-dimensional clusters, automat-\nically discriminating and creating new categories based on\ninput data. Primarily, ART models are classiﬁed as unsu-\npervised learning model; however, there exist ART variants\nthat employ supervised and hybrid learning approaches as\nwell. The main setback of most NN models is that they\nlose old information (updating/diminishing weights) as new\ninformation arrives, therefore an ideal model should be ﬂexible\nenough to accommodate new information without losing the\nold one, and this is called the plasticity-stability problem.\nART models provide a solution to this problem by self-\norganizing in real time and creating a competitive environment\nfor neurons, automatically discriminating/creating new clusters\n7\nTABLE III: Applications of Hierarchical Learning/ Deep Learning in Networking Applications\nReference\nTechnique\nBrief Summary\nInternet Trafﬁc Classiﬁcation\nLotfollahi et al. [22]\nSAE & CNN\nSAE and CNN were used for feature extraction from the Internet trafﬁc data for classiﬁcation and\ncharacterizing purpose.\nWang et al. [23]\nCNN\nCNN is used to extract features from the Internet trafﬁc where trafﬁc is considered as an image for\nmalware detection.\nYouseﬁet al. [24]\nAutoencoder\nAutoencoder is used as a generative model to learn the latent feature representation of network\ntrafﬁc vector, for cyber attack detection and classiﬁcation.\nAnomaly/Intrusion Detection\nAygun et al. [25]\nDenoising Autoen-\ncoder\nStochastically Improved autoencoder and denosing autoencoder are used to learn feature for zero\nday anomaly detection in Internet trafﬁc.\nPutchala et al. [26]\nRNN\nGated recurrent unit and random forest techniques are used for feature extraction and anomaly\ndetection in IoT data.\nTuor et al. [27]\nRNN\nRNN and DNN are employed to extract feature from raw data which then used for threat assessment\nand insider threat detection in data streams.\nNetwork Operations, Optimization and Analytics\nAguiar et al. [28]\nRandom\nNeural\nNetwork\nRandom neural network are used for extracting the quality behavior of multimedia application for\nimproving the QoE of multimedia applications in wireless mesh network.\nPiamrat et al. [29]\nRandom\nNeural\nNetwork\nRandom neural network are used for learning the mapping between QoE score and technical\nparameters so that it can give QoE score in real-time for multimedia applications in IEEE 802.11\nwireless networks.\nEmerging Networking Application of Unsupervised Learning\nKarra et al. [30]\nDNN&CNN\nHierarchical learning is used for feature extraction from spectrogram snap shots of signal for\nmodulation detection in communication system based on software deﬁned radio.\nZhang et al. [31]\nCNN\nConvolutional ﬁlters are used for feature extraction from cognitive radio waveforms for automatic\nrecognition.\nMoysen et al. [32]\nANN\nAuthors expressed ANN as a recommended system to learn the hierarchy of the output, which is\nlater used in SON.\nXie et al. [33]\nRNN\nRNN variant LSTM is used for learning memory based hierarchy of time interval based IoT sensor\ndata, from smart cities datasets.\namong neurons to accommodate any new information.\nART model resonates around (top-down) observer expecta-\ntions and (bottom-up) sensory information while keeping their\ndifference within the threshold limits of vigilance parameter,\nwhich in result is considered as the member of the expected\nclass of neurons [45]. Learning of an ART model primarily\nconsists of a comparison ﬁeld, recognition ﬁeld, vigilance\n(threshold) parameter and a reset module. The comparison\nﬁeld takes an input vector, which in result is passed, to best\nmatch in the recognition ﬁeld; the best match is the current\nwinning neuron. Each neuron in the recognition ﬁeld passes a\nnegative output in proportion to the quality of the match, which\ninhibits other outputs therefore exhibiting lateral inhibitions\n(competitions). Once the winning neuron is selected after a\ncompetition with the best match to the input vector, the reset\nmodule compares the quality of the match to the vigilance\nthreshold. If the winning neuron is within the threshold, it is\nselected as the output, else the winning neuron is reset and the\nprocess is started again to ﬁnd the next best match to the input\nvector. In case where no neuron is capable to pass the threshold\ntest, a search procedure begins in which the reset module\ndisables recognition neurons one at a time to ﬁnd a correct\nmatch whose weight can be adjusted to accommodate the new\nmatch, therefore ART models are called self-organizing and\ncan deal with the plasticity/stability dilemma.\n3) Unsupervised Deep NN: In recent years unsupervised\ndeep NN has become the most successful unsupervised struc-\nture due to its application in many benchmarking problems and\napplications [46]. Three major types of unsupervised deep NNs\nare deep belief NNs, deep autoencoders, and convolutional\nNNs.\nDeep Belief NN: Deep Belief Neural Network or simply\nDeep Belief Networks (DBN) is a probability based generative\ngraph model that is composed of hierarchical layers of stochas-\ntic latent variables having binary valued activations, which are\nreferred as hidden units or feature detectors. The top layers in\nDBNs have undirected, symmetric connections between them\nforming associative memory. DBNs provide a breakthrough in\nunsupervised learning paradigm. In the learning stage, DBN\nlearns to reconstruct its input, each layer acting as feature\ndetectors. DBN can be trained by greedy layer-wise training\nstarting from the top layer with raw input, subsequent layers\nare trained with the input data from the previous visible layer\n[36]. Once the network is trained in unsupervised manner\nand learned the distribution of the data, it can be ﬁne tuned\nusing supervised learning methods, or supervised layers can be\nconcatenated in order to achieve the desired task (for instance,\nclassiﬁcation).\nDeep Autoencoder: Another famous type of DBN is the deep\nautoencoder, which is composed of two symmetric DBNs—\n8\nthe ﬁrst of which is used to encode the input vector, while\nthe second decodes. By the end of the training of the deep\nautoencoder, it tends to reconstruct the input vector at the\noutput neurons, and therefore the central layer between both\nDBNs is the actual compressed feature vector.\nConvolutional NN: Convolutional NN (CNN) are feed for-\nward NN in which neurons are adapted to respond to overlap-\nping regions in two-dimensional input ﬁelds such as visual\nor audio input. It is commonly achieved by local sparse\nconnections among successive layers and tied shared weights\nfollowed by rectifying and pooling layers which results in\ntransformation invariant feature extraction. Another advantage\nof CNN over simple multilayer NN is that it is compara-\ntively easier to train due to sparsely connected layers with\nthe same number of hidden units. CNNs represent the most\nsigniﬁcant type of architecture for computer vision as they\nsolve two challenges with the conventional NNs: 1) scalable\nand computationally tractable algorithms are needed for pro-\ncessing high-dimensional images; and 2) algorithms should be\ntransformation invariant since objects in an image can occur\nat an arbitrary position. However, most CNNs are composed\nof supervised feature detectors in the lower and middle hidden\nlayers. In order to extract features in an unsupervised manner,\na hybrid of CNN and DBN, called Convolutional Deep Belief\nNetwork (CDBN), is proposed in [47]. Making probabilistic\nmax-pooling1 to cover larger input area and convolution as\nan inference algorithm makes this model scalable with higher\ndimensional input. Learning is processed in an unsupervised\nmanner as proposed in [37], i.e., greedy layer-wise (lower to\nhigher) training with unlabeled data.\nCDBN is a promising scalable generative model for learning\ntranslation invariant hierarchical representation from any high-\ndimensional unlabeled data in an unsupervised manner taking\nadvantage of both worlds, i.e., DBN and CNN. CNN, being\nwidely employed for computer vision applications, can be\nemployed in computer networks for optimization of Quality of\nExperience (QoE) and Quality of Service (QoS) of multimedia\ncontent delivery over networks, which is an open research\nproblem for next generation computer networks [48].\n4) Unsupervised Recurrent NN: Recurrent NN (RNN) is\nthe most complex type of NN, and hence the nearest match\nto an actual human brain that processes sequential inputs.\nIt can learn temporal behaviors of a given training data.\nRNN employs an internal memory per neuron to process such\nsequential inputs in order to exhibit the effect of previous event\non the next. Compared to feed forward NNs, RNN is a stateful\nnetwork. It may contain computational cycles among states,\nand uses time as the parameter in the transition function from\none unit to another. Being complex and recently developed, it\nis an open research problem to create domain-speciﬁc RNN\nmodels and train them with a sequential data. Speciﬁcally,\nthere are two perspectives of RNN to be discussed in the\nscope of this survey, namely, the depth of the architecture\nand the training of the network. The depth, in the case of a\n1Max-pooling is an algorithm of selecting the most responsive receptive\nﬁeld of a given interest region.\nsimple artiﬁcial NN, is the presence of hierarchical nonlinear\nintermediate layers between the input and output signals. In\nthe case of a RNN, there are different hypotheses explaining\nthe concept of depth. One hypothesis suggests that RNNs\nare inherently deep in nature when expanded with respect to\nsequential input; there are a series of nonlinear computations\nbetween the input at time t(i) and the output at time t(i + k).\nHowever, at an individual discrete time step, certain tran-\nsitions are neither deep nor nonlinear. There exist input-\nto-hidden, hidden-to-hidden, and hidden-to-output transitions,\nwhich are shallow in the sense that there are no intermediate\nnonlinear layers at discrete time step. In this regard, different\ndeep architectures are proposed in [49] that introduce interme-\ndiate nonlinear transitional layers in between the input, hidden\nand output layers. Another novel approach is also proposed by\nstacking hidden units to create hierarchical representation of\nhidden units, which mimic the deep nature of standard deep\nNNs.\nDue to the inherent complex nature of RNN, to the best\nof our knowledge, there is no widely adopted approach for\ntraining RNNs and many novel methods (both supervised\nand unsupervised) are introduced to train RNNs. Considering\nunsupervised learning of RNN in the scope of this paper,\nKlapper-Rybicka et al. [50] employ Long Short-term Memory\n(LSTM) RNN to be trained in an unsupervised manner using\nunsupervised learning algorithms, namely Binary Information\nGain Optimization and Non-Parametric Entropy Optimization,\nin order to make a network to discriminate between a set\nof temporal sequences and cluster them into groups. Results\nhave shown remarkable ability of RNNs for learning temporal\nsequences and clustering them based on a variety of features.\nTwo major types of unsupervised recurrent NN are Hopﬁeld\nNN and Boltzmann machine.\nHopﬁeld NN: Hopﬁeld NN is a cyclic recurrent NN where\neach node is connected to other. Hopﬁeld NN provides an\nabstraction of circular shift register memory with nonlinear\nactivation functions to form a global energy function with\nguaranteed convergence to local minima. Hopﬁeld NNs are\nused for ﬁnding clusters in the data without a supervisor.\nBoltzmann Machine: Boltzmann machine is a stochastic\nsymmetric recurrent NN that is used for search and learn-\ning problems. Due to binary vector based simple learning\nalgorithm of Boltzmann machine, very interesting features\nrepresenting the complex unstructured data can be learned\n[51]. Since Boltzmann machine uses multiple hidden layers\nas feature detectors, the learning algorithm becomes very\nslow. To avoid the slow learning and to achieve faster feature\ndetection instead of Boltzmann machine, a faster version,\nnamely restricted Boltzmann machine (RBM), is used for\npractical problems [52]. Restricted Boltzmann machine learns\na probability distribution over its input data. It is faster than a\nBoltzmann machine because it only uses one hidden layer as\nfeature detector layer. RBM is used for dimensionality reduc-\ntion, clustering and feature learning in computer networks.\n5) Signiﬁcant Applications of Hierarchical Learning in Net-\nworks: ANNs/DNNs are the most researched topic when creat-\n9\nFig. 5: Clustering process\ning intelligent systems in computer vision and natural language\nprocessing whereas their application in computer networks\nare very limited, they are employed in different networking\napplications such as classiﬁcation of trafﬁc, anomaly/intrusion\ndetection, detecting Distributed Denial of Service (DDoS)\nattacks, and resource management in cognitive radios [53]. The\nmotivation of using DNN for learning and predicting in net-\nworks is the unsupervised training that detects hidden patterns\nin ample amount of data that is near to impossible for a human\nto handcraft features catering for all scenarios. Moreover, many\nnew research shows that a single model is not enough for\nthe need of some applications, so developing a hybrid NN\narchitecture having pros and cons of different models creates\na new efﬁcient NN which provides even better results. Such\nan approach is used in [54], in which a hybrid model of ART\nand RNN is employed to learn and predict trafﬁc volume in a\ncomputer network in real time. Real-time prediction is essential\nto adaptive ﬂow control, which is achieved by using hybrid\ntechniques so that ART can learn new input patterns without\nre-training the entire network and can predict accurately in the\ntime series of RNN. Furthermore, DNNs are also being used\nin resource allocation and QoE/QoS optimizations. Using NN\nfor optimization, efﬁcient resource allocation without affecting\nthe user experience can be crucial in the time when resources\nare scarce. Authors of [55], [56] propose a simple DBN for\noptimizing multimedia content delivery over wireless networks\nby keeping QoE optimal for end users. Table III also provides\na tabulated description of hierarchical learning in networking\napplications. However, these are just a few notable examples\nof deep learning and neural networks in networks, refer to\nSection III for more applications and detailed discussion on\ndeep learning and neural networks in computer networks.\nB. Data Clustering\nClustering is an unsupervised learning task that aims to\nﬁnd hidden patterns in unlabeled input data in the form of\nclusters [57]. Simply put, it encompasses arrangement of data\nin meaningful natural groupings on the basis of the similarity\nbetween different features (as illustrated in Figure 5) to learn\nabout its structure. Clustering involves the organization of data\nin such a way that there is high intra-cluster and low inter-\ncluster similarity. The resulting structured data is termed as\ndata-concept [58]. Clustering is used in numerous applications\nfrom the ﬁelds of ML, data mining, network analysis, pattern\nrecognition and computer vision. The various techniques used\nfor data clustering are described in more detail later in Section\nII-B. In networking, clustering techniques are widely deployed\nfor applications such as trafﬁc analysis and anomaly detection\nin all kinds of networks (e.g., wireless sensor networks and\nmobile adhoc networks), with anomaly detection [59].\nClustering improves performance in various applications.\nMcGregor et al. [60] propose an efﬁcient packet tracing ap-\nproach using the Expectation-Maximization (EM) probabilistic\nclustering algorithm, which groups ﬂows (packets) into a small\nnumber of clusters, where the goal is to analyze network trafﬁc\nusing a set of representative clusters.\nA brief overview of different types of clustering methods\nand their relationships can be seen in Figure 6. Clustering can\nbe divided into three main types [61], namely hierarchical\nclustering, Bayesian clustering, and partitional clustering.\nHierarchical clustering creates a hierarchical decomposition\nof data, whereas Bayesian clustering forms a probabilistic\nmodel of the data that decides the fate of a new test point\nprobabilistically. In contrast, partitional clustering constructs\nmultiple partitions and evaluates them on the basis of certain\ncriterion or characteristic such as the Euclidean distance.\nBefore delving into the general sub-types of clustering,\nthere are two unique clustering techniques, which need to\nbe discussed, namely density-based clustering and grid-based\nclustering. In some cases, density-based clustering is classiﬁed\nas a partitional clustering technique; however, we have kept it\nseparate considering its applications in networking. Density-\nbased models target the most densely populated area of a\ndata space, and separates it from areas having low densities,\nthus forming clusters [62]. Chen and Tu [63] use density-\nbased clustering to cluster data stream in real time, which\nis important in many applications (e.g., intrusion detection in\nnetworks). Another technique is grid-based clustering, which\ndivides the data space into cells to form a grid-like structure;\nsubsequently, all clustering actions are performed on this grid\n[64]. Leung and Leckie [64] also present a novel approach\nthat uses customized grid-based clustering algorithm to detect\nanomalies in networks.\nWe move on next to describe three major types of data\nclustering approaches as per the taxonomy shown in Figure\n6.\n10\nFig. 6: Clustering Taxonomy\n1) Hierarchical Clustering:\nHierarchical clustering is a\nwell-known strategy in data mining and statistical analysis\nin which data is clustered into a hierarchy of clusters us-\ning an agglomerative (bottom up) or a divisive (top down)\napproach. Almost all hierarchical clustering algorithms are\nunsupervised and deterministic. The primary advantage of\nhierarchical clustering over unsupervised K-means and EM\nalgorithms is that it does not require the number of clusters\nto be speciﬁed beforehand. However, this advantage comes\nat the cost of computational efﬁciency. Common hierarchical\nclustering algorithms have at least quadratic computational\ncomplexity compared to the linear complexity of K-means\nand EM algorithms. Hierarchical clustering methods have a\npitfall: these methods fail to accurately classify messy high-\ndimensional data as its heuristic may fail due to the structural\nimperfections of empirical data. Furthermore, the computa-\ntional complexity of the common agglomerative hierarchical\nalgorithms is NP-hard. SOM, as discussed in Section II-A2,\nis a modern approach that can overcome the shortcomings of\nhierarchical models [65].\n2) Bayesian Clustering: Bayesian clustering is a proba-\nbilistic clustering strategy where the posterior distribution\nof the data is learned on the basis of a prior probability\ndistribution. Bayesian clustering is divided into two major\ncategories, namely parametric and non-parametric [66]. Major\ndifference between parametric and non-parametric techniques\nis the dimensionality of parameter space: if there are ﬁnite\ndimensions in the parameter space, the underlying technique\nis called Bayesian parametric; otherwise, the underlying tech-\nnique is called Bayesian non-parametric. A major pitfall with\nthe Bayesian clustering approach is that the choice of the\nwrong prior probability distributions can distort the projection\nof the data. Kurt et al. [67] performed Bayesian nonparametric\nclustering of network trafﬁc data to determine the network\napplication type.\n3) Partitional Clustering: Partitional clustering corresponds\nto a special class of clustering algorithms that decomposes\ndata into a set of disjoint clusters. Given n observations, the\nclustering algorithm partitions a data into k < n clusters\n[68]. Partitional clustering is further classiﬁed into K-means\nclustering and mixture models.\na) K-Means Clustering: K-means clustering is a simple,\nyet widely used approach for classiﬁcation. It takes a statistical\nvector as an input to deduce classiﬁcation models or classiﬁers.\nK-means clustering tends to distribute m observations into\nn clusters where each observation belongs to the nearest\ncluster. The membership of an observation to a cluster is\ndetermined using the cluster mean. K-means clustering is used\nin numerous applications in the domains of network analysis\nand trafﬁc classiﬁcation. Gaddam et al. [69] use K-means\nclustering in conjunction with supervised ID3 decision tree\nlearning models to detect anomalies in a network. ID3 decision\ntree is an iterative supervised decision tree algorithm based\non the concept learning system. K-means clustering provided\nexcellent results when used in trafﬁc classiﬁcation. Yingqiu et\nal. [70] show that K-means clustering performs well in trafﬁc\nclassiﬁcation with an accuracy of 90%.\nK-means clustering is also used in the domain of network\nsecurity and intrusion detection. Meng et al. [71] propose\na K-means algorithm for intrusion detection. Experimental\nresults on a subset of KDD-99 dataset show that detection\nrate stays above 96% while the false alarm rate stays below\n4%. Results and analysis of experiments on K-means algorithm\nhave demonstrated a better ability to search clusters globally.\nAnother variation of K-means is known as K-medoids, in\nwhich rather than taking the mean of the clusters, the most\ncentrally located data point of a cluster is considered as the\nreference point of the corresponding cluster [72]. Few of\nthe applications of K-medoids in the spectrum of anomaly\ndetection can be seen here [72] [73].\nb) Mixture Models: Mixture models are powerful prob-\nabilistic models for univariate and multivariate data. Mixture\nmodels are used to make statistical inferences and deductions\nabout the properties of the sub-populations given only ob-\nservations on the pooled population. They are also used to\nstatistically model data in the domains of pattern recognition,\n11\ncomputer vision, ML, etc. Finite mixtures, which are a basic\ntype of mixture model, naturally model observations that are\nproduced by a set of alternative random sources. Inferring and\ndeducing different parameters from these sources based on\ntheir respective observations lead to clustering of the set of\nobservations. This approach to clustering tackles drawbacks\nof heuristic based clustering methods, and hence it is proven\nto be an efﬁcient method for node classiﬁcation in any large-\nscale network and has shown to yield efﬁcient results compared\nto techniques commonly used. For instance, K-means and\nhierarchical agglomerative methods rely on supervised design\ndecisions, such as the number of clusters or validity of models\n[74]. Moreover, combining EM algorithm with mixture models\nproduces remarkable results in deciphering the structure and\ntopology of the vertices connected through a multi-dimensional\nnetwork [75]. Bahrololum et al. [76] used Gaussian mixture\nmodel (GMM) to outperform signature based anomaly detec-\ntion in network trafﬁc data.\n4) Signiﬁcant Applications of Clustering in Networks:\nClustering can be found in mostly all unsupervised learning\nproblems, and there are diverse applications of clustering in\nthe domain of computer networks. Two major networking\napplications where signiﬁcant use of clustering can be seen are\nintrusion detection and Internet trafﬁc classiﬁcation. One novel\nway to detect anomaly is proposed [77], and this approach\npreprocesses the data using Genetic Algorithm (GA) com-\nbined with hierarchical clustering approach called Balanced\nIterative Reducing using Clustering Hierarchies (BIRCH) to\nprovide an efﬁcient classiﬁer based on Support Vector Machine\n(SVM). This hierarchical clustering approach stores abstracted\ndata points instead of the whole dataset, thus giving more\naccurate and quick classiﬁcation compared to all past meth-\nods, producing better results in detecting anomalies. Another\napproach [64] discusses the use of grid-based and density-\nbased clustering for anomaly and intrusion detection using\nunsupervised learning. Basically, a scalable parallel framework\nfor clustering large datasets with high dimensions is proposed\nand then improved by inculcating frequency pattern trees. Ta-\nble IV also provides a tabulated description of data clustering\napplications in networks. These are just few notable examples\nof clustering approaches in networks: refer to Section III for\ndetailed discussion on some salient clustering applications in\nthe context of networks.\nC. Latent Variable Models\nA latent variable model is a statistical model that relates\nthe manifest variables with a set of latent or hidden variables.\nLatent variable model allows us to express relatively complex\ndistributions in terms of tractable joint distributions over an\nexpanded variable space [86]. Underlying variables of a pro-\ncess are represented in higher dimensional space using a ﬁxed\ntransformation, and stochastic variations are known as latent\nvariable models where the distribution in higher dimension\nis due to small number of hidden variables acting in a\ncombination [87]. These models are used for data visualization,\ndimensionality reduction, optimization, distribution learning,\nblind signal separation and factor analysis. Next we will begin\nour discussion on various latent variable models, namely mix-\nture distribution, factor analysis, blind signal separation, non-\nnegative matrix factorization, Bayesian networks & probabilis-\ntic graph models (PGM), hidden Markov model (HMM), and\nnonlinear dimensionality reduction techniques (which further\nincludes generative topographic mapping, multi-dimensional\nscaling, principal curves, Isomap, localliy linear embedding,\nand t-distributed stochastic neighbor embedding).\n1) Mixture Distribution: Mixture distribution is an important\nlatent variable model that is used for estimating the underly-\ning density function. Mixture distribution provides a general\nframework for density estimation by using the simpler para-\nmetric distributions. Expectation maximization (EM) algorithm\nis used for estimating the mixture distribution model [88],\nthrough a maximization of the log likelihood of the mixture\ndistribution model.\n2) Factor Analysis: Another important type of latent vari-\nable model is factor analysis, which is a density estimation\nmodel. It has been used quite often in collaborative ﬁltering\nand dimensionality reduction. It is different from other latent\nvariable models in terms of the allowed variance for different\ndimensions as most latent variable models for dimensionality\nreduction in conventional settings use a ﬁxed variance Gaus-\nsian noise model. In factor analysis model, latent variables\nhave diagonal covariance rather than isotropic covariance.\n3) Blind Signal Separation: Blind Signal Separation (BSS),\nalso referred to as Blind Source Separation, is the identiﬁcation\nand separation of independent source signals from mixed input\nsignals without or very little information about the mixing\nprocess. Figure 7 depicts the basic BSS process in which\nsource signals are extracted from a mixture of signals. It\nis a fundamental and challenging problem in the domain of\nsignal processing although the concept is extensively used in\nall types of multi-dimensional data processing. Most common\ntechniques employed for BSS are principal component analysis\n(PCA) and independent component analysis (ICA).\na) Principal Component Analysis (PCA) is a statistical\nprocedure that utilizes orthogonal transformation on the data to\nconvert n number of possibly correlated variables into lesser k\nnumber of uncorrelated variables named principal components.\nPrincipal components are arranged in the descending order of\ntheir variability, ﬁrst one catering for the most variable and the\nlast one for the least. Being a primary technique for exploratory\ndata analysis, PCA takes a cloud of data in n dimensions and\nrotates it such that maximum variability in the data is visible.\nUsing this technique, it brings out the strong patterns in the\ndataset so that these patterns are more recognizable thereby\nmaking the data easier to explore and visualize.\nPCA has primarily been used for dimensionality reduction\nin which input data of n dimensions is reduced to k dimensions\nwithout losing critical information in the data. The choice of\nthe number of principal components is a question of design\ndecision. Much research has been conducted on selecting the\nnumber of components such as cross-validation approxima-\ntions [89]. Optimally, k is chosen such that the ratio of the\naverage squared projection error to the total variation in the\n12\nTABLE IV: Applications of Data Clustering in Networking Applications\nReference\nTechnique\nBrief Summary\nInternet Trafﬁc Classiﬁcation\nAdda et al. [78]\nK-means & EM\nA comparative analysis of Network trafﬁc fault classiﬁcation is performed between K-means and\nEM techniques.\nVluaductu et al. [79]\nK-means\n&\nDissimilarity-based\nclustering\nSemi supervised approach for Internet trafﬁc classiﬁcation beneﬁts from K-means and dissimilarity-\nbased clustering as a ﬁrst step for the Internet trafﬁc classiﬁcation.\nLiu et al. [80]\nK-means\nA novel variant of K-means clustering namely recursive time continuity constrained K-Means\nclustering, is proposed and used for real-time In-App activity analysis of encrypted trafﬁc streams.\nExtracted feature vector of cluster centers are fed to random forest for further classiﬁcation.\nAnomaly/Intrusion Detection\nParwez et al. [81]\nK-means & Hierar-\nchical Clustering\nK-means and hierarchical clustering is used to detect anomalies in call detail records of mobile\nwireless networks data.\nLorido et al. [82]\nGMM\nGMM is used for detecting the anomalies that are affecting resources in cloud data centers.\nFrishman et al. [83]\nK-means\nK-means clustering is used for clustering the input data trafﬁc for load balancing for network security.\nDimensionality Reduction and Visualization\nKumar et al. [84]\nFuzzy Feature Clus-\ntering\nA new feature clustering based approach for dimensionality reduction of Internet trafﬁc for intrusion\ndetection is presented.\nWiradinata et al. [85]\nFuzzy C-mean clus-\ntering & PCA\nThis works combines data clustering technique combined with PCA is used for dimensionality\nreduction and classiﬁcation of the Internet trafﬁc.\nFig. 7: Blind signal separation (BSS): A mixed signal composed of various input signals mixed by some mixing process is\nblindly processed (i.e., with no or minimal information about the mixing process) to show the original signals.\ndata is less than or equal to 1% by which 99% of variance is\nretained in the k principal components. But, depending on the\napplication domain, different designs can increase/decrease the\nratio while maximizing the required output. Commonly, many\nfeatures of a dataset are often highly correlated; hence, PCA\nresults in retaining 99% of the variance while signiﬁcantly\nreducing the data dimensions.\nb) Independent Component Analysis (ICA) is another tech-\nnique for BSS that focuses in separating multivariate input data\ninto additive components with the underlying assumption that\nthe components are non-Gaussian and statistically independent.\nThe most common example to understand ICA is the cocktail\nparty problem in which there are n people talking simulta-\nneously in a room and one tries to listen to a single voice.\nICA actually separates source signals from input mixed signal\nby either minimizing the statistical dependence or maximizing\nthe non-Gaussian property among the components in the\ninput signals by keeping the underlying assumptions valid.\nStatistically, ICA can be seen as the extension of PCA, while\nPCA tries to maximize the second moment (variance) of data,\nhence relying heavily on Gaussian features; on the other hand,\nICA exploits inherently non-Gaussian features of the data and\ntries to maximize the fourth moment of linear combination of\ninputs to extract non-normal source components in the data\n[90].\n4) Non-Negative Matrix Factorization: Non-Negative Ma-\ntrix Factorization (NMF) is a technique to factorize a large\nmatrix into two or more smaller matrices with no negative\nvalues, that is when multiplied, it reconstructs the approximate\noriginal matrix. NMF is a novel method in decomposing multi-\nvariate data making it easy and straightforward for exploratory\nanalysis. By NMF, hidden patterns and intrinsic features within\nthe data can be identiﬁed by decomposing them into smaller\nchunks, enhancing the interpretability of data for analysis,\nwith positivity constraints. However, there exist many classes\nof algorithms [91] for NMF having different generalization\nproperties, for example, two of them are analyzed in [92], one\nof which minimizes the least square error and while the other\nfocuses on the Kullback-Leibler divergence keeping algorithm\nconvergence intact.\n13\n5) Hidden Markov Model: Hidden Markov Model (HMM)\nare stochastic models of great utility, especially in domains\nwhere we wish to analyze temporal or dynamic processes\nsuch as speech recognition, primary users (PU) arrival pattern\nin cognitive radio networks (CRNs), etc. HMMs are highly\nrelevant to CRNs since many environmental parameters in\nCRNs are not directly observable. An HMM-based approach\ncan analytically model a Markovian stochastic process in\nwhich we do not access to the actual states, which are assumed\nto be unobserved or hidden; instead, we can observe a state\nthat is stochastically dependent on the hidden state. It is for\nthis reason that an HMM is deﬁned to be a doubly stochastic\nprocess: ﬁrst, the underlying stochastic process is not observ-\nable; and second, another stochastic process, dependent on\nthe underlying stochastic process, that produces a sequence\nof observed symbols [93].\n6) Bayesian\nNetworks\n&\nProbabilistic\nGraph\nModels\n(PGM): In Bayesian learning we try to ﬁnd the posterior\nprobability distributions for all parameter settings, in this setup,\nwe ensure that we have a posterior probability for every\npossible parameter setting. It is computationally expensive\nbut we can use complicated models with small dataset and\nstill avoid overﬁtting. Posterior probabilities are calculated\nby dividing the product of sampling distribution and prior\ndistribution by marginal likelihood; in simple words posterior\nprobabilities are calculated using Bayes theorem. Basis of re-\ninforcement learning was also derived by using Bayes theorem\n[94]. Since Bayesian learning is computationally expensive\na new research trend is approximate Bayesian learning [95].\nAuthors in [96] has given a comprehensive survey of different\napproximate Bayesian inference algorithms. With the emer-\ngence of Bayesian deep learning framework the deployment\nof Bayes learning based solution is increasing rapidly.\nProbabilistic graph modeling is a concept associated with\nBayesian learning. A model representing the probabilistic\nrelationship between random variables through a graph is\nknown as probabilistic graph model (PGM). Nodes and edges\nin the graph represent a random variable and their probabilistic\ndependence, respectively. PGM are of two types: directed PGM\nand undirected PGM. Bayes networks also fall in the regime\nof directed PGM. PGM are used in many important areas such\nas computer vision, speech processing and communication\nsystems. Bayesian learning combined with PGM and latent\nvariable models forms a probabilistic framework where deep\nlearning is used as a substrate for making improved learning\narchitecture for recommender systems, topic modeling, and\ncontrol systems [97].\n7) Signiﬁcant Applications of Latent Variable Models in\nNetworks: In [98], authors have applied latent structure on\nemail corpus to ﬁnd interpretable latent structure as well as\nevaluating its predictive accuracy on missing data task. A\ndynamic latent model for social network is represented in [99].\nA characterization of the end-to-end delay using a Weibull\nmixture model is discussed in [100]. Mixture models for end\nhost trafﬁc analysis has been explored in [101]. BSS is a set of\nstatistical algorithms that are widely used in different applica-\ntion domains to perform different tasks such as dimensionality\nreduction, correlating and mapping features, etc. Yan et al.\n[102] employ PCA for Internet trafﬁc classiﬁcation in order to\nseparate different types of ﬂows in a network packet stream.\nSimilarly, authors of [103] employ PCA for feature learning\nand a supervised SVM classiﬁer for classiﬁcation in order to\ndetect intrusion in an autonomous network system. Another\napproach for detecting anomalies and intrusions proposed in\n[104] uses NMF to factorize different ﬂow features and cluster\nthem accordingly. Furthermore, ICA has been widely used\nin telecommunication networks to separate mixed and noisy\nsource signals for efﬁcient service. For example, [105] extends\na variant of ICA called Efﬁcient Fast ICA (EF-ICA) for\ndetecting and estimating the symbol signals from the mixed\nCDMA signals received from the source endpoint.\nIn other literature, PCA uses a probabilistic approach to\nﬁnd the degree of conﬁdence in detecting anomaly in wireless\nnetworks [106]. Furthermore, PCA is also chosen as a method\nof clustering and designing Wireless Sensor Networks (WSNs)\nwith multiple sink nodes [107]. However, these are just a few\nnotable examples of BSS in networks, refer to Section III for\nmore applications and detailed discussion on BSS techniques\nin the networking domain.\nBayesian learning has been applied for classifying the\nInternet trafﬁc, where Internet trafﬁc is classiﬁed based on the\nposterior probability distributions. Real discretized conditional\nprobability is used to construct a Bayesian classiﬁer for early\ntrafﬁc identiﬁcation in campus network has been proposed in\n[108]. Host level intrusion detection using Bayesian networks\nis proposed in [109]. Authors in [110] purposed a Bayesian\nlearning based feature vector selection for anomalies classi-\nﬁcation in BGP. Port scan attacks prevention scheme using\nBayesian learning approach is discussed in [111]. Internet\nthreat detection estimation system is presented in [112]. A\nnew approach towards outlier detection using Bayesian belief\nnetworks is described in [113]. Application of Bayesian net-\nworks in MIMO systems has been explored in [114]. Location\nestimation using Bayesian network in LAN is discussed in\n[115]. Similarly Bayes theory and PGM are both used in\nLow Density Parity Check (LDPC) and Turbo codes, which\nare the fundamental components of information coding theory.\nTable V also provides a tabulated description of latent variable\nmodels applications in networking.\nD. Dimensionality Reduction\nRepresenting data in fewer dimensions is another well-\nestablished task of unsupervised learning. Real world data\noften have high dimensions—in many datasets, these dimen-\nsions can run into thousands, even millions, of potentially\ncorrelated dimensions [125]. However, it is observed that the\nintrinsic dimensionality (governing parameters) of the data is\nless than the total number of dimensions. In order to ﬁnd the\nessential pattern of the underlying data by extracting intrinsic\ndimensions, it is necessary that the real essence is not lost;\ne.g., it may be the case that a phenomenon is observable\nonly in higher-dimensional data and is suppressed in lower\ndimensions, these phenomena are said to suffer from the curse\nof dimensionality [126]. While dimensionality reduction is\n14\nTABLE V: Applications of Latent Variable Models in Networking Applications\nReference\nTechnique\nBrief Summary\nInternet Trafﬁc Classiﬁcation\nLiu et al. [116]\nMixture\nDistribution\nAn improved EM algorithm is proposed which derives a better GMM and used for the Internet\ntrafﬁc classiﬁcation.\nShi et al. [117]\nPCA\nPCA based feature selection approach is used for the Internet trafﬁc classiﬁcation. Where PCA is\nemployed for feature selection and irrelevant feature removal.\nTroia et al. [118]\nNMF\nNMF based models are applied on the data streams to ﬁnd the trafﬁc patterns which frequently\noccurs in network for identiﬁcation and classiﬁcation of tidal trafﬁc patterns in metro area mobile\nnetwork trafﬁc.\nAnomaly/Intrusion Detection\nNie et al. [119]\nBayesian Networks\nBayesian networks are employed for anomaly and intrusion detection such as DDoS attacks in cloud\ncomputing networks.\nBang et al. [120]\nHidden\nSemi-\nMarkov Model\nHidden semi-Markov model is used to detect LTE signalling attack.\nNetwork Operations, Optimization and Analytics\nChen et al. [121]\nBayesian Networks\nScale-able Bayesian network models are used for data ﬂow monitoring and analysis.\nMokhtar et al. [122]\nHMM\nHMM and statistical analytic techniques combined with semantic analysis are used to propose a\nnetwork management tool.\nDimensionality Reduction and Visualization\nFurno et al. [123]\nPCA\n&\nFactor\nAnalysis\nPCA and factor analysis are used for dimensionality reduction and latent correlation identiﬁcation\nin mobile trafﬁc demand data.\nMalli et al. [124]\nPCA\nPCA is used for dimensionality reduction and orthogonal coordinates of the social media proﬁles\nin ranking the social media proﬁles.\nsometimes used interchangeably with feature selection [127]\n[128], a subtle difference exists between the two [129]. Feature\nselection is traditionally performed as a supervised task with a\ndomain expert helping in handcrafting a set of critical features\nof the data. Such an approach generally can perform well but\nis not scalable and prone to judgment bias. Dimensionality\nreduction, on the other hand, is more generally an unsupervised\ntask, where instead of choosing a subset of features, it creates\nnew features (dimensions) as a function of all features. Said\ndifferently, feature selection considers supervised data labels,\nwhile dimensionality reduction focuses on the data points and\ntheir distributions in N-dimensional space.\nThere exist different techniques for reducing data dimen-\nsions [130] including projection of higher dimensional points\nonto lower dimensions, independent representation, and sparse\nrepresentation, which should be capable of reconstructing the\napproximate data. Dimensionality reduction is useful for data\nmodeling, compression, and visualization. By creating repre-\nsentative functional dimensions of the data and eliminating\nredundant ones, it becomes easier to visualize and form a\nlearning model. Independent representation tries to disconnect\nthe source of variation underlying the data distribution such\nthat the dimensions of the representation are statistically in-\ndependent [21]. Sparse representation technique represents the\ndata vectors in linear combinations of small basis vectors.\nIt is worth noting here that many of the latent variable\nmodels (e.g., PCA, ICA, factor analysis) also function as tech-\nniques for dimensionality reduction. In addition to techniques\nsuch as PCA, ICA—which infer the latent inherent structure of\nthe data through a linear projection of the data—a number of\nnonlinear dimensionality reduction techniques have also been\ndeveloped and will be focused upon in this section to avoid\nrepetition of linear dimensionality reduction techniques that\nhave already been covered as part of the previous subsection.\nLinear dimensionality reduction techniques are useful in many\nsettings but these methods may miss important nonlinear\nstructure in the data due to their subspace assumption, which\nposits that the high-dimensional data points lie on a linear\nsubspace (for example, on a 2-D or 3D plane). Such an\nassumption fails in high dimensions when data points are\nrandom but highly correlated with neighbors. In such environ-\nments nonlinear dimensionality reductions through manifold\nlearning techniques—which can be construed as an attempt\nto generalize linear frameworks like PCA so that nonlinear\nstructure in data can also be recognized—become desirable.\nEven though some supervised variants also exist, manifold\nlearning is mostly performed in an unsupervised fashion using\nthe nonlinear manifold substructure learned from the high-\ndimensional structure of the data from the data itself without\nthe use of any predetermined classiﬁer or labeled data. Some\nnonlinear dimensionality reduction (manifold learning) tech-\nniques are described below:\n1) Isomap: Isomap is a nonlinear dimensionality reduction\ntechnique that ﬁnds the underlying low dimensional geometric\ninformation about the dataset. Algorithmic features of PCA\nand MDS are combined to learn the low dimensional nonlinear\nmanifold structure in the data [131]. Isomap uses geodesic\ndistance along the shortest path to calculate the low dimension\nrepresentation shortest path, which can be computed using\nDijkstra’s algorithm.\n2) Generative Topographic Model: Generative topographic\nmapping (GTM) represents the nonlinear latent variable map-\n15\nping from continuous low dimensional distributions embedded\nin high dimensional spaces [132]. Data space in GTM is rep-\nresented as reference vectors and these vectors are a projection\nof latent points in data space. It is a probabilistic variant of\nSOM and works by calculating the Euclidean distance between\ndata points. GTM optimizes the log likelihood function, and\nthe resulting probability deﬁnes the density in data space.\n3) Locally Linear Embedding: Locally linear embedding\n(LLE) [125] is an unsupervised nonlinear dimensionality re-\nduction algorithm. LLE represents the data in lower dimen-\nsions yet preserving the higher dimensional embedding. LLE\ndepicts data in single global coordinate of lower dimensional\nmapping of input data. LLE is used to visualize multi-\ndimensional dimensional manifolds and feature extraction.\n4) Principal Curves: Principal curves is a nonlinear dataset\nsummarizing technique where non-parametric curves passes\nthrough the middle of multi-dimensional dataset providing the\nsummary of the dataset [133]. These smooth curves minimize\nthe average squared orthogonal distance between data points,\nthis process also resembles to the maximum likelihood for\nnonlinear regression in the presence of Gaussian noise [134].\n5) Nonlinear Multi-dimensional Scaling: Nonlinear multi-\ndimensional scaling (NMDS) [135] is a nonlinear latent vari-\nable representation scheme. It works as an alternative scheme\nfor factor analysis. In factor analysis, a multivariate normal\ndistribution is assumed and similarities between different ob-\njects are expressed as a correlation matrix. Whereas NMDS\ndoes not impose such a condition, and it is designed to reach\nthe optimal low dimensional conﬁguration where similarities\nand dissimilarities among matrices can be observed. NMDS is\nalso used in data visualization and mining tools for depicting\nthe multi-dimensional data in 3 dimensions based on the\nsimilarities in the distance matrix.\n6) t-Distributed\nStochastic\nNeighbor\nEmbedding:\nt-\ndistributed stochastic neighbor embedding (t-SNE) is another\nnonlinear dimensionality reduction scheme. It is used to\nrepresent high dimensional data in 2 or 3 dimensions. t-SNE\nconstructs a probability distribution in high dimensional space\nand constructs a similar distribution in lower dimensions and\nminimizes the KullbackLeibler (KL) divergence between two\ndistributions (which is a useful way to measure the difference\nbetween two probability distributions) [136].\nTable VI also provides a tabulated description of dimension-\nality reduction applications in networking. The applications of\nnonlinear dimensionality reduction methods are later described\nin detail in Section III-D.\nE. Outlier Detection\nOutlier detection is an important application of unsupervised\nlearning. A sample point that is distant from other samples\nis called an outlier. An outlier may occur due to noise,\nmeasurement error, heavy tail distributions and mixture of two\ndistributions. There are two popular underlying techniques for\nunsupervised outlier detection upon which many algorithms\nare designed, namely nearest neighbor based technique and\nclustering based method.\n1) Nearest Neighbor Based Outlier Detection:\nNearest\nneighbor method works on estimating the Euclidean distances\nor average distance of every sample from all other samples\nin the dataset. There are many algorithms based on nearest\nneighbor based techniques, with the most famous extension of\nnearest neighbor being k-nearest neighbor technique in which\nonly k nearest neighbors participate in the outlier detection\n[146]. Local outlier factor is another outlier detection algo-\nrithm, which works as an extension of the k-nearest neighbor\nalgorithm. Connectivity based outlier factors [147], inﬂuenced\noutlierness [148], and local outlier probability models [149] are\nfew famous examples of the nearest neighbor based techniques.\n2) Cluster Based Outlier Detection: Clustering based meth-\nods use the conventional K-means clustering technique to\nﬁnd the dense locations in the data and then perform den-\nsity estimation on those clusters. After density estimation, a\nheuristic is used to classify the formed cluster according to\nthe cluster size. Anomaly score is computed by calculating the\ndistance between every point and its cluster head. Local density\ncluster based outlier factor [150], clustering based multivariate\nGaussian outlier score [151] [152] and histogram based outlier\nscore [153] are the famous cluster based outlier detection\nmodels in literature. SVM and PCA are also suggested for\noutlier detection in literature.\n3) Signiﬁcant Applications of Outlier Detection in Networks:\nOutlier detection algorithms are used in many different appli-\ncations such as intrusion detection, fraud detection, data leak-\nage prevention, surveillance, energy consumption anomalies,\nforensic analysis, critical state detection in designs, electrocar-\ndiogram and computed tomography scan for tumor detection.\nUnsupervised anomaly detection is performed by estimating\nthe distances and densities of the provided non-annotated data\n[154]. More applications of outlier detection schemes will be\ndiscussed in Section III\nF. Reinforcement Learning\nUnsupervised learning can also be applied in the context\nof optimization and decision-making. Reinforcement Learning\n(RL) is an ML technique that attempts to learn about the opti-\nmal action with respect to the dynamic operating environment\n[155]. Speciﬁcally, a decision maker (or an agent) observes\nstate and reward from the operating environment and takes the\nbest-known action, which leads to the optimal action as time\ngoes by. Due to the dynamicity of the operating environment,\nthe optimal action for the operating environment is expected\nto change; hence the need to learn about the optimal action\nfrom time to time. The state represents the decision-making\nfactors, and the reward represents the positive or negative\neffects of the selected action on the network performance. For\neach state-action pair, an agent keeps track of its Q-value,\nwhich accumulates the rewards for the action taken under the\nstate, as time goes by. The agent selects an optimal action,\nwhich has the highest Q-value, in order to optimize the network\nperformance. RL techniques can be broadly categorized as\nbeing either model-free or model-based [156]. We use the term\nmodel to refer to an abstraction used by the agent to predict\n16\nTABLE VI: Applications of Dimensionality Reduction in Networking Applications\nReference\nTechnique\nBrief Summary\nInternet Trafﬁc Classiﬁcation\nCao et al. [137]\nPCA & SVM\nInternet trafﬁc classiﬁcation model is proposed based on PCA and SVM, where PCA is employed\nfor dimensionality reduction and SVM for classiﬁcation.\nZhou et al. [138]\nSOM & Probabilis-\ntic NN\nProposed approach probabilistic neural network is used for dimensionality reduction and SOM are\nemployed for network trafﬁc classiﬁcation.\nAnomaly/Intrusion Detection\nErfani et al. [139]\nDBN\nDimensionality reduction of high dimensional feature set is performed by training a DBN as\nnonlinear dimensionality reduction tool for human activity recognition using smart phones.\nNicolau et al. [140]\nAutoencoders\nLatent representation learnt by using autoencoder is used for anomaly detection in network trafﬁc,\nwhich is performed by using single Gaussian and full kernel density estimation.\nIkram et al. [141]\nPCA & SVM\nA hybrid approach for intrusion detection is described, where PCA is used to perform dimensionality\nreduction operation on network data and SVM is used to detect intrusion in that low dimensional\ndata.\nNetwork Operations, Optimization and Analytics\nMoysen et al. [142]\nPCA\nPCA is used for low dimensional feature extraction in a mobile network planning tool based on\ndata analytic.\nOssia et al. [143]\nPCA & Simple Em-\nbedding\nPCA combined with simple embedding from deep learning is used for dimensionality reduction\nwhich reduces the communication overhead between client and server.\nDimensionality Reduction and Visualization\nRajendran et al. [144]\nt-SNE & LSTM\nLSTM is applied for modulation recognition in wireless data. t-SNE is used to perform dimension-\nality reduction and visualization of the wireless dataset’s FFT response.\nSarshar et al. [145]\nt-SNE & K-means\nt-SNE is used for visualizing a high dimensional Wi-Fi mobility data in 3D.\nhow the environment will respond to its actions—i.e., given\nthe state and the action performed therein by the agent, the\nmodel predicts stochastically the next state and the expected\nreward.\nTo apply RL, the RL model (embedded in each agent) is\nidentiﬁed by deﬁning the state, action, and reward represen-\ntations; this allows an agent access to a range of traditional\nand extended RL algorithms, such as the multi-agent approach.\nMost applications that apply RL take advantage of the beneﬁts\nbrought about by its intrinsic characteristics. Notably, RL\ntakes account of a wide range of dynamic factors (e.g., trafﬁc\ncharacteristics and channel capacity) affecting the network\nperformance (e.g., throughput) since the reward represents the\neffects to the network performance. Also, RL does not need\na model of the operating environment. This means that an\nagent can learn without prior knowledge about the operating\nenvironment. Nevertheless, the traditional RL approach comes\nwith some shortcomings, particularly its inability to achieve\nnetwork-wide performance enhancement, large number of\nstate-action pairs, and low convergence rate to the optimal\naction.\nIn recent times, there has been exciting developments in\ncombining RL and deep neutral networks to create a more\npowerful hybrid approach called “deep reinforcement learning”\nthat is also applicable to environments in which there are no\nhandcrafted features available or where state spaces are not\nfully observed and low dimensional. Such techniques have\nbeen used to achieve human-level control that comfortably\nsurpassed the performance of previous algorithms and achieved\na level compared to professional human games tester across\na set of 49 games including Atari 2600 games, using the\nsame algorithm, architecture, and hyper-parameters [157]. The\ngenerality of such an approach can be used proﬁtably and\napplied in the future in a number of networking settings. Next,\nwe show some popular extended RL models that have been\nadopted to address the shortcomings of the traditional RL\napproach.\n1) Multi-agent Reinforcement Learning: While the tradi-\ntional RL approach enables an individual agent to learn about\nthe optimal action that maximizes the local network perfor-\nmance, Multi-agent Reinforcement Learning (MARL) enables\na set of agents to learn about each other’s information, such\nas Q-values and rewards, via direct communication or predic-\ntion to learn about the optimal joint action that maximizes\nthe global performance [158]. A notable difference between\nMARL and the traditional RL approach is that both own and\nneighbors’ information is used to update Q-values in MARL,\nwhile only own information is used in the traditional RL\napproach. By using the neighbor agents’ information in the\nupdate of the Q-values, an agent takes account of the actions\ntaken by its neighbor agents. This is necessary because an\nagent’s action can affect and be affected by other agents’\nchoice of actions in a shared operating environment. As time\ngoes by, the agents select their respective action that is part\nof the joint action, which maximizes the global Q-value (or\nnetwork-wide performance) in a collaborative manner. Various\nkinds of information can be exchanged including the Q-value\nof the current action [159] and the maximum Q-value of the\ncurrent state (also called value function) [160].\n2) Reinforcement Learning with Function Approximation:\nThe traditional RL approach keeps track of the Q-values\n17\nof all state-action pairs in a tabular format. The number of\nstate-action pairs grows exponentially as the number of states\nand actions grow, resulting in increased stress on the storage\nrequirement of the Q-values. RL with function approximation\n(RLFA) represents the Q-values of the state-action pairs using\na signiﬁcantly smaller number of features. Each Q-value is\nrepresented using a feature, which consists of a set of mea-\nsurable properties of a state-action pair, and a weight vector,\nwhich consists of a set of tunable parameters used to adjust\nthe appropriateness of the feature [161].\n3) Model-based Reinforcement Learning: During normal\noperation, an agent must converge to the optimal action;\nhowever, the convergence rate can be unpredictable due to\nthe dynamicity of the operating environment. While increasing\nthe learning rate (or the dependence on the current reward\nrather than historical rewards) of the RL model can intuitively\nincrease the convergence rate, this can lead to the ﬂuctuation\nof the Q-values if the current reward changes signiﬁcantly\nparticularly when the dynamicity of the operating environment\nis high. The model-based RL (MRL) approach addresses this\nby creating a model of the operating environment, and uses it\nto compute and update its Q-values. One way to do this is to\nestimate the state transition probability, which is the probability\nof a transition from one state to another when an action is\nundertaken [160]. Another way to do this is to compute the\nprobability of the environment operating in a particular state\n[162]. The model of the operating environment can also serves\nas a learning tool.\n4) Q-learning: Q-learning, proposed by Watkins in 1992\n[163], is a popular model-free RL approach that allows an\nagent to learn how to act optimally with comparatively little\ncomputational requirements. In a Q-learning setting, the agent\ndirectly determines the optimal policy by mapping environ-\nmental states to actions without constructing the corresponding\nstochastic model of the environment [156]. Q-learning works\nby incrementally improving its estimation of the Q-values,\nwhich describe the quality of particular actions at particular\nstates estimated by learning a Q-function that gives the ex-\npected utility of taking a given action in a given state but\nfollowing the optimal policy thereafter.\n5) Signiﬁcant Applications of RL in Networks: RL has been\napplied in wide ranges of applications to optimize network\noperations due to its versatility. Using MARL, agents exchange\ninformation (e.g., actions, Q-values, value functions) among\nthemselves to perform target tracking where agents schedule\nand allocate target tracking tasks among themselves to keep\ntrack of moving objects in a WSN [159]. Using RLFA, an\nagent reduces the large number of state-action pairs, which\nrepresent the probability of a channel being available and\nselected for transmission in channel sensing [161]. Using\nMRL, an agent can compute the state transition probability,\nwhich is used to select a next-hop node for packet transmission\nin routing [164]. Another application of MRL is to compute\nthe probability of the operating environment operating in a\nparticular state, which is then used to select a channel to sense\nand access in order to reduce interference. RL has also been\nproposed as an aid for enhancing security schemes for CRNs\nthrough the detection of malicious nodes and their attacks\nthey launch [165]. Q-learning is another popular RL technique\nthat has been applied in the networking context—e.g., we\nhighlight one example application of Q-learning in the context\nof Heterogeneous Mobile Networks (HetNets) [166] in which\nthe authors proposed a fuzzy Q-learning based user-centric cell\nassociation scheme for ensuring appropriate QoS provisioning\nfor users with results improving the state of the art.\nG. Lessons Learnt\nKey lessons drawn from the review of unsupervised learning\ntechniques are summarized below.\n1) Hierarchical learning techniques are the most popular\nschemes in literature for feature detection and extraction.\n2) Learning the joint distribution of a complex distribution\nover an expanded variable space is a difﬁcult task. Latent\nvariable models have been the recommended and well-\nestablished schemes in literature for this problem. These\nmodels are also used for dimensionality reduction and\nbetter representation of data.\n3) Visualization of unlabeled multidimensional data is an-\nother unsupervised task. In this research we have explored\nthe dimensionality reduction as a underlying scheme for\ndeveloping a better multidimensional data visualization\ntools.\n4) Reinforcement learning schemes for learning, decision-\nmaking, and network performance evaluation have also\nbeen surveyed and its potential application in network\nmanagement and optimization is considered a potential\nresearch area.\nIII.\nAPPLICATIONS OF UNSUPERVISED LEARNING IN\nNETWORKING\nIn this section, we will introduce some signiﬁcant applica-\ntions of the unsupervised learning techniques that have been\ndiscussed in Section II in the context of computer networks.\nWe highlight the broad spectrum of applications in networking\nand emphasize the importance of ML-based techniques, rather\nthan classical hard-coded statistical methods, for achieving\nmore efﬁciency, adaptability, and performance enhancement.\nA. Internet Trafﬁc Classiﬁcation\nInternet trafﬁc classiﬁcation is of prime importance in\nnetworking as it provides a way to understand, develop and\nmeasure the Internet. Internet trafﬁc classiﬁcation is an im-\nportant component for service providers to understand the\ncharacteristics of the service such as quality of service, quality\nof experience, user behavior, network security and many other\nkey factors related to overall structure of the network [173].\nIn this subsection, we will survey the unsupervised learning\napplications in network trafﬁc classiﬁcation.\nAs networks evolve at a rapid pace, the malicious intruders\nare also evolving their strategies. Numerous novel hacking and\nintrusion techniques are being regularly introduced causing\nsevere ﬁnancial jolts to companies and headaches to their\n18\nTABLE VII: Internet Trafﬁc Classiﬁcation with respect to Unsupervised Learning Techniques and Tasks\nReference\nTechnique\nTask\nBrief Summary\nZhang et al. [167]\nNon Parametric NN\nHierarchical Representa-\ntions/ Deep Learning\nApplied statistical correlation with non parametric NN to produce efﬁcient and\nadaptive results in trafﬁc classiﬁcation.\nMcGregor et al. [60]\nEM-based clustering\nData clustering\nApplied EM probabilistic algorithm to cluster ﬂows based on various attributes\nsuch as byte counts, inter-arrival statistics, etc. in ﬂow classiﬁcation.\nErman et al. [168]\nEM-based clustering\nData clustering\nApplied EM-based clustering approach to yield 9% better results compared to\nsupervised Na¨ıve Bayes based approach in trafﬁc classiﬁcation.\nYingqiu et al. [70]\nK-Means\nData clustering\nApplied K-means clustering algorithm to produce an overall 90% accuracy in\nInternet trafﬁc classiﬁcation in a completely unsupervised manner.\nKornycky et al. [169]\nGMM\nData Clustering\nGMM with universal background model is used for encrypted WLAN trafﬁc\nclassiﬁcation.\nLiu et al. [170]\nGMM\nData Clustering\nGMM and Kerner’s trafﬁc theory based ML model is used to evaluate real-time\nInternet trafﬁc performance.\nErman et al. [171]\nK-Means, DBSCAN\nData clustering\nApplied cluster analysis to effectively identify similar trafﬁc using transport\nlayer statistics to overcome the problem of dynamic port allocation in port based\nclassiﬁcation.\nGuyen et al. [172]\nNa¨ıve Bayes clustering\nData clustering\nApplied Na¨ıve Bayes clustering algorithm in trafﬁc classiﬁcation.\nYan et al. [102]\nPCA\nBlind Signal Separation\nApplied PCA and fast correlation based ﬁlter algorithm that yields more accurate\nand stable experimental results in Internet trafﬁc ﬂow classiﬁcation.\nadministrators. Tackling these unknown intrusions through\naccurate trafﬁc classiﬁcation on the network edge therefore\nbecomes a critical challenge and an important component of\nnetwork security domain. Initially, when networks used to\nbe small, simple port based classiﬁcation technique that tried\nto identify the associated application with the corresponding\npacket based on its port number was used. However, this\napproach is now obsolete because recent malicious softwares\nuse dynamic port-negotiation mechanism to bypass ﬁrewalls\nand security applications. A number of contrasting Internet\ntrafﬁc classiﬁcation techniques have been proposed since then,\nand some important ones are discussed next.\nMost of the modern trafﬁc classiﬁcation methods use differ-\nent ML and clustering techniques to produce accurate clusters\nof packets depending on their applications, thus producing efﬁ-\ncient packet classiﬁcation [4]. The main purpose of classifying\nnetwork’s trafﬁc is to recognize the destination application of\nthe corresponding packet and to control the ﬂow of the trafﬁc\nwhen needed such as prioritizing one ﬂow over others. Another\nimportant aspect of trafﬁc classiﬁcation is to detect intrusions\nand malicious attacks or screen out forbidden applications\n(packets).\nFirst step in classifying Internet trafﬁc is selecting accu-\nrate features, which is an extremely important, yet complex\ntask. Accurate feature selection helps ML algorithms to avoid\nproblems like class imbalance, low efﬁciency and low classi-\nﬁcation rate. There are three major feature selection methods\nin Internet trafﬁc for classiﬁcation: namely, the ﬁlter method,\nthe wrapper based method, and the embedded method. These\nmethods are based on different ML and genetic learning\nalgorithms [174]. Two major concerns in feature selection for\nInternet trafﬁc classiﬁcation are the large size of data and\nimbalanced trafﬁc classes. To deal with these issues and to\nensure accurate feature selection, a min-max ensemble feature\nselection scheme is proposed in [175]. A new information\ntheoretic approach for feature selection for skewed datasets\nis described in [176]. This algorithm has resolved the multi-\nclass imbalance issue but it does not resolve the issues of\nfeature selection. In 2017, an unsupervised autoencoder based\nscheme has outperformed previous feature learning schemes,\nautoencoders were used as a generative model and were trained\nin a way that the bottleneck layer learnt a latent representation\nof the feature set; these features were then used for malware\nclassiﬁcation and anomaly detection to produce results that\nimproved the state of the art in feature selection [24].\nMuch work has been done on classifying trafﬁc based on\nsupervised ML techniques. Initially in 2004, the concept of\nclustering bi-directional ﬂows of packets came out with the use\nof EM probabilistic clustering algorithm, which clusters the\nﬂows depending on various attributes such as packet size statis-\ntics, inter-arrival statistics, byte counts, and connection dura-\ntion, etc. [60]. Furthermore, clustering is combined with the\nabove model [172]; this strategy uses Na¨ıve Bayes clustering to\nclassify trafﬁc in an automated fashion. Recently, unsupervised\nML techniques have also been introduced in the domain of\nnetwork security for classifying trafﬁc. Major developments\ninclude a hybrid model to classify trafﬁc in more unsupervised\nmanner [177], which uses both labeled and unlabeled data\nto train the classiﬁer making it more durable and efﬁcient.\nHowever, later on, completely unsupervised methods for trafﬁc\nclassiﬁcation have been proposed, and still much work is going\non in this area. Initially, completely unsupervised approach for\ntrafﬁc classiﬁcation was employed using K-means clustering\nalgorithm combined with log transformation to classify data\ninto corresponding clusters. Then, [70] highlighted that using\nK-means and this method for trafﬁc classiﬁcation can improve\naccuracy by 10% to achieve an overall 90% accuracy.\nAnother improved and faster approach was proposed in\n2006 [178], which examines the size of the ﬁrst ﬁve packets\nand determines the application correctly using unsupervised\nlearning techniques. This approach has shown to produce\nbetter results than the state-of-the-art trafﬁc classiﬁer, and\nalso has removed its drawbacks (such as dealing with outliers\nor unknown packets, etc.). Another similar automated trafﬁc\nclassiﬁer and application identiﬁer can be seen in [179], and\nthey use the auto-class unsupervised Bayesian classiﬁer, which\n19\nautomatically learns the inherent natural classes in a dataset.\nIn 2013, another novel strategy for trafﬁc classiﬁcation\nknown as network trafﬁc classiﬁcation using correlation was\nproposed [167], which uses non-parametric NN combined\nwith statistical measurement of correlation within data to\nefﬁciently classify trafﬁc. The presented approach addressed\nthe three major drawbacks of supervised and unsupervised\nlearning classiﬁcation models: ﬁrstly, they are inappropriate\nfor sparse complex networks as labeling of training data takes\ntoo much computation and time; secondly, many supervised\nschemes such as SVM are not robust to training data size; and\nlastly, and most importantly, all supervised and unsupervised\nalgorithms perform poorly if there are few training samples.\nThus, classifying the trafﬁc using correlations appears to be\nmore efﬁcient and adapting. Oliveira et al. [180] compared four\nANN approaches for computer network trafﬁc, and modeled\nthe Internet trafﬁc as a time series and used mathematical\nmethods to predict the time series. A greedy layer-wise train-\ning for unsupervised stacked autoencoder produced excellent\nclassiﬁcation results, but at the cost of signiﬁcant system\ncomplexity. Genetic algorithm combined with constraint clus-\ntering process are used for Internet trafﬁc data characterization\n[181]. In another work, a two-phased ML approach for Internet\ntrafﬁc classiﬁcation using K-means and C5.0 decision tree is\npresented in [182] where the average accuracy of classiﬁcation\nwas 92.37%.\nA new approach for Internet trafﬁc classiﬁcation has been in-\ntroduced in 2017 by Vl˘adut¸u et al. [79] in which unidirectional\nand bidirectional information is extracted from the collected\ntrafﬁc, and K-means clustering is performed on the basis of sta-\ntistical properties of the extracted ﬂows. A supervised classiﬁer\nthen classiﬁes these clusters. Another unsupervised learning\nbased algorithm for Internet trafﬁc detection is described in\n[183] where a restricted Boltzmann machine based SVM is\nproposed for trafﬁc detection, this paper models the detection\nas classiﬁcation problem. Results were compared with ANN\nand decision tree algorithms on the basis of precision and\nF1 score. Application of deep learning algorithms in Internet\ntrafﬁc classiﬁcation has been discussed in [10], with this work\nalso outlining the open research challenges in applying deep\nlearning for Internet trafﬁc classiﬁcation. These problems are\nrelated to training the models for big data since Internet\ndata for deep learning falls in big data regime, optimization\nissues of the designed models given the uncertainty in Internet\ntrafﬁc and scalability of deep learning architectures in Internet\ntrafﬁc classiﬁcation. To cope with the challenges of devel-\noping a ﬂexible high-performance platform that can capture\ndata from a high speed network operating at more than 60\nGbps, Gonzalez et al. [184] have introduced a platform for\nhigh speed packet to tuple sequence conversion which can\nsigniﬁcantly advance the state of the art in real-time network\ntrafﬁc classiﬁcation. In another work, Aminanto and Kim [185]\nused stacked autoencoders for Internet trafﬁc classiﬁcation and\nproduced more than 90% accurate results for the two classes\nin KDD 99 dataset.\nDeep belief network combined with Gaussian model em-\nployed for Internet trafﬁc prediction in wireless mesh backbone\nnetwork has been shown to outperform the previous maximum\nlikelihood estimation technique for trafﬁc prediction [186].\nGiven the uncertainty of WLAN channel trafﬁc classiﬁcation is\nvery tricky, [169] proposed a new variant of Gaussian mixture\nmodel by incorporating universal background model and used\nit for the ﬁrst time to classify the WLAN trafﬁc. A brief\noverview of the different Internet trafﬁc classiﬁcation systems,\nclassiﬁed on the basis of unsupervised technique and tasks\ndiscussed earlier, is presented in the Table VII.\nB. Anomaly/Intrusion Detection\nThe increasing use of networks in every domain has in-\ncreased the risk of network intrusions, which makes user pri-\nvacy and the security of critical data vulnerable to attacks. Ac-\ncording to the annual computer crime and security survey 2005\n[203], conducted by the combined teams of CSI (Computer\nSecurity Institute) and FBI (Federal Bureau of Investigation),\ntotal ﬁnancial losses faced by companies due to the security\nattacks and the network intrusions were estimated as US $130\nmillion. Moreover, according to Symantec Internet Security\nThreat Report [204], approximately 5000 new vulnerabilities\nwere identiﬁed in the year 2015. In addition, more than 400\nmillion new variants of malware and 9 major breaches were\ndetected exposing 10 million identities. Therefore, insecurity\nin today’s networking environment has given rise to the ever-\nevolving domain of network security and intrusion/anomaly\ndetection [204].\nIn general, Intrusion Detection Systems (IDS) recognize or\nidentify any act of security breach within a computer or a\nnetwork; speciﬁcally, all requests which could compromise the\nconﬁdentiality and availability of data or resources of a system\nor a particular network. Generally, intrusion detection systems\ncan be categorized into three types: (1) signature-based intru-\nsion detection systems; (2) anomaly detection systems; and (3)\ncompound/hybrid detection systems, which include selective\nattributes of both preceding systems.\nSignature detection, also known as misuse detection, is a\ntechnique that was initially used for tracing and identifying\nmisuses of user’s important data, computer resources, and\nintrusions in the network based on the previously collected\nor stored signatures of intrusion attempts. The most important\nbeneﬁt of a signature-based system is that a computer admin-\nistrator can exactly identify the type of attack a computer is\ncurrently experiencing based on the sequence of the packets\ndeﬁned by stored signatures. However, it is nearly impossible\nto maintain the signature database of all evolving possible\nattacks, thus this pitfall of the signature-based technique has\ngiven rise to anomaly detection systems.\nAnomaly Detection System (ADS) is a modern intrusion and\nanomaly detection system. Initially, it creates a baseline image\nof a system proﬁle, its network and user program activity.\nThen, on the basis of this baseline image, ADS classiﬁes\nany activity deviating from this behavior as an intrusion.\nFew beneﬁts of this technique are: ﬁrstly, they are capable\nof detecting insider attacks such as using system resources\nthrough another user proﬁle; secondly, each ADS is based on\na customized user proﬁle which makes it very difﬁcult for\nattackers to ascertain which types of attacks would not set an\n20\nTABLE VIII: Anomaly & Network Intrusion Detection Systems (A-NIDS) with respect to Unsupervised Learning Techniques\nReference\nTechnique\nBrief Summary\nHierarchical Representations/ Deep Learning\nZhang et al. [187]\nHierarchical NN\nApplied radial basis function in a two layered hierarchical IDS to detect intruders in real time.\nRhodes et al. [188]\nSOM\nAdvocated unsupervised NNs such as SOM to provide a powerful supplement to existing IDSs.\nKayacik et al. [189]\nSOM\nOverviewed the capabilities of SOM and its application in IDS.\nZanero & Stefano [190]\nSOM\nAnalyzed TCP data trafﬁc patterns using SOM and detected anomalies based on abnormal behavior.\nLichodzijewski et al. [191]\nSOM\nApplied SOM to host based intrusion detection.\nLichodzijewski et al. [192]\nSOM\nApplied a hierarchical NN to detect intruders, emphasizing on the development of relational hierarchies and\ntime representation.\nAmini et al. [193]\nSOM & ART\nApplied SOM combined with ART networks in real-time IDS.\nDepren et al. [194]\nSOM & J.48 Decision Tree\nApplied SOM combined with J.48 decision tree algorithm in IDS to detect anomaly and misuses intelligently.\nGolovko et al. [195]\nMulti-Layer Perceptrons (MLP)\nPresented a two-tier IDS architecture. PCA in the ﬁrst tier reduces input dimensions, while MLP in the second\ntier detects and recognizes attacks with low detection time and high accuracy.\nData Clustering\nLeung et al. [64]\nDensity & Grid Based Clustering\nApplied an unsupervised clustering strategy in density and grid based clustering algorithms to detect anomalies.\nChimphlee et al. [77]\nFuzzy Rough Clustering\nApplied the idea of Fuzzy set theory and fuzzy rough C-means clustering algorithms in IDS to detect abnormal\nbehaviors in networks, producing excellent results.\nJianliang et al. [71]\nK-Means\nApplied K-means clustering in IDS to detect intrusions and anomalies.\nMuniyandi et al. [196]\nK-Means\nwith\nC4.5\nDecision\nTrees\nApplied K-means clustering combined with C4.5 decision tree models to detect intrusive and anomalous\nbehavior in networks and systems.\nCasas et al. [197]\nSub-space Clustering\nImplemented a unique unsupervised outliers and anomaly detection approach using Sub-Space Clustering\nand Multiple Evidence Accumulation techniques to exactly identify different kinds of network intrusions and\nattacks such as DoS/DDoS, probing attacks, buffer overﬂows, etc.\nZanero et al. [198]\nTwo-Tier Clustering\nApplied a novel bi-layered clustering technique, in which the ﬁrst layer constitutes of clustering of packets\nand the second layer is responsible for anomaly detection and time correlation, to detect intrusions.\nGaddam et al. [69]\nK-Means & ID3 Decision Trees\nApplied K-means clustering combined with ID3 decision tree models to detect intrusive and anomalous\nbehavior in systems.\nZhong et al. [199]\nCentroid Based Clustering\nPresented a survey on intrusion detection techniques based on centroid clustering as well as other popular\nunsupervised approaches.\nGreggio et al. [200]\nFinite GMM\nAn unsupervised greedy learning of ﬁnite GMM is used for anomaly detection in intrusion detection system.\nBlind Signal Separation\nXu et al. [103]\nPCA\nApplied PCA and SVM in IDS.\nWang et al. [201]\nPCA\nApplied a novel approach to translate each network connection into a data vector, and then applied PCA to\nreduce its dimensionality and detect anomalies.\nGolovko et al. [202]\nPCA\nApplied PCA and dimensionality reduction techniques in attack recognition and anomaly detection.\nGuan et al. [104]\nNMF\nApplied NMF algorithms to capture intrusion and network anomalies.\nalarm; and lastly, it detects unknown behavior in a computer\nsystem rather than detecting intrusions, thus it is capable of\ndetecting any unknown sophisticated attack which is different\nfrom the users’ usual behavior. However, these beneﬁts come\nwith a trade-off, in which the process of training a system on\na user’s ‘normal’ proﬁle and maintaining those proﬁles is a\ntime consuming and challenging task. If an inappropriate user\nproﬁle is created, it can result in poor performance. Since ADS\ndetects any behavior that does not align with a user’s normal\nproﬁle, its false alarm rate can be high. Lastly, another pitfall\nof ADS is that a malicious user can train ADS gradually to\naccept inappropriate trafﬁc as normal.\nAs anomaly and intrusion detection has been a popular\nresearch area since the origin of networking and Internet,\nnumerous supervised as well as unsupervised [205] learning\ntechniques have been applied to efﬁciently detect intrusions\nand malicious activities. However, latest research focuses on\nthe application of unsupervised learning techniques in this\narea due to the challenge and promise of using big data for\noptimizing networks.\nInitial work focuses on the application of basic unsupervised\nclustering algorithms for detecting intrusions and anomalies. In\n2005, an unsupervised approach was proposed based on den-\nsity and grid based clustering to accurately classify the high-\ndimensional dataset in a set of clusters; those points which\ndo not fall in any cluster are marked as abnormal [64]. This\napproach has produced good results but false positive rate was\nvery high. In a follow-up work, another improved approach\nthat used fuzzy rough C-means clustering was introduced [77]\n[199]. K-means clustering is also another famous approach\nused for detecting anomalies which was later proposed in\n2009 [71], which showed great accuracy and outperformed\nexisting unsupervised methods. However, later in 2012, an im-\nproved method which used K-means clustering combined with\nC4.5 decision tree algorithm was proposed [196] to produce\nmore efﬁcient results than prior approaches. [206] combines\ncluster centers and nearest neighbors for effective feature\nrepresentation which ensures a better intrusion detection, a\nlimitation with this approach is that it is not able to detect\nuser to resource and remote to local attacks. Another scheme\nusing unsupervised learning approach for anomaly detection is\npresented in [207]. The presented scheme combines subspace\nclustering and correlation analysis to detect anomalies and\nprovide protection against unknown anomalies; this experiment\nused WIDE backbone networks data [208] spanning over six\nyears and produced better results then previous K-means based\n21\ntechniques. Work presented in [209] shows that for different\nintrusions schemes, there are a small set of measurements\nrequired to differentiate between normal and anomalous trafﬁc;\nthe authors used two co-clustering schemes to perform clus-\ntering and to determine which measurement subset contributed\nthe most towards accurate detection.\nAnother famous approach for increasing detection accuracy\nis ensemble learning, work presented in [210] employed many\nhybrid incremental ML approach with gradient boosting and\nensemble learning to achieve better detection performance.\nAuthors in [211] surveyed anomaly detection research from\n2009 to 2014 and ﬁnd out the a unique algorithmic simi-\nlarity for anomaly detection in Internet trafﬁc: most of the\nalgorithms studied have following similarities 1) Removal\nof redundant information in training phase to ensure better\nlearning performance 2) Feature selection usually performed\nusing unsupervised techniques and increases the accuracy of\ndetection 3) Use ensembles classiﬁers or hybrid classiﬁers\nrather than baseline algorithms to get better results. Authors\nin [212] have developed an artiﬁcal immune system based\nintrusion detection system they have used density based spatial\nclustering of applications with noise to develop an immune\nsystem against the network intrusion detection.\nThe application of unsupervised intrusion detection in cloud\nnetwork is presented in [213] where authors have proposed a\nfuzzy clustering ANN to detect the less frequent attacks and\nimprove the detection stability in cloud networks. Another\napplication of unsupervised intrusion detection system for\nclouds is surveyed in [214], where fuzzy logic based intrusion\ndetection system using supervised and unsupervised ANN is\nproposed for intrusion detection; this approach is used for DOS\nand DDoS attacks where the scale of the attack is very large.\nNetwork intrusion anomaly detection (NIDS) based on K-\nmeans clustering are surveyed in [215]; this survey is unique as\nit provides distance and similarity measure of the intrusion de-\ntection and this perspective has not been studied before 2015.\nUnsupervised learning based application of anomaly detection\nschemes for wireless personal area networks, wireless sensor\nnetworks, cyber physical systems, and WLANs is surveyed in\n[216].\nAnother paper [217] reviewing anomaly detection has pre-\nsented the application of unsupervised SVM and clustering\nbased applications in network intrusion detection systems.\nUnsupervised discretization algorithm is used in Bayesian\nnetwork classiﬁer for intrusion detection, which is based on\nBayesian model averaging [218]; the authors show that the\nproposed algorithm performs better than the Na¨ıve Bayes clas-\nsiﬁer in terms of accuracy on the NSL-KDD intrusion detection\ndataset. Border gateway protocol (BGP)—the core Internet\ninter-autonomous systems (inter-AS) routing protocol—is also\nerror prone to intrusions and anomalies. To detect these BGP\nanomalies, many supervised and unsupervised ML solutions\n(such as hidden Markov models and principal component anal-\nysis) have been proposed in literature [219] for anomaly and\nintrusion detection. Another problem for anomaly detection is\nlow volume attacks, which have become a big challenge for\nnetwork trafﬁc anomaly detection. While long range depen-\ndencies (LRD) are used to identify these low volume attacks,\nLRD usually works on aggregated trafﬁc volume; but since the\nvolume of trafﬁc is low, the attacks can pass undetected. To\naccurately identify low volume abnormalities, Assadhan et al.\n[220] proposed the examination of LRD behavior of control\nplane and data plane separately to identify low volume attacks.\nOther than clustering, another widely used unsupervised\ntechnique for detecting malicious and abnormal behavior in\nnetworks is SOMs. The specialty of SOMs is that they can\nautomatically organize a variety of inputs and deduce patterns\namong themselves, and subsequently determine whether the\nnew input ﬁts in the deduced pattern or not, thus detecting\nabnormal inputs [188] [189]. SOMs have also been used in\nhost-based intrusion detection systems in which intruders and\nabusers are identiﬁed at a host system through incoming data\ntrafﬁc [192], later on a more robust and efﬁcient technique\nwas proposed to analyze data patterns in TCP trafﬁc [190].\nFurthermore, complex NNs have also been applied to solve\nthe same problem and remarkable results have been produced.\nA few examples include the application of ART combined\nwith SOM [193]. The use of PCA can also be seen in detect-\ning intrusions [201]. NMF has also been used for detecting\nintruders and abusers [104], and lastly dimension reduction\ntechniques have also been applied to eradicate intrusions and\nanomalies in the system [202]. For more applications, refer\nto Table VIII, which classiﬁes different network anomaly\nand intrusion detection systems on the basis of unsupervised\nlearning techniques discussed earlier.\nC. Network Operations, Optimizations and Analytics\nNetwork management comprises of all the operations in-\ncluded in initializing, monitoring and managing of a computer\nnetwork based on its network functions, which are the primary\nrequirements of the network operations. The general purpose\nof network management and monitoring systems is to ensure\nthat basic network functions are fulﬁlled, and if there is any\nmalfunctioning in the network, it should be reported and\naddressed accordingly. Following is a summary of different\nnetwork optimization tasks achieved through unsupervised\nlearning models.\n1) QoS/ QoE Optimization: QoS and QoE are measures of\nthe service performance and end-user experience, respectively.\nQoS mainly deals with the performance as seen by the user\nbeing measured quantitatively, while QoE is a qualitative\nmeasure of a subjective metrics experienced by the user.\nQoS/QoE for Internet services (especially multimedia content\ndelivery services) is crucial in order to maximize the user\nexperience. With the dynamic and bursty nature of Internet\ntrafﬁc, computer networks should be able to adapt to these\nchanges without compromising the end-user experiences. As\nQoE is quite subjective, it heavily relies on the underlying\nQoS which is affected by different network parameters; [236]\nand [237] suggested different measurable factors to determine\nthe overall approximation of QoS such as error rates, bit\nrate, throughput, transmission delay, availability, jitter, etc.\nFurthermore, these factors are used to correlate QoS with QoE\nin the perspective of video streaming where QoE is essential\nto end-users.\n22\nTABLE IX: Unsupervised Learning Techniques employed for Network Operations, Optimizations and Analytics\nReference\nTechnique\nBrief Summary\nNetwork Type\nHierarchical Representations/ Deep Learning\nKulakov et al. [221]\nART fuzzy\nApplied ART NNs at clusterheads and sensor nodes to extract regular patterns,\nreducing data for lesser communication overhead.\nWSN\nAkojwar et al. [222]\nART\nApplied ART at each network node for data aggregation.\nWSN\nLi et al. [223]\nDNN\nApplied different DNN layers corresponding to WSN layers in order to compress\ndata.\nWSN\nGelenbe et al. [224]\nRNN\nApplied RNN to achieve optimal QoS in cognitive packet networks.\nCognitive networks\nCordina et al. [225]\nSOM\nApplied SOM to cluster nodes into categories based on node location, energy\nand concentration; some nodes becomes clusterheads.\nWSN\nEnami et al. [226]\nSOM\nApplied SOM to categorize and select nodes with higher energy levels to become\nclusterheads based on node energy levels.\nWSN\nDehni et al. [227]\nSOM\nApplied SOM followed by K-means to cluster and select clusterheads in WSNs.\nWSN\nOldewurtel et al. [228]\nSOM\nApplied SOMs in clusterheads to ﬁnd patterns in data.\nWSN\nBarreto et al. [229]\nDNN\nApplied a competitive neural algorithm for condition monitoring and fault\ndetection in 3G cellular networks.\nCellular networks\nMoustapha et al. [230]\nRNN\nApplied RNN for fault detection. RNN, which is deployed in each sensor node,\ntakes inputs from neighboring nodes, and generates outputs for comparison with\nthe generated data; if the difference exceeds a certain threshold, the node is\nregarded as anomalous.\nWSN\nData Clustering\nHoan et al. [231]\nFuzzy C-Means Cluster-\ning\nApplied fuzzy C-means clustering technique to select nodes with the highest\nresidual energy to gather data and send information using an energy-efﬁcient\nrouting in WSNs.\nWSN\nOyman et al. [232]\nK-Means Clustering\nApplied K-means clustering to design multiple sink nodes in WSNs.\nWSN\nZhang et al. [233]\nK-Means Partitioning\nApplied K-means clustering to identify compromised nodes and applied\nKullback-Leibler (KL) distance to determine the trustworthiness (reputation) of\neach node in a trust-based WSN.\nWSN\nBlind Signal Separation\nKapoor et al. [234]\nPCA\nApplied PCA to resolve the problem of cooperative spectrum sensing in cognitive\nradio networks.\nCognitive radio networks\nRistaniemi et al. [235]\nICA\nApplied ICA based CDMA receivers to separate and identify mixed source\nsignals.\nCDMA\nAhmed et al. [106]\nPCA\nApplied PCA to evaluate the degree of conﬁdence in detection probability\nprovided by a WSN. The probabilistic approach is a deviation from the idealistic\nassumption of sensing coverage used in a binary detection model.\nWSN\nChatzigiannakis et al. [107]\nPCA\nApplied PCA for hierarchical anomaly detection in a distributed WSN.\nWSN\nThe dynamic nature of Internet dictates network design for\ndifferent applications to maximize QoS/QoE, since there is\nno predeﬁned adaptive algorithm that can be used to fulﬁll\nall the necessary requirements for prospective application.\nDue to this fact, ML approaches are employed in order to\nadapt to the real-time network conditions and take measures\nto stabilize/maximize the user experience. [238] employed a\nhybrid architecture having unsupervised feature learning with\nsupervised classiﬁcation for QoE-based video admission con-\ntrol and resource management. Unsupervised feature learning\nin this system is carried out by using a fully connected\nNN comprising RBMs, which capture descriptive features of\nvideo that are later classiﬁed by using a supervised classiﬁer.\nSimilarly, [239] presents an algorithm to estimate the Mean\nOpinion Score, a metric for measuring QoE, for VoIP services\nby using SOM to map quality metrics to features.\nMoreover, research has shown that QoE-driven content opti-\nmization leads to the optimal utilization of network. Ahammad\net al. [240] showed that 43% of the bit overhead on average can\nbe reduced per image delivered on the web. This is achieved by\nusing the quality metric VoQS (Variation of Quality Signature),\nwhich can arbitrarily compare two images in terms of web\ndelivery performance. By applying this metric for unsupervised\nclustering of large image dataset, multiple coherent groups are\nformed in device-targeted and content-dependent manner. In\nanother study [241], deep learning is used to assess the QoE\nof 3D images that have yet to show good results compared\nwith the other deterministic algorithms. The outcome is a\nReduced Reference QoE assessment process for automatic\nimage assessment, and it has a signiﬁcant potential to be\nextended to work on 3D video assessment.\nIn [242], a unique technique of the model-based RL ap-\nproach is applied to improve bandwidth availability, and hence\nthroughput performance, of a network. The MRL model is\nembedded in a node that creates a model of the operating\nenvironment, and uses it to generate virtual states and rewards\nfor the virtual actions taken. As the agent does not need to wait\nfor the real states and rewards from the operating environment,\nit can explore various kinds of actions on the virtual operating\nenvironment within a short period of time which helps to\nexpedite the learning process, and hence the convergence rate\nto the optimal action. In [243], a MARL approach is applied in\nwhich nodes exchange Q-values among themselves and select\ntheir respective next-hop nodes with the best possible channel\n23\nconditions while forwarding packets towards the destination.\nThis helps to improve throughput performance as nodes in\na network ensure that packets are successfully sent to the\ndestination in a collaborative manner.\n2) TCP Optimization: Transmission Control Protocol (TCP)\nis the core end-to-end protocol in TCP/IP stack that provides\nreliable, ordered and error-free delivery of messages between\ntwo communicating hosts. Due to the fact that TCP provides\nreliable and in-order delivery, congestion control is one of\nthe major concerns of this protocol, which is commonly dealt\nwith the algorithms deﬁned in RFC 5681. However, classi-\ncal congestion control algorithms are sub-optimal in hybrid\nwired/wireless networks as they react to packet loss in the same\nmanner in all network situations. In order to overcome this\nshortcoming of classical TCP congestion control algorithms,\nan ML-based approach is proposed in [244], which employs a\nsupervised classiﬁer based on features learned for classifying a\npacket loss due to congestion or link errors. Other approaches\nto this problem currently employed in literature includes using\nRL that uses fuzzy logic based reward evaluator based on game\ntheory [245]. Another promising approach, named Remy [246],\nuses a modiﬁed model of Markov decision process based on\nthree factors: 1) prior knowledge about the network; 2) a trafﬁc\nmodel based on user needs (i.e., throughput and delay); and 3)\nan objective function that is to be maximized. By this learning\napproach, a customized best-suited congestion control scheme\nis produced speciﬁcally for that part of the network, adapted\nto its unique requirements. However, classifying packet losses\nusing unsupervised learning methods is still an open research\nproblem and there is a need of real-time adaptive congestion\ncontrol mechanism for multi-modal hybrid networks.\nFor more applications, refer to Table IX, which classiﬁes\ndifferent various network optimization and operation works on\nthe basis of their network type and the unsupervised learning\ntechnique used.\nD. Dimensionality Reduction & Visualization\nNetwork data usually consists of multiple dimensions. To\napply machine learning techniques effectively the number of\nvariables are needed to be reduced. Dimensionality reduction\nschemes have a number of signiﬁcant potential applications in\nnetworks. In particular, dimensionality reduction can be used\nto facilitate network operations (e.g., for anomaly/intrusion de-\ntection, reliability analysis, or for fault prediction) and network\nmanagement (e.g., through visualization of high-dimensional\nnetworking data). A tabulated summary of various research\nworks using dimensionality reduction techniques for various\nkinds of networking applications is provided in Table X.\nDimensionality reduction techniques have been used to\nimprove the effectiveness of the anomaly/intrusion detection\nsystem. Niyaz et al. [259] proposed a DDoS detection system\nin SDN where dimensionality reduction is used for feature\nextraction and reduction in unsupervised manner using stacked\nsparse autoencoders. Cordero et al. [260] proposed a ﬂow\nbased anomaly intrusion detection using replicator neural net-\nwork. Proposed network is based on an encoder and decoder\nwhere the hidden layer between encoder and decoder performs\nthe dimensionality reduction in unsupervised manner, this\nprocess also corresponds to PCA. Similarly Chen et al. [261]\nhave proposed another anomaly detection procedure where\ndimensionality reduction for feature extraction is performed\nusing multi-scale PCA and then using wavelet analysis, so\nthat the anomalous trafﬁc is separated from the ﬂow. Di-\nmensionality reduction using robust PCA based on minimum\ncovariance determinant estimator for anomaly detection is\npresented in [262]. Thaseen et al. [263] applied PCA for\ndimensionality reduction in network intrusion detection ap-\nplication. To improve the performance of intrusion detection\nscheme, another algorithm based on dimensionality reduction\nfor new feature learning using PCA is presented in [264] [265].\nAlmusallam et al. [266] have reviewed the dimensionality\nreduction schemes for intrusion detection in multimedia trafﬁc\nand proposed an unsupervised feature selection scheme based\non the dimensionality reduced multimedia data.\nDimensionality reduction using autoencoders performs a vi-\ntal role in fault prediction and reliability analysis of the cellular\nnetworks, this work also recommends deep belief networks\nand autoencoders as logical fault prediction techniques for\nself organizing networks [267]. Most of the Internet appli-\ncations use encrypted trafﬁc for communication, previously\ndeep packet inspection (DPI) was considered a standard way\nof classifying network trafﬁc but with the varying nature of the\nnetwork application and randomization of port numbers and\npayload size DPI has lost its signiﬁcance. Authors in [268]\nhave proposed a hybrid scheme for network trafﬁc classiﬁca-\ntion. Proposed scheme uses extreme machine learning, genetic\nalgorithms and dimensionality reduction for feature selection\nand trafﬁc classiﬁcation. Ansari et al. [269] applied fuzzy\nset theoretic approach for dimensionality reduction along with\nfuzzy C-mean clustering algorithm for quality of web usage.\nIn another work, Alsheikh et al. [270] used Shrinking Sparse\nAutoEncoders (SSAE) for representing high-dimensional data\nand utilized SSAE in compressive sensing settings.\nVisualization of high dimensional data in lower dimension\nrepresentation is another application of dimensionality reduc-\ntion. There are many relevant techniques such as PCA and\nt-SNE that can be used to extract the underlying structure of\nhigh-dimensional data, which can then be visualized to aid hu-\nman insight seeking and decision-making [136]. A number of\nresearchers have proposed to utilize dimensionality reduction\ntechniques to aid visualization of networking data. Patwari et\nal. [256] proposed a manifold learning based visualization tool\nfor network trafﬁc visualization and anomaly detection. Labib\net al. [271] proposed a PCA-based for the detection and visu-\nalization of networking attacks in which PCA is used for the\ndimensionality reduction of the feature vector extracted from\nKDD network trafﬁc dataset. Lokovc et al. [272] used t-SNE\nfor depicting malware ﬁngerprints in their proposed network\nintrusion detection system. Ancona et al. [273] proposed a\nrectangular dualization scheme for visualizing the underlying\nnetwork topology. Cherubin et al. [274] used dimensionality\nreduction and t-SNE of clustering and visualization of botnet\ntrafﬁc. Finally, a lightweight platform for home Internet mon-\nitoring is presented in [275] where PCA and t-SNE is used\nfor dimensionality reduction and visualization of the network\n24\nTABLE X: Dimensionality Reduction Techniques employed for Networking Applications\nReference\nTechnique\nBrief Summary\nNetwork/Technology\nType\nO’Shea et al. [247]\nAutoencoders\nApplied autoencoders to design an end-to-end communication system that can\njointly learn transmitter and receiver implementations as well as signal encodings\nin unsupervised manner.\nMIMO\nO’Shea et al. [248]\nAutoencoders\nA new approach for designing and optimizing the physical layer is explored\nusing autoencoders for dimensionality reduction.\nMIMO\nO’Shea et al. [249]\nConvolutional Autoencoders\nApplied autoencoders for representation learning of structured radio communi-\ncation signals.\nSoftware Radio/ Cogni-\ntive Radio\nHuang et al. [250]\nMulti-dimensional Scaling\nApplied distance based subspace dimensionality reduction technique for anomaly\ndetection in data trafﬁc.\nInternet Trafﬁc\nZoha et al. [251]\nMulti-dimensional Scaling\nUsed MDS to preprocess a statistical dataset for cell outage detection in SON.\nSON\nShirazinia et al. [252]\nSparse Gaussian Method\nApplied sparse Gaussian method for linear dimensionality reduction over noisy\nchannels in wireless sensor networks.\nWSN\nHou et al. [253]\nPCA\nLinear and nonlinear dimensionality reduction techniques along with support\nvector machine has be experimentally tested for cognitive radio.\nCognitive Radio\nKhalid et al. [254]\nPCA\nApplied L1 norm PCA for dimensionality reduction in network intrusion\ndetection system.\nInternet Trafﬁc\nGoodman et al. [255]\nPCA\nApplied PCA for diemensionality reduction in anomaly detection for cyber\nsecurity applications.\nSMS\nPatwari et al. [256]\nManifold Learning\nProposed a manifold learning based visualization tool for network trafﬁc\nvisualization and anomaly detection.\nInternet Trafﬁc\nLopez et al. [257]\nTransfer Learning and t-SNE\nUsed transfer learning for multimedia web mining and t-SNE for dimensionality\nreduction and visualization of web mining resultant model.\nMultimedia Web\nBan et al. [258]\nClustering and t-SNE\nProposed an early threat detection scheme using darknet data, where clustering\nis used for threat detection and dimensionality reduction for visualization is\nperformed by using t-SNE.\nInternet Trafﬁc\ntrafﬁc. A number of tools are readily available—e.g., Divvy\n[276], Weka [277]—that implement dimensionality reduction\nand other unsupervised ML techniques (such as PCA and\nmanifold learning) and allow exploratory data analysis and\nvisualization of high-dimensional data.\nDimensionality reduction techniques and tools have been\nutilized in all kinds of networks and we present some recent\nexamples related to self-organizing networks (SONs) and soft-\nware deﬁned radios (SDRs). Liao et al. [278] proposed a semi\nsupervised learning scheme for anomaly detection in SON\nbased on dimensionality reduction and fuzzy classiﬁcation\ntechnique. Chernov et al. [279] used minor component analysis\n(MCA) for dimensionality reduction as a preprocessing step\nfor user level statistical data in LTE-A networks to detect the\ncell outage. Zoha et al. [251] used multi-dimensional scaling\n(MDS), a dimensionality reduction scheme, as part of the\npreprocessing step for cell outage detection in SON. Another\ndata driven approach by Zoha et al. [280] also uses MDS\nfor getting low dimensional embedding of target key point\nindicator vector as a preprocessing step to automatically detect\ncell outage in SON. Turkka et al. [281] used PCA for dimen-\nsionality reduction of drive test samples to detect cell outages\nautonomously in SON. Conventional routing schemes are not\nsufﬁcient for the ﬁfth generation of communication systems.\nKato et al. [282] proposed a supervised deep learning based\nrouting scheme for heterogeneous network trafﬁc control.\nAlthough supervised approach performed well, but gathering\na lot of heterogeneous trafﬁc with labels, and then processing\nthem with a plain ANN is computationally extensive and prone\nto errors due to the imbalanced nature of the input data and\nthe potential for overﬁtting. In 2017, Mao et al. [283] has\npresented a deep learning based approach for routing and cost\neffective packet processing. The proposed model uses deep\nbelief architecture and beneﬁts from the dimensionality reduc-\ntion property of restricted Boltzmann machine. The proposed\nwork also provides a novel Graphics Processing Unit (GPU)\nbased router architecture. The detailed analysis shows that\ndeep learning based SDR and routing technique can meet the\nchanging network requirements and massive network trafﬁc\ngrowth. The routing scheme proposed in [283] outperforms\nconventional open shortest path ﬁrst (OSPF) routing technique\nin terms of throughput and average delay per hop.\nE. Emerging Networking Applications of Unsupervised Learn-\ning\nNext generation network architectures such as Software\ndeﬁned Networks (SDN), Self Organizing Networks (SON),\nand Internet of Things (IoT) are expected to be the basis of\nfuture intelligent, adaptive, and dynamic networks [284]. ML\ntechniques will be at the center of this revolution providing\naforementioned properties. This subsection covers the recent\napplications of unsupervised ML techniques in SDNs, SONs,\nand IoTs.\n1) Software Deﬁned Networks: SDN is a disruptive new\nnetworking architecture that simpliﬁes network operating and\nmanaging tasks and provides infrastructural support for novel\ninnovations by making the network programmable [285]. In\nsimple terms, the idea of programmable networks is to simply\ndecouple the data forwarding plane and control/decision plane,\nwhich is rather tightly coupled in current infrastructure. The\nuse of SDN can also be seen in managing and optimizing\nnetworks as network operators go through a lot of hassle to\nimplement high level security policies in term of distributed\nlow level system conﬁgurations, thus SDN resolves this issue\nby decoupling the planes and giving network operators better\n25\ncontrol and visibility over network, enabling them to make fre-\nquent changes to network state and providing support for high-\nlevel speciﬁcation language for network control [286]. SDN is\napplicable in a wide variety of areas ranging from enterprise\nnetworks, data centers, infrastructure based wireless access\nnetworks, optical networks to home and small businesses, each\nproviding many future research opportunities [285].\nUnsupervised ML techniques are seeing a surging interest in\nSDN community as can be seen by a spate of recent work. A\npopular application of unsupervised ML techniques in SDNs\nrelates to the application of intrusion detection and mitigation\nof security attacks [287]. Another approach for detecting\nanomalies in cloud environment using unsupervised learning\nmodel has been proposed by Dean et al. [288] that uses SOM\nto capture emergent system behavior and predict unknown and\nnovel anomalies without any prior training or conﬁguration.\nA DDoS detection system for SDN is presented in [259]\nwhere stacked autoencoders are used to detect DDoS attacks.\nA density peak based clustering algorithm for DDoS attack is\nproposed as a new method to review the potentials of using\nSDN to develop an efﬁcient anomaly detection method [289].\nGoswami et al. [290] have recently presented an intelligent\nthreat aware response system for SDN using reinforcement\nlearning, this work also recommends using unsupervised fea-\nture learning to improve the threat detection process. Another\nframework for anomaly detection, classiﬁcation, and mitigation\nfor SDN is presented in [291] where unsupervised learning\nis used for trafﬁc feature analysis. Zhang et al. [292] have\npresented a forensic framework for SDN and recommended\nK-means clustering for anomaly detection in SDN. Another\nwork [293] discusses the potential opportunities for using un-\nsupervised learning for trafﬁc classiﬁcation in SDN. Moreover,\ndeep learning and distributed processing can also be applied\nto such models in order to better adapt with evolving networks\nand contribute to the future of SDN infrastructure as a service.\n2) Self Organizing Networks:\nSelf organizing networks\n(SON) is another new and popular research regime in network-\ning, SON are inspired from the biological system which works\nin self organization and achieve the task by learning from the\nsurrounding environment. As the connected network devices\nare growing exponentially, and the communication cell size\nhas reduced to femtocells, the property of self organization\nis becoming increasingly desirable [294]. A reinforcement\nlearning based approach for designing self organization based\nsmall cell network is presented in [295]. Feasibility of SON\napplication in ﬁfth generation (5G) of wireless communica-\ntion is studied in [296] and the study shows that without\n(supervised as well as unsupervised) ML support, SON is not\npossible. Application of ML techniques in SON has become\na very important research area as it involves learning from\nthe surroundings for intelligent decision-making and reliable\ncommunication [2].\nApplication of different ML-based SON for heterogeneous\nnetworks is considered in [297], this paper also describes the\nunsupervised ANN, hidden Markov models and reinforcement\nlearning techniques employed for better learning from the\nsurroundings and adapting accordingly. PCA and clustering are\nthe two mostly used unsupervised learning schemes utilized\nfor parameter optimization and feature learning in SON where\nas reinforcement learning, fuzzy reinforcement learning, Q\nlearning, double Q learning and deep reinforcement learning\nare the major schemes used for interacting with the environ-\nment [294]. These ML schemes are used in self-conﬁguration,\nself-healing, and self-optimization schemes. Game theory is\nanother unsupervised learning approach used for designing\nself optimization and greedy self conﬁguration design of SON\nsystems [298]. Authors in [299] proposed an unsupervised\nANN for link quality estimation of SON which outperformed\nsimple moving average and exponentially weighted moving\naverages.\n3) Internet of Things: Internet of things (IoT) is an emerging\nparadigm with a growing academia and industry interest.\nIoT is new networking paradigm and it is expected to be\ndeployed in health care, smart cities, industry, home automa-\ntion, agriculture, and industry. With such a vast plane of\napplications, IoT needs ML to collect and analyze data to\nmake intelligent decisions. The key challenge that IoT must\ndeal with is the extremely large scale (billions of devices)\nof future IoT deployments [300]. Designing, analyzing and\npredicting are the three major tasks and all involves ML, a\nfew examples of unsupervised ML are shared next. Gubbi et\nal. [301] recommend using unsupervised ML techniques for\nfeature extraction and supervised learning for classiﬁcation\nand predictions. Given the scale of the IoT, a large amount\nof data is expected in the network and therefore requires a\nload balancing method, a load balancing algorithm based on\nrestricted Boltzmann machine is proposed in [302]. Online\nclustering scheme form dynamic IoT data streams is described\nin [303]. Another work describing an ML application in IoT\nrecommends a combination of PCA and regression for IoT to\nget better prediction [304]. Usage of clustering technique in\nembedded systems for IoT applications is presented in [305].\nAn application using denoising autoencoders for acoustic mod-\neling in IoT is presented in [306].\nF. Lessons Learnt\nKey leassons drawn from the review of unsupervised learn-\ning in networking applications are summarized below:\n1) A recommended and well studied method for unsuper-\nvised Internet trafﬁc classiﬁcation in literature is data\nclustering combined with the latent representation learn-\ning on trafﬁc feature set by using autoencoders. Min-max\nensemble learning will help to increase the efﬁciency of\nunsupervised learning if required.\n2) Semi supervised learning is also an appropriate method\nfor Internet trafﬁc classiﬁcation given some labeled trafﬁc\ndata and channel characteristics are available for initial\nmodel training.\n3) Application of generative models and transfer learning for\nthe Internet trafﬁc classiﬁcation has not been explored\nproperly in literature and can be a potential research\ndirection.\n4) The overwhelming growth in network trafﬁc and expected\nsurge in trafﬁc with the evolution of 5G and IoT also\n26\nelevates the level of threat and anomalies in network\ntrafﬁc. To deal with these anomalies in Internet trafﬁc,\ndata clustering, PCA, SOM, and ART are well explored\nunsupervised learning techniques in literature. Self-taught\nlearning has also been explored as a potential solution\nfor anomaly detection and remains a possible research\ndirection for future research in anomaly detection in\nnetwork trafﬁc.\n5) Unsupervised learning techniques for network manage-\nment and optimization is a very less explored area as\ncompared to anomaly detection and trafﬁc classiﬁcation.\nApplications of NN, RBM, Q learning, and deep re-\ninforcement learning techniques to Internet trafﬁc for\nmanagement and optimization is an open research area.\n6) Current state of the art in dimensionality reduction in\nnetwork trafﬁc is based on PCA and multidimensional\nscaling. Autoencoders, t-SNE, and manifold learning is\na potential area of research in terms of dimensionality\nreduction and visualization.\nIV.\nFUTURE WORK: SOME RESEARCH CHALLENGES AND\nOPPORTUNITIES\nThis section provides a discussion on some open directions\nfor future work and the relevant opportunities in applying\nunsupervised ML in the ﬁeld of networking.\nA. Simpliﬁed Network Management\nWhile new network architectures such as SDN have been\nproposed in recent years to simply network management,\nnetwork operators are still expected to know too much, and\nto correlate between what they know about how their network\nis designed with the current network’s condition through their\nmonitoring sources. Operators who manage these requirements\nby wrestling with complexity manually will deﬁnitely welcome\nany respite that they can get from (semi-)automated unsu-\npervised machine learning. As highlighted in by [307], for\nML to become pervasive in networking, the “semantic gap”—\nwhich refers to the key challenge of transferring ML results\ninto actionable insights and reports for the network operator—\nmust be overcome. This can facilitate a shift from a reactive\ninteraction style for network management, where the network\nmanager is expected to check maps and graphs when things go\nwrong, to a proactive one, where automated reports and notiﬁ-\ncations are created for different services and network regions.\nIdeally, this would be abstract yet informative, such as Google\nMaps Directions, e.g. “there is heavier trafﬁc than usual on\nyour route” as well as suggestions about possible actions.\nThis could be coupled with automated correlation of different\nreports coming from different parts of the network. This will\nrequire a move beyond mere notiﬁcations and visualizations to\nmore substantial synthesis through which potential sources of\nproblems can be identiﬁed. Another example relates to making\nmeasurements more user-oriented. Most users would be more\ninterested in QoE instead of QoS, i.e., how the current condi-\ntion of the network affects their applications and services rather\nthan just raw QoS metrics. The development of measurement\nobjectives should be from a business-eyeball perspective—and\nnot only through presenting statistics gathered through various\ntools and protocols such as traceroute, ping, BGP, etc. with\nthe burden of putting the various pieces of knowledge together\nbeing on the user.\nB. Semi-Supervised Learning for Computer Networks\nSemi-supervised learning lies between supervised and un-\nsupervised learning. The idea behind semi-supervised learn-\ning is to improve the learning ability by using unlabeled\ndata incorporation with small set of labeled examples. In\ncomputer networks, semi-supervised learning is partially used\nin anomaly detection and trafﬁc classiﬁcation and has great\npotential to be used with deep unsupervised learning architec-\ntures like generative adversarial networks for improving the\nstate of the art in anomaly detection and trafﬁc classiﬁcation.\nSimilarly user behavior learning for cyber security can also\nbe tackled in a semi-supervised fashion. A semi-supervised\nlearning based anomaly detection approach is presented in\n[308]. The presented approach used large amounts of unla-\nbeled samples together with labeled samples to build a better\nintrusion detection classiﬁer. In particular, a single hidden layer\nfeed-forward NN is trained to output a fuzzy membership\nvector. The results show that using unlabeled samples help\nsigniﬁcantly improve the classiﬁer’s performance. In another\nwork, Watkins et al. [309] have proposed a semi-supervised\nlearning with 97% accuracy to ﬁlter out non-malicious data in\nmillions of queries that Domain Name Service (DNS) servers\nreceive.\nC. Transfer Learning in Computer Networks\nTransfer learning is an emerging ML technique in which\nknowledge learned from one problem is applied to a different\nbut related problem [310]. Although it is often thought that\nfor ML algorithms, the training and future data must be in the\nsame feature space and must have same distribution, this is not\nnecessarily the case in many real-world applications. In such\ncases, it is desirable to have transfer learning, or knowledge\ntransfer between the different task domains. Transfer learning\nhas been successfully applied in computer vision and NLP\napplications but its implementation for networking has not\nbeen witnessed—even though in principle, this can be useful in\nnetworking as well due to the similar nature of Internet trafﬁc\nand enterprise network trafﬁc in many respects. Bacstuug\net al. [311] used transfer learning based caching procedure\nfor wireless networks providing backhaul ofﬂoading in 5G\nnetworks.\nD. Federated Learning in Computer Networks\nFederated learning is a collaborative ML technique, which\ndoes not make use of centralized training data, and works by\ndistributing the processing on different machines. Federated\nlearning is considered to be the next big thing in cloud\nnetworks as they ensure privacy of the user data and less\ncomputation on the cloud to reduce the cost and energy\n[312]. System and method for network address management\nin federated cloud is presented in [313] and application of\n27\nfederated IoT and cloud computing for health care is presented\nin [314]. An end-to-end security architecture for federated\ncloud and IoT is presented in [315].\nE. General Adversarial Networks (GANs) in Computer Net-\nworks\nAdversarial networks—based on generative adversarial net-\nwork (GAN) training originally proposed by Goodfellow and\ncolleagues at the University of Montreal [316]—have recently\nemerged as a new technique using which machines can be\ntrained to predict outcomes by only the observing the world\n(without necessarily being provided labeled data). An adver-\nsarial network has two NN models: a generatorwhich is re-\nsponsible for generating some type of data from some random\ninputand a discriminator, which has the task of distinguishing\nbetween input from the generator or a real data set. The two\nNNs optimize themselves together resulting in more realistic\ngeneration of data by the generator, and a better sense of what\nis plausible in the real world for the discriminator. The use of\nGANs for ML in networking can improve the performance of\nML-based networking applications such as anomaly detection\nin which malicious users have an incentive to adversarial craft\nnew attacks to avoid detection by network managers.\nV.\nPITFALLS AND CAVEATS OF USING UNSUPERVISED\nML IN NETWORKING\nWith the beneﬁts and intriguing results of unsupervised\nlearning, there also exists many shortcomings that are not\naddressed widely in the literature. Some potential pitfalls and\ncaveats related to unsupervised learning are discussed next.\nA. Inappropriate Technique Selection\nTo start with, the ﬁrst potential pitfall could be the selection\nof technique. Different unsupervised learning and predicting\ntechniques may have excellent results on some applications\nwhile performing poorly on others—it is important to choose\nthe best technique for the task at hand. Another reason could\nbe a poor selection of features or parameters on which basis\npredictions are made—thus parameter optimization is also\nimportant for unsupervised algorithms.\nB. Lack of Interpretability of Some Unsupervised ML Algo-\nrithms\nSome unsupervised algorithms such as deep NNs operate as\na blackbox, which makes it difﬁcult to explain and interpret\nthe working of such models. This makes the use of such\ntechniques unsuitable for applications in which interpretability\nis important. As pointed out in [307], understandability of the\nsemantics of the decisions made by ML is especially important\nfor the operational success of ML in large-scale operational\nnetworks and its acceptance by operators, network managers,\nand users. But prediction accuracy and simplicity are often in\nconﬂict [317]. As an example, the greater accuracy of NNs\naccrues from its complex nature in which input variables are\ncombined in a nonlinear fashion to build a complicated hard-\nto-explain model; with NNs it may not be possible to get\ninterpretability as well since they make a tradeoff in which\nthey sacriﬁce interpretability to achieve high accuracy. There\nare various ongoing research efforts that are focused on making\ntechniques such as NNs less opaque [318]. Apart from the\nfocus on NNs, there is a general interest in making AI and\nML more explainable and interpretable—e.g., the Defense\nAdvanced Research Projects Agency or DARPA’s explainable\nAI project2 is aiming to develop explainable AI models (lever-\naging various design options spanning the performance-vs-\nexplainability tradeoff space) that can explain the rationale of\ntheir decision-making so that users are able to appropriately\ntrust these models particularly for new envisioned control\napplications in which optimization decisions are made au-\ntonomously by algorithms.\nC. Lack of Operational Success of ML in Networking\nIn literature, researchers have noted that despite substantial\nacademic research, and practical applications of unsupervised\nlearning in other ﬁelds, we see that there is a dearth of prac-\ntical applications of ML solutions in operational networks—\nparticular for applications such as network intrusion detection\n[307], which are challenging problems for a number of reasons\nincluding 1) the very high cost of errors; 2) the lack of\ntraining data; 3) the semantic gap between results and their\noperational interpretation; 4) enormous variability in input\ndata; and ﬁnally, 5) fundamental difﬁculties in conducting\nsound performance evaluations. Even for other applications,\nthe success of ML and its wide adoption in practical systems at\nscale lags the success of ML solutions in many other domains.\nD. Ignoring Simple Non-Machine-Learning Based Tools\nOne should also keep in mind a common pitfall that\nacademic researchers may suffer from: which is not realize\nthat network operators may have have simpler non-machine\nlearning based solutions that may work as well as na¨ıve ML\nbased solutions in practical settings. Failure to examine the\nground realities of operational networks will undermine the\neffectiveness of ML based solutions. We should expect ML\nbased solutions to augment and supplement rather than replace\nother non-machine-learning based solutions—at least for the\nforeseeable future.\nE. Overﬁtting\nAnother potential issue with unsupervised models is over-\nﬁtting; it corresponds to a model representing the noise or\nrandom error rather than learning the actual pattern in data.\nWhile commonly associated with supervised ML, the problem\nof overﬁtting lurks whenever we learn from data and thus is\napplicable to unsupervised ML as well. As illustrated in Figure\n8, ideally speaking, we expect ML algorithms to provide im-\nproved performance with more data; but with increasing model\ncomplexity, performance starts to deteriorate after a certain\npoint—although, it is possible to get poorer results empirically\n2https://www.darpa.mil/program/explainable-artiﬁcial-intelligence\n28\nFig. 8: Intuitively, we expect the ML model’s performance to\nimprove with more data but to deteriorate in performance if the\nmodel becomes overly complex for the data. Figure adapted\nfrom [319].\nwith increasing data when working with unoptimized out-of-\nthe-box ML algorithms [319]. According to the Occam Razor\nprinciple, the model complexity should be commensurate with\nthe amount of data available, and with overly complex models,\nthe ability to predict and generalize diminishes. Two major\nreasons of overﬁtting could be the overly large size of learn-\ning model and less sample data used for training purposes.\nGenerally data is divided into two portions (actual data and\nstochastic noise); due to the unavailability of labels or related\ninformation, unsupervised learning model can overﬁt the data,\nwhich causes issues in testing and deployment phase. Cross\nvalidation, regularization, and Chi-squared testing are highly\nrecommended designing or tweaking an unsupervised learning\nalgorithm to avoid overﬁtting [320].\nF. Data Quality Issues\nIt should be noted that all ML is data dependent, and the per-\nformance of ML algorithms is affected largely by the nature,\nvolume, quality, and representation of data. Data quality issues\nmust be carefully considered since any problem with the data\nquality will seriously mar the performance of ML algorithms.\nA potential problem is that dataset may be imbalanced if the\nsamples size from one class is very much smaller or larger\nthan the other classes [321]. In such imbalanced datasets, the\nalgorithm must be careful not to ignore the rare class by\nassuming it to be noise. Although, imbalanced datasets are\nmore of a nuisance for supervised learning techniques, they\nmay also pose problems for unsupervised and semi-supervised\nlearning techniques.\nG. Inaccurate Model Building\nIt is difﬁcult to build accurate and generic models since\neach model is optimized for certain kind of applications.\nUnsupervised ML models should be applied after carefully\nstudying the application and the suitability of the algorithm\nin such settings [322]. For example, we highlight certain\nissues related to the unsupervised task of clustering: 1) random\ninitialization in K-means is not recommended; 2) number of\nclusters are not known before the clustering operation as we\ndo not have labels; 3) in the case of hierarchical clustering,\nwe don not know when to stop and this can cause increase\nin the time complexity of the process; and 4) evaluating the\nclustering result is very tricky since the ground truth is mostly\nunknown.\nH. Machine Learning in Adversarial Environments\nMany networking problems, such as anomaly detection,\nis an adversarial problem in which the malicious intruder\nis continually trying to outwit the network administrators\n(and the tools used by the network administrators). In such\nsettings, machine learning that learns from historical data may\nnot perform due to clever crafting of attacks speciﬁcally for\ncircumventing any schemes based on previous data.\nDue to these challenges, pitfalls, and weaknesses, due\ncare must be exercised while using unsupervised and semi-\nsupervised ML. These pitfalls can be avoided in part by\nusing various best practices [323], such as end-to-end learning\npipeline testing, visualization of learning algorithm, regular-\nization, proper feature engineering, dropout, sanity checks\nthrough human inspection—whichever is appropriate for the\nproblem’s context.\nVI.\nCONCLUSIONS\nWe have provided a comprehensive survey of machine\nlearning tasks and latest unsupervised learning techniques and\ntrends along with a detailed discussion of the applications of\nthese techniques in networking related tasks. Despite the recent\nwave of success of unsupervised learning, there is a scarcity\nof unsupervised learning literature for computer networking\napplications, which this survey aims to address. The few\npreviously published survey papers differ from our work in\ntheir focus, scope, and breadth; we have written this paper\nin a manner that carefully synthesizes the insights from these\nsurvey papers while also providing contemporary coverage of\nrecent advances. Due to the versatility and evolving nature of\ncomputer networks, it was impossible to cover each and every\napplication; however, an attempt has been made to cover all\nthe major networking applications of unsupervised learning\nand the relevant techniques. We have also presented concise\nfuture work and open research areas in the ﬁeld of networking,\nwhich are related to unsupervised learning, coupled with a\nbrief discussion of signiﬁcant pitfalls and challenges in using\nunsupervised machine learning in networks.\nREFERENCES\n[1]\nR. W. Thomas, D. H. Friend, L. A. DaSilva, and A. B. MacKenzie,\n“Cognitive networks,” in Cognitive radio, software deﬁned radio, and\nadaptive wireless systems, pp. 17–41, Springer, 2007.\n[2]\nS. Latif, F. Pervez, M. Usama, and J. Qadir, “Artiﬁcial intelligence\nas an enabler for cognitive self-organizing future networks,” arXiv\npreprint arXiv:1702.02823, 2017.\n[3]\nA. Patcha and J.-M. Park, “An overview of anomaly detection tech-\nniques: Existing solutions and latest technological trends,” Computer\nnetworks, vol. 51, no. 12, pp. 3448–3470, 2007.\n[4]\nT. T. Nguyen and G. Armitage, “A survey of techniques for Internet\ntrafﬁc classiﬁcation using Machine Learning,” Communications Sur-\nveys & Tutorials, IEEE, vol. 10, no. 4, pp. 56–76, 2008.\n29\n[5]\nM. Bkassiny, Y. Li, and S. K. Jayaweera, “A survey on machine-\nlearning techniques in cognitive radios,” Communications Surveys &\nTutorials, IEEE, vol. 15, no. 3, pp. 1136–1159, 2013.\n[6]\nM. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Machine learning\nin wireless sensor networks: Algorithms, strategies, and applications,”\nIEEE Communications Surveys & Tutorials, vol. 16, no. 4, pp. 1996–\n2018, 2014.\n[7]\nA. L. Buczak and E. Guven, “A survey of data mining and machine\nlearning methods for cyber security intrusion detection,” IEEE Com-\nmunications Surveys Tutorials, vol. 18, no. 2, pp. 1153–1176, 2016.\n[8]\nP. V. Klaine, M. A. Imran, O. Onireti, and R. D. Souza, “A survey\nof machine learning techniques applied to self organizing cellular\nnetworks,” IEEE Communications Surveys & Tutorials, 2017.\n[9]\nA. Meshram and C. Haas, “Anomaly detection in industrial networks\nusing machine learning: A roadmap,” in Machine Learning for Cyber\nPhysical Systems, pp. 65–72, Springer, 2017.\n[10]\nZ. Fadlullah, F. Tang, B. Mao, N. Kato, O. Akashi, T. Inoue, and\nK. Mizutani, “State-of-the-art deep learning: Evolving machine intel-\nligence toward tomorrows intelligent network trafﬁc control systems,”\nIEEE Communications Surveys & Tutorials, 2017.\n[11]\nE. Hodo, X. Bellekens, A. Hamilton, C. Tachtatzis, and R. Atkinson,\n“Shallow and deep networks intrusion detection system: A taxonomy\nand survey,” arXiv preprint arXiv:1701.02145, 2017.\n[12]\nJ. Qadir, K.-L. A. Yau, M. A. Imran, Q. Ni, and A. V. Vasilakos,\n“IEEE access special section editorial: Artiﬁcial intelligence enabled\nnetworking,” IEEE Access, vol. 3, pp. 3079–3082, 2015.\n[13]\nS. Suthaharan, “Big data classiﬁcation: Problems and challenges in\nnetwork intrusion prediction with machine learning,” ACM SIGMET-\nRICS Performance Evaluation Review, vol. 41, no. 4, pp. 70–73, 2014.\n[14]\nS. Shenker, M. Casado, T. Koponen, N. McKeown, et al., “The future\nof networking, and the past of protocols,” Open Networking Summit,\nvol. 20, pp. 1–30, 2011.\n[15]\nA. Malik, J. Qadir, B. Ahmad, K.-L. A. Yau, and U. Ullah, “Qos in\nieee 802.11-based wireless networks: a contemporary review,” Journal\nof Network and Computer Applications, vol. 55, pp. 24–46, 2015.\n[16]\nY. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature,\nvol. 521, no. 7553, pp. 436–444, 2015.\n[17]\nJ. Qadir, “Artiﬁcial intelligence based cognitive routing for cognitive\nradio networks,” Artiﬁcial Intelligence Review, vol. 45, no. 1, pp. 25–\n96, 2016.\n[18]\nN. Ahad, J. Qadir, and N. Ahsan, “Neural networks in wireless net-\nworks: Techniques, applications and guidelines,” Journal of Network\nand Computer Applications, vol. 68, pp. 1–27, 2016.\n[19]\nI. Guyon, S. Gunn, M. Nikravesh, and L. A. Zadeh, Feature extraction:\nfoundations and applications, vol. 207. Springer, 2008.\n[20]\nA. Coates, A. Y. Ng, and H. Lee, “An analysis of single-layer\nnetworks in unsupervised feature learning,” in International conference\non artiﬁcial intelligence and statistics, pp. 215–223, 2011.\n[21]\nI. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT Press,\n2016.\n[22]\nM. J. S. M. S. Mohammad Lotfollahi, Ramin Shirali, “Deep packet: A\nnovel approach for encrypted trafﬁc classiﬁcation using deep learning.”\n[23]\nW. Wang, M. Zhu, X. Zeng, X. Ye, and Y. Sheng, “Malware trafﬁc\nclassiﬁcation using convolutional neural network for representation\nlearning,” in Information Networking (ICOIN), 2017 International\nConference on, pp. 712–717, IEEE, 2017.\n[24]\nM. Youseﬁ-Azar, V. Varadharajan, L. Hamey, and U. Tupakula,\n“Autoencoder-based feature learning for cyber security applications,”\nin Neural Networks (IJCNN), 2017 International Joint Conference on,\npp. 3854–3861, IEEE, 2017.\n[25]\nR. C. Aygun and A. G. Yavuz, “Network anomaly detection with\nstochastically improved autoencoder based models,” in Cyber Secu-\nrity and Cloud Computing (CSCloud), 2017 IEEE 4th International\nConference on, pp. 193–198, IEEE, 2017.\n[26]\nM. K. Putchala, Deep Learning Approach for Intrusion Detection\nSystem (IDS) in the Internet of Things (IoT) Network using Gated\nRecurrent Neural Networks (GRU). PhD thesis, Wright State Univer-\nsity, 2017.\n[27]\nA. Tuor, S. Kaplan, B. Hutchinson, N. Nichols, and S. Robinson,\n“Deep learning for unsupervised insider threat detection in structured\ncybersecurity data streams,” 2017.\n[28]\nE. Aguiar, A. Riker, M. Mu, and S. Zeadally, “Real-time qoe prediction\nfor multimedia applications in wireless mesh networks,” in Consumer\nCommunications and Networking Conference (CCNC), 2012 IEEE,\npp. 592–596, IEEE, 2012.\n[29]\nK. Piamrat, A. Ksentini, C. Viho, and J.-M. Bonnin, “Qoe-aware\nadmission control for multimedia applications in ieee 802.11 wireless\nnetworks,” in Vehicular Technology Conference, 2008. VTC 2008-Fall.\nIEEE 68th, pp. 1–5, IEEE, 2008.\n[30]\nK. Karra, S. Kuzdeba, and J. Petersen, “Modulation recognition using\nhierarchical deep neural networks,” in Dynamic Spectrum Access\nNetworks (DySPAN), 2017 IEEE International Symposium on, pp. 1–3,\nIEEE, 2017.\n[31]\nM. Zhang, M. Diao, and L. Guo, “Convolutional neural networks for\nautomatic cognitive radio waveform recognition,” IEEE Access, vol. 5,\npp. 11074–11082, 2017.\n[32]\nJ. Moysen and L. Giupponi, “From 4g to 5g: Self-organized\nnetwork\nmanagement\nmeets\nmachine\nlearning,”\narXiv\npreprint\narXiv:1707.09300, 2017.\n[33]\nX. Xie, D. Wu, S. Liu, and R. Li, “Iot data analytics using deep\nlearning,” arXiv preprint arXiv:1708.03854, 2017.\n[34]\nJ. Schmidhuber, “Deep learning in neural networks: An overview,”\nNeural Networks, vol. 61, pp. 85–117, 2015.\n[35]\nY. Bengio, “Learning deep architectures for AI,” Foundations and\ntrends R⃝in Machine Learning, vol. 2, no. 1, pp. 1–127, 2009.\n[36]\nG. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm\nfor deep belief nets,” Neural Computation, vol. 18, no. 7, pp. 1527–\n1554, 2006.\n[37]\nY. Bengio, P. Lamblin, D. Popovici, H. Larochelle, et al., “Greedy\nlayer-wise training of deep networks,” Advances in neural information\nprocessing systems, vol. 19, p. 153, 2007.\n[38]\nC. Poultney, S. Chopra, Y. L. Cun, et al., “Efﬁcient learning of sparse\nrepresentations with an energy-based model,” in Advances in neural\ninformation processing systems, pp. 1137–1144, 2006.\n[39]\nJ. Ngiam, A. Coates, A. Lahiri, B. Prochnow, Q. V. Le, and A. Y.\nNg, “On optimization methods for deep learning,” in Proceedings of\nthe 28th International Conference on Machine Learning (ICML-11),\npp. 265–272, 2011.\n[40]\nC. Doersch, “Tutorial on variational autoencoders,” arXiv preprint\narXiv:1606.05908, 2016.\n[41]\nT. Kohonen, “The self-organizing map,” Proceedings of the IEEE,\nvol. 78, no. 9, pp. 1464–1480, 1990.\n[42]\nT. Kohonen, “The self-organizing map,” Neurocomputing, vol. 21,\nno. 1, pp. 1–6, 1998.\n[43]\nF. Rosenblatt, “The perceptron: a probabilistic model for information\nstorage and organization in the brain.,” Psychological review, vol. 65,\nno. 6, p. 386, 1958.\n[44]\nS. S. Haykin, Neural networks and learning machines, vol. 3. Pearson\nEducation Upper Saddle River, 2009.\n[45]\nG. A. Carpenter and S. Grossberg, Adaptive resonance theory.\nSpringer, 2010.\n[46]\nJ. Karhunen, T. Raiko, and K. Cho, “Unsupervised deep learning:\nA short review,” Advances in Independent Component Analysis and\nLearning Machines, p. 125, 2015.\n[47]\nH. Lee, R. Grosse, R. Ranganath, and A. Y. Ng, “Convolutional\ndeep belief networks for scalable unsupervised learning of hierarchical\nrepresentations,” in Proceedings of the 26th Annual International\nConference on Machine Learning, pp. 609–616, ACM, 2009.\n30\n[48]\nS. Barakovi´c and L. Skorin-Kapov, “Survey and challenges of QoE\nmanagement issues in wireless networks,” Journal of Computer Net-\nworks and Communications, vol. 2013, 2013.\n[49]\nR. Pascanu, C. Gulcehre, K. Cho, and Y. Bengio, “How to construct\ndeep recurrent neural networks,” arXiv preprint arXiv:1312.6026,\n2013.\n[50]\nM. Klapper-Rybicka, N. N. Schraudolph, and J. Schmidhuber, “Un-\nsupervised learning in LSTM recurrent neural networks,” in Artiﬁcial\nNeural Networks ICANN 2001, pp. 684–691, Springer, 2001.\n[51]\nG. E. Hinton, “Boltzmann machine,” Scholarpedia, vol. 2, no. 5,\np. 1668, 2007. revision #91075.\n[52]\nR. Salakhutdinov and G. Hinton, “Deep Boltzmann machines,” in\nArtiﬁcial Intelligence and Statistics, pp. 448–455, 2009.\n[53]\nK. Tsagkaris, A. Katidiotis, and P. Demestichas, “Neural network-\nbased learning schemes for cognitive radio systems,” Computer Com-\nmunications, vol. 31, no. 14, pp. 3394–3404, 2008.\n[54]\nF. H. V. Teles and L. L. Lee, “A Neural Architecture Based on the\nAdaptive Resonant Theory and Recurrent Neural Networks,” IJCSA,\nvol. 4, no. 3, pp. 45–56, 2007.\n[55]\nD. Munaretto, D. Zucchetto, A. Zanella, and M. Zorzi, “Data-driven\nQoE optimization techniques for multi-user wireless networks,” in\nComputing, Networking and Communications (ICNC), 2015 Interna-\ntional Conference on, pp. 653–657, IEEE, 2015.\n[56]\nL. Badia, D. Munaretto, A. Testolin, A. Zanella, and M. Zorzi,\n“Cognition-based networks: Applying cognitive science to multimedia\nwireless networking,” in A World of Wireless, Mobile and Multimedia\nNetworks (WoWMoM), 2014 IEEE 15th International Symposium on,\npp. 1–6, IEEE, 2014.\n[57]\nN. Grira, M. Crucianu, and N. Boujemaa, “Unsupervised and semi-\nsupervised clustering: a brief survey,” A Review of Machine Learning\nTechniques for Processing Multimedia Content, vol. 1, pp. 9–16, 2004.\n[58]\nP. Berkhin, “A survey of clustering data mining techniques,” in\nGrouping multidimensional data, pp. 25–71, Springer, 2006.\n[59]\nM. H. Bhuyan, D. K. Bhattacharyya, and J. K. Kalita, “Network\nanomaly detection: methods, systems and tools,” Communications\nSurveys & Tutorials, IEEE, vol. 16, no. 1, pp. 303–336, 2014.\n[60]\nA. McGregor, M. Hall, P. Lorier, and J. Brunskill, “Flow clustering\nusing machine learning techniques,” in Passive and Active Network\nMeasurement, pp. 205–214, Springer, 2004.\n[61]\nR. Xu and D. Wunsch, “Survey of clustering algorithms,” IEEE\nTransactions on neural networks, vol. 16, no. 3, pp. 645–678, 2005.\n[62]\nM. Rehman and S. A. Mehdi, “Comparison of density-based clustering\nalgorithms,” Lahore College for Women University, Lahore, Pakistan,\nUniversity of Management and Technology, Lahore, Pakistan, 2005.\n[63]\nY. Chen and L. Tu, “Density-based clustering for real-time stream\ndata,” in Proceedings of the 13th ACM SIGKDD international confer-\nence on Knowledge discovery and data mining, pp. 133–142, ACM,\n2007.\n[64]\nK. Leung and C. Leckie, “Unsupervised anomaly detection in network\nintrusion detection using clusters,” in Proceedings of the Twenty-eighth\nAustralasian conference on Computer Science-Volume 38, pp. 333–\n342, Australian Computer Society, Inc., 2005.\n[65]\nP. Mangiameli, S. K. Chen, and D. West, “A comparison of SOM neu-\nral network and hierarchical clustering methods,” European Journal of\nOperational Research, vol. 93, no. 2, pp. 402–417, 1996.\n[66]\nP. Orbanz and Y. W. Teh, “Bayesian nonparametric models,” in\nEncyclopedia of Machine Learning, pp. 81–89, Springer, 2011.\n[67]\nB. Kurt, A. T. Cemgil, M. Mungan, and E. Saygun, “Bayesian\nnonparametric clustering of network trafﬁc data,”\n[68]\nX. Jin and J. Han, Encyclopedia of Machine Learning, ch. Partitional\nClustering, pp. 766–766. Boston, MA: Springer US, 2010.\n[69]\nS. R. Gaddam, V. V. Phoha, and K. S. Balagani, “K-means+ ID3: A\nnovel method for supervised anomaly detection by cascading k-means\nclustering and ID3 decision tree learning methods,” IEEE Transactions\non Knowledge and Data Engineering, vol. 19, no. 3, pp. 345–354,\n2007.\n[70]\nL. Yingqiu, L. Wei, and L. Yunchun, “Network trafﬁc classiﬁcation\nusing K-Means clustering,” in Second International Multi-Symposiums\non Computer and Computational Sciences (IMSCCS), 2007., pp. 360–\n365, IEEE, 2007.\n[71]\nM. Jianliang, S. Haikun, and B. Ling, “The application on intrusion\ndetection based on k-means cluster algorithm,” in Information Technol-\nogy and Applications, 2009. IFITA’09. International Forum on, vol. 1,\npp. 150–152, IEEE, 2009.\n[72]\nR. Chitrakar and H. Chuanhe, “Anomaly detection using support vector\nmachine classiﬁcation with k-medoids clustering,” in Internet (AH-\nICI), 2012 Third Asian Himalayas International Conference on, pp. 1–\n5, IEEE, 2012.\n[73]\nR. Chitrakar and H. Chuanhe, “Anomaly based intrusion detection\nusing hybrid learning approach of combining k-medoids clustering and\nnaive Bayes classiﬁcation,” in Wireless Communications, Networking\nand Mobile Computing (WiCOM), 2012 8th International Conference\non, pp. 1–5, IEEE, 2012.\n[74]\nM. A. Figueiredo and A. K. Jain, “Unsupervised learning of ﬁnite\nmixture models,” Pattern Analysis and Machine Intelligence, IEEE\nTransactions on, vol. 24, no. 3, pp. 381–396, 2002.\n[75]\nM. E. Newman and E. A. Leicht, “Mixture models and exploratory\nanalysis in networks,” Proceedings of the National Academy of Sci-\nences, vol. 104, no. 23, pp. 9564–9569, 2007.\n[76]\nM. Bahrololum and M. Khaleghi, “Anomaly intrusion detection system\nusing gaussian mixture model,” in Convergence and Hybrid Informa-\ntion Technology, 2008. ICCIT’08. Third International Conference on,\nvol. 1, pp. 1162–1167, IEEE, 2008.\n[77]\nW. Chimphlee, A. H. Abdullah, M. N. M. Sap, S. Srinoy, and\nS. Chimphlee, “Anomaly-based intrusion detection using fuzzy rough\nclustering,” in Hybrid Information Technology, 2006. ICHIT’06. Inter-\nnational Conference on, vol. 1, pp. 329–334, IEEE, 2006.\n[78]\nM. Adda, K. Qader, and M. Al-Kasassbeh, “Comparative analysis of\nclustering techniques in network trafﬁc faults classiﬁcation,” Interna-\ntional Journal of Innovative Research in Computer and Communica-\ntion Engineering, vol. 5, no. 4, pp. 6551–6563, 2017.\n[79]\nA. Vl˘adut¸u, D. Com˘aneci, and C. Dobre, “Internet trafﬁc classiﬁcation\nbased on ﬂows’ statistical properties with machine learning,” Interna-\ntional Journal of Network Management, vol. 27, no. 3, 2017.\n[80]\nJ. Liu, Y. Fu, J. Ming, Y. Ren, L. Sun, and H. Xiong, “Effective and\nreal-time in-app activity analysis in encrypted internet trafﬁc streams,”\nin Proceedings of the 23rd ACM SIGKDD International Conference\non Knowledge Discovery and Data Mining, pp. 335–344, ACM, 2017.\n[81]\nM. S. Parwez, D. Rawat, and M. Garuba, “Big data analytics for\nuser activity analysis and user anomaly detection in mobile wireless\nnetwork,” IEEE Transactions on Industrial Informatics, 2017.\n[82]\nT. Lorido-Botran, S. Huerta, L. Tom´as, J. Tordsson, and B. Sanz, “An\nunsupervised approach to online noisy-neighbor detection in cloud data\ncenters,” Expert Systems with Applications, vol. 89, pp. 188–204, 2017.\n[83]\nG. Frishman, Y. Ben-Itzhak, and O. Margalit, “Cluster-based load\nbalancing for better network security,” in Proceedings of the Workshop\non Big Data Analytics and Machine Learning for Data Communication\nNetworks, pp. 7–12, ACM, 2017.\n[84]\nG. R. Kumar, N. Mangathayaru, and G. Narsimha, “A feature cluster-\ning based dimensionality reduction for intrusion detection (fcbdr).,”\nIADIS International Journal on Computer Science & Information\nSystems, vol. 12, no. 1, 2017.\n[85]\nT. Wiradinata and A. S. Paramita, “Clustering and feature selection\ntechnique for improving internet trafﬁc classiﬁcation using k-nn,”\n2016.\n[86]\nC. M. Bishop, “Latent variable models,” in Learning in graphical\nmodels, pp. 371–403, Springer, 1998.\n[87]\nA. Skrondal and S. RABE-HESKETH, “Latent variable modelling: a\n31\nsurvey,” Scandinavian Journal of Statistics, vol. 34, no. 4, pp. 712–\n745, 2007.\n[88]\nC. M. Bishop, Neural networks for pattern recognition.\nOxford\nuniversity press, 1995.\n[89]\nJ. Josse and F. Husson, “Selecting the number of components in\nprincipal component analysis using cross-validation approximations,”\nComputational Statistics & Data Analysis, vol. 56, no. 6, pp. 1869–\n1879, 2012.\n[90]\nA. Hyv¨arinen and E. Oja, “Independent component analysis: algo-\nrithms and applications,” Neural networks, vol. 13, no. 4, pp. 411–430,\n2000.\n[91]\nY.-X. Wang and Y.-J. Zhang, “Nonnegative matrix factorization: A\ncomprehensive review,” IEEE Transactions on Knowledge and Data\nEngineering,, vol. 25, no. 6, pp. 1336–1353, 2013.\n[92]\nD. D. Lee and H. S. Seung, “Algorithms for non-negative matrix\nfactorization,” in Advances in neural information processing systems,\npp. 556–562, 2001.\n[93]\nO. Capp´e, E. Moulines, and T. Ryd´en, “Inference in hidden Markov\nmodels,” in Proceedings of EUSFLAT Conference, pp. 14–16, 2009.\n[94]\nM. O. Duff, Optimal Learning: Computational procedures for Bayes-\nadaptive Markov decision processes.\nPhD thesis, University of\nMassachusetts Amherst, 2002.\n[95]\nM. J. Beal, Variational algorithms for approximate Bayesian inference.\nUniversity of London United Kingdom, 2003.\n[96]\nT. P. Minka, A family of algorithms for approximate Bayesian infer-\nence. PhD thesis, Massachusetts Institute of Technology, 2001.\n[97]\nH. Wang and D.-Y. Yeung, “Towards Bayesian deep learning: A\nsurvey,” arXiv preprint arXiv:1604.01662, 2016.\n[98]\nC. DuBois, J. R. Foulds, and P. Smyth, “Latent set models for two-\nmode network data.,” in ICWSM, 2011.\n[99]\nJ. R. Foulds, C. DuBois, A. U. Asuncion, C. T. Butts, and P. Smyth,\n“A dynamic relational inﬁnite feature model for longitudinal social\nnetworks.,” in AISTATS, vol. 11, pp. 287–295, 2011.\n[100]\nJ.-A. Hern´andez and I. W. Phillips, “Weibull mixture model to\ncharacterise end-to-end internet delay at coarse time-scales,” IEE\nProceedings-Communications, vol. 153, no. 2, pp. 295–304, 2006.\n[101]\nJ. M. Agosta, J. Chandrashekar, M. Crovella, N. Taft, and D. Ting,\n“Mixture models of endhost network trafﬁc,” in INFOCOM, 2013\nProceedings IEEE, pp. 225–229, IEEE, 2013.\n[102]\nR. Yan and R. Liu, “Principal component analysis based network trafﬁc\nclassiﬁcation,” Journal of computers, vol. 9, no. 5, pp. 1234–1240,\n2014.\n[103]\nX. Xu and X. Wang, “An adaptive network intrusion detection method\nbased on PCA and support vector machines,” in Advanced Data Mining\nand Applications, pp. 696–703, Springer, 2005.\n[104]\nX. Guan, W. Wang, and X. Zhang, “Fast intrusion detection based on\na non-negative matrix factorization model,” Journal of Network and\nComputer Applications, vol. 32, no. 1, pp. 31–44, 2009.\n[105]\nZ. Albataineh and F. Salem, “New blind multiuser detection in DS-\nCDMA based on extension of efﬁcient fast independent component\nanalysis (EF-ICA),” in 2013 4th International Conference on Intelli-\ngent Systems, Modelling and Simulation, pp. 543–548, IEEE, 2013.\n[106]\nN. Ahmed, S. S. Kanhere, and S. Jha, “Probabilistic coverage in\nwireless sensor networks,” in Local Computer Networks, 2005. 30th\nAnniversary. The IEEE Conference on, pp. 8–pp, IEEE, 2005.\n[107]\nV.\nChatzigiannakis,\nS.\nPapavassiliou,\nM.\nGrammatikou,\nand\nB. Maglaris, “Hierarchical anomaly detection in distributed large-scale\nsensor networks,” in Computers and Communications, 2006. ISCC’06.\nProceedings. 11th IEEE Symposium on, pp. 761–767, IEEE, 2006.\n[108]\nR. Gu, H. Wang, and Y. Ji, “Early trafﬁc identiﬁcation using Bayesian\nnetworks,” in Network Infrastructure and Digital Content, 2010 2nd\nIEEE International Conference on, pp. 564–568, IEEE, 2010.\n[109]\nJ. Xu and C. Shelton, “Continuous time Bayesian networks for host\nlevel network intrusion detection,” Machine learning and knowledge\ndiscovery in databases, pp. 613–627, 2008.\n[110]\nN. Al-Rousan, S. Haeri, and L. Trajkovi´c, “Feature selection for\nclassiﬁcation of BGP anomalies using Bayesian models,” in Machine\nLearning and Cybernetics (ICMLC), 2012 International Conference\non, vol. 1, pp. 140–147, IEEE, 2012.\n[111]\nD.-p. Liu, M.-w. Zhang, and T. Li, “Network trafﬁc analysis using\nreﬁned Bayesian reasoning to detect ﬂooding and port scan attacks,”\nin Advanced Computer Theory and Engineering, 2008. ICACTE’08.\nInternational Conference on, pp. 1000–1004, IEEE, 2008.\n[112]\nM. Ishiguro, H. Suzuki, I. Murase, and H. Ohno, “Internet threat\ndetection system using Bayesian estimation,” in Proc. The 16th Annual\nComputer Security Incident Handling Conference, 2004.\n[113]\nD. Janakiram, V. Reddy, and A. P. Kumar, “Outlier detection in\nwireless sensor networks using Bayesian belief networks,” in Com-\nmunication System Software and Middleware, 2006. Comsware 2006.\nFirst International Conference on, pp. 1–6, IEEE, 2006.\n[114]\nS. Haykin, K. Huber, and Z. Chen, “Bayesian sequential state estima-\ntion for MIMO wireless communications,” Proceedings of the IEEE,\nvol. 92, no. 3, pp. 439–454, 2004.\n[115]\nS. Ito and N. Kawaguchi, “Bayesian based location estimation system\nusing wireless LAN,” in Pervasive Computing and Communications\nWorkshops, 2005. PerCom 2005 Workshops. Third IEEE International\nConference on, pp. 273–278, IEEE, 2005.\n[116]\nS. Liu, J. Hu, S. Hao, and T. Song, “Improved em method for internet\ntrafﬁc classiﬁcation,” in Knowledge and Smart Technology (KST), 2016\n8th International Conference on, pp. 13–17, IEEE, 2016.\n[117]\nH. Shi, H. Li, D. Zhang, C. Cheng, and W. Wu, “Efﬁcient and robust\nfeature extraction and selection for trafﬁc classiﬁcation,” Computer\nNetworks, vol. 119, pp. 1–16, 2017.\n[118]\nS. Troia, G. Sheng, R. Alvizu, G. A. Maier, and A. Pattavina,\n“Identiﬁcation of tidal-trafﬁc patterns in metro-area mobile networks\nvia matrix factorization based model,” in Pervasive Computing and\nCommunications Workshops (PerCom Workshops), 2017 IEEE Inter-\nnational Conference on, pp. 297–301, IEEE, 2017.\n[119]\nL. Nie, D. Jiang, and Z. Lv, “Modeling network trafﬁc for trafﬁc matrix\nestimation and anomaly detection based on bayesian network in cloud\ncomputing networks,” Annals of Telecommunications, vol. 72, no. 5-6,\npp. 297–305, 2017.\n[120]\nJ.-h. Bang, Y.-J. Cho, and K. Kang, “Anomaly detection of network-\ninitiated lte signaling trafﬁc in wireless sensor and actuator networks\nbased on a hidden semi-markov model,” Computers & Security,\nvol. 65, pp. 108–120, 2017.\n[121]\nX. Chen, K. Irie, D. Banks, R. Haslinger, J. Thomas, and M. West,\n“Scalable bayesian modeling, monitoring and analysis of dynamic\nnetwork ﬂow data,” Journal of the American Statistical Association,\nno. just-accepted, 2017.\n[122]\nB. Mokhtar and M. Eltoweissy, “Big data and semantics management\nsystem for computer networks,” Ad Hoc Networks, vol. 57, pp. 32–51,\n2017.\n[123]\nA. Furno, M. Fiore, and R. Stanica, “Joint spatial and temporal\nclassiﬁcation of mobile trafﬁc demands,” in INFOCOM–36th Annual\nIEEE International Conference on Computer Communications, 2017.\n[124]\nM. Malli, N. Said, and A. Fadlallah, “A new model for rating users\nproﬁles in online social networks,” Computer and Information Science,\nvol. 10, no. 2, p. 39, 2017.\n[125]\nS. T. Roweis and L. K. Saul, “Nonlinear dimensionality reduction by\nlocally linear embedding,” Science, vol. 290, no. 5500, pp. 2323–2326,\n2000.\n[126]\nE. Keogh and A. Mueen, “Curse of dimensionality,” in Encyclopedia\nof Machine Learning, pp. 257–258, Springer, 2011.\n[127]\nP. Pudil and J. Novoviˇcov´a, “Novel methods for feature subset se-\nlection with respect to problem knowledge,” in Feature Extraction,\nConstruction and Selection, pp. 101–116, Springer, 1998.\n32\n[128]\nL. Yu and H. Liu, “Feature selection for high-dimensional data: A\nfast correlation-based ﬁlter solution,” in International Conference on\nMachine Learning, vol. 3, pp. 856–863, 2003.\n[129]\nW. M. Hartmann, “Dimension reduction vs. variable selection,” in\nApplied Parallel Computing. State of the Art in Scientiﬁc Computing,\npp. 931–938, Springer, 2006.\n[130]\nI. K. Fodor, “A survey of dimension reduction techniques,” Technical\nReport UCRL-ID-148494, Lawrence Livermore National Laboratory,\n2002.\n[131]\nJ. B. Tenenbaum, V. De Silva, and J. C. Langford, “A global geometric\nframework for nonlinear dimensionality reduction,” science, vol. 290,\nno. 5500, pp. 2319–2323, 2000.\n[132]\nC. Bishop, M. Svensn, and C. K. Williams, “Gtm: The generative\ntopographic mapping,” 1998.\n[133]\nT. Hastie and W. Stuetzle, “Principal curves,” Journal of the American\nStatistical Association, vol. 84, no. 406, pp. 502–516, 1989.\n[134]\nD. Lee, “Estimations of principal curves,” http://www.dgp.toronto.edu/\n∼dwlee/pcurve/pcurve csc2515.pdf.\n[135]\nJ. B. Kruskal, “Nonmetric multidimensional scaling: a numerical\nmethod,” Psychometrika, vol. 29, no. 2, pp. 115–129, 1964.\n[136]\nL. v. d. Maaten and G. Hinton, “Visualizing data using t-SNE,” Journal\nof Machine Learning Research, vol. 9, no. Nov, pp. 2579–2605, 2008.\n[137]\nJ. Cao, Z. Fang, G. Qu, H. Sun, and D. Zhang, “An accurate trafﬁc\nclassiﬁcation model based on support vector machines,” International\nJournal of Network Management, vol. 27, no. 1, 2017.\n[138]\nW. Zhou, X. Zhou, S. Dong, and B. Lubomir, “A som and pnn model\nfor network trafﬁc classiﬁcation,” Bolet´ın T´ecnico, vol. 55, no. 1,\npp. 174–182, 2017.\n[139]\nS. M. Erfani, S. Rajasegarar, S. Karunasekera, and C. Leckie, “High-\ndimensional and large-scale anomaly detection using a linear one-class\nsvm with deep learning,” Pattern Recognition, vol. 58, pp. 121–134,\n2016.\n[140]\nM. Nicolau, J. McDermott, et al., “A hybrid autoencoder and density\nestimation model for anomaly detection,” in International Conference\non Parallel Problem Solving from Nature, pp. 717–726, Springer, 2016.\n[141]\nS. T. Ikram and A. K. Cherukuri, “Improving accuracy of intrusion\ndetection model using pca and optimized svm,” Journal of computing\nand information technology, vol. 24, no. 2, pp. 133–148, 2016.\n[142]\nJ. Moysen, L. Giupponi, and J. Mangues-Bafalluy, “A mobile network\nplanning tool based on data analytics,” Mobile Information Systems,\nvol. 2017, 2017.\n[143]\nS. A. Ossia, A. S. Shamsabadi, A. Taheri, H. R. Rabiee, N. Lane,\nand H. Haddadi, “A hybrid deep learning architecture for privacy-\npreserving mobile analytics,” arXiv preprint arXiv:1703.02952, 2017.\n[144]\nS. Rajendran, W. Meert, D. Giustiniano, V. Lenders, and S. Pollin,\n“Distributed deep learning models for wireless signal classiﬁcation\nwith low-cost spectrum sensors,” arXiv preprint arXiv:1707.08908,\n2017.\n[145]\nM. H. Sarshar, Analyzing Large Scale Wi-Fi Data Using Supervised\nand Unsupervised Learning Techniques. PhD thesis, 2017.\n[146]\nS. Ramaswamy, R. Rastogi, and K. Shim, “Efﬁcient algorithms for\nmining outliers from large data sets,” in ACM Sigmod Record, vol. 29,\npp. 427–438, ACM, 2000.\n[147]\nJ. Tang, Z. Chen, A. W.-C. Fu, and D. W. Cheung, “Enhancing\neffectiveness of outlier detections for low density patterns,” in Paciﬁc-\nAsia Conference on Knowledge Discovery and Data Mining, pp. 535–\n548, Springer, 2002.\n[148]\nW. Jin, A. Tung, J. Han, and W. Wang, “Ranking outliers using sym-\nmetric neighborhood relationship,” Advances in Knowledge Discovery\nand Data Mining, pp. 577–593, 2006.\n[149]\nH.-P. Kriegel, P. Kr¨oger, E. Schubert, and A. Zimek, “Loop: local\noutlier probabilities,” in Proceedings of the 18th ACM conference on\nInformation and knowledge management, pp. 1649–1652, ACM, 2009.\n[150]\nZ. He, X. Xu, and S. Deng, “Discovering cluster-based local outliers,”\nPattern Recognition Letters, vol. 24, no. 9, pp. 1641–1650, 2003.\n[151]\nM. Goldstein and S. Uchida, “Behavior analysis using unsupervised\nanomaly detection,” in The 10th Joint Workshop on Machine Percep-\ntion and Robotics (MPR 2014). Online, 2014.\n[152]\nM. Goldstein and S. Uchida, “A comparative evaluation of unsuper-\nvised anomaly detection algorithms for multivariate data,” PloS one,\nvol. 11, no. 4, p. e0152173, 2016.\n[153]\nM. Goldstein and A. Dengel, “Histogram-based outlier score (HBOS):\nA fast unsupervised anomaly detection algorithm,” KI-2012: Poster\nand Demo Track, pp. 59–63, 2012.\n[154]\nV. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A\nsurvey,” ACM computing surveys (CSUR), vol. 41, no. 3, p. 15, 2009.\n[155]\nS. Richard S. and B. Andrew G., Reinforcement learning: an intro-\nduction. MIT Press, 1998.\n[156]\nR. S. Sutton and A. G. Barto, Reinforcement learning: An introduction,\nvol. 1. MIT press Cambridge, 1998.\n[157]\nV. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.\nBellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski,\net al., “Human-level control through deep reinforcement learning,”\nNature, vol. 518, no. 7540, pp. 529–533, 2015.\n[158]\nH. M. Schwartz, Multi-agent machine learning: A reinforcement\napproach. John Wiley & Sons, 2014.\n[159]\nK. Muhidul Islam and R. Bernhard, “Resource coordination in wireless\nsensor networks by cooperative reinforcement learning,” in Pervasive\nComputing and Communications Workshops (PERCOM Workshops),\n2012 IEEE International Conference on, pp. 895–900, IEEE, 2012.\n[160]\nS. Jeff, W. Wong-Keen, M. Andrew, and R. Martin, “Distributed value\nfunctions,” in 16th Conference on Machine Learning, pp. 371–378,\n1999.\n[161]\nL. Jarmo, K. Visa, K. Sanjeev R., and P. H. Vincent, “Reinforcement\nlearning based distributed multiagent sensing policy for cognitive radio\nnetworks,” in IEEE International Symposium on Dynamic Spectrum\nAccess Networks, pp. 642–646, IEEE, 2011.\n[162]\nB. Mario, J. Sudharman K., and A. Keith A., “Distributed reinforce-\nment learning based MAC protocols for autonomous cognitive sec-\nondary users,” in 20th Annual Wireless and Optical Communications\nConference, pp. 1–6, IEEE, 2011.\n[163]\nC. J. Watkins and P. Dayan, “Q-learning,” Machine learning, vol. 8,\nno. 3-4, pp. 279–292, 1992.\n[164]\nH. Tiansi and F. Yunsi, “QELAR: a machine-learning-based adaptive\nrouting protocol for energy-efﬁcient and lifetime-extended underwater\nsensor networks,” IEEE Transactions on Mobile Computing, vol. 9,\nno. 6, pp. 796–809, 2010.\n[165]\nM. H. Ling, K.-L. A. Yau, J. Qadir, G. S. Poh, and Q. Ni, “Application\nof reinforcement learning for security enhancement in cognitive radio\nnetworks,” Applied Soft Computing, vol. 37, pp. 809–829, 2015.\n[166]\nF. Pervez, M. Jaber, J. Qadir, S. Younis, and M. A. Imran, “Fuzzy\nq-learning-based user-centric backhaul-aware user cell association\nscheme,” in Wireless Communications and Mobile Computing Confer-\nence (IWCMC), 2017 13th International, pp. 1840–1845, IEEE, 2017.\n[167]\nJ. Zhang, Y. Xiang, Y. Wang, W. Zhou, Y. Xiang, and Y. Guan,\n“Network trafﬁc classiﬁcation using correlation information,” Parallel\nand Distributed Systems, IEEE Transactions on, vol. 24, no. 1,\npp. 104–117, 2013.\n[168]\nJ. Erman, A. Mahanti, and M. Arlitt, “Qrp05-4: Internet trafﬁc\nidentiﬁcation using machine learning,” in Global Telecommunications\nConference, 2006. GLOBECOM’06. IEEE, pp. 1–6, IEEE, 2006.\n[169]\nJ. Kornycky, O. Abdul-Hameed, A. Kondoz, and B. C. Barber, “Radio\nfrequency trafﬁc classiﬁcation over WLAN,” IEEE/ACM Transactions\non Networking, vol. 25, no. 1, pp. 56–68, 2017.\n[170]\nX. Liu, L. Pan, and X. Sun, “Real-time trafﬁc status classiﬁcation\nbased on gaussian mixture model,” in Data Science in Cyberspace\n(DSC), IEEE International Conference on, pp. 573–578, IEEE, 2016.\n33\n[171]\nJ. Erman, M. Arlitt, and A. Mahanti, “Trafﬁc classiﬁcation using clus-\ntering algorithms,” in Proceedings of the 2006 SIGCOMM workshop\non Mining network data, pp. 281–286, ACM, 2006.\n[172]\nT. T. Nguyen and G. Armitage, “Clustering to assist supervised\nmachine learning for real-time IP trafﬁc classiﬁcation,” in Communi-\ncations, 2008. ICC’08. IEEE International Conference on, pp. 5857–\n5862, IEEE, 2008.\n[173]\nM. Shaﬁq, X. Yu, A. A. Laghari, L. Yao, N. K. Karn, and F. Ab-\ndessamia, “Network trafﬁc classiﬁcation techniques and comparative\nanalysis using machine learning algorithms,” in Computer and Com-\nmunications (ICCC), 2016 2nd IEEE International Conference on,\npp. 2451–2455, IEEE, 2016.\n[174]\nY. Dhote, S. Agrawal, and A. J. Deen, “A survey on feature selec-\ntion techniques for internet trafﬁc classiﬁcation,” in Computational\nIntelligence and Communication Networks (CICN), 2015 International\nConference on, pp. 1375–1380, IEEE, 2015.\n[175]\nY. Huang, Y. Li, and B. Qiang, “Internet trafﬁc classiﬁcation based on\nmin-max ensemble feature selection,” in Neural Networks (IJCNN),\n2016 International Joint Conference on, pp. 3485–3492, IEEE, 2016.\n[176]\nL. Zhen and L. Qiong, “A new feature selection method for Internet\ntrafﬁc classiﬁcation using ML,” Physics Procedia, vol. 33, pp. 1338–\n1345, 2012.\n[177]\nJ. Erman, A. Mahanti, M. Arlitt, I. Cohen, and C. Williamson,\n“Ofﬂine/realtime trafﬁc classiﬁcation using semi-supervised learning,”\nPerformance Evaluation, vol. 64, no. 9, pp. 1194–1213, 2007.\n[178]\nL. Bernaille, R. Teixeira, I. Akodkenou, A. Soule, and K. Salamatian,\n“Trafﬁc classiﬁcation on the ﬂy,” ACM SIGCOMM Computer Com-\nmunication Review, vol. 36, no. 2, pp. 23–26, 2006.\n[179]\nS. Zander, T. Nguyen, and G. Armitage, “Automated trafﬁc clas-\nsiﬁcation and application identiﬁcation using machine learning,” in\nThe IEEE Conference on Local Computer Networks 30th Anniversary\n(LCN’05) l, pp. 250–257, IEEE, 2005.\n[180]\nT. P. Oliveira, J. S. Barbar, and A. S. Soares, “Computer network trafﬁc\nprediction: a comparison between traditional and deep learning neural\nnetworks,” International Journal of Big Data Intelligence, vol. 3, no. 1,\npp. 28–37, 2016.\n[181]\nN. Shrivastava and A. Dubey, “Internet trafﬁc data categorization using\nparticle of swarm optimization algorithm,” in Colossal Data Analysis\nand Networking (CDAN), Symposium on, pp. 1–8, IEEE, 2016.\n[182]\nT. Bakhshi and B. Ghita, “On Internet trafﬁc classiﬁcation: A two-\nphased machine learning approach,” Journal of Computer Networks\nand Communications, vol. 2016, 2016.\n[183]\nJ. Yang, J. Deng, S. Li, and Y. Hao, “Improved trafﬁc detection with\nsupport vector machine based on restricted Boltzmann machine,” Soft\nComputing, vol. 21, no. 11, pp. 3101–3112, 2017.\n[184]\nR. Gonzalez, F. Manco, A. Garcia-Duran, J. Mendes, F. Huici, S. Nic-\ncolini, and M. Niepert, “Net2Vec: Deep learning for the network,”\narXiv preprint arXiv:1705.03881, 2017.\n[185]\nM. E. Aminanto and K. Kim, “Deep learning-based feature selection\nfor intrusion detection system in transport layer,” http://caislab.kaist.\nac.kr/publication/paper ﬁles/2016/20160623 AM.pdf, 2016.\n[186]\nL. Nie, D. Jiang, S. Yu, and H. Song, “Network trafﬁc prediction\nbased on deep belief network in wireless mesh backbone networks,” in\nWireless Communications and Networking Conference (WCNC), 2017\nIEEE, pp. 1–5, IEEE, 2017.\n[187]\nC. Zhang, J. Jiang, and M. Kamel, “Intrusion detection using hierar-\nchical neural networks,” Pattern Recognition Letters, vol. 26, no. 6,\npp. 779–791, 2005.\n[188]\nB. C. Rhodes, J. A. Mahaffey, and J. D. Cannady, “Multiple self-\norganizing maps for intrusion detection,” in Proceedings of the 23rd\nnational information systems security conference, pp. 16–19, 2000.\n[189]\nH. G. Kayacik, M. Heywood, et al., “On the capability of an SOM\nbased intrusion detection system,” in Neural Networks, 2003. Proceed-\nings of the International Joint Conference on, vol. 3, pp. 1808–1813,\nIEEE, 2003.\n[190]\nS. Zanero, “Analyzing TCP trafﬁc patterns using self organizing maps,”\nin Image Analysis and Processing–ICIAP 2005, pp. 83–90, Springer,\n2005.\n[191]\nP. Lichodzijewski, A. N. Zincir-Heywood, and M. I. Heywood, “Host-\nbased intrusion detection using self-organizing maps,” in IEEE inter-\nnational joint conference on neural networks, pp. 1714–1719, 2002.\n[192]\nP. Lichodzijewski, A. N. Zincir-Heywood, and M. I. Heywood,\n“Dynamic intrusion detection using self-organizing maps,” in The\n14th Annual Canadian Information Technology Security Symposium\n(CITSS), Citeseer, 2002.\n[193]\nM. Amini, R. Jalili, and H. R. Shahriari, “RT-UNNID: A practical solu-\ntion to real-time network-based intrusion detection using unsupervised\nneural networks,” Computers & Security, vol. 25, no. 6, pp. 459–468,\n2006.\n[194]\nO. Depren, M. Topallar, E. Anarim, and M. K. Ciliz, “An intelligent\nintrusion detection system (IDS) for anomaly and misuse detection in\ncomputer networks,” Expert systems with Applications, vol. 29, no. 4,\npp. 713–722, 2005.\n[195]\nV. Golovko and L. Vaitsekhovich, “Neural network techniques for\nintrusion detection,” in Proc. Int. Conf. Neural Networks and Artiﬁcial\nIntelligence, pp. 65–69, 2006.\n[196]\nA. P. Muniyandi, R. Rajeswari, and R. Rajaram, “Network anomaly\ndetection by cascading k-means clustering and C4.5 decision tree\nalgorithm,” Procedia Engineering, vol. 30, pp. 174–182, 2012.\n[197]\nP. Casas, J. Mazel, and P. Owezarski, “Unsupervised network intru-\nsion detection systems: Detecting the unknown without knowledge,”\nComputer Communications, vol. 35, no. 7, pp. 772–783, 2012.\n[198]\nS. Zanero and S. M. Savaresi, “Unsupervised learning techniques\nfor an intrusion detection system,” in Proceedings of the 2004 ACM\nsymposium on Applied computing, pp. 412–419, ACM, 2004.\n[199]\nS. Zhong, T. M. Khoshgoftaar, and N. Seliya, “Clustering-based net-\nwork intrusion detection,” International Journal of reliability, Quality\nand safety Engineering, vol. 14, no. 02, pp. 169–187, 2007.\n[200]\nN. Greggio, “Anomaly detection in idss by means of unsupervised\ngreedy learning of ﬁnite mixture models,” Soft Computing, pp. 1–16,\n2017.\n[201]\nW. Wang and R. Battiti, “Identifying intrusions in computer networks\nwith Principal Component Analysis,” in Availability, Reliability and\nSecurity, 2006. ARES 2006. The First International Conference on,\npp. 8–pp, IEEE, 2006.\n[202]\nV. Golovko, L. U. Vaitsekhovich, P. Kochurko, U. S. Rubanau, et al.,\n“Dimensionality reduction and attack recognition using neural network\napproaches,” in Neural Networks, 2007. IJCNN 2007. International\nJoint Conference on, pp. 2734–2739, IEEE, 2007.\n[203]\nL. A. Gordon, M. P. Loeb, W. Lucyshyn, and R. Richardson, “2005\nCSI/FBI computer crime and security survey,” Computer Security\nJournal, 2005.\n[204]\n“2016 internet security threat report.” https://www.symantec.com/\nsecurity-center/threat-report. Accessed: 2017-02-02.\n[205]\nC.-F. Tsai, Y.-F. Hsu, C.-Y. Lin, and W.-Y. Lin, “Intrusion detection\nby machine learning: A review,” Expert Systems with Applications,\nvol. 36, no. 10, pp. 11994–12000, 2009.\n[206]\nW.-C. Lin, S.-W. Ke, and C.-F. Tsai, “CANN: An intrusion detection\nsystem based on combining cluster centers and nearest neighbors,”\nKnowledge-based systems, vol. 78, pp. 13–21, 2015.\n[207]\nJ. Mazel, P. Casas, R. Fontugne, K. Fukuda, and P. Owezarski,\n“Hunting attacks in the dark: clustering and correlation analysis for\nunsupervised anomaly detection,” International Journal of Network\nManagement, vol. 25, no. 5, pp. 283–305, 2015.\n[208]\nC. Sony and K. Cho, “Trafﬁc data repository at the WIDE project,”\nin Proceedings of USENIX 2000 Annual Technical Conference:\nFREENIX Track, pp. 263–270, 2000.\n[209]\nE. E. Papalexakis, A. Beutel, and P. Steenkiste, “Network anomaly\ndetection using co-clustering,” in Encyclopedia of Social Network\nAnalysis and Mining, pp. 1054–1068, Springer, 2014.\n34\n[210]\nV. Miˇskovic, M. Milosavljevi´c, S. Adamovi´c, and A. Jevremovi´c,\n“Application of hybrid incremental machine learning methods to\nanomaly based intrusion detection,” methods, vol. 5, p. 6, 2014.\n[211]\nN. F. Haq, A. R. Onik, M. Avishek, K. Hridoy, M. Rafni, F. M.\nShah, and D. M. Farid, “Application of machine learning approaches\nin intrusion detection system: a survey,” International Journal of\nAdvanced Research in Artiﬁcial Intelligence, 2015.\n[212]\nT. H¨am¨al¨ainen, “Artiﬁcial immune system based intrusion detection:\ninnate immunity using an unsupervised learning approach,” Interna-\ntional Journal of Digital Content Technology and its Applications\n(JDCTA), 2014.\n[213]\nG. K. Chaturvedi, A. K. Chaturvedi, and V. R. More, “A study of in-\ntrusion detection system for cloud network using FC-ANN algorithm,”\n2016.\n[214]\nC. Modi, D. Patel, B. Borisaniya, H. Patel, A. Patel, and M. Rajarajan,\n“A survey of intrusion detection techniques in cloud,” Journal of\nNetwork and Computer Applications, vol. 36, no. 1, pp. 42–57, 2013.\n[215]\nD. J. Weller-Fahy, B. J. Borghetti, and A. A. Sodemann, “A survey\nof distance and similarity measures used within network intrusion\nanomaly detection,” IEEE Communications Surveys & Tutorials,\nvol. 17, no. 1, pp. 70–91, 2015.\n[216]\nR. Mitchell and R. Chen, “A survey of intrusion detection in wireless\nnetwork applications,” Computer Communications, vol. 42, pp. 1–23,\n2014.\n[217]\nM. Ahmed, A. N. Mahmood, and J. Hu, “A survey of network anomaly\ndetection techniques,” Journal of Network and Computer Applications,\nvol. 60, pp. 19–31, 2016.\n[218]\nL. Xiao, Y. Chen, and C. K. Chang, “Bayesian model averaging of\nBayesian network classiﬁers for intrusion detection,” in Computer\nSoftware and Applications Conference Workshops (COMPSACW),\n2014 IEEE 38th International, pp. 128–133, IEEE, 2014.\n[219]\nB. Al-Musawi, P. Branch, and G. Armitage, “BGP anomaly detection\ntechniques: A survey,” IEEE Communications Surveys & Tutorials,\nvol. 19, no. 1, pp. 377–396, 2017.\n[220]\nB. AsSadhan, K. Zeb, J. Al-Muhtadi, and S. Alshebeili, “Anomaly\ndetection based on LRD behavior analysis of decomposed control\nand data planes network trafﬁc using soss and farima models,” IEEE\nAccess, 2017.\n[221]\nA. Kulakov, D. Davcev, and G. Trajkovski, “Application of wavelet\nneural-networks in wireless sensor networks,” in Software Engi-\nneering, Artiﬁcial Intelligence, Networking and Parallel/Distributed\nComputing, 2005 and First ACIS International Workshop on Self-\nAssembling Wireless Networks. SNPD/SAWN 2005. Sixth International\nConference on, pp. 262–267, IEEE, 2005.\n[222]\nS. G. Akojwar and R. M. Patrikar, “Improving life time of wireless\nsensor networks using neural network based classiﬁcation techniques\nwith cooperative routing,” International Journal of Communications,\nvol. 2, no. 1, pp. 75–86, 2008.\n[223]\nC. Li, X. Xie, Y. Huang, H. Wang, and C. Niu, “Distributed data\nmining based on deep neural network for wireless sensor network,”\nInternational Journal of Distributed Sensor Networks, 2014.\n[224]\nE. Gelenbe, R. Lent, A. Montuori, and Z. Xu, “Cognitive packet net-\nworks: QoS and performance,” in Modeling, Analysis and Simulation\nof Computer and Telecommunications Systems, 2002. MASCOTS 2002.\nProceedings. 10th IEEE International Symposium on, pp. 3–9, IEEE,\n2002.\n[225]\nM. Cordina and C. J. Debono, “Increasing wireless sensor network\nlifetime through the application of som neural networks,” in Commu-\nnications, Control and Signal Processing, 2008. ISCCSP 2008. 3rd\nInternational Symposium on, pp. 467–471, IEEE, 2008.\n[226]\nN. Enami and R. A. Moghadam, “Energy based clustering self organiz-\ning map protocol for extending wireless sensor networks lifetime and\ncoverage,” Canadian Journal on Multimedia and Wireless Networks,\nvol. 1, no. 4, pp. 42–54, 2010.\n[227]\nL. Dehni, F. Krief, and Y. Bennani, “Power control and clustering\nin wireless sensor networks,” in Challenges in Ad Hoc Networking,\npp. 31–40, Springer, 2006.\n[228]\nF. Oldewurtel and P. Mahonen, “Neural wireless sensor networks,”\nin Systems and Networks Communications, 2006. ICSNC’06. Interna-\ntional Conference on, pp. 28–28, IEEE, 2006.\n[229]\nG. A. Barreto, J. Mota, L. G. Souza, R. A. Frota, and L. Aguayo,\n“Condition monitoring of 3G cellular networks through competitive\nneural models,” Neural Networks, IEEE Transactions on, vol. 16, no. 5,\npp. 1064–1075, 2005.\n[230]\nA. I. Moustapha and R. R. Selmic, “Wireless sensor network mod-\neling using modiﬁed recurrent neural networks: Application to fault\ndetection,” Instrumentation and Measurement, IEEE Transactions on,\nvol. 57, no. 5, pp. 981–988, 2008.\n[231]\nD. Hoang, R. Kumar, and S. Panda, “Fuzzy C-Means clustering\nprotocol for wireless sensor networks,” in Industrial Electronics (ISIE),\n2010 IEEE International Symposium on, pp. 3477–3482, IEEE, 2010.\n[232]\nE. I. Oyman and C. Ersoy, “Multiple sink network design problem in\nlarge scale wireless sensor networks,” in Communications, 2004 IEEE\nInternational Conference on, vol. 6, pp. 3663–3667, IEEE, 2004.\n[233]\nW. Zhang, S. K. Das, and Y. Liu, “A trust based framework for secure\ndata aggregation in wireless sensor networks,” in Sensor and Ad Hoc\nCommunications and Networks, 2006. SECON’06. 2006 3rd Annual\nIEEE Communications Society on, vol. 1, pp. 60–69, IEEE, 2006.\n[234]\nG. Kapoor and K. Rajawat, “Outlier-aware cooperative spectrum sens-\ning in cognitive radio networks,” Physical Communication, vol. 17,\npp. 118–127, 2015.\n[235]\nT. Ristaniemi and J. Joutsensalo, “Advanced ICA-based receivers for\nblock fading DS-CDMA channels,” Signal Processing, vol. 82, no. 3,\npp. 417–431, 2002.\n[236]\nM. S. Mushtaq, B. Augustin, and A. Mellouk, “Empirical study based\non machine learning approach to assess the QoS/QoE correlation,” in\nNetworks and Optical Communications (NOC), 2012 17th European\nConference on, pp. 1–7, IEEE, 2012.\n[237]\nM. Alreshoodi and J. Woods, “Survey on QoE\\ QoS CORRELATION\nModels for Multimedia Services,” International Journal of Distributed\nand Parallel Systems, vol. 4, no. 3, p. 53, 2013.\n[238]\nA. Testolin, M. Zanforlin, M. De Filippo De Grazia, D. Munaretto,\nA. Zanella, and M. Zorzi, “A machine learning approach to QoE-based\nvideo admission control and resource allocation in wireless systems,”\nin Ad Hoc Networking Workshop (MED-HOC-NET), 2014 13th Annual\nMediterranean, pp. 31–38, IEEE, 2014.\n[239]\nS. Przylucki, “Assessment of the QoE in Voice Services Based on the\nSelf-Organizing Neural Network Structure,” in Computer Networks,\npp. 144–153, Springer, 2011.\n[240]\nP. Ahammad, B. Kennedy, P. Ganti, and H. Kolam, “QoE-driven\nUnsupervised Image Categorization for Optimized Web Delivery:\nShort Paper,” in Proceedings of the ACM International Conference\non Multimedia, pp. 797–800, ACM, 2014.\n[241]\nD. C. Mocanu, G. Exarchakos, and A. Liotta, “Deep learning for\nobjective quality assessment of 3D images,” in Image Processing\n(ICIP), 2014 IEEE International Conference on, pp. 758–762, IEEE,\n2014.\n[242]\nB. Francisco, A. Ramon, P.-R. Jordi, and S. Oriol, “Distributed\nspectrum management based on reinforcement learning,” in 14th Inter-\nnational Conference on Cognitive Radio Oriented Wireless Networks\nand Communications, pp. 1–6, IEEE, 2009.\n[243]\nL. Xuedong, C. Min, X. Yang, B. LLangko, and L. Victo C. M.,\n“MRL-CC: a novel cooperative communication protocol for QoS\nprovisioning in wireless sensor networks,” International Journal of\nSensor Networks, vol. 8, no. 2, pp. 98–108, 2010.\n[244]\nP. Geurts, I. El Khayat, and G. Leduc, “A machine learning approach\nto improve congestion control over wireless computer networks,” in\nData Mining, 2004. ICDM’04. Fourth IEEE International Conference\non, pp. 383–386, IEEE, 2004.\n[245]\nK.-S. Hwang, S.-W. Tan, M.-C. Hsiao, and C.-S. Wu, “Cooperative\n35\nmultiagent congestion control for high-speed networks,” Systems, Man,\nand Cybernetics, Part B: Cybernetics, IEEE Transactions on, vol. 35,\nno. 2, pp. 255–268, 2005.\n[246]\nK. Winstein and H. Balakrishnan, “Tcp ex machina: computer-\ngenerated congestion control,” in ACM SIGCOMM Computer Com-\nmunication Review, vol. 43, pp. 123–134, ACM, 2013.\n[247]\nT. J. O’Shea and J. Hoydis, “An introduction to machine learning\ncommunications systems,” arXiv preprint arXiv:1702.00832, 2017.\n[248]\nT. J. O’Shea, T. Erpek, and T. C. Clancy, “Deep learning based MIMO\ncommunications,” arXiv preprint arXiv:1707.07980, 2017.\n[249]\nT. J. O’Shea, J. Corgan, and T. C. Clancy, “Unsupervised representa-\ntion learning of structured radio communication signals,” in Sensing,\nProcessing and Learning for Intelligent Machines (SPLINE), 2016\nFirst International Workshop on, pp. 1–5, IEEE, 2016.\n[250]\nT. Huang, H. Sethu, and N. Kandasamy, “A new approach to di-\nmensionality reduction for anomaly detection in data trafﬁc,” IEEE\nTransactions on Network and Service Management, vol. 13, no. 3,\npp. 651–665, 2016.\n[251]\nA. Zoha, A. Saeed, A. Imran, M. A. Imran, and A. Abu-Dayya, “A\nlearning-based approach for autonomous outage detection and cov-\nerage optimization,” Transactions on Emerging Telecommunications\nTechnologies, vol. 27, no. 3, pp. 439–450, 2016.\n[252]\nA. Shirazinia and S. Dey, “Power-constrained sparse gaussian linear\ndimensionality reduction over noisy channels,” IEEE Transactions on\nSignal Processing, vol. 63, no. 21, pp. 5837–5852, 2015.\n[253]\nS. Hou, R. C. Qiu, Z. Chen, and Z. Hu, “Svm and dimensionality\nreduction in cognitive radio with experimental validation,” arXiv\npreprint arXiv:1106.2325, 2011.\n[254]\nC. Khalid, E. Zyad, and B. Mohammed, “Network intrusion detection\nsystem using L1-norm PCA,” in Information Assurance and Security\n(IAS), 2015 11th International Conference on, pp. 118–122, IEEE,\n2015.\n[255]\nE. Goodman, J. Ingram, S. Martin, and D. Grunwald, “Using bipartite\nanomaly features for cyber security applications,” in Machine Learning\nand Applications (ICMLA), 2015 IEEE 14th International Conference\non, pp. 301–306, IEEE, 2015.\n[256]\nN. Patwari, A. O. Hero III, and A. Pacholski, “Manifold learning\nvisualization of network trafﬁc data,” in Proceedings of the 2005 ACM\nSIGCOMM workshop on Mining network data, pp. 191–196, ACM,\n2005.\n[257]\nD. L´opez-S´anchez, A. G. Arrieta, and J. M. Corchado, “Deep neural\nnetworks and transfer learning applied to multimedia web mining,” in\nDistributed Computing and Artiﬁcial Intelligence, 14th International\nConference, vol. 620, p. 124, Springer, 2018.\n[258]\nT. Ban, S. Pang, M. Eto, D. Inoue, K. Nakao, and R. Huang, “Towards\nearly detection of novel attack patterns through the lens of a large-\nscale darknet,” in Ubiquitous Intelligence & Computing, Advanced\nand Trusted Computing, Scalable Computing and Communications,\nCloud and Big Data Computing, Internet of People, and Smart World\nCongress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld), 2016 Intl\nIEEE Conferences, pp. 341–349, IEEE, 2016.\n[259]\nQ. Niyaz, W. Sun, and A. Y. Javaid, “A deep learning based DDoS de-\ntection system in software-deﬁned networking (SDN),” arXiv preprint\narXiv:1611.07400, 2016.\n[260]\nC. G. Cordero, S. Hauke, M. M¨uhlh¨auser, and M. Fischer, “Analyz-\ning ﬂow-based anomaly intrusion detection using replicator neural\nnetworks,” in Privacy, Security and Trust (PST), 2016 14th Annual\nConference on, pp. 317–324, IEEE, 2016.\n[261]\nZ. Chen, C. K. Yeo, B. S. Lee, and C. T. Lau, “A novel anomaly\ndetection system using feature-based MSPCA with sketch,” in Wireless\nand Optical Communication Conference (WOCC), 2017 26th, pp. 1–6,\nIEEE, 2017.\n[262]\nT. Matsuda, T. Morita, T. Kudo, and T. Takine, “Trafﬁc anomaly\ndetection based on robust principal component analysis using periodic\ntrafﬁc behavior,” IEICE Transactions on Communications, vol. 100,\nno. 5, pp. 749–761, 2017.\n[263]\nI. S. Thaseen and C. A. Kumar, “Intrusion detection model using\nfusion of PCA and optimized SVM,” in Contemporary Computing\nand Informatics (IC3I), 2014 International Conference on, pp. 879–\n884, IEEE, 2014.\n[264]\nB. Subba, S. Biswas, and S. Karmakar, “Enhancing performance of\nanomaly based intrusion detection systems through dimensionality\nreduction using principal component analysis,” in Advanced Networks\nand Telecommunications Systems (ANTS), 2016 IEEE International\nConference on, pp. 1–6, IEEE, 2016.\n[265]\nI. Z. Muttaqien and T. Ahmad, “Increasing performance of IDS by\nselecting and transforming features,” in Communication, Networks\nand Satellite (COMNETSAT), 2016 IEEE International Conference on,\npp. 85–90, IEEE, 2016.\n[266]\nN. Y. Almusallam, Z. Tari, P. Bertok, and A. Y. Zomaya, “Dimension-\nality reduction for intrusion detection systems in multi-data streamsa\nreview and proposal of unsupervised feature selection scheme,” in\nEmergent Computation, pp. 467–487, Springer, 2017.\n[267]\nY. Kumar, H. Farooq, and A. Imran, “Fault prediction and reliability\nanalysis in a real cellular network,” in Wireless Communications and\nMobile Computing Conference (IWCMC), 2017 13th International,\npp. 1090–1095, IEEE, 2017.\n[268]\nZ. Nascimento, D. Sadok, S. Fernandes, and J. Kelner, “Multi-objective\noptimization of a hybrid model for network trafﬁc classiﬁcation\nby combining machine learning techniques,” in Neural Networks\n(IJCNN), 2014 International Joint Conference on, pp. 2116–2122,\nIEEE, 2014.\n[269]\nZ. Ansari, M. Azeem, A. V. Babu, and W. Ahmed, “A fuzzy ap-\nproach for feature evaluation and dimensionality reduction to im-\nprove the quality of web usage mining results,” arXiv preprint\narXiv:1509.00690, 2015.\n[270]\nM. A. Alsheikh, S. Lin, H.-P. Tan, and D. Niyato, “Toward a robust\nsparse data representation for wireless sensor networks,” in Local\nComputer Networks (LCN), 2015 IEEE 40th Conference on, pp. 117–\n124, IEEE, 2015.\n[271]\nK. Labib and V. R. Vemuri, “An application of principal component\nanalysis to the detection and visualization of computer network at-\ntacks,” Annals of telecommunications, vol. 61, no. 1, pp. 218–234,\n2006.\n[272]\nJ. Lokoˇc, J. Kohout, P. ˇCech, T. Skopal, and T. Pevn`y, “k-NN\nclassiﬁcation of malware in HTTPS trafﬁc using the metric space\napproach,” in Paciﬁc-Asia Workshop on Intelligence and Security\nInformatics, pp. 131–145, Springer, 2016.\n[273]\nM. Ancona, W. Cazzola, S. Drago, and G. Quercini, “Visualizing\nand managing network topologies via rectangular dualization,” in\nComputers and Communications, 2006. ISCC’06. Proceedings. 11th\nIEEE Symposium on, pp. 1000–1005, IEEE, 2006.\n[274]\nG. Cherubin, I. Nouretdinov, A. Gammerman, R. Jordaney, Z. Wang,\nD. Papini, and L. Cavallaro, “Conformal clustering and its application\nto botnet trafﬁc.,” in SLDS, pp. 313–322, 2015.\n[275]\nI. Marsh, “A lightweight measurement platform for home internet\nmonitoring,” http://cheesepi.sics.se/Publications/mmsys2017.pdf.\n[276]\nJ. M. Lewis, V. R. De Sa, and L. Van Der Maaten, “Divvy: fast and\nintuitive exploratory data analysis,” The Journal of Machine Learning\nResearch, vol. 14, no. 1, pp. 3159–3163, 2013.\n[277]\nG. Holmes, A. Donkin, and I. H. Witten, “Weka: A machine learning\nworkbench,” in Intelligent Information Systems, 1994. Proceedings of\nthe 1994 Second Australian and New Zealand Conference on, pp. 357–\n361, IEEE, 1994.\n[278]\nQ. Liao and S. Stanczak, “Network state awareness and proactive\nanomaly detection in self-organizing networks,” in Globecom Work-\nshops (GC Wkshps), 2015 IEEE, pp. 1–6, IEEE, 2015.\n[279]\nS. Chernov, D. Petrov, and T. Ristaniemi, “Location accuracy impact\non cell outage detection in lte-a networks,” in Wireless Communi-\n36\ncations and Mobile Computing Conference (IWCMC), 2015 Interna-\ntional, pp. 1162–1167, IEEE, 2015.\n[280]\nA. Zoha, A. Saeed, A. Imran, M. A. Imran, and A. Abu-Dayya, “Data-\ndriven analytics for automated cell outage detection in self-organizing\nnetworks,” in Design of Reliable Communication Networks (DRCN),\n2015 11th International Conference on the, pp. 203–210, IEEE, 2015.\n[281]\nJ.\nTurkka,\nF.\nChernogorov,\nK.\nBrigatti,\nT.\nRistaniemi,\nand\nJ. Lempi¨ainen, “An approach for network outage detection from drive-\ntesting databases,” Journal of Computer Networks and Communica-\ntions, vol. 2012, 2012.\n[282]\nN. Kato, Z. M. Fadlullah, B. Mao, F. Tang, O. Akashi, T. Inoue, and\nK. Mizutani, “The deep learning vision for heterogeneous network\ntrafﬁc control: proposal, challenges, and future perspective,” IEEE\nWireless Communications, vol. 24, no. 3, pp. 146–153, 2017.\n[283]\nB. Mao, Z. M. Fadlullah, F. Tang, N. Kato, O. Akashi, T. Inoue, and\nK. Mizutani, “Routing or computing? the paradigm shift towards intel-\nligent computer network packet transmission based on deep learning,”\nIEEE Transactions on Computers, 2017.\n[284]\nJ. Qadir, N. Ahad, E. Mushtaq, and M. Bilal, “SDNs, clouds, and big\ndata: new opportunities,” in Frontiers of Information Technology (FIT),\n2014 12th International Conference on, pp. 28–33, IEEE, 2014.\n[285]\nB. A. Nunes, M. Mendonca, X.-N. Nguyen, K. Obraczka, and\nT. Turletti, “A survey of software-deﬁned networking: Past, present,\nand future of programmable networks,” Communications Surveys &\nTutorials, IEEE, vol. 16, no. 3, pp. 1617–1634, 2014.\n[286]\nH. Kim and N. Feamster, “Improving network management with soft-\nware deﬁned networking,” Communications Magazine, IEEE, vol. 51,\nno. 2, pp. 114–119, 2013.\n[287]\nJ. Ashraf and S. Latif, “Handling Intrusion and DDoS attacks in\nSoftware Deﬁned Networks using Machine Learning Techniques,” in\nSoftware Engineering Conference (NSEC), 2014 National, pp. 55–60,\nIEEE, 2014.\n[288]\nD. J. Dean, H. Nguyen, and X. Gu, “Ubl: unsupervised behavior\nlearning for predicting performance anomalies in virtualized cloud\nsystems,” in Proceedings of the 9th international conference on\nAutonomic computing, pp. 191–200, ACM, 2012.\n[289]\nD. He, S. Chan, X. Ni, and M. Guizani, “Software-deﬁned-networking-\nenabled trafﬁc anomaly detection and mitigation,” IEEE Internet of\nThings Journal, 2017.\n[290]\nK.\nK.\nGoswami,\n“Intelligent\nthreat-aware\nresponse\nsystem\nin\nsoftware-deﬁned networks,” http://scholarworks.sjsu.edu/etd theses/\n4801/, 2017.\n[291]\nA. S. da Silva, J. A. Wickboldt, L. Z. Granville, and A. Schaeffer-Filho,\n“ATLANTIC: a framework for anomaly trafﬁc detection, classiﬁcation,\nand mitigation in SDN,” in Network Operations and Management\nSymposium (NOMS), 2016 IEEE/IFIP, pp. 27–35, IEEE, 2016.\n[292]\nS.-h. Zhang, X.-x. Meng, and L.-h. Wang, “SDNForensics: A compre-\nhensive forensics framework for software deﬁned network,” Develop-\nment, vol. 3, no. 4, p. 5, 2017.\n[293]\nP. Amaral, J. Dinis, P. Pinto, L. Bernardo, J. Tavares, and H. S.\nMamede, “Machine learning in software deﬁned networks: Data col-\nlection and trafﬁc classiﬁcation,” in Network Protocols (ICNP), 2016\nIEEE 24th International Conference on, pp. 1–5, IEEE, 2016.\n[294]\nO. G. Aliu, A. Imran, M. A. Imran, and B. Evans, “A survey of\nself organisation in future cellular networks,” IEEE Communications\nSurveys & Tutorials, vol. 15, no. 1, pp. 336–361, 2013.\n[295]\nM. Bennis, S. M. Perlaza, P. Blasco, Z. Han, and H. V. Poor,\n“Self-organization in small cell networks: A reinforcement learning\napproach,” IEEE transactions on wireless communications, vol. 12,\nno. 7, pp. 3202–3212, 2013.\n[296]\nA. Imran, A. Zoha, and A. Abu-Dayya, “Challenges in 5g: how to\nempower son with big data for enabling 5g,” IEEE Network, vol. 28,\nno. 6, pp. 27–33, 2014.\n[297]\nX. Wang, X. Li, and V. C. Leung, “Artiﬁcial intelligence-based\ntechniques for emerging heterogeneous network: State of the arts,\nopportunities, and challenges,” IEEE Access, vol. 3, pp. 1379–1391,\n2015.\n[298]\nA. Misra and K. K. Sarma, “Self-organization and optimization in\nheterogenous networks,” in Interference Mitigation and Energy Man-\nagement in 5G Heterogeneous Cellular Networks, pp. 246–268, IGI\nGlobal, 2017.\n[299]\nZ. Zhang, K. Long, J. Wang, and F. Dressler, “On swarm intelligence\ninspired self-organized networking: its bionic mechanisms, designing\nprinciples and optimization approaches,” IEEE Communications Sur-\nveys & Tutorials, vol. 16, no. 1, pp. 513–537, 2014.\n[300]\nZ. Wen, R. Yang, P. Garraghan, T. Lin, J. Xu, and M. Rovatsos,\n“Fog orchestration for Internet of things services,” IEEE Internet\nComputing, vol. 21, no. 2, pp. 16–24, 2017.\n[301]\nJ. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of\nthings (IoT): A vision, architectural elements, and future directions,”\nFuture generation computer systems, vol. 29, no. 7, pp. 1645–1660,\n2013.\n[302]\nH.-Y. Kim and J.-M. Kim, “A load balancing scheme based on deep-\nlearning in IoT,” Cluster Computing, vol. 20, no. 1, pp. 873–878,\n2017.\n[303]\nD. Puschmann, P. Barnaghi, and R. Tafazolli, “Adaptive clustering for\ndynamic IoT data streams,” IEEE Internet of Things Journal, vol. 4,\nno. 1, pp. 64–74, 2017.\n[304]\nH. Assem, L. Xu, T. S. Buda, and D. OSullivan, “Machine learning\nas a service for enabling internet of things and people,” Personal and\nUbiquitous Computing, vol. 20, no. 6, pp. 899–914, 2016.\n[305]\nJ. Lee, M. Stanley, A. Spanias, and C. Tepedelenlioglu, “Integrating\nmachine learning in embedded sensor systems for internet-of-things\napplications,” in Signal Processing and Information Technology (IS-\nSPIT), 2016 IEEE International Symposium on, pp. 290–294, IEEE,\n2016.\n[306]\nP. Lin, D.-C. Lyu, F. Chen, S.-S. Wang, and Y. Tsao, “Multi-style\nlearning with denoising autoencoders for acoustic modeling in the\ninternet of things (IoT),” Computer Speech & Language, 2017.\n[307]\nR. Sommer and V. Paxson, “Outside the closed world: On using\nmachine learning for network intrusion detection,” in Security and\nPrivacy (SP), 2010 IEEE Symposium on, pp. 305–316, IEEE, 2010.\n[308]\nR. A. R. Ashfaq, X.-Z. Wang, J. Z. Huang, H. Abbas, and Y.-L.\nHe, “Fuzziness based semi-supervised learning approach for intrusion\ndetection system,” Information Sciences, vol. 378, pp. 484–497, 2017.\n[309]\nL. Watkins, S. Beck, J. Zook, A. Buczak, J. Chavis, W. H. Robinson,\nJ. A. Morales, and S. Mishra, “Using semi-supervised machine learn-\ning to address the big data problem in DNS networks,” in Computing\nand Communication Workshop and Conference (CCWC), 2017 IEEE\n7th Annual, pp. 1–6, IEEE, 2017.\n[310]\nS. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE\nTransactions on knowledge and data engineering, vol. 22, no. 10,\npp. 1345–1359, 2010.\n[311]\nE. Bas¸tu˘g, M. Bennis, and M. Debbah, “A transfer learning approach\nfor cache-enabled wireless networks,” in Modeling and Optimization\nin Mobile, Ad Hoc, and Wireless Networks (WiOpt), 2015 13th\nInternational Symposium on, pp. 161–166, IEEE, 2015.\n[312]\nJ. Koneˇcn`y, H. B. McMahan, F. X. Yu, P. Richt´arik, A. T. Suresh, and\nD. Bacon, “Federated learning: Strategies for improving communica-\ntion efﬁciency,” arXiv preprint arXiv:1610.05492, 2016.\n[313]\nA. Gokhale and A. Bhagwat, “System and method for network\naddress administration and management in federated cloud computing\nnetworks,” May 30 2017. US Patent 9,667,486.\n[314]\nJ. H. Abawajy and M. M. Hassan, “Federated internet of things and\ncloud computing pervasive patient health monitoring system,” IEEE\nCommunications Magazine, vol. 55, no. 1, pp. 48–53, 2017.\n[315]\nP. Massonet, L. Deru, A. Achour, S. Dupont, A. Levin, and M. Vil-\nlari, “End-to-end security architecture for federated cloud and IoT\nnetworks,” in Smart Computing (SMARTCOMP), 2017 IEEE Inter-\nnational Conference on, pp. 1–6, IEEE, 2017.\n37\n[316]\nI. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,\nS. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,”\nin Advances in neural information processing systems, pp. 2672–2680,\n2014.\n[317]\nL. Breiman, “Statistical modeling: The two cultures (with comments\nand a rejoinder by the author),” Statistical science, vol. 16, no. 3,\npp. 199–231, 2001.\n[318]\nI. Sturm, S. Lapuschkin, W. Samek, and K.-R. M¨uller, “Interpretable\ndeep neural networks for single-trial eeg classiﬁcation,” Journal of\nneuroscience methods, vol. 274, pp. 141–145, 2016.\n[319]\nX. Zhu, C. Vondrick, C. C. Fowlkes, and D. Ramanan, “Do we\nneed more training data?,” International Journal of Computer Vision,\nvol. 119, no. 1, pp. 76–92, 2016.\n[320]\nP. Domingos, “A few useful things to know about machine learning,”\nCommunications of the ACM, vol. 55, no. 10, pp. 78–87, 2012.\n[321]\nA. Amin, S. Anwar, A. Adnan, M. Nawaz, N. Howard, J. Qadir,\nA. Hawalah, and A. Hussain, “Comparing oversampling techniques\nto handle the class imbalance problem: a customer churn prediction\ncase study,” IEEE Access, vol. 4, pp. 7940–7957, 2016.\n[322]\nG. P. Zhang, “Avoiding pitfalls in neural network research,” Systems,\nMan, and Cybernetics, Part C: Applications and Reviews, IEEE\nTransactions on, vol. 37, no. 1, pp. 3–16, 2007.\n[323]\nA. Ng, “Advice for applying machine learning,” Stanford University,\nhttp://cs229.stanford.edu/materials/ML-advice.pdf, 2011.\n",
  "categories": [
    "cs.NI",
    "cs.LG"
  ],
  "published": "2017-09-19",
  "updated": "2017-09-19"
}