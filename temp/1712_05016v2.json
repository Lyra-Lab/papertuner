{
  "id": "http://arxiv.org/abs/1712.05016v2",
  "title": "Deep Prior",
  "authors": [
    "Alexandre Lacoste",
    "Thomas Boquet",
    "Negar Rostamzadeh",
    "Boris Oreshkin",
    "Wonchang Chung",
    "David Krueger"
  ],
  "abstract": "The recent literature on deep learning offers new tools to learn a rich\nprobability distribution over high dimensional data such as images or sounds.\nIn this work we investigate the possibility of learning the prior distribution\nover neural network parameters using such tools. Our resulting variational\nBayes algorithm generalizes well to new tasks, even when very few training\nexamples are provided. Furthermore, this learned prior allows the model to\nextrapolate correctly far from a given task's training data on a meta-dataset\nof periodic signals.",
  "text": "Deep Prior\nAlexandre Lacoste\nallac@elementai.com\nThomas Boquet\nthomas@elementai.com\nNegar Rostamzadeh\nnegar@elementai.com\nBoris Oreshkin\nboris@elementai.com\nWonchang Chung\nwonchang@elementai.com\nDavid Krueger\ndavid.krueger@elementai.com\nAbstract\nThe recent literature on deep learning offers new tools to learn a rich probability\ndistribution over high dimensional data such as images or sounds. In this work\nwe investigate the possibility of learning the prior distribution over neural network\nparameters using such tools. Our resulting variational Bayes algorithm generalizes\nwell to new tasks, even when very few training examples are provided. Furthermore,\nthis learned prior allows the model to extrapolate correctly far from a given task’s\ntraining data on a meta-dataset of periodic signals.\n1\nLearning a Rich Prior\nBayesian Neural Networks [1, 2, 3, 4] are now scalable and can be used to estimate prediction\nuncertainty and model uncertainty [5]. While many efforts focus on better approximation of the\nposterior, we believe that the quality of the uncertainty highly depends on the choice of the prior.\nHence, we consider learning a prior from previous tasks by learning a probability distribution p(w|α)\nover the weights w of a network, parameterized by α, and leveraging this learned prior to reduce\nsample complexity on new tasks.\nMore formally we consider a hierarchical Bayes approach across N tasks, with hyper-prior p(α).\nEach task has its own parameters wj, with W = {wj}N\nj=1. Using all datasets D = {Sj}N\nj=1, we have\nthe following posterior:1\np(W, α|D) = p(α|D)\nY\nj\np(wj|α, Sj)\n∝p(D|W)p(W|α)p(α)\n∝\nY\nj\nY\ni\np(yij|xij, wj)p(wj|α)p(α),\nFor simplicity, in this work, we consider a point estimation of p(α|D). This can be justify by\nconsidering scenarios where we have a lot of samples to learn α across many tasks while the\nuncertainty we truly care about is the uncertainty over wj for new tasks.\nTo go beyond normal distributions for expressing p(wj|α, Sj), we get inspiration from the generator\nof generative adversarial networks [6]. We use an auxiliary variable z ∼N(0, I) and a deterministic\nfunction projecting the noise z to the space of w i.e. w = hα(z). Marginalizing z, we have: p(w|α) =\nR\nz p(z)p(w|z, α)dz =\nR\nz p(z)δhα(z)−wdz, where δ is the Dirac delta function. Unfortunately,\ndirectly marginalizing z is untractable for general hα. To overcome this issue, we add z to the joint\n1p(xij) cancelled with itself from the denominator since it does not depend on wj nor α. This would have\nbeen different for a generative approach.\nSecond workshop on Bayesian Deep Learning (NIPS 2017), Long Beach, CA, USA.\narXiv:1712.05016v2  [stat.ML]  16 Dec 2017\ninference and we marginalize at inference time. Considering the point estimation of α, we now have:\nN\nY\nj=1\np(wj|zj, α, Sj)p(zj|α, Sj) ∝\nN\nY\nj=1\np(wj|zj, α)p(zj)\nnj\nY\ni=1\np(yij|xij, wj),\nwhere p(yij|xij, wj) is simply the conventional likelihood function of a neural network with weight\nmatrices generated from the function hα i.e.: wj = hα(zj). Also, we use:\np(zj) = N(0, I)\np(zj, wj|α) = p(zj)δhα(zj)−wj\np(zj, wj|α, Sj) = p(zj|α, Sj)δhα(zj)−wj\nThe task now consists in jointly learning a function hα common to all tasks and a posterior distribution\np(zj|α, Sj) for each task. At inference time, predictions are performed by marginalizing z i.e.:\np(y|x, D) =\nE\nz∼p(zj|α,Sj)p(y|x, hα(z))\n1.1\nHierarchical Variational Bayes Neural Network\nGiven a family of distributions q({wj, zj}N\nj=1) = Q\nj qθj(zj|Sj)δhα(zj)−wj, parameterized by\n{θj}N\nj=1 and α, the Evidence Lower Bound (ELBO) is:\nln p(D) ≥\nE\nq({wj,zj}N\nj=1)\nN\nX\nj=1\nnj\nX\ni=1\nln p(yij|xij, wj) −KL (q ∥p) ,\n=\nN\nX\nj=1\nE\nqθj (zj|Sj)\nnj\nX\ni=1\nln p(yij|xij, hα(zj)) −\nX\nj\nE\nq(wj,zj) ln qθj(zj|Sj)\np(zj)\nδhα(zj)−wj\nδhα(zj)−wj\n=\nN\nX\nj=1\nE\nqθj (zj|Sj)\nnj\nX\ni=1\nln p(yij|xij, hα(zj)) −\nX\nj\nKL\n\u0000qθj(zj|Sj)\n\r\r p(zj)\n\u0001\nNote that after simpliﬁcation2, the ELBO no longer depends explicitly on w . This is due to the fact\nthat both the posterior and the prior are using the same function to project z into w space3. A similar\nsimpliﬁcation also happened in the likelihood, leaving the whole loss function independent of w.\nThis simpliﬁcation has a major positive impact on the scalability of our approach. Since we no longer\nneed to explicitly calculate the KL on the space of w, we can simplify the likelihood function to the\nfollowing p(yij|xij, zj, α), which can be a deep network, parameterized by α taking both xij and zj\nas inputs. This contrasts with the previous formulation where hα(z) produces all the weights of a\nnetwork, yielding a really high dimensional representation and slow training.\n2\nRelated Work\nTo our knowledge, the only existing work performing hierarchical Bayesian inference with neural\nnetworks for multi-task and few shot learning is the Neural Statistician [7]. Their algorithm shares\nimportant similarities with ours. They have a main network conditioned on a probabilistic encoding of\nthe task, learned through variational Bayes. However, the main network is a generative model instead\nof a discriminative model i.e. they use a variational auto-encoder [8]. Also, instead of using a free\nform embedding for each task, they use an encoding network which reads every samples in the training\nset to generate the task encoding. Those two differences make our algorithm simpler to implement\nand more scalable to bigger dataset. Finally, their algorithm was not developed under the perspective\nof weight uncertainty and there is no exploration of model uncertainty in their experiments.\nSome recent papers on meta-learning are also targeting transfer learning from multiple tasks. Model-\nAgnostic Meta-Learning [9] ﬁnds a shared parameter θ such that for a given task, one gradient step on\n2We can justify the cancellation of the Dirac delta functions by instead considering a Gaussian with ﬁnite\nvariance, ϵ. For all ϵ > 0, the cancellation is valid, so letting ϵ →0, we recover the result.\n3Since the posterior need to stay within the support of the prior, there is no need to do otherwise\n2\n0\n2\n2\n0\n2\n0\n2\n6\n4\n2\n0\n2\n4\n6\n0\n2\ndata\nfn\nFigure 1: Preview of a few tasks (blue line) with\nincreasing amount of training samples (red dots).\nSamples from the posterior distribution are shown\nin semi-transparent colors. The width of each sam-\nples is two standard deviations (provided by the\npredicted heteroskedastic noise).\n16\n32\n64\n128\n256\n512\nN samples\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nMean Square Error\nIncreasing dataset size\nmodel\nwithout kl\nwith kl\nFigure 2: Mean Square Error on increasing\ndataset size. The baseline corresponds to the\nsame model without the KL regularizer. Each\nvalue is averaged over 100 tasks and 10 different\nrestart.\nθ using the training set will yield a model with good predictions on the test set. Then, a meta-gradient\nupdate is performed from the test error through the one gradient step in the training set, to update\nθ. This yields a simple and scalable procedure which learns to generalize. However this approach\ndoes not enable model uncertainty. Finally, [10] also considers a meta-learning approach where an\nencoding network reads the training set and generate the parameters of a model, which is trained to\nperform well on the testings set.\n3\nExperimental Results\n3.1\nRegression on 1d Harmonic signals\nWe demonstrate the ability of our model to learn a good prior on a dataset of periodic signals. The\nmodel successfully generalizes the periodic structure to unseen signals, while maintaining appropriate\nuncertainty about which periodic signal the data is sampled from. Speciﬁcally, each dataset consists\nof (x, y) pairs (noisily) sampled from a sum of two sine waves with different phase and amplitude\n(but the same frequency):\nf(x) = a1 sin(ω · x + b1) + a2 sin(2 · ω · x + b2); y ∼N(f(x), σ2\ny).\nWe construct a meta-training set of 5000 tasks, sampling ω ∼U(5, 7), (b1, b2) ∼U(0, 2π)2 and\n(a1, a2) ∼N(0, 1)2 independently for each task. Then, x values are sampled according to N(µx, 1)\nwhere µx ∼U(−4, 4) and the number of training samples ranges from 4 to 50. Evaluation is\nperformed on tasks never seen during training.\n3.2\nModel\nFor a simple implementation of p(zj|Sj), one can use N(µj, σ2\nj), where µj and σj are d dimensional\nvectors for each task j, learned through the reparameterization trick [8]. But, we found that inverse\nautoregressive ﬂow (IAF) [11] converges at a faster rate and yields better ﬁnal results.\nOnce z is obtained, we simply concatenate with x and use 12 densely connected layers of 128 neurons\nwith residual connections between every other layer. The ﬁnal layer linearly projects to 2 outputs µy\nand s, where s is used to produce a heteroskedastic noise, σy = sigmoid(s) · 0.1 + 0.001. Finally,\nwe use p(y|x, z) = N(µy, σ2\ny) to express the likelihood of the training set. To help gradient ﬂow, we\nuse ReLU activation functions and Layer Normalization4 [12].\n4Layer norm only marginally helped.\n3\n3.3\nDiscussion\nThe results in Figure 1 exhibit the expected behavior. In the ﬁrst plot, we can see the posterior latching\non the single training point and, most importantly, we observe a wide diversity of different functions\nplausible under what we consider a good learned prior. In the second plot, with 2 training points, the\nposterior is already having a good idea of the frequency. Then with 8 points, the task is mostly solved\nand we are able to extrapolate far away from the training points. Finally with 256 points, the posterior\nbecome highly conﬁdent on the observed points, and leverages the learned “periodic function” prior\nto extrapolate conﬁdently in regions without any observations.\nIn Figure 2, we compare the mean squared error against a version of the model with no KL, which\nwould correspond to a more traditional approach to multi-task learning. The comparison is performed\non an increasing size of the training set and we can observe a systematic and signiﬁcant gain over the\nbaseline. We also compared using the log likelihood metric and the Without-KL version is off the\nchart, performing 10 times worse on average.\nWe also observed some local minimum issues during training on new tasks5. We believe it is caused\nby the posterior distribution being highly multi-modal in the small sample size regime6. In principle,\nIAF should be able to handle multi-modal distributions. However, extended experiments showed it\nwas not adapting beyond a single distorted mode.\nReferences\n[1] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty\nin neural networks. arXiv preprint arXiv:1505.05424, 2015.\n[2] Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local\nreparameterization trick. In Advances in Neural Information Processing Systems, pages 2575–\n2583, 2015.\n[3] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing\nmodel uncertainty in deep learning.\nIn Maria Florina Balcan and Kilian Q. Weinberger,\neditors, Proceedings of The 33rd International Conference on Machine Learning, volume 48 of\nProceedings of Machine Learning Research, pages 1050–1059, New York, New York, USA,\n20–22 Jun 2016. PMLR.\n[4] David Krueger, Chin-Wei Huang, Riashat Islam, Ryan Turner, Alexandre Lacoste, and Aaron\nCourville. Bayesian hypernetworks. arXiv preprint arXiv:1710.04759, 2017.\n[5] Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep bayesian active learning with image\ndata. arXiv preprint arXiv:1703.02910, 2017.\n[6] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil\nOzair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural\ninformation processing systems, pages 2672–2680, 2014.\n[7] Harrison Edwards and Amos Storkey.\nTowards a neural statistician.\narXiv preprint\narXiv:1606.02185, 2016.\n[8] Diederik P Kingma and Max Welling.\nAuto-encoding variational bayes.\narXiv preprint\narXiv:1312.6114, 2013.\n[9] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adapta-\ntion of deep networks. arXiv preprint arXiv:1703.03400, 2017.\n[10] Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. 2016.\n[11] Diederik P Kingma, Tim Salimans, and Max Welling. Improving variational inference with\ninverse autoregressive ﬂow. arXiv preprint arXiv:1606.04934, 2016.\n[12] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\narXiv:1607.06450, 2016.\n5Which was resolved with a few restart selected on a validation set.\n6With more data, the main mode highly shadows the other modes\n4\n",
  "categories": [
    "stat.ML",
    "cs.LG"
  ],
  "published": "2017-12-13",
  "updated": "2017-12-16"
}