{
  "id": "http://arxiv.org/abs/1712.05574v1",
  "title": "Soft Seeded SSL Graphs for Unsupervised Semantic Similarity-based Retrieval",
  "authors": [
    "Avikalp Srivastava",
    "Madhav Datt"
  ],
  "abstract": "Semantic similarity based retrieval is playing an increasingly important role\nin many IR systems such as modern web search, question-answering, similar\ndocument retrieval etc. Improvements in retrieval of semantically similar\ncontent are very significant to applications like Quora, Stack Overflow, Siri\netc. We propose a novel unsupervised model for semantic similarity based\ncontent retrieval, where we construct semantic flow graphs for each query, and\nintroduce the concept of \"soft seeding\" in graph based semi-supervised learning\n(SSL) to convert this into an unsupervised model.\n  We demonstrate the effectiveness of our model on an equivalent question\nretrieval problem on the Stack Exchange QA dataset, where our unsupervised\napproach significantly outperforms the state-of-the-art unsupervised models,\nand produces comparable results to the best supervised models. Our research\nprovides a method to tackle semantic similarity based retrieval without any\ntraining data, and allows seamless extension to different domain QA\ncommunities, as well as to other semantic equivalence tasks.",
  "text": "arXiv:1712.05574v1  [cs.IR]  15 Dec 2017\nSof Seeded SSL Graphs for Unsupervised Semantic\nSimilarity-based Retrieval\nAvikalp Srivastava\nIndian Institute for Technology, Kharagpur\navikalp22@iitkgp.ac.in\nMadhav Datt\nIndian Institute of Technology, Kharagpur\nmadhav@iitkgp.ac.in\nABSTRACT\nSemantic similarity based retrieval is playing an increasingly im-\nportant role in many IR systems such as modern web search, question-\nanswering, similar document retrieval etc. Improvements in retrieval\nof semantically similar content are very signiﬁcant to applications\nlike Quora, Stack Overﬂow, Siri etc. We propose a novel unsuper-\nvised model for semantic similarity based content retrieval, where\nwe construct semantic ﬂow graphs for each query, and introduce\nthe concept of \"soft seeding\" in graph based semi-supervised learn-\ning (SSL) to convert this into an unsupervised model.\nWe demonstrate the eﬀectiveness of our model on an equiva-\nlent question retrieval problem on the Stack Exchange QA dataset,\nwhere our unsupervised approach signiﬁcantly outperforms the\nstate-of-the-art unsupervised models, and produces comparable re-\nsults to the best supervised models. Our research provides a method\nto tackle semantic similarity based retrieval without any training\ndata, and allows seamless extension to diﬀerent domain QA com-\nmunities, as well as to other semantic equivalence tasks.\n1\nINTRODUCTION\nSemantic matching and ranking play a key role in various infor-\nmation retrieval and natural language understanding applications\nsuch as modern web search, dialogue systems, cross language infor-\nmation retrieval, paraphrasing, textual entailment, question-answering,\nsimilar document identiﬁcation etc. The retrieval model for a query\nis dependent on the characteristics of the task and can be based\non relevance, response/answer to query, entailment, similarity or\nequivalence [9]. In this work we focus on retrieval of semantically\nequivalent content to a given query. This ﬁnds multiple applica-\ntions in areas of equivalent question retrieval, similar document\ndetection, and paraphrasing applications such as summarization,\ndialogue, overcoming redundancies in short texts.\nWith the growing popularity of sites like Stack Overﬂow, Quora,\nBaidu Zhidao, and other Q&A forums, semantic similarity based\ncontent retrieval and ranking, particularly in case of questions, is\nbecoming increasingly important, as this enables them to help users\nsee if their questions have already been answered, possibly in a dif-\nferent form, and reduce duplicate content on such websites.\nDetecting semantically similar content is an extremely hard prob-\nlem mainly because of 3 key factors: (1) the same content can be\nphrased with very diﬀerent sentence structure and wording; (2) sim-\nilarly worded content may represent relation to very diﬀerent queries;\nand (3) building training data to capture the diversity and varia-\ntions in content is very expensive in terms of time and cost. Thus,\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor proﬁt or commercial advantage and that copies bear this notice and the full citation\non the ﬁrst page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior speciﬁc permission and/or\na fee. Request permissions from permissions@acm.org.\nCIKM’17 , November 6–10, 2017, Singapore, Singapore\n© 2017 Association for Computing Machinery.\nACM ISBN 978-1-4503-4918-5/17/11...$15.00\nhttps://doi.org/10.1145/3132847.3133162\nnaive word-overlap based measures of content similarity such as\n[5] do not work for semantic similarity based retrieval problems.\nIn this paper, we propose a novel unsupervised model for re-\ntrieval of semantically equivalent content, where we (a) frame it as\na graph-based semi-supervised learning problem; (b) build query\ninduced semantic ﬂow subgraphs for each given query; (c) intro-\nduce the concept of \"soft seeding\" to convert it to an unsupervised\nsolution; and (d) leverage the ﬂexibility of our model by incorpo-\nrating multiple additional textual features. Our model signiﬁcantly\nout-performs the state-of-the-art in unsupervised settings (38.6%\nvs 34.1% precision for top-10 retrieval), and produces comparable\nresults to the best supervised models, such as BOW-CNN [6]\n2\nRELATED WORK\nSimilarity-based retrieval and ranking models are built by develop-\ning a similarity function between the query and document objects.\nRecent works on learning short-text pair similarity focus on repre-\nsentation learning algorithms where the the intrinsic low-dimensional\nstructure in data is exploited to induce similarity. Convolutional\nneural networks have proven eﬀective in capturing the semantic\nand syntactic aspects of input sentences, given suﬃcient amount\nof training data. [13] uses Pairwise Convolutional Neural Network\narchitecture (PCNN), a supervised model that encodes question-\nanswer pairs into discriminative feature vectors, and produces state-\nof-the-art performance on question-answering tasks.\nThe eﬀectiveness of CNNs in semantic analysis of short texts has\nmotivated their usage in retrieval of equivalent questions. [4] uses\nCNNs for binary decision making on equivalence, given a question\npair, and is extended in [6] where the CNN is coupled with a tradi-\ntional bag-of-words representation to learn hybrid representations\nfor equivalent question retrieval on Stack Exchange Q&A sites. The\nCNN and BOW-CNN approaches outperform previous traditional\nIR approaches like TFIDF [10], LMDirichlet and LMJelinekMercer\n[16]. However, the primary limitation of such architectures is their\ndependence on availability of a large amount of high quality train-\ning data, making them diﬃcult to apply to diﬀerent domains of\nQ&A datasets, as representations need to be re-learned, and fresh\nand extensive training data is required. This also considerably in-\nhibits their applicability and extension to other orthogonal applica-\ntions involving semantic similarity based retrieval.\nThe use of stacked context-sensitive autoencoderswas introduced\nby [1], where the latent representations of a query object and its\ncontext are combined into a context-sensitive embeddings. This\nprovides an unsupervised model that produces results compara-\nble to the supervised CNN and BOW-CNN models. In a supervised\nsetting, this autoencoder model learns weights for combining the\ncontext-sensitive representation of question pairs along with addi-\ntional features derived from BOW representations and word over-\nlap features. The importance of BOW features in question ranking\nis shown by [6] where BOW-CNN signiﬁcantly outperforms CNN.\nHowever, this autoencoder model is limited by its inability to use\nthese additional features in unsupervised settings, where it simply\ncomputes the cosine similarity of the context-sensitive representa-\ntion of the question pair. We leverage our model’s ﬂexibility, and ex-\nploit properties of SSL graphs by incorporating feature nodes, thus\nallowing introduction of multiple additional features. Since [1] uses\naveraged word embeddings as document level vectors, this leads\nto loss of syntactic and word-level information. Our approach uti-\nlizes the recently proposed Word Mover’s Distance (WMD) metric\n[8] which elevates high-quality word embeddings to a document\nmetric by formulating the distance between two documents as an\noptimal transport problem between the embedded words, eliminat-\ning the need of obtaining explicit document vector representation.\nWMD is completely unsupervised and hyper-parameter free, and\nhas achieved unprecedented results on kNN-based document clas-\nsiﬁcation and inherently captures the bag-of-words representation\nof documents.\n3\nSOFT SEEDED SSL GRAPHS\nSemi-supervised learning approaches have proven successful in sce-\nnarios where labeled data is scarce and unlabeled data is present in\nabundance, and have been rapidly supplanting supervised systems.\nThese approaches leverage unlabeled data by propagating labels\nvia unlabeled samples to capture indirect similarity. This property\ncan specially prove helpful in the problem of semantic equivalence\nbased retrieval in unsupervised setting, where similarity measures\nthat strongly correlate with label assignment are used for discov-\nering indirect similarities through various paths between the data\npoints. Graph-based SSL algorithms based on label propagation are\na sub-class of SSL algorithms that use label information associated\nwith initial seed nodes and ﬂow this information in a principled,\niterative manner [15] and have been widely used in IR and NLP\napplications.\nA crucial component of graph-based SSL approaches is the con-\nstruction of input graph, which should facilitate ﬂow of semantic\ninformation among nodes with high pairwise and global feature\nbased similarity measures, for the particular task of propagating\nsemantic equivalence based labels. It is also worth noting that past\nSSL graph based approaches use a single graph network for global\nlabel propagation covering the entire dataset in a transductive set-\nting where small amount of training data is available for assigning\nthe initial seeds. In our case however, we need to work with labels\n(single-dimension) that correspond to semantic equivalence to the\ngiven query, and hence local networks need to be constructed for\neach query, requiring a new strategy for initial seed assignment.\nWe now move on to explain the construction and usage of SSL\ngraphs with respect to the speciﬁc task of retrieving top semanti-\ncally equivalent questions in online Q&A communities and forums.\n3.1\nQuery Induced Subgraphs\nGiven the question dataset Q = {q1,q2, ...,qN }, we ﬁrst seek to\nlearn dense vector representations capturing the underlying seman-\ntics for each of the word in the dataset’s vocabulary, obtained after\npruning of 30 highest frequency words and removal of stopwords,\nurls and code-tags. We use pre-trained word2vec embeddings [11]\nas initialization and further train the model on our dataset Q to ac-\ncount for the presence of speciﬁc technical terms and topics in the\ndataset. Bogdanova et al. [4] demonstrates a signiﬁcant improve-\nment in performance on equivalent question detection on using in-\ndomain word embeddings as opposed to pre-trained embeddings.\nWe thus obtain an embedding matrix X ∈IRd×n, where the ith\ncolumn xi represents the d-dimensional embedding for the ith to-\nkenized word.\nGiven a query question qi ∈Q, we obtain a normalized bag-\nof-words (nBOW) representation di ∈IRn for qi. To induce a se-\nmantic ﬂow subgraph based on this query, we ﬁrst retrieve k ques-\ntions which share least Word Mover’s Distance with qi. To com-\npute WMD between document representations d and d′, a sparse\nﬂow transport matrix T ∈IRn×n where Ti,j ≥0 is computed as a\nsolution of the following linear program:\nmin\nT≥0\nn\nX\ni,j=1\nTijc(i, j)\nsubject to:\nn\nX\nj=1\nTij = di\n∀i ∈{1, 2, . . . ,n}\nn\nX\ni=1\nTij = d′\nj\n∀j ∈{1, 2, . . . ,n}\nwhere c(i, j) corresponds to the Euclidean distance between em-\nbeddings for word i and word j.\nConsidering the high computational complexity of WMD metric,\nit is infeasible to compute the distance of query question with every\nother question in the dataset, and hence the faster Word Centroid\nDistance (||Xd −Xd′||2) is ﬁrst used to limit candidates for ﬁnd-\ning k-nearest neighbors using WMD. Similar heuristic is applied\nto each of these k ’1-hop’ neighbors of the query node to obtain a\nmaximum of k2 ’2-hop’ neighbors under no-overlap, and thus an\ninduced subgraph with maximum k2 + k + 1 nodes. The WMD ma-\ntrix for the nodes of this subgraph is computed and the distance\nmeasures are used as edge weights to obtain a complete subgraph.\nA choice to drop edges exhibiting distance above a threshold is also\navailable. We thus have a query induced subgraph with semantic\nﬂow links, where an important thing to note is that edge weights\ncorrespond to node pair distance and not similarity.\n3.2\nAugmenting Feature Nodes\nTraditional document feature representations, such as bag-of-words,\nIDF-weighted word overlap and other lexical features, signiﬁcantly\nimprove semantic retrieval when used in conjunction with latent\ndeep learning based representations for texts not limited to single\nsentences [6]. Additionally, one of the weaknesses of approaches\nrelying on word vectors is inability to deal with proper nouns and\nnumbers, which can be found in abundance in general QA forums.\nThus the additional features are augmented to the query induced\nsubgraph as feature nodes, a method adopted for lexical features in\n[7]. Particularly, we use word overlap features, common n-grams\nand skip-grams (up to length 3) as feature nodes (VF ), in addition\nto nodes (VR) in the query induced subgraph. An edge (vf ,vr ) for\nvf ∈VF and vr ∈VR with weight as IDF value of vf is added if vf\nbelongs to feature set of vr . We would also like to point out that\nBOW representation of documents is inherently considered in the\ncomputation of their Word Mover’s Distance.\n3.3\nSoft Seeding\nBeing a subset of semi-supervised learning based approaches, SSL\ngraphs naturally require a small amount of initial training labels,\nwhich are used as seed labels for the seed nodes for providing the\ninformation that propagates through the graph network. Even in\npresence of some supervised data, this is diﬃcult to incorporate in\nSSL graphs that are constructed as query induced subgraphs, since\n2\nsome seed labels signaling equivalence/non-equivalence will be re-\nquired for each query.\nHere, we describe our method of introducing soft seeds in query\ninduced SSL graphs, which serves the dual purpose of combating\nthe problem of unavailability of initial seeds and incorporating mul-\ntiple measures of semantic similarity in the framework. Our main\nobjective is to be able to choose nodes in the induced subgraph\nwhich can be assigned as 1-seeds (i.e. with initial soft label = 1.0 cor-\nresponding to high semantic equivalence with query node) and 0-\nseeds (low semantic equivalence with query node), and later adapt\nthe SSL graph objective function to take into account the softness of\nthese seeds, as compared to the hard training data based seeds avail-\nable otherwise. One hard seed available is the query node (with\nlabel = 1.0) which acts as a source of ﬂow of high semantic equiva-\nlence to it’s neighboring nodes weighted by the edge weights.\nAssignment of the initial soft seeds requires a similarity mea-\nsure diﬀerent from the one used to construct the graph and feature\nlinks to avoid conditioning. An important semantic similarity mea-\nsure exploited in question retrieval tasks is topic modeling based\ndocument representation. [1] uses sparse non-negative matrix fac-\ntorization (NMF) to obtain topic and context matrices, and feed the\ncontext vectors to its autoencoder architecture as the context of\nthe query question. In the next section, we explain our choices for\nthe topic modeling approaches for obtaining 1-seeds and 0-seeds\nfollowed by the optimization objective for our ﬁnal query induced\nSSL graph.\n(I) Thresholded SVD based Topic Model for 1-seeds\nNMF exhibits a natural clustering property,however our approach\ntowards assigning 1-seeds with high conﬁdence requires not only\nanalyzing the questions/documents in the same topic induced clus-\nter as the query document, but also requires that this topic forms\nthe dominant topic for the query and that within this cluster a fur-\nther reﬁned score among the documents can be obtained for as-\nsigning more accurate near-to-1 soft labels. Recent work by [3]\ngives a SVD-based algorithm followed by thresholding on the data\nmatrix that provides bound l1 reconstruction error under the sim-\nplifying and empirically supported assumptions of documents be-\ning drawn from dominant admixtures and presence of topic speciﬁc\ncatchwords. We brieﬂy explain the assumptions with the help of pa-\nrameters w0 (lowest probability that a topic is dominant), and non-\nnegative reals α, β, ρ,δ,ϵ,ϵ0 satisfying: β +ρ ≤(1−δ)α,\nα +2δ ≤\n0.5,\nand\nδ ≤0.08\n(a) Dominant Admixture assumption: (i) If for every docu-\nment, there is one topic whose weight is signiﬁcantly higher than\nthe other topics i.e. for a document j with dominant topicl(j),Wl(j),j ≥\nα and Wl′j ≤β,\n∀l ′ ̸= l(j); (ii) there exists at-least a small frac-\ntion (ϵ0w0s) of documents which are almost purely (≥1 −δ) on\nthat topic.\n(b) Catchwords assumption: Presence of a group of words, say\n{S1,S2, . . . , Sk }, for each of the k topics which together occur with\nhigh probability (P\ni ∈Sl Mil ≥p0) and that each individual word\nin the group occurs more frequently in that topic than any other\n(∀i ∈Sl, ∀l ′ ̸= l,Mil′ ≤ρMil)\nWe utilize these simplifying assumptions to learn topics from\ndominant admixtures for the given dataset Q. Sparse thresholding\nis applied to the data matrix A, where threshold for the ith word\nis determined as follows (given m is average number of words per\ndocument): Let ζi be the highest value of ζ ∈{0, 1, . . . ,m} such\nthat |{j : Aij > ζ\nm }|≥w0s\n2 ; |{j : Aij = ζ\nm |≤3ϵw0s. The thresholds\n(ζ ) are used to obtain the thresholded matrix B:\nBij =\n(p\nζi,\nif Aij > ζi\nm\n0,\notherwise\nThe singular values of this thresholded matrix B are provably\nbounded, and this condition is used by the authors to prove that\nthe clusters (R1, R2, . . . , Rk) generated by Lloyd’s k-means cluster-\ning on the columns of B with initial starting centers as the k-means\nclustering centers of columns of SVD-based k-rank approximation\nB(k) of B correctly identify almost all the documents’ dominant\ntopics. Thus all the documents belonging to the same cluster as\nthe query document are candidates for 1-seeds. We now obtain\na reﬁned score based on the sum of document terms over identi-\nﬁed catchwords. We bypass the posterior inference of document\ntopic distribution, and compute the sparse catchword-based topic\nweights for each document. For the set of catchwords Jl for topic l,\nthe weight of topic l in document j is calculated as P\ni ∈Jl Aij which\nevaluates to zero for majority of topics giving us a sparse catch-\nword based representation, whose cosine similarity with query rep-\nresentation is ﬁnally utilized to retrieve top k’ seeds and assign the\nsimilarity value as soft label.\n(II) Thresholded SVD for 0-seeds\nTo assign 0-seeds with high conﬁdence, we analyze the topic-\nword distribution vectors in the topic matrix obtained by thresh-\nolded SVD algorithm. The vector M.,l′ with maximum euclidean\ndistance from M.,l , where l corresponds to the dominant topic for\nquery document is selected. For each document in the l’ cluster, we\nanalyze the topic diﬀerential score [2] for topic l with reference to\nthe query document, and select the k’ documents with lowest topic\ndiﬀerential scores as the 0-seeds with their topic diﬀerential scores\nas soft labels.\n3.4\nOptimization Objective\nThe optimization objective for our ﬁnal SSL varies from the stan-\ndard objective in 3 aspects: (a) The label dimension for each node\nis simply 1, (b) the edge weights linking the primary nodes of the\ngraph signify distance and not similarity and (c) we account for\nthe softness of the initial seeds by relaxing the penalty on change\nof seed label values from their initial values, and introduce dropout\non the edges linked to the soft seeds with probability p. A localized\nform of over-ﬁtting occurs, where nodes adjacent to soft-seeded\nnodes, learn much of their value from those nodes, and may end\nup having much greater ﬁt/agreement with the localized sub-graph\nstructure instead of the overall graph. We leverage its analogous\nnature to training a neural network, and counter this eﬀect by re-\nducing the inﬂuence of the local sub-graph via dropout [14].\nsi( ˆCi −Ci)2 + µpp( ˆCi −U )2\n+ µnp(\nX\nj ∈NF (i)\nwij( ˆCi −ˆCj)2 +\nX\nk ∈NR(i)\nwik( ˆCi −ˆCk)2)\nwhere ˆp∗si is an indicator for seeds that corresponds tomax(s, 1−\ns) for their initial seed value s, and is 0 for non-seeds and ˆp is 1 in\ncase of no dropout and 0 otherwise. ˆCi denotes the learned current\nlabel value of node i, Ci is the initial assigned values for seeds. U\ncorresponds to the uniform prior (0.5), and NR(i) and NF (i) denote\nthe graph node and feature node neighbor set for ith node. Since\nwij are WMD based distances, we modify this loss function to pe-\nnalize label similarity rather than separation. Thus the term in the\nfunction is changed to (\nP\nj ∈NF (i)\nwij(1 −( ˆCi −ˆCj)2)), where the con-\nstant term is the sum of weights of all outgoing edges from node i\n3\nand hence can be dropped. Thus, the only change is that this term\nis subtracted rather than added in the loss function. We follow the\nvanilla Jacobi iterative update and set the termination conditions\nthreshold on maximum change in a label’s distribution [12]\n4\nEXPERIMENTAL EVALUATION\nWe evaluate our model on the \"qSim\" dataset with a question rank-\ning task, where given a test question, the model should retrieve the\ntopk questions that are semantically equivalent to the test question\nfor k ∈K, K = {1, 5, 10}. qSim is a community question-answer\ndataset scraped from Stack Exchange along with ground-truth la-\nbels for semantically equivalent questions from [6]. For the sake\nof direct comparison, we use the same test data distribution given\nin [6] and used by [1]. Statistics of the dataset are shown in Table\n1. The parameter settings adopted for conducting these experiment\ninvolve k = 50, 300 and 750 nearest neighbor retrievals for the query\ninduced subgraph for Precision @1, @5 and @10 tasks respectively,\nwhere WCD measure was used initially to retrieve 500, 3000 and\n7500 documents respectively. For application of TSVD, we used\nnumber of topics as k = 200, parameters w0 = 1\nk ,ϵ = 1\n10,ϵ0 = 1\n6. In\nthe following section, our proposed model, Soft Seeded SSL Graph,\nis abbreviated as SSG. We use SSG-D and SSG-WD to refer to our\nmodel with dropout and without dropout respectively. We com-\nTable 1: qSim Dataset Statistics\nSplit\nPairs\n%Positive Pairs\nTrain\n205K\n0.048%\nDev\n43M\n0.001%\nTest\n82M\n0.001%\npare our unsupervised Soft Seeded SSL Graph based model against\nthe supervised PCNN and PBOW-PCNN models presented in [6],\nthe supervised SAE and CSAE models, and the unsupervised SAE\nand CSAE models as presented in [1]. We also compare our model\nagainst the supervised SAE-DST and CSAE-DST models which in-\nclude additional element-wise similarity features as described in\n[1]. We use Precision at Rank k, denoted by P@k, k ∈K, to eval-\nuate performance of our model. Results in table 2 demonstrate the\neﬀects of dropout in our model.\nTable 2: Question ranking precision for our model, without\nand with dropout respectively\nModel\nP@1\nP@5\nP@10\nSSG-WD\n19.0\n34.6\n38.1\nSSG-D\n18.9\n34.9\n38.6\nTable 3: Question ranking precision in supervised settings\nModel\nP@1\nP@5\nP@10\nPCNN\n20.0\n33.8\n40.1\nSAE\n16.8\n29.4\n32.8\nCSAE\n21.4\n34.9\n37.2\nPBOW-PCNN\n22.3\n39.7\n46.4\nSAE-DST\n22.2\n35.9\n42.0\nCSAE-DST\n24.6\n37.9\n38.9\n5\nCONCLUSION\nAs can be observed from Tables 3 and 4, our completely unsuper-\nvised model for semantic similarity based content retrieval, signif-\nicantly outperforms the state-of-the-art unsupervised models, by\n0.3%, 1.7% and 4.5% for question ranking precision for top-1, 5 and\n10 retrieval, respectively. It also produces results comparable to the\nbest supervised models, in higher ranks (top-5, 10 retrieval). In this\npaper, we also proposed a new domain of application of SSL graphs\nfor query based retrieval, and subsequently introduced soft seeding\nas a strategy to make our model completely unsupervised, thus, en-\nabling extension to diﬀerent domain QA communities, and to other\nsemantic equivalence tasks.\nTable 4: Question ranking precision for models in unsuper-\nvised settings, including our model, with dropout\nModel\nP@1\nP@5\nP@10\nSAE\n17.3\n32.4\n32.8\nCSAE\n18.6\n33.2\n34.1\nSSG-D\n18.9\n34.9\n38.6\n6\nFUTURE WORK\nWhile our paper is focused on proposing a novel model for se-\nmantic similarity based content retrieval, it also provides an adap-\ntive framework for solving any problem that could be framed as\na graph-based semi-supervised learning task, in an unsupervised\nmanner. This improves possibilities for research and applications\nof semantic matching and ranking in domains where labeled data\nin unavailable. We are currently extending this work for faceted\nrecommendation of web news articles, and preliminary results are\nencouraging.\nREFERENCES\n[1] Hadi Amiri, Philip Resnik, Jordan Boyd-Graber, and Hal Daumé III. 2016. Learn-\ning text pair similarity with context-sensitive autoencoders. In Proceedings of\nthe 54th Annual Meeting of the Association for Computational Linguistics, Vol. 1.\n1882–1892.\n[2] Ramakrishna B Bairi, Raghavendra Udupa, and Ganesh Ramakrishnan. 2016. A\nFramework for Task-speciﬁc Short Document Expansion. In Proceedings of the\n25th ACM International on Conference on Information and Knowledge Manage-\nment. ACM, 791–800.\n[3] Trapit Bansal, Chiranjib Bhattacharyya, and Ravindran Kannan. 2014. A prov-\nable SVD-based algorithm for learning topics in dominant admixture corpus. In\nAdvances in Neural Information Processing Systems. 1997–2005.\n[4] Dasha Bogdanova, Cícero Nogueira dos Santos, Luciano Barbosa, and Bianca\nZadrozny. 2015. Detecting Semantically Equivalent Questions in Online User\nForums.. In CoNLL, Vol. 123. 2015.\n[5] Andrei Z Broder, Steven C Glassman, Mark S Manasse, and Geoﬀrey Zweig. 1997.\nSyntactic clustering of the web. Computer Networks and ISDN Systems 29, 8-13\n(1997), 1157–1166.\n[6] Cícero Nogueira dos Santos, Luciano Barbosa, Dasha Bogdanova, and Bianca\nZadrozny. 2015.\nLearning Hybrid Representations to Retrieve Semantically\nEquivalent Questions.. In ACL (2). 694–699.\n[7] Anjuli Kannan, Karol Kurach, Sujith Ravi, Tobias Kaufmann, Andrew Tomkins,\nBalint Miklos, Greg Corrado, László Lukács, Marina Ganea, Peter Young, et al.\nSmart Reply: Automated Response Suggestion for Email. (????).\n[8] Matt Kusner, Yu Sun, Nicholas Kolkin, and Kilian Weinberger. 2015.\nFrom\nword embeddings to document distances. In International Conference on Machine\nLearning. 957–966.\n[9] Hang Li, Jun Xu, et al. 2014. Semantic matching in search. Foundations and\nTrends® in Information Retrieval 7, 5 (2014), 343–469.\n[10] Christopher D Manning, Prabhakar Raghavan, Hinrich Schütze, et al. 2008. Intro-\nduction to information retrieval. Vol. 1. Cambridge university press Cambridge.\n[11] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and JeﬀDean. 2013.\nDistributed representations of words and phrases and their compositionality. In\nAdvances in neural information processing systems. 3111–3119.\n[12] Sujith Ravi and Qiming Diao. 2016. Large scale distributed semi-supervisedlearn-\ning using streaming approximation. In Proceedings of AISTATS.\n4\n[13] Aliaksei Severyn and Alessandro Moschitti. 2015. Learning to rank short text\npairs with convolutional deep neural networks. In Proceedings of the 38th In-\nternational ACM SIGIR Conference on Research and Development in Information\nRetrieval. ACM, 373–382.\n[14] Nitish Srivastava,Geoﬀrey E Hinton, Alex Krizhevsky,Ilya Sutskever,and Ruslan\nSalakhutdinov. 2014. Dropout: a simple way to prevent neural networks from\noverﬁtting. Journal of Machine Learning Research 15, 1 (2014), 1929–1958.\n[15] Partha Talukdar and Koby Crammer. 2009. New regularized algorithms for trans-\nductive learning. Machine Learning and Knowledge Discovery in Databases (2009),\n442–457.\n[16] Chengxiang Zhai and John Laﬀerty. 2004. A study of smoothing methods for lan-\nguage models applied to information retrieval. ACM Transactions on Information\nSystems (TOIS) 22, 2 (2004), 179–214.\n5\n",
  "categories": [
    "cs.IR"
  ],
  "published": "2017-12-15",
  "updated": "2017-12-15"
}