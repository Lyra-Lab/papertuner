{
  "id": "http://arxiv.org/abs/1712.07886v2",
  "title": "Estimating the Success of Unsupervised Image to Image Translation",
  "authors": [
    "Sagie Benaim",
    "Tomer Galanti",
    "Lior Wolf"
  ],
  "abstract": "While in supervised learning, the validation error is an unbiased estimator\nof the generalization (test) error and complexity-based generalization bounds\nare abundant, no such bounds exist for learning a mapping in an unsupervised\nway. As a result, when training GANs and specifically when using GANs for\nlearning to map between domains in a completely unsupervised way, one is forced\nto select the hyperparameters and the stopping epoch by subjectively examining\nmultiple options. We propose a novel bound for predicting the success of\nunsupervised cross domain mapping methods, which is motivated by the recently\nproposed Simplicity Principle. The bound can be applied both in expectation,\nfor comparing hyperparameters and for selecting a stopping criterion, or per\nsample, in order to predict the success of a specific cross-domain translation.\nThe utility of the bound is demonstrated in an extensive set of experiments\nemploying multiple recent algorithms. Our code is available at\nhttps://github.com/sagiebenaim/gan_bound .",
  "text": "Estimating the Success of Unsupervised\nImage to Image Translation\nSagie Benaim∗\nsagieb@mail.tau.ac.il\nTomer Galanti∗\ntomerga2@post.tau.ac.il\nThe Blavatnik School of Computer Science\nTel Aviv University\nTel Aviv, Israel\nLior Wolf\nwolf@fb.com\nFacebook AI Research &\nThe Blavatnik School of Computer Science\nTel Aviv University\nTel Aviv, Israel\nAbstract\nWhile in supervised learning, the validation error is an unbiased estimator of the\ngeneralization (test) error and complexity-based generalization bounds are abun-\ndant, no such bounds exist for learning a mapping in an unsupervised way. As a\nresult, when training GANs and speciﬁcally when using GANs for learning to map\nbetween domains in a completely unsupervised way, one is forced to select the hy-\nperparameters and the stopping epoch by subjectively examining multiple options.\nWe propose a novel bound for predicting the success of unsupervised cross domain\nmapping methods, which is motivated by the recently proposed Simplicity Princi-\nple. The bound can be applied both in expectation, for comparing hyperparameters\nand for selecting a stopping criterion, or per sample, in order to predict the success\nof a speciﬁc cross-domain translation. The utility of the bound is demonstrated in\nan extensive set of experiments employing multiple recent algorithms. Our code is\navailable at https://github.com/sagiebenaim/gan_bound.\n1. Introduction\nIn unsupervised learning, the process of selecting hyperparameters and the lack of\nclear stopping criteria are a constant source of frustration. This issue is commonplace\nfor GANs [1] and the derived technologies, in which the training process optimizes\nmultiple losses that balance each other. Practitioners are often uncertain regarding\nthe results obtained when evaluating GAN-based methods, and many avoid using\nthese altogether. One solution is to employ more stable methods such as [2]. However,\n∗. Authors contributed equally\n1\narXiv:1712.07886v2  [cs.LG]  22 Mar 2018\nthese methods do not always match the results obtained by GANs. In this work, we\noﬀer, for an important family of GAN methodologies, an algorithm for selecting the\nhyperparameters, as well as a stopping criterion.\nSpeciﬁcally, we focus on predicting the success of algorithms that map between\ntwo image domains in an unsupervised manner. Multiple GAN-based methods have\nrecently demonstrated convincing results, despite the apparent inherent ambiguity,\nwhich is described in Sec. 2. We derive what is, as far as we know, the ﬁrst error\nbound for unsupervised cross domain mapping.\nIn addition to the novel capability of predicting the success, in expectation, of a\nmapping that was trained using one of the unsupervised mapping methods, we can\npredict the success of mapping every single sample individually. This is remarkable for\ntwo reasons: (i) even supervised generalization bounds do not deliver this capability;\nand (ii) we deal with complex multivariate regression problems (mapping between\nimages) and not with classiﬁcation problems, in which pseudo probabilities are often\nassigned.\nIn Sec. 2, we formulate the problem and present background on the Simplicity\nPrinciple of [3].\nThen, in Sec. 3, we derive the prediction bounds and introduce\nmultiple algorithms. Sec. 4 presents extensive empirical evidence for the success of\nour algorithms, when applied to multiple recent methods. This includes a unique\ncombination of the hyperband method [4], which is perhaps the leading method in\nhyperparameter optimization, in the supervised setting, with our bound. This com-\nbination enables the application of hyperband in unsupervised learning, where, as far\nas we know, no hyperparameter selection method exists.\n1.1 Related Work\nGenerative Adversarial Networks GAN [1] methods train a generator network\nG that synthesizes samples from a target distribution, given noise vectors, by jointly\ntraining a second, adversarial, network D. Conditional GANs employ a vector of\nparameters that directs the generator, in addition to (or instead of) the noise vector.\nThese GANs can generate images from a speciﬁc class [5] or based on a textual\ndescription [6], or invert mid-level network activations [7]. Our bound also applies\nin these situations. However, this is not the focus of our experiments, which target\nimage mapping, in which the created image is based on an input image [8, 9, 10, 11,\n12, 13, 14].\nUnsupervised Mapping The validation of our bound focuses on recent cross-\ndomain mapping methods that employ no supervision, except for sample images from\nthe two domains. This ability was demonstrated recently [8, 9, 10, 14] in image to\nimage translation and slightly earlier for translating between natural languages [15].\nThe DiscoGAN [8] method, similar to other methods [9, 10], learns mappings in\nboth directions, i.e., from domain A to domain B and vice versa. Our experiments also\nemploy the DistanceGAN method [14], which unlike the circularity based methods,\nis applied only in one direction (from A to B). The constraint used by this method\n2\nis that the distances for a pair of inputs x1, x2 ∈A before and after the mapping, by\nthe learned mapping G, are highly correlated, i.e., ||x1 −x2|| ∼||G(x1) −G(x2)||.\nWeakly Supervised Mapping Our bound can also be applied to GAN-based meth-\nods that match between the source domain and the target domain by also incorpo-\nrating a ﬁxed pre-trained feature map f and requiring f-constancy, i.e, that the\nactivations of f are the same for the input samples and for mapped samples [12, 16].\nDuring training, the various components of the loss (GAN, f-constancy, and a few\nothers) do not provide a clear signal when to stop training or which hyperparameters\nto use.\nGeneralization Bounds for Unsupervised Learning Only a few generalization\nbounds for unsupervised learning were suggested in the literature.\nIn [17], PAC-\nBayesian generalization bounds are presented for density estimation.\n[18] gives an\nalgorithm for estimating a bounded density using a ﬁnite combination of densities\nfrom a given class. This algorithm has estimation error bounded by O(1/√n). Our\nwork studies the error of a mapping and not the KL-divergence with respect to a\ntarget distribution.\nFurther, our bound is data-dependent and not based on the\ncomplexity of the hypothesis class.\nHyperparameter Optimization Hyperparameters are constants and conﬁgura-\ntions that are being used by a learning algorithm. Hyperparameter selection is the\nprocess of selecting the hyperparameters that will produce better learning. This in-\ncludes optimizing the number of epochs, size and depth of the neural network being\ntrained, learning rate, etc. Many of the earlier hyperparameter methods that go be-\nyond a random- or a grid-search were Bayesian in nature [19, 20, 21, 22, 23]. The\nhyperband method [4], which is currently leading various supervised learning bench-\nmarks, is based on the multi-arm bandit problem. It employs partial training and\ndynamically allocates more resources to successful conﬁgurations. All such methods\ncrucially rely on a validation error to be available for a given conﬁguration, which\nmeans that these can only be used in the supervised settings. Our work enables, for\nthe ﬁrst time, the usage of such methods also in the unsupervised setting, by using\nour bound in lieu of the validation error for predicting the ground truth error.\n2. Problem Setup\nIn Sec. 2.1 we deﬁne the alignment problem. Sec 2.2 illustrates the Simplicity Principle\nwhich was introduced in [3] and was veriﬁed with an extensive set of experiments.\nSec. 2.3 and everything that follows are completely novel. The section proposes the\nOccam’s razor property, which extends the deﬁnition of the Simplicity Principle, and\nwhich is used in Sec. 3 to derive the main results and algorithms.\n2.1 The Alignment Problem\nThe learning algorithm is provided with two unlabeled datasets: one includes i.i.d\nsamples from a ﬁrst distribution and the second, i.i.d samples from a second distri-\n3\nbution.\nSA = {xi}m\ni=1\ni.i.d\n∼Dm\nA and SB = {yi}n\ni=1\ni.i.d\n∼Dn\nB\n(1)\nDA and DB are distributions over XA and XB (resp.). In addition, yAB denotes the\ntarget function, which is one of the functions that map the ﬁrst domain to the second,\nsuch that yAB◦DA = DB (g◦D is deﬁned to be the distribution of g(x) where x ∼D).\nThe goal of the learner is to ﬁt a function G ∈H, for some hypothesis class H that\nis closest to yAB, i.e,\ninf\nG∈H RDA[G, yAB]\n(2)\nwhere RD[f1, f2] =\nE\nx∼D [ℓ(f1(x), f2(x))], for a loss function ℓ: RM × RM →R and\ndistribution D.\nIt is not clear that such ﬁtting is possible, without additional information. Assume,\nfor example, that there is a natural order on the samples in XB. A mapping that maps\nan input sample x ∈XA to the sample that is next in order to yAB(x), could be just\nas feasible. More generally, one can permute the samples in XA by some function Π\nthat replaces each sample with another sample that has a similar likelihood and learn\nG that satisﬁes G = Π ◦yAB. This diﬃculty is referred to in [3] as “the alignment\nproblem”.\nIn multiple recent contributions [15, 8, 9, 10], circularity is employed. Circularity\nrequires the recovery of both yAB and yBA = y−1\nAB simultaneously. Namely, functions\nG and G′ are learned jointly by minimizing the following objective:\ndisc(G ◦DA, DB) + disc(G′ ◦DB, DA) + RDA[G′ ◦G, IdA] + RDB[G ◦G′, IdB]\n(3)\nwhere\ndisc(D1, D2) = sup\nc1,c2∈C\n\f\fRD1[c1, c2] −RD2[c1, c2]\n\f\f\n(4)\ndenotes the discrepancy between distributions D1 and D2, and C is a set of discrimi-\nnators. This discrepancy is implemented by a GAN, as in [24].\nAs shown in [3], the circularity constraint does not eliminate the uncertainty in\nits entirety. In DistanceGAN [14], the circularity was replaced by a multidimensional\nscaling type of constraint, which enforces a high correlation between the distances\nin the two domains. However, since these constraints hold only approximately, the\nambiguity is not completely eliminated.\n2.2 The Simplicity Principle\nIn order to understand how the recent unsupervised image mapping methods work\ndespite the inherent ambiguity, [3] recently showed that the target (“semantic”) map-\nping yAB is typically the distribution preserving mapping (h ◦DA = DB) with the\nlowest complexity. It was shown that such mappings are expected to be unique.\nAs a motivating example to the key role of minimal mappings, consider the domain\nA of uniformly distributed points (x1, x2)⊤∈R2, where x1 = x2 ∈[−1, 1]. Let B\nbe the domain of uniformly distributed points in {(x1, x2)⊤|x1 ∈[0, 1], x2 = 0} ∪\n4\n(-1,0)\n(0,0)\n(1,0)\n(0,-1)\n(0,1)\n(-1,0)\n(0,0)\n(1,0)\n(0,-1)\n(0,1)\n(a)\n(b)\nFigure 1:\nAn illustrative example, where the two domains are the blue and green\nareas. There are inﬁnitely many mappings that preserve the uniform distribution on\nthe two domains. However, only two stand out as “semantic”. These two, which are\ndepicted in red, are exactly the two mappings that can be captured by a minimal\nneural network with ReLU activations. (a) the mapping y1\nAB. (b) the mapping y2\nAB\n(see Eq. 5).\n{(x1, x2)⊤|x2 ∈[0, 1], x1 = 0}. We note that there are inﬁnitely many mappings from\ndomain A to B that, given inputs in A, result in the uniform distribution of B and\nsatisfy the circularity constraint (Eq. 3).\nHowever, it is easy to see that when restricting the hypothesis class to neural\nnetworks with one layer of size 2, and ReLU activations σ, there are only two options\nleft.\nIn this case, h(x) = σa(Wx), for W ∈R2×2,b ∈R2.\nThe only admissible\nsolutions are of the form W =\n\u0012 a\n1 −a\nb\n−1 −b\n\u0013\nor W ′ =\n\u0012 a\n−1 −a\nb\n1 −b\n\u0013\n, which\nare identical, for every a, b ∈R, to one of the following functions:\ny1\nAB((x, x)⊤) =\n\u001a (x, 0)⊤\nif x ≥0\n(0, −x)⊤\nif x ≤0\nand y2\nAB((x, x)⊤) =\n\u001a (0, x)⊤\nif x ≥0\n(−x, 0)⊤\nif x ≤0\n(5)\nTherefore, by restricting the hypothesis space to be minimal, we eliminate all\nalternative solutions, except two.\nThese two are exactly the two mappings that\nwould commonly be considered “more semantic” than any other mapping, see Fig. 1.\nAnother motivating example can be found in [3].\n2.3 Occam’s Razor\nWe note that the Simplicity Principle, presented in [3], is highly related to the prin-\nciple known as Occam’s razor. In this section we provide a deﬁnition of the Occam’s\nrazor property which extends the formulation of the Simplicity Principle used in [3].\nOur formulation is not limited to Kolmogorov-like complexity of multi-layered neural\nnetworks as in [3] and is more general.\n5\nGiven two domains A = (XA, DA) and B = (XB, DB), a mapping yAB : XA →XB\nsatisﬁes the Occam’s razor property between domains A and B, if it has minimal\ncomplexity among the functions h : XA →XB that satisfy h ◦DA ≈DB. Minimal\ncomplexity is deﬁned by the nesting of hypothesis classes, which forms a partial\norder, and not as a continuous score. For example, if Hj is the set of neural networks\nof a speciﬁc architecture and Hi is the set of neural networks of the architecture\nobtained after deleting one of the hidden neurons, then, Hi ⊂Hj. Intuitively, minimal\ncomplexity would mean that there is no sub-class that can implement a mapping\nh : XA →XB such that h ◦DA ≈DB. For this purpose, we deﬁne,\nP(H; ϵ) =\nn\nG ∈H\n\f\f\f disc(G ◦DA, DB) ≤ϵ\no\n(6)\nDeﬁnition 1 (Occam’s razor property). Let A = (XA, DA) and B = (XB, DB) be\ntwo domains and U = {Hi}i∈I be a family of hypothesis classes. A mapping yAB :\nXA →XB satisﬁes an (ϵ1, ϵ2)-Occam’s razor property if for every H ∈U such that\nP(H; ϵ1) ̸= ∅, we have:\ninf\nG∈P(H;ϵ1)RDA[G, yAB] ≤ϵ2.\nInformally, according to Def. 1, a function satisﬁes the Occam’s razor property,\nif it can be approximated by even the lowest-complexity hypothesis classes that suc-\ncessfully map between the domains A and B. If yAB has the (ϵ1, ϵ2)-Occam’s razor\nproperty, then it is ϵ2-close to a function in every minimal hypothesis class H ∈U\nsuch that P(H; ϵ1) ̸= ∅. As the hypothesis class H grows, so does P(H; ϵ1), i.e.,\nHi ⊂Hj implies that P(Hi; ϵ1) ⊂P(Hj; ϵ1). Therefore, the growing P(H; ϵ1) would\nalways contain at least one function that is ϵ2-close to yAB. Nevertheless, as the hy-\npothesis class grows, P(H; ϵ1) can potentially contain many functions f that satisfy\nf ◦DA ≈DB and diﬀer from each other, causing an increased amount of ambiguity.\nIn addition, we note that uniqueness is not assumed, and the property may hold for\nmultiple mappings.\n3. Estimating the Ground Truth Error\nIn this section, we introduce a bound on the generalization risk between a given\nfunction G1 ∈H and an unknown target function yAB, i.e., RDA[G1, yAB]. This bound\nis based on a bias-variance decomposition and sums two terms: the bias error and\nthe approximation error. The bias error is the maximal risk possible with a member\nG2 of the class P(H; ϵ1), i.e.,\nsup\nG2∈P(H;ϵ1)\nRDA[G1, G2]. The approximation error is the\nminimal possible risk between a member G of the class P(H; ϵ1) with respect to yAB,\ni.e.,\ninf\nG∈P(H;ϵ1)RDA[G, yAB].\n3.1 Derivation of the Bound and the Algorithms\nThe bound is a consequence of using a loss ℓthat satisﬁes the triangle inequality.\nLosses of this type include the L1 loss, which is often used in cross domain mapping.\n6\nThe L2 loss satisﬁes the triangle inequality up to a factor of three, which would incur\nthe addition of a factor into the bound.\nLemma 2. Let A = (XA, DA) and B = (XB, DB) be two domains, U = {Hi}i∈I be a\nfamily of hypothesis classes and ϵ1 > 0. In addition, assume that ℓis a loss function\nthat satisﬁes the triangle inequality. Then, for all H ∈U such that P(H; ϵ1) ̸= ∅and\ntwo functions yAB and G1, we have:\nRDA[G1, yAB] ≤\nsup\nG2∈P(H;ϵ1)\nRDA[G1, G2] +\ninf\nG∈P(H;ϵ1)RDA[G, yAB]\n(7)\nProof Let G∗= arg inf\nG∈P(H;ϵ1)\nRDA[G, yAB]. By the triangle inequality, we have:\nRDA[G1, yAB] ≤RDA[G1, G∗] + RDA[G∗, yAB]\n≤\nsup\nG2∈P(H;ϵ1)\nRDA[G1, G2] +\ninf\nG∈P(H;ϵ1)RDA[G, yAB]\n(8)\nIf yAB satisﬁes Occam’s razor, then the approximation error is lower than ϵ2 and by\nEq. 7 in Lem. 2 the following bound is obtained:\nRDA[G1, yAB] ≤\nsup\nG2∈P(H;ϵ1)\nRDA[G1, G2] + ϵ2\n(9)\nEq. 9 provides us with an accessible bound for the generalization risk. The right\nhand side can be directly approximated by training a neural network G2 that has a\ndiscrepancy lower than ϵ1 and has the maximal risk with regards to G1, i.e.,\nsup\nG2∈H\nRDA[G1, G2] s.t: disc(G2 ◦DA, DB) ≤ϵ1\n(10)\nBy applying Lagrange relaxation, we obtain the following Lagrangian dual form:\nL(G2, λ) = RDA[G1, G2] + µ · (ϵ1 −disc(G2 ◦DA, DB))\n(11)\nTherefore, instead of computing Eq. 10, we maximize the dual form in Eq. 11. For\nconvenience, we will use the following equivalent representation of it:\nmax\nG2 RDA[G1, G2] + µ · (ϵ1 −disc(G2 ◦DA, DB))\n⇐⇒min\nG2 −RDA[G1, G2] −µ · (ϵ1 −disc(G2 ◦DA, DB))\n⇐⇒min\nG2 disc(G2 ◦DA, DB) −(1/µ) · RDA[G1, G2] −ϵ1\nλ:=1/µ\n⇐⇒min\nG2 disc(G2 ◦DA, DB) −λRDA[G1, G2]\n(12)\nThe expectation over x ∼DA (resp x ∼DB) in the risk and discrepancy are replaced,\nas is often done, with the sum over the training samples in domain A (resp B). Based\non this, we present a stopping criterion in Alg. 1, and a method for hyperparameter\nselection in Alg. 2. Eq. 11 is manifested in Step 4 of the former and Step 6 of the\nlatter is the selection criterion that appears as the last line of both algorithms.\n7\nAlgorithm 1 Deciding when to stop training G1\nRequire: SA and SB: unlabeled training sets; H: a hypothesis class; ϵ1: a threshold;\nλ: a trade-oﬀparameter; T2: a ﬁxed number of epochs for G2; T1: a maximal\nnumber of epochs.\n1: Initialize G0\n1 ∈H and G0\n2 ∈H randomly.\n2: for i = 1, ..., T1 do\n3:\nTrain Gi−1\n1\nfor one epoch to minimize disc(Gi−1\n1\n◦DA, DB), obtaining Gi\n1.\n4:\nTrain Gi\n2 for T2 epochs to minimize disc(Gi\n2 ◦DA, DB) −λRDA[Gi\n1, Gi\n2].\n▷T2 provides a ﬁxed comparison point.\n5: end for\n6: return Gt\n1 such that: t = arg min\ni∈[T]\nRDA[Gi\n1, Gi\n2].\nAlgorithm 2 Model Selection\nRequire: SA and SB: unlabeled training sets; U = {Hi}i∈I: a family of hypothesis\nclasses; ϵ: a threshold; λ: a trade-oﬀparameter.\n1: Initialize J = ∅.\n2: for i ∈I do\n3:\nTrain Gi\n1 ∈Hi to minimize disc(Gi\n1 ◦DA, DB).\n4:\nif disc(Gi\n1 ◦DA, DB) ≤ϵ then\n5:\nAdd i to J.\n6:\nTrain Gi\n2 ∈Hi to minimize disc(Gi\n2 ◦DA, DB) −λRDA[Gi\n1, Gi\n2].\n7:\nend if\n8: end for\n9: return Gi\n1 such that: i = arg min\nj∈J\nRDA[Gj\n1, Gj\n2].\n3.2 Bound on the Loss of Each Sample\nWe next extend the bound to estimate the error ℓ(G1(x), yAB(x)) of mapping by G1\na speciﬁc sample x ∼DA. Lem. 3 follows very closely to Lem. 2. It gives rise to\na simple method for bounding the loss of G1 on a speciﬁc sample x. Note that the\nsecond term in the bound does not depend on G1 and is expected to be small, since\nit denotes the capability of overﬁtting on a single sample x.\nLemma 3. Let A = (XA, DA) and B = (XB, DB) be two domains and H a hypothesis\nclass. In addition, let ℓbe a loss function satisfying the triangle inequality. Then, for\nany target function yAB and G1 ∈H, we have:\nℓ(G1(x), yAB(x)) ≤\nsup\nG2∈P(H;ϵ)\nℓ(G1(x), G2(x)) +\ninf\nG∈P(H;ϵ)ℓ(G(x), yAB(x))\n(13)\nSimilarly to the analysis done in Sec. 3, Eq. 13 provides us with an accessible\nbound for the generalization risk. The RHS can be directly approximated by training\n8\nAlgorithm 3 Bounding the loss of G1 on sample x\nRequire: SA and SB: unlabeled training sets; H: a hypothesis class; G1 ∈H: a\nmapping; λ: a trade-oﬀparameter; x: a speciﬁc sample.\n1: Train G2 ∈H to minimize disc(G2 ◦DA, DB) −λℓ(G1(x), G2(x)).\n2: return ℓ(G1(x), G2(x)).\na neural network G2 of a discrepancy lower than ϵ and has maximal loss with regards\nto G1, i.e.,\nsup\nG2∈H\nℓ(G1(x), G2(x)) s.t: disc(G2 ◦DA, DB) ≤ϵ\n(14)\nWith similar considerations as in Sec. 3, we replace Eq. 14 with the following objective:\nmin\nG2∈H disc(G2 ◦DA, DB) −λℓ(G1(x), G2(x))\n(15)\nAs before, the expectation over x ∼DA and x ∼DB in the discrepancy are replaced\nwith the sum over the training samples in domain A and B (resp.).\nIn practice, we modify Eq. 15 such that x is weighted to half the weight of all\nsamples, during the training of G2. This emphasizes the role of x and allows us to\ntrain G2 for less epochs. This is important, as a diﬀerent G2 must be trained for\nmeasuring the error of each sample x.\n3.3 Deriving an Unsupervised Variant of Hyperband using the Bound\nIn order to optimize multiple hyperparameters simultaneously, we create an unsu-\npervised variant of the hyperband method [4]. Hyperband requires the evaluation of\nthe loss for every conﬁguration of hyperparameters. In our case, our loss is the risk\nfunction, RDA[G1, yAB]. Since we cannot compute the actual risk, we replace it with\nour bound\nsup\nG2∈P(H;ϵ1)\nRDA[G1, G2].\nIn particular, the function ‘run then return val loss’ in the hyperband algorithm\n(Alg. 1 of [4]), which is a plug-in function for loss evaluation, is provided with our\nbound from Eq. 9 after training G2, as in Eq. 11. Our variant of this function is listed\nin Alg. 4. It employs two additional procedures that are used to store the learned\nmodels G1 and G2 at a certain point in the training process and to retrieve these to\ncontinue the training for a set amount of epochs. The retrieval function is simply a\nmap between a vector of hypermarkets and a tuple of the learned networks and the\nnumber of epochs T when stored. For a new vector of hyperparameters, it returns\nT = 0 and two randomly initialized networks, with architectures that are determined\nby the given set of hyperparameters. When a network is retrieved, it is then trained\nfor a number of epochs that is the diﬀerence between the required number of epochs\nT, which is given by the hyperband method, and the number of epochs it was already\ntrained, denoted by Tlast.\n9\nAlgorithm 4 Unsupervised run then return val loss for hyperband\nRequire: SA, SB, and λ as before. T: Number of epochs. θ: Set of hyperparameters\n1: [G1, G2, Tlast] = return stored functions(θ)\n2: Train G1 for T −Tlast epochs to minimize disc(G1 ◦DA, DB).\n3: Train G2 for T −Tlast epochs to minimize disc(G2 ◦DA, DB) −λRDA[G1, G2].\n4: store functions(θ, [G1, G2, T])\n5: return RDA[G1, G2].\nTable 1: Pearson correlations and the corresponding p-values (in parentheses) of the\nground truth error with: (i) the bound, (ii) the GAN losses, and (iii) the circularity\nlosses or (iv) the distance correlation loss. ∗The cycle loss A →B →A is shown for\nDiscoGAN and the distance correlation loss is shown for DistanceGAN.\nAlg.\nMethod\nDataset\nBound\nGANA\nGANB\nCycleA/LD∗\nCycleB\nAlg. 1 Disco-\nShoes2Edges\n1.00 (<1E-16)\n-0.15 (3E-03)\n-0.28 (1E-08)\n0.76(<1E-16)\n0.79(<1E-16)\nGAN [8]\nBags2Edges\n1.00 (<1E-16)\n-0.26 (6E-11)\n-0.57 (<1E-16)\n0.85 (<1E-16)\n0.84 (<1E-16)\nCityscapes\n0.94 (<1E-16)\n-0.66 (<1E-16)\n-0.69 (<1E-16)\n-0.26 (1E-07)\n0.80 (<1E-16)\nFacades\n0.85 (<1E-16)\n-0.46 (<1E-16)\n0.66 (<1E-16)\n0.92 (<1E-16)\n0.66 (<1E-16)\nMaps\n1.00 (<1E-16)\n-0.81 (<1E-16)\n0.58 (<1E-16)\n0.20 (9E-05)\n-0.14 (5E-03)\nDistance- Shoes2Edges\n0.98 (<1E-16)\n-\n-0.25 (2E-16)\n-0.14 (1E-05)\n-\nGAN [14] Bags2Edges\n0.93 (<1E-16)\n-\n-0.08 (2E-02)\n0.34 (<1E-16)\n-\nCityscapes\n0.59 (<1E-16)\n-\n0.22 (1E-11)\n-0.41 (<1E-16)\n-\nFacades\n0.48 (<1E-16)\n-\n0.03 (5E-01)\n-0.01 (9E-01)\n-\nMaps\n1.00 (<1E-16)\n-\n-0.73 (<1E-16)\n0.39 (4E-16)\n-\nAlg. 2 Disco-\nShoes2Edges\n0.95 (1E-03)\n0.73 (7E-02)\n0.51 (2E-01)\n0.05 (9E-01)\n0.05 (9E-01)\nGAN [8]\nBags2Edges\n0.99 (2E-06)\n0.64 (2E-01)\n0.54 (3E-01)\n-0.26 (7E-01)\n-0.20 (7E-01)\nCityscapes\n0.99 (1E-03)\n0.69 (9E-02)\n0.85 (2E-02)\n-0.53 (2E-01)\n-0.42 (4E-01)\nFacades\n0.94 (1E-03)\n-0.33 (4E-01)\n0.88 (4E-02)\n0.66 (8E-02)\n-0.45 (3E-01)\nMaps\n1.00 (1E-03)\n0.62 (1E-01)\n0.54 (2E-01)\n0.60 (2E-01)\n0.07 (9E-01)\nDistance- Shoes2Edges\n0.96 (1E-04)\n-\n0.33 (5E-01)\n-0.87 (6E-03)\n-\nGAN [14] Bags2Edges\n0.98 (1E-05)\n-\n-0.11 (8E-01)\n0.23 (6E-01)\n-\nCityscapes\n0.92 (1E-03)\n-\n0.66 (8E-02)\n-0.49 (2E-01)\n-\nFacades\n0.84 (2E-02)\n-\n0.75 (5E-02)\n0.37 (4E-01)\n-\nMaps\n0.95 (1E-03)\n-\n-0.43 (3E-01)\n-0.15 (7E-01)\n-\nAlg. 3 Disco-\nShoes2Edges\n0.92 (<1E-16)\n-0.12 (5E-01)\n0.02 (9E-01)\n0.29 (6E-02)\n0.15 (4E-01)\nGAN [8]\nBags2Edges\n0.96 (<1E-16)\n0.25 (1E-01)\n0.08 (6E-01)\n0.08 (6E-01)\n0.05 (7E-01)\nCityscapes\n0.78 (4E-04)\n0.24 (4E-01)\n-0.16 (6E-01)\n-0.04 (9E-01)\n0.03 (9E-01)\nFacades\n0.80 (6E-10)\n0.13 (4E-01)\n0.16 (3E-01)\n0.20 (2E-01)\n0.09 (5E-01)\nMaps\n0.66 (1E-03)\n0.08 (7E-01)\n0.12 (6E-01)\n0.17 (5E-01)\n-0.25 (3E-01)\nDistance- Shoes2Edges\n0.98 (<1E-16)\n-\n-0.05 (7E-01)\n0.84 (<1E-16)\n-\nGAN [14] Bags2Edges\n0.92 (<1E-16)\n-\n-0.28 (2E-01)\n0.45 (3E-02)\n-\nCityscapes\n0.51 (4E-04)\n-\n0.10 (5E-01)\n0.28 (2E-2)\n-\nFacades\n0.72 (<1E-16)\n-\n-0.01 (1E00)\n0.08 (6E-01)\n-\nMaps\n0.94 (1E-06)\n-\n0.20 (2E-01)\n0.30 (6E-02)\n-\n4. Experiments\nWe test the three algorithms on two unsupervised alignment methods: DiscoGAN [8]\nand DistanceGAN [14]. In DiscoGAN, we train G1 (and G2), using two GANs and\ntwo circularity constraints; in DistanceGAN, one GAN and one distance correlation\n10\nMaps\nCityscapes\nFacades\nBags2Edges\nShoes2Edges\n(Alg 1, discoGAN)\n(Alg 1, distanceGAN)\n(Alg 2, discoGAN)\n(Alg 2, distanceGAN)\nFigure 2: Results of Alg. 1, 2. Ground truth errors are in red and bound in black.\nx-axis is the iteration or number of layers. y-axis is expected risk. For Alg. 1 it takes\na few epochs for G1 to have a small enough discrepancy, until which the bound is\nineﬀective.\nloss are used.\nThe published parameters for each dataset are used, except when\napplying our model selection method, where we vary the number of layers and when\nusing hyperband, where we vary the learning rate and the batch size as well.\nFive datasets were used in the experiments: (i) aerial photographs to maps, trained\non data scraped from Google Maps [13], (ii) the mapping between photographs from\nthe cityscapes dataset and their per-pixel semantic labels [25], (iii) architectural pho-\ntographs to their labels from the CMP Facades dataset [26], (iv) handbag images [27]\nto their binary edge images as obtained from the HED edge detector [28], and (v) a\nsimilar dataset for the shoe images from [29].\n11\n(Maps)\n(Cityscapes)\n(Facades)\n(Shoes2Edges)\n(Bags2Edges)\nFigure 3: Results of Alg. 3. Results shown for DiscoGAN for the ﬁrst row and for\nDistanceGAN in the second row. The ground truth errors (x-axis) vs. bound (y-axis)\nare shown per point. The coeﬃcient of determination is shown (top right).\n(a)\n(b)\nFigure 4: Results of Alg. 3 on DiscoGAN bags2edges. (a) The ground truth errors vs.\nthe bound per point are shown. This is the same as Fig. 3 top right plot with added\ninformation identifying speciﬁc points. (b) The source (x), ground truth (yAB(x))\nand mapping (G1(x)) of the marked points.\nThroughout the experiments, ﬁxed values are used as the low-discrepancy thresh-\nold (ϵ1 = 0.2). The tradeoﬀparameter between the dissimilarity term and the ﬁtting\nterm during the training of G2 is set, per dataset, to be the maximal value such that\nthe ﬁtting of G2 provides a solution that has a discrepancy lower than the threshold,\ndisc(G2 ◦DA, DB) ≤ϵ1. This is done once, for the default parameters of G1, as given\nin the original DiscoGAN and DistanceGAN [8, 14].\nThe results of all experiments are summarized in Tab. 1, which presents the cor-\nrelation and p-value between the ground truth error, as a function of the independent\n12\n(Handbags2Edges, discoGAN) (Shoes2Edges, distanceGAN)\n(Maps, distanceGAN)\nFigure 5: Per-epoch per-sample results for three experiments, four points each. x-axis is\niteration. y-axis is the per-sample error. Red line indicates the ground truth error of an\nindividual sample, i.e ||G1(x) −y(x)||1. Black line indicates our bound for an individual\nsample, i.e ||G1(x)−G2(x)||1. Note that it takes a few epochs for G1 to have a small enough\ndiscrepancy, until which the bound is ineﬀective.\nvariable, and the bound. The independent variable is either the training epoch, the\narchitecture, or the sample, depending on the algorithm tested. For example, in Alg. 2\nwe wish to decide on the best architecture, the independent variable is the number\nof layers. A high correlation (low p-value) between the bound and the ground truth\nerror, both as a function of the number of layers, indicates the validity of the bound\nand the utility of the algorithm. Similar correlations are shown with the GAN losses\nand the reconstruction losses (DiscoGAN) or the distance correlation loss (Distance-\nGAN), in order to demonstrate that these are much less correlated with the ground\ntruth error. In the plots of Fig. 2, we omit the other scores in order to reduce clutter.\n13\n(a)\n(b)\nFigure 6: Applying unsupervised hyperband for selecting the best conﬁguration for UNIT\nfor the Maps dataset. (a) blue and orange lines are bound and ground truth error as in\nFig. 7. (b) Images produced for 3 diﬀerent conﬁgurations as indicated on the plot in (a).\nStopping Criterion (Alg. 1) For testing the stopping criterion suggested in Alg. 1,\nwe compared, at each time point, two scores that are averaged over all training\nsamples: ||G1(x)−G2(x)||1, which is our bound, and the ground truth error ||G1(x)−\nyAB(x)||1, where yAB(x) is the ground truth image that matches x in domain B.\nNote that similar to the experiments with ground truth in the literature [8, 9, 14],\nthe ground truth error is measured in the label space and not in the image domain.\nThe mapping in the other direction yBA is not one to one.\nThe results are depicted in the main results table (Tab. 1) as well as in Fig. 2\nfor both DiscoGAN (ﬁrst column) and DistanceGAN (second column). As can be\nseen, there is an excellent match between the mean ground truth error of the learned\nmapping G1 and the predicted error. No such level of correlation is present when\nconsidering the GAN losses or the reconstruction losses (for DiscoGAN), or the dis-\ntance correlation loss of DistanceGAN. Speciﬁcally, the very low p-values in the ﬁrst\ncolumn of Tab. 1 show that there is a clear correlation between the ground truth\nerror and our bound for all datasets. For the other columns, the values in question\nare chosen to be the losses used for G1. The lower scores in these columns show that\nnone of these values are as correlated with the ground truth error, and so cannot be\nused to estimate this error.\nIn the experiment of Alg. 1 for DiscoGAN, which has a large number of sample\npoints, the cycle from B to A and back to B is signiﬁcantly correlated with the ground\ntruth error with very low p-values in four out of ﬁve datasets. However, its correlation\nis signiﬁcantly lower than that of our bound.\nIn Fig. 2, the Facades graph shows a diﬀerent behavior than the other graphs.\nThis is because the Facades dataset is inherently ambiguous and presents multiple\npossible mappings from A to B. Each mapping satisﬁes the Occam’s razor property\nseparately.\n14\nSelecting Architecture using Alg. 2 Next we vary the number of layers of G and\nconsider its eﬀect on the risk by measuring the bound and the ground truth error\n(which cannot be computed in an unsupervised way); A large correlation between\nour bound and the ground truth error is observed, see Tab. 1 and Fig. 2, columns 3\nand 4. We can therefore optimize the number of layers based on our bound. With a\nmuch smaller number of sample points, the p-values are generally higher than in the\nprevious experiment.\nBeyond correlations, Fig 2 (all four columns), can be used to quantify the gain\nfrom using the two algorithms. The “regret” when using the algorithm is simply the\nground truth error at the minimal value of the bound minus the minimal ground\ntruth error.\nPredicting per-Sample Loss with Alg. 3 Finally, we consider the per sample\nloss. The results are reported numerically in Tab. 1 and plotted in Fig. 3, 4. As can\nbe seen, there is a high degree of correlation between the measured bound and the\nground truth error. Therefore, our method is able to reliably predict the per-sample\nsuccess of a multivariate mapping learned in a fully unsupervised manner.\nRemarkably, this correlation also seems to hold when considering the time axis,\ni.e., we can combine Alg. 1 and Alg. 3 and select the stopping epoch that is best for a\nspeciﬁc sample. Fig. 5 depicts, for three experiments, the bound and the per-sample\nloss of G1 over time. In each graph, we plotted the values of the bound and the loss\nover time during training of G1. In each column we have the results for four samples\nwith a speciﬁc dataset and method. As can be seen, in the datasets tested, the bound\nholds over time. However, the points of a speciﬁc dataset seem to follow relatively\nsimilar patterns of improvement in time.\nSelecting Architecture with the Modiﬁed Hyperband Algorithm Our bound\nis used in Sec. 3.3 to create an unsupervised variant of the hyperband method. In\ncomparison to Alg. 2, this allows for the optimization of multiple hyperparameters at\nonce, while enjoying the eﬃcient search strategy of the hyperband method.\nFig. 7 demonstrates the applicability of our unsupervised hyperband-based method\nfor diﬀerent datasets, employing both DiscoGAN and DistanceGAN. The graphs show\nthe error and the bound obtained for the selected conﬁguration after up to 35 hy-\nperband iterations. As can be seen, in all cases, the method is able to recover a\nconﬁguration that is signiﬁcantly better than what is recovered, when only optimiz-\ning for the number of layers. To further demonstrate the generality of our method,\nwe applied it on the UNIT [30] architecture. As the runtime of UNIT is much higher\nthan DiscoGAN and DistanceGAN, this did not allow for extensive experimentation.\nWe therefore focused on the most useful application of applying hyperband on a rela-\ntively complex dataset, speciﬁcally Maps. Fig. 6 and Tab. 7(b) show the convergence\non the hyperband method.\n15\n5. Conclusions\nWe extend the envelope of what is known to be possible in unsupervised learning by\nshowing that we can reliably predict the error of a cross-domain mapping that was\ntrained without matching samples. This is true both in expectation, with application\nto hyperparameter selection, and per sample, thus supporting dynamic conﬁdence-\nbased run time behavior, and (future work) unsupervised boosting during training.\nThe method is based on measuring the maximal distance within the set of low\ndiscrepancy mappings. This measure becomes the bound by applying what we deﬁne\nas the Occam’s razor property, which is a general form of the Simplicity Principle.\nTherefore, the clear empirical success observed in our experiments supports the recent\nhypothesis that simplicity plays a key role in unsupervised learning.\nAcknowledgements\nThis project has received funding from the European Research Council (ERC) under\nthe European Union’s Horizon 2020 research and innovation programme (grant ERC\nCoG 725974).\n16\nMaps\nCityscapes\nFacades\nBags2Edges\nShoes2Edges\n(a)\nDataset\nNumber\nBatch\nLearning\nLayers\nSize\nRate\nDiscoGAN [8]\nShoes2Edges\n3\n24\n0.0008\nBags2Edges\n2\n59\n0.0010\nCityscapes\n3\n27\n0.0009\nFacades\n3\n20\n0.0008\nMaps\n3\n20\n0.0005\nDistanceGAN [14]\nShoes2Edges\n3\n15\n0.0007\nBags2Edges\n3\n33\n0.0007\nCityscapes\n4\n21\n0.0006\nFacades\n3\n8\n0.0006\nMaps\n3\n20\n0.0005\nDataset\n#Layers\n#Res\nL.Rate\nUNIT [30]\nMaps\n3\n1\n0.0003\n(b)\ndefault\nunsupervised\nparameters\nhyperband\nx\nG1(x)\nG1(x)\n(c)\nFigure 7: Applying unsupervised hyperband for selecting the best conﬁguration. For Disco-\nGAN and DistanceGAN we optimize of the number of encoder and decoder layers, batch\nsize and learning rate while for UNIT, we optmized for the number of encoder and decoder\nLayers, number of resnet layers and learning rate. (a) For each dataset, the ﬁrst plot is\nof DiscoGAN and the second is of DistanceGAN. Hyperband optimizes according to the\nbound values indicated in blue. The corresponding ground truth errors are shown in or-\nange. Dotted lines represent the best conﬁguration errors, when varying only the number of\nlayers without hyperband (blue for bound and orange for ground truth error). Each graph\nshows the error of the best conﬁguration selected by hyperband as a function the number\nof hyperband iterations. (b) The corresponding hyperparameters of the best conﬁguration\nas selected by hyperband. (c) Images produced for DiscoGAN’s shoes2edges: 1st column\nis the input, the 2nd is the result of DiscoGAN’s default conﬁguration, 3rd is the result of\nthe conﬁguration selected by our unsupervised Hyperband.\n17\nReferences\n[1] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,\nS., Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014)\n[2] Bojanowski, P., Joulin, A., Lopez-Paz, D., Szlam, A.:\nOptimizing the latent\nspace of generative networks. arXiv preprint arXiv:1707.05776 (2017)\n[3] Galanti, T., Wolf, L., Benaim, S.:\nThe role of minimal complexity functions\nin unsupervised learning of semantic mappings.\nInternational Conference on\nLearning Representations (2018)\n[4] Li, L., Jamieson, K.G., DeSalvo, G., Rostamizadeh, A., Talwalkar, A.: Eﬃcient\nhyperparameter optimization and inﬁnitely many armed bandits. arXiv preprint\narXiv:1603.06560 (2016)\n[5] Mirza, M., Osindero, S.: Conditional generative adversarial nets. arXiv preprint\narXiv:1411.1784 (2014)\n[6] Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H.: Generative\nadversarial text to image synthesis. In: ICML. (2016)\n[7] Dosovitskiy, A., Brox, T.: Generating images with perceptual similarity metrics\nbased on deep networks. arXiv preprint arXiv:1602.02644 (2016)\n[8] Kim, T., Cha, M., Kim, H., Lee, J., Kim, J.: Learning to discover cross-domain\nrelations with generative adversarial networks. arXiv preprint arXiv:1703.05192\n(2017)\n[9] Zhu, J.Y., Park, T., Isola, P., Efros, A.A.: Unpaired image-to-image translation\nusing cycle-consistent adversarial networkss. arXiv preprint arXiv:1703.10593\n(2017)\n[10] Yi, Z., Zhang, H., Tan, P., Gong, M.: DualGAN: Unsupervised dual learning for\nimage-to-image translation. arXiv preprint arXiv:1704.02510 (2017)\n[11] Liu, M.Y., Tuzel, O.: Coupled generative adversarial networks. In: NIPS. (2016)\n469–477\n[12] Taigman, Y., Polyak, A., Wolf, L.: Unsupervised cross-domain image generation.\nIn: International Conference on Learning Representations (ICLR). (2017)\n[13] Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.:\nImage-to-image translation with\nconditional adversarial networks. In: CVPR. (2017)\n[14] Benaim, S., Wolf, L.:\nOne-sided unsupervised domain mapping.\nIn: NIPS.\n(2017)\n18\n[15] Xia, Y., He, D., Qin, T., Wang, L., Yu, N., Liu, T.Y., Ma, W.Y.: Dual learning\nfor machine translation. arXiv preprint arXiv:1611.00179 (2016)\n[16] Wolf, L., Taigman, Y., Polyak, A.:\nUnsupervised creation of parameterized\navatars. In: The IEEE International Conference on Computer Vision (ICCV).\n(Oct 2017)\n[17] Seldin, Y., Tishby, N.: Pac-bayesian generalization bound for density estimation\nwith application to co-clustering. In: AISTATS. (2009)\n[18] Rakhlin, A., Panchenko, D., Mukherjee, S.: Esaim: Probability and statistics\nrisk bounds for mixture density estimation. (2005)\n[19] Snoek, J., Larochelle, H., Adams, R.P.: Practical bayesian optimization of ma-\nchine learning algorithms. In: NIPS. (2012)\n[20] Hutter, F., Hoos, H.H., Leyton-Brown, K.: Sequential model-based optimization\nfor general algorithm conﬁguration. In: Learning and Intelligent Optimization.\n(2011)\n[21] Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. J.\nMach. Learn. Res. 13 (February 2012) 281–305\n[22] Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-weka: Combined\nselection and hyperparameter optimization of classiﬁcation algorithms. In: KDD.\n(2013)\n[23] Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H.H.:\nTowards an empirical foundation for assessing bayesian optimization of hyper-\nparameters. (2013)\n[24] Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F.,\nMarchand, M., Lempitsky, V.: Domain-adversarial training of neural networks.\nJ. Mach. Learn. Res. 17(1) (2016) 2096–2030\n[25] Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,\nFranke, U., Roth, S., Schiele, B.:\nThe cityscapes dataset for semantic urban\nscene understanding. In: CVPR. (2016)\n[26] Radim Tyleˇcek, R.ˇS.: Spatial pattern templates for recognition of objects with\nregular structure. In: Proc. GCPR. (2013)\n[27] Zhu, J.Y., Kr¨ahenb¨uhl, P., Shechtman, E., Efros, A.A.: Generative visual ma-\nnipulation on the natural image manifold. In: ECCV. (2016)\n[28] Xie, S., Tu, Z.: Holistically-nested edge detection. In: ICCV. (2015)\n19\n[29] Yu, A., Grauman, K.: Fine-grained visual comparisons with local learning. In:\nCVPR. (2014)\n[30] Liu, M.Y., Breuel, T., Kautz, J.: Unsupervised image-to-image translation net-\nworks. In: NIPS. (2017)\n20\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2017-12-21",
  "updated": "2018-03-22"
}