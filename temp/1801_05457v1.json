{
  "id": "http://arxiv.org/abs/1801.05457v1",
  "title": "Solutions to problems with deep learning",
  "authors": [
    "J Gerard Wolff"
  ],
  "abstract": "Despite the several successes of deep learning systems, there are concerns\nabout their limitations, discussed most recently by Gary Marcus. This paper\ndiscusses Marcus's concerns and some others, together with solutions to several\nof these problems provided by the \"P theory of intelligence\" and its\nrealisation in the \"SP computer model\". The main advantages of the SP system\nare: relatively small requirements for data and the ability to learn from a\nsingle experience; the ability to model both hierarchical and non-hierarchical\nstructures; strengths in several kinds of reasoning, including `commonsense'\nreasoning; transparency in the representation of knowledge, and the provision\nof an audit trail for all processing; the likelihood that the SP system could\nnot be fooled into bizarre or eccentric recognition of stimuli, as deep\nlearning systems can be; the SP system provides a robust solution to the\nproblem of `catastrophic forgetting' in deep learning systems; the SP system\nprovides a theoretically-coherent solution to the problems of correcting over-\nand under-generalisations in learning, and learning correct structures despite\nerrors in data; unlike most research on deep learning, the SP programme of\nresearch draws extensively on research on human learning, perception, and\ncognition; and the SP programme of research has an overarching theory,\nsupported by evidence, something that is largely missing from research on deep\nlearning. In general, the SP system provides a much firmer foundation than deep\nlearning for the development of artificial general intelligence.",
  "text": "arXiv:1801.05457v1  [cs.LG]  8 Jan 2018\nSolutions to problems with deep learning\nJ Gerard Wolﬀ∗\nJanuary 18, 2018\nAbstract\nDespite the several successes of deep learning systems, there are\nconcerns about their limitations, discussed most recently by Gary\nMarcus.\nThis paper discusses Marcus’s concerns and some others,\ntogether with solutions to several of these problems provided by the\nSP theory of intelligence and its realisation in the SP computer model.\nThe main advantages of the SP system are: relatively small require-\nments for data and the ability to learn from a single experience; the\nability to model both hierarchical and non-hierarchical structures;\nstrengths in several kinds of reasoning, including ‘commonsense’ rea-\nsoning; transparency in the representation of knowledge, and the pro-\nvision of an audit trail for all processing; the likelihood that the SP\nsystem could not be fooled into bizarre or eccentric recognition of stim-\nuli, as deep learning systems can be; the SP system provides a robust\nsolution to the problem of ‘catastrophic forgetting’ in deep learning\nsystems; the SP system provides a theoretically-coherent solution to\nthe problems of correcting over- and under-generalisations in learn-\ning, and learning correct structures despite errors in data; unlike most\nresearch on deep learning, the SP programme of research draws ex-\ntensively on research on human learning, perception, and cognition;\nand the SP programme of research has an overarching theory, sup-\nported by evidence, something that is largely missing from research\non deep learning. In general, the SP system provides a much ﬁrmer\nfoundation than deep learning for the development of artiﬁcial general\nintelligence.\n∗Dr Gerry Wolﬀ, BA (Cantab), PhD (Wales), CEng, MBCS, MIEEE; CognitionRe-\nsearch.org, Menai Bridge, UK; jgw@cognitionresearch.org; +44 (0) 1248 712962; +44 (0)\n7746 290775; Skype: gerry.wolﬀ; Web: www.cognitionresearch.org.\n1\n1\nIntroduction\nDeep learning has received a great deal of attention, largely because of what\nit can do well, but there are concerns about its limitations, discussed most\nrecently by Gary Marcus [9].\nThis short paper discusses Marcus’s concerns brieﬂy and some others,\ntogether with solutions to several of these problems provided by the SP theory\nof intelligence and its realisation in the SP computer model [18, 17], outlined\nin [24, Appendix A] with pointers to where fuller information may be found.1\nSeveral of these solutions have been described in [23, Section V]. Refer-\nences to this paper are made at appropriate points below.\n2\nWhat deep learning does well\nAs Marcus says: “Deep learning, as it is primarily used, is essentially a\nstatistical technique for classifying patterns, based on sample data, using\nneural networks with multiple layers.” [9, p. 3]. Even in applications such\nas the playing of games, it seems that the primary function of deep learning\nis in the recognition of patterns.\n3\nProblems with deep learning and how they\nmay be solved\nIn this section, the ﬁrst 10 subheadings are the same as in [9], with the\nrelevant section number shown at the end of each heading. The remaining\nheadings are drawn largely from [23, Section V], unless they are already\ncovered by the ﬁrst 10 headings.\n3.1\nDeep learning thus far is data hungry (3.1)\nThe data-hungry nature of deep learning and how this may be overcome in\nthe SP system has been discussed quite fully in [23, Section V-E]. There is\nalso relevant discussion in [23, Section V-D].\nIn brief, the SP system, like a person, can learn from a single exposure\nor experience, and it can begin to form meaningful new structures and gen-\neralisations with exposure to a mere handful of other examples.\n1Publications in the SP programme of research, most with download links, may be\nfound on www.cognitionresearch.org/sp.htm.\n2\nIn this connection, the SP system is much more like a child than are deep\nlearning systems: neuroscientist David Cox has been reported as saying:\n“To build a dog detector [with a deep learning system], you need to show the\nprogram thousands of things that are dogs and thousands that aren’t dogs.\nMy daughter only had to see one dog.” and, the report says, she was happily\npointing out puppies ever since.2\nWhat about the slow learning of complex skills like speaking and under-\nstanding a new language or how to play a piano? With deep learning, it\nis assumed that this kind of slow acquisition of skills may be explained by\nthe gradual strengthening of links in Hebbian-style learning. By contrast, in\nthe SP system, the slow learning of complex skills may be explained by the\ncomplexity of the search that is required to ﬁnd good structures.\nIn summary, the SP system can explain learning from a single exposure\nor experience and it can explain the slow learning of complex skills.\nBy\ncontrast, a deep learning system can explain the slow learning of complex\nskills, but it fails to explain how learning may be achieved with a single\nexposure or experience, and more generally, it is excessively demanding in\nits requirements for data.\n3.2\nDeep learning thus far is shallow and has limited\ncapacity for transfer (3.2)\nIn [9, Section 3.2], Marcus points out quite rightly that “it is important to\nrealize that the word ‘deep’ in deep learning refers to a technical, architec-\ntural property (the large number of hidden layers used in a modern neural\nnetworks, where there predecessors used only one)” (p. 7).\nHe goes on to say that it is easy to over-interpret the results from a deep\nlearning system. For example, “according to a widely-circulated video of the\nsystem learning to play the brick-breaking Atari game Breakout, ‘after 240\nminutes of training, [the system] realizes that digging a tunnel through the\nwall is the most eﬀective technique to beat the game’. But the system has\nlearned no such thing; it doesn’t really understand what a tunnel, or what\na wall is; it has just learned speciﬁc contingencies for particular scenarios.\nTransfer tests—in which the deep reinforcement learning system is confronted\nwith scenarios that diﬀer in minor ways from the one ones on which the\nsystem was trained show that deep reinforcement learnings solutions are often\nextremely superﬁcial.” (p. 8).\nThe SP system certainly does not provide a comprehensive solution to\n2“Inside the moonshot eﬀort to ﬁnally ﬁgure out the brain”, MIT Technology Review,\n2017-10-12, bit.ly/2wRxsOg.\n3\nissues like those just described.\nIn brief, it seems fair to summarise the\nstrengths and potential of the SP system, and to compare it with deep learn-\ning systems, as follows:\n• The SP system has strengths in the representation of diverse kinds of\nknowledge, in diverse aspects of intelligence, and in the seamless inte-\ngration of diverse kinds of knowledge and diverse aspects of intelligence,\nin any combination. These strengths, which all ﬂow from the powerful\nconcept of SP-multiple-alignment, are summarised in [24, Sections 3, 4,\nand 5], with pointers to where fuller information may be found.\n• Although the SP system has strengths in the representation of diverse\nkinds of knowledge, it seems likely that more research will be required to\nunderstand how the system may learn and represent the great range of\nconcepts employed by people. There is some discussion in [19, Sections\n6.1 and 6.2] about how the system may develop a concept of a three-\ndimensional object, and in [19, Section 5.3], there is brief discussion of\nthe development of concepts like motion and speed.\n• At a ‘deep’ level, it seems likely that all kinds of learning, both in\ndeep learning systems and in the SP system, may be understood as the\nlearning of statistical contingencies.\n3.3\nDeep learning thus far has no natural way to deal\nwith hierarchical structure (3.3)\nComputer models developed in a programme of research on language learning\n(summarised in [18]) were designed to work by ‘hierarchical chunking’. As one\nmight expect, these models were good at representing hierarchical structures.\nBut in the ‘SP’ programme of research—where the aim has been to sim-\nplify and integrate observations and concepts across artiﬁcial intelligence,\nmainstream computing, mathematics, and human learning, perception, and\ncognition—hierarchical chunking would not do. The challenge has been to\ncreate a framework that would serve equally well for the representation of\nboth hierarchical and non-hierarchical structures.\nWhat has proved to be a good solution is the concept of SP-multiple-\nalignment, borrowed and adapted from the concept of ‘multiple sequence\nalignment’ in bioinformatics.\nAlthough the basic idea is to create align-\nments of two or more sequences,3 the framework lends itself very well to the\n3It is envisaged that at some stage the SP system will be adapted work with\ntwo-dimensional patterns as well as on-dimensional sequences.\n4\nrepresentation of the kinds of hierarchical structures recognised in linguistic\nanalysis, as can be seen in Figure 1.\n0\nt w o\nk i t t e n\ns\np l a y\n0\n| | |\n| | | | | |\n|\n| | | |\n1\n| | |\nNr 5 k i t t e n #Nr |\n| | | |\n1\n| | |\n|\n|\n|\n| | | |\n2\n| | |\nN Np Nr\n#Nr s #N\n| | | |\n2\n| | |\n| |\n|\n| | | |\n3\nD Dp 4 t w o #D | |\n|\n| | | |\n3\n|\n|\n| |\n|\n| | | |\n4\nNP D\n#D N |\n#N #NP\n| | | |\n4\n|\n|\n|\n| | | |\n5\n|\n|\n|\nVr 1 p l a y #Vr\n5\n|\n|\n|\n|\n|\n6\n|\n|\n|\nV Vp Vr\n#Vr #V\n6\n|\n|\n|\n| |\n|\n7 S Num\n; NP\n|\n#NP V |\n#V #S 7\n|\n|\n|\n|\n8\nNum PL ;\nNp\nVp\n8\nFigure 1: The best SP-multiple-alignment created by the SP computer model\nwith a store of SP-patterns like those in rows 1 to 8 (representing grammatical\nstructures, including words) and an SP-pattern representing a sentence to be\nparsed shown in row 0.\nThere is more discussion in [23, Section V-K].\n3.4\nDeep learning thus far has struggled with open-\nended inference (3.4)\nNo work has yet been done to explore whether or how the SP system can\nmodel ‘open ended’ inferences but, unlike deep learning systems, it has\nstrengths in several diﬀerent forms of reasoning including:\none-step ‘de-\nductive’ reasoning; chains of reasoning; abductive reasoning; reasoning with\nprobabilistic networks and trees; reasoning with ‘rules’; nonmonotonic rea-\nsoning and reasoning with default values; Bayesian reasoning with ‘explaining\naway’; causal reasoning; reasoning that is not supported by evidence; the in-\nheritance of attributes in class hierarchies; and inheritance of contexts in\npart-whole hierarchies ([17, Chapter 7], [18, Section 10]). Where it is ap-\npropriate, probabilities for inferences may be calculated in a straightforward\nmanner ([17, Section 3.7], [18, Section 4.4]). There is also potential for spatial\nreasoning [20, Section V-F.1], and for what-if reasoning [20, Section V-F.2].\nThere is more discussion in [23, Section V-L].\n5\n3.5\nDeep learning thus far is not suﬃciently transpar-\nent (3.5)\nMarcus [9, Section 3.5] writes that “Although some strides have been [made]\nin visualizing the contributions of individuals nodes in complex networks ...,\nmost observers would acknowledge that neural networks as a whole remain\nsomething of a black box.” (p. 11).\nIn this respect, there is a sharp contrast with the SP system [23, Section\nV-J]:\n• All knowledge stored by the SP system is transparent and open to\ninspection.\n• In general, knowledge in the SP system is likely to be comprehensible\nby people but problems may arise with concepts that have not yet been\nwell studied in the SP programme of research (Section 3.2).\n• There is an audit trail for all processing performed by the SP system\nand all conclusions it may reach.\n3.6\nDeep learning thus far has not been well integrated\nwith prior knowledge (3.6)\nMarcus [9, Section 3.6] writes that “Work in deep learning typically consists\nof ﬁnding a training database, sets of inputs associated with respective out-\nputs, and learn all that is required for the problem by learning the relations\nbetween those inputs and outputs, using whatever clever architectural vari-\nants one might devise, along with techniques for cleaning and augmenting\nthe data set. With just a handful of exceptions, ..., prior knowledge is often\ndeliberately minimized.” (p. 11).\nLater, he writes that “It also not straightforward in general how to in-\ntegrate prior knowledge into a deep learning system:, in part because the\nknowledge represented in deep learning systems pertains mainly to (largely\nopaque) correlations between features, rather than to abstractions like quan-\ntiﬁed statements (e.g.\nall men are mortal), see discussion of universally-\nquantiﬁed one-to-one-mappings in Marcus (2001), or generics ....” (p. 11).\nSimilar things may be said about the SP system but, here, the problems\nare likely to be less severe. This is because, in general, prior knowledge may\nbe represented in the same format as knowledge that the system learns for\nitself.\nLater in the same section, Marcus writes:\n6\n“Problems that have less to do with categorization and more to\ndo with commonsense reasoning essentially lie outside the scope\nof what deep learning is appropriate for, and so far as I can tell,\ndeep learning has little to oﬀer such problems. In a recent review\nof commonsense reasoning, Ernie Davis and I [5] began with a set\nof easily-drawn inferences that people can readily answer with-\nout anything like direct training, such as Who is taller, Prince\nWilliam or his baby son Prince George? Can you make a salad\nout of a polyester shirt? If you stick a pin into a carrot, does it\nmake a hole in the carrot or in the pin?\n“As far as I know, nobody has even tried to tackle this sort of\nthing with deep learning.\n“Such apparently simple problems require humans to integrate\nknowledge across vastly disparate sources, and as such are a long\nway from the sweet spot of deep learning-style perceptual classi-\nﬁcation. Instead, they are perhaps best thought of as a sign that\nentirely diﬀerent sorts of tools are needed, along with deep learn-\ning, if we are to reach human-level cognitive ﬂexibility.” (p. 12).\nIt appears that the SP system has considerable potential with the kinds of\ncommonsense reasoning discussed by Davis and Marcus [5]. This is described\nin [21], a detailed response to the issues raised in their paper.\n3.7\nDeep learning thus far cannot inherently distin-\nguish causation from correlation (3.7)\nMarcus [9, Section 3.7] writes: “If it is a truism that causation does not\nequal correlation, the distinction between the two is also a serious concern for\ndeep learning. Roughly speaking, deep learning learns complex correlations\nbetween input and output features, but with no inherent representation of\ncausality.” (p. 12–13).\nIt cannot be claimed that there is a comprehensive analysis, within the SP\nsystem, of the diﬀerence between causation and correlation. But the system\ndoes produce useful demonstrations of how such concepts may be modelled\nin the system:\n• Causation. In [18, Section 10.5] and [17, Section 7.9], there is a demon-\nstration of how the SP system may serve in the causal diagnosis of\nfaults in an electronic circuit.\n7\n• Correlation. In [18, Section 10.2] and [17, Section 7.8], there is an ex-\nample showing how Bayesian reasoning, with conditional probabilities\ncentre stage, may be modelled in the SP system.\n3.8\nDeep learning presumes a largely stable world, in\nways that may be problematic (3.8)\nMarcus [9, Section 3.8] writes: “The logic of deep learning is such that it is\nlikely to work best in highly stable worlds, like the board game Go, which\nhas unvarying rules, and less well in systems such as politics and economics\nthat are constantly changing.” (p. 13).\nMuch the same may be said of the SP system, or any other system that\nmodels the world via its statistical structure, which is the rule for most AI\nsystems.\nThe trick, of course, for people and for artiﬁcial systems, is to be prepared\nfor constant changes in the phenomena that one is modelling.\nAnd with\npredictions in areas such as economics, there is the possibility that each\nprediction itself may change what it is that is being predicted!\n3.9\nDeep learning thus far works well as an approxima-\ntion, but its answers often cannot be fully trusted\n(3.9)\nMarcus [9, Section 3.9] notes that there are now many examples where deep\nlearning systems are fooled into making misclassiﬁcations which appear ec-\ncentric or bizarre to people. In [23, Section V-G] I have described similar\nexamples.\nIn the latter section I have written:\n“With regard to the ﬁrst kind of error—failing to recognise some-\nthing that is almost identical to what has been recognised—there\nis already evidence that the SP computer model would not make\nthat kind of mistake. It can recognise words containing errors\nof omission, commission and substitution [17, Section 6.2.1], and\nlikewise for diseases in medical diagnosis viewed as pattern recog-\nnition [16, Section 3.6] and in the parsing of natural language [2,\nSection 4.2.2].\n“No attempt has been made to test experimentally whether or\nnot the SP computer model is prone to the second kind of error—\n8\nrecognising abstract patterns as ordinary objects—but a knowl-\nedge of how it works suggests that it would not be.”\nIn general, it seems that the SP system is unlikely to make the strange\nerrors of classiﬁcation to which deep learning systems are prone.\n3.10\nDeep learning thus far is diﬃcult to engineer with\n(3.10)\nMarcus [9, Section 3.10] writes:\n“Another fact that follows from all the issues raised above is that\nis simply hard to do robust engineering with deep learning. As a\nteam of authors at Google put it in 2014, in the title of an impor-\ntant, and as yet unanswered essay [12], machine learning is ‘the\nhigh-interest credit card of technical debt’, meaning that is com-\nparatively easy to make systems that work in some limited set of\ncircumstances (short term gain), but quite diﬃcult to guarantee\nthat they will work in alternative circumstances with novel data\nthat may not resemble previous training data (long term debt,\nparticularly if one system is used as an element in another larger\nsystem).\n“In an important talk at ICML, Leon Bottou [4] compared ma-\nchine learning to the development of an airplane engine, and\nnoted that while the airplane design relies on building complex\nsystems out of simpler systems for which it was possible to create\nsound guarantees about performance, machine learning lacks the\ncapacity to produce comparable guarantees. As Google’s Peter\nNorvig [10] has noted, machine learning as yet lacks the incremen-\ntality, transparency and debuggability of classical programming,\ntrading oﬀa kind of simplicity for deep challenges in achieving\nrobustness.\n“Henderson and colleagues have recently extended these points,\nwith a focus on deep reinforcement learning, noting some seri-\nous issues in the ﬁeld related to robustness and replicability [6].”\n(p. 14).\nEvidence to date suggests that these remarks are unlikely to apply to the\nSP system. Although development of the system has taken a long time, the\nSP computer model now exhibits considerable stability and robustness, and\npromises to provide a sound basis for scaling up with parallel processing, and\nfor further developments as noted in [18, Section 3.3].\n9\n3.11\nCatastrophic forgetting\nA weakness of deep learning that was overlooked in the writing of [23] is\na problem called “catastrophic forgetting”, meaning the way in which new\nlearning in a deep learning system wipes out old memories. A solution has\nbeen proposed in [8] but it appears to be partial, and it is unlikely to be\nsatisfactory in the long run.\nThe SP system is immune to any such inﬂuence in its learning. All learn-\ning is achieved by the addition of new SP-patterns to the system’s store of\nSP-patterns, and, while there may be some merging of new information with\nold information that is similar, new learning does not disturb old learning.\nOf course, there may be a case for introducing some kind of forgetting\ninto the system, but the system as it is now does not forget.\n3.12\nUnder- and over-generalisations and their correc-\ntion\nA general problem in any kind of learning system, especially the learning of a\nnatural language, is how to generalise ‘correctly’ from the ﬁnite sample of in-\nformation which is the basis for learning—avoiding both over-generalisations\nand under-generalisations. A related problem is learning from ‘dirty data’:\nhow to learn ‘correct’ structures despite the fact that most samples of data\ncontain ‘errors’—and this in the face of evidence that learning may be suc-\ncessful without the opportunity for children to receive correction from adults\nor older children.\nSeveral solutions have been proposed for deep learning systems, some of\nwhich are referenced in [23, Section V-N]. But I believe it is fair to say that\nnone of them are entirely satisfactory.\nWhat I believe is a much better solution has been described in [18, Section\n5.3] and in [23, Section V-N]. In brief:\n1. Given a ﬁnite sample of data, I, compress it as much as possible to\nyield a grammar, G, and an encoding, E, of I in terms of G.\n2. In general, it will be found that G represents the ‘essence’ of I, with-\nout over- or under-generalisations, and without ‘errors’ from the ‘dirty\ndata’.\nNaturally, there are many associated issues that may be discussed but I\nbelieve that the framework outlined here will prove to be sound.\n10\n3.13\nPsychology and neuroscience\nIt has long been recognised that deep learning systems are only loosely related\nto any kind of structure or processing in the brain. More generally, research\non deep learning has been conducted largely without reference to what has\nbeen learned about human learning, perception, and cognition, or what is\nknown about neuroscience.\nBy contrast, the SP system draws extensively on my own background\nin cognitive psychology, and my extensive programme of research on the\nlearning of a ﬁrst language or languages by children (summarised in [15]).\nFrom its beginnings, the SP programme of research has been inﬂuenced\nby a long-running theme, beginning with research by Fred Attneave [1], Ho-\nrace Barlow [2, 3] and others, pointing to the importance of information\ncompression in human learning, perception, and cognition.\nIt is also relevant to mention that abstract structures and processes in the\nSP system, map quite neatly on to what appear to be plausible structures of\nneurons and their interconnections, and how they may function, described in\n[22].\n3.14\nOverarching theory\nA variety of sources, perhaps most notably the work of Ray Solomonoﬀ[13,\n14] point to the importance of information compression in learning.\nIn research on deep learning in artiﬁcial neural networks, well reviewed\nby J¨urgen Schmidhuber [11], there is some recognition of the importance of\ninformation compression [11, Sections 4.2, 4.4, and 5.6.3], but it appears that\nthe idea is not well developed in deep learning systems.\nBy contrast, as readers may have learned from [18, 17], and may guess\nfrom Section 3.12, the SP system is devoted to the compression of informa-\ntion, and more precisely compression of information via the powerful concept\nof SP-multiple-alignment, illustrated in Figure 1. There is much evidence in\nsupport of this theory presented in [18, 17] and elsewhere.\nIn general, the SP system has a coherent overarching theory, something\nwhich is largely missing from research in deep learning.\n4\nPotential risks of excessive hype\nIn [9, Section 4], Marcus writes:\n“My own largest fear is that the ﬁeld of AI could get trapped\nin a local minimum, dwelling too heavily in the wrong part of\n11\nintellectual space, focusing too much on the detailed exploration\nof a particular class of accessible but limited models that are\ngeared around capturing low-hanging fruit—potentially neglect-\ning riskier excursions that might ultimately lead to a more robust\npath.”\nThis chimes very much with my own experience.\nDespite many re-\nspectable publications in the SP programme of research, and many useful\nresults, it has proved very diﬃcult to get a hearing for this work by those\nengaged in research on deep learning. It seems that the extraordinary enthu-\nsiasm for deep learning, perhaps coupled with the large amounts of money\nbeing channelled into this area, has made it very diﬃcult for researchers to\ndivert any of their attention to anything other than deep learning. One se-\nnior researcher, who was kind enough to reply to one of my emails, said that\nalthough the SP research may be interesting, he does not have the time to\nlook at it.\nGood science and engineering is not like this. To solve diﬃcult problems\nit is necessary to maintain several paths through the search space, and for\nresearchers in any one area to be prepared to keep abreast of developments\nin other areas. In keeping with that approach, the central aim of the SP\nprogramme of research is simpliﬁcation and integration of observations and\nconcepts across artiﬁcial intelligence, mainstream computing, mathematics,\nand human learning, perception, and cognition.\nOverspecialisation is a phenomenon noted by John Kelly and Steve\nHamm, both of IBM, in their book Smart Machines [7]. In connection with\nresearch on diﬀerent sensory modalities they write:\n“In order to make this great leap and become true thinking ma-\nchines, the cognitive systems of the future will integrate informa-\ntion from multiple sensing technologies. Today, as scientists labor\nto create machine technologies to augment our senses, there’s a\nstrong tendency to view each sensory ﬁeld in isolation as special-\nists focus only on a single sensory capability. Experts in each\nsense don’t read journals devoted to the others senses, and they\ndon’t attend one another’s conferences. Even within IBM, our\nspecialists in diﬀerent sensing technologies don’t interact much.\nYet if machines are to help humans understand the world, they\nhave to make sense of it and communicate about it in a way\nthat’s familiar and comprehensible to humans. This integration\nof data from various sensing technologies is beginning to happen\nin multimedia and visual analytics, where vision and sound are\n12\ncorrelated. But that’s just the start of what will be required in\nthe next era of computing. (p. 74).\n5\nWhat would be better?\nIn [9, Section 5], Marcus writes: “Despite all of the problems I have sketched,\nI don’t think that we need to abandon deep learning.\nRather, we need\nto reconceptualize it: not as a universal solvent, but simply as one tool\namong many, a power screwdriver in a world in which we also need hammers,\nwrenches, and pliers, not to mentions chisels and drills, voltmeters, logic\nprobes, and oscilloscopes.” (p. 18).\nYes, of course, in the spirit of maintaining several paths through the\nsearch space, it would be wrong to abandon all research on deep learning.\nBut there is certainly a need to open up other areas and I believe the SP\nframework is one of them.\nRegarding Marcus’s remarks about symbolic and sub-symbolic systems\n[9, Section 5.2], I believe the SP system bridges that divide. In principle, it\nmay work at any level of granularity.\nIn connection with this: “The power and ﬂexibility of the brain comes\nin part from its capacity to dynamically integrate many diﬀerent computa-\ntions in real-time. The process of scene perception, for instance, seamlessly\nintegrates direct sensory information with complex abstractions about ob-\njects and their properties, lighting sources, and so forth.” (p. 20), a major\nstrength of the SP system, due largely to the powerful concept of SP-multiple-\nalignment, is the ability of the system to integrate diverse kinds of knowledge\nand diverse aspects of intelligence, in any combination.\nAs may be seen from Section 3.13, I agree very much that we should build\n“models that are motivated not just by mathematics but also by clues from\nthe strengths of human psychology.” (p. 21).\n6\nConclusion\nThe gist of this paper is that, while research on deep learning should certainly\ncontinue, the SP programme of research also merits attention. In that con-\nnection, the SP system has several advantages compared with deep learning\nsystems. The main ones are:\n• Quantities of data and one-trial learning (Section 3.1). By contrast\nwith deep learning systems, the SP system can produce meaningful\nresults with quite small amounts of data. It provides a model for the\n13\nway in which people can learn from a single exposure or experience. At\nthe same time it provides an explanation for why it takes time to learn\ncomplex skills.\n• Hierarchical and non-hierarchical structures (Section 3.3). Unlike deep\nlearning systems—which do no lend themselves well to the representa-\ntion of hierarchical structures—the SP system, via the concept of SP-\nmultiple-alignment, accommodates such structures very well. At the\nsame time, it also provides for the representation of non-hierarchical\nstructures.\n• Reasoning (Sections 3.4 and 3.6). Although no attempt has yet been\nmade to explore whether or how the SP system may perform ‘open\nended’ inference, the SP system has—unlike deep learning systems—\nstrengths in several diﬀerent kinds of reasoning. It also has strengths\nin ‘commonsense’ reasoning, as described in [21].\n• Transparency (Section 3.5). By contrast with deep learning systems,\nthe SP system provides complete transparency in the way in which\nit represents knowledge and it provides a full audit trail for all its\nprocessing.\n• It is unlikely that an SP system would be easily fooled (Section 3.9).\nDeep learning systems can misclassify stimuli in ways that people ﬁnd\neccentric or bizarre. Experience with the SP system, and a knowledge\nof how it works, suggests that it would be unlikely to make that kind\nof error.\n• Catastrophic forgetting (Section 3.11).\nA striking weakness of deep\nlearning systems is ‘catastrophic forgetting’—the way in which new\nlearning wipes out old learning. The SP system does not suﬀer from\nthis problem because new learning does not disturb old learning.\n• Correction of over- and under-generalisations, and learning from ‘dirty\ndata’ (Section 3.12). With deep learning systems, a variety of solutions\nhave been proposed for how to generalise correctly from a sample of\ndata, without over- or under-generalisation, but it appears that none\nof them are entirely satisfactory. By contrast, the SP system proposes\na theoretically-coherent solution that ﬂows from the core theory in the\nsystem. Those same principles provide an explanation of how learning\ncan be successful, despite errors in the data which is the basis for\nlearning.\n14\n• Psychology and neuroscience (Section 3.13).\nBy contrast with deep\nlearning systems, which have long been recognised as being only loosely\nrelated to what is known about the workings of the human brain, the SP\nsystem draws extensively on research on human learning, perception,\nand cognition. The SP system also suggests how abstract structures\nand processes in the system may be realised in terms of neurons and\ntheir interconnections.\n• Overarching theory (Section 3.14). The central principle in the SP the-\nory, derived from much research in cognitive psychology and supported\nby much evidence, is that much of human learning, perception, and\ncognition, may be understood as compression of information via the\nconcept of SP-multiple-alignment. By contrast, deep learning systems\nhave little or no over-arching theory.\nIn general, I believe that SP system provides a much ﬁrmer foundation\nthan deep learning for the development of artiﬁcial general intelligence.\nReferences\n[1] F. Attneave. Some informational aspects of visual perception. Psycho-\nlogical Review, 61:183–193, 1954.\n[2] H. B. Barlow. Sensory mechanisms, the reduction of redundancy, and\nintelligence. In HMSO, editor, The Mechanisation of Thought Processes,\npages 535–559. Her Majesty’s Stationery Oﬃce, London, 1959.\n[3] H. B. Barlow. Trigger features, adaptation and economy of impulses.\nIn K. N. Leibovic, editor, Information Processes in the Nervous System,\npages 209–230. Springer, New York, 1969.\n[4] L. Bottou. Two big challenges in machine learning. In Proceedings from\n32nd International Conference on Machine Learning, 2015.\n[5] E. Davis and G. Marcus. Commonsense reasoning and commonsense\nknowledge in artiﬁcial intelligence.\nCommunications of the ACM,\n58(9):92–103, 2015.\n[6] P. Henderson, R. Islam, P. Bachman, J. Pineau, D. Precup, and\nD. Meger.\nDeep reinforcement learning that matters.\n2017.\narXiv,\ncs.LG.\n15\n[7] J. E. Kelly and S. Hamm. Smart machines: IBM’s Watson and the era\nof cognitive computing. Columbia University Press, New York, Kindle\nedition, 2013.\n[8] J. Kirkpatrick. Overcoming catastrophic forgetting in neural networks.\nProceedings of the National Academy of Sciences of the United States of\nAmerica, 114(13):3521–3526, 2017.\n[9] G. Marcus. Deep learning: a critical appraisal. arXiv, 1801.00631v1\n[cs.AI]:1–27, 2018.\n[10] P. Norvig. State-of-the-art AI: building tomorrow’s intelligent systems.\nIn Proceedings from EmTech Digital, San Francisco, 2016.\n[11] J. Schmidhuber. Deep learning in neural networks: an overview. Neural\nNetworks, 61:85–117, 2015.\n[12] D. Sculley, T. Phillips, D. Ebner, V. Chaudhary, and M. Young. Machine\nlearning: The high-interest credit card of technical debt. In Proceedings\nfrom SE4ML: Software Engineering for Machine Learning (NIPS 2014\nWorkshop), 2014.\n[13] R. J. Solomonoﬀ. A formal theory of inductive inference. Parts I and II.\nInformation and Control, 7:1–22 and 224–254, 1964.\n[14] R. J. Solomonoﬀ. The discovery of algorithmic probability. Journal of\nComputer and System Sciences, 55(1):73–88, 1997.\n[15] J. G. Wolﬀ. Learning syntax and meanings through optimization and\ndistributional analysis.\nIn Y. Levy, I. M. Schlesinger, and M. D. S.\nBraine, editors, Categories and Processes in Language Acquisition, pages\n179–215. Lawrence Erlbaum, Hillsdale, NJ, 1988. bit.ly/ZIGjyc.\n[16] J. G. Wolﬀ.\nMedical diagnosis as pattern recognition in a frame-\nwork of information compression by multiple alignment, uniﬁcation and\nsearch. Decision Support Systems, 42:608–625, 2006. bit.ly/1F366o7,\narXiv:1409.8053.\n[17] J. G. Wolﬀ. Unifying Computing and Cognition: the SP Theory and Its\nApplications. CognitionResearch.org, Menai Bridge, 2006. ISBNs: 0-\n9550726-0-3 (ebook edition), 0-9550726-1-1 (print edition). Distributors,\nincluding Amazon.com, are detailed on bit.ly/WmB1rs.\n[18] J. G. Wolﬀ. The SP theory of intelligence: an overview. Information,\n4(3):283–341, 2013. bit.ly/1NOMJ6l, arXiv:1306.3888.\n16\n[19] J. G. Wolﬀ.\nApplication of the SP theory of intelligence to the un-\nderstanding of natural vision and the development of computer vision.\nSpringerPlus, 3(1):552–570, 2014. bit.ly/2oIpZB6, arXiv:1303.2071.\n[20] J. G. Wolﬀ. Autonomous robots and the SP theory of intelligence. IEEE\nAccess, 2:1629–1651, 2014. bit.ly/18DxU5K, arXiv:1409.8027.\n[21] J. G. Wolﬀ.\nCommonsense reasoning, commonsense knowledge, and\nthe SP theory of intelligence. Technical report, CognitionResearch.org,\n2016. bit.ly/2eBoE9E, arXiv:1609.07772.\n[22] J. G. Wolﬀ. Information compression, multiple alignment, and the rep-\nresentation and processing of knowledge in the brain. Frontiers in Psy-\nchology, 7:1584, 2016. bit.ly/2esmYyt, arXiv:1604.05535.\n[23] J. G. Wolﬀ.\nThe SP theory of intelligence:\nits distinctive features\nand advantages.\nIEEE Access, 4:216–246, 2016.\nbit.ly/2qgq5QF,\narXiv:1508.04087.\n[24] J. G. Wolﬀ.\nStrengths and potential of the sp theory of intel-\nligence in general, human-like artiﬁcial intelligence.\nTechnical re-\nport, CognitionResearch.org, 2017.\nbit.ly/2z3rM8b, viXra:1711.0292,\nhal.archives-ouvertes.fr/hal-01633376.\n17\n",
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "published": "2018-01-08",
  "updated": "2018-01-08"
}