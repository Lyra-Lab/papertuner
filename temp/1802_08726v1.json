{
  "id": "http://arxiv.org/abs/1802.08726v1",
  "title": "Longitudinal Face Aging in the Wild - Recent Deep Learning Approaches",
  "authors": [
    "Chi Nhan Duong",
    "Khoa Luu",
    "Kha Gia Quach",
    "Tien D. Bui"
  ],
  "abstract": "Face Aging has raised considerable attentions and interest from the computer\nvision community in recent years. Numerous approaches ranging from purely image\nprocessing techniques to deep learning structures have been proposed in\nliterature. In this paper, we aim to give a review of recent developments of\nmodern deep learning based approaches, i.e. Deep Generative Models, for Face\nAging task. Their structures, formulation, learning algorithms as well as\nsynthesized results are also provided with systematic discussions. Moreover,\nthe aging databases used in most methods to learn the aging process are also\nreviewed.",
  "text": "Longitudinal Face Aging in the Wild - Recent Deep Learning Approaches\nChi Nhan Duong\nConcordia University\nMontreal, Quebec, Canada\nEmail: c duon@encs.concordia.ca\nKha Gia Quach\nConcordia University\nMontreal, Quebec, Canada\nEmail: k q@encs.concordia.ca\nKhoa Luu\nCyLab Biometrics Center\nDept. of Electrical and Computer Engineering\nCarnegie Mellon University Pittsburgh, PA, USA\nEmail: kluu@andrew.cmu.edu\nTien D. Bui\nConcordia University\nMontreal, Quebec, Canada\nEmail: bui@encs.concordia.ca\nAbstract—Face Aging has raised considerable attentions and\ninterest from the computer vision community in recent years.\nNumerous approaches ranging from purely image processing\ntechniques to deep learning structures have been proposed in\nliterature. In this paper, we aim to give a review of recent\ndevelopments of modern deep learning based approaches, i.e.\nDeep Generative Models, for Face Aging task. Their structures,\nformulation, learning algorithms as well as synthesized results\nare also provided with systematic discussions. Moreover, the\naging databases used in most methods to learn the aging process\nare also reviewed.\nKeywords-Face Aging, Face Age Progression, Deep Genera-\ntive Models.\nI. INTRODUCTION\nIn recent years, age progression has received consider-\nable interest from the computer vision community. Start-\ning from the predominant approaches that require lots of\ntime and professional skills with the support from forensic\nartists, several breakthroughs have been achieved. Numerous\nautomatic age progression approaches from anthropology\ntheories to deep learning models have been proposed. In\ngeneral, the age progression methods can be technically\nclassiﬁed into four categories, i.e. modeling, reconstruction,\nprototyping and deep learning based methods. The meth-\nods in the ﬁrst three categories usually tend to simulate\nthe aging process of facial features by (1) adopting prior\nknowledge from anthropometric studies ; or (2) representing\nthe face geometry and appearance by a set of parameters\nvia conventional models such as Active Appearance Models\n(AAMs), 3D Morphable Models (3DMM) and manipulate\nthese parameters via learned aging functions. Although they\nhave achieved some inspiring synthesis results, these face\nrepresentations are still linear and facing lots of limitations\nin modeling the non-linear aging process.\nMeanwhile, the fourth category introduces modern ap-\nproaches with the state-of-the-art Deep Generative Mod-\nels (DGM) for both face modeling and aging embedding\nFigure 1.\nGiven input images, Age Progression task is to predict the future\nfaces of that subject many years later.\nprocess. Since deep learning structures have more capabil-\nities of interpreting and transferring the highly non-linear\nfeatures of the input signals, they are more suitable for\nmodeling the human aging process. As a result, superior\nsynthesized facial images [10], [11], [12], [39], [41] can be\ngenerated. Inspired by these state-of-the-art results, in this\npaper, we aim to provide a review of recent developments\nfor face age progression. Both structures and formulations of\nseveral Deep Generative Models, i.e. Restricted Boltzmann\nMachines (RBM), Deep Boltzmann Machines (DBM), and\nGenerative Adversarial Network (GAN), as well as the\nway they are adopted to age progression problem will be\npresented. Moreover, several common face aging databases\nare also reviewed.\nII. FACE AGING DATABASES\nDatabase collection for face aging is also a challenging\nproblem. There are several requirements during the collect-\ning process. Not only should each subject have images at\ndifferent ages, but also the covered age range should be\nlarge. Therefore, face aging databases are still limited in\nterms of age labels and the number of available databases.\nThe characteristics and age distributions of several current\nexisting face aging databases are summarized in Table I and\narXiv:1802.08726v1  [cs.CV]  23 Feb 2018\nTable I\nPROPERTIES OF DIFFERENT AGING DATABASES.“IN-THE-WILD” IMAGES ARE THE ONES COLLECTED FROM UNCONSTRAINED REAL-WORLD\nCONDITIONS.\nDatabase\n# Images\n# Subjects\nLabel type\nImage type\nSubject type\nClean Label\nPublic\nMORPH - Album 1 [30]\n1690\n628\nYears old\nMugshot\nNon-famous\n\u0014\n\u0014\nMORPH - Album 2 [30]\n55134\n13000\nYears old\nMugshot\nnon-famous\n\u0014\n\u0014\nFG-NET [1]\n1002\n82\nYears old\nIn-the-wild\nNon-famous\n\u0014\n\u0014\nAdienceFaces [21]\n26580\n2984\nAge groups\nIn-the-wild\nNon-famous\n\u0014\n\u0014\nCACD [6]\n163446\n2000\nYears old\nIn-the-wild\nCelebrities\n\u0017\n\u0014\nIMDB-WIKI [31]\n523051\n20284\nYears old\nIn-the-wild\nCelebrities\n\u0017\n\u0014\nAgeDB [25]\n16488\n568\nYears old\nIn-the-wild\nCelebrities\n\u0014\n\u0014\nAGFW (Ours) [10]\n18685\n14185\nAge groups\nIn-the-wild/Mugshot\nNon-famous\n\u0014\n\u0014\nAGFW-v2 (Ours)\n36325\n27688\nAge groups\nIn-the-wild/Mugshot\nNon-famous\n\u0014\n\u0014\nFigure 2.\nNormalized Age Distribution of Face Aging Databases\nFig. 2. Further than these databases, a large-scale in-the-\nwild dataset, named AGing Face in-the-Wild (AGFW),\nwas also introduced in our work [10] with 18,685 facial\nimages with individual ages sampled ranging from 10 to 64.\nIn this database, images are divided into 11 age groups with\nthe span of 5 years, each group contains 1,700 images on\naverage. This database is then extended to AGFW-v2 with\ndouble scale, i.e. 36,325 images with an average of 3,300\nimages per age group.\nIII. CONVENTIONAL APPROACHES\nIn this section, we provide a brief review of conventional\nage progression approaches including modeling, prototyp-\ning, and reconstructing based approaches. Their properties\nare also summarized in Table II.\nA. Modeling-based approach\nModeling-based approach is among the earliest categories\npresented for face age progression. These methods usually\nexploit some kinds of appearance models, i.e. Active Ap-\npearance Models (AAM), 3D Morphable Models (3DMM),\nto represent the shapes and texture of the input face by\na set of parameters. Then the aging process is simulated\nby learning some aging functions from the relationship of\nthe parameter sets of different age groups. In particular,\nPattersons et al. [26] and Lanitis et al. [20] employed a set\nof Active Appearance Models (AAMs) parameters with four\naging functions to model both the general and the speciﬁc\naging processes. Four variations of aging functions were\nintroduced: Global Aging Function, Appearance Speciﬁc\nAging Function (ASA), Weighted Appearance Aging Func-\ntion (WAA), and Weighted Person Speciﬁc Aging Function\n(WSA). Also by employing AAMs during the modeling step,\nLuu et al. [24] later incorporated familial facial cues to the\nprocess of face age progression.\nAnother direction of modeling was proposed in [13] with\na deﬁnition of AGing pattErn Subspace (AGES). In this\napproach, the authors construct a representative subspace for\naging patterns as a chronological sequence of face images.\nThen given an image, the proper aging pattern is determined\nby the projection in this subspace that produces smallest\nreconstruction error. Finally, the synthesized result at a target\nage is obtained by the reconstructed faces corresponding\nto that age position in the subspace. Tsai et al. [38] then\nenhanced the AGES using guidance faces corresponding to\nthe subject’s characteristics to produce more stable results.\nSuo et al. [35], [36] introduced the three-layer And-Or Graph\n(AOG) of smaller parts, i.e. eyes, nose, mouth, etc., to model\na face. Then, the face aging process was learned for each\npart using a Markov chain.\nB. Prototyping approach\nThe main idea of the methods in this category is to\npredeﬁne some types of aging prototypes and transfer the\ndifference between these prototypes to produce synthesized\nface images. Usually, the aging prototypes are deﬁned by\nthe average faces of all age groups [32]. Then, input face\nimage can be progressed to the target age by incorporating\nthe differences between the prototypes of two age groups [5].\nNotice that this approach requires a good alignment between\nfaces in order to produce plausible results. Kemelmacher-\nShlizerman et al. [18] then proposed to construct high\nquality average prototypes from a large-scale set of images.\nTable II\nA SUMMARY OF CONVENTIONAL APPROACHES FOR AGE PROGRESSION.\nMethod\nApproach\nRepresentation\nArchitecture\nSummary\nLanitis et al.\n2002 [20]\nModel based\nAAMs\n\u0017\nModel generic and speciﬁc aging processes\nfour types of aging functions\nPattersons et al.\n2006 [26]\nModel based\nAAMs\n\u0017\nLearning Effects of morphological changes\nMore efforts on the adult aging stage\nLuu et al.\n2009 [24]\nModel based\nAAMs\n\u0017\nIncorporated familial facial cues\nGeng et al.\n2007 [13]\nModel based\nAging Patterns\nAging Pattern Subspace\nGrammatical face model\nTsai et al.\n2014 [38]\nModel based\nAging Patterns\nAging Pattern Subspace\nGuidance faces according to subject’s feature\nSuo et al.\n2010 [36]\nModel based\nPart-based\nAnd-Or-Graph\nMarkov Chain on Parse Graphs\nSuo et al.\n2012 [35]\nModel based\nPart-based\nAnd-Or-Graph\nComposition of short-term graph evolution\nKemelmacher-\nShlizerman et al.\n2014 [18]\nPrototype\nImage pixel\n\u0017\nIllumination normalization and subspace\nalignment before transferring difference\nbetween prototypes.\nShu et al.\n2015 [34]\nReconstructing\nSparse Representation\nCoupled dictionaries\nDictionary Learning with personality-aware\ncoupled reconstruction loss\nYang et al.\n2016 [40]\nReconstructing\nSparse Representation\nHidden Factor Analysis\nSparse reconstruction with age-speciﬁc\nfeature\nFigure 3.\nExamples of age-progressed faces obtained by Illumination-\nAware Age Progression approach [18].\nSharper average faces are obtained via the collection ﬂow\nmethod introduced in [23] to align and normalize all the\nimages in one age group. Then illumination normalization\nand subspace alignment technique are employed to handle\nimages with various lighting conditions. Figure 3 illustrates\nthe results obtained in [18].\nC. Reconstructing-based approach\nRather than constructing aging prototypes for each age\ngroup, the reconstructing-based methods focus on construct-\ning the “aging basis” for each age group and model aging\nfaces by the combination of these bases. Dictionary learning\ntechniques are usually employed for this type of approach.\nShu et al. [34] proposed to use the aging coupled dictionaries\n(CDL) to model personalized aging patterns by preserving\npersonalized facial features. The dictionaries are learned us-\ning face pairs from neighboring age groups via a personality-\naware coupled reconstruction loss. Yang et al. [40] repre-\nsented person-speciﬁc and age-speciﬁc factors independently\nusing sparse representation hidden factor analysis (HFA).\nSince only age-speciﬁc gradually changes over time, the\nage factor is transformed to the target age group via sparse\nreconstruction and then combined with the identity factor to\nachieve the aged face.\nIV. DEEP GENERATIVE MODELS FOR FACE AGING\nIn this section, we ﬁrstly provide an overview of the\nstructures and formulations of the common Deep Generative\nModels before going through the age progression techniques\ndeveloped from these structures.\nA. From Linear Models to Deep Structures\nCompared to linear models such as AAMs and 3DMM,\ndeep structures have gained signiﬁcant attention as one of\nthe emerging research topics in both representing higher-\nlevel data features and learning the distribution of observa-\ntions. For example, being designed following the concepts\nfrom Probabilistic Graphical Models (PGM), the RBM-\nbased models organize their non-linear latent variables in\nmultiple connected layers with an energy function such that\neach layer can learn a different factor to represent the data\nvariations. This section introduces the structures, formula-\ntions of several Deep Generative Models including RBM,\nDeep Boltzmann Machines (DBM), Generative Adversarial\nNetworks (GANs).\nFigure 4.\nStructures of (a) RBM, (b) TRBM and (c) DBM.\n1) Restricted Boltzmann Machines (RBM) [15]: are undi-\nrected graphical models consisting two layers of stochastic\nunits, i.e. visible v and hidden units h. This is a simpliﬁed\nversion of Boltzmann Machines where no intra connections\nbetween units in the same layer is created. RBM structure is\na bipartite graph where visible and hidden units are pairwise\nconditionally independent. Given a binary state of v, h, the\nenergy of RBM and the joint distribution of visible and\nhidden units can be computed as\n−E(v, h) = vT Wh + bT v + aT h\nP(v, h; θ) =\n1\nZ(θ) exp{−E(v, h)}\n(1)\nwhere θ = {W, b, a} denotes the parameter set of RBM including\nthe connection weights and the biases of visible and hidden units,\nrespectively. The conditional probabilities RBM structure can be\ncomputed as p(hj = 1|v) = σ(P\ni viwij+aj) and p(vi = 1|h) =\nσ(P\nj hjwij + bi) where σ(·) is the logistic function.\nIn the original RBM, both visible and hidden units are binary.\nTo make it more powerful and be able to deal with real-valued\ndata, an extension of RBM, named Gaussian Restricted Boltzmann\nMachine, is introduced in [19]. In Gaussian RBM, the visible units\nare assumed to have values in [−∞, ∞] and normally distributed\nwith mean bi and variance σ2\ni . Another extension of RBM is\nTemporal Restricted Boltzmann Machines (TRBM) [37] which was\ndesigned to model complex time-series structure. The structure of\nTRBM is shown in Fig. 4 (b). The major difference between the\noriginal RBM and TRBM is the directed connections from both\nvisible and hidden units of previous states to the current states.\nWith these new connections, the short history of their activations\ncan act as “memory” and is able to contribute to the inference step\nof current states of visible units.\n2) Deep Boltzmann Machines (DBM): As an extension of\nRBM with more than one hidden layer, the structure of DBM\ncontains several RBMs organized in layers. Thanks to this structure,\nthe hidden units in higher layer can learn more complicated\ncorrelations of features captured in lower layer. Another interesting\npoint of DBM is that these higher representations can be built\nfrom the training data in an unsupervised fashion. Unlike other\nmodels such as Deep Belief Network [16] or Deep Autoencoders\n[4], all connections between units in two consecutive layers are\nundirected. As a result, each unit receives both bottom-up and top-\ndown information and, therefore, can better propagate uncertainty\nduring the inference process.\nLet {h(1), h(2)} be the set of units in two hidden layers, the\nenergy of the state {v, h(1), h(2)} is given as follows.\n−E(v, h(1), h(2); θ) =v⊤W(1)h(1) + h(1)⊤W(2)h(2)\n(2)\nwhere θ = {W(1), W(2)} are the weights of visible-to-\nhidden and hidden-to-hidden connections. Notice that the\nbias terms for visible and hidden units are ignored in\nEqn. (2) for simplifying the representation. Exploiting the\nadvantages of DBM, Deep Appearance Models (DAM) [9]\nand Robust Deep Appearance Models (RDAM) [27] have\nbeen introduced and proven to be superior to other classical\nmodels such as AAMs in inferencing a representation for\nnew face images under various challenging conditions.\n3) Generative Adversarial Networks (GAN): In order to\navoid the intractable Markov chain sampling during the\ntraining stage of RBM, Goodfellow et al. [14] borrowed\nthe idea from adversarial system to design their Generative\nAdversarial Networks (GAN). The intuition behind this\napproach is to set up a game between generator and discrim-\ninator. On one hand, the discriminator learns to determine\nwhether given data are from the generator or real samples.\nOn the other hand, the generator learns how to fool the\ndiscriminator by its generated samples. This game continues\nas the learning process takes place. The learning process\nwill stop at a point that the discriminator can’t distinguish\nbetween real data and the ones produced by the generator.\nThis is also an indication that the generator has already\nlearned the distribution of input data. Formally, let x be the\ninput data, pg be the distribution learned from generator,\nand pz(z) be the prior distribution of variable z. Then\nGAN is deﬁned by two neural networks representing two\ndifferentiable functions for the generator G(z, θg) : z 7→x\nand discriminator D(x, θd) : x 7→y where y denotes\nthe probability that x comes from the data distribution\nrather than pg; θg and θd are the parameters of the CNNs\nrepresenting G and D, respectively. The training process is\nthen formulated as maximizing the probability D(x) while\nminimizing log (1 −D(G(z))):\nmin\nG max\nD\nV (D, G) =Ex∼pdata(x) [log D(x)]\n+ Ez∼pz(z) [log (1 −D(G(z)))]\n(3)\nIn original GAN, the use of fully connected neural network\nfor its generator makes it very hard to generate high-\nresolution face images. Then numerous extensions of GAN\nfocusing on different aspects of this structure have been\nproposed in literature such as Laplacian pyramid Generative\nAdversarial Networks (LAPGAN) [8], Deep Convolutional\nGenerative Adversarial Networks (DCGAN) [28], Info-GAN\n[7], Wasserstein GAN [3].\nB. Deep Aging Models for Age Progression\nThanks to the power of Deep Learning models in terms\nof non-linear variations modeling, many deep learning based\nage progression approaches have been recently developed\nand achieved considerable results in face age progression.\nTable III summarizes the key features of these deep learning\nbased approaches.\nTRBM-based model: In addition to single face model-\ning, a TRBM based age progression model is introduced in\n[10] to embed the temporal relationship between images in\na face sequence. By taking the advantages of log-likelihood\nobjective function and avoiding the ℓ2 reconstruction error\nduring training, the model is able to efﬁciently capture\nthe non-linear aging process and automatically synthesize\na series of age-progressed faces in various age ranges with\nTable III\nPROPERTIES OF DEEP GENERATIVE MODEL APPROACHES FOR AGE PROGRESSION. DEEP LEARNING (DL), LOG-LIKELIHOOD (LL), INVERSE\nREINFORCEMENT LEARNING (IRL), PROBABILISTIC GRAPHICAL MODELS (PGM), ADVERSARIAL (ADV)\nMethod\nApproach\nArchitecture\nLoss\nFunction\nNon\n-Linearity\nTractable\nModel\nSubject\nDependent\nMultiple\nInput\nsupport\nWang et al. 2016 [39]\nDL\nRNN\nℓ2\n\u0014\n\u0014\n\u0017\n\u0017\nZhang et al. 2017 [41]\nDL\nGAN\nADV + ℓ2\n\u0014\n\u0014\n\u0017\n\u0017\nAntipov et al. 2017 [2]\nDL\nGAN\nADV + ℓ2\n\u0014\n\u0014\n\u0017\n\u0017\nLi et al. 2018 [22]\nDL\nGAN\nADV + ℓ2 + ID + Age\n\u0014\n\u0014\n\u0017\n\u0017\nOurs, 2016 [10]\nDL\nTRBM\nLL\n\u0014\n\u0017\n\u0017\n\u0017\nOurs, 2017 [11]\nDL\nPGM + CNN\nLL\n\u0014\n\u0014\n\u0017\n\u0017\nOurs, 2017 [12]\nDL + IRL\nPGM + CNN\nLL\n\u0014\n\u0014\n\u0014\n\u0014\nFigure 5.\nArchitectures of (A) the TRBM-based model [10] with post-processing steps, and (B) GAN-based Age Progression model [41].\nmore aging details. This approach has presented a carefully\ndesigned architecture with the combination of both RBM\nand TRBM for age variation modeling and age transforma-\ntion embedding. Fig. 5(A) illustrates the aging architecture\nwith TRBM proposed in [10]. In this approach, the long-\nterm aging development is considered as a composition of\nshort-term changes and can be represented as a sequence\nof that subject faces in different age groups. After the\ndecomposition, a set of RBMs is employed to model the age\nvariation of each age group as well as the wrinkles presented\nin the faces of older ages. Then the TRBM based model is\nconstructed to embed the aging transformation between faces\nof consecutive age groups. Particularly, keeping similar form\nof the energy function as original TRBM and RBM , the bias\nterms are deﬁned as\nbt\ni =bi + Bivt−1 +\nX\nl\nPlis<=t\nl\nat\nj =aj + Ajvt−1 +\nX\nl\nQljs<=t\nl\n(4)\nwhere {A, B, P, Q} are the model parameters; and s<=t =\n{st, st−1} denote the reference faces produced by the set\nof learned RBM. With this structure, both linear and non-\nlinear interactions between faces are efﬁciently exploited.\nFinally, some wrinkle enhancement together with geometry\nconstraints are incorporated in post-processing steps for\nmore consistent results. Therefore, plausible synthesized\nresults can be achieved using this technique. A comparison\nin term of synthesis quality between this model and other\nconventional approaches is shown in Fig. 7.\nRecurrent Neural Network-based model: Approaching\nthe age progression in a similar way of decomposition,\ninstead of using TRBM, Wang et al. [39] proposed to use\na Recurrent Neural Network with two-layer gated recurrent\nunit (GRU) to model aging sequence. With the recurrent con-\nnection between the hidden units, the model can efﬁciently\nexploit the information from previous faces as “memory” to\nproduce smoother transition between faces during synthe-\nsizing process. Fig. 6(A) illustrates the architecture of the\nproposed RNN for age progression. In particular, let xt be\nthe input face at young age, this network ﬁrstly encodes\nit into latent representation ht (hidden/memory units) by\nthe bottom GRU and then decodes this representation into\nan older face ˆht of the subject using the top GRU. The\nrelationship between xt and ht can be interpreted as follows.\nzt = σ(Wzhht−1 + Wzxxt + bz)\nrt = σ(Wrhht−1 + Wrxxt + br)\nct = tanh(Wchrt ⊙ht−1 + Wcxxt + bc)\nht = (1 −zt) ⊙ht−1 + zt ⊙ct\n(5)\nSimilar formulations are also employed for the relationship\nbetween ht and ˆht. Then the difference between ˆht and the\nground-truth aged face is computed in a form of ℓ2 loss\nfunction. The system is then trained to obtain the synthesis\ncapability. Finally, in order to generate the wrinkles for the\naged-faces, the prototyping-style approach is adopted for\nwrinkle transferring. Although this approach has produced\nsome improvements comparing to classical approaches, the\nuse of a ﬁxed reconstruction loss function has limited its\nFigure 6.\nStructures of (A) RNN-based model [39], (B) Temporal Non-Volume Preserving (TNVP) approach [11], and (C) Subject-dependent Deep Aging\nPath (SDAP) [12]. While SDAP shares the Mapping function with TNVP, it aims at embedding the aging transformation of the whole aging sequence.\nFigure 7.\nA comparison between age-progressed sequence generated by\nTRBM based model [10] and IAAP approach [18].\nsynthesis ability and usually resulted in blurry faces.\nGAN-based model: Rather than step-by-step synthesis\nas in previous approaches, Antipov et al. [2], Zhang et\nal. [41], and Li et al. [22] turned into another direction\nof age progression, i.e. direct approach, and adopted the\nstructure of GAN in their architectures. Fig. 5(B) illustrates\nthe structure of the Conditional Adversarial Autoencoder\n(CAAE) [41]. From this ﬁgure, one can easily see that the\nthe authors have adopted the GAN structure as presented\nin Section IV-A3 with an additional age label feature in\nthe representation of latent variables. By this way, they\ncan further encode the relationship between subject identity\nrelated high-level features of the input face and its age label.\nAfter training, by simply changing the aging label according\nto the target age, the deep-neural-network generator is able\nto synthesize the aged face at that age. Compared to Eqn.\n(3), the new objective function is adapted as.\nmin\nE,G\nmax\nDz,Dimg λL(x, G(E(x), l)) + γTV (G(E(x), l))\n+ Ez∗∼p(z) [log Dz(z∗)] + Ex∼pdata(x) [log(1 −Dz(E(x)))]\n+ Ex,l∼pdata(x,l) [log Dimg(x, l)]\n+ Ex,l∼pdata(x,l) [log(1 −Dimg(G(E(x), l)))]\nwhere l denotes the vector represented age label; z is the\nlatent feature vector; E is the decoder function, i.e. E(x) =\nz. L(·, ·) and TV (·) are the ℓ2 norm and total variation\nfunctions, respectively. pdata(x) denotes the distribution of\nthe training data. As one can see, the conditional constraint\non the age label is represented in the last two terms of\nthe loss function. Although this model type can avoid the\nrequirement of longitudinal age database during training, it\nis not easy to be converged due to the step of maintaining a\ngood balance between generator and discriminator which is\nhard to achieve. Moreover, similar to RNN-based approach,\nGAN-based models also incorporate the ℓ2-norm in their\nobjective functions. Therefore, their synthesized results are\nlimited in terms of the image sharpness.\nTemporal Non-Volume Preserving transformation:\nRecently, addressing a limitation of intractable learning\nprocess of TRBM based model as well as the image quality\nof RNN-based and GAN-based approaches, the Temporal\nNon-Volume Preserving (TNVP) approach is introduced in\n[11] for embedding the feature transformations between\nfaces in consecutive stages while keeping a tractable density\nfunction, exact inference and evaluation. Unlike previous\napproaches which incorporate only PGM or CNN structures,\nthis proposed model enjoys the advantages of both archi-\ntectures to improve its image synthesis quality and highly\nnon-linear feature generation. The idea of this model start\nfrom a PGM with relationships between variables in image\nand latent domains (see Fig. 6(B)) given by\nzt−1 = F1(xt−1; θ1)\nzt = H(zt−1, xt; θ2, θ3)\n= G(zt−1; θ3) + F2(xt; θ2)\n(6)\nwhere F1, F2 denote the bijection functions mapping xt−1\nand xt to their latent variables zt−1, zt, respectively. G is the\nFigure 8. A comparison between Deep Learning Approaches, i.e. TNVP [11], TRBM [10], against conventional approaches including IAAP [18], Exemplar\nbased (EAP) [33], and Craniofacial Growth (CGAP) [29] models.\nfunction embedding the aging transformation between latent\nvariables. Then the probability density function is derived by.\npXt(xt|xt−1; θ) = pXt(xt|zt−1; θ)\n= pZt(zt|zt−1; θ)\n\f\f\f\f\n∂H(zt−1, xt; θ)\n∂xt\n\f\f\f\f\n= pZt(zt|zt−1; θ)\n\f\f\f\f\n∂F2(xt; θ)\n∂xt\n\f\f\f\f\n(7)\nwhere pXt(xt|xt−1; θ) and pZt(zt|zt−1; θ) denote the con-\nditional distribution of xt and zt, respectively. By a speciﬁc\ndesign of mapping functions F1, F2, the two terms on the\nright-hand-side of Eqn. (7) can be computed exactly and ef-\nfectively. As a result, the authors can form a deep CNN net-\nwork optimized under the concepts of PGM. While keeping\nthe tractable log-likelihood density estimation in its objective\nfunction, the model turns age progression architectures into\nnew direction where the CNN network can avoid using\na ﬁx reconstruction loss function and obtain high-quality\nsynthesized faces. Fig. 8 illustrates the synthesized results\nachieved by TNVP in comparison with other approaches.\nSubject-dependent Deep Aging Path (SDAP) model:\nInspiring from the advantages of TVNP, the Inverse Re-\ninforcement (IRL) Learning is also taken into account\nin the structure of Subject-dependent Deep Aging Path\n(SDAP) model [12]. Under the hypothesis that each subject\nshould have his/her own facial development, Duong et al.\n[12] proposed to use an additional aging controller in the\nstructure of TNVP. Then rather than only embedding the\naging transformation between pairwise relationship between\nconsecutive age groups, the SDAP structure learns from\nthe aging transformation of the whole face sequence for\nbetter long-term aging synthesis. This goal is achieved via a\nSubject-Dependent Aging Policy Network which guarantees\nto provide an appropriate planning aging path for the age\ncontroller corresponding to the subject’s features. The most\ninteresting point of SDAP is that this is one of the pioneers\nincorporating IRL framework into age progression task. In\nthis approach, let ζi = {x1\ni , a1\ni , . . . , xT\ni } be the age sequence\nof i-th subject where {x1\ni , . . . , xT\ni } are the face sequence\n10 -5\n10 -4\n10 -3\n10 -2\n10 -1\n10 0\nFalse Acceptance Rate\n0\n0.2\n0.4\n0.6\n0.8\n1\nTrue Acceptance Rate\nSF + SDAP\nSF + TNVP\nSF\nDeepsense_small\n3DiVi-tdvm6\nBarebones_FR-cnn\nNTechLAB_small\nFigure 9.\nAn example of age invariant face recognition by using age\nprogression models, i.e. TVNP [11] and SDAP [12]. By incorporated their\nsynthesized results, the accuracy of face recognition (FR) system can be\nimproved signiﬁcantly. Note that the results of other FR methods are\nprovided in Megaface website [17].\nrepresenting the facial development of i-th subject and aj\ni\ndenote the variables control the aging amount added to xj\ni\nto become xj+1\ni\n. The probability of ζi can be formulated\nvia an energy function EΓ(ζi) by\nP(ζi) = 1\nZ exp(−EΓ(ζi))\n(8)\nwhere Z is the partition function. Notice that the formulation\nof Eqn. (8) is very similar to joint distribution between\nvariables of RBM as in Eqn. (1). Then the goal is to learn\na Subject-Dependent Aging Policy Network that can predict\naj\ni for each xj\ni during synthesized process. The objective\nfunction is deﬁned as.\nΓ∗= arg max\nΓ\nL(ζ; Γ) = 1\nM log\nY\nζi∈ζ\nP(ζi)\n(9)\nFinally, a speciﬁc design of IRL framework is proposed\nto learn the Policy Network. From the experimental results,\nSDAP has shown its potential to outperform TNVP and other\napproaches on synthesis results and cross-age veriﬁcation\naccuracy. As shown in Fig. 9, SDAP can help to signiﬁcantly\nimprove the accuracy for face recognition system.\nV. CONCLUSION\nIn this paper, we have reviewed the main structures\nof Deep Generative Models for Age Progression task.\nCompared to other classical approaches, Deep Learning\nhas shown its potential either in learning the highly non-\nlinear age variation or aging transformation embedding. As\na result, not only do their synthesized faces improve in\nthe image quality but also help to signiﬁcantly boost the\nrecognition accuracy for cross-age face veriﬁcation system.\nSeveral common aging databases that support the facial\nmodeling and aging embedding process are also discussed.\nREFERENCES\n[1] FG-NET Aging Database. http://www.fgnet.rsunit.com.\n[2] G. Antipov, M. Baccouche, and J.-L. Dugelay. Face aging\nwith conditional generative adversarial networks.\narXiv\npreprint arXiv:1702.01983, 2017.\n[3] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein gan.\narXiv preprint arXiv:1701.07875, 2017.\n[4] Y. Bengio. Learning deep architectures for ai. Foundations\nand trends R⃝in Machine Learning, 2(1):1–127, 2009.\n[5] D. M. Burt and D. I. Perrett.\nPerception of age in adult\ncaucasian male faces: Computer graphic manipulation of\nshape and colour information. Proc R Soc Lond B Biol Sci,\n259(1355):137–143, 1995.\n[6] B.-C. Chen, C.-S. Chen, and W. H. Hsu. Cross-age reference\ncoding for age-invariant face recognition and retrieval.\nIn\nECCV, 2014.\n[7] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever,\nand P. Abbeel. Infogan: Interpretable representation learning\nby information maximizing generative adversarial nets.\nIn\nNIPS, pages 2172–2180, 2016.\n[8] E. L. Denton, S. Chintala, R. Fergus, et al. Deep genera-\ntive image models using a laplacian pyramid of adversarial\nnetworks. In NIPS, pages 1486–1494, 2015.\n[9] C. N. Duong, K. Luu, K. G. Quach, and T. D. Bui. Beyond\nprincipal components: Deep boltzmann machines for face\nmodeling. In CVPR, pages 4786–4794. IEEE, 2015.\n[10] C. N. Duong, K. Luu, K. G. Quach, and T. D. Bui. Longitu-\ndinal face modeling via temporal deep restricted boltzmann\nmachines. In CVPR, 2016.\n[11] C. N. Duong, K. G. Quach, K. Luu, N. Le, and M. Savvides.\nTemporal non-volume preserving approach to facial age-\nprogression and age-invariant face recognition.\nIn ICCV,\n2017.\n[12] C. N. Duong, K. G. Quach, K. Luu, T. Le, and M. Sav-\nvides. Learning from longitudinal face demonstration-where\ntractable deep modeling meets inverse reinforcement learning.\narXiv preprint arXiv:1711.10520, 2017.\n[13] X. Geng, Z.-H. Zhou, and K. Smith-Miles. Automatic age es-\ntimation based on facial aging patterns. PAMI, 29(12):2234–\n2240, 2007.\n[14] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-\nFarley, S. Ozair, A. Courville, and Y. Bengio.\nGenerative\nadversarial nets. In NIPS, pages 2672–2680, 2014.\n[15] G. E. Hinton. Training products of experts by minimizing\ncontrastive divergence. Neural computation, 2002.\n[16] G. E. Hinton and R. R. Salakhutdinov.\nReducing the\ndimensionality of data with neural networks.\nScience,\n313(5786):504–507, 2006.\n[17] I. Kemelmacher-Shlizerman, S. M. Seitz, D. Miller, and\nE. Brossard. The megaface benchmark: 1 million faces for\nrecognition at scale. In CVPR, 2016.\n[18] I. Kemelmacher-Shlizerman, S. Suwajanakorn, and S. M.\nSeitz. Illumination-aware age progression. In CVPR, pages\n3334–3341. IEEE, 2014.\n[19] A. Krizhevsky and G. Hinton. Learning multiple layers of\nfeatures from tiny images. 2009.\n[20] A. Lanitis, C. J. Taylor, and T. F. Cootes. Toward automatic\nsimulation of aging effects on face images. PAMI, 24(4):442–\n455, 2002.\n[21] G. Levi and T. Hassner. Age and gender classiﬁcation using\nconvolutional neural networks. In CVPRW, 2015.\n[22] P. Li, Y. Hu, Q. Li, R. He, and Z. Sun. Global and local\nconsistent age generative adversarial networks. arXiv preprint\narXiv:1801.08390, 2018.\n[23] C. Liu, J. Yuen, and A. Torralba. Sift ﬂow: Dense correspon-\ndence across scenes and its applications. TPAMI, 33(5):978–\n994, 2011.\n[24] K. Luu, C. Suen, T. Bui, and J. K. Ricanek. Automatic child-\nface age-progression based on heritability factors of familial\nfaces. In BIdS, pages 1–6. IEEE, 2009.\n[25] S. Moschoglou, A. Papaioannou, C. Sagonas, J. Deng, I. Kot-\nsia, and S. Zafeiriou.\nAgedb: the ﬁrst manually collected,\nin-the-wild age database. In CVPR-W, Hawaii, 2017.\n[26] E. Patterson, K. Ricanek, M. Albert, and E. Boone.\nAu-\ntomatic representation of adult aging in facial images.\nIn\nProc. IASTED Intl Conf. Visualization, Imaging, and Image\nProcessing, pages 171–176, 2006.\n[27] K. G. Quach, C. N. Duong, K. Luu, and T. D. Bui. Robust\ndeep appearance models. In ICPR, pages 390–395, 2016.\n[28] A. Radford, L. Metz, and S. Chintala. Unsupervised represen-\ntation learning with deep convolutional generative adversarial\nnetworks. arXiv preprint arXiv:1511.06434, 2015.\n[29] N. Ramanathan and R. Chellappa. Modeling age progression\nin young faces. In CVPR, 2006.\n[30] K. Ricanek Jr and T. Tesafaye. Morph: A longitudinal image\ndatabase of normal adult age-progression.\nIn FGR 2006.,\npages 341–345. IEEE, 2006.\n[31] R. Rothe, R. Timofte, and L. V. Gool.\nDeep expectation\nof real and apparent age from a single image without facial\nlandmarks. IJCV, 2016.\n[32] D. Rowland, D. Perrett, et al. Manipulating facial appearance\nthrough shape and color. CG&A, IEEE, 15(5):70–76, 1995.\n[33] C.-T. Shen, W.-H. Lu, S.-W. Shih, and H.-Y. M. Liao.\nExemplar-based age progression prediction in children faces.\nIn ISM, pages 123–128. IEEE, 2011.\n[34] X. Shu, J. Tang, H. Lai, L. Liu, and S. Yan. Personalized age\nprogression with aging dictionary. In ICCV, December 2015.\n[35] J. Suo, X. Chen, S. Shan, W. Gao, and Q. Dai. A concate-\nnational graph evolution aging model. PAMI, 34(11):2083–\n2096, 2012.\n[36] J. Suo, S.-C. Zhu, S. Shan, and X. Chen. A compositional\nand dynamic model for face aging. PAMI, 32(3), 2010.\n[37] I. Sutskever and G. E. Hinton. Learning multilevel distributed\nrepresentations for high-dimensional sequences. In AISTATS,\npages 548–555, 2007.\n[38] M.-H. Tsai, Y.-K. Liao, and I.-C. Lin. Human face aging with\nguided prediction and detail synthesis. Multimedia tools and\napplications, 72(1):801–824, 2014.\n[39] W. Wang, Z. Cui, Y. Yan, J. Feng, S. Yan, X. Shu, and\nN. Sebe. Recurrent face aging. In CVPR, 2016.\n[40] H. Yang, D. Huang, Y. Wang, H. Wang, and Y. Tang. Face\naging effect simulation using hidden factor analysis joint\nsparse representation. TIP, 25(6):2493–2507, 2016.\n[41] Z. Zhang, Y. Song, and H. Qi. Age progression/regression by\nconditional adversarial autoencoder. In CVPR, July 2017.\n",
  "categories": [
    "cs.CV"
  ],
  "published": "2018-02-23",
  "updated": "2018-02-23"
}