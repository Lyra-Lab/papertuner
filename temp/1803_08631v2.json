{
  "id": "http://arxiv.org/abs/1803.08631v2",
  "title": "SEGEN: Sample-Ensemble Genetic Evolutional Network Model",
  "authors": [
    "Jiawei Zhang",
    "Limeng Cui",
    "Fisher B. Gouza"
  ],
  "abstract": "Deep learning, a rebranding of deep neural network research works, has\nachieved a remarkable success in recent years. With multiple hidden layers,\ndeep learning models aim at computing the hierarchical feature representations\nof the observational data. Meanwhile, due to its severe disadvantages in data\nconsumption, computational resources, parameter tuning costs and the lack of\nresult explainability, deep learning has also suffered from lots of criticism.\nIn this paper, we will introduce a new representation learning model, namely\n\"Sample-Ensemble Genetic Evolutionary Network\" (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building one single\ndeep model, based on a set of sampled sub-instances, SEGEN adopts a\ngenetic-evolutionary learning strategy to build a group of unit models\ngenerations by generations. The unit models incorporated in SEGEN can be either\ntraditional machine learning models or the recent deep learning models with a\nmuch \"narrower\" and \"shallower\" architecture. The learning results of each\ninstance at the final generation will be effectively combined from each unit\nmodel via diffusive propagation and ensemble learning strategies. From the\ncomputational perspective, SEGEN requires far less data, fewer computational\nresources and parameter tuning efforts, but has sound theoretic\ninterpretability of the learning process and results. Extensive experiments\nhave been done on several different real-world benchmark datasets, and the\nexperimental results obtained by SEGEN have demonstrated its advantages over\nthe state-of-the-art representation learning models.",
  "text": "seGEN: Sample-Ensemble Genetic Evolutionary\nNetwork Model\nJiawei Zhang1, Limeng Cui2, Fisher B. Gouza1\n1IFM Lab, Department of Computer Science, Florida State University, FL, USA\n2University of Chinese Academy of Sciences, Beijing, China\njiawei@ifmlab.org, lmcui932@163.com, ﬁsherbgouza@gmail.com\nAbstract—Deep learning, a rebranding of deep neural network\nresearch works, has achieved a remarkable success in recent\nyears. With multiple hidden layers, deep learning models aim\nat computing the hierarchical feature representations of the\nobservational data. Meanwhile, due to its severe disadvantages\nin data consumption, computational resources, parameter tuning\ncosts and the lack of result explainability, deep learning has also\nsuffered from lots of criticism. In this paper, we will introduce\na new representation learning model, namely “Sample-Ensemble\nGenetic Evolutionary Network” (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building\none single deep model, based on a set of sampled sub-instances,\nSEGEN adopts a genetic-evolutionary learning strategy to build\na group of unit models generations by generations. The unit\nmodels incorporated in SEGEN can be either traditional machine\nlearning models or the recent deep learning models with a much\n“narrower” and “shallower” architecture. The learning results of\neach instance at the ﬁnal generation will be effectively combined\nfrom each unit model via diffusive propagation and ensemble\nlearning strategies. From the computational perspective, SEGEN\nrequires far less data, fewer computational resources and param-\neter tuning efforts, but has sound theoretic interpretability of the\nlearning process and results. Extensive experiments have been\ndone on several different real-world benchmark datasets, and\nthe experimental results obtained by SEGEN have demonstrated\nits advantages over the state-of-the-art representation learning\nmodels.\nIndex Terms—Genetic Evolutionary Network; Deep Learning;\nGenetic Algorithm; Ensemble Learning; Representation Learn-\ning\nI. INTRODUCTION\nIn recent years, deep learning, a rebranding of deep neural\nnetwork research works, has achieved a remarkable success.\nThe essence of deep learning is to compute the hierarchical\nfeature representations of the observational data [9], [16]. With\nmultiple hidden layers, the deep learning models have the\ncapacity to capture very good projections from the input data\nspace to the objective output space, whose outstanding per-\nformance has been widely illustrated in various applications,\nincluding speech and audio processing [8], [12], language\nmodeling and processing [1], [20], information retrieval [11],\n[23], objective recognition and computer vision [16], as well\nas multimodal and multi-task learning [28], [29]. By this\ncontext so far, various kinds of deep learning models have\nbeen proposed already, including deep belief network [13],\ndeep Boltzmann machine [23], deep neural network [14], [15]\nand deep autoencoder model [25].\nMeanwhile, deep learning models also suffer from several\nserious criticism due to their several severe disadvantages\n[30]. Generally, learning and training deep learning models\nusually demands (1) a large amount of training data, (2) large\nand powerful computational facilities, (3) heavy parameter\ntuning costs, but lacks (4) theoretic explanation of the learning\nprocess and results. These disadvantages greatly hinder the\napplication of deep learning models in many areas which can-\nnot meet the requirements or requests a clear interpretability\nof the learning performance. Due to these reasons, by this\ncontext so far, deep learning research and application works\nare mostly carried out within/via the collaboration with several\nbig technical companies, but the models proposed by them\n(involving hundreds of hidden layers, billions of parameters,\nand using a large cluster with thousands of server nodes [6])\ncan hardly be applied in other real-world applications.\nIn this paper, we propose a brand new model, namely\nSEGEN (Sample-Ensemble Genetic Evolutionary Network),\nwhich can work as an alternative approach to the deep learning\nmodels. Instead of building one single model with a deep\narchitecture, SEGEN adopts a genetic-evolutionary learning\nstrategy to train a group of unit models generations by\ngenerations. Here, the unit models can be either traditional\nmachine learning models or deep learning models with a much\n“narrower” and “shallower” structure. Each unit model will\nbe trained with a batch of training instances sampled form\nthe dataset. By selecting the good unit models from each\ngeneration (according to their performance on a validation set),\nSEGEN will evolve itself and create the next generation of\nunit modes with probabilistic genetic crossover and mutation,\nwhere the selection and crossover probabilities are highly\ndependent on their performance ﬁtness evaluation. Finally,\nthe learning results of the data instances will be effectively\ncombined from each unit model via diffusive propagation\nand ensemble learning strategies. These terms and techniques\nmentioned here will be explained in great detail in Section III.\nCompared with the existing deep learning models, SEGEN\nhave several great advantages, and we will illustrate them from\nboth the bionics perspective and the computational perspective\nas follows.\nFrom the bionics perspective, SEGEN effectively models\nthe evolution of creatures from generations to generations,\nwhere the creatures suitable for the environment will have a\nlarger chance to survive and generate the offsprings. Mean-\narXiv:1803.08631v2  [cs.NE]  5 Jun 2018\nwhile, the offsprings inheriting good genes from its parents\nwill be likely to adapt to the environment as well. In the\nSEGEN model, each unit network model in generations can\nbe treated as an independent creature, which will receive a\ndifferent subsets of training instances and learn its own model\nvariables. For the unit models suitable for the environment\n(i.e., achieving a good performance on a validation set), they\nwill have a larger chance to generate their child models. The\nparent model achieving better performance will also have a\ngreater chance to pass their variables to the child model.\nFrom the computational perspective, SEGEN requires far\nless data and resources, and also has a sound theoretic\nexplanation of the learning process and results. The unit\nmodels in each generation of SEGEN are of a much simpler\narchitecture, learning of which can be accomplished with\nmuch less training data, less computational resources and\nless hyper-parameter tuning efforts. In addition, the training\ndataset pool, model hyper-parameters are shared by the unit\nmodels, and the increase of generation size (i.e., unit model\nnumber in each generation) or generation number (i.e., how\nmany generation rounds will be needed) will not increase the\nlearning resources consumption. The relatively “narrower” and\n“shallower” structure of unit models will also signiﬁcantly\nenhance the interpretability of the unit models training process\nas well as the learning results, especially if the unit models\nare the traditional non-deep learning models. Furthermore, the\nsound theoretical foundations of genetic algorithm and ensem-\nble learning will also help explain the information inheritance\nthrough generations and result ensemble in SEGEN.\nIn this paper, we will use network embedding problem [26],\n[3], [21] (applying autoencoder as the unit model) as an exam-\nple to illustrate the SEGEN model. Meanwhile, applications of\nSEGEN on other data categories (e.g., images and raw feature\ninputs) with CNN and MLP as the unit model will also be\nprovided in Section IV-D. The following parts of this paper\nare organized as follows. The problem formulation is provided\nin Section II. Model SEGEN will be introduced in Section III,\nwhose performance will be evaluated in Section IV. Finally,\nSection V introduces the related works and we conclude this\npaper in Section VI.\nII. PROBLEM FORMULATION\nIn this section, we will provide the deﬁnitions of several\nimportant terminologies, based on which we will deﬁne the\nnetwork representation learning problem.\nA. Terminology Deﬁnition\nThe SEGEN model will be illustrated based on the network\nrepresentation learning problem in this paper, where the input\nis usually a large-sized network structured dataset.\nDEFINITION 1: (Network Data): Formally, a network struc-\ntured dataset can be represented as a graph G = (V, E), where\nV denotes the node set and E contains the set of links among\nthe nodes.\nIn the real-world applications, lots of data can be modeled\nas networks. For instance, online social media can be repre-\nsented as a network involving users as the nodes and social\nconnections as the links; e-commerce website can be denoted\nas a network with customer and products as the nodes, and\npurchase relation as the links; academic bibliographical data\ncan be modeled as a network containing papers, authors as the\nnodes, and write/cite relationships as the links. Given a large-\nsized input network data G = (V, E), a group of sub-networks\ncan be extracted from it, which can be formally represented\nas a sub-network set of G.\nDEFINITION 2: (Sub-network Set): Based on a certain\nsampling strategy, we can represent the set of sampled sub-\nnetworks from network G as set G = {g1, g2, · · · , gm} of size\nm. Here, gi ∈G denotes a sub-network of G, and it can be\nrepresented as gi = (Vgi, Egi), where Vgi ⊆V, Egi ⊆E and\nG ̸= gi.\nIn Section III, we will introduce several different sampling\nstrategies, which will be applied to obtained several different\nsub-network pools for unit model building and validation.\nB. Problem Formulation\nProblem Statement: Based on the input network data G =\n(V, E), the network representation learning problem aims at\nlearning a mapping f\n: V →Rd to project each node\nfrom the network to a low-dimensional feature space. There\nusually exist some requirements on mapping f(·), which\nshould preserve the original network structure, i.e., closer\nnodes should have close representations; while disconnected\nnodes have different representations on the other hand.\nIII. PROPOSED METHODS\nIn this section, we will introduce the proposed frame-\nwork SEGEN in detail. As shown in Figure 1, the proposed\nframework involves three steps: (1) network sampling, (2)\nsub-network representation learning, and (3) result ensemble.\nGiven the large-scale input network data, framework SEGEN\nwill sample a set of sub-networks, which will be used as\nthe input to the genetic evolutionary network model for\nrepresentation learning. Based on the learned results for the\nsub-networks, framework SEGEN will combine them together\nto obtain the ﬁnal output result. In the following parts, we will\nintroduce these three steps in great detail respectively.\nA. Network Sampling\nIn framework SEGEN, instead of handling the input large-\nscale network data directly, we propose to sample a subset (of\nset size s) of small-sized sub-networks (of a pre-speciﬁed sub-\nnetwork size k) instead and learn the representation feature\nvectors of nodes based on the sub-networks. To ensure the\nlearned representations can effectively represent the char-\nacteristics of nodes, we need to ensure the sampled sub-\nnetworks share similar properties as the original large-sized\ninput network. As shown in Figure 1, 5 different types of\nnetwork sampling strategies (indicated in 5 different colors)\nare adopted in this paper, and each strategy will lead to a\ngroup of small-sized sub-networks, which can capture both\nthe local and global structures of the original network.\n2\n…\n2nd generation\n…\nKth generation\n…\n1st generation\n…\n…\n…\n…\n…\n…\nInput  \nNetwork\nGenetic Evolutionary Network Model\nSampled  \nSub-Networks\nLearning Results\nOutput  \nResult\n…\nStep 1: Network Sampling\nStep 2: Sub-Network Representation Learning\nStep 3: Result Ensemble\nFig. 1. The SEGEN Framework.\n1) BFS based Network Sampling: Based on the input\nnetwork G = (V, E), Breadth-First-Search (BFS) based net-\nwork sampling strategy randomly picks a seed node from\nset V and performs BFS to expend to the unreached nodes.\nFormally, the neighbors of node v ∈V can be denoted as\nset Γ(v; 1) = {u|u ∈V ∧(u, v) ∈E}. After picking v,\nthe sampling strategy will continue to randomly add k −1\nnodes from set Γ(v; 1), if |Γ(v; 1)| ≥k −1; otherwise, the\nsampling strategy will go to the 2-hop neighbors of v (i.e.,\nΓ(v; 2) = {u|∃w ∈V, (u, w) ∈E ∧(w, v) ∈E ∧(u, v) /∈E})\nand so forth until the remaining k −1 nodes are selected. In\nthe case when the size of connected component that v involves\nin is smaller than k, the strategy will further pick another seed\nnode to do BFS from that node to ﬁnish the sampling of k\nnodes. These sampled k nodes together with the edges among\nthem will form a sampled sub-network g, and all the p sampled\nsub-networks will form the sub-network pool GBFS (parameter\np denotes the pool size).\n2) DFS\nbased\nNetwork\nSampling:\nDepth-First-Search\n(DFS) based network sampling strategy works in a very similar\nway as the BFS based strategy, but it adopts DFS to expand to\nthe unreached nodes instead. Similar to the BFS method, in the\ncase when the node connected component has size less than\nk, DFS sampling strategy will also continue to pick another\nnode as the seed node to continue the sampling process. The\nsampled nodes together with the links among them will form\nthe sub-networks to be involved in the ﬁnal sampled sub-\nnetwork pool GDFS (of size p).\nA remark to be added here: the sub-networks sampled\nvia BFS can mainly capture the local network structure of\nnodes (i.e., the neighborhood), and in many of the cases\nthey are star structured diagrams with the picked seed node\nat the center surrounded by its neighbors. Meanwhile, the\nsub-networks sampled with DFS are slightly different, which\ninvolve “deeper” network connection patterns. In the extreme\ncase, the sub-networks sampled via DFS can be a path from\nthe seed nodes to a node which is (k −1)-hop away.\n3) HS based Network Sampling: To balance between those\nextreme cases aforementioned, we introduce a Hybrid-Search\n(HS) based network sampling strategy by combining BFS and\nDFS. HS randomly picks seed nodes from the network, and\nreaches other nodes based on either BFS or DFS strategies\nwith probabilities p and (1 −p) respectively. For instance,\nin the sampling process, HS ﬁrst picks node v ∈V as the\nseed node, and samples a random node u ∈Γ(v; 1). To\ndetermine the next node to sample, HS will “toss a coin” with\np probability to sample nodes from Γ(v; 1) \\ {u} (i.e., BFS)\nand 1−p probability to sample nodes from Γ(u; 1)\\{v} (i.e.,\nDFS). Such a process continues until k nodes are selected,\nand the sampled nodes together with the links among them\nwill form the sub-network. We can represent all the sampled\nsub-networks by the HS based network sampling strategy as\npool GHS.\nThese three network sampling strategies are mainly based\non the connections among the nodes, and nodes in the sampled\nsub-networks are mostly connected. However, in the real-\nworld networks, the connections among nodes are usually very\nsparse, and most of the node pairs are not connected. In the\nfollowing part, we will introduce two other sampling strategies\nto handle such a case.\n4) Biased Node Sampling:\nInstead of sampling sub-\nnetworks via the connections among them, the node sampling\nstrategy picks the nodes at random from the network. Based\non node sampling, the ﬁnal sampled sub-network may not\nnecessarily be connected and can involve many isolated nodes.\nFurthermore, uniform sampling of nodes will also deteriorate\nthe network properties, since it treats all the nodes equally and\nfails to consider their differences. In this paper, we propose\nto adopt the biased node sampling strategy, where the nodes\nwith more connections (i.e., larger degrees) will have larger\nprobabilities to be sampled. Based on the connections among\nthe nodes, we can represent the degree of node v ∈V as\n3\nd(u) = |Γ(u; 1)|, and the probabilities for u to be sampled\ncan be denoted as p(u) =\nd(u)\n2|E| . Instead of focusing on the\nlocal structures of the network, the sub-networks sampled with\nthe biased node sampling strategy can capture more “global”\nstructures of the input network. Formally, all the sub-networks\nsampled via this strategy can be represented as pool GNS.\n5) Biased Edge Sampling: Another “global” sub-network\nsampling strategy is the edge based sampling strategy, which\nsamples the edges instead of nodes. Here, uniform sampling\nof edges will be reduced to biased node selection, where high-\ndegree nodes will have a larger probability to be involved in\nthe sub-network. In this paper, we propose to adopt a biased\nedge sampling strategy instead. For each edge (u, v) ∈E,\nthe probability for it to be sampled is actually proportional to\nd(u)+d(v)\n2|E|\n. The sampled edges together with the incident nodes\nwill form a sub-network, and all the sampled sub-networks\nwith biased edge sampling strategy can be denoted as pool\nGES.\nThese two network sampling strategies can select the sub-\nstructures of the input network from a global perspective,\nwhich can effectively capture the sparsity property of the input\nnetwork. In the experiments to be introduced in Section IV,\nwe will evaluate these different sampling strategies in detail.\nB. GEN Model\nIn this part, we will focus on introducing the Genetic\nEvolutionary Network (GEN) model, which accepts each sub-\nnetwork pool as the input and learns the representation feature\nvectors of nodes as the output. We will use G to represent the\nsampled pool set, which can be GBFS, GDFS, GHS, GNS or GES\nrespectively.\n1) Unit Model Population Initialization:\nIn the GEN\nmodel, there exist multiple generations of unit models, where\nthe earlier generations will evolve and generate the later\ngenerations. Each generation will also involve a group of unit\nmodels, namely the unit model population. Formally, the initial\ngeneration of the unit models (i.e., the 1st generation) can\nbe represented as set M1 = {M 1\n1 , M 1\n2 , · · · , M 1\nm} (of size\nm), where M 1\ni is a base unit model to be introduced in the\nfollowing subsection. Formally, the variables involved in each\nunit model, e.g., M 1\ni , can be denoted as vector θ1\ni , which\ncovers the weight and bias terms in the model (which will be\ntreated as the model genes in the evolution to be introduced\nlater). In the initialization step, the variables of each unit model\nare assigned with a random value generated from the standard\nnormal distribution.\n2) Unit Model Description: In this paper, we will take\nnetwork representation learning as an example, and propose\nto adopt the correlated autoencoder as the base model. We\nwant to clarify again that the SEGEN framework is a general\nframework, and it works well for different types of data as\nwell as different base models. For some other tasks or other\nlearning settings, many other existing models, e.g., CNN and\nMLP to be introduced in Section IV-D, can be adopted as the\nbase model as well.\n…\n…\n…\n…\n…\n…\n…\nxi\nˆxi\nzi\ny1\ni\nˆy1\ni\n…\n…\nFig. 2. Traditional Autoencoder Model.\nAutoencoder is an unsupervised neural network model,\nwhich projects data instances from the original feature space\nto a lower-dimensional feature space via a series of non-linear\nmappings. Autoencoder model involves two steps: encoder and\ndecoder. The encoder part projects the original feature vectors\nto the objective feature space, while the decoder step recovers\nthe latent feature representations to a reconstructed feature\nspace.\nBased on each sampled sub-network g ∈T , where g =\n(Vg, Eg), we can represent the sub-network structure as an\nadjacency matrix Ag = {0, 1}|Vg|×|Vg|, where Ag(i, j) = 1\niff (vi, vj) ∈Eg. Formally, for each node vi ∈Vg, we can\nrepresent its raw feature as xi = Ag(i, :). Let y1\ni , y2\ni , · · · , yo\ni\nbe the corresponding latent feature representation of xi at\nhidden layers 1, 2, · · · , o in the encoder step. The encoding\nresult in the objective feature space can be denoted as zi ∈Rd\nof dimension d. In the decoder step, the input will be the\nlatent feature vector zi, and the ﬁnal output will be the\nreconstructed vector ˆxi (of the same dimension as xi). The\nlatent feature vectors at each hidden layers can be represented\nas ˆyo\ni , ˆyo−1\ni\n, · · · , ˆy1\ni . As shown in the architecture in Figure 2,\nthe relationships among these variables can be represented\nwith the following equations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEncoder:\ny1\ni = σ(W1xi + b1),\nyk\ni = σ(Wkyk−1\ni\n+ bk),\n∀k ∈{2, · · · , o},\nzi = σ(Wo+1yo\ni + bo+1).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecoder:\nˆyo\ni = σ( ˆ\nWo+1zi + ˆbo+1),\nˆyk−1\ni\n= σ( ˆ\nWkˆyk\ni + ˆbk),\n∀k ∈{2, · · · , o},\nˆxi = σ( ˆ\nW1ˆy1\ni + ˆb1).\nThe objective of traditional autoencoder model is to mini-\nmize the loss between the original feature vector xi and the\nreconstructed feature vector ˆxi of data instances. Meanwhile,\nfor the network representation learning task, the learning task\nof nodes in the sub-networks are not independent but highly\ncorrelated. For the connected nodes, they should have closer\nrepresentation feature vectors in the latent feature space; while\nfor those which are isolated, their latent representation feature\nvectors should be far away instead. What’s more, since the\ninput feature vectors are extremely sparse (lots of the entries\nare 0s), simply feeding them to the model may lead to some\ntrivial solutions, like 0 vector for both zi and the decoded\nvector ˆxi. Therefore, we propose to extend the Autoencoder\n4\nmodel to the correlated scenario for networks, and deﬁne the\nobjective of the correlated autoencoder model as follows:\nLe(g) =\nX\nvi∈Vg\n∥(xi −ˆxi) ⊙bi∥2\n2 + α\nX\nvi,vj∈Vg,vi̸=vj\nsi,j ∥zi −zj∥2\n2\n+ β ·\no\nX\ni=1\n\u0012\r\rWi\r\r2\nF +\n\r\r\r ˆ\nWi\r\r\r\n2\nF\n\u0013\n,\nwhere si,j\n=\n(\n+1,\nif Ag(i, j) = 1,\n−1,\nif Ag(i, j) = 0. and α, β are the\nweights of the correlation and regularization terms respec-\ntively. Entries in weight vector bi have value 1 except the\nentries corresponding to non-zero element in xi, which will\nbe assigned with value γ (γ > 1) to preserve these non-zero\nentries in the reconstructed vector ˆxi.\n3) Generation Model Learning Setting: Instead of ﬁtting\neach unit model with all the sub-networks in the pool G, in\nGEN, a set of sub-network training batches T1, T2, · · · , Tm\nwill be sampled for each unit model respectively in the\nlearning process, where |Ti| = b, ∀i ∈{1, 2, · · · , m} are of\nthe pre-deﬁned batch size b. These batches may share common\nsub-networks as well, i.e., Ti ∩Tj may not necessary be ∅. In\nthe GEN model, the unit models learning process for each\ngeneration involves two steps: (1) generating the batches Ti\nfrom the pool set G for each unit model M 1\ni ∈M1, and (2)\nlearning the variables of the unit model M 1\ni based on sub-\nnetworks in batch Ti. Considering that the unit models have a\nmuch smaller number of hidden layers, the learning time cost\nof each unit model will be much less than the deeper models\non larger-sized networks. In Section IV, we will provide a\nmore detailed analysis about the running time cost and space\ncost of SEGEN.\n4) Unit Model Fitness Evaluation and Selection: The unit\nmodels in the generation set M1 can have different perfor-\nmance, due to (1) different initial variable values, and (2)\ndifferent training batches in the learning process. In framework\nSEGEN, instead of applying “deep” models with multiple\nhidden layers, we propose to “deepen” the models in another\nway: “evolve the unit model into ‘deeper’ generations”. A\ngenetic algorithm style method is adopted here for evolving the\nunit models, in which the well-trained unit models will have a\nhigher chance to survive and evolve to the next generation. To\npick the well-trained unit models, we need to evaluate their\nperformance, which is done with the validation set V sampled\nfrom the pool. For each unit model M 1\nk ∈M1, based on the\nsub-networks in set V, we can represent the introduced loss\nof the model as\nLc(M 1\nk; V) =\nX\ng∈V\nX\nvi,vj∈Vg,vi̸=vj\nsi,j\n\r\rz1\nk,i −z1\nk,j\n\r\r2\n2 ,\nwhere z1\nk,i and z1\nk,j denote the learned latent representation\nfeature vectors of nodes vi, vj in the sampled sub-network g\nand si,j is deﬁned based on g in the same way as introduced\nbefore.\nThe probability for each unit model to be picked as the\nparent model for the crossover and mutation operations can\nbe represented as\np(M 1\nk) =\nexp−L(M 1\nk;V)\nP\nM 1\ni ∈M1 exp−L(M 1\ni ;V) .\nIn the real-world applications, a normalization of the loss terms\namong these unit models is necessary. For the unit model\nintroducing a smaller loss, it will have a larger chance to\nbe selected as the parent unit model. Considering that the\ncrossover is usually done based a pair of parent models, we\ncan represent the pairs of parent models selected from set M1\nas P1 = {(M 1\ni , M 1\nj )k}k∈{1,2,··· ,m}, based on which we will\nbe able to generate the next generation of unit models, i.e.,\nM2.\n5) Unit Model Crossover and Mutation: For the kth pair of\nparent unit model (M 1\ni , M 1\nj )k ∈P1, we can denote their genes\nas their variables θ1\ni , θ1\nj respectively (since the differences\namong the unit models mainly lie in their variables), which\nare actually their chromosomes for crossover and mutation.\nCrossover: In this paper, we propose to adopt the uniform\ncrossover to get the chromosomes (i.e., the variables) of\ntheir child model. Considering that the parent models M 1\ni\nand M 1\nj can actually achieve different performance on the\nvalidation set V, in the crossover, the unit model achieving\nbetter performance should have a larger chance to pass its\nchromosomes to the child model.\nFormally, the chromosome inheritance probability for parent\nmodel M 1\ni can be represented as\np(M 1\ni ) =\nexp−L(M 1\ni ;V)\nexp−L(M 1\ni ;V) + exp−L(M 1\nj ;V)\nMeanwhile, the chromosome inheritance probability for model\nM 1\nj can be denoted as p(M 1\nj ) = 1 −p(M 1\ni ).\nIn the uniform crossover method, based on parent model\npair (M 1\ni , M 1\nj )k ∈P1, we can represent the obtained child\nmodel chromosome vector as θ2\nk ∈R|θ1| (the superscript\ndenotes the 2nd generation and |θ1| denotes the variable\nlength), which is generated from the chromosome vectors θ1\ni\nand θ1\nj of the parent models. Meanwhile, the crossover choice\nat each position of the chromosomes vector can be represented\nas a vector c ∈{i, j}|θ1|. The entries in vector c are randomly\nselected from values in {i, j} with a probability p(M 1\ni ) to pick\nvalue i and a probability p(M 1\nj ) to pick value j respectively.\nThe lth entry of vector θ2\nk before mutation can be represented\nas\nˆθ2\nk(l) = 1 (c(l) = i) · θ1\ni (l) + 1 (c(l) = j) · θ1\nj(l),\nwhere indicator function 1(·) returns value 1 if the condition\nis True; otherwise, it returns value 0.\nMutation: The variables in the chromosome vector ˆθ2\nk(l) ∈\nR|θ1| are all real values, and some of them can be altered,\nwhich is also called mutation in traditional genetic algorithm.\nMutation happens rarely, and the chromosome mutation prob-\nability is γ in the GEN model. Formally, we can represent the\n5\nmutation indicator vector as m ∈{0, 1}d, and the lth entry of\nvector θ2\nk after mutation can be represented as\nθ2\nk(l) = 1 (m(l) = 0) · ˆθ2\nk(l) + 1 (c(l) = 1) · rand(0, 1),\nwhere rand(0, 1) denotes a random value selected from range\n[0, 1]. Formally, the chromosome vector θ2\nk deﬁnes a new\nunit model with knowledge inherited form the parent models,\nwhich can be denoted as M 2\nk. Based on the parent model\nset P1, we can represent all the newly generated models\nas M2\n= {M 2\nk}(M 1\ni ,M 1\nj )k∈P1, which will form the 2nd\ngeneration of unit models.\nC. Result Ensemble\nBased on the models introduced in the previous subsection,\nin this part, we will introduce the hierarchical result ensemble\nmethod, which involves two steps: (1) local ensemble of results\nfor the sub-networks on each sampling strategies, and (2)\nglobal ensemble of results obtained across different sampling\nstrategies.\n1) Local Ensemble: Based on the sub-network pool G\nobtained via the sampling strategies introduced before, we\nhave learned the Kth generation of the GEN model MK (or\nM for simplicity), which contains m unit models. In this part,\nwe will introduce how to fuse the learned representations from\neach sub-networks with the unit models. Formally, given a\nsub-network g ∈G with node set Vg, by applying unit model\nMj ∈M to g, we can represent the learned representation for\nnode vq ∈Vg as vector zj,q, where q denotes the unique node\nindex in the original complete network G before sampling. For\nthe nodes vp /∈Vg, we can denote its representation vector\nzj,p = null, which denotes a dummy vector of length d.\nFormally, we will be able represent the learned representation\nfeature vector for node vq as\nzq =\nG\ng∈G,Mj∈M,\nzj,q,\n(1)\nwhere operator ⊔denotes the concatenation operation of\nfeature vectors.\nConsidering that in the network sampling step, not all nodes\nwill be selected in sub-networks. For the nodes vp /∈Vg, ∀g ∈\nG, we will not be able to learn its representation feature\nvector (or its representation will be ﬁlled with a list of dummy\nempty vector). Formally, we can represent these non-appearing\nnodes as set Vn = V \\ S\ng∈G Vg. In this paper, to compute\nthe representation for these nodes, we propose to propagate\nthe learned representation from their neighborhoods to them\ninstead. Formally, given node vp ∈Vn and its neighbor set\nΓ(vp) = {vo|vo ∈V ∧(u, vp) ∈E}, if there exists node in\nΓ(vp) with non-empty representation feature vector, we can\nrepresent the propagated representation for vp as\nzp = 1\nN\nX\nvo∈Γ(vp)\n1(vo /∈Vn) · zo,\n(2)\nwhere N = P\nvo∈Γ(vp) 1(vo /∈Vn). In the case that Γ(vp) ⊂\nVn, random padding will be applied to get the representation\nvector zp for node vp.\n2) Global Ensemble: Generally, these different network\nsampling strategies introduced at the beginning in Sec-\ntion III-A captures different local/global structures of the\nnetwork, which will all be useful for the node representation\nlearning. In the global result ensemble step, we propose to\ngroup these features together as the output.\nFormally, based on the BFS, DFS, HS, biased node and\nbiased edge sampling strategies, to differentiate their learned\nrepresentations for nodes (e.g., vq ∈V), we can denoted their\nrepresentation feature vectors as zBFS\nq , zDFS\nq\n, zHS\nq , zNS\nq\nand zES\nq\nrespectively. In the case that node vq has never appeared in\nany sub-networks in any of the sampling strategies, its cor-\nresponding feature vector can be denoted as a dummy vector\nﬁlled with 0s. In the global ensemble step, we propose to\nlinearly sum the feature vectors to get the fuses representation\n¯zq as follows:\n¯zq =\nX\ni∈{BFS,DFS,HS,NS,ES}\nwi · zi\nq.\nLearning of the weight parameters wBFS, wDFS, wHS, wNS and\nwES is feasible with the complete network structure, but it may\nintroduce extra time costs and greatly degrade the efﬁciency\nSEGEN. In this paper, we will simply assign them with equal\nvalue, i.e., ¯zq is an average of zBFS\nq , zDFS\nq\n, zHS\nq , zNS\nq\nand zES\nq\nlearned with different sampling strategies.\nD. Model Analysis\nIn this section, we will analyze the proposed model SEGEN\nregarding its performance, running time and space cost, which\nwill also illustrate the advantages of SEGEN compared with\nthe other existing deep learning models.\n1) Performance Analysis: Model\nSEGEN, in a certain\nsense, can also be called a “deep” model. Instead of stacking\nmultiple hidden layers inside one single model like existing\ndeep learning models, SEGEN is deep since the unit models\nin the successive generations are generated by a namely\n“evolutionary layer” which performs the validation, selection,\ncrossover, and mutation operations connecting these gener-\nations. Between the generations, these “evolutionary opera-\ntions” mainly work on the unit model variables, which allows\nthe immigration of learned knowledge from generation to gen-\neration. In addition, via these generations, the last generation\nin SEGEN can also capture the overall patterns of the dataset.\nSince the unit models in different generations are built with\ndifferent sampled training batches, as more generations are\ninvolved, the dataset will be samples thoroughly for learning\nSEGEN. There have been lots of research works done on\nanalyzing the convergence, performance bounds of genetic\nalgorithms [22], which can provide the theoretic foundations\nfor SEGEN.\nDue to the difference in parent model selection, crossover,\nmutation operations and different sampled training batches, the\nunit models in the generations of SEGEN may perform quite\ndifferently. In the last step, SEGEN will effectively combine\nthe learning results from the multiple unit models together.\nWith the diverse results combined from these different learning\n6\nmodels, SEGEN is able to achieve better performance than\neach of the unit models, which have been effectively demon-\nstrated in [32].\n2) Space and Time Complexity Analysis: According the the\nmodel descriptions provided in Section III, we summarize the\nkey parameters used in SEGEN as follows, which will help\nanalyze its space and time complexity.\n• Sampling: Original data size: n. Sub-instance size: n′.\nPool size: p.\n• Learning: Generation number: K. Population size: m.\nFeature vector size: d. Training/Validation batch size: b.\nHere, we will use network structured data as an example to\nanalyze the space and time complexity of the SEGEN model.\nSpace Complexity: Given a large-scale network with n nodes,\nthe space cost required for storing the whole network in\na matrix representation is O(n2). Meanwhile, via network\nsampling, we can obtain a pool of sub-networks, and the space\nrequired for storing these sub-networks takes O\n\u0000p(n′)2\u0001\n.\nGenerally, in application of SEGEN, n′ can take very small\nnumber, e.g., 50, and p can take value p = c ·\nn\nn′ (c is a\nconstant) so as to cover all the nodes in the network. In such\na case, the space cost of SEGEN will be linear to n, O(cn′n),\nwhich is much smaller than O(n2).\nTime Complexity: Depending on the speciﬁc unit models\nused in composing SEGEN, we can represent the introduced\ntime complexity of learn one unit model with the original\nnetwork with n nodes as O(f(n)), where f(n) is usually\na high-order function. Meanwhile, for learning SEGEN on\nthe sampled sub-networks with n′ nodes, all the introduced\ntime cost will be O (Km(b · f(n′) + d · n′)), where term\nd · n′ (an approximation to variable size) represents the cost\nintroduced in the unit model crossover and mutation about\nthe model variables. Here, by assigning b with a ﬁxed value\nb = c · n\nn′ , the time complexity of SEGEN will be reduced to\nO\n\u0010\nKmc f(n′)\nn′\n· n + Kmdn′\u0011\n, which is linear to n.\n3) Advantages Over Deep Learning Models: Compared\nwith existing deep learning models based on the whole dataset,\nthe advantages of SEGEN are summarized below:\n• Less Data for Unit Model Learning: For each unit model,\nwhich are of a “shallow” and “narrow” structure (shallow:\nless or even no hidden layers, narrow: based on sampled\nsub-instances with a much smaller size), which needs far\nless variables and less data for learning each unit model.\n• Less Computational Resources: Each unit model is of\na much simpler structure, learning process of which\nconsumes far less computational resources in both time\nand space costs.\n• Less Parameter Tuning: SEGEN can accept both deep\n(in a simpler version) and shallow learning models as the\nunit model, and the hyper-parameters can also be shared\namong the unit models, which will lead to far less hyper-\nparameters to tune in the learning process.\n• Sound Theoretic Explanation: The unit learning model,\ngenetic algorithm and ensemble learning (aforemen-\ntioned) can all provide the theoretic foundation for\n0\n100\n200\n300\n400\n500\nGeneration Number\n30000\n20000\n10000\nc\n(a) Foursquare: Convergence\n0\n100\n200\n300\n400\n500\nGeneration Number\n25000\n20000\n15000\n10000\n5000\nc\n(b) Twitter: Convergence\nFig. 3. Convergence Analysis on Foursquare and Twitter.\nSEGEN, which will lead to sound theoretic explanation\nof both the learning result and the SEGEN model itself.\nIV. EXPERIMENTS\nTo test the effectiveness of the proposed model, exten-\nsive experiments will be done on several real-world network\nstructured datasets, including social networks, images and\nraw feature representation datasets. In this section, we will\nﬁrst introduce the detailed experimental settings, covering\nexperimental setups, comparison methods, evaluation tasks\nand metrics for the social network representation learning task.\nAfter that, we will show its convergence analysis, parameter\nanalysis and the main experimental results of SEGEN on\nthe social network datasets. Finally, we will provide the\nexperiments SEGEN based on the image and raw feature\nrepresentation datasets involving CNN and MLP as the unit\nmodels respectively.\nA. Social Network Dataset Experimental Settings\n1) Experimental Setup: The network datasets used in the\nexperiments are crawled from two different online social\nnetworks, Twitter and Foursquare, respectively. The Twitter\nnetwork dataset involves 5, 120 users and 130, 576 social\nconnections among the user nodes. Meanwhile, the Foursquare\nnetwork dataset contains 5, 392 users together with the 55, 926\nsocial links connecting them. According to the descriptions of\nSEGEN, based on the complete input network datasets, a set\nof sub-networks are randomly sampled with network sampling\nstrategies introduced in this paper, where the sub-network size\nis denoted as n′, and the pool size is controlled by p. Based\non the training/validation batches sampled sub-network pool,\nK generations of unit models will be built in SEGEN, where\neach generation involves m unit models (convergence analysis\nregarding parameter K is available in Section IV-B). Finally,\nthe learning results at the ending generation will be effectively\ncombined to generate the ensemble output. For the nodes\nwhich have never been sampled in any sub-networks, their\nrepresentations can be learned with the diffusive propagation\nfrom their neighbor nodes introduced in this paper. The learned\nresults by SEGEN will be evaluated with two application tasks,\ni.e., network recovery and community detection respectively.\nThe detailed parameters sensitivity analysis is also available\nin Section IV-B.\n7\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nAUC\n0.82\n0.82\n0.83\n0.83\n0.84\n0.84\n0.85\n0.85\n0.86\n0.86\n(a) Foursquare: AUC\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nPrec@500\n0.63\n0.67\n0.71\n0.74\n0.78\n0.82\n0.85\n0.89\n0.92\n0.96\n(b) Foursquare: Prec@500\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nDensity\n0.19\n0.20\n0.21\n0.22\n0.23\n0.25\n0.26\n0.27\n0.28\n0.29\n(c) Foursquare: Density\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nSilhouette\n-0.03\n-0.03\n-0.02\n-0.02\n-0.02\n-0.02\n-0.01\n-0.01\n-0.01\n-0.01\n(d) Foursquare: Silhouette\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nAUC\n0.69\n0.71\n0.72\n0.73\n0.75\n0.76\n0.77\n0.79\n0.80\n0.81\n(e) Twitter: AUC\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nPrec@500\n0.35\n0.40\n0.45\n0.49\n0.54\n0.59\n0.64\n0.69\n0.74\n0.79\n(f) Twitter: Prec@500\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nDensity\n0.48\n0.51\n0.54\n0.57\n0.60\n0.63\n0.66\n0.69\n0.72\n0.75\n(g) Twitter: Density\nSub-Network Size\n10\n20\n30\n40\n50\nPool Size\n200\n400\n600\n800\n1000\nSilhouette\n0.08\n0.10\n0.11\n0.13\n0.14\n0.15\n0.17\n0.18\n0.20\n0.21\n(h) Twitter: Silhouette\nFig. 4. Sampling Parameter Analysis on Foursquare and Twitter.\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10\n20\n30\n40\n50\nAUC \n0.81\n0.82\n0.82\n0.82\n0.82\n0.82\n0.82\n0.82\n0.82\n0.82\n(a) Foursquare: AUC\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10 20 30\n40\n50\nPrec@500 \n0.76\n0.76\n0.77\n0.78\n0.79\n0.79\n0.80\n0.81\n0.81\n0.82\n(b) Foursquare: Prec@500\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10\n20\n30\n40\n50\nDensity\n0.18\n0.18\n0.19\n0.19\n0.19\n0.19\n0.19\n0.19\n0.20\n0.20\n(c) Foursquare: Density\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10\n20\n30\n40\n50\nSilhouette\n-0.02\n-0.02\n-0.02\n-0.02\n-0.02\n-0.02\n-0.02\n-0.02\n-0.01\n-0.01\n(d) Foursquare: Silhouette\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10\n20\n30\n40\n50\n AUC \n0.81\n0.81\n0.81\n0.81\n0.82\n0.82\n0.82\n0.82\n0.82\n0.82\n(e) Twitter: AUC\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10\n20\n30\n40\n50\nPrec@500\n0.56\n0.59\n0.62\n0.65\n0.68\n0.71\n0.74\n0.77\n0.79\n0.82\n(f) Twitter: Prec@500\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10\n20\n30\n40\n50\nDensity\n0.47\n0.47\n0.47\n0.48\n0.48\n0.48\n0.48\n0.49\n0.49\n0.49\n(g) Twitter: Density\nBatch Size\n10\n20\n30\n40\n50\nGeneration Size\n10\n20\n30\n40\n50\nSilhouette\n0.07\n0.07\n0.08\n0.08\n0.08\n0.08\n0.09\n0.09\n0.09\n0.10\n(h) Twitter: Silhouette\nFig. 5. Batch and Generation Size Parameter Analysis on Foursquare and Twitter.\n2) Comparison Methods: The network representation learn-\ning comparison models used in this paper are listed as follows\n• SEGEN: Model SEGEN proposed in this paper is based\non the genetic algorithm and ensemble learning, which\neffectively combines the learned sub-network representa-\ntion feature vectors from the unit models to generate the\nfeature vectors of the whole network.\n• LINE: The LINE model is a scalable network embedding\nmodel proposed in [24], which optimizes an objective\nfunction that preserves both the local and global network\nstructures. LINE uses a edge-sampling algorithm to ad-\ndresses the limitation of the classical stochastic gradient\ndescent.\n• DEEPWALK: The DEEPWALK model [21] extends the\nword2vec model [19] to the network embedding scenario.\nDEEPWALK uses local information obtained from trun-\ncated random walks to learn latent representations.\n• NODE2VEC: The NODE2VEC model [10] introduces a\nﬂexible notion of a node’s network neighborhood and\ndesign a biased random walk procedure to sample the\nneighbors for node representation learning.\n• HPE: The HPE model [4] is originally proposed for\nlearning user preference in recommendation problems,\nwhich can effectively project the information from het-\nerogeneous networks to a low-dimensional space.\n3) Evaluation Tasks and Metrics: The network representa-\ntion learning results can hardly be evaluated directly, whose\nevaluations are usually based on certain application tasks.\nIn this paper, we propose to use application tasks, network\nrecovery and clustering, to evaluate the learned representation\nfeatures from the comparison methods. Furthermore, the net-\nwork recovery results are evaluated by metrics, like AUC and\n8\nTABLE I\nREPRESENTATION LEARNING EXPERIMENT RESULTS COMPARISON ON FOURSQUARE NETWORK DATASET.\nNetwork\nAUC\nPrec@500\nCommunity\nDensity\nSilhouette\nRecovery\n1\n5\n10\n1\n5\n10\nDetection\n5\n25\n50\n5\n25\n50\nSEGEN(PS2)\n0.909 (2) 0.909 (2) 0.909 (2)\n0.872 (2)\n0.642 (3)\n0.530 (3)\nSEGEN(PS3)\n0.875 (2)\n0.550 (2)\n0.792 (3)\n0.353 (2)\n0.206 (2)\n0.208 (3)\nSEGEN(PS1)\n0.817 (6) 0.819 (6) 0.818 (6)\n0.772 (5)\n0.400 (4)\n0.266 (4)\nSEGEN(PS1)\n0.792 (6)\n0.477 (4)\n0.742 (4)\n0.317 (4)\n0.188 (3)\n0.156 (5)\nSEGEN-HS(PS2)\n0.935 (1) 0.936 (1) 0.936 (1)\n0.852 (4)\n0.388 (5)\n0.000 (-)\nSEGEN-HS(PS3)\n0.812 (5)\n0.385 (11)\n0.705 (5)\n0.252 (10)\n0.056 (6)\n0.166 (4)\nSEGEN-BFS(PS2) 0.860 (4) 0.859 (4) 0.858 (4) 0.428 (10)\n0.000 (-)\n0.000 (-)\nSEGEN-BFS(PS3)\n0.746 (7)\n0.425 (8)\n0.587 (6)\n0.206 (11) 0.022 (10)\n0.108 (6)\nSEGEN-DFS(PS2) 0.881 (3) 0.882 (3) 0.881 (3)\n0.965 (1)\n0.814 (2)\n0.648 (2) SEGEN-DFS(PS3)\n0.860 (4)\n0.532 (3)\n0.436 (11)\n0.280 (9)\n0.017 (11) -0.006 (11)\nSEGEN-NS(PS2)\n0.801 (7) 0.797 (7) 0.797 (7) 0.256 (11) 0.002 (10) 0.002 (9)\nSEGEN-NS(PS3)\n0.871 (3)\n0.425 (8)\n0.824 (2)\n0.327 (3)\n0.060 (5)\n0.294 (2)\nSEGEN-ES(PS2)\n0.820 (5) 0.822 (5) 0.822 (5)\n0.872 (2)\n0.872 (1)\n0.872 (1)\nSEGEN-ES(PS3)\n0.948 (1)\n0.933 (1)\n0.924 (1)\n0.482 (1)\n0.429 (1)\n0.407 (1)\nLINE [24]\n0.536 (9) 0.537 (9) 0.537 (9)\n0.712 (6)\n0.268 (9)\n0.172 (7)\nLINE [24]\n0.695 (8)\n0.443 (6)\n0.478 (8)\n0.311 (5)\n0.046 (8)\n0.082 (8)\nDEEPWALK [21]\n0.536 (9) 0.537 (9) 0.537 (9)\n0.686 (9)\n0.308 (7)\n0.184 (6)\nDEEPWALK [21]\n0.695 (8)\n0.449 (5)\n0.485 (7)\n0.311 (5)\n0.042 (9)\n0.082 (8)\nNODE2VEC [10]\n0.538 (8) 0.540 (8) 0.539 (8)\n0.692 (8)\n0.299 (8)\n0.162 (8)\nNODE2VEC [10]\n0.691 (11) 0.419 (10)\n0.469 (9)\n0.297 8\n0.066 (4)\n0.070 (10)\nHPE [4]\n0.536 (9) 0.537 (9) 0.537 (9)\n0.708 (7)\n0.354 (6)\n0.188 (5)\nHPE [4]\n0.695 (8)\n0.431 (7)\n0.465 (10)\n0.311 (5)\n0.051 (7)\n0.089 (7)\nTABLE II\nREPRESENTATION LEARNING EXPERIMENT RESULTS COMPARISON ON TWITTER NETWORK DATASET.\nNetwork\nAUC\nPrec@500\nCommunity\nDensity\nSilhouette\nRecovery\n1\n5\n10\n1\n5\n10\nDetection\n5\n25\n50\n5\n25\n50\nSEGEN(PS4)\n0.879 (1)\n0.881 (1)\n0.881 (1)\n0.914 (3) 0.638 (3) 0.370 (3)\nSEGEN(PS5)\n0.980 (2)\n0.845 (3)\n0.770 (3)\n0.566 (4)\n0.353 (3)\n0.341 (2)\nSEGEN(PS1)\n0.814 (4)\n0.813 (4)\n0.814 (4)\n0.606 (4) 0.194 (4) 0.102 (4)\nSEGEN(PS1)\n0.786 (7)\n0.751 (4)\n0.753 (4) 0.481 (10) 0.328 (4)\n0.318 (4)\nSEGEN-HS(PS4)\n0.862 (2)\n0.863 (2)\n0.863 (2)\n0.594 (5)\n0.000 (-) 0.000 (-)\nSEGEN-HS(PS5)\n0.967 (6) 0.171 (11) 0.116 (11) 0.549 (5) -0.021 (11) -0.032 (10)\nSEGEN-BFS(PS4) 0.846 (3)\n0.846 (3)\n0.846 (3)\n0.570 (6)\n0.000 (-) 0.000 (-) SEGEN-BFS(PS5) 0.973 (4)\n0.973 (2)\n0.886 (2)\n0.622 (2)\n0.517 (2)\n0.330 (3)\nSEGEN-DFS(PS4) 0.503 (10) 0.508 (10) 0.507 (10) 0.268 (10) 0.000 (-) 0.000 (-) SEGEN-DFS(PS5) 0.994 (1)\n0.338 (9) 0.143 (10) 0.532 (7)\n0.237 (6)\n-0.023 (9)\nSEGEN-NS(PS4)\n0.794 (5)\n0.794 (5)\n0.795 (5)\n0.962 (2) 0.824 (2) 0.688 (2) SEGEN-NS(PS5)\n0.979 (3)\n0.981 (1)\n0.965 (1)\n0.597 (3)\n0.525 (1)\n0.461 (1)\nSEGEN-ES(PS4)\n0.758 (6)\n0.760 (6)\n0.760 (6)\n1.000 (1) 1.000 (1) 1.000 (1)\nSEGEN-ES(PS5)\n0.970 (5)\n0.525 (8)\n0.482 (8)\n0.693 (1)\n0.284 (5) -0.059 (11)\nLINE [24]\n0.254 (11) 0.254 (11) 0.253 (11) 0.106 (11) 0.018 (7) 0.006 (7)\nLINE [24]\n0.524 (11) 0.324 (10) 0.251 (9) 0.465 (11) -0.012 (9)\n-0.012 (7)\nDEEPWALK [21]\n0.533 (9)\n0.531 (9)\n0.532 (9)\n0.524 (9) 0.146 (6) 0.070 (6) DEEPWALK [21] 0.545 (10) 0.542 (7)\n0.503 (7)\n0.492 (9)\n0.173 (8)\n0.150 (6)\nNODE2VEC [10]\n0.704 (7)\n0.703 (7)\n0.704 (7)\n0.528 (8) 0.012 (8) 0.000 (-)\nNODE2VEC [10]\n0.697 (8)\n0.693 (5)\n0.694 (5)\n0.530 (8) -0.020 (10) -0.015 (8)\nHPE [4]\n0.593 (8)\n0.595 (8)\n0.594 (8)\n0.534 (7) 0.186 (5) 0.094 (5)\nHPE [4]\n0.579 (9)\n0.579 (6)\n0.579 (6)\n0.544 (6)\n0.208 (7)\n0.187 (5)\nPrecision@500. Meanwhile the clustering results are evaluated\nby Density and Silhouette.\n4) Default Parameter Setting: Without speciﬁc remarks,\nthe default parameter setting for SEGEN in the experiments\nwill be Parameter Setting 1 (PS1): sub-network size: 10, pool\nsize: 200, batch size: 10, generation unit model number: 10,\ngeneration number: 30.\nB. Social Network Dataset Experimental Analysis\nIn this part, we will provide experimental analysis about the\nconvergence and parameters of SEGEN, including the sub-\nnetwork size, the pool size, batch size and generation size\nrespectively.\n1) Convergence Analysis: The learning process of SEGEN\ninvolves multiple generations. Before showing the experimen-\ntal results, we will analyze how many generations will be\nrequired for achieving stable results. In Figure 3, we provide\nthe introduced loss by the SEGEN on both Foursquare and\nTwitter networks, where the x axis denotes the generations\nand y axis represents the sum of introduced Lc loss on the\nvalidation set based on all these 5 different sampling strategies.\nAccording to the results, model SEGEN can converge within\nless 30 generations for the network representation learning on\nboth Foursquare and Twitter, which will be used as the max-\ngeneration number throughout the following experiments.\n2) Pool Sampling Parameter Analysis: In Figure 4, we\nshow the sensitivity analysis about the network sampling pa-\nrameters, i.e., sub-network size and the pool size, evaluated by\nAUC, Prec@500, Density and Silhouette respectively, where\nFigures 4(a)-4(d) are about the Foursquare and Figures 4(e)-\n4(h) are about the Twitter network. The sub-network size\nparameter changes with values in {5, 10, 15, · · · , 50} and pool\nsize changes with values in range {100, 200, · · · , 1000}.\nAccording to the plots, for the Foursquare network, larger\nsub-network size and larger pool size will lead to better\nperformance in the network recovery task; meanwhile, smaller\nsub-network size will achiver better performance for the\ncommunity detection task. For instance, SEGEN can achieve\n9\nthe best performance with sub-network size 50 and pool size\n600 for the network recovery task; and SEGEN obtain the\nbest performance with sub-network size 25 and pool size 300\nfor the community detection. For the Twitter network, the\nperformance of SEGEN is relatively stable for the parameters\nanalyzed, which has some ﬂuctuations for certain parameter\nvalues. According to the results, the optimal sub-network and\npool sizes parameter values for the network recovery task are\n50 and 700 for the network recovery task; meanwhile, for the\ncommunity detection task, the optimal parameter values are\n45 and 500 respectively.\n3) Model Learning Parameter Analysis: In Figure 5, we\nprovide the parameter sensitivity analysis about the batch\nsize and generation size (i.e., the number of unit models\nin each generation) on Foursquare and Twitter. We change\nthe generation size and batch size both with values in\n{5, 10, 15, · · · , 50}, and compute the AUC, Prec@500, Den-\nsity and Silhouette scores obtained by SEGEN.\nAccording Figures 5(a)-5(d), batch size has no signiﬁcant\nimpact on the performance of SEGEN, and the generation\nsize may affect SEGEN greatly, especially for the Prec@500\nmetric (the AUC obtained by SEGEN changes within range\n[0.81, 0.82] with actually minor ﬂuctuation in terms of the\nvalues). The selected optimal parameter values selected for\nnetwork recovery are 50 and 5 for generation and bath sizes.\nMeanwhile, for the community detection, SEGEN performs\nthe best with smaller generation and batch size, whose optimal\nvalues are 5 and 35 respectively. For the Twitter network,\nthe impact of the batch size and generation size is different\nfrom that on Foursquare: smaller generation size lead to\nbetter performance for SEGEN evaluated by Prec@500. The\nﬂuctuation in terms of AUC is also minor in terms of the\nvalues, and the optimal values of the generation size and batch\nsize parameters for the network recovery task are 5 and 10\nrespectively. For the community detection task on Twitter, we\nselect generation size 5 and batch size 40 as the optimal value.\nC. Social Network Dataset Experimental Results\nBased on the above parameter analysis, we provide the\nperformance analysis of SEGEN and baseline methods in\nTables I-II, where the parameter settings are speciﬁed next to\nthe method name. We provide the rank of method performance\namong all the methods, which are denoted by the numbers in\nblue font, and the top 5 results are in a bolded font. As shown\nin the Tables, we have the network recovery and community\ndetection results on the left and right sections respectively. For\nthe network recovery task, we change the ratio of negative\nlinks compared with positive links with values {1, 5, 10},\nwhich are evaluated by the metrics AUC and Prec@500.\nFor the community detection task, we change the number of\nclusters with values {5, 25, 50}, and the results are evaluated\nby the metrics Density and Silhouette.\nBesides PS1 introduced at the beginning of Section IV-A,\nwe have 4 other parameter settings selected based on the\nparameter analysis introduced before. PS2 for network recov-\nery on Foursquare: sub-network size 50, pool size 600, batch\nsize 5, generation size 50. PS3 for community detection on\nFoursquare: sub-network size 25, pool size 300, batch size\n35, generation size 5. PS4 for network recovery on Twitter:\nsub-network size 50, pool size 700, batch size 10, generation\nsize 5. PS5 for community detection on Twitter: sub-network\nsize 45, pool size 500, batch size 50, generation size 5.\nAccording to the results shown in Table I, method SEGEN\nwith PS2 can obtain very good performance for both the\nnetwork recovery task and the community detection task. For\ninstance, for the network recovery task, method SEGEN with\nPS2 achieves 0.909 AUC score, which ranks the second and\nonly lose to SEGEN-HS with PS2; meanwhile, SEGEN with\nPS2 also achieves the second highest Prec@500 score (i.e.,\n0.872 for np-ratio = 1) and the third highest Prec@500 score\n(i.e., 0.642 and 0.530 for np-ratios 5 and 10) among the\ncomparison methods. On the other hand, for the community\ndetection task,\nSEGEN with PS3 can generally rank the\nsecond/third among the comparison methods for both density\nand silhouette evaluation metrics. For instance, with the cluster\nnumber is 5, the density obtained by SEGEN ranks the second\namong the methods, which loses to SEGEN-LS only. Similar\nresults can be observed for the Twitter network as shown in\nFigure II.\nBy comparing SEGEN with SEGEN merely based on HS,\nBFS, DFS, NS, LS, we observe that the variants based on one\ncertain type of sampling strategies can obtain relatively biased\nperformance, i.e., good performance for the network recovery\ntask but bad performance for the community detection task\nor the reverse. For instance, as shown in Figure I, methods\nSEGEN with HS, BFS, DFS performs very good for the\nnetwork recovery task, but its performance for the community\ndetection ranks even after LINE, HPE and DEEPWALK. On\nthe other hand, SEGEN with NS and LS is shown to perform\nwell for the community detection task instead in Figure I,\nthose performance ranks around 7 for the network recovery\ntask. For the Twitter network, similar biased results can be\nobserved but the results are not identically the same. Model\nSEGEN combining these different sampling strategies together\nachieves relatively balanced and stable performance for differ-\nent tasks. Compared with the baseline methods LINE, HPE,\nDEEPWALK and NODE2VEC, model SEGEN can obtain much\nbetter performance, which also demonstrate the effectiveness\nof SEGEN as an alternative approach for deep learning models\non network representation learning.\nD. Experiments on Other Datasets and Unit Models\nBesides the extended autoencoder model and the social\nnetwork datasets, we have also tested the effectiveness of\nSEGEN on other datasets and with other unit models.\nIn Table III, we show the experimental results of SEGEN\nand other baseline methods on the MNIST hand-written image\ndatasets. The dataset contains 60, 000 training instances and\n10, 000 testing instances, where each instance is a 28 × 28\nimage with labels denoting their corresponding numbers. Con-\nvolutional Neural Network (CNN) is used as the unit model\nin SEGEN, which involves 2 convolutional layers, 2 max-\n10\nTABLE III\nEXPERIMENTS ON MNIST DATASET.\nComparison Methods\nAccuracy Rate%\nSEGEN (CNN)\n99.37\nLeNet-5\n99.05 [17]\ngcForest\n99.26 [31]\nDeep Belief Net\n98.75 [13]\nRandom Forest\n96.8 [31]\nSVM (rbf)\n98.60 [7]\nTABLE IV\nEXPERIMENTS ON OTHER DATASETS.\nComparison Methods\nAccuracy Rate % on Datasets\nYEAST\nADULT\nLETTER\nSEGEN (MLP)\n63.70\n87.05\n96.90\nMLP\n62.05\n85.03\n96.70\ngcForest\n63.45\n86.40\n97.40\nRandom Forest\n60.44\n85.63\n96.28\nSVM (rbf)\n40.76\n76.41\n97.06\nkNN (k=3)\n48.80\n76.00\n95.23\npooling layers, and two fully connection layers (with a 0.2\ndropout rate). ReLU is used as the activation function in\nCNN, and we adopt Adam as the optimization algorithm.\nHere, the images are of a small size and no sampling is\nperformed, while the learning results of the best unit model\nin the ending generation (based on a validation batch) will\nbe outputted as the ﬁnal results. In the experiments, SEGEN\n(CNN) is compared with several classic methods (e.g., LeNet-\n5, SVM, Random Forest, Deep Belief Net) and state-of-the-art\nmethod (gcForest). According to the results, SEGEN (CNN)\ncan outperform the baseline methods with great advantages.\nThe Accuracy rate obtained by SEGEN is 99.37%, which is\nmuch higher than the other comparison methods.\nMeanwhile, in Table IV, we provide the learning results on\nthree other benchmark datasets, including YEAST1, ADULT2\nand LETTER3. These three datasets are in the traditional\nfeature representations. Multi-Layer Perceptron (MLP) is used\nas the unit model in SEGEN for these three datasets. We\ncannot ﬁnd one uniﬁed architecture of MLP, which works for\nall these three datasets. In the experiments, for the YEAST\ndataset, the MLP involves 1 input layer, 2 hidden layers and\n1 output layers, whose neuron numbers are 8-64-16-10; for\nthe ADULT, the MLP architecture contains the neurons 14-\n70-50-2; for the LETTER dataset, the used MLP has 3 hidden\nlayers with neurons 16-64-48-32-26 at each layer respectively.\nThe Adam optimization algorithm with 0.001 learning rate is\nused to train the MLP model. For the ensemble strategy in\nthese experiments, the best unit model is selected to generate\nthe ﬁnal prediction output. According to the results, compared\nwith the baseline methods, SEGEN (MLP) can also perform\nvery well with MLP on the raw feature representation datasets\nwith great advantages, especially the YEAST and ADULT\ndatasets. As to the LETTER dataset, SEGEN (MLP) only loses\nto gcForest, but can outperform the other methods consistently.\nV. RELATED WORK\nDeep Learning Research and Applications: The essence\nof deep learning is to compute hierarchical features or rep-\nresentations of the observational data [9], [16]. With the\nsurge of deep learning research and applications in recent\nyears, lots of research works have appeared to apply the\ndeep learning methods, like deep belief network [13], deep\n1https://archive.ics.uci.edu/ml/datasets/Yeast\n2https://archive.ics.uci.edu/ml/datasets/adult\n3https://archive.ics.uci.edu/ml/datasets/letter+recognition\nBoltzmann machine [23], Deep neural network [14], [15] and\nDeep autoencoder model [25], in various applications, like\nspeech and audio processing [8], [12], language modeling and\nprocessing [1], [20], information retrieval [11], [23], objective\nrecognition and computer vision [16], as well as multimodal\nand multi-task learning [28], [29].\nNetwork Embedding: Network embedding has become a very\nhot research problem recently, which can project a graph-\nstructured data to the feature vector representations. In graphs,\nthe relation can be treated as a translation of the entities,\nand many translation based embedding models have been\nproposed, like TransE [2], TransH [27] and TransR [18]. In re-\ncent years, many network embedding works based on random\nwalk model and deep learning models have been introduced,\nlike Deepwalk [21], LINE [24], node2vec [10], HNE [3] and\nDNE [26]. Perozzi et al. extends the word2vec model [19] to\nthe network scenario and introduce the Deepwalk algorithm\n[21]. Tang et al. [24] propose to embed the networks with\nLINE algorithm, which can preserve both the local and global\nnetwork structures. Grover et al. [10] introduce a ﬂexible\nnotion of a node’s network neighborhood and design a biased\nrandom walk procedure to sample the neighbors. Chang et al.\n[3] learn the embedding of networks involving text and image\ninformation. Chen et al. [5] introduce a task guided embedding\nmodel to learn the representations for the author identiﬁcation\nproblem.\nVI. CONCLUSION\nIn this paper, we have introduced an alternative approach to\ndeep learning models, namely SEGEN. Signiﬁcantly different\nfrom the existing deep learning models, SEGEN builds a\ngroup of unit models generations by generations, instead of\nbuilding one single model with extremely deep architectures.\nThe choice of unit models covered in SEGEN can be either\ntraditional machine learning models or the latest deep learning\nmodels with a “smaller” and “narrower” architecture. SEGEN\nhas great advantages over deep learning models, since it\nrequires much less training data, computational resources,\nparameter tuning efforts but provides more information about\nits learning and result integration process. The effectiveness\nof efﬁciency of SEGEN have been well demonstrated with\nthe extensive experiments done on the real-world network\nstructured datasets.\n11\nREFERENCES\n[1] E. Arisoy, T. Sainath, B. Kingsbury, and B. Ramabhadran. Deep neural\nnetwork language models. In WLM, 2012.\n[2] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko.\nTranslating embeddings for modeling multi-relational data.\nIn NIPS.\n2013.\n[3] S. Chang, W. Han, J. Tang, G. Qi, C. Aggarwal, and T. Huang.\nHeterogeneous network embedding via deep architectures.\nIn KDD,\n2015.\n[4] C. Chen, M. Tsai, Y. Lin, and Y. Yang. Query-based music recommen-\ndations via preference embedding. In RecSys, 2016.\n[5] T. Chen and Y. Sun. Task-guided and path-augmented heterogeneous\nnetwork embedding for author identiﬁcation. CoRR, abs/1612.02814,\n2016.\n[6] J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, Q. Le, M. Mao,\nM. Ranzato, A. Senior, P. Tucker, K. Yang, and A. Ng. Large scale\ndistributed deep networks. In NIPS, 2012.\n[7] D. Decoste and B. Sch¨olkopf. Training invariant support vector ma-\nchines. Mach. Learn., 2002.\n[8] L. Deng, G. Hinton, and B. Kingsbury.\nNew types of deep neural\nnetwork learning for speech recognition and related applications: An\noverview. In ICASSP, 2013.\n[9] I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. MIT Press,\n2016. http://www.deeplearningbook.org.\n[10] A. Grover and J. Leskovec. Node2vec: Scalable feature learning for\nnetworks. In KDD, 2016.\n[11] S. Hill.\nElite and upper-class families.\nIn Families: A Social Class\nPerspective. 2012.\n[12] G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior,\nV. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury. Deep neural\nnetworks for acoustic modeling in speech recognition.\nIEEE Signal\nProcessing Magazine, 2012.\n[13] G. Hinton, S. Osindero, and Y. Teh. A fast learning algorithm for deep\nbelief nets. Neural Comput., 2006.\n[14] H. Jaeger. Tutorial on training recurrent neural networks, covering BPPT,\nRTRL, EKF and the “echo state network” approach. Technical report,\nFraunhofer Institute for Autonomous Intelligent Systems (AIS), 2002.\n[15] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classiﬁcation with\ndeep convolutional neural networks. In NIPS, 2012.\n[16] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. Nature, 521, 2015.\nhttp://dx.doi.org/10.1038/nature14539.\n[17] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning\napplied to document recognition. Proceedings of the IEEE, 1998.\n[18] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu. Learning entity and relation\nembeddings for knowledge graph completion. In AAAI, 2015.\n[19] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean. Distributed\nrepresentations of words and phrases and their compositionality.\nIn\nNIPS, 2013.\n[20] A. Mnih and G. Hinton. A scalable hierarchical distributed language\nmodel. In NIPS. 2009.\n[21] B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk: Online learning of\nsocial representations. In KDD, 2014.\n[22] G. Rudolph.\nConvergence analysis of canonical genetic algorithms.\nIEEE Transactions on Neural Networks, 1994.\n[23] R. Salakhutdinov and G. Hinton.\nSemantic hashing.\nInternational\nJournal of Approximate Reasoning, 2009.\n[24] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei. Line: Large-\nscale information network embedding. In WWW, 2015.\n[25] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P. Manzagol.\nStacked denoising autoencoders: Learning useful representations in a\ndeep network with a local denoising criterion.\nJournal of Machine\nLearning Research, 2010.\n[26] D. Wang, P. Cui, and W. Zhu. Structural deep network embedding. In\nKDD, 2016.\n[27] Z. Wang, J. Zhang, J. Feng, and Z. Chen. Knowledge graph embedding\nby translating on hyperplanes. In AAAI, 2014.\n[28] J. Weston, S. Bengio, and N. Usunier. Large scale image annotation:\nLearning to rank with joint word-image embeddings. Journal of Machine\nLearning, 2010.\n[29] J. Weston, S. Bengio, and N. Usunier.\nWsabie: Scaling up to large\nvocabulary image annotation. In IJCAI, 2011.\n[30] Z. Zhou and J. Feng. Deep forest: Towards an alternative to deep neural\nnetworks. In IJCAI, 2017.\n[31] Z. Zhou and J. Feng. Deep forest: Towards an alternative to deep neural\nnetworks. In IJCAI, 2017.\n[32] Z. Zhou, J. Wu, and W. Tang. Ensembling neural networks: Many could\nbe better than all. Artif. Intell., 2002.\n12\n",
  "categories": [
    "cs.NE",
    "cs.AI",
    "cs.LG"
  ],
  "published": "2018-03-23",
  "updated": "2018-06-05"
}