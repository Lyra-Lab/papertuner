{
  "id": "http://arxiv.org/abs/1805.00352v1",
  "title": "Word2Vec and Doc2Vec in Unsupervised Sentiment Analysis of Clinical Discharge Summaries",
  "authors": [
    "Qufei Chen",
    "Marina Sokolova"
  ],
  "abstract": "In this study, we explored application of Word2Vec and Doc2Vec for sentiment\nanalysis of clinical discharge summaries. We applied unsupervised learning\nsince the data sets did not have sentiment annotations. Note that unsupervised\nlearning is a more realistic scenario than supervised learning which requires\nan access to a training set of sentiment-annotated data. We aim to detect if\nthere exists any underlying bias towards or against a certain disease. We used\nSentiWordNet to establish a gold sentiment standard for the data sets and\nevaluate performance of Word2Vec and Doc2Vec methods. We have shown that the\nWord2vec and Doc2Vec methods complement each other results in sentiment\nanalysis of the data sets.",
  "text": "Word2Vec and Doc2Vec in Unsupervised Sentiment Analysis of Clinical \nDischarge Summaries \n \nQufei Chen \nMarina Sokolova \nUniversity of Ottawa \nIBDA@Dalhousie University and  \nUniversity of Ottawa \nqchen037@uottawa.ca \nsokolova@uottawa.ca \n \nAbstract \n \nIn this study, we explored application of Word2Vec and Doc2Vec for sentiment analysis of clinical \ndischarge summaries. We applied unsupervised learning since the data sets did not have \nsentiment annotations. Note that unsupervised learning is a more realistic scenario than \nsupervised learning which requires an access to a training set of sentiment-annotated data. \nWe aim to detect if there exists any underlying bias towards or against a certain disease.   \nWe used SentiWordNet to establish a gold sentiment standard for the data sets and evaluate \nperformance of Word2Vec and Doc2Vec methods. We have shown that the Word2vec and \nDoc2Vec methods complement each other’s results in sentiment analysis of the data sets.   \nIntroduction \n \nSentiment analysis is the process of identifying opinions expressed in text. Most of the current \nresearch of sentiment analysis deals with subjective text, such as customer-written reviews or \nTwitter [7]. There is considerably less research of sentiment analysis of clinical text in the medical \ndomain. Sentiment analysis in clinical records is quite different from traditional methods. Clinical \nrecords are meant be written in an objective way. Most of the written text is descriptive rather \nthan opinionated – it is much more likely to find a sentence that reads “the patient presented with \nchest pain” rather than “the patient is doing really badly”. Most opinions are not directly stated, \nbut are rather subtle or even unintentional, and is often underlying in the word choice and \nmethod of writing of the text. This results in the number of sentiment terms expressed in the text \nto be rather low (5% - 11% in clinical narratives)(Denecke & Deng, 2015), consequently resulting in \na lower accuracy of sentiment analysis (Deng, Declerck, Lendvai, & Denecke, 2016). In addition, \nthe language used in clinical records is very formal and often contains an excess of medical terms \nand conditions that are not often found elsewhere. \n \nConsequences of detecting opinions in clinical text are also quite significant. It is very important to \nbe able to detect and address bias, especially when dealing with patient care. Identifying the \npresence of bias can serve to make sure that patients are not discriminated against due to their \nafflictions, and are all receiving equal quality care. If a bias towards a disease is detected, it can \nalso be indicative of a broader social view towards these diseases and people who are afflicted by \nthem. \n \nMost of the research on sentiment analysis of clinical records has been performed using lexical \nresources and dictionaries such as SentiWordNet (Esuli & Sebastiani, 2006), WordNetAffect \n(Strapparava & Valitutti, 2014), and MPQA (Wiebe, Wilson, & Cardie, 2005). While those resources \nwork well for identifying sentiment in highly opinionated text, they do not perform as well on \nclinical narratives (Deng, Stoehr, & Denecke, Retrieving Attitudes: Sentiment Analysis from Clinical \nNarratives, 2014). Another challenge for sentiment analysis of clinical records comes from a \nprohibitively high cost of sentiment annotations of a large set of clinical records. Thus, supervised \nlearning often becomes unfeasible as it is requires an access to a labeled training data. As a result, \nunsupervised learning from unlabeled data becomes the most realistic scenario in sentiment \nanalysis of clinical text.   \n \nThe objective of our study is to apply Word2Vec and Doc2Vec in unsupervised sentiment analysis \nof a set of clinical discharge summaries; the summaries are written by physicians and nurses. We \nuse SentiWordNet to establish a gold sentiment standard in a dataset. SentiWordNet is a state-of-\nthe-art sentiment lexicon that has been proven to have a reliable performance compared to other \nsentiment lexicons (Musto, Semeraro, & Polignano, 2014). We use SentiWordNet to detect the \noverall sentiment scores and sentiment ratios in our datasets. Using the results as our benchmarks, \nwe then evaluate performance of Word2Vec and Doc2Vec in identifying sentiments in those \ndatasets.  \n \nRelated Work \n \nSentiWordNet has proven to be a reliable sentiment Knowledge Base in several sentiment analysis \ncompetitions. It obtained the best performing resource when sentiment analysis was conducted \non the SemEval2013 dataset (Nakov, Kozareva, Ritter, Rosenthal, Stoyanov, & Wilson, 2013): \nSentiWordNet’s best accuracy was 58.99%, whereas the 2nd best accuracy 58.25% was obtained by \nMPQA. It again obtained the best accuracy on the Stanford Twitter Sentiment dataset (Go, \nBhayani, & Huang, 2009): SentiWordNet’s performance resulted in 72.42% accuracy, and the 2nd \nbest accuracy of 70.75% was again obtained by MPQA (Musto, Semeraro, & Polignano, 2014). \nThose and other similar results make SentiWordNet our first choice for establishing a gold \nsentiment standard for the data sets.  \n \nDeng et al [6] studied how physicians and nurses implicitly and explicitly express their judgments \nin patient records by using a sentiment lexicon to determine the sentiment of a document. The \nauthors counted the number of positive and negative occurrences in radiology reports and nurse \nletters, and then compared their results with manual annotations by clinical experts (Deng, Stoehr, \n& Denecke, Retrieving Attitudes: Sentiment Analysis from Clinical Narratives, 2014). The authors \ndefine sentiment as information relating the certainty of an observation, information on the \nhealth status, or outcome of a medical treatment. However, the accuracy of the proposed method \nwas only 42.0% on nurse letters and 44.6% radiology reports respectively. The authors concluded \nthat a simple method for sentiment analysis is not well suited to analyze sentiment in clinical \nnarratives. We, in other hand, apply advanced Word2Vec and Doc2Vec methods to analyze \nsentiments in clinical narratives.      \n \nSentiment analysis of tweets under a supervised learning framework has been studied in (Tang, \nWei, Yang, Zhou, Liu, & Qin). The authors aimed to learn sentiment specific word embeddings \n(SSWE), which encodes sentiment information into the word embedding representation. SSWE \noutperformed traditional neural network models such as Word2Vec on classifying sentiment since \ntraditional models cannot distinguish between words with opposite sentiment that occur in the \nsame context (such as good and bad). The accuracy of SSWE outperformed Word2Vec by about 10% \nfor both of the lexicons measured (Hu and Liu (Liu & Hu, 2004), MPQA (Wiebe, Wilson, & Cardie, \n2005)). Our study, however, differs in two critical ways: i) we work with clinical texts that contain \nmuch less sentiment terms than Twitter; ii) we apply unsupervised learning which is a more \nrealistic setting. It is also difficult to obtain access to a large dataset of sentiment labelled clinical \ndata that is required for supervised learning approaches.  \n \n \nData Set \n \nThe deidentified clinical records used in this research were provided by the i2b2 National Center \nfor Biomedical Computing funded by U54LM008748 and were originally prepared for the Shared \nTasks for Challenges in NLP for Clinical Data organized by Dr. Ozlem Uzuner, i2b2 and SUNY.  \nWe were given access to a number of different datasets created by the Informatics for Integrating \nBiology to the Bedside Center (i2b2).  \n \nWe have chosen the Obesity NLP Challenge Dataset. This dataset was created by i2b2 for a natural \nlanguage processing challenge focusing on the extraction of information on obesity and fifteen \nother common comorbidities (hereinafter referred to as diseases) (Uzuner, 2009). The reason for \nchoosing this dataset is due to the fact that obesity is a highly stigmatized condition in society, \nwith obese individuals often being discriminated against by society (Puhl & Heuer, 2009). It would \nbe important to observe if physicians and nurses exhibit the same bias in their clinical writings.   \n \nThe dataset consists of 1237 de-identified clinical discharge summaries written by physicians and \nnurses, as well as a set of annotations that specifies for each discharge summary the occurrence of \nany number of diseases. The annotations split the occurrence into four classes: Present, Absent, \nQuestionable, and Unknown.   \n \nFrom the given annotations, we were able to separate the discharge summaries into subsets that \ncorrespond to each disease. For the purposes of this study, we only used the occurrence class \nPresent as the criteria for determining the separation of subsets. This means that a discharge \nsummary is classified into a particular subset if and only if its class of occurrence for that disease is \nPresent. The number of discharge summaries associated with each disease is listed in Table 1.  \n \nAs we can see in Table 1, some diseases are not well represented (e.g. Venous Insufficiency and \nHypertriglyceridemia), containing too few discharge summaries with that disease being present. \nSuch datasets are too small to perform an accurate statistical and computational analysis on them. \nTherefore, for the purposes of this study we have chosen data sets corresponding to three \ndiseases:  \n \n1. Hypertension (the most prevalent disease) \n2. Diabetes (the second most prevalent) \n3. Obesity (known for having a negative stigma and the reason this dataset was chosen) \n \nEach set of discharge summaries relating to one of these diseases will be referred to as a subset.  \n \n \nTable 1: Frequency Distribution of Diseases \nAnnotated Disease Number of Summaries \nHypertension \n816 \nDiabetes \n737 \nAtherosclerotic CV disease (CAD) \n610 \nHypercholesterolemia \n459 \nHeart failure (CHF) \n444 \nObesity \n443 \nGallstones \n178 \nOsteoarthritis (OA) \n175 \nGERD \n167 \nDepression \n158 \nObstructive sleep apnea (OSA) \n157 \nPeripheral vascular disease (PVD) \n147 \nAsthma \n143 \nGout \n123 \nHypertriglyceridemia \n25 \nVenous Insufficiency \n24 \n \n \nWe performed information extraction with the aid of the Python pandas library, an open source \npython data processing tool (https://pandas.pydata.org/). We were able to extract the discharge \nsummaries corresponding to each dataset by using data frames to cross-reference the discharge \nsummary ID with the IDs in the annotations files. We then sorted the subsets in order of their \ndescending frequency.  \n \nThrough manual analysis of the distribution of discharge summaries in each subset, we observed \nthat many discharge summaries are associated with more than one disease or condition (e.g. \nobesity and diabetes). Taking into account disease combinations allows a finer-grade sentiment \nanalysis.   \n \nTherefore, in addition to the discharge summaries for the three chosen diseases (i.e., hypertension, \ndiabetes, and obesity), we will also be taking their set differences (discharge summaries belonging \nto set A but not set B) as well as their intersections (discharge summaries belonging to both set A \nand set B) as additional subsets. The resulting twelve subsets along with the number of summaries \nare shown in Table 2. These are the twelve subsets that will be used for the upcoming \nexperiments in Section Knowledge Base and Methods.  \n \n \nTable 2: Summary distribution in the subsets \nAnnotated Disease Number of Summaries \nHypertension 816 \nDiabetes 737 \nObesity 443 \nHypertension and Diabetes 595 \nDiabetes and not Hypertension 142 \nHypertension and not Diabetes 221 \nObesity and Diabetes 258 \nDiabetes and not Obesity 479 \nObesity and not Diabetes 185 \nObesity and Hypertension 332 \nHypertension and not Obesity 484 \nObesity and not Hypertension 111 \n \n \nData Preprocessing \n \nThe preprocessing of the data was done in Python with the aid of the Natural Language Toolkit \n(NLTK) (https://www.nltk.org/). First, we removed all of the formatting text and special characters \nfrom each discharge summary. We then tokenized the remaining discharge summary text. Stop \nwords were also removed using NLTK’s English stop words corpus \n(https://www.nltk.org/book/ch02.html). On the next step of preprocessing, we had to decide \nwhether we use stemming or lemmatization to further process the data. \n \nStemming is the procedure of using a crude heuristic process to chop off the end of a word, for the \ngoal of reducing words in an inflectional or derivational form down to its base form (Manning, \n2009). Stemming algorithms usually consists of a static series of steps that are applied to a word to \ntransform it. Lemmatization on the other hand, uses a dictionary and the morphological analysis \nof words in order to return the base dictionary form of a word (known as a lemma) (Manning, \n2009). Lemmas themselves are words that can be found in a dictionary, whereas the result of \nstemming can and often result in terms that are not standalone English words. For example, when \napplying a stemming algorithm, the word see would just return s, while lemmatization would \nreturn either see or saw.  \n \nIn deciding between stemming and lemmatization, we recalled that our knowledge base \nSentiWordNet contains sentiments for English dictionary words in WordNet’s database \n(https://wordnet.princeton.edu/). Therefore, occurrence of too many inflectional or derivational \nforms may not be recognized by SentiWordNet. Similarly, occurrence of too many stem terms that \nare not proper English words is also not beneficial, since these terms will not be recognized by \nSentiWordNet either. \n \nWe tested the result of performing sentiment analysis with SentiWordNet on the datasets with \nstemming using the Porter Stemming Algorithm (https://tartarus.org/martin/PorterStemmer/) and \nlemmatization separately, and compared them to the original data (with no stemming and no \nlemmatization) to observe the effects. The results reported in Table 3 show that stemming results \nin the least number of terms being matched to sentiments in SentiWordNet at an average of only \n20.77%, and lemmatization having the best result with an average of 32.04% of terms matched. \nFrom the results of this test, we have decided to continue with the lemmatized datasets for the \nrest of the analysis.  \n \nTable 3: The effects of Stemming and Lemmatization on the percentage of term matches of each \ndataset in SentiWordNet \nDataset \nPercentage of Terms Matched in Dataset \n Original Data \nStemming \nLemmatization \nHypertension \n0.2127 \n0.1553 \n0.2328 \nObesity not Hypertension \n0.3605 \n0.1596 \n0.3632 \nDiabetes not Obesity \n0.2479 \n0.2026 \n0.2756 \nObesity not Diabetes \n0.3206 \n0.2321 \n0.4564 \nHypertension not Obesity \n0.2474 \n0.2026 \n0.2426 \nDiabetes \n0.2214 \n0.1909 \n0.3757 \nDiabetes not Hypertension \n0.3394 \n0.2026 \n0.2794 \nObesity \n0.2563 \n0.2536 \n0.2825 \nHypertension and Diabetes \n0.2666 \n0.1846 \n0.2763 \nObesity and Hypertension \n0.2666 \n0.2780 \n0.2996 \nObesity and Diabetes \n0.2666 \n0.2465 \n0.4045 \nHypertension not Diabetes \n0.3062 \n0.1837 \n0.3566 \nAverage Percent Matched \n0.2760 \n0.2077 \n0.3204 \n \n \nAfter lemmatizing the terms in the datasets, we then proceeded to use WordNet to perform part \nof speech tagging on each term to prepare them for use with SentiWordNet. \nKnowledge Base and Methods Used \n \nIn this study, we will first be using SentiWordNet to determine the overall sentiment scores of \neach subset, as well as their sentiment ratios which we determine as the proportion of positive \nterms to negative terms in each dataset. We will then be constructing a Word2Vec model of the \ndata, as well as a Doc2Vec Model of the data, and then compute the cosine similarities of each \nsubset against the other subsets using both the Word2Vec model and the Doc2Vec model.  \n \nSentiWordNet \n \nSentiWordNet is a lexical resource used for opinion mining created by Esuli and Sebastiani (2006). \nIt is based on WordNet, a lexical database for the English language that groups words together \ninto sets of synonyms (called synsets). SentiWordNet works on top of that by assigning each \nsynset in WordNet three sentiment scores: a Positive score, a Negative score, and an objective \nscore. The positive score and the negative score make up the subjective portion of the word, and \nthe objective score is calculated by taking one minus the sum of the positive and negative scores \n(in other words, the objective scores is equal to one minus the total subjective component of the \nword). For example, the term breakdown contains a positive score of 0, a negative score of 0.25, \nand an objective score of 0.75. For each of the twelve subsets listed in Table 2, we used \nSentiWordNet to evaluate the sentiment of each term in the subset, and then calculated the \naverage score for the Positive sentiment, the Negative sentiment, and the Objective sentiment. \nThe resulting sentiment scores are shown in Table 4. \n \nWe can see from Table 4 that the majority of each dataset is comprised of objective sentiments \n(approx. 90% for each dataset), while the positive and negative scores are significantly lower, but \nwith minute differences. This is an expected outcome, since clinical narratives are meant to be \nwritten in an objective manner, and therefore less subjective terms should be expected. But to \nproperly compare the scores, we need to analyze if the proportion of subjective (positive and \nnegative) terms are equally distributed between subsets.  \n \nTable 4: Average SentiWordNet sentiment scores of each dataset \n Data Subset \nPositive \nScore \nNegative \nScore \nObjective \nScore \nOverall Sentiment \n(Negative Score – Positive \nScore) \nHypertension not obesity \n0.0521 \n0.0698 \n0.8781 \n0.0178 \nDiabetes not obesity \n0.0507 \n0.0708 \n0.8786 \n0.0201 \nDiabetes not hypertension \n0.0518 \n0.0725 \n0.8757 \n0.0207 \ndiabetes \n0.0510 \n0.0717 \n0.8773 \n0.0208 \nHypertension and diabetes \n0.0500 \n0.0710 \n0.8790 \n0.0209 \nhypertension \n0.0506 \n0.0719 \n0.8775 \n0.0213 \nObesity not hypertension \n0.0512 \n0.0728 \n0.8760 \n0.0216 \nObesity and diabetes \n0.0507 \n0.0724 \n0.8769 \n0.0217 \nobesity \n0.0495 \n0.0720 \n0.8785 \n0.0225 \nObesity not diabetes \n0.0503 \n0.0736 \n0.8761 \n0.0233 \nHypertension not diabetes \n0.0484 \n0.0729 \n0.8787 \n0.0245 \nObesity and hypertension \n0.0487 \n0.0747 \n0.8765 \n0.0260 \nOverall Average \n0.0504 \n0.0722 \n0.8774 \n0.0218 \n \n \nFigure 1 shows the percentage of positive and negative scores of each subset plotted against each \nother. We can see from this graph that there are certain datasets that have a higher than average \nnegative score combined with a lower than average positive score (such as the dataset obesity and \nhypertension). This could be indicative of a negative bias in relation to the other subsets. In \ncontrast, the opposite behavior can also be observed – the dataset hypertension not obesity \ncontains a lower than average negative sentiment score combined with a higher than average \npositive sentiment score. This could be indicative of a positive bias in relation to the other data \nsets.  \n \nAs we can observe from Figure 1, the most negative overall sentiment occurs when the difference \nbetween the negative score and the positive score is high. Similarly, the most positive overall \nsentiment occurs when that difference is small. Thus, we can deduce that the overall relative \nsentiment of each subset can be obtained through taking the difference between the negative \nsentiment and the positive sentiment.  \n \nThe overall sentiment of each subset is obtained by taking the difference of the negative \nsentiment score and the positive sentiment score for each subset; we plot them on Figure 2. The \noverall sentiment scores can also be found in Table 4. We can see from these results that the \nobesity and hypertension dataset has the most negative overall sentiment, with the subset obesity \nbeing the second most negative, and the subset hypertension not diabetes being the third most \nnegative. In contrast, the hypertension not obesity subset has the most positive overall sentiment.  \n \n \nFigure 1: Percentage of negative vs. positive SentiWordNet scores \n \n \n0.0670\n0.0680\n0.0690\n0.0700\n0.0710\n0.0720\n0.0730\n0.0740\n0.0750\n0.0760\n0.0460\n0.0470\n0.0480\n0.0490\n0.0500\n0.0510\n0.0520\n0.0530hypertension_not_obesitydiabetes_not_obesitydiabetes_not_hypertensiondiabeteshypertension_and_diabeteshypertensionobesity_not_hypertensionobesity_and_diabetesobesity_not_diabeteshypertension_not_diabetesobesityobesity_and_hypertension\nPercent (%) Positive \nPositive\nNegative\n \n \n \nFigure 2: SentiWordNet overall sentiment (calculated by taking the difference of negative and \npositive SentiWordNet score of each dataset) \n \n \nWe also extracted the frequency of words of each sentiment in each subset. From these \nfrequencies, we generated the ratio of positive terms to negative terms of each dataset. We \nreport the raw frequency of positive and negative terms as well as their ratios in Table 5. The \nsubsets are sorted from the smallest ratio of negative terms to the largest ratio. We can see from \nthe data that the positive ratio and negative ratio have an inverse relationship. This relationship is \nplotted in Figure 3.  \n \nFrom Table 5, we can observe that the subset obesity not hypertension contains the highest ratio \nof positive terms combined with the lowest ratio of negative terms. This indicates that once again \nthis subset has the overall most positive sentiment. Similarly, the subset obesity and hypertension \ncontains the highest ratio of negative terms combined with the lowest ratio of positive terms, thus \nindicating that it possesses the most negative overall sentiment of all the datasets. \n \nThe overall sentiment ranking of a few subsets according to the ratio of positive and negative \nterms differs slightly from their overall SentiWordNet sentiment scores. The subset obesity not \nhypertension has the highest positive ratio and the lowest negative ratio, yet it contains an \naverage overall sentiment score in relation the rest of the datasets. This could indicate that \nalthough this dataset contains a large proportion of positive terms, the strengths of those terms \nare not very high.   \n \n \n \n0.0150\n0.0170\n0.0190\n0.0210\n0.0230\n0.0250\n0.0270hypertension_not_obesitydiabetes_not_obesitydiabetes_not_hypertensiondiabeteshypertension_and_diabeteshypertensionobesity_not_hypertensionobesity_and_diabetesobesity_not_diabeteshypertension_not_diabetesobesityobesity_and_hypertension\nDifference (%) \nTable 5: Ratio of Positive and negative SentiWordNet terms extracted from each subset \nDataset \nNumber of \nPositive \nterms \nNumber of \nNegative terms \nRatio  \nPositive (%) \nRatio  \nNegative (%) \nObesity not hypertension \n2636 \n2708 \n0.4933 \n0.5067 \nHypertension not obesity \n4322 \n4447 \n0.4929 \n0.5071 \nDiabetes not hypertension \n2931 \n3016 \n0.4929 \n0.5071 \nDiabetes not obesity \n4321 \n4467 \n0.4917 \n0.5083 \ndiabetes \n4941 \n5114 \n0.4914 \n0.5086 \nHypertension and \ndiabetes \n4597 \n4768 \n0.4909 \n0.5091 \nObesity not diabetes \n3006 \n3122 \n0.4905 \n0.5095 \nhypertension \n4971 \n5163 \n0.4905 \n0.5095 \nObesity and diabetes \n3503 \n3657 \n0.4892 \n0.5108 \nHypertension not diabetes \n3186 \n3338 \n0.4884 \n0.5116 \nobesity \n4142 \n4341 \n0.4883 \n0.5117 \nObesity and hypertension \n3744 \n3948 \n0.4867 \n0.5133 \nOverall Average \n3858.33 \n4007.42 \n0.49 \n0.51 \nFigure 3: Ratio of Positive and Negative terms of each dataset \n \n \n \nWord2Vec \n \nWord2Vec is group of unsupervised shallow two-layer neural network models developed by \nMikolov et al that produces word embeddings (Mikolov, Chen, Corrado, & Dean, 2013). Word \n0.4800\n0.4850\n0.4900\n0.4950\n0.5000\n0.5050\n0.5100\n0.5150obesity_not_hypertensionhypertension_not_obesitydiabetes_not_hypertensiondiabetes_not_obesitydiabeteshypertension_and_diabetesobesity_not_diabeteshypertensionobesity_and_diabeteshypertension_not_diabetesobesityobesity_and_hypertension\nPercentage \npos%\nneg%\nembeddings are the numeric representation of words in the form of vectors. Word2Vec produces \nword embeddings based on the contextual semantics of words in a text (based on the context that \nthe word occurs in). Words with similar linguistic contexts are mathematically grouped together in \na vector space, which preserves the semantic relationship between words. Word2Vec can then \nuse these word embeddings to produce predictions on a word’s meaning.  \n \n \nThere are two model architectures of Word2Vec that can be used:  \n- \nSkip-Gram model \n- \nContinuous Bag-of-Words model (CBOW)  \n \nThe skip-gram model takes in a word as input and aims to predict a target context, while the \ncontinuous bag of words method takes in a context as input and aims to predict a specific word \n(Deep Learning for Java, 2017). Since we would like to learn the contexts of the words in the data \nsets, we will be employing the continuous bag-of-words model.  \n \nCosine similarity measures the difference between vectors based on the cosine of the angle \nbetween the vectors while normalizing for length (Manning, 2009). This results in a measure for \nthe difference in orientation of the vectors in the vector space rather than a measure of \nmagnitude. We trained a continuous bag-of-words Word2Vec model on the entire dataset (1237 \ndocuments) and then proceeded to calculate the cosine similarity between each pair of subsets. \nThe input vector for each subset consisted of all the terms in that subset.  \n \nTable 6: Word2Vec and Doc2Vec corpus sizes \nDataset/Model Corpus Size (Number of Terms) \nComplete Training Dataset \n804152 \nTrained Word2Vec Model Vocabulary \n7584 \nTrained Doc2Vec Model Vocabulary \n12927 \nObesity and Diabetes \n213968 \nHypertension not Diabetes \n124385 \nHypertension \n525672 \nDiabetes not Hypertension \n91237 \nHypertension not Obesity \n311704 \nObesity not Hypertension \n62745 \nObesity not Diabetes \n101089 \nDiabetes not Obesity \n316900 \nDiabetes  \n492524 \nObesity and Hypertension \n213968 \nObesity \n276713 \nHypertension and Diabetes \n213968 \n \n \nThe corpus size of the training dataset and the vocabulary sizes of all the subsets used for \nevaluation are listed in Table 6. These exact datasets are used for the training and evaluation of \nboth the Word2Vec model and the Doc2Vec model (presented later in this paper). The resulting \nvocabulary sizes of the trained Word2Vec and Doc2Vec models are also listed in Table 6. Further \nwe will use unique subset ID in lieu of its full descriptive name; the IDs are listed in Table 7.  \n \n \nTable 7: Dataset IDs \nData Subset Name ID \nObesity 1 \nHypertension 2 \nDiabetes 3 \nObesity and Hypertension 4 \nObesity not Hypertension 5 \nHypertension not Obesity 6 \nObesity and Diabetes 7 \nObesity not Diabetes 8 \nDiabetes not Obesity 9 \nHypertension and Diabetes 10 \nHypertension not Diabetes 11 \nDiabetes not Hypertension 12 \n \n \nTable 8: Word2Vec cosine similarity between datasets \nID \n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10 \n11 \n12 \n1 \n1.0000 \n0.9987 \n0.9977 \n0.9986 \n0.9831 \n0.9955 \n0.9989 \n0.9966 \n0.9954 \n0.9980 \n0.9947 \n0.9892 \n2 \n0.9987 \n1.0000 \n0.9994 \n0.9972 \n0.9820 \n0.9987 \n0.9981 \n0.9945 \n0.9986 \n0.9996 \n0.9953 \n0.9916 \n3 \n0.9977 \n0.9994 \n1.0000 \n0.9957 \n0.9828 \n0.9987 \n0.9982 \n0.9913 \n0.9995 \n0.9997 \n0.9922 \n0.9942 \n4 \n0.9986 \n0.9972 \n0.9957 \n1.0000 \n0.9722 \n0.9922 \n0.9985 \n0.9936 \n0.9927 \n0.9972 \n0.9912 \n0.9821 \n5 \n0.9831 \n0.9820 \n0.9828 \n0.9722 \n1.0000 \n0.9855 \n0.9788 \n0.9855 \n0.9836 \n0.9791 \n0.9855 \n0.9925 \n6 \n0.9955 \n0.9987 \n0.9987 \n0.9922 \n0.9855 \n1.0000 \n0.9946 \n0.9919 \n0.9995 \n0.9980 \n0.9948 \n0.9949 \n7 \n0.9989 \n0.9981 \n0.9982 \n0.9985 \n0.9788 \n0.9946 \n1.0000 \n0.9917 \n0.9958 \n0.9987 \n0.9899 \n0.9893 \n8 \n0.9966 \n0.9945 \n0.9913 \n0.9936 \n0.9855 \n0.9919 \n0.9917 \n1.0000 \n0.9896 \n0.9915 \n0.9982 \n0.9838 \n9 \n0.9954 \n0.9986 \n0.9995 \n0.9927 \n0.9836 \n0.9995 \n0.9958 \n0.9896 \n1.0000 \n0.9988 \n0.9920 \n0.9955 \n10 \n0.9980 \n0.9996 \n0.9997 \n0.9972 \n0.9791 \n0.9980 \n0.9987 \n0.9915 \n0.9988 \n1.0000 \n0.9920 \n0.9913 \n11 \n0.9947 \n0.9953 \n0.9922 \n0.9912 \n0.9855 \n0.9948 \n0.9899 \n0.9982 \n0.9920 \n0.9920 \n1.0000 \n0.9862 \n12 \n0.9892 \n0.9916 \n0.9942 \n0.9821 \n0.9925 \n0.9949 \n0.9893 \n0.9838 \n0.9955 \n0.9913 \n0.9862 \n1.0000 \n \n \n \nThe results of the cosine similarity between the terms of each subset are shown in Table 8. We can \nsee that all the scores are very similar, with very high values around 0.99. This indicates that the \nsimilarity of the terms in each subset to all other subsets is very high. From Table 8, we can \nobserve that the datasets with the highest cosine similarity are subset 10 (Hypertension and \nDiabetes) and subset 3 (Diabetes) with a 0.9997 cosine similarity. The subsets with the lowest \ncosine similarity are subset 5 (Obesity not Hypertension) and subset 4 (Obesity and Hypertension) \nwith a 0.9722 cosine similarity. In Table 8, the subsets with the highest similarities are highlighted \nin green while the subsets with the lowest similarities are highlighted in orange.  \n \nDoc2Vec \n \nDoc2Vec is an extension of Word2Vec that is applied to a document as a whole instead of \nindividual words. This model was developed by Le and Mikolov, and aims to create a numerical \nrepresentation of a document rather than a word (Le & Mikolov, 2014). Doc2Vec operates on the \nlogic that the meaning of a word also depends on the document that it occurs in. The vectors \ngenerated by Doc2Vec can be used for finding similarities between documents. We trained a \nDoc2Vec model on all of the discharge summaries in the complete dataset (1237 discharge \nsummaries), and then proceeded to convert each subset into its word embedding representation \n(also known as an inferred vector). We then computed the cosine similarities between each pair of \nsubsets. The results of the cosine similarities scores between subsets are shown in Table 9.  \n \nTable 9: Doc2Vec cosine similarity scores between datasets \n \nID \n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10 \n11 \n12 \n1 \n1.0000 \n0.7943 \n0.8116 \n0.9229 \n0.6842 \n0.5638 \n0.8976 \n0.7973 \n0.6670 \n0.7750 \n0.6681 \n0.5548 \n2 \n0.7943 \n1.0000 \n0.8921 \n0.7697 \n0.7349 \n0.7927 \n0.7781 \n0.7538 \n0.8122 \n0.8950 \n0.6308 \n0.6643 \n3 \n0.8116 \n0.8921 \n1.0000 \n0.8280 \n0.6241 \n0.7233 \n0.8248 \n0.6292 \n0.7866 \n0.9623 \n0.5121 \n0.6806 \n4 \n0.9229 \n0.7697 \n0.8280 \n1.0000 \n0.6146 \n0.5868 \n0.9430 \n0.7833 \n0.7031 \n0.8026 \n0.6045 \n0.5341 \n5 \n0.6842 \n0.7349 \n0.6241 \n0.6146 \n1.0000 \n0.6180 \n0.6774 \n0.6585 \n0.6641 \n0.6213 \n0.7058 \n0.7288 \n6 \n0.5638 \n0.7927 \n0.7233 \n0.5868 \n0.6180 \n1.0000 \n0.6335 \n0.5787 \n0.9020 \n0.7281 \n0.6502 \n0.6470 \n7 \n0.8976 \n0.7781 \n0.8248 \n0.9430 \n0.6774 \n0.6335 \n1.0000 \n0.7484 \n0.7191 \n0.7904 \n0.6660 \n0.6074 \n8 \n0.7973 \n0.7538 \n0.6292 \n0.7833 \n0.6585 \n0.5787 \n0.7484 \n1.0000 \n0.6062 \n0.6724 \n0.7722 \n0.3546 \n9 \n0.6670 \n0.8122 \n0.7866 \n0.7031 \n0.6641 \n0.9020 \n0.7191 \n0.6062 \n1.0000 \n0.7842 \n0.6192 \n0.7292 \n10 \n0.7750 \n0.8950 \n0.9623 \n0.8026 \n0.6213 \n0.7281 \n0.7904 \n0.6724 \n0.7842 \n1.0000 \n0.5520 \n0.6708 \n11 \n0.6681 \n0.6308 \n0.5121 \n0.6045 \n0.7058 \n0.6502 \n0.6660 \n0.7722 \n0.6192 \n0.5520 \n1.0000 \n0.4814 \n12 \n0.5548 \n0.6643 \n0.6806 \n0.5341 \n0.7288 \n0.6470 \n0.6074 \n0.3546 \n0.7292 \n0.6708 \n0.4814 \n1.0000 \n \n \n \nFrom Table 9, we can observe that the most similar pair of subsets are subset 10 (Hypertension \nand Diabetes) and subset 3 (Diabetes) with a cosine similarity score of 0.9623. The least similar \npair of subsets are subset 12 (Diabetes not Hypertension) and subset 8 (Obesity not Diabetes) with \na cosine similarity score of 0.3546. In Table 9, the subsets with the highest similarities are \nhighlighted in green while the subsets with the lowest similarities are highlighted in orange.  \n \nAnalysis of Results \n \nWe performed a statistical analysis on the SentiWordNet sentiment scores in order to evaluate \nwhether or not the results were statistically significant. We performed an independent two-\nsample Welch’s t-test on the SentiWordNet sentiment scores between each pair of subsets. \nThe Welch’s t-test is a variation of the Student’s t-test. It performs better than the Student’s t-test \nwhen the samples being compared have unequal variances and sample sizes, and performs the \nsame as the Student’s t-test when the variances and sample sizes are equal (Lakens, 2015). Since \nall our subsets are of different sizes, and we cannot assume equal variance between subsets, we \nperformed an independent two-sample Welch’s t-test on each pair of subsets for the positive \nsentiment score, the negative sentiment score, and the overall sentiment score. \n \nOur null hypothesis for each test is that the means of both samples are equal (μ1 = μ2). The p-value \nof each test represents the probability of finding the observed results when the null hypothesis is \ntrue – in other words, it represents the smallest level of significance at which the null hypothesis \ncan be rejected (Investopedia). We used the Welch’s t-test function in the statistics module of \nSciPy, an open source python library for scientific computing (www.scipy.org), to calculate the p-\nvalues. \n \n The results of the Welch’s t-test are shown in Table 10, Table 11, and Table 12.  \nTable 10: Welch’s t-test p-value results for SentiWordNet positive sentiment \nID \n1 \n1 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10 \n11 \n12 \n1 \n1.000 \n0.307 \n0.291 \n0.952 \n0.581 \n0.553 \n0.837 \n0.850 \n0.457 \n0.798 \n0.876 \n0.365 \n2 \n0.307 \n1.000 \n0.967 \n0.294 \n0.746 \n0.689 \n0.449 \n0.465 \n0.804 \n0.441 \n0.436 \n0.988 \n3 \n0.291 \n0.967 \n1.000 \n0.279 \n0.721 \n0.662 \n0.429 \n0.446 \n0.775 \n0.421 \n0.417 \n0.984 \n4 \n0.952 \n0.294 \n0.279 \n1.000 \n0.554 \n0.526 \n0.796 \n0.810 \n0.435 \n0.757 \n0.835 \n0.349 \n5 \n0.581 \n0.746 \n0.721 \n0.554 \n1.000 \n0.978 \n0.727 \n0.731 \n0.918 \n0.738 \n0.704 \n0.761 \n6 \n0.553 \n0.689 \n0.662 \n0.526 \n0.978 \n1.000 \n0.719 \n0.725 \n0.882 \n0.729 \n0.694 \n0.715 \n7 \n0.837 \n0.449 \n0.429 \n0.796 \n0.727 \n0.719 \n1.000 \n0.994 \n0.615 \n0.972 \n0.967 \n0.495 \n8 \n0.850 \n0.465 \n0.446 \n0.810 \n0.731 \n0.725 \n0.994 \n1.000 \n0.625 \n0.967 \n0.974 \n0.506 \n9 \n0.457 \n0.804 \n0.775 \n0.435 \n0.918 \n0.882 \n0.615 \n0.625 \n1.000 \n0.618 \n0.594 \n0.817 \n10 \n0.798 \n0.441 \n0.421 \n0.757 \n0.738 \n0.729 \n0.972 \n0.967 \n0.618 \n1.000 \n0.938 \n0.493 \n11 \n0.876 \n0.436 \n0.417 \n0.835 \n0.704 \n0.694 \n0.967 \n0.974 \n0.594 \n0.938 \n1.000 \n0.480 \n12 \n0.365 \n0.988 \n0.984 \n0.349 \n0.761 \n0.715 \n0.495 \n0.506 \n0.817 \n0.493 \n0.480 \n1.000 \n \n \n \nTable 11: : Welch’s t-test p-value results for SentiWordNet negative sentiment \nID \n1 \n1 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10 \n11 \n12 \n1 \n1.000 \n0.771 \n0.736 \n0.614 \n0.983 \n0.376 \n0.897 \n0.817 \n0.546 \n0.574 \n0.852 \n0.924 \n2 \n0.771 \n1.000 \n0.960 \n0.419 \n0.818 \n0.530 \n0.885 \n0.982 \n0.738 \n0.773 \n0.644 \n0.870 \n3 \n0.736 \n0.960 \n1.000 \n0.395 \n0.787 \n0.564 \n0.849 \n0.948 \n0.775 \n0.811 \n0.614 \n0.836 \n4 \n0.614 \n0.419 \n0.395 \n1.000 \n0.642 \n0.170 \n0.540 \n0.492 \n0.273 \n0.288 \n0.773 \n0.578 \n5 \n0.983 \n0.818 \n0.787 \n0.642 \n1.000 \n0.455 \n0.926 \n0.851 \n0.614 \n0.641 \n0.853 \n0.947 \n6 \n0.376 \n0.530 \n0.564 \n0.170 \n0.455 \n1.000 \n0.472 \n0.571 \n0.777 \n0.737 \n0.314 \n0.480 \n7 \n0.897 \n0.885 \n0.849 \n0.540 \n0.926 \n0.472 \n1.000 \n0.915 \n0.653 \n0.683 \n0.764 \n0.980 \n8 \n0.817 \n0.982 \n0.948 \n0.492 \n0.851 \n0.571 \n0.915 \n1.000 \n0.754 \n0.786 \n0.697 \n0.900 \n9 \n0.546 \n0.738 \n0.775 \n0.273 \n0.614 \n0.777 \n0.653 \n0.754 \n1.000 \n0.961 \n0.455 \n0.651 \n10 \n0.574 \n0.773 \n0.811 \n0.288 \n0.641 \n0.737 \n0.683 \n0.786 \n0.961 \n1.000 \n0.477 \n0.680 \n11 \n0.852 \n0.644 \n0.614 \n0.773 \n0.853 \n0.314 \n0.764 \n0.697 \n0.455 \n0.477 \n1.000 \n0.793 \n12 \n0.924 \n0.870 \n0.836 \n0.578 \n0.947 \n0.480 \n0.980 \n0.900 \n0.651 \n0.680 \n0.793 \n1.000 \n \n \nTable 12: Welch’s t-test p-value results for SentiWordNet overall sentiment  \nID \n1 \n1 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10 \n11 \n12 \n1 \n1.000 \n0.450 \n0.377 \n0.725 \n0.561 \n0.116 \n0.547 \n0.682 \n0.309 \n0.399 \n0.802 \n0.431 \n2 \n0.450 \n1.000 \n0.892 \n0.274 \n0.960 \n0.384 \n0.924 \n0.796 \n0.770 \n0.919 \n0.661 \n0.895 \n3 \n0.377 \n0.892 \n1.000 \n0.224 \n0.871 \n0.463 \n0.827 \n0.707 \n0.873 \n0.974 \n0.578 \n0.989 \n4 \n0.725 \n0.274 \n0.224 \n1.000 \n0.382 \n0.061 \n0.357 \n0.472 \n0.181 \n0.240 \n0.568 \n0.277 \n5 \n0.561 \n0.960 \n0.871 \n0.382 \n1.000 \n0.439 \n0.974 \n0.860 \n0.769 \n0.893 \n0.743 \n0.873 \n6 \n0.116 \n0.384 \n0.463 \n0.061 \n0.439 \n1.000 \n0.373 \n0.312 \n0.575 \n0.448 \n0.229 \n0.530 \n7 \n0.547 \n0.924 \n0.827 \n0.357 \n0.974 \n0.373 \n1.000 \n0.875 \n0.718 \n0.852 \n0.748 \n0.836 \n8 \n0.682 \n0.796 \n0.707 \n0.472 \n0.860 \n0.312 \n0.875 \n1.000 \n0.611 \n0.731 \n0.877 \n0.727 \n9 \n0.309 \n0.770 \n0.873 \n0.181 \n0.769 \n0.575 \n0.718 \n0.611 \n1.000 \n0.849 \n0.491 \n0.900 \n10 \n0.399 \n0.919 \n0.974 \n0.240 \n0.893 \n0.448 \n0.852 \n0.731 \n0.849 \n1.000 \n0.601 \n0.966 \n11 \n0.802 \n0.661 \n0.578 \n0.568 \n0.743 \n0.229 \n0.748 \n0.877 \n0.491 \n0.601 \n1.000 \n0.610 \n12 \n0.431 \n0.895 \n0.989 \n0.277 \n0.873 \n0.530 \n0.836 \n0.727 \n0.900 \n0.966 \n0.610 \n1.000 \n \n \nThe lowest p-value for each test is highlighted in orange. Table 10 lists the p-values of the Welch’s \nt-test for the SentiWordNet positive sentiment scores. The lowest p-value observed is 0.291 \nbetween subset 1 (Obesity) and subset 3 (Diabetes). This is a very high p-value, indicating that 29.1% \nof the time we would accept the null hypothesis. Or in other words, there is only a 70.9% chance \nthat the difference is statistically significant. \n \n Table 11 lists the p-values of the Welch’s t-test for the SentiWordNet negative sentiment scores. \nThe lowest p-value observed is 0.170 between subset 4 (Obesity and Hypertension) and subset 6 \n(Hypertension not Obesity). Although this p-value is better than the p-value for the positive \nsentiment score, there is still only an 83.0% chance that the difference is statistically significant.  \n \nTable 12 lists the p-values of the Welch’s t-test for the SentiWordNet overall sentiment scores. We \ncan observe that the lowest p-value is 0.061, and occurs again between subset 4 (Obesity and \nHypertension) and subset 6 (Hypertension not Obesity). This p-value indicates that there is a 93.9% \nchance that the difference is statistically significant. Although this value is not quite 95% (the \naccepted standard), it is still considered quite high since it is below 0.1. \n \nRecall that from Figure 2 we can discern that the subset Obesity and Hypertension possesses the \nmost negative overall sentiment, while the subset Hypertension not Obesity possesses the most \npositive overall sentiment. Through conducting a Welch’s t-test, we have determined that the \ndifference between these two datasets have a 93.9% chance of being statistically significant. \n \nDiscussion of Sentiments \n \nWe aim to empirically analyze the sentiment agreement (Cagan, Frank, & Tsarfaty, 2017) between \nWord2Vec, Doc2Vec, and SentiWordNet. We examine the most similar and the most different in \nsentiment pairs of subsets produced by each of these methods.  \n \nMost Similar Subsets. When determining the most similar in sentiment pair of subsets from the \ndata, the Doc2Vec cosine similarity score, Word2Vec cosine similarity score, the SentiWordNet \nsentiment score, and SentiWordNet sentiment ratios all show the same result: the most similar \npair of subsets are subset 10 (Hypertension and Diabetes) and subset 3 (Diabetes). The \ncharacteristics of these two subsets are summarized in Table 13.  \n \n \nTable 13: Most Similar subsets \n \nMost Similar Subsets \nDataset Hypertension and Diabetes \n (ID = 10) \nDiabetes  \n(ID = 3) \nDoc2Vec Score 0.9623 \nWord2Vec Score 0.9997 \nSentiWordNet Positive Score 0.0500 \n0.510 \nSentiWordNet Negative Score 0.0710 \n0.0717 \nSentiWordNet Overall Score 0.0209 \n0.0208 \nWelch’s t-test positive p-value 0.421 \nWelch’s t-test negative p-value 0.811 \nWelch’s t-test overall p-value 0.974 \nSentiWordNet positive terms 4597 \n4941 \nSentiWordNet negative terms 4768 \n5114 \nSentiWordNet positive terms ratio 0.4909 \n0.4914 \nSentiWordNet negative terms \nratio 0.5091 \n0.5086 \n \n \nWe can observe from the Doc2Vec cosine similarity results (shown in Table 9) that the most \nsimilar pair of subset 10 (Hypertension and Diabetes) and subset 3 (Diabetes) has a cosine \nsimilarity score of 0.9623. The corresponding Word2Vec cosine similarity scores (shown in Table 8) \nfor these two datasets is 0.9997, which is also the highest Word2Vec cosine similarity score \nobserved out of all pairs of subsets. This indicates that these two datasets are the two most similar \nsubsets according to the Doc2Vec model and Word2Vec model.  \n \nAs shown in Table 13, the SentiWordNet sentiment scores for these two subsets are very similar \n(the subset Hypertension and Diabetes having an overall sentiment of 0.0209 and the subset \nDiabetes having an overall sentiment score of 0.0208). In Figure 2 we can actually see that the \nsubset Hypertension and Diabetes and the subset Diabetes lie right next to each other on the plot, \nwith the subset Diabetes having the fourth most positive sentiment, and the subset Hypertension \nand Diabetes having the fifth most positive sentiment. The difference between their overall \nsentiment scores is only 0.001. In fact, these two subsets are tied for the most similar overall \nsentiment (the pair of subsets Diabetes and Diabetes and not Hypertension also have the same \noverall sentiment difference of 0.0001).  \n \nWhen examining the results of a Welch’s t-test on the sentiment scores of these two datasets, we \ncan observe that the p-value for the positive sentiment score is 0.421, the p-value for the negative \nsentiment score is 0.811, and the p-value for the overall sentiment score is 0.974. These values are \nall very high, which indicates that the null hypothesis of equal means should be accepted. \nAccepting the null hypothesis indicates that there is no statistically significant difference between \nthe two datasets. This result supports our observation that these two datasets have a very high \nsimilarity in sentiment.  \n \nThe ratio of positive and negative sentiment terms between the two subsets are also very similar \n(with the subset Hypertension and Diabetes having a positive terms ratio of 0.4900, and a negative \nterms ratio of 0.5091, and the subset Diabetes having a positive terms ratio of 0.4914, and a \nnegative terms ratio of 0.5086). As shown in Figure 3, the subset Diabetes has the fifth smallest \nratio of negative terms, as well as the fifth smallest ratio of positive terms. Very similarly, the \nsubset Hypertension and Diabetes has the sixth smallest ratio of negative terms, as well as the \nsixth smallest ratio of positive terms. We can observe that the distributions of positive and \nnegative words of the two datasets are very similar.  \n \nFor determining the most similar in sentiment pair of subsets, the Doc2Vec cosine similarity, the \nWord2Vec cosine similarity, the SentiWordNet sentiment scores, and the SentiWordNet sentiment \nratios seem to all agree that the subset Hypertension and Diabetes and the subset Diabetes are \nthe most similar in sentiment.  \n \nMost Different Subsets. When determining the most different in sentiment pair of subsets from \nthe data, the Doc2Vec cosine similarity score, Word2Vec cosine similarity score, the SentiWordNet \nsentiment score, and SentiWordNet sentiment ratios all show different results. The pair of subsets \ndetermined to be most difference by each evaluation method are: \n \n- \nDoc2Vev: subset 8 (Obesity not Diabetes) and subset 12 (Diabetes not Hypertension) \n- \nSentiWordNet Sentiment Score: subset 6 (Hypertension and not Obesity) and subset 4 \n(Obesity and Hypertension \n- \nWord2Vec and SentiWordNet Sentiment Ratio: subset 5 (Obesity and not Hypertension) \nand subset 4 (Obesity and Hypertension) \n \nDoc2Vec Result. According to the Doc2Vec cosine similarity results (shown in Table 9), the most \ndifferent in sentiment pair of subsets are subset 8 (Obesity not Diabetes ) and subset 12 (Diabetes \nnot Hypertension) at a cosine similarity score of 0.3546. The characteristics of these two subsets \nare summarized in Table 14. \n \nThe Word2Vec cosine similarity of these two datasets is 0.9838, which is a relatively average \nsimilarity score in comparison to the rest of the datasets (the highest similarity being 0.9997 and \nthe lowest similarity being 0.9722). This result is not very informative.  \nWhen examining the SentiWordNet scores of these two subsets, we can observe that the subset \nDiabetes and not Hypertension is the third most positive overall, and the subset Obesity and not \nDiabetes is the ninth most positive overall (see Figure 2). While there is a relatively large \ndifference of 0.0026 between their overall sentiment scores, this is not the largest difference in \noverall sentiment that exists. The results of the Welch’s t-test on these two subsets also strongly \nindicate that the difference between the two datasets are not significant (the overall p-value of \n0.727 signifies that there is only a 27.3% chance that the difference is statistically significant).  \n \nTable 14: Most different subsets according to Doc2Vec \n \nMost Different Subsets \nDataset Obesity not Diabetes \n (ID = 8) \nDiabetes not Hypertension  \n(ID = 12) \nDoc2Vec Score 0.3546 \nWord2Vec Score 0.9838 \nSentiWordNet Positive Score 0.0503 \n0.0518 \nSentiWordNet Negative Score 0.0736 \n0.0725 \nSentiWordNet Negative - Positive 0.0233 \n0.0207 \nWelch’s t-test positive p-value 0.506 \nWelch’s t-test negative p-value 0.900 \nWelch’s t-test overall p-value 0.727 \nSentiWordNet positive terms 3006 \n2931 \nSentiWordNet negative terms 3122 \n3016 \nSentiWordNet positive terms ratio 0.4905 \n0.4929 \nSentiWordNet negative terms \nratio \n0.5095 \n0.5071 \n \n \n \n \nExamining the ratio of sentiment terms in each subset gives a comparable result – the subset \nDiabetes and not Hypertension has the third lowest ratio of negative terms (0.5071), while the \nsubset Obesity and not Diabetes has the seventh lowest ratio of negative terms (0.5095). Although \nthere exists a difference of 0.0024, the difference is not the largest out of all the subsets - the \nlargest difference being 0.0066 occurring between the subsets Obesity and Hypertension and \nObesity not Hypertension.  \n \nSentiWordNet Sentiment Score Result. According to the SentiWordNet overall sentiment results \n(shown in Table 4), the most different pair of datasets are subset 6 (Hypertension and not Obesity ) \nand subset 4 (Obesity and Hypertension). The difference between their overall sentiment scores is \n0.0082, the largest difference of any two datasets. The characteristics of these two subsets are \nsummarized in Table 15.  \n \nWhen observing the SentiWordNet overall sentiment scores of these two subsets (shown in Table \n4), we can observe that the subset Hypertension and not Obesity is the most positive subset \noverall, while the subset Obesity and Hypertension is the most negative overall (see Figure 2). \nThese two subsets have the largest difference of positive sentiment scores and negative sentiment \nscores. Observing the results of the Welch’s t-test on these two subsets shows a similar result – \nthe p-value for the overall sentiment is 0.061, the smallest and most significant score of all the \ndatasets. This signifies that we can reject the null hypothesis with a 93.9% confidence, i.e., there is \na 93.9% chance that difference between these two datasets is statistically significant. \n \n \n \nTable 15: Most different subsets according to SentiWordNet overall sentiment \n \nMost Different Subsets \nDataset Hypertension and not Obesity \n (ID = 6) \nObesity and Hypertension  \n(ID = 4) \nDoc2Vec Score 0.5868 \nWord2Vec Score 0.9922 \nSentiWordNet Positive Score 0.0521 \n0.0487 \nSentiWordNet Negative Score 0.0698 \n0.0747 \nSentiWordNet Negative - Positive 0.0178 \n0.0260 \nWelch’s t-test positive p-value 0.526 \nWelch’s t-test negative p-value 0.170 \nWelch’s t-test overall p-value 0.061 \nSentiWordNet positive terms 4322 \n3744 \nSentiWordNet negative terms 4447 \n3948 \nSentiWordNet positive terms ratio 0.4929 \n0.4867 \nSentiWordNet negative terms \nratio \n0.5071 \n0.5133 \n \n \n \nExamining the ratio of sentiment terms in each subset gives a similar result – the subset \nHypertension and not Obesity has the second highest ratio of positive terms combined with the \nsecond lowest ratio of negative terms (making it second most positive overall). The subset Obesity \nand Hypertension has the lowest ratio of positive terms combined with the highest ratio of \nnegative terms (making it the most negative overall) (see Table 5). In terms of the difference in \nratio of positive and negative terms, these two datasets are the second most different pair of \ndatasets (the most different pair of subsets being Obesity and not Hypertension and Obesity and \nHypertension), indicating that they are indeed quite different in sentiment.  \n \nThe Word2Vec cosine similarity of these two subsets is 0.9922, and is a relatively average \nsimilarity score in comparison to the rest of the datasets. The Doc2Vec cosine similarity of these \ntwo subsets in 0.5868, and is also a relatively average similarity score in comparison to the rest of \nthe datasets. Neither of these cosine similarity scores shows the same differences as the \nSentiWordNet sentiment scores.  \n \nWord2Vec and SentiWordNet Sentiment Ratio Result. According to the Word2Vec cosine \nsimilarity results (shown in Table 9), the most different pair of datasets are subset 5 (Obesity and \nnot Hypertension) and subset 4 (Obesity and Hypertension) at a cosine similarity score of 0.9722. \nThe Doc2Vec cosine similarity of these two datasets is 0.6146, which is a relatively average \nsimilarity score in comparison to the rest of the datasets (the highest similarity being 0.9623 and \nthe lowest similarity being 0.3546). This result does not reflect the same differences as the \nWord2Vec cosine similarity score.    \n \nWhen observing the SentiWordNet overall sentiment scores of these two subsets (shown in Table \n4), we can see that subset 5 (Obesity and not Hypertension) is the seventh most positive overall \nand subset 4 (Obesity and Hypertension) is the twelfth most positive (or the most negative) (see \nFigure 2). While there does exist a difference between these subsets, this difference is not as large \nas some other pairs of subsets (such as Hypertensions and not Obesity and Obesity and \nHypertension). Additionally, when analyzing the result of the Welch’s t-test for these two subsets, \nthe p-value for all three tests is very high, which strongly indicates that the difference between the \ntwo datasets is not statistically significant (an overall sentiment p-value of 0.382 signifies that \nthere is only a 67.8% change that the difference is statistically significant).   \n \nWhen observing the ratio of sentiment terms in each subset, we can see that subset 5 (Obesity \nand not Hypertension) contains the highest ratio of positive terms (0.4933) combined with the \nlowest ratio of negative terms (0.5067), and subset 4 (Obesity and Hypertension) contains the \nlowest ratio of positive terms (0.4867) combined with the highest ration of negative terms \n(0.5133). In terms of the difference in ratio of positive and negative terms, these two datasets are \nindeed the pair of subsets that are most different in sentiment. The ratio of sentiment terms \nsupports the Word2Vec result that these two subsets are the most different.  \n \n \n \nTable 16: Most different subsets according to Word2Vec and SentiWordNet sentiment ratio \n \nMost Different Subsets \nDataset Obesity and not Hypertension \n(ID = 5) \nObesity and Hypertension  \n(ID = 4) \nDoc2Vec Score 0.6146 \nWord2Vec Score 0.9722 \nSentiWordNet Positive Score 0.0512 \n0.0487 \nSentiWordNet Negative Score 0.0728 \n0.0747 \nSentiWordNet Negative - Positive 0.0216 \n0.0260 \nWelch’s t-test positive p-value 0.554 \nWelch’s t-test negative p-value 0.642 \nWelch’s t-test overall p-value 0.382 \nSentiWordNet positive terms 2636 \n3744 \nSentiWordNet negative terms 2708 \n3948 \nSentiWordNet positive terms ratio 0.4933 \n0.4867 \nSentiWordNet negative terms \nratio \n0.5067 \n0.5133 \n \n \n \nOverall Results for Most Different In Sentiment Subsets. The pair of documents determined by \nDoc2Vec cosine similarity to be most different in sentiment are subset 8 (Obesity not Diabetes) \nand subset 12 (Diabetes not Hypertension) (see Table 14). This result is not supported by the \nresults from the Word2Vec cosine similarity, the SentiWordNet sentiment score, nor the \nSentiWordNet sentiment ratio.  \n \nThe pair of documents determined by the overall SentiWordNet sentiment score to be the most \ndifferent in sentiment are subset 6 (Hypertension and not Obesity ) and subset 4 (Obesity and \nHypertension) (see Table 15). This result is supported by the result of the Welch’s t-test (having a \n93.9% chance that the difference between these two subsets is statistically significant). It is also to \nan extent supported by the SentiWordNet sentiment ratios as being the second most different \npair of subsets. But there is no strong evidence from Word2Vec cosine similarity nor Doc2Vec \ncosine similarity between the subsets that supports this result.  \n \nThe Word2Vec cosine similarity and the SentiWordNet sentiment ratios both determined subset 5 \n(Obesity and not Hypertension) and subset 4 (Obesity and Hypertension) to be the most different \nin sentiment (see Table 16). But this result is not strongly supported by either Doc2Vec cosine \nsimilarity or by SentiWordNet sentiment scores.  \n \nConclusions and Future Work \n \nIn this study, we explored the application of the unsupervised machine learning models Word2Vec \nand Doc2Vec on detecting sentiments of clinical discharge summaries. We have discovered that \nWord2vec and Doc2Vec have the same performance as SentiWordNet on the task of predicting \ndatasets with similar sentiments. We have also discovered that Doc2Vec does not perform well in \npredicting datasets with different sentiments. Word2Vec on the other hand, is able to distinguish \nbetween subsets with a different ratios of sentiment terms (positive and negative), but not by \ntheir overall sentiment score. We used Welch’s t-test to evaluate statistical significance of the \nobtained results. \n  \nWe performed sentiment analysis on 12 subsets of clinical discharge summaries to evaluate the \noverall sentiment scores of subsets relating to certain diseases. We found through using the \ntraditional sentiment lexicon SentiWordNet that the subset Hypertension not Obesity contained \nthe most positive overall sentiment relative to the other subsets, and the subset Obesity and \nHypertension contained the most negative overall sentiment relative to the other subsets. On the \ntwo datasets, Welch’s t-test resulted in a p-value of 0.061, indicating that there is 93.9% chance \nthat the difference between the subsets are statistically significant.  \nFuture work in this area include extending the scope of the analysis to different datasets, such as \nage or gender, and including different lexical resources (such as MPQA (Wiebe, Wilson, & Cardie, \n2005) and Bing Liu’s Opinion Lexicon (Liu & Hu, 2004)) as part of our analysis. Furthermore, we \nplan develop a method to evaluate the performance of unsupervised machine learning models \n(such as Word2Vec and Doc2Vec) in determining sentiment of a document.  \nReferences \n[1]  K. Denecke and Y. Deng, \"Sentiment analysis in medical settings,\" Artificial Intelligence in Medicine, vol. 64, no. 1, \npp. 17-27 , May 2015.  \n[2]  Y. Deng, T. Declerck, P. Lendvai and K. Denecke, \"The Generation of a Corpus for Clinical Sentiment Analysis,\" in \nThe Semantic Web -- ESWC 2016 Satellite Events, 2016.  \n[3]  A. Esuli and F. Sebastiani, \"SENTIWORDNET: A publicly available lexical resource for opinion mining,\" in 5th \nConference on Language Resources and Evaluation (LREC’06), Genova, 2006.  \n[4]  C. Strapparava and A. Valitutti, \"Wordnet-affect: an affective extension of wordnet,\" in 4th International \nConference on Language Resources and Evaluation, Lisbon, 2014.  \n[5]  J. Wiebe, T. Wilson and C. Cardie, \"Annotating expressions of opinions and emotions in language,\" Language \nResources and Evaluation, vol. 39, no. 2-3, pp. 165-210, 2005.  \n[6]  Y. Deng, M. Stoehr and K. Denecke, \"Retrieving Attitudes: Sentiment Analysis from Clinical Narratives,\" in Medical \nInformation Retrieval Workshop at SIGIR 2014, Gold Coast, 2014.  \n[7]  D. Tang, F. Wei, N. Yang, M. Zhou, T. Liu and B. Qin, \"Learning Sentiment-Specific Word Embedding for Twitter \nSentiment Classification,\" in ACL, 2014.  \n[8]  C. Musto, G. Semeraro and M. Polignano, \"A comparison of Lexicon-based approaches for Sentiment Analysis of \nmicroblog posts,\" in CEUR Workshop Proceedings, Pisa, 2014.  \n[9]  P. Nakov, Z. Kozareva, A. Ritter, S. Rosenthal, V. Stoyanov and T. Wilson, \"Semeval-2013 task 2: Sentiment \nanalysis in twitter,\" in Joint Conference on Lexical and Computational Semantics, Atlanta, 2013.  \n[10] A. Go, R. Bhayani and L. Huang, \"Twitter sentiment classification using distant supervision,\"  Stanford, 2009. \n[11] Ö. Uzuner, Recognizing Obesity and Co-morbidities in Sparse Data, 2009, pp. 561-570. \n[12] R. M. Puhl and A. C. Heuer, \"The stigma of obesity: a review and update,\" Obesity (Silver Spring), vol. 17, no. 5, \npp. 941-64, May 2009.  \n[13] C. D. Manning, An Introduction to Information Retrieval, Cambridge: Cambridge University Press, 2009, pp. 32-34. \n[14] T. Mikolov, K. Chen, G. Corrado and J. Dean, \"Efficient Estimation of Word Representations in Vector Space,\" \nCoRR, vol. abs/1301.3781, Jan 2013.  \n[15] Deep Learning for Java, \"Word2Vec, Doc2vec & GloVe: Neural Word Embeddings for Natural Language \nProcessing,\" 2017. [Online]. Available: https://deeplearning4j.org/word2vec.html. \n[16] Q. Le and T. Mikolov, \"Distributed Representations of Sentences and Documents,\" in 31st International \nConference on International Conference on Machine Learning, Beijing, 2014.  \n[17] D. Lakens, \"Always use Welch's t-test instead of Student's t-test,\" 26 Jan 2015. [Online]. Available: \nhttp://daniellakens.blogspot.ca/2015/01/always-use-welchs-t-test-instead-of.html. [Accessed 23 April 2018]. \n[18] Investopedia, \"P-Value,\" [Online]. Available: https://www.investopedia.com/terms/p/p-value.asp.  \n[19] T. Cagan, S. L. Frank and R. Tsarfaty, \"Data-Driven Broad-Coverage Grammars for Opinionated Natural Language \nGeneration (ONLG),\" in ACL, Vancouver, 2017.  \n[20] B. Liu and M. Hu, \"Opinion Mining, Sentiment Analysis, and Opinion Spam Detection,\" 15 May 2004. [Online]. \nAvailable: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html. \n \n \n",
  "categories": [
    "cs.CL",
    "cs.LG",
    "68T05, 68T50"
  ],
  "published": "2018-05-01",
  "updated": "2018-05-01"
}