{
  "id": "http://arxiv.org/abs/1805.02269v2",
  "title": "Incorporating Privileged Information to Unsupervised Anomaly Detection",
  "authors": [
    "Shubhranshu Shekhar",
    "Leman Akoglu"
  ],
  "abstract": "We introduce a new unsupervised anomaly detection ensemble called SPI which\ncan harness privileged information - data available only for training examples\nbut not for (future) test examples. Our ideas build on the Learning Using\nPrivileged Information (LUPI) paradigm pioneered by Vapnik et al. [19,17],\nwhich we extend to unsupervised learning and in particular to anomaly\ndetection. SPI (for Spotting anomalies with Privileged Information) constructs\na number of frames/fragments of knowledge (i.e., density estimates) in the\nprivileged space and transfers them to the anomaly scoring space through\n\"imitation\" functions that use only the partial information available for test\nexamples. Our generalization of the LUPI paradigm to unsupervised anomaly\ndetection shepherds the field in several key directions, including (i) domain\nknowledge-augmented detection using expert annotations as PI, (ii) fast\ndetection using computationally-demanding data as PI, and (iii) early detection\nusing \"historical future\" data as PI. Through extensive experiments on\nsimulated and real datasets, we show that augmenting privileged information to\nanomaly detection significantly improves detection performance. We also\ndemonstrate the promise of SPI under all three settings (i-iii); with PI\ncapturing expert knowledge, computationally expensive features, and future data\non three real world detection tasks.",
  "text": "Incorporating Privileged Information to\nUnsupervised Anomaly Detection\nShubhranshu Shekhar\nLeman Akoglu\nCarnegie Mellon University\nHeinz College of Information Systems and Public Policy\n{shubhras, lakoglu}@andrew.cmu.edu\nAbstract. We introduce a new unsupervised anomaly detection ensem-\nble called SPI which can harness privileged information—data available\nonly for training examples but not for (future) test examples. Our ideas\nbuild on the Learning Using Privileged Information (LUPI) paradigm pi-\noneered by Vapnik et al. [19,17], which we extend to unsupervised learn-\ning and in particular to anomaly detection. SPI (for Spotting anomalies\nwith Privileged Information) constructs a number of frames/fragments\nof knowledge (i.e., density estimates) in the privileged space and trans-\nfers them to the anomaly scoring space through “imitation” functions\nthat use only the partial information available for test examples.\nOur\ngeneralization of the LUPI paradigm to unsupervised anomaly detec-\ntion shepherds the ﬁeld in several key directions, including (i) domain-\nknowledge-augmented detection using expert annotations as PI, (ii) fast\ndetection using computationally-demanding data as PI, and (iii) early\ndetection using “historical future” data as PI. Through extensive exper-\niments on simulated and real datasets, we show that augmenting privi-\nleged information to anomaly detection signiﬁcantly improves detection\nperformance. We also demonstrate the promise of SPI under all three\nsettings (i–iii); with PI capturing expert knowledge, computationally-\nexpensive features, and future data on three real world detection tasks.\n1\nIntroduction\nOutlier detection in point-cloud data has been studied extensively [1]. In this\nwork we consider a unique setting with a much sparser literature: the problem of\naugmenting privileged information into unsupervised anomaly detection. Simply\nput, privileged information (PI) is additional data/knowledge/information that\nis available only at the learning/model building phase for (subset of) training\nexamples, which however is unavailable for (future) test examples.\nThe LUPI framework.\nLearning Using Privileged Information (LUPI)\nhas been pioneered by Vapnik et al. ﬁrst in the context of SVMs [19,17] (PI-\nincorporated SVM is named SVM+), later generalized to neural networks [18].\nThe setup involves an Intelligent (or non-trivial) Teacher at learning phase, who\nprovides the Student with privileged information (like explanations, metaphors,\netc.), denoted x∗\ni , about each training example xi, i = 1 . . . n. The key point\narXiv:1805.02269v2  [cs.LG]  24 May 2018\n2\nShubhranshu Shekhar\nLeman Akoglu\nin this paradigm is that privileged information is not available at the test phase\n(when Student operates without guidance of Teacher). Therefore, the goal is to\nbuild models (in our case, detectors) that can leverage/incorporate such addi-\ntional information but yet, not depend on the availability of PI at test time.\nExample: The additional information x∗\ni ’s belong to space X∗which is, gen-\nerally speaking, diﬀerent from space X. In other words, the feature spaces of\nvectors x∗\ni ’s and xi’s do not overlap. As an example, consider the task of iden-\ntifying cancerous biopsy images. Here the images are in pixel space X. Suppose\nthat there is an Intelligent Teacher that can recognize patterns in such images\nrelevant to cancer. Looking at a biopsy image, Teacher can provide a description\nlike “Aggressive proliferation of A-cells into B-cells” or “Absence of any dynamic”.\nNote that such descriptions are in a specialized language space X∗, diﬀerent from\npixel space X. Further, they would be available only for a set of examples and\nnot when the model is to operate autonomously in the future.\nLUPI’s advantages: LUPI has been shown to (i) improve rate of convergence\nfor learning, i.e., require asymptotically fewer examples to learn [19], as well as\n(ii) improve accuracy, when one can learn a model in space X∗that is not much\nworse than the best model in space X (i.e., PI is intelligent/non-trivial) [18].\nMotivated by these advantages, LUPI has been applied to a number of problems\nfrom action recognition [13] to risk modeling [14] (expanded in §5). However, the\nfocus of all such work has mainly been on supervised learning.\nLUPI for anomaly detection. The only (perhaps straightforward) exten-\nsion of LUPI to unsupervised anomaly detection has been introduced recently,\ngeneralizing SVM+ to the One-Class SVM (namely OC-SVM+) [2] for mal-\nware and bot detection. The issue is that OC-SVM is not a reliable detector—\nexperiments on numerous benchmark datasets with ground truth by Emmott\net al. that compared popular anomaly detection algorithms ﬁnd that OC-SVM\nranks at the bottom (Table 1, pg. 4 [6]; also see our results in §4). We note\nthat the top performer in [6] is the Isolation Forest (iForest) algorithm [11], an\nensemble of randomized trees.\nOur contributions: Motivated by LUPI’s potential value to learning and the\nscarcity in the literature of its generalization to anomaly detection, we propose\na new technique called SPI (pronounced ‘spy’), for Spotting anomalies with\nPrivileged Information. Our work bridges the gap (for the ﬁrst time) between\nLUPI and unsupervised ensemble based anomaly detection that is considered\nstate-of-the-art [6]. We summarize our main contributions as follows.\n– Study of LUPI for anomaly detection: We analyze how LUPI can ben-\neﬁt anomaly detection, not only when PI is truly unavailable at test time (as\nin traditional setup) but also when PI is strategically and willingly avoided at\ntest time. We argue that data/information that incurs overhead on resources\n($$$/storage/battery/etc.), timeliness, or vulnerability, if designated as PI,\ncan enable resource-frugal, early, and preventive detection (expanded in §2).\n– PI-incorporated detection algorithm: We show how to incorporate\nPI into ensemble based detectors and propose SPI, which constructs\nframes/fragments of knowledge (speciﬁcally, density estimates) in the priv-\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n3\nileged space (X∗) and transfers them to the anomaly scoring space (X)\nthrough “imitation” functions that use only the partial information avail-\nable for test examples. To the best of our knowledge, ours is the ﬁrst at-\ntempt to leveraging PI for improving the state-of-the-art ensemble methods\nfor anomaly detection within an unsupervised LUPI framework. Moreover,\nwhile SPI augments PI within the tree-ensemble detector iForest [11], our\nsolution can easily be applied to any other ensemble based detector (§3).\n– Applications: Besides extensive simulation experiments, we employ SPI\non three real-world case studies where PI respectively captures (i) expert\nknowledge, (ii) computationally-expensive features, and (iii) “historical fu-\nture” data, which demonstrate the beneﬁts that PI can unlock for anomaly\ndetection in terms of accuracy, speed, and detection latency (§4).\nReproducibility: Implementation of SPI and real world datasets used in exper-\niments are open-sourced at http://www.andrew.cmu.edu/user/shubhras/SPI.\n2\nMotivation: How can LUPI beneﬁt anomaly detection?\nThe implications of the LUPI paradigm for anomaly detection is particularly\nexciting. Here, we discuss a number of detection scenarios and demonstrate that\nLUPI unlocks advantages for anomaly detection problems in multiple aspects.\nIn the original LUPI framework [19], privileged information (hereafter PI) is\ndeﬁned as data that is available only at training stage for training examples but\nunavailable at test time for test examples. Several anomaly detection scenarios\nadmit this deﬁnition directly. Interestingly, PI can also be speciﬁed as strategi-\ncally “unavailable” for anomaly detection. That is, one can willingly avoid using\ncertain data at test time (while incorporating such data into detection models at\ntrain phase1) in order to achieve resource eﬃciency, speed, and robustness. We\norganize detection scenarios into two with PI as (truly) Unavailable vs. Strategic,\nand elaborate with examples below. Table 1 gives a summary.\nUnavailable PI: This setting includes typical scenarios, where PI is (truly)\nunknown for test examples.\n1. “historical future” data: When training an anomaly detection model with\noﬄine/historical data that is over time (e.g., temporal features), one may use\nvalues both before and after time t while creating an example for each t. Such\ndata is PI; not available when the model is deployed to operate in real-time.\n2. after-the-fact data: In malware detection, the goal is to detect before it\ngets hold of and harms the system. One may have historical data for some (train-\ning) examples from past exposures, including measurements of system variables\n(number of disk/port read/writes, CPU usage, etc.). Such after-the-exposure\nmeasurements can be incorporated as PI.\n3. advanced technical data: This includes scenarios where some (training)\nexamples are well-understood but those to be detected are simply unknown. For\n1 Note that training phase in anomaly detection does not involve the use of any labels.\n4\nShubhranshu Shekhar\nLeman Akoglu\nTable 1:\nTypes of data used in anomaly detection with various overhead on\nresources ($$$, storage, battery, etc.), timeliness, and/or risk, if used as privileged\ninformation can enable resource-frugal, early, as well as preventive detection.\nProperties vs.\nType of Privileged Info\nUnavailable\nvs. Strategic\nneed\nResources\ncause\nDelay\nincur\nRisk\n1. “historical future” data\nU\nn/a\nn/a\nn/a\n2. after-the-fact data\nU\nn/a\nn/a\nn/a\n3. advanced technical data\nU\nn/a\nn/a\nn/a\n4. restricted-access data\nU, S\n\u0013\n5. expert knowledge\nU, S\n\u0013\n\u0013\n6. compute-heavy data\nS\n\u0013\n\u0013\n7. unsafe-to-collect data\nS\n\u0013\n\u0013\n8. easy-target-to-tamper data\nS\n\u0013\nexample, the expected behavior of various types of apps on a system may be\ncommon domain knowledge that can be converted to PI, but such knowledge\nmay not (yet) be available for new-coming apps.\nStrategic PI: Strategic scenarios involve PI that can in principle be acquired\nbut is willingly avoided at test time to achieve gains in resources, time, or risk.\n4. restricted-access data: One may want to build models that do not assume\naccess to private data or intellectual property at test time, such as source code\n(for apps or executables), even if they could be acquired through resources. Such\ninformation can also be truly unavailable, e.g. encrypted within the software.\n5. expert knowledge: Annotations about some training examples may be avail-\nable from experts, which are truly unavailable at test time. One could also strate-\ngically choose to avoid expert involvement at test time, which (a) may be costly\nto obtain and/or (b) cause signiﬁcant delay, especially for real-time detection.\n6. compute-heavy data: One may strategically choose not to rely on features\nthat are computationally expensive to obtain, especially in real-time detection,\nbut rather use such data as PI (which can be extracted oﬄine at training phase).\nSuch features not only cause delay but also require compute resources (which\ne.g., may drain batteries in detecting malware apps on cellphones).\n7. unsafe-to-collect data: This involves cases where collecting PI at test time\nis unsafe/dangerous. For example, the slower a drone moves to capture high-\nresolution (privileged) images for surveillance, not only it causes delay but more\nimportantly, the more susceptible it becomes to be taken down.\n8. easy-target-to-tamper data: Finally, one may want to avoid relying on fea-\ntures that are easy for adversaries to tamper with. Examples to those features\ninclude self-reported data (like age, location, etc.). Such data may be available\nreliably for some training examples and can be used as PI.\nIn short, by strategically designating PI one can achieve resource, timeliness,\nand robustness gains for various anomaly detection tasks. Designating features\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n5\nthat need resources as PI →allow resource-frugal (“lazy”) detection; features\nthat cause delay as PI →allow early/speedy detection; and designating features\nthat incur vulnerability as PI →allow preventive and more robust detection.\nIn this subsection, we laid out a long list of scenarios that make LUPI-based\nlearning particularly attractive for anomaly detection. In our experiments (§4)\nwe demonstrate its premise for scenarios 1., 5. and 6. above using three real world\ndatasets, while leaving others as what we believe interesting future investigations.\n3\nPrivileged Info-Augmented Anomaly Detection\nThe Learning Setting Formally, the input for the anomaly detection model\nat learning phase are tuples of the form\nD = {(x1, x∗\n1), (x2, x∗\n2), . . . , (xn, x∗\nn)} ,\nwhere xi = (x1\ni , . . . , xd\ni ) ∈X and x∗\ni = (x∗1\ni , . . . , x∗p\ni ) ∈X∗. Note that this is an\nunsupervised learning setting where label information, i.e., yi’s are not available.\nThe privileged information is represented as a feature vector x∗∈Rp that is in\nspace X∗, which is additional to and diﬀerent from the feature space X in which\nthe primary information is represented as a feature vector x ∈Rd.\nThe important distinction from the traditional anomaly detection setting is\nthat the input to the (trained) detector at testing phase are feature vectors\n{xn+1, xn+2, . . . , xn+m} .\nThat is, the (future) test examples do not carry any privileged information.\nThe anomaly detection model is to score the incoming/test examples and make\ndecisions solely based on the primary features x ∈X.\nIn this text, we refer to space X∗as the privileged space and to X as the\ndecision space. Here, a key assumption is that the information in the privileged\nspace is intelligent/nontrivial, that is, it allows to create models f ∗(x∗) that de-\ntect anomalies with vectors x∗corresponding to vectors x with higher accuracy\nthan models f(x). As a result, the main question that arises which we address\nin this work is: “how can one use the knowledge of the information in space X∗\nto improve the performance of the desired model f(x) in space X?”\nIn what follows, we present a ﬁrst-cut attempt to the problem that is a\nnatural knowledge transfer between the two feature spaces (called FT for feature\ntransfer). We then lay out the shortcomings of such an attempt, and present our\nproposed solution SPI. We compare to FT (and other baselines) in experiments.\n3.1\nFirst Attempt: Incorporating PI by Transfer of Features\nA natural attempt to learning under privileged information that is unavailable\nfor test examples is to treat the task as a missing data problem. Then, typical\ntechniques for data imputation can be employed where missing (privileged) fea-\ntures are replaced with their predictions from the available (primary) features.\n6\nShubhranshu Shekhar\nLeman Akoglu\nIn this scheme, one simply maps vectors x ∈X into vectors x∗∈X∗and then\nbuilds a detector model in the transformed space. The goal is to ﬁnd the trans-\nformation of vectors x = (x1, . . . , xd) into vectors φ(x) = (φ1(x), . . . , φp(x))\nthat minimizes the expected risk given as\nR(φ) =\np\nX\nj=1\nmin\nφj\nZ\n(x∗j −φj(x))2p(x∗j, x)dx∗jdx ,\n(1)\nwhere p(x∗j, x) is the joint probability of coordinate x∗j and vector x, and\nfunctions φj(x) are deﬁned by p regressors.\nHere, one could construct approximations to functions φj(x), j = {1, . . . , p}\nby solving p regression estimation problems based on the training examples\n(x1, x∗j\n1 ), . . . , (xn, x∗j\nn ), j = 1, . . . , p ,\nwhere xi’s are input to each regression φj and the jth coordinate of the cor-\nresponding vector x∗\ni , i.e. x∗j\ni ’s are treated as the output, by minimizing the\nregularized empirical loss functional\nR(φj) = min\nφj\nn\nX\ni=1\n(x∗j\ni −φj(xi))2 + λjpenalty(φj), j = 1, . . . , p .\n(2)\nHaving estimated the transfer functions ˆφj’s (using linear or non-linear re-\ngression techniques), one can then learn any desired anomaly detector f( ˆφ(x))\nusing the training examples, which concludes the learning phase. Note that the\ndetector does not require access to privileged features x∗and can be employed\nsolely on primary features x of the test examples i = n + 1, . . . , m.\n3.2\nProposed SPI: Incorporating PI by Transfer of Decisions\nTreating PI as missing data and predicting x∗from x could be a diﬃcult task,\nwhen privileged features are complex and high dimensional (i.e., p is large). Pro-\nvided f ∗(x∗) is an accurate detection model, a more direct goal would be to\nmimic its decisions—the scores that f ∗assigns to the training examples. Map-\nping data between two spaces, as compared to decisions, would be attempting to\nsolve a more general problem, that is likely harder and unnecessarily wasteful.\nThe general idea behind transferring decisions/knowledge (instead of data)\nis to identify a small number of elements in the privileged space X∗that well-\napproximate the function f ∗(x∗), and then try to transfer them to the decision\nspace—through the approximation of those elements in space X. This is the\nknowledge transfer mechanism in LUPI by Vapnik and Izmailov [17]. They il-\nlustrated this mechanism for the (supervised) SVM classiﬁer. We generalize this\nconcept to unsupervised anomaly detection.\nThe knowledge transfer mechanism uses three building blocks of knowledge\nrepresentation in AI, as listed in Table 2. We ﬁrst review this concept for SVMs,\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n7\nfollowed by our proposed SPI. While SPI is clearly diﬀerent in terms of the task\nit is addressing as well as in its approach, as we will show, it is inspired by and\nbuilds on the same fundamental mechanism.\nTable 2: Three building blocks of knowledge representation in artiﬁcial intelligence,\nin context of SVM-LUPI for classiﬁcation [17] and SPI for anomaly detection [this\npaper].\nSVM-LUPI\nSPI (Proposed)\n1. Fundamental elements of knowledge\nsupport vectors\nisolation trees\n2. Frames (fragments) of the knowledge\nkernel functions\ntree anomaly scores\n3. Structural connections of the frames\nweighted sum\nweighted sum (by L2R)\nKnowledge transfer for SVM: The fundamental elements of knowledge in\nthe SVM classiﬁer are the support vectors. In this scheme, one constructs two\nSVMs; one in X space and another in X∗space. Without loss of generality, let\nx1, . . . , xt be the support vectors of SVM solution in space X and x∗\n1, . . . , x∗\nt∗\nbe the support vectors of SVM solution in space X∗, where t and t∗are the\nrespective number of support vectors.\nThe decision rule f ∗in space X∗(which one aims to mimic) has the form\nf ∗(x∗) =\nt∗\nX\nk=1\nykα∗\nkK∗(x∗\nk, x∗) + b∗,\n(3)\nwhere K∗(x∗\nk, x∗) is the kernel function of similarity between support vector x∗\nk\nand vector x∗∈X∗, also referred as the frames (or fragments) of knowledge.\nEq. (3) depicts the structural connection of these fragments, which is a weighted\nsum with learned weights α∗\nk’s.\nThe goal is to approximate each fragment of knowledge K∗(x∗\nk, x∗), k =\n1, . . . , t∗in X∗using the fragments of knowledge in X; i.e., the t kernel func-\ntions K(x1, x), . . . , K(xt, x) of the SVM trained in X. To this end, one maps\nt-dimensional vectors z = (K(x1, x), . . . , K(xt, x)) ∈Z into t∗-dimensional vec-\ntors z∗= (K∗(x∗\n1, x∗), . . . , K∗(x∗\nt∗, x∗)) ∈Z∗through t∗regression estimation\nproblems. That is, the goal is to ﬁnd regressors φ1(z), . . . , φt∗(z) in X such that\nφk(zi) ≈K∗(x∗\nk, x∗\ni ), k = 1, . . . , t∗\n(4)\nfor all training examples i = 1, . . . , n. For each k = 1, . . . , t∗, one can construct\nthe approximation to function φk by training a regression on the data\n{(z1, K∗(x∗\nk, x∗\n1)), . . . , (zn, K∗(x∗\nk, x∗\nn))}, k = 1, . . . , t∗,\nwhere we regress vectors zi’s onto scalar output K∗(x∗\nk, x∗\ni )’s to obtain ˆφk.\n8\nShubhranshu Shekhar\nLeman Akoglu\nFig. 1: Anomaly detection with PI illustrated. FT maps data between spaces\n(§3.1) whereas SPI (and “light” version SPI-lite) mimic decisions (§3.2).\nFor the prediction of a test example x, one can then replace each K∗(x∗\nk, x∗)\nin Eq. (3) (which requires privileged features x∗) with ˆφk(z) (which mimics it,\nusing only the primary features x—to be exact, by ﬁrst transforming x into z\nthrough the frames K(xj, x), j = 1, . . . , t in the X space).\nKnowledge transfer for SPI: In contrast to mapping of features from space\nX to space X∗, knowledge transfer of decisions maps space Z to Z∗in which\nfragments of knowledge are represented. Next, we show how to generalize these\nideas to anomaly detection with no label supervision. Figure 1 shows an overview.\nTo this end, we utilize a state-of-the-art ensemble technique for anomaly\ndetection, called Isolation Forest [11] (hereafters iF, for short), which builds a\nset of extremely randomized trees. In essence, each tree approximates density\nin a random feature subspace and anomalousness of a point is quantiﬁed by the\nsum of such partial estimates across all trees.\nIn this setting, one can think of the individual trees in the ensemble to consti-\ntute the fundamental elements and the partial density estimates (i.e., individual\nanomaly scores from trees) to constitute the fragments of knowledge, where the\nstructural connection of the fragments is achieved by an unweighted sum.\nSimilar to the scheme with SVMs, we construct two iFs; one in X space and\nanother in X∗space. Let T = T1, . . . , Tt denote the trees in the ensemble in\nX and T ∗= T ∗\n1 , . . . , T ∗\nt∗the trees in the ensemble in X∗, where t and t∗are\nthe respective number of trees (prespeciﬁed by the user, typically a few 100s).\nFurther, let S∗(T ∗\nk , x∗) denote the anomaly score estimated by tree T ∗\nk for a\ngiven x∗(the lower the more anomalous; refer to [11] for details of the scoring).\nS(Tk, x) is deﬁned similarly. Then, the anomaly score s∗for a point x∗in space\nX∗(which we aim to mimic) is written as\ns∗(x∗) =\nt∗\nX\nk=1\nS∗(T ∗\nk , x∗) ,\n(5)\nwhich is analogous to Eq. (3). To mimic/approximate each fragment of knowl-\nedge S∗(T ∗\nk , x∗), k = 1, . . . , t∗in X∗using the fragments of knowledge in X; i.e.,\nthe t scores for x: S(T1, x), . . . , S(Tt, x) of the iF trained in X, we estimate t∗\nregressors φ1(z), . . . , φt∗(z) in X such that\nφk(zi) ≈S∗(T ∗\nk , x∗\ni ), k = 1, . . . , t∗\n(6)\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n9\nAlgorithm 1 SPI-Train: Incorporating PI to Unsupervised Anomaly Detector\nInput: training examples {(x1, x∗\n1), . . . , (xn, x∗\nn)}\nOutput: detection model (ensemble-of-trees) T\nin X space; regressors ˆφk’s, k =\n1, . . . , t∗; β (or γ for kernelized L2R)\n1: Learn t∗isolation trees T ∗= {T ∗\n1 , . . . , T ∗\nt∗} on x∗\ni ’s i = 1, . . . , n\n2: Learn t isolation trees T = {T1, . . . , Tt} on xi’s i = 1, . . . , n\n3: Construct leaf score vectors zi’s, i = 1, . . . , n, based on T\n4: for each k = 1, . . . , t∗do\n5:\nLearn regressor ˆφk of zi’s onto S∗(T ∗\nk , x∗\ni )’s\n6:\nObtain β by optimizing C in (9) (or γ for kernelized Cψ)\n7: end for\nfor all training examples i = 1, . . . , n, where zi = (S(T1, xi), . . . , S(Tt, xi)).\nSimply put, each ˆφk is an approximate mapping of all the t scores from the\nensemble T in X to an individual score (fragment of knowledge) by tree T ∗\nk of\nthe ensemble T ∗in X∗. In practice, we learn a mapping from the leaves rather\nthan the trees of T for a more granular mapping. Speciﬁcally, we construct\nvectors zi = (z′\ni1, . . . , z′\nit) where each z′\nik is a size ℓk vector in which the value at\nindex leaf(Tk, xi) is set to S(Tk, xi) and other entries to zero. Here, ℓk denotes\nthe number of leaves in tree Tk and leaf(·) returns the index of the leaf that xi\nfalls into in the corresponding tree (note that xi belongs to exactly one leaf of\nany tree, since the trees partition the feature space).\nSPI-lite: A “light” version.\nWe note that instead of mimicking each\nindividual fragment of knowledge S∗(T ∗\nk , x∗)’s, one could also directly mimic the\n“ﬁnal decision” s∗(x∗). To this end, we also introduce SPI-lite, which estimates\na single regressor φ(zi) ≈s∗(x∗\ni ) for i = 1, . . . , n (also see Figure 1). We compare\nSPI and SPI-lite empirically in §4.\nLearning to Rank (L2R) like in X∗: An important challenge in learning\nto accurately mimic the scores s∗’s in Eq. (5) is to make sure that the regressors\nφk’s are very accurate in their approximations in Eq. (6). Even then, it is hard\nto guarantee that the ﬁnal ranking of points by Pt∗\nk=1 ˆφk(zi) would reﬂect their\nranking by s∗(x∗\ni ). Our ultimate goal, after all, is to mimic the ranking of the\nensemble in X∗space since anomaly detection is a ranking problem at its heart.\nAlgorithm 2 SPI-Test: PI-Augmented Unsupervised Anomaly Detection\nInput: test examples {xn+1, . . . , xn+m}; T , ˆφk’s k = 1, . . . , t∗, β (or γ if kernelized)\nOutput: estimated anomaly scores {sn+1, . . . , sn+m} for all test examples\n1: for each test example xe, e = n + 1, . . . , n + m do\n2:\nConstruct leaf score vector ze = (z′\ne1, . . . , z′\net) where entry in each z′\nek for index\nleaf(Tk, xe) is set to S(Tk, xe) and to 0 o.w., for k = 1, . . . , t\n3:\nConstruct φe = (ˆφ1(ze), . . . , ˆφt∗(ze))\n4:\nEstimate anomaly score as se = βφT\ne (or se = Pn\nl=1 γlK(φl, φe) if kernelized)\n5: end for\n10\nShubhranshu Shekhar\nLeman Akoglu\nTo this end, we set up an additional pairwise learning to rank objective as\nfollows. Let us denote by φi = (ˆφ1(zi), . . . , ˆφt∗(zi)) the t∗-dimensional vector\nof estimated knowledge fragments for each training example i. For each pair of\ntraining examples, we create a tuple of the form ((φi, φj), p∗\nij) where\np∗\nij = P(s∗\ni < s∗\nj) = σ(−(s∗\ni −s∗\nj)) ,\n(7)\nwhich is the probability that i is ranked ahead of j by anomalousness in X∗\nspace (recall that lower s∗is more anomalous), where σ(v) = 1/(1 + e−v) is the\nsigmoid function. Notice that the larger the gap between the anomaly scores of\ni and j, the larger this probability gets (i.e., more surely i ranks above j)\nGiven the training pair tuples above, our goal of learning-to-rank is to esti-\nmate β ∈Rt∗, such that\npij = σ(∆ij) = σ(βφT\ni −βφT\nj ) = σ(−ˆs∗\ni + ˆs∗\nj)) ≈p∗\nij, ∀i, j ∈{1, . . . , n} . (8)\nWe then utilize the cross entropy as our cost function over all (i, j) pairs, as\nmin\nβ\nC =\nX\n(i,j)\n−p∗\nij log(pij) −(1 −p∗\nij) log(1 −pij) =\nX\n(i,j)\n−p∗\nij∆ij + log(1 + e∆ij) (9)\nwhere p∗\nij’s are given as input to the learning as speciﬁed in Eq. (7) and pij is\ndenoted in Eq. (8) and is parameterized by β that is to be estimated.\nThe objective function in (9) is convex and can be solved via a gradient-based\noptimization, where dC\ndβ = P\n(i,j)(pij −p∗\nij)(φi−φj) (details omitted for brevity).\nMore importantly, in case the linear mapping s∗\ni ≈βφT\ni is not suﬃciently ac-\ncurate to capture the desired pairwise rankings, the objective can be kernelized\nto learn a non-linear mapping that is likely more accurate. The idea is to write\nβψ = Pn\nl=1 γlψ(φl) (in the transformed space) as a weighted linear combination\nof (transformed) training examples, for feature transformation function ψ(·) and\nparameter vector γ ∈Rn to be estimated. Then, ∆ij in objective (9) in the\ntransformed space can be written as\n∆ij =\nn\nX\nl=1\nγl[ψ(φl)ψ(φi)T −ψ(φl)ψ(φj)T ] =\nn\nX\nl=1\nγl[K(φl, φi)−K(φl, φj)]. (10)\nThe kernelized objective, denoted Cψ, can also be solved through gradient-\nbased optimization where we can show partial derivatives (w.r.t. each γl) to be\nequal to ∂Cψ\n∂γl = P\n(i,j)(pij −p∗\nij)[K(φl, φi) −K(φl, φj)]. Given the estimated\nγl’s, prediction of score is done by Pn\nl=1 γlK(φl, φe) for any (test) example e.\nThe SPI Algorithm: We outline the steps of SPI for both training and testing\n(i.e., detection) in Algo. 1 and Algo. 2, respectively. Note that the test-time\ndetection no longer relies on the availability of privileged features for the test\nexamples, but yet be able to leverage/incorporate them through its training.\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n11\n4\nExperiments\nWe design experiments to evaluate our methods in two diﬀerent settings:\n1. Benchmark Evaluation: We show the eﬀectiveness of augmenting PI (see\nTable 3) on 17 publicly available benchmark datasets.2\n2. Real-world Use Cases: We conduct experiments on LingSpam3 and\nBotOrNot4 datasets to show that (i) domain-expert knowledge as PI im-\nproves spam detection, (ii) compute-expensive PI enables fast detection at\ntest time, and (iii) “historical future” PI allows early detection of bots.\nBaselines We compare both SPI and SPI-lite to the following baselines:\n1. iF(X-only): Isolation Forest [11] serves as a simple baseline that operates\nsolely in decision space X. PI is not used neither for modeling nor detection.\n2. OC-SVM+ (PI-incorporated): OC+ for short, is an extension of (unsuper-\nvised) One-Class SVM that incorporates PI as introduced in [2].\n3. FT(PI-incorporated): This is the direct feature transfer method that incor-\nporates PI by learning a mapping X →X∗as we introduced in §3.1.\n* iF* (X∗-only): iF that operates in X∗space. We report performance by iF*\nonly for reference, since PI is unavailable at test time.\n4.1\nBenchmark Evaluation\nThe benchmark datasets do not have an explicit PI representation. Therefore,\nin our experiments we introduce PI as explained below.\nGenerating privileged representation. For each dataset, we introduce PI by\nperturbing normal observations. We designate a small random fraction (= 0.1)\nof n normal data points as anomalies. then, we randomly select a subset of p\nattributes and add zero-mean Gaussian noise to the designated anomalies along\nthe selected subset of attributes with matching variances of the selected features.\nThe p selected features represent PI since anomalies stand-out in this subspace\ndue to added noise, while the rest of the d attributes represent X space. Using\nnormal observations allows us to control for features that could be used as PI.\nThus we discard the actual anomalies from these datasets where PI is unknown.\nWe construct 4 versions per dataset with varying fraction γ of perturbed\nfeatures (PI) retained in X∗space. In particular, each set has γp features in X∗,\nand (1 −γ)p + d features in X for γ ∈{0.9, 0.7, 0.5, 0.3}.\nResults We report the results on perturbed datasets with γ = 0.7 as fraction\nof features retained in space X∗. Table 3 reports mean Average Precision (area\nunder the precision-recall curve) against 17 datasets for diﬀerent methods. The\nresults are averaged across 5 independent runs on stratiﬁed train-test splits.\n2 http://agents.fel.cvut.cz/stegodata/Loda.zip\n3 http://csmining.org/index.php/ling-spam-datasets.html\n4 https://botometer.iuni.iu.edu/bot-repository/datasets/caverlee-2011/caverlee-2011.zip\n12\nShubhranshu Shekhar\nLeman Akoglu\nTable 3: Mean Average Precision (MAP) on benchmark datasets (avg’ed over 5\nruns) for γ = 0.7. Numbers in parentheses indicate rank of each algorithm on\neach dataset. iF* (for reference only) reports MAP in the X∗space.\nDatasets\np+d\nn\niF\nOC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer\n30\n357\n0.1279 (4) 0.0935 (6) 0.0974 (5) 0.4574 (3) 0.5746 (2)\n0.6773 (1)\nionosphere\n33\n225\n0.0519 (4) 0.2914 (1) 0.0590 (3) 0.0512 (5) 0.0470 (6)\n0.0905 (2)\nletter-recognition\n617\n4197\n0.0889 (6) 0.1473 (4) 0.0908 (5) 0.3799 (3) 0.6413 (2)\n0.9662 (1)\nmultiple-features\n649\n1200\n0.1609 (5) 0.1271 (6) 0.2044 (4) 0.6589 (3) 0.8548 (2)\n1.0000 (1)\nwall-following-robot\n24\n2923\n0.1946 (5) 0.2172 (4) 0.1848 (6) 0.4331 (3) 0.5987 (2)\n0.7538 (1)\ncardiotocography\n27\n1831\n0.2669 (5) 0.6107 (4) 0.2552 (6) 0.6609 (3) 0.6946 (2)\n0.8081 (1)\nisolet\n617\n4497\n0.1533 (5) 0.1561 (4) 0.1303 (6) 0.5084 (3) 0.7124 (2)\n0.9691 (1)\nlibras\n90\n216\n0.1368 (5) 0.4479 (4) 0.0585 (6) 0.5175 (3) 0.6806 (2)\n1.0000 (1)\nparkinsons\n22\n147\n0.0701 (6) 0.0964 (4) 0.0714 (5) 0.1556 (3) 0.1976 (1)\n0.1778 (2)\nstatlog-satimage\n36\n3594\n0.2108 (6) 0.5347 (5) 0.5804 (4) 0.9167 (3) 0.9480 (2)\n0.9942 (1)\ngisette\n4971\n3500\n0.1231 (4) 0.0814 (6) 0.0977 (5) 0.5593 (3) 0.8769 (2)\n0.9997 (1)\nwaveform-1\n21\n3304\n0.1322 (4) 0.1481 (3) 0.0841 (6) 0.1234 (5) 0.1556 (2)\n0.4877 (1)\nmadelon\n500\n1300\n0.7562 (5) 0.1167 (6) 0.9973 (2) 0.9233 (4) 0.9925 (3)\n1.0000 (1)\nsynthetic-control\n60\n400\n0.3207 (6) 0.7889 (4) 0.6870 (5) 0.8103 (3) 0.8539 (2)\n0.9889 (1)\nwaveform-2\n21\n3304\n0.1271 (5) 0.2828 (2) 0.1014 (6) 0.1778 (3) 0.1772 (4)\n0.2944 (1)\nstatlog-vehicle\n18\n629\n0.1137 (6) 0.3146 (5) 0.6326 (4) 0.6561 (3) 0.7336 (2)\n1.0000 (1)\nstatlog-segment\n18\n1320\n0.1250 (6) 0.2323 (4) 0.1868 (5) 0.3304 (3) 0.3875 (2)\n0.7399 (1)\n(Average Rank)\n(5.11)\n(4.23)\n(4.88)\n(3.29)\n(2.35)\n(1.11)\n1\n2\n3\n4\n5\n6\niF*\nSPI\nSPI-l\noc+\nFT\niF\nCD\nFig. 2: Average rank of algorithms (w.r.t.\nMAP) and comparison by the Nemenyi\ntest. Groups of methods not signiﬁ-\ncantly diﬀerent (at p-val = 0.05) are\nconnected with horizontal lines. CD de-\npicts critical distance required to reject\nequivalence. Note that SPI is signiﬁ-\ncantly better than the baselines.\nOur SPI outperforms competition\nin detection performance in most of\nthe datasets. To compare the meth-\nods statistically, we use the non-\nparametric Friedman test [5] based on\nthe average ranks. Table 3 reports the\nranks (in parentheses) on each dataset\nas well as the average ranks. With p-\nvalue = 2.16 × 10−11, we reject the\nnull hypothesis that all the methods\nare equivalent using Friedman test.\nWe proceed with Nemenyi post-hoc\ntest to compare the algorithms pair-\nwise and to ﬁnd out the ones that dif-\nfer signiﬁcantly. The test identiﬁes performance of two algorithms to be signif-\nicantly diﬀerent if their average ranks diﬀer by at least the “critical diﬀerence”\n(CD). In our case, comparing 6 methods on 17 datasets at signiﬁcance level\nα = 0.05, CD = 1.82.\nResults of the post-hoc test are summarized through a graphical representa-\ntion in Figure 2. We ﬁnd that SPI is signiﬁcant better than all the baselines.\nWe also notice that SPI has no signiﬁcant diﬀerence from iF* which uses PI at\ntest time, demonstrating its eﬀectiveness in augmenting PI. While all the base-\nlines are comparable to SPI-lite, its average rank is better (also see last row in\nTable 3), followed by other PI-incorporated detectors, and lastly iF with no PI.\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n13\nAverage Precision (AP) is a widely-accepted metric to quantify overall per-\nformance of ranking methods like anomaly detectors. We also report average\nrank of the algorithms against other popular metrics including AUC of ROC\ncurve, ndcg@10 and precision@10 in Figure 3. Notice that the results are\nconsistent across measures, SPI and SPI-lite performing among the best.\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\n(a) MAP\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(b) AUC\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(c) ndcg@10\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(d) precision@10\nFig. 3: SPI and SPI-lite outperform competition w.r.t. diﬀerent evaluation met-\nrics. Average rank (bars) across benchmark datasets. iF* shown for reference.\nThe results with γ ∈{0.9, 0.5, 0.3} are similar and reported in Table 5, Ta-\nble 6, and Table 7 (see Appendix §A.1). We have performed additional simulation\nexperiments on datasets with ground truth outliers, where original features are\ntreated as PI and newly added columns with Gaussian noise as X space (or\nprimary) features. Details of those experiments are reported in Appendix §A.2.\n4.2\nReal-world Use Cases\nData description.\nLingSpam dataset3 consists of 2412 non-spam and 481\nspam email messages from a linguistics mailing-list. We evaluate two use cases\n(1) domain-expert knowledge as PI and (2) compute-expensive PI on LingSpam.\nBotOrNot dataset4 is collected from Twitter during December 30, 2009 to\nAugust 2, 2010. It contains 22,223 content polluters (bots) and 19,276 legitimate\nusers, along with their number of followings over time and tweets. For our exper-\niments, we select accounts with age less than 10 days (for early detection task) at\nthe beginning of dataset collection. The subset contains 901 legitimate (human)\naccounts and 4535 bots. We create 10 sets containing all the legitimate and a\nrandom 10% sample of the bots. We evaluate use case (3) “historical future” as\nPI report results averaged over these sets.\nCase 1: Domain-expert Knowledge as PI for Email Spam Detection.\nX∗space: The Linguistic Inquiry and Word Count (LIWC) software5 is\na widely used text analysis tool in social sciences. It uses a manually-curated\nkeyword dictionary to categorize text into 90 psycholinguistic classes. Construc-\ntion of LIWC dictionary relies exclusively on human experts which is a slow\nand evolving process. For the LingSpam dataset, we use the percentage of word\ncounts in each class (assigned by LIWC software) as the privileged features.\n5 https://liwc.wpengine.com/\n14\nShubhranshu Shekhar\nLeman Akoglu\nTable 4: SPI and SPI-lite rank better than competing methods w.r.t. diﬀerent\nevaluation metrics. Results are averaged across 15 runs. iF* shown for reference.\nUse case\nMetric\niF OC+\nFT SPI-l\nSPI\niF*\nDomain-expert\nKnowledge as PI\nMAP\n0.2767 0.2021 0.4449 0.4604 0.4317\n0.4708\nAUC\n0.5357 0.5379 0.7942 0.8182 0.8141\n0.8330\nndcg@k 0.3575 0.2468 0.4783 0.4873 0.4613\n0.4975\np@k\n0.2931 0.2236 0.4265 0.4279 0.4071\n0.4473\nCompute-\nExpensive\nFeatures as PI\nMAP\n0.2767 0.1975 0.2892 0.3140 0.3131\n0.3216\nAUC\n0.5357 0.5369 0.5781 0.6232 0.6184\n0.6572\nndcg@k 0.3575 0.2275 0.3680 0.3899 0.3924\n0.3930\np@k\n0.2931 0.2200 0.2974 0.3182 0.3225\n0.3283\nX space: The bag-of-word model is widely used as feature representation in\ntext analysis. As such, we use the term frequencies for our email corpus as the\nprimary features.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFPR\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nTPR\nIF = 0.5357\nOC+ = 0.5379\nFT = 0.7942\nSPI-L = 0.8182\nSPI = 0.8141\nIF* = 0.8330\nFig. 4: Detection performance on Case 1: us-\ning expert knowledge as PI. Legend depicts\nthe AUC values. PI-incorporated detectors\n(except OC-SVM+) outperform non-PI iF\nand achieve similar performance to iF*.\nFigure\n4\nshows\nthe\ndetection\nperformance of algorithms in ROC\ncurves (averaged over 15 indepen-\ndent runs on stratiﬁed train-test\nsplits). We ﬁnd that iF, which does\nnot leverage PI but operates solely\nin X space, is signiﬁcantly worse\nthan most PI-incorporated methods.\nOC-SVM+ is nearly as poor as\niF despite using PI—this is poten-\ntially due to OC-SVM being a poor\nanomaly detector in the ﬁrst place,\nas shown in [6] and as we argued\nin §1. All knowledge transfer meth-\nods, SPI, SPI-lite, and FT, per-\nform similarly on this case study, and\nare as good as iF*, directly using X∗.\nIn Table 4, we report detection performance of algorithms with respect to\nwidely used ranking metrics including MAP, ndcg@k and precision@k (av-\neraged over 15 independent runs on stratiﬁed train-test splits) for use cases on\nLingSpam dataset. Notice that the results are consistent (with AUC) across\nmeasures, SPI and SPI-lite performing among the best.\nCase 2: Compute-Expensive Features as PI for Email Spam Detection.\nX∗space: Beyond bag-of-words, one can use syntactic features to capture\nstylistic diﬀerences between spam and non-spam emails. To this end, we extract\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n15\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFPR\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nTPR\nIF = 0.5357\nOC+ = 0.5369\nFT = 0.5781\nSPI-L = 0.6232\nSPI = 0.6184\nIF* = 0.6572\n0.25\n0.5\n0.75\n1.0\nFraction of test data\n0.001\n0.01\n0.1\n1\n10\nWall-clock time in sec (x1000)\niF\noc+\nFT\nSPI-l\nSPI\niF*\n10−1\n101\nTime in sec.(x1000)\n0.55\n0.60\n0.65\nAUC\nOur methods\n~5500x\nspeed-up\n~10 hours\n~7 seconds\nFig. 5: Comparison of detectors on Case 2: using computationally-expensive features\nas PI. (a) detection performance, legend depicts AUC values; and (b) wall-clock time\nrequired (in seconds, note the logarithmic scale) vs. test data size [inset plot on top\nright: AUC vs. time (methods depicted with symbols)].\nfeatures from the parse trees of emails using the StanfordParser6. The parser\nprovides the taxonomy (tree) of Part-of-Speech (PoS) tags for each sentence,\nbased on which we construct (i) PoS bi-gram frequencies, and (ii) quantitative\nfeatures (width, height, and horizontal/vertical imbalance) of the parse tree.\nOn average, StanfordParser requires 66 seconds7 to parse and extract features\nfrom a single raw email in LingSpam. Since the features are computationally\ndemanding, we incorporate those as PI to facilitate faster detection at test time.\nX space: We use the term frequencies as the primary features as in Case 1.\nFigure 5 (a) shows the detection performance of methods in terms of AUC\nunder ROC. We ﬁnd that iF*using (privileged) syntactic features achieves lower\nAUC of ∼0.65 as compared to ∼0.83 using (privileged) LIWC features in Case 1.\nAccordingly, all methods perform relatively lower, suggesting that the syntactic\nfeatures are less informative of spam than psycholinguistic ones. Nonetheless,\nwe observe that the performance ordering remains consistent, where iF ranks at\nthe bottom and SPI and SPI-lite get closest to iF*.\nFigure 5 (b) shows the comparison of wall-clock time required by each detec-\ntor to compute the anomaly scores at test time for varying fraction of test data.\nOn average, SPI achieves 5500× speed-up over iF* that employs the parser at\ntest time. This is a considerable improvement of response time for comparable\naccuracy. Also notice the inset plot showing the AUC vs. total test time, where\nour proposed SPI and SPI-lite are closest to the ideal point at the top left.\nTable 4 quantiﬁes performance of methods against other metrics which are\nconsistent with AUC.\nCase 3: “Historical Future” as PI for Twitter Bot Detection.\nWe use temporal data from the activity and network evolution of an account\nto capture behavioral diﬀerences between a human and a bot. We construct\ntemporal features including volume, rate-of-change, and lag-autocorrelations of\nthe number of followings. We also extract temporal features from text such as\ncount of tweets, links, hash-tags and mentions.\n6 https://nlp.stanford.edu/software/lex-parser.shtml\n7 using a single thread on 2.2 GHz Intel Core i7 CPU with 8 cores and 16GB RAM\n16\nShubhranshu Shekhar\nLeman Akoglu\nX∗space: All the temporal features within ft days in the future (relative\nto detection at time t) constitute privileged features. Such future values would\nnot be available at any test time point but can be found in historical data.\nX space: Temporal features within ht days in the past as well as static user\nfeatures (from screen name and proﬁle description) constitute primary features.\nFigure 6 (a) reports the detection performance of algorithms in terms of ROC\ncurves (averaged over 10 sets) at time t = 2 days after the data collection started;\nfor ht = 2, ft = 7. The ﬁndings are similar to other cases: SPI and SPI-lite\noutperform the competing methods in terms of AUC and OC-SVM+ performs\nsimilar to non-PI iF; demonstrating that knowledge transfer based methods are\nmore suitable for real-world use cases.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFPR\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nTPR\nIF = 0.7758\nOC+ = 0.7749\nFT = 0.8087\nSPI-L = 0.8481\nSPI = 0.8312\nIF* = 0.9285\nt = 0\nt = 1\nt = 2\nt = 3\nt = 4\nEvaluation at t\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\nAUC\niF\nSPI\niF*\n24 hours\n~7% AUC gain\nFig. 6: Comparison of detectors on Case 3: using “historical future” data as PI. (a) SPI\noutperforms competition in performance and is closest to iF*’s; (b) SPI achieves same\ndetection performance as iF 24 hours earlier, and gets close to iF*in 3 days of history.\nFigure 7 shows the eﬀect of number look ahead days as PI on the performance\nof PI incorporated methods. We ﬁnd that the gain in performance through PI\nsaturates in about a week indicating that temporally local network changes are\nmore valuable for bot detection task. Once again, SPI and SPI-lite outperform\ncompeting methods at bot detection task over varying number of future days as\nPI.\nFigure 6 (b) compares the detection performance of SPI and iF over time;\nfor detection at t = {0, 1, 2, 3, 4}. As time passes, historical data grows as ht =\n{0, 1, 2, 3, 4} where “historical future” data is ﬁxed at ft = 7 for PI-incorporated\nmethods. Notice that at time t = 1, SPI achieves similar detection performance\nto iF’s performance at t = 2 that uses more historical data of 2 days. As such,\nSPI enables 24 hours early detection as compared to non-PI iF for the same\naccuracy. Notice that with the increase in historical data, the performances of\nboth methods improve, as expected. At the same time, that of SPI improves\nfaster, ultimately reaching a higher saturation level, speciﬁcally ∼7% higher\nrelative to iF. Moreover, SPI gets close to iF*’s level in just around 3 days.\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n17\nft = 1\nft = 3\nft = 5\nft = 7\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\nAUC\niF\noc+\nFT\nSPI-l\nSPI\niF*\nFig. 7: Eﬀect of future information on PI incorporated method. ht = 3 and\nft ∈{1, 3, 5, 7} days\n5\nRelated Work\nWe review the history of LUPI, follow up and related work on learning with\nside/hidden information, as well as LUPI-based anomaly detection.\nLearning Under Privileged Information: The LUPI paradigm is intro-\nduced by Vapnik and Vashist [19] as the SVM+ method, where, Teacher provides\nStudent not only with (training) examples but also explanations, comparisons,\nmetaphors, etc. which accelerate the learning process. Roughly speaking, PI ad-\njusts Student’s concept of similarity between training examples and reduces the\namount of data required for learning. Lapin et al. [10] showed that learning\nwith PI is a particular instance of importance weighting in SVMs. Another such\nmechanism was introduced more recently by Vapnik and Izmailov [17], where\nknowledge is transferred from the space of PI to the space where the decision\nfunction is built. The general idea is to specify a small number of fundamental\nconcepts of knowledge in the privileged space and then try to transfer them; i.e.,\nconstruct additional features in decision space via e.g., regression techniques in\ndecision space. Importantly, the knowledge transfer mechanism is not restricted\nto SVMs, but generalizes, e.g. to neural networks [18].\nLUPI has been applied to a number of diﬀerent settings including clustering\n[7,12], metric learning [8], learning to rank [15], malware and bot detection [2,3],\nrisk modeling [14], as well as recognizing objects [16], actions and events [13].\nLearning with Side/Hidden Information: Several other work, particularly in\ncomputer vision [4,20], propose methods to learn with data that is unavailable\nat test time referred as side and hidden information (e.g., text descriptions or\ntags for general images, facial expression annotations for face images, etc.). In\naddition, Jonschkowski et al. [9] describe various patterns of learning with side\ninformation. All of these work focus on supervised learning problems.\nLUPI-based Anomaly Detection: With the exception of One-Class SVM\n(OC-SVM+) [2], which is a direct extension of Vapnik’s (supervised) SVM+,\n18\nShubhranshu Shekhar\nLeman Akoglu\nthe LUPI framework has been utilized only for supervised learning problems.\nWhile anomaly detection has been studied extensively [1], we are unaware of any\nwork other than [2] leveraging privileged information for unsupervised anomaly\ndetection. As we argued in §2 and empirically demonstrated through benchmark\nexperiments [6], OC-SVM+ is not an eﬀective solution to anomaly detection.\nMotivated by this along with the premises of the LUPI paradigm, we are the ﬁrst\nto design a new technique that ties LUPI with unsupervised tree-based ensemble\nmethods, which are considered state-of-the-art for anomaly detection.\n6\nConclusion\nWe introduced SPI, a new ensemble approach that leverages privileged infor-\nmation (data available only for training examples) for unsupervised anomaly\ndetection. Our work builds on the LUPI paradigm, and to the best of our knowl-\nedge, is the ﬁrst attempt to incorporating PI to improve the state-of-the-art\nensemble detectors. We validated the eﬀectiveness of our method on both bench-\nmark datasets as well as three real-world case studies. We showed that SPI and\nSPI-lite consistently outperform the baselines. Our case studies leveraged a\nvariety of privileged information—“historical future”, complex features, expert\nknowledge—and veriﬁed that SPI can unlock multiple beneﬁts for anomaly de-\ntection in terms of detection latency, speed, as well as accuracy.\nReferences\n1. C. C. Aggarwal. Outlier Analysis. Springer, 2013.\n2. E. Burnaev and D. Smolyakov. One-class SVM with privileged information and\nits application to malware detection. In ICDM Workshops, pages 273–280, 2016.\n3. Z. B. Celik, P. McDaniel, R. Izmailov, N. Papernot, and A. Swami. Extending\ndetection with forensic information. arXiv:1603.09638, 2016.\n4. J. Chen, X. Liu, and S. Lyu. Boosting with side information. In ACCV, 2012.\n5. J. Demšar. Statistical comparisons of classiﬁers over multiple data sets. Journal\nof Machine Learning Research, 7(Jan):1–30, 2006.\n6. A. Emmott, S. Das, T. Dietterich, A. Fern, and W.-K. Wong. Systematic con-\nstruction of anomaly detection benchmarks from real data. In KDD ODD, 2013.\n7. J. Feyereisl and U. Aickelin. Privileged information for data clustering. Inf. Sci.,\n194:4–23, 2012.\n8. S. Fouad, P. Tino, S. Raychaudhury, and P. Schneider. Incorporating privileged\ninformation through metric learning. IEEE Neural Net. Learning Sys., 24(7), 2013.\n9. R. Jonschkowski, S. Höfer, and O. Brock. Patterns for learning with side informa-\ntion. arXiv:1511.06429, 2015.\n10. M. Lapin, M. Hein, and B. Schiele. Learning using privileged information: Svm+\nand weighted svm. Neural Networks, 53:95–108, 2014.\n11. F. T. Liu, K. M. Ting, and Z.-H. Zhou. Isolation forest. In ICDM, 2008.\n12. R. M. Marcacini, M. A. Domingues, E. R. Hruschka, and S. O. Rezende. Privileged\ninformation for hierarchical document clustering: A metric learning approach. In\nICPR, pages 3636–3641, 2014.\n13. L. Niu, W. Li, and D. Xu. Exploiting privileged information from web data for\naction and event recognition. Intern. J. of Comp. Vision, 118(2):130–150, 2016.\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n19\n14. B. Ribeiro, C. Silva, N. Chen, A. Vieira, and J. C. das Neves. Enhanced default\nrisk models with SVM+. Expert Syst. Appl., 39(11):10140–10152, 2012.\n15. V. Sharmanska, N. Quadrianto, and C. H. Lampert. Learning to rank using priv-\nileged information. In ICCV, pages 825–832, 2013.\n16. V. Sharmanska, N. Quadrianto, and C. H. Lampert. Learning to transfer privileged\ninformation. arXiv:1410.0389, 2014.\n17. V. Vapnik and R. Izmailov. Learning with intelligent teacher: Similarity control\nand knowledge transfer. In Stat. Learning and Data Sci., pages 3–32, 2015.\n18. V. Vapnik and R. Izmailov. Knowledge transfer in svm and neural networks. Ann.\nMath. Artif. Intell., 81(1-2):3–19, 2017.\n19. V. Vapnik and A. Vashist. A new learning paradigm: Learning using privileged\ninformation. Neural Networks, 22(5-6):544–557, 2009.\n20. Z. Wang and Q. Ji. Classiﬁer learning with hidden information. In CVPR, 2015.\nA\nAppendix\nA.1\nBenchmark Evaluation\nWe report the results on perturbed datasets with γ ∈{0.9, 0.5, 0.3} as fraction\nof features retained in space X∗. Table 5, Table 6, and Table 7 report MAP\nagainst 17 datasets for diﬀerent methods for γ ∈{0.9, 0.5, 0.3}. The results are\naveraged across 5 independent runs on stratiﬁed train-test splits.\nTable 5: Mean Average Precision (MAP) on benchmark datasets (avg’ed over 5\nruns) for γ = 0.9. iF* (for reference only) reports MAP in the X∗space.\nDataset\np+d\nn\niF OC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer\n30\n357\n0.0921 0.0945 0.0758\n0.0917\n0.1074\n0.6584\nionosphere\n33\n225\n0.0509 0.1010 0.0566\n0.0400\n0.1029\n0.1997\nletter-recognition\n617 4197\n0.0756 0.1052 0.0854\n0.0848\n0.3014\n0.9331\nmultiple-features\n649 1200\n0.1351 0.1047 0.3521\n0.4188\n0.6687\n1.0000\nwall-following-robot\n24 2923\n0.1496 0.1345 0.1288\n0.1213\n0.1223\n0.7288\ncardiotocography\n27 1831\n0.1868 0.3577 0.1768\n0.3766\n0.4269\n0.8131\nisolet\n617 4497\n0.1284 0.1251 0.1282\n0.1789\n0.2766\n0.9688\nlibras\n90\n216\n0.0712 0.1126 0.0883\n0.2756\n0.1476\n1.0000\nparkinsons\n22\n147\n0.0443 0.1378 0.0486\n0.0619\n0.1485\n0.1889\nstatlog-satimage\n36 3594\n0.1387 0.0906 0.1423\n0.1332\n0.1234\n0.9999\ngisette\n4971 3500\n0.0892 0.0843 0.1039\n0.1953\n0.3771\n0.9968\nwaveform-1\n21 3304\n0.1052 0.1086 0.0933\n0.1035\n0.0974\n0.5201\nmadelon\n500 1300\n0.3009 0.1090 0.5529\n0.6215\n0.8232\n1.0000\nsynthetic-control-chart 60\n400\n0.2495 0.4334 0.4167\n0.3889\n0.5025\n1.0000\nwaveform-2\n21 3304\n0.0906 0.1199 0.0937\n0.1105\n0.1027\n0.4253\nstatlog-vehicle\n18\n629\n0.0918 0.1309 0.0950\n0.1110\n0.1474\n1.0000\nstatlog-segment\n18 1320\n0.0997 0.1348 0.1928\n0.1968\n0.1831\n0.7943\n20\nShubhranshu Shekhar\nLeman Akoglu\nTable 6: Mean Average Precision (MAP) on benchmark datasets (avg’ed over 5\nruns) for γ = 0.5. iF* (for reference only) reports MAP in the X∗space.\nDataset\np+d\nn\niF OC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer\n30\n357\n0.1718 0.2991 0.5926\n0.5725\n0.6787\n0.8224\nionosphere\n33\n225\n0.0518 0.1445 0.0557\n0.0428\n0.0500\n0.5833\nletter-recognition\n617 4197\n0.1127 0.2436 0.0793\n0.4652\n0.7950\n0.9079\nmultiple-features\n649 1200\n0.2137 0.1184 0.4486\n0.8456\n0.9580\n1.0000\nwall-following-robot\n24 2923\n0.2995 0.5545 0.2164\n0.4134\n0.5035\n0.5611\ncardiotocography\n27 1831\n0.4044 0.5945 0.2133\n0.6840\n0.6396\n0.7824\nisolet\n617 4497\n0.1833 0.2360 0.1229\n0.5454\n0.8015\n0.9051\nlibras\n90\n216\n0.1448 0.5419 0.8333\n1.0000\n1.0000\n1.0000\nparkinsons\n22\n147\n0.0772 0.0957 0.1369\n0.1476\n0.1889\n0.3333\nstatlog-satimage\n36 3594\n0.3410 0.6395 0.8667\n0.9739\n0.9878\n0.9885\ngisette\n4971 3500\n0.1522 0.0910 0.1058\n0.6013\n0.9494\n0.9921\nwaveform-1\n21 3304\n0.1702 0.4247 0.1668\n0.2952\n0.3123\n0.6266\nmadelon\n500 1300\n0.9943 0.1115 1.0000\n0.9811\n0.9786\n1.0000\nsynthetic-control-chart\n60\n400\n0.4901 1.0000 0.5108\n0.8711\n0.8875\n0.9587\nwaveform-2\n21 3304\n0.1881 0.4368 0.3215\n0.3573\n0.3595\n0.4162\nstatlog-vehicle\n18\n629\n0.2397 0.4683 0.8672\n0.7304\n0.7886\n0.8593\nstatlog-segment\n18 1320\n0.2013 0.3572 0.1043\n0.2983\n0.4190\n0.3724\nTable 7: Mean Average Precision (MAP) on benchmark datasets (avg’ed over 5\nruns) for γ = 0.3. iF* (for reference only) reports MAP in the X∗space.\nDataset\np+d\nn\niF OC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer\n30\n357\n0.2358 0.4469 0.2432\n0.3988\n0.4424\n0.6506\nionosphere\n33\n225\n0.0534 0.2382 0.0482\n0.0430\n0.0519\n0.0520\nletter-recognition\n617 4197\n0.1449 0.4707 0.0835\n0.5839\n0.8361\n0.9382\nmultiple-features\n649 1200\n0.3053 0.1238 0.3795\n0.7876\n0.9263\n0.9958\nwall-following-robot\n24 2923\n0.4448 0.3954 0.3217\n0.3528\n0.3956\n0.4500\ncardiotocography\n27 1831\n0.5827 0.8330 0.2060\n0.7850\n0.7695\n0.8812\nisolet\n617 4497\n0.2753 0.4870 0.1021\n0.6902\n0.8756\n0.8871\nlibras\n90\n216\n0.5278 0.5245 0.0369\n1.0000\n1.0000\n1.0000\nparkinsons\n22\n147\n0.1037 0.1109 0.0376\n0.2778\n0.3889\n0.4509\nstatlog-satimage\n36 3594\n0.5209 0.6722 0.9587\n0.9932\n0.9835\n0.9914\ngisette\n4971 3500\n0.2544 0.0876 0.1066\n0.8696\n0.9819\n0.9667\nwaveform-1\n21 3304\n0.3039 0.6456 0.1564\n0.2109\n0.2061\n0.2539\nmadelon\n500 1300\n1.0000 0.1103 1.0000\n0.9912\n1.0000\n1.0000\nsynthetic-control-chart\n60\n400\n0.7791 1.0000 0.3982\n0.9778\n0.9444\n1.0000\nwaveform-2\n21 3304\n0.2429 0.5012 0.3237\n0.3607\n0.3387\n0.5368\nstatlog-vehicle\n18\n629\n0.4156 0.6411 0.7945\n0.9363\n0.9618\n0.8729\nstatlog-segment\n18 1320\n0.3764 0.9049 0.0700\n0.3441\n0.3413\n0.3596\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n21\nOur methods perform better compared to competition on majority of\ndatasets. To compare the methods statistically, we use Friedman test based on\naverage rank of methods; for γ ∈{0.9, 0.5, 0.3}. With p-val << 0.01, we reject\nthe null hypothesis that methods are equivalent across γ values. We then pro-\nceed with Nemenyi post-hoc test to compare the algorithms pairwise and to ﬁnd\nout the ones that diﬀer signiﬁcantly. The test identiﬁes performance of two al-\ngorithms to be signiﬁcantly diﬀerent if their average ranks diﬀer by at least the\n“critical diﬀerence” (CD).\n1\n2\n3\n4\n5\n6\niF*\nSPI\nSPI-l\noc+\nFT\niF\nCD\n(a) γ = 0.9\n1\n2\n3\n4\n5\n6\niF*\nSPI\nSPI-l\noc+\nFT\niF\nCD\n(b) γ = 0.5\n1\n2\n3\n4\n5\n6\niF*\nSPI\nSPI-l\noc+\niF\nFT\nCD\n(c) γ = 0.3\nFig. 8: Comparison of algorithms in terms of average rank (wrt MAP) with the\nNemenyi test on perturbed datasets with diﬀerent γ values. Groups of methods\nthat are not signiﬁcantly diﬀerent (at p-val = 0.05) are connected.\nResults of the post-hoc test are summarized through a graphical represen-\ntation in Figure 8. For γ = 0.9, we ﬁnd that iF* always ranks at 1, since we\nretain 90% of X∗feature. Even with 10% useful features in X space, SPI is\nsigniﬁcantly better than iF, and SPI has no signiﬁcant diﬀerence when com-\npared to iF*. Other methods are comparable in performance to iF indicating\nthat algorithms failed to exploit the minimal useful features present in X space.\n22\nShubhranshu Shekhar\nLeman Akoglu\nFor γ = 0.5 (Figure 8), we ﬁnd that SPI has no signiﬁcant diﬀerence when\ncompared to iF*. While all the PI incorporated methods are comparable, on\naverage SPI and SPI-lite rank better than the baselines.\nFor γ = 0.3 (Figure 8), we ﬁnd that iF (X-only) has no signiﬁcant diﬀerence\nfrom iF* (X∗only). This is expected since X space has many useful features.\nOur methods have no signiﬁcant diﬀerence from either iF or iF*. While there is\nno signiﬁcant diﬀerence, on average our methods still rank better than others.\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\n(a) MAP\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(b) AUC\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(c) ndcg@10\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(d) precision@10\nFig. 9: SPI and SPI-lite outperform competition w.r.t. diﬀerent evaluation\nmetrics row-wise for γ ∈{0.9, 0.5, 0.3}. Average rank (bars) across benchmark\ndatasets. iF* shown for reference.\nWe also report average rank of the algorithms against widely used ranking\nmetrics including AUC of ROC curve, ndcg@10 and precision@10 in Fig-\nure 9. Notice that the results are consistent across measures for γ ∈{0.9, 0.5, 0.3},\nSPI and SPI-lite performing among the best.\nA.2\nBenchmark Evaluation: Simulation 2\nAs mentioned earlier, the benchmark datasets do not have an explicit PI rep-\nresentation. Given a p dimensional dataset, we identify two groups of features\nthat represent X space and X∗space in the following way.\nX∗space: The original feature representation of the dataset is used as PI.\nX space: We create X space by generating new feature columns with Gaus-\nsian noise. In particular, we generate columns 10 times of original dataset di-\nmensionality with Gaussian noise N(0.01µ, 0.01σ) where µ is the mean and σ is\nthe standard deviation of all features in the original dataset.\nSimilar to ﬁrst simulation setting, we construct 4 versions per dataset with\nvarying fraction γ of original features (PI) retained in X∗space. In partic-\nular, each set has γp features in X∗, and (1 −γ)p+10p features in X for\nγ ∈{0.9, 0.7, 0.5, 0.3}.\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n23\nResults:\nWe\nreport\nthe\nresults\non\nperturbed\ndatasets\nwith\nγ\n∈\n{0.9, 0.7, 0.5, 0.3} as fraction of features retained in space X∗. Table 8, Table 9,\nTable 10, and Table 11 report MAP against 7 datasets for diﬀerent methods for\nγ ∈{0.9, 0.7, 0.5, 0.3}. The results are averaged across 5 independent runs on\nstratiﬁed train-test splits.\nTable 8: Mean Average Precision (MAP) on perturbed datasets (averaged over\n5 runs); for γ = 0.9. iF* (reference) reports MAP in the X∗space.\nDataset\np Outliers\niF OC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer 30\n211\n0.5159 0.2206 0.7139\n0.7247\n0.7979\n0.7764\nionosphere\n33\n125\n0.3957 0.5208 0.3935\n0.5377\n0.6939\n0.6984\ncardio\n21\n176\n0.1240 0.1493 0.5810\n0.3531\n0.4355\n0.6314\nsatellite\n36\n2036\n0.3771 0.3384 0.7233\n0.7388\n0.7347\n0.7257\nwbc\n30\n21\n0.1506 0.2530 0.2247\n0.0995\n0.2994\n0.6208\nuci-ionosphere 33\n126\n0.3971 0.5462 0.4773\n0.6034\n0.7128\n0.7703\nsatimage-2\n36\n71\n0.0206 0.0069 0.7425\n0.6186\n0.6956\n0.9015\nTable 9: Mean Average Precision (MAP) on perturbed datasets (averaged over\n5 runs); for γ = 0.7. iF* (reference) reports MAP in the X∗space.\nDataset\np Outliers\niF OC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer 30\n211\n0.5714 0.2196 0.7324\n0.6931\n0.7399\n0.7431\nionosphere\n33\n125\n0.4793 0.4545 0.3500\n0.7041\n0.7043\n0.7134\ncardio\n21\n176\n0.1962 0.0756 0.8379\n0.5315\n0.6518\n0.8582\nsatellite\n36\n2036\n0.4446 0.2384 0.7056\n0.7217\n0.7060\n0.7221\nwbc\n30\n21\n0.1003 0.3702 0.6000\n0.2624\n0.5563\n0.6204\nuci-ionosphere 33\n126\n0.4253 0.3946 0.4391\n0.6609\n0.7353\n0.8214\nsatimage-2\n36\n71\n0.0871 0.0042 0.7377\n0.8017\n0.8400\n0.9481\nTo compare the methods statistically, we use Friedman test based on average\nrank of methods; for γ ∈{0.9, 0.7, 0.5, 0.3}. With p-val << 0.01, we reject the\nnull hypothesis that methods are equivalent across γ values. We proceed with\nthe Nemenyi post hoc test to ﬁnd out which methods actually diﬀer.\nWe summarize our ﬁnding after post hoc test graphically in Figure 10. For\nγ = 0.9, we ﬁnd that all the PI incorporated methods except OC-SVM+ have\nno signiﬁcant diﬀerence when compared to iF*. Our method SPI signiﬁcantly\noutperforms iF. While the PI incorporated methods are comparable, on average\nour methods rank better than others.\n24\nShubhranshu Shekhar\nLeman Akoglu\nTable 10: Mean Average Precision (MAP) on perturbed datasets (averaged over\n5 runs); for γ = 0.5. iF* (reference) reports MAP in the X∗space.\nDataset\np Outliers\niF OC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer 30\n211\n0.5740 0.2196 0.7981\n0.7224\n0.7214\n0.7656\nionosphere\n33\n125\n0.5644 0.3429 0.3378\n0.6246\n0.6933\n0.7213\ncardio\n21\n176\n0.2209 0.0950 0.6250\n0.5380\n0.6108\n0.6082\nsatellite\n36\n2036\n0.5627 0.2359 0.6718\n0.7052\n0.6660\n0.7292\nwbc\n30\n21\n0.1804 0.2322 0.5829\n0.3817\n0.5103\n0.6094\nuci-ionosphere 33\n126\n0.5172 0.3871 0.4339\n0.6240\n0.7212\n0.8234\nsatimage-2\n36\n71\n0.1675 0.0042 0.7353\n0.8101\n0.8029\n0.8882\nTable 11: Mean Average Precision (MAP) on perturbed datasets (averaged over\n5 runs); for γ = 0.3. iF* (reference) reports MAP in the X∗space.\nDataset\np Outliers\niF OC+\nFT SPI-lite\nSPI\niF*\nbreast-cancer 30\n211\n0.6108 0.2193 0.6706\n0.6682\n0.6272\n0.6122\nionosphere\n33\n125\n0.6045 0.2817 0.3587\n0.6683\n0.7198\n0.7230\ncardio\n21\n176\n0.3305 0.1171 0.5851\n0.5044\n0.5230\n0.5254\nsatellite\n36\n2036\n0.6029 0.2359 0.6662\n0.7034\n0.6530\n0.6726\nwbc\n30\n21\n0.2769 0.2115 0.4791\n0.4823\n0.4419\n0.4759\nuci-ionosphere 33\n126\n0.6244 0.3728 0.4420\n0.6830\n0.7225\n0.7768\nsatimage-2\n36\n71\n0.3827 0.0043 0.7450\n0.7949\n0.8305\n0.8327\nIncorporating Privileged Information to Unsupervised Anomaly Detection\n25\n1\n2\n3\n4\n5\n6\niF*\nSPI\nSPI-l\nFT\noc+\niF\nCD\n(a) γ = 0.9\n1\n2\n3\n4\n5\n6\niF*\nSPI\nSPI-l\nFT\niF\noc+\nCD\n(b) γ = 0.7\n1\n2\n3\n4\n5\n6\niF*\nSPI\nSPI-l\nFT\niF\noc+\nCD\n(c) γ = 0.5\n1\n2\n3\n4\n5\n6\niF*\nSPI-l\nSPI\nFT\niF\noc+\nCD\n(d) γ = 0.3\nFig. 10: Simulation 2: Comparison of algorithms in terms of average rank (wrt\nMAP) with the Nemenyi test for diﬀerent γ values. Groups of methods that are\nnot signiﬁcantly diﬀerent (at p-val = 0.05) are connected.\n26\nShubhranshu Shekhar\nLeman Akoglu\nFor γ = 0.7 and γ = 0.5 (Figure 10), we ﬁnd that methods incorporating PI\nthrough knowledge transfer have no signiﬁcant diﬀerence to iF*. While all the\nPI incorporated methods are comparable except OC-SVM+, comparatively on\naverage our methods rank better.\nFor γ = 0.3 (Figure 10), we ﬁnd that iF (X-only) has no signiﬁcant diﬀerence\nfrom iF* (X∗only). This is expected since X space has many useful features.\nOur methods have no signiﬁcant diﬀerence from either iF or iF*. On average\nour methods still rank better than others.\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\nMean Rank\n(a) MAP\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(b) AUC\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(c) ndcg@10\niF\nFT\noc+ SPI-l SPI\niF*\n0.0\n2.5\n5.0\n(d) precision@10\nFig. 11: Simulation 2: SPI and SPI-lite rank better than competing methods\nw.r.t. diﬀerent evaluation metrics row-wise for γ ∈{0.9, 0.7, 0.5, 0.3}. Average\nrank (bars) across benchmark datasets. iF* shown for reference.\nWe also report average rank of the algorithms against other popular ranking\nmetrics including AUC of ROC curve, ndcg@10 and precision@10 in Fig-\nure 11. Notice that the results are consistent across measures for γ ∈{0.9, 0.7, 0.5,\n0.3}, SPI and SPI-lite rank better than competing methods.\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2018-05-06",
  "updated": "2018-05-24"
}