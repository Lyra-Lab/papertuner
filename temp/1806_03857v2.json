{
  "id": "http://arxiv.org/abs/1806.03857v2",
  "title": "Deep Learning for Classification Tasks on Geospatial Vector Polygons",
  "authors": [
    "Rein van 't Veer",
    "Peter Bloem",
    "Erwin Folmer"
  ],
  "abstract": "In this paper, we evaluate the accuracy of deep learning approaches on\ngeospatial vector geometry classification tasks. The purpose of this evaluation\nis to investigate the ability of deep learning models to learn from geometry\ncoordinates directly. Previous machine learning research applied to geospatial\npolygon data did not use geometries directly, but derived properties thereof.\nThese are produced by way of extracting geometry properties such as Fourier\ndescriptors. Instead, our introduced deep neural net architectures are able to\nlearn on sequences of coordinates mapped directly from polygons. In three\nclassification tasks we show that the deep learning architectures are\ncompetitive with common learning algorithms that require extracted features.",
  "text": "Deep Learning for Classiﬁcation Tasks on\nGeospatial Vector Polygons\nR.H. van ’t Veer∗\nP. Bloem†\nE.J.A. Folmer‡\nJune 12, 2019\nAbstract\nIn this paper, we evaluate the accuracy of deep learning approaches\non geospatial vector geometry classiﬁcation tasks. The purpose of this\nevaluation is to investigate the ability of deep learning models to learn\nfrom geometry coordinates directly. Previous machine learning research\napplied to geospatial polygon data did not use geometries directly, but\nderived properties thereof. These are produced by way of extracting ge-\nometry properties such as Fourier descriptors. Instead, our introduced\ndeep neural net architectures are able to learn on sequences of coordi-\nnates mapped directly from polygons.\nIn three classiﬁcation tasks we\nshow that the deep learning architectures are competitive with common\nlearning algorithms that require extracted features.\nAcknowledgements\nThis work was supported by the Dutch National Cadastre (Kadaster) and the\nAmsterdam Academic Alliance Data Science (AAA-DS) Program Award to the\nUvA and VU Universities. We would also like to thank the following organisa-\ntions. The source data for the neighbourhoods task is published by Statistics\nNetherlands (CBS) and distributed by the Publieke Dienstverlening op de Kaart\norganization (PDOK) under a Creative Commons (CC) Attribution license. The\ndata for the buildings task was published by the Dutch National Cadastre un-\nder a CC Zero license. The archaeological data in raw form is hosted by Data\nArchiving and Networked Services, and re-licensed by kind permission of copy-\nright holder ADC ArcheoProjecten under CC-BY-4.0. We thank Henk Scholten,\nFrank van Harmelen, Xander Wilcke, Maurice de Kleijn, Jaap Boter, Chris Lu-\ncas, Eduardo Dias, Brian de Vogel and anonymous reviewers for their helpful\ncomments.\n∗Vrije Universiteit Amsterdam, Kadaster, Geodan: r.h.vant.veer@vu.nl, orcid: https://\norcid.org/0000-0003-0520-6684\n†Vrije Universiteit Amsterdam, orcid: https://orcid.org/0000-0002-0189-5817\n‡University of Twente, Kadaster, orcid: https://orcid.org/0000-0002-7845-1763\n1\narXiv:1806.03857v2  [stat.ML]  11 Jun 2019\n1\nIntroduction\nFor many tasks, it is useful to analyse the geometric shapes of geospatial objects,\nsuch as in quality assessment or enrichment of map data (Fan et al, 2014) or\nsuch as the classiﬁcation of topographical objects (Keyes and Winstanley, 1999).\nMachine learning is increasingly used in geospatial analysis tasks.\nMachine\nlearning can learn from data by extracting patterns (Goodfellow et al, 2016,\n2).\nFor example, machine learning can be applied to classify building types\n(Xu et al, 2017), analyse wildﬁres (Araya et al, 2016), traﬃc safety (Eﬀati\net al, 2015), cluster spatial objects (Hagenauer, 2016), detect aircraft shapes\n(Wu et al, 2016) or classify road sections (Andr´aˇsik and B´ıl, 2016): tasks that\nextend beyond standard GIS processing operations. The prediction of house\nprices (Montero et al, 2018) and the estimation of pedestrian side walk widths\n(Brezina et al, 2017) are tasks that could also beneﬁt from the application of\nmachine learning analysis on geometric shapes.\nDeep learning is a relatively new addition to the collection of machine learn-\ning methods. Deep learning allows stacking multiple learning layers to form\na model that is able to train latent representations at varying levels of data\nabstraction (LeCun et al, 2015). In this paper, we will use the term shallow\nmachine learning (Ball et al, 2017, 2-3) to refer to methods that are not based\non deep learning methods. A distinguishing property of deep versus shallow\nlearning methods is that shallow learning requires a preprocessing step known\nin machine learning as feature extraction (LeCun et al, 2015, 438), a lossy data\ntransformation process. Shallow models require feature vectors as input data,\nso when using data of variable length such as geometries, shallow learning al-\ngorithms depend on feature extraction.\nOne advantage of deep models over\nshallow models is that these feature extraction methods are not required for\ndeep learning, which is why we want to explore the abilities of deep learning\nto operate on all available geometry data rather than on an extracted set of\nfeatures.\nThe purpose of this article is to assess the accuracy of working with vec-\ntor geometries in deep neural nets, by comparing them with existing shallow\nmachine learning methods in an experiment with three classiﬁcation tasks on\nvector polygons. Our main objective is to train deep learning models on all\navailable data. From this objective we do not require our deep learning models\nto exceed shallow model accuracy, but we do require the deep models to at least\nmatch shallow model accuracy. Thus, the main question we want to answer is:\nCan deep learning models achieve accuracies comparable with\nshallow learning models in analysing geospatial vector shapes?\nThese are the contributions made in this paper:\n1. We compare the performance of shallow and deep learning methods on\ngeospatial vector data, as detailed in Section 3. We show that the deep\nlearning models introduced here match shallow models in accuracy at\nclassiﬁcation tasks on real-world geospatial polygon data.\n2. We introduce three classiﬁcation tasks restricted to geospatial vector poly-\n2\nTerm\nGIS\nML\nGeometry\nA spatial representation\nof an object encoded as\none or more points that\nmay be interconnected\nVector\nA geometry deﬁned by\nvertices and edges\nA one-dimensional array\nVectorization\nConversion of raster or\nanalog data into\ngeospatial vector\ngeometries\nConversion of data into\na tensor interpretable by\na machine learning algo-\nrithm\nFeature\nA geospatial object\nA data property\nShape\nA geospatial object\ngeometry\nA tensor size along its di-\nmensions\nK-nearest neighbours\nThe k spatially closest\nobjects\nA\nlearning\nalgorithm\nbased on closest resem-\nblance\nTable 1: Terms in the ﬁelds of GIS and ML\ngons that serve as a novel and open access benchmark on geospatial vector\nshape recognition, detailed in Section 4. The benchmark data ﬁles are\navailable as open data.1\nSince the domains of geospatial information systems (GIS) and machine\nlearning (ML) have partially overlapping vocabularies, we provide Table 1 of\nhomonyms and their use in the two ﬁelds of GIS and ML. Where used in this\narticle, the terms are clariﬁed by their ﬁeld or, where possible, avoided.\nVector geometries as raster data\nOur research focuses on machine learn-\ning on geospatial vector data without rasterization of the geometry data. How-\never, as any geometry can be expressed as raster data, the question must be\naddressed why one should not simply convert vector data to raster and use ma-\nchine learning algorithms that are commonly used on raster data. The answer\nto this is that geospatial vector data is often better suited for representation\nof discrete geospatial objects, because rasterization leads to loss of information\nalmost everywhere:\n1. Geospatial vector data is highly versatile in representing geometries at\nvarying spatial levels of detail, whereas raster data has a resolution of\nﬁxed and uniform size. Geospatial vector data can leverage these diﬀerent\nlevels to represent, for example, the rough shape of a country and the\ndetailed shape of a microbe, at opposite sides of the globe within a single\nmulti-part geometry.\n1Data available at http://hdl.handle.net/10411/GYPPBR\n3\n2. Vector data is almost always more compact in comparison with raster\ndata. Depending on the accuracy of the source data, materialisation of\nvector data into raster data often requires expansion to transform the\nvector data into a uniform rasterized sampling of a continuous ﬁeld.\n3. Geospatial vector data can be reasoned over by any Geospatial Information\nSystem (GIS) in terms of topology: properties of geospatial objects with\nrespect to other geospatial objects in the same set that are invariant under\nlinear transformations, such as object intersection or spatial adjacency\n(Huisman and De By, 2009, 102). With rasterization, this information\nmay be partially or completely lost: a small gap between two disjoint\ngeometries for example may be lost if the pixel resolution is lower than\nthe gap size.\nThus, the rasterization process is trivial but lossy, where the inverse process\nof geospatial vectorization is non-trivial and requires human or algorithmic in-\nterpretation (Huisman and De By, 2009, 309). For these reasons, it is important\nto explore the capabilities of shape analysis by machine learning models without\nresorting to rasterization.\nThe further article structure is as follows: we position our work within re-\nlated research in Section 2, we explain the methods of our research in Section 3,\nwe discuss the classiﬁcation tasks in Section 4, and the model performance re-\nsults on these tasks in Section 5.\n2\nRelated work\nThe vast majority of machine learning research in the geospatial domain is\nfocused on analysis of remote sensing data, as shown by overview works from,\nfor example, Zhu et al (2017) and Ball et al (2017); and by challenges such as the\nCrowdAI mapping challenge2 and the DeepGlobe Machine Vision Challenge3\n(Demir et al, 2018).\nCompared to remote sensing raster data, far fewer publications go into the\nmatter of analysing geospatial vector shape data through machine learning\nstrategies. The most common method is to rasterize the vector shapes ﬁrst.\nXu et al (2017) have published a deep learning strategy for comparing building\nfootprints. However, the approach by Xu et al. requires preprocessing that ras-\nterizes aggregated data and does not classify individual geometries. Similarly,\nthe shapes in the deep learning image retrieval task through sketches described\nby Jiang et al (2017) are raster-based rather than vector-based abstractions, as\nare the aircraft shapes extracted from remote sensing in the work by Wu et al\n(2016). The work on 3D model retrieval by Wang et al (2017) uses a diﬀerent\nrasterization strategy: 2D-projected images are generated from 3D models to\ncreate an image search database. Cheng and Han (2016, 2-9) survey a number of\n2https://www.crowdai.org/challenges/mapping-challenge\n3http://www.grss-ieee.org/news/the-deepglobe-machine-vision-challenge/\n4\nworks involving geometric shape data, but aimed at classical (i.e. non-machine\nlearning) remote sensing object detection strategies, rather than on machine\nlearning analysis of the geometric shapes themselves. In contrast to the raster-\nbased strategies from these works, we aim to research the possibility of avoiding\nthe rasterization process and operate on geometries directly, as will be explained\nin Section 3.2.1.\nResearch on machine learning analysis of non-rasterized vector shapes is\nscarce. The algorithms used by Andr´aˇsik and B´ıl (2016) are trained directly\non geometry properties based on angles and radii of vertices in road sections,\nextracted from simpliﬁed road geometries. Their method, however, is optimized\nto the speciﬁc task of classifying short road sections from short polylines. Eﬀati\net al (2015, 120-121) adopt a similar strategy for the road properties for the\npurposes of traﬃc safety analysis. We aim to explore more generic shape anal-\nysis methods through machine learning, rather than task-speciﬁc ones. A deep\nlearning model operating on vector geometries was developed by Ha and Eck\n(2018), using a model they named sketch-rnn. Sketch-rnn shows how a deep\nlearning architecture can be used work with vector geometries directly. The\ndata collected for sketch-rnn used a web-based crowd-sourcing tool, inviting\nusers to draw simple vector drawings of cats, t-shirts and a host of other object\ncategories. Given an object category, the generative sketch-rnn model is able\nto analyse partial shapes drawn by the user and extrapolate these to complete\nsketches.4\n3\nMethods\nThe classiﬁcation tasks in this paper operate on real-world polygon data. To\nbe precise, we use the term polygon to mean a single connected sequence (i.e.\nwithout polygon holes) of three or more coplanar lines. Every line in a polygon\nis deﬁned by two points in R2, where each point is shared by exactly two lines to\nform a closed loop. We impose no validity constraint on polygons, i.e. polygons\nmay be self-intersecting.\n3.1\nShallow models\n3.1.1\nPreprocessing\nShallow machine learning methods operate on feature vectors of ﬁxed length,\nso more complex input data such as geometries need to be transformed. This\ntransformation step is known in machine learning as feature extraction (LeCun\net al, 2015, 438) or feature engineering (Domingos, 2012, 84). So, contrary to\ndeep learning models discussed in Section 3.3, shallow methods do not oper-\nate on geometry coordinates directly, since vector geometries are sequences of\nvertices that are both of higher rank and of variable length, as we will explain\n4https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html\n5\nFigure 1: Order 1, 2, 3 and 4 elliptic Fourier reconstruction approximations\n(red) of a polygon (blue). Each order level adds to the approximation. Adapted\nfrom Kuhl and Giardina (1982, 237)\nin Section 3.2.1. Applied to geospatial vector data, we rely on extracting in-\nformation from a geometry that characterizes its shape in a lower-dimensional,\nﬁxed-length representation.\nFourier descriptors are a common choice as a feature engineering method\nfor extracting properties from geometries (Zhang et al, 2002; Keyes and Win-\nstanley, 1999; Zahn and Roskies, 1972; Loncaric, 1998). For our preprocessing,\nwe used the Elliptic Fourier Descriptor (EFD) method by Kuhl and Giardina\n(1982). Elliptic Fourier descriptors are created by iterating over the coordinates\nof the vertices in a geometry, transforming any number of coordinates of the\ngeometry into a vector representing the geometry in an elliptic approximation.\nThis transformation can be reversed, producing an approximation of the origi-\nnal geometry, its reconstructive accuracy depending on the order or the number\nof harmonics (Kuhl and Giardina, 1982, 239), the order or number being a pos-\nitive integer. The higher the order, the better the approximation gets, as shown\nin Figure 1.\nThe Fourier descriptors were constructed using the pyefd package,5 which\nimplements the algorithms by Kuhl and Giardina (1982) made speciﬁcally for\ncreating descriptors for vector geometries. The pyefd package produces nor-\nmalized and non-normalized descriptors; the normalized descriptors are start\nposition, scale, rotation and translation invariant (Kuhl and Giardina, 1982,\n236). For the data used in training the shallow models, both normalized and\nnon-normalized Fourier descriptors were included.\nAdded to the descriptors\nare three other easily obtained geometry properties: the polygon surface area,\nnumber of vertices and geometry boundary length.\n5https://pypi.python.org/pypi/pyefd\n6\n3.1.2\nShallow model selection\nAs explained in Section 1 we distinguish between two families of machine learn-\ning methods. From the shallow model family, we selected four standard algo-\nrithms:\n• K-nearest neighbour classiﬁer;\n• Logistic regression;\n• Support Vector Machine (SVM) with Radial Basis Function (RBF) kernel.\nOther kernels (linear, polynomial) were tested but RBF always produced\nbetter results;\n• Decision tree classiﬁer.\nThese model types are so well-established that we will not elaborate upon\nthese here.\nLogistic regression goes back to Cox (1958), decision trees to\nBreiman et al (1984), k-nearest neighbour to at least Cover and Hart (1967).\nWith over twenty-ﬁve years of history, the SVM by Boser et al (1992) is the\nrelatively new algorithm in the shallow model family.\n3.2\nDeep models\n3.2.1\nPreprocessing\nThe problem with shallow model feature extraction of geospatial vector data is\nthat it results in information loss: the original shapes can only be approximated,\nbut not fully reconstructed by reversing the feature extraction process. Ideally,\nit would not be necessary to extract an information subset of geospatial data in\nadvance to obtain good predictions. Deep learning allows us to train models on\ngeospatial vector data by directly feeding the geometry coordinates to a deep\nlearning model, without extracting intermediate features. To explain how deep\nlearning is able to learn from polygon data directly, we need to discuss our\nmachine learning vectorization method.\n3.2.2\nGeometries as machine learning vector sequences\nOur geometry tensor encoding was derived from the work by Ha and Eck (2018),\nwhere each geometry sample Gi in a data set of size n is encoded as a sequence\nof geometry vertex vectors: ⟨gi\n1, gi\n2, gi\n3, . . . , gi\nm⟩, and where m is the number\nof vertices in the geometry. Each vector gi\nj is a concatenation of:\n• a coordinate point vector pi\nj in R2. In fact any coordinate system in R2\nis supported in this vector representation.\n• A one-hot vector ri\nj in R3 to mark the end of either the point, sub-geometry\nor a ﬁnal stop for the vertices in Gi. For each gi\nj in a polygon geometry,\nri\nj =\n\u00021\n0\n0\u0003\nexcept for the last vertex, where ri\nm marks the end of\n7\nthe polygon as the ﬁnal stop\n\u00020\n0\n1\u0003\n. In case of a multipolygon, each\nsub-polygon is terminated by a sub-geometry stop\n\u0002\n0\n1\n0\n\u0003\nexcept for\nthe last, which is marked as a ﬁnal stop.\nCombined, gi\nj is a vector of length 5, as shown in Figure 2.\nAs we explained in Section 1, the rasterization process is lossy. As such, it\ncan be considered a feature extraction method by which we lose information\nthat may be of use to the machine learning model. So, for our deep neural\nnet architectures, geometries are expressed as normalized vector sequences of\ngeometry vertices. This process is fully reversible in reconstructing the geometry\nshape and orientation, but it does require centering and scaling the data. For\ndeep learning models to perform, the data needs to be normalized to a mean of\nzero and scaled to a variance of about one.\nGeospatial coordinates are often expressed in degrees of longitude and lat-\nitude, where one degree of latitude equals roughly 111 kilometres. However,\nvector geometries usually operate on the level of meters or even centimetres. To\ncounter this normalization imbalance, every point vector pi\nj in every geometry\nGi, pi\nj is normalized to\npi\nj\n′ =\npi\nj −pi\ns\n,\n(1)\nwhere pi is the geometry centroid of geometry Gi, computed as the mean average\nof all pi in a single geometry Gi. Scale factor s is the standard deviation over the\nbounding values bi\nmin and bi\nmax of all geometries. bi\nmin and bi\nmax for a geometry\nGi are deﬁned as\nbi\nmin = min\n\u0010\npi −pi\n\u0011\n,\n(2)\nand\nbi\nmax = max\n\u0010\npi −pi\n\u0011\n.\n(3)\nThis is a simpler two-value version of the standard bounding box that would\nnormally list the minimum and maximum values for a geometry in two dimen-\nsions. Scale factor s is then computed as the scalar standard deviation over all\nbounding values B:\nB = ⟨b1\nmin, b1\nmax, b2\nmin, b2\nmax, . . . , bn\nmin, bn\nmax⟩\n(4)\nGeometries often vary in the number of vertices required to approximate the\nshape of a real-world object. As a consequence, the geometry vector sequences\nvary in length. Deep learning models have the beneﬁt of being able to train and\npredict on variable length sequences (Bahdanau et al, 2014). However, within\none batch the sequences need to be of the same length in order to uniformly\napply the model weights and biases on the entire batch as a single tensor. To\nachieve this ﬁxed sequence size within a batch, the geometry vectors are ﬁrst\nsorted in reverse order, with the largest geometry ﬁrst and the smallest last.\nThis sorted set of geometries is subdivided into bins of size nbin, where nbin is\nat least the training batch size. This is to increase computational eﬃciency and\n8\n52.3340\n52.3340\n52.3339\n52.3339\n52.3338\n52.3338\n4.8643\n4.8643\n4.8644\n4.8644\n4.8645\n4.8645\n4.8646\n4.8646\n4.8647\n4.8647\n(a)\nPolygon coordinates\nCenter: remove mean of\n[4.8644271, 52.3339057]\nScale:\ndivide by scale\nfactor of 2.64501e-4\n4.86447, 52.33384\n4.2857e-5, -6.5714e-5\n0.16198, -0.24845\n4.86447, 52.33386\n4.2857e-5, -4.5714e-5\n0.16198, -0.17283\n4.86456, 52.33386\n1.32857e-4, -4.5714e-5\n0.50229, -0.17283\n4.86456, 52.33386\n1.32857e-4, 1.44286e-4\n0.50229, 0.54550\n4.86423, 52.33405\n-1.97143e-4, 1.44286e-4\n-0.74534, 0.54550\n4.86423, 52.33405\n-1.97143e-4, -6.5714e-5\n-0.74534, -0.24845\n4.86447, 52.33384\n4.2857e-5, -6.5714e-5\n0.16959, -0.24845\n(b)\nTensor representation\n[0.16198, -0.24845, 1, 0, 0],\n[0.16198, -0.17283, 1, 0, 0],\n[0.50229, -0.17283, 1, 0, 0],\n[0.50229, 0.54550, 1, 0, 0],\n[-0.74534, 0.54550, 1, 0, 0],\n[-0.74534, -0.24845, 1, 0, 0],\n[0.16959, -0.24845, 0, 0, 1]\n(c)\nFigure 2: A building polygon (a) with its coordinate normalization by local mean\nsubtraction and global scaling (b) and the vector representation (c). Coordinates\n(in CRS84 projection) and standard deviation have been truncated to ﬁve digit\nprecision for the sake of brevity. In the ﬁnal tensor representation (c) the render\ntype is added.\n9\nreduce training time on what otherwise would be a large array of very small\nbatches. If there are insuﬃcient geometries of sequence length mbin to create\na set of samples of batch size, smaller geometries are added and padded to\nsequence length mbin. Thus, a geometry with a sequence length m of 144 points\nis zero-padded to a size mbin of 148 if the largest sequence length in the batch\nis 148. This preprocessing of binning and limited padding reduced the training\ntime to one quarter of the time needed for training on ﬁxed size sequences.\nAlthough there is no theoretical upper bound to the sequence length, there\nis a practical one for the amount of memory on commodity hardware. The data\nsets contain a small amount of very large geometries. To improve computational\neﬃciency and prevent memory errors, these rare cases are simpliﬁed using the\nDouglas-Peucker algorithm (Douglas and Peucker, 1973). In this way, only 0.17\npercent of the geometries in our experiments needed to be simpliﬁed.\n3.3\nDeep model selection\nThe motivation for using deep learning on geospatial vector data goes beyond\nmatching or improving existing methods. Deep learning allows us to explore new\nmethods for working with geospatial data, in complex pipelines involving com-\nbinations of raster, numerical and textual data (Ngiam et al, 2011), including\ngeospatial vector data. Deep learning can be used for classiﬁcation or regression\ntasks, but also for training generative models, producing new text (Sutskever\net al, 2014), image (Goodfellow et al, 2014) and even vector shape (Ha and Eck,\n2018) outputs. Knowing how well deep learning models can learn directly from\ngeometries is a ﬁrst step in building more complex generative pipelines with\nconﬁdence that the model is able to correctly interpret the data.\nWe introduce two deep learning, end-to-end trained models where vector-\nserialized geometries are given as input data. The deep learning model ﬁgures\nout the relevant data properties for itself without the need for the feature ex-\ntraction required for the shallow models. In the next subsections we describe\ntwo relatively simple deep learning architectures that we evaluate on our tasks:\na convolutional model and a recurrent model. We explain these deep learning\nmodels in some detail.\n3.3.1\nConvolutional neural net\nThe ﬁrst introduced deep learning model uses a 1D convolutional neural net\n(CNN) layout, shown in Figure 3. For an introduction to the workings of the\nCNN, we refer the reader to Olah (2014). As a ﬁrst layer, our model uses a\nReLU-activated convolution layer with a ﬁlter size of 32, a kernel size of ﬁve\nand a stride of one. With this conﬁguration, the CNN starts a sliding window\nacross the ﬁrst ﬁve geometry vectors, i.e. gi\n1 through gi\n5, producing a vector of\nsize 32 as speciﬁed by the ﬁlter hyperparameter6. This window of size ﬁve is\nslid along the vectors of the geometry, until the end of the geometry including\n6Hyperparameters are the conﬁguration settings of the machine learning model that are\nnot optimized by the algorithm itself, such as the batch size.\n10\nInput layer\nFully connected (#classes, SoftMax)\nshape: (m, 5)\nConv1D (filters: 32, kernel: 5, ReLU)\nMaxPooling1D (pool size: 3, stride: 3)\nConv1D (filters: 64, kernel: 5, ReLU)\nGlobalAveragePooling1D\nFully connected (32, ReLU)\nshape: (m, 32)\nshape: (m/3, 32)\nshape: (m/3, 64)\nshape: (64)\nshape: (32)\nshape: (#classes)\nBi-directional\nLSTM (32)\nForwards\nLSTM (32)\nBackwards\nInput layer\nFully connected (#classes, SoftMax)\nshape: (m, 5)\nshape: (m, 64)\nshape: (#classes)\nFigure 3: Convolutional (left) and recurrent (right) model layouts.\n11\nvector: 5\nvector: 32\ngeometry 2\ngeometry 1\ngeometry 3\n...\nsequence length: 9 + padding\nMax pooling \npool size: 3\nstride: 3\nCNN 1D\nfilters: 32 \nkernel: 5\nvector: 32\nFigure 4: The ﬁrst two layers of the CNN model. With a kernel size of ﬁve, the\nCNN inspects a sliding window over the ﬁrst ﬁve geometry vectors in geometry\nG1, producing the green element in the CNN output vector. The CNN then\nmoves to the ﬁve elements to the right, and produces the red vector element,\nnext the orange vector, repeated until the end of the geometry (the next three\nwindows in grey). This process is repeated for each ﬁlter and then moves to the\nnext geometry, in the direction of the black arrow. The max pooling operation\ncombines the maximum output element values of the CNN, shown in purple for\ngeometry 1.\n12\nvector: 5\nvector: 32\nsequence length: 6\nLSTM cell\nLSTM cell\ng1\ng2\ng3\ng4\ng5\ng6\nLSTM cell\nLSTM cell\nLSTM cell\nLSTM cell\nstate\nstate\nstate\nstate\nstate\noutput\ngeometry 2\ngeometry 1\ngeometry 3\noutput\noutput\noutput\noutput\noutput\nFigure 5: Forward-facing LSTM, as part of the ﬁrst layer of the LSTM model.\nUnlike the CNN architecture, complete vectors are fed one by one to the same\nLSTM cell. The green boxes therefore represent the same cell, with only its\nstate updated: along with each next geometry vector, the output and previous\nstate of the LSTM cell are passed along from one vector to the next. For the\npurposes of classiﬁcation as in this article, only the last LSTM output is returned\n(in orange), the intermediate outputs (in grey) are discarded.\npadding. Padding ensures outputs by the CNN of the same sequence length\nas the input, to prevent size errors on small geometries where the tensor size\nbecomes too small to pass through the speciﬁed network layers. After gi\n1 through\ngi\n5 the CNN continues at the second set of geometry entries gi\n2 through gi\n6. After\ninspecting all values of all the vectors in the ﬁrst geometry, the CNN continues\nat the next geometry (see Figure 4).\nThe ﬁrst CNN layer is followed by a max pooling layer with a pooling size\nof three and a stride of three. The max pooling operation with a pool size of\nthree combines the maximum values of three CNN output vectors into a single\nsequence vector of the same length. The reduction of the CNN output to one-\nthird is speciﬁed by the max pooling stride hyperparameter: after combining\nCNN output vectors ci\n1, ci\n2 and ci\n3, the max pooling operation skips forward\nto combine outputs ci\n4, ci\n5 and ci\n6, and so on. After the max pooling layer, a\nsecond convolution layer (not shown in Figure 4) interprets the output of the\n13\nmax pooling layer, with hyperparameters identical to the ﬁrst but with 64 ﬁlters\ninstead of 32. This CNN layer is followed by a global average pooling layer that\nreduces the tensor rank to two by computing the average over the third tensor\naxis. The output is subsequently fed to a ReLU activated fully connected layer.\nThe last layer is a softmax-activated fully connected layer to produce probability\noutputs that sum to one.\n3.3.2\nRecurrent neural net\nThe second deep learning model uses a recurrent neural net (RNN) layout as\nshown in Figure 3.\nAn RNN processes input data sequentially, re-using the\noutputs of the network in each slice of the input sequence as additional input\nfor the next slice (Goodfellow et al, 2016, 364) by which the network can carry\nover information between slices and capture long-term dependencies in the in-\nput sequence. While there are several RNN architectures, we opted to evaluate\nan Long-Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) ar-\nchitecture, as this is one popular architecture, shown by Ha and Eck (2018) to\nbe eﬀective for vector geometry analysis.\nThe core of our model is a single bi-directional LSTM layer. The LSTM\narchitecture is a particular type of RNN, designed to process sequences of data\nwith a trainable forget gate. This forget gate regulates the information retained\nfrom one geometry vertex to the next. During training, the LSTM learns which\ninformation in the sequence is of interest to retain, by passing both the vector\nin the sequence, the output and the cell state from one input vector to the next\n(see Figure 5). For a detailed discussion of recurrent neural nets and LSTMs in\nthe geospatial domain, we refer the reader to Mou et al (2017). An introduction\nto LSTMs is given by Olah (2015). LSTMs have been shown to be eﬀective on\nsequences such as words in a sentence (Sutskever et al, 2014), but also sequen-\ntial geometry-like data such as handwriting recognition and synthesis (Graves,\n2013). The ability of the LSTM to learn long-term dependencies (Goodfellow\net al, 2016, 400) in sequences of input data renders it a suitable architecture to\ntest its abilities on geospatial vector geometries.\nThe bi-directional architecture feeds the sequence of geometry vertices for-\nwards as well as backwards through LSTM cells (Schuster and Paliwal, 1997),\nwhere the resulting output from these cells is concatenated. This allows the\nnetwork to learn from the preceding vertices in the geometry as well as the ones\nthat are ahead. In our model, we conﬁgured both the forwards and backwards\nLSTM to produce an output of size 32, combined to 64. As with the CNN\nmodel, the last layer is a softmax-activated fully connected layer to produce\nprobability outputs that sum to one.\n3.4\nEvaluation methodology\nTo compare our selected shallow and deep learning models, we designed a set\nof experiments applicable to both shallow and deep models, informative to our\nresearch question and straightforward to interpret. We focus on a set of clas-\n14\nsiﬁcation tasks as explained in Section 4, for which our models are required to\ncorrectly assign individual polygons to a certain type, based on only the polygon\nshape.\nFor the classiﬁcation tasks, we select data sets on the following requirements:\n• Each task contributes to evaluate the accuracy performance of deep learn-\ning models versus shallow models. The data sets for the tasks contain\nreal-world polygon data from diﬀerent domains, with diﬀerent use cases\nand on diﬀerent spatial scales;\n• Each data set contains enough data to draw conclusions on model general-\nization; we set a requirement for data sets of at least 12,000 geometries in\norder to provide a training set of at least 10,000 geometries, a validation\nset of at least 1,000 geometries and a test set of at least 1,000 geometries;\n• Each task requires the models to infer information from the polygon shape,\nand from the polygon shape alone. To this end, data is selected to be likely\nto contain shape information relevant to the classiﬁcation task but not a\ntrivial solution;\n• We require our data to be available under an open license, to be accessible\nfor future research.\nThrough the use of classiﬁcation tasks, both the shallow and deep model perfor-\nmance can be directly compared. Classiﬁcation tasks can be expressed through\nthe simple metric of accuracy score: the ratio of correctly assigned test samples\nover the total set of test samples. We also add a baseline majority class accu-\nracy score: the fraction of the prevalent class, included as a baseline of the most\nsimple method to exceed. The models are trained on a training data set, the\nmodel performance was iteratively tuned to best perform on an evaluation set\nand ﬁnally tested once on a test set that was unseen during any of the tuning\nruns. The resulting test set accuracy scores are listed in Table 3. We include\na discussion of the misclassiﬁcation behaviour of the models by analysing the\nconfusion matrices (Stehman, 1997).\nFor optimal reproducibility, we use only open data7 and open source meth-\nods to answer our research question. We release all preprocessing code, deep\nlearning models and shallow models as open source software.8 Scikit-learn (Pe-\ndregosa et al, 2011) provides the shallow learning algorithms. To evaluate shal-\nlow model accuracy on each task, we use a brute force grid search with 5-fold\ncross validation to ﬁnd the best applicable hyperparameters for k (k-nearest\nneighbours), degree (decision tree), C (SVM, logistic regression) and gamma\n(SVM). SVM grid searches are restricted to a maximum number of 10M itera-\ntions to allow the grid search operation to complete within a day. Grid searches\non SVM models and k-nearest neighbours are restricted to a subset of the train-\ning data to allow the grid search to ﬁnish within a day on commodity hardware.\n7Data available at http://hdl.handle.net/10411/GYPPBR\n8Code available at https://github.com/SPINlab/geometry-learning\n15\nAll shallow models are trained, however, using the full training set on the the\nbest hyperparameters obtained from the grid search. The deep learning models\nare implemented using Keras (Chollet et al, 2015) version 2 with a TensorFlow\n(Abadi et al, 2016) version 1.7 backend. All deep model hyperparameters are\ntuned on the full training and validation set, using validation data split ran-\ndomly from the training data.\nFor the grid searches, we do not assume that including an arbitrarily high\nnumber of descriptors produces the best accuracy score. Instead, the number of\nextracted Fourier descriptors used during training is included as a hyperparam-\neter in the grid search for each shallow model, to produce the descriptor order\nat which the grid search obtains the best results. The best parameters found in\nthe grid searches are listed in Table 4 of Appendix A.\n4\nTasks\nWe created a set of three classiﬁcation tasks to evaluate the performance of\nseveral machine learning algorithms in shape recognition on real-world poly-\ngon data. From the requirements listed in Section 3.4 the following tasks and\naccompanying data sets were selected:\n1. Predicting whether the number of inhabitants in a neighbourhood is above\nor below the national median, based on the neighbourhood geometry;\n2. Predicting a building class from the building contour polygon. The avail-\nable classes are buildings for the purpose of gathering; industrial activity;\nlodging; habitation; shopping; oﬃce buildings; health care; education; and\nsports.\n3. Predicting an archaeological feature type from its geometry.\nFeatures\nare available as an instance of either a layer; wall; ditch; pit; natural\nphenomenon; post hole; well; post hole with visible post; wooden object;\nor recent disturbance.\nThe classes and their frequencies are displayed in Table 2.\n4.1\nNeighbourhood inhabitants\nThe ﬁrst task is to predict the number of inhabitants for a certain neighbour-\nhood to be above or below the Dutch national median of 735 inhabitants. A\nneighbourhood is a geographical region of varying size and shape, as deﬁned\nby Statistics Netherlands.9\nThe data was harvested from the 2017 districts\nand neighbourhoods Web Feature Service.10\nFor the sake of evaluation sim-\nplicity, the task has been shaped into a binary class prediction: to predict a\nneighbourhood for having equal or more (6,610 neighbourhoods) or less (6,598\n9https://www.cbs.nl/-/media/_pdf/2017/36/2017ep37%20toelichting%20wijk%20en%\n20buurtkaart%202017.pdf (only available in Dutch).\n10https://geodata.nationaalgeoregister.nl/wijkenbuurten2017/wfs\n16\n52.34\n52.34\n52.33\n52.33\n4.85\n4.85\n4.86\n4.86\n4.87\n4.87\n4.88\n4.88\n4.89\n4.89\nNeighborhood inhabitants\nBelow median\nEqual or above median\nFigure 6: Map visualisation of neighbourhoods at scale 1:25,000 in Amsterdam\nnear the VU University complex. In bold the absolute number of inhabitants\nper neighbourhood. Zero-count neighbourhoods are areas such as parks or oﬃce\nzones. Map coordinates in WGS84 degrees.\n17\n52.336\n52.336\n52.332\n52.332\n4.860\n4.860\n4.864\n4.864\n4.868\n4.868\n4.872\n4.872\nBuilding type\nGathering\nHealth care\nIndustry\nOﬃce\nLodging\nEducation\nSports\nShopping\nHabitation\nOther\nFigure 7: Map visualisation of buildings at scale 1:10,000 near the VU University\ncomplex. Map coordinates in WGS84 degrees.\n52.7168\n52.7168\n52.7167\n52.7167\n5.2656\n5.2656\n5.2657\n5.2657\nArchaeology types\nDitch\nWooden object\nPit\nLayer\nWall\nNatural\nPost hole with post\nPost hole\nRecent\nWell\nFigure 8: Map visualisation of archaeological ground features at scale 1:500,\nfrom (Roessingh and Lohof, 2010). Map coordinates in WGS84 degrees.\n18\nNeighbourhood\ninhabitants\nClass\nfrequency\n≥median\n6,610\n< median\n6,598\nTotal\n13,208\nBuildings\nFunction\nfrequency\nHabitation\n23,000\nIndustrial\n23,000\nLodging\n23,000\nShopping\n23,000\nGatherings\n22,007\nOﬃce\n21,014\nEducation\n10,717\nHealthcare\n7,832\nSports\n6,916\nTotal\n160,486\nArchaeological\nfeatures\nClass\nfrequency\nPost hole\n24,991\nPit\n7,713\nNatural\nphenomenon\n6,136\nRecent\ndisturbance\n5,625\nDitch\n4,926\nWooden\nobject\n2,499\nLayer\n1,321\nWall\n1,387\nPost hole with\nvisible post\n1,005\nWater well\n980\nTotal\n56,583\nTable 2: Class frequency for the three tasks of neighbourhood inhabitants (left),\nbuilding types (middle) and archaeological feature types (right).\nneighbourhoods) than the median of the absolute number of inhabitants of the\nentire set of neighbourhoods for the Netherlands for the year 2017. The me-\ndian was chosen to create an even split11 of the two classes. For purposes of\nevaluation simplicity it is appropriate to estimate the median on the absolute\nnumber of inhabitants rather than population density. Calculating population\ndensity would add complexity to the task by requiring the models to divide the\nestimated number of inhabitants over an estimate of the neighbourhood sur-\nface area. Designed as a binary classiﬁcation task, its purpose is primarily to\nevaluate model performance. However, the task could be re-designed to solve\nreal-world problems: for example in estimating population sizes or densities for\ndisaster areas based on topographical region shapes (Brown et al, 2001).\n4.2\nBuilding types\nThe second task is to classify a building from the building footprint geometry,\nharvested from the buildings and addresses base registration (BAG) Web Fea-\nture Service.12 The data set consists of buildings in nine functional classes, for\na total of 160,486 buildings in the combined training and test dataset. Since the\ncomplete source data set comprises over ﬁve million buildings, each class was\n11The slight diﬀerence between the class frequencies is explained by a higher occurrence of\nneighbourhoods with number of inhabitants equal to the median number.\n12https://geodata.nationaalgeoregister.nl/bag/wfs\n19\ntrimmed to a maximum of the ﬁrst 23,000 instances per class to prevent creating\na data set too large to experiment on. With this selection, the buildings set still\nhas the most data of the three tasks. The task of classifying a building based on\nits shape can have clear quality control beneﬁts: one could assess the likelihood\nof a speciﬁc building to belong to a speciﬁc type based on shape characteris-\ntics. Subsequently, a system could ﬂag buildings as suspect that fall below a\nlikelihood threshold for their current building class and suggest a replacement\nbuilding class based on a higher likelihood.\n4.3\nArchaeological features\nThe third task is to classify an archaeological feature from its observed geome-\ntry. Archaeological features are ﬁeld observations of disturbances in the subsoil\nas a result of human activities in the past. Archaeological institutions in the\nNetherlands store the results of archaeological ﬁeld research in a digital repos-\nitory (Gilissen, 2017; Hollander, 2014). From the DANS EASY repository,13\nfrom ten archaeological projects (Roessingh and Lohof, 2010; Gerrets and Ja-\ncobs, 2011; Van der Veken and Prangsma, 2011; Dijkstra and Zuidhoﬀ, 2011;\nDijkstra et al, 2010; van de Velde et al, 2002; van der Velde, 2011; Dijkstra,\n2012; Roessingh and Blom, 2012; Van der Veken and Blom, 2012), a total of\n56583 geometries was collected in ten classes.\nOf the three tasks, the class\ndistribution for this dataset is the most unbalanced: the data shows a clear\nover-representation of post holes (44,2 %). Although the archaeological data\ntask was designed for our experimental model evaluation purposes primarily,\nthe ability to infer feature types from archaeological feature shapes is useful\nin ﬁeld work, where a good performing model can assist in a documentation\nsystem, suggesting a likely feature class based on shape information.\n5\nEvaluation\nThe accuracy scores of the model performance on each of the three tasks allow\nus to compare the performance of the deep learning models against the shallow\nlearning models. Table 3 shows the results for each of the three benchmark\ntasks. The accuracy scores were produced from model predictions on the test\nset, consisting of geometries in the data set that were unseen by the models\nduring training. The deep learning model experiments were repeated ten-fold:\nrandomized network initialisation and batch sampling produce slight variations\nin accuracy scores between training sessions. The accuracy ﬁgures for the deep\nneural models therefore represent mean and standard deviation from the test\npredictions on the independently repeated training sessions.\nWe note the following conclusions from these accuracy scores:\n1. The deep neural nets are at least competitive with the best shallow models,\nfor each of the three tasks. In ﬁve out of the six deep learning experiments,\n13https://easy.dans.knaw.nl\n20\nMethod\nTask (no. of classes)\nNeighbourhood\ninhabitants (2)\nBuilding\ntypes\n(9)\nArchaeological\nfeature\ntypes\n(10)\nMajority class\n0.514\n0.142\n0.444\nk-NN\n0.671\n0.377\n0.596\nLogistic regression\n0.659\n0.328\n0.555\nSVM RBF\n0.683\n0.365\n0.601\nDecision tree\n0.682\n0.389\n0.615\nCNN\n0.664 ± 0.005\n0.408 ± 0.003\n0.624 ± 0.002\nRNN\n0.608 ± 0.016\n0.389 ± 0.008\n0.614 ± 0.004\nTable 3: Table of results with accuracy scores for the majority class (top row)\nshallow models (middle four rows) the deep learning models (bottom two rows),\nwith the best scores per task in bold. The number of classes per task is listed\nbetween brackets in the column headers. The standard deviations on the deep\nlearning models on the bottom two rows were obtained from test set predictions\non ten-fold repeated, independent training sessions.\nthe deep models perform on par with or slightly better than the best\nshallow models, but in the broad sense they do not outperform the shallow\nmodels by a wide margin.\n2. On two of the three classiﬁcation tasks, the CNN architecture is able\nto outperform the shallow models by a few percentage points.\nIf top\nperformance in a certain geometry classiﬁcation task is required, the CNN\nis likely to be a good choice.\nTo gain further insight into model performance, we include an analysis the\nconfusion matrices of the test runs. As there are 18 confusion matrices in total,\nthese are not included in the article.14 In general the misclassiﬁcation is reﬂected\nin similar patterns across all models, with higher errors for models that under-\nperform on a certain task. A few task-speciﬁc details are discussed in B, but in\ngeneral the misclassiﬁcation behaviour of the deep models does not diﬀer from\nthe shallow models.\nAs mentioned in Section 3.2.1, the number of elliptic Fourier descriptors\nused for training the shallow models was included as a hyperparameter in the\ngrid search. A closer inspection of these hyperparameters in Appendix A is of\ninterest:\n1. Nearly all shallow models beneﬁt from adding Fourier descriptors. A no-\ntable exception is the k-nearest neighbours algorithm, which scores the\n14The confusion matrices are available for download from https://dataverse.nl/api/\naccess/datafile/13051\n21\nhighest accuracy in two of the three tasks only when no Fourier descrip-\ntors are added to the training data. As it appears from the three tasks,\nthe k-NN algorithm is less able to extract meaningful information from\nthe Fourier descriptors.\n2. The shallow models have a clear preference for lower orders of Fourier de-\nscriptors. Even though many higher orders (up to order 24) were tested,\nno shallow model was able to perform better on descriptor orders higher\nthan four. Order four descriptors only provide a very rough approxima-\ntion of the original geometry, as is well visualised in Kuhl and Giardina’s\npaper Kuhl and Giardina (1982, 243) and Figure 1. Still, the descriptors\nevidently contain enough important shape information for most shallow\nmodels to improve the accuracy score.\n3. Support vector machines come with a misclassiﬁcation tolerance hyperpa-\nrameter C. In situations where SVMs with high C settings (low tolerance)\nlead to higher performance, such as the ones for the archaeology classiﬁca-\ntion task, the training sessions were exceedingly time-consuming to train\non our data. Where low C-values tended to converge in seconds, high val-\nues could literally take days or even weeks to converge. To prevent having\nto wait for extended periods of time—there is no indication in what time\nframe a training session on a set of hyperparameters will converge—we\nneeded to constrain the amount of training data and the maximum of it-\nerations, especially on hyperparameter grid searches. It is quite possible\nthat as a consequence of these constraints, the grid search fails to produce\nthe optimal hyperparameter settings, but this is an unfortunate side eﬀect\nof using SVMs on Fourier descriptors of geometries.\n6\nConclusion and future research\nIn this article, we compared the accuracy of deep learning models against base-\nlines of shallow learning methods on geospatial vector data classiﬁcation tasks.\nWe evaluated two deep learning models and four shallow learning models on\nthree new classiﬁcation tasks involving only geometries. To answer the ques-\ntion whether deep learning performs better than shallow learning, we directly\ncompared the accuracy scores of these models on these three tasks. From our\nexperiments we showed that our deep learning models are competitive with\nestablished shallow machine learning models, in two of the three tasks outper-\nforming them by a small margin.\nNone of the chosen recognition tasks appear to be trivial. Classifying objects\nfrom geometries alone is a tough assignment for any algorithm. The advantage\nof having a set of tough tasks is that these can serve as benchmarks: in future\nexperiments, diﬀerent learning algorithms or model layouts it may be possible to\nobtain higher accuracy scores. However, there is a possibility that the accuracy\nﬁgures presented in the evaluation represent the maximum that can be learned\nfrom geometries alone.\nFrom these experiments alone it cannot be deduced\n22\nwhether these ﬁgures can actually be improved on. If there is a hard ceiling\nat the best performing models, perhaps the benchmarks can be improved by\nincluding more data than just the geometries alone, for example information\ngathered from the direct spatial surroundings or other properties of the spatial\nobjects. The benchmark presented here can be considered a ﬁrst attempt.\nAn area that might see improvement is the performance of LSTMs. In an\nearlier development stage, the LSTMs were trained on ﬁxed length rather than\non the variable length sequences. During this stage, the LSTMs performed sig-\nniﬁcantly better (on validation data, no ﬁnal tests were performed) on ﬁxed\nlength sequences, outperforming the CNNs. However, training on ﬁxed length\nsequences was abandoned because it requires simplifying geometries to a ﬁxed\nmaximum of points per geometry.\nThis was not consistent with our aim of\ntraining on all available information. Creating ﬁxed length sequences also re-\nquired adding a large amount of zero-padding to increase sequence length on\nall geometries shorter than the ﬁxed size. After switching to variable length\nsequences, the performance of the CNN models increased and the LSTM per-\nformance dropped considerably. We hypothesize that there is room to improve\nthe LSTM model conﬁguration to CNN model performance or perhaps even\nbetter. To test this in future research, the ﬁxed length sequences were included\nin the benchmark data.\nThere are several open questions to further explore the use of deep learning\nmodels for geometries.\nIt would be helpful to verify the accuracy on other\ntypes of geometries, such as multi-lines, multi-points or even heterogeneous\ngeometry collections.\nAlso, the deep neural net’s comprehension of holes in\npolygons could be beneﬁcial. Another interesting road to explore is to combine\ngeometries with other information sources as input data, such as remote sensing\ndata or textual descriptions. Deep learning poses a viable route to explore more\ncomplex pipelines. Such pipelines could include geometries and other modalities\nas inputs, to produce multi-modal combinations of sequences (Sutskever et al,\n2014), images (He et al, 2017) or new geometries (Ha and Eck, 2018) as output.\nThis paper is a step in that direction, by showing that is possible to have deep\nneural nets learn from geometries directly.\nAppendices\nA\nHyperparameter grid search results for shal-\nlow models\nThe grid searches discussed in Section 3 resulted in a set of best hyperparameter\nsettings for the shallow models. These best settings are listed in Table 4 and\ninclude the ranges that were searched. The range for the elliptic fourier descrip-\ntor order o is always the same: each grid search was executed on the orders\n⟨0, 1, 2, 3, 4, 6, 8, 12, 16, 20, 24⟩. The search intervals for the other hyperparam-\n23\nMethod\nTask\nNeighbourhood\ninhabitants (2)\nBuilding\ntypes\n(9)\nArchaeological\nfeature\ntypes\n(10)\nDecision tree o=2\no=3\no=3\nd=6 in [4, 9]\nd=10 in [6, 12]\nd=9 in [5, 10]\nk-NN\no=1\no=0\no=0\nk=26 in [21, 30]\nk=29 in [21, 30]\nk=29 in [21, 30]\nSVM RBF\no=1\no=0\no=2\nC=1 in 1e[−2, 3]\nC=1000\nin\n1e[−2, 3]\nC=100\nin\n1e[−1, 3]\nγ=1 in 1e[−3, 3]\nγ=10 in 1e[−2, 3]\nγ=0.01\nin\n1e[−4, 4]\nLogistic\nregression\no=1\no=4\no=8\nC=0.01\nin\n1e[−3, 1]\nC=1 in 1e[−2, 3]\nC=1000\nin\n1e[−2, 3]\nTable 4: Hyperparameters for the shallow models. Interval values for decision\ntree and k-nearest neighbours ∈N, for the SVM in log scale, with the exponent\ninterval ∈N.\neters are listed in Table 4. The k-hyperparameter of the k-nearest neighbour\nmodels and the maximum depth d hyperparameter for the decision tree have\nintervals with values ∈N. For the other hyperparameters, the listed interval\nvalues are powers of ten, as indicated by the scientiﬁc notation.\nB\nConfusion matrix discussion\nThere are a few task-speciﬁc details to the confusion matrices mentioned in\nSection 5. Interesting to note is that all models over-estimate the number of\ninhabitants on the test set. Due to random selection, there is a slight over-\nrepresentation of neighbourhoods below the median in the test set (51,4 %)\nbut this does not account for the large over-estimation of the models. Over-\nestimations are about twice (1,92) as frequent as the number of under-estimated\nerrors. We can only speculate on why this is—it may be due to some shape\nimbalance in the random test set selection. All models struggle to distinguish\nbetween buildings with lodging function and habitation, which is understandable\nsince any house can be made suitable for temporary lodging. Interestingly, the\nRNN model appears less prone to identifying lodging as habitation, but only\nto lose this advantage to a higher misclassiﬁcation of habitation as lodging.\nSimilarly, on the archaeology task all models have particular trouble separating\nnatural phenomena from post holes, which can be attributed to being of similar\nsize and shape. Often many archaeological features are preliminary marked as\npost holes when later, after making cross-sections, to be identiﬁed as natural\n24\nphenomena.\nReferences\nAbadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, Corrado GS, Davis\nA, Dean J, Devin M, Ghemawat S, Goodfellow IJ, Harp A, Irving G, Isard\nM, Jia Y, J´ozefowicz R, Kaiser L, Kudlur M, Levenberg J, Man´e D, Monga\nR, Moore S, Murray DG, Olah C, Schuster M, Shlens J, Steiner B, Sutskever\nI, Talwar K, Tucker PA, Vanhoucke V, Vasudevan V, Vi´egas FB, Vinyals\nO, Warden P, Wattenberg M, Wicke M, Yu Y, Zheng X (2016) Tensorﬂow:\nLarge-scale machine learning on heterogeneous distributed systems. CoRR\nabs/1603.04467, URL http://arxiv.org/abs/1603.04467\nAndr´aˇsik R, B´ıl M (2016) Eﬃcient road geometry identiﬁcation from digital\nvector data. Journal of Geographical Systems 18(3):249–264, DOI 10.1007/\ns10109-016-0230-1, URL https://doi.org/10.1007/s10109-016-0230-1\nAraya YH, Remmel TK, Perera AH (2016) What governs the presence of\nresidual vegetation in boreal wildﬁres?\nJournal of Geographical Systems\n18(2):159–181, DOI 10.1007/s10109-016-0227-9, URL https://doi.org/10.\n1007/s10109-016-0227-9\nBahdanau D, Cho K, Bengio Y (2014) Neural machine translation by jointly\nlearning to align and translate. CoRR abs/1409.0473, URL http://arxiv.\norg/abs/1409.0473, 1409.0473\nBall\nJE,\nAnderson\nDT,\nChan\nCS\n(2017)\nComprehensive\nsurvey\nof\ndeep\nlearning\nin\nremote\nsensing:\ntheories,\ntools,\nand\nchal-\nlenges\nfor\nthe\ncommunity.\nJournal\nof\nApplied\nRemote\nSensing\n11(4):042609,\nURL\nhttps://www.spiedigitallibrary.org/journals/\nJournal-of-Applied-Remote-Sensing/volume-11/issue-4/042609/\nComprehensive-survey-of-deep-learning-in-remote-sensing--theories/\n10.1117/1.JRS.11.042609.full\nBoser BE, Guyon IM, Vapnik VN (1992) A training algorithm for optimal mar-\ngin classiﬁers. In: Proceedings of the ﬁfth annual workshop on Computational\nlearning theory, ACM, pp 144–152, URL http://citeseerx.ist.psu.edu/\nviewdoc/download?doi=10.1.1.21.3818&rep=rep1&type=pdf\nBreiman L, Friedman JH, Olshen RA, Stone CJ (1984) Classiﬁcation and re-\ngression trees. Wadsworth & Brooks/Cole Advanced Books & Software\nBrezina T, Graser A, Leth U (2017) Geometric methods for estimating represen-\ntative sidewalk widths applied to vienna’s streetscape surfaces database. Jour-\nnal of Geographical Systems 19(2):157–174, DOI 10.1007/s10109-017-0245-2,\nURL https://doi.org/10.1007/s10109-017-0245-2\n25\nBrown V, Jacquier G, Coulombier D, Balandine S, Belanger F, Legros D (2001)\nRapid assessment of population size by area sampling in disaster situations.\nDisasters\n25(2):164–171,\nURL\nhttp://www.parkdatabase.org/files/\ndocuments/2001_brown_et_al_rapid_assessment_of_population_size_\nby_area_sampling_in_disaster_situations.pdf\nCheng G, Han J (2016) A survey on object detection in optical remote sensing\nimages. ISPRS Journal of Photogrammetry and Remote Sensing 117:11–28,\nURL https://arxiv.org/pdf/1603.06201\nChollet F, et al (2015) Keras. https://github.com/fchollet/keras\nCover T, Hart P (1967) Nearest neighbor pattern classiﬁcation. IEEE transac-\ntions on information theory 13(1):21–27, URL https://www.cs.bgu.ac.il/\n~adsmb182/wiki.files/borak-lecture%20notes.pdf\nCox DR (1958) The regression analysis of binary sequences. Journal of the Royal\nStatistical Society Series B (Methodological) 20(2):215–242, URL http://\nwww.jstor.org/stable/2983890\nDemir I, Koperski K, Lindenbaum D, Pang G, Huang J, Basu S, Hughes F, Tuia\nD, Raskar R (2018) Deepglobe 2018: A challenge to parse the earth through\nsatellite images. ArXiv e-prints URL https://arxiv.org/abs/1805.06561\nDijkstra J (2012) Wijk bij Duurstede veilingterrein do opgraving. https://doi.\norg/10.17026/dans-x8d-qmae, DOI 10.17026/dans-x8d-qmae\nDijkstra J, ZuidhoﬀF (2011) Veere rijksweg N57 proefsleuven begeleid-\ning opgraving. https://doi.org/10.17026/dans-xyc-re2w, DOI 10.17026/\ndans-xyc-re2w\nDijkstra J, Houkes M, Ostkamp S (2010) Gouda Bolwerk opgraving en\nbegeleiding. https://doi.org/10.17026/dans-xzm-x29h, DOI 10.17026/\ndans-xzm-x29h\nDomingos P (2012) A few useful things to know about machine learning.\nCommunications of the ACM 55(10):78–87, URL https://dl.acm.org/\ncitation.cfm?id=2347755\nDouglas DH, Peucker TK (1973) Algorithms for the reduction of the number\nof points required to represent a digitized line or its caricature. Cartograph-\nica: The International Journal for Geographic Information and Geovisual-\nization 10(2):112–122, DOI 10.3138/FM57-6770-U75U-7727, URL https:\n//doi.org/10.3138/FM57-6770-U75U-7727\nEﬀati M, Thill JC, Shabani S (2015) Geospatial and machine learning tech-\nniques for wicked social science problems:\nanalysis of crash severity on\na regional highway corridor. Journal of Geographical Systems 17(2):107–\n135, DOI 10.1007/s10109-015-0210-x, URL https://doi.org/10.1007/\ns10109-015-0210-x\n26\nFan H, Zipf A, Fu Q, Neis P (2014) Quality assessment for building footprints\ndata on openstreetmap. International Journal of Geographical Information\nScience 28(4):700–719\nGerrets D, Jacobs E (2011) Venlo TPN deelgebied 1 en 2 opgraving. https:\n//doi.org/10.17026/dans-26f-55zu, DOI 10.17026/dans-26f-55zu\nGilissen V (2017) Archiving the past while keeping up with the times. Studies\nin Digital Heritage 1(2):194–205, DOI 10.14434/sdh.v1i2.23238, URL https:\n//doi.org/10.14434/sdh.v1i2.23238\nGoodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair\nS,\nCourville\nA,\nBengio\nY\n(2014)\nGenerative\nadversarial\nnets.\nIn:\nGhahramani Z, Welling M, Cortes C, Lawrence ND, Weinberger KQ\n(eds) Advances in Neural Information Processing Systems 27,\nCurran\nAssociates,\nInc.,\npp 2672–2680,\nURL http://papers.nips.cc/paper/\n5423-generative-adversarial-nets.pdf\nGoodfellow I, Bengio Y, Courville A (2016) Deep Learning. MIT Press, http:\n//www.deeplearningbook.org\nGraves A (2013) Generating sequences with recurrent neural networks. CoRR\nabs/1308.0850, URL http://arxiv.org/abs/1308.0850, 1308.0850\nHa D, Eck D (2018) A neural representation of sketch drawings. In: International\nConference on Learning Representations, URL https://openreview.net/\nforum?id=Hy6GHpkCW\nHagenauer J (2016) Weighted merge context for clustering and quantizing spa-\ntial data with self-organizing neural networks. Journal of Geographical Sys-\ntems 18(1):1–15, DOI 10.1007/s10109-015-0220-8, URL https://doi.org/\n10.1007/s10109-015-0220-8\nHe K, Gkioxari G, Doll´ar P, Girshick RB (2017) Mask R-CNN. CoRR\nabs/1703.06870, URL http://arxiv.org/abs/1703.06870, 1703.06870\nHochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Compu-\ntation 9(8):1735–1780, DOI 10.1162/neco.1997.9.8.1735, URL https://doi.\norg/10.1162/neco.1997.9.8.1735\nHollander H (2014) The e-depot for dutch archaeology. archiving and publica-\ntion of archaeological data. In: Conference on Cultural Heritage and New\nTechnologies (CHNT), Vienna, Stadt Arch¨aologie Wien\nHuisman O, De By R (2009) Principles of geographic information systems.\nITC Educational Textbook Series 1, URL https://kartoweb.itc.nl/\ngeometrics/Publications/PoGIS2009%20Chapter%204%20selection.pdf\n27\nJiang T, Xia G, Lu Q (2017) Sketch-based aerial image retrieval. In: 2017 IEEE\nInternational Conference on Image Processing (ICIP), pp 3690–3694, DOI 10.\n1109/ICIP.2017.8296971, URL http://captain.whu.edu.cn/papers/ICIP_\njiang.pdf\nKeyes L, Winstanley AC (1999) Fourier descriptors as a general classiﬁcation\ntool for topographic shapes. IPRCS, pp 193–203, URL http://eprints.\nmaynoothuniversity.ie/66/\nKuhl FP, Giardina CR (1982) Elliptic fourier features of a closed contour.\nComputer graphics and image processing 18(3):236–258, DOI 10.1016/\n0146-664X(82)90034-X, URL http://dx.doi.org/10.1016/0146-664X(82)\n90034-X\nLeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature 521(7553):436–\n444,\nDOI doi:10.1038/nature14539,\nURL http://dx.doi.org/10.1038/\nnature14539\nLoncaric S (1998) A survey of shape analysis techniques. Pattern Recog-\nnition\n31(8):983\n–\n1001,\nDOI\nhttps://doi.org/10.1016/S0031-2023(97)\n00122-2,\nURL\nhttp://www.sciencedirect.com/science/article/pii/\nS0031202397001222\nMontero JM, M´ınguez R, Fern´andez-Avil´es G (2018) Housing price predic-\ntion: parametric versus semi-parametric spatial hedonic models. Journal of\nGeographical Systems 20(1):27–55, DOI 10.1007/s10109-017-0257-y, URL\nhttps://doi.org/10.1007/s10109-017-0257-y\nMou L, Ghamisi P, Zhu XX (2017) Deep recurrent neural networks for hyper-\nspectral image classiﬁcation. IEEE Transactions on Geoscience and Remote\nSensing 55(7):3639–3655, DOI 10.1109/TGRS.2016.2636241, URL http://\ndx.doi.org/10.1109/TGRS.2016.2636241\nNgiam J, Khosla A, Kim M, Nam J, Lee H, Ng AY (2011) Multimodal deep\nlearning. In: Proceedings of the 28th international conference on machine\nlearning (ICML-11), pp 689–696, URL http://ai.stanford.edu/~ang/\npapers/icml11-MultimodalDeepLearning.pdf\nOlah C (2014) Conv nets:\nA modular perspective. URL https://colah.\ngithub.io/posts/2014-07-Conv-Nets-Modular/\nOlah C (2015) Understanding lstm networks. URL https://colah.github.io/\nposts/2015-08-Understanding-LSTMs/\nPedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel\nM, Prettenhofer P, Weiss R, Dubourg V, Vanderplas J, Passos A, Cournapeau\nD, Brucher M, Perrot M, Duchesnay E (2011) Scikit-learn: Machine learning\nin Python. Journal of Machine Learning Research 12:2825–2830, URL http:\n//www.jmlr.org/papers/v12/pedregosa11a.html\n28\nRoessingh W, Blom E (2012) Oosterhout Vrachelen de Contreie Vrachelen\n4 opgraving. https://doi.org/10.17026/dans-25d-fpe5, DOI 10.17026/\ndans-25d-fpe5\nRoessingh W, Lohof E (2010) Enkhuizen Kadijken 5a en 5b opgraving. https:\n//doi.org/10.17026/dans-27r-e5f8, DOI 10.17026/dans-27r-e5f8\nSchuster M, Paliwal KK (1997) Bidirectional recurrent neural networks.\nIEEE\nTransactions\non\nSignal\nProcessing\n45(11):2673–2681,\nDOI\n10.1109/78.650093, URL https://www.researchgate.net/profile/Mike_\nSchuster/publication/3316656_Bidirectional_recurrent_neural_\nnetworks/links/56861d4008ae19758395f85c.pdf\nStehman SV (1997) Selecting and interpreting measures of thematic classiﬁ-\ncation accuracy. Remote sensing of Environment 62(1):77–89, URL https:\n//www.researchgate.net/profile/Stephen_Stehman/publication/\n222169047_Selecting_and_interpreting_measures_of_thematic_\nclassification_accuracy/links/5b5a0fe5a6fdccf0b2f8fe87/\nSelecting-and-interpreting-measures-of-thematic-classification-accuracy.\npdf\nSutskever\nI,\nVinyals\nO,\nLe\nQV\n(2014)\nSequence\nto\nsequence\nlearn-\ning with neural networks. In:\nAdvances in neural information pro-\ncessing systems,\npp 3104–3112,\nURL http://papers.nips.cc/paper/\n5346-sequence-to-sequence-learning-with-neural-networks.pdf\nVan der Veken B, Blom E (2012) Veghel Scheiﬀelaar ii opgraving. https://\ndoi.org/10.17026/dans-z93-7zbe, DOI 10.17026/dans-z93-7zbe\nVan der Veken B, Prangsma N (2011) Montferland Didam westelijke randweg\nKerkwijk opgraving. https://doi.org/10.17026/dans-zmk-35vy, DOI 10.\n17026/dans-zmk-35vy\nvan der Velde H (2011) Katwijk Zanderij Westerbaan opgraving. https://doi.\norg/10.17026/dans-znz-r2ba, DOI 10.17026/dans-znz-r2ba\nvan de Velde H, Ostkamp S, Veldman H, Wyns S (2002) Venlo Maasboulevard.\nhttps://doi.org/10.17026/dans-x84-msac, DOI 10.17026/dans-x84-msac\nWang Y, Zhang L, Tong X, Liu S, Fang T (2017) A feature extraction and\nsimilarity metric-learning framework for urban model retrieval. International\nJournal of Geographical Information Science 31(9):1749–1769, DOI 10.1080/\n13658816.2017.1334888, URL https://doi.org/10.1080/13658816.2017.\n1334888, https://doi.org/10.1080/13658816.2017.1334888\nWu Q, Diao W, Dou F, Sun X, Zheng X, Fu K, Zhao F (2016) Shape-based ob-\nject extraction in high-resolution remote-sensing images using deep boltzmann\nmachine. International Journal of Remote Sensing 37(24):6012–6022, DOI 10.\n1080/01431161.2016.1253897, URL https://doi.org/10.1080/01431161.\n2016.1253897, https://doi.org/10.1080/01431161.2016.1253897\n29\nXu Y, Chen Z, Xie Z, Wu L (2017) Quality assessment of building footprint\ndata using a deep autoencoder network. International Journal of Geographical\nInformation Science 31(10):1929–1951, URL http://www.tandfonline.com/\ndoi/abs/10.1080/13658816.2017.1341632\nZahn CT, Roskies RZ (1972) Fourier descriptors for plane closed curves. IEEE\nTransactions on computers C-21(3):269–281, DOI 10.1109/TC.1972.5008949,\nURL http://dx.doi.org/10.1109/TC.1972.5008949\nZhang D, Lu G, et al (2002) A comparative study of fourier descriptors for shape\nrepresentation and retrieval. In: Proc. of 5th Asian Conference on Computer\nVision (ACCV), Citeseer, pp 646–651, URL http://citeseerx.ist.psu.\nedu/viewdoc/summary?doi=10.1.1.73.5993\nZhu XX, Tuia D, Mou L, Xia G, Zhang L, Xu F, Fraundorfer F (2017)\nDeep learning in remote sensing: A comprehensive review and list of re-\nsources. IEEE Geoscience and Remote Sensing Magazine 5(4):8–36, DOI\n10.1109/MGRS.2017.2762307,\nURL\nhttp://arxiv.org/abs/1710.03959,\n1710.03959\n30\n",
  "categories": [
    "stat.ML",
    "cs.LG",
    "I.2.10; I.5.1; G.3"
  ],
  "published": "2018-06-11",
  "updated": "2019-06-11"
}