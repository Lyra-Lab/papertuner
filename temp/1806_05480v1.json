{
  "id": "http://arxiv.org/abs/1806.05480v1",
  "title": "Automatic Language Identification for Romance Languages using Stop Words and Diacritics",
  "authors": [
    "Ciprian-Octavian Truică",
    "Julien Velcin",
    "Alexandru Boicea"
  ],
  "abstract": "Automatic language identification is a natural language processing problem\nthat tries to determine the natural language of a given content. In this paper\nwe present a statistical method for automatic language identification of\nwritten text using dictionaries containing stop words and diacritics. We\npropose different approaches that combine the two dictionaries to accurately\ndetermine the language of textual corpora. This method was chosen because stop\nwords and diacritics are very specific to a language, although some languages\nhave some similar words and special characters they are not all common. The\nlanguages taken into account were romance languages because they are very\nsimilar and usually it is hard to distinguish between them from a computational\npoint of view. We have tested our method using a Twitter corpus and a news\narticle corpus. Both corpora consists of UTF-8 encoded text, so the diacritics\ncould be taken into account, in the case that the text has no diacritics only\nthe stop words are used to determine the language of the text. The experimental\nresults show that the proposed method has an accuracy of over 90% for small\ntexts and over 99.8% for",
  "text": "Automatic Language Identiﬁcation for Romance\nLanguages using Stop Words and Diacritics\nTool/Experimental Paper\nCiprian-Octavian Truic˘a\nComputer Science and Engineering Department\nFaculty of Automatic Control and Computers\nUniversity Politehnica of Bucharest\nBucharest, Romania\nEmail: ciprian.truica@cs.pub.ro\nJulien Velcin\nUniversity of Lyon\nERIC Laboratory, Lyon 2\nLyon, France\nEmail: julien.velcin@univ-lyon2.fr\nAlexandru Boicea\nComputer Science and Engineering Department\nFaculty of Automatic Control and Computers\nUniversity Politehnica of Bucharest\nBucharest, Romania\nEmail: alexandru.boicea@cs.pub.ro\nAbstract—Automatic language identiﬁcation is a natural lan-\nguage processing problem that tries to determine the natural\nlanguage of a given content. In this paper we present a statistical\nmethod for automatic language identiﬁcation of written text\nusing dictionaries containing stop words and diacritics. We\npropose different approaches that combine the two dictionaries\nto accurately determine the language of textual corpora. This\nmethod was chosen because stop words and diacritics are very\nspeciﬁc to a language, although some languages have some similar\nwords and special characters they are not all common. The\nlanguages taken into account were romance languages because\nthey are very similar and usually it is hard to distinguish between\nthem from a computational point of view. We have tested our\nmethod using a Twitter corpus and a news article corpus. Both\ncorpora consists of UTF-8 encoded text, so the diacritics could\nbe taken into account, in the case that the text has no diacritics\nonly the stop words are used to determine the language of the\ntext. The experimental results show that the proposed method\nhas an accuracy of over 90% for small texts and over 99.8% for\nlarge texts.\nKeywords—automatic language identiﬁcation, stop words, dia-\ncritics, accuracy\nI.\nINTRODUCTION\nAutomatic language identiﬁcation (LID) is the problem of\ndetermining the natural language of a given content. As the\ntextual data volume generated each day in different languages\nincreases, LID is one of the basic steps needed for prepro-\ncessing text documents in order to do further textual analysis.\n[7].\nLID is one of the ﬁrst basic text processing techniques used\nin Cross-language Information Retrieval (CLIR) - also known\nas Multilingual Information Retrieval (MLIR), text mining and\nknowledge discovery in text (KDT) [6]. In these ﬁelds, the\ntext processing step such as indexing, tokenization, part of\nspeech tagging (POS), stemming and lemmatization are highly\ndependent on the language.\nIn this paper we propose a statistical method using two dic-\ntionaries for automatic language identiﬁcation. The dictionaries\ncontain stop words and diacritics (glyph added to a letter). The\nstop words dictionary is constructed using the most common\nwords written with diacritics for the studied languages. Further\nmore, we enhance this dictionary with terms written without\ndiacritics. The diacritics dictionary contains the diacritics for\neach language. The method either use the dictionaries as they\nare, or weigh the terms based on the existence of the term in\neach language. To the best of our knowledge, these method\nhas not been yet attempted in the literature.\nThe studied languages are romance languages, which are\nvery similar to each other from a lexical point of view [4]\n(Table I), this being the main reason why these languages were\nchosen for testing our statistical method.\nTABLE I.\nLEXICAL LANGUAGE SIMILARITIES BETWEEN THE STUDIED\nLANGUAGES (N/A NO DATA AVAILABLE)1\nLanguage\nFrench\nItalian\nPortuguese\nRomanian\nSpanish\nFrench\n1\n0.89\n0.75\n0.75\n0.75\nItalian\n0.89\n1\nN/A\n0.77\n0.82\nPortuguese\n0.75\nN/A\n1\n0.72\n0.89\nRomanian\n0.75\n0.77\n0.72\n1\n0.71\nSpanish\n0.75\n0.82\n0.89\n0.71\n1\nThis paper is structured as follows. Section II discusses\nrelated work done on automatic language detection. Section\nIII presents our experimental setup and the proposed method\nfor LID. Section IV presents experimental data and ﬁndings\nand discusses the results. The ﬁnal section concludes with a\ndiscussion and a summary.\nII.\nRELATED WORK\nThe major approaches for language identiﬁcation include:\ndetection based on stop words usage, detection based on char-\nacter n-grams frequency, detection based on machine learning\n(ML) and hybrid methods.\nStop words, from the point of view of LID, are deﬁned as\nthe most frequently terms as determined by a representative\nlanguage sample. This list of words has been shown to be\neffective for language identiﬁcation because these terms are\nvery speciﬁc to a language [7].\nThe method based on character n-grams was ﬁrst proposed\nby Ted Dunning [5]. To form n-grams, the text drawn from\na representative sample for each language is partitioned into\noverlapping sequences of n characters. The counts of frequency\nfrom the resulting n-grams form a characteristic ﬁngerprint\nof languages, which can be compared to a corresponding\nfrequency analysis on the text for which the language is to\nbe determined. In the literature there have been proposed ap-\nplications and frameworks that identify the language based on\n1Ethnologue: Languages of the World http://www.ethnologue.com/\narXiv:1806.05480v1  [cs.CL]  14 Jun 2018\nthis approach. They perform well on text collections extracted\nfrom Web Pages, but do not perform well for short texts [8].\nXafopoulos et al. used the discrete hidden Markov models\n(HMMs) with three models for comparison on a data set\ncontaining a collection of Web Pages collected over hotel Web\nSites in 5 languages. The texts in the tested corpus were not\nnoisy, because this genre of Web Sites presents the information\nas clean as possible [11]. Their accuracy is between 95% and\n99% for the sample corpus.\nTimothy Baldwin et al. performed a study based on\ndifferent classiﬁcation methods using the nearest neighbor\nmodel with three distances, Naive Bayes and support vector\nmachine (SVM) model [2]. Their results show that the nearest\nneighbor model using n-grams is the most suitable for the\ntested datasets, with accuracy ranging form 87% to 90%. Other\nmachine learning approaches use graph representation based\non n-gram features and graph similarities with an accuracy\nbetween 95% and 98% [10] or centroid-based classiﬁcation\nwith an accuracy between 97% and 99.7% [9].\nOn short messages, like tweets, Bergsma et al. used Pre-\ndiction by Pattern Matching and Logistic Regression with\ndifferent features to classify languages under the same family\nof languages (Arabic, Slavic and Indo-Iranian) [3]. Their\naccuracy is between 97% and 98% for the selected corpus.\nHybrid approaches use one or more of these methods.\nAbainia et al. propose different approaches that use term based\nand characters based methods [1]. Their experiments show that\nthe proposed hybrid methods are quite interesting and present\ngood language identiﬁcation performances in noisy texts, with\naccuracy ranging between 72% and 97%.\nIII.\nEXPERIMENTAL SETUP AND ALGORITHM\nThe corpora used for experiments are freely available, and\nthey can be downloaded from the Web2. For the experimental\ntests, a Twitter corpus and a news articles corpus are used.\nBefore applying the method for LID, the texts’ language was\ndetermined using the source of the data. This step is useful to\ndetermining the accuracy of our approach. Also, the texts are\npreprocessed to improve the language detection accuracy by\nremoving punctuation and non-alphabetical characters.\nBefore applying the algorithm, the stop words and diacritics\ndictionaries were created. The stop words dictionary was\ndownloaded from the Web3 and enhanced with stop words\nwith no diacritics manually. This is useful because there are\ntexts in the Twitter corpus written without diacritics and they\ncan be misclassiﬁed. A total number of approximately 500 stop\nwords is used for each language.\nTABLE II.\nDIACRITICS BY LANGUAGE\nLanguage\nDiacritics\nFrench\n`aˆaæc¸`e´eˆe¨eˆı¨ıˆoœ`uˆu¨u\nItalian\n`a´a`e´e`ı´ı`o´o`u´u\nPortuguese\n´aˆa˜a`ac¸´eˆe´ı´oˆo˜o´u\nRomanian\n˘aˆaˆıs,s¸t,t¸\nSpanish\n´a´e´ı´o´u˜n¨u\nTable II presents the diacritics used for LID. Although t¸\n(t-cedilla) and s¸ (s-cedilla) are not Romanian diacritics, due\n2News articles and tweets corpora http://www.corpora.heliohost.org/\n3Stop words list http://www.ranks.nl/stopwords\nto some wrong implementations of the correct diacritics s, (s-\ncomma) and t, (t-comma), these were taken into account when\nconstructing the diacritics dictionary.\nThe proposed method uses the term frequency of weighted\nstop words and diacritics. The term can be either a diacritic or a\nstop word. Using Equation (1) each text receives a score based\non the two dictionaries, the language that gets the highest score\nis selected as the language of the text. In case that there are no\ndiacritics in the text the score will only be computed using the\nstop words dictionary, p = 1. The ﬁnal score is calculated\nas the weighted sum of the frequency of stop words plus\nthe frequency of diacritics in the text for each language. The\nfrequency can be computed using the two different measures\npresented in the previous chapter. The motivation for using a\nweight is based on the fact that the terms speciﬁc to a language\nshould have a higher impact on the score than the ones that\nare common between languages, which is similar to the inverse\ndocument frequency (IDF) factor.\nscore(text, lang) =\np · P\nw f(w, text) · weight(w, lang) +\n(1)\n(1 −p) · P\nd f(d, text) · weight(d, lang)\nf(term, text) =\n(\nfterm,text\nlog(1 + fterm,text)\n(2)\nweight(term, lang) =\n\n\n\n\n\n1\nN\nn\nlog(1 + N\nn )\n(3)\nIn Equation (1), the following notations are used: lang rep-\nresents the tested language, w represents a stop word in the stop\nwords dictionary for the given language, d represents a diacritic\nin the dictionary of diacritics for the given language. Parameter\np ∈[0, 1] is used to increase the impact of terms and to cor-\nrelate stop words with diacritics. The function f(term, text)\nis used to compute the term frequency (Equation 2). It can be\ncalculate as the raw term frequency for a term, the number of\noccurrences of a term in the text, f(term, text) = fterm,text,\nor it can be normalized using the logarithmic normalization\nf(term, text) = log(1 + fterm,text). As the term frequency\nfunction, the term weighting function, weight(term, lang),\ncan be computed using different approaches (Equation 3). If\nthe terms are not weighted, then weight(term, lang) = 1.\nAnother way for computing the weight is to take into account\nthe frequency of a term in the studied languages. In this case,\nthe fallowing formula for the weight function can be used\nweight(term, lang) = N\nn . In this formula N is the number of\nlanguages tested and n = |{term : term ∈lang}| represents\nthe number of languages that contains the term. The term n can\nnever be equal to 0 because it appears at least in one language.\nAs the term frequency function, the weight function can be\nlogarithmic normalized weight(term, lang) = log(1 + N\nn ).\nAlthough the last formula is similar to IDF from information\nretrieval (IR), it is not the same as it does not calculate\nthe occurrence of a term in the corpus, but computes the\noccurrence of a dictionary term in the studied languages.\nIV.\nEXPERIMENTAL RESULTS\nThe method is applied on two corpora. The ﬁrst is a Twitter\ncorpus containing 500 000 tweets with 100 000 tweets for each\nstudied language. The second one is a news articles corpus\nthat contains 250 000 entries with 50 000 articles for each\nstudied language. All the text are encoded using UTF-8. The\naccuracy of each approach is determined by using the initial\nclassiﬁcation of the texts. Although a small sample of the\ninitial copora was manually validated, it should be noted that\nthe initial classiﬁcation was done automatically, based on the\ninitial corpora sources, therefore the texts may contain noise\nor could be wrongly classiﬁed.\nFirst we wanted to test the accuracy of our method whether\nwe use only diacritics or only stop words. Test 1 uses only dia-\ncritics, setting p = 0 and no weight, weight(term, lang) = 1.\nThe second test (Test 2) uses weighted diacritics, setting p = 0\nand weight(term, lang) =\nN\nn . For our third test (Test 3),\nwe tested only stop words with no weight, setting p = 1.\nTest 4 deals with weighted stop words using p = 1 and\nweight(term, lang) = N\nn . The next two sets of tests use both\ndiacritics and stop words with weight(term, lang) = 1. For\nTest 5 we set p =\n1\n2. Because diacritics are more language\nspeciﬁc and they will better determine the language than\nstop words, we also wanted to test whether the accuracy\nimproves if we set parameter p to favor the second term of\nEquation (1). We choose to double the impact of diacritics\nfor Test 6 by setting p =\n1\n3. The next two sets of tests\nuse weighted terms with weight(term, lang) = N\nn . For Test\n7 we set p =\n1\n2. In Test 8 we enhanced the impact that\ndiacritics have on determining the language to see if the\naccuracy improves further by setting p =\n1\n3. For the last\ntest (Test 9) we used the logarithmic normalization for the\nterm frequency, f(term, text) = log(1 + fterm,text), and the\nweight, weight(term, lang) = log(1 + N\nn ), together with\np = 1\n3.\nTable III presents the experimental result of the method\napplied on the Twitter corpus and Table IV presents the results\nof the method applied to the news article corpus.\nTABLE III.\nTWITTER CORPUS ACCURACY COMPARISON\nTest No.\nFrench\nItalian\nPortuguese\nRomanian\nSpanish\nTest 1\n6.31%\n8.67%\n34.53%\n22.39%\n12.49%\nTest 2\n6.31%\n8.69%\n34.54%\n22.40%\n12.57%\nTest 3\n92.80%\n90.78%\n88.79%\n83.00%\n89.49%\nTest 4\n93.14%\n90.98%\n88.95%\n88.59%\n90.46%\nTest 5\n93.62%\n91.33%\n90.62%\n85.40%\n90.68%\nTest 6\n93.64%\n91.29%\n90.70%\n85.60%\n90.73%\nTest 7\n93.88%\n91.57%\n90.70%\n90.15%\n91.59%\nTest 8\n93.90%\n91.56%\n90.78%\n90.18%\n91.63%\nTest 9\n94.09%\n91.68%\n91.02%\n90.07%\n92.18%\nFig. 1.\nAccuracy comparison for the Twitter Corpus\nWhen using weighted stop words and diacritics with our\nmethod the accuracy is over 90% for the twitter corpus for all\nthe tested languages. From our test results, we can conclude\nthat the highest accuracy is achieved when p = 1\n3 for weighted\nterm, showing the real impact of diacritics for LID. In Figure\n1 we compare the accuracy of each test for each language.\nFrom the experimental results, one can conclude that by\nsetting p =\n1\n2 and p =\n1\n3, work very well on the news\narticle corpus with an almost 100% accuracy for all the tested\nlanguages, the lowest accuracy being over 99.8%. Text size has\na signiﬁcant impact on the method because more information\nis available for classiﬁcation. Adding weights to stop words\nand diacritics proves to be a very efﬁcient approach for the\nRomanian and Italian languages. Taking into account only stop\nwords (Test 3 and Test 4) yields an accuracy of over 99% for\nautomatically determining the languages of news articles. The\nmethod’s accuracy is high (Figure 2) because the information\nin this corpus does not present a lot of noise.\nTABLE IV.\nNEWS ARTICLES CORPUS ACCURACY COMPARISON\nTest No.\nFrench\nItalian\nPortuguese\nRomanian\nSpanish\nTest 1\n51.49%\n31.34%\n95.56%\n96.90%\n45.54%\nTest 2\n51.51%\n31.42%\n95.57%\n96.89%\n46.02%\nTest 3\n99.89%\n99.77%\n99.86%\n99.03%\n99.95%\nTest 4\n99.89%\n99.82%\n99.86%\n99.78%\n99.95%\nTest 5\n99.92%\n99.80%\n99.97%\n99.91%\n99.96%\nTest 6\n99.93%\n99.80%\n99.98%\n99.93%\n99.96%\nTest 7\n99.92%\n99.84%\n99.97%\n99.97%\n99.95%\nTest 8\n99.93%\n99.84%\n99.97%\n99.97%\n99.96%\nTest 9\n99.93%\n99.84%\n99.98%\n99.97%\n99.97%\nFig. 2.\nAccuracy comparison for the News Articles Corpus\nTable IV show the wrongly classiﬁed tweets by Test 9,\nwhere we set p = 1\n3, f(term, text) = log(1 + fterm,text) and\nweight(term, lang) = log(1 + N\nn ). This miss-classiﬁcation\ncan be attributed to a high percentage of tweets, between 5%\nand 8%, that could not be classiﬁed. This set of tests has the\noverall lowest percentage of tweets that could not be classiﬁed.\nTABLE V.\nTWEETS WRONGLY CLASSIFIED BY TEST 9\nLanguage\nFrench\nItalian\nPortuguese\nRomanian\nSpanish\nFrench\n94.09%\n0.32%\n0.26%\n0.69%\n0.30%\nItalian\n0.22%\n91.68%\n0.75%\n1.12%\n0.63%\nPortuguese\n0.20%\n0.19%\n91.02%\n0.25%\n1.03%\nRomanian\n0.03%\n0.06%\n0.09%\n90.07%\n0.07%\nSpanish\n0.13%\n0.14%\n0.37%\n0.17%\n92.18%\nNot Classiﬁed\n5.33%\n7.61%\n7.51%\n7.70%\n5.79%\nAs expected, the accuracy is lower when taking into ac-\ncount only stop words or diacritics than when both dictionaries\nare used for LID. The accuracy discrepancy between the\ndifferent sets of tests can be seen especially for the Twitter\ncorpus where, for some languages, the difference between\naccuracies are considerably high (Figure 1). Instead, for the\nnews articles corpus this approach achieves an accuracy of over\n96% for Romanian and Portuguese. This could be attributed\nto the fact that Romanian and Portuguese have more diacritics\nthat are widely used and are not found in the other studied\nlanguages.\nMiss-classiﬁcation appears because diacritics and stop\nwords are common between languages. For example the Span-\nish tweet all´ı estar´e cannot be classiﬁed because our method\nwill only compute the score based on the diacritics ´ı and ´e,\nwhich appear in Italian, Spanish and Portuguese. The French\ntweet il y a plong´e son visage is wrongly classiﬁed as Spanish.\nThis miss-classiﬁcation arises because the term y appears as a\nSpanish stop word but not as a French one. The Italian tweet\nbuona sera wagli`u is miss-classiﬁed as French. In this case\nthe term sera is considered as a French stop word but not an\nItalian one. The Romanian tweet universitate facultate istorie\ncannot be classiﬁed because it does not contain stop words or\ndiacritics. The same miss-classiﬁcation appears for the Italian\ntweet messaggio ricevuto. The dictionaries must be carefully\nbuilt so that miss-classiﬁcations do not appear.\nV.\nCONCLUSION\nStop words prove to be very effective for automatic\nlanguage identiﬁcation. Although with different semantical\nmeanings, stop words can be very similar, even the same, for\nlanguages that are related. For example the word la appears\nas a word in French, Italian, Spanish and Romanian, but does\nnot appear in Portuguese. Other terms are very speciﬁc to a\nlanguage and the scoring can be skipped altogether if they are\nfound, e.g., the stop word s,i (s-comma and i) is only found in\nRomanian, votre is only found in French, etc.\nDiacritics also prove very useful for LID. Some diacritics\nappear for certain language, e.g., t, (t-comma) for Romanian, `ı\n(i with grave accent) for Italian, ˜a (a-tilde) for Portuguese, etc.\nIf the analyzed text is written correctly, then, only by looking\nat the set of diacritics and the stop words, a LID method can\naccurately classify the given text and no scoring is necessary,\nespecially in the cases where the diacritics are unique to the\nlanguage and are widely used.\nThe experimental results show that for the news articles\ncorpus a very high accuracy is achieved when using the method\nwith both dictionaries to classify the corpus, almost all the\ntexts are correctly classiﬁed with an accuracy of over 99.8%.\nThis result can be attributed to the fact that the texts from the\nnews articles are written using diacritics. The size of the text\nhas a considerable impact on the accuracy as it present more\ninformation to the method.\nFor the Twitter corpus the method using weighted terns\nwith p = 1\n3 achieves the overall best accuracy. Although, the\naccuracy difference between Test 7 and 8 is very small, almost\ninsigniﬁcant, under 0.1%. The best accuracy is achieved when\nthe logarithmic normalization is used for the term frequency\nand the weight (Text 9). To improve the accuracy for short\ntexts and lower miss-classiﬁcation, our method can be used\ntogether with the already existing major approaches for LID.\nIt should be taken into account that these languages come\nfrom the same linguistic family and they are very similar from\na lexical point of view, and some of the diacritics and stop\nwords are common. The accuracy of the Twitter corpus is lower\nthan the accuracy of the news articles corpus because not all\nthe texts are written using diacritics. Some noise could also be\nfound in this corpus, some tweets could only contain links or\nhashtags, which were not taken into account when doing LID.\nThe presented method is very ﬂexible and it can be imple-\nmented in any programming language and at any application\nlayer. It does not need any training as it is needed for LID\nalgorithms that use ML, being highly dependent on the natural\nlanguage instead of a training corpus. There is a minimal\nnumber of computations done, the temporal complexity being\nO(|w| + |d|), where |w| is equal to the number of stop words\nand |d| is the equal to the number of diacritics used. Because\nthis method is based on dictionaries, the score function can\nupgrade or degrade to a different one, giving ﬂexibility when\none of the dictionaries is missing.\nIn conclusion, although stop words usually are a good\nmeasure for automatic language detection, for small and large\ntexts the accuracy of LID can be improved by using diacritics.\nBased on the experimental result, we can observe that if we\nwant to improve accuracy and remove miss-classiﬁcation the\nstop words dictionary must be well-built, conveniently by\nexperts in the ﬁeld.\nIn future work, we seek to ﬁne tune the parameter p\nby automatically learning it to see if we can achieve better\naccuracy. We also want to test this statistical approach on\nother Romance languages (e.g. Occitan, Catalan, Venetian,\nAromanian, Galician etc.) and other Indo-European families of\nlanguages such as Germanic and Slavic. From an architectural\npoint of view, we also want to parallelize the algorithm as\nmuch as possible to reach real-time performance.\nREFERENCES\n[1]\nK. Abainia, S. Ouamour, H. Sayoud. Robust Language Identiﬁcation\nof Noisy Texts Proposal of Hybrid Approaches The 25th International\nWorkshop on Database and Expert Systems Applications (DEXA), 228–\n232, 2014.\n[2]\nT. Baldwin, M. Lui. Language Identiﬁcation: The Long and the Short of\nthe Matter. Human Language Technologies: The 2010 Annual Confer-\nence of the North American Chapter of the ACL, 229–237, 2010.\n[3]\nS. Bergsma, P. McNamee, M. Bagdouri, C. Fink, T. Wilson. Lan-\nguage Identiﬁcation for Creating Language-Speciﬁc Twitter Collections.\nProceedings of the 2012 Workshop on Language in Social Media\n(LSM2012), 65–74, 2012.\n[4]\nA.M. Ciobanu, L.P. Dinu. An Etymological Approach to Cross-Language\nOrthographic Similarity: Application on Romanian. Proceedings of the\n2014 Conference on Empirical Methods in Natural Language Processing\n(EMNLP), 1047–1058, 2014\n[5]\nT. Dunning. Statistical Identiﬁcation of Language Technical Report, CRL\nTechnical Memo MCCS-94-273, 1–29, 1994.\n[6]\nR. Feldman, I. Dagan. KDT - Knowledge Discovery in Texts Proceedings\nof the First International Conference on Knowledge Discovery (KDD),\n112–117, 1995\n[7]\nC. Peters, M. Braschler, P Clough. Multilingual Information Retrieval:\nFrom Research to Practice. Springer Science & Business Media, 2012\n[8]\nS. Rajesh, L. Vandana, C.A. Carie, B. Marapelli. Recognizing the\nlanguages in Web Pages - A framework for NLP. IEEE International\nConference on Computational Intelligence and Computing Research\n(ICCIC), 1–5, 2013\n[9]\nH. Takc¸ı, T. Gungor. A high performance centroid-based classiﬁcation\napproach for Language Identiﬁcation. Pattern Recognition Letters 33,\n2077–2084, 2012\n[10]\nE. Tromp, M. Pechenizkiy. Graph-Based N-gram Language Identi-\nﬁcation on Short Texts. Proceedings of the 20th Machine Learning\nconference of Belgium and The Netherlands, 27–34, 2011.\n[11]\nA. Xafopoulos, C. Kotropoulos, G. Almpanidis, I. Pitas. Language\nIdentiﬁcation in Web Documents using Discrete HMMs. The Journal\nPattern of Recognition Society, Pattern Recognition 37, 583–597, 2004\n",
  "categories": [
    "cs.CL",
    "cs.IR"
  ],
  "published": "2018-06-14",
  "updated": "2018-06-14"
}