{
  "id": "http://arxiv.org/abs/1807.00914v3",
  "title": "Modeling Language Variation and Universals: A Survey on Typological Linguistics for Natural Language Processing",
  "authors": [
    "Edoardo Maria Ponti",
    "Helen O'Horan",
    "Yevgeni Berzak",
    "Ivan Vulić",
    "Roi Reichart",
    "Thierry Poibeau",
    "Ekaterina Shutova",
    "Anna Korhonen"
  ],
  "abstract": "Linguistic typology aims to capture structural and semantic variation across\nthe world's languages. A large-scale typology could provide excellent guidance\nfor multilingual Natural Language Processing (NLP), particularly for languages\nthat suffer from the lack of human labeled resources. We present an extensive\nliterature survey on the use of typological information in the development of\nNLP techniques. Our survey demonstrates that to date, the use of information in\nexisting typological databases has resulted in consistent but modest\nimprovements in system performance. We show that this is due to both intrinsic\nlimitations of databases (in terms of coverage and feature granularity) and\nunder-employment of the typological features included in them. We advocate for\na new approach that adapts the broad and discrete nature of typological\ncategories to the contextual and continuous nature of machine learning\nalgorithms used in contemporary NLP. In particular, we suggest that such\napproach could be facilitated by recent developments in data-driven induction\nof typological knowledge.",
  "text": "Modeling Language Variation and Universals:\nA Survey on Typological Linguistics for\nNatural Language Processing\nEdoardo Maria Ponti∗\nLTL, University of Cambridge\nHelen O’Horan∗∗\nLTL, University of Cambridge\nYevgeni Berzak†\nDepartment of Brain and Cognitive\nSciences, MIT\nIvan Vuli´c‡\nLTL, University of Cambridge\nRoi Reichart§\nFaculty of Industrial Engineering and\nManagement, Technion – IIT\nThierry Poibeau#\nLATTICE Lab, CNRS and ENS/PSL and\nUniv. Sorbonne nouvelle/USPC\nEkaterina Shutova**\nILLC, University of Amsterdam\nAnna Korhonen††\nLTL, University of Cambridge\nLinguistic typology aims to capture structural and semantic variation across the world’s\nlanguages. A large-scale typology could provide excellent guidance for multilingual Natural\nLanguage Processing (NLP), particularly for languages that suffer from the lack of human labeled\nresources. We present an extensive literature survey on the use of typological information in the\ndevelopment of NLP techniques. Our survey demonstrates that to date, the use of information\nin existing typological databases has resulted in consistent but modest improvements in system\nperformance. We show that this is due to both intrinsic limitations of databases (in terms of\ncoverage and feature granularity) and under-employment of the typological features included in\nthem. We advocate for a new approach that adapts the broad and discrete nature of typological\ncategories to the contextual and continuous nature of machine learning algorithms used in\ncontemporary NLP. In particular, we suggest that such approach could be facilitated by recent\ndevelopments in data-driven induction of typological knowledge.\n∗English Faculty Building, 9 West Road Cambridge CB3 9DA, United Kingdom. E-mail: ep490@cam.ac.uk\n∗∗English Faculty Building. E-mail: helen.ohoran@gmail.com\n† 77 Massachusetts Avenue, Cambridge, MA 02139, USA. E-mail: berzak@mit.edu\n‡ English Faculty Building. E-mail: iv250@cam.ac.uk\n§ Technion City, Haifa 3200003, Israel. E-mail: roiri@ie.technion.ac.il\n# 1 Rue Maurice Arnoux, 92120 Montrouge, France. E-mail: thierry.poibeau@ens.fr\n∗∗Science Park 107, 1098 XG Amsterdam, Netherlands. E-mail: shutova.e@uva.nl\n†† English Faculty Building. E-mail: alk23@cam.ac.uk\nSubmission received: 30 June 2018; revised version received: 20 March 2019; accepted for publication: 12 June\n2019.\n© 2019 Association for Computational Linguistics\narXiv:1807.00914v3  [cs.CL]  26 Oct 2020\nVolume xx, Number xx\n1. Introduction\nThe world’s languages may share universal features at a deep, abstract level, but the\nstructures found in real-world, surface-level texts can vary signiﬁcantly. This cross-\nlingual variation has challenged the development of robust, multilingually applicable\nNLP technology, and as a consequence, existing NLP is still largely limited to a handful of\nresource-rich languages. The architecture design, training, and hyper-parameter tuning\nof most current algorithms are far from being language-agnostic, and often inadvertently\nincorporate language-speciﬁc biases (Bender 2009, 2011). In addition, most state-of-the-\nart machine learning models rely on supervision from (large amounts of) labeled data\n— a requirement that cannot be met for the majority of the world’s languages (Snyder\n2010).\nOver time, approaches have been developed to address the data bottleneck in\nmultilingual NLP. These include unsupervised models that do not rely on the availability\nof manually annotated resources (Snyder and Barzilay 2008; Vuli´c, De Smet, and Moens\n2011, inter alia) and techniques that transfer data or models from resource-rich to resource-\npoor languages (Padó and Lapata 2005; Das and Petrov 2011; Täckström, McDonald,\nand Uszkoreit 2012, inter alia). Some multilingual applications, such as Neural Machine\nTranslation and Information Retrieval, have been facilitated by learning joint models\nthat learn from several languages (Ammar et al. 2016; Johnson et al. 2017, inter alia)\nor via multilingual distributed representations of words and sentences (Mikolov, Le,\nand Sutskever 2013, inter alia). Such techniques can lead to signiﬁcant improvements in\nperformance and parameter efﬁciency over monolingual baselines (Pappas and Popescu-\nBelis 2017).\nAnother, highly promising source of information for modelling cross-lingual varia-\ntion can be found in the ﬁeld of Linguistic Typology. This discipline aims to systematically\ncompare and document the world’s languages based on the empirical observation of their\nvariation with respect to cross-lingual benchmarks (Comrie 1989; Croft 2003). Research\nefforts in this ﬁeld have resulted in large typological databases, e.g. most prominently\nthe World Atlas of Language Structures (WALS) (Dryer and Haspelmath 2013). Such\ndatabases can serve as a source of guidance for feature choice, algorithm design, and\ndata selection or generation in multilingual NLP.\nPrevious surveys on this topic have covered earlier research integrating typological\nknowledge into NLP (O’Horan et al. 2016; Bender 2016), however, there is still no\nconsensus on the general effectiveness of this approach. For instance, Sproat (2016)\nhas argued that data-driven machine learning should not need to commit to any\nassumptions about categorical and manually deﬁned language types as deﬁned in\ntypological databases.\nIn this paper, we provide an extensive survey of typologically informed NLP methods\nto date, including the more recent neural approaches not previously surveyed in this\narea. We consider the impact of typological (including both structural and semantic)\ninformation on system performance and discuss the optimal sources for such information.\nTraditionally, typological information has been obtained from hand-crafted databases\nand, therefore, it tends to be coarse-grained and incomplete. Recent research has focused\non inferring typological information automatically from multilingual data (Asgari and\nSchütze 2017, inter alia), with the speciﬁc purpose of obtaining a more complete and\nﬁner-grained set of feature values. We survey these techniques and discuss ways to\nintegrate their predictions into the current NLP algorithms. To the best of our knowledge,\nthis has not yet been covered in the existing literature.\n2\nPonti et al.\nModeling Language Variation and Universals\nIn short, the key questions our paper addresses can be summarized as follows:\n(i) Which NLP tasks and applications can beneﬁt from typology? (ii) What are the\nadvantages and limitations of currently available typological databases? Can data-driven\ninference of typological features offer an alternative source of information? (iii) Which\nmethods have been proposed to incorporate typological information in NLP systems,\nand how should such information be encoded? (iv) To what extent does the performance\nof typology-savvy methods surpass typology-agnostic baselines? How does typology\ncompare to other criteria of language classiﬁcation, such as genealogy? (v) How can\ntypology be harnessed for data selection, rule-based systems, and model interpretation?\nWe start this survey with a brief overview of Linguistic Typology (§ 2) and multilin-\ngual NLP (§ 3). After these introductory sections we proceed to examine the development\nof typological information for NLP, including that in hand-crafted typological databases\nand that derived through automatic inference from linguistic data (§ 4). In the same\nsection, we also describe typological features commonly selected for application in NLP.\nIn § 5 we discuss ways in which typological information has been integrated into NLP\nalgorithms, identifying the main trends and comparing the performance of a range of\nmethods. Finally, in § 6 we discuss the current limitations in the use of typology in NLP\nand propose novel research directions inspired by our ﬁndings.\n2. Overview of Linguistic Typology\nThere is no consensus on the precise number of languages in the world. For example,\nGlottolog provides the estimate of 7748 (Hammarström et al. 2016), while Ethnologue\n(Lewis, Simons, and Fennig 2016) refers to 7097.1 This is due to the fact that deﬁning\nwhat constitutes a ’language’ is in part arbitrary. Mutual intelligibility, which is used\nas the main criterion for including different language variants under the same label, is\ngradient in nature. Moreover, social and political factors play a role in the deﬁnition of\nlanguage.\nLinguistic Typology is the discipline that studies the variation among the world’s\nlanguages through their systematic comparison (Comrie 1989; Croft 2003). The compari-\nson is challenging because linguistic categories cannot be pre-deﬁned (Haspelmath 2007).\nRather, cross-linguistically signiﬁcant categories emerge inductively from the comparison\nof known languages, and are progressively reﬁned with the discovery of new languages.\nCrucially, the comparison needs to be based on functional criteria, rather than formal\ncriteria. Typologists distinguish between constructions, abstract and universal functions,\nand strategies, the type of expressions adopted by each language to codify a speciﬁc\nconstruction (Croft et al. 2017). For instance, the passive voice is considered a strategy\nthat emphasizes the semantic role of patient: some languages lack this strategy and use\nothers strategies to express the construction. For instance, Awtuw (Sepik family) simply\nallows for the subject to be omitted.\nThe classiﬁcation of the strategies in each language is grounded in typological\ndocumentation (Bickel 2007, p. 248). Documentation is empirical in nature and involves\ncollecting texts or speech excerpts, and assessing the features of a language based on their\nanalysis. The resulting information is stored in large databases (see § 4.1) of attribute–\nvalues (this pair is henceforth referred to as typological feature), where usually each\n1 These counts include only languages traditionally spoken by a community as their principal means of\ncommunication, and exclude unattested, pidgin, whistled, and sign languages.\n3\nVolume xx, Number xx\nattribute corresponds to a construction and each value to the most widespread strategy\nin a speciﬁc language.\nAnalysis of cross-lingual patterns reveals that cross-lingual variation is bounded and\nfar from random (Greenberg 1966b). Indeed, typological features can be interdependent:\nthe presence of one feature may implicate another (in one direction or both). This\ninterdependence is called restricted universal, as opposed to unrestricted universals,\nwhich specify properties shared unconditionally by all languages. Such typological\nuniversals (restricted or not) are rarely absolute (i.e. exceptionless); rather, they are\ntendencies (Corbett 2010), hence they are called “statistical”. For example, consider\nthis restricted universal: if a language (such as Hmong Njua, Hmong–Mien family)\nhas prepositions, then genitive-like modiﬁers follow their head. If, instead, a language\n(such as Slavey, Na–Dené family) has postpositions, the order of heads and genitive-\nlike modiﬁers is swapped. However, there are known exceptions: Norwegian (Indo–\nEuropean) has prepositions but genitives precede their syntactic heads.2 Moreover, some\ntypological features are rare while others are highly frequent. Interestingly, this also\nmeans that some languages are intuitively more plausible than others. Implications and\nfrequencies of features are important as they unravel the deeper explanatory factors\nunderlying the patterns of cross-linguistic variation (Dryer 1998).\nCross-lingual variation can be found at all levels of linguistic structure. The seminal\nworks on Linguistic Typology were concerned with morphosyntax, mainly morphologi-\ncal systems (Sapir 2014 [1921], p. 128) and word order (Greenberg 1966b). This level of\nanalysis deals with the form of meaningful elements (morphemes and words) and their\ncombination, hence it is called structural typology. As an example, consider the alignment\nof the nominal case system (Dixon 1994): some languages like Nenets (Uralic) use the\nsame case for subjects of both transitive and intransitive verbs, and a different one for\nobjects (nominative–accusative alignment). Other languages like Lezgian (Northeast\nCaucasian) group together intransitive subjects and objects, and treat transitive subjects\ndifferently (ergative–absolutive alignment).\nOn the other hand, semantic typology studies languages at the semantic and prag-\nmatic levels. This area was pioneered by anthropologists interested in kinship (d’Andrade\n1995) and colors (Berlin and Kay 1969), and was expanded by studies on lexical classes\n(Dixon 1977). The main focus of semantic typology has been to categorize languages\nin terms of concepts (Evans 2011) in the lexicon, in particular with respect to the 1)\ngranularity, 2) division (boundary location), and 3) membership criteria (grouping and\ndissection). For instance, consider the event expressed by to open (something). It lacks a\nprecise equivalent in languages such as Korean, where similar verbs overlap in meaning\nonly in part (Bowerman and Choi 2001). For instance, ppaeda means ‘to remove an object\nfrom tight ﬁt’, used e.g. for drawers, and pyeolchida means ‘to spread out a ﬂat thing’,\nused e.g. for hands. Moreover, the English verb encodes the resulting state of the event,\nwhereas an equivalent verb in another language such as Spanish (abrir) rather expresses\nthe manner of the event (Talmy 1991). Although variation in the categories is pervasive\ndue to their partly arbitrary nature, it is constrained cross-lingually via shared cognitive\nconstraints (Majid et al. 2007).\nSimilarities between languages do not always arise from language-internal dynamics\nbut also from external factors. In particular, similarities can be inherited from a common\n2 Exception-less generalizations are known as absolute universals. However, properties that have been\nproposed as such are often controversial, because they are too vacuous or have been eventually falsiﬁed\n(Evans and Levinson 2009).\n4\nPonti et al.\nModeling Language Variation and Universals\nancestor (genealogical bias) or borrowed by contact with a neighbor (areal bias) (Bakker\n2010). Owing to genealogical inheritance, there are features that are widespread within a\nfamily but extremely rare elsewhere (e.g. the presence of click phonemes in the Khoisan\nlanguages). As an example of geographic percolation, most languages in the Balkan area\n(Albanian, Bulgarian, Macedonian, Romanian, Torlakian) have developed, even without\na common ancestor, a deﬁnite article that is put after its noun simply because of their\nclose proximity.\nResearch in linguistic typology has sought to disentangle such factors and to integrate\nthem into a single framework aimed at answering the question “what’s where why?”\n(Nichols 1992). Language can be viewed as a hybrid biological and cultural system. The\ntwo components co-evolved in a twin track, developing partly independently and partly\nvia mutual interaction (Durham 1991). The causes of cross-lingual variation can therefore\nbe studied from two complementary perspectives — from the perspective of functional\ntheories or event-based theories (Bickel 2015). The former theories involve cognitive and\ncommunicative principles (internal factors) and account for the origin of variation, while\nthe latter ones emphasize the imitation of patterns found in other languages (external\nfactors) and account for the propagation (or extinction) of typological features (Croft\n1995, 2000).\nExamples of functional principles include factors associated with language use, such\nas the frequency or processing complexity of a pattern (Cristofaro and Ramat 1999).\nPatterns that are easy or widespread get integrated into the grammar (Haspelmath 1999,\ninter alia). On the other hand, functional principles allow the speakers to draw similar\ninferences from similar contexts, leading to locally motivated pathways of diachronic\nchange through the process known as grammaticalization (Greenberg 1966a, 1978; Bybee\n1988). For instance, in the world’s languages (including English) the future tense marker\nalmost always originates from verbs expressing direction, duty, will, or attempt because\nthey imply a future situation.\nThe diachronic and gradual origin of the changes in language patterns and the statis-\ntical nature of the universals explain why languages do not behave monolithically. Each\nlanguage can adopt several strategies for a given construction and partly inconsistent\nsemantic categories. In other words, typological patterns tend to be gradient. For instance,\nthe semantics of grammatical and lexical categories can be represented on continuous\nmulti-dimensional maps (Croft and Poole 2008). Bybee and McClelland (2005) have\nnoted how this gradience resembles the patterns learned by connectionist networks (and\nstatistical machine learning algorithms in general). In particular, they argue that such\narchitectures are sensitive to both local (contextual) information and general patterns, as\nwell as to their frequency of use, similarly to natural languages.\nTypological documentation is limited by the fact that the evidence available for each\nlanguage is highly unbalanced and many languages are not even recorded in a written\nform.3 However, large typological databases such as WALS (Dryer and Haspelmath 2013)\nnevertheless have an impressive coverage (syntactic features for up to 1519 languages).\nWhere such information can be usefully integrated in machine learning, it can provide\nan alternative form of guidance to manual construction of resources that are now largely\nlacking for low resource languages. We discuss the existing typological databases and\nthe integration of their features into NLP models in sections 4 and 5.\n3 According to Lewis, Simons, and Fennig (2016), 34.4% of the world’s languages are threatened, not\ntransmitted to younger generations, moribund, nearly extinct or dormant. Moreover, 34% of the world’s\nlanguages are vigorous but have not yet developed a system of writing.\n5\nVolume xx, Number xx\n3. Overview of Multilingual NLP\nThe scarcity of data and resources in many languages represents a major challenge for\nmultilingual NLP. Many state-of-the-art methods rely on supervised learning, hence their\nperformance depends on the availability of manually crafted datasets annotated with\nlinguistic information (e.g., treebanks, parallel corpora) and/or lexical databases (e.g.,\nterminology databases, dictionaries). Although similar resources are available for key\ntasks in a few well-researched languages, the majority of the world’s languages lack them\nalmost entirely. This gap cannot be easily bridged: the creation of linguistic resources is a\ntime-consuming process and requires skilled labor. Furthermore, the immense range of\npossible tasks and languages makes the aim of a complete coverage unrealistic.\nOne solution to this problem explored by the research community abandons the\nuse of annotated resources altogether and instead focuses on unsupervised learning.\nThis class of methods infers probabilistic models of the observations given some latent\nvariables. In other words, it unravels the hidden structures within unlabeled text data.\nAlthough these methods have been employed extensively for multilingual applications\n(Snyder and Barzilay 2008; Vuli´c, De Smet, and Moens 2011; Titov and Klementiev\n2012, inter alia), their performance tends to lag behind the more linguistically informed\nsupervised learning approaches (Täckström, McDonald, and Nivre 2013). Moreover, they\nhave been rarely combined with typological knowledge. For these reasons, we do not\nreview them in this chapter.\nOther promising ways to overcome data scarcity include transferring models or\ndata from resource-rich to resource-poor languages (§ 3.1) or learning joint models\nfrom annotated examples in multiple languages (§ 3.2) in order to leverage language\ninter-dependencies. Early approaches of this kind have relied on universal, high-level\ndelexicalized features, such as PoS tags and dependency relations. More recently,\nhowever, the incompatibility of (language-speciﬁc) lexica has been countered by mapping\nequivalent words into the same multilingual semantic space through representation\nlearning (§ 3.3). This has enriched language transfer and multilingual joint modelling\nwith lexicalized features. In this chapter, we provide an overview of these methods, as\nthey constitute the backbone of the typology-savvy algorithms surveyed in § 5.\n3.1 Language Transfer\nLinguistic information can be transferred from resource-rich languages to resource-poor\nlanguages: these are commonly referred to as source languages and target languages,\nrespectively. Language transfer is challenging as it requires us to match word sequences\nwith different lexica and word orders, or syntactic trees with different (anisomorphic)\nstructures (Ponti et al. 2018a). As a consequence, the information obtained from the source\nlanguages typically needs to be adapted, by tailoring it to the properties of the target\nlanguages. The methods developed for language transfer include annotation projection,\n(de)lexicalized model transfer, and translation (Agi´c et al. 2014). We illustrate them below\nusing dependency parsing as an example.\nAnnotation projection was introduced in the seminal work of Yarowsky, Ngai, and\nWicentowski (2001) and Hwa et al. (2005). In its original formulation, as illustrated in\nFigure 1a, a source text is parsed and word-aligned with a target parallel raw text. Its\nannotation (e.g. PoS tags and dependency trees) is then projected directly and used to\ntrain a supervised model on the target language. Later reﬁnements to this process are\nknown as soft projection, where constraints can be used to complement alignment, based\non distributional similarity (Das and Petrov 2011) or constituent membership (Padó and\n6\nPonti et al.\nModeling Language Variation and Universals\nFigure 1: Three methods for language transfer: a) annotation projection, b) model transfer,\nand c) translation. The image has been adapted from Tiedemann (2015).\nLapata 2009). Moreover, source model expectations on labels (Wang and Manning 2014;\nAgi´c et al. 2016) or sets of most likely labels (Khapra et al. 2011; Wisniewski et al. 2014)\ncan be projected instead of single categorical labels. These can constrain unsupervised\nmodels by reducing the divergence between the expectations on target labels and on\nsource labels or support ‘ambiguous learning’ on the target language, respectively.\nModel transfer instead involves training a model (e.g. a parser) on a source language\nand applying it on a target language (Zeman and Resnik 2008), as shown in Figure\n1b. Due to their incompatible vocabularies, models are typically delexicalized prior\nto transfer and take language-independent (Nivre et al. 2016) or harmonized (Zhang\net al. 2012) features as input. In order to bridge the vocabulary gap, model transfer was\nlater augmented with multilingual Brown word clusters (Täckström, McDonald, and\nUszkoreit 2012) or multilingual distributed word representations (see § 3.3).\nMachine translation offers an alternative to lexicalization in absence of annotated\nparallel data. As shown in Figure 1c, a source sentence is machine translated into a\ntarget language, (Banea et al. 2008) or through a bilingual lexicon (Durrett, Pauls, and\nKlein 2012). Its annotation is then projected and used to train a target-side supervised\nmodel. Translated documents can also be employed to generate multilingual sentence\nrepresentations, which facilitate language transfer (Zhou, Wan, and Xiao 2016).\nSome of these methods are hampered by their resource requirements. In fact,\nannotation projection and translation need parallel texts to align words and train\ntranslation systems, respectively (Agi´c, Hovy, and Søgaard 2015). Moreover, comparisons\nof state-of-the-art algorithms revealed that model transfer is competitive with machine\ntranslation in terms of performance (Conneau et al. 2018). Partly owing to these reasons,\ntypological knowledge has been mostly harnessed in connection with model transfer,\nas we discuss in § 5.2. Moreover, typological features can guide the selection of the best\n7\nVolume xx, Number xx\nFigure 2: In multilingual joint learning, representations can be private or shared across\nlanguages. Tied parameters are shown as neurons with identical color. Image adapted\nfrom Fang and Cohn (2017), representing multilingual PoS tagging for Bambara (left)\nand Warlpiri (right).\nsource language to match to a target language for language transfer (Agi´c et al. 2016,\ninter alia), which beneﬁts all the above-mentioned methods (see § 5.3).\n3.2 Multilingual Joint Supervised Learning\nNLP models can be learned jointly from the data in multiple languages. In addition to\nfacilitating intrinsically multilingual applications, such as Neural Machine Translation\nand Information Extraction, this approach often surpasses language-speciﬁc monolingual\nmodels as it can leverage more (although noisier) data (Ammar et al. 2016, inter alia). This\nis particularly true in scenarios where either a target or all languages are resource-lean\n(Khapra et al. 2011) or in code-switching scenarios (Adel, Vu, and Schultz 2013). In fact,\nmultilingual joint learning improves over pure model transfer also in scenarios with\nlimited amounts of labeled data in target language(s) (Fang and Cohn 2017).4\nA key strategy for multilingual joint learning is parameter sharing (Johnson et al.\n2017). More speciﬁcally, in state-of-the-art neural architectures input and hidden repre-\nsentations can be either private (language-speciﬁc) or shared across languages. Shared\nrepresentations are the result of tying the parameters of a network component across\nlanguages, such as word embeddings (Guo et al. 2016), character embeddings (Yang,\nSalakhutdinov, and Cohen 2016), hidden layers (Duong et al. 2015b) or the attention\n4 This approach is also more cost-effective in terms of parameters (Pappas and Popescu-Belis 2017).\n8\nPonti et al.\nModeling Language Variation and Universals\nmechanism (Pappas and Popescu-Belis 2017). Figure 2 shows an example where all the\ncomponents of a PoS tagger are shared between two languages (Malagasy on the left and\nPolish on the right). Parameter sharing, however, does not necessarily imply parameter\nidentity: it can be enforced by minimizing the distance between parameters (Duong et al.\n2015a) or between latent representations of parallel sentences (Niehues et al. 2011; Zhou\net al. 2015) in separate language-speciﬁc models.\nAnother common strategy in multilingual joint modeling is providing information\nabout the properties of the language of the current text in the form of input language\nvectors (Guo et al. 2016). The intuition is that this helps tailoring the joint model toward\nspeciﬁc languages. These vectors can be learned end-to-end in neural language modeling\ntasks (Tsvetkov et al. 2016; Östling and Tiedemann 2017) or neural machine translation\ntasks (Johnson et al. 2017; Ha, Niehues, and Waibel 2016). Ammar et al. (2016) instead\nused language vectors as a prior for language identity or typological features.\nIn § 5.2, we discuss ways in which typological knowledge is used to balance\nprivate and shared neural network components and provide informative input language\nvectors. In § 6.3, we argue that language vectors do not need to be limited to features\nextracted from typological databases, but also include automatically induced typological\ninformation (Malaviya, Neubig, and Littell 2017, see § 4.3).\n3.3 Multilingual Representation Learning\nThe multilingual algorithms reviewed in § 3.1 and § 3.2 are facilitated by dense real-\nvalued vector representations of words, known as multilingual word embeddings. These\ncan be learned from corpora and provide pivotal lexical features to several downstream\nNLP applications. In multilingual word embeddings, similar words (regardless of the\nactual language) obtain similar representations. Various methods to generate multilingual\nword embeddings have been developed. We follow the classiﬁcation proposed by Ruder\n(2018), whereas we refer the reader to Upadhyay et al. (2016) for an empirical comparison.\nMonolingual mapping generates independent monolingual representations and\nsubsequently learns a linear map between a source language and a target language based\non a bilingual lexicon (Mikolov, Le, and Sutskever 2013) or in an unsupervised fashion\nthrough adversarial networks (Conneau et al. 2017). Alternatively, both spaces can be\ncast into a new, lower-dimensional space through canonical correlation analysis (CCA)\nbased on dictionaries (Ammar et al. 2016) or word alignments (Guo et al. 2015).\nPseudo-cross-lingual approaches merge words with contexts of other languages\nand generate representations based on this mixed corpus. Substitutions are based on\nWiktionary (Xiao and Guo 2014) or machine translation (Gouws and Søgaard 2015;\nDuong et al. 2016). Moreover, the mixed corpus can be produced by randomly shufﬂing\nwords between aligned documents in two languages (Vuli´c and Moens 2015).\nCross-lingual training approaches jointly learn embeddings from parallel corpora\nand enforce cross-lingual constraints. This involves minimizing the distance of the hidden\nsentence representations of the two languages (Hermann and Blunsom 2014) or decoding\none from the other (Lauly, Boulanger, and Larochelle 2013), possibly adding a correlation\nterm to the loss (Chandar et al. 2014).\nJoint optimization typically involves learning distinct monolingual embeddings,\nwhile enforcing cross-lingual constraints. These can be based on alignment-based\ntranslations (Klementiev, Titov, and Bhattarai 2012), cross-lingual word contexts (Luong,\nPham, and Manning 2015), the average representations of parallel sentences (Gouws,\nBengio, and Corrado 2015), or images (Rotman, Vuli´c, and Reichart 2018).\n9\nVolume xx, Number xx\nIn this section, we have brieﬂy outlined the most widely used methods in mul-\ntilingual NLP. Although they offer a solution to data scarcity, cross-lingual variation\nremains a challenge for transferring knowledge across languages or learning from several\nlanguages simultaneously. Typological information offers promising ways to address this\nproblem. In particular, we have noted that it can support model transfer, parameter\nsharing, and input biasing through language vectors. In the next two sections, we\nelaborate on these solutions. In particular, we review the development of typological\ninformation and the speciﬁc features which are selected for various NLP tasks (§ 4).\nAfterwards, we discuss ways in which these features are integrated in NLP algorithms,\nfor which applications they have been harnessed, and whether they truly beneﬁt system\nperformance (§ 5).\n4. Selection and Development of Typological Information\nIn this section we ﬁrst present major publicly available typological databases and then\ndiscuss how typological information relevant to NLP models is selected, pre-processed\nand encoded. Finally, we highlight some limitations of database documentation with\nrespect to coverage and feature granularity, and discuss how missing and ﬁner-grained\nfeatures can be obtained automatically.\n4.1 Hand-Crafted Documentation in Typological Databases\nFigure 3: Number of grammatical genders for nouns in the world’s languages according\nto WALS (Dryer and Haspelmath 2013): none (white), two (yellow), three (orange), four\n(red), ﬁve or more (black).\nTypological databases are created manually by linguists. They contain taxonomies\nof typological features, their possible values, as well as the documentation of feature\nvalues for the world’s languages. Major typological databases, listed in Table 1, typically\norganize linguistic information in terms of universal features and language-speciﬁc\nvalues. For example, Figure 3 presents language-speciﬁc values for the feature number of\ngrammatical genders for nouns on a world map. Note that each language is color-coded\n10\nPonti et al.\nModeling Language Variation and Universals\nName\nLevels\nCoverage\nFeature Example\nWorld Atlas of\nLanguage\nStructures\n(WALS)\nPhonology,\nMorphosyn-\ntax, Lexical\nsemantics\n2,676 languages;\n192 attributes; 17%\nvalues covered\nORDER OF OBJECT AND VERB\nAmele : OV (713)\nGbaya Kara : VO (705)\nAtlas of Pidgin\nand Creole\nLanguage\nStructures\n(APiCS)\nPhonology,\nMorphosyntax\n76 languages; 335\nattributes\nTENSE–ASPECT SYSTEMS\nTernate Chabacano : purely aspectual (10)\nAfrikaans : purely temporal (1)\nURIEL\nTypological\nCompendium\nPhonology,\nMorphosyn-\ntax, Lexical\nsemantics\n8,070 languages;\n284 attributes;\n~439,000 values\nCASE IS PREFIX\nBerber (Middle Atlas) : yes (38)\nHawaaian : no (993)\nSyntactic\nStructures of the\nWorld’s\nLanguages\n(SSWL)\nMorphosyntax\n262 languages;\n148 attributes; 45%\nvalues covered\nSTANDARD NEGATION IS SUFFIX\nAmharic : yes (21)\nLaal : no (170)\nAUTOTYP\nMorphosyntax\n825 languages,\n~1000 attributes\nPRESENCE OF CLUSIVITY\n!Kung (Ju) : false\nIk (Kuliak) : true\nValency Patterns\nLeipzig (ValPaL)\nPredicate–\nargument\nstructures\n36 languages; 80\nattributes; 1,156\nvalues\nTO LAUGH\nMandinka : 1 > V\nSliammon : V.sbj[1] 1\nLyon–\nAlbuquerque\nPhonological\nSystems Database\n(LAPSyD)\nPhonology\n422 languages;\n~70 attributes\nâ AND ú\nSindhi : yes (1)\nChuvash : no (421)\nPHOIBLE Online\nPhonology\n2155 languages;\n2,160 attributes\nm\nVietnamese : yes (2053)\nPirahã : no (102)\nStressTyp2\nPhonology\n699 languages;\n927 attributes\nSTRESS ON FIRST SYLLABLE\nKoromfé : yes (183)\nCubeo : no (516)\nWorld Loanword\nDatabase (WOLD)\nLexical\nsemantics\n41 languages; 24\nattributes; ~2000\nvalues\nHORSE\nQuechua : kaballu borrowed (24)\nSakha : s1lg1 no evidence (18)\nIntercontinental\nDictionary Series\n(IDS)\nLexical\nsemantics\n329 languages;\n1310 attributes\nWORLD\nRussian : mir\nTocharian A : ¯arki´sos.i\nAutomated\nSimilarity\nJudgment\nProgram (ASJP)\nLexical\nSemantics\n7,221 languages;\n40 attributes\nI\nAinu Maoka : co7okay\nJapanese : watashi\nTable 1: An overview of major publicly accessible databases of typological information.\nThe databases are ordered by description level (and secondly by date of creation), along\nwith their coverage. The table also provides feature examples: for each feature (in small\ncapitals) we present two example languages with distinct feature values, and the total\nnumber of languages with each value in parenthesis (where applicable).\n11\nVolume xx, Number xx\naccording to its value. Further examples for each database can be found in the rightmost\ncolumn of Table 1.\nSome databases store information pertaining to multiple levels of linguistic de-\nscription. These include the World Atlas of Language Structures (WALS) (Dryer and\nHaspelmath 2013) and the Atlas of Pidgin and Creole Language Structures (APiCS)\n(Michaelis et al. 2013). Among all presently available databases, WALS has been the\nmost widely used in NLP. In this resource, which has 142 typological features in total,\n1–19 deal with phonology, 20–29 with morphology, 30–57 with nominal categories, 58–64\nwith nominal syntax, 65–80 with verbal categories, 81–97 and 143–144 with word order,\n98–121 with simple clauses, 122–128 with complex sentences, 129–138 with the lexicon,\nand 139–142 with other properties.\nOther databases only cover features at a speciﬁc level of linguistic description. For\nexample, both Syntactic Structures of the World’s Languages (SSWL) (Collins and Kayne\n2009) and AUTOTYP (Bickel et al. 2017) focus on syntax. SSWL features are manually\ncrafted, whereas AUTOTYP features are derived automatically from primary linguistic\ndata using scripts. The Valency Patterns Leipzig (ValPaL) (Hartmann, Haspelmath, and\nTaylor 2013) provides verbs as attributes and predicate–argument structures as their\nvalues (including both valency and morphosyntactic constraints). For example, in both\nMandinka and Sliammon, the verb to laugh has a valency of 1; in other words, it requires\nonly one mandatory argument, the subject. In Mandinka the subject precedes the verb,\nbut there is no agreement requirement; in Sliammon, on the other hand, the word order\ndoes not matter, but the verb is required to morphologically agree with the subject.\nFor phonology, the Phonetics Information Base and Lexicon (PHOIBLE) (Moran,\nMcCloy, and Wright 2014) collates information on segments (binary phonetic features). In\nthe Lyon–Albuquerque Phonological Systems Database (LAPSyD) (Maddieson et al.\n2013), attributes are articulatory traits, syllabic structures or tonal systems. Finally,\nStressTyp2 (Goedemans, Heinz, and der Hulst 2014) deals with stress and accent patterns.\nFor instance, in Koromfé each word’s ﬁrst syllable has to be stressed, but not in Cubeo.\nOther databases document various aspects of semantics. The World Loanword\nDatabase (WOLD) (Haspelmath and Tadmor 2009) documents loanwords by identifying\nthe donor languages and the source words. The Automated Similarity Judgment Program\n(ASJP) (Wichmann, Holman, and Brown 2016) and the Intercontinental Dictionary Series\n(IDS) (Key and Comrie 2015) indicate how a meaning is lexicalized across languages: e.g.\nthe concept of WORLD is expressed as mir in Russian, and as ¯arki´sos.i in Tocharian A.\nAlthough typological databases store abundant information on many languages,\nthey suffer from shortcomings that limit their usefulness. Perhaps the most signiﬁcant\nshortcoming of such resources is their limited coverage. In fact, feature values are\nmissing for most languages in most databases. Other shortcomings are related to feature\ngranularity. In particular, most databases fail to account for feature value variation within\neach language: they report only majority value rather than the full range of possible\nvalues and their corresponding frequencies. For example, the dominant Adjective–Noun\nword order in Italian is Adjective before Noun; however, the opposite order is also\nattested. The latter information is often missing from typological databases.\nFurther challenges are posed by restricted feature applicability and feature hierar-\nchies. Firstly, some features apply, by deﬁnition, only to subsets of languages that share\nanother feature value. For instance, WALS feature 113A documents “Symmetric and\nAsymmetric Standard Negation\", whereas WALS feature 114A “Subtypes of Asymmetric\nStandard Negation”. Although a special NA value is assigned for symmetric-negation\nlanguages in the latter, there are cases where languages without the prerequisite feature\nare simply omitted from the sample. Secondly, features can be partially redundant, and\n12\nPonti et al.\nModeling Language Variation and Universals\nSubject, Object and Verb 81A\nSubject and Verb 82A\nObject and Verb 83A\nObject, Oblique and Verb 84A\nAdposition and Noun Phrase 85A\nGenitive and Noun 86A\nAdjective and Noun 87A\nDemonstrative and Noun 88A\nNumeral and Noun 89A\n0\n2\n4\n6\nAmmar+ 2016\nDaiber+ 2016\nNaseem+ 2012\nTäckström+ 2013\nZhang+ 2012\nZhang+ 2015\nFigure 4: Feature sets employed in a sample of typologically informed experiments for\ndependency parsing. The numbers refer to WALS ordering (Dryer and Haspelmath\n2013).\nsubsume other features. For instance, WALS feature 81A “Order of Subject, Object and\nVerb” encodes the same information as WALS feature 82A “Order of Subject and Verb”\nand 83A “Order of Object and Verb”, with the addition of the order of Subject and Object.\n4.2 Feature Selection from Typological Databases\nThe databases presented above can serve as a rich source of typological information\nfor NLP. In this section, we survey the feature sets that have been extracted from these\ndatabases in typologically informed NLP studies. In § 5.4, we review in which ways\nand to which degree of success these features have been integrated in machine learning\nalgorithms.\nMost NLP work incorporated a subset of word order features from WALS (Dryer and\nHaspelmath 2013), mostly for the task of syntactic dependency parsing, where word order\nprovides crucial guidance (Naseem, Barzilay, and Globerson 2012). The feature subsets\nused in different studies are shown in Figure 4. As depicted in the ﬁgure, these studies\nemployed quite similar word order features. The feature set ﬁrst established by Naseem,\nBarzilay, and Globerson (2012) served as inspiration for subsequent works. These works,\nhowever, often discarded features with the same value for all of the languages in their\nsample, as these were not discriminative.\nAnother group of studies used more comprehensive feature sets. The feature set\nof Daiber, Stanojevi´c, and Sima’an (2016) included not only WALS word order features\nbut also nominal categories (e.g. ‘Conjunctions and Universal Quantiﬁers’) and nominal\nsyntax (e.g. ‘Possessive Classiﬁcation’). Berzak, Reichart, and Katz (2015) considered all\nfeatures from WALS associated with morphosyntax and pruned out the redundant ones,\nresulting in a total of 119 features. Søgaard and Wulff (2012) utilized all the features in\nWALS with the exception of phonological features. Tsvetkov et al. (2016) selected 190\nbinarized phonological features from URIEL (Littel, Mortensen, and Levin 2016). These\n13\nVolume xx, Number xx\nga\nfi\nhu\nit\nes\nfr\nde\nsv\ncs\nen\n(a) Word-order features\nhu\nfi\nga\nsv\nde\nen\ncs\nit\nes\nfr\n(b) All WALS features with average genus values\nFigure 5: Heat maps of encodings for different subsets of typological WALS features\ntaken from Ammar et al. (2016): rows stand for languages, dimensions for attributes, and\ncolor intensities for feature values. Encodings are clustered hierarchically by similarity.\nThe meaning of language codes is: DE German, CS Czech, EN English, ES Spanish, FR\nFrench, FI Finnish, GA Irish Gaelic, HU Hungarian, IT Italian, SV Swedish.\nfeatures encoded the presence of single segments, classes of segments, minimal contrasts\nin a language inventory, and the number of segments in a class. For instance, they record\nwhether a language allows two sounds to differ only in voicing, such as /t/ and /d/.\nFinally, a small number of experiments adopted the entire feature inventory of\ntypological databases, without any sort of pre-selection. In particular Agi´c (2017) and\nAmmar et al. (2016) extracted all the features in WALS, while (Deri and Knight 2016)\nall the features in URIEL. Schone and Jurafsky (2001) did not resort to basic typological\nfeatures, but rather to “several hundred [implicational universals] applicable to syntax”\ndrawn from the Universal Archive (Plank and Filiminova 1996).\nTypological attributes that are extracted from typological databases are typically\nrepresented as feature vectors in which each dimension encodes a feature value. This\nfeature representation is often binarized (Georgi, Xia, and Lewis 2010): for each possible\nvalue v of each database attribute a, a new feature is created with value 1 if it corresponds\nto the actual value for a speciﬁc language and 0 otherwise. Note that this increases\nthe number of features by a factor of\n1\n||a||\nP||a||\ni=1 ||vai||. Although binarization helps\nharmonizing different features and different databases, it obscures the different types of\ntypological variables.\nTo what extent do the limitations of typological databases mentioned in § 4.1\naffect the feature sets surveyed in this section? The coverage is generally broad for\nthe languages used in these experiments, as they tend to be well documented. For\ninstance, on average 79.8% of the feature values are populated for the 14 languages\nappearing in Berzak, Reichart, and Katz (2015), as opposed to 17 percent for all the\nlanguages in WALS.\n14\nPonti et al.\nModeling Language Variation and Universals\nAuthor\nDetails\nRequirements\nLangs\nFeatures\nMorphosyntactic Annotation\nLiu (2010)\nTreebank count\nTreebank\n20\nword order\nLewis and Xia\n(2008)\nIGT projection\nIGT, source\nchunker\n97\nword and\nmorpheme order,\ndeterminers\nBender et al. (2013)\nIGT projection\nIGT, source\nchunker\n31\nword order and\ncase alignment\nÖstling (2015)\nTreebank\nprojection\nParallel text,\nsource tagger\nand parser\n986\nword order\nZhang et al. (2016)\nPoS projection\nsource tagger,\nseed dictionary\n6\nword order\nUnsupervised Propagation\nTeh, Daumé III,\nand Roy (2007)\nHierarchical\ntypological cluster\nWALS\n2150\nwhole\nGeorgi, Xia, and\nLewis (2010)\nMajority value\nfrom k-means\ntypological cluster\nWALS\nwhole\nwhole\nCoke, King, and\nRadev (2016)\nMajority value\nfrom genus\nGenealogy and\nWALS\n325\nword order and\npassive\nLittel, Mortensen,\nand Levin (2016)\nFamily, area, and\ntypology-based\nNearest Neighbors\nGenealogy and\nWALS\nwhole\nwhole\nBerzak, Reichart,\nand Katz (2014)\nEnglish as a\nSecond\nLanguage-based\nNearest Neighbors\nESL texts\n14\nwhole\nMalaviya, Neubig,\nand Littell (2017)\nTask-based\nlanguage vector\nNMT dataset\n1017\nwhole\nBjerva and\nAugenstein (2018)\nTask-based\nlanguage vector\nPoS tag dataset\n27-824\nphonology,\nmorphology,\nsyntax\nSupervised Learning\nTakamura, Nagata,\nand Kawasaki\n(2016)\nLogistic regression\nWALS\nwhole\nwhole\nMurawaki (2017)\nBayesian + feature\nand language\ninteractions\nGenealogy and\nWALS\n2607\nwhole\nWang and Eisner\n(2017)\nFeed-forward\nNeural Network\nWALS, tagger,\nsynthetic\ntreebanks\n37\nword order\nCotterell and\nEisner (2017)\nDeterminant Point\nProcess with\nneural features\nWALS\n200\nvowel inventory\nDaumé III and\nCampbell (2007)\nImplication\nuniversals\nGenealogy and\nWALS\nwhole\nwhole\nLu (2013)\nAutomatic\ndiscovery\nGenealogy and\nWALS\n1646\nword order\nCross-lingual\ndistribution\nWälchli and\nCysouw (2012)\nSentence edit\ndistance\nMulti-parallel\ntexts, pivot\n100\nmotion verbs\nAsgari and\nSchütze (2017)\nPivot alignment\nMulti-parallel\ntexts, pivot\n1163\ntense markers\nRoy et al. (2014)\nCorrelations in\ncounts and\nentropy\nNone\n23\nadposition word\norder\nTable 2: An overview of the strategies for prediction of typological features.\n15\nVolume xx, Number xx\nIt is hard to assess at a large scale how informative is a set of typological features.\nHowever, these can be meaningfully compared with genealogical information. Ideally,\nthese two properties should not be completely equivalent (otherwise they would be\nredundant),5 but at the same time they should partly overlap (language cognates inherit\ntypological properties from the same ancestors). In Figure 5, we show two feature sets\nappearing in Ammar et al. (2016), each depicted as a heatmap. Each row represents a\nlanguage in the data, each cell is colored according to the feature value, ranging from 0\nto 1. In particular, the feature set of Figure 5a is the subset of word order features listed\nin Figure 4; and Figure 5b is a large set of WALS features where values are averaged by\nlanguage genus to ﬁll in missing values.\nIn order to compare the similarities of the typological feature vectors among\nlanguages, we clustered languages hierarchically based on such vectors.6 Intuitively, the\nmore this hierarchy resembles their actual family tree, the more redundant typological\ninformation is. This is the case for 5b, where the lowest-lever clusters correspond\nexactly to a genus or family (top-down: Romance, Slavic, Germanic, Celtic, Uralic).\nStill, the language vectors belonging to the same cluster display some micro-variations\nin individual features. On the other hand, 5a shows clusters differing from language\ngenealogy: for instance, English and Czech are merged although they belong to different\ngenera (Germanic and Slavic). However, this feature set fails to account for ﬁne-grained\ndifferences among related languages: for instance, French, Spanish, and Italian receive\nthe same encoding.7\nTo sum up, this section’s survey on typological feature sets reveals that most\nexperiments have taken into account a small number of databases and features therein.\nHowever, several studies did utilize a larger set of coherent features or full databases.\nAlthough well-documented languages do not suffer much from coverage issues, we\nshowed how difﬁcult it is to select typological features that are non-redundant with\ngenealogy, fully discriminative, and informative. The next section addresses these\nproblems proposing automatic prediction as a solution.\n4.3 Automatic Prediction of Typological Features\nThe partial coverage and coarse granularity of existing typological resources sparked\na line of research on automatic acquisition of typological information. Missing feature\nvalues can be predicted based on: i) heuristics from morphosyntactic annotation that\npre-exists, such as treebanks, or is transferred from aligned texts (§ 4.3.1); ii) unsupervised\npropagation from other values in a database based on clustering or language similarity\nmetrics (§ 4.3.2); iii) supervised learning with Bayesian models or artiﬁcial neural\nnetworks (§ 4.3.3); or iv) heuristics based on co-occurrence metrics, typically applied to\nmulti-parallel texts (§ 4.3.4). These strategies are summarized in Table 2.\nWith the exception of Naseem, Barzilay, and Globerson (2012), who treated typo-\nlogical information as a latent variable, automatically acquired typological features\nhave not been integrated into algorithms for NLP applications to date. However, they\nhave several advantages over manually crafted features. Unsupervised propagation and\nsupervised learning ﬁll in missing values in databases, thereby extending their coverage.\nMoreover, heuristics based on morphosyntactic annotation and co-occurrence metrics\n5 This does not apply to isolates, however: by deﬁnition, no genealogical information is available for these\nlanguages. Hence, typology is the only source of information about their properties.\n6 Clustering was performed through the complete linkage method.\n7 Notwithstanding they have different preferences over word orders (Liu 2010).\n16\nPonti et al.\nModeling Language Variation and Universals\nextract additional information that is not recorded in typological databases. Further,\nthey can account for the distribution of feature values within single languages, rather\nthan just the majority value. Finally, they do not make use of discrete cross-lingual\ncategories to compare languages; rather, language properties are reﬂected in continuous\nrepresentations, which is in line with their gradient nature (see § 2)\n4.3.1 Heuristics based on morphosyntactic annotation. Morphosyntactic feature values\ncan be extracted via heuristics from morphologically and syntactically annotated texts.\nFor example, word order features can be calculated by counting the average direction\nof dependency relations or constituency hierarchies (Liu 2010). Consider the tree of a\nsentence in Welsh from Bender et al. (2013) in Figure 6. The relative order of verb–subject,\nand verb–object can be deduced from the position of the relevant nodes VBD, NNS and\nNNO (highlighted).\nS\nPP\nNN\nbachgen\nboy\nIN+DT\ni’r\nto the\nNP\nNNO\nlyfr\nbook\nNP\nNNS\nathro\nteacher\nDT\nyr\nthe\nVBD\nrhoddodd\ngave\nFigure 6: Constituency tree of a Welsh sentence.\nMorphosyntactic annotation is often unavailable for resource-lean languages. In such\ncases, it can be projected from a source directly to several target languages through\nlanguage transfer. For instance, Östling (2015) project source morphosyntactic annotation\ndirectly to several languages through a multilingual word alignment. After the alignment\nand projection, word order features are calculated by the average direction of dependency\nrelations. Similarly, Zhang et al. (2016) transfer POS annotation with a model transfer\ntechnique relying on multilingual embeddings, created through monolingual mapping\n(see § 3.3). After the projection, they predict feature values with a multiclass Support\nVector Machine (SVM) using POS tag n-gram features.\nFinally, typological information can be extracted from Interlinear Glossed Texts (IGT).\nSuch collections of example sentences are collated by linguists and contain grammatical\nglosses with morphological information. These can guide alignment between the example\nsentence and its English translation. Lewis and Xia (2008) and Bender et al. (2013)\nproject chunking information from English and train Context Free Grammars on target\nlanguages. After collapsing identical rules, they arrange them by frequency and infer\nword order features.\n4.3.2 Unsupervised propagation. Another line of research seeks to increase the coverage\nof typological databases borrowing missing values from the known values in other\nlanguages. One approach is clustering languages according to some criterion and\npropagating the majority value within each cluster. Hierarchical clusters can be created\neither according to typological features (e.g. Teh, Daumé III, and Roy (2007)) or based on\nlanguage genus (Coke, King, and Radev 2016). Through extensive evaluation, Georgi, Xia,\n17\nVolume xx, Number xx\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\n−10\n0\n10\n−10\n−5\n0\n5\n10\n15\n(a) Input vectors\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\n−10\n−5\n0\n5\n10\n15\n−10\n0\n10\n(b) Cell states\nG\nG\nG\nG\nG\nG\nGG\nG\nG\nG\nGG\nG\n−10\n0\n10\n−10\n0\n10\n20\nfamily\nG −−\nAfro−Asiatic\nAtlantic−Congo\nAustronesian\nIndo−European\nNambiquaran\nNuclear Trans New Guinea\nOtomanguean\nSino−Tibetan\n(c) Predicted WALS\nFigure 7: Language representations dimensionality-reduced with t-SNE.\nand Lewis (2010) demonstrate that typology based clustering outperforms genealogical\nclustering for unsupervised propagation of typological features. Among the clustering\ntechniques examined, k-means appears to be the most reliable as compared to k-medoids,\nthe Unweighted Pair Group Method with Arithmetic mean (UPGMA), repeated bisection,\nand hierarchical methods with partitional clusters.\nLanguage similarity measures can also rely on a distributed representation of each\nlanguage. These language vectors are trained end-to-end as part of neural models\nfor downstream tasks such as many-to-one Neural Machine Translation. In particular,\nlanguage vectors can be obtained from artiﬁcial trainable tokens concatenated to every\ninput sentence, similarly to Johnson et al. (2017), or from the aggregated values of the\nhidden state of a neural encoder. Using these language representations, typological\nfeature values are propagated using K Nearest Neighbors (Bjerva and Augenstein 2018)\nor predicted with logistic regression (Malaviya, Neubig, and Littell 2017).\nLanguage vectors can be conceived as data-driven, continuous typological rep-\nresentations of a language, and as such provide an alternative to manually crafted\ntypological representations. Similarly to the analysis carried out in § 4.2, we can\ninvestigate how much language vectors align with genealogical information. Figure\n7 compares continuous representations based on artiﬁcial tokens (Figure 7a) and encoder\nhidden states (Figure 7b) with vectors of discrete WALS features from URIEL (Figure 7c).\nAll the representations are reduced to 2 dimensions with t-SNE, and color-coded based\non their language family.\nAs the plots demonstrate, the information encoded in WALS vectors is akin to ge-\nnealogical information, partly because of biases introduced by family-based propagation\nof missing values (Littel, Mortensen, and Levin 2016, see § 4.3.2). On the other hand,\nartiﬁcial tokens and encoder hidden states cannot be reduced to genealogical clusters.\nYet, their ability to predict missing values is not inferior to WALS features (as detailed\nin § 4.3.5). This implies that discrete and continuous representations appear to capture\ndifferent aspects of the cross-lingual variation, while being both informative. For this\nreason, they are possibly complementary and could be combined in the future.\n4.3.3 Supervised learning. As an alternative to unsupervised propagation, one can learn\nan explicit model for predicting feature values through supervised classiﬁcation. For\ninstance, Takamura, Nagata, and Kawasaki (2016) use logistic regression with WALS\nfeatures and evaluate this model in a cross-validation setting where one language is held\n18\nPonti et al.\nModeling Language Variation and Universals\nout in each fold. Wang and Eisner (2017) provide supervision to a feed-forward neural\nnetwork with windows of PoS tags from natural and synthetic corpora.\nSupervised learning of typology can also be guided by non typological information\n(see § 2). Within the Bayesian framework, Murawaki (2017) exploits not only typological\nbut also genealogical and areal dependencies among languages to represent each\nlanguage as a binary latent parameter vector through a series of autologistic models.\nCotterell and Eisner (2017, 2018) develop a point-process generative model of vowel\ninventories (represented as either IPA symbols or acoustic formants) based on some\nuniversal cognitive principles: dispersion (phonemes are as spread out as possible in the\nacoustic space) and focalization (some positions in the acoustic space are preferred due\nto the similarity of the main formants).\nAn alternative approach to supervised prediction of typology is based on learning\nimplicational universals of the kind pioneered by Greenberg (1963) with probabilistic\nmodels from existing typological databases. Using such universals, features can be\ndeduced by modus ponens. For instance, once it has been established that the presence\nof ‘High consonant/vowel ratio’ and ‘No front-rounded vowels’ implies ‘No tones’, the\nlatter feature value can be deduced from the premises if those are known. Daumé III\nand Campbell (2007) proposes a Bayesian model for learning typological universals that\npredicts features based on the intuition that their likelihood does not equal their prior\nprobability, but rather is constrained by other features. Lu (2013) cast this problem as\nknowledge discovery, where language features are encoded in a Directed Acyclic Graph.\nThe strength of implication universals is represented as weights associated with the\nedges of this graph.\n4.3.4 Heuristics based on Cross-Lingual Distributional Information. Typological fea-\ntures can also emerge in a data-driven fashion, based on distributional information from\nFigure 8: Wälchli and Cysouw (2012)’s cross-lingual sentence visualization for Mapun-\ngundun. In the top-right corner is the legend of the motion verbs taken into consideration.\nEach data point is an instance of a verb in a sentence, positioned according to its\ncontextualized sense. English glosses are the authors’ interpretations of the main clusters.\n19\nVolume xx, Number xx\nmulti-parallel texts. Wälchli and Cysouw (2012) create a matrix where each row is a\nparallel sentence, each column is a language, and cell values are lemmas of motion\nverbs occurring in those sentences. This matrix can be transformed to a (Hamming)\ndistance matrix between sentence pairs, and reduced to lower dimensionality via Multi-\nDimensional Scaling (MDS). This provides a continuous map of lexical semantics that is\nlanguage-speciﬁc, but motivated by categories that emerge across languages. For instance,\nFigure 8 shows the ﬁrst two dimensions of the MDS similarity matrix in Mapudungun,\nwhere the ﬁrst dimension can be interpreted as reﬂecting the direction of motion.\nAsgari and Schütze (2017) devised a procedure to obtain markers of grammatical\nfeatures across languages. Initially, they manually select a language containing an\nunambiguous and overt marker for a speciﬁc typological feature (called head pivot)\nbased on linguistic expertise. For instance, ti in Seychellois Creole (French Creole) is a\nhead pivot for past tense marking. Then, this marker is connected to equivalent markers\nin other languages through alignment-based χ2 test in a multi-parallel corpus and n-gram\ncounts.\nFinally, typological features can be derived from raw texts in a completely unsu-\npervised fashion, without multi-parallel texts. Roy et al. (2014) use heuristics to predict\nthe order of adpositions and nouns. Adpositions are identiﬁed as the most frequent\nwords. Afterwards, the position of the noun is established based on whether selectional\nrestrictions appear on the right context or the left context of the adposition, according to\ncount-based and entropy-based metrics.\n4.3.5 Comparison of the strategies. Establishing which of the above-mentioned strate-\ngies is optimal in terms of prediction accuracy is not straightforward. In Figure 9, we\ncollect the scores reported by several of the surveyed papers, provided that they concern\nspeciﬁc features or the whole WALS dataset (as opposed to subsets) and are numerical\n(as opposed to graphical plots). However, these results are not strictly comparable,\nsince language samples and/or the split of data partitions may differ. The lack of\nstandardization in this respect allows us to draw conclusions only about the difﬁculty of\npredicting each feature relative to a speciﬁc strategy: for instance, the correct value of\npassive voice is harder to predict than word order, as claimed by Bender et al. (2013) and\nwitnessed by Figure 9.\nHowever, some papers carry out comparisons of the different strategies within the\nsame experimental setting. According to Coke, King, and Radev (2016), propagation from\nthe genus majority value outperforms logistic regression among word-order typological\nfeatures. On the other hand, Georgi, Xia, and Lewis (2010) argue that typology-based\nclusters are to be preferred in general. This apparent contradiction stems from the nature\nof the target features: genealogy excels in word order features due to their diachronic\nstability. As they tend to be preserved over time, they are often shared by all members of\na family. In turn, majority value propagation is surpassed by supervised classiﬁcation\nwhen evaluated on the entire WALS feature set (Takamura, Nagata, and Kawasaki 2016).\nIn general, there appears to be no ‘one-size-ﬁts-all’ algorithm. For instance, Coke,\nKing, and Radev (2016) outperform Wang and Eisner (2017) for object–verb order (83A)\nbut are inferior to it for adposition–noun (85A). In fact, each strategy is suited for\ndifferent features, and requires different resources. Based on Figure 9, the extraction of\ninformation from morphosyntactic annotation is well suited for word order features,\nwhereas distributional heuristics from multi-parallel texts are more informative about\nlexicalization patterns. On the other hand, unsupervised propagation and supervised\nlearning are general-purpose strategies. Moreover, the ﬁrst two presuppose some\nannotated and/or parallel texts, whereas the second two need a pre-existing database\n20\nPonti et al.\nModeling Language Variation and Universals\n0\n25\n50\n75\n100\n107A33A 37A 38A 51A 69A 81A 82A 83A 85A 86A 87A 88A 89A 92A 98Awhole\nPaper\nBender 2013\nBjerva 2018\nCoke 2015\nGeorgi 2010\nLewis 2008\nLittel 2017\nMalaviya 2017\nMurawaki 2017\nOstling 2015\nTakamura 2015\nWang 2017\nFigure 9: Accuracy of different approaches (see legend on the right) in predicting missing\nvalues of WALS typological features (speciﬁed on the vertical axis).\ndocumentation. Strategies may be preferred according to which resources are available\nfor a speciﬁc language.\nMany strategies have a common weakness, however, as they postulate incorrectly\nthat language samples are independent and identically distributed (Lu 2013; Cotterell\nand Eisner 2017). This is not the case due to the interactions of family, area, and\nimplicational universals. The solutions adopted to mitigate this weakness vary: Wang and\nEisner (2017) balance the data distribution with synthetic examples, whereas Takamura,\nNagata, and Kawasaki (2016) model family and area interactions explicitly. However,\naccording to Murawaki (2017), these interactions have different degrees of impact on\ntypological features. In particular, inter-feature dependencies are more inﬂuential than\ninter-language dependencies, and horizontal diffusibility (borrowing from neighbours)\nis more prominent than vertical stability (inheriting from ancestors).\nFinally, a potential direction for future investigation emerges from this section’s\nsurvey. In addition to missing value completion, automatic prediction often also accounts\nfor the variation internal to each language. However, some strategies go even further, and\n“open the way for a typology where generalizations can be made without there being\nany need to reduce the attested diversity of categorization patterns to discrete types”\n(Wälchli and Cysouw 2012). In fact, language vectors (Malaviya, Neubig, and Littell\n2017; Bjerva and Augenstein 2018) and distributional information from multi-parallel\ntexts (Asgari and Schütze 2017) are promising insofar they capture latent properties\nof languages in a bottom-up fashion, preserving their gradient nature. This offers an\nalternative to hand-crafted database features: in § 6.3 we make a case for integrating\ncontinuous, data-driven typological representations into NLP algorithms.\n21\nVolume xx, Number xx\nAuthor\nDetails\nNumber of\nLanguages /\nFamilies\nTask\nRules\nBender (2016)\nGrammar generation\n12 / 8\nsemantic parsing\nFeature engineering\nNaseem, Barzilay,\nand Globerson (2012)\nGenerative\n17 / 10\nsyntactic parsing\nTäckström,\nMcDonald, and\nNivre (2013)\nDiscriminative\ngraph-based\n16 / 7\nsyntactic parsing\nZhang and Barzilay\n(2015)\nDiscriminative\ntensor-based\n10 / 4\nsyntactic parsing\nDaiber, Stanojevi´c,\nand Sima’an (2016)\nOne-to-many MLP\n22 / 5\nreordering for\nmachine translation\nAmmar et al. (2016)\nMulti-lingual\ntransition-based\n7 / 1\nsyntactic parsing\nTsvetkov et al. (2016)\nPhone-based\npolyglot language\nmodel\n9 / 4\nidentiﬁcation of\nlexical borrowings\nand speech synthesis\nSchone and Jurafsky\n(2001)\nDesign of Bayesian\nnetwork\n1 / 1\nword cluster labeling\nData Manipulation\nDeri and Knight\n(2016)\nTypology-based\nselection\n227\ngrapheme to\nphoneme\nAgi´c (2017)\nPoS divergence\nmetric\n26 / 5\nsyntactic parsing\nSøgaard and Wulff\n(2012)\nTypology-based\nweighing\n12 / 1\nsyntactic parsing\nWang and Eisner\n(2017)\nWord-order-based\ntree synthesis\n17 / 7\nsyntactic parsing\nPonti et al. (2018a)\nConstruction-based\ntree preprocessing\n6 / 3\nmachine translation,\nsentence similarity\nTable 3: An overview of the approaches to use typological features in NLP models.\n5. Uses of Typological Information in NLP Models\nThe typological features developed as discussed in § 4 are of signiﬁcant importance\nfor NLP algorithms. Particularly, they are employed in three main ways. First, they\ncan be manually converted into rules for expert systems (§5.1); second, they can be\nintegrated into algorithms as constraints that inject prior knowledge or tie together\nspeciﬁc parameters across languages (§ 5.2); and, ﬁnally, they can guide data selection\nand synthesis (§ 5.3). All of these approaches are summarized in Table 3 and described\nin detail in the following sections, with a particular focus on the second approach.\n5.1 Rule-based Systems\nAn interesting example of a rule-based system in our context is the Grammar Matrix\nkit, presented by Bender (2016), where rule-based grammars can be generated from\ntypological features. These grammars are designed within the framework of Minimal\nRecursion Semantics (Copestake et al. 2005) and can parse a natural language input\nstring into a semantic logical form.\nThe Grammar Matrix consists of a universal core grammar and language-speciﬁc\nlibraries for phenomena where typological variation is attested. For instance, the module\nfor coordination typology expects the speciﬁcation of the kind, pattern, and position\nof a grammatical marking, as well as the phrase types it covers. For instance, the Ono\nlanguage (Trans–New Guinea) expresses it with a lexical, monosyndetic, pre-nominal\n22\nPonti et al.\nModeling Language Variation and Universals\nmarker so in noun phrases. A collection of pre-deﬁned grammars is available through\nthe Language CoLLAGE initiative (Bender 2014).\n5.2 Feature Engineering and Constraints\nThe most common usage of typological features in NLP is in feature engineering and\nconstraint design for machine learning algorithms. Two popular approaches we consider\nhere are language transfer with selective sharing, where the parameters of languages with\nsimilar typological features are tied together (§ 5.2.1), and joint multilingual learning,\nwhere typological information is used in order to bias models to reﬂect the properties of\nspeciﬁc languages (see § 5.2.2).\n5.2.1 Selective sharing. This framework was introduced by Naseem, Barzilay, and\nGloberson (2012) and was subsequently adopted by Täckström, McDonald, and Nivre\n(2013) and Zhang and Barzilay (2015). It aims at parsing sentences in a language transfer\nsetting (see § 3.1) where there are multiple source languages and a single unobserved\ntarget language. It assumes that head–modiﬁer relations between part of speech pairs\nare universal, but the order of parts of speech within a sentence is language-speciﬁc.\nFor instance, adjectives always modify nouns, but in Igbo (Niger–Congo) they linearly\nprecede nouns, while in Nihali (isolate) they follow nouns. Leveraging this intuition,\nselective sharing models learn dependency relations from all source languages, while\nordering is learned from typologically related languages only.\nSelective sharing was originally implemented in a generative framework, factorizing\nthe recursive generation of dependency tree fragments into two steps (Naseem, Barzilay,\nand Globerson 2012). The ﬁrst one is universal: the algorithm selects an unordered\n(possibly empty) set of modiﬁers {M} given a head h with probability P({M}|h), where\nboth the head and the modiﬁers are characterized by their PoS tags. The second step is\nlanguage-speciﬁc: each dependent m is assigned a direction d (left or right) with respect\nto h based on the language l, with probability P(d|m, h, l). Dependents in the same\ndirection are eventually ordered with a probability drawn from a uniform distribution\nover their possible unique permutations. The total probability is then deﬁned as follows:\nP(n|h, θ1) · σn\n X\nmi∈M\nP(mi|h, θ2)\n!\n·\nY\nmi∈M\nσ (w · g(m, h, l, fl)) ·\n1\n||MR||||ML||\n(1)\nIn Equation 1, the ﬁrst step is expressed as two factors: the estimation of the number n of\nmodiﬁers, parametrized by θ1, and the actual selection of modiﬁers, parametrized by θ2,\nwith the softmax function σ converting the n values into probabilities. The second step,\noverseeing the assignment of a direction to the dependencies, is parametrized by w that\nmultiplies a feature function g(), whose arguments include a typology feature vector\nfl. The values of all the parameters are estimated by maximizing the likelihood of the\nobservations.\nTäckström, McDonald, and Nivre (2013) proposed a discriminative version of the\nmodel, in order to amend the alleged limitations of the original generative variant. In\nparticular, they dispose of the strong independence assumptions (e.g. between choice\nand ordering of modiﬁers) and invalid feature combinations. For instance, the WALS\nfeature ‘Order of subject, verb, and object’ (81A) should be taken into account only when\nthe head under consideration is a verb and the dependent is a noun, but in the generative\nmodel this feature was fed to g() regardless of the head–dependency pair. The method of\n23\nVolume xx, Number xx\nTäckström, McDonald, and Nivre (2013) is a delexicalized ﬁrst-order graph-based parser\nbased on a carefully selected feature set. From the set proposed by McDonald, Crammer,\nand Pereira (2005), they keep only (universal) features describing selectional preferences\nand dependency length. Moreover, they introduce (language-speciﬁc) features for the\ndirectionality of dependents, based on combinations of the PoS tags of the head and\nmodiﬁers with corresponding WALS values.\nThis approach was further extended to tensor-based models by Zhang and Barzilay\n(2015), in order to avoid the shortcomings of manual feature selection. They induce\na compact hidden representation of features and languages by factorizing a tensor\nconstructed from their combination. The prior knowledge from the typological database\nenables the model to forbid the invalid interactions, by generating intermediate feature\nembeddings in a hierarchical structure. In particular, given n words and l dependency\nrelations, each arc h →m is encoded as the tensor product of three feature vectors for\nheads Φh ∈Rn, modiﬁers Φm ∈Rn and the arcs Φh→m ∈Rl. A score is obtained through\nthe inner product of these and the corresponding r rank-1 dense parameter matrices for\nheads H ∈Rn×r, dependents M ∈Rn×r, and arcs M ∈Rl×r. The resulting embedding is\nsubsequently constrained through a summation with the typological features Tuφtu:\nS(h\nl−→m) =\nr\nX\ni=1\n[Hcφhc]i[Mcφmc]i ⊙\n{[Tlφtl]i + [Lφl]i ⊙\n([Tuφtu]i + [Hφh]i[Mφm]i[Dφd]i)}\n(2)\nEquation 2 shows how the overall score of a labeled dependency is enriched (by element-\nwise product) with (1) the features and parameters for arc labels Lφl constrained by\nthe typological vector Tlφtl; and (2) features and parameters for head contexts Hcφhc\nand dependent contexts Mcφmc. This loss is optimized within a maximum soft-margin\nobjective through on-line passive–aggressive updates.\nThe different approaches to selective sharing presented here explicitly deal with\ncases where the typological features do not match any of the source languages, which\nmay lead learning astray. Naseem, Barzilay, and Globerson (2012) propose a variant of\ntheir algorithm where the typological features are not observed (in WALS), treating\nthem as latent variables, and learning the model parameters in an unsupervised\nfashion with the Expectation Maximization algorithm (Dempster, Laird, and Rubin\n1977). Täckström, McDonald, and Nivre (2013) tackle the same problem from the side\nof ambiguous learning. The discriminative model on the target language is trained on\nsets of automatically predicted ambiguous labels by. Finally, Zhang and Barzilay (2015)\nemploy semi-supervised techniques, where only a handful of annotated examples from\nthe target language is available.\n5.2.2 Multi-lingual Biasing. Some papers leverage typological features to gear the shared\nparameters of a joint multilingual model toward the properties of a speciﬁc language.\nDaiber, Stanojevi´c, and Sima’an (2016) develop a reordering algorithm that estimates the\npermutation probabilities of aligned word pairs in multi-lingual parallel texts. The best\nsequence of permutations is inferred via k-best graph search in a ﬁnite state automaton,\nproducing a lattice. This algorithm, which receives lexical, morphological, and syntactic\nfeatures of the source word pairs and typological features of the target language as input,\nhas shown to beneﬁt a downstream machine translation task.\n24\nPonti et al.\nModeling Language Variation and Universals\nThe joint multilingual parser of Ammar et al. (2016) shares hidden-layer parameters\nacross languages, and combines both language-invariant and language-speciﬁc features\nin its copious lexicalized input feature set. This transition-based parser selects the next\naction z (e.g. SHIFT) from a pool of possible actions given its current state pt, as deﬁned\nin Equation 3:\nP(z|pt) = σ(gz\n⊤max(0, W st ⊕bt ⊕at ⊕lit + b) + qz)\n(3)\nP(z|pt) is deﬁned in terms of a set of iteratively manipulated, densely represented data\nstructures: a buffer bt, a stack st, and an action history at. The hidden representation\nof these modules are the output of stack-LSTMs, that are in turn fed with input\nword feature representations (stack and buffer) and action representations (history).\nThe shared parameters are biased toward a particular language through language\nembeddings lit. The language embeddings consist of (a non-linear transformation of)\neither a mere one-hot identity vector or a vector of typological properties taken from\nWALS. In particular, they are added to both input feature and action vectors, to affect the\nthree above-mentioned modules individually, and concatenated to the hidden module\nrepresentations, to affect the entire parser state. The resulting state representation is\npropagated through an action-speciﬁc layer parametrized by gt and qt, and activated by\na softmax function σ over actions.\nSimilarly, typological features have been employed to bias input and hidden states of\nlanguage models. For example, Tsvetkov et al. (2016) proposed a multilingual phoneme-\nlevel language model where an input phoneme x and a language vector ℓat time t are\nlinearly mapped to a local context representation and then passed to a global LSTM.\nThis hidden representation Gℓ\nt is factored by a non-linear transformation of typological\nfeatures tℓ, as shown in Equation 4:\nGℓ\nt = LSTM(Wcxxt + Wcℓxℓ+ b, gt−1) ⊗tanh(Wℓtℓ+ bℓ)⊤\n(4)\nP(φt|φ<t, ℓ) = σ(W vec(Gℓ\nt) + b)\n(5)\nAs described in Equation 5, Gℓ\nt is then vectorized and mapped to a probability distribu-\ntion of possible next phonemes φt. The phoneme vectors, learned by the language model\nin an end-to-end manner, were demonstrated to beneﬁt two downstream applications:\nlexical borrowing identiﬁcation and speech synthesis.\nMoreover, typological features (in the form of implicational universals) can guide\nthe design of Bayesian networks. Schone and Jurafsky (2001) assign part-of-speech labels\nto word clusters acquired in an unsupervised fashion. The underlying network is acyclic\nand directed, and is converted to a join-tree network to handle multiple parents (Jensen\n1996). For instance, the sub-graph for the ordering of numerals and nouns is intertwined\nalso with properties of adjectives and adpositions. The ﬁnal objective maximizes the\nprobability of a tag Ti and a feature set Φi given the implicational universals U as\nargmaxT P({Φi, Ti}n\ni=1|U).\n5.3 Data Selection, Synthesis, and Preprocessing\nAnother way in which typological features are used in NLP is to guide data selection.\nThis procedure is crucial for 1) language transfer methods, as it guides the choice of the\nmost suitable source languages and examples; and 2) multilingual joint models, in order\nto weigh the contribution of each language and example. The selection is typically carried\n25\nVolume xx, Number xx\nout through general language similarity metrics. For instance, Deri and Knight (2016) base\ntheir selection on the URIEL language typology database, considering information about\ngenealogical, geographic, syntactic, and phonetic properties. This facilitates language\ntransfer of grapheme-to-phoneme models, by guiding the choice of source languages\nand aligning phoneme inventories.\nMetrics for source selection can also be extracted in a data-driven fashion, without\nexplicit reference to structured taxonomies. For instance, Rosa and Zabokrtsky (2015)\nestimate the Kullback–Leibler divergence between part-of-speech trigram distributions\nfor delexicalized parser transfer. In order to approximate the divergence in syntactic\nstructures between languages, Ponti et al. (2018a) employ the Jaccard distance between\nmorphological feature sets and the tree edit distance of delexicalized dependency parses\nof similar sentences.\nA-priori and bottom-up approaches can also be combined. For delexicalized parser\ntransfer, Agi´c (2017) relies on a weighted sum of distances based on 1) the PoS divergence\ndeﬁned by Rosa and Zabokrtsky (2015); 2) the character-based identity prediction of\nthe target language; and 3) the Hamming distance from the target language typological\nvector. In fact, they have different weaknesses: language identity (and consequently\ntypology) fail to abstract away from language scripts. On the other hand, the accuracy of\nPoS-based metrics deteriorates easily in scenarios with poor amounts of data.\nSource language selection is a special case of source language weighting where\nweights are one-hot vectors. However, weights can also be gradient and consist of real\nnumbers. Søgaard and Wulff (2012) adapt delexicalized parsers by weighting every\ntraining instance based on the inverse of the Hamming distance between typological\n(or genealogical) features in source and target languages. An equivalent bottom-up\napproach is developed by Søgaard (2011) who weighs source language sentences based\non the perplexity between their coarse PoS tags and the predictions of a sequential model\ntrained on the target language.\nAlternatively, the lack of target annotated data can be alleviated by synthesizing new\nexamples, thus boosting the variety and amount of the source data. For instance, the\nGalactic Dependency Treebanks stem from real trees whose nodes have been permuted\nprobabilistically according to the word order rules for nouns and verbs in other languages\n(Wang and Eisner 2016). Synthetic trees improve the performance of model transfer\nfor parsing when the source is chosen in a supervised way (performance on target\ndevelopment data) and in an unsupervised way (coverage of target PoS sequences).\nRather than generating new synthetic data, Ponti et al. (2018a) leverage typological\nfeatures to pre-process treebanks in order to reduce their variation in language transfer\ntasks. In particular, they adapt source trees to the typology of a target language with\nrespect to several constructions in a rule-based fashion. For instance, relative clauses in\nArabic (Afro–Asiatic) with an indeﬁnite antecedent drop the relative pronoun, which\nis mandatory in Portuguese (Indo–European). Hence, the pronoun has to be added,\nor deleted in the other direction. Feeding pre-processed syntactic trees to lexicalized\nsyntax-based neural models, such as feature-based recurrent encoders (Sennrich and\nHaddow 2016) or TreeLSTMs (Tai, Socher, and Manning 2015), achieves state-of-the-art\nresults in Neural Machine Translation and cross-lingual sentence similarity classiﬁcation.\n5.4 Comparison\nIn light of the performance of the above methods, to what extent can typological features\nbeneﬁt downstream NLP tasks and applications? To answer this key question, consider\nthe performance scores of each model reported in Figure 10. Each model has been\n26\nPonti et al.\nModeling Language Variation and Universals\nUAS\nUAS\nUAS\nBLEU\nMAE\nUAS\nPPL\nWER\nUAS\nUAS\nUAS\nBLEU\nF1\nAgic 2017\nAmmar 2016\nBerzak 2016\nDaiber 2016\nDeri 2016\nNaseem 2012\nPonti 2018 (NMT)\nPonti 2018 (STS)\nSogaard 2012\nTackstrom 2013\nTsvetkov 2016\nWang 2016\nZhang 2015\n0\n25\n50\n75\n100\nFeature\nBaseline\nData−driven\nGenealogy\nLanguage Identity\nTypology\nFigure 10: Performance of the surveyed algorithms for the tasks detailed in Table\n3. The algorithms are evaluated with different feature sets: no typological features\n(Baseline), latently inferred typology (Data-driven), Genealogy, Language Identity, and\ngold database features (Typology). Evaluation metrics are reported right of the bars:\nUnlabeled Attachment Score (UAS), Perplexity (PPL), F1 Score, BiLingual Evaluation\nUnderstudy (BLEU), Word Error Rate (WER), and Mean Absolute Error (MAE).\nevaluated in the original paper in one (or more) of the three main settings: with gold\ndatabase features (Typology), with latently inferred typological features (Data-driven), or\nwithout both (Baseline), and with otherwise identical architecture and hyper-parameters.\nIt is evident that typology-enriched models consistently outperform baselines across\nseveral NLP tasks. Indeed, the scores are higher for metrics that increase (Unlabeled\nAttachment Score, F1 Score and BLEU) and lower for metrics that decrease (Word\nError Rate, Mean Average Error and Perplexity) with better predictions. Nevertheless,\nimprovements tend to be moderate, and only a small number of experiments support\n27\nVolume xx, Number xx\nthem with statistical signiﬁcance tests. In general, it appears that they fall short of the\npotential usefulness of typology: in § 6 we analyse the possible reasons for this.\nSome of the experiments we have surveyed investigate the effect of substituting\ntypological features with features related to Genealogy and Language Identity (e.g.\none-hot encoding of languages). Based on the results in Figure 10, it is unclear whether\ntypology should be preferred, as it is sometimes rivaled by other types of features.\nIn particular, it is typology that excels according to Tsvetkov et al. (2016), genealogy\naccording to Søgaard and Wulff (2012) and Täckström, McDonald, and Nivre (2013), and\nlanguage identity according to Ammar et al. (2016). However, drawing conclusions from\nthe last experiment seems incautious: in § 4.2, we argued that their selection of features\n(presented in Figure 5) is debatable due to low diversiﬁcation or noise. Moreover, it\nshould be emphasized that one-hot language encoding is limited to the joint multilingual\nlearning setting: since it does not convey any information, it is of no avail in language\ntransfer.\nFinally, let us consider the effectiveness of the above methods with respect to\nincorporating typological features in NLP models. In case of selective sharing, the tensor-\nbased discriminative model (Zhang and Barzilay 2015) outperforms the graph-based\ndiscriminative model (Täckström, McDonald, and Nivre 2013), which in turn surpasses\nthe generative model (Naseem, Barzilay, and Globerson 2012). With regard to biasing\nmultilingual models, there is a clear tendency toward letting typological features interact\nnot merely with the input representation, but also with deeper levels of abstraction such\nas hidden layers.\nOverall, this comparison supports the claim that typology can potentially aid in\ndesigning the architecture of algorithms, engineering their features, and selecting and\npre-processing their data. Nonetheless, this discussion also revealed that many challenges\nlie ahead for each of these goals to be accomplished fully. We discuss them in the next\nsection.\n6. Future Research Avenues\nIn § 5 we surveyed the current uses of typological information in NLP. In this section we\ndiscuss potential future research avenues that may result in a closer and more effective\nintegration of linguistic typology and multilingual NLP. In particular, we discuss: 1) the\nextension of existing methods to new tasks, possibly exploiting typological resources that\nhave been neglected thus far (§ 6.1); 2) new methods for injecting typological information\ninto NLP models as soft constraints or auxiliary objectives (§ 6.2); and 3) new ways to\nacquire and represent typological information that reﬂect the gradient and contextual\nnature of cross-lingual variation (§ 6.3).\n6.1 Extending the Usage to New Tasks and Features\nThe trends observed in § 5 reveal that typology is integrated into NLP models mostly in\nthe context of morphosyntactic tasks, and particularly syntactic parsing. Some exceptions\ninclude other levels of linguistic structure, such as phonology (Tsvetkov et al. 2016; Deri\nand Knight 2016) and semantics (Bender 2016; Ponti et al. 2018a). As a consequence, the\nset of selected typological features is mostly limited to a handful of word-order features\nfrom a single database, WALS. Nonetheless, the array of tasks that pertain to polyglot\nNLP is broad, and other typological datasets that have thus far been neglected may be\nrelevant for them.\n28\nPonti et al.\nModeling Language Variation and Universals\nFor example, typological frame semantics might beneﬁt semantic role labeling, as\nit speciﬁes the valency patterns of predicates across languages, including the number\nof arguments, their morphological markers, and their order. This information can be\ncast in the form of priors for unsupervised syntax-based Bayesian models (Titov and\nKlementiev 2012), guidance for alignments in annotation projection (Padó and Lapata\n2009; Van der Plas, Merlo, and Henderson 2011), or regularizers for model transfer in\norder to tailor the source model to the grammar of the target language (Kozhevnikov\nand Titov 2013). Cross-lingual information about frame semantics can be extracted, for\nexample, from the Valency Patterns Leipzig database (ValPaL).\nTypological information regarding lexical semantics patterns can further assist\nvarious NLP tasks, by providing information about translationally equivalent words\nacross languages. Such information is provided in databases such as the World Loanword\nDatabase (WOLD), the Intercontinental Dictionary Series (IDS), and the Automated\nSimilarity Judgment Program (ASJP). One example task is word sense disambiguation,\nas senses can be propagated from multilingual word graphs (Silberer and Ponzetto 2010)\nby bootstrapping from a few pivot pairs (Khapra et al. 2011), by imposing constraints in\nsentence alignments and harvesting bag-of-words features from these (Lefever, Hoste,\nand De Cock 2011), or by providing seeds for multilingual WE-based lexicalized model\ntransfer (Zennaki, Semmar, and Besacier 2016).\nAnother task where lexical semantics is crucial is sentiment analysis, for similar\nreasons: bilingual lexicons constrain word alignments for annotation projection (Almeida\net al. 2015) and provide pivots for shared multilingual representations in model transfer\n(Fernández, Esuli, and Sebastiani 2015; Ziser and Reichart 2018). Moreover, sentiment\nanalysis can leverage morphosyntactic typological information about constructions that\nalter polarity, such as negation (Ponti, Vuli´c, and Korhonen 2017).\nFinally, morphological information was shown to aid interpreting the intrinsic\ndifﬁculty of texts for language modeling and neural machine translation, both in\nsupervised (Johnson et al. 2017) and in unsupervised (Artetxe et al. 2018) setups. In\nfact, the degree of fusion between roots and inﬂectional/derivative morphemes impacts\nthe type/token ratio of texts, and consequently their rate of infrequent words. Moreover,\nthe ambiguity of mapping between form and meaning of morphemes determines the\nusefulness of injecting character-level information (Gerz et al. 2018a,b). This variation\nhas to be taken into account in both language transfer and multilingual joint learning.\nAs a ﬁnal note, we stress that the addition of new features does not concern just\nfuture work, but also the existing typology-savvy methods, which can widen their\nscope. For instance, the parsing experiments grounded on selective sharing (§ 5.2) could\nalso take into consideration WALS features about Nominal Categories, Nominal Syntax,\nVerbal Categories, Simple Clauses, and Complex Sentences, as well as features from other\ndatabases such as SSWL, APiCS, and AUTOTYP. Likewise, models for phonological tasks\n(Tsvetkov et al. 2016; Deri and Knight 2016) could also extract features from typological\ndatabases such as LAPSyD and StressTyp2.\n6.2 Injecting Typological Information into Machine Learning Algorithms\nIn § 5, we discussed the potential of typological information to provide guidance to NLP\nmethods, and surveyed approaches such as network design in Bayesian models (Schone\nand Jurafsky 2001), selective sharing (Naseem, Barzilay, and Globerson 2012, inter alia),\nand biasing of multilingual joint models (Ammar et al. 2016, inter alia). However, many\nother frameworks (including those already mentioned in § 3) have been developed\nindependently in order to allow the integration of expert and domain knowledge into\n29\nVolume xx, Number xx\ntraditional feature-based machine learning algorithms and neural networks. In this\nsection we survey these frameworks and discuss their applicability to the integration of\ntypological information into NLP models.\nEncoding cross-language variation and preferences into a machine learning model\nrequires a mechanism that can bias the learning (i.e. training and parameter estimation)\nand inference (prediction) of the model towards some pre-deﬁned knowledge. In prac-\ntice, learning algorithms, both linear (e.g. structured perceptron (Collins 2002), MIRA\n(Crammer and Singer 2003) and structured SVM (Taskar, Guestrin, and Koller 2004))\nand non-linear (deep neural models) iterate between an inference step and a step of\nparameter update with respect to a gold standard. The inference step is the natural place\nwhere external knowledge could be encoded through constraints. This step biases the\nprediction of the model to agree with the external knowledge which, in turn, affects both\nthe training process and the ﬁnal prediction of the model at test time.\nInformation about cross-lingual variation, particularly when extracted empirically\n(see § 4), reﬂects tendencies rather than strict rules. As a consequence, soft, rather than\nhard constraints are a natural vehicle for their encoding. We next survey a number of\nexisting approaches that can efﬁciently encode such constraints.\nThe goal of an inference algorithm is to predict the best output label according to\nthe current state of the model parameters.8 For this purpose, the algorithm searches the\nspace of possible output labels in order to ﬁnd the best one. Efﬁciency hence plays a\nkey role in these algorithms. Introducing soft constraints into an inference algorithm,\ntherefore, posits an algorithmic challenge: how can the output of the model be biased to\nagree with the constraints while the efﬁciency of the search procedure is kept? In this\npaper we do not answer this question directly but rather survey a number of approaches\nthat succeed in dealing with it.\nSince linear models have been prominent in NLP research for a much longer time,\nit is not surprising that frameworks for the integration of soft constraints into these\nmodels are much more developed. The approaches proposed for this purpose include\nposterior regularization (PR) (Ganchev et al. 2010), generalized expectation (GE) (Mann\nand McCallum 2008), constraint-driven learning (CODL) (Chang, Ratinov, and Roth\n2007), dual decomposition (DD) (Globerson and Jaakkola 2007; Komodakis, Paragios, and\nTziritas 2011) and Bayesian modeling (Cohen 2016). These techniques employ different\ntypes of knowledge encoding, e.g. PR uses expectation constraints on the posterior\nparameter distribution, GE prefers parameter settings where the model’s distribution\non unsupervised data matches a predeﬁned target distribution, CODL enriches existing\nstatistical models with Integer Linear Programming (ILP) constraints, while in Bayesian\nmodeling a prior distribution is deﬁned on the model parameters.\nPR has already been used for incorporating universal linguistic knowledge into an\nunsupervised parsing model (Naseem et al. 2010). In the future, it could be extended\nto typological knowledge, which is a good ﬁt for soft constraints. As another option,\nBayesian modeling sets prior probability distributions according to the relationships\nencoded in typological features (Schone and Jurafsky 2001). Finally, DD has been applied\nto multi-task learning, which paves the way for typological knowledge encoding through\na multi-task architecture in which one of the tasks is the actual NLP application and\nthe other is the data-driven prediction of typological features. In fact a modiﬁcation of\n8 Generally speaking, an inference algorithm can make other predictions such as computing expectations\nand marginal probabilities. As in the context of this paper we are mostly focused on the prediction of the\nbest output label, we refer only to this type of inference problems.\n30\nPonti et al.\nModeling Language Variation and Universals\nthis archiecture has already been applied to minimally supervised learning and domain\nadaptation with soft (non-typological) constraints (Rush et al. 2012; Reichart and Barzilay\n2012).\nThe same ideas could be exploited in deep learning algorithms. We have seen in § 3.2\nthat multilingual joint models combine both shared and language-dependent parameters,\nin order to capture the universal properties and cross-lingual differences, respectively. In\norder to enforce this division of roles more efﬁciently, these models could be augmented\nwith the auxiliary task of predicting typological features automatically. This auxiliary\nobjective could update parameters of the language-speciﬁc component, or those of\nthe shared component, in an adversarial fashion, similarly to what Chen et al. (2018)\nimplemented by predicting language identity.\nRecently, Hu et al. (2016a,b) and Wang and Poon (2018) proposed frameworks\nthat integrate deep neural models with manually speciﬁed or automatically induced\nconstraints. Similarly to CoDL, the focus in Hu et al. (2016a) and Wang and Poon (2018) is\non logical rules, while the ideas in Hu et al. (2016b) are related to PR. These frameworks\nprovide a promising avenue for the integration of typological information and deep\nmodels.\nA particular non-linear deep learning domain where knowledge integration is\nalready prominent is multilingual representation learning (§ 3.3). In this domain a\nnumber of works (Faruqui et al. 2015; Rothe and Schütze 2015; Osborne, Narayan, and\nCohen 2016; Mrkši´c et al. 2016) have proposed means through which external knowledge\nsourced from linguistic resources (such as WordNet, BabelNet, or lists of morphemes)\ncan be encoded in word embeddings. Among the state-of-the-art specialization methods\nATTRACT-REPEL (Mrkši´c et al. 2017; Vuli´c et al. 2017) pushes together or pulls apart vector\npairs according to relational constraints, while preserving the relationship between words\nin the original space and possibly propagating the specialization knowledge to unseen\nwords or transferring it to other languages (Ponti et al. 2018b). The success of these\nworks suggests that a more extensive integration of external linguistic knowledge in\ngeneral, and typological knowledge in particular, is likely to play a key role in the future\ndevelopment of word representations.\n6.3 A New Typology: Gradience and Context-Sensitivity\nAs shown in § 4.2, most of the typology-savvy algorithms thus far exploited features\nextracted from manually crafted databases. However, this approach is riddled by several\nshortcomings, which are reﬂected in the small performance improvements observed in\n§ 5.4. Luckily, these shortcomings may potentially be averted through the use of methods\nthat allow typological information to emerge from the data in a bottom-up fashion, rather\nthan being predetermined. In what follows we advocate for such a data-driven approach,\nbased on several considerations.\nFirstly, typological databases provide incomplete documentation of the cross-lingual\nvariation, in terms of features and languages. Raw textual data, which is easily accessible\nfor many languages and cost-effective, may provide a valid alternative that can facilitate\nautomatic learning of more complete knowledge. Secondly, database information is\napproximate, as it is restricted to the majority strategy within a language. However,\nin theory each language allows for multiple strategies in different contexts and with\ndifferent frequencies, hence databases risk hindering models from learning less likely\nbut plausible patterns (Sproat 2016). Inferring typological information from text would\nenable a system to discover patterns within individual examples, including both the\nfrequent and the infrequent ones. Thirdly, typological features in databases are discrete,\n31\nVolume xx, Number xx\nemploying predeﬁned categories devised to make high-level generalizations across\nlanguages. However, several categories in natural language are gradient (see for instance\nthe discussion on semantic categorization in § 2), hence they are better captured by\ncontinuous features. In addition to being psychologically motivated, this sort of gradient\nrepresentation is also more compatible with machine learning algorithms and particularly\nwith deep neural models that naturally operate with real-valued multi-dimensional word\nembeddings and hidden states.\nTo sum up, the automatic development of typological information and its possible\nintegration into machine learning algorithms have the potential to solve an important\nbottleneck in polyglot NLP. Current manually curated databases consist of incomplete,\napproximate, and discrete features that are intended to reﬂect contextual and gradient\ninformation implicitly present in text. These features are fed to continuous, probabilistic,\nand contextual machine learning models — which do not form a natural ﬁt for the\ntypological features. Instead, we believe that modeling cross-lingual variation directly\nfrom textual data can yield typological information that is more suitable for machine\nlearning.\nSeveral techniques surveyed in § 4.3 are suited to serve this purpose. In particular,\nthe extraction from morphosyntactic annotation (Liu 2010, inter alia) and alignments\nfrom multi-parallel texts (Asgari and Schütze 2017, inter alia) provide information\nabout typological constructions at the level of individual examples. Moreover, language\nvectors (Malaviya, Neubig, and Littell 2017; Bjerva and Augenstein 2018) and alignments\nfrom multi-parallel texts preserve the gradient nature of typology through continuous\nrepresentations.\nThe successful integration of these components would affect the way multilingual\nfeature engineering is performed. As opposed to using binary vectors of typological\nfeatures, the information about language-internal variation could be encoded as real-\nvalued vectors where each dimension is a possible strategy for a given construction\nand its relative frequency within a language. As an alternative, selective sharing and\nmultilingual biasing could be performed at the level of individual examples rather\nthan languages as a whole. In particular, model parameters could be transferred among\nsimilar examples and input/hidden representations could be conditioned on contextual\ntypological patterns. Finally, focusing on the various instantiations of a particular type\nrather than considering languages as indissoluble blocks would enhance data selection,\nsimilarly to what Søgaard (2011) achieved using PoS n-grams for similarity measurement.\nThe selection of similar sentences rather than similar languages as source data in language\ntransfer is likely to yield large improvements, as demonstrated by Agi´c (2017) for parsing\nin an oracle setting.\nFinally, the bottom-up development of typological features may address also\nradically resource-less languages that lack even raw textual data in a digital format.\nFor this group, which still constitutes a large portion of the world’s languages, there\nare often available reference grammars written by ﬁeld linguists, which are the ultimate\nsource for typological databases. These grammars could be queried automatically, and\nﬁne-grained typological information could be harvested through information extraction\ntechniques.\n7. Conclusions\nIn this article, we surveyed a wide range of approaches integrating typological informa-\ntion, derived from the empirical and systematic comparison of the world’s languages,\nand NLP algorithms. The most fundamental problem for the advancement of this line of\n32\nPonti et al.\nModeling Language Variation and Universals\nresearch is bridging the gap between the interpretable, language-wide, and discrete\nfeatures of linguistic typology found in database documentation, and the opaque,\ncontextual, and probabilistic models of NLP. We addressed this problem by exploring\na series of questions: i) for which tasks and applications is typology useful? ii) Which\nare the advantages and limitations of currently available typological databases? Can\ndata-driven inference of typological features offer an alternative source of information?\niii) Which methods allow us to inject typological information from external resources,\nand how should such information be encoded? iv) By which margin do typology-savvy\nmethods surpass typology-agnostic baselines? How does typology compare to other\ncriteria of language classiﬁcation, such as genealogy? v) In addition to augmenting\nmachine learning algorithms, which other purposes do typology serve for NLP? We\nsummarize our key ﬁndings below:\n1.\nTypological information is currently used predominantly for morphosyn-\ntactic tasks, in particular dependency parsing. As a consequence, these\napproaches typically select a limited subset of features from a single dataset\n(WALS) and focus on a single aspect of variation (typically word order).\nHowever, typological databases also cover other important features, related\nto predicate–argument structure (ValPaL), phonology (LAPSyD, PHOIBLE,\nStressTyp2) and lexical semantics (IDS, ASJP), which are currently largely\nneglected by the multilingual NLP community. In fact, these features have\nthe potential to beneﬁt many tasks addressed by language transfer or joint\nmultilingual learning techniques, such as semantic role labeling, word sense\ndisambiguation, or sentiment analysis.\n2.\nTypological databases tend to be incomplete, containing missing values\nfor individual languages or features. This hinders the integration of the\ninformation in such databases into NLP models; and therefore, several tech-\nniques have been developed to predict missing values automatically. They\ninclude heuristics derived from morphosyntactic annotation; propagation\nfrom other languages based on hierarchical clusters or similarity metrics;\nsupervised models; and distributional methods applied to multi-parallel\ntexts. However, none of these techniques surpasses the others across the\nboard in prediction accuracy, as each excels in different feature types. A\nchallenge left for future work is creating ensembles of techniques to offset\ntheir individual disadvantages.\n3.\nThe most widespread approach to exploit typological features in NLP\nalgorithms is “selective sharing” for language transfer. Its intuition is that a\nmodel should learn universal properties from all examples, but language-\nspeciﬁc information only from examples with similar typological properties.\nAnother successful approach is gearing multilingual joint models towards\nspeciﬁc languages by concatenating typological features in input, or condi-\ntioning hidden layers and global sequence representations on them. New\napproaches could be inspired by traditional techniques for encoding external\nknowledge into machine learning algorithms through soft constraints on the\ninference step, semi-supervised prototype-driven methods, specialization of\nsemantic spaces, or auxiliary objectives in a multi-task learning setting.\n4.\nThe integration of typological features into NLP models yields consistent\n(even if often moderate) improvements over baselines lacking such features.\n33\nVolume xx, Number xx\nMoreover, guidance from typology should be preferred to features related\nto genealogy or other language properties. Models enriched with the latter\nfeatures occasionally perform equally well due to their correlation with\ntypological features, but fall short when it comes to modeling diversiﬁed\nlanguage samples or ﬁne-grained differences among languages.\n5.\nIn addition to feature engineering, typological information has served\nseveral other purposes. Firstly, it allows experts to deﬁne rule-based models,\nor to assign priors and independence assumptions in Bayesian graphical\nmodels. Secondly, it facilitates data selection and weighting, at the level\nof both languages and individual examples. Annotated data can be also\nsynthesized or preprocessed according to typological criteria, in order to\nincrease their coverage of phenomena or availability for further languages.\nThirdly, typology enables researchers to interpret and reasonably foresee the\ndifference in performance of algorithms across the sampled languages.\nFinally, we advocated for a new approach to linguistic typology inspired by the most\nrecent trends in the discipline and aimed at averting some fundamental limitations of the\ncurrent approach. In fact, typological database documentation is incomplete, approxi-\nmate, and discrete. As a consequence, it does not ﬁt well with the gradient and contextual\nmodels of machine learning. However, typological databases are originally created from\nraw linguistic data. An alternative approach could involve learning typology from such\ndata automatically (i.e. from scratch). This would capture the variation within languages\nat the level of individual examples, and to naturally encode typological information into\ncontinuous representations. These goals have already been partly achieved by methods\ninvolving language vectors, heuristics derived from morphosyntactic annotation, or\ndistributional information from multi-parallel texts. The main future challenge is the\nintegration of these methods into machine learning models, as opposed to sourcing\ntypological features from databases.\nIn general, we demonstrated that typology is relevant to a wide range of NLP tasks\nand provides the most effective and principled way to carry out language transfer\nand multilingual joint learning. We hope that the research described in this survey will\nprovide a platform for deeper integration of typological information and NLP techniques,\nthus furthering the advancement of multilingual NLP.\nAcknowledgments\nThis work is supported by ERC Consolidator Grant LEXICAL (no 648909).\nReferences\nAdel, Heike, Ngoc Thang Vu, and Tanja\nSchultz. 2013. Combination of recurrent\nneural networks and factored language\nmodels for code-switching language\nmodeling. In Proceedings of ACL, pages\n206–211.\nAgi´c, Željko. 2017. Cross-lingual parser\nselection for low-resource languages. In\nProceedings of the NoDaLiDa 2017 Workshop\non Universal Dependencies (UDW 2017),\npages 1–10.\nAgi´c, Željko, Dirk Hovy, and Anders Søgaard.\n2015. If all you have is a bit of the Bible:\nLearning POS taggers for truly\nlow-resource languages. In The 53rd Annual\nMeeting of the Association for Computational\nLinguistics and the 7th International Joint\nConference of the Asian Federation of Natural\nLanguage Processing (ACL - IJCNLP 2015),\npages 268–272.\nAgi´c, Željko, Anders Johannsen, Barbara\nPlank, Héctor Alonso Martínez, Natalie\nSchluter, and Anders Søgaard. 2016.\nMultilingual projection for parsing truly\n34\nPonti et al.\nModeling Language Variation and Universals\nlow-resource languages. Transactions of the\nAssociation for Computational Linguistics,\n4:301.\nAgi´c, Željko, Jörg Tiedemann, Kaja\nDobrovoljc, Simon Krek, Danijela Merkler,\nand Sara Može. 2014. Cross-lingual\ndependency parsing of related languages\nwith rich morphosyntactic tagsets. In\nProceedings of the EMNLP 2014 Workshop on\nLanguage Technology for Closely Related\nLanguages and Language Variants, pages\n13–24.\nAlmeida, Mariana SC, Cláudia Pinto, Helena\nFigueira, Pedro Mendes, and André FT\nMartins. 2015. Aligning opinions:\nCross-lingual opinion mining with\ndependencies. In Proceedings of the 53rd\nAnnual Meeting of the Association for\nComputational Linguistics and the 7th\nInternational Joint Conference on Natural\nLanguage Processing, pages 408–418.\nAmmar, Waleed, George Mulcaire, Miguel\nBallesteros, Chris Dyer, and Noah A Smith.\n2016. Many languages, one parser. TACL.\nArtetxe, Mikel, Gorka Labaka, Eneko Agirre,\nand Kyunghyun Cho. 2018. Unsupervised\nneural machine translation. In Proceedings\nof the Sixth International Conference on\nLearning Representations, pages 1–12.\nAsgari, Ehsaneddin and Hinrich Schütze.\n2017. Past, present, future: A\ncomputational investigation of the\ntypology of tense in 1000 languages. In\nProceedings of the 2017 Conference on\nEmpirical Methods in Natural Language\nProcessing, pages 113–124.\nBakker, Dik. 2010. Language sampling. In\nJJ Song, editor, The Oxford handbook of\nlinguistic typology. Oxford University Press,\npages 100–127.\nBanea, Carmen, Rada Mihalcea, Janyce Wiebe,\nand Samer Hassan. 2008. Multilingual\nsubjectivity analysis using machine\ntranslation. In Proceedings of the Conference\non Empirical Methods in Natural Language\nProcessing, pages 127–135.\nBender, Emily M. 2009. Linguistically naïve !=\nlanguage independent: why NLP needs\nlinguistic typology. In Proceedings of the\nEACL 2009 Workshop on the Interaction\nbetween Linguistics and Computational\nLinguistics: Virtuous, Vicious or Vacuous?,\npages 26–32.\nBender, Emily M. 2011. On achieving and\nevaluating language-independence in NLP.\nLinguistic Issues in Language Technology,\n3(6):1–26.\nBender, Emily M. 2014. Language collage:\nGrammatical description with the lingo\ngrammar matrix. In LREC, pages\n2447–2451.\nBender, Emily M. 2016. Linguistic typology in\nnatural language processing. Linguistic\nTypology, 20(3):645–660.\nBender, Emily M., Michael Wayne Goodman,\nJoshua Crowgey, and Fei Xia. 2013.\nTowards creating precision grammars from\ninterlinear glossed text: Inferring\nlarge-scale typological properties. In\nLaTeCH 2013, pages 74–83.\nBerlin, Brent and Paul Kay. 1969. Basic color\nterms: Their universality and evolution.\nCalifornia University Press.\nBerzak, Yevgeni, Roi Reichart, and Boris Katz.\n2014. Reconstructing native language\ntypology from foreign language usage. In\nCoNLL, pages 21–29.\nBerzak, Yevgeni, Roi Reichart, and Boris Katz.\n2015. Contrastive analysis with predictive\npower: Typology driven estimation of\ngrammatical error distributions in ESL. In\nCoNLL, pages 94–102.\nBickel, Balthasar. 2007. Typology in the 21st\ncentury: Major current developments.\nLinguistic Typology, 11(1):239–251.\nBickel, Balthasar. 2015. Distributional\ntypology: statistical inquiries into the\ndynamics of linguistic diversity. Oxford\nhandbook of linguistic analysis, pages\n901–923.\nBickel, Balthasar, Johanna Nichols, Taras\nZakharko, Alena Witzlack-Makarevich,\nKristine Hildebrandt, Michael Rießler,\nLennart Bierkandt, Fernando Zúˆniga, and\nJohn Lowe. 2017. The AUTOTYP\ntypological databases. version 0.1.0.\nTechnical report.\nBjerva, Johannes and Isabelle Augenstein.\n2018. From phonology to syntax:\nUnsupervised linguistic typology at\ndifferent levels with language embeddings.\nIn Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for\nComputational Linguistics: Human Language\nTechnologies, Volume 1 (Long Papers),\nvolume 1, pages 907–916.\nBowerman, Melissa and Soonja Choi. 2001.\nShaping meanings for language: universal\nand language-speciﬁc in the acquisition of\nsemantic categories. In Language acquisition\nand conceptual development. Cambridge\nUniversity Press, pages 475–511.\nBybee, Joan and James L McClelland. 2005.\nAlternatives to the combinatorial paradigm\nof linguistic theory based on domain\ngeneral principles of human cognition. The\nlinguistic review, 22(2-4):381–410.\n35\nVolume xx, Number xx\nBybee, Joan L. 1988. The diachronic\ndimension in explanation. In JA Hawkins,\neditor, Explaining language universals. Basil\nBlackwell, pages 350–379.\nChandar, Sarath, Stanislas Lauly, Hugo\nLarochelle, Mitesh Khapra, Balaraman\nRavindran, Vikas C Raykar, and Amrita\nSaha. 2014. An autoencoder approach to\nlearning bilingual word representations. In\nAdvances in Neural Information Processing\nSystems, pages 1853–1861.\nChang, Ming-Wei, Lev Ratinov, and Dan Roth.\n2007. Guiding semi-supervision with\nconstraint-driven learning. In ACL, pages\n280–287.\nChen, Xilun, Yu Sun, Ben Athiwaratkun,\nClaire Cardie, and Kilian Weinberger. 2018.\nAdversarial deep averaging networks for\ncross-lingual sentiment classiﬁcation.\nTransactions of the Association for\nComputational Linguistics, 6:557–570.\nCohen, Shay B. 2016. Bayesian Analysis in\nNatural Language Processing. Synthesis\nLectures on Human Language\nTechnologies. Morgan and Claypool.\nCoke, Reed, Ben King, and Dragomir R.\nRadev. 2016. Classifying syntactic\nregularities for hundreds of languages.\nCoRR, abs/1603.08016.\nCollins, Chris and Richard Kayne. 2009.\nSyntactic structures of the world’s\nlanguages. http:\n//sswl.railsplayground.net/.\nCollins, Michael. 2002. Discriminative\ntraining methods for hidden markov\nmodels: Theory and experiments with\nperceptron algorithms. In EMNLP, pages\n1–8.\nComrie, Bernard. 1989. Language universals\nand linguistic typology: Syntax and\nmorphology. University of Chicago Press.\nConneau, Alexis, Guillaume Lample,\nMarc’Aurelio Ranzato, Ludovic Denoyer,\nand Hervé Jégou. 2017. Word translation\nwithout parallel data. arXiv preprint\narXiv:1710.04087.\nConneau, Alexis, Ruty Rinott, Guillaume\nLample, Adina Williams, Samuel Bowman,\nHolger Schwenk, and Veselin Stoyanov.\n2018. XNLI: Evaluating cross-lingual\nsentence representations. In Proceedings of\nthe 2018 Conference on Empirical Methods in\nNatural Language Processing, pages\n2475–2485.\nCopestake, Ann, Dan Flickinger, Carl Pollard,\nand Ivan A Sag. 2005. Minimal recursion\nsemantics: An introduction. Research on\nlanguage and computation, 3(2-3):281–332.\nCorbett, Greville G. 2010. Implicational\nhierarchies. In JJ Song, editor, The Oxford\nhandbook of linguistic typology. Oxford\nUniversity Press, pages 190–205.\nCotterell, Ryan and Jason Eisner. 2017.\nProbabilistic typology: Deep generative\nmodels of vowel inventories. In Proceedings\nof the 55th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long\nPapers), volume 1, pages 1182–1192.\nCotterell, Ryan and Jason Eisner. 2018. A deep\ngenerative model of vowel formant\ntypology. In Proceedings of the 2018\nConference of the North American Chapter of\nthe Association for Computational Linguistics:\nHuman Language Technologies, Volume 1\n(Long Papers), volume 1, pages 37–46.\nCrammer, Koby and Yoram Singer. 2003.\nUltraconservative online algorithms for\nmulticlass problems. Journal of Machine\nLearning Research, 3:951–991.\nCristofaro, S and P Ramat. 1999. Introduzione\nalla tipologia linguistica. Carocci.\nCroft, William. 1995. Autonomy and\nfunctionalist linguistics. Language, pages\n490–532.\nCroft, William. 2000. Explaining language\nchange: An evolutionary approach. Pearson\nEducation.\nCroft, William. 2003. Typology and universals.\nCambridge University Press.\nCroft, William, Dawn Nordquist, Katherine\nLooney, and Michael Regan. 2017.\nLinguistic typology meets universal\ndependencies. In Proceedings of the 15th\nInternational Workshop on Treebanks and\nLinguistic Theories (TLT15), pages 63–75.\nCroft, William and Keith T Poole. 2008.\nInferring universals from grammatical\nvariation: Multidimensional scaling for\ntypological analysis. Theoretical linguistics,\n34(1):1–37.\nDaiber, Joachim, Miloš Stanojevi´c, and Khalil\nSima’an. 2016. Universal reordering via\nlinguistic typology. In Proceedings of\nCOLING 2016, the 26th International\nConference on Computational Linguistics:\nTechnical Papers, pages 3167–3176.\nd’Andrade, Roy G. 1995. The development of\ncognitive anthropology. Cambridge\nUniversity Press.\nDas, Dipanjan and Slav Petrov. 2011.\nUnsupervised part-of-speech tagging with\nbilingual graph-based projections. In ACL,\npages 600–609.\nDaumé III, Hal and Lyle Campbell. 2007. A\nBayesian model for discovering typological\nimplications. In ACL, pages 65–72.\n36\nPonti et al.\nModeling Language Variation and Universals\nDempster, Arthur P, Nan M Laird, and\nDonald B Rubin. 1977. Maximum\nlikelihood from incomplete data via the em\nalgorithm. Journal of the royal statistical\nsociety. Series B (methodological), pages 1–38.\nDeri, Aliya and Kevin Knight. 2016.\nGrapheme-to-phoneme models for (almost)\nany language. In ACL, pages 399–408.\nDixon, Robert MW. 1977. Where have all the\nadjectives gone? Studies in Language.\nInternational Journal sponsored by the\nFoundation “Foundations of Language”,\n1(1):19–80.\nDixon, Robert MW. 1994. Ergativity.\nCambridge University Press.\nDryer, Matthew S. 1998. Why statistical\nuniversals are better than absolute\nuniversals. In Papers from the 33rd Regional\nMeeting of the Chicago Linguistic Society,\npages 1–23.\nDryer, Matthew S. and Martin Haspelmath,\neditors. 2013. WALS Online. Max Planck\nInstitute for Evolutionary Anthropology.\nDuong, Long, Trevor Cohn, Steven Bird, and\nPaul Cook. 2015a. Low resource\ndependency parsing: Cross-lingual\nparameter sharing in a neural network\nparser. In Proceedings of the 53rd Annual\nMeeting of the Association for Computational\nLinguistics and the 7th International Joint\nConference on Natural Language Processing,\nvolume 2, pages 845–850.\nDuong, Long, Trevor Cohn, Steven Bird, and\nPaul Cook. 2015b. A neural network model\nfor low-resource universal dependency\nparsing. In Proceedings of the 2015\nConference on Empirical Methods in Natural\nLanguage Processing, pages 339–348.\nDuong, Long, Hiroshi Kanayama, Tengfei Ma,\nSteven Bird, and Trevor Cohn. 2016.\nLearning crosslingual word embeddings\nwithout bilingual corpora. In Proceedings of\nthe 2016 Conference on Empirical Methods in\nNatural Language Processing, pages\n1285–1295.\nDurham, William H. 1991. Coevolution: Genes,\nculture, and human diversity. Stanford\nUniversity Press.\nDurrett, Greg, Adam Pauls, and Dan Klein.\n2012. Syntactic transfer using a bilingual\nlexicon. In Proceedings of the 2012 Joint\nConference on Empirical Methods in Natural\nLanguage Processing and Computational\nNatural Language Learning, pages 1–11.\nEvans, Nicholas. 2011. Semantic typology. In\nThe Oxford Handbook of Linguistic Typology.\nOxford University Press, pages 504–533.\nEvans, Nicholas and Stephen C Levinson.\n2009. The myth of language universals:\nLanguage diversity and its importance for\ncognitive science. Behavioral and brain\nsciences, 32(5):429–448.\nFang, Meng and Trevor Cohn. 2017. Model\ntransfer for tagging low-resource languages\nusing a bilingual dictionary. In Proceedings\nof the 55th Annual Meeting of the Association\nfor Computational Linguistics (Volume 2:\nShort Papers), volume 2, pages 587–593.\nFaruqui, Manaal, Jesse Dodge, Sujay Kumar\nJauhar, Chris Dyer, Eduard Hovy, and\nNoah A. Smith. 2015. Retroﬁtting word\nvectors to semantic lexicons. In\nNAACL-HLT, pages 1606–1615.\nFernández, Alejandro Moreo, Andrea Esuli,\nand Fabrizio Sebastiani. 2015.\nDistributional correspondence indexing for\ncross-lingual and cross-domain sentiment\nclassiﬁcation. Journal of Artiﬁcial Intelligence\nResearch, 55:131–163.\nGanchev, Kuzman, Jennifer Gillenwater, Ben\nTaskar, et al. 2010. Posterior regularization\nfor structured latent variable models.\nJournal of Machine Learning Research,\n11:2001–2049.\nGeorgi, Ryan, Fei Xia, and William Lewis.\n2010. Comparing language similarity\nacross genetic and typologically-based\ngroupings. In COLING, pages 385–393.\nGerz, Daniela, Edoardo Maria Ponti, Jason\nNaradowsky, Roi Reichart, Anna Korhonen,\nand Ivan Vuli´c. 2018a. Language modeling\nfor morphologically rich languages:\nCharacter-aware modeling for word-level\nprediction. Transactions of the Association of\nComputational Linguistics, pages 451–466.\nGerz, Daniela, Ivan Vuli´c, Edoardo Maria\nPonti, Roi Reichart, and Anna Korhonen.\n2018b. On the relation between linguistic\ntypology and (limitations of) multilingual\nlanguage modeling. In Proceedings of the\n2018 Conference on Empirical Methods in\nNatural Language Processing, pages 316–327.\nGloberson, Amir and Tommi S Jaakkola. 2007.\nFixing max-product: Convergent message\npassing algorithms for MAP LP-relaxations.\nIn NIPS, pages 553–560.\nGoedemans, Rob, Jeffrey Heinz, and\nHarry Van der Hulst, editors. 2014.\nStresstyp2. University of Connecticut,\nUniversity of Delaware, Leiden University,\nand the U.S. National Science Foundation.\nGouws, Stephan, Yoshua Bengio, and Greg\nCorrado. 2015. Bilbowa: Fast bilingual\ndistributed representations without word\nalignments. In International Conference on\nMachine Learning, pages 748–756.\nGouws, Stephan and Anders Søgaard. 2015.\nSimple task-speciﬁc bilingual word\n37\nVolume xx, Number xx\nembeddings. In NAACL-HLT, pages\n1386–1390.\nGreenberg, Joseph H. 1963. Some universals\nof grammar with particular reference to the\norder of meaningful elements. Universals of\nLanguage, 2:73–113.\nGreenberg, Joseph H. 1966a. Synchronic and\ndiachronic universals in phonology.\nLanguage, 42(2):508–517.\nGreenberg, Joseph H. 1966b. Universals of\nlanguage. MIT Press.\nGreenberg, Joseph H. 1978. Diachrony,\nsynchrony and language universals. In\nJoseph H. Greenberg, Charles A. Ferguson,\nand Edith A. Moravcsik, editors, Universals\nof Human Language, Vol. 1: Method and\nTheory. Stanford University Press, pages\n61–92.\nGuo, Jiang, Wanxiang Che, Haifeng Wang,\nand Ting Liu. 2016. A universal framework\nfor inductive transfer parsing across\nmulti-typed treebanks. In Proceedings of\nCOLING 2016, the 26th International\nConference on Computational Linguistics:\nTechnical Papers, pages 12–22.\nGuo, Jiang, Wanxiang Che, David Yarowsky,\nHaifeng Wang, and Ting Liu. 2015.\nCross-lingual dependency parsing based\non distributed representations. In\nProceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and\nthe 7th International Joint Conference on\nNatural Language Processing, volume 1,\npages 1234–1244.\nHa, Thanh-Le, Jan Niehues, and Alexander\nWaibel. 2016. Toward multilingual neural\nmachine translation with universal encoder\nand decoder. In Proceedings of the 2016\nInternational Workshop on Spoken Language\nTranslation (IWSLT).\nHammarström, Harald, Robert Forkel, Martin\nHaspelmath, and Sebastian Bank, editors.\n2016. Glottolog 2.7. Max Planck Institute for\nthe Science of Human History, Jena.\nHartmann, Iren, Martin Haspelmath, and\nBradley Taylor, editors. 2013. Valency\nPatterns Leipzig. Max Planck Institute for\nEvolutionary Anthropology, Leipzig.\nHaspelmath, Martin. 1999. Optimality and\ndiachronic adaptation. Zeitschrift für\nSprachwissenschaft, 18(2):180–205.\nHaspelmath, Martin. 2007. Pre-established\ncategories don’t exist: Consequences for\nlanguage description and typology.\nLinguistic typology, 11(1):119–132.\nHaspelmath, Martin and Uri Tadmor, editors.\n2009. WOLD. Max Planck Institute for\nEvolutionary Anthropology, Leipzig.\nHermann, Karl Moritz and Phil Blunsom.\n2014. Multilingual distributed\nrepresentations without word alignment.\nIn Proceedings of ICLR.\nHu, Zhiting, Xuezhe Ma, Zhengzhong Liu,\nEduard Hovy, and Eric Xing. 2016a.\nHarnessing deep neural networks with\nlogic rules. In Proceedings of the 54th Annual\nMeeting of the Association for Computational\nLinguistics (Volume 1: Long Papers),\nvolume 1, pages 2410–2420.\nHu, Zhiting, Zichao Yang, Ruslan\nSalakhutdinov, and Eric Xing. 2016b. Deep\nneural networks with massive learned\nknowledge. In Proceedings of the 2016\nConference on Empirical Methods in Natural\nLanguage Processing, pages 1670–1679.\nHwa, Rebecca, Philip Resnik, Amy Weinberg,\nClara I. Cabezas, and Okan Kolak. 2005.\nBootstrapping parsers via syntactic\nprojection across parallel texts. Natural\nLanguage Engineering, 11(3):311–325.\nJensen, Finn V. 1996. An introduction to\nBayesian networks, volume 210. UCL press\nLondon.\nJohnson, Melvin, Mike Schuster, Quoc V Le,\nMaxim Krikun, Yonghui Wu, Zhifeng Chen,\nNikhil Thorat, Fernanda Viégas, Martin\nWattenberg, Greg Corrado, et al. 2017.\nGoogle’s multilingual neural machine\ntranslation system: Enabling zero-shot\ntranslation. Transactions of the Association of\nComputational Linguistics, 5(1):339–351.\nKey, Mary Ritchie and Bernard Comrie,\neditors. 2015. IDS. Max Planck Institute for\nEvolutionary Anthropology, Leipzig.\nKhapra, Mitesh M., Salil Joshi, Arindam\nChatterjee, and Pushpak Bhattacharyya.\n2011. Together we can: Bilingual\nbootstrapping for WSD. In ACL, pages\n561–569.\nKlementiev, Alexandre, Ivan Titov, and Binod\nBhattarai. 2012. Inducing crosslingual\ndistributed representations of words. In\nCOLING, pages 1459–1474.\nKomodakis, Nikos, Nikos Paragios, and\nGeorgios Tziritas. 2011. MRF energy\nminimization and beyond via dual\ndecomposition. IEEE Transactions on Pattern\nAnalysis and Machine Intelligence,\n33(3):531–552.\nKozhevnikov, Mikhail and Ivan Titov. 2013.\nCross-lingual transfer of semantic role\nlabeling models. In Proceedings of the 51st\nAnnual Meeting of the Association for\nComputational Linguistics, pages 1190–1200.\nLauly, Stanislas, Alex Boulanger, and Hugo\nLarochelle. 2013. Learning multilingual\nword representations using a bag-of-words\n38\nPonti et al.\nModeling Language Variation and Universals\nautoencoder. In Deep Learning Workshop at\nNIPS.\nLefever, Els, Véronique Hoste, and Martine\nDe Cock. 2011. Parasense or how to use\nparallel corpora for word sense\ndisambiguation. In Proceedings of the 49th\nAnnual Meeting of the Association for\nComputational Linguistics, volume 2, pages\n317–322.\nLewis, M Paul, Gary F Simons, and Charles D\nFennig. 2016. Ethnologue: Languages of the\nworld, 19th edition. SIL international.\nLewis, William D and Fei Xia. 2008.\nAutomatically identifying computationally\nrelevant typological features. In IJCNLP,\npages 685–690.\nLittel, Patrick, David R. Mortensen, and Lori\nLevin. 2016. URIEL Typological database.\nPittsburgh: CMU.\nLiu, Haitao. 2010. Dependency direction as a\nmeans of word-order typology: A method\nbased on dependency treebanks. Lingua,\n120(6):1567–1578.\nLu, Xia. 2013. Exploring word order\nuniversals: a probabilistic graphical model\napproach. In Proceedings of ACL (Student\nResearch Workshop), pages 150–157.\nLuong, Thang, Hieu Pham, and\nChristopher D Manning. 2015. Bilingual\nword representations with monolingual\nquality in mind. In Proceedings of the 1st\nWorkshop on Vector Space Modeling for\nNatural Language Processing, pages 151–159.\nMaddieson, Ian, Sébastien Flavier, Egidio\nMarsico, Christophe Coupé, and François\nPellegrino. 2013. LAPSyd:\nLyon-Albuquerque phonological systems\ndatabase. In INTERSPEECH, pages\n3022–3026.\nMajid, Asifa, Melissa Bowerman, Miriam van\nStaden, and James S Boster. 2007. The\nsemantic categories of cutting and breaking\nevents: A crosslinguistic perspective.\nCognitive Linguistics, 18(2):133–152.\nMalaviya, Chaitanya, Graham Neubig, and\nPatrick Littell. 2017. Learning language\nrepresentations for typology prediction. In\nProceedings of the 2017 Conference on\nEmpirical Methods in Natural Language\nProcessing, pages 2529–2535.\nMann, Gideon S. and Andrew McCallum.\n2008. Generalized expectation criteria for\nsemi-supervised learning of conditional\nrandom ﬁelds. In ACL, pages 870–878.\nMcDonald, Ryan, Koby Crammer, and\nFernando Pereira. 2005. Online\nlarge-margin training of dependency\nparsers. In Proceedings of the 43rd annual\nmeeting on association for computational\nlinguistics, pages 91–98.\nMichaelis, Susanne Maria, Philippe Maurer,\nMartin Haspelmath, and Magnus Huber,\neditors. 2013. Atlas of Pidgin and Creole\nLanguage Structures Online. Max Planck\nInstitute for Evolutionary Anthropology.\nMikolov, Tomas, Quoc V Le, and Ilya\nSutskever. 2013. Exploiting similarities\namong languages for machine translation.\narXiv preprint arXiv:1309.4168.\nMoran, Steven, Daniel McCloy, and Richard\nWright, editors. 2014. PHOIBLE Online.\nMax Planck Institute for Evolutionary\nAnthropology, Leipzig.\nMrkši´c, Nikola, Ivan Vuli´c, Diarmuid Ó\nSéaghdha, Ira Leviant, Roi Reichart, Milica\nGaši´c, Anna Korhonen, and Steve Young.\n2017. Semantic specialization of\ndistributional word vector spaces using\nmonolingual and cross-lingual constraints.\nTransactions of the Association of\nComputational Linguistics, 5(1):309–324.\nMrkši´c, Nikola, Diarmuid Ó Séaghdha, Blaise\nThomson, Milica Gaši´c, Lina\nRojas-Barahona, Pei-Hao Su, David\nVandyke, Tsung-Hsien Wen, and Steve\nYoung. 2016. Counter-ﬁtting word vectors\nto linguistic constraints. In NAACL-HLT,\npages 142–148.\nMurawaki, Yugo. 2017. Diachrony-aware\ninduction of binary latent representations\nfrom typological features. In Proceedings of\nthe Eighth International Joint Conference on\nNatural Language Processing (Volume 1: Long\nPapers), volume 1, pages 451–461.\nNaseem, Tahira, Regina Barzilay, and Amir\nGloberson. 2012. Selective sharing for\nmultilingual dependency parsing. In ACL,\npages 629–637.\nNaseem, Tahira, Harr Chen, Regina Barzilay,\nand Mark Johnson. 2010. Using universal\nlinguistic knowledge to guide grammar\ninduction. In Proceedings of EMNLP 2010,\npages 1234–1244.\nNichols, Johanna. 1992. Language diversity in\nspace and time. University of Chicago Press.\nNiehues, Jan, Teresa Herrmann, Stephan\nVogel, and Alex Waibel. 2011. Wider\ncontext by using bilingual language models\nin machine translation. In Proceedings of the\nSixth Workshop on Statistical Machine\nTranslation, pages 198–206.\nNivre, Joakim, Marie-Catherine de Marneffe,\nFilip Ginter, Yoav Goldberg, Jan Hajic,\nChristopher D. Manning, Ryan McDonald,\nSlav Petrov, Sampo Pyysalo, Natalia\nSilveira, Reut Tsarfaty, and Daniel Zeman.\n2016. Universal dependencies v1: A\nmultilingual treebank collection. In LREC,\n39\nVolume xx, Number xx\npages 1659–1666.\nO’Horan, Helen, Yevgeni Berzak, Ivan Vuli´c,\nRoi Reichart, and Anna Korhonen. 2016.\nSurvey on the use of typological\ninformation in natural language processing.\nProceedings of COLING 2016, the 26th\nInternational Conference on Computational\nLinguistics: Technical Papers, pages\n1297–1308.\nOsborne, D., S. Narayan, and S. B. Cohen.\n2016. Encoding prior knowledge with\neigenword embeddings. Transactions of the\nACL, pages 417–430.\nÖstling, Robert. 2015. Word order typology\nthrough multilingual word alignment. In\nACL, pages 205–211.\nÖstling, Robert and Jörg Tiedemann. 2017.\nContinuous multilinguality with language\nvectors. In Proceedings of the 15th Conference\nof the European Chapter of the Association for\nComputational Linguistics: Volume 2, Short\nPapers, volume 2, pages 644–649.\nPadó, Sebastian and Mirella Lapata. 2005.\nCross-linguistic projection of role-semantic\ninformation. In EMNLP, pages 859–866.\nPadó, Sebastian and Mirella Lapata. 2009.\nCross-lingual annotation projection for\nsemantic roles. Journal of Artiﬁcial\nIntelligence Research, 36(1):307–340.\nPappas, Nikolaos and Andrei Popescu-Belis.\n2017. Multilingual hierarchical attention\nnetworks for document classiﬁcation. In\n8th International Joint Conference on Natural\nLanguage Processing (IJCNLP),\nEPFL-CONF-231134, pages 1015–1025.\nPlank, Frans and Elena Filiminova. 1996.\nUniversals archive.\nhttp://www.ling.unikonstanz.de/\npages/proj/sprachbau.htm.\nUniversität Konstanz.\nVan der Plas, Lonneke, Paola Merlo, and\nJames Henderson. 2011. Scaling up\nautomatic cross-lingual semantic role\nannotation. In Proceedings of the 49th Annual\nMeeting of the Association for Computational\nLinguistics, volume 2, pages 299–304.\nPonti, Edoardo Maria, Roi Reichart, Anna\nKorhonen, and Ivan Vuli´c. 2018a.\nIsomorphic transfer of syntactic structures\nin cross-lingual nlp. In Proceedings of the\n56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long\nPapers), volume 1, pages 1531–1542.\nPonti, Edoardo Maria, Ivan Vuli´c, Goran\nGlavaš, Nikola Mrkši´c, and Anna\nKorhonen. 2018b. Adversarial propagation\nand zero-shot cross-lingual transfer of\nword vector specialization. In Proceedings of\nthe 2018 Conference on Empirical Methods in\nNatural Language Processing, pages 282–293.\nPonti, Edoardo Maria, Ivan Vuli´c, and Anna\nKorhonen. 2017. Decoding sentiment from\ndistributed representations of sentences. In\nProceedings of the 6th Joint Conference on\nLexical and Computational Semantics (* SEM\n2017), pages 22–32.\nReichart, Roi and Regina Barzilay. 2012. Multi\nevent extraction guided by global\nconstraints. In NAACL, pages 70–79.\nRosa, Rudolf and Zdenek Zabokrtsky. 2015.\nKLcpos3 - a language similarity measure\nfor delexicalized parser transfer. In ACL,\npages 243–249.\nRothe, Sascha and Hinrich Schütze. 2015.\nAutoExtend: Extending word embeddings\nto embeddings for synsets and lexemes. In\nACL, pages 1793–1803.\nRotman, Guy, Ivan Vuli´c, and Roi Reichart.\n2018. Bridging languages through images\nwith deep partial canonical correlation\nanalysis. In Proceedings of ACL 2018, pages\n910–921.\nRoy, Rishiraj Saha, Rahul Katare, Niloy\nGanguly, and Monojit Choudhury. 2014.\nAutomatic discovery of adposition\ntypology. In Proceedings of COLING, pages\n1037–1046.\nRuder, Sebastian. 2018. A survey of\ncross-lingual embedding models. Journal of\nArtiﬁcial Intelligence Research.\nRush, Alexander M., Roi Reichart, Michael\nCollins, and Amir Globerson. 2012.\nImproved parsing and POS tagging using\ninter-sentence consistency constraints. In\nEMNLP-CoNLL, pages 1434–1444.\nSapir, Edward. 2014 [1921]. Language.\nCambridge University Press.\nSchone, Patrick and Daniel Jurafsky. 2001.\nLanguage-independent induction of part of\nspeech class labels using only language\nuniversals. In IJCAI-2001 Workshop \"Text\nLearning: Beyond Supervision\".\nSennrich, Rico and Barry Haddow. 2016.\nLinguistic input features improve neural\nmachine translation. In Proceedings of the\nFirst Conference on Machine Translation,\nvolume 1, pages 83–91.\nSilberer, Carina and Simone Paolo Ponzetto.\n2010. UHD: Cross-lingual word sense\ndisambiguation using multilingual\nco-occurrence graphs. In Proceedings of the\n5th International Workshop on Semantic\nEvaluation, pages 134–137.\nSnyder, Ben. 2010. Unsupervised Multilingual\nLearning. PhD thesis. MIT.\nSnyder, Benjamin and Regina Barzilay. 2008.\nUnsupervised multilingual learning for\nmorphological segmentation. In\n40\nPonti et al.\nModeling Language Variation and Universals\nProceedings of ACL-08: HLT, pages 737–745.\nSøgaard, Anders. 2011. Data point selection\nfor cross-language adaptation of\ndependency parsers. In ACL, pages\n682–686.\nSøgaard, Anders and Julie Wulff. 2012. An\nempirical study of non-lexical extensions to\ndelexicalized transfer. Proceedings of\nCOLING 2012: Posters, pages 1181–1190.\nSproat, Richard. 2016. Language typology in\nspeech and language technology. Linguistic\nTypology, 20(3):635–644.\nTäckström, Oscar, Ryan McDonald, and\nJoakim Nivre. 2013. Target language\nadaptation of discriminative transfer\nparsers. In NAACL-HLT, pages 1061–1071.\nTäckström, Oscar, Ryan McDonald, and Jakob\nUszkoreit. 2012. Cross-lingual word\nclusters for direct transfer of linguistic\nstructure. In NAACL-HLT, pages 477–487.\nTai, Kai Sheng, Richard Socher, and\nChristopher D Manning. 2015. Improved\nsemantic representations from\ntree-structured long short-term memory\nnetworks. In Proceedings of the 53rd Annual\nMeeting of the Association for Computational\nLinguistics and the 7th International Joint\nConference on Natural Language Processing\n(Volume 1: Long Papers), volume 1, pages\n1556–1566.\nTakamura, Hiroya, Ryo Nagata, and\nYoshifumi Kawasaki. 2016. Discriminative\nanalysis of linguistic features for\ntypological study. In LREC, pages 69–76.\nTalmy, Leonard. 1991. Path to realization: A\ntypology of event conﬂation. In Proceedings\nof the Seventeenth Annual Meeting of the\nBerkeley Linguistics Society: General Session\nand Parasession on The Grammar of Event\nStructure, pages 480–519.\nTaskar, Ben, Carlos Guestrin, and Daphne\nKoller. 2004. Max-margin Markov\nnetworks. In NIPS, pages 25–32.\nTeh, Yee Whye, Hal Daumé III, and Daniel M\nRoy. 2007. Bayesian agglomerative\nclustering with coalescents. In Proceedings\nof NIPS, pages 1473–1480.\nTiedemann, Jörg. 2015. Cross-lingual\ndependency parsing with universal\ndependencies and predicted pos labels.\nProceedings of the Third International\nConference on Dependency Linguistics\n(Depling 2015), pages 340–349.\nTitov, Ivan and Alexandre Klementiev. 2012.\nCrosslingual induction of semantic roles.\nIn Proceedings of the 50th Annual Meeting of\nthe Association for Computational Linguistics:\nLong Papers-Volume 1, pages 647–656.\nTsvetkov, Yulia, Sunayana Sitaram, Manaal\nFaruqui, Guillaume Lample, Patrick Littell,\nDavid Mortensen, Alan W. Black, Lori\nLevin, and Chris Dyer. 2016. Polyglot\nneural language models: A case study in\ncross-lingual phonetic representation\nlearning. In NAACL, pages 1357–1366.\nUpadhyay, Shyam, Manaal Faruqui, Chris\nDyer, and Dan Roth. 2016. Cross-lingual\nmodels of word embeddings: An empirical\ncomparison. In Proceedings of the 54th\nAnnual Meeting of the Association for\nComputational Linguistics (Volume 1: Long\nPapers), volume 1, pages 1661–1670.\nVuli´c, Ivan, Wim De Smet, and\nMarie-Francine Moens. 2011. Identifying\nword translations from comparable corpora\nusing latent topic models. In Proceedings of\nthe 49th Annual Meeting of the Association for\nComputational Linguistics: Human Language\nTechnologies: short papers-Volume 2, pages\n479–484.\nVuli´c, Ivan and Marie-Francine Moens. 2015.\nBilingual word embeddings from\nnon-parallel document-aligned data\napplied to bilingual lexicon induction. In\nProceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and\nthe 7th International Joint Conference on\nNatural Language Processing (Volume 2: Short\nPapers), volume 2, pages 719–725.\nVuli´c, Ivan, Nikola Mrkši´c, Roi Reichart,\nDiarmuid Ó Séaghdha, Steve Young, and\nAnna Korhonen. 2017. Morph-ﬁtting:\nFine-tuning word vector spaces with\nsimple language-speciﬁc rules. In\nProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics\n(Volume 1: Long Papers), volume 1, pages\n56–68.\nWälchli, Bernhard and Michael Cysouw. 2012.\nLexical typology through similarity\nsemantics: Toward a semantic map of\nmotion verbs. Linguistics, 50(3):671–710.\nWang, Dingquan and Jason Eisner. 2016. The\ngalactic dependencies treebanks: Getting\nmore data by synthesizing new languages.\nTransactions of the Association for\nComputational Linguistics, 4:491–505.\nWang, Dingquan and Jason Eisner. 2017.\nFine-grained prediction of syntactic\ntypology: Discovering latent structure with\nsupervised learning. Transactions of the\nAssociation for Computational Linguistics\n(TACL), 5:147–162.\nWang, Hai and Hoifung Poon. 2018. Deep\nprobabilistic logic: A unifying framework\nfor indirect supervision. In Proceedings of\nthe 2018 Conference on Empirical Methods in\n41\nVolume xx, Number xx\nNatural Language Processing.\nWang, Mengqiu and Christopher D Manning.\n2014. Cross-lingual pseudo-projected\nexpectation regularization for weakly\nsupervised learning. Transactions of the\nAssociation for Computational Linguistics,\n2:55–66.\nWichmann, Søren, Eric W. Holman, and\nCecil H. Brown, editors. 2016. The ASJP\nDatabase (version 17). Max Planck Institute\nfor Evolutionary Anthropology, Leipzig.\nWisniewski, Guillaume, Nicolas Pécheux,\nSouhir Gahbiche-Braham, and François\nYvon. 2014. Cross-lingual part-of-speech\ntagging through ambiguous learning. In\nEMNLP, pages 1779–1785.\nXiao, Min and Yuhong Guo. 2014. Distributed\nword representation learning for\ncross-lingual dependency parsing. In\nProceedings of CoNLL, pages 119–129.\nYang, Zhilin, Ruslan Salakhutdinov, and\nWilliam Cohen. 2016. Multi-task\ncross-lingual sequence tagging from\nscratch. arXiv preprint arXiv:1603.06270.\nYarowsky, David, Grace Ngai, and Richard\nWicentowski. 2001. Inducing multilingual\ntext analysis tools via robust projection\nacross aligned corpora. In Proceedings of the\nﬁrst international conference on Human\nlanguage technology research, pages 1–8.\nZeman, Daniel and Philip Resnik. 2008.\nCross-language parser adaptation between\nrelated languages. In Proceedings of IJCNLP,\npages 35–42.\nZennaki, Othman, Nasredine Semmar, and\nLaurent Besacier. 2016. Inducing\nmultilingual text analysis tools using\nbidirectional recurrent neural networks. In\nProceedings of COLING 2016, the 26th\nInternational Conference on Computational\nLinguistics: Technical Papers, pages 450–460.\nZhang, Yuan and Regina Barzilay. 2015.\nHierarchical low-rank tensors for\nmultilingual transfer parsing. In EMNLP,\npages 1857–1867.\nZhang, Yuan, David Gaddy, Regina Barzilay,\nand Tommi Jaakkola. 2016. Ten pairs to tag\n– multilingual POS tagging via coarse\nmapping between embeddings. In NAACL,\npages 1307–1317.\nZhang, Yuan, Roi Reichart, Regina Barzilay,\nand Amir Globerson. 2012. Learning to\nmap into a universal POS tagset. In\nEMNLP, pages 1368–1378.\nZhou, Guangyou, Tingting He, Jun Zhao, and\nWensheng Wu. 2015. A subspace learning\nframework for cross-lingual sentiment\nclassiﬁcation with partial parallel data. In\nProceedings of the Twenty-Fourth International\nJoint Conference on Artiﬁcial Intelligence\n(IJCAI 2015), pages 1426–1432.\nZhou, Xinjie, Xianjun Wan, and Jianguo Xiao.\n2016. Cross-lingual sentiment classiﬁcation\nwith bilingual document representation\nlearning. In Proceedings of the 54th Annual\nMeeting of the Association for Computational\nLinguistics, pages 1403–1412.\nZiser, Yftah and Roi Reichart. 2018. Deep\npivot-based modeling for cross-language\ncross-domain transfer with minimal\nguidance. In Proceedings of the 2018\nConference on Empirical Methods in Natural\nLanguage Processing, pages 238–249.\n42\n43\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2018-07-02",
  "updated": "2020-10-26"
}