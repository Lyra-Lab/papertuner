{
  "id": "http://arxiv.org/abs/1807.09844v2",
  "title": "Modular Mechanistic Networks: On Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing",
  "authors": [
    "Simon Dobnik",
    "John D. Kelleher"
  ],
  "abstract": "Natural language processing (NLP) can be done using either top-down (theory\ndriven) and bottom-up (data driven) approaches, which we call mechanistic and\nphenomenological respectively. The approaches are frequently considered to\nstand in opposition to each other. Examining some recent approaches in deep\nlearning we argue that deep neural networks incorporate both perspectives and,\nfurthermore, that leveraging this aspect of deep learning may help in solving\ncomplex problems within language technology, such as modelling language and\nperception in the domain of spatial cognition.",
  "text": "Modular Mechanistic Networks: On Bridging\nMechanistic and Phenomenological Models with\nDeep Neural Networks in Natural Language\nProcessing\nSimon Dobnik\nCLASP and FLOV\nUniversity of Gotenburg, Sweden\nsimon.dobnik@gu.se\nJohn D. Kelleher\nADAPT Centre for Digital Content Technology\nDublin Institute of Technology, Ireland\njohn.d.kelleher@dit.ie\nAbstract\nNatural language processing (NLP) can be done using either top-down\n(theory driven) and bottom-up (data driven) approaches, which we call mech-\nanistic and phenomenological respectively. The approaches are frequently\nconsidered to stand in opposition to each other. Examining some recent ap-\nproaches in deep learning we argue that deep neural networks incorporate\nboth perspectives and, furthermore, that leveraging this aspect of deep learn-\ning may help in solving complex problems within language technology, such\nas modelling language and perception in the domain of spatial cognition.\n1\nIntroduction\nThere are two distinct methodologies to build computational models of language\nor of world in general. The ﬁrst approach can be characterised as qualitative, sym-\nbolic and driven by domain theory (we will call this a top-down or mechanistic\napproach), whereas the second approach may be characterised as quantitative, nu-\nmeric and driven by data and computational learning theory (we will call this the\nbottom-up or phenomenological approach). In this context we are borrowing the\nterminology of phenomenological model from the literature on the Philosophy of\nScience where the term phenomenological model is sometimes used to describe\nmodels that are independent of theory (see for example [45]), but more generally is\nused to describe models that focus on the observable properties (phenomena) of a\ndomain (rather than explaining the hidden mechanisms relating these phenomena)\n1\narXiv:1807.09844v2  [cs.CL]  23 Mar 2019\n[21]. For this paper we use the term phenomenological model to characterise mod-\nels which are primarily driven by ﬁtting to observable relationships between phe-\nnomena in a domain, as represented by correlations between features in a dataset\nsampled from the domain; as opposed to models that are derived from a domain\ntheory of the interactions between domain features. The focus of this paper is to\nexamine and frame the potentially synergistic relationship between these distinct\nanalytic methods for natural language processing (NLP) in the light of recent ad-\nvances in deep neural networks (DNNs) and deep learning.\nIn historic terms this discussion is recurrent throughout the history of NLP.\nFor example, early approaches such as [51, 1] are mechanistic in nature as they\nare based on logic and other formal approaches such as features structures and\nuniﬁcation which are tools that allow formalisation of domain theories. With the\navailability of large corpora in mid-1990s there was a shift to data-driven phe-\nnomenological approaches with a focus on statistical machine learning methods\n[43, 55]. This inspired several discussions on the relation between the two ap-\nproaches (e.g., [22, 25]). We share the view of some that both approaches are in\nfact in a complimentary distribution with each other as shown in Table 1 (adapted\nfrom a slide by Stephen Pulman). Mechanistic approaches provide deep coverage\nbut of a limited domain; outside a domain they prove brittle and therefore limited.\nOn the other hand, phenomenological approaches are wide-coverage and robust to\nvariation found in data but provide a shallow representation of language.\ntech/cov\nwide\nnarrow\ndeep\nour goal\nsymbolic\nshallow\ndata-based\nuseless\nTable 1: Properties of mechanistic and phenomenological approaches in NLP\nOur desiderata is a wide-coverage system with deep analyses. It was consid-\nered that this could be achieved by a hybrid model but working out such a model\nhas proven not a trivial task. Systems that used both approaches treated them nor-\nmally as independent black-boxes organised in layers (e.g. [37]). However, the\nmarked recent advances in the NLP based on deep (!) neural networks have made\nthe question of how these two methodologies should be used, related and integrated\nin NLP research apposite.\nThe choice of a method depends on the goal of the task for which it is used.\nOne goal for processing natural language is to develop useful applications that help\nhumans in their daily life, for example machine translation and speech recognition.\nIn application scenarios where a rough analysis is acceptable (e.g., a translation\nthat provides the gist of the message) and large annotated and structured corpora\nare available, machine learning is the methodology of choice to address this goal.\nHowever, where precise analysis is required or where there is a scarcity of data, a\nmachine learning approach may not be suitable. Furthermore, if the goal of pro-\n2\ncessing language is rather motivated by the desire to better understand its cognitive\nfoundations, than a machine learning methodology, particularly one based on an\nunconstrained, fully connected deep neural network, is not appropriate. The crit-\nicisms of unconstrained neural network based models (typically characterised by\nfully-connected feed-forward multi-layer networks) in cognitive science has a long\nhistory (see [44] inter alia) and often focuses on (i) the difﬁcultly in analysing in\na domain-theoretic sense how the model works, and (ii) the, somewhat ironic, sci-\nentiﬁc short-coming that neural networks are such powerful and general learning\nmechanisms that demonstrating the ability of a network to learn a particular map-\nping or a function is scientiﬁcally useless from a cognitive science perspective. In\nparticular, as Massaro [44] argues, a neural network model is so adaptable that\ngiven the appropriate dataset and sufﬁcient time and computing power it is likely\nto be able to learn mappings that not only support a cognitive theory but also ones\nthat contradict that theory. One approach to address this problem is to introduce\ndomain relevant structural constraints into the model via the network architecture,\nearly approaches include [18, 19, 46]. Indeed, we argue in this paper that one of\nthe important and somewhat overlooked factors driving the success of research in\ndeep learning is the speciﬁcity and modularity of deep learning architectures to the\ntasks they are applied too.\nContribution:\nIn this paper we evaluate the relation between mechanistic and\nphenomenological models and argue that although it appears that the former have\nlost their signiﬁcance in computational linguistics and its applications they are still\nvery much present in the form of formal language modelling that underlines most\nof the current work with machine learning. Moreover, we highlight that many of\nthe recent advances in deep learning for NLP are not based on unconstrained neural\nnetworks but rather that these networks have task speciﬁc architectures that encode\ndomain-theoretic considerations. In this light, the relationship between mechanis-\ntic and phenomenological models can be viewed as potentially more synergistic.\nGiven that many logical theories are deﬁned in terms of functions and composi-\ntional operations and neural networks learn and compose functions, a logic-based\ndomain theory of linguistic performance can naturally inform the structural design\nof deep learning architectures and thereby merge the beneﬁts of both in terms of\nmodel interpretability and performance.\nOverview:\nIn Section 2, we discuss recent developments in deep learning ap-\nproaches in NLP and situate them within the current debate; then, in Section 3, we\nuse the computational modelling of spatial language as an NLP case study to frame\nthe possible synergies between formal models and machine learning and set out our\nthoughts for potential approaches to developing a more synergistic understanding\nof the formal models and machine learning for NLP research. In Section 4 we give\nour concluding thoughts.\n3\n2\nDeep Learning: A New Synthesis?\nIn recent years deep learning (DL) models have improved or in some cases markedly\nimproved the state of the art across a range of NLP tasks. Some of the drivers of DL\nsuccess include: (i) the availability of large datasets, (ii) more powerful computers,\nand (iii) the power of learning and adaptability of connectionist neural networks.\nHowever, another and less obvious driver of DL is the fact that (iv) DL network\nmodels often have architectures that are speciﬁcally tailored or structured to the\nneeds of a speciﬁc domain or task. This fact becomes obvious when one consid-\ners the variety of DL architectures that have been proposed in the literature. For\nexample, a schematic overview of neural network architectures can be found at at:\nhttp://www.asimovinstitute.org/neural-network-zoo/ [56].\n2.1\nModularity in Deep Learning Architectures\nThere are a large-number of network design parameters that may be driven by ex-\nperimental results rather than domain theory. For example, (i) the size of the net-\nwork, (ii) the depth of the layers, (iii) the size of the matrices passed between the\nlayers, (iv) activation functions and (v) optimiser are all network parameters that\nare often determined through an empirical trial-and-error process that is informed\nby designer intuition [26]. However, the diversity of current network architectures\nextends beyond differences in these parameters and this diversity of network archi-\ntecture is not a given. For example, given the ﬂexibility of neural networks, one\napproach to accommodating structure into the processing of a network is to apply\nminimal constraints on the architecture and to rely on the ability of the learning\nalgorithm to induce the relevant structure constraints by adjusting the network’s\nweights.\nOn the other hand, it has, however, long been known that pre-structuring a\nneural network by the careful design of its architecture to ﬁt the requirements of the\ntask results in better generalisation of the model beyond the training dataset [39].\nUnderstood in this context, DL is assisted (or supervised!) by the task designer\nin terms of a priori background knowledge who decides what kind of networks\nthey are going to build, the number of layers, what kind of layers, the connectivity\nbetween the layers and other parameters. DL is most frequently not using fully\nconnected layers, instead several kinds of layered networks have been developed\ntailored to the task. In this respect DL models capture top-down domain informed\nspeciﬁcation that we have seen with the rule-based NLP systems. This ﬂexibility\nof neural networks is ensured by their modular design which takes as a basis a\nsingle perceptron unit which can be thought of encoding a simple concept. When\nseveral units are organised and connected into larger collections of units, these\nmay be given interpretations that we give to symbolic representations in rule-based\nsystems. The level of conceptual supervision may thus vary from no-supervision\nwhen fully connected layers are used, to weak supervision that primes the networks\nto learn particular structures, to strong supervision where the structure is given and\n4\nonly parameters of this structure are trained.\nAn example of weak supervision are Recurrent Neural Networks (RNNs) that\ncapture sequence learning required for language models. The design of current\nstate-of-the-art RNN language models is informed by linguistic phenomena such as\nshort- and long-distance dependencies between linguistic units. In order to improve\nthe ability of RNNs to model long-distance dependencies, contemporary RNN lan-\nguage models use Long-Short Memory Units (LSTM) or Gated Recurrent Units\n(GRUs) which may be further augmented with attention mechanisms [49]. The\ninputs and outputs of such networks can be either characters or words, the latter\nrepresented as word embeddings in vector spaces.\nAnother example of weakly supervised neural networks, in the sense that their\ndesign is informed by a domain, are Convolutional Neural Networks (CNNs) which\nhave their origin in image processing [39]. In CNNs the convolutions are meant\nas ﬁlters that encode a region of pixels into a single neural unit which learns to\nrespond to the occurrence of a pixel pattern in the region speciﬁc visual feature.\nImportantly, the weights associated with a speciﬁc convolution are shared across\na group of neurons such that together the group of neurons check for the occur-\nrence of the visual features across the full surface of the image. Additionally, as\nobjects or entities may occur in different parts of image, to decrease the effects of\nspatial continuum, operations such as pooling are used that encode convolved rep-\nresentations from various parts of the image. In analogy to learning visual features,\nCNNs have also been used for language modelling to capture different patterns of\ncharacters in strings [35].\nSpecialised networks may be treated as modules which are sequenced after\neach other. For example, the current Neural Machine Translation (NMT) archi-\ntecture is the encoder-decoder [54, 3, 41, 27]. This architecture uses one RNN,\nknown as the encoder, to fully process the input sentence and generate its vector\nbased representation. This is passed to a second RNN, the decoder, which im-\nplements a language model of the target language which generates the translation\nword by word. Domain theoretic considerations have affected the design how the\ntwo language modelling networks are connected in a number of ways. For ex-\nample, an understanding that different languages have different word orders lead\nto enabling the decoder to look both back and forward along the input sentence\nduring translation. This is implemented by fully processing the input sequence\nwith the ﬁrst RNN before translation is generated by the second RNN. However,\nthe understanding of the need for local dependencies between different sections\nof the translation and somewhat a contrary requirement to the need for a poten-\ntially global perspective on the input has resulted in the development of attention\nmechanisms within the NMT framework. This means that DL network architec-\ntures modules are not only sequenced but they are also stacked. A variant of the\nNMT encoder-decoder architecture that replaces the encoder RNN with a CNN\nhas revolutionised the ﬁeld of image captioning [57]. Figure 1 gives a schematic\nrepresentation of such image captioning systems. The CNN module learns to rep-\nresent images as vector representations of visual features and the RNN module is\n5\nFigure 1: A schematic representation of DL image captioning architectures\na language model whose output is conditioned on the visual representations. We\nhave already mentioned that CNNs are also used to generate word representations.\nThese representations are then passed to an RNN model to predict the next word\nin the context of preceding words in the sequence (see [35]). The advantage of\nusing a CNN module to learn word representation is that it enables the system to\ncapture spelling variation of morphologically-rich languages or texts from social\nmedia that does not use standard spelling of words. This and also the preceding\nexamples therefore illustrate how different levels of linguistic representations are\nmodelled in modular DL architectures.\nIn summary, the design of a DL architectures, where DL networks are treated\nas composable modules, can constrain and guide a number of factors that are im-\nportant in representing language and other modalities, in particular the hierarchical\ncomposition of features and the sequencing of the representations. Importantly,\nthe neural representations that are used in these cases are inspired by rich work on\ntop-down rule-based mechanistic natural language processing.\n2.2\nPhenomenological versus Mechanistic Models\nThe ability to treat neural networks as composable modules within an overall sys-\ntem architecture is a powerful one. This is because during training it is possible\nto back-propagate the error through each of the system’s modules (networks) and\ntrain them in consort while permitting each module to learn its distinctive task in\nparallel with the other modules in the network. However, the power of this ap-\nproach has led to some research being based on a relatively shallow understanding\nof domain theory and most of the work being spent on ﬁtting the hyper-parameters\nof the training algorithm through a grid-search driven by experimental performance\non gold-standard datasets. The domain theory is only used to inform the broad out-\nlines of the system architecture. Using image-captioning as an example, and at the\nrisk of presenting a caricature, this approach may be described as: “we are doing\nimage-captioning so we need a CNN to encode the image and an RNN to generate\nthe language and we will let the learning algorithm sort out the rest of the details”.\nThis theory free, or at least, theory light approach to NLP research is primarily\ndriven by performance on gold-standard datasets and lamentably frequently the\nanalysis of the systems is limited to the presentation of system results relative to a\nstate-of-the-art leader-board with relatively little reﬂection on the how the structure\n6\nof the model reﬂects theoretic considerations. This focus on performance in terms\nof accurately modelling the empirical relationship between inputs and outputs and\nwhere the trained model is treated as a black box aligns with what we describe as\nthe phenomenological tradition in machine learning. This can be contrasted with\nan alternative tradition within machine learning which is sometimes described as\nbeing based on mechanistic models. Mechanistic models presuppose a domain\ntheory and the model is essentially a computational implementation of this domain\ntheory. To illustrate this difference, contrast for example the approach to training a\nsupport vector machine classiﬁer where multiple kernels are tested until one with\nhigh performance on a dataset is found versus the approach to deﬁning the topology\nof a Bayesian network in such a way that it mirrors a theory informed model of\nthe causal relationships between relevant variables in the domain [32]. Once the\ntheoretical model has been implemented, the free parameters of the model can then\nbe empirically ﬁt to the data.\nConsequently, mechanistic models are informed by both top-down theoretical\nconsiderations of a task designer but they are also sensitive to bottom-up empirical\nconsiderations, the training data. Mechanistic models have several advantages,\nfor example: they can be used to test a domain theory. If the model is accurate,\nthis provides evidence that the theory is correct. Assuming the theory is correct,\nthey are likely to outperform phenomenological models in contexts where data is\nlimited.1 The top top-down approach provides background knowledge that restricts\nthe size of the training search space.\nTraditionally, neural networks have been considered the paradigmatic exam-\nple of a phenomenological model. However, viewing neural networks as compo-\nnent modules within a larger deep-learning systems opens the door to sophisticated\nmechanistic deep-learning models. Such an approach to network design is, how-\never, dependent on the system designer being informed by domain theory and is\ntherefore strongly supervised in terms of background knowledge. An example of\nmodular networks where each module is some conﬁguration of neural units that are\ntailored to optimise parameters of a particular task is described in [2] who work in\nthe domain of question answering. The architecture learns how to map questions\nand visual or database representations to textual answers. In order to answer a\nquestion, the network learns a network layout of modules that are responsible for\nthe individual steps required to answer the question. For example, to answer “What\ncolour is the bird” the network applies the attention module to ﬁnd the object from\nthe question, followed by a module that identiﬁes the colour of the attended re-\ngion in the image. The possible sequences of modules are constrained by being\nrepresented as typed functions: in fact the modules translate to typed functional\napplications through which compositionality of linguistic meaning is ensured as in\nformal semantics [4]. The system learns (using reinforcement learning) a layout\nmodel which predicts the sequence of modules to produce an answer for a question\nsentence and an execution module which learns how to ground a network layout\n1See discussion on generative versus discriminative models in [32].\n7\nin the image or database representation. An extension of this work is described in\n[24] where both procedures rely on less background knowledge. For example, the\nsystem does not use a dependency parser to parse the input sentence but an LSTM\nlanguage module and the modules use a more generic architecture.\nThe modular networks are in line with the structured connectionism of [18]\nand constrained connectionism of Regier [46] “in which complex domain-speciﬁc\nstructures are built into the network, constraining its operation in clearly under-\nstandable and analysable ways” [46, p. 2]. Regiers’s presentation of constrained\nconnectionism is based on a case study on learning spatial relations and events. The\ncase study describes the design and training of a neural network that receives short\nmovies of 2 two-dimensional objects, a static rectangle and a circle which is either\nstatic or moving, as input and the model learns to predict the correct spatial term to\ndescribe the position and movement of the circle relative to the rectangle. For ex-\nample, a static circle might be described as above the rectangle, whereas a moving\ncircle might move out from under the rectangle. A crucial aspect of this case study\nfor Regier’s argument is that the neural network’s architecture is constrained in so\nfar as it incorporates a number of structural devices that are motivated by neuro-\nlogical and psychological evidence concerning the human visual system, including\nmotion buffers, angle and orientation computations components, and boundary and\nfeature maps for objects in the input. Following [46], in the next section we will\ntake spatial language as an NLP case-study and discuss how domain theory can be\nused to extend current deep-learning systems so as to move them further towards\nthe mechanistic pole within the phenomenological versus mechanistic spectrum.\n3\nSpatial Language\nOur focus is computational modelling of spatial language, such as the chair is to\nthe left and close to the table or go down the corridor until the large painting\non your right, then turn left, which requires integration of different sources of\nknowledge that affect its semantics, including: (i) scene geometry, (ii) perspective\nand perceptual context, (iii) world knowledge about dynamic kinematic routines\nof objects, and (iv) interaction between agents through language and dialogue and\nwith the environment through perception. Below we describe these properties in\nmore detail:\nScene geometry is described within a two-dimensional or three-dimensional co-\nordinate frame in which we can represent locations of objects as geometric shapes\nas well as angles and distances between them. Over a given area we can identify\ndifferent degrees of applicability of a spatial description, for example with spatial\ntemplates [40, 11]. A spatial template may be inﬂuenced by perceptual context\nthrough the presence of other objects in the scene known as distractors [31, 7],\nocclusion [34, 33], and attention [47].\nDirectionals such as to the left of require a model of perspective or assignment\nof a frame of reference [42] which includes a viewpoint parameter. The viewpoint\n8\nmay be deﬁned linguistically from your view or from there but it is frequently left\nout. Ambiguity with respect to the intended perspective of a reference can affect\nthe grounding of spatial terms in surprising ways [5, 28]. However, frequently the\nintended perspective can be either inferred from the perceptual context (if only one\ninterpretation is possible, see for example the discussion on contrastive versus rel-\native meanings in [30]) or it may be linguistically negotiated and aligned between\nconversational partners in dialogue [17, 14, 13].\nAs mentioned earlier, spatial descriptions do not refer to the actual objects in\nspace but to conceptual geometric representations of these objects, which may be\npoints, lines, areas and volumes. The representation depends on how we view the\nscene, for example under the water (water ≈surface) and in the water (water ≈\nvolume). The inﬂuence of world knowledge goes beyond object conceptualisation.\nSome prepositions are more sensitive to the way the objects interact with each\n(their dynamic kinematic routines) while other are more sensitive to the way the\nobjects relate geometrically [10].\nFinally, because situated agents are located within dynamic linguistic and per-\nceptual environments they must continuously adapt their understanding and rep-\nresentations relative to these context. On the language side they must maintain\nlanguage coordination with dialogue partners [6, 20, 50, 12]. A good example of\nadaptation of contextual meaning through linguistic interaction is the coordinated\nassignment of frame of reference mentioned earlier.\nIn summary, the meaning of spatial descriptions is dynamic, dependent on sev-\neral sources of contextually provided knowledge which provide a challenge for\nits computational modelling because of its contextual underspeciﬁcation and be-\ncause it is difﬁcult to provide and integrate that kind of knowledge. On the other\nhand, a computational system taking into account these meaning components in\ncontext would be able to understand and generate better, more human-like, spatial\ndescriptions and engage in more efﬁcient communication in the domain of situated\nagents and humans. Furthermore, it could exploit the synergies between different\nknowledge sources to compensate missing knowledge in one source from another\n[53, 52, 50].\n3.1\nModular Mechanistic (Neural) Models of Spatial Language\nThe discussion in the preceding section highlighted the numerous factors that im-\npinge on the semantics of spatial language. It is this multiplicity of factors that\nmake spatial language such a useful case study for this paper, the complexity of the\nproblem invites a modular approach where the solution can be built in a piecewise\nmanner and then integrated. One challenge to this approach to spatial language is\nthe lack of an overarching theory explaining how these different factors should be\nintegrated, examples of candidate theories that could act as a starting point here\ninclude [23] and [8].\nAt the same time there are a number of examples of neural models in the litera-\nture that could provide a basis for the design of speciﬁc modules. We have already\n9\ndiscussed [46] which captured geometric factors and paths of motion. Another\nexample of a mechanistic neural model of spatial descriptions is described in [9].\nTheir system processes dynamic visual scenes containing three objects: a teapot\npouring water into a cup and the network learns to optimise, for each temporal\nsnapshot of a scene, the appropriateness score of a spatial description obtained in\nsubject experiments. The idea behind these experiments is that descriptions such\nas over and above are sensitive to a different degree to geometric and functional\nproperties of a scene, the latter arising from the interactions between objects as\nmentioned earlier. The model is split into three modules: (i) a vision processing\nmodule that deals with detection of objects from image sequences that show the\ninteraction of objects, the tea pot, the water and the cup, using an attention mech-\nanism, (ii) an Elman recurrent network that learns the dynamics of the attended\nobjects in the scene over time, and (iii) a dual feed-forward vision and language\nnetwork to which representations from the hidden layer of the Elman network are\nfed and which learns how to predict the appropriateness score of each descrip-\ntion for each temporal conﬁguration of objects. Each module of this network is\ndedicated to a particular task: (i) to recognition of objects, (ii) to follow motion of\nattended objects in time and (iii) to integration of the attended object locations with\nlanguage to predict the appropriateness score, factors that have been identiﬁed to\nbe relevant for computational modelling of spatial language and cognition through\nprevious experimental work [10]. The example shows the effectiveness of repre-\nsenting networks as modules and their possibility of joint training where individual\nmodules constrain each other.\nThe model could be extended in several ways. For example, contemporary\nCNNs and RNNs could be used which have become standard in neural modelling\nof vision and language due to their state-of-the-art performance. Secondly, the\napproach is trained on a small dataset of artiﬁcially generated images of a single\ninteractive conﬁguration of three objects.2 An open question is how the model\nscales on a large corpus of image descriptions [36] where considerable noise is\nadded. There will be several objects, their appearance and location may be dis-\ntorted by the angle at which the image is taken, there are no complete temporal\nsequences of objects and the corpora typically does not contain human judgement\nscores on how appropriate a description is given an image. Finally, Coventry et.\nal.’s model integrates three modalities used in spatial cognition, but as we have seen\nthere are several others [9]. An important aspect is grounded linguistic interaction\nand adaptation between agents. For example, [38] describe a system where two\nnetworks are trained to perform referential games (dialogue games performed over\nsome visual scene) between two agents. In this context, the agents develop their\nown language interactively. An open research question is whether parameters such\nframe of reference intended by the speaker of a description could also be learned\nthis way. Note that this is not always overtly speciﬁed, e.g. from my left.\n2To be fair to the authors, their intention was not to build an image captioning system but to show\nthat modular networks can optimise human experimental judgements.\n10\nSometimes a mechanistic design of the network architecture constrains what a\nmodel can learn in undesirable ways. For example, Kelleher & Dobnik argue that\ncontemporary image captioning networks as in Figure 1 have been conﬁgured in a\nway that they capture visual properties of objects rather than spatial relations be-\ntween them [29]. Consequently, within the captions generated by these systems the\nrelation between the preposition and the object is not grounded in geometric repre-\nsentation of space but only in the linguistic sequences through the decoder language\nmodel where the co-occurrence of particular words in a sequence is estimated.\n[16, 15] show that a language model is predictive of functional relations between\nobjects that spatial relations are also sensitive to but in this case the geometric di-\nmension is missing. This indicates that the architecture of these image-captioning\nsystems, although modular, ignores important domain theoretic considerations and\nhence are best understood as close to the phenomenological (black-box) than the\nmechanistic (grey-box) network design philosophy this paper advocates.\nIn summary, it follows that an appropriate computational model of spatial lan-\nguage should consist of several connected modalities (for which individual neural\nnetwork architectures are speciﬁed) but also of a general network that connects\nthese modalities, thus akin to the specialised regions and their interconnections in\nthe brain [48]. The challenge of creating and training such a system is obviously\nsigniﬁcant, however one feature of neural network training that may make this\ntask easier is that it is possible to back-propagate through a pre-trained network.\nThis opens the possibility of pre-training networks as modules (sometimes even on\ndifferent datasets) that carry out speciﬁc theory-informed tasks and then training\nlarger systems that represent the full-theory by including these pre-trained modules\ncomponents within the system and training other modules and/or integration layers\nwhile keeping the weights of the pre-trained modules frozen during training.\n4\nConclusion and Future Research\nDNNs provide a platform for machine learning that permits great ﬂexibility in com-\nbining top-down speciﬁcation (in terms of hand-designed structures and rules) and\ndata driven approaches. Designers can tailor the network structures to each in-\ndividual learning problem and therefore effectively reach the goal of combining\nmechanistic and phenomenological approaches: a problem that has been investi-\ngated in NLP for several decades. The strength of DNNs is in the compositionality\nof perceptrons or neural units, and indeed networks themselves, which represent\nindividual classiﬁcation functions that can be combined in novel ways. This was\nnot possible with other approaches in machine learning to the same degree with a\nconsequences that these worked more as black boxes. Finally, although we are not\nadvocating that there is a direct similarity between DNNs and human cognition, it\nis nonetheless the case that DNNs are inspired by neurons and connectionist or-\nganisation of human brain and hence at some high abstract level they share some\nsimilarities, for example basic classiﬁcation units combine to larger structures, the\n11\nstructures get specialised to modules to perform certain tasks, and training and clas-\nsiﬁcation is performed across several modules. Therefore, this might be a possible\nexplanation that DNNs have been so successful in computational modelling of lan-\nguage and vision, the surface manifestations of the underlying human cognition, as\nat some abstract level they represent a similar architecture to human cognition.\nAcknowledgements\nThe research of Dobnik was supported by a grant from the Swedish Research\nCouncil (VR project 2014-39) for the establishment of the Centre for Linguistic\nTheory and Studies in Probability (CLASP) at Department of Philosophy, Linguis-\ntics and Theory of Science (FLoV), University of Gothenburg.\nThe research of Kelleher was supported by the ADAPT Research Centre. The\nADAPT Centre for Digital Content Technology is funded under the SFI Research\nCentres Programme (Grant 13/RC/2106) and is co-funded under the European Re-\ngional Development Funds.\nReferences\n[1] Hiyan Alshawi. The Core Language Engine. ACL-MIT Press series in natural\nlanguage processing. MIT Press, Cambridge, Mass., 1992.\n[2] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Learning to\ncompose neural networks for question answering. In Proceedings of NAACL-\nHLT 2016, pages 1545–1554, San Diego, California, June 12-17 2016. Asso-\nciation for Computational Linguistics.\n[3] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine\ntranslation by jointly learning to align and translate.\narXiv:1409.0473v7\n[Cs.CL], pages 1–15, 2014.\n[4] Patrick Blackburn and Johan Bos. Representation and inference for natu-\nral language. A ﬁrst course in computational semantics. CSLI Publications,\n2005.\n[5] L.A. Carlson-Radvansky and G.D. Logan. The inﬂuence of reference frame\nselection on spatial template construction. Journal of Memory and Langauge,\n37:411–437, 1997.\n[6] Herbert H. Clark. Using language. Cambridge University Press, Cambridge,\n1996.\n[7] Fintan Costello and John D. Kelleher. Spatial prepositions in context: The\nsemantics of Near in the presense of distractor objects. In Proceedings of the\n3rd ACL-Sigsem Workshop on Prepositions, pages 1–8, 2006.\n12\n[8] Kenny Coventry and Simon Garrod. Spatial prepositions and the functional\ngeometric framework. Towards a classiﬁcation of extra-geometric inﬂuences.,\nvolume 2. Oxford University Press, 2005.\n[9] Kenny R. Coventry, Angelo Cangelosi, Rohanna Rajapakse, Alison Bacon,\nStephen Newstead, Dan Joyce, and Lynn V. Richards. Spatial prepositions\nand vague quantiﬁers: Implementing the functional geometric framework. In\nChristian Freksa, Markus Knauff, Bernd Krieg-Br¨uckner, Bernhard Nebel,\nand Thomas Barkowsky, editors, Spatial Cognition IV. Reasoning, Action,\nInteraction, volume 3343 of Lecture Notes in Computer Science, pages 98–\n110. Springer Berlin Heidelberg, 2005.\n[10] Kenny R. Coventry, Merc`e Prat-Sala, and Lynn Richards. The interplay be-\ntween geometry and function in the apprehension of Over, Under, Above and\nBelow. Journal of Memory and Language, 44(3):376–398, 2001.\n[11] Simon Dobnik and Amelie ˚Astbom. (Perceptual) grounding as interaction.\nIn Volha Petukhova and Ye Tian, editors, Proceedings of Saardial – Semdial\n2017: The 21st Workshop on the Semantics and Pragmatics of Dialogue,\npages 17–26, Saarbr¨ucken, Germany, August 15–17 2017.\n[12] Simon Dobnik and Erik de Graaf. KILLE: a framework for situated agents\nfor learning language through interaction.\nIn J¨org Tiedemann and Nina\nTahmasebi, editors, Proceedings of the 21st Nordic Conference on Com-\nputational Linguistics (NoDaLiDa), pages 162–171, Gothenburg, Sweden,\n22–24 May 2017. Northern European Association for Language Technology\n(NEALT), Association for Computational Linguistics.\n[13] Simon Dobnik, Christine Howes, Kim Demaret, and John D. Kelleher. To-\nwards a computational model of frame of reference alignment in Swedish\ndialogue. In Johanna Bj¨orklund and Sara Stymne, editors, Proceedings of the\nSixth Swedish language technology conference (SLTC), pages 1–3, Ume˚a,\n17–18 November 2016. Ume˚a University.\n[14] Simon Dobnik, Christine Howes, and John D. Kelleher. Changing perspec-\ntive: Local alignment of reference frames in dialogue. In Christine Howes\nand Staffan Larsson, editors, Proceedings of goDIAL – Semdial 2015: The\n19th Workshop on the Semantics and Pragmatics of Dialogue, pages 24–32,\nGothenburg, Sweden, 24–26th August 2015.\n[15] Simon Dobnik and John Kelleher. Exploration of functional semantics of\nprepositions from corpora of descriptions of visual scenes. In Proceedings of\nthe Third V&L Net Workshop on Vision and Language, pages 33–37, Dublin,\nIreland, August 2014. Dublin City University and the Association for Com-\nputational Linguistics.\n13\n[16] Simon Dobnik and John D. Kelleher.\nTowards an automatic identiﬁca-\ntion of functional and geometric spatial prepositions.\nIn Proceedings of\nPRE-CogSsci 2013: Production of referring expressions - bridging the gap\nbetween cognitive and computational approaches to reference, pages 1–6,\nBerlin, Germany, 31 July 2013.\n[17] Simon Dobnik, John D. Kelleher, and Christos Koniaris. Priming and align-\nment of frame of reference in situated conversation. In Verena Rieser and\nPhilippe Muller, editors, Proceedings of DialWatt – Semdial 2014: The 18th\nWorkshop on the Semantics and Pragmatics of Dialogue, pages 43–52, Edin-\nburgh, 1–3 September 2014.\n[18] J. A. Feldman, M. A. Fanty, and N. H. Goodard. Computing with structured\nneural networks. Computer, 21(3):91–103, March 1988.\n[19] Jerome A. Feldman. Structured neural networks in nature and in computer\nscience. In Rolf Eckmiller and Christoph v.d. Malsburg, editors, Neural Com-\nputers, pages 17–21. Springer, Berlin, Heidelberg, 1989.\n[20] Raquel Fern´andez, Staffan Larsson, Robin Cooper, Jonathan Ginzburg, and\nDavid Schlangen. Reciprocal learning via dialogue interaction: Challenges\nand prospects.\nIn Proceedings of the IJCAI 2011 Workshop on Agents\nLearning Interactively from Human Teachers (ALIHT), Barcelona, Catalonia,\nSpain, 2011.\n[21] Roman Frigg and Stephan Hartmann.\nModels in science.\nIn Edward N.\nZalta, editor, The Stanford Encyclopedia of Philosophy (Spring 2017 Edi-\ntion). Metaphysics Research Lab, Stanford University, 2017.\n[22] Gerald Gazdar. Paradigm merger in natural language processing. In Ian Wand\nand Robin Milner, editors, Computing Tomorrow, pages 88–109. Cambridge\nUniversity Press, New York, NY, USA, 1996.\n[23] Annette Herskovits. Language and Spatial Cognition. Cambridge University\nPress, New York, NY, USA, 1987.\n[24] Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Judy Hoffman,\nFei-Fei Li, C. Lawrence Zitnick, and Ross B. Girshick. Inferring and execut-\ning programs for visual reasoning. arXiv:1705.03633v1 [cs.CV], pages 1–13,\n2017.\n[25] Karen I. B. Sp¨arck Jones, Gerald J. M. Gazdar, and Roger M. Needham. In-\ntroduction: combining formal theories and statistical data in natural language\nprocessing. Philosophical Transactions of the Royal Society of London A:\nMathematical, Physical and Engineering Sciences, 358(1769):1227–1238,\n2000.\n14\n[26] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui\nWu.\nExploring the limits of language modeling.\narXiv:1602.02410v2\n[cs.CL], pages 1–11, 2016.\n[27] John D. Kelleher.\nFundamentals of machine learning for neural machine\ntranslation. In Proceedings of the Translating Europen Forum 2016: Focus-\ning on Translation Technologies. European Commission Directorate-General\nfor Translation, 2016.\n[28] John D. Kelleher and Fintan J. Costello. Cognitive representations of pro-\njective prepositions. In Proceedings of the Second ACL-SIGSEM workshop\non the linguistic dimensions of prepositions and their use in computational\nlinguistics formalisms and applications, pages 119–127, University of Essex,\nColchester, United Kingdom, 2005. Association for Computational Linguis-\ntics.\n[29] John D. Kelleher and Simon Dobnik.\nWhat is not where: the challenge\nof integrating spatial representations into deep learning architectures.\nIn\nCLASP Papers in Computational Linguistics: Proceedings of the Confer-\nence on Logic and Machine Learning in Natural Language (LaML 2017),\nvolume 1, pages 41–52, Gothenburg, Sweden, 12–13 June 2017.\n[30] John D. Kelleher and Geert-Jan M. Kruijff. A context-dependent algorithm\nfor generating locative expressions in physically situated environments. In\nGraham Wilcock, Kristiina Jokinen, Chris Mellish, and Ehud Reiter, editors,\nProceedings of the Tenth European Workshop on Natural Language Genera-\ntion (ENLG-05), pages 1–7, Aberdeen, Scotland, August 8–10 2005. Associ-\nation for Computational Linguistics.\n[31] John D. Kelleher and Geert-Jan M. Kruijff. A context-dependent model of\nproximity in physically situated environments. In Proceedings of the Sec-\nond ACL-SIGSEM workshop on the linguistic dimensions of prepositions and\ntheir use in computational linguistics formalisms and applications, Univer-\nsity of Essex, Colchester, United Kingdom, 2005. Association for Computa-\ntional Linguistics.\n[32] John D Kelleher, Brian Mac Namee, and Aoife D’Arcy. Fundamentals of\nmachine learning for predictive data analytics: algorithms, worked examples,\nand case studies. MIT Press, 2015.\n[33] John D. Kelleher, Robert Ross, Colm Sloan, and Brian Mac Namee. The\neffect of occlusion on the semantics of projective spatial terms: a case study\nin grounding language in perception. Cognitive Processing, 12(1):95–108,\nFebruary 2011.\n15\n[34] John D. Kelleher and Josef van Genabith. A computational model of the ref-\nerential semantics of projective prepositions. In P. Saint-Dizier, editor, Syn-\ntax and Semantics of Prepositions, Speech and Language Processing. Kluwer\nAcademic Publishers, Dordrecht, The Netherlands, 2006.\n[35] Yoon Kim, Yacine Jernite, David Sontag, and Alexander M. Rush. Character-\naware neural language models. In Proceedings of the Thirtieth AAAI Confer-\nence on Artiﬁcial Intelligence (AAAI-16), pages 2741–2749, Phoenix, Ari-\nzona USA, February 12–17 2016.\n[36] Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua\nKravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma,\nMichael Bernstein, and Li Fei-Fei. Visual genome: Connecting language and\nvision using crowdsourced dense image annotations. International Journal\nof Computer Vision, 123(1):32–73, May 2017.\n[37] Geert-Jan M. Kruijff, Hendrik Zender, Patric Jensfelt, and Henrik I. Chris-\ntensen. Situated dialogue and spatial organization: what, where... and why?\nInternational Journal of Advanced Robotic Systems, 4(1):125–138, 2007.\n[38] Angeliki\nLazaridou,\nAlexander\nPeysakhovich,\nand\nMarco\nBaroni.\nMulti-agent\ncooperation\nand\nthe\nemergence\nof\n(natural)\nlanguage.\narXiv:1612.07182v2 [cs.CL], pages 1–11, 2016.\n[39] Yann LeCun. Generalization and network design strategies. Technical re-\nport CRG-TR-89-4, Department of Computer Science, University of Toronto,\nJune 1989.\n[40] Gordon D. Logan and Daniel D. Sadler. A computational analysis of the\napprehension of spatial relations. In Paul Bloom, Mary A. Peterson, Lynn\nNadel, and Merrill F. Garrett, editors, Language and Space, pages 493–530.\nMIT Press, Cambridge, MA, 1996.\n[41] Minh-Thang Luong, Hieu Pham, and Christopher D. Manning. Effective ap-\nproaches to attention-based neural machine translation. In Proceedings of the\nConference on Empirical Methods in Natural Language Processing (EMNLP\n2015), pages 1412–1421, Lisbon, Portugal, September 17–21 2015.\n[42] Didier Maillat. The semantics and pragmatics of directionals: a case study\nin English and French. PhD thesis, University of Oxford: Committee for\nComparative Philology and General Linguistics, Oxford, United Kingdom,\nMay 2003.\n[43] Christopher D. Manning and Hinrich Sch¨utze. Foundations of statistical nat-\nural language processing. The MIT Press, 1999.\n[44] Dominic Massaro. Some criticisms of connectionist models of human per-\nformance. Journal of Memory and Language, 27:213–234, 1988.\n16\n[45] Ernan McMullin. What do physical models tell us?\nIn Bob van Rootse-\nlaar and Johan Frederik Staal, editors, Logic, Methodology and Science III:\nProceedings of the Third International Congress for Logic, Methodology and\nPhilosophy of Science, Amsterdam 1967, pages 385–396. North-Holland Pub-\nlishing Company, 1968.\n[46] Terry Regier.\nThe human semantic potential: Spatial language and con-\nstrained connectionism. MIT Press, 1996.\n[47] Terry Regier and Laura A. Carlson. Grounding spatial language in percep-\ntion: an empirical and computational investigation. Journal of Experimental\nPsychology: General, 130(2):273–298, 2001.\n[48] Ardi Roelofs. A dorsal-pathway account of aphasic language production: The\nWEAVER++/ARC model. Cortex, 59:33–48, 2014.\n[49] Giancarlo Salton, Robert Ross, and John D. Kelleher. Attentive language\nmodels. In Proceedings of the 8th International Joing Conference on Natural\nLanguage Processing (IJCNLP), pages 441–450, Taipei, Taiwan, November\n27 – December 1 2017.\n[50] Niels Schutte, Brian Mac Namee, and John D. Kelleher. Robot perception\nerrors and human resolution strategies in situated human–robot dialogue. Ad-\nvanced Robotics, 31(5):243–257, 2017.\n[51] Stuart Shieber. An Introduction to Uniﬁcation-Based Approaches to Gram-\nmar. CSLI Publications, Stanford, 1986.\n[52] Danijel Skoˇcaj, Matej Kristan, Alen Vreˇcko, Marko Mahniˇc, Miroslav\nJan´ıˇcek, Geert-Jan M. Kruijff, Marc Hanheide, Nick Hawes, Thomas Keller,\nMichael Zillich, and Kai Zhou. A system for interactive learning in dialogue\nwith a tutor. In IEEE/RSJ International Conference on Intelligent Robots and\nSystems IROS 2011, San Francisco, CA, USA, 25-30 September 2011.\n[53] Luc Steels and Martin Loetzsch. Perspective alignment in spatial language. In\nKenny R. Coventry, Thora Tenbrink, and John. A. Bateman, editors, Spatial\nLanguage and Dialogue. Oxford University Press, 2009.\n[54] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learn-\ning with neural networks. In Z. Ghahramani, M. Welling, C. Cortes, N. D.\nLawrence, and K. Q. Weinberger, editors, Advances in Neural Information\nProcessing Systems 27 (NIPS 2014), pages 3104–3112. Curran Associates,\nInc., 2014.\n[55] Peter D Turney, Patrick Pantel, et al.\nFrom frequency to meaning: Vec-\ntor space models of semantics. Journal of artiﬁcial intelligence research,\n37(1):141–188, 2010.\n17\n[56] Fjodor van Veen. The neural network ZOO. The Asimov Institute Blog posted\non September 14, September 14 2016.\n[57] Kelvin Xu, Jimmy Ba, Ryan Kiros, Aaron Courville, Ruslan Salakhutdinov,\nRichard Zemel, and Yoshua Bengio. Show, attend and tell: Neural image\ncaption generation with visual attention. arXiv:1502.03044v3 [cs.LG], pages\n1–22, February 11 2015.\n18\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG",
    "cs.NE",
    "stat.ML"
  ],
  "published": "2018-07-21",
  "updated": "2019-03-23"
}