{
  "id": "http://arxiv.org/abs/1808.05077v1",
  "title": "Exploiting Deep Learning for Persian Sentiment Analysis",
  "authors": [
    "Kia Dashtipour",
    "Mandar Gogate",
    "Ahsan Adeel",
    "Cosimo Ieracitano",
    "Hadi Larijani",
    "Amir Hussain"
  ],
  "abstract": "The rise of social media is enabling people to freely express their opinions\nabout products and services. The aim of sentiment analysis is to automatically\ndetermine subject's sentiment (e.g., positive, negative, or neutral) towards a\nparticular aspect such as topic, product, movie, news etc. Deep learning has\nrecently emerged as a powerful machine learning technique to tackle a growing\ndemand of accurate sentiment analysis. However, limited work has been conducted\nto apply deep learning algorithms to languages other than English, such as\nPersian. In this work, two deep learning models (deep autoencoders and deep\nconvolutional neural networks (CNNs)) are developed and applied to a novel\nPersian movie reviews dataset. The proposed deep learning models are analyzed\nand compared with the state-of-the-art shallow multilayer perceptron (MLP)\nbased machine learning model. Simulation results demonstrate the enhanced\nperformance of deep learning over state-of-the-art MLP.",
  "text": "Exploiting Deep Learning for Persian Sentiment\nAnalysis\nKia Dashtipour1, Mandar Gogate1, Ahsan Adeel1, Cosimo Ieracitano2 Hadi\nLarijani3, and Amir Hussain1\n1 Department of Computing Science and Mathematics, Faculty of Natural Sciences,\nUniversity of Stirling, FK9 4LA Stirling, United Kingdom\n2 DICEAM Department, University Mediterranea of Reggio Calabria, 89124 Reggio\nCalabria, Italy\n3 Department of Communication, Network and Electronic Engineering, Glasgow\nCaledonian University, G4 0BA Glasgow, United Kingdom\n∗email:kd28@cs.stir.ac.uk\nAbstract. The rise of social media is enabling people to freely express\ntheir opinions about products and services. The aim of sentiment anal-\nysis is to automatically determine subject’s sentiment (e.g., positive,\nnegative, or neutral) towards a particular aspect such as topic, prod-\nuct, movie, news etc. Deep learning has recently emerged as a powerful\nmachine learning technique to tackle a growing demand of accurate\nsentiment analysis. However, limited work has been conducted to apply\ndeep learning algorithms to languages other than English, such as Per-\nsian. In this work, two deep learning models (deep autoencoders and\ndeep convolutional neural networks (CNNs)) are developed and applied\nto a novel Persian movie reviews dataset. The proposed deep learning\nmodels are analyzed and compared with the the state-of-the-art shal-\nlow multilayer perceptron (MLP) based machine learning model. Sim-\nulation results demonstrate the enhanced performance of deep learning\nover state-of-the-art MLP.\nKeywords: Persian Sentiment Analysis · Persian Movie Reviews ·\nDeep Learning.\n1\nIntroduction\nIn recent years, social media, forums, blogs and other forms of online commu-\nnication tools have radically aﬀected everyday life, especially how people ex-\npress their opinions and comments. The extraction of useful information (such\nas people’s opinion about companies brand) from the huge amount of unstruc-\ntured data is vital for most companies and organizations[5]. The product re-\nviews are important for business owners as they can take business decision\naccordingly to automatically classify users opinions towards products and ser-\nvices. The application of sentiment analysis is not limited to product or movie\nreviews but can be applied to diﬀerent ﬁelds such as news, politics, sport etc.\narXiv:1808.05077v1  [cs.CL]  15 Aug 2018\n2\nK. Dashtipour et al.\nFor example, in online political debates, the sentiment analysis can be used to\nidentify people’s opinions on a certain election candidate or political parties\n[27][19][20]. In this context, sentiment analysis has been widely used in diﬀer-\nent languages by using traditional and advanced machine learning techniques.\nHowever, limited research has been conducted to develop models for the Per-\nsian language.\nThe sentiment analysis is a method to automatically process large amounts of\ndata and classify text into positive or negative sentiments) [2] [8]. Sentiment\nanalysis can be performed at two levels: at the document level or at the sen-\ntence level. At document level it is used to classify the sentiment expressed in\nthe document (positive or negative), whereas, at sentence level is used to iden-\ntify the sentiments expressed only in the sentence under analysis [7] [6].\nIn the literature, deep learning based automated feature extraction has been\nshown to outperform state-of-the-art manual feature engineering based classi-\nﬁers such as Support Vector Machine (SVM), Naive Bayes (NB) or Multilayer\nPerceptron (MLP) etc. One of the important techniques in deep learning is the\nautoencoder that generally involves reducing the number of feature dimensions\nunder consideration. The aim of dimensionality reduction is to obtain a set\nof principal variables to improve the performance of the approach. Similarly,\nCNNs have been proven to be very eﬀective in sentiment analysis. However,\nlittle work has been carried out to exploit deep learning based feature repre-\nsentation for Persian sentiment analysis [16] [10]. In this paper, we present two\ndeep learning models (deep autoencoders and CNNs) for Persian sentiment\nanalysis. The obtained deep learning results are compared with MLP.\nThe rest of the paper is organized as follows: Section 2 presents related work.\nSection 3 presents methodology and experimental results. Finally, section 4\nconcludes this paper.\n2\nRelated Works\nIn the literature, extensive research has been carried out to model novel sen-\ntiment analysis models using both shallow and deep learning algorithms. For\nexample, the authors in [3] proposed a novel deep learning approach for polar-\nity detection in product reviews. The authors addressed two major limitations\nof stacked denoising of autoencoders, high computational cost and the lack of\nscalability of high dimensional features. Their experimental results showed the\neﬀectiveness of proposed autoencoders in achieving accuracy upto 87%. Zhai et\nal., [28] proposed a ﬁve layers autoencoder for learning the speciﬁc representa-\ntion of textual data. The autoencoders are generalised using loss function and\nderived discriminative loss function from label information. The experimen-\ntal results showed that the model outperformed bag of words, denoising au-\ntoencoders and other traditional methods, achieving accuracy rate up to 85%\n. Sun et al., [26] proposed a novel method to extract contextual information\nfrom text using a convolutional autoencoder architecture. The experimental\nresults showed that the proposed model outperformed traditional SVM and\nExploiting Deep Learning for Persian Sentiment Analysis\n3\nNave Bayes models, reporting accuracy of 83.1 %, 63.9% and 67.8% respec-\ntively.\nSu et al., [24] proposed an approach for a neural generative autoencoder for\nlearning bilingual word embedding. The experimental results showed the ef-\nfectiveness of their approach on English-Chinese, English-German, English-\nFrench and English-Spanish (75.36% accuracy). Kim et al., [14] proposed a\nmethod to capture the non-linear structure of data using CNN classiﬁer. The\nexperimental results showed the eﬀectiveness of the method on the multi-\ndomain dataset (movie reviews and product reviews). However, the disadvan-\ntage is only SVM and Naive Bayes classiﬁers are used to evaluate the perfor-\nmance of the method and deep learning classiﬁers are not exploited. Zhang\net al., [29] proposed an approach using deep learning classiﬁers to detect po-\nlarity in Japanese movie reviews. The approach used denoising autoencoder\nand adapted to other domains such as product reviews. The advantage of\nthe approach is not depended on any language and could be used for vari-\nous languages by applying diﬀerent datasets. AP et al., [1] proposed a CNN\nbased model for cross-language learning of vectorial word representations that\nis coherent between two languages. The method is evaluated using English\nand German movie reviews dataset. The experimental results showed CNN\n(83.45% accuracy) outperformed as compared to SVM (65.25% accuracy).\nZhou et al., [30] proposed an autoencoder architecture constituting an LSTM-\nencoder and decoder in order to capture features in the text and reduce di-\nmensionality of data. The LSTM encoder used the interactive scheme to go\nthrough the sequence of sentences and LSTM decoder reconstructed the vec-\ntor of sentences. The model is evaluated using diﬀerent datasets such as book\nreviews, DVD reviews, and music reviews, acquiring accuracy up to 81.05%,\n81.06%, and 79.40% respectively. Mesnil et al., [17] proposed an approach us-\ning ensemble classiﬁcation to detect polarity in the movie reviews. The authors\ncombined several machine learning algorithms such as SVM, Naive Bayes and\nRNN to achieve better results, where autoencoders were used to reduce the di-\nmensionality of features. The experimental results showed the combination of\nunigram, bigram and trigram features (91.87% accuracy) outperformed uni-\ngram (91.56% accuracy) and bigram (88.61% accuracy).\nScheible et al., [22] trained an approach using semi-supervised recursive au-\ntoencoder to detect polarity in movie reviews dataset, consisted of 5000 pos-\nitive and 5000 negative sentiments. The experimental results demonstrated\nthat the proposed approach successfully detected polarity in movie reviews\ndataset (83.13% accuracy) and outperformed standard SVM (68.36% accu-\nracy) model. Dai et al., [4] developed an autoencoder to detect polarity in the\ntext using deep learning classiﬁer. The LSTM was trained on IMDB movie re-\nviews dataset. The experimental results showed the outperformance of their\nproposed approach over SVM. In table 1 some of the autoencoder approaches\nare depicted.\n4\nK. Dashtipour et al.\n3\nMethodology and Experimental Results\nThe novel dataset used in this work was collected manually and includes Per-\nsian movie reviews from 2014 to 2016. A subset of dataset was used to train\nthe neural network (60% training dataset) and rest of the data (40%) was used\nto test and validate the performance of the trained neural network (testing\nset (30%), validation set (10%)). There are two types of labels in the dataset:\npositive or negative. The reviews were manually annotated by three native\nPersian speakers aged between 30 and 50 years old.\nAfter data collection, the corpus was pre-processed using tokenisation, nor-\nmalisation and stemming techniques. The process of converting sentences into\nsingle word or token is called tokenisation. For example, ”The movie is great”\nis changed to ”The”, ”movie”, ”is”, ”great” [25]. There are some words which\ncontain numbers. For example, ”great” is written as ”gr8” or ”gooood” as\nwritten as ”good” . The normalisation is used to convert these words into nor-\nmal forms [21]. The process of converting words into their root is called stem-\nming. For example, going was changed to go [15]. Words were converted into\nvectors. The fasttext was used to convert each word into 300-dimensions vec-\ntors. Fasttext is a library for text classiﬁcation and representation [13][18][10].\nFor classiﬁcation, MLP, autoencoders and CNNs have been used. Fig. 1. de-\npicts the modelled MLP architectures. MLP classifer was trained for 100 itera-\ntions [9]. Fig. 2. depicts the modelled autoencoder architecture. Autoencoder is\na feed-forward deep neural network with unsupervised learning and it is used\nfor dimensionality reduction. The autoencoder consists of input, output and\nhidden layers. Autoencoder is used to compress the input into a latent-space\nand then the output is reconstructed [23] [11] [12]. The exploited autoencoder\nmodel is depcited in Fig. 1. The autoencoder consists of one input layer three\nhidden layers (1500, 512, 1500) and an output layer. Convolutional Neural\nNetworks contains three layers (input, hidden and output layer). The hidden\nlayer consists of convolutional layers, pooling layers, fully connected layers and\nnormalisation layer. The hj is denotes the hidden neurons of j, with bias of bj\n, is a weight sum over continuous visible nodes v which is given by:\nhj = bj +\nX\nviwij\n(1)\nThe modelled CNN architecture is depicted in Fig. 3 [12][11]. For CNN mod-\nelling, each utterance was represented as a concatenation vector of constituent\nwords. The network has total 11 layers: 4 convolution layers, 4 max pooling\nand 3 fully connected layers. Convolution layers have ﬁlters of size 2 and with\n15 feature maps. Each convolution layer is followed by a max polling layer\nwith window size 2. The last max pooling layer is followed by fully connected\nlayers of size 5000, 500 and 4. For ﬁnal layer, softmax activation is used.\nExploiting Deep Learning for Persian Sentiment Analysis\n5\nFig. 1. Multilayer Perceptron\nFig. 2. Autoencoder\nTo evaluate the performance of the proposed approach, precision (1), recall\n(2), f-Measure (3), and prediction accuracy (4) have been used as a perfor-\nmance matrices. The experimental results are shown in Table 1, where it can\nbe seen that autoencoders outperformed MLP and CNN outperformed autoen-\ncoders with the highest achieved accuracy of 82.6%.\nPrecision =\nTP\nTP + FP\n(2)\nRecall =\nTP\nTP + FN\n(3)\nF measure = 2 ∗Precision ∗Recall\nPrecision + Recall\n(4)\nAccuracy =\nTP + TN\nTP + TN + FP + FN\n(5)\nwhere TP is denotes true positive, TN is true negative, FP is false positive,\nand FN is false negative.\n6\nK. Dashtipour et al.\nFig. 3. Deep Convolutional Neural Network\n4\nConclusion\nSentiment analysis has been used extensively for a wide of range of real-world\napplications, ranging from product reviews, surveys feedback, to business in-\ntelligence, and operational improvements. However, the majority of research\neﬀorts are devoted to English-language only, where information of great impor-\ntance is also available in other languages. In this work, we focus on developing\nsentiment analysis models for Persian language, speciﬁcally for Persian movie\nreviews. Two deep learning models (deep autoencoders and deep CNNs) are\ndeveloped and compared with the the state-of-the-art shallow MLP based ma-\nchine learning model. Simulations results revealed the outperformance of our\nproposed CNN model over autoencoders and MLP. In future, we intend to ex-\nploit more advanced deep learning models such as Long Short-Term Memory\n(LSTM) and LSTM-CNNs to further evaluate the performance of our devel-\noped novel Persian dataset.\n5\nAcknowledgment\nAmir Hussain and Ahsan Adeel were supported by the UK Engineering and\nPhysical Sciences Research Council (EPSRC) grant No.EP/M026981/1.\nExploiting Deep Learning for Persian Sentiment Analysis\n7\nMLP\nPrecision Recall F-measure Accuracy (%)\nNegative 0.78\n0.76\n0.77\nPositive 0.79\n0.81\n0.8\nAVG\n0.78\n0.78\n0.78\n78.49\nMLP-Autoencoder\nPrecision Recall F-measure Accuracy (%)\nNegative 0.78\n0.81\n0.79\nPositive 0.82\n0.8\n0.81\nAVG\n0.8\n0.8\n0.8\n80.08\n1D-CNN\nPrecision Recall F-measure Accuracy (%)\nNegative 0.90\n0.78\n0.83\nPositive 0.77\n0.89\n0.82\nAVG\n0.84\n0.83\n0.83\n82.86\nTable 1. Results: MLP vs. Autoencoder vs. Convolutional Neural Network\nReferences\n1. AP, S.C., Lauly, S., Larochelle, H., Khapra, M., Ravindran, B., Raykar, V.C.,\nSaha, A.: An autoencoder approach to learning bilingual word representations.\nIn: Advances in Neural Information Processing Systems. pp. 1853–1861 (2014)\n2. Cambria, E., Poria, S., Hazarika, D., Kwok, K.: Senticnet 5: discovering concep-\ntual primitives for sentiment analysis by means of context embeddings. In: AAAI\n(2018)\n3. Chen, M., Xu, Z., Weinberger, K., Sha, F.: Marginalized denoising autoencoders\nfor domain adaptation. arXiv preprint arXiv:1206.4683 (2012)\n4. Dai, A.M., Le, Q.V.: Semi-supervised sequence learning. In: Advances in Neural\nInformation Processing Systems. pp. 3079–3087 (2015)\n5. Dashtipour, K., Gogate, M., Adeel, A., Algaraﬁ, A., Durrani, T., Hussain, A.:\nComparative study of persian sentiment analysis based on diﬀerent feature com-\nbinations. In: Communications, Signal Processing, and Systems. CSPS 2017. Lec-\nture Notes in Electrical Engineering, vol 463. pp. 2288–2294. Springer (2017)\n6. Dashtipour, K., Gogate, M., Adeel, A., Algaraﬁ, A., Howard, N., Hussain, A.:\nPersian named entity recognition. In: Cognitive Informatics & Cognitive Com-\nputing (ICCI* CC), 2017 IEEE 16th International Conference on. pp. 79–83.\nIEEE (2017)\n7. Dashtipour, K., Hussain, A., Zhou, Q., Gelbukh, A., Hawalah, A.Y., Cambria,\nE.: Persent: a freely available persian sentiment lexicon. In: International Confer-\nence on Brain Inspired Cognitive Systems. pp. 310–320. Springer (2016)\n8. Dashtipour, K., Poria, S., Hussain, A., Cambria, E., Hawalah, A.Y., Gelbukh,\nA., Zhou, Q.: Multilingual sentiment analysis: state of the art and independent\ncomparison of techniques. Cognitive computation 8(4), 757–771 (2016)\n9. Gardner, M.W., Dorling, S.: Artiﬁcial neural networks (the multilayer percep-\ntron)a review of applications in the atmospheric sciences. Atmospheric environ-\nment 32(14-15), 2627–2636 (1998)\n10. Gasparini, S., Campolo, M., Ieracitano, C., Mammone, N., Ferlazzo, E., Sueri,\nC., Tripodi, G.G., Aguglia, U., Morabito, F.C.: Information theoretic-based in-\n8\nK. Dashtipour et al.\nterpretation of a deep neural network approach in diagnosing psychogenic non-\nepileptic seizures. Entropy 20(2), 43 (2018)\n11. Gogate, M., Adeel, A., Hussain, A.: Deep learning driven multimodal fusion for\nautomated deception detection. In: Computational Intelligence (SSCI), 2017\nIEEE Symposium Series on. pp. 1–6. IEEE (2017)\n12. Gogate, M., Adeel, A., Hussain, A.: A novel brain-inspired compression-based\noptimised multimodal fusion for emotion recognition. In: Computational Intelli-\ngence (SSCI), 2017 IEEE Symposium Series on. pp. 1–7. IEEE (2017)\n13. Joulin, A., Grave, E., Bojanowski, P., Douze, M., J´egou, H., Mikolov, T.: Fast-\ntext.zip: Compressing text classiﬁcation models. arXiv preprint arXiv:1612.03651\n(2016)\n14. Kim, Y.: Convolutional neural networks for sentence classiﬁcation. arXiv\npreprint arXiv:1408.5882 (2014)\n15. Korenius, T., Laurikkala, J., J¨arvelin, K., Juhola, M.: Stemming and lemmatiza-\ntion in the clustering of ﬁnnish text documents. In: Proceedings of the thirteenth\nACM international conference on Information and knowledge management. pp.\n625–633. ACM (2004)\n16. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. nature 521(7553), 436 (2015)\n17. Mesnil, G., Mikolov, T., Ranzato, M., Bengio, Y.: Ensemble of generative and\ndiscriminative techniques for sentiment analysis of movie reviews. arXiv preprint\narXiv:1412.5335 (2014)\n18. Morabito, F.C., Campolo, M., Ieracitano, C., Ebadi, J.M., Bonanno, L., Bra-\nmanti, A., Desalvo, S., Mammone, N., Bramanti, P.: Deep convolutional neural\nnetworks for classiﬁcation of mild cognitive impaired and alzheimer’s disease pa-\ntients from scalp eeg recordings. In: Research and Technologies for Society and\nIndustry Leveraging a better tomorrow (RTSI), 2016 IEEE 2nd International\nForum on. pp. 1–6. IEEE (2016)\n19. Ren, J., Jiang, J.: Hierarchical modeling and adaptive clustering for real-time\nsummarization of rush videos. IEEE Transactions on Multimedia 11(5), 906–917\n(2009)\n20. Ren, J., Jiang, J., Feng, Y.: Activity-driven content adaptation for eﬀective video\nsummarization. Journal of Visual Communication and Image Representation\n21(8), 930–938 (2010)\n21. Reynolds, D.A.: Comparison of background normalization methods for text-\nindependent speaker veriﬁcation. In: Fifth European Conference on Speech Com-\nmunication and Technology (1997)\n22. Scheible, C., Sch¨utze, H.: Cutting recursive autoencoder trees. arXiv preprint\narXiv:1301.2811 (2013)\n23. Semeniuta, S., Severyn, A., Barth, E.: A hybrid convolutional variational autoen-\ncoder for text generation. arXiv preprint arXiv:1702.02390 (2017)\n24. Su, J., Wu, S., Zhang, B., Wu, C., Qin, Y., Xiong, D.: A neural generative au-\ntoencoder for bilingual word embeddings. Information Sciences 424, 287–300\n(2018)\n25. Sumathy, K., Chidambaram, M.: Text mining: concepts, applications, tools and\nissues-an overview. International Journal of Computer Applications 80(4) (2013)\n26. Sun, X., Li, C., Ren, F.: Sentiment analysis for chinese microblog based on deep\nneural networks with convolutional extension features. Neurocomputing 210,\n227–236 (2016)\n27. Tan, S.S., Na, J.C.: Mining semantic patterns for sentiment analysis of prod-\nuct reviews. In: International Conference on Theory and Practice of Digital Li-\nbraries. pp. 382–393. Springer (2017)\nExploiting Deep Learning for Persian Sentiment Analysis\n9\n28. Zhai, S., Zhang, Z.M.: Semisupervised autoencoder for sentiment analysis. In:\nAAAI. pp. 1394–1400 (2016)\n29. Zhang, P., Komachi, M.: Japanese sentiment classiﬁcation with stacked denoising\nauto-encoder using distributed word representation. In: Proceedings of the 29th\nPaciﬁc Asia Conference on Language, Information and Computation. pp. 150–\n159 (2015)\n30. Zhou, H., Chen, L., Shi, F., Huang, D.: Learning bilingual sentiment word em-\nbeddings for cross-language sentiment classiﬁcation. In: Proceedings of the 53rd\nAnnual Meeting of the Association for Computational Linguistics and the 7th\nInternational Joint Conference on Natural Language Processing (Volume 1: Long\nPapers). vol. 1, pp. 430–440 (2015)\n",
  "categories": [
    "cs.CL",
    "I.2.7; I.5.0"
  ],
  "published": "2018-08-15",
  "updated": "2018-08-15"
}