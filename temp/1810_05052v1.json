{
  "id": "http://arxiv.org/abs/1810.05052v1",
  "title": "Deep Learning for Image Denoising: A Survey",
  "authors": [
    "Chunwei Tian",
    "Yong Xu",
    "Lunke Fei",
    "Ke Yan"
  ],
  "abstract": "Since the proposal of big data analysis and Graphic Processing Unit (GPU),\nthe deep learning technology has received a great deal of attention and has\nbeen widely applied in the field of imaging processing. In this paper, we have\nan aim to completely review and summarize the deep learning technologies for\nimage denoising proposed in recent years. Morever, we systematically analyze\nthe conventional machine learning methods for image denoising. Finally, we\npoint out some research directions for the deep learning technologies in image\ndenoising.",
  "text": "arXiv:1810.05052v1  [cs.CV]  11 Oct 2018\nDeep Learning for Image Denoising: A Survey\nChunwei Tian 1,2, Yong Xu 1,2,*, Lunke Fei3, and Ke Yan1,2\n1. Bio-Computing Research Center, Harbin Institute of Technology, Shenzhen,\nShenzhen. 518055 Guangdong, China\n2. Shenzhen Medical Biometrics Perception and Analysis Engineering Laboratory,\nShenzhen, Shenzhen. 518055 Guangdong, China\n3. School of Computers, Guangdong University of Technology, Guangzhou 510006,\nChina\n{chunweitian@163.com,yongxu@ymail.com,flksxm@126.com,yanke401@163.com}\nAbstract. Since the proposal of big data analysis and Graphic Process-\ning Unit (GPU), the deep learning technology has received a great deal of\nattention and has been widely applied in the ﬁeld of imaging processing.\nIn this paper, we have an aim to completely review and summarize the\ndeep learning technologies for image denoising proposed in recent years.\nMorever, we systematically analyze the conventional machine learning\nmethods for image denoising. Finally, we point out some research di-\nrections for the deep learning technologies in image denoising. abstract\nenvironment.\nKeywords: Deep Learning, Convolution neural networks, GPU; Image\nDenoising.\n1\nIntroduction\nImage processing has numerous applications including image segmentation [28],\nimage classiﬁcation [25,38,32,12], object detection [13], video tracking [36], im-\nage restoration [48] and action recognition [35]. Especially, the image denoising\ntechnology is one of the most important branches of image processing technolo-\ngies and is used as an ex-ample to show the development of the image processing\ntechnologies in last 20 years [42]. Buades et al. [5] proposed a non-local algorithm\nmethod to deal with image denoising. Lan et al. [19] fused the belief propagation\ninference method and Markov Random Fields (MRFs) to address image denois-\ning. Dabov et al. [9] proposed to transform grouping similar two-dimensional im-\nage fragments into three-dimensional data arrays to improve sparisty for image\ndenoising. These selection and extraction methods have amazing performance for\nimage denoising. However, the conventional methods have two challenges [45].\nFirst, these methods are non-convex, which need to manually set parameters.\nSecond, these methods refer a complex optimization problem for the test stage,\nresulting in high computational cost.\nIn recent years, researches have shown that deep learning technologies can\nreply to deeper architecture to automatically learn and ﬁnd more suitable image\n2\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\nfeatures rather than manual setting parameters, which eﬀectively address draw-\nbacks of traditional methods mentioned above [18]. Big data and GPU are also\nessential for deep learning technologies to improve the learning ability [16]. The\nlearning ability of deep learning is ﬁnished by model (also referred to as network)\nand the model consists of many layers, including the convolutional layer, pooling\nlayer, batch normalization layer and full connection layer. In other words, deep\nlearning technologies can convert input data (e.g. images, speech and video) into\noutputs (e.g. object category, password unlocking and traﬃc information) by the\nmodel [24]. Especially, convolutional neural network (CNN) is one of the most\ntypical and successful deep learning network for image processing [20]. CNN was\noriginated LeNet from 1998 and it was successfully used in hand-written digit\nrecognition, achieving excellent performance [21]. However, convolutional neural\nnetworks (CNNs) havent been widely used in other real applications before the\narise of GPU and big data. In other words, the real success of CNNs attributed\nto ImageNet Large Scale Visual Recognition Challenge 2012 (ILSVRC 2012)\nwhere new CNN was proposed, named AlexNet and became a world champion\nin this ILSVRC 2012 [18,43].\nIn subsequent years, deeper neural networks have becoming popular and ob-\ntain promising performance for image processing [29]. Karen Simonyan et al. [29]\nin-creased the depth of neural networks to 16-19 weighted layers and convolution\nﬁlter size of each layer was 3 × 3 for image recognition. Christian Szegedy et\nal. [30] provided a mechanism by using sparsely connected layer [2] instead of\nfully connected layers to increase the width and depth of the neural networks for\nimage classiﬁcation, named as Inception V1. Inception V1 eﬀectively prevented\nto overﬁtting from enlarged size (width) of network and reduced the computing\nresource from increased depth of network. Previous researches show that the\ndeep networks essentially use an end-to-end multilayer fashion to fuse diﬀerent\nlevel fashion [17] and classiﬁers and the extracted features can be more robust\nby increasing the number of depth in networks. Despite deep networks have\nobtained successfully applications for image processing [27] , they can generate\nvanishing gradient or exploding gradient [4] with increased network depth. That\nmakes network hamper convergence. This problem can be solved by normalized\ninitialization [39]. However, when deeper neural networks get to converge, net-\nworks are saturated and degrade quickly with increasing depth of networks. The\nappearance of residual network eﬀectively dealt with problems above for im-\nage recognition [15]. ResNeXt method is tested to be very eﬀectively for image\nclassiﬁcation [40]. Spatial-temporal Attention (SPA) method is very competitive\nfor visual tracking [50]. Residual Dense Network (RDN) is also an eﬀective tool\nfor image super-resolution [49]. Furthermore, DiracNets [44], IndRNN [23] and\nvaria-tional U-Net [11] also provide us with many competitive technologies for\nimage pro-cessing. These deep networks are also widely applied in image de-\nnoising, which is the branch of image processing technologies. For example, the\ncombination of kernel-prediction net and CNN is used to obtain denoised image\n[3]. BMCNN utilizes NSS and CNN to deal with image denoising [1]. GAN is\nused to remove noise from noisy image [33].\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\n3\nAlthough the researches above expose that deep learning technologies have\nob-tained enormous success in the applications of image denoising, to own knowl-\nedge, there is no comparative study of deep learning technologies for image\ndenoising. Deep learning technologies refer to properties of image denosing to\npropose wise solution methods, which are embedded in multiple hidden layers\nwith end-end con-nection to better deal with them. Therefore, a survey is im-\nportant and necessary to review the principles, performance, diﬀerence, merits,\nshortcomings and technical potential for image processing. Deeper CNNs (e.g.\nAlexNet, GoogLeNet, VGG and ResNet), which can show the ideas of deep learn-\ning technologies and successful rea-sons for image denoising. To better show the\nrobustness of deep learning denoising, the performance of deep learning for im-\nage denoising is shown. The potential chal-lenges and directions of deep learning\ntechnologies for image denoising in the future are also oﬀered in this paper.\nThe remainder of this paper is organized as follows. Section 2 overviews of\ntypical deep learning methods. Section 3 provides deep learning technologies for\nimage de-noising. Section 4 points out some potential research directions. Section\n6 presents the conclusions of this paper.\n2\nTypical deep network\nNowadays, the most widely used model is trained with end-to-end in a supervised\nfashion, which is easy and simple to implement to train models. The popular\nnetwork architecture is CNNs (ResNet). This network is widely used to deal with\napplications of image processing and obtain enormous success. The following\nsections will show the popular deep learning technology, discuss the merits and\ndiﬀerences of the meth-od in Section 2.\n2.1\nResNet\nDeep CNNs have result in a lot of breakthroughs for image recognition. Espe-\ncially, deep network plays an important role on image classiﬁcation [30]. Many\nother visual recognition applications are beneﬁcial from deep networks. However,\ndeeper network can have vanishing/exploding gradients [30]. This problem has\nbeen eﬀectively solved by normalized initialization [33], which makes the network\nconverge. When this network starts converging, performance of the network gets\ndegraded. For exam-ple, the depth of this network are increased, the errors in the\ntraining model are in-creasing. The problem is eﬀectively addressed by ResNet\n[15]. The ideas of ResNet are that outputs of each two layers and their inputs\nare added as the new input. ResNet include many blocks and the block is shown\nin Fig.1, where x and f , respectively, denote input and activation function.\nA residual block is obtained by f(x) + x . The ResNet is popular based on\nthe following reasons. First, ResNet is deep rather than width, which eﬀectively\ncontrols the number of parameters and overcomes the overﬁtting problem. Sec-\nond, it uses less pooling layers and more downsampling operations to improve\ntransmission eﬃciency. Third, it uses BN and average pooling for regularization,\n4\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\nwhich accelerate the speed of training model. Finally, it uses 3 × 3 ﬁlters of each\nconvolutional layer to train model, which is faster than using the combination\nof 3 × 3 and 1 × 1 ﬁlters. As a result, ResNest takes the ﬁrst place in ILSVRC\n2015 and reduces 3.57% error on the ImageNet test set.\nIn addition, deformation networks of Residual network are popular and have\nbeen widely used in image classiﬁcation, image denoising [41] and image resolu-\ntion [31].\nWeight layer  \nWeight layer \nRelu\nx\nRelu\nX\nidentity\nF(x)\nF(x)+x\nFig. 1. Residual network: a building block\n3\nImage Denoising\nImage denoising is topic applications for image processing. We take image de-\nnoising as an example to show the performance and principle for deep learning\ntech-nologies in image processing applications.\nThe aim of image denoising is to obtain clean image x from a noisy image y\nwhich is explained by y = x + n. n denotes the additive white Gaussian noise\n(AWGN) with variance σ2 . From the machine learning knowledge, we know that\nthe image prior is an important for image denoising. In the past ten years, a lot of\nmethods are proposed for model with image priors, such as Markov random ﬁled\n(MRF) method [19], BM3D [9], NCSR [10] and NSS [6]. Although these methods\nperform well for image denoising, they have two drawbacks. First, these methods\nneed to optimize, which results in increasing computational cost. Second, these\nmethods are non-convex, which need manual settings to improve performance.\nTo address the problems, some discriminative learning schemes were proposed.\nA trainable nonlinear reaction diﬀusion method was proposed and used to learn\nimage prior [26]. A cascade of shrinkage ﬁelds fuse the random ﬁeld-based model\nand half-quadratic algorithm into a single architecture [46]. Despite methods\nimprove the performances for image denoising, they are limited to the speciﬁed\nforms of prior. Another shortcoming is that these methods cant use a model to\ndeal with blind image denoising.\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\n5\nDeep learning technologies can eﬀectively deal with problems above. And\ndeep learning technologies are chosen for image denoising based on the following\nthree-fold. First, they have deep architecture, which can learn more extractions.\nSecond, BN and ReLu are added into deep architectures, which can accelerate\nthe training speed. Third, networks of deep learning methods can run on GPU,\nwhich can train more samples and improve the eﬃciency. The proposed DnCNN\n[45] uses BN and ResNet to perform image denoising. This network not only\ndeals with blind image denoising, but also addresses image super-resolution task\nand JPEG image deblocking. Its architecture is as shown in Fig. 2. Speciﬁcally, it\nobtains the residual image from the model and it needs to use y = x+n to obtain\nclean image when it is in the test phase. It obtained PSNR of 29.13, which is\nhigher than the state-of-the-art BM3D method of 28.57 for BSD68 dataset with\nσ = 25.\nFig. 2. The architecture of DnCNN\nFig. 3. Results of CBM3D and FFDNet for color image denoising (a)Noisy(σ=35)\n(b)CBM3D(29.90dB) (c)FFDNet(30.51dB)\nFFDNet [46] uses noise level map and noisy image as input to deal with\ndiﬀerent noise levels. This method exploits a single model to deal with multi-\nple noise levels. It is also faster than BM3D on GPU and CPU. As shown in\n6\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\nFig.3, performance of FFDNet outperforms the CBM3D [19] method in image\ndenoising. IRCNN [47] fuses the model-based optimization method and CNN to\naddress image denoising problem, which can deal with diﬀerent inverse problems\nand multiple tasks with one single mode. In addition, it adds dilated convolution\ninto network, which improves the per-formance for denoising. Its architecture is\nshown as Fig. 4.\nFig. 4. The architecture of IRCNN\nIn addition, many other methods also obtain well performance for image\ndenoising. For example, fusion of the dilated convolution and ResNet is used for\nimage denoising [37]. It is a good choice for combing disparate sources of experts\nfor image denosing [8]. Universal denoising networks [22] for image denoising and\ndeep CNN denoiser prior to eliminate multicative noise [34] are also eﬀective for\nimage denoising. As shown in Table 1, deep learning methods are superior to the\nconverntional methods. And the DnCNN method obtains excellent performance\nfor image denoising.\nTable 1. Comparisons of diﬀerent methods with σ = 25 for image denoising.\nMethods\nPSNR Dataset\nBM3D [9]\n28.57 BSD68\nWNNM [14] 28.83 BSD68\nTNRD [7]\n28.92 BSD68\nDnCNN [45] 29.23 BSD68\nFFDNet [46] 29.19 BSD68\nIRCNN [47] 29.15 BSD68\nDDRN [37]\n29.18 BSD68\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\n7\n4\nResearch directions\n4.1\nThe challenges of deep learning technologies in image denoising\nAccording to existing researches, deep learning technologies achieve promising\nresults in image denoising. However, these technologies also suﬀer from some\nchallenges as follows. (1) Current deep learning denoising methods only deal with\nAWGN, which are not eﬀective for real noisy images, such as low light images.\n(2) They cant use a model to deal with all the low level vision tasks, such as\nimage denoising, image super-resolution, image blurring and image deblocking.\n(3) They cant use a model to address the blind Gaussian noise.\n4.2\nSome potential directions of deep learning technologies for\nimage denoising\nAccording to the previous researches, deep learning technologies have the follow-\ning changes for image denoising application above. First, deep learning technolo-\ngies design diﬀerent network architectures to deal with tasks above. Second, they\ncan fuse the optimization and discrimination methods. Third, they can use mul-\ntiple tasks to design the network. Fourth, they can change the input of the neural\nnetworks.\n5\nConclusion\nThis paper ﬁrst comprehensively introduces the development of deep learning\ntechnologies on image processing applications. And then shows the implementa-\ntions of typical CNNs. After that, image denoising is illustrated in detail, which\nconcludes the diﬀerences and ideas of diﬀerent methods for image denoising in\nreal world. Finally, this paper shows the challenges of deep learning methods for\nimage processing applications and oﬀers solutions. This review oﬀers important\ncues on deep learning technologies for image processing applications. We believe\nthat this paper could pro-vide researchers with a useful guideline working in the\nrelated ﬁelds, especially for the beginners worked in deep-learning.\n6\nAcknowledgment\nThis paper was supported in part by Shenzhen Municipal Science and Technol-\nogy Innovation Council under Grant no. JCYJ20170811155725434, in part by\nthe National Natural Science Foundation under Grant no. 61876051.\nReferences\n1. Byeongyong Ahn and Nam Ik Cho. Block-matching convolutional neural network\nfor image denoising. arXiv preprint arXiv:1704.00524, 2017.\n8\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\n2. Sanjeev Arora, Aditya Bhaskara, Rong Ge, and Tengyu Ma.\nProvable bounds\nfor learning some deep representations. In International Conference on Machine\nLearning, pages 584–592, 2014.\n3. Steve Bako, Thijs Vogels, Brian McWilliams, Mark Meyer, Jan Nov´ak, Alex\nHarvill, Pradeep Sen, Tony Derose, and Fabrice Rousselle. Kernel-predicting con-\nvolutional networks for denoising monte carlo renderings.\nACM Trans. Graph,\n36(4):97, 2017.\n4. Yoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long-term depen-\ndencies with gradient descent is diﬃcult. IEEE transactions on neural networks,\n5(2):157–166, 1994.\n5. Antoni Buades, Bartomeu Coll, and J-M Morel. A non-local algorithm for image\ndenoising. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE\nComputer Society Conference on, volume 2, pages 60–65. IEEE, 2005.\n6. Antoni Buades, Bartomeu Coll, and Jean-Michel Morel. Nonlocal image and movie\ndenoising. International journal of computer vision, 76(2):123–139, 2008.\n7. Yunjin Chen and Thomas Pock. Trainable nonlinear reaction diﬀusion: A ﬂexible\nframework for fast and eﬀective image restoration. IEEE transactions on pattern\nanalysis and machine intelligence, 39(6):1256–1272, 2017.\n8. Joon Hee Choi, Omar Elgendy, and Stanley H Chan. Integrating disparate sources\nof experts for robust image denoising. arXiv preprint arXiv:1711.06712, 2017.\n9. Kostadin Dabov, Alessandro Foi, Vladimir Katkovnik, and Karen Egiazarian. Im-\nage denoising by sparse 3-d transform-domain collaborative ﬁltering. IEEE Trans-\nactions on image processing, 16(8):2080–2095, 2007.\n10. Weisheng Dong, Lei Zhang, Guangming Shi, and Xin Li. Nonlocally centralized\nsparse representation for image restoration. IEEE Transactions on Image Process-\ning, 22(4):1620–1630, 2013.\n11. Patrick Esser, Ekaterina Sutter, and Bj¨orn Ommer. A variational u-net for condi-\ntional appearance and shape generation. In Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition, pages 8857–8866, 2018.\n12. Lunke Fei, Guangming Lu, Wei Jia, Shaohua Teng, and David Zhang. Feature\nextraction methods for palmprint recognition: A survey and evaluation.\nIEEE\nTransactions on Systems, Man, and Cybernetics: Systems, 2018.\n13. Ross Girshick, JeﬀDonahue, Trevor Darrell, and Jitendra Malik.\nRich feature\nhierarchies for accurate object detection and semantic segmentation. In Proceedings\nof the IEEE conference on computer vision and pattern recognition, pages 580–587,\n2014.\n14. Shuhang Gu, Lei Zhang, Wangmeng Zuo, and Xiangchu Feng. Weighted nuclear\nnorm minimization with application to image denoising.\nIn Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, pages 2862–2869,\n2014.\n15. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning\nfor image recognition. In Proceedings of the IEEE conference on computer vision\nand pattern recognition, pages 770–778, 2016.\n16. Qibin Hou, Ming-Ming Cheng, Xiaowei Hu, Ali Borji, Zhuowen Tu, and Philip\nTorr. Deeply supervised salient object detection with short connections. In 2017\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages\n5300–5309. IEEE, 2017.\n17. Sergey\nIoﬀe\nand\nChristian\nSzegedy.\nBatch\nnormalization:\nAccelerating\ndeep network training by reducing internal covariate shift.\narXiv preprint\narXiv:1502.03167, 2015.\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\n9\n18. Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet classiﬁcation\nwith deep convolutional neural networks. In Advances in neural information pro-\ncessing systems, pages 1097–1105, 2012.\n19. Xiangyang Lan, Stefan Roth, Daniel Huttenlocher, and Michael J Black. Eﬃcient\nbelief propagation with learned higher-order markov random ﬁelds. In European\nconference on computer vision, pages 269–282. Springer, 2006.\n20. Steve Lawrence, C Lee Giles, Ah Chung Tsoi, and Andrew D Back. Face recog-\nnition: A convolutional neural-network approach.\nIEEE transactions on neural\nnetworks, 8(1):98–113, 1997.\n21. Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E\nHoward, Wayne Hubbard, and Lawrence D Jackel. Backpropagation applied to\nhandwritten zip code recognition. Neural computation, 1(4):541–551, 1989.\n22. Stamatios Lefkimmiatis. Universal denoising networks: A novel cnn architecture\nfor image denoising. In Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition, pages 3204–3213, 2018.\n23. Shuai Li, Wanqing Li, Chris Cook, Ce Zhu, and Yanbo Gao. Independently recur-\nrent neural network (indrnn): Building a longer and deeper rnn. In Proceedings of\nthe IEEE Conference on Computer Vision and Pattern Recognition, pages 5457–\n5466, 2018.\n24. Geert Litjens, Thijs Kooi, Babak Ehteshami Bejnordi, Arnaud Arindra Adiyoso\nSetio, Francesco Ciompi, Mohsen Ghafoorian, Jeroen AWM van der Laak, Bram\nVan Ginneken, and Clara I S´anchez. A survey on deep learning in medical image\nanalysis. Medical image analysis, 42:60–88, 2017.\n25. Yongbin Qin and Chunwei Tian. Weighted feature space representation with kernel\nfor image classiﬁcation. Arabian Journal for Science and Engineering, pages 1–13,\n2017.\n26. Uwe Schmidt and Stefan Roth. Shrinkage ﬁelds for eﬀective image restoration. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition,\npages 2774–2781, 2014.\n27. Pierre Sermanet, David Eigen, Xiang Zhang, Micha¨el Mathieu, Rob Fergus, and\nYann LeCun. Overfeat: Integrated recognition, localization and detection using\nconvolutional networks. arXiv preprint arXiv:1312.6229, 2013.\n28. Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE\nTransactions on pattern analysis and machine intelligence, 22(8):888–905, 2000.\n29. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for\nlarge-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.\n30. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir\nAnguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going\ndeeper with convolutions.\nIn Proceedings of the IEEE conference on computer\nvision and pattern recognition, pages 1–9, 2015.\n31. Ying Tai, Jian Yang, Xiaoming Liu, and Chunyan Xu.\nMemnet: A persistent\nmemory network for image restoration. In Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition, pages 4539–4547, 2017.\n32. Chunwei Tian, Qi Zhang, Guanglu Sun, Zhichao Song, and Siyan Li.\nFft con-\nsolidated sparse and collaborative representation for image classiﬁcation. Arabian\nJournal for Science and Engineering, 43(2):741–758, 2018.\n33. Subarna Tripathi, Zachary C Lipton, and Truong Q Nguyen. Correction by pro-\njection: Denoising images with generative adversarial networks.\narXiv preprint\narXiv:1803.04477, 2018.\n10\nDLIDS: Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan\n34. Guodong Wang, GuoTao Wang, Zhenkuan Pan, and Zhimei Zhang. Multiplicative\nnoise removal using deep cnn denoiser prior. In Intelligent Signal Processing and\nCommunication Systems (ISPACS), 2017 International Symposium on, pages 1–6.\nIEEE, 2017.\n35. Heng Wang, Alexander Kl¨aser, Cordelia Schmid, and Cheng-Lin Liu. Action recog-\nnition by dense trajectories. In Computer Vision and Pattern Recognition (CVPR),\n2011 IEEE Conference on, pages 3169–3176. IEEE, 2011.\n36. Li Wang, Ting Liu, Gang Wang, Kap Luk Chan, and Qingxiong Yang. Video track-\ning using learned hierarchical features. IEEE Transactions on Image Processing,\n24(4):1424–1435, 2015.\n37. Tianyang Wang, Mingxuan Sun, and Kaoning Hu. Dilated residual network for\nimage denoising. arXiv preprint arXiv:1708.05473, 2017.\n38. Jie Wen, Xiaozhao Fang, Yong Xu, Chunwei Tian, and Lunke Fei.\nLow-rank\nrepresentation with adaptive graph regularization. Neural Networks, 108:83–96,\n2018.\n39. Yuxin\nWu\nand\nKaiming\nHe.\nGroup\nnormalization.\narXiv\npreprint\narXiv:1803.08494, 2018.\n40. Saining Xie, Ross Girshick, Piotr Doll´ar, Zhuowen Tu, and Kaiming He. Aggre-\ngated residual transformations for deep neural networks. In Computer Vision and\nPattern Recognition (CVPR), 2017 IEEE Conference on, pages 5987–5995. IEEE,\n2017.\n41. Weiying Xie, Yunsong Li, and Xiuping Jia.\nDeep convolutional networks with\nresidual learning for accurate spectral-spatial denoising. Neurocomputing, 2018.\n42. Jun Xu, Lei Zhang, Wangmeng Zuo, David Zhang, and Xiangchu Feng. Patch group\nbased nonlocal self-similarity prior learning for image denoising. In Proceedings of\nthe IEEE international conference on computer vision, pages 244–252, 2015.\n43. Yang You, Zhao Zhang, Cho-Jui Hsieh, James Demmel, and Kurt Keutzer. 100-\nepoch imagenet training with alexnet in 24 minutes. ArXiv e-prints, 2017.\n44. Sergey Zagoruyko and Nikos Komodakis.\nDiracnets: training very deep neural\nnetworks without skip-connections. arXiv preprint arXiv:1706.00388, 2017.\n45. Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang. Beyond\na gaussian denoiser: Residual learning of deep cnn for image denoising.\nIEEE\nTransactions on Image Processing, 26(7):3142–3155, 2017.\n46. Kai Zhang, Wangmeng Zuo, and Lei Zhang. Ffdnet: Toward a fast and ﬂexible\nsolution for cnn based image denoising. IEEE Transactions on Image Processing,\n2018.\n47. Kai Zhang, Wangmeng Zuo, and Lei Zhang. Learning a single convolutional super-\nresolution network for multiple degradations. In IEEE Conference on Computer\nVision and Pattern Recognition, volume 6, 2018.\n48. Lei Zhang and Wangmeng Zuo. Image restoration: From sparse and low-rank priors\nto deep priors. IEEE Signal Processing Magazine, 34(5):172–179, 2017.\n49. Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong, and Yun Fu. Residual dense\nnetwork for image super-resolution. In The IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 2018.\n50. Zheng Zhu, Wei Wu, Wei Zou, and Junjie Yan. End-to-end ﬂow correlation tracking\nwith spatial-temporal attention. illumination, 42:20, 2017.\n",
  "categories": [
    "cs.CV"
  ],
  "published": "2018-10-11",
  "updated": "2018-10-11"
}