{
  "id": "http://arxiv.org/abs/1810.06665v1",
  "title": "Stop Illegal Comments: A Multi-Task Deep Learning Approach",
  "authors": [
    "Ahmed Elnaggar",
    "Bernhard Waltl",
    "Ingo Glaser",
    "Jörg Landthaler",
    "Elena Scepankova",
    "Florian Matthes"
  ],
  "abstract": "Deep learning methods are often difficult to apply in the legal domain due to\nthe large amount of labeled data required by deep learning methods. A recent\nnew trend in the deep learning community is the application of multi-task\nmodels that enable single deep neural networks to perform more than one task at\nthe same time, for example classification and translation tasks. These powerful\nnovel models are capable of transferring knowledge among different tasks or\ntraining sets and therefore could open up the legal domain for many deep\nlearning applications. In this paper, we investigate the transfer learning\ncapabilities of such a multi-task model on a classification task on the\npublicly available Kaggle toxic comment dataset for classifying illegal\ncomments and we can report promising results.",
  "text": "Stop Illegal Comments: A Multi-Task\nDeep Learning Approach\nAhmed ELNAGGAR 1, Bernhard WALTL a, Ingo GLASER a, J¨org LANDTHALER a,\nElena SCEPANKOVA a and Florian MATTHES a\naSoftware Engineering for Business Information Systems, Technische Universit¨at\nM¨unchen, Germany\nAbstract. Deep learning methods are often difﬁcult to apply in the legal domain\ndue to the large amount of labeled data required by deep learning methods. A recent\nnew trend in the deep learning community is the application of multi-task mod-\nels that enable single deep neural networks to perform more than one task at the\nsame time, for example classiﬁcation and translation tasks. These powerful novel\nmodels are capable of transferring knowledge among different tasks or training\nsets and therefore could open up the legal domain for many deep learning applica-\ntions. In this paper, we investigate the transfer learning capabilities of such a multi-\ntask model on a classiﬁcation task on the publicly available Kaggle toxic comment\ndataset for classifying illegal comments and we can report promising results.\nKeywords. Multi-Task Deep Learning, Deep Learning, Text Classiﬁcation\n1. Introduction\nThe analysis of textual documents is an important task in the legal domain [1]. A plethora\nof different use cases exist, that heavily rely on analysis and inspection of documents.\nThe importance is not restricted to legal research tasks, such as the analysis of statutory\ntexts, judgments, or contracts, but also includes reviewing the content of text documents\nwith regard to facts and evidences [1]. More and more pieces of circumstantial evidence\nare discovered using technology, especially when it comes up to inspect huge document\ncorpora. The ﬁeld of e-Discovery, forensics, legal reasoning and argument mining, and\ninformation extraction (IE) is well-studied and established in the ﬁeld of legal informatics\n[2]. Especially the usage during due diligence is highly attractive as it helps to save\nvaluable resources, such as money and time.\nTechnology assists human experts during complex discovery tasks to ﬁnd the “nee-\ndle in the haystack”. Methods and software tools have been used successfully to detect\ncrime such as organized manipulation, e.g., analysis of a very large collection of e-mails\nduring the VW scandal of manipulated software, or to automatically unveil discrimina-\ntion in the internet. The latter is especially relevant for social media platforms but also for\ne-participation initiatives. The past has shown, that anonymity within the internet attracts\n1Corresponding Author: Ahmed Elnaggar, Software Engineering for Business Information Systems,\nBoltzmannstr. 3, 85748 Garching bei M¨unchen, Germany; E-mail: ahmed.elnaggar@tum.de.\narXiv:1810.06665v1  [cs.IR]  15 Oct 2018\nusers for inappropriate, unconstitutional and illegal comments. For example, extremist\nstatements, threats, insults, and so forth. Online platforms are getting more responsible in\ncharge of the content that users create and share with others. The responsibility to delete\ncomments on request but also to proactively delete illegal comments is more and more\nin the charge of the platform providers, which struggle at this complex and tedious task.\nThis leads to the need of a highly accurate software to perform this task automatically.\nThis paper contributes to the detection and classiﬁcation of statements and com-\nments with regard to their sentimental content. The sentiment analysis is restricted to in-\nspect text with regard to illegal content, such as discrimination. The approach described\nin the paper extends the existing state-of-the-art in the ﬁeld and uses a multi-task learning\narchitecture based on deep learning (DL). The result is relevant for every social media\nplatform that wants to improve compliance by proactively detecting problematic com-\nments and statements.\nThe remainder of the paper is structured as follows: Section 2 describes related work\nand similar approaches in the domain of sentiment analysis to detect illegal statements. It\nalso introduces some recent work on utilizing DL in this matter. Section 3 introduces the\nmulti-label system by describing the dataset that is used, the algorithms, and the topology\nof the architecture. The experimental setup is described in Section 4, while the results are\ndiscussed in Section 5. Based on the results, the limitations and potential arising research\ndirections are described in Section 6.\n2. Related Work\nThe computer-assisted analysis of legal documents is highly relevant and has attracted\nresearchers for quite some time. Sentiment analysis, also called opinion mining, is an\nimportant ﬁeld of research, not only in the legal domain [4]. Pang et al. [11] provide\na comprehensive overview of different approaches to sentiment analysis across various\ndomains. This paper deals with sentiment analysis in comments from various online\nsources in order to detect illegal comments. Hutto & Gilbert [5] came up with a rule\nbased system, called VADER, to analyze social media text. A deep dive on supervised\nsentiment analysis based on various multilingual web texts was made by Boiy & Moens\n[3]. They used hand-crafted features to train three different ML classiﬁers (support vec-\ntor machines (SVM), multinomial naive bayes, and maximum entropy classiﬁer) on the\ngiven task. Even though there are several existing works on this topic, among others\n[6,10,9,14], hardly any attempt has been made in the legal domain by utilizing DL.\n3. Illegal Content Detection System\nIn this section, we are covering the datasets which we used, and a detail description of\nthe Multi-Task Multi-Embedding algorithm that we have used.\n3.1. Datasets\nMulti-Label Illegal Comments: The main dataset was provided by Jigsaw which is a\nteam within Google through one of Kaggle competitions [7]. Each sample has a text\ncomment which is labeled with one or more labels among six labels: Toxic, Severe Toxic,\nObscene, Threat, Insult and Identity Hate. The dataset is divided into a training set and\na test set. The number of samples of the training dataset and test dataset is 159571 and\n63978 respectively. Figure 1 shows the number of multilabel occurrences on the training\ndataset.\nFigure 1. Number of multi-label occurrence on the training dataset\nThe biggest challenge of this dataset is imbalance class distribution, where the num-\nber of true classes is between 0.3% and 10%. In these cases most machine learning algo-\nrithms tend to give very high accuracy because it is easier for the algorithms to just pro-\nduce one value either 1 or 0 to minimize the loss function. However, in this case, it cru-\ncially important to predict the toxicity of the comments and not just predict every com-\nment as clean comment. This is a major problem in the legal domain where the number\nof positive or negative samples for many problems are very low. In Figure 2, the number\nof comments occurrence of each class on the training dataset is presented. For example,\nthe number of threat comments is about 0.3% which make it difﬁcult for the algorithm\nto predict it correctly.\nThe dataset contains text from various languages. The top 30 unicode scripts occur-\nrence on the training dataset is presented in Table 1. This is another problem since most\nof the modern machine learning algorithm uses speciﬁc language word representations\nlike word embedding. Which means the model will just set all the other languages words\nto zero. However, since the number of Non-English comments was less than 0.5% and as\nshown on the word cloud almost all of the major illegal words were in English, we only\nfocused on English comments.\nA word cloud for each class is presented in Figure 3 for the top 1000 word occur-\nrence. Since the illegal comments were collected from wiki page comments, we can no-\ntice that the top keywords on clean comments are ”Wikipedia, page and article”. A sec-\nond example, on ”Identity Hate” class, the top keywords target speciﬁc race or speciﬁc\nFigure 2. Number of comment occurrence on the training dataset for each class\nTable 1. Top 30 unicode scripts occurrence on the train dataset\nLanguage\nOccurrence\nLanguage\nOccurrence\nLanguage\nOccurrence\nLatin\n159564\nBengali\n25\nKannada\n4\nGreek\n456\nRunic\n22\nLao\n4\nHan\n344\nHangul\n21\nGujarati\n3\nCyrillic\n272\nEthiopic\n20\nTelugu\n3\nArabic\n78\nGeorgian\n17\nTibetan\n3\nHiragana\n66\nTamil\n9\nOriya\n2\nKatakana\n55\nThai\n8\nSinhala\n2\nDevanagari\n52\nGurmukhi\n7\nBopomofo\n1\nInherited\n50\nArmenian\n6\nMalayalam\n1\nHebrew\n48\nKhmer\n5\nSyriac\n1\nreligion like ”Nigger or Jew”. A third example, on ”Threat” class, the top keywords were\nlife threatening words like ”Die or Kill”. In Figure 3h, we can see a word cloud of over\nall top 1000 word occurrence, and clearly none of the most occurred words on the six\nlabels appear. This makes the machine learning algorithms difﬁcult to predict them.\nToxic, Attack and Aggression Comments: Additionally, three datasets were used to an-\nalyze if it is beneﬁcial for the main dataset to join training it with these three datasets us-\ning Multi-task training. These speciﬁc datasets were chosen because generally in multi-\ntask training, the closer the tasks the better the results. All of them were also provided\nby Jigsaw team. The number of samples of the toxic, attack and aggression datasets are\n159686, 115864, 115864 samples. These three datasets also suffer from the imbalance\nclass distribution problem.\n(a) Clean\n(b) Toxic\n(c) Severe Toxic\n(d) Obsence\n(e) Threat\n(f) Insult\n(g) Identity Hate\n(h) All Combined\nFigure 3. Single gram word cloud of the top 1000 word occurrence for each comments class\n3.2. Multi-Task Multi-Embedding Model\nFigure 4 shows the Model Architecture, where the model receives four different inputs\nfrom four different datasets (Main Multi-Label Illegal, Toxic, Attack and Aggression)\nand produce four different outputs for each task, while the whole layers are hard shared\namong all tasks [13]. Simply, hard sharing means all the internal learning parameters are\nshared among all tasks. The model can be divided into the following layers:\n3.2.1. Word Representations Layer\nEach input goes through three different word embedding layers (FastTexts [8] ,\nGlove [12] and our Glove). The Fast Text is 2 million word vectors trained on Common\nCrawl with dimension 300, while Glove is 2.2 million word vectors trained on Com-\nmon Crawl with dimension 300. Furthermore, we trained a custom Glove model with\ncomments from English Wikipedia talk pages [15] which produced 0.5 million word\nvectors with dimension 300. Each word embedding model is followed by 20% Spatial\n1D Dropout, which simply tries to hide some words representations’ during training to\nreduce over ﬁtting. Two ideas are behind using different word representation, ﬁrst is to\ncapture different semantic and syntactic features of words, second is to cover as many\nwords as possible by training them on different unstructured text sources.\n3.2.2. Recurrent Neural Network (RNN) Layers\nEach word embedding layer is followed by two parallel Bidirectional RNN layers. The\nﬁrst is a GRU and second one is LSTM layer. Both layers has 128 neurons and is fol-\nlowed by 20% dropout. This creates a total of 3 GRU layers and 3 LSTM layers. The\nmain beneﬁt of using these RNN layers is to allow the model to capture the relationship\nbetween the sequence of words.\n3.2.3. Convolutional Neural Network (CNN) Layers\nAfterwards, a separate CNN layer takes the output of each separate RNN layer, which\ncreates a total of 6 CNN layers. The hyper parameters of each CNN are as follows: the\nnumber of ﬁlters is 64, the kernel size is 2, and the activation function was RELU. Each\none is followed by 20% dropout. Afterward The output of the CNN layers is concatenated\ninto 2 outputs. The ﬁrst and second concatenation concatenates the output of the 3 CNN\nlayers coming after the LSTM layers and the output of the 3 CNN layers coming after\nthe GRU layers respectively.\n3.2.4. Pooling Layers\nThe output of each concatenation of the CNN layers goes through separate Max Pooling\nand Average Pooling. Afterwards, the output of the 2 Max Pooling and the 2 Average\nPooling layers are concatenated together.\n3.2.5. Dense Layers\nFinally, separate 4 dense layers take the output of the concatenated pooling layers to\nproduce the ﬁnal outputs. The ﬁrst dense layer produces 6 outputs for each label of the\nmain illegal comment dataset (Toxic, Severe Toxic, Obscene, Threat, Insult and Identity\nHate), while the second, third and fourth dense layers produce only 1 output for each\nclass on each complementary datasets (Toxic, Attack and Aggression).\n4. Experimental Settings\n4.1. Training Details\nSeveral single task algorithms were tested against the multi-task multi-embedding algo-\nrthim. All the single task algorithms were trained only on the main dataset, while the\nFigure 4. Multi-Task Multi-Embedding Deep Learning Architecture\nmulti-task multi-embedding algorithm were trained on at least two data sets together.\nSome standard classic approach algorithms were tested like Linear Regression (LR) and\nDecision Trees (DT). Other single task deep learning algorithms which were tested were\nreported by top participants in the Kaggle competition including: BI-GRU, CNN and\nBI-RNN-CNN models. The BI-GRU models is 2 layers of bi-directional GRU with 128\nunits. The CNN models consist of 4 parallel CNN layers ”300 neurons and kernel sizes\nare 2,3,4 and 5 respectively” followed by global max pooling, then concatenated together\nand followed by a ﬁnal dense layer with 36 neurons. The BI-RNN-CNN models consist\nof 2 parallel GRU and LSTM ”128 neurons” layers, followed separate CNN layers ”64\nneurons”, followed by max and average and max pooling and then concatenated together.\nGenerally, all the models were trained until they converged using early stop to pre-\nvent over-ﬁtting. For neural network based models a mini-batch stochastic gradient de-\ncent was used, with a binary cross-entropy loss function. Furthermore, the Adam opti-\nmizer was used to optimize the loss function on all of the neural network models with\nlearning rate 1e−3. L1-norm or L2-norm regularization were not used, but dropout was\nused as discussed on the previous section. For our Multi-Task model at each training step\nwe trained the model for the same batch size of each problem sequentially.\nAll Models were trained using one computer with one Nvidia Titan XP GPU with\n12 GB Ram, 20 CPU cores and 128 Memory Ram.\n4.2. Metrics\nAs stated in the previous subsection the main dataset is skewed, which means the accu-\nracy can’t be a reliable measurement. That is why we choose the precision, recall and F1\nscore to give us a more reliable measurement. The equations for precision, recall and F1\nscore is shown in equation 1, 2 and 3 respectively.\nPrecision =\n#TruePositives\n#TruePositives+#FalsePositives\n(1)\nRecall =\n#TruePositives\n#TruePositives+#FalseNegatives\n(2)\nF1 = Precision×Recall\nPrecision+Recall\n(3)\n5. Results and Discussion\nTable 2 shows the result of the tested algorithms regarding precision, recall and F1 score\nmatrices. All of the algorithms were able to reach an average 99% F1 score for all the\nnegative labels ”Clean Comment” however, the problems arise with the positive labels\n”illegal comments” where the average F1 score ranges between 38% and 59%. The Lin-\near regression algorithm using TF-IDF performed the worst with an average positive F1\nscore 38%. However, the decision tree using TF-IDF, which is another classical ML al-\ngorithm performed well compared to the deep learning models with F1 score 54%, de-\nspite the fact it doesn’t use any word embedding layer which transfer a lot of information\nfor all the tokens, after being trained in big unstructured text datasets. The reason is that\nDecision Trees (DT) algorithms don’t affect too much with imbalanced class data com-\npared to other machine learning approaches. Both the BI-GRU and CNN models using\nfastText performed lower than the DT with an average F1 score 53% and 52%. The best\nmodel among all the single task approaches was the BI-RNN-CNN model using fastText\nwith an average F1 score 58%. However, by changing the embedding layer with Glove\nand our pre-trained model the BI-RNN-CNN F1 score decreased with average F1 score\n54% and 52%.\nThe multi-task multi-embedding algorithm when used by combining the main data\nset with either toxic, attack or aggression didn’t out-perform the best single task model\nwith average F1 score 55%, 56% and 56%. However, when the 4 data sets were combined\nit out-performed the best single task model with an average F1 score 59%.\nFirst observation, the balance of samples per label affect dramatically the perfor-\nmance of all algorithms. All models were able to perfectly predict a clean comment\nwhich was not the case with illegal comments, because the number of clean samples is\nalmost about 97% of the data set.\nSecond observation, multi-task algorithms with more data sets generalize much bet-\nter than when only few data sets are chosen. Despite the fact that the model couldn’t out-\nperform all the F1 scores of every label, but it did generalize better on the overall average\nF1 score.\nThird observation, multi-task algorithms which were fed with the 4 datasets had\nmuch higher true positive Rate (Recall), especially on the labels with very few samples\n(severe toxic, threat and identity hate). Which in this case makes it a better choice since\nthe algorithm tends to be sensitive to classify the illegal comments.\n6. Conclusion\nMulti-task deep learning models are a promising new technology that could pave the\nway for more deep learning applications in the legal domain by transferring knowledge\nfrom large datasets to small datasets. We investigate the transfer learning capabilities\nTable 2. Precision, Recall and F1 score of base line machine learning models versus our proposed Multi-Task\nMulti-Embedding Model\nArchticture\nSingle Task\nMulti-Task\nModel\nLR\nDT\nBI-GRU\nCNN\nBI-RNN-CNN\nMulti-Emb RNN-CNN\nDatasets\nMulti-Label Illegal\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nX\nToxic\nX\nX\nAttack\nX\nX\nAgression\nX\nX\nWord Embedding\nTF-IDF\nX\nX\nFastText\nX\nX\nX\nX\nX\nX\nX\nGlove\nX\nX\nX\nX\nX\nOur\nX\nX\nX\nX\nX\nToxic\nP\n0\n0,95\n0,98\n0,98\n0,99\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n1\n0,78\n0,63\n0,6\n0,55\n0,64\n0,62\n0,64\n0,61\n0,6\n0,6\n0,64\nR\n0\n0,98\n0,95\n0,94\n0,93\n0,95\n0,95\n0,95\n0,94\n0,94\n0,94\n0,95\n1\n0,56\n0,77\n0,85\n0,87\n0,81\n0,81\n0,78\n0,83\n0,82\n0,83\n0,8\nF1\n0\n0,97\n0,96\n0,96\n0,95\n0,97\n0,96\n0,97\n0,96\n0,96\n0,96\n0,96\n1\n0,65\n0,7\n0,7\n0,67\n0,71\n0,7\n0,7\n0,71\n0,7\n0,7\n0,71\nSevere toxic\nP\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0,37\n0,35\n0,45\n0,39\n0,51\n0,43\n0,45\n0,45\n0,45\n0,35\n0,35\nR\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0,2\n0,25\n0,27\n0,31\n0,21\n0,36\n0,34\n0,2\n0,22\n0,39\n0,41\nF1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0,26\n0,29\n0,34\n0,35\n0,3\n0,39\n0,39\n0,28\n0,29\n0,37\n0,38\nObscene\nP\n0\n0,97\n0,98\n0,98\n0,99\n0,99\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n1\n0,88\n0,68\n0,66\n0,59\n0,64\n0,73\n0,73\n0,69\n0,68\n0,69\n0,7\nR\n0\n1\n0,98\n0,98\n0,97\n0,97\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n1\n0,5\n0,72\n0,75\n0,8\n0,78\n0,68\n0,68\n0,73\n0,73\n0,73\n0,71\nF1\n0\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n1\n0,64\n0,7\n0,7\n0,68\n0,7\n0,71\n0,7\n0,71\n0,7\n0,71\n0,71\nThreat\nP\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0,65\n0,49\n0,31\n0,58\n0,44\n0,51\n0,38\n0,35\n0,36\n0,4\nR\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n0,28\n0,12\n0,14\n0,47\n0,28\n0,13\n0,51\n0,59\n0,52\n0,6\nF1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0,01\n0,39\n0,2\n0,2\n0,52\n0,34\n0,2\n0,43\n0,44\n0,42\n0,48\nInsult\nP\n0\n0,97\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,97\n0,97\n0,98\n1\n0,83\n0,74\n0,72\n0,6\n0,73\n0,68\n0,69\n0,76\n0,8\n0,76\n0,77\nR\n0\n1\n0,99\n0,99\n0,97\n0,99\n0,98\n0,98\n0,99\n0,99\n0,99\n0,99\n1\n0,4\n0,58\n0,65\n0,73\n0,64\n0,68\n0,65\n0,57\n0,54\n0,54\n0,56\nF1\n0\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n0,98\n1\n0,54\n0,65\n0,68\n0,66\n0,68\n0,68\n0,67\n0,65\n0,64\n0,63\n0,65\nIdentity hate\nP\n0\n0,99\n0,99\n0,99\n0,99\n1\n0,99\n0,99\n0,99\n0,99\n0,99\n1\n1\n0,73\n0,78\n0,72\n0,59\n0,59\n0,73\n0,8\n0,61\n0,6\n0,54\n0,54\nR\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0,99\n1\n0,09\n0,39\n0,48\n0,51\n0,58\n0,32\n0,3\n0,47\n0,55\n0,48\n0,64\nF1\n0\n0,99\n1\n1\n1\n1\n1\n1\n1\n1\n0,99\n0,99\n1\n0,16\n0,52\n0,57\n0,54\n0,59\n0,44\n0,43\n0,53\n0,57\n0,51\n0,58\nTotal Average\nF1\n0\n0,99\n0,99\n0,99\n0,99\n0,99\n0,99\n0,99\n0,99\n0,99\n0,99\n0,99\n1\n0,38\n0,54\n0,53\n0,52\n0,58\n0,54\n0,52\n0,55\n0,56\n0,56\n0,59\nof a particular multi-task architecture on a classiﬁcation task on the publicly available\ntoxic-comments Kaggle challenge dataset. We explore the toxic-comments dataset in\ndepth and identify the imbalanced classes as a major challenge.Our multi-task approach\ndoes not signiﬁcantly improve upon single-task models in terms of F1-score. However,\nit improves the recall score signiﬁcantly for labels with a low number of samples, which\nis extremely important to this use-case. A key result is that we can observe a signiﬁcant\nimprovement in F1-score when adding additional, related datasets to train the multi-task\nmodel.\nThese promising results encourage us to further investigate the transfer learning ca-\npabilities of multi-task models. In particular, it is unclear, what deep neural network ar-\nchitectures are most suitable for applications in the legal domain. It will be necessary\nto explore different combinations of tasks, datasets, architectures and hyper parameter\nselections to better understand the transfer learning capabilities of transfer learning es-\npecially with multi-task models.\n7. Acknowledgements\nWe gratefully acknowledge the support of NVIDIA Corporation with the donation of the\nTitan XP Pascal GPU used for this research.\nReferences\n[1]\nKevin D Ashley. Artiﬁcial intelligence and legal analytics: new tools for law practice in the digital age.\nCambridge University Press, 2017.\n[2]\nKevin D Ashley and Will Bridewell. Emerging ai & law approaches to automating analysis and re-\ntrieval of electronically stored information in discovery proceedings. Artiﬁcial Intelligence and Law,\n18(4):311–320, 2010.\n[3]\nErik Boiy and Marie-Francine Moens. A machine learning approach to sentiment analysis in multilin-\ngual web texts. Information retrieval, 12(5):526–558, 2009.\n[4]\nJack G Conrad and Frank Schilder. Opinion mining in legal blogs. In Proceedings of the 11th interna-\ntional conference on Artiﬁcial intelligence and law, pages 231–236. ACM, 2007.\n[5]\nCJ Hutto Eric Gilbert. Vader: A parsimonious rule-based model for sentiment analysis of social me-\ndia text. In Eighth International Conference on Weblogs and Social Media (ICWSM-14). Available at\n(20/04/16) http://comp. social. gatech. edu/papers/icwsm14. vader. hutto. pdf, 2014.\n[6]\nJinju Hong, Sehan Kim, Jeawon Park, and Jaehyun Choi. A malicious comments detection technique\non the internet using sentiment analysis and svm. Journal of the Korea Institute of Information and\nCommunication Engineering, 20(2):260–267, 2016.\n[7]\nJigsaw. Kaggle toxic comment classiﬁcation challenge, 2018 (accessed Augest 8, 2018). https://\nwww.kaggle.com/c/jigsaw-toxic-comment-classification-challenge.\n[8]\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of tricks for efﬁcient text\nclassiﬁcation. arXiv preprint arXiv:1607.01759, 2016.\n[9]\nGeorgios Paltoglou. Sentiment Analysis in Social Media, pages 3–17. Springer Vienna, Vienna, 2014.\n[10]\nGeorgios Paltoglou and Mike Thelwall. Twitter, myspace, digg: Unsupervised sentiment analysis in\nsocial media. ACM Trans. Intell. Syst. Technol., 3(4):66:1–66:19, September 2012.\n[11]\nBo Pang, Lillian Lee, et al. Opinion mining and sentiment analysis. Foundations and Trends R⃝in\nInformation Retrieval, 2(1–2):1–135, 2008.\n[12]\nJeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word repre-\nsentation. In Proceedings of the 2014 conference on empirical methods in natural language processing\n(EMNLP), pages 1532–1543, 2014.\n[13]\nSebastian Ruder.\nAn overview of multi-task learning in deep neural networks.\narXiv preprint\narXiv:1706.05098, 2017.\n[14]\nSara Owsley Sood, Elizabeth F Churchill, and Judd Antin. Automatic identiﬁcation of personal in-\nsults on social news sites. Journal of the American Society for Information Science and Technology,\n63(2):270–285, 2012.\n[15]\nEllery Wulczyn, Nithum Thain, and Lucas Dixon.\nEx machina: Personal attacks seen at scale.\nIn\nProceedings of the 26th International Conference on World Wide Web, pages 1391–1399. International\nWorld Wide Web Conferences Steering Committee, 2017.\n",
  "categories": [
    "cs.IR",
    "cs.CL",
    "cs.LG",
    "stat.ML"
  ],
  "published": "2018-10-15",
  "updated": "2018-10-15"
}