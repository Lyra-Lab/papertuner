{
  "id": "http://arxiv.org/abs/1810.09391v1",
  "title": "A neuro-inspired architecture for unsupervised continual learning based on online clustering and hierarchical predictive coding",
  "authors": [
    "Constantine Dovrolis"
  ],
  "abstract": "We propose that the Continual Learning desiderata can be achieved through a\nneuro-inspired architecture, grounded on Mountcastle's cortical column\nhypothesis. The proposed architecture involves a single module, called\nSelf-Taught Associative Memory (STAM), which models the function of a cortical\ncolumn. STAMs are repeated in multi-level hierarchies involving feedforward,\nlateral and feedback connections. STAM networks learn in an unsupervised\nmanner, based on a combination of online clustering and hierarchical predictive\ncoding. This short paper only presents the architecture and its connections\nwith neuroscience. A mathematical formulation and experimental results will be\npresented in an extended version of this paper.",
  "text": "A neuro-inspired architecture for unsupervised\ncontinual learning based on online clustering and\nhierarchical predictive coding\nConstantine Dovrolis\nSchool of Computer Science\nGeorgia Institute of Technology\nAtlanta, GA 30332\nconstantine@gatech.edu\nAbstract\nWe propose that the Continual Learning desiderata can be achieved through a\nneuro-inspired architecture, grounded on Mountcastle’s cortical column hypothesis\n(Mountcastle, 1997). The proposed architecture involves a single module, called\nSelf-Taught Associative Memory (STAM), which models the function of a cortical\ncolumn. STAMs are repeated in multi-level hierarchies involving feedforward,\nlateral and feedback connections. STAM networks learn in an unsupervised manner,\nbased on a combination of online clustering and hierarchical predictive coding. This\nshort paper only presents the architecture and its connections with neuroscience. A\nmathematical formulation and experimental results will be presented in an extended\nversion of this paper.\n1\nConnection with neuroscience\nInstead of providing directly an algorithmic description of STAMs (that would hide the connection to\nneuroscience and cortical columns), we ﬁrst give a sequence of points about cortical columns that\nthe design of STAMs is based on. We should note that the following points are still an active area of\nresearch and debate among neuroscientists - they should not be viewed as proven facts. In the same\nway that computer science has created useful ANNs based on a crude model of a neuron’s function,\nwe may also ﬁnd out that STAMs are useful in practice even though they may be only a caricature of\nhow cortical columns, and the cortex in general, work.\n1) The cerebral cortex consists of the same six-layer module, referred to as cortical column, repeated\nthroughout the cortex with minor anatomical differences. The \"canonical cortical circuit\" by Douglas\nand Martin (see Fig.1) captures what is currently known about this module at the level of connections\nbetween the six cortical layers (Douglas et al., 1989; Douglas and Martin, 2004). The complete\nconnectome of a cortical column, at the level of individual neurons and synapses, is not yet known.\n2) If the same cortical module is used in brain regions associated with very different function (e.g., the\ncolumns of V1 \"see\" visual features, the columns of A1 \"hear\" sounds, the columns of the prefontal\ncortex make plans), we are led to the hypothesis that the cortical column performs a very general\nbut powerful computational function. The neuroscience literature is sparse in offering hypotheses\nabout what this common function may be. In the following, we refer to this unknown computational\nfunction of cortical columns as Φ(x), where x is a vector that represents the collection of inputs into\na column. We propose a speciﬁc function Φ(x) in Section 2.\n3) The structure of cortical columns is such that it can be viewed as a module with two input channels:\na feedforward input channel from lower brain regions (such as the thalamus) or from lower-level\nPreprint. Work in progress.\narXiv:1810.09391v1  [cs.LG]  22 Oct 2018\nFigure 1: The canonical cortical circuit as represented by Douglas and Martin in (Douglas and\nMartin, 2004). The diagram shows two instances of the circuit, one in “Area-a” and another in\n“Area-b”. The layer number (e.g., L4) represents the layer where the soma is located. Red arrows\nrepresent excitatory projections between neurons of the same column, while blue arrows represent\ninhibitory projections (they are mostly between neurons of the same layer). The black arrows\nrepresent connections between different columns (or other brain regions). Feedforward inputs enter\nprimarily into L4. L4 neurons project to L2/3 neurons. The feedforward outputs originate from L2/3\n(pyramidal) neurons. Information from L2/3 neurons is also sent to the deep layers (L5 and L6),\nwhere the feedback outputs originate from. L6 neurons also project their (intracolumn) feedback\nback to the input L4 neurons. External feedback connections from other cortical columns project\nmostly to L3 neurons.\ncortical regions (e.g., V1 columns projecting to V2 columns), and a feedback input channel from\nhigher-level cortical regions (e.g., from V2 columns to V1 columns). Symmetrically, a cortical column\nhas two output channels: the feedback outputs towards lower-level cortical regions and other parts of\nthe brain, and the feedforward outputs towards higher cortical regions. These feedforward/feedback\nchannels are used to create hierarchies of cortical columns in which most connections are reciprocal.\nBased on this distinction, we revise our notation as Φ(xf, xb), where xf is the feedforward input\nvector and xb is the feedback input vector.\n4) The internal connectivity of neurons at a cortical column is relatively dense (compared to the\nconnection density between different columns) and forms multiple feedback loops. In particular, there\nare recurrent circuits of excitatory and inhibitory neurons at layer-4 (where xf enters the column), at\nlayers 2/3 (where xb enters the column, and the feedforward output yf exits the column) and at layers\n5/6 (where the feedback output yb exits the column). There are also internal feedback circuits from\nthe output neurons at layers-5/6 to the input neurons at layer-4. Such recurrent circuits and feedback\npaths from outputs to inputs are common in artiﬁcial networks implementing sequential/stateful\ncomputations, such as associative memory networks (Lansner, 2009). In other words, the highly\nrecurrent structure of cortical columns implies that their function is probably more complex than\nstateless computations (such as ﬁltering, feature detection or any other memoryless mathematical\ntransformation of their inputs). In fact, it has been shown that recurrent neural networks with rational\nweights are Turing-complete (Siegelmann, 2012).\n5) It has been previously hypothesized, based on the structure of the cortical circuit, that the function\nof cortical columns is to perform predictive coding (Bastos et al., 2012). In that framework, feedback\nprojections between columns transfer predictions while feedforward projections between prediction\nerrors (Rao and Ballard, 1999). A column acts as a generative model that can predict its feedforward\ninputs based on its own priors (stored locally) and also based on predictions that are fed back\n2\nfrom higher-level columns. Note that the predictive coding hypothesis does not propose a speciﬁc\nalgorithm for generating these predictions - it is only a framework that speciﬁes the type of information\n(predictions and prediction errors) that ﬂow in the feedback and feedforward paths, respectively. Our\nSTAM model can be thought of as a speciﬁc implementation of the predictive coding hypothesis, as\ndescribed in Section 2.\n6) Cortical columns have the capability to incrementally learn from their inputs, storing internal\nrepresentations that can generalize from few exemplars to useful invariants, at least after some initial\n\"development stage\". For instance, each column of the Inferior Temporal (IT) visual region responds\nto different orientations or partial views of speciﬁc animate or inanimate objects (e.g., faces) (Tanaka,\n1996). Each column is highly selective (e.g., it only responding to faces) but it is also has strong\ngeneralization abilities (e.g., responds to same face independent of rotation, light, occlusions). In\nother words, it appears that a cortical column stores related \"prototypes\", and exemplars that are\nsimilar to that prototype are recognized by that column (Kiani et al., 2007; Kriegeskorte et al., 2008).\nFrom the computational perspective, this is essentially an online clustering operation: an input\nvector is mapped to its nearest cluster centroid (according to some distance metric). Additionally, the\ncentroid of the chosen cluster is adjusted incrementally with every new exemplar so that it comes a\nbit closer to that input vector - this is how an online clustering module gradually learns the structure\nof the input data.\n7) An online clustering algorithm that is similar to k-means (and asymptotically equivalent to k-\nmeans) can be implemented with a rather simple recurrent neural network of excitatory and inhibitory\nspiking neurons, as shown recently (Pehlevan et al., 2018). That circuit models the olfactory system\nin Drosophila but similar recurrent E/I circuits are also present in layer-4 of cortical columns. We\nhypothesize that the main function of the E/I circuits at layer-4 is also to perform online clustering of\nthat column’s feedforward inputs.\n2\nSTAM architecture\nPutting the previous seven points together, we now describe the computational function Φ(xf, xb)\nthat we associate with cortical columns, and describe the proposed STAM module in more detail.\nA STAM module receives two input channels (feedforward xf and feedback xb) and it produces the\ncorresponding two output channels. The ﬁrst function of a STAM is to perform online clustering of\nthe feedforward input vector xf that it receives. We hypothesize that this is also the main function of\nthe E/I circuits at layer-4 of a cortical column, similar to the neural circuit of (Pehlevan et al., 2018).\nThe number of clusters in STAMs is dynamically adjusted driven by “novelty detection\" (if the new\ninput is far from any existing centroid, add a new cluster) and “overlap detection\" (if two centroids\nare quite close, merge the two clusters) - we are still investigating how these two mechanisms are\nimplemented in the brain.\nThe centroid c(xf) that is closest to the given exemplar xf is then compared to the predicted centroid\nthat arrives from a higher-level STAM through feedback connections (see Fig.2). In cortical columns,\nthis comparison is probably performed at layers 2/3 because that is where neurons receive projections\nfrom both layer-4 and projections from higher-level columns (Fig.1). In STAMs, this comparison\nresults in the difference c(xf) −xb between the local centroid and what the next-level STAM predicts\nfor the corresponding receptive ﬁeld. It is this difference (prediction error) that constitutes the\nfeedforward output of the STAM. In cortical columns, we hypothesize that this corresponds to the\noutput projections from layers 2/3. Returning to STAMs, this prediction error is then transformed to\nthe feedback that will be sent back to each of the lower-level STAMs, so that each STAM will only\nreceive the feedback that corresponds to its own receptive ﬁeld. In cortical columns, we hypothesize\nthat this is the function of neurons at layers 5/6 (Fig.1).\nIn summary, a STAM module integrates three computational functions: online clustering, associative\nmemory formation (i.e., learning and updating the location of the centroids), and hierarchical\npredictive coding. The online clustering component groups together similar inputs, allowing the\nSTAM to generalize. The patterns that a STAM learns are the centroids of each cluster – all previously\ninputs/exemplars are discarded. That centroid c(x) becomes the “recalled memory\" when that STAM\nis presented with vector x. Even if the vector x is noisy or partially observed, the centroid c(x) should\nremain the same as long as x falls in the basin of attraction of c(x). Finally, the proposed STAM\nhierarchies, including the reciprocal projections between successive levels, implement hierarchical\n3\nFigure 2: A two-level hierarchy of STAM modules. Each level-1 STAM outputs to the level-2 STAM\nthe closest centroid for the portion of the input covered by its receptive ﬁeld. The level-2 STAM\nclusters those centroids and it generates a higher-level prediction of what the entire input image\nis. It also sends back to each level-1 STAM its prediction for the (smaller) receptive ﬁeld of the\ncorresponding level-1 STAM. The locally generated level-1 centroid is compared to the predicted\ncentroid from the level-2 STAM, the prediction error is forwarded to higher-level STAMs, while the\nrevised local prediction is forwarded to lower-level STAMs.\npredictive coding: lower-level STAMs reduce the dimensionality of the input data and at the same\ntime they are regulated by higher-level STAMs that “see the bigger picture” (i.e., they have a larger\nreceptive ﬁeld but potentially in a lower resolution) aggregating information from lower-level STAMs.\n3\nConnection with Continual Learning\nLet us now examine how the proposed architecture addresses the desiderata that is often associated\nwith Continual Learning (CL):\n1. Online learning: STAMs constantly update their centroids with every example. There is no\nseparate training stage, and there is no speciﬁc task for which the network optimizes the features it\nlearns. Any tasks that require classiﬁcation will of course require one or few labeled examples so that\nthe corresponding clusters that were formed previously are now associated with the name of a class.\n2. Transfer learning: The hierarchical nature of the proposed architecture means that features learned\n(in an unsupervised manner) at lower-level STAMs can be reused in different tasks that higher-level\nSTAMs perform. Through hierarchical predictive coding, this process is also taking place in the\ntop-down direction: for instance, if the visual data shift at some point from bright to dark images, but\nthe objects are still the same (e.g., animals), the centroids of the higher-level STAMs will remain the\nsame, modulating the lower-level STAMs to darken their centroids instead of learning new prototypes.\n3. Resistance to catastrophic forgetting: If the system does not operate at full capacity (see next\npoint), the introduction of a new prototype will lead to the creation of new clusters at some STAMs in\nthe hierarchy (e.g., layer-1 STAMs will learn new elementary visual features if we start feeding them\nnatural images instead of MNIST examples – while a STAM at a higher-level would create a new\ncluster when it ﬁrst starts seeing examples of scooters but without affecting the cluster associated\nwith bicycles).\n4. Bounded system size: The learning capacity of a STAM architecture depends on two factors:\nthe number of STAMs and the maximum number of centroids that each STAM can store. These\ntwo capacity constraints require the system to forget past prototypes that have not been recently\nupdated with new exemplars because the corresponding cluster centroids will gradually shift towards\n4\nmore recently exemplars of different prototypes. This is a graceful forgetting process however (e.g.,\ngradually forgetting the facial characteristics of our children when they were ten years younger).\n5. No direct access to previous experience: A STAM only needs to store the centroids of the clusters\nit has learned so far. Those centroids correspond to prototypes, allowing the STAM to generalize. All\npreviously seen exemplars are discarded.\n4\nRelated work and discussion\nOur main premise is that the cortical column represents the main anatomical and functional module\nin the cortex. This premise is inspired by the groundbreaking work of V.Mountcastle (Mountcastle,\n1978, 1997), by follow up work by Martin, Douglas, and colleagues (Douglas et al., 1989; Douglas\nand Martin, 2004), and by more recent ﬁndings such as (Kaschube et al., 2010; Kaas, 2012; Reid,\n2012; Miller, 2016). It should be noted that this hypothesis is not adopted by everyone in neuroscience\n- there are many “contrarian voices\" that question whether the structure of cortical columns is the\nsame throughout the cortex (Molnár, 2013) or whether there is actually a common function behind\nthis structure (Horton and Adams, 2005). We believe that this debate reﬂects the importance of this\nquestion in neuroscience. We hope to contribute to this debate by exploring the continual learning\ncapabilities of hierarchical networks of cortical columns computationally, modeling cortical columns\nas STAMs.\nIn the context of modeling cortical columns with STAMs, the most relevant prior work has appeared\nin the theoretical neuroscience literature, in the context of hierarchical Bayesian inference (Lee and\nMumford, 2003) and predictive coding (Rao and Ballard, 1999; Bastos et al., 2012). D.Mumford had\nproposed a similar model of how the cortex works based on Grenader’s \"pattern theory\" (without\nusing the term \"predictive coding\" though) (Mumford, 1992) – that model associates cortical feedback\npaths with \"analysis by synthesis\", i.e., higher level cortical regions generate hypotheses for the\ninputs received by lower level regions. Similar ideas have been proposed by S.Ullman (ascending\nand descending cortical streams performing \"pattern search\") (Ullman, 1995), and by S.Grossberg\nin a model of “laminar cortical circuits\", which consider the connectivity between layers in cortical\ncolumns, and bidirectional “adaptive resonance\" networks that model the effect of top-down attention\nmechanisms (Grossberg, 2007). More recently, K.Miller has proposed that two operations performed\nby cortical columns are a “feedforward computation of selectivity\" (similar to clustering operations in\nSTAMs) and a recurrent computation of adaptive gain control between external stimuli and competing\ninternally generated signals (similar to the STAM operation of comparing the result of local clustering\nwith predictions from higher-levels) (Miller, 2016). The idea that cortical columns constitute the\nbuilding block of associative memory networks, which is also central in our STAMs architecture, was\nﬁrst presented by Lansner and colleagues (Fransén and Lansner, 1998; Lansner, 2009).\nIn the context of machine learning and artiﬁcial neural networks, the STAM architecture has simi-\nlarities with several unsupervised methods. First, there is a large body of work in clustering-based\nmethods for unsupervised learning – see (Caron et al., 2018) for a recent review. For instance, the\nwork of Coates and Ng has shown that k-means clustering is not only simpler and faster than methods\nbased on sparse autoencoders or Gaussian mixtures – it also performs better in feature learning as\nlong as the model has enough hidden nodes (centroids in the clustering case) and the receptive ﬁeld\n(i.e., input dimensionality) is sufﬁciently small (Coates et al., 2011). For tasks in which the input\ndimensionality is large, clustering can be used as the basic building block of deep hierarchies (Coates\nand Ng, 2012) – similar to the feedforward aspect of the STAM architecture.\nThe previous clustering-based methods, however, do not include the feedback component of the\nSTAM architecture, which is inspired by the recurrent connectivity in the brain. Machine learning\nmethods such as Helmholtz machines (Dayan et al., 1995) and Deep Predictive Coding (Lotter et al.,\n2016) are similar to the STAM architecture in terms of how they use feedback connections - but they\nare not based on clustering and they have not been developed in the context of continual learning\ntasks, meaning that they assume a mostly stationary environment.\nAnother approach to model the function of cortical columns, and to construct hierarchies based\non that model, has been pursued by J.Hawkins and colleagues at Numenta (George and Hawkins,\n2009). Even though our high-level position is the same (namely, that the basic building block of\nartiﬁcial neural networks should be a functional model of the cortical column, rather than individual\nneurons), the Numenta architecture (“Hierarchical Temporal Memory\") is signiﬁcantly different\n5\nthan the STAMs architecture. One major difference is that the former is based on a hierarchy of\ncoincidence detectors while the latter combines online clustering and predictive coding.\nAcknowledgments\nThis research is supported by DARPA’s Lifelong Learning Machines (L2M) program, under Coopera-\ntive Agreement HR0011-18-2-0019.\nThe author is grateful to Sarah Pallas for discussions about cortical columns, and to Zsolt Kira for\ndiscussions about the ML aspects of this architecture. Also, thanks are due to Thomas Papastergiou\nfor creating Fig.2 and to Joseph Aribido, Seth Baer, David Nicholson, Astrid Prinz, and James Smith\nfor their comments.\nReferences\nAndre M Bastos, W Martin Usrey, Rick A Adams, George R Mangun, Pascal Fries, and Karl J Friston.\nCanonical microcircuits for predictive coding. Neuron, 76(4):695–711, 2012. ISSN 0896-6273.\nMathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep clustering for unsuper-\nvised learning of visual features. arXiv preprint arXiv:1807.05520, 2018.\nAdam Coates and Andrew Y Ng. Learning feature representations with k-means, pages 561–580.\nSpringer, 2012.\nAdam Coates, Andrew Ng, and Honglak Lee. An analysis of single-layer networks in unsupervised\nfeature learning. In Proceedings of the fourteenth international conference on artiﬁcial intelligence\nand statistics, pages 215–223, 2011.\nPeter Dayan, Geoffrey E Hinton, Radford M Neal, and Richard S Zemel. The helmholtz machine.\nNeural computation, 7(5):889–904, 1995. ISSN 0899-7667.\nR. J. Douglas and K. A. C. Martin. Neuronal circuits of the neocortex. Annual Review of Neuroscience,\n27:419–452, 2004.\nR.J. Douglas, K.A.C. Martin, and D. Whitteridge. A canonical microcircuit for neocortex. Neural\nComputation, 1:480–488, 1989.\nErik Fransén and Anders Lansner. A model of cortical associative memory based on a horizontal\nnetwork of connected columns. Network: Computation in Neural Systems, 9(2):235–264, 1998.\nISSN 0954-898X.\nDileep George and Jeff Hawkins. Towards a mathematical theory of cortical micro-circuits. PLoS\ncomputational biology, 5(10):e1000532, 2009. ISSN 1553-7358.\nStephen Grossberg. Towards a uniﬁed theory of neocortex: laminar cortical circuits for vision and\ncognition. Progress in brain research, 165:79–104, 2007. ISSN 0079-6123.\nJonathan C Horton and Daniel L Adams. The cortical column: a structure without a function.\nPhilosophical Transactions of the Royal Society of London B: Biological Sciences, 360(1456):\n837–862, 2005. ISSN 0962-8436.\nJon H. Kaas. Evolution of columns, modules, and domains in the neocortex of primates. Proceedings\nof the National Academy of Sciences, 109(Supplement 1):10655–10660, 2012. doi: 10.1073/pnas.\n1201892109. URL http://www.pnas.org/content/109/suppl.1/10655.abstract.\nMatthias Kaschube, Michael Schnabel, Siegrid Löwel, David M. Coppola, Leonard E. White, and\nFred Wolf. Universality in the evolution of orientation columns in the visual cortex. Science, 330\n(6007):1113–1116, 2010. doi: 10.1126/science.1194869. URL http://www.sciencemag.org/\ncontent/330/6007/1113.abstract.\nRoozbeh Kiani, Hossein Esteky, Koorosh Mirpour, and Keiji Tanaka. Object category structure\nin response patterns of neuronal population in monkey inferior temporal cortex. Journal of\nneurophysiology, 97(6):4296–4309, 2007. ISSN 0022-3077.\n6\nNikolaus Kriegeskorte, Marieke Mur, Douglas A Ruff, Roozbeh Kiani, Jerzy Bodurka, Hossein\nEsteky, Keiji Tanaka, and Peter A Bandettini. Matching categorical object representations in\ninferior temporal cortex of man and monkey. Neuron, 60(6):1126–1141, 2008. ISSN 0896-6273.\nAnders Lansner. Associative memory models: from the cell-assembly theory to biophysically detailed\ncortex simulations. Trends in neurosciences, 32(3):178–186, 2009. ISSN 0166-2236.\nTai Sing Lee and David Mumford. Hierarchical bayesian inference in the visual cortex. JOSA A, 20\n(7):1434–1448, 2003. ISSN 1520-8532.\nWilliam Lotter, Gabriel Kreiman, and David Cox. Deep predictive coding networks for video\nprediction and unsupervised learning. arXiv preprint arXiv:1605.08104, 2016.\nKenneth D. Miller. Canonical computations of cerebral cortex. Current Opinion in Neurobiology,\n37:75–84, 2016. ISSN 0959-4388. doi: http://dx.doi.org/10.1016/j.conb.2016.01.008. URL\nhttp://www.sciencedirect.com/science/article/pii/S095943881600009X.\nZ Molnár. Cortical columns, pages 109–129. Elsevier, 2013.\nV.B. Mountcastle. The columnar organization of the neocortex. Brain, 120(4):701–722, 1997.\nVernon Mountcastle. An organizing principle for cerebral function: the unit module and the distributed\nsystem. The mindful brain, 1978.\nDavid Mumford. On the computational architecture of the neocortex. Biological cybernetics, 66(3):\n241–251, 1992. ISSN 0340-1200.\nCengiz Pehlevan, Alexander Genkin, and Dmitri B. Chklovskii. A clustering neural network model\nof insect olfaction. bioRxiv, 2018. URL http://biorxiv.org/content/early/2018/01/27/\n226746.abstract.\nRajesh PN Rao and Dana H Ballard. Predictive coding in the visual cortex: a functional interpretation\nof some extra-classical receptive-ﬁeld effects. Nature neuroscience, 2(1):79, 1999. ISSN 1546-\n1726.\nR. Clay Reid. From functional architecture to functional connectomics. Neuron, 75(2):209–\n217, 2012. ISSN 0896-6273. URL http://linkinghub.elsevier.com/retrieve/pii/\nS0896627312005934.\nHava T Siegelmann. Neural networks and analog computation: beyond the Turing limit. Springer\nScience and Business Media, 2012. ISBN 146120707X.\nKeiji Tanaka. Inferotemporal cortex and object vision. Annual review of neuroscience, 19(1):109–139,\n1996. ISSN 0147-006X.\nShimon Ullman. Sequence seeking and counter streams: a computational model for bidirectional\ninformation ﬂow in the visual cortex. Cerebral cortex, 5(1):1–11, 1995. ISSN 1460-2199.\n7\n",
  "categories": [
    "cs.LG",
    "cs.AI",
    "q-bio.NC",
    "stat.ML"
  ],
  "published": "2018-10-22",
  "updated": "2018-10-22"
}