{
  "id": "http://arxiv.org/abs/1812.00602v1",
  "title": "Examining Deep Learning Architectures for Crime Classification and Prediction",
  "authors": [
    "Panagiotis Stalidis",
    "Theodoros Semertzidis",
    "Petros Daras"
  ],
  "abstract": "In this paper, a detailed study on crime classification and prediction using\ndeep learning architectures is presented. We examine the effectiveness of deep\nlearning algorithms on this domain and provide recommendations for designing\nand training deep learning systems for predicting crime areas, using open data\nfrom police reports. Having as training data time-series of crime types per\nlocation, a comparative study of 10 state-of-the-art methods against 3\ndifferent deep learning configurations is conducted. In our experiments with\nfive publicly available datasets, we demonstrate that the deep learning-based\nmethods consistently outperform the existing best-performing methods. Moreover,\nwe evaluate the effectiveness of different parameters in the deep learning\narchitectures and give insights for configuring them in order to achieve\nimproved performance in crime classification and finally crime prediction.",
  "text": "1\nExamining Deep Learning Architectures for Crime\nClassiﬁcation and Prediction\nPanagiotis Stalidis, Theodoros Semertzidis, Member, IEEE and Petros Daras, Senior Member, IEEE\nAbstract—In this paper, a detailed study on crime classiﬁcation\nand prediction using deep learning architectures is presented.\nWe examine the effectiveness of deep learning algorithms on\nthis domain and provide recommendations for designing and\ntraining deep learning systems for predicting crime areas, using\nopen data from police reports. Having as training data time-\nseries of crime types per location, a comparative study of\n10 state-of-the-art methods against 3 different deep learning\nconﬁgurations is conducted. In our experiments with ﬁve publicly\navailable datasets, we demonstrate that the deep learning-based\nmethods consistently outperform the existing best-performing\nmethods. Moreover, we evaluate the effectiveness of different\nparameters in the deep learning architectures and give insights\nfor conﬁguring them in order to achieve improved performance\nin crime classiﬁcation and ﬁnally crime prediction.\nIndex Terms—Deep Learning, Crime Prediction, Spatiotempo-\nral\nI. INTRODUCTION\nP\nREDICTIVE policing is the use of analytical techniques\nto identify either likely places of future crime scenes or\npast crime perpetrators, by applying statistical predictions [29].\nAs a crime typically involves a perpetrator and a target and\noccurs at a certain place and time, techniques of predictive\npolicing need to answer: a) who will commit a crime, b) who\nwill be offended, c) what type of crime, d) in which location\nand e) at what time a new crime will take place. This work\ndoes not focus on the victim and the offender, but on the\nprediction of occurrence of a certain crime type per location\nand time using past data.\nThe ultimate goal, in a policing context, is the selection of\nthe top areas in the city for the prioritization of law enforce-\nment resources per department. One of the most challenging\nissues of police departments is to have accurate crime forecasts\nto dynamically deploy patrols and other resources so as to\nimprove deterring of crime occurrence and police response\ntimes.\nRoutine activity theory [8] suggests that most crimes take\nplace when three conditions are met: a motivated offender,\na suitable victim and lack of victim protection. The rational\nchoice theory [9], suggests that prospective criminal weights\nthe gain of successfully committing the crime against the\nprobability of being caught and makes a rational choice\nwhether to actually commit the crime or not. Both theories\nagree that a crime takes place when a person willing to\ncommit it has an opportunity to do so. As empirical studies\nP. Stalidis, T. Semertzidis and P. Daras are with the Information Tech-\nnologies Institute, Centre for Research and Technology Hellas, Thessaloniki,\nGreece. Email: stalidis,theosem,daras@iti.gr\nManuscript received 19 Sep. 2017; revised 22 Mar. 2018\nin near repeat victimization [15, 19, 20, 3] have shown, these\nopportunities are not randomly distributed, but follow patterns\nin both space and time. Traditionally, police ofﬁcers use maps\nof an area and place a pin on the map for every reported\nincident. Studying these maps, they can detect these patterns\nand thus, to efﬁciently predict hotspots; A hotspot is deﬁned\nas the area with the higher possibility for a crime to occur,\ncompared to the neighbouring areas.\nSimple mapping methods are not sufﬁcient to make use of\nthese general phenomena as early indicators for predicting\ncrimes but more complex methodologies, such as machine\nlearning, are needed. Various machine learning methodologies\nlike Random Forests [4], Naive Bayes [47] and Support Vector\nMachines (SVMs) [10] have been exploited in the literature\nboth for predicting the number of crimes that will occur in an\narea and for hotspot prediction. The success of a machine\nlearning analysis highly depends on the experience of the\nanalyst to prepare the data and to hand-craft features that\ndescribe properly the problem in question.\nDeep learning is a machine learning approach where the al-\ngorithm can extract the features from the raw data, overcoming\nthe limitations of other machine learning methodologies. Of\ncource this beneﬁt comes at a high price in computational\ncomplexity and demand in raw data. This global research\ntrend was picked recently by Wang et al. [41] for predicting\nhourly ﬂuctuations in crime rates. Building on this very\ninteresting work, we investigate DL architectures for crime\nhotspot prediction and present design recommendations. The\nmajor contributions of this paper are:\n• We present 3 fundamental DL architecture conﬁgurations\nfor crime prediction based on encoding: a) the spatial\nand then the temporal patterns, b) the temporal and then\nthe spatial patterns, c) temporal and spatial patterns in\nparallel.\n• We experimentally evaluate and select the most efﬁcient\nconﬁguration to deepen our investigation.\n• We compare our models with 10 state-of-the-art algo-\nrithms on 5 different crime prediction datasets with more\nthan 10 years of crime report data.\n• Finally, we propose a guide for designing DL models for\ncrime hotspot prediction and classiﬁcation.\nThe rest of the paper is organized as follows: Section II, dis-\ncusses the related work on crime prediction and classiﬁcation\nas well as recent developments in deep learning approaches\nfor spatio-temporal data. Section III, formulates the problem\nin question. Section IV, discusses the proposed methods for\napplying DL in crime prediction and classiﬁcation. Section\narXiv:1812.00602v1  [cs.LG]  3 Dec 2018\n2\nV presents the baseline approaches, the datasets used and the\nmetrics to measure the effectiveness of each model. In Section\nVI, the presentation and discussion of results in different\nconﬁgurations and\nII. RELATED WORK\nCriminology literature investigates the relationship between\ncrime and various features, developing approaches for crime\nforecasting. The majority of the works focus on the prediction\nof hotspots, which are areas of varying geographical size\nwith high crime probability. The methods include Spatial and\nTemporal Analysis of Crime (STAC)[22], Thematic Mapping\n[42] and Kernel Density Estimation (KDE) [33].\nIn STAC, the densest concentrations of points on the map\nare detected and then ﬁt to a standard deviational ellipse for\neach one. Through the study of the size and the alignment of\nthe ellipses, the analyst can draw conclusions about the nature\nof the underlying crime clusters [6].\nIn Thematic Mapping, the map is split in boundary areas\nwhile offences are placed as points on a map. The points can\nthen be aggregated to geographic unit areas and shaded in\naccordance with the number of crimes that fall within [42].\nThis technique enables quick determination of areas with a\nhigh incidence of crime and allows further analysis of the\nproblem by “zooming in” on those areas. Boundary areas can\nbe arbitrarily deﬁned, using i.e. police beats, enabling linking\nof crime with other data sources, such as population.\nOwing to the varying size and shape of most geographical\nboundaries, thematic mapping can be misleading in identifying\nthe existence of the highest crime concentrations [11]. Hence,\nthis technique can fail to reveal patterns across and within the\ngeographical division of boundary areas [5]. KDE divides the\narea in a regular grid of cells and estimates a density value for\neach cell, using a kernel function that estimates the probability\ndensity of the actual crime incidents [2, 37]. The resulting\ntwo-dimensional scalar can then be used to create a heatmap,\naffected by the cell size, the bandwidth and the kernel function\nused [30].\nAll three abovementioned methods solely rely on the spatial\ndimension of incidents. On the other hand, methods presented\nby Mohler et al. [24] and Ratcliffe [32], model the temporal\ndimension of the crime. Mohler et al. propose the use of self-\nexciting point process to model the crime and gain insights\ninto the temporal trends in the rate of burglary, while Ratcliffe\ninvestigates the temporal constraints on crime and proposes an\noffender travel and opportunity model. These works validate\nthe claim that a proportion of offending is driven by the avail-\nability of opportunities presented in Cohen’s routine activity\ntheory [8].\nNakaya and Yano [25], extend the crime cluster analysis\nwith a temporal dimension. They employ the space-time vari-\nants of KDE to simultaneously visualize geographical extent\nand duration of crime clusters. Taking a step further, Toole\net al. [40], use criminal offense records to identify spatio-\ntemporal patterns at multiple scales. They employ various\nquantitative tools from mathematics and physics and identify\nsigniﬁcant correlation in both space and time in the crime\nbehavioral data.\nMachine learning has also been a popular approach for\ncrime forecasting. Olligschlaeger [27] examines the use of\nMulti-Layer Perceptrons (MLP) on GIS systems. One of the\nuse cases is the prediction of drug related calls for service on\nthe 911 call centers of Pittsburgh USA. By super imposing the\nmap area with a grid of cells, Olligschlaeger creates 445 cells\nof a 2150 sq feet area each. For each cell, 3 call related early\nindicators are calculated: a) the number of weapon related\ncalls, b) the number of robbery related calls and c) the number\nof assaults related calls that occur in the cell area. Additionally,\nthe proportion of commercial to residential properties in the\ncell area and a seasonal index are also used as indicators.\nDue to the lack of processing power in 1997, the MLP neural\nnetwork that was used had a mere 9 neurons in a single hidden\nlayer.\nKianhmer and Alhajj [21], use SVMs in a machine learning\napproach of hotspot location prediction. The success of SVMs\nis re-examined by Yu et al. [45] in comparison to other\nmachine learning approaches like Naive Bayes and Random\nForests. They observe that in the case of residential burglary,\nwhat has happened in a particular place is likely to reoccur.\nGorr and Olligschlaeger compare different regression ap-\nproaches for predicting a set of crime categories using data\nfrom Pittsburgh [14]. They run regressions of different com-\nplexity on the same data set and compare the results. They\nfound that simple time series were outperformed by more\nsophisticated methods. In particular, they found that by using a\nsmoothing coefﬁcient (i.e. applying increased weight on recent\ndata) the predicted mean absolute percent error is improved.\nXu et al. [44], combine online learning with ensemble\nmethods for their spatiotemporal forecast framework. This\nframework estimates the optimal weights for combining the\nensemble member forecasts. Moreover, it uses an “online”\nalgorithm that revises its previous forecasts when a future\nforecast is incorrect.\nYu et al. [46] propose a new approach to identify the\nhierarchical structure of spatio-temporal patterns at different\nresolution levels and subsequently construct a predictive model\nbased on the identiﬁed structure. They ﬁrst obtain indicators\nwithin different spatio-temporal spaces and construct dis-\ntributed spatio-temporal patterns (DSTP). Next, they use a\ngreedy searching and pruning algorithm to combine the DSTPs\nin order to form an ensemble spatio-temporal pattern (ESTP).\nThe model, named CCRBoost, combines multiple layers of\nweighted ESTPs. They tested this method in predicting res-\nidential burglary, achieving 80% accuracy on a non-publicly\navailable dataset.\nRecently, Wang et al. [41] propose the use of deep learn-\ning for the prediction of hourly crime rates. In particular,\ntheir model ST-ResNet, extends the ResNet [16] model for\nuse in spatio-temporal problems like crime forecasting. They\ndetected that future crime rates depend on the trend set in the\nprevious week, the time of day and the nearby events both in\nspace and in time. For each one of these contributing factors\nthey use a separate ResNet model that offers a prediction based\non indicators of a weekly period, a daily period and an hourly\nperiod respectively. The outputs of the 3 models are combined\nto form a common prediction. They also use external features\n3\nlike day of month, day of week and hour of day to get a more\naccurate prediction.\nWang et al. propose a methodology very similar to Si-\nmonyan and Zisserman [38]. Motivated by the fact that\nvideos can be naturally decomposed into spatial and temporal\ncomponents, Simonyan and Zisserman propose a two stream\napproach that breaks down the learning of video representation\nby using one stream to learn spatial and the other stream to\nlearn temporal clues. For the spatial stream they adopt a typical\nCNN architecture using raw RGB images as input to detect\nappearance information. To account for temporal clues among\nadjacent frames, they explicitly generate multiple-frame dense\noptical ﬂows derived from computing displacement vector\nﬁelds between those frames.\nSince this temporal stream operates on adjacent frames, it\ncan only depict movements within a short time window. The\nsecond and most important problem of this method is that the\norder of the frames is not taken into account. Both problems\nare addressed by Wu et al.[43], by replacing the temporal\nCNN stream with a Long-Short Term Memory (LSTM) [17]\nnetwork, thus leveraging long term temporal dynamics. By\nfusing the outputs of the two streams, they jointly capture\nspatial and temporal features for video classiﬁcation. They\nobserved that CNNs and LSTMs are highly complementary.\nAccording to Ruta et al.[36] high complementarity of methods\nleads to ensemble methods that have excellent generalization\nability.\nIII. PROBLEM FORMULATION\nLet D be the dataset of n four-dimensional vectors xi\nwith i ∈{1, n} where each xi contains information on the\nlocation (longitude and latitude), the time and the type of a\nreported crime (crime category). It is typical in the literature\nto aggregate the spatial information by splitting the city map\nin a two-dimensional grid with cell edge size l, so that a p\ncells square grid is produced (e.g. given a 8km by 8km sized\nmap and a cell edge size l = 500m, p = 16 is calculated and\nthus a 16 × 16 cells grid is produced).\nNext, the xi data points are aggregated in each correspond-\ning cell as a sum of occurrences of a certain crime type.\nMoreover, since the data are time-series of data points, the\ndata are also split in time windows of duration t and create\nmultiple aggregated incident maps I for the whole period T\nof the time-series.\nOur goal is to classify each cell as hotspot or not for a\ncertain type of crime with the highest possible spatial resolu-\ntion in a neighbourhood of the monitored city. Additionally,\nthe hotspots that are predicted should be ranked according\nto the number of crimes that will occur inside their area for\nprioritizing and allocating policing resources more efﬁciently.\nIn order to enhance the probability of an area being predicted\nas a hotspot, we use secondary parallel prediction of the\nnumber of occurrences y for each crime.\nAccordingly, the problem is deﬁned as: a) a binary classiﬁ-\ncation of the cells that will have occurrence of a certain crime\nin a certain time window in the future; b) the probability that\na crime is classiﬁed as a hotspot is dependant on the number\nof occurrences y of a certain crime for each cell in the deﬁned\nfuture time window.\nIV. PROPOSED METHODOLOGY\nCNNs consist of convolutional layers, characterized by an\ninput map I, a bank of ﬁlters K and biases b, producing an\noutput map O. In the case of crime maps, by aggregating the\ncrime incidents xi to cells for every incident type and timespan\nt, we produce an ordered collection of incident maps I for the\nwhole duration T, with height h, width w and c channels such\nthat I ∈Rh×w×c, analogous to a sequence of image frames\nfrom a video. Subsequently, for a bank of d ﬁlters with size\nk1 and k2, we have K ∈Rk1×k2×c×d and biases b ∈Rd, one\nfor each ﬁlter. The output map O ∈Rh×w×d is calculated by\napplying:\nOij =\nk1−1\nX\nm=0\nk2−1\nX\nn=0\nC\nX\nc=0\nKm,n,c · Ii+m,j+n,c + b\n(1)\nfor every i ∈{1, H −k1}, j ∈{1, W −k2}, for each ﬁlter.\nLSTMs, are a variant of RNNs that are better suited to long\nsequences since they do not suffer from the vanishing gradient\neffect [17]. An LSTM cell, maps the input vector x(t) ∈Rn for\neach timestep t to the output vector h(t) ∈Rm, by recursively\ncomputing the activations of the units in the network using the\nfollowing equations:\ni(t) = σ(Wxix(t) + Whih(t−1) + Whih(t) + bi)\nf (t) = σ(Wxfx(t) + Whfh(t) + Whfh(t) + bf)\nc(t) = f (t)c(t−1) + it tanh(Wxcx(t) + Whch(t) + bc)\no(t) = σ(Wxox(t) + Whoh(t−1) + Whoh(t) + bo)\nh(t) = o(t) tanh(c(t))\n(2)\nwhere x(t) and h(t) are the input and output vectors, i(t), f (t),\nc(t), o(t) are respectively the activation vectors of the input\ngate, forget gate, memory cell and output gate, and Wab denote\nthe weight matrix from a to b. In each time step t, the input\nof the LSTM cell consists of the input vector x(t) at time t\nand the output vector h(t−1) from time step t −1.\nBased on the methodology of Wu et al. combination of\nCNNs and RNNs can be jointly used for a spatiotemporal\nforecasting model. Depending on the order that CNNs and\nLSTMs are used, 3 approaches present themselves.\nThe ﬁrst approach, named SFTT (Fig. 1a), passes each\nincident map from a CNN submodel, producing a feature\nvector for every timespan t that encodes the spatial distribution\nof incidents in a feature space that is much smaller than the\noriginal. The sequence of T\nt feature vectors is then fed into\nthe LSTM network which can extract temporal features. All\n11 crime categories are used as input for the incident maps\nin separate input channels. The intuition is that the ratio of\ncrime types in each area encodes implicitly the socioeconomic\nstatus and activities’ proﬁle of the area and thus provides\nbetter modeling of the situation. The justiﬁcation is presented\nin Section VI-C.\nThe second approach is to input the feature maps to an RNN\nsubmodel for temporal feature extraction and then use a CNN\n4\n(a)\n(b)\n(c)\nFig. 1. Overview of the sequence of feature extraction: (a) the spatial features\nﬁrst then the temporal (SFTT), (b) the temporal features ﬁrst then the spatial\n(TFTS) and (c) spatial and temporal features in two parallel branches (ParB)\nfor spatial features. For this approach, named TFTS (Fig. 1b),\nwe ﬁrstly extract a temporal feature vector for each cell by\npassing each sequence of incidents xi of each cell through\nan LSTM network model. The extracted temporal features for\neach cell retain the relative position on the monitored area (i.e.\ntheir cell position), thus temporal maps of the area are created.\nThe temporal maps are then used as input features that are fed\nto a CNN network for spatial information extraction.\nThe third possibility is to extract spatial and temporal\nfeatures in parallel, named ParB (Fig. 1c), using 2 separate\nbranches. The output of the 2 branches can be combined so\nthat prediction accounts for both groups of features.\nFor the spatial feature extraction, we explore four possible\nbody architectures depicted in Fig. 2. Three out of them are\nbased on VGGNet [39], ResNet [16] and FastMask [18],\nrespectively, while the fourth one is a combination of the\nResNet and the FastMask models. All these models were\noriginally designed to extract features from images of size\n224×224 pixels. In order to follow the grid resolution ranges\nused in related crime prediction papers [46, 11, 6, 5], the input\ngrid resolution had to be reduced. Thus, similar models but\nwith smaller input and fewer parameters were implemented.\nA common practice in DL is to take models that are trained\nin one dataset and use them in another dataset, sometimes\neven in different domains. One reason that we did not use\nthe ImageNet [35] pre-trained models of VGG, ResNet and\nFastMask is that we altered the models themselves. Another\nreason is that the ImageNet dataset is not only of a different\n(a)\n(b)\n(c)\n(d)\nFig. 2. Convolutional network body architectures used for the extraction of\nspatial information: (a) VGGNet, (b) ResNet, (c) FastMask, (d) FastResidual-\nMask. Convolutional layers are coloured green, pooling layers are coloured\nyellow and the grey are non-parametric layers (i.e. concatenation)\ndomain but the structural and statistical characteristics of\nimages is completely different than incident maps that a\nrandom start is preferred.\nIn our VGGNet body, we use series of 5 pairs of convolution\nlayers, where the ﬁrst 3 are followed by pooling layers. In the\nﬁrst 4 pairs of convolution layers the ﬁlter size we use is 3×3,\nwhile in the last pair the ﬁlter size is 1×1. The ﬁrst 2 pairs of\nconvolutions apply 32 ﬁlters, the following 2 pairs apply 64\nﬁlters and the last pair applies 256 ﬁlters. In all convolution\nfunction layers the activation function is the Rectiﬁed Linear\nUnits (ReLU), which allows the networks to converge faster\n[39]. The pooling layers use the max operation. We use a Batch\nNormalization layer and a Dropout layer after each pooling\nlayer, since our datasets are fairly small and the possibility\nof overﬁtting is signiﬁcant. The complete CNN body of this\nnetwork is depicted in Fig. 2a.\nA more complex CNN that has proven to be more effective\nin extracting spatial information in image classiﬁcation than\nVGGNet is ResNet [16]. In ResNet, the added residual layers\naim to solve the degradation problem that was encountered\nwhen the convolutional networks became too deep. In every\n5\nconvolution block there is a shortcut connection added to each\npair of 3 × 3 ﬁlters. Inspired by this tactic, we modiﬁed the\nfeature extractor to incorporate residual connections as shown\nin Fig. 2b. In each block, we use 3 convolution layers with\n3 × 3, 1 × 1 and 3 × 3 sized ﬁlters and a parallel residual\nconvolution layer with a ﬁlter size of 3×3. In each consecutive\nblock, the number of ﬁlters in the last convolution layer and the\nresidual layer, is doubled with regard to the previous block.\nThe number of ﬁlters in the ﬁrst 2 convolution layers is a\nquarter of the last. The output of the block layers with the\noutput of the residual layer is then averaged before a max\npooling layer changes the scale.\nIn FastMask [18], Hu et al. use a block of convolutional\nlayers (called a neck) in order to extract features of different\nscales. The features are then concatenated before they are\nforwarded to the next neck. The output of all the necks is also\nconcatenated before passed on to the classiﬁcation layers. In\norder to change scale, in each neck there is an average pooling\nlayer. Each neck has 2 paths for information to ﬂow. In the\none path, the input of the neck is passed through an average\npooling layer, thus zooming out without extracting any new\nfeatures. The other path uses 2 convolutional layers with 3×3\nsized ﬁlters, extracting this way a number of features from\nthis scale. In Fig. 2c we illustrate our own implementation of\nthe FastMask model.\nThe two methods differ in their philosophy of using the\nresidual information. In ResNet the blocks are used sequen-\ntially, while in FastMask the outputs of all blocks are brought\ntogether in one last concatenation layer. Moreover, the residual\ninformation is averaged with the new features in the ResNet\ndesign, while in FastMask the residual information is concate-\nnated to the newly extracted features. By using the blocks of\nResNet in the place of FastMask necks, we create a variation\nwhere averaged main and residual features from each scale are\nthen concatenated (Fig. 2d).\nThe temporal feature extraction in the ﬁrst approach is\nachieved by extracting the temporal correlations in the se-\nquence of vectors holding the spatial features by using an\nLSTM submodel. This LSTM model consists of 3 consequtive\nLSTM layers where the 2 ﬁrst ones have 500 neurons each,\nwhile the last one has the same number of neurons as the\nnumber of cells that the model predicts. In the second and third\napproaches, an LSTM submodel with 3 layers of 32 neurons\nis applied to each cell of the input. Each LSTM layer adds\nanother level of non-linearity in the extraction of temporal\npatterns from the input data.\nIn all proposed models, the extracted spatio-temporal fea-\ntures are ﬁnally fed into two parallel fully connected output\nlayers. On the one output layer we use the binary cross entropy\n(BCE) loss function in order to classify each cell as a hotspot\nor not:\nBCE = −1\nN\nN\nX\ni\n[ˆoi log oi + (1 −ˆoi) log (1 −oi)]\n(3)\nwhere N is the total number of cells, ˆoi is the predicted class\nof cell i and oi is the actual class of cell i.\nOn the other output layer we apply the mean squared error\n(MSE) loss function:\nMSE = −1\nN\nN\nX\ni\n(yi −ˆyi)2\n(4)\nwhere N is the total number of cells, ˆyi is the predicted\nnumber of crimes that will occur in the cell during the target\ntime period and yi is the actual number of crimes that occurred\ninside cell i during the target time period.\nThe loss from both outputs is combined during the back\npropagation step, so that the spatio-temporal features that are\nextracted, affected by the classiﬁcation of a cell as a hotspot\nand to the number of crimes that occurred within the cell.\nThis approach was selected to drive the ﬁnal classiﬁer to give\nbigger probabilities to cells where multiple crimes occur.\nBy changing the binary cross entropy loss function to the\nequivalent multi-class cross entropy (equation 5), we are able\nto predict the hotspot distribution for all the crimes at the same\nnetwork.\nMCCE = −1\nN\nN\nX\ni\nC\nX\nk\n[ˆoik log oik]\n(5)\nV. EXPERIMENTAL SETUP\nA. Algorithms\nIn order to have a proper assessment of the capability of\nthe DL methods, we compare them with the state-of-the-art\nCCRBoost [46] and ST-ResNet [41] methods, as well as eight\nbaseline methodologies that commonly appear in the recent\nrelevant literature.\n1) CCRBoost [46]. CCRBoost starts with multi-clustering\nfollowed by local feature learning processes to discover\nall possible distributed patterns from distributions of\ndifferent shapes, sizes, and time periods. The ﬁnal\nclassiﬁcation label is produced using groupings of the\nmost suitable distributed patterns.\n2) ST-ResNet [41]. The original ST-ResNet model uses 3\nsubmodels with residual connections, that each has 4\ninput channels in parallel, in order to extract indicators\nfrom 3 trends: previous week, time of day and recent\nevents. In our problem, the temporal resolution is not\nhourly but daily so the 3 periods are replaced by day of\nmonth, day of week and recent events equivalently.\n3) Decision Trees(C4.5) [31] using conﬁdence factor of\n0.25; Decision Trees is a non-parametric supervised\nlearning method that predicts the value of a target\nvariable by learning simple decision rules inferred from\nthe data features.\n4) Naive Bayes [47] classiﬁer with a polynomial kernel;\nNaive Bayes methods are a set of supervised learning\nalgorithms based on applying Bayes’ theorem with the\n“naive” assumption of independence between every pair\nof features.\n5) LogitBoost [13] using 100 as its weight threshold; The\nLogitBoost algorithm uses Newton steps for ﬁtting an\nadditive symmetric logistic model by maximum likeli-\nhood.\n6\nTABLE I\nCOMPLEXITY OF ALL ALGORITHMS IN TOTAL TRAINING TIME FOR THE\n“ALL CRIMES” CRIME TYPE IN THE PHILADELPHIA DATASET AND\nNUMBER OF TRAINABLE PARAMETERS FOR THE DL ARCHITECTURES\nAlgorithm\nTraining time\n# Parameters\nCCRBoost\n0:00:38\n-\nDecision Trees (C4.5)\n0:00:02\n-\nNaive Bayes\n0:00:03\n-\nLogit Boost\n0:00:05\n-\nSVM\n0:01:17\n-\nRandom Forests\n0:00:03\n-\nKNN\n0:00:02\n-\nMLP (150)\n0:00:13\n-\nMLP (150, 300, 150, 50)\n0:00:24\n-\nST-ResNet\n0:05:59\n1.343.043\nSFTT-VGG19\n0:48:11\n30.117.120\nTFTS\n0:24:32\n10.260.016\nParB\n3:15:05\n31.942.280\nSFTT-ResNet\n0:17:53\n7.348.899\nSFTT-FastMask\n0:17:57\n6.917.264\nSFTT-FastResMask\n1:53:09\n7.610.299\n6) Random Forests [4] with 10 trees; A random forest is\na meta estimator that ﬁts a number of decision tree\nclassiﬁers on various sub-samples of the dataset and use\naveraging to improve the predictive accuracy and control\nover-ﬁtting.\n7) Support Vector Machine (SVM) [10] with a linear\nkernel; SVMs are learning machines implementing the\nstructural risk minimization inductive principle to obtain\ngood generalization on a limited number of learning\npatterns.\n8) k Nearest Neighbours [1] with 3 neighbours; kNN is a\nclassiﬁer that makes a prediction based on the majority\nvote of the k nearest samples on the feature vector space.\n9) MultiLayer Perceptron (MLP(150)) [27] with one hidden\nlayer of 150 neurons;\n10) MultiLayer\nPerceptron\n(MLP(150,300,150,50))\n[34]\nwith four hidden layers of 150, 300, 150 and 50 neurons\neach;\nThe CCRBoost algorithm was reimplemented by us in\npython, ST-ResNet is based on DeepST [48] which we down-\nloaded from github1 and adapted, while for the rest of the\nbaseline methods we used the implementations available from\nscikit-learn [28]. Our DL experiments were implemented in\nthe Keras framework [7] using the tensorﬂow [23] backend.\nThe complexity of the algorithms is compared, in terms of\ncomputational time and the number of learnable parameters,\nin Table I. The baseline algorithm are typically much faster,\nhowever the DL based ones are also equally applicable since\nthey need minutes of computation to return results. The only\nexception is SFTT-FastResmask which required approx. 2\nhours to converge. All experiments were performed on a\n12core 3.3GHz linux system with 64GB RAM and an Nvidia\nTitanX GPU with CUDA [26].\n1https://github.com/lucktroy/DeepST/tree/master/scripts\n/papers/AAAI17\nTABLE II\nBASIC STATISTICS FOR THE 5 EXAMINED DATASETS\nDataset\nstart year\nend year\nNum. of incidents\nPhiladelphia\n2006\n2017\n2,203,785\nSeattle\n1996\n2016\n684,472\nMinneapolis\n2010\n2016\n136,121\nDC Metro\n2008\n2017\n313,410\nSan Francisco\n2003\n2015\n878,049\nFig. 3. Philadelphia map overlayed with a plotting of all incidents that occured\nin 2006.\nB. Datasets\nIn the last couple of years a number of new datasets have\nbeen published in the ﬁeld of crime prediction, mainly from\nlaw enforcement agencies in the US. In this paper, we have\nselected and used in our experiments, 5 of the most prominent\nopen datasets that can be downloaded from Kaggle2. These 5\ndatasets include incident reports from Seattle3, Minneapolis4,\nPhiladelphia5, San Fransisco6 and Metropolitan DC7 police\ndepartments. While each dataset contains a number of unique\nattributes, all 5 datasets report a location (in latitude and\nlongitude), a time and a type of event for each incident xi.\nThe basic information for each dataset is presented in Table\nII.\nAn example plotting of all incidents from 2006 in the\nPhiladelphia dataset is depicted in Fig. 3.\nSome of the datasets have multiple time attributes recorded,\nfor example, the time when an incident took place and the time\nwhen it was reported. Since the report time is recorded by\nautomatic systems, we selected to use this time feature when\navailable.\nThe datasets include different codes for event types, differ-\nent levels of description for event types and different event\ntypes that are recorded. In order to mitigate the discrepancies\n2https://www.kaggle.com/\n3https://www.kaggle.com/samharris/seattle-crime\n4https://www.kaggle.com/mrisdal/minneapolis-incidents-crime\n5https://www.kaggle.com/mchirico/philadelphiacrimedata\n6https://www.kaggle.com/c/sf-crimedatasets/\n7https://www.kaggle.com/vinchinzu/dc-metro-crime-data\n7\nas much as possible, we decided to homogenize the provided\ndata classes into 10 crime types (i.e. “Homicide”, “Robbery”,\n“Arson”, “Vice”, “Motor Vehicle”, “Narcotics”, “Assault”,\n“Theft”, “Burglary”,“Other”) and assign each of the datasets’\ncategories to one of these. We deﬁned the “Other” category for\nthe crime types that do not easily fall into the other categories\nor where the location is highly constrained or totally irrelevant\nto the crime type as is for example fraud and embezzlement.\nMoreover, we used one class for all aforementioned types of\ncrime, which aims to encapsulate high crime areas irrespective\nof the crime type, named “All Crimes”. A detailed presentation\nof the classes of each dataset and the homogenization approach\nwe followed, is reported in Appendix A.\nThe spatial resolution of all datasets is enough for a block-\nlevel analysis of crime. Being consistent with the grid resolu-\ntion ranges that are used in related crime prediction papers\n[46, 11, 6, 5] the ﬁner block size resolution is deﬁned to\nhave cell edge size l ≈450m, resulting in grids of 40 × 40\ncells. Using an even ﬁner resolution, the resulting grids would\nbe extremely sparse, especially in crime types with a small\nnumber of incidents. The coarser resolution of neighbourhoods\nhas cells with approximate cell edge size l ≈800m, leading\nto grids of 16 × 16 cells. For the different datasets, instead of\nadjusting the number of cells according to actual distances in\nthe cities, we opted to use a ﬁxed number of cells overlayed\non the area under investigation for each dataset.\nWe aim to create a setting where emerging hotspots are\npredicted in advance by evaluating past incidents in the current\nmonth. Thus, the past incidents are aggregated in incident\nmaps I of timespan t of 1 day, and for a period T of 30 days\ni.e. 30 daily incident maps are used as input to forecast crimes\nfor the next period. We used a daily timespan to aggregate\nincidents xi so that enough temporal detail can be extracted\nwhile the time series are sufﬁciently populated.\nThe smallest of our datasets describes just over 4 years of\ndata. For this reason, we extracted from all the datasets 3 years\nof incidents to use as training data and 1 year of incidents for\ntesting purposes. Testing is performed by making a prediction\nfor every month and the reported scores are the mean of the\ntwelve individual prediction scores. The number of samples\nis relatively small but is enough to evaluate which of the\nproposed architectures can perform better.\nEach cell is marked as a hotspot, if at least one incident\noccurred in the following month, otherwise a coldspot. After\nthe crime categories are merged, for the training time period,\nthe average number of hotspots per day is presented in Table\nIII for every crime type. The cells that had no activity in the\ntotal duration of the experiments are considered outside the\nstudy area and were removed from the metrics calculation. In\nTable III we only present the number of cells that remain inside\nthe study area. From these numbers we observe that especially\nin the sparsest crime types there is a class imbalance problem.\nIn order to avoid it, we have selected metrics that take this\nfact into account.\nC. Metrics\nWhen dealing with data that have class imbalance, the\nmetric of accuracy is not very informative because by always\nTABLE III\nMEAN NUMBER OF HOTSPOTS PER DAY FOR EVERY CRIME TYPE AND\nDATASET FOR THE HIGHEST RESOLUTION OF 40 CELLS BY 40 CELLS\nCrime Type\nPhiladelphia\nSeattle\nMinneapolis\nDC Metro\nSan Francisco\nASSAULT\n80.28\n12.84\n3.08\n6.32\n14.96\nTHEFT\n116.72\n21.34\n17.46\n27.39\n40.44\nROBBERY\n20.74\n2.99\n6.13\n10.56\n4.74\nBURGLARY\n23.76\n17.06\n12.36\n9.81\n8.65\nMOTOR VEHICLE\n27.94\n10.01\n14.44\n8.43\n7.77\nARSON\n1.37\n0.10\n0.32\n0.10\n0.29\nHOMICIDE\n0.80\n0.03\n0.74\n0.27\n0.0\nVICE\n4.36\n22.59\n0.72\n0.59\n1.59\nNARCOTICS\n27.90\n3.21\n0.0\n0.0\n5.54\nOTHER\n102.37\n40.15\n0.09\n23.24\n51.81\n# CELLS\n752\n818\n1123\n702\n1057\npredicting the most dominant class the scores will be very\nhigh. F1score is preferred because it is the harmonic mean\nof precision and recall. Precision is the number of correct\npositive results divided by the number of all positive results,\nand recall is the number of correct positive results divided by\nthe number of positive results that should have been returned.\nThe F1score is calculated by:\nF1score = 2 ∗precision ∗recall\nprecision + recall\n(6)\nWith the F1score we measure the ability of the methods to\nboth correctly predict hotspots and how many of the hotspots\nwe identiﬁed at the same time.\nAUROC (Area Under Curve - Receiver Operating Charac-\nteristic) is the calculated area under a receiver operating char-\nacteristic curve. The ROC curve plots parametrically TPR(m)\nversus FPR(m) with m being the probability threshold used\nto classify a prediction as hotspot. The TPR (True Positive\nRate) and FPR (False Positive Rate) are deﬁned as:\nTPR =\nTruehot\nTruehot + Falsecold\n(7)\nFPR =\nFalsehot\nFalsehot + Truecold\n(8)\nThe area under the curve summarizes the performance of\na classiﬁer for all possible thresholds and is equal to the\nprobability that a classiﬁer will rank a randomly chosen\nhotspot higher than a randomly chosen coldspot, when using\nnormalized units [12].\nAUROC =\nZ −∞\n∞\nTPR(m) −FPR′(m)dm\n(9)\nAUCPR (Area Under Curve - Precision Recall) equiva-\nlently, is the calculated area under a precision-recall curve.\nA precision recall curve plots parametrically precision(m)\nversus recall(m) with m the varying parameter as above,\nwhere:\nprecision =\nTruehot\nTruehot + Falsehot\n(10)\nrecall =\nTruehot\nTruehot + Falsecold\n(11)\nPAI (Prediction Accuracy Index), which is deﬁned by\nChainey et al.[6] speciﬁcally for crime prediction and mea-\nsures the effectiveness of the forecasts with the following\nequation:\nPAI =\nr\nR\na\nA\n(12)\n8\nwhere r is the number of crimes that occur in an examined\nforecast area, R is the total number of crimes in the entire map,\na is the forecast area size, and A is the area size of the entire\nmap under study. The PAI metric offers a useful insight to the\neffectiveness of the forecast each method produces, since it not\nonly measures the number of correct hotspots but takes into\naccount the importance of each hotspot, which is our ultimate\ngoal. This metric depends heavily on the percentage of the total\narea that is predicted to be hot. In order to simulate pragmatic\nconditions where a law enforcement agency has a limit to the\navailable resources for ﬁghting crime, we limit the maximum\narea that can be predicted as hot to 5% of the total area and\nreport this metric as PAI@5.\nVI. RESULTS\nThe selected experimental approach was to evaluate which\nof the proposed DL methods is the most robust compared with\nthe state-of-the-art algorithms and select it for further analy-\nsis. In Section VI-A the comparison against all algorithms,\ndatasets and metrics is presented. Section VI-B examines\nthe robustness of the models in varying cell sizes. Sections\nVI-C and VI-D present different submodel conﬁgurations on\nthe selected DL approach. Section VI-E presents the effect\nof batch normalization and dropbout techniques. Finally, the\nimpact of multi-label classiﬁcation compared with the binary\napproach is examined in Section VI-F.\nA. Evaluation of Models\nBy comparing the three main model building approaches,\nwe investigate if the data are more correlated in the spatial\nor temporal axes. In the ﬁrst approach, the spatial dimension\nof the data is explored before the detection of temporal struc-\ntures (SFTT). For the second approach (TFTS), the temporal\ndimension is ﬁrst explored and then, the temporal features are\nused to detect spatial features. In the third approach (i.e. ParB),\nwe use two parallel branches, one to extract spatial features\nand one to extract temporal features. The two sets of features\nare then combined before they are given to the classiﬁer. In\nFig. 4, we present the F1score, AUCPR, AUROC and\nPAI@5, respectively for the DL approaches, compared to the\n10 baseline approaches, per dataset for the “All Crimes” crime\ntype in the highest resolution of p = 40 i.e. 40×40 cells. The\nROC-curves and PR-curves for the same experiment are shown\nin Fig. 5. Similar behaviour appears for the rest of the crime\ntypes.\nFrom the results we can see that all three DL approaches\ngive consistently better performance than the baseline methods\nin the binary classiﬁcation task of a cell being a hotspot or\nnot, with SFTT being the winning approach. For each cell the\nSFTT approach gives the highest scores in all metrics for all\ndatasets except the San Francisco one. The TFTS approach\nfollows in the second place while the ParB approach does not\nperform well in this task.\nB. Evaluation of Cell Size\nThe second major parameter that we evaluated is the effect\nof spatial resolution on the approaches. The resolutions that\n(a)\n(b)\n(c)\n(d)\nFig. 4.\n(a) F1score, (b) PR AUC and (c) ROC AUC per dataset for “All\nCrimes” crime type for the 3 DL models and 10 baseline approaches for cell\nsize of 450m (40 by 40). Best viewed in color.\nwere tested vary from the coarsest resolution of p = 16 (i.e.\n16×16 cells grid) to the ﬁnest of p = 40 cells grid with a step\nof p = 8 cells and the results for every metric are presented\nin Table IV. While increasing the number of cells, the feature\nmaps become sparser.\nIt is evident that increasing the spatial resolution leads\n9\nTABLE IV\nF1SCORE, PRECISION-RECALL AUC, ROC AUC AND PAI@5 FOR DIFFERENT p (I.E. DIFFERENT RESOLUTIONS) IN THE PHILADELPHIA DATASET FOR\n“ALL CRIMES” CRIME TYPE. THE WINNING ALGORITHM IS IN BOLD.\nF1score\nAUCPR\nAUROC\nPAI@5\nAlgorithm\n16\n24\n32\n40\n16\n24\n32\n40\n16\n24\n32\n40\n16\n24\n32\n40\nCCRBoost\n0.93\n0.92\n0.88\n0.88\n0.99\n0.99\n0.98\n0.97\n0.92\n0.92\n0.90\n0.91\n1.87\n1.94\n1.86\n2.00\nDecision Trees (C4.5)\n0.93\n0.92\n0.90\n0.89\n0.99\n0.97\n0.97\n0.96\n0.85\n0.80\n0.78\n0.79\n0.59\n1.51\n1.54\n1.80\nNaive Bayes\n0.92\n0.87\n0.84\n0.83\n0.98\n0.98\n0.98\n0.97\n0.82\n0.89\n0.86\n0.88\n1.21\n2.82\n2.00\n1.93\nLogit Boost\n0.94\n0.92\n0.91\n0.89\n1.00\n0.99\n0.99\n0.99\n0.99\n0.96\n0.94\n0.94\n0.81\n1.73\n2.52\n1.91\nSVM\n0.94\n0.93\n0.91\n0.90\n0.99\n0.99\n0.98\n0.98\n0.91\n0.93\n0.90\n0.90\n0.06\n0.12\n0.19\n0.25\nRandom Forests\n0.94\n0.92\n0.90\n0.89\n1.00\n0.99\n0.98\n0.98\n0.97\n0.94\n0.91\n0.92\n1.04\n2.44\n1.93\n1.98\nKNN\n0.94\n0.92\n0.91\n0.89\n0.99\n0.98\n0.97\n0.97\n0.86\n0.87\n0.84\n0.88\n0.93\n1.66\n1.89\n2.29\nMLP (150)\n0.94\n0.92\n0.90\n0.89\n0.98\n0.99\n0.98\n0.98\n0.84\n0.94\n0.91\n0.92\n2.21\n2.09\n2.30\n2.95\nMLP (150, 300, 150, 50)\n0.94\n0.92\n0.90\n0.89\n0.97\n0.99\n0.98\n0.98\n0.79\n0.91\n0.91\n0.90\n1.31\n2.10\n2.15\n2.70\nST-ResNet\n0.91\n0.88\n0.86\n0.82\n0.99\n0.99\n0.99\n0.99\n0.98\n0.96\n0.96\n0.96\n3.30\n1.62\n2.55\n2.56\nSFTT\n0.99\n0.97\n0.96\n0.94\n1.00\n1.00\n1.00\n0.99\n0.99\n0.98\n0.97\n0.97\n4.02\n4.34\n4.14\n4.33\nTFTS\n0.99\n0.97\n0.95\n0.94\n1.00\n0.98\n0.99\n0.99\n0.95\n0.81\n0.93\n0.96\n4.30\n4.40\n4.10\n4.12\nParB\n0.99\n0.96\n0.94\n0.92\n0.99\n0.99\n0.99\n0.99\n0.88\n0.91\n0.94\n0.94\n4.32\n3.41\n3.29\n3.31\n(a)\n(b)\nFig. 5.\n(a) ROC Curves and (b) Precision-Recall Curves for “All Crimes”\ncrime type for the 4 DL bodies and 10 baseline approaches in the Philadelphia\ndataset. Best viewed in color.\nto a deterioration of F1score for all models, including the\nbaselines. On the other hand, the PAI metric seems to beneﬁt\nfrom the greater detail in some of the compared algorithms,\nwhich is expected, since the same proportion of crimes is\ncorrectly predicted but inside a smaller proportion of the\nstudy area. In the AUC metrics, the SFTT approach constantly\noutperfoms all other approaches.\nHaving these results as guide to our further research, the\nSFTT approach was selected for the rest of our experiments\nas the winning conﬁguration.\nC. Evaluation of Spatial Body\nHaving selected the SFTT approach, Fig. 6 presents a\ncomparison of the 4 bodies’ performance for various crime\ntypes. In all of the metrics the FastMask model has the\nworst performance compared to the other bodies. While the\nFastResMask body has similar performance with the ResNet\nbody, the later has fewer parameters (therefore a smaller\nmemory footprint) and is faster to train (Table I). We can\nconclude that for this task, the extraction of features from\ndifferent scales of the data is reduntant and ineffective.\nThe VGG body performs equivalently with the ResNet body\nin the F1score metric (Fig. 6a) which measures the correctly\nidentiﬁed hotspots when considering all the cells inside the\nstudy area. In the AUC metrics (Fig. 6b and 6c), which\nmeasure the probability that a randomly selected hotspot is\ncorrectly identiﬁed as such, the VGG body performs better\nthan the ResNet body.\nOn the other hand, in the 4 crime types with the more\nincidents, the performance of the VGG body is inferior to\nthat of ResNet for the PAI metric (Fig. 6d) which measures if\nthe more signiﬁcant (in terms of more occuring crimes) cells\nare marked as more probable to be hotspots.\nA new set of experiments was conducted for the selection\nand modeling of input data with only 1 crime category as\ninput versus all 11 crime categories as input. Our experiments\nveriﬁed that the proposed setup of having all 11 crime cate-\ngories as input channels contributes positively to the F1score\nperformance of the model by a factor of 2.5% in the Seattle\ndataset, up to 4.5% in the Philadelphia dataset.\nD. Evaluation of Temporal Body\nThe quality of temporal clues extracted from the temporal\npart of our SFTT model can be affected by the depth and\nthe width of the RNN. To evaluate these two parameters we\nperformed experiments ﬁrstly by changing only the depth of\nLSTM layers in the network and then by changing only the\nwidth of the LSTM layers.\nThe depth of the temporal part of the network is deﬁned by\nthe number of LSTM layers present in the network. For every\nconsecutive LSTM layer a new level of non linear abstraction\nis introduced in the network. We evaluated the effect by using\n10\n(a)\n(b)\n(c)\n(d)\nFig. 6. (a) F1score, (b) PR AUC, (c) ROC AUC and (d) PAI@5 per crime type\nin the Philadelphia dataset, for 4 spatial clue extractor bodies. Best viewed in\ncolor.\nfrom one to nine LSTM layers to reveal that there was no\nsigniﬁcant gain by adding more layers. More speciﬁcally, the\nF1score of our tested model in the Philadelphia “All Crimes”,\nwhich is the class with most data, was 0.94289 ± 0.00003\nin all examined depths. Following the same behaviour, the\nF1score of the model on Philadelphia “Burglary” (sparse with\nfew records) was at 0.76475 ± 0.00017 for all numbers of\nLSTM layers.\nThe width of the network is deﬁned by the number of hidden\nstates that exist in each LSTM layer and deﬁnes the amount\nof temporal information that can be modelled. To examine the\neffect that LSTM layers’ width has on the performance of the\nmodel, we varied the width up to 500 hidden neurons in each\nLSTM layer. We observed in the results that almost all the\navailable temporal information can be captured with LSTM\nlayers of only 50 hidden neurons.\nE. Evaluation of Batch Normalization and Dropout\nThe amount of data that is available for the training process\nis fairly small, compared to image classiﬁcation datasets with\nmillions of samples. This lack of data can lead to networks\nthat overﬁt by learning the training data but not being able to\ngeneralise properly.\nIn DL literature the two most common methods to overcome\noverﬁtting problems is the use of Batch Normalization and\nDropout. We used Batch Normalization after every pooling\nlayer and tested several variations of Dropout layers. When\nwe removed Batch Normalization the performance dropped\nsigniﬁcantly.\nA Dropout layer, randomly zeroes out a percentage of the\ninput data values, during the training phase, thus creating\nvariations of the training data in each epoch. These random\nvariations effectively multiply the number of training samples\nand allow the networks to generalize better. By increasing the\npercentage of dropout, more virtual samples are created but the\ndata become sparser. In order to ﬁnd the best compromise, we\ninvestigated dropout percentages from 10% up to 90%. Adding\nmore dropout helps the predictor to generalize a little bit better\nfor the more populated “All Crimes” crime type in predicting\nthe most probable hotspots. For all other crime types, varying\nthe percentage of dropout has no measurable effect.\nF. Multi-label hotspot classiﬁcation\nAs a ﬁnal experiment on the conﬁguration of the proposed\napproach, a multi-label classiﬁcation was tested. The aim was\nto evaluate how the proposed model performs when simulta-\nneously predicting the probability for each cell to be a hotspot\nfor all possible crime types at the same time. To do so, the last\nlayers’ dimension was changed from 1 (binary classiﬁcation)\nto 11, which is the number of crime types in the dataset. The\nloss function was also modiﬁed from binary cross entropy\nto multi-class cross entropy. In order for the predictions of\nthis setup to remain comparable with our previous results, we\nkept the last layer activation function to sigmoid, which is the\ntypical for the conﬁguration of multi-label models. For this\nexperiment, the SFTT model with ResNet spatial body was\nused and the results are presented in Fig. 7. As it is expected,\nthe binary classiﬁcation model outperforms the multi-label\nmodel in each crime type except the “All Crimes” type were\nthe same performance is observed. This is observed due to\nclass imbalance as well as difﬁculty of the model to predict\naccurately all the labels (i.e. classes), due to the sparsity of\nthe data.\nREFERENCES\n11\nFig. 7.\nF1score per crime type in the Philadelphia dataset, for binary and\nmulti-label hotspot prediction. Best viewed in color.\nVII. CONCLUSIONS AND FUTURE WORK\nIn this paper we investigated the capability of DL methods\nto forecast hotspot areas in an urban environment, where\ncrimes of certain types are more likely to occur in a deﬁned\nfuture window. To achieve this goal we fed the DL methods\nwith the minimum amount of data containing only spatial,\ntemporal and crime type information. In order for the models\nto better predict the order of “hotness” we used a dual output\nsetting where the second output is the number of crimes that\noccurred in the same future window. Moreover, we selected\nour SFTT model conﬁguration as the winning one, compared\nwith 10 different algorithms in 5 crime incidence datasets and\nfurther analysed the selected parameters for robust results.\nIn the future, we will investigate if incorporating additional\ninformation to our system, like temporal semantics, demo-\ngraphics, weather, street maps and points of interest in the\narea can help our model to learn better features. Temporal\nsemantics can help the prediction of ﬂuctuations in crime rates\nthat depend on seasonal events, like holidays, and time of day\nevents, like shift change in stores.\nBy replacing dense layers with convolutional in both the\ntemporal clues extraction and the classiﬁcation parts of the\nmodel, in a full convolutional network fashion, we can increase\nthe spatial resolution. Another road that we did not explore is\nto pre-process and augment the available data. Preprocessing\nsteps could include normalization of the data and blind source\nseparation, while data augmentation can come from ﬂipping\nand rotating the data on their spatial dimensions. Additional\ndata could be created by changing the shift of the temporal\nsliding window from daily to hourly rate.\nREFERENCES\n[1]\nSunil Arya et al. “An optimal algorithm for approxi-\nmate nearest neighbor searching ﬁxed dimensions”. In:\nJournal of the ACM (JACM) 45.6 (1998), pp. 891–923.\n[2]\nChristopher M Bishop. “Pattern recognition”. In: Ma-\nchine Learning 128 (2006), pp. 1–58.\n[3]\nKate J Bowers and Shane D Johnson. “Who commits\nnear repeats? A test of the boost explanation”. In:\nWestern Criminology Review 5.3 (2004), pp. 12–24.\n[4]\nLeo Breiman. “Random forests”. In: Machine learning\n45.1 (2001), pp. 5–32.\n[5]\nSpencer Chainey and Jerry Ratcliffe. GIS and crime\nmapping. John Wiley & Sons, 2013.\n[6]\nSpencer Chainey, Lisa Tompson, and Sebastian Uhlig.\n“The utility of hotspot mapping for predicting spatial\npatterns of crime”. In: Security Journal 21.1-2 (2008),\npp. 4–28.\n[7]\nFrancois Chollet et al. Keras. https://github.com/keras-\nteam/keras. 2015.\n[8]\nLawrence E Cohen and Marcus Felson. “Social change\nand crime rate trends: A routine activity approach”. In:\nAmerican sociological review (1979), pp. 588–608.\n[9]\nDerek B Cornish and Ronald V Clarke. The reasoning\ncriminal: Rational choice perspectives on offending.\nTransaction Publishers, 2014.\n[10]\nCorinna Cortes and Vladimir Vapnik. “Support-vector\nnetworks”. In: Machine learning 20.3 (1995), pp. 273–\n297.\n[11]\nJohn\nEck\net\nal.\n“Mapping\ncrime:\nUnderstanding\nhotspots”. In: (2005).\n[12]\nTom Fawcett. “An introduction to ROC analysis”. In:\nPattern recognition letters 27.8 (2006), pp. 861–874.\n[13]\nJerome Friedman, Trevor Hastie, Robert Tibshirani,\net al. “Additive logistic regression: a statistical view\nof boosting (with discussion and a rejoinder by the\nauthors)”. In: The annals of statistics 28.2 (2000),\npp. 337–407.\n[14]\nWilpen Gorr, Andreas Olligschlaeger, and Yvonne\nThompson. “Short-term forecasting of crime”. In: Inter-\nnational Journal of Forecasting 19.4 (2003), pp. 579–\n594.\n[15]\nTony H Grubesic and Elizabeth A Mack. “Spatio-\ntemporal interaction of urban crime”. In: Journal of\nQuantitative Criminology 24.3 (2008), pp. 285–306.\n[16]\nKaiming He et al. “Deep residual learning for image\nrecognition”. In: Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition. 2016,\npp. 770–778.\n[17]\nSepp Hochreiter and J¨urgen Schmidhuber. “Long short-\nterm memory”. In: Neural computation 9.8 (1997),\npp. 1735–1780.\n[18]\nHexiang Hu et al. “FastMask: Segment Multi-scale\nObject Candidates in One Shot”. In: arXiv preprint\narXiv:1612.08843 (2016).\n[19]\nShane D Johnson, Kate Bowers, and Alex Hirschﬁeld.\n“New insights into the spatial and temporal distribution\nof repeat victimization”. In: The British Journal of\nCriminology (1997), pp. 224–241.\n[20]\nShane D Johnson et al. “Space–time patterns of risk: a\ncross national assessment of residential burglary victim-\nization”. In: Journal of Quantitative Criminology 23.3\n(2007), pp. 201–219.\n[21]\nKeivan Kianmehr and Reda Alhajj. “Effectiveness of\nsupport vector machine for crime hot-spots prediction”.\nIn: Applied Artiﬁcial Intelligence 22.5 (2008), pp. 433–\n458.\n[22]\nNed Levine and II CrimeStat. “A spatial statistics\nprogram for the analysis of crime incident locations”.\n12\nIn: Ned Levine and Associates, Houston, TX, and the\nNational Institute of Justice, Washington, DC (2002).\n[23]\nMart´ın Abadi et al. TensorFlow: Large-Scale Machine\nLearning on Heterogeneous Systems. Software avail-\nable from tensorﬂow.org. 2015. URL: https : / / www.\ntensorﬂow.org/.\n[24]\nGeorge O Mohler et al. “Self-exciting point process\nmodeling of crime”. In: Journal of the American Sta-\ntistical Association 106.493 (2011), pp. 100–108.\n[25]\nTomoki Nakaya and Keiji Yano. “Visualising Crime\nClusters in a Space-time Cube: An Exploratory Data-\nanalysis Approach Using Space-time Kernel Density\nEstimation and Scan Statistics”. In: Transactions in GIS\n14.3 (2010), pp. 223–239.\n[26]\nCUDA Nvidia. Programming guide. 2010.\n[27]\nAndreas M Olligschlaeger. “Artiﬁcial neural networks\nand crime mapping”. In: Crime mapping and crime\nprevention (1997), pp. 313–348.\n[28]\nFabian Pedregosa et al. “Scikit-learn: Machine learning\nin Python”. In: Journal of Machine Learning Research\n12.Oct (2011), pp. 2825–2830.\n[29]\nWalt L Perry. Predictive policing: The role of crime\nforecasting in law enforcement operations. Rand Cor-\nporation, 2013.\n[30]\nJose Florencio de Queiroz Neto, Emanuele Marques\ndos Santos, and Creto Augusto Vidal. “MSKDE-Using\nMarching Squares to Quickly Make High Quality Crime\nHotspot Maps”. In: Graphics, Patterns and Images\n(SIBGRAPI), 2016 29th SIBGRAPI Conference on.\nIEEE. 2016, pp. 305–312.\n[31]\nJ Ross Quinlan. C4. 5: programs for machine learning.\nElsevier, 2014.\n[32]\nJerry H Ratcliffe. “A temporal constraint theory to\nexplain opportunity-based spatial offending patterns”.\nIn: Journal of Research in Crime and Delinquency 43.3\n(2006), pp. 261–291.\n[33]\nMurray Rosenblatt et al. “Remarks on some nonpara-\nmetric estimates of a density function”. In: The Annals\nof Mathematical Statistics 27.3 (1956), pp. 832–837.\n[34]\nDennis W Ruck et al. “The multilayer perceptron as an\napproximation to a Bayes optimal discriminant func-\ntion”. In: IEEE Transactions on Neural Networks 1.4\n(1990), pp. 296–298.\n[35]\nOlga Russakovsky et al. “Imagenet large scale visual\nrecognition challenge”. In: International Journal of\nComputer Vision 115.3 (2015), pp. 211–252.\n[36]\nDymitr Ruta, Bogdan Gabrys, and Christiane Lemke.\n“A generic multilevel architecture for time series pre-\ndiction”. In: IEEE Transactions on Knowledge and Data\nEngineering 23.3 (2011), pp. 350–359.\n[37]\nBernard W Silverman. Density estimation for statistics\nand data analysis. Vol. 26. CRC press, 1986.\n[38]\nKaren\nSimonyan\nand\nAndrew\nZisserman.\n“Two-\nstream convolutional networks for action recognition in\nvideos”. In: Advances in neural information processing\nsystems. 2014, pp. 568–576.\n[39]\nKaren Simonyan and Andrew Zisserman. “Very deep\nconvolutional networks for large-scale image recogni-\ntion”. In: arXiv preprint arXiv:1409.1556 (2014).\n[40]\nJameson\nL\nToole,\nNathan\nEagle,\nand\nJoshua\nB\nPlotkin. “Spatiotemporal correlations in criminal of-\nfense records”. In: ACM Transactions on Intelligent\nSystems and Technology (TIST) 2.4 (2011), p. 38.\n[41]\nBao Wang et al. “Deep Learning for Real Time Crime\nForecasting”.\nIn:\narXiv\npreprint\narXiv:1707.03340\n(2017).\n[42]\nD Williamson et al. “Tools in the spatial analysis\nof crime. Mapping and analysing crime data”. In: A.\nHirschﬁeld and K. Bowers. London and New York,\nTaylor & Francis 1 (2001), p. 187.\n[43]\nZuxuan Wu et al. “Modeling spatial-temporal clues in\na hybrid deep learning framework for video classiﬁca-\ntion”. In: Proceedings of the 23rd ACM international\nconference on Multimedia. ACM. 2015, pp. 461–470.\n[44]\nJianpeng Xu et al. “Online Multi-Task Learning Frame-\nwork for Ensemble Forecasting”. In: IEEE Transac-\ntions on Knowledge and Data Engineering 29.6 (2017),\npp. 1268–1280.\n[45]\nChung-Hsien\nYu\net\nal.\n“Crime\nforecasting\nusing\ndata mining techniques”. In: Data Mining Workshops\n(ICDMW), 2011 IEEE 11th International Conference\non. IEEE. 2011, pp. 779–786.\n[46]\nChung-Hsien Yu et al. “Hierarchical Spatio-Temporal\nPattern Discovery and Predictive Modeling”. In: IEEE\nTransactions on Knowledge and Data Engineering 28.4\n(2016), pp. 979–993.\n[47]\nHarry Zhang. “The optimality of naive Bayes”. In: AA\n1.2 (2004), p. 3.\n[48]\nJunbo Zhang, Yu Zheng, and Dekang Qi. “Deep Spatio-\nTemporal Residual Networks for Citywide Crowd Flows\nPrediction.” In: AAAI. 2017, pp. 1655–1661.\n",
  "categories": [
    "cs.LG",
    "cs.CY",
    "stat.ML"
  ],
  "published": "2018-12-03",
  "updated": "2018-12-03"
}