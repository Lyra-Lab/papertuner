{
  "id": "http://arxiv.org/abs/1812.01967v2",
  "title": "Unsupervised Feature Learning Architecture with Multi-clustering Integration RBM",
  "authors": [
    "Jielei Chu",
    "Hongjun Wang",
    "Jing Liu",
    "Zhiguo Gong",
    "Tianrui Li"
  ],
  "abstract": "In this paper, we present a novel unsupervised feature learning architecture,\nwhich consists of a multi-clustering integration module and a variant of RBM\ntermed multi-clustering integration RBM (MIRBM). In the multi-clustering\nintegration module, we apply three unsupervised K-means, affinity propagation\nand spectral clustering algorithms to obtain three different clustering\npartitions (CPs) without any background knowledge or label. Then, an unanimous\nvoting strategy is used to generate a local clustering partition (LCP). The\nnovel MIRBM model is a core feature encoding part of the proposed unsupervised\nfeature learning architecture. The novelty of it is that the LCP as an\nunsupervised guidance is integrated into one step contrastive divergence (CD1)\nlearning to guide the distribution of the hidden layer features. For the\ninstance in the same LCP cluster, the hidden and reconstructed hidden layer\nfeatures of the MIRBM model in the proposed architecture tend to constrict\ntogether in the training process. Meanwhile, each LCP center tends to disperse\nfrom each other as much as possible in the hidden and reconstructed hidden\nlayer during training. The experiments demonstrate that the proposed\nunsupervised feature learning architecture has more powerful feature\nrepresentation and generalization capability than the state-of-the-art graph\nregularized RBM (GraphRBM) for clustering tasks in the Microsoft Research Asia\nMultimedia (MSRA-MM)2.0 dataset.",
  "text": "1\nUnsupervised Feature Learning Architecture with\nMulti-clustering Integration RBM\nJielei Chu, member, IEEE, Hongjun Wang, Jing Liu,\nZhiguo Gong, Senior member, IEEE, Tianrui Li, Senior member, IEEE\nAbstract—In this paper, we present a novel unsupervised\nfeature learning architecture, which consists of a multi-clustering\nintegration module and a variant of RBM termed multi-clustering\nintegration RBM (MIRBM). In the multi-clustering integration\nmodule, we apply three unsupervised K-means, afﬁnity propaga-\ntion and spectral clustering algorithms to obtain three different\nclustering partitions (CPs) without any background knowledge\nor label. Then, an unanimous voting strategy is used to generate\na local clustering partition (LCP). The novel MIRBM model is a\ncore feature encoding part of the proposed unsupervised feature\nlearning architecture. The novelty of it is that the LCP as an\nunsupervised guidance is integrated into one step contrastive\ndivergence (CD1) learning to guide the distribution of the hidden\nlayer features. For the instance in the same LCP cluster, the\nhidden and reconstructed hidden layer features of the MIRBM\nmodel in the proposed architecture tend to constrict together\nin the training process. Meanwhile, each LCP center tends to\ndisperse from each other as much as possible in the hidden\nand reconstructed hidden layer during training. The experiments\ndemonstrate that the proposed unsupervised feature learning\narchitecture has more powerful feature representation and gen-\neralization capability than the state-of-the-art graph regularized\nRBM (GraphRBM) for clustering tasks in the Microsoft Research\nAsia Multimedia (MSRA-MM)2.0 dataset.\nKeywords-multi-clustering integration RBM; unsupervised fea-\nture learning; CD1 learning; image clustering.\nI. INTRODUCTION\nFeature learning is a crucial phase in many applications (e.g.\nvisual recognition [1], scene analysis [2], object recognition\n[3], multimodal learning [4], [5], speech recognition [6], image\nclassiﬁcation [7]). Supervised feature learning has achieved\ngreat success in machine learning [8]. However, the labeled\ndata is scarce in many applications. In recent years, some\nworks focus on the unsupervised feature learning method [9],\n[10], [11], [12], [13], [14]. But, how to obtain appropriate\nfeatures distribution without any background is still a hard\nproblem in machine learning. To address this, a novel un-\nsupervised feature learning architecture with multi-clustering\nintegration RBM is designed in this paper.\nMany modeling paradigms such as autoencoders and\nJielei Chu, Hongjun Wang, Tianrui Li (the corresponding author) are with\nthe Institute of Artiﬁcial Intelligence, School of Information Science and\nTechnology, Southwest Jiaotong University, Chengdu 611756, China. Tianrui\nLi is also with National Engineering Laboratory of Integrated Transportation\nBig Data Application Technology, Southwest Jiaotong University, Chengdu\n611756, China. e-mails: {jieleichu, wanghongjun, trli}@swjtu.edu.cn.\nJing Liu is with the School of Business, Sichuan University, Sichuan,\n610065, Chengdu, China. e-mail: liujing@scu.edu.cn.\nZhiguo Gong is with the State Key Laboratory of Internet of Things for\nSmart City, Department of Computer and Information Science, University of\nMacau, Macau, China. Email: fstzgg@um.edu.mo\nenergy-based models have been applied to feature learning.\nThe restricted Boltzmann machine (RBM) [15] is a popular\nenergy-based model for unsupervised feature learning and\naims to explore appropriate hidden features. The structure of\na RBM is a bipartite graph consisting of a binary visible layer\nand a binary hidden layer. There are no connections between\nthe visible layer units and the hidden layer units. The most\npopular learning algorithms of RBM such as stochastic max-\nimum likelihood [16] and contrastive divergence (CD) [17]\nbase on the efﬁcient Gibbs sampling. There are a large number\nof successful applications based on the RBMs, e.g., speaker\nrecognition [6], feature fusion [5], clustering [9], classiﬁcation\n[18], [19], [20], computer vision [21] and speech recognition\n[22]. Meanwhile, various variants of the RBMs have been\nproposed by the researchers, e.g., pairwise constraints RBM\nwith Gaussian visible units (pcGRBM) [23], classiﬁcation\nRBM [24], fuzzy RBM (FRBM) [25] and spike-and-slab RBM\n(ssRBM) [26]. For real-valued data, the RBM with Gaussian\nvisible units [4], [23] as the canonical energy model has\nusually been applied to extract the hidden features from image\ndata. Unlike standard RBM, the visible layer units of the model\nhave Gaussian noise and the hidden layer still maintains binary\nunits. The CD learning can also be used to train the RBM\nwith Gaussian visible units [27]. The hidden representations\nof traditional RBMs do not have explicit instance-level con-\nstraints. So, Chu et al. presented semi-supervised pcGRBM\nin which pairwise constraints are fused into the reconstructed\nvisible layer [23]. However, the labeled data is lacking in many\napplications and it is expensive to obtain more labels. So,\nit is certainly worth exploring unsupervised feature learning\nmethod of RBMs by fusing external interventions.\nIn this paper, we present a novel unsupervised feature\nlearning architecture, which consists of a multi-clustering inte-\ngration module and a variant of RBM termed multi-clustering\nintegration RBM (MIRBM). In the multi-clustering integra-\ntion module, we choose three unsupervised K-means, afﬁnity\npropagation (AP) and spectral clustering (SC) algorithms to\nobtain three different global clustering partitions (CPs). Then,\nan unanimous voting strategy is used to generate the local\nclustering partition (LCP) of visible layer data. Hence, the\nLCP only has partial visible layer data. The visual example\nis shown in Fig. 2. The novel MIRBM model is a core\nfeature encoding part of the proposed unsupervised feature\nlearning architecture. The novelty of it is that the LCP as\nan unsupervised guidance is integrated into the CD1 learning\nto guide the distribution of the hidden layer features. For the\ninstance in the same LCP cluster, the hidden and reconstructed\narXiv:1812.01967v2  [cs.LG]  2 Apr 2020\n2\nhidden layer features of the MIRBM model in the proposed\narchitecture tend to constrict together in the training process.\nMeanwhile, each LCP center tends to disperse from each\nother as much as possible in the hidden and reconstructed\nhidden layer during training. As far as we know, this is the\nﬁrst work to use the LCP as as an unsupervised guidance\nto guide the distribution of the hidden layer features of the\nproposed MIRBM model in the unsupervised feature learning\narchitecture. The contributions of our work are summarized\nbelow.\n• A novel unsupervised feature learning architecture is\nproposed, which consists of a multi-clustering integration\nmodule and an MIRBM model. The multi-clustering\nintegration module is used to obtain unsupervised guid-\nance information. The MIRBM model is a core feature\nencoding part to extract hidden layer features.\n• In the multi-clustering integration module of the proposed\narchitecture, three unsupervised algorithms are employed\nto obtain three different global CPs without any back-\nground knowledge or label. The LCP is generated by the\nunanimous voting strategy from three different CPs.\n• The MIRBM model in the proposed architecture uses the\nLCP as an unsupervised guidance to guide the distribution\nof the hidden layer features by integrating the LCP into\nthe CD1 learning. For the instance in the same LCP\ncluster, the hidden and reconstructed hidden layer features\nof the MIRBM modle in the proposed architecture tend\nto constrict together in the training process. Meanwhile,\neach LCP center tends to disperse from each other as\nmuch as possible in the hidden and reconstructed hidden\nlayer during training.\n• It is demonstrated that the proposed architecture has\nmore powerful feature representation and generalization\ncapability than the state-of-the-art GraphRBM in the\nMicrosoft Research Asia Multimedia (MSRA-MM)2.0\ndataset for image clustering task.\nThe remaining of the paper is organized as follows. The\nliterature review is provided in Section II. In Section III, the\ntheoretical background is described. An unsupervised feature\nlearning architecture together with the MIRBM model are\nproposed in Section IV. The experimental results are shown\nin Section V. Finally, we conclude in Section VI and discuss\na few correlative future work.\nII. LITERATURE REVIEW\nIn this section, we review literature on supervised, semi-\nsupervised, unsupervised feature learning based on RBMs and\nother models, together with the voting strategy in supervised\nlearning.\nSupervised feature learning has proved to be an effective\nmethod in machine learning [7], [28], [8], [29], [30]. Amer\net al. [28] proposed a Multimodal Discriminative CRBMs\n(MMDCRBMs) model based on a Conditional RBMs (an\nextension of the RBM). Its training process is composed\nof training each modality using labeled data and training\na fusion layer. For multi-modality deep learning, Bu et al.\n[31] developed a supervised 3D feature learning framework in\nwhich a RBM is used to mine the deep correlations of different\nmodalities. Cheng et al. [32] presented a novel duplex metric\nlearning (DML) framework for feature learning and image\nclassiﬁcation. The main task of DML is to learn an effective\nhidden layer feature of a discriminative stacked autoencoder\n(DSAE). In the feature space of the DSAE, similar and\ndissimilar samples are mapped close to each other and further\napart, respectively. This framework is the most related work to\nour study, but it belongs to supervised feature learning with a\nDSAE by layer-wisely imposing metric learning method and\nit is applied to image classiﬁcation tasks.\nHowever, supervision information, e.g., labels, is scarce and\nit is expensive to obtain more labels in many applications. So,\nsome works [33], [34], [23] explored semi-supervised feature\nlearning which only needs a small number of labels. Chu\net al. [23] presented a pcGRBM model by fusing pairwise\nconstraints into the reconstructed visible layer for clustering\ntasks. To mitigate the burden of annotation, Yesilbek and\nSezgin [35] applied self-learning methods to build a system\nthat can learn from large amounts of unlabeled data and few\nlabeled examples for sketch recognition. The systems perform\nself-learning by extending a small labeled set with new ex-\namples which are extracted from unlabeled sketches. Chen\net al. [34] developed a deep sparase auto-encoder network\nwith supervised ﬁne-tuning and unsupervised layer-wise self-\nlearning for fault identiﬁcation.\nThe class RBMs have powerful unsupervised feature learn-\ning capability. To exploit more powerful feature leaning ability,\nmany unsupervised feature learning approaches based on the\nRBMs have been proposed by previous researches [36], [37],\n[38], [39], [40], [9], [41]. Chopra and Yadav [39] presented\na unique technique to extract fault feature from the noisy\nacoustic signal by an unsupervised RBM. Zhang et al. [40]\nproposed unsupervised feature learning based on recursive\nautoencoders network (RAE) for image classﬁcation. They\nused the spectral and spatial information from original data\nto produce high-level features. Xie et al. [41] showed a\nnovel approach to optimize RBM pre-training by capturing\nprincipal component directions of the input with principal\ncomponent analysis. Al-Dmour and Al-Ani [42] proposed\na fully-automatic segmentation algorithm in which a neural\nnetwork (NN) model is used to extract the features of the brain\ntissue image and is trained using clustering labels produced by\nthree clustering algorithms. The obtained classes are combined\nby majority voting. The study is closely related to our work,\nbut our encoding framework based on RBMs is guided by\nself-learning local supervisions which stem from unsupervised\nclustering algorithms and unanimous voting strategy. More\nspeciﬁcally, these self-learning local supervisions from visible\nlayers are integrated into the CD learning of RBMs to constrict\nand disperse the distribution of the hidden layer features and\nreconstructed hidden layer features. Stewart and Ermon [43]\npresented a new technique to supervise NN by prior domain\nknowledge for computer vision tasks. It is a related work\nto our study. However, their work faces to a convolutional\nneural network (CNN) and requires large amounts of prior\ndomain knowledge and how to encode prior knowledge into\nloss functions of a CNN is a new challenge.\n3\nTwo existing voting strategies are often used to supervised\nlearning in previous researches. One is the max-voting scheme.\nFor example, Azimi et al. [44] developed a deep learning\nmethod for low carbon steel microstructural classiﬁcation via\nfully CNN (FCNN) accompanied by a max-voting scheme.\nThe other is the majority voting scheme. For example, Seera\net al. [45] applied a recurrent NN (RNN) to extract features\nfrom the Transcranial Doppler (TCD) signals for classiﬁcation\ntasks. This work proposed an ensemble RNN model in which\nthe majority voting scheme is used to combine the single RNN\npredictions. Recently various voting classiﬁers using majority\nvoting have been proposed to enhance the performance of the\nclassiﬁcation [46], [47], [48], [49], [50], [51].\nChen et al. [9] illustrated a new graph regularized RBM\n(GraphRBM) to extract hidden layer representations for un-\nsupervised clustering and classiﬁcation problem. Meanwhile,\nthey have considered the manifold structure of the image\ndata. The GraphRBM is a state-of-the-art unsupervised feature\nlearning model and it is also the most relevant work to our\nmethod. Hence, we compare our unsupervised feature learning\narchitecture with the GraphRBM in the experiments.\nIII. THEORETICAL BACKGROUND\nA. Restricted Boltzmann Machine\nA RBM [15] consists of two-layer structure: a visible\nlayer and a hidden layer with stochastic binary units via\nsymmetrically weighted connections. It has no interior-layer\nconnections both between the visible layer units and between\nthe hidden layer units. An energy function of a joint distri-\nbution of the visible layer and hidden layer units takes the\nform:\nE(v, h) = −\nX\ni∈visibles\naivi −\nX\nj∈hiddens\nbjhj −\nX\ni,j\nvihjwij,\n(1)\nwhere v is the visible layer vector and vi is the binary states of\nvisible unit i, h is the hidden layer vector and hj is the binary\nstates of hidden unit j, ai and bj are the biases of visible layer\nand hidden layer respectively, wij is the symmetric connection\nweight between vi and hj.\nThe probability distribution over a vector v and with the\nparameters θ = {a, b, W} takes the form:\np(v, θ) = e−E(v,θ)\nZ(θ)\n(2)\nwhere Z(θ) = P\nv\ne−E(v,θ) is a normalisation constant, a is\na vector of the visible layer biases, b is a vector of the\nhidden layer biases, W is connection matrix. The conditional\nprobability distributions of hidden layer and visible layer units\nof the RBM are given by:\np(hj = 1|v) = σ(bj +\nX\ni\nviwij)\n(3)\nand\np(vi = 1|h) = σ(ai +\nX\nj\nhjwij),\n(4)\nwhere σ is the sigmoid function.\nB. Gaussian Linear Visible Units\nThe classical RBM was designed with binary units for both\nthe hidden and visible layers [17]. For training real-valued\ndata, the visible layer of RBM consists of Gaussian linear\nunits and the hidden layer of RBM is still binary units. The\nenergy function of RBM with Gaussian linear visible units\ntakes the form:\nE(v, h) = −\nX\ni∈visibles\n(vi −ai)2\n2σ2\ni\n−\nX\nj∈hiddens\nbjhj−\nX\ni,j\nvi\nσi\nhjwij,\n(5)\nwhere σi is the standard deviation of visible unit i with\nGaussian noise. In the visible layer, the conditional probability\nis deﬁned by:\np(v|h) = N(\nX\nhWT +, σ2),\n(6)\nwhere N(·) represents gaussian density (µ = P hWT + a).\nThe update rules of the parameters become simple when the\nlinear visible units have unit variance of Gaussian noise. Then,\nthe reconstructed values of Gaussian linear visible units are\nequal to their top-down input values from the binary hidden\nunits plus their bias.\nC. Contrastive Divergence Learning\nTo learn the parameters of symmetric connection weight\nof the RBM by Maximum-likelihood (ML) learning [17], the\nupdate rule is given by:\n∆wij = ε(< vihj >0 −< vihj >∞),\n(7)\nwhere ε is a learning rate, the angle brackets denote the\nexpectations of the distribution, < vihj >∞represents the\nexpectations under the distribution of the RBM model. But it\nis very hard to obtain unbiased sample of < vihj >∞.\nSo, a faster learning algorithm [17] was proposed by apply-\ning approximation of the gradient of CD. Karakida et al. [27]\ndemonstrated that CD1 learning is simpler than Maximum-\nlikelihood (ML) learning in RBMs. The CD1 learning follows\nthe gradient of the difference of two divergences approxi-\nmately as follows:\nCD1 = KL(p0||p∞) −KL(p1||p∞),\n(8)\nwhere KL(p0||p∞) = P\nv\np0(v)log p0(v)\np(v;θ ) and KL(p1||p∞) =\nP\nv\np1(v)log p1(v)\np(v;θ) are Kullback-Leibler divergences, p0 is the\ndistribution of the data, p1 is the ﬁrst step distribution of the\nMarkov chain and p∞is the distribution of the model. Then\nthe change of symmetric connection weight with CD1 learning\nis given by:\n∆wij = ε(< vihj >0 −< vihj >1),\n(9)\nwhere the hidden layer units are driven by visible data,\n< vihj >0 denotes the expectations under the distribution\nof visible and hidden layer units, < vihj >1 represents the\nexpectations under the distribution of reconstructed visible and\nhidden layer units. Similarly, the changes of biases ai and bj\nwith CD1 learning are given by:\n∆ai = ε(< vi >0 −< vi >1)\n(10)\n4\nand\n∆bj = ε(< hj >0 −< hj >1).\n(11)\nSo, the update rules of all parameters take the form\nw(τ+1)\nij\n= w(τ)\nij + ε(< vihj >0 −< vihj >1),\n(12)\na(τ+1)\ni\n= a(τ)\ni\n+ ε(< vi >0 −< vi >1)\n(13)\nand\nb(τ+1)\nj\n= b(τ)\nj\n+ ε(< hj >0 −< hj >1).\n(14)\nThe learning efﬁciency can be obviously improved by the CD1\nlearning.\nIV. UNSUPERVISED FEATURE LEARNING ARCHITECTURE\nWITH MIRBM\nIn this section, we present a novel unsupervised feature\nlearning architecture. The MIRBM model as a core part of the\narchitecture is used to extract hidden layer features. Then, the\ndetailed inferences for the update rules of the MIRBM model\nparameters are listed. We design a learning algorithm of the\nMIRBM model and analyse its convergence and complexity.\nA. Architecture\nTo explore more effective unsupervised feature learning\nmethod, we construct a novel feature learning architecture,\nwhich consists of a multi-clustering integration module and\nan MIRBM model. It is shown in Fig. 1. The multi-clustering\nintegration module is used to generate an unsupervised guid-\nance LCP for the next MIRBM model. Three unsupervised\nK-means, AP and SC algorithms are applied to obtain three\nCPs, then an unanimous voting strategy is used to generate\nthe LCP. An example of multi-clustering integration module\nis shown in Fig. 2.\nThe MIRBM model is a most important part of the archi-\ntecture. The unsupervised LCP information is integrated into\nthe CD1 learning to guide the train process of it. With the LCP\nassistance, the hidden and reconstructed hidden layer features\nof MIRBM model tend to constrict together in the training\nprocess for the instance in the same LCP cluster. Meanwhile,\neach LCP center tends to disperse from each other as much as\npossible in the hidden and reconstructed hidden layer during\ntraining.\nB. The MIRBM model\nSuppose that Vdata = {v1, v2, · · · , vN} is the original data\nset. Hdata = {h1, h2, · · · , hN} is the hidden layer feature\nset. Vrecon = {ev1,ev2, · · · ,evN} is the reconstructed visible\nlayer data set. Hrecon = {eh1, eh2, · · · , ehN} is the hidden\nfeatures set of reconstructed data. Let V1, V2, · · · VK be K\nlocal clusters of visible layer set Vdata, Hi(i = 1, 2, · · · , K)\nare local clusters mapped of Vi(i = 1, 2, · · · , K), respectively.\nSimilarly, eV1, eV2, · · · , eVK are K local clusters of reconstructed\nvisible layer set Vrecon, eHi(i = 1, 2, · · · , K) are K local\nclusters mapped of eVi(i = 1, 2, · · · , K), respectively. We use\nthe gradient descent method to obtain approximate optimal\nparameters of the MIRBM model. In the encoding process, we\nTABLE I\nLIST OF SYMBOLS.\nNotation\nDeﬁnition\nVdata\nVisible layer data set\nHdata\nHidden layer feature set\nVrecon\nReconstructed visible layer set\nHrecon\nHidden layer feature of reconstructed visible layer set\nvs, vt\nVisible layer row vector\nhs, ht\nHidden layer feature row vector\nevs,evt\nReconstructed visible layer row vector\nehs, eht\nHidden layer feature row vector of reconstructed data\nVk\nAll vectors of Vk ⊂Vdata belonging to the same cluster.\neVk\nAll vectors of eVk ⊂Vrecon belonging to the same cluster.\nHk\nAll vectors of Hk ⊂Hdata belonging to the same cluster.\neHk\nAll vectors of eHk ⊂Hrecon belonging to the same cluster.\nCk\nThe center of cluster Hk\neCk\nThe center of cluster eHk\nOk\nThe center of cluster Vk\neOk\nThe center of cluster eVk\nexpect that the hidden features and the reconstructed hidden\nfeatures of the instance in the same LCP cluster become more\nconcentrated together. Meanwhile, each LCP center tends to\ndisperse from each other as much as possible in the hidden\nand reconstructed hidden layer during training of CD1 learning\nmethod. Therefore, the objective function takes form:\nF(θ, Vdata) = −η [KL(p0||p∞) −KL(p1||p∞)] +\n\u00101 −η\nNh\nK\nX\nk=1\nX\nhs,ht∈Hk\n∥hs −ht∥2 −1 −η\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n∥Cp−\nCq∥2\u0011\n+\n\u00101 −η\nNh\nK\nX\nk=1\nX\nehs,eht∈eHk\n∥ehs −eht∥2 −1 −η\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n∥eCp\n−eCq∥2\u0011\n,\n(15)\nwhere η ∈(0, 1) is a scale coefﬁcient, Nh is the cardinality\nof Hk(k = 1, 2, · · · , K), NC =\nK(K−1)\n2\nis the number of\npairwise cluster center.\nTo simplify the expression of the objective function,\nLdata(θ) and Lrecon(θ) functions take form:\nLdata(θ) =\n1\nNh\nK\nX\nk=1\nX\nhs,ht∈Hk\n∥hs −ht∥2 −\n1\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n∥Cp −Cq∥2\n(16)\nand\nLrecon(θ) =\n1\nNh\nK\nX\nk=1\nX\nehs,eht∈eHk\n∥ehs −eht∥2 −\n1\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n∥eCp −eCq∥2.\n(17)\nSo the objective function has another form:\nF(θ, Vdata) = −η [KL(p0||p∞) −KL(p1||p∞)]\n+ (1 −η) [Ldata(θ) + Lrecon(θ)] .\n(18)\n5\n...\n...\n...\n......\n...\n...\nW, a, b\njv\nhn\n~\nh\nh~\nh1\nhj\n~\n...\n~hn\nhj\n...\nh1~\n~\n~\ndata\n~v\n...\n... ṽm\nṽi\nṽ1\n...\n...\nvi\nv1\nvm v\nreconstructed visible data\nData\nK-means\nCP1\nCP2\nCP3\nLCP\nMulti-clustering Integration\nAP\nSC\nUnsupervised Feature Learning Architecture with Multi-clustering Integration RBM\nUnanimous \nVoting\nMIRBM Training\nFig. 1.\nUnsupervised feature learning architecture with MIRBM model. The multi-clustering integration module is used to obtain unsupervised guidance\ninformation LCP by three unsupervised clustering algorithms and unanimous voting strategy. The MIRBM model as a core feature encoding part uses\nunsupervised LCP to guide the distribution of the hidden layer features by integrating the LCP into its training process of CD1 learning.\nUnanimous\n Voting\nLocal Cluster Partition (LCP)\n Cluster Partition (CP)\n CP1\n CP2\n CP3\n K-means\n AP\n SC\nFig. 2.\nAn example of multi-clustering integration module. Left: three kinds of different CPs which contain all instances are generated by K-means, AP and\nSC algorithms. Right: an unanimous voting strategy is used to produce the LCP with three kinds of CPs. The LCP only contains a portion of the instance\nand three dots represent three local centers of it.\nC. The Inference\nThe next hardest problem is how to optimize the objective\nfunction:\narg min\nθ\nF(θ, Vdata)\n(19)\nThe approximate derivative of the KL(p0||p∞) −KL(p1||p∞)\ncan be obtained by CD1 learning method, so the next problems\nare how to get the gradients of Ldata(θ) and Lrecon(θ).\nFirstly, we compute the gradients of Ldata as follows. Because\nLdata(θ) has another equivalent form:\nLdata(θ) =\n1\nNh\nK\nX\nk=1\nX\nhs,ht∈Hk\n(hs −ht)(hs −ht)T\n−\n1\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n(Cp −Cq)(Cp −Cq)T .\n(20)\nThen we can obtain:\n∂Ldata(θ)\n∂wij\n=\n1\nNh\n\u0014 K\nX\nk=1\nX\nhs,ht∈Hk\n(hs −ht)∂(hs −ht)T\n∂wij\n+\nK\nX\nk=1\nX\nhs,ht∈Hk\n∂(hs −ht)\n∂wij\n(hs −ht)T\n\u0015\n−\n1\nNC\n\u0014 K−1\nX\np=1\nK\nX\nq=p+1\n(Cp −Cq)∂(Cp −Cq)T\n∂wij\n+\nK−1\nX\np=1\nK\nX\nq=p+1\n∂(Cp −Cq)\n∂wij\n(Cp −Cq)T\n\u0015\n.\n(21)\nFrom above result, we can see that the following task is how\nto compute\n∂(hs−ht)T\n∂wij\n,\n∂(hs−ht)\n∂wij\n,\n∂(Cp−Cq)T\n∂wij\nand\n∂(Cp−Cq)\n∂wij\n.\n6\nNext, all of them are solved separately.\n∂(hs −ht)T\n∂wij\n= ( ∂hs\n∂wij\n−∂ht\n∂wij\n)T\n=\n\u0014∂(σ(b + vsW))\n∂wij\n−∂(σ(b + vtW))\n∂wij\n\u0015T\n.\n(22)\nObviously, σ(b + vsW) is a row vector, all components of\nwhich are independent of wij except j component. So,\n∂σ(b + vsW)\n∂wij\n=\n(0, · · · , 0\n| {z }\nj−1\n,\n∂σ(bj +\nnP\ni=1\nvsiwij)\n∂wij\n, 0, · · · , 0\n| {z }\nn−j\n).\n(23)\nBecause\n∂σ(bj+\nn\nP\ni=1\nvsiwij)\n∂wij\n= hsj(1 −hsj)vsi, the ﬁnal result\nof ∂σ(b+vsW)\n∂wij\nhas an expression as follows:\n∂σ(b + vsW)\n∂wij\n= (0, · · · , 0\n| {z }\nj−1\n, hsj(1 −hsj)vsi, 0, · · · , 0\n| {z }\nn−j\n).\n(24)\nSimilarly, the expression of ﬁnal result of\n∂σ(b+vtW)\n∂wij\nis as\nfollows:\n∂σ(b + vtW)\n∂wij\n= (0, · · · , 0\n| {z }\nj−1\n, htj(1 −htj)vti, 0, · · · , 0\n| {z }\nn−j\n).\n(25)\nThen, the ﬁnal result of ∂(hs−ht)T\n∂wij\nis a column vector:\n∂(hs −ht)T\n∂wij\n=\n(0, · · · , 0\n| {z }\nj−1\n, hsj(1 −hsj)vsi −htj(1 −htj)vti, 0, · · · , 0\n| {z }\nn−j\n)T .\n(26)\nSimilarly,\n∂(hs −ht)\n∂wij\n=\n(0, · · · , 0\n| {z }\nj−1\n, hsj(1 −hsj)vsi −htj(1 −htj)vti, 0, · · · , 0\n| {z }\nn−j\n),\n(27)\n∂(Cp −Cq)T\n∂wij\n=\n(0, · · · , 0\n| {z }\nj−1\n, Cpj(1 −Cpj)Opi −Cqj(1 −Cqj)Oqi, 0, · · · , 0\n| {z }\nn−j\n)T\n(28)\nand\n∂(Cp −Cq)\n∂wij\n=\n(0, · · · , 0\n| {z }\nj−1\n, Cpj(1 −Cpj)Opi −Cqj(1 −Cqj)Oqi, 0, · · · , 0\n| {z }\nn−j\n).\n(29)\nEqs. (26), (27), (28) and (29) are substituted in Eq. (21). Then\n∂Ldata(θ)\n∂wij\n=\n2\nNh\nK\nX\nk=1\nX\nhs,ht∈Hk\n(hsj −htj)\n\u0014\nhsj(1 −hsj)vsi −htj(1 −htj)vti\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n(Cpj −Cqj)\n\u0014\nCpj(1 −Cpj)Opi−\nCqj(1 −Cqj)Oqi\n\u0015\n.\n(30)\nUsing above same solution, we can obtain:\n∂Lrecon(θ)\n∂wij\n=\n2\nNh\nK\nX\nk=1\nX\nehs,eht∈f\nHk\n(ehsj −ehtj)\n\u0014\nehsj(1 −ehsj)evsi −ehtj(1 −ehtj)evti\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n( eCpj −eCqj)\n\u0014\neCpj(1 −eCpj)eopi−\neCqj(1 −eCqj)eoqi\n\u0015\n.\n(31)\nThe following task is how to obtain\n∂Lrecon(θ)\n∂bj\nand\n∂Lrecon(θ)\n∂bj\n. Because\n∂σ(bj+\nn\nP\ni=1\nvsiwij)\n∂bj\n= hsj(1 −hsj) and\n∂σ(bj+\nn\nP\ni=1\nvtiwij)\n∂bj\n= htj(1−htj), the ﬁnal result of ∂σ(b+vsW)\n∂bj\nand ∂σ(b+vtW)\n∂bj\nhave expressions as follows:\n∂σ(b + vsW)\n∂bj\n= (0, · · · , 0\n| {z }\nj−1\n, hsj(1 −hsj), 0, · · · , 0\n| {z }\nn−j\n)\n(32)\nand\n∂σ(b + vtW)\n∂bj\n= (0, · · · , 0\n| {z }\nj−1\n, htj(1 −htj), 0, · · · , 0\n| {z }\nn−j\n).\n(33)\nSo, the ﬁnal result of ∂Ldata(θ)\n∂bj\nis as follows.\n∂Ldata(θ)\n∂bj\n=\n2\nNh\nK\nX\nk=1\nX\nhs,ht∈Hk\n(hsj −htj)\n\u0014\nhsj(1 −hsj) −htj(1 −htj)\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n(Cpj −Cqj)\n\u0014\nCpj(1 −Cpj)−\nCqj(1 −Cqj)\n\u0015\n.\n(34)\n7\nSimilarly, the expression of ∂Lrecon(θ)\n∂bj\nis as follows.\n∂Lrecon(θ)\n∂bj\n=\n2\nNh\nK\nX\nk=1\nX\nehs,eht∈eHk\n(ehsj −ehtj)\n\u0014\nehsj(1 −ehsj) −ehtj(1 −ehtj)\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n( eCpj −eCqj)\n\u0014\neCpj(1 −eCpj)−\neCqj(1 −eCqj)\n\u0015\n.\n(35)\nBecause\n∂σ(bj+\nn\nP\ni=1\nvsiwij)\n∂ai\n= 0 and\n∂σ(bj+\nn\nP\ni=1\nvtiwij)\n∂ai\n= 0, the\nﬁnal results of ∂σ(b+vsW)\n∂ai\nand ∂σ(b+vtW)\n∂ai\nare zero vectors.\nThen we can obtain: ∂Ldata(θ)\n∂ai\n= 0, ∂Lrecon(θ)\n∂ai\n= 0.\nFinally, following the CD1 learning and the gradient of\nthe Ldata and Lrecon, the update rules of the symmetric\nconnection weight take the form:\nw(τ+1)\nij\n= w(τ)\nij + ηε(< vihj >0 −< vihj >1) + (1 −η)\n(\n2\nNh\nK\nX\nk=1\nX\nhs,ht∈Hk\n(hsj −htj)\n\u0014\nhsj(1 −hsj)vsi −htj(1−\nhtj)vti\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n(Cpj −Cqj)\n\u0014\nCpj(1 −Cpj)Opi\n−Cqj(1 −Cqj)Oqi\n\u0015)\n+ (1 −η)\n(\n2\nNh\nK\nX\nk=1\nX\nehs,eht∈f\nHk\n(ehsj\n−ehtj)\n\u0014\nehsj(1 −ehsj)evsi −ehtj(1 −ehtj)evti\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n( eCpj −eCqj)\n\u0014\neCpj(1 −eCpj)eopi −eCqj(1 −eCqj)eoqi\n\u0015)\n.\n(36)\nThe update rules of biases bj take the form:\nb(τ+1)\nj\n= b(τ)\nj\n+ ηε(< hj >0 −< hj >1) + (1 −η)\n(\n2\nNh\nK\nX\nk=1\nX\nhs,ht∈Hk\n(hsj −htj)\n\u0014\nhsj(1 −hsj) −htj(1 −htj)\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n(Cpj −Cqj)\n\u0014\nCpj(1 −Cpj)−\nCqj(1 −Cqj)\n\u0015)\n+ (1 −η)\n(\n2\nNh\nK\nX\nk=1\nX\nehs,eht∈f\nHk\n(ehsj −ehtj)\n\u0014\nehsj(1 −ehsj) −ehtj(1 −ehtj)\n\u0015\n−\n2\nNC\nK−1\nX\np=1\nK\nX\nq=p+1\n( eCpj −eCqj)\n\u0014\neCpj(1 −eCpj)−\neCqj(1 −eCqj)\n\u0015)\n(37)\nand the update rules of biases ai take the form:\na(τ+1)\ni\n= a(τ)\ni\n+ ηε(< vi >0 −< vi >1).\n(38)\nNext, for iterative updating rules Eqs. (36), (37) and (38),\nthe convergence needs to be analyzed theoretically.\nD. Convergence Analysis\nIn this subsection, we use the convergence analysis method\n[52], [53] to prove that the objective function decreases\nmonotonically by the iterative updating rules Eqs. (36), (37)\nand (38).\nTheorem 1: In each iteration, the objective function Eq.\n(15) will monotonically decrease.\nProof: Assume that aτ, bτ and Wτ have been derived in\nthe τth iteration. We ﬁx aτ and bτ to optimize Wτ. Obviously,\naccording to stochastic gradient descent method, there is the\nfollowing inequality:\nF(aτ, bτ, W(τ+1), Vdata) ≤F(aτ, bτ, Wτ, Vdata)\n(39)\nThen, the parameters W and a are ﬁxed as W(τ+1) and aτ to\noptimize b. We have another inequality:\nF(aτ, b(τ+1), W(τ+1), Vdata) ≤F(aτ, bτ, W(τ+1), Vdata)\n(40)\nSimilarily, the parameters W and b are ﬁxed as W(τ+1) and\nb(τ+1) to optimize a. We get the third inequality:\nF(a(τ+1), b(τ+1), W(τ+1), Vdata) ≤F(aτ, bτ+1, Wτ+1, Vdata)\n(41)\nSo, from Eqs. (39), (40) and (41), we have\nF(aτ+1, bτ+1, Wτ+1, Vdata) ≤F(aτ, bτ, Wτ, Vdata)\n(42)\nThus, the objective function decreases monotonically by the\niterative updating rules Eqs. (36), (37) and (38). The learning\nalgorithm of the MIRBM model is summarized as follows.\nLearning Algorithm of MIRBM\nInput: Vdata is original data set;\nη is a scale coefﬁcient;\nLCP is the local cluster partition of the Vdata.\nOutput: The model parameters of a,b and W.\nFor each iteration do\nFor all visible layer vectors do\nSample hidden layer distribution by Eq. (3);\nEnd For\nFor all hidden layer vectors do\nIf visible layer is binary unit do\nSample reconstructed visible layer distribution by\nEq. (4);\nElse\nSample reconstructed visible layer distribution by\nlinear transformation;\nEnd For\nObtain the gradients of Eqs. (30), (31), (34) and (35);\nUse Eqs. (36), (37) and (38) to update W, b and\n8\nTABLE II\nSUMMARY OF THE EXPERIMENT DATASETS.\nNo.\nDataset\nclasses\nInstances\nfeature\n1\nalphabet\n3\n814\n892\n2\namericanﬂag\n3\n873\n892\n3\naquarium\n3\n922\n892\n4\nbaobab\n3\n900\n892\n5\nbathroom\n3\n924\n892\n6\nberet\n3\n876\n892\n7\nbirthdaycake\n3\n932\n892\n8\nblog\n3\n943\n892\n9\nblood\n3\n866\n892\n10\nboat\n3\n857\n892\n11\nboomerang\n3\n910\n892\n12\nbuilding\n3\n911\n892\n13\nwallpaper\n3\n919\n899\n14\nweapon\n3\n858\n899\n15\nweddingdress\n3\n883\n899\na, respectively;\nEnd For\nReturn W, b and a.\nE. Complexity Analysis\nLet the iteration times of the MIRBM model learning\nalgorithm be Ts and Vdata have N vectors. Then, the time\ncomplexities of hidden layer feature sampling and recon-\nstructed visible layer distribution sampling are both O(N).\nSuppose that the auxiliary LCP guiding has K clusters and\nthe k(k = 1, 2, · · · , K) cluster has Mk instances. To obtain\nthe gradients of Eqs. (30), (31), (34) and (35), the time\ncomplexities are both O(K Mk(Mk−1)\n2\n). Other step of MIRBM\nmodel learning algorithm need O(1) time complex. Eventually,\nthe time complexity of MIRBM model learning algorithm is\nO(Ts(N + KMk(Mk −1))).\nV. EXPERIMENT RESULTS\nIn this section, we compare the proposed unsupervised fea-\nture learning architecture with the state-of-the-art GraphRBM\nusing image clustering task. The experimental data include\nﬁfteen real-valued image datasets. Three groups nine algo-\nrithms are used to prove the hidden feature learning capability\nand generalization ability of our architecture. We choose\nfour external evaluation metrics to evaluate the clustering\nperformance.\nA. Datasets\nTo compare with the state-of-the-art GraphRBM, we choose\nﬁfteen real-valued image datasets from from the Microsoft Re-\nsearch Asia Multimedia (MSRA-MM)2.0 [54]. The summary\nof the experiment datasets is shown in Table II.\nB. Experimental Settings\nTo compare our architecture with the state-of-the-art\nGraphRBM, we choose ﬁfteen real-valued image datasets\nin the experiments. In the MIRBM model of the proposed\narchitecture, the visible layer units are set to Gaussian linear\nvisible units for real-valued data sets. A linear transformation\nis adopted in the process of visible layer reconstruction. To\ncompare fairness, the learning rate of our MIRBM model and\nthe GraphRBM is both set to 10−2. One of the key parameters\nη is set to 0.1, 0.2, · · · , 0.9 to analysis the sensitivity.\nWe choose three groups nine clustering algorithms to\nevaluate the hidden layer feature learning ability and gen-\neralization ability of our feature learning architecture. The\nﬁrst group is K-means [55], afﬁnity propagation (AP)\n[56] and spectral clustering (SC)[57] algorithms using the\noriginal data as their input. The second group is K-\nmeans+GraphRBM, AP+GraphRBM and SC+GraphRBM al-\ngorithms based on the GraphRBM using the hidden layer\nfeatures of the GraphRBM as their input. The last group is\nK-means+MIRBM, AP+MIRBM and SC+MIRBM algorithms\nbased on our architecture using the hidden layer features of\nthe MIRBM model as their input.\nC. Evaluation Metrics\nTo prove the hidden layer feature learning capability of\nthe proposed architecture, we choose four external evaluation\nmetrics accuracy [58], purity [59], Fowlkes and Mallows Index\n[60] and Jaccard Index[61] [62]) to evaluate the clustering\nperformance.\n1) Accuracy: Given an instance xi, let hi and gi be the\ncluster label and the true label, respectively. The clustering\naccuracy is given by:\nAC =\nP\ni=1\nδ(gi, map(hi))\nn\n,\n(43)\nwhere AC ∈[0, 1], n is the total number of instances, map(hi)\nmaps each cluster label hi to the equivalent label from the\ndata set, and δ(x, y) equals to one if x = y and equals to zero\notherwise.\n2) Purity: The purity is used to measure the extent of each\ncluster contained data points from primarily one class. It is\nan external transparent evaluation measure for cluster quality.\nThe purity is given by:\npurity =\nK\nX\ni=1\nni\nn P(Si), P(Si) = 1\nni\nmax\nj (nj\ni),\n(44)\nwhere nj\ni is the number of the i-th input class that is assigned\nto the j-th cluster and Si is a particular cluster size of ni.\n3) Fowlkes and Mallows Index: The Fowlkes and Mallows\nindex is an external evaluation method for two clusterings that\ncan be deﬁned as:\nFMI =\nr\nTP\nTP + FP ×\nTP\nTP + FN ,\n(45)\nwhere TP, FP and FN are the number of true positives,\nfalse positives and false negatives, respectively.\n4) Jaccard Index: The Jaccard Index as an external evalu-\nation method is used to gauge the diversity and similarity of\nsample sets. Given two sets A and B, each of them has n\nattributes. The total number of each combination of attributes\nis deﬁned by:\n9\n• Ma represents the total number of attributes, if A and B\nhave a value of 1.\n• Mb represents the total number of attributes, if the\nattribute of A has a value 0 and B has a value of 1.\n• Mc represents the total number of attributes, if the\nattribute of A has a value 1 and B has a value of 0.\nThe Jaccard Index, J, is given as:\nJ =\nMa\nMb + Mc + Ma\n.\n(46)\nD. Performance Comparison\nIn this subsection, we use three groups of nine clustering\nalgorithms to compare the state-of-the-art GraphRBM and our\nunsupervised feature learning architecture.\n1) Accuracy Comparison: In Table III, we list the results\nof the accuracy of three groups contrastive algorithms. The\nﬁrst group is K-means, AP and SC algorithm using original\ndata as input. The second group is K-means+GraphRBM,\nAP+GraphRBM and SC+GraphRBM algorithm using the hid-\nden layer features of the GraphRBM as input. The ﬁnal\ngroup is K-means+MIRBM, AP+MIRBM and SC+MIRBM\nalgorithm using the hidden layer features of our MIRBM\nmodel as input. From Table III, we can see that the best\nperformances distribute over the algorithms based on our ar-\nchitecture. For some datasets (e.g. blog, boomerang, wallpaper\nand weddingdress), K-means+MIRBM algorithm shows the\nbest performance. And the SC+MIRBM algorithm shows the\nbest performance in the datasets baobab and birthdaycake.\nFor other datasets, the AP+MIRBM algorithm shows the best\nperformance. For all datasets, the average accuracies of K-\nmeans, AP and SC algorithms are 0.4309, 0.4408 and 0.4194,\nrespectively. The K-means+GraphRBM, AP+GraphRBM and\nSC+GraphRBM algorithms based on the GraphRBM raise\nthe average accuracies to 0.4584, 0.4623 and 0.4472, respec-\ntively. However, the average accuracies of K-means+MIRBM,\nAP+MIRBM and SC+MIRBM algorithms based on our ar-\nchitecture raise greatly to 0.5783, 0.6031 and 0.5273, respec-\ntively. Hence, the hidden layer features of MIRBM model as\nthe input of K-means, AP and SC algorithms can enhance\nthe average accuracies by 14.71%, 16.23% and 10.79%,\nrespectively. In terms of feature representation ability of\nour architecture and the GraphRBM, the average accura-\ncies of the K-means+MIRBM, AP+MIRBM, SC+MIRBM\nalgorithms are 11.99%, 14.08% and 8.01% higher than K-\nmeans+GraphRBM, AP+GraphRBM, SC+GraphRBM algo-\nrithms, respectively.\nFor each dataset, more intuitive performance comparisons\nare shown in Fig. 3. There are twelve datasets (alphabet,\namericanﬂag, aquarium, baobab, bathroom, beret, birthday-\ncake, blog, boat, boomerang, building and wallpaper) show\noutstanding performances about three kinds of algorithms\nbased on our architecture simultaneously.\n2) Purity Comparison: We report the results of the purity\nof K-means+GraphRBM, AP+GraphRBM, SC+GraphRBM\nalgorithms based on the GraphRBM and K-means+MIRBM,\nAP+MIRBM, SC+MIRBM algorithms based on our archi-\ntecture in Table IV. From Table IV, we can see that the\nbest performances distribute mainly over the algorithms based\non our architecture expect for the baobab and birthdaycake\ndatasets. The results of average purity of K-means, AP and\nSC algorithms using original data as input are 0.7483, 0.7509\nand 0.7465, respectively. But, the results of average purity of\nK-means+GraphRBM, AP+GraphRBM and SC+GraphRBM\nalgorithms using the hidden features of GraphRBM as input\nare raised to 0.7578, 0.7625 and 0.7568, respectively. For our\narchitecture, the results of average Jac of K-means+MIRBM,\nAP+MIRBM and SC+MIRBM algorithms using the hidden\nfeatures of it as input are signiﬁcantly raised to 0.7590, 0.7653\nand 0.7607, respectively. As a whole, the proposed architecture\nhas better feature learning ability than the GraphRBM.\nAmong three groups contrastive algorithms, the intuitive\ncomparisons of the average purity results are shown in Fig. 4.\nAll the algorithms based on our MIRBM model show better\nperformances.\n3) FMI Comparison: The FMI results of all contrastive\nalgorithms are listed in Table V. From Table V, the results of\naverage FMI of K-means, AP and SC algorithms using original\ndata as input are 0.4382, 0.4359 and 0.4238, respectively. They\nare raised to 0.4619, 0.4653 and 0.4529, respectively, by the\nGraphRBM using hidden layer features of it as input. How-\never, our architecture further improves the results of average\nFMI to 0.5977, 0.6322 and 0.5482, respectively. Clearly, the\nGraphRBM and our architecture both have powerful feature\nlearning capabilities. But, our architecture model shows more\npowerful hidden layer feature extraction capabilities than the\nGraphRBM. From Table V, the best performances of all\ndatasets are distributed over the algorithms based on the\nproposed architecture, especially with regard to AP+MIRBM\nalgorithm.\nThe intuitive comparisons of the average FMI results among\nthree groups contrastive algorithms are shown in Fig. 4. The\nK-means+MIRBM, AP+MIRBM and SC+MIRBM algorithms\nbased on the proposed architecture show absolute advantages.\n4) Jac Comparison:\nIn Table VI, we report the re-\nsults of the Jac of K-means+GraphRBM, AP+GraphRBM,\nSC+GraphRBM algorithms based on the GraphRBM and K-\nmeans+MIRBM, AP+MIRBM, SC+MIRBM algorithms based\non the proposed architecture. Meanwhile, we report the results\nof the Jac of original K-means, AP and SC algorithms. From\nTable VI, we can see that the best performances of all datasets\ndistribute over the algorithms based on our architecture. In\nfact, they distribute mainly over the algorithms AP+MIRBM.\nFor all datasets, the results of average Jac of K-means, AP and\nSC algorithms using original data as input are 0.2748, 0.2749\nand 0.2618, respectively. But, the results of average Jac of\nK-means+GraphRBM, AP+GraphRBM and SC+GraphRBM\nalgorithms using the hidden features of GraphRBM as input\nare raised to 0.2989, 0.3018 and 0.2905, respectively. Hence,\nthe GraphRBM has certain capability of feature representation.\nFor the proposed architecture, the results of average Jac of\nK-means+MIRBM, AP+MIRBM and SC+MIRBM algorithms\nusing the hidden features of it as input are signiﬁcantly raised\nto 0.4098, 0.4463 and 0.3702, respectively. Therefore, the\nproposed architecture shows excellent performance for Jac\nevaluation metric.\n10\nTABLE III\nTHE PERFORMANCES OF THE ACCURACIES AND VARIANCE (η = 0.1).\nDataset (No.)\nK-means\nAP\nSC\nK-means+GraphRBM\nAP+GraphRBM\nSC+GraphRBM\nK-means+MIRBM\nAP+MIRBM\nSC+MIRBM\nalphabet\n0.4066±0.0002\n0.4042±0.0005\n0.4386±0.0001\n0.3808±0.0003\n0.3796±0.0001\n0.3980±0.0002\n0.4530±0.0003\n0.4607±0.0002\n0.4447±0.0001\namericanﬂag\n0.4513±0.0003\n0.4376±0.0001\n0.4204±0.0002\n0.4284±0.0001\n0.4318±0.0002\n0.4124±0.0003\n0.5470±0.0004\n0.5670±0.0001\n0.5384±0.0005\naquarium\n0.3720±0.0001\n0.3709±0.0002\n0.3970±0.0002\n0.5293±0.0001\n0.5315±0.0003\n0.5119±0.0001\n0.6817±0.0001\n0.7017±0.0003\n0.6941±0.0002\nbaobab\n0.4989±0.0002\n0.5511±0.0004\n0.4822±0.0001\n0.4722±0.0006\n0.4778±0.0003\n0.4456±0.0002\n0.5900±0.0004\n0.5478±0.0002\n0.6078±0.0005\nbathroom\n0.3723±0.0003\n0.4221±0.0001\n0.3820±0.0004\n0.4383±0.0002\n0.4372±0.0002\n0.4058±0.0003\n0.7787±0.0004\n0.7987±0.0001\n0.4286±0.0002\nberet\n0.4635±0.0001\n0.3995±0.0004\n0.4110±0.0003\n0.4532±0.0002\n0.4543±0.0003\n0.4338±0.0003\n0.5097±0.0005\n0.5559±0.0003\n0.4532±0.0002\nbirthdaycake\n0.4957±0.0003\n0.4753±0.0001\n0.4818±0.0001\n0.5697±0.0004\n0.5504±0.0003\n0.5322±0.0001\n0.6506±0.0002\n0.6620±0.0002\n0.6620±0.0004\nblog\n0.3998±0.0001\n0.3860±0.0003\n0.3796±0.0003\n0.4973±0.0002\n0.4719±0.0001\n0.4677±0.0003\n0.7149±0.0004\n0.6257±0.0002\n0.5440±0.0005\nblood\n0.4885±0.0001\n0.5589±0.0003\n0.3868±0.0004\n0.6085±0.0002\n0.6282±0.0002\n0.5878±0.0004\n0.4708±0.0003\n0.8072±0.0005\n0.4908±0.0001\nboat\n0.3991±0.0002\n0.4236±0.0002\n0.4014±0.0001\n0.3711±0.0003\n0.4072±0.0001\n0.3967±0.0002\n0.6124±0.0004\n0.6289±0.0003\n0.6056±0.0003\nboomerang\n0.3890±0.0003\n0.4923±0.0002\n0.4473±0.0004\n0.3989±0.0005\n0.4143±0.0003\n0.3945±0.0002\n0.5262±0.0004\n0.5253±0.0003\n0.4681±0.0003\nbuilding\n0.5148±0.0002\n0.4874±0.0001\n0.4742±0.0003\n0.4632±0.0002\n0.4841±0.0002\n0.4479±0.0001\n0.6781±0.0003\n0.7146±0.0001\n0.6981±0.0004\nwallpaper\n0.4255±0.0003\n0.4342±0.0002\n0.3874±0.0001\n0.4363±0.0002\n0.4407±0.0002\n0.4385±0.0001\n0.5426±0.0003\n0.5256±0.0003\n0.4755±0.0002\nweapon\n0.4196±0.0003\n0.3753±0.0002\n0.4254±0.0002\n0.4033±0.0004\n0.4079±0.0006\n0.3939±0.0002\n0.4660±0.0005\n0.4860±0.0006\n0.3951±0.0004\nweddingdress\n0.3669±0.0002\n0.3930±0.0002\n0.3760±0.0001\n0.4258±0.0004\n0.4179±0.0003\n0.4417±0.0002\n0.4534±0.0002\n0.4394±0.0004\n0.4032±0.0001\nAverage\n0.4309\n0.4408\n0.4194\n0.4584\n0.4623\n0.4472\n0.5783\n0.6031\n0.5273\nTABLE IV\nTHE PERFORMANCES OF THE PURITY (η = 0.1).\nDataset (No.)\nK-means\nAP\nSC\nK-means+GraphRBM\nAP+GraphRBM\nSC+GraphRBM\nK-means+MIRBM\nAP+MIRBM\nSC+MIRBM\nalphabet\n0.8395\n0.8453\n0.8447\n0.8425\n0.8474\n0.8442\n0.8748\n0.8605\n0.8439\namericanﬂag\n0.8375\n0.8212\n0.8320\n0.8717\n0.8738\n0.8705\n0.8877\n0.8947\n0.8829\naquarium\n0.6961\n0.6983\n0.6952\n0.7074\n0.7125\n0.7050\n0.7148\n0.7218\n0.7193\nbaobab\n0.7676\n0.7528\n0.7659\n0.7955\n0.8003\n0.7955\n0.7842\n0.7644\n0.7909\nbathroom\n0.5782\n0.5804\n0.5775\n0.5586\n0.5643\n0.5595\n0.5747\n0.5817\n0.5801\nberet\n0.6942\n0.7095\n0.7032\n0.7132\n0.7182\n0.7111\n0.7135\n0.7212\n0.7232\nbirthdaycake\n0.7342\n0.7694\n0.7420\n0.7931\n0.7977\n0.7901\n0.7093\n0.7314\n0.7546\nblog\n0.6723\n0.6684\n0.6749\n0.6697\n0.6740\n0.6704\n0.6754\n0.6789\n0.6811\nblood\n0.4615\n0.4608\n0.4606\n0.4611\n0.4662\n0.4604\n0.4426\n0.4682\n0.4496\nboat\n0.8102\n0.8260\n0.8018\n0.8109\n0.8212\n0.8109\n0.8231\n0.8299\n0.8296\nboomerang\n0.9027\n0.8760\n0.8825\n0.9038\n0.9056\n0.8989\n0.8954\n0.9041\n0.8911\nbuilding\n0.6317\n0.6637\n0.6452\n0.6872\n0.6924\n0.6871\n0.6956\n0.7024\n0.7020\nwallpaper\n0.7797\n0.7829\n0.7770\n0.7752\n0.7800\n0.7755\n0.7811\n0.7873\n0.7836\nweapon\n0.9428\n0.9364\n0.9165\n0.9415\n0.9465\n0.9397\n0.9478\n0.9548\n0.9345\nweddingdress\n0.8921\n0.8845\n0.8868\n0.8738\n0.8760\n0.8715\n0.8848\n0.8935\n0.8889\nAverage\n0.7483\n0.7509\n0.7465\n0.7578\n0.7625\n0.7568\n0.7590\n0.7653\n0.7607\nTABLE V\nTHE PERFORMANCES OF THE FMI (η = 0.1).\nDataset (No.)\nK-means\nAP\nSC\nK-means+GraphRBM\nAP+GraphRBM\nSC+GraphRBM\nK-means+MIRBM\nAP+MIRBM\nSC+MIRBM\nalphabet\n0.3791\n0.3808\n0.3817\n0.3746\n0.3753\n0.3738\n0.5769\n0.5855\n0.4463\namericanﬂag\n0.4164\n0.4101\n0.4046\n0.4306\n0.4431\n0.4181\n0.5843\n0.6443\n0.6101\naquarium\n0.4412\n0.4323\n0.4323\n0.5133\n0.5147\n0.4920\n0.6770\n0.7370\n0.7282\nbaobab\n0.4659\n0.4931\n0.4580\n0.4844\n0.4890\n0.4638\n0.5451\n0.5055\n0.6030\nbathroom\n0.4729\n0.4849\n0.4726\n0.4922\n0.4910\n0.4904\n0.7514\n0.8114\n0.4996\nberet\n0.4746\n0.4337\n0.4353\n0.4631\n0.4643\n0.4575\n0.4747\n0.5654\n0.4783\nbirthdaycake\n0.4612\n0.4288\n0.4513\n0.5434\n0.5183\n0.5137\n0.6069\n0.6618\n0.6594\nblog\n0.4502\n0.4477\n0.4453\n0.5031\n0.4842\n0.4839\n0.7003\n0.6256\n0.5472\nblood\n0.5290\n0.5769\n0.4923\n0.6117\n0.6282\n0.5946\n0.5258\n0.8166\n0.5858\nboat\n0.4212\n0.4212\n0.4181\n0.4053\n0.4204\n0.4104\n0.6234\n0.6772\n0.6398\nboomerang\n0.3719\n0.4143\n0.3884\n0.3926\n0.4026\n0.3911\n0.5089\n0.5270\n0.4307\nbuilding\n0.4876\n0.5060\n0.4669\n0.4711\n0.4861\n0.4696\n0.6657\n0.7456\n0.7255\nwallpaper\n0.4153\n0.4154\n0.4044\n0.4737\n0.4845\n0.4671\n0.6182\n0.5430\n0.4921\nweapon\n0.4366\n0.3665\n0.3695\n0.3863\n0.4058\n0.3818\n0.5463\n0.6063\n0.4728\nweddingdress\n0.3702\n0.3732\n0.3721\n0.3914\n0.3802\n0.3890\n0.4555\n0.5026\n0.4036\nAverage\n0.4382\n0.4359\n0.4238\n0.4619\n0.4653\n0.4529\n0.5977\n0.6322\n0.5482\nThe intuitive comparisons of the average Jac results among\nthree groups contrastive algorithms are shown in Fig. 4. All the\nalgorithms based on the proposed architecture show absolute\nadvantages.\nE. Generalization Ability\nFrom Tables III, IV, V and VI, the K-means+MIRBM,\nAP+MIRBM and SC+MIRBM algorithms based on the pro-\nposed architecture show the best performance in their own\ngroups with four evaluation metrics. With regard to the accu-\nracy, FMI and Jac evaluation metrics, the K-means+MIRBM,\nAP+MIRBM and SC+MIRBM algorithms show the best per-\nformance than other groups algorithms. These mean that the\nhidden layer features of the proposed architecture are available\nfor three different clustering algorithms. Hence, our architec-\nture shows excellent generalization ability for unsupervised\nfeature learning.\nF. Sensitivity Analysis of the Key Parameter η\nThe parameter η is an important scale coefﬁcient in the\nproposed architecture. It has a direct impact on the role of\nauxiliary guidance LCP. Hence, we need analysis its sen-\nsitivity. The results of K-means+MIRBM, AP+MIRBM and\nSC+MIRBM algorithms based on our architecture are shown\n11\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: alphabet\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: americanflag\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: aquarium\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: baobab\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: bathroom\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: beret\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: birthdaycake\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: blog\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: blood\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: boat\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: boomerang\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: building\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: wallpaper\n0\n0.1\n0.2\n0.3\n0.4\n0.5\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: weapon\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAccuracy\nDataset: weddingdress\nFig. 3.\nAccuracy comparison between the proposed algorithms (K-means+MIRBM, AP+MIRBM and SC+MIRBM) and contrastive algorithms (η = 0.1).\n12\nTABLE VI\nTHE PERFORMANCES OF THE JAC (η = 0.1).\nDataset (No.)\nK-means\nAP\nSC\nK-means+GraphRBM\nAP+GraphRBM\nSC+GraphRBM\nK-means+MIRBM\nAP+MIRBM\nSC+MIRBM\nalphabet\n0.2330\n0.2341\n0.2345\n0.2297\n0.2302\n0.2287\n0.3557\n0.3852\n0.2871\namericanﬂag\n0.2612\n0.2578\n0.2521\n0.2739\n0.2833\n0.2643\n0.3652\n0.4152\n0.3923\naquarium\n0.2767\n0.2687\n0.2665\n0.3437\n0.3451\n0.3234\n0.4932\n0.5432\n0.5350\nbaobab\n0.3008\n0.3252\n0.2932\n0.3195\n0.3235\n0.3018\n0.3752\n0.3363\n0.4240\nbathroom\n0.2885\n0.3024\n0.2878\n0.3051\n0.3041\n0.3036\n0.6083\n0.6583\n0.3181\nberet\n0.3031\n0.2695\n0.2686\n0.2968\n0.2979\n0.2908\n0.3148\n0.3926\n0.3119\nbirthdaycake\n0.2957\n0.2691\n0.2873\n0.3713\n0.3496\n0.3454\n0.4332\n0.4760\n0.4660\nblog\n0.2773\n0.2767\n0.2732\n0.3299\n0.3111\n0.3114\n0.5280\n0.4522\n0.3761\nblood\n0.3403\n0.3940\n0.2997\n0.4319\n0.4516\n0.4118\n0.3544\n0.6787\n0.4044\nboat\n0.2627\n0.2650\n0.2598\n0.2511\n0.2645\n0.2552\n0.4171\n0.4631\n0.4393\nboomerang\n0.2276\n0.2607\n0.2399\n0.2442\n0.2520\n0.2431\n0.3227\n0.3460\n0.2744\nbuilding\n0.3126\n0.3303\n0.2924\n0.3019\n0.3168\n0.3007\n0.4891\n0.5567\n0.5390\nwallpaper\n0.2595\n0.2599\n0.2504\n0.3101\n0.3190\n0.3046\n0.4100\n0.3661\n0.3251\nweapon\n0.2747\n0.2243\n0.2263\n0.2391\n0.2532\n0.2358\n0.3176\n0.3676\n0.2955\nweddingdress\n0.2263\n0.2285\n0.2276\n0.2430\n0.2338\n0.2410\n0.2838\n0.3228\n0.2528\nAverage\n0.2748\n0.2749\n0.2618\n0.2989\n0.3018\n0.2905\n0.4098\n0.4463\n0.3702\n0.6\n0.62\n0.64\n0.66\n0.68\n0.7\n0.72\n0.74\n0.76\n0.78\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAverage Purity of all datasets\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAverage FMI of all datasets\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\nK−means\nKmeans+GraphRBM\nK−means+MIRBM\nAP\nAP+GraphRBM\nAP+MIRBM\nSC\nSC+GraphRBM\nSC+MIRBM\nAverage Jac of all datasets\nFig. 4.\nThe performances of average purity and FMI and Jac (η = 0.1).\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nK−means+MIRBM Clustering Algorithm\nη\n \n \nAccuracy\nFowlkes and Mallows Index\nPurity\nJaccard Index\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nAP+MIRBM Clustering Algorithm\nη\n \n \nAccuracy\nFowlkes and Mallows Index\nPurity\nJaccard Index\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nSC+MIRBM Clustering Algorithm\nη\n \n \nAccuracy\nFowlkes and Mallows Index\nPurity\nJaccard Index\nFig. 5.\nSensitivity analysis of the key parameters η for the K-means+MIRBM, AP+MIRBM and SC+MIRBM algorithms based on the proposed architecture.\nin Fig. 5. The accuracy, purity, FMI and Jac evaluation metrics\nshow the best performance when the parameter η is set to\n0.1. The performance of accuracy decrease rapidly with the\nincrease of parameter η from 0.1 to 0.9. The performance of\nFMI and Jac decrease rapidly with the increase of parameter\nη except for K-means+MIRBM algorithm. But, the purity is\ninsensitive to other evaluating metrics with the increase of\nparameter η.\nVI. CONCLUSIONS\nWe presented a novel unsupervised feature learning archi-\ntecture for image clustering. The main motivation behind the\nproposed architecture was the need to guide feature distri-\nbution for clustering by unsupervised LCP in the training\nprocess. We compared the proposed architecture with state-\nof-the-art GraphRBM to reveal the feature representation\ncapability. In our experimental datasets, the proposed archi-\ntecture showed better performance than the GraphRBM. For\nan important scale coefﬁcient η, we studied its sensitivity.\nWhen the parameter η = 0.1, the accuracy, purity, FMI\nand Jac evaluation metrics showed the best performance.\nThe performance of accuracy decreased rapidly with the\nincrease of parameter η. The performance of FMI and Jac\ndecreased rapidly with the increase of parameter η except for\nK-means+MIRBM algorithm. But, the purity was insensitive\nto other evaluating metrics with the increase of parameter\nη for K-means+MIRBM, AP+MIRBM and SC+MIRBM al-\ngorithms. Furthermore, we demonstrated that the proposed\n13\narchitecture has excellent generalization ability for different\nclustering algorithms.\nFor future work, we would like to exploit more efﬁ-\ncient unsupervised feature learning architecture for large-scale\ndatasets. Deep architecture is also an interesting work in the\nfuture.\nVII. ACKNOWLEDGEMENT\nThis work were partially supported by the National Sci-\nence Foundation of China (Nos. 61773324, 61573292 and\n61976247).\nREFERENCES\n[1] B. Yuan, J. Tu, R. W. Zhao, Y. Zheng, and Y. G. Jiang, “Learning part-\nbased mid-level representation for visual recognition,” Neurocomputing,\n2017.\n[2] J. Gao, J. Yang, G. Wang, and M. Li, “A novel feature extraction\nmethod for scene recognition based on centered convolutional restricted\nboltzmann machines,” Neurocomputing, vol. 11, no. 2, pp. p14–19, 2016.\n[3] W. Diao, X. Sun, F. Dou, M. Yan, H. Wang, and K. Fu, “Object\nrecognition in remote sensing images using sparse deep belief networks,”\nRemote Sensing Letters, vol. 6, no. 10, pp. 745–754, 2015.\n[4] S. Choo and H. Lee, “Learning framework of multimodal gaussian–\nbernoulli rbm handling real-value input data,” Neurocomputing, vol. 275,\npp. 1813–1822, 2018.\n[5] K. Li, C. Zou, S. Bu, Y. Liang, J. Zhang, and M. Gong, “Multi-modal\nfeature fusion for geographic image annotation,” Pattern Recognition,\nvol. 73, 2017.\n[6] O. Ghahabi and J. Hernando, “Restricted boltzmann machines for vector\nrepresentation of speech in speaker recognition,” Computer Speech and\nLanguage, vol. 47, pp. 16–29, 2018.\n[7] C. L. P. Chen and S. Feng, “Generative and discriminative fuzzy\nrestricted boltzmann machine learning for text and image classiﬁcation,”\nIEEE Transactions on Cybernetics, pp. 1–12, 2018.\n[8] Y. Lecun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521,\nno. 7553, p. 436, 2015.\n[9] D. Chen, J. Lv, and Z. Yi, “Graph regularized restricted boltzmann ma-\nchine.” IEEE Transactions on Neural Networks and Learning Systems,\nvol. PP, no. 99, pp. 1–9, 2017.\n[10] J. Tang and H. Liu, “An unsupervised feature selection framework\nfor social media data,” IEEE Transactions on Knowledge and Data\nEngineering, vol. 26, no. 12, pp. 2914–2927, Dec 2014.\n[11] M. Chen, I. W. Tsang, M. Tan, and T. J. Cham, “A uniﬁed feature\nselection framework for graph embedding on high dimensional data,”\nIEEE Transactions on Knowledge and Data Engineering, vol. 27, no. 6,\npp. 1465–1477, June 2015.\n[12] D. Wang, F. Nie, and H. Huang, “Feature selection via global redundancy\nminimization,” IEEE Transactions on Knowledge and Data Engineering,\nvol. 27, no. 10, pp. 2743–2755, Oct 2015.\n[13] M. Banerjee and N. R. Pal, “Unsupervised feature selection with\ncontrolled redundancy (ufescor),” IEEE Transactions on Knowledge and\nData Engineering, vol. 27, no. 12, pp. 3390–3403, Dec 2015.\n[14] X. Zhu, S. Zhang, R. Hu, Y. Zhu, and j. song, “Local and global structure\npreservation for robust unsupervised spectral feature selection,” IEEE\nTransactions on Knowledge and Data Engineering, vol. 30, no. 3, pp.\n517–529, March 2018.\n[15] G. Hinton and T. Sejnowski, “Learning and releaming in boltzmann\nmachines,” Parallel distributed processing: Explorations in the mi-\ncrostructure of cognition, vol. 1, pp. 282–317, 1986.\n[16] T. Tieleman, “Training restricted boltzmann machines using approxima-\ntions to the likelihood gradient,” in International Conference on Machine\nLearning, 2008, pp. 1064–1071.\n[17] G. E. Hinton, “Training products of experts by minimizing contrastive\ndivergence,” Neural Computation, vol. 14, no. 8, pp. 1771–1800, 2002.\n[18] N. Lu, T. Li, X. Ren, and H. Miao, “A deep learning scheme for motor\nimagery classiﬁcation based on restricted boltzmann machines,” IEEE\nTransactions on Neural Systems and Rehabilitation Engineering, vol. PP,\nno. 99, pp. 1–1, 2016.\n[19] O. Fink, E. Zio, and U. Weidmann, “Fuzzy classiﬁcation with restricted\nboltzman machines and echo-state networks for predicting potential\nrailway door system failures,” IEEE Transactions on Reliability, vol. 64,\nno. 3, pp. 861–868, 2015.\n[20] Y. Chen, X. Zhao, and X. Jia, “Spectral–spatial classiﬁcation of hyper-\nspectral data based on deep belief network,” IEEE Journal of Selected\nTopics in Applied Earth Observations and Remote Sensing, vol. 8, no. 6,\npp. 2381–2392, 2015.\n[21] S. Nie, Z. Wang, and Q. Ji, “A generative restricted boltzmann machine\nbased method for high-dimensional motion data modeling,” Computer\nVision and Image Understanding, vol. 136(C), pp. 14–22, 2015.\n[22] A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition with\ndeep recurrent neural networks,” in 2013 IEEE International Conference\non Acoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2013,\npp. 6645–6649.\n[23] J. Chu, H. Wang, H. Meng, P. Jin, and T. Li, “Restricted boltzmann\nmachines with gaussian visible units guided by pairwise constraints,”\nIEEE Transactions on Cybernetics, pp. 1–14, 2018.\n[24] Q. Yu, Y. Hou, X. Zhao, and G. Cheng, “R´enyi divergence based gen-\neralization for learning of classiﬁcation restricted boltzmann machines,”\nin 2014 IEEE International Conference on Data Mining Workshop\n(ICDMW).\nIEEE, 2014, pp. 692–697.\n[25] C. Chen, C. Y. Zhang, L. Chen, and M. Gan, “Fuzzy restricted boltzmann\nmachine for the enhancement of deep learning,” IEEE Transactions on\nFuzzy Systems, vol. 23, no. 6, pp. 2163–2173, 2015.\n[26] A. Courville, G. Desjardins, J. Bergstra, and Y. Bengio, “The spike-and-\nslab rbm and extensions to discrete and sparse data distributions,” IEEE\nTransactions on Pattern Analysis and Machine Intelligence, vol. 36,\nno. 9, pp. 1874–1887, 2014.\n[27] R. Karakida, M. Okada, and S.-i. Amari, “Dynamical analysis of\ncontrastive divergence learning: Restricted boltzmann machines with\ngaussian visible units,” Neural Networks, vol. 79, pp. 78–87, 2016.\n[28] M. R. Amer, T. Shields, B. Siddiquie, A. Tamrakar, A. Divakaran, and\nS. Chai, “Deep multimodal fusion: A hybrid approach,” International\nJournal of Computer Vision, pp. 1–17, 2017.\n[29] H. Luo, P. Jia, S. Qiao, and S. Duan, “Enhancing electronic nose per-\nformance based on a novel qpso-rbm technique,” Sensors and Actuators\nB: Chemical, vol. 259, pp. 241–249, 2018.\n[30] A. A. Alani, “Arabic handwritten digit recognition based on restricted\nboltzmann machine and convolutional neural networks,” Information,\nvol. 8, no. 4, p. 142, 2017.\n[31] S. Bu, L. Wang, P. Han, Z. Liu, and K. Li, “3d shape recognition and\nretrieval based on multi-modality deep learning,” Neurocomputing, vol.\n259, pp. 183–193, 2017.\n[32] G. Cheng, P. Zhou, and J. Han, “Duplex metric learning for image set\nclassiﬁcation.” IEEE Transactions on Image Processing, vol. 27, no. 1,\npp. 281–292, 2017.\n[33] G. Chen, “Deep transductive semi-supervised maximum margin cluster-\ning,” arXiv preprint arXiv:1501.06237, 2015.\n[34] R. Chen, S. Chen, M. He, D. He, and B. Tang, “Rolling bearing fault\nseverity identiﬁcation using deep sparse auto-encoder network with noise\nadded sample expansion,” Proceedings of the Institution of Mechanical\nEngineers, Part O: Journal of Risk and Reliability, vol. 231, no. 6, pp.\n666–679, 2017.\n[35] K. T. Yesilbek and T. M. Sezgin, “Sketch recognition with few exam-\nples,” Computers and Graphics, vol. 69, pp. 80–91, 2017.\n[36] C. T. Sari and C. Gunduz-Demir, “Unsupervised feature extraction via\ndeep learning for histopathological classiﬁcation of colon tissue images,”\nIEEE Transactions on Medical Imaging, pp. 1–1, 2018.\n[37] M. A. Keyvanrad and M. M. Homayounpour, “Effective sparsity control\nin deep belief networks using normal regularization term,” Knowledge\nand Information Systems, vol. 53, no. 2, pp. 533–550, 2017.\n[38] X. Tang, N. Zhang, J. Zhou, and Q. Liu, “Hidden-layer visible deep\nstacking network optimized by pso for motor imagery eeg recognition,”\nNeurocomputing, vol. 234, no. C, pp. 1–10, 2016.\n[39] P. Chopra and S. K. Yadav, “Restricted boltzmann machine and softmax\nregression for fault detection and classiﬁcation,” Complex and Intelligent\nSystems, vol. 4, no. 1, pp. 67–77, 2018.\n[40] X. Zhang, Y. Liang, C. Li, H. Ning, L. Jiao, and H. Zhou, “Recur-\nsive autoencoders-based unsupervised feature learning for hyperspectral\nimage classiﬁcation,” IEEE Geoscience and Remote Sensing Letters,\nvol. 14, no. 11, pp. 1928–1932, 2017.\n[41] C. Xie, J. Lv, and X. Li, “Finding a good initial conﬁguration of param-\neters for restricted boltzmann machine pre-training,” Soft Computing,\npp. 1–9, 2016.\n[42] H. Al-Dmour and A. Al-Ani, “A clustering fusion technique for mr brain\ntissue segmentation,” Neurocomputing, vol. 275, pp. 546–559, 2018.\n[43] R. Stewart and S. Ermon, “Label-free supervision of neural networks\nwith physics and domain knowledge,” in AAAI, 2017, pp. 2576–2582.\n14\n[44] S. M. Azimi, D. Britz, M. Engstler, M. Fritz, and F. Mcklich, “Advanced\nsteel microstructural classiﬁcation by deep learning methods,” Scientiﬁc\nReports, vol. 8, no. 1, 2017.\n[45] M. Seera, C. P. Lim, K. S. Tan, and S. L. Wei, “Classiﬁcation of\ntranscranial doppler signals using individual and ensemble recurrent\nneural networks,” Neurocomputing, vol. 249, no. C, pp. 337–344, 2017.\n[46] K. Verma and R. K. Sharma, “Comparison of hmm- and svm-based\nstroke classiﬁers for gurmukhi script,” Neural Computing and Applica-\ntions, pp. 1–13, 2016.\n[47] K. A. Abdalmalak and A. Gallardo-Antolłn, “Enhancement of a text-\nindependent speaker veriﬁcation system by using feature combination\nand parallel structure classiﬁers,” Neural Computing and Applications,\npp. 1–15, 2016.\n[48] H. Guan, T. Liu, J. Jiang, D. Tao, J. Zhang, H. Niu, W. Zhu,\nY. Wang, J. Cheng, and N. A. Kochan, “Classifying mci subtypes in\ncommunity-dwelling elderly using cross-sectional and longitudinal mri-\nbased biomarkers:,” Frontiers in Aging Neuroscience, vol. 9, pp. 309–\n322, 2017.\n[49] M. Tahir, B. Jan, M. Hayat, S. U. Shah, and M. Amin, “Efﬁcient com-\nputational model for classiﬁcation of protein localization images using\nextended threshold adjacency statistics and support vector machines,”\nComputer Methods and Programs in Biomedicine, vol. 157, 2018.\n[50] M. P. Hosseini, D. Pompili, K. Elisevich, and H. Soltanian-Zadeh,\n“Random ensemble learning for eeg classiﬁcation,” Artiﬁcial Intelligence\nin Medicine, 2018.\n[51] R. He, T. Tan, L. Davis, and Z. Sun, “Learning structured ordinal\nmeasures for video based face recognition,” Pattern Recognition, vol. 75,\npp. 4–14, mar 2018.\n[52] M. Yang, R. Shang, L. Jiao, W. Zhang, Y. Yuan, and S. Yang, “Feature\nselection based dual-graph sparse non-negative matrix factorization for\nlocal discriminative clustering,” Neurocomputing.\n[53] R. Shang, W. Wang, R. Stolkin, and L. Jiao, “Non-negative spectral\nlearning and sparse regression-based dual-graph regularized feature\nselection,” IEEE Transactions on Cybernetics, vol. 48, no. 2, pp. 793–\n806, Feb 2018.\n[54] H. Li, M. Wang, and X.-S. Hua, “Msra-mm 2.0: A large-scale web\nmultimedia dataset,” in IEEE International Conference on Data Mining\nWorkshops.\nIEEE, 2009, pp. 164–169.\n[55] S. Lloyd, “Least squares quantization in pcm,” IEEE Transactions on\nInformation Theory, vol. 28, no. 2, pp. 129–137, 1982.\n[56] B. J. Frey and D. Dueck, “Clustering by passing messages between data\npoints,” Science, vol. 315, no. 5814, pp. 972–976, 2007.\n[57] A. Y. Ng, M. I. Jordan, Y. Weiss et al., “On spectral clustering: Analysis\nand an algorithm,” Advances in Neural Information Processing Systems,\nvol. 2, pp. 849–856, 2002.\n[58] D. Cai, X. He, and J. Han, “Document clustering using locality preserv-\ning indexing,” IEEE Transactions on Knowledge and Data Engineering,\nvol. 17, no. 12, pp. 1624–1637, 2005.\n[59] C. Ding, T. Li, W. Peng, and H. Park, “Orthogonal nonnegative matrix\nt-factorizations for clustering,” in the 12th ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining.\nACM, 2006,\npp. 126–135.\n[60] R. Liu, H. Wang, and X. Yu, “Shared-nearest-neighbor-based clustering\nby fast search and ﬁnd of density peaks,” Information Sciences, vol. 450,\npp. 200 – 226, 2018.\n[61] R. Real and J. M. Vargas, “The probabilistic basis of jaccard’s index of\nsimilarity,” Systematic Biology, vol. 45, no. 3, pp. 380–385, 1996.\n[62] C.-M. Hwang, M.-S. Yang, and W.-L. Hung, “New similarity measures\nof intuitionistic fuzzy sets based on the jaccard index with its application\nto clustering,” International Journal of Intelligent Systems, vol. 33, no. 8,\npp. 1672–1688, 2018.\nJielei Chu received the B.S. degree from Southwest\nJiaotong University, Chengdu, China in 2008, and is\ncurrently working toward the Ph.D. degree at South-\nwest Jiaotong University. His research interests are\ndeep learning, data mining, semi-supervised learning\nand ensemble learning.\nHongjun Wang received his Ph.D. degree in com-\nputer science from Sichuan University of China\nin 2009. He is currently Associate Professor of\nthe Key Lab of Cloud Computing and Intelligent\nTechniques in Southwest Jiaotong University. His\nresearch interests are machine learning, data min-\ning and ensemble learning. He published over 30\nresearch papers in journals and conferences and he\nis a member of ACM and CCF. He has a reviewer\nfor several academic journals.\nJing Liu received his Ph.D. degree in management\nfrom Southwest Jiaotong University.She is currently\nan Assistant Professor of Business SchoolinSichuan\nUniversity. Her research interestsare machine learn-\ning, ﬁnancial technologyand modelling and forecast-\ning high-frequency data.\nZhiguo Gong received the Ph.D. degree in computer\nscience from the Institute of Mathematics, Chinese\nAcademy of Science, Beijing,China. He is currently\na Professor with the Faculty of Science and Tech-\nnology, University of Macau, Macau, China. His\ncurrent research interests include machine learning,\ndata mining, database, and information retrieval.\nTianrui Li (SM’11) received the B.S., M.S., and\nPh.D. degrees in trafﬁc information processing\nand control from Southwest Jiaotong University,\nChengdu, China, in 1992, 1995, and 2002, respec-\ntively. He was a Post-Doctoral Researcher with\nBelgian Nuclear Research Centre, Mol, Belgium,\nfrom 2005 to 2006, and a Visiting Professor with\nHasselt University, Hasselt, Belgium, in 2008; Uni-\nversity of Technology, Sydney, Australia, in 2009;\nand University of Regina, Regina, Canada, in 2014.\nHe is currently a Professor and the Director of the\nKey Laboratory of Cloud Computing and Intelligent Techniques, Southwest\nJiaotong University. He has authored or co-authored over 150 research papers\nin refereed journals and conferences. His research interests include big data,\ncloud computing, data mining, granular computing, and rough sets. Dr. Li is\na fellow of the International Rough Set Society.\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2018-12-05",
  "updated": "2020-04-02"
}