{
  "id": "http://arxiv.org/abs/1812.03288v1",
  "title": "No Peek: A Survey of private distributed deep learning",
  "authors": [
    "Praneeth Vepakomma",
    "Tristan Swedish",
    "Ramesh Raskar",
    "Otkrist Gupta",
    "Abhimanyu Dubey"
  ],
  "abstract": "We survey distributed deep learning models for training or inference without\naccessing raw data from clients. These methods aim to protect confidential\npatterns in data while still allowing servers to train models. The distributed\ndeep learning methods of federated learning, split learning and large batch\nstochastic gradient descent are compared in addition to private and secure\napproaches of differential privacy, homomorphic encryption, oblivious transfer\nand garbled circuits in the context of neural networks. We study their\nbenefits, limitations and trade-offs with regards to computational resources,\ndata leakage and communication efficiency and also share our anticipated future\ntrends.",
  "text": "No Peek: A Survey of private distributed deep\nlearning\nPraneeth Vepakomma⋆, Tristan Swedish, Ramesh Raskar, Otkrist Gupta, and\nAbhimanyu Dubey\nMassachusetts Institute of Technology\nCambridge, MA 02139, U.S.A\nAbstract. We survey distributed deep learning models for training or\ninference without accessing raw data from clients. These methods aim to\nprotect conﬁdential patterns in data while still allowing servers to train\nmodels. The distributed deep learning methods of federated learning,\nsplit learning and large batch stochastic gradient descent are compared\nin addition to private and secure approaches of diﬀerential privacy, homo-\nmorphic encryption, oblivious transfer and garbled circuits in the context\nof neural networks. We study their beneﬁts, limitations and trade-oﬀs\nwith regards to computational resources, data leakage and communication\neﬃciency and also share our anticipated future trends.\n1\nIntroduction\nEmerging technologies in domains such as biomedicine, health and ﬁnance beneﬁt\nfrom distributed deep learning methods which can allow multiple entities to train\na deep neural network without requiring data sharing or resource aggregation\nat one single place. In particular, we are interested in distributed deep learning\napproaches that bridge the gap between distributed data sources (clients) and a\npowerful centralized computing resource (server) under the constraint that local\ndata sources of clients are not allowed to be shared with the server or amongst\nother clients.\nWe survey and compare such distributed deep learning techniques and classify\nthem across various dimensions of level and type of protection oﬀered, model\nperformance and resources required such as memory, time, communications\nbandwidth and synchronization requirements. We introduce the terminology of\n‘no peek’ to refer to distributed deep learning techniques that do not share their\ndata in raw form. We note that such no peek techniques allow the server to train\nmodels without ’peeking at’, or directly observing, raw data belonging to clients.\nAdditionally, we survey some generic approaches to protecting data and models.\nSome of these approaches have already been used in combination with distributed\ndeep learning methods that possess varying levels of the no peek property. These\ngeneric approaches include de-identiﬁcation methods like anonymization [52],\nobfuscation methods like diﬀerential privacy [100,101,102] and cryptographic\n⋆Corresponding author e-mail: vepakom@mit.edu\narXiv:1812.03288v1  [cs.LG]  8 Dec 2018\n2\nNo Peek: A Survey of private distributed deep learning\ntechniques like homomorphic encryption [19,93,96] and secure multi-party com-\nputation (MPC) protocols like oblivious transfer [84,47] and garbled circuits\n[41].\nIn the rest of the paper, we focus on distributed deep learning techniques such\nas splitNN [31,2], large batch synchronous stochastic gradient descent (SGD)\n[20,9], federated learning[3] and other variants [107,108,109,110] in the context\nof protecting data and models.\n1.1\nNo peek rule\nWe refer to techniques of distributed deep learning that do not look at raw\ndata once it leaves the client as satisfying the property of ’no peek’. No peek is\nnecessitated by trust and regulatory issues. For example, hospitals are typically\nnot allowed to share data with for-proﬁt entities due to trust issues. They also\nare unable to share it with external entities (data cannot physically leave the\npremises) due to limited consent of the patients, and regulations such as HIPAA\n[5,1,6,7,8] that prevent sharing many aspects of the data to external entities.\nSome techniques go a step ahead by also not revealing details of the model\narchitecture as well. In these techniques, neither the server nor client can access\nthe details of the other’s architecture or weights.\n1.2\nWhat needs to be protected\nProtection mechanisms in the context of distributed deep learning should protect\nvarious aspects of datasets such as\n1. Input features\n2. Output labels or responses\n3. Model details including the architecture, parameters and loss function\n4. Identiﬁable information such as which party contributed to a speciﬁc record\n1.3\nComputational Goals\nIt is also quite important that any mechanism that aims to protect these details\nalso preserves utility of the model above an acceptable level. These goals are to\nbe ideally achieved at a low cost with regards to\n1. Memory\n2. Computational time\n3. Communications bandwidth\n4. Synchronization\nAs shown in Fig 1. below smaller hospitals or tele-healthcare screening centers\ndo not acquire an enormous number of diagnostic images and they could also\nbe limited by diagnostic manpower. A distributed machine learning method for\ndiagnosis in this setting should ideally not share any raw data (no peek) and at\nsame time achieve high accuracy while using signiﬁcantly lower resources. This\nhelps smaller hospitals to eﬀectively serve those in need while beneﬁting from\ndecentralized entities.\nNo Peek: A Survey of private distributed deep learning\n3\nDistributed\nMethod\nPartial/Full Leak-\nage\nDiﬀerential\nPrivacy\nHomomorphic\nEncryption\nOblivious Transfer,\nGarbled Circuits\nDistributed NN\n[Dean2012, Wen2017,\nDas2016, Ooi2015],\nBen2018]\n[Hynes2018,\nAbadi2016,\nShokri2015,\nPapernot2016]\n[Juvekar2018,\nGilad2016]\n[Rouhani2017,\nMohassel2017,\nRiazi2018,\nOrlandi2007]\nLarge Batch\nSynchronous SGD\n[Konečný2015,\nChen2016]\nFederated\nLearn-\ning\n[McMahan2017,\nNock2018]\n[Geyer2017]\n[Aono2018,\nHardy2017]\n[Bonawitz2016]\nSplitNN\n[Gupta2018,\nVepakomma2018]\nTable 1: This is a survey of distributed deep learning methods with decreasing\nlevels of leakage from distributed NN to splitNN. Hybrid approaches of these\ntechniques and diﬀerential privacy, homomorphic encryption and MPC are also\nincluded. The citations for these 9 groups have been grouped separately with\nsubtitles in the references section for convenience.\nFig. 1: Non-cooperating health units\nFig. 2: Distributed learning without\nraw data sharing\n2\nNo peek approaches for distributed deep learning\nIn table 1 we provide corresponding references to various combinations of dis-\ntributed deep learning techniques along with generic approaches for protection\nthat are not speciﬁc to deep learning such as diﬀerential privacy homomorphic\nencryption and secure multi-party computation. The distributed deep learning\ntechniques such as splitNN, federated learning and large batch synchronous SGD\nare ‘no peek’. In addition splitNN also protects model details of the architecture\nand weights, unlike the other techniques. We detail this below in table 2 in\nterms of the levels of protection oﬀered on data, intermediate representations and\nhyperparameters that include the deep learning architecture and learnt weights.\nIn federated learning and large batch synchronous SGD, the architecture and\nparameters are shared between the client and server along with intermediate\nrepresentations of the model that include the gradients, activations and weight\nupdates which are shared during the learning process. Although the data is\n4\nNo Peek: A Survey of private distributed deep learning\nnot explicitly shared in raw form in these two techniques, works like [106] have\nshown that raw data can be reconstructed up to an approximation by adversaries,\nespecially given the fact that the architecture and parameters are not completely\nprotected. SplitNN [31] has an added advantage in this context in that it does not\nshare the architecture and weights of the model. The protection oﬀered by splitNN\nlies in the compact representations found in deeper layers of neural networks\nand the diﬃculty of recovering the underlying data from these representations\nwithout knowing the model weights used to produce them. Such representations\nform after passing the data through numerous activations whose inverse in the\ncase of ReLU are nonlinear and ill-deﬁned (the inverse of a zero-valued ReLU\ncan map to any negative number). Such representations have been shown to\npreserve information important for certain tasks (path following [4]), without\nrevealing information about the underlying data (such as image features in a\n3D coordinate system). The intermediate representation shared by splitNN also\nrequires minimal bandwidth in comparison to federated learning and large batch\nsynchronous SGD, as only the activations from one layer of the client called the\ncut layer are shared with the server without any associated functions required to\ninvert them back to raw data. In table 3, we compare these techniques based on\nNo Peek Deep Learning Data revealed Hyperparameters\nrevealed\nIntermediate\nrepresentation\nrevealed\nLarge Batch\nSynchronous SGD\nNo\nYes\nYes\nFederated Learning\nNo\nYes\nYes\nSplitNN\nNo\nNo\nYes\nTable 2: In this table, we compare the level of privacy oﬀered over data, model\narchitecture, model parameters and intermediate representations by techniques\nlike federated learning, large batch synchronous SGD and splitNN. On all these\naspects, splitNN out performs federated learning or large batch synchronous\nSGD.\nresources required such as computations, communication bandwidth, memory\nand synchronization. We categorize the techniques across these dimensions as\nhaving low, medium and high requirements. As shown, splitNN requires the lowest\nresources on the client side. This is because the architecture is cut (arbitrary\nshape and not necessarily vertical) at a layer where the computations are only\nperformed up to that cut on the client side. The rest of the computations happen\non the server side. The experimental results in [31], quantify these comparisons.\n3\nFederated Learning\nKey idea: In this approach the clients download the current model from central\nserver and improve it by updating their model weights based on their local data.\nThe client model parameter updates are aggregated to generate server model.\nThis model is again downloaded by the clients and the process continues. There\nis no explicit sharing of raw data in this setup.\nNo Peek: A Survey of private distributed deep learning\n5\nAlgorithm 1 Naive Federated Learning. Goal: To learn W ∈Rd1×d2 from\ndata stored across a large number of clients. The K clients are indexed by k; B\nis the local minibatch size, E is the number of local epochs, and η is the learning\nrate.\nEnsure:Server executes at round t ≥0:\nDistribute Wt to a subset St of nt clients\nfor each client k ∈St in parallel do\nHk\nt ←ClientUpdate(k, wt)\nSet Ht :=\n1\nnt\nP\ni∈St Hi\nt\nSet Wt+1 = Wt + ηtHt\nEnsure:ClientUpdate(k, Wt):\n// Run on client k\nB ←(split Pk into batches of size B)\nSet Wk\nt = Wt\nfor each local epoch i from 1 to E do\nfor batch b ∈B do\nWk\nt ←Wk\nt −η▽ℓ(Wk\nt ; b)\nreturn Hk\nt = Wk\nt −Wt to server\nAlgorithm 2 (Communication-Eﬃcient Learning of Deep Networks from Decen-\ntralized Data):Federated Averaging. The K clients are indexed by k; B is the\nlocal minibatch size, E is the number of local epochs, and η is the learning rate.\nEnsure:Server executes:\ninitialize w0\nfor each round t = 1, 2, . . . do\nm ←max(C · K, 1)\nSt ←(random set of m clients)\nfor each client k ∈St in parallel do\nwk\nt+1 ←ClientUpdate(k, wt)\nwt+1 ←PK\nk=1\nnk\nn wk\nt+1\nEnsure:ClientUpdate(k, w):\n// Run on client k\nB ←(split Pk into batches of size B)\nfor each local epoch i from 1 to E do\nfor batch b ∈B do\nw ←w −η▽ℓ(w; b)\nreturn w to server\n3.1\nBeneﬁts\nThere is no explicit sharing of raw data. It has been shown in the convex case\nwith IID data that in the worst-case, the global model produced is no better\nthan training a model on a single client [9,3].\n3.2\nLimitations\nPerformance drops sharply when local data with clients is non i.i.d. That said,\nrecent work in [112] on federated learning in this setting shows positive results. It\n6\nNo Peek: A Survey of private distributed deep learning\nalso requires large network bandwidth, memory and computation requirements\non the client side depending on size of model, computation needs of complete\nforward and backward propagation. Advanced compression methods can be used\ninstead to reduce this overload. There has been active recent work for neural\nnetwork compression such as [35,36,111]. These works can thereby reduce the\ncosts for communication bandwidth when used in distributed learning. Federated\nlearning has no theoretical guarantees or trade-oﬀs of privacy or security to date.\nClient Resources\nRequired\nCompute Bandwidth Memory Synchronization\nLarge Batch\nSynchronous SGD\nHigh\nHigh\nHigh\nSynchronous updates with backup\nworkers to compensate slow machines.\nFederated Learning Medium\nMedium\nHigh\nSynchronous client-server updates.\nSplitNN\nLow\nLow\nLow\nSynchronous client-server updates.\nTable 3: In this table, we compare the resources required for computation,\nbandwidth, memory and synchronization by techniques like federated learning,\nlarge batch synchronous SGD and SplitNN. SplitNN consumes fewer resources\nthan federated learning and large batch synchronous SGD in these aspects except\nfor synchronization requirements that are similar across all three techniques.\n3.3\nFuture Trends\nData poisoning attacks on federated learning [37] where malicious users can inject\nfalse training data to negatively eﬀect the classiﬁcation performance of the model\nhave been proposed. Adversarial robustness to such attacks need to be improved.\nUsing neural-network compression schemes in conjunction with federated learning\nto reduce the communication overload is an avenue for future work. Looking at\ncombinations of federated learning and diﬀerential privacy, secure multi-party\ncomputation is an interesting direction for future work given that there has been\nactive research in the recent time in all these areas.\n4\nLarge Batch Synchronous SGD\n4.1\nKey Idea\nThe technique introduces additional backup workers to work on updating the\nweights, and chooses to synchronously update the aggregated model, as soon\nas any of the fastest N workers ﬁnish their updates. This is an improvement\nin accuracy over asynchronous SGD where some of the local workers might be\nupdating the weights of a more stale model as the client-server updates are\nasynchronous. It also is relatively faster than synchronous SGD with no back-up\nworkers where the servers wait for all the clients to ﬁnish their updates before\naggregating the model parameters to update the model.\nNo Peek: A Survey of private distributed deep learning\n7\n4.2\nBeneﬁts\nIt allows for faster synchronous SGD, and is more accurate than asynchronous\nSGD approaches where some clients end up updating the weights based on a\nmore stale model.\n4.3\nLimitations\nThe computational requirements and communication bandwidth required is much\nhigher than other distributed deep learning methods.\n4.4\nFuture Trends\nThe future trends are similar to that of federated learning as this method is very\nsimilar in essence to federated learning although it instead runs on a single batch\nof data. This method has high computational overload and network footprint.\nTo make this method more sustainable in data center or decentralized settings,\nfuture work in improving its eﬃciency is important.\nAlgorithm 3 Large-Batch SGD\nEnsure:Worker Update(k), where k = 1, . . . , N + b\nInput: Dataset X, B mini-batch size.\nfor t = 0, 1, . . . do\nWait to read θ(t) = (θ(t)[0], . . . , θ(t)[M])\nfrom parameter servers.\nG(t)\nk\n:= 0\nfor i = 1, . . . , B do\nSample datapoint exk,i from X.\nG(t)\nk\n←G(t)\nk\n+ 1\nB ∇F(exk,i; θ(t)).\nSend (G(t)\nk , t) to parameter servers.\nEnsure:Parameter Server Update(j), where k = 1, . . . , N + b\nInput γ0, γ1, . . . learning rates, α decay rate, N number of mini-batches to aggregate,\nθ(0) model initialization.\nfor t = 0, 1, . . . do\nG = {}\nwhile |G| < N do\nWait for (G, t′) from any worker.\nif t′ == t then\nG ←G ∪{G}.\nelse\nDrop gradient G.\nθ(t+1)[j] ←θ(t)[j] −γt\nN\nP\nG∈G G[j].\n¯θ(t)[j] = α¯θ(t−1)[j] + (1 −α)θ(t)[j].\n8\nNo Peek: A Survey of private distributed deep learning\n5\nSplit Learning (SplitNN)\n5.1\nKey Idea\nIn this method each client trains the network upto a certain layer known as the\ncut layer and sends the weights to server. The server then trains the network for\nrest of the layers. This completes the forward propagation. Server then generates\nthe gradients for the ﬁnal layer and back-propagates the error until the cut layer.\nThe gradient is then passed over to the client. The rest of the back-propagation\nis completed by client. This is continued till the network is trained. The shape of\nthe cut could be arbitrary and not necessarily, vertical. In this framework as well\nthere is no explicit sharing of raw data.\n5.2\nBeneﬁts\nClient-side communication costs are signiﬁcantly reduced as the data to be\ntransmitted is restricted to ﬁrst few layers of the splitNN prior to the split. The\nclient-side computation costs of learning the weights of the network are also\nsigniﬁcantly reduced for the same reason. In terms of model performance, the\naccuracies of Split NN remained much higher than federated learning and large\nbatch synchronous SGD with a drastically smaller client side computational\nburden when training on a larger number of clients.\n5.3\nLimitations\nIt requires a relatively larger overall communication bandwidth when training\nover a smaller number of clients although it ends up being much lower than\nother methods in settings with large number of clients. Advanced neural network\ncompression methods such as [35,36,111] can be used to reduce the communica-\ntion load. The communication bandwidth can also be traded for computation\non client by allowing for more layers at client to represent further compressed\nrepresentations.\n5.4\nFuture Trends\nGiven its no peek properties, no model detail sharing and high resource eﬃciency\nof this recently proposed method, it is well placed to provide direct applications to\nimportant domains like distributed healthcare, distributed clinical trials, inter and\nintra organizational collaboration and ﬁnance. Using neural-network compression\nschemes in conjunction with splitNN to reduce communication overload is a\npromising avenue for future work. Looking at combinations of federated learning\nand diﬀerential privacy, secure multi-party computation is an interesting direction\nfor future work as well given that there has been active research in recent time\nin all these areas.\nNo Peek: A Survey of private distributed deep learning\n9\nAlgorithm 4 SplitNN. The K clients are indexed by k; B is the local minibatch\nsize, and η is the learning rate.\nEnsure:Server executes at round t ≥0:\nfor each client k ∈St in parallel do\nAk\nt ←ClientUpdate(k, t)\nCompute Wt ←Wt −η▽ℓ(Wt; At)\nSend ▽ℓ(At; Wt) to client k for ClientBackprop(k, t)\nEnsure:ClientUpdate(k, t):\n// Run on client k\nAk\nt = φ\nfor each local epoch i from 1 to E do\nfor batch b ∈B do\nConcatenate f(b, Hk\nt ) to Ak\nt\nreturn Ak\nt to server\nEnsure:ClientBackprop(k, t, ▽ℓ(At; Wt)):\n// Run on client k\nfor batch b ∈B do\nHk\nt = Hk\nt −η▽ℓ(At; Wt; b)\n6\nMethods to Further Reduce Leakage and Improve\nEﬃciency\n6.1\nObfuscation with Diﬀerential Privacy for NN\nKey Idea: The methods in [14] modify stochastic gradient descent (SGD) based\noptimization used in learning neural networks by clipping the gradient for each\nlot of data and adding Gaussian noise to it during the optimization as opposed to\nadding noise to ﬁnal parameters of the model, which could be overly conservative\nthereby aﬀecting the utility of the trained model.The sigma for the noise is chosen\nat each step so as to maintain a guaranteed epsilon-delta diﬀerential privacy for\na given lot of data. The tradeoﬀbetween the conﬂicting objectives of accuracy\nand privacy is determined by the lot size.\nBeneﬁts and Limitations: The privacy is always dependent on a limited\nprivacy budget while this also has an inversely proportional dependency with\nmodel accuracy. This is unlike in SplitNN where high accuracies are achieved\nwithout sharing raw data. The guarantees of diﬀerential privacy are currently\ntheoretically backed unlike in SplitNN or Federated Learning. It also violates the\nno-peak rule when the privacy budget is over.\nFuture Trends: There is a lot of scope in combining diﬀerential privacy with\ndistributed deep learning methods like splitNN, federated learning and large\nbatch SGD as it adds to stronger theoretical guarantees on preventing data\nleakage.\n10\nNo Peek: A Survey of private distributed deep learning\n6.2\nHomomorphic Encryption for NN\nKey Idea Homomorphic encryption aims to preserve the structure of ciphers\nsuch that addition and multiplicative operations can be performed after the\nencryption. All operations in a neural network except for activation functions\nare sum and product operations which can be encoded using Homomorphic\nencryption. Activation functions are approximated with either higher degree\npolynomials, Taylor series, standard or modiﬁed Chebyshev polynomials that are\nthen implemented as part of Homomorphic encryption schemes. The works in\n[17,19] apply these ideas in the context of deep learning. A greatly detailed survey\ncomparing various software libraries for homomorphic encryption is provided in\n[115].\nAlgorithm 5 Diﬀerentially private SGD\nRequire: Examples {x1, ..., xN}, loss function L(θ) =\n1\nN\nP\ni L(θ, xi). Parameters:\nlearning rate ηt, noise scale σ, group size L, gradient norm bound C.\nInitialize θ0 randomly\nfor t ∈[T] do\nTake a random sample Lt with sampling probability L/N\nCompute gradient\nFor each i ∈Lt, compute gt(xi) ←∇θtL(θt, xi)\nClip gradient\n¯gt(xi) ←gt(xi)/ max\n\u00001, ∥gt(xi)∥2\nC\n\u0001\nAdd noise\n˜gt ←1\nL\n\u0000P\ni ¯gt(xi) + N(0, σ2C2I)\n\u0001\nDescent\nθt+1 ←θt −ηt˜gt\nOutput θT and compute the overall privacy cost (ε, δ) using a privacy accounting\nmethod.\nAlgorithm There are a variety of schemes which have been shown to have\nhomomorphic properties, and are provably secure. The most common use the\nsecurity of the LWE (learning with errors) problem, which seeks to solve a linear\nsystem after adding noise. This problem is diﬃcult to solve in certain conditions\n(when the dimension of the vector space is much larger than the computational\nrange), and has even been shown to be secure under known quantum attacks. In\nshort, LWE contains an algebraic structure with homomorphisms for addition\nand multiplication under the ﬁnite ﬁeld of integers (so all multiplication/addition\nof ﬁnite integers can be encrypted and evaluated homomorphically as a LWE\nproblem). In practice, implementations use R-LWE (Ring-LWE, use polynomial\nrings instead of vector spaces explicitly), which uses a slightly diﬀerent represen-\ntation, but the underlying algebraic structure remains largely the same.\nSimple LWE example: The key generation, encryption/decryption and corre-\nsponding add/multiply operations for a simple LWE example are given below.\nNo Peek: A Survey of private distributed deep learning\n11\nKeygen:\nA ∈Zm×n\nq\nS ∼Zn\nq\ne ∼N n\nb = As + e\n(1)\nEncrypt/Encode:\nr1, e1 ∼N\nc = (ca, cb) =\n\u0000AT r1, bT r1 + m1 + e1\n\u0001\n(2)\nAdd/Multiply:\ncadd = c1 + c2\n(3)\ncmult = D (c1 ⊗c2)\n(4)\nwhere ⊗is the tensor product and D is a dimension switching matrix that sim-\npliﬁes the resulting ciphertext. A proof of correctness and further sophistication\naddressing this scheme as a practical system can be found in the LWE literature.\nBeneﬁts and Limitations These techniques need specialized hardware or\nextensive computational resources to scale. They are capable of providing a higher\nlevel of security that allows for perfect decryption and are not dependent on\ntrade-oﬀs of obfuscation vs. accuracy. The tradeoﬀs involved in this case are more\nwith regards to computational eﬃciency. For example, some work (Microsoft’s\nSEAL) shows that to perform logistic regression on 1MB of data, 10GB of\nmemory are required, and massive parallelization is necessary to achieve real-time\nthroughput on practical problems (some tasks may not be parallelizable as such).\nLWE hardness is believed to be valid even in a post-quantum cryptographic\nenvironment.\nFuture Trends This method requires very high computational resources, to\nmake it scalable to practical deep learning architectures. Current techniques have\nonly been benchmarked on simple networks over small datasets such as MNIST\nhand-written digit recognition. Development of faster methods for large scale\ndeep learning and specialized hardware is an important avenue for future work.\n6.3\nMulti-Party Computation (MPC) and Garbled Circuits\nKey Idea: These techniques are based on the idea of secret sharing and zero\nknowledge proof that we describe. The protection is achieved by sharing a\n12\nNo Peek: A Survey of private distributed deep learning\nsecret message with diﬀerent entities and requiring that these entities cooperate\ntogether in order to gain accessibility. There are certain problems where two\nentities collaborate to compute a function without sharing information about the\ninputs to the function with each other. The classic example is the millionaire’s\nproblem, where f(x1, x2) is computed by two parties, when one party has x1\nand the other has x2, and it’s impossible for the party to the learn the value\nthe other party holds. f(x1, x2) will return a positive number if x1 > x2 and a\nnegative value if x2 > x1. In this way, two millionaire’s can determine who has\nmore money without sharing the total value at each hold. This has practical\napplications to untrusted “credit checks” or as an example for a particular kind of\n“Zero Knowledge Proof.” Yao’s [48] garbled circuit protocol for the millionaire’s\nproblem and 1–2 oblivious transfer [114,113] are prominent works in this direction.\nComputational implementations and frameworks for this work such as Obliv-C,\nObliVM, SPDZ and Sharemind are prominent.\nBeneﬁts and Limitations: These techniques have been studied for problems\nlike secure stable matching, linear system solving and parallel graph algorithms.\nThere is not much work done at intersection of MPC with deep learning.\nFuture Trends: Specialized hardwares for MPC are being developed to realize\npractical applications of these protocols. As current day machine learning relies\nheavily on large scale deep-learning architectures on large datasets, bridging this\ngap between MPC frameworks and distributed deep learning is an important\navenue for future work.\nMethod\n100 Clients\n500 Clients\nLarge Batch SGD\n29.4 TFlops\n5.89 TFlops\nFederated Learning 29.4 TFlops\n5.89 TFlops\nSplitNN\n0.1548 TFlops 0.03 TFlops\nTable 4: Computation resources consumed per client when training CIFAR 10\nover VGG (in teraﬂops) are drastically lower for SplitNN than Large Batch SGD\nand Federated Learning.\n7\nComparison of resource eﬃciency across no peek\ndistributed deep learning\nWe now share a comparison from [31] of validation accuracy and required client\ncomputational resources in Figure 1 for the three techniques of federated learning,\nlarge batch synchronous SGD and splitNN as they are tailored for distributed\ndeep learning. As seen in this ﬁgure, the comparisons were done on datasets of\nCIFAR 10 and CIFAR 100 using VGG and Resnet-50 architectures for 100 and\n500 client based setups respectively. In this distributed learning experiment we\nclearly see that SplitNN outperforms the techniques of federated learning and\nlarge batch synchronous SGD in terms of higher accuracies with drastically lower\nNo Peek: A Survey of private distributed deep learning\n13\nMethod\n100 Clients 500 Clients\nLarge Batch SGD\n13 GB\n14 GB\nFederated Learning 3 GB\n2.4 GB\nSplitNN\n6 GB\n1.2 GB\nTable 5: Computation bandwidth required per client when training CIFAR 100\nover ResNet (in gigabytes) is lower for splitNN than large batch SGD and\nfederated learning with a large number of clients. For setups with a smaller\nnumber of clients, federated learning requires a lower bandwidth than splitNN.\nLarge batch SGD methods popular in data centers use a heavy bandwidth in\nboth settings.\ncomputational requirements on the side of clients. In tables 4 and 5 we share more\ncomparisons from [31] on computing resources in TFlops and communication\nbandwidth in GB required by these techniques. SplitNN again has a drastic\nimprovement of computational resource eﬃciency on the client side. In the case\nwith a relatively smaller number of clients the communication bandwidth required\nby federated learning is less than splitNN.\n(a) Accuracy vs client-side ﬂops on 100\nclients with VGG on CIFAR 10\n(b) Accuracy vs client-side ﬂops on 500\nclients with Resnet-50 on CIFAR 100\nFig. 3: We show dramatic reduction in computational burden (in tﬂops) while\nmaintaining higher accuracies when training over large number of clients with\nsplitNN. Blue line denotes distributed deep learning using splitNN, red line\nindicate federated averaging and green line indicates large batch SGD.\n14\nNo Peek: A Survey of private distributed deep learning\n8\nConclusion and Future Work\nNo peek deep neural networks require new thinking when compared to existing\ndata protection methods that attempt to aggregate siloed data for the beneﬁt\nof server models. We describe the emergence of three methods in this setting:\nsplitNN, federated learning and large batch SGD. Novel combinations of these\nmethods with diﬀerential privacy, homomorphic encryption and secure MPC\ncould further exploit theoretical guarantees. We show that in settings with large\nnumber of clients, splitNN needs the least communications bandwidth while\nfederated learning does better with relatively smaller number of clients. In this\ndirection, improving resource and communication eﬃciencies of no peek methods\nwould be another avenue for impactful future work. Using advanced neural\nnetwork compression methods [35,111,36] will help further reduce the required\nnetwork footprint. It is also important to study adversarial robustness to data\npoisoning attacks [37] where malicious users can inject false training data to\nnegatively eﬀect the classiﬁcation performance of the model. Adversarial attack\nschemes from this parallel research area need to be taken into consideration\nwhile developing no peek mechanisms. Eﬃcient no peek methods have direct\napplications to important domains like distributed healthcare, distributed clinical\ntrials, inter and intra organizational collaboration and ﬁnance. We therefore\ncontemplate novel no peek distributed deep learning applications in the future.\n9\nReferences\nReferences\n1. Centers for Disease Control and Prevention,HIPAA privacy rule and public health.\nGuidance from CDC and the US Department of Health and Human Services,\nMMWR: Morbidity and mortality weekly report, US Centers for Disease Control\nand Prevention, 2003\n2. keywords = block10, Vepakomma, Praneeth and Gupta, Otkrist and Swedish,\nTristan and Raskar, Ramesh, Split learning for health: Distributed deep learning\nwithout sharing raw patient data, arXiv1812.00564,2018\n3. H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson and Blaise\nAguera y Arcas, Communication-eﬃcient learning of deep networks from decentral-\nized data, 20’th International Conference on Artiﬁcial Intelligence and Statistics\n(AISTATS), 2017.\n4. Swedish, Tristan and Raskar, Ramesh, Deep Visual Teach and Repeat on Path\nNetworks, The IEEE Conference on Computer Vision and Pattern Recognition\n(CVPR) Workshops, 2018.\n5. Annas, George J. , HIPAA regulations-a new era of medical-record privacy?, New\nEngland Journal of Medicine, Vol.348 (15), pp.1486–1490, 2003.\n6. Mercuri, Rebecca T. , The HIPAA-potamus in health care data security, Commu-\nnications of the ACM, Vol.47 (7), pp.25–28, 2004.\n7. Gostin, Lawrence O., Levit, Laura A. and Nass, Sharyl J. , Beyond the HIPAA\nprivacy rule: enhancing privacy, improving health through research, National\nAcademies Press, 2009.\nNo Peek: A Survey of private distributed deep learning\n15\n8. Luxton, David D and Kayl, Robert A and Mishkind, Matthew C. , mHealth\ndata security: The need for HIPAA-compliant standardization, Telemedicine and\ne-Health, Vol.18(4), pp. 284–288, 2012.\n9. Konečny, Jakub and McMahan, H Brendan and Yu, Felix X and Richtárik, Peter\nand Suresh, Ananda Theertha and Bacon, D. , Federated learning: Strategies for\nimproving communication eﬃciency, arXiv preprint arXiv:1610.05492, 2016.\n10. Hynes, Nick and Cheng, Raymond and Song, Dawn , Eﬃcient Deep Learning on\nMulti-Source Private Data, arXiv preprint arXiv:1807.06689, 2018.\n11. Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and\nMironov, Ilya and Talwar, Kunal and Zhang, Li, Deep learning with diﬀerential\nprivacy, Proceedings of the 2016 ACM SIGSAC Conference on Computer and\nCommunications Security, pp.308–318, 2016.\n12. Shokri, Reza and Shmatikov, Vitaly, Privacy-preserving deep learning, Proceedings\nof the 22nd ACM SIGSAC conference on computer and communications security,\npp.1310–1321 2015.\n13. Papernot, Nicolas and Abadi, Martín and Erlingsson, Ulfar and Goodfellow, Ian\nand Talwar, Kunal, Semi-supervised knowledge transfer for deep learning from\nprivate training data, arXiv preprint arXiv:1610.05755, 2016.\n14. Geyer, Robin C and Klein, Tassilo and Nabi, Moin, Diﬀerentially private federated\nlearning: A client level perspective, arXiv preprint arXiv:1712.07557, 2017.\n15. Rouhani, Bita Darvish and Riazi, M Sadegh and Koushanfar, Farinaz, Deepsecure:\nScalable provably-secure deep learning, arXiv preprint arXiv:1705.08963, 2017.\n16. Rouhani, Bita Darvish and Riazi, M Sadegh and Koushanfar, Farinaz, SecureML:\nA system for scalable privacy-preserving machine learning, 38th IEEE Symposium\non Security and Privacy (SP), 2017.\n17. Hesamifard, Ehsan and Takabi, Hassan and Ghasemi, Mehdi, CryptoDL: Deep\nNeural Networks over Encrypted Data, arXiv preprint arXiv:1711.05189, 2017.\n18. Hardy, Stephen and Henecka, Wilko and Ivey-Law, Hamish and Nock, Richard\nand Patrini, Giorgio and Smith, Guillaume and Thorne, Brian, Private feder-\nated learning on vertically partitioned data via entity resolution and additively\nhomomorphic encryption, arXiv preprint arXiv:1711.10677, 2017.\n19. Aono, Yoshinori and Hayashi, Takuya and Wang, Lihua and Moriai, Shiho, Privacy-\npreserving deep learning via additively homomorphic encryptionn, IEEE Transac-\ntions on Information Forensics and Security, Vol.13(5), pp.1333–1345arXiv preprint\narXiv:1711.10677, 2018.\n20. Chen, Jianmin and Pan, Xinghao and Monga, Rajat and Bengio, Samy and\nJozefowicz, Rafal, Revisiting distributed synchronous SGD, IEEE Transactions on\nInformation Forensics and Security, Vol.13(5), arXiv preprint arXiv:1604.00981,\n2016.\n21. Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio\nand McMahan, H Brendan and Patel, Sarvar and Ramage, Daniel and Segal,\nAaron and Seth, Karn, Practical secure aggregation for privacy-preserving machine\nlearning, Proceedings of the 2017 ACM SIGSAC Conference on Computer and\nCommunications Security, pp.1175–1191, 2017.\n22. Ben-Nun, Tal and Hoeﬂer, Torsten, Demystifying Parallel and Distributed Deep\nLearning: An In-Depth Concurrency Analysis, arXiv preprint arXiv:1802.09941,\n2018.\n23. Shickel, Benjamin and Tighe, Patrick James and Bihorac, Azra and Rashidi,\nParisa, Deep EHR: A survey of recent advances in deep learning techniques for\nelectronic health record (EHR) analysis, IEEE journal of biomedical and health\ninformatics, Vol.22(5) pp.1589–1604, 2018.\n16\nNo Peek: A Survey of private distributed deep learning\n24. Ching, Travers and Himmelstein, Daniel S and Beaulieu-Jones, Brett K and Kalinin,\nAlexandr A and Do, Brian T and Way, Gregory P and Ferrero, Enrico and Agapow,\nPaul-Michael and Zietz, Michael and Hoﬀman, Michael M , Opportunities and\nobstacles for deep learning in biology and medicine, Journal of The Royal Society\nInterface, Vol.15(141), 2018.\n25. Miotto, Riccardo and Wang, Fei and Wang, Shuang and Jiang, Xiaoqian and\nDudley, Joel T., Deep learning for healthcare: review, opportunities and challenges,\nBrieﬁngs in bioinformatics, 2017.\n26. Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet\nS., Advances in Neural Information Processing Systems, pp.4424–4434, 2017.\n27. Syverson, Paul and Dingledine, R and Mathewson, N, Tor: The second generation\nonion router,Usenix Security, 2004.\n28. Ravı, Daniele and Wong, Charence and Deligianni, Fani and Berthelot, Melissa and\nAndreu-Perez, Javier and Lo, Benny and Yang, Guang-Zhong, Deep learning for\nhealth informatics, IEEE journal of biomedical and health informatics, Vol.21(1),\npp.4–21, 2017.\n29. Alipanahi, Babak and Delong, Andrew and Weirauch, Matthew T and Frey,\nBrendan J, Predicting the sequence speciﬁcities of DNA-and RNA-binding proteins\nby deep learning, Nature biotechnology, Vol.33(8), 2015.\n30. Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud\nArindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der\nLaak, Jeroen AWM and Van Ginneken, Bram and Sánchez, Clara I, A survey on\ndeep learning in medical image analysis, Medical image analysis, Vol.42, pp.60–88,\n2017.\n31. Gupta, Otkrist and Raskar, Ramesh, Distributed learning of deep neural network\nover multiple agents, Journal of Network and Computer Applications, Vol.116,\npp.1–8, 2018.\n32. Navathe, Shamkant and Ceri, Stefano and Wiederhold, Gio and Dou, Jinglie, Ver-\ntical partitioning algorithms for database design, ACM Transactions on Database\nSystems (TODS), Vol.9(4), pp.680–710, 1984.\n33. Agrawal, Sanjay and Narasayya, Vivek and Yang, Beverly, Integrating vertical\nand horizontal partitioning into automated physical database design, Proceedings\nof the 2004 ACM SIGMOD international conference on Management of data,\npp.359–370, 2004.\n34. Abadi, Daniel J and Marcus, Adam and Madden, Samuel R and Hollenbach, Kate,\nScalable semantic web data management using vertical partitioning, Proceedings\nof the 33rd international conference on Very large data bases, pp.411–422, 2007.\n35. Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J,\nDeep gradient compression: Reducing the communication bandwidth for distributed\ntraining, arXiv preprint arXiv:1712.01887, 2017.\n36. Han, Song and Mao, Huizi and Dally, William J, Deep compression: Compressing\ndeep neural networks with pruning, trained quantization and huﬀman coding,\narXiv preprint arXiv:1510.00149, 2015.\n37. Fung, Clement and Yoon, Chris JM and Beschastnikh, Ivan, Mitigating Sybils in\nFederated Learning Poisoning, arXiv preprint arXiv:1808.04866, 2018.\n38. Xie, Liyang and Lin, Kaixiang and Wang, Shu and Wang, Fei and Zhou,\nJiayu, Diﬀerentially Private Generative Adversarial Network, arXiv preprint\narXiv:1802.06739, 2018.\n39. Crawford, Jack LH and Gentry, Craig and Halevi, Shai and Platt, Daniel and\nShoup, Victor, Doing Real Work with FHE: The Case of Logistic Regression, 2018\nNo Peek: A Survey of private distributed deep learning\n17\n40. Sans, Edouard Dufour and Gay, Romain and Pointcheval, David, Reading in the\nDark: Classifying Encrypted Digits with Functional Encryption, 2018\n41. Rosulek, Mike, Improvements for Gate-Hiding Garbled Circuits, International\nConference in Cryptology in India, 2017\n42. Choudhury, Ashish and Loftus, Jake and Orsini, Emmanuela and Patra, Arpita\nand Smart, Nigel P, Between a Rock and a Hard Place: Interpolating between MPC\nand FHE, International Conference on the Theory and Application of Cryptology\nand Information Security, 2013\n43. Keller, Marcel and Pastro, Valerio and Rotaru, Dragos, Overdrive: making SPDZ\ngreat again, Annual International Conference on the Theory and Applications of\nCryptographic Techniques, 2018\n44. Juvekar, Chiraag and Vaikuntanathan, Vinod and Chandrakasan, Anantha, Gazelle:\nA low latency framework for secure neural network inference, arXiv preprint\narXiv:1801.05507, 2018\n45. Gilad-Bachrach, Ran and Dowlin, Nathan and Laine, Kim and Lauter, Kristin\nand Naehrig, Michael and Wernsing, John, Cryptonets: Applying neural networks\nto encrypted data with high throughput and accuracy, International Conference\non Machine Learning, 2016\n46. Riazi, M Sadegh and Weinert, Christian and Tkachenko, Oleksandr and Songhori,\nEbrahim M and Schneider, Thomas and Koushanfar, Farinaz, Chameleon: A hybrid\nsecure computation framework for machine learning applications, Proceedings of\nthe 2018 on Asia Conference on Computer and Communications Security, 2018\n47. Liu, Jian and Juuti, Mika and Lu, Yao and Asokan, N, Oblivious neural network\npredictions via minionn transformations, Proceedings of the 2017 ACM SIGSAC\nConference on Computer and Communications Security, 2017\n48. , Andrew C. Yao, Protocols for Secure Computations, University of California\nBerkeley, California, IEEE Foundations of Computer Science, 23rd Annual Sym-\nposium on, https://research.cs.wisc.edu/areas/sec/yao1982-ocr.pdf, 1982\n49. Ziad, M Tarek Ibn and Alanwar, Amr and Alzantot, Moustafa and Srivastava,\nMani, Cryptoimg: Privacy preserving processing over encrypted images, IEEE\nConference on Communications and Network Security, 2016\n50. Mironov, Ilya, Renyi diﬀerential privacy, IEEE 30th Computer Security Founda-\ntions Symposium, 2017\n51. Kuo, Yu-Hsuan and Chiu, Cho-Chun and Kifer, Daniel and Hay, Michael and\nMachanavajjhala, Ashwin, Diﬀerentially private hierarchical count-of-counts his-\ntograms, Proceedings of the VLDB Endowment, 2018\n52. Li, Ninghui and Li, Tiancheng and Venkatasubramanian, Suresh, t-closeness:\nPrivacy beyond k-anonymity and l-diversity, IEEE 23rd International Conference\non Data Engineering (ICDE), 2007\n53. He, Xi and Machanavajjhala, Ashwin and Ding, Bolin, Blowﬁsh privacy: Tuning\nprivacy-utility trade-oﬀs using policies, Proceedings of the 2014 ACM SIGMOD\ninternational conference on Management of data, 2014\n54. He, Xi and Cormode, Graham and Machanavajjhala, Ashwin and Procopiuc,\nCecilia M and Srivastava, Divesh, DPT: diﬀerentially private trajectory synthesis\nusing hierarchical reference systems, Proceedings of the VLDB Endowment, 2015\n55. Carlini, Nicholas and Liu, Chang and Kos, Jernej and Erlingsson, Úlfar and Song,\nDawn, The Secret Sharer: Measuring Unintended Neural Network Memorization\n& Extracting Secrets,arXiv preprint arXiv:1802.08232, 2018\n56. Hisham Husain, Zac Cranko, Richard Nock, Integral Privacy for Sampling from\nMolliﬁer Densities with Approximation Guarantees, arXiv:1806.04819, 2018\n18\nNo Peek: A Survey of private distributed deep learning\n57. Zhang, Zuhe and Rubinstein, Benjamin IP and Dimitrakakis, Christos, On the\nDiﬀerential Privacy of Bayesian Inference, AAAI conference on artiﬁcial intelligence,\nAAAI, 2016\n58. Jain, Prateek and Kothari, Pravesh and Thakurta, Abhradeep, Diﬀerentially\nprivate online learningConference on Learning Theory,2012\n59. Xi Wu and Fengan Li and Arun Kumar and Kamalika Chaudhuri and Somesh\nJha and Jeﬀrey F. Naughton, Bolt-on Diﬀerential Privacy for Scalable Stochastic\nGradient Descent-based Analytics, SIGMOD Conference, 2017\n60. Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah\nand Shmatikov, Vitaly, How To Backdoor Federated Learning, arXiv preprint\narXiv:1807.00459, 2018\n61. Jalaj Upadhyay, Diﬀerentially Private Linear Algebra in the Streaming Model,\nIACR Cryptology ePrint Archive, 2014\n62. Nikita Mishra, Private Stochastic Multi-arm Bandits: From Theory to Practice,\n31 st International Conference on Machine Learning (ICML), 2014\n63. Ruochi Zhang and Parv Venkitasubramaniam, Mutual-Information-Private Online\nGradient Descent Algorithm, 2018 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP), 2018\n64. Seth Gilbert and Xiao Liu and Haifeng Yu, On Diﬀerentially Private Online\nCollaborative Recommendation Systems, International Conference on Information\nSecurity and Cryptology, 2015\n65. John N. Tsitsiklis and Kuang Xu and Zhi Xu, Private Sequential Learning, COLT,\n2018\n66. Depeng Xu and Shuhan Yuan and Xintao Wu, Diﬀerential Privacy Preserving\nCausal Graph Discovery, IEEE Symposium on Privacy-Aware Computing (PAC),\n2017\n67. Jacob D. Abernethy and Chansoo Lee and Audra McMillan and Ambuj Tewari,\nOnline Learning via Diﬀerential Privacy, CoRR, abs/1711.10019, 2017\n68. Ngoc-Son Phan and Xintao Wu and Dejing Dou, Preserving diﬀerential privacy in\nconvolutional deep belief networks, Machine Learning Journal, Springer, 2017\n69. Giulia C. Fanti and Vasyl Pihur and Úlfar Erlingsson, Building a RAPPOR with\nthe Unknown: Privacy-Preserving Learning of Associations and Data Dictionaries,\n2016\n70. Ziteng Wang and Chi Jin and Kai Fan and Jiaqi Zhang and Junliang Huang and\nYiqiao Zhong and Liwei Wang, Diﬀerentially Private Data Releasing for Smooth\nQueries, Journal of Machine Learning Research, 2016\n71. Raghavendran Balu and Teddy Furon, Diﬀerentially Private Matrix Factorization\nusing Sketching Techniques, Proceedings of the 4th ACM Workshop on Information\nHiding and Multimedia Security, 2016\n72. Mohsen Ghassemi and Anand D. Sarwate and Rebecca N. Wright, Diﬀerentially\nPrivate Online Active Learning with Applications to Anomaly Detection, AISec-\nCCS, 2016\n73. Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney,\nMichael W, Hessian-based Analysis of Large Batch Training and Robustness to\nAdversaries, arXiv preprint arXiv:1802.08241, 2018\n74. Yuncheng Wu and Yao Wu and Hui Peng and Juru Zeng and Hong Chen and\nCuiping Li, Diﬀerentially private density estimation via Gaussian mixtures model,\nIEEE/ACM 24th International Symposium on Quality of Service (IWQoS), 2016\n75. Shiva Prasad Kasiviswanathan and Hongxia Jin, Eﬃcient Private Empirical\nRisk Minimization for High-dimensional Learning, Interncational Conference on\nMachine Learning, ICML, 2016\nNo Peek: A Survey of private distributed deep learning\n19\n76. Lu Tian and Bargav Jayaraman and Q. Gu and David Evans, Aggregating Private\nSparse Learning Models Using Multi-Party Computation, 2016\n77. John C. Duchi and Michael I. Jordan and Martin J. Wainwright, Privacy Aware\nLearning, Neural Information Processing Systems (NIPS), 2012\n78. Marco Gaboardi and Emilio Jesús Gallego Arias and Justin Hsu and Aaron Roth\nand Zhiwei Steven Wu, Dual Query: Practical Private Query Release for High\nDimensional Data, Interncational Conference on Machine Learning, ICML, 2014\n79. Nikolaenko, Valeria and Weinsberg, Udi and Ioannidis, Stratis and Joye, Marc\nand Boneh, Dan and Taft, Nina, Privacy-preserving ridge regression on hundreds\nof millions of records, IEEE Symposium on Security and Privacy (SP), 2013\n80. Miran Kim and Kristin E. Lauter, Private Genome Analysis through Homomorphic\nEncryption, BMC medical informatics and decision making, 2015\n81. Thore Graepel and Kristin E. Lauter and Michael Naehrig, ML Conﬁdential:\nMachine Learning on Encrypted Data, IACR Cryptology ePrint Archive, 2012\n82. Raphael Bost and Raluca A. Popa and Stephen Tu and ShaﬁGoldwasser, Machine\nLearning Classiﬁcation over Encrypted Data, IACR Cryptology ePrint Archive,\n2014\n83. Oded Goldreich and ShaﬁGoldwasser and Dana Ron, Property Testing and its\nconnection to Learning and Approximation, Journal of the ACM, 1996\n84. Orlandi, Claudio and Piva, Alessandro and Barni, Mauro, Oblivious neural net-\nwork computing via homomorphic encryption, EURASIP Journal on Information\nSecurity, Springer, 2007\n85. Shengshan Hu and Qian Wang and Jingjun Wang and Sherman S. M. Chow and\nQin Zou, Securing Fast Learning! Ridge Regression over Encrypted Big Data,\nIEEE Trustcom/BigDataSE/ISPA, 2016\n86. Mauro Barni and Pierluigi Failla and Riccardo Lazzeretti and Ahmad-Reza Sadeghi\nand Thomas Schneider, Privacy-Preserving ECG Classiﬁcation With Branching\nPrograms and Neural Networks, IEEE Transactions on Information Forensics and\nSecurity, 2011\n87. Zhan Qin and Jingbo Yan and Kui Ren and Chang Wen Chen and Xinyu Wang,\nSecSIFT: Secure Image SIFT Feature Extraction in Cloud Computing, TOMCCAP,\n2016\n88. Yifeng Zheng and Helei Cui and Xinyu Wang and Jiantao Zhou, Privacy-Preserving\nImage Denoising From External Cloud Databases, IEEE Transactions on Informa-\ntion Forensics and Security, 2017\n89. Reda Bellafqira and Gouenou Coatrieux and Dalel Bouslimi and Gwénolé Quellec\nand Michel Cozic, Secured Outsourced Content Based Image Retrieval Based\non Encrypted Signatures Extracted From Homomorphically Encrypted Images,\nCoRR abs/1704.00457,2017\n90. Reda Bellafqira and Gouenou Coatrieux and Emmanuelle Génin and Michel\nCozic Secure Multilayer Perceptron Based On Homomorphic Encryption, CoRR\nabs/1806.02709, 2018\n91. Ryo Yonetani and Vishnu Naresh Boddeti and Kris M. Kitani and Yoichi Sato,\nPrivacy-Preserving Visual Learning Using Doubly Permuted Homomorphic En-\ncryption, 2017 IEEE International Conference on Computer Vision (ICCV), 2017\n92. Tribhuvanesh Orekondy and Seong Joon Oh and Bernt Schiele and Mario Fritz,\nUnderstanding and Controlling User Linkability in Decentralized Learning, CoRR\nabs/1805.05838, 2018\n93. David Wu, Using Homomorphic Encryption for Large Scale Statistical Analysis,\nStanford report, 2012\n20\nNo Peek: A Survey of private distributed deep learning\n94. Pedro M. Esperança and Louis J. M. Aslett and Chris C. Holmes, Encrypted\naccelerated least squares regression, Artiﬁcial intelligence and statistics, AISTATS,\n2017\n95. Richard Nock and Stephen Hardy and Wilko Henecka and Hamish Ivey-Law and\nGiorgio Patrini and Guillaume Smith and Brian Thorne, Entity Resolution and\nFederated Learning get a Federated Resolution, CoRR, abs/1803.04035, 2018\n96. Wen-Jie Lu and Jun Sakuma, Using Fully Homomorphic Encryption for Statistical\nAnalysis of Categorical, Ordinal and Numerical Data, 2016\n97. Yuchen Zhang and Wenrui Dai and Xiaoqian Jiang and Hongkai Xiong and\nShuang Wang, FORESEE: Fully Outsourced secuRe gEnome Study basEd on\nhomomorphic Encryption, BMC medical informatics and decision making, 2015\n98. Md. Nazmus Sadat and Md Momin Al Aziz and Noman Mohammed and Feng\nChen and Shuang Wang and Xiaoqian Jiang, SAFETY: Secure gwAs in Federated\nEnvironment Through a hYbrid solution with Intel SGX and Homomorphic\nEncryption, IEEE/ACM transactions on computational biology and bioinformatics,\n2018\n99. Md Momin Al Aziz and Mohammad Zahidul Hasan and Noman Mohammed and\nDima Alhadidi, Secure and Eﬃcient Multiparty Computation on Genomic Data,\n2016\n100. Dwork, Cynthia and Roth, Aaron, The algorithmic foundations of diﬀerential pri-\nvacy, Foundations and Trends R\n⃝in Theoretical Computer Science, Now Publishers\nInc, 2014\n101. Cynthia Dwork and Frank McSherry and Kobbi Nissim and Adam D. Smith,\nCalibrating Noise to Sensitivity in Private Data Analysis, TCC, 2006\n102. Dwork, Cynthia, A Firm Foundation for Private Data Analysis, Commun. ACM,\n10.1145/1866739.1866758, ACM\n103. Bourse, Florian and Minelli, Michele and Minihold, Matthias and Paillier, Pas-\ncal Fast homomorphic evaluation of deep discretized neural networks, Annual\nInternational Cryptology Conference, Springer, 2018\n104. Upadhyay, Jalaj, The Price of Diﬀerential Privacy for Low-Rank Factorization,\nNeural Information Processing Systems,2018\n105. Awan, Jordan and Slavkovic, Aleksandra, Diﬀerentially Private Uniformly Most\nPowerful Tests for Binomial Data, Neural Information Processing Systems, 2018\n106. Hitaj, Briland and Ateniese, Giuseppe and Perez-Cruz, Fernando, Deep models\nunder the GAN: information leakage from collaborative deep learning, Proceedings\nof the 2017 ACM SIGSAC Conference on Computer and Communications Security,\n2017\n107. Dean, Jeﬀrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin,\nMatthieu and Mao, Mark and Senior, Andrew and Tucker, Paul and Yang, Ke and\nLe, Quoc V, Large scale distributed deep networks, Advances in neural information\nprocessing systems, 2012\n108. Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and\nChen, Yiran and Li, Hai, Terngrad: Ternary gradients to reduce communication\nin distributed deep learning, Advances in neural information processing systems,\n2017\n109. Das, Dipankar and Avancha, Sasikanth and Mudigere, Dheevatsa and Vaidynathan,\nKarthikeyan and Sridharan, Srinivas and Kalamkar, Dhiraj and Kaul, Bharat and\nDubey, Pradeep, Distributed deep learning using synchronous stochastic gradient\ndescent, arXiv preprint arXiv:1602.06709, 2016\nNo Peek: A Survey of private distributed deep learning\n21\n110. Ooi, Beng Chin and Tan, Kian-Lee and Wang, Sheng and Wang, Wei and Cai,\nQingchao and Chen, Gang and Gao, Jinyang and Luo, Zhaojing and Tung, Anthony\nKH and Wang, Yuan, SINGA: A distributed deep learning platform, Proceedings\nof the 23rd ACM international conference on Multimedia, 2015\n111. Louizos, Christos and Ullrich, Karen and Welling, Max Bayesian compression for\ndeep learning, Advances in Neural Information Processing Systems, 2017\n112. Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon\nand Chandra, Vikas, Federated Learnin\n113. Even, Shimon and Goldreich, Oded and Lempel, Abraham, A randomized protocol\nfor signing contracts, Communications of the ACM, 1985\n114. Rabin, Michael O, How To Exchange Secrets with Oblivious Transfer, IACR\nCryptology ePrint Archive, 2005\n115. Sathya, Sai Sri and Vepakomma, Praneeth and Raskar, Ramesh and Ramachan-\ndra, Ranjan and Bhattacharya, Santanu, A Review of Homomorphic Encryption\nLibraries for Secure Computation, arXiv1812.02428, 2018\n",
  "categories": [
    "cs.LG",
    "cs.DC",
    "stat.ML"
  ],
  "published": "2018-12-08",
  "updated": "2018-12-08"
}