{
  "id": "http://arxiv.org/abs/1812.05272v1",
  "title": "Towards a General-Purpose Linguistic Annotation Backend",
  "authors": [
    "Graham Neubig",
    "Patrick Littell",
    "Chian-Yu Chen",
    "Jean Lee",
    "Zirui Li",
    "Yu-Hsiang Lin",
    "Yuyan Zhang"
  ],
  "abstract": "Language documentation is inherently a time-intensive process; transcription,\nglossing, and corpus management consume a significant portion of documentary\nlinguists' work. Advances in natural language processing can help to accelerate\nthis work, using the linguists' past decisions as training material, but\nquestions remain about how to prioritize human involvement. In this extended\nabstract, we describe the beginnings of a new project that will attempt to ease\nthis language documentation process through the use of natural language\nprocessing (NLP) technology. It is based on (1) methods to adapt NLP tools to\nnew languages, based on recent advances in massively multilingual neural\nnetworks, and (2) backend APIs and interfaces that allow linguists to upload\ntheir data. We then describe our current progress on two fronts: automatic\nphoneme transcription, and glossing. Finally, we briefly describe our future\ndirections.",
  "text": "Towards a General-Purpose Linguistic Annotation Backend\nGraham Neubig†, Patrick Littell‡, Chian-Yu Chen†, Jean Lee†,\nZirui Li†, Yu-Hsiang Lin†, Yuyan Zhang†\n†Language Technologies Institute, Carnegie Mellon University\n‡National Research Council Canada\ngneubig@cs.cmu.edu\n1\nIntroduction\nLanguage documentation is inherently a time-\nintensive process; transcription, glossing, and cor-\npus management consume a signiﬁcant portion of\ndocumentary linguists’ work. Advances in natu-\nral language processing can help to accelerate this\nwork, using the linguists’ past decisions as train-\ning material, but questions remain about how to\nprioritize human involvement.\nIn this extended abstract, we describe the begin-\nnings of a new project that will attempt to ease this\nlanguage documentation process through the use\nof natural language processing (NLP) technology.\nIt is based on (1) methods to adapt NLP tools to\nnew languages, based on recent advances in mas-\nsively multilingual neural networks, and (2) back-\nend APIs and interfaces that allow linguists to up-\nload their data (§2). We then describe our current\nprogress on two fronts: automatic phoneme tran-\nscription, and glossing (§3). Finally, we brieﬂy\ndescribe our future directions (§4).\n2\nOverall Framework\nThe ﬁnal goal of our project is to create a lin-\nguistic annotation backend (LAB), that will take\nin raw or partially annotated linguistic data, and\nprovide annotation candidates for a linguist (or\nother interested party) to peruse.\nCandidates\nfor the types of services to provide are auto-\nmatic phoneme transcription (Adams et al., 2018;\nMichaud et al., 2018), speech-to-text alignmen\n(Johnson et al., 2018), word segmentation (Peng\net al., 2004; Goldwater et al., 2009), morpholog-\nical analysis (Yarowsky and Wicentowski, 2000),\nsyntactic analysis (Nivre, 2005), automatic gloss-\ning (Riding, 2008), or linguistic typology predic-\ntion (Daume III and Campbell, 2007). The LAB\nwill be hosted on a server and exposed as an API\nthat can be linked to popular annotation software\nsuch as ELAN1 or FLEx.2\nThe obvious difﬁculty in creating such an in-\nterface is data scarcity in the languages in ques-\ntion. In order to overcome these barriers, we plan\nto take advantage of recent advances in NLP that\nallow for multilingual modeling (T¨ackstr¨om et al.,\n2012; Johnson et al., 2016) and multi-task learning\n(Caruana, 1997), which allow models to be trained\nwith very little, or even no data in the target lan-\nguage (Neubig and Hu, 2018). We also plan to uti-\nlize active learning (Settles, 2009), which specif-\nically asks the linguists to focus on particular ex-\namples to maximize the effect of linguists’ lim-\nited time when working with ﬁeld data.\nWhile\nthere is still no alternative to signiﬁcant human\nengagement when processing data, many of the\ndecisions a linguist is faced with when transcrib-\ning, glossing, organizing, or searching a corpus are\nrelatively rote – decisions that could be deducible\nfrom past decisions or from similar languages.\n3\nCurrent Progress: A\nBackend/Interface for Automatic\nPhoneme Transcription and Glossing\nAs ﬁrst steps towards realizing our ﬁnal goal, we\nhave currently developed a backend for two tasks\n(automatic phoneme transcription and glossing),\nwhich is integrated with a simple example inter-\nface.\n3.1\nBackend Overview\nThe current LAB is based on a simple three-step\nprocess:\nData Upload The linguist uploads any existing\nannotated data to the interface.\n1https://tla.mpi.nl/tools/tla-tools/\nelan/\n2https://software.sil.org/fieldworks/\narXiv:1812.05272v1  [cs.CL]  13 Dec 2018\nFigure 1: The prototype of the automated interface sup-\nporting transcription and glossing.\nFigure 2: Uploading the training data to the automated\ninterface for transcription model training.\nModel Training A model is trained to process\nthis data. This training could potentially uti-\nlize other data sources for multilingual and\nmulti-task training.\nData Annotation The linguist uploads unanno-\ntated data, and the trained model proposes an-\nnotations for the linguist to accept or edit.\nAn example of an overall interface exposing this\nfunctionality for the currently implemented tasks\nof transcription and glossing is shown in Figure 1.\n3.2\nPhoneme Recognition\nThe automatic phoneme transcription component\nprovides an interactive online interface for users\nto manage speech recognition models and tran-\nscribe speech recordings. The speech recognition\nmodel can be any one of the user’s choosing as\nlong as it supports the API. In our current system,\nwe use Persephone (Adams et al., 2018) as our\ntranscription backend, which is designed for low-\nresource language transcription. Through the API,\nthe users can upload a batch of speech recordings\nalong with the corresponding transcriptions as the\ntraining data to train a transcription model tailored\nto the language and speakers of their interest. The\nsystem is equipped with some default model and\ntraining conﬁgurations so that the users are not re-\nquired to have expert knowledge of the transcrip-\ntion model and training. The model obtained from\neach training session will then be stored for later\nuse. Figures 2 to 4 show the work ﬂow of training\na transcription model.\nThe users can upload speech recordings they\nwant to transcribe to the interface, and perform the\nautomatic transcription using previously trained\nmodels (Figures 5 and 6). The interface shows the\ntranscription results to the users, and the users can\nFigure 3: Training a transcription model using the\ntraining data uploaded by the user.\nFigure 4: Training a transcription model using the\ntraining data uploaded by the user.\noptionally edit the transcription results to ﬁx errors\nor make model improvements (Figure 7). The re-\nﬁned transcriptions can then be downloaded by the\nusers. If the user’s data privacy preferences allow,\nthe system can also collect them along with the\noriginal speech recordings as extra training data to\nfurther ﬁne tune the model.\n3.3\nAutomatic Glossing\nThe interface also supports making glossing sug-\ngestions.\nGlosses are generated word-by-word\nwith Moses (Koehn et al., 2007), a statistical ma-\nchine translation system. The system takes par-\nallel data as input, which could be either the\nlanguage and translations, or the language and\nglosses. Using this parallel data, we learn a word\nalignment with a statistical model, speciﬁcally the\nIBM alignment models (Brown et al., 1993) as\nimplemented in GIZA++ (Och and Ney, 2003).\nThen we perform phrase extraction (Koehn, 2010),\nwhich gives us a translation probability distribu-\ntion for each word or phrase in the combined cor-\npus. We then display translations with high proba-\nbility as glossing suggestions. An example of how\nthe automatic glossing suggestion works on the in-\nterface can be seen in Fig. 8.\n4\nFuture Plans\nWorking with ﬁeld data is highly rewarding, but on\na moment-to-moment basis the work is not usually\nparticularly engaging; most of the individual deci-\nsion events that a linguist makes during ﬁeld cor-\npus creation do not fully engage their reasoning\ncapacity. Our goal is to maximize the effects of\nhuman engagement with data by maximizing the\ntime the linguist spends on interesting and relevant\nFigure 5: Uploading the speech recordings to tran-\nscribe.\nFigure 6: Transcribing the speech recordings using the\nmodel previously trained.\ndecisions. We intend to explore this question with\nrespect to both low-level decisions (“What word\nwas said here?”) and high-level decisions (“These\nutterances exemplify ergativity in this language;\nare there other examples in this corpus?”). Our\nfuture work towards this goal will take a three-\npronged approach: developing a general-purpose\nlinguistic annotation API and integrating it with\npopular annotation frameworks, developing new\nmethods to perform multi-lingual and multi-task\nlearning to train effective models even in a paucity\nof training data, and working with linguists to help\nreﬁne and prioritize our work in these areas. In\nparticular, for the third goal we are actively seek-\ning collaborators who would be interested in test-\ning and giving advice about the utility of the pro-\nposed approach.\nAcknowledgements\nWe thank Alexis Michaud for his useful comments\nand help in preparation of data, Oliver Adams\nfor his help with Persephone, and Antonis Anas-\ntasopoulos for helping us access and prepare the\nGriko data. This material is based upon work sup-\nported by the National Science Foundation under\nGrant No. 1761548.\nReferences\nOliver Adams, Trevor Cohn, Graham Neubig, Steven\nBird, and Alexis Michaud. 2018.\nEvaluating\nphonemic transcription of low-resource tonal lan-\nguages for language documentation. In Language\nResources and Evaluation Conference (LREC).,\nMiyazaki, Japan.\nAntonios Anastasopoulos, Marika Lekakou, Josep\nQuer, Eleni Zimianiti, Justin DeBenedetto, and\nDavid Chiang. 2018. Part-of-speech tagging on an\nendangered language: a parallel Griko-Italian re-\nsource. In Proc. COLING.\nPeter F. Brown,\nVincent J.Della Pietra,\nStephen\nA. Della Pietra, and Robert L. Mercer. 1993. The\nmathematics of statistical machine translation: Pa-\nrameter estimation.\nComputational Linguistics,\n19:263–312.\nRich Caruana. 1997.\nMultitask learning.\nMachine\nlearning, 28(1):41–75.\nHal Daume III and Lyle Campbell. 2007. A Bayesian\nmodel for discovering typological implications. In\nProc. ACL, pages 65–72. Association for Computa-\ntional Linguistics.\nSharon Goldwater, Thomas L. Grifﬁths, and Mark\nJohnson. 2009.\nA Bayesian framework for word\nsegmentation:\nExploring the effects of context.\nCognition, 112(1).\nLisa M Johnson, Marianna Di Paolo, and Adrian Bell.\n2018. Forced alignment for understudied language\nvarieties: Testing prosodylab-aligner with tongan\ndata. Language Documentation and Conservation.\nMelvin Johnson et al. 2016. Google’s multilingual neu-\nral machine translation system: Enabling zero-shot\ntranslation. arXiv preprint arXiv:1611.04558.\nPhilipp Koehn. 2010. Statistical Machine Translation.\nCambridge Press.\nPhilipp Koehn, Hieu Hoang, Alexandra Birch, Chris\nCallison-Burch, Marcello Federico, Nicola Bertoldi,\nBrooke Cowan,\nWade Shen,\nChristine Moran,\nRichard Zens, Chris Dyer, Ondrej Bojar, Alexandra\nConstantin, and Evan Herbst. 2007. Moses: Open\nsource toolkit for statistical machine translation. In\nProc. ACL, pages 177–180.\nAlexis Michaud, Oliver Adams, Trevor Anthony Cohn,\nGraham Neubig, and Sverine Guillaume. 2018. In-\ntegrating automatic transcription into the language\ndocumentation workﬂow: Experiments with na data\nand the persephone toolkit. Language Documenta-\ntion and Conservation.\nGraham Neubig and Junjie Hu. 2018. Rapid adaptation\nof neural machine translation to new languages. In\nProc. EMNLP, Brussels, Belgium.\nJoakim Nivre. 2005. Dependency grammar and depen-\ndency parsing. MSI report, 5133(1959):1–32.\nFranz Josef Och and Hermann Ney. 2003. A systematic\ncomparison of various statistical alignment models.\nComputational Linguistics, 29(1):19–51.\nFuchun Peng, Fangfang Feng, and Andrew McCallum.\n2004. Chinese segmentation and new word detec-\ntion using conditional random ﬁelds. In Proc. COL-\nING.\nJon D Riding. 2008. Statistical glossing, language in-\ndependent analysis in bible translation. Translating\nand the Computer, 30.\nFigure 7: The users can examine the transcription results and optionally edit the results to correct errors.\nFigure 8: An example of generated glosses, for Griko language data from Anastasopoulos et al. (2018).\nBurr Settles. 2009. Active learning literature survey.\nComputer Sciences 1648, University of Wisconsin–\nMadison.\nOscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszko-\nreit. 2012.\nCross-lingual word clusters for direct\ntransfer of linguistic structure.\nIn Proc. NAACL,\npages 477–487, Montr´eal, Canada. Association for\nComputational Linguistics.\nDavid Yarowsky and Richard Wicentowski. 2000.\nMinimally supervised morphological analysis by\nmultimodal alignment. In Proc. ACL.\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2018-12-13",
  "updated": "2018-12-13"
}