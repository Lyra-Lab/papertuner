{
  "id": "http://arxiv.org/abs/1812.05448v4",
  "title": "A First Look at Deep Learning Apps on Smartphones",
  "authors": [
    "Mengwei Xu",
    "Jiawei Liu",
    "Yuanqiang Liu",
    "Felix Xiaozhu Lin",
    "Yunxin Liu",
    "Xuanzhe Liu"
  ],
  "abstract": "We are in the dawn of deep learning explosion for smartphones. To bridge the\ngap between research and practice, we present the first empirical study on\n16,500 the most popular Android apps, demystifying how smartphone apps exploit\ndeep learning in the wild. To this end, we build a new static tool that\ndissects apps and analyzes their deep learning functions. Our study answers\nthreefold questions: what are the early adopter apps of deep learning, what do\nthey use deep learning for, and how do their deep learning models look like.\nOur study has strong implications for app developers, smartphone vendors, and\ndeep learning R\\&D. On one hand, our findings paint a promising picture of deep\nlearning for smartphones, showing the prosperity of mobile deep learning\nframeworks as well as the prosperity of apps building their cores atop deep\nlearning. On the other hand, our findings urge optimizations on deep learning\nmodels deployed on smartphones, the protection of these models, and validation\nof research ideas on these models.",
  "text": "A First Look at Deep Learning Apps on Smartphones\nMengwei Xu, Jiawei Liu, Yuanqiang Liu\nKey Lab of High-Confidence Software Technologies\n(Peking University), MoE, Beijing, China\n{mwx,1500012828,yuanqiangliu}@pku.edu.cn\nFelix Xiaozhu Lin\nPurdue ECE\nWest Lafayette, Indiana, USA\nxzl@purdue.edu\nYunxin Liu\nMicrosoft Research\nBeijing, China\nyunxin.liu@microsoft.com\nXuanzhe Liu\nKey Lab of High-Confidence Software Technologies\n(Peking University), MoE, Beijing, China\nxzl@pku.edu.cn\nABSTRACT\nWe are in the dawn of deep learning explosion for smartphones.\nTo bridge the gap between research and practice, we present the\nfirst empirical study on 16,500 the most popular Android apps,\ndemystifying how smartphone apps exploit deep learning in the\nwild. To this end, we build a new static tool that dissects apps and\nanalyzes their deep learning functions. Our study answers threefold\nquestions: what are the early adopter apps of deep learning, what do\nthey use deep learning for, and how do their deep learning models\nlook like. Our study has strong implications for app developers,\nsmartphone vendors, and deep learning R&D. On one hand, our\nfindings paint a promising picture of deep learning for smartphones,\nshowing the prosperity of mobile deep learning frameworks as well\nas the prosperity of apps building their cores atop deep learning. On\nthe other hand, our findings urge optimizations on deep learning\nmodels deployed on smartphones, protection of these models, and\nvalidation of research ideas on these models.\nKEYWORDS\nMobile Computing, Deep Learning, Empirical Study\n1\nINTRODUCTION\nBeing ubiquitous, smartphones are among the most promising\nplatforms for deep learning (DL), the key impetus towards mobile\nintelligence in recent years [3, 6, 8, 28]. Such a huge market is driven\nby continuous advances in DL, including the introduction of latest\nneural network (NN) hardware [48, 50, 62, 118], improvement in\nDL algorithms [58, 86, 91, 99], and increased penetration in huge\ninformation analytics [54, 59, 88, 90]. The research community has\nbuilt numerous DL-based novel apps [46, 74, 75, 85, 92, 117]. The\nindustry has also tried to utilize DL in their mobile products. For\nexample, in the newly released Android 9 Pie OS, Google introduces\na small feed-forward NN model to enable Smart Linkify, a useful\nAPI that adds clickable links when certain types of entities are\ndetected in text [39].\nYear 2017 marked the dawn of DL for smartphones. Almost si-\nmultaneously, most major vendors roll out their DL frameworks for\nsmartphones, or mobile DL framework for short. These frameworks\ninclude TensorFlow Lite (TFLite) from Google [38] (Nov. 2017),\nXuanzhe Liu is the paper’s corresponding author.\nWWW’19, May 2019, San Francisco, USA\n2019. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\nCaffe2 from Facebook [9] (Apr. 2017), Core ML from Apple [12]\n(Jun. 2017), ncnn from Tencent [36] (Jul. 2017), and MDL from\nBaidu [25] (Sep. 2017). These frameworks share the same goal: exe-\ncuting DL inference solely on smartphones. Compared to offloading\nDL inference from smartphones to the cloud [2, 20, 22], on-device\nDL inference better protects user privacy, continues to operate in\nthe face of poor Internet connectivity, and relieves app authors\nfrom paying the expense of running DL in the cloud [48, 69, 72, 73,\n73, 75, 80, 114, 118].\nFollowing the DL framework explosion, there emerges the first\nwave of smartphone apps that embrace DL techniques. We deem\nit crucial to understand these apps and in particular how they use\nDL, because history has proven that such early adopters heavily\ninfluence or even decide the evolution of new technologies [95] –\nsmartphone DL in our case.\nTo this end, we present the first empirical study on how real-\nworld Android apps exploit DL techniques. Our study seeks to\nanswer threefold questions: what are the characteristics of apps\nthat have adopted DL, what do they use DL for, and what are their\nDL models. Essentially, our study aims findings on how DL is being\nused by smartphone apps in the wild and the entailed implications,\nfilling an important gap between mobile DL research and practice.\nFor the study, we have examined a large set of Android apps\nfrom the official Google Play market. We take two snapshots of the\napp market in early Jun. 2018 and early Sep. 2018 (3 months apart),\nrespectively. Each snapshot consists of 16,500 the most popular apps\ncovering 33 different categories listed on Google Play. We generate\ninsights by inspecting individual apps as well as by comparing the\ntwo snapshots. To automate the analysis of numerous Android apps,\nwe build a new analyzer that inspects app installation packages,\nidentifies the apps that use DL (dubbed “DL apps”), and extracts DL\nmodels from these apps for inspection. To realize such a tool, we\neschew from looking for specific code pattern and instead identify\nthe usage of known DL frameworks, based on a rationale that most\nDL apps are developed atop DL frameworks.\nOur key findings are summarized as follows.\nEarly adopters are top apps (§4.2) We have found 211 DL apps in\nthe set of apps collected in Sep. 2018. Only 1.3% of all the apps, these\nDL apps collectively contribute 11.9% of total downloads of all the\napps and 10.5% of total reviews. In the month of Sep. 2018, the 221\nDL apps are downloaded for around 13,000,000 times and receive\n9,600,000 reviews. DL apps grow fast, showing a 27% increase in\ntheir numbers over the 3 months in our study.\narXiv:1812.05448v4  [cs.LG]  13 Jan 2021\nWWW’19, May 2019, San Francisco, USA\nMengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and Xuanzhe Liu\nDL is used as core building blocks (§4.3) We find that 81% DL\napps use DL to support their core functionalities. That is, these apps\nwould fail to operate without their use of DL. The number of such\nDL apps grow by 23% over the period of 3 months.\nPhoto beauty is the top use (§4.3) DL is known for its diverse\napplications, as confirmed by the usage discovered by us, e.g. emoji\nprediction and speech recognition. Among them, photo beauty is\nthe most popular use case: 94 (44.5%) DL apps use DL for photo\nbeauty; 61 (29%) DL apps come from the photography category.\nMobile DL frameworks are gaining traction (§4.4) While full-\nfledged DL frameworks such as TensorFlow are still popular among\nDL apps due to their momentum, DL frameworks designed and\noptimized for constrained resources are increasingly popular. For\ninstance, the number of DL apps using TFLite has grown by 258%\nover the period of 3 months.\nMost DL models miss obvious optimizations. (§5.2) Despite\nwell-known optimizations, e.g. quantization which can reduce DL\ncost by up to two orders of magnitude with little accuracy loss [63],\nwe find only 6% of DL models coming with such optimizations.\nOn-device DL is lighter than one may expect. (§5.3) Despite\nthe common belief that the power of DL models comes from rich\nparameters and deep layers, we find that DL models used in apps are\nvery small, with median memory usage of 2.47 MB and inference\ncomputation of 10M FLOPs, which typically incurs inference delay\nof tens of milliseconds. These models are not only much lighter\nthan full models for servers (e.g. ResNet-50 with 200 MB memory\nand 4G FLOPs inference computations) but also lighter than well-\nknown models specifically crafted for smartphones, e.g. MobileNet\nwith 54 MB memory and 500M FLOPs inference computations.\nDL models are poorly protected. (§5.4) We find only 39.2% dis-\ncovered models are obfuscated and 19.2% models are encrypted.\nThe remaining models are trivial to extract and therefore subject\nto unauthorized reuse.\nSummary of implications: Overall, our findings paint a promis-\ning picture of DL on smartphones, motivating future research and\ndevelopment. Specifically, the findings show strong implications\nfor multiple stakeholders of the mobile DL ecosystem. To app de-\nvelopers: our findings show that DL can be very affordable on\nsmartphones; developers, especially individuals or small compa-\nnies, should have more confidence in deploying DL in their apps;\ninterested developers should consider building DL capability atop\nmobile DL frameworks; a few app categories, notably photography,\nare most likely to benefit from DL techniques. To DL framework\ndevelopers: our findings encourage continuous development of\nframeworks optimized for smartphones; our findings also show\nthe urgent need for model protection as the first-class concern of\nframeworks. To hardware designers: our findings motivate DL\naccelerator designs to give priority to the layers popular among\nmobile DL models. To DL researchers: our findings suggest that\nnew proposal for optimizing DL inference should be validated on\nlightweight models that see extensive deployment on smartphones\nin the wild.\nIn summary, our contributions are as follows.\n• We design and implement a tool for analyzing the DL adop-\ntion in Android apps. Capable of identifying the DL usage\nin Android apps and extracting the corresponding DL mod-\nels for inspection, our tool enables automatic analysis of\nnumerous apps for DL.\n• We carry out the first large-scale study of 16,500 Android\napps for their DL adoption. Through the empirical analysis,\nwe contribute new findings on the first wave of apps that\nadopt DL techniques. In the dawn of DL explosion for smart-\nphones, our findings generate valuable implications to key\nstakeholders of the mobile ecosystem and shed light on the\nevolution of DL for smartphones. We plan to publicize our\ntools and datasets.\nThe remainder of the paper is organized as follows. We describe\nthe background knowledge and our motivations in Section 2. We\npresent our research goal and the analyzing tool which helps us\nidentify DL usage and extract DL models in Section 3. We present\nthe analysis results of DL apps and DL models in Section 4 and\nSection 5, respectively. We discuss the limitations and possible\nfuture work in Section 6. We survey the related work in Section 7,\nand conclude in Section 8.\n2\nBACKGROUND\nDL models and frameworks DL has revolutionized many AI\ntasks, notably computer vision and natural language processing,\nthrough substantial boosts in algorithm accuracy. In practice, DL\nalgorithms are deployed as two primary parts. The first one is\nDL models, which often comprise neuron layers of various types,\ne.g. convolution layers, pooling layers, and fully-connected lay-\ners. Based on the constituting layers and their organizations, DL\nmodels fall into different categories, e.g., Convolutional Neural Net-\nwork (CNN) containing convolution layers, and Recurrent Neural\nNetwork (RNN) processing sequential inputs with their recurrent\nsub-architectures. The second part is DL frameworks that produce\nDL models (i.e. training) and execute the models over input data\n(i.e. inference). Since a production DL framework often entails\ntremendous engineering efforts, most app developers tend to ex-\nploit existing frameworks by major vendors, such as TensorFlow\nfrom Google.\nDeploying mobile DL As training models is intensive in both\ndata and computing [79], smartphone developers often count on\ncloud servers for modeling training offline prior to app deployment.\nAt app installation time, the trained models are deployed as part of\nthe app installation package. At runtime, apps perform inference\nwith the trained models by invoking DL frameworks, and therefore\nexecute AI tasks such as face recognition and language translation.\nInference: on-cloud vs. on-device Towards enabling DL on\nsmartphones, model inference can be either offloaded to the cloud\nor executed solely on smartphones. Offloading to the cloud is a\nclassical use case of Software-as-a-Service (SaaS), and has been well\nstudied in prior work [44, 67, 94, 116]. The mobile devices upload\ndata and retrieve the inference results, transparently leveraging\nrich data center resources as server-class GPU. Yet, we have ob-\nserved on-device DL inference is quickly gaining popularity due\nto its unique advantages of stronger privacy protection, resilience\nagainst poor Internet connectivity, and lower cloud cost to app de-\nvelopers. We will present more evidence in the paper. In this work,\nA First Look at Deep Learning Apps on Smartphones\nWWW’19, May 2019, San Francisco, USA\nwe focus our empirical study on such on-device deep learning for\nsmartphones.\n3\nGOAL AND METHODOLOGY\n3.1\nResearch Goal\nThe goal of our study is to demystify how smartphone apps\nexploit DL techniques in the wild. Our study focuses on two types\nof subjects: i) smartphone apps that embrace DL and ii) the DL\nframeworks and models used in practice. Accordingly, we charac-\nterize the apps, the frameworks, and the models. We will present\nthe results in Section 4 and Section 5 respectively.\nScope We focus our analysis on Android apps, as Android rep-\nresents a dominant portion of smartphone shipment (88% in the\nsecond quarter of 2018) and hence serves a good proxy for the entire\nsmartphone app population [19].\nDatasets We retrieve from the Google Play store the full dataset\nused in this work. We select 16,500 apps in total, which consist of\nthe top 500 free apps with most downloads from each of the 33\ncategories defined by Google Play1. We have crawled two datasets at\ndifferent moments, June 2018 and September 2018, which are three\nmonths apart. The two app datasets have more than 2/3 overlapped\napps. For each app, we download its apk file and crawl its meta\ninformation (e.g. app description and user rating) from the Google\nPlay web page for analysis. Our analysis primarily focuses on the\nnewer dataset, i.e., Sep. 2018, and the difference between the two\ndata sets, unless specified otherwise.\n3.2\nWorkflow Overview\nWe design and implement an analyzing tool to enable our re-\nsearch goal on large-scale Android apps. The tool runs in a semiau-\ntomatic way, as illustrated in Figure 1.\nThe very first step of the analyzing tool is identifying DL apps\namong a given set of Android apps as input. This is achieved via the\nmodule named DL Sniffer. The core idea of DL Sniffer, is detecting\nthe usage of popular DL frameworks, instead of directly finding\nthe usage of DL. After identifying DL apps, it performs analysis\non those apps. During analysis, we use the manifest files extracted\nfrom DL apps via tool aapt [4] and the meta information crawled\nfrom the corresponding Google Play web page. The manifest files\ninclude information such as package name, app version, required\npermissions, etc. The web pages include information such as app\ndescription, user rating, app developer, etc.\nThe analyzing tool further extracts DL models from those DL\napps. This extraction is achieved via a module called Model Ex-\ntractor. After extracting DL models, it performs analysis on them.\nHowever, we here face the challenge that the models are mostly\nin different formats. Though developers are investing substantial\nefforts in integrating different model formats, such as designing\na standardized one [26], the ecosystem of DL frameworks is still\nbroken and fragmented nowadays. Thus, when looking into the\ninternal structures of DL models, we substantially leverage the\navailable tools and source of different frameworks. Fortunately,\n1Different app categories on Google Play can be visited via url https://play.google.\ncom/store/apps/category/XXX, where XXX can be GAME or other category names.\nmost of the frameworks we investigated (details in Table 2) are\nopen-source and well-documented.\nWe discuss more details of DL Sniffer and Model Extractor in\nSection 4.1 and Section 5.1, respectively.\n4\nAPPLICATION ANALYSIS\nThis section presents our analysis of smartphone DL apps. We\nfirst describe our methodology in Section 4.1 and then the following\nthree major aspects of the DL apps:\n• The characteristics of DL apps (§4.2): their popularity, their dif-\nference from non-DL apps, and their developers.\n• The role of DL (§4.3): the popular usage of DL in apps, the cat-\negories of DL apps, and evidence that DL is already used as core\nbuilding blocks of apps.\n• An analysis of DL frameworks (§4.4): which frameworks are used,\nthe cost, and their adoption trend over time.\n4.1\nMethodology: finding DL apps\nAs a part of our analyzing tool (Section 3.2), DL Sniffer takes\napk file(s) as input, and outputs which of them use DL technique.\nDetecting DL usage is difficult, instead DL Sniffer mainly detects the\nusage of popular DL frameworks with Android support. Currently,\nDL Sniffer supports the detection of 16 popular DL frameworks,\nincluding TensorFlow, Caffe, TFLite, etc, and the details of those\nframeworks will be presented later in Section 4.4 & Table 2. DL\nSniffer uses two ways to mine the usage of DL frameworks: (1) For\nthose who provide native C++ APIs, DL Sniffer first decomposes\nthe apk files via Apktool [5], and extracts the native shared libraries\n(with suffix “.so”). DL Sniffer then searches for specific strings on the\nrodata section of those libraries. Those strings can be regarded as\nidentifications of corresponding frameworks, and are pre-defined\nby us. For example, we notice that the shared libraries that use\nTensorFlow always have “TF_AllocateTensor” in its rodata section.\n(2) For those who only support Java APIs, DL Sniffer first converts\nthe apk file into smali code via dex2jar [14]. The smali code, which\nis a disassembled version of the DEX binary used by Android’s\nDavik VM, enables us to carry out static program analysis. DL\nSniffer statically goes through the class/method names of smali\ncode and checks whether certain APIs exist. For example, the class\nMultiLayerConfiguration is used in almost every app that embeds\nDeepLearning4J framework.\nBesides detecting the usage of DL frameworks, we also try to\nidentify DL apps that don’t use the frameworks listed in Table 2\n(called “no lib” in this work). Similarly, this is achieved by searching\nspecific strings on the rodata section of native libraries as men-\ntioned above, but the strings we use here are pre-defined such as\n“neural network”, “convolution”, “lstm”, etc, rather than extracted\nfrom existing frameworks. We then manually check the detection\ncorrectness through reverse engineering, filtering those don’t really\nhave DL usage (false positive). This manual check is also performed\non other DL apps detected using the aforementioned approach, to\nensure good accuracy in DL identification.\nWWW’19, May 2019, San Francisco, USA\nMengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and Xuanzhe Liu\nmanif-\nest file\nDL Sniffer\nsmali\ncode\nnative\nlib\napktool\ndex2jar\naapt\nlib\nscanner\nsmali\nanalyzer\nhas\nDL?\nApplication\nAnalysis\nModel\nAnalysis\nmeta\ninfo\ncrawler\nModel Extractor\nresearchers\nreverse\nengineer\nmodel\nscanner\nmodel\nvalidator\nDL Models\nfull app\ndataset\nDL app\ndataset\nFigure 1: The overall workflow of our analyzing tool.\n4.2\nCharacteristics of DL apps\n• Is DL gaining popularity on smartphones? Our study shows:\nover our investigation period (June 2018 – Sept. 2018), the total\nnumber of DL apps has increased by 27.1%, from 166 to 211. We\nfurther investigate the new downloads and reviews of DL apps\nwithin one month of Sept. 2018: in that period, the 221 DL apps are\ndownloaded for around 13,000,000 times and receive 9,600,000 new\nreviews. The results indicate a substantial amount of smartphones\nare running DL apps nowadays.\n• How are DL apps different from non-DL apps? We investi-\ngate the following three aspects with results illustrated in Figure 2.\nDownloads and Reviews are representative of apps’ popularity.\nAs observed, the median number of downloads and reviews of\nDL apps are 5,000,000 and 41,074 respectively, much larger than\nnon-DL apps, i.e., 100,000 and 1,036 respectively. We also count\nthe download rankings of each DL apps within the corresponding\ncategory. The median number of such ranking is 89 among total\n500 apps for each category. We deem the above statistics as strong\nevidences that top apps are early adopters in deploying DL in mobile\napps. Such phenomenon can be explained that making DL work\nin the wild, though appealing, takes a lot of engineering efforts.\nThe cycle of developing DL functionality on smartphones includes\nmodel construction, data collection, model training, offline/online\ntesting, etc. Thus, many small companies or individual developers\nlack the resources to exploit DL on their apps.\nRatings show how much appreciation users give to apps. The\nFigure shows that DL apps and non-DL apps have similar ratings\nfrom users, with the same median number 4.3.\nApp size: as shown in Figure 2, DL apps have much larger apk\nfiles than non-DL apps (median number: 35.5MB vs 12.1MB). This\nis reasonable since having DL not only adds DL frameworks and\nmodels to the apps, it also confidently indicates that the apps have\nmuch richer features.\n• Who are the developers of DL apps? We also study the de-\nvelopers of DL apps. The results show that the identified 211 DL\napps belong to 172 developers (companies), among which 27 de-\nvelopers have more than one DL apps. The developers with most\nDL apps are “Google LLC” (10) and “Fotoable,Inc” (6). We observe\nmany big companies own more than one DL apps, including Google,\nDL apps\nnon-DL apps\n(a) download\n0\n2\n4\n6\n8\n10\nMillion Downloads\nDL apps\nnon-DL apps\n(b) review\n0\n10000\n20000\n30000\n40000\n50000\n# of Reviews\nDL apps\nnon-DL apps\n(c) rating\n3.0\n3.5\n4.0\n4.5\n5.0\nRatings\nDL apps\nnon-DL apps\n(d) app size\n0\n20\n40\n60\n80\nApp Size (MB)\nFigure 2: Comparisons between DL apps and non-DL apps on\nvarious aspects (a)–(d). Each box shows the 75th percentile,\nmedian, and 25th percentile from top to bottom. We manu-\nally set the y-axis limits for better presentation in (b): the\nmissed out 75th percentile of DL apps is 324,044.\nAdobe, Facebook, Kakao, Meitu, etc. This suggests that those big\ncompanies are pioneers in adopting DL into their products. We also\nnotice that the DL apps from same developer often have identical\nDL frameworks. For example, four products from Fotoable Inc use\nthe exactly same native library called libncnn_style.0.2.so to support\nDL technique. This is because that DL frameworks and even the\nDL models are easily reusable: a good nature of DL technique that\ncan help reduce the engineering efforts of developers.\nA First Look at Deep Learning Apps on Smartphones\nWWW’19, May 2019, San Francisco, USA\nusage\ndetailed usage\nas core feature\nphoto beauty: 97\n94 (96.9%)\nface detection: 52\n44 (84.6%)\naugmented reality: 19\n5 (26.3%)\nface identification: 8\n7 (87.5%)\nimage classification: 11\n6 (54.5%)\nobject recognition: 10\n9 (90%)\nimage: 149\ntext recognition:11\n4 (36.3%)\nword&emoji prediction: 15\n15 (100%)\nauto-correct: 10\n10 (100%)\ntranslation: 7\n3 (42.8%)\ntext classification: 4\n2 (50%)\ntext:26\nsmart reply: 2\n0 (0%)\nspeech recognition: 18\n7 (38.9%)\naudio: 24\nsound recognition: 8\n8 (100%)\nrecommendation: 11\n2 (18.1%)\nmovement tracking: 9\n4 (44.4%)\nsimulation: 4\n4 (100%)\nabnormal detection: 4\n4 (100%)\nvideo segment: 2\n1 (50%)\nother: 19\naction detection: 2\n0 (0%)\ntotal: 211\n171 (81.0%)\nTable 1: The DL usage in different apps. Note: as one app may\nhave multiple DL uses, the sum of detailed usage (column 2)\nmight exceed the corresponding coarse usage (column 1).\nImplications: The popularity of DL among top smartphone apps,\nespecially ones developed by big companies, should endow smaller\ncompanies or independent developers with strong confidence in de-\nploying DL in their apps.\n4.3\nThe roles of DL in apps\n• What are the popular uses of DL? To understand the roles\nplayed by DL, we manually classify the usage of DL on different\napps. This is achieved by looking into the app description and app\ncontents. The results are shown in Table 1. Each app has one or\nmore usages, and the usage is represented in two different levels\n(coarse and detailed). 10 apps are left out since we cannot confirm\ntheir DL usage.\nOverall, image processing is the most popular usage of DL on\nsmartphones, far more than text and audio processing (149 vs. 26 &\n24). This is not surprising since computer vision is the field where\nDL starts the revolution [70], and the progress on this field has\nbeen lasting since then [78]. In more details, photo beauty (97)\nand face detection (52) are mostly widely used in DL apps, usually\nfound in photo editing and camera apps to beautify pictures. In text\nfield, word & emoji prediction (15) and auto-correct (10) are also\npopular, usually found in input method apps like GBoard. For audio\nprocessing, DL is mainly used for speech recognition (14). Besides,\nthere are other types of usage such as recommendation (11) which\nis often found in shopping apps.\n• Which categories do DL apps come from? Figure 3 summa-\nrizes the number of DL apps in different categories. As observed,\nalmost 29% DL apps (61 out of 211) are in category photograph, all\nof which use DL for image processing. Social category is another\n0% \n20% \n40% \n60% \n80% \n100% \nPhotograph\nSocial\nVideo_Players\nProductivity\nLibraries\nCommunications\nFinance\nEntertainment\nPersonalization\nShopping\nSports\nimage\ntext\naudio\nother\n61\n23\n14\n13\n10\n10\n8\n7\n6\n6\n6\nFigure 3: Distributions of DL apps over categories defined by\nGoogle Play. Numbers on top: the counts of DL apps in the\ncorresponding categories. Apps in each category are further\nbroken down by DL usage (see Table 1 for description). Cat-\negories with fewer than 5 DL apps are not shown.\nhotspot with 23 DL apps in total, 78% of which use DL for image\nprocessing while others use it for text, audio, etc. The category\nof productivity also contains 13 DL apps, but most of them (62%)\nuse DL for text processing. Overall, we can see that the DL us-\nage is somehow diverse, with 11 categories has more than 5 DL\napps among the top 500. Such diversity gives credits to the good\ngenerality of DL technique.\nImplications: Our findings encourage developers of certain types\nof apps, notably the ones with photo beauty, to embrace DL. Our\nfindings also motivate encapsulating DL algorithms within higher\nlevel abstractions that cater to popular uses in apps. For instance,\ncompanies such as SenseTime already starts to ship DL-based face\ndetection libraries to app developers. Masking the details of DL models\nand frameworks, such abstractions would make DL more friendly to\ndevelopers.\n• Is DL a core building block? We also manually tag each DL\nusage as core feature or not. We define the DL functionality as apps’\ncore feature if and only if two conditions are satisfied: (1) hot: the\nDL functionality is very likely to be invoked every time the apps are\nopened and used by users, (2) essential: without the DL functionality,\nthe apps’ main functionality will be severely compromised or even\nbecome infeasible. For example, DL on text recognition is treated as\ncore feature in a scanner app (Adobe Scan) that helps users translate\nan image into text, but not in a payment app (Alipay) that uses it\nto scan ID card for identification. Similarly, DL on photo beauty is\ntreated as core feature in a camera app (Meitu), but not in a social\napp (Facebook Messenger Kids).\nOverall, 171 out of 211 (81%) apps use DL to support core features.\nSpecifically, since photo beauty (96.9%) and face detection (84.6%)\nare primarily used in photo & camera apps, their usage is essen-\ntial. Similarly, word & emoji prediction (100%) and auto-correct\n(100%) are treated as core features in keyboard apps, helping users\ninput more efficiently and accurately. However, recommendation\n(18.1%) is often provided as complementary feature to others such\nas shopping apps, thus not treated as core feature.\nWWW’19, May 2019, San Francisco, USA\nMengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and Xuanzhe Liu\n51\n26\n22\n28\n31\n12\n25\n34\n47\n25\n22\n21\n12\n10\n15\n25\n0\n10\n20\n30\n40\n50\n60\nTOTAL\nTensorFlow\nCaffe\nParrots\nncnn\nTFLite\nCaffe2\nother lib\nno lib\nNumber of DL apps\nJun. 2018\nSep. 2018\n166\n211\nFigure 4: Numbers of DL apps using various mobile DL\nframeworks. “other lib”: the DL apps developed on the\nframeworks in Table 2 but not itemized here, e.g. mace, SNPE,\nand xnn. “no lib”: apps with DL functions but using no DL\nframeworks from Table 2. Note that the number in “TOTAL”\nis lower than the sum of others since some DL apps have in-\ntegrated multiple frameworks.\nImplications: Our findings support future investment on R&D of\nmobile DL, as core user experience on smartphones will likely depend\non DL performance [73] and security [89, 102].\n4.4\nDL frameworks\nAs mentioned in Section 2, DL frameworks are critical to DL\nadoption, as most developers use those frameworks to build their DL\napps. In this subsection, we investigate into how those frameworks\nare used in DL apps: the numbers, the sizes, the practice, etc.\n• A glance over popular DL frameworks We first make an in-\nvestigation into popular DL frameworks, and the results are summa-\nrized in Table 2. We select those 21 frameworks for their popularity,\ne.g., forks and stars on GitHub, gained attention on StackOver-\nflow and other Internet channels. Among those 21 frameworks, 16\nframeworks support Android platform via Java (official language on\nAndroid) and/or C++ (native support via cross-compilation). Most\nof them are open-source, while others are either provided to public\nas a binary SDK (SNPE, CoreML), or only accessible by the providers’\n(collaborators’) own products (xNN, Parrots). Most of them use cus-\ntomized format to store and represent the model files, but some\nleverage existing approaches, such as ProtoBuf [29]. We also no-\ntice a trend on lightweight DL inference frameworks, which are\ndesigned specifically for mobile apps but have no training-support\nback-end (ncnn, FeatherCNN, MACE, etc). Those frameworks can-\nnot train DL models, but can predict with pre-trained models via\nother frameworks such as TensorFlow or Caffe. Note that our later\nanalysis substantially relies on the openness of DL frameworks:\nit enables us to use the existing tools to analyze or even visualize\n147\n142\n48\nJun. 2018\nSep. 2018\nCheck-out (5)\nCheck-in\nFigure 5: The number of check-in and check-out DL apps.\nthe DL models such as TensorFlow, or build our own interpreting\nscripts to analyze them based on the open code such as ncnn.\n• What is the adoption of DL frameworks? As summarized in\nFigure 4, the most popular DL frameworks used in Sep. 2018 are\nTensorFlow (51), TFLite (31), and ncnn (28), as they contribute to\nalmost 50% of the total number of DL apps. Other popular frame-\nworks include Caffe, Parrots, and Caffe2. We have made several\nobservations from those 6 dominant frameworks as following.\n(1) All these frameworks are developed by big companies (e.g.\nGoogle), AI unicorns (e.g. SenseTime), or renowned universities\n(e.g. Berkeley).\n(2) 5 out of these 6 frameworks are open-source, except Parrots\nwhich is provided as SDK to consumers. In fact, it is believed that\nopenness is already an important feature in machine learning, es-\npecially DL society, as it supposes to [101]. It helps developers\nreproduce the state-of-the-art scientific algorithms, customize for\npersonal usage, etc. As a result, for example, TensorFlow has more\nthan 1,670 contributors up to Oct. 2018, going far beyond the com-\nmunity of Google.\n(3) Most (4 out of 6) frameworks are optimized for smartphones,\nexcept Caffe and TensorFlow. Those mobile DL frameworks are\ndesigned and developed specifically for mobile devices, usually\nwithout training back-end, so that the resulted libraries can be\nfaster and more lightweight. As an example, TFLite stems from Ten-\nsorFlow, but is designed for edge devices and reported to have lower\ninference time and smaller library size than TensorFlow [121]. Be-\nsides those popular frameworks, we identify 34 (16.1%) DL apps that\ndon’t use any framework in Table 2. These apps use self-developed\nengines to support DL functionality.\n• Are mobile DL frameworks gaining traction? As shown in\nFigure 4, DL frameworks optimized for smartphones, such as TFLite\nand ncnn, quickly gain popularity: the number of TFLite-based DL\napps has increased from 12 to 31; that of ncnn increases from 21\nto 28. We deem it as the trend of mobile DL ecosystem: To train a\nmodel offline, use large, mature, and generic frameworks that focus\non developer friendliness and feature completeness. To deploy a model\non edge devices, switch to mobile-oriented frameworks that focus on\nperformance (inference latency, memory footprint, and library size).\nWe also investigate into the DL check-in and check-out behavior\nin mobile apps. We define the check-in DL apps as those that have\nno DL usage in earlier version (Jun. 2018) but add the DL usage\nin newer version (Sep. 2018), and the check-out vice versa. Note\nthat the app list of our two datasets are not identical since we\ncrawl the most popular ones, but the popularity is changing. So\nwe only consider the apps that exist in both lists (11,710 in total),\nand conclude the results in Figure 5. As observed, 48 out of the 190\n(25.3%) DL apps in newer version are checked in between Jun. 2018\nA First Look at Deep Learning Apps on Smartphones\nWWW’19, May 2019, San Francisco, USA\nFramework\nOwner\nSupported Mobile Platform\nMobile API\nIs Open-\nsource\nSupported Model\nFormat\nSupport\nTraining\nTensorFlow [37]\nGoogle\nAndroid CPU, iOS CPU\nJava, C++\n✓\nProtoBuf (.pb, .pbtxt)\n✓\nTF Lite [38]\nGoogle\nAndroid CPU, iOS CPU\nJava, C++\n✓\nFlatBuffers (.tflite)\n✗\nCaffe [71]\nBerkeley\nAndroid CPU, iOS CPU\nC++\n✓\ncustomized, json\n(.caffemodel, .prototxt)\n✓\nCaffe2 [9]\nFacebook\nAndroid CPU, iOS CPU\nC++\n✓\nProtoBuf (.pb)\n✓\nMxNet [49]\nApache Incubator\nAndroid CPU, iOS CPU\nC++\n✓\ncustomized, json (.json,\n.params)\n✓\nDeepLearning4J [13]\nSkymind\nAndroid CPU\nJava\n✓\ncustomized (.zip)\n✓\nncnn [36]\nTencent\nAndroid CPU, iOS CPU\nC++\n✓\ncustomized (.params, .bin)\n✗\nOpenCV [27]\nOpenCV Team\nAndroid CPU, iOS CPU\nC++\n✓\nTesnorFlow, Caffe, etc\n✗\nFeatherCNN [17]\nTencent\nAndroid CPU, iOS CPU\nC++\n✓\ncustomized (.feathermodel)\n✗\nPaddlePaddle [25]\nBaidu\nAndroid CPU, iOS CPU & GPU\nC++\n✓\ncustomized (.tar)\n✓\nxNN [41]\nAlibaba\nAndroid CPU, iOS CPU\nunknown\n✗\nunknown\nunknown\nsuperid [35]\nSuperID\nAndroid CPU, iOS CPU\nunknown\n✗\nunknown\nunknown\nParrots [31]\nSenseTime\nAndroid CPU, iOS CPU\nunknown\n✗\nunknown\nunknown\nMACE [24]\nXiaoMi\nAndroid CPU, GPU, DSP\nC++\n✓\ncustomized (.pb, .yml, .a)\n✗\nSNPE [32]\nQualcomm\nQualcomm CPU, GPU, DSP\nJava, C++\n✗\ncustomized (.dlc)\n✗\nCNNDroid [76]\nOskouei et al.\nAndroid CPU & GPU\nJava\n✓\nMessagePack (.model)\n✗\nCoreML [12]\nApple\niOS CPU, GPU\nSwift, OC\n✗\ncustomized, ProtoBuf\n(.proto, .mlmodel)\n✓\nChainer [10]\nPreferred Networks\n/\n/\n✓\ncustomized\n(.chainermodel)\n✓\nCNTK [23]\nMicrosoft\n/\n/\n✓\nProtoBuf (.proto)\n✓\nTorch [40]\nFacebook\n/\n/\n✓\ncustomized (.dat)\n✓\nPyTorch [30]\nFacebook\n/\n/\n✓\ncustomized, pickle (.pkl)\n✓\nTable 2: An overview of popular deep learning frameworks and their smartphone support at the time of writing (Nov. 2018).\nand Sep. 2018. We also notice that some DL apps in old version\nchecked out, but the number is much smaller (5). The reasons of\ncheck-out can be that the developers remove the corresponding\nfunctionality or just replace the DL with other approaches. Overall,\nthe statistics support the fact that DL technique is increasingly\nadopted in mobile apps.\n• What is the storage overhead of frameworks? Figure 6 shows\nthe sizes of DL libs, i.e. the physical incarnation of DL frameworks.\nAs shown, the average size of DL libs is 7.5MB, almost 6 times\ncompared to the non-DL libs. Here, we only use the non-DL libs\nfound within DL apps. The results show that DL libs are commonly\nheavier than non-DL libs, because implementing DL functionality,\neven without training backend, is quite complex. Looking into\ndifferent frameworks, using TensorFlow and Caffe results in larger\nDL libs, i.e., 15.3MB and 10.1MB respectively, while others are all\nlower than 5MB. The reason is that mobile supports of TensorFlow\nand Caffe are ported from the original frameworks and substantially\nreuse the code base from them. However, these two frameworks\nare designed for distributed on-cloud DL. As comparison, other\nframeworks in Figure 6 are specifically designed for mobile devices\nto the purpose of good performance.\nOne app may incorporate multiple DL frameworks. Surpris-\ningly, we find that 24 DL apps embed more than one DL frameworks.\nFor example, AliPay, the most popular payment app in China, has\nboth xnn and ncnn inside. We deem such multi-usage as (poten-\ntially) bad practice, since it unnecessarily increases the apk size\nand memory footprint when these frameworks need to be loaded\n15.3\n10.1\n4.7\n2.5\n2.1\n4.1\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\nTF\nCaffe\nParrots\nncnn\nTFLite\nCaffe2\nDL-lib Size (MB)\nDL-libs Average: 7.5\nnon-DL-libs Average: 1.3\nFigure 6: The binary library sizes of DL frameworks.\nsimultaneously. According to our statistics, the overhead is around\n5.4MB, contributing to 13.6% to the total apk size on average. Such\noverhead can be avoided by running different tasks based on one\nframework, since most DL frameworks are quite generic and can\nsupport various types of DL models. Even if not, they can be eas-\nily extended to support the missing features [1]. The reason of\nsuch multi-usage behavior can be twofold. First, one app might be\ndeveloped by different engineers (groups), who introduce differ-\nent frameworks for their own DL purpose. Second, the developers\nmay just reuse existing code and models for specific tasks, without\nmerging them together in one DL implementation.\nImplications: Our findings highlight the advantages and popularity\nof mobile DL frameworks, encouraging further optimizations on them.\nOur findings also motivate app developers to give these frameworks\npriority considerations in choosing the incarnation of DL algorithms.\nWWW’19, May 2019, San Francisco, USA\nMengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and Xuanzhe Liu\nLayer\ntype\n% of\nmodels\n# in each\nmodel\nLayer\ntype\n% of\nmodels\n# in each\nmodels\nconv\n87.7\n5 / 14.8\nrelu\n51.0\n6 / 16.3\npooling\n76.5\n2 / 2.8\nsplit\n46.9\n1 / 7.5\nsoftmax\n69.1\n1 / 1.1\nprelu\n32.1\n4 / 4.6\nfc\n60.5\n3 / 5.6\nreshape\n28.4\n2 / 24.1\nadd\n56.8\n9.5 / 23.8\ndropout\n21.0\n1 / 1.0\nTable 3: Layers used in DL models. “% of models” shows how\nmany models contain such layer, while “# in each model”\nshows the median/mean numbers of occurrences in each\nmodel that contains such layer. “conv” and “fc” are short for\nconvolution and fully-connect.\n5\nMODEL ANALYSIS\nThis section focuses on the model-level analysis of DL technique.\nWe first describe the methodology details, e.g., the design of Model\nExtractor in Section 5.1. Then, we show the analysis results on\nthose DL models from three main aspects.\n• The structures of DL models: the model types, layer types,\nand optimizations used (Section 5.2).\n• The resource footprint of DL models: storage, memory, exe-\ncution complexity, etc (Section 5.3).\n• The security of DL models: using obfuscation and encryption\nto protect models from being stolen (Section 5.4).\n5.1\nModel Extractor: finding DL models\nAs a part of our analyzing tool (Section 3.2), Model Extractor\ntakes DL apps which we have already identified as input, and out-\nputs the DL model(s) used in each app. Model Extractor scans the\nassets folder of each decomposed DL apps, tries to validate each\nmodel file inside. Since DL frameworks use different formats to\nstore their model files, Model Extractor has a validator for each of\nsupported framework. However, we observe that many models are\nnot stored as plaintext inside apk files. For example, some of them\nare encrypted on storage, and decrypted when apps running on\ndevices. For such cases, Model Extractor tries to reverse engineer\nthe apps, and extract the analyzable models.\nOverall results We extract DL models based on the most pop-\nular frameworks, i.e., TFLite, TensorFlow, ncnn, Caffe, or Caffe2. In\nsummary, we successfully extract 176 DL models, which come from\n71 DL apps. The reasons why we cannot extract models from the\nother DL apps could be (i) the models are well protected and hidden\nin the apk files; (ii) the models are retrieved from Internet during\nruntime. Among the extracted models, we can analyze 98 of them,\nwhich come from 42 DL apps. The other extracted models cannot\nbe parsed via our framework currently because (i) the models are\nin format which we have no insights into, such as Parrots-based\nmodels, since the corresponding frameworks are not open-source;\n(ii) the models are encrypted.\n5.2\nModel Structures\n• DL model types Among the DL models extracted, 87.7% mod-\nels are CNN models, 7.8% models are RNN models, while others\nare not confirmed yet. The CNN models are mostly used in im-\nage/video processing and text classification. The RNN models are\n1-bit Quan.\n8-bit Quan.\n16-bit Quan.\nSparsity\nTF\nunsupported\n4.78%\n0.00%\n0.00%\nTFLite\nunsupported\n66.67%\nunsupported\nunsupported\nCaffe\nunsupported\n0.00%\nunsupported\nunsupported\nCaffe2\nunsupported\n0.00%\nunsupported\nunsupported\nncnn\nunsupported\n0.00%\nunsupported\nunsupported\nTotal\n0.00%\n6.32%\n0.00%\n0.00%\nTable 4: Optimizations applied on DL models.\nmostly used in text/voice processing, such as word prediction, trans-\nlation, speech recognition, etc. The results are consistent with the\nconventional wisdom: CNN models are good at capturing visual\ncharacteristics from images, while RNN models are powerful at\nprocessing sequential data with temporal relationships such as text\nand audio.\n• DL layer types We then characterize different types of layers\nused in DL models. As shown in Table 3, convolution (conv) is the\nmost commonly used type. 87.7% models have at least one convolu-\ntional layer, and the median (mean) number of convolutional layers\nused in those models is 5 (14.8). This is not surprising since convo-\nlution is the core of CNN models, and CNN is the dominant model\narchitecture used in vision tasks. Our previous analysis already\ndemonstrates that image processing is the most popular use case\nof mobile DL. Similarly, pooling is also an important layer type in\nCNN models, included in 76.5% DL models. Besides, softmax is also\nfrequently used (69.1%), but don’t repeatedly show up in one single\nmodel. This is because softmax layer usually resides at the end\nof DL models to get the probabilities as output. As a comparison,\nfully-connected (fc) layers are less common, only used in 60.5% DL\nmodels. A possible reason is that fully-connected layer is known to\nbe very parameter- and computation-intensive, and can be replaced\nby other layers such as convolution [18]. Other frequently used\nlayer types include add, split, relu, prelu, dropout, and reshape.\nImplications: Our findings motivate framework and hardware ven-\ndors who are interested in optimizing mobile DL to focus on the\npopular DL layers we discovered in deployed models, e.g. convolution.\nWe also notice that a small number (5) of DL models contain\ncustomized layer types. Such customization is made as an extension\nto existing DL frameworks [1]. The result indicates that the func-\ntionalities of current DL frameworks are mostly complete enough.\n• Model optimizations Various techniques have been proposed\nto optimize the DL models in consideration of their sizes and com-\nputation complexity. Here, we study the usage of two most popular\ntechniques in the wild: quantization and sparsity. Quantization\ncompresses DL models by reducing the number of bits required\nto represent each weight. The quantization has different levels, in-\ncluding 16-bit [61], 8-bit [105], and even 1-bit [53, 93], while the\noriginal models are usually presented in 32-bit floating points. Spar-\nsity [77, 107] has also been extensively studied in prior literatures\nas an effective approach to make compact DL models. It’s mainly\nused in matrix multiplication and convolutional layers to reduce\nparameters. Such optimizations are long known to reduce DL cost\nby up to two orders of magnitude without compromising model\naccuracy [63].\nA First Look at Deep Learning Apps on Smartphones\nWWW’19, May 2019, San Francisco, USA\nTensorFlow\nTFLite\nCaffe\nncnn\nParrots\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\n15.0\nModel Size (MB)\nFigure 7: The size of DL models in different frameworks.\nWe leave out Caffe2 since we only successfully extract one\nmodel in Caffe2 format.\nLeNet-5\nsqueezenet\nmobilenet\nvgg-\n16\nAlexnet\nResNet-50\nFigure 8: The cost of memory and computation of DL models\nextracted from apps. Red dots: classical CNN architectures\nas references. Black crosses: extracted DL models, which are\nvisually summarized by a covariance error ellipse [16].\nTable 4 summarizes the optimizations applied on DL models.\nHere we focus on the DL models for 5 popular frameworks, i.e., Ten-\nsorFlow (TF), TFLite, Caffe, Caffe2, and ncnn. Overall, most of these\nframeworks only support 8-bit quantization, except TensorFlow who\nhas 16-bit quantization and sparsity support. However, only a frac-\ntion of DL models apply the optimization techniques: 6.32% models\nare quantized into 8-bit, while others are non-optimized.\nImplications: The findings that well-known DL optimizations are\nmissing in real-world deployment suggest the efficiency potential of\nmobile DL is still largely untapped. The findings also urge immediate\nactions to fix the missing optimizations.\n5.3\nModel Resource Footprint\n• Model size. Figure 7 illustrates the size of DL models (in storage).\nOverall, we find that the extracted DL models are quite small (me-\ndian: 1.6MB, mean: 2.5MB), compared to classical models such as\nVGG-16 [100] (around 500MB) and MobileNet [69] (around 16MB).\nThe models in TensorFLow format (median: 3.2MB) are relatively\nlarger than the models in other formats such as TFLite (median:\n0.75MB) and ncnn (median: 0.86MB).\n• Runtime overhead. We then study the runtime performance of\nDL models. Here, we focus on two aspects: memory and computa-\ntions. The memory usage includes both the model parameters and\nthe generated intermediate results (feature maps). For computation\ncomplexity, we use floating point operations (FLOPs) during one\ninference as the metric. Here we use only part of models in Tensor-\nFlow and ncnn formats since some others don’t have fixed input\nsizes, e.g., image size, so that the computation complexity can only\nbe determined at runtime [15]. We also include the performance of\nsome other classical CNN models such as AlexNet, MobileNet, etc.\nAs illustrated in Figure 8, the black crosses represent the DL\nmodels we have extracted, while the red dots represent the classical\nCNN architectures. Overall, the results show that in-the-wild DL\nmodels are very lightweight in consideration of memory usage and\ncomputation complexity, with median value of 2.47 MB and 10M\nFLOPs respectively. Running such models on mobile processors is\ninexpensive. For example, as estimated on the CPU of Snapdragon\n8452, the execution time of 80% models are less than 15ms which\nis translated to 67 FPS [33]. To be compared, ResNet-50, one of\nthe state-of-the-art models in image classification task, has around\n200MB memory usage and 4GFLOPs computations. Even MobileNet\nand SqueezeNet, which are designed and optimized for mobile\nscenarios, require more memory usage and computations than 90%\nthose mobile DL models that we have discovered.\nImplications: Our findings of dominant lightweight DL models on\nsmartphones give app developers a valuable assurance: DL inference\ncan be as cheap as a few MBs of memory overhead and tens of ms\nexecution delay. Our findings challenge existing research on DL in-\nference, which are typically centered on full-blown models (e.g. VGG)\nand validated on these models [55, 64, 72, 73, 80, 82]. Given the signifi-\ncance of smartphones as DL platforms, future DL algorithm proposals\nshould consider applicability on lightweight models and treat resource\nconstraints as the first-class concern.\n5.4\nModel Security\nFinally, we investigate into how DL models are protected. We\ndeem model protection as an important step to AI system/app\nsecurity, because if attackers can acquire the model, they can (i)\nsteal the intellectual property by reusing the model file or re-train\na new model based on the stolen one; (ii) easily attack the DL-\nbased apps via adversarial attack [89]. We focus on two practical\nprotection mechanisms.\n• Obfuscation is a rather shallow approach to prevent at-\ntackers from gaining insights into the model structures by\nremoving any meaningful text, e.g., developers-defined layer\nnames.\n• Encryption is better in security by avoiding attackers from\ngetting the model structures/parameters, but also causes in-\nevitable overhead for apps to decrypt the models in memory.\nHere, we deem encrypted models as always obfuscated too.\nWe investigate into how obfuscation and encryption are employed\non DL models that we have extracted. We analyze the DL models\nextracted from apps using TensorFLow, TFLite, ncnn, caffe, and Caffe2.\nIn total, we confirm the security level of 120 DL models. Note that\n2A typical mobile chip used by many popular smartphones such as Galaxy S8.\nWWW’19, May 2019, San Francisco, USA\nMengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and Xuanzhe Liu\nhere encryption doesn’t necessarily mean encryption algorithm, but\nalso includes cases where developers customize the model format\nso that the model cannot be parsed via the DL framework.\nThe results show that among the 120 DL models, we find 47\n(39.2%) models are obfuscated and 23 (19.2%) models are encrypted.\nNote that these two sets of apps are overlapped: encrypted apps\nare also obfuscated. The results indicate that most DL models are\nexposed without protection, thus can be easily extracted and utilized\nby attackers. In fact, only few frameworks in Table 2 support ob-\nfuscation, e.g., ncnn can convert models into binaries where text\nis all striped [34], and Mace can convert a model to C++ code [11].\nWhat’s worse, no framework provides help in model encryption\nas far as we know. Thus, developers have to implement their own\nencryption/decryption mechanism, which can impose non-trivial\nprogramming overhead.\nImplications: The grim situation of model security urges strong\nprotection over proprietary models in a way similar to protecting\ncopyright digital contents on smartphones [42, 87, 96, 119]. This ne-\ncessitates a synergy among new tools, OS mechanisms and policies,\nand hardware mechanisms such as Intel SGX [21] and ARM Trust-\nZone [7].\n6\nLIMITATIONS AND FUTURE WORK\nLimitations of our analyzing tool Though we carefully de-\nsign our analyzer to capture as many DL apps as possible, and\ninvolve a lot of manual efforts to validate the results, we can still\nhave false identifications. For example, those DL apps that neither\ndepend on any popular DL frameworks nor have any string patterns\nin the native libraries, will be missed out. In addition, the apps that\nhave integrated DL frameworks but don’t really use them will be\nfalsely classified as DL apps, which shouldn’t happen though. For\nthe first case, we plan to mine the code pattern of DL implementa-\ntion and use the pattern to predict more DL apps that might involve\nDL. For the second one, we plan to further enhance our analyzer\nwith advanced static analysis technique [43] so that it can detect\nwhether the API calls (sinks) of DL libraries will be invoked or not.\nLonger-term analysis Currently, we carry out our empirical\nstudy based on the app datasets obtained in Jun. and Sep. 2018.\nIn the future, we plan to actively maintain and update our study\nby extending to more time steps, e.g., every 3 months. We believe\nthat more solid and interesting results can be made through such\nlong-term analysis. We will also keep watch on newly emerging\nDL frameworks and add them to our analyzing tool.\nMore platforms In this work, we only analyze the adoption of\nDL on Android apps. Though Android is quite representative of\nthe mobile ecosystem, more interesting findings might be made by\nexpanding our study on other platforms such as iOS and Android\nWear. We believe that comparing the DL adoption on different plat-\nforms can feed in more implications to researchers and developers.\nInvolving dynamic analysis For now, our analysis remains\nstatic. Though static analysis technology is quite powerful, we\nbelieve that dynamic analysis can provide more useful findings.\nFor example, by running the DL models on off-the-shelf mobile\ndevices, we can characterize the accurate runtime performance, e.g.,\nend-to-end latency and energy consumption.\n7\nRELATED WORK\nIn this section, we discuss existing literature studies that relate\nto our work in this paper.\nMobile DL Due to their ubiquitous nature, mobile devices can\ngenerate a wide range of unique sensor data, and thus create count-\nless opportunities for DL tasks. The prior efforts on mobile DL can\nbe mainly summarized into two categories. First, researchers have\nbuilt numerous novel applications based on DL [46, 74, 75, 85, 92].\nFor example, MobileDeepPill [117] is a small-footprint mobile DL\nsystem that can accurately recognize unconstrained pill images.\nSecond, various optimization techniques have been proposed to\nreduce the overhead of DL on resource-constrained mobile devices.\nThe optimizations include model compression [55, 64, 73, 80, 108],\nhardware customizations [48, 50, 62, 118], lightweight models [47,\n69, 75, 106], knowledge distilling [45, 68, 117], and cloud offload-\ning [66, 72, 120]. These studies are usually carried out under lab\nenvironments, based on classical models such as VGG and ResNet,\nin lack of real-world workloads and insights. Thus, our work is\nmotivated by those enormous efforts that try to bring DL to mo-\nbile devices, and fill the gap between the academic literature and\nindustry products.\nML/DL as cloud services Besides on-device fashion, the DL\nfunctionality, or in a broader scope of Machine Learning (ML), can\nalso be accessed as cloud services. The service providers include\nAmazon [2], Google [20], Microsoft Azure [22], etc. There are some\nprior analyzing studies focusing on such MLaaS (machine learning\nas a service) platforms. Yao et al. [116] comprehensively investi-\ngate into effectiveness of popular MLaas systems, and find that\nwith more user control comes greater risk. Some other literature\nstudies [57, 98, 104] focus on the security issues of those platforms\ntowards different types of attacks. MLaaS platforms have some\nadvantages in protecting intellectual property and performance.\nHowever, compared to on-device fashion, they also have some\nshortcomings such as privacy concerns and unstable accessibility.\nThus, some DL tasks are more fit to be run on local devices, e.g.,\nword-prediction in keyboard. Our work also proves that on-device\nDL has been already adopted in many real-world apps to some\nextent, and is going to be popular on smartphones.\nEmpirical study of DL Prior empirical analysis mainly focuses\non assisting developers to build better DL apps/systems/models.\nZhang et al. [122] characterize the defects (bugs) in DL programs\nvia mining the StackOverflow QA pages and GitHub projects. Con-\nsequently, the results are limited in only open-source, small-scale\nprojects. Fawzi et al. [56] analyze the topology and geometry of the\nstate-of-the-art deep networks, as well as their associated decision\nboundary. Senior et al. [97] investigate into how the learning rate\nused in stochastic gradient descent impacts the training perfor-\nmance, and propose schemes to select proper learning rate. These\nstudies mostly focus on classical and small-scale DL models pro-\nposed in previous literature, while our study mine the knowledge\nfrom large-scale in-the-wild mobile apps.\nDL Model protection Some recent efforts have been investi-\ngated in protecting DL models. For example, various watermarking\nmechanisms [42, 87, 96, 119] have been proposed to protect intel-\nlectual property of DL models. This approach, however, cannot\nprotect models from being extracted and attacked. As a closer step,\nA First Look at Deep Learning Apps on Smartphones\nWWW’19, May 2019, San Francisco, USA\nsome researchers [60, 65, 103] secure the DL systems/models based\non secure execution environments (SEE) such as Intel SGX [21].\nHowever, those techniques are still not practical for in-the-wild\ndeployment. Some DL frameworks also provide mechanisms for\nmodel protection. For example, Mace [24] supports developers to\nconvert models to C++ code [11]. However, our results show that a\nlarge number of DL models are exposed without secure protection.\n8\nCONCLUSIONS\nIn this work, we have carried out the first empirical study to\nunderstand how deep learning technique is adopted in real-world\nsmartphones, as a bridge between the research and practice. By\nmining and analyzing large-scale Android apps based on a static\ntool, we have reached interesting and valuable findings. For exam-\nple, we show that early adopters of mobile deep learning are top\napps, and the role played by deep learning in those apps is critical\nand core. Our findings also provide strong and valuable implica-\ntions to multiple stakeholders of the mobile ecosystem, including\ndevelopers, hardware designers and researchers.\nREFERENCES\n[1] 2018. Add a new op in TensorFlow. https://www.tensorflow.org/guide/extend/\nop.\n[2] 2018. Amazon Machine Learning. https://aws.amazon.com/machine-learning.\n[3] 2018.\nAn Exploration of Mobile First AI.\nhttps://medium.com/swlh/\nan-exploration-of-mobile-first-ai-576c944efd36.\n[4] 2018. Android aapt. http://elinux.org/Android_aapt.\n[5] 2018.\nApktool: A tool for reverse engineering Android apk files.\nhttps://\nibotpeaches.github.io/Apktool/.\n[6] 2018.\nApple\nCOO:\nSmartphone\nis\na\n’major\nplatform’\nfor\nfuture\nof\nAI.\nhttps://www.techrepublic.com/article/\napple-coo-smartphone-is-a-major-platform-for-future-of-ai/.\n[7] 2018. Arm TrustZone. https://developer.arm.com/technologies/trustzone.\n[8] 2018.\nArtificial\nIntelligence\nNext\nKey\nGrowth\nArea\nfor\nSmart-\nphones\nas\nNumbers\nTop\nSix\nBillion\nby\n2020,\nIHS\nMarkit\nSays.\nhttps://news.ihsmarkit.com/press-release/technology/\nartificial-intelligence-next-key-growth-area-smartphones-numbers-top-six-bi.\n[9] 2018. Caffe2 deep learning framework. https://github.com/caffe2/caffe2.\n[10] 2018. Chainer. https://chainer.org/.\n[11] 2018. Converting model to C++ code. https://mace.readthedocs.io/en/latest/\nuser_guide/advanced_usage.html.\n[12] 2018. CoreML by Apple. https://developer.apple.com/documentation/coreml.\n[13] 2018. Deep Learning for Java. https://deeplearning4j.org/.\n[14] 2018. dex2jar. https://github.com/pxb1988/dex2jar.\n[15] 2018. Dynamic shapes in TensorFlow. https://www.tensorflow.org/guide/\ntensors.\n[16] 2018.\nError Ellipses.\nhttp://www.cs.utah.edu/~tch/CS4300/resources/refs/\nErrorEllipses.pdf.\n[17] 2018. FeatherCNN. https://github.com/Tencent/FeatherCNN.\n[18] 2018. Fully-connected Layers in Convolutional Neural Networks). https://\ncs231n.github.io/convolutional-networks/.\n[19] 2018.\nGlobal\nmobile\nOS\nmarket\nshare\nin\nsales\nto\nend\nusers.\nhttps://www.statista.com/statistics/266136/\nglobal-market-share-held-by-smartphone-operating-systems/.\n[20] 2018. Google Prediction API. https://cloud.google.com/prediction.\n[21] 2018. Intel Software Guard Extensions. https://software.intel.com/en-us/sgx.\n[22] 2018. Microsoft Azure ML Studio. https://azure.microsoft.com/en-us/services/\nmachine-learning.\n[23] 2018. Microsoft Cognitive Toolkit (CNTK). https://github.com/Microsoft/CNTK.\n[24] 2018. Mobile AI Compute Engine. https://github.com/XiaoMi/mace.\n[25] 2018. Mobile deep learning. https://github.com/baidu/mobile-deep-learning.\n[26] 2018. Open neural network exchange format. https://onnx.ai/.\n[27] 2018. Open Source Computer Vision Library. https://opencv.org/.\n[28] 2018.\nOver\nHalf\nof\nSmartphone\nOwners\nUse\nVoice\nAssistants.\nhttps://voicebot.ai/2018/04/03/\nover-half-of-smartphone-owners-use-voice-assistants-siri-leads-the-pack/.\n[29] 2018. Protocol Buffer. https://developers.google.com/protocol-buffers/.\n[30] 2018. pytorch. http://pytorch.org/.\n[31] 2018. SenseTime. https://www.sensetime.com/?lang=en-us.\n[32] 2018. Snapdragon Neural Processing Engine. https://developer.qualcomm.com/\nsoftware/snapdragon-neural-processing-engine.\n[33] 2018. Snapdragon performance. https://www.anandtech.com/show/12420/\nsnapdragon-845-performance-preview/2.\n[34] 2018.\nStrip visible string in ncnn.\nhttps://github.com/Tencent/ncnn/wiki/\nhow-to-use-ncnn-with-alexnet.\n[35] 2018. SuperID Android SDK. https://github.com/SuperID/superid-android-sdk.\n[36] 2018. Tencent ncnn deep learning framework. https://github.com/Tencent/ncnn.\n[37] 2018. TensorFlow. https://www.tensorflow.org/.\n[38] 2018. TensorFlow Lite. https://www.tensorflow.org/mobile/tflite/.\n[39] 2018.\nThe Machine Learning Behind Android Smart Linkify.\nhttps://ai.\ngoogleblog.com/2018/08/the-machine-learning-behind-android.html.\n[40] 2018. torch. http://torch.ch/.\n[41] 2018.\nxNN deep learning framework.\nhttps://myrgzn.gitee.io/rgzn/news/\npage100.html.\n[42] Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, and Joseph Keshet.\n2018. Turning Your Weakness Into a Strength: Watermarking Deep Neural\nNetworks by Backdooring. arXiv preprint arXiv:1802.04633 (2018).\n[43] Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexandre Bartel,\nJacques Klein, Yves Le Traon, Damien Octeau, and Patrick McDaniel. 2014.\nFlowdroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint\nanalysis for android apps. Acm Sigplan Notices 49, 6 (2014), 259–269.\n[44] Davide Bacciu, Stefano Chessa, Claudio Gallicchio, and Alessio Micheli. 2017.\nOn the need of machine learning as a service for the internet of things. In\nProceedings of the 1st International Conference on Internet of Things and Machine\nLearning, IML 2017. 22:1–22:8.\n[45] Anoop Korattikara Balan, Vivek Rathod, Kevin P Murphy, and Max Welling.\n2015. Bayesian dark knowledge. In Advances in Neural Information Processing\nSystems. 3438–3446.\n[46] Michael Barz and Daniel Sonntag. 2016. Gaze-guided Object Classification Using\nDeep Neural Networks for Attention-based Computing. In Proceedings of the\n2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing\n(UbiComp’16). 253–256.\n[47] Guoguo Chen, Carolina Parada, and Georg Heigold. 2014. Small-footprint\nKeyword Spotting Using Deep Neural Networks. In IEEE International Conference\non Acoustics, Speech and Signal Processing, (ICASSP’14). 4087–4091.\n[48] Tianshi Chen, Zidong Du, Ninghui Sun, Jia Wang, Chengyong Wu, Yunji Chen,\nand Olivier Temam. 2014. DianNao: a Small-footprint High-throughput Acceler-\nator for Ubiquitous Machine-Learning. In Architectural Support for Programming\nLanguages and Operating Systems (ASPLOS’14). 269–284.\n[49] Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun\nXiao, Bing Xu, Chiyuan Zhang, and Zheng Zhang. 2015. MXNet: A Flexible\nand Efficient Machine Learning Library for Heterogeneous Distributed Systems.\nCoRR abs/1512.01274 (2015).\n[50] Yu-Hsin Chen, Joel S. Emer, and Vivienne Sze. 2016. Eyeriss: A Spatial Architec-\nture for Energy-Efficient Dataflow for Convolutional Neural Networks. In 43rd\nACM/IEEE Annual International Symposium on Computer Architecture, (ISCA’16).\n367–379.\n[51] Zhenpeng Chen, Yanbin Cao, Yuanqiang Liu, Haoyu Wang, Tao Xie, and Xu-\nanzhe Liu. 2020. A comprehensive study on challenges in deploying deep\nlearning based software. In Proceedings of the 28th ACM Joint Meeting on Eu-\nropean Software Engineering Conference and Symposium on the Foundations of\nSoftware Engineering. 750–762.\n[52] Zhenpeng Chen, Sheng Shen, Ziniu Hu, Xuan Lu, Qiaozhu Mei, and Xuanzhe\nLiu. 2019. Emoji-powered representation learning for cross-lingual sentiment\nclassification. In The World Wide Web Conference. 251–262.\n[53] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. 2015. Binarycon-\nnect: Training deep neural networks with binary weights during propagations.\nIn Advances in neural information processing systems. 3123–3131.\n[54] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks\nfor youtube recommendations. In Proceedings of the 10th ACM Conference on\nRecommender Systems. 191–198.\n[55] Emily L. Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus.\n2014. Exploiting Linear Structure Within Convolutional Networks for Efficient\nEvaluation. In Advances in Neural Information Processing Systems 27: Annual\nConference on Neural Information Processing Systems (NIPS’14). 1269–1277.\n[56] Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, and Stefano\nSoatto. 2018. Empirical study of the topology and geometry of deep networks.\nIn IEEE CVPR.\n[57] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. 2015. Model inversion\nattacks that exploit confidence information and basic countermeasures. In Pro-\nceedings of the 22nd ACM SIGSAC Conference on Computer and Communications\nSecurity. 1322–1333.\n[58] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,\nSherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial\nnets. In Advances in neural information processing systems. 2672–2680.\n[59] Mihajlo Grbovic and Haibin Cheng. 2018. Real-time Personalization using\nEmbeddings for Search Ranking at Airbnb. In Proceedings of the 24th ACM\nWWW’19, May 2019, San Francisco, USA\nMengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and Xuanzhe Liu\nSIGKDD International Conference on Knowledge Discovery & Data Mining. 311–\n320.\n[60] Zhongshu Gu, Heqing Huang, Jialong Zhang, Dong Su, Ankita Lamba, Dimitrios\nPendarakis, and Ian Molloy. 2018. Securing Input Data of Deep Learning Infer-\nence Systems via Partitioned Enclave Execution. arXiv preprint arXiv:1807.00969\n(2018).\n[61] Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan.\n2015. Deep learning with limited numerical precision. In International Conference\non Machine Learning. 1737–1746.\n[62] Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A. Horowitz,\nand William J. Dally. 2016. EIE: Efficient Inference Engine on Compressed\nDeep Neural Network. In 43rd ACM/IEEE Annual International Symposium on\nComputer Architecture, (ISCA’16). 243–254.\n[63] Song Han, Huizi Mao, and William J Dally. 2015. Deep compression: Com-\npressing deep neural networks with pruning, trained quantization and huffman\ncoding. arXiv preprint arXiv:1510.00149 (2015).\n[64] Seungyeop Han, Haichen Shen, Matthai Philipose, Sharad Agarwal, Alec Wol-\nman, and Arvind Krishnamurthy. 2016. MCDNN: An Approximation-Based\nExecution Framework for Deep Stream Processing Under Resource Constraints.\nIn Proceedings of the 14th Annual International Conference on Mobile Systems,\nApplications, and Services (MobiSys’16). 123–136.\n[65] Lucjan Hanzlik, Yang Zhang, Kathrin Grosse, Ahmed Salem, Max Augustin,\nMichael Backes, and Mario Fritz. 2018. MLCapsule: Guarded Offline Deployment\nof Machine Learning as a Service. arXiv preprint arXiv:1808.00590 (2018).\n[66] Johann Hauswald, Yiping Kang, Michael A. Laurenzano, Quan Chen, Cheng\nLi, Trevor N. Mudge, Ronald G. Dreslinski, Jason Mars, and Lingjia Tang. 2015.\nDjiNN and Tonic: DNN as a service and its implications for future warehouse\nscale computers. In Proceedings of the 42nd Annual International Symposium on\nComputer Architecture, Portland, OR, USA, June 13-17, 2015. 27–40.\n[67] Ehsan Hesamifard, Hassan Takabi, Mehdi Ghasemi, and Rebecca N. Wright.\n2018. Privacy-preserving Machine Learning as a Service. PoPETs 2018, 3 (2018),\n123–142.\n[68] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge\nin a neural network. arXiv preprint arXiv:1503.02531 (2015).\n[69] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun\nWang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. MobileNets:\nEfficient Convolutional Neural Networks for Mobile Vision Applications. CoRR\nabs/1704.04861 (2017).\n[70] Forrest N. Iandola, Matthew W. Moskewicz, Khalid Ashraf, Song Han, William J.\nDally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level Accuracy with 50x\nFewer Parameters and <1MB Model Size. arXiv preprint arXiv:1602.07360 (2016).\n[71] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long,\nRoss B. Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Convo-\nlutional Architecture for Fast Feature Embedding. In Proceedings of the ACM\nInternational Conference on Multimedia, MM ’14, Orlando, FL, USA, November 03\n- 07, 2014. 675–678.\n[72] Yiping Kang, Johann Hauswald, Cao Gao, Austin Rovinski, Trevor N. Mudge,\nJason Mars, and Lingjia Tang. 2017. Neurosurgeon: Collaborative Intelligence\nBetween the Cloud and Mobile Edge. In Proceedings of the Twenty-Second Inter-\nnational Conference on Architectural Support for Programming Languages and\nOperating Systems (ASPLOS’17). 615–629.\n[73] Nicholas D. Lane, Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi, Lei\nJiao, Lorena Qendro, and Fahim Kawsar. 2016. DeepX: A Software Accelerator\nfor Low-power Deep Learning Inference on Mobile Devices. In 15th ACM/IEEE\nInternational Conference on Information Processing in Sensor Networks (IPSN\n2016). 23:1–23:12.\n[74] Nicholas D. Lane, Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi, and\nFahim Kawsar. 2015. An Early Resource Characterization of Deep Learning\non Wearables, Smartphones and Internet-of-Things Devices. In Proceedings\nof the 2015 International Workshop on Internet of Things towards Applications\n(IoT-App’15). 7–12.\n[75] Nicholas D. Lane, Petko Georgiev, and Lorena Qendro. 2015. DeepEar: Robust\nSmartphone Audio Sensing in Unconstrained Acoustic Environments Using\nDeep Learning. In Proceedings of the 2015 ACM International Joint Conference on\nPervasive and Ubiquitous Computing (UbiComp’15). 283–294.\n[76] Seyyed Salar Latifi Oskouei, Hossein Golestani, Matin Hashemi, and Soheil\nGhiasi. 2016. CNNdroid: GPU-Accelerated Execution of Trained Deep Con-\nvolutional Neural Networks on Android. In Proceedings of the 2016 ACM on\nMultimedia Conference. 1201–1205.\n[77] Vadim Lebedev and Victor Lempitsky. 2016. Fast convnets using group-wise\nbrain damage. In Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition. 2554–2564.\n[78] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature\n521, 7553 (2015), 436.\n[79] Mu Li, Tong Zhang, Yuqiang Chen, and Alexander J Smola. 2014. Efficient mini-\nbatch training for stochastic optimization. In Proceedings of the 20th international\nconference on Knowledge discovery and data mining (KDD’14). 661–670.\n[80] Sicong Liu, Yingyan Lin, Zimu Zhou, Kaiming Nan, Hui Liu, and Junzhao Du.\n2018. On-Demand Deep Model Compression for Mobile Devices: A Usage-\nDriven Model Selection Framework. In Proceedings of the 16th Annual Inter-\nnational Conference on Mobile Systems, Applications, and Services (MobiSys’18).\n389–400.\n[81] Xuanzhe Liu, Yi Hui, Wei Sun, and Haiqi Liang. 2007. Towards service composi-\ntion based on mashup. In 2007 IEEE Congress on Services (Services 2007). IEEE,\n332–339.\n[82] Huynh Nguyen Loc, Youngki Lee, and Rajesh Krishna Balan. 2017. DeepMon:\nMobile GPU-based Deep Learning Framework for Continuous Vision Appli-\ncations. In Proceedings of the 15th Annual International Conference on Mobile\nSystems, Applications, and Services (MobiSys’17). 82–95.\n[83] Yun Ma, Ziniu Hu, Diandian Gu, Li Zhou, Qiaozhu Mei, Gang Huang, and\nXuanzhe Liu. 2020. Roaming Through the Castle Tunnels: An Empirical Analysis\nof Inter-app Navigation of Android Apps. ACM Transactions on the Web (TWEB)\n14, 3 (2020), 1–24.\n[84] Yun Ma, Dongwei Xiang, Shuyu Zheng, Deyu Tian, and Xuanzhe Liu. 2019.\nMoving deep learning into web browser: How far can we go?. In The World\nWide Web Conference. 1234–1244.\n[85] Gaurav Mittal, Kaushal B. Yagnik, Mohit Garg, and Narayanan C. Krishnan.\n2016. SpotGarbage: Smartphone App to Detect Garbage Using Deep Learning.\nIn Proceedings of the 2016 ACM International Joint Conference on Pervasive and\nUbiquitous Computing (UbiComp’16). 940–945.\n[86] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness,\nMarc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg\nOstrovski, et al. 2015. Human-level control through deep reinforcement learning.\nNature 518, 7540 (2015), 529.\n[87] Yuki Nagai, Yusuke Uchida, Shigeyuki Sakazawa, and Shin’ichi Satoh. 2018. Dig-\nital watermarking for deep neural networks. International Journal of Multimedia\nInformation Retrieval 7, 1 (2018), 3–16.\n[88] Shumpei Okura, Yukihiro Tagami, Shingo Ono, and Akira Tajima. 2017.\nEmbedding-based news recommendation for millions of users. In Proceedings\nof the 23rd ACM SIGKDD International Conference on Knowledge Discovery and\nData Mining. 1933–1942.\n[89] Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Ce-\nlik, and Ananthram Swami. 2016. The limitations of deep learning in adversarial\nsettings. In Security and Privacy (EuroS&P), 2016 IEEE European Symposium on.\n372–387.\n[90] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online\nlearning of social representations. In Proceedings of the 20th ACM SIGKDD\ninternational conference on Knowledge discovery and data mining (KDD’14). 701–\n710.\n[91] Alec Radford, Luke Metz, and Soumith Chintala. 2015. Unsupervised represen-\ntation learning with deep convolutional generative adversarial networks. arXiv\npreprint arXiv:1511.06434 (2015).\n[92] Valentin Radu, Nicholas D. Lane, Sourav Bhattacharya, Cecilia Mascolo, Ma-\nhesh K. Marina, and Fahim Kawsar. 2016. Towards Multimodal Deep Learning\nfor Activity Recognition on Mobile Devices. In Proceedings of the 2016 ACM Inter-\nnational Joint Conference on Pervasive and Ubiquitous Computing (UbiComp’16).\n185–188.\n[93] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016.\nXnor-net: Imagenet classification using binary convolutional neural networks.\nIn European Conference on Computer Vision. 525–542.\n[94] Mauro Ribeiro, Katarina Grolinger, and Miriam A. M. Capretz. 2015. MLaaS:\nMachine Learning as a Service. In 14th IEEE International Conference on Machine\nLearning and Applications, ICMLA 2015. 896–902.\n[95] Everett M Rogers. 2010. Diffusion of innovations. Simon and Schuster.\n[96] Bita Darvish Rouhani, Huili Chen, and Farinaz Koushanfar. [n. d.]. DeepSigns:\nA Generic Watermarking Framework for Protecting the Ownership of Deep\nLearning Models. ([n. d.]).\n[97] Andrew Senior, Georg Heigold, Ke Yang, et al. 2013. An empirical study of\nlearning rates in deep neural networks for speech recognition. In Acoustics,\nSpeech and Signal Processing (ICASSP), 2013 IEEE International Conference on.\nIEEE, 6724–6728.\n[98] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017.\nMembership inference attacks against machine learning models. In Security and\nPrivacy (SP), 2017 IEEE Symposium on. 3–18.\n[99] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja\nHuang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,\net al. 2017. Mastering the game of Go without human knowledge. Nature 550,\n7676 (2017), 354.\n[100] Karen Simonyan and Andrew Zisserman. 2014.\nVery Deep Convolutional\nNetworks for Large-Scale Image Recognition. CoRR abs/1409.1556 (2014).\n[101] SÃk, ren Sonnenburg, Mikio L Braun, Cheng Soon Ong, Samy Bengio, Leon\nBottou, Geoffrey Holmes, Yann LeCun, Klaus-Robert MÃžller, Fernando Pereira,\nCarl Edward Rasmussen, et al. 2007. The need for open source software in\nmachine learning. Journal of Machine Learning Research (JMLR) 8, Oct (2007),\nA First Look at Deep Learning Apps on Smartphones\nWWW’19, May 2019, San Francisco, USA\n2443–2466.\n[102] Ion Stoica, Dawn Song, Raluca Ada Popa, David Patterson, Michael W Mahoney,\nRandy Katz, Anthony D Joseph, Michael Jordan, Joseph M Hellerstein, Joseph E\nGonzalez, et al. 2017. A berkeley view of systems challenges for ai. arXiv\npreprint arXiv:1712.05855 (2017).\n[103] Florian Tramer and Dan Boneh. 2018. Slalom: Fast, Verifiable and Private Execu-\ntion of Neural Networks in Trusted Hardware. arXiv preprint arXiv:1806.03287\n(2018).\n[104] Florian Tramèr, Fan Zhang, Ari Juels, Michael K Reiter, and Thomas Ristenpart.\n2016. Stealing Machine Learning Models via Prediction APIs.. In USENIX Security\nSymposium. 601–618.\n[105] Vincent Vanhoucke, Andrew Senior, and Mark Z Mao. 2011. Improving the\nspeed of neural networks on CPUs. In Proc. Deep Learning and Unsupervised\nFeature Learning NIPS Workshop, Vol. 1. 4.\n[106] Ehsan Variani, Xin Lei, Erik McDermott, Ignacio Lopez-Moreno, and Javier\nGonzalez-Dominguez. 2014. Deep Deural Detworks for Small Footprint Text-\ndependent Speaker Verification. In IEEE International Conference on Acoustics,\nSpeech and Signal Processing, (ICASSP’14). 4052–4056.\n[107] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. 2016. Learning\nstructured sparsity in deep neural networks. In Advances in Neural Information\nProcessing Systems. 2074–2082.\n[108] Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, and Jian Cheng. 2016.\nQuantized Convolutional Neural Networks for Mobile Devices. In 2016 IEEE\nConference on Computer Vision and Pattern Recognition, (CVPR’16). 4820–4828.\n[109] Chenren Xu, Shuang Jiang, Guojie Luo, Guangyu Sun, Ning An, Gang Huang,\nand Xuanzhe Liu. 2020. The Case for FPGA-based Edge Computing. IEEE\nTransactions on Mobile Computing (2020).\n[110] Mengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and\nXuanzhe Liu. 2019. A first look at deep learning apps on smartphones. In The\nWorld Wide Web Conference. 2125–2136.\n[111] Mengwei Xu, Yun Ma, Xuanzhe Liu, Felix Xiaozhu Lin, and Yunxin Liu. 2017.\nAppHolmes: Detecting and characterizing app collusion among third-party\nAndroid markets. In Proceedings of the 26th International Conference on World\nWide Web. 143–152.\n[112] Mengwei Xu, Tiantu Xu, Yunxin Liu, Xuanzhe Liu, Gang Huang, and Felix Xi-\naozhu Lin. 2020. A query engine for zero-streaming cameras. In Proceedings of\nthe 26th Annual International Conference on Mobile Computing and Networking.\n1–3.\n[113] Mengwei Xu, Xiwen Zhang, Yunxin Liu, Gang Huang, Xuanzhe Liu, and Felix Xi-\naozhu Lin. 2020. Approximate query service on autonomous iot cameras. In\nProceedings of the 18th International Conference on Mobile Systems, Applications,\nand Services. 191–205.\n[114] Mengwei Xu, Mengze Zhu, Yunxin Liu, Felix Xiaozhu Lin, and Xuanzhe Liu.\n2018. DeepCache: Principled Cache for Mobile Deep Vision. In Proceedings of\nthe 24th Annual International Conference on Mobile Computing and Networking.\n129–144.\n[115] Chengxu Yang, QiPeng Wang, Mengwei Xu, Shangguang Wang, Kaigui Bian,\nand Xuanzhe Liu. 2020. Heterogeneity-aware federated learning. arXiv preprint\narXiv:2006.06983 (2020).\n[116] Yuanshun Yao, Zhujun Xiao, Bolun Wang, Bimal Viswanath, Haitao Zheng, and\nBen Y. Zhao. 2017. Complexity vs. performance: empirical analysis of machine\nlearning as a service. In Proceedings of the 2017 Internet Measurement Conference,\nIMC 2017, London, United Kingdom, November 1-3, 2017. 384–397.\n[117] Xiao Zeng, Kai Cao, and Mi Zhang. 2017. MobileDeepPill: A Small-Footprint\nMobile Deep Learning System for Recognizing Unconstrained Pill Images. In\nProceedings of the 15th Annual International Conference on Mobile Systems, Ap-\nplications, and Services (MobiSys’17). 56–67.\n[118] Chen Zhang, Peng Li, Guangyu Sun, Yijin Guan, Bingjun Xiao, and Jason Cong.\n2015. Optimizing FPGA-based Accelerator Design for Deep Convolutional Neu-\nral Networks. In Proceedings of the 2015 ACM/SIGDA International Symposium\non Field-Programmable Gate Arrays (FPGA’15). 161–170.\n[119] Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu, Marc Ph Stoecklin, Heqing\nHuang, and Ian Molloy. 2018. Protecting Intellectual Property of Deep Neural\nNetworks with Watermarking. In Proceedings of the 2018 on Asia Conference on\nComputer and Communications Security. 159–172.\n[120] Qingchen Zhang, Laurence T. Yang, and Zhikui Chen. 2016. Privacy Preserving\nDeep Computation Model on Cloud for Big Data Feature Learning. IEEE Trans.\nComputers (2016), 1351–1362.\n[121] Xingzhou Zhang, Yifan Wang, and Weisong Shi. 2018. pCAMP: Performance\nComparison of Machine Learning Packages on the Edges. (2018).\n[122] Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang.\n2018. An Empirical Study on TensorFlow Program Bugs. (2018).\n",
  "categories": [
    "cs.LG",
    "cs.CY"
  ],
  "published": "2018-11-08",
  "updated": "2021-01-13"
}