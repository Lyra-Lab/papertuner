{
  "id": "http://arxiv.org/abs/1812.06175v3",
  "title": "Can Deep Learning Predict Risky Retail Investors? A Case Study in Financial Risk Behavior Forecasting",
  "authors": [
    "Yaodong Yang",
    "Alisa Kolesnikova",
    "Stefan Lessmann",
    "Tiejun Ma",
    "Ming-Chien Sung",
    "Johnnie E. V. Johnson"
  ],
  "abstract": "The paper examines the potential of deep learning to support decisions in\nfinancial risk management. We develop a deep learning model for predicting\nwhether individual spread traders secure profits from future trades. This task\nembodies typical modeling challenges faced in risk and behavior forecasting.\nConventional machine learning requires data that is representative of the\nfeature-target relationship and relies on the often costly development,\nmaintenance, and revision of handcrafted features. Consequently, modeling\nhighly variable, heterogeneous patterns such as trader behavior is challenging.\nDeep learning promises a remedy. Learning hierarchical distributed\nrepresentations of the data in an automatic manner (e.g. risk taking behavior),\nit uncovers generative features that determine the target (e.g., trader's\nprofitability), avoids manual feature engineering, and is more robust toward\nchange (e.g. dynamic market conditions). The results of employing a deep\nnetwork for operational risk forecasting confirm the feature learning\ncapability of deep learning, provide guidance on designing a suitable network\narchitecture and demonstrate the superiority of deep learning over machine\nlearning and rule-based benchmarks.",
  "text": "Can Deep Learning Predict Risky Retail Investors? A Case Study in\nFinancial Risk Behavior Forecasting\nY. Yang†,a, A. Kim†,b, S. Lessmann†,b, T. Ma†,c, M.-C. Sung†,c,∗, J.E.V. Johnson†,c\naDepartment of Computer Science, University College London\nbSchool of Business and Economics, Humboldt-University of Berlin\ncSouthampton Business School, University of Southampton\nAbstract\nThe paper examines the potential of deep learning to support decisions in ﬁnancial risk management.\nWe develop a deep learning model for predicting whether individual spread traders secure proﬁts from\nfuture trades. This task embodies typical modeling challenges faced in risk and behavior forecasting.\nConventional machine learning requires data that is representative of the feature-target relationship and\nrelies on the often costly development, maintenance, and revision of handcrafted features. Consequently,\nmodeling highly variable, heterogeneous patterns such as trader behavior is challenging. Deep learning\npromises a remedy. Learning hierarchical distributed representations of the data in an automatic manner\n(e.g.\nrisk taking behavior), it uncovers generative features that determine the target (e.g., trader’s\nproﬁtability), avoids manual feature engineering, and is more robust toward change (e.g. dynamic market\nconditions). The results of employing a deep network for operational risk forecasting conﬁrm the feature\nlearning capability of deep learning, provide guidance on designing a suitable network architecture and\ndemonstrate the superiority of deep learning over machine learning and rule-based benchmarks.\nKeywords:\nrisk management, retail ﬁnance, forecasting, deep learning\n1. Introduction\nThe paper applies recently developed deep learning (DL) methods to forecast the behavior of retail\ninvestors in the spread-trading market. Market makers depend on accurate forecasts of traders’ future\nsuccess to manage ﬁnancial risks. Through developing a DL-based forecasting model and conﬁrming the\nproﬁtability of a model-based hedging strategy, we provide evidence that characteristic features of DL\ngeneralize to the structured data sets commonly employed in retail ﬁnance and decision support.\nDeep neural networks (DNN) operate in a stage-wise manner. Each layer receives an input from\nprevious layers, learns a high-level representation of the input, and passes the representation (i.e., output)\nto a subsequent layer. Applications in face recognition exemplify this approach. To detect faces in an\nimage, ﬁrst DNN layers learn low-level concepts such as lines and borders from raw pixels. Deeper layers\ngeneralize lower layer outputs to more complex concepts such as squares and triangles that eventually\nform a face [1]. An analogous example in decision support could be corporate credit risk modeling.\n∗†Authors contribute equally. Published at European Journal of Operational Research (EOR16143/EJOR-D-18-00153).\nEmail addresses: yaodong.yang@outlook.com (Y. Yang†,), alisa.k@protonmail.com (A. Kim†,),\nstefan.lessmann@hu-berlin.de (S. Lessmann†,), tiejun.ma@soton.ac.uk (T. Ma†,), M.SUNG@soton.ac.uk\n[Corresponding author] (M.-C. Sung†,), J.E.Johnson@soton.ac.uk (J.E.V. Johnson†,)\nPreprint submitted to Elsevier\nNovember 19, 2019\narXiv:1812.06175v3  [q-fin.RM]  17 Nov 2019\nBankruptcy prediction models estimate default probabilities on the basis of ratios of accounting variables\n(e.g., total assets/total liabilities) [2]. In a DL framework, such ratios represent a low level representation.\nUsing balance sheet ﬁgures as input, lower layers in a DNN can relate statement variables and calculate\ninformative ratios in a data-driven manner. A higher level representation of the data could then include\nthe trend in a ﬁnancial ratio or inter-dependencies between ratio variables. The speciﬁc representation is\ncalculated autonomously. A hierarchical composition of representations of diﬀerent complexities enable\na DNN to learn abstract concepts such as that of a delinquent borrower. Representation learning also\nenhances the ability of a model to extract patterns that are not well represented in the training data,\nwhich is a problem for machine learning (ML) models [3]. DL methods have delivered excellent results in\napplications such as computer vision, language processing, and others [4]. This success has established\nthe eﬀectiveness of DL-based feature learning in applications that rely on unstructured data [5].\nApplications of conventional ML are manifold. Marketing models support all stages of the customer\nlife cycle including response modeling, cross-/up-selling [6], and churn prediction [7]. Financial institu-\ntions use ML to anticipate ﬁnancial market developments [8], predict the solvency of corporate borrowers\n[9], or inform credit approval decisions [10]. Such applications rely on structured data such as past cus-\ntomer transactions, price developments, or loan repayments. It is not obvious that the success of DL in\nunstructured data processing generalizes to decision support applications where structured data prevails.\nTherefore, the objectives of the paper are to examine the eﬀectiveness of DL in decision support, to test\nwhether its feature learning ability generalizes to the structured data sets typically encountered in this\nﬁeld, and to oﬀer guidance on how to setup a DL-based decision support model.\nWe pursue our objectives in a ﬁnancial risk management context. Using data from the spread-trading\nmarket, we predict the proﬁtability of individual traders. The modeling goal is to identify traders that\npose a high risk to the market maker, and recommend a hedging policy that maximizes the marker maker’s\nproﬁts. Beyond the utility of such a policy for a spread-trading company, the trader risk prediction task\nrepresents challenges that are commonly encountered in ML-based decision support.\nA ﬁrst challenge is class imbalance. Adverse events such as borrower default represent minorities in\ntheir populations, and this impedes ML [7]. A second challenge called concept drift arises in dynamic\nenvironments. ML models learn a functional relationship between subject characteristics (e.g., previous\ntrades of a client) and a target (e.g., trader proﬁtability) from past data. Changes in the environment\nrender this relationship more volatile and harder to infer. The curse-of-dimensionality is another modeling\nchallenge. Corporate data warehouses provide a huge amount of information about modeling subjects\n(e.g., traders) and it is diﬃcult to learn generalizable patterns in the presence of a large number of\nfeatures [11]. Finally, the success of ML depends on the availability of informative features. Feature\nengineering is carried out manually by domain experts. Given high labor costs, a shortage of skilled\nanalysts and the need to revise hand-crafted features in response to external changes (e.g., in trader\nbehavior), manual feature engineering decreases the eﬃciency of ML and becomes an impediment to\nML-based decision support.\nThe common denominator of the modeling challenges is that they reduce the representativeness of the\ntraining data. Being a data-driven approach, ML suﬀers from reduced representativeness, which suggests\n2\nthat the challenges diminish the eﬀectiveness and eﬃciency of data-driven ML models. Considering our\napplication setting as an example, the representation learning ability of DL could help to identify a more\ngeneric representation of the trading proﬁle of high-risk traders than that embodied in hand-crafted\nfeatures. More generality in the inferred feature-target-relationship would oﬀer higher robustness toward\nexternal variations in trading behavior; for example, variations introduced by changes in business cycle,\nmarket conditions, company operations, etc. Replacing the need for costly manual feature engineering\nwould also raise the eﬃciency of model-based decision support.\nExamining the degree to which DL remedies common modeling challenges in decision support, the\npaper makes the following contributions. First, it is one of the ﬁrst studies to examine the eﬀectiveness\nof DL in conjunction with structured, individual-level behavioral customer data. Predicting individual\ntrader’s risk taking behavior, we focus on retail ﬁnance, which is a pivotal application area for operations\nresearch [12] that, to our knowledge, no previous DL study has considered. Empirical results provide\nevidence that DL predicts substantially more accurately than ML methods. Second, we demonstrate the\nability of DL to learn informative features from operational data in an automatic manner. Prior research\nhas conﬁrmed this ability for unstructured data [1]. We expand previous results to transactional and\nbehavioral customer data. This ﬁnding is managerially meaningful because many enterprises employ\nstructured data for decision support. Third, the paper contributes to ﬁnancial risk taking forecasting\npractice in that it proposes a DNN-based approach to eﬀectively manage risk and inform hedging decisions\nin a speculative ﬁnancial market.\nThe DL methodology that we employ in the paper is not new. However, DL and its constituent\nconcepts such as distributed representations are rarely explained in the language of business functions.\nBusiness users can beneﬁt from an understanding of DL concepts to enable them to engage with data\nscientists and consultants on an informed basis. A better understanding might also lead to more appreci-\nation of formal, mathematical models and help to overcome organizational inertia, which is a well-known\nimpediment to fact-based decision support [13, 14]. Against this background, a ﬁnal contribution of the\npaper is that it increases awareness of DL in business through evidencing its potential and providing a\nconcrete recipe for how to set up, train, and implement a DNN-based decision support approach. To\nachieve this, we elaborate on the methodological underpinnings of DL and the decision model we devise\nfor trader risk classiﬁcation. We note that a similar objective has independently been pursued in a recent,\nrelated paper by Kraus et al. [15].\n2. Related Work\nThe literature on DL is growing at high pace [1, 4, 5]. We focus on DL applications in ﬁnance. Table\n1 analyzes corresponding studies along diﬀerent dimensions related to the forecasting setting, underlying\ndata, and neural network topology. To clarify the selection of papers, we acknowledge that DL has other\napplications in ﬁnance beyond forecasting including index tracking [16] or modeling state dynamics in\nlimit-order-book data [17]. DL has also been applied to generate ﬁnancial forecasts from textual data\n[18]. Table 1 does not include such studies as they do not concentrate on prediction or consider a diﬀerent\nsource of data. Finally, one may argue that a recurrent neural network (RNN) is a DNN by deﬁnition,\n3\nbecause recurrent cells exhibit temporal depth. With the rise of DL, gated RNNs such as LSTM (long\nshort-term memory) gained popularity and are often characterized as DNNs [19]. This is not necessarily\ntrue for their predecessors, some of which have been used in ﬁnance [20]. Table 1 analyzes studies that\nused contemporary gated RNNs and omits those that use earlier types of RNNs.\nTable 1 shows that the majority (roughly 60%) of previous studies forecast developments in ﬁnancial\nmarkets, such as price movements [21], volatility [22] or market crashes [23]. Applications in risk analytics\nsuch as ﬁnancial distress prediction [24] or credit scoring [25] are also popular. Considering the objectives\nof forecasting, columns two and three reveal that previous studies have not considered forecasting human\nbehavior, which is the focus of this paper.\nThe type of input data represents a second diﬀerence between most previous studies and this paper.\nDNNs that forecast ﬁnancial market prices typically receive lagged prices as inputs. For example, [21]\nand [19] use minute- and day-level price returns as inputs. By contrast, the risk modeling task we face\nconsists of a dynamic regression problem with diﬀerent types of predictor variables (see Section 5.1).\nThe feature columns in Table 1 show that few prior studies mix numerical and discrete input variables.\nA core feature of DNNs is the ability to automatically extract predictive features from the input\ndata [26]. One objective of this paper is to conﬁrm the feature learning capability in a risk management\ncontext. A substantial diﬀerence in the type of input data has implications for feature learning. It is\nnot obvious that results observed in a time series setting generalize to a dynamic regression setting with\ndiverse input variables. With respect to risk management, we observe from the column proﬁt simulation\nin Table 1 that most previous work has not examined the economic implications of a DL-based risk\nmanagement approach; [25] being an exception.\nIn addition to the application setting and input data, a third diﬀerence between most previous work\nand this study concerns the architecture of the DNN. Table 1 sketches the topology of previous networks in\nits three rightmost columns. Given our focus on forecasting studies, every network includes a supervised\nlearning mechanism, meaning that weights in the network are trained through minimizing the empirical\nloss on the training data set [27]. This is typically implemented by means of a fully-connected output\nlayer. This layer requires only one unit with a linear or softmax activation function to solve regression\nand classiﬁcation problems, respectively. Table 1 shows that purely supervised learning networks prevail\nin previous work. From this observation, we conclude that more research into networks with supervised\nand unsupervised layers is desirable.\nIn total, nine studies consider unsupervised pre-training. The majority implement pre-training using\na deep belief network. Long before pre-training was popularized, a seminal study proposed self-organizing\nmaps for unsupervised time series pattern extraction [28]. Stacked denoising auto-encoders (SdA), the\napproach we use for feature learning, have received little attention. Evidence of their eﬀectiveness in risk\nanalytics is originally provided in this paper.\nIn summary, the contribution of our work to literature emerges through a combination of charac-\nteristics concerning the forecasting setting, the data employed, and the way in which we devise and\nassess the DL-based forecasting model through using state-of-the-art approaches for network training\nand unsupervised pre-training and evaluation of the proﬁtability of model-based hedging decisions.\n4\nThe study closest related to our work is [25].\nThe authors estimate a DNN from a data set of\nover 3.5 billion loan-month observations with 272 variables relating to loan characteristics and local\neconomic factors to support portfolio management. To that end, [25] model the transition probabilities of\nindividual loans between states ranging from current over diﬀerent delayed payment states to delinquency\nor foreclosure. Our study diﬀers from [25] in terms of the application setting and DL methodology.\nThe DL models of [25] consists of feed-forward networks of up to 7 layers (and ensembles thereof).\nDeep feed-forward networks are a generalization of the three-layer networks widely used in previous work\n([29]). The DNN architecture proposed here is diﬀerent. It uses multiple layers of diﬀerent types of units\nand relies on unsupervised pre-training to extract predictive features. Pre-training elements provide\ndistinctive advantages and have been found eﬀective in ﬁnancial applications [16]. Consequently, we\nfurther advance the methodology of [25].\nMortgage risk modeling [25] and credit scoring in general, diﬀer substantially from trader risk pre-\ndiction. A credit product can be considered a put option. The lender has the right to grant credit, but\nno obligation to do so. Credits may also be secured by collateral and, most importantly, it is possible to\nhedge risks while still earning money from commissions. However, we consider a spread-trading context\nwhere the market maker is obliged to accept orders from its clients. These orders are similar to futures\ncontracts with an arbitrary strike date. Unlike in the credit industry where customers are given a credit\nlimit, in the spread trading market, informed traders or insiders can make unlimited proﬁts from the\nmarket marker. At the same time, the economics of the spread-trading market require the market maker\nto hedge risks very selectively because hedging quickly reduces revenues to zero. Thus, our forecasting\ntask is to identify those traders who pose a substantial risk to the market maker.\n3. Risk Taking and Behavior Forecasting in the Spread-Trading Market\nSpread trading is becoming increasingly signiﬁcant. Forty percent of the 1.2 trillion traded annually\non the London Stock Exchange is equity derivative related and 25 percent of this (120 billion) relates to\nspread trading [30]. Spread trading often refers to pairs trading of stocks or to trading spreads in the\nfutures market [31]. However, our study focuses on the form of spread trading which relates to retail\ncontracts for diﬀerence (CFD). In this market, a retail investor and a market maker enter a contract\nrelated to a speciﬁed ﬁnancial instrument (e.g. a share, commodity or an index) and at the end of the\ncontract they exchange the diﬀerence between the closing and opening price of that ﬁnancial instrument.\nConsequently, investors trade on the direction and magnitude of movements of a ﬁnancial instrument.\nFor example, a client might place a long order on the S&P500 with stake size $10 per point. If the\nS&P500 rises by a particular increment, the client makes a proﬁt of $10 ∗increment; otherwise s/he\nloses this amount. The market maker quotes bid and ask prices for marketable instruments. Unlike\nbrokers, who help clients to trade with other investors, market makers buy or sell ﬁnancial instruments\nfrom their own inventory. Provided clients meet a margin requirement, they can open and close positions\nat any time. The market maker is obliged to accept these orders and faces the risk of adverse selection.\n5\nTable 1: Summary of Related Work on DL in Finance\nArea1\nSubject2\nTarget\nTime\nSeries\nTime Window\nObser-\nvations\nFeatures3\nHorizon\nStudy Design\nData part.4\nProﬁt\nsim.\nSupervised\nLayers5\nUnsup.\nPretrain.5\nArchitecture6\n[28]\nMM\nExr\nDirection\n5\n9/1973 - 5/1987\n3,645\n2\ncon\nday\nrolling window\n100 / 30\nRNN\nSOM\nx-7-2-o\n[32]\nExr\nReturn\n3\n1976 - 2004\n< 1, 000\n5\ncon\nweek\ntemporal split\n0.7 / 0.3\nFC\nDBM\nx-20-20-20-o\n[22]\nInd\nVolatility\n1\n10/2004 - 7/2015\n2,682\n25 (t3)\ncon\nday\ntemporal split\n0.7 / 0.3\nLSTM\nx-1-o\n[33]\nFut\nDirection\n43\n3/1991 - 9/2014\n50\n9895\ncon\n5 min\nrolling window\n25000 / 12500\nyes\nFC\nx-1000-100-100-\n100-o\n[21]\nFut\nReturn\n4\n1/2014 - 9/2015\n100\n150\ncon\nminute\nrolling window\n15000 / 5000\nyes\nRLRNN\nx-128-128-128-\n20-o\n[34]\nInd\nReturn\n6\n7/2008 - 9/2016\n2,079\n19 (t4)\ncon\nday\nrolling window\n2y / 1q / 1q7\nyes\nLSTM\nSdA\nx-10-10-10-10-\n10-1-1-1-1-1-o\n[35]\nSto\nBetter S&P500\n∼500\n1/1992 - 10/2015\n380\n31\ncon\nday\nrolling window\n750 / 250\nyes\nFC\nx-31-10-5-o\n[36]\nCo\nWTI crude oil\nspot price\n1\n1/1986 - 5/2016\n365\n200\ncon\nmonth\ntemporal split\n0.80 / 0.20\nFC\nSdA\nx-100-10-o\n[19]\nSto\nBetter S&P500\n∼500\n1/1992 - 10/2015\n380\n1 (t240)\ncon\nday\nrolling window\n750 / 250\nyes\nLSTM\nx-25-o\n[37]\nInd\nReturn\n2\n1/2000 - 7/2017\n4,3\n6 (t20)\ncon\nday\ntemporal split\n0.45 / 0.55\nyes\nLSTM+\nLSTM+FC\nx-(x1-5-3 —\nx2-4-2)-2-o\n[23]\nInd\nCrash\n2\n1/1996 - 12/2017\n5,4\n131\ncon\n1 | 5 days\ntemporal split\n0.66 / 0.33\nFC\nx-64-32-8-2-o\n[38]\nInd\nVolatility\n1\n1/2001 - 1/2017\n3,963\n6 (t22)\ncon\nday\ntemporal split\n0.68 / 0.32\nLSTM+FC\nx-10-4-2-5-o\n[39]\nSto\nBetter S&P\n300\n1/1993 - 5/2015\n6300\n≤592\ncon\nday\nrolling window\n504 / 126\nyes\nFC\nDBN\nx-148-74-o\n[40]\nRA\nEnt\nInsolvency\nN.A.\n2002 - 2006\n1,2\n30\ncon\nYear\nrandom split\n800 / 400\nFC\nDBN\nx-500-500-1000-o\n[41]\nEnt\nInsolvency\nN.A.\n2001 - 2011\n∼83, 000\n180\ncon\nYear\nrolling window\n04.01.2001\nFC\nDBN\nx-1000-1000-\n1000-o\n[42]\nEnt\nFirm perf.\n22\n2000 - 2015\n286\n15\ncon\nYear\ntemporal split\n10. Mrz\nFC\nDBN\nx-200-200-200-\n200-o\n[43]\nEnt\nRating\nN.A.\n1/2016 - 12/2016\n661\n11\nmix\nN.A.\ncross-val.\n10 fold\nFC\nDBN\nNot speciﬁed\n[25]\nMor\nDefault\nN.A.\n1/1995 - 6/2014\n3.5 ∗109\n272\nmix\nmonth\ntemporal split\n214 / 19\nyes\nFC\nx-200-140-140-\n140-140-o\n[24]\nEnt\nInsolvency\n286\n2016 - 2017\n117,019\n181\ncon\nN.A.\nrandom split\n0.6/0.2/ 0.2\nFC\nx-50-50-1\n[44]\nFD\nCC\nFraud\n2\n5/2015 - 5/2015\n1.65 ∗107\n30 (t10)\nmix\nN.A.\ntemporal split\n0.43/ 0.08/ 0.49\nLSTM\nx-100-100-100-o\n1 MM: ﬁnancial market modeling, RA: risk analytics, FD: fraud detection\n2 Exr: exchange rate of a pair of currencies, Ind: ﬁnancial market index, Fut: future contract, Sto: individual stock, Co: commodity, Ent: enterprise, Mor: mortgage, CC: credit card.\n3 Number of input features and their type using abbreviations con (continuous feature) and mix (continuous and categorical features). For studies that use LSTM networks we also report the length of a time-lagged input sequence using the notation (tl) where t\nmeans time and l is the number of lags. For example, [3] consider 25 features and feed the last three observations (days) of each feature into their LSTM.\n4 Partitioning of the data for model training, validation, and testing. Fractional numbers represent percentages with respect to the size of the data set while values greater zero depict absolute numbers of observations. The notation is training set size / validation\nset size / test set size. Not all studies use separate validation data. Then, the two values given in the column represent training set size / test set size.\n5 RNN: recurrent neural network, FC: fully-connected layer, LSTM: Long-short-term-memory, RLRNN: reinforcement learning RNN, SOM: self-organizing-map, SdA: stacked denoising auto-encoders, DBM: deep belief network.\n6 Symbols x and o represent the multivariate input and scalar output of the network. Numbers give the size of hidden layers. For studies that use pre-training, hidden layer sizes refer to units of the unsupervised layers (e.g., DBM, SOM, or SdA). Exceptions and\nspecial cases for complex topologies exists and we elaborate on these in the discussion of the table.\n7 The notation is slightly diﬀerent from other studies. The authors use a rolling window evaluation to train, validate, and test their models using daily prices from two years, one quarter, and one quarter, respectively.\nForecasting which traders pose the most risk ( i.e. those who are likely to make the most proﬁt)\nand deciding which risks to hedge into the main market is crucial for market makers. Informed traders\nmight take advantage of inside information and leave the market maker with positions against a market\nrally. In theory, the potential loss of the market maker from one trade is unbounded. For example, IG\nGroup, the largest retail ﬁnancial services provider in UK, recently lost 30 million GBP due to deﬁcient\nrisk control and inﬂexible hedging strategies. As a result of similar problems, FXCM, the largest market\nmaker on the global spot FX market, went bankrupt1.\nThe spread between quoted bid and ask prices is the main source of revenue of the market maker.\nFor liquid markets, such as those for the S&P500 or for the USD/GBP the spread is greater in the\nspread trading market than in the underlying market. However, for less liquid ﬁnancial instruments (e.g.\nthe DAX or FTSE100 index) the spread is less than that oﬀered in the underlying market. This later\nsituation is often faced by spread trading ﬁrms when they need to place large volume transactions into\nthe underlying market for less liquid ﬁnancial instruments. If the market maker hedges a trade, they\nlose the potential proﬁt from the spread whether or not the hedging was necessary. The market maker\nalso faces transaction costs to hedge a position, including commission and the higher spreads in some\nmarkets when they seek to hedge large volumes. Therefore, designing a predictive classiﬁcation model\nthat distinguishes A-book clients (i.e. those who pose most risk to the market maker) from B-book\nclients (those who pose less risk) is vital. The market maker will hedge positions from A-book clients\nto protect against losses and will take the risk of the positions from B-book clients to increase proﬁts.\nTypically, 90% of the total revenues come from B-book clients [45].\nWe study the decision whether to hedge an incoming trade. This task translates into a classiﬁcation\nproblem, which we address through developing a DNN to predict high risk (A-book) traders. If the DNN\nlearns patterns from observed trading behavior that facilitate an accurate prediction of a trader’s future\nsuccesses, it can assist the market maker through recommending hedging decisions and enhancing risk\nmanagement in daily operations. Figure 1 illustrates the DNN-enabled hedging strategy.\nFigure 1: Workﬂow of how hedge strategy works for market makers\n1See\nhttps://www.forbes.com/sites/steveschaefer/2015/01/16/swiss-bank-stunner-claims-victims-currency-broker-\nfxcm-bludgeoned/#7e94f5466de0\n7\n3.1. Trader Classiﬁcation and Hedging Strategy\nThe deﬁnition of an A-book client is subjective and depends on the business strategy of the market\nmaker. The company which provided the data prefers to remain anonymous (we refer to them hereafter\nas STX), but is a large player in the UK spread-trading market. From interviews with their front-desk\ndealers, who engage in day-to-day risk management, we found that STX at the time of the study, deﬁned\na client i to be a high risk trader if s/he secured a return greater than 5% from her previous 20 trades.\nThe strategy of STX was to hedge the trades of these clients.\nThe deployed hedging strategy is dynamic, since STX determines the status of a client (A- or B-book)\nfrom the performance of their previous 20 trades. Therefore, client status can change due to a single\ntrade. Accordingly, we frequently observe a situation where STX takes the risk of trade j of client i while\nhedging against trade j + k of client i. In a speculative market, the overall return of a set of past trades\ncan give misleading guidance to the future proﬁtability of a trader. For example, a skilled trader, who\nfollows a consistent strategy, shows high trading discipline, routinely uses and updates stop-loss limits,\netc., can regularly lose money due to the randomness of the environment.\nSimilarly, a poor trader,\nwho violates all the above principles, occasionally makes a proﬁt. This suggests that a trader’s past\nperformance is not necessarily a reliable signal of their true ability. Consequently, the goal of developing\na client classiﬁcation model is to generate a superior signal for hedging decisions by accounting for all\nother characteristics available in the data.\nWe develop a DNN to learn the latent nature of a trader from past trading data. The target concept,\ntrader ability, is highly variable, corrupted by noise, and diﬃcult to accommodate in a pre-deﬁned, static\nset of trader characteristics. Therefore, it will be important for the DNN to distill, from transactional\ndata, high-level distributed representations of the target concept, which capture the underlying generative\nfactors that explain variations in trading behavior. In this regard, success in trader classiﬁcation will\nevidence the ability of DL to automatically extract informative features.\n3.2. Trader Behavior Prediction and Decision Support\nIt is not obvious that representation learning is eﬀective in risk management. Applications such as,\ncredit scoring, churn prediction or trader classiﬁcation involve the forecasting of human behavior. One\nwould expect the maximal attainable accuracy in a behavior forecasting model to be less than in, e.g., face\ndetection. For example, the prediction target is less clearly deﬁned (e.g., STX used a 5% threshold but\nthis is subjective) and the feature-target relationship is typically weak. Our trader behavior forecasting\nstudy aims to clarify the potential of representation learning and DL in decision support.\nWe argue that the prediction task is representative of a range of modeling challenges in decision\nsupport because it exhibits several characteristics that often occur in corporate applications of data-\ndriven prediction models. More speciﬁcally, we face challenges that diminish the representativeness of\nthe training data. First, in response to previous gains and losses and changes in the macro-environment,\nthe behavior of individual traders can be variable, erratic and dynamic. Second, detailed, time-ordered\ninformation about individual traders, asset prices and their underlying fundamentals and broader indica-\ntors of market sentiment (e.g., economic growth) are readily available, which leads to high dimensionality.\n8\nThird, the speciﬁc way in which variables relate to each other and govern traders’ proﬁts is complex,\nnonlinear, and likely to evolve over time. Automatic feature extraction, if successful, is a promising way\nto cope with these challenges. Fourth, the spread trading setting displays class imbalance in that only a\nfew traders succeed in securing systematic positive returns above 5%, while the vast majority of clients\nlose money. Last, eﬀective risk management requires accurate predictions at the level of an individual\ntrader. Accuracy is a general requirement in predictive decision support.\n4. Methodology\nDL applications in risk analytics are yet sparse.\nWe revisit principles of DL and detail how we\nconﬁgure the DNN to classify spread traders. The online Appendix elaborates on these concepts and\nDNN training. A recent study on DL for business analytics also provides valuable background [15].\n4.1. Principles of Deep Learning\nDL aims at learning multiple levels of representations from data. Higher levels represent more abstract\nconcepts. A deep architecture with multiple layers of abstraction and its ability to learn distributed\nrepresentations provides several advantages over conventional shallow ML methods.\nThe deep architecture. ML methods learn a functional relationship between variables, which character-\nize the relationship between an observation and a prediction target. High variability of this function\ncomplicates the ML approach and may lead to poor generalization. Sources of high variability include\nexternal shocks to the environment in which a decision model operates. Learning theory suggests that\nto represent a functional relationship, a learning machine with depth k needs exponentially more com-\nputational units than a machine with depth k + 1 [26]. The depth of commonly-used machine learning\nmethods is as follows [3]: linear and logistics regression (depth 1); boosting and stacking ensembles:\ndepth of base learner (depth +1, one extra layer for combining the votes from base learners); decision\ntrees, one-hidden-layer artiﬁcial neural networks (ANNs), support vector machines (depth 2); the visual\nsystem in the human brain (depth 5-10, [46]).\nThe concept of depth explains a large number of empirical ﬁndings related to, for example, ANNs or\nsupport vector machines outperforming simple regression models or ensemble classiﬁers outperforming\nindividual learners [10]. Increased depth allows these methods to implicitly learn an extra level of repre-\nsentation from data [3]. Additional levels facilitate generalization to new combinations of the features,\nwhich are less represented in the training data. Enlarged capacity also allows the learning machine to\ncapture more variations in the target function, which discriminates classes accurately.\nFurthermore,\nthe number of computational units a model can aﬀord is severely restricted by the number of training\nexamples. As a result, when there are variations of interest in the target function, shallow architectures\nneed extreme complexity (large amounts of computational units) to ﬁt the function. Consequently, they\nneed exponentially more training examples than a model with greater depth [3].\n9\nDistributed Representations. DL methods learn distributed representations from data. An example of\na distributed representation is principal component analysis (PCA). PCA re-orients a data set in the\ndirection of the eigenvectors, which are ordered according to their contribution to explained variation.\nThis is a distributed representation where the raw variables collaborate to generate a principle component.\nIn predictive ML, principle components can replace the original variables. The functional relationship\nto learn is then that between the target variable and the principle components. This can simplify the\nlearning task, increase predictive accuracy, and facilitate feature reduction [47]. However, ML methods\nlearn local, non-distributed representations. Using the raw variables in a data set, they partition the\ninput space into mutually exclusive regions.\nFor example, support vector machines infer a decision\nboundary from the local training examples of adjacent classes that are closest to each other.\nThe goal of ML is to classify novel examples, which are not part of the training set. However, the\ntraining data may lack representativeness (e.g., because of a change in the environment). Distributed rep-\nresentations are better able to accommodate new observations that the training data does not represent\nwell. Consider our trader classiﬁcation problem as an example: Traders exhibit diﬀerent trading styles;\nthey use diﬀerent strategies, follow diﬀerent stop-loss rules, etc. Assume traders are split into 5 diﬀerent\nclusters, with traders in the same cluster sharing a trading style. Using a non-distributed representation,\nwe need 5 diﬀerent features to exclusively represent each cluster, 0 = 00000, 1 = 01000, ..., 4 = 00001. A\ndistributed representation requires only ⌈log2 5⌉= 3 features to model the clusters (as a binary code),\n0 = 000, 1 = 001, ..., 4 = 100. Using three distributed features, this representation can also accommodate\na new type of trader (i.e., using trading strategies that have not been employed in the training sample):\n5 = 101. This exempliﬁes an advantage of distributed representations, namely that the number of pat-\nterns that the representation can distinguish grows exponentially with the number of features. However,\nfor non-distributed representations, this number grows, at best, linearly.\n4.2. Building the Deep Neural Network\nDL methods consist of multiple components with levels of non-linear transformations.\nA typical\ninstance is a neural network with several hidden layers [35, 25]. Training a DNN requires solving a\nnon-convex optimization problem, which is diﬃcult because of the vanishing gradient problem [48].\nGradient vanishing prohibits propagating error information from the upper layer back to lower layers\nin the network, so that connection weights in lower layers cannot be adapted [49]. As a result, the\noptimization will often terminate in poor local minima. Remedies to this problem include unsupervised\npre-training, parametric Rectiﬁer Unit (ReLu), Xavier initialization, dropout, and batch normalization.\nWe take advantage of these techniques to develop a trader classiﬁcation DNN for risk management.\nBelow, we introduce pre-training and dropout. Interested readers ﬁnd a similar description of the other\nconcepts in the online Appendix.\n4.2.1. Unsupervised Pre-Training\nThe goal of pre-training is to ﬁnd invariant, generative factors (i.e., distributed representations),\nwhich explain variations in the data and amplify those variations that are important for subsequent\ndiscrimination. Through a sequence of non-linear transformations, pre-training creates layers of inherent\n10\nfeature detectors without requiring data labels. This facilitates a local learning of connection weights.\nAvoiding a propagation of error information through multiple layers of the network, pre-training helps to\novercome the vanishing gradient problem. Stacking multiple layers of progressively more sophisticated\nfeature detectors, the DNN can be initialized to sensible starting values. After discovering a structural\nrelationship in the data, one can then add a supervised learning technique (e.g., logistic regression)\non top of the pre-trained network and tune parameters using back-propagation.\nUnsupervised pre-\ntraining, where the use of the target label is postponed until the ﬁne-tuning stage, is especially useful in\nmanagement decision support where class imbalance is a common problem [50].\nTwo classical implementations of pre-training are deep belief networks (DBN), which are pre-trained\nby restricted Boltzmann machine [51], and stacked denoising autoencoders (SdA), which are pre-trained\nby the autoencoder [48]. Both strategies minimize an approximation of the log-likelihood of a generative\nmodel and, accordingly, typically show similar performance [52, 53]. This, together with the fact that\ndeep belief networks have already received some attention in the risk analytics literature (see Table 1),\nled us to use the framework of the stacked denoising autoencoder [53].\nDenoising Autoencoder. The denoising autoencoder (dA) learns a distributed representation (namely\nthe ”code”) from input samples. Suppose we have N samples and each sample has p features. Receiving\nan input x ∈Rp, the learning process of a dA includes four steps:\nStep 1: Corruption. The dA ﬁrst corrupts the input x. By sampling from the Binomial distribution\n(n = N, p = pq) , (where the corruption rate qp is a hyper parameter that needs tuning outside the\nmodel), the dA randomly corrupts a subset of the observed samples and deliberately introduces noise.\nFor example, if the input features a binary, corruption corresponds to ﬂipping bits.\nStep 2: Encoder. The dA deterministically maps the corrupted input ex into a higher-level represen-\ntation (the code) y ∈Rk. The encoding process is conducted via an ordinary one-hidden-layer neural\nnetwork (the number of hidden units k is a hyper parameter that needs tuning outside the model). With\nweight matrix W, biases b, and encoding function h(·), e.g., sigmoid function, y is given as:\ny = h(W · ex + b)\n(1)\nStep 3: Decoder. The code y is mapped back by a decoder into the reconstruction z that has the same\nshape as the input x. Given the code y, z should be regarded as a prediction of x. Such reconstruction\nrepresents a denoising process; it tries to reconstruct the input from a noisy (corrupted) version of it.\nSimilar to the encoder, the decoder has the weight matrix f\nW, biases eb, and a decoding function g(·).\nThe reconstruction z is:\nz = g(f\nW · y + eb)\n(2)\nStep 4: Training. Optimizing the parameters of dA (W, b, f\nW, eb) involves minimizing the reconstruc-\ntion error L(x,z); achieved by letting the code y learn a distributed representation that captures the main\nfactors of variation in x. Theoretically, if we use the mean squared error (LH(x,z) = ||x −z||2) as the\ncost function and linear functions as both encoder h(·) and decoder functions g(·), the dA is equivalent\nto PCA; the k hidden units in code y represent the ﬁrst k principal components of the data. The choice\n11\nof cost function depends on the distributional assumptions of input x. In this paper, we measure the re-\nconstruction error by the cross entropy loss function, as most of our features are probabilities x ∈[0, 1]p.\nIn addition, we incorporate an L2 penalty (also called weight decay). This is equivalent to assuming\na Gaussian prior over the weights and a common approach to encourage sparsity among weights and\nimprove generalization. The regularization parameter λ captures the trade-oﬀbetween reconstruction\nerror and model complexity. The parameter needs tuning outside the model and oﬀers a way to protect\nagainst overﬁtting. Higher values of λ penalize model complexity more heavily and, ceteris paribus,\nreduce the risk of overﬁtting. The ﬁnal cost function is:\nL(x, z) = −1\nN\nN\nX\ni=1\np\nX\nk=1\n[xik log zik + (1 −xik) log(1 −zik)] + λ ∥W∥2\n(3)\nSeveral solvers (e.g., stochastic gradient descent) are available to carry out the optimization.\narg min\nw, e\nw,b,eb\nL(x, z | Θ)\n(4)\nStep 5: Stacking. Once a dA has been trained, one can stack another dA on top. Layers are organized\nin a feed-forward manner. The second dA takes the encoded output of the previous dA (the code y)\nas its new inputs x. Each layer of dA is trained locally, ﬁnding its own optimal weights regardless of\nthe other layers. Iteratively, a number of dAs can be stacked upon each other to construct a stacked\ndenoising autoencoder (SdA). The encoding weights of each dA can then be treated as initializations for\nthe network in the next step. Figure 2 illustrates the working ﬂow of dA.\nFigure 2: Architecture of denoising auto-encoder.\n4.2.2. Supervised ﬁne-tuning\nThe SdA can be trained in a feed-forward, layer-wise manner. To employ the network for prediction,\nnetwork training continues with supervised ﬁne-tuning that teaches the DNN which types of trading\nbehaviors (in the form of distributed representations) identify A-book clients.\nTo that end, we add\na softmax regression on top of the SdA. This way, we solve a supervised learning problem using the\ndistributed representation of the raw input as features (which the SdA output embodies), and a binary\nindicator variable as target, which indicates whether a trade should be hedged. Formally, with parameter\nweight W and bias b, the probability that a trade x belongs to class i is:\n12\nP(Y = i|x, W, b) = softmaxi(Wx + b) =\neWix+bi\nP\nj eWjx+bj\n(5)\nWe employ the negative log-likelihood as cost function in supervised ﬁne-tuning. Suppose y(i) is the true\nclass for the input x(i), the cost function then states:\nL(W, b, x) = −\nN\nX\ni=1\nlog(P(Y = y(i)|x(i), W, b))\n(6)\n4.2.3. Protecting Against Overﬁtting Using Dropout Regularization\nDNN are vulnerable to overﬁtting. To prohibit the model emphasizing idiosyncratic patterns of the\ntraining data, our DNN includes a dropout layer behind each hidden layer. Figure 3 depicts the concept of\ndropout. During training, hidden layer neurons and their corresponding connection weights are removed\nfrom the DNN. This is done for each batch of training samples in an iteration. The gradients contributed\nby that batch of samples also bypass the dropped-out neurons during back-propagation (see the online\nAppendix for a detailed explanation of DNN training). The probability of a hidden neuron dropping out\nfollows a Bernoulli distribution with a given dropout rate.\nA DNN trained with dropout mimics the behavior of an ensemble model. When calculating predic-\ntions, the DNN considers all hidden layer neurons but multiplies the connecting weights of each hidden\nneuron by the expectation of the Bernoulli distribution. This way, although training a single DNN with\nN hidden neurons, the prediction of the DNN implicitly integrates predictions of 2N candidate networks\nwith diﬀerent combinations of hidden neurons. More formally, dropout simulates a geometric model\naveraging process; each possible combination of hidden neurons is considered, which is the extreme case\nof bagging. Model combination is known to increase predictive accuracy [7, 10].\nDropout also acts as a regularizer. It removes random weights from training, which prevents hidden\nneurons from co-adapting to each other. Moreover, model averaging reduces variance, which, via the\nbias-variance decomposition, reduces forecast error. Controlling the complexity of a DNN, dropout helps\nto protect against overﬁtting [54].\nFigure 3: Principle of dropout in training and predicting.\nRecall that we augment dropout through using an L2−penalty during SdA training to increase the\nrobustness of the DNN toward overﬁtting. For the same reason, we make use of early-stopping.\n13\n4.2.4. Network Training and Conﬁguration\nOur DNN involves unsupervised pre-training using SdA. We tune weights in a layer-wiser manner and\nthen ﬁne-tune the DNN as a whole in a supervised way, with each hidden layer followed by a dropout\nlayer.\nIn addition, we use several other DL concepts to protect against overﬁtting and simplify the\nnetwork training process including Xavier’s initialization, batch normalization layers and using ReLU as\nthe activation function. Previous work on DL has elaborated on these concepts and established their\nutility [27], and we detail them in the online Appendix. To facilitate replication, Algorithm 1 in the online\nAppendix provides a complete description of the employed DNN using pseudo-code. The architecture of\nthe DNN is also sketched in Figure 4 (below), together with other parts of our methodology.\nThe parameters to determine in the pre-training stage are the weight matrix and bias in each dA\n(both the encoder and the decoder). The parameters in the supervised ﬁne-tuning stage are the weight\nmatrix and bias in each encoder of SdA and in the softmax regression.\nWe use stochastic gradient\ndescent with momentum and a decaying learning rate for DNN training. The online Appendix provides\nan explanation of these concepts and motivates our choices. In particular, Algorithm 1 in the online\nAppendix provides a fully-comprehensive description of network training using pseudo-code. Section 2\nof the online Appendix also elaborates on our approach to decide on DNN hyper-parameters such as the\nnumber of hidden layers in SdA, and how we tune these using random search [55].\nThe techniques we employ are available in DL software packages, which facilitate deﬁning the topology\nof a DNN, provide routines for numerical optimization to train the DNN, and oﬀer the functionality to\napply a trained model for forecasting. We use the Python library Theano, which is a GPU-based library\nfor scalable computing. The GPUs used for experiments were Nvidia Tesla K20m with 2496 cores and\n5GB GDDR5 high bandwidth memory each. We observe this infrastructure to provide a 10-15 times\nimprovement in speed over training a DNN using traditional CPUs for DNN training (which equates to\nreducing run-times from more than a week to 1-2 days). In appraising these ﬁgures it is important to\nnote that i) large run-times result from the size of the data set, and that ii) training complex ML models\nmay be as costly. For example, depending on the speciﬁc conﬁguration, training a random forest (RF)\nclassiﬁer on the spread trading data can easily require more than 3 days.\n5. Experimental Design\nThe section describes the spread-trading data set, elaborates on the deﬁnition of A-book clients, and\nintroduces model evaluation criteria and benchmark classiﬁers. Figure 4 summarizes the empirical design\ntogether with core parts of our methodology and the proposed DNN.\n5.1. Dataset and Target Label Deﬁnition\nSTX provided 11 years of real-life trading data for the period November 2003 to July 2014. Overall,\nthe data includes the trades of 25, 000 active traders (over 30 million trades across 6064 diﬀerent ﬁnancial\ninstruments). To prepare the data for analysis, we replaced missing values using EM imputation and\nChebyshev’s method for outlier treatment [11].\n14\nIndividual Transactional \nBehaviour Data\nMarket Price  \nData\nClassified High/Low \nRisk Individual\nMissing Data(EM Imputation)&  Outliers (Chebyshev Method)\n&SMOTE (Class Imbalance) &IFBSA  (sensitivity analysis)\nClassic  ML methods\nLogistic\nANN\nRandom Forest\nAdaptive Boosting\nSVM\nNaïve Bayes\nC5.0 Tree\nOther DL models\n(FDNN, CNN, LSTM)\nValidation Measures:\nP&L, AUC, F-Score; \nBootstrap\nDNN Framework\nFigure 4: Topology of the DNN using sDA with 4 hidden layers with 128, 1024, 1024, 128 hidden units each. The output\nlayer predicts class probabilities based on the output of the last dropout layer using the softmax function. DNN predictions\nare compared to ML benchmarks for assessing predictive performance.\nSupervised learning requires a labeled data set D = {yj, xj}j=1...n, where xj is a vector of features\nthat characterize trade j, n = 30 million is the total number of trades in the data, and yi denotes the\ntarget variable. However, data characterizing an individual trade is limited. Relating trades to their\ncorresponding traders facilitates enriching the set of features by using information from previous trades\nj −k to decide on trade j.\nThe decision task of STX is whether to hedge trade j. Therefore, we consider a binary target:\nyij\n=\n\n\n\n\n\n+1 →hedge ,\niif Returni ≥5%\n−1\n,\notherwise\n(7)\nwith\n(8)\nReturni\n=\nP\n20<j≤100 P&Li,j\nP\n20<j≤100 Margini,j\nwhere i, j index trader i and trade j, respectively, P&L is the proﬁt and loss of trade j, and Margin\nis the amount of money required by the market maker in order to place the order, which normally equals\nthe stake size times the margin requirement. To label trade j, we determine the status of trader i at\nthe time of issuing that trade. We deﬁne trader i to be an A-book client if s/he secures a return above\n5% from her next hundred trades subsequent to j. Recall that the 5% threshold mimics the current\npolicy of STX. We also sustain the STX approach to hedge all trades from A-book clients. However, our\nmethod to deﬁne the client status and label their trades is forward looking whereas STX considers the\npast proﬁts of trader i. Our target label deﬁnition is also dynamic in that the trader status can change\n15\nwith every trade. According to that deﬁnition, 6.43% of the trades in the data set come from A-book\nclients and should be hedged.\nOf course, at the time when STX receives trade j, the future proﬁts of trader i are unknown. There-\nfore, we develop a prediction model to forecast yij from the information the company can observe at\nthe time when trade j is made. The feature vector xij includes demographic information of the client\nmaking trade j and information concerning the client’s trading behavior for the 20 trades prior to trade\nj. The decision to consider the past 20 trades is based on the hedging policy of STX, which uses a rolling\nwindow of the 20 trades prior to trade j to decide on the status of the client.\n5.2. Trader Characteristics and Feature Creation\nWe create variables for trader classiﬁcation based on interviews with experienced members of the\ndealing desk of STX. A ﬁrst round of interviews was aimed at identifying risk factors that domain experts\ndeem indicative of good/bad traders. Based on corresponding results, we developed a semi-structured\nsurvey that was presented to seven members of the dealing desk in a second round of interviews. The\nsurvey asked participants to evaluate behavioral traits, which emerged from the ﬁrst round, on a Likert\nScale from 1-7, where values of 1 and 7 represent a strong indication for bad and good trading behavior,\nrespectively. After completing the survey, we asked participants to suggest strategies they would apply\nif trading the FTSE100 index and a single stock from the FTSE100, respectively. This was to gather\nideas for novel factors not yet covered in the survey. The results of the interviews guided the feature\nengineering. A non-disclosure agreement with STX prohibits formally deﬁning all features. However,\nthe following description provides a comprehensive overview of the type of features and how they have\nbeen created. The features reﬂect the speciﬁc situation of STX. Risk analysts may ﬁnd the following\ndescription useful to inform feature engineering in related applications. However, since our study focuses\non the application of a DL methodology, it does not warrant claims related to generalizability of features.\nIn general, features split into ﬁve groups. The ﬁrst group comprises trader demographics such as age,\ncountry of origin, post code, employment status and salary group. Features of this group are nominal\nand enter ML models in the form a dummy codes. STX employs a range of socio- and micro-geographic\ndata to cluster post codes. They follow a similar logic to cluster countries. 2\nFeatures of the second group capture the past performance of traders. We use aggregations such as\nthe mean and standard deviation to calculate corresponding features over a rolling window of 20 previous\ntrades relative to the focal trade. The choice of a window size of 20 follows STX’s hedging policy at the\ntime of the study. In addition to proﬁtability, we compute a set of related performance indicators such\nas the average win rate, average number of points in proﬁt, whether a client has been in proﬁt, etc. We\nalso consider the risk adjusted return (i.e., Sharpe ratio [56] and features related to the number and sizes\nof past withdrawals and deposits).\n2 STX has not revealed details of their cluster mechanisms to us. However, they assured us that the clustering does not\nemploy any information of trader proﬁts, which might otherwise introduce a look-ahead bias through leaking information\nfrom the prediction target to the features.\n16\nA third group of features describes traders’ preferences related to markets and channels. For exam-\nple, one feature simply counts the number of markets in which a trader invests while another encodes\nwhether traders showed a strong preference for a speciﬁc market in their previous 20 trades. Using this\ninformation, we create features describing the most popular market cluster in a trader’s full history and\nlast 20 trades, respectively. The subgroup of channel preferences includes features that count the number\nof opening and closing trades made through the STX web front-end and mobile app, respectively, as well\nas ratios derived from these counts.\nResults of the survey identiﬁed the disposition eﬀect as a relevant factor to detect poor traders. The\ndisposition eﬀect [57] describes the phenomenon that investors tend to quickly sell trades that are in\nproﬁt but are reluctant to sell trades in loss. Features of the fourth group strive to capture the disposition\neﬀect. We determine per trader the average amount and time s/he leaves winning and loosing positions\nopen, and calculate their ratio. We also consider sums instead of averages and window lengths of the\nprevious 20 and all previous trades.\nAnother discriminating factor that emerged from the interviews concerns trading discipline. Members\nof the dealing desk pointed out that good traders display a tendency to set manual limits (stop losses\nand proﬁt levels) and when making proﬁts to move these with the market. The ﬁfth group of features\ncaptures signals concerning the consistency of a trader’s strategy. The variation index of stake sizes\nexempliﬁes corresponding features. We also consider simpler features such as the standard deviation of\nstake sizes and features that capture the frequency of trades as well as their variation. Other features in\nthis group relate to the tendency of clients to trade within/outside of normal trading hours (e.g., number\nand share of corresponding trades), which we consider an indicator of traders’ professionalism. The\ndegree to which traders partially close trades may also signal expertise and hence traders posing a higher\nrisk. Hence, we create a feature measuring the share of trades that have been closed in the previous 20\ntrades. The previous examples sketch the type of features we employ. Using operations such as varying\nwindow sizes, aggregation functions, creating dummy features through comparing a feature to a threshold\n(e.g., whether any of the last 20 trades has been closed using the mobile app), and considering bi-variate\ninteractions, we obtain a collection of close to 100 features. An objective of the paper is to test whether\nthe DNN can learn predictive higher-level features automatically. For example, the discussion on feature\nengineering suggests multicollinearity among features, which feature selection could remedy. However, a\nsub-goal following from our objective is to test how eﬀectively the DNN automatically discards redundant\nand irrelevant features. Therefore, we do not perform feature selection.\n5.3. Exploratory Data Analysis and Feature Importance\nTo shed light on how A-book and B-book clients diﬀer across the features, we report results of an\nexploratory data analysis. Table 2 reports descriptive statistics for the ten top-ranked features for A-book\nand B-book clients, respectively. We select these features according to the Fisher-score [7]. Features with\nthe suﬃx 20 are calculated over a window of 20 past trades relative to a focal trade. For example, given a\ntrade j (equivalent to one observation in the data set) from a trader i, we consider the j −1, j −2, ...j −20\ntrades of trader i and calculate their mean, standard deviation, etc. We use all available trades of a trader\n17\nif s/he has less than 20 trades. To ensure comparability across features, values in Table 2 are scaled to\nthe zero-one interval using min/max scaling.\nInterestingly, the Fisher-score ranks the feature PassAvgReturn20, which determines the current\nhedging policy of STX, as the tenth most important feature. This suggests that some improvement of\nthe current policy might be possible by basing decisions on one of the more important features such\nas ProﬁtxDur20, which is the top feature in the Fisher-score ranking. More generally, Table 2 reveals\nthat diﬀerences between the client groups in the means of variable values are small. This indicates that\ngood and bad traders cluster in the behavioral space spanned by these features and that a classiﬁcation\nof traders will be challenging. To support this view, we estimate a logistic regression model on the\ntraining set using the features of Table 2 and observe a McFadden R2 close to zero. Considering standard\ndeviations, Table 2 suggests that the trading behavior of B-book clients is slightly more volatile compared\nto A-book clients, which supports ﬁndings from the interviews that good traders follow a consistent\nstrategy. Table 2 also emphasizes the disposition eﬀect as a potentially discriminating factor. Several\nof the top ten features aim at capturing the disposition eﬀect through contrasting the duration with\nwhich traders keep winning versus losing positions. Last, the third and fourth moment of the feature\ndistributions hint at some diﬀerences between good and bad traders. However, as shown by the failure\nof the logistic regression, translating these diﬀerences into a classiﬁcation rule is diﬃcult and may be\nimpossible with a linear model. To further substantiate this interpretation, the online Appendix provides\nan analysis of feature importance using the RF classiﬁer [11]. RF-based importance weights (see Section\n3 of the online Appendix) diﬀer notably from Table 2 in that the ten most important features in terms\nof the Fisher-score achieve only moderate importance ranks according to RF. This may evidence the\nexistence of nonlinearity in the feature response relationships or feature interactions, both of which the\nFisher-score cannot accommodate. We further elaborate this point in Section 6.1 when re-appraising\nfeature importance using information fusion-based sensitivity analysis [58, 59] .\n5.4. Data Organization, Evaluation Criteria and Benchmark Classiﬁers\nWe use n-fold cross-validation to assess the predictive performance of ML models. Repeating model\nbuilding and assessment n times increases the robustness of results compared to a single partitioning of\nthe data into training and test set. We consider settings of n = 10 and n = 5 in subsequent comparisons.\nThe client classiﬁcation problem exhibits class imbalance and asymmetric error costs.\nA false negative (FP) error corresponds to misclassifying an A-book client as a B-book client. A\nfalse positive (FP) error describes the opposite case where a B-client is misclassiﬁed as high risk trader.\nThe economic implication of a FP error is that the market maker hedges a trade from a B-client. This\nis less suitable because B-clients lose money on average. These clients’ losses represent proﬁts to the\nmarket maker but are driven to zero if a trade is hedged. The FN error is more severe because failing\nto hedge a trade from a high risk trader may leave the market maker with a very large loss. To reﬂect\nthis cost asymmetry, we evaluate a classiﬁcation model in terms of the proﬁt or loss (P&L) that results\nfrom hedging trades according to model predictions.\nP&L accounts for the actual proﬁts/losses per trade. In addition, we average the P&L across trades\n18\nTable 2: Descriptive Statistics of Top-Ten Features\nFeature\nMean\nStd.Dev.\nSkew\nDescription\nA-book\nB-book\nA-book\nB-book\nA-book\nB-book\nProﬁtxDur20\n0.325\n0.332\n0.172\n0.178\n0.994\n0.962\nInteraction of ProﬁtRate20 and\nDurationRate20\nSharpeRatio20\n0.443\n0.446\n0.081\n0.085\n1.097\n1.131\nMean/st.dev. of returns\nProﬁtRate20\n0.496\n0.504\n0.241\n0.248\n0.346\n0.328\nAverage proﬁt rate of client\nWinTradeRate20\n0.621\n0.626\n0.203\n0.207\n-0.203\n-0.210\nClients average winning rate\nAvgOpen\n0.534\n0.539\n0.218\n0.228\n-0.345\n-0.311\nAverage\nof\nthe\nP&L\namong\ntrader’s ﬁrst 20 trades\nDurationRate20\n0.319\n0.322\n0.119\n0.121\n-0.148\n-0.161\nAverage time client leaves win-\nning vs losing position open\nPerFTSE20\n0.251\n0.244\n0.357\n0.353\n1.151\n1.197\nShare of trades placed in the\nFTSE100\nDurationRatio20\n0.127\n0.128\n0.067\n0.070\n3.398\n3.812\nMean trade duration (mins) /\nstd.dev. trade duration\nAvgShortSales20\n0.487\n0.482\n0.269\n0.274\n-0.027\n-0.018\nShare of short positions\nPassAvgReturn20\n0.502\n0.503\n0.052\n0.057\n-0.295\n0.065\nAvg. return up to last 20 trades\nfrom A-clients and B-clients. The resulting means provide an estimate of the average costs of a FN error,\ncF N, and a FP error, cF P, respectively. We then compute the average, class-dependent misclassiﬁcation\ncosts of a classiﬁer per trade as: cF N · FNR + cF P · FPR to obtain a second monetary performance\nmeasure. Grounding on class-speciﬁc averages as opposed to trade-level proﬁts/losses, the average mis-\nclassiﬁcation costs (AMC) is more robust toward the speciﬁc trades that a model classiﬁes (in)correctly\nand outliers, while the P&L reﬂects the true monetary implications of deploying a classiﬁer to our sample\nof data. Hence, the two measures complement each other.\nFinally, several standard indicators are available to assess the performance of a classiﬁcation model.\nTo obtain a broad view on model performance, we consider the area under a receiver-operating-characteristics\ncurve (AUC), sensitivity, speciﬁcity, precision, the G-mean, and the F-measure. The selection of perfor-\nmance indicators draws inspiration from prior literature [60, 61] and covers a range of popular indicators.\nA detailed discussion of their merits and demerits is beyond the scope of the paper but is available in the\nliterature [11]. Roughly speaking, the AUC assesses a classiﬁer’s ability to discriminate A- and B-book\nclients. Sensitivity and speciﬁcity depict class-level classiﬁer accuracy and thus the foundation of the\nAMC measure. Precision emphasizes a model’s ability to detect high risk traders while G-mean and the\nF-measure are designed for robustness toward class imbalance.\nTo compare the performance of our DNN to benchmarks, we select ﬁve ML classiﬁers as benchmarks,\nincluding logistic regression, ANNs, RF, adaptive boosting (Adaboost), and support vector machines\n(SVM). A comprehensive description of the classiﬁers is available in, e.g., [11]. We report the hyper-\nparameter settings that we consider during model selection in Section 2 of the online Appendix, where\nwe also elaborate on hyper-parameter tuning.\n19\n6. Empirical Results\nThe empirical analysis compares the DNN to benchmark classiﬁers and rule-based hedging strategies,\nwhich embody domain knowledge. It also sheds light on the origins of DNN performance.\n6.1. Predictive Accuracy of the DNN and ML-based Benchmark Classiﬁers\nWe ﬁrst present results concerning the predictive performance of diﬀerent classiﬁers across diﬀerent\nevaluation criteria in Table 3. Bold face highlights the best performing model per evaluation criteria.\nP&L and AMC values are measured in GBP and refer to an individual trade. For example, a P&L\nvalue of 121.67, which we observe for the DNN, implies that hedging incoming trades according to DNN\nrecommendations, the market maker would on average earn 121.67 GBP from each trade. A value of\n483.84 for AMC, on the other hand, indicates that an oracle model, which knows the outcome of each\nincoming trade and hedges accordingly, would produce 483.84 GBP proﬁt per trade for the market\nmaker. Clearly, the optimal hedging of an oracle model is a theoretical benchmark. All values in Table\n3 represent averages, which we obtain from 10-fold cross-validation.\nTable 3: Performance Comparison of the DNN vs. Benchmarks ML Classiﬁers\nP&L\nAMC\nAUC\nSensitivity\nSpeciﬁcity\nPrecision\nG-Mean\nF-score\nDNN\n121.67\n483.84\n0.814\n0.631\n0.994\n0.987\n0.792\n0.661\nLogit\n111.67\n926.45\n0.705\n0.293\n0.997\n0.982\n0.540\n0.402\nANN\n109.14\n915.73\n0.635\n0.301\n0.997\n0.982\n0.545\n0.408\nRandom Forest\n107.18\n928.61\n0.720\n0.291\n0.997\n0.983\n0.538\n0.404\nAdaBoost\n101.24\n937.48\n0.638\n0.284\n0.996\n0.981\n0.532\n0.383\nSVM\n68.34\n825.56\n0.691\n0.370\n0.995\n0.984\n0.598\n0.430\nTable 3 provides evidence for the superiority of the proposed DNN. It performs substantially better\nthan ML benchmarks across several performance indicators. The only exception is speciﬁcity where all\nclassiﬁers perform close to perfect and RF has a small edge over the other models. In terms of P&L,\nthe most relevant indicator for STX, we observe an improvement of nine percent compared to the logit\nmodel; the runner-up in terms of P&L. Improvements in the second monetary metric, AMC, are more\nsubstantial. The DNN performs roughly twice as good as ML benchmarks. Other indicators in Table\n3 clarify the origin of the AMC results. All classiﬁers achieve high speciﬁcity and precision, while we\nobserve sizeable diﬀerences in terms of sensitivity. Precision close to one indicates that whenever a model\nclassiﬁes a trade to pose high-risk and recommend hedging, this classiﬁcation is typically correct. This\nis true for every classiﬁer in the comparison. However, the DNN achieves higher sensitivity, meaning\nthat it identiﬁes a larger fraction of such high-risk trades. In consequence, the DNN hedges against\nmore trades that come from A-book clients and avoids corresponding losses. In this regard, one may\ninterpret Table 3 as evidence that the DNN implements a more prudent risk management strategy than\nthe benchmarks. Results in terms of G-mean and the F-measure conﬁrm that the DNN achieves a much\nbetter balance between sensitivity and speciﬁcity and precision, respectively. AUC results complement\n20\nthe evaluation and show that the DNN achieves better ranking performance. Ranking trades according\nto model-estimated class probabilities, the DNN discriminates A- and B-client trades more accurately\nthan the benchmarks, achieving 13 percent higher AUC than the (second best) RF classiﬁer.\nIn relation to monetary performance, it is interesting to consider why the DNN displays a larger edge\nover benchmarks in terms of AMC than in P&L. The two measures diﬀer by construction. P&L considers\nthe actual return from a trade, whereas AMC is based on the average return over A-client and B-client\ntrades, respectively.\nConsidering a trade that leaves the market maker with a large loss, P&L will\npenalize a wrong classiﬁcation of that trade more severely than AMC. Therefore, Table 3 indicates that\nthe DNN has misclassiﬁed some large loss trades, which benchmark models predicted correctly. This\nmight suggest that an ensemble of the DNN and other classiﬁers could perform even better than the\nDNN alone.\nHowever, exploiting synergy among diﬀerent classiﬁers is not trivial if their individual\nperformances are very diﬀerent.\nFor example, it is clear from Table 3 that a simple average of the\nforecasts of the DNN and one other classiﬁer will deteriorate predictive accuracy. Given the appealing\nperformance of the DNN in Table 3 we leave an evaluation of forecast combination for future research\nand focus our attention on clarifying the origins of DNN performance.\nThe performance of a classiﬁer depends on the features and their predictive value. The explanatory\ndata analysis did not identify single features with high predictive power. A simple logit model using\nonly the features of Table 2 performed close to random. To obtain a clearer view on the feature-response\nrelationship, we employ information-fusion based sensitivity analysis (IFBSA). Originally proposed by\n[58], IFBSA has been used in several studies to examine feature importance through the lens of multiple\nclassiﬁers [60, 62, 63]. IFBSA ﬁrst assesses the importance of an individual feature as the percentage ratio\nof the model error without this feature to the model error with that feature included [62]. IFBSA repeats\nthis assessment for all features. Evaluating the marginal impact of a feature on model performance, the\nﬁrst IFBSA step shares similarities with RF-based feature importance weights, which interested readers\ncan ﬁnd in the online Appendix. A crucial distinction between IFBSA and RF-based feature importance\nis that the former considers several diﬀerent classiﬁcation models (i.e., the classiﬁers of Table 3 in our\ncase). Let st (x) denote the prediction of classiﬁer t = 1, ..., T for feature vector x (e.g., p (A-client|x)).\nWe can then write the combined prediction of a committee of T classiﬁers as:\nˆyfused = ψ (s1 (x) , s2 (x) , ..., sT (x))\n(9)\nwhere ψ represents a mechanism to fuse individual classiﬁer predictions. Considering a linear fusion\nfunction with normalized weights ωt such that PT\nt=1 ωt = 1, equation (9) becomes [59]:\nˆyfused =\nT\nX\nt=1\nωtst (x)\n(10)\nIFBSA determines classiﬁer weights ωt based on the predictive performance of a classiﬁer. This ensures\nthat better classiﬁers such as the DNN in Table 3 receive higher weights while all classiﬁers’ opinions on\na feature are taken into account. More speciﬁcally, let Vt,k denote the normalized feature importance\nweight of feature k in classiﬁer t. Then, replacing predictions st (x) in (10) with Vt,k, we obtain the ﬁnal,\n21\nFigure 5: Feature importance according to IFBSA [58, 8]\nFigure 6: IFBSA importance per feature group.\nfused importance weight of that feature as [60]:\nVk (fused) =\nT\nX\nt=1\nωtVt,k (x)\n(11)\nApplying IFBSA to the classiﬁer results of Table 3, we obtain the distribution of fused feature\nimportance weights shown in Figure 5. We highlight features that the Fisher-score-based importance\nanalysis (see Table 2) identiﬁed as the top ten most important features. Figure 5 depicts aggregated\nIFBSA importance weights for each of the ﬁve groups of features in our data set.\nThe distribution of feature importance in Figure 5 displays two break points.\nThere is a small\nset of highly informative features. We also observe a large set covering roughly half of the remaining\nfeatures where importance ranks are moderate. IFBSA attributes relatively low importance weights to\nthe remaining features. The top-ten features of the Fisher-score assessment (see Table 2) belong to the\nsecond group. IFBSA judges these to be moderately important. Given that IFBSA and the Fisher-score\nincorporate fundamentally diﬀerent perspectives toward feature importance, diﬀerences between their\nimportance rankings are to be expected. We take Figure 5 as evidence of intricate dependencies between\nthe binary response and the features, which the Fisher-score does not capture. For example, the Fisher-\nscore ranking does not incorporate those features that IFBSA ﬁnds most relevant. It is tempting to\ncharacterize the three groups of features in Figure 5 as groups including features that are, respectively,\nnonlinearly related to the prediction target, linearly related, and unrelated. However, Table 3 challenges\nthis interpretation in that the linear logit model performs competitively to nonlinear classiﬁers. ANN,\nSVM, RF, etc. should be able to extract predictive value from the top-ranked features in Figure 5 beyond\nthat which the logit model is able to extract if these features were nonlinearly related to the target. Yet,\nacross several indicators of predictive performance, their forecasts do not appear to be more accurate\nthan those of the logit model. Recall that IFBSA discounts feature importance signals of all classiﬁers\nbut weights these according to classiﬁer performance when computing ﬁnal, fused feature importance\n22\nweights via (10) and (11). Table 3 shows the DNN to perform substantially better than the benchmarks.\nAccordingly, fused weights are slightly geared toward DNN results (ωDNN ≈20 percent). Therefore, we\nexpect the ranks in Figure 5 to also reﬂect a feature’s contribution to a latent, abstract representation of\ntraders’ behavioral characteristics, which the DNN distills from the data through its deep architecture.\nHowever, this interpretation requires further analysis to better understand the origin of DNN success\nand how it connects to the features. Subsequent sections shed light on these matters. To conclude the\nfeature importance evaluation using IFBSA we note from Figure 6 that the overall amount of predictive\ninformation within the features distributes evenly across the ﬁve categories of features.\n6.2. Antecedents of DNN Forecast Accuracy\nTable 3 evidences the superiority of the DNN over ML-benchmarks for the speciﬁc data set used\nhere. To examine the robustness of model performance, it is important to clarify the antecedents of\nDNN success. One characteristic of the DNN is its multilayered - deep - architecture. Prior research\nestablishes a connection between the depth of a model and its expressive capacity [26], which suggests\ndepth to be a determinant of predictive accuracy. The use of unsupervised pre-training also distinguishes\nthe DNN from the ML benchmarks. Aiding model training through ﬁnding more abstract, generative\nfeatures, we expect predictive accuracy to beneﬁt from pre-training. A third factor of interest is class\nimbalance. Skewed class distributions are a well-known impediment to classiﬁcation. The DNN being\nmore robust toward class imbalance could thus also explain the results of Table 3. In the following, we\nexamine the inﬂuence and importance of these three factors.\n6.2.1. The Deep Architecture\nThe DNN generates predictions in the last layer, where the last layer output neuron receives the\ncombined input from multiple previous layers of SdAs and translates these signals into class probability\npredictions using the softmax function.\nThis network conﬁguration is equivalent to running logistic\nregression on the output of the hidden layers. To shed light on the value of the deep architecture, we\ncompare DNN predictions to predictions from an ordinary logistic regression with the original features\nas covariates. The logistic model represents an approach which takes away the deep hidden layers from\nthe DNN and only sustains the last layer. This is useful for appraising the merit of the distributed\nrepresentations, which the deep hidden layers extract from the raw features.\nFigure 7 displays the receiver-operating-characteristics (ROC) and a Precision-Recall (PR) curve\nfor the DNN and a simple logit model. The plot emphasizes that the deep architecture substantially\nimproves the network’s discriminative ability. The performance of the logit model on raw features is\nalmost random. The AUC value of 0.812 for the DNN suggests that performing the same regression on\nthe high level representations, which the DNN learns from the raw features, facilitates a reliable detection\nof the positive class. Consequently, the DNN succeeds in extracting predictive features from the input\ndata. In appraising Figure 7 it is important to note that the logit model is not meant to contribute a\nstrong benchmark. As shown in Table 3, a regularized logit model with feature selection performs better\nthan random. The purpose of Figure 7 is to evaluate the overall eﬀect of the deep architecture compared\nto using the raw features as is, which motivates using the ordinary logit model for this comparison.\n23\nThe overall conclusion emerging from the analysis is that the deep architecture aﬀects the predictive\nperformance of the DNN.\nROC / Precision−Recall Curve\nRecall / False Positive Rate\nPrecision\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n0.2\n0.4\n0.6\n0.8\nTrue Positive Rate\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLogistic\n[ 0.092, 0.481 ]\nDeep Learning\n[ 0.286, 0.812 ]\nFigure 7: ROC (black), Precision-Recall Curve (grey) of DL and logit.\n6.2.2. Unsupervised Pre-Training\nThe proposed DNN uses unsupervised pre-training for representation learning and feature extraction.\nTo conﬁrm the merit of pre-training, we examine the discriminative strength of each neuron in the unsu-\npervised pre-training stage. We aim to check whether DNN learns distributed representations that help\ndiﬀerentiate A- and B-book clients from unlabeled data. To that end, Figure 8 provides the histograms\nof activation values for neurons in the ﬁrst dA layer of the DNN. The histograms show that activation\nvalues tend to be less than 0.4 when receiving a trade from a B-book client. Trades from A-book clients\ntypically result in an activation value of 0.4 and above. While the magnitude of the activation values\nis irrelevant, the discrepancy of activation values for trades from diﬀerent types of clients illustrates\nthat - even with unlabeled data - the neurons in the ﬁrst dA layer diﬀerentiate A- from B-book client\ntrades. The intricate non-linear transformation between layers prohibit a replication of this analysis for\nhigher layers because the relationship between activation values and input signals is no longer monotone.\nHowever, Figure 8 provides preliminary evidence that the spread trading data facilitates the extraction\nof higher-level generative features using pre-training.\nTo gain more insight into the link between activation values and trades from diﬀerent types of traders,\nwe examine whether trades that trigger high activation values in a neuron are worth hedging. We ﬁrst\ncalculate the maximum and minimum activation values for every neuron of the ﬁrst layer, and 20 equally\nspaced threshold values between these boundaries. Subsequent analysis is based on a single neuron.\nWe chose the neuron and corresponding threshold that give the purest separation between A- and B-\nbook client trades (see Figure 8) upon manual inspection. Using this neuron, we ﬁnd the 100 trades\nthat activate the neuron the most. Figure 9 plots these trades on the overall P&L distribution. The\nresults illustrate that, with a few false negatives, 97% of the trades that maximally activate the neuron\n24\nActivation Value\nDensity\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\nFigure 8: Histogram of ﬁrst dA layer activation values for\nA-book (dark color) and B-Book (light color) client trades.\n−5000\n0\n5000\n0.0000\n0.0005\n0.0010\n0.0015\nProfit & Loss\nDensity\nJohnson Su\nMean: −97.35,\nSkew: −88.02,\nKurtosis: 753381\nFigure 9: Top 100 stimuli of the best neuron\nfrom the test set\nend in proﬁt and leave the market maker with a loss. Hedging against these trades, as indicated by\nthe neuron’s activation levels, is economically sensible. Although the eventual hedging decisions are\nbased on the prediction of the DNN as a whole, the single neuron analysis provides further evidence of\nunsupervised pre-training of SdA layers to extract patterns that are indicative of a trade’s risk. This\nconﬁrms that the DNN learns distributed representations from the input data, which eventually help to\ndistinguish high risk traders from other clients.\n6.2.3. Analysis of the Class Imbalance Eﬀect\nA growing body of literature on deep imbalanced learning indicates that DL models inherit vulner-\nability toward class imbalance from their ML ancestors [64]. On the other hand, pre-training might\nequip the proposed DNN with some robustness toward class skew. Pre-training is carried out in an\nunsupervised manner so that class imbalance cannot impede model training. Figure 8 indicates that,\nwithout having access to class labels, pre-training has extracted patterns that help to diﬀerentiate high\nrisk traders and B-book clients. Only the DNN has access to this information, which might give it an\nadvantage over the ML benchmarks in the comparison of Table 3. To test this, we repeat the comparison\nafter addressing class imbalance using the SMOTE (synthetic minority class oversampling technique)\nalgorithm. SMOTE remedies class skew through creating artiﬁcial minority class examples in the neigh-\nborhood of actual minority class cases [65]. We execute SMOTE until the number of artiﬁcially created\nA-book clients equals that of the B-book clients, and repeat the comparison of classiﬁers on the over-\nsampled data. Since SMOTE increases the number of observations and, in turn, the time to train a\nmodel, we reduce the number of cross-validation folds to ﬁve. Note that oversampling occurs only in the\ntraining data. The validation fold reﬂects the true class distribution in the data to give an unbiased view\non model performance. Table 4 details the classiﬁers’ predictive performance on the oversampled data.\nWe ﬁnd SMOTE to improve all classiﬁers.\nWith very few exceptions, results in Table 4 display\nhigher performance compared to Table 3 and the magnitude of the improvement is often substantial.\n25\nTable 4: Predictive Performance of the DNN vs. Benchmark ML Classiﬁers After Applying SMOTE\nP&L\nAMC\nAUC\nSensitivity\nSpeciﬁcity\nPrecision\nG-Mean\nF-score\nDNN\n283.31\n243.17\n0.889\n0.815\n0.996\n0.992\n0.896\n0.804\nLogit\n260.45\n525.57\n0.806\n0.600\n0.983\n0.979\n0.751\n0.397\nANN\n233.55\n484.19\n0.858\n0.632\n0.974\n0.967\n0.785\n0.438\nRandom Forest\n262.85\n581.22\n0.792\n0.557\n0.988\n0.979\n0.742\n0.519\nAdaBoost\n259.45\n484.19\n0.803\n0.632\n0.974\n0.967\n0.785\n0.438\nSVM\n204.35\n930.26\n0.825\n0.619\n0.992\n0.984\n0.779\n0.522\nFor example, the AUC of the DNN is nine percent higher (0.889 c.f. 0.814) when using SMOTE. Other\nclassiﬁers experience a similar or larger improvement.\nThe ANN classiﬁer, for example, achieves an\nAUC that is 35 percent better with SMOTE (0.858 c.f. 0.635). The sensitivity results are substantially\nbetter, which conﬁrms that SMOTE has increased a classiﬁer’s awareness of the minority class. Higher\nsensitivity often comes at the price of reduced speciﬁcity and precision. However, Table 4 reveals that\nclassiﬁer performance in terms of both speciﬁcity and precision is almost as good as before applying\nSMOTE. Accordingly, the G-mean and F-score emphasize that SMOTE achieves a much better balance\nbetween sensitivity (recall) and speciﬁcity and precision, respectively.\nLikewise, P&L and AMC are\nmagnitudes better with SMOTE.\nWe also ﬁnd some evidence that the margin by which the DNN outperforms ML benchmarks decreases.\nConsidering for example the AUC, which gives an overall assessment of a classiﬁers discriminatory ability,\nthe strongest benchmarks after oversampling is ANN, which the DNN outperforms by a margin of 3.6\npercent (0.889 c.f. 0.858). In Table 3, the edge of the DNN over the runner-up in AUC was 13 percent\n(0.814 c.f. 0.720 for RF). An interpretation of this tendency is that Table 3 gives an optimistic picture of\nDNN performance. The accuracy gap between the DNN and the ML benchmarks is less than that which\nTable 3 suggests if ML benchmarks receive auxiliary tuning in the form of remedying class imbalance\nusing SMOTE. However, this view also implies that the DNN to be more robust toward class imbalance.\nWhile beneﬁting from SMOTE, its ability to identify high risk traders accurately is less dependent\non oversampling the minority class compared to the ML benchmarks. This interpretation follows from\nexamining the magnitude of performance improvement in Table 4 compared to Table 3, which is typically\nsmaller for the DNN than for ML benchmarks. Higher robustness toward imbalance agrees with results\nof Figure 8 concerning the merit of unsupervised pre-training.\n6.3. Implications for Risk Management\nA model-based hedging policy comprises hedging the trades of clients classiﬁed as A-book by the\nmodel and taking the risk of all other trades. To clarify the managerial value of the proposed DNN, we\ncompare its P&L to that of rule-based hedging strategies. One rule-based approach is the current policy\nof STX, which involves hedging trades of clients who secured a return above ﬁve percent in their previous\n20 trades. In addition, we develop three custom hedging heuristics. Our ﬁrst policy, Custom 1, relies on\n26\nFigure 10: Average P&L per trade in GBP of the DNN and Rule-Based Hedging Policies\nthe Sharpe Ratio and singles out traders who achieve a higher than average Sharpe ratio in their past\n20 trades. We suggest that securing risk-adjusted returns above the average indicates trader expertise.\nSince professionalism is only one reason for a successful trading history, Custom 2 heuristic addresses\nanother group of traders, which we characterize as overconﬁdent. Such traders may display higher yields\nthan other market participants and exhibit aggressive trading behavior, manifesting itself through bigger\nlot sizes, higher frequency and shorter time interval trades [66]. The Custom 2 heuristic thus considers\nthe average trade duration and number of trades to deduce traders who may pose a greater risk. The\nthird strategy, Custom 3, hedges trades from clients with a positive track record since trading with STX.\nThe rationale is that traders who are unsuccessful in their early experiences might quit. Traders with a\nlonger track record are either truly successful (and should be hedged against) or gamblers with a negative\nexpected value (and should not be hedged against). Following this line of thinking, the most important\nrisk STX is facing comes from new A-book clients. Comparisons to Custom 3 shed light on the ability\nof the DNN to identify such new A clients, as improvement over Custom 3 signals the DNN recognizing\nhigh risk traders that the track record-based logic of Custom 3 fails to capture.3 We also consider an\nensemble of the custom rule-based heuristics, constructed by means of majority voting.\nDrawing on domain knowledge, the rule-based strategies adopt a deductive approach. To complement\nthe analysis, we add an inductive approach in the form of a classiﬁcation tree. Trees are regarded as\ninterpretable classiﬁers. However, the degree to which decision makers can understand trees depends on\ntheir depth. In the interest of interpretability, we consider a classiﬁcation tree (ctree) with two levels.\nFigure 10 reveals the current policy of STX to be the most suitable deductive hedging strategy. The\nlogic of Custom 1 - 3 draws on ﬁnancial theory. However, each of the three approaches, as well as an\nensemble of them, performs worse than a hypothetical baseline setting in which STX would not hedge\nany trade. Observing Custom 1 - 3 to perform worse than this baseline supports the view that the focal\ntrader classiﬁcation task represents a challenging problem. Following this line of reasoning, Figure 10\n3We are grateful to an anonymous reviewer who suggested the logic of the Custom 3 heuristic.\n27\nalso emphasizes the soundness of the STX policy.\nUnlike the deductive STX approach, the tree-based heuristic learns from past data. We observe the\ntree to use three features: a trader’s average P&L in their initial 20 trades with STX, the minimum\nnumber of minutes until closing a losing position in their last 20 trades, and the average Sharpe ratio\nover their last 20 trades. These features display similarity with the custom heuristics. For example,\nconsidering a trader’s initial performance follows the logic of Custom 3. Accounting for risk-adjusted\nreturns is similar to Custom 1. Finally, considering a trader’s reaction toward losses, the tree uses one\nof the variables capturing the disposition eﬀect. We observe the two-level tree to produce slightly larger\nP&L than the STX heuristic. This suggest that a trader’s average past performance, embodied in the\nSTX approach, approximates the more complex rule set of the tree with some accuracy. Although the\ncriticality of accurate hedging in the spread trading market suggests a revision of the STX approach\nwith a tree-based approach, another ﬁnding from Figure 10 is that implementing a DNN-based hedging\nstrategy enables STX to further improve P&L compared to its current policy and the other rule-based\nhedging strategies we consider. Compared to the STX heuristic, the DNN raises per trade proﬁts by\n121.67 - 88.28 = 33.40 GBP, which implies a substantial improvement.\nThe STX heuristic represents an established business practice at the partner company and reﬂects\nmany years of industry experience. Moreover, the heuristic is extremely fast to execute and completely\ntransparent. The situation for the DNN is far diﬀerent. Classifying incoming trades more accurately,\na DNN-based hedging policy is more proﬁtable than rule-based approaches. The main cost of accuracy\nand proﬁtability improvements is the black-box character of the corresponding risk management system.\nThe client classiﬁcation rules from the DNN originate from automatically extracted distributed repre-\nsentations of high risk traders. The business logic encapsulated in these rules is not interpretable for\ndecision-makers, which also prohibits testing the agreement of these rules with domain knowledge.\nImproved performance of the DNN leaves risk managers with the task to decide whether performance\nimprovements are large enough to compensate the opaqueness of DNN and associated disadvantages,\nsuch as a lack of justiﬁability, higher computational requirements, etc. In the case of STX, we expect\nthe imperative to hedge trades accurately and the magnitude of the performance improvement observed\non their data to justify the adoption of a sophisticated DNN-based hedging strategy. The same might\nbe true for other the spread-trading companies, although these would ﬁrst need to replicate the results\nof this study to conﬁrm the eﬀectiveness of the DNN. A detailed description of the DNN conﬁguration\nin the paper and especially the online Appendix will simplify this task (see Algorithm 1 in the online\nAppendix).\nA more strategic consideration is that reluctance to adopt a new technology such as a\nsophisticated DNN-based hedging policy might harm the competitive position of STX if competitors\ndeploy corresponding solutions and use them to oﬀer better prices to retail investors. At the same time,\nwe caution against an overly optimistic view toward advanced DL-based decision aids. The empirical\nresults observed in this study come from a single data source, which, although large in size, reﬂects the\npeculiarities of the market position and client structure of STX, and require a replication with diﬀerent\ndata in future research to raise conﬁdence in the superiority of DL that we observe here.\n28\nFigure 11: Retail traders’ average winning ratio and average P&L points (proﬁt in dark, loss in grey) on diﬀerent categories\nof investments on the spread trading market.\n7. Discussion\nThe empirical results suggest the DNN to outperform rule-based and ML benchmarks. It identiﬁes\nhigh risk traders more accurately than other classiﬁers and provides higher ﬁnancial gains when used\nfor hedging decisions. Striving to explain the inferior performance of ML benchmarks, we note that\npredicting traders’ risk taking behavior and future proﬁtability under dynamic market conditions is a\nchallenging task. Traders diﬀer in their characteristics and trading behavior, and both are likely to\nchange over time. Identifying unskilled traders is especially diﬃcult due to the high variation in both\nbehavior (input) and performance (output). Compared to genuine good traders, it is harder to identify\nuniform trading patterns for poor traders. Interviews with STX’s staﬀhint at skilled traders sharing\ncertain characteristics such as the ability to capture market rallies, following a consistent strategy, setting\nand adjusting limits, etc. There are countless ways in which poor traders lose money, including ignoring\nany of the above rules. In the high dimensional behavioral space, the number of potential variations of\npoor traders is innumerable. This contradicts the prior assumption of ML methods that the distribution\nP(label|features) is smooth and well represented in the training data. Although based on an economic\nrationale, input features relating to past risk-adjusted return, trading frequency, etc. do not facilitate\nan accurate discrimination of spurious from genuine good traders. This arises because several feature\nvalues may coincide. The entanglement of spurious and genuine good traders in the behavioral feature\nspace of trader characteristics complicates the trader classiﬁcation problem. Moreover, the chance of\nmaking proﬁt in the spread-trading market is highly noisy. Even poor traders can, by luck, win money.\nIn fact, Figure 11 reveals that most of the clients who trade with STX have a greater than ﬁfty percent\nwin/lose ratio. However, Figure 11 also shows that average losses exceed average winnings by a large\nmargin. Therefore, it is often sensible to classify a trader as a B-client and refrain from hedging their\ntrades, even if many of their previous trades ended in proﬁt.\nThe deep architecture equips DNN with higher expressive capacity to store the large number of vari-\nations of trading behaviors. Increased depth enables the DNN to proﬁle new combinations of behavioral\nvariations and generalize to new trading patterns less represented in the training data. Furthermore,\na speciﬁc DNN component we employ for trader classiﬁcation is unsupervised pre-training. Observed\nresults conﬁrm that pre-training enables the DNN to construct layers of feature detectors that capture\n29\nunderlying generative factors, which explain variations across diﬀerent trading behaviors. Stacking mul-\ntiple layers of progressively more sophisticated feature detectors, the DNN learns to disentangle these\nfactors from the input distribution. Variations that are important for subsequent discrimination are\nampliﬁed, while irrelevant information within the input data is suppressed [67]. We examine this ability\nin Figure 7, 8 and 9. After pre-training, the higher levels of the feature hierarchy store robust, infor-\nmative, and generalizable representations that are less likely to be misled - and, thus, invariant to - the\nentangling of trading patterns in the input-space. In summary, the DNN draws upon the raw features\nand creates sensible abstractions from these features that exhibit a stronger connection with the target\nand facilitate predicting that target with higher accuracy.\n8. Conclusions\nWe set out to examine the eﬀectiveness of DL in management support. Corresponding applications\noften involve developing normative decision models from structured data. We focus on ﬁnancial risk\ntaking behavior prediction and develop a DNN-based risk management system.\nThe results obtained throughout several experiments conﬁrm the ability of DL, and the speciﬁc\narchitecture of the DNN we propose, to extract informative features in an automatic manner. We also\nobserve DNN-based predictions of trader behavior based on these features to be substantially more\naccurate than the forecasts of benchmark classiﬁers. Finally, our results demonstrate that improvements\nin forecast accuracy translate into sizable increases in operating proﬁt. This conﬁrms the ability of the\nproposed DNN to eﬀectively support (hedging) decision-making in our risk management case study.\nMore generally, we provide evidence that the characteristic features of DL may generalize to the\nstructured data sets commonly employed in retail ﬁnance and corporate decision support. In particular,\nwe demonstrate that it is possible to successfully model patterns associated with individual behaviour\n(which can be variable, erratic and dynamic), in an automatic manner to generate features that determine\na target measure (e.g. proﬁtability). For the case study explored here, we faced the challenges of class\nimbalance, concept drift (which arises in dynamic environments), the curse-of-dimensionality and the\nhigh costs to develop and revise hand-crafted features in response to external changes. Many of these\nchallenges are faced by those seeking to predict human behaviour in related ﬁelds. Until now, most of\nthese tasks have been tackled using a range of statistical and ML techniques. Our ﬁndings, open up the\npossibility of employing a similar DL architecture to that adopted here to tackle a range of consumer\nrelated prediction tasks, such as helping banks improve their risk control by making eﬀective credit\napproval decisions and predicting the solvency of corporate borrowers, of assisting governments predict\nhow consumers will respond to tax and regulation changes, and supporting companies in marketing\ndecisions involving churn prediction, response modelling and cross-/up selling. Many of these tasks rely\non structured data, and we have shown that the DL methodology we propose can improve forecasting\naccuracy in settings that require the prediction of human behaviour based on structured data.\nA distinctive feature of our case study stems from the fact that a small group of individuals pose very\nhigh risk. In theory, a single trade can result in unbounded losses in the spread trading market. High\nrisk individuals (A-clients) are only a small fraction of the population but determine the overall risk\n30\nexposure of the market maker to a large extent. This characteristic sets our study apart from standard\ncredit scoring settings and other ﬁnancial applications where losses are often bounded. Thus, our study\ncontributes to new ways of managing major risks coming from minority individuals.\nDNNs may be\nparticularly suitable for developing decision support system to tackle challenges with similar features\nsuch as insider or malicious behaviour detection, fraud modeling, or cyber-attack, where only a small set\nof professionals can cause major losses for an enterprise.\nA fruitful area for future research will be to explore to what extent the architecture adopted here\nproves eﬀective and/or to what extent it needs to be adapted to meet the particular demands of other\nhuman behaviour-related forecasting tasks. Future work exploring the extent to which networks with\nsupervised and unsupervised layers such as SdA, which we ﬁnd to work well in risk analytics, is of\nparticular interest to us since unsupervised learning oﬀers advantages when labeled data is sparse. Having\ndemonstrated that signiﬁcant gains can be made in forecasting accuracy in one setting involving the\nprediction of human behaviour, our hope is that this leads to future studies demonstrating that DL can\nhelp solve many of the worlds problems associated with unpredictable human behaviour.\nAcknowledgement\nWe thank the editor, Prof. Teunter, for his eﬀorts in handling our paper and are thankful to three\nanonymous reviewers whose feedback has helped tremendously to improve earlier versions of the paper.\nWe are especially grateful to J.C. Moreno Paredes for his invaluable help with data preparation.\nReferences\nReferences\n[1] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, Nature 521 (7553) (2015) 436–444.\n[2] R. Geng, I. Bose, X. Chen, Prediction of ﬁnancial distress: An empirical study of listed chinese\ncompanies using data mining, European Journal of Operational Research 241 (1) (2015) 236–247.\n[3] Y. Bengio, Learning deep architectures for AI, Foundations and trends R⃝in Machine Learning 2 (1)\n(2009) 1–127.\n[4] J. Schmidhuber, Deep learning in neural networks: An overview, Neural Networks 61 (2015) 85–117.\n[5] W. Liu, Z. Wang, X. Liu, N. Zeng, Y. Liu, F. E. Alsaadi, A survey of deep neural network architec-\ntures and their applications, Neurocomputing 234 (2017) 11–26.\n[6] Z.-Y. Chen, Z.-P. Fan, M. Sun, A multi-kernel support tensor machine for classiﬁcation with mul-\ntitype multiway data and an application to cross-selling recommendations, European Journal of\nOperational Research 255 (1) (2016) 110–120.\n[7] W. Verbeke, K. Dejaeger, D. Martens, J. Hur, B. Baesens, New insights into churn prediction in the\ntelecommunication sector: A proﬁt driven data mining approach, European Journal of Operational\nResearch 218 (1) (2012) 211–229.\n31\n[8] A. Oztekin, R. Kizilaslan, S. Freund, A. Iseri, A data analytic approach to forecasting daily stock\nreturns in an emerging market, European Journal of Operational Research 253 (3) (2016) 697–710.\n[9] P. du Jardin, A two-stage classiﬁcation technique for bankruptcy prediction, European Journal of\nOperational Research 254 (1) (2016) 236–252.\n[10] S. Lessmann, B. Baesens, H.-V. Seow, L. C. Thomas, Benchmarking state-of-the-art classiﬁcation\nalgorithms for credit scoring: An update of research, European Journal of Operational Research\n247 (1) (2015) 124–136.\n[11] T. Hastie, R. Tibshirani, J. H. Friedman, The Elements of Statistical Learning, 2nd Edition,\nSpringer, New York, 2009.\n[12] J. N. Crook, D. B. Edelman, L. C. Thomas, Recent developments in consumer credit risk assessment,\nEuropean Journal of Operational Research 183 (3) (2007) 1447–1465.\n[13] G. L. Lilien, Bridging the academicpractitioner divide in marketing decision models, Journal of\nMarketing 75 (4) (2011) 196–210.\n[14] C. Hsinchun, R. H. L. Chiang, V. C. Storey, Business intelligence and analytics: From big data to\nbig impact, MIS Quarterly 36 (4) (2012) 1165–1188.\n[15] M. Kraus, S. Feuerriegel, A. Oztekin, Deep learning in business analytics and operations research:\nModels, applications and managerial implications, European Journal of Operational Research forth-\ncoming.\n[16] J. B. Heaton, N. G. Polson, J. H. Witte, Deep learning for ﬁnance: deep portfolios, Applied Stochas-\ntic Models in Business and Industry 33 (1) (2017) 3–12, asmb.2209.\n[17] J. Sirignano, Deep learning for limit order books, CoRR abs/1601.01987.\nURL https://arxiv.org/abs/1601.01987\n[18] M. Kraus, S. Feuerriegel, Decision support from ﬁnancial disclosures with deep neural networks and\ntransfer learning, Decision Support Systems 104 (2017) 38–48.\n[19] T. Fischer, C. Krauss, Deep learning with long short-term memory networks for ﬁnancial market\npredictions, European Journal of Operational Research 270 (2) (2018) 654–669.\n[20] N. Huck, Pairs selection and outranking: An application to the S&P 100 index, European Journal\nof Operational Research 196 (2) (2009) 819–825.\n[21] Y. Deng, F. Bao, Y. Kong, Z. Ren, Q. Dai, Deep direct reinforcement learning for ﬁnancial signal\nrepresentation and trading, IEEE Transactions on Neural Networks and Learning Systems 28 (3)\n(2017) 653–664.\n[22] R. Xiong, E. P. Nichols, Y. Shen, Deep learning stock volatility with google domestic trends, CoRR\narXiv:1512.04916v3.\n32\n[23] S. P. Chatzis, V. Siakoulis, A. Petropoulos, E. Stavroulakis, N. Vlachogiannakis, Forecasting stock\nmarket crisis events using deep and statistical machine learning techniques, Expert Systems with\nApplications 112 (2018) 353–371.\n[24] P. M. Addo, D. Guegan, B. Hassani, Credit risk analysis using machine and deep learning, Risks\n6 (2) (2018) 1–20.\n[25] J. A. Sirignano, A. Sadhwani, K. Giesecke, Deep learning for mortgage risk (2016).\nURL https://people.stanford.edu/giesecke/\n[26] G. F. Montufar, R. Pascanu, K. Cho, Y. Bengio, On the number of linear regions of deep neural\nnetworks, in: Advances in Neural Information Processing Systems, 2014, pp. 2924–2932.\n[27] Y. Bengio, I. Goodfellow, A. Courville, Deep learning, MIT Press, 2016.\n[28] C. L. Giles, S. Lawrence, A. C. Tsoi, Noisy time series prediction using recurrent neural networks\nand grammatical inference, Machine Learning 44 (1) (2001) 161–183.\n[29] A. Oztekin, R. Kizilaslan, S. Freund, A. Iseri, A data analytic approach to forecasting daily stock\nreturns in an emerging market, European Journal of Operational Research 253 (3) (2016) 697–710.\n[30] C. Brady, R. Ramyar, White paper on spread betting, Lond. Cass Bus. Sch.\n[31] N. Huck, Pairs trading and outranking: The multi-step-ahead forecasting case, European Journal\nof Operational Research 207 (3) (2010) 1702–1716.\n[32] F. Shen, J. Chao, J. Zhao, Forecasting exchange rate using deep belief networks and conjugate\ngradient method, Neurocomputing 167 (2015) 243–253.\n[33] M. Dixon, D. Klabjan, J. H. Bang, Classiﬁcation-based ﬁnancial markets prediction using deep\nneural networks, Algorithmic Finance 6 (3-4) (2017) 67–77.\n[34] W. Bao, J. Yue, Y. Rao, A deep learning framework for ﬁnancial time series using stacked autoen-\ncoders and long-short term memory, PLOS ONE 12 (7).\n[35] C. Krauss, X. A. Do, N. Huck, Deep neural networks, gradient-boosted trees, random forests:\nStatistical arbitrage on the S&P 500, European Journal of Operational Research 259 (2) (2017)\n689–702.\n[36] Y. Zhao, J. Li, L. Yu, A deep learning ensemble approach for crude oil price forecasting, Energy\nEconomics 66 (2017) 9–16.\n[37] Y. Baek, H. Y. Kim, Modaugnet: A new forecasting framework for stock market index value with an\noverﬁtting prevention lstm module and a prediction lstm module, Expert Systems with Applications\n113 (2018) 457–480.\n[38] H. Y. Kim, C. H. Won, Forecasting the volatility of stock price index: A hybrid model integrating\nlstm with multiple garch-type models, Expert Systems with Applications 103 (2018) 25–37.\n33\n[39] N. Huck, Large data sets and machine learning: Applications to statistical arbitrage, European\nJournal of Operational Research 278 (1) (2019) 330–342.\n[40] B. Ribeiro, N. Lopes, Deep belief networks for ﬁnancial prediction, in:\nB.-L. Lu, L. Zhang,\nJ. Kwok (Eds.), Proccedings of the International Conference on Neural Information Processing\n(ICONIP’2011), Neural Information Processing, Springer Berlin Heidelberg, Berlin, Heidelberg,\n2011, pp. 766–773.\n[41] S. H. Yeh, C. J. Wang, M. F. Tsai, Deep belief networks for predicting corporate defaults, in:\nProceedings of the 24th Wireless and Optical Communication Conference (WOCC), IEEE Computer\nSociety, 2015, pp. 159–163.\n[42] J. Lee, D. Jang, S. Park, Deep learning-based corporate performance prediction model considering\ntechnical capability, Sustainability 9 (6) (2017) 899–911.\n[43] C. Luo, D. Wu, D. Wu, A deep learning approach for credit scoring using credit default swaps,\nEngineering Applications of Artiﬁcial Intelligence 65 (2017) 465–470.\n[44] J. Jurgovsky, M. Granitzer, K. Ziegler, S. Calabretto, P.-E. Portier, L. He-Guelton, O. Caelen,\nSequence classiﬁcation for credit-card fraud detection, Expert Systems with Applications 100 (2018)\n234–245.\n[45] M. Pryor, The Financial Spread Betting Handbook 2e: A Guide to Making Money Trading Spread\nBets, Harriman House Limited, 2011.\n[46] T. Serre, G. Kreiman, M. Kouh, C. Cadieu, U. Knoblich, T. Poggio, A quantitative theory of\nimmediate visual recognition, Progress in brain research 165 (2007) 33–56.\n[47] A. Ula, O. T. Yldz, E. Alpaydn, Eigenclassiﬁers for combining correlated classiﬁers, Information\nSciences 187 (0) (2012) 109–120.\n[48] Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle, et al., Greedy layer-wise training of deep net-\nworks, Advances in neural information processing systems 19 (2007) 153.\n[49] H. Larochelle, Y. Bengio, J. Louradour, P. Lamblin, Exploring strategies for training deep neural\nnetworks, The Journal of Machine Learning Research 10 (2009) 1–40.\n[50] J. Luo, X. Yan, Y. Tian, Unsupervised quadratic surface support vector machine with application\nto credit risk assessment, European Journal of Operational Research 280 (3) (2020) 1008–1017.\n[51] G. Hinton, S. Osindero, Y.-W. Teh, A fast learning algorithm for deep belief nets, Neural computa-\ntion 18 (7) (2006) 1527–1554.\n[52] Y. Bengio, O. Delalleau, Justifying and generalizing contrastive divergence, Neural Computation\n21 (6) (2009) 1601–1621.\n34\n[53] P. Vincent, H. Larochelle, Y. Bengio, P.-A. Manzagol, Extracting and composing robust features\nwith denoising autoencoders, in: Proceedings of the 25th International Conference on Machine\nlearning, ACM, 2008, pp. 1096–1103.\n[54] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov, Dropout: A simple way to\nprevent neural networks from overﬁtting, The Journal of Machine Learning Research 15 (1) (2014)\n1929–1958.\n[55] Y. Bengio, Practical recommendations for gradient-based training of deep architectures, in: Neural\nNetworks: Tricks of the Trade, Springer, 2012, pp. 437–478.\n[56] K. Dowd, Adjusting for risk: An improved Sharpe ratio, International Review of Economics &\nFinance 9 (3) (2000) 209 – 222.\n[57] M. Weber, C. F. Camerer, The disposition eﬀect in securities trading: An experimental analysis,\nJournal of Economic Behavior & Organization 33 (2) (1998) 167–184.\n[58] D. Delen, R. Sharda, P. Kumar, Movie forecast guru: A web-based dss for hollywood managers,\nDecision Support Systems 43 (4) (2007) 1151–1170.\n[59] A. Oztekin, D. Delen, A. Turkyilmaz, S. Zaim, A machine learning-based usability evaluation\nmethod for elearning systems, Decision Support Systems 56 (2013) 63–73.\n[60] A. Oztekin, Information fusion-based meta-classiﬁcation predictive modeling for etf performance,\nInformation Systems Frontiers 20 (2) (2018) 223–238.\n[61] A. Oztekin, L. Al-Ebbini, Z. Sevkli, D. Delen, A decision analytic approach to predicting quality\nof life for lung transplant recipients: A hybrid genetic algorithms-based methodology, European\nJournal of Operational Research 266 (2) (2018) 639–651.\n[62] C. Sevim, A. Oztekin, O. Bali, S. Gumus, E. Guresen, Developing an early warning system to predict\ncurrency crises, European Journal of Operational Research 237 (3) (2014) 1095–1104.\n[63] A. Oztekin, M. R. Khan, A business-analytic approach to identify critical factors in quantitative\ndisciplines, Journal of Computer Information Systems 54 (4) (2014) 60–70.\n[64] J. M. Johnson, T. M. Khoshgoftaar, Survey on deep learning with class imbalance, Journal of Big\nData 6 (1) (2019) 27.\n[65] H. He, E. A. Garcia, Learning from imbalanced data, Knowledge and Data Engineering, IEEE\nTransactions on 21 (9) (2009) 1263–1284.\n[66] A. V. Benos, Aggressiveness and survival of overconﬁdent traders, Journal of Financial Markets\n1 (3) (1998) 353 – 383.\n[67] D. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, S. Bengio, Why does unsupervised\npre-training help deep learning?, The Journal of Machine Learning Research 11 (2010) 625–660.\n35\n",
  "categories": [
    "q-fin.RM",
    "cs.LG",
    "stat.AP"
  ],
  "published": "2018-12-14",
  "updated": "2019-11-17"
}