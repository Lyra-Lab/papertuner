{
  "id": "http://arxiv.org/abs/1812.08951v2",
  "title": "Analysis Methods in Neural Language Processing: A Survey",
  "authors": [
    "Yonatan Belinkov",
    "James Glass"
  ],
  "abstract": "The field of natural language processing has seen impressive progress in\nrecent years, with neural network models replacing many of the traditional\nsystems. A plethora of new models have been proposed, many of which are thought\nto be opaque compared to their feature-rich counterparts. This has led\nresearchers to analyze, interpret, and evaluate neural networks in novel and\nmore fine-grained ways. In this survey paper, we review analysis methods in\nneural language processing, categorize them according to prominent research\ntrends, highlight existing limitations, and point to potential directions for\nfuture work.",
  "text": "Analysis Methods in Neural Language Processing: A Survey\nYonatan Belinkov12 and James Glass1\n1MIT Computer Science and Artiﬁcial Intelligence Laboratory\n2Harvard School of Engineering and Applied Sciences\nCambridge, MA, USA\n{belinkov, glass}@mit.edu\nAbstract\nThe ﬁeld of natural language processing has\nseen impressive progress in recent years,\nwith neural network models replacing many\nof the traditional systems. A plethora of new\nmodels have been proposed, many of which\nare thought to be opaque compared to their\nfeature-rich counterparts. This has led re-\nsearchers to analyze, interpret, and evalu-\nate neural networks in novel and more ﬁne-\ngrained ways. In this survey paper, we re-\nview analysis methods in neural language\nprocessing, categorize them according to\nprominent research trends, highlight exist-\ning limitations, and point to potential direc-\ntions for future work.\n1\nIntroduction\nThe rise of deep learning has transformed the\nﬁeld of natural language processing (NLP) in re-\ncent years.\nModels based on neural networks\nhave obtained impressive improvements in vari-\nous tasks, including language modeling (Mikolov\net al., 2010; Jozefowicz et al., 2016), syntactic\nparsing (Kiperwasser and Goldberg, 2016), ma-\nchine translation (MT) (Bahdanau et al., 2014;\nSutskever et al., 2014), and many other tasks; see\nGoldberg (2017) for example success stories.\nThis progress has been accompanied by a myr-\niad of new neural network architectures. In many\ncases, traditional feature-rich systems are being re-\nplaced by end-to-end neural networks that aim to\nmap input text to some output prediction. As end-\nto-end systems are gaining prevalence, one may\npoint to two trends. First, some push back against\nthe abandonment of linguistic knowledge and call\nfor incorporating it inside the networks in different\nways.1 Others strive to better understand how neu-\nral language processing models work. This theme\n1See, for instance, Noah Smith’s invited talk at ACL\n2017: vimeo.com/234958746.\nSee also a recent de-\nbate on this matter by Chris Manning and Yann LeCun:\nof analyzing neural networks has connections to\nthe broader work on interpretability in machine\nlearning, along with speciﬁc characteristics of the\nNLP ﬁeld.\nWhy should we analyze our neural NLP mod-\nels?\nTo some extent, this question falls into\nthe larger question of interpretability in machine\nlearning, which has been the subject of much de-\nbate in recent years.2 Arguments in favor of in-\nterpretability in machine learning usually mention\ngoals like accountability, trust, fairness, safety,\nand reliability (Doshi-Velez and Kim, 2017; Lip-\nton, 2016). Arguments against typically stress per-\nformance as the most important desideratum. All\nthese arguments naturally apply to machine learn-\ning applications in NLP.\nIn the context of NLP, this question needs to\nbe understood in light of earlier NLP work, often\nreferred to as feature-rich or feature-engineered\nsystems. In some of these systems, features are\nmore easily understood by humans – they can be\nmorphological properties, lexical classes, syntac-\ntic categories, semantic relations, etc. In theory,\none could observe the importance assigned by sta-\ntistical NLP models to such features in order to\ngain a better understanding of the model.3 In con-\ntrast, it is more difﬁcult to understand what hap-\npens in an end-to-end neural network model that\ntakes input (say, word embeddings) and generates\nan output (say, a sentence classiﬁcation). Much of\nthe analysis work thus aims to understand how lin-\nguistic concepts that were common as features in\nNLP systems are captured in neural networks.\nAs the analysis of neural networks for language\nwww.youtube.com/watch?v=fKk9KhGRBdI. (Videos\naccessed on December 11, 2018.)\n2See,\nfor\nexample,\nthe\nNIPS\n2017\ndebate:\nwww.youtube.com/watch?v=2hW05ZfsUUo.\n(Ac-\ncessed on December 11, 2018.)\n3Nevertheless, one could question how feasible such an\nanalysis is; consider for example interpreting support vectors\nin high-dimensional support vector machines (SVMs).\narXiv:1812.08951v2  [cs.CL]  14 Jan 2019\nis becoming more and more prevalent, neural net-\nworks in various NLP tasks are being analyzed;\ndifferent network architectures and components\nare being compared; and a variety of new anal-\nysis methods are being developed.\nThis survey\naims to review and summarize this body of work,\nhighlight current trends, and point to existing lacu-\nnae. It organizes the literature into several themes.\nSection 2 reviews work that targets a fundamen-\ntal question: what kind of linguistic information\nis captured in neural networks? We also point to\nlimitations in current methods for answering this\nquestion. Section 3 discusses visualization meth-\nods, and emphasizes the difﬁculty in evaluating vi-\nsualization work. In Section 4 we discuss the com-\npilation of challenge sets, or test suites, for ﬁne-\ngrained evaluation, a methodology that has old\nroots in NLP. Section 5 deals with the generation\nand use of adversarial examples to probe weak-\nnesses of neural networks.\nWe point to unique\ncharacteristics of dealing with text as a discrete\ninput and how different studies handle them. Sec-\ntion 6 summarizes work on explaining model pre-\ndictions, an important goal of interpretability re-\nsearch. This is a relatively under-explored area,\nand we call for more work in this direction. Sec-\ntion 7 mentions a few other methods that do not\nfall neatly into one of the above themes. In the\nconclusion, we summarize the main gaps and po-\ntential research directions for the ﬁeld.\nThe paper is accompanied by online supple-\nmentary materials that contain detailed references\nfor studies corresponding to Sections 2, 4, and\n5 (Tables SM1, SM2, and SM3, respectively),\navailable at http://boknilev.github.io/\nnlp-analysis-methods.\nBefore proceeding, we brieﬂy mention some\nearlier work of a similar spirit.\nA historical note\nReviewing the vast literature\non neural networks for language is beyond our\nscope.4 However, we mention here a few repre-\nsentative studies that focused on analyzing such\nnetworks, in order to illustrate how recent trends\nhave roots that go back to before the recent deep\nlearning revival.\nRumelhart and McClelland (1986) built a feed-\nforward neural network for learning the English\n4For instance, a neural network that learns distributed rep-\nresentations of words was developed already in Miikkulainen\nand Dyer (1991). See Goodfellow et al. (2016, chapter 12.4)\nfor references to other important milestones.\npast tense and analyzed its performance on a va-\nriety of examples and conditions. They were es-\npecially concerned with the performance over the\ncourse of training, as their goal was to model the\npast form acquisition in children. They also ana-\nlyzed a scaled-down version having 8 input units\nand 8 output units, which allowed them to de-\nscribe it exhaustively and examine how certain\nrules manifest in network weights.\nIn his seminal work on recurrent neural net-\nworks (RNNs), Elman trained networks on syn-\nthetic sentences in a language prediction task (El-\nman, 1989, 1990, 1991). Through extensive anal-\nyses, he showed how networks discover the no-\ntion of a word when predicting characters; cap-\nture syntactic structures like number agreement;\nand acquire word representations that reﬂect lexi-\ncal and syntactic categories. Similar analyses were\nlater applied to other networks and tasks (Har-\nris, 1990; Niklasson and Linåker, 2000; Pollack,\n1990; Frank et al., 2013).\nWhile Elman’s work was limited in some\nways, such as evaluating generalization or various\nlinguistic phenomena—as Elman himself recog-\nnized (Elman, 1989)—it introduced methods that\nare still relevant today: from visualizing network\nactivations in time, through clustering words by\nhidden state activations, to projecting representa-\ntions to dimensions that emerge as capturing prop-\nerties like sentence number or verb valency. The\nsections on visualization (Section 3) and identi-\nfying linguistic information (Section 2) contain\nmany examples for these kinds of analysis.\n2\nWhat linguistic information is\ncaptured in neural networks\nNeural network models in NLP are typically\ntrained in an end-to-end manner on input-output\npairs, without explicitly encoding linguistic fea-\ntures. Thus a primary questions is the following:\nwhat linguistic information is captured in neural\nnetworks? When examining answers to this ques-\ntion, it is convenient to consider three dimensions:\nwhich methods are used for conducting the analy-\nsis, what kind of linguistic information is sought,\nand which objects in the neural network are be-\ning investigated. Table SM1 (in the supplementary\nmaterials) categorizes relevant analysis work ac-\ncording to these criteria. In the next sub-sections,\nwe discuss trends in analysis work along these\nlines, followed by a discussion of limitations of\ncurrent approaches.\n2.1\nMethods\nThe most common approach for associating neu-\nral network components with linguistic properties\nis to predict such properties from activations of\nthe neural network.\nTypically, in this approach\na neural network model is trained on some task\n(say, MT) and its weights are frozen. Then, the\ntrained model is used for generating feature repre-\nsentations for another task by running it on a cor-\npus with linguistic annotations and recording the\nrepresentations (say, hidden state activations). An-\nother classiﬁer is then used for predicting the prop-\nerty of interest (say, part-of-speech (POS) tags).\nThe performance of this classiﬁer is used for eval-\nuating the quality of the generated representations,\nand by proxy that of the original model. This kind\nof approach has been used in numerous papers in\nrecent years; see Table SM1 for references.5 It is\nreferred to by various names, including “auxiliary\nprediction tasks” (Adi et al., 2017b), “diagnostic\nclassiﬁers” (Veldhoen et al., 2016), and “probing\ntasks” (Conneau et al., 2018).\nAs an example of this approach,\nlet us\nwalk through an application to analyzing syn-\ntax in neural machine translation (NMT) by\nShi et al. (2016b).\nIn this work, two NMT\nmodels were trained on standard parallel data\n– English→French and English→German.\nThe\ntrained models (speciﬁcally, the encoders) were\nrun on an annotated corpus and their hidden states\nwere used for training a logistic regression clas-\nsiﬁer that predicts different syntactic properties.\nThe authors concluded that the NMT encoders\nlearn signiﬁcant syntactic information at both\nword-level and sentence-level.\nThey also com-\npared representations at different encoding layers\nand found that “local features are somehow pre-\nserved in the lower layer whereas more global,\nabstract information tends to be stored in the up-\nper layer.” These results demonstrate the kind of\ninsights that the classiﬁcation analysis may lead\nto, especially when comparing different models or\nmodel components.\nOther methods for ﬁnding correspondences be-\ntween parts of the neural network and certain\nproperties include counting how often attention\nweights agree with a linguistic property like\nanaphora resolution (Voita et al., 2018) or directly\n5A similar method has been used to analyze hierarchi-\ncal structure in neural networks trained on arithmetic expres-\nsions (Veldhoen et al., 2016; Hupkes et al., 2018).\ncomputing correlations between neural network\nactivations and some property, for example, cor-\nrelating RNN state activations with depth in a\nsyntactic tree (Qian et al., 2016a) or with Mel-\nfrequency cepstral coefﬁcient (MFCC) acoustic\nfeatures (Wu and King, 2016). Such correspon-\ndence may also be computed indirectly. For in-\nstance, Alishahi et al. (2017) deﬁned an ABX dis-\ncrimination task to evaluate how a neural model of\nspeech (grounded in vision) encoded phonology.\nGiven phoneme representations from different lay-\ners in their model, and three phonemes, A, B, and\nX, they compared whether the model representa-\ntion for X is closer to A or B. This discrimina-\ntion task enabled them to draw conclusions about\nwhich layers encoder phonology better, observing\nthat lower layers generally encode more phonolog-\nical information.\n2.2\nLinguistic phenomena\nDifferent kinds of linguistic information have been\nanalyzed, ranging from basic properties like sen-\ntence length, word position, word presence, or\nsimple word order, to morphological, syntactic,\nand semantic information. Phonetic/phonemic in-\nformation, speaker information, and style and ac-\ncent information have been studied in neural net-\nwork models for speech, or in joint audio-visual\nmodels. See Table SM1 for references.\nWhile it is difﬁcult to synthesize a holistic pic-\nture from this diverse body of work, it appears\nthat neural networks are able to learn a substan-\ntial amount of information on various linguistic\nphenomena. These models are especially success-\nful at capturing frequent properties, while some\nrare properties are more difﬁcult to learn. Linzen\net al. (2016), for instance, found that long short-\nterm memory (LSTM) language models are able\nto capture subject-verb agreement in many com-\nmon cases, while direct supervision is required for\nsolving harder cases.\nAnother theme that emerges in several studies\nis the hierarchical nature of the learned represen-\ntations. We have already mentioned such ﬁndings\nregarding NMT (Shi et al., 2016b) and a visually\ngrounded speech model (Alishahi et al., 2017).\nHierarchical representations of syntax were also\nreported to emerge in other RNN models (Blevins\net al., 2018).\nFinally, a couple of papers discovered that mod-\nels trained with latent trees perform better on nat-\nural language inference (NLI) (Williams et al.,\n2018; Maillard and Clark, 2018) than ones trained\nwith linguistically-annotated trees. Moreover, the\ntrees in these models do not resemble syntactic\ntrees corresponding to known linguistic theories,\nwhich casts doubts on the importance of syntax-\nlearning in the underlying neural network.6\n2.3\nNeural network components\nIn terms of the object of study, various neural neu-\nral network components were investigated, includ-\ning word embeddings, RNN hidden states or gate\nactivations, sentence embeddings, and attention\nweights in sequence-to-sequence (seq2seq) mod-\nels. Generally less work has analyzed convolu-\ntional neural networks (CNNs) in NLP, but see\nJacovi et al. (2018) for a recent exception.\nIn\nspeech processing, researchers have analyzed lay-\ners in deep neural networks for speech recognition\nand different speaker embeddings. Some analy-\nsis has also been devoted to joint language-vision\nor audio-vision models, or to similarities between\nword embeddings and convolutional image rep-\nresentations. Table SM1 provides detailed refer-\nences.\n2.4\nLimitations\nThe classiﬁcation approach may ﬁnd that a cer-\ntain amount of linguistic information is captured\nin the neural network.\nHowever, this does not\nnecessarily mean that the information is used by\nthe network. For example, Vanmassenhove et al.\n(2017) investigated aspect in NMT (and in phrase-\nbased statistical MT). They trained a classiﬁer on\nNMT sentence encoding vectors and found that\nthey can accurately predict tense about 90% of the\ntime. However, when evaluating the output trans-\nlations, they found them to have the correct tense\nonly 79% of the time. They interpreted this re-\nsult to mean that “part of the aspectual informa-\ntion is lost during decoding”. Relatedly, Cífka and\nBojar (2018) compared the performance of vari-\nous NMT models in terms of translation quality\n(BLEU) and representation quality (classiﬁcation\ntasks). They found a negative correlation between\nthe two, suggesting that high-quality systems may\nnot be learning certain sentence meanings. In con-\ntrast, Artetxe et al. (2018) showed that word em-\nbeddings contain divergent linguistic information,\n6Others found that even simple binary trees may work\nwell in MT (Wang et al., 2018b) and sentence classiﬁca-\ntion (Chen et al., 2015).\nwhich can be uncovered by applying a linear trans-\nformation on the learned embeddings. Their re-\nsults suggest an alternative explanation, showing\nthat “embedding models are able to encode diver-\ngent linguistic information but have limits on how\nthis information is surfaced.”\nFrom a methodological point of view, most of\nthe relevant analysis work is concerned with cor-\nrelation: how correlated are neural network com-\nponents with linguistic properties? What may be\nlacking is a measure of causation: how does the\nencoding of linguistic properties affect the sys-\ntem output. Giulianelli et al. (2018) make some\nheadway on this question. They predicted number\nagreement from RNN hidden states and gates at\ndifferent time steps. They then intervened in how\nthe model processes the sentence by changing a\nhidden activation based on the difference between\nthe prediction and the correct label. This improved\nagreement prediction accuracy, and the effect per-\nsisted over the course of the sentence, indicating\nthat this information has an effect on the model.\nHowever, they did not report the effect on overall\nmodel quality, for example by measuring perplex-\nity. Methods from causal inference may shed new\nlight on some of these questions.\nFinally, the predictor for the auxiliary task is\nusually a simple classiﬁer, such as logistic re-\ngression. A few studies compared different clas-\nsiﬁers and found that deeper classiﬁers lead to\noverall better results, but do not alter the respec-\ntive trends when comparing different models or\ncomponents (Qian et al., 2016b; Belinkov, 2018).\nInterestingly, Conneau et al. (2018) found that\ntasks requiring more nuanced linguistic knowl-\nedge (e.g., tree depth, coordination inversion) gain\nthe most from using a deeper classiﬁer. However,\nthe approach is usually taken for granted; given\nits prevalence, it appears that better theoretical or\nempirical foundations are in place.\n3\nVisualization\nVisualization is a valuable tool for analyzing neu-\nral networks in the language domain and beyond.\nEarly work visualized hidden unit activations in\nRNNs trained on an artiﬁcial language modeling\ntask, and observed how they correspond to certain\ngrammatical relations such as agreement (Elman,\n1991). Much recent work has focused on visu-\nalizing activations on speciﬁc examples in mod-\nern neural networks for language (Karpathy et al.,\nFigure 1: A heatmap visualizing neuron activa-\ntions. In this case, the activations capture position\nin the sentence.\n2015; Kádár et al., 2017; Qian et al., 2016a; Liu\net al., 2018) and speech (Wu and King, 2016;\nNagamine et al., 2015; Wang et al., 2017b). Fig-\nure 1 shows an example visualization of a neuron\nthat captures position of words in a sentence. The\nheatmap uses blue and red colors for negative and\npositive activation values, respectively, enabling\nthe user to quickly grasp the function of this neu-\nron.\nThe attention mechanism that originated in\nwork on NMT (Bahdanau et al., 2014) also lends\nitself to a natural visualization. The alignments\nobtained via different attention mechanisms have\nproduced visualizations ranging from tasks like\nNLI (Rocktäschel et al., 2016; Yin et al., 2016),\nsummarization (Rush et al., 2015), MT post-\nediting (Jauregi Unanue et al., 2018), and morpho-\nlogical inﬂection (Aharoni and Goldberg, 2017),\nto matching users on social media (Tay et al.,\n2018).\nFigure 2 reproduces a visualization of\nattention alignments from the original work by\nBahdanau et al..\nHere grayscale values corre-\nspond to the weight of the attention between words\nin an English source sentence (columns) and its\nFrench translation (rows).\nAs Bahdanau et al.\nexplain, this visualization demonstrates that the\nNMT model learned a soft alignment between\nsource and target words. Some aspects of word\norder may also be noticed, as in the reordering\nof noun and adjective when translating the phrase\n“European Economic Area”.\nAnother line of work computes various saliency\nmeasures to attribute predictions to input features.\nThe important or salient features can then be vi-\nsualized in selected examples (Li et al., 2016a;\nAubakirova and Bansal, 2016; Sundararajan et al.,\n2017; Arras et al., 2017a,b; Ding et al., 2017; Mur-\ndoch et al., 2018; Mudrakarta et al., 2018; Mon-\ntavon et al., 2018; Godin et al., 2018). Saliency\ncan also be computed with respect to intermediate\nvalues, rather than input features (Ghaeini et al.,\n2018).7\n7Generally,\nmany of the visualization methods are\nadapted from the vision domain, where they have been ex-\ntremely popular; see Zhang and Zhu (2018) for a survey.\nFigure 2:\nA visualization of attention weights,\nshowing soft alignment between source and target\nsentences in an NMT model. Reproduced from\nBahdanau et al. (2014), with permission.\nAn instructive visualization technique is to clus-\nter neural network activations and compare them\nto some linguistic property. Early work clustered\nRNN activations, showing that they organize in\nlexical categories (Elman, 1989, 1990). Similar\ntechniques have been followed by others.\nRe-\ncent examples include clustering of sentence em-\nbeddings in an RNN encoder trained in a multi-\ntask learning scenario (Brunner et al., 2017), and\nphoneme clusters in a joint audio-visual RNN\nmodel (Alishahi et al., 2017).\nA\nfew\nonline\ntools\nfor\nvisualizing\nneu-\nral networks have recently become available.\nLSTMVis (Strobelt et al., 2018b) visualizes RNN\nactivations, focusing on tracing hidden state dy-\nnamics.8 Seq2Seq-Vis (Strobelt et al., 2018a)\nvisualizes different modules in attention-based\nseq2seq models, with the goal of examining model\ndecisions and testing alternative decisions.\nAn-\nother tool focused on comparing attention align-\nments was proposed by Rikters (2018). It also pro-\nvides translation conﬁdence scores based on the\ndistribution of attention weights. NeuroX (Dalvi\net al., 2019b) is a tool for ﬁnding and analyzing\nindividual neurons, focusing on machine transla-\ntion.\nEvaluation\nAs in much work on interpretability,\nevaluating visualization quality is difﬁcult and of-\nten limited to qualitative examples. A few notable\n8RNNVis (Ming et al., 2017) is a similar tool, but its on-\nline demo does not seem to be available at the time of writing.\nexceptions report human evaluations of visualiza-\ntion quality. Singh et al. (2018) showed humans\nhierarchical clusterings of input words generated\nby two interpretation methods, and asked them\nto evaluate which method is more accurate, or in\nwhich method they trust more. Others reported\nhuman evaluations for attention visualization in\nconversation modeling (Freeman et al., 2018) and\nmedical code prediction tasks (Mullenbach et al.,\n2018).\nThe availability of open-source tools of the sort\ndescribed above will hopefully encourage users to\nutilize visualization in their regular research and\ndevelopment cycle. However, it remains to be seen\nhow useful visualizations turn out to be.\n4\nChallenge sets\nThe majority of benchmark datasets in NLP are\ndrawn from text corpora, reﬂecting a natural\nfrequency distribution of language phenomena.\nWhile useful in practice for evaluating system\nperformance in the average case, such datasets\nmay fail to capture a wide range of phenomena.\nAn alternative evaluation framework consists of\nchallenge sets, also known as test suites, which\nhave been used in NLP for a long time (Lehmann\net al., 1996), especially for evaluating MT sys-\ntems (King and Falkedal, 1990; Isahara, 1995;\nKoh et al., 2001). Lehmann et al. (1996) noted\nseveral key properties of test suites: systematicity,\ncontrol over data, inclusion of negative data, and\nexhaustivity. They contrasted such datasets with\ntest corpora, “whose main advantage is that they\nreﬂect naturally occurring data.” This idea under-\nlines much of the work on challenge sets and is\nechoed in more recent work (Wang et al., 2018a).\nFor instance, Cooper et al. (1996) constructed a se-\nmantic test suite that targets phenomena as diverse\nas quantiﬁers, plurals, anaphora, ellipsis, adjecti-\nval properties, and so on.\nAfter a hiatus of a couple of decades,9 challenge\nsets have recently gained renewed popularity in\nthe NLP community. In this section, we include\ndatasets used for evaluating neural network mod-\nels that diverge from the common average-case\nevaluation. Many of them share some of the prop-\nerties noted by Lehmann et al. (1996), although\nnegative examples (ill-formed data) are typically\n9One could speculate that their decrease in popularity can\nbe attributed to the rise of large-scale quantitative evaluation\nof statistical NLP systems.\nless utilized. The challenge datasets can be cate-\ngorized along the following criteria: the task they\nseek to evaluate, the linguistic phenomena they\naim to study, the language(s) they target, their\nsize, their method of construction, and how perfor-\nmance is evaluated.10 Table SM2 (in the supple-\nmentary materials) categorizes many recent chal-\nlenge sets along these criteria. Below we discuss\ncommon trends along these lines.\n4.1\nTask\nBy far, the most targeted tasks in challenge sets\nare NLI and MT. This can partly be explained by\nthe popularity of these tasks and the prevalence\nof neural models proposed for solving them. Per-\nhaps more importantly, tasks like NLI and MT ar-\nguably require inferences at various linguistic lev-\nels, making the challenge set evaluation especially\nattractive. Still, other high-level tasks like read-\ning comprehension or question answering have not\nreceived as much attention, and may also beneﬁt\nfrom the careful construction of challenge sets.\nA signiﬁcant body of work aims to evaluate\nthe quality of embedding models by correlating\nthe similarity they induce on word or sentence\npairs with human similarity judgments. Datasets\ncontaining such similarity scores are often used\nto evaluate word embeddings (Finkelstein et al.,\n2002; Bruni et al., 2012; Hill et al., 2015, in-\nter alia) or sentence embeddings; see the many\nshared tasks on semantic textual similarity in Se-\nmEval (Cer et al., 2017, and previous editions).\nMany of these datasets evaluate similarity at a\ncoarse-grained level, but some provide a more\nﬁne-grained evaluation of similarity or related-\nness. For example, some datasets are dedicated\nfor speciﬁc word classes such as verbs (Gerz et al.,\n2016) or rare words (Luong et al., 2013), or for\nevaluating compositional knowledge in sentence\nembeddings (Marelli et al., 2014). Multilingual\nand cross-lingual versions have also been col-\nlected (Leviant and Reichart, 2015; Cer et al.,\n2017). Although these datasets are widely used,\nthis kind of evaluation has been criticized for\nits subjectivity and questionable correlation with\ndownstream performance (Faruqui et al., 2016).\n10Another typology of evaluation protocols was put forth\nby Burlot and Yvon (2017). Their criteria are partially over-\nlapping with ours, although they did not provide a compre-\nhensive categorization as the one compiled here.\n4.2\nLinguistic phenomena\nOne of the primary goals of challenge sets is to\nevaluate models on their ability to handle spe-\nciﬁc linguistic phenomena.\nWhile earlier stud-\nies emphasized exhaustivity (Cooper et al., 1996;\nLehmann et al., 1996), recent ones tend to fo-\ncus on a few properties of interest.\nFor exam-\nple, Sennrich (2017) introduced a challenge set for\nMT evaluation focusing on 5 properties: subject-\nverb agreement, noun phrase agreement, verb-\nparticle constructions, polarity, and transliteration.\nSlightly more elaborated is an MT challenge set\nfor morphology, including 14 morphological prop-\nerties (Burlot and Yvon, 2017). See Table SM2 for\nreferences to datasets targeting other phenomena.\nOther challenge sets cover a more diverse range\nof linguistic properties, in the spirit of some of\nthe earlier work. For instance, extending the cat-\negories in Cooper et al. (1996), the GLUE anal-\nysis set for NLI covers more than 30 phenom-\nena in four coarse categories (lexical semantics,\npredicate-argument structure, logic, and knowl-\nedge). In MT evaluation, Burchardt et al. (2017)\nreported results using a large test suite cover-\ning 120 phenomena, partly based on Lehmann\net al. (1996).11\nIsabelle et al. (2017) and Is-\nabelle and Kuhn (2018) prepared challenge sets\nfor MT evaluation covering ﬁne-grained phenom-\nena at morpho-syntactic, syntactic, and lexical lev-\nels.\nGenerally, datasets that are constructed pro-\ngrammatically tend to cover less ﬁne-grained lin-\nguistic properties, while manually constructed\ndatasets represent more diverse phenomena.\n4.3\nLanguages\nAs unfortunately usual in much NLP work, espe-\ncially neural NLP, the vast majority of challenge\nsets are in English. This situation is slightly better\nin MT evaluation, where naturally all datasets fea-\nture other languages (see Table SM2). A notable\nexception is the work by Gulordava et al. (2018),\nwho constructed examples for evaluating number\nagreement in language modeling in English, Rus-\nsian, Hebrew, and Italian. Clearly, there is room\nfor more challenge sets in non-English languages.\nHowever, perhaps more pressing is the need for\nlarge-scale non-English datasets (besides MT) to\ndevelop neural models for popular NLP tasks.\n11Their dataset does not seem to be available yet, but more\ndetails are promised to appear in a future publication.\n4.4\nScale\nThe size of proposed challenge sets varies greatly\n(Table SM2). As expected, datasets constructed\nby hand are smaller, with typical sizes in the\nhundreds. Automatically-built datasets are much\nlarger, ranging from several thousands to close to a\nhundred thousand (Sennrich, 2017), or even more\nthan one million examples (Linzen et al., 2016).\nIn the latter case, the authors argue that such a\nlarge test set is needed for obtaining a sufﬁcient\nrepresentation of rare cases.\nA few manually-\nconstructed datasets contain a fairly large number\nof examples, up to 10K (Burchardt et al., 2017).\n4.5\nConstruction method\nChallenge sets are usually created either program-\nmatically or manually, by hand-crafting speciﬁc\nexamples.\nOften, semi-automatic methods are\nused to compile an initial list of examples that\nis manually veriﬁed by annotators. The speciﬁc\nmethod also affects the kind of language use and\nhow natural or artiﬁcial/synthetic the examples\nare. We describe here some trends in dataset con-\nstruction methods in the hope that they may be\nuseful for researchers contemplating new datasets.\nSeveral datasets were constructed by modify-\ning or extracting examples from existing datasets.\nFor instance, Sanchez et al. (2018) and Glockner\net al. (2018) extracted examples from SNLI (Bow-\nman et al., 2015) and replaced speciﬁc words such\nas hypernyms, synonyms, and antonyms, followed\nby manual veriﬁcation. Linzen et al. (2016), on\nthe other hand, extracted examples of subject-verb\nagreement from raw texts using heuristics, result-\ning in a large-scale dataset. Gulordava et al. (2018)\nextended this to other agreement phenomena, but\nthey relied on syntactic information available in\ntreebanks, resulting in a smaller dataset.\nSeveral challenge sets utilize existing test suites,\neither as a direct source of examples (Burchardt\net al., 2017) or for searching similar naturally oc-\ncurring examples (Wang et al., 2018a).12\nSennrich (2017) introduced a method for eval-\nuating NMT systems via contrastive translation\npairs, where the system is asked to estimate the\nprobability of two candidate translations that are\ndesigned to reﬂect speciﬁc linguistic properties.\nSennrich generated such pairs programmatically\n12Wang et al. (2018a) also veriﬁed that their examples do\nnot contain annotation artifacts, a potential problem noted in\nrecent studies (Gururangan et al., 2018; Poliak et al., 2018b).\nby applying simple heuristics, such as changing\ngender and number to induce agreement errors, re-\nsulting in a large-scale challenge set of close to\n100K examples.\nThis framework was extended\nto evaluate other properties, but often requir-\ning more sophisticated generation methods like\nusing morphological analyzers/generators (Burlot\nand Yvon, 2017) or more manual involvement\nin generation (Bawden et al., 2018) or veriﬁca-\ntion (Rios Gonzales et al., 2017).\nFinally, a few of studies deﬁne templates\nthat capture certain linguistic properties and in-\nstantiate them with word lists (Dasgupta et al.,\n2018; Rudinger et al., 2018; Zhao et al., 2018a).\nTemplate-based generation has the advantage of\nproviding more control, for example for obtaining\na speciﬁc vocabulary distribution, but this comes\nat the expense of how natural the examples are.\n4.6\nEvaluation\nSystems are typically evaluated by their perfor-\nmance on the challenge set examples, either with\nthe same metric used for evaluating the system in\nthe ﬁrst place, or via a proxy, as in the contrastive\npairs evaluation of Sennrich (2017). Automatic\nevaluation metrics are cheap to obtain and can be\ncalculated on a large scale. However, they may\nmiss certain aspects. Thus a few studies report hu-\nman evaluation on their challenge sets, such as in\nMT (Isabelle et al., 2017; Burchardt et al., 2017).\nWe note here also that judging the quality of a\nmodel by its performance on a challenge set can\nbe tricky. Some authors emphasize their wish to\ntest systems on extreme or difﬁcult cases, “beyond\nnormal operational capacity” (Naik et al., 2018).\nHowever, whether or not one should expect sys-\ntems to perform well on specially chosen cases (as\nopposed to the average case) may depend on one’s\ngoals. To put results in perspective, one may com-\npare model performance to human performance on\nthe same task (Gulordava et al., 2018).\n5\nAdversarial examples\nUnderstanding a model requires also an under-\nstanding of its failures. Despite their success in\nmany tasks, machine learning systems can also be\nvery sensitive to malicious attacks or adversarial\nexamples (Szegedy et al., 2014; Goodfellow et al.,\n2015). In the vision domain, small changes to the\ninput image can lead to misclassiﬁcation, even if\nsuch changes are indistinguishable by humans.\nThe basic setup in work on adversarial examples\ncan be described as follows.13 Given a neural net-\nwork model f and an input example x, we seek to\ngenerate an adversarial example x′ that will have\na minimal distance from x, while being assigned a\ndifferent label by f:\nmin\nx′ ||x −x′||\ns.t.\nf(x) = l, f(x′) = l′, l ̸= l′\nIn the vision domain, x can be the input image pix-\nels, resulting in a fairly intuitive interpretation of\nthis optimization problem: measuring the distance\n||x −x′|| is straightforward, and ﬁnding x′ can be\ndone by computing gradients with respect to the\ninput, since all quantities are continuous.\nIn the text domain, the input is discrete (for ex-\nample, a sequence of words), which poses two\nproblems. First, it is not clear how to measure the\ndistance between the original and adversarial ex-\namples, x and x′, which are two discrete objects\n(say, two words or sentences). Second, minimiz-\ning this distance cannot be easily formulated as an\noptimization problem, as this requires computing\ngradients with respect to a discrete input.\nIn the following, we review methods for han-\ndling these difﬁculties according to several cri-\nteria: the adversary’s knowledge, the speciﬁcity\nof the attack, the linguistic unit being modiﬁed,\nand the task on which the attacked model was\ntrained.14 Table SM3 (in the supplementary ma-\nterials) categorizes work on adversarial examples\nin NLP according to these criteria.\n5.1\nAdversary’s knowledge\nAdversarial examples can be generated using ac-\ncess to model parameters, also known as white-\nbox attacks, or without such access, with black-\nbox attacks (Papernot et al., 2016a, 2017; Narodyt-\nska and Kasiviswanathan, 2017; Liu et al., 2017).\nWhite-box attacks are difﬁcult to adapt to the\ntext world as they typically require computing gra-\ndients with respect to the input, which would be\ndiscrete in the text case. One option is to com-\npute gradients with respect to the input word em-\nbeddings, and perturb the embeddings. Since this\nmay result in a vector that does not correspond to\n13The notation here follows Yuan et al. (2017).\n14These criteria are partly taken from Yuan et al. (2017),\nwhere a more elaborate taxonomy is laid out. At present,\nthough, the work on adversarial examples in NLP is more\nlimited than in computer vision, so our criteria will sufﬁce.\nany word, one could search for the closest word\nembedding in a given dictionary (Papernot et al.,\n2016b); Cheng et al. (2018) extended this idea to\nseq2seq models. Others computed gradients with\nrespect to input word embeddings to identify and\nrank words to be modiﬁed (Samanta and Mehta,\n2017; Liang et al., 2018). Ebrahimi et al. (2018b)\ndeveloped an alternative method by representing\ntext edit operations in vector space (e.g., a bi-\nnary vector specifying which characters in a word\nwould be changed) and approximating the change\nin loss with the derivative along this vector.\nGiven the difﬁculty in generating white-box ad-\nversarial examples for text, much research has\nbeen devoted to black-box examples. Often, the\nadversarial examples are inspired by text edits that\nare thought to be natural or commonly generated\nby humans, such as typos, misspellings, and so\non (Sakaguchi et al., 2017; Heigold et al., 2018;\nBelinkov and Bisk, 2018). Gao et al. (2018) de-\nﬁned scoring functions to identify tokens to mod-\nify. Their functions do not require access to model\ninternals, but they do require the model prediction\nscore. After identifying the important tokens, they\nmodify characters with common edit operations.\nZhao et al. (2018c) used generative adversar-\nial networks (GANs) (Goodfellow et al., 2014) to\nminimize the distance between latent representa-\ntions of input and adversarial examples, and per-\nformed perturbations in latent space. Since the la-\ntent representations do not need to come from the\nattacked model, this is a black-box attack.\nFinally, Alzantot et al. (2018) developed an in-\nteresting population-based genetic algorithm for\ncrafting adversarial examples for text classiﬁca-\ntion, by maintaining a population of modiﬁcations\nof the original sentence and evaluating ﬁtness of\nmodiﬁcations at each generation. They do not re-\nquire access to model parameters, but do use pre-\ndiction scores. A similar idea was proposed by\nKuleshov et al. (2018).\n5.2\nAttack speciﬁcity\nAdversarial attacks can be classiﬁed to targeted\nvs. non-targeted attacks (Yuan et al., 2017).\nA\ntargeted attack speciﬁes a speciﬁc false class, l′,\nwhile a non-targeted attack only cares that the pre-\ndicted class is wrong, l′ ̸= l. Targeted attacks\nare more difﬁcult to generate, as they typically re-\nquire knowledge of model parameters, i.e., they\nare white-box attacks.\nThis might explain why\nthe majority of adversarial examples in NLP are\nnon-targeted (see Table SM3). A few targeted at-\ntacks include Liang et al. (2018), which speciﬁed\na desired class to fool a text classiﬁer, and Chen\net al. (2018a), which speciﬁed words or captions\nto generate in an image captioning model. Oth-\ners targeted speciﬁc words to omit, replace, or\ninclude when attacking seq2seq models (Cheng\net al., 2018; Ebrahimi et al., 2018a).\nMethods for generating targeted attacks in NLP\ncould possibly take more inspiration from adver-\nsarial attacks in other ﬁelds. For instance, in at-\ntacking malware detection systems, several stud-\nies developed targeted attacks in a black-box sce-\nnario (Yuan et al., 2017). A black-box targeted at-\ntack for MT was proposed by Zhao et al. (2018c),\nwho used GANs to search for attacks on Google’s\nMT system after mapping sentences into contin-\nuous space with adversarially regularized autoen-\ncoders (Zhao et al., 2018b).\n5.3\nLinguistic unit\nMost of the work on adversarial text examples\ninvolves modiﬁcations at the character- and/or\nword-level; see Table SM3 for speciﬁc references.\nOther transformations include adding sentences\nor text chunks (Jia and Liang, 2017) or gen-\nerating paraphrases with desired syntactic struc-\ntures (Iyyer et al., 2018).\nIn image captioning,\nChen et al. (2018a) modiﬁed pixes in the input im-\nage to generate targeted attacks on the caption text.\n5.4\nTask\nGenerally, most work on adversarial examples\nin NLP concentrates on relatively high-level lan-\nguage understanding tasks, such as text classiﬁ-\ncation (including sentiment analysis) and reading\ncomprehension, while work on text generation fo-\ncuses mainly on MT. See Table SM3 for refer-\nences. There is relatively little work on adversar-\nial examples for more low-level language process-\ning tasks, although one can mention morphologi-\ncal tagging (Heigold et al., 2018) and spelling cor-\nrection (Sakaguchi et al., 2017).\n5.5\nCoherence & perturbation measurement\nIn adversarial image examples, it is fairly straight-\nforward to measure the perturbation, either by\nmeasuring distance in pixel space, say ||x −x′||\nunder some norm, or with alternative measures\nthat are better correlated with human percep-\ntion (Rozsa et al., 2016). It is also visually com-\npelling to present an adversarial image with imper-\nceptible difference from its source image. In the\ntext domain, measuring distance is not as straight-\nforward and even small changes to the text may\nbe perceptible by humans. Thus, evaluation of at-\ntacks is fairly tricky. Some studies imposed con-\nstraints on adversarial examples to have a small\nnumber of edit operations (Gao et al., 2018). Oth-\ners ensured syntactic or semantic coherence in\ndifferent ways, such as ﬁltering replacements by\nword similarity or sentence similarity (Alzantot\net al., 2018; Kuleshov et al., 2018), or by us-\ning synonyms and other word lists (Samanta and\nMehta, 2017; Yang et al., 2018).\nSome reported whether a human can classify\nthe adversarial example correctly (Yang et al.,\n2018), but this does not indicate how perceptible\nthe changes are. More informative human studies\nevaluate grammaticality or similarity of the adver-\nsarial examples to the original ones (Zhao et al.,\n2018c; Alzantot et al., 2018). Given the inherent\ndifﬁculty in generating imperceptible changes in\ntext, more such evaluations are needed.\n6\nExplaining predictions\nExplaining speciﬁc predictions is recognized as\na desideratum in intereptability work (Lipton,\n2016), argued to increase the accountability of ma-\nchine learning systems (Doshi-Velez et al., 2017).\nHowever, explaining why a deep, highly non-\nlinear neural network makes a certain prediction\nis not trivial. One solution is to ask the model to\ngenerate explanations along with its primary pre-\ndiction (Zaidan et al., 2007; Zhang et al., 2016),15\nbut this approach requires manual annotations of\nexplanations, which may be hard to collect.\nAn alternative approach is to use parts of the\ninput as explanations.\nFor example, Lei et al.\n(2016) deﬁned a generator that learns a distribu-\ntion over text fragments as candidate rationales\nfor justifying predictions, evaluated on sentiment\nanalysis. Alvarez-Melis and Jaakkola (2017) dis-\ncovered input-output associations in a sequence-\nto-sequence learning scenario, by perturbing the\ninput and ﬁnding the most relevant associations.\nGupta and Schütze (2018) inspected how informa-\ntion is accumulated in RNNs towards a prediction,\nand associated peaks in prediction scores with im-\nportant input segments. As these methods use in-\n15Other work considered learning textual-visual explana-\ntions from multi-modal annotations (Park et al., 2018).\nput segments to explain predictions, they do not\nshed much light on the internal computations that\ntake place in the network.\nAt present, despite the recognized importance\nfor interpretability, our ability to explain predic-\ntions of neural networks in NLP is still limited.\n7\nOther methods\nWe brieﬂy mention here several analysis methods\nthat do not fall neatly into the previous sections.\nA number of studies evaluated the effect of eras-\ning or masking certain neural network compo-\nnents, such as word embedding dimensions, hid-\nden units, or even full words (Li et al., 2016b;\nFeng et al., 2018; Khandelwal et al., 2018; Bau\net al., 2018). For example, Li et al. (2016b) erased\nspeciﬁc dimensions in word embeddings or hid-\nden states and computed the change in proba-\nbility assigned to different labels.\nTheir exper-\niments revealed interesting differences between\nword embedding models, where in some models\ninformation is more focused in individual dimen-\nsions. They also found that information is more\ndistributed in hidden layers than in the input layer,\nand erased entire words to ﬁnd important words in\na sentiment analysis task.\nSeveral studies conducted behavioral experi-\nments to interpret word embeddings by deﬁning\nintrusion tasks, where humans need to identify\nan intruder word, chosen based on difference in\nword embedding dimensions (Murphy et al., 2012;\nFyshe et al., 2015; Faruqui et al., 2015).16 In this\nkind of work, a word embedding model may be\ndeemed more interpretable if humans are better\nable to identify the intruding words.\nSince the\nevaluation is costly for high-dimensional represen-\ntations, alternative automatic metrics were consid-\nered (Park et al., 2017; Senel et al., 2018).\nA long tradition in work on neural networks is\nto evaluate and analyze their ability to learn dif-\nferent formal languages (Das et al., 1992; Casey,\n1996; Gers and Schmidhuber, 2001; Bodén and\nWiles, 2002; Chalup and Blair, 2003). This trend\ncontinues today, with research into modern ar-\nchitectures and what formal languages they can\nlearn (Weiss et al., 2018; Bernardy, 2018; Suzgun\net al., 2019), or the formal properties they pos-\nsess (Chen et al., 2018b).\n16The methodology follows earlier work on evaluating the\ninterpretability of probabilistic topic models with intrusion\ntasks (Chang et al., 2009).\n8\nConclusion\nAnalyzing neural networks has become a hot topic\nin NLP research. This survey attempted to review\nand summarize as much of the current research as\npossible, while organizing it along several promi-\nnent themes. We have emphasized aspects in anal-\nysis that are speciﬁc to language – namely, what\nlinguistic information is captured in neural net-\nworks, which phenomena they are successful at\ncapturing, and where they fail. Many of the analy-\nsis methods are general techniques from the larger\nmachine learning community, such as visualiza-\ntion via saliency measures, or evaluation by ad-\nversarial examples. But even those sometimes re-\nquire non-trivial adaptations to work with text in-\nput. Some methods are more speciﬁc to the ﬁeld,\nbut may prove useful in other domains. Challenge\nsets or test suites are such a case.\nThroughout this survey, we have identiﬁed sev-\neral limitations or gaps in current analysis work:\n• The use of auxiliary classiﬁcation tasks for\nidentifying which linguistic properties neural\nnetworks capture has become standard prac-\ntice (Section 2), while lacking both a theoret-\nical foundation and a better empirical consid-\neration of the link between the auxiliary tasks\nand the original task.\n• Evaluation of analysis work is often lim-\nited or qualitative, especially in visualization\ntechniques (Section 3). Newer forms of eval-\nuation are needed for determining the success\nof different methods.\n• Relatively little work has been done on ex-\nplaining predictions of neural network mod-\nels, apart from providing visualizations (Sec-\ntion 6).\nWith the increasing public de-\nmand for explaining algorithmic choices in\nmachine learning systems (Doshi-Velez and\nKim, 2017; Doshi-Velez et al., 2017), there is\npressing need for progress in this direction.\n• Much of the analysis work is focused on the\nEnglish language, especially in constructing\nchallenge sets for various tasks (Section 4),\nwith the exception of MT due to its inherent\nmultilingual character. Developing resources\nand evaluating methods on other languages is\nimportant as the ﬁeld grows and matures.\n• More challenge sets for evaluating other tasks\nbesides NLI and MT are needed.\nFinally, as with any survey in a rapidly evolving\nﬁeld, this paper is likely to omit relevant recent\nwork by the time of publication. While we in-\ntend to continue updating the online appendix with\nnewer publications, we hope that our summariza-\ntion of prominent analysis work and its categoriza-\ntion into several themes will be a useful guide for\nscholars interested in analyzing and understanding\nneural networks for NLP.\nAcknowledgments\nWe would like to thank the anonymous reviewers\nand the TACL Action Editor for their very help-\nful comments. This work was supported by the\nQatar Computing Research Institute. Y.B. is also\nsupported by the Harvard Mind, Brain, Behavior\nInitiative.\nReferences\nYossi Adi, Einat Kermany, Yonatan Belinkov, Ofer\nLavi, and Yoav Goldberg. 2017a. Analysis of\nsentence embedding models using prediction\ntasks in natural language processing. IBM Jour-\nnal of Research and Development, 61(4):3–9.\nYossi Adi, Einat Kermany, Yonatan Belinkov, Ofer\nLavi, and Yoav Goldberg. 2017b. Fine-grained\nAnalysis of Sentence Embeddings Using Auxil-\niary Prediction Tasks. In International Confer-\nence on Learning Representations (ICLR).\nRoee Aharoni and Yoav Goldberg. 2017. Morpho-\nlogical Inﬂection Generation with Hard Mono-\ntonic Attention.\nIn Proceedings of the 55th\nAnnual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers),\npages 2004–2015. Association for Computa-\ntional Linguistics.\nWasi Uddin Ahmad,\nXueying Bai,\nZhechao\nHuang, Chao Jiang, Nanyun Peng, and Kai-Wei\nChang. 2018. Multi-task Learning for Univer-\nsal Sentence Embeddings: A Thorough Evalua-\ntion using Transfer and Auxiliary Tasks. arXiv\npreprint arXiv:1804.07911v2.\nAfra Alishahi, Marie Barking, and Grzegorz Chru-\npała. 2017.\nEncoding of phonology in a re-\ncurrent neural model of grounded speech.\nIn\nProceedings of the 21st Conference on Com-\nputational Natural Language Learning (CoNLL\n2017), pages 368–378. Association for Compu-\ntational Linguistics.\nDavid Alvarez-Melis and Tommi Jaakkola. 2017.\nA causal framework for explaining the predic-\ntions of black-box sequence-to-sequence mod-\nels. In Proceedings of the 2017 Conference on\nEmpirical Methods in Natural Language Pro-\ncessing, pages 412–421. Association for Com-\nputational Linguistics.\nMoustafa Alzantot, Yash Sharma, Ahmed Elgo-\nhary, Bo-Jhang Ho, Mani Srivastava, and Kai-\nWei Chang. 2018.\nGenerating Natural Lan-\nguage Adversarial Examples.\nIn Proceedings\nof the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 2890–\n2896. Association for Computational Linguis-\ntics.\nLeila Arras, Franziska Horn, Grégoire Montavon,\nKlaus-Robert Müller, and Wojciech Samek.\n2017a. \"What is relevant in a text document?\":\nAn interpretable machine learning approach.\nPLOS ONE, 12(8):1–23.\nLeila Arras, Grégoire Montavon, Klaus-Robert\nMüller, and Wojciech Samek. 2017b. Explain-\ning Recurrent Neural Network Predictions in\nSentiment Analysis.\nIn Proceedings of the\n8th Workshop on Computational Approaches to\nSubjectivity, Sentiment and Social Media Anal-\nysis, pages 159–168. Association for Computa-\ntional Linguistics.\nMikel Artetxe,\nGorka Labaka,\nInigo Lopez-\nGazpio, and Eneko Agirre. 2018.\nUncover-\ning Divergent Linguistic Information in Word\nEmbeddings with Lessons for Intrinsic and Ex-\ntrinsic Evaluation. In Proceedings of the 22nd\nConference on Computational Natural Lan-\nguage Learning, pages 282–291. Association\nfor Computational Linguistics.\nMalika Aubakirova and Mohit Bansal. 2016. In-\nterpreting Neural Networks to Improve Polite-\nness Comprehension.\nIn Proceedings of the\n2016 Conference on Empirical Methods in Nat-\nural Language Processing, pages 2035–2041.\nAssociation for Computational Linguistics.\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua\nBengio. 2014. Neural Machine Translation by\nJointly Learning to Align and Translate. arXiv\npreprint arXiv:1409.0473v7.\nAnthony Bau, Yonatan Belinkov, Hassan Sajjad,\nNadir Durrani, Fahim Dalvi, and James Glass.\n2018.\nIdentifying and Controlling Important\nNeurons in Neural Machine Translation. arXiv\npreprint arXiv:1811.01157v1.\nRachel Bawden, Rico Sennrich, Alexandra Birch,\nand Barry Haddow. 2018.\nEvaluating Dis-\ncourse Phenomena in Neural Machine Transla-\ntion.\nIn Proceedings of the 2018 Conference\nof the North American Chapter of the Associ-\nation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Pa-\npers), pages 1304–1313. Association for Com-\nputational Linguistics.\nYonatan Belinkov. 2018. On Internal Language\nRepresentations in Deep Learning: An Analy-\nsis of Machine Translation and Speech Recog-\nnition. Ph.D. thesis, Massachusetts Institute of\nTechnology.\nYonatan Belinkov and Yonatan Bisk. 2018. Syn-\nthetic and Natural Noise Both Break Neural\nMachine Translation. In International Confer-\nence on Learning Representations (ICLR).\nYonatan Belinkov, Nadir Durrani, Fahim Dalvi,\nHassan Sajjad, and James Glass. 2017a. What\ndo Neural Machine Translation Models Learn\nabout Morphology? In Proceedings of the 55th\nAnnual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers),\npages 861–872. Association for Computational\nLinguistics.\nYonatan Belinkov and James Glass. 2017. Ana-\nlyzing Hidden Representations in End-to-End\nAutomatic Speech Recognition Systems.\nIn\nI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,\nR. Fergus, S. Vishwanathan, and R. Garnett, ed-\nitors, Advances in Neural Information Process-\ning Systems 30, pages 2441–2451. Curran As-\nsociates, Inc.\nYonatan Belinkov, Lluís Màrquez, Hassan Sajjad,\nNadir Durrani, Fahim Dalvi, and James Glass.\n2017b. Evaluating Layers of Representation in\nNeural Machine Translation on Part-of-Speech\nand Semantic Tagging Tasks. In Proceedings\nof the Eighth International Joint Conference on\nNatural Language Processing (Volume 1: Long\nPapers), pages 1–10. Asian Federation of Natu-\nral Language Processing.\nJean-Philippe Bernardy. 2018.\nCan Recurrent\nNeural Networks Learn Nested Recursion?\nLiLT (Linguistic Issues in Language Technol-\nogy), 16(1).\nArianna Bisazza and Clara Tump. 2018. The Lazy\nEncoder: A Fine-Grained Analysis of the Role\nof Morphology in Neural Machine Translation.\nIn Proceedings of the 2018 Conference on Em-\npirical Methods in Natural Language Process-\ning, pages 2871–2876. Association for Compu-\ntational Linguistics.\nTerra Blevins, Omer Levy, and Luke Zettlemoyer.\n2018.\nDeep RNNs Encode Soft Hierarchical\nSyntax.\nIn Proceedings of the 56th Annual\nMeeting of the Association for Computational\nLinguistics (Volume 2: Short Papers), pages 14–\n19. Association for Computational Linguistics.\nMikael Bodén and Janet Wiles. 2002.\nOn\nlearning context-free and context-sensitive lan-\nguages.\nIEEE Transactions on Neural Net-\nworks, 13(2):491–493.\nSamuel R. Bowman, Gabor Angeli, Christopher\nPotts, and Christopher D. Manning. 2015.\nA\nlarge annotated corpus for learning natural lan-\nguage inference.\nIn Proceedings of the 2015\nConference on Empirical Methods in Natural\nLanguage Processing, pages 632–642. Associ-\nation for Computational Linguistics.\nElia Bruni, Gemma Boleda, Marco Baroni, and\nNam Khanh Tran. 2012. Distributional Seman-\ntics in Technicolor. In Proceedings of the 50th\nAnnual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers),\npages 136–145. Association for Computational\nLinguistics.\nGino Brunner, Yuyi Wang, Roger Wattenhofer,\nand Michael Weigelt. 2017. Natural Language\nMultitasking: Analyzing and Improving Syn-\ntactic Saliency of Hidden Representations. The\n31st Annual Conference on Neural Information\nProcessing (NIPS) - Workshop on Learning Dis-\nentangled Features: from Perception to Control.\nAljoscha Burchardt, Vivien Macketanz, Jon De-\nhdari, Georg Heigold, Jan-Thorsten Peter, and\nPhilip Williams. 2017. A Linguistic Evaluation\nof Rule-Based, Phrase-Based, and Neural MT\nEngines. The Prague Bulletin of Mathematical\nLinguistics, 108(1):159–170.\nFranck Burlot and François Yvon. 2017. Evaluat-\ning the morphological competence of Machine\nTranslation Systems. In Proceedings of the Sec-\nond Conference on Machine Translation, pages\n43–55. Association for Computational Linguis-\ntics.\nMike Casey. 1996.\nThe Dynamics of Discrete-\nTime Computation, with Application to Recur-\nrent Neural Networks and Finite State Machine\nExtraction.\nNeural computation, 8(6):1135–\n1178.\nDaniel Cer, Mona Diab, Eneko Agirre, Inigo\nLopez-Gazpio,\nand\nLucia\nSpecia.\n2017.\nSemEval-2017 Task 1: Semantic Textual Sim-\nilarity Multilingual and Crosslingual Focused\nEvaluation. In Proceedings of the 11th Inter-\nnational Workshop on Semantic Evaluation\n(SemEval-2017), pages 1–14. Association for\nComputational Linguistics.\nRahma Chaabouni, Ewan Dunbar, Neil Zeghi-\ndour, and Emmanuel Dupoux. 2017. Learning\nweakly supervised multimodal phoneme em-\nbeddings. In Interspeech 2017.\nStephan K. Chalup and Alan D. Blair. 2003. Incre-\nmental Training of First Order Recurrent Neu-\nral Networks to Predict a Context-sensitive Lan-\nguage. Neural Networks, 16(7):955–972.\nJonathan Chang, Sean Gerrish, Chong Wang, Jor-\ndan L. Boyd-graber, and David M. Blei. 2009.\nReading Tea Leaves: How Humans Interpret\nTopic Models. In Y. Bengio, D. Schuurmans,\nJ. D. Lafferty, C. K. I. Williams, and A. Cu-\nlotta, editors, Advances in Neural Information\nProcessing Systems 22, pages 288–296. Curran\nAssociates, Inc.\nHongge Chen, Huan Zhang, Pin-Yu Chen, Jinfeng\nYi, and Cho-Jui Hsieh. 2018a. Attacking visual\nlanguage grounding with adversarial examples:\nA case study on neural image captioning.\nIn\nProceedings of the 56th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers), pages 2587–2597. Asso-\nciation for Computational Linguistics.\nXinchi Chen, Xipeng Qiu, Chenxi Zhu, Shiyu Wu,\nand Xuanjing Huang. 2015. Sentence Model-\ning with Gated Recursive Neural Network. In\nProceedings of the 2015 Conference on Empir-\nical Methods in Natural Language Processing,\npages 793–798. Association for Computational\nLinguistics.\nYining Chen, Sorcha Gilroy, Andreas Maletti,\nJonathan May, and Kevin Knight. 2018b. Re-\ncurrent Neural Networks as Weighted Lan-\nguage Recognizers.\nIn Proceedings of the\n2018 Conference of the North American Chap-\nter of the Association for Computational Lin-\nguistics: Human Language Technologies, Vol-\nume 1 (Long Papers), pages 2261–2271. Asso-\nciation for Computational Linguistics.\nMinhao Cheng, Jinfeng Yi, Huan Zhang, Pin-Yu\nChen, and Cho-Jui Hsieh. 2018.\nSeq2Sick:\nEvaluating the Robustness of Sequence-to-\nSequence Models with Adversarial Examples.\narXiv preprint arXiv:1803.01128v1.\nGrzegorz Chrupała, Lieke Gelderloos, and Afra\nAlishahi. 2017. Representations of language in\na model of visually grounded speech signal. In\nProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers), pages 613–622. Associa-\ntion for Computational Linguistics.\nOndˇrej Cífka and Ondˇrej Bojar. 2018. Are BLEU\nand Meaning Representation in Opposition? In\nProceedings of the 56th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1362–1371. Asso-\nciation for Computational Linguistics.\nAlexis Conneau, Germán Kruszewski, Guillaume\nLample, Loïc Barrault, and Marco Baroni.\n2018. What you can cram into a single $&!#*\nvector: Probing sentence embeddings for lin-\nguistic properties. In Proceedings of the 56th\nAnnual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers),\npages 2126–2136. Association for Computa-\ntional Linguistics.\nRobin Cooper, Dick Crouch, Jan van Eijck, Chris\nFox, Josef van Genabith, Jan Jaspars, Hans\nKamp, David Milward, Manfred Pinkal, Mas-\nsimo Poesio, Steve Pulman, Ted Briscoe, Hol-\nger Maier, and Karsten Konrad. 1996. Using\nthe framework. Technical report, The FraCaS\nConsortium.\nFahim Dalvi,\nNadir Durrani,\nHassan Sajjad,\nYonatan Belinkov, D. Anthony Bau, and James\nGlass. 2019a.\nWhat Is One Grain of Sand\nin the Desert? Analyzing Individual Neurons\nin Deep NLP Models.\nIn Proceedings of the\nThirty-Third AAAI Conference on Artiﬁcial In-\ntelligence (AAAI).\nFahim Dalvi,\nNadir Durrani,\nHassan Sajjad,\nYonatan Belinkov, and Stephan Vogel. 2017.\nUnderstanding and Improving Morphological\nLearning in the Neural Machine Translation\nDecoder.\nIn Proceedings of the Eighth In-\nternational Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers),\npages 142–151. Asian Federation of Natural\nLanguage Processing.\nFahim Dalvi, Avery Nortonsmith, D. Anthony\nBau, Yonatan Belinkov, Hassan Sajjad, Nadir\nDurrani, and James Glass. 2019b.\nNeuroX:\nA Toolkit for Analyzing Individual Neurons\nin Neural Networks.\nIn Proceedings of the\nThirty-Third AAAI Conference on Artiﬁcial In-\ntelligence (AAAI): Demonstrations Track.\nSreerupa Das, C. Lee Giles, and Guo-Zheng Sun.\n1992. Learning Context-free Grammars: Capa-\nbilities and Limitations of a Recurrent Neural\nNetwork with an External Stack Memory. In\nProceedings of The Fourteenth Annual Confer-\nence of Cognitive Science Society. Indiana Uni-\nversity, page 14.\nIshita Dasgupta, Demi Guo, Andreas Stuhlmüller,\nSamuel J. Gershman, and Noah D. Good-\nman. 2018.\nEvaluating Compositionality\nin Sentence Embeddings.\narXiv preprint\narXiv:1802.04302v2.\nDhanush Dharmaretnam and Alona Fyshe. 2018.\nThe Emergence of Semantics in Neural Net-\nwork Representations of Visual Information.\nIn Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for\nComputational Linguistics: Human Language\nTechnologies, Volume 2 (Short Papers), pages\n776–780. Association for Computational Lin-\nguistics.\nYanzhuo Ding, Yang Liu, Huanbo Luan, and\nMaosong Sun. 2017.\nVisualizing and Under-\nstanding Neural Machine Translation. In Pro-\nceedings of the 55th Annual Meeting of the As-\nsociation for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1150–1159. Asso-\nciation for Computational Linguistics.\nFinale Doshi-Velez and Been Kim. 2017.\nTo-\nwards A Rigorous Science of Interpretable\nMachine\nLearning.\nIn\narXiv\npreprint\narXiv:1702.08608v2.\nFinale Doshi-Velez, Mason Kortz, Ryan Budish,\nChris Bavitz, Sam Gershman, David O’Brien,\nStuart Shieber, James Waldo, David Wein-\nberger, and Alexandra Wood. 2017. Account-\nability of AI Under the Law: The Role of Ex-\nplanation. Berkman Center Publication Forth-\ncoming.\nJennifer Drexler and James Glass. 2017. Analy-\nsis of Audio-Visual Features for Unsupervised\nSpeech Recognition.\nIn International Work-\nshop on Grounding Language Understanding.\nJavid Ebrahimi, Daniel Lowd, and Dejing Dou.\n2018a. On Adversarial Examples for Character-\nLevel Neural Machine Translation. In Proceed-\nings of the 27th International Conference on\nComputational Linguistics, pages 653–663. As-\nsociation for Computational Linguistics.\nJavid Ebrahimi, Anyi Rao, Daniel Lowd, and De-\njing Dou. 2018b. HotFlip: White-Box Adver-\nsarial Examples for Text Classiﬁcation. In Pro-\nceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Vol-\nume 2: Short Papers), pages 31–36. Association\nfor Computational Linguistics.\nAli Elkahky, Kellie Webster, Daniel Andor, and\nEmily Pitler. 2018. A Challenge Set and Meth-\nods for Noun-Verb Ambiguity. In Proceedings\nof the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 2562–\n2572. Association for Computational Linguis-\ntics.\nZied Elloumi, Laurent Besacier, Olivier Galib-\nert, and Benjamin Lecouteux. 2018. Analyzing\nLearned Representations of a Deep ASR Per-\nformance Prediction Model. In Proceedings of\nthe 2018 EMNLP Workshop BlackboxNLP: An-\nalyzing and Interpreting Neural Networks for\nNLP, pages 9–15. Association for Computa-\ntional Linguistics.\nJeffrey L. Elman. 1989. Representation and Struc-\nture in Connectionist Models. Technical report,\nUniversity of California, San Diego, Center for\nResearch in Language.\nJeffrey L. Elman. 1990.\nFinding Structure in\nTime. Cognitive science, 14(2):179–211.\nJeffrey L. Elman. 1991.\nDistributed representa-\ntions, simple recurrent networks, and grammat-\nical structure. Machine learning, 7(2-3):195–\n225.\nAllyson Ettinger, Ahmed Elgohary, and Philip\nResnik. 2016. Probing for semantic evidence\nof composition by means of simple classiﬁca-\ntion tasks. In Proceedings of the 1st Workshop\non Evaluating Vector-Space Representations for\nNLP, pages 134–139. Association for Computa-\ntional Linguistics.\nManaal Faruqui, Yulia Tsvetkov, Pushpendre Ras-\ntogi, and Chris Dyer. 2016.\nProblems With\nEvaluation of Word Embeddings Using Word\nSimilarity Tasks. In Proc. of the 1st Workshop\non Evaluating Vector Space Representations for\nNLP.\nManaal Faruqui, Yulia Tsvetkov, Dani Yogatama,\nChris Dyer, and Noah A. Smith. 2015. Sparse\nOvercomplete Word Vector Representations. In\nProceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and\nthe 7th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Pa-\npers), pages 1491–1500. Association for Com-\nputational Linguistics.\nShi Feng, Eric Wallace, Alvin Grissom II, Mo-\nhit Iyyer, Pedro Rodriguez, and Jordan Boyd-\nGraber. 2018.\nPathologies of Neural Models\nMake Interpretations Difﬁcult. In Proceedings\nof the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 3719–\n3728. Association for Computational Linguis-\ntics.\nLev Finkelstein, Evgeniy Gabrilovich, Yossi Ma-\ntias, Ehud Rivlin, Zach Solan, Gadi Wolfman,\nand Eytan Ruppin. 2002.\nPlacing Search in\nContext: The Concept Revisited. ACM Trans-\nactions on information systems, 20(1):116–131.\nRobert Frank,\nDonald Mathis,\nand William\nBadecker. 2013. The Acquisition of Anaphora\nby Simple Recurrent Networks. Language Ac-\nquisition, 20(3):181–227.\nCynthia Freeman, Jonathan Merriman, Abhinav\nAggarwal, Ian Beaver, and Abdullah Mueen.\n2018. Paying Attention to Attention: Highlight-\ning Inﬂuential Samples in Sequential Analysis.\narXiv preprint arXiv:1808.02113v1.\nAlona Fyshe, Leila Wehbe, Partha P. Talukdar,\nBrian Murphy, and Tom M. Mitchell. 2015.\nA Compositional and Interpretable Semantic\nSpace. In Proceedings of the 2015 Conference\nof the North American Chapter of the Associ-\nation for Computational Linguistics: Human\nLanguage Technologies, pages 32–41. Associ-\nation for Computational Linguistics.\nDavid Gaddy, Mitchell Stern, and Dan Klein.\n2018. What’s Going On in Neural Constituency\nParsers? An Analysis. In Proceedings of the\n2018 Conference of the North American Chap-\nter of the Association for Computational Lin-\nguistics: Human Language Technologies, Vol-\nume 1 (Long Papers), pages 999–1010. Associ-\nation for Computational Linguistics.\nJ. Ganesh, Manish Gupta, and Vasudeva Varma.\n2017.\nInterpretation of Semantic Tweet Rep-\nresentations.\nIn Proceedings of the 2017\nIEEE/ACM International Conference on Ad-\nvances in Social Networks Analysis and Mining\n2017, ASONAM ’17, pages 95–102, New York,\nNY, USA. ACM.\nJi Gao,\nJack Lanchantin,\nMary Lou Soffa,\nand Yanjun Qi. 2018.\nBlack-box Genera-\ntion of Adversarial Text Sequences to Evade\nDeep Learning Classiﬁers.\narXiv preprint\narXiv:1801.04354v5.\nLieke Gelderloos and Grzegorz Chrupała. 2016.\nFrom phonemes to images: Levels of represen-\ntation in a recurrent neural model of visually-\ngrounded language learning. In Proceedings of\nCOLING 2016, the 26th International Confer-\nence on Computational Linguistics: Technical\nPapers, pages 1309–1319, Osaka, Japan. The\nCOLING 2016 Organizing Committee.\nFelix A. Gers and Jürgen Schmidhuber. 2001.\nLSTM\nRecurrent\nNetworks\nLearn\nSimple\nContext-Free\nand\nContext-Sensitive\nLan-\nguages.\nIEEE\nTransactions\non\nNeural\nNetworks, 12(6):1333–1340.\nDaniela Gerz, Ivan Vuli´c, Felix Hill, Roi Reichart,\nand Anna Korhonen. 2016. SimVerb-3500: A\nLarge-Scale Evaluation Set of Verb Similarity.\nIn Proceedings of the 2016 Conference on Em-\npirical Methods in Natural Language Process-\ning, pages 2173–2182. Association for Compu-\ntational Linguistics.\nHamidreza Ghader and Christof Monz. 2017.\nWhat does Attention in Neural Machine Trans-\nlation Pay Attention to? In Proceedings of the\nEighth International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Pa-\npers), pages 30–39. Asian Federation of Natural\nLanguage Processing.\nReza Ghaeini, Xiaoli Fern, and Prasad Tadepalli.\n2018.\nInterpreting Recurrent and Attention-\nBased Neural Models: A Case Study on Nat-\nural Language Inference. In Proceedings of the\n2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 4952–4957.\nAssociation for Computational Linguistics.\nMario Giulianelli, Jack Harding, Florian Mohn-\nert, Dieuwke Hupkes, and Willem Zuidema.\n2018. Under the Hood: Using Diagnostic Clas-\nsiﬁers to Investigate and Improve how Lan-\nguage Models Track Agreement Information.\nIn Proceedings of the 2018 EMNLP Workshop\nBlackboxNLP: Analyzing and Interpreting Neu-\nral Networks for NLP, pages 240–248. Associ-\nation for Computational Linguistics.\nMax Glockner, Vered Shwartz, and Yoav Gold-\nberg. 2018. Breaking NLI Systems with Sen-\ntences that Require Simple Lexical Inferences.\nIn Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics\n(Volume 2: Short Papers), pages 650–655. As-\nsociation for Computational Linguistics.\nFréderic Godin, Kris Demuynck, Joni Dambre,\nWesley De Neve, and Thomas Demeester. 2018.\nExplaining Character-Aware Neural Networks\nfor Word-Level Prediction: Do They Discover\nLinguistic Rules?\nIn Proceedings of the 2018\nConference on Empirical Methods in Natural\nLanguage Processing, pages 3275–3284. Asso-\nciation for Computational Linguistics.\nYoav Goldberg. 2017. Neural Network methods\nfor Natural Language Processing, volume 10 of\nSynthesis Lectures on Human Language Tech-\nnologies. Morgan & Claypool Publishers.\nIan Goodfellow,\nYoshua Bengio,\nand Aaron\nCourville. 2016. Deep Learning. MIT Press.\nhttp://www.deeplearningbook.org.\nIan Goodfellow,\nJean Pouget-Abadie,\nMehdi\nMirza, Bing Xu, David Warde-Farley, Sherjil\nOzair, Aaron Courville, and Yoshua Bengio.\n2014.\nGenerative Adversarial Nets.\nIn Ad-\nvances in neural information processing sys-\ntems, pages 2672–2680.\nIan J. Goodfellow, Jonathon Shlens, and Christian\nSzegedy. 2015. Explaining and Harnessing Ad-\nversarial Examples.\nIn International Confer-\nence on Learning Representations (ICLR).\nKristina Gulordava, Piotr Bojanowski, Edouard\nGrave, Tal Linzen, and Marco Baroni. 2018.\nColorless Green Recurrent Networks Dream\nHierarchically.\nIn Proceedings of the 2018\nConference of the North American Chapter\nof the Association for Computational Linguis-\ntics: Human Language Technologies, Volume 1\n(Long Papers), pages 1195–1205. Association\nfor Computational Linguistics.\nAbhijeet Gupta, Gemma Boleda, Marco Baroni,\nand Sebastian Padó. 2015. Distributional vec-\ntors encode referential attributes. In Proceed-\nings of the 2015 Conference on Empirical Meth-\nods in Natural Language Processing, pages 12–\n21. Association for Computational Linguistics.\nPankaj Gupta and Hinrich Schütze. 2018. LISA:\nExplaining Recurrent Neural Network Judg-\nments via Layer-wIse Semantic Accumulation\nand Example to Pattern Transformation.\nIn\nProceedings of the 2018 EMNLP Workshop\nBlackboxNLP: Analyzing and Interpreting Neu-\nral Networks for NLP, pages 154–164. Associ-\nation for Computational Linguistics.\nSuchin Gururangan, Swabha Swayamdipta, Omer\nLevy, Roy Schwartz, Samuel Bowman, and\nNoah A. Smith. 2018. Annotation Artifacts in\nNatural Language Inference Data. In Proceed-\nings of the 2018 Conference of the North Amer-\nican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technolo-\ngies, Volume 2 (Short Papers), pages 107–112.\nAssociation for Computational Linguistics.\nCatherine L. Harris. 1990.\nConnectionism and\nCognitive Linguistics.\nConnection Science,\n2(1-2):7–33.\nDavid Harwath and James Glass. 2017.\nLearn-\ning Word-Like Units from Joint Audio-Visual\nAnalysis.\nIn Proceedings of the 55th Annual\nMeeting of the Association for Computational\nLinguistics (Volume 1:\nLong Papers), pages\n506–517. Association for Computational Lin-\nguistics.\nGeorg Heigold, Günter Neumann, and Josef van\nGenabith. 2018.\nHow Robust Are Character-\nBased Word Embeddings in Tagging and MT\nAgainst Wrod Scramlbing or Randdm Nouse?\nIn Proceedings of the 13th Conference of The\nAssociation for Machine Translation in the\nAmericas (Volume 1: Research Track), pages\n68–79.\nFelix Hill, Roi Reichart, and Anna Korhonen.\n2015.\nSimLex-999:\nEvaluating Semantic\nModels With (Genuine) Similarity Estimation.\nComputational Linguistics, 41(4):665–695.\nDieuwke Hupkes, Sara Veldhoen, and Willem\nZuidema. 2018.\nVisualisation and ’diagnos-\ntic classiﬁers’ reveal how recurrent and recur-\nsive neural networks process hierarchical struc-\nture. Journal of Artiﬁcial Intelligence Research,\n61:907–926.\nPierre Isabelle, Colin Cherry, and George Foster.\n2017. A Challenge Set Approach to Evaluat-\ning Machine Translation. In Proceedings of the\n2017 Conference on Empirical Methods in Nat-\nural Language Processing, pages 2486–2496.\nAssociation for Computational Linguistics.\nPierre Isabelle and Roland Kuhn. 2018. A Chal-\nlenge Set for French–> English Machine Trans-\nlation. arXiv preprint arXiv:1806.02725v2.\nHitoshi Isahara. 1995. JEIDA’s test-sets for qual-\nity evaluation of MT systems-technical evalua-\ntion from the developer’s point of view. In Pro-\nceedings of MT Summit V.\nMohit Iyyer, John Wieting, Kevin Gimpel, and\nLuke Zettlemoyer. 2018.\nAdversarial Exam-\nple Generation with Syntactically Controlled\nParaphrase Networks.\nIn Proceedings of the\n2018 Conference of the North American Chap-\nter of the Association for Computational Lin-\nguistics: Human Language Technologies, Vol-\nume 1 (Long Papers), pages 1875–1885. Asso-\nciation for Computational Linguistics.\nAlon Jacovi, Oren Sar Shalom, and Yoav Gold-\nberg. 2018. Understanding Convolutional Neu-\nral Networks for Text Classiﬁcation.\nIn Pro-\nceedings of the 2018 EMNLP Workshop Black-\nboxNLP: Analyzing and Interpreting Neural\nNetworks for NLP, pages 56–65. Association\nfor Computational Linguistics.\nInigo Jauregi Unanue, Ehsan Zare Borzeshi, and\nMassimo Piccardi. 2018. A Shared Attention\nMechanism for Interpretation of Neural Auto-\nmatic Post-Editing Systems. In Proceedings of\nthe 2nd Workshop on Neural Machine Transla-\ntion and Generation, pages 11–17. Association\nfor Computational Linguistics.\nRobin Jia and Percy Liang. 2017. Adversarial ex-\namples for evaluating reading comprehension\nsystems. In Proceedings of the 2017 Confer-\nence on Empirical Methods in Natural Lan-\nguage Processing, pages 2021–2031. Associa-\ntion for Computational Linguistics.\nRafal Jozefowicz, Oriol Vinyals, Mike Schuster,\nNoam Shazeer, and Yonghui Wu. 2016. Explor-\ning the Limits of Language Modeling.\narXiv\npreprint arXiv:1602.02410v2.\nAkos Kádár, Grzegorz Chrupała, and Afra Al-\nishahi. 2017.\nRepresentation of Linguistic\nForm and Function in Recurrent Neural Net-\nworks. Computational Linguistics, 43(4):761–\n780.\nAndrej\nKarpathy,\nJustin\nJohnson,\nand\nFei-\nFei Li. 2015.\nVisualizing and Understand-\ning Recurrent Networks.\narXiv preprint\narXiv:1506.02078v2.\nUrvashi Khandelwal, He He, Peng Qi, and Dan Ju-\nrafsky. 2018. Sharp Nearby, Fuzzy Far Away:\nHow Neural Language Models Use Context. In\nProceedings of the 56th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers), pages 284–294. Associa-\ntion for Computational Linguistics.\nMargaret King and Kirsten Falkedal. 1990. Using\nTest Suites in Evaluation of Machine Transla-\ntion Systems. In COLNG 1990 Volume 2: Pa-\npers presented to the 13th International Confer-\nence on Computational Linguistics.\nEliyahu Kiperwasser and Yoav Goldberg. 2016.\nSimple and Accurate Dependency Parsing Us-\ning Bidirectional LSTM Feature Representa-\ntions. Transactions of the Association for Com-\nputational Linguistics, 4:313–327.\nSungryong Koh, Jinee Maeng, Ji-Young Lee,\nYoung-Sook Chae, and Key-Sun Choi. 2001. A\ntest suite for evaluation of English-to-Korean\nmachine translation systems.\nIn MT Summit\nConference.\nArne Köhn. 2015. What’s in an Embedding? Ana-\nlyzing Word Embeddings through Multilingual\nEvaluation. In Proceedings of the 2015 Con-\nference on Empirical Methods in Natural Lan-\nguage Processing, pages 2067–2073, Lisbon,\nPortugal. Association for Computational Lin-\nguistics.\nVolodymyr\nKuleshov,\nShantanu\nThakoor,\nTingfung Lau,\nand Stefano Ermon. 2018.\nAdversarial Examples for Natural Language\nClassiﬁcation Problems.\nBrenden Lake and Marco Baroni. 2018. Gener-\nalization without Systematicity: On the Com-\npositional Skills of Sequence-to-Sequence Re-\ncurrent Networks. In Proceedings of the 35th\nInternational Conference on Machine Learning,\nvolume 80 of Proceedings of Machine Learning\nResearch, pages 2873–2882, Stockholmsmäs-\nsan, Stockholm, Sweden. PMLR.\nSabine Lehmann, Stephan Oepen, Sylvie Regnier-\nProst, Klaus Netter, Veronika Lux, Judith Klein,\nKirsten Falkedal, Frederik Fouvry, Dominique\nEstival, Eva Dauphin, Herve Compagnion, Ju-\ndith Baur, Lorna Balkan, and Doug Arnold.\n1996.\nTSNLP - Test Suites for Natural Lan-\nguage Processing. In COLING 1996 Volume 2:\nThe 16th International Conference on Compu-\ntational Linguistics.\nTao Lei, Regina Barzilay, and Tommi Jaakkola.\n2016.\nRationalizing Neural Predictions.\nIn\nProceedings of the 2016 Conference on Empir-\nical Methods in Natural Language Processing,\npages 107–117. Association for Computational\nLinguistics.\nIra Leviant and Roi Reichart. 2015.\nSeparated\nby an Un-common Language: Towards Judg-\nment Language Informed Vector Space Model-\ning. arXiv preprint arXiv:1508.00106v5.\nJiwei Li, Xinlei Chen, Eduard Hovy, and Dan Ju-\nrafsky. 2016a. Visualizing and Understanding\nNeural Models in NLP. In Proceedings of the\n2016 Conference of the North American Chap-\nter of the Association for Computational Lin-\nguistics: Human Language Technologies, pages\n681–691. Association for Computational Lin-\nguistics.\nJiwei Li,\nWill Monroe,\nand Dan Jurafsky.\n2016b.\nUnderstanding\nNeural\nNetworks\nthrough Representation Erasure. arXiv preprint\narXiv:1612.08220v3.\nBin Liang, Hongcheng Li, Miaoqiang Su, Pan\nBian, Xirong Li, and Wenchang Shi. 2018.\nDeep Text Classiﬁcation Can be Fooled.\nIn\nProceedings of the Twenty-Seventh Interna-\ntional Joint Conference on Artiﬁcial Intelli-\ngence, IJCAI-18, pages 4208–4215. Interna-\ntional Joint Conferences on Artiﬁcial Intelli-\ngence Organization.\nTal Linzen, Emmanuel Dupoux, and Yoav Gold-\nberg. 2016. Assessing the Ability of LSTMs to\nLearn Syntax-Sensitive Dependencies. Trans-\nactions of the Association for Computational\nLinguistics, 4:521–535.\nZachary C. Lipton. 2016. The Mythos of Model\nInterpretability. In ICML Workshop on Human\nInterpretability of Machine Learning.\nNelson F. Liu, Omer Levy, Roy Schwartz, Chen-\nhao Tan, and Noah A. Smith. 2018. LSTMs Ex-\nploit Linguistic Attributes of Data. In Proceed-\nings of The Third Workshop on Representation\nLearning for NLP, pages 180–186. Association\nfor Computational Linguistics.\nYanpei Liu, Xinyun Chen, Chang Liu, and Dawn\nSong. 2017. Delving into Transferable Adver-\nsarial Examples and Black-box Attacks. In In-\nternational Conference on Learning Represen-\ntations (ICLR).\nThang Luong, Richard Socher, and Christopher\nManning. 2013.\nBetter Word Representa-\ntions with Recursive Neural Networks for Mor-\nphology.\nIn Proceedings of the Seventeenth\nConference on Computational Natural Lan-\nguage Learning, pages 104–113. Association\nfor Computational Linguistics.\nJean Maillard and Stephen Clark. 2018.\nLa-\ntent Tree Learning with Differentiable Parsers:\nShift-Reduce Parsing and Chart Parsing.\nIn\nProceedings of the Workshop on the Relevance\nof Linguistic Structure in Neural Architectures\nfor NLP, pages 13–18. Association for Compu-\ntational Linguistics.\nMarco Marelli, Luisa Bentivogli, Marco Ba-\nroni, Raffaella Bernardi, Stefano Menini, and\nRoberto Zamparelli. 2014. SemEval-2014 Task\n1: Evaluation of Compositional Distributional\nSemantic Models on Full Sentences through\nSemantic Relatedness and Textual Entailment.\nIn Proceedings of the 8th International Work-\nshop on Semantic Evaluation (SemEval 2014),\npages 1–8. Association for Computational Lin-\nguistics.\nR. Thomas McCoy, Robert Frank, and Tal Linzen.\n2018. Revisiting the poverty of the stimulus:\nHierarchical generalization without a hierarchi-\ncal bias in recurrent neural networks. In Pro-\nceedings of the 40th Annual Conference of the\nCognitive Science Society.\nRisto Miikkulainen and Michael G. Dyer. 1991.\nNatural Language Processing With Modular\nPdp Networks and Distributed Lexicon. Cog-\nnitive Science, 15(3):343–399.\nTomáš Mikolov, Martin Karaﬁát, Lukáš Bur-\nget, Jan ˇCernock`y, and Sanjeev Khudanpur.\n2010. Recurrent neural network based language\nmodel. In Eleventh Annual Conference of the\nInternational Speech Communication Associa-\ntion.\nYao Ming, Shaozu Cao, Ruixiang Zhang, Zhen\nLi, Yuanzhe Chen, Yangqiu Song, and Huamin\nQu. 2017. Understanding Hidden Memories of\nRecurrent Neural Networks. In IEEE Confer-\nence on Visual Analytics Science and Technol-\nogy (IEEE VAST 2017).\nGrégoire Montavon, Wojciech Samek, and Klaus-\nRobert Müller. 2018. Methods for interpreting\nand understanding deep neural networks. Digi-\ntal Signal Processing, 73:1 – 15.\nPramod\nKaushik\nMudrakarta,\nAnkur\nTaly,\nMukund Sundararajan, and Kedar Dhamdhere.\n2018. Did the Model Understand the Question?\nIn Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics\n(Volume 1: Long Papers), pages 1896–1906.\nAssociation for Computational Linguistics.\nJames Mullenbach, Sarah Wiegreffe, Jon Duke,\nJimeng Sun, and Jacob Eisenstein. 2018. Ex-\nplainable Prediction of Medical Codes from\nClinical Text.\nIn Proceedings of the 2018\nConference of the North American Chapter\nof the Association for Computational Linguis-\ntics: Human Language Technologies, Volume 1\n(Long Papers), pages 1101–1111. Association\nfor Computational Linguistics.\nW. James Murdoch, Peter J. Liu, and Bin Yu.\n2018.\nBeyond Word Importance:\nContex-\ntual Decomposition to Extract Interactions from\nLSTMs. In International Conference on Learn-\ning Representations.\nBrian Murphy, Partha Talukdar, and Tom Mitchell.\n2012. Learning Effective and Interpretable Se-\nmantic Models using Non-Negative Sparse Em-\nbedding.\nIn Proceedings of COLING 2012,\npages 1933–1950. The COLING 2012 Organiz-\ning Committee.\nTasha Nagamine, Michael L. Seltzer, and Nima\nMesgarani. 2015. Exploring How Deep Neural\nNetworks Form Phonemic Categories. In Inter-\nspeech 2015.\nTasha Nagamine, Michael L. Seltzer, and Nima\nMesgarani. 2016.\nOn the Role of Nonlin-\near Transformations in Deep Neural Network\nAcoustic Models. In Interspeech 2016, pages\n803–807.\nAakanksha Naik, Abhilasha Ravichander, Nor-\nman Sadeh, Carolyn Rose, and Graham Neu-\nbig. 2018.\nStress Test Evaluation for Nat-\nural Language Inference.\nIn Proceedings of\nthe 27th International Conference on Compu-\ntational Linguistics, pages 2340–2353. Associ-\nation for Computational Linguistics.\nNina Narodytska and Shiva Kasiviswanathan.\n2017. Simple Black-Box Adversarial Attacks\non Deep Neural Networks. In 2017 IEEE Con-\nference on Computer Vision and Pattern Recog-\nnition Workshops (CVPRW), pages 1310–1318.\nLars Niklasson and Fredrik Linåker. 2000. Dis-\ntributed representations for extended syntac-\ntic transformation. Connection Science, 12(3-\n4):299–314.\nTong Niu and Mohit Bansal. 2018.\nAdversar-\nial Over-Sensitivity and Over-Stability Strate-\ngies for Dialogue Models.\nIn Proceedings of\nthe 22nd Conference on Computational Natural\nLanguage Learning, pages 486–496. Associa-\ntion for Computational Linguistics.\nNicolas Papernot, Patrick McDaniel, and Ian\nGoodfellow. 2016a.\nTransferability in Ma-\nchine Learning: From Phenomena to Black-\nBox Attacks using Adversarial Samples. arXiv\npreprint arXiv:1605.07277v1.\nNicolas Papernot, Patrick McDaniel, Ian Goodfel-\nlow, Somesh Jha, Z. Berkay Celik, and Anan-\nthram Swami. 2017. Practical Black-Box At-\ntacks Against Machine Learning. In Proceed-\nings of the 2017 ACM on Asia Conference on\nComputer and Communications Security, ASIA\nCCS ’17, pages 506–519, New York, NY, USA.\nACM.\nNicolas Papernot, Patrick McDaniel, Ananthram\nSwami, and Richard Harang. 2016b.\nCraft-\ning Adversarial Input Sequences for Recurrent\nNeural Networks. In Military Communications\nConference, MILCOM 2016-2016 IEEE, pages\n49–54. IEEE.\nDong Huk Park, Lisa Anne Hendricks, Zeynep\nAkata, Anna Rohrbach, Bernt Schiele, Trevor\nDarrell, and Marcus Rohrbach. 2018.\nMulti-\nmodal Explanations: Justifying Decisions and\nPointing to the Evidence. In The IEEE Confer-\nence on Computer Vision and Pattern Recogni-\ntion (CVPR).\nSungjoon Park, JinYeong Bak, and Alice Oh.\n2017.\nRotated Word Vector Representations\nand their Interpretability. In Proceedings of the\n2017 Conference on Empirical Methods in Nat-\nural Language Processing, pages 401–411. As-\nsociation for Computational Linguistics.\nMatthew Peters, Mark Neumann, Luke Zettle-\nmoyer, and Wen-tau Yih. 2018.\nDissecting\nContextual Word Embeddings:\nArchitecture\nand Representation. In Proceedings of the 2018\nConference on Empirical Methods in Natural\nLanguage Processing, pages 1499–1509. Asso-\nciation for Computational Linguistics.\nAdam Poliak, Aparajita Haldar, Rachel Rudinger,\nJ. Edward Hu, Ellie Pavlick, Aaron Steven\nWhite, and Benjamin Van Durme. 2018a. Col-\nlecting Diverse Natural Language Inference\nProblems for Sentence Representation Evalua-\ntion. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Pro-\ncessing, pages 67–81. Association for Compu-\ntational Linguistics.\nAdam\nPoliak,\nJason\nNaradowsky,\nAparajita\nHaldar,\nRachel\nRudinger,\nand\nBenjamin\nVan Durme. 2018b. Hypothesis Only Baselines\nin Natural Language Inference. In Proceedings\nof the Seventh Joint Conference on Lexical\nand Computational Semantics, pages 180–191.\nAssociation for Computational Linguistics.\nJordan\nB.\nPollack.\n1990.\nRecursive\ndis-\ntributed representations. Artiﬁcial Intelligence,\n46(1):77 – 105.\nPeng Qian, Xipeng Qiu, and Xuanjing Huang.\n2016a. Analyzing Linguistic Knowledge in Se-\nquential Model of Sentence. In Proceedings of\nthe 2016 Conference on Empirical Methods in\nNatural Language Processing, pages 826–835,\nAustin, Texas. Association for Computational\nLinguistics.\nPeng Qian, Xipeng Qiu, and Xuanjing Huang.\n2016b. Investigating Language Universal and\nSpeciﬁc Properties in Word Embeddings.\nIn\nProceedings of the 54th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1478–1488, Berlin,\nGermany. Association for Computational Lin-\nguistics.\nMarco Tulio Ribeiro, Sameer Singh, and Carlos\nGuestrin. 2018.\nSemantically Equivalent Ad-\nversarial Rules for Debugging NLP models. In\nProceedings of the 56th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers), pages 856–865. Associa-\ntion for Computational Linguistics.\nMat¯ıss\nRikters.\n2018.\nDebugging\nNeural\nMachine\nTranslations.\narXiv\npreprint\narXiv:1808.02733v1.\nAnnette Rios Gonzales, Laura Mascarell, and Rico\nSennrich. 2017. Improving Word Sense Disam-\nbiguation in Neural Machine Translation with\nSense Embeddings. In Proceedings of the Sec-\nond Conference on Machine Translation, pages\n11–19. Association for Computational Linguis-\ntics.\nTim\nRocktäschel,\nEdward\nGrefenstette,\nKarl\nMoritz\nHermann,\nTomáš\nKoˇcisk`y,\nand Phil Blunsom. 2016.\nReasoning about\nEntailment with Neural Attention. In Interna-\ntional Conference on Learning Representations\n(ICLR).\nAndras Rozsa, Ethan M. Rudd, and Terrance E.\nBoult. 2016.\nAdversarial Diversity and Hard\nPositive Generation.\nIn Proceedings of the\nIEEE Conference on Computer Vision and Pat-\ntern Recognition Workshops, pages 25–32.\nRachel\nRudinger,\nJason\nNaradowsky,\nBrian\nLeonard, and Benjamin Van Durme. 2018.\nGender Bias in Coreference Resolution. In Pro-\nceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Com-\nputational Linguistics: Human Language Tech-\nnologies, Volume 2 (Short Papers), pages 8–14.\nAssociation for Computational Linguistics.\nD. E. Rumelhart and J. L. McClelland. 1986. Par-\nallel Distributed Processing: Explorations in the\nMicrostructure of Cognition. volume 2, chapter\nOn Learning the Past Tenses of English Verbs,\npages 216–271. MIT Press, Cambridge, MA,\nUSA.\nAlexander M. Rush, Sumit Chopra, and Jason\nWeston. 2015. A Neural Attention Model for\nAbstractive Sentence Summarization. In Pro-\nceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing,\npages 379–389. Association for Computational\nLinguistics.\nKeisuke Sakaguchi, Kevin Duh, Matt Post, and\nBenjamin Van Durme. 2017. Robsut Wrod Re-\nocginiton via Semi-Character Recurrent Neu-\nral Network.\nIn Proceedings of the Thirty-\nFirst AAAI Conference on Artiﬁcial Intelli-\ngence, February 4-9, 2017, San Francisco, Cal-\nifornia, USA., pages 3281–3287. AAAI Press.\nSuranjana Samanta and Sameep Mehta. 2017.\nTowards Crafting Text Adversarial Samples.\narXiv preprint arXiv:1707.02812v1.\nIvan Sanchez, Jeff Mitchell, and Sebastian Riedel.\n2018. Behavior Analysis of NLI Models: Un-\ncovering the Inﬂuence of Three Factors on Ro-\nbustness. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the As-\nsociation for Computational Linguistics: Hu-\nman Language Technologies, Volume 1 (Long\nPapers), pages 1975–1985. Association for\nComputational Linguistics.\nMotoki Sato, Jun Suzuki, Hiroyuki Shindo, and\nYuji Matsumoto. 2018. Interpretable Adversar-\nial Perturbation in Input Embedding Space for\nText. In Proceedings of the Twenty-Seventh In-\nternational Joint Conference on Artiﬁcial In-\ntelligence, IJCAI-18, pages 4323–4330. Inter-\nnational Joint Conferences on Artiﬁcial Intelli-\ngence Organization.\nLutﬁKerem Senel, Ihsan Utlu, Veysel Yucesoy,\nAykut Koc, and Tolga Cukur. 2018.\nSeman-\ntic Structure and Interpretability of Word Em-\nbeddings. IEEE/ACM Transactions on Audio,\nSpeech, and Language Processing.\nRico Sennrich. 2017.\nHow Grammatical is\nCharacter-level Neural Machine Translation?\nAssessing MT Quality with Contrastive Trans-\nlation Pairs. In Proceedings of the 15th Confer-\nence of the European Chapter of the Association\nfor Computational Linguistics: Volume 2, Short\nPapers, pages 376–382. Association for Com-\nputational Linguistics.\nHaoyue Shi, Jiayuan Mao, Tete Xiao, Yuning\nJiang, and Jian Sun. 2018. Learning Visually-\nGrounded Semantics from Contrastive Adver-\nsarial Samples. In Proceedings of the 27th In-\nternational Conference on Computational Lin-\nguistics, pages 3715–3727. Association for\nComputational Linguistics.\nXing Shi, Kevin Knight, and Deniz Yuret. 2016a.\nWhy Neural Translations are the Right Length.\nIn Proceedings of the 2016 Conference on Em-\npirical Methods in Natural Language Process-\ning, pages 2278–2282. Association for Compu-\ntational Linguistics.\nXing Shi, Inkit Padhi, and Kevin Knight. 2016b.\nDoes String-Based Neural MT Learn Source\nSyntax?\nIn Proceedings of the 2016 Con-\nference on Empirical Methods in Natural Lan-\nguage Processing, pages 1526–1534, Austin,\nTexas. Association for Computational Linguis-\ntics.\nChandan Singh, W. James Murdoch, and Bin\nYu. 2018.\nHierarchical interpretations for\nneural network predictions.\narXiv preprint\narXiv:1806.05337v1.\nHendrik Strobelt, Sebastian Gehrmann, Michael\nBehrisch, Adam Perer, Hanspeter Pﬁster, and\nAlexander M. Rush. 2018a.\nSeq2Seq-Vis:\nA\nVisual\nDebugging\nTool\nfor\nSequence-\nto-Sequence\nModels.\narXiv\npreprint\narXiv:1804.09299v1.\nHendrik Strobelt, Sebastian Gehrmann, Hanspeter\nPﬁster, and Alexander M. Rush. 2018b. LST-\nMVis: A Tool for Visual Analysis of Hidden\nState Dynamics in Recurrent Neural Networks.\nIEEE transactions on visualization and com-\nputer graphics, 24(1):667–676.\nMukund Sundararajan, Ankur Taly, and Qiqi Yan.\n2017.\nAxiomatic Attribution for Deep Net-\nworks.\nIn Proceedings of the 34th Interna-\ntional Conference on Machine Learning, vol-\nume 70 of Proceedings of Machine Learning\nResearch, pages 3319–3328, International Con-\nvention Centre, Sydney, Australia. PMLR.\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le.\n2014.\nSequence to Sequence Learning with\nNeural Networks. In Advances in neural infor-\nmation processing systems, pages 3104–3112.\nMirac Suzgun, Yonatan Belinkov, and Stuart M.\nShieber. 2019. On Evaluating the Generaliza-\ntion of LSTM Models in Formal Languages. In\nProceedings of the Society for Computation in\nLinguistics (SCiL).\nChristian\nSzegedy,\nWojciech\nZaremba,\nIlya\nSutskever, Joan Bruna, Dumitru Erhan, Ian\nGoodfellow, and Rob Fergus. 2014.\nIntrigu-\ning properties of neural networks. In Interna-\ntional Conference on Learning Representations\n(ICLR).\nGongbo Tang, Rico Sennrich, and Joakim Nivre.\n2018. An Analysis of Attention Mechanisms:\nThe Case of Word Sense Disambiguation in\nNeural Machine Translation. In Proceedings of\nthe Third Conference on Machine Translation:\nResearch Papers, pages 26–35. Association for\nComputational Linguistics.\nYi Tay, Anh Tuan Luu, and Siu Cheung Hui.\n2018. CoupleNet: Paying Attention to Couples\nwith Coupled Attention for Relationship Rec-\nommendation. In Proceedings of the Twelfth In-\nternational AAAI Conference on Web and Social\nMedia (ICWSM).\nKe Tran, Arianna Bisazza, and Christof Monz.\n2018.\nThe Importance of Being Recurrent\nfor Modeling Hierarchical Structure.\nIn Pro-\nceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing,\npages 4731–4736. Association for Computa-\ntional Linguistics.\nEva Vanmassenhove, Jinhua Du, and Andy Way.\n2017.\nInvestigating ‘Aspect’ in NMT and\nSMT: Translating the English Simple Past and\nPresent Perfect. Computational Linguistics in\nthe Netherlands Journal, 7:109–128.\nSara Veldhoen, Dieuwke Hupkes, and Willem\nZuidema. 2016. Diagnostic Classiﬁers: Reveal-\ning how Neural Networks Process Hierarchical\nStructure. In CEUR Workshop Proceedings.\nElena Voita, Pavel Serdyukov, Rico Sennrich, and\nIvan Titov. 2018. Context-Aware Neural Ma-\nchine Translation Learns Anaphora Resolution.\nIn Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics\n(Volume 1: Long Papers), pages 1264–1274.\nAssociation for Computational Linguistics.\nEkaterina Vylomova, Trevor Cohn, Xuanli He,\nand Gholamreza Haffari. 2016.\nWord Rep-\nresentation Models for Morphologically Rich\nLanguages in Neural Machine Translation.\narXiv preprint arXiv:1606.04217v1.\nAlex Wang, Amapreet Singh, Julian Michael, Fe-\nlix Hill, Omer Levy, and Samuel R. Bowman.\n2018a. GLUE: A Multi-Task Benchmark and\nAnalysis Platform for Natural Language Under-\nstanding. arXiv preprint arXiv:1804.07461v1.\nShuai Wang, Yanmin Qian, and Kai Yu. 2017a.\nWhat Does the Speaker Embedding Encode? In\nInterspeech 2017, pages 1497–1501.\nXinyi Wang, Hieu Pham, Pengcheng Yin, and\nGraham Neubig. 2018b. A Tree-based Decoder\nfor Neural Machine Translation. In Conference\non Empirical Methods in Natural Language\nProcessing (EMNLP), Brussels, Belgium.\nYu-Hsuan Wang, Cheng-Tao Chung, and Hung-yi\nLee. 2017b.\nGate Activation Signal Analysis\nfor Gated Recurrent Neural Networks and Its\nCorrelation with Phoneme Boundaries. In In-\nterspeech 2017.\nGail Weiss, Yoav Goldberg, and Eran Yahav. 2018.\nOn the Practical Computational Power of Finite\nPrecision RNNs for Language Recognition. In\nProceedings of the 56th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 2: Short Papers), pages 740–745. Associa-\ntion for Computational Linguistics.\nAdina Williams, Andrew Drozdov, and Samuel R.\nBowman. 2018. Do latent tree learning mod-\nels identify meaningful structure in sentences?\nTransactions of the Association for Computa-\ntional Linguistics, 6:253–267.\nZhizheng Wu and Simon King. 2016. Investigat-\ning gated recurrent networks for speech syn-\nthesis.\nIn 2016 IEEE International Confer-\nence on Acoustics, Speech and Signal Process-\ning (ICASSP), pages 5140–5144. IEEE.\nPuyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-\nLing Wang, and Michael I. Jordan. 2018.\nGreedy Attack and Gumbel Attack: Generating\nAdversarial Examples for Discrete Data. arXiv\npreprint arXiv:1805.12316v1.\nWenpeng Yin, Hinrich Schütze, Bing Xiang, and\nBowen Zhou. 2016. ABCNN: Attention-Based\nConvolutional Neural Network for Modeling\nSentence Pairs. Transactions of the Association\nfor Computational Linguistics, 4:259–272.\nXiaoyong Yuan, Pan He, Qile Zhu, and Xiaolin\nLi. 2017. Adversarial Examples: Attacks and\nDefenses for Deep Learning.\narXiv preprint\narXiv:1712.07107v3.\nOmar Zaidan, Jason Eisner, and Christine Piatko.\n2007.\nUsing “Annotator Rationales” to Im-\nprove Machine Learning for Text Categoriza-\ntion. In Human Language Technologies 2007:\nThe Conference of the North American Chap-\nter of the Association for Computational Lin-\nguistics; Proceedings of the Main Conference,\npages 260–267. Association for Computational\nLinguistics.\nQuan-shi Zhang and Song-chun Zhu. 2018. Vi-\nsual interpretability for deep learning: A sur-\nvey.\nFrontiers of Information Technology &\nElectronic Engineering, 19(1):27–39.\nYe Zhang, Iain Marshall, and Byron C. Wal-\nlace. 2016.\nRationale-Augmented Convolu-\ntional Neural Networks for Text Classiﬁcation.\nIn Proceedings of the 2016 Conference on Em-\npirical Methods in Natural Language Process-\ning, pages 795–804. Association for Computa-\ntional Linguistics.\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente\nOrdonez, and Kai-Wei Chang. 2018a.\nGen-\nder Bias in Coreference Resolution: Evaluation\nand Debiasing Methods. In Proceedings of the\n2018 Conference of the North American Chap-\nter of the Association for Computational Lin-\nguistics: Human Language Technologies, Vol-\nume 2 (Short Papers), pages 15–20. Association\nfor Computational Linguistics.\nJunbo Zhao, Yoon Kim, Kelly Zhang, Alexan-\nder Rush, and Yann LeCun. 2018b. Adversar-\nially Regularized Autoencoders.\nIn Proceed-\nings of the 35th International Conference on\nMachine Learning, volume 80 of Proceedings\nof Machine Learning Research, pages 5902–\n5911, Stockholmsmässan, Stockholm, Sweden.\nPMLR.\nZhengli Zhao, Dheeru Dua, and Sameer Singh.\n2018c. Generating Natural Adversarial Exam-\nples. In International Conference on Learning\nRepresentations.\nSupplementary Materials\nReference\nComponent\nProperty\nMethod\n(Elloumi et al., 2018)\nCNN activations\nStyle, accent, broadcast program\nClassiﬁcation\n(Belinkov and Glass, 2017)\nCNN/RNN activations\nPhonetic units\nClassiﬁcation\n(Dalvi et al., 2019a)\nNMT and LM neurons\nPOS, morphology, lexical semantics\nClassiﬁcation\n(Shi et al., 2016a)\nNMT encoder neurons\nSentence length\nRegression\n(Belinkov et al., 2017b)\nNMT states\nPOS, lexical semantics\nClassiﬁcation\n(Belinkov\net\nal.,\n2017a;\nDalvi et al., 2017)\nNMT states\nPOS, morphology\nClassiﬁcation\n(Bisazza and Tump, 2018)\nNMT states\nMorphology\nClassiﬁcation\n(Tran et al., 2018)\nRNN\n/\nself-attention\nstates\nSubject-verb agreement\nLikelihood\ncom-\nparison,\ndirect\nclassiﬁcation\n(Wang et al., 2017b)\nRNN gates\nPhoneme boundaries\nChange in activa-\ntion signal\n(McCoy et al., 2018)\nRNN sentence embed-\nding\nHierarchical structure\nClassiﬁcation\n(Blevins et al., 2018)\nRNN states\nPOS, ancestor label prediction, dependency\nrelation prediction\nClassiﬁcation\n(Shi et al., 2016b)\nRNN states\nPOS, top syntactic sequence, smallest con-\nstituent, tense, voice\nClassiﬁcation\n(Gulordava et al., 2018)\nRNN states\nNumber agreement\nLikelihood\ncom-\nparison\n(Linzen et al., 2016)\nRNN states\nSubject-verb agreement\nLikelihood\ncom-\nparison,\ndirect\nclassiﬁcation\n(Liu et al., 2018)\nRNN states\nWord presence\nDirect classiﬁca-\ntion\n(Alishahi et al., 2017)\nRNN states in audio-\nvisual model\nPhonemes, synonyms\nClassiﬁcation,\nclustering,\ndis-\ncrimination\n(Gelderloos and Chrupała,\n2016)\nRNN\nstates\nin\nlanguage-vision model\nWord boundary, word similarity\nClassiﬁcation\n(Qian et al., 2016a)\nRNN states/gates\nPOS, syntactic role, gender, case, deﬁnite-\nness, verb form, mood\nClassiﬁcation,\ncorrelation\n(Wu and King, 2016)\nRNN states/gates\nAcoustic features\nCorrelation\n(Ghader and Monz, 2017)\nAttention weights\nPOS, word alignment\nDistribution mea-\nsures, match with\nalignments\n(Voita et al., 2018)\nAttention weights\nAnaphora\nAttention score\n(Tang et al., 2018)\nAttention weights\nWord sense disambiguation\nDistribution mea-\nsures\n(Drexler and Glass, 2017)\nAudio-visual CNN ac-\ntivations\nPhonemes, speakers, word identity\nClustering,\ndis-\ncrimination\n(Harwath and Glass, 2017)\nAudio-visual CNN em-\nbeddings\nWord classes\nClustering\n(Chrupała et al., 2017)\nAudio-visual RNN ac-\ntivations\nUtterance length, word presence, homonym\ndisambiguation\nClassiﬁcation, re-\ngression, similar-\nity measures\n(Peters et al., 2018)\nbiLM\nrepresentations\n(RNN,\nTransformer,\ngated CNN)\nPOS, constituency parsing, coreference\nClassiﬁcation;\nsimilarity scores\n(Nagamine et al., 2016)\nHidden activations in\nfeed-forward\nacoustic\nmodel\nPhonemes, phonetic features\nClassiﬁcation,\nclustering\nmea-\nsures\nTable SM1: A categorization of work trying to ﬁnd linguistic information in neural networks according\nto the neural network component investigated, the linguistic property sought, and the analysis method.\nContinued on next page\nContinued from previous page\nReference\nComponent\nProperty\nMethod\n(Nagamine et al., 2015)\nHidden activations in\nfeed-forward\nacoustic\nmodel\nPhonemes, phonetic features, gender\nClustering,\naver-\nage activations by\ngroup/label\n(Chaabouni et al., 2017)\nHidden activations in\nfeed-forward\naudio-\nvisual model\nPhonetic features\nDiscrimination\n(Vylomova et al., 2016)\nNMT word embeddings\nsynonyms, morphological features\nNearest neighbors\n(Gaddy et al., 2018)\nParser\nword\nembed-\ndings\nWord features (shape, etc.)\nClassiﬁcation;\nalso other meth-\nods\n(Ettinger et al., 2016)\nSentence embeddings\nSemantic role, word presence\nClassiﬁcation\n(Adi et al., 2017a,b)\nSentence embeddings\nSentence length, word presence, word order\nClassiﬁcation\n(Ahmad et al., 2018)\nSentence embeddings\nSentence length, word presence, word order;\nPOS, word sense disambiguation; sentence\norder\nClassiﬁcation\n(Ganesh et al., 2017)\nSentence embeddings\nSentence length, word presence, word order;\northography; social tasks\nClassiﬁcation\n(Conneau et al., 2018)\nSentence embeddings\nSentence length, word presence, word order;\ntree depth, top constituent; main tense, sub-\nject/object number, semantic odd man out,\ncoordinate inversion\nClassiﬁcation\n(Brunner et al., 2017)\nSentence embeddings\nSynthetic syntactic patterns\nClustering\n(Wang et al., 2017a)\nSpeaker embeddings\nSpeaker, speech content, word order, utter-\nance length, channel, gender, speaking rate\nClassiﬁcation\n(Qian et al., 2016b)\nWord embeddings\nPOS, dependency relations, morphological\nfeatures, emotions\nClassiﬁcation\n(Köhn, 2015)\nWord embeddings\nPOS, head POS, dependency relation, gender,\ncase, number, tense\nClassiﬁcation\n(Gupta et al., 2015)\nWord embeddings\nReferential attributes\nClassiﬁcation\n(Dharmaretnam and Fyshe,\n2018)\nWord embeddings, vi-\nsion CNN\nConcepts\nSimilarity\nmea-\nsures\nTable SM1: A categorization of work trying to ﬁnd linguistic information in neural networks according\nto the neural network component investigated, the linguistic property sought, and the analysis method.\nReference\nTask\nPhenomena\nLanguages\nSize\nConstruction\n(Naik et al., 2018)\nNLI\nAntonyms, quantities, spelling,\nword overlap, negation, length\nEnglish\n7596\nAutomatic\n(Dasgupta et al., 2018)\nNLI\nCompositionality\nEnglish\n44010\nAutomatic\n(Sanchez et al., 2018)\nNLI\nAntonyms, hyper/hyponyms\nEnglish\n6279\nSemi-auto.\n(Wang et al., 2018a)\nNLI\nDiverse semantics\nEnglish\n550\nManual\n(Glockner et al., 2018)\nNLI\nLexical inference\nEnglish\n8193\nSemi-auto.\n(Poliak et al., 2018a)\nNLI\nDiverse\nEnglish\n570K\nManual,\nsemi-auto.,\nautomatic\n(Rios Gonzales et al.,\n2017)\nMT\nWord sense disambiguation\nGerman→English/\nFrench\n13900\nSemi-auto.\n(Burlot and Yvon, 2017)\nMT\nMorphology\nEnglish→Czech/Latvian\n18500\nAutomatic\n(Sennrich, 2017)\nMT\nPolarity, verb-particle construc-\ntions, agreement, transliteration\nEnglish→German\n97K\nAutomatic\n(Bawden et al., 2018)\nMT\nDiscourse\nEnglish→French\n400\nManual\n(Isabelle et al., 2017; Is-\nabelle and Kuhn, 2018)\nMT\nMorpho-syntax, syntax, lexicon\nEnglish↔French\n108 + 506\nManual\n(Burchardt et al., 2017)\nMT\nDiverse\nEnglish↔German\n10000\nManual\n(Linzen et al., 2016)\nLM\nSubject-verb agreement\nEnglish\n∼1.35M\nAutomatic\n(Gulordava et al., 2018)\nLM\nNumber agreement\nEnglish,\nRussian,\nHebrew, Italian\n∼10K\nAutomatic\n(Rudinger et al., 2018)\nCoref.\nGender bias\nEnglish\n720\nSemi-auto.\n(Zhao et al., 2018a)\nCoref.\nGender bias\nEnglish\n3160\nSemi-auto.\n(Lake and Baroni, 2018)\nseq2seq\nCompositionality\nEnglish\n20910\nAutomatic\n(Elkahky et al., 2018)\nPOS\ntagging\nNoun-verb ambiguity\nEnglish\n32654\nSemi-auto.\nTable SM2: A categorization of challenge sets for evaluating neural networks according to the NLP task,\nthe linguistic phenomena, the represented languages, the dataset size, and the construction method.\nMethod\nKnowledge\nTargeted\nUnit\nTask\n(Belinkov and Bisk, 2018)\nBlack\n\u0017\nChar\nMT\n(Heigold et al., 2018)\nBlack\n\u0017\nChar\nMT, morphology\n(Sakaguchi et al., 2017)\nBlack\n\u0017\nChar\nSpelling correction\n(Zhao et al., 2018c)\nBlack\n\u0013, \u0017\nWord\nMT, natural language inference\n(Gao et al., 2018)\nBlack\n\u0017\nChar\nText classiﬁcation, sentiment\n(Jia and Liang, 2017)\nBlack\n\u0017\nSentence\nReading comprehension\n(Iyyer et al., 2018)\nBlack\n\u0017\nSyntax\nSentiment, entailment\n(Shi et al., 2018)\nBlack\n\u0017\nWord\nImage captioning\n(Alzantot et al., 2018)\nBlack\n\u0017\nWord\nNLI, sentiment\n(Kuleshov et al., 2018)\nBlack\n\u0017\nWord\nText classiﬁcation, sentiment\n(Ribeiro et al., 2018)\nBlack\n\u0017\nWord\nReading comprehension, visual QA, sentiment\n(Niu and Bansal, 2018)\nBlack\n\u0017\nWord\nDialogue\n(Chen et al., 2018a)\nWhite\n\u0013\nPixels\nImage captioning\n(Ebrahimi et al., 2018a)\nWhite\n\u0013\nWord\nMT\n(Cheng et al., 2018)\nWhite\n\u0013\nWord\nMT, summarization\n(Mudrakarta et al., 2018)\nWhite\n\u0017\nWord\nReading comprehension, visual and table QA\n(Papernot et al., 2016b)\nWhite\n\u0017\nWord\nSentiment\n(Samanta and Mehta, 2017)\nWhite\n\u0017\nWord\nSentiment, gender detection\n(Sato et al., 2018)\nWhite\n\u0017\nWord\nText classiﬁcation, sentiment, grammatical er-\nror detection\n(Liang et al., 2018)\nWhite\n\u0013\nWord/Char Text classiﬁcation\n(Ebrahimi et al., 2018b)\nWhite\n\u0017\nWord/Char Text classiﬁcation\n(Yang et al., 2018)\nWhite\n\u0017\nWord/Char Text classiﬁcation\nTable SM3: A categorization of methods for adversarial examples in NLP according to adversary’s knowl-\nedge (white-box vs. black-box), attack speciﬁcity (targeted vs. non-targeted), the modiﬁed linguistic unit\n(words, characters, etc.), and the attacked task.\n",
  "categories": [
    "cs.CL",
    "cs.LG",
    "cs.NE",
    "68T50",
    "I.2.7"
  ],
  "published": "2018-12-21",
  "updated": "2019-01-14"
}