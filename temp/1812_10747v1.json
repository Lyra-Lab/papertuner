{
  "id": "http://arxiv.org/abs/1812.10747v1",
  "title": "Off-the-grid model based deep learning (O-MODL)",
  "authors": [
    "Aniket Pramanik",
    "Hemant Kumar Aggarwal",
    "Mathews Jacob"
  ],
  "abstract": "We introduce a model based off-the-grid image reconstruction algorithm using\ndeep learned priors. The main difference of the proposed scheme with current\ndeep learning strategies is the learning of non-linear annihilation relations\nin Fourier space. We rely on a model based framework, which allows us to use a\nsignificantly smaller deep network, compared to direct approaches that also\nlearn how to invert the forward model. Preliminary comparisons against image\ndomain MoDL approach demonstrates the potential of the off-the-grid\nformulation. The main benefit of the proposed scheme compared to structured\nlow-rank methods is the quite significant reduction in computational\ncomplexity.",
  "text": "OFF-THE-GRID MODEL BASED DEEP LEARNING (O-MODL)\nAniket Pramanik, Hemant Aggarwal, Mathews Jacob\nUniversity of Iowa, Iowa, USA\nABSTRACT\nWe introduce a model based off-the grid image reconstruction\nalgorithm using deep learned priors. The main difference of\nthe proposed scheme with current deep learning strategies\nis the learning of non-linear annihilation relations in Fourier\nspace. We rely on a model based framework, which allows\nus to use a signiÔ¨Åcantly smaller deep network, compared\nto direct approaches that also learn how to invert the for-\nward model. Preliminary comparisons against image domain\nMoDL approach demonstrates the potential of the off-the-grid\nformulation. The main beneÔ¨Åt of the proposed scheme com-\npared to structured low-rank methods is the quite signiÔ¨Åcant\nreduction in computational complexity.\nIndex Terms‚Äî off-the-grid, CNN, MRI\n1. INTRODUCTION\nThe recovery of images from undersampled Fourier measure-\nments is a classic problem in MRI and several other modal-\nities. The popular approach is to constrain the reconstruc-\ntions using compactness priors including sparsity.\nSeveral\nresearchers have recently introduced off-the-grid continuous\ndomain priors that are robust to discretization errors [1, 2],\nwhich provide signiÔ¨Åcantly improved image quality in a range\nof applications. However, the main challenge is the signiÔ¨Åcant\nincrease in computational complexity.\nRecently, several researchers have introduced deep learn-\ning methods as fast and efÔ¨Åcient alternatives to compressed\nsensing algorithms. Current approaches can be categorized\ninto direct and model based strategies. The direct approaches\ndirectly estimate the images from the undersampled measure-\nments or their transforms/features [3, 4]. These methods learn\nto invert the forward operator over the space/manifold of im-\nages. While this approach is more popular, a challenge with\nthese schemes is the need to learn the inverse, which often\nrequires large models (e.g. UNET); this often translates to\nthe need for extensive training data. Model based strategies\ninstead formulate the recovery as a penalized optimization\nproblem using a forward model that mimics the acquisition\nscheme [5]; the penalty is designed to encourage the recon-\nstructed image to be close to the space/manifold of images.\nSince they rely on an explicit forward model, they often only\nThis work is supported by NIH 1R01EB019961-01A1.\nrequire a much smaller network than direct methods, which\nsigniÔ¨Åcantly reduces the training data demand. Recent stud-\nies also show the beneÔ¨Åt in sharing the network parameters\nacross iterations, end-to-end training, as well as using opti-\nmization blocks within the network [5].\nThe main focus of this work is to extend deep learning\nto the off-the-grid setting, similar to the structured low-\nrank setting in [1, 2]. SpeciÔ¨Åcally, we consider an iterative\nreweighted least-squares (IRLS) formulation of our off-the-\ngrid algorithm, termed as GIRAF. We show that the structure\nof GIRAF, which alternates between data consistency en-\nforcement and denoising of the Fourier coefÔ¨Åcients of the\npartial derivatives by projecting it to the constraint set, has\nextensive similarities to the MoDL framework.\nThe main\ndifference with MoDL is that the learning is performed in the\nFourier domain, and the denoising network is linear; GIRAF\nrelies on a residual convolution and deconvolution (Ô¨Çipped\nconvolution) denoising Ô¨Ålter-bank with shared Ô¨Ålters, which\nis learned from the available k-space measurements in an\niterative fashion. The residual Ô¨Ålterbank projects the Fourier\ncoefÔ¨Åcients to the signal subspace, thus denoising them. To\nsigniÔ¨Åcantly reduce the computational complexity of these\noff-the-grid methods, we propose to use a deep non-linear\nconvolutional neural network as the denoiser for the Fourier\ncoefÔ¨Åcients of the partial derivatives. Similar to GIRAF, we\npropose to use convolutional and deconvolutional blocks with\nshared parameters. The parameters of the deep network are\nlearned in an end-to-end fashion as in MoDL. This work has\nconnections with k-space deep learning approach [6], which\nfollows a direct approach of estimating images from measure-\nments, bypassing a forward model. By contrast, we follow a\nmodel based strategy, which has the beneÔ¨Åts discussed above.\nWe determine the utility of the proposed scheme in the\nsingle coil image recovery setting.\nThanks to the MoDL\nformulation, few training datasets were sufÔ¨Åcient to reliably\nlearn the parameters of the model. The comparisons of the\nproposed scheme against MoDL shows the potential of the\nproposed scheme.\nOur future work will focus on the ex-\ntension of the framework to the multi-coil setting and more\nelaborate comparisons with state of the art algorithms.\n2. PROBLEM SETTING AND BACKGROUND\nWe consider the recovery of the Fourier coefÔ¨Åcients of a func-\ntion f(r) from its noisy undersampled Fourier measurements\narXiv:1812.10747v1  [cs.LG]  27 Dec 2018\nb = AÀÜf + Œ∑, where ÀÜf denotes the Fourier transform of f(r),\nand A is an undersampling matrix, while Œ∑ is additive noise.\n2.1. Piecewise smooth images & annihilation relations\nRecent work off-the-grid methods [1, 2] model the signal f to\nbe piecewise smooth, when the partial derivatives of f vanish\neverywhere except on an edge set. Similar to [1], we model\nthe edge set as the zero-set of a bandlimited function ¬µ. With\nthese assumptions, the Ô¨Årst order partial derivatives of the sig-\nnal satisÔ¨Åes ‚àáf.¬µ = 0, which translates to c\n‚àáf ‚àóh = 0,\nwhere h\nF‚Üî¬µ is the bandlimited Fourier transform of ¬µ. The\ntheory in [1] shows that if the assumed size of the Ô¨Ålter h is\ngreater than the true bandwidth, there exist several linearly\nindependent Ô¨Ånite impulse response (FIR) Ô¨Ålters that satisfy\nc\n‚àáf‚àóhi = 0; i = 1, .., N. The above relation can be expressed\nin a matrix form as\n\u0002\nG(h1)\nG(h2)\n. . .\nG(hN)\n\u0003\n|\n{z\n}\nT (H)\nc\n‚àáf = 0.\n(1)\nHere, G(hi) is a block Toeplitz matrix that corresponds to 2-D\nconvolution. i.e, G(hi) c\n‚àáf = hi ‚àóc\n‚àáf. Using commutativity\nof convolutions, the above relation can also be expressed as\nÔ£Æ\nÔ£∞G\n\u0010\nbfx\n\u0011\nG\n\u0010\nbfy\n\u0011\nÔ£π\nÔ£ª\n|\n{z\n}\nT ( c\n‚àáf)\nH = 0.\n(2)\nwhere G(bfx) is the block Toeplitz matrix constructed from bfx.\n2.2. GIRAF algorithm for off-the-grid image recovery\nIn practice, the Ô¨Ålters hi; i = 1, .., N are unknown. Two step\nmethods [1, 2] estimate the Ô¨Ålters hi; i = 1, .., N or equiv-\nalently T (H) from fully sampled regions of Fourier space,\nwhich is also called as calibration regions, using (2). When\nthe Fourier samples are non-uniformly sampled, the above\ntwo step approach is not feasible. Note that (2) implies that\nthe matrix T (H) is low-rank. The unconstrained version of\nGIRAF algorithm poses the recovery as\nÀÜf = arg min\nÀÜ\nf\nŒª\n\r\r\rT ( c\n‚àáf)\n\r\r\r\n‚àó+ ‚à•A ÀÜf ‚àíb‚à•2,\n(3)\nwhere ‚à•¬∑ ‚à•‚àóis the nuclear norm that encourages the matrix\nto be low-rank. GIRAF relies on an iterative least squares\noptimization problem, which majorizes the nuclear norm as\n‚à•T( c\n‚àáf)‚à•‚àó‚â§‚à•T( c\n‚àáf)H‚à•2\nF . This algorithm alternates be-\ntween the estimation of H as H =\n\u0002\nT‚àó(T( c\n‚àáf)) + œµI\n\u0003‚àí1/4\nand updating f by\nÀÜf = arg min\nÀÜ\nf\nŒª‚à•T (H) c\n‚àáf‚à•2\nF + ‚à•A ÀÜf ‚àíb‚à•2\n(4)\nùõÅ(. )\nGradient\nNw\nDC Layer, \nEq. (6)\nDw\nzx,zy\nAHb\nfn\n(a) Iterative algorithm\nConv \nG(H) \nDeConv \nG(H)H \n‚àáùëì \nz \n(b) GIRAF residual denoising block\nConv \nBN \ntanh \nConv \nBN \ntanh \nDeconv \nBN \ntanh \nDeconv \nBN \nN \ntimes \nLayer 2N \nLayer N+1 \nLayer N \nLayer 1 \nN \ntimes \nDw \nShared weights \n(c) O-MoDL residual denoising block\nFig. 1. Outline of the recursive learning architectures. (a) Pro-\nposed iterative algorithm, which alternates between a residual\ndenoiser block and data-consistency block. GIRAF and O-\nMoDL frameworks differs only in the structure of the residual\ndenoiser blocks, shown in (b) and (c), respectively. (b). GI-\nRAF residual denoising block, where the Ô¨Ålters H are learned\nusing structured low-rank matrix completion. (c) O-MoDL\nresidual denoising block: the linear denoiser in GIRAF is re-\nplaced by a deep CNN architecture, which uses convolution\nand deconvolution blocks. The Ô¨Ålter parameters of the corre-\nsponding convolution and deconvolution blocks are shared.\nA challenge with the alternating minimization strategy is the\nhigh computational complexity of the algorithm. Motivated\nby the fast computation offered by our MoDL framework [5],\nwe introduce a deep learning solution.\n3. OFF-THE-GRID MODEL BASED DEEP\nLEARNING (O-MODL)\nWe Ô¨Årst show that the GIRAF algorithm can be viewed as\na recursive network, which has alternating blocks imposing\ndata consistency and denoising of the data.\n3.1. Network structure of GIRAF\nWe consider a penalized version of (4), using an auxiliary\nvariable z:\nC {f, z}\n=\narg min\nf,z ‚à•A ÀÜf ‚àíb‚à•2 + Œ≤‚à•c\n‚àáf ‚àíz‚à•2 +\nŒª‚à•T (H) z‚à•2\nF\n(5)\n(a) Original\n(b) MoDL\n(c) Proposed\n(d) SENSE\n(e) AHb\n(f) MoDL\n(g) Proposed\n(h) SENSE\n(i) Original\n(j) MoDL\n(k) Proposed\n(l) SENSE\n(m) AHb\n(n) MoDL\n(o) Proposed\n(p) SENSE\nFig. 2. Reconstruction results of two-fold accelerated data.\nFigures (a)-(h) correspond to Coil 1 images while (i)-(p) cor-\nrespond to Coil 6 images. (b) MoDL:16.33 db (c) O-MoDL:\n18.57 db, (d) SENSE: 12.72 db, (f)-(h) are the error images.\n(j) MoDL,16.74 db (k) O-MoDL,18.98 db, (l) SENSE, 12.88\ndb, (n)-(p) are the error images.\nNote that the above formulation is equivalent to (4) when Œ≤ ‚Üí\n‚àû. We use an alternating algorithm to solve for f and z:\nfn+1\n=\narg min\nÀÜ\nf\n‚à•A ÀÜf ‚àíb‚à•2 + Œ≤‚à•c\n‚àáf ‚àízn‚à•2\n(6)\nzn+1\n=\narg min\nz Œ≤‚à•‚àád\nfn+1 ‚àíz‚à•2 + Œª‚à•T (H) z‚à•2\nF (7)\nProblem (6) is analytically solved, when A is a sampling op-\nerator. Solving (7), we get z =\nh\nI +\nŒª\nŒ≤ T (H)HT (H)\ni‚àí1 c\n‚àáf.\nUsing matrix inversion lemma and assuming Œª << Œ≤, we ap-\nproximate the solution as:\nz ‚âà\n\u0014\nI ‚àíŒª\nŒ≤ T (H)HT (H)\n\u0015\nc\n‚àáf.\n(8)\nNote from (2) that Ô¨Ålters H are surrogates for the null\nspace of T ( c\n‚àáf). Hence, T (H)HT (H) z can be viewed as\nthe projection of z onto the null-space of H; (8) can be viewed\nas a residual block, which removes the null-space components\nof c\n‚àáf. The alternating algorithm speciÔ¨Åed by (8) and (6) can\nbe unrolled to a deep architecture as in [5].\n3.2. Deep learning in k-space\nMotivated by the success of MoDL [5], we introduce a novel\ndeep learning solution to reduce the computational complex-\nity of GIRAF. SpeciÔ¨Åcally, we replace the denoiser in GIRAF,\nspeciÔ¨Åed by (8), by a CNN, whose parameters are learned\nfrom exemplar data. The structure of O-MoDL is similar to\nGIRAF, involving two alternating blocks, Dw = I ‚àíNw (de-\nnoiser) and DC (data consistency). We rely on an n-layer O-\nMoDL Nw block consists of ‚Äôn‚Äô convolution layers followed\nby ‚Äôn‚Äô deconvolution (convolution with Ô¨Çipped Ô¨Ålters) layers,\nfollowed by batch normalization (BN) and non-linear activa-\ntion function. We chose the non-linear activation function as\na hyperbolic tangent (tanh) activation function. Each convo-\nlution layer only retains the valid convolutions to eliminate\nboundary effects. The use of deconvolution blocks ensures\nthe smaller image obtained after convolution grows back to its\noriginal size. The DC block refers to (6). The main difference\nof this framework with GIRAF is the depth of the denoiser\nnetwork (see Fig. 2.1) and the presence of non-linearities and\nbatch normalization steps within the network. The key differ-\nence of the proposed scheme with MoDL is that the learning\nis performed in k-space, unlike most deep learning image re-\ncovery strategies. The denoiser network uses convolution and\ndeconvolution layers similar to GIRAF, which share weights.\nThis is a another distinction with MoDL, which uses a series\nof convolutional blocks with no weight sharing. Similar to\nMoDL, we also share the same network across iterations.\n4. RESULTS\nMulti-channel brain MRI data was collected from Ô¨Åve sub-\njects at University of Iowa Hospitals using 3D T2 CUBE se-\nquence with Cartesian readouts using a 12-channel head coil.\nThe data from four subjects was used for training, while the\ndata from the Ô¨Åfth subject was used for testing. We retro-\nspectively undersampled the phase encodes to train and test\nthe framework; we note that this approach is completely con-\nsistent with a future prospective acquisition, where a subset\nof phase encodes can be pre-selected and acquired. All the\nexperiments were performed with variable-density Cartesian\nrandom sampling mask with different undersampling factors.\nWe chose 30 most informative slices from each coil, yield-\ning 360 from each subject to form a training dataset of 1440\nslices.\nWe trained a network with an Nw block consisting of Ô¨Åve\nconvolution and Ô¨Åve deconvolution layers as described in sec-\ntion 3.2. Each layer consisted of 64 complex 3 x 3 Ô¨Ålters. The\niterative model was unrolled with Ô¨Åve iterations, which was\ntrained to minimize the mean square error between the out-\nput and the non-undersampled images. The training took 7\n(a) Original\n(b) MoDL\n(c) Proposed\n(d) SENSE\n(e) AHb\n(f) MoDL\n(g) Proposed\n(h) SENSE\n(i) Original\n(j) MoDL\n(k) Proposed\n(l) SENSE\n(m) AHb\n(n) MoDL\n(o) Proposed\n(p) SENSE\nFig. 3. Reconstruction results of four-fold accelerated data.\nFigures(a)-(h) correspond to Coil 1 images while (i)-(p) cor-\nrespond to Coil 6 images.\n(b) MoDL:12.58 db (c) O-\nMoDL:13.84 db, (d) SENSE: 11.52 db, (f)-(h) are the er-\nror images. (j) MoDL,12.21 db (k) O-MoDL,13.54 db, (l)\nSENSE, 11.87 db, (n)-(p) are the error images.\nhours on an NVIDIA Tesla p100 GPU on 1440 slices. By\ncontrast, the run time for reconstucting a single image is only\n50 milliseconds. We compare the performance of O-MoDL\nagainst our image domain deep learning method (MoDL) and\nSENSE reconstructions for two-fold and four-fold accelerated\ndata. For fair comparisons, we train both the networks with\nsame number of iterations and trainable parameters. The SNR\nimprovement in each case can be observed in table 1. Fig. 2\nand 3 show reconstructions of different coil images from two\nand four fold accelerated data respectively. Results show that\nthe proposed scheme can provide improved reconstructions\nover the MoDL scheme [5], which was trained exactly in the\nsame fashion.\n5. CONCLUSION\nWe proposed an off-the-grid deep learning architecture for\nmodel based MR image reconstruction. Unlike many of the\ncurrent CNN architectures, the algorithm works in the Fourier\ndomain. The algorithm is a non-linear extension of recent\nstructured low-rank off-the-grid methods, which rely on an-\n2-fold/4-fold accelerated data\nNoise (œÉ)\nMoDL\nProposed\nSENSE\n10\n16.42/12.46\n18.30/13.71\n11.7/11.44\n11\n16.35/12.22\n18.29/13.68\n11.06/10.54\n12\n15.92/11.91\n18.27/13.68\n10.66/9.89\n13\n15.77/11.51\n18.25/13.66\n10.48/9.76\nTable 1. Quantitative comparison of MoDL, Proposed, and\nSENSE reconstructions. The SNR is reported in dB and the\ntwo Ô¨Ågures correspond to two fold and four fold acceleration.\nnihilation relations in the Fourier domain resulting from con-\ntinuous domain image properties. Unlike the linear annihi-\nlation relations that are self learned in structured low-rank\nsetting, the proposed framework learns non-linear annihila-\ntion relations in the Fourier domain from exemplar data; the\nnon-linearities facilitate the the generalization of the annihi-\nlation properties to images unseen by the training algorithm,\neliminating the need for self-learning the weights. The main\nbeneÔ¨Åt of the proposed scheme is the quite signiÔ¨Åcant reduc-\ntion in run time, compared to structured low-rank algorithms.\nThe preliminary experimental comparisons demonstrate the\nimprovements offered by the proposed scheme over image\ndomain MoDL framework.\n6. REFERENCES\n[1] Greg Ongie and Mathews Jacob, ‚ÄúOff-the-Grid Recov-\nery of Piecewise Constant Images from Few Fourier Sam-\nples,‚Äù SIAM on Imag. Sci., vol. 9, no. 3, pp. 1004‚Äî-1041,\n2016.\n[2] Justin P Haldar, ‚ÄúLow-rank modeling of local k-space\nneighborhoods (loraks) for constrained mri,‚Äù IEEE trans-\nactions on medical imaging, vol. 33, no. 3, pp. 668‚Äì681,\n2014.\n[3] Jong Chul Ye, Yoseob Han, and Eunju Cha, ‚ÄúDeep con-\nvolutional framelets: A general deep learning framework\nfor inverse problems,‚Äù\nSIAM Journal on Imaging Sci-\nences, vol. 11, no. 2, pp. 991‚Äì1048, 2018.\n[4] Kyong Hwan Jin, Michael T. McCann, Emmanuel\nFroustey, and Michael Unser, ‚ÄúDeep Convolutional Neu-\nral Network for Inverse Problems in Imaging,‚Äù vol. 29,\npp. 4509‚Äì4522, 2017.\n[5] Hemant Kumar Aggarwal, Merry P Mani, and Mathews\nJacob, ‚ÄúModl: Model based deep learning architecture\nfor inverse problems,‚Äù arXiv preprint arXiv:1712.02862,\n2017.\n[6] Yoseob Han and Jong Chul Ye, ‚Äúk-space deep learning\nfor accelerated mri,‚Äù arXiv preprint arXiv:1805.03779,\n2018.\n",
  "categories": [
    "cs.LG",
    "cs.CV",
    "stat.ML"
  ],
  "published": "2018-12-27",
  "updated": "2018-12-27"
}