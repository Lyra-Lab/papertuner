{
  "id": "http://arxiv.org/abs/1901.04195v1",
  "title": "Integrating Learning and Reasoning with Deep Logic Models",
  "authors": [
    "Giuseppe Marra",
    "Francesco Giannini",
    "Michelangelo Diligenti",
    "Marco Gori"
  ],
  "abstract": "Deep learning is very effective at jointly learning feature representations\nand classification models, especially when dealing with high dimensional input\npatterns. Probabilistic logic reasoning, on the other hand, is capable to take\nconsistent and robust decisions in complex environments. The integration of\ndeep learning and logic reasoning is still an open-research problem and it is\nconsidered to be the key for the development of real intelligent agents. This\npaper presents Deep Logic Models, which are deep graphical models integrating\ndeep learning and logic reasoning both for learning and inference. Deep Logic\nModels create an end-to-end differentiable architecture, where deep learners\nare embedded into a network implementing a continuous relaxation of the logic\nknowledge. The learning process allows to jointly learn the weights of the deep\nlearners and the meta-parameters controlling the high-level reasoning. The\nexperimental results show that the proposed methodology overtakes the\nlimitations of the other approaches that have been proposed to bridge deep\nlearning and reasoning.",
  "text": "Integrating Learning and Reasoning with\nDeep Logic Models\nGiuseppe Marra1,2, Francesco Giannini2\nMichelangelo Diligenti2 and Marco Gori2\n1Department of Information Engineering\nUniversity of Florence, ITALY\n2Department of Information Engineering and Mathematics\nUniversity of Siena, ITALY\ne-mail: g.marra@uniﬁ.it, {fgiannini,diligmic,marco}@diism.unisi.it\nJanuary 15, 2019\nAbstract\nDeep learning is very eﬀective at jointly learning feature representa-\ntions and classiﬁcation models, especially when dealing with high dimen-\nsional input patterns. Probabilistic logic reasoning, on the other hand,\nis capable to take consistent and robust decisions in complex environ-\nments. The integration of deep learning and logic reasoning is still an\nopen-research problem and it is considered to be the key for the develop-\nment of real intelligent agents. This paper presents Deep Logic Models,\nwhich are deep graphical models integrating deep learning and logic rea-\nsoning both for learning and inference. Deep Logic Models create an end-\nto-end diﬀerentiable architecture, where deep learners are embedded into\na network implementing a continuous relaxation of the logic knowledge.\nThe learning process allows to jointly learn the weights of the deep learn-\ners and the meta-parameters controlling the high-level reasoning.\nThe\nexperimental results show that the proposed methodology overtakes the\nlimitations of the other approaches that have been proposed to bridge\ndeep learning and reasoning.\n1\nIntroduction\nArtiﬁcial Intelligence (AI) approaches can be generally divided into symbolic\nand sub-symbolic approaches.\nSub-symbolic approaches like artiﬁcial neural\nnetworks have attracted most attention of the AI community in the last few\nyears. Indeed, sub-symbolic approaches have got a large competitive advantage\nfrom the availability of a large amount of labeled data in some applications.\nIn these contexts, sub-symbolic approaches and, in particular, deep learning\nones are eﬀective in processing low-level perception inputs [3, 18]. For instance,\n1\narXiv:1901.04195v1  [cs.LG]  14 Jan 2019\ndeep learning architectures have been achieved state-of-the-art results in a wide\nrange of tasks, e.g. speech recognition, computer vision, natural language pro-\ncessing, where deep learning can eﬀectively develop feature representations and\nclassiﬁcation models at the same time.\nOn the other hand, symbolic reasoning [7, 16, 23], which is typically based\non logical and probabilistic inference, allows to perform high-level reasoning\n(possibly under uncertainty) without having to deal with thousands of learn-\ning hyper-parameters. Even if recent work has tried to gain insight on how a\ndeep model works [21], sub-symbolic approaches are still mostly seen as black-\nboxes, whereas symbolic approaches are generally more easier to interpret, as\nthe symbol manipulation or chain of reasoning can be unfolded to provide an\nunderstandable explanation to a human operator.\nIn spite of the incredible success of deep learning, many researchers have\nrecently started to question the ability of deep learning to bring us real AI,\nbecause the amount and quality of training data would explode in order to\njointly learn the high-level reasoning that is needed to perform complex tasks [2].\nFor example, forcing some structure to the output of a deep learner has been\nshown to bring beneﬁts in image segmentation tasks, even when simple output\ncorrelations were added to the enforced contextual information [6].\nBlending symbolic and sub-symbolic approaches is one of the most challeng-\ning open problem in AI and, recently, a lot of works, often referred as neuro-\nsymbolic approaches [10], have been proposed by several authors [6, 14, 22, 27].\nIn this paper, we present Deep Logic Models (DLMs), a uniﬁed framework to\nintegrate logical reasoning and deep learning. DLMs bridge an input layer pro-\ncessing the sensorial input patterns, like images, video, text, from a higher level\nwhich enforces some structure to the model output. Unlike in Semantic-based\nRegularization [8] or Logic Tensor Networks [9], the sensorial and reasoning lay-\ners can be jointly trained, so that the high-level weights imposing the output\nstructure are jointly learned together with the neural network weights, process-\ning the low-level input. The bonding is very general as any (set of) deep learners\ncan be integrated and any output structure can be expressed. This paper will\nmainly focus on expressing the high-level structure using logic formalism like\nﬁrst–order logic (FOL). In particular, a consistent and fully diﬀerentiable relax-\nation of FOL is used to map the knowledge into a set of potentials that can be\nused in training and inference.\nThe outline of the paper is the following.\nSection 2 presents the model\nand the integration of logic and learning.\nSection 3 compares and connects\nthe presented work with previous work in the literature and Section 4 shows\nthe experimental evaluation of the proposed ideas on various datasets. Finally,\nSection 5 draws some conclusions and highlights some planned future work.\n2\nModel\nWe indicate as θ the model parameters, and X the collection of input sensorial\ndata. Deep Logic Models (DLMs) assume that the prediction of the system\n2\nx\nf\ny\nw\nλ\nFigure 1: The DLM graphical model assumes that the output variables y depend\non the output of ﬁrst stage f, processing the input X. This corresponds to the\nbreakdown into a lower sensorial layer and a high level semantic one.\nis constrained by the available prior knowledge.\nTherefore, unlike standard\nNeural networks which compute the output via a simple forward pass, the out-\nput computation in DLM can be decomposed into two stages: a low-level stage\nprocessing the input patterns, and a subsequent semantic stage, expressing con-\nstraints over the output and performing higher level reasoning. We indicate by\ny = {y1, . . . , yn} and by f = {f1, . . . , fn} the two multivariate random vari-\nables corresponding to the output of the model and to the output of the ﬁrst\nstage respectively, where n > 0 denotes the dimension of the model outcomes.\nAssuming that the input data is processed using neural networks, the model\nparameters can be split into two independent components θ = {w, λ}, where\nw is the vector of weights of the networks fnn and λ is the vector of weights of\nthe second stage, controlling the semantic layer and the constraint enforcement.\nFigure 1 shows the graphical dependencies among the stochastic variables that\nare involved in our model. The ﬁrst layer processes the inputs returning the\nvalues f using a model with parameters w. The higher layer takes as input f\nand applies reasoning using a set of constraints, whose parameters are indicated\nas λ, then it returns the set of output variables y.\nThe Bayes rule allows to link the probability of the parameters to the pos-\nterior and prior distributions:\np(θ|y, X) ∝p(y|θ, X)p(θ) .\nAssuming the breakdown into a sensorial and a semantic level, the prior may\nbe decomposed as p(θ) = p(λ)p(w), while the posterior can be computed by\nmarginalizing over the assignments for f:\np(y|θ, X) =\nZ\nf\np(y|f, λ) · p(f|w, X)df .\n(1)\nA typical choice is to link p(f|w, X) to the outputs of the neural architectures:\np(f|w, X) =\n1\nZ(f) exp\n\u0012\n−(f −f nn)2\n2σ2\n\u0013\n,\n3\nwhere the actual (deterministic) output of the networks fnn over the inputs is\nindicated as f nn. Please note that there is a one-to-one correspondence among\neach element of y, f and f nn, such that |y| = |f| = |f nn|.\nHowever, the integral in Equation (1) is too expensive to compute and, as\ncommonly done in the deep learning community, only the actual output of the\nnetwork is considered, namely:\np(f|w, X) ≈δ(f −f nn) ,\nresulting in the following approximation of the posterior:\np(y|θ, X) ≈p(y|f nn, λ) .\nA Deep Logic Model assumes that p(y|f nn, λ) is modeled via an undirected\nprobabilistic graphical model in the exponential family, such that:\np(y|f nn, λ) ≜\n1\nZ(y) exp\n \nΦr(y, f nn) +\nX\nc\nλcΦc(y)\n!\n,\n(2)\nwhere the Φc are potential functions expressing some constraints on the output\nvariables, λ = {λ1, λ2, . . . , λC} are parameters controlling the conﬁdence for the\nsingle constraints where a higher value corresponds to a stronger enforcement\nof the corresponding constraint, Φr is a potential favoring solutions where the\noutput closely follows the predictions provided by the neural networks (for in-\nstance Φr(y, f nn) = −1\n2||y −f nn||2) and Z(y) is a normalization factor (i.e.\nthe partition function):\nZ(y) =\nZ\ny\nexp\n \nΦr(y, f nn) +\nX\nc\nλcΦc(y)\n!\ndy.\n2.1\nMAP Inference\nMAP inference assumes that the model parameters are known and it aims at\nﬁnding the assignment maximizing p(y|f nn, λ). MAP inference does not require\nto compute the partition function Z which acts as a constant when the weights\nare ﬁxed. Therefore:\nyM = argmax\ny\nlog p(y|f nn, λ) = argmax\ny\n\"\nΦr(y, f nn) +\nX\nc\nλcΦc(y)\n#\n.\nThe above maximization problem can be optimized via gradient descent by\ncomputing:\n∇y log p(y|f nn, λ) = ∇yΦr(y, f nn) +\nX\nc\nλc∇yΦc(y)\n4\n2.2\nLearning\nTraining can be carried out by maximizing the likelihood of the training data:\nargmax\nθ\nlog p(θ|yt, X) = log p(yt|θ, X) + log p(w) + log p(λ) .\nIn particular, assuming that p(yt|θ, X) follows the model deﬁned in equation\n(2) and the parameter priors follow Gaussian distributions, we get:\nlog p(θ|yt, X)=−α\n2 ||w||2 −β\n2 ||λ||2 −Φr(yt, f nn) +\nX\nc\nλcΦc(yt) −log Z(y)\nwhere α, β are meta-parameters determined by the variance of the selected Gaus-\nsian distributions. Also in this case the likelihood may be maximized by gradient\ndescent using the following derivatives with respect to the model parameters:\n∂log p(θ|yt,X)\n∂λc\n=\n−βλc + Φc(yt) −Ep [Φc]\n∂log p(θ|yt,X)\n∂wi\n=\n−αwi + ∂Φr(yt,f nn)\n∂wi\n−Ep\nh\n∂Φr\n∂wi\ni\nUnfortunately, the direct computation of the expected values in the above\nderivatives is not feasible. A possible approximation [12, 13] relies on replacing\nthe expected values with the corresponding value at the MAP solution, assum-\ning that most of the probability mass of the distribution is centered around it.\nThis can be done directly on the above expressions for the derivatives or in the\nlog likelihood:\nlog p(yt|f nn, X) ≈Φr(yt, f nn) −Φr(yM, f nn) +\nX\nc\nλc (Φc(yt) −Φc(yM))\nFrom the above approximation, it emerges that the likelihood tends to be\nmaximized when the MAP solution is close to the training data, namely if\nΦr(yt, f nn) ≃Φr(yM, f nn) and Φc(yt) ≃Φc(yM) ∀c. Furthermore, the proba-\nbility distribution is more centered around the MAP solution when Φr(yM, f nn)\nis close to its maximum value. We assume that Φr is negative and have zero as\nupper bound: Φr(y, f nn) ≤0 ∀y, f nn, like it holds for example for the already\nmentioned negative quadratic potential Φr(y, f nn) = −1\n2||y−f nn||2. Therefore,\nthe constraint Φr(yt, f nn) ≃Φr(yM, f nn) is transformed into the two separate\nconstraints Φr(yt, f nn) ≃0 and Φr(yM, f nn) ≃0.\nThis means that, given the current MAP solution, it is possible to increase\nthe log likelihood by computing the gradient and weight updates using the\nfollowing cost function:\nlog p(w) + log p(λ) + Φr(yt, f nn) + Φr(yM, f nn) +\nX\nc\nλc [Φc(yt) −Φc(yM)]\nIn this paper, a quadratic form for the priors and the potentials is selected, but\nother choices are possible. For example, Φr(·) could instead be implemented as\n5\nData: Input data X, output targets yt, function models with weights w\nResult: Trained model parameters θ = {λ, w}\nInitialize i = 0, λ = 0, random w;\nwhile not converged ∧i < max_iterations do\nCompute function outputs f nn on X using current function weights\nw;\nCompute MAP solution yM = argmaxy log p(y|f nn, λ);\nCompute gradient ∇θCθ(yt, yM, X);\nUpdate θ via gradient descent: θi+1 = θi −λlr · ∇θCθ(yt, yM, X);\nSet i=i+1;\nend\nAlgorithm 1: Iterative algorithm to train the function weights w and the\nconstraint weights λ.\na negative cross entropy loss. Therefore, replacing the selected forms for the po-\ntentials and changing the sign to transform a maximization into a minimization\nproblem, yields the following cost function, given the current MAP solution:\nCθ(yt, yM, X)\n=\nα\n2 ||w||2 + β\n2 ||λ||2 + 1\n2||yt −f nn||2 + 1\n2||yM −f nn||2 +\n+\nX\nc\nλc [Φc(yt) −Φc(yM)] .\n(3)\nMinimizing the cost function Cθ(yt, yM, X) is just a local approximation of\nthe full likelihood maximization for the current MAP solution. Therefore, the\ntraining process alternates the computation of the MAP solution, the computa-\ntion of the gradient for Cθ(yt, yM, X) and one weight update step. Algorithm 1\nsummarizes this iterative training algorithm.\nPlease note that, for any con-\nstraint c, the parameter λc admits also a negative value. This is in case the c-th\nconstraint turns out to be too satisﬁed by the actual MAP solution with respect\nto the satisfaction degree on the training data.\n2.3\nMapping Constraints into a Continuous Logic\nThe DLM model is absolutely general in terms of the constraints that can be\nexpressed on the outputs. However, this paper mainly focuses on constraints\nexpressed in the output space y by means of ﬁrst–order logic formulas. There-\nfore, this section focuses on deﬁning a methodology to integrate prior knowledge\nexpressed via FOL into a continuous optimization process.\nIn this framework we only deal with closed FOL formulas, namely formu-\nlas where any variable occurring in predicates is quantiﬁed. In the following,\ngiven an m-ary predicate p and a tuple (a1, . . . , am) ∈Dom(p), we say that\np(a1, . . . , am) ∈[0, 1] is a grounding of p. Given a grounding of the variables\noccurring in a FOL formula (namely a grounding for all the predicates involved\nin the formula), the truth degree of the formula for that grounding is computed\nusing the t-norm fuzzy logic theory as proposed in [24]. The overall degree of\n6\noperation\nt-norm\nProduct\nMinimum\nŁukasiewicz\na ∧b\na · b\nmin(a, b)\nmax(0, a + b −1)\na ∨b\na + b −a · b\nmax(a, b)\nmin(1, a + b)\n¬a\n1 −a\n1 −a\n1 −a\na ⇒b\nmin(1, b\na)\na ≤b?1 : b\nmin(1, 1 −a + b)\nTable 1: The Operations performed by the single units of an expression tree\ndepending on the inputs a, b and the used t-norm.\nsatisfaction of a FOL formula is obtained by grounding all the variables in such\nformula and aggregating the values with diﬀerent operators depending on the\noccurring quantiﬁers. The details of this process are explained in the following\nof the section.\nGrounded Expressions.\nAny fully grounded FOL rule corresponds to an\nexpression in propositional logic and we start showing how a propositional logic\nexpression may be converted into a diﬀerentiable form. In particular, one expres-\nsion tree is built for each considered grounded FOL rule, where any occurrence\nof the basic logic connectives (¬, ∧, ∨, ⇒) is replaced by a unit computing its cor-\nresponding fuzzy logic operation according to a certain logic semantics. In this\nregard, some recent work shows how to get convex (or even linear) functional\nconstraints exploiting the convex Łukasiewicz fragment [11].\nThe expression\ntree can take as input the output values of the grounded predicates and then re-\ncursively compute the output values of all the nodes in the expression tree. The\nvalue obtained on the root node is the result of the evaluation of the expression\ngiven the input grounded predicates.\nTable 1 shows the algebraic operations corresponding to the logic operators\nfor diﬀerent selections of the t-norms.\nPlease note that the logic operators\nare always monotonic with respect of any single variable, but they are not\nalways diﬀerentiable (nor even continuous). However, the sub-space where the\noperators are non-diﬀerentiable has null-Lebesgue measure, therefore they do\nnot pose any practical issue, when used as part of a gradient descent optimization\nschema as detailed in the following.\nWe assume that the input data X can be divided into a set of sub-domains\nX = {X1, X2, . . .}, such that each variable vi of a FOL formula ranges over the\ndata of one input domain, namely vi ∈Xdi, where di is the index of the domain\nfor the variable vi.\nFor example, let us consider the rule ∀v1∀v2 ¬A(v1, v2) ∧B(v1). For any as-\nsignment to v1 and v2, the expression tree returns the output value [1−A(v1, v2)]·\nB(v1), assuming to exploit the product t-norm to convert the connectives.\nQuantiﬁers.\nThe truth degree of a formula containing an expression with a\nuniversally quantiﬁed variable vi is computed as the average of the t-norm truth\ndegree of the expression, when grounding vi over its domain. The truth degree\n7\nof the existential quantiﬁer is the maximum of the t-norm expression grounded\nover the domain of the quantiﬁed variable. When multiple quantiﬁed variables\nare present, the conversion is performed from the outer to the inner variable.\nWhen only universal quantiﬁers are present the aggregation is equivalent to the\noverall average over each grounding.\nIn the previous example, this yields the following expression:\nΦ(X, A, B) =\n1\n|Xd1| · |Xd2|\nX\nv1∈Xd1\nX\nv2∈Xd2\n[1 −A(v1, v2)] · B(v1) .\n(4)\n2.4\nPotentials expressing the logic knowledge\nIt is now possible to explain how to build the potentials from the prior knowl-\nedge. In any learning task, each unknown grounded predicate corresponds to\none variable in the vector y. In the above example, the number of groundings is\n|Xd1|×|Xd2| (i.e. the size of the cartesian product of the domains of A) and |Xd1|\n(i.e. the size of the domain of B). Therefore, assuming that both predicates A, B\nare unknown, |y| = |f| = |Xd1|×|Xd2|+|Xd1|. The vector f nn is built similarly\nby replacing a generic predicate with its neural implementation and then emplac-\ning the function values for the groundings in the vector. Again for the considered\nexample: f nn = {fA(v11, v21), . . . , fA(v1|Xd1|, v2|Xd2|), fB(v11), . . . , fB(v1|d2|)},\nwhere vij is the j-th grounding for the i-th variable and fA, fB are the learned\nneural approximations of A and B, respectively. Finally, the diﬀerentiable po-\ntential for the example formula is obtained by replacing in Equation (4) each\ngrounded predicate with the corresponding stochastic variable in y.\nFigure 2 shows the undirected graphical model corresponding to the DLM\nfor the running example rule used in this section, assuming that v1 can assume\nvalues over the constants {Mary, John} and v2 over {Munich, London}. Each\nstochastic node yi approximates one grounded predicate, while the fi nodes are\nthe actual output of a neural network getting as input the pattern represen-\ntations of the corresponding grounding. The vertical connections between two\nyi and fi nodes correspond to the cliques over the groundings for which the\nΦr potential can be decomposed. The links between the yi nodes corresponds\nto the cliques over the groundings of the rule for which the corresponding Φc\npotential can be decomposed. The structure of these latter cliques follows a\ntemplate determined by the rule, that is repeated for the single groundings.\nThe graphical model is similar to the ones built by Probabilistic Soft Logic [1]\nor Markov Logic Networks [26], but enriched with the nodes corresponding to\nthe output of the neural networks.\n3\nRelated Works\nDLMs have also their roots in Probabilistic Soft Logic (PSL) [1], a probabilistic\nlogic using an undirected graphical model to represent a grounded FOL knowl-\nedge base, and employing a similar diﬀerentiable and convex approximation of\n8\ny1 ≈A(Mary, Munich)\nf1 = fA(xMary, xMunich)\nw\ny2 ≈A(Mary, London)\nf2 = fA(xMary, xLondon)\nw\ny3 ≈A(John, Munich)\nf3 = fA(xJohn, xMunich)\nw\ny4 ≈A(John, London)\nf4 = fA(xJohn, xLondon)\nw\ny5 ≈B(Mary)\nf5 = fB(xMary)\nw\ny6 ≈B(John)\nf6 = fB(xJohn)\nw\nFigure 2:\nThe undirected graphical model built by a DLM for the rule\n∀v1∀v2 ¬A(v1, v2) ∧B(v1) where v1 can assume values over the constants\n{Mary, John} and v2 over {Munich, London}. Each stochastic node yi ap-\nproximates one grounded predicate, while the fi nodes are the actual output of\na network getting the pattern representations of a grounding.\nFOL. PSL, similar to a DLM, allows to learn the weight of each formula in the\nKB by maximizing the log likelihood of the training data. However in PSL, rule\nweights are restricted to only positive values denoting how far the rule is from\nbeing satisﬁed. On the other hand, in DLMs the rule weights denote the needed\nconstraint reactions to match the degree satisfaction of the training data. In\naddition, unlike DLMs, PSL focuses on logic reasoning without any integration\nwith deep learners, beside a simple stacking with no joint training.\nThe integration of learning from data and symbolic reasoning [10] has re-\ncently attracted a lot of attention. Hu at al. [15], Semantic-based regularization\n(SBR) [8] for kernel machines and Logic Tensor Networks (LTN) [9] for neural\nnetworks share the same basic idea of integrating logic reasoning and learning\nusing a similar continuous relaxation of logic to the one presented in this paper.\nHowever, this class of approaches considers the reasoning layer as frozen, with-\nout allowing to jointly train its parameters. This is a big limitation, as these\n9\nmethods work better only with hard constraints, while they are less suitable in\npresence of reasoning under uncertainty.\nThe integration of deep learning with Conditional Random Fields (CRFs) [20]\nis also an alternative approach to enforce some structure on the network output.\nThis approach has been proved to be quite successful on sequence labeling for\nnatural language processing tasks. This methodology can be seen as a special\ncase of the more general methodology presented in this paper, when the poten-\ntial functions are used to represent the correlations among consecutive outputs\nof a recurrent deep network.\nDeepProbLog [22] extends the popular ProbLog [7] probabilistic program-\nming framework with the integration of deep learners. DeepProbLog requires\nthe output from the neural networks to be probabilities and an independence\nassumption among atoms in the logic is required to make inference tractable.\nThis is a strong restriction, since the sub-symbolic layer often consists of several\nneural layers sharing weights.\nA Neural Theorem Prover (NTP) [27, 28] is an end-to-end diﬀerentiable\nprover based on the Prolog’s backward chaining algorithm. An NTP constructs\nan end-to-end diﬀerentiable architecture capable of proving queries to a KB\nusing sub-symbolic vector representations. NTPs have been proven to be ef-\nfective in tasks like entity linking and knowledge base completion. However,\nan NTP encodes relations as vectors using a frozen pre-selected function (like\ncosine similarity). This can be ineﬀective in modeling relations with a complex\nand multifaceted nature (for example a relation friend(A,B) can be triggered\nby diﬀerent relationships of the representations in the embedding space). On\nthe other hand, DLMs allow a relation to be encoded by any selected function\n(e.g. any deep neural networks), which is co-trained during learning. Therefore,\nDLMs are capable of a more powerful and ﬂexible exploitation of the represen-\ntation space. On the other end, DLMs require to fully ground a KB (like SBR,\nLTN, PSL and most of other methods discussed here), while NTPs expands\nonly the groundings on the explored frontier, which can be more eﬃcient in\nsome cases.\nDeep Structured Models [6, 19] use a similar graphical model to bridge the\nsensorial and semantic levels. However, they have mainly focused on imposing\ncorrelations on the output layer, without any focus on logic reasoning. Fur-\nthermore, DLMs transform the training process into an iterative constrained\noptimization problem, which is very diﬀerent from the approximation of the\npartition function used in Deep Structured Models.\nDLMs also open up the possibility to iteratively integrate rule induction\nmechanisms like the ones proposed by the Inductive Logic Programming com-\nmunity [17, 25].\n10\nFigure 3: A sample of the data used in the PAIRS experiment, where each\ncolumn is a pair of digits.\n4\nExperimental Results\n4.1\nThe PAIRS artiﬁcial dataset\nConsider the following artiﬁcial task. We are provided with 1000 pairs of hand-\nwritten digits images sampled from the MNIST dataset.\nThe pairs are not\nconstructed randomly but they are compilied according to the following struc-\nture:\n1. pairs with mixed even-odd digits are not allowed;\n2. the ﬁrst image of a pair represents a digit randomly selected from a uniform\ndistribution;\n3. if the ﬁrst image is an even (resp.\nodd) digit, the second image of a\npair represents one of the ﬁve even (resp. odd) digits with probabilities\np1 ≥p2 ≥p3 ≥p4 ≥p5, with p1 the probability of being an image of\nthe same digit, p2 the probability of being an image of the next even/odd\ndigit, and so on.\nFor example, if the ﬁrst image of a pair is selected to be a two, the second image\nwill be a two with probability p1, it will be a four with probability p2, a six\nwith probability p3 and so on, in a circular fashion. An example is shown in\nFigure 3. A correct classiﬁcation happens when both digit in a pair are correctly\npredicted.\nTo model a task using DLMs there are some common design choices regard-\ning these two features that one needs to take.\nWe use the current example\nto show them. The ﬁrst choice is to individuate the constants of the problem\nand their sensorial representation in the perceptual space. Depending on the\nproblem, the constants can live in a single or multiple separate domains. In the\npairs example, the images are constants and each one is represented as a vector\nof pixel brightnesses like commonly done in deep learning.\nThe second choice is the selection of the predicates that should predict some\ncharacteristic over the constants and their implementation. In the pairs experi-\nment, the predicates are the membership functions for single digits (e.g. one(x),\ntwo(x), etc.). A single neural network with 1 hidden layer, 10 hidden neurons\nand 10 outputs, each one mapped to a predicate, was used in this toy experi-\nment. The choice of a small neural network is due to the fact that the goal is\nnot to get the best possible results, but to show how the prior knowledge can\nhelp a classiﬁer to improve its decision. In more complex experiments, diﬀerent\n11\nModel\nNN\nSBR\nDLM-NN\nDLM\nAccuracy\n0.62\n0.64\n0.65\n0.76\nTable 2: Comparison of the accuracy metric on the PAIRS dataset using diﬀer-\nent models.\nnetworks can be used for diﬀerent sets of predicates, or each use a separate\nnetwork for each predicate.\nFinally, the prior knowledge is selected.\nIn the pairs dataset, where the\nconstants are grouped in pairs, it is natural to express the correlations among\ntwo images in a pair via the prior knowledge. Therefore, the knowledge consists\nof 100 rules in the form ∀(x, y) D1(x) →D2(y), where (x, y) is a generic pair of\nimages and (D1, D2) range over all the possible pairs of digit classes.\nWe performed the experiments with p1 = 0.9, p2 = 0.07, p3 = p4 = p5 = 0.01.\nAll the images are rotated with a random degree between 0 and 90 anti-clockwise\nto increase the complexity of the task. There is a strong regularity in having\ntwo images representing the same digit in a pair, even some rare deviations from\nthis rule are possible. Moreover, there are some inadmissible pairs, i.e. those\ncontaining mixed even-odd digits. The train and test sets are built by sampling\n90% and 10% image pairs.\nThe results provided using a DLM have been compared against the following\nbaselines:\n• the neural network (NN) with no knowledge of the structure of the prob-\nlem;\n• the Semantic Based Regularization [8] (SBR) framework, which also em-\nploys logical rules to improve the learner. However, the rule weights are\ntreated as ﬁxed parameters, which are not jointly trained during learning.\nSince searching in the space of these parameters via cross-validation is not\nfeasible, a strong prior was provided to make SBR prefers pairs with the\nsame image using 10 rules of the form ∀(x, y) D(x) →D(y), for each digit\nclass D. These rules hold true in most cases and improve the baseline\nperformance of the network.\nTable 4.1 shows how the neural network output of a DLM (DLM-NN) already\nbeats both the same neural model trained without prior knowledge and SBR.\nThis happens because the neural network in DLM is indirectly adjusted to\nrespect the prior knowledge in the overall optimization problem. When reading\nthe DLM output from the MAP solution (DLM), the results are signiﬁcantly\nimproved.\n4.2\nLink Prediction in Knowledge Graphs\nNeural-symbolic approaches have been proved to be very powerful to perform\napproximated logical reasoning [29]. A common approach is to assign to each\nlogical constant and relation a learned vectorial representation [4]. Approximate\n12\nreasoning is then carried out in this embedded space. Link Prediction in Knowl-\nedge Graphs is a generic reasoning task where it is requested to establish the\nlinks of the graph between semantic entities acting as constants. Rocktaschel et\nal. [28] shows state-of-the-art performances on some link prediction benchmarks\nby combining Prolog backward chain with a soft uniﬁcation scheme.\nThis section shows how to model a link prediction task on the Countries\ndataset using a Deep Logic Models, and compare this proposed solution to the\nother state-of-the-art approaches.\nDataset.\nThe Countries dataset [5] consists of 244 countries (e.g. germany),\n5 regions (e.g. europe), 23 sub-regions (e.g. western europe, northern america,\netc.), which act as the constants of the KB. Two types of binary relations among\nthe constant are present in the dataset: locatedIn(c1, c2), expressing that c1\nis part of c2 and neighborOf(c1, c2), expressing that c1 neighbors with c2. The\nknowledge base consists of 1158 facts about the countries, regions and sub-\nregions, expressed in the form of Prolog facts (e.g. locatedIn(italy,europe)).\nThe training, validation and test sets are composed by 204, 20 and 20 countries,\nrespectively, such that each country in the validation and test sets has at least\none neighbor in the training set. Three diﬀerent tasks have been proposed for\nthis dataset with an increasing level of diﬃculty. For all tasks, the goal is to\npredict the relation locatedIn(c, r) for every test country c and all ﬁve regions r,\nbut the access to training atoms in the KB varies, as explained in the following:\n• Task S1: all ground atoms locatedIn(c, r) where c is a test country and\nr is a region are removed from the KB. Since information about the sub-\nregion of test countries is still contained in the KB, this task can be solved\nexactly by learning the transitivity of the locatedIn relation.\n• Task S2: like S1 but all grounded atoms locatedIn(c, s), where c is a test\ncountry and s is a sub-region, are removed. The location of test countries\nneeds to be inferred from the location of its neighbors. This task is more\ndiﬃcult than S1, as neighboring countries might not be in the same region.\n• Task S3: like S2, but all ground atoms locatedIn(c, r), where r is a\nregion and c is a training country with either a test or validation country\nas a neighbor, are removed. This task requires multiple reasoning steps\nto determine an unknown link, and it strongly exploits the sub-symbolic\nreasoning capability of the model to be eﬀectively solved.\nModel.\nEach country, region and sub-region corresponds to a constant. Since\nthe constants are just symbols, each one is assigned to an embedding, which\nis learned together with the other parameters of the model.\nThe predicates\nare the binary relations locatedIn and neighborOf, which connect constants\nin the KB. Each relation is learned via a separate neural network with a 50\nneuron hidden layer taking as input the concatenation of the embeddings of\nthe constants. In particular, similarly to [4], the constants are encoded into a\n13\nTask\nComplEx\nNTP\nNTPλ\nDLM\nS1\n99.37\n90.83\n100.00\n100.00\nS2\n87.95\n87.40\n93.04\n97.79\nS3\n48.44\n56.68\n77.26\n91.93\nTable 3: Comparison of the accuracy provided by diﬀerent methods on link\nprediction on the Countries dataset. Bold numbers are the best performers for\neach task.\none-hot vector, which is processed by the ﬁrst layer of the network, outputting\nan embedding composed by 50 real number values. As commonly done in link\nprediction tasks, the learning process is performed in a transductive mode. In\nparticular, the input X consists of all possible constants for the task, while\nthe train examples yt will cover only a subset of all the possible grounded\npredicates, leaving to the joint train and inference process the generalization of\nthe prediction to the other unknown grounded relations. Indeed, the output of\nthe train process in this case is both the set of model parameters and the MAP\nsolution predicting the unknown grounded relations that hold true.\nMulti-step dependencies among the constants are very important to predict\nthe existence of a link in this task. For example in task S1, the prediction of a\nlink among a country and a region can be established via the path passing by a\nsub-region, once the model learns a rule stating the transitivity of the locatedIn\nrelation (i.e. locatedIn(x, y) ∧locatedIn(y, z) →locatedIn(x, z)). Exploit-\ning instead the rule neighborOf(x, y)∧locatedIn(y, z) →locatedIn(x, z), the\nmodel should be capable of approximately solving task S2.\nAll 8 rules ∀x ∀y ∀z A(x, y) ∧B(y,z) →C(y, z), where A, B and C are either\nneighborOf or locatedIn are added to the knowledge base for this experiment.\nThese rules represent all the 2-steps paths reasoning that can be encoded, and\nthe strength of each rule needs to be estimated as part of the learning process for\neach task. The training process will iteratively minimize Equation 3 by jointly\ndetermining the embeddings and the network weights such that network outputs\nand the MAP solution will correctly predict the training data, while respecting\nthe constraints on the MAP solution at the same level as on the train data.\nResults.\nTable 4.2 compares DLM against the state-of-the-art methods used\nby Rocktaschel et al. [28], namely ComplEx, NTP and NTPλ.\nTask S1 is\nthe only one that can be solved exactly when the transitive property of the\nlocatedIn relation has been learned to always hold true. Indeed, most methods\nare able to perfectly solve this task, except for the plain NTP model. DLM is\ncapable perfectly solving this task by joining the logical reasoning capabilities\nwith the discriminative power of neural networks. DLMs perform better than\nthe competitors on tasks S2 and S3, thanks to additional ﬂexibility obtained by\njointly training the relation functions using neural networks, unlike the simple\nvectorial operations like the cosine similarity employed by the competitors.\n14\n5\nConclusions and future work\nThis paper presents Deep Logic Models that integrate (deep) learning and logic\nreasoning into a single fully diﬀerentiable architecture. The logic can be ex-\npressed with unrestricted FOL formalism, where each FOL rule is converted\ninto a diﬀerentiable potential function, which can be integrated into the learn-\ning process. The main advantage of the presented framework is the ability to\nfully integrate learning from low-level representations and semantic high-level\nreasoning over the network outputs. Allowing to jointly learn the weights of\nthe deep learners and the parameters controlling the reasoning enables a pos-\nitive feedback loop, which is shown to improve the accuracy of both layers.\nFuture work will try to bridge the gap between fully grounded methodologies\nlike current Deep Logic Models and Theorem Provers which expand only the\ngroundings needed to expand the frontier of the search space.\nReferences\n[1] Bach, S.H., Broecheler, M., Huang, B., Getoor, L.: Hinge-loss markov\nrandom ﬁelds and probabilistic soft logic. arXiv preprint arXiv:1505.04406\n(2015)\n[2] Battaglia, P.W., Hamrick, J.B., Bapst, V., Sanchez-Gonzalez, A., Zam-\nbaldi, V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner,\nR., et al.: Relational inductive biases, deep learning, and graph networks.\narXiv preprint arXiv:1806.01261 (2018)\n[3] Bengio, Y., et al.: Learning deep architectures for ai. Foundations and\ntrends R⃝in Machine Learning 2(1), 1–127 (2009)\n[4] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., Yakhnenko, O.:\nTranslating embeddings for modeling multi-relational data. In: Advances\nin neural information processing systems. pp. 2787–2795 (2013)\n[5] Bouchard, G., Singh, S., Trouillon, T.: On approximate reasoning capa-\nbilities of low-rank vector spaces. AAAI Spring Syposium on Knowledge\nRepresentation and Reasoning (KRR): Integrating Symbolic and Neural\nApproaches (2015)\n[6] Chen, L.C., Schwing, A., Yuille, A., Urtasun, R.: Learning deep structured\nmodels. In: International Conference on Machine Learning. pp. 1785–1794\n(2015)\n[7] De Raedt, L., Kimmig, A., Toivonen, H.: Problog: A probabilistic pro-\nlog and its application in link discovery. In:\nProceedings of the 20th\nInternational Joint Conference on Artiﬁcal Intelligence. pp. 2468–2473.\nIJCAI’07, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA\n(2007), http://dl.acm.org/citation.cfm?id=1625275.1625673\n15\n[8] Diligenti, M., Gori, M., Sacca, C.: Semantic-based regularization for learn-\ning and inference. Artiﬁcial Intelligence 244, 143–165 (2017)\n[9] Donadello, I., Seraﬁni, L., Garcez, A.d.: Logic tensor networks for semantic\nimage interpretation. arXiv preprint arXiv:1705.08968 (2017)\n[10] Garcez, A.S.d., Broda, K.B., Gabbay, D.M.: Neural-symbolic learning sys-\ntems: foundations and applications. Springer Science & Business Media\n(2012)\n[11] Giannini, F., Diligenti, M., Gori, M., Maggini, M.: On a convex logic\nfragment for learning and reasoning. IEEE Transactions on Fuzzy Systems\n(2018)\n[12] Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y.: Deep learning, vol. 1.\nMIT press Cambridge (2016)\n[13] Haykin, S.: Neural Networks: A Comprehensive Foundation. Prentice Hall\nPTR, Upper Saddle River, NJ, USA, 1st edn. (1994)\n[14] Hazan, T., Schwing, A.G., Urtasun, R.: Blending learning and inference\nin conditional random ﬁelds. The Journal of Machine Learning Research\n17(1), 8305–8329 (2016)\n[15] Hu, Z., Ma, X., Liu, Z., Hovy, E., Xing, E.: Harnessing deep neural net-\nworks with logic rules. arXiv preprint arXiv:1603.06318 (2016)\n[16] Kimmig, A., Bach, S., Broecheler, M., Huang, B., Getoor, L.: A short\nintroduction to probabilistic soft logic. In: Proceedings of the NIPS Work-\nshop on Probabilistic Programming: Foundations and Applications. pp.\n1–4 (2012)\n[17] Lavrac, N., Dzeroski, S.: Inductive logic programming. In: WLP. pp. 146–\n160. Springer (1994)\n[18] LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P.: Gradient-based learning\napplied to document recognition. Proceedings of the IEEE 86(11), 2278–\n2324 (1998)\n[19] Lin, G., Shen, C., Van Den Hengel, A., Reid, I.: Eﬃcient piecewise training\nof deep structured models for semantic segmentation. In: Proceedings of\nthe IEEE Conference on Computer Vision and Pattern Recognition. pp.\n3194–3203 (2016)\n[20] Ma, X., Hovy, E.: End-to-end sequence labeling via bi-directional lstm-\ncnns-crf. In: Proceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers). pp. 1064–1074.\nAssociation for Computational Linguistics (2016), http://aclweb.org/\nanthology/P16-1101\n16\n[21] Mahendran, A., Vedaldi, A.: Understanding deep image representations by\ninverting them. In: Proceedings of the IEEE conference on computer vision\nand pattern recognition. pp. 5188–5196 (2015)\n[22] Manhaeve, R., Dumančić, S., Kimmig, A., Demeester, T., De Raedt,\nL.: Deepproblog: Neural probabilistic logic programming. arXiv preprint\narXiv:1805.10872 (2018)\n[23] Muggleton, S., De Raedt, L.: Inductive logic programming: Theory and\nmethods. The Journal of Logic Programming 19, 629–679 (1994)\n[24] Novák, V., Perﬁlieva, I., Mockor, J.: Mathematical principles of fuzzy logic,\nvol. 517. Springer Science & Business Media (2012)\n[25] Quinlan, J.R.: Learning logical deﬁnitions from relations. Machine learning\n5(3), 239–266 (1990)\n[26] Richardson, M., Domingos, P.: Markov logic networks. Machine learning\n62(1-2), 107–136 (2006)\n[27] Rocktäschel, T., Riedel, S.: Learning knowledge base inference with neu-\nral theorem provers. In: Proceedings of the 5th Workshop on Automated\nKnowledge Base Construction. pp. 45–50 (2016)\n[28] Rocktäschel, T., Riedel, S.: End-to-end diﬀerentiable proving. In: Ad-\nvances in Neural Information Processing Systems. pp. 3788–3800 (2017)\n[29] Trouillon, T., Welbl, J., Riedel, S., Gaussier, É., Bouchard, G.: Complex\nembeddings for simple link prediction. In: International Conference on Ma-\nchine Learning. pp. 2071–2080 (2016)\n17\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2019-01-14",
  "updated": "2019-01-14"
}