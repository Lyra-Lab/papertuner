{
  "id": "http://arxiv.org/abs/1901.04355v1",
  "title": "Iterative Deep Learning Based Unbiased Stereology With Human-in-the-Loop",
  "authors": [
    "Saeed S. Alahmari",
    "Dmitry Goldgof",
    "Lawrence O. Hall",
    "Palak Dave",
    "Hady Ahmady Phoulady",
    "Peter R. Mouton"
  ],
  "abstract": "Lack of enough labeled data is a major problem in building machine learning\nbased models when the manual annotation (labeling) is error-prone, expensive,\ntedious, and time-consuming. In this paper, we introduce an iterative deep\nlearning based method to improve segmentation and counting of cells based on\nunbiased stereology applied to regions of interest of extended depth of field\n(EDF) images. This method uses an existing machine learning algorithm called\nthe adaptive segmentation algorithm (ASA) to generate masks (verified by a\nuser) for EDF images to train deep learning models. Then an iterative deep\nlearning approach is used to feed newly predicted and accepted deep learning\nmasks/images (verified by a user) to the training set of the deep learning\nmodel. The error rate in unbiased stereology count of cells on an unseen test\nset reduced from about 3 % to less than 1 % after 5 iterations of the iterative\ndeep learning based unbiased stereology process.",
  "text": "Iterative Deep Learning Based Unbiased Stereology\nWith Human-in-the-Loop\nSaeed S. Alahmari1, Dmitry Goldgof1, Lawrence O. Hall1, Palak Dave1, Hady Ahmady Phoulady2,\nand Peter R. Mouton3\n1Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA\n2Department of Computer Science, University of Southern Maine, Portland, ME, USA\n3SRC Bioscience, Tampa, FL USA\n{saeed3,goldgof,lohall,palakdave}@mail.usf.edu, {hady.ahmadyphoulady}@maine.edu,\nand {peter}@disector.com\nAbstract—Lack of enough labeled data is a major problem\nin building machine learning based models when the manual\nannotation (labeling) is error-prone, expensive, tedious, and\ntime-consuming. In this paper, we introduce an iterative deep\nlearning based method to improve segmentation and counting\nof cells based on unbiased stereology applied to regions of\ninterest of extended depth of ﬁeld (EDF) images. This method\nuses an existing machine learning algorithm called the adaptive\nsegmentation algorithm (ASA) to generate masks (veriﬁed by a\nuser) for EDF images to train deep learning models. Then an\niterative deep learning approach is used to feed newly predicted\nand accepted deep learning masks/images (veriﬁed by a user) to\nthe training set of the deep learning model. The error rate in\nunbiased stereology count of cells on an unseen test set reduced\nfrom about 3 % to less than 1 % after 5 iterations of the iterative\ndeep learning based unbiased stereology process.\nIndex Terms—Unbiased Stereology, Active learning, Deep\nlearning, EDF, ASA\nI. INTRODUCTION\nUnbiased stereology is a set of theoretical and practical\nmethods for making accurate counts of stained cells by\ncarefully avoiding all known sources of methodological bias\n[1] [2]. Examples of common stereology parameters include\ncounts of total cell number and cell density; region and\nmean cell volumes; surface area and surface density; and\ntotal length and length density [3] [1]. However, current\ncomputer-assisted stereology systems available to bioscientists\nand medical scientists are based on a technology developed\nmore than two decades ago. Therefore, a simple study\nrequires tedious counting of hundreds of cells per sample\nby a well-trained technician [4]. For example, a simple\ncount of immunostained cells in a deﬁned region of interest\n(ROI) requires about 2-3 hours for a well-trained technician\nto achieve a reliable result. Though based on theoretically\nunbiased principles, this approach is prone to data errors and\nlow reproducibility due to user subjectivity, variable expertise,\nand fatigue. The Adaptive Segmentation Algorithm (ASA)\n[2] makes stereology counts of total numbers of brain cells\n(Neu-N immunostained neurons) by automatic segmentation\nand cell counting on Extended Depth of Field (EDF) images\n[5] [6]. However, ASA requires manual adjustment of several\nparameters (i.g., minimum cell size, cell maximum size, and\nGaussian Mixture Model (GMM) threshold) to achieve a\ngood result. In Section IV, we present ASA details.\nA critical aspect of building successful machine learning\nmodels is the availability of labeled data. However, labeled\ndata is hard to obtain because the process is time-consuming,\nlabor-intensive, and tedious. Additionally, data labeling in a\nmedical ﬁeld is mostly restricted to experts in the ﬁeld and\ngenerally cannot be prepared by a crowdsourcing approach for\nreasons such as the quality of annotation and subject privacy.\nTo overcome labeling difﬁculties for stereology images (i.e.,\ncreating pixel-wise labels), we propose an iterative deep\nlearning method to generate segmentation masks of cells\non stained NeuN tissue images; then a human-in-the-loop\napproach was taken to verify each predicted mask and feed\ncorrect images-masks pairs to the training set.\nDeep\nneural\nnetworks\nhave\ngenerated\nconsiderable\ninterest in the medical imaging ﬁeld because they have shown\nperformance advantages over conventional engineered image\nanalysis algorithms. Although the idea of neural networks\nhas been around for a long time, the recent deep neural\nnetworks revolution is partly due to the development of the\nconvolutional neural network (CNN), optimization algorithms\n[7]\n[8]\n[9]\n[10],\nand\npowerful,\nefﬁcient\ncomputation\nresources. Deep learning refers to learning methods that\noften start from raw data get to a more abstract level [11].\nConvolutional\nNeural\nNetworks\nhave\nshown\nsigniﬁcant\nsuccess in challenging tasks in image classiﬁcation and\nrecognition [12] [13]. In this paper, we use a CNN based\narchitecture for medical image segmentation known as Unet\n[14]. This architecture is a simple, fast, and end-to-end fully\nconvolutional network that contains contraction and expansion\npaths to capture context and learn precise localization.\nIn this paper, we propose a method that iteratively\nutilizes deep learning with human-in-the-loop and an existing\narXiv:1901.04355v1  [cs.CV]  14 Jan 2019\nunsupervised algorithm (ASA) which eliminates human data\nlabeling entirely (creating masks) of NeuN stained images to\nquantify the number of cells in an ROI. This approach uses a\nstate-of-art deep learning architecture in which user veriﬁed\nASA results of EDF images are used to train a convolution\nneural network (CNN) model to segment and make automatic\nneuron counts on test images. Meanwhile, a set of deep\nlearning predicted masks are veriﬁed by a human-in-the-loop\nand fed back to the train set. The main innovation is: i)\nelimination of human labeling effort (creating masks) using\nan existing unsupervised algorithm (ASA) to generate masks\nto train a CNN, ii) using a deep learning iterative process\nto reduce human effort in data labeling, where the user only\nveriﬁes the correctness of segmentation, and iii) improving\ndeep learning stereology cell counting by adding correctly\nlabeled images (EDF images and their corresponding masks)\nto the training set for the next iteration.\nII. UNBAISED STEREOLOGY\nUnbiased stereology is the state-of-the-art for biological\nobjects quantiﬁcation in tissue sections [15]. An essential com-\nponent of this approach is unbiased sampling (i.e., systematic-\nrandom) that avoids all sources of biased assumption such\nas shape, size, and orientation [15] [3]. Unbiased stereology\nuses a virtual disector box to quantify the number of cells in\na region-of-interest (ROI). Counted cells are based on their\nlocation within an ROI and disector box. For instance, cells\ntouching the disector inclusion-line (i.e., disector upper and\nright line) or inside the disector box are counted. However,\ncells that touch the exclusion line (i.e., disector lower and left\nline) are not counted. An example of the disector box counting\nprocedure is shown in Fig. 1a, where the green line represents\ninclusion line, and the red line represents the exclusion line.\nCounted cells are marked manually with the blue marks.\nIII. DATA SET\nThe data set used in this work was sampled from the\nneocortex brain region of Tg4510 mice. As described by\nMouton et al. in [2], animals and the process used in this study\nwere approved by the University of South Florida (USF) Insti-\ntutional Animal Care and Use Committee which follows NIH\nguidelines. The data set includes both genetically modiﬁed\nmice and control mice. Mice neurons change while expressing\nmutant tau. These neuron changes include neuron degeneration\nand neuroglia cells activation [2] [16] [17]. Mice samples\nwere stained with NeuN single staining from which counting\nwas performed manually using an optical fractionator [4].\nDisector stacks were captured and saved using the Stereologer\nsystem [2]. Table I shows the number of sections from which\nmultiple stacks were obtained and converted into EDF images.\nThe total number of EDF images we have is 966 with their\ncorresponding ASA masks.\nIV. ADAPTIVE SEGMENTATION ALGORITHM\nAs shown in [2], the adaptive segmentation algorithm (ASA)\nconsists of multiple steps optimized to segment cells at high\nTABLE I\nDATASETS MOUSE ID, NUMBER OF SECTIONS PER MOUSE AND TOTAL\nNUMBER OF STACKS PER MOUSE\nMouse ID\nNumber of sections\nNumber of stacks\n02\n8\n113\n03\n6\n121\n14\n8\n90\n17\n7\n91\n29\n8\n135\n21\n7\n102\n24\n8\n103\n67\n8\n104\n09\n6\n107\nmagniﬁcation (63 to 100x oil immersion) microscopy. The\nASA includes a Gaussian Mixture (GMM), morphological\noperations, Voronoi diagrams, and watershed segmentation. It\nstarts with EDF images to segment NeuN stained cells within\na region of interest (ROI) using GMM; where GMM uses\npixel intensity for the Expectation Maximization algorithm\n(EM) to estimate its components followed by thresholding and\nmorphological operations to get separate cells. A processed\nEDF image using opening then closing by reconstruction is\nused in the watershed foreground and background markers\nextraction. These foreground and background markers are\nused in applying the watershed segmentation followed by\nsegmentation approximation using Voronoi diagrams. ASA\nuses a smoothing process to enhance cell boundaries using\na Savitzky-Golay ﬁlter [18]. The reason to use ASA is that\nmanual annotation does not provide mask information, but\ninstead, it provides a mark of what cell is being counted based\non the unbiased stereology approach. An example of manual\nannotation is shown in Fig. 1a.\nV. METHOD\nIn unbiased stereology, where labeling cells is tedious,\ntime-consuming, and subject to errors, an iterative deep\nlearning approach can leverage the data labeling process\nand generate correctly labeled examples that could help in\nbuilding a more robust model. The EDF algorithm [6] was\napplied to each stack of images to produce a single in-focus\nimage as shown in Fig.\n1b. Using EDF images, initial\nlabels (masks) for our data set have been created using the\nASA algorithm as shown in Fig.\n1c, followed by a manual\nveriﬁcation step to identify ASA accepted masks/images (i.e.,\nASA masks which match the manual annotation) from ASA\nrejected masks/images (i.e., ASA masks do not match the\nmanual annotation) as illustrated in Fig. 2a. An example of\nmanual annotation marks is shown in Fig.\n1a, where blue\nmarks correspond to counted cells. For instance, the image\nshown in Fig. 1c was accepted by a user because every cell\nmask (white blobs) inside or touching inclusion line (i.e.,\nupper and right green line shown in Fig.\n1a) correspond to\nblue marks (counted cells) in the manual annotation shown\nin Fig.\n1a. This user veriﬁcation step ignores cells that\ntouch the exclusion line (disector left and lower line) for the\n(a) Manual annotation\n(b) EDF image\n(c) ASA mask\nFig. 1.\nAn example from our data set, where a) is the manual annotation\n(counted neurons have green dots), b) is the EDF image, and c) is the ASA\nmask for the EDF image shown in (b)\npurpose of training deep learning model.\nIn this section, we describe our iterative deep learning\napproach which can be described in ﬁve steps: 1) we train\na deep learning model (Unet) on EDF images, and their\ncorresponding ASA accepted masks that match manual\nannotation images; 2) A prediction was made on EDF images\nof ASA rejected masks that do not match manual annotation,\nand we refer to this set of images as the ”active set”; 3)\nAnother set that does not overlap with either the training nor\nthe active set is the ”test set” which contains EDF images of\ndifferent sections of a unique mouse (mouse id 17); 4) The\nresults of testing a trained deep learning model on the active\nset were veriﬁed by the user by comparing the predicted\nmask and manual annotation similarity (as described in the\nprevious paragraph). If a mask matches the manual annotation\nimage (i.e., cells marked for counting on a manual annotation\nimage were segmented correctly using deep learning), then\nthat mask and its corresponding EDF image are augmented\nusing a combination of elasticity and rotation augmentation\nand then the augmented images are added to the training set\nfor deep learning. Meanwhile, the EDF gets removed from\nthe active set. On the other hand, if a mask does not match\nwith its corresponding manual annotation image, then its\nEDF image remains in the active set; 5) The iterative process\nwas performed for ﬁve iterations. Fig.\n2b demonstrates the\nproposed method. It is important to note that human-in-the-\nloop involvement means accepting or rejecting a mask based\non its corresponding manual annotation as shown in Fig. 1a.\nTherefore, no relabeling was made by the human-in-the-loop.\n(a) Initial masks created using ASA followed by human veriﬁcation\n(b) Iterative human-in-the-loop veriﬁcation of deep learning predicted masks\nFig. 2. Proposed method in two steps: a) creating EDF images, and applying\nASA, then human veriﬁcation, and then b) iterative process using accepted\nASA masks/images for training, and ASA masks/images as an active set.\nHuman veriﬁcation (i.e., accept or reject) on every predicted mask. Test set\nis a separate mouse (mouse id 17)\nFor each iteration of our method, we trained a deep\nlearning architecture (Unet) for 100 epochs using Keras and\nTensorﬂow backend [19] [20]. The Adam optimizer was used\nwhere the learning rate was set to 1e−4, while exponential\ndecay rates for the moment estimates hyperparameters β1\n(ﬁrst moment) and β2 (second moment) were set to 0.9 and\n0.999 respectively. [21].\nBased on the unbiased stereology method, cells counted in\nan ROI are those stained cells that are located inside the ROI\nor touching the inclusion line (i.e., top and right green line)\nbut not touching the exclusion line (i.e., bottom and left red\nlines) as shown in Fig.\n1a. For training purposes, we have\nkept all cells by ignoring the unbiased stereology constraints.\nHowever, prior to reporting the results on the test set (mouse\nid 17), a postprocessing step was applied to remove small\nnoise on the predicted mask, separate touching cells, and to\nimpose unbiased stereology criteria of counting by removing\ncells that touch the exclusion disector line.\nVI. EXPERIMENTS AND RESULTS\nOur data set has 966 stacks from 9 different mice. The EDF\nalgorithm was used to create EDF images for each stack to get\nan in-focus image. The number of images in the initial train\nset (no augmentation) is 147 images, the number of images in\nthe initial active set is 728 images, and the number of images\nin the test set is 91 images. Data augmentation used in this\nexperiment was rotation 15° of elastic augmentation [22]. For\nexample, for an image M, we apply an elastic algorithm with\ntwo different random seeds, which yields two elastic images\nM1, M2. Then for each of M, M1, and M2 we apply rotation\naugmentation of 15°. The total number of images generated\nby applying elastic then rotation augmentation of a single\nimage is 72 images (including original image). This elastic\nand rotation augmentation is applied to the EDF images, and\nthen we cropped images 20 pixels around the disector line as\nshown in Fig. 1b. We have used error rate to report results\non the test set as shown in Equation\n1, where ytrue is the\nnumber of counted cells on ground truth (manual annotation),\nand ypred is the number of counted cells on a predicted deep\nlearning mask. For iteration 1, training on ASA accepted only\nimages, and testing on a separate mouse (i.e., test set) resulted\nin 3.16 % error rate, and the user accepted 379 images from\nthe active set. Increasing training images helped to reduce the\nerror rate on the second iteration to 0.82 %; furthermore, 81\nimages were accepted by the user and moved to the training\nset. The lowest error rate on the test set was 0.41 % with a\nhigher number of training images (iteration 4).\nError rate = |ytrue −ypred|\nytrue\n∗100\n(1)\nTABLE II\nRESULTS OF THE PROPOSED METHOD THAT SHOWS THE NUMBER OF\nACCEPTED IMAGES FROM ACTIVE SET IN EVERY ITERARTION, AND THE\nERROR RATE (%) ON A TEST SET (MOUSE ID 17)\nIteration number\nNumber of accepted images\nError rate on test set (%)\n1\n379\n3.16\n2\n81\n0.82\n3\n51\n1.92\n4\n18\n0.41\n5\n15\n0.55\nIn Table II, complete results of the iterative deep learning\nbased unbiased stereology approach of ﬁve iterations are\nprovided. Fig.\n3 shows an example from our data set to\ncompare the ASA mask, and the iterative deep learning\npredicted mask. Fig.\n3b shows an improved segmentation\nof cells on EDF image which was accepted on the ﬁfth\niteration. One unanticipated ﬁnding was that on the third\nand ﬁfth iterations, the error rate was slightly higher than\nthe prior iteration. This could be caused by the rotation\naugmentation artifacts and user subjectivity when accepting\nnew images/masks from the active set. In Fig.\n4, we show\na visual comparison between the iterative deep learning\n(a) ASA\n(b) deep learning\nFig. 3. Example from our data set, where a) the ASA masks contour overlaid\non manual annotation image (counted neurons have blue marks), b) the\niterative deep learning predicted masks contour (accepted on the ﬁfth iteration\nof our iterative deep learning based unbiased stereology) overlaid on manual\nannotation image\nSection1 Section2 Section3 Section4 Section5 Section6 Section7 Section8\nTest mouse sections\n0\n50\n100\n150\n200\nTotal neuron count\nManual_count\nUnet_count\nASA_count\nFig. 4. Test mouse cells count using manual, ASA, and Unet (deep learning)\nTABLE III\nTEST MOUSE CELLS COUNT USING MANUAL METHOD, UNET (DEEP\nLEARNING), AND ASA.\nTest mouse\nManual cells count\nUnet cells count\nASA cells count\nSection 1\n74\n82\n65\nSection 2\n142\n137\n121\nSection 3\n177\n160\n157\nSection 4\n49\n48\n50\nSection 5\n58\n59\n54\nSection 6\n70\n64\n57\nSection 7\n83\n92\n77\nSection 8\n74\n81\n66\niteration (iteration 4) results, ASA, and manual counting.\nWhere manual cell count, ASA based cell count, and deep\nlearning (Unet) based cell count are reported for the test set.\nThe ASA error rate on the test set (mouse id 17) was 11\n%. Additionally, the cell count of the test mouse in different\nsections is shown in Table III. A comparison between ASA\nresults and Unet (Deep learning) results on three examples\nfrom the test set after post-processing and applying unbiased\nstereology counting rules is presented in Fig. 5.\n(a) ASA\n(b) Deep learning\n(c) ASA\n(d) Deep learning\n(e) ASA\n(f) Deep learning\nFig. 5.\nExamples from the test set, where a,c, and d are the ASA mask\ncontours overlaid on manual annotation images (counted neurons have blue\nmarks), b, d, and f are the iterative deep learning predicted masks (iteration\n5) contours overlaid on manual annotation image\nVII. DISCUSSION\nThe evidence from this study suggests that the iterative\ndeep learning based unbiased stereology method presented\nherein is much faster and more accurate than the state-of-the-\nart stereology since human involvement was mainly reduced.\nThe state-of-the-art stereology takes about 2-3 hours per an\nROI; however, the proposed method herein estimated time was\napproximately 20-30 minutes per an ROI (including preparing\nmasks using ASA, human veriﬁcation, using the trained model\nfor the prediction on the test set, post-processing, and count-\ning). Human involvement reduction was as follows:\n1) Instead of creating initial labels manually (creating\nmasks), an unsupervised algorithm (ASA) was utilized\nto create initial masks, then a user veriﬁcation step to\nmerely accept or reject an image/mask based on the\nmatch to the manual annotation.\n2) Instead of relabeling active set images/masks predicted\nby deep learning in each iteration of the iterative deep\nlearning process, the human-in-the-loop was only verify-\ning the correctness of predicted masks, that is accepting\nor rejecting based on the match to the manual annotation\nas described earlier.\nLack of a large number of properly annotated images\nremains an obstacle to many researchers, especially in the\nmedical ﬁeld; because manual image annotation is tedious\nand error-prone work. Additionally, lack of expert labor\nto annotate a large number of images to build a more\nrobust model is an issue. Therefore, utilizing a pre-existing\nalgorithm (i.e., ASA) to generate masks for EDF images\novercomes signiﬁcant challenges such as creating masks\nmanually. However, a user intervention in creating masks\nwas not eliminated but instead reduced; since ASA masks\nneed a veriﬁcation step to accept masks that match manual\nannotation. As a result, training of the deep learning model\nwas done on EDF images, and their corresponding accepted\nASA masks. Therefore, it can thus be suggested that using\npre-existing methods such as ASA for initial mask generation\nfollowed by a veriﬁcation step is the most suitable way to\naccelerate data labeling (i.e., segmentation) that would have\ntaken a large amount of time otherwise. Additionally, using\na human-in-the-loop for iterative deep learning to verify\npredicted masks on an unlabeled set of EDF images (i.e.,\nactive set) is an optimal method to increase training images\nwith correct labels (masks).\nThe generalisability of this study is subject to certain\nlimitations. For instance, lack of enough data to best train\ndeep learning models. Another limitation is user subjectivity\nin verifying predicted masks by deep learning in the active set.\nNotwithstanding the relatively limited data and user subjectiv-\nity constraints, this work offers valuable insights into using\nan existing unsupervised algorithm (ASA) to generate masks\n(labels) instead of human labeling (creating masks), then\nimproving the model performance by iterative deep learning\nbased unbiased stereology with a human-in-the-loop.\nVIII. CONCLUSION\nThis paper presents an iterative deep learning based\nunbiased stereology strategy that uses an existing unsupervised\nalgorithm (ASA) to obtain masks as initial labels for training\na deep convolutional neural network to segment and count\ncells on ROIs of NeuN single stained images. The proposed\nmethod herein was able to achieve good results (error rate less\nthan 1 %) compared to the ASA cell counting (error rate of\n11%), although ASA generated the initial labels (segmentation\nmasks). Moreover, the proposed algorithm eliminates human\neffort in data labeling, where human-in-the-loop work was\nmerely to verify masks based on the corresponding manual\nannotation. Our approach has some drawbacks such as human-\nin-the-loop effort and subjectivity which could be an obstacle\nwith massive sets of images for veriﬁcation. Iterative deep\nlearning based unbiased stereology techniques in conjunction\nwith initial labels (masks) from an existing algorithm (ASA)\nshowed encouraging results compared to ASA and the\ncurrent stereology counting method which is laborious, slow,\nand time-consuming to obtain for a signiﬁcant amount of data.\nIX. ACKNOWLEDGMENTS\nThe authors would like to thank Dr. Marcia Gordon of\nMichigan State University (Grand Rapids, MI) for the gen-\nerous donation of the stained tissue sections for these studies.\nThis research was partially supported by the National Science\nFoundation under award number (#1513126) and (#1746511).\nREFERENCES\n[1] P. R. Mouton, Unbiased stereology: a concise guide.\nJHU Press, 2011.\n[2] P. R. Mouton, H. A. Phoulady, D. Goldgof, L. O. Hall, M. Gordon, and\nD. Morgan, “Unbiased estimation of cell number using the automatic\noptical fractionator,” Journal of chemical neuroanatomy, vol. 80, pp.\nA1–A8, 2017.\n[3] M. Burke, S. Zangenehpour, P. R. Mouton, and M. Ptito, “Knowing what\ncounts: unbiased stereology in the non-human primate brain,” Journal\nof visualized experiments: JoVE, p. 27, 2009.\n[4] M. West, L. Slomianka, and H. J. G. Gundersen, “Unbiased stereological\nestimation of the total number of neurons in the subdivisions of the rat\nhippocampus using the optical fractionator,” The Anatomical Record,\nvol. 231, no. 4, pp. 482–497, 1991.\n[5] A. G. Valdecasas, D. Marshall, J. M. Becerra, and J. Terrero, “On the\nextended depth of focus algorithms for bright ﬁeld microscopy,” Micron,\nvol. 32, no. 6, pp. 559–569, 2001.\n[6] A. P. Bradley and P. C. Bamford, “A one-pass extended depth of ﬁeld\nalgorithm based on the over-complete discrete wavelet transform,” in\nImage and Vision Computing’04 New Zealand (IVCNZ’04).\nnot found,\n2004, pp. 279–284.\n[7] G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of\ndata with neural networks,” science, vol. 313, no. 5786, pp. 504–507,\n2006.\n[8] V. Nair and G. E. Hinton, “Rectiﬁed linear units improve restricted boltz-\nmann machines,” in Proceedings of the 27th international conference on\nmachine learning (ICML-10), 2010, pp. 807–814.\n[9] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhut-\ndinov, “Dropout: A simple way to prevent neural networks from over-\nﬁtting,” The Journal of Machine Learning Research, vol. 15, no. 1, pp.\n1929–1958, 2014.\n[10] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep\nnetwork training by reducing internal covariate shift,” arXiv preprint\narXiv:1502.03167, 2015.\n[11] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, vol. 521,\nno. 7553, p. 436, 2015.\n[12] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi,\nM. Ghafoorian, J. A. van der Laak, B. van Ginneken, and C. I. S´anchez,\n“A survey on deep learning in medical image analysis,” Medical image\nanalysis, vol. 42, pp. 60–88, 2017.\n[13] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation\nwith deep convolutional neural networks,” in Advances in neural infor-\nmation processing systems, 2012, pp. 1097–1105.\n[14] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks\nfor biomedical image segmentation,” in International Conference on\nMedical image computing and computer-assisted intervention. Springer,\n2015, pp. 234–241.\n[15] C. B. Saper, “Any way you cut it: a new journal policy for the use of\nunbiased counting methods,” Journal of Comparative Neurology, vol.\n364, no. 1, pp. 5–5, 1996.\n[16] K. Santacruz, J. Lewis, T. Spires, J. Paulson, L. Kotilinek, M. Ingelsson,\nA. Guimaraes, M. Deture, M. Ramsden, E. McGowan et al., “Tau\nsuppression in a neurodegenerative mouse model improves memory\nfunction,” Science, vol. 309, no. 5733, pp. 476–481, 2005.\n[17] T. L. Spires, J. D. Orne, K. SantaCruz, R. Pitstick, G. A. Carlson,\nK. H. Ashe, and B. T. Hyman, “Region-speciﬁc dissociation of neuronal\nloss and neuroﬁbrillary pathology in a mouse model of tauopathy,” The\nAmerican journal of pathology, vol. 168, no. 5, pp. 1598–1607, 2006.\n[18] A. Savitzky and M. J. Golay, “Smoothing and differentiation of data\nby simpliﬁed least squares procedures.” Analytical chemistry, vol. 36,\nno. 8, pp. 1627–1639, 1964.\n[19] F. Chollet et al., “Keras,” https://github.com/fchollet/keras, 2015.\n[20] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S.\nCorrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow,\nA. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser,\nM. Kudlur, J. Levenberg, D. Man´e, R. Monga, S. Moore, D. Murray,\nC. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar,\nP. Tucker, V. Vanhoucke, V. Vasudevan, F. Vi´egas, O. Vinyals,\nP. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng,\n“TensorFlow: Large-scale machine learning on heterogeneous systems,”\n2015, software available from tensorﬂow.org. [Online]. Available:\nhttps://www.tensorﬂow.org/\n[21] D. Kinga and J. B. Adam, “A method for stochastic optimization,” in\nInternational Conference on Learning Representations (ICLR), 2015.\n[22] P. Y. Simard, D. Steinkraus, J. C. Platt et al., “Best practices for\nconvolutional neural networks applied to visual document analysis.” in\nICDAR, vol. 3, 2003, pp. 958–962.\n",
  "categories": [
    "cs.CV",
    "cs.LG"
  ],
  "published": "2019-01-14",
  "updated": "2019-01-14"
}