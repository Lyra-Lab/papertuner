{
  "id": "http://arxiv.org/abs/1905.12614v4",
  "title": "Unsupervised Model Selection for Variational Disentangled Representation Learning",
  "authors": [
    "Sunny Duan",
    "Loic Matthey",
    "Andre Saraiva",
    "Nicholas Watters",
    "Christopher P. Burgess",
    "Alexander Lerchner",
    "Irina Higgins"
  ],
  "abstract": "Disentangled representations have recently been shown to improve fairness,\ndata efficiency and generalisation in simple supervised and reinforcement\nlearning tasks. To extend the benefits of disentangled representations to more\ncomplex domains and practical applications, it is important to enable\nhyperparameter tuning and model selection of existing unsupervised approaches\nwithout requiring access to ground truth attribute labels, which are not\navailable for most datasets. This paper addresses this problem by introducing a\nsimple yet robust and reliable method for unsupervised disentangled model\nselection. Our approach, Unsupervised Disentanglement Ranking (UDR), leverages\nthe recent theoretical results that explain why variational autoencoders\ndisentangle (Rolinek et al, 2019), to quantify the quality of disentanglement\nby performing pairwise comparisons between trained model representations. We\nshow that our approach performs comparably to the existing supervised\nalternatives across 5,400 models from six state of the art unsupervised\ndisentangled representation learning model classes. Furthermore, we show that\nthe ranking produced by our approach correlates well with the final task\nperformance on two different domains.",
  "text": "Published as a conference paper at ICLR 2020\nUNSUPERVISED MODEL SELECTION FOR\nVARIATIONAL DISENTANGLED\nREPRESENTATION LEARNING\nSunny Duan∗\nDeepMind\nsunnyd@google.com\nLoic Matthey\nDeepMind\nlmatthey@google.com\nAndre Saraiva\nDeepMind\nandresnds@google.com\nNick Watters\nDeepMind\nnwatters@google.com\nChris Burgess\nDeepMind\ncpburgess@google.com\nAlexander Lerchner\nDeepMind\nlerchner@google.com\nIrina Higgins∗\nDeepMind\nirinah@google.com\nABSTRACT\nDisentangled representations have recently been shown to improve fairness, data\nefﬁciency and generalisation in simple supervised and reinforcement learning tasks.\nTo extend the beneﬁts of disentangled representations to more complex domains and\npractical applications, it is important to enable hyperparameter tuning and model se-\nlection of existing unsupervised approaches without requiring access to ground truth\nattribute labels, which are not available for most datasets. This paper addresses this\nproblem by introducing a simple yet robust and reliable method for unsupervised dis-\nentangled model selection. Our approach, Unsupervised Disentanglement Ranking\n(UDR)1, leverages the recent theoretical results that explain why variational autoen-\ncoders disentangle (Rolinek et al., 2019), to quantify the quality of disentanglement\nby performing pairwise comparisons between trained model representations. We\nshow that our approach performs comparably to the existing supervised alternatives\nacross 5400 models from six state of the art unsupervised disentangled representation\nlearning model classes. Furthermore, we show that the ranking produced by our\napproach correlates well with the ﬁnal task performance on two different domains.\n1\nINTRODUCTION\nHappy families are all alike; every unhappy family is unhappy in its own way. —\nLeo Tolstoy, Anna Karenina\nDespite the success of deep learning in the recent years (Hu et al., 2018; Espeholt et al., 2018;\nSilver et al., 2018; Lample et al., 2018; Hessel et al., 2017; Oord et al., 2016), the majority of state\nof the art approaches are still missing many basic yet important properties, such as fairness, data\nefﬁcient learning, strong generalisation beyond the training data distribution, or the ability to transfer\nknowledge between tasks (Lake et al., 2016; Garnelo et al., 2016; Marcus, 2018). The idea that a\ngood representation can help with such shortcomings is not new, and recently a number of papers have\ndemonstrated that models with disentangled representations show improvements in terms of these\nshortcomings (Higgins et al., 2017b; 2018b; Achille et al., 2018; Steenbrugge et al., 2018; Nair et al.,\n2018; Laversanne-Finot et al., 2018; van Steenkiste et al., 2019; Locatello et al., 2019). A common\nintuitive way to think about disentangled representations is that it should reﬂect the compositional\n∗Equal contribution.\n1We have released the code for our method as part of disentanglement_lib\n1\narXiv:1905.12614v4  [cs.LG]  14 Feb 2020\nPublished as a conference paper at ICLR 2020\nRoof height\nColour\nRotation\nCar type\nSeed 1\nSeed 2\nSeed 3\nUDR = 0.806\nSeed 1\nUDR = 0.204\nz1\nz3\nz4\nz2\nz5\n-3\n3\n-3\n3\n-3\n3\n-3\n3\nz1\nz3\nz4\nz2\nz5\nz1\nz3\nz4\nz2\nz5\nFigure 1: Latent traversals for one of the best and worst ranked trained β-VAE models using the\nUnsupervised Disentanglement Ranking (UDRL) method on the 3D Cars dataset. For each seed image\nwe ﬁx all latents zi to the inferred value, then vary the value of one latent at a time to visualise its\neffect on the reconstructions. The high scoring model (left 3 blocks) appears well disentangled, since\nindividual latents have consistent semantic meaning across seeds. The low scoring model (right block)\nis highly entangled, since the latent traversals are not easily interpretable.\nstructure of the world. For example, to describe an object we often use words pertaining to its colour,\nposition, shape and size. We can use different words to describe these properties because they relate to\nindependent factors of variation in our world, i.e. properties which can be compositionally recombined.\nHence a disentangled representation of objects should reﬂect this by factorising into dimensions which\ncorrespond to those properties (Bengio et al., 2013; Higgins et al., 2018a).\nThe ability to automatically discover the compositional factors of complex real datasets can be of\ngreat importance in many practical applications of machine learning and data science. However, it is\nimportant to be able to learn such representations in an unsupervised manner, since most interesting\ndatasets do not have their generative factors fully labelled. For a long time scalable unsupervised\ndisentangled representation learning was impossible, until recently a new class of models based on\nVariational Autoencoders (VAEs) (Kingma & Welling, 2014; Rezende et al., 2014) was developed.\nThese approaches (Higgins et al., 2017a; Burgess et al., 2017; Chen et al., 2018; Kumar et al., 2017; Kim\n& Mnih, 2018) scale reasonably well and are the current state of the art in unsupervised disentangled\nrepresentation learning. However, so far the beneﬁts of these techniques have not been widely exploited\nbecause of two major shortcomings: First, the quality of the achieved disentangling is sensitive to\nthe choice of hyperparameters, however, model selection is currently impossible without having\naccess to the ground truth generative process and/or attribute labels, which are required by all the\ncurrently existing disentanglement metrics (Higgins et al., 2017a; Kim & Mnih, 2018; Chen et al., 2018;\nEastwood & Williams, 2018; Ridgeway & Mozer, 2018). Second, even if one could apply any of the\nexisting disentanglement metrics for model selection, the scores produced by these metrics can vary a\nlot even for models with the same hyperparameters and trained on the same data (Locatello et al., 2018).\nWhile a lot of this variance is explained by the actual quality of the learnt representations, some of it\nis introduced by the metrics themselves. In particular, all of the existing supervised disentanglement\nmetrics assume a single “canonical” factorisation of the generative factors, any deviation from which is\npenalised. Such a “canonical” factorisation, however, is not chosen in a principled manner. Indeed, for\nthe majority of datasets, apart from the simplest ones, multiple equally valid disentangled representa-\ntions may be possible (see Higgins et al. (2018a) for a discussion). For example, the intuitive way that\nhumans reason about colour is in terms of hue and saturation. However, colour may also be represented\nin RGB, YUV, HSV, HSL, CIELAB. Any of the above representations are as valid as each other, yet\nonly one of them is allowed to be “canonical” by the supervised metrics. Hence, a model that learns\nto represent colour in a subspace aligned with HSV will be penalised by a supervised metric which\nassumes that the canonical disentangled representation of colour should be in RGB. This is despite\nthe fact that both representations are equal in terms of preserving the compositional property at the\ncore of what makes disentangled representations useful (Higgins et al., 2018a). Hence, the ﬁeld ﬁnds\nitself in a predicament. From one point of view, there exists a set of approaches capable of reasonably\nscalable unsupervised disentangled representation learning. On the other hand, these models are hard\nto use in practice, because there is no easy way to do a hyperparameter search and model selection.\nThis paper attempts to bridge this gap. We propose a simple yet effective method for unsupervised model\nselection for the class of current state-of-the-art VAE-based unsupervised disentangled representation\nlearning methods. Our approach, Unsupervised Disentanglement Ranking (UDR), leverages the recent\n2\nPublished as a conference paper at ICLR 2020\ntheoretical results that explain why variational autoencoders disentangle (Rolinek et al., 2019), to quan-\ntify the quality of disentanglement by performing pairwise comparisons between trained model repre-\nsentations. We evaluate the validity of our unsupervised model selection metric against the four best ex-\nisting supervised alternatives reported in the large scale study by Locatello et al. (2018): the β-VAE met-\nric (Higgins et al., 2017a), the FactorVAE metric (Kim & Mnih, 2018), Mutual Information Gap (MIG)\n(Chen et al., 2018) and DCI Disentanglement scores (Eastwood & Williams, 2018). We do so for all\nexisting state of the art disentangled representation learning approaches: β-VAE (Higgins et al., 2017a),\nCCI-VAE (Burgess et al., 2017), FactorVAE (Kim & Mnih, 2018), TC-VAE (Chen et al., 2018) and two\nversions of DIP-VAE (Kumar et al., 2017). We validate our proposed method on two datasets with fully\nknown generative processes commonly used to evaluate the quality of disentangled representations:\ndSprites (Matthey et al., 2017) and 3D Shapes (Burgess & Kim, 2018), and show that our unsupervised\nmodel selection method is able to match the supervised baselines in terms of guiding a hyperparameter\nsearch and picking the most disentangled trained models both quantitatively and qualitatively. We also\napply our approach to the 3D Cars dataset (Reed et al., 2014), where the full set of ground truth attribute\nlabels is not available, and conﬁrm through visual inspection that the ranking produced by our method\nis meaningful (Fig. 1). Overall we evaluate 6 different model classes, with 6 separate hyperparameter\nsettings and 50 seeds on 3 separate datasets, totalling 5400 models and show that our method is both ac-\ncurate and consistent across models and datasets. Finally, we validate that the model ranking produced\nby our approach correlates well with the ﬁnal task performance on two recently reported tasks: a classiﬁ-\ncation fairness task (Locatello et al., 2019) and a model-based reinforcement learning (RL) task (Watters\net al., 2019). Indeed, on the former our approach outperformed the reported supervised baseline scores.\n2\nOPERATIONAL DEFINITION OF DISENTANGLING\nGiven a dataset of observations X ={x1,...,xN}, we assume that there exist a number of plausible\ngenerative processes gi that produce the observations from a small set of corresponding Ki independent\ngenerative factors ci. For each choice of i, g :cn 7→xn, where p(cn)=QK\nj=1p(cj\nn). For example, a\ndataset containing images of an object, which can be of a particular shape and colour, and which can\nbe in a particular vertical and horizontal positions, may be created by a generative process that assumes\na ground truth disentangled factorisation into shape x colour x position, or shape x hue x saturation\nx position X x position Y. We operationalise a model as having learnt a disentangled representation, if it\nlearns to invert of one of the generative processes gi and recover a latent representation z ∈RL, so that\nit best explains the observed data p(z,x)≈p(ci,x), and factorises the same way as the corresponding\ndata generative factors ci. The choice of the generative process can be determined by the interaction\nbetween the model class and the observed data distribution p(x), as discussed next in Sec. 3.1.\n3\nVARIATIONAL UNSUPERVISED DISENTANGLING\nThe current state of the art approaches to unsupervised disentangled representation learning are based\non the Variational Autoencoder (VAE) framework (Rezende et al., 2014; Kingma & Welling, 2014).\nVAEs attempt to estimate the lower bound on the joint distribution of the data and the latent factors\np(x,z) by optimising the following objective:\nLV AE =Ep(x)[ Eqφ(z|x)[log pθ(x|z)]−KL(qφ(z|x) || p(z)) ]\n(1)\nwhere, in the usual case, the prior p(z) is chosen to be an isotropic unit Gaussian. In order to encourage\ndisentangling, different approaches decompose the objective in Eq. 1 into various terms and change\ntheir relative weighting. In this paper we will consider six state of the art approaches to unsupervised\ndisentangled representation learning that can be grouped into three broad classes based on how they\nmodify the objective in Eq. 1: 1) β-VAE (Higgins et al., 2017a) and CCI-VAE (Burgess et al., 2017)\nupweight the KL term; 2) FactorVAE (Kim & Mnih, 2018) and TC-VAE (Chen et al., 2018) introduce\na total correlation penalty; and 3) two different implementations of DIP-VAE (-I and -II) (Kumar et al.,\n2017) penalise the deviation of the the marginal posterior from a factorised prior (see Sec. A.4.1 in\nSupplementary Material for details).\n3\nPublished as a conference paper at ICLR 2020\n3.1\nWHY DO VAES DISENTANGLE?\nIn order to understand the reasoning behind our proposed unsupervised disentangled model selection\nmethod, it is ﬁrst important to understand why VAEs disentangle. The objective in Eq. 1 does not in\nitself encourage disentangling, as discussed in Rolinek et al. (2019) and Locatello et al. (2018). Indeed,\nany rotationally invariant prior makes disentangled representations learnt in an unsupervised setting\nunidentiﬁable when optimising Eq. 1. This theoretical result is not surprising and has been known for a\nwhile in the ICA literature (Comon, 1994), however what is surprising is that disentangling VAEs appear\nto work in practice. The question of what makes VAEs disentangle was answered by Rolinek et al.\n(2019), who were able to show that it is the peculiarities of the VAE implementation choices that allow\ndisentanglingtoemerge(seealsodiscussioninBurgessetal.(2017);Mathieuetal.(2019)). Inparticular,\nthe interactions between the reconstruction objective (the ﬁrst term in Eq. 1) and the enhanced pressure\ntomatchadiagonalpriorcreatedbythemodiﬁedobjectivesofthedisentanglingVAEs, forcethedecoder\nto approximate PCA-like behaviour locally around the data samples. Rolinek et al. (2019) demonstrated\nthat during training VAEs often enter the so-called “polarised regime”, where many of the latent\ndimensions of the posterior are effectively switched off by being reduced to the prior qφ(zj)=p(zj)\n(this behaviour is often further encouraged by the extra disentangling terms added to the ELBO). When\ntrained in such a regime, a linear approximation of the Jacobian of the decoder around a data sample xi,\nJi = ∂Decθ(µφ(xi))\n∂µφ(xi)\n, is forced to have orthogonal columns, and hence to separate the generative factors\nbased on the amount of reconstruction variance they induce. Given that the transformations induced\nby different generative factors will typically have different effects on the pixel space (e.g. changing the\nposition of a sprite will typically affect more pixels than changing its size), such local orthogonalisation\nof the decoder induces an identiﬁable disentangled latent space for each particular dataset. An\nequivalent statement is that for a well disentangled VAE, the SVD decomposition J =UΣV ⊤of the\nJacobian J calculated as above, results in a trivial V , which is a signed permutation matrix.\n4\nUNSUPERVISED DISENTANGLED MODEL SELECTION\nWe now describe how the insights from Sec. 3.1 motivate the development of our proposed\nUnsupervised Disentanglement Ranking (UDR) method. Our method relies on the assumption that\nfor a particular dataset and a VAE-based unsupervised disentangled representation learning model\nclass, disentangled representations are all alike, while every entangled representation is entangled\nin its own way, to rephrase Tolstoy. We justify this assumption next.\nDisentangled representations are similar\nAccording to Rolinek et al. (2019) for a given\nnon-adversarial dataset a disentangling VAE will likely keep converging to the same disentangled\nrepresentation (up to permutation and sign inverse). Note that this representation will correspond to\na single plausible disentangled generative process gi using the notation we introduced in Sec. 2. This\nis because any two different disentangled representations za and zb learnt by a VAE-based model\nwill only differ in terms of the corresponding signed permutation matrices Va and Vb of the SVD\ndecompositions of the locally linear approximations of the Jacobians of their decoders.\nEntangled representations are different\nUnfortunately the ﬁeld of machine learning has little\ntheoretical understanding of the nature and learning dynamics of internal representations in neural\nnetworks. The few pieces of research that have looked into the nature of model representations (Raghu\net al., 2017; Li et al., 2016; Wang et al., 2018; Morcos et al., 2018) have been empirical rather than\ntheoretical in nature. All of them suggest that neural networks tend to converge to different hidden\nrepresentations despite being trained on the same task with the same hyperparameters and architecture\nand reaching similar levels of task performance. Furthermore, the theoretical analysis and the empirical\ndemonstrations in Rolinek et al. (2019) suggest that the entangled VAEs learn representations that\nare different at least up to a rotation induced by a non-degenerate matrix V in the SVD decomposition\nof the local linear approximation of the decoder Jacobian Ji.\nThe justiﬁcations presented above rely on the theoretical work of Rolinek et al. (2019), which was\nempirically veriﬁed only for the β-VAE. We have reasons to believe that the theory also holds for the\nother model classes presented in this paper, apart from DIP-VAE-I. We empirically verify that this\nis the case in Sec. A.10 in Supplementary Materials. Furthermore, in Sec. 5 we show that our proposed\nmethod works well in practice across all model classes, including DIP-VAE-I.\n4\nPublished as a conference paper at ICLR 2020\nUnsupervised Disentanglement Ranking\nOur proposed UDR method consists of four steps\n(illustrated in Fig. 4 in Supplementary Material):\n1. Train M =H ×S models, where H is the number of different hyperparameter settings, and S is\nthe number of different initial model weight conﬁgurations (seeds).\n2. For each trained model i ∈{1,...,M}, sample without replacement P ≤S other trained models\nwith the same hyperparameters but different seeds.\n3. Perform P pairwise comparisons per trained model and calculate the respective UDRij scores,\nwhere i∈{1,...,M} is the model index, and j ∈{1,...,P} is its unique pairwise match from Step 2.\n4. Aggregate UDRij scores for each model i to report the ﬁnal UDRi =avgj(UDRij) scores, where\navgj(·) is the median over P scores.\nThe key part of the UDR method is Step 3, where we calculate the UDRij score that summarises how\nsimilar the representations of the two models i and j are. As per the justiﬁcations above, two latent\nrepresentations zi and zj should be scored as highly similar if they axis align with each other up to\npermutation (the same ground truth factor ck may be encoded by different latent dimensions within\nthe two models, zi,a and zj,b where a̸=b), sign inverse (the two models may learn to encode the values\nof the generative factor in the opposite order compared to each other, zi,a = −zj,b), and subsetting\n(one model may learn a subset of the factors that the other model has learnt if the relevant disentangling\nhyperparameters encourage a different number of latents to be switched off in the two models). In\norder for the UDR to be invariant to the ﬁrst scenario, we propose calculating a full L×L similarity\nmatrix Rij between the individual dimensions of zi ∈RL and zj ∈RL (see Fig. 5 in Supplementary\nMaterial). In order to address the second point, we take the absolute value of the similarity matrix |Rij|.\nFinally, to address the third point, we divide the UDR score by the average number of informative\nlatents discovered by the two models. Note that even though disentangling often happens when the\nVAEs enter the “polarised regime”, where many of the latent dimensions are switched off, the rankings\nproduced by UDR are not affected by whether the model operates in such a regime or not.\nTo populate the similarity matrix Rij we calculate each matrix element as the similarity between\ntwo vectors zi,a and zj,b, where zi,a is a response of a single latent dimension za of model i over\nthe entire ordered dataset or a ﬁxed number of ordered mini-batches if the former is computationally\nrestrictive (see Sec. A.5 in Supplementary Material for details). We considered two versions of the UDR\nscore based on the method used for calculating the vector similarity: the non-parametric UDRS, using\nSpearman’s correlation; and the parametric UDRL, using Lasso regression following past work on\nevaluatingrepresentations(Eastwood&Williams,2018;Lietal.,2016). InpracticetheLassoregression\nversion worked slightly better, so the remainder of the paper is restricted to UDRL (we use UDRL and\nUDR interchangeably to refer to this version), while UDRS is discussed in the Supplementary Materials.\nGiven a similarity matrix Rij, we want to ﬁnd one-to-one correspondence between all the informative\nlatent dimensions within the chosen pair of models. Hence, we want to see at most a single strong\ncorrelation in each row and column of the similarity matrix. To that accord, we step through the matrix\nR = |Rij|, one column and row at a time, looking for the strongest correlation, and weighting it by\nthe proportional weight it has within its respective column or row. We then average all such weighted\nscores over all the informative row and column latents to calculate the ﬁnal UDRij score:\n1\nda+db\n\"X\nb\nr2\na·IKL(b)\nP\naR(a,b) +\nX\na\nr2\nb ·IKL(a)\nP\nbR(a,b)\n#\n(2)\nwhere ra = maxa R(a,b) and rb = maxb R(a,b). IKL indicates an “informative” latent within a\nmodel and d is the number of such latents: da =P\naIKL(a) and db =P\nbIKL(b). We deﬁne a latent\ndimension as “informative” if it has learnt a latent posterior which diverges from the prior:\nIKL(a)=\n\u001a1\nKL(qφ(za|x) || p(za))>0.01\n0\notherwise\n(3)\nUDR variations\nWe explored whether doing all-to-all pairwise comparisons, with models in\nStep 2 sampled from the set of all M models rather than the subset of S models with the same\nhyperparameters, would produce more accurate results. Additionally we investigated the effect of\nchoosing different numbers of models P for pairwise comparisons by sampling P ∼U[5,45].\n5\nPublished as a conference paper at ICLR 2020\ndSprites\nScore\nScore\n3D Shapes\nScore\nScore\nFigure 2: Hyperparameter search results for six unsupervised disentangling model classes evaluated\nusing the unsupervised UDR and the supervised β-VAE, FactorVAE, MIG and DCI Disentangling\nmetrics and trained on either dSprites (top) or 3D Shapes (bottom) datasets. “Hyper” corresponds to\nthe particular hyperparameter setting considered (see Tbl. 5 in Supplementary Materials for particular\nvalues). The box and whisker plots for each hyperparameter setting are summarising the scores for\n50 different model seeds. Higher median values indivate better hyperparameters. The ranking of\nhyperparameters tends to be similar between the different metrics, including UDR.\nUDR assumptions and limitations\nNote that our approach is aimed at the current state of the\nart disentangling VAEs, for which the assumptions of our metric have been demonstrated to hold\n(Rolinek et al., 2019). It may be applied to other model classes, however the following assumptions\nand limitations need to be considered:\n1. Disentangled representations produced by two models from the same class trained on the\nsame dataset are likely to be more similar than entangled representations – this holds for\ndisentangling VAEs (Rolinek et al., 2019), but may not hold more broadly.\n2. Continuous, monotonic and scalar factors – UDR assumes that these properties hold for the data\ngenerative factors and their representations. This is true for the disentangling approaches described\nin Sec. 3, but may not hold more generally. It is likely that UDR can be adapted to work with other\nkinds of generative factors (e.g. factors with special or no geometry) by exchanging the similarity\ncalculations in Step 3 with an appropriate measure, however we leave this for future work.\n6\nPublished as a conference paper at ICLR 2020\nMODEL CLASS\nDSPRITES\n3DSHAPES\nLASSO\nSPEARMAN\nLASSO\nSPEARMAN\nHYPER ALL-2-ALL HYPER ALL-2-ALL HYPER ALL-2-ALL HYPER ALL-2-ALL\nβ-VAE\n0.60\n0.76\n0.54\n0.72\n0.71\n0.68\n0.70\n0.71\nTC-VAE\n0.40\n0.67\n0.37\n0.60\n0.81\n0.79\n0.81\n0.75\nDIP-VAE\n0.61\n0.69\n0.65\n0.72\n0.75\n0.74\n0.75\n0.78\nTable 1: Rank correlations between MIG and different versions of UDR across two datasets and three\nmodel classes. The performance is comparable across datasets, UDR versions and model classes. See\nFig. 6 in Supplementary Materials for comparisons with other supervised metrics.\n3. Herd effect – since UDR detects disentangled representations through pairwise comparisons, the\nscore it assigns to each individual model will depend on the nature of the other models involved\nin these comparisons. This means that UDR is unable to detect a single disentangled model within\na hyperparameter sweep. It also means that when models are only compared within a single hyper-\nparameter setting, individual model scores may be over/under estimated as they tend to be drawn\ntowards the mean of the scores of the other models within a hyperparameter group. Thus, it is prefer-\nable to perform the UDR-A2A during model selection and UDR during hyperparameter selection.\n4. Explicitness bias – UDR does not penalise models that learn a subset of the data generative\nfactors. In fact, such models often score higher than those that learn the full set of generative\nfactors, because the current state of the art disentangling approaches tend to trade-off the number\nof discovered factors for cleaner disentangling. As discussed in Sec. 2, we provide the practitioner\nwith the ability to choose the most disentangled model per number of factors discovered by\napproximating this with the d score in Eq. 2.\n5. Computational cost – UDR requires training a number of seeds per hyperparameter setting and\nM ×P pairwise comparisons per hyperparameter search, which may be computationally expensive.\nSaying this, training multiple seeds per hyperparameter setting is a good research practice to\nproduce more robust results and UDR computations are highly parallelisable.\nTo summarise, UDR relies on a number of assumptions and has certain limitations that we hope to\nrelax in future work. However, it offers improvements over the existing supervised metrics. Apart\nfrom being the only method that does not rely on supervised attribute labels, its scores are often\nmore representative of the true disentanglement quality (e.g. see Fig. 3 and Fig. 9 in Supplementary\nMaterials), and it does not assume a single “canonical” disentangled factorisation per dataset. Hence,\nwe believe that UDR can be a useful method for unlocking the power of unsupervised disentangled\nrepresentation learning to real-life practical applications, at least in the near future.\n5\nEXPERIMENTS\nOur hope was to develop a method for unsupervised disentangled model selection with the following\nproperties: it should 1) help with hyperparameter tuning by producing an aggregate score that can be\nused to guide evolutionary or Bayesian methods (Jaderberg et al., 2018; Snoek et al., 2012; Thornton\net al., 2012; Bergstra et al., 2011; Hutter et al., 2011; Miikkulainen et al., 2017); 2) rank individual\ntrained models based on their disentanglement quality; 3) correlate well with ﬁnal task performance.\nIn this section we evaluate our proposed UDR against these qualities. For the reported experiments\nwe use the trained model checkpoints and supervised scores from Locatello et al. (2018) to evaluate\nβ-VAE, CCI-VAE, FactorVAE, TC-VAE, DIP-VAE-I and DIP-VAE-II on two benchmark datasets:\ndSprites (Matthey et al., 2017) and 3D Shapes (Burgess & Kim, 2018) (see Sec. A.3 for details). Each\nmodel is trained with H =6 different hyperparameter settings (detailed in Sec. A.4.1 in Supplementary\nMaterial), with S =50 seeds per setting, and P =50 pairwise comparisons.\nUDR correlates well with the supervised metrics.\nTo validate UDR, we calculate Spearman’s\ncorrelation between its model ranking and that produced by four existing supervised disentanglement\nmetrics found to be the most meaningful in the large scale comparison study by Locatello et al.\n(2018): the original β-VAE metric (Higgins et al., 2017a), FactorVAE metric (Kim & Mnih, 2018),\nMutual Information Gap (MIG) (Chen et al., 2018) and DCI Disentanglement (Eastwood & Williams,\n2018) (see Sec. A.6 in Supplementary Material for metric details). The average correlation for UDR\n7\nPublished as a conference paper at ICLR 2020\n0.895 / 0.616 \nd = 3\nCCI-VAE \nz1\nz10\n-3\n3\n0.607 / 0.751 \nd = 5\nβ-VAE \nz1\nz10\n-3\n3\n0.444 / 0.774 \nTC-VAE \nd = 6\nz1\nz10\n-3\n3\n0.212 / 0.692 \nDIP-VAE \nd = 10\nz1\nz10\n-3\n3\nFigure 3: Latent traversals of the top ranked trained DIP-VAE-I, TC-VAE, CCI-VAE and β-VAE\naccording to the UDR method. At the top of each plot the two presented scores are UDR/FactorVAE\nmetric. Note that the FactorVAE metric scores visually entangled models very highly. d is the number\nof informative latents. The uninformative latents are greyed out.\nis 0.54 ± 0.06 and for UDR-A2A is 0.60 ± 0.11. This is comparable to the average Spearman’s\ncorrelation between the model rankings produced by the different supervised metrics: 0.67 ± 0.2.\nThe variance in rankings produced by the different metrics is explained by the fact that the metrics\ncapture different aspects of disentangling (see Sec. A.2 in Supplementary Materials for a discussion\nof how UDR relates to other representation comparison methods). Tbl. 1 provides a breakdown of\ncorrelation scores between MIG and the different versions of UDR for different model classes and\ndatasets. It is clear that the different versions of UDR perform similarly to each other, and this holds\nacross datasets and model classes. Note that unlike the supervised metrics, UDR does not assume\na “canonical” disentangled representation. Instead, it allows any one of the many equivalent possible\nground truth generative processes to become the “canonical” one for each particular dataset and model\nclass, as per the theoretical results by Rolinek et al. (2019) summarised in Sec. 3.1.\nUDR is useful for hyperparameter selection.\nFig. 2 compares the scores produced by UDR and\nthe four supervised metrics for 3600 trained models, split over six model classes, two datasets and six\nhyperparametersettings. Weconsiderthemedianscoreproﬁlesacrossthesixhyperparametersettingsto\nevaluatewhetheraparticularsettingisbetterthanothers. ItcanbeseenthatUDRbroadlyagreeswiththe\nsupervised metrics on which hyperparameters are more promising for disentangling. This holds across\ndatasets and model classes. Hence, UDR may be useful for evaluating model ﬁtness for disentangled\nrepresentation learning as part of an evolutionary algorithm or Bayesian hyperparameter tuning.\nUDR is useful for model selection.\nFig. 2 can also be used to examine whether a particular trained\nmodel has learnt a good disentangled representation. We see that some models reach high UDR scores.\nFor example, more models score highly as the value of the β hyperparameter is increased in the β-VAE\nmodel class. This is in line with the previously reported results (Higgins et al., 2017a). Note that the 0th\nhyperparameter setting in this case corresponds to β =1, which is equivalent to the standard VAE objec-\ntive (Kingma & Welling, 2014; Rezende et al., 2014). As expected, these models score low in terms of\ndisentangling. We also see that for some model classes (e.g. DIP-VAE-I, DIP-VAE-II and FactorVAE on\ndSprites) no trained model scores highly according to UDR. This suggests that none of the hyperparam-\neter choices explored were good for this particular dataset, and that no instance of the model class learnt\nto disentangle well. To test this, we use latent traversals to qualitatively evaluate the level of disentangle-\nment achieved by the models, ranked by their UDR scores. This is a common technique to qualitatively\nevaluate the level of disentanglement on simple visual datasets where no ground truth attribute labels are\navailable. Such traversals involve changing the value of one latent dimension at a time and evaluating its\neffect on the resulting reconstructions to understand whether the latent has learnt to represent anything\nsemantically meaningful. Fig. 3 demonstrates that the qualitative disentanglement quality is reﬂected\nwell in the UDR scores. The ﬁgure also highlights that the supervised metric scores can sometimes be\noveroptimistic. For example, compare TC-VAE and β-VAE traversals in Fig. 3. These are scored simi-\nlarly by the supervised metric (0.774 and 0.751) but differently by UDR (0.444 and 0.607). Qualitative\nevaluation of the traversals clearly shows that β-VAE learnt a more disentangled representation than TC-\nVAE, which is captured by UDR but not by the supervised metric. Fig. 9 in Supplementary Material pro-\nvides more examples. We also evaluated how well UDR ranks models trained on more complex datasets,\nCelebA and ImageNet, and found that it performs well (see Sec. A.9 in Supplementary Materials).\n8\nPublished as a conference paper at ICLR 2020\nSAMPLE # (P )\n5\n10\n15\n20\n25\n30\n35\n40\n45\nCORRELATION 0.51±0.07 0.57±0.03 0.57±0.05 0.6±0.03 0.59±0.03 0.61±0.02 0.61±0.02 0.61±0.01 0.61±0.01\nTable 2: Rank correlations of the UDR score with the β-VAE metric on the dSprites dataset for a β-VAE\nhyperparameter search as the number of pairwise comparisons P per model were changed.\nUDR works well even with ﬁve pairwise comparisons.\nWe test the effect of the number of\npairwise comparisons P on the variance and accuracy of the UDR scores. Tbl. 2 reports the changes\nin the rank correlation with the β-VAE metric on the dSprites dataset as P is varied between 5 and 45.\nWe see that the correlation between the UDR and the β-VAE metric becomes higher and the variance\ndecreases as the number of seeds is increased. However, even with P =5 the correlation is reasonable.\nUDR generalises to a dataset with no attribute labels.\nWe investigate whether UDR can be useful\nfor selecting well disentangled models trained on the 3D Cars (Reed et al., 2014) dataset with poorly\nlabelled attributes, which makes it a bad ﬁt for supervised disentanglement metrics. Fig. 1 shows that\na highly ranked model according to UDR appears disentangled, while a poorly ranked one appears\nentangled. Fig. 10 in Supplementary Material provides more examples of high and low scoring models\naccording to the UDR method.\nUDR predicts ﬁnal task performance.\nWe developed UDR to help practitioners use disentangled\nrepresentations to better solve subsequent tasks. Hence, we evaluate whether the model ranking pro-\nduced by UDR correlates with task performance on two different domains: the fairness on a classiﬁca-\ntion task introduced by Locatello et al. (2018), and data efﬁciency on a clustering task for a model-based\nreinforcement learning agent introduced by Watters et al. (2019) (see Sec. A.8 in Supplementary Mate-\nrials for more details). We found that UDR had an average of 0.8 Spearman correlation with the fairness\nscores, which is higher than the average of 0.72 correlation between fairness and supervised scores\nreported by Locatello et al. (2018). We also found that UDR scores had 0.56 Spearman correlation with\ndata efﬁciency of the COBRA agent. The difference between the best and the worst models according\nto UDR amounted to around 66% reduction in the number of steps to 90% success rate on the task.\n6\nCONCLUSION\nWe have introduced UDR, the ﬁrst method for unsupervised model selection for variational\ndisentangled representation learning. We have validated our approach on 5400 models covering\nall six state of the art VAE-based unsupervised disentangled representation learning model classes.\nWe compared UDR to four existing supervised disentanglement metrics both quantitatively and\nqualitatively, and demonstrated that our approach works reliably well across three different datasets,\noften ranking models more accurately than the supervised alternatives. Moreover, UDR avoids one\nof the big shortcomings of the supervised disentangling metrics – the arbitrary choice of a “canonical”\ndisentangled factorisation, instead allowing any of the equally valid disentangled generative processes\nto be accepted. Finally, we also demonstrated that UDR is useful for predicting ﬁnal task performance\nusing two different domains. Hence, we hope that UDR can be a step towards unlocking the power\nof unsupervised disentangled representation learning to real-life applications.\nACKNOWLEDGEMENTS\nWe thank Olivier Bachem and Francesco Locatello for helping us re-use their code and model\ncheckpoints, and Neil Rabinowitz, Avraham Ruderman and Tatjana Chavdarova for useful feedback.\nREFERENCES\nAlessandro Achille, Tom Eccles, Loic Matthey, Christopher P Burgess, Nick Watters, Alexander Lerchner, and\nIrina Higgins. Life-long disentangled representation learning with cross-domain latent homologies. NIPS, 2018.\nYoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives.\nIEEE transactions on pattern analysis and machine intelligence, 35(8):1798–1828, 2013.\n9\nPublished as a conference paper at ICLR 2020\nJames Bergstra, Remi Bardenet, Yoshua Bengio, and Balazs Kegl. Algorithms for hyper-parameter optimization.\nNIPS, 2011.\nChris Burgess and Hyunjik Kim. 3d shapes dataset. https://github.com/deepmind/3dshapes-dataset/, 2018.\nChristopher P. Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, and Alexander\nLerchner. Understanding disentangling in β-VAE. NIPS Workshop of Learning Disentangled Features, 2017.\nChristopher P Burgess, Loic Matthey, Nick Watters, Rishabh Kabra, Irina Higgins, Matt Botvinick, and Alexander\nLerchner. MONet: Unsupervised scene decomposition and representation. arXiv preprint, January 2019.\nTian Qi Chen, Xuechen Li, Roger Grosse, and David Duvenaud. Isolating sources of disentanglement in\nvariational autoencoders. NIPS, 2018.\nTaco Cohen and Max Welling. Group equivariant convolutional networks. ICML, 2016.\nPierre Comon. Independent component analysis, a new concept? Signal Processing, 36:287–314, 1994.\nCian Eastwood and Christopher K. I. Williams. A framework for the quantitative evaluation of disentangled\nrepresentations. ICLR, 2018.\nLasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymyr Mnih, Tom Ward, Yotam Doron, Vlad\nFiroiu, Tim Harley, Iain Dunning, Shane Legg, and Koray Kavukcuoglu. IMPALA: Scalable distributed deep-rl\nwith importance weighted actor-learner architectures. arxiv, 2018.\nMarta Garnelo, Kai Arulkumaran, and Murray Shanahan. Towards deep symbolic reinforcement learning. arXiv\npreprint arXiv:1609.05518, 2016.\nRobert Gens and Pedro M. Domingos. Deep symmetry networks. NIPS, 2014.\nDavid R. Hardoon, Sandor Szedmak, and John Shawe-Taylor. Canonical correlation analysis; an overview with\napplication to learning methods. Neural Computation, 16(12):2639 – 2664, 2004.\nMatteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg Ostrovski, Will Dabney, Dan Horgan,\nBilal Piot, Mohammad Azar, and David Silver. Rainbow: Combining improvements in deep reinforcement\nlearning. arxiv, 2017.\nIrina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed,\nand Alexander Lerchner. β-VAE: Learning basic visual concepts with a constrained variational framework.\nICLR, 2017a.\nIrina Higgins, Arka Pal, Andrei Rusu, Loic Matthey, Christopher Burgess, Alexander Pritzel, Matthew Botvinick,\nCharles Blundell, and Alexander Lerchner. DARLA: Improving zero-shot transfer in reinforcement learning.\nICML, 2017b.\nIrina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey, Danilo Rezende, and Alexander\nLerchner. Towards a deﬁnition of disentangled representations. arXiv, 2018a.\nIrina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher Burgess, Matko Bosnjak, Murray Shanahan,\nMatthew Botvinick, Demis Hassabis, and Alexander Lerchner. SCAN: Learning hierarchical compositional\nvisual concepts. ICLR, 2018b.\nJie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks. CVPR, 2018.\nFrank Hutter, Holger Hoos, and Kevin Leyton-Brown. Sequential model-based optimization for general algorithm\nconﬁguration. Learning and Intelligent Optimization, 2011.\nMax Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M. Czarnecki, Jeff Donahue, Ali Razavi,\nOriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, Chrisantha Fernando, and Koray Kavukcuoglu.\nPopulation based training of neural networks. arXiv, 2018.\nHyunjik Kim and Andriy Mnih. Disentangling by factorising. ICLR, 2018.\nDiederik P. Kingma and Max Welling. Auto-encoding variational bayes. ICLR, 2014.\nNikolaus Kriegeskorte, Marieke Mur, and Peter Bandettini. Representational similarity analysis – connecting\nthe branches of systems neuroscience. Front Syst Neurosci., 4(2), 2008.\nAbhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. Variational inference of disentangled latent\nconcepts from unlabeled observations. arxiv, 2017.\n10\nPublished as a conference paper at ICLR 2020\nBrenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman. Building machines that\nlearn and think like people. Behavioral and Brain Sciences, pp. 1–101, 2016.\nGuillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marc’Aurelio Ranzato. Phrase-based\n& neural unsupervised machine translation. arxiv, 2018.\nAdrien Laversanne-Finot, Alexandre Péré, and Pierre-Yves Oudeyer. Curiosity driven exploration of learned\ndisentangled goal spaces. arxiv, 2018.\nYixuan Li, Jason Yosinski, Jeff Clune, Hod Lipson, and John Hopcroft. Convergent learning: Do different neural\nnetworks learn the same representations? ICLR, 2016.\nFrancesco Locatello, Stefan Bauer, Mario Lucic, Sylvain Gelly, Bernhard Schölkopf, and Olivier Bachem.\nChallenging common assumptions in the unsupervised learning of disentangled representations. ICML, 97:\n4114–4124, 2018.\nFrancesco Locatello, Gabriele Abbati, Tom Rainforth, Stefan Bauer, Bernhard Schölkopf, and Olivier Bachem.\nOn the fairness of disentangled representations. arxiv, 2019.\nGary Marcus. Deep learning: A critical appraisal. arxiv, 2018.\nEmile Mathieu, Tom Rainforth, N. Siddharth, and Yee Whye Teh. Disentangling disentanglement in variational\nautoencoders. ICML, 2019.\nLoic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner. dsprites: Disentanglement testing sprites\ndataset, 2017. URL https://github.com/deepmind/dsprites-dataset/.\nRisto Miikkulainen, Jason Liang, Elliot Meyerson, Aditya Rawal, Dan Fink, Olivier Francon, Bala Raju, Hormoz\nShahrzad, Arshak Navruzyan, Nigel Duffy, and Babak Hodjat. Evolving Deep Neural Networks. arxiv, 2017.\nAri S. Morcos, Maithra Raghu, and Samy Bengio. Insights on representational similarity in neural networks\nwith canonical correlation. NIPS, 2018.\nAshvin Nair, Vitchyr Pong, Murtaza Dalal, Shikhar Bahl, Steven Lin, and Sergey Levine. Visual reinforcement\nlearning with imagined goals. arxiv, 2018.\nAaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal\nKalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio. arXiv\npreprint arXiv:1609.03499, 2016.\nMaithra Raghu, Justin Gilmer, Jason Yosinski, and Jascha Sohl-Dickstein. Svcca: Singular vector canonical\ncorrelation analysis for deep learning dynamics and interpretability. NIPS, 2017.\nScott Reed, Kihyuk Sohn, Yuting Zhang, and Honglak Lee. Learning to disentangle factors of variation with\nmanifold interaction. ICML, 2014.\nDanilo J Rezende and Fabio Viola. Generalized elbo with constrained optimization, geco. Workshop on Bayesian\nDeep Learning, NeurIPS, 2018.\nDanilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate\ninference in deep generative models. ICML, 32(2):1278–1286, 2014.\nKarl Ridgeway and Michael C Mozer. Learning deep disentangled embeddings with the f-statistic loss. NIPS, 2018.\nMichal Rolinek, Dominik Zietlow, and Georg Martius. Variational autoencoders pursue pca directions (by\naccident). CVPR, 2019.\nJürgen Schmidhuber. Learning factorial codes by predictability minimization. Neural Computation, 4(6):\n863–869, 1992.\nDavid Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot,\nLaurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, and Demis Hassabis.\nA general reinforcement learning algorithm that masters chess, shogi, and go through self-play. Science, 362\n(6419):1140–1144, 2018. doi: 10.1126/science.aar6404.\nJ. Snoek, H. Larochelle, and R. P. Adams. Practical Bayesian Optimization of Machine Learning Algorithms.\narXiv, 2012.\nStefano Soatto. Steps toward a theory of visual information. Technical Report UCLA-CSD100028, 2010.\n11\nPublished as a conference paper at ICLR 2020\nXander Steenbrugge, Sam Leroux, Tim Verbelen, and Bart Dhoedt. Improving generalization for abstract\nreasoning tasks using disentangled feature representations. arxiv, 2018.\nRaphael Suter, Dorde Miladinovic, Stefan Bauer, and Bernhard Scholkopf. Interventional robustness of deep\nlatent variable models. arxiv, 2018.\nC. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown. Auto-WEKA: Combined Selection and Hyperparameter\nOptimization of Classiﬁcation Algorithms. arXiv, 2012.\nSjoerd van Steenkiste, Francesco Locatello, Jürgen Schmidhuber, and Olivier Bachem. Are disentangled\nrepresentations helpful for abstract visual reasoning? arxiv, 2019.\nLiwei Wang, Lunjia Hu, Jiayuan Gu, Yue Wu, Zhiqiang Hu, Kun He, and John Hopcroft. Towards understanding\nlearning representations: To what extent do different neural networks learn the same representation. NeurIPS,\n2018.\nNicholas Watters, Loic Matthey, Matko Bosnjak, Christopher P. Burgess, and Alexander Lerchner. Cobra: Data-\nefﬁcient model-based rl through unsupervised object discovery and curiosity-driven exploration. arxiv, 2019.\n12\nPublished as a conference paper at ICLR 2020\nA\nSUPPLEMENTARY MATERIAL\nA.1\nUSEFUL PROPERTIES OF DISENTANGLED REPRESENTATIONS\nDisentangled representations are particularly useful because they re-represent the information contained in the\ndata in a way that enables semantically meaningful compositionality. For example, having discovered that the\ndata is generated using two factors, colour and shape, such a model would be able to support meaningful reasoning\nabout ﬁctitious objects, like pink elephants, despite having never seen one during training (Higgins et al., 2017b;\n2018b). This opens up opportunities for counterfactual reasoning, more robust and interpretable inference and\nmodel-based planning (Higgins et al., 2018a; Suter et al., 2018). Furthermore, such a representation would support\nmore data efﬁcient learning for subsequent tasks, like a classiﬁcation objective for differentiating elephants from\ncats. This could be achieved by ignoring the nuisance variables irrelevant for the task, e.g. the colour variations,\nby simply masking out the disentangled subspaces that learnt to represent such nuisances, while only paying\nattention to the task-relevant subspaces, e.g. the units that learnt to represent shape (Cohen & Welling, 2016; Gens\n& Domingos, 2014; Soatto, 2010). Hence, the semantically meaningful compositional nature of disentangled\nrepresentations is perhaps the most sought after aspect of disentangling, due to its strong implications for\ngeneralisation, data efﬁciency and interpretability (Schmidhuber, 1992; Bengio et al., 2013; Higgins et al., 2018a).\nA.2\nASPECTS OF DISENTANGLEMENT MEASURED BY DIFFERENT METRICS\nMethods for evaluating and comparing representations have been proposed in the past. The most similar\napproaches to ours are the DCI Disentanglement score from Eastwood & Williams (2018) and the axis alignment\ncomparison of representations in trained classiﬁers proposed in Li et al. (2016). The former is not directly\napplicable for unsupervised disentangled model selection, since it requires access to the ground truth attribute\nlabels. Even when adapted to compare two latent representations, our preliminary experiments suggested that\nthe entropy based aggregation proposed in Eastwood & Williams (2018) is inferior to our aggregation in Eq. 2\nwhen used in the UDR setup. The approach by Li et al. (2016) shares the similarity matrix calculation step with\nus, however they never go beyond that quantitatively, opting for qualitative evaluations of model representations\ninstead. Hence, their approach is not directly applicable to quantitative unsupervised disentangled model ranking.\nOther related approaches worth mentioning are the Canonical Correlation Analysis (CCA) and its modiﬁcations\n(Hardoon et al., 2004; Raghu et al., 2017; Morcos et al., 2018). These approaches, however, tend to be invariant\nto invertible afﬁne transformations and therefore to the axis alignment of individual neurons, which makes them\nunsuitable for evaluating disentangling quality. Finally, Representation Similarity Matrix (RSM) (Kriegeskorte\net al., 2008) is a commonly used method in Neuroscience for comparing the representations of different systems\nto the same set of stimuli. This technique, however, is not applicable for measuring disentangling, because it\nignores dimension-wise response properties.\nWhen talking about disentangled representations, three properties are generally considered: modularity,\ncompactness and explicitness2 (Ridgeway & Mozer, 2018). Modularity measures whether each latent dimension\nencodes only one data generative factor, compactness measures whether each data generative factor is encoded by\na single latent dimension, and explicitness measures whether all the information about the data generative factors\ncan be decoded from the latent representation. We believe that modularity is the key aspect of disentangling,\nsince it measures whether the representation is compositional, which gives disentangled representations the\nmajority of their beneﬁcial properties (see Sec. A.1 in Supplementary Materials for more details). Compactness,\non the other hand, may not always be desirable. For example, according to a recent deﬁnition of disentangled\nrepresentations (Higgins et al., 2018a), it is theoretically impossible to represent 3D rotation in a single dimension\n(see also Ridgeway & Mozer (2018)). Finally, while explicitness is clearly desirable for preserving information\nabout the data that may be useful for subsequent tasks, in practice models often fail to discover and represent\nthe full set of the data generative factors due to restrictions on both the observed data distribution and the model\ncapacity (Mathieu et al., 2019). Hence, we suggest noting the explicitness of a representation, but not necessarily\npunishing its disentanglement ranking if it is not fully explicit. Instead, we suggest that the practitioner should\nhave the choice to select the most disentangled model given a particular number of discovered generative factors.\nHence, in the rest of the paper we will use the term “disentanglement” to refer to the compositional property\nof a representation related to the modularity measure. Tbl. 3 provides a summary of how the different metrics\nconsidered in the paper compare in terms of modularity, compactness and explicitness.\nA.3\nDATASET DETAILS\ndSprites\nA commonly used unit test for evaluating disentangling is the dSprites dataset (Matthey et al., 2017).\nThis dataset consists of images of a single binary sprite pasted on a blank background and can be fully described\nby ﬁve generative factors: shape (3 values), position x (32 values), position y (32 values), size (6 values) and\n2Similar properties have also been referred to as disentanglement, completeness and informativeness respec-\ntively in the independent yet concurrent paper by Eastwood & Williams (2018).\n13\nPublished as a conference paper at ICLR 2020\nTable 3: Disentangled model selection metrics comparison. M - modularity, C - compactness, E -\nexplicitness (Ridgeway & Mozer, 2018)\nMETRIC\nM C E\nβ-VAE\n√× √\nFACTORVAE\n√√√\nMIG\n√√√\nDCI DISENTANGLEMENT √× ×\nUDR\n√× ×\nrotation (40 values). All the generative factors are sampled from a uniform distribution. Rotation is sampled\nfrom the full 360 degree range. The generative process for this dataset is fully deterministic, resulting in 737,280\ntotal images produced from the Cartesian product of the generative factors.\n3D Shapes\nA more complex dataset for evaluating disentangling is the 3D Shapes dataset (Burgess & Kim,\n2018). This dataset consists of images of a single 3D object in a room and is fully speciﬁed by six generative\nfactors: ﬂoor colour (10 values), wall colour (10 values), object colour (10 values), size (8 values), shape (4 values)\nand rotation (15 values). All the generative factors are sampled from a uniform distribution. Colours are sampled\nfrom the circular hue space. Rotation is sampled from the [-30, 30] degree angle range.\n3D Cars\nThis dataset was adapted from Reed et al. (2014). The full data generative process for this dataset is\nunknown. Thelabelledfactorsinclude199carmodelsand24rotationssampledfromthefull360degreeoutofplane\nrotation range. An example of an unlabelled generative factor is the colour of the car – this varies across the dataset.\nA.4\nUNSUPERVISED DISENTANGLED REPRESENTATION LEARNING MODELS\nAs mentioned in Sec. 3, current state of the art approaches to unsupervised disentangled representation learning\nare based on the VAE (Kingma & Welling, 2014; Rezende et al., 2014) objective presented in Eq. 1. These\napproaches decompose the objective in Eq. 1 into various terms and change their relative weighting to exploit\nthe trade-off between the capacity of the latent information bottleneck with independent sources of noise, and the\nquality of the resulting reconstruction in order to learn a disentangled representation. The ﬁrst such modiﬁcation\nwas introduced by Higgins et al. (2017a) in their β-VAE framework:\nEp(x)[ Eqφ(z|x)[log pθ(x|z)]−β KL(qφ(z|x) || p(z)) ]\n(4)\nIn order to achieve disentangling in β-VAE, the KL term in Eq. 4 is typically up-weighted by setting β > 1.\nThis implicitly reduces the latent bottleneck capacity and, through the interaction with the reconstruction term,\nencourages the generative factors ck with different reconstruction proﬁles to be encoded by different independent\nnoisy channels zl in the latent bottleneck. Building on the β-VAE ideas, CCI-VAE (Burgess et al., 2017)\nsuggested slowly increasing the bottleneck capacity during training, thus improving the ﬁnal disentanglement\nand reconstruction quality:\nEp(x)[ Eqφ(z|x)[log pθ(x|z)]−γ |KL(qφ(z|x) || p(z))−C| ]\n(5)\nLater approaches (Kim & Mnih, 2018; Chen et al., 2018; Kumar et al., 2017) showed that the KL term in Eq. 1\ncan be further decomposed according to:\nEp(x)[ KL(qφ(z|x) || p(z)) ]=I(x;z)+KL(qφ(z) || p(z))\n(6)\nHence, penalising the full KL term as in Eqs. 4-5 is not optimal, since it unnecessarily penalises the mutual infor-\nmation between the latents and the data. To remove this undesirable side effect, different authors suggested instead\nadding more targeted penalised terms to the VAE objective function. These include different implementations\nof the total correlation penalty (FactorVAE by Kim & Mnih (2018) and TC-VAE by Chen et al. (2018)):\nLV AE−γ KL(qφ(z) ||\nM\nY\nj=1\nqφ(zj))\n(7)\nand different implementations of the penalty that pushes the marginal posterior towards a factorised prior\n(DIP-VAE by Kumar et al. (2017)):\nLV AE−γ KL(qφ(z) || p(z))\n(8)\nA.4.1\nMODEL IMPLEMENTATION DETAILS\nWe re-used the trained checkpoints from Locatello et al. (2018), hence we recommend the readers to check the\noriginal paper for model implementation details. Brieﬂy, the following architecture and optimiser were used.\n14\nPublished as a conference paper at ICLR 2020\nTable 4: Encoder and Decoder Implementation details shared for all models\nEncoder\nDecoder\nInput: 64 × 64 × number of channels Input: R10\n4 × 4 conv, 32 ReLU, stride 2\nFC, 256 ReLU\n4 × 4 conv, 32 ReLU, stride 2\nFC, 4 × 4 × 64 ReLU\n4 × 4 conv, 64 ReLU, stride 2\nFC, 4 × 4 upconv, 64 ReLU, stride 2\n4 × 4 conv, 64 ReLU, stride 2\nFC, 4 × 4 upconv, 32 ReLU, stride 2\nFC 256, F2 2 × 10\n4 × 4 upconv, 32 ReLU, stride 2\n4 × 4 upconv, number of channels, stride 2\nTable 5: Hyperparameters used for each model architecture\nModel\nParameters\nValues\nβ-VAE\nβ\n[1, 2, 4, 6, 8, 16]\nCCI-VAE\ncmax\n[5, 10, 25, 50, 75, 100]\niteration threshold 100000\nγ\n1000\nFactorVAE\nγ\n[10, 20, 30, 40, 50, 100]\nDIP-VAE-I λod\n[1, 2, 5, 10, 20, 50]\nλd\n10λod\nDIP-VAE-II λod\n[1, 2, 5, 10, 20, 50]\nλd\nλod\nTC-VAE\nβ\n[1, 2, 4, 6, 8, 10]\n(a) Common hyperparameters across all\nmodels\nParameter\nValues\nBatch Size\n64\nLatent space dimension 10\nOptimizer\nAdam\nAdam: beta1\n0.9\nAdam: beta2\n0.999\nAdam: epsilon\n1e-8\nAdam: learning rate\n0.0001\nDecoder type\nBernoulli\n(b) FactorVAE discrimina-\ntor architecture\nDiscriminator\nFC, 1000 leaky ReLU\nFC, 1000 leaky ReLU\nFC, 1000 leaky ReLU\nFC, 1000 leaky ReLU\nFC, 1000 leaky ReLU\nFC, 1000 leaky ReLU\nFC, 2\n(c) FactorVAE discriminator pa-\nrameters\nParameter\nValues\nBatch size\n64\nOptimizer\nAdam\nAdam: beta1\n0.5\nAdam: beta2\n0.9\nAdam: epsilon\n1e-8\nAdam: learning rate 0.0001\nTable 6: Miscellaneous model details\nFor consistency, all the models were trained using the same architecture, optimiser, and hyperparameters. All\nof the methods use a deep neural network to encode and decode the latent embedding and the parameters of\nthe latent factors are predicted using a Gaussian encoder whose architecture is speciﬁed in Table 4. All of the\nmodels predict a latent vector with 10 factors. Each model was also trained with 6 different levels of regularisation\nstrength speciﬁed in Table 5. The ranges of the hyperparameters used for the various levels of regularisation\nwere speciﬁed to show a diversity of different performance on different datasets without relying on pre-existing\nintuition on good hyperparameters, however ranges were based on hyperparameters that were used previously\nin literature. For each of the model classes outlined above, we tried 6 hyperparameter values with 50 seeds each.\nβ-VAE\nThe β-VAE (Higgins et al., 2017a) model is similar to the vanilla VAE model but with an additional\nhyperparameter β to modify the strength of the KL regulariser.\n15\nPublished as a conference paper at ICLR 2020\nEp(x)[ Eqφ(z|x)[log pθ(x|z)]−β KL(qφ(z|x) || p(z)) ]\n(9)\nwhere a β value of 1 corresponds to the vanilla VAE model. Increasing β enforces a stronger prior on the latent\ndistribution and encourages the representation to be independent.\nCCI-VAE\nThe CCI-VAE model (Burgess et al., 2017) is a variant of the β-VAE where the KL divergence\nis encouraged to match a controlled value C which is increased gradually throughout training. This yields us\nthe objective function for CCI-VAE.\nEp(x)[ Eqφ(z|x)[log pθ(x|z)]−β |KL(qφ(z|x) || p(z))−C| ]\n(10)\nFactorVAE\nFactorVAE (Kim & Mnih, 2018) speciﬁcally penalises the dependencies between the latent\ndimensions such that the “Total Correlation” term is targeted yielding a modiﬁed version of the β-VAE objective.\nEp(x)[ Eqφ(z|x)[log pθ(x|z)]−KL(qφ(z|x) || p(z)) ]\n−βKL(q(z)||\nY\nj\nq(zj))\n(11)\nThe “Total Correlation” term is intractable in this case so for FactorVAE, samples are used from both q(z|x)\nand q(z) as well as the density-ratio trick to compute an estimate of the “Total Correlation” term. FactorVAE uses\nan additional discriminator network to approximate the density ratio in the KL divergence. The implementation\ndetails for the discriminator network and its hyperparameters can be found in Table 5(b) and 5(c).\nTC-VAE\nThe TC-VAE model (Chen et al., 2018) which independently from FactorVAE has a similar objective\nKL regulariser which contains a “Total Correlation” term. In the case of TC-VAE the “Total Correlation” term\nis estimated using a biased Monte-Carlo estimate.\n(3) \nCreate MxP similarity \nmatrices, for each\ncalculate UDRij score\nUDR1 = 0.47\n(4) \nAggregate \nUDRij scores \nfor each of M models\nUDR2 = 0.72\nUDRM = 0.36\n(1) \nTrain M=HxS models\nHyper 1\nseed 1\nseed 2\nseed S\nHyper 2\nHyper H\n(2) \nSelect P models for \npairwise comparisons \nwith each of M models \n0.43\n0.87\n0.32\nModel i=1 of M\nj = 1\nj = 2\nj = P\nseed 1\nseed 2\nseed S\nseed 1\nseed 2\nseed S\nFigure 4: Schematic illustration of the UDR method. See details in text.\nDIP-VAE\nThe DIP-VAE model also adds regularisation to the aggregated posterior but instead an additional\nloss term is added to encourage it to match the factorised prior. Since the KL divergence is intractable, other\nmeasures of divergence are used instead. Covp(x)[µφ(x)] can be used, yielding the DIP-VAE-I objective\nEp(x)[ Eqφ(z|x)[log pθ(x|z)]−KL(qφ(z|x) || p(z)) ]\n−λod\nX\ni̸=j\n[Covp(x)[µφ(x)]]2\nij\n−λd\nX\ni\n([Covp(x)[µφ(x)]]ii−1)2\n(12)\n16\nPublished as a conference paper at ICLR 2020\nor Covqφ[z] is used instead yielding the DIP-VAE-II objective.\nEp(x)[ Eqφ(z|x)[log pθ(x|z)]−KL(qφ(z|x) || p(z)) ]\n−λod\nX\ni̸=j\n[Covqφ[z]]2\nij\n−λd\nX\ni\n([Covqφ[z]]ii−1)2\n(13)\nA.5\nUDR IMPLEMENTATION DETAILS\nSimilarity matrix\nTo compute the similarity matrix Rij we follow the approach of Li et al. (2016) and\nMorcos et al. (2018). For a given dataset X = {x1,x2,...,,xN} and a neuron a ∈{1,...,L} of model i\n(denoted as zi,a), we deﬁne zi,a to be the vector of mean inferred posteriors qi(zi|xi) across the full dataset:\nzi,a = (zi,a(x1),...,zi,a(xN)) ∈RN. Note that this is different from the often considered notion of a “latent\nrepresentation vector”. Here zi,a is a response of a single latent dimension over the entire dataset, not an entire\nlatent response for a single input. We then calculate the similarity between each two of such vectors zi,a and\nzj,b using either Lasso regression or Spearman’s correlation.\nLasso regression (UDRL)\nWe trained L lasso regressors to predict each of the latent responses zi,a from\nzj using the dataset of latent encodings Zi,a ={(zj,1,zi,a,1),...,(zj,N,zi,a,N)}. Each row in Rij(a) is then ﬁlled\nin using the weights of the trained Lasso regressor for zi,a. The lasso regressors were trained using the default\nScikit-learn multi-task lasso objective minw\n1\n2nsamples ||XW −Y ||2\nF ro+λ||W||21 where Fro is the Frobenius\nnorm: ||A||F ro =\nqP\nija2\nij and the l1l2 loss is computed as ||A||21 = P\ni\nqP\nja2\nij. λ is chosen using cross\nvalidation and the lasso is trained until convergence until either 1000 iterations have been run or our updates\nare below a tolerance of 0.0001. Lasso regressors were trained on a dataset of 10000 latents from each model\nand training was performed using coordinate descent over the entire dataset. Rnm is then computed by extracting\nthe weights in the trained lasso regressor and computing their absolute value (Eastwood & Williams, 2018). It\nis important that the representations are normalised per-latent such that the relative importances computed per\nlatent are scaled to reﬂect their contribution to the output. Normalising our latents also ensures that the weights\nthat are computed roughly lie in the interval [−1,1].\nSpearman’s based similarity matrix (UDRS)\nWe calculate each entry in the similarity matrix according\nto Rij(a,b)=Corr(zi,a,zj,b), where Corr stands for Spearman’s correlation. We use Spearman’s correlation to\nmeasure the similarity between zi,a and zj,b, because we do not want to necessarily assume a linear relationship\nbetween the two latent encodings, since the geometry of the representational space is not crucial for measuring\nwhether a representation is disentangled (see Sec. 2), but we do hope to ﬁnd a monotonic dependence between\nthem. Spearman correlation coefﬁcients were computed by extracting 1000 samples from each model and\ncomputing the Spearman correlation over all the samples on a per-latent basis.\nAll-to-all calculations\nTo make all-to-all comparisons, we picked 10 random seeds per hyperparameter\nsetting and limited all the calculations to those models. Hence we made the maximum of (60 choose 2) pairwise\nmodel comparisons when calculating UDR-A2A.\nInformative latent thresholding\nUninformative latents typically have KL≪0.01 while informative latents\nhave KL≫0.01, so KL=0.01 threshold in Eq. 3 is somewhat arbitrarily chosen to pick out the informative latents z.\nSample reduction experiments\nWe randomly sampled without replacement 20 different sets of P models\nfor pairwise comparison from the original set of 50 models with the same hyperparameter setting for UDR or\n60 models with different seeds and hyperparameters for UDR-A2A.\nA.6\nSUPERVISED METRIC IMPLEMENTATION DETAILS\nOriginal β-VAE metric.\nFirst proposed in Higgins et al. (2017a), this metric suggests sampling two batches\nof observations x where in both batches the same single data generative factor is ﬁxed to a particular value, while\nthe other factors are sampled randomly from the underlying distribution. These two batches are encoded into\nthe corresponding latent representations qφ(z|x) and the pairwise differences between the corresponding mean\nlatent values from the two batches are taken. Disentanglement is measured as the ability of a linear classiﬁer\nto predict the index of the data generative factor that was ﬁxed when generating x.\nWe compute the β-VAE score by ﬁrst randomly picking a single factor of variation and ﬁxing the value of that\nfactor to a randomly sampled value. We then generate two batches of 64 where all the other factors are sampled\n17\nPublished as a conference paper at ICLR 2020\nrandomly and take the mean of the differences between the latent mean responses in the two batches to generate a\ntraining point. This process is repeated 10000 times to generate a training set by using the ﬁxed factor of variation\nas the label. We then train a logistic regression on the data using Scikit-learn and report the evaluation accuracy\non a test set of 5000 as the disentanglement score.\nFactorVAE metric.\nKim & Mnih (2018) proposed a modiﬁcation on the β-VAE metric which made the\nclassiﬁer non-parametric (majority vote based on the index of the latent dimension with the least variance after the\npairwise difference step). This made the FactorVAE metric more robust, since the classiﬁer did not need to be\noptimised. Furthermore, the FactorVAE metric is more accurate than the β-VAE one, since the β-VAE metric often\nover-estimates the level of disentanglement by reporting 100% disentanglement even when only K−1 factors\nwere disentangled.\nThe Factor VAE score is computed similarly to the β-VAE metric but with a few modiﬁcations. First we draw\na set of 10000 random samples from the dataset and we estimate the variance of the mean latent responses in\nthe model. Latents with a variance of less than 0.05 are discarded. Then batches of 64 samples are generated\nby a random set of generative factors with a single ﬁxed generative factor. The variances of all the latent responses\nover the 64 samples are computed and divided by the latent variance computed in the ﬁrst step. The variances\nare averaged to generate a single training point using the ﬁxed factor of variation as the label. 10000 such training\npoints are generated as the training set. A majority vote classiﬁer is trained to pick out the ﬁxed generative factor\nand the evaluation accuracy is computed on test set of 5000 and reported as the disentanglement score.\nVAE 1\nVAE M\nTrained \nmodel pool\nzj\n1\n2\nL\nzi\n1\n2\nL\nSpearman\nLasso\nEntangled\nDisentangled\nA\nC\nB\nx\ny\ns\nx\ny\nFigure 5: A: Schematic illustration of the pairwise model comparison. Two trained models i and j are\nsampled for pairwise comparison. Both models learnt a perfectly disentangled representation, learning\nto represent two (positions x/y) and three (positions x/y, and size) generative factors respectively.\nSimilarity matrix Rij: white – high similarity between latent dimensions, black – low. B: Similarity\nmatrix Rij for the same pair of models, calculated using either Spearman correlation or Lasso regression.\nThe latter is often cleaner. C: Examples of Lasso similarity matrices of an entangled vs a disentangled\nmodel.\nMutual Information Gap (MIG).\nThe MIG metric proposed in Chen et al. (2018) proposes estimating\nthe mutual information (MI) between each data generative factor and each latent dimension. For each factor,\nthey consider two latent dimensions with the highest MI scores. It is assumed that in a disentangled representation\nonly one latent dimension will have high MI with a single data generative factor, and hence the difference between\nthese two MI scores will be large. Hence, the MIG score is calculated as the average normalised difference\nbetween such pairs of MI scores per each data generative factor. Chen et al. (2018) suggest that the MIG score\nis more general and unbiased than the β-VAE and FactorVAE metrics.\nWe compute the Mutual Information Gap by taking the discretising the mean representation of 10000 samples into\n20 bins. The disentanglement score is then derived by computing, per generative factor, the difference between\nthe top two latents with the greatest mutual information with the generative factor and taking the mean.\n18\nPublished as a conference paper at ICLR 2020\nTable 7: Rank correlations between each of the scores produced by the four versions of UDR and four\nsupervised metrics. The scores are averaged over three model classes, two datasets and four supervised\nmetrics. See Supplementary Material for details.\nUDR\nLASSO\nSPEARMAN SUPERVISED\nHYPER\n0.54±0.06 0.53±0.07\n0.67±0.2\nALL-TO-ALL 0.60±0.11 0.59±0.10\n1\nK\nK\nX\nk=1\n1\nHvk\n\u0010\nI(z(k)\nj\n)−max\nj̸=jkI(zj,vk)\n\u0011\n(14)\nwhere K is the number of generative factors, from which vk is a single generative factor zj is the mean\nrepresentation and j(k) = argmaxjIn(zj;vk) is the latent representation with the greatest mutual information\nwith the generative factor. Hvk is the computed entropy of the generative factor.\nDCI Disentanglement.\nThis is the disentanglement part of the three-part metric proposed by Eastwood &\nWilliams (2018). The DCI disentanglement metric is somewhat similar to our unsupervised metric, whereby the\nauthors train a random forest classiﬁer to predict the ground truth factors from the corresponding latent encodings\nq(z|x). They then use the resulting M ×N matrix of feature importance weights to calculate the difference\nbetween the entropy of the probability that a latent dimension is important for predicting a particular ground\ntruth factor weighted by the relative importance of each dimension.\nThe DCI disentanglement metric is an implementation of the disentanglement metric as described in Eastwood &\nWilliams (2018) using a gradient boosted tree. It was computed by ﬁrst extracting the relative importance of each\nlatent mean representation as a predictor for each generative factor by training a gradient boosted tree using the de-\nfault Scikit-learn model on 10000 training and 1000 test points and extracting the importance weights. The weights\nare summarised into an importance matrix Rij with the number of rows equal to the number of generative factors\nand columns equal to the number of latents. The disentanglement score for each column is computed as Di =(1−\nHK(Pi)) where HK(Pi)=−PK−1\nk=0 PiklogKPik denotes the entropy. Pik =Rij/PK−1\nk=0 is the probability of the\nlatentfactoriinbeingimportantforpredictingfactork. Theweightedmeanofthescoresforthecolumniscomputed\nusing the relative predictive importance of each column as the weight D=P\nipi∗Di where pi =P\njRij/P\nijRij.\nA.7\nADDITIONAL RESULTS\nWe evaluated four UDR versions, which differed in terms of whether Spearman- and Lasso-based similarity\nmatrices Rij were used (subscripts S and L respectively), and whether the models for pairwise similarity\ncomparison are picked from the pool of different seeds trained with the same hyperparameters or from the pool\nof all models (the latter indicated by the A2A sufﬁx). The A2A correlations in Tbl. 7 are on average slightly higher,\nhowever these scores are more computationally expensive to compute due to the higher number of total pairwise\nsimilarity calculations. For that reason, the scores presented in the table are calculated using only 20% of all\nthe trained models. Hence, the results presented in the main text of the paper are computed using the UDRL score,\nwhich allowed us to evaluate all 5400 models and performed slightly better than the UDRS score. Figs. 6-8 provide\nmore details on the performance of the different UDR versions.\nTo qualitatively validate that the UDR method is ranking models well, we look into more detail into the β-VAE\nmodel ranking when evaluated with the DCI disentanglement metric on the dSprites dataset. This scenario resulted\nin the worst disagreement between UDR and the supervised metric as shown in Fig. 6. We consider the UDRL\nversion of our method, since it appears to give the best trade off between overall correlations with the supervised\nmetrics and hyperparameter selection accuracy. Fig. 9 demonstrates that the poor correlation between UDRL\nand DCI Disentanglement is due to the supervised metric. Models ranked highly by UDRL but poorly by DCI\nDisentanglement appear to be qualitatively disentangled through visual inspection of latent traversals. Conversely,\nmodels scored highly by DCI Disentanglement but poorly by UDRL appear entangled.\nA.8\nUDR CORRELATION WITH FINAL TASK PERFORMANCE\nTo illustrate the usefulness of UDR to select disentangled models, we ran two experiments. We computed the\nUDR correlation with fairness scores and with data efﬁciency on a model-based RL task.\nFairness scores.\nFig. 11 (left) demonstrates that UDR correlates well with the classiﬁcation fairness scores\nintroduced by Locatello et al. (2019). We adopted a similar setup described in Locatello et al. (2019) to compute fair-\nness, using a gradient booting classiﬁer over 10000 labelled examples. The fairness score was computed by taking\n19\nPublished as a conference paper at ICLR 2020\nLasso\nSpearman\nHyper\nAll-to-all\nFigure 6: Rank correlation between different versions of UDR with different supervised metrics across\ntwo datasets and three model classes. We see that the UDRL approaches slightly outperform the UDRS\nones.\nthe mean of the fairness scores across all targets and all sensitive variables where the fairness scores are computed\nby measuring the total variation after intervening on the sensitive variable. The fairness scores were compared\nagainst the Lasso regression version of UDR where models were paired only within the same hyperparameters.\nModel-based RL data efﬁciency.\nWe reproduced the results from the COBRA agent (Watters et al., 2019),\nto observe if UDR would correlate with the ﬁnal tasks performance when using VAEs as state representations. More\nprecisely, we will look at the training data efﬁciency, reported as the number of steps needed to achieve 90% perfor-\nmance on the Clustering tasks (see Watters et al. (2019) for details), while using differently disentangled models.\nThe agent is provided with a pre-trained MONet (Burgess et al., 2019), an exploration policy and a transition\nmodel and has to learn a good reward predictor for the task in a dense reward setting. It uses Model Predictive\nControl in order to plan and solve the task, where sprites have to be clustered by color (e.g. two blue sprites and\ntwo red sprites). In COBRA, the authors use a MONet with disentangled representation by using a high β =1.\nWhen pre-training MONet, we used β ∈{0.01,0.1,1} in order to introduce entanglement in the representations\nwithout compromising reconstruction accuracy and pre-trained 10 seeds for each value of β. We use 5 random\ninitialisations of the reward predictor for each possible MONet model, and train them to perform the clustering\ntask as explained in Watters et al. (2019). We report the number of steps to reach 90% success, averaged across\nthe initialisations. The UDR score is computed by feeding images with a single sprite to obtain an associated\nunique representation and proceeding as described in the main text.\nAs can be seen in Figure 11 (right), we ﬁnd that the UDR scores correlate with this ﬁnal data efﬁciency (linear\nregression shown, Spearman correlation ρ = 0.56). This indicates that one could leverage the UDR score as a\nmetric to select representations for further tasks. In this analysis we used the version of UDR that uses Spearman\ncorrelations and within-hyperparameter model comparisons.\nA.9\nEVALUATING UDR ON MORE COMPLEX DATASETS\nWe evaluated whether UDR is useful for model selection on more complex datasets. In particular, we chose\nCelebA and ImageNet. While disentangling VAEs have been shown to perform well on CelebA in the past\n(e.g. Higgins et al. (2018b)), ImageNet is notoriously too complex for even vanilla VAEs to model. However,\nwe still wanted to verify whether the coarse representations of VAEs on ImageNet could be disentangled, and\nif so, whether UDR would be useful for model selection. To this end, we ran a hyperparameter sweep for the\nβ-VAE and ranked its representations using UDR. Fig. 12 shows that UDR scores are clearly different for the\ndifferent values of the β hyperparameter. It is also clear that the models were able to learn about CelebA and\nproduce reasonable reconstructions, but on ImageNet even the vanilla VAEs struggled to represent anything but\nthe coarsest information. Figs. 13-14 plot latent traversals for three randomly chosen models with high (>0.6) and\nlow (<0.3) UDR scores. The latents are sorted by their informativeness, as approximated by their batch-averaged\nper dimension KL with the prior as per Eq. 3. It is clear that for both datasets those models that are ranked high\nby the UDR have both more interpretable and more similar representations than those models that are ranked low.\n20\nPublished as a conference paper at ICLR 2020\ndSprites\nShapes 3D\nScore\nβ-VAE\nUDRL\nUDRS\nUDRL-A2A\nUDRS-A2A\nDIP-VAE\nUDRL\nUDRS\nUDRL-A2A\nUDRS-A2A\nTC-VAE\nUDRL\nUDRS\nUDRL-A2A\nUDRS-A2A\nScore\nβ-VAE\nUDRL\nUDRS\nUDRL-A2A\nUDRS-A2A\nDIP-VAE\nUDRL\nUDRS\nUDRL-A2A\nUDRS-A2A\nTC-VAE\nUDRL\nUDRS\nUDRL-A2A\nUDRS-A2A\nFigure 7: The range of scores for each hyperparameter setting for the dSprites and 3D Shapes datasets\nfor various models and metrics. We see that the different versions of the UDR method broadly agree\nwith each other.\nA.10\nQUALITATIVE EVALUATION OF MODEL REPRESENTATIONS RANKED BY UDR SCORES\nIn this section we attempt to qualitatively verify our assumption that “for a particular dataset and a VAE-based un-\nsupervised disentangled representation learning model class, disentangled representations are all alike, while every\nentangled representation is entangled in its own way, to rephrase Tolstoy”. The theoretical justiﬁcation of the pro-\nposed UDR hinges on the work by Rolinek et al. (2019). However, that work only empirically evaluated their analy-\nsis on the β-VAE model class. Even though we have reasons to believe that their theoretical results would also hold\nfor the other disentangling VAEs evaluated in this paper, in this section we empirically evaluate whether this is true.\nFirst, we check if all model classes operate in the so called “polarised regime”, which was highlighted by Rolinek\net al. (2019) as being important for pushing VAEs towards disentanglement. It is known that even vanilla VAEs\n(Kingma & Welling, 2014; Rezende et al., 2014) enter the “polarised regime”, which is often cited as one of their\nshortcomings (e.g. see Rezende & Viola (2018)). All of the disentangling VAEs considered in this paper augment\nthe original ELBO objective with extra terms. None of these extra terms penalise entering the “polarised regime”,\napart from that of DIP-VAE-I. We tested empirically whether different model classes entered the “polarised\nregime” during our hyperparameter sweeps. We did this by counting the number of latents that were “switched\noff” in each of the 5400 models considered in our paper by using Eq. 3. We found that all models apart from\nDIP-VAE-I entered the polarised regime during the hyperparameter sweep, having on average 2.95/10 latents\n“switched off” (with a standard deviation of 1.97).\nSecond, we check if the models scored highly by the UDR do indeed have similar representations, and models\nthat are scored low have dissimilar representations. We do this qualitatively by plotting latent traversals for\nthree randomly chosen models within each of the six disentangling VAE model classes considered in this paper.\n21\nPublished as a conference paper at ICLR 2020\nLasso\nSpearman\nHyper\nAll-to-all\n# of comparisons\n# of comparisons\n# of comparisons\n# of comparisons\nFigure 8: Rank correlations of the different versions of the UDR score with the β-VAE metric on\nthe dSprites dataset for a β-VAE hyperparameter search as the number of pairwise comparisons per\nmodel were changed. Higher number of comparisons leads to more accurate and more stable rankings,\nhowever these are still decent even with 5 pairwise comparisons per model.\nWe groups these plots by UDR scores into three bands: high (UDR>0.4), medium (0.3<UDR<0.4) and low\n(UDR<0.3). Fig. 15 shows latent traversals for all model classes that were able to achieve the high range of\nUDR scores (note that some model classes were not able to achieve high UDR values with the hyperparameter\nsettings evaluated in this paper). We present the latent traversals for all ten latents per model without sorting\nthem in any particular way. We also colour code the latents by their semantic meaning (if the meaning is apparent\nfrom the latent traversal). Fig. 15 shows that the representations learnt by the highly ranked models all appear\nto be very similar (up to subsetting, sign inverse and permutation). Note that the models also include many latents\nthat are “switched off”. Fig. 16 shows latent traversals for two model classes that did not achieve high UDR scores.\nWe see that these models now have fewer semantically meaningful latent dimensions, and fewer latents that are\nuninformative or “switched off”. Finally, Fig. 17 shows latent traversals for all model classes that had models\nwhich scored low on UDR. We see that many of these models do not have any uninformative latents, and their\nrepresentations are hard to interpret. Furthermore, it is hard to ﬁnd similarity between the representations learnt\nby the different models. Together, Figs. 15-17 empirically verify that our assumption holds for the model classes\nconsidered in this paper. However, we recommend that any practitioner using UDR on new disentangling model\nclasses developed in the future ﬁrst verify that the assumptions of the UDR hold for those models. We suggest\ntraining the new models on a number of toy but well studied datasets (like dSprites or Shapes3D) and checking\nif the ranks produced by UDR correlate with those produced by the supervised metrics. Furthermore, we suggest\na qualitative evaluation of the traversals plots for the high and low scoring models.\n22\nPublished as a conference paper at ICLR 2020\nby hyperparameter value \nby informative latents # \n1\n2\n4\n6\n3\n5\n-3\n3\nz1\nz10\n-3\n3\n-3\n3\n-3\n3\n-3\n3\n-3\n3\nz1\nz10\nFigure 9: Example latent traversals of some of the best and worst ranked β-VAE models using the\nUDRL (ordinate) and DCI Disentanglement (abscissa) metrics, coloured either by hyperparameter\nvalue (top) or ﬁnal informative latent number (bottom). Uninformative units are greyed out. The\nmodels ranked highly by UDRL do appear to be well disentangled, despite being ranked poorly by\nDCI Disentanglement (1, 2, 4). On the other hand, models ranked well by DCI Disentanglement but\npoorly by UDRL look quite entangled (5, 6). Finally, models ranked poorly by both metrics do appear\nentangled (3).\n23\nPublished as a conference paper at ICLR 2020\nUDR = 0.806\nd = 7\nUDR = 0.204\nd = 10\nUDR = 0.148\nd = 10\nUDR = 0.589\nd = 6\nz1\nz10\n-3\n3\nUDR = 0.165\nd = 9\nz1\nz10\n-3\n3\nUDR = 0.579\nd = 5\nz1\nz10\n-3\n3\nz1\nz10\n-3\n3\nz1\nz10\n-3\n3\nz1\nz10\n-3\n3\nFigure 10: Example latent traversals of some of the best and worst ranked β-VAE models using the\nUDRL scores. Uninformative latents are greyed out.\nFigure 11: Left: Spearman correlation between UDR scores and classiﬁcation fairness scores intro-\nduced by Locatello et al. (2019) across sixty models trained per each one of the three different model\nclasses (rows) and over two datasets (columns). Right: Spearman correlation between UDR scores and\ndata efﬁciency for learning a clustering task by the COBRA agent introduced by Watters et al. (2019).\nLower step number is better.\n24\nPublished as a conference paper at ICLR 2020\nInput\nReconstruction\nInput\nReconstruction\nFigure 12: Distribution of UDRS scores (P=50) for 300 β-VAE models trained with 6 settings of the β\nhyperparameter and 50 seeds on CelebA and ImageNet datasets. The reconstructions shown are for the\nvanilla VAE (β =1). ImageNet is a complex dataset that VAEs struggle to model well.\nLatent\nTraversal\nLatent\nTraversal\nUDR > 0.6\nUDR < 0.3\nFigure 13: Latent traversals for the four most informative latents ordered by their KL from the prior\nfor three different β-VAE models that ranked high or low according to UDR. Those models that were\nranked high have learnt representations that are both interpretable and very similar across models.\nThose models that were ranked low have learnt representations that are harder to interpret and they do\nnot appear similar to each other across models.\n25\nPublished as a conference paper at ICLR 2020\nLatent\nTraversal\nLatent\nTraversal\nUDR > 0.6\nUDR < 0.3\nFigure 14: Latent traversals for the six most informative latents ordered by their KL from the prior for\nthree different β-VAE models that ranked high or low according to UDR. Despite the fact that none of\nthe β-VAE or VAE models were able to learn to reconstruct this dataset well, those models that were\nranked high by the UDR still managed to learn representations that are more interpretable and more\nsimilar across models. This is unlike the representations of those models that were ranked low by the\nUDR.\n26\nPublished as a conference paper at ICLR 2020\nLatent\nTraversal\nLatent\nTraversal\nLatent\nTraversal\nβ-VAE\nTC-VAE\nCCI-VAE\nPosition x\nPosition y\nSize\nRotation\nEntangled\nUninformative\nUDR > 0.4\nFigure 15: Latent traversals for all ten latent dimensions presented in no particular ordering for three\ndifferent models per model class. These models were ranked highly by the UDR. It can be seen that\nthey learnt interpretable and similar representations up to permutation, sign inverse and subsetting. We\nincluded all model classes that achieved UDR scores in the range speciﬁed (UDR > 0.4).\n27\nPublished as a conference paper at ICLR 2020\nLatent\nTraversal\nLatent\nTraversal\nFactor VAE\nDIP-VAE-II\nPosition x\nPosition y\nSize\nRotation\nEntangled\nUninformative\n0.3 < UDR < 0.4\nFigure 16: Latent traversals for all ten latent dimensions presented in no particular ordering for three\ndifferent models per model class. These models received medium UDR scores. It can be seen that they\nlearnt less interpretable and less similar representations than the models shown in Fig. 15. None of the\nmodels in these model classes scored higher than the range speciﬁed (0.3 < UDR < 0.4).\n28\nPublished as a conference paper at ICLR 2020\nLatent\nTraversal\nLatent\nTraversal\nLatent\nTraversal\nβ-VAE\nTC-VAE\nFactor VAE\nLatent\nTraversal\nDIP-VAE-I\nLatent\nTraversal\nDIP-VAE-II\nPosition x\nPosition y\nSize\nRotation\nEntangled\nUninformative\nUDR < 0.3\nFigure 17: Latent traversals for all ten latent dimensions presented in no particular ordering for three\ndifferent models per model class. These models received low UDR scores. It can be seen that their\nrepresentations are hard to interpret and they look quite different from each other. We included all\nmodel classes that achieved UDR scores in the range speciﬁed (UDR < 0.3).\n29\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2019-05-29",
  "updated": "2020-02-14"
}