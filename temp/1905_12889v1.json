{
  "id": "http://arxiv.org/abs/1905.12889v1",
  "title": "Unsupervised pre-training helps to conserve views from input distribution",
  "authors": [
    "Nicolas Pinchaud"
  ],
  "abstract": "We investigate the effects of the unsupervised pre-training method under the\nperspective of information theory. If the input distribution displays multiple\nviews of the supervision, then unsupervised pre-training allows to learn\nhierarchical representation which communicates these views across layers, while\ndisentangling the supervision. Disentanglement of supervision leads learned\nfeatures to be independent conditionally to the label. In case of binary\nfeatures, we show that conditional independence allows to extract label's\ninformation with a linear model and therefore helps to solve under-fitting. We\nsuppose that representations displaying multiple views help to solve\nover-fitting because each view provides information that helps to reduce\nmodel's variance. We propose a practical method to measure both disentanglement\nof supervision and quantity of views within a binary representation. We show\nthat unsupervised pre-training helps to conserve views from input distribution,\nwhereas representations learned using supervised models disregard most of them.",
  "text": "Unsupervised pre-training helps to conserve views from input\ndistribution\nNicolas Pinchaud\nnicolas.pinchaud@gmail.com\nAbstract\nWe investigate the eﬀects of the unsupervised\npre-training method under the perspective of\ninformation theory.\nIf the input distribu-\ntion displays multiple views of the supervi-\nsion, then unsupervised pre-training allows to\nlearn hierarchical representation which com-\nmunicates these views across layers, while\ndisentangling the supervision.\nDisentangle-\nment of supervision leads learned features to\nbe independent conditionally to the label. In\ncase of binary features, we show that condi-\ntional independence allows to extract label’s\ninformation with a linear model and there-\nfore helps to solve under-ﬁtting.\nWe sup-\npose that representations displaying multiple\nviews help to solve over-ﬁtting because each\nview provides information that helps to re-\nduce model’s variance. We propose a practi-\ncal method to measure both disentanglement\nof supervision and quantity of views within\na binary representation. We show that unsu-\npervised pre-training helps to conserve views\nfrom input distribution, whereas representa-\ntions learned using supervised models disre-\ngard most of them.\n1. Introduction\nIn the context of classiﬁcation problem, we want to\nlearn a conditional distribution P(Y |X) of two ran-\ndom variables : X the input vector, and Y the label.\nTo solve this, a data set D of samples from the joint\ndistribution P(X, Y ) is provided. The goal is to learn\na model P(Y |X, θ) of the true distribution, where θ\nrepresents its parameters. The deep learning approach\nproposes to learn an intermediate representation H of\nX using a hierarchy H(1), ..., H(L−1), H(L) of random\nAppearing in Proceedings of the 29 th International Confer-\nence on Machine Learning, Edinburgh, Scotland, UK, 2012.\nCopyright 2012 by the author(s)/owner(s).\nvectors, where H = H(L), such that we have the fol-\nlowing factorization :\nP(H(1), ..., H(L−1), H|X) =\nP(H|H(L−1)) × ... × P(H(1)|X)\n(1)\nThis form allows to easily and eﬃciently sample\nP(H|X) by successively sampling each factor. Using\nthe intermediate representation H may allow to eas-\nily learn a model of P(Y |H) and then get P(Y |X) by\ncomposition : P(Y, H|X) = P(Y |H)P(H|X).\nThis\nprocess may be more successful than directly learn\na model of P(Y |X), especially if we know how to\nget good representations. A popular method, intro-\nduced by (Hinton et al., 2006) and (Bengio et al.,\n2007), is to learn P(H|X) by greedily stacking factors\nP(H(l+1)|H(l)) learned using unsupervised models like\nRBMs (Welling et al., 2004) or auto-encoders (Vin-\ncent et al., 2008) or variations of them (Rifai et al.,\n2011)(Ranzato et al., 2010). Why does this method\ngive rise to distribution H that helps to solve the su-\npervised problem ?\nThe reasons remain mainly un-\nclear. It has been shown that stacking RBMs is equiv-\nalent to learn a deep generative model of data (Hinton\net al., 2006). The intuition is that knowledge of how\nthe data behave allows to deduce the label easily since\nit is just one of the aspects of this behavior. Other\nworks suggest that this method act as a regularization\nhelping to ﬁnd model’s parameters that generalize well\n(Erhan et al., 2010), or show that it helps to learn in-\nvariant features (Goodfellow et al., 2009). We propose\nan approach by an information theoretic (Shannon,\n1948) analysis of features obtained with unsupervised\npre-training. Deep learning usually deals with input\ndistributions that are high dimensional random vec-\ntors. These distributions are likely to display infor-\nmation about supervision in multiple ways. For ex-\nample there may exist various subsets of components\nfrom the vector that provide full information about\nlabels. These views can be helpful for generalization\nas they provide information that may help to deter-\nmine the parameters of the model. Experiments show\nthat supervised approaches naively try to disentangle\nthe supervision without concern about preservation\narXiv:1905.12889v1  [cs.LG]  30 May 2019\nUnsupervised pre-training helps to conserve views from input distribution\nof these views.\nOn the contrary, unsupervised pre-\ntraining does both, disentanglement of supervision and\npreservation of views. Disentanglement of supervision\nis related to features being independent conditionally\nto the supervision Y . If H is binary, we show that\na conditional independence with Y enables to model\nP(Y |H) with a linear model.\nThe paper is organized as follows. We ﬁrst deﬁne our\nframework in section 2. Section 3 relates conditional\nindependence with disentanglement of supervision in\nthe case of binary features. In section 4 we propose\nto deﬁne a measure of relevance of views contained\nin representations using information interaction. The\nsection 5 deﬁnes a practical method to measure both\nconditional independence of components and view rel-\nevance. Finally, experiments are presented in section\n6.\n2. Framework and Notations\nA deep representation (1) is trained by greedily stack-\ning simpler learning modules. We start by learning the\nparameters θ(1) of the ﬁrst one P(H(1)|X, θ(1)), which\nis then used to train the next one P(H(2)|H(1), θ(2)),\nand so on. We abstract the notation of a module with\nthe parametrized distribution P(B|V, θ), where (B, V )\nis instantiated with corresponding pair1 (H(l), H(l−1)).\nWe suppose that layers are binary, B ∈{0, 1}m. We\nnote Bi, the ith component of B. We note Πn the set\nof subsets of components of B of size n, and Πi\nn the\nset of subsets of components of B of size n that do\nnot contain Bi. We note H(.) and I(., .) the Shannon\nentropy and the mutual information. We suppose that\nthe inference of B is easy by assuming that :\nP(B|V, θ) =\nY\ni\nP(Bi|V, θ)\n(2)\nWe suppose that Y is a discrete random variable.\n3. Supervision disentanglement as\nconditional independence\nIn this section we relate disentanglement of Y with\nindependence of components of B conditionally to Y\nby pointing out that the latter enables classes to be\nlinearly separable. This is shown by the following the-\norem :\nTheorem 3.1 Let Y be a discrete random variable\ntaking values in Y, let B be a binary random vector\ntaking values in {0, 1}m.\nIf H(Y |B) = 0, and if components of B are indepen-\n1With H(0) = X\ndent conditionally to Y , then for all classes yn ∈Y\nso that P(yn) > 0, there exists a vector µ(n) ∈Rm+1\nsuch that ∀b, P(B = b) ̸= 0 we have :\n(b0, ..., bm−1, 1).µ(n) > 0 ⇔P(yn|b) = 1\nThe underlying idea of the proof is that if we have con-\nditional independence, then for each class yn values of\nB|yn are restricted to a sub-hypercube of {0, 1}m such\nthat there is no intersection between sub-hypercubes\nof diﬀerent classes. This allows to ﬁnd hyper-planes\nthat separate them.\nBefore proving the theorem, we introduce several lem-\nmas. We suppose that hypotheses H(Y |B) = 0 and\nP(B|Y ) = Q\ni P(Bi|Y ) (conditional independence of\ncomponents) are satisﬁed.\nLet yn ∈Y so that P(Y = yn) > 0, we note :\nBn = {b ∈{0, 1}m, P(b|yn) ̸= 0}\nLemma 3.2 Let yn ∈Y so that P(Y = yn) > 0, let\nyl ∈Y so that P(Y = yl) > 0 and yl ̸= yn, then\nBn ∩Bl = ∅\nProof by contradiction : Suppose ∃b ∈Bn ∩Bl, then\nwe have P(b|yn) > 0 and P(b|yl) > 0. By the Bayes\ntheorem and because P(b) > 0, P(yn) > 0, P(yl) > 0,\nwe can write :\nP(b|yn) > 0 ⇒P(yn|b) > 0\nP(b|yl) > 0 ⇒P(yl|b) > 0\nSince we suppose that H(Y |B) = 0, then ∃!y, P(y|b) =\n1, so ∀˜y ̸= y, P(˜y|b) = 0. We deduce that P(yn|b) =\nP(yl|b) = 1, and then yn = yl which contradicts the\nhypothesis yn ̸= yl □\nLet B =\nS\nyn∈Y,P (yn)>0\nBn\nLemma 3.3 We have\nB = {b ∈{0, 1}m, P(B = b) > 0}\nProof : Let ˆb ∈B, then ∃yn ∈Y, P(yn) > 0,ˆb ∈Bn.\nTherefore P(ˆb|yn) > 0, which implies that p(ˆb) > 0,\nthen ˆb ∈{b ∈{0, 1}m, P(B = b) > 0}.\nLet ˆb ∈{b ∈{0, 1}m, P(B = b) > 0}, then since\nH(Y |B) = 0, ∃!yn, P(yn|ˆb) = 1, and knowing that\nP(ˆb) > 0, the Bayes theorem allows us to write\nP(ˆb|yn) > 0, then ˆb ∈Bn □\nLet yn ∈Y so that P(Y = yn) > 0, we consider ϕ(n) ∈\n{−1, 0, 1}m so that\nϕ(n)\ni\n=\n\n\n\n0\nif P(Bi = 1|yn) ∈]0, 1[\n−1\nif P(Bi = 1|yn) = 0\n1\nif P(Bi = 1|yn) = 1\nUnsupervised pre-training helps to conserve views from input distribution\nLemma 3.4 Let yn ∈Y so that P(Y = yn) > 0, let\nyl ∈Y so that P(Y = yl) > 0 and yl ̸= yn, then\n∃i, ϕ(n)\ni\n= −ϕ(l)\ni\n̸= 0\nProof by contradiction : If the lemma is false, for all\ni, we have one of the following case :\n\n\n\n\n\n\n\n\n\nϕ(n)\ni\n= ϕ(l)\ni\n̸= 0\nϕ(n)\ni\n= ϕ(l)\ni\n= 0\nϕ(n)\ni\n̸= 0 and ϕ(l)\ni\n= 0\nϕ(n)\ni\n= 0 and ϕ(l)\ni\n̸= 0\nLet b ∈{0, 1}m such that ∀i :\nbi =\n\n\n\n\n\n\n\n\n\n\n\nϕ(n)\ni\n+1\n2\nif ϕ(n)\ni\n= ϕ(l)\ni\n̸= 0\n0\nif ϕ(n)\ni\n= ϕ(l)\ni\n= 0\nϕ(n)\ni\n+1\n2\nif ϕ(n)\ni\n̸= 0 and ϕ(l)\ni\n= 0\nϕ(l)\ni\n+1\n2\nif ϕ(n)\ni\n= 0 and ϕ(l)\ni\n̸= 0\nBy construction we have ∀i, P(Bi = bi|yn) > 0 and\nP(Bi = bi|yl) > 0, and the conditional independence\ngives us P(B = b|yn) > 0 and P(B = b|yl) > 0,\ntherefore b ∈B(n) ∩B(l) which is in contradiction with\nthe lemma 3.2 □\nLet yn ∈Y, P(yn) > 0, b ∈Bn, we deﬁne a vector\nS(n,b) ∈Rm such that :\n∀i, S(n,b)\ni\n= (2bi −1)ϕ(n)\ni\nLemma 3.5 Let yn ∈Y, P(yn) > 0, b ∈Bn, we have\nP\ni S(n,b)\ni\n= (2b −1)T .ϕ(n) = (ϕ(n))T .ϕ(n)\nProof : It suﬃces to see that ϕ(n)\ni\n̸= 0 then 2bi −1 =\nϕ(n)\ni\n□\nLemma 3.6 Let yn ∈Y, P(yn) > 0, b ∈Bn, let ˜b ∈B\nso that ˜b /∈Bn, then P\ni S(n,˜b)\ni\n+ 2 ≤P\ni S(n,b)\ni\nProof : If b ∈B and ˜b /∈Bn, then ∃!yl, P(yl) > 0, yl ̸=\nyn,˜b ∈Bl.\nLet 0 ≤i < m, necessarily S(n,˜b)\ni\n≤1, we distinguish\nthree possible cases depending on ϕ(n)\ni\n:\nif ϕ(n)\ni\n= 0 then S(n,˜b)\ni\n= S(n,b)\ni\n= 0\nif ϕ(n)\ni\n= 1 then bi = 1 and S(n,b)\ni\n= 1 so S(n,˜b)\ni\n≤S(n,b)\ni\nif ϕ(n)\ni\n= −1 then bi = 0 and S(n,b)\ni\n= 1 so S(n,˜b)\ni\n≤\nS(n,b)\ni\nwe deduce that S(n,˜b)\ni\n≤S(n,b)\ni\nand that S(n,b)\ni\n= 1 ⇐⇒\nϕ(n)\ni\n̸= 0\nBy the lemma 3.4, ∃j so that ˜bj ̸= bj and ϕ(n)\nj\n̸= 0,\nwe have then S(n,b)\nj\n= 1 and S(n,˜b)\nj\n= −1 and then\nS(n,˜b)\nj\n+ 2 ≤S(n,b)\nj\n.\nWe conclude that P\ni S(n,˜b)\ni\n+ 2 ≤P\ni S(n,b)\ni\n□\nLet yn ∈Y, P(yn) > 0, we deﬁne the vector µ(n) ∈\nRm+1 so that\nµ(n)\ni\n=\n(\n2ϕ(n)\ni\nif 0 ≤i < m\n1 −P\ni[(ϕ(n)\ni\n)2 + ϕ(n)\ni\n]\nif i = m\nNote that for every b ∈{0, 1}m,\n(b0, ..., bm−1, 1).µ(n) =\nX\ni\nS(n,b)\ni\n−(ϕ(n))T .ϕ(n) + 1\nLemma 3.7 Let yn ∈Y, P(yn) > 0, let b ∈B,\nIf b ∈Bn, then (b0, ..., bm−1, 1).µ(n) > 0\nIf b /∈Bn, then (b0, ..., bm−1, 1).µ(n) < 0\nProof :\nIf b ∈Bn, then by lemma 3.5, we have\n(b0, ..., bm−1, 1).µ(n) = 1\nIf b /∈Bn, then by lemma 3.5 and lemma 3.6, we have\n(b0, ..., bm−1, 1).µ(n) ≤−1 □\nWe can now prove the theorem 3.1 :\nLet yn ∈Y so that P(yn) > 0, let b so that P(B =\nb) > 0.\nProof\nof\nnecessity\n:\nWe\nsuppose\nthat\n(b0, ..., bm−1, 1).µ(n) > 0.\nSince P(b) > 0, then b ∈B, therefore, by lemma 3.2\nand 3.3, ∃!yl, P(yl) > 0, b ∈Bl.\nIf yl ̸= yn, then b /∈Bn and the lemma 3.7 tells us\nthat (b0, ..., bm−1, 1).µ(n) < 0 which contradicts the\nhypothesis made at the beginning of the proof. We\nhave then yl = yn. Since yl = yn, then b ∈Bn, so\nP(b|yn) > 0.\nSince H(Y |B) = 0, then necessarily\nP(yn|b) = 1. □\nProof of suﬃciency : If P(yn|b) = 1, then since P(b) >\n0, p(yn) > 0 and with the use of Bayes theorem, we\ncan say that P(b|yn) > 0, then b ∈Bn. If b ∈Bn, then\nthe lemma 3.7 ensures that (b0, ..., bm−1, 1).µ(n) > 0 □\n3.1. A measure of conditional dependency\nWe propose to measure the conditional dependency\nbetween a subset I of components of B with the fol-\nlowing function :\ndB(I) := 1\n|I|\n X\nBi∈I\nH(Bi|Y ) −H(I|Y )\n!\nUnsupervised pre-training helps to conserve views from input distribution\ndB(I) is a normalized version of conditional total cor-\nrelation between variables in I, this normalization al-\nlows to compare the measurements between subsets of\ndiﬀerent sizes. dB(I) = 0 if and only if components in\nI are independent conditionally to Y . We note DB(n)\nthe average value of dB over subsets of size n :\nDB(n) :=\n1\n|Πn|\nX\nI∈Πn\ndB(I)\n4. Representations displaying multiple\nviews\nIf the input distribution X has high dimensionality, it\nis likely that it expresses the information about Y in\nmultiple ways. For example, in a case of face recog-\nnition task, it is likely that observation of only halves\nof faces should be enough to deduce their label. This\ndistribution displays multiple views of Y , each of them\nbeing a diﬀerent subset of components of X.\nWe deﬁne a view as a subset of components of B. We\ncall a complete view, a view that displays full infor-\nmation about Y . According to our deﬁnition, unless\nit is complete, a view does not need to display full\ninformation about Y .\nAs a motivation in favor of having multiple complete\nviews, we propose an analogy with bagging (Breiman,\n1996). The data set D can be split in multiple ones\naccording to each view. They are used to learn a set of\npredictors that are aggregated to form a more stable\none.\n4.1. A measure of diﬀerence between views\nWe suppose that, to be useful, each views have to\ndisplay information about Y in diﬀerent ways.\nWe\npropose to measure such diﬀerence with interaction\ninformation (Mcgill, 1954).\nLet consider two views\nI+ and I−being subsets of components of B. Sup-\npose that these two views are duplicates, such that\nI+ = I−. Then for a feature Bi ∈I+ from one view,\nthere exists another feature Bj ∈I−from other view,\nsuch that Bi = Bj. These two features expresses the\nsame information about Y .\nThis can be character-\nized by I(Bi, Y |Bj) = I(Bj, Y |Bi) = 0. Observation\nof Bj (respectively Bi), vanishes the mutual informa-\ntion of Bi (respectively Bj) with Y .\nNow suppose\nI+ ∩I−= ∅such that for any features Bi ∈I+ and\nBj ∈I−, Bi and Bj do not display the same infor-\nmation about Y .\nThis can be characterized by the\nrelations I(Bi, Y |Bj) = I(Bi, Y ) and I(Bj, Y |Bi) =\nI(Bj, Y ).\nObservation of one feature does not alter\nthe mutual information of the other one. More gener-\nally, Bi does not display the same information about\nY than any subset I ⊂I−, if I(Bi, Y |I) = I(Bi, Y ).\nThese considerations lead us to deﬁne a measure of\ndiﬀerence between views by measuring average inter-\naction that have any component with up to n other\ncomponents and Y :\nCB(n) := 1\nm\nX\ni\nn\nX\nj=1\n1\n|Πi\nj|\nX\nI∈Πi\nj\nI(Bi, I, Y )\nwhere I(Bi, I, Y ) = I(Bi, Y |I) −I(Bi, Y ) is the in-\nteraction information between Bi, Y and I.\nNega-\ntivity of CB(n) indicates the presence of redundancy\nbetween components. Positivity indicates presence of\nsynergy because information about Y cannot be ob-\ntained by disjoint observations of components.\nWe\nshall see that there exists a relation between condi-\ntional independence of components and interaction in-\nformation.\nSince any permutation of variables does\nnot change the interaction information :\nI(Bi, I, Y ) = I(I, Bi, Y ) = I(I, Y, Bi) = ...\nWe can write :\nI(Bi, I, Y ) = I(Bi, I|Y ) −I(Bi, I)\nUnder hypothesis of independence of components con-\nditionally to Y we have I(Bi, I|Y ) = 0, and conse-\nquently interaction cannot be positive.\n5. Information proﬁle\nWe propose to deﬁne an information proﬁle for the ran-\ndom vector B that summarizes the mutual information\nof subsets of its components with Y and that allows\nto compute their average interaction information. We\ndeﬁne the information proﬁle by the following function\n:\nfB(n) := 1\nm\nX\ni\n1\n|Πin|\nX\nI∈Πin\nI(Bi, Y |I)\nfB(n) represents the average mutual information be-\ntween one component and Y when n other components\nare observed.\nInformation proﬁle allows to get the average mutual\ninformation between n components and Y :\nFB(n) :=\n1\n|Πn|\nX\nI∈Πn\nI(I, Y ) =\nn−1\nX\nj=0\nfB(j)\nAnd consequently, the quantity m\nn is an estimation of\nthe number of non-intersecting views displaying F(n)\nbit of information about Y .\nUnsupervised pre-training helps to conserve views from input distribution\n5.1. Information proﬁle and interaction\ninformation\nThe average information interaction between any com-\nponent, any other n components, and Y , can be writ-\nten :\n1\nm\nX\ni\n1\n|Πin|\nX\nI∈Πin\nI(Bi, I, Y )\nwhich can be simply computed with a diﬀerence using\ninformation proﬁle : fB(n) −fB(0)\nThis allows to compute CB(n) :\nCB(n) =\nn\nX\nj=1\n(fB(j) −fB(0))\n5.2. Estimation of information proﬁle\nComputing fB is not tractable because of sum over el-\nements of Πi\nn and computation of mutual information\nI(Bi, Y |I). We propose the following estimation :\nˆfB(n) = 1\nm\nX\ni\n1\n|Sin|\nX\nI∈Sin\nˆI(Bi, Y |I)\nwhere Si\nn is a set of samples from the set Πi\nn.\nˆI(Bi, Y |I) is an estimation of the mutual information\nusing the following estimation of conditional entropy :\nˆH(Bi|I, Y ) = 1\n|Γ|\nX\n(b,y)∈Γ\nH(Bi|b, y)\nwhere Γ is a set of samples from P(I, Y |θ). We can\nsample from P(I, Y |θ) by randomly picking an exam-\nple (x, y) ∈D, then sample from P(I|x, θ), which is\neasy if we have (2).\nSimilarly, we can estimate H(Bi|I), and then get an\nestimation of mutual information :\nˆI(Bi, Y |I) = ˆH(Bi|I) −ˆH(Bi|I, Y )\nTo evaluate the quality of estimation ˆfB, we compared\nit with the computable information proﬁle of a binary\nrandom vector Bα, which distribution is deﬁned and\nparametrized by α as following. We assume the condi-\ntional independence of components with respect to Y\n:\nP(Bα|Y ) =\nY\nj\nP(Bα\nj |Y )\nWe also suppose that Y is binary and uniform, such\nthat P(Y = 1) = P(Y = 0) =\n1\n2.\nThe following\nhypotheses complete to deﬁne distribution of Bα :\n∀j, P(Bα\nj = 0|Y = 0) = α\n∀j, P(Bα\nj = 1|Y = 1) = α\nwith 1\n2 ≤α ≤1.\nThe information proﬁle of Bα is computable because\nwe have :\n|I| = |J | ⇒I(Bα\ni , Y |I) = I(Bα\ni , Y |J )\n(3)\nFigure 1(a) shows the accuracy of estimate ˆfBα(n) for\nvarious values of α. The number of samples is |Γ| = 32\nand |Si\nn| = 100.\nThe estimate is accurate, however\nmore variance is expected for distributions that do not\nsatisfy (3).\nWe note ˆFB the estimate of FB obtained using ˆfB.\n5.3. Estimation of DB(n)\nWe use estimates of conditional entropies from section\n5.2 to compute an estimate ˆDB(n) of DB(n) :\nˆDB(n) = 1\nm\nn\nX\nj=1\nX\ni\n1\n|Si\nj|\nX\nI∈Si\nj\n\u0010\nˆH(Bi|Y ) −ˆH(Bi|I, Y )\n\u0011\n6. Experiments\nWe performed experiments on a variation of the well\nknow MNIST data set, in which the digit labels are\ngrouped in two classes depending on their parity. This\ndata set represents a variable Y that has one bit of\nentropy. We learned representations with both super-\nvised and unsupervised models. For the former case,\nwe stacked RBMs, for the latter we used a discrimina-\ntive RBM (DRBM) (Larochelle & Bengio, 2008) and\na stochastic supervised binary encoder (SSBE).\nStochastic supervised binary encoder :\nA SSBE\nis a supervised model designed to learn multiple views.\nThis model uses a learning objective function that\naims to maximize the mutual information of Y with\nﬁxed-size subsets of components of the representation.\nWe use the following model :\nP(B|X, θ = {W, c}) = σ(W.X + c)\nwhere σ is the sigmoid function2 , W is a3 m × mX\nmatrix of weights, and c a m-dimensional vector of\nbiases. The learning objective aims to maximize mu-\ntual information I(I, Y ) for any subset of components\nI ∈Πn, its objective function is written :\nθ∗\n=\narg max\nθ\nX\nI∈Πn\nI(I, Y |θ)\n=\narg min\nθ\nX\nI∈Πn\nH(Y |I, θ)\n2σ(x) =\n1\n1+e−x\n3we note mX the dimensionality of X\nUnsupervised pre-training helps to conserve views from input distribution\n0\n20\n40\n60\n80\n100\nNumber of components\n0\n0.01\n0.02\n0.03\nConditional mutual information\nestimate\ntrue\n(a) Comparison between fBα and its estimate ˆfBα,\nfor α ∈{0.57, 0.58, 0.6}.\n0\n50\n100\n150\n200\nNumber of components\n0\n0.005\n0.01\n0.015\n0.02\nConditional mutual information\nRAW\n1 Layer RBM\n2 Layers RBM\n3 Layers RBM\n6 Layers RBM\nSSBE\nSparse SSBE\nDRBM\nRBM 112 feat\n(b) Information proﬁles estimates ˆfB computed on\nthe train set.\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nMutual information\n0\n5\n10\n15\n20\n25\nNumber of views\nRAW\n1 Layer RBM\n2 Layers RBM\n3 Layers RBM\n6 Layers RBM\nSSBE\nSparse SSBE\nDRBM\nRBM 112 feat\n(c) For each size n of subset of components from\nthe representation, the average mutual information\nˆFB(n) (on the x-axis) versus the number of non-\nintersecting views m\nn (on the y-axis).\n0\n0.2\n0.4\n0.6\n0.8\n1\nMutual information\n−0.015\n−0.01\n−0.005\n0\n0.005\nAverage interactions\nRAW\n1 Layer RBM\n2 Layers RBM\n3 Layers RBM\n6 Layers RBM\nSSBE\nSparse SSBE\nDRBM\nRBM 112 feat\n(d) For each size n of subset of components from\nthe representation, the average mutual information\nˆFB(n) (on the x-axis) versus the average interac-\ntions ˆCB(n) (on the y-axis).\n0\n0.2\n0.4\n0.6\n0.8\n1\nMutual information\n0\n0.05\n0.1\n0.15\n0.2\nNormalized conditional total correlation\nRAW\n1 Layer RBM\n2 Layers RBM\n3 Layers RBM\n6 Layers RBM\nSSBE\nSparse SSBE\nDRBM\nRBM 112 feat\n(e) For each size n of subset of components from\nthe representation, the average mutual information\nˆFB(n) (on the x-axis) versus the average normalized\nconditional total correlation ˆDB(n) (on the y-axis).\nFigure 1. Unsupervised models manage to conserve views from the input distribution, whereas supervised models do not.\nThe gradient over parameters θ is intractable, but\nwe can compute an estimation with samples from the\ndistribution P(Y, B, X|θ) = P(Y, X)P(B|X, θ) using\ndata set D and current parameters θ.\nUnless speciﬁcally mentioned, all representations are\nlearned with the same size m = 784 corresponding to\nthe input dimension. On ﬁgures, RAW designates the\ninput distribution by interpreting pixels as probabil-\nities. RBM 112 Feat is a learned RBM from which\nwe picked up 112 of its hidden variables, they were\nduplicated seven times to form a new representation.\nSparse SSBE is a SSBE learned with a sparse regular-\nization applied on components of B. This is done by\nUnsupervised pre-training helps to conserve views from input distribution\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nMutual information\n0\n5\n10\n15\n20\n25\nNumber of views\nRAW\n1 layer 256 components\n2 layers 256 components\n1 layer 784 components\n2 layers 784 components\n1 layer 1024 components\n2 layers 1024 components\n(a) Conjoint observation with the ﬁgure 2(b) show\nthat larger representations allow to conserve more\nviews from input distribution.\n0\n0.2\n0.4\n0.6\n0.8\n1\nMutual information\n−0.01\n−0.005\n0\n0.005\n0.01\nAverage interactions\nRAW\n1 layer 256 components\n2 layers 256 components\n1 layer 784 components\n2 layers 784 components\n1 layer 1024 components\n2 layers 1024 components\n(b) Larger representations manage to learn non in-\nteracting features. Smaller representations, either\ndo not manage to solve positive interactions or learn\nredundant features.\n0\n0.2\n0.4\n0.6\n0.8\n1\nMutual information\n0\n0.1\n0.2\n0.3\n0.4\nNormalized conditional total correlation\nRAW\n1 layer 256 components\n2 layers 256 components\n1 layer 784 components\n2 layers 784 components\n1 layer 1024 components\n2 layers 1024 components\n(c) Larger representations manage to have low con-\nditional total correlation, while smaller representa-\ntions do not.\nFigure 2. Eﬀects of the size of the representation on the quantity of preserved views and disentanglement of supervision.\nadding the following term to the objective function :\nλ\nX\ni\nDKL(B(p)∥P(Bi|θ))\nwhere DKL(.||.) designates the Kullback-Leibler diver-\ngence, B(p) is the Bernoulli distribution of parameter\np.\nHyper-parameters are λ that controls the mag-\nnitude of the regularization, and p that controls the\nsparsity level.\nThe ﬁgure 1(b) shows information proﬁle estimates\ncomputed on the training set4. We computed ˆfB(n)\nwith increasing values of n until ˆfB(n) < 0.001, this\nexplains missing data for some models. The number\nof samples was |Γ| = 32 and |Si\nn| = 100. We see that\nproﬁle of RAW has its maximum at around 40 compo-\nnents, with a high diﬀerence ˆfB(40) −ˆfB(0), this in-\ndicates strong positive interactions in the input distri-\nbution. These are resolved as we increase layer depth\nfor stacked RBMs (proﬁles ﬂatten).\nOn ﬁgures 1(c),1(d) and 1(e), are displayed for each\n4We got same proﬁles on the test set.\nsize n of subset of components, the average mutual\ninformation ˆFB(n) (on the x-axis) versus (on the y-\naxis) :\n• number of non-intersecting views m\nn (ﬁgure 1(c)),\n• the average interactions ˆCB(n) (ﬁgure 1(d)),\n• the average normalized conditional total correla-\ntion ˆDB(n) (ﬁgure 1(e)).\nFor stacked RBMs, we observe that, as the number\nof layer increases, the total correlation decreases (ﬁg-\nure 1(e)), indicating improvement of disentanglement\nof supervision. However, the ﬁgure 1(c) shows a coun-\nterpart which is the decreasing number of views as we\nincrease depth.\nThis can be an explanation of why\nincreasing further the number of layer decreases the\nclassiﬁcation performances as shown in (Erhan et al.,\n2010).\nThe partial data for the DRBM shows that the model\nhas likely learned only one view (ﬁgure 1(c)).\nThe\nUnsupervised pre-training helps to conserve views from input distribution\nmodel has retained only enough information to achieve\nits learning objective.\nThe SSBE learned without sparsity displays high con-\nditional total correlation indicating no disentangle-\nment of classes (ﬁgure 1(e)).\nThis is not surprising\nsince its objective is to maximize mutual information\nwithout constraint on how this information have to be\narranged. However, it appears that adding a sparsity\nconstraint greatly reduces the total correlation. The\nSSBE was specially designed to learn multiple views\nin a supervised fashion. It has apparently succeeded\nas seen on ﬁgure 1(c), but the ﬁgure 1(d) shows that\nthey are highly redundant.\nThe RBM with duplicated features (RBM 112 Feat on\nﬁgures) shows, as expected, a reduced number of views\ncompared to the original RBM (ﬁgure 1(c)). It has a\nsimilar proﬁle than 3 stacked RBMs, except that it has\na higher conditional total correlation.\nFinally, ﬁgures 2(a), 2(b) and 2(c) show eﬀect of vari-\nation of the size of representation learned with stacked\nRBMs. We see that larger representation helps to have\nboth non interacting components and low conditional\ntotal correlation, while smaller representation fails to\nsolve positives interactions from the input distribution\nand has high conditional total correlations.\n7. Discussions and future work\nWe proposed to analyze the representations learned\nwith unsupervised pre-training under the perspective\nof information theory. We proposed two measures :\n• a measure of conditional independence of compo-\nnents. We showed that conditional independence\nof components in the context of binary features\nenables classes to be linearly separable.\n• a measure of quantity of views of the supervision\nwithin the representation. We supposed that the\ninput distribution displays various views about\nthe supervision, and that learning a representa-\ntion that preserves them helps to better general-\nize because they provide information that help to\ndetermine parameters of the model.\nExperiments showed that, according to our measures,\nrepresentations learned with unsupervised models suc-\nceeded to conserve views from input distribution,\nwhereas supervised attempts failed.\nOur approach suggests a new learning objective for\nlearning representations :\ndisentangling supervision\nwhile trying to conserve views about supervision.\nSome information displayed by input may be irrele-\nvant for the supervision, e.g. textures or backgrounds\non image recognition tasks, transferring them in the\nrepresentation would be wasteful. As future work, this\nsuggests that biasing unsupervised models by integrat-\ning the supervision signal during pre-training may help\nto conserve views by keeping only the relevant infor-\nmation and improve classiﬁcation performance.\nReferences\nBengio, Yoshua, Lamblin, Pascal, Popovici, Dan, and\nLarochelle, Hugo. Greedy layer-wise training of deep\nnetworks. In NIPS. 2007.\nBreiman, Leo. Bagging predictors. Machine Learning,\n1996.\nErhan, Dumitru, Courville, Aaron, Bengio, Yoshua,\nand Vincent, Pascal. Why does unsupervised pre-\ntraining help deep learning? In AISTATS, 2010.\nGoodfellow, Ian, Le, Quoc, Saxe, Andrew, and Ng,\nAndrew Y. Measuring invariances in deep networks.\nIn NIPS. 2009.\nHinton, Geoﬀrey E., Osindero, Simon, and Teh, Yee-\nWhye. A fast learning algorithm for deep belief nets.\nIn Neural Computation, 2006.\nLarochelle, Hugo and Bengio, Yoshua. Classiﬁcation\nusing discriminative restricted boltzmann machines.\nICML, 2008.\nMcgill, W. J. Multivariate information transmission.\nPsychometrika, 19(2):97–116, 1954.\nRanzato, Marc’Aurelio, Krizhevsky, Alex, and Hinton,\nGeoﬀrey E. Factored 3-Way Restricted Boltzmann\nMachines For Modeling Natural Images. AISTAT,\n2010.\nRifai, Salah, Vincent, Pascal, Muller, Xavier, Glo-\nrot, Xavier, and Bengio, Yoshua. Contractive auto-\nencoders: Explicit invariance during feature extrac-\ntion. ICML, 2011.\nShannon, Claude E. A mathematical theory of com-\nmunication. The Bell system technical journal, 27,\n1948.\nVincent, Pascal, Larochelle, Hugo, Bengio, Yoshua,\nand antoine Manzagol, Pierre. Extracting and com-\nposing robust features with denoising autoencoders,\n2008.\nWelling, Max, Zvi, Michal R., and Hinton, Geoﬀrey E.\nExponential Family Harmoniums with an Applica-\ntion to Information Retrieval. In NIPS, 2004.\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2019-05-30",
  "updated": "2019-05-30"
}