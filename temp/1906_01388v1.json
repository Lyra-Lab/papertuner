{
  "id": "http://arxiv.org/abs/1906.01388v1",
  "title": "A Comprehensive Study on Deep Learning Bug Characteristics",
  "authors": [
    "Md Johirul Islam",
    "Giang Nguyen",
    "Rangeet Pan",
    "Hridesh Rajan"
  ],
  "abstract": "Deep learning has gained substantial popularity in recent years. Developers\nmainly rely on libraries and tools to add deep learning capabilities to their\nsoftware. What kinds of bugs are frequently found in such software? What are\nthe root causes of such bugs? What impacts do such bugs have? Which stages of\ndeep learning pipeline are more bug prone? Are there any antipatterns?\nUnderstanding such characteristics of bugs in deep learning software has the\npotential to foster the development of better deep learning platforms,\ndebugging mechanisms, development practices, and encourage the development of\nanalysis and verification frameworks. Therefore, we study 2716 high-quality\nposts from Stack Overflow and 500 bug fix commits from Github about five\npopular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to\nunderstand the types of bugs, root causes of bugs, impacts of bugs, bug-prone\nstage of deep learning pipeline as well as whether there are some common\nantipatterns found in this buggy software. The key findings of our study\ninclude: data bug and logic bug are the most severe bug types in deep learning\nsoftware appearing more than 48% of the times, major root causes of these bugs\nare Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing up\nmore than 43% of the times. We have also found that the bugs in the usage of\ndeep learning libraries have some common antipatterns that lead to a strong\ncorrelation of bug types among the libraries.",
  "text": "A Comprehensive Study on Deep Learning Bug Characteristics\nMd Johirul Islam\nmislam@iastate.edu\nIowa State University\nAmes, IA\nGiang Nguyen\ngnguyen@iastate.edu\nIowa State University\nAmes, IA\nRangeet Pan\nrangeet@iastate.edu\nIowa State University\nAmes, IA\nHridesh Rajan\nhridesh@iastate.edu\nIowa State University\nAmes, IA\nABSTRACT\nDeep learning has gained substantial popularity in recent years.\nDevelopers mainly rely on libraries and tools to add deep learning\ncapabilities to their software. What kinds of bugs are frequently\nfound in such software? What are the root causes of such bugs?\nWhat impacts do such bugs have? Which stages of deep learning\npipeline are more bug prone? Are there any antipatterns? Under-\nstanding such characteristics of bugs in deep learning software\nhas the potential to foster the development of better deep learning\nplatforms, debugging mechanisms, development practices, and en-\ncourage the development of analysis and verification frameworks.\nTherefore, we study 2716 high-quality posts from Stack Overflow\nand 500 bug fix commits from Github about five popular deep\nlearning libraries Caffe, Keras, Tensorflow, Theano, and Torch to\nunderstand the types of bugs, root causes of bugs, impacts of bugs,\nbug-prone stage of deep learning pipeline as well as whether there\nare some common antipatterns found in this buggy software. The\nkey findings of our study include: data bug and logic bug are the\nmost severe bug types in deep learning software appearing more\nthan 48% of the times, major root causes of these bugs are Incorrect\nModel Parameter (IPS) and Structural Inefficiency (SI) showing up\nmore than 43% of the times. We have also found that the bugs in the\nusage of deep learning libraries have some common antipatterns\nthat lead to a strong correlation of bug types among the libraries.\nKEYWORDS\nDeep learning software, Q&A forums, Bugs, Deep learning bugs,\nEmpirical Study of Bugs\nACM Reference Format:\nMd Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan. 2019. A\nComprehensive Study on Deep Learning Bug Characteristics. In Proceedings\nof The 27th ACM Joint European Software Engineering Conference and Sym-\nposium on the Foundations of Software Engineering (ESEC/FSE 2019). ACM,\nNew York, NY, USA, Article 4, 11 pages. https://doi.org/10.475/123_4\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\n© 2019 Copyright held by the owner/author(s).\nACM ISBN 123-4567-24-567/08/06...$15.00\nhttps://doi.org/10.475/123_4\n1\nINTRODUCTION\nA class of machine learning algorithms known as deep learning\nhas received much attention in both academia and industry. These\nalgorithms use multiple layers of transformation functions to con-\nvert input to output, each layer learning successively higher-level\nof abstractions in the data. The availability of large datasets has\nmade it feasible to train (adjust the weights of) these multiple lay-\ners. While the jury is still out on the impact of deep learning on\noverall understanding of software’s behavior, a significant uptick\nin its usage and applications in wide ranging areas combine to\nwarrant research on software engineering practices in the presence\nof deep learning. This work focuses on the characteristics of bugs\nin software that makes use of deep learning libraries.\nPrevious work on this topic generally fall under two categories:\nthose that have studied bugs in the implementation of machine\nlearning libraries themselves, and those that have studied bugs\nin the usage of a specific deep learning library. A key work in\nthe first category is Thung et al. [21] who studied bugs in the\nimplementation of three machine learning systems Mahout, Lucene,\nand OpenNLP. In the second category, Zhang et al. [25] have studied\nbugs in software that make use of the Tensorflow library. While\nboth categories of approaches have advanced our knowledge of\nML systems, we do not yet have a comprehensive understanding\nof bugs encountered by the class of deep learning libraries.\nThis work presents a comprehensive study of bugs in the usage\nof deep learning libraries. We have selected top five popular deep\nlearning libraries Caffe [12], Keras [7], Tensorflow [1], Theano [20],\nand Torch [8] based on the user counts from developers Q&A forum\nStack Overflow. While each of these libraries are for deep learning\nthey have different design goals. For example, Tensorflow focuses\non providing low-level, highly configurable facilities whereas Keras\naims to provide high-level abstractions hiding the low-level details.\nTheano and Torch are focused on easing the use of GPU computing\nto make deep learning more scalable. Thus, studying them simul-\ntaneously allows us to compare and contrast their design goals\nvis-à-vis bugs in their usage.\nWe have used two sources of data in our study: posts about these\nlibraries on Stack Overflow and also Github bug fix commits. The\nfirst dataset gives us insights into bugs that developers encounter\nwhen building software with deep learning libraries. A number of\nthese bugs would, hopefully, be fixed based on the discussion in\nQ&A forum. The second dataset gives us insights into bugs that\nwere found and fixed in open source software. Our study focuses\narXiv:1906.01388v1  [cs.SE]  3 Jun 2019\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nMd Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan\nTable 1: Summary of the dataset used in the Study\nLibrary\nStack Overflow\nGithub\n# Posts\n# Bugs\n# Commits\n# Bugs\nCaffe\n183\n35\n100\n26\nKeras\n567\n162\n100\n348\nTensorflow\n1558\n166\n100\n100\nTheano\n231\n27\n100\n35\nTorch\n177\n25\n100\n46\nTotal\n2716\n415\n500\n555\non following research questions and compares our findings across\nthe five subject libraries.\nRQ1: (Bug Type) What type of bugs are more frequent?\nRQ2: (Root cause) What are the root causes of bugs?\nRQ3: (Bug Impact) What are the frequent impacts of bugs?\nRQ4: (Bug prone stages) Which deep learning pipeline stages are\nmore vulnerable to bugs?\nRQ5: (Commonality) Do the bugs follow a common pattern?\nRQ6: (Bug evolution) How did the bug pattern change over time?\nFindings-at-a-glance. Our study show that most of the deep\nlearning bugs are Data Bugs and Logic Bugs [5], the primary root\ncauses that cause the bugs are Structural Inefficiency (SI) and In-\ncorrect Model Parameter (IPS) [5], most of the bugs happen in the\nData Preparation stage of the deep learning pipeline. Our study also\nconfirms some of the findings of Tensorflow conducted by Zhang et\nal. [25]. We have also studied some antipatterns in the bugs to find\nwhether there is any commonality in the code patterns that results\nin bugs. Our findings show that there is strong correlation among\nthe distribution of bugs as well as in the antipatterns. Finally, we\nconclude with a discussion on our findings suggesting immediate\nactions and future research directions based on these findings.\n2\nMETHODOLOGY\n2.1\nData Collection\nIn our study two different data sources are used. Stack Overflow\nposts and Github bug fix commits are the sources of data we used\nfor studying the bugs in deep learning software. A summary of the\ndataset is shown in Table 1.\n2.1.1\nStack Overflow Data Collection. To study bugs in deep\nlearning software, we have collected data from Stack Overflow, a\nwell-known Q&A site for developers to discuss software develop-\nment problems. The data collection process consists of two steps.\nIn the first step, we select candidate posts discussing deep learn-\ning libraries. We focus on five deep learning libraries: Caffe, Keras,\nTensorflow, Theano, and Torch. These are the five most discussed\ndeep learning libraries on Stack Overflow. We did that by searching\nfor posts tagged with Caffe, Keras, Tensorflow, Theano, and Torch.\nWhen posts are about specific libraries, they are more likely to talk\nabout bugs in using deep learning libraries. Using these criteria,\nwe selected all posts about these five libraries. We further filtered\nthe posts that did not contain any source code because posts about\nbugs usually contain code snippets. Moreover, we reduced the num-\nber of posts by selecting the posts whose scores, computed as the\ndifference between the number of its upvotes and the number of\nits downvotes, were greater than 5 to focus on the high-quality\nposts and keep the manual effort manageable. After this step, in\ntotal, we selected 183, 567, 1558, 231, and 177 posts for Caffe, Keras,\nTensorflow, Theano, and Torch, respectively.\nIn the second step, we manually read these candidates to iden-\ntify the ones about bugs. After that, the second and the third au-\nthors manually reviewed the candidates. For each post, we read the\nquestion and all answers focusing on the best-accepted one. If the\nbest-accepted answer was to fix the usages of the deep learning\nAPI(s) in the question, we considered that post as talking about\ndeep learning bugs. After this step, we found 35, 162, 166, 27, and\n25 bugs for Caffe, Keras, Tensorflow, Theano, and Torch respectively.\n2.1.2\nGithub Data Collection. Github is a large source of deep\nlearning repositories. We mine the Github commits to study the\nchange in the commits and to check and confirm the bug patterns\nthat we studied from Stack Overflow. The data collection process\nconsists of two steps.\nFirst, we collect all the repositories of Caffe, Keras, Tensorflow,\nTheano, and Torch. After that, we mine all the commits whose title\ncontain word \"fix\" of these libraries. Then, we randomly select\n100 commits for each libraries from mined commits and classify\nthem.\nSecondly, we use the same process that we used for Stack Over-\nflow. Specifically, the second and the third authors manually studied\nthe 500 commits and separately label them. After that, these two au-\nthors compare their results to fix the conflict in the labeling process.\nWe study every line of change in each commits; therefore, some\ncommits have more than one bugs and some commit does not have\nbug. Overall, we got 26, 348, 100, 35, and, 46 bugs for the commits\nof Caffe, Keras, Tensorflow, Theano, and Torch, respectively.\n2.2\nClassification\nIn our classification, we focus on three criteria which are bug types,\nroot causes and effects of bug. The classification scheme used for\nlabeling of the bugs in each of these three criteria discussed in §2.4,\n§2.5, and §2.6. We have also classified the bugs into different deep\nlearning stages [24].\nTo label the bug types we followed the classification from an\nalready existing well vetted taxonomy [5] and appended on top\nof that. The added types were based on the data that we studied\nfollowing an open coding scheme.\nThe bugs may have different root causes and effects. A supervised\npilot study and open coding schemes were used to identify the\neffects that are possible through these bugs. We have adapted the\nclassification scheme of root causes and bug effects from [25] and\nadded on top of that as found from the study of the posts. The\nthird author studied the posts initially to finalize the classification\nscheme for bug types, root causes and effects. We followed the open\ncoding scheme and pilot study was conducted to get agreement on\nthe classification.\nWe also classified the bugs into different stages of the pipeline\nto understand which stages are more vulnerable to bugs. Deep\nlearning process can be divided into seven stage pipeline [24]. The\nstages are data collection, data preparation, choice of model, train-\ning, evaluation, hyper parameter tuning and prediction. Among the\nseven stages, the first one is not related to software development.\nA Comprehensive Study on Deep Learning Bug Characteristics\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nThe other stages are related to software development, and are sup-\nported by the deep learning libraries through their APIs. We use\nthese stages to label the bugs into different stages.\n2.3\nLabeling the Bugs\nOnce we have all the classification criteria, we used those criteria\nto label the posts. The second and the third authors independently\nstudied the posts. We measured the inter rater aggrement among\nthe labellers using Cohen’s Kappa coefficient [22] when 5%, 10%,\n20% , 30%, 40%, 50%, 60%, 70%, 80%, 90% and 100% of the posts were\nlabeled. After 5% labeling, the Cohen’s Kappa coefficient was close\nto 0. Then we conducted a training session among the raters to\nclarify the labeling and what they mean. After the training session,\nwe conducted another pilot study at 10% including the first 5%. This\ntime the Cohen’s Kappa coefficient was 82%. We again discussed\nthe results and find out the reasons for major disagreements. We\nthen discussed those cases further through examples and continued\nlabeling. The Cohen’s Kappa coefficient was more than 90% in\nsubsequent pilot studies.\nThe labeling effort was continuously being monitored with the\nhelp of Kappa coefficient to understand the agreement. We con-\nducted reconciling efforts ideally at every 10% interval of the label-\ning. The posts where there was disagreement between the raters\nwere further discussed in the presence of a supervisor. After dis-\ncussion and arguments a common label was given. Finally all the\nbugs were given a common label.\n2.4\nTypes of Bugs in Deep Learning Software\nDevelopers often confront different types of bugs while trying to\nwrite deep learning software. To understand those bugs and their\nroot causes, we have classified them into different categories. The\nclassification has been done on the basis of all the Stack Overflow\nposts that we analyzed. The classification is adapted from [5], where\na well organized taxonomy of bugs is presented.\n2.4.1\nAPI Bug. This group of bugs is caused by deep learning\nAPI. Generally, when a developer uses a deep learning API, dif-\nferent bugs associated with that API are inherited automatically\nwithout the knowledge of the user. The prime causes for triggering\nof deep learning API bugs can be because of the change of API\ndefinition with different versions, lack of inter-API compatibility\nand sometimes wrong or confused documentation.\n2.4.2\nCoding Bug. This kind of bugs originate due to mistakes\nin coding syntax. This in turn, introduces other types of bugs in the\nsoftware which lead to either run time error or incorrect results.\nA big percentage of the deep learning bugs that we have checked\narises from syntactic mistakes or a certain scenario which cannot be\nfixed by changing only some lines of code; hence, needs to change\nthe whole module. Though a robust compiler usually takes care of\nthe basic coding mistakes, in certain scenarios, this type of bugs\nare not captured by the compiler resulting in wrong output.\n2.4.3\nData Bug. This bug may arise if an input to the deep\nlearning software is not properly formatted or cleaned well before\nprocessing in any deep learning model. This type of bug occurs\nbefore data enters into the deep learning model. It is not because\nof the wrong deep learning model, rather it is purely based on the\ntype and structure training or test data. Similar to coding bugs, data\nbugs are usually flagged by the compiler, but in some scenarios, it\ncan pass unchecked through the compilation process and generate\nerroneous results.\n2.4.4\nStructural Bug(SB). A vast majority of the deep learning\nbugs are occurring due to incorrect definitions of the deep learning\nmodel’s structure. These include mismatch of dimensions between\ndifferent layers of deep learning models, the presence of anomaly\nbetween the training and test datasets, use of incorrect data struc-\ntures in implementing a particular function, etc. This type of bugs\ncan be further classified into another four categories.\nControl and Sequence Bug. This subclass of the bug is caused\nby the wrong structure of control flow. In many scenarios, due\nto wrong if-else or loop guarding condition, the model does not\nperform as expected. This type of bug either leads to a crash when\na part of deep learning model does not work or, leads to incorrect\nfunctionality due to mishandling of data through the layers.\nData Flow Bug. The main difference between the Data Flow Bug\nand the Data Bug is the place of origination. If a bug occurs due to\nthe type or shape mismatch of input data after it has been feed to\nthe deep learning model, it will be called Data Flow Bug. It includes\nthe scenarios when model layers are not in synchronization because\nof different data shape used in consecutive layers. To fix these bugs,\ndevelopers need to modify the model or reshape the data.\nInitialization Bug. In deep learning, Initialization Bug means the\nparameters or the functions are not initialized properly before they\nare used. This type of bugs would not necessarily produce run time\nerror but it will simply make the model perform worse. Here, the\ndefinition of functions includes both user-defined and API defined.\nWe also categorize a bug into this category when the API has not\nbeen initialized properly.\nLogic Bug. In deep learning, the logical understanding of each\nstage of the pipeline is an integral part of the coding process. With\nan incorrect logical structure of the deep learning model, the out-\nput of a program may result in either a runtime error or a faulty\noutcome. These bugs are often generated in the absence of proper\nguarding conditions in the code or trying to implement a feature\nwhich is not possible in the given structure of the deep learning\nmodel.\nProcessing Bug. One of the most important decisions in the deep\nlearning model structure is to choose the correct algorithm for\nthe learning process. In fact, different deep learning algorithms\ncan lead to different performances and outputs [11]. Also, to make\ndifferent layers be compatible with each other, the data types of\neach layer need to follow a contract between them. Processing Bugs\nhappen due to the violation of these contracts and wrong choice of\nalgorithms.\n2.4.5\nNon Model Structural Bug(NMSB). Unlike SB, NMSB is\ncreated outside the modeling stage. In other words, this bug can\nhappen in any deep learning stage except the modeling stage such\nas the training stage or the prediction stage. NMSB has similar\nsubcategories with SB. Subcategories of NMSB are Control and Se-\nquence Bug, Logic Bug, Processing Bug, and Initialization Bug. We\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nMd Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan\ndo not define Non Model Structural Data Flow Bug like Structural\nData Flow Bug because Data Bug already covers the meaning of\nNon Model Structural Data Flow Bug.\nControl and Sequence Bug. This subclass is similar to Control and\nSequence Bug in SB. The bug is caused by an incorrect structure of\ncontrol flow like wrong if-else condition; however, this kind of bug\nhappens outside modeling stage.\nInitialization Bug. This subclass is similar to Initialization Bug\nin SB. The bug is caused by initializing a parameter or a function in\na wrong way; however, this kind of bug happens outside modeling\nstage.\nLogic Bug. This subclass is similar to Logic Bug in SB. The bug\nis caused by misunderstanding how case statements and logical\noperators behave singly; however, this kind of bug happens outside\nmodeling stage.\nProcessing Bug. This subclass is similar to Processing Bug in SB.\nThe bug is caused by an incorrect choice of algorithm; however,\nthis kind of bug happens outside modeling stage.\n2.5\nClassification of Root Causes of bugs\n2.5.1\nAbsence of inter API compatibility. The main reason for\nthese bugs is the inconsistency of the combination of two different\nkinds of libraries. For example, a user cannot directly use Numpy\nfunction in Keras because neither Tensorflow backend nor Theano\nbackend of Keras has the implementation of Numpy function.\n2.5.2\nAbsence of type checking. The major effect of the bugs is\ncrash. This kind of bugs involves a type mismatch problem when\ncalling API methods. These bugs are usually mistakes related to the\nuse of wrong type of parameters in an API.\n2.5.3\nAPI Change. The reason for these bugs is the release of\nthe new version of a deep learning library. In other words, the bug\nhappens when the new API version is not backward compatible with\nits previous version. For example, a user updates the new version\nof a deep learning library which has new API syntax; however,\nthe user does not modify his/her code to fit with the new version,\nwhich leads to the API change bug.\n2.5.4\nAPI Misuse. This kind of bugs often arises when users use\na deep learning API without fully understanding. Missing condi-\ntions can be one kind of API misuse, and this bug occurs when a\nusage does not follow the API usage constraints to ensure certain\nrequired conditions. Crash is the main effect of these bugs.\n2.5.5\nConfusion with Computation Model. These bugs happen\nwhen a user gets confused about the function of deep learning API,\nwhich leads to the misuse of the computation model assumed by the\ndeep learning library. For instance, a user gets confused between\nthe graph construction and the evaluation phase.\n2.5.6\nIncorrect Model Parameter or Structure (IPS). IPS causes\nproblems with constructing the deep learning model, e.g. incor-\nrect model structures or using inappropriate parameters. IPS is a\ncommon bug in the deep learning software because of both the\nlack of deep learning knowledge among the users and the incom-\nprehension of deep learning models. This kind of bugs causes the\nfunctional incorrectness; thus, the effect of this bug is crash.\n2.5.7\nOthers. These bugs are not related to deep learninng soft-\nware. In other words, these bugs are mostly related to mistakes in\nthe development process like incorrect syntax.\n2.5.8\nStructure Inefficiency (SI). SI causes problems related to\nmodeling stage in deep learning software like IPS; however, SI leads\nto bad performance of the deep learning software while IPS leads\nto crash.\n2.5.9\nUnaligned Tensor (UT). These bugs often occur in the\ncomputation graph construction phase. When a user builds the\ncomputation graph in deep learning process, they have to provide\ncorrect input data with required specifications to a deep learning\nAPI; however, many users do not know exactly their specifications,\nor they misunderstand API signature, which leads to UT bugs.\n2.5.10\nWrong Documentation. Incorrect information in library\ndocumentation leads to these bugs. Deep learning library users may\nface this kind of bugs when they read an incorrect definition or an\nincorrect usage of a deep learning API from documentation.\n2.6\nClassification of Effects of bugs\n2.6.1\nBad performance. Bad performance or poor performance\nis one of common kind of effect in deep learning software. Further-\nmore, the major root causes of this effect are SI or CCM that are\nrelated to model construction. Even though developers can use the\ndeep learning libraries correctly, they still face deep learning model\nconstruction problems because APIs in these libraries are highly\nabstract.\n2.6.2\nCrash. Crash is the most frequent effect in deep learning.\nIn fact, any kind of bugs can lead to Crash. A symptom of crash is\nthat the software stops running and prints out an error message.\n2.6.3\nData Corruption. Data corruption happens when the data\nis corrupted as the data flows through the network. This effect is a\nconsequence of misunderstanding the deep learning algorithms or\nAPIs. When Data Corruption occurs, a user will receive unexpected\noutputs.\n2.6.4\nHang. Hang effect is caused when a deep learning soft-\nware ceases to respond to inputs. Either slow hardware or inappro-\npriate deep learning algorithm can lead to Hang. A symptom of\nHang is that the software runs for a long period of time without\nproviding the desired output.\n2.6.5\nIncorrect Functionality. This effect occurs when the soft-\nware behaves in an unexpeced way without any runtime or compile-\ntime error/warning. This includes the incorrect output format,\nmodel layers are working desirably, etc.\n2.6.6\nMemory out of bound. Deep learning software often halts\ndue to unavailability of the memory resources. This can be caused\nby, either the wrong model structure or, not having enough com-\nputing resources to train a particular model.\nA Comprehensive Study on Deep Learning Bug Characteristics\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nCaffe\nKeras\nTF\nTheano\nTorch\nAPI Bug\nData Bug\nNMSB.Initialization Bug\nNMSB.Logic Bugs\nNMSB.Processing Bug\nNMSB.Control and Sequence Bug\nSB.Control and Sequence Bug\nSB.Data flow Bug\nSB.Initialization Bug\nSB.Logic Bugs\nSB.Processing Bug\nFigure 1: Distribution of Bug Types in Stack Overflow\n3\nFREQUENT BUG TYPES\nIn this section, we explore the answer to RQ1 through statistically\nanalyzing the labeled data. The normalized distribution of bug types\nin Stack Overflow data is shown in Figure 1. The distribution of\nbugs shown in Figure 1 and the Stack Overflow and Github data\nin Table 2 shows the presence of different kinds of bugs in both\nStack Overflow and Github for the deep learning libraries we have\nstudied. We present some of the key findings related to bug types\nin the following subsections.\n3.1\nData Bugs\nFinding 1: Data Bugs appear more than 26% of the times.\nFrom Figure 1 we see that among the bug types the Data Bugs\nappear most of the time (26%) in all the libraries. In the studied\nStack Overflow data, we have seen 30% of the posts in Tensorflow,\n24% posts in Keras, 36% posts in Torch, 35% posts in Theano, and\n9% posts in Caffe have Data Bugs. Data bugs mostly appear due to\nthe absence of data pre-processing like feature engineering, data\nvalidation, data shuffling, etc.\nThe large percentage of Data Bugs indicate data pre-processing\nrelated difficulties are appearing quite often which could be ad-\ndressed by some data verification tools. If we can provide some static\nanalysis tools using modern abstract data types like DataFrame and\nthe properties of the model, that would help the deep learning com-\nmunity. For example, a developer is trying to read some image files\nusing the following method1.\n1\ndef\n_read32 ( bytestream ) :\n2\ndt = numpy . dtype ( numpy . uint32 ) . newbyteorder ( ' > ' )\n3\nreturn numpy . frombuffer ( bytestream . read ( 4 ) ,\ndtype= dt )\nThe developer eventually got stuck with the following error while\ntrying to train the model using the data returned by the previous\nlibrary call.\n1\nTypeError :\nonly\ni n t e g e r\ns c a l a r\narrays\ncan be\nconverted\nto a\ns c a l a r\nindex\nAn expert suggested an answer to change the last return statement\nwith the following, which solved the problem and was accepted by\nthe developer:\n1\nreturn numpy . frombuffer ( bytestream . read ( 4 ) ,\ndtype= dt ) [ 0 ]\n1https://tinyurl.com/y3v9o7pu\nTable 2: Statistics of Bug Types in Stack Overflow and Github\nCaffe\nKeras\nTF\nTheano\nTorch P value\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nAPI Bug\n6% 0% 11% 57% 11% 72% 7% 3% 16% 2% 0.3207\nData Bug\n9% 49% 24% 8% 30% 0% 35% 17% 36% 15% 0.3901\nNMSB.Control and Sequence Bug 0% 8% 0% 0% 0% 0% 4% 0% 0% 7% 0.3056\nNMSB.Initialization Bug\n0% 0% 1% 0% 1% 0% 0% 3% 0% 0% 0.7655\nNMSB.Logic Bugs\n11% 0% 13% 2% 8% 0% 25% 6% 12% 7% 0.0109\nNMSB.Processing Bug\n0% 0% 0% 0% 1% 0% 0% 3% 0% 7% 0.2323\nSB.Control and Sequence Bug\n6% 12% 2% 0% 4% 0% 4% 3% 8 % 9% 1.0000\nSB.Data flow Bug\n3% 8% 13% 26% 15% 0% 0% 14% 4% 16% 0.2873\nSB.Initialization Bug\n0% 0% 1% 0% 8% 1% 0% 23% 20% 11% 0.8446\nSB.Logic Bugs\n42% 15% 27% 3% 18% 23% 18% 14% 0% 13% 0.3442\nSB.Processing Bug\n23% 8% 8% 4% 4% 4% 7% 14% 4% 13% 0.8535\nThe bug is hard to fix by just looking at the error message. It is\ndifficult to identify the exact reason of bug which led the developer\nto post a question on Stack Overflow and the question was upvoted\nby other fellow developers as a qualified post.\n3.2\nStructural Logic Bugs\nFinding 2: Caffe has 43% Structural Logic Bugs.\nThe second major bug type is Structural Logic Bug in Stack Over-\nflow which was expected from our initial hypothesis based on a\npilot study. Caffe has more Structural Logic Bugs in Stack Overflow\ncompared to other libraries. This indicates that the majority of the\nbugs in Caffe are made during construction and logical organiza-\ntion of the model. Other libraries also have significant portion of\nStructural Logic Bugs ranging from 0% - 27%.\n3.3\nAPI Bugs\nFinding 3: Torch, Keras, Tensorflow have 16%, 11% and 11% API\nbugs respectively.\nIn deep learning libraries API changes sometimes break the entire\nproduction code. The implicit dependence between libraries cause\nproblems when one library has some major changes. For example,\nwhen Numpy is updated Tensorflow, Keras software may fail. Keras\noften uses Tensorflow or Theano as backend and hence update of\nTensorflow or Theano can cause the software developed using Keras\nto crash. API bugs are seen to appear more often in Keras and\nTensorflow as shown in Figure 1. More than 81% of the API bugs\nare from Keras and Tensorflow. For example, in the following code\nsnippet extracted from Stack Overflow we see a scenario where the\ndeveloper trying to train a model fails due to the upgrade of APIs\nand changing the keyword names in the API signature of Keras.\n1\nmodel . f i t ( trainX ,\ntrainY ,\nepochs =100 ,\nb a t c h _ s i z e =1 ,\nverbose =2)\nThe developer will get the error because epochs keyword does not\nexist in version 2+ of Keras.\n1\nmodel . f i t ( trainX ,\ntrainY ,\nb a t c h _ s i z e =1 ,\nverbose =2 ,\nepochs = 100)\nF i l e\n2\n\" / usr / l o c a l / l i b / python2 . 7 / s i t e −packages / keras / models . py \" ,\nl i n e\n612 ,\nin\nf i t\n3\ns t r ( kwargs ) )\nException :\nReceived unknown keyword arguments :\n{ '\nepochs ' :\n100}\nTo fix this error, the developer needs to change from epochs to\nnb_epoch\n1\nmodel . f i t ( trainX ,\ntrainY ,\nnb_epoch =100 ,\nb a t c h _ s i z e =1 ,\nverbose =2)\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nMd Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nCaffe\nKeras\nTF\nTheano\nTorch\nAbsence of type checking\nAPI Change\nAPI Misuse\nConfusion with Computation Model\nIncorrect Model Parameter or Structure\nStructure Ineffciency\nUnaligned Tensor\nAbsense of inter API compatibility\nOthers\nFigure 2: Stack Overflow Root Cause Classification\n3.4\nBugs in Github projects\nWe have also analyzed the distributions of bugs in some Github bug\nfix commits. The distribution of bugs across different libraries in\nGithub data is shown in Table 2. We computed the P value using t-\ntest where one distribution is bug type in Github for all the libraries\nand the other distribution is bug type for all the libraries in Stack\nOverflow.\nFinding 4: All the bug types have a similar pattern in Github and\nStack Overflow for all the libraries.\nWe analyze the Stack Overflow and Github result using the t-\ntest to find whether the distributions differ significantly. We use\n95% significant level to find the difference beween Stack Overflow\nand Github results for each of the bug type In our analysis the\nnull hypothesis is: H0: The distributions are same. If we fail to\nreject this null hypothesis using the t-test then we can say the\ndistributions follow the same pattern in both Stack Overflow and\nGithub data.\nWe see that for all the bug types except Non Model Structural\nLogic Bug the P value is greater than 5% indicating they have a\nsimilar pattern as we fail to reject the null hypothesis.\n4\nROOT CAUSE\nIn this section, we present the analyses and findings to answer RQ2\nidentifying major root causes of bugs in deep learning software.\nThe normalized distribution of root causes in Stack Overflow code\nsnippets is shown in Figure 2. The data in Table 3 shows the presence\nof different categories of root causes in both Stack Overflow and\nGithub for the deep learning libraries and presents P value showing\nthe similarity of distributions using t-test. We discuss the significant\nroot causes in the following subsections.\n4.1\nIncorrect Model Parameter (IPS)\nFinding 5: IPS is the most malicious root cause resulting in average\n24% of the bugs across the libraries.\nIPS results in bugs that causes the program to crash at runtime and\nthe execution does not succeed. In Tensorflow and Theano IPS leads\nother root causes in causing bugs having 26% and 26% of the total\nshare of root causes, respectively.\nTable 3: Statistics of the Root Causes of Bugs\nCaffe\nKeras\nTF\nTheano Torch P value\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nAbsense of inter API compatibility\n0% 0% 1% 0% 1% 0% 0% 0% 0% 0% 0.1411\nAbsence of type checking\n3% 12% 8% 3% 15%15%30%20% 8% 13% 0.9717\nAPI Change\n0% 0% 7% 51% 9% 58% 4% 0% 8% 2% 0.2485\nAPI Misuse\n11% 0% 15% 4% 14% 0% 7% 3% 12% 2% 0.0003\nConfusion with Computation Model\n14%28% 9% 1% 6% 10%11% 3% 12% 4% 0.7839\nIncorrect Model Parameter or Structure26%31%21%30%26%16%30%14%20%19% 0.5040\nOthers\n0% 0% 0% 0% 0% 0% 0% 0% 0% 2% 0.3466\nStructure Ineffciency\n37%12%26% 5% 13% 1% 11%26%12%38% 0.7170\nUnaligned Tensor\n3% 19%12% 5% 16% 0% 7% 34%28%20% 0.7541\nWrong Documentation\n6% 0% 1% 1% 0% 0% 0% 0% 0% 0% 0.3402\n4.2\nStructural Inefficiency (SI)\nFinding 6: Keras, Caffe have 25% and 37% bugs that are resulted\nfrom SI.\nSI bugs do not cause the program to crash. These bugs often yield\nsuboptimal performance of the deep learning model. These bugs\nhave more relation to QoS or non-functional requirements. For\nexample, a programmer is trying to train a model to recognize\nhandwritten digits but the accuracy does not improve and stays\nconstant from epochs 2 - 10. 2\n1\nEpoch\n1/10\n2\n2394/2394 [==============================] −0 s −l o s s :\n0 . 6 8 9 8 −\nacc :\n0 .5 4 5 5 −v a l _ l o s s :\n0. 6 8 35 −val_acc :\n0 .5 7 16\n3\nEpoch\n2/10\n4\n2394/2394 [==============================] −0 s −l o s s :\n0 . 6 8 7 9 −\nacc :\n0 .5 5 2 2 −v a l _ l o s s :\n0. 6 9 01 −val_acc :\n0 .5 7 16\n5\n. . . . . . . . .\n6\nEpoch\n10/10\n7\n2394/2394 [==============================] −0 s −l o s s :\n0 . 6 8 7 7 −\nacc :\n0 .5 5 2 2 −v a l _ l o s s :\n0. 6 8 49 −val_acc :\n0 .5 7 16\n8\n1027/1027 [==============================] −0 s\nThe problem that was pointed out by an expert, which solved\nthe performance degradation bug is following:\n1\n# In summary ,\nr e p l a c e\nt h i s\nl i n e :\n2\nmodel . compile ( l o s s = \" c a t e g o r i c a l _ c r o s s e n t r o p y \" ,\noptimizer = \" adam\n\" )\n3\n# with\nt h i s :\n4\nfrom\nkeras . o p t i m i z e r s\nimport SGD\n5\nopt = SGD( l r = 0 . 0 1 )\n6\nmodel . compile ( l o s s = \" c a t e g o r i c a l _ c r o s s e n t r o p y \" ,\noptimizer = opt )\nThe answer suggested to change optimizer for enhancing the\nperformance.\n4.3\nUnaligned Tensor (UT)\nFinding 7: Torch has 28% of the bugs due to UT.\nIn deep learning, tensor dimensions are important for successful\nconstruction of the model. Tensorflow, Keras, Torch, Theano, Caffe\nhave respectively 16%, 12%, 28%, 7% and 3% of bugs due to UT\nrespectively. In Torch UT is the highest root cause of bugs.\n4.4\nAbsence of Type checking\nFinding 8: Theano has 30% of the bugs due to the absence of type\nchecking.\nMost of the deep learning libraries are written in Python. Due to\nthe dynamic nature of Python, the problem of the absence of type\n2https://stackoverflow.com/questions/37213388/keras-accuracy-does-not-change\nA Comprehensive Study on Deep Learning Bug Characteristics\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nAbsence of type checking\nAbsense of inter API compatibility\nAPI Change (APIC)\nAPI Misuse (APIM)\nConfusion with Computation Model(CCM)\nIncorrect Model Parameter or Structure (IPS)\nOthers\nStructure Ineffciency (SI)\nUnaligned Tensor (UT)\nFigure 3: Relation between Root Causes and Types of Bugs\nchecking is felt strongly in these libraries. The absence of type\nchecking leads to 30% of the bugs in Theano, 8% of the bugs in Keras\nand 15% of the bugs in Tensorflow.\n4.5\nAPI Change\nFinding 9: Tensorflow and Keras have 9% and 7% bugs due to API\nchange.\nIn deep learning libraries, API change tends to have a drastic effect.\nThese libraries are interdependent. So, API change in one library\nbreaks other libraries.\n4.6\nRoot Causes in Github data\nFinding 10: Except API Misuse all other root causes have similar\npatterns in both Github and Stack Overflow root causes of bugs.\nWe computed the P value at 95% significant level for both the Stack\nOverflow and Github data for all the root causes in the five libraries.\nWe see that, P value for API Misuse root cause is much less than 5%\nindicating API Misuse in Stack Overflow and Github has different\ndistribution compared to other root causes as we reject the null\nhypothesis. The other root causes are similar for both Stack Overflow\nand Github data as their P value is greater than 5%.\n4.7\nRelation of Root Cause with Bug Type\nFinding 11: SI contributes 3% - 52% and IPS contirbutes 24% - 62%\nof the bugs related to model.\nWe have seen from Figure 3 that most of the non model related\nbugs are caused by API Misuse (6% - 100%). Non Model Structural\nInitialization Bugs and Non Model Structural Processing Bugs are\ncaused by API Misuse in 100% of the time in our studied data.\nInterestingly in API Bug API Change plays the vital role (68%)\ncompared to API Misuse (20%); however, the model related bugs\nare more vulnerable to IPS and SI root causes. We see from Figure 3\nthat Structural Control and Sequence Bug, Structaral Data Flow\nBug, Structural Initialization Bug, Structural Logic Bug, Structural\nProcessing Bug which are related to model are caused by SI 31%,\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nCaffe\nKeras\nTF\nTheano\nTorch\nBad Performance\nCrash\nData Corruption\nHang\nIncorrect Functionality\nMemory Out of bound\nUnknown\nFigure 4: Distribution of Bug Effects in Stack Overflow\n3%, 10%, 33% and 53% of the times respectively and caused by IPS\n62%, 59%, 40%, 36%, 24% of the times respectively.\n5\nIMPACTS FROM BUGS\nIn this section, we explore the answer to RQ3 to understand the\nmajor effects of bugs in deep learning software. The normalized\ndistribution of effects of Stack Overflow is shown in Fig. 4. The\ndata in Table 4 shows the presence of different kinds of effects in\nboth Stack Overflow and Github for the deep learning libraries. We\ndiscuss some of the major effects of bugs in deep learning software\nin the rest of this section.\n5.1\nCrash\nFinding 12: In average more than 66% of the bugs cause crash of\nthe programs.\nOur analysis reveals that, the most severe effect of bugs is Crash. In\ndeep learning, the bugs mostly cause total failure of the program.\nIn all the libraries Crash is the top impact ranging from 40% - 77%\nas shown in Figure 4.\n5.2\nBad Performance\nFinding 13: In Caffe, Keras, Tensorflow, Theano, Torch 31%, 16%,\n8%, 11%, and 8% bugs caused bad performance respectively.\nBad performance is often a concern for deep learning software\ndevelopers. Even though the model trains successfully, during the\nevaluation or prediction phase the model may give very poor accu-\nracy in classifying the target classes.\nFor example, in the following code snippet the user had low\naccuracy after traning because of the use of incorrect value of\nparameter nb_words. The user should use nb_words + 1 instead\nof nb_words as answered by an expert. 3\n1\nembedded = Embedding ( nb_words ,\noutput_dim=hidden ,\ninput_length =\nmaxlen ) ( sequence )\n5.3\nIncorrect Functionality\nFinding 14: 12% of the bugs in average in the libraries cause\nIncorrect Functionality .\nIncorrect functionality happens when the behavior of the software\nreflects some unexplainable outcome which is not expected from\nthe logical organization of the model or from previous experience\nof the developer.\n3https://stackoverflow.com/questions/37817588/masking-for-keras-blstm\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nMd Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan\nTable 4: Effects of Bugs in Stack Overflow and Github\nCaffe\nKeras\nTF\nTheano\nTorch\nP value\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nSO\nGitHub\nBad Performance\n31% 19% 16% 14% 8%\n8% 11% 6%\n8% 24% 0.9152\nCrash\n40% 69% 61% 86% 77% 92% 70% 20% 60% 16% 0.7812\nData Corruption\n6%\n4%\n5%\n0%\n6%\n0%\n4%\n6%\n4% 16%\n0.948\nHang\n0%\n0%\n0%\n0%\n1%\n0%\n0%\n0%\n0%\n0%\n0.3466\nIncorrect Functionality 23% 8% 13% 0%\n7%\n0% 11% 59% 16% 42% 0.5418\nMemory Out of bound\n0%\n0%\n3%\n0%\n1%\n0%\n4%\n0%\n0%\n0%\n0.0844\nUnknown\n0%\n0%\n2%\n0%\n0%\n0%\n0%\n9% 12% 2%\n0.8419\nFor example, in the following code snippet the user wants to\nconvert the image to a 28 ∗28 Numpy array; however, the output is\na black image.4\n1\nwith\nt f . Session ( )\nas\ns e s s :\n2\nf i r s t _ i m a g e = mnist . t r a i n . images [ 0 ]\n3\nf i r s t _ i m a g e = np . array ( f i r s t _ i m a g e ,\ndtype = ' uint8 ' )\n4\np i x e l s = f i r s t _ i m a g e . reshape ( ( 2 8 ,\n28) )\n5\np l t . imshow ( p i x e l s ,\ncmap = ' gray ' )\nThe user got incorrect output because of casting a float array to\nuint8, which will convert all the pixels to 0 if they are less than\n1. To fix the problem, the user can multiply the array with 255 as\nsuggested by an answer. Theano has a higher percentage of posts\nabout incorrect functionality problems more common than bad\nperformance.\n5.4\nEffects of Bugs in Github\nFinding 15: For all the libraries the P value for Stack Overflow\nand Github bug effects reject the null hypothesis to confirm that the\nbugs have similar effects from Stack Overflow as well as Github bugs.\nThe P value is shown in Table 4 shows that Bad Performance in\nStack Overflow and Github have 79% of P value which indicates that\nthey are very similar. Crash has P value of 50% in Stack Overflow and\nGithub indicating they also can not reject the null hypothesis with\nstrong confidence. None of the impacts reject the null hypothesis\nat 95% significance level.\n6\nDIFFICULT DEEP LEARNING STAGES\nIn this section, we answer RQ4 by studying the bugs happening\nat the different stage of the deep learning pipeline. We use the\ncategorization of the posts about deep learning stages to analyze\nRQ4.\n6.1\nData Preparation\nFinding 16: 32% of the bugs are in the data preparation stage of\nthe deep learning pipeline.\nFrom Figure 5 we see, most of the bugs in deep learning program-\nming happen at the data preparation stage.\n6.2\nTraining stage\nFinding 17: 27% of the bugs are seen during the training stage.\nThe next stage where most bugs happen is the Training stage which\nis kind of expected. A lot of bugs related to IPS and SI are from the\ntraining stage.\n4https://stackoverflow.com/questions/42353676/display-mnist-image-using-matplotlib\nData Preparation\nChoice of Model\nTraining\nEvaluation\nHyper parameter tuning\nPrediction\n0\n5\n10\n15\n20\n25\n30\n35\nBugs (%)\nFigure 5: Bugs at different stages of the Deep Learning\npipeline\nKeras\nTensorflow\nCaffe\nTorch\nTheano\nTheano\nTorch\nCaffe\nTensorflow\nKeras\n0.99\n1\n0.72\n0.97\n0.97\n0.97\n0.68\n0.8\n0.68\n0.99\nCorrelation of Bug Type\n0.72\n0.78\n0.84\n0.90\n0.96\nFigure 6: Correlation of Bug Types among the libraries\n6.3\nChoice of model\nFinding 18: Choice of model stage shows 23% of the bugs.\nChoice of model is the third stage in terms of the likelihood to have\nbugs. In choice of model stage, we construct the model and chose\nthe right algorithm. Major root causes of bugs in this stage are IPS,\nSI, and UT.\n7\nCOMMONALITY OF BUG\nIn this section, we try to explore the answer to RQ5 to identify\nwhether there is any relationship among the bugs in different deep\nlearning libraries. Our primary hypothesis was that the libraries\nwill be strongly correlated based on the distribution of bugs as they\nare doing the similar tasks.\nOur analysis confirms that hypothesis as shown in Figure 6. We\nsee that the libraries have a strong correlation coefficient close to\n1. Surprisingly Torch has shown very weak correlation with other\nlibraries in terms of bug type. We then randomly studied the 30\nposts having codes for each of the libraries to see whether we notice\nany common antipatterns that can lead to this strong correlation\nof bug type.\nA Comprehensive Study on Deep Learning Bug Characteristics\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n50\nContinuous\nObsolescence\nCut and Paste\nProgramming\nDead Code\nGolden Hammer\nInput Kludge\nMushroom\nManagement\nSphagetti Code\n% of Antipattern\nCaffe\nKeras\nTensorflow\nTheano\nTorch\nFigure 7: Distribution of different antipatterns\nFinding 19: Tensorflow and Caffe have a similar distribution of\nantipatterns while Torch has different distributions of antipatterns.\nWe have identified the antipatterns through deeper analysis of\nthe Stack Overflow buggy codes for further investigating the strong\ncorrelation of Tensorflow and Caffe as well as the weak correlation\nof Torch and Caffe. The antipatterns found are Continuous Obso-\nlescence, Cut-and-Paste Programming, Dead Code, Golden\nHammer, Input Kludge, Mushroom Management, Spaghetti\nCode. This classification is taken from [2]. The distribution of differ-\nent antipatterns across the libraries is shown in Figure 7. We see that\nin Tensorflow and Caffe 30%+ of the antipatterns are Input Kludge.\nOn the other hand, in Torch 40% of the bugs happen due to the Cut-\nand-Paste Programming antipattern. This shows that the strong\ncorrelation between the distribution of bugs in Torch and Caffe can\nbe explained from the similarity of common antipatterns for these\ntwo libraries. The weak correlation between the distribution of\nTorch and Caffe bugs can be the result of a dissimilar distribution\nof antipatterns between these two libraries. For example, we see\nStack Overflow code snippets of Input Kludge antipatterns from\nTensorflow and Caffe in the example shown in Figure 8. Both of\nthese programs can be easily broken by user input and the program\ndoes not perform sanity check on the inputs.\n8\nEVOLUTION OF BUGS\nIn this section, we explore the answer to RQ6 to understand how\nthe bug patterns have changed over time.\n8.1\nPositive growth of Structural Logic Bugs\nFinding 20: In Keras, Caffe, Tensorflow Structural logic bugs are\nshowing increasing trend.\nFrom 2015 - 2018 Structural logic bugs in Caffe are respectively 30%,\n32%, 67%, 100% indicating structural logic bugs are being discussed\nmore by the developers since 2015. It is expected as deep learning\nstarted gaining increasing attention since 2015 and more developers\nstarted to use deep learning libraries to write software.\n8.2\nDecreasing trend of Data Bugs\nFinding 21: Data Bugs slowly decreased since 2015 except Torch.\nIn Torch Data Bugs stayed almost consistent maintaining close\nto 50% of the bugs in discussed in 2016-2018. In Keras Data Bugs\nslowly decreased from 27% - 15% since 2015. In Tensorflow Data\nBugs slowly decreased from 30% - 10% since 2015 - 2018. In the other\ntwo libraries also, the Data Bugs slowly decreased reaching close to\n0. The possible reason for this trend is the development of popular\nspecialized data libraries like pandas that enable exploratory data\nanalysis to understand the properties of data better. Besides, the\nuse of Tensor data type having type and shape information helps\nto get rid of some of the Data Bugs. Still more verification support\nin these libraries will help to get rid of these bugs.\n9\nTHREATS TO VALIDITY\nInternal threat. One internal threat to the validity of our results\ncould be our classification of the bugs. We used the classification\nscheme from a vetted taxonomy [5, 25] to classify the bugs. We also\nfollowed open coding scheme to add more types if needed. One\nPhD student was initially dedicated to go over all the posts to come\nup with additional classification scheme, if necessary. This whole\nprocess was monitored using pilot study. Another possible source of\nthe threat is that the labeling of the data can be biased. To mitigate\nthis threat two trained Ph.D. students independently studied the\nmisuse posts to label them. The inter-rater agreements was mea-\nsured using Cohen’s Kappa coefficient and the disagreements were\nreconciled under the monitoring of an expert. We conducted pilot\nstudy to continuously monitor the labeling process and conducted\nfurther training at 5% and 10% of the labeling where the Kappa\ncoefficient was close to 0% and 80%.\nExternal threat. An external threat can be the trustworthiness\nof the dataset we collected. To avoid low-quality posts we only\ncollected the posts that have score of at least 5. A score of 5 can be\na good metric to trust the post as a good discussion topic among\nthe programmer community that cannot merely be solved using\nsome Google search. The reputation of the users asking question\nabout deep learning can be another reason to question the quality\nof the posts. To alleviate this threat we have only studied top scored\nposts which are from users with different range of reputations (1 -\n150K+). This indicates that the posts are from users ranging from\nnewbie to experts.\n10\nDISCUSSION\nWe have seen in the analysis of RQ1 that most of the bugs in deep\nlearning programming are Data Bugs. These type of Bugs can have\ndrastic effect causing the program to crash as well as leading to\nbad performance. In general, we see the programmers have very\nlimited or no access to data verification tools. It is often confusing\nwhether the data is in right format needed by the model, whether\nthe variables are properly encoded or not, whether there are missing\ndata that can cause the model to fail, whether the train test split\nis good enough, whether the data is shuffled properly to avoid\ntraining bias etc. This finding suggests that development of data\nverification tools can help programmers solve a large number\nof data bugs. As deep learning models are strongly coupled with\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nMd Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan\n(a) Tensorflow Example of Input Kludge\n(b) Caffe Example of Input Kludge\nFigure 8: Example of similar antipattern in Tensorflow and Caffe\nFigure 9: Timeline of Evolution of Bugs\ndata, model analysis tool to explore whether a particular model\nis the right fit for the data in hand can help to resolve these strong\ncoupling of data and model related problems.\nWe have also seen while exploring RQ1 that structural logic\nbugs are the second major type of bugs. This happens due to wrong\nlogical organization of the model, hidden layers, using wrong codes,\netc. These kind of problems can be solved by some automated\nmodel and parameter recommendation tools. How to develop\nthese kind of tools need further research. A methodology could be\nto mine large scale open source code repositories and identify the\ncommon code patterns and suggest examples from common code\npatterns used in qualified code bases.\n11\nRELATED WORKS\nEmpirical Study on Bugs. Thung et al. [21] studied three machine\nlearning systems, Apache Mahout, Lucene, and OpenNLP and man-\nually categorize the bugs into different categories. They focused on\nbug frequencies, bug types, severity of the bug, bug-fixing duration,\nbug-fixing effort, and bug impact. Different from them, we focus\non bug types, bug root causes, and bug impact of five deep learning\nlibraries which are Tensorflow, Keras, Torch, Caffe, and Theano.\nZhang et al. [25] investigated bugs from deep learning applica-\ntions built on top of Tensorflow. They collected bugs from Stack\nOverflow questions and Github commits. Then, they manually stud-\nied the collected bugs based on three perspectives which are root\ncause, bug type, and impact. While Zhang et al. have certainly\ncharted the course, we have studied a cross-section of five deep\nlearning libraries with different design constraints. Furthermore,\nbesides root cause, bug type, and impact, we also focus on bugs in\ndeep learning stages which includes data preparation, modeling,\ntraining, evaluation, tuning, prediction. We have also studied some\ncommon antipatterns to explain the strong correlation of bugs in\nthese libraries as bugs have strong relation to antipatterns [19].\nThere are some empirical studies focused on specific types of\nbugs. Lu et. al. [17] studied real-world concurrency bug character-\nistics. Gao et. al. [10] conducted an empirical study on recovery\nbugs in large-scale distributed systems. API changes problems was\nstudied by [4, 9, 14, 15]. Our work focuses on the bugs in the usage\nof deep learning libraries.\nBugs classification. Classification of API-misuse from different\nperspectives and domains have been done previously. Classification\nof software defects by IEEE served as the basis for IBM’s orthogonal\ndefect classification (ODC) as discussed in [6]. The defect types\ninclude conceptual program elements which are function, check,\ndocumentation, assignment, algorithm and violation type. More re-\ncently, [23] presents a Python predictive analysis. Their tool is able\nto detect 46 bugs with 16 unreported before and they also classify\nthose bugs base on their defect in the Python program. Our study\nfocus on deep learning bugs, we classify the bugs based on bug\ntype, root cause, and effect.\nStack Overflow and Github study. Meldrum et. al. [18] studied\n266 papers using Stack Overflow platforms to show the growing\nimpact of Stack Overflow on software engineering research. Kavaler\n[13, 16] used Stack Overflow to analyze Android APIs. Barua et. al.\n[3] analyzed the textual content of Stack Overflow discussions to\nunderstand the thoughts and needs of developers. These works\nhave not studied bugs in deep learning software.\n12\nCONCLUSION\nAlthough deep learning has gained much popularity and strong\ndeveloper community in recent years, developing software using\nexisting deep learning libraries can be error-prone. In this paper, we\nhave presented an empirical study to explore the bugs in software\nusing deep learning libraries. In our study we have studied 2716\nA Comprehensive Study on Deep Learning Bug Characteristics\nESEC/FSE 2019, 26–30 August, 2019, Tallinn, Estonia\nqualified Stack Overflow posts and 500 Github bug fix commits\nto identify the bug types, root causes of bugs, effects of bugs in\nusage of deep learning. We have also performed an inter-stage\nanalysis to identify the stages of deep learning pipeline that are\nmore vulnerable to bugs. We have also studied the buggy codes in\nStack Overflow to find antipatterns leading to bugs to understand\nthe strong correlation of the bug types in deep learning libraries.\nOur study found that data bug and logic bug are the most severe\nbug types in deep learning software appearing more than 50% of\nthe times. Major root causes of these bugs are Incorrect Model\nParameter (IPS) and Structural Inefficiency (SI). Last but not least,\nbugs in the usage of deep learning libraries are strongly correlated.\nREFERENCES\n[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey\nDean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al.\n2016. TensorFlow: A System for Large-Scale Machine Learning.. In OSDI, Vol. 16.\n265–283.\n[2] Alexander Shvets. 2017. Software Development AntiPatterns. (2017). https:\n//sourcemaking.com/antipatterns/software-development-antipatterns.\n[3] Anton Barua, Stephen W Thomas, and Ahmed E Hassan. 2014. What are devel-\nopers talking about? an analysis of topics and trends in stack overflow. Empirical\nSoftware Engineering 19, 3 (2014), 619–654.\n[4] Gabriele Bavota, Mario Linares-Vasquez, Carlos Eduardo Bernal-Cardenas, Mas-\nsimiliano Di Penta, Rocco Oliveto, and Denys Poshyvanyk. 2015. The impact\nof api change-and fault-proneness on the user ratings of android apps. IEEE\nTransactions on Software Engineering 41, 4 (2015), 384–407.\n[5] Boris Beizer. 1984. Software system testing and quality assurance. Van Nostrand\nReinhold Co.\n[6] Ram Chillarege, Inderpal S. Bhandari, Jarir K. Chaar, Michael J. Halliday, Di-\nane S. Moebus, Bonnie K. Ray, and Man-Yuen Wong. 1992. Orthogonal Defect\nClassification-A Concept for In-Process Measurements. IEEE Trans. Softw. Eng.\n18, 11 (Nov. 1992), 943–956. https://doi.org/10.1109/32.177364\n[7] François Chollet et al. 2015. Keras. https://github.com/fchollet/keras. (2015).\n[8] Ronan Collobert, Samy Bengio, and Johnny Mariéthoz. 2002. Torch: a modular\nmachine learning software library. Technical Report. Idiap.\n[9] Danny Dig and Ralph Johnson. 2006. How do APIs evolve? A story of refactoring.\nJournal of software maintenance and evolution: Research and Practice 18, 2 (2006),\n83–107.\n[10] Yu Gao, Wensheng Dou, Feng Qin, Chushu Gao, Dong Wang, Jun Wei, Ruirui\nHuang, Li Zhou, and Yongming Wu. 2018. An empirical study on crash recovery\nbugs in large-scale distributed systems. In Proceedings of the 2018 26th ACM Joint\nMeeting on European Software Engineering Conference and Symposium on the\nFoundations of Software Engineering. ACM, 539–550.\n[11] David Gómez and Alfonso Rojas. 2016. An empirical overview of the no free\nlunch theorem and its effect on real-world machine learning classification. Neural\ncomputation 28, 1 (2016), 216–228.\n[12] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long,\nRoss Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Convolu-\ntional architecture for fast feature embedding. In Proceedings of the 22nd ACM\ninternational conference on Multimedia. ACM, 675–678.\n[13] David Kavaler, Daryl Posnett, Clint Gibler, Hao Chen, Premkumar Devanbu, and\nVladimir Filkov. 2013. Using and asking: Apis used in the android market and\nasked about in stackoverflow. In International Conference on Social Informatics.\nSpringer, 405–418.\n[14] Raula Gaikovina Kula, Ali Ouni, Daniel M German, and Katsuro Inoue. 2018. An\nempirical study on the impact of refactoring activities on evolving client-used\nAPIs. Information and Software Technology 93 (2018), 186–199.\n[15] Jun Li, Yingfei Xiong, Xuanzhe Liu, and Lu Zhang. 2013. How does web service\nAPI evolution affect clients?. In 2013 IEEE 20th International Conference on Web\nServices. IEEE, 300–307.\n[16] Mario Linares-Vásquez, Gabriele Bavota, Massimiliano Di Penta, Rocco Oliveto,\nand Denys Poshyvanyk. 2014. How do api changes trigger stack overflow dis-\ncussions? a study on the android sdk. In proceedings of the 22nd International\nConference on Program Comprehension. ACM, 83–94.\n[17] Shan Lu, Soyeon Park, Eunsoo Seo, and Yuanyuan Zhou. 2008. Learning from\nmistakes: a comprehensive study on real world concurrency bug characteristics.\nIn ACM SIGARCH Computer Architecture News, Vol. 36. ACM, 329–339.\n[18] Sarah Meldrum, Sherlock A Licorish, and Bastin Tony Roy Savarimuthu. 2017.\nCrowdsourced Knowledge on Stack Overflow: A Systematic Mapping Study. In\nProceedings of the 21st International Conference on Evaluation and Assessment in\nSoftware Engineering. ACM, 180–185.\n[19] Seyyed Ehsan Salamati Taba, Foutse Khomh, Ying Zou, Ahmed E Hassan, and\nMeiyappan Nagappan. 2013. Predicting bugs using antipatterns. In 2013 IEEE\nInternational Conference on Software Maintenance. IEEE, 270–279.\n[20] The Theano Development Team, Rami Al-Rfou, Guillaume Alain, Amjad Alma-\nhairi, Christof Angermueller, Dzmitry Bahdanau, Nicolas Ballas, Frédéric Bastien,\nJustin Bayer, Anatoly Belikov, et al. 2016. Theano: A Python framework for\nfast computation of mathematical expressions. arXiv preprint arXiv:1605.02688\n(2016).\n[21] Ferdian Thung, Shaowei Wang, David Lo, and Lingxiao Jiang. 2012. An empiri-\ncal study of bugs in machine learning systems. In 2012 IEEE 23rd International\nSymposium on Software Reliability Engineering. IEEE, 271–280.\n[22] Anthony J Viera, Joanne M Garrett, et al. 2005. Understanding interobserver\nagreement: the kappa statistic. Fam med 37, 5 (2005), 360–363.\n[23] Zhaogui Xu, Peng Liu, Xiangyu Zhang, and Baowen Xu. 2016. Python predic-\ntive analysis for bug detection. In Proceedings of the 2016 24th ACM SIGSOFT\nInternational Symposium on Foundations of Software Engineering. ACM, 121–132.\n[24] Yufeng Guo. 2017.\nThe 7 Steps of Machine Learning.\n(2017).\nhttps:\n//towardsdatascience.com/the-7-steps-of-machine-learning-2877d7e5548e.\n[25] Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang.\n2018. An empirical study on TensorFlow program bugs. In Proceedings of the 27th\nACM SIGSOFT International Symposium on Software Testing and Analysis. ACM,\n129–140.\n",
  "categories": [
    "cs.SE",
    "cs.LG"
  ],
  "published": "2019-06-03",
  "updated": "2019-06-03"
}