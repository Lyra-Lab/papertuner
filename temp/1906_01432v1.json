{
  "id": "http://arxiv.org/abs/1906.01432v1",
  "title": "Knowledge-augmented Column Networks: Guiding Deep Learning with Advice",
  "authors": [
    "Mayukh Das",
    "Devendra Singh Dhami",
    "Yang Yu",
    "Gautam Kunapuli",
    "Sriraam Natarajan"
  ],
  "abstract": "Recently, deep models have had considerable success in several tasks,\nespecially with low-level representations. However, effective learning from\nsparse noisy samples is a major challenge in most deep models, especially in\ndomains with structured representations. Inspired by the proven success of\nhuman guided machine learning, we propose Knowledge-augmented Column Networks,\na relational deep learning framework that leverages human advice/knowledge to\nlearn better models in presence of sparsity and systematic noise.",
  "text": "Knowledge-augmented Column Networks: Guiding Deep Learning with Advice\nMayukh Das 1 Devendra Singh Dhami 1 Yang Yu 1 Gautam Kunapuli 1 Sriraam Natarajan 1\nAbstract\nRecently, deep models have had considerable suc-\ncess in several tasks, especially with low-level\nrepresentations. However, effective learning from\nsparse noisy samples is a major challenge in most\ndeep models, especially in domains with struc-\ntured representations. Inspired by the proven suc-\ncess of human guided machine learning, we pro-\npose Knowledge-augmented Column Networks, a\nrelational deep learning framework that leverages\nhuman advice/knowledge to learn better models\nin presence of sparsity and systematic noise.\n1. Introduction\nThe re-emergence of Deep Learning (Goodfellow et al.,\n2016) has demonstrated signiﬁcant success in difﬁcult real-\nworld domains such as image (Krizhevsky et al., 2012),\naudio (Lee et al., 2009) and video processing (Yue-Hei Ng\net al., 2015). Deep Learning is recently being increasingly\napplied to structured domains, where the data is represented\nusing richer symbolic or graph features to capture relational\nstructure between entities and attributes in the domain. Such\nmodels are able to capture increasingly complex interactions\nbetween features with deeper layers. However, the combi-\nnatorial complexity of reasoning over a large number of\nrelations and objects has remains a signiﬁcant bottleneck to\novercome.\nWhile recent work in relational deep learning seeks to ad-\ndress the problem of faithful modeling of relational structure\n(Kazemi & Poole, 2018; ˇSourek et al., 2015; Kaur et al.,\n2017), we focus on Column Networks (CLNs) (Pham et al.,\n2017) which are deep architectures composed of several\n(feedforward) mini-columns, each of which represents an\nentity in the domain. Relationships between two entities are\nmodeled through edges between mini-columns. The true\npower of column networks come from natural modeling\nof long-range inter-entity interactions with progressively\ndeeper layers and have been successfully applied to col-\n1University of Texas, Dallas. Correspondence to: Mayukh Das\n<mayukh.das1@utdallas.edu>.\n2019 ICML Workshop on Human in the Loop Learning (HILL\n2019), Long Beach, USA. Copyright by the author(s).\nlective classiﬁcation tasks. However, CLNs rely on large\namounts of data and incorporate little to no knowledge about\nthe problem domain. While this may sufﬁce for low-level ap-\nplications such as image/video processing, it is a concern in\nrelational domains consisting of rich, semantic information.\nBiasing the learners is necessary in order to allow them\nto inductively leap from training instances to true general-\nization over new instances (Mitchell, 1980). While deep\nlearning does incorporate one such bias in the form of do-\nmain knowledge (for example, through parameter tying or\nconvolution, which exploits neighborhood information), we\nare motivated to develop systems that can incorporate richer\nand more general forms of domain knowledge. This is espe-\ncially germane for deep relational models as they inherently\nconstruct and reason over richer representations.\nOne way in which a human can guide learning is by provid-\ning rules over training examples and features (Shavlik &\nTowell, 1989; Towell & Shavlik, 1994; Fung et al., 2003;\nKunapuli et al., 2010). Another way that has been studied\nextensively is expressing preferences within the preference-\nelicitation framework (Braziunas & Boutilier, 2006). We are\ninspired by this form of advice as they have been successful\nwithin the context of inverse reinforcement learning (Kuna-\npuli et al., 2013), imitation learning (Odom et al., 2015) and\nplanning (Das et al., 2018).\nThe motivation for our approach is as follows: to develop a\nframework that allows a human to guide deep learning by\nincorporating rules and constraints that deﬁne the domain\nand its aspects. Incorporation of prior knowledge into deep\nlearning has begun to receive interest recently (Ding et al.,\n2018). However, in many such approaches, the guidance is\nnot through a human, but rather through a pre-processing\nalgorithm to generate guidance. Our framework is much\nmore general, in that a domain expert provides guidance\nduring learning. We exploit the rich representation power\nof relational methods to capture, represent and incorporate\nsuch rules into relational deep learning models.\nWe make the following contributions: (1) we propose the\nformalism of Knowledge-augmented Column Networks (K-\nCLN), (2) we present an approach to inject generalized\ndomain knowledge in a CLN and develop the learning strat-\negy that exploits this knowledge, and (3) we demonstrate,\nacross two real problems, in some of which CLNs have been\narXiv:1906.01432v1  [cs.LG]  31 May 2019\nKnowledge-augmented Column Networks: Guiding Deep Learning with Advice\npreviously employed, the effectiveness and efﬁciency of in-\njecting domain knowledge. Speciﬁcally, our results across\nthe domains clearly show statistically superior performance\nwith small amounts of data. As far as we are aware, this is\nthe ﬁrst work on human-guided CLNs.\n2. Knowledge-augmented Column Networks\nColumn Networks (Pham et al., 2017) allow for encoding in-\nteractions/relations between entities as well as the attributes\nof such entities in a principled manner without explicit re-\nlational feature construction or vector embedding. This is\nimportant when dealing with structured domains, especially,\nin the case of collective classiﬁcation. This enables us to\nseamlessly transform a multi-relational knowledge graph\ninto a deep architecture making them one of the robust rela-\ntional deep models. Figure 1 illustrates an example column\nnetwork, w.r.t. the knowledge graph on the left. Note how\neach entity forms its own column and relations are captured\nvia the sparse inter-column connectors.\nConsider a graph G = (V, A), where V = {ei}|V |\ni=1 is the\nset of vertices/entities. A is the set of arcs/edges between\ntwo entities ei and ej denoted as r(ei, ej). Also, G is multi-\nrelational, i.e., r ∈R where R is the set of relation types\nin the domain. To obtain the equivalent Column Network\nC from G, let xi be the feature vector representing the at-\ntributes of an entity ei and yi its label predicted by the\nmodel1. ht\ni denotes a hidden node w.r.t. entity ei at the hid-\nden layer t (t = 1, . . . , T is the index of the hidden layers).\nAs mentioned earlier, the context between 2 consecutive lay-\ners captures the dependency of the immediate neighborhood\n(based on arcs/edges/inter-column connectors). For entity\nei, the context w.r.t. r and hidden nodes are computed as,\nct\nir =\n1\n|Nr(i)|\nX\nj∈Nr(i)\nht−1\nj\n;\n(1)\nht\ni = g\n \nbt + W tht−1\ni\n+ 1\nz\nX\nr∈R\nV t\nr ct\nir\n!\n(2)\nwhere Nr(i) are all the neighbors of ei w.r.t.\nr in the\nknowledge graph G. Note the absence of context connec-\ntors between ht\n2 and ht\n4 (Figure 1, right) since there does\nnot exist any relation between e2 and e4 (Figure 1, left).\nThe activation of the hidden nodes is computed as the sum\nof the bias, the weighted output of the previous hidden\nlayer and the weighted contexts where W t ∈RKt×Kt1 and\nV t\nr ∈RKt×Kt1 are weight parameters and bt is a bias for\nsome activation function g. z is a pre-deﬁned constant that\ncontrols the parameterized contexts from growing too large\nfor complex relations. Setting z to the average number of\nneighbors of an entity is a reasonable assumption. The ﬁnal\n1∵i uniquely indexes ei, we use ei and i interchangeably\noutput layer is a softmax over the last hidden layer.\nP(yi = ℓ|hT\ni ) = softmax\n\u0000bl + WlhT\ni\n\u0001\n(3)\nwhere ℓ∈L is the label (L is the set of labels) and T is the\nindex of the last hidden layer.\nWhile CLNs are relation-aware deep models that can repre-\nsent and learn from structured data faithfully, they are not\ndevoid of limitations, especially the challenges of effective\nlearning with sparse samples or systematic noise. Several\napproaches (Jiang et al., 2018; Goldberger & Ben-Reuven,\n2017; Miyato et al., 2018) enable effective learning of deep\nmodels in presence of noise, however our problem setting is\nsigniﬁcantly different, due to - [(1) Type of noise]: we aim\nto handle systematic/targeted noise (Odom & Natarajan,\n2018b). It occurs frequently in real-world due to cognitive\nbias or sample sparsity. [(2) Type of error]: Systematic\nnoise leads to generalization errors. [(3) Structured data]:\nK-CLN works in the context of structured data (enti-\nties/relations). Structured/relational data, thought crucial, is\ninherently sparse (most relations are false in the real world).\nGiven: A sparse multi-relational graph G, attributes xi\nof each entity (sparse or noisy) in G, equivalent Column-\nNetwork C and access to a Human-expert\nTo Do: More effective and efﬁcient collective classiﬁ-\ncation by knowledge augmented training of C(θ), where\nθ = ⟨{W t}T\n1 , {V t\nr }t=T\nr∈R;t=1, {Wℓ}ℓ∈L⟩is the set of all\nthe network parameters of the Column Network.\nTo this effect we propose Knowledge-augmented CoLumn\nNetwork that incorporates human advice into deep models\nin a principled manner using a gated architecture, where\n‘Advice Gates’ augment/modify the trained network\nparameters based on the advice.\n2.1. Knowledge Representation\nAny model speciﬁc encoding of domain knowledge, such as\nnumeric constraints or modiﬁed loss functions etc., has sev-\neral limitations, namely (1) counter-intuitive to the humans\nsince they are domain experts and not experts in machine\nlearning (2) the resulting framework is brittle and not gener-\nalizable. Consequently, we employ preference rules (akin\nto IF-THEN statements) to capture human knowledge.\nDeﬁnition 1 A preference is a modiﬁed Horn clause,\n∧k,xAttrk(Ex) ∧. . . ∧r∈R,x,y r(Ex, Ey) ⇒[label(Ez, ℓ1) ↑;\nlabel(Ek, ℓ2) ↓]\nwhere ℓ1, ℓ2 ∈L and the Ex are variables over entities,\nAttrk(Ex) are attributes of Ex and r is a relation. ↑and\n↓indicate the preferred non-preferred labels respectively.\nQuantiﬁcation is implicitly ∀and hence dropped. We denote\na set of preference rules as P.\nKnowledge-augmented Column Networks: Guiding Deep Learning with Advice\nFigure 1. Original Column network (diagram source: (Pham et al., 2017))\nFigure 2. K-CLN architecture\n2.2. Knowledge Injection\nGiven that knowledge is provided as partially-instantiated\npreference rules P, more than one entity may satisfy a pref-\nerence rule. Also, more than one preference rules may be\napplicable for a single entity. The key idea is that we aim to\nconsider the error of the trained model w.r.t. both the data\nand the advice. Consequently, in addition to the “data gra-\ndient” as with original CLNs, there is a “advice gradient”.\nThis gradient acts a feedback to augment the learned weight\nparameters (both column and context weights) towards the\ndirection of the advice gradient. It must be mentioned that\nnot all parameters will be augmented. Only the parame-\nters w.r.t. the entities and relations (contexts) that satisfy P\nshould be affected. Let P be the set of entities and relations\nthat satisfy the set of preference rules P. The hidden nodes\n(equation 1) can now be expressed as,\nht\ni = g\n \nbt + W tht−1\ni\nΓ(W )\ni\n+ 1\nz\nX\nr∈R\nV t\nr ct\nirΓ(c)\nir\n!\ns.t. Γi, Γi,r =\n(\n1\nif i, r /∈P\nF(α∇P\ni )\nif i, r ∈P\n(4)\nwhere i ∈P and Γ(W )\ni\nand Γ(c)\nir are advice-based soft gates\nwith respect to a hidden node and its context respectively.\nF() is some gating function, ∇P\ni is the “advice gradient”\nand α is the trade-off parameter explained later. The key\naspect of soft gates is that they attempt to enhance or de-\ncrease the contribution of particular edges in the column\nnetwork aligned with the direction of the “advice gradi-\nent”. We choose the gating function F() as an exponen-\ntial [F(α∇P\ni ) = exp (α∇P\ni )]. The intuition is that soft\ngates are natural, as they are multiplicative and a posi-\ntive gradient will result in exp (α∇P\ni ) > 1 increasing the\nvalue/contribution of the respective term, while a negative\ngradient results in exp (α∇P\ni ) < 1 pushing them down.\nWe now present the “advice gradient” (the gradient with\nrespect to preferred labels).\nProposition 1 Under the assumption that the loss function\nwith respect to advice / preferred labels is a log-likelihood,\nof the form LP = log P(y(P)\ni\n|hT\ni ), then the advice gradient\nis, ∇P\ni = I(y(P)\ni\n)−P(yi), where y(P)\ni\nis the preferred label\nof entity and i ∈P and I is an indicator function over the\npreferred label. For binary classiﬁcation, the indicator is\ninconsequential but for multi-class scenarios it is essential\n(I = 1 for preferred label ℓand I = 0 for L \\ ℓ).\nAn entity can satisfy multiple advice rules. So we take\nthe most preferred label. In case of conﬂicting advice (i.e.\ndifferent labels are equally advised), we set the advice label\nto be the label given by the data, y(P)\ni\n= yi.\nProposition 2 Given that the loss function Hi of original\nCLN is cross-entropy (binary or sparse-categorical for the\nbinary and multi-class prediction cases respectively) and\nthe objective with respect to advice is log-likelihood, the\nfunctional gradient of the modiﬁed objective for K-CLN is,\n∇(H′\ni) =(1 −α)\n\u0000yiI −P(yi|hT )\n\u0001\n+ α(IP\ni −P(yP\ni |hT ))\n=(1 −α)∇i + α∇P\ni\n(5)\nwhere 0 ≤α ≤1 is the trade-off parameter between the\neffect of data and effect of advice, Ii and IP\ni are the indi-\ncator functions on the label w.r.t. the data and the advice\nrespectively and ∇i and ∇P\ni are the gradients, similarly,\nw.r.t. data and advice respectively.\nHence, it follows from Proposition 2 that the data and the\nadvice balances the training of the K-CLN network param-\neters θP via the trade-off hyperparameter α. When data is\nnoisy (or sparse with negligible examples for a region of the\nparameter space) the advice (if correct) induces a bias on\nthe output distribution towards the correct label. Even\nif the advice is incorrect, the network still tries to learn\nthe correct distribution to some extent from the data (if not\nnoisy). The contribution of the effect of data versus the ef-\nfect of advice will primarily depend on α. If both the data\nand human advice are sub-optimal (noisy), the correct\nlabel distribution is not even learnable. We exclude the\nformal proofs due to space limitation.\n2.3. The Algorithm\nAlgorithm 1 outlines the key steps involved in our approach.\nIt trains a Column Network using both the data (the knowl-\nKnowledge-augmented Column Networks: Guiding Deep Learning with Advice\nAlgorithm 1 Knowledge-augmented CoLumn Networks\nRequire: Knowledge graph G, Column network C(θ), Ad-\nvice P, Trade-off α\n1: K-CLN CP(θP) ←C(θ)\n2: Initialize parameters of K-CLN θP ←{0}\n3: MP = ⟨MW , Mc, Mlabel⟩←CREATEMASK(G, P)\n4: Initial gradients @ epoch 0 ∀i ∇P\ni,0 = 0; i ∈P\n5: for epochs k=1 to convergence do\n6:\nGet advice gradients ∇P\ni,(k−1) w.r.t. prev. epoch k−1\n7:\nGates ΓP\ni , ΓP\ni,r ←exp (α∇P\ni × MP\ni )\n8:\nTrain CP using Equation 4; Update θP\n9:\nCompute ∀i P(yi) from CP for current epoch k\n10:\nStore ∀i ∇P\ni,k ←I(y(P)\ni\n) −P(yi) using Mlabel\n11: end for\n12: return K-CLN CP\nedge graph G) and the human advice (set of preference rules\nP). It returns a K-CLN CP where θP are the network pa-\nrameters. As described earlier, the network parameters of K-\nCLN (same as CLN) are manipulated (stored and updated)\nvia tensor algebra with appropriate indexing for entities and\nrelations. Also recall that our gating functions are piece-\nwise/non-smooth and apply only to the subspace of entities,\nfeatures and relations where the preference rules are satis-\nﬁed. Thus, as a pre-processing step, we create tensor masks\nthat compactly encode such a subspace with a call to the\nprocedure CREATEMASK(), explained later. At the end of\nevery epoch the output probabilities and the gradients are\ncomputed and stored in a shared data structure [line: 10] for\ncomputing advice gates in the next epoch. Rest of the train-\ning strategy is similar original CLN, except modiﬁed hidden\nunits (Equation 4) [line: 8] and data and advice trade-off\nparameter α.\nProcedure CREATEMASK() constructs the advice tensor\nmask(s) over the space of entities, features and rela-\ntions/contexts, based on the advice rules, that are required\nto compute the gates. The main components are - (1) The\nentity mask MW (|entities| × |feature| tensor) that indi-\ncates entity and feature indexes affected by the preferences;\n(2) The context mask Mc (|entities| × |entities|) which\nindicates the affected contexts/relations; (3) The label mask\nMlabel stores the preferred label of the affected entities, in\none-hot encoding. Advice mask computation requires efﬁ-\ncient satisﬁability checking for each preference rule against\nthe knowledge graph. We solve this via efﬁcient subgraph\nmatching proposed by Das et al. (2019). The masks are\nbinary with 1 encoding true and 0 encoding false.\n3. Experiments\nWe investigate the following questions as part of our ex-\nperiments, - [Q1] Can K-CLNs learn effectively with noisy\nsparse samples i.e., performance? [Q2] Can K-CLNs learn\nefﬁciently with noisy sparse samples i.e., speed of learning?\n[Q3] How does quality of advice affect the performance of\nK-CLN i.e., reliance on robust advice? We compare against\nthe original Column Networks architecture with no advice2\nas a baseline. We show how advice/knowledge can guide\nmodel learning towards better predictive performance and\nefﬁciency, in the context of collective classiﬁcation using\nColumn Networks.\n3.1. Experimental Setup\nSystem: K-CLN has been developed by extending origi-\nnal CLN architecture, which uses Keras as the functional\ndeep learning API with a Theano backend for tensor ma-\nnipulation. We extend this system to include: (1) advice\ngradient feedback at the end of every epoch, (2) modiﬁed\nhidden layer computations and (3) a pre-processing wrapper\nto parse the advice/preference rules and create appropriate\ntensor masks. Since it is not straightforward to access ﬁnal\nlayer output probabilities from inside any hidden layer using\nkeras, we use Callbacks to write/update the predicted proba-\nbilities to a shared data structure at the end of every epoch.\nRest of the architecture follows from original CLNs. The\nadvice masks encode P, i.e., the set of entities and contexts\nwhere the gates are applicable.\nDomains: We evaluate our approach on two relational\ndomains – Pubmed Diabetes, a multi-class classiﬁcation\nproblem and Internet Social Debates, a binary classiﬁcation\nproblem. Pubmed Diabetes3 is a citation network for pre-\ndicting whether a peer-reviewed article is about Diabetes\nType 1, Type 2 or none, using textual features (TF-IDF vec-\ntors) from 19717 pubmed abstracts. It comprises articles,\nconsidered as an entities, with 500 bag-of-words textual fea-\ntures (TF-IDF weighted word vectors), and 44, 338 citation\nrelationships among each other. Internet Social Debates4\nis a data set for predicting stance (‘for’/‘against’) about a\ndebate topic from online posts on social debates. It contains\n6662 posts (entities) characterized by TF-IDF vectors, ex-\ntracted from the text and header, and ∼25000 relations of\n2 types, ‘sameAuthor’ and ‘sameThread’.\nMetrics: Following (Pham et al., 2017), we report micro-F1\nscore, which aggregates the contributions of all classes to\ncompute the average F1 score, for the multi-class problem\nand AUC-PR for the binary one. We use 10 hidden layers\nand 40 hidden units per column in each layer. All results\nare averaged over 5 runs and our settings are consistent with\noriginal CLN.\nHuman Advice: K-CLN can handle arbitrarily complex\nadvice (encoded as preference rules). However, even with\n2Vanilla CLN indicates original architecture (Pham et al., 2017)\n3https://linqs.soe.ucsc.edu/data\n4http://nldslab.soe.ucsc.edu/iac/v2/\nKnowledge-augmented Column Networks: Guiding Deep Learning with Advice\nFigure 3. [Pubmed Diabetes publication prediction (multi-class)] Learning curves - Micro-F1, (Left) w.r.t. training epochs at 24% (of\ntotal) sample, (Right) w.r.t. varying sample sizes [best viewed in color].\nFigure 4. [Internet Social debate stance prediction (binary class)] Learning curves - Micro-F1, (Top) w.r.t. training epochs at 24% (of\ntotal) sample, (Bottom) w.r.t. varying sample sizes [best viewed in color].\nsome relatively simple rules K-CLN is effective in sparse\nsamples. For instance, in Pubmed, the longest preference\nrule used is, HasWord(e1, ‘fat′) ∧HasWord(e1, ‘obese′)\n∧Cites(e2, e1) ⇒label(e2, type2) ↑. This simply in-\ndicates an article citing another one discussing obesity. is\nlikely about Type2 diabetes, Expert knowledge from real\nphysicians can thus, prove to be even more effective. Note\nthat sub-optimal advice may lead to a wrong direction of\nthe Advice Gradient. However, since the data balances the\neffect of advice during training as shown by (Patrini et al.,\n2017), our soft gates do not alter the loss but instead pro-\nmote/demote the contribution of nodes/contexts.\n3.2. Experimental Results\nOur goal is to demonstrate the efﬁciency and effectiveness\nof K-CLNs with smaller set of training examples. Hence,\nwe present the aforementioned metrics with varying sam-\nple size and with varying epochs and compare our model\nagainst Vanilla CLN. We split the data sets into a training\nset and a hold-out test set with 60%-40% ratio. For varying\nepochs we only learn on 40% of our training set (i.e., 24%\nof the complete data) to train the model with varying epochs\nand test on the hold-out test set. Figures 3 (Left) and 4\n(Left) illustrate the micro-F1 scores with varying epochs\nfor PubMed diabetes and internet social debate data sets\nresp. K-CLN converges signiﬁcantly faster (less epochs),\nat times, with better predictive performance at convergence\nwhich shows that K-CLNs learn more efﬁciently with noisy\nsparse samples thereby answering (Q1) afﬁrmatively.\nEffectiveness of K-CLN is illustrated by its performance\nwith respect to the varying sample sizes of the training set,\nespecially in the low sample ranges. The intuition is, do-\nmain knowledge should help guide the model to learn better\nwhen the amount of training data available is small. K-\nCLN is trained on gradually varying sample size from 5%\nof the training data (3% of the complete data) till 80% of\nthe training data (48% of complete data) and tested on the\nhold-out test set. Figures 3 (Right) and 4 (Right) present\nthe micro-F1 with varying sample sizes for PubMed dia-\nbetes and internet social debate respectively.For internet\nsocial debate stance prediction, K-CLN outperforms Vanilla\nCLN with all sample sizes lower than, approximately, 35%.\nHowever, in case of PubMed, K-CLN outperforms Vanilla\nCLN for all sample sizes we experimented with, thus an-\nswering (Q2) afﬁrmatively. K-CLNs learn effectively with\nnoisy sparse samples.\nKnowledge-augmented Column Networks: Guiding Deep Learning with Advice\n(a) F1 (varying sample & α)\n(b) AUC-PR (varying sample & α)\nFigure 5. Performance, F1 and AUC-PR, of K-CLN on Internet Social Debates data set across different sample sizes, with varying\ntrade-off parameter α (on the advice gradient). Note that the advice here is incorrect/sub-optimal. α = 0 has the same performance as\nno-advice (Vanilla CLN), hence not plotted.\nAn obvious question that will arise is – how robust is our\nlearning system to that of noisy/incorrect advice? Con-\nversely, how does the choice of α affect the quality of the\nlearned model? To answer these questions speciﬁcally, we\nperformed an additional experiment on the Internet Social\nDebates domain by augmenting the learner with incorrect\nadvice. This incorrect advice is essentially created by chang-\ning the preferred label of the advice rules to incorrect values\n(based on our understating). Also, recall that the contribu-\ntion of advice is dependent on the trade-off parameter α,\nwhich controls the robustness of K-CLN to advice quality.\nConsequently, we experimented with different values of α\n(0.2, 0.4, . . . , 1.0), across varying sample sizes.\nFigure 5 shows how with higher α values the performance\ndeteriorates due to the effect of noisy advice. α = 0 is not\nplotted since the performance is same as no-advice/Vanilla\nCLN. Note that with reasonably low values of α = 0.2, 0.4,\nthe performance does not deteriorate much and is, in fact,\nbetter in some samples. Thus with reasonably low values\nof α K-CLN is robust to quality of advice (Q3). We picked\none domain to present the results of this robustness but have\nobserved similar behavior in both the domains. These exper-\niments empirically support our theoretical analysis (Propo-\nsition 2). We found that when α ≤0.5, K-CLN performs\nwell even with noisy advice. In the earlier experiments\nwhere we use potentially good advice, we report the results\nwith α = 1, So it is reasonable to assign higher weight\nto the advice and the contribution of the entities and rela-\ntions/contexts affected by it, given the advice is noise-free.\nAlso, note that the drop in performance towards very low\nsample sizes (in Figure 5) highlights how learning is chal-\nlenging in the noisy-data and noisy-advice scenario. This\naligns with our general understanding of most human-in-\nthe-loop/advice-based approaches in AI. Trade-off between\ndata and advice via a weighted combination of both is a\nwell studied solution in related literature (Odom & Natara-\njan, 2018a) and, hence, we adapt the same in our context.\nTracking the expertise of humans to infer advice quality is\nan interesting future research direction.\n4. Conclusion\nWe considered the problem of providing guidance for CLNs.\nSpeciﬁcally, inspired by treating the domain experts as true\ndomain experts and not CLN experts, we developed a for-\nmulation based on preferences. This formulation allowed\nfor natural speciﬁcation of guidance. We derived the gradi-\nents based on advice and outlined the integration with the\noriginal CLN formulation. Our initial evaluation across a\ncouple of domains clearly demonstrate the effectiveness and\nefﬁciency of the approach, speciﬁcally in knowledge-rich,\ndata-scarce problems. We are also experimenting on a few\nmore domains and the results will be included in the full\nversion of the paper. Exploring other types of advice includ-\ning feature importance, qualitative constraints, privileged\ninformation, etc. is a potential future direction. Scaling our\napproach to web-scale data is a natural extension. Finally,\nextending the idea to other deep models and applications\nto more real domains remains an interesting direction for\nfuture research.\nAcknowledgements:\nMD, GK & SN gratefully acknowl-\nedge the support of CwC Program Contract W911NF-15-\n1-0461 with the US Defense Advanced Research Projects\nAgency (DARPA) and the Army Research Ofﬁce (ARO). SN\nalso acknowledges the NSF grant IIS-1836565 and AFOSR\naward FA9550-18-1-0462. DSD acknowledges the National\nInstitute of Health (NIH) grant no. R01 GM097628. Any\nopinions, ﬁndings and conclusion or recommendations are\nthose of the authors and do not necessarily reﬂect the view\nof the DARPA, ARO, AFOSR or the US government.\nKnowledge-augmented Column Networks: Guiding Deep Learning with Advice\nReferences\nBraziunas, D. and Boutilier, C. Preference elicitation and\ngeneralized additive utility. In AAAI, 2006.\nDas, M., Odom, P., Islam, M. R., Doppa, J. R., Roth, D., and\nNatarajan, S. Preference-Guided Planning: An Active\nElicitation Approach. In AAMAS, 2018.\nDas, M., Dhami, D. S., Kunapuli, G., Kersting, K. R., and\nNatarajan, S. Fast Relational Probabilistic Inference and\nLearning: Approximate Counting via Hypergraphs. In\nAAAI, 2019.\nDing, X., Luo, Y., Li, Q., Cheng, Y., Cai, G., Munnoch,\nR., Xue, D., Yu, Q., Zheng, X., and Wang, B. Prior\nknowledge-based deep learning method for indoor object\nrecognition and application. Systems Science & Control\nEngineering, 2018.\nFung, G. M., Mangasarian, O. L., and Shavlik, J. W.\nKnowledge-based support vector machine classiﬁers. In\nAdvances in neural information processing systems, 2003.\nGoldberger, J. and Ben-Reuven, E. Training deep neural-\nnetworks using a noise adaptation layer. In ICLR, 2017.\nGoodfellow, I., Bengio, Y., and Courville, A. Deep Learning.\nThe MIT Press, 2016.\nJiang, L., Zhou, Z., Leung, T., Li, L.-J., and Fei-Fei, L. Men-\ntornet: Learning data-driven curriculum for very deep\nneural networks on corrupted labels. In ICML, 2018.\nKaur, N., Kunapuli, G., Khot, T., Kersting, K., Cohen, W.,\nand Natarajan, S. Relational restricted boltzmann ma-\nchines: A probabilistic logic learning approach. In ILP,\n2017.\nKazemi, S. M. and Poole, D. RelNN: A deep neural model\nfor relational learning. In AAAI, 2018.\nKrizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet\nclassiﬁcation with deep convolutional neural networks.\nIn NIPS, 2012.\nKunapuli, G., Bennett, K. P., Shabbeer, A., Maclin, R.,\nand Shavlik, J. Online knowledge-based support vector\nmachines. In Joint European Conference on Machine\nLearning and Knowledge Discovery in Databases, 2010.\nKunapuli, G., Odom, P., Shavlik, J. W., and Natarajan, S.\nGuiding autonomous agents to better behaviors through\nhuman advice. In Data Mining (ICDM), 2013 IEEE 13th\nInternational Conference on, pp. 409–418. IEEE, 2013.\nLee, H., Pham, P., Largman, Y., and Y. Ng, A. Unsupervised\nfeature learning for audio classiﬁcation using convolu-\ntional deep belief networks. In NIPS, 2009.\nMitchell, T. M. The need for biases in learning generaliza-\ntions. Department of Computer Science, Laboratory for\nComputer Science Research, Rutgers Univ. New Jersey,\n1980.\nMiyato, T., Maeda, S.-i., Ishii, S., and Koyama, M. Virtual\nadversarial training: a regularization method for super-\nvised and semi-supervised learning. TPAMI, 2018.\nOdom, P. and Natarajan, S. Human-guided learning for\nprobabilistic logic models. Frontiers in Robotics and AI,\nsection Computational Intelligence, 2018a.\nOdom, P. and Natarajan, S. Human-guided learning for\nprobabilistic logic models. Frontiers in Robotics and AI,\n2018b.\nOdom, P., Khot, T., Porter, R., and Natarajan, S. Knowledge-\nbased probabilistic logic learning. In AAAI, 2015.\nPatrini, G., Rozza, A., Menon, A. K., Nock, R., and Qu, L.\nMaking deep neural networks robust to label noise: A\nloss correction approach. In CVPR, 2017.\nPham, T., Tran, T., Phung, D. Q., and Venkatesh, S. Column\nnetworks for collective classiﬁcation. In AAAI, 2017.\nShavlik, J. W. and Towell, G. G. Combining explanation-\nbased learning and artiﬁcial neural networks. In Pro-\nceedings of the sixth international workshop on Machine\nlearning. Elsevier, 1989.\nTowell, G. G. and Shavlik, J. W. Knowledge-based artiﬁcial\nneural networks. Artiﬁcial intelligence, 1994.\nˇSourek, G., Aschenbrenner, V., ˇZelezny, F., and Kuˇzelka,\nO. Lifted relational neural networks. In NIPS Work-\nshop on Cognitive Comput.: Integr. Neural & Symbolic\nApproaches, 2015.\nYue-Hei Ng, J., Hausknecht, M., Vijayanarasimhan, S.,\nVinyals, O., Monga, R., and Toderici, G. Beyond short\nsnippets: Deep networks for video classiﬁcation.\nIn\nCVPR, 2015.\n",
  "categories": [
    "cs.LG",
    "cs.AI",
    "stat.ML"
  ],
  "published": "2019-05-31",
  "updated": "2019-05-31"
}