{
  "id": "http://arxiv.org/abs/1907.04490v1",
  "title": "Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning",
  "authors": [
    "Michael Lutter",
    "Christian Ritter",
    "Jan Peters"
  ],
  "abstract": "Deep learning has achieved astonishing results on many tasks with large\namounts of data and generalization within the proximity of training data. For\nmany important real-world applications, these requirements are unfeasible and\nadditional prior knowledge on the task domain is required to overcome the\nresulting problems. In particular, learning physics models for model-based\ncontrol requires robust extrapolation from fewer samples - often collected\nonline in real-time - and model errors may lead to drastic damages of the\nsystem. Directly incorporating physical insight has enabled us to obtain a\nnovel deep model learning approach that extrapolates well while requiring fewer\nsamples. As a first example, we propose Deep Lagrangian Networks (DeLaN) as a\ndeep network structure upon which Lagrangian Mechanics have been imposed. DeLaN\ncan learn the equations of motion of a mechanical system (i.e., system\ndynamics) with a deep network efficiently while ensuring physical plausibility.\nThe resulting DeLaN network performs very well at robot tracking control. The\nproposed method did not only outperform previous model learning approaches at\nlearning speed but exhibits substantially improved and more robust\nextrapolation to novel trajectories and learns online in real-time",
  "text": "Published as a conference paper at ICLR 2019\nDeep Lagrangian Networks:\nUsing Physics as Model Prior for Deep Learning\nMichael Lutter, Christian Ritter & Jan Peters ∗\nDepartment of Computer Science\nTechnische Universität Darmstadt\nHochschulstr. 10, 64289 Darmstadt, Germany\n{Lutter, Peters}@ias.tu-darmstadt.de\nAbstract\nDeep learning has achieved astonishing results on many tasks with large amounts of\ndata and generalization within the proximity of training data. For many important\nreal-world applications, these requirements are unfeasible and additional prior\nknowledge on the task domain is required to overcome the resulting problems.\nIn particular, learning physics models for model-based control requires robust\nextrapolation from fewer samples – often collected online in real-time – and model\nerrors may lead to drastic damages of the system.\nDirectly incorporating physical insight has enabled us to obtain a novel deep model\nlearning approach that extrapolates well while requiring fewer samples. As a ﬁrst\nexample, we propose Deep Lagrangian Networks (DeLaN) as a deep network\nstructure upon which Lagrangian Mechanics have been imposed.\nDeLaN can\nlearn the equations of motion of a mechanical system (i.e., system dynamics) with\na deep network eﬃciently while ensuring physical plausibility.\nThe resulting DeLaN network performs very well at robot tracking control. The\nproposed method did not only outperform previous model learning approaches at\nlearning speed but exhibits substantially improved and more robust extrapolation\nto novel trajectories and learns online in real-time.\n1\nIntroduction\nIn the last ﬁve years, deep learning has propelled most areas of learning forward at an impressive\npace (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2017) – with the exception of physically\nembodied systems. This lag in comparison to other application areas is somewhat surprising as\nlearning physical models is critical for applications that control embodied systems, reason about\nprior actions or plan future actions (e.g., service robotics, industrial automation). Instead, most\nengineers prefer classical oﬀ-the-shelf modeling as it ensures physical plausibility – at a high cost\nof precise measurements1 and engineering eﬀort. These plausible representations are preferred as\nthese models guarantee to extrapolate to new samples, while learned models only achieve good\nperformance in the vicinity of the training data.\nTo learn a model that obtains physically plausible representations, we propose to use the insights from\nphysics as a model prior for deep learning. In particular, the combination of deep learning and physics\nseems natural as the compositional structure of deep networks enables the eﬃcient computation of\nthe derivatives at machine precision (Raissi & Karniadakis, 2018) and, thus, can encode a diﬀerential\nequation describing physical processes. Therefore, we suggest to encode the physics prior in the form\nof a diﬀerential in the network topology. This adapted topology ampliﬁes the information content\nof the training samples, regularizes the end-to-end training, and emphasizes robust models capable\nof extrapolating to new samples while simultaneously ensuring physical plausibility. Hereby, we\nconcentrate on learning models of mechanical systems using the Euler-Lagrange-Equation, a second\norder ordinary diﬀerential equation (ODE) originating from Lagrangian Mechanics, as physics prior.\n∗Max Planck Institute for Intelligent Systems, Spemannstr. 41, 72076 Tübingen, Germany\n1Highly precise models usually require taking the physical system apart and measuring the separated pieces\n(Albu-Schäﬀer, 2002).\n1\narXiv:1907.04490v1  [cs.LG]  10 Jul 2019\nPublished as a conference paper at ICLR 2019\nWe focus on learning models of mechanical systems as this problem is one of the fundamental\nchallenges of robotics (de Wit et al., 2012; Schaal et al., 2002).\nContribution\nThe contribution of this work is twofold. First, we derive a network topology called Deep Lagrangian\nNetworks (DeLaN) encoding the Euler-Lagrange equation originating from Lagrangian Mechanics.\nThis topology can be trained using standard end-to-end optimization techniques while maintaining\nphysical plausibility. Therefore, the obtained model must comply with physics. Unlike previous\napproaches to learning physics (Atkeson et al., 1986; Ledezma & Haddadin, 2017), which engineered\nﬁxed features from physical assumptions requiring knowledge of the speciﬁc physical embodiment,\nwe are ‘only’ enforcing physics upon a generic deep network. For DeLaN only the system state and\nthe control signal are speciﬁc to the physical system but neither the proposed network structure nor\nthe training procedure. Second, we extensively evaluate the proposed approach by using the model\nto control a simulated 2 degrees of freedom (dof) robot and the physical 7-dof robot Barrett WAM in\nreal time. We demonstrate DeLaN’s control performance where DeLaN learns the dynamics model\nonline starting from random initialization. In comparison to analytic- and other learned models,\nDeLaN yields a better control performance while at the same time extrapolates to new desired\ntrajectories.\nIn the following we provide an overview about related work (Section 2) and brieﬂy summarize\nLagrangian Mechanics (Section 3). Subsequently, we derive our proposed approach DeLaN and the\nnecessary characteristics for end-to-end training are shown (Section 4). Finally, the experiments in\nSection 5 evaluate the model learning performance for both simulated and physical robots. Here,\nDeLaN outperforms existing approaches.\n2\nRelated Work\nModels describing system dynamics, i.e. the coupling of control input τττ and system state q, are\nessential for model-based control approaches (Ioannou & Sun, 1996). Depending on the control\napproach, the control law relies either on the forward model f , mapping from control input to the\nchange of system state, or on the inverse model f −1, mapping from system change to control input,\ni.e.,\nf (q, Ûq, τττ) = Üq,\nf −1(q, Ûq, Üq) = τττ.\n(1)\nExamples for application of these models are inverse dynamics control (de Wit et al., 2012), which\nuses the inverse model to compensate system dynamics, while model-predictive control (Camacho &\nAlba, 2013) and optimal control (Zhou et al., 1996) use the forward model to plan the control input.\nThese models can be either derived from physics or learned from data. The physics models must\nbe derived for the individual system embodiment and requires precise knowledge of the physical\nproperties (Albu-Schäﬀer, 2002). When learning the model2, mostly standard machine learning\ntechniques are applied to ﬁt either the forward- or inverse-model to the training data. E.g., authors\nused Linear Regression (Schaal et al., 2002; Haruno et al., 2001), Gaussian Mixture Regression\n(Calinon et al., 2010; Khansari-Zadeh & Billard, 2011), Gaussian Process Regression (Kocijan\net al., 2004; Nguyen-Tuong et al., 2009; Nguyen-Tuong & Peters, 2010), Support Vector Regression\n(Choi et al., 2007; Ferreira et al., 2007), feedforward- (Jansen, 1994; Lenz et al., 2015; Ledezma &\nHaddadin, 2017; Sanchez-Gonzalez et al., 2018) or recurrent neural networks (Rueckert et al., 2017)\nto ﬁt the model to the observed measurements.\nOnly few approaches incorporate prior knowledge into the learning problem. Sanchez-Gonzalez\net al. (2018) use the graph representation of the kinematic structure as input.\nWhile the work\nof Atkeson et al. (1986), commonly referenced as the standard system identiﬁcation technique for\nrobot manipulators (Siciliano & Khatib, 2016), uses the Newton-Euler formalism to derive physics\nfeatures using the kinematic structure and the joint measurements such that the learning of the\ndynamics model simpliﬁes to linear regression. Similarly, Ledezma & Haddadin (2017) hard-code\nthese physics features within a neural network and learn the dynamics parameters using gradient\ndescent rather than linear regression. Even though these physics features are derived from physics, the\n2Further information can be found in the model learning survey by Nguyen-Tuong & Peters (2011).\n2\nPublished as a conference paper at ICLR 2019\nlearned parameters for mass, center of gravity and inertia must not necessarily comply with physics\nas the learned parameters may violate the positive deﬁniteness of the inertia matrix or the parallel\naxis theorem (Ting et al., 2006). Furthermore, the linear regression is commonly underdetermined\nand only allows to infer linear combinations of the dynamics parameters and cannot be applied to\nclose-loop kinematics (Siciliano & Khatib, 2016).\nDeLaN follows the line of structured learning problems but in contrast to previous approaches\nguarantees physical plausibility and provides a more general formulation. This general formulation\nenables DeLaN to learn the dynamics for any kinematic structure, including kinematic trees and\nclosed-loop kinematics, and in addition does not require any knowledge about the kinematic structure.\nTherefore, DeLaN is identical for all mechanical systems, which is in strong contrast to the Newton-\nEuler approaches, where the features are speciﬁc to the kinematic structure. Only the system state\nand input is speciﬁc to the system but neither the network topology nor the optimization procedure.\nThe combination of diﬀerential equations and Neural Networks has previously been investigated in\nliterature. Early on Lagaris et al. (1998; 2000) proposed to learn the solution of partial diﬀerential\nequations (PDE) using neural networks and currently this topic is being rediscovered by Raissi &\nKarniadakis (2018); Sirignano & Spiliopoulos (2017); Long et al. (2017). Most research focuses on\nusing machine learning to overcome the limitations of PDE solvers. E.g., Sirignano & Spiliopoulos\n(2017) proposed the Deep Galerkin method to solve a high-dimensional PDE from scattered data.\nOnly the work of Raissi et al. (2017) took the opposite standpoint of using the knowledge of the speciﬁc\ndiﬀerential equation to structure the learning problem and achieve lower sample complexity. In this\npaper, we follow the same motivation as Raissi et al. (2017) but take a diﬀerent approach. Rather\nthan explicitly solving the diﬀerential equation, DeLaN only uses the structure of the diﬀerential\nequation to guide the learning problem of inferring the equations of motion. Thereby the diﬀerential\nequation is only implicitly solved. In addition, the proposed approach uses diﬀerent encoding of\nthe partial derivatives, which achieves the eﬃcient computation within a single feed-forward pass,\nenabling the application within control loops.\n3\nPreliminaries: Lagrangian Mechanics\nDescribing the equations of motion for mechanical systems has been extensively studied and various\nformalisms to derive these equations exist.\nThe most prominent are Newtonian-, Hamiltonian-\nand Lagrangian-Mechanics. Within this work Lagrangian Mechanics is used, more speciﬁcally the\nEuler-Lagrange formulation with non-conservative forces and generalized coordinates.3 Generalized\ncoordinates are coordinates that uniquely deﬁne the system conﬁguration. This formalism deﬁnes\nthe Lagrangian L as a function of generalized coordinates q describing the complete dynamics of\na given system. The Lagrangian is not unique and every L which yields the correct equations of\nmotion is valid. The Lagrangian is generally chosen to be\nL = T −V\n(2)\nwhere T is the kinetic energy and V is the potential energy. The kinetic energy T can be computed\nfor all choices of generalized coordinates using T = 1\n2 ÛqTH(q)Ûq, whereas H(q) is the symmetric\nand positive deﬁnite inertia matrix (de Wit et al., 2012). The positive deﬁniteness ensures that all\nnon-zero velocities lead to positive kinetic energy. Applying the calculus of variations yields the\nEuler-Lagrange equation with non-conservative forces described by\nd\ndt\n∂L\n∂Ûqi\n−∂L\n∂qi\n= τττi\n(3)\nwhere τττ are generalized forces. Substituting L and dV/dq = g(q) into Equation 3 yields the second\norder ordinary diﬀerential equation (ODE) described by\nH(q)Üq+ ÛH(q)Ûq−1\n2\n\u0012 ∂\n∂q\n\u0010\nÛqTH(q)Ûq\n\u0011\u0013T\n|                                 {z                                 }\nBc(q, Ûq)\n+g(q) = τττ\n(4)\n3More information can be found in the textbooks (Greenwood, 2006; de Wit et al., 2012; Featherstone,\n2007)\n3\nPublished as a conference paper at ICLR 2019\nwhere c describes the forces generated by the Centripetal and Coriolis forces (Featherstone, 2007).\nUsing this ODE any multi-particle mechanical system with holonomic constraints can be described.\nFor example various authors used this ODE to manually derived the equations of motion for coupled\npendulums (Greenwood, 2006), robotic manipulators with ﬂexible joints (Book, 1984; Spong, 1987),\nparallel robots (Miller, 1992; Geng et al., 1992; Liu et al., 1993) or legged robots (Hemami & Wyman,\n1979; Golliday & Hemami, 1977).\n4\nIncorporating Lagrangian Mechanics into Deep Learning\nStarting from the Euler-Lagrange equation (Equation 4), traditional engineering approaches would\nestimate H(q) and g(q) from the approximated or measured masses, lengths and moments of inertia.\nOn the contrary most traditional model learning approaches would ignore the structure and learn the\ninverse dynamics model directly from data. DeLaN bridges this gap by incorporating the structure\nintroduced by the ODE into the learning problem and learns the parameters in an end-to-end fashion.\nMore concretely, DeLaN approximates the inverse model by representing the unknown functions g(q)\nand H(q) as a feed-forward networks. Rather than representing H(q) directly, the lower-triangular\nmatrix L(q) is represented as deep network. Therefore, g(q) and H(q) are described by\nˆH(q) = ˆL(q; θ)ˆL(q; θ)T\nˆg(q) = ˆg(q; ψ)\nwhereˆ. refers to an approximation and θ and ψ are the respective network parameters. The parameters\nθ and ψ can be obtained by minimizing the violation of the physical law described by Lagrangian\nMechanics. Therefore, the optimization problem is described by\n(θ∗, ψ∗) = argmin\nθ,ψ\nℓ\n\u0010\nˆf −1(q, Ûq, Üq; θ,ψ), τττ\n\u0011\n(5)\nwith\nˆf −1(q, Ûq, Üq; θ, ψ) = ˆLˆL\nT Üq+ d\ndt\n\u0010\nˆLˆL\nT \u0011\nÛq−1\n2\n\u0012 ∂\n∂q\n\u0010\nÛqT ˆLˆL\nT Ûq\n\u0011\u0013T\n+ ˆg\n(6)\ns.t. 0 < xT ˆLˆL\nT x\n∀x ∈Rn\n0\n(7)\nwhere ˆf −1 is the inverse model and ℓcan be any diﬀerentiable loss function. The computational\ngraph of ˆf −1 is shown in Figure 1.\nUsing this formulation one can conclude further properties of the learned model. Neither ˆL nor\nˆg are functions of Ûq or Üq and, hence, the obtained parameters should, within limits, generalize to\narbitrary velocities and accelerations. In addition, the obtained model can be reformulated and used\nas a forward model. Solving Equation 6 for Üq yields the forward model described by\nˆf (q, Ûq, τττ ; θ, ψ) =\n\u0010\nˆLˆL\nT \u0011−1\n \nτττ −d\ndt\n\u0010\nˆLˆL\nT \u0011\nÛq+ 1\n2\n\u0012 ∂\n∂q\n\u0010\nÛqT ˆLˆL\nT Ûq\n\u0011\u0013T\n−ˆg\n!\n(8)\nwhere ˆLˆL\nT is guaranteed to be invertible due to the positive deﬁnite constraint (Equation 7). However,\nsolving the optimization problem of Equation 5 directly is not possible due to the ill-posedness of the\nLagrangian L not being unique. The Euler-Lagrange equation is invariant to linear transformation\nand, hence, the Lagrangian L′ = αL + β solves the Euler-Lagrange equation if α is non-zero and\nL is a valid Lagrangian. This problem can be mitigated by adding an additional penalty term to\nEquation 5 described by\n(θ∗, ψ∗) = argmin\nθ,ψ\nℓ\n\u0010\nˆf −1(q, Ûq, Üq; θ,ψ), τττ\n\u0011\n+λ Ω(θ, ψ)\n(9)\nwhere Ωis the L2-norm of the network weights.\nSolving the optimization problem of Equation 9 with a gradient based end-to-end learning approach\nis non-trivial due to the positive deﬁnite constraint (Equation 7) and the derivatives contained in ˆf −1.\nIn particular, d(LLT)/dt and ∂\u0000ÛqTLLT Ûq\u0001 /∂qi cannot be computed using automatic diﬀerentiation\nas t is not an input of the network and most implementations of automatic diﬀerentiation do not allow\nthe backpropagation of the gradient through the computed derivatives. Therefore, the derivatives\ncontained in ˆf −1 must be computed analytically to exploit the full gradient information for training\n4\nPublished as a conference paper at ICLR 2019\nof the parameters. In the following we introduce a network structure that fulﬁlls the positive-deﬁnite\nconstraint for all parameters (Section 4.1), prove that the derivatives d(LLT)/dt and ∂\u0000ÛqTLLT Ûq\u0001 /∂qi\ncan be computed analytically (Section 4.2) and show an eﬃcient implementation for computing the\nderivatives using a single feed-forward pass (Section 4.3). Using these three properties the resulting\nnetwork architecture can be used within a real-time control loop and trained using standard end-to-end\noptimization techniques.\n!\"\n!# $\n!\n!%&\n$'\"$\nH$\n%\ṅ%\n̈%\n*\nReLu Network\nPhysics Transformations\n0\n0\n0\n∗\n0\n0\n∗\n∗\n0\n-.- = \"\n+\n+\n+\n∗\n0\n0\n0\n∗\n0\n0\n0\n∗\n+\n+\nb\n0\n12\n13\nLinear Network\nFigure 1: The computational graph of the Deep Lagrangian Network (DeLaN). Shown in blue and\ngreen is the neural network with the three separate heads computing g(q), ld(q), lo(q). The orange\nboxes correspond to the reshaping operations and the derivatives contained in the Euler-Lagrange\nequation. For training the gradients are backpropagated through all vertices highlighted in orange.\n4.1\nSymmetry and Positive Definiteness of H\nEnsuring the symmetry and positive deﬁniteness of H is essential as this constraint enforces positive\nkinetic energy for all non-zero velocities. In addition, the positive deﬁniteness ensures that H is\ninvertible and the obtained model can be used as forward model. By representing the matrix H as\nthe product of a lower-triangular matrix the symmetry and the positive semi-deﬁniteness is ensured\nwhile simultaneously reducing the number of parameters. The positive deﬁniteness is obtained if the\ndiagonal of L is positive. This positive diagonal also guarantees that L is invertible. Using a deep\nnetwork with diﬀerent heads and altering the activation of the output layer one can obtain a positive\ndiagonal. The oﬀ-diagonal elements Lo use a linear activation while the diagonal elements Ld use a\nnon-negative activation, e.g., ReLu or Softplus. In addition, a positive scalar b is added to diagonal\nelements. Thereby, ensuring a positive diagonal of L and the positive eigenvalues of H. In addition,\nwe chose to share parameters between L and g as both rely on the same physical embodiment. The\nnetwork architecture, with three-heads representing the diagonal ld and oﬀ-diagonal lo entries of L\nand g, is shown in Figure 1.\n4.2\nDeriving the derivatives\nThe derivatives d \u0000LLT \u0001 /dt and ∂\u0000ÛqTLLT Ûq\u0001 /∂qi are required for computing the control signal τττ\nusing the inverse model and, hence, must be available within the forward pass. In addition, the\nsecond order derivatives, used within the backpropagation of the gradients, must exist to train the\nnetwork using end-to-end training. To enable the computation of the second order derivatives using\nautomatic diﬀerentiation the forward computation must be performed analytically. Both derivatives,\nd \u0000LLT \u0001 /dt and ∂\u0000ÛqTLLT Ûq\u0001 /∂qi, have closed form solutions and can be derived by ﬁrst computing\nthe respective derivative of L and second substituting the reshaped derivative of the vectorized form\nl. For the temporal derivative d \u0000LLT \u0001 /dt this yields\nd\ndt H(q) = d\ndt\n\u0010\nLLT \u0011\n= LdL\ndt\nT\n+ dL\ndt LT\n(10)\nwhereas dL/dt can be substituted with the reshaped form of\nd\ndt l = ∂l\n∂q\n∂q\n∂t +\nN\nÕ\ni=1\n∂l\n∂Wi\n∂Wi\n∂t\n+\nN\nÕ\ni=1\n∂l\n∂bi\n∂bi\n∂t\n(11)\n5\nPublished as a conference paper at ICLR 2019\n(b)\n∗\n0\n0\n∗\n∗\n0\n∗\n∗\n∗\n∗\n0\n0\n∗\n∗\n0\n∗\n∗\n∗\n0\n∗\n0\n0\n∗\n0\n0\n∗\n0\nW1\nb1\na1\n#\n$#\n$%\nW0\nb0\na0\n∗\n0\n0\n∗\n∗\n0\n∗\n∗\n∗\n$#\n$% ̇%\n%\ṅ%\n'\n('\n(%)\n$'\n$*\n(a)\nWi\nbi\nai\nMatMul\nAdd\ngi\nMatMul\ndiag(ai)\ng‘i\n+,-\n+,-./\n,-\n,-./\nFigure 2: (a) Computational graph of the Lagrangian layer. The orange boxes highlight the learnable\nparameters. The upper computational sub-graph corresponds to the standard network layer while\nthe lower sub-graph is the extension of the Lagrangian layer to simultaneously compute ∂hi/∂hi−1.\n(b) Computational graph of the chained Lagrangian layer to compute L, dL/dt and ∂L/∂qi using a\nsingle feed-forward pass.\nwhere i refers to the i-th network layer consisting of an aﬃne transformation and the non-linearity g,\ni.e., hi = gi\n\u0000WT\ni hi−1 +bi\n\u0001. Equation 11 can be simpliﬁed as the network weights Wi and biases bi\nare time-invariant, i.e., dWi/dt = 0 and dbi/dt = 0. Therefore, dl/dt is described by\nd\ndt l = ∂l\n∂q Ûq.\n(12)\nDue to the compositional structure of the network and the diﬀerentiability of the non-linearity, the\nderivative with respect to the network input dl/dq can be computed by recursively applying the chain\nrule, i.e.,\n∂l\n∂q =\n∂l\n∂hN−1\n∂hN−1\n∂hN−2\n··· ∂h1\n∂q\n∂hi\n∂hi−1\n= diag\n\u0010\ng′(WT\ni hi−1 +bi)\n\u0011\nWi\n(13)\nwhere g′ is the derivative of the non-linearity.\nSimilarly to the previous derivation, the partial\nderivative of the quadratic term can be computed using the chain rule, which yields\n∂\n∂qi\n\u0002ÛqTHÛq\n\u0003\n= tr\n\u0014\u0010\nÛqÛqT \u0011T ∂H\n∂qi\n\u0015\n= ÛqT\n\u0012 ∂L\n∂qi\nLT +L ∂L\n∂qi\nT \u0013\nÛq\n(14)\nwhereas ∂L/∂qi can be constructed using the columns of previously derived ∂l/∂q. Therefore, all\nderivatives included within ˆf can be computed in closed form.\n4.3\nComputing the Derivatives\nThe derivatives of Section 4.2 must be computed within a real-time control loop and only add\nminimal computational complexity in order to not break the real-time constraint.\nl and ∂l/∂q,\nrequired within Equation 10 and Equation 14, can be simultaneously computed using an extended\nstandard layer. Extending the aﬃne transformation and non-linearity of the standard layer with an\nadditional sub-graph for computing ∂hi/∂hi−1 yields the Lagrangian layer described by\nai = Wihi−1 +bi\nh1 = gi (ai)\n∂hi\n∂hi−1\n= diag \u0000g′\ni(ai)\u0001 Wi.\nThe computational graph of the Lagrangian layer is shown in Figure 2a. Chaining the Lagrangian\nlayer yields the compositional structure of ∂l/∂q (Equation 13) and enables the eﬃcient computation\nof ∂l/∂q. Additional reshaping operations compute dL/dt and ∂L/∂qi.\n5\nExperimental Evaluation: Learning an Inverse Dynamics Model for\nRobot Control\nTo demonstrate the applicability and extrapolation of DeLaN, the proposed network topology is\napplied to model-based control for a simulated 2-dof robot (Figure 3b) and the physical 7-dof robot\n6\nPublished as a conference paper at ICLR 2019\n(d)\n(c)\n−0.5\n0.0\n0.5\n1.0\n1.5\n2.0\nx [m]\n−2.0\n−1.5\n−1.0\n−0.5\n0.0\n0.5\n1.0\n1.5\ny [m]\nCos 0\nCos 1\n(b)\n(a)\n!, ̇!\nRobot\nPD-Controller\nInverse Model\n$%&'(!, ̇!, ̈!; +)\n!-, ̇!-, ̈!-\n-\n.\nInverse Model\n$%&'(!, ̇!, ̈!; +)\nLoss\nL 0., .\n∇+2\nTraining Process\nControl Loop\nFigure 3: (a) Real-time control loop using a PD-Controller with a feed-forward torque τττFF, compen-\nsating the system dynamics, to control the joint torques τττ. The training process reads the joint states\nand applies torques to learn the system dynamics online. Once a new model becomes available the\ninverse model ˆf −1 in the control loop is updated. (b) The simulated 2-dof robot drawing the cosine\ntrajectories. (c) The simulated Barrett WAM drawing the 3d cosine 0 trajectory. (d) The physical\nBarrett WAM.\nBarrett WAM (Figure 3d). The performance of DeLaN is evaluated using the tracking error on train\nand test trajectories and compared to a learned and analytic model. This evaluation scheme follows\nexisting work (Nguyen-Tuong et al., 2009; Sanchez-Gonzalez et al., 2018) as the tracking error is\nthe relevant performance indicator while the mean squared error (MSE)4 obtained using sample\nbased optimization exaggerates model performance (Hobbs & Hepenstal, 1989). In addition to most\nprevious work, we strictly limit all model predictions to real-time and perform the learning online,\ni.e., the models are randomly initialized and must learn the model during the experiment.\nExperimental Setup\nWithin the experiment the robot executes multiple desired trajectories with speciﬁed joint positions,\nvelocities and accelerations. The control signal, consisting of motor torques, is generated using\na non-linear feedforward controller, i.e., a low gain PD-Controller augmented with a feed-forward\ntorque τττ f f to compensate system dynamics. The control law is described by\nτττ = Kp (qd −q)+Kd (Ûqd −Ûq)+ τττ f f\nwith τττ f f = ˆf −1(qd, Ûqd, Üqd)\nwhere Kp, Kd are the controller gains and qd, Ûqd, Üqd the desired joint positions, velocities and\naccelerations. The control-loop is shown in Figure 3a. For all experiments the control frequency\nis set to 500Hz while the desired joint state and respectively τττ f f is updated with a frequency of\nfd = 200Hz. All feed-forward torques are computed online and, hence, the computation time is\nstrictly limited to T ≤1/200s. The tracking performance is deﬁned as the sum of the MSE evaluated\nat the sampling points of the reference trajectory.\nFor the desired trajectories two diﬀerent data sets are used. The ﬁrst data set contains all single stroke\ncharacters5 while the second data set uses cosine curves in joint space (Figure 3c). The 20 characters\nare spatially and temporally re-scaled to comply with the robot kinematics. The joint references\nare computed using the inverse kinematics. Due to the diﬀerent characters, the desired trajectories\ncontain smooth and sharp turns and cover a wide variety of diﬀerent shapes but are limited to a small\ntask space region. In contrast, the cosine trajectories are smooth but cover a large task space region.\nBaselines\nThe performance of DeLaN is compared to an analytic inverse dynamics model, a standard feed-\nforward neural network (FF-NN) and a PD-Controller. For the analytic models the torque is computed\nusing the Recursive Newton-Euler algorithm (RNE) (Luh et al., 1980), which computes the feed-\nforward torque using estimated physical properties of the system, i.e. the link dimensions, masses\nand moments of inertia. For implementations the open-source library PyBullet (Coumans & Bai,\n2016–2018) is used.\nBoth deep networks use the same dimensionality, ReLu nonlinearities and must learn the system\ndynamics online starting from random initialization. The training samples containing joint states\nand applied torques (q, Ûq, Üq, τττ)0,...T are directly read from the control loop as shown in Figure 3a.\n4An oﬄine comparisons evaluating the MSE on datasets can be found in the Appendix A.\n5The data set was created by Williams et al. (2008) and is available at Dheeru & Karra Taniskidou (2017))\n7\nPublished as a conference paper at ICLR 2019\nd\na\ne\n0\n1\n2\n3\nTorque [Nm]\nJoint 0\nτ\nDeLaN\nGround Truth\nd\na\ne\n−1.0\n−0.5\n0.0\n0.5\nTorque [Nm]\nJoint 1\n(a)\nd\na\ne\n−1\n0\n1\n2\nTorque [Nm]\nH(q)¨q\nd\na\ne\n−0.75\n−0.50\n−0.25\n0.00\n0.25\nTorque [Nm]\n(b)\nd\na\ne\n−0.1\n0.0\n0.1\n0.2\n0.3\nTorque [Nm]\nc(q, ˙q)\nd\na\ne\n0.0\n0.1\n0.2\n0.3\nTorque [Nm]\n(c)\nd\na\ne\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\nTorque [Nm]\ng(q)\nd\na\ne\n−0.4\n−0.2\n0.0\n0.2\n0.4\nTorque [Nm]\n(d)\n1 2\n4\n6\n8\n10 12 14 16 18 20\n10−3\n10−2\n10−1\n100\nMean Squared Errror\nOﬄine Testing Error\nDeLaN\nFF-NN\n1 2\n4\n6\n8\n10 12 14 16 18 20\nTrain Characters\n10−3\n10−2\n10−1\n100\nMean Squared Error\n(e)\nFigure 4: (a) The torque τττ required to generate the characters ’a’, ’d’ and ’e’ in black. Using these\nsamples DeLaN was trained oﬄine and learns the red trajectory. DeLaN can not only learn the\ndesired torques but also disambiguate the individual torque components even though DeLaN was\ntrained on the super-imposed torques. Using Equation 6 DeLaN can represent the inertial force HÜq\n(b), the Coriolis and Centrifugal forces c(q, Ûq) (c) and the gravitational force g(q) (d). All components\nmatch closely the ground truth data. (e) shows the oﬄine MSE of the feed-forward neural network\nand DeLaN for each joint.\nThe training runs in a separate process on the same machine and solves the optimization problem\nonline. Once the training process computed a new model, the inverse model ˆf −1 of the control loop\nis updated.\n5.1\nSimulated Robot Experiments\nThe 2-dof robot shown in Figure 3b is simulated using PyBullet and executes the character and\ncosine trajectories. Figure 4 shows the ground truth torques of the characters ’a’, ’d’, ’e’, the torque\nground truth components and the learned decomposition using DeLaN (Figure 4a-d). Even though\nDeLaN is trained on the super-imposed torques, DeLaN learns to disambiguate the inertial force\nHÜq , the Coriolis and Centrifugal force c(q, Ûq) and the gravitational force g(q) as the respective\ncurves overlap closely. Hence, DeLaN is capable of learning the underlying physical model using\nthe proposed network topology trained with standard end-to-end optimization. Figure 4d shows\nthe oﬄine MSE on the test set averaged over multiple seeds for the FF-NN and DeLaN w.r.t. to\ndiﬀerent training set sizes. The diﬀerent training set sizes correspond to the combination of n random\ncharacters, i.e., a training set size of 1 corresponds to training the model on a single character and\nevaluating the performance on the remaining 19 characters. DeLaN clearly obtains a lower test MSE\ncompared to the FF-NN. Especially the diﬀerence in performance increases when the training set\nis reduced. This increasing diﬀerence on the test MSE highlights the reduced sample complexity\nand the good extrapolation to unseen samples.\nThis diﬀerence in performance is ampliﬁed on\nthe real-time control-task where the models are learned online starting from random initialization.\nFigure 5a and b shows the accumulated tracking error per testing character and the testing error\naveraged over all test characters while Figure 5c shows the qualitative comparison of the control\nperformance6. It is important to point out that all shown results are averaged over multiple seeds and\nonly incorporate characters not used for training and, hence, focus the evaluation on the extrapolation\nto new trajectories. The qualitative comparison shows that DeLaN is able to execute all 20 characters\nwhen trained on 8 random characters. The obtained tracking error is comparable to the analytic\nmodel, which in this case contains the simulation parameters and is optimal. In contrast, the FF-NN\nshows signiﬁcant deviation from the desired trajectories when trained on 8 random characters. The\nquantitative comparison of the accumulated tracking error over seeds (Figure 5b) shows that DeLaN\nobtains lower tracking error on all training set sizes compared to the FF-NN. This good performance\nusing only few training characters shows that DeLaN has a lower sample complexity and better\nextrapolation to unseen trajectories compared to the FF-NN.\nFigure 6a and b show the performance on the cosine trajectories. For this experiment the models\nare only trained online on two trajectories with a velocity scale of 1x. To assess the extrapolation\nw.r.t. velocities and accelerations the learned models are tested on the same trajectories with scaled\nvelocities (gray area of Figure 6).\nOn the training trajectories DeLaN and the FF-NN perform\n6The full results containing all characters are provided in the Appendix B.\n8\nPublished as a conference paper at ICLR 2019\nRNE\nPD-Controller\nFF-NN\nn = 1\nFF-NN\nn = 6\nFF-NN\nn = 8\nFF-NN\nn = 10\n(c)\nDeLaN\nn = 1\nDeLaN\nn = 6\nDeLaN\nn = 8\nDeLaN\nn = 10\n1\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nTrain Characters\n10−1\n100\n101\n102\n103\nAccumulated Tracking Error\n(b)\nTracking Error\nFF-NN\nDeLaN\nRNE\nPD-Controller\na\nb\nc\nd\ne\ng\nh\nl\nm\nn\no\np\nq\nr\ns\nu\nv\nw\ny\nz\n10−2\n10−1\n100\n101\n102\n103\nTracking Error\n(a)\nMLP\nLagrangian\nRNE\nPD-Controller\nFigure 5: (a) The average performance of DeLaN and the feed forward neural network for each\ncharacter. The 4 columns of the boxplots correspond to diﬀerent numbers of training characters,\ni.e., n = 1, 6, 8, 10. (b) The median performance of DeLaN, the feed forward neural network and\nthe analytic baselines averaged over multiple seeds. The shaded areas highlight the 5th and the\n95th percentile. (c) The qualitative performance for the analytic baselines, the feed forward neural\nnetwork and DeLaN. The desired trajectories are shown in red.\ncomparable. When the velocities are increased the performance of FF-NN deteriorates because the\nnew trajectories do not lie within the vicinity of the training distribution as the domain of the FF-NN\nis deﬁned as (q, Ûq, Üq). Therefore, FF-NN cannot extrapolate to the testing data. In contrast, the\ndomain of the networks ˆL and ˆg composing DeLaN only consist of q, rather than (q, Ûq, Üq). This\nreduced domain enables DeLaN, within limit, to extrapolate to the test trajectories. The increase in\ntracking error is caused by the structure of ˆf −1, where model errors to scale quadratic with velocities.\nHowever, the obtained tracking error on the testing trajectories is signiﬁcantly lower compared to\nFF-NN.\n5.2\nPhysical Robot Experiments\nFor physical experiments the desired trajectories are executed on the Barrett WAM, a robot with\ndirect cable drives. The direct cable drives produce high torques generating fast and dexterous\nmovements but yield complex dynamics, which cannot be modelled using rigid-body dynamics due\nto the variable stiﬀness and lengths of the cables7. Therefore, the Barrett WAM is ideal for testing\nthe applicability of model learning and analytic models8 on complex dynamics. For the physical\nexperiments we focus on the cosine trajectories as these trajectories produce dynamic movements\nwhile character trajectories are mainly dominated by the gravitational forces. In addition, only the\ndynamics of the four lower joints are learned because these joints dominate the dynamics and the\nupper joints cannot be suﬃciently excited to retrieve the dynamics parameters.\nFigure 6c and d show the tracking error on the cosine trajectories using the the simulated Barrett\nWAM while Figure 6e and f show the tracking error of the physical Barrett WAM. It is important\nto note, that the simulation only simulates the rigid-body dynamics not including the direct cables\ndrives and the simulation parameters are inconsistent with the parameters of the analytic model.\nTherefore, the analytic model is not optimal. On the training trajectories executed on the physical\nsystem the FF-NN performs better compared to DeLaN and the analytic model. DeLaN achieves\nslightly better tracking error than the analytic model, which uses the same rigid-body assumptions\nas DeLaN. That shows DeLaN can learn a dynamics model of the WAM but is limited by the model\nassumptions of Lagrangian Mechanics. These assumptions cannot represent the dynamics of the\n7The cable drives and cables could be modelled simplistically using two joints connected by massless spring.\n8The analytic model of the Barrett WAM is obtained using a publicly available URDF (JHU LCSR, 2018)\n9\nPublished as a conference paper at ICLR 2019\n1\n1.25 1.5 1.75\n2\n2.25 2.5\nVelocity Scale\n10−1\n100\n101\n102\n103\n104\nMean Tracking Error\n(a)\nTest Data\n2 DoF Robot - Cosine 0\n1\n1.25 1.5 1.75\n2\n2.25 2.5\nVelocity Scale\n10−1\n100\n101\n102\n103\n104\n(b)\nTest Data\n2 DoF Robot - Cosine 1\n1\n1.25\n1.5\n1.75\n2\n2.25\nVelocity Scale\n10−1\n100\n101\n102\n103\n104\n(c)\nTest Data\nSim WAM - Cosine 0\n1\n1.25\n1.5\n1.75\n2\n2.25\nVelocity Scale\n10−1\n100\n101\n102\n103\n104\n(d)\nTest Data\nSim WAM - Cosine 1\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10−1\n100\n101\n102\n103\n104\n(e)\nTest Data\nBarrett WAM - Cosine 2\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10−1\n100\n101\n102\n103\n104\n(f)\nTest Data\nBarrett WAM - Cosine 3\nDeLaN\nFF-NN\nRNE\nFigure 6: The tracking error of the cosine trajectories for the simulated 2-dof robot (a & b), the\nsimulated (c & d) and the physical Barrett WAM (e & f). The feed-forward neural network and\nDeLaN are trained only on the trajectories at a velocity scale of 1×. Afterwards the models are tested\non the same trajectories with increased velocities to evaluate the extrapolation to new velocities.\ncable drives. When comparing to the simulated results, DeLaN and the FF-NN perform comparable\nbut signiﬁcantly better than the analytic model. These simulation results show that DeLaN can learn\nan accurate model of the WAM, when the underlying assumptions of the physics prior hold. The\ntracking performance on the physical system and the simulation indicate that DeLaN can learn a\nmodel within the model class of the physics prior but also inherits the limitations of the physics\nprior. For this speciﬁc experiment the FF-NN can locally learn correlations of the torques w.r.t. q, Ûq\nand Üq while such correlation cannot be represented by the network topology of DeLaN because such\ncorrelation should, by deﬁnition of the physics prior, not exist.\nWhen extrapolating to the identical trajectories with higher velocities (gray area of Figure 6) the\ntracking error of the FF-NN deteriorates much faster compared to DeLaN, because the FF-NN overﬁts\nto the training data. The tracking error of the analytic model remains constant and demonstrates\nthe guaranteed extrapolation of the analytic models. When comparing the simulated results, the\nFF-NN cannot extrapolate to the new velocities and the tracking error deteriorates similarly to the\nperformance on the physical robot. In contrast to the FF-NN, DeLaN can extrapolate to the higher\nvelocities and maintains a good tracking error. Even further, DeLaN obtains a better tracking error\ncompared the analytic model on all velocity scales. This low tracking error on all test trajectories\nhighlights the improved extrapolation of DeLaN compared to other model learning approaches.\n6\nConclusion\nWe introduced the concept of incorporating a physics prior within the deep learning framework\nto achieve lower sample complexity and better extrapolation.\nIn particular, we proposed Deep\nLagrangian Networks (DeLaN), a deep network on which Lagrangian Mechanics is imposed. This\nspeciﬁc network topology enabled us to learn the system dynamics using end-to-end training while\nmaintaining physical plausibility. We showed that DeLaN is able to learn the underlying physics\nfrom a super-imposed signal, as DeLaN can recover the contribution of the inertial-, gravitational\nand centripetal forces from sensor data. The quantitative evaluation within a real-time control loop\nassessing the tracking error showed that DeLaN can learn the system dynamics online, obtains lower\nsample complexity and better generalization compared to a feed-forward neural network. DeLaN can\nextrapolate to new trajectories as well as to increased velocities, where the performance of the feed-\nforward network deteriorates due to the overﬁtting to the training data. When applied to a physical\nsystems with complex dynamics the bounded representational power of the physics prior can be\nlimiting. However, this limited representational power enforces the physical plausibility and obtains\nthe lower sample complexity and substantially better generalization. In future work the physics prior\nshould be extended to represent a wider system class by introducing additional non-conservative\nforces within the Lagrangian.\nAcknowledgments\nThis project has received funding from the European Union’s Horizon 2020 research and innovation\nprogram under grant agreement No #640554 (SKILLS4ROBOTS). Furthermore, this research was\nalso supported by grants from ABB, NVIDIA and the NVIDIA DGX Station.\n10\nPublished as a conference paper at ICLR 2019\nReferences\nAlin Albu-Schäﬀer. Regelung von Robotern mit elastischen Gelenken am Beispiel der DLR-\nLeichtbauarme. PhD thesis, Technische Universität München, 2002.\nChristopher G Atkeson, Chae H An, and John M Hollerbach. Estimation of inertial parameters of\nmanipulator loads and links. The International Journal of Robotics Research, 5(3):101–119,\n1986.\nWayne J Book. Recursive lagrangian dynamics of ﬂexible manipulator arms. The International\nJournal of Robotics Research, 3(3):87–101, 1984.\nSylvain Calinon, Florent D’halluin, Eric L Sauser, Darwin G Caldwell, and Aude G Billard. Learning\nand reproduction of gestures by imitation. IEEE Robotics & Automation Magazine, 17(2):44–54,\n2010.\nEduardo F Camacho and Carlos Bordons Alba. Model predictive control. Springer Science &\nBusiness Media, Berlin, Heidelberg, 2013.\nYounggeun Choi, Shin-Young Cheong, and Nicolas Schweighofer. Local online support vector\nregression for learning control. In International Symposium on Computational Intelligence in\nRobotics and Automation, pp. 13–18. IEEE, 2007.\nErwin Coumans and Yunfei Bai. Pybullet, a python module for physics simulation for games, robotics\nand machine learning. http://pybullet.org, 2016–2018.\nCarlos Canudas de Wit, Bruno Siciliano, and Georges Bastin. Theory of robot control. Springer\nScience & Business Media, 2012.\nDua Dheeru and EﬁKarra Taniskidou.\nUCI machine learning repository, 2017.\nURL http:\n//archive.ics.uci.edu/ml.\nRoy Featherstone. Rigid Body Dynamics Algorithms. Springer-Verlag, Berlin, Heidelberg, 2007.\nISBN 0387743146.\nJoao P Ferreira, Manuel Crisostomo, A Paulo Coimbra, and Bernardete Ribeiro. Simulation control\nof a biped robot with support vector regression. In IEEE International Symposium on Intelligent\nSignal Processing, pp. 1–6. IEEE, 2007.\nZheng Geng, Leonard S Haynes, James D Lee, and Robert L Carroll. On the dynamic model and\nkinematic analysis of a class of stewart platforms. Robotics and autonomous systems, 9(4):\n237–254, 1992.\nC. Leslie Golliday and Hooshang Hemami. An approach to analyzing biped locomotion dynamics\nand designing robot locomotion controls. IEEE Transactions on Automatic Control, 22(6):\n963–972, December 1977. ISSN 0018-9286. doi: 10.1109/TAC.1977.1101650.\nDonald T Greenwood. Advanced dynamics. Cambridge University Press, 2006.\nMasahiko Haruno, Daniel M Wolpert, and Mitsuo Kawato. Mosaic model for sensorimotor learning\nand control. Neural computation, 13(10):2201–2220, 2001.\nHooshang Hemami and Bostwick Wyman. Modeling and control of constrained dynamic systems\nwith application to biped locomotion in the frontal plane. IEEE Transactions on Automatic\nControl, 24(4):526–535, August 1979. ISSN 0018-9286. doi: 10.1109/TAC.1979.1102105.\nBenjamin F Hobbs and Ann Hepenstal. Is optimization optimistically biased?\nWater Resources\nResearch, 25(2):152–160, 1989.\nPetros A Ioannou and Jing Sun. Robust adaptive control, volume 1. Prentice-Hall, 1996.\nM Jansen. Learning an accurate neural model of the dynamics of a typical industrial robot. In\nInternational Conference on Artiﬁcial Neural Networks, pp. 1257–1260, 1994.\n11\nPublished as a conference paper at ICLR 2019\nJHU LCSR JHU LCSR. Barrett model containing the 7-dof urdf, 2018. URL https://github.\ncom/jhu-lcsr/barrett_model.\nS Mohammad Khansari-Zadeh and Aude Billard. Learning stable nonlinear dynamical systems with\ngaussian mixture models. IEEE Transactions on Robotics, 27(5):943–957, 2011.\nJuš Kocijan, Roderick Murray-Smith, Carl Edward Rasmussen, and Agathe Girard. Gaussian process\nmodel based predictive control. In American Control Conference, volume 3, pp. 2214–2219.\nIEEE, 2004.\nAlex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet classiﬁcation with deep convolu-\ntional neural networks. In Advances in Neural Information Processing Systems, pp. 1097–1105,\n2012.\nIsaac E Lagaris, Aristidis Likas, and Dimitrios I Fotiadis. Artiﬁcial neural networks for solving\nordinary and partial diﬀerential equations. IEEE Transactions on Neural Networks, 9(5):987–\n1000, 1998.\nIsaac E Lagaris, Aristidis C Likas, and Dimitris G Papageorgiou. Neural-network methods for\nboundary value problems with irregular boundaries. IEEE Transactions on Neural Networks, 11\n(5):1041–1049, 2000.\nFernando Díaz Ledezma and Sami Haddadin. First-order-principles-based constructive network\ntopologies: An application to robot inverse dynamics. In IEEE-RAS International Conference\non Humanoid Robotics, 2017, pp. 438–445. IEEE, 2017.\nIan Lenz, Ross A Knepper, and Ashutosh Saxena. Deepmpc: Learning deep latent features for model\npredictive control. In Robotics: Science and Systems, 2015.\nKai Liu, Frank Lewis, Guy Lebret, and David Taylor. The singularities and dynamics of a stewart\nplatform manipulator. Journal of Intelligent and Robotic Systems, 8(3):287–308, 1993.\nZichao Long, Yiping Lu, Xianzhong Ma, and Bin Dong. Pde-net: Learning pdes from data. arXiv\npreprint arXiv:1710.09668, 2017.\nJohn YS Luh, Michael W Walker, and Richard PC Paul. On-line computational scheme for mechanical\nmanipulators. Journal of Dynamic Systems, Measurement, and Control, 102(2):69–76, 1980.\nK Miller. The lagrange-based model of delta-4 robot dynamics. Robotersysteme, 8:49–54, 1992.\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare,\nAlex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control\nthrough deep reinforcement learning. Nature, 518(7540):529, 2015.\nDuy Nguyen-Tuong and Jan Peters. Using model knowledge for learning inverse dynamics. In\nInternational Conference on Robotics and Automation, pp. 2677–2682, 2010.\nDuy Nguyen-Tuong and Jan Peters. Model learning for robot control: a survey. Cognitive Processing,\n12(4):319–340, 2011.\nDuy Nguyen-Tuong, Matthias Seeger, and Jan Peters. Model learning with local gaussian process\nregression. Advanced Robotics, 23(15):2015–2034, 2009.\nMaziar Raissi and George Em Karniadakis. Hidden physics models: Machine learning of nonlinear\npartial diﬀerential equations. Journal of Computational Physics, 357:125–141, 2018.\nMaziar Raissi, Paris Perdikaris, and George Em Karniadakis. Physics informed deep learning (part i):\nData-driven solutions of nonlinear partial diﬀerential equations. arXiv preprint arXiv:1711.10561,\n2017.\nElmar Rueckert, Moritz Nakatenus, Samuele Tosatto, and Jan Peters. Learning inverse dynamics\nmodels in o (n) time with lstm networks. In IEEE-RAS International Conference on Humanoid\nRobotics, pp. 811–816. IEEE, 2017.\n12\nPublished as a conference paper at ICLR 2019\nAlvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller,\nRaia Hadsell, and Peter Battaglia. Graph networks as learnable physics engines for inference and\ncontrol. arXiv preprint arXiv:1806.01242, 2018.\nStefan Schaal, Christopher G Atkeson, and Sethu Vijayakumar. Scalable techniques from nonpara-\nmetric statistics for real time robot learning. Applied Intelligence, 17(1):49–60, 2002.\nBruno Siciliano and Oussama Khatib. Springer handbook of robotics. Springer, 2016.\nDavid Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez,\nThomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go\nwithout human knowledge. Nature, 550(7676):354, 2017.\nJustin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial\ndiﬀerential equations. arXiv preprint arXiv:1708.07469, 2017.\nMark W Spong. Modeling and control of elastic joint robots. Journal of dynamic systems, mea-\nsurement, and control, 109(4):310–318, 1987.\nJo-Anne Ting, Michael Mistry, Jan Peters, Stefan Schaal, and Jun Nakanishi. A bayesian approach\nto nonlinear parameter identiﬁcation for rigid body dynamics. In Robotics: Science and Systems,\npp. 32–39, 2006.\nBen Williams, Marc Toussaint, and Amos J Storkey. Modelling motion primitives and their timing\nin biologically executed movements. In Advances in Neural Information Processing Systems 20,\npp. 1609–1616. 2008.\nKemin Zhou, John Comstock Doyle, Keith Glover, et al. Robust and optimal control, volume 40.\nPrentice Hall, New Jersey, 1996.\n13\nPublished as a conference paper at ICLR 2019\nAppendix A: Offline Benchmarks\n1\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nTrain Characters\n10−2\n10−1\nMSE\n(a)\nOﬄine Training Error\nDeLaN\nSI\nFF-NN\n1\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nTrain Characters\n10−2\n10−1\nMSE\n(b)\nOﬄine Testing Error\nFigure 7: The mean squared error averaged of 20 seeds on the training- (a) and test-set (b) of the\ncharacter trajectories for the two joint robot. The models are trained oﬄine using n characters and\ntested using the remaining 20−n characters. The training samples are corrupted with white noise,\nwhile the performance is tested on noise-free trajectories.\nTo evaluate the performance of DeLaN without the control task, DeLaN was trained oﬄine on previ-\nously collected data and evaluated using the mean squared error (MSE) on the test and training set.\nFor comparison, DeLaN is compared to the system identiﬁcation approach (SI) described by Atkeson\net al. (1986), a feed-forward neural network (FF-NN) and the Recursive Newton Euler algorithm\n(RNE) using an analytic model. For this comparison, one must point out that the system identiﬁcation\napproach relies on the availability of the kinematics, as the Jacobians and transformations w.r.t. to\nevery link must be known to compute the necessary features. In contrast, neither DeLaN nor the\nFF-NN require this knowledge and must implicitly also learn the kinematics.\nFigure 7 shows the MSE averaged over 20 seeds on the character data set executed on the two-joint\nrobot. For this data set, the models are trained using noisy samples and evaluated on the noise-free\nand previously unseen characters. The FF-NN performs the best on the training set, but overﬁts\nto the training data. Therefore, the FF-NN does not generalize to unseen characters. In contrast,\nthe SI approach does not overﬁt to the noise and extrapolates to previously unseen characters. In\ncomparison, the structure of DeLaN regularizes the training and prevents the overﬁtting to the\ncorrupted training data. Therefore, DeLaN extrapolates better than the FF-NN but not as good as the\nSI approach. Similar results can be observed on the cosine data set using the Barrett WAM simulated\nin SL (Figure 8 a, b). The FF-NN performs best on the training trajectory but the performance\ndeteriorates when this network extrapolates to higher velocities. SI performs worse on the training\ntrajectory but extrapolates to higher velocities. In comparison, DeLaN performs comparable to the\nSI approach on the training trajectory, extrapolates signiﬁcantly better than the FF-NN but does not\nextrapolate as good as the SI approach. For the physical system (Figure 8 c, d), the results diﬀer from\nthe results in simulation. On the physical system the SI approach only achieves the same performance\nas RNE, which is signiﬁcantly worse compared to the performance of DeLaN and the FF-NN. When\nevaluating the extrapolation to higher velocities, the analytic model and the SI approach extrapolate\nto higher velocities, while the MSE for the FF-NN signiﬁcantly increases. In comparison, DeLaN\nextrapolates better compared to the FF-NN but not as good as the analytic model or the SI approach.\nThis performance diﬀerence between the simulation and physical system can be explained by the\nunderlying model assumptions and the robustness to noise.\nWhile DeLaN only assumes rigid-\nbody dynamics, the SI approach also assumes the exact knowledge of the kinematic structure. For\nsimulation both assumptions are valid. However, for the physical system, the exact kinematics are\nunknown due to production imperfections and the direct cable drives applying torques to ﬂexible\njoints violate the rigid-body assumption. Therefore, the SI approach performs signiﬁcantly worse\non the physical system. Furthermore, the noise robustness becomes more important for the physical\nsystem due to the inherent sensor noise. While the linear regression of the SI approach is easily\ncorrupted by noise or outliers, the gradient based optimization of the networks is more robust to\nnoise. This robustness can be observed in Figure 9, which shows the correlation between the variance\nof Gaussian noise corrupting the training data and the MSE of the simulated and noise-free cosine\n14\nPublished as a conference paper at ICLR 2019\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10−3\n10−2\n10−1\n100\n101\n102\n103\nMSE\n(a)\nTest Data\nSL Barrett WAM - Cosine 0\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10−3\n10−2\n10−1\n100\n101\n102\n103\nMSE\n(b)\nTest Data\nSL Barrett WAM - Cosine 1\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10−3\n10−2\n10−1\n100\n101\n102\n103\nMSE\n(c)\nTest Data\nBarrett WAM - Cosine 0\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10−3\n10−2\n10−1\n100\n101\n102\n103\nMSE\n(d)\nTest Data\nBarrett WAM - Cosine 1\nSI\nDeLaN\nFF-NN\nRNE\nFigure 8: The mean squared error of the cosine trajectories for the simulated (a, b) and the physical\nBarrett WAM (c and d).\nThe system identiﬁcation approach, feed-forward neural network and\nDeLaN are trained oﬄine using only the trajectories at a velocity scale of 1×. Afterwards the models\nare tested on the same trajectories with increased velocities to evaluate the extrapolation to new\nvelocities.\ntrajectories. With increasing noise levels, the MSE of the SI approach increases signiﬁcantly faster\ncompared to the models learned using gradient descent.\nConcluding, the extrapolation of DeLaN to unseen trajectories and higher velocities is not as good\nas the SI approach but signiﬁcantly better than the generic FF-NN. This increased extrapolation\ncompared to the generic network is achieved by the Lagrangian Mechanics prior of DeLaN. Even\nthough this prior promotes extrapolation, the prior also hinders the performance on the physical\nrobot, because the prior cannot represent the dynamics of the direct cable drives. Therefore, DeLaN\nperforms worse than the FF-NN, which does not assume any model structure. However, DeLaN\noutperforms the SI approach on the physical system, which also assumes rigid-body dynamics and\nrequires the exact knowledge of the kinematics.\n10−3\n10−2\n10−1\nNoise Variance σ2\n10−2\n10−1\n100\n101\nMSE\nNoise Robustness\nRNE\nDeLaN\nFF-NN\nSI\nFigure 9: The mean squared error on the simulated and noise-free cosine trajectories with velocity\nscale of 1x.\nFor oﬄine training the samples are corrupted using i.i.d.\nnoise sampled from a\nmultivariate Normal distribution with the variance of σ2I.\n15\nPublished as a conference paper at ICLR 2019\nAppendix B: Complete Online Results\nPD-Controller\na\nRNE\nb\nc\nd\ne\ng\nh\nl\nm\nn\no\np\nq\nr\ns\nu\nv\nw\ny\nz\nDeLaN\nn = 1\nDeLaN\nn = 2\nDeLaN\nn = 4\nDeLaN\nn = 6\nDeLaN\nn = 8\nDeLaN\nn = 10\nDeLaN\nn = 12\nFF-NN\nn = 1\nFF-NN\nn = 2\nFF-NN\nn = 4\nFF-NN\nn = 6\nFF-NN\nn = 8\nFF-NN\nn = 10\nFF-NN\nn = 12\nFigure 10: The qualitative performance for the analytic baselines, the feed forward neural network\nand DeLaN for diﬀerent number of random training characters. The desired trajectories are shown\nin red.\n16\nPublished as a conference paper at ICLR 2019\na\nb\nc\nd\ne\ng\nh\nl\nm\nn\no\np\nq\nr\ns\nu\nv\nw\ny\nz\nCharacter\n10\n2\n10\n1\n100\n101\n102\n103\nTracking Error\nDeLaN\nFF-NN\nPD-Controller\nRNE\nFigure 11: The average performance of DeLaN and the feed forward neural network for each\ncharacter. The columns of the boxplots correspond to diﬀerent numbers of training characters, i.e.,\nn = 1, 2, 4, 6, 8, 10, 12.\n17\n",
  "categories": [
    "cs.LG",
    "cs.RO",
    "cs.SY",
    "eess.SY",
    "stat.ML"
  ],
  "published": "2019-07-10",
  "updated": "2019-07-10"
}