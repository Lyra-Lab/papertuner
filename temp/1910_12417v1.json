{
  "id": "http://arxiv.org/abs/1910.12417v1",
  "title": "Deep causal representation learning for unsupervised domain adaptation",
  "authors": [
    "Raha Moraffah",
    "Kai Shu",
    "Adrienne Raglin",
    "Huan Liu"
  ],
  "abstract": "Studies show that the representations learned by deep neural networks can be\ntransferred to similar prediction tasks in other domains for which we do not\nhave enough labeled data. However, as we transition to higher layers in the\nmodel, the representations become more task-specific and less generalizable.\nRecent research on deep domain adaptation proposed to mitigate this problem by\nforcing the deep model to learn more transferable feature representations\nacross domains. This is achieved by incorporating domain adaptation methods\ninto deep learning pipeline. The majority of existing models learn the\ntransferable feature representations which are highly correlated with the\noutcome. However, correlations are not always transferable. In this paper, we\npropose a novel deep causal representation learning framework for unsupervised\ndomain adaptation, in which we propose to learn domain-invariant causal\nrepresentations of the input from the source domain. We simulate a virtual\ntarget domain using reweighted samples from the source domain and estimate the\ncausal effect of features on the outcomes. The extensive comparative study\ndemonstrates the strengths of the proposed model for unsupervised domain\nadaptation via causal representations.",
  "text": "DEEP CAUSAL REPRESENTATION LEARNING FOR\nUNSUPERVISED DOMAIN ADAPTATION\nA PREPRINT\nRaha Moraffah\nDepartment of Computer Science\nArizona State University\nTempe, AZ 85281\nrmoraffa@asu.edu\nKai Shu\nDepartment of Computer Science\nArizona State University\nTempe, AZ 85281\nkai.shu@asu.edu\nAdrienne Raglin\nArmy Research Lab\n2800 Powder Mill Rd\nAdelphi, MD 20783\nadrienne.raglin2.civ@mail.mil\nHuan Liu\nDepartment of Computer Science\nArizona State University\nTempe, AZ 85281\nhliu@asu.edu\nOctober 29, 2019\nABSTRACT\nStudies show that the representations learned by deep neural networks can be transferred to similar\nprediction tasks in other domains for which we do not have enough labeled data. However, as we\ntransition to higher layers in the model, the representations become more task-speciﬁc and less\ngeneralizable. Recent research on deep domain adaptation proposed to mitigate this problem by\nforcing the deep model to learn more transferable feature representations across domains. This is\nachieved by incorporating domain adaptation methods into deep learning pipeline. The majority of\nexisting models learn the transferable feature representations which are highly correlated with the\noutcome. However, correlations are not always transferable. In this paper, we propose a novel deep\ncausal representation learning framework for unsupervised domain adaptation, in which we propose\nto learn domain-invariant causal representations of the input from the source domain. We simulate\na virtual target domain using reweighted samples from the source domain and estimate the causal\neffect of features on the outcomes. The extensive comparative study demonstrates the strengths of the\nproposed model for unsupervised domain adaptation via causal representations.\n1\nIntroduction\nDeep neural networks have had great achievements in different areas such as image classiﬁcation [1] and object\ndetection [2]. These models usually require huge amounts of training data. However, collecting and annotating datasets\nare usually labor-intensive. Luckily, there are huge amounts of labeled data available from other domains that can be\nleveraged. However, distributions of the source (i.e., the learning model is trained on) and target (i.e., the dataset we\nwish to apply the trained model on) are usually different, which leads to the failure of those models that transfer the\nknowledge from source to target domain directly.\nEven though deep neural nets can learn transferable representations, studies show that differences between distributions\nof source and target domains (domain shift) can affect the performance of these models and the representations become\nless transferable in higher layers of the network [3][4]. Moreover, in many real-world cases where no or few labeled\ndata is available in the target domain, overﬁtting to the source distribution ensues if the model is trained in a supervised\nmanner on data in both source and target domains [5]. Various unsupervised deep domain adaptation methods are\nproposed to utilize labeled samples from source domain and unlabeled samples from the target domain, and learn a\nclassiﬁer which minimizes the prediction error in the target domain by embedding shallow domain adaptation methods\narXiv:1910.12417v1  [cs.LG]  28 Oct 2019\nA PREPRINT - OCTOBER 29, 2019\ny\nz\nc\ns\nFigure 1: A causal diagram: c and s are causal and spurious features, z confounders, and y prediction outcome.\ninto deep learning pipeline and learning representations that are both predictive and domain invariant [6] [7] [8] [9].\nHowever, these methods learn feature representations correlated with the outcome. Since some correlations can be\nspurious and therefore not transferable, we propose to learn the causal feature representations for unsupervised domain\nadaptation. Causal feature representations of the data are those used to deﬁne the structure of the outcome variable\nrather than the context. For instance, consider a picture of a cat. Features such as eyes, ears and shape of the face\nwhich are related to the structure of a cat and thus are referred to as causal feature representations, and features such\nas background of the image are called context feature representations. Figure 1 illustrates one possible causal graph\nof the extracted features such as eyes, ears, background and the outcome variable (i.e., an indicator of whether the\nimage is a cat or not). Causal features such as eyes and ears (i.e., c) have direct causal effect on the outcome whereas\ncontext features (i.e., s) are spurious features, i.e. the correlations between them and the outcome variable are due to the\nexistence of z, a confounder. The correlations due to confounding variables in the data are misleading and may not be\ntransferable across different target domains.\nThe causal mechanism that maps the cause to the effect should not depend on the distribution of the cause [10] and\ncausal features are naturally transferable across different domains [11]. For instance, in our example, if the model learns\nthe features related to the structure of cats such as eyes, ears, whiskers and etc., instead of learning the context features,\nthese causal features are more transferable across domains. This can be achieved by learning causal relationships\nbetween features and the outcome instead of their correlations.\nIn order to capture the causal relationships of the learned representations on the outcome, followng [12], our framework\nin Figure 1 simulates a virtual target domain on top of the representations learned from the source data by re-weighting\nthe samples from the source domain. We show that in this simulated target domain, only representations that are\nthe causes of the outcome variable (c) are extracted and all other correlations such as those between s and y) are\nremoved. Therefore, the model can learn the representations with highest causal effect on the outcome by measuring\nthe correlations between the outcome and representations of the virtual domain. These representations are then used\nalong with the causal mechanism to perform prediction in a target domain. Learning these weights are embedded into\nthe pipeline of the deep neural net and occurs jointly with parameters of the deep model. This way, the model can learn\nthe representations which are both predictive and invariant across different domains.\nOur major contributions are summarized as follows:\n• We study a novel problem of learning causal representations for unsupervised domain adaptation;\n• We propose a general framework DCDAN to learn causal feature representations and causal mechanisms to\nmake prediction in target domains and show that the learned representations are indeed those with highest\ncausal effects on the target variables; and\n• We conduct experiments to demonstrate the effectiveness of the proposed framework for unsupervised domain\nadaptation by learning causal feature representations.\n2\nRelated Work\nWe review research on deep visual domain adaptation and causal inference in domain adaptation and feature learning.\nDeep visual domain adaptation. Despite the achievements of deep neural networks in feature learning, [4] and [3]\nshow that the transferability of the features learned decreases by the last layer of the network. Deep domain adaptation\naddresses the issue by embedding domain adaptation into the pipeline of deep models and learning representations\nthat are both predictive and domain invariant. This is achieved by using several different criteria. For example, [7],\n[13] and [6] leverage class labels as a guide for transferring knowledge across different domains. [14], [6] and [9]\napproach the problem by aligning the statistical distribution shifts between source and target domains. To compare\n2\nA PREPRINT - OCTOBER 29, 2019\nthe distributions of source and target domains, criteria such as maximum mean discrepancy (MMD) [14], [6], [8], [9],\nKullback-Leibler(KL) divergence [15], and correlation alignment (CORAL) [16], [17] have been used. Another line of\nwork focuses on adversarial-based domain adaptation which minimizes the distance between source and target domains\nthrough an adversarial objective of the domain discriminator, aiming to encourage domain confusion, including [7],\n[18], and [19] on visual deep domain adaptation.\nCausal inference in domain adaptation. Recent work on shallow domain adaptation proposes to learn invariant\nfeatures for domain adaptation over agnostic target domains. For instance, [11] propose a causal framework to identify\nthe invariant features across different datasets and use them for prediction. [20] propose to ﬁnd the causal features by\nexploring the invariance of conditional distribution of the target variable across different domains. [12] propose a causal\napproach to select domain invariant predictors among all predictors and use them to perform domain adaptation across\nunknown environments. However, they are all designed for shallow domain adaptation and choose useful predictors\nrather than learning them from the data.\nCausal inference has been also utilized for learning visual features from the data. [21] proposes a visual causal\nfeature learning framework which constructs causal variables from micro variables in observational data with minimum\nexperimental effort.However, this work requires performing experiments.\n3\nPreliminaries of Domain Adaptation\nIn this work, given a source domain Ds = {(xs\ni, ys\ni )}ns\ni=1 with ns labeled samples, we predict the labels for an unlabeled\ntarget domain Dt = {xt\ni}nt\ni=1 by leveraging samples from the source domain to minimize prediction errors. Let P and Q\ndenote the distributions of the source and target domains, respectively. P(X, Y) and Q(X, Y) are the joint distributions\nof the inputs and outcomes for source and target domains. In general, these two joint distributions are different, i.e.,\nP(X, Y) ̸= Q(X, Y). Following the traditional setting [5], we have two basic assumptions: (i) P(YS|XS) = P(YT |XT ),\nwhich means the conditional distribution of the outcome given the data remains the same across different environments;\nand (ii) P(X) ̸= Q(X), indicating that the difference between the joint distribution of the inputs and outcomes originates\nfrom the difference between the marginal distributions of the inputs. Moreover, we assume that the difference between\nmarginal distributions of the inputs comes from a drift in the feature space of the problem (or covariate shift). Speciﬁcally,\nwe study the problem of constructing a deep neural network that learns transferable representations, Z, for which the\nconditional probability of the outcomes remains the same across different domains and learns a classiﬁer (θ (.)) such\nthat θ maps the learned representations to the outcome and the target loss ϵ(θ) = Pr(x,y)∼Q[θ(x) ̸= y] is minimized.\n4\nProposed Framework - DCDAN\nWe propose a Deep Causal Representation learning framework for unsupervised Domain Adaptation (DCDAN) to learn\ntransferable feature representations for target domain prediction. A deep neural network combines feature extraction\nand a classiﬁer which learns the highly correlated feature representations with the outcome. However, some of these\ncorrelations could be due to biases in the data, e.g., confounding bias. We aim to remove spurious correlations learned\nby the model by measuring the causal effects of the representations on the outcome. DCDAN consists of a regularization\nterm which learns the balancing weights for the source data by balancing the distribution with respect to feature\nrepresentations learned from the data. These weights are designed in a way to help the model capture the causal effects\nof the features on the target variable instead of their correlations. Moreover, our model includes a weighted loss function\nof deep neural net, where the weight of each sample comes from the regularization term and the loss function is in\ncharge of learning predictive domain invariant features as well as a classiﬁer which maps the learned representations to\nthe output, or a causal mechanism. By embedding the sample weights of the learning component into the pipeline of the\nmodel and jointly learning these weights with the representations, we can beneﬁt from the deep model to learn causal\nfeatures that are both transferable and good predictors for the target. The framework is shown in Figure 2.\n4.1\nBalancing Sample Weights Regularizer\nAs discussed in the previous section, in order to learn the representations with causal effect on the outcome (i.e.\ncausal feature representations) and reduce the confounding bias, we need to force the deep neural net to learn the\ncausal relationships instead of the correlations. To do so, following [12], we reweight samples in the source domain\nwith sample weights which enable us to capture the causal effect of each learned feature on the outcome variable by\ncontrolling the effect of all other features in the learned representation. Variable balancing techniques are often used in\ncausal effect estimation from observational data where the distributions of the covariates are different between treatment\nand control groups due to the non-random assignment of the treatments to the units. In order to get an unbiased\nestimation of the causal effect of the treatment variables, one approach is to balance distributions of the treatment and\n3\nA PREPRINT - OCTOBER 29, 2019\nFlatten\nSimulated \nTarget \nDomain\nRepresentation \nof the source \ndomain\nOutput \nLayer\nInput \nLayer\nFeature Learning\nClassification\nW\n(Computed by balancing \nsample weights regularizer)\n \nFigure 2: An overview of DCDAN that learns causal representation of the data for prediction.\ncontrol groups by applying balancing weights on the samples. One way to learn these weights is to characterize the\ndistributions of the treatment and control groups by their moments and learn the weights W as following:\nW = argmin\nW\n∥\nP\ni:Ti=1 wi · xi\nP\ni:Ti=1 wi\n−\nP\ni:Ti=0 wi · xi\nP\ni:Ti=0 wi\n∥2\n2\nwhere T is the treatment variable and T = 1 and T = 0 represent the treatment and control groups respectively.\nIt is shown that by considering each feature learned in the set of feature representations as a treatment variable and\nlearning weights to balance the distribution of the source data with respect to every learned feature representation,\nwe can learn a new domain, in which only causal feature representations are correlated with the outcome. These new\nrepresentations then can be used to estimate the causal contributions of source representations on the outcome. The\nsample weights can be learned by minimizing the below function:\nG =\n|Z|\nX\ni=1\n∥ZT\n.,−i · (W ◦I(Z.,i))\nW T · I(Z.,i)\n−ZT\n.,−i · (W ◦(1 −(I(Z.,i))))\nW T · (1 −I(Z.,i))\n∥2\n2\nwhere W ∈Rns×1 denotes a vector of sample weights, Z = h(X) represents the feature representations extracted from\nthe deep model, Z.,i is a vector of i-th feature representation of all samples, Z.,−i is the set of all features representations\nexcept the i-th ones, ◦refers to the Hadamard product and I is and indicator matrix that indicates whether the feature\nexists in data samples (i.e. the entry is equal to one, which means the samples belong to the treatment group) or does\nnot exist (the entry is equal to zero and, which means data samples belong to the control group). In order to create\nthe Indicator matrix, we binarize the representations by leveraging the methods proposed in [22] for binarizing neural\nnetworks. In order to binarize the representations, two different possible approaches can be used. The ﬁrst function is\ndeterministic:\nxb = Sign(x) =\n\u001a\n+1\nx ≥0,\n0\notherwise,\nwhere xb is the binarizaed version of the real-valued variable x. This function is easy to implement and is shown to\nwork well in practice. The second function is stochastic:\nxb = Sign(x) =\n\u001a\n+1\nwith probability p = σ(x),\n0\nwith probability 1 −p,\nwhere σ is the \"hard-sigmoid\" function deﬁned as:\n4\nA PREPRINT - OCTOBER 29, 2019\nσ(x) = clip(x + 1\n2\n, 0, 1) = max(0, min(1, x + 1\n2\n))\nThis stochastic function makes the overlap assumption (1) more plausible than a deterministic function. Since the\nderivative of both binarization functions are almost zero everywhere during the back-propagation, following Hinton\n2012’s lectures and [22], we use “straight-through estimator\" for back propagation.\n4.2\nDeep Causal Domain Adaptation\nWe explore the idea of using a sample reweighting regularizer for learning transferable features in deep networks.\nConvolutional Neural Networks (CNN) are widely used deep frameworks in computer vision [1] and achieved great\nperformance in a variety of tasks. However, as discussed earlier, transferring these models to new domains, layers of\nthe CNN model become less transferable at more task-speciﬁc layers. Therefore, it requires vast amounts of labeled\ndata in the target domain to ﬁne-tune the model and avoid over-ﬁtting. Unsupervised domain adaptation frameworks\nsuch as [9] and [8] leverage unlabeled data in the target domain and learn the more transferable representations in the\nsource domain to the target domain. They learn transferable feature representations highly correlated with the outcome.\nRelying on correlations limits their performance since correlations do not necessarily exist in other domains, thus,\nmay not be transferable. If we ﬁnd only transferable feature representations, the performance on the target domain\ncan be further improved. We propose to learn causal representations of the input for which conditional distributions\nof the outcomes (a.k.a. causal mechanisms) remain the same across different domains even if the distributions of the\ninputs change [10]. this can be achieved by reweighting the learned representations with sample weights learned by a\nbalancing sample regularizer. Reweighted samples play the role of a virtual target domain in which only representations\nwith causal contributions on the outcome are correlated with the target and spurious correlations between two variables\nthat do not truly exist and are due to the confounders are removed. By doing so, we force the model to learn features\nwith highest causal contributions on the outcome.\nWe implement DCDAN on the Resnet-50 architecture [23] which can be easily replaced with any other convolutional\nneural network framework. Resnet-50 is used as a backbone for a variety of tasks in computer vision such as deep\ntransfer learning. It consists of 5 stages with convolutions and identity blocks. Each convolution and identity block\nconsist of 3 convolution layers. Resnet-50 leverages the concept of skipping connections, which proposes to add the\noriginal input to the output of the convolution block while stacking the convolution layers together, to reduce the risk of\nvanishing the gradients during back-propagation. The empirical risk of CNN can be written as:\nmin\nΘ\n1\nns\nns\nX\ni=1\nJ(Θ(xs\ni), ys\ni )\n(1)\nwhere J is the cross-entropy loss function, Θ parameters of CNN, and Θ(xs\ni) the conditional probability that CNN\nassigns xs\ni to label ys\ni .\nTo learn invariant causal feature representations among different domains by using a balancing sample reweighting\nregularizer, we propose to jointly learn the sample weights from the data, reweight the representations by these these\nweights and minimize the loss of prediction for the the reweighted samples. This can be done by reweighting the loss\nof each sample with its corresponding weight and minimizing the weighted empirical loss of CNN and the balancing\nregularizer G simultaneously. This way, we can reduce the bias in the correlations learned by the model and learn the\nfeatures with highest causal effect on the output that are also informative for prediction. Therefore, we embed the\nbalancing sample reweighting regularizer into the CNN framework as:\nmin\nΘ,W\n1\nns\nns\nX\ni=1\nwiJ(Θ(xs\ni), ys\ni ) + λ1G\nsubject to W ≥0, ∥W∥2\n2 ≤λ2,\n|h(X)|\nX\nj\nwj −1)2 ≤λ3\n(2)\nwhere Pns\ni=1 wiJ(Θ(xs\ni), ys\ni ) is the weighted cross-entropy loss function, representing the weighted empirical loss of\nCNN model, G the balancing sample reweighting regularizer, W ∈Rns×1 a vector of sample weights, W ≥0 ensures\nall the weights are non-negative, ∥W∥2\n2 ≤λ2 tries to reduce the sample variance and (P wj −1)2 ≤λ3 avoids all\nsample weights from being zero.\n5\nA PREPRINT - OCTOBER 29, 2019\n(a)\n(b)\n(c)\nFigure 3: An example of samples in dataset constructed to perform (EQ2) and heat-map generated by DCDAN. Figure\n3(a) shows a sample image from the data, Figure 3(b) shows the ground truth for causal features of ﬁgure 3(a) extracted\nfrom VQA-X dataset and ﬁgure 3(c) shows the heat-map generated by DCDAN for the causal feature representations\nTo optimize DCDAN, we update θ and W iteratively using mini-batch SGD. A detailed algorithm of the optimization\nframework can be found in the supplementary material.\n4.3\nTheoretical analysis\nIn this section, we explain the key assumption of our proposed method and provide some analysis on the reasons why\nthe method learns the causal features (i.e. the features with highest causal contributions on the target variable). In order\nfor our method to work, we need to make the overlap assumption, which is a common assumption in causal inference\nliterature [12]. Overlap assumption ensures that for each data instance in the treatment group, a counterpart from control\ngroup can be found.\nAssumption 1. [Overlap] For any variable Ti, where Ti is the treatment variable for i-th sample in the data, 0 <\nPr(Ti = 1|X = xi) < 1 for any xi in the dataset.\nProposition 1. Feature representations learned by DCDAN have highest causal contributions on the outcome.\nProof of this proposition is in the supplementary material.\nPostulate 1 (Independence of mechanism and input). Following [10], we assume that the causal mechanism is\n\"independent\" of the distribution of the cause. In other words, P(E|C) contains no information about P(C) where E is\nthe effect (i.e. outcome) and C is the cause. This indicates that changes in P(C) has no inﬂuence on the mechanism\nafter it is learned.\nPostulate 1 implies that once the causal mechanism (i.e. P(E|C)) is learned, we can assume that it remains the same\neven when the distribution of the input (i.e. P(x)) and therefore distribution of causes (i.e. P(C)) changes. Therefore,\nwe can address the covariate shift problem [24], where P(Y |X) remains the same across different environment while\nP(X) changes, by learning the causal features from the input and a functions that maps those feature to the outcome.\n5\nExperiments\nOur experiments are designed to evaluate the effectiveness of the proposed DCDAN with the following questions:\n• EQ1: How is DCDAN compared to existing unsupervised deep domain adaptation frameworks?\n• EQ2: Are the feature representations learned by DCDAN, causal features for predicting outcomes?\n• EQ3: How does varying the causal regularizer and other hyperparameters affect the classiﬁcation performance\nof DCDAN?\nWe introduce the datasets and representative state-of-the-art deep domain adaptation frameworks, then compare the\nperformance of DCDAN for an object recognition task to answer EQ1. For EQ2, we investigate the ability of DCDAN\nto learn and extract causal features from the data. For EQ3, we perform experiments by varying all hyperparametes of\nthe model and report their performance.\n6\nA PREPRINT - OCTOBER 29, 2019\n5.1\nDatasets\nTo answer EQ1, following the convention for domain adaptation study, we use Ofﬁce-31 and Ofﬁce-10+Caltech-10,\ntwo of the widely-adopted, publicly available benchmark datasets. Ofﬁce-31 consists of 4,652 images within 31\ncategories collected from three distinct domains: Amazon (A), which contains images downloaded from amazon.com,\nWebcam (W) and DSLR (D), which are images taken by web camera and digital SLR camera in an ofﬁce with different\nenvironment variation. For a comprehensive comparison, following [9], we evaluate the performance of all models by\nconsidering all possible pairs among the three domains: A →W, D →W, W →D, A →D, D →A, and W →A.\nOfﬁce-10 + Caltech-10 dataset consists of 10 common categories shared by the Ofﬁce31 and Caltech-256 (C). Thus,\nfor all 4 domains (A, W, D, and C), we conduct evaluations on all remaining possible pairs involving C: A →C,\nW →C, D →C, C →A, C →W, and C →D.\nTable 1: The Prediction Performance on Domain Adaptation on Office-31\nMethod\nA →W\nD →W\nW →D\nA →D\nD →A\nW →A\nAverage\nResNet-50\n69.685\n97.610\n99.405\n71.485\n63.080\n61.448\n77.118\nDDC\n77.987\n96.981\n100.000\n81.526\n65.246\n64.004\n80.957\nDAN\n82.000\n97.000\n100.000\n83.000\n66.000\n65.000\n82.166\nDeepCoral\n77.800\n97.700\n99.700\n81.500\n64.600\n64.000\n80.883\nDANN\n82.000\n96.900\n99.100\n79.700\n68.200\n67.400\n82.216\nHAFN\n82.900\n98.100\n99.600\n83.700\n69.700\n68.100\n83.683\nDCDAN\n81.000\n99.000\n100.000\n86.000\n69.000\n70.000\n84.166\nTable 2: The Prediction Performance on Domain Adaptation on Office-10+Caltech-10\nMethod\nA →C\nW →C\nD →C\nC →A\nC →W\nC →D\nAverage\nResNet-50\n86.375\n89.671\n87.978\n93.423\n93.559\n93.631\n90.772\nDDC\n91.184\n89.670\n89.586\n94.989\n95.932\n96.815\n93.029\nDAN\n91.000\n89.000\n87.000\n95.000\n96.000\n96.000\n92.333\nDeepCoral\n90.293\n88.691\n87.529\n95.198\n95.593\n96.178\n92.247\nDANN\n91.451\n87.000\n84.862\n94.000\n94.000\n92.000\n90.552\nHAFN\n90.115\n91.629\n95.302\n91.718\n95.254\n92.356\n92.729\nDCDAN\n92.000\n90.000\n91.000\n94.000\n96.000\n96.000\n93.166\nTo answer EQ2, a dataset with causal features ground truths is needed. However, obtaining ground truths for causal\nfeatures of objects is a difﬁcult task since existing datasets for object recognition do not include the causal features of\nthe targets and only contain the ground truths for the labels of the images in the datasets. Therefore, to answer EQ2, we\nconstruct a dataset with reliable ground truth for causal features corresponding to target variables by utilizing a subset\nof Visual Question Answering Explanation (VQA-X) dataset proposed in [25], where a set of images extracted from\nMSCOCO dataset1 along with a set of questions, answers, visual and textual explanations for questions are provided\nby human annotators. To construct the dataset for our study, we extract a subset of VQA-X dataset that contains only\nsingle objects with their corresponding labels from MSCOCO dataset. Our dataset consists of actual images, their\nlabels and the visual explanations of the target variable which represents the causal feature representations of the target.\nThese visual explanations are given by heatmaps provided by human experts. Figures 3(a) and 3(b) show one example\nof the data.\n5.2\nCompared Baseline Methods\nIn this section, we brieﬂy introduce the representative state-of-the-art baseline methods for deep domain adaptation:\n• ResNet-50 [23]: It is a state-of-the-art convolution neural network model for image classiﬁcation. It uti-\nlizes a deep residual neural network structure which introduces the identity shortcut connect to skip layers\nautomatically to avoid overﬁtting for deep neural networks.\n• DDC [8]: DDC is a deep domain confusion model that aims to maximize the domain invariance by adding an\nadaptation layer in convolution neural networks with a single-kernel maximum mean discrepancies (MMD)\nregularization proposed in [26].\n• DAN [9]: DAN is a deep adaptive neural network model for unsupervised domain adaptation. It reduces the\ndomain discrepancy via optimal multi-kernel selection for mean embedding matching.\n1http://cocodataset.org\n7\nA PREPRINT - OCTOBER 29, 2019\n• Deep CORAL [16]: Deep CORAL is an unsupervised deep domain adaptation framework, which learns a non-\nlinear transformation that aligns the second-order statistics between the source and target feature activations in\ndeep neural networks.\n• DANN [18]: DANN is an adversarial representation learning framework in which one classiﬁer aims to\ndistinguish the learn source/target features while the another feature extractor tries to confuse the domain\nclassiﬁer. The minimax optimization is then solved through a gradient reversal layer.\n• HAFN [27]: Hard Adaptive Feature Norm is a variantl of AFN, a non-parametric Adaptive Feature Norm\nframework for unsupervised domain adaptation, based on adapting feature norms of source and target domains\nto achieve symmetry over a large number of values.\n5.3\nClassiﬁcation Performance Comparison\nTo answer EQ1, we compare DCDAN with aforementioned representative methods. Following existing works on deep\ndomain adaptation, we utilize accuracy as the evaluation metric. For baseline methods, we follow standard evaluation\nmechanism for unsupervised domain adaptation and use all source instances with labels and all target instances without\nlabels [9]. We implement all the baselines using PyTorch 2. In addition, we evaluate all compared approaches through\ngrid search on the hyperparameter space, and report the best results. For MMD-based methods (i.e. DDC and DAN),\nwe use Gaussian kernels. The experimental results are shown in Table 1 and Table 2. From the tables, we make the\nfollowing observations:\n(a) DCDAN\n(b) Resnet-50\nFigure 4: Heatmaps generated by DCDAN and Resnet-50 on a subset of VQA-X data.\n• Without access to data in the target domain, DCDAN still outperform the baselines in many cases for both\ndatasets, which validates that causal feature representations are helpful for learning transferable features across\ndomains.\n• DCDAN signiﬁcantly outperforms Resnet-50, the only baseline that does not use any information from the\ntarget domain, which suggests that DCDAN can perform unsupervised domain adaptation.\n5.4\nCausal Feature Evaluation\nIn this subsection, to answer EQ2, we evaluate the performance of DCDAN for discovering causal features automatically\nfrom the data. It is worth mentioning that all of the baselines used in our ﬁrst experiment are designed for improving the\nperformance of image classiﬁcation in the target domain and none of them are initially proposed to discover interpretable\ncausal features. However, due to the nature of our approach, it is expected to be able to learn more interpretable features\nfrom the data by looking for the features that belong to the structure of the object rather than the context. In order to\nshow the effectiveness of our model in learning causal features, we propose to run DCDAN and a pretrained Resnet-50\non a subset of VQA-X dataset [25] as described in \"Datasets\" section, extract their feature representations heatmaps\nand compare them to the visual ground truths provided in VQA-X.\nIn order to make a fair comparison, we ﬁne-tune our model on a small subset of single-object images in Imagenet dataset\n[28] and extract the feature representation heatmaps from the ﬁne-tuned DCDAN and pre-trained Resnet-50 using the\nmethod proposed in [29]. Figure 3(c) shows an example generated heatmap by DCDAN. To compare the generated\n2https://pytorch.org/\n8\nA PREPRINT - OCTOBER 29, 2019\n10 2\n10 1\n100\n1\n75\n80\n85\n90\n95\nAverage Accuracy (%)\nA\nW\nC\nW\n(a) Accuracy vs. λ1\n10 4\n10 3\n10 2\n10 1\n2\n77.5\n80.0\n82.5\n85.0\n87.5\n90.0\n92.5\n95.0\nAverage Accuracy (%)\nA\nW\nC\nW\n(b) Accuracy vs. λ2\n10 3\n10 2\n10 1\n3\n77.5\n80.0\n82.5\n85.0\n87.5\n90.0\n92.5\n95.0\nAverage Accuracy (%)\nA\nW\nC\nW\n(c) Accuracy vs. λ3\nFigure 5: Accuracy of DCDAN with varying hyperparameters λ1, λ2 and λ3 on tasks A →W and C →W\nheatmaps, Following traditional settings, we use Rank correlarion as our evaluation metric. Following [30], to calculate\nthe Rank Correlation, we ﬁrst scale both the ground truths and heatmaps generated by the models to 14x14, rank the\npixels according to their spatial attention and compute the correlation between two ranked lists. Our experiment shows\nthat the rank correlation for DCDAN is 0.4501 whereas the rank correlation for the pre-trained Resnet-50 is 0.4077,\nwhich demonstrates the effectiveness of DCDAN on learning causal representations. Figure 6 shows an example of the\ngenerated heatmaps by DCDAN and pre-trained Resnet-50. As seen in Figure 3(b), the feature representation heatmaps\ngenerated by DCDAN are more focused on the causal features of the object, whereas the features learned by Resnet-50\ncan contain both causal and context features.\n5.5\nParameter Analysis\nTo answer (EQ3), we investigate the effect of hyperparameters of the model on the performance (i.e. accuracy of the\nmodel) and report the results in Figure 5. The performance is reported on tasks A →W and C →W. To be more\nspeciﬁc, Figure 5(a) illustrates the performance of the balancing sample weights regularizer (λ1) on classiﬁcation\nperformance of DCDAN as it varies in the λ1 ∈{0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1}. We observe that the accuracy of\nDCDAN ﬁrst increases and then decreases as λ1 varies in the mentioned range. This further conﬁrms that a good\ntrade-off between causal loss and classiﬁcation loss can result in learning more transferable features. Figure 5(b) shows\nthe effect of λ2 ∈{0.0001, 0.0005, 0.001, 0.002, 0.01, 0.1} the hyperparameter which controls the sample variance, on\nthe accuracy of DCDAN. We also report the effect of λ3 ∈{0.0005, 0.001, 0.002, 0.01, 0.1, 0.2} which is designed to\nprevent all sample weights from being zero in Figure 5(c). To measure the effect of λ3 on the performance.\n6\nConclusion\nIn this paper, we propose DCDAN, a novel Deep Causal Representation learning framework for unsupervised domain\nadaptation to generate more transferable feature representations by extracting causal feature representations instead\nof only considering the correlations. In order to learn the causal representations a virtual target domain consists of\nreweighted samples is generated. These sample weights are learned concurrently with the feature representations and\nin the pipeline of the deep model. Experiments demonstrate the effectiveness of our model for both classiﬁcation\nperformance and learning causal feature representations.\n9\nA PREPRINT - OCTOBER 29, 2019\n7\nProof of Proposition 1\nFeature representations learned by DCDAN are the features with highest causal contributions on the outcome.\nProof. Following [12], it can be proved that 1) reweighted feature representations in the simulated target domain are\nindependent of each other and 2) In the new target domain, only causal feature representations are correlated with the\noutcome and the possible spurious correlations between the context features and outcome vanish. To be more speciﬁc,\nwe have:\nPr(YT = y|ST = s)\n= ECT (Pr(YT = y|Ct, ST = s)|ST = s)\n= ECT (Pr(YT = y|Ct)|ST = s)\n= Pr(YT = y)\nwhere T denotes the target domain, C represents all causal features, S denotes all spurious variables and Y is the\noutcome variable.\nThis shows that by simulating a target domain using the balancing sample weights, correlation between the simulated\nrepresentations for virtual target domain and the outcome variable can be measured to estimate the unbiased causal\ncontribution of representations on the target and using these virtual representations in the pipeline of the deep model,\nwe can learn the feature representations with highest causal contributions on the data instead of the using correaltions.\nIn other words, features with high spurious correlations are not learned.\n8\nOptimization of DCDAN\nAlgorithm 1 explains the optimization procedure of the proposed framework. DCDAN utilizes an alternating optimiza-\ntion approach to solve the optimization problem deﬁned in Eq (2). To be more speciﬁc, DCDAN updates θ and W\niteratively using mini-batch stochastic gradient descent.\nAlgorithm 1 Deep Causal Domain Adaptation Network algorithm\nRequire: Matrix of input images X and ground truth labels Y\nEnsure: Updated parameters of the model W and θ\nInitialize the iteration variable t ←0\nInitialize parameters W (0) and θ(0)\nCalculate the loss function with (W (0), θ(0)) as stated in Eq (2) in the paper .\nrepeat\nt ←t + 1\nθt ←update θ using Stochastic Gradient Descent while W is ﬁxed\nW t ←update W using Stochastic Gradient Descent while θ is ﬁxed\nCalculate loss function with (W t, θt)\nuntil Loss function converges or maximum iteration is reached\nreturn W, θ\n9\nAdditional Case Studies for Learnig Causal Feature Representations\nIn this section, we provide more case studies for \"Causal Feature Evaluation\" section of the paper. Both DCDAN and\nResnet-50 are trained according to the settings explained in \"Causal Feature Evaluation\" section on a subset of VQA-X\ndataset [25] as described in \"Datasets\" section. Figure 6 shows some examples of the heatmaps generated by both our\nproposed framework and Resnet-50. Heatmaps generated by DCDAN are more focused on the regions which blong\nto the structure of the outcome (i.e. causal features), whereas the features learned by Resnet-50 belong to both the\nstructure as well as the context.\n10\nA PREPRINT - OCTOBER 29, 2019\n(a) Heatmap generated for an in-\nstance of pizza class by DCDAN\n(b) Heatmap generated for an in-\nstance of bird class by DCDAN\n(c) Heatmap generated for an in-\nstance of dog class by DCDAN\n(d) Heatmap generated for an in-\nstance of pizza class by Resnet-50\n(e) Heatmap generated for an in-\nstance of bird class by Resnet-50\n(f) Heatmap generated for an in-\nstance of dog class by Resnet-50\nFigure 6: Heatmaps generated by DCDAN and Resnet-50 on a subset of VQA-X data. First row shows the feature\nrepresentation heatmaps generated by our propose DCDAN and sencond row shows the heatmaps generated by\npre-trained Resnet-50\n11\nA PREPRINT - OCTOBER 29, 2019\nReferences\n[1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classiﬁcation with deep convolutional neural\nnetworks. NIPS, 2012.\n[2] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. Rich feature hierarchies for accurate object\ndetection and semantic segmentation. CVPR.\n[3] Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf: A\ndeep convolutional activation feature for generic visual recognition. In ICML, 2014.\n[4] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable are features in deep neural\nnetworks? CoRR, abs/1411.1792, 2014.\n[5] Mei Wang and Weihong Deng. Deep visual domain adaptation: A survey. CoRR, abs/1802.03601, 2018.\n[6] Mingsheng Long, Jianmin Wang, and Michael I. Jordan. Unsupervised domain adaptation with residual transfer\nnetworks. CoRR, abs/1602.04433, 2016.\n[7] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and\ntasks. ICCV, 2015.\n[8] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing\nfor domain invariance. arXiv preprint arXiv:1412.3474, 2014.\n[9] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I Jordan. Learning transferable features with deep\nadaptation networks. arXiv preprint arXiv:1502.02791, 2015.\n[10] Bernhard Schölkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun Zhang, and Joris Mooij. On causal and\nanticausal learning. ICML, 2012.\n[11] Mateo Rojas-Carulla, Bernhard Schölkopf, Richard Turner, and Jonas Peters. Invariant models for causal transfer\nlearning. J. Mach. Learn. Res., 2018.\n[12] Kun Kuang, Ruoxuan Xiong, Peng Cui, Susan Athey, and Bo Li. Stable prediction across unknown environments.\nCoRR, abs/1806.06270, 2018.\n[13] Xingchao Peng, Judy Hoffman, Stella X. Yu, and Kate Saenko. Fine-to-coarse knowledge transfer for low-res\nimage classiﬁcation. ICIP, 2016.\n[14] Mingsheng Long, Jianmin Wang, and Michael I. Jordan. Deep transfer learning with joint adaptation networks.\nCoRR, abs/1605.06636, 2016.\n[15] Fuzhen Zhuang, Xiaohu Cheng, Ping Luo, Sinno Jialin Pan, and Qing He. Supervised representation learning\nwith double encoding-layer autoencoder for transfer learning. ACM Trans. Intell. Syst. Technol., 2017.\n[16] Baochen Sun and Kate Saenko. Deep CORAL: correlation alignment for deep domain adaptation. CoRR,\nabs/1607.01719, 2016.\n[17] Baochen Sun, Jiashi Feng, and Kate Saenko.\nReturn of frustratingly easy domain adaptation.\nCoRR,\nabs/1511.05547, 2015.\n[18] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. ICML, 2015.\n[19] Ming-Yu Liu and Oncel Tuzel. Coupled generative adversarial networks. CoRR, abs/1606.07536, 2016.\n[20] J. Peters, P. Bühlmann, and N. Meinshausen. Causal inference using invariant prediction: identiﬁcation and\nconﬁdence intervals. Journal of the Royal Statistical Society, Series B, 2016.\n[21] Krzysztof Chalupka, Pietro Perona, and Frederick Eberhardt. Visual causal feature learning. UAI, 2015.\n[22] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural networks\nwith binary weights during propagations. CoRR, abs/1511.00363, 2015.\n[23] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In\nCVPR, 2016.\n[24] Masashi Sugiyama and Motoaki Kawanabe. Machine Learning in Non-Stationary Environments: Introduction to\nCovariate Shift Adaptation. The MIT Press, 2012.\n[25] Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Anna Rohrbach, Bernt Schiele, Trevor Darrell, and Marcus\nRohrbach. Multimodal explanations: Justifying decisions and pointing to the evidence. In CVPR, 2018.\n[26] A. Gretton, K. Borgwardt, M. Rasch, B. Schölkopf, and A. Smola. A kernel two-sample test. Journal of Machine\nLearning Research, 2012.\n12\nA PREPRINT - OCTOBER 29, 2019\n[27] Ruijia Xu, Guanbin Li, Jihan Yang, and Liang Lin. Unsupervised domain adaptation: An adaptive feature norm\napproach. CoRR, abs/1811.07456, 2018.\n[28] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej\nKarpathy, Aditya Khosla, Michael S. Bernstein, Alexander C. Berg, and Fei-Fei Li. Imagenet large scale visual\nrecognition challenge. CoRR, abs/1409.0575, 2014.\n[29] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv\nBatra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In ICCV, 2017.\n[30] Abhishek Das, Harsh Agrawal, Larry Zitnick, Devi Parikh, and Dhruv Batra. Human attention in visual question\nanswering: Do humans and deep networks look at the same regions? Computer Vision and Image Understanding,\n2017.\n13\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2019-10-28",
  "updated": "2019-10-28"
}