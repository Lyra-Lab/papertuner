{
  "id": "http://arxiv.org/abs/1911.08459v1",
  "title": "Deep Unsupervised Clustering with Clustered Generator Model",
  "authors": [
    "Dandan Zhu",
    "Tian Han",
    "Linqi Zhou",
    "Xiaokang Yang",
    "Ying Nian Wu"
  ],
  "abstract": "This paper addresses the problem of unsupervised clustering which remains one\nof the most fundamental challenges in machine learning and artificial\nintelligence. We propose the clustered generator model for clustering which\ncontains both continuous and discrete latent variables. Discrete latent\nvariables model the cluster label while the continuous ones model variations\nwithin each cluster. The learning of the model proceeds in a unified\nprobabilistic framework and incorporates the unsupervised clustering as an\ninner step without the need for an extra inference model as in existing\nvariational-based models. The latent variables learned serve as both observed\ndata embedding or latent representation for data distribution. Our experiments\nshow that the proposed model can achieve competitive unsupervised clustering\naccuracy and can learn disentangled latent representations to generate\nrealistic samples. In addition, the model can be naturally extended to\nper-pixel unsupervised clustering which remains largely unexplored.",
  "text": "Deep Unsupervised Clustering with Clustered Generator Model\nDandan Zhu1, Tian Han2∗, Linqi Zhou3, Xiaokang Yang1, Ying Nian Wu3\n1Shanghai Jiao Tong University\n2Stevens Institute of Technology\n3 University of California, Los Angeles\n{ddz,xkyang}@sjtu.edu.cn, than6@stevens.edu, linqizhou907@gmail.com, ywu@stat.ucla.edu\nAbstract\nThis paper addresses the problem of unsupervised clus-\ntering which remains one of the most fundamental chal-\nlenges in machine learning and artiﬁcial intelligence. We\npropose the clustered generator model for clustering which\ncontains both continuous and discrete latent variables. Dis-\ncrete latent variables model the cluster label while the con-\ntinuous ones model variations within each cluster.\nThe\nlearning of the model proceeds in a uniﬁed probabilistic\nframework and incorporates the unsupervised clustering as\nan inner step without the need for an extra inference model\nas in existing variational-based models. The latent vari-\nables learned serve as both observed data embedding or\nlatent representation for data distribution. Our experiments\nshow that the proposed model can achieve competitive un-\nsupervised clustering accuracy and can learn disentangled\nlatent representations to generate realistic samples. In ad-\ndition, the model can be naturally extended to per-pixel un-\nsupervised clustering which remains largely unexplored.\n1. Introduction\nClustering as one of the central themes in data under-\nstanding and analysis has been widely studied in the realm\nof unsupervised learning. However, unsupervised cluster-\ning remains one of the most fundamental challenges in ma-\nchine learning because of high dimensionality of data and\nhigh complexities of their hidden structures.\nLong-established approaches for unsupervised cluster-\ning including K-means [15] and Gaussian Mixture Model\n(GMM) [3] are still the building blocks for numerous appli-\ncations due to their efﬁciency and simplicity. However, their\ndistance metrics are limited to data space, making them in-\neffective for high-dimensional data such as images. There-\nfore, considerable efforts have been put into obtaining a\ngood feature embedding of data, usually of low dimension-\nality, for effective clustering [37]. However, the representa-\ntion obtained by standalone data embedding typically can-\n∗Tian Han is the corresponding author\nnot capture the latent structure and variation of the observed\ndata which may be ineffective for clustering. We believe\nthe good representation for clustering should also be able\nto compactly represent the observed data distribution to en-\ncode all necessary characteristics of the observation.\nDeep generative models (a.k.a the generator models)\nhave shown great promise in learning latent representa-\ntions for high-dimensional signals such as images and\nvideos [32, 24, 11]. Generator models parameterized by\ndeep neural networks specify a non-linear mapping from\nlatent variables to observed data. As a compact probabilis-\ntic representation of knowledge, it can embed the high-\ndimensional data into low-dimensional latent representa-\ntion. Besides, it has been shown that the generator model\nis also capable of generating realistic images indicating that\nthe learned latent representation encode all necessary and\nuseful information of the data. Though powerful, the gen-\nerator model is mainly studied with the focus on generation\ntasks using continuous latent variables. While it is clear\nthat we pursue both objectives of jointly learning latent rep-\nresentations and clustering, developing and learning such\ngenerator model for unsupervised clustering is still in its in-\nfancy with only a few recent existing works [22, 9, 23].\nIn this paper, we develop a new model-based clustering\nalgorithm using generator model. Speciﬁcally, we propose\nto use the generator model with both discrete and continu-\nous latent variables. The discrete latent variables are used\nto model cluster labels while continuous ones are used to\nmodel variations within each cluster. Such model is termed\nthe clustered generator model to emphasize the fact that it\naims to achieve unsupervised clustering. By learning the\nclustered generator model, we naturally incorporate the un-\nsupervised clustering as an inference step for discrete latent\nvariables in an inner loop, and as a result, useful latent rep-\nresentations (i.e., discrete and continuous latent variables)\nand the unsupervised clustering are seamlessly integrated\ninto a uniﬁed probabilistic learning framework. The experi-\nments show that by learning the clustered generator model,\nwe could achieve competitive or even state-of-art unsuper-\nvised clustering accuracy while obtaining realistic and dis-\nentangled latent representations.\n1\narXiv:1911.08459v1  [stat.ML]  19 Nov 2019\n1.1. Related Work and Contributions\nOur work is closely related to unsupervised clustering as\nwell as learning the generator models.\nThe most fundamental methods for clustering are the\nK-means [15] algorithm and Gaussian Mixture Model\n(GMM)[3]. K-means assumes the data are centered around\nsome centroids and clusters are found by minimizing l2 dis-\ntance to the centroid within each cluster. GMM, on the\nother hand, assumes that data are generated by mixture of\nGaussian distribution whose parameters are learned through\nExpectation-Maximization (EM) algorithm. Without utiliz-\ning the proper representation, these methods are ineffective\nin handling high-dimensional data whose underlying struc-\nture can be highly non-linear. Spectral clustering and its\nvariants [34, 31, 36, 38] further generalize the distance func-\ntion for non-linear clusters, yet in general they can be com-\nputationally intensive and still result in unsatisfactory clus-\ntering on high-dimensional data.\nGenerator models have received increasing attention\nover the past few years as they can effectively capture\ndata distribution through latent representations.\nGenera-\ntive Adversarial Network (GAN) [10] and Variational Auto-\nencoder (VAE) [24, 33] are two notable examples. These\ngenerative models have shown their great potential in vari-\nous applications such as image generation [32, 2, 13], im-\nage completion [11, 12], and disentangled latent representa-\ntion [16, 7, 14]. However, integrating such powerful knowl-\nedge representation tool with the unsupervised clustering\ntask has not been thoroughly investigated.\nOnly a few existing works jointly consider learning\nthe latent representation for data and the clustering task.\nConditional-VAE (CVAE) [23] considers discrete latent\nvariables for clustering and is closely related to our work,\nbut it is primarily developed for supervised/semi-supervised\nlearning where (part of) the data label is given. HashGAN\n[5] is a novel model that combines pairs of conditional\nWasserstein GAN (PC-WGAN) and hash encoded infor-\nmation. It mainly uses a new PC-WGAN conditional on\npairwise similarity information to generate an image that\nis closest to the real image. However, this method is also\nmainly used in supervised/semi-supervised tasks.\nVaria-\ntional Deep Embedding (VaDE) [22] and Gaussian Mixture\nVariational Auto-encoder (GMVAE) [9] combine GMM\nmodels and VAEs for unsupervised clustering. Adversar-\nial Auto-encoder (AAE) [27] can also be adapted to unsu-\npervised clustering, but it needs to use GAN to match the\naggregated posterior of latent representation with the prior\nof VAE, requiring complex computation and additional net-\nwork structures. Other related models include Deep Em-\nbedded Clustering (DEC) [37] and more recent Invariant\nInformation Clustering (IIC) [21] which speciﬁcally learn\nfeature representations for clustering tasks. The latent rep-\nresentations learned by DEC and IIC are unable to represent\nthe observed data distribution, thereby failing to general-\nize to other tasks (e.g., generation). While most of these\nvariational-based models could achieve relatively impres-\nsive clustering accuracy, they need to design and learn sep-\narate inference model for cluster labels. Besides, due to the\ndiscrete nature of cluster labels, variational learning can-\nnot take advantage of reparametrization trick and generally\nneed further approximation.\nIn contrast to recent models that use variational learning\nfor latent representation and clustering, we introduce the\nnovel clustered generator model for unsupervised cluster-\ning. Learning such model will naturally integrate the unsu-\npervised clustering process as an inference inner loop with-\nout utilizing additional networks or any further approxima-\ntion.\nContributions of our paper are as follows:\n• We propose the clustered generator model for unsu-\npervised clustering which includes discrete latent vari-\nables to model cluster labels and continuous latent\nvariables to capture variations within each cluster.\n• We develop a novel learning algorithm for clustered\ngenerator model in a probabilistic framework which\nnaturally involves the unsupervised clustering as an ex-\nact inference step without any assisting models and any\napproximations.\n• We conduct extensive experiments to show the ef-\nfectiveness of the proposed model. Speciﬁcally, our\nmodel can achieve competitive unsupervised cluster-\ning accuracy on large-scale image datasets and could\nget reasonably well per-pixel unsupervised clustering,\na task that has remained largely unexplored before.\nBesides, our model can obtain disentangled latent rep-\nresentations as indicated by its realistic generation.\n2. Model and Learning Algorithm\nIn this section, we describe the details of the model and\nthe corresponding inference and learning algorithm.\n2.1. Clustered Generator Model\nSuppose x be the observed data of dimension D. The\ngenerator model [10] assumes the observation x is gener-\nated by latent variable z of dimension d:\nz ∼N(0, Id); x = Gθ(z) + ϵ\nwhere ϵ ∼N(0, σ2ID) is the noise and is independent of z,\nand Gθ(z) is the top-down neural network with parameters\nθ. In general, the latent variable z is of low-dimension (i.e.,\nd < D) and is learned to (1) embed the high-dimensional\ndata x in a low-dimensional latent space, and (2) represent\nthe data distribution of x through a generative model that\ngenerates realistic samples.\n2\nTraditional generator models have been shown to be ef-\nfective in image generation [32, 2, 13]. However, it only\ndeals with the latent variable z that is continuous, making\nit ineffective in clustering tasks which are discrete in na-\nture. Therefore, we propose to use the generator model with\nboth discrete and continuous latent variables for unsuper-\nvised clustering.\nSuppose we have K clusters, the observed data x is now\ngenerated by not only the continuous latent variables z but\nalso the discrete latent variables y of dimension K which\nrepresents the cluster labels:\nz\n∼\nN(0, Id); y ∼Cat(π);\nx\n=\nGθ(z, y) + ϵ\nwhere Cat(π) denotes the categorical distribution with π\nbeing the prior probability for K clusters. ϵ ∼N(0, σ2ID)\nis the noise of the model and is independent of z and y.\nWe call such model clustered generator to emphasize the\nfact that it incorporates the unsupervised clustering natu-\nrally inside its learning framework. In this way, the latent\nvariables z and y are served as both observed data x em-\nbedding which is for clustering and latent representation\nwhich is for representing the data distribution of x. A sim-\nilar form has been used in [23]. However, the model is not\ndeveloped for unsupervised clustering. Besides, the repre-\nsentation learned for clustering is different from the latent\nrepresentation learned for data distribution which can be in-\neffective in both realms. We will elaborate this point in the\nnext section and experiments.\n2.2. Inference and Learning\nThe clustered generator model deﬁnes the generation\nprocess as: z ∼p(z), y ∼p(y), x ∼pθ(x|y, z). Therefore,\nthe complete data model can be deﬁned as pθ(x, y, z) =\np(z)p(y)pθ(x|y, z).\nIf we observe a set of training data\n{xi, i = 1, ..., n} coming from the true but unknown dis-\ntribution pdata, then the learning and inference of the clus-\ntered generator model can be accomplished by maximizing\nthe observed-data log-likelihood:\nL(θ)\n=\n1\nn\nn\nX\ni=1\nlog pθ(xi)\n=\n1\nn\nn\nX\ni=1\nlog\nZ\nz\nX\ny\npθ(xi, y, z)dydz\nThe model parameters θ can be learned by gradient descent\nwhich amounts to evaluating:\n∂L(θ)\n∂θ\n=\n1\nn\nn\nX\ni=1\n∂log pθ(xi)\n∂θ\n=\n1\nn\nn\nX\ni=1\nEpθ(y,z|xi)\n\u0014 ∂\n∂θ log pθ(xi, y, z)\n\u0015\n(1)\nHowever, the evaluation of expectation in Eqn. 1 is in gen-\neral analytically intractable. For given observation example\nx, we obtain fair samples from the posterior distribution,\ni.e., y, z ∼pθ(y, z|x), using Gibbs sampler which itera-\ntively performs the conditional sampling on latent variables\nz and y, i.e., z ∼pθ(z|x, y), y ∼pθ(y|x, z).\n2.2.1\nInference on continuous z:\nThe continuous latent variable z is sampled based on poste-\nrior distribution given y ﬁxed:\nz ∼pθ(z|x, y) ∝pθ(z, x, y)\n(2)\nFair samples can be drawn using MCMC techniques like\nHMC or Langevin dynamics [29]. Langevin dynamics is\nused in this work because it can help navigate the landscape\nof the latent space more thoroughly and effectively. Specif-\nically, we have:\nzτ+1 = zτ + δ ∂\n∂z log pθ(z, x, y) +\n√\n2δNτ\n(3)\nwhere δ is the step size and τ is the time stamp for langevin\ninference. Nτ ∼N(0, Id) is the random noise projected in\neach iteration. The log-joint can be evaluated as:\nlog pθ(z, x, y) = −||z||2\n2\n2\n−||x −Gθ(y, z)||2\n2\n2σ2\n+ C\n(4)\nwhere C is the constant which does not involve z. Variable\nσ is the pre-speciﬁed standard deviation of our model. Note\nthat y is ﬁxed to be the currently sampled value during the\nlearning iteration. It has been shown that the dynamic has\nthe pθ(z, x, y) as its stationary distribution. Therefore, the\nfair sample for z from pθ(z|x, y) can be ensured.\nIn fact, from Eqn. 2, we can see that for given obser-\nvation example x, the inference on z amounts to ﬁnding\nthe suitable latent representation to resemble the observa-\ntion assuming it comes from a speciﬁc cluster as indicated\nby y.\n2.2.2\nInference on discrete y:\nThe discrete latent variable y is sampled based on posterior\ndistribution given z ﬁxed:\ny ∼pθ(y|x, z) =\npθ(x, y, z)\nP\ny pθ(x, y, z)\n(5)\nSuppose we have K clusters, then:\np(y = i)\n=\npθ(x, y = i, z)\nPK\ni=1 pθ(x, y = i, z)\n(6)\nwhere\npθ(x, y = i, z) ∝πi exp\n\u0014\n−||x −Gθ(y = i, z)||2\n2\n2σ2\n\u0015\n(7)\n3\nand πi is the prior probability of i-th cluster which is pre-\nspeciﬁed.\nIn fact, from Eqn. 5, the inference on y is based on true\nposterior distribution and essentially estimates the proba-\nbility of observed x falling into each cluster based on the\ncurrent latent representation z. This is essentially unsuper-\nvised clustering based on the current representation z and\nthe model Gθ(·). Existing variational-based models [23, 22]\nhave to design and learn a separate inference model for y,\ni.e., qφ(y|x), int order to approximate the true posterior dis-\ntribution pθ(y|x) which can be ineffective as demonstrated\nin our experiments.\n2.2.3\nLearning model parameter θ:\nFor given observed example xi, after obtaining inferred\ncontinuous latent variable zi using Eqn. 3 and discrete la-\ntent variable yi using Eqn. 6. We then use the sampled yi\nand zi to learn the clustered generator model by stochastic\ngradient descent as in Eqn. 1. More precisely,\n∂L(θ)\n∂θ\n=\n1\nn\nn\nX\ni=1\n\u0014 ∂\n∂θ log pθ(xi, yi, zi)\n\u0015\n(8)\nThe whole algorithm iterates the above three steps until con-\nvergence. Note that [11] shares the similar alternating na-\nture as ours. However, their model does not consider the\ndiscrete latent variable and is mainly developed for image\ngeneration. See Algorithm 1 for an summarized learning\nand inference of our model.\nNote that the whole algorithm can be efﬁcient and scale\nwell for relatively large datasets which can be shown in our\nexperiments.\nThough we use the Langevin sampling on\nz which involves multiple steps, however, the gradient in\nEqn.3 shares the same chain rule computation as in Eqn.8\nwhich greatly reduce the computation burden.\n3. Experiments\nIn this section, we demonstrate the effectiveness of the\nproposed model through the experimental results. Firstly,\nin order to show that the superior unsupervised clustering\nperformance of the proposed model, we provide a quanti-\ntative comparison of the unsupervised clustering accuracy\nof our method with other state-of-the-art methods on three\nbenchmark datasets (i.e. MNIST [25], SVHN [30], STL-10\n[8]). Furthermore, to demonstrate that the proposed model\ncan be adapted for inferring 2D label map, we perform un-\nsupervised clustering for per-pixel labels on three datasets\n(i.e., Facades [35], COCO-Stuff [4] and Potsdam [20]) and\ncompared it with the CVAE [23] and other state-of-the-art\nmethods. Meanwhile, in order to demonstrate that our pro-\nposed model has the ability to learn disentangled latent rep-\nresentations and generate realistic images, we perform im-\nage generation experiments on three benchmark datasets.\nAlgorithm 1 Learning and inference algorithm\nRequire:\n(1) training examples {xi}n\ni=1\n(2) cluster number K\n(3) cluster prior probability π = {πi}K\ni=1\n(4) number of Langevin steps l and learning iterations T\nEnsure:\n(1) learned parameters θ\n(2) inferred continuous latent variable {zi}n\ni=1\n(3) inferred discrete latent variable {yi}n\ni=1\n1: Let t ←0, initialize θ.\n2: Initialize {zi}n\ni=1 ∼N(0, Id)\n3: Initialize {yi}n\ni=1 ∼Cat(π)\nrepeat\n4: Inference on z: For each observed xi, starting from\nthe current zi and yi, run Langevin dynamics l steps to\nupdate zi as in Eqn. 3\n5: Inference on y: For each observed xi, based on the\ncurrent zi, sample, or obtain a Maximum a Posteriori\n(MAP), of y using estimated probability as in Eqn. 6.\n5: Learning θ: Update θt+1 ←θt + ηtL′(θt), with\nlearning rate ηt, where L′(θt) is computed according\nto Eqn. 8.\n5: Let t ←t + 1\nuntil t = T\nFinally, we also explore the effect of varying K’s value on\nclustering performance.\n3.1. Datasets\nTo evaluate our method, we use six public datasets:\nMNIST, SVHN, STL-10, Facades, COCO-Stuff and Pots-\ndam datasets. Figure 1 shows an example of these datasets.\nMNIST: This is a standard handwritten digits dataset. It\nconsists of 60,000 training samples and 10,000 testing sam-\nples. Each image in this dataset consists of 28 × 28 pixels,\neach of which is represented by a gray value. We reshape\neach image to a 784-dimensional row vector.\nSVHN: This dataset is obtained from the house number in\nthe Google Street View image. All images in the dataset are\n32×32 color house number images, including 73257 digits\nfor training, 26032 digits for testing sets, and extra 531131\ntraining digits, with approximately 600,000 cropped im-\nages. We use testing data to evaluate our unsupervised clus-\ntering and rest of the data is used for model training.\nSTL-10: This is an image dataset containing 10 classes\nof objects, 1,300 per class, 500 training images and 800\ntesting images. All images in the dataset are 96 × 96 color\nimages. We use training images for our model learning and\n800 testing images for unsupervised clustering accuracy\nevaluation.\n4\n(a) MNIST\n(b) SVHN\n(c) STL-10\n(d) Facades\n(e) COCO-Stuff\n(f) Potsdam\nFigure 1. Some examples of the six datasets.\nFacades: Facades dataset [35] is assembled at the Center\nfor Machine Perception, including 606 rectiﬁed images of\nfacades from various sources. It is divided into training\nsets, testing sets and validation sets. The facades are from\ncities around the world and different architectural styles.\nWe mainly consider four labels including wall, doors,\nwindows and decorations which contains roof, cornice\nand sill. We need to emphasize that the Facades dataset is\ncommonly used for image-to-image translation [18] where\nthe image is synthesized given the label map, and in this\npaper we aim to obtain the label map given the image.\nCOCO-Stuff: COCO-Stuff [4] is a challenging and diverse\nsegmentation dataset containing “stuff” classes ranging\nfrom buildings to bodies of water. Following the procedure\nin [21], we use the 15 coarse labels and 52k images\nvariant taking only images with at least 75% stuff pixels.\nCOCO-Stuff-3 is a subset of COCO-Stuff with only sky,\nground and plants labelled. All input images are shrunk,\ncropped to 128 × 128 pixels and Sobel pre-processed as\nin [21].\nPotsdam: Potsdam [20] contains 8550 RGBIR 200 × 200\npx satellite images, of which 3150 are unlabelled.\nAs\nin [21], we test the 6-label variant (roads and cars, vege-\ntation and trees, buildings and clutter) as well as a 3-label\nvariant (Potsdam-3). The construction of Potsdam-3 and\nthe training/testing set preparation also follows [21].\nNote that images from Facades, COCO-Stuff and Pots-\ndam have been manually annotated, however, the annota-\ntions are not used in our model training and are only used\nfor ground-truth evaluation.\n3.2. Evaluation Metric\nSimilar to the work of DEC [37], we use the unsu-\npervised clustering accuracy (ACC) to evaluate the perfor-\nmance of the proposed method. The formula is deﬁned as\nfollows:\nACC = max\nm∈M\n1\nN\nN\nX\ni=1\n1{li = m(ci)},\n(9)\nwhere N is the total number of all samples, li is the ground-\ntruth label and ci is the clustering assignment obtained by\nvarious models. m ∈M indicates all possible one-to-one\nmapping set between cluster assignment and labels. Kuh-\nnMunkres algorithm [28] is used to ﬁnd the best mapping.\nThe range of ACC is between 0 and 1. If the value of ACC\nis larger, it indicates that the unsupervised classiﬁcation per-\nformance is better.\n3.3. Implementation Details\nOur implementation is based on Tensorﬂow [1] frame-\nwork. The experiments are all carried out on a workstation\nwith NVIDIA GeForce RTX 2080Ti and 1 TB RAM.\nDuring the training process, the parameters of our algo-\nrithm are set as follows: we set the standard deviation σ of\nthe noise vector ε to 0.3. In each learning iteration, we set\nthe number of steps l of Langevin dynamic sampling to 100.\nWe performed T = 1000 learning iterations with learning\nrate 0.0002 and momentum 0.5.\nThe proposed cluster generation model mainly adopts\nthe structure of the deconvolutional-based generator, which\nis composed of multiple convolutional layers and decon-\nvolution layers. The complete convolutional layer is com-\nposed of convolution, ReLU layer and downsampled oper-\nation. The deconvolution layer consists of linear superpo-\nsition, ReLu layer, and upsampling operation. To make the\ntraining process more stable, we also use batch normaliza-\ntion [17]. The detailed structural information of our pro-\nposed clustered generator model will be given later and our\nexperimental code will be released.\nWe use various convolutional structures to generate the\nrealistic images through our proposed new learning algo-\nrithm. Particularly, we mainly introduce the structure of the\nnetwork for image generation on the MNIST dataset. The\nnetwork structure for image generation on the other datasets\n(SVHN, STL-10) is similar to the network structure on the\nMNIST dataset. Below we describe in detail the structure\nof the network model for performing image generation on\nthe MNIST dataset as follows.\nThe proposed network structure consists of 5 layers of\nconvolution and 5 layers of deconvolution layer. In the con-\nvolution stage, the convolution kernel size of each layer is\n4×4, the stride from the layer 1 to layer 5 is set to 1, 2, 2, 2,\n2, respectively. In the deconvolution stage, the convolution\nkernel size of each of the deconvolution layer is 4 × 4 with\nstride 2 from layer 6 to layer 9, and the stride on the layer\n10 is set to be 1. We utilize the one-hot form of the dis-\n5\n(a) MNIST\n(b) SVHN\n(c) STL-10\nFigure 2. Generated samples by our proposed method. Each row shares the same z and each column shares the same y. (a) Generate\nsamples on the MNIST dataset. (b) Generate samples on the SVHN dataset. (c) Generate samples on the STL-10 dataset.\nFigure 3. The impact of Langevin steps for unsupervised clustering\nin terms of ACC. More Langevin steps for inference indicate more\naccurate clustering.\ncrete latent variable with dimension 10, and set dimension\nfor continuous latent variables to be 100.\nMethod\nK\nMNIST\nSVHN\nSTL-10\nK-means\n10\n53.49%\n28.40%\n–\nAAE [27]\n16\n83.48%\n80.01%\n–\nDEC [37]\n10\n84.30%\n80.62%\n11.90%\nVaDE [22]\n10\n94.46%\n84.45%\n–\nHashGAN [5]\n10\n96.50%\n39.40%\n–\nCVAE [23]\n10\n82.26%\n62.37%\n58.25%\nIIC [21]\n10\n99.2%\n–\n59.6%\nOur method\n10\n98.35%\n85.15%\n75.30%\nTable 1. Comparison of unsupervised clustering accuracy (ACC)\nfor various methods on different datasets.\n3.4. Unsupervised Clustering\nWe now evaluate the model on the task of unsupervised\nclustering. We learn our model on the training sets of the\nbenchmark datasets (MNIST, SVHN and STL-10) and eval-\nuate their clustering performance on the corresponding test-\ning sets. Given the test data, we infer its corresponding\ncluster label using Eqn. 6.\nIf the inference is accurate,\nthen we would expect a competitive unsupervised cluster-\ning accuracy as indicated by ACC. We made a quantitative\ncomparison of various clustering methods, and the compar-\nison results are shown in Table 1.\nNote that the CVAE\n[23] model is primarily developed for supervised/semi-\nsupervised learning settings and we extend it for unsuper-\nvised clustering for a fair comparison.\nAs can be seen\nfrom Table 1, all deep learning models (AAE [27], DEC\n[37], VaDE [22], HashGAN [5], IIC[21] and CVAE [23])\nperform better than the traditional machine learning meth-\nods (K-means[15]). Moreover, we can achieve competi-\ntive unsupervised clustering accuracy compared with the\nstate-of-the-art methods. Speciﬁcally, on MNIST, SVHN\nand STL-10 dataset, our method achieves clustering accu-\nracy of 98.35%, 85.15% and 75.30%, which are over the\nCVAE method by 16.09%, 12.78% and 17.05%, respec-\ntively. Performance improvement is more obvious on the\nSTL-10 dataset.\nThe competitive or superior clustering accuracy ob-\ntained indicates that the inference process of our model\nis more accurate than the existing variational-based mod-\nels [22, 27, 23]. We argue this is due to the fact that those\nvariational models need carefully designed approximated\nrecognition models qφ(y|x) for efﬁcient inference. On the\nother hand, our model can perform exact inference based on\nposterior distribution in a uniﬁed probabilistic framework\nwhich leads to better inference and clustering accuracy. It\nis worth noting that more steps of Langevin dynamics with\n6\nEqn. 3 will render more accurate inference on continuous z\nwhich will further improve the accuracy of the unsupervised\nclustering as can be seen from Figure 3.\n3.5. Per-pixel Unsupervised Clustering\nIn this section, we evaluate the ability of the model\nto accurately infer 2D discrete latent map by performing\nunsupervised clustering tasks on three datasets: Facades,\nCOCO-stuff and Potsdam. To the best of our knowledge,\nthere is currently among the only few methods [21] that\nattempt to perform per-pixel unsupervised clustering of an\nimage. The main challenge is that the per-pixel clustering\nshould conform to the underlying pixel-wise relations (e.g.,\nconsistency for neighbouring regions) which require accu-\nrate inference. Our proposed model can obtain reasonably\nwell per-pixel unsupervised clustering result.\nMethod\nCOCO-Stuff-3\nCOCO-Stuff\nPotsdam-3\nPotsdam\nK-means\n52.2%\n14.1%\n45.7%\n35.3%\nSIFT [26]\n38.1%\n20.2%\n38.2%\n28.5%\nDeepCluster [6]\n41.6%\n19.9%\n41.7%\n29.2%\nCo-Occurrence [19]\n54.0%\n24.3%\n63.9%\n44.9%\nIIC [21]\n72.3%\n27.7%\n65.1%\n45.4%\nCVAE [23]\n62.4%\n24.5%\n61.9%\n39.8%\nOur method\n73.3%\n28.1%\n66.3%\n46.2%\nTable 2. Comparison of unsupervised clustering accuracy (ACC)\nfor various methods on different datasets. The accuracy numbers\nexcept CVAE and our model are from [21].\nUnlike tradition clustering methods, we cluster each\npixel on the label map. The traditional clustering method,\nas we show in the previous experiment, considers one-\ndimensional vector space which forms a one-hot representa-\ntion. It should be noted that we are now performing cluster-\ning in a two-dimensional pixel space. Speciﬁcally, we con-\nsider one-hot representation for every pixel based on which\nwe perform the inference using Eqn. 5. In order to make\na fair comparison with the CVAE model, all other settings\n(e.g. the number of labels in datasets and the number of it-\nerations of the unsupervised clustering algorithm) are kept\nuntouched except for the clustering method.\nFor a qualitative comparison, we present the cluster as-\nsignment obtained by our method and CVAE method in the\nform of label maps and compare them with the ground truth\nlabels. The visualization of the per-pixel unsupervised clus-\ntering results is shown in Figure 4. We also quantitatively\ncompare with the CVAE and other related baseline mod-\nels in terms clustering accuracy (ACC) on COCO-Stuff and\nPotsdam datasets. The preparation of the datasets are fol-\nlowed by the routine in [21] and the results are shown in\nTable 2. Note that the baseline models (SIFT [26], Deep-\nCluster [6],Co-Occurrence [19] ) do not directly learn a\nclustering function and requires further application of k-\nmeans to be used for image clustering. The most recent\nIIC [21] model can directly learn 2D clustering map, how-\never, it only learns the feature embedding and is unable to\nrepresent the observed data distribution, therefore does not\nhave generation ability as we do in Sec.3.6.\nAs shown in Figure 4, compared to CVAE method, our\napproach can better preserve the internal structure of the\nbuilding and objects, and can also clearly display the details.\nThis can be further veriﬁed by Table 2 where our model\nachieve the competitive or better clustering accuracy.\n3.6. Image Generation\nOur model can not only obtain the powerful data embed-\nding to ensure the accurate unsupervised clustering, it can\nalso learn the disentangled latent representations to generate\nrealistic samples. To demonstrate the effectiveness of our\nproposed, we perform experiments on the MNIST, SVHN\nand STL-10 datasets. We set K = 10 on three datasets to\ntrain our proposed model and show that the learning and\ninference of the latent variables could obtain disentangled\nlatent representations of the data. To show this, we obtain\nthe generated samples through learned clustered generator\nmodel by varying the two sets of latent variables in the fol-\nlowing way:\n(1) Firstly, we change the continuous latent variable z\nwithin a certain range by ﬁxing the discrete class y;\n(2) Secondly, we ﬁx the continuous latent variable z and\nenumerate all possible values of discrete class label y.\nFigure 2 shows the generation result of our model on\nthe three datasets MNIST, SVHN and STL10. As can be\nseen from Figure 2, the image generated by our model is\nboth realistic and diverse. Meanwhile, it can be clearly seen\nthat if the cluster label is ﬁxed, the generated samples have\ndifferent styles and variations while maintaining their iden-\ntity, indicating that continuous latent variable z effectively\ncaptures the variations within each cluster. On the other\nhand, the change of discrete latent variable y could change\nthe identity of the sample, indicating that it can be effective\nfor cluster label modeling. Therefore, the learned discrete\nlatent variable y and continuous z form the disentangled la-\ntent representation.\n3.7. The Impact of the Number of Clusters\nThe number of clusters K is given as priori in our model,\nand K is set to be the number of classes for each dataset. To\nfurther investigate how different K could affect our model,\nwe conduct experiments on the MNIST dataset for differ-\nent K. We randomly set different K values on the MNIST\ndataset, such as 6 and 12. The experimental results of clus-\ntering are shown in Figure 5. It can be seen from Figure\n5 that if the number of clusters K is smaller than the ac-\ntual number of classes, digits with similar appearances are\ngrouped together, such as digits 3, 6, and 5. If the number\nof clusters K is larger than the actual the number of classes,\nsome digits are divided into subclasses based on visually\n7\nFigure 4. Qualitative comparison of our clustering results with the CVAE method on three datasets: Facade (top), COCO-Stuff-3 (middle)\nand Potsdam-3 (bottom). The ﬁrst column is the testing image. The second column is the clustering result of our method. The third column\nis the clustering result of the CVAE method, and the ground-truth (GT) label map is shown in the last column. COCO-Stuff-3 considers\nlabels: sky, vegetation and ground. The Potsdam-3 considers: vegetation, roads and buildings.\n(a) k=6\n(b) k=12\nFigure 5.\nVisual comparison of the clustering results by setting\ndifferent number of clusters (i.e. 6 and 12) on the MNIST dataset.\nappearance identiﬁable attributes, such as digits italics and\nroundness. As can be seen from the Figure 5 (b), the upright\nand oblique 1 are divided into two clusters, and the 9 with\ntwo handwritten styles are also divided into two clusters.\n4. Conclusion\nIn this paper, we propose the clustered generator model\nfor the task of unsupervised clustering. The clustered gener-\nator model contains both the discrete latent variables which\ncapture the cluster labels and the continuous latent variables\nwhich capture the variations within the clusters. We then\ndevelop the novel learning and inference algorithm for clus-\ntered generator in a uniﬁed probabilistic framework. Specif-\nically, we iteratively infer the continuous and discrete latent\nvariables in a Gibbs manner, then use the inferred variables\nto learn the clustered generator model. The learning can\nnaturally incorporate the unsupervised clustering as an in-\nference step without the need for extra assisting models for\napproximation. The latent variables learned can be served\nas both observed data embedding as well as latent repre-\nsentations for data distribution. The extensive experiments\nshow both quantitatively and qualitatively the effectiveness\nof our proposed model.\nThe model can be adapted for semi-supervised learning\ngiven only a small portion of the label. The model can also\nbe generalized to a dynamic one by including the transition\nmodel for latent variables. Besides, the number of clusters\nK is pre-speciﬁed in the current work and can be learned\ndirectly from data. We leave these as our future directions.\n8\nAcknowledgment\nThe work is partially supported by DARPA XAI project\nN66001-17-2-4029.\nReferences\n[1] Mart´ın Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen,\nAndy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghe-\nmawat, Geoffrey Irving, Michael Isard, et al. Tensorﬂow: A\nsystem for large-scale machine learning. In 12th {USENIX}\nSymposium on Operating Systems Design and Implementa-\ntion ({OSDI} 16), pages 265–283, 2016. 5\n[2] Martin Arjovsky, Soumith Chintala, and L´eon Bottou.\nWasserstein gan.\narXiv preprint arXiv:1701.07875, 2017.\n2, 3\n[3] Christopher M. Bishop. Pattern Recognition and Machine\nLearning (Information Science and Statistics).\nSpringer-\nVerlag, Berlin, Heidelberg, 2006. 1, 2\n[4] Holger Caesar, Jasper Uijlings, and Vittorio Ferrari. Coco-\nstuff: Thing and stuff classes in context.\nIn Proceedings\nof the IEEE Conference on Computer Vision and Pattern\nRecognition, pages 1209–1218, 2018. 4, 5\n[5] Yue Cao, Bin Liu, Mingsheng Long, and Jianmin Wang.\nHashgan:\nDeep learning to hash with pair conditional\nwasserstein gan. In The IEEE Conference on Computer Vi-\nsion and Pattern Recognition (CVPR), June 2018. 2, 6\n[6] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and\nMatthijs Douze. Deep clustering for unsupervised learning\nof visual features. In Proceedings of the European Confer-\nence on Computer Vision (ECCV), pages 132–149, 2018. 7,\n8\n[7] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya\nSutskever, and Pieter Abbeel. Infogan: Interpretable repre-\nsentation learning by information maximizing generative ad-\nversarial nets. In Advances in Neural Information Processing\nSystems, pages 2172–2180, 2016. 2\n[8] Adam Coates, Andrew Ng, and Honglak Lee.\nAn analy-\nsis of single-layer networks in unsupervised feature learning.\nIn Proceedings of the fourteenth international conference on\nartiﬁcial intelligence and statistics, pages 215–223, 2011. 4\n[9] Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo,\nMatthew CH Lee, Hugh Salimbeni, Kai Arulkumaran, and\nMurray Shanahan.\nDeep unsupervised clustering with\ngaussian mixture variational autoencoders. arXiv preprint\narXiv:1611.02648, 2016. 1, 2\n[10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing\nXu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and\nYoshua Bengio. Generative adversarial nets. In Advances\nin neural information processing systems, pages 2672–2680,\n2014. 2\n[11] Tian Han, Yang Lu, Song-Chun Zhu, and Ying Nian Wu. Al-\nternating back-propagation for generator network. In AAAI,\nvolume 3, page 13, 2017. 1, 2, 4\n[12] Tian Han, Erik Nijkamp, Xiaolin Fang, Mitch Hill, Song-\nChun Zhu, and Ying Nian Wu. Divergence triangle for joint\ntraining of generator model, energy-based model, and infer-\nence model. arXiv preprint arXiv:1812.10907, 2018. 2\n[13] Tian Han, Erik Nijkamp, Xiaolin Fang, Mitch Hill, Song-\nChun Zhu, and Ying Nian Wu. Divergence triangle for joint\ntraining of generator model, energy-based model, and in-\nferential model.\nIn Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition, pages 8670–\n8679, 2019. 2, 3\n[14] Tian Han, Xianglei Xing, and Ying Nian Wu.\nLearning\nmulti-view generator network for shared representation. In\n2018 24th International Conference on Pattern Recognition\n(ICPR), pages 2062–2068. IEEE, 2018. 2\n[15] John A Hartigan and Manchek A Wong. Algorithm as 136:\nA k-means clustering algorithm. Journal of the Royal Sta-\ntistical Society. Series C (Applied Statistics), 28(1):100–108,\n1979. 1, 2, 6\n[16] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess,\nXavier Glorot, Matthew Botvinick, Shakir Mohamed, and\nAlexander Lerchner. beta-vae: Learning basic visual con-\ncepts with a constrained variational framework.\nICLR,\n2(5):6, 2017. 2\n[17] Sergey Ioffe and Christian Szegedy. Batch normalization:\nAccelerating deep network training by reducing internal co-\nvariate shift. arXiv preprint arXiv:1502.03167, 2015. 5\n[18] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A\nEfros. Image-to-image translation with conditional adver-\nsarial networks. In Proceedings of the IEEE conference on\ncomputer vision and pattern recognition, pages 1125–1134,\n2017. 5\n[19] Phillip Isola, Daniel Zoran, Dilip Krishnan, and Edward H\nAdelson.\nLearning visual groups from co-occurrences in\nspace and time. arXiv preprint arXiv:1511.06811, 2015. 7,\n8\n[20] WGIII ISPRS. 4. isprs 2d semantic labeling contest. 4, 5\n[21] Xu Ji, Jo˜ao F Henriques, and Andrea Vedaldi.\nInvariant\ninformation clustering for unsupervised image classiﬁcation\nand segmentation. In Proceedings of the IEEE International\nConference on Computer Vision, pages 9865–9874, 2019. 2,\n5, 6, 7, 8\n[22] Zhuxi Jiang, Yin Zheng, Huachun Tan, Bangsheng Tang, and\nHanning Zhou. Variational deep embedding: An unsuper-\nvised and generative approach to clustering. arXiv preprint\narXiv:1611.05148, 2016. 1, 2, 4, 6\n[23] Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende,\nand Max Welling. Semi-supervised learning with deep gen-\nerative models. In Advances in neural information process-\ning systems, pages 3581–3589, 2014. 1, 2, 3, 4, 6, 7\n[24] Diederik P Kingma and Max Welling. Auto-encoding varia-\ntional bayes. arXiv preprint arXiv:1312.6114, 2013. 1, 2\n[25] Yann LeCun, L´eon Bottou, Yoshua Bengio, Patrick Haffner,\net al. Gradient-based learning applied to document recog-\nnition. Proceedings of the IEEE, 86(11):2278–2324, 1998.\n4\n[26] David G Lowe.\nDistinctive image features from scale-\ninvariant keypoints. International journal of computer vi-\nsion, 60(2):91–110, 2004. 7, 8\n[27] Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian\nGoodfellow, and Brendan Frey. Adversarial autoencoders.\narXiv preprint arXiv:1511.05644, 2015. 2, 6\n9\n[28] James Munkres. Algorithms for the assignment and trans-\nportation problems. Journal of the society for industrial and\napplied mathematics, 5(1):32–38, 1957. 5\n[29] Radford M Neal et al. Mcmc using hamiltonian dynamics.\nHandbook of markov chain monte carlo, 2(11):2, 2011. 3\n[30] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis-\nsacco, Bo Wu, and Andrew Y Ng. Reading digits in natural\nimages with unsupervised feature learning. 2011. 4\n[31] Andrew Y Ng, Michael I Jordan, and Yair Weiss. On spectral\nclustering: Analysis and an algorithm. In Advances in neural\ninformation processing systems, pages 849–856, 2002. 2\n[32] Alec Radford, Luke Metz, and Soumith Chintala.\nUn-\nsupervised representation learning with deep convolu-\ntional generative adversarial networks.\narXiv preprint\narXiv:1511.06434, 2015. 1, 2, 3\n[33] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wier-\nstra. Stochastic backpropagation and approximate inference\nin deep generative models. arXiv preprint arXiv:1401.4082,\n2014. 2\n[34] Jianbo Shi and Jitendra Malik. Normalized cuts and image\nsegmentation. Departmental Papers (CIS), page 107, 2000.\n2\n[35] Radim Tyleˇcek and Radim ˇS´ara. Spatial pattern templates\nfor recognition of objects with regular structure.\nIn Ger-\nman Conference on Pattern Recognition, pages 364–374.\nSpringer, 2013. 4, 5\n[36] Ulrike Von Luxburg. A tutorial on spectral clustering. Statis-\ntics and computing, 17(4):395–416, 2007. 2\n[37] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised\ndeep embedding for clustering analysis.\nIn International\nconference on machine learning, pages 478–487, 2016. 1,\n2, 5, 6\n[38] Yi Yang, Dong Xu, Feiping Nie, Shuicheng Yan, and Yueting\nZhuang. Image clustering using local discriminant models\nand global integration. IEEE Transactions on Image Pro-\ncessing, 19(10):2761–2773, 2010. 2\n10\n",
  "categories": [
    "stat.ML",
    "cs.LG"
  ],
  "published": "2019-11-19",
  "updated": "2019-11-19"
}