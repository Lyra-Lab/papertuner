{
  "id": "http://arxiv.org/abs/1912.02864v1",
  "title": "Transfer Learning from an Auxiliary Discriminative Task for Unsupervised Anomaly Detection",
  "authors": [
    "Urwa Muaz",
    "Stanislav Sobolevsky"
  ],
  "abstract": "Unsupervised anomaly detection from high dimensional data like mobility\nnetworks is a challenging task. Study of different approaches of feature\nengineering from such high dimensional data have been a focus of research in\nthis field. This study aims to investigate the transferability of features\nlearned by network classification to unsupervised anomaly detection. We propose\nuse of an auxiliary classification task to extract features from unlabelled\ndata by supervised learning, which can be used for unsupervised anomaly\ndetection. We validate this approach by designing experiments to detect\nanomalies in mobility network data from New York and Taipei, and compare the\nresults to traditional unsupervised feature learning approaches of PCA and\nautoencoders. We find that our feature learning approach yields best anomaly\ndetection performance for both datasets, outperforming other studied\napproaches. This establishes the utility of this approach to feature\nengineering, which can be applied to other problems of similar nature.",
  "text": "Transfer Learning from an Auxiliary Discriminative Task for\nUnsupervised Anomaly Detection\nUrwa Muaz\nCenter for Urban Science and Progress\nNew York University\nurwa.muaz@nyu.edu\nStanislav Sobolevsky\nCenter for Urban Science and Progress\nNew York University,\nInstitute Of Design And Urbanism\nITMO University, Saint-Petersburg\nsobolevsky@nyu.edu\nAbstract\nUnsupervised anomaly detection from high\ndimensional data like mobility networks is\na challenging task.\nStudy of different ap-\nproaches of feature engineering from such\nhigh dimensional data have been a focus\nof research in this ﬁeld.\nThis study aims\nto investigate the transferability of features\nlearned by network classiﬁcation to unsuper-\nvised anomaly detection.\nWe propose use\nof an auxiliary classiﬁcation task to extract\nfeatures from unlabelled data by supervised\nlearning, which can be used for unsupervised\nanomaly detection. We validate this approach\nby designing experiments to detect anomalies\nin mobility network data from New York and\nTaipei, and compare the results to traditional\nunsupervised feature learning approaches of\nPCA and autoencoders. We ﬁnd that our fea-\nture learning approach yields best anomaly de-\ntection performance for both datasets, outper-\nforming other studied approaches. This estab-\nlishes the utility of this approach to feature en-\ngineering, which can be applied to other prob-\nlems of similar nature.\n1\nIntroduction\nRecent availability of big data on human mobility\nbroadens our horizons of understanding of human\nsociety at global (Hawelka et al., 2014; Belyi et al.,\n2017) and local scale (Kung et al., 2014; Kang\net al., 2013; Amini et al., 2014) and urban trans-\nportation in particular (Santi et al., 2014; Nyhan\net al., 2016; Tachet et al., 2016). However com-\nplexity and dimensionality of the data along with\nsparsity of available measurements at the local\nscale and resulting high noise-to-signal ratio chal-\nlenges our ability of detecting robust and mean-\ningful patterns from it.\nUnsupervised anomaly detection is a ma-\njor frontier of machine learning research with\nwidespread applications in many domains, trans-\nportation being one of them.\nThere is an in-\ncreasing interest in detection of anomalous mo-\nbility patterns and congestion events. According\nto the Federal Highway Administration (FHWA)\nthese non recurring congestion events account for\napproximately 55 % of delays caused in travel\ntimes of the drivers in the United States System-\natics (2004). Predicting future trafﬁc congestions\ncan inform the route planning and scheduling and\nprevent worsening of these conditions. Anoma-\nlies in urban mobility patterns can also be indica-\ntive of potentially dangerous situations. Examples\nof these scenarios include 2015 New Years Eve\ncelebrations in Shanghai, where overcrowding re-\nsulted in a stampede causing 36 casualties. Early\ndetection of these events can enable the authorities\nto take preventive measures to mitigate and pre-\nvent the consequences.\nThe core of anomaly detection is constructing a\nprobabilistic model of normal behavior and iden-\ntifying anomalies as observations with small like-\nlihood under the model. Mobility network data\nis usually very high-dimensional and traditional\nanomaly detection methods do not perform well\nwith high dimensional data, especially when the\ndataset size is not many times larger than the num-\nber of dimensions Chandola et al. (2009). This is\na generic issue with machine learning models and\nis referred to as the curse of dimensionality Bell-\nman (1957). Most prior works address this issue\nby adopting a two stage approach (Ranshous et al.,\n2015; Chandola et al., 2009), where low dimen-\nsional representation is learned prior to applying\nanomaly detection techniques on the latent repre-\nsentation.\nUnsupervised feature learning from unlabelled\ndata is itself an important area of research.\nTraditionally, low dimensional representation is\nachieved using statistical decomposition methods\nlike PCA Jolliffe (2011) or deep representation\nlearning methods like auto-encoders Hinton and\nSalakhutdinov (2006). PCA can be used to en-\narXiv:1912.02864v1  [cs.LG]  5 Dec 2019\ncode the data into low dimensional space with\naim to capture most of the variance of the raw\ndata, and auto-encoders compress the data into\nlow dimensional representation space with the ob-\njective of accurate reconstruction of the raw data.\nIn this study we formulate an arbitrary classiﬁ-\ncation task from the data for which labels are\nknown and train deep neural networks classiﬁers\non it. We then investigate if the deep features ex-\ntracted from the higher layers of this classiﬁca-\ntion network are transferable to the unsupervised\nanomaly detection task. Furthermore, we evaluate\nthis approach on anomaly detection in urban mo-\nbility and compare it to other feature learning ap-\nproaches mentioned above. We ﬁnd that transfer\nlearning from an auxiliary classiﬁcation task to un-\nsupervised task on the same data set is a promising\napproach and yields better results than other fea-\nture learning approaches considered in this study.\nOur main contributions are summarized as fol-\nlows: i) we show that discriminative training on\nan auxiliary classiﬁcation task is a promising ap-\nproach to learn meaningful feature representation\nwhich is transferable to unsupervised anomaly de-\ntection, this has not been studied before to the\nbest of our knowledge ii) we provide an empiri-\ncal comparison of our approach with existing ap-\nproaches of PCA and autoencoders iii) we vali-\ndate our approach on a downstream application of\nanomaly detection in urban mobility networks iv)\nwe show that in presence of underlying topology,\nuse of graph convolutional layers give better fea-\nture space as measured by efﬁcacy of anomaly de-\ntection.\n2\nRelated Work\nThe most widely used method for anomaly detec-\ntion is density estimation of the feature space and\nisolating low probability density observations as\nanomalies. Methods used for density estimation\ninclude multivariate Gaussian Models multivari-\nate Gaussian Models, Gaussian Mixture Models,\nk-means (Barnett and Lewis, 1984; Zimek et al.,\n2012; Kim and Scott, 2012). Since the network\ndata is usually high-dimensional, direct applica-\ntion of these algorithms suffer from the curse of\ndimensionality. Most prior works address this is-\nsue by adopting a two stage approach (Chandola\net al., 2009; Ranshous et al., 2015), where low di-\nmensional representation is learned from high di-\nmensional data ﬁrst, and subsequently density es-\ntimation based anomaly detection is applied to this\nlatent representation. There are numerous meth-\nods in literature to achieve low dimensional repre-\nsentation from data.\nStatistical decomposition methods perform di-\nmensionality reduction by leveraging the fact that\nusually high dimensional data has underlying low\ndimensional structure and thus most of the vari-\nance of the data can be encoded in a few dimen-\nsions. Most widely used means of achieving ma-\ntrix decomposition is Principal Component Anal-\nysis (PCA) Jolliffe (2011), and its more sophis-\nticated variants have also been studied (Huber,\n2011; Cand`es et al., 2011). We use PCA as one\nof our baseline methods.\nUnsupervised\nDeep\nrepresentation\nlearning\nmethods like autoencoders Hinton and Salakhut-\ndinov (2006) and generative adversarial networks\n(GAN) Goodfellow et al. (2014) are used to learn\na latent representation that are capable of accu-\nrate reconstruction or generation of data. Unlike\nlinear PCA they are capable of learning complex\nnon-linear relationships. Autoencoders have been\nwidely used in computer vision to learn power-\nful representations from unlabelled data (Chan-\ndola et al., 2009; Zhai et al., 2016; Bengio et al.,\n2007; MarcAurelio Ranzato et al., 2007; Masci\net al., 2011). They are also a popular dimensional-\nity reduction technique for anomaly detection in\nhigh dimensional dataset (Zhou and Paffenroth,\n2017; Zhai et al., 2016). Zong et al. (2018) uses\na coupled pipeline of deep autoencoder and Gaus-\nsian Mixture Models for unsupervised anomaly\ndetection. Sobolevsky et al. (2019) builds upon\nthis to proposes a three stage pipeline approach\nfor anomaly detection in high dimensional net-\nwork data sets, they use topological aggregation\nbefore Autoencoder and Gaussian Mixture Mod-\nels to tackle the issue of high noise to signal ra-\ntio in edge level measurements. Some previous\nworks use cost associated with reconstruction as\nfeature for anomaly detection. They rely on the as-\nsumption that anomalies can not be accurately re-\nconstructed from the representation space, which\ndoes not always hold so latent space provides more\nreliable features Zong et al. (2018).\nSimilarly\nto autoencoders, use of GAN as a representation\nlearning technique is also a growing research ﬁeld\n(Zenati et al., 2018; Schlegl et al., 2017). We im-\nplement deep autoencoders as a second baseline\nfor comparison with our proposed methodology.\nCity\nDays\nNodes\nAvg. Daily Ridership\nNational Holidays\nTaipei\n638\n108\n112055\n30\nNew York\n548\n263\n7060\n15\nTable 1: Dataset Summary\nNew York\nTaipei\nNetwork\nNodes\nEdges\nNodes\nEdges\nRaw\n263\n65722\n108\n11664\nAggregated\n24\n576\n10\n100\nTable 2: Topological Aggregation of Mobility Network\nDiscriminative training can be used for feature\nlearning from unlabelled data by creating an aux-\niliary classiﬁcation task to train neural networks.\nActivations from deeper layers can be used as a\nlow dimensional latent space for end application.\nTheir use in computer vision have shown that they\nare capable of learning powerful representations.\nExamples of this type of tasks in computer vision\nare learning the relative positions of image patches\n(Doersch et al., 2015; Noroozi and Favaro, 2016) ,\ncolorizing grayscale images (Zhang et al., 2016;\nLarsson et al., 2016), or learning the geometric\ntransformations applied on images Zimek et al.\n(2012). Usually, discriminative feature learning is\nused as a pre-training method for transfer learn-\ning into another supervised task.\nFirst research\nthat investigates the use of features learned from\na supervised task for unsupervised learning prob-\nlem is conducted by Gu´erin et al. (2017). This re-\nsearch shows that performance of deep CNN fea-\ntures from imagenet for image clustering is com-\nparable to other state of the art unsupervised fea-\nture learning methods. To the best of our knowl-\nedge the transferability of features learned from\nclassiﬁcation to unsupervised anomaly detection\nhave not been studied before. In this research we\ninvestigate this problem.\n3\nMethodology\n3.1\nDatasets\nMobility Datasets: In this study we used two pub-\nlicly available real world urban mobility datasets.\nFirst dataset is a subway ridership dataset for the\ncity of Taipei, this data contains origin destina-\ntion mobility for 108 subway stations. 21 months\nof data ranging from January 2017 to September\n2018 was used in this study. Second dataset is taxi\ntrips for the city of New York, this contains ori-\ngin destination trip information for 263 taxi zones\nin New York. 18 Months of data ranging from\nJuly 2017 to December 2018 was used for this\nstudy. Both datasets were aggregated at a daily\nlevel for experiments. Since ridership counts over\ntime could be affected by data collection which\nsometimes changes over extensive periods of time,\nwe apply normalization along the spatial axis to\navoid temporal inconsistencies.\nEvents Datasets: We are investigating a novel\nmethodology for unsupervised anomaly detection\nbut we need a mechanism to compare the per-\nformance of our method to other existing tech-\nniques. For that purpose, we collected a dataset of\ndates which we believe will have anomalous urban\nmobility patterns. National holidays are a good\nchoice because they result in closing of public and\nprivate institutions and disrupt the commute pat-\nterns of the city. Furthermore, they occur more\nfrequently as compared to other rare events, ren-\ndering the performance estimates more reliable.\nThere were 30 national holidays in Taipei and 16\nin New York for the respective durations under\nstudy. Dataset summary is provided in table 1.\n3.2\nPipeline Approach\nA two staged pipieline approach is common in\nprior works (Chandola et al., 2009; Ranshous\net al., 2015), where ﬁrst stage is feature learning\nwhere a meaningful low dimensional representa-\ntion is learned from high dimensional data, and\nsecond stage is application of density estimation\nbased anomaly detection to this feature represen-\ntation. Sobolevsky et al. (2019) proposes a three\nstaged pipeline for anomaly detection in high di-\nmensional network data, they add a topological\naggregation as a ﬁrst step before feature learning\nto tackle the issue of high noise to signal ratio in\nedge level measurements. The approach has been\nfurther evaluated in He et al. (2019) for anomaly\ndetection in urban mobility across several major\ncities, and yielded superior results to other ap-\nproaches under study. We adopt this three stage\npipeline approach when dealing with edge level\nfeatures. Within this anomaly detection pipeline\nframework we test our proposed feature learning\nmethod as its second step and compare it with ex-\nisting methods by evaluating the overall perfor-\nmance of the resulting pipeline.\n3.3\nNetwork Representation\nThe mobility data with origin destination informa-\ntion is a natural candidate for being represented\nas a temporal network. Each day of data is repre-\nsented as a graph, where Taxi zones in New York\nand subway stations in Taipei become the nodes of\nthe network. Two different network conﬁgurations\nhave been used for this research, ﬁrst models rid-\nership as node features and the other regards them\nas edge features.\nEdge Features: In this conﬁguration there are\nno node features and edge features denote the rid-\nership between the nodes. The edge level features\nhave very high dimensionality and also suffer from\nhigh noise to signal ratio, so we need to use some\nsort of aggregation. We use the pipeline approach\nproposed by Sobolevsky et al. (2019). Topological\naggregation of network is performed through com-\nmunity detection to address these issues prior to\nlow dimensional feature engineering. Community\naggregation also reduces the dimensionality of the\ngraph data, making it more manageable for exper-\niments. We use COMBO proposed by Sobolevsky\net al. (2014) for community aggregation of the net-\nwork in this study. The effect of network aggrega-\ntion on network size is summarized in table 2. This\npipeline approach is used for all experiments and\nbaselines for edge feature conﬁguration.\nNode Features: Alternatively we aggregate the\nincoming and outgoing trafﬁc for each node to get\nthe node features. This reduces dimensionality of\nthe problem allowing to focus on a key character-\nistic of mobility such as local distribution of its\nvolume. It might be efﬁcient for many applica-\ntions discovering patterns where the local volume\nis impacted and individual nodes have sufﬁcient\ndata volume, however missing the network struc-\nture could be seen as a limitation. However the\nadvantage of this representation is that one can\nuse it along with the actual physical connections\nof the transport system. This allows us to use fur-\nther graph convolution localizing the ﬁlters based\non transport connections. Such physical connec-\ntions are clearly represented between subway sta-\ntions unlike the taxi zones, so this network repre-\nsentation is only used for Taipei subway data.\nFigure 1: Transfer Learning from AutoEncoder\nFigure 2: Transfer Learning from Auxiliary Classiﬁca-\ntion\n3.4\nFeature Learning\nSince the network data is high-dimensional, di-\nrect application of anomaly detection algorithms\nsuffer from the curse of dimensionality Chandola\net al. (2009). Prior works address this issue by\nadopting a two stage approach (Chandola et al.,\n2009; Ranshous et al., 2015), where low dimen-\nsional representation is learned from high dimen-\nsional data ﬁrst, and subsequently density estima-\ntion based anomaly detection is applied to this la-\ntent representation.\nThus, to further reduce the\ncomplexity of high-dimensional network data en-\nabling the application of anomaly detection, we\nneed to learn a suitable low dimensional features\nspace. A large body of traditional dimensionality\nreduction tools are available, most common ones\nbeing statistical decomposition methods like PCA\nJolliffe (2011) and deep representation learning\nmethods like auto-encoders Hinton and Salakhut-\ndinov (2006). Along with our proposed feature\nlearning approach we also implement traditionally\nused techniques from the literature. All the meth-\nods represent the data into 20 dimensional latent\nspace for fair comparison.\nWe propose an auxiliary classiﬁcation task\nwhich we believe will enable the classiﬁer to learn\nrepresentations that will be useful for anomaly de-\ntection. We train models to discriminate weekdays\nfrom weekends based on daily ridership patterns.\nWe use a Multilayered perceptron (MLP) com-\nposed of four fully connected layers, where the\nnumber of nodes in each layer decrease steadily to\nachieve dimensionality reduction while preserving\nthe information necessary for classiﬁcation. Fig-\nure 1 and Figure 2 provide a architectural compar-\nison of our approach and deep autoencoders, one\nof the baselines. Network is trained for the classi-\nﬁcation task and the activations of third layer are\nused as a 20 dimensional latent space. This does\nnot use topological structure on the network. This\nmethod is denoted as Discriminative-MLP in the\nresults. Model trained on cross entropy loss us-\ning adam optimizer. 100 epochs of training are\nperformed with weight decay and learning rate of\n0.001.\nGraph Convolutions: Node feature represen-\ntation of Taipei also encodes the topological infor-\nmation of connectivity of stations. Transport net-\nworks are known to have strong spatial and struc-\ntural correlations. Multilayered percepton is very\ngood at modeling complex non linear relation-\nships but it does not adequately address the spa-\ntial and structural dependencies between different\nnodes in a trafﬁc network accurately. Convolu-\ntional neural networks (CNN) based approaches\n(Ma et al., 2017; Zhang et al., 2017) have been\nused in transport networks because of their abil-\nity to model spatial relationships between nodes.\nThough, traditional CNN work well with mod-\nelling images and other spatial relationships in Eu-\nclidean space, they are not appropriate for net-\nworks where the connectivity and structure goes\nbeyond spatial proximity. Recently, convolution\noperators have been generalized for graph domain\nand many variants exist in the literature.\nRe-\ncently, they have been applied to trafﬁc modelling\nproblems with great success (Li et al., 2017; Cui\net al., 2018). We use ﬁrst order approximations\nof spectral graph convolution introduced by Kipf\nand Welling (2016) in this study to model spa-\ntial relationships. Higher order convolutions can\nbe achieved by stacking multiple ﬁrst order graph\nconvolution layers. We experiment with preceding\nthe MLP with graph convolutional layers to see\nif this improves the quality of latent representa-\ntions. In this model the MLP component operates\non latent representation of nodes rather than actual\nnode features. This architecture is referred to as\nDiscriminative-GCN in the results. We stacked\ndifferent number of ﬁrst order GCN layers to ﬁnd\nthe optimal order of convolution for anomaly de-\ntection in Taipei subway network. Training pa-\nrameters and method is similar to MLP method\ndescribed above.\n3.5\nFeature Learning Baselines\nPCA essentially learns a linear transformation that\nprojects the data into another space, where vectors\nof projections are deﬁned by the variance of the\ndata. By restricting the dimensionality to a certain\nnumber of components that account for most of\nthe variance of the data set, we can achieve dimen-\nsionality reduction. We retain ﬁrst 20 components\nto achieve a 20 dimensional latent representation.\nAutoencoders are neural networks that can be\nused to reduce the data into a low dimensional\nlatent space. As shown in ﬁgure 1 they have a\nencoder-decoder architecture, where the encoder\nmaps the input to latent space and decoder re-\nconstructs the input. They are trained using back\npropagation for accurate reconstruction of the in-\nput.\nBy intuition, these low dimensional latent\nvariables should encode most important features\nof the input since they are capable of accurate re-\nconstructing of the input. We implement autoen-\ncoder to represent our data into 20 dimensional la-\ntent space. Both the encoder and decoder are com-\nposed of three layers and the network is trained us-\ning binary cross entropy loss. 100 epochs of train-\ning are performed with weight decay and learning\nrate of 0.01 using adams optimizer.\nFeatures\nF1 Score\nPrecision\nRecall\nHolidays Identiﬁed\nPCA\n0.458\n0.579\n0.379\n11\nAutoencoder\n0.433\n0.419\n0.448\n13\nDiscriminative MLP\n0.575\n0.451\n0.793\n23\nDiscriminative GCN\n0.633\n0.655\n0.613\n19\nTable 3: Anomaly detection results for Node Feature representation of Taipei\nFeatures\nF1 Score\nPrecision\nRecall\nHolidays Identiﬁed\nPCA\n0.547\n0.455\n0.690\n20\nAutoencoder\n0.550\n0.431\n0.759\n22\nDiscriminative MLP\n0.778\n0.840\n0.724\n21\nTable 4: Anomaly detection results for Edge Feature representation of Taipei\nFeatures\nF1 Score\nPrecision\nRecall\nHolidays Identiﬁed\nPCA\n0.563\n0.563\n0.563\n9\nAutoencoder\n0.200\n0.130\n0.438\n7\nDiscriminative MLP\n0.563\n0.563\n0.563\n9\nTable 5: Anomaly detection results for New York\n3.6\nDensity Estimation\nGaussian Mixture Model Reynolds (2015) is used\nto construct a density estimation model of nor-\nmal behavior and anomalies are identiﬁed as ob-\nservations with small probability density under\nthis model. A simple approach would be to ﬁt a\nmultivariate Gaussian to data and perform outlier\ndetection based on p-value threshold as done by\nHodge and Austin (2004). But real world data of-\nten has multiple underlying distributions and as-\nsumption of a single distribution does not hold.\nIn our case, the weekdays are expected to have a\ndifferent ridership distribution than weekends. A\npotential solution is to use gaussian mixture mod-\nels (GMM) Reynolds (2015), which is paramet-\nric probability distribution model which represents\nthe data distribution as weighted sum of normally\ndistributed sub-populations. Thus we use GMM\nfor density estimation and outlier detection is then\nperformed by p-value thresholding on component\nsub-populations as done by Laxhammar (2008).\n3.7\nModel Evaluation\nIt is hard to form a robust evaluation mecha-\nnism for unsupervised anomaly detection since the\nground truth is not known. We use the ability of\nthe methods to identify National Holidays from\nnormal days as a proxy of its performance. It is\nworth noting that we should not except very high\nperformance scores in these experiments since Na-\ntional Holidays do not constitute all the anoma-\nlies and the false positives we get might actually\nbe other events resulting in anomalies in transport\nnetworks. For convenient comparison of the ap-\nproaches described above, we report the best F1\nscore for each of the methods. F1 score gives a\none value performance metric by computing har-\nmonic average of precision and recall.\n4\nResults and Discussion\nThe results for the experiments are summarised\nin table 3 and table 4.\nAs it can be observed\nthat representations learned from discriminative\ntraining on auxiliary classiﬁcation task provides\nbest F1 scores across all experiments. For node\nfeature representation of Taipei data discrimina-\ntive features perform signiﬁcantly better than both\nPCA and autoencoders, and using graph convolu-\ntion layers further improve the anomaly detection\nF1 scores. Similarly, for edge feature representa-\ntion experiments, discriminative feature learning\noutperforms traditional techniques. Thus, it can\nbe empirically backed that discriminative train-\ning using an auxiliary classiﬁcation task is a vi-\nable approach for feature learning and these fea-\ntures are transferable to unsupervised tasks like\nanomaly detection. it is interesting to note that for\nNew York the performance of anomaly detection\nis signiﬁcantly lower than Taipei. National holi-\ndays might have a stronger effect on the mobility\npatterns of Taipei than New York, or the changes\nmight be reﬂected more strongly in subway rider-\nship than taxi ridership. Furthermore, since Taipei\nhas twice the number of national holidays so its\nresults are statistically more reliable.\nFeature learning methods achieve low dimen-\nsional latent representation with different objec-\ntives, which might not result in representations\nsuitable for unsupervised anomaly detection. PCA\nperforms dimensionality reduction with aim to re-\ntain most of the variance of the data but still the\ninformation vital for anomaly detection might re-\nside in the omitted information, resulting in infe-\nrior performance in anomaly detection. Autoen-\ncoder compresses the data into latent space that is\ncapable for accurate reconstruction of the output,\nbut the features that are essential for anomaly de-\ntection might not be essential for reconstruction.\nWe note that the auxiliary classiﬁcation task that\nwe proposed was closely related to the original\ntask of anomaly detection, hence transferability of\nfeatures was high. If latent space has enough in-\nformation to separate weekdays and weekends it\nis plausible that it is also good at distinguishing\nholidays from normal days.\nFinally, we note that use of GCN improves the\nquality of latent representations. GCNs are able to\nmodel spatial and structural dependencies by us-\ning localized ﬁlters, so that is why they were able\nto learn more stable representations for Taipei sub-\nway network, which has a clearly deﬁned topol-\nogy.\n5\nConclusion\nThis paper evaluated the tranferrability of features\nlearned from an auxiliary classiﬁcation task to\nunsupervised anomaly detection in temporal net-\nworks, using human mobility as an example.The\nproposed discriminative feature learning is used\nwithin a suitable pipeline approach for anomaly\ndetection as one of its phases reducing overall di-\nmensionality of the task. The results clearly indi-\ncate the usefulness of this approach to attain ef-\nﬁcient feature learning by improving the overall\nanomaly detection F1 scores over the traditional\nunsupervised feature learning approaches.\nIn broader terms, this work further establish the\ntranferrability of features from supervised learn-\ning to unsupervised tasks such as anomaly de-\ntection.\nWe believe that this approach of ﬁnd-\ning a suitable classiﬁcation task which has avail-\nable labels and perform supervised classiﬁcation\nto extract features, is highly generalizable to other\ndomains where the labelled data is not available.\nOur results establish it as promising alternative to\nunsupervised and self supervised feature learning\ntechniques.\nWe have seen that discriminative training results\nin best representations for our unsupervised learn-\ning task but it is critical to note that transferability\nof the features would depend on the nature of the\nclassiﬁcation task and its relevance to the down-\nstream unsupervised task. Identiﬁcation of a suit-\nable classiﬁcation task with the availability of la-\nbels can be seen as a limitation of this approach.\nIn future works, it would be interesting to in-\nvestigate how the transferability of the features\nchanges with the nature of the task.\nReferences\nAlexander\nAmini,\nKevin\nKung,\nChaogui\nKang,\nStanislav Sobolevsky, and Carlo Ratti. 2014. The\nimpact of social segregation on human mobility in\ndeveloping and industrialized regions.\nEPJ Data\nScience, 3(1):6.\nV Barnett and T Lewis. 1984. Discordancy tests for\noutliers in univariate samples. Outliers in statistical\ndata, 3:120–121.\nRichard Bellman. 1957.\nDynamic programming.\nPrinceton University Press.\nAlexander Belyi, Iva Bojic, Stanislav Sobolevsky,\nIzabela Sitko, Bartosz Hawelka, Lada Rudikova,\nAlexander Kurbatski, and Carlo Ratti. 2017. Global\nmulti-layer network of human mobility.\nInterna-\ntional Journal of Geographical Information Science,\n31(7):1381–1402.\nYoshua Bengio, Pascal Lamblin, Dan Popovici, and\nHugo Larochelle. 2007. Greedy layer-wise training\nof deep networks. In Advances in neural informa-\ntion processing systems, pages 153–160.\nEmmanuel J Cand`es, Xiaodong Li, Yi Ma, and John\nWright. 2011. Robust principal component analy-\nsis? Journal of the ACM (JACM), 58(3):11.\nVarun Chandola, Arindam Banerjee, and Vipin Kumar.\n2009. Anomaly detection: A survey. ACM comput-\ning surveys (CSUR), 41(3):15.\nZhiyong Cui, Kristian Henrickson, Ruimin Ke, and\nYinhai Wang. 2018. Trafﬁc graph convolutional re-\ncurrent neural network: A deep learning framework\nfor network-scale trafﬁc learning and forecasting.\narXiv preprint arXiv:1802.07007.\nCarl Doersch, Abhinav Gupta, and Alexei A Efros.\n2015.\nUnsupervised visual representation learn-\ning by context prediction.\nIn Proceedings of the\nIEEE International Conference on Computer Vision,\npages 1422–1430.\nIan Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,\nBing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. 2014. Generative ad-\nversarial nets.\nIn Advances in neural information\nprocessing systems, pages 2672–2680.\nJoris Gu´erin, Olivier Gibaru, St´ephane Thiery, and\nEric Nyiri. 2017.\nCnn features are also great\nat unsupervised classiﬁcation.\narXiv preprint\narXiv:1707.01700.\nBartosz Hawelka, Izabela Sitko, Euro Beinat, Stanislav\nSobolevsky, Pavlos Kazakopoulos, and Carlo Ratti.\n2014. Geo-located twitter as proxy for global mo-\nbility patterns. Cartography and Geographic Infor-\nmation Science, 41(3):260–271.\nMingyi He, Shivam Pathak, Urwa Muaz, Jingtian\nZhou, Saloni Saini, Sergey Malinchik, and Stanislav\nSobolevsky. 2019.\nPattern and anomaly detec-\ntion in urban temporal networks.\narXiv preprint\narXiv:1912.01960.\nGeoffrey E Hinton and Ruslan R Salakhutdinov. 2006.\nReducing the dimensionality of data with neural net-\nworks. science, 313(5786):504–507.\nVictoria Hodge and Jim Austin. 2004. A survey of out-\nlier detection methodologies. Artiﬁcial intelligence\nreview, 22(2):85–126.\nPeter J Huber. 2011. Robust statistics. Springer.\nIan Jolliffe. 2011.\nPrincipal component analysis.\nSpringer.\nChaogui Kang, Stanislav Sobolevsky, Yu Liu, and\nCarlo Ratti. 2013. Exploring human movements in\nsingapore: a comparative analysis based on mobile\nphone and taxicab usages.\nIn Proceedings of the\n2nd ACM SIGKDD international workshop on ur-\nban computing, page 1. ACM.\nJooSeuk Kim and Clayton D Scott. 2012. Robust ker-\nnel density estimation. Journal of Machine Learn-\ning Research, 13(Sep):2529–2565.\nThomas N Kipf and Max Welling. 2016.\nSemi-\nsupervised classiﬁcation with graph convolutional\nnetworks. arXiv preprint arXiv:1609.02907.\nKevin S Kung, Kael Greco, Stanislav Sobolevsky, and\nCarlo Ratti. 2014. Exploring universal patterns in\nhuman home-work commuting from mobile phone\ndata. PloS one, 9(6):e96180.\nGustav\nLarsson,\nMichael\nMaire,\nand\nGregory\nShakhnarovich. 2016. Learning representations for\nautomatic colorization. In European Conference on\nComputer Vision, pages 577–593. Springer.\nRikard Laxhammar. 2008. Anomaly detection for sea\nsurveillance. In 2008 11th international conference\non information fusion, pages 1–8. IEEE.\nYaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu.\n2017. Diffusion convolutional recurrent neural net-\nwork: Data-driven trafﬁc forecasting. arXiv preprint\narXiv:1707.01926.\nXiaolei Ma, Zhuang Dai, Zhengbing He, Jihui Ma,\nYong Wang, and Yunpeng Wang. 2017. Learning\ntrafﬁc as images: a deep convolutional neural net-\nwork for large-scale transportation network speed\nprediction. Sensors, 17(4):818.\nFu-Jie Huang MarcAurelio Ranzato, Y-Lan Boureau,\nand Yann LeCun. 2007. Unsupervised learning of\ninvariant feature hierarchies with applications to ob-\nject recognition.\nIn Proc. Computer Vision and\nPattern Recognition Conference (CVPR07). IEEE\nPress, volume 127.\nJonathan Masci, Ueli Meier, Dan Cires¸an, and J¨urgen\nSchmidhuber. 2011.\nStacked convolutional auto-\nencoders for hierarchical feature extraction.\nIn\nInternational Conference on Artiﬁcial Neural Net-\nworks, pages 52–59. Springer.\nMehdi Noroozi and Paolo Favaro. 2016. Unsupervised\nlearning of visual representations by solving jigsaw\npuzzles. In European Conference on Computer Vi-\nsion, pages 69–84. Springer.\nMarguerite Nyhan, Stanislav Sobolevsky, Chaogui\nKang, Prudence Robinson, Andrea Corti, Michael\nSzell,\nDavid Streets,\nZifeng Lu,\nRex Britter,\nSteven RH Barrett, et al. 2016.\nPredicting vehic-\nular emissions in high spatial resolution using per-\nvasively measured transportation data and micro-\nscopic emissions model. Atmospheric environment,\n140:352–363.\nStephen Ranshous, Shitian Shen, Danai Koutra, Steve\nHarenberg, Christos Faloutsos, and Nagiza F Sam-\natova. 2015.\nAnomaly detection in dynamic net-\nworks: a survey. Wiley Interdisciplinary Reviews:\nComputational Statistics, 7(3):223–247.\nDouglas Reynolds. 2015.\nGaussian mixture models.\nEncyclopedia of biometrics, pages 827–832.\nPaolo Santi, Giovanni Resta, Michael Szell, Stanislav\nSobolevsky, Steven H Strogatz, and Carlo Ratti.\n2014. Quantifying the beneﬁts of vehicle pooling\nwith shareability networks. Proceedings of the Na-\ntional Academy of Sciences, 111(37):13290–13294.\nThomas Schlegl, Philipp Seeb¨ock, Sebastian M Wald-\nstein, Ursula Schmidt-Erfurth, and Georg Langs.\n2017.\nUnsupervised anomaly detection with gen-\nerative adversarial networks to guide marker dis-\ncovery.\nIn International Conference on Informa-\ntion Processing in Medical Imaging, pages 146–157.\nSpringer.\nStanislav Sobolevsky, Riccardo Campari, Alexander\nBelyi, and Carlo Ratti. 2014.\nGeneral optimiza-\ntion technique for high-quality community detec-\ntion in complex networks.\nPhysical Review E,\n90(1):012811.\nStanislav Sobolevsky, Philipp Kats, Colin Bradley,\nMingyi He, and Sergey Malinchik. 2019. Anomaly\ndetection in temporal networks. In NetSci.\nCambridge Systematics. 2004. Trafﬁc congestion and\nreliability: Linking solutions to problems. Technical\nreport, United States. Federal Highway Administra-\ntion.\nRemi Tachet,\nPaolo Santi,\nStanislav Sobolevsky,\nLuis Ignacio Reyes-Castro, Emilio Frazzoli, Dirk\nHelbing, and Carlo Ratti. 2016.\nRevisiting street\nintersections using slot-based systems.\nPloS one,\n11(3):e0149607.\nHoussam Zenati, Chuan Sheng Foo, Bruno Lecouat,\nGaurav Manek,\nand Vijay Ramaseshan Chan-\ndrasekhar. 2018. Efﬁcient gan-based anomaly de-\ntection. arXiv preprint arXiv:1802.06222.\nShuangfei Zhai, Yu Cheng, Weining Lu, and Zhongfei\nZhang. 2016.\nDeep structured energy based\nmodels for anomaly detection.\narXiv preprint\narXiv:1605.07717.\nJunbo Zhang, Yu Zheng, and Dekang Qi. 2017.\nDeep spatio-temporal residual networks for citywide\ncrowd ﬂows prediction. In Thirty-First AAAI Con-\nference on Artiﬁcial Intelligence.\nRichard Zhang, Phillip Isola, and Alexei A Efros. 2016.\nColorful image colorization.\nIn European confer-\nence on computer vision, pages 649–666. Springer.\nChong Zhou and Randy C Paffenroth. 2017. Anomaly\ndetection with robust deep autoencoders.\nIn Pro-\nceedings of the 23rd ACM SIGKDD International\nConference on Knowledge Discovery and Data Min-\ning, pages 665–674. ACM.\nArthur Zimek, Erich Schubert, and Hans-Peter Kriegel.\n2012. A survey on unsupervised outlier detection in\nhigh-dimensional numerical data. Statistical Analy-\nsis and Data Mining: The ASA Data Science Jour-\nnal, 5(5):363–387.\nBo Zong, Qi Song, Martin Renqiang Min, Wei Cheng,\nCristian Lumezanu, Daeki Cho, and Haifeng Chen.\n2018. Deep autoencoding gaussian mixture model\nfor unsupervised anomaly detection.\n",
  "categories": [
    "cs.LG",
    "physics.soc-ph",
    "stat.ML",
    "68T10"
  ],
  "published": "2019-12-05",
  "updated": "2019-12-05"
}