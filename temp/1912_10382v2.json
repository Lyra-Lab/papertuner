{
  "id": "http://arxiv.org/abs/1912.10382v2",
  "title": "Deep Learning via Dynamical Systems: An Approximation Perspective",
  "authors": [
    "Qianxiao Li",
    "Ting Lin",
    "Zuowei Shen"
  ],
  "abstract": "We build on the dynamical systems approach to deep learning, where deep\nresidual networks are idealized as continuous-time dynamical systems, from the\napproximation perspective. In particular, we establish general sufficient\nconditions for universal approximation using continuous-time deep residual\nnetworks, which can also be understood as approximation theories in $L^p$ using\nflow maps of dynamical systems. In specific cases, rates of approximation in\nterms of the time horizon are also established. Overall, these results reveal\nthat composition function approximation through flow maps present a new\nparadigm in approximation theory and contributes to building a useful\nmathematical framework to investigate deep learning.",
  "text": "arXiv:1912.10382v2  [cs.LG]  8 Jun 2020\nDeep Learning via Dynamical Systems: An\nApproximation Perspective\nQianxiao Li\nTing Lin\nZuowei Shen\nAbstract\nWe build on the dynamical systems approach to deep learning, where deep resid-\nual networks are idealized as continuous-time dynamical systems, from the approx-\nimation perspective. In particular, we establish general sufﬁcient conditions for uni-\nversal approximation using continuous-time deep residual networks, which can also\nbe understood as approximation theories in Lp using ﬂow maps of dynamical sys-\ntems. In speciﬁc cases, rates of approximation in terms of the time horizon are also\nestablished. Overall, these results reveal that composition function approximation\nthrough ﬂow maps present a new paradigm in approximation theory and contributes\nto building a useful mathematical framework to investigate deep learning.\nKeywords. Deep learning, Approximation theory, Controllability\n1\nIntroduction and Problem Formulation\nDespite the empirical success of deep learning, one outstanding challenge is to develop\na useful theoretical framework to understand its effectiveness by capturing the effect of\nsequential function composition in deep neural networks. In some sense, this is a dis-\ntinguishing feature of deep learning that separates it from traditional machine learning\nmethodologies.\nOne candidate for such a framework is the dynamical systems approach [13, 20, 25],\nwhich regards deep neural networks as a discretization of an ordinary differential equation.\nConsequently, the latter can be regarded as the object of analysis in place of the former.\nQ. Li: Department of Mathematics, National University of Singapore; e-mail: qianxiao@nus.edu.sg\nT. Lin: School of Mathematical Sciences, Peking University; e-mail: lintingsms@pku.edu.cn\nZ. Shen: Department of Mathematics, National University of Singapore; e-mail: matzuows@nus.edu.sg\nMathematics Subject Classiﬁcation (2010): Primary 41A99; Secondary 93B05\n1\n2\nQianxiao Li, Ting Lin, Zuowei Shen\nAn advantage of this idealization is that a host of mathematical tools from dynamical\nsystems, optimal control and differential equations can then be brought to bear on various\nissues faced in deep learning, and more importantly, shed light on the role of composition\non function approximation and learning.\nSince its introduction, the dynamical systems approach led to much progress in terms\nof novel algorithms [37, 53], architectures [20, 5, 39, 31, 51, 46, 44] and emerging ap-\nplications [55, 57, 7, 30, 16]. On the contrary, the present work is focused on the the-\noretical underpinnings of this approach. From the optimization perspective, it has been\nestablished that learning in this framework can be recast as an mean-ﬁeld optimal control\nproblem [25, 14], and local and global characterizations can be derived based on gen-\neralizations of the classical Pontryagin’s maximum principle and the Hamilton-Jacobi-\nBellman equation. Other theoretical developments include continuum limits and connec-\ntions to optimal transport [42, 47, 43]. Nevertheless, the other fundamental questions in\nthis approach remain largely unexplored, especially when it comes to the function approx-\nimation properties of these continuous-time idealizations of deep neural networks. In this\npaper, we establish some basic results in this direction.\n1.1\nThe Supervised Learning Setting\nWe ﬁrst describe the setting of the standard supervised learning problem we study in this\npaper. We consider a set of inputs X ⊂Rn and outputs Y ⊂Rm that are subsets of\nEuclidean spaces. In supervised learning, we seek to approximate some ground truth or\ntarget (oracle) function, which is a mapping F : X →Y. For example, in a typical\nclassiﬁcation problem, each x speciﬁes the pixel values of a d × d image (n = d2), and y\nis its corresponding class label, which is a one-hot encoding corresponding to m different\nclasses of images, e.g. for m = 3, y = (0, 1, 0) corresponds to a label belong to the second\nclass. The ground truth function F deﬁnes the label y = F(x) associated with each image\nx, and it is the goal of supervised learning to approximate F from data. Concretely, one\nproceeds in two steps.\nFirst, we specify a hypothesis space\nH = {Fθ : X →Y | θ ∈Θ} ,\n(1.1)\nwhich is a family of approximating functions parametrized by θ ∈Θ. The parameter\nset Θ is usually again some subset of a Euclidean space. For example, in classical linear\nbasis regression models (Y = R), we may consider a set of orthonormal basis functions\n{φi ∈L2(X ), i = 1, 2, . . . } forming a hypothesis space by linear combinations, i.e. H =\nDeep Learning via Dynamical Systems: An Approximation Perspective\n3\n{P\ni aiφi : ai ∈R, P\ni a2\ni < ∞}. Of course, there are other hypothesis spaces one can\nconsider, such as deep neural networks that we will discuss later.\nNext, we ﬁnd an approximant ˆF ∈H of F by solving an optimization problem typically\nof the form\ninf\nG∈H\nˆ\nX\nℓ(F(x), G(x))dµ(x),\n(1.2)\nHere, µ is a probability measure on X modelling the input distribution and ℓ: Y ×\nY →R is a loss function that is minimized when its arguments are equal. A common\nchoice for regression problems is the square loss, ℓ(y, y′) = ∥y −y′∥2\n2, in which case\nthe solution of (1.2) is a projection of F onto H in L2(X , µ). For classiﬁcation problems,\ntypically one uses a surrogate loss function in place of the classiﬁcation accuracy, e.g.\ncross entropy loss. Due to non-square loss functions and complex model architectures, in\npractice problem (1.2) is only solved approximately to give a ˆF as an approximation to\nF. Moreover, one typically do not have an explicit form for µ, but we have data samples\nfrom it: xi, yi = F(xi) for i = 1, 2, . . . , N. In this case, we can set µ to be the empirical\nmeasure µ = 1\nN\nPN\ni=1 δxi, yielding the so-called empirical risk minimization problem\ninf\nG∈H\n1\nN\nN\nX\ni=1\nℓ(F(xi), G(xi)).\n(1.3)\nThis objective function is also called the training loss, since it is the loss function evaluated\non the model predictions versus the true labels, averaged over the training samples.\n1.2\nDeep Residual Neural Networks\nIn deep learning, the hypothesis space H consists of functions in the forms of neural\nnetworks of varying architectures. In this paper, we will focus on a very successful class\nof deep network architectures known as residual networks [22]. These neural networks\nbuild the hypothesis space by iterating the following difference equation\nzs+1 = zs + fθs(zs),\nz0 = x,\ns = 0, . . . , S −1.\n(1.4)\nThe number S is the total number of layers of the network, and s indexes the layers.\nThe function fθs speciﬁes the architecture of the network, which depends on the trainable\nparameters θs at each layer s. For example, in the simplest case of a fully connected\nnetwork, we have\nfθs(z) = Vsσ(Wsz + bs),\nθs = (Ws, Vs, bs)\nWs ∈Rq×n,\nVs ∈Rn×q,\nbs ∈Rq.\n(1.5)\n4\nQianxiao Li, Ting Lin, Zuowei Shen\nHere, σ : R →R is called the activation function, and is applied element-wise to a vector\nin Rn. Popular examples include the rectiﬁed linear unit (ReLU) ReLU(z) = max(0, z),\nthe sigmoid Sig(z) = 1/(1 + e−z) and tanh(z). Depending on the application, more\ncomplex fθ are employed, such as those involving blocks of fully connected layers or\nconvolution layers. In this paper, we do not make explicit assumption on the form of fθs\nand consider the general difference equation (1.4) deﬁning the class of residual network\narchitecture. We remark that it is possible to have different parameter dimensions for\neach layer as is often the case in practice, but for simplicity of analysis we shall take\nthem to have the same dimension and belong to a common parameter set Θ, by possibly\nembedding in higher dimensional Euclidean spaces.\nNow, let us denote by ϕS(x; θ) the mapping x 7→zS via (1.4). This is the ﬂow map of\nthe difference equation, which depends on the parameters θ = (θ0, . . . , θS−1). To match\noutput dimension, we typically introduce another mapping g taken from a family G of\nfunctions from Rn to Y ⊂Rm at the end of the network (classiﬁcation or regression layer,\nas is typically called). We will hereafter call this the terminal family, and it is usually\nsimple, e.g. some collection of afﬁne functions. Together, they form the S-layer residual\nnetwork hypothesis space\nHresnet(S) = {g ◦ϕS(·; θ) | g ∈G, θ ∈ΘS}\n(1.6)\nOne can see that this hypothesis space is essentially compositional in nature. First, the\nfunctions in H involves a composition of a ﬂow map ϕS and the last layer g. Moreover,\nthe ﬂow map ϕS itself is a composition of maps, each of which is a step in (1.4). One chal-\nlenge in the development of a mathematical theory of deep learning is the understanding\nthe effect of compositions on approximation and learning, due to the lack of mathematical\ntools to handle function compositions.\n1.3\nThe Dynamical Systems Viewpoint\nThe results in this paper concerns a recent approach introduced in part to simplify the\ncomplexity arising from the compositional aspects of the residual network hypothesis\nspace. This is the dynamical systems approach, where deep residual networks are ideal-\nized as continuous-time dynamical systems [13, 25, 39, 14]. Instead of (1.4), we consider\nits continuous-time idealization\n˙z(t) = fθ(t)(z(t)),\nθ(t) ∈Θ,\nt ∈[0, T],\nz(0) = x.\n(1.7)\nThat is, we replace the discrete layer numbers s by a continuous variable t, which results\nin a new continuous-time dynamics described by an ordinary differential equation (ODE).\nDeep Learning via Dynamical Systems: An Approximation Perspective\n5\nNote that for this approximation to be precise, one would need a slight modiﬁcation of\nthe right hand side (1.4) into zs + δ · fθs(zs) for some small δ > 0. The limit δ →0\nwith T = Sδ held constant gives (1.7) with the identiﬁcation t ≈δs. Empirical work\nshows that this modiﬁcation is justiﬁed since for trained deep residual networks, zs+1 −zs\ntends to be small [50, 23]. Consequently, the trainable variables θ is a now a indexed by a\ncontinuous variable t. We will assume that each fθ is a Lipschitz continuous function on\nRn, so that (1.7) admits unique solutions (see Proposition 3.1).\nAs in discrete time, for a terminal time T > 0, z(T) can be seen as a function of its\ninitial condition x, and we denote it by ϕT(·, θ) : Rn →Rn. The map ϕT is known\nas the Poincar´e map or the ﬂow map of the dynamical system (1.7). It depends on the\nparameters θ = {θ(t) ∈Θ : t ∈[0, T]}, which is now a function of time. We impose a\nweak regularity condition of θ with respect to t by restricting θ to be essentially bounded,\ni.e. θ ∈L∞([0, T], Θ). As a result, we can replace the hypothesis space (1.6) by\nHode(T) = {g ◦ϕT(·, θ) | g ∈G, θ ∈L∞([0, T], Θ)}\n(1.8)\nwith the terminal time T playing the role of depth. In words, this hypothesis space con-\ntains functions which are regression/classiﬁcation layers g composed with ﬂow maps of a\ndynamical system in the form of an ODE. It is also convenient to consider the hypothesis\nspace of arbitrarily deep continuous-time networks as the union\nHode =\n[\nT>0\nHode(T). =\n[\nT>0\n{g ◦ϕT(·, θ) | g ∈G, θ ∈L∞([0, T], Θ)}\n(1.9)\nThe key advantage of this viewpoint is that a variety of tools from continuous time analy-\nsis can be used to analyze various issues in deep learning. This was pursued for example,\nin [25, 26] for learning algorithms and [39, 6, 5] on network stability. In this paper, we\nare concerned with the problem of approximation, which is one of the most basic mathe-\nmatical questions we can ask given a hypothesis space. Let us outline the problem below.\n1.4\nThe Problem of Approximation\nThe problem of approximation essentially asks how big Hode is. In other words, what kind\nof functions can we approximate using functions in Hode? Before we present our results,\nlet us ﬁrst distinguish the concept of approximation and that of representation.\n• We say that a function F can be represented by Hode if F ∈Hode.\n• In contrast, we say that F can be approximated by Hode if for any ε > 0, there exists\na bF ∈Hode such that it is close to F up to error ε. Equivalently, F lies in the closure\nof Hode under some topology.\n6\nQianxiao Li, Ting Lin, Zuowei Shen\nTherefore, representation and approximation are mathematically distinct notions. The fact\nthat some class of mappings cannot be represented by Hode does not prevent it from being\napproximated by Hode to arbitrary accuracy. For example, it is well-known that ﬂow maps\nmust be orientation-preserving (OP), which are a very small set of functions in the Baire\nCategory sense [36]. At the same time, it is also known that OP diffeomorphisms are\ndense in Lp in dimensions larger than one [4]. However, what we need here is more than\ndensity: the approximation set should have good structure for computation. In this paper,\nwe investigate the density of ﬂow maps with structural constraints.\nWe will work mostly in continuous time. Nevertheless, it makes sense to ask what the\nresults in continuous time imply for discrete dynamics. After all, the latter is what we can\nactually implement in practice as machine learning models. Observe that in the reverse\ndirection, zs+1 = zs + δfθs(zs) can be seen as a forward Euler discretization of (1.7). It is\nwell-known that for ﬁnite time horizon T and ﬁxed compact domain, Euler discretization\nhas global truncation error in supremum norm of O(δ) = O(T/S) (See e.g. [24], Ch 5).\nIn other words, any function in Hode can be uniformly approximated by a discrete residual\nnetwork provided the number of layers S is large enough. Consequently, if a function can\nbe approximated by Hode, then it can be approximated by a sufﬁciently deep residual\nneural network corresponding to an Euler discretization. In this sense, we can see that\napproximation results in continuous time have immediate consequences for its discrete\ncounterpart.\n2\nMain Results and Implications\nIn this section, we summarize our main results on the approximation properties of Hode\nand discuss their signiﬁcance with respect to related results in the literature in the direction\nof approximation theory through the viewpoint of function composition, approximation\nproperties of deep neural networks, as well as controllability problems in dynamical sys-\ntems. We begin with ﬁxing some notation.\n2.1\nNotation\nThroughout this paper, we adopt the following notation:\n1. Let K be a measurable subset of Rn. We denote by C(K) the space of real-valued\ncontinuous functions on K, with norm ∥f∥C(K) = supx∈K |f(x)|. Similarly, for p ∈\n[1, ∞), Lp(K) denotes the space of p-integrable measurable functions on K, with\nnorm ∥f∥Lp(K) = (\n´\nK |f(x)|pdx)1/p. Vector-valued functions are denoted similarly.\nDeep Learning via Dynamical Systems: An Approximation Perspective\n7\n2. A function f on K is called Lipschitz if |f(x) −f(x′)| ≤L|x −x′| holds for all\nx, x′ ∈K. The smallest constant L for which this is true is denoted as Lip(f).\n3. Given a uniformly continuous function f, we denote by ωf its modulus of continuity,\ni.e. ωf(r) := sup|x−x′|≤r |f(x) −f(x′)|.\n4. For any collection F of functions on Rn, we denote by F its closure under the\ntopology of compact convergence. In other words, f ∈F if for any compact K ⊂\nRn and any ε > 0, there exists bf ∈F such that ∥f −bf∥C(K) ≤ε. As a short form,\nwe will refer to this as approximation closure.\n5. For any collection F of functions on Rn, we denote by CH(F) its convex hull and\nCH(F) the approximation closure of its convex hull, i.e. closure under the topology\nof compact convergence.\n2.2\nApproximation Results\nLet us begin by slightly simplifying the form of the continuous-time hypothesis space. Let\nus denote by F the set of functions that constitute the right hand side of Equation (1.7):\nF = {fθ : Rn →Rn | θ ∈Θ}.\n(2.1)\nConsequently, we can denote the family of ﬂow maps generated by F as\nΦ(F, T) := {x 7→z(T) | ˙z(t) = ft(z(t)), ft ∈F, z(0) = x, t ∈[0, T]}\n(2.2)\nThis allows us to write Hode compactly without explicit reference to the parameterization\nHode = Hode(F, G) =\n[\nT>0\n{g ◦ϕ | g ∈G, ϕ ∈Φ(F, T)}.\n(2.3)\nWe will hereafter call F a control family, since they control the dynamics induced by the\ndifferential equation (1.7). Unless speciﬁed otherwise, we assume F contains only Lips-\nchitz functions, which ensures existence and uniqueness of solutions to the corresponding\nODEs (See. Proposition 3.1). As before, G is called the terminal family.\nThe central results in this paper establishes conditions on F and G that induce an universal\napproximation property for Hode. To state the results we will need some deﬁnitions con-\ncerning properties of the control family. The ﬁrst is the concept of well functions, which\nplays a fundamental role in constructing approximation dynamics.\nDeﬁnition 2.1 (Well Function). We say a Lipschitz function h : Rn →R is a well function\nif there exists a bounded open convex set Ω⊂Rn such that\nΩ⊂{x ∈Rn | h(x) = 0} ⊂Ω.\n(2.4)\n8\nQianxiao Li, Ting Lin, Zuowei Shen\nHere the Ωis the closure of Ωin the usual topology on Rn.\nMoreover, we say that a vector valued function h : Rn →Rn′ is a well function if each of\nits component hi : Rn →R is a well function in the sense above.\nThe name “well function” highlights the rough shape of this type of functions: the zero\nset of a well function is like the bottom of a well. Of course, the “walls” of this well need\nnot always point upwards and we only require that they are never zero outside of Ω.\nWe also deﬁne the notion of restricted afﬁne invariance, which is weaker than the usual\nform of afﬁne invariance.\nDeﬁnition 2.2 (Restricted Afﬁne Invariance). Let F be a set of functions from Rn to Rn.\nWe say that F is restricted afﬁne invariant if f ∈F implies Df(A · +b) ∈F, where\nb ∈Rn is any vector, and D, A are any n × n diagonal matrices, such that the entries of\nD are ±1 or 0, and entries of A are smaller than or equal to 1.\nNow, let us state our main result on universal approximation of functions by ﬂow maps of\ndynamical systems in dimension n ≥2.\nTheorem 2.3 (Sufﬁcient Condition for Universal Approximation). Let n ≥2 and F :\nRn →Rm be continuous. Suppose that the control family F and the terminal family G\nsatisﬁes the following conditions\n1. For any compact K ⊂Rn, there exists a Lipschitz g ∈G such that F(K) ⊂g(Rn).\n2. CH(F) contains a well function (Deﬁnition 2.1).\n3. F is restricted afﬁne invariant (Deﬁnition 2.2).\nThen, for any p ∈[1, ∞), compact K ⊂Rn and ε > 0, there exists bF ∈Hode such that\n∥F −bF∥Lp(K) ≤ε.\n(2.5)\nIn the language of approximation theory for neural networks, Theorem 2.3 is known as\nan universal approximation theorem, and Hode satisfying the conditions laid out is said to\nhave the universal approximation property.\nHere, the covering condition F(K) ⊂g(Rn) is in some sense necessary. If the range of\ng does not cover F(K), say it misses an open subset U ⊂F(K), then no ﬂow maps\ncomposed with it can approximate F. Fortunately, this condition is very easy to satisfy.\nFor example, suppose m = 1 (regression problems), then any linear function g(x) = w⊤x\nfor which w ̸= 0 sufﬁces, since it is surjective.\nThe requirement n ≥2 is also necessary. In one dimension, the result is actually false, due\nto the topological constraint induced by ﬂow maps of dynamical systems. More precisely,\nDeep Learning via Dynamical Systems: An Approximation Perspective\n9\nfor n = 1 one can show that each bF ∈Hode must be continuous and increasing, and fur-\nthermore that its closure also contains only increasing functions. Hence, there is no hope\nin approximating any function that is strictly decreasing on an open interval. However, we\ncan prove the next best thing in one dimension: any continuous and increasing function\ncan be approximated by a dynamical system driven by the control family F.\nTheorem 2.4 (Sufﬁcient Condition for Universal Approximation in 1D). Let n = 1. Then,\nTheorem 2.3 holds under the additional assumption that F is increasing.\nRemark 2.5. In one dimension, Theorem 2.4 still holds if one replaces the Lp(K) norm\nby C(K), and furthermore one can relax the restricted afﬁne invariance property to in-\nvariance with respect to only D = ±1 and A = 1 in Deﬁnition 2.2, i.e. we only require\nsymmetry and translation invariance.\nLet us now give some examples of control families satisfying the requirements of Theo-\nrems 2.3 and 2.4 in order to highlight the general applicability of these results.\nExample 2.6 (ReLU Networks). Recall that the fully connected architecture 1.5 with\nReLU activation corresponds to the control family\nFReLU =\n\b\nz 7→V ReLU(Wz + b) | W ∈Rq×n, V ∈Rn×q, b ∈Rq\t\n(2.6)\nwhere ReLU(z)i = max(zi, 0) and q ≥n. It is clear that restricted afﬁne invariance\nholds. Moreover, one can easily construct a well function: Let Ω= (−1, 1)n ⊂Rn be the\nopen cube. Consider the function h : Rn →Rn whose components are all equal and are\ngiven by\n[h(z)]i = 1\n2n\nn\nX\nj=1\n[ReLU(−1 −zj) + ReLU(zj −1)],\ni = 1, . . . , n.\n(2.7)\nClearly, h ∈CH(F) ⊂CH(F) and h is a well function with respect to Ω. Therefore, fully\nconnected residual networks with ReLU activations possesses the universal approxima-\ntion property as a consequence of our results. Note that this result can be proved using\nother methods that takes an explicit architectural assumption e.g. [28, 40, 41].\nWe now discuss examples of some architectural variations that can be handled with our\napproach. As far as we are aware, such results have not been established in the literature\nusing other means.\nExample 2.7 (Other Activations). Let us now discuss how our results can apply just as\neasily to other network architectures, e.g. with different choice of the activation function.\nAs a demonstration, we consider another commonly used activation function known as\nthe sigmoid activation\nSig(z) =\n1\n1 + e−z .\n(2.8)\n10\nQianxiao Li, Ting Lin, Zuowei Shen\nin place of the ReLU activation in (2.6). We call this family FSig. In this case, restricted\nafﬁne invariance is again obvious. To build a well-function, let us deﬁne the scalar soft-\nthreshold function s : R →R\ns(z) = 1\n2 min(max(|z| −1, 0), 1)\n(2.9)\nand for M, N positive integers we deﬁne the scalar function\nsM,N(z) =\n1\n2N\nN\nX\nk=1\nh\nSig(M(−qk −z)) + Sig(M(z −qk))\ni\n.\n(2.10)\nwhere qk = 1+(k/N). We ﬁrst show that sM,N can approximate s on any compact subset\nof R if M, N are large enough, and it is sufﬁcient to consider the subset to be intervals of\nthe form [−K, K]. We now estimate |s(z) −sM,N(z)| directly, and by symmetry we only\nneed to check 0 ≤z ≤K. There are three cases:\nCase 1: 0 ≤z < 1. Here, s(z) = 0. Then each z −qk, −z −qk ≥−1/N and hence\n|sM,N(z)| ≤\n1\n1+exp(M/N).\nCase 2: ql ≤z < ql+1 for some l ≥0. Then 1) we have Sig(M(−qk −z)) <\n1\n1+exp(M/N)\nfor all k; 2) |1 −Sig(M(z −qk))| <\n1\n1+exp(M/N) for k < l, since z −qk > 1/N; 3)\n|Sig(M(z −qk))| <\n1\n1+exp(M/N) for k > l + 1, since z −qk < −1/N. Combining these\nestimates we have\n\f\f\f\f\nl\n2N −sM,N(z)\n\f\f\f\f <\n1\n2N +\n1\n1 + exp(M/N),\n(2.11)\nand since |s(z) −\nl\n2N | <\n1\n2N , we have |s(z) −sM,N(z)| < 1\nN +\n1\n1+exp(M/N).\nCase 3: z ≥2. Here, s(z) = 1, and the estimates for case 2 above also hold true. Thus,\nwe have |1 −sM,N(z)| < 1\nN +\n1\n1+exp(M/N).\nCombining the cases above, we have for any K > 0 and |z| ≤K,\n|s(z) −sM,N(z)| < 1\nN +\n1\n1 + exp(M/N).\n(2.12)\nBy sending M = N2 →∞, we can make the right hand side arbitrarily small, as re-\nquired.\nNow, let us deﬁne the function h : Rn →Rn where\n[h(z)]i = 1\nn\nn\nX\nj=1\ns(zj),\ni = 1, . . . , n.\n(2.13)\nIt is clear that h is a well function with respect to the cube (−1, 1)n. Moreover, by es-\ntimate (2.12) h can be uniformly approximated on any compact subset by [hM,N]i =\nDeep Learning via Dynamical Systems: An Approximation Perspective\n11\n1\nn\nPn\nj=1 sM,N(zj), which belongs to CH(FSig). Thus, h ∈CH(FSig) (recall the deﬁni-\ntion of closure with respect to the topology of compact convergence in Sec. 2.1) and we\nconclude using our results that continuous fully connected residual networks with sig-\nmoid activations also possess the universal approximation property. Other activations\nsuch as tanh can be handled similarly. Importantly, we can see that in our framework,\nrelatively little effort is required to handle such variations in architecture, but for existing\napproaches whose proofs rely on explicit architectural choices such as ReLU, this may be\nmuch more involved.\nExample 2.8 (Residual Blocks). As a further demonstration of the ﬂexibility of our results,\nwe can consider another type of variation of the basic residual network, which considers\na “residual block” with more than one fully connected layer. For example, each block can\nbe of the form\nus = σ(W (1)\ns zs + b(1)\ns ),\nzs+1 = zs + Vsσ(W (2)\ns us + b(2)\ns ),\n(2.14)\nwhere σ is some nonlinear activation function applied element-wise. In fact, the original\nformulation of residual networks has such a block structure, albeit with convolutional\nlayers and ReLU activations [22]. Now, the corresponding control family for the idealized\ncontinuous-time dynamics is\nFblock = {z 7→V σ(W (2)σ(W (1)z + b(1)) + b(2))\n| V ∈Rn×q2, W (1) ∈Rq1×n, b(1) ∈Rq1, W (2) ∈Rq2×q1, b(2) ∈Rq2},\n(2.15)\nwhere q2, q1 ≥n. We now show that we can deduce universal approximation of this family\nfrom previous results. As before, restricted afﬁne invariance holds trivially. Thus, it only\nremains to show that CH(Fblock) contains a well function.\nTo proceed, we may set q1 = q2 = n without loss of generality, since otherwise we can\njust pad the corresponding matrices/vectors with zeros. Now, let us assume that the “one-\nlayer” control family\nFσ = {x 7→V σ(Wz + b) | W ∈Rn×n, b ∈Rn}\n(2.16)\nis such that CH(Fσ) contains a well function that is non-negative. From the previous\nexamples, we know that this is true for σ = ReLU or σ = Sig. In addition, we assume\nthat the activation σ satisﬁes a non-degeneracy condition: there exists a closed interval\nI ⊂R such that its pre-image σ−1(I) is also a closed interval. Note that most activations\nwe use in practice satisfy this condition.\nLet us deﬁne a control family F, which is a subset of Fblock, in which we set W (1) = I\nand b(1) = 0. We also reparameterize the remaining variables as W (2) →f\nW (2)f\nW (1),\n12\nQianxiao Li, Ting Lin, Zuowei Shen\nb(2) →f\nW (2)eb(1) + eb(2) to obtain the smaller control family\nF = {z 7→V σ(f\nW (2)[f\nW (1)σ(z) + eb(1)] + eb(2))\n| V ∈Rn×n, f\nW (1) ∈Rn×n,eb(1) ∈Rn, f\nW (2) ∈Rn×n,eb(2) ∈Rn},\n(2.17)\nWe now show that CH(F) contains a well function. Since the activation function is applied\nelement-wise, we may ﬁrst consider the 1D case, as we have done is the ﬁrst two examples.\nSuppose that s is a scalar well function such that z 7→(s(z1), . . . , s(zn)) ∈CH(Fσ) and\nthat s is non-negative (see Examples 2.6 and 2.7 for construction). Then we know that\nz 7→(s(aσ(z1) + b), . . . , s(aσ(zn) + b)) ∈CH(F) ⊂CH(Fblock) for all a, b ∈R. It\nsufﬁces to verify that s(aσ(·) + b) is a scalar well function, for some a and b satisfying\nsuitable conditions. We now show this is the case. Take a closed interval I ⊂R such that\nσ−1(I) is also a closed interval. By rescaling and translating, we can take the zero set of\ns to be the interval [−1, 1]. Then, we choose a, b such that z 7→az + b maps I to [−1, 1],\nfrom which we can deduce that s(aσ(·)+b) is also a well function. We may now construct\na well function in n dimensions analogously to the previous examples\n[h(z)]i = 1\nn\nn\nX\nj=1\ns(zj),\ni = 1, . . . , n,\n(2.18)\nand by construction h is a well function in CH(F) ⊂CH(Fblock). By our results, this\nagain induces the universal approximation property of its corresponding Hode.\nThe above examples serves to illustrate the ﬂexibility of a sufﬁcient condition in deriving\nuniversal approximation results for many different architectures. It is possible that some,\nor even all of these results can be derived using other means (such as reproducing other\nuniversal function classes), but such arguments are likely to be involved and more impor-\ntantly, they have to be handled on a case-by-case basis, lacking a systematic approach\nsuch as the one introduced in this paper. We end this section with a remark on a negative\nexample.\nRemark 2.9. Observe that using linear activations σ(z) = z constitute a control family\nwhich does not contain a well function in CH(F). We also can immediately see that it\ncannot produce universal approximating ﬂow maps, since the resulting ﬂow maps are\nalways linear functions.\nLet us now discuss the implication of Theorems 2.3 and 2.4 in three broad directions:\n1) approximation of functions by compositions; 2) approximation theory of deep neural\nnetworks and 3) control theory and dynamical systems.\nDeep Learning via Dynamical Systems: An Approximation Perspective\n13\n2.3\nApproximation of Functions by Composition\nLet us ﬁrst discuss our results in the context of classical approximation theory, but through\nthe lens of compositional function approximation. In other words, we will recast classical\napproximation methods in the form of a compositional hypothesis space (c.f. (1.8))\nH = {g ◦ϕ | g ∈G, ϕ ∈Φ},\n(2.19)\nwhich then allows us to compare and contrast with the setting considered in this paper.\nAs before, we call G the terminal family, and for convenience we will refer to Φ as a\ntransformation family, to highlight the fact that it contains functions whose purpose is to\ntransform the domain of a function g in order to resemble a target function F.\nWe start with the simplest setting in classical approximation theory, namely linear N-term\napproximation. Here, we consider a ﬁxed, countable collection D of functions from Rn to\nR, which we call a dictionary. The dictionary is assumed to have some structure so that\nthey are simple to represent or compute. Common examples include polynomials, simple\nperiodic functions such as sines and cosines, as well as other types of commonly seen\nbasis functions. Linear N-term approximation takes the ﬁrst N elements φ1, φ2, . . . , φN\nof D and forms an approximant bF of F via their linear combinations\nbF(x) =\nN\nX\ni=1\nwiφi(x),\nwi ∈Rm,\ni = 1, 2, . . . , N.\n(2.20)\nFrom the viewpoint of compositional function approximation, we may express the above\nhypothesis space by considering the linear terminal family\nG(N) =\n(\nx 7→\nN\nX\ni=1\nwixi | wi ∈Rm, i = 1, . . . , N\n)\n(2.21)\nThen, we obtain the compositional representation of the hypothesis space\nH(N) = {g ◦ϕ | g ∈G(N), ϕ = (φ1, . . . , φN)}.\n(2.22)\nIn other words, the basic N-term linear approximation can be recast as a compositional\nhypothesis space consisting of a linear terminal family and a transformation family con-\ntaining of just one N-dimensional vector-valued function, whose coordinates are the ﬁrst\nN elements of the dictionary D. This is called linear approximation, because for two tar-\nget functions F1 and F2, whose best approximation (in terms of lowest approximation\nerror, see Sec. 1) are bF1 and bF2 respectively, then the best approximation of λ1F1 + λ2F2\nis λ1 bF1 + λ2 bF2 for any λ1, λ2 ∈R.\nNonlinear N-term approximation [11] takes this approach a step further, by lifting the\nrestriction that we only use the ﬁrst N elements in D. Instead, we are allowed to choose,\n14\nQianxiao Li, Ting Lin, Zuowei Shen\ngiven a target F, which N functions to pick from D. For this reason, the dictionaries D\nused in nonlinear approximation can be an uncountable family of functions. In this case,\nthe compositional family is\nH(N) = {g ◦ϕ | g ∈G(N), ϕ ∈DN}.\n(2.23)\nThe term “nonlinear” highlights the fact that the best approximations for functions do not\nremain invariant under linear combinations.\nIn these classical scenarios, the compositional formulations (2.22) and (2.23) share cer-\ntain similarities. Most importantly, their transformation families have simplistic structures,\nand the terminal family is linear, hence also simple. Consequently, one must rely on hav-\ning a large N in order to form a good approximation. A function can be efﬁciently approx-\nimated via linear approximation (i.e. requiring a small N) if its expansion coefﬁcients in\nD decays rapidly. On the other hand, efﬁcient approximation through nonlinear approxi-\nmation relies on the sparsity of this expansion. Nevertheless, in both cases the complexity\nof their respective hypothesis spaces arise from a large number of linear combination of\nsimple functions.\nLet us now contrast our results on Hode, which is also in this compositional form (See (1.8)).\nFirst, our results holds for more general terminal families that are not restricted to linear\nones. Second, by looking at the form of Hode and comparing with (2.22) and (2.23), we\nobserve that the complexity of Hode arises not due to linear combination of functions,\nsince universal approximation holds despite ϕ having ﬁxed output dimension. Instead,\nthe complexity of Hode arises from compositions, a point which we shall now expand on.\nObserve that besides the overall compositional structure of a terminal family and a trans-\nformation family, a second aspect of composition is also involved in Hode: the transforma-\ntion family Φ(F, T) is itself generated by compositions of simple functions. To see this,\nobserve that for any ﬂow map of an ODE ϕT up to time T, we can write it as\nϕT = ϕτM ◦ϕτM−1 ◦· · · ◦ϕτ2 ◦ϕτ1,\n(2.24)\nwhere τ1 + · · · + τM = T, and each ϕτi represents the portion of the ﬂow map from\nt = P\ns≤i−1 τs to t = P\ns≤i τs (we set τ0 = 0) [1]. By increasing the number of such\npartitions, each ϕτi becomes closer to the identity mapping. More generally, the family of\nﬂow maps forms a continuous semi-group under the binary operation of composition, with\nthe identity element recovered when the time horizon of a ﬂow map goes to 0. Therefore,\neach member of the transformation family Φ(F, T) can be decomposed into a sequence\nof compositional mappings, each of which can be made arbitrarily close to the identity,\nas long as at the same time one increases the number of such compositions. While this\ndecomposition holds true for any ﬂow map of an ODE, the main results in this paper go\nDeep Learning via Dynamical Systems: An Approximation Perspective\n15\na step further and show that the universal approximation property holds even when the\nﬂow map is restricted to one that is generated by some control family F verifying the\nassumptions in Theorem 2.3.\nWe remark that in classical nonlinear approximation, the dictionary D could also involve\ncompositions. A prime examples of this is wavelets [34, 9, 38] where one starts with\nsome template function ψ (mother wavelet) and generates a dictionary by composing it\nwith translations and dilations. For example, in one dimension the wavelet dictionary has\nthe following compositional representation\nD = {ψ ◦T | T(x) = (x −x0)/λ, x0 ∈R, λ > 0}.\n(2.25)\nThe main contrasting aspect in Hode is that the compositional transformations are much\nmore complex. Instead of simple translations and dilations, the transformation family in\nHode involves complex rearrangement dynamics in the form of a ODE ﬂow that may be\nadapted to the speciﬁc target function F at hand.\nIn summary, contrary to classical approximation schemes, Hode is built from composi-\ntions of functions from a simple terminal family G and a complex transformation family\nΦ(F, T), whose members can further be decomposed into a sequence of compositions\nof functions that are simple in two aspects: they are close to the identity map and they\nare generated by a potentially simple control family F. Consequently, the complexity of\nHode arises almost purely from the process of composition of these simple mappings. In\nother words, we trade complexity in T (compositions) for N (linear combinations), and\ncan achieve universal approximation even when the transformation family has ﬁxed out-\nput dimensions. From this viewpoint, the results in this paper highlights the power of\ncomposition for approximating functions.\n2.4\nApproximation Theory of Deep Neural Networks\nAs discussed previously, the transformation family in Hode consisting of ﬂow maps is\nhighly complex due to repeated compositions. At the same time, however, just like dic-\ntionaries in linear and nonlinear approximation, it possesses structure that allows us to\ncarry out approximation in practice. Concretely, recall that each ﬂow map can be decom-\nposed as in (2.24), where each component ϕτi is not only close to the identity, but is close\nin such a way that the perturbation from identity is constrained by the control family F.\nThus, one just need to parameterize each ϕτi by selecting appropriate functions from F\nand then compose them together to form an approximating ﬂow map. From this view-\npoint, the family of deep residual network architectures is a realization of this procedure,\n16\nQianxiao Li, Ting Lin, Zuowei Shen\nby using a one-step forward Euler discretization is approximate each ϕτi. Concretely,\nϕτi(z) = z +\nˆ τi\n0\nf(z(t))dt ≈z + τif(z),\n(2.26)\nfor τi small, which corresponds to the family of deep residual architectures motivated in\nSec. 1. The standard convergence result for Euler discretization [24] allows one to carry\napproximation results in continuous time to the discrete case. In view of this, we now\ndiscuss our results in the context of approximation results in deep learning.\nWe start with the continuous-time case. Most existing theoretical work on the continuous-\ntime dynamical systems approach to deep learning focus on optimization aspects in the\nform of mean-ﬁeld optimal control [14, 29], or the connections between the continuous-\ntime idealization to discrete time [48, 42, 43]. The present paper focuses on the approxi-\nmation aspects of continuous-time deep learning, which is less studied. One exception is\nthe recent work of Zhang et al. [54], who derived some results in the direction of approx-\nimation. However, an important assumption there was that the driving force on the right\nhand side of ODEs (here the control family F) are themselves universal approximators.\nConsequently, such results do not elucidate the power of composition and ﬂows, since\neach “layer” is already so complex to approximate an arbitrary function, and there is no\nneed for the ﬂow to perform any additional approximation.\nIn contrast, the approximation results here do not require F, or even CH(F), to be univer-\nsal approximators. In fact, F can be a very small set of functions, and the approximation\npower of these dynamical systems are by construction attributed to the dynamics of the\nﬂow. For example, the assumption that CH(F) contains a well function does not imply\nF that drives the dynamical system is complex, since the former can be much larger than\nthe latter. In the 1D ReLU control family that induces the fully connected network with\nReLU activations (See (1.4)), one can easily construct a well function with respect to the\ninterval Ω= (q1, q2) by averaging two ReLU functions: 1\n2[ReLU(q1−x)+ReLU(x−q2)],\nbut the control family F = {vReLU(w · +b)} is not complex enough to approximate ar-\nbitrary functions without further linear combinations. We have already illustrated this in\nExamples 2.6, 2.7 and 2.8.\nWe also note that unlike results in [54], the results here for n ≥2 do not require em-\nbedding the dynamical system in higher dimensions to achieve universal approximation.\nThe negative results given in [54] (and also [12]), which motivated embedding in higher\ndimensions, are basically on limitation of representation: ﬂow maps of ODEs are orien-\ntation preserving (OP) homeomorphisms (See Def. 3.2) and thus can only represent such\nmappings. However, these are not counter-examples for approximation. For instance, it is\nknown that OP diffeomorphism (and hence OP homeomorphisms) can approximate any\nL∞functions on open bounded domains in dimensions greater than or equal to two [4].\nDeep Learning via Dynamical Systems: An Approximation Perspective\n17\nAlthough the present paper focuses on the continuous-time idealization, we should also\ndiscuss the results here in relation to the relevant work on the approximation theory\nof discrete deep neural networks. In this case, one line of work to establish universal\napproximation is to show that deep networks can approximate some other family of\nfunctions known to be universal approximators themselves, such as wavelets [35] and\nshearlets [19]. Another approach is to focus on certain speciﬁc architectures, such as\nin [32, 28, 58, 3, 10, 15], which sometimes allows for explicit asymptotic approximation\nrates to be derived for appropriate target function classes. Furthermore, non-asymptotic\napproximation rates for deep ReLU networks are obtained in [41, 40]. They are based on\nexplicit constructions using composition, and hence is similar in ﬂavor to the results here\nif we take an explicit control family and discretize in time.\nWith respect to all these works, the main difference of the results presented here is that\nwe study sufﬁcient conditions for approximation. In other words, we do not start with\nan a priori speciﬁc architecture (e.g. the form of the function fθ, or the type of activa-\ntion σ in (1.4)). In particular, none of the approximation results we present here depend\non reproducing some other basis functions that are known to have the universal approx-\nimation property. Instead, we derive conditions on the respective control and terminal\nfamilies F, G that induces the universal approximation property in Hode. One advantage\nof this viewpoint is that we can isolate the approximation power that arises from the act\nof composition, from that which arises from the speciﬁc architectural choices themselves.\nAs an example, the approximation results in [28] relies on approximating piecewise con-\nstant functions with ﬁnitely many discontinuities, hence its proof depends heavily on the\nReLU activation. Furthermore, the high dimensional results there requires constructing\nthe proximal grid indicator function, which is not straightforward with activations other\nthan ReLU. We note that for the deep non-residual case, more precise approximation re-\nsults including non-asymptotic rates for the ReLU architecture can be derived [41, 40]. In\ncontrast, the main results in this paper proceeds in a more general way without assuming\ncertain precise architectures. Therefore, these results have greater applicability to diverse\narchitectures (See Examples 2.6, 2.7 and 2.8), and perhaps even novel ones that may arise\nin future deep learning applications.\n2.5\nControl Theory and Dynamical Systems\nLastly, the results here are also of relevance to mathematical control theory and the theory\nof dynamical systems. In fact, the problem of approximating functions by ﬂow maps is\nclosely related to the problem of controllability in the control theory [45]. However, there\nis one key difference: in the usual controllability problem on Euclidean spaces, our task\nis to steer one particular input x0 to a desired output value ϕ(x0). However, here we want\n18\nQianxiao Li, Ting Lin, Zuowei Shen\nto steer the entire set of input values in K to ϕ(K) by the same control θ(t). This can be\nthought of as an inﬁnite-dimensional function space version of controllability, which is a\nmuch less explored area and present controllability results in inﬁnite dimensions mostly\nfocus on the control of partial differential equations [8, 2].\nIn the theory of dynamical systems, it is well known that functions represented by ﬂow\nmaps possess restrictions. For example, [36] gives a negative result that the diffeomor-\nphisms generated by C1 vector ﬁelds are few in the Baire category sense. Some works\nalso give explicit criteria for mappings that can be represented by ﬂows, such as [17] in\nR2, [49] in Rn, and more recently, [56] generalizes some results to the Banach space set-\nting. However, these results are on exact representation, not approximation, and hence do\nnot contradict the positive results presented in this paper. The results on approximation\nproperties are fewer. A relevant one is [4], who showed that every Lp mapping can be\napproximated by orientation-preserving diffeomorphisms constructed using polar factor-\nization and measure-preserving ﬂows. The results of the current paper gives an alternative\nconstruction of a dynamical system whose ﬂow also have such an approximation property.\nMoreover, Theorem 2.3 gives some weak sufﬁcient conditions for any controlled dynam-\nical system to have this property. In this sense, the results here further contribute to the\nunderstanding of the density of ﬂow maps in Lp.\n3\nPreliminaries\nIn this section, we state and prove where necessary some preliminary results that are used\nto deduce our main results in the next section.\n3.1\nBackground Results on Ordinary Differential Equations\nThroughout this paper, we use some elementary properties and techniques in classical\nanalysis of ODEs. For completeness, we compile these results in this section. The proofs\nof well-known results that are slightly involved are omitted and unfamiliar readers are\nreferred to [1] for a comprehensive introduction to the theory of ordinary differential\nequations.\nNote that the differential equation that generates the transformation family in Hode is of\nthe form\n˙z = ft(z),\nft ∈F,\n0 < t ≤T,\nz(0) = z0,\n(3.1)\nwhere z0, z(t) ∈Rn. Such equations are called time inhomogeneous, since the forcing\nfunction ft changes in time. However, in subsequent proofs of approximation results, we\nDeep Learning via Dynamical Systems: An Approximation Perspective\n19\nusually consider t 7→ft that are piece-wise constant, i.e. ft = fi for all t ∈[Ti, Ti+1].\nIn this case, for each interval on which ft does not change, it is enough to consider the\ntime-homogeneous equation\n˙z = f(z),\n0 < t ≤T,\nz(0) = z0,\n(3.2)\nwhere f : Rn →Rn is ﬁxed in time. An equivalent form of the ODE is the following\nintegral form\nz(t) = z0 +\nˆ t\n0\nf(z(s))ds.\n(3.3)\nThe following classical result can be proved using ﬁxed point arguments (see e.g. [1], Ch.\n4).\nProposition 3.1 (Existence, Uniqueness and Dependence on Initial Condition). Let f be\nLipschitz. Then, the solution to (3.2) exists and is unique. Moreover, for each t, z(t) is a\ncontinuous function of z0. If in addition, f is r-times continuously differentiable for r ≥1,\nthen for each t, z(t) is a (r −1)-times continuously differentiable function of z0.\nRecall that the ﬂow map ϕT : Rn →Rn of (3.2) is the mapping from z0 7→z(T) where\n{z(t)} satisﬁes (3.2). This is well-deﬁned owing to Prop 3.1. Thus, we hereafter assume\nf is Lipschitz. Let us now discuss an important constraint that such ﬂow maps satisfy.\nDeﬁnition 3.2 (Orientation Preserving for Diffeomorphism Case). We call a diffeomor-\nphism ϕ : Rn →Rn orientation preserving (OP) if det Jϕ(x) > 0 for all x ∈Rn, where\nJϕ is the Jacobian of ϕ, i.e. [Jϕ(x)]ij = ∂ϕi\n∂xj (x).\nProposition 3.3. Suppose f is twice continuously differentiable. Then, the ﬂow map ϕT\nof (3.2) is an OP diffeomorphism.\nProof. First, the ﬂow map of ˙z = −f(z) is the inverse of ϕT, and they are both differen-\ntiable due to Prop. 3.1.\nTo prove the OP property, observe that ϕ0 is the identity map, and so\nϕT(x) = ϕ0(x) +\nˆ T\n0\nf(ϕt(x))dt.\n(3.4)\nThus, we have\nJϕT (x) = I +\nˆ T\n0\nJf(ϕt(x))Jϕt(x)dt\n(3.5)\nHence\nJϕT (x) = exp\n\u0012ˆ T\n0\nJf(ϕt(x))dt\n\u0013\n.\n(3.6)\nSince det exp(A) = exp(Trace A) > 0, the OP property follows.\n20\nQianxiao Li, Ting Lin, Zuowei Shen\nDeﬁnition 3.2 requires differentiability. If the mapping ϕ is only bi-Lipschitz, we can\ndeﬁne the Jacobian almost everywhere, due to celebrated Rademacher’s Theorem. Hence\nwe call a bi-Lipschitz mapping OP if det Jϕ > 0 almost everywhere. If ϕ is merely\ncontinuous, a proper deﬁnition is subtle and can be given by homological techniques,\nsee [21].\nHowever, if we restrict our interest to lower dimensional spaces, such as on the real line\n(n = 1) or the plane (n = 2), the deﬁnition of OP can be easily given without any\ndifferentiability requirements. In this paper, we will only need to use the n = 1 case\nof OP, where a homeomorphism is OP if and only if it is increasing. The deﬁnition is\na natural extension of diffeomorphism case. Below, we prove the one dimensional case\nthat ﬂow maps that are not necessarily differentiable must still be orientation preserving\nhomeomorphisms. This is sufﬁcient to prove our subsequent results. Note that this result\nis well-known (see [1], Ch 1) and we write its proof for completeness.\nProposition 3.4. Let n = 1 and ϕT be the ﬂow map of (3.2). Then, ϕT is increasing.\nProof. It is enough to show that if z1 and z2 are solutions of (3.2), but with different initial\nvalues x1 < x2. Then z1(t) < z2(t) for all t ≥0. Suppose not, we assume z1(t0) = z2(t0)\nfor some t0. Consider the following ODE:\n˙w = −f(w),\nw(0) = z1(t0).\n(3.7)\nThen both z1(t0 −·) and z2(t0 −·) are solutions to the above. By uniqueness we have\nz1(t0 −t) = z2(t0 −t) for all t, which implies x1 = z1(0) = z2(0) = x2, a contradiction.\nSince both z1 and z2 are continuous in t, we have z1(t) < z2(t) for all t.\nNext we state a version of the well-known Gr¨onwall’s Inequality [18].\nProposition 3.5 (Gr¨onwall’s Inequality). Let f : R →R be a scalar function such that\nf(t) ≥0 and f(t) ≤A + B\n´ t\n0 f(τ)dτ. Then f(t) ≤AeBt.\nFinally, we prove some practical results, which follow easily from classical results but are\nused in some proofs of the main body.\nProposition 3.6. Let n = 1 and z(·; x) be the solution of the ODE (3.2) with initial value\nx. When x is in some compact set K ⊂R, then the continuous modulus of ﬁnite time\nωz(·;x),[0,T](r) =\nsup\n0≤t1≤t2≤T\n|t2−t1|≤r\n\f\fz(t1; x) −z(t1; x)\n\f\f\n(3.8)\nconverges to 0 as r →0 uniformly on x ∈K.\nProof. We denote a = min K, b = max K , By Proposition 3.4, we know that z(t; a) ≤\ny(t; x) ≤y(t; b), thus H = {z(t; x) : x ∈K, t ∈[0, T]} ⊂[mint z(t; a), maxt z(t; b)] is\nDeep Learning via Dynamical Systems: An Approximation Perspective\n21\ncompact, so is f(H) = {f(h) : h ∈H}. Suppose M = maxh∈H |f(h)|, we have\nsup\n0≤t1≤t2≤T\n|t2−t1|≤r\n|z(t1; x) −z(t2; x)| ≤rM,\n(3.9)\nimplying the result.\nThe following proposition shows that in one dimension, if we have a well function, we\ncan transport one point into another if they are located in the same side of well function’s\nzero interval. Note that by deﬁnition, the well function cannot change sign outside of this\ninterval.\nProposition 3.7. Let n = 1. Suppose f(x) < 0 for all x ≥x0. Then for x0 < x1 < x2.\nConsider the ODE:\n˙z = f(z),\nz(0) = x2.\n(3.10)\nThen ultimately the ODE system will reach x1, i.e., for some T, z(T) = x1.\nBefore proving it, we give a simple example to illustrate this proposition. Suppose that\nf(z) = −ReLU(z −x0), then direct computation shows z(T) = (x2 −x0) exp(−T)+x0.\nIn this case, T = ln((x2 −x0)/(x1 −x0)) demonstrates the proposition. Intuitively, this\nproposition shows under the stated conditions, x0 is an attractor for the unbounded interval\n(x0, ∞).\nProof. Notice that f is assumed to be continuous, and it sufﬁces to give an estimate\non z(T). We only need to prove that for some T, z(T) < x1, and the result can be\neasily derived by the continuity of T 7→z(T) and that z(0) = x2. Choose an arbitrary\nex1 ∈(x0, x1) and deﬁne m = −supx∈[ex1,x2] f(x). We have\nz(t) = x2 +\nˆ t\n0\nf(z(s))ds.\n(3.11)\nSet t = (x2−x1)/m. If z(t) ≤ex (which is smaller than x1) then we are done by continuity.\nOtherwise, we have z(t) ≤−m for all t′ ∈[0, t], yielding\nz(t) ≤x2 +\nˆ t\n0\n(−m)ds = x2 −mx2 −x1\nm\n= x1\n(3.12)\nwhich by again implies our result by continuity.\nWith these results on ODEs in mind, we now present the proofs of our main results.\n22\nQianxiao Li, Ting Lin, Zuowei Shen\n3.2\nFrom Approximation of Functions to Approximations of Domain\nTransformations\nNow, we show that under mild conditions, as long as we can approximate any continuous\ndomain transformation ϕ : Rn →Rn using ﬂow maps, we can show that Hode is an\nuniversal approximator. Consequently, we can pass to the problem of approximating an\narbitrary ϕ by ﬂow maps in establishing our main results.\nProposition 3.8. Let F : Rn →Rm be continuous and g : Rn →Rm be Lipschitz. Let\nK ⊂Rn be compact and suppose g(Rn) ⊃F(K). Then, for any ε > 0 and p ∈[1, ∞),\nthere exists a continuous function ϕ : K →Rn such that\n∥F −g ◦ϕ∥Lp(K) ≤ε.\n(3.13)\nProof. This follows from a general result on function composition proved in [27]. We\nprove this in the special case here for completeness.\nThe set F(K) is compact, so for any δ > 0 we can form a partition F(K) = ∪i=1,...,NBi\nwith diam(Bi) ≤δ. By assumption, g−1(Bi) is non-empty for each i, so let us pick\nzi ∈g−1(Bi). For each i we deﬁne Ai = (F −1(Bi) ∩K) so that {Ai} forms a partition\nof K. By inner regularity of the Lebesgue measure, for any δ′ > 0 and for each i we\ncan ﬁnd a compact Ki ⊂Ai with λ(Ai \\ Ki) ≤δ′ (λ is the Lebesgue measure) and\nthat Ki’s are disjoint. By Urysohn’s lemma, for each i there exists a continuous function\nϕi : K →[0, 1] such that ϕi = 1 on Ki and ϕi = 0 on ∪j̸=iKj.\nNow, we form the continuous function\nϕ(x) =\nN\nX\ni=1\nziϕi(x).\n(3.14)\nWe deﬁne the set K′ = {PN\ni=1 αizi : αi ∈[0, 1]}, which is clearly compact and ϕ(x) ∈\nK′ for all x. Then, we have\n∥F −g ◦ϕ∥Lp(K) =\nN\nX\ni=1\n∥F −g ◦ϕ∥Lp(Ki) +\nN\nX\ni=1\n∥F −g ◦ϕ∥Lp(Ai\\Ki)\n≤\nN\nX\ni=1\n∥F −g ◦ϕi∥Lp(Ki) +\n\u0002\n∥F∥C(K) + ∥g∥C(K′)\n\u0003\nNδ′.\n(3.15)\nWe take δ′ small enough so that the last term is bounded by δ. Then, we have\n∥F −g ◦ϕ∥Lp(K) ≤\nN\nX\ni=1\nδ|Ki| + δ ≤(1 + |K|)δ.\n(3.16)\nTaking δ = ε/(1 + |K|) yields the result.\nDeep Learning via Dynamical Systems: An Approximation Perspective\n23\nWe shall hereafter assume that g(Rn) ⊃F(K), which as discussed earlier is easily satis-\nﬁed. Hence we have the following immediate corollary.\nCorollary 3.9. Assume the conditions in Proposition 3.8. Let Φ be some collection of\ncontinuous functions from Rn to Rn such that for any δ > 0 and any continuous function\nϕ1 : Rn →Rn, there exists ϕ2 ∈Φ with ∥ϕ1 −ϕ2∥Lp(K) ≤δ. Then, there exists ϕ ∈Φ\nsuch that ∥F −g ◦ϕ∥Lp(K) ≤ε.\nProof. Using Proposition 3.8, there is a ϕ1 such that ∥F −g ◦ϕ1∥Lp(K) ≤ε/2. Now take\nϕ ∈Φ such that ∥ϕ1 −ϕ∥Lp(K) ≤ε/(2Lip(g)). Then,\n∥F −g ◦ϕ∥Lp(K) ≤∥F −g ◦ϕ1∥Lp(K) + ∥g ◦ϕ1 −g ◦ϕ∥Lp(K)\n≤ε\n2 + Lip(g)\n\u0012ˆ\nK\n∥ϕ1(x) −ϕ(x)∥pdx\n\u00131/p\n≤ε.\n(3.17)\n3.3\nProperties of Attainable Sets and Approximation Closures\nOwing to Corollary 3.9, for the rest of the paper we will focus on proving universal ap-\nproximation of continuous transformation functions ϕ from Rn to Rn by ﬂow maps of the\ndynamical system\n˙z(t) = ft(z(t)),\nft ∈F,\nz(0) = x,\n(3.18)\nafter which we can deduce universal approximation properties of Hode via Corollary 3.9.\nWe now establish some basic properties of ﬂow maps and closure properties. In principle,\nin our hypothesis space (2.3) we allow t 7→ft(z) to be any essentially bounded measur-\nable mapping for any z ∈Rn. However, it turns out that to establish approximation results,\nit is enough to consider the smaller family of piece-wise constant in time mappings, i.e.\nft = fj ∈F for t ∈[tj−1, tj). For a ﬁxed f in the control family F, to emphasize\ndependence on f we denote by ϕf\nτ the ﬂow map of the following ODE at time horizon τ:\n˙z(t) = f(z(t)),\nz(0) = x.\n(3.19)\nThat is,\nϕf\nτ = z(τ)\nwhere\n˙z(t) = f(z(t)),\nz(0) = x,\nt ∈[0, τ].\n(3.20)\nThe attainable set of a ﬁnite time horizon T due to piece-wise constant in time controls,\ndenoted as AF(T), is deﬁned as\nAF(T) =\nn\nϕfk\nτk ◦ϕfk−1\nτk−1 ◦· · · ◦ϕf1\nτ1 | τ1 + · · · + τk = T, f1, . . . , fk ∈F, k ≥1\no\n,\n(3.21)\n24\nQianxiao Li, Ting Lin, Zuowei Shen\nIn other words, AF(T) contains the ﬂow map of an ODE whose right hand side is fi for\nt ∈[ti−1, ti), j = 1, . . . , k, with τi = ti −ti−1 and t0 = 0. It contains all the domain\ntransformations that can be attained by an ODE by selecting a piece-wise constant in\ntime driving forces from F up to a terminal time T. The union of attainable sets over\nall possible terminal times, AF = ∪T>0AF(T), is the overall attainable set. In view of\nCorollary 3.9, to establish the approximation property of Hode it is sufﬁcient to prove\nthat any continuous transformation ϕ can be approximated by mappings in AF. Note that\nAF(T) is a subset of Φ(F, T) deﬁned in (2.2). Now, let us prove some properties of the\napproximation closure (i.e. closure with respect to the topology of compact convergence,\nsee Sec. 2.1) of attainable sets.\nLemma 3.10. Let n = 1. If A is a family of continuous and increasing functions from R\nto R, then A contains only increasing functions.\nProof. Immediate.\nNext, we state and prove an important property about approximation closures of control\nfamilies: F shares the same approximation ability as CH(F) when used to drive dynami-\ncal systems. However, a convex hull of Lipschitz function family might not be a Lipschitz\nfunction family in general. Hence we adopt a slightly different description.\nProposition 3.11. Let F be a Lipschitz control family. Then, for any Lipschitz control\nfamily eF such that F ⊂eF ⊂CH(F), we have\nAF = A e\nF.\n(3.22)\nProposition 3.11 is an important result concerning the effect of continuous evolution,\nwhich can be regarded as a continuous family of compositions: any function family driv-\ning a dynamical system is as good as its convex hull in driving the system, which can\nbe an immensely larger family of functions. Similar properties of ﬂows have been ob-\nserved in the context of variational problems, see [52]. This is a ﬁrst hint at the power of\ncomposition on function approximation.\nTo prove Proposition 3.11 we need the following lemmas.\nLemma 3.12. If AF, A e\nF are attainable sets of F, eF and F ⊂eF ⊂F . Then we have\nAF = A e\nF.\n(3.23)\nProof. It sufﬁces to show that A e\nF ⊂AF, which implies AF ⊂A e\nF ⊂AF and hence the\nlemma. Note that any ˜ϕ ∈A e\nF is of the form\n˜ϕ = ϕ\n˜fk\ntk ◦ϕ\n˜fk−1\ntk−1 ◦· · · ◦ϕ\n˜f1\nt1\n(3.24)\nDeep Learning via Dynamical Systems: An Approximation Perspective\n25\nwhere each ˜fi ∈e\nF. To prove the lemma, we have to show that for any compact K ⊂Rn\nand any ε > 0, we can construct a function ϕ ∈AF such that ∥˜ϕ−ϕ∥C(K) ≤ε. We prove\nthis by induction on k ≥0. First, the case when k = 0 is obvious since it is just the identity\nmapping. Suppose now that the statement holds for k −1 and ﬁx any compact K. Write\n˜ϕ = ϕ\n˜fk\ntk ◦˜ψ, where ˜ψ is composition of k −1 ﬂow maps driven by eF. By the inductive\nhypothesis, for any ε1 (to set later) there exists ψ ∈AF, such that ∥ψ −˜ψ∥C(K) ≤ε1.\nMoreover, by the assumption e\nF ⊂F, for any ε2 and compact K′ there is a function\nfk ∈F such that ∥fk −˜fk∥C(K′) ≤ε2. Here, we choose K′ = {x | infy∈ψ(K) ∥x −y∥≤\n2(ε1 + tk)etkLip( ˜fk))} and ε2 < 1.\nNow, consider two ODEs:\n˜z(t) = ˜ψ(x) +\nˆ t\n0\n˜fk(˜z(τ))dτ,\n(3.25)\nand\nz(t) = ψ(x) +\nˆ t\n0\nfk(z(τ))dτ.\n(3.26)\nWe have ˜ϕ(x) = ˜z(tk) and x 7→z(tk) belongs to AF, thus it remains to show that the\nsolutions of these ODEs can be made arbitrarily close. In fact, we show the following\nestimates holds:\nsup\n0≤t≤tk\n|z(t) −˜z(t)| < 2(ε1 + tkε2)etkLip( ˜fk).\n(3.27)\nWe prove by contradiction. Suppose not, then set\nt = inf{s ≥0 : |z(s) −˜z(s)| ≥2(ε1 + tkε2)etkLip( ˜fk)}\n(3.28)\nBy continuity we have |z(t) −˜z(t)| ≥2(ε1 + tkε2)etkLip( ˜fk). By assumption we also have\n| ˜fk(z(τ)) −fk(z(τ))| ≤ε2 for all τ < t. By subtracting, we have\n|˜z(t) −z(t)| ≤ε1 + |\nˆ t\n0\n˜fk(˜z(τ))dτ −\nˆ t\n0\nfk(z(τ))dτ|\n≤ε1 +\nˆ t\n0\n| ˜fk(z(τ)) −fk(z(τ))|dτ +\nˆ t\n0\n| ˜fk(˜z(τ)) −˜fk(z(τ))|dτ\n≤ε1 + ε2t + Lip( ˜fk)\nˆ t\n0\n|˜z(τ) −z(τ)|dτ.\n(3.29)\nBy Gr¨onwall’s inequality, we have\nsup\n0≤t≤tk\n|˜z(t) −z(t)| ≤(ε1 + tkε2)etkLip( ˜fk),\n(3.30)\nwhich contradicts to the choice of t. Hence (3.27) holds, and we can choose ε1 and ε2\narbitrarily small, which concludes the proof.\n26\nQianxiao Li, Ting Lin, Zuowei Shen\nLemma 3.13. Suppose f, g ∈F and t > 0, then we have ϕ(f+g)/2\nt\n∈AF.\nProof. We will show that ϕf\nt/2N◦ϕg\nt/2N ◦· · ·◦ϕf\nt/2N ◦ϕg\nt/2N can approximate ϕ(f+g)/2\nt\n∈AF\narbitrarily well by increasing N. The mapping ϕ(f+g)/2\nt\nis the solution of\nz(t) =x +\nˆ t\n0\n\u0012f + g\n2\n\u0013\n(z(τ))dτ\n=x +\nˆ t/2N\n0\n+\nˆ 3t/2N\n2t/2N\n+ · · · +\nˆ (2N−1)t/2N\n(2N−2)t/2N\n(f + g)(z(τ))dτ\n+\nˆ 2t/2N\nt/2N\n+ · · · +\nˆ t\n(2N−1)t/2Nt\n\u0014\u0012f + g\n2\n\u0013\n(z(τ)) −\n\u0012f + g\n2\n\u0013 \u0012\nz\n\u0012\nτ −\nt\n2N\n\u0013\u0013\u0015\ndτ\n=x +\nˆ t/2N\n0\n+\nˆ 3t/2N\n2t/2N\n+ · · · +\nˆ (2N−1)t/2N\n(2N−2)t/2N\nf(z(τ))dτ\n+\nˆ 2t/2N\nt/2N\n+ · · · +\nˆ t\n(2N−1)t/2Nt\ng(z(τ))dτ\n+\nˆ 2t/2N\nt/2N\n+ · · · +\nˆ t\n(2N−1)t/2Nt\n\u0014\u0012f + g\n2\n\u0013\n(z(τ)) −\n\u0012f + g\n2\n\u0013 \u0012\nz\n\u0012\nτ −\nt\n2N\n\u0013\u0013\u0015\n+\n\u0014\ng\n\u0012\nz\n\u0012\nτ −\nt\n2N\n\u0013\u0013\n−g(z(τ))\n\u0015\ndτ.\n(3.31)\nThus if w(t) satisfying:\nw(t) =x +\nˆ t/2N\n0\n+\nˆ 3t/2N\n2t/2N\n+ · · · +\nˆ (2N−1)t/2N\n(2N−2)t/2N\nf(w(τ))dτ+\n+\nˆ 2t/2N\nt/2N\n+ · · · +\nˆ t\n(2N−1)t/2Nt\ng(w(τ))dτ.\n(3.32)\nThen we have\n|z(t) −w(t)| ≤\nˆ t\n0\nmax(Lip(f), Lip(g))|z(τ) −w(τ)|dτ\n+ t\n2ωz,[0,t]\n\u0012 t\n2N\n\u0013 \u0014\nLip\n\u0012f + g\n2\n\u0013\n+ Lip(g)\n\u0015\n.\n(3.33)\nRecall that ω is the modulus of continuity deﬁned in Proposition 3.6. Again, by Gr¨onwall’s\ninequality we have\n|z(t) −w(t)| ≤t\n2ωz,[0,t]\n\u0012 t\n2N\n\u0013 \u0014\nLip\n\u0012f + g\n2\n\u0013\n+ Lip(g)\n\u0015\nemax(Lip(f),Lip(g)).\n(3.34)\nFor any selected compact set K, ωz,[0,t]( t\n2n)\n→\n0 by Proposition 3.6, thus we obtain\nϕ(f+g)/2\nt\n∈AF.\nDeep Learning via Dynamical Systems: An Approximation Perspective\n27\nNow, we are ready to prove Proposition 3.11.\nProof of Proposition 3.11. Using the same technique in the proof of Lemma 3.13, we can\nshow that for f1, · · · , fm ∈F, ϕh\nt ∈AF, where h = P\ni qifi for some rational numbers\nqi. Let AF′ be the attainable set with control family F ′ = {Pm\ni=1 qifi : qi ∈Q, P\ni qi =\n1, fi ∈F, m ∈N}, then we have AF′ = AF. Since F ′ = F, we arrive at the desired\nresult using Lemma 3.12.\n4\nProof of Main Results\nIn this section, we prove the main results (Theorem 2.3 and 2.4). We start with the one di-\nmensional case to gain some insights on how a result can be established in general, and in\nparticular, elucidate the role of well functions (Deﬁnition 2.1) in constructing rearrange-\nment dynamics. This serves to motivate the extension of the results in higher dimensions.\n4.1\nApproximation Results in One Dimension and the Proof of Theo-\nrem 2.4\nWe take n = 1 in this subsection. Proposition 3.4, together with the fact that compositions\nof continuous and increasing functions are again continuous and increasing, implies that\nany function from AF must be continuous and increasing. This poses a restriction on the\napproximation power of AF as the following result shows:\nProposition 4.1. Let n = 1 and F be a Lipschitz control family, whose attainable set is\nAF. Then AF contains only increasing functions.\nProof. Proposition 3.4 implies that any function in AF is continuous and increasing,\nsince both properties are closed under composition. The proposition then follows from\nLemma 3.10.\nIt follows from Proposition 4.1 that any continuous function ϕ that is strictly decreasing\nover an interval [c, d] cannot be approximated by AF. Nevertheless, it makes sense to ask\nfor the next best property: can AF approximate any continuous and increasing function?\nTo investigate this problem, we ﬁrst select an appropriate control family, which corre-\nsponds to deep neural networks with ReLU activations, and see if it can indeed approxi-\nmate any such function. We will remove this explicit architectural assumption later. The\nReLU control family in n = 1 is given by\nF = {vReLU(w · +b) : v, w, b ∈R} .\n(4.1)\n28\nQianxiao Li, Ting Lin, Zuowei Shen\nNotice that the ReLU control family (4.1) satisﬁes the restricted afﬁne invariant condition\nas deﬁned in Deﬁnition 2.2.\nWe now show that in one dimension, ﬂow maps of ODEs driven by the ReLU control\nfamily can in fact approximate any continuous function.\nProposition 4.2. Let ϕ : R →R be continuous and increasing and F be the 1D ReLU\ncontrol family (4.1). Then, for any ε > 0 and compact K ⊂R, there exists bϕ ∈AF such\nthat ∥ϕ −bϕ∥C(K) ≤ε. In other words, ϕ ∈AF.\nProof. We need the following lemma, from which we can deduce the desired result .\nLemma 4.3. Let M ≥1. Given x1 < · · · < xM and y1 < · · · < yM, there exists a\nfunction ψ ∈AF such that ψ(xi) = yi.\nWe postpone the proof of Lemma 4.3 and ﬁrst show how to prove Proposition 4.2 from\nit. By replacing K with a larger set, we can always assume that K is a closed interval.\nConsider a partition ∆on K, with nodes x1 < · · · < xM.\nBy Lemma 4.3, we can ﬁnd ψ ∈AF such that ψ(xi) = ϕ(xi) for all i = 1, . . . , M.\nTherefore\nψ(x) −ϕ(x) ≤ψ(xi+1) −ϕ(xi) ≤ϕ(xi+1) −ϕ(xi) ≤ωϕ(|∆|)\n(4.2)\nwhenever x ∈[xi, xi+1]. Here |∆| := max1≤i≤M |xi −xi−1|. We deduce that ψ(x) −\nϕ(x) ≥−ωϕ(|∆|) holds for the same reason. Hence we have ∥ϕ −ψ∥C(K) ≤ωϕ(|∆|).\nSince ϕ is continuous, sending |∆| to 0 and using Proposition 3.6 gives the desired result.\nNow it remains to prove Lemma 4.3 constructively. To do this, ﬁrst observe that the def-\ninition of well function (Deﬁnition 2.1) when specialized to one dimension is a function\nhQ such that hQ(x) = 0 if and only if x ∈Q = [q1, q2] for some q2 > q1. This can be\nconstructed by the ReLU family (c.f. Example 2.6) by\nhQ = 1\n2[ReLU(q1 −x) + ReLU(x −q2)].\n(4.3)\nObviously, hQ ∈CH(F) ⊂CH(F), so that the condition that the latter contains a well\nfunction is trivially satisﬁed for the ReLU control family.\nProof of Lemma 4.3. By Proposition 3.11, we denote eF = F ∪{hQ : Q ⊂K}. We\nwill show that eF can produce the desired approximation property. We construct using\ninduction a mapping ϕk which maps xi to yi for i = 1, 2, · · · , k. First we show the base\ncase k = 1. Take hQ to be the well function with respect to Q = [q1, q2]. Since F is\nDeep Learning via Dynamical Systems: An Approximation Perspective\n29\ntranslation invariant, we can suppose that both x1 and y1 are greater than q2. Since hQ\ndoes not change sign in [q2, ∞), by Proposition 3.7 we know that either ϕ\nhQ\nt\nor ϕ\n−hQ\nt\ncan\nmap x1 into y1 for some t. Thus we prove the base case since F is symmetric.\nSuppose we have ϕk, now we will construct ϕk+1 based on ϕk. Applying ϕk, we may\nassume that xi = yi, i = 1, 2, · · · , k. Again we assume hQ is a well function with zero\ninterval Q = [q1, q2](q2 < min(x1, y1)) and hQ′ is a well function with interval Q′ =\n[q0, q1]. We further assume that hQ′(x) < 0 on [q1, ∞), hQ(x) < 0 on [q2, ∞), otherwise\nwe can use −hQ or −hQ′ in their places.\nLet t1 = inf{t : ϕ\nhQ′\nt\n(xk) < q2} and t2 = sup{t : ϕ\nhQ′\nt\n(xk+1) > q2, ϕ\nhQ′\nt\n(yk+1) > q2}.\nClearly we have t1 < t2. Choose any t′ ∈(t1, t2), and ψ = ϕ\n±hQ\nt\nmapping ϕ\nhQ′\nt′ (xk+1) to\nϕ\nhQ′\nt′ (yk+1), we construct\nϕk+1 = ϕ\n−hQ′\nt′\n◦ψ ◦ϕ\nhQ′\nt′\n◦ϕk\n(4.4)\nas desired. By induction, we have completed the proof of Lemma 4.3.\nSufﬁcient Conditions for Approximation of Continuous and Increasing functions\nand the Proof of Theorem 2.4.\nWe showed previously that all continuous and increas-\ning functions can be approximated by ReLU-driven dynamical systems. In this section,\nwe shall do away with an explicit architecture, which leads to the proof of Theorem 2.4.\nThe key observation from the proof of Lemma 4.3, is that all we really need is having\na well function contained in CH(AF) that we can translate and change signs, which is\nachieved by a restricted afﬁne invariance assumption. On the other hand, whether or not\nF itself is a ReLU control family, or any other speciﬁc family, is inconsequential. This\nmotivates us to ask the question of sufﬁciency: what assumptions on F is enough to guar-\nantee that it is a universal control family? Notice that instead of constructing an explicit\nwell function in the form of the average of two ReLU functions, we can just use an arbi-\ntrary well function as deﬁned in 2.1 to drive the dynamics. The following result makes\nthis precise.\nProposition 4.4. Assume the control family F is symmetric and translation invariant,\nwhich is equivalent to restricted afﬁne invariant with D = ±1 and A = 1 in Deﬁnition 2.2,\nand that CH(F) contains a well function. Then, the conclusion in Proposition 4.2 holds.\nProof. The proof is almost identical to that of Proposition 4.2 with the well function con-\nstructed by averaging two ReLU functions replaced by a general well function contained\nin CH(F). Notice that since a well function does not change sign out of I, by choosing\na proper sign one can always shrink a ﬁnite point arbitrarily close to the interval. This\nfollows from Proposition 3.7.\n30\nQianxiao Li, Ting Lin, Zuowei Shen\nProposition 4.4 combined with Corollary 3.9 implies Theorem 2.4. Clearly, Proposition 4.4\ngeneralizes Proposition 4.2. It also follows that if CH(F) contains all continuous func-\ntions, it must contain in particular a well function and so AF has the desired approxima-\ntion property. However, this is not necessary for universal approximation to hold.\nRemark 4.5. In one dimension, the ability for a dynamical system to approximate any\ncontinuous and increasing function has the immediate consequence that if we were to\nembed the dynamical system in two dimensions, then we can approximate any continuous\nfunction ϕ of bounded variation, as long as we are allowed a linear transformation in\nthe end, e.g. if g in Prop. 3.8 is linear. This is because a continuous function of bounded\nvariation can always be written as a difference of two continuous and increasing functions.\nHowever, this does require embedding in high dimensions. We will show later that for\nn ≥2, embedding is not necessary to achieve universal approximation.\n4.2\nApproximation Rates in One Dimension\nAll results so far are on whether a given function can be approximated by a dynamical\nsystem with control families satisfying certain conditions. However, by the very deﬁnition\nof the attainable set we are forced to consider dynamical systems of ﬁnite, but arbitrarily\nlarge time horizons. Just like in the development of traditional approximation theory, one\nmay be interested to ask the following: given an approximation budget, how well can we\napproximate a given function? Perhaps a more pertinent question is this: what kind of\nfunctions can be efﬁciently approximated by dynamical systems? There are more than\none way to deﬁne the notion of budget. Here, we will consider a natural one in continuous\ntime: the time horizon T.\nIn this part, we give some results in this direction in the simplest case: the one dimensional\ncase (n = 1) and the ReLU activation control family. For convenience of exposition, we\nassume that our target function ϕ is deﬁned on [0, 1]. We postpone results on general\ncontrol families in higher dimensions to future work.\nTo properly quantize the efﬁciency, we should eliminate the positive homogeneity of the\nReLU control function, which masks the effect of the time horizon T due to the ability to\narbitrarily rescale time. Therefore, we restrict |v|, |w| ≤1 in vReLU(w · +b) and then the\nquantity of time horizon becomes meaningful.\nRemark 4.6. An alternative is using\n´\n|w|dt to measure the approximation cost in place\nof T. This notation is related to the Barron space analysis [33]. It can be checked that one\ncan change T into\n´\n|w|dt in the following results. Lastly, it is also possible to measure\nthe complexity of the variation of w, v, b in time. Here, we do not consider such cases.\nFirst, we show in the following lemma that if ϕ is piecewise linear, then it can be repre-\nDeep Learning via Dynamical Systems: An Approximation Perspective\n31\nsented by functions in AF(T) for some T large enough.\nBefore introducing the following lemma, we ﬁrst deﬁne the Total Variation with a slight\nmodiﬁcation. Suppose u is a function deﬁned on [0, 1], we extend u to uE such that uE = 0\nin [−ε, 0) ∪(1, 1 + ε]. We deﬁne ∥u∥TV = ∥uE∥TV[−ε,1+ε], the latter is deﬁned as\n∥f∥TV[−ε,1+ε] =\nsup\n−ε=x0<···<xM=1+ε\nM\nX\ni=1\n|f(xi) −f(xi−1)|\n(4.5)\nLemma 4.7. If ln ϕ′ is a piecewise constant function with N pieces, then ϕ can be written\nas\nϕ = ϕg1\nt1 ◦· · · ◦ϕgN−1\ntN−1 + c.\n(4.6)\nHere, gi ∈F and ϕ·\n· denotes the ﬂow maps as deﬁned in Section 3.2 and c is a constant.\nMoreover, we have ϕ ∈AF(T) for T ≥∥ln ϕ′∥TV\nProof. We ﬁrst show an auxiliary result, suppose that\nϕ = ϕg1\nt1 ◦· · · ◦ϕgN−1\ntN−1 + c,\n(4.7)\nThen ln ϕ′ can be written as the sum of N −1 Heaviside functions. The proof is by\ninduction. For the N = 1 case it can be checked by direct calculation, and suppose that\nϕ = ϕg1\nt1 ◦ϕ2 and we have\nϕ = ϕg1\nt1\n′(ϕ2(x))ϕ′\n2(x)\n(4.8)\nby chain rule. Thus\nln ϕ′ = ln ϕg1\nt1\n′(ϕ2(x)) + ln ϕ′\n2(x)\n(4.9)\nand the ﬁrst term in RHS is a Heaviside function, while the second term is a sum of N −2\nHeaviside functions by induction hypothesis. Hence we prove the result by induction.\nThe proof of the original proposition is inductive by construction. Take derivative on\nϕ = ϕg1\nt1 ◦· · · ◦ϕgN−1\ntN−1 + c, we obtain ln ϕ′ = ln ϕg1\nt1\n′ + · · · + ln ϕgN−1\ntN−1\n′. Since ln ϕ′ is a\npiecewise constant function, it can be written as\nln ϕ′ = H1 + H2 + · · · + HN−1,\n(4.10)\nwhere all Hi are Heaviside functions. Integrate ϕgN−1\ntN−1\n′(x) = HN−1(x) we obtain ϕgN−1\ntN−1 ,\nand then integrate\nϕgN−2\ntN−2\n′(x) = HN−2(ϕgN−1\ntN−1 )−1(x)\n(4.11)\n32\nQianxiao Li, Ting Lin, Zuowei Shen\nwe obtain ϕgN−2\ntN−2 , and so on. One can easily verify that each ϕ·\n· is a ﬂow map generated by\nsome ReLU activation function. Hence we prove the ﬁrst part of the proposition.\nFor the second part, we notice that if f = ReLU(wx + b), then ln ϕf\nt\n′ is a Heaviside\nfunction with a jump at x = −b/w. Since we can ﬁnd a decomposition P\ni Hi such that\nP\ni |wi| = ∥ln ϕ′∥TV. Thus the second part of proposition is proven.\nFrom the proof of the previous lemma, we know that T = ∥ln ϕ′∥TV[0,1] is optimal, since\nP\ni |ai| ≤∥ln ϕ′∥TV[0,1] holds (TV is a semi-norm). In view of this lemma, we prove the\nfollowing, which gives a quantitative approximation result.\nProposition 4.8. Suppose ϕ : [0, 1] →R is an increasing function. Moreover, suppose ϕ\nis piecewise smooth and T0 := ∥ln ϕ′∥TV([0,1]) ≤∞. Then ϕ ∈AF(T) for T ≥T0.\nProof. The key ideas of the proof is separated into two parts. The ﬁrst part is to show\nthat the constant in Lemma 4.7 has negligible cost, by considering ϕεReLU(·+M)\nt\nϕ−εReLU(·)\nt\n.\nThis provides a translation on [0, 1]: x 7→x + (eε −1)M. By sending M →∞we can\nconstruct any translation with negligible time cost.\nThe second part is that if | ln ϕ′(x)−ln ψ′(x)| ≤ε, and ϕ(0) = ψ(0), then |ϕ(x)−ψ(x)| ≤\n(eε −1)∥ϕ′∥C[0,1].\nNow it sufﬁces to prove a rather simple result: given a function u = ln ϕ′, on each pieces\nI′ of u, we can use piecewise constant function v|I′ to approximate u|I′ (restriction on\nI′) such that ∥v∥TV[0,1] ≤∥u∥TV[0,1] and ∥v −u∥∞≤ε. Thus we can ﬁnd a function\nϕ ∈AF((1 −ε)T0) such that ln ϕ′ = (1 −ε)v. By compositing a translation, we know\nthat there exists ψ ∈AF(T0) such that ∥ψ −ϕ∥C[0,1] ≤exp(ε∥ϕ∥C[0,1] + ε). Thus we\nconclude that ϕ ∈AF(T0).\nThe preceding results show that it is possible to constrain the approximation space to ﬂow\nmaps with time horizon up to some ﬁnite T0, provided that the target function ϕ is such\nthat ∥ln ϕ′∥≤T. In this sense, the total variation of the logarithm of ϕ is a measure of\ncomplexity under our compositional approximation procedure.\nLet us now develop the quantitative results a little further for the case where T is not\nsufﬁciently large, i.e. T < ∥ln ϕ′∥TV. This involves analyzing the error\nET(ϕ) =\ninf\nψ∈AF (T) ∥ϕ −ψ∥C(K),\n(4.12)\nwhich may be non-zero when T < ∥ln ϕ′∥TV.\nProposition 4.9. ET(ϕ) is given by the following optimization problem\ninf\nψ\n∥ϕ −ψ∥C[0,1],\ns.t. ∥ln ψ′∥TV ≤T.\n(4.13)\nDeep Learning via Dynamical Systems: An Approximation Perspective\n33\nNotice that the existence of ln ψ′ implies that ψ is a continuously increasing function, so\nwe may consider the above optimization problem only for the case where ψ is continu-\nously increasing.\nIt is generally hard to work with optimization problems such as (4.13), since it involves\ntotal variations of logarithms of functions. Below, we formulate its relaxed version.\nProposition 4.10. Denote the relaxed optimization problem\nγ(u, T) = inf\nv\n∥u −v∥C[0,1],\ns.t. ∥v∥TV ≤T.\n(4.14)\nThen ET (ϕ) ≤[exp(γ(ln ϕ′, T)) −1]∥ϕ′∥C[0,1]\nProof. We choose v such that ∥v∥TV ≤T and\n∥ln ϕ′ −v∥C[0,1] ≤γ(ln ϕ′, T) + ε.\n(4.15)\nChoose ψ such that ln ψ′ = v and ψ(0) = ϕ(0). Then since ∥ln ψ′\nϕ′ ∥TV ≤γ(ln ϕ′, T) + ε,\nwe have | ψ′\nϕ′ −1| ≤exp(γ(ln ϕ′, T) + ε) −1.\nHence\n|ϕ(x) −ψ(x)| ≤\nˆ x\n0\n|ϕ′(x)|\n\f\f\f\f1 −ψ′(x)\nϕ′(x)\n\f\f\f\f ≤∥ϕ′∥C[0,1] [exp(γ(ln ϕ′, T)ε) −1] .\n(4.16)\nSending ε →0, we arrive at the result.\nIn general, both (4.13) and (4.14) are hard to solve. However, for some simple cases of u,\nthe problem (4.14) has explicit solution. For example, if u itself is a increasing function,\nthen the solution of (4.14) is 1\n2(∥u∥TV −T). If u is increasing in [0, s] and decreasing\nin [s, 1], then the solution of (4.14) is 1\n4(∥u∥TV −T). This gives approximation rates for\nspeciﬁc cases, but a general investigation of these approximation rates are postponed to\nfuture work.\n4.3\nApproximation Results in Higher Dimensions and the Proof of\nTheorem 2.3\nIn this section, we will generalize the universal approximation results to higher dimen-\nsions. The interesting ﬁnding is that in higher dimensions, the fact that AF contains only\nOP homeomorphisms no longer poses a restriction on approximations in the Lp sense.\nMoreover, the sufﬁcient condition for universal approximation in higher dimensions is\nclosely related to that in one dimension, where the rearrangement dynamics are driven\nby well functions. We will prove the following result, which together with Corollary 3.9\nimplies Theorem 2.3.\n34\nQianxiao Li, Ting Lin, Zuowei Shen\nProposition 4.11. Let n ≥2. Suppose F is restricted afﬁne invariant and CH(F) con-\ntains a well function. Then for any compact set K, p ∈[1, ∞), ϕ ∈C(Rn) , ε > 0, there\nexists a mapping ˜ϕ ∈AF, such that ∥˜ϕ −ϕ∥Lp(K) ≤ε.\nWe notice that for the purpose of approximation, the fact CH(F) contains a well function\nh allows us to assume without loss of generality that F contains a well function. To see\nthis, denote by eF the smallest restricted afﬁne invariant set containing F ∪h. We have\nF ⊂eF ⊂CH(F). Proposition 3.11 then says that AF = A e\nF, hence we can prove\napproximation results using eF in place of F.\n4.3.1\nPreliminaries\nIn order to prove Proposition 4.11, we require a few preliminary results which we state\nand prove in this subsection. The key approach in proving the proposition is similar to\nthe one dimensional case: we show that we can transform a ﬁnite number of distinct\nsource points into a ﬁnite number of target points, which are not necessary distinct. More\nprecisely, we show the following proposition, which generalize Lemma 4.3 given in the\none dimensional case.\nLemma 4.12. Suppose F contains a well function. Let ε > 0 and x1, · · · , xm, y1, · · · , ym ∈\nRn be such that {xk} are distinct points. Then there exists ψ ∈AF such that |ψ(xk) −\nyk| ≤ε for all k = 1, . . . , m.\nLemma 4.12 follows from the combination of the following two lemmas.\nLemma 4.13. Suppose F contains a well function and x1, · · · , xm are distinct points.\nThen given any ε > 0, there exists a ﬂow map ψ ∈AF such that |ψ(xk) −xk| ≤ε, such\nthat for each i = 1, 2, · · ·n, [ψ(xk)]i (the i-th coordinate of ψ(xk)) k = 1, 2, · · · , m are\nm distinct real numbers.\nLemma 4.14. Suppose F contains a well function, x1, · · · , xm are distinct points and\nsatisfy the result of Lemma 4.13, that is, {xk\ni } are m distinct real numbers for any i. Then\ngiven any ε > 0 for m target points y1, · · · , ym, we have a ﬂow map ψ ∈AF such that\n|ψ(xk) −yk| ≤ε .\nNow we prove these two lemmas.\nProof of Lemma 4.13. To prove the lemma it is enough to show that if there is a pair of\ntwo points xj and xk, such that xj\nI = xk\nI for some I, we can then ﬁnd a ﬂow map η ∈AF\nsuch that η can separate xj\nI and xk\nI and at the same time, do not cause other pairs of points\nwithout initially distinct coordinates to overlap. Without loss of generality, we assume\nj = 1, k = 2, I = 1, and we only need to show that if x1\n1 = x2\n1, then there exists an\nη ∈AF such that\nDeep Learning via Dynamical Systems: An Approximation Perspective\n35\n1. |η(xk) −xk| ≤ε1 :=\n1\nnm2ε;\n2. [η(x1)]1 ̸= [η(x2)]1;\n3. if xk\n1 ̸= xl\n1, then [η(xk)]1 ̸= [η(xl)]1.\nWe brieﬂy explain these requirements. Consider\nX1 = {(k, l) : 1 ≤k < l ≤m, xk\n1 = xl\n1}\n(4.17)\nand\nη(X1) = {(k, l) : 1 ≤k < l ≤m, [η(xk)]1 = [η(xl)]1}.\n(4.18)\n2 and 3 implies that #X1 > #η(X1) ≥0, hence #X1 is strictly decreasing after η.\nDenote d = min{|xk\n1 −xl\n1| : xk\n1 ̸= xl\n1}. Since x1 and x2 are two distinct points, we can\nﬁnd a coordinate index I(̸= 1) such that x1\nI ̸= x2\nI. Here we assume x1\nI < x2\nI. Suppose f\nin F is a well function with zero set {Ω1}. Written in coordinate form, f is given by\nf = (f1, · · · , · · · , fn),\n(4.19)\nwhere each fi : Rn →R. Since F is translation invariant, we can assume Ω1 contains 0\nwithout loss of generality.\nConsider the following dynamics\n˙z1 = f1(xI + b),\n˙zi = 0, i = 2, · · · , n.\n(4.20)\nNotice that the boundedness and convexity of Ω1 guarantees that the reduced 1D dy-\nnamics satisﬁes our previous discussion (it contains 1D well function, since the inter-\nsection of a bounded convex set with a line is an interval) In other words, we choose\nD = diag(1, 0, · · · , 0), Aij = δiIδjI, b = (0, 0, · · · , bI, 0)T in the form ˜f = Df(A · +b).\nbI is chosen such that x1\nI + bI ∈Ω1 but x2\nI + bI ̸∈Ω1. The existence of bI is implied by\nthe boundedness of Ω1. We denote by Pt the ﬂow map of this dynamics. We next choose\na proper t such that 1,2,3 are satisﬁed.\nSince ˜f1(x1) = 0 and ˜f1(x2) ̸= 0, we deduce that [Pt(x1)]1 ̸= [Pt(x2)]1 whenever t ̸=\n0. Hence 2 is satisﬁed with no additional condition. Notice that when |Pt(xk) −xk| ≤\nmin(ε1, d\n3), then both 1 and 3 are satisﬁed. Since CH({xk}) is bounded, hence ∥Pt −\nid ∥C(CH({xk})) →0 when t →0 by Proposition 3.6. Therefore there exists t0 > 0,\nsuch that ∥Pt −id ∥C(CH({xk})) ≤min(ε1, d\n3). Hence we conclude that η = Pt0 satisﬁes\n1,2,3.\n36\nQianxiao Li, Ting Lin, Zuowei Shen\nProof of Lemma 4.14. Without loss of generality, we can assume that for each coordinate\nindex i, yk\ni are m distinct real numbers, since if not, we can always add a small pertur-\nbation to it directly and this will not affect approximation. We also assume Ω1 contains\norigin, as we did in the proof of Lemma 4.13.\nThe basic idea is similar to Lemma 4.13, by choosing a proper linear transformation we\ncan freeze some point while transporting other points. Since we need to control more than\n2 points, we can take multiple transformations and evolve them sequentially. We only\nneed to prove for any coordinate index i (without loss of generality i = 1), we can ﬁnd an\nη ∈AF such that [η(xk)]1 = yk\n1.\nWith a re-labelling, we can assume that x1\n2 < x2\n2 < · · · < xm\n2 . Consider the following\ndynamics\n˙z1 = f1(az2 + b),\n˙zi = 0, i = 2, · · · , n.\n(4.21)\nIn other words, we choose D = diag(1, 0, · · · , 0), Aij = aδi2δj2, b = (0, b2, · · · , , 0)T\nin the form ˜f = Df(A · +b). a is chosen sufﬁciently small such that all Axk are lying\nin Ω1. We denote the ﬂow map by Pt(b2), where the dependence of b2 is emphasized. To\nsimplify our notation, we use P−t(b2) to denote the ﬂow map of ˙z = −Df(Az + b).\nNow we wish to choose r1, r2, · · ·rm, such that f1(Axi + rj) = 0 if and only if i < j. Let\n{0} × (ul, ur) × · · · = Ω1 ∩\n\u0000{0} × R × · · · ), where (ul, ur) be the restriction of Ω1, on\ncoordinate index 2. Then a choice of rk is rk = ur −axk\n2 + a\n2 minj(xj\n2 −xj−1\n2\n).\nNow {η(k)} are deﬁned recursively. That is,\nη(0) = id\nη(k) = Ptk(rk) ◦η(k−1),\nwhere\ntk = (yk\n1 −[η(k−1)(xk)]1)/f1(Axk + rk).\n(4.22)\nWe now prove that η = η(m) ◦· · · ◦η(1) satisﬁes our requirement. By induction (on k), we\nshow that: [η(k)(xi)]1 = yi\n1 for i ≤k. k = 0 is vacuous. Suppose [η(k−1)(xi)]1 = yi\n1 for\ni ≤k −1, since [η(k−1)(xi)]2 = xi\n2, we have\nη(k)(xi) = Ptk(rk)(η(k−1)(xi)) = η(k−1)(xi) = yi.\n(4.23)\nBy deﬁnition we know that η(k)(xk) = yk. Hence the induction step is proved. From\ninduction, we know that η satisﬁes our requirement.\n4.3.2\nProof of Proposition 4.11.\nProof. Since K is compact, by extension it sufﬁces to consider the case that K is a hyper-\ncube. We can for simplicity take the unit hyper-cube K = [0, 1]n, since the general case\nDeep Learning via Dynamical Systems: An Approximation Perspective\n37\nis similar. Since ϕ ∈Lp(K), by standard approximation theory ϕ can be approximated\nby piecewise constant functions, i.e. there exists\nˆϕ =\nX\ni\nϕiχi\n(4.24)\nsuch that ∥ˆϕ −ϕ∥Lp(K) ≤ε/2. Here i = [i1, · · · , in] is a multi-index, ϕi ∈Rn and χi is\nthe indicator of the cube\n□i =\n\u0014 i1\nN , i1 + 1\nN\n\u0015\n× · · · ×\n\u0014in\nN , in + 1\nN\n\u0015\n.\n(4.25)\nwe also denote pi = ( i1\nN , · · · , in\nN ). We also deﬁne a shrunken cube\n□α\ni =\n\u0014 i1\nN , i1 + α\nN\n\u0015\n× · · · ×\n\u0014in\nN , in + α\nN\n\u0015\n.\n(4.26)\nwhere 0 < α ≤1. We have K = ∪i□i, and we deﬁne Kα = ∪i□α\ni . We also construct\na shrinking function in one dimension hα : [0, 1] →[0, 1], such that hα(x) =\ni\nN if\ni\nN ≤\nx ≤i+α\nN , and continuously increasing in [0, 1]. Using this, we can form a n dimensional\nshrinking map by tensor product:\nHα(x) = (hα(x1), · · · , hα(xn)).\n(4.27)\nThe idea of the proof of Proposition 4.11 is quite simple: we just contract each grid □i into\na point pi approximately, then use the lemma above to transform each pi into ϕi. The latter\nis discussed in the preliminary step, we here construct an “almost” contraction mapping\nin AF that approximates Hα.\nClaim: For a given tolerance ε1 > 0, there exists a ﬂow map eH ∈AF such that | eH −\nHα|C(K) ≤ε1.\nProof of the Claim. Since h is increasing and continuous, we wish to utilize our result\nin 1 dimension. Concretely speaking, we demonstrate how to restrict the n dimensional\ncontrol family to one dimension.\nSuppose F is a n dimensional control family, then we deﬁne for each f = (f1, . . . , fn) ∈\nF the dynamics driven by its restriction to ﬁrst coordinate by\n˙z1 = f1(x1),\n˙zi = 0 for i ≥2,\n(4.28)\ni.e., take D = A = diag(1, 0, · · · , 0). Such control systems is denoted as FR,1 (R means\nrestriction and 1 means ﬁrst coordinate). Clearly FR,1 is closed under composition. More-\nover, AFR,1 is coincide with the following set\nAR × {id} × {id} · · ·{id},\n(4.29)\n38\nQianxiao Li, Ting Lin, Zuowei Shen\nwhere R is a one dimensional control family\nR = {g(x) | g(x) = f1(x, 0, · · · , 0)\nf ∈F}.\n(4.30)\nSince F contains a well function, so does R. By Proposition 4.4 we can ﬁnd ˜h ∈R such\nthat |˜h −hα|C([0,1]) ≤ε\nn.\nBy composition we know that ˜H := (˜h, ˜h, · · · , ˜h) is in AF, and | ˜H −Hα|C(K) ≤ε.\nWe use aforementioned notations, ψ for transport pi to ϕi, and ˜H is the approximate\ncontraction mapping, satisfying the following estimates:\n|ψ(pi) −ϕi| ≤ε1 < 1,\n(4.31)\n∥˜H −Hα∥C(K) ≤ε2 < 1.\n(4.32)\nHere ε1 and ε2 is to be determined later.\nNow we estimate the error of ∥ψ ◦eH −ϕ∥Lp(K). For any α we can write\n∥ψ ◦eH −ϕ∥Lp(K) ≤∥ψ ◦eH −ˆϕ∥Lp(K) + ∥ˆϕ −ϕ∥Lp(K)\n≤∥ψ ◦eH −ˆϕ∥Lp(Kα) + ∥ψ ◦eH −ˆϕ∥Lp(K\\Kα) + ε\n2\n≤J1 + J2 + ε\n2.\n(4.33)\nEstimation of J1.\nJ1 =∥ψ ◦eH −ψ ◦Hα∥Lp(Kα) + ∥ψ ◦Hα −ˆϕ∥Lp(Kα)\n≤ωψ(∥˜H −Hα∥C(K)) +\nX\ni\n|ψ(pi) −ϕi| · |□i|1/p\n≤ωψ(∥˜H −Hα∥C(K)) + Nn−n/pε1\n≤ωψ(ε2) + Nn−n/pε1.\n(4.34)\nEstimation of J2. Denote eK = [−1, 2]n as an enlarged cube. We have\nJ2 ≤|K \\ Kα| ·\n\u0012\ndiam(ψ( ˜K)) + ∥ˆϕ∥L∞(K)\n\u0013\n.\n(4.35)\nWe choose ψ such that ε1 ≤ε\n8, α such that\n|K \\ Kα| ≤\n\u0012\ndiam(ψ( ˜K)) + ∥ˆϕ∥L∞(K)\n\u0013−1 ε\n4,\n(4.36)\nand ﬁnally ˜H such that ωψ(ε2) ≤\nε\n8. Therefore we have ∥ψ ◦eH −ϕ∥≤ε, take ˜ϕ =\nψ ◦eH ∈AF yielding the result.\nAs in the 1D case, Proposition 4.11 together with Corollary 3.9 imply Theorem 2.3.\nDeep Learning via Dynamical Systems: An Approximation Perspective\n39\n4.4\nApproximation Results in Tensor-Product Type Dynamical Sys-\ntems\nSometimes, we are interested in control families generated by a tensor products. Such\ncontrol families have the advantage that it can be parameterized by scalar functions of\none variable, hence may allow for greater ﬂexibility in analysis and practice. In this last\nsection, we give some results that apply speciﬁcally to tensor product control families. Let\nus denote\nΠF = {f(x) = (g(x1), g(x2), · · · , g(xn)) : g ∈F},\n(4.37)\nwhere F is a one dimensional control family.\nAs in the results in higher dimensions, we may wish consider the n dimensional con-\ntrol family F(n), which is the smallest set containing ΠF that is also invariant under\nf(·) 7→Df(A · +b), where D, A are diagonal matrices. However, all functions ψ in AF\nare separable: ψ = (ψ1(x1), · · · , ψn(xn)). Moreover, we can deduce from the 1D results\nthat ψi is continuously increasing. Clearly, this F(n) has limited approximation ability.\nInstead, we will relax the requirement that A is diagonal so that it can be any matrix, lead-\ning to a stronger version of the restricted invariance requirement in Theorem 2.3. This\nthen leads to the following approximation result:\nProposition 4.15. Suppose F(n) and F satisﬁes\n1. F(n) contains ΠF;\n2. F(n) is invariant under f(·) 7→Df(A · +b), where D is any diagonal matrix, A is\nany matrix, b is any Rd vectors;\n3. AF contains all continuous and increasing functions from R to R.\nThen for any ε > 0, p ∈(1, ∞] and compact set K, and ϕ ∈C(Rn), we have ˜ϕ ∈AF(n),\nsuch that ∥ϕ −˜ϕ∥Lp(K) ≤ε.\nRemark 4.16. This result is not a corollary of Proposition 4.11, even if CH(F) contains\na well function. Since in this case the zero set of the tensor product of the well function\nmay be unbounded.\nSimilar to estimation of Proposition 4.11, we omit the main body of this proof but only\nrestate preparations about ψ and eH.\nEstimations on eH.\nLemma 4.17. Suppose F(n) and F satisﬁes conditions in Proposition 4.15. For a given\ntolerance ε1 > 0, there exists a ﬂow map eH ∈AF(n) such that | eH −Hα|C(K) ≤ε1.\n40\nQianxiao Li, Ting Lin, Zuowei Shen\nProof. This is straightforward from the deﬁnition of the tensor product control family and\nAF contains all continuous increasing functions.\nEstimations on ψ.\nBefore the main estimate, we ﬁrst show a useful lemma.\nLemma 4.18. Suppose that g ∈AF, then (x1, x2, · · · , xn) 7→(x1 + g(x2), x2 · · · , xn) is\nin AF(n).\nProof. We decompose the construction into two parts. By setting D = diag(1, 1, 0, · · · , 0)\nand A22 = A12 = 1 and Aij = 0 otherwise. We ﬁrst only look at the second coordinate,\nknowing that for all g ∈AF, there exists a ﬁnite number S ≥1 of ﬂow maps ϕts\nfs,\ns = 1, · · · , S, such that\ng = ϕtS\nfS ◦· · · ◦ϕt1\nf1.\n(4.38)\nHere, D and A are chosen in the previous paragraph, we deduce that x1 −x2 is constant\nunder all mapping with following form:\nz 7→Df(Az + b).\n(4.39)\nIf we select f1, · · · , fS, sending x2 to g(x2), we know x1 7→x1 + g(x2) −x2. Hence\n(x1, x2, · · · , xn) 7→(x1 + g(x2), x2, · · · , xn)\n(4.40)\nis in AF(n).\nAlso, by setting D = diag(1, 0, · · · , 0) and Aij = δi2δj2, we know that\n(x1, x2, · · · , xn) 7→(x1, g−1(x2), · · · , xn)\n(4.41)\nis in AF(n). Composing two parts yields the result.\nLemma 4.19 (Analogous to Lemma 4.13). Suppose F(n) and F satisﬁes conditions in\nProposition 4.15 and x1, · · · , xm are distinct points. Then, given any ε > 0, there exists\na ﬂow map ψ ∈AF(n), such that |ψ(xk) −xk| ≤ε, and that for each i = 1, 2, · · ·n,\n[ψ(xk)]i (the ith coordinate of ψ(xk)), k = 1, 2, · · · , m are m distinct real numbers.\nProof. Similar to Lemma 4.13, we prove that if x1\n1 and x2\n1, then we can ﬁnd a η that\nseparates them. The three requirements are the same as we established in Lemma 4.13,\nhence omitted here.\nSuppose x1\nI ̸= x2\nI for some I. We can ﬁnd two continuously increasing function P(·) and\nQ(·) such that\nP(x1\nI) −Q(x1\nI) = 1,\nP(x2\nI) −Q(x2\nI) = −1,\nP(xk\nI) −Q(xk\nI) = 0,\n(4.42)\nDeep Learning via Dynamical Systems: An Approximation Perspective\n41\nfor the other k’s. By assumptions on F, we can ﬁnd eP(·) and eQ(·) such that\n∥P(·) −eP(·)∥C([0,1]), ∥Q(·) −eQ(·)∥C([0,1]) ≤min(d, 1)\n4\n.\n(4.43)\nBy Lemma 4.17, we know that (x1, · · · , xn) 7→(x1 + eP(xI) −eQ(xI), · · · xn) is in AF(n).\nIt can be checked that this is our desired η.\nLemma 4.20 (Analogous to Lemma 4.14). Suppose F(n) and F satisﬁes conditions in\nProposition 4.15and x1, · · · , xm are distinct points. Moreover we assume xk satisﬁes the\nresult of Lemma 4.13, that is, {xk\ni , k = 1, . . . , m} are m distinct real numbers for any i.\nThen, given any ε > 0, for m target point y1, · · · , ym, we have a ﬂow map ψ ∈AF(n)\nsuch that |ψ(xk) −yk| ≤ε .\nProof. Similar to proof of Lemma 4.14, we use x2 to translate x1 (denoted as η). We ﬁnd\ntwo one dimensional P(·) and Q(·), both continuously increasing, such that xk\n1 +P(xk\n2)−\nQ(xk\n2) = yk\n1. By assumptions on F we can ﬁnd eP(·) and eQ(·), such that\n∥P(·) −eP(·)∥C([0,1]), ∥Q(·) −eQ(·)∥C([0,1]) ≤ε\n2.\n(4.44)\nSince\nη = (x1, · · · , xn) 7→(x1 + eP(x2) −eQ(x2), · · · xn)\n(4.45)\nis in AF(n), and |[η(xk)]1 −yk\n1| ≤ε, we conclude that η satisﬁes our requirement.\nCombining these two lemmas, we obtain the following result from which we can deduce\nProp. 4.15\nLemma 4.21 (Analogous to Lemma 4.12). Suppose F(n) and F satisfy the conditions\nin Proposition 4.15. Let ε > 0 and x1, · · · , xm, y1, · · · , ym ∈Rn be such that {xk}\nare distinct points. Then there exists ψ ∈AF(n) such that |ψ(xk) −yk| ≤ε for all\nk = 1, . . . , m.\nReferences\n[1] Arnold, V. I. (1973). Ordinary differential equations.\n[2] Balachandran, K. and Dauer, J. P. (2002). Controllability of nonlinear systems in\nBanach spaces: A survey. Journal of Optimization Theory and Applications, 115(1):7–\n28.\n42\nQianxiao Li, Ting Lin, Zuowei Shen\n[3] Bao, C., Li, Q., Tai, C., Wu, L., and Xiang, X. (2019). Approximation analysis of\nconvolutional neural networks. Submitted.\n[4] Brenier, Y. and Gangbo, W. (2003). lp approximation of maps by diffeomorphisms.\nCalculus of Variations and Partial Differential Equations, 16(2):147–164.\n[5] Chang, B., Meng, L., Haber, E., Ruthotto, L., Begert, D., and Holtham, E. (2018).\nReversible architectures for arbitrarily deep residual neural networks. In Thirty-Second\nAAAI Conference on Artiﬁcial Intelligence.\n[6] Chang, B., Meng, L., Haber, E., Tung, F., and Begert, D. (2017). Multi-level residual\nnetworks from dynamical systems view. arXiv preprint arXiv:1710.10348.\n[7] Chen, T. Q., Rubanova, Y., Bettencourt, J., and Duvenaud, D. K. (2018). Neural\nordinary differential equations. In Advances in neural information processing systems,\npages 6571–6583.\n[8] Chukwu, E. N. and Lenhart, S. M. (1991). Controllability questions for nonlinear sys-\ntems in abstract spaces. Journal of Optimization Theory and Applications, 68(3):437–\n462.\n[9] Daubechies, I. (1992). Ten lectures on wavelets, volume 61. Siam.\n[10] Daubechies, I., DeVore, R., Foucart, S., Hanin, B., and Petrova, G. (2019). Nonlinear\napproximation and (deep) relu networks. arXiv preprint arXiv:1905.02199.\n[11] DeVore, R. A. (1998). Nonlinear approximation. Acta numerica, 7:51–150.\n[12] Dupont, E., Doucet, A., and Teh, Y. W. (2019). Augmented neural odes. arXiv\npreprint arXiv:1904.01681.\n[13] E, W. (2017). A Proposal on Machine Learning via Dynamical Systems. Communi-\ncations in Mathematics and Statistics, 5(1):1–11.\n[14] E, W., Han, J., and Li, Q. (2019a). A mean-ﬁeld optimal control formulation of deep\nlearning. Research in the Mathematical Sciences, 6(1):10.\n[15] E, W., Ma, C., and Wang, Q. (2019b). A Priori Estimates of the Population Risk for\nResidual Networks. arXiv:1903.02154 [cs, stat]. arXiv: 1903.02154.\n[16] Efﬂand, A., Kobler, E., Kunisch, K., and Pock, T. (2020). Variational networks: An\noptimal control approach to early stopping variational methods for image restoration.\nJournal of Mathematical Imaging and Vision, pages 1–21.\nDeep Learning via Dynamical Systems: An Approximation Perspective\n43\n[17] Fort, M. K. (1955). The embedding of homeomorphisms in ﬂows. Proceedings of\nthe American Mathematical Society, 6(6):960–967.\n[18] Gronwall, T. H. (1919). Note on the Derivatives with Respect to a Parameter of the\nSolutions of a System of Differential Equations. Annals of Mathematics, 20(4):292–\n296.\n[19] G¨uhring, I., Kutyniok, G., and Petersen, P. (2019). Error bounds for approximations\nwith deep relu neural networks in ws,p norms. arXiv preprint arXiv:1902.07896.\n[20] Haber, E. and Ruthotto, L. (2017). Stable architectures for deep neural networks.\nInverse Problems, 34(1):14004.\n[21] Hatcher, A. (2000). Algebraic topology. Cambridge Univ. Press, Cambridge.\n[22] He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual learning for image\nrecognition. In Proceedings of the IEEE Computer Society Conference on Computer\nVision and Pattern Recognition.\n[23] Jastrzebski, S., Arpit, D., Ballas, N., Verma, V., Che, T., and Bengio, Y. (2017).\nResidual connections encourage iterative inference. arXiv preprint arXiv:1710.04773.\n[24] Leveque, R. J. (2007). Finite Difference Methods for Ordinary and Partial Differen-\ntial Equations: Steady-State and Time-Dependent Problems.\n[25] Li, Q., Chen, L., Tai, C., and E, W. (2018). Maximum Principle Based Algorithms\nfor Deep Learning. Journal of Machine Learning Research, 18(1):1–29.\n[26] Li, Q. and Hao, S. (2018). An Optimal Control Approach to Deep Learning and\nApplications to Discrete-Weight Neural Networks. In Proceedings of the 35th Interna-\ntional Conference on Machine Learning, volume 80 of Proceedings of Machine Learn-\ning Research, pages 2985–2994. PMLR.\n[27] Li, Q., Shen, Z., and Tai, C. (2019). Deep approximation of functions by composi-\ntion. In prepartion.\n[28] Lin, H. and Jegelka, S. (2018). Resnet with one-neuron hidden layers is a universal\napproximator. In Advances in Neural Information Processing Systems, pages 6169–\n6178.\n[29] Liu, H. and Markowich, P. (2019). Selection dynamics for deep neural networks.\narXiv preprint arXiv:1905.09076.\n44\nQianxiao Li, Ting Lin, Zuowei Shen\n[30] Lu, Y., Li, Z., He, D., Sun, Z., Dong, B., Qin, T., Wang, L., and Liu, T.-Y. (2019).\nUnderstanding and Improving Transformer From a Multi-Particle Dynamic System\nPoint of View. arXiv preprint arXiv:1906.02762.\n[31] Lu, Y., Zhong, A., Li, Q., and Dong, B. (2018). Beyond Finite Layer Neural Net-\nworks: Bridging Deep Architectures and Numerical Differential Equations. In Pro-\nceedings of the 35th International Conference on Machine Learning, volume 80 of\nProceedings of Machine Learning Research, pages 3276–3285. PMLR.\n[32] Lu, Z., Pu, H., Wang, F., Hu, Z., and Wang, L. (2017). The expressive power of\nneural networks: A view from the width. In Advances in neural information processing\nsystems, pages 6231–6239.\n[33] Ma, C., Wu, L., et al. (2019). Barron spaces and the compositional function spaces\nfor neural network models. arXiv preprint arXiv:1906.08039.\n[34] Mallat, S. (1999). A wavelet tour of signal processing. Elsevier.\n[35] Mallat, S. (2016). Understanding deep convolutional networks. Philosophical Trans-\nactions of the Royal Society A: Mathematical, Physical and Engineering Sciences,\n374(2065):20150203.\n[36] Palis, J. (1974). Vector ﬁelds generate few diffeomorphisms. Bulletin of the Ameri-\ncan Mathematical Society, 80(3):503–505.\n[37] Parpas, P. and Muir, C. (2019). Predict globally, correct locally: Parallel-in-time\noptimal control of neural networks. arXiv preprint arXiv:1902.02542.\n[38] Ron, A. and Shen, Z. (1997). Afﬁne systems inl2 (rd): the analysis of the analysis\noperator. Journal of Functional Analysis, 148(2):408–447.\n[39] Ruthotto, L. and Haber, E. (2018). Deep neural networks motivated by partial differ-\nential equations. arXiv preprint arXiv:1804.04272.\n[40] Shen, Z., Yang, H., and Zhang, S. (2019a). Deep network approximation character-\nized by number of neurons.\n[41] Shen, Z., Yang, H., and Zhang, S. (2019b). Nonlinear approximation via composi-\ntions. arXiv preprint arXiv:1902.10170.\n[42] Sonoda, S. and Murata, N. (2017). Double continuum limit of deep neural networks.\nIn ICML Workshop Principled Approaches to Deep Learning.\nDeep Learning via Dynamical Systems: An Approximation Perspective\n45\n[43] Sonoda, S. and Murata, N. (2019). Transport analysis of inﬁnitely deep neural net-\nwork. The Journal of Machine Learning Research, 20(1):31–82.\n[44] Sun, Q., Tao, Y., and Du, Q. (2018). Stochastic training of residual networks: a\ndifferential equation viewpoint. arXiv preprint arXiv:1812.00174.\n[45] Sussmann, H. (2017). Nonlinear controllability and optimal control. CRC Press.\n[46] Tao, Y., Sun, Q., Du, Q., and Liu, W. (2018). Nonlocal neural networks, nonlocal dif-\nfusion and nonlocal modeling. In Advances in Neural Information Processing Systems,\npages 496–506.\n[47] Thorpe, M. and van Gennip, Y. (2018a). Deep limits of residual neural networks.\narXiv preprint arXiv:1810.11741.\n[48] Thorpe, M. and van Gennip, Y. (2018b). Deep limits of residual neural networks.\narXiv preprint arXiv:1810.11741.\n[49] Utz, W. (1981). The embedding of homeomorphisms in continuous ﬂows. In Topol-\nogy Proc, volume 6, pages 159–177.\n[50] Veit, A., Wilber, M. J., and Belongie, S. (2016). Residual networks behave like en-\nsembles of relatively shallow networks. In Advances in neural information processing\nsystems, pages 550–558.\n[51] Wang, B., Yuan, B., Shi, Z., and Osher, S. J. (2018). Enresnet: Resnet ensemble via\nthe feynman-kac formalism. arXiv preprint arXiv:1811.10745.\n[52] Warga, J. (1962). Relaxed variational problems. Journal of Mathematical Analysis\nand Applications, 4(1):111–128.\n[53] Zhang, D., Zhang, T., Lu, Y., Zhu, Z., and Dong, B. (2019a).\nYou only prop-\nagate once: Painless adversarial training using maximal principle.\narXiv preprint\narXiv:1905.00877.\n[54] Zhang, H., Gao, X., Unterman, J., and Arodz, T. (2019b). Approximation capabili-\nties of neural ordinary differential equations. arXiv preprint arXiv:1907.12998.\n[55] Zhang, L. and Wang, L. (2018). Monge-Ampere Flow for Generative Modeling.\narXiv preprint arXiv:1809.10188.\n[56] Zhang, X. (2009). Embedding diffeomorphisms in ﬂows in banach spaces. Ergodic\nTheory and Dynamical Systems, 29(4):1349–1367.\n46\nQianxiao Li, Ting Lin, Zuowei Shen\n[57] Zhang, X., Lu, Y., Liu, J., and Dong, B. (2018). Dynamically unfolding recurrent\nrestorer: A moving endpoint control method for image restoration.\narXiv preprint\narXiv:1805.07709.\n[58] Zhou, D.-X. (2018). Deep distributed convolutional neural networks: Universality.\nAnalysis and Applications, 16(06):895–919.\n",
  "categories": [
    "cs.LG",
    "math.OC",
    "stat.ML"
  ],
  "published": "2019-12-22",
  "updated": "2020-06-08"
}