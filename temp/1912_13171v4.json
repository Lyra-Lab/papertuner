{
  "id": "http://arxiv.org/abs/1912.13171v4",
  "title": "Deep Learning on Image Denoising: An overview",
  "authors": [
    "Chunwei Tian",
    "Lunke Fei",
    "Wenxian Zheng",
    "Yong Xu",
    "Wangmeng Zuo",
    "Chia-Wen Lin"
  ],
  "abstract": "Deep learning techniques have received much attention in the area of image\ndenoising. However, there are substantial differences in the various types of\ndeep learning methods dealing with image denoising. Specifically,\ndiscriminative learning based on deep learning can ably address the issue of\nGaussian noise. Optimization models based on deep learning are effective in\nestimating the real noise. However, there has thus far been little related\nresearch to summarize the different deep learning techniques for image\ndenoising. In this paper, we offer a comparative study of deep techniques in\nimage denoising. We first classify the deep convolutional neural networks\n(CNNs) for additive white noisy images; the deep CNNs for real noisy images;\nthe deep CNNs for blind denoising and the deep CNNs for hybrid noisy images,\nwhich represents the combination of noisy, blurred and low-resolution images.\nThen, we analyze the motivations and principles of the different types of deep\nlearning methods. Next, we compare the state-of-the-art methods on public\ndenoising datasets in terms of quantitative and qualitative analysis. Finally,\nwe point out some potential challenges and directions of future research.",
  "text": "Deep Learning on Image Denoising: An Overview\nChunwei Tiana,b, Lunke Feic, Wenxian Zhengd, Yong Xua,b,e,∗, Wangmeng Zuof,e, Chia-Wen Ling\naBio-Computing Research Center, Harbin Institute of Technology, Shenzhen, Shenzhen, 518055, Guangdong, China\nbShenzhen Key Laboratory of Visual Object Detection and Recognition, Shenzhen, 518055, Guangdong, China\ncSchool of Computers, Guangdong University of Technology, Guangzhou, 510006, Guangdong, China\ndTsinghua Shenzhen International Graduate School, Shenzhen, 518055, Guangdong, China\nePeng Cheng Laboratory, Shenzhen, 518055, Guangdong, China\nfSchool of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, Heilongjiang, China\ngDepartment of Electrical Engineering and the Institute of Communications Engineering, National Tsing Hua\nUniversity, Hsinchu, Taiwan\nAbstract\nDeep learning techniques have received much attention in the area of image denoising. However,\nthere are substantial differences in the various types of deep learning methods dealing with image\ndenoising. Speciﬁcally, discriminative learning based on deep learning can ably address the issue\nof Gaussian noise. Optimization models based on deep learning are effective in estimating the\nreal noise. However, there has thus far been little related research to summarize the different\ndeep learning techniques for image denoising. In this paper, we offer a comparative study of\ndeep techniques in image denoising. We ﬁrst classify the deep convolutional neural networks\n(CNNs) for additive white noisy images; the deep CNNs for real noisy images; the deep CNNs for\nblind denoising and the deep CNNs for hybrid noisy images, which represents the combination\nof noisy, blurred and low-resolution images. Then, we analyze the motivations and principles of\nthe different types of deep learning methods. Next, we compare the state-of-the-art methods on\npublic denoising datasets in terms of quantitative and qualitative analysis. Finally, we point out\nsome potential challenges and directions of future research.\nKeywords: Deep learning, Image denoising, Real noisy images, Blind denoising, Hybrid noisy\nimages\n1. Introduction\nDigital image devices have been widely applied in many ﬁelds, including recognition of indi-\nviduals [117, 222, 223], and remote sensing [50]. The captured image is a degraded image from the\nlatent observation, in which the degradation processing is affected by factors such as lighting and\nnoise corruption [265, 254]. Speciﬁcally, the noise is generated in the processes of transmission\nand compression from the unknown latent observation [231]. It is essential to use image denoising\ntechniques to remove the noise and recover the latent observation from the given degraded image.\n∗Corresponding author\nEmail address: yongxu@ymail.com (Yong Xu)\nPreprint submitted to Elsevier\nAugust 4, 2020\narXiv:1912.13171v4  [eess.IV]  3 Aug 2020\nImage denoising techniques have attracted much attention in recent 50 years [19, 233]. At\nthe outset, nonlinear and non-adaptive ﬁlters were used for image applications [87]. Nonlinear\nﬁlters can preserve the edge information to suppress the noise, unlike linear ﬁlters [170]. Adap-\ntive nonlinear ﬁlters depend on local signal-to-noise ratios to derive an appropriate weighting\nfactor for removing noise from an image corrupted by the combination of additive random, signal-\ndependent, impulse noise and additive random noise [19]. Non-adaptive ﬁlters can simultaneously\nuse edge information and signal-to-noise ratio information to estimate the noise [82]. In time,\nmachine learning methods, such as sparse-based methods were successfully applied in image de-\nnoising [45]. A non-locally centralized sparse representation (NCSR) method used nonlocal self-\nsimilarity to optimize the sparse method, and obtained high performance for image denoising [49].\nTo reduce computational costs, a dictionary learning method was used to quickly ﬁlter the noise\n[54]. To recover the detailed information of the latent clean image, priori knowledge (i.e., total\nvariation regularization) can smooth the noisy image in order to deal with the corrupted image\n[163, 178]. More competitive methods for image denoising can be found in [150, 275, 258], in-\ncluding the Markov random ﬁeld (MRF) [184], the weighted nuclear norm minimization (WNNM)\n[69], learned simultaneous sparse coding (LSSC) [150], cascade of shrinkage ﬁelds (CSF) [184],\ntrainable nonlinear reaction diffusion (TNRD) [35] and gradient histogram estimation and preser-\nvation (GHEP) [275].\nAlthough most of the above methods have achieved reasonably good performance in image\ndenoising, they suffered from several drawbacks [146], including the need for optimization meth-\nods for the test phase, manual setting parameters, and a certain model for single denoising tasks.\nRecently, as architectures became more ﬂexible, deep learning techniques gained the ability to\novercome these drawbacks [146].\nThe original deep learning technologies were ﬁrst used in image processing in the 1980s [60]\nand were ﬁrst used in image denoising by Zhou et al. [38, 273]. That is, the proposed denoising\nwork ﬁrst used a neural network with both the known shift-invariant blur function and additive\nnoise to recover the latent clean image. After that, the neural network used weighting factors\nto remove complex noise [38]. To reduce the high computational costs, a feedforward network\nwas proposed to make a tradeoff between denoising efﬁciency and performance [198]. The feed-\nforward network can smooth the given corrupted image by Kuwahara ﬁlters, which were similar\nto convolutions. In addition, this research proved that the mean squared error (MSE) acted as a\nloss function and was not unique to neural networks [48, 68]. Subsequently, more optimization\nalgorithms were used to accelerate the convergence of the trained network and to promote the\ndenoising performance [16, 47, 61]. The combination of maximum entropy and prima-dual La-\ngrangian multipliers to enhance the expressive ability of neural networks proved to be a good tool\nfor image denoising [15]. To further make a tradeoff between fast execution and denoising per-\nformance, greedy algorithms and asynchronous algorithms were applied in neural networks [164].\nAlternatively, designing a novel network architecture proved to be very competitive in eliminat-\ning the noise, through either increasing the depth or changing activation function [190]. Cellular\nneural networks (CENNs) mainly used nodes with templates to obtain the averaging function and\neffectively suppress the noise [190, 161]. Although this proposed method can obtain good denois-\ning results, it requires the parameters of the templates to be set manually. To resolve this problem,\nthe gradient descent was developed [252, 114]. To a certain degree, these deep techniques can im-\n2\nprove denoising performance. However, these networks did not easily allow the addition of new\nplug-in units, which limited their applications in the real world [59].\nBased on the reasons above, convolutional neural networks (CNNs) were proposed [141, 180].\nThe CNN as well as the LeNet had real-world application in handwritten digit recognition [113].\nHowever, due to the following drawbacks, they were not widely applied in computer systems\n[109]. First, deep CNNs can generate vanishing gradients. Second, activation functions such as\nsigmoid [154] and tanh [92] resulted in high computational cost. Third, the hardware platform\ndid not support the complex network. However, that changed in 2012 with AlexNet in that year’s\nImageNet Large-Scale Visual Recognition Challenge (ILSVRC) [109]. After that, deep network\narchitectures (e.g., VGG [189] and GoogLeNet [196]) were widely applied in the ﬁelds of image\n[225, 217, 119], video [138, 248], nature language processing [52] and speech processing [267],\nespecially low-level computer vision [169, 204].\nDeep networks were ﬁrst applied in image denoising in 2015 [129, 234]. The proposed network\nneed not manually set parameters for removing the noise. After then, deep networks were widely\napplied in speech [268], video [247] and image restoration [209, 176]. Mao et al. [152] used\nmultiple convolutions and deconvolutions to suppress the noise and recover the high-resolution\nimage. For addressing multiple low-level tasks via a model, a denoising CNN (DnCNN) [258]\nconsisting of convolutions, batch normalization (BN) [89], rectiﬁed linear unit (ReLU) [159] and\nresidual learning (RL) [75] was proposed to deal with image denoising, super-resolution, and\nJPEG image deblocking. Taking into account the tradeoff between denoising performance and\nspeed, a color non-local network (CNLNet) [116] combined non-local self-similarity (NLSS) and\nCNN to efﬁciently remove color-image noise.\nIn terms of blind denoising, a fast and ﬂexible denoising CNN (FFDNet) [260] presented dif-\nferent noise levels and the noisy image patch as the input of a denoising network to improve\ndenoising speed and process blind denoising. For handling unpaired noisy images, a generative\nadversarial network (GAN) CNN blind denoiser (GCBD) [31] resolved this problem by ﬁrst gener-\nating the ground truth, then inputting the obtained ground truth into the GAN to train the denoiser.\nAlternatively, a convolutional blind denoising network (CBDNet) [71] removed the noise from the\ngiven real noisy image by two sub-networks, one in charge of estimating the noise of the real noisy\nimage, and the other for obtaining the latent clean image. For more complex corrupted images,\na deep plug-and-play super-resolution (DPSR) method [262] was developed to estimate blur ker-\nnel and noise, and recover a high-resolution image. Although other important research has been\nconducted in the ﬁeld of image denoising in recent years, there have been only a few reviews to\nsummarize the deep learning techniques in image denoising [205]. Although Ref. [205] referred to\na good deal work, it lacked more detailed classiﬁcation information about deep learning for image\ndenoising. For example, related work pretaining to unpaired real noisy images was not covered.\nTo this end, we aim to provide an overview of deep learning for image denoising, in terms of both\napplications and analysis. Finally, we discuss the state-of-the-art methods for image denoising,\nincluding how they can be further expanded to respond to the challenges of the future, as well as\npotential research directions. An outline of this survey is shown in Fig. 1.\nThis overview covers more than 200 papers about deep learning for image denoising in recent\nyears. The main contributions in this paper can be summarized as follows.\n1. The overview illustrates the effects of deep learning methods on the ﬁeld of image denoising.\n3\nDeep learning for image \ndenoising\nAdditive white \nnoisy images\nReal noisy images\nBlind denoising\nHybrid noisy \nimages\nThe main frameworks of deep \nlearning in  image denoising\nPerformance comparsion referred \nto deep learning methods on \nimage denoising\nChallenges and potential directions \nOf deep learning for image \ndenoising\nCNN/NN for \nAWNI denoising\nCNN/NN and \nfeature extraction \nmethod for AWNI \ndenoising\nThe combination \nof optimization \nmethod and \nCNN/NN\nWeak edge-\ninformation noisy-\nimage denoising\nNon-linear \nnoisy-image \ndenoising\nHigh dimensional \nnoisy-image \ndenoising\nHigh \ndimensional \nnoisy-images\n High \ncomputational cost \nfor image \ndenoising \nDenoising \nspeed\nDenoising \nperformance\nFigure 1: Outline of the survey. It consists of four parts, including basic frameworks, categories, performance com-\nparison, challenges and potential directions. Speciﬁcally, categories comprise additive white noisy images, real noisy\nimages, blind denoising and hybrid noisy images.\n2. The overview summarizes the solutions of deep learning techniques for different types\nof noise (i.e., additive white noise, blind noise, real noise and hybrid noise) and analyzes the\nmotivations and principles of these methods in image denoising, where blind noise denotes noise\nof unknown types. Finally, we evaluate the denoising performance of these methods in terms of\nquantitative and qualitative analysis.\n3. The overview points out some potential challenges and directions for deep learning in the\nuse of image denoising.\nThe rest of this overview is organized as followed.\nSection 2 discusses the popular deep learning frameworks for image applications. Section\n3 presents the main categories of deep learning in image denoising, as well as a comparison and\nanalysis of these methods. Section 4 offers a performance comparison of these denoising methods.\nSection 5 discusses the remaining challenges and potential research directions. Section 6 offers\nthe authors’ conclusions.\n4\n2. Fundamental frameworks of deep learning methods for image denoising\nThis section offers a discussion of deep learning, including the ideas behind it, the main net-\nwork frameworks (techniques), and the hardware and software, which is the basis for the deep\nlearning techniques for image denoising covered in this survey.\n2.1. Machine learning methods for image denoising\nMachine learning methods consist of supervised, semi-supervised and unsupervised learning\nmethods. Supervised learning methods [133, 228, 120] use the given label to put the obtained\nfeatures closer to the target for learning parameters and training the denoising model. For example,\ntake a given denoising model y = x + µ, where x, y and µ represent the given clean image,\nnoisy image and additive Gaussian noise (AWGN) of standard deviation σ, respectively. From\nthe equation above and Bayesian knowledge, it can be seen that the learning of parameters of the\ndenoising model relies on pair {xk, yk}N\nk=1, where xk and yk denote the kth clean image and noisy\nimage, respectively. Also, N is the number of noisy images. This processing can be expressed as\nxk = f(yk, θ, m), where θ is the parameters and m denotes the given noise level.\nUnsupervised learning methods [115] use given training samples to ﬁnd patterns rather than\nlabel matching and ﬁnish speciﬁc tasks, such as unpairing real low-resolution images [250]. The\nrecently proposed Cycle-in-Cycle GAN (CinCGAN) recovered a high-resolution image by ﬁrst\nestimating the high-resolution image as a label, then exploiting the obtained label and loss function\nto train the super-resolution model.\nSemi-supervised learning methods [40] apply a model from a given data distribution to build\na learner for labeling unlabeled samples. This mechanism is favored by small sample tasks, such\nas medical diagnosis. A semi-supervised learned sinogram restoration network (SLSR-Net) can\nlearn feature distribution from paired sinograms via a supervised network, and then, convert the\nobtained feature distribution to a high-ﬁdelity sinogram from unlabeled low-dose sinograms via\nan unsupervised network [157].\n2.2. Neural networks for image denoising\nNeural networks are the basis of machine learning methods, which in turn are the basis of deep\nlearning techniques [183]. Most neural networks consist of neurons, input X, activation function\nf, weights W = [W 0, W 1, ..., W n−1] and biases b = [b0, b1, ..., bn]. The activation functions such\nas Sigmoid [154, 104] and tanh [92, 55] can convert the linear input into non-linearity through W\nand b as follows.\nf(X; W; b) = f(W TX + b).\n(1)\nNote that if the neural network has multiple layers, it is regarded as multilayer perceptron\n(MLP) [25]. In addition, the middle layers are treated as hidden layers beside the input and output\nlayers. This process can be expressed as\nf(X; W; b) = f(W nf(W n−1...f(W 0X + b0)...bn−1) + bn),\n(2)\nwhere n is the ﬁnal layer of the neural network. To help readers understand the principle of the\nneural network, a visual example is provided in Fig. 2.\n5\n1x\n2x\n3x\n1b\n2b\n3b\n1h\n2h\n3h\n4b\n1o\nInput Layer\nHidden Layer\nOutput Layer\n1\nw\n2\nw\n3\nw\n4\nw\n5\nw\n6\nw\n7\nw\n8\nw\n9\nw\n10\nw\n11\nw\n12\nw\n1b\n2b\n3b\n4b\nFigure 2: Two-layer neural network.\nThe two-layer fully connected neural network includes two layers: a hidden layer and output\nlayer (the input layer is not generally regarded as a layer of a neural network). There are parameters\nto be deﬁned: x1, x2, x3 and o1 represent the inputs and output of this neural network, respectively.\nw1, w2, ..., w11, w12 and b1, b2, b3, b4 are the weights and biases, respectively. For example, the\noutput of one neuron h1 via Eqs. (3) and (4) is obtained as follows:\nf(zh1) = f(w1x1 + w4x2 + w7x3 + b1).\n(3)\no(h1) = f(zh1).\n(4)\nFirst, the output of the network o1 is obtained. Then, the network uses back propagation\n(BP) [81] and loss function to learn parameters. That is, when the loss value is within speciﬁed\nlimitation, the trained model is considered as well-trained. It should be noted that if the number\nof layers of a neural network is more than three, it is also referred to as a deep neural network.\nStacked auto-encoders (SARs) [80] and deep belief networks (DBNs) [17, 79] are typical deep\nneural networks. They used stacked layers in an unsupervised manner to train the models and\nobtain good performance. However, these networks are not simple to implement and require a\ngood deal of manual settings to achieve an optimal model. Due to this, end-to-end connected\nnetworks, especially CNNs, were proposed [241]. CNNs have wide applications in the ﬁeld of\nimage processing, especially image denoising.\n6\n2.3. CNNs for image denoising\nDue to their plug-and-play network architectures, CNNs have achieved great success in image\nprocessing [257, 145, 121]. As a pioneer in CNN technology, LeNet [113] used convolutional\nkernels of different sizes to extract features and obtain good performance in image classiﬁcation.\nHowever, due to the Sigmoid activation function, LeNet had a slow convergence speed, which was\na shortcoming in real-world applications.\nAfter LeNet, the proposed AlexNet [109] was a milestone for deep learning. Its success\nwas due to several reasons. First, the graphics processing unit (GPU) [154] provided strong\ncomputational ability. Second, random clipping (i.e., dropout) solved the overﬁtting problem.\nThird, ReLU [159] improved the speed of stochastic gradient descent (SGD) rather than Sigmoid\n[22]. Fourth, the data augmentation method further addressed the overﬁtting problem. Although\nAlexNet achieved good performance, it required substantial memory usage due to its large con-\nvolutional kernels. That limited its real-world applications, such as in smart cameras. After that,\nduring the period of 2014 to 2016, deeper network architectures with small ﬁlters were preferred to\nimprove the performance and reduce computational costs. Speciﬁcally, VGG [189] stacked more\nconvolutions with small kernel sizes to win the ImageNet LSVR Challenge in 2014. Fig. 3 depicts\nthe network architecture.\n  \nImage \npool,1/2\npool,1/2\npool,1/2\npool,1/2\npool,1/2\n3\n3\n\nConv, 64\n3\n3\n\nConv, 64\n3 3\n\n3\n3\n\n3 3\n\n3\n3\n\n3\n3\n\n3 3\n\n3 3\n\n3\n3\n\n3\n3\n\n3\n3\n\n3\n3\n\n3\n3\n\n3\n3\n\n3\n3\n\nConv, 128\nConv, 128\nConv, 256\nConv, 256\nConv, 256\nConv, 256\nConv, 512\nConv, 512\nConv, 512\nConv, 512\nConv, 512\nConv, 512\nfc 4096\nConv, 512\nConv, 512\nfc 4096\nfc 1000\nFigure 3: Network architecture of VGG.\nWith the success of deeper networks, the research turned to increasing their width. GoogLeNet\n[196] increased the width to improve the performance for image applications. Moreover, GoogLeNet\ntransformed a large convolutional kernel into two smaller convolution kernels in order to reduce\nthe number of parameters and computational cost. GoogLeNet also used the inception module\n[132] as well as Inception 1. Its visual network ﬁgure is shown in Fig. 4.\n        convolutions\nPrevious layer\nFilter concatenation\n1 1\n\n3 3\n\n5 5\n\n1 1\n\n1 1\n\n1 1\n\n3 3\n\n convolutions\n convolutions\n convolutions\n convolutions\n max pooling\n convolutions\nFigure 4: Network architecture of GoogLeNet (Inception 1).\nAlthough VGG and GoogLeNet methods are effective for image applications, they have two\ndrawbacks: if the network is very deep, this may result in vanishing or exploding gradients; and if\n7\nthe network is very wide, it may be subject to the phenomenon of overﬁtting. To overcome these\nproblems, ResNet [75] was proposed in 2016. Each block was given by adding residual learning\noperation in ResNet to improve the performance of image recognition, which leads to ResNet\nwinning the mageNet LSVR in 2015. Fig. 5 depicts the concept of residual learning.\nWeight layer\nInput\nOutput\n...\n...\nWeight layer\n x\n( )\nf x\nRe LU\n( )\nf x\nx\n\nx\nidentity\nResidual Block \nResidual Block \nResidual Block \nRe LU\nFigure 5: Network architecture of ResNet.\nSince 2014, deep networks have been widely used in real-world image applications, such as\nfacial recognition [86] and medical diagnosis [124]. However, in many applications, captured\nimages, such as real noisy images, are not sufﬁcient, and deep CNNs tend to perform poorly in\nimage applications. For this reason, GANs [173] were developed. GANs consisted of two net-\nworks: generative and discriminative networks. The generative network (also referred to as the\ngenerator) is used to generate samples, according to input samples. The discriminative network\n(also called the discriminator) is used to judge the truth of both input samples and generated sam-\nples. The two networks are adversarial. Note that if the discriminator can accurately distinguish\nreal samples and generate samples from generator, the trained model is regarded as ﬁnished. The\nnetwork architecture of the GAN can be seen in Fig. 6. Due to its ability to construct supplemental\ntraining samples, the GAN is very effective for small sample tasks, such as facial recognition [211]\nand complex noisy image denoising [31]. These mentioned CNNs are basic networks for image\ndenoising.\n2.4. Hardware and software used in deep learning\nOne reason for the success of deep learning is the GPU. The GPU uses the CUDA [162],\nOpenCL [193] and cuDNN [37] platforms to strengthen its parallel computing ability, which ex-\nceeds the speed of the CPU by 10 to 30 times. The GPU consists of an NVIDIA consumer line of\ngraphics cards (i.e., GTX 680, GTX 980, GTX 1070, GTX 1070Ti, GTX1080, GTX 1080Ti, RTX\n2070, RTX 2080, RTX 2080Ti, Tesla K40c, Tesla K80, Quadro M6000, Quadro GP100, Quadro\nP6000 and Tesla V100) and AMD (i.e., Radeon Vega 64 and FE) [110].\n8\nReal images\nDiscriminator\nGenerator\nFake images\nNoise\nUpdate\nFigure 6: Network architecture of GAN.\nDeep learning software can provide interfaces to call the GPU. Popular software packages\ninclude:\n(1) Caffe [96] based on C++, provides C++, Python and Matlab interfaces, which can also\nrun on both the CPU and GPU. It is widely used for object detection tasks. However, it requires\ndevelopers to master C++.\n(2) Theano [18] is a compiler of math expressions for dealing with large-scale neural net-\nworks. Theano provides a Python interface and is used in image super-resolution, denoising and\nclassiﬁcation.\n(3) Matconvnet [214] offers the Matlab interface. It is utilized in image classiﬁcation, denois-\ning and super-resolution, and video tracking. However, it requires Matlab mastery.\n(4) TensorFlow [1] is a relatively high-order machine learning library. It is faster than Theano\nfor compilation. TensorFlow offers C++ and Python interfaces and is used in object detection,\nimage classiﬁcation, denoising and super-resolution.\n(5) Keras [41] based on TensorFlow and Theano is implemented in Python and offers a Python\ninterface. It can be used in image classiﬁcation, object detection, image resolution, image denois-\ning and action recognition.\n(6) PyTorch [168] is implemented in Python and offers a Python interface. It is employed\nin image classiﬁcation, object detection, image segmentation, action recognition, image super-\nresolution, image denoising and video tracking.\n3. Deep learning techniques in image denoising\n3.1. Deep learning techniques for additive white noisy-image denoising\nDue to the insufﬁciency of real noisy images, additive white noisy images (AWNIs) are widely\nused to train the denoising model [102]. AWNIs include Gaussian, Poisson, Salt, Pepper and\nmultiplicative noisy images [56]. There are several deep learning techniques for AWNI denoising,\nincluding CNN/NN; the combination of CNN/NN and common feature extraction methods; and\nthe combination of the optimization method and CNN/NN.\n3.1.1. CNN/NN for AWNI denoising\nAutomatic feature extraction methods can play a major role in reducing the computational\ncosts for image applications [240, 179, 143]. For this reason, CNNs have been developed for im-\nage denoising [155, 134]. Zhang et al. [258] proposed a model as well as a DnCNN to deal with\n9\nTable 1: CNN/NN for AWNI denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nZhang et al. (2017) [258]\nCNN\nGaussian image denoising, super-resolution and JPEG deblocking\nCNN with residual learning, and BN for image denoising\nWang et al. (2017) [219]\nCNN\nGaussian image denoising\nCNN with dilated convolutions, and BN for image denoising\nBae et al. (2017) [13]\nCNN\nGaussian image denoisng, super-resolution\nCNN with wavelet domain, and residual learning (RL) for image restoration\nJin et al. (2017) [101]\nCNN\nMedical (X-ray) image restoration\nImproved Unet from iterative shrinkage idea for medical image restoration\nTai et al. (2017) [197]\nCNN\nGaussian image denoisng, super-resolution and JPEG deblocking\nCNN with recursive unit, gate unit for image restoration\nAnwar et al. (2017) [12]\nCNN\nGaussian image denoisng\nCNN with fully connected layer, RL and dilated convolutions for image denoising\nMcCann et al. (2017)] [102]\nCNN\nInverse problems (i.e., denoising, deconvolution, super-resolution)\nCNN for inverse problems\nYe et al. (2018) [242]\nCNN\nInverse problems(i.e., Gaussian image denoising, super-resoluion)\nSignal processing ideas guide CNN for inverse problems\nYuan et al. (2018) [249]\nCNN\nHyper-spectral image denoising\nCNN with multiscale, multilevel features techniques for hyper-spectral image denoising\nJiang et al. (2018) [98]\nCNN\nGaussian image denoising\nMulti-channel CNN for image denoising\nChang et al. (2018) [28]\nCNN\nHyper-spectral image (HSI) denoising, HIS restoration\nCNN consolidated spectral and spatial coins for hyper-spectral image denoising\nJeon et al. (2018) [93]\nCNN\nSpeckle noise reduction from digital holographic images\nSpeckle noise reduction of digital holographic image from Multi-scale CNN\nGholizadeh-Ansari et al. (2018) [63]\nCNN\nLow-dose CT image denoising, X-ray image denosing\nCNN with dilated convolutions for low-dose CT image denoising\nUchida et al. (2018) [213]\nCNN\nNon-blind image denoising\nCNN with residual learning for non-blind image denoising\nXiao et al. (2018) [227]\nCNN\nStripe noise reduction of infrared cloud images\nCNN with skip connection for infrared-cloud-image denoising\nChen et al. (2018) [34]\nCNN\nGaussian image denoisng, blind denoising\nCNN based on RL and perceptual loss for edge enhancement\nYu et al. (2018) [246]\nCNN\nSeismic, random, linear and multiple noise reduction of images\nA survey on deep learning for three applications\nYu et al. (2018) [245]\nCNN\nOptical coherence tomography (OCT) image denoising\nGAN with dense skip connection for optical coherence tomography image denoising\nLi et al. (2018) [118]\nCNN\nGround-roll noise reduction\nAn overview of deep learning techniques on ground-roll noise\nAbbasi et al. (2018) [2]\nCNN\nOCT image denoising\nFully CNN with multiple inputs, and RL for OCT image denoising\nZarshenas et al. (2018) [253]\nCNN\nGaussian noisy image denoising\nDeep CNN with internal and external residual learning for image denoising\nChen et al. (2018) [29]\nCNN\nGaussian noisy image denoising\nCNN with recursive operations for image denoising\nPanda et al. (2018) [165]\nCNN\nGaussian noisy image denoising\nCNN with exponential linear units, and dilated convolutions for image denoising\nSheremet et al. (2018) [186]\nCNN\nImage denoising from info-communication systems\nCNN on image denoising from info-communication systems\nChen et al. (2018) [30]\nCNN\nAerial-image denoising\nCNN with multi-scale technique, and RL for aerial-image denoising\nPardasani et al. (2018) [166]\nCNN\nGaussian, poisson or any additive-white noise reduction\nCNN with BN for image denoising\nCouturier et al. (2018) [42]\nNN\nGaussian and multiplicative speckle noise reduction\nEncoder-decoder network with multiple skip connections for image denoising\nPark et al. (2018) [167]\nCNN\nGaussian noisy image denoising\nCNN with dilated convolutions for image denoising\nPriyanka et al. (2019) [172]\nCNN\nGaussian noisy image denoisng\nCNN with symmetric network architecture for image denoising\nLian et al. (2019) [194]\nCNN\nPoisson-noise-image denoising\nCNN with multi scale, and multiple skip connections for Poisson image denoising\nTripathi et al. (2018) [212]\nCNN\nGaussian noisy image denoising\nGAN for image denoising\nZheng et al. (2019) [271]\nCNN\nGaussian noisy image denoising\nCNN for image denoising\nTian et al. (2019) [204]\nCNN\nGaussian noisy image denoising\nCNN for image denoising\nRemez et al. (2018) [175]\nCNN\nGaussian and Poisson image denoising\nCNN for image denoising\nTian et al. (2020) [207]\nCNN\nGaussian image denoising and real noisy image denoising\nCNN with BRN, RL and dilated convolutions for image denosing\nTian et al. (2020) [206]\nCNN\nGaussian image denoising, blind denoising and real noisy image denoising\nCNN with attention mechanism and sparse method for image denoising\nTian et al. (2020) [208]\nCNN\nGaussian image denoising, blind denoising and real noisy image denoising\nTwo CNNs with sparse method for image denoising\nmultiple low-level vision tasks, i.e., image denoising, super-resolution and deblocking through\nCNN, batch normalization [89] and residual learning techniques [75]. Wang et al. [219], Bae\net al. [13] and Jifara et al. [101] also presented a residual learning into deeper CNN for image\ndenoising. However, the deeper CNN technique relied on a deeper layer rather than a shallow\nlayer, which resulted in a long-term dependency problem. Several signal-base methods were pro-\nposed to resolve this problem. Tai et al. [197] exploited recursive and gate units to adaptively\nmine more accurate features and recover clean images. Inspired by a low-rank Hankel matrix in\nlow-level vision, Ye et al. [242] provided convolution frames to explain the connection between\nsignal processing and deep learning by convolving local and nonlocal bases. For solving insufﬁ-\ncient noisy images (i.e., hyperspectral and medical images), several recent works have attempted\nto extract more useful information through the use of improved CNNs [28, 77, 245, 139]. For\nexample, Yuan et al. [249] combined a deep CNN, residual learning and multiscale knowledge\nto remove the noise from hyperspectral-noisy images. However, these proposed CNNs led to the\nlikelihood of increased computational costs and memory consumption, which was not conducive\nfor real-world applications. To address this phenomenon, Gholizadeh et al. [63] utilized dilated\nconvolutions [62] to enlarge the receptive ﬁeld and reduce the depth of network without incurring\nextra costs for CT image denoising. Lian et al. [194] proposed a residual network via multi-scale\ncross-path concatenation to suppress the noise. Most of the above methods relied on improved\nCNNs to deal with the noise. Therefore, designing network architectures is important for image\ndenoising [167, 118].\n10\nChanging network architectures involves the following methods [246, 149, 177]: fusing fea-\ntures from multiple inputs of a CNN; changing the loss function; increasing depth or width of the\nCNN; adding some auxiliary plug-ins into CNNs; and introducing skip connections or cascade\noperations into CNNs. Speciﬁcally, the ﬁrst method includes three types: different parts of one\nsample as multiple inputs from different networks [2]; different perspectives for the one sample\nas input, such as multiple scales [93, 30]; and different channels of a CNN as input [98]. The\nsecond method involves the design of different loss functions according to the characteristics of\nnature images to extract more robust features [10]. For example, Chen et al. [34] jointed Eu-\nclidean and perceptual loss functions to mine more edge information for image denoising. The\nthird method enlarged the receptive ﬁeld size to improve denoising performance via increasing\nthe depth or width of the network [213, 253, 186]. The fourth method applied plug-ins, such as\nactivation function, dilated convolution, fully connected layer and pooling operations, to enhance\nthe expressive ability of the CNN [165, 172, 166]. The ﬁfth method utilized skip connections\n[227, 29, 42, 12] or cascade operations [194, 36] to provide complementary information for the\ndeep layer in a CNN. Table 1 provides an overview of CNNs for AWNI denoising.\n3.1.2. CNN/NN and common feature extraction methods for AWNI denoising\nFeature extraction is used to represent the entire image in image processing, and it is important\nfor machine learning [130, 144, 238]. However, because deep learning techniques are black box\ntechniques, they do not allow the choice of choose features, and therefore cannot guarantee that\nthe obtained features are the most robust [187, 221]. Motivated by problem, researches embedded\ncommon feature extraction methods into CNNs for the purpose of image denoising. They did this\nfor ﬁve reasons: weak edge-information noisy images, non-linear noisy images, high dimensional\nnoisy images and non-salient noisy images, and high computational costs.\nFor weak edge-information noisy images, CNN with transformation domain methods were\nproposed by Guan et al. [70], Li et al. [122], Liu et al. [137], Latif et al. [111] and Yang et al.\n[237]. However, they were not effective in removing the noise. Speciﬁcally, in [137], the proposed\nsolution used the wavelet method and U-net to eliminate the gridding effect of dilated convolutions\non enlarging the receptive ﬁeld for image restoration.\nFor non-linear noisy images, CNNs with kernel methods proved useful [14, 235]. These meth-\nods mostly consisted of three steps [158]. The ﬁrst step used CNN to extract features. The second\nstep utilized the kernel method to convert obtained non-linear features into linearity. The third step\nexploited the residual learning to construct the latent clean image.\nFor high dimensional noisy images, the combination of CNN and the dimensional reduction\nmethod was proposed [229, 72]. For example, Khaw et al. [106] used a CNN with principal\ncomponent analysis (PCA) for image denoising. This consisted of three steps. The ﬁrst step\nused convolution operations to extract features. The second step utilized the PCA to reduce the\ndimension of the obtained features. The third step employed convolutions to deal with the obtained\nfeatures from the PCA and to reconstruct a clean image.\nFor non-salient noisy images, signal processing can guide the CNN in extracting salient fea-\ntures [94, 103, 174, 2]. Speciﬁcally, skip connection is a typical operation of signal processing\n[103].\n11\nTable 2: CNN/NN and common feature extraction methods for AWNI denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nBako et al. (2017) [194]\nCNN\nMonte Carlo-rendered images denoising\nCNN with kernel method for estimating noise piexls\nAhn et al. (2017) [7]\nCNN\nGaussian image denoising\nCNN with NSS for image denoising\nKhaw et al. (2017) [106]\nCNN\nImpulse noise reduction\nCNN with PCA for image denoising\nVogel et al. (2017) [215]\nCNN\nGaussian image denoising\nU-net with multi scales technique for image denoising\nMildenhall et al. (2018) [158]\nNN\nLow-light synthetic noisy image denoising, real noise\nEncoder-decoder with multi scales, and kernel method for image denoising\nLiu et al. (2018) [137]\nCNN\nGaussian image denoisng, super-resolution and JPEG deblocking\nU-net with wavelet for image restoration\nYang et al. (2018) [237]\nCNN\nGaussian image denoisng\nCNN with BM3D for image denoising\nGuo et al. (2018) [72]\nCNN\nImage blurring and denoising\nCNN with RL, and sparse method for image denoising\nJia et al. (2018) [94]\nCNN\nGaussian image denoisng\nCNN with multi scales, and dense RL operations for image denoising\nRan et al. (2018) [174]\nCNN\nOCT image denoising, OCT image super-resolution\nCNN with multi views for image restoration\nLi et al. (2018) [140]\nCNN\nMedical image denoising, stomach pathological image denoising\nCNN consolidated wavelet for medical image denoising\nAhn et al. (2018) [8]\nCNN\nGaussian image denoisng\nCNN with NSS for image denoising\nXie et al. (2018) [229]\nCNN\nHyper-spectral image denoising\nCNN with RL, and PCA for low-dose CT image denoising\nKadimesetty et al. (2019) [103]\nCNN\nLow-Dose computed tomography (CT) image denoising\nCNN with RL, batch normalization (BN) for medical image denoising\nGuan et al. (2019) [70]\nCNN\nStripe noise reduction\nCNN with wavelet-image denoising\nAbbasi et al. (2019) [2]\nNN\n3D magnetic resonance image denoising, medical image denoising\nGAN based on encoder-decoder and RL for medical denoising\nXu et al. (2019) [235]\nCNN\nSynthetic and real noisy and video denoising\nCNN based on deformable kernel for image and video denoising\nFor tasks involving high computational costs, a CNN with relations nature of pixels from an\nimage was very effective in decreasing complexity [2, 8, 7]. For example, Ahn et al. [7] used a\nCNN with non-local self-similarity (NSS) to ﬁlter the noise, where similar characteristics of the\ngiven noisy image can accelerate the speed of extraction feature and reduce computational costs.\nMore detailed information on these methods mentioned can be found in Table 2.\n3.1.3. Combination of optimization method and CNN/NN for AWNI denoising\nMachine learning uses optimization techniques [85, 126] and discriminative learning methods\n[125, 135] to deal with image applications. Although optimization methods have good perfor-\nmance on different low-level vision tasks, these methods need manual setting parameters, which\nare time-consuming [209, 210]. The discriminative learning methods are fast in image restoration.\nHowever, they are not ﬂexible for low-level vision tasks. To achieve a tradeoff between efﬁciency\nand ﬂexibility, a discriminative learning optimization-based method [156, 20] was presented for\nimage applications, such as image denoising. CNNs with prior knowledge via regular term of\nloss function is a common method in image denoising [83], which can be divided two categories:\nimprovement of denoising speed and improvement of denoising performance.\nFor improving denoising speed, an optimization method using a CNN was an effective tool for\nrapidly ﬁnding the optimal solution in image denoising [39, 58]. For example, a GAN with the\nmaximum a posteriori (MAP) method was used to estimate the noise and deal with other tasks,\nsuch as image inpainting and super-resolution [243]. An experience-based greed algorithm and\ntransfer learning strategies with a CNN can accelerate a genetic algorithm to obtain a clean image\n[136]. Noisy image and noise level mapping were inputs of the CNN, which had faster execution\nin predicting the noise [202].\n12\nTable 3: The combination of the optimization method and CNN/NN for AWNI denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nHong et al. (2018) [83]\nCNN\nGaussian image denoising\nAuto-Encoder with BN, and ReLU for image denoising\nCho et al. (2018) [39]\nCNN\nGaussian image denoising\nCNN with separable convolution, and gradient prior for image denoising\nFu et al. (2018) [58]\nCNN\nSalt and pepper noise removal\nCNN with non-local switching ﬁlter for salt and pepper noise\nYeh et al. (2018) [243]\nCNN\nImage denoising super-resolution and inpainting\nGAN with MAP for image restoration\nLiu et al. (2018) [136]\nCNN\nMedical image denoising, computed tomography perfusion for image denoising\nCNN with genetic algorithm for medical image denoising\nTassano et al. (2019) [202]\nCNN\nGaussian image denoisng\nCNN with noise level, upscaling, downscaling operation for image denoising\nHeckel et al. (2018) [76]\nCNN\nImage denoisng\nCNN with deep prior for image denoising\nJiao et al. (2017) [100]\nCNN\nGaussian image denoisng, image inpainting\nCNN with inference, residual operation for image restoration\nWang et al. (2017) [218]\nCNN\nImage denoising\nCNN with total variation for image denoising\nLi et al. (2019) [128]\nCNN\nImage painting\nCNN with split Bregman iteration algorithm for image painting\nSun et al. (2018) [195]\nCNN\nGaussian image denoisng\nGAN with skip-connections, and ResNet blocks for image denoising\nZhi et al. (2018) [272]\nCNN\nGaussian image denoising\nGAN with multiscale for image denoising\nDu et al. (2018) [51]\nCNN\nGaussian image denoising\nCNN with wavelet for medcial image restoration\nLiu et al. (2019) [140]\nCNN\nGaussian image denoising, real noisy image denoising, rain removal\nDual CNN with residual operations for image restoration\nKhan et al. (2019) [105]\nCNN\nSymbol denoising\nCNN with quadrature amplitude modulation for symbol denoising\nZhang et al. (2019) [266]\nCNN\nImage Possian denoising\nCNN with variance-stabilizing transformation for poisson denoising\nCruz et al. (2018) [43]\nCNN\nGaussian image denoising\nCNN with nonlocal ﬁlter for image denoising\nJia et al. (2019) [95]\nCNN\nGaussian image denoising\nCNN based on a fractional-order differential equation for image denoising\nFor improving denoising performance, a CNN combined optimization method was used to\nmake a noisy image smooth [76, 65, 100]. A CNN with total variation denoising reduced the\neffect of noise pixels [218]. Combining the Split Bregman iteration algorithm and CNN [128]\ncan enhance pixels through image depth to obtain a latent clean image. A dual-stage CNN with\nfeature matching can better recover the detailed information of the clean image, especially noisy\nimages [195]. The GAN with the nearest neighbor algorithm was effective in ﬁltering out noisy\nimages from clean images [272]. A combined CNN used wavefront coding to enhance the pixels\nof latent clean images via the transform domain [51]. Other effective denoising methods are shown\nin [140, 105, 66]. Table 3 shows detailed information about the combination of the optimization\nmethods and CNN/NN in AWNI denoising.\n3.2. Deep learning techniques for real noisy image denoising\nThere are mainly two types of deep learning techniques for image denoising: single end-to-end\nCNN and the combination of prior knowledge and CNN.\nFor the ﬁrst method, changing the network architecture is an effective way to remove the noise\nfrom the given real corrupted image. Multiscale knowledge is effective for image denoising. For\nexample, a CNN consisting of convolution, ReLU and RL employed different phase features to en-\nhance the expressive ability of the low-light image denoising model [201]. To overcome the blurry\nand false image artifacts, a dual U-Net with skip connection was proposed for computed tomogra-\nphy (CT) image reconstruction [73]. To address the problem of resource-constraints problem, Tian\net al. [207] used a dual CNN with batch renormalization [88], RL and dilated convolutions to deal\nwith real noisy images. Based on nature of light images, two CNNs utilized anisotropic parallax\nanalysis to generate structural parallax information for real noisy images [32]. Using a CNN to\nresolve remote sensing [97] and medical images [107] under low-light conditions proved effective\n[99]. To extract more detailed information, recurrent connections were used to enhance the repre-\nsentative ability to deal with corrupted images in the real world [64, 269]. To deal with unknown\nreal noisy images, a residual structure was utilized to facilitate low-frequency features, and then,\nan attention mechanism [206] could be applied to extract more potential features from channels\n[11]. To produce the noisy image, a technique used imitating cameral pipelines to construct the\ndegradation model in order to ﬁlter the real noisy images [91]. To tackle the problem of unpairing\nnoisy images, an unsupervised learning method embedded into the CNN proved effective in image\n13\ndenoising [44]. The self-consistent GAN [236] ﬁrst used a CNN to estimate the noise of the given\nnoisy image as a label, and then, applied another CNN and the obtained label to remove the noise\nfor other noisy images. This concept has also been extended to general CNNs. The Noise2Inverse\nmethod used a CNN to predict the value of a noisy pixel, according to its surrounding noisy pixels\n[78]. The attention mechanism merged into a 3D self-supervised network can improve the efﬁ-\nciency of removing the noise from medical noisy images [123]. More detailed information about\nthe above research is shown in Table 4.\nTable 4: CNNs for real noisy image denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nTao et al. (2019) [201]\nCNN\nReal noisy image denoising, low-light image enhancement\nCNN with ReLU, and RL for real noisy image denoising\nChen et al. (2018) [31]\nCNN\nReal noisy image denoising, blind denoising\nGAN for real noisy image denoising\nHan et al. (2018) [73]\nCNN\nCT image reconstruction\nU-Net with skip connection for CT image reconstruction\nChen et al. (2018) [32]\nCNN\nReal noisy image denoising\nCNNs with anisotropic parallax analysis for real noisy image denoising\nJian et al. (2018) [97]\nCNN\nLow-light remote sense image denoising\nCNN for image denoising\nKhoroushadi et al. (2019) [107]\nCNN\nMedical image denoising, CT image denoising\nCNN for image denoising\nJiang et al. (2018) [99]\nCNN\nLow-light image enhancement\nCNN with symmetric pathways for low-light image enhancement\nGodard et al. (2018) [64]\nCNN\nReal noisy image denoising\nCNN with recurrent connections for real noisy image denoising\nZhao et al. (2019) [269]\nCNN\nReal noisy image denoising\nCNN with recurrent conncetions for real noisy image denoising\nAnwar et al. (2019) [11]\nCNN\nReal noisy image denoising\nCNN with RL, attention mechanism for real noisy image denoising\nJaroensri et al. (2019) [220]\nCNN\nReal noisy image denoising\nCNN for real noisy image denoising\nGreen et al. (2018) [67]\nCNN\nCT image denoising, real noisy image denoising\nCNN for real noisy image denoising\nBrooks et al. (2019) [24]\nCNN\nReal noisy image denoising\nCNN with image processing pipeline for real noisy image denoising\nTian et al. (2020) [207]\nCNN\nGaussian image denoising and real noisy image denoising\nCNN with BRN, RL and dilated convolutions for image denosing\nTian et al. (2020) [206]\nCNN\nGaussian image denoising, blind denoising and real noisy image denoising\nCNN with attention mechanism and sparse method for image denoising\nTian et al. (2020) [208]\nCNN\nGaussian image denoising, blind denoising and real noisy image denoising\nTwo CNNs with sparse method for image denoising\nCui et al. (2019) [44]\nCNN\nPositron emission tomography image denoising, real noisy image denoising\nUnsupervised CNN for unpair real noisy image denoising\nYan et al. (2019) [236]\nCNN\nReal noisy image denoising\nSelf-supervised GAN for unpair real noisy image denoising\nBroaddus et al. (2020) [23]\nCNN\nBlind denoising and real noisy image denoising\nSelf-supervised CNN for unpair ﬂuorescence microscopy image denoising\nLi et al. (2020) [123]\nCNN\nCT noisy image denoising\nSelf-supervised CNN with attention mechanism for unpair CT image denoising\nHendriksen et al. (2020) [78]\nCNN\nCT noisy image denoising\nSelf-supervised CNN for unpair CT image denoising\nWu et al. (2020) [224]\nCNN\nCT noisy image denoising\nSelf-supervised CNN for unpair dynamic CT image denoising\nThe method combining CNN and prior knowledge can better deal with both speed and complex\nnoise task in real noisy images. Zhang et al. [259] proposed using half quadratic splitting (HQS)\nand CNN to estimate the noise from the given real noisy image. Guo et al. [71] proposed a three-\nphase denoising method. The ﬁrst phase used a Gaussian noise and in-camera processing pipeline\nto synthesize noisy images. The synthetic and real noisy images were merged to better represent\nreal noisy images. The second phase used a sub-network with asymmetric and total variation\nlosses to estimate the noise of real noisy image. The third phase exploited the original noisy image\nand estimated noise to recover the latent clean image. To address the problem of unpaired noisy\nimages, the combination of CNN and prior knowledge in a semi-supervised way was developed\n[157]. A hierarchical deep GAN (HD-GAN) ﬁrst used a cluster algorithm to classify multiple\ncategories of each patient’s CT, then built a dataset by collecting the images in the same categories\nfrom different patients. Finally, the GAN was used to deal with the obtained dataset for image\ndenoising and classiﬁcation [40]. A similar method performed well in 3D mapping [185].\nA CNN with channel prior knowledge was effective for low-light image enhancement [200].\nTable 5 shows the detailed information about the above research.\n14\nTable 5: CNNs for real noisy image denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nZhang et al. (2017) [259]\nCNN\nReal-noisy image denoising\nCNN with HQS for real noisy image\nGuo et al. (2019) [71]\nCNN\nReal-noisy image denoising\nCNN and cameral processing pipeline for real noisy image\nTao et al. (2019) [200]\nCNN\nLow-light image enhancement\nCNN with channel prior for low-light image enhancement\nMa et al. (2018) [148]\nCNN\nTomography image denoising\nGAN with edge-prior for CT image denoising\nYue et al. (2018) [251]\nCNN\nReal-noisy image denoising, blind denoising\nCNN with variational inference for blind denoising and real-noisy image denoisng\nSong et al. (2019) [192]\nCNN\nReal noisy image denoising\nCNN with dynamic residual dense block for real noisy image denoising\nLin et al. (2019) [131]\nCNN\nReal noisy image denoising\nGAN with attentive mechanism and noise domain for real noisy image denoising\nMeng et al. (2020) [157]\nCNN\nReal noisy image denoising\nCNN with semi-supervised learning for medical noisy image denoising\nShantia et al. (2015) [185]\nCNN\nReal noisy image denoising\nCNN with semi-supervised learning for 3D map\nChoi et al. (2019) [40]\nCNN\nReal noisy image denoising\nCNN with semi-supervised learning for medical noisy image denoising\n3.3. Deep learning techniques for blind denoising\nIn the real world, images are easily corrupted and noise is complex. Therefore, blind denoising\ntechniques are important [142]. An FFDNet [260] used noise level and noise as the input of CNN\nto train a denoiser for unknown noisy images. Subsequently, several methods were proposed to\nsolve the problem of blind denoising. An image device mechanism proposed by Kenzo et al. [90]\nutilized soft shrinkage to adjust the noise level for blind denoising. For unpaired noisy images,\nusing CNNs to estimate noise proved effective [191]. Yang et al. [239] used known noise levels to\ntrain a denoiser, then utilized this denoiser to estimate the level of noise. To resolve the problem of\nrandom noise attenuation, a CNN with RL was used to ﬁlter complex noise [256, 188]. Changing\nthe network architecture can improve the denoising performance for blind denoising. Majumdar et\nal. [151] proposed the use of an auto-encoder to tackle unknown noise. For mixed noise, cascaded\nCNNs were effective in removing the additive white Gaussian noise (AWGN) and impulse noise\n[4]. Table 6 displays more information about these denoising methods.\nTable 6: Deep learning techniques for blind denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nZhang et al. (2018) [260]\nCNN\nBlind denoising\nCNN with varying noise level for blind denoising\nKenzo et al. (2018) [90]\nCNN\nBlind denoising\nCNN with soft shrinkage for blind denoising\nSoltanayev et al. (2018) [191]\nCNN\nBlind denoising\nCNN for unpaired noisy images\nYang et al. (2017) [239]\nCNN\nBlind denoising\nCNNs with RL for blind denoising\nZhang et al. (2018) [256]\nCNN\nBlind denoising, random noise\nCNN with RL for blind denoising\nSi et al. (2018) [188]\nCNN\nBlind denoising, random noise\nCNN for image denoising\nMajumdar et al. (2018) [99]\nNN\nBlind denoising\nAuto-encoder for blind denoising\nAbiko et al. (2019) [64]\nCNN\nBlind denoising, complex noisy image denoising\ncascaded CNNs for blind denoising\nCha et al. (2019) [239]\nCNN\nBlind denoising\nGAN for blind image denoising\nTian et al. (2020) [206]\nCNN\nGaussian image denoising, blind denoising and real noisy image denoising\nCNN with attention mechanism and sparse method for image denoising\n3.4. Deep learning techniques for hybrid noisy image denoising\nIn the real world, captured images are affected by complex environments. Motivated by that,\nseveral researchers proposed hybrid-noisy-image denoising techniques. Li et al. [127] proposed\nthe combination of CNN and warped guidance to resolve the questions of noise, blur and JPEG\ncompression. Zhang et al. [261] used a model to deal with multiple degradations, such as noise,\nblur kernel and low-resolution image. To enhance the raw sensor data, Kokkinos et al. [108]\npresented a residual CNN with an iterative algorithm for image demosaicing and denoising. To\n15\nhandle arbitrary blur kernels, Zhang et al. [262] proposed to use cascaded deblurring and single-\nimage super-resolution (SISR) networks to recover plug-and-play super-resolution images. These\nhybrid noisy image denoising methods are presented in Table 7.\nTable 7: Deep learning techniques for hybrid noisy image denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nLi et al. (2018) [127]\nCNN\nNoise, blur kernel, JPEG compression\nThe combination of CNN and warped guidance for multiple degradations\nZhang et al. (2018) [261]\nCNN\nNoise, blur kernel, low-resolution image\nCNN for multiple degradations\nKokkinos et al. (2019) [108]\nCNN\nImage demosaicking and denoising\nResidual CNN with iterative algorithm for image demosaicking and denoising\nIt is noted that an image carries ﬁnite information, which is not beneﬁcial in real-world ap-\nplications. To address this problem, burst techniques were developed [226]. However, the burst\nimage suffered from the effects of noise and camera shake, which increased the difﬁculty of imple-\nmenting the actual task. Recently, there has been much interest in deep learning technologies for\nburst image denoising, where the noise is removed frame by frame [9]. Recurrent fully convolu-\ntional deep neural networks can ﬁlter the noise for all frames in a sequence of arbitrary length [64].\nThe combination of CNN and the kernel method can boost the denoising performance for burst\nnoisy images [153, 158]. In terms of complex background noisy images, an attention mechanism\ncombined the kernel and CNN to enhance the effect of key features for burst image denoising,\nwhich can accelerate the training speed [255]. For low-light conditions, using a CNN to map\na given burst noisy image to sRGB outputs can obtain a multi-frame denoising image sequence\n[269]. To reduce network complexity, a CNN with residual learning directly trained a denoising\nmodel rather than an explicit aligning procedure [199]. These burst denoising methods are listed\nin Table 8.\nTable 8: Deep learning techniques for burst denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nXia et al. (2019) [226]\nCNN\nBurst denoising\nCNN for burst denoising\nAittala et al. (2018) [9]\nCNN\nBurst denoising\nCNN for burst denoising\nGodard et al. (2018) [64]\nCNN\nBurst denoising\nCNN for burst denoising\nMarin et al. (2019) [153]\nCNN\nBurst denoising\nCNN with kernel idea for burst denoising\nMildenhall et al. (2018) [158]\nCNN\nBurst denoising\nCNN with kernel idea for burst denoising\nZhang et al. (2020) [255]\nCNN\nBurst denoising\nCNN with kernel idea and attention idea for burst denoising\nZhao et al. (2019) [269]\nCNN\nBurst denoising\nCNN for burst denoising\nTan et al. (2019) [199]\nCNN\nBurst denoising\nCNN without explicit aligning procedure for burst denoising\nSimilar to burst images, video detection is decomposed into each frame. Therefore, deep\nlearning techniques for additive white noisy-image denoising, real noisy image denoising, blind\ndenoising , hybrid noisy image denoising are also suitable to video denoising [182, 216]. A recur-\nrent neural network [33] utilized an end-to-end CNN to remove the noise from corrupted video. To\nimprove video denoising, reducing the video redundancy is an effective method. A non-local patch\nidea fused CNN can efﬁciently suppress the noise for video and image denoising [46]. A CNN\ncombined temporal information to make a tradeoff between performance and training efﬁciency\nin video denoising [203]. For blind video denoising, a two-stage CNN proved to be a good choice\n[53]. The ﬁrst phase trained a video denoising model by ﬁne-tuning a pre-trained AWGN denois-\ning network [53]. The second phase obtained latent clean video by the obtained video denoising\nmodel. These video denoising methods are described in Table 9.\n16\nTable 9: Deep learning techniques for video denoising.\nReferences\nMethods\nApplications\nKey words (remarks)\nSadda et al. (2018) [182]\nCNN\nMedical noisy video\nCNN for video denoising\nWang et al. (2020) [216]\nCNN\nAdditive white Gaussian and salt-and-pepper noisy video\nCNN for video denoising\nChen et al. (2016) [33]\nCNN\nAdditive white Poisson-Gaussian noisy video\nCNN for video denoising\nDavy et al. (2018) [46]\nCNN\nAdditive white Gaussian noisy video\nCNN with non-local idea for video denoising\nTassano et al. (2019) [203]\nCNN\nAdditive white Gaussian noisy video\nCNN with temporal information for video denoising\nEhret et al. (2019) [53]\nCNN\nblind video denoising\nCNN with pre-trained technology for blind video denoising\n4. Experimental results\n4.1. Datasets\n4.1.1. Training datasets\nThe training datasets are divided into two categories: gray-noisy and color-noisy images.\nGary-noisy image datasets can be used to train Gaussian denoisers and blind denoisers. They\nincluded the BSD400 dataset [21] and Waterloo Exploration Database [147]. The BSD400 dataset\nwas composed of 400 images in .png format, and was cropped into a size of 180×180 for training\na denoising model. The Waterloo Exploration Database consisted of 4,744 nature images with\na .png format. Color-noisy images included the BSD432 [258], Waterloo Exploration Database\nand polyU-Real-World-Noisy-Images datasets [230]. Speciﬁcally, the polyU-Real-World-Noisy-\nImages consisted of 100 real noisy images with sizes of 2, 784 × 1, 856 obtained by ﬁve cameras:\na Nikon D800, Canon 5D Mark II, Sony A7 II, Canon 80D and Canon 600D.\n4.1.2. Test datasets\nThe test datasets included gray-noisy and color-noisy image datasets. The gray-noisy image\ndataset was composed of Set12 and BSD68 [258]. The Set12 contained 12 scenes. The BSD68\ncontained 68 nature images. They were used to test the Gaussian denoiser and a denoiser of blind\nnoise. The color-noisy image dataset included CBSD68, Kodak24 [57], McMaster [263], cc [160],\nDND [171], NC12 [112], SIDD [3] and Nam [160]. The Kodak24 and McMaster contained 24\nand 18 color noisy images, respectively. The cc contained 15 real noisy images of different ISO,\ni.e., 1,600, 3,200 and 6,400. The DND contained 50 real noisy images and the clean images were\ncaptured by low-ISO images. The NC12 contained 12 noisy images and did not have ground-truth\nclean images. The SIDD contained real noisy images from smart phones, and consisted of 320\nimage pairs of noisy and ground-truth images. The Nam included 11 scenes, which were saved in\nJPGE format.\n4.2. Experimental results\nTo verify the denoising performance of some methods mentaioned in Section 3, we conducted\nsome experiments on the Set12, BSD68, CBSD68, Kodak24, McMaster, DND, SIDD, Nam, cc\nand NC12 datasets in terms of quantitative and qualitative evaluations. The quantitative evaluation\nmainly used peak-signal-to-noise-ratio (PSNR) [84] values of different denoisers to test the de-\nnoising effects. Additionally, we used the runtime of denoising of an image to support the PSNR\nfor quantitative evaluation. The qualitative evaluation used visual ﬁgures to show the recovered\nclean images.\n17\nTable 10: PSNR (dB) of different methods on the BSD68 for different noise levels (i.e., 15, 25 and 50).\nMethods\n15\n25\n50\nBM3D [45]\n31.07\n28.57\n25.62\nWNNM [69]\n31.37\n28.83\n25.87\nEPLL [274]\n31.21\n28.68\n25.67\nMLP [25]\n-\n28.96\n26.03\nCSF [184]\n31.24\n28.74\n-\nTNRD [35]\n31.42\n28.92\n25.97\nECNDNet [204]\n31.71\n29.22\n26.23\nRED [152]\n-\n-\n26.35\nDnCNN [258]\n31.72\n29.23\n26.23\nDDRN [219]\n31.68\n29.18\n26.21\nPHGMS [13]\n31.86\n-\n26.36\nMemNet [197]\n-\n-\n26.35\nEEDN [34]\n31.58\n28.97\n26.03\nNBCNN [213]\n31.57\n29.11\n26.16\nNNC [253]\n31.49\n28.88\n25.25\nELDRN [165]\n32.11\n29.68\n26.76\nPSN-K [10]\n31.70\n29.27\n26.32\nPSN-U [10]\n31.60\n29.17\n26.30\nDDFN [42]\n31.66\n29.16\n26.19\nCIMM [12]\n31.81\n29.34\n26.40\nDWDN [122]\n31.78\n29.36\n-\nMWCNN [137]\n31.86\n29.41\n26.53\nBM3D-Net [237]\n31.42\n28.83\n25.73\nMPFE-CNN [103]\n31.79\n29.31\n26.34\nIRCNN [259]\n31.63\n29.15\n26.19\nFFDNet [260]\n31.62\n29.19\n26.30\nBRDNet [207]\n31.79\n29.29\n26.36\nETN [218]\n31.82\n29.34\n26.32\nADNet [206]\n31.74\n29.25\n26.29\nNN3D [43]\n-\n-\n26.42\nFOCNet [95]\n31.83\n29.38\n26.50\nDudeNet [208]\n31.78\n29.29\n26.31\nTable 11: FSIM of different methods on the BSD68 for different noise levels (i.e., 15, 25 and 50).\nMethods\n15\n25\n50\nBM3D [45]\n0.9894\n0.9811\n0.9629\nMLP [25]\n0.9671\n0.9821\n0.9344\nTNRD [35]\n0.9697\n0.9820\n0.9291\nECNDNet [204]\n0.9911\n0.9837\n0.9686\nIRCNN [259]\n0.9905\n0.9835\n0.9700\nBRDNet [207]\n0.9913\n0.9841\n0.9687\nADNet [206]\n0.9912\n0.9837\n0.9673\n4.2.1. Deep learning techniques for additive white noisy-image denoising\nComparisons of denoising methods should take into consideration additive white noise, includ-\ning Gaussian, Poisson, low-light noise, and salt and pepper noise, all of which have signiﬁcantly\ndifferent noise levels. Furthermore, many of the methods use different tools, which can have a sig-\nniﬁcant inﬂuence on denoising results. For these reasons, we chose typical Gaussian noise to test\nthe denoising performance of the various methods. In addition, most of the denoising methods use\nPSNR as a quantitative index. Therefore, we used the BSD68, Set12, CBSD68, Kodak24 and Mc-\nMaster datasets to test the denoising performance of deep learning techniques for additive white\nnoisy-image denoising. Table 10 shows the PSNR values of different networks with different noise\nlevels for gray additive white noisy image denoising. To understand the denoising performance\n18\nof different methods, we used a feature similarity index (FSIM) [264] as a visual quality metric\nto conduct experiments on BSD68 for different noise levels (i.e., 15, 25 and 50), as shown in Ta-\nble 11. To test the ability of dealing with single gray additive white noisy images from different\nnetworks, Set12 was used to conduct experiments, as shown in Table 12. Table 13 displays the\ndenoising performance of different methods for color additive white noisy image denoising. Table\n14 presents the efﬁciency of different methods for image denoising. For qualitative analysis, we\nmagniﬁed one area of the latent clean image from different methods. As shown in Figs. 7-10, the\nobserved area is clearer, and the corresponding method has better denoising performance.\n4.2.2. Deep learning techniques for real-noisy image denoising\nFor testing the denoising performance of deep learning techniques for real-noisy images, the\npublic datasets, such as DND, SIDD, Nam and CC, were chosen to design the experiments. We\nchose not to use the NC12 dataset because the ground-truth clean images from NC12 were un-\navailable. Also, to help readers better understand these methods, we added several traditional\ndenoising methods, such as BM3D, as comparative methods. From Tables 15 and 16, we can see\nthat the DRDN obtained the best results on the DND and SSID in real-noisy image denoising,\nrespectively. For compressed noisy images, the AGAN obtained excellent performance, as shown\nin Table 17. For real noisy images of different ISO values, the SDNet and BRDNet achieved the\nbest and second-best denoising performance, respectively, as described in Table 18.\n4.2.3. Deep learning techniques for blind denoising\nIt is known that noise is complex in the real world, and not subject to rules. This is why blind\ndenoising techniques, especially deep learning techniques, have been developed. Comparing the\ndenoising performance of different deep learning techniques is very useful. The state-of-the-art\ndenoising methods such as DnCNN, FFDNet, ADNet, SCNN and G2G1 on the BSD68 and Set12\nwere chosen to design the experiments. FFDNet and ADNet are superior to other methods in blind\ndenoising, as shown in Tables 19 and 20, respectively.\n4.2.4. Deep learning techniques for hybrid-noisy-image denoising\nIn the real world, corrupted images may include different kinds of noise [74], which makes it\nvery difﬁcult to recover a latent clean image. To resolve this problem, deep learning techniques\nbased multi-degradation idea have been proposed, as discussed in Section 3.4. Here we introduce\nthe denoising performance of the multi-degradation model, as shown in Table 21, where the Warp-\nNet method is shown to be very competitive in comparison with other popular denoising methods,\nsuch as DnCNN and MemNet.\n5. Discussion\nDeep learning techniques are seeing increasing use in image denoising. This paper offers a\nsurvey of these techniques in order to help readers understand these methods. In this section, we\npresent the potential areas of further research for image denoising and points out several as yet\nunsolved problems.\n19\nTable 12: PSNR (dB) of different methods on the Set12 for different noise levels (i.e., 15, 25 and 50).\nImages\nC.man\nHouse\nPeppers\nStarﬁsh\nMonarch\nAirplane\nParrot\nLena\nBarbara\nBoat\nMan\nCouple\nAverage\nNoise Level\nσ = 15\nBM3D [45]\n31.91\n34.93\n32.69\n31.14\n31.85\n31.07\n31.37\n34.26\n33.10\n32.13\n31.92\n32.10\n32.37\nWNNM [69]\n32.17\n35.13\n32.99\n31.82\n32.71\n31.39\n31.62\n34.27\n33.60\n32.27\n32.11\n32.17\n32.70\nEPLL [274]\n31.85\n34.17\n32.64\n31.13\n32.10\n31.19\n31.42\n33.92\n31.38\n31.93\n32.00\n31.93\n32.14\nCSF [184]\n31.95\n34.39\n32.85\n31.55\n32.33\n31.33\n31.37\n34.06\n31.92\n32.01\n32.08\n31.98\n32.32\nTNRD [35]\n32.19\n34.53\n33.04\n31.75\n32.56\n31.46\n31.63\n34.24\n32.13\n32.14\n32.23\n32.11\n32.50\nECNDNet [204]\n32.56\n34.97\n33.25\n32.17\n33.11\n31.70\n31.82\n34.52\n32.41\n32.37\n32.39\n32.39\n32.81\nDnCNN [258]\n32.61\n34.97\n33.30\n32.20\n33.09\n31.70\n31.83\n34.62\n32.64\n32.42\n32.46\n32.47\n32.86\nPSN-K [10]\n32.58\n35.04\n33.23\n32.17\n33.11\n31.75\n31.89\n34.62\n32.64\n32.52\n32.39\n32.43\n32.86\nPSN-U [10]\n32.04\n35.03\n33.21\n31.94\n32.93\n31.61\n31.62\n34.56\n32.49\n32.41\n32.37\n32.43\n32.72\nCIMM [12]\n32.61\n35.21\n33.21\n32.35\n33.33\n31.77\n32.01\n34.69\n32.74\n32.44\n32.50\n32.52\n32.95\nIRCNN [259]\n32.55\n34.89\n33.31\n32.02\n32.82\n31.70\n31.84\n34.53\n32.43\n32.34\n32.40\n32.40\n32.77\nFFDNet [260]\n32.43\n35.07\n33.25\n31.99\n32.66\n31.57\n31.81\n34.62\n32.54\n32.38\n32.41\n32.46\n32.77\nBRDNet [207]\n32.80\n35.27\n33.47\n32.24\n33.35\n31.85\n32.00\n34.75\n32.93\n32.55\n32.50\n32.62\n33.03\nADNet [206]\n32.81\n35.22\n33.49\n32.17\n33.17\n31.86\n31.96\n34.71\n32.80\n32.57\n32.47\n32.58\n32.98\nDudeNet [208]\n32.71\n35.13\n33.38\n32.29\n33.28\n31.78\n31.93\n34.66\n32.73\n32.46\n32.46\n32.49\n32.94\nNoise Level\nσ = 25\nBM3D [45]\n29.45\n32.85\n30.16\n28.56\n29.25\n28.42\n28.93\n32.07\n30.71\n29.90\n29.61\n29.71\n29.97\nWNNM [69]\n29.64\n33.22\n30.42\n29.03\n29.84\n28.69\n29.15\n32.24\n31.24\n30.03\n29.76\n29.82\n30.26\nEPLL [274]\n29.26\n32.17\n30.17\n28.51\n29.39\n28.61\n28.95\n31.73\n28.61\n29.74\n29.66\n29.53\n29.69\nMLP [25]\n29.61\n32.56\n30.30\n28.82\n29.61\n28.82\n29.25\n32.25\n29.54\n29.97\n29.88\n29.73\n30.03\nCSF [184]\n29.48\n32.39\n30.32\n28.80\n29.62\n28.72\n28.90\n31.79\n29.03\n29.76\n29.71\n29.53\n29.84\nTNRD [35]\n29.72\n32.53\n30.57\n29.02\n29.85\n28.88\n29.18\n32.00\n29.41\n29.91\n29.87\n29.71\n30.06\nECNDNet [204]\n30.11\n33.08\n30.85\n29.43\n30.30\n29.07\n29.38\n32.38\n29.84\n30.14\n30.03\n30.03\n30.39\nDnCNN [258]\n30.18\n33.06\n30.87\n29.41\n30.28\n29.13\n29.43\n32.44\n30.00\n30.21\n30.10\n30.12\n30.43\nPSN-K [10]\n30.28\n33.26\n31.01\n29.57\n30.30\n29.28\n29.38\n32.57\n30.17\n30.31\n30.10\n30.18\n30.53\nPSN-U [10]\n29.79\n33.23\n30.90\n29.30\n30.17\n29.06\n29.25\n32.45\n29.94\n30.25\n30.05\n30.12\n30.38\nCIMM [12]\n30.26\n33.44\n30.87\n29.77\n30.62\n29.23\n29.61\n32.66\n30.29\n30.30\n30.18\n30.24\n30.62\nIRCNN [259]\n30.08\n33.06\n30.88\n29.27\n30.09\n29.12\n29.47\n32.43\n29.92\n30.17\n30.04\n30.08\n30.38\nFFDNet [260]\n30.10\n33.28\n30.93\n29.32\n30.08\n29.04\n29.44\n32.57\n30.01\n30.25\n30.11\n30.20\n30.44\nBRDNet [207]\n31.39\n33.41\n31.04\n29.46\n30.50\n29.20\n29.55\n32.65\n30.34\n30.33\n30.14\n30.28\n30.61\nADNet [206]\n30.34\n33.41\n31.14\n29.41\n30.39\n29.17\n29.49\n32.61\n30.25\n30.37\n30.08\n30.24\n30.58\nDudeNet [208]\n30.23\n33.24\n30.98\n29.53\n30.44\n29.14\n29.48\n32.52\n30.15\n30.24\n30.08\n30.15\n30.52\nNoise Level\nσ = 50\nBM3D [45]\n26.13\n29.69\n26.68\n25.04\n25.82\n25.10\n25.90\n29.05\n27.22\n26.78\n26.81\n26.46\n26.72\nWNNM [69]\n26.45\n30.33\n26.95\n25.44\n26.32\n25.42\n26.14\n29.25\n27.79\n26.97\n26.94\n26.64\n27.05\nEPLL [274]\n26.10\n29.12\n26.80\n25.12\n25.94\n25.31\n25.95\n28.68\n24.83\n26.74\n26.79\n26.30\n26.47\nMLP [25]\n26.37\n29.64\n26.68\n25.43\n26.26\n25.56\n26.12\n29.32\n25.24\n27.03\n27.06\n26.67\n26.78\nTNRD [35]\n26.62\n29.48\n27.10\n25.42\n26.31\n25.59\n26.16\n28.93\n25.70\n26.94\n26.98\n26.50\n26.81\nECNDNet [204]\n27.07\n30.12\n27.30\n25.72\n26.82\n25.79\n26.32\n29.29\n26.26\n27.16\n27.11\n26.84\n27.15\nDnCNN [258]\n27.03\n30.00\n27.32\n25.70\n26.78\n25.87\n26.48\n29.39\n26.22\n27.20\n27.24\n26.90\n27.18\nPSN-K [10]\n27.10\n30.34\n27.40\n25.84\n26.92\n25.90\n26.56\n29.54\n26.45\n27.20\n27.21\n27.09\n27.30\nPSN-U [10]\n27.21\n30.21\n27.53\n25.63\n26.93\n25.89\n26.62\n29.54\n26.56\n27.27\n27.23\n27.04\n27.31\nCIMM [12]\n27.25\n30.70\n27.54\n26.05\n27.21\n26.06\n26.53\n29.65\n26.62\n27.36\n27.26\n27.24\n27.46\nIRCNN [259]\n26.88\n29.96\n27.33\n25.57\n26.61\n25.89\n26.55\n29.40\n26.24\n27.17\n27.17\n26.88\n27.14\nFFDNet [260]\n27.05\n30.37\n27.54\n25.75\n26.81\n25.89\n26.57\n29.66\n26.45\n27.33\n27.29\n27.08\n27.32\nBRDNet [207]\n27.44\n30.53\n27.67\n25.77\n26.97\n25.93\n26.66\n29.73\n26.85\n27.38\n27.27\n27.17\n27.45\nADNet [206]\n27.31\n30.59\n27.69\n25.70\n26.90\n25.88\n26.56\n29.59\n26.64\n27.35\n27.17\n27.07\n27.37\nDudeNet [208]\n27.22\n30.27\n27.51\n25.88\n26.93\n25.88\n26.50\n29.45\n26.49\n27.26\n27.19\n26.97\n27.30\nImage denoising based on deep learning techniques mainly are effective in increasing denois-\ning performance and efﬁciency, and performing complex denoising tasks. Solutions for improving\ndenoising performance include the following:\n1) Enlarging the receptive ﬁeld can capture more context information. Enlarging the receptive\n20\nTable 13: PSNR (dB) of different methods on the CBSD68, Kodak24 and McMaster for different noise levels (i.e.,\n15, 25, 35, 50 and 75).\nDatasets\nMethods\nσ = 15\nσ = 25\nσ = 35\nσ = 50\nσ = 75\nCBSD68\nCBM3D [45]\n33.52\n30.71\n28.89\n27.38\n25.74\nDnCNN [258]\n33.98\n31.31\n29.65\n28.01\n-\nDDRN [219]\n33.93\n31.24\n-\n27.86\n-\nEEDN [34]\n33.65\n31.03\n-\n27.85\n-\nDDFN [42]\n34.17\n31.52\n29.88\n28.26\n-\nCIMM [12]\n31.81\n29.34\n-\n26.40\n-\nBM3D-Net [237]\n33.79\n30.79\n-\n27.48\n-\nIRCNN [259]\n33.86\n31.16\n29.50\n27.86\n-\nFFDNet [260]\n33.80\n31.18\n29.57\n27.96\n26.24\nBRDNet [207]\n34.10\n31.43\n29.77\n28.16\n26.43\nGPADCNN [39]\n33.83\n31.12\n29.46\n-\n-\nFFDNet [202]\n33.76\n31.18\n29.58\n-\n26.57\nETN [218]\n34.10\n31.41\n-\n28.01\n-\nADNet [206]\n33.99\n31.31\n29.66\n28.04\n26.33\nDudeNet [208]\n34.01\n31.34\n29.71\n28.09\n26.40\nKodak24\nCBM3D [45]\n34.28\n31.68\n29.90\n28.46\n26.82\nDnCNN [258]\n34.73\n32.23\n30.64\n29.02\n-\nIRCNN [259]\n34.56\n32.03\n30.43\n28.81\n-\nFFDNet [260]\n34.55\n32.11\n30.56\n28.99\n27.25\nBRDNet [207]\n34.88\n32.41\n30.80\n29.22\n27.49\nFFDNet [202]\n34.53\n32.12\n30.59\n-\n27.61\nADNet [206]\n34.76\n32.26\n30.68\n29.10\n27.40\nDudeNet [208]\n34.81\n32.26\n30.69\n29.10\n27.39\nMcMaster\nCBM3D [45]\n34.06\n31.66\n29.92\n28.51\n26.79\nDnCNN [258]\n34.80\n32.47\n30.91\n29.21\n-\nIRCNN [259]\n34.58\n32.18\n30.59\n28.91\n-\nFFDNet [260]\n34.47\n32.25\n30.76\n29.14\n27.29\nBRDNet [207]\n35.08\n32.75\n31.15\n29.52\n27.72\nADNet [206]\n34.93\n32.56\n31.00\n29.36\n27.53\nTable 14: Running time of 13 popular denoising methods for the noisy images of sizes 256 × 256, 512 × 512 and\n1024 × 1024.\nMethods\nDevice\n256 × 256\n512 × 512\n1024 × 1024\nBM3D [45]\nCPU\n0.65\n2.85\n11.89\nWNNM [69]\nCPU\n203.1\n773.2\n2536.4\nEPLL [274]\nCPU\n25.4\n45.5\n422.1\nMLP [25]\nCPU\n1.42\n5.51\n19.4\nCSF [184]\nCPU\n2.11\n5.67\n40.8\nCSF [184]\nGPU\n-\n0.92\n1.72\nTNRD [35]\nCPU\n0.45\n1.33\n4.61\nTNRD [35]\nGPU\n0.010\n0.032\n0.116\nECNDNet [204]\nGPU\n0.012\n0.079\n0.205\nDnCNN [258]\nCPU\n0.74\n3.41\n12.1\nDnCNN [258]\nGPU\n0.014\n0.051\n0.200\nFFDNet [260]\nCPU\n0.90\n4.11\n14.1\nFFDNet [260]\nGPU\n0.016\n0.060\n0.235\nIRCNN [259]\nCPU\n0.310\n1.24\n4.65\nIRCNN [259]\nGPU\n0.012\n0.038\n0.146\nBRDNet [207]\nGPU\n0.062\n0.207\n0.788\nADNet [206]\nGPU\n0.0467\n0.0798\n0.2077\nDudeNet [208]\nGPU\n0.018\n0.422\n1.246\n21\n(a) \n(b) \n(c) \n(d) \n(e) \n(f) \n(g) \n   (h) \n(i)\nFigure 7: Denoising results of different methods on one image from the BSD68 with σ=15: (a) original image,\n(b) noisy image/24.62dB, (c) BM3D/35.29dB, (d) EPLL/34.98dB, (e) DnCNN/36.20dB, (f) FFDNet/36.75dB, (g)\nIRCNN/35.94dB, (h) ECNDNet/36.03dB, and (i) BRDNet/36.59dB.\nﬁeld can be accomplished by increasing the depth and width of the networks. However, this results\nin higher computational costs and more memory consumption. One technique for resolving this\n22\n(a) \n(b) \n    (c) \n(d) \n   (e) \n    (f) \n(g) \n   (h) \n(i)\nFigure 8: Denoising results of different methods on one image from the Set12 with σ=25: (a) original image, (b)\nnoisy image/20.22dB, (c) BM3D/29.26dB, (d) EPLL/29.44dB, (e) DnCNN/30.28dB, (f) FFDNet/30.08dB, (g) IR-\nCNN/30.09dB, (h) ECNDNet/30.30dB, and (i) BRDNet/30.50dB.\n     (a)\n   (b) \n   (c)  \n  (d) \n  (e) \n(f)\nFigure 9: Denoising results of different methods on one image from the McMaster with σ=35: (a) original image, (b)\nnoisy image/18.46dB, (c) DnCNN/33.05B, (d) FFDNet/33.03dB, (e) IRCNN/32.74dB, and (f) BRDNet/33.26dB.\n23\n(a) \n(b) \n    (c) \n(d) \n  (e) \n(f)\nFigure 10: Denoising results of different methods on one image from the Kodak24 with σ=50: (a) original image, (b)\nnoisy image/14.58dB, (c) DnCNN/25.80B, (d) FFDNet/26.13dB, (e) IRCNN/26.10dB, and (f) BRDNet/26.33dB.\nTable 15: PSNR (dB) of different methods on the DND for real-noisy image denoising.\nMethods\nDND\nEPLL [274]\n33.51\nTNRD [35]\n33.65\nNCSR [49]\n34.05\nMLP [25]\n34.23\nBM3D [45]\n34.51\nFoE [181]\n34.62\nWNNM [69]\n34.67\nKSVD [6]\n36.49\nCDnCNN-B [258]\n32.43\nFFDNet [260]\n34.40\nMCWNNM [137]\n37.38\nTWSC [232]\n37.94\nGCBD [31]\n35.58\nCIMM [12]\n36.04\nCBDNet [71]\n37.72\nVDN [251]\n39.38\nDRDN [192]\n39.40\nAGAN [131]\n38.13\nproblem, is dilated convolution, which not only contributions to higher performance and efﬁciency,\nbut is also very effective for mining more edge information.\n2) The simultaneous use of extra information (also called prior knowledge) and a CNN is an\neffective approach to facilitate obtaining more accurate features. This is implemented by designing\nthe loss function.\n24\nTable 16: PSNR (dB) of different methods on the SIDD for real-noisy image denoising.\nMethods\nSIDD\nCBM3D [45]\n25.65\nWNNM [69]\n25.78\nMLP [25]\n24.71\nDnCNN-B [258]\n23.66\nCBDNet [71]\n33.28\nVDN [251]\n39.23\nDRDN [192]\n39.60\nTable 17: PSNR (dB) of different methods on the Nam for real-noisy image denoising.\nMethods\nNam\nNI [5]\n31.52\nTWSC [232]\n37.52\nBM3D [45]\n39.84\nNC [112]\n40.41\nWNNM [69]\n41.04\nCDnCNN-B [258]\n37.49\nMCWNNM [137]\n37.91\nCBDNet [71]\n41.02\nCBDNet(JPEG) [71]\n41.31\nDRDN [192]\n38.45\nAGAN [131]\n41.38\nTable 18: PSNR (dB) of different methods on the cc for real-noisy image denoising.\nCamera Settings\nCBM3D [45]\nMLP [25]\nTNRD [35]\nDnCNN [258]\nNI [5]\nNC [112]\nWNNM [69]\nBRDNet [207]\nSDNet [270]\nADNet [206]\nDudeNet [208]\nCanon 5D ISO=3200\n39.76\n39.00\n39.51\n37.26\n35.68\n38.76\n37.51\n37.63\n39.83\n35.96\n36.66\n36.40\n36.34\n36.47\n34.13\n34.03\n35.69\n33.86\n37.28\n37.25\n36.11\n36.70\n36.37\n36.33\n36.45\n34.09\n32.63\n35.54\n31.43\n37.75\n36.79\n34.49\n35.03\nNikon D600 ISO=3200\n34.18\n34.70\n34.79\n33.62\n31.78\n35.57\n33.46\n34.55\n35.50\n33.94\n33.72\n35.07\n36.20\n36.37\n34.48\n35.16\n36.70\n36.09\n35.99\n37.24\n34.33\n34.70\n37.13\n39.33\n39.49\n35.41\n39.98\n39.28\n39.86\n38.62\n41.18\n38.87\n37.98\nNikon D800 ISO=1600\n36.81\n37.95\n38.11\n35.79\n34.84\n38.01\n36.35\n39.22\n38.77\n37.61\n38.10\n37.76\n40.23\n40.52\n36.08\n38.42\n39.05\n39.99\n39.67\n40.87\n38.24\n39.15\n37.51\n37.94\n38.17\n35.48\n35.79\n38.20\n37.15\n39.04\n38.86\n36.89\n36.14\nNikon D800 ISO=3200\n35.05\n37.55\n37.69\n34.08\n38.36\n38.07\n38.60\n38.28\n39.94\n37.20\n36.93\n34.07\n35.91\n35.90\n33.70\n35.53\n35.72\n36.04\n37.18\n36.78\n35.67\n35.80\n34.42\n38.15\n38.21\n33.31\n40.05\n36.76\n39.73\n38.85\n39.78\n38.09\n37.49\nNikon D800 ISO=6400\n31.13\n32.69\n32.81\n29.83\n34.08\n33.49\n33.29\n32.75\n33.34\n32.24\n31.94\n31.22\n32.33\n32.33\n30.55\n32.13\n32.79\n31.16\n33.24\n33.29\n32.59\n32.51\n30.97\n32.29\n32.29\n30.09\n31.52\n32.86\n31.98\n32.89\n33.22\n33.14\n32.91\nAverage\n35.19\n36.46\n36.61\n33.86\n35.33\n36.43\n35.77\n36.73\n37.51\n35.69\n35.72\nTable 19: Different methods on the BSD68 for different noise levels (i.e., 15, 25 and 50).\nMethods\n15\n25\n50\nDnCNN-B [258]\n31.61\n29.16\n26.23\nFFDNet [260]\n31.62\n29.19\n26.30\nSCNN [90]\n31.48\n29.03\n26.08\nADNet-B [206]\n31.56\n29.14\n26.24\nDnCNN-SURE-T [191]\n-\n29.00\n25.95\nDnCNN-MSE-GT [191]\n-\n29.20\n26.22\nG2G1(LM,BSD) [27]\n31.55\n28.93\n25.73\n25\nTable 20: Average PSNR (dB) results of different methods on Set12 with noise levels of 25 and 50.\nImages\nC.man\nHouse\nPeppers\nStarﬁsh\nMonarch\nAirplane\nParrot\nLena\nBarbara\nBoat\nMan\nCouple\nAverage\nNoise Level\nσ = 25\nDnCNN-B [258]\n29.94\n33.05\n30.84\n29.34\n30.25\n29.09\n29.35\n32.42\n29.69\n30.20\n30.09\n30.10\n30.36\nFFDNet [260]\n30.10\n33.28\n30.93\n29.32\n30.08\n29.04\n29.44\n32.57\n30.01\n30.25\n30.11\n30.20\n30.44\nADNet-B [206]\n29.94\n33.38\n30.99\n29.22\n30.38\n29.16\n29.41\n32.59\n30.05\n30.28\n30.01\n30.15\n30.46\nDudeNet-B [208]\n30.01\n33.15\n30.87\n29.39\n30.31\n29.07\n29.40\n32.42\n29.76\n30.18\n30.03\n30.06\n30.39\nDNCNN-SURE-T [191]\n29.86\n32.73\n30.57\n29.11\n30.13\n28.93\n29.26\n32.08\n29.44\n29.86\n29.91\n29.78\n30.14\nDNCNN-MSE-GT [191]\n30.14\n33.16\n30.84\n29.40\n30.45\n29.11\n29.36\n32.44\n29.91\n30.11\n30.08\n30.06\n30.42\nNoise Level\nσ = 50\nDnCNN-B [258]\n27.03\n30.02\n27.39\n25.72\n26.83\n25.89\n26.48\n29.38\n26.38\n27.23\n27.23\n26.91\n27.21\nFFDNet [260]\n27.05\n30.37\n27.54\n25.75\n26.81\n25.89\n26.57\n29.66\n26.45\n27.33\n27.29\n27.08\n27.32\nADNet-B [206]\n27.22\n30.43\n27.70\n25.63\n26.92\n26.03\n26.56\n29.53\n26.51\n27.22\n27.19\n27.05\n27.33\nDudeNet-B [208]\n27.19\n30.11\n27.50\n25.69\n26.82\n25.85\n26.46\n29.35\n26.38\n27.20\n27.13\n26.90\n27.22\nDNCNN-SURE-T [191]\n26.47\n29.20\n26.78\n25.39\n26.53\n25.65\n26.21\n28.81\n25.23\n26.79\n26.97\n26.48\n26.71\nDNCNN-MSE-GT [191]\n27.03\n29.92\n27.27\n25.65\n26.95\n25.93\n26.43\n29.31\n26.17\n27.12\n27.22\n26.94\n27.16\nTable 21: Different methods on the VggFace2and WebFace for image denoising.\nMethods\nVggFace2 [26]\nWebFace [244]\n4 ×\n8 ×\n4 ×\n8 ×\nDnCNN [258]\n26.73\n23.29\n28.35\n24.75\nMemNet [197]\n26.85\n23.31\n28.57\n24.77\nWarpNet [127]\n28.55\n24.10\n32.31\n27.21\n3) Combining local and global information can enhance the memory abilities of the shallow\nlayers on deep layers to better ﬁlter the noise. Two methods for addressing this problem are\nresidual operation and recursive operation.\n4) Single processing methods can be used to suppress the noise. The single processing tech-\nnique fused into the deep CNN can achieve excellent performance. For example, the wavelet\ntechnique is gathered into the U-Net to deal with image restoration [137].\n5) Data augmentation, such as horizontal ﬂip, vertical ﬂip and color jittering, can help the\ndenoising methods learn more types of noise, which can enhance the expressive ability of the\ndenoising models. Additionally, using the GAN to construct virtual noisy images is also useful for\nimage denoising.\n6) Transfer learning, graph and neural architecture search methods can obtain good denoising\nresults.\n7) Improving the hardware or camera mechanism can reduce the effect of noise on the captured\nimage.\nCompressing deep neural networks has achieved great success in improving the efﬁciency of\ndenoising. Reducing the depth or the width of deep neural networks can reduce the complexity\nof these networks in image denoising. Also, the use of small convolutional kernel and group\nconvolution can reduce the number of parameters, thereby accelerating the speed of training. The\nfusion of dimension reduction methods, such as principal component analysis (PCA) and CNN,\ncan also lead to improvements in denoising efﬁciency.\nFor resolving complex noisy images, step-by-step processing is a very popular method. For\nexample, using a two-step mechanism is a way of dealing with a noisy image with low-resolution.\nThe ﬁrst step involves the recovery of a high-resolution image by a CNN. The second step uses a\nnovel CNN to ﬁlter the noise of the high-resolution image. In the example above, the two CNNs\n26\nare implemented via a cascade operation. This two-step mechanism is ideal for unsupervised noise\ntasks, such as real noisy images and blind denoising. That is, the ﬁrst step relies on a CNN with\noptimization algorithms, i.e., maximum a posteriori, to estimate the noise as ground truth (referred\nas a label). The second step utilized another CNN and obtained ground truth to train a denoising\nmodel for real-noisy image denoising or blind denoising. The self-supervised learning fused into\nthe CNN is a good choice for real-noisy image denoising or blind denoising.\nAlthough deep learning techniques have attained great success in these three scenarios, there\nare still challenges in the ﬁeld of image denoising. These include:\n1) Deeper denoising networks require more memory resources.\n2) Training deeper denoising networks is not a stable solution for real noisy image, unpaired\nnoisy image and multi-degradation tasks.\n3) Real noisy images are not easily captured, which results in inadequate training samples.\n4) Deep CNNs are difﬁcult to solve unsupervised denoising tasks.\n5) More accurate metrics need to be found for image denoising. PSNR and SSIM are popu-\nlar metrics for the task of image restoration. PSNR suffers from excessive smoothing, which is\nvery difﬁcult to recognize indistinguishable images. SSIM depends on brightness, contrast and\nstructure, and therefore cannot accurately evaluate image perceptual quality.\n6. Conclusion\nIn this paper, we compare, study and summarize the deep networks used for on image de-\nnoising. First, we show the basic frameworks of deep learning for image denoising. Then, we\npresent the deep learning techniques for noisy tasks, including additive white noisy images, blind\ndenoising, real noisy images and hybrid noisy images. Next, for each category of noisy tasks,\nwe analyze the motivation and theory of denoising networks. Next, we compare the denoising\nresults, efﬁciency and visual effects of different networks on benchmark datasets, and then per-\nform a cross-comparison of the different types of image denoising methods with different types of\nnoise. Finally, some potential areas for further research are suggested, and the challenges of deep\nlearning in image denoising are discussed.\nOver the past few years, Gaussian noisy image denoising techniques have achieved great suc-\ncess, particularly in scenarios where the Gaussian noise is regular. However, in the real world the\nnoise is complex and irregular. Improving the hardware devices in order to better suppress the\nnoise for capturing a high-quality image is very important. Moreover, the obtained image may\nbe blurry, low-resolution and corrupted. Therefore, it is critical to determine how to effectively\nrecover the latent clean image from the superposed noisy image. Furthermore, while the use of\ndeep learning techniques to learn features requires the ground truth, the obtained real noisy im-\nages do not have the ground truth. These are urgent challenges that researches and scholars need\nto address.\nAcknowledgments\nThis paper is partially supported by the National Natural Science Foundation of China under\nGrant No. 61876051, in part by Shenzhen Municipal Science and Technology Innovation, Council\n27\nunder Grant No. JSGG20190220153602271 and in part by the Natural Science Foundation of\nGuang dong Province under Grant No. 2019A1515011811.\nReferences\nReferences\n[1] Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard,\nM., et al., 2016. Tensorﬂow: A system for large-scale machine learning. In: 12th Symposium on Operating\nSystems Design and Implementation. pp. 265–283.\n[2] Abbasi, A., Monadjemi, A., Fang, L., Rabbani, H., Zhang, Y., 2019. Three-dimensional optical coherence\ntomography image denoising through multi-input fully-convolutional networks. Computers in Biology and\nMedicine 108, 1–8.\n[3] Abdelhamed, A., Lin, S., Brown, M. S., 2018. A high-quality denoising dataset for smartphone cameras. In:\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1692–1700.\n[4] Abiko, R., Ikehara, M., 2019. Blind denoising of mixed gaussian-impulse noise by single cnn. In: ICASSP\n2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, pp.\n1717–1721.\n[5] ABSoft, N., 2017. Neat image.\n[6] Aharon, M., Elad, M., Bruckstein, A., 2006. K-svd: An algorithm for designing overcomplete dictionaries for\nsparse representation. IEEE Transactions on Signal Processing 54 (11), 4311–4322.\n[7] Ahn, B., Cho, N. I., 2017. Block-matching convolutional neural network for image denoising. arXiv preprint\narXiv:1704.00524.\n[8] Ahn, B., Kim, Y., Park, G., Cho, N. I., 2018. Block-matching convolutional neural network (bmcnn): Improv-\ning cnn-based denoising by block-matched inputs. In: 2018 Asia-Paciﬁc Signal and Information Processing\nAssociation Annual Summit and Conference (APSIPA ASC). IEEE, pp. 516–525.\n[9] Aittala, M., Durand, F., 2018. Burst image deblurring using permutation invariant convolutional neural net-\nworks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 731–747.\n[10] Aljadaany, R., Pal, D. K., Savvides, M., 2019. Proximal splitting networks for image restoration. arXiv preprint\narXiv:1903.07154.\n[11] Anwar, S., Barnes, N., 2019. Real image denoising with feature attention. arXiv preprint arXiv:1904.07396.\n[12] Anwar, S., Huynh, C. P., Porikli, F., 2017. Chaining identity mapping modules for image denoising. arXiv\npreprint arXiv:1712.02933.\n[13] Bae, W., Yoo, J., Chul Ye, J., 2017. Beyond deep residual learning for image restoration: Persistent homology-\nguided manifold simpliﬁcation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition Workshops. pp. 145–153.\n[14] Bako, S., Vogels, T., McWilliams, B., Meyer, M., Nov´ak, J., Harvill, A., Sen, P., Derose, T., Rousselle, F.,\n2017. Kernel-predicting convolutional networks for denoising monte carlo renderings. ACM Transactions on\nGraphics (TOG) 36 (4), 97.\n[15] Bedini, L., Tonazzini, A., 1990. Neural network use in maximum entropy image restoration. Image and Vision\nComputing 8 (2), 108–114.\n[16] Bedini, L., Tonazzini, A., 1992. Image restoration preserving discontinuities: the bayesian approach and neural\nnetworks. Image and Vision Computing 10 (2), 108–118.\n[17] Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., 2007. Greedy layer-wise training of deep networks. In:\nAdvances in Neural Information Processing Systems. pp. 153–160.\n[18] Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D.,\nBengio, Y., 2010. Theano: a cpu and gpu math expression compiler. In: Proceedings of the Python for Scientiﬁc\nComputing Conference (SciPy). Vol. 4. Austin, TX.\n[19] Bernstein, R., 1987. Adaptive nonlinear ﬁlters for simultaneous removal of different kinds of noise in images.\nIEEE Transactions on Circuits and Systems 34 (11), 1275–1291.\n28\n[20] Bigdeli,\nS. A.,\nZwicker,\nM.,\n2017. Image restoration using autoencoding priors. arXiv preprint\narXiv:1703.09964.\n[21] Bigdeli, S. A., Zwicker, M., Favaro, P., Jin, M., 2017. Deep mean-shift priors for image restoration. In: Ad-\nvances in Neural Information Processing Systems. pp. 763–772.\n[22] Bottou, L., 2010. Large-scale machine learning with stochastic gradient descent. In: Proceedings of COMP-\nSTAT’2010. Springer, pp. 177–186.\n[23] Broaddus, C., Krull, A., Weigert, M., Schmidt, U., Myers, G., 2020. Removing structured noise with self-\nsupervised blind-spot networks. In: 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI).\nIEEE, pp. 159–163.\n[24] Brooks, T., Mildenhall, B., Xue, T., Chen, J., Sharlet, D., Barron, J. T., 2019. Unprocessing images for learned\nraw denoising. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp.\n11036–11045.\n[25] Burger, H. C., Schuler, C. J., Harmeling, S., 2012. Image denoising: Can plain neural networks compete with\nbm3d? In: 2012 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, pp. 2392–2399.\n[26] Cao, Q., Shen, L., Xie, W., Parkhi, O. M., Zisserman, A., 2018. Vggface2: A dataset for recognising faces\nacross pose and age. In: 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition\n(FG 2018). IEEE, pp. 67–74.\n[27] Cha, S., Park, T., Moon, T., 2019. Gan2gan: Generative noise learning for blind image denoising with single\nnoisy images. arXiv preprint arXiv:1905.10488.\n[28] Chang, Y., Yan, L., Fang, H., Zhong, S., Liao, W., 2018. Hsi-denet: Hyperspectral image restoration via\nconvolutional neural network. IEEE Transactions on Geoscience and Remote Sensing 57 (2), 667–682.\n[29] Chen, C., Xiong, Z., Tian, X., Wu, F., 2018. Deep boosting for image denoising. In: Proceedings of the\nEuropean Conference on Computer Vision (ECCV). pp. 3–18.\n[30] Chen, C., Xu, Z., 2018. Aerial-image denoising based on convolutional neural network with multi-scale resid-\nual learning approach. Information 9 (7), 169.\n[31] Chen, J., Chen, J., Chao, H., Yang, M., 2018. Image blind denoising with generative adversarial network based\nnoise modeling. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp.\n3155–3164.\n[32] Chen, J., Hou, J., Chau, L.-P., 2018. Light ﬁeld denoising via anisotropic parallax analysis in a cnn framework.\nIEEE Signal Processing Letters 25 (9), 1403–1407.\n[33] Chen, X., Song, L., Yang, X., 2016. Deep rnns for video denoising. In: Applications of Digital Image Process-\ning XXXIX. Vol. 9971. International Society for Optics and Photonics, p. 99711T.\n[34] Chen, X., Zhan, S., Ji, D., Xu, L., Wu, C., Li, X., 2018. Image denoising via deep network based on edge\nenhancement. Journal of Ambient Intelligence and Humanized Computing, 1–11.\n[35] Chen, Y., Pock, T., 2016. Trainable nonlinear reaction diffusion: A ﬂexible framework for fast and effective\nimage restoration. IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (6), 1256–1272.\n[36] Chen, Y., Yu, M., Jiang, G., Peng, Z., Chen, F., 2019. End-to-end single image enhancement based on a dual\nnetwork cascade model. Journal of Visual Communication and Image Representation 61, 284–295.\n[37] Chetlur, S., Woolley, C., Vandermersch, P., Cohen, J., Tran, J., Catanzaro, B., Shelhamer, E., 2014. cudnn:\nEfﬁcient primitives for deep learning. arXiv preprint arXiv:1410.0759.\n[38] Chiang, Y.-W., Sullivan, B., 1989. Multi-frame image restoration using a neural network. In: Proceedings of\nthe 32nd Midwest Symposium on Circuits and Systems,. IEEE, pp. 744–747.\n[39] Cho, S. I., Kang, S.-J., 2018. Gradient prior-aided cnn denoiser with separable convolution-based optimization\nof feature dimension. IEEE Transactions on Multimedia 21 (2), 484–493.\n[40] Choi, K., Vania, M., Kim, S., 2019. Semi-supervised learning for low-dose ct image restoration with hierarchi-\ncal deep generative adversarial network (hd-gan). In: 2019 41st Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society (EMBC). IEEE, pp. 2683–2686.\n[41] Chollet, F., et al., 2015. Keras.\n[42] Couturier, R., Perrot, G., Salomon, M., 2018. Image denoising using a deep encoder-decoder network with\nskip connections. In: International Conference on Neural Information Processing. Springer, pp. 554–565.\n[43] Cruz, C., Foi, A., Katkovnik, V., Egiazarian, K., 2018. Nonlocality-reinforced convolutional neural networks\n29\nfor image denoising. IEEE Signal Processing Letters 25 (8), 1216–1220.\n[44] Cui, J., Gong, K., Guo, N., Wu, C., Meng, X., Kim, K., Zheng, K., Wu, Z., Fu, L., Xu, B., et al., 2019.\nPet image denoising using unsupervised deep learning. European journal of nuclear medicine and molecular\nimaging 46 (13), 2780–2789.\n[45] Dabov, K., Foi, A., Katkovnik, V., Egiazarian, K., 2007. Image denoising by sparse 3-d transform-domain\ncollaborative ﬁltering. IEEE Transactions on Image Processing 16 (8), 2080–2095.\n[46] Davy, A., Ehret, T., Morel, J.-M., Arias, P., Facciolo, G., 2018. Non-local video denoising by cnn. arXiv\npreprint arXiv:1811.12758.\n[47] de Figueiredo, M. T., Leitao, J. M., 1992. Image restoration using neural networks. In: [Proceedings] ICASSP-\n92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing. Vol. 2. IEEE, pp. 409–\n412.\n[48] de Ridder, D., Duin, R. P., Verbeek, P. W., Van Vliet, L., 1999. The applicability of neural networks to non-\nlinear image processing. Pattern Analysis & Applications 2 (2), 111–128.\n[49] Dong, W., Zhang, L., Shi, G., Li, X., 2012. Nonlocally centralized sparse representation for image restoration.\nIEEE Transactions on Image Processing 22 (4), 1620–1630.\n[50] Du, B., Wei, Q., Liu, R., 2019. An improved quantum-behaved particle swarm optimization for endmember\nextraction. IEEE Transactions on Geoscience and Remote Sensing.\n[51] Du, H., Dong, L., Liu, M., Zhao, Y., Jia, W., Liu, X., Hui, M., Kong, L., Hao, Q., 2018. Image restoration\nbased on deep convolutional network in wavefront coding imaging system. In: 2018 Digital Image Computing:\nTechniques and Applications (DICTA). IEEE, pp. 1–8.\n[52] Duan, C., Cui, L., Chen, X., Wei, F., Zhu, C., Zhao, T., 2018. Attention-fused deep matching network for\nnatural language inference. In: IJCAI. pp. 4033–4040.\n[53] Ehret, T., Davy, A., Morel, J.-M., Facciolo, G., Arias, P., 2019. Model-blind video denoising via frame-to-\nframe training. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp.\n11369–11378.\n[54] Elad, M., Aharon, M., 2006. Image denoising via sparse and redundant representations over learned dictionar-\nies. IEEE Transactions on Image Processing 15 (12), 3736–3745.\n[55] Fan, E., 2000. Extended tanh-function method and its applications to nonlinear equations. Physics Letters A\n277 (4-5), 212–218.\n[56] Farooque, M. A., Rohankar, J. S., 2013. Survey on various noises and techniques for denoising the color image.\nInternational Journal of Application or Innovation in Engineering & Management (IJAIEM) 2 (11), 217–221.\n[57] Franzen, R., 1999. Kodak lossless true color image suite. source: http://r0k. us/graphics/kodak 4.\n[58] Fu, B., Zhao, X., Li, Y., Wang, X., Ren, Y., 2019. A convolutional neural networks denoising approach for salt\nand pepper noise. Multimedia Tools and Applications 78 (21), 30707–30721.\n[59] Fukushima, K., 1980. Neocognitron: A self-organizing neural network model for a mechanism of pattern\nrecognition unaffected by shift in position. Biological Cybernetics 36 (4), 193–202.\n[60] Fukushima, K., Miyake, S., 1982. Neocognitron: A self-organizing neural network model for a mechanism of\nvisual pattern recognition. In: Competition and Cooperation in Neural Nets. Springer, pp. 267–285.\n[61] Gardner, E., Wallace, D., Stroud, N., 1989. Training with noise and the storage of correlated patterns in a neural\nnetwork model. Journal of Physics A: Mathematical and General 22 (12), 2019.\n[62] Gashi, D., Pereira, M., Vterkovska, V., 2017. Multi-scale context aggregation by dilated convolutions machine\nlearning-project.\n[63] Gholizadeh-Ansari, M., Alirezaie, J., Babyn, P., 2018. Low-dose ct denoising with dilated residual network.\nIn: 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society\n(EMBC). IEEE, pp. 5117–5120.\n[64] Godard, C., Matzen, K., Uyttendaele, M., 2018. Deep burst denoising. In: Proceedings of the European Con-\nference on Computer Vision (ECCV). pp. 538–554.\n[65] Gondara, L., Wang, K., 2017. Recovering loss to followup information using denoising autoencoders. In: 2017\nIEEE International Conference on Big Data (Big Data). IEEE, pp. 1936–1945.\n[66] Gong, D., Zhang, Z., Shi, Q., Hengel, A. v. d., Shen, C., Zhang, Y., 2018. Learning an optimizer for image\ndeconvolution. arXiv preprint arXiv:1804.03368.\n30\n[67] Green, M., Marom, E. M., Konen, E., Kiryati, N., Mayer, A., 2018. Learning real noise for ultra-low dose lung\nct denoising. In: International Workshop on Patch-based Techniques in Medical Imaging. Springer, pp. 3–11.\n[68] Greenhill, D., Davies, E., 1994. Relative effectiveness of neural networks for image noise suppression. In:\nMachine Intelligence and Pattern Recognition. Vol. 16. Elsevier, pp. 367–378.\n[69] Gu, S., Zhang, L., Zuo, W., Feng, X., 2014. Weighted nuclear norm minimization with application to image\ndenoising. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2862–\n2869.\n[70] Guan, J., Lai, R., Xiong, A., 2019. Wavelet deep neural network for stripe noise removal. IEEE Access 7,\n44544–44554.\n[71] Guo, S., Yan, Z., Zhang, K., Zuo, W., Zhang, L., 2019. Toward convolutional blind denoising of real pho-\ntographs. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1712–\n1722.\n[72] Guo, Z., Sun, Y., Jian, M., Zhang, X., 2018. Deep residual network with sparse feedback for image restoration.\nApplied Sciences 8 (12), 2417.\n[73] Han, Y., Ye, J. C., 2018. Framing u-net via deep convolutional framelets: Application to sparse-view ct. IEEE\nTransactions on Medical Imaging 37 (6), 1418–1429.\n[74] He, J., Dong, C., Qiao, Y., 2019. Multi-dimension modulation for image restoration with dynamic controllable\nresidual learning. arXiv preprint arXiv:1912.05293.\n[75] He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. In: Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition. pp. 770–778.\n[76] Heckel, R., Huang, W., Hand, P., Voroninski, V., 2018. Rate-optimal denoising with deep neural networks.\narXiv preprint arXiv:1805.08855.\n[77] Heinrich, M. P., Stille, M., Buzug, T. M., 2018. Residual u-net convolutional neural network architecture for\nlow-dose ct denoising. Current Directions in Biomedical Engineering 4 (1), 297–300.\n[78] Hendriksen, A. A., Pelt, D. M., Batenburg, K. J., 2020. Noise2inverse: Self-supervised deep convolutional\ndenoising for linear inverse problems in imaging. arXiv preprint arXiv:2001.11801.\n[79] Hinton, G., Osindero, S., ???? The, y. 2006. a fast learning algorithm for deep belief nets. Neural Computation\n18 (7).\n[80] Hinton, G. E., Salakhutdinov, R. R., 2006. Reducing the dimensionality of data with neural networks. Science\n313 (5786), 504–507.\n[81] Hirose, Y., Yamashita, K., Hijiya, S., 1991. Back-propagation algorithm which varies the number of hidden\nunits. Neural Networks 4 (1), 61–66.\n[82] Hong, S.-W., Bao, P., 2000. An edge-preserving subband coding model based on non-adaptive and adaptive\nregularization. Image and Vision Computing 18 (8), 573–582.\n[83] Hongqiang, M., Shiping, M., Yuelei, X., Mingming, Z., 2018. An adaptive image denoising method based on\ndeep rectiﬁed denoising auto-encoder. In: Journal of Physics: Conference Series. Vol. 1060. IOP Publishing,\np. 012048.\n[84] Hore, A., Ziou, D., 2010. Image quality metrics: Psnr vs. ssim. In: 2010 20th International Conference on\nPattern Recognition. IEEE, pp. 2366–2369.\n[85] Hsu, C.-C., Lin, C.-W., 2017. Cnn-based joint clustering and representation learning with feature drift com-\npensation for large-scale image data. IEEE Transactions on Multimedia 20 (2), 421–429.\n[86] Hu, G., Yang, Y., Yi, D., Kittler, J., Christmas, W., Li, S. Z., Hospedales, T., 2015. When face recognition\nmeets with deep learning: an evaluation of convolutional neural networks for face recognition. In: Proceedings\nof the IEEE international Conference on Computer Vision Workshops. pp. 142–150.\n[87] HUANG, T., 1971. Stability of two-dimensional recursive ﬁlters(mathematical model for stability problem in\ntwo-dimensional recursive ﬁltering).\n[88] Ioffe, S., 2017. Batch renormalization: Towards reducing minibatch dependence in batch-normalized models.\nIn: Advances In Neural Information Processing Systems. pp. 1945–1953.\n[89] Ioffe, S., Szegedy, C., 2015. Batch normalization: Accelerating deep network training by reducing internal\ncovariate shift. arXiv preprint arXiv:1502.03167.\n[90] Isogawa, K., Ida, T., Shiodera, T., Takeguchi, T., 2017. Deep shrinkage convolutional neural network for\n31\nadaptive noise reduction. IEEE Signal Processing Letters 25 (2), 224–228.\n[91] Jaroensri, R., Biscarrat, C., Aittala, M., Durand, F., 2019. Generating training data for denoising real rgb images\nvia camera pipeline simulation. arXiv preprint arXiv:1904.08825.\n[92] Jarrett, K., Kavukcuoglu, K., Ranzato, M., LeCun, Y., 2009. What is the best multi-stage architecture for object\nrecognition? In: 2009 IEEE 12th International Conference on Computer Vision. IEEE, pp. 2146–2153.\n[93] Jeon, W., Jeong, W., Son, K., Yang, H., 2018. Speckle noise reduction for digital holographic images using\nmulti-scale convolutional neural networks. Optics Letters 43 (17), 4240–4243.\n[94] Jia, X., Chai, H., Guo, Y., Huang, Y., Zhao, B., 2018. Multiscale parallel feature extraction convolution neural\nnetwork for image denoising. Journal of Electronic Imaging 27 (6), 063031.\n[95] Jia, X., Liu, S., Feng, X., Zhang, L., 2019. Focnet: A fractional optimal control network for image denoising.\nIn: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 6054–6063.\n[96] Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., 2014.\nCaffe: Convolutional architecture for fast feature embedding. In: Proceedings of the 22nd ACM International\nConference on Multimedia. ACM, pp. 675–678.\n[97] Jian, W., Zhao, H., Bai, Z., Fan, X., 2018. Low-light remote sensing images enhancement algorithm based on\nfully convolutional neural network. In: China High Resolution Earth Observation Conference. Springer, pp.\n56–65.\n[98] Jiang, D., Dou, W., Vosters, L., Xu, X., Sun, Y., Tan, T., 2018. Denoising of 3d magnetic resonance images\nwith multi-channel residual learning of convolutional neural network. Japanese Journal of Radiology 36 (9),\n566–574.\n[99] Jiang, L., Jing, Y., Hu, S., Ge, B., Xiao, W., 2018. Deep reﬁnement network for natural low-light image\nenhancement in symmetric pathways. Symmetry 10 (10), 491.\n[100] Jiao, J., Tu, W.-C., He, S., Lau, R. W., 2017. Formresnet: Formatted residual learning for image restoration. In:\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. pp. 38–46.\n[101] Jifara, W., Jiang, F., Rho, S., Cheng, M., Liu, S., 2019. Medical image denoising using convolutional neural\nnetwork: a residual learning approach. The Journal of Supercomputing 75 (2), 704–718.\n[102] Jin, K. H., McCann, M. T., Froustey, E., Unser, M., 2017. Deep convolutional neural network for inverse\nproblems in imaging. IEEE Transactions on Image Processing 26 (9), 4509–4522.\n[103] Kadimesetty, V. S., Gutta, S., Ganapathy, S., Yalavarthy, P. K., 2018. Convolutional neural network-based\nrobust denoising of low-dose computed tomography perfusion maps. IEEE Transactions on Radiation and\nPlasma Medical Sciences 3 (2), 137–152.\n[104] Karlik, B., Olgac, A. V., 2011. Performance analysis of various activation functions in generalized mlp archi-\ntectures of neural networks. International Journal of Artiﬁcial Intelligence and Expert Systems 1 (4), 111–122.\n[105] Khan, S., Khan, K. S., Shin, S. Y., 2019. Symbol denoising in high order m-qam using residual learning of\ndeep cnn. In: 2019 16th IEEE Annual Consumer Communications & Networking Conference (CCNC). IEEE,\npp. 1–6.\n[106] Khaw, H. Y., Soon, F. C., Chuah, J. H., Chow, C.-O., 2017. Image noise types recognition using convolutional\nneural network with principal components analysis. IET Image Processing 11 (12), 1238–1245.\n[107] Khoroushadi, M., Sadegh, M., 2018. Enhancement in low-dose computed tomography through image denoising\ntechniques: Wavelets and deep learning. Ph.D. thesis, ProQuest Dissertations Publishing.\n[108] Kokkinos, F., Lefkimmiatis, S., 2019. Iterative joint image demosaicking and denoising using a residual de-\nnoising network. IEEE Transactions on Image Processing.\n[109] Krizhevsky, A., Sutskever, I., Hinton, G. E., 2012. Imagenet classiﬁcation with deep convolutional neural\nnetworks. In: Advances in Neural Information Processing Systems. pp. 1097–1105.\n[110] Kutzner, C., P´all, S., Fechner, M., Esztermann, A., de Groot, B. L., Grubm¨uller, H., 2019. More bang for your\nbuck: improved use of gpu nodes for gromacs 2018. arXiv preprint arXiv:1903.05918.\n[111] Latif, G., Iskandar, D. A., Alghazo, J., Butt, M., Khan, A. H., 2018. Deep cnn based mr image denoising for\ntumor segmentation using watershed transform. International Journal of Engineering & Technology 7 (2.3),\n37–42.\n[112] Lebrun, M., Colom, M., Morel, J.-M., 2015. The noise clinic: a blind image denoising algorithm. Image\nProcessing On Line 5, 1–54.\n32\n[113] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., et al., 1998. Gradient-based learning applied to document\nrecognition. Proceedings of the IEEE 86 (11), 2278–2324.\n[114] Lee, C.-C., de Gyvez, J. P., 1996. Color image processing in a cellular neural-network environment. IEEE\nTransactions on Neural Networks 7 (5), 1086–1098.\n[115] Lee, D., Yun, S., Choi, S., Yoo, H., Yang, M.-H., Oh, S., 2018. Unsupervised holistic image generation from\nkey local patches. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 19–35.\n[116] Lefkimmiatis, S., 2017. Non-local color image denoising with convolutional neural networks. In: Proceedings\nof the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3587–3596.\n[117] Lei, Y., Yuan, W., Wang, H., Wenhu, Y., Bo, W., 2016. A skin segmentation algorithm based on stacked\nautoencoders. IEEE Transactions on Multimedia 19 (4), 740–749.\n[118] Li, H., Yang, W., Yong, X., 2018. Deep learning for ground-roll noise attenuation. In: SEG Technical Program\nExpanded Abstracts 2018. Society of Exploration Geophysicists, pp. 1981–1985.\n[119] Li, J., Li, M., Lu, G., Zhang, B., Yin, H., Zhang, D., 2020. Similarity and diversity induced paired projection\nfor cross-modal retrieval. Information Sciences.\n[120] Li, J., Lu, G., Zhang, B., You, J., Zhang, D., 2019. Shared linear encoder-based multikernel gaussian process\nlatent variable model for visual classiﬁcation. IEEE transactions on cybernetics.\n[121] Li, J., Zhang, B., Zhang, D., 2017. Shared autoencoder gaussian process latent variable model for visual\nclassiﬁcation. IEEE transactions on neural networks and learning systems 29 (9), 4272–4286.\n[122] Li, L., Wu, J., Jin, X., 2018. Cnn denoising for medical image based on wavelet domain. In: 2018 9th Interna-\ntional Conference on Information Technology in Medicine and Education (ITME). IEEE, pp. 105–109.\n[123] Li, M., Hsu, W., Xie, X., Cong, J., Gao, W., 2020. Sacnn: Self-attention convolutional neural network for\nlow-dose ct denoising with self-supervised perceptual loss network. IEEE Transactions on Medical Imaging.\n[124] Li, Q., Cai, W., Wang, X., Zhou, Y., Feng, D. D., Chen, M., 2014. Medical image classiﬁcation with convo-\nlutional neural network. In: 2014 13th International Conference on Control Automation Robotics & Vision\n(ICARCV). IEEE, pp. 844–848.\n[125] Li, S., He, F., Du, B., Zhang, L., Xu, Y., Tao, D., 2019. Fast spatio-temporal residual network for video\nsuper-resolution. arXiv preprint arXiv:1904.02870.\n[126] Li, X., Du, B., Xu, C., Zhang, Y., Zhang, L., Tao, D., 2020. Robust learning with imperfect privileged infor-\nmation. Artiﬁcial Intelligence 282, 103246.\n[127] Li, X., Liu, M., Ye, Y., Zuo, W., Lin, L., Yang, R., 2018. Learning warped guidance for blind face restoration.\nIn: Proceedings of the European Conference on Computer Vision (ECCV). pp. 272–289.\n[128] Li, Z., Wu, J., 2019. Learning deep cnn denoiser priors for depth image inpainting. Applied Sciences 9 (6),\n1103.\n[129] Liang, J., Liu, R., 2015. Stacked denoising autoencoder and dropout together to prevent overﬁtting in deep\nneural network. In: 2015 8th International Congress on Image and Signal Processing (CISP). IEEE, pp. 697–\n701.\n[130] Liang, X., Zhang, D., Lu, G., Guo, Z., Luo, N., 2019. A novel multicamera system for high-speed touchless\npalm recognition. IEEE Transactions on Systems, Man, and Cybernetics: Systems.\n[131] Lin, K., Li, T. H., Liu, S., Li, G., 2019. Real photographs denoising with noise domain adaptation and attentive\ngenerative adversarial network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition Workshops. pp. 0–0.\n[132] Lin, M., Chen, Q., Yan, S., 2013. Network in network. arXiv preprint arXiv:1312.4400.\n[133] Litjens, G., Kooi, T., Bejnordi, B. E., Setio, A. A. A., Ciompi, F., Ghafoorian, M., Van Der Laak, J. A.,\nVan Ginneken, B., S´anchez, C. I., 2017. A survey on deep learning in medical image analysis. Medical Image\nAnalysis 42, 60–88.\n[134] Liu, D., Wen, B., Liu, X., Wang, Z., Huang, T. S., 2017. When image denoising meets high-level vision tasks:\nA deep learning approach. arXiv preprint arXiv:1706.04284.\n[135] Liu, P., Fang, R., 2017. Wide inference network for image denoising via learning pixel-distribution prior. arXiv\npreprint arXiv:1707.05414.\n[136] Liu, P., Li, Y., El Basha, M. D., Fang, R., 2018. Neural network evolution using expedited genetic algorithm for\nmedical image denoising. In: International Conference on Medical Image Computing and Computer-Assisted\n33\nIntervention. Springer, pp. 12–20.\n[137] Liu, P., Zhang, H., Zhang, K., Lin, L., Zuo, W., 2018. Multi-level wavelet-cnn for image restoration. In:\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. pp. 773–782.\n[138] Liu, Q., Lu, X., He, Z., Zhang, C., Chen, W.-S., 2017. Deep convolutional neural networks for thermal infrared\nobject tracking. Knowledge-Based Systems 134, 189–198.\n[139] Liu, W., Lee, J., 2019. A 3-d atrous convolution neural network for hyperspectral image denoising. IEEE\nTransactions on Geoscience and Remote Sensing.\n[140] Liu, X., Suganuma, M., Sun, Z., Okatani, T., 2019. Dual residual networks leveraging the potential of paired\noperations for image restoration. In: Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition. pp. 7007–7016.\n[141] Lo, S.-C., Lou, S.-L., Lin, J.-S., Freedman, M. T., Chien, M. V., Mun, S. K., 1995. Artiﬁcial convolution neural\nnetwork techniques and applications for lung nodule detection. IEEE Transactions on Medical Imaging 14 (4),\n711–718.\n[142] LOO TIANG KUAN, L., 2017. Survey of deep neural networks in blind denoising using different architectures\nand different labels. Ph.D. thesis.\n[143] Lu, Y., Lai, Z., Li, X., Wong, W. K., Yuan, C., Zhang, D., 2018. Low-rank 2-d neighborhood preserving\nprojection for enhanced robust image representation. IEEE Transactions on Cybernetics 49 (5), 1859–1872.\n[144] Lu, Y., Wong, W., Lai, Z., Li, X., 2019. Robust ﬂexible preserving embedding. IEEE Transactions on Cyber-\nnetics.\n[145] Lu, Z., Yu, Z., Ya-Li, P., Shi-Gang, L., Xiaojun, W., Gang, L., Yuan, R., 2018. Fast single image super-\nresolution via dilated residual networks. IEEE Access.\n[146] Lucas, A., Iliadis, M., Molina, R., Katsaggelos, A. K., 2018. Using deep neural networks for inverse problems\nin imaging: beyond analytical methods. IEEE Signal Processing Magazine 35 (1), 20–36.\n[147] Ma, K., Duanmu, Z., Wu, Q., Wang, Z., Yong, H., Li, H., Zhang, L., 2016. Waterloo exploration database: New\nchallenges for image quality assessment models. IEEE Transactions on Image Processing 26 (2), 1004–1016.\n[148] Ma, Y., Chen, X., Zhu, W., Cheng, X., Xiang, D., Shi, F., 2018. Speckle noise reduction in optical coherence\ntomography images based on edge-sensitive cgan. Biomedical Optics Express 9 (11), 5129–5146.\n[149] Maﬁ, M., Martin, H., Cabrerizo, M., Andrian, J., Barreto, A., Adjouadi, M., 2018. A comprehensive survey on\nimpulse and gaussian denoising ﬁlters for digital images. Signal Processing.\n[150] Mairal, J., Bach, F. R., Ponce, J., Sapiro, G., Zisserman, A., 2009. Non-local sparse models for image restora-\ntion. In: ICCV. Vol. 29. Citeseer, pp. 54–62.\n[151] Majumdar, A., 2018. Blind denoising autoencoder. IEEE Transactions on Neural Networks and Learning Sys-\ntems 30 (1), 312–317.\n[152] Mao, X., Shen, C., Yang, Y.-B., 2016. Image restoration using very deep convolutional encoder-decoder net-\nworks with symmetric skip connections. In: Advances in Neural Information Processing Systems. pp. 2802–\n2810.\n[153] Marinˇc, T., Srinivasan, V., G¨ul, S., Hellge, C., Samek, W., 2019. Multi-kernel prediction networks for denoising\nof burst images. In: 2019 IEEE International Conference on Image Processing (ICIP). IEEE, pp. 2404–2408.\n[154] Marreiros, A. C., Daunizeau, J., Kiebel, S. J., Friston, K. J., 2008. Population dynamics: variance and the\nsigmoid activation function. Neuroimage 42 (1), 147–157.\n[155] McCann, M. T., Jin, K. H., Unser, M., 2017. Convolutional neural networks for inverse problems in imaging:\nA review. IEEE Signal Processing Magazine 34 (6), 85–95.\n[156] Meinhardt, T., Moller, M., Hazirbas, C., Cremers, D., 2017. Learning proximal operators: Using denoising\nnetworks for regularizing inverse imaging problems. In: Proceedings of the IEEE International Conference on\nComputer Vision. pp. 1781–1790.\n[157] Meng, M., Li, S., Yao, L., Li, D., Zhu, M., Gao, Q., Xie, Q., Zhao, Q., Bian, Z., Huang, J., et al., 2020. Semi-\nsupervised learned sinogram restoration network for low-dose ct image reconstruction. In: Medical Imaging\n2020: Physics of Medical Imaging. Vol. 11312. International Society for Optics and Photonics, p. 113120B.\n[158] Mildenhall, B., Barron, J. T., Chen, J., Sharlet, D., Ng, R., Carroll, R., 2018. Burst denoising with kernel\nprediction networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\npp. 2502–2510.\n34\n[159] Nair, V., Hinton, G. E., 2010. Rectiﬁed linear units improve restricted boltzmann machines. In: Proceedings of\nthe 27th international conference on machine learning (ICML-10). pp. 807–814.\n[160] Nam, S., Hwang, Y., Matsushita, Y., Joo Kim, S., 2016. A holistic approach to cross-channel image noise\nmodeling and its application to image denoising. In: Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition. pp. 1683–1691.\n[161] Nossek, J., Roska, T., 1993. Special issue on cellular neural networks-introduction.\n[162] Nvidia, C., 2011. Nvidia cuda c programming guide. Nvidia Corporation 120 (18), 8.\n[163] Osher, S., Burger, M., Goldfarb, D., Xu, J., Yin, W., 2005. An iterative regularization method for total variation-\nbased image restoration. Multiscale Modeling & Simulation 4 (2), 460–489.\n[164] Paik, J. K., Katsaggelos, A. K., 1992. Image restoration using a modiﬁed hopﬁeld network. IEEE Transactions\non Image Processing 1 (1), 49–63.\n[165] Panda, A., Naskar, R., Pal, S., 2018. Exponential linear unit dilated residual network for digital image denois-\ning. Journal of Electronic Imaging 27 (5), 053024.\n[166] Pardasani, R., Shreemali, U., 2018. Image denoising and super-resolution using residual learning of deep\nconvolutional network. arXiv preprint arXiv:1809.08229.\n[167] Park, J. H., Kim, J. H., Cho, S. I., 2018. The analysis of cnn structure for image denoising. In: 2018 Interna-\ntional SoC Design Conference (ISOCC). IEEE, pp. 220–221.\n[168] Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., Lerer,\nA., 2017. Automatic differentiation in pytorch.\n[169] Peng, Y., Zhang, L., Liu, S., Wu, X., Zhang, Y., Wang, X., 2019. Dilated residual networks with symmetric\nskip connection for image denoising. Neurocomputing 345, 67–76.\n[170] Pitas, I., Venetsanopoulos, A., 1986. Nonlinear mean ﬁlters in image processing. IEEE Transactions on Acous-\ntics, Speech, and Signal Processing 34 (3), 573–584.\n[171] Plotz, T., Roth, S., 2017. Benchmarking denoising algorithms with real photographs. In: Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition. pp. 1586–1595.\n[172] Priyanka, S. A., Wang, Y.-K., 2019. Fully symmetric convolutional network for effective image denoising.\nApplied Sciences 9 (4), 778.\n[173] Radford, A., Metz, L., Chintala, S., 2015. Unsupervised representation learning with deep convolutional gen-\nerative adversarial networks. arXiv preprint arXiv:1511.06434.\n[174] Ran, M., Hu, J., Chen, Y., Chen, H., Sun, H., Zhou, J., Zhang, Y., 2019. Denoising of 3d magnetic resonance\nimages using a residual encoder–decoder wasserstein generative adversarial network. Medical Image Analysis\n55, 165–180.\n[175] Remez, T., Litany, O., Giryes, R., Bronstein, A. M., 2018. Class-aware fully convolutional gaussian and poisson\ndenoising. IEEE Transactions on Image Processing 27 (11), 5707–5722.\n[176] Ren, D., Shang, W., Zhu, P., Hu, Q., Meng, D., Zuo, W., 2020. Single image deraining using bilateral recurrent\nnetwork. IEEE Transactions on Image Processing.\n[177] Ren, D., Zuo, W., Hu, Q., Zhu, P., Meng, D., 2019. Progressive image deraining networks: a better and simpler\nbaseline. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3937–\n3946.\n[178] Ren, D., Zuo, W., Zhang, D., Zhang, L., Yang, M.-H., 2019. Simultaneous ﬁdelity and regularization learning\nfor image restoration. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n[179] Ren, W., Liu, S., Ma, L., Xu, Q., Xu, X., Cao, X., Du, J., Yang, M.-H., 2019. Low-light image enhancement\nvia a deep hybrid network. IEEE Transactions on Image Processing 28 (9), 4364–4375.\n[180] Ren, W., Pan, J., Zhang, H., Cao, X., Yang, M.-H., 2020. Single image dehazing via multi-scale convolutional\nneural networks with holistic edges. International Journal of Computer Vision 128 (1), 240–259.\n[181] Roth, S., Black, M. J., 2005. Fields of experts: A framework for learning image priors. In: 2005 IEEE Computer\nSociety Conference on Computer Vision and Pattern Recognition (CVPR’05). Vol. 2. Citeseer, pp. 860–867.\n[182] Sadda, P., Qarni, T., 2018. Real-time medical video denoising with deep learning: application to angiography.\nInternational journal of applied information systems 12 (13), 22.\n[183] Schmidhuber, J., 2015. Deep learning in neural networks: An overview. Neural Networks 61, 85–117.\n[184] Schmidt, U., Roth, S., 2014. Shrinkage ﬁelds for effective image restoration. In: Proceedings of the IEEE\n35\nConference on Computer Vision and Pattern Recognition. pp. 2774–2781.\n[185] Shantia, A., Timmers, R., Schomaker, L., Wiering, M., 2015. Indoor localization by denoising autoencoders\nand semi-supervised learning in 3d simulated environment. In: 2015 International Joint Conference on Neural\nNetworks (IJCNN). IEEE, pp. 1–7.\n[186] Sheremet, O., Sheremet, K., Sadovoi, O., Sokhina, Y., 2018. Convolutional neural networks for image de-\nnoising in infocommunication systems. In: 2018 International Scientiﬁc-Practical Conference Problems of\nInfocommunications. Science and Technology (PIC S&T). IEEE, pp. 429–432.\n[187] Shwartz-Ziv, R., Tishby, N., 2017. Opening the black box of deep neural networks via information. arXiv\npreprint arXiv:1703.00810.\n[188] Si, X., Yuan, Y., 2018. Random noise attenuation based on residual learning of deep convolutional neural\nnetwork. In: SEG Technical Program Expanded Abstracts 2018. Society of Exploration Geophysicists, pp.\n1986–1990.\n[189] Simonyan, K., Zisserman, A., 2014. Very deep convolutional networks for large-scale image recognition. arXiv\npreprint arXiv:1409.1556.\n[190] Sivakumar, K., Desai, U. B., 1993. Image restoration using a multilayer perceptron with a multilevel sigmoidal\nfunction. IEEE Transactions on Signal Processing 41 (5), 2018–2022.\n[191] Soltanayev, S., Chun, S. Y., 2018. Training deep learning based denoisers without ground truth data. In: Ad-\nvances in Neural Information Processing Systems. pp. 3257–3267.\n[192] Song, Y., Zhu, Y., Du, X., 2019. Dynamic residual dense network for image denoising. Sensors 19 (17), 3809.\n[193] Stone, J. E., Gohara, D., Shi, G., 2010. Opencl: A parallel programming standard for heterogeneous computing\nsystems. Computing in science & engineering 12 (3), 66.\n[194] Su, Y., Lian, Q., Zhang, X., Shi, B., Fan, X., 2019. Multi-scale cross-path concatenation residual network for\npoisson denoising. IET Image Processing.\n[195] Sun, X., Kottayil, N. K., Mukherjee, S., Cheng, I., 2018. Adversarial training for dual-stage image denoising\nenhanced with feature matching. In: International Conference on Smart Multimedia. Springer, pp. 357–366.\n[196] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich,\nA., 2015. Going deeper with convolutions. In: Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition. pp. 1–9.\n[197] Tai, Y., Yang, J., Liu, X., Xu, C., 2017. Memnet: A persistent memory network for image restoration. In:\nProceedings of the IEEE international Conference on Computer Vision. pp. 4539–4547.\n[198] Tamura, S., 1989. An analysis of a noise reduction neural network. In: International Conference on Acoustics,\nSpeech, and Signal Processing,. IEEE, pp. 2001–2004.\n[199] Tan, H., Xiao, H., Lai, S., Liu, Y., Zhang, M., 2019. Deep residual learning for burst denoising. In: 2019 IEEE\n4th International Conference on Image, Vision and Computing (ICIVC). IEEE, pp. 156–161.\n[200] Tao, L., Zhu, C., Song, J., Lu, T., Jia, H., Xie, X., 2017. Low-light image enhancement using cnn and bright\nchannel prior. In: 2017 IEEE International Conference on Image Processing (ICIP). IEEE, pp. 3215–3219.\n[201] Tao, L., Zhu, C., Xiang, G., Li, Y., Jia, H., Xie, X., 2017. Llcnn: A convolutional neural network for low-light\nimage enhancement. In: 2017 IEEE Visual Communications and Image Processing (VCIP). IEEE, pp. 1–4.\n[202] Tassano, M., Delon, J., Veit, T., 2019. An analysis and implementation of the ffdnet image denoising method.\nImage Processing On Line 9, 1–25.\n[203] Tassano, M., Delon, J., Veit, T., 2019. Dvdnet: A fast network for deep video denoising. In: 2019 IEEE\nInternational Conference on Image Processing (ICIP). IEEE, pp. 1805–1809.\n[204] Tian, C., Xu, Y., Fei, L., Wang, J., Wen, J., Luo, N., 2019. Enhanced cnn for image denoising. CAAI Transac-\ntions on Intelligence Technology 4 (1), 17–23.\n[205] Tian, C., Xu, Y., Fei, L., Yan, K., 2018. Deep learning for image denoising: a survey. In: International Confer-\nence on Genetic and Evolutionary Computing. Springer, pp. 563–572.\n[206] Tian, C., Xu, Y., Li, Z., Zuo, W., Fei, L., Liu, H., 2020. Attention-guided cnn for image denoising. Neural\nNetworks.\n[207] Tian, C., Xu, Y., Zuo, W., 2020. Image denoising using deep cnn with batch renormalization. Neural Networks\n121, 461–473.\n[208] Tian, C., Xu, Y., Zuo, W., Du, B., Lin, C.-W., Zhang, D., 2020. Designing and training of a dual cnn for image\n36\ndenoising. arXiv preprint arXiv:2007.03951.\n[209] Tian, C., Xu, Y., Zuo, W., Zhang, B., Fei, L., Lin, C.-W., 2020. Coarse-to-ﬁne cnn for image super-resolution.\nIEEE Transactions on Multimedia.\n[210] Tian, C., Zhuge, R., Wu, Z., Xu, Y., Zuo, W., Chen, C., Lin, C.-W., 2020. Lightweight image super-resolution\nwith enhanced cnn. Knowledge-Based Systems, 106235.\n[211] Tran, L., Yin, X., Liu, X., 2017. Disentangled representation learning gan for pose-invariant face recognition.\nIn: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1415–1424.\n[212] Tripathi, S., Lipton, Z. C., Nguyen, T. Q., 2018. Correction by projection: Denoising images with generative\nadversarial networks. arXiv preprint arXiv:1803.04477.\n[213] Uchida, K., Tanaka, M., Okutomi, M., 2018. Non-blind image restoration based on convolutional neural net-\nwork. In: 2018 IEEE 7th Global Conference on Consumer Electronics (GCCE). IEEE, pp. 40–44.\n[214] Vedaldi, A., Lenc, K., 2015. Matconvnet: Convolutional neural networks for matlab. In: Proceedings of the\n23rd ACM International Conference on Multimedia. ACM, pp. 689–692.\n[215] Vogel, C., Pock, T., 2017. A primal dual network for low-level vision problems. In: German Conference on\nPattern Recognition. Springer, pp. 189–202.\n[216] Wang, C., Zhou, S. K., Cheng, Z., 2020. First image then video: A two-stage network for spatiotemporal video\ndenoising. arXiv preprint arXiv:2001.00346.\n[217] Wang, H., Wang, Q., Gao, M., Li, P., Zuo, W., 2018. Multi-scale location-aware kernel representation for\nobject detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp.\n1248–1257.\n[218] Wang, T., Qin, Z., Zhu, M., 2017. An elu network with total variation for image denoising. In: International\nConference on Neural Information Processing. Springer, pp. 227–237.\n[219] Wang, T., Sun, M., Hu, K., 2017. Dilated deep residual network for image denoising. In: 2017 IEEE 29th\nInternational Conference on Tools with Artiﬁcial Intelligence (ICTAI). IEEE, pp. 1272–1279.\n[220] Wang, X., Dai, F., Ma, Y., Guo, J., Zhao, Q., Zhang, Y., 2019. Near-infrared image guided neural networks\nfor color image denoising. In: ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and\nSignal Processing (ICASSP). IEEE, pp. 3807–3811.\n[221] Wei, J., Xia, Y., Zhang, Y., 2019. M3net: A multi-model, multi-size, and multi-view deep neural network for\nbrain magnetic resonance image segmentation. Pattern Recognition 91, 366–378.\n[222] Wen, J., Xu, Y., Liu, H., 2020. Incomplete multiview spectral clustering with adaptive graph learning. IEEE\nTransactions on Cybernetics 50 (4), 1418–1429.\n[223] Wen, J., Zhang, Z., Zhang, Z., Fei, L., Wang, M., 2020. Generalized incomplete multiview clustering with\nﬂexible locality structure diffusion. IEEE Transactions on Cybernetics.\n[224] Wu, D., Ren, H., Li, Q., 2020. Self-supervised dynamic ct perfusion image denoising with deep neural net-\nworks. arXiv preprint arXiv:2005.09766.\n[225] Wu, S., Xu, Y., 2019. Dsn: A new deformable subnetwork for object detection. IEEE Transactions on Circuits\nand Systems for Video Technology.\n[226] Xia, Z., Perazzi, F., Gharbi, M., Sunkavalli, K., Chakrabarti, A., 2019. Basis prediction networks for effective\nburst denoising with large kernels. arXiv preprint arXiv:1912.04421.\n[227] Xiao, P., Guo, Y., Zhuang, P., 2018. Removing stripe noise from infrared cloud images via deep convolutional\nnetworks. IEEE Photonics Journal 10 (4), 1–14.\n[228] Xiao, X., Xiong, N. N., Lai, J., Wang, C.-D., Sun, Z., Yan, J., 2019. A local consensus index scheme for\nrandom-valued impulse noise detection systems. IEEE Transactions on Systems, Man, and Cybernetics: Sys-\ntems.\n[229] Xie, W., Li, Y., Jia, X., 2018. Deep convolutional networks with residual learning for accurate spectral-spatial\ndenoising. Neurocomputing 312, 372–381.\n[230] Xu, J., Li, H., Liang, Z., Zhang, D., Zhang, L., 2018. Real-world noisy image denoising: A new benchmark.\narXiv preprint arXiv:1804.02603.\n[231] Xu, J., Zhang, L., Zhang, D., 2018. External prior guided internal prior learning for real-world noisy image\ndenoising. IEEE Transactions on Image Processing 27 (6), 2996–3010.\n[232] Xu, J., Zhang, L., Zhang, D., 2018. A trilateral weighted sparse coding scheme for real-world image denoising.\n37\nIn: Proceedings of the European Conference on Computer Vision (ECCV). pp. 20–36.\n[233] Xu, J., Zhang, L., Zuo, W., Zhang, D., Feng, X., 2015. Patch group based nonlocal self-similarity prior learning\nfor image denoising. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 244–252.\n[234] Xu, Q., Zhang, C., Zhang, L., 2015. Denoising convolutional neural network. In: 2015 IEEE International\nConference on Information and Automation. IEEE, pp. 1184–1187.\n[235] Xu, X., Li, M., Sun, W., 2019. Learning deformable kernels for image and video denoising. arXiv preprint\narXiv:1904.06903.\n[236] Yan, H., Tan, V., Yang, W., Feng, J., 2019. Unsupervised image noise modeling with self-consistent gan. arXiv\npreprint arXiv:1906.05762.\n[237] Yang, D., Sun, J., 2017. Bm3d-net: A convolutional neural network for transform-domain collaborative ﬁlter-\ning. IEEE Signal Processing Letters 25 (1), 55–59.\n[238] Yang, J., Chu, D., Zhang, L., Xu, Y., Yang, J., 2013. Sparse representation classiﬁer steered discriminative\nprojection with applications to face recognition. IEEE Transactions on Neural Networks and Learning Systems\n24 (7), 1023–1035.\n[239] Yang, J., Liu, X., Song, X., Li, K., 2017. Estimation of signal-dependent noise level function using multi-\ncolumn convolutional neural network. In: 2017 IEEE International Conference on Image Processing (ICIP).\nIEEE, pp. 2418–2422.\n[240] Yang, J., Zhang, L., Xu, Y., Yang, J.-y., 2012. Beyond sparsity: The role of l1-optimizer in pattern classiﬁcation.\nPattern Recognition 45 (3), 1104–1118.\n[241] Yao, Y., Wu, X., Zhang, L., Shan, S., Zuo, W., 2018. Joint representation and truncated inference learning for\ncorrelation ﬁlter based tracking. In: Proceedings of the European Conference on Computer Vision (ECCV).\npp. 552–567.\n[242] Ye, J. C., Han, Y., Cha, E., 2018. Deep convolutional framelets: A general deep learning framework for inverse\nproblems. SIAM Journal on Imaging Sciences 11 (2), 991–1048.\n[243] Yeh, R. A., Lim, T. Y., Chen, C., Schwing, A. G., Hasegawa-Johnson, M., Do, M., 2018. Image restoration with\ndeep generative models. In: 2018 IEEE International Conference on Acoustics, Speech and Signal Processing\n(ICASSP). IEEE, pp. 6772–6776.\n[244] Yi, D., Lei, Z., Liao, S., Li, S. Z., 2014. Learning face representation from scratch. arXiv preprint\narXiv:1411.7923.\n[245] Yu, A., Liu, X., Wei, X., Fu, T., Liu, D., 2018. Generative adversarial networks with dense connection for\noptical coherence tomography images denoising. In: 2018 11th International Congress on Image and Signal\nProcessing, BioMedical Engineering and Informatics (CISP-BMEI). IEEE, pp. 1–5.\n[246] Yu, S., Ma, J., Wang, W., 2019. Deep learning for denoising. Geophysics 84 (6), V333–V350.\n[247] Yuan, D., Fan, N., He, Z., 2020. Learning target-focusing convolutional regression model for visual object\ntracking. Knowledge-Based Systems, 105526.\n[248] Yuan, D., Li, X., He, Z., Liu, Q., Lu, S., 2020. Visual object tracking with adaptive structural convolutional\nnetwork. Knowledge-Based Systems, 105554.\n[249] Yuan, Q., Zhang, Q., Li, J., Shen, H., Zhang, L., 2018. Hyperspectral image denoising employing a spatial–\nspectral deep residual convolutional neural network. IEEE Transactions on Geoscience and Remote Sensing\n57 (2), 1205–1218.\n[250] Yuan, Y., Liu, S., Zhang, J., Zhang, Y., Dong, C., Lin, L., 2018. Unsupervised image super-resolution using\ncycle-in-cycle generative adversarial networks. In: Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition Workshops. pp. 701–710.\n[251] Yue, Z., Yong, H., Zhao, Q., Meng, D., Zhang, L., 2019. Variational denoising network: Toward blind noise\nmodeling and removal. In: Advances in Neural Information Processing Systems. pp. 1688–1699.\n[252] Zamparelli, M., 1997. Genetically trained cellular neural networks. Neural Networks 10 (6), 1143–1151.\n[253] Zarshenas, A., Suzuki, K., 2018. Deep neural network convolution for natural image denoising. In: 2018 IEEE\nInternational Conference on Systems, Man, and Cybernetics (SMC). IEEE, pp. 2534–2539.\n[254] Zha, Z., Yuan, X., Yue, T., Zhou, J., 2018. From rank estimation to rank approximation: Rank residual con-\nstraint for image denoising. arXiv preprint arXiv:1807.02504.\n[255] Zhang, B., Jin, S., Xia, Y., Huang, Y., Xiong, Z., 2020. Attention mechanism enhanced kernel prediction\n38\nnetworks for denoising of burst images. In: ICASSP 2020-2020 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP). IEEE, pp. 2083–2087.\n[256] Zhang, F., Liu, D., Wang, X., Chen, W., Wang, W., 2018. Random noise attenuation method for seismic data\nbased on deep residual networks. In: International Geophysical Conference, Beijing, China, 24-27 April 2018.\nSociety of Exploration Geophysicists and Chinese Petroleum Society, pp. 1774–1777.\n[257] Zhang, J., Ghanem, B., 2018. Ista-net: Interpretable optimization-inspired deep network for image compressive\nsensing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1828–1837.\n[258] Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L., 2017. Beyond a gaussian denoiser: Residual learning of\ndeep cnn for image denoising. IEEE Transactions on Image Processing 26 (7), 3142–3155.\n[259] Zhang, K., Zuo, W., Gu, S., Zhang, L., 2017. Learning deep cnn denoiser prior for image restoration. In:\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3929–3938.\n[260] Zhang, K., Zuo, W., Zhang, L., 2018. Ffdnet: Toward a fast and ﬂexible solution for cnn-based image denoising.\nIEEE Transactions on Image Processing 27 (9), 4608–4622.\n[261] Zhang, K., Zuo, W., Zhang, L., 2018. Learning a single convolutional super-resolution network for multiple\ndegradations. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3262–\n3271.\n[262] Zhang, K., Zuo, W., Zhang, L., 2019. Deep plug-and-play super-resolution for arbitrary blur kernels. In: Pro-\nceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1671–1681.\n[263] Zhang, L., Wu, X., Buades, A., Li, X., 2011. Color demosaicking by local directional interpolation and nonlocal\nadaptive thresholding. Journal of Electronic imaging 20 (2), 023016.\n[264] Zhang, L., Zhang, L., Mou, X., Zhang, D., 2011. Fsim: A feature similarity index for image quality assessment.\nIEEE transactions on Image Processing 20 (8), 2378–2386.\n[265] Zhang, L., Zuo, W., 2017. Image restoration: From sparse and low-rank priors to deep priors [lecture notes].\nIEEE Signal Processing Magazine 34 (5), 172–179.\n[266] Zhang, M., Zhang, F., Liu, Q., Wang, S., 2019. Vst-net: Variance-stabilizing transformation inspired network\nfor poisson denoising. Journal of Visual Communication and Image Representation 62, 12–22.\n[267] Zhang, Z., Geiger, J., Pohjalainen, J., Mousa, A. E.-D., Jin, W., Schuller, B., 2018. Deep learning for envi-\nronmentally robust speech recognition: An overview of recent developments. ACM Transactions on Intelligent\nSystems and Technology (TIST) 9 (5), 49.\n[268] Zhang, Z., Wang, L., Kai, A., Yamada, T., Li, W., Iwahashi, M., 2015. Deep neural network-based bottleneck\nfeature and denoising autoencoder-based dereverberation for distant-talking speaker identiﬁcation. EURASIP\nJournal on Audio, Speech, and Music Processing 2015 (1), 12.\n[269] Zhao, D., Ma, L., Li, S., Yu, D., 2019. End-to-end denoising of dark burst images using recurrent fully convo-\nlutional networks. arXiv preprint arXiv:1904.07483.\n[270] Zhao, H., Shao, W., Bao, B., Li, H., 2019. A simple and robust deep convolutional approach to blind image\ndenoising. In: Proceedings of the IEEE International Conference on Computer Vision Workshops. pp. 0–0.\n[271] Zheng, Y., Duan, H., Tang, X., Wang, C., Zhou, J., 2019. Denoising in the dark: Privacy-preserving deep neural\nnetwork based image denoising. IEEE Transactions on Dependable and Secure Computing.\n[272] ZhiPing, Q., YuanQi, Z., Yi, S., XiangBo, L., 2018. A new generative adversarial network for texture pre-\nserving image denoising. In: 2018 Eighth International Conference on Image Processing Theory, Tools and\nApplications (IPTA). IEEE, pp. 1–5.\n[273] Zhou, Y., Chellappa, R., Jenkins, B., 1987. A novel approach to image restoration based on a neural network.\nIn: Proceedings of the International Conference on Neural Networks, San Diego, California.\n[274] Zoran, D., Weiss, Y., 2011. From learning models of natural image patches to whole image restoration. In:\n2011 International Conference on Computer Vision. IEEE, pp. 479–486.\n[275] Zuo, W., Zhang, L., Song, C., Zhang, D., Gao, H., 2014. Gradient histogram estimation and preservation for\ntexture enhanced image denoising. IEEE Transactions on Image Processing 23 (6), 2459–2472.\n39\n",
  "categories": [
    "eess.IV",
    "cs.CV"
  ],
  "published": "2019-12-31",
  "updated": "2020-08-03"
}