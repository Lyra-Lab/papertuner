{
  "id": "http://arxiv.org/abs/2001.01432v3",
  "title": "Deep Learning-Based Solvability of Underdetermined Inverse Problems in Medical Imaging",
  "authors": [
    "Chang Min Hyun",
    "Seong Hyeon Baek",
    "Mingyu Lee",
    "Sung Min Lee",
    "Jin Keun Seo"
  ],
  "abstract": "Recently, with the significant developments in deep learning techniques,\nsolving underdetermined inverse problems has become one of the major concerns\nin the medical imaging domain. Typical examples include undersampled magnetic\nresonance imaging, interior tomography, and sparse-view computed tomography,\nwhere deep learning techniques have achieved excellent performances. Although\ndeep learning methods appear to overcome the limitations of existing\nmathematical methods when handling various underdetermined problems, there is a\nlack of rigorous mathematical foundations that would allow us to elucidate the\nreasons for the remarkable performance of deep learning methods. This study\nfocuses on learning the causal relationship regarding the structure of the\ntraining data suitable for deep learning, to solve highly underdetermined\ninverse problems. We observe that a majority of the problems of solving\nunderdetermined linear systems in medical imaging are highly non-linear.\nFurthermore, we analyze if a desired reconstruction map can be learnable from\nthe training data and underdetermined system.",
  "text": "DEEP LEARNING-BASED SOLVABILITY OF UNDERDETERMINED\nINVERSE PROBLEMS IN MEDICAL IMAGING ∗\nCHANG MIN HYUN†, SEONG HYEON BAEK†, MINGYU LEE†, SUNG MIN LEE†, AND\nJIN KEUN SEO†‡\nAbstract. Recently, with the signiﬁcant developments in deep learning techniques, solving un-\nderdetermined inverse problems has become one of the major concerns in the medical imaging domain,\nwhere underdetermined problems are motivated by the willingness to provide high resolution medical\nimages with as little data as possible, by optimizing data collection in terms of minimal acquisition\ntime, cost-eﬀectiveness, and low invasiveness. Typical examples include undersampled magnetic res-\nonance imaging(MRI), interior tomography, and sparse-view computed tomography(CT), where deep\nlearning techniques have achieved excellent performances. However, there is a lack of mathematical\nanalysis of why the deep learning method is performing well. This study aims to explain about learn-\ning the causal relationship regarding the structure of the training data suitable for deep learning, to\nsolve highly underdetermined problems. We present a particular low-dimensional solution model to\nhighlight the advantage of deep learning methods over conventional methods, where two approaches\nuse the prior information of the solution in a completely diﬀerent way. We also analyze whether\ndeep learning methods can learn the desired reconstruction map from training data in the three\nmodels (undersampled MRI, sparse-view CT, interior tomography). This paper also discusses the\nnonlinearity structure of underdetermined linear systems and conditions of learning (called M-RIP\ncondition).\nKey words. underdetermined linear inverse problem, deep learning, medical imaging, magnetic\nresonance imaging, computed tomography\nAMS subject classiﬁcations. 15A29, 65F22, 68T05, 68Q32\n1. Introduction. In medical imaging, we want to improve our visual ability to\nprovide meaningful expression and useful description of diagnosis and treatment, while\noptimizing data collection in terms of minimal acquisition time, cost-eﬀectiveness, and\nlow invasiveness. The goal is to ﬁnd a function f that maps from inputs (what we\nmeasure) to outputs (reconstructing useful medical images):\n(1.1)\nf(input data) = useful output.\nThe output could be the two- or three-dimensional visual representation of the interior\nof a body, such as computerized tomography (CT) [30, 50] and magnetic resonance\nimaging (MRI) [43, 23]. To achieve the output of reasonable resolution and accuracy,\nwe have used a suitable means of measurement (input), which allows to reconstruct\nthe output.\nConventional CT and MRI data collections are designed to obtain a well-posed\nreconstruction method in the sense that the corresponding forward models are well-\nposed. The forward model can be expressed as the well-posed linear system as follows:\n(1.2)\nAfully = bfull\nwhere bfull denotes the “fully sampled” data (e.g, sinogram in CT and k-space data\nin MRI), y denotes the CT or MRI image, and Afull denotes the invertible matrix\nrepresenting discrete Radon transform for CT and discrete Fourier transform for MRI.\nMore precisely, the forward model of CT is based on the assumption that the measured\n∗This work was supported by Samsung Science & Technology Foundation (No. SRFC-IT1902-09).\n†Department of Computational Science and Engineering, Yonsei University, Seoul, Korea\n‡To whom the corresponding author (seoj@yonsei.ac.kr)\n1\narXiv:2001.01432v3  [eess.IV]  26 Jun 2020\n2\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nX-ray projection data is the Radon transform of the output image. To achieve the\ngiven resolution of the output and invert the corresponding discrete Radon transform,\na suﬃcient number of projection angles are required so that the number of equations\n(measured data) becomes greater than the number of unknowns (the number of pixels\nin the image). Hence, given the resolution of the output, the traditional approaches\nrequire a certain amount of data acquisition in order to make the reconstruction\nproblem well-posed in the sense of Hadamard[24].\nBecause of the great needs to reduce the radiation dose in CT and data acqui-\nsition time in MRI, considerable attention has been given to solve underdetermined\nproblems (or ill-posed inverse problems) that violate the Nyquist criteria [52] in the\nsense that the number of equations is much smaller than the number of unknowns.\nThe demand for undersampled MRI is because of the long scan time with the human\nbody trapped in an inconvenient narrow bore; shortening the MRI scan time can\nincrease the satisfaction of patient, reduce the artifacts caused by patient movement,\nand reduce the medical costs [41, 45, 8, 15, 63]. The need for low-dose CT arises\nfrom the cancer risks associated with the exposure of patients to ionizing radiation\n[33, 42, 6]. A highly underdetermined problem (far less equations than unknowns)\ncorresponding to (1.2) can be expressed as follows:\n(1.3)\nA\n|{z}\nSsub(Afull)\ny =\nb\n|{z}\nSsub(bfull)\nwhere Ssub denotes a subsampling operator.\nFor example, in undersampled MRI,\nb = Ssub(bfull) denotes an undersampled k-space data violating the Nyquist sampling\ncriterion, and y denotes MRI image reconstructed using a fully sampled k-space data.\nBecause A is not an invertible matrix, there exist inﬁnitely many solutions.\nSolving the underdetermined problem (1.3) depends on the appropriate use of a\npriori information about medical CT or MRI images as solutions. However, the con-\nventional approaches using prior knowledge, such as regularization and compressed\nsensing(CS) approaches, may not be appropriate for medical images in which small\nanomalous details are more important than the overall feature [35]. Currently, deep\nlearning techniques have exhibited excellent achievement in various underdetermined\nproblems such as undersampled MRI, interior tomography, and sparse view CT. They\nseem to overcome the limitations of the existing mathematical methods in handling\nvarious ill-posed problems [36, 25, 31].\nIt is highly expected that deep learning\nmethodologies will improve their performance, as training data and experience are\naccumulated over time. However, there is a tremendous lack of a rigorous mathe-\nmatical foundation that would allow us to understand the reasons for the remarkable\nperformance of deep learning methods [38].\nThis study aims to provide a systematic basis for learning the causal relationship\nregarding the structure of the training data suitable for deep learning to solve highly\nunderdetermined problems. The goal of the undersampled problem (1.3) is to ﬁnd a\nreconstruction map f♭: b →y that maps from the highly undersampled data b to the\nimage y = A−1\nfullbfull in (1.2). Here, for ease of explanation, we ignore the noise in b and\nabuse the notation of A−1\nfull, which should be understood as representing the ﬁltered\nbackprojection (FBP) in CT and the inverse Fourier transform in MRI [61]. Without\nusing a constraint on y, one cannot ﬁnd the reconstruction map f♭. Hence, we must use\nthe prior knowledge on the data distribution of all possible images to be reconstructed.\nTo extract prior knowledge on solutions, deep learning-based techniques use training\ndata {(b(k), y(k))}ndata\nk=1 , where y(k) = A−1\nfullb(k)\nfull and b(k) = Ssubb(k)\nfull.\nUNDERDETERMINED INVERSE PROBLEMS\n3\nLearning f♭: b →y can be achieved by learning the following map:\n(1.4)\nf : x = A♯b 7→y = A−1\nfullbfull.\nwhere A♯= A−1\nfullS∗\nsub and S∗\nsub is the dual of Ssub, which can be understood as the\nzero padding operator corresponding to the subsampling Ssub. Using the transformed\ntraining data {(x(k), y(k))}ndata\nk=1 , where x(k) = A♯b(k), we consider the learning objec-\ntive as follows:\n(1.5)\nf = argmin\nf∈NN\nndata\nX\nk=1\n∥f(x(k)) −y(k)∥ℓ2\nwhere NN denotes a set of functions described in a special form of neural network and\n∥· ∥ℓp is the ℓp norm of the vector. Notably, this f in (1.5) is designed to work well\nonly on a low-dimensional solution manifold obtained by regressing the training data\n{y(k)}ndata\nk=1 , not on the entire image domain.\nThis paper aims to provide some mathematical grounds for the learnability of f\nby using various performance experiments. In Section 2.2, we present a particular\nlow-dimensional solution model to highlight the advantage of a deep learning method\nover conventional methods using PCA, wavelets, and total variation regularization. In\nSection 3, we discusses the nonlinearity structure of underdetermined linear systems\nand conditions of learning (called M-RIP condition). We observe that highly under-\ndetermined linear systems in medical imaging are highly non-linear. We also examine\nwhether a desired reconstruction map f : x →y can be learnable from the training\ndata. The learning ability depends on the subsampling strategy Ssub, and quality and\nquantity of training data. Section 3.1 investigates the learnability of undersampled\nMRI. It depends on the sampling pattern as follows: (i) If Ssub is a uniform subsam-\npling, f is not learnable because there exist two diﬀerent realistic images, namely,\ny and y′, such that A♯A(y −y′) = 0. (ii) If Ssub denotes a uniform sampling with\none additional phase encoding line, then f is learnable. We also deal with the learn-\nability of f in interior tomography (see Section 3.2) and sparse-view CT (see Section\n3.3). In interior tomography, f is learnable because f(x) −x is directionally analytic;\ntherefore, it is determined by the very local information of it. In sparse-view CT,\nf is somehow learnable because f(x) −x has common repetitive local patterns that\nare very diﬀerent from realistic images. Finally, in Section 4, we discuss some issues\nrelated to deep learning-based solvability for underdetermined problems.\n2. Analysis on Underdetermined Inverse Problem. This section considers\nthe underdetermined problem (1.3), where b represents the undersampled data (e.g.,\nk-space data in undersampled MRI and sinogram data in sparse-view CT and inte-\nrior tomography). We denote the dimensions of row and column vectors by n and\nm, respectively. Note that n is the same as the dimension of image. The relation\nbetween the undersampled data b and the corresponding fully sampled data bfull can\nbe expressed by\n(2.1)\nb = Ssub(bfull)\nwhere Ssub denotes the subsampling operator. Since A is m × n matrix with m ≪n,\nthe underdetermined problem (1.3) has inﬁnitely many solutions, which constitute\nthe n −m dimensional subplane given by the followings:\n(2.2)\nNb(A) := {y ∈Rn(or Cn) : Ay = b}\n4\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nSolving Underdetermined Problem: Ay “ b\nM1\nimage\nx “ A7b\nAimage\nMimage\ny “ Gphq\nNbpAq Ş Mimage “ tyu\nf : x “ A7b ÞÑ y\nA7A : y ÞÑ x\nK\nh\nG : h ÞÑ y\ngenerator\nNbpAq “ tz : Az “ bu\n“ t¨ ¨ ¨\n¨ ¨ ¨ u\nf is learnable if A satisﬁes M-RIP condition:\nc}y ´ y1} ď }Ay ´ Ay1} ď 1\nc}y ´ y1}, @y, y P Mimage\nFig. 1. Description of solvability of underdetermined inverse problem Ay = b. Solving Ay = b\ncan be achieved by learning f : x = A♯b 7→y = A−1\nfull bfull in (1.4) with probing the solution manifold\nMimage.\nIf A satisﬁes the M-RIP condition, then A♯A : Mimage 7→M′\nimage is one-to-one, i.e.,\nNb(A) ∩Mimage = {y} is unique. In general, f is nonlinear and the degree of non-linearity depends\non the sampling strategy of b and the degree of bending the solution manifold.\nTo ﬁnd f in (1.4), it is necessary to ﬁnd a way to convert the distorted image x = A♯b\nto the desired image y, which is selected from the set Nb(A). In order to determine\nthe unique solution among Nb(A), we have to restrict the solution by invoking the\nprior knowledge of expected solutions.\n2.1. Constrained reconstruction problem. Assume that Aimage is a set of\nall realistic images that include the set of all y = A−1\nfullbfull ∈Rn(or Cn), where bfull\ndenotes the fully sampled medical data. We consider the following constraint problem:\n(2.3)\n\u001a Solve Ay = b\nsubject to the constrait y ∈Aimage.\nIdeally, we hope that Nb(A) ∩Aimage = {y ∈Aimage : Ay = b} ̸= ∅, and that all the\nimages in the set Nb(A)∩Aimage are visually same for radiologists. Hence, it seems to\nbe necessary to describe a similarity measure between two images, y, y′ ∈Aimage, by\ndeﬁning the distance distradiologist(y, y′); e.g., distradiologist(y, y′) = 0 means that both\nimages are visually the same for radiologists. Currently, it seems to be considerably\ndiﬃcult to develop a concept of distradiologist(y, y′) that agrees with the perspective\nof medical radiologists. To simplify the problem (2.3) along with avoiding complex\nsimilarity issues in terms of radiologists, let us assume the following:\n[H1] Any image in Aimage lies on or near a low-dimensional manifold, which is\ndenoted by Mimage, whose Hausdorﬀdimension, which is denoted by dmfd, is\nsmaller than m (i.e., the dimension of sampled vector b).\n[H2] There exists a generator G : h ∈K →y ∈Rn such that the following hold:\n(2.4)\nMimage = {y ∈Rn : y = G(h) and h ∈K}\nwhere K denotes a subset of Rdmfd. Moreover, there exists a constant c ∈(0, 1]\nsuch that the following hold: For all h, h′ ∈K,\n(2.5)\nc∥h −h′∥≤∥G(h) −G(h′)∥≤1\nc ∥h −h′∥\nUNDERDETERMINED INVERSE PROBLEMS\n5\nh “ ph1, h2, ¨ ¨ ¨ , h7q\nh1\nh2\nLatent space K Ă R7\nGenerator G\nGphq “ ´ 1\n4πR˚I´1\n„\nln\nˆ\nsinhph7RχDhq\nh7RχDh\n˙\nGph1q\nGph2q\nImage space R256ˆ256\nMimage\nh1\n3\nh1\n4\nh1\n1\nh1\n2\nh1\n5\nh1\n6\nD2\nD1\nD1 “ Bpph1\n1, h1\n2q, h1\n5q\nD2 “ Bpph1\n3, h1\n4q, h1\n6q\nDh “ D1 Y D2\nFig. 2. Special solution manifold Mimage ⊂R256×256 to highlight the advantage of deep learning\nmethod over conventional methods.\nIt is generated by the generator function G in (2.10).\nThe\nmanifold Mimage is seven dimensional. Images in Mimage consist of two disks and a special streaking\nfeature joining the two disks.\n[H3] There exists a normalization map N : Aimage 7→Mimage such that if two images\ny, y′ ∈Aimage are visually the same for radiologists, then N(y) = N(y′).\nThe manifold Mimage can be viewed as a set of all 256×256 human head-MR images in\nundersampled MRI problems, or as a set of all 512×512 CT images in underdetermined\nCT problems. In the normalization map N, the diﬀerence y −N(y) can be a noise\nthat does not contain any diagnostic feature.\nIf we have both the generator G and the normalizer N in the above assump-\ntions [H1]–[H3], the underdetermined problem (2.3) becomes a somewhat well-posed\nproblem as follows:\n(2.6)\nGiven x = A♯b, solve AG(h) = Ax for h\nwhere the number of unknowns are smaller than the number of equations. A necessary\ncondition for the solvability of (2.6) is dmfd ≤n −m. Moreover, with the aid of the\ngenerator G, the very ambiguous distance distradiologist(y, y′) from the viewpoint of\nradiologist can be clearly deﬁned as ∥h−h′∥, where G(h) = N(y) and G(h′) = N(y′).\nHowever, ﬁnding both the generator G and the normalizer N may be very diﬃcult\ntask, which is expected to be achieved via deep learning techniques using a training\ndataset {y(k)}ndata\nk=1 in the near future.\nThe reconstruction map f : x →y in (1.4) can be expressed as\n(2.7)\nf(x) := argmin\ny∈Mimage\n∥A♯Ay −x∥2\nℓ2,\nby assuming that there exists a unique minimizer and that Mimage is known. Since it\nis very diﬃcult to know the manifold Mimage, one can achieve the reconstruction map\nf as follows:\n(2.8)\nf := argmin\nf∈NN\nndata\nX\nk=1\n∥f(x(k)) −y(k)∥2\nℓ2,\nwhere NN denotes a set of functions described in a special form of neural network.\nAn important question is “what is the minimum ratio of undersampling to provide\nguarantee of accurate reconstruction f in (2.7)?”. It is closely related to the dimension\nof the manifold Mimage and the capability of ﬁnding the generator G in [H2]. Currently,\n6\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nInput data x\nGround truth y\nLinear Approaches\nCS Approaches\nDeep Learning\nPCA\nFourier\nHaar Wavelet\nTotal Variation\nDb4 Wavelet\nU-net\nFig. 3. Empirical results using various reconstruction approaches for the sparse-view CT prob-\nlem with the special solution manifold in (2.9). For the linear projection approach, three diﬀerent\nlinear representations (PCA, Fourier, and Haar wavelet) of the input data were truncated at the\n800th term after arranging the terms in the descending order according to the absolute value of their\ncoeﬃcients. For implementing the CS approach, we applied the ℓ1 convex relaxation method using\ntwo diﬀerent transforms (total variation(TV) and Daubechies four tap(Db4) wavelet). An optimal\nregularization parameter was empirically selected between 0.01 and 1. Lastly, as the deep learning\ntechnique, U-net, trained by 800 training data pairs, is used.\nour explicit knowledge on the solution prior (i.e., Mimage) is very limited and hardly\nbuilt.\nTo clarify a concept of manifold prior, we try to solve and analyze underde-\ntermined problems subjected to the model manifold, which is well-understood in a\nmathematical framework.\n2.2. A special solution manifold: Comparison of conventional methods\nwith deep learning method. This section provides a novel example of a low-\ndimensional manifold Mimage to explain [H1]–[H3]. Using this manifold, we examine\nthe capability of solving the sparse-view CT model using various exiting methods such\nas linear approaches (e.g. PCA, truncated Fourier and wavelet transform), sparse\nsensing (e.g.\nTV and Dictionary learning), and deep learning (e.g.\nU-net).\nThis\nspecial solution manifold Mimage highlights the advantage of deep learning method\nUNDERDETERMINED INVERSE PROBLEMS\n7\nover conventional methods, where two approaches use prior information of the solution\nin a completely diﬀerent way.\nOur example of the manifold Mimage in [H1] is seven dimensional and given by\n(2.9)\nMimage := { G(h) ∈Rn : h ∈K}\nwhere n = 2562, K is a compact subset of R7, and the continuous version of G(h) is\ngiven by\n(2.10)\nG(h) = −1\n4π R∗I−1\n\u0014\nln\n\u0012sinh (h7RχDh)\nh7RχDh\n\u0013\u0015\nwhere the notations are the following:\n• R∗is the dual of the Radon transform R. (See Section 3.2 for details.)\n• I−1 is the Riesz potential of degree -1.\n• h = (h1, h2, · · · , h7).\n• Dh is a union of two disks with centers (h1, h2), (h2, h3) and radii h5, h6.\n• χD is the characteristic function of D.\nThis example originates from the paper [55], where the image of G(h) represents metal\nartifacts of CT in the presence of metallic objects occupied in the region Dh. Fig. 2\nshows images on the manifold Mimage.\nAssuming that G is known, consider the highly underdetermined problem (1.3)\nto ﬁnd the following reconstruction map:\n(2.11)\nf : x ∈M′\nimage 7→y ∈Mimage satisfying A♯Ay = x\nwhere\n(2.12)\nM′\nimage := { A♯AG(h) : h ∈K }\nIf m (the number of equations) is greater than seven, it is possible to ﬁnd f and this\nf can be obtained as follows:\n(2.13)\nf(x) = G(h),\nh = argmin\nh∈K\n∥A♯AG(h) −x∥2\nℓ2\nHowever, we do not know G in practice.\nIn the remaining part of this section, we examine the capability of various methods\nfor ﬁnding a reconstruction map f : x 7→y in (2.11) using the sparse-view CT model\ndescribed in Section 3.3. Let {(x(k), y(k))}ndata\nk=1 denote a training data set.\n2.2.1. Linear projection approach. This subsection explains that there may\nnot exist an appropriate low-dimensional linear projection that captures the variations\nin G(h). Principal component analysis (PCA) is widely used for the dimensionality\nreduction in which the unknown manifold Mimage is approximated by a linear subspace\nspanned by the set of principal components {dk}nPCA-basis\nk=1\n. To be precise, the ﬁrst\nprincipal component, d1, is obtained as follows:\n(2.14)\nd1 = argmax\n|d|=1\ndT YT Yd\nwhere Y := (y1, y2, · · · , yndata)T . Similarly, the second principal component, d2, is\nobtained by computing the ﬁrst principal component of matrix Y1 := Y −d1dT\n1 .\n8\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nCh\nCh\nSpantyp0q , ¨ ¨ ¨ , yp35q u\nyp0q\nyp1q\nyp0.5q\nyp0q\nyp1q\nyp2q\nProjV yp0.5q\n«\n1\n2 pyp0q ` yp1q q\nFig. 4. Linear dimensionality reduction methods such as PCA may provide a poor approxi-\nmation of the highly curved manifold in (2.16). Let V = span{y(k)}35\nk=0 where y(k) is the kπ/18\ndegree rotated image of the image y(0). Let y(0.5) be the π/36 degree rotated image of the image\ny(0). The projection of y(0.5) onto V is approximately equal to 1\n2 (y(0) +y(1)) that destroys the main\ncharacteristics of y(0.5).\nContinuing this process, we obtain the orthogonal basis {dk}nPCA-basis\nk=1\n. Subsequently,\nthe reconstruction map f is given by\n(2.15)\nf(x) = Dh,\nh = argmin\nh\n∥A♯ADh −x∥2\nℓ2\nwhere D denotes the matrix whose columns are {dk}nPCA-basis\nk=1\n.\nFig. 4 depicts that PCA fails to provide satisfactory approximations of images\nin the unknown manifold Mimage, because the low dimensional subspace spanned by\nthe principal components cannot suﬃciently cover the nonlinearity of the solution\nmanifold. In Fig. 4, Ch represents the following one-dimensional curve lying on the\nmanifold Mimage:\n(2.16)\nCh := {G(Tθh) : 0 < θ ≤2π}, Tθ =\n\n\nRθ\n0\n0\n0\nRθ\n0\n0\n0\nI\n\n\nwhere Rθ is the rotation matrix with angle θ, I is 3 × 3 identity matrix, and 0\nhere denotes the corresponding zero matrix. The plane in Fig. 4 represents the 36-\ndimensional space spanned by the sampled images {y(k)}35\nk=0, which are sampled at\nθ =\nk\n362π, k = 0, · · · , 35, on the curve Ch. Although Ch is the map of the simple circle\n{Tθh : 0 < θ ≤2π} (in the latent space) through the generator function G, it is highly\ncurved and complex due to the severe nonlinearity of function G. Therefore, with the\nlimited expressivity of PCA [56], one cannot adequately approximate the curve Ch by\nusing the plane spanned by {y(k)}35\nk=0.\nFig. 3 depict that linear approaches, including PCA, in solving the underdeter-\nmined problem (1.3) result in the signiﬁcant loss of information from the original\nimage. The inability of the linear projection approach to provide the global approxi-\nmation of the highly curved image manifold is the reason for such poor reconstruction\nresults.\n2.2.2. Compressed sensing approach. Compressed sensing(CS) is based on\nthe assumption that y ∈Mimage has sparse representation under a basis {dk}nCS-basis\nk=1\n,\nUNDERDETERMINED INVERSE PROBLEMS\n9\nLearn f by updating\nWl`1 “ Wl ´ β∇p 1\nndata\nndata\nř\nk“1\n}fpxpkqq ´ ypkq}q\n[Training Process]\nxpk´1q\nxpkq\nxpk`1q\nypk´1q\nypkq\nypk`1q\nt\nu\n,\n,\n“ txpkqundata\nk“1 Ď M1\nimage\nu\nt\n,\n,\n“ typkqundata\nk“1 Ď Mimage\n¨ ¨ ¨\n¨ ¨ ¨\n¨ ¨ ¨\n¨ ¨ ¨\nxpkq “ A7Aypkq\nf “ argmin\nfPNN\np 1\nndata\nndata\nř\nk“1\n}fpxpkqq ´ ypkq}q\n[Test Evaluation]\nxtest\nxtest\nytest\n(hope)\nP M1\nimageztxpkqundata\nk“1\nfp\nq«\nP Mimage\nFig. 5. Deep learning framework for estimating the reconstruction map f : x 7→y. For a given\ndeep learning network and training dataset {x(k), y(k)}ndata\nk=1 , the reconstruction map f is obtained\nby minimizing the discrepancy between the network outputs {f(x(k))}ndata\nk=1 and the corresponding\nlabels {y(k)}ndata\nk=1 . Despite the ﬁnite number of training data, we hope the function f to provide an\naccurate approximation of the test label ytest for any unobserved test data xtest ∈M′\nimage \\{x(k)}ndata\nk=1 .\ni.e.,\n(2.17)\ny = Dh\ns.t. ∥h∥ℓ0 ≪nCS-basis\nwhere D is a matrix whose k-th column corresponds to dk and ∥h∥ℓ0 is the number of\nnon-zero entries of h. In CS, ℓ1 convex relaxation methods are widely used to make\nthe problem computationally feasible. A sparse approximation to the solution of the\nunderdetermined problem (1.3) is obtained as follows:\n(2.18)\nf(x) = Dh,\nh = argmin\nh\n∥A♯ADh −x∥2\nℓ2 + λ∥h∥ℓ1\nwhere λ is a regularization parameter that controls the trade-oﬀbetween data ﬁdelity\nand the regularity enforcing the sparsity of h. Kindly refer to [16, 15, 9, 11, ?] for\nadditional details. We implement the CS technique by using several wavelet bases,\nwhich are eﬃcient in CS applications for natural images [14, 47]. However, the re-\nconstruction results from Fig. 3 show that some details are not preserved in the CS\nprocess.\nThe total variation(TV)-based CS method imposes a sparsity of the image gradi-\nent, where f(x) can be obtained as follows:\n(2.19)\nf(x) = argmin\ny\n∥A♯Ay −x∥2\nℓ2 + λ∥∇y∥ℓ1\nFig.\n3 shows that TV-based CS method also eliminates some of the details.\nTV\nmethod does not selectively preserve the streaking feature lying between two disks,\nwhile removing the other artifacts.\nDictionary learning [54, 2] utilizes the given training data to ﬁnd a (redundant and\ndata-driven) basis {dk}ndic\nk=1 that can represent every y ∈Mimage as a sparse vector.\nA learned dictionary can handle a speciﬁc problem considerably better than analysis-\ndriven dictionaries (e.g. wavelet and framelet) [17, 1, 46, 68, 59]. Dictionary learning\napproaches have a drawback in dealing with high-dimensional data due to the huge\ncomputational complexity; hence, the patch-based approach (e.g. image patch of size\n8 × 8 pixels) has been adopted in most image processing applications. However, this\napproach might not be ﬁt for the tasks for which the global information should be\nsuﬃciently incorporated.\n10\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\n32\n32\n32\n64\n64\n64\n128\n128\n128\n256\n128\n256\n128\n64\n128\n64\n32\n64\n32\n32\nU-net (= f)\n≈\nxtest\nTest data\nf(xtest)\nTest output\nTest label\nytest\n→: 3 × 3 Convolution with Batch Normalization and ReLU Activation\n→: 1 × 1 Convolution\n→: 2 × 2 Max Pooling\n→: 2 × 2 Avg Unpooling\n→: Copy and Concat\nFig. 6.\nDeep learning approach using U-net for solving the sparse-view CT model with the\nspecial solution manifold.\nBy training U-net with 800 data pairs, the reconstruction function f\nis obtained. In Tensorﬂow environment, the minimization process was performed by using Batch\nnormalization and Adam optimizer with learning rate 0.001, mini-batch size 16, and 1000 epochs.\nFor a given test data xtest, the reconstruction function f provides the test output f(xtest) which\napproximates the test label ytest.\n2.2.3. Deep learning approach. Deep learning techniques expand our ability\nto solve underdetermined problems via sophisticated learning process by using group-\ndata ﬁdelity of the training data; furthermore, they appear to eﬀectively deal with\nthe limitations of the existing mathematical methods in handling various ill-posed\nproblems. In CS, f(x) in (2.19) can be viewed as a solution of the nonlinear Euler-\nLagrange equation associated with the trade-oﬀbetween two separative competitive\nobjectives of maximizing the “single data ﬁdelity” and minimizing TV (as a sparse\nprior of natural images). However, this sparse prior may not be appropriate for pre-\nserving small features that contain clinically useful information. In contrast, the deep\nlearning approach (1.5) utilizes “group-data ﬁdelity” to estimate the reconstruction\nmap f : x 7→y by seemingly probing the relationship between unknown manifolds\nMimage and M′\nimage. The reconstruction f is obtained by minimizing the group-data\ndiscrepancy Pndata\nk=1 ∥f(x(k)) −y(k)∥(i.e. maximizing the group-data ﬁdelity) on a\nﬁnite number of training pairs {(x(k), y(k))}ndata\nk=1 lying on M′\nimage × Mimage, as shown\nin Fig. 5.\nIn particular, U-net [58] has achieved enormous success in ﬁnding the map for\nvarious underdetermined medical imaging problems [31, 36, 25]. In U-net, the network\narchitecture of f comprises a contraction path Φ : x 7→h and an expansion path\nΨ : h 7→y; f(x) = Ψ ◦Φ(x). To be precise, the simplest form of the contraction path\nΦ is expressed by\n(2.20)\nh = Φ(x) = σ(w3 ⊛P(σ(w2 ⊛σ(w1 ⊛x + c1) + c2)) + c3)\nand the corresponding expansive path Ψ is represented as\n(2.21)\nΨ(h) = w6 ⊙(σ(w5 ⊛(Ccat(Upool(σ(w4 ⊛h + c4)), z)) + c5))\nwhere z = σ(w2 ⊛σ(w 1 ⊛x + c1) + c2). Here, σ(z) = ReLU(z), P is a pooling\noperator, Upool is an unpooling operator, and Ccat is a concatenation operator. The\nwork in [58] can be referred for a more detailed description. The overall structure of\nU-net is shown in Fig. 6.\nThe map f : x 7→y, as a function of parameters W = {w1, c1, w2, c2, · · · }, is\ndetermined as follows:\n(2.22)\nf = argmin\nf∈NN\n1\nndata\nndata\nX\nk=1\n∥f(x(k)) −y(k)∥2\nℓ2\nwhere NN denotes a set of all the functions of the form f = Ψ ◦Φ that vary with W.\nFig. 3 shows remarkable performance of U-net.\nUNDERDETERMINED INVERSE PROBLEMS\n11\nbfull\nA´1\nfull\nA´1\nfull\nSubsampling\nSsub\nZero ﬁlling\nS˚\nsub\nb “ Ssubbfull\nf\nf5\nA7\nA\nA\nS˚\nsubb “ S˚\nsubSsubbfull\nx “ A7b “ A´1\nfull S˚\nsubb\ny “ A´1\nfull bfull\nFig. 7. Undersampled MRI problem is to recover an image y = A−1\nfull bfull from undersampled\ndata b = Ssubbfull, where Ssub is a subsampling operator and bfull is a fully-sampled data in the\nsense of Nyquist sampling. All images are displayed by taking their absolute values. Using the deep\nlearning technique, we attempt to ﬁnd a reconstruction function f that maps from x = A♯b to\ny. Since the structure of x is determined by the subsampling operator Ssub, the learning f can be\naﬀected by the subsampling strategy.\n3. Solvability of Underdetermined Linear System. In undersampled prob-\nlems, the subsampling strategy Ssub inside A = SsubAfull is important for the unique-\nness of solution y on the manifold Mimage among all the possible solutions in Nb(A).\nPrecisely, a proper subsampling strategy Ssub is related to the following manifold re-\nstricted isometry property (RIP) condition. The matrix A associated with Ssub is said\nto satisfy the M-RIP condition if there exists a constant c ∈(0, 1] such that\n(3.1)\nc∥y −y′∥≤∥Ay −Ay′∥≤1\nc ∥y −y′∥for all y, y′ ∈Mimage.\nThe following two observations explain the necessary condition for constructing\na suitable subsampling strategy:\nObservation 3.1. If A satisﬁes the M-RIP condition in (3.1), then\n(3.2)\nA♯A : Mimage 7→M′\nimage is one-to-one.\nProof. Suppose that there are two diﬀerent y and y′ such that A♯Ay = A♯Ay′.\nSince A♯= A−1\nfullS∗\nsub,\n0 = ∥Afull(A♯Ay −A♯Ay′)∥= ∥S∗\nsub(Ay −Ay′)∥\n= ∥Ay −Ay′∥≥c∥y −y′∥\nwhere the last inequality follows from (3.1). Hence, y −y′ = 0, which contradicts the\nassumption.\nObservation 3.2. The reconstruction map f : x ∈M′\nimage 7→y ∈Mimage is\nlearnable if A satisﬁes the M-RIP condition.\n12\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\n+\nψ P N0pA7Aq\ny P Mimage\ny ` ψ P Mimage\nA7A\nx “ A7Ay “ A7Apy ` ψq\nFig. 8.\nLocation uncertainty on the solution manifold when using a uniform subsampling\nwith factor 4; let us consider two diﬀerent MR images, y and y + ψ, where the location of a\nsmall anomaly is only diﬀerent.\nWhen taking A♯A to the images, we obtain the same output\nx = A♯Ay = A♯A(y+ψ), where A is given by A = SsubAfull and Ssub denotes a uniform subsampling\nwith factor 4.\nIf the corresponding matrix A does not satisfy the M-RIP condition, there exist\ny1 ̸= y2 such that x = A♯Ay1 = A♯Ay2; therefore, it is impossible to learn such f\ndue to indistinguishability. The issue of learnability associated with A that does not\nsatisfy the M-RIP condition will be addressed in Section 3.1 with a concrete example.\nGiven a highly undersampling operator Ssub, the map f can be viewed as an image\nrestoration function with ﬁlling-in missing data or unfolding image data; therefore,\nf(x) depends on the image structure. The nonlinearity of f is aﬀected by Ssub and\nthe degree of bending of the manifold Mimage. The following observation explains\nthat most problems of solving underdetermined linear systems in medical imaging are\nhighly non-linear.\nObservation 3.3. Suppose that A satisﬁes the M-RIP condition. Let VMimage\nbe the span of the set { ∂\n∂hj G(h) : h ∈K, j = 1, · · · , dmfd}. If dim VMimage > m, then\nthe reconstruction map f : x ∈M′\nimage 7→y ∈Mimage is non-linear.\nProof. Note that f satisﬁes f(x) = y with x = A♯Ay for all y ∈Mimage. Since\nMimage is generated by G, we obtain\n(3.3)\nf(A♯AG(h)) = G(h),\n∀h ∈K\nTaking gradient with respect to h on both sides, then\n(3.4)\n∇xf(A♯AG(h))A♯A∇hG(h) = ∇hG(h), ∀h ∈K\nTo derive a contradiction, suppose f is linear; i.e., there exists a ﬁxed matrix B ∈Rn×n\nsuch that ∇xf(x) = B for all x ∈A♯AMimage. Subsequently, (3.4) becomes\n(3.5)\nBA♯A∇G(h) = ∇G(h),\n∀h ∈K\nHence, denoting the eigenspace of BA♯A corresponding to the eigenvalue λ by Eλ(BA♯A),\nwe have\n(3.6)\nE1(BA♯A) ⊇VMimage\nUNDERDETERMINED INVERSE PROBLEMS\n13\n+\n+\n+\n+\nÑ\nÑ\nÑ\nÑ\nx1\nx1\nx1\nx1\nreal part of x2\nreal part of x2\nreal part of x2\nreal part of x2\ny1\ny2\ny3\ny4\nFig. 9. Empirical observation regarding how to eliminate the location uncertainty by adding\none phase encoding line in the k-space.\nFour images (y1, y2, y3, and y4) containing one small\nanomaly in four diﬀerent locations generate the same x1; however, one additional phase encoding\nline information x2 can deal with location uncertainty in x1.\nand from the assumption on the dimension of VMimage,\n(3.7)\ndim E1(BA♯A) > m.\nSince Rank(BA♯A) ≤Rank(A) = m,\n(3.8)\ndim E0(BA♯A) ≥n −m.\nThis is a contradiction because\n(3.9)\ndim E0(BA♯A) + dim E1(BA♯A) > n.\n3.1. Undersampled MRI. In MRI, we apply an oscillating magnetic ﬁeld to\nthe imaging object in an MR scanner (being conﬁned in a strong magnetic ﬁeld) to\nacquire the k-space data (b), which is used to produce a cross-sectional MR image y.\nIn fully sampled MRI, the relation between a 2D MR image y and the corresponding\nfully sampled k-space data bfull can be expressed in the following form [62]:\n(3.10)\nX\na,b=1,··· ,√n\ne−2πi(ak1∆k+bk2∆k)y(a, b)\n|\n{z\n}\nAfully\n= bfull(k1, k2)\nwhere ∆k denotes the Nyquist sampling distance, which is chosen in such a way that\n(3.11)\ny(a, b) =\nX\nk1,k1=1,··· ,√n\ne2πi(ak1∆k+bk2∆k)bfull(k1, k2).\nIn other words, the Nyquist sampling make the problem Afully = bfull well-posed so\nthat the standard reconstruction y = A−1\nfullbfull can be obtained by 2D discrete inverse\nFourier transform.\nAssume that the frequency-encoding is along the k1-axis and that the phase-\nencoding is along the k2-axis in the k-space. Noting that the MRI scan time is roughly\nproportional to the number of time consuming phase-encoding steps in k-space, there\nhave been numerous attempts to shorten the MRI scan time by skipping the phase-\nencoding lines in the k-space [63, 23]. In the undersampled MRI, we attempt to ﬁnd\n14\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nthe optimal reconstruction function that maps the highly undersampled k-space data\n(b that violates Nyquist sampling criterion) to an image (y) close to the MR image\ncorresponding to the fully sampled data (bfull that satisﬁes the Nyquist sampling\ncriterion).\nWith undersampled data b, the corresponding problem is\n(3.12)\nSsubAfull\n|\n{z\n}\nA\nu = Ssub(bfull)\n|\n{z\n}\nb\nwhere Ssub denotes a subsampling operator and b = Ssub(bfull). The image x = A♯b\nis one of the solutions of (3.12), because A♯is the pseudo-inverse of A in this case.\nThe undersampled MRI problem aims to ﬁnd an image restoration map f : x =\nA−1\nfullS∗\nsubb 7→y = A−1\nfullbfull. See Fig. 7.\n3.1.1. Uniform subsampling. According to the Poisson summation formula,\nthe discrete Fourier transform of the uniformly subsampled data with factor 4 pro-\nduces the following four-folded image [61]:\n(3.13)\nx(a, b) = A♯Ay = 1\n4\nX\nb′≡b (mod\n√n\n4 )\ny(a, b′)\nwhere b′ ≡b (mod\n√n\n4 ) means that both b and b′ leave the same remainder when\ndivided by\n√n\n4 . Unfortunately, there exists an uncertainty that makes it impossible to\nreconstruct y from x, and therefore f is not learnable. To see the reason, we consider\nthe following:\nΨufm := N0(A♯A) = Span{ψ0,β\na∗,b∗: a∗, b∗∈Z√n, β = 1, 2, 3}\nwhere Zn := {1, · · · , n} for any positive integer n and ψ0,β\na∗,b∗is given by\n(3.14)\nψ0,β\na∗,b∗(a, b) =\n\n\n\n1\nif (a, b) = (a∗, b∗)\n−1\nif (a, b) = (a∗, b∗) + (0,\n√n\n4 β)\n0\notherwise\nHere, b∗+\n√\nl\n4 β should be understood as modulo √n.\nObservation 3.4. There exists a non-zero ψ ∈Ψufm and y ∈Mimage such that\ny + ψ ∈Mimage.\nThe observation implies that the M-RIP condition does not hold, as f requires the fol-\nlowing contradictory two conditions f(x) = y and f(x) = y + ψ, where x = A♯Ay =\nA♯A(y + ψ). The location of a small anomaly cannot be determined, and, therefore,\nthere are many location uncertainties under the uniform subsampling, as shown in Fig.\n8. This is the main reason why f is not learnable under the uniform subsampling.\n3.1.2. Uniform sampling with adding one phase encoding line. This\nsection provides a way to improve the separability by adding only one phase encoding\nline to a uniform subsampling. Let Ssub be the uniform subsampling of factor 4 upon\nadding one phase encoding line. Then, x = A♯b can be decomposed into two parts:\n(3.15)\nx(a, b) = x1(a, b) + x2(a, b)\nUNDERDETERMINED INVERSE PROBLEMS\n15\nΩROI\nSupport of AfullχΩROI\nbfull\nγ\nx\ny\nx ´ y “ 1\n2π2\nż\ntθ0pl1qRΩROI\nR˚\nθ0\nB\nBa1bptθ0pa1qq\na ´ a1\nda1\nA´1\nfull\nA´1\nfull\nSubsampling\nSsub\nZero ﬁlling\nS˚\nsub\nb “ Ssubbfull\nf\nS˚\nsubb “ S˚\nsubSsubbfull\nx “ A´1\nfull S˚\nsubb\ny “ A´1\nfull bfullχΩROI\nCupping Artifact\nFig. 10. Interior tomography problem is to recover an image y = A−1\nfull bfullχΩROI in our region of\ninterest (ROI) ΩROI by using the truncated data b = Ssubbfull, where Ssub is a subsampling operator\nand χ is a characteristic function.\nApplying the deep learning method, the reconstruction map\nf : x 7→y is learnable because of the analyticity of residual x −y.\nwhere x1 is the uniform sampling part given by\nx1(a, b) := 1\n4\nX\nb′ ≡b (mod\n√n\n4 )\ny(a, b′)\n(3.16)\nand x2 is the single phase encoding part given by\nx2(a, b) :=\nX\nb′∈Z√n\ny(a, b′)e2πi(b−b′)∆k\n(3.17)\nAdding the additional low frequency line in the k-space (compared to the previous\nuniform sampling) provides the additional information of x2. Subsequently, the situ-\nation is dramatically changed to counter the anomaly-location uncertainty in uniform\nsampling. Fig. 9 shows why the x2 information can eﬀectively handle the location\nuncertainty in Observation 3.4.\n3.2. Interior tomography. This section explains the underdetermined system\nfor the interior tomography problem. For simplicity, let us consider a 2-D parallel\nbeam system and assume that the projection data for the entire ﬁeld of view(FOV)\nis given by\n(3.18)\nbfull(ϕ, s) = Ru(ϕ, s) :=\nZ\nR2 u(t)δ(θ · t −s)dt\nwhere u represents an attenuation distribution on 2D-slice, t = (t1, t2), θ = (cos ϕ, sin ϕ),\nand δ(·) is the Dirac delta function. The discrete version of (3.18) can be expressed\nby the following linear system\n(3.19)\nAfullu = bfull\n16\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nwhere the Nyquist criterion must be considered in terms of the expected resolution\nof the CT image(u) and sampling(b). The standard reconstruction u = A−1\nfullbfull is\nbased on the FBP algorithm, which is based on the following identity:\n(3.20)\nu(t) =\nZ π\n0\nZ\nR\n|ω|Fbfull(ϕ, ω)e2πiωt·θdωdϕ\nwhere F is 1 dimensional Fourier transform associated with the variable ω and u and\nb are the continuous forms of u and bfull, respectively, in (3.19) [50].\nNow, we are ready to explain the interior tomography problem. Let ΩROI ⊂R2\ndenote the local region of interests(ROI), whose size in the interior tomography is\nsmaller than that of a patient’s body to be scanned, as depicted in Fig. 10. In the\ninterior tomography, we attempt to reconstruct uχΩROI by using the truncated data\nbfullχD, where χΩROI is the characteristic function of ΩROI and D is the support of\nRχΩROI.\nThe discrete form of this interior tomography can be expressed as follows:\n(3.21)\nReconstruct y = uχΩROI satisfying Au = b\nwhere b = Ssub(bfull), with the subsampling Ssub deﬁned as Ssub(bfull) := bfullχD, and\nA := SsubAfull. The dual operator of Ssub, which is denoted by S∗\nsub, can be interpreted\nas a zero-ﬁlling process in the unmeasured parts of b in terms of bfull, as shown in\nFig 10. The standard FBP algorithm for the zero-ﬁlled data S∗\nsubb provides the image\nx = A−1\nfullS∗\nsubb with cupping artifacts [18, 66]. Then, our reconstruction problem is\nthe following:\nFind a function f : x 7→y\nsatisfying A♯Au = x and y = uχΩROI.\n(3.22)\nTo explain the learnability of f : x 7→y, we consider the continuous version. The\nHilbert transform of u with θ is deﬁned by\n(3.23)\nHθu(t) = 1\nπ\nZ\nR\nu(tθ(a))\na −t · θ da\nwhere tθ(a) is the point given by\n(3.24)\ntθ(a) = aθ + (t · θ⊥)θ⊥, (θ⊥= (−sin ϕ, cos ϕ)).\nNote that {tθ(a) : a ∈R} is the θ directional line passing through t. Let us deﬁne\n(3.25)\nR∗\nθ0h(t) =\nZ ϕ0+π\nϕ0\nh(t · θ, ϕ)dϕ\nMost interior tomography algorithms are based on the following identity [51, 66] :\n(3.26)\nu(tθ0(a)) = 1\n2R∗\nθ0Hθ0\n∂\n∂ab(tθ0(a))\nApplying the Hilbert transform to both sides of the above identity,\n(3.27)\nHθ0u(tθ0(a)) = −1\n2π R∗\nθ0\n∂\n∂ab(tθ0(a))\nUNDERDETERMINED INVERSE PROBLEMS\n17\ny\nx\nbfull\nA´1\nfull\nA´1\nfull\nSubsampling\nSsub\nZero ﬁlling\nS˚\nsub\nb “ Ssubbfull\nf\nS˚\nsubb “ S˚\nsubSsubbfull\nx “ A´1\nfull S˚\nsubb\ny “ A´1\nfull bfull\nFig. 11. Sparse-view CT aims to reconstruct an image y = A−1\nfull bfull from uniformly under-\nsampled data b = Ssubb, where Ssub is the subsampling operator. Applying the deep learning method,\nwe attempt to learn f that produces y from the input x = A−1\nfull S∗\nsubb. The map f is learnable due\nto a simple structure of the residual x −y.\nGiven t ∈ΩROI and θ0, we have the following identity: For tθ0(a) ∈ΩROI,\n(3.28)\nu(tθ0(a)) = Ψin\nθ0b(tθ0(a)) + Ψout\nθ0 b(tθ0(a))\nwhere\n(3.29)\nΨin\nθ0b(tθ0(a)) =\n1\n2π2\nZ\ntθ0(a′)∈ΩROI\nR∗\nθ0\n∂\n∂a′ b(tθ0(a′))\na′ −a\nda′\nand\n(3.30)\nΨout\nθ0 b(tθ0(a)) =\n1\n2π2\nZ\ntθ0(a′)/∈ΩROI\nR∗\nθ0\n∂\n∂a′ b(tθ0(a′))\na′ −a\nda′.\nThe main point is that Ψout\nθ0 b(tθ0(a)) is analytic in the line segment γ = {a ∈R :\ntθ0(a) ∈ΩROI} [66]. This means that Ψout\nθ0 b(tθ0(γ)) is completely determined by its\nknowledge in any open subset of γ. Consequently, u(tθ0(γ)) can be recovered from\nΨin\nθ0b(tθ0(γ)) and the information of Ψout\nθ0 b(tθ0(γ)) in the small open subset of γ.\nNow, we revisit the original discrete problem (3.22). Finding the function f : x 7→\ny is equivalent to ﬁnding the correction of the residual x −y. The analytic property\nof Ψout\nθ0 b(tθ0(γ)) explains the structure of the residual x −y in ΩROI. Owing to the\nanalytic structure of x −y along the line segments, x −y in ΩROI has very diﬀerent\nimage structure from that of y (medical image); therefore, x can be decomposed into\ny and x −y. Hence, the function f : x 7→y is learnable.\n3.3. Sparse-view CT. The sparse-view CT problem aims to ﬁnd a reconstruc-\ntion function that maps from a sparse-view sinogram b to an image whose quality is as\nhigh as that of a regular CT image reconstructed by full-view sinogram bfull. Through-\nout this section, we will denote the sub-sampling operator by Ssub, so b = Ssubbfull.\n18\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nAssuming that the subsampled data b = Ssub(bfull) violates the Nyquist’s rule,\nthe standard FBP algorithm using b produces a streaking artifacted CT image, which\ncan be expressed as\n(3.31)\nx = A−1\nfullS∗\nsubb\nwhere S∗\nsubb is a zero-ﬁlled data of b and S∗\nsub is the dual operator of Ssub.\nThe corresponding high quality image reconstructed from bfull (satisfying the\nNyquist’s rule) is given by\n(3.32)\ny = A−1\nfullbfull\nThe goal is to learn the function f : x 7→y using {(x(k), y(k))}ndata\nk=1 .\nThe image structures of x−y and y are very diﬀerent from each other, as shown in\nFigure 11. Numerous researches have been conducted on image enhancement methods\nby suppressing noise x −y. The following CS technique is widely used to alleviate\nthe noise x −y :\n(3.33)\ny = argmin\ny\n∥A♯Ay −x∥2\nℓ2 + λ∥∇y∥ℓ1\nwhere ∥∇y∥ℓ1 is used to penalize the undesired feature x −y. According to [10, 9],\nthe convex minimization problem (3.33) is somehow close to the following problem:\n(3.34)\ny = argmin\ny∈Wα\n∥A♯Ay −x∥2\nℓ2\nwhere Wα := {y : ∥∇y∥0 ≤α}, α is a positive integer, and ∥∇y∥0 indicates the\nnumber of non-zero entries of ∇y. Since Wα is a ﬁnite union of the α-dimensional\nspace, the constraint y ∈Wα shrinks the domain of solutions by enforcing sparsity.\nIf α is suﬃciently smaller than m (the number of equations), then A satisﬁes α-RIP\ncondition [9] within the sparse set Wα. Namely, ∥Ay −Ay′∦= 0 for any diﬀerent\nimages y ̸= y′ in Wα, so that the uniqueness of the problem (3.34) can be guaranteed\nwithin the sparse set Wα.\nAssuming that A satisﬁes the α-RIP condition and that Mimage is given by Wα,\nA satisﬁes the M-RIP condition in (3.1), and, thus, the reconstruction f is learnable\nfrom Observation 3.2. In the sparse-view CT problem, as several CS methods exhibit\nfairly successful reconstruction results [73, 42], the forward operator A seems to pos-\nsess some property somewhat closely related with RIP condition on the sparse set Wα.\nHowever, the handmade set Wα as prior knowledge can be viewed as a very rough\napproximation to the manifold Mimage, and hence it is limited in its ability to preserve\nsmall details with important medical information. Owing to the highly curved struc-\nture of Mimage as observed in Section 2.2, deep learning approaches [36, 26, 67] have\nbeen proposed to facilitate the machine-learned intrinsic regularizer using training\ndata.\nRemark 3.5. Let us give a brief comment on A−1\nfull . In general, the solution of\nAfully = b can be expressed as y = (A∗\nfullAfull)−1Afullb and therefore A−1\nfull should be\nunderstood as (A∗\nfullAfull)−1Afull. In CT, A−1\nfull represents the operator corresponding to\nthe FBP algorithm as a practically feasible reconstruction.\n4. Discussion. In this section, we discuss several interesting issues related to\ndeep learning-based solvability for underdetermined problems in medical imaging.\nAn important question is “what is the minimum ratio of undersampling to provide\nguarantee of accurate reconstruction?”. It is closely related to the dimension of the\nmanifold.\nUNDERDETERMINED INVERSE PROBLEMS\n19\n‚ ‚ ‚\n‚ ‚ ‚\nη\nη\nη\nη\nLearnability of fη : xη ÞÑ yη\n‚ ‚ ‚\n‚ ‚ ‚\nη\n# (number)\nthe # of unknown pixels\nthe # of equations\ndim(Mη\nimage)\n(expected)\nPatch extraction without overlapping\nPatch extraction without overlapping\nx\ny\nxη\nyη\nFig. 12. Learnability of fη : xη 7→yη. Let yη denote an image patch of size 256 × η extracted\nfrom a 256×256 MR image y and xη be an aliased image obtained by xη = A♯Ayη. The learnability\nof reconstruction map fη seems to be related with the dimension of solution set Mη\nimage. Here, Mη\nimage\nis the set of all extracted patches from 256 × 256 MR images.\n4.1. Solvability Issue. This subsection discuss an interesting characteristic of\nthe learning problem in the underdetermined MRI described in Section 3.1, where\nthe uniform subsampling of factor 4 with additional phase encoding lines is used as\nthe subsampling strategy. For the ease of explanation, we assume n = 256 × 256 (i.e.\ny represents a 256 × 256 MR image) and uniform subsampling of factor 4 adding 12\nsupplementary phase encoding lines.\nFor a given integer η ≥1, let {y(j)\nη\n∈R256×η}npatch\nj=1\nbe a set of the image patches\nextracted from an image y and let {x(j)\nη }npatch\nj=1\nbe the corresponding set of the aliased\nimages, given by x(j)\nη\n= A♯Ay(j)\nη . We assume that there is no overlap between all the\npatches. (See Fig. 12.)\nThis section aims to investigate whether the factor of η is important in learning\nfη : xη 7→yη. To observe the eﬀects of η, we train the U-net by varying η, using the\nfollowing training dataset:\n(4.1)\n{(x(j,k)\nη\n, y(j,k)\nη\n) | j = 1, · · · , npatch and k = 1, · · · , ndata}\nwhere y(j,k)\nη\nrepresents j-th image patch extracted from the n-th label MR image y(k).\nThe reconstruction map fη aims to solve the linear system that has 76 × η num-\nber of equations with 256 × η number of unknowns. As η increases, the number of\nunknowns increases more rapidly than the number of equations. See the middle box\nin Fig. 12. However, our experimental results, described in Fig. 13, demonstrate that\nthe learning ability is gradually improved as η increases.\nThe experimental results in Fig. 13 can be explained by means of the dimension-\nality of the manifold given by\n(4.2)\nMη\nimage := {yη | yη is a 256 × η patch extracted from y}\nThe dimension of Mη\nimage, denoted by gM(η), can be viewed as a function of η variable.\nAs shown in the middle box in Fig. 12, gM(η) seems to grow very slowly; therefore,\ngM(η) might intersect with the linear function g#equations(η) = 76η (i.e. the number of\nequations). Assuming η∗is the intersection point (i.e. gM(η∗) = g#equations(η∗)), fη\ncan be regarded as learnable, provided η ≥η∗. This interpretation can be supported\nby the error estimations in Fig. 13.\n20\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\n‚ ‚ ‚\n‚ ‚ ‚\nPatch extraction without overlapping\nx\ntest\nx\ntest\nη\n‚ ‚ ‚\n‚ ‚ ‚\nfηpx\ntestq\nfηpx\ntest\nη q\nPatch Rearrangement\nTest inference\nby fη\nη\n1 8\n32\n256\nMSE = 2.321 ˆ 10´4\nMSE = 2.021 ˆ 10´4\nMSE = 1.788 ˆ 10´4\nMSE = 1.691 ˆ 10´4\nTest Label\nFig. 13. Test performance evaluation of fη with various η = 1, 8, 32, and 256. For each η, the\nfunction fη is obtained by training the U-net with the corresponding image patches extracted from\n1500 MR images {y(k)}1500\nk=1 . To compare quantitative performances with one another, a given test\nimage xtest /∈{x(k)}1500\nk=1 is divided into image patches, where each patch is reconstructed through\nthe trained U-net fη, and the reconstruction outputs are rearranged into one image fη(xtest). We\nalso qualitatively evaluate the test result qualitatively by computing the mean squared error(MSE)\nbetween the inference output fη(xtest) and label ytest.\nLet us explain the reasons for expecting gM(η) to grow signiﬁcantly slowly as η\nincreases. Assume that Mimage is the set of all the human head MR images. Then,\nall the images in Mimage possess a similar anatomical structure that consists of skull,\ngray matter, white matter, cerebellum, among others. In addition, every skull and\ntissue in the image have distinct features that can be represented nonlinearly by a\nrelatively small number of latent variables, and so does for the entire image. Notably,\nthe skull and tissues of the image are spatially interconnected, and even if a part of the\nimage is missing, the missing part can be recovered with the help of the surrounding\nimage information.\nThis is the reason that image inpainting techniques [5] have\nbeen successful in image restoration for ﬁlling-in the missing areas in images. These\nobservations seem to indicate that gM(η) does not change much with η near η = 256,\nwhere gM(256) corresponds to the dimension of the entire image.\nTherefore, we\nexpect that gM(256) ≪g#equations(256), so that there exists η∗(the turning point for\nlearnability) such that gM(η∗) = g#equations(η∗). If the curse-of-dimensionality does\nnot matter, it may be better to learn 3D images in total rather than dividing 3D\nimages into multiple pieces.\nA rigorous mathematical analysis of this issue is the\nUNDERDETERMINED INVERSE PROBLEMS\n21\nMimage\ny\nΦ\nΨ\nh\nLatent Space\nM1\nimage\nx\ng\nf\nA7A\nΨ ˝ g\nFig. 14. What happens if a low dimensional latent representation is possible? Imagine that we\nhave a low dimensional latent generator Ψ : h 7→y and an encoder Ψ : y 7→h such that Ψ◦Φ(y) ≈y\nfor all y ∈Mimage. If we have a map g : x 7→h = Ψ(y), then the reconstruction map f : x 7→y is\ngiven by f = Ψ ◦g.\nsubject of our future research topic.\n4.2. Some issues on learning low dimensional representation. In our\nundersampled problems, the dimension of y (i.e., the total number of pixels in the\nimage) is considerably bigger than the dimension of b (i.e., the number of independent\ncomponents in the measurement data). Since there exist inﬁnitely many images that\nsolve the mathematical model Ay = b, we need to reﬂect prior information about the\nunknown solution manifold, either implicitly or explicitly, in the image restoration\nprocess.\nOver several decades, various regularization approaches have been used with pre-\ndeﬁned convex regularization functionals in order to incorporate a-priori information\non y. CS methods involving ℓ1-norm regularization minimization have been powerful\nfor noise removal, whereas they suﬀer from limitations in preserving small features.\nIn medical imaging, there are a variety of small features, such that the diﬀerence in\nthe data ﬁdelity is very small as compared with that in normalization, whether or not\nthose small features are present. Hence, ﬁnding a more sophisticated normalization\nto keep small features remains a challenging problem.\nUnlike in CS (predetermined convex-norm-based approach), deep learning can\nbe viewed as a black box model approach where training data is used for probing\nthe solution manifold. To ensure the possibility of solving undersampled problems\nthrough deep learning, it would be desirable to investigate the performance of low\ndimensional representation learning for the unknown manifold from training data.\nAutoencoder(AE) techniques (as the natural evolution of PCA) are widely used to\nﬁnd a low dimensional representation for the unknown Mimage from the known training\ndata {y(k)}ndata\nk=1 [29, 40]. The AE consists of a encoder Φ : y →h for a compressed\nlatent representation and a decoder Ψ : h →y for providing Ψ ◦Φ(y) ≈y (i.e.,\nan output image is similar to the original input image). Assuming that Φ provides\na satisfactory approximation of the solution manifold, the underdetermined problem\n(1.3) can be solved as follows:\n(4.3)\nf(x) = Ψ(h),\nh = argmin\nh\n∥AΨ(h) −Ax∥\nA deep learning technique can be used to solve the problem (4.3), as in the minimiza-\n22\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\ndlatent “ 100\nTest\nSample\nPCA\nAE\nVAE\n256ˆ256 Head MR Image\n512ˆ512 Head CT Image\nFig. 15. Learning a low dimensional representation for MR and CT images with three dif-\nferent dimension reduction techniques (principal component analysis(PCA), auto-encoder(AE), and\nvariational AE(VAE)). By using each technique, an encoder Φ and decoder Ψ are trained so that\nMR or CT images are projected into a 100 dimensional space (i.e. dlatent = 100) by using 1800 MR\nimages of pixel dimension 256 × 256 or using 3400 CT images of pixel dimension 512 × 512. PCA\nwas performed by a built-in function pca in MATLAB. For AE and VAE, we used convolutional\nAE and VAE structures, respectively, consisting of modiﬁed residual blocks from ResNET [27, 28].\nThe networks were implemented in the Tensorﬂow environment. After the training, we tested three\ndiﬀerent samples for each MR and CT case, displayed in the ﬁrst row, and the corresponding test\nresults are displayed from the second to last row.\ntion problem (4.3) it might be diﬃcult to use the standard gradient descent method\nbecause of the complex deep learning structure of the decoder Ψ. If the dimension of\nthe latent space is reasonably small, the reconstruction map is achieved by\n(4.4)\nf(x) = Ψ ◦g(x), g := argmin\ng∈NN\nndata\nX\nk=1\n∥g(x(k)) −h(k)∥\nwhere h(k) = Φ(y(k)). One can refer to Fig. 14 for the schematic understanding of the\nmethod. Recent papers have reported that the AE-based approaches show remarkable\nperformances in several applications [12, 60, 34, 64]. However, for high dimensional\ndata, AEs seem to suﬀer from the blurring and loss of small details, as depicted in Fig.\n15. Improving performance of AEs in high dimensional medical image applications is\nstill a challenging issue.\nsGenerative adversarial networks (GANs) have been utilized to generate realistic\nimages via interactions between learning and synthesis [20, 57, 71]. Typically, the\narchitecture of GANs comprises two main parts; generator Ψ and discriminator Γ.\nThe GAN network aims to ﬁnd a Ψ that maps from a random noise vector h in\nthe latent space to an image in a real data distribution associated with the training\nUNDERDETERMINED INVERSE PROBLEMS\n23\ndlatent “ 100\nVAE\nGAN\nDCGAN\nWGAN\nPGGAN\nGenerated 256ˆ256 Head MR Image\nGenerated 512ˆ512 Head CT Image\nFig. 16. Learning low dimensional representation for MR and CT images using ﬁve diﬀerent\ngenerative models, variational auto-encoder(VAE), generative adversarial network(GAN), deep con-\nvolutional GAN(DCGAN), Wasserstein GAN(WGAN), and progressive generative GAN(PGGAN).\nUsing these generative models, we learn a generator Ψ that synthesizes MR or CT images from points\nsampled in 100 dimensional Gaussian distribution (i.e. dlatent = 100). In our experiments, we used\na typical network structure for each generative model, as described in [40, 20, 57, 22, 37].\nWe\nreplaced the cross-entropy of GAN into Hinge loss, and the Wasserstein loss of PGGAN into Hinge\nloss with spectral normalization in order to obtain the stability on learning [72]. All the networks\nwere implemented in the Tensorﬂow environment with 1800 MR images and 3400 CT images. In\neach row, three diﬀerent synthesized images from each trained generative models are displayed for\neach CT and MR case.\ndata {y(k)}ndata\nk=1 . The generator Ψ is trained with the assistance of the discriminator\nΓ in such a way that Γ misclassiﬁes Ψ(h) as a real image. The training procedure\nof GAN can be viewed as a performance competition between the generator and\nthe discriminator. Although GANs have achieved remarkable success in generating\nvarious realistic images, there exist some limitations in synthesizing high resolution\nmedical data. The GAN’s approach makes it diﬃcult to deal with high-dimensional\ndata because the generated image can be easily distinguished from the training data,\nwhich can lead to collapse or instability during the training process [53].\nSeveral\nvariations of GAN, such as Wasserstein GAN(WGAN) [4, 22] and progressive growing\nGAN(PGGAN) [37], have been developed to deal with the training instability. WGAN\nuses Wasserstein distance, which may improve the loss sensitivity with respect to\nchange of parameters, compared to the Jensen-Shannon distance used in the original\n24\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\nGAN. Fig. 16 shows that in our WGAN experiment, nearly plausible synthesis results\nare generated for high dimensional medical image, whereas the synthesized images still\nsuﬀer from somewhat lack of reality. PGGAN facilitates synthesis of high dimensional\ndata via hierarchical multi-scale learning fashion from low resolution to the desired\nhigh resolution; therefore, the network can focus on the overall structures at the\nbeginning of the process, before shifting attention gradually to ﬁner scale details via\nlater connections as the training advances. Fig. 16 depicts our PGGAN experiment\nwith the spectral weight normalization [48], that provides high quality synthesis.\nUnfortunately, unlike bidirectional AE, which provides an explicit prior, GANs\nlearn only the unidirectional mapping Ψ : h 7→y and, therefore, it is diﬃcult to\nachieve (4.4). Recently, new strategies have been developed to use the implicit prior\nobtained using GANs as a solution prior for solving ill-posed inverse problems such\nas the undersampled MRI [49], image denoising [65], and inpainting [69]. Also, a\nscattering generator [3] with the advantages of both GAN and AE has been proposed.\nHowever, applications in high dimensional medical imaging problems are still far from\nsatisfactory.\n5. Conclusion. This work concerns with the solvability of undersampling prob-\nlems with the use of training data. The undersampled MRI, sparse view CT, and\ninterior tomography are typical examples of the underdetermined problem, which in-\nvolve much fewer equations (measured data) than unknowns (pixels of the image).\nTo compensate for the uncertainty of the huge number of free parameters (diﬀerence\nbetween the number of equations and the number of unknowns), we need to limit\nthe solution manifold using prior information of the expected images. Regularization\ntechniques have been widely used to impose very speciﬁc prior distributions on the\nexpected images, such as penalizing a special norm of images (or promoting sparsity\nin expressions). However, norm-based regularization might not actually be able to\nprovide a clinically useful image properly in advance. Well-known CS methods, which\nemploy random sampling and are based on regularization methods, are eﬀective in\nalleviating highly oscillatory noise while maintaining the overall structure; however,\nsparse sensing techniques tend to eliminate small anomalies, as shown in Section 2.2.2.\nDL techniques appear to deal with various underdetermined inverse problems by\neﬀectively probing the unknown nonlinear manifold Mimage through training data. It\nseems to handle the uncertainty of solutions to the highly ill-posed problems.\nAccording to Hadamard [24], the linear problem Ay = b is well-posed if the\nfollowing two conditions hold (while ignoring the existence issue): ﬁrst, for each b, it\nhas a unique solution, and second, the solution is stable under the perturbation of b.\nHowever, we note that whether the problem is well-posed depends on the choice of\nthe solution space. Many ill-posed problems can be well-posed within the constrained\nsolution spaces (e.g. sparse solution spaces). For a simple example, we consider the\nPoisson’s equation ∇· ∇u = b in the 2-D domain Ω= {(r cos θ, r sin θ) | 0 < r <\n1, 0 < θ < 3π\n2 } with the homogeneous Dirichlet boundary condition u|∂Ω= 0. If u∗is\na solution, so are u = u∗+(r\n2\n3 n−r\n−2\n3 n) sin( 2\n3θ) for n = 0, 1, 2, · · · .. Hence, the problem\nis ill-posed without the constraint of the Sobolev sapce H1(Ω) = {u |\nR\nΩ|u|2+|∇u|2 <\n∞}.\nSimilarly, the underdetermined problem Ay = b can be well-posed under a\nsuitable solution manifold Mimage. DL methods seem to possess ambiguous capability\nof learning data representation.\nRecently, several experiments regarding adversarial classiﬁcations [19, 13] (e.g.,\nfalse positive output of cancer) have shown that deep neural networks obtained via\ngradient descent-based error minimization procedure are vulnerable to various noisy-\nUNDERDETERMINED INVERSE PROBLEMS\n25\nlike perturbations, resulting in incorrect output (that can be critical in medical en-\nvironments). These experiments show that a well-trained function f in (1.5) works\nonly in the immediate vicinity of a manifold, whereas producing incorrect results if\nthe input deviates even slightly from the training data manifold. In practice, the\nmeasured data is exposed to various noise sources such as machine dependent noise;\ntherefore, the developed algorithm must be stable against the perturbations due to\nnoise sources. Hence, normalization of the input data is essential for improving ro-\nbustness and generalizability of the deep learning network against adversarial attacks\n[21, 70, 19].\nFor input data normalization, we attempt to project the input x to its normalized\nform N(x) in the way that two images x and N(x) are almost the same from the view-\npoint of radiologists. It is quite complicated to deﬁne the distance distradiologist(x, x′)\nin terms of radiologist’s view. If we have a good generator G, it can be deﬁned as\n(5.1)\ndistradiologist(x, x′) = ∥h −h′∥\nwhere G(h) = N(x) and G(h′) = N(x′). The Euclidian distance ∥h −h′∥can be\nsomewhat equivalent to the geodesic distance between N(x) and N(x′) on the man-\nifold. For example, given a noisy input x, its normalization N(x) can be a denoised\nimage while preserving the salient features of x. The issues of ﬁnding the normaliza-\ntion N and the generator G would be very challenging tasks. Although there are still\nseveral challenging issues in deep learning associated with solving ill-posed inverse\nproblems in medical imaging area, recent remarkable developments indicate that it\nhas enormous potential to provide a useful means of overcoming the limitations of the\ntraditional methods.\nREFERENCES\n[1] M. Aharon and M. Elad, “Sparse and redundant modeling of image content using an image-\nsignature-dictionary,” SIAM Journal on Imaging Sciences, vol. 1, 2008, pp. 228–247.\n[2] M. Aharon, M. Elad, and A. Bruckstein, “K-svd: An algorithm for designing overcomplete\ndictionaries for sparse representation, IEEE Transactions on signal processing, vol. 54,\n2006, pp. 4311–4322.\n[3] T. Angles and S. Mallat, “Generative networks as inverse problems with scattering transforms,”\nICLR, 2018.\n[4] M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein GAN,” arXiv:1701.07875, 2017.\n[5] M. Bertalmio, G. Sapiro, V. Caselles, and C. Ballester, “Image inpainting,” in Proceedings of\nthe 27th annual conference on Computer graphics and interactive techniques, 2000, pp.\n417–424.\n[6] D. J. Brenner and E. J. Hall, “Computed tomography scan increasing source of radiation\nexposure,” New England Journal of Medicine, vol. 357, 2007, pp. 2277–2284.\n[7] A. M. Bruckstein, D. L. Donoho, and M. Elad, “From sparse solutions of systems of equations\nto sparse modeling of signals and images, SIAM Review, 51 (2008), p. 3481.\n[8] E. J. Cand`es, J. Romberg, and T. Tao, “Robust uncertainty principles:exact signal reconstruc-\ntion from highly incomplete frequency information,” IEEE Trnas. on Information Theory,\nvol. 52, 2006, pp. 489–509.\n[9] E. J. Cand`es, J. K. Romberg, and T. Tao, “Stable signal recovery from incomplete and inac-\ncurate measurements,” Communications on Pure and Applied Mathematics, vol. 59, 2006,\npp. 1207–1223.\n[10] E. J. Cand`es and T. Tao, “Decoding by linear programming,” IEEE Transactions on Informa-\ntion Theory, vol. 51, 2005, pp. 4203–4215.\n[11] E. J. Cand`es and T. Tao, “Reﬂections on compressed sensing,” IEEE Information Theory\nSociety Newsletter, vol. 58, 2008, pp. 20–23.\n[12] J. H. R. Chang, C. Li, B. Poczos, B. V. K. V. Kumar, and A. C. Sankaranarayanan, “One\nnetwork to solve them all solving linear inverse problems using deep projection models,”\n2017 IEEE International Conference on Computer Vision (ICCV), 2017, pp. 5889–5898.\n26\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\n[13] T. Ching, D. S. Himmelstein, B. K. Beaulieu-Jones, A. A. Kalinin, B. T. Do, G. P. Way, E.\nFerrero, P.-M. Agapow, M. Zietz, M. M. Hoﬀman, et al., “Opportunities and obstacles for\ndeep learning in biology and medicine,” Journal of The Royal Society Interface, vol. 15,\n2018, p. 20170387.\n[14] I. Daubechies, M. Defrise, and C. De Mol, “An iterative thresholding algorithm for linear\ninverse problems with a sparsity constraint,” Communications on Pure and Applied 737\nMathematics, vol. 57, 2004, pp. 1413–1457.\n[15] D. Donoho, “Compressed sensing,” IEEE Trans. on Information Theory, vol. 52, 2006, pp.\n1288–1306.\n[16] D. L. Donoho and M. Elad, “optimally sparse representation in general (non-orthogonal) dic-\ntionaries via ℓ1 minimization,” Proc. Natl Acad. Sci. USA, vol. 100, 2003, pp. 2197–2202.\n[17] M. Elad and M. Aharon, “Image denoising via sparse and redundant representations over\nlearned dictionaries,” IEEE Transactions on Image processing, vol. 15, 2006, pp. 3736–\n3745.\n[18] A. Faridani, E. L. Ritman, and K. T. Smith, “Local tomography,” SIAM Journal on Applied\nMathematics, vol. 52, 1992, pp. 459–484.\n[19] S. G. Finlayson, J. D. Bowers, J. Ito, J. L. Zittrain, A. L. Beam, and I. S. Kohane, “Adversarial\nattacks on medical machine learning,” Science, vol. 363, 2019, pp. 1287–1289.\n[20] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville,\nand Y. Bengio, “Generative adversarial nets,” Advances in Neural Information Processing\nSystems, vol. 27, 2014, pp. 2672–2680.\n[21] I. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,”\nin International Conference on Learning Representations, 2015.\n[22] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville, “Improved training of\nwasserstein GANs,” arXiv:1704.00028, 2017.\n[23] E. Haacke, R. Brown, M. Thompson, and R. Venkatesan, “Magnetic resonance imaging physical\nprinciples and sequence design,” New York: Wiley, 1999.\n[24] J. Hadamard, “Sur les probl´emes aux d´eri´e´es partielles et leur signiﬁcation physique,” Bull.\nUniv. Princeton, vol. 13, 1902, pp. 49–52.\n[25] Y. Han, J. Gu, and J. C. Ye, “Deep learning interior tomography for region-of-interest recon-\nstruction,” arXiv, 2017.\n[26] Y. Han and J. C. Ye, “Framing u-net via deep convolutional framelets: Application to sparse-\nview CT,” IEEE transactions on medical imaging, vol. 37, 2018, pp. 1418–1429.\n[27] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” 2016 IEEE\nConference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770–778.\n[28] K. He, X. Zhang, S. Ren, and J. Sun, “Identity mappings in deep residual networks,” in\nEuropean conference on computer vision, Springer, 2016, pp. 630–645.\n[29] G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of data with neural\nnetworks,” Science, vol. 313, 2006, pp. 504–507.\n[30] G. N. Hounsﬁeld, “Computerized transverse axial scanning (tomography): Part 1. description\nof system,” British Journal of Radiology, vol. 46, 1973, pp. 1016–1022.\n[31] C. M. Hyun, H. P. Kim, S. M. Lee, S. Lee, and J. K. Seo, “Deep learning for undersampled\nMRI reconstruction,” Physics in Medicine and Biology, vol. 63, 2018, p. 135007.\n[32] S. Ioﬀe and C. Szegedy, “Batch normalization: Accelerating deep network training by reducing\ninternal covariate shift,” arXiv preprint arXiv:1502.03167, 2015.\n[33] M. K. Islam, T. G. Purdie, B. D. Norrlinger, H. Alasti, D. J. Moseley, M. B. Sharpe, J.\nH. Siewerdsen, and D. A. Jaﬀray, “Patient dose from kilovoltage cone beam computed\ntomography imaging in radiation therapy,” Medical physics, vol. 33, 2006, pp. 1573–1582.\n[34] S. Jalali and X. Yuan, “Using auto-encoders for solving ill-posed linear inverse problems,”\narXiv:1901.05045, 2019.\n[35] O. N. Jaspan, R. Fleysher, and M. L. Lipton, “Compressed sensing MRI: a review of the clinical\nliterature,” The British journal of radiology, vol. 88, 2015.\n[36] K. H. Jin, M. T. McCann, E. Froustey, and M. Unser, “Deep convolutional neural network for\ninverse problems in imaging,” IEEE Trans. Image Process, vol. 26, 2017, pp. 4509–4522.\n[37] T. Karras, T. Aila, S. Laine, and J. Lehtinen, “Progressive growing of GANs for improved\nquality, stability, and variation,” ICLR, 2018.\n[38] K. Kawaguchi, L. P. Kaelbling, and Y. Bengio, “Generalization in deep learning,” In Mathe-\nmatics of Deep Learning, Cambridge University Press, 2017.\n[39] D. P. Kingma and J. Ba, “Adam:\nA method for stochastic optimization,” arXiv preprint\narXiv:1412.6980, 2014.\n[40] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” arXiv:1312.6114, 2013.\n[41] D. A. Koﬀand H. Shulman, “An overview of digital compression of medical images: can we\nUNDERDETERMINED INVERSE PROBLEMS\n27\nuse lossy image compression in radiology?,” Canadian Association of Radiologists Journal,\nvol. 57, 2006, pp. 211–217.\n[42] H. Kudo, T. Suzuki, and E. A. Rashed, “Image reconstruction for sparse-view CT and interior\nCT - introduction to compressed sensing and diﬀerentiated backprojection,” Quantitative\nimaging in medicine and surgery, vol. 3, 2013, p. 147.\n[43] P. Lauterbur, “Image formation by induced local interactions: Examples of employing nuclear\nmagnetic resonance,” Nature, vol. 242, 1973, pp. 190–191.\n[44] C. P. Loizou, V. Murray, M. S. Pattichis, I. Seimenis, M. Pantziaris, and C. S. Pattichis, “Mul-\ntiscale amplitude-modulation frequency-modulation (am-fm) texture analysis of multiple\nsclerosis in brain MRI images,” IEEE Transactions on Information Technology in Biomed-\nicine, vol. 15, 2010, pp. 119–129.\n[45] M. Lustig, D. L. Donoho, and J. M. Pauly, “Sparse MRI: The application of compressed sensing\nfor rapid MR imaging,” Magnetic Resonance in Medicine, vol. 58, 2007, pp. 1182–1195.\n[46] J. Mairal, M. Elad, and G. Sapiro, “Sparse representation for color image restoration,” IEEE\nTransactions on Image Processing, vol. 17, 2008, pp. 53–69.\n[47] S. G. Mallat, “A wavelet tour of signal processing,” Academic Press, 2009.\n[48] T. Miyato, T. Kataoka, M. Koyama, and Y. Yoshida, “Spectral normalization for generative\nadversarial networks,” ICLR, 2018.\n[49] D. Narnhofer, K. Hammernik, F. Knoll, and T. Pock, “Inverse GANs for accelerated MRI\nreconstruction,” Proc. SPIE : Wavelets and Sparsity XVIII, vol. 11138, 2019, pp. 381–392.\n[50] F. Natterer, “The mathematics of computerized tomography,” John Wiley and Sons, 1986.\n[51] F. Noo, R. Clackdoyle, and J. D. Pack, “A two-step hilbert transform method for 2D image\nreconstruction,” Physics in Medicine and Biology, vol. 49, 2004, pp. 3903–3923.\n[52] H. Nyquist, “Certain topics in telegraph transmission theory,” Trans. AIEE, vol. 47, 1928, pp.\n617 – 644.\n[53] A. Odena, C. Olah, and J. Shlens, “Conditional image synthesis with auxiliary classiﬁer GANs,”\nICML, 2017.\n[54] B. A. Olshausen and D. J. Field, “Emergence of simple-cell receptive ﬁeld properties by learning\na sparse code for natural images,” Nature, vol. 381, 1996, p. 607.\n[55] H. S. Park, J. K. Choi, and J. K. Seo, “Characterization of metal artifacts in X-ray computed\ntomography,” Communications on Pure and Applied Mathematics, vol. 70, 2017, pp. 2191–\n2217.\n[56] B. Poole, S. Lahiri, M. Raghu, J. Sohl-Dickstein, and S. Ganguli, “Exponential expressivity in\ndeep neural networks through transient chaos,” 2016, pp. 3360–3368.\n[57] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation learning with deep convo-\nlutional generative adversarial networks,” ICLR, 2016.\n[58] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image\nsegmentation,” MICCAI 2015: Medical Image Computing and Computer-Assisted Inter-\nvention MICCAI 2015, 2015.\n[59] R. Rubinstein, A. M. Bruckstein, and M. Elad, “Dictionaries for sparse representation model-\ning,” Proceedings of the IEEE, vol. 98, 2010, pp. 1045–1057.\n[60] J. K. Seo, K. C. Kim, A. Jargal, K. Lee, and B. Harrach, “A learning-based method for solving\nill-posed nonlinear inverse problems: A simulation study of lung EIT,” SIAM Journal on\nImaging Sciences, vol. 12, 2019, p. 12751295.\n[61] J. K. Seo and E. J. Woo, “Nonlinear inverse problems in imaging,” John Wiley and Sons, 2013.\n[62] J. K. Seo, E. J. Woo, U. Katscher, and Y. Wang, “Electro-magnetic tissue properties MRI,”\nImperial College Press, 2014.\n[63] D. K. Sodickson and W. Manning, “Simultaneous acquisition of spatial harmonics (smash): fast\nimaging with radiofrequency coil arrays,” Magn. Reson. Med., vol. 38, 1997, pp. 591–603.\n[64] K. C. Tezcan, C. F. Baumgartner, R. Luechinger, K. P. Pruessmann, and E. Konukoglu, “MR\nimage reconstruction using deep density priors,” IEEE transactions on medical imaging,\n2018.\n[65] S. Tripathi, Z. C. Lipton, and T. Q. Nguyen, “Correction by projection: Denoising images with\ngenerative adversarial networks,” arXiv, 2018.\n[66] G. Wang and H. Yu, “Meaning of interior tomography,” Physics in medicine and biology, vol.\n58, 2013, pp. R161–R186.\n[67] S. Xie, X. Zheng, Y. Chen, L. Xie, J. Liu, Y. Zhang, J. Yan, H. Zhu, and Y. Hu, “Artifact\nremoval using improved googlenet for sparse-view CT reconstruction,” Scientic reports,\nvol. 8, 2018, p. 6700.\n[68] J. Yang, J. Wright, T. S. Huang, and Y. Ma, “Image super-resolution via sparse representation,”\nIEEE transactions on image processing, vol. 19, 2010, pp. 2861–2873.\n[69] R. A. Yeh, C. Chen, T. Yian Lim, A. G. Schwing, M. Hasegawa-Johnson, and M. N. Do,\n28\nC. M. HYUN, S. H. BAEK, M. LEE, S. M. LEE, AND J. K. SEO\n“Semantic image inpainting with deep generative models,” in Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition, 2017, pp. 5485 – 5493.\n[70] X. Yuan, P. He, Q. Zhu, and X. Li, “Adversarial examples: Attacks and defenses for deep\nlearning,” IEEE transactions on neural networks and learning systems, 2019.\n[71] Xin Yi, Ekta Walia, and Paul Babyn, “Generative adversarial network in medical imaging: A\nreview,” Medical Image Analysis, 2019, p. 101552.\n[72] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena, “Self-attention generative adversarial\nnetworks,” arXiv:1805.08318, 2018.\n[73] Z. Zhu, K. Wahid, P. Babyn, D. Cooper, I. Pratt, and Y. Carter, “Improved compressed\nsensing-based algorithm for sparse-view CT image reconstruction”, Computational and\nmathematical methods in medicine, 2013.\nSupplementary Material.\nThis appendix provides deep learning results for\nundersampled MRI, interior tomography, and sparse-view CT problem. To learn a\nreconstruction map f : x 7→y, we adopt the modiﬁed U-net architecture, described\nin Fig. 6, and set feature depths of the network to be multiples of 64.\nTo train U-net, we generate a training dataset {x(k), y(k)}ndata\nk=1\nin the following\nsense: Let {y(k)}ndata\nk=1 be a given set of medical images. Here, y(k) represents 256×256\nhead MR image in undersampled MRI problem and 256 × 256 abdominal CT image\nin interior tomography and sparse-view CT problem. The corresponding input data\nx(k) is generated by computing x(k) = A−1\nfullS∗\nsubAy(k). In our real implementation,\n1500 MR images [44] are used for undersampled MRI problem and 1800 CT images\nare used for interior tomography and sparse-view CT problem.\nWith the generated training dataset, U-net is trained by minimizing ℓ2 loss, as\nmentioned in (2.22). the minimization process was performed using Adam optimizer\nwith learning rate 0.001, mini-batch size 16, and 3000 epochs. In addition, Batch\nnormalization [39] is used for mitigating the overﬁtting issue.\nUNDERDETERMINED INVERSE PROBLEMS\n29\nTest input\nReference image\nU-net reconstruction\nError\nUndersampled\nMRI\n(only uniform subsampling)\nUndersampled\nMRI\n(uniform subsampling with\nadditional one phase encoding line)\nSparse-view CT\nInterior\ntomography\nFig. 17. Deep learning results using U-net for undersampled MRI, sparse-view CT, and interior\ntomography problem.\nThe images in ﬁrst, second, third, and fourth column represent test input\nimages, reference images, U-net reconstruction results, and errors, respectively.\n",
  "categories": [
    "eess.IV",
    "cs.LG",
    "stat.ML"
  ],
  "published": "2020-01-06",
  "updated": "2020-06-26"
}