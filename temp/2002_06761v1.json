{
  "id": "http://arxiv.org/abs/2002.06761v1",
  "title": "Hybrid Embedded Deep Stacked Sparse Autoencoder with w_LPPD SVM Ensemble",
  "authors": [
    "Yongming Li",
    "Yan Lei",
    "Pin Wang",
    "Yuchuan Liu"
  ],
  "abstract": "Deep learning is a kind of feature learning method with strong nonliear\nfeature transformation and becomes more and more important in many fields of\nartificial intelligence. Deep autoencoder is one representative method of the\ndeep learning methods, and can effectively extract abstract the information of\ndatasets. However, it does not consider the complementarity between the deep\nfeatures and original features during deep feature transformation. Besides, it\nsuffers from small sample problem. In order to solve these problems, a novel\ndeep autoencoder - hybrid feature embedded stacked sparse autoencoder(HESSAE)\nhas been proposed in this paper. HFESAE is capable to learn discriminant deep\nfeatures with the help of embedding original features to filter weak\nhidden-layer outputs during training. For the issue that class representation\nability of abstract information is limited by small sample problem, a feature\nfusion strategy has been designed aiming to combining abstract information\nlearned by HFESAE with original feature and obtain hybrid features for feature\nreduction. The strategy is hybrid feature selection strategy based on L1\nregularization followed by an support vector machine(SVM) ensemble model, in\nwhich weighted local discriminant preservation projection (w_LPPD), is designed\nand employed on each base classifier. At the end of this paper, several\nrepresentative public datasets are used to verify the effectiveness of the\nproposed algorithm. The experimental results demonstrated that, the proposed\nfeature learning method yields superior performance compared to other existing\nand state of art feature learning algorithms including some representative deep\nautoencoder methods.",
  "text": "Hybrid Embedded Deep Stacked Sparse Autoencoder with w_LPPD SVM Ensemble\nYongming Li*, Yan Lei, Pin Wang, Yuchuan Liu\nSchool of Microelectornics and Communication Engineering, Chongqing University, Chongqing, 400044, China\n(Corresponding Author: Yongming Li, yongmingli@cqu.edu.cn )\nAbstract:\nDeep learning is a kind of feature learning method with strong nonliear feature transformation and becomes\nmore and more important in many fields of artificial intelligence. Deep autoencoder is one representative method of\nthe deep learning methods, and can effectively extract abstract the information of datasets. However, it does not\nconsider the complementarity between the deep features and original features during deep feature transformation.\nBesides, it suffers from small sample problem. In order to solve these problems, a novel deep autoencoder - hybrid\nfeature embedded stacked sparse autoencoder(HESSAE) has been proposed in this paper. HFESAE is capable to\nlearn discriminant deep features with the help of embedding original features to filter weak hidden-layer outputs\nduring training. For the issue that class representation ability of abstract information is limited by small sample\nproblem, a feature fusion strategy has been designed aiming to combining abstract information learned by HFESAE\nwith original feature and obtain hybrid features for feature reduction. The strategy is hybrid feature selection\nstrategy based on L1 regularization followed by an support vector machine(SVM) ensemble model, in which\nweighted local discriminant preservation projection (w_LPPD), is designed and employed on each base classifier.\nAt the end of this paper, several representative public datasets are used to verify the effectiveness of the proposed\nalgorithm. The experimental results demonstrated that, the proposed feature learning method yields superior\nperformance compared to other existing and state of art feature learning algorithms including some representative\ndeep autoencoder methods.\nKey words: Embedded deep learning; Hybrid feature embedded stacked sparse autoencoder(HESSAE); weighted\nlocal discriminant preservation projection (w_LPPD); Feature fusion; Ensemble learning.\n1. Introduction\nIn the pattern recognition tasks, the strength of the class representation of the features has a decisive effect on\nthe performance of the model. However, redundant information and noise are inevitable for most of the data\ngenerated in real life, which will lead to increased complexity and decreased performance of classifier [1]. In\naddition, it is difficult to obtain the increasingly complex relationships latent in data, which are beneficial to\nenhance classification performance. Feature learning, a crucial step in pattern recognition tasks, is able to mine key\ninformation in data according to specific tasks, while reducing data dimensions. Therefore, it has attracted widely\nattentions in recent decades [2-4].\nVarious methods of feature learning have been proposed and they are mainly divided into two categories:\nfeature selection and feature extraction. Feature selection [5] can be seen as a process of searching for an optimal\nfeature subset with strong classification ability according to criteria and obtain high-dimensional characteristics by\nanalyzing low-dimensional data. It is an effective technique to acquire key features from the initial feature space\nand simplify data analysis. The typical feature selection algorithms include regularization methods -- Least absolute\nshrinkage and selection operator (Lasso) [6], filter method – Relief [7] and p_value [8], and so on. Feature\nextraction mainly aims to map original high-dimensional data to a specific low-dimensional space by minimizing\ninformation loss. Well-known algorithms contain principle component analysis (PCA) [9], linear discriminant\nanalysis (LDA) [10], locality preserving projections (LPP) [11], etc. PCA projects the original d-dimensional data\nonto the l-dimensional linear subspace (l < d), which is spanned by the principal eigenvectors of data’s covariance\nmatrix. LDA searches the linear subspace by minimizing the within-class scatter and maximizing inter-class scatter.\nBoth of these two methods are linear dimension-reduction methods. Despite its successful use in computer vision\nand pattern recognition, the linear model may fail due to most real-world data is nonlinear. LPP, a typical\nrepresentative algorithm of manifold dimensionality reduction, can optimally preserve the neighboring structure of\nthe dataset and has received extensive attention.\nHowever, large amount of data generated in various fields is not only large in volume but also heterogeneous\nor complex in nature. Conventional feature learning algorithms are shallow feature learning and rely on empirical\nknowledge, which cannot effectively mine the inherent non-linear complex relationships between data, thus, there\nare some limitations for these methods. In recent years, deep feature learning techniques have achieved\nstate-of-the-art performance in various fields, such as image classification [12-13], speech recognition [14-15],\nmachine translation[16-17], etc. Multi-layer neural network has excellent feature learning ability, and the learned\nfeatures have a more essential description of the data, which is conducive to visualization or classification [18].\nAutoencoder (AE) [19], a typical deep learning model, is able to learn data representations by minimizing\nreconstructed errors between input data and outputs. AEs are easy to stack by taking the outputs of last hidden layer\nof AE as the inputs of the next AE, which is named stacked autoencoder(SAE). As SAE has advantages of deep\nneural network and strong expressive ability, SAEs and extensions such as stacked sparse autoencoders(SSAE),\nstacked\ndenoising\nautoencoders\n(SDAE)\ndemonstrate\na\npromising\nability\nto\nlearn\nmeaningful\nrepresentations[20-22]. SSAEs can find some interesting structures in the input data by introducing sparse\nconstraints, while SDAEs learn useful information by reconstructing input data that contains noise. Although\nSSAEs and SDAEs have achieved some success in subsequent applications [23-26], effective feature learning of\nAEs is still a challenging problem. A recent study [27] designed a deep kernelized autoencoder by aligning inner\nproducts between codes with respect to a kernel matrix. The proposed autoencoder can learn similarity-preserving\nembedding of input data. The study [28] proposes an enhanced stacked denoising autoencoder (ESDAE) with\nmanifold regularization for wafer map pattern recognition in manufacturing processes. Specifically, it applies\nmanifold regularization for deep learning to detection and recognition of wafer map defects for further improving\nperformance in describing data distributions. The research [29] proposes to introduce a distance constraint that is\nadded to the SSAE to form a new distance constrained SSAE (DCSSAE) network. They believed that distance\nconstraint can maximize the distinction between the target pixels and other background pixels in the feature\nspace.Yet, there are still some potential drawbacks with these structures. Firstly, it is not always clear what kind of\nproperties of the input data need to be captured by the autoencoders. Not all the features learned by hidden layers\nare always useful and representative, and sometimes even display a reduced discrimination ability to classification\ntasks. Secondly, due to a large number of parameters, deep autoencoders are easy to suffer from overfitting with\nsmall size sample, which limits the generalization ability of the deep autoencoders to learn effective features.\nTo tackle the issues mentioned above, a Hybrid Feature Embedded Sparse Stacked Autoencoder(HESSAE)\nhas been proposed here. The primary idea of HESSAE is to evaluate the effectiveness of the outputs in hidden\nlayers and introduce the constraints of original information in the layer-wise training process. To achieve that,\noriginal features are embedded into the encoded outputs of each AE to filter out hidden representations with weak\ndiscrimination ability. Then the original features are embedded into the output of the current layer (hybrid features)\nto construct feature representations at higher hidden layers, retaining a certain amount of useful information and\nbeing employed to classification task. Sparsity constraint is employed on hidden units to improve the capacity to\nmine more interesting structure in data. In order to solve the small size sample problem, a feature fusion strategy\nhas been designed. Specifically, feature selection based on L1 regularization is applied on hybrid features output by\nthe HESSAE. In order to further eliminate redundancy of the features and improve the generalization ability of the\nproposed algorithm, support vector machine (SVM) ensemble model with weighted local discriminant preservation\nprojection (w_LPPD) has been constructed. W_LPPD is a novel manifold learning method proposed by the authors,\nwhich considers outliers in the samples and effectively removes some samples far away from the center of the class.\nThe main contributions and innovations of this paper can be stated as follows:\n(1)In this paper, hybrid feature embedded unit is introduced into training process for the first time to construct\nHFESAE, which can obtain the features more complementary with the original features.\n(2)In terms of feature fusion, we designed a manifold ensemble learner, which make the deep features learned by\nHFESAE more efficient for small size samples learning.\n(3)Three-step feature learning not only learns deep features with abstract information but also adapts to small\nsamples learning. Meanwhile, it is able to remove low-quality and invalid features, and reduce dimensions, thus\nimproving the accuracy and reliability in subsequent classification tasks.\n(4) The hybrid embedded idea can be applied into other deep learning methods except deep stacked autoencoder.\nThe rest of this paper is organized as follows: section 2 enumerates the related work; section 3 mainly\nillustrates the proposed algorithm. Experiments and results are presented in section 4 and the final section is\ndiscussion and conclusion.\n2. Related work\nIn this section, some representative deep autoencoder models and feature fusion methods are reviewed briefly.\nDeep autoencoder models mainly including typical stacked autoencoder, stacked sparse autoencoder and improved\nsparse\nautoencoder.\nIn\nthis\npaper,\nthe\ndata\nmatrix\nis\ndenoted\nas\n1\n2\n={ ,\n,\n,\n}\nN n\nN\nX\nx x\nx\n\n\n\nand\n1\n2\n(\n,\n,\n,\n)\nn\ni\ni\ni\nin\nx\nx\nx\nx\n\n\ndenotes the i-th sample, where\nN\nand\nn\nare the number of samples and feature\ndimension respectively.\n1\n2\n{ ,\n,,\n,\n}\nN d\nN\nH\nh h\nh\n\n\n\n\nis the output matrix of hidden layer of autoencoder, where d\nis the dimension of the feature vector in hidden layer .\n(a)\n(b)\nFig.1. (a) autoencoder(AE); (b) stacked autoencoder(SAE).\n2.1 Representative Stacked Autoencoder models\nA. Stacked Autoencoder(SAE)\nAutoencoder (AE) [19] is one type of artificial neural networks structurally defined by three layers: input layer,\nhidden layer and output layer, which compose an encoder and a decoder. In the AE, the encoder transforms date\nmatrix X into a hidden representation H with a tunable number of neural units\nd , and fallowed by a nonlinear\nactivation.\nB. Stacked Sparse Autoencoder(SSAE)\nAutoencoder is originally proposed based on the idea of dimensionality reduction, which will lose the ability\nto automatically learn features when there are more hidden layer nodes than the input nodes. Sparse\nautoencoder(SAE) [31] is obtained by adding some sparse constraints on the traditional autoencoder, that is\nsuppress most of the output of hidden layer neurons.\nC. Locality-Constrained Sparse Autoencoder(LSAE)\nLuo et al. [32] proposed a locality-constrained sparse auto-encoder (LSAE) for image classification. They\nbelieve that the locality is more essential than sparsity for classification tasks. Therefore, the concept of locality is\nintroduced into the sparse autoencoder, which ennables the autoencoder to encode similar inputs using similar\nfeatures.\nD. Weight-Clustering Sparse Autoencoder(WCSAE)\nFan et al. [33] proposed a weight-clustering sparse autoencoders(WCSAE) combined object-oriented classification\nwith difference images. They believed that superfluous features are extracted in high-level feature extraction when\nsimilar weights exist in the weight matrix, which cannot enhance the performance to represent data. Therefore,\nsimilar weights in the hidden layer of WCSAE are clustered layer-wise.\nE. Stacked Pruning Sparse Autoencoder(SPSAE)\nHaiping Zhu et al. [45] proposed a new stacked pruning sparse autoencoder (SPSAE) model. The main idea\nof this model is to uses the superior features extracted in all the previous layers to participate in the subsequent\nlayers, thus to create new channel between the front layers and the back layers. In addition, a pruning operation is\nadded into the model so as to prohibit non-superior units from participating in all the subsequent layers.\nSpecifically, the SPSAE is constructed by SAE model, whose training objection is followed by Eq.9. Theses SAEs\nare constructed as a fully connected network rather than simply connected in series, which is, directly connecting\nthe layers with feature mapping in the network. In this way, the input of the each layer comes from the output of all\nthe previous layers and the feature information of previous layers can be shared to subsequent layers. To solve the\nproblem of the increased number of SAE units and training time, the input data of the units with large\nreconstruction errors in pre-training are prohibited from participating in the subsequent training process, which is\ncalled pruning operation.\n2.2 Deep-Shallow Feature Fusion\nIn recognition tasks, combining relevant information of multiple features is divided to decision level fusion\nand feature level fusion. Majtner et al. [34] proposed a decision level fusion algorithm for skin lesion classification.\nThey combined two SVM classifier. One used hand-crafted features, and another employed feature derived from\nCNN. Both of the two classifier predicted the class or class score, then the label with the highest absolute score\nvalue would be chosen as result. To classify the thyroid nodules, Liu et al. [35] also fused deep features learned by\nCNN and three kinds of conventional features in decision level, but the classification result was determined by\npositive-sample-first majority voting strategy.\nIn terms of feature level fusion, Suk et al. [36] extracted abstract information in raw handcrafted imaging\nfeatures by deep autoencoder as deep features, which were concatenated with raw feature vectors. Sparse learning\nwas employed on cascaded feature to select optimal subset, which is send to clssifier for AD/MCI diagnosis. Mei et\nal. [37] proposed an unsupervised-learningbased feature-level fusion approach for mura defect recognition.\nFeatures extracted by the unsupervised-learning-based model and the handcrafted descriptors are simply concatenated to\nform the representations of defect images. Kan [38] proposed a general fusion unit to fuse handcrafted feature\ninformation and CNN representations. Specifically, both of them were transformed into a relatively consistent\nspace by fully connected converter, respectively, which can suppress useless information. Then, merge two type\nfeatures by a supervised feature embedding layer.\n3. The proposed method\nIn this section, the proposed algorithm is introduced here. This algorithm mainly includes three parts. First, a\nproposed hybrid feature embedded stacked sparse autoencoder(HESSAE) is proposed for learning the feautres with\nhigh complementary with original features. Seconded, L1 regularization learning is designed and applied on the\nhybrid features (output of HESSAE and original features) to select optimal feature subset. Finally, an ensemble\nmodel is established based on w_LPPD and SVM. The three-step feature leaning method is able to extract abstract\ninformation as well as retain initial information and remove redundancy among features.\n3.1 Hybrid-Feature embedded sparse stacked autoencoder (HESSAE)\nThe proposed hybrid-feature embedded stacked sparse autoencoder(HESSAE) model is given in Fig. 2.\nFig.2. Hybrid feature embedded stacked sparse autoencoder (HESSAE)\nThe embedding unit between two encoders is an important component for the proposed model. Assuming HESSAE\nis constructed by K autoencoders, and\n( )\n( )\n( )\n( )\n( )\n1\n2\n{\n,\n,\n,\n}\nk\nk\nk\nk\nk\nN d\nN\nH\nh\nh\nh\n\n\n\n\ndenotes the output matrix of k-th hidden\nlayer. The first autoencoder in HESSAE is traditional autoencoder training The coded feature vectors in the rest\nlayers of HESSAE can be defined as:\n1\n( )\n(\n1)\n1\n(\n(\n)\n),     1\nk\nk\nT\nk\nk\nk\nK\nW\nh\nf\nL x\nh\nb\n\n\n\n\n\n\n(1)\nWhere\n1\nk\nW\nand\n1\nkb\nare weight matrix and bias vector of encoder in k-th autoencoder respectively. In this paper,\nlogistic sigmoid function\n1\n( )\n1\nexp(\n)\nf x\nx\n\n\n\nis used as the activation function.\nIn Eq. (1), represents concatenating learned feature vector and original feature vector, and L denotes an embedding\nunits, which can be formulated by:\n(\n1)\n(\n1)\n(\n)\n(\n)\nk\nT\nk\nL x\nh\nG\nx\nh\n\n\n\n\n\n(2)\nWhere\n(\n1)\n(\n1)\n(\n)\nk\nk\nn d\nd\nG\n\n\n\n\n\nis the corresponding transformation matrix consisted by zero and one. The embedding\nunits aims to introduce certain initial information constraint during layer-wise pre-training process, meanwhile,\nfilter out some useless features. Considering the divergence of feature can explain their class discrimination ability\nto some extends, the objective function of embedding units can be defined as:\n(\n1)\n(\n1)\n(\n1)\nmax\n(\n(\n)(\n)\n)\n.\nT\nk\nk\nT\nG\nk\nij\ntr G\nX\nH\nX\nH\nG\ns t\nG\nd\n\n\n\n\n\n\n\n(3)\nWhere\n( )\nk\nd\nis the number of hidden units in kth layer. Calculating covariance matrix D of\n(\n1)\nk\nX\nH\n\n\nand sorting\nthe diagonal elements in decreasing order. Then the first\n1\nk \nvalues are taken to form a vector\n(\n1)\nk\ns\n\n\n. The\nelements ofG can be determined by:\n1,   if  \n0,   \nij\nj\nii\ns\nG\notherwise\nD\n\n\n\n(4)\nWhere\nii\nD\nis\nthe\nith\ndiagonal\nelement\nof\ncovariance\nmatrix\nD\n,\njs\nis\nthe\nj-th\nelement\nof\ns ,\nand\n(\n1)\n(\n1)\n[1,\n],\n[1,\n]\nk\nk\ni\nn\nd\nj\nd\n\n\n\n\n\n.\nWith Eq. (1-4), the hidden outputs of each autoencoder can be obtained. The\ndecoder function of kth autoencoder can be rewritten as:\n2\n(\n1)\n( )\n2 ,    \n'(\n)\n(\n)\n1\nT\nk\nk\nk\nk\nL x\nh\nf W h\nb\nk\nK\n\n\n\n\n\n\n(5)\nWhere\n'\nL denotes the reconstruction for the output of embedding unit.\n2\nk\nW\nand\n2\nkb are weight matrix and bias vector\nof k-th decoder. In the training process, sparse criterion is applied to hidden layers of HESSAE to discover\ninteresting structures in input data. In this paper, Kullback-Leibler (KL) divergence as a tractable unsupervised\nobjective is introduced in order to sparse representation. It is the relative entropy to measure the difference between\ntwo Bernoulli random variables: the average activation\nj\n\n\nof the j-th hidden unit and the target average\nactivation . KL divergence is formulated as follows:\n1\n1\n( )\n1\n1\n(\n||\n)\nlog(\n)\n(1\n)log(\n)\n1\n1\n(\n)\nd\nd\nj\nj\nj\nj\nj\nN\nj\ni\nj\ni\nKL\nf\nx\nN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\nWhere\n( )\n(\n)\nj\ni\nf\nx\nis the activation value of the i-th input vector to the j-th unit of hidden layer. The value increases\nmonotonously along with the increasing different between and\nj\n\n\n, and when\nj\n\n\n\n\n,\n(\n||\n)\n0\nj\nKL \n\n\n\n.\nTherefore, by setting a small sparse parameter , most of the average outputs of hidden units are zeros and, thus,\nsparse representation can be achieved. By introducing embedding units and sparse constraint, the training object\nfunction of kth (\n1\nk ) layer in HESSAE can be written as follows:\n( )\n(\n1)\n(\n1)\n2\n1\n2\n2\n2\n1\n1\n1\n1\narg  min\n||\n(\n)\n'(\n) ||\n(||\n||\n||\n|| ) \n(\nlog(\n)\n(1\n)log(\n))\n1\nk\nN\nd\nk\nk\ni\ni\ni\ni\nk\nk\ni\nj\nj\nj\nL x\nh\nL x\nh\nW\nW\nN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(7)\nWhere \nand \ndenote Penalty parameters of regularization term and sparsity constraint respectively. Training\nprocess with eq. (18) is called pre-training, after which the hidden layer of pre-trained autoencoders are cascaded\none by one to form a stacked autoencoder, and its initial parameters are determined by pre-training. Focusing on the\nultimate goal is to obtain features with better category representation ability, so we further optimize the whole\nnetwork in a supervised manner. In order to achieve that, softmax layer are taken as classification layer connected\non the top of the HESSAE. The fine-tune process of the stacked network is based on back-propagation with\ngradient decent. Because of the characteristics of pre-tune, the fine-tune flowing it can reduce the risk of falling\ninto local optimum. The proposed HESSAE algorithm is summarized in Algorithm 1.\nThe learned nonlinear transformation by HESSAE can be regard as a effective feature learning, which not only\nmakes use of the characteristics that deep network can learn the potential relationships among data, but also\nimproves the robustness of deep features by introducing initial information constraint into the deep network. After\nthe training of the whole network, for every input original feature vector\n1\n2\n(\n,\n,\n,\n)\ni\ni\ni\nin\nx\nx\nx\nx\n\n\n, a new feature vector\ncan be obtained in each hidden layer and different layer represents different level information. Generally, the higher\nthe layer in the network, the more complicated or abstract patterns inherent in the input data there is. Therefore, we\ntake the outputs of the last hidden layer as learned deep feature, recorded as\n1\n2\n'\n(\n',\n',...,\n')\ni\ni\ni\niq\nx\nx\nx\nx\n\n. Then we\nconstruct an augmented feature vector\nix\n\nby concatenating\nix\nand\n'\nix :\n(\n)\n1\n2\n1\n2\n \n (\n, x ,\n,\n, \n',\n',...,\n')\n \nn q\ni\ni\ni\nid\ni\ni\niq\nx\nx\nx\nx\nx\nx\n\n\n\n\n\n（8）\nAlgorithm 1: HESSAE\nInput: training data X\nStep1: Setting parameters, including: , , , and the number of hidden units in each AE, number of\niteration.\nStep2: Pre-training:\n1) Training the first layer of HESSAE and extracting the output of encoder as\n1\nH（）.\n2)for k =2:K\na) Embedding original feature into deep feature\n1\nH（k- ）by Eq(2); transformation matrix G is\ndetermined by Eq. (3-4).\nb) Training the kth AE with object function in Eq. (7), then extracting the output\nk\nH（）of hidden\nlayer, which will be the input of next AE.\nend\nStep3: Stacking the hidden layer and adding an softmax layer on the top, of which the input is\n( )\nk\nH\nStep4: Fine-tune the whole network based on back-propagation with gradient decent, and the training goal is to\nminimize classification loss.\nStep5: Extracting the output\n( )\nk\nH\nof final hidden layer in the fine-tuned HESSAE as learned deep feature.\nOutput: Deep feature\n3.2 Hybrid feature selection strategy based on L1 regularization\nThe hybrid feature vector obtained according to Eq. (8) has richer category information. However, simple\ncombination will lead to high dimension problem, which means possible dimension disaster. On the other hand, we\nbelieve that these features are not independent, and there is some redundant information among two types of feature.\nTherefore, it is necessary to process the candidate feature vector effectively to extract the most useful information.\nSpecifically,\n1L\nregularization uses a penalty term to control the sum of the absolute values of the parameters\nto be small, giving a sparse feature vector. For the new dataset\n1\n{( ,\n)}N\ni\ni\ni\nX\nx y\n\n\n\n\n, where\nn q\nix\n\n\n\ndenotes ith\nsample with hybrid features and\niy\nis corresponding label. Considering the simplest regression model with the\nsquared error as loss function, the optimization objective function can be defined as:\n2\n1\n1\n1\narg min\n(\n)\n|\n|\nn q\nn q\nN\ni\np\nip\np\nw\ni\np\np\ny\nw x\nw\n\n\n\n\n\n\n\n\n\n\n\n\n(9)\nWhere L1-regularization is introduced to mitigate the problem of overfitting.\np\nw is the regression coefficients of\npth feature. \ndenotes a sparsity control parameter, and the larger it is, the more sparse the model is. Proximal\nGradient Descent is used to solve Eq. (9), and the iteration of each step should be:\n( )\n2\n(\n1)\n( )\n2\n1\n2\n1\n( )\n(\n(\n(\n)\n) )\n1\nargmin\n||\n(\n) ||\n||\n||\n2\nN\nk\nT\ni\ni\nk\nk\ni\nk\nw\ny\nw\nx\nM\nw\nw\nw\nw\nM\nw\n\n\n\n\n\n\n\n\n\n\n\n\n(10)\nWhere\n1\n2\n(\n,\n,\n)\nn\nq\nw\nw w\nw \n\n\n, M is a constant great than zero.\nAssuming\n( )\n2\n( )\n1\n( )\n(\n(\n(\n)\n) )\n1\nN\nk\nT\ni\ni\nk\ni\nk\ny\nw\nx\nu\nw\nM\nw\n\n\n\n\n\n\n\n\n, the closed-form solution of Eq. (10) can be calculated by:\n(\n1)\n/\n,  \n/\n  ;\n   0,              |\n|\n  \n/\n;  \n/\n,  \n/\n;\np\np\nk\np\np\np\np\nu\nM\nM\nu\nw\nu\nM\nu\nM\nu\nM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(11)\nIn Eq. (11),\n(\n1)\nk\np\nw\n\nand\np\nu\nare the p-th component of\n(\n1)\nk\nw\n\nand u respectively. The result of solving the L1-\nnormalization expresses that only features corresponding to the non-zero component of\np\nw\ncan be choose to the\nfinal feature subset.\n3.3 w_LPPD SVM ensemble model\n3.3.1 Weighted locality preserving discriminant projection（w-LPPD）\nWeighted local preserving discriminant projection is a novel effective feature reduction method, which\nconsiders outliers in the samples, removing some samples far away from the center of the class. Firstly, it\nintroduces random subspace sampling; Secondly, locality preserving discriminant projection is established based on\nthe proposed objective function; finally, integrating multi-space mapping matrices to construct the ultimate\nmapping matrix. Assuming\nmc\nk\ndenotes the number of samples sampling for c-th, the number of total samples\nafter sampling is\n1\nC\nm\nmc\nc\nk\nk\n\n\n. The local between-class scatter matrix\nLB\nS\nwith the\nm\nk\nnearest neighbors of the\ncenter\nlb\n\n, and the local within-class scatter matrix\nLW\nS\nwith the\nmc\nk\nnearest neighbors of the class\ncenter\nlwc\n\ncan be defined as follows:\n1\n(\n)(\n)\nC\nLB\nlc\nlbc\nlb\nlbc\nlb\nc\nS\nN\n\n\n\n\n\n\n\n\n\n(12)\n( )\n( )\n1\n1\n(\n)(\n)\nmc\nc\nc\nC\nT\nLW\ni\nlwc\ni\nlwc\nc\ni\nk\nS\nx\nx\n\n\n\n\n\n\n\n\n(13)\nWhere local numbers\nm\nb\nk\nr\nN\n\n\n\n\n\nand\nmc\nw\nc\nk\nr\nN\n\n\n\n\n\n,\nbr\nand\nwr\nare sampling ratio coefficients, N and\nc\nN\nare\nthe number of total sample and c-th sample respectively.\n1,\n(\n)\n1\nm\nlb\ni\ni\nm\nm\nkm\nN\nk\nx\nx\nk\n\n\n\n\n\nis the center of local part for\nLB\nS\ncomputation,\n( )\n1,\n(\n)\n1\nlc\nc\nlbc\ni\ni\nm\nlc\nkm\nN\nN\nx\nx\nN\n\n\n\n\n\nis the center of the c-th local part for\nLB\nS\ncomputation,\nlc\nN\nis the\nnumber of the c-th class in local part, and\n( )\n( )\n1,\n(\n)\n1\nlc\nc\nc\nmc\nc\nlwc\ni\ni\nmc\nk\nN\nN\nm\nx\nx\nk\n\n\n\n\n\nis the center of the c-th local class for\nLW\nS\ncomputation.\nFurthermore, the locality preservation regularization term is shown as follows:\n2\n1\n1\n1\n1\nmin\n2\n(\n(\n)\n)\n(\n)\nN\nN\nT\nT\nij\ni\nj\nW\ni\nj\nN\nN\nT\nT\nT\nij\ni\ni\ni\nj\ni\nj\nT\nT\nA W x\nW x\nTr W\nA x x\nx x\nW\nTr W XLX W\n\n\n\n\n\n\n\n\n\n\n(14)\nWhere L is the Laplacian matrix ,\nii\nij\nj\nD\nA\n\nis the diagonal matrix, and A is the affinity matrix, which can be\ncalculated in following manners:\n1,   \n(\n) || \n( )\n0,    \n                              \ni\nk\nj\nj\nk\ni\nij\nif x\nN\nx\nx\nN\nx\nA\nothers\n\n\n\n\n\n(15)\nWith Eq. (12-14) and the proposed w-LPPD can be formulated as:\nmin\n(\n)\n. . \n(\n)\n(\n)\nT\nLW\nW\nT\nT\nT\nLB\nTr W S\nW\ns t Tr W S W\nTr W XLX W\nI\n\n\n\n\n(16)\nWhere represent the regularization coefficient, \nis constant. It can be seen from the objective function that the\nw-LPPD aims to minimize the trace of local within-class scatter matrix and maximize the between-class scatter\nmatrix while preserving the locality of the sample.\nBy introducing Lagrange multiplier , the objection function Eq. (16) finally can be written as:\n(\n, )\n(\n)\n(\n)\nT\nT\nT\nT\nLW\nLB\nL W\nTr W S\nW\nW S W\nW XLX W\nI\n\n\n\n\n\n\n\n\n(17)\nTaking the derivation of W and obtain optimal solutions.\n1\n(\n, )\n0\n{\n(\n)\n(\n)}\n0\n(\n)\nT\nT\nT\nT\nLW\nLB\nT\nLB\nLW\nL W\nW\nTr W S\nW\nW S W\nW XLX W\nI\nW\nS\nXLX\nS\nW\nW\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(18)\nApparently, through Eq. (18), the projection matrix W can be easily obtained by generalized eigenvalue\ndecomposition. The vector\n1\n2\n(\n,\n,...,\n)\nk\nk\nW\nw w\nw\n\nis comprised of the top k eigenvectors of W . Then, the original\ndata can be projected into a low dimension space spanned by the columns of\nk\nW\nto achieve dimensionality\nreduction. As mentioned before, we exploit LPPD on random subspace, so we can get P projection matrixes:\n1\n2\n,\n,  \n ,\np\nk\nk\nk\nW W\nW\n\n. The final mapping matrix\nF\nk\nW\nis obtained by weighting\n1\n2\n,\n,  \n ,\np\nk\nk\nk\nW W\nW\n\n. Its mathematical\nexpression as follows:\n1\n2\n1\n2\n1\n \n \np\nF\np\np\nk\nk\nk\np\nk\ni\nk\ni\nW\nW\nW\nW\nW\n\n\n\n\n\n\n\n\n\n(19)\nWhere\ni\nis the weight coefficient, it can be determined by grid search. Note that\n1\n1\np\ni\ni\n\n\n\n\n.\nThrough w_LPPD, we can further map the deep-shallow feature subset selected by L1 regularization to another\nlow-dimension feature space, where the distance of samples from different class will be farther, but the distance of\nsamples from same class will be closer. According to that, the feature obtained by this way own more effective\nclass representation and discriminant ability\n3.3.2 Ensemble learning based on w_LPPD and SVM\nAssuming that sampling ration of samples and features are\n1\nand\n2\nrespectively, and sampling K times\nto form\nK\nsubsets based on bagging strategy. Then w_LPPD is applied on each subsets. The ultimate\nK\ntraining subsets obtained by w_LPPD will respectively be fed into K\nbase classifiers for training. In this paper,\nsupport vector machine(SVM) is used as base classifier. The classification result of validation samples will be\ndecided by weighting voting mechanism. The weight of each classifier can be calculated according to the following\nformula:\n1\n,\n(\n)\ntrain\nik\ni\nN\ni\nk\ntrain\nC\ny\nw\nN\n\n\n\n(20)\nWhere\n,\n \n1 ,  \n \n(\n)\n0 ,        \nik\ni\nik\ni\nC\ny\nC\ny\nothers\nif\n\n\n\n\n\n,\ntrain\nN\nmeans the number of training set. Assuming the class number of dataset\nis C , for i-th sample\nix with label\niy\n,\nik\nC\nis the forecast result of k-th classifier. The probability of sample\nix\nbelongs to c-th class can be expressed as:\n1\n1\n(\n)|\n(\n, )\nc\ni\nK\nC\nc\nkc\nik\nk\nP x\nx\nw\nC\nc\n\n\n\n\n\n(21)\nThen the ultimate class label predicted by the ensemble model can be decided by following formula:\n1\n2\n'\nmax{ (\n), (\n), \n , (\n)} \nC\ni\ni\ni\ni\nc\ny\nP x\nx\nP x\nx\nP x\nx\n\n\n\n\n\n(22)\n4. Experimental result and analysis\n4.1 Data and Experimental conditions\nIn our study, groups of experiments have been performed on several datasets with different sample size and\nfeature dimension to validate the performance of the proposed method. Brief information about dataset is shown in\nTable Ӏ.\nAll experiments were carried out in an experimental environment: the experimental operating system is\nWindows 10, 64-bit operating system, and the memory size was 128 GB. The programming tool is MATLAB,\nvision R2018b.\nFor description, the number of base autoencoder in the proposed HESSAE is set as three. The number of each\nhidden units is determined by taking into account of the dimensionality of the original feature vector for different\ndatasets to choose range and using grid search to find the best structure. It is worth noting that different structure\nfor different dataset reflects the necessity of considering different high-level non-linear relations inherent in\nlow-level feature for different classification tasks. The tunable parameters in the proposed HESSAE model mainly\ncontains regularization\nTable Ӏ. Basic information of datasets\nDatabase name\nInstances\nAttributes\nClass\nRelevant papers\nAD\n90\n32\n3\nReference [39]\nStatlog_Landsat_Satellite\n(Statlog)\n6435\n36\n6\nReference [41]\nPen-Based Recognition of\nHandwritten Digits\n(Pen-Digits)\n10992\n16\n10\nReference [42]\nUrban land cover\n( Urban)\n675\n148\n9\nReference [44]\nparameter , \nand sparsity parameter .The optimal structure and parameters of the HESSAE models in our\nexperiments are presented in table П.\nTable П.\nThe HESSAE structure and parameters for seven datasets\ndatasets\nHidden units\n\n\n\nepochs\nAD\n100 - 50 - 25\n10-5\n5\n0.02\n500\nUrban\n600 - 300 - 80\n10-3\n2\n0.07\n600\nPen-Digits\n80 - 30 - 10\n10-4\n4\n0.05\n1000\nStatlog\n120 - 60 - 20\n10-3\n5\n0.05\n1000\nFor w_LPPD SVM ensemble, local ratio coefficients in w_LPPD are set as\n0.9\nbr \n,\n0.9\nwr \n, the sampling\nration\n1=0.7\n\n,\n2 =0.5\n\n, and the number of base classifier is set as five. In experiment, hold-out cross validation\nmethod was used. That means for all datasets, the labeled samples were split into two subsets, one accounted for\none-third of all samples as test data, and the rest as train data. In order to eliminate the influence of accidental\nfactors, each experiment was repeat five times to calculate the average accuracy and standard deviation as ultimate\nperformance.\n4.2 Verification of the proposed method\nIn order to reflect the efficiency of the proposed algorithm, our methods are compared with representative\nfeature learning methods, including feature selection algorithms: Lasso, relief and p_value; feature extraction\nalgorithms: PCA, LDA, and LPP. To ensure a fair comparison, in each experiment, the training samples and test\nsamples for each method are identical, and grid-search is used to find the best parameter for these methods. Taking\ninto account of the base classifier in our methods is SVM, so we adopted SVM as classifier to evaluate\naforementioned approaches. The average accuracy and variance are listed in table Ш.\nTable Ш illustrated that the proposed method have a superior performance compared to others. For six datasets,\nour methods can significantly improve classification accuracy. For example, the classification accuracies on AD\nand LSVT are enhanced by more than 12% compared with no processing, and they are also outperform traditional\nfeature selection and feature extraction methods. In addition, as what can be seen, the standard deviations under our\nmethod are significantly smaller, which means that our algorithm is more stable. The possible reason is that the\nproposed method is capable to discover potential patterns among the data and effectively fuse the low-level and\nhigh-level features followed by dimension-reduction ensemble model, thus improving classification accuracy\nobviously. We also can see the proposed method have better generalization capability.\nTable Ш. Classification accuracy (meanvariance) of different algorithms (%)\nOF\nPCA\nLDA\nLPP\nRlief\nLasso\nP_value\nProposed\nmethod\nAD\n54\n9.54\n60\n8.49\n60\n7.07\n58.67\n6.91\n56.66\n8.49\n55.33\n8.02\n48.67\n7.67\n67.33\n2.49\nUrban\n79.99\n1.04\n81.51\n1.02\n82.57\n0.73\n81.96\n0.81\n81.15\n0.87\n79.64\n0.96\n79.82\n1.79\n83.20\n1.01\nPen-Digits\n97.52\n0.22\n97.49\n0.23\n97.37\n0.35\n97.91\n1.14\n96.94\n0.26\n97.52\n0.22\n93.07\n2.21\n98.00\n0.12\nStatlog\n86.64\n0.41\n87.43\n0.57\n87.23\n0.42\n87.54\n0.59\n86.59\n0.22\n86.61\n0.33\n86.63\n0.29\n87.28\n0.12\nNotes OF: Original features\nIn order to verify the feature extraction capability of the proposed hybrid feature embedded sparse stacked\nautoencoder(HESSAE), stacked autoencoder(SAE), stacked sparse autonencoder(SSAE) are compared with the\nproposed network. The proposed autoencoder without sparse constraints named HESAE, which is used as a\ncomparison to verify the necessity of sparse constraints for HESSAE. All the networks are constructed with three\nhidden layers and a softmax layer. The regularization parameters and sparse parameter are set to the same values.\nThe classification accuracy of the deep features learned by the above structures are recorded in Table Ⅳ. As shown\nin table Ⅳ, the proposed method structure achieved the highest accuracy in most cases, which proves the idea of\nintroducing initial information into and filtering out some less discriminative features in pre-processing is feasible.\nIn table Ⅳ, we also can observe that sparse constraints can significantly improve the robustness of deep\nautoencoders, no matter the conventional one or the proposed one.\nTable ⅣClassification accuracy (mean variance) of different deep autoencoder classifiers(%)\nSAE[20]\nSSAE[31]\nProposed\nHESSAE\nProposed\nHESAE\nAD\n50.677.95\n56.675.27\n59.333.65\n56.004.94\nUrban\n74.483.33\n79.730.67\n71.912.63\n68.003.09\nPen-Digits\n89.641.44\n93.800.51\n96.040.47\n94.070.53\nStatlog\n83.670.36\n84.850.84\n86.360.59\n86.390.43\nFurthermore, the major parts of the proposed method are verified. To verify the high-level feature learned by\nHESSAE can been regarded as the latent representations with discriminant information hidden in the data, we\ndesigned experiments that only use high-level feature. To validate the combination of low-level feature and\nhigh-level feature will result in high dimensionality and high redundancy, simultaneously show our methods can\nmitigate these problems gradually, we set up experiments that use merged features without process, merged feature\nwith L1 regularization, and merged feature with the proposed fusion mechanism, respectively. The results are listed\nin tableⅤ.\nAs we can see, deep features do have a certain class representation ability, and sometimes they are similar to\nor even exceeded the original features. In deep learning, a large number of training samples is required to prevent\noverfitting, so datasets with relatively larger size benefit from HESSAE, such as Pen-digits with 10992 samples and\nStatlog with 6435 samples. Cascading raw data directly with deep features have shown lower accuracy in almost\nevery datasets, which we believe is caused by high dimensionality information redundancy. The results\ndemonstrated that L1 regularization and w-LPPD SVM ensemble employed on hybrid feature are able to remove\nredundancy effectively and retain valid classification information. Meanwhile, the designed fusion method is an\neffective fusion strategy that can improve the accuracy and stability of the classification. The results show that the\nmajor parts are effective.\nTable Ⅴ. Classification accuracy (meanvariance) of the major parts in the proposed method (%)\nOF\nDF\nHF\nHF&L1\nHF&L1&\nEnsemble\nAD\n54.00\n9.54\n57.33\n5.47\n52.00\n6.05\n53.33\n6.33\n67.33\n2.49\nUrban\n79.99\n1.04\n71.64\n1.45\n79.73\n1.31\n80.27\n1.07\n83.20\n1.01\nPen-Digits\n97.52\n0.22\n96.04\n0.67\n97.51\n0.21\n97.76\n0.18\n98.00\n0.12\nStatlog\n86.64\n0.41\n86.45\n0.74\n86.60\n0.43\n86.68\n0.39\n87.28\n0.12\nNotes: DF: Deep features learned by HESSAE; HF: Hybrid feature (Cascade of original features and deep features); HF&L1: Hybrid\nfeature selection with L1 regularization; HF&L1&Ensemble : HF&L1 followed by w_LPPD SVM ensemble.\n5. Discussion and Conclusion\nDeep stacked autoencoder is a kind of important deep learning method. Although it is easy to understand and\nrealize, and has wide application, existing deep stacked autoencoder methods did not consider to fuse the original\nfeatures within hidden layers and during training. One of the negative results is the deep features are not\ncomplementary with the original features sufficiently, thereby affecting the quality of subsequent feature fusion.\nTo tackle this issue, a novel improved deep stacked autoencoder ensemble has been proposed in this paper. Deep\nfeatures extracted by an improved hybrid feature embedded stacked autoencoder are fused with original features to\nmitigate the small-sample problem, then feature selection based on L1 regularization and w_LPPD SVM ensemble\nmodel have been designed for solving high dimensionality problem and improving reliability. Experiments were\nconducted on various representative datasets with different sample size and feature dimension. The experimental\nresults demonstrated the proposed method outperforms other well-known methods in terms of classification\naccuracy and stability.\nThe value of this work can be summarized as follows:(1) The proposed HESSAE can obtain better initial\nparameters by embedding initial information and discarding some weak features during pre-training, thus learning\nmore effective deep representations and more complementary features with original features. (2) W_LPPD-SVM\nensemle is designed to deal with feature subset with small size samples. (3) Three-steps feature learning is designed\nand is able to extract abstract information as well as retain useful initial information. The advantages above\ncontribute to higher accuracy and stability of the proposed algorithm. 4) the hybrid embedded idea can be applied\ninto other deep learning methods except deep stacked autoencoder.\nThere are still some shortcoming of the proposed methods, the future work is to optimize the structure or\ntraining standards of deep encoders, improving the quality of learned deep features. Besides, other deep learning\nmethods can be considered for further verification.\nReference\n[1]\nC. Yao, J. Han, F. Nie, F. Xiao and X. Li, \"Local Regression and Global Information-Embedded Dimension\nReduction,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 29, no. 10, pp. 4882-4893,\nOct. 2018.\n[2]\nK. Simonyan, A. Vedaldi and A. Zisserman, \"Learning Local Feature Descriptors Using Convex\nOptimisation,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 8, pp.\n1573-1585, Aug. 2014.\n[3]\nT. Zhang, W. Zheng, Z. Cui, Y. Zong, J. Yan and K. Yan, \"A Deep Neural Network-Driven Feature Learning\nMethod for Multi-view Facial Expression Recognition,\" IEEE Transactions on Multimedia, vol. 18, no. 12, pp.\n2528-2536, Dec. 2016.\n[4]\nH. Phan, L. Hertel, M. Maass, R. Mazur and A. Mertins, \"Learning Representations for Nonspeech Audio\nEvents Through Their Similarities to Speech Patterns,\" IEEE/ACM Transactions on Audio, Speech, and\nLanguage Processing, vol. 24, no. 4, pp. 807-822, April 2016.\n[5]\nC. Wang, Q. Hu, X. Wang, D. Chen, Y. Qian and Z. Dong, \"Feature Selection Based on Neighborhood\nDiscrimination Index,\" IEEE Transactions on Neural Networks and Learning Systems, vol. 29, no. 7, pp.\n2986-2999, July 2018.\n[6]\nYamada M, Jitkrittum W, Sigal L et al., \"High-dimensional feature selection by feature-wise kernelized\nLasso,\" Neural Computation, vol. 26, no. 1, pp. 185-207, Jan. 2014.\n[7]\nLin J, Kai L U, Sun Y, \"A Novel Relief Feature Selection Algorithm Based on Mean-Variance Model,\" System\nSimulation Technology, 2013, 8(16):3921-3929.\n[8]\nDonoho D, Jin J, \"Higher criticism thresholding: Optimal feature selection when useful features are rare and\nweak,\" Proceedings of the National Academy of Sciences of the United States of America, 2008,\n105(39):14790-14795.\n[9]\nWold S, \" Principal component analysis,\" Chemometrics & Intelligent Laboratory Systems, 1987, 2(1):37-52.\n[10] Li C H, Kuo B C, Lin C T, \"LDA-Based Clustering Algorithm and Its Application to an Unsupervised Feature\nExtraction,\" IEEE Transactions on Fuzzy Systems, 2011, 19(1):152-163.\n[11] X. He and P. Niyogi, \"Locality preserving projections,\" Advances in Neural Information Processing System,\nvol. 16. Cambridge, MA, USA:MIT Press, 2003, pp. 100–115.\n[12] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. A. Alemi, \"Inception-v4, inception-resnet and the impact of\nresidual connections on learning, \" Proc. 31st AAAI Conf. Artif. Intell., Feb. 2017, San Francisco, CA, USA,\n2017, pp. 4278–4284.\n[13] Z. Han et al., \"Deep spatiality: Unsupervised learning of spatially-enhanced global and local 3D features by\ndeep neural network with coupled softmax,\" IEEE Trans. Image Process., vol. 27, no. 6, pp. 3049–3063, Jun.\n2018.\n[14] B. Wu et al., \"An End-to-End Deep Learning Approach to Simultaneous Speech Dereverberation and Acoustic\nModeling for Robust Speech Recognition,\" IEEE Journal of Selected Topics in Signal Processing, vol. 11, no.\n8, pp. 1289-1300, Dec. 2017.\n[15] Đ. T. Grozdić and S. T. Jovičić, \"Whispered Speech Recognition Using Deep Denoising Autoencoder and\nInverse Filtering,\" IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 25, no. 12, pp.\n2313-2322, Dec. 2017.\n[16] I. Sutskever, O. Vinyals, Q.V. Le, \"Sequence to sequence learning with neural networks,\" Adv. Neural Inf.\nProcess. Syst., 2014, pp. 3104–3112\n[17] K. Cho, B. Van Merriënboer,Ç. Gülçehre, D. Bahdanau, F. Bougares, H. Schwenk, Y. Bengio, \"Learning\nphrase representations using rnn encoder–decoder for statistical machine translation,\" Proceedings of the 2014\nConference on Empirical Methods in Natural Language Processing (EMNLP), 2014, pp. 1724–1734\n[18] Hinton,\nG.\nE,\n\"Reducing\nthe\nDimensionality\nof\nData\nwith\nNeural\nNetworks,\"\nScience,\n2006,\n313(5786):504-507.\n[19] David\nE.\nRumelhart;\nJames\nL.\nMcClelland,\n\"Learning\nInternal\nRepresentations\nby\nError\nPropagation,\" Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations,\nMITP, 1987, pp.318-362.\n[20] F. Lv, M. Han and T. Qiu, \"Remote Sensing Image Classification Based on Ensemble Extreme Learning\nMachine With Stacked Autoencoder,\" IEEE Access, vol. 5, pp. 9021-9031, 2017.\n[21] C. Tao, H. Pan, Y. Li and Z. Zou, \"Unsupervised Spectral–Spatial Feature Learning With Stacked Sparse\nAutoencoder for Hyperspectral Imagery Classification,\" IEEE Geoscience and Remote Sensing Letters, vol. 12,\nno. 12, pp. 2438-2442, Dec. 2015.\n[22] G. Jiang, H. He, P. Xie and Y. Tang, \"Stacked Multilevel-Denoising Autoencoders: A New Representation\nLearning Approach for Wind Turbine Gearbox Fault Diagnosis,\" IEEE Transactions on Instrumentation and\nMeasurement, vol. 66, no. 9, pp. 2391-2402, Sept. 2017.\n[23] J. Dai, H. Song, G. Sheng and X. Jiang, \"Cleaning Method for Status Monitoring Data of Power Equipment\nBased on Stacked Denoising Autoencoders,\" IEEE Access, vol. 5, pp. 22863-22870, 2017.\n[24] Y. Lei, W. Yuan, H. Wang, Y. Wenhu and W. Bo, \"A Skin Segmentation Algorithm Based on Stacked\nAutoencoders,\" IEEE Transactions on Multimedia, vol. 19, no. 4, pp. 740-749, April 2017.\n[25] Y. Qi, C. Shen, D. Wang, J. Shi, X. Jiang and Z. Zhu, \"Stacked Sparse Autoencoder-Based Deep Network for\nFault Diagnosis of Rotating Machinery,\" IEEE Access, vol. 5, pp. 15066-15079, 2017.\n[26] L. Wang, Z. Zhang and J. Chen, \"Short-Term Electricity Price Forecasting With Stacked Denoising\nAutoencoders,\" IEEE Transactions on Power Systems, vol. 32, no. 4, pp. 2673-2681, July 2017.\n[27] Michael Kampffmeyer, Sigurd Løkse, Filippo M. Bianchi, Robert Jenssen, Lorenzo Livi. \"The deep kernelized\nautoencoder,\" Applied Soft Computing,Volume 71,2018,Pages 816-825,ISSN 1568-4946.\n[28] J. Yu, \"Enhanced Stacked Denoising Autoencoder-Based Feature Learning for Recognition of Wafer Map\nDefects,\" IEEE Transactions on Semiconductor Manufacturing, vol. 32, no. 4, pp. 613-624, Nov. 2019.\n[29] Y. Shi, J. Lei, Y. Yin, K. Cao, Y. Li and C. Chang, \"Discriminative Feature Learning With Distance\nConstrained Stacked Sparse Autoencoder for Hyperspectral Target Detection,\" IEEE Geoscience and Remote\nSensing Letters, vol. 16, no. 9, pp. 1462-1466, Sept. 2019.\n[30] Bengio,\nand\nY.\n\"Learning\nDeep\nArchitectures\nfor\nAI.\"\nFoundations\nand\nTrends?\nin\nMachine\nLearning 2.1(2009):1-127.\n[31] B. Yan and G. Han, \"Effective Feature Extraction via Stacked Sparse Autoencoder to Improve Intrusion\nDetection System,\" IEEE Access, vol. 6, pp. 41238-41248, 2018.\n[32] W.\nLuo,\nJ.\nYang,\nW.\nXu\nand\nT.\nFu,\n\"Locality-Constrained\nSparse\nAuto-Encoder\nfor\nImage\nClassification,\" IEEE Signal Processing Letters, vol. 22, no. 8, pp. 1070-1073, Aug. 2015.\n[33] J. Fan, K. Lin and M. Han, \"A Novel Joint Change Detection Approach Based on Weight-Clustering Sparse\nAutoencoders,\" IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 12,\nno. 2, pp. 685-699, Feb. 2019.\n[34] T. Majtner, S. Yildirim-Yayilgan and J. Y. Hardeberg, \"Combining deep learning and hand-crafted features for\nskin lesion classification,\" 2016 Sixth International Conference on Image Processing Theory, Tools and\nApplications (IPTA), Oulu, 2016, pp. 1-6.\n[35] T. Liu, S. Xie, J. Yu, L. Niu and W. Sun, \"Classification of thyroid nodules in ultrasound images using deep\nmodel based transfer learning and hybrid features,\" 2017 IEEE International Conference on Acoustics, Speech\nand Signal Processing (ICASSP), New Orleans, LA, 2017, pp. 919-923.\n[36] Suk, Heung Il , S. W. Lee , and D. Shen . \"Latent feature representation with stacked auto-encoder for\nAD/MCI diagnosis.\" Brain Structure and Function 220.2(2013):841-859.\n[37] S. Mei, H. Yang and Z. Yin, \"Unsupervised-Learning-Based Feature-Level Fusion Method for Mura Defect\nRecognition,\" IEEE Transactions on Semiconductor Manufacturing, vol. 30, no. 1, pp. 105-113, Feb. 2017\n[38] S. Kan, Y. Cen, Z. He, Z. Zhang, L. Zhang and Y. Wang, \"Supervised Deep Feature Embedding With\nHandcrafted Feature,\" IEEE Transactions on Image Processing, vol. 28, no. 12, pp. 5809-5823, Dec. 2019.\n[39] Tan X , Liu Y , Li Y , et al. \"Localized instance fusion of MRI data of Alzheimer’s disease for classification\nbased on instance transfer ensemble learning, \" BioMedical Engineering OnLine, 2018, 17(1):49.\n[40] Sakar B E , Isenkul M E , Sakar C O , et al., \"Collection and Analysis of a Parkinson Speech Dataset With\nMultiple Types of Sound Recordings\". IEEE Journal of Biomedical and Health Informatics, 2013,\n17(4):828-834.\n[41] Dua, D. and Karra Taniskidou, E. UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine,\nCA: University of California, School of Information and Computor Science. 2017\n[42] Hoti F, Holmström L, \"A semiparametric density estimation approach to pattern classification,\" Pattern\nRecognition, 2004, 37(3):409-419.\n[43] Tsanas A, Little M A, Fox C, et al., \"Objective Automatic Assessment of Rehabilitative Speech Treatment in\nParkinson's Disease,\" IEEE Transactions on Neural Systems & Rehabilitation Engineering A Publication of\nthe IEEE Engineering in Medicine & Biology Society, 2014, 22(1):181.\n[44] Johnson B, Xie Z, \"Classifying a high resolution image of an urban area using super-object information,\"\nISPRS Journal of Photogrammetry and Remote Sensing, 2013, 83:40-49.\n[45] H. Zhu, J. Cheng, et al., \"Stacked pruning sparse denoising autoencoder based intelligent fault diagnosis of\nrolling bearings,\" Applied Soft Computing, vol. 88, sp. 106060, March. 2020.\nAcknowledgments\nWe are grateful for the support of the National Natural Science Foundation of China NSFC (No. 61771080); the\nFundamental Research Funds for the Central Universities (2019CDQYTX019, 2019CDCGTX306) , the Basic and\nAdvanced Research Project in Chongqing (cstc2018jcyjAX0779); and the Southwest Hospital Science and\nTechnology Innovation Program (SWH2016LHYS-11).\nAuthor contributions\nYL conceived of the study, participated in its design and coordination and helped draft the manuscript. YL and\nPW\nparticipated\nin\nthe\nmeasurements\nof\nall\nsubjects\nand\ndrafted\nthe\ncomplete\nmanuscript.\nYL\nmanaged the trials and assisted with writing the discussion in the manuscript.\nAll authors read and approved the final manuscript.\nConflict of Interest\nThe authors declare that they have no conflicts of interest related to this work.\nEthics Approval and Consent to Participate\nNot applicable\nConsent for publication\nNot applicable\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2020-02-17",
  "updated": "2020-02-17"
}