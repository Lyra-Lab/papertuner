{
  "id": "http://arxiv.org/abs/2002.10221v2",
  "title": "The Archimedean trap: Why traditional reinforcement learning will probably not yield AGI",
  "authors": [
    "Samuel Allen Alexander"
  ],
  "abstract": "After generalizing the Archimedean property of real numbers in such a way as\nto make it adaptable to non-numeric structures, we demonstrate that the real\nnumbers cannot be used to accurately measure non-Archimedean structures. We\nargue that, since an agent with Artificial General Intelligence (AGI) should\nhave no problem engaging in tasks that inherently involve non-Archimedean\nrewards, and since traditional reinforcement learning rewards are real numbers,\ntherefore traditional reinforcement learning probably will not lead to AGI. We\nindicate two possible ways traditional reinforcement learning could be altered\nto remove this roadblock.",
  "text": "This is an open access article licensed under the Creative Commons BY-NC-ND License.\nJournal of Artiﬁcial General Intelligence 11(1) 70–85, 2020\nSubmitted 2020-02-16\nDOI: 10.2478/jagi-2020-0004\nAccepted 2020-09-29\nThe Archimedean trap: Why traditional reinforcement\nlearning will probably not yield AGI\nSamuel Allen Alexander\nsamuelallenalexander@gmail.com\nQuantitative Research Analyst\nThe U.S. Securities and Exchange Commission\nNew York Regional Oﬃce\nEditor: Alexey Potapov\nAbstract\nAfter generalizing the Archimedean property of real numbers in such a way as to make\nit adaptable to non-numeric structures, we demonstrate that the real numbers cannot be\nused to accurately measure non-Archimedean structures. We argue that, since an agent\nwith Artiﬁcial General Intelligence (AGI) should have no problem engaging in tasks that\ninherently involve non-Archimedean rewards, and since traditional reinforcement learning\nrewards are real numbers, therefore traditional reinforcement learning probably will not\nlead to AGI. We indicate two possible ways traditional reinforcement learning could be\naltered to remove this roadblock.\n1. Introduction\nWhenever we measure anything using a particular number system, the corresponding\nmeasurements will be constrained by the structure of that number system. If the number\nsystem has a diﬀerent structure than the things we are measuring with it, then our\nmeasurements will suﬀer accordingly, just as if we were trying to force square pegs into\nround holes.\nFor example, the natural numbers make lousy candidates for measuring lengths in a\nphysics laboratory. Lengths in the lab have properties such as, for example, the fact that\nfor any two distinct lengths, there is an intermediate length strictly between them. The\nnatural numbers lack this property. Imagine the poor physicist, brought up in a world\nof only natural numbers, scratching his or her head upon encountering a rod with length\nstrictly between two rods of length 1 and 2.\nIt is tempting to think of the real numbers R—i.e., the unique complete ordered ﬁeld—\nas a generic number system with whatever structure suits our needs. But the real numbers\ndo have their own speciﬁc structure. That structure is ﬂexible enough to accomodate many\nneeds, but we shouldn’t just take that for granted. One particular property constraining\nthe real numbers is the following.\nLemma 1 (The Archimedean Property1) Let r > 0 be any positive real number. For every\nreal number y, there is some natural number n such that nr > y.\n1. The Archimedean property is named after Archimedes of Syracuse. A similar property appears as the\nﬁfth axiom in his On the Sphere and Cylinder (Archimedes, 1897):\n70\narXiv:2002.10221v2  [cs.LG]  20 Oct 2020\nThe Archimedean trap\nRather than directly prove Lemma 1, we will prove a generalized result which, we will\nargue, is more adaptable to other structures.\nLemma 2 (The Generalized Archimedean Property) Let r > 0 be any positive real number.\nFor any x, y ∈R, say that x is signiﬁcantly less than y if x ≤y −r. If x0, x1, x2, . . . is\nany inﬁnite sequence of real numbers, where each xi is signiﬁcantly less than xi+1, then for\nevery real number y, there exists some i such that y is signiﬁcantly less than xi.\nProof If not, then there is some y such that y +r > xi for all i. Thus, X = {x0, x1, x2, . . .}\nhas an upper bound. By the completeness of R, X must have a least upper bound z ∈R.\nSince z is the least upper bound for X, z −r is not an upper bound for X, so there is some\ni such that xi > z −r. By assumption, xi ≤xi+1 −r, so xi+1 > z, contradicting the choice\nof z.\nLemma 1 follows from Lemma 2 by letting xi = ir.\nThe above property is automatically inherited by subsystems of the reals, such as the\nrational numbers Q, the natural numbers N, the integers Z, or the algebraic numbers. All\ninherit the Generalized Archimedean Property in obvious ways.\nLemma 2 allows us to adapt the notion of Archimedeanness to other things than real\nnumbers, even to things for which there is no notion of arithmetic at all (Lemma 1 would\nnot adapt to such things). All we need is a notion of “signiﬁcantly less than”. For any set\nof things, some of which are “signiﬁcantly less than” others, we can ask whether or not the\nproperty in Lemma 2 holds. We will make this formal in Section 2.\nExample 1 (Fuzzy widgets) Suppose we have some fuzzy widgets, and we observe that\ncertain widgets are fuzzier than others. Naturally, we are inclined to quantify the fuzziness\nof the widgets, assigning them numerical fuzziness measures from some number system.\nNine times out of ten, we choose to use the real numbers, or a subsystem thereof, often\nwithout a second thought. But suppose among these widgets, there happen to be widgets\nx0, x1, . . . such that each xi is signiﬁcantly less fuzzy than xi+1, and another widget y such\nthat xi is signiﬁcantly less fuzzy than y for i = 0, 1, . . .. Suddenly, our decision to use real\nnumbers puts us in a bind. It is impossible to assign real number fuzziness measures to\nFurther, of unequal lines, unequal surfaces, and unequal solids, the greater exceeds the less by\nsuch a magnitude as, when added to itself, can be made to exceed any assigned magnitude\namong those which are comparable with [it and with] one another.\nNote that Archimedes speciﬁcally restricts his statement to lengths, surface areas and volumes, in fact\ngoing out of his way to limit the magnitudes to which said length/area/volume can be made to exceed\n(he could have saved some words by stopping his sentence at “...can be made to exceed any assigned\nmagnitude”, if that were his intention).\nThe Archimedean property is also closely related to Deﬁnition 4 of Book V of Euclid’s Elements\n(Euclid, 2007):\n(Those) magnitudes are said to have a ratio with respect to one another which, being multiplied,\nare capable of exceeding one another.\nProposition 1 of Book X is also relevant. Many math historians speak of the modern-day Archimedean\nproperty, Archimedes’ 5th axiom, and Euclid’s properties as being identical, but in fact they are all\nsubtly diﬀerent from one another, see Bair et al. (2013).\n71\nS. Alexander\nour widgets in such a way that signiﬁcantly less fuzzy widgets get signiﬁcantly smaller real\nnumber measures. That would contradict Lemma 2.\nNote that the above example does not require us to have any notion of multiplying\nfuzziness by a natural number n (as we would need to have if we wanted to adapt Lemma\n1). This illustrates the enhanced adaptability of Lemma 2.\nThe structure of this paper is as follows.\n• In Section 2 we formally adapt Lemma 2 to obtain a notion of Archimedeanness\nfor non-numerical structures, and demonstrate that non-Archimedean such structures\ncannot accurately be measured using the real numbers.\n• In Section 3 we argue that traditional reinforcement learning probably will not lead\nto AGI because its rewards are overly constrained.\n• In Section 4 we discuss non-traditional variations of reinforcement learning that avoid\nthe problem of overly constrained rewards.\n• In Section 5 we summarize and make concluding remarks.\n2. Generalized Archimedean Structures\nThe real numbers possess the Archimedean property, but other structures may or may not.\nTo make this more precise, we introduce the following formalism, adapting from Lemma 2.\nDeﬁnition 3 A signiﬁcantly-ordered structure is a collection X with an ordering ≪. For\nx1, x2 ∈X, we say x1 is signiﬁcantly less than x2 if x1 ≪x2. A signiﬁcantly-ordered\nstructure is Archimedean if it has the following property: for every X-sequence x0 ≪x1 ≪\nx2 ≪· · · , for every y ∈X, there is some i ∈{0, 1, . . .} such that y ≪xi.\nFor any real number r > 0, a prototypical example of an Archimedean signiﬁcantly-\nordered structure is the real numbers with ≪deﬁned such that x1 ≪x2 if and only if\nx1 ≤x2 −r.\nDeﬁnition 4 Suppose (X, ≪) is a signiﬁcantly-ordered structure. A function f : X →R\nis said to accurately measure (X, ≪) if there is some real r > 0 such that the following\nrequirement holds:\n• For all x1, x2 ∈X, x1 ≪x2 if and only if f(x1) ≤f(x2) −r.\nThe following proposition formalizes the dilemma we illustrated in Example 1.\nProposition 5 (Inadequacy of the reals for non-Archimedean structures) Suppose (X, ≪)\nis a signiﬁcantly-ordered structure. If X is non-Archimedean, then no function f : X →R\naccurately measures (X, ≪).\n72\nThe Archimedean trap\nProof Assume, for sake of a contradiction, that some f : X →R exists which accurately\nmeasures (X, ≪). Thus there is some real r > 0 such that for all x1, x2 ∈X, x1 ≪x2\nif and only if f(x1) ≤f(x2) −r. Since X is non-Archimedean, there is some X-sequence\nx0 ≪x1 ≪x2 ≪· · · and some y ∈X such that there is no i such that y ≪xi. By choice\nof r, each f(xi) ≤f(xi+1)−r and there is no i such that f(y) ≤f(xi)−r. This contradicts\nLemma 2.\nProposition 5 tells us that we cannot accurately measure non-Archimedean structures\nusing real numbers2. Any attempt to do so will necessarily be misleading, because ordering\nrelationships among the non-Archimedean structures will fail to be reﬂected by the real-\nnumber measurements given to them. We will inevitably end up like the puzzled physicist\nbrought up in a world of only natural numbers, confronted by a rod of length 1.5.\nRemark 6 (Spearman’s Law of Diminishing Returns) Suppose (X, ≪) is a non-Archimedean\nsigniﬁcantly-ordered structure with elements x0, x1, . . . and y such that x0 ≪x1 ≪· · ·\nand each xi ≪y. Suppose f : X →R has the property that f(x0) < f(x1) < · · · and\neach f(xi) < f(y).\nThen the monotone convergence theorem implies that limi→∞f(xi)\nconverges to some ﬁnite value.\nThis suggests a general law of diminishing returns:\nany time a non-Archimedean signiﬁcantly-ordered structure (X, ≪) is measured using real\nnumbers, if the measurement does not blatantly violate ≪(in other words, if there are\nno x1 ≪x2 such that x1 is given a larger real-number measurement than x2), then there\nwill inevitably be elements x0 ≪x1 ≪· · · exhibiting diminishing returns, in the sense\nthat the measurements of xi and xj are approximately equal for all large enough i, j. If\nhuman intelligence is non-Archimedean, this could potentially shed light on a psychometrical\nphenomenon called Spearman’s Law of Diminishing Returns (Spearman, 1927; Blum and\nHolling, 2017; Hern´andez-Orallo, 2019), the empirical tendency of cognitive ability tests\nto be less correlated in high-intelligence populations. Even tiny measurement errors would\neventually dominate the test result diﬀerences as the true measurements plateau.\nExample 2 (Examples of non-Archimedean structures)\n• (Sets) Say that set x1 is signiﬁcantly smaller than set x2 if there is an injective function\nfrom x1 into x2 but there is no bijective function from x1 onto x2. It is easy to show\nthere are sets x0, x1, . . ., with each xi signiﬁcantly smaller than xi+1, and each xi is\nsigniﬁcantly smaller than y = ∪∞\ni=0xi. Thus, sets are non-Archimedean. In the ﬁeld\nof set theory, mathematicians measure the size of sets using Georg Cantor’s famous\nnon-Archimedean number system, the cardinal numbers.\n• (Logical theories) It is not diﬃcult to come up with (for example) true theories\nx0, x1, . . . (in the language of arithmetic) such that each xi+1 proves the consistency\nof xi, and an additional true theory y (in the language of arithmetic) which proves\nthe consistency of ∪∞\ni=0xi. In a sense, then, each xi is signiﬁcantly weaker than xi+1\n2. There is an area of research known as measurement theory, which, traditionally, “takes the real numbers\nas a pre-given numerical domain” (Nieder´ee, 1992). Some work has been done to generalize measurement\ntheory away from this assumption (Narens, 1974; Skala, 1975; Rizza, 2016). We would submit this paper\nas further motivation in that direction.\n73\nS. Alexander\n(see G¨odel’s incompleteness theorems), and each xi is signiﬁcantly weaker than y.\nIn this sense, logical theories are non-Archimedean.\nIn the ﬁeld of proof theory\n(Pohlers, 2008; Rathjen, 2006), logicians measure the logical strength of theories using\ncomputable ordinal numbers, another non-Archimedean number system.\n• (Asymptotic runtime complexities) Suppose x0, x1, . . . are algorithms such that each\nxi has runtime complexity Θ(ni), and suppose y is an algorithm with runtime\ncomplexity Θ(2n). Then in a certain sense, each xi has signiﬁcantly lower asymptotic\nruntime complexity than xi+1, and each xi has signiﬁcantly lower asymptotic runtime\ncomplexity than y. In this sense, asymptotic runtime complexity is non-Archimedean.\nIn computer science, these runtime complexities are usually measured using big-O,\nbig-Θ, or similar notation systems.\nExample 3 (Speculative examples of potentially non-Archimedean structures) Certain\nstructures might plausibly be non-Archimedean, but it is a diﬃcult question to say whether\nthey truly are or not. The reader could come up with such examples in great abundance.\n• (Musical beauty) Assuming there is such a thing as objective musical beauty (not\ncontingent on features of the human condition, etc.), then it is plausible that musical\nbeauty might be non-Archimedean, in the following sense:\nthere might be songs\nx0, x1, . . . such that each xi is signiﬁcantly less beautiful than xi+1, and another song\ny such that each xi is signiﬁcantly less beautiful than y.\n• (Ethical utility) Early utilitarian Jeremy Bentham suggested a hedonistic calculus\nin which pleasure measurements would be assigned to actions, to help adjudicate\nethical dilemmas.\nHis successor, John Stuart Mill, objected that some actions are\nincomparably better than others:\n“If one of [two pleasures] is, by those who are\ncompetently acquainted with both, placed so far above the other that they prefer it\n... and would not resign it for any quantity of the other pleasure which their nature\nis capable of, we are justiﬁed in ascribing to the preferred enjoyment a superiority in\nquality, so far outweighing quantity as to render it, in comparison, of small account”\n(Mill, 2016). This suggests that Bentham’s pleasures are non-Archimedean.\n• (AGI) It is plausible that there are3 AGIs x0, x1, . . . such that each xi is signiﬁcantly\nless intelligent than xi+1, and another AGI y such that each xi is signiﬁcantly\nless intelligent than y.\nWe ﬁrst pointed this out in (Alexander, 2019b), where we\npropose measuring the intelligence of mechanical knowing agents using computable\nordinals, the same non-Archimedean number system which proof theorists use to\nmeasure logical strength of mathematical theories. Incidentally, if AGI intelligence\nis non-Archimedean, then Proposition 5 shows it is impossible to measure machine\nintelligence using real numbers without some of those measurements being misleading4.\n3. As hinted by Protagoras, assuming Protagoras’s own intelligence stays constant and remains higher than\nthe intelligence of his student and that they live forever and that better means signiﬁcantly better: “The\nvery day you start, you will go home a better man, and the same thing will happen the day after. Every\nday, day after day, you will get better and better” (Plato, 1997).\n4. This would solve an open problem implicitly stated by Legg and Hutter (2007) when they said of their\nreal-number universal intelligence measure: “...none of these people have been able to communicate why\n74\nThe Archimedean trap\n• (Nonstandard cosmologies) Some authors (Al-Dhalimy and Geyer, 2016; Andr´eka et\nal., 2012; Reeder, 2012; Rosinger, 2007; Chen, 2020) have even speculated about the\nnature of non-Archimedean space and/or time.\n3. Reinforcement learning\nIn reinforcement learning (RL), an agent interacts with an environment, taking actions\nfrom a ﬁxed set of possible actions. With every action the agent takes, the environment\nresponds with a new observation and with a reward. In traditional RL, these rewards are\nreal numbers (many authors further constrain them to be rational numbers).\nBy restricting rewards to be real (or rational) numbers, we unconsciously constrain RL\nto only be applicable toward tasks of an inherently Archimedean nature.\nFor example,\nWirth et al. (2017) point out that in tasks related to cancer treatment (Zhao, Kosorok, and\nZeng, 2009), “the death of a patient should be avoided at any cost. However, an inﬁnitely\nnegative reward breaks classic reinforcement learning algorithms and arbitrary, ﬁnite values\nhave to be selected.” This problem could be avoided if instead of real numbers, rewards\nwere drawn from a suitable non-Archimedean number system containing negative inﬁnities.\nDoing so would be a departure from traditional RL.\nExample 4 To give an intuitive example, assume that musical beauty is non-Archimedean,\nas in Example 3. We can imagine environments where the RL agent is tasked with composing\nsongs. For example, the possible actions the agent is allowed to take might include one\naction for each piano key, plus an additional “stand and bow” action to signal that a song is\nﬁnished. Whenever the agent stands and bows, the agent is rewarded with applause based on\nthe beauty of the song the agent composed5. Assuming musical beauty is non-Archimedean,\nsuch an environment falls outside the possibility of traditional RL. By Lemma 5, there is no\nway to assign real number rewards to songs without misleading the agent. If x0, x1, x2, . . . are\nsongs where each xi is signiﬁcantly less beautiful than xi+1, and all the xi are signiﬁcantly\nless beautiful than another song y, then there is no way to assign real-valued rewards to\nthese songs such that each xi gets signiﬁcantly less reward than xi+1 and signiﬁcantly less\nreward than y.\nOr, to re-use the cancer example, assume there are certain bad procedures the robotic\nsurgeon could take, each one signiﬁcantly worse than the previous, but all still signiﬁcantly\nbetter than killing the patient.\nThere is no way to assign real-valued rewards to these\nactions, and to killing the patient, in such a way that each bad action gets punished\nsigniﬁcantly harsher than the previous, but still signiﬁcantly more forgivingly than the\npunishment for killing the patient.\nThe reader might object by challenging the non-Archimedeanness of music and of\nmedical procedures.\nBut we only used those to make the examples more intuitive.\nIf\nthe reader insists, we can resort to mathematical tasks.\nthe work [on measuring universal intelligence using real numbers] is so obviously ﬂawed in any concrete\nway ... If anyone would like to properly explain their position to us in the future, we promise not to\nchase you down the street!”\n5. To quote Wang and Hammer (2015): “Decision makings often do not happen at the level of basic\noperations, but at the level of composed actions, where there are usually inﬁnite possibilities.”\n75\nS. Alexander\nExample 5 Imagine that the agent is tasked with typing up mathematical theories, and\nwhen the agent stands and bows, the agent is rewarded with applause based on the proof-\ntheoretical strength of the theory (or hit with tomatoes if the theory is inconsistent). In\nExample 2 we noted that proof-theoretical strength of theories is non-Archimedean. There\nexist theories x0, x1, . . ., each signiﬁcantly proof-theoretically weaker than the next, and\nanother theory y, signiﬁcantly proof-theoretically stronger than all the xi’s.\nWe cannot\npossibly assign real-valued rewards to these theories without misleading the agent.\nThe reader might object to Example 5 on the grounds that judging the proof-theoretical\nstrength of a theory is inherently non-computable anyway. The example could be modiﬁed\nso that instead of typing up mathematical theories, the agent has to type up mathematical\nsubtheories in (say) the language of Peano arithmetic, accompanied by consistency proofs in\n(say) ZFC. It can be shown that the proof-theoretical strength of mathematical theories is\nstill non-Archimedean, even when restricted to subtheories of arithmetic whose consistency\ncan be proven in ZFC6.\nThe reader might object that the above theories-with-proofs example is contrived. But\nan AGI with human or better intelligence should have no problem at least comprehending\nand attempting such a task (regardless of whether or not the AGI is able to perform well\nat it). When we prove that the Halting Problem is unsolvable, we do so by considering\ncontrived programs that we could write if the Halting Problem were solvable.\nThe\ncontrivedness of those programs does not invalidate the proof of the unsolvability of\nthe Halting Problem.\nAgain, when we prove that C++ templates are Turing complete\n(Veldhuizen, 2003), we do so by considering extremely bizarre C++ templates that would\nnever arise naturally in a software studio. This does not invalidate the proof that C++\ntemplates are Turing complete.\nFinally, the reader might object that approximating inﬁnite rewards with arbitrary\nlarge ﬁnite rewards is good enough. Who cares (the argument might go) whether pushing\na button gives the agent inﬁnite pleasure or only a million units of pleasure? Either way\n(the argument goes) the agent is going to learn to prefer that button over a button that\ngives only .1 units of pleasure. The following example shows that this logic breaks down in\nnon-Markov environments.\nExample 6 (Delayed gratiﬁcation) Consider an environment with a red button and a blue\nbutton. Pushing the red button always grants +1 reward. As for the blue button, suppose the\nagent presses the blue button for the ith time. If i = 2j for some integer j, then the agent\nshall receive a reward of ω (the smallest inﬁnite ordinal), but otherwise, the agent shall\nreceive 0 reward. If we approximate ω with a real-value of, say, 1, 000, 000, then after a\nlong enough time spent in the environment, an AGI will be misled into thinking that it isn’t\nworth the longer and longer wait-times between blue-button rewards: eventually, it will take\nmore than 1, 000, 000 blue-button-presses to get rewarded, and the rewards will mislead the\nAGI into thinking it more worthwhile to get the guaranteed +1 reward from the red button.\n6. For example, let x0 be the theory of Peano arithmetic, and for each i, let xi+1 be xi together with\nCON(xi), a canonical axiom encoding the consistency of xi. Let y be the theory of Peano arithmetic\nalong with CON(∪ixi). ZFC is certainly adequate to prove the consistency of each of these theories. In\nthe sense of Example 2, each xi is signiﬁcantly weaker than xi+1 and signiﬁcantly weaker than y.\n76\nThe Archimedean trap\nOur critic could respond to Example 6 by making the approximation dynamic, say,\nmaking the 2jth press of the blue button grant 1000000 · 2j reward, but at this point, the\ncritic is clearly just hard-coding the correct actions into the reward function, something\nwhich is only possible in Example 6 because the environment is simple enough that we can\ncompletely understand it ourselves. For the kinds of non-trivial environments where AGI\nwould actually be useful, such carefully engineered reward approximations would quickly\nbecome intractible.\nReinforcement Learning is useful for many practical tasks, but at least in its traditional\nﬂavor, it is too constrained (by its arbitrary choice of number system for its rewards) to\napply to certain non-Archimedean tasks7, which, however contrived they are, could certainly\nbe attempted by an AGI. Traditional reinforcement learning will probably not lead to AGI.\n4. Non-traditional reinforcement learning\nWe have argued that traditional RL will probably not lead to AGI, because an AGI is\ncapable of attempting non-Archimedean tasks whose rewards are too rich to express using\nreal numbers. There are at least two potential ways to change RL so as to make it applicable\nto such tasks and, thus, at least potentially capable of leading to AGI. Of course, there is no\nguarantee that removing the roadblock in this paper will cause RL to lead to AGI. There\nmight be other roadblocks besides the inadequate reward number system8.\n4.1 Preference-based reinforcement learning\nA lot of exciting research has been done on non-traditional variations of RL where, instead of\ngiving the agent numerical rewards for taking actions, one instead informs the agent about\nthe relative preference of various actions or action-sequences. See (Wirth et al., 2017) for a\nsurvey. This nicely side-steps the problems from this paper.\n4.2 Reinforcement learning with other number systems\nThe most obvious way to modify RL to avoid the problems presented in this paper is to\nchange which number system is used9. As far as this author is aware, the choice to use real\n(or rational) numbers for rewards was not made based on any fundamental criteria10. The\nreal (or rational) numbers are currently a useful pragmatic choice because they are easy\nto compute with using 21st century software and 21st century school curricula, but that’s\nhardly relevant in the ﬁeld of genuine AGI. One might say the real numbers were a good\nchoice because they are familiar, but even that is arguable: in general, students are usually\n7. Perhaps explaining why “despite almost two decades of RL research, there has been little solid evidence\nof RL systems that may one day lead to [AGI]” (Livingston, Garvey, and Elhanany, 2008).\n8. For example, many RL authors consider non-deterministic environments where rewards and observations\ninclude an element of randomness.\nThe probabilities involved are, traditionally, assumed to be real\nnumbers.\nPerhaps some recent work (Benci, Horsten, and Wenmackers, 2013) on non-Archimedean\nprobability could be relevant against that roadblock.\n9. Anticipated by Rizza (2016).\n10. Nieder´ee (1992) points out that there are no deeper reasons to assume that the number system should\nnecessarily even have the same cardinality as R. And Rizza (2016) says: “No particular feature of the\nspace of informational states suggests that such a codomain [as R] should be selected”.\n77\nS. Alexander\nnot taught what the real numbers actually are, unless they major in pure mathematics at\nthe university level. Anyway, the familiarity argument is totally irrelevant in the ﬁeld of\nAGI.\nVarious non-Archimedean number systems exist. Number systems can be discrete or\ncontinuous; the nature of reinforcement learning clearly suggests a continuous number\nsystem. We will consider three continuous number systems: formal Laurent series; hyperreal\nnumbers; and surreal numbers.\n4.2.1 Formal Laurent series\nDavid Tall (1980) described the following real-number-extending number system (which he\ncalled the “superreals”, but that vocabulary does not seem to have caught on).\nDeﬁnition 7 A formal Laurent series is a formal expression of the form\n∞\nX\nj=−∞\najϵj\nsuch that there is some integer j0 such that aj = 0 for all j < j0. Suppose A = P∞\nj=−∞ajϵj\nand B = P∞\nj=−∞bjϵj are two distinct formal Laurent series. We declare A < B if and only\nif aj < bj where j is the smallest index such that aj ̸= bj.\nFor brevity, we will write aϵb for the formal Laurent series P∞\nj=−∞ajϵj where ab = a\nand aj = 0 for all j ̸= 0. Likewise, we may write, for example, 5ϵ−1 + 2ϵ3 for the formal\nLaurent series P∞\nj=−∞ajϵj where a−1 = 5, a3 = 2, and aj = 0 for all j ̸∈{−1, 3}, and\nsimilarly for other ﬁnite sums of powers of ϵ.\nWe can consider the real numbers R to be embedded in the formal Laurent series by\nway of the embedding r 7→rϵ0. Having done so, the intuition is that, for example, 1ϵ1 is\nwhat we might call a “ﬁrst-order inﬁnitesimal number”, smaller than every positive real;\n1ϵ2 is what we might call a “second-order inﬁnitesimal number”, smaller than every positive\nﬁrst-order inﬁnitesimal number; and so on. Likewise, 1ϵ−1 is what we might call a “ﬁrst-\norder inﬁnite number”, bigger than every real; 1ϵ−2 is what we might call a “second-order\ninﬁnite number”, bigger than every ﬁrst-order inﬁnite number; and so on. Thus, the formal\nLaurent series should suﬃce to address the speciﬁc problem described by Wirth et al. (2017)\nin which an inﬁnite negative reward is required when the RL agent kills the cancer patient.\nThere are natural ways to deﬁne arithmetic on formal Laurent series, but we will avoid\nthose details here. The advantage of the formal Laurent series number system is that it is\nrelatively concrete, compared to the more abstract hyperreal or surreal numbers discussed\nbelow.\nExample 7 (Examples of formal Laurent series comparisons)\n1. Consider A = 5ϵ−1 −2ϵ0 + 3ϵ1 + 4ϵ2 and B = 5ϵ−1 −2ϵ0 + 1ϵ1 + 4ϵ2 + 5ϵ6. The ϵ−1-\nand ϵ0-coeﬃcients of A and B are equal, so we compare their ϵ1-coeﬃcients. A has\nan ϵ1-coeﬃcient of 3 and B has an ϵ1-coeﬃcient of 1, and 3 > 1, so A > B.\n2. Consider A = 999999ϵ5 and B = 0.00001ϵ4. The ϵ4-coeﬃcient of A is 0, which is\nsmaller than B’s ϵ4-coeﬃcient (0.00001), so A < B.\n78\nThe Archimedean trap\nThere is a natural way to consider formal Laurent series as a signiﬁcantly-ordered\nstructure, generalizing the notion of “signiﬁcantly greater than” from Lemma 2.\nDeﬁnition 8\n1. For every Laurent series A = P∞\nj=−∞ajϵj, let o(A) (the order of A)\nbe the smallest integer j such that aj ̸= 0, or o(A) = ∞if there is no such j. Let\nLC(A) (the leading coeﬃcient of A) be the ϵo(A)-coeﬃcient of A, or 0 if o(A) = ∞.\n2. Let r > 0 be any positive real number. For any formal Laurent series A = P∞\nj=−∞ajϵj\nand B = P∞\nj=−∞bjϵj, we say A ≪r B if one of the following conditions holds:\n• o(A) > o(B) and LC(B) > 0; or\n• o(A) < o(B) and LC(A) < 0; or\n• o(A) = o(B) and LC(A) ≤LC(B) −r.\nLemma 9 For any real r > 0, the formal Laurent series, considered as a signiﬁcantly-\nordered structure according to ≪r, are non-Archimedean.\nProof Let r > 0. Recall from Deﬁnition 3 that the formal Laurent series, considered as a\nsigniﬁcantly-ordered structure according to ≪r, are Archimedean if and only if the following\nstatement is true:\n• For every sequence x0 ≪r x1 ≪r x2 ≪r · · · of formal Laurent series, for every formal\nLaurent series y, there is some i such that y ≪r xi.\nWe will exhibit a particular sequence x0 ≪r x1 ≪r x2 ≪r · · · of formal Laurent series, and\na formal Laurent series y, such that the above statement fails, thereby showing that the\nformal Laurent series are non-Archimedean.\nLet x0 = rϵ1, x1 = 2rϵ1, x2 = 3rϵ1, and in general let xi = (i + 1)rϵ1. Let y = 1ϵ0.\nThus o(x0) = o(x1) = o(x2) = · · · = 1, and LC(x0) = r, LC(x1) = 2r, LC(x2) = 3r, and in\ngeneral LC(xi) = (i + 1)r for each i = 0, 1, 2, . . .. Meanwhile, o(y) = 0 and LC(y) = 1.\nBy Deﬁnition 8, each xi ≪r xi+1 for i = 0, 1, 2, . . . (because each o(xi) = o(xi+1) = 1 and\neach LC(xi) = (i+1)r ≤LC(xi+1)−r = (i+2)r−r = (i+1)r). Thus, if the formal Laurent\nseries were Archimedean, there would have to be some i ∈{0, 1, . . .} such that y ≪r xi.\nThis is impossible because for any such i, o(y) = 0 < 1 = o(xi) and LC(xi) = (i+1)r > 0.\nUnfortunately, although the formal Laurent series contain inﬁnities and inﬁnitesimals, in\na sense we will make formal, they still do not contain “enough” inﬁnities and inﬁnitesimals\nto accomodate the fully general environments that an AGI should be able to navigate. To\nmake this formal, we introduce a weaker notion of Archimedeanness.\nDeﬁnition 10 Suppose (X, ≪) is a signiﬁcantly-ordered structure. We deﬁne a new order\n≪′ on X as follows.\nFor any x, y ∈X, we declare x ≪′ y if and only if there is an\nX-sequence x0, x1, . . . such that the following conditions hold:\n1. x0 = x.\n2. Each xi ≪xi+1.\n79\nS. Alexander\n3. Each xi ≪y.\nWe say (X, ≪) is semi-Archimedean if the following condition holds:\n• For every X-sequence x0 ≪′ x1 ≪′ x2 ≪′ · · · , for every y ∈X, there is some i such\nthat y ≪xi.\nTo be semi-Archimedean is a weaker condition than to be Archimedean, but it is\nstill a condition, and one which there is evidently no reason to assume should constrain\nreinforcement learning rewards in general.\nFor example, just as it is unclear whether\nmusical beauty is Archimedean, likewise, it is unclear whether musical beauty is even semi-\nArchimedean. If musical beauty is not semi-Archimedean, then Example 4 does not merely\nsuggest the inadequacy of real number rewards, but of rewards from any semi-Archimedean\nnumber system. And if musical beauty is too informal, we can still fall back to mathematical\ntheories (Example 5), for the strength of mathematical theories can be shown not to be\nsemi-Archimedean.\nIn the following theorem, we show that the formal Laurent series are semi-Archimedean.\nBy the above paragraph, this suggests that even if we extended reinforcement learning to\npermit formal Laurent series rewards, the resulting framework would still probably not lead\nto AGI.\nTheorem 11 For any real r > 0, the formal Laurent series are semi-Archimedean when\nconsidered as a signiﬁcantly-ordered structure as in Deﬁnition 8.\nProof Let r > 0. For simplicity, we write ≪for ≪r and ≪′ for ≪′\nr.\nClaim 1: Whenever a ≪′ b, then b ≥0.\nTo see this, assume a ≪′ b, so there are\na = x0, x1, . . . such that each xi ≪xi+1 and each xi ≪b. If any xi ≥0 then, since xi ≪b,\nit follows that b ≥0, as desired. But suppose every xi < 0. If all the o(xi) were equal,\nthen, since each xi ≪xi+1, it would follow that each LC(xi) ≤LC(xi+1) −r, so Lemma\n2 would imply LC(xi) > 0 for some i, contradicting the assumption that xi < 0. So there\nis some minimal i1 such that o(xi1+1) ̸= o(xi1), and since xi1 and xi1+1 are negative, this\nimplies o(xi1+1) < o(xi1), and by minimality of i1, o(xj) = o(x0) for all j ≤i1. By identical\nreasoning applied to the sequence xi1, xi1+1, . . ., there is some minimal i2 > i1 such that\no(xi2+1) < o(xi2) and such that o(xj) = o(xi1+1) for all i1 + 1 ≤j ≤i2. Continuing in this\nway, there are i1 < i2 < · · · such that o(xi) shrinks for all i = ij and o(xi) stays constant\neverywhere else. Thus, if b were negative, there would be some i such that o(xi) < o(b),\nwhich, since xi is also negative, would imply xi > b, contradicting that xi ≪b. This proves\nClaim 1.\nClaim 2: Whenever a ≪′ b and a ≥0, then o(a) > o(b). To see this, assume a ≥0 and\na ≪′ b, so there is a sequence a = x0 ≪x1 ≪· · · with each xi ≪b.\nCase 1: All the o(xi) are equal. Then each LC(xi+1) ≥LC(xi) + r, so by Lemma 2,\nthere is some i such that LC(xi) > LC(b). Since xi ≪b, this implies o(xi) > o(b). Thus\no(a) = o(x0) = o(xi) > o(b), as desired.\nCase 2: There is some minimal i such that o(xi+1) ̸= o(xi). Since a ≥0 and a = x0,\nit follows that xi ≥0 and xi+1 ≥0. Since xi+1 > xi, this implies o(xi+1) < o(xi). Since\nxi+1 ≪b, this implies o(b) ≥o(xi+1) > o(xi). By minimality of i, o(xi) = o(x0) = o(a), so\no(a) > o(b), as desired. This proves Claim 2.\n80\nThe Archimedean trap\nFinally we prove the theorem.\nSuppose x0 ≪′ x1 ≪′ · · · , and let y be any formal\nLaurent series, we must show there is some i such that y ≪xi. By Claim 1, x1 ≥0. Since\nx1 ≥0 and x1 ≪′ x2 ≪′ · · · , it follows that xi > 0 for all i ≥2. By Claim 2, for all i ≥1,\no(xi+1) < o(xi). It follows that there is some i ≥2 such that o(xi) < o(y). Thus we are in\nthe case where o(y) > o(xi) and (since xi > 0) LC(xi) > 0, so by Deﬁnition 8, y ≪xi.\n4.2.2 Hyperreal numbers\nThe ﬁeld of mathematics where the calculus is formalized with inﬁnite and inﬁnitesimal\nquantities is called nonstandard analysis (Robinson, 1974). The numbers most commonly\nassociated with this ﬁeld are the so-called hyperreal numbers.\nThe hyperreal numbers can be introduced axiomatically or by means of a semi-\nconstructive method which depends on usage of a certain black box, a device known as\na free ultraﬁlter. Logicians have proven that free ultraﬁlters exist but that, unfortunately,\nit is impossible to concretely exhibit one. This severely limits (if not completely ruins) the\npractical usefulness of reinforcement learning with hyperreal rewards.\nNevertheless, the hyperreals might be useful for proving abstract structural properties\nabout AGI11. It can be shown that the hyperreals are not even semi-Archimedean (much\nless Archimedean). Thus, for the purpose of proving abstract theorems about RL agents\nwith fully generalized rewards, the hyperreals would be more appropriate than the formal\nLaurent series.\n4.2.3 Surreal numbers\nAll of the well-known non-Archimedean extensions of R (including formal Laurent series\nand hyperreals) are subsystems of the so-called surreal numbers (Conway, 2000; Knuth,\n1974; Ehrlich, 2012). The surreal numbers were initially discovered during John Conway’s\nattempts to study two-player combinatorial games like Go and Chess, so it would not be\nsurprising if they turn out to be important in the eventual development of AGI.\nUnlike the hyperreals, the construction of the surreal numbers does not depend on any\nnon-constructive black boxes such as free ultraﬁlters. They are constructed as the union\nof a hierarchy Sα of subsystems where α ranges over the ordinal numbers. Assuming that\nagents with AGI are implemented using computers with no additional power beyond the\nChurch-Turing Thesis, then for the purposes of AGI, it would be appropriate to restrict\nour attention to some computable subset of the surreal numbers, which would presumably\nbe the union of some hierarchy Cα where α ranges over the computable ordinal numbers.\nFor any particular level Cα in this hierarchy, we could consider the sub-universe Eα of\nsurreal-reward RL environments with rewards restricted to Cα.\nAssuming AGI agents are Turing computable, no individual AGI can possibly compre-\nhend codes for all computable ordinals, because the set of codes of computable ordinals is\nbadly non-computably-enumerable. This is profound, because it seems to suggest that any\n11. Similar to the way we use free ultraﬁlters in (Alexander, 2019a) to obtain comparators of the utility-\nmaximizing ability of traditional deterministic RL agents, and prove structural properties about said\ncomparators.\nIn fact, in that paper, we essentially independently re-invented the free ultraﬁlter\nconstruction of the hyperreals, without realizing it at the time!\n81\nS. Alexander\nparticular AGI can only comprehend RL environments in Eα if that AGI can comprehend\nα. In other words, for any particular RL environment e with computable surreal number\nrewards, there must be some minimal computable ordinal α such that e has rewards from\nEα; if an AGI is not intelligent enough to comprehend α, then it seems like there should\nbe no way for the AGI to comprehend e either12. We would submit this state of aﬀairs as\nevidence in favor of our thesis (Alexander, 2019b) that a machine’s intelligence ought to be\nmeasured in terms of the computable ordinals which the machine comprehends.\nThe above paragraph points at a possible joint path toward AGI incorporating both\nmachine learning and symbolic logic—toward “the integration of Symbolic and Statistical\nAI” (Maruyama, 2020)—perhaps a much-needed reconciliation of these two approaches.\n4.3 Alternate number systems: tentative verdict\nFor many simple environments not too far outside of traditional RL, formal Laurent series\ncould probably serve as a fairly practical number system. But formal Laurent series have\nlimitations suggesting that RL with formal Laurent series rewards will probably not be\nenough to reach AGI, for the same reason that RL with real number rewards will probably\nnot be enough.\nBecause of their dependence on free ultraﬁlters, the hyperreal numbers will probably\nnever be of practical use as RL rewards, but it could conceivably be possible to use them\nto prove abstract structural results about AGI from a bird’s-eye view.\nThe surreal numbers (or a computable subset thereof) seem like the most promising\ncandidate for RL rewards that could plausibly lead to AGI. We would certainly hesitate to\ncall them “practical”, though. To work with any but the most trivial of surreal numbers,\none would need to implement sophisticated symbolic-logical machinery, and that’s just to\nget one’s foot in the door.\nThis does, however, oﬀer a ray of hope in that doing deep\nlearning techniques with surreal numbers could be a way to combine both symbolic logic\nand statistical methods into a joint approach.\n5. Conclusion\nIn traditional reinforcement learning, utility-maximizing agents interact with environments,\nreceiving real (or rational) number rewards in response to actions, and using those rewards to\nupdate their behavior. We have argued that the decision to limit rewards to real numbers\nis inappropriate in the context of AGI, because the real numbers have the Archimedean\nproperty, which makes it impossible to use them to accurately portray the value of actions\nwhen a task involves inherently non-Archimedean rewards. Thus, we argue, traditional RL\nprobably will not lead to AGI, because a genuine AGI should have no trouble comprehending\nand at least attempting tasks that inherently involve non-Archimedean rewards.\nWe\nsuggested two possible ways to modify traditional reinforcement learning to ﬁx this bug:\nswitch to preference-based reinforcement learning, or else generalize reinforcement learning\nto allow rewards from a non-Archimedean number system.\n12. This situation is reminiscent of (Hibbard, 2011).\n82\nThe Archimedean trap\nAcknowledgments\nWe gratefully acknowledge Bryan Dawson, Jos´e Hern´andez-Orallo, Mikhail Katz, Brendon\nMiller-Boldt, Stewart Shapiro, the SEC’s Quantitative Analytics Unit’s machine learning\nseminar, and the reviewers for comments and feedback.\nReferences\nAl-Dhalimy, H., and Geyer, C. J.\n2016.\nSurreal Time and Ultratasks.\nThe Review of\nSymbolic Logic 9(4):836–847.\nAlexander, S. A.\n2019a.\nIntelligence via ultraﬁlters:\nstructural properties of some\nintelligence comparators of deterministic Legg-Hutter agents.\nJournal of Artiﬁcial\nGeneral Intelligence 10:24–45.\nAlexander, S. A. 2019b. Measuring the intelligence of an idealized mechanical knowing\nagent. In Cognition, Interdisciplinary Foundations, Models, and Applications (CIFMA).\nAndr´eka, H.; Madar´asz, J. X.; N´emeti, I.; and Sz´ekely, G. 2012. A logic road from special\nrelativity to general relativity. Synthese 186(3):633–649.\nArchimedes. 1897. On the Sphere and Cylinder. In Heath, T., ed., The works of Archimedes.\nCambridge University Press.\nBair, J.; B laszczyk, P.; Ely, R.; Henry, V.; Kanovei, V.; Katz, K. U.; Katz, M. G.;\nKutateladze, S. S.; McGaﬀey, T.; Schaps, D. M.; Sherry, D.; and Shnider, S.\n2013.\nIs mathematical history written by the victors? Notices of the American Mathematical\nSociety 60(7):886–904.\nBenci, V.; Horsten, L.; and Wenmackers, S. 2013. Non-Archimedean probability. Milan\nJournal of Mathematics 81(1):121–151.\nBlum, D., and Holling, H. 2017. Spearman’s law of diminishing returns. A meta-analysis.\nIntelligence 65:60–66.\nChen, L. 2020. Inﬁnitesimal gunk. Journal of Philosophical Logic 49:981–1004.\nConway, J. H. 2000. On Numbers and Games. CRC Press, 2nd edition.\nEhrlich, P. 2012. The absolute arithmetic continuum and the uniﬁcation of all numbers\ngreat and small. Bulletin of Symbolic Logic 18:1–45.\nEuclid. 2007. Book V: Theory of Proportion. In Casey, J., ed., First Six Books of the\nElements of Euclid. Project Gutenburg.\nHern´andez-Orallo, J. 2019. AI Generality and Spearman’s Law of Diminishing Returns.\nJournal of Artiﬁcial Intelligence Research 64:529–562.\nHibbard, B.\n2011.\nMeasuring agent intelligence via hierarchies of environments.\nIn\nInternational Conference on Artiﬁcial General Intelligence, 303–308. Springer.\n83\nS. Alexander\nKnuth, D. E. 1974. Surreal numbers: a mathematical novelette. Addison-Wesley.\nLegg, S., and Hutter, M. 2007. Universal intelligence: A deﬁnition of machine intelligence.\nMinds and machines 17(4):391–444.\nLivingston, S.; Garvey, J.; and Elhanany, I.\n2008.\nOn the broad implications of\nreinforcement learning based AGI.\nIn International Conference on Artiﬁcial General\nIntelligence, 478–482.\nMaruyama, Y.\n2020.\nSymbolic and Statistical Theories of Cognition:\nTowards\nIntegrated Artiﬁcial Intelligence. In Cognition, Interdisciplinary Foundations, Models,\nand Applications (CIFMA).\nMill, J. S. 2016. Utilitarianism. In Seven masterpieces of philosophy. Routledge. 337–383.\nNarens, L.\n1974.\nMeasurement without Archimedean axioms.\nPhilosophy of Science\n41(4):374–393.\nNieder´ee, R.\n1992.\nWhat do numbers measure?:\nA new approach to fundamental\nmeasurement. Mathematical Social Sciences 24(2-3):237–276.\nPlato. 1997. Protagoras. In Cooper, J. M.; Hutchinson, D. S.; et al., eds., Plato: complete\nworks. Hackett Publishing.\nPohlers, W. 2008. Proof theory: The ﬁrst step into impredicativity. Springer.\nRathjen, M. 2006. The art of ordinal analysis. In Proceedings of the International Congress\nof Mathematicians, volume 2, 45–69.\nReeder, P. F. 2012. Inﬁnitesimals for Metaphysics: Consequences for the Ontologies of\nSpace and Time. Ph.D. Dissertation, The Ohio State University.\nRizza, D.\n2016.\nDivergent Mathematical Treatments in Utility Theory.\nErkenntnis\n81(6):1287–1303.\nRobinson, A. 1974. Non-standard analysis. Princeton University Press.\nRosinger, E. E. 2007. Cosmic Contact: To Be, or Not To Be Archimedean? arXiv preprint\nphysics/0702206.\nSkala, H. J. 1975. Non-Archimedean utility theory. D. Reidel Publishing.\nSpearman, C. 1927. The abilities of man. Macmillan.\nTall, D. 1980. Looking at graphs through inﬁnitesimal microscopes, windows and telescopes.\nThe Mathematical Gazette 64:22–49.\nVeldhuizen, T. L. 2003. C++ Templates are Turing Complete. Technical report, Indiana\nUniversity.\nWang, P., and Hammer, P.\n2015. Assumptions of decision-making models in AGI. In\nInternational Conference on Artiﬁcial General Intelligence, 197–207. Springer.\n84\nThe Archimedean trap\nWirth, C.; Akrour, R.; Neumann, G.; and F¨urnkranz, J. 2017. A survey of preference-based\nreinforcement learning methods. The Journal of Machine Learning Research 18(1):4945–\n4990.\nZhao, Y.; Kosorok, M. R.; and Zeng, D. 2009. Reinforcement learning design for cancer\nclinical trials. Statistics in medicine 28(26):3294–3315.\n85\n",
  "categories": [
    "cs.LG",
    "cs.AI",
    "97R40"
  ],
  "published": "2020-02-15",
  "updated": "2020-10-20"
}