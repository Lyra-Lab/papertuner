{
  "id": "http://arxiv.org/abs/2003.12415v1",
  "title": "Learning representations in Bayesian Confidence Propagation neural networks",
  "authors": [
    "Naresh Balaji Ravichandran",
    "Anders Lansner",
    "Pawel Herman"
  ],
  "abstract": "Unsupervised learning of hierarchical representations has been one of the\nmost vibrant research directions in deep learning during recent years. In this\nwork we study biologically inspired unsupervised strategies in neural networks\nbased on local Hebbian learning. We propose new mechanisms to extend the\nBayesian Confidence Propagating Neural Network (BCPNN) architecture, and\ndemonstrate their capability for unsupervised learning of salient hidden\nrepresentations when tested on the MNIST dataset.",
  "text": " \nLearning representations in Bayesian Confidence \nPropagation neural networks \n \nNaresh Balaji Ravichandran \nComputational Brain Science Lab \nKTH Royal Institute of Technology \nStockholm, Sweden \nnbrav@kth.se \n \nAnders Lansner \nComputational Brain Science Lab \nStockholm University and KTH Royal \nInstitute of Technology \nStockholm, Sweden \nala@kth.se \n \nPawel Herman \nComputational Brain Science Lab \nKTH Royal Institute of Technology \nStockholm, Sweden \npaherman@kth.se \n \n \n \nAbstract​—Unsupervised\nlearning\nof\nhierarchical\n \n \n \n \nrepresentations has been one of the most vibrant research\n \n \n \n \n \n \n \n \n \ndirections in deep learning during recent years. In this work\n \n \n \n \n \n \n \n \n \n \nwe study biologically inspired unsupervised strategies in neural\n \n \n \n \n \n \n \n \nnetworks based on local Hebbian learning. We propose new\n \n \n \n \n \n \n \n \n \nmechanisms to extend the Bayesian Confidence Propagating\n \n \n \n \n \n \n \nNeural Network (BCPNN) architecture, and demonstrate their\n \n \n \n \n \n \n \ncapability\nfor\nunsupervised\nlearning\nof\nsalient\nhidden\n \n \n \n \n \n \n \nrepresentations when tested on the MNIST dataset. \nKeywords—​neural\nnetworks,\nbio-inspired,\nbrain-like,\n \n \n \n \nunsupervised learning, structural plasticity. \nI.\nI​NTRODUCTION \nArtificial neural networks (ANN) have made remarkable\n \n \n \n \n \n \n \nprogress in supervised pattern recognition in recent years.\n \n \n \n \n \n \n \n \nANNs achieve this mainly under the umbrella of deep\n \n \n \n \n \n \n \n \n \nlearning by discovering hierarchies of abstract features in\n \n \n \n \n \n \n \n \nthe data using multiple layers of distributed representations.\n \n \n \n \n \n \n \n \nAt this stage, it is valuable to study how they compare with\n \n \n     \n \n \n \n \n \n \n \nthe\nbiological\nneural\nnetworks,\nand\nexplore\nnew\n \n \n \n \n \n \n \nopportunities at this intersection.  \nWe see at least three fundamental differences between\n \n \n \n \n \n \n \n \ncurrent deep learning approaches and the brain: \nFirstly, most deep learning methods rely extensively on\n \n \n \n \n \n \n \n \nlabelled samples for learning the entire hierarchy of\n \n \n \n \n \n \n \n \nrepresentations, although biological systems mostly learn in\n \n \n \n \n \n   \nan unsupervised fashion. Recent work in deep learning\n \n \n \n \n \n \n \n \nresearch has increasingly paid attention to developing\n \n \n \n \n \n \n \nunsupervised learning methods ​[1, 2​, ​3]​, and the work we\n \n \n \n \n \n \n \n \n \n \npresent here will also be in this direction.  \nSecondly, deep learning methods predominantly make\n \n \n \n \n \n \nuse of error back-propagation (backprop) for learning the\n \n \n \n \n \n \n \n \nweights in the network. Although extremely efficient,\n \n \n \n \n \n \n \nbackprop has several issues that make it an unlikely\n \n \n \n \n \n \n \n \n \ncandidate model for synaptic plasticity in the brain. The\n \n \n \n \n \n \n \n \n \nmost apparent issue is that the synaptic connection strength\n \n \n   \n \n \n \n \n \nbetween two biological neurons is expected to comply with\n \n \n \n   \n \n \n \n \nHebb’s postulate, i.e. to depend only on the available local\n \n \n \n \n \n \n \n \n \n \ninformation provided by the activities of the pre- and\n \n \n \n \n \n \n \n \n \npostsynaptic neurons. This is violated in backprop, since\n \n \n \n \n \n \n \n \nsynaptic\nweight updates need gradient signals to be\n \n \n \n \n \n \n \n \ncommunicated from distant output layers. We refer to other\n \n \n \n \n \n \n   \n \nwork for a detailed review and possible biologically\n \n \n \n \n \n \n \n \nplausible alternatives to backprop ​[4]​. \nThirdly, an important difference between current deep\n \n \n \n \n \n \n \nANNs and the brain concerns the abundance of recurrent\n \n \n \n \n \n \n \n \n \nconnections in the latter. A typical cortical area receives on\n \n \n \n   \n \n \n \n \n \nthe order of 10% of synapses from lower order structures,\n \n \n \n \n \n \n \n \n \n \ne.g. thalamus, and the rest from other cortical neurons ​[5]​.\n \n \n \n \n \n \n \n \n \n \nIn contrast, deep learning networks rely predominantly on\n \n \n \n \n \n \n \n \nfeed-forward connectivity. The surplus 90% connections are\n \n \n \n \n \n \n \nlikely\ninvolved\nin\nassociative\nmemory,\nconstraint-\n \n \n \n \n \n \nsatisfaction, top-down modulation and selective attention\n \n \n \n \n \n \n[5]​. However, we will not consider those important aspects\n \n \n \n \n \n \n \n \n \nof cortical computation in this work. \nThis motivates exploring alternative more biologically\n \n \n \n \n \n \nplausible\nlearning\nstrategies\nthat\nenable\nunsupervised\n \n \n \n \n \n \nlearning of representations using local Hebbian rules. The\n \n \n \n \n \n \n \n \napproach we follow here involves framing the update and\n \n \n \n \n \n \n \n \n \nlearning steps of the neural network as probabilistic\n \n \n \n \n \n \n \n \ncomputations. Probabilistic approaches are widely used in\n \n \n \n \n \n \n \nboth deep learning models ​[3] and computational models of\n \n \n \n \n \n \n \n \n \nbrain function ​[6]​. One disadvantage of probabilistic models\n \n \n \n \n \n \n \n \nis that the known methods do not scale well in practice.\n \n \n \n \n \n \n \n \n \n \n \nAlso, inference and learning with distributed representations\n \n \n \n \n \n \n \nis\noften\nintractable\nand\nwe\ninvariably\nresort\nto\n \n \n \n \n \n \n \n \napproximation ​[3, 7]​.   \nIn this work, we further adopt a modular network\n \n \n \n \n \n \n \n \n \narchitecture used for more biologically detailed cortical\n \n \n \n \n \n \n \nmemory models ​[7​, ​8] and earlier abstract work ​[9, 10]​. The\n \n \n \n \n \n \n \n \n \n \n \nnetworks\nare\nmodularized\nin terms of hypercolumns\n \n \n \n \n \n \n \ncomprising a number of functional minicolumns interacting\n   \n \n \n \n \n \nin a soft-winner-take-all manner. The abstract view of a\n   \n \n \n \n \n \n   \nhypercolumn is that it represents some attribute, e.g. edge\n \n \n   \n \n \n \n \n \norientation, in a discrete coded manner. A minicolumn unit\n \n   \n \n \n   \n \n \nrepresents\na\nlocal\nsubnetwork\nof\naround a hundred\n \n \n \n \n \n \n \n \nrecurrently connected neurons with similar receptive field\n \n \n \n \n \n \n \nproperties. Such an architecture was initially generalized\n \n \n \n \n \n \n \nfrom primary visual cortex, but today has more support also\n \n \n \n \n \n \n \n \n \n \nfrom later experimental work and has featured in spiking\n \n \n \n \n \n \n \n \n \ncomputational models of cortex ​[11, 12​,  ​13]​. \nII.\nR​ELATED​ ​WORK \nA popular variety of unsupervised learning approach is to\n \n \n \n \n \n \n \n \n \ntrain a hidden layer to reproduce the input data, for example,\n   \n \n   \n \n \n \n \n \n \nXXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE \nautoencoders and Restricted Boltzmann Machines (RBM).\n \n \n \n \n \n \nThe autoencoder and RBM networks trained with just one\n \n \n \n \n \n \n \n \n \nhidden layer are relevant here since the learning of weights\n \n \n \n \n \n \n \n \n \n \nof the connections from the input to hidden layers rely on\n \n \n \n \n \n \n \n \n \n \n \nlocal gradients, and the representations can be stacked on\n \n \n \n \n \n \n \n \n \ntop of each other to learn hierarchical features. However,\n \n \n \n \n \n \n \n \n \nstacked autoencoders and stacked RBMs are only used as\n \n \n \n \n \n \n \n \n \npre-training procedures on which end-to-end supervised\n \n \n \n \n \n \nfine-tuning\n(using backprop) is performed ​[2]​. Other\n \n \n \n \n \n \n \nunsupervised methods like variational autoencoders and\n \n \n \n \n \n \ngenerative adversarial networks are very promising, but they\n \n \n \n \n \n \n \n \ngenerally depend on training the network with backprop. \nRecent work by Krotov and Hopfield ​[14] addresses this\n \n \n \n \n \n \n \n \n \nspecific problem by learning hidden representations solely\n \n \n \n \n \n \n \nusing an unsupervised method. Their network trains the\n \n \n \n \n \n \n \n \ninput\nto hidden feed-forward connections along with\n \n \n \n \n \n \n \nadditional (non-plastic) recurrent inhibitory connections that\n \n \n \n \n \n \nprovides competition within the hidden layer. For evaluating\n \n \n \n \n \n \n \n \nthe representation, the weights are frozen, and another layer\n \n \n \n \n \n \n \n \n \nconnecting the labels is trained using a linear classifier. Our\n \n \n   \n \n   \n \n \n \napproach shares some common features with that of Krotov\n \n \n \n \n \n \n \n \n \nand Hopfield ​[14]​, e.g. learning hidden representations by\n \n \n \n \n \n \n \n \nunsupervised methods, and evaluating the representations by\n \n \n \n \n \n \n \nanother supervised classifier. However, this work differs by\n \n \n \n \n \n \n \n \nfollowing a probabilistic approach extending the BCPNN\n   \n \n \n \n \n \narchitecture (explained in the next section).   \nAll the related models we have discussed so far employ\n \n \n \n \n \n \n \n \n \n \neither recurrent connectivity within the hidden layer, or\n \n \n \n \n \n \n \n \nhidden-to-input feed-back connections, or both. In this\n \n \n \n \n \n \n \nwork, we only use feed-forward connections, along with an\n \n \n \n \n \n \n \n \n \nimplicit competition via a local softmax operation.  \nIt is also observed that, for unsupervised learning, having\n \n \n \n \n \n \n \n \n \nsparse\nconnectivity\nin\nthe\nfeed-forward\nconnections\n \n \n \n \n \n \nperforms\nbetter\nthan\nfull\nconnectivity\n​[15]​.\nThe\n \n \n \n \n \n \n \nunsupervised learning methods we have discussed so far,\n \n \n \n \n \n \n \n \nhowever, employ full connectivity ​[14, 15]​. In addition to\n \n \n \n \n \n \n \n \n \nthe unsupervised methods, networks employing supervised\n \n \n \n \n \n \nlearning like convolutional neural networks (CNNs) force a\n \n \n \n \n \n \n   \nfixed spatial filter to obtain this sparse connectivity. Here\n \n \n \n \n \n \n \n \n \nwe take an alternate approach where, along with learning\n \n \n \n \n \n \n \n \n \nthe weights of the feed-forward connections, which is\n \n \n \n \n \n \n \n \nregarded\nas\nbiological\nsynaptic\nplasticity,\nwe\nalso\n \n \n \n \n \n \n \nsimultaneously learn the sparse connectivity between the\n \n \n \n \n \n \n \ninput and hidden layer, in analogy with the structural\n \n \n \n \n \n \n \n \n \nplasticity in the brain ​[16]​.  \nIII.\nB​AYESIAN​ C​ONFIDENCE​ P​ROPAGATION​ ​NEURAL \nNETWORK \nWe describe the network architecture and update rules\n \n \n \n \n \n \n \n \nfor the Bayesian Confidence Propagation Neural Network\n \n \n \n \n \n \n \n(BCPNN).\nThe\nsimplest\nBCPNN\narchitecture\nfor\n \n \n \n \n \n \nclassification contains two layers, one for data and the other\n \n \n \n \n \n \n \n \n \n \nfor labels.  \nA layer consists of a set of hypercolumns (HC), each of\n \n \n \n   \n \n \n \n \n \n \nwhich represents a discrete random variable\n(upper\n \n \n \n \n \n  Xi  \n \ncase). Each HC, in turn, is composed of a set of\n \n \n \n \n \n \n \n \n \n \n \nminicolumns (MC) representing a particular instance of the\n \n \n   \n \n \n \n \nrandom variable\n(lower case). The probability of the\n \n  xi  \n \n \n \n \n \n \nvariable\nis then a multinomial distribution, defined as\n  Xi  \n \n   \n \n \n \n \n, such that\n. In the neural\n(X\n)\np\ni = xi\n \n \n \n(X\n) \n1\n∑\n \nxi\np\ni = xi\n=  \n \n \n \n \nnetwork, the activity of the MC is interpreted as\n,\n \n \n \n \n \n   \n \n  (X\n)\np\ni = xi\n \nand the sum of activities of all the MCs inside a HC sums to\n \n \n \n \n \n \n \n \n \n   \n \n   \none. \nSince the network is a probabilistic graphical model, we\n \n \n     \n \n \n \n \ncan compute the posterior of a target HC in the label layer\n \n \n \n \n   \n \n \n \n \n \n \nconditioned on all the source HCs in the input layer. We\n \n \n \n \n \n \n \n \n \n \n \nwill use\n’s and\n’s for referring the HCs in the input and\n \n  x\n \n  y\n \n \n \n \n \n \n \n \n \noutput layer respectively.\nComputing the exact posterior\n \n \n \n \n \n \n \nover the target HC is intractable, since it scales\n(Y |X\n)\np\nj\n1:N  \n \n \n \n   \n \n   \n \nexponentially with the number of units. The assumptions\n \n \n \n \n \n \n \n \nand\n(X , .,\n|Y )\n(X |Y )\np\n1 . XN\nj = ∏\nN\ni=1\np\ni\nj  \n \n(X , .,\n)\n(X )\np\n1 . XN = ∏\nN\ni=1\np\ni  \nallows us to write the posterior  as: \n(Y |X , .,\n)\n(Y )\n \np\nj\n1 . XN = p\nj\np(X ,..,X )\n1\nN\np(X ,..,X |Y )\n1\nN\nj\n \n                    \n(Y )\n \n= p\nj ∏\nN\ni=1\np(X )\ni\np(X |Y )\ni\nj  \n                      \n(Y )\n \n= p\nj ∏\nN\ni=1\np(X ,Y )\ni\nj\np(X ) p(Y )\ni\nj  \nWhen\nthe\nnetwork\nis\ndriven\nby\ninput\ndata\n \n \n \n \n \n \n \n \n,\nwe\ncan\nwrite\nthe posterior\n, .,\n}\n, .,\n}\n{X1 . XN\n= {x1\nD . xD\nN\n \n \n \n \n \n \nprobabilities of a target MC in terms of the source MCs as: \n(y |x , .,\n)\n(y )\np\nj\n1\nD . xD\nN = p\nj ∏\nN\ni=1\n \np(x ,y )\n1\nD\nj\np(x )p(y )\n1\nD\nj  \n                   \n(y )\n \n= p\nj ∏\nN\ni=1\n∏\n \nxi\n (\np(x ,y )\ni\nj\np(x )p(y )\ni\nj )\nI(x =x\n)\ni\ni\nD\n  \nwhere\nis the indicator function that equals 1 if its\n  (·)\nI\n \n \n \n \n \n \n     \n \nargument is true, and zero otherwise. We have written the\n \n \n \n \n \n \n \n \n \n \nposterior of the target MC as a function of all the source\n \n \n \n \n \n   \n \n \n \n \n \nMCs (all \n’s). The log posterior can be written as:\nxi\n \nog p(y |x , .,\n)\nog p(y )\nl\nj\n1\nD . xD\nN = l\nj  \n(x\n) log \n+ ∑\nN\ni=1\n∑\n \nxi\nI\ni = xi\nD\np(x ,y )\ni\nj\np(x )p(y )\ni\nj   \nSince the posterior is linear in the indicator function of\n \n \n \n \n \n \n \n \n \n \ndata\nsample,\ncan be approximated by its\n \n \n(x\n)\nI\ni = xi\nD  \n \n \n \n \n \nexpected value, that is,\n. Except for\n, all the\n \n \n \n \n(x )\np\ni\nD\n \n \n \n(x )\np\ni\nD\n \n \n \nterms in the posterior are functions of the marginals\n,\n \n \n \n \n \n \n \n \n  (x )\np\ni\n \n,\nand\n.\nWe\ndefine\nthe\nterms\nbias\n(x )\np\nj\n \n \n(x ,\n)\np\ni xj\n \n \n \n \n \nand weight\nin\nβ(y )\nog p(y )\n \nj = l\nj  \n \n \n(x ,\n)\nog \nw\ni yj = l\np(x ,y )\ni\nj\np(x )p(y )\ni\nj   \n \nanalogy with artificial neural networks.  \nThe inference step to calculate the posterior probabilities\n \n \n   \n \n \n \n \nof the target MCs conditioned on the input sample is given\n \n \n \n \n \n \n \n \n   \n \nby the activity update equations: \n(y ) \nβ(y ) \nw(x ,\n)\nh\nj\n=  \nj\n+ ∑\nN\ni=1\n∑\n \nxi\n p(x )\ni\nD\n \ni yj  \n                        \n \nπ(y )\nj  =\nexp(γh(y ))\nj\nexp(γh(y ))\n∑\n \nk\n \nk\n  \n      (1) \nwhere\nis the total input received by each target\n \n(y )\nh\nj  \n \n \n \n \n \n \n \n \nMC from which the activity\nis recovered by softmax\n \n \n \n \n  (y )\nπ\nj    \n \n \n \nnormalization (with  gain \n) within the HC.\nγ\n \nThe learning step involves incrementally updating all the\n \n \n \n \n \n \n \n \nmarginals as input samples are presented. The marginals,\n \n \n \n \n \n \n \n \nbias and weight parameters are updated as follows: \n (π(x )−(x )) ,\nτ p\ndt\ndp(x )\ni = kp\ni\np\ni\n  \n (π(x )π(y )\n(x ,\n)),\nτ p\ndt\ndp(x ,y )\ni\nj = kp\ni\nj −p\ni yj\n \n (π(y )\n(y )),\nτ p\ndt\ndp(y )\nj = kp\nj −p\nj\n \n,\n(y )\n log p(y )\nβ\nj = kβ\nj\n \n                       \n.                (2)\n(x ,\n)\n log \nw\ni yj = kw\np(x ,y )\ni\nj\np(x )p(y )\ni\nj  \n \nThe terms\n,\n,\n, and\nare the plasticity gain,\n \n  kp   kβ   kw  \n  τ p  \n \n \n \n \nbias\ngain,\nweight\ngain,\nand\nlearning\ntime constant,\n \n \n \n \n \n \n \n \nrespectively. Equations 1 and 2 define the complete set of\n \n   \n   \n \n \n \n \n \nupdate and learning equations of the BCPNN architecture. \nThe scope of the work is limited to this abstract model of\n \n \n \n \n \n \n \n \n \n \n \n \nBCPNN where MCs are the fundamental computational\n \n \n \n \n \n \n \nunit. The use of this network architecture and learning rule\n \n \n \n \n \n \n \n \n \n \nto model short- and long-term memory with palimpsest\n \n \n \n \n \n \n \n \nproperties in biological memory context can be found in our\n \n \n \n \n \n \n \n   \n \nprevious work ​[​6, ​17​]. \nIV.\nU​NSUPERVISED​ ​REPRESENTATION​ ​LEARNING \nThe network for unsupervised learning is similar to the\n \n \n \n \n \n \n \n \n \ntwo-layer network, except we now have more than one HC,\n \n \n \n \n \n \n \n \n \n \neach of which can contain arbitrary number of MCs (see\n \n \n \n \n \n \n \n \n \n \nFigure 2). On top of this network, we introduce additional\n \n \n \n \n \n \n \n \n \n \nmechanisms that enable learning representations.  \nA. Bias regulation \nThe BCPNN update rule implements Bayesian inference\n \n \n \n \n \n \n \nif the parameters are learnt with the source and target layer\n \n \n \n \n \n \n \n \n \n \n \nprobabilities available as observations. When the target\n \n \n \n \n \n \n \nlayer is hidden, we are learning the representations, and we\n   \n \n \n \n \n \n \n \n \ncannot expect the update rule to follow Bayesian inference.\n \n \n \n \n \n \n \n \n \nIn fact, we can see that performing learning and inference\n \n \n \n \n \n \n \n \n \n \nsimultaneously is counter-productive in this case.  \nConsider\na\nhidden\nrepresentation\nwith\na\nnoisy\n \n \n \n \n \n \n \ninitialization that assigns some MCs with slightly higher\n \n \n \n \n \n \n \n \nmarginal probability\nthan others. Learning will then\n \n \n(z )\np\nj  \n \n \n \n \n \namplify this difference, and find parameters that will\n \n \n \n \n \n \n \n \nassociate more input samples with the MCs with high\n,\n \n \n \n \n \n \n \n \n  (z )\np\nj\n \ncausing the marginals to increase further. One way to\n \n \n \n \n \n \n \n \n \ncircumvent this effect is to “push” MCs that have low\n \n \n     \n \n \n \n \n  (z )\np\nj  \nto be more active in the future, a kind of activity\n \n \n \n \n \n \n \n \n \n \n \nhomeostasis in biological terms \nWe use a bias regulation mechanism, where the bias gain\n \n   \n \n \n \n \n \n \n \nfor each MC, which equals 1 if we are performing just\nkβ\n \n \n \n \n     \n \n \n \n \nBayesian inference, is made a function of\n. One\n \n \n \n \n \n \n \n(z )\np\nj\n \n \nmotivation for choosing the bias gain is that, we want to\n \n \n \n \n \n \n \n \n \n \n \ninfluence the marginal\nalone, leaving out the weight\n \n \n \n(z )\np\nj  \n \n \n \n \n \nparameters that is responsible for learning the input to\n \n \n \n \n \n \n \n \n \nhidden mapping. The value of\nis compared with\n \n \n \n \n \n(z )\np\nj  \n \n \n \nrespect\nto\nthe\nmaximum\nentropy\nprobability,\n \n \n \n \n \n \n, where\nis the number of MCs in a\n/N\npMaxEnt = 1\nMC  \n  N MC  \n \n \n \n \n \n   \nHC. Notice that the maximum entropy distribution is the\n \n \n \n \n \n \n \n \n \nideal representation without the input layer, since all the\n \n \n \n \n \n \n \n \n \nMCs have equal marginal probability, and hence\n \n \n \n \n \n \n  pMaxEnt  \nacts as the reference for bias regulation. The update\n \n \n \n \n \n \n \n \n \nequation of \n is:\nkβ\n \nk\nτ k dt\ndkβ = 1 + ( β −1)\n(p\n/4)\nMaxEnt\n2\n(p(z ) −p\n/4)\nj  \nMaxEnt\n2\n \n \nwhere\nis the time\nconstant. The mechanism\n  τ k  \n \n \n \n \n \n \nmaintains the value of gain\nat around one when\n \n \n \n \n  kβ  \n \n \n \n \n, and drops sharply to negative values\np(z )\nj  ≫pMaxEnt  \n \n \n \n \n \n \nwhen\nis below\n(see Figure 1). The rate of\n  p(z )\nj   \n \n  pMaxEnt  \n \n \n \n \n \n \nthis drop is controlled using the parameter\n, defined as\n \n   \n \n \n \n  khalf  \n \n \nthe value of gain \n at \n.\nkβ = khalf\n/2 p\np(z )\nj  = 1\nMaxEnt  \n \nFigure 1: Bias regulation mechanism. For generating the figure, \n and \nwas used.\n−\n \nkhalf = 5\n.01  \npMaxEnt = 0\n \n \nB. Structural plasticity \nStructural plasticity aims to find receptive fields for the\n \n \n \n \n \n \n \n \n \nhidden MCs from the input layer. We define a boolean\n \n \n \n \n \n \n \n   \n \nvariable\ndenoting the connection from the\nth input HC\n  M ij  \n \n \n \n \n  i\n \n \n \nto the\nth hidden HC as either active\nor silent\n \n  j\n \n \n \n \n \n  M ij = 1  \n \n \n. Each\nis initialized randomly with probability\nM ij = 0  \n  M ij    \n \n \n \n \n. Once initialized, the total number of active incoming\npM  \n \n \n \n \n \n \n \n \nconnections to each hidden HC is fixed whereas the\n \n \n \n \n \n \n \n \n \noutgoing connections from a source HC can be changed.\n \n \n   \n \n \n \n \n \nThe mutual information (MI) between the\nth HC and\nth\n \n \n \n \n \n  i\n \n \n  j\n \nHC\nis\ncalculated\nfrom\nthe\nBCPNN\nweights:\n \n \n \n \n \n \n \n. The input HCs then normalizes\nw(x ,\n)\nIij =  ∑\n \nx ,z\ni\nj\np(x ,\n)\ni zj  \ni zj\n \n \n \n \n \n \nthe MI by the total number of active outgoing connections: \n.\n/(1\n)\nI\n︿\nij = Iij \n+ ∑\n \nk\nM ik\n \nSince the total number of active incoming connections is\n \n \n \n \n \n \n \n \n \nfixed, each hidden HC greedily maximizes the\nit\n \n \n \n \n \n \n  I\n︿\nij \n \nreceives by removing the active connection with the lowest\n \n \n \n \n \n \n \n \n \n(set\nfrom 1 to 0) and add an inactive connection\nI\n︿\nij \n  M ij  \n   \n \n \n \n \n \n \n \nwith the highest\n(set\nfrom 0 to 1). We call this\n \n \n  I\n︿\nij  \n  M ij  \n   \n \n \n \n \n \noperation a ​flip​, and use a parameter\nto set the\n \n \n \n \n   \n  N flips  \n \n \n \nnumber of flips made per training iteration. \n \n \n \nFigure 2: The schematic of the network used for unsupervised learning. In \nthis network, the input layer contains nine binary HCs  (grey circles on the \nleft), and the hidden layer contains three HCs (grey boxes), each of which \ncontains four MCs (grey circles inside the boxes).  The existence of a \nconnection between an input HC and hidden HC is shown as a blue strip, \ni.e.,  \n. The input-hidden weights are shown as yellow dots and are\n \nM ij = 1\n \npresent only when a connection already exists. \n \nV.\nC​LASSIFICATION \nAfter learning the input-hidden connection, we freeze\n \n \n \n \n \n \n \nthe weights, biases, and receptive fields of this connection,\n \n \n \n \n \n \n \n \n \nand treat the hidden layer representations as input to train a\n \n \n \n \n \n \n \n \n \n   \nBCPNN classifier with an output (label) layer. We add\n \n \n \n \n \n \n \n \n \nanother BCPNN projection from hidden to output layer with\n \n \n \n \n   \n \n \n \na negative gain\n(in contrast to the existing\n \n \n \n−\nkw = 1  \n \n \n \n \n \nprojection with\n). This is analogous to a network\n \n  kw = 1  \n \n \n \n   \n \narchitecture used to model reinforcement learning in the\n \n \n \n \n \n \n \n \nbasal ganglia ​[18]​. We call the projections ​Go ​(\n) and\n \n \n \n \n \n \n \n  kw = 1  \n \nNo-Go (\n), as they are intended to increase the\n \n−\nkw = 1  \n \n \n \n \n \n \n \nprobability of correct labels and reduce the probability of\n \n \n \n \n \n \n \n \n \nwrong labels, respectively. The classification layer training\n \n \n \n \n \n \n \nprocedure is as follows: we first drive the pre-trained\n \n \n \n \n \n \n \n \n \nnetwork from input samples and check the predicted label.\n \n \n \n \n \n \n \n \n \nIf the classification is wrong, we either train the Go\n \n \n \n \n \n \n \n \n \n \nprojection (by setting the output activations to the true\n \n \n \n \n \n \n \n \n \nlabel), or train the No-Go projection (by setting the output\n \n \n \n \n \n \n \n \n \n \nactivations to the predicted label), or both. We run this\n \n \n \n \n \n \n \n \n \n \nprocedure for \n epochs.\nN sup\n \nVI.\nR​ESULTS \nWe evaluate the model using the MNIST hand-written\n \n \n \n \n \n \n \n \ndigits database [​19]​. The MNIST dataset contains 60000\n \n \n \n \n \n \n \n \ntraining and 10000 test 28x28 images. The grey-scale\n \n \n \n \n \n \n \n \nintensities\nwere\nnormalized\nto\nthe\nrange\n[0,1]\nand\n \n \n \n \n \n \n \n \ninterpreted as probabilities. For each of the following\n \n \n \n \n \n \n \n \nsubsections, we used 50000 random training samples for\n \n \n \n \n \n \n \n \ntraining, report on the other 10000 in the validation set, and\n \n \n \n \n \n \n \n \n \n \n \nat the end of this section, report the test accuracy of 10000\n \n \n \n \n \n \n \n \n \n \n \n \nsamples for the best set of model parameters. The network\n \n \n \n \n \n \n \n \n \n \nhad 784 input HCs, the hidden layer had 30 HCs and 100\n \n \n \n \n \n \n \n \n \n \n \n \nMCs per HC, and the output layer had one HC with 10 MCs\n \n \n \n \n \n \n \n \n \n \n \n \n \ncorresponding to digit labels. The time constants\nand\n \n \n \n \n \n \n  τ k  \n  τ p  \nwere scaled by the training time, and we varied these scaling\n \n \n \n \n \n \n \n \n \n \n \nfactors\nand\nin the experiments. The parameters used\n  τ o\nk  \n  τ o\np    \n \n \n \n \n \nin the simulation are listed in Table 1. All the results\n \n \n \n \n \n \n \n \n \n \n \npresented here are the mean and standard deviation of the\n \n \n \n \n \n \n \n \n \n \nmean squared validation error over 10 random runs of the\n \n \n \n \n \n \n \n \n \n \nnetwork, unless stated otherwise. \nTABLE I.  M​ODEL​ ​PARAMETERS \nSymbol \nValue \nDescription \nt\nΔ  \n0.01 \nTime-step \n \nγ  \n1 \nSoftmax gain \n \nkhalf  \n-100 \nBias gain when marginal is /2 p\n \n1\nMaxEnt  \n \nτ o\np  \n0.5 \nMultiplier for learning time-constant \n \nτ o\nk  \n0.1 \nMultiplier for bias gain time-constant \n \npM  \n0.1 \nProbability of connections from input to \nhidden layer \n,\n \nN train N val  \n50k, \n10k \nNumber of training and validation samples \n \nN usup  \n5 \nNumber of epochs of training for \nunsupervised learning \n \nN sup  \n25 \nNumber of epochs for training the BCPNN \nclassifier \n \nA. Bias regulation \nWe evaluate the bias regulation mechanism by measuring\n \n \n \n \n \n \n \n \nthe accuracy ​while varying the relevant parameters:\nis\n \n \n \n \n \n \n  khalf\n \nchanged from\nto\nin steps of\n, and\nfrom\n \n \n0\n−1    \n00\n−1\n   \n \n \n0\n−1\n \n  τ o\nk  \n \nto\nin exponential steps of\n. Results are shown\n0\n1 −2  \n  0\n1 1  \n \n \n \n  0\n1\n \n \n \n \nin Figure 3a. The accuracy improves consistently as\nis\n \n \n \n \n \n \n \n  khalf    \nlowered and converges at around\nto\n. This\n \n \n   \n0\nkhalf <  −5     6.7\n9\n \n \nsuggests that our bias regulation mechanism effectively\n \n \n \n \n \n \n \nimproves the representations.  \n \nTo\nquantitatively assess the effect of\non the\n \n \n \n \n \n \nkhalf  \n \n \nmarginals\n, we compute the marginal entropy of each\n \n(z )\np\nj\n \n \n \n \n \n \n \n \nthe\nHC,\n,\nand\nplot\nthe\n \n \n(p(Z ))\n(z ) log p(z )\nH\nj\n= ∑\n \nzj\np\nj\nj\n \n \n \n \nhistogram of this entropy over the 30 HCs (Figure 3c). Note\n \n \n \n \n \n \n \n \n \n \n \nthat for the marginals, higher entropy is preferred since it\n \n \n \n \n \n \n \n \n   \nindicates all the MCs in a HC are utilized evenly, and\n \n \n \n \n   \n \n \n \n \n \nwas our target while designing the bias regulation\npMaxEnt  \n \n \n \n \n \n \n \n \nmechanism. Even though the number of samples used in\n \n \n \n \n \n \n \n \n \nplotting this histogram is low (\n), it clearly shows that\n \n \n   \n  N HC\n   \n \n \n \nlowering the\n increases the entropy of all the HCs.\nkhalf\n \n \n \n \nFigure 3: Accuracy results as a function of \n for different values of\n \nkhalf\n \ntime constant of bias gain \n (3a), accuracy results as a function of\n \nτ o\nk\n \nsoftmax gain \n for different values of learning time constant (3b).\n \nγ\n \nHistogram of marginal entropy \n of hidden layer HCs for different\n(Z )  \np\nj\n \n (3c), and histogram of conditional entropy \n for different\n \nkhalf\n(Z |X)  \np\nj\n \nvalues of softmax gain \n(3d).\n \nγ\n \n \n \nThe marginals give the overall utilization of the MCs over\n \n \n \n \n \n \n \n \n \n \nthe training set, and we have evaluated it by measuring the\n \n \n \n \n \n \n   \n \n \n \nentropy of this marginal distribution with respect to the\n \n \n \n \n \n \n \n \n \nparameter that regulates the bias\n. However, the\n \n \n \n \n \nk\n)\n( half\n \n \n \nmarginals by themselves cannot give the complete picture of\n \n \n \n \n \n \n \n \n \nthe representations since they do not take into account how\n \n \n \n \n \n \n \n \n \n \nwell the representations differentiate between samples. To\n \n \n \n \n \n \n \nsee this, we can imagine a worse-case scenario where all the\n \n \n \n \n   \n \n \n \n \n \nMCs, for all the input samples, have a posterior of\n.\n \n \n \n \n \n \n   \n \n  pMaxEnt  \nThis will result in high marginal entropy, but is certainly not\n \n \n   \n \n \n \n   \n \n \ndesirable.  \n \nWe measured the entropy of the posterior distribution of\n \n \n \n \n \n \n \n \n \nthe MCs conditioned on each input sample, that is,\n \n \n \n \n \n \n \n \nContrary to the entropy of the marginals, we\nH(p(Z |X)).\n \nj\n \n \n \n \n \n \n \n \n \nexpect this entropy to be as low as possible as we want the\n \n \n \n \n \n \n \n \n \n \n \n \n \nposteriors in the hidden layer to be certain about the\n \n \n \n \n \n \n \n \n \n \nconditioned input sample. The hyper-parameter that will\n \n \n \n \n \n \n \ncontrol this is the softmax gain\n. We computed the\n \n \n \n \n \n  γ  \n \n \n \nconditional entropy of all HCs per sample, and plotted the\n \n \n \n \n \n \n \n \n \n \nhistogram over all samples in Figure 3d. The histogram\n \n \n \n \n \n \n \n \n \nshows that the entropy predominantly has values\n,\n \n \n \n \n \n \n  < 2  \nwhereas\nthe\nmaximum\nentropy\nis\naround\n \n \n \n \n \n \nfor\n. This confirms that the bias\n)\n.6\nlog(pMaxEnt ≈4\n \n  γ = 1  \n \n \n \n \n \nregulation does not force the representations to have high\n \n \n \n \n \n \n \n \n \nmarginal entropy at the cost of making all posterior per\n \n \n \n \n \n \n \n \n \n \nsample have high entropy. Figure 3b shows an interesting\n \n \n \n \n \n \n \n \n \nrelationship between accuracy of the representations and the\n \n \n \n \n \n \n \n \nsoftmax gain\n. One would expect low values of\nto have\n \n  γ  \n \n \n \n \n \n  γ    \n \npoor performance since we “flatten” the posteriors to be\n \n \n \n \n \n \n \n \n \nequal in value, and thereby, losing information about the\n \n \n \n \n \n \n \n \n \ninput sample. However, high values of\n(>1) also worsen\n \n \n \n \n \n  γ  \n \n \n \nthe performance, that is, having “winner-take-all” like\n \n \n \n \n \n \n \nrepresentations\nneed\nnot\nnecessarily\nimply\nbetter\n \n \n \n \n \n \nrepresentations.  \nB. Structural plasticity \nIn Figure 4, we visualize the receptive fields of four\n \n \n \n \n \n \n \n \n \n \nrandomly chosen HCs and a subset of the corresponding\n \n \n \n   \n \n \n \n \nMCs in the network. Notice that we obtain rather contiguous\n   \n \n \n \n \n \n \n \n \npatches even though no spatial structure of images were\n \n \n \n \n \n \n \n \n \npresented. The receptive fields of MCs also seem to capture\n \n \n \n \n \n \n \n   \n \ndiverse features such as lines and strokes. \n \n \nFig 4: Receptive fields. Each row corresponds to a randomly chosen HC \nand the constituent MCs.. First column shows the receptive field of HC \nbefore training and second column after training (black means \n). \nM ij = 1  \nThe remaining columns shows the receptive field of nine randomly chosen \nMCs in the HC. \nThe parameter\nwas introduced to control the number\n \n  N flip  \n \n \n \n \n \n \nof flips in the receptive field per iteration. We measure the\n \n \n \n \n \n \n \n \n \n \n \naccuracy while varying\nfrom 1 to 258 exponentially in\n \n \n  N flip  \n     \n \n   \nsteps of 2. Figure 5 shows that the accuracy converges at\n \n \n \n   \n \n \n \n \n \n \n.\n6\nN flip = 1\n \nC. Classification  \nTable 2 shows the accuracy when learning with the\n \n \n \n \n \n \n \n \n \nfollowing strategies: (i) Go, (ii) No-Go and, (iii) Go +\n \n \n \n \n \n \n \n \n \n \nNo-Go. Go and No-Go strategies perform well individually,\n \n \n \n \n \n \n \n \nbut Go + No-Go performs slightly better.  \n \nFor the parameter set we found best suited (Table 1), we\n \n \n \n \n \n \n \n \n \n \n \nreport the train and test accuracies as 99.10\n0.63 % and\n \n \n \n \n \n \n \n±\n \n \n \n96.49\n0.12%, respectively.\n±\n \n \n \nFigure 5: Accuracy results as a function of number of receptive field flips \nper iteration \nTABLE II. \nC​LASSIFICATION​ ​RESULTS \nArchitecture \nAccuracy (train) \nAccuracy (validation) \nGo \n98.03 \n 0.28\n \n±\n \n96.40 \n 0.10\n \n±\n \nNo-Go \n97.21 \n 0.13\n \n±\n \n96.23 \n0.13\n \n±\n \nGo + No-Go \n99.10  \n0.63\n \n±\n \n96.52 \n 0.08\n \n±\n \n \nVII.\nD​ISCUSSION \nWe have demonstrated that the proposed network model can\n \n \n \n \n \n \n \n \n \nperform unsupervised representation learning using local\n \n \n \n \n \n \nHebbian rules. The performance on MNIST is significantly\n \n \n \n \n \n   \n \nlower than the “superhuman” deep learning methods.\n \n \n \n \n \n \n \nHowever, we consider it to be of lesser importance than the\n \n \n   \n \n \n \n \n \n \n \nlower\ncomplexity\nof our correlation based brain-like\n \n \n \n \n \n \n \nlearning\napproach,\nwhich\nhas\na\npotential\nfor\nhigh\n \n \n \n \n \n \n \n \nrobustness,\ngood\nscaling\nand\nlow-power\nhardware\n \n \n \n \n \n \nimplementations. \n \nIt is important to note that the unsupervised learning\n \n \n \n \n \n \n \n \n \nmethods introduced here are proof-of-concept designs and\n \n \n \n \n \n \n \nnot meant to directly model some specific biological system\n \n \n \n \n \n \n \n \n \nor structure. Yet, they may shed some light on the\n \n \n \n \n \n \n \n \n \n \nhierarchical\nfunctional\norganization\nof\ne.g.\nsensory\n \n \n \n \n \n \nprocessing streams in the brain. \n \nFurther work will focus on extending our architecture with a\n \n \n \n \n \n \n \n \n   \nbrain-like deep structure and recurrent connectivity as well\n \n \n \n \n \n \n \n \nas to compare functionality and performance to other\n \n \n \n \n \n \n \n \npopular unsupervised learning networks such as stacked\n \n \n \n \n \n \n \nauto-encoders and stacked RBMs ​[2]​, as well as the network\n \n \n \n \n \n \n \n \n \n \nby Krotov and Hopfield ​[14]​. \nA​CKNOWLEDGMENT \nThis project is funded within the framework of Swedish\n \n \n \n \n \n \n \n \n \ne-Science Research Centre (SeRC). The simulations were\n \n \n \n \n \n \n \nperformed on resources provided by the Swedish National\n \n \n \n \n \n \n \n \nInfrastructure for Computing (SNIC) at the PDC Center for\n \n \n \n   \n \n \n \n \nHigh Performance Computing, KTH Royal Institute of\n \n \n \n \n \n \n \nTechnology. \nR​EFERENCES \n[1]\nY. Bengio, A. Courville, and P. Vincent, “Representation learning: a \nreview and new perspectives,” ​IEEE Trans. Pattern Anal. Mach. \nIntell.​, vol. 35, no. 8, pp. 1798–1828, Aug. 2013. \n[2]\nD. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, and S. \nBengio, “Why does unsupervised pre-training help deep learning?,” ​J. \nMachine Learning Research​, vol. 11, pp. 625–660, 2010. \n[3]\nI. Goodfellow, Y. Bengio, and A. Courville, ​Deep Learning​. MIT \nPress, 2016. \n[4]\nJ. C. R. Whittington and R. Bogacz, “Theories of Error \nBack-Propagation in the Brain,” ​Trends Cogn. Sci.​, vol. 23, no. 3, pp. \n235–250, Mar. 2019. \n[5]\nR. J. Douglas and K. A. C. Martin, “Recurrent neuronal circuits in the \nneocortex,” ​Current Biology​, vol. 17, no. 13. pp. R496–R500, 2007, \ndoi: ​10.1016/j.cub.2007.04.024​. \n[6]\nK. Doya, ​Bayesian Brain: Probabilistic Approaches to Neural Coding​. \nMIT Press, 2007. \n[7]\nF. Fiebig and A. Lansner, “A Spiking Working Memory Model Based \non Hebbian Short-Term Potentiation,” ​The Journal of Neuroscience​, \nvol. 37, no. 1. pp. 83–96, 2017, doi: ​10.1523/jneurosci.1989-16.2016​. \n[8]\nM. Lundqvist, P. Herman, and A. Lansner, “Theta and Gamma Power \nIncreases and Alpha/Beta Power Decreases with Memory Load in an \nAttractor Network Model,” ​Journal of Cognitive Neuroscience​, vol. \n23, no. 10. pp. 3008–3020, 2011, doi: ​10.1162/jocn_a_00029​. \n[9]\nA. Sandberg, A. Lansner, K. M. Petersson, and O. Ekeberg, “A \nBayesian attractor network with incremental learning,” ​Network​, vol. \n13, no. 2, pp. 179–194, May 2002. \n[10] A. Lansner, S. Benjaminsson, and C. Johansson, “From ANN to \nBiomimetic Information Processing,” ​Biologically Inspired Signal \nProcessing for Chemical Sensing​. pp. 33–43, 2009, doi: \n10.1007/978-3-642-00176-5_2​. \n[11] V. Mountcastle, “The columnar organization of the neocortex,” ​Brain​, \nvol. 120, no. 4. pp. 701–722, 1997, doi: ​10.1093/brain/120.4.701​. \n[12] K. Rockland, “Five points on columns,” ​Frontiers in Neuroanatomy​. \n2010, doi: ​10.3389/fnana.2010.00022​. \n[13] A. Lansner, “Associative memory models: from the cell-assembly \ntheory to biophysically detailed cortex simulations,” ​Trends in \nNeurosciences​, vol. 32, no. 3. pp. 178–186, 2009, doi: \n10.1016/j.tins.2008.12.002​. \n[14] D. Krotov and J. J. Hopfield, “Unsupervised learning by competing \nhidden units,” ​Proc. Natl. Acad. Sci. U. S. A.​, vol. 116, no. 16, pp. \n7723–7731, Apr. 2019. \n[15] B. Illing, W. Gerstner, and J. Brea, “Biologically plausible deep \nlearning — But how far can we go with shallow networks?,” ​Neural \nNetworks​, vol. 118. pp. 90–101, 2019, doi: \n10.1016/j.neunet.2019.06.001​. \n[16] M. Butz, F. Wörgötter, and A. van Ooyen, “Activity-dependent \nstructural plasticity,” ​Brain Research Reviews​, vol. 60, no. 2. pp. \n287–305, 2009, doi: ​10.1016/j.brainresrev.2008.12.023​. \n[17] P. J. Tully, M. H. Hennig, and A. Lansner, “Synaptic and nonsynaptic \nplasticity approximating probabilistic inference,” ​Frontiers in Synaptic \nNeuroscience​, vol. 6. 2014, doi: ​10.3389/fnsyn.2014.00008​. \n[18] P. Berthet, J. Hellgren-Kotaleski, and A. Lansner, “Action selection \nperformance of a reconfigurable basal ganglia inspired model with \nHebbian-Bayesian Go-NoGo connectivity,” ​Front. Behav. Neurosci.​, \nvol. 6, p. 65, Oct. 2012. \n[19] “MNIST handwritten digit database, Yann LeCun, Corinna Cortes and \nChris Burges.” [Online]. Available: \nhttp://yann.lecun.com/exdb/mnist/​. [Accessed: 30-Jan-2020]. \n \n \n \n \n",
  "categories": [
    "cs.LG",
    "cs.NE",
    "stat.ML"
  ],
  "published": "2020-03-27",
  "updated": "2020-03-27"
}