{
  "id": "http://arxiv.org/abs/2003.13541v1",
  "title": "A Privacy-Preserving Distributed Architecture for Deep-Learning-as-a-Service",
  "authors": [
    "Simone Disabato",
    "Alessandro Falcetta",
    "Alessio Mongelluzzo",
    "Manuel Roveri"
  ],
  "abstract": "Deep-learning-as-a-service is a novel and promising computing paradigm aiming\nat providing machine/deep learning solutions and mechanisms through Cloud-based\ncomputing infrastructures. Thanks to its ability to remotely execute and train\ndeep learning models (that typically require high computational loads and\nmemory occupation), such an approach guarantees high performance, scalability,\nand availability. Unfortunately, such an approach requires to send information\nto be processed (e.g., signals, images, positions, sounds, videos) to the\nCloud, hence having potentially catastrophic-impacts on the privacy of users.\nThis paper introduces a novel distributed architecture for\ndeep-learning-as-a-service that is able to preserve the user sensitive data\nwhile providing Cloud-based machine and deep learning services. The proposed\narchitecture, which relies on Homomorphic Encryption that is able to perform\noperations on encrypted data, has been tailored for Convolutional Neural\nNetworks (CNNs) in the domain of image analysis and implemented through a\nclient-server REST-based approach. Experimental results show the effectiveness\nof the proposed architecture.",
  "text": "IEEE Copyright Notice\nCopyright c⃝2020 IEEE Personal use of this material is permitted. Permission from IEEE must be obtained for all other\nuses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes,\ncreating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this\nwork in other works.\nA Privacy-Preserving Distributed Architecture for Deep-Learning-as-a-Service\nSimone Disabato1\nAlessandro Falcetta1\nAlessio Mongelluzzo1\nManuel Roveri1\nAccepted to be published in: 2020 International Joint Conference on Neural Networks (IJCNN), Glasgow,\nJuly 19–24, 2020\nPlease cite as:\nS. Disabato, A. Falcetta, A. Mongelluzzo, and M. Roveri. ”A Privacy-Preserving Distributed\nArchitecture for Deep-Learning-as-a-Service.” 2020 International Joint Conference on Neural\nNetworks (IJCNN). IEEE, 2020.\nBibTex\n@inproceedings{disabato2020privacy,\ntitle={A Privacy-Preserving\nDistributed Architecture for\nDeep-Learning-as-a-Service},\nauthor={Disabato, Simone, and Falcetta, Alessandro, and\nMongelluzzo, Alessio, and Roveri, Manuel},\nbooktitle={2020 International Joint Conference on Neural\nNetworks (IJCNN)},\npages={1--8},\nyear={2020},\norganization={IEEE}\n}\n1Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy.\narXiv:2003.13541v1  [cs.LG]  30 Mar 2020\nA Privacy-Preserving Distributed Architecture\nfor Deep-Learning-as-a-Service\nSimone Disabato, Alessandro Falcetta, Alessio Mongelluzzo, and Manuel Roveri\nDipartimento di Elettronica, Informazione e Bioingegneria,\nPolitecnico di Milano, Milano, Italy\nEmail: alessandro.falcetta@mail.polimi.it, {simone.disabato,alessio.mongelluzzo,manuel.roveri}@polimi.it\nAbstract—Deep-learning-as-a-service is a novel and promising\ncomputing paradigm aiming at providing machine/deep learning\nsolutions and mechanisms through Cloud-based computing in-\nfrastructures. Thanks to its ability to remotely execute and train\ndeep learning models (that typically require high computational\nloads and memory occupation), such an approach guarantees\nhigh performance, scalability, and availability. Unfortunately,\nsuch an approach requires to send information to be processed\n(e.g., signals, images, positions, sounds, videos) to the Cloud,\nhence having potentially catastrophic-impacts on the privacy of\nusers. This paper introduces a novel distributed architecture\nfor deep-learning-as-a-service that is able to preserve the user\nsensitive data while providing Cloud-based machine and deep\nlearning services. The proposed architecture, which relies on\nHomomorphic Encryption that is able to perform operations on\nencrypted data, has been tailored for Convolutional Neural Net-\nworks (CNNs) in the domain of image analysis and implemented\nthrough a client-server REST-based approach. Experimental\nresults show the effectiveness of the proposed architecture.\nI. INTRODUCTION\nIn recent years, the technological evolution of Cloud-\nbased computing infrastructures intercepted the ever-growing\ndemand of machine and deep-learning solutions leading to\nthe novel paradigms of machine and deep-learning-as-a-\nservice [1]. The core of such computing paradigms is that\nCloud providers provide ready-to-use remotely-executable ma-\nchine/deep learning services in addition to virtual computing\nenvironments (as in infrastructure-as-a-service) or platform-\nbased solutions (as in platforms-as-a-service). Examples of\nsuch services are the identiﬁcation of faces in images or videos\nor the conversion of text-to-speech or speech-to-text [2]. From\nthe perspective of the user, being ready-to-use, these services\ndo not require the training of the models (that are pre-trained\nby the Cloud provider) nor the local recall of such models (that\nare executed on the Cloud). Moreover, the Cloud-based com-\nputing infrastructure providing such machine/deep learning\nsolutions as-a-service allows to support scalability, availability,\nmaintainability, and pay-per-use billing mechanisms [3].\nUnfortunately, to be effective, such an approach involves\nthe processing of data that might be sensitive, e.g., personal\npictures or videos, medical diagnoses, as well as data that\nmight reveal ethnic origin, political opinions, but also genetic,\nbiometric and health data [4].\nThe aim of this paper is to introduce a novel distributed\narchitecture meant to preserve the privacy of user data in\nthe deep-learning-as-a-service computing scenario. To achieve\nthis goal, the proposed architecture relies on Homomorphic\nEncryption (HE) that is an encryption scheme allowing the\nprocess of encrypted data [5]. In the proposed architecture,\nby exploiting the properties of HE, users can locally encrypt\ntheir data through a public key, send them to a suitably-\nencoded Cloud-based deep-learning service (provided through\nthe deep-learning-as-a-service approach), and receive back the\nencrypted results of the computation that are locally decrypted\nthrough the private key. More speciﬁcally, such architecture al-\nlows to decouple the encryption/decryption phases, which are\ncarried out on the device of the user (e.g., a personal computer\nor a mobile device), from the deep-learning processing, which\nis carried out on the Cloud-based computing infrastructure.\nSuch a HE-based distributed architecture allows to preserve\nthe privacy of data (plain data are never sent to the Cloud\nprovider) while guaranteeing scalability, availability, and high\nperformance provided by Cloud-based solution.\nThe ability to process encrypted data of HE comes at two\nmain drawbacks. First, the computational load and the memory\ndemand of HE-encoded operations is much higher than regular\nones, hence making the HE-encoded deep-learning processing\nhighly demanding in terms of computation and memory.\nThis is the reason why we focused on a deep-learning-as-\na-service approach where the computation is carried out on\nhigh performing units on the Cloud. Second, HE supports\nonly a limited set of operations (typically sums and multi-\nplications). For this reason, prior to the encoding provided\nby the HE scheme, the deep-learning models have to be\nredesigned and retrained taking into account the constraints\non the set of available operations. In addition, HE schemes\nhave to be conﬁgured through some parameters that trade-off\nthe accuracy in the computation with the computational loads\nand memory occupation. Such a conﬁguration, that depends on\nthe processing chain and the data to be processed, is managed\nat the Cloud-level by providing different settings of parameters\nthat can be explored by the user.\nThe proposed architecture is intended to work with any\nmachine and/or deep learning solution. However, in this work,\nit has been tailored to image analysis solutions leveraging\nConvolutional Neural Networks (CNNs) [6], and implemented\nthrough a client (locally executed on the user device) de-\nveloped as a Python library and a server developed as a\ndeep-learning-as-a-service container implemented on Amazon\nAWS. The developed architecture relies on a Representational\nstate transfer (REST) paradigm for exchanging encrypted data\nand results between client and server, while messages rely on\nJSON format.\nA wide experimental campaign shows the feasibility and\nevaluates the performance of the proposed architecture. The\nPython Library for the client and the Amazon AWS Container\nare made available to the scientiﬁc community1.\nThe paper is organized as follows. Section II introduces\na background on HE, while Section III describes the related\nliterature. The proposed architecture is detailed in Section IV,\nwhile the technological implementation is described in Sec-\ntion V. Experimental results are described in Section VI and\nconclusions are ﬁnally drawn in Section VII.\nII. BACKGROUND\nThe homomorphic scheme encryption is a special type of\nencryption that allows (a set of) operations to be performed\non encrypted data, i.e., directly on the ciphertexts. More\nspeciﬁcally, as detailed in [7], an encryption function E and\nits decryption function D are homomorphic w.r.t. a class of\nfunctions F if, for any function f ∈F, we can construct a\nfunction g such that f(x) = D(g(E(x))) for a set of input x.\nThe\nHE\nscheme\nconsidered\nin\nthis\npaper\nis\nthe\nBrakerski/Fan-Vercauteren (BFV) scheme [8] that, similarly\nto other works [9], [10], is based on the Ring-Learning With\nErrors (RLWE) problem. While a detailed description of such a\nproblem and its security/implementation aspects can be found\nin [11], we here provide a brief introduction to the main\nconcepts. The BFV scheme relies on the following set of\nencryption parameters (from now on denoted with Θ):\n• m: Polynomial modulus degree,\n• p: Plaintext modulus, and\n• q: Ciphertext coefﬁcient modulus.\nThe parameter m must be a positive power of 2 and represents\nthe degree of the cyclotomic polynomial Φm(x). The plaintext\nmodulus p is a positive integer that represents the module of\nthe coefﬁcients of the polynomial ring Rp = Zp[x]/Φm(x)\n(onto which the RLWE problem is based). Finally, the param-\neter q is a large positive integer resulting from the product\nof distinct prime numbers and represents the modulo of the\ncoefﬁcients of the polynomial ring in the ciphertext space. A\ncrucial concept of a HE scheme is the Noise Budget (NB) that\nis an indicator related to the number of operations that can\nbe done on a ciphertext while guaranteeing the correctness\nof the result. This problem (i.e., the maximum number of\noperations on the ciphertext) comes from the fact that, during\nthe encryption phase, noise is added to the ciphertexts to\nguarantee that, being p1 = p2 two plain values to be encrypted\nwith the same public key, the corresponding ciphertexts c1 and\nc2 are different (i.e., c1 ̸= c2). All the operations performed\non the ciphertext consume a certain amount of NB (depending\non the type of operation and the input): operations like\nadditions and multiplications between ciphertext and plaintext\n1Code\nis\navailable\nfor\ndownload\nas\na\npublic\nrepository\nat\nhttps://github.com/AlexMV12/PyCrCNN.git\nconsume a small amount of NB, while multiplications between\nciphertexts are particularly demanding in terms of NB. When\nthe NB decreases to 0, decrypting that ciphertext will produce\nan incorrect result.\nFrom a practical point of view, the choice of the encryption\nparameters Θ determines several aspects: the initial value\nof the NB, its consumption during computations (hence the\nnumber of operations to be performed on a ciphertext), the\nlevel of security against ciphertext attacks, the computational\nload and memory occupation of the HE processing and the\naccuracy of the results (i.e., measuring the correctness of the\ndecrypted values). For example, the initial NB increases with\nm at the expense of larger memory occupation and computa-\ntional loads. The plaintext modulus p is directly related to the\naccuracy of the HE processing. Despite being a very difﬁcult\nparameter to be tuned, the theory states that larger values of\np will produce more accurate results at the expense of larger\nreductions of the NB. Finally, the parameter q inﬂuences both\nthe initial NB and the level of security of the encryption. A\ndetailed description of the parameters and their effect on the\nHE scheme can be found in [12].\nWe emphasize that choosing the best parameter conﬁgu-\nration is a trade-off between accuracy and performance and\ndepends on the type and complexity of the processing, the\nset of feasible operations and the available computational\nresources. Practical guidelines to choose Θ will be given in\nSection IV-D.\nIII. RELATED LITERATURE\nThe idea of using HE to preserve the privacy of data during\nthe computation has been introduced in [13]. In this work, pri-\nvacy homomorphisms are deﬁned as encryption functions that\nallow one to operate on encrypted data without preliminarily\ndecrypting the operands [13]. The ﬁrst HE schemes allow only\nadditions [14], [15], [16], or multiplications [17].\nThe ﬁrst homomorphic encryption scheme allowing both\nmultiplication and additions has been proposed in [18]. There,\nthe idea was to rely on ideal lattice-based cryptography to pro-\nvide a scheme supporting additions and multiplications with\ntheoretically-grounded security guarantees. After that, [19]\nextended this work by relaxing the ideal lattice assumption\n(and its security), but allowing the usage of integer poly-\nnomial rings to deﬁne the cyphertexts. [10] introduces the\nBrakerski-Gentry-Vaikuntanathan (BGV) scheme that relies on\npolynomial rings to deﬁne the cyphertexts and on the learning\nwith error (LWE) and ring learning with errors (RLWE) prob-\nlems to provide theoretically-grounded security guarantees.\nThe RLWE problem is also the basis of the Brakerski/Fan-\nVercauteren (BFV) scheme [8], detailed in Section II, and the\nCheon-Kim-Kim-Song (CKKS) scheme [9], that extends the\npolynomial rings to the complex numbers and isometric rings.\nThe HE schemes mentioned above are theoretical and, to be\napplied, have then been implemented to speciﬁc processing\nchains. As regards deep learning solutions, CryptoNets [20]\nrelies on the HE BFV scheme to execute CNNs on encrypted\ninputs by introducing several possible ways of approximat-\ning the non-linear computation characterizing many layers\nof a CNN. Similarly, [21] provides a fast HE scheme for\nthe (discretized) CNN inference. Recently, the nGraph-HE\nframework [22] has been proposed. This framework allows\nto train CNNs in plaintext on a given hardware and deploy\ntrained models to HE cryptosystems operating on encrypted\ndata. Unfortunately, these works are speciﬁc of a given DL\nsolution (e.g., CNNs in [20]), whereas our architecture is\nmeant to be general-purpose and able to hide the complexity\nof adopting HE solutions, similarly to what proposed in [22],\nstill maintaining the as-a-service paradigm.\nThe literature presents also works aiming at offering en-\ncrypted computation. For example, [23] proposed the Secure\nMulti-Party Computation (SMC) approach, where more than\none actor (namely, a party) collaborate in computing a function\nand having only partial knowledge of the data they are working\non. These solutions do not encompass HE. [24] applied SMC\nwith the Pailler HE [16] to CNNs, where a party owns the data\nand another owns the CNN. Hence, both the data and CNN\nare kept secret during the computation. Other examples can be\nfound in [25], [26]. Finally, the Gazelle framework [27] relies\non SMC and HE, to provide low-latency inference for CNN.\nIV. THE PROPOSED ARCHITECTURE\nThe proposed privacy-preserving distributed architecture\nfor deep-learning-as-a-service, called HE-DL, is shown in\nFigure 1. More speciﬁcally, HE-DL relies on a distributed\napproach where the Encryption E (I, Θ, kp) of user data I\nand the Decryption D (ˆy, Θ, ks) of processed data ϕΘ(ˆI) are\ncarried out on the user device given the HE parameters Θ and\nwith the public key kp and secret key ks. Both E (·) and D (·)\nare based on HE-BFV scheme described in Section II.\nConversely, the deep learning processing ϕΘ(·) is carried\nout in the Cloud. This is a crucial step since deep learning\nprocessing is typically highly demanding in terms of com-\nputational load and memory occupation. We emphasize that,\nas commented in Section II, the considered deep-learning-as-\na-service computation has to be approximated by using only\naddition and multiplication in order to process the ciphertext\nˆI. For this reason, the set of deep-learning models DL models\nf (·)s that are made available by the Cloud are approximated\nthrough addition and multiplication, i.e., deﬁning the set of\napproximated DL models ϕ (·)s. Once approximated, ϕ (·)s\nhave to be encoded following the rule of the HE-BFV scheme\nto get the encoded deep-learning-as-a-service ϕΘ(·) by rely-\ning on the HE parameters Θ. This encoding phase converts\nplain values parameters of DL models in a form which can be\ncomputed by the HE-BFV scheme on encrypted inputs ˆI.\nThe DL models considered in this work are the CNNs\naiming at classifying the input images I into a class y ∈Y . In\nsuch a scenario the proposed HE-DL makes available the deep-\nlearning-as-a-service computing paradigm into two different\nmodalities:\n• recall: the processing ϕΘ(·) provides the encrypted ver-\nsion ˆy of the ﬁnal classiﬁcation y of I;\n• transfer learning: the processing ϕΘ(·) provides the en-\ncrypted version of a processing stage of the considered\nCNN applied to the input image I. The ﬁnal classiﬁcation\ny is carried out on the User Device thanks to a suitably-\ntrained classiﬁer (e.g., a Support Vector Machine or a\nneural based classiﬁer).\nThese two modalities will be detailed in the rest of the section,\ntogether with the description of the encryption/decryption\nphases, the approximation and encoding of CNNs, the conﬁg-\nuration of the encryption parameters and the communication\nbetween user device and Cloud.\nA. Encryption and Decryption\nLet P be a process generating images I ∈Rw×h×c of height\nh, width w and channels c and let Θ = {m, p, q} be the array\nof encryptions parameters, as deﬁned in Section II.\nThe encryption function E (I, Θ, kp) transforms (based on\nthe HE-BFV scheme) a plain image I into an encrypted image\nˆI given the HE encryption parameters Θ with the support of\na public key kp. The decryption function D(ˆy, Θ, ks) operates\non the encrypted output ˆy of the computation ϕΘ(ˆI), being ˆI\nthe encrypted image. More speciﬁcally, D(ˆy, Θ, ks) computes\nthe plain output y given the same set of parameters Θ and\nthe secret key ks (corresponding to kp). The semantic of y\ndepends on the considered working modality of HE-DL:\n• y is the classiﬁcation label of the input image I in the\nrecall modality;\n• y is an array of extracted features representing the values\nof the activation function of a given layer of the CNN in\nthe transfer learning modality.\nB. Approximated and encoded DL processing\nWe emphasize that the proposed architecture HE-DL is\ngeneral enough to employ a wide range of machine/deep\nlearning models. In this paper, we decided to focus on CNNs\nfor two main reasons. First, CNNs are widely-used and very-\neffective solutions for image classiﬁcations. Second, for most\nof their processing, CNNs are composed of addition and\nmultiplication operations making them suitable candidates to\nbe considered within a HE scheme.\nLet f (I) be a CNN composed of L layers η(l)\nθl\nwith\nparameters θl and l = 1, . . . , L, aimed at extracting features\nand providing the classiﬁcation output y of an input image I.\nThe general architecture of f (I) is shown in Figure 2a.\nAs mentioned above, in order to be used with HE, CNNs\nhave to be approximated by considering only computing layers\nand activation functions that are suitable for the considered\nHE-BFV scheme. Given that only addition and multiplication\nare permitted, only polynomials functions can be computed\ndirectly, while non-polynomials operations must be either\napproximated with a polynomial form or replaced with other\n(and permitted) types of operations. For instance, the ReLU\nactivation function is a non-polynomial operation, hence it\ncannot be considered in the HE scenario. Similarly to what\ndone in [20], in the proposed HE-DL architecture, we deﬁne\nDL Models\nEncoded Deep-Learning-as-a-Service\nI, kp\n̂I\ny\nApproximate DL Model\nEncoding HE Θ\nCloud\nUser Device\nHE DL\n-\nφΘ( ⋅)\nφ ( ⋅)\n̂y\nks\nEncrypt E(I, Θ, kp)\nDecrypt D( ̂y, Θ, ks)\nf ( ⋅)\nφΘ( ̂I )\nFig. 1. The proposed privacy-preserving architecture for deep-learning-as-a-\nservice.\nthe approximated CNN model ϕ (·) of the original CNN f (·)\nby considering the following rules:\n• the ReLU activation function is replaced with a Square\nactivation function that simply squares the input value;\n• the max-Pooling operator is replaced with the average\none, with the division converted to a multiplication by\n1\nfs ,\nwhere fs is the pooling size (ﬁxed and a-priori known).\n• Approximate the other non-polynomial layers as in [20].\nThe result of this approximation is a CNN ϕ (·) whose\nprocessing layers φ(l)\nˆθl\ncan be encoded with the considered\nHE-BFV scheme. To simplify the notation, the parameters of\neach layer θl or ˆθl are omitted from now on. It is important\nto note that, after performing the replacement of the non-\npolynomial layers, the model has to be trained again. This\nis necessary because the weights of the plain model are not\nvalid anymore if the activation functions or other layers have\nbeen replaced by different ones. Hence, to provide a deep-\nlearning-as-a-service, ϕ (·) must be retrained with the same\nsettings in which the plain one was trained (e.g., same dataset,\nsame learning algorithm, etc..). Obviously, if the original\nmodel f (·) already contains HE-compatible processing layers,\nthis procedure is not necessary. Moreover, it’s noteworthy\nthat this approximation process can introduce a variation in\nthe accuracy between f (·) and ϕ (·). This aspect will be\nexplored in the experimental section described in Section VI.\nWe emphasize that we considered (and made available to the\nscientiﬁc community) two already approximated and trained\nmodels, i.e., a 5-layers CNN and a 6-layers CNN trained on\nthe FashionMNIST data-set [28]; these models will be used\nin the experimental section.\nTo work with the encrypted images ˆIs, the suitably ap-\nproximated CNN ϕ must be encoded with the parameters Θ\nas deﬁned by the HE-BFV scheme leading to the encoded\nCNN ϕΘ(·). As shown in Figure 2b, the HE-based encrypted\nprocessing can be formalized as follows:\ny = D (ˆy, Θ, ks) = D (ϕΘ (E (I, Θ, kp)) , Θ, ks) ,\n(1)\nwhere ˆy represents the image I’s encrypted classiﬁcation.\nC. DL models: recall and transfer learning\nAs mentioned above, the deep-learning-as-a-service com-\nputing paradigm is made available in two different modalities,\nrecall and transfer learning. The difference between the two\nmodalities lies in how Eq. (1) is implemented. The former\noperates on the decrypted output y of the CNN ϕ last layer L\n(typically a softmax on top of a classiﬁcation layer), whereas\nthe latter one works on the features I˜l extracted at a given\nCNN level ˜l, with 1 ≤˜l < L (typically a convolutional or\npooling one). The two modalities are detailed in what follows.\nRecall: This is the modality where the user relies on one of\nthe ready-to-use encoded CNN ϕΘ(·)s to classify the image I.\nMore precisely, the user wants the image I to be encrypted into\nˆI and to be forwarded through all the layers of the encoded\nCNN ϕΘ, hence obtaining the ﬁnal result ˆy of the classiﬁcation\ntask, without transmitting the image I to the service provider.\nThe assumption underlying this modality is that the chosen\nmodel ϕΘ(·) is trained to classify images of the same domain\nof the input image I (e.g., the model ϕΘ(·) is trained to\nrecognize the digits and I is an image of a digit).\nTransfer Learning: When the application problem of the\nuser is not matched by the model ϕΘ(·)s (e.g., the user\nwants to distinguish between cars and bikes while available\nmodels have been trained to classify digits or faces), the\ntransfer learning modality comes into play. In fact, following\nthe transfer learning paradigm [29], [30], the processing of a\npre-trained CNN can be split into two parts: feature extraction\nand classiﬁcation. The feature extraction processing represents\na pre-trained feature extractor able to feed an ad-hoc classiﬁer\ntrained on the speciﬁc image classiﬁcation problem (that can\nbe different from the one originally used to train the CNN).\nThis allows to use part of a pre-trained CNN and train only a\nﬁnal classiﬁer (hence reducing the complexity for the training\nand the number of images required for the training.\nIn our scenario, the encrypted input images, ˆIs, will be\nforwarded through the encoded model ϕΘ up to a layer ˜l. More\nspeciﬁcally, ϕΘ comprises layers from 1 to ˜l, with 1 ≤˜l ≤L,\nwhereas all the (eventually) remaining layers, from ˜l+1 to the\nﬁnal one L remain plain and operate on the decrypted output\nof layer ˜l, i.e., I˜l = D\n\u0010\nϕ˜l\nΘ (E (I, Θ, kp)) , Θ, ks\n\u0011\n, where ϕ˜l\nΘ\nrepresents the encoded CNN up to layer ˜l with parameters\nΘ. The output of the model will be, in this case, the features\nextracted from every image I. The user may use these features\nto train a local classiﬁer (e.g., a Support Vector Machine); an\nexample will be shown in section VI.\nWe emphasize that, following such an approach, the user\nis able to locally train a classiﬁer on the decrypted vectors\ny = D (ˆy, Θ, ks), being ˆy the output of ϕΘ. A set of K\nimages {I1, . . . , IK} is sent to HE-DL providing the corre-\nsponding output {ˆy1, . . . , ˆyK} that are locally decrypted into\nI\nφ(1) (I)\nφ(2) \u0000I1\u0001\n. . .\nφ(L−1) \u0010\nIL−2\u0011\nφL \u0010\nIL−1\u0011\ny = ϕ (I)\nI1\nI2\nIL−2\nIL−1\nϕ (·)\n(a) The plain processing of an approximated CNN ϕ (·) composed of L layers. Each layer φl, with 1 ≤l ≤L is here composed only of\nmultiplications and/or additions. The difference w.r.t. the usual CNN-based classiﬁer f (·) relies only in these approximations. Note that also\nthe layers parameters θls, here omitted, may require to be approximated (and referred to as ˆθl) in the approximated CNN ϕ (·) .\nˆI\nφ(1)\nΘ\n\u0010\nˆI\n\u0011\nφ(2)\nΘ\n\u0010\nˆI1\u0011\n. . .\nφ(L−1)\nΘ\n\u0010\nˆIL−2\u0011\nφL\nΘ\n\u0010\nˆIL−1\u0011\nˆy = ϕΘ\n\u0010\nˆI\n\u0011\nˆI1\nˆI2\nˆIL−2\nˆIL−1\nϕΘ (·)\n(b) The encrypted processing of the CNN ϕΘ(·). The CNN is encoded with HE parameters Θ, operates on images ˆIs with the same\nparameters Θ and returns the encrypted classiﬁcation output ˆy.\nFig. 2. A comparison of the plain and approximated CNN processing with the encrypted one. The layers’ parameters θls are omitted to simplify the notation.\n{y1, . . . , yK}. The vector set {y1, . . . , yK} is used together\nwith the corresponding labels (that are available to the user)\nto locally train a classiﬁer. Once trained, the system is ready-\nto-use: the user can send an encrypted image ˆI to the Cloud,\nreceive the CNN output ˆy, decrypt it to y and apply the\nclassiﬁer on y.\nD. Encryption parameters\nAs already mentioned, the choice of Θ is critical to get cor-\nrect processing of the encrypted image ˆI. The choice for q is\nparticularly difﬁcult and inﬂuences the security of the scheme.\nFor this purpose SEAL library [31] provides a speciﬁc function\nthat, given the polynomial modulus degree m and the desired\nAES-equivalent security level (sec), returns a suggested value\nfor q [12]. In this work we considered sec equals to 128\nbits which is the default value of SEAL. Hence, we relied\non the SEAL function to automatically set the values of q to\nguarantee a 128 bits security level, while we selected m ∈\n{1024, 2048, 4096} and p ∈{32, 712, 37780, 1.3 · 105, 1.5 ·\n105, 2.6 · 105, 5.2 · 105, 6.0 · 105, 2.1 · 106, 1.3 · 108, 1.5 · 108},\nthrough an experimental analysis. The effects of the different\nchoices for Θ are shown in Section VI.\nE. Communication between User Device and Cloud\nThe communication between the User Device and the\nCloud is carried out through a JSON-format message. More\nspeciﬁcally, being an on-demand computation, clients have\nto perform a request to the on-line deep-learning-as-service\nprovider including:\n• a set of parameters, including the encryption parameters\nm and p, the security level sec, the identiﬁer of the chosen\nDL model ϕΘ(·) to use in the computation, and the\nspeciﬁc layers to use (which will determine the modality,\ni.e., recall or transfer learning);\n• the encrypted image ˆI on which the computation is\nperformed, which has to be encrypted using a public key\ngenerated according to the encryption parameters.\nInformation about the available models will be published\nby the provider. ˆI is transmitted as a vector in which the\nciphertexts are encoded as base64 strings making it possible\nto embed them into JSON ﬁles. Once the computation has\nbeen carried out, the Cloud responds with a JSON message\ncontaining the encrypted result vector.\nAs an example, if the user wants to classify a batch of 20\nimages from the FashionMNIST using Model1, the JSON will\ncontain [m = 2048, p = 600201, sec = 128], the details of the\nmodels (”model”=”Model1”, ”layers”= [0, 1, 2, 3, 4, 5, 6]) and\nthe encrypted image (a vector with dimensions [20, 1, 28, 28]).\nThe answer JSON message will contain the encrypted classi-\nﬁcation, so a vector of dimension [20, 10] of ciphertexts.\nV. IMPLEMENTATION\nThe architecture introduced in the previous section has\nbeen implemented through a Python library, named PyCrCNN,\ncomprising a client-side and a server application. PyCrCNN\nsupports the encryption and decryption of batches of integer or\nﬂoat values and the application of the common layers used in\nCNNs like convolutional layers, average pool layers, and fully\nconnected layers, relying on PyTorch library [32]. For the HE\noperations, PyCrCNN relies on the Pyfhel library v2.0.1 [33],\nLaurent (SAP) and Onen (EURECOM), licensed under the\nGNU GPL v3 license2.\nA. Client\nThe client-side can encrypt the input images Is and decrypt\nthe resulting answer ˆy in a transparent way with respect to the\nuser. Once the parameters are set (which include encryption\nparameters Θ, name and layers of the chosen model ϕ(·),\nserver URL and port), the client-side of PyCrCNN exposes\na function which receives I as a NumPy [34] vector and\nreturns y as a NumPy vector; this makes it compliant with\nmany machine learning frameworks for Python. Before starting\nthe computation, a public and secret key pair (kp, ks) is\ngenerated. The input batch is encrypted and encoded in base64\nstrings that will be included in the JSON payload along with\nthe parameters Θ (as described in the previous section). To\nperform the request, the JSON payload is uploaded to an\nAmazon S3 bucket. Then, a POST request containing the\naddress to the uploaded data is made to the deep-learning-as-\na-service URL and, once the reply ˆy is received, the resulting\nbatch is downloaded from the bucket and decrypted using the\nkey ks generated before. Finally, the user receives back the\ndecrypted value y as a NumPy array.\n2Pyfhel is a wrapper on the Microsoft SEAL library.\nCNN:\nPlain f (·)\nPlain Approximated ϕ (·)\nEncoded ϕΘ (·)\nΘ1 = {211, 1.3 · 105}\nΘ2 = {211, 1.5 · 105}\nΘ3 = {211, 6.0 · 105}\nΘ4 = {212, 1.5 · 108}\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\nEncryption Parameters Θ = (m, p)\nAccuracy\n(a) The results of the 6-layer CNN.\nΘ1 = {212, 2.6 · 105}\nΘ2 = {212, 5.2 · 105}\nΘ3 = {212, 2.1 · 106}\nΘ4 = {212, 1.3 · 108}\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\nEncryption Parameters Θ = (m, p)\nAccuracy\n(b) The results of the 5-layer CNN.\nFig. 3. The recall accuracy results of both the 6-layer CNN and the 5-layer CNN on the FashionMNIST dataset [28], with the standard deviation over ﬁve\nexperiments. For each considered encryption parameters Θi, three cases are compared: the plain CNN without approximations f (·), the same plain CNN\napproximated to have only additions and multiplications ϕ (·), and, ﬁnally, the encoded CNN with Θi, i.e., ϕΘi (·). It is noteworthy to point out that with\nencryption parameters Θi smaller (i.e., smaller m and p) than those shown, the accuracy quickly drops to that of a random classiﬁer.\nB. Server\nThe server side of the deep-learning-as-a-service must be\ninvoked via web API. For this purpose, we relied on a set of\nAmazon Web Services (AWS) tools comprising Sagemaker,\nElastic Container Registry (ECR), AWS Lambda, API Gate-\nway, and S3. More precisely, we extended the built-in models\noffered by Sagemaker with our own custom algorithm, i.e.,\nPyCrCNN, by creating a Docker container compliant with\nSagemaker Docker Images speciﬁcations, uploading it to ECR\nand deploying the model on Sagemaker. The Docker container\nuses NginX as a web server, Gunicorn as a WSGI and Flask,\na Python library, as a web framework to expose the APIs\nrequired by Sagemaker. With a mock ﬁt method we load\nand store the model to S3; with the actual predict method\nthe model performs the feature extraction task. Hence, the\nproposed deep-learning-as-a-service is made available through\na REST API: the client invokes the endpoint URL with a POST\nrequest whose JSON payload contains the S3 path to the image\nˆI encrypted by the client and the aforementioned encryption\nparameters Θ. In order to obtain a JSON-serializable payload,\nwe encode the encrypted image ˆI as a base64 string. The client\nreceives back the encrypted server response ˆy as a base64\nstring containing the extracted features.\nVI. EXPERIMENTAL RESULTS\nThe aim of this section is to evaluate the accuracy and\nthe computation load of the deep-learning-as-service provided\ntrough PyCrCNN both in recall and transfer learning modality.\nSection VI-A describes the CNNs provided by the deep-\nlearning-as-service, while Section VI-B details the considered\ndatasets. Accuracy and computational load on both recall and\ntransfer learning modality are shown in Sections VI-C, VI-D\nand VI-E.\nA. Description of the CNNs\nThe ﬁrst deep learning model is a 6-layer CNN composed\nby the following processing layers: a convolutional layer with\n8 3x3 ﬁlters, a 2x2 maximum pooling layer with stride 3, a\nconvolutional layer with 16 3x3 ﬁlters and stride 2, a 2x2\nmaximum pooling layer and two fully-connected layers with\n16 and 10 neurons respectively. The second deep learning\nmodel is a 5-layer CNN composed by a convolutional layer\nwith 16 3x3 ﬁlters with stride 3 and a ReLU activation\nfunction, a 3x3 maximum pooling layer with stride 3 and two\nfully connected layers with 72 and 10 neurons respectively.\nB. Datasets\nTwo datasets have been considered in the analysis:\n• MNIST [35] is a datasets of handwritten digits composed\nof 70000 grey-scale 28x28 images, belonging to 10\nclasses. From the datasets, 5000 images were used for\ntraining and 5000 for validation.\n• FashionMNIST [28] is a datasets of fashion products\ncomposed of 70000 grey-scale 28x28 images, belonging\nto 10 classes. From the datasets, 60000 images were used\nfor training and 10000 for validation.\nIn particular, the FashionMNIST dataset has been considered\nin the recall modality, while MNIST has been used in the\ntransfer learning one.\nC. Recall\nIn this modality a user wants to use a deep-learning-as-a-\nservice model ϕΘ(·) published by a Cloud service provider,\nobtaining the classiﬁcation y of an input image I. Figure 3a\nand 3b show the accuracy of the 6-layers CNN and the 5-layers\nCNN on the FashionMNIST dataset, respectively, with respect\nto different values of Θ (the parameter q has been omitted\nsince automatically set). The two CNNs in both the conﬁg-\nurations, plain and approximated, have been trained on the\nFashionMNIST training dataset for 20 epochs, with a learning\nrate of 0.001. As expected, the accuracy of the encoded model\nϕΘ(·) increases with m and p. In particular, the conﬁguration\nof parameters Θ4 (characterized by the largest values of m\nand p) provides the same performance of the approximated\nTABLE I\nTHE THREE DESCRIBED CONFIGURATIONS RESULTS, WITH A COMMON PC\nAS A CLIENT AND AN AMAZON EC2 INSTANCE AS A SERVER. THE MAIN\nRESULT, t, IS THE TIME REQUIRED TO PROCESS AN IMAGE FOR EACH\nSCENARIO. THE THREE COMPONENTS OF t ARE tc, THE TIME REQUIRED\nFOR THE LOCAL ENCRYPTION/DECRYPTION, tt, THE TIME FOR THE DATA\nTRANSFER AND ts, THE TIME REQUIRED FOR THE PROCESSING ON THE\nCLOUD. THE PROPOSED VALUES ARE EXPRESSED IN SECONDS.\ntc\ntt\nts\nt = tc + tt + ts\nRecall\n6-layers CNN\nΘ1\n2.2 ± 0.2\n3.7 ± 0.0\n11.8 ± 0.1\n17.7 ± 0.3\nΘ2\n2.2 ± 0.1\n3.7 ± 0.0\n11.9 ± 0.1\n17.8 ± 0.2\nΘ3\n2.1 ± 0.1\n3.7 ± 0.0\n11.9 ± 0.0\n17.7 ± 0.1\nΘ4\n4.7 ± 0.3\n14.7 ± 0.0\n49.7 ± 0.5\n69.1 ± 0.8\nRecall\n5-layers CNN\nΘ1\n5.2 ± 0.0\n14.7 ± 0.0\n26.2 ± 0.3\n46.1 ± 0.3\nΘ2\n5.2 ± 0.0\n14.7 ± 0.0\n26.1 ± 0.1\n46.0 ± 0.1\nΘ3\n5.2 ± 0.0\n14.7 ± 0.0\n25.8 ± 0.1\n45.7 ± 0.1\nΘ4\n5.2 ± 0.0\n14.7 ± 0.0\n25.8 ± 0.1\n45.7 ± 0.1\nTransfer\nLearning\nΘ1\n1.2 ± 0.0\n2.0 ± 0.0\n5.5 ± 0.0\n8.7 ± 0.0\nΘ2\n2.4 ± 0.1\n3.9 ± 0.0\n11.6 ± 0.1\n17.9 ± 0.2\nΘ3\n2.4 ± 0.0\n3.9 ± 0.0\n11.5 ± 0.0\n17.8 ± 0.0\nΘ4\n2.4 ± 0.0\n3.9 ± 0.0\n11.5 ± 0.0\n17.8 ± 0.0\nmodel ϕ (·) operating on plain data. It is noteworthy to point\nout that the 6-layers CNN (Figure 3a), when used plain, is\nindeed better than the 5-layers CNN (Figure 3b): in fact, the\nformer has higher accuracy than the latter. However, after\nthe approximation, the 5-layers CNN outperforms the 6-layers\nCNN. This suggests that the approximated CNN ϕ (·) could\nbe designed from scratch.\nD. Transfer learning\nIn this modality, the user relies on deep-learning-as-a-\nservice ϕΘ(·) as a feature extractor to train a local classiﬁer,\nas described in Section IV-C. Two types of classiﬁers have\nbeen used, i.e., an SVM-based classiﬁer and a Fully-Connected\nbased classiﬁer. Both classiﬁers have been trained using the\nfeatures extracted from images coming from the MNIST [35]\ndataset, using the ﬁrst 4 layers of the pre-trained 6-layers\nCNN. In particular, 5000 images were used for the training\nof the classiﬁers and 5000 for the testing. Figure\n4 shows\nthe accuracy of the SVM-based classiﬁer and Fully-Connected\nclassiﬁer. Different values for Θ show the impact on the\nprecision of the extracted features, hence the accuracy of\nthe trained classiﬁers. Here, two main comments arise. First,\nmoving from Θ3 to Θ4 (with a relevant increase in the\nparameter p) does not induce a signiﬁcant improvement in\nthe accuracy. This means that the value p = 37780 well\ncharacterizes the processing chain of ϕΘ(·). Secondly, Θ2 for\nthe 6-layers CNN in the recall scenario is equal to Θ4 in the\ntransfer learning scenario. However, in the latter case, this set\nof parameters provides enough NB and precision to carry out\nthe computations correctly, while in the former case it does\nnot. This can be explained by the fact that in this transfer\nBaselines:\nf (4) (·) + SVM\nϕ(4) (·) + SVM\nClassiﬁers:\nϕ(4)\nΘ (·) + SVM\nϕ(4)\nΘ (·) + FC\n0.75\n0.8\n0.85\n0.9\n0.95\nAccuracy\nΘ1 = {210, 32}\nΘ2 = {211, 712}\nΘ3 = {211, 37780}\nΘ4 = {211, 1.5 · 105}\n0.3\n0.35\n0.4\n0.45\nEncryption Parameters Θ = (m, p)\nFig. 4. The transfer learning accuracy results on the features extracted at layer\nl = 4 of the 6-layer CNN to the MNIST dataset [35]. For each considered\nencryption parameters Θi, four cases are compared: the plain CNN without\napproximations f(4) (·) with a SVM-based classiﬁer, the same plain CNN\napproximated to have only additions and multiplications ϕ(4) (·) with the\nSVM, and, the encoded CNN with Θi, i.e., ϕ(4)\nΘi (·) with either a SVM or a\nFully-Connected classiﬁer.\nlearning scenario the number of encoded layers is lower than\nin the recall one.\nE. Timing\nIn addition to the accuracy, we evaluated the performance\nof the proposed PyCrCNN implementation by measuring the\ncomputational times on the client and the server-side and by\nestimating the transmission times of exchange information. For\nthis purpose, we considered a single image taken from the\nFashionMNIST dataset for the recall modality and from the\nMNIST dataset for the transfer learning modality, in a single-\nthreaded scenario. The models ϕΘ(·) have been encoded with\nthe same Θ used for the analysis of the accuracy described\nabove.\nThe experimental results about the computational time are\nshown in Table I where\n• tc is the time spent on the client to generate the\nkeys couple (kp, ks), to execute the encryption function\nE (I, Θ, kp) and the decryption function D(ˆy, Θ, ks). The\nmachine used for the client is equipped with a 2.30GHz\n64-bit dual-core processor and 8192 MB of RAM.\n• ts is the time spent by the server to encode the model ϕ(·)\nand process the encrypted image, ϕΘ(ˆI). The machine\nused as a server is an Amazon EC2 instance with 72\n64-bit cores at 3.6GHz and 144 GIB of RAM.\n• tt estimates the transmission times of sending the en-\ncrypted image ˆI and receiving back the encrypted re-\nsult ˆy. For the transmission part we modeled an high-\nbandwidth scenario, where we employ the transmission\ntechnology Wi-Fi 4 (standard IEEE 802.11n) using a\nsingle-antenna with 64-QAM modulation on the 20 MHz\nchannel with he data-rate ρ = 72.2Mb/s [36].\nTwo main comments arise. First, as expected, all the three\ncomponent of the computational times increase with m. More\nspeciﬁcally, tc and ts increase due to the larger computational\nload required to process encrypted data with larger m, while\ntt increases due to the increase of the size of the ciphertexts.\nIn addition, tc is always lower than ts since E (I, Θ, kp) and\nD(ˆy, Θ, ks) are less computational demanding than ϕΘ(ˆI).\nSecond, an increase in p does not result in a variation of the\ncomputational times ts. All in all, p should be tuned focusing\non the accuracy of the results, while m must be tuned by\ntrading-off accuracy and computational load.\nVII. CONCLUSIONS\nThe\naim\nof\nthis\npaper\nwas\nto\nintroduce\na\nnovel\nprivacy-preserving distributed architecture for deep-learning-\nas-service. The proposed architecture, which relies on Ho-\nmomorphic Encryption, supports the Cloud-based processing\nof encrypted data to preserve the privacy of user data. The\nproposed architecture has been tailored to Convolutional Neu-\nral Networks and an implementation based on Python and\nAmazon AWS is made available. Experimental results show\nthe effectiveness of what proposed.\nFuture work will consider the automatic conﬁguration of\nthe Homomorphic Encryption parameters, the extension of the\ndeep learning models to deep recurrent neural networks and\noptimized client implementation for Internet-of-Things devices\n(characterized by constraints on computation and memory).\nACKNOWLEDGEMENT\nThis work has been partially supported by the project\n“GAUChO ” Project funded by MIUR under PRIN 2015.\nREFERENCES\n[1] Y. Yao, Z. Xiao, B. Wang, B. Viswanath et al., “Complexity vs.\nperformance: empirical analysis of machine learning as a service,” in\nProceedings of the 2017 Internet Measurement Conference.\nACM,\n2017, pp. 384–397.\n[2] M. S. Hossain and G. Muhammad, “Cloud-assisted speech and face\nrecognition framework for health monitoring,” Mobile Networks and\nApplications, vol. 20, no. 3, pp. 391–399, 2015.\n[3] T. Erl, R. Puttini, and Z. Mahmood, Cloud computing: concepts,\ntechnology & architecture.\nPearson Education, 2013.\n[4] E. P. Council of European Union, “Regulation (eu) no 2016/679, article\n4(1),” 2016.\n[5] A. Acar, H. Aksu, A. S. Uluagac, and M. Conti, “A survey on\nhomomorphic encryption schemes: Theory and implementation,” ACM\nComputing Surveys (CSUR), vol. 51, no. 4, p. 79, 2018.\n[6] Y. LeCun, Y. Bengio et al., “Convolutional networks for images, speech,\nand time series,” The handbook of brain theory and neural networks,\nvol. 3361, no. 10, p. 1995, 1995.\n[7] F. Boemer, Y. Lao, R. Cammarota, and C. Wierzynski, “ngraph-he: a\ngraph compiler for deep learning on homomorphically encrypted data,”\nin Proceedings of the 16th ACM International Conference on Computing\nFrontiers.\nACM, 2019, pp. 3–13.\n[8] J. Fan and F. Vercauteren, “Somewhat practical fully homomorphic\nencryption.” IACR Cryptology ePrint Archive, vol. 2012, p. 144, 2012.\n[9] J. H. Cheon, A. Kim, M. Kim, and Y. Song, “Homomorphic encryption\nfor arithmetic of approximate numbers,” in International Conference on\nthe Theory and Application of Cryptology and Information Security.\nSpringer, 2017, pp. 409–437.\n[10] Z. Brakerski, C. Gentry, and V. Vaikuntanathan, “(leveled) fully ho-\nmomorphic encryption without bootstrapping,” ACM Transactions on\nComputation Theory (TOCT), vol. 6, no. 3, p. 13, 2014.\n[11] V. Lyubashevsky, C. Peikert, and O. Regev, “On ideal lattices and\nlearning with errors over rings,” in Annual International Conference on\nthe Theory and Applications of Cryptographic Techniques.\nSpringer,\n2010, pp. 1–23.\n[12] K. Laine, “Simple encrypted arithmetic library 2.3.1,” Microsoft Re-\nsearch, WA, USA, Tech. Rep., 2017.\n[13] R. L. Rivest, L. Adleman, M. L. Dertouzos et al., “On data banks and\nprivacy homomorphisms,” Foundations of secure computation, vol. 4,\nno. 11, pp. 169–180, 1978.\n[14] D. Naccache and J. Stern, “A new public key cryptosystem based on\nhigher residues,” in ACM Conference on Computer and Communications\nSecurity.\nCiteseer, 1998, pp. 59–66.\n[15] T. Okamoto and S. Uchiyama, “A new public-key cryptosystem as secure\nas factoring,” in International conference on the theory and applications\nof cryptographic techniques.\nSpringer, 1998, pp. 308–318.\n[16] P. Paillier, “Public-key cryptosystems based on composite degree resid-\nuosity classes,” in International Conference on the Theory and Applica-\ntions of Cryptographic Techniques.\nSpringer, 1999, pp. 223–238.\n[17] T. ElGamal, “A public key cryptosystem and a signature scheme\nbased on discrete logarithms,” IEEE transactions on information theory,\nvol. 31, no. 4, pp. 469–472, 1985.\n[18] C. Gentry et al., “Fully homomorphic encryption using ideal lattices.”\nin Stoc, vol. 9, no. 2009, 2009, pp. 169–178.\n[19] M. Van Dijk, C. Gentry, S. Halevi, and V. Vaikuntanathan, “Fully\nhomomorphic encryption over the integers,” in Annual International\nConference on the Theory and Applications of Cryptographic Tech-\nniques.\nSpringer, 2010, pp. 24–43.\n[20] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter et al., “Cryptonets:\nApplying neural networks to encrypted data with high throughput and\naccuracy,” in International Conference on Machine Learning, 2016, pp.\n201–210.\n[21] F. Bourse, M. Minelli, M. Minihold, and P. Paillier, “Fast homomorphic\nevaluation of deep discretized neural networks,” in Annual International\nCryptology Conference.\nSpringer, 2018, pp. 483–512.\n[22] F. Boemer, A. Costache, R. Cammarota, and C. Wierzynski, “ngraph-\nhe2: A high-throughput framework for neural network inference on\nencrypted data,” in Proceedings of the 7th ACM Workshop on Encrypted\nComputing & Applied Homomorphic Cryptography, 2019, pp. 45–56.\n[23] A. C. Yao, “Protocols for secure computations,” in 23rd annual sympo-\nsium on foundations of computer science (sfcs 1982).\nIEEE, 1982, pp.\n160–164.\n[24] M. Barni, C. Orlandi, and A. Piva, “A privacy-preserving protocol for\nneural-network-based computation,” in Proceedings of the 8th workshop\non Multimedia and security.\nACM, 2006, pp. 146–151.\n[25] P. Mohassel and Y. Zhang, “Secureml: A system for scalable privacy-\npreserving machine learning,” in 2017 IEEE Symposium on Security and\nPrivacy (SP).\nIEEE, 2017, pp. 19–38.\n[26] B. D. Rouhani, M. S. Riazi, and F. Koushanfar, “Deepsecure: Scalable\nprovably-secure deep learning,” in Proceedings of the 55th Annual\nDesign Automation Conference.\nACM, 2018, p. 2.\n[27] C. Juvekar, V. Vaikuntanathan, and A. Chandrakasan, “{GAZELLE}: A\nlow latency framework for secure neural network inference,” in 27th\n{USENIX} Security Symposium ({USENIX} Security 18), 2018, pp.\n1651–1669.\n[28] H. Xiao, K. Rasul, and R. Vollgraf, “Fashion-mnist: a novel image\ndataset for benchmarking machine learning algorithms,” arXiv preprint\narXiv:1708.07747, 2017.\n[29] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are\nfeatures in deep neural networks?” in Advances in neural information\nprocessing systems, 2014, pp. 3320–3328.\n[30] C. Alippi, S. Disabato, and M. Roveri, “Moving convolutional neu-\nral networks to embedded systems: the alexnet and vgg-16 case,”\nin Proceedings of the 17th ACM/IEEE International Conference on\nInformation Processing in Sensor Networks.\nIEEE Press, 2018, pp.\n212–223.\n[31] “Microsoft SEAL,” https://github.com/Microsoft/SEAL, microsoft Re-\nsearch, Redmond, WA.\n[32] A. Paszke, S. Gross, F. Massa, A. Lerer et al., “Pytorch: An imperative\nstyle, high-performance deep learning library,” in Advances in Neural\nInformation Processing Systems, 2019, pp. 8024–8035.\n[33] M. O. Alberto Ibarrondo, Laurent Gomez, “Pyfhel: Python for homo-\nmorphic encryption libraries,” https://github.com/ibarrond/Pyfhel, 2018.\n[34] S. v. d. Walt, S. C. Colbert, and G. Varoquaux, “The numpy array: a\nstructure for efﬁcient numerical computation,” Computing in Science &\nEngineering, vol. 13, no. 2, pp. 22–30, 2011.\n[35] Y. LeCun, “The mnist database of handwritten digits,” http://yann. lecun.\ncom/exdb/mnist/, 1998.\n[36] Y. Xiao, “Ieee 802.11 n: enhancements for higher throughput in wireless\nlans,” IEEE Wireless Communications, vol. 12, no. 6, pp. 82–91, 2005.\n",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "published": "2020-03-30",
  "updated": "2020-03-30"
}