{
  "id": "http://arxiv.org/abs/2004.00503v1",
  "title": "Deep Learning Approach for Enhanced Cyber Threat Indicators in Twitter Stream",
  "authors": [
    "Simran K",
    "Prathiksha Balakrishna",
    "Vinayakumar R",
    "Soman KP"
  ],
  "abstract": "In recent days, the amount of Cyber Security text data shared via social\nmedia resources mainly Twitter has increased. An accurate analysis of this data\ncan help to develop cyber threat situational awareness framework for a cyber\nthreat. This work proposes a deep learning based approach for tweet data\nanalysis. To convert the tweets into numerical representations, various text\nrepresentations are employed. These features are feed into deep learning\narchitecture for optimal feature extraction as well as classification. Various\nhyperparameter tuning approaches are used for identifying optimal text\nrepresentation method as well as optimal network parameters and network\nstructures for deep learning models. For comparative analysis, the classical\ntext representation method with classical machine learning algorithm is\nemployed. From the detailed analysis of experiments, we found that the deep\nlearning architecture with advanced text representation methods performed\nbetter than the classical text representation and classical machine learning\nalgorithms. The primary reason for this is that the advanced text\nrepresentation methods have the capability to learn sequential properties which\nexist among the textual data and deep learning architectures learns the optimal\nfeatures along with decreasing the feature size.",
  "text": "Deep Learning Approach for Enhanced Cyber\nThreat Indicators in Twitter Stream\nSimran K1, Prathiksha Balakrishna2, Vinayakumar R3,1, and Soman KP1\n1 Center for Computational Engineering and Networking, Amrita School Of\nEngineering, Amrita vishwa vidyapeetham, Coimbatore, India.\nsimiketha19@gmail.com\n2 Graduate School, Computer Science Department,\nTexas State University. prathi.93april8@gmail.com\n3 Division of Biomedical Informatics, Cincinnati Children’s Hospital Medical Centre,\nCincinnati, OH, United States.\nVinayakumar.Ravi@cchmc.org, vinayakumarr77@gmail.com\nAbstract. In recent days, the amount of Cyber Security text data shared\nvia social media resources mainly Twitter has increased. An accurate\nanalysis of this data can help to develop cyber threat situational aware-\nness framework for a cyber threat. This work proposes a deep learn-\ning based approach for tweet data analysis. To convert the tweets into\nnumerical representations, various text representations are employed.\nThese features are feed into deep learning architecture for optimal fea-\nture extraction as well as classiﬁcation. Various hyperparameter tuning\napproaches are used for identifying optimal text representation method\nas well as optimal network parameters and network structures for deep\nlearning models. For comparative analysis, the classical text represen-\ntation method with classical machine learning algorithm is employed.\nFrom the detailed analysis of experiments, we found that the deep learn-\ning architecture with advanced text representation methods performed\nbetter than the classical text representation and classical machine learn-\ning algorithms. The primary reason for this is that the advanced text\nrepresentation methods have the capability to learn sequential proper-\nties which exist among the textual data and deep learning architectures\nlearns the optimal features along with decreasing the feature size.\nKeywords: Information Extraction · Twitter · Cyber Security · Deep\nlearning.\n1\nIntroduction\nAs social media is an interactive platform where individuals share thoughts,\ninformation, professional interests and diﬀerent types of expression via virtual\ncommunities and systems, it introduces a rich and timely source of informa-\ntion on events occurring everywhere throughout the world [13]. Social media\ngiants like Facebook, Twitter, WhatsApp, etc enable a lot of applications like\nrecognizing the area of missing people during catastrophic events or earthquake\narXiv:2004.00503v1  [cs.CL]  31 Mar 2020\n2\nSimran et al.\ndetection. Past work on event extraction has depended on a large amount of\nlabeled information or taken an open-domain approach in which general events\nare extracted without a particular core interest. Information analyst is often in-\nterested in tracking a very speciﬁc type of event, for example, data breaches or\naccount hijacking and probably won’t have time or expertise to build an infor-\nmation extraction framework from scratch in response to emerging incidents. To\naddress this challenge we introduce a deep learning approach for rapid training\ncyber threat indicators for the Twitter stream.\nOpen-Source Intelligence (OSINT) provides a vital source of information and\nhas proven to be an important asset for Cyber Threat Intelligence (CTI). One of\nOSINT rich sources is Twitter. Twitter’s popularity in the society provides an\nenvironment for defensive and oﬀensive Cyber Security practitioners to debate,\nand promote timely indicators of diﬀerent type of cyber events such as attacks,\nmalware, vulnerabilities, etc. Various initial reports of recent major cyber events\nlike the exposure of multiple “0-day”Microsoft Windows vulnerabilities, exposure\nof ransomware campaigns [1] and user reports on DDoS attacks [2] exhibits the\nvalue of Twitter data to CTI analysts.\nMultiple frameworks for detecting as well as analysing the treat indicators in\nTwitter stream have come from the research on Twitter-based OSINT collection.\nHowever, most of these proposals have a high false-positive rate in detecting the\nrelevant tweets as they are using heavily manual heuristics like keyword lists that\nare relevant to Cyber Security are used to detect and ﬁlter tweets. Furthermore,\npotentially valuable information in tweets is getting neglected by the emergence\nof new terminology and ﬂexible typography. In recent days, the applications of\ndeep learning with natural language processing methods leveraged in various Cy-\nber Security tasks [13,14,15,16,17,18,19,20]. These methods have obtained good\nperformance and most importantly, these methods performed well compared to\nthe classical machine learning classiﬁers.\nThe major contribution of this proposed work are given below:\n1. This work proposes a deep learning based framework for cyber threat in-\ndicators in the Twitter stream. The framework is highly scalable on using\ncommodity hardware.\n2. To identify a proper tweet representation, various state-of-the-art text rep-\nresentation exists in the domain of natural language processing (NLP) are\nleveraged for cyber threat indicators in Twitter Stream.\n3. To identify an optimal machine learning approach, we have carried out a\ncomprehensive and in-depth study of the application of classical machine\nlearning and deep learning theory in the context of cyber threat indicators\nin Twitter stream.\n4. In particular, we discuss several parameterization options for classical ma-\nchine learning, deep learning, and tweet representation and we present a\nlarge variety of benchmarks which have been used to either experimentally\nvalidate our choices or to help us to take the adequate decision.\nThe remaining of this paper is arranged in the following order: Section 2\ndocuments a survey of the related literature, followed by background related to\nDeep Learning based Cyber Threat Indicators in Twitter\n3\nNLP and deep learning concepts in Section 3. Section 4 provides a description\nof Cyber Security related tweets data set used in this work. Section 5 describes\nthe details of the proposed architecture. Section 6 reports the experiments and\nobservations made by the proposed architecture. Section 7 concludes the paper\nas well as tells the remakes on future work of research.\n2\nLiterature Survey\nClassiﬁcation and detection of CTI extraction from Twitter are less investigated\ncompared to the other area, for example, crime prevention [3], identiﬁcation of\ncyber-bullies [4], and disaster response [5]. To distinguish three sorts of threats\nand events ie., account hijacking, data breaches, and Distributed Denial of Ser-\nvice (DDoS) attacks, Khandpur et al. [6] proposed an architecture to separate\ncyber threat as well as security information from the Tweets. Target domain gen-\neration, event extraction, and dynamically typed query expansion are the three\nmajor segments of this framework. This methodology is powerful as it abuses\nsyntactic, semantic analysis and dependency tree graph yet it requires the per-\nsistent tracking of features for each type of threat. It likewise requests a high\ncomputational overhead to produce as well as keep the focus on corpus space of\ntweet content for query extension. Also, this architecture can’t ﬂawlessly stretch\nout to more classiﬁcations of threats and events.\nFurthermore, categorizing Cyber Security events from tweets was proposed\nby Le Sceller et al. [7]. The detection of events uses the taxonomy of Cyber\nSecurity and a set of keywords that describes the event type. Expanding of the\nset of seed keywords are performed by not only identifying but also attaching new\nwords with comparative meaning with regards to word embeddings utilizing a\nphysically indicated edge in the cosine similarity distance between word vectors.\nTerm frequency - inverse document frequency (TF-IDF) method which produced\nevents as groups of tweets was used in this framework. Inadvertent biasing eﬀects\nof the initial seed keywords caused this algorithm to give a high false-positive\nrate.\nSecurity Vulnerability Concept Extractor (SVCE) was utilized to process\ntweets in the structure proposed in [8]. SVSE is trained on a data set containing\nreports of the national vulnerability database to recognize as well as label the\nterms and ideas identiﬁed with CTI, for example, aﬀected software, consequences\nof the attack and so forth. To additionally improve the extracted information,\nthe ideas and substances extracted by SVCE are examined dependent on out-\nside freely accessible semantic learning bases such as DBPedia. The client needs\nto specify a target framework proﬁle included data about installed software or\nhardware, as this system is produced for client-based applications. As per the\ninformation provided, an ontology is produced and utilized alongside SWRL\nrules to address as well as organize time-delicate CTI entries. Later conversion\nfrom separated and labeled CTIs to RDF triple proclamations is ﬁnished. The\nready alert system can reason over the information as RDF connected informa-\n4\nSimran et al.\ntion portrayal is put away in the knowledge base. This framework is incapable\nof distinguishing novel threat types and indicators.\nIn [9], ontology-based technique and Named Entity Recognition (NER) were\nutilized to classify tweets as related events or not related events. This framework\nperforms topic identiﬁcation by means of cross-referencing NER results with\nother external knowledge bases, for example, DBPedia utilizing Wikipedias Cur-\nrent Event Portal just as human info gathered using Amazon Mechanical Turk,\nproduced an annotated data set of tweet event type and CTI. Diﬀerent machine\nlearning algorithms, for example, naive bayes, support vector machines (SVM)\nand deep learning architectures such as long short term memory (LSTM), recur-\nrent neural network (RNN) used this annotated data set and the best outcome\nwas delivered by LSTM architecture with word embedding. They additionally\nshow that particular classiﬁcations of NER are useful in classifying the classes\nas well as event type, though the nonexclusive class of NER is useful in binary\nclassiﬁcation. Pagerank algorithm was used in this work for topic recognizable\nproof.\n[10] proposed a framework which recognizes inﬂuential user or community\nof people to prioritize CTI information. This was ﬁnished utilizing a scoring\nstrategy that is scores were given to the user and community who produced CTI-\nrelated tweets. This work has four segments. For gathering information from the\nTwitter platform, a social media connector is referred as the principal segment.\nThe second segment is a module for recognizing and stretching out the rundown\nof specialists to discover developing themes. The third segment comprises of\nweight contribution and ﬁtness calculation. Lastly, to recognize emerging threats\nthe author proposed a topic detection algorithm. Anyhow, threat indicators are\nnot adequately referred by the specialists in this work.\nThe framework proposed in [11] is a weekly supervised learning approach\nthat trains a model for extracting new classes of Cyber Security events. This\nframework does extraction by seeding a little amount of positive event tests over\na fundamentally amount of unlabeled data. The target to learn in this work is\ndone by regularizing the label distribution over the unlabeled distribution. This\nwork is vigorously reliant on historical seed and neglects to give the details of\ncoordinating named entities into an event category.\n3\nBackground\n3.1\nText representation\nTo represent the tweet into numeric form, we used various text representations in\nthis works. The basic idea behind these text representations is discussed below.\nBag-of-Words (TDM, TF-IDF): Bag-of-words is basically a collection of\nwords. So the texts (tweets) are represented as a bag of its words. Every unique\nword passed as an input will have a position in this bag (vector). The vec-\ntor records the frequency of the words in the tweets. Term document matrix\nDeep Learning based Cyber Threat Indicators in Twitter\n5\n(TDM) and Term frequency-inverse document frequency (TF-IDF) are features\nextracted from the documents. They are the measures used to understand the\nsimilarities between the tweets. TDM will have each corpus word as rows and\ndocument (tweet) as columns. The matrix represents the frequencies of the words\noccurring in that particular tweet. The most used words are highlighted because\nof their high frequency. TF-IDF tells how frequently a word occurs in a speciﬁc\nrecord contrasted with the whole corpus. The uncommon words are featured to\ndemonstrate their relative signiﬁcance.\nN-gram: N-gram is a contiguous order of n items from a given sample of\ncontent (tweets). N-gram with N = 1 is known as a unigram and it takes\none word/character at once. N = 2 and N = 3 are called bigram and tri-\ngram respectively and will take two and three words/characters at a time. If n\nwords/characters are to be taken at once then N will be equal to n.\nKeras Embedding: Word Embedding basically converts words into a dense\nvector of real numbers in such a way that sequence and word similarities are\nadditionally safeguarded. Keras oﬀers an Embedding layer which is initialized\nwith random weights. It will learn embedding of all the words in the training\nset but the input word should be represented by a unique integer. Keras is an\nopen-source neural network library which contains various executions of gen-\nerally utilized neural network building blocks. It also supports convolutional,\nrecurrent neural networks and other common utility layers like pooling, batch\nnormalization, and dropout.\nfastText: fastText chips away at character n-gram level instead of just word\nlevel (word2vec) and it is better for morphologically rich dialects. To convert\nwords into vectors it utilizes skip-gram and subword model. Given the present\nword, skip-gram model predicts the surrounding words. In the event that window\nsize is 2, at that point we see just 5 vectors at once. The subword model will\nsee the internal structure of the words. In this model n-grams per word are\nextracted. For example, her will have distinctive vector and n-gram her from the\nword where will have a diﬀerent vector.\n3.2\nDeep learning\nTo understand which deep learning approach works for enhanced cyber threat\nindicators in the Twitter stream, we used various deep learning architectures.\nThe basic idea behind diﬀerent deep learning approaches is given below.\nDeep Neural Network: A deep neural network (DNN) is a neural network\nwith multiple layers which makes it somewhat mind-boggling. DNN contains\none input layer, at least one hidden layer, and one output layer. Each hidden\nlayer contains a rectiﬁed linear unit (ReLU). ReLU is an activation function\n6\nSimran et al.\nwhich characterized the positive piece of its argument. It has less vanishing\ngradient problems and computationally eﬃcient. Hidden layer is also called a\nfully connected layer since every neuron in one layer is associated with every\nneuron in the following layer.\nConvolutional Neural Network: A convolutional neural network (CNN) oth-\nerwise called ConvNet is a deep neural network which is based on shared-loads\narchitecture. It lessens the number of free parameters enabling the network to\nbe deeper with fewer parameters. Generally, CNN architecture contains convolu-\ntion, pooling, and fully connected layers. The convolution operation is performed\nusing a number of ﬁlters which slide through the input and learns the features of\nthe input data. Pooling layer is used to decrease the size of the feature matrix.\nThe pooling can be min, max, or average. At the end of the CNN, there will\nbe at least one fully connected layer where all the neurons are connected to all\nthe neurons of its previous layer. Also in between these layers batchnomraliza-\ntion and dropout can be used. Batch normalization layer allows the network to\nlearn by itself a little bit more independently of other layers and in turn reduces\noverﬁtting as it has slight regularization eﬀects. Dropout is a regularization tech-\nnique in which some neurons are randomly ignored during training the model.\nThis method is treated like a layer and makes neural networks with diﬀerent\narchitectures to train in parallel.\nRecurrent Structures (RNN, LSTM, GRU): A recurrent neural network\n(RNN) is a recurrent structure where associations between nodes form a directed\ngraph along a sequence. This enables RNN to display temporal dynamic behavior\nfor a time sequence that is applied to natural language processing (NLP). RNNs\ncan utilize their internal state to process arrangements of inputs yet can do it\nfor just a short amount of time i.e., they can not remember long term data.\nLong short-term memory (LSTM) network is another recurrent structure\nthat contains a cell, and three gates namely, input, output, and forget gate. A\ncell recalls esteems over discretionary time intervals and the three gates direct\nthe stream of data in and out of the cell. This makes LSTM remember long\nterm information. LSTMs were created to manage the vanishing and exploding\ngradient problems that can be experienced when training conventional RNNs.\nGated recurrent unit (GRU) is an enhanced version of standard RNN and\nis also considered as a minor variation from LSTM. To tackle the disappearing\ngradient problem of a standard RNN, GRU utilizes update gate and reset gate.\nThese two vectors choose what information ought to be passed to the output.\nThey are exceptional in light of the fact that they can be trained to keep in-\nformation from a long prior time, without washing it through time or evacuate\ninformation which is superﬂuous to the expectation.\nDeep Learning based Cyber Threat Indicators in Twitter\n7\n4\nDescription of the Data set\nThe data set for data analysis of tweets from Twitter social media resource is\nprovided by [12]. The authors used a stream listener to listen to the streaming of\ntweets from Twitter. They selected a set of keywords in order to ﬁlter as well as\nnarrow down the results of the stream listener. The words like “0day” and “vul-\nnerability” were selected for applicability to CTI. For producing more targeted\nﬁlters, words related to a particular type of threat were selected. Preprocessing\nof the data set is also performed in [12]. The detailed statistics are tabulated in\nTable 1 and 2.\nTable 1. Binary class Twitter data samples.\nData set Relevant Irrelevant\nTrain\n11,781\n5,313\nTest\n2,989\n1,285\nTable 2. Multiclass Twitter data samples.\nCategory\nTrain data set Test data set\nVulnerability\n5,926\n1,428\nRansomware\n2,549\n654\nDDoS\n1,776\n469\nData leak\n106\n30\nGeneral\n5,588\n1,410\nDay\n585\n145\nBotnet\n564\n138\n5\nProposed Architecture\nThe proposed architecture is shown in Figure 1. The preprocessed tweets are\nsent to Keras embedding layer where the words are converted into dense vectors.\nThese numerical features are passed into CNN and then to GRU layer for feature\ngeneration. Finally, the output from GRU is sent to a fully connected layer for\nclassiﬁcation.\n8\nSimran et al.\nFig. 1. Proposed Architecture.\n6\nExperiments, Results and Observations\nScikit-learn4 and TensorFlow5 with Keras6 framework were utilized to imple-\nment classical machine learning algorithms and deep learning architectures re-\nspectively. All the models are trained on GPU enabled TensorFlow. Various\nstatistical measures are utilized in order to evaluate the performance of the pro-\nposed framework.\nPreprocessing steps given in the proposed architecture section is followed for\nthe data set to convert the unstructured format into a structured format. In this\nwork, various text representation methods such as TDM, TF-IDF, 3-gram, and\nembedding are employed. SVM is implemented along with TDM and TF-IDF.\nSVM uses rbf kernel and c value of 100. Scikit-learn default parameters of TDM\nand TF-IDF are used. As the tweet length is not huge and there are a lot of\nimportant keywords used in tweets that might be the reason why TF-IDF has\nperformed better than TDM. We followed n-gram representation speciﬁcally 3-\ngram is employed and we constructed a feature vector whose length will very\nhuge. So in order to decrease the dimension be employed featurization technique\nto decrease the length of the sequence. This 1,000 length vector is passed into a\ndeep neural network (DNN). DNN contains three layers, the ﬁrst layer contains\n1,024 neurons, the second layer contains 512 neurons and the third layer contains\n128 neurons. In a sequential model, initially random weights are given to the\nmodel and these random values will be updated based on the loss of the function\nwhile backpropagation. When Keras embedding is employed along with the deep\n4 https://scikit-learn.org/\n5 https://www.tensorﬂow.org/\n6 https://keras.io/\nDeep Learning based Cyber Threat Indicators in Twitter\n9\nTable 3. Average performance metrics.\nModel\nAccuracy (%) Precision (%) Recall (%) F1-Score (%)\nBinary class classiﬁcation\nSVM-TDM\n81.9\n68.8\n72.8\n70.7\nSVM-TF-IDF\n82.2\n69.2\n73.6\n71.3\nDNN-3gram\n82.9\n73.5\n67.6\n70.4\nCNN-Keras word embedding [12]\n83.6\n71.4\n75.9\n73.6\nRNN-Keras word embedding\n83.1\n71.7\n72.1\n71.9\nLSTM-Keras word embedding\n84.3\n70.1\n83.1\n76.0\nGRU-Keras word embedding\n84.7\n73.9\n76.0\n74.9\nCNN-GRU-Keras word embedding 85.8\n73.7\n82.3\n77.8\nfastText\n84.4\n74.6\n73.2\n73.9\nMulticlass classiﬁcation\nSVM-TDM\n86.2\n86.2\n86.2\n86.2\nSVM-TF-IDF\n86.3\n86.4\n86.3\n86.3\nDNN-3gram\n86.9\n87.0\n86.9\n86.9\nCNN-Keras word embedding [12]\n87.5\n87.8\n87.5\n87.6\nRNN-Keras word embedding\n87.0\n87.1\n87.0\n87.0\nLSTM-Keras word embedding\n88.0\n88.1\n88.0\n88.0\nGRU-Keras word embedding\n88.4\n88.8\n88.4\n88.5\nCNN-GRU-Keras word embedding 89.3\n90.3\n89.3\n89.3\nfastText\n87.9\n88.0\n87.9\n87.9\nlearning model, updation of weight will take place upto the embedding layer\nduring backpropogation and not just stop at the deep neural layers. Since the\ndata set is not huge, word embedding like word2vec is not followed in this work.\nVarious deep learning classiﬁers like CNN, RNN, LSTM, GRU, CNN-GRU are\nused along with Keras word embedding in order to ﬁnd the best deep learning\nmodel. Embedding size of 128, batch-size of 32, learning rate of 0.01, 128 hidden\nunits, and Adam optimizer are hyperparameter value used by RNN, LSTM,\nGRU, CNN, and CNN-GRU classiﬁers. The output layer consists of 1 neuron\nin binary classiﬁcation and 7 neurons for multiclass classiﬁcation. In CNN, the\nnumber of ﬁlters used is 64 and the ﬁlter length is 3. In CNN-GRU as well as\nGRU, the number of hidden units used is 50. Finally, fastText is employed as\nfastText has given better performance in recent day applications. The value of\nparameters for fastText are learning rate of 0.1, dimension of 128, minimum\nword count of 1, 100 epochs, and 2 N-grams. The average performance metrics\nof all the models for binary and multiclass data set are reported in Table 3.\nAmong all, CNN-GRU along with Keras word embedding has performed better\n10\nSimran et al.\nin both binary and multiclass classiﬁcation. For all the models, the training data\nset is used for training the models and testing data set is used to test the trained\nmodels.\n7\nConclusion and Future Work\nTwitter is one of the most popular social networks, where users share their\nopinions on various topics. The tweet could be related to security. This work\nevaluates the performance of various text representation techniques along with\nvarious deep learning models for cyber threat indicators in the Twitter stream.\nCNN-GRU with Keras embedding performed better than any other architecture\nin both binary as well as multiclass classiﬁcation. The best part about the pro-\nposed architecture is that it does not require any feature engineering technique\nto be employed. Present and future work focus on event tracking and event\ndetection of cyber threats using social media resources like Twitter, Facebook,\netc.\nAcknowledgements\nThis research was supported in part by Paramount Computer Systems and\nLakhshya Cyber Security Labs. We are grateful to NVIDIA India, for the GPU\nhardware support to research grant. We are also grateful to Computational En-\ngineering and Networking (CEN) department for encouraging the research.\nReferences\n1. A. Sapienza, A. Bessi, S. Damodaran, P. Shakarian, K. Lerman, and E. Ferrara,\nEarly warnings of cyber threats in online discussions, in Data Mining Workshops\n(ICDMW), 2017 IEEE International Conference on. IEEE, 2017, pp. 667674\n2. C. Sabottke, O. Suciu, and T. Dumitras, Vulnerability disclosure in the age of\nsocial media: Exploiting twitter for predicting real-world exploits. in USENIX\nSecurity Symposium, 2015, pp. 10411056.\n3. T. Mackey, J. Kalyanam, J. Klugman, E. Kuzmenko, and R. Gupta, Solution to\ndetect, classify, and report illicit online marketing and sales of controlled sub-\nstances via twitter: Using machine learning and web forensics to combat digital\nopioid access, Journal of medical Internet research, vol. 20, no. 4, 2018.\n4. P. Galan-Garca, J. G. d. l. Puerta, C. L. Gomez, I. Santos, and P. G. Bringas,\nSupervised machine learning for the detection of troll proﬁles in twitter social\nnetwork: Application to a real case of cyberbullying, Logic Journal of the IGPL,\nvol. 24, no. 1, pp. 4253, 2016.\n5. Z. Ashktorab, C. Brown, M. Nandi, and A. Culotta, Tweedr: Mining twitter to\ninform disaster response. in ISCRAM, 2014.\n6. R. P. Khandpur, T. Ji, S. Jan, G. Wang, C.-T. Lu, and N. Ramakrishnan, Crowd-\nsourcing cybersecurity: Cyber attack detection using social media, in Proceedings\nof the 2017 ACM on Conference on Information and Knowledge Management.\nACM, 2017, pp. 1049 1057.\nDeep Learning based Cyber Threat Indicators in Twitter\n11\n7. Q. Le Sceller, E. B. Karbab, M. Debbabi, and F. Iqbal, Sonar: Automatic detec-\ntion of cyber security events over the twitter stream, in Proceedings of the 12th\nInternational Conference on Availability, Reliability and Security. ACM, 2017, p.\n23.\n8. S. Mittal, P. K. Das, V. Mulwad, A. Joshi, and T. Finin, Cybertwitter: Using twit-\nter to generate alerts for cybersecurity threats and vulnerabilities, in Proceedings\nof the 2016 IEEE/ACM International Conference on Advances in Social Networks\nAnalysis and Mining. IEEE Press, 2016, pp. 860867.\n9. A. Edouard, Event detection and analysis on short text messages, Ph.D. disserta-\ntion, Universite CotedAzur, 2017.\n10. K.-C. Lee, C.-H. Hsieh, L.-J. Wei, C.-H. Mao, J.- H. Dai, and Y.-T. Kuang, Sec-\nbuzzer: cyber security emerging topic mining with open threat intelligence retrieval\nand timeline event annotation, Soft Computing, vol. 21, no. 11, pp. 28832896, 2017.\n11. A. Ritter, E. Wright, W. Casey, and T. Mitchell, Weakly supervised extraction\nof computer security events from twitter, in Proceedings of the 24th Interna-\ntional Conference on World Wide Web. International World Wide Web Confer-\nences Steering Committee, 2015, pp. 896905.\n12. Behzadan, V., Aguirre, C., Bose, A., & Hsu, W. (2018). Corpus and Deep Learning\nClassiﬁer for Collection of Cyber Threat Indicators in Twitter Stream. 2018 IEEE\nInternational Conference on Big Data (Big Data), 5002-5007.\n13. Vinayakumar, R., Alazab, M., Jolfaei, A., Soman, K. P., & Poornachandran, P.\n(2019, May). Ransomware triage using deep learning: twitter as a case study. In\n2019 Cybersecurity and Cyberforensics Conference (CCC) (pp. 67-73). IEEE.\n14. Vinayakumar, R., Soman, K. P., Poornachandran, P., & Menon, V. K. (2019).\nA Deep-dive on Machine Learning for Cyber Security Use Cases. In Machine\nLearning for Computer and Cyber Security (pp. 122-158). CRC Press.\n15. Vinayakumar, R., Soman, K. P., Poornachandran, P., Alazab, M., & Jolfaei, A.\n(2019). DBD: Deep Learning DGA-Based Botnet Detection. In Deep Learning\nApplications for Cyber Security (pp. 127-149). Springer, Cham.\n16. Vinayakumar, R., Soman, K. P., Poornachandran, P., Akarsh, S., & Elhoseny,\nM. (2019). Deep Learning Framework for Cyber Threat Situational Awareness\nBased on Email and URL Data Analysis. In Cybersecurity and Secure Information\nSystems (pp. 87-124). Springer, Cham.\n17. Vinayakumar, R., Soman, K. P., Poornachandran, P., Akarsh, S., & Elhoseny, M.\n(2019). Improved DGA Domain Names Detection and Categorization Using Deep\nLearning Architectures with Classical Machine Learning Algorithms. In Cyberse-\ncurity and Secure Information Systems (pp. 161-192). Springer, Cham.\n18. Vinayakumar, R., Alazab, M., Srinivasan, S., Pham, Q. V., Padannayil, S. K., &\nSimran, K. (2020). A Visualized Botnet Detection System based Deep Learning for\nthe Internet of Things Networks of Smart Cities. IEEE Transactions on Industry\nApplications.\n19. Vinayakumar, R., Alazab, M., Soman, K. P., Poornachandran, P., & Venkatraman,\nS. (2019). Robust intelligent malware detection using deep learning. IEEE Access,\n7, 46717-46738.\n20. Vinayakumar, R., & Soman, K. P. (2020). Siamese neural network architecture\nfor homoglyph attacks detection. ICT Express, 6(1), 16-19.\n",
  "categories": [
    "cs.CL",
    "cs.CR",
    "cs.LG",
    "cs.NE",
    "cs.SI"
  ],
  "published": "2020-03-31",
  "updated": "2020-03-31"
}