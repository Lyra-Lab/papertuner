{
  "id": "http://arxiv.org/abs/2004.10151v3",
  "title": "Experience Grounds Language",
  "authors": [
    "Yonatan Bisk",
    "Ari Holtzman",
    "Jesse Thomason",
    "Jacob Andreas",
    "Yoshua Bengio",
    "Joyce Chai",
    "Mirella Lapata",
    "Angeliki Lazaridou",
    "Jonathan May",
    "Aleksandr Nisnevich",
    "Nicolas Pinto",
    "Joseph Turian"
  ],
  "abstract": "Language understanding research is held back by a failure to relate language\nto the physical world it describes and to the social interactions it\nfacilitates. Despite the incredible effectiveness of language processing models\nto tackle tasks after being trained on text alone, successful linguistic\ncommunication relies on a shared experience of the world. It is this shared\nexperience that makes utterances meaningful.\n  Natural language processing is a diverse field, and progress throughout its\ndevelopment has come from new representational theories, modeling techniques,\ndata collection paradigms, and tasks. We posit that the present success of\nrepresentation learning approaches trained on large, text-only corpora requires\nthe parallel tradition of research on the broader physical and social context\nof language to address the deeper questions of communication.",
  "text": "Experience Grounds Language\nYonatan Bisk*\nAri Holtzman*\nJesse Thomason*\nJacob Andreas\nYoshua Bengio\nJoyce Chai\nMirella Lapata\nAngeliki Lazaridou\nJonathan May\nAleksandr Nisnevich\nNicolas Pinto\nJoseph Turian\nAbstract\nLanguage understanding research is held back\nby a failure to relate language to the physical\nworld it describes and to the social interactions\nit facilitates. Despite the incredible effective-\nness of language processing models to tackle\ntasks after being trained on text alone, success-\nful linguistic communication relies on a shared\nexperience of the world. It is this shared expe-\nrience that makes utterances meaningful.\nNatural language processing is a diverse ﬁeld,\nand progress throughout its development has\ncome from new representational theories, mod-\neling techniques, data collection paradigms,\nand tasks. We posit that the present success\nof representation learning approaches trained\non large, text-only corpora requires the paral-\nlel tradition of research on the broader physi-\ncal and social context of language to address\nthe deeper questions of communication.\nImprovements in hardware and data collection\nhave galvanized progress in NLP across many\nbenchmark tasks. Impressive performance has been\nachieved in language modeling (Radford et al.,\n2019; Zellers et al., 2019b; Keskar et al., 2019) and\nspan-selection question answering (Devlin et al.,\n2019; Yang et al., 2019b; Lan et al., 2020) through\nmassive data and massive models. With models\nexceeding human performance on such tasks, now\nis an excellent time to reﬂect on a key question:\nWhere is NLP going?\nIn this paper, we consider how the data and world\na language learner is exposed to deﬁne and con-\nstrains the scope of that learner’s semantics. Mean-\ning does not arise from the statistical distribution\nof words, but from their use by people to communi-\ncate. Many of the assumptions and understandings\non which communication relies lie outside of text.\nWe must consider what is missing from models\nMeaning is not a unique property of language, but a\ngeneral characteristic of human activity ... We cannot\nsay that each morpheme or word has a single or central\nmeaning, or even that it has a continuous or coherent\nrange of meanings ... there are two separate uses and\nmeanings of language – the concrete ... and the abstract.\nZellig S. Harris (Distributional Structure 1954)\ntrained solely on text corpora, even when those cor-\npora are meticulously annotated or Internet-scale.\nYou can’t learn language from the radio. Nearly\nevery NLP course will at some point make this\nclaim. The futility of learning language from lin-\nguistic signal alone is intuitive, and mirrors the\nbelief that humans lean deeply on non-linguistic\nknowledge (Chomsky, 1965, 1980). However, as\na ﬁeld we attempt this futility: trying to learn lan-\nguage from the Internet, which stands in as the\nmodern radio to deliver limitless language. In this\npiece, we argue that the need for language to attach\nto “extralinguistic events\" (Ervin-Tripp, 1973) and\nthe requirement for social context (Baldwin et al.,\n1996) should guide our research.\nDrawing inspiration from previous work in NLP,\nCognitive Science, and Linguistics, we propose the\nnotion of a World Scope (WS) as a lens through\nwhich to audit progress in NLP. We describe ﬁve\nWSs, and note that most trending work in NLP\noperates in the second (Internet-scale data).\nWe deﬁne ﬁve levels of World Scope:\nWS1. Corpus (our past)\nWS2. Internet (most of current NLP)\nWS3. Perception (multimodal NLP)\nWS4. Embodiment\nWS5. Social\nThese World Scopes go beyond text to consider\nthe contextual foundations of language: grounding,\nembodiment, and social interaction. We describe a\nbrief history and ongoing progression of how con-\ntextual information can factor into representations\nand tasks. We conclude with a discussion of how\narXiv:2004.10151v3  [cs.CL]  2 Nov 2020\nthis integration can move the ﬁeld forward. We be-\nlieve this World Scope framing serves as a roadmap\nfor truly contextual language understanding.\n1\nWS1: Corpora and Representations\nThe story of data-driven language research begins\nwith the corpus. The Penn Treebank (Marcus et al.,\n1993) is the canonical example of a clean subset of\nnaturally generated language, processed and anno-\ntated for the purpose of studying representations.\nSuch corpora and the model representations built\nfrom them exemplify WS1. Community energy\nwas initially directed at ﬁnding formal linguistic\nstructure, such as recovering syntax trees. Recent\nsuccess on downstream tasks has not required such\nexplicitly annotated signal, leaning instead on un-\nstructured fuzzy representations. These representa-\ntions span from dense word vectors (Mikolov et al.,\n2013) to contextualized pretrained representations\n(Peters et al., 2018; Devlin et al., 2019).\nWord representations have a long history predat-\ning the recent success of deep learning methods.\nOutside of NLP, philosophy (Austin, 1975) and lin-\nguistics (Lakoff, 1973; Coleman and Kay, 1981)\nrecognized that meaning is ﬂexible yet structured.\nEarly experiments on neural networks trained with\nsequences of words (Elman, 1990; Bengio et al.,\n2003) suggested that vector representations could\ncapture both syntax and semantics. Subsequent\nexperiments with larger models, documents, and\ncorpora have demonstrated that representations\nlearned from text capture a great deal of informa-\ntion about meaning in and out of context (Collobert\nand Weston, 2008; Turian et al., 2010; Mikolov\net al., 2013; McCann et al., 2017).\nThe intuition of such embedding representations,\nthat context lends meaning, has long been acknowl-\nedged (Firth, 1957; Turney and Pantel, 2010). Ear-\nlier on, discrete, hierarchical representations, such\nas agglomerative clustering guided by mutual in-\nformation (Brown et al., 1992), were constructed\nwith some innate interpretability. A word’s position\nin such a hierarchy captures semantic and syntac-\ntic distinctions. When the Baum–Welch algorithm\n(Welch, 2003) is applied to unsupervised Hidden\nMarkov Models, it assigns a class distribution to\nevery word, and that distribution is a partial rep-\nresentation of a word’s “meaning.” If the set of\nclasses is small, syntax-like classes are induced;\nif the set is large, classes become more semantic.\nThese representations are powerful in that they cap-\n1960\n1970\n1980\n1990\n2000\n2010\n2020\nYear\n0\n20\n40\n60\n80\n100\n% of 2019 Citations\nHarris 1954\nFirth 1957\nChomsky 1957\nAcademic interest in Firth and Harris increases dramatically\naround 2010, perhaps due to the popularization of Firth (1957)\n“You shall know a word by the company it keeps.\"\nture linguistic intuitions without supervision, but\nthey are constrained by the structure they impose\nwith respect to the number of classes chosen.\nThe intuition that meaning requires a large con-\ntext, that “You shall know a word by the company\nit keeps.\" – Firth (1957), manifested early via La-\ntent Semantic Indexing/Analysis (Deerwester et al.,\n1988, 1990; Dumais, 2004) and later in the gen-\nerative framework of Latent Dirichlet Allocation\n(Blei et al., 2003). LDA represents a document as\na bag-of-words conditioned on latent topics, while\nLSI/A use singular value decomposition to project\na co-occurrence matrix to a low dimensional word\nvector that preserves locality. These methods dis-\ncard sentence structure in favor of the document.\nRepresenting words through other words is a\ncomfortable proposition, as it provides the illusion\nof deﬁnitions by implicit analogy to thesauri and\nrelated words in a dictionary deﬁnition. However,\nthe recent trends in deep learning approaches to\nlanguage modeling favor representing meaning in\nﬁxed-length vectors with no obvious interpretation.\nThe question of where meaning resides in “connec-\ntionist” systems like Deep Neural Networks is an\nold one (Pollack, 1987; James and Miikkulainen,\n1995). Are concepts distributed through edges or\nlocal to units in an artiﬁcial neural network?\n“... there has been a long and unresolved\ndebate between those who favor localist\nrepresentations in which each process-\ning element corresponds to a meaningful\nconcept and those who favor distributed\nrepresentations.”\nHinton (1990)\nSpecial Issue on Connectionist Symbol Processing\nIn connectionism, words were no longer deﬁned\nover interpretable dimensions or symbols, which\nwere perceived as having intrinsic meaning. The\ntension of modeling symbols and distributed repre-\nsentations is articulated by Smolensky (1990), and\nalternative representations (Kohonen, 1984; Hinton\net al., 1986; Barlow, 1989) and approaches to struc-\nture and composition (Erk and Padó, 2008; Socher\net al., 2012) span decades of research.\nThe Brown Corpus (Francis, 1964) and Penn\nTreebank (Marcus et al., 1993) deﬁned context and\nstructure in NLP for decades. Only relatively re-\ncently (Baroni et al., 2009) has the cost of annota-\ntions decreased enough, and have large-scale web-\ncrawls become viable, to enable the introduction of\nmore complex text-based tasks. This transition to\nlarger, unstructured context (WS2) induced a richer\nsemantics than was previously believed possible\nunder the distributional hypothesis.\n2\nWS2: The Written World\nCorpora in NLP have broadened to include large\nweb-crawls. The use of unstructured, unlabeled,\nmulti-domain, and multilingual data broadens our\nworld scope, in the limit, to everything humanity\nhas ever written.1 We are no longer constrained to\na single author or source, and the temptation for\nNLP is to believe everything that needs knowing\ncan be learned from the written world. But, a large\nand noisy text corpus is still a text corpus.\nThis move towards using large scale raw data\nhas led to substantial advances in performance on\nexisting and novel community benchmarks (Devlin\net al., 2019; Brown et al., 2020). Scale in data and\nmodeling has demonstrated that a single represen-\ntation can discover both rich syntax and semantics\nwithout our help (Tenney et al., 2019). This change\nis perhaps best seen in transfer learning enabled\nby representations in deep models. Traditionally,\ntransfer learning relied on our understanding of\nmodel classes, such as English grammar. Domain\nadaptation simply required sufﬁcient data to cap-\nture lexical variation, by assuming most higher-\nlevel structure would remain the same. Unsuper-\nvised representations today capture deep associ-\nations across multiple domains, and can be used\nsuccessfully transfer knowledge into surprisingly\ndiverse contexts (Brown et al., 2020).\nThese representations require scale in terms of\nboth data and parameters. Concretely, Mikolov\net al. (2013) trained on 1.6 billion tokens, while\nPennington et al. (2014) scaled up to 840 billion\ntokens from Common Crawl. Recent approaches\n1A parallel discussion would focus on the hardware re-\nquired to enable advances to higher World Scopes. Playsta-\ntions (Pinto et al., 2009) and then GPUs (Krizhevsky et al.,\n2012) made many WS2 advances possible. Perception, inter-\naction, and robotics leverage other new hardware.\nhave made progress by substantially increasing the\nnumber of model parameters to better consume\nthese vast quantities of data. Where Peters et al.\n(2018) introduced ELMo with ∼108 parameters,\nTransformer models (Vaswani et al., 2017) have\ncontinued to scale by orders of magnitude between\npapers (Devlin et al., 2019; Radford et al., 2019;\nZellers et al., 2019b) to ∼1011 (Brown et al., 2020).\nCurrent models are the next (impressive) step\nin language modeling which started with Good\n(1953), the weights of Kneser and Ney (1995);\nChen and Goodman (1996), and the power-law\ndistributions of Teh (2006). Modern approaches\nto learning dense representations allow us to bet-\nter estimate these distributions from massive cor-\npora. However, modeling lexical co-occurrence,\nno matter the scale, is still modeling the written\nworld. Models constructed this way blindly search\nfor symbolic co-occurences void of meaning.\nHow can models yield both “impressive results”\nand “diminishing returns”? Language modeling—\nthe modern workhorse of neural NLP systems—is\na canonical example. Recent pretraining literature\nhas produced results that few could have predicted,\ncrowding leaderboards with “super-human\" accu-\nracy (Rajpurkar et al., 2018). However, there are\ndiminishing returns. For example, on the LAM-\nBADA dataset (Paperno et al., 2016), designed\nto capture human intuition, GPT2 (Radford et al.,\n2019) (1.5B), Megatron-LM (Shoeybi et al., 2019)\n(8.3B), and TuringNLG (Rosset, 2020) (17B) per-\nform within a few points of each other and very far\nfrom perfect (<68%). When adding another order\nof magnitude of parameters (175B) Brown et al.\n(2020) gain 8 percentage-points, impressive but\nstill leaving 25% unsolved. Continuing to expand\nhardware, data sizes, and ﬁnancial compute cost\nby orders of magnitude will yield further gains, but\nthe slope of the increase is quickly decreasing.\nThe aforementioned approaches for learning\ntransferable representations demonstrate that sen-\ntence and document context provide powerful sig-\nnals for learning aspects of meaning, especially se-\nmantic relations among words (Fu et al., 2014) and\ninferential relationships among sentences (Wang\net al., 2019a). The extent to which they capture\ndeeper notions of contextual meaning remains an\nopen question. Past work has found that pretrained\nword and sentence representations fail to capture\nmany grounded features of words (Lucy and Gau-\nthier, 2017) and sentences, and current NLU sys-\ntems fail on the thick tail of experience-informed in-\nferences, such as hard coreference problems (Peng\net al., 2015). “I parked my car in the compact park-\ning space because it looked (big/small) enough.”\nstill presents problems for text-only learners.\nAs text pretraining schemes seem to be reach-\ning the point of diminishing returns, even for some\nsyntactic phenomena (van Schijndel et al., 2019),\nwe posit that other forms of supervision, such as\nmultimodal perception (Ilharco et al., 2019), are\nnecessary to learn the remaining aspects of mean-\ning in context. Learning by observation should not\nbe a purely linguistic process, since leveraging and\ncombining the patterns of multimodal perception\ncan combinatorially boost the amount of signal in\ndata through cross-referencing and synthesis.\n3\nWS3: The World of Sights and Sounds\nLanguage learning needs perception, because per-\nception forms the basis for many of our semantic\naxioms. Learned, physical heuristics, such as the\nfact that a falling cat will land quietly, are general-\nized and abstracted into language metaphors like\nas nimble as a cat (Lakoff, 1980). World knowl-\nedge forms the basis for how people make entail-\nment and reasoning decisions, commonly driven\nby mental simulation and analogy (Hofstadter and\nSander, 2013). Perception is the foremost source\nof reporting bias. The assumption that we all see\nand hear the same things informs not just what we\nname, but what we choose to assume and leave un-\nwritten. Further, there exists strong evidence that\nchildren require grounded sensory perception, not\njust speech, to learn language (Sachs et al., 1981;\nO’Grady, 2005; Vigliocco et al., 2014).\nPerception includes auditory, tactile, and visual\ninput.\nEven restricted to purely linguistic sig-\nnals, sarcasm, stress, and meaning can be implied\nthrough prosody. Further, tactile senses lend mean-\ning, both physical (Sinapov et al., 2014; Thomason\net al., 2016) and abstract, to concepts like heavy and\nsoft. Visual perception is a rich signal for modeling\na vastness of experiences in the world that cannot\nbe documented by text alone (Harnad, 1990).\nFor example, frames and scripts (Schank and\nAbelson, 1977; Charniak, 1977; Dejong, 1981;\nMooney and Dejong, 1985) require understand-\ning often unstated sets of pre- and post-conditions\nabout the world. To borrow from Charniak (1977),\nhow should we learn the meaning, method, and im-\nplications of painting? A web crawl of knowledge\nEugene Charniak (A Framed PAINTING: The Representation\nof a Common Sense Knowledge Fragment 1977)\nfrom an exponential number of possible how-to,\ntext-only guides and manuals (Bisk et al., 2020)\nis misdirected without some fundamental referents\nto which to ground symbols. Models must be able\nto watch and recognize objects, people, and activi-\nties to understand the language describing them (Li\net al., 2019b; Krishna et al., 2017; Yatskar et al.,\n2016; Perlis, 2016) and access ﬁne-grained notions\nof causality, physics, and social interactions.\nWhile the NLP community has played an im-\nportant role in the history of grounding (Mooney,\n2008), recently remarkable progress has taken\nplace in the Computer Vision community. It is\ntempting to assume that vision models trained\nto identify 1,000 ImageNet classes (Russakovsky\net al., 2015)2 are limited to extracting a bag of vi-\nsual words. In reality, Computer Vision has been\nmaking in-roads into complex visual, physical, and\nsocial phenomena, while providing reusable infras-\ntructure.3 The stability of these architectures allows\nfor new research into more challenging world mod-\neling. Mottaghi et al. (2016) predicts the effects of\nforces on objects in images. Bakhtin et al. (2019)\nextends this physical reasoning to complex puzzles\nof cause and effect. Sun et al. (2019b,a) models\nscripts and actions, and alternative unsupervised\ntraining regimes (Bachman et al., 2019) open up\nresearch towards automatic concept formation.\nAdvances in computer vision have enabled build-\ning semantic representations rich enough to inter-\nact with natural language. In the last decade of\nwork descendant from image captioning (Farhadi\net al., 2010; Mitchell et al., 2012), a myriad of\ntasks on visual question answering (Antol et al.,\n2015; Das et al., 2018; Yagcioglu et al., 2018),\nnatural language and visual reasoning (Suhr et al.,\n2019b), visual commonsense (Zellers et al., 2019a),\n2Or the 1,600 classes of Anderson et al. (2017).\n3Torchvision/Detectron2 include dozens of trained models.\nand multilingual captioning/translation via video\n(Wang et al., 2019b) have emerged. These com-\nbined text and vision benchmarks are rich enough\nto train large-scale, multimodal transformers (Li\net al., 2019a; Lu et al., 2019; Zhou et al., 2019)\nwithout language pretraining (e.g. via conceptual\ncaptions (Sharma et al., 2018)) or further broad-\nened to include audio (Tsai et al., 2019). Vision can\nalso help ground speech signals (Srinivasan et al.,\n2020; Harwath et al., 2019) to facilitate discovery\nof linguistic concepts (Harwath et al., 2020).\nAt the same time, NLP resources contributed\nto the success of these vision backbones. Hierar-\nchical semantic representations emerge from Im-\nageNet classiﬁcation pretraining partially due to\nclass hypernyms owed to that dataset’s WordNet\norigins. For example, the person class sub-divides\ninto many professions and hobbies, like ﬁreﬁghter,\ngymnast, and doctor. To differentiate such sibling\nclasses, learned vectors can also encode lower-level\ncharacteristics like clothing, hair, and typical sur-\nrounding scenes. These representations allow for\npixel level masks and skeletal modeling, and can be\nextended to zero-shot settings targeting all 20K Im-\nageNet categories (Chao et al., 2016; Changpinyo\net al., 2017). Modern architectures also learn to dif-\nferentiate instances within a general class, such as\nface. For example, facial recognition benchmarks\nrequire distinguishing over 10K unique faces (Liu\net al., 2015). While vision is by no means “solved,”\nbenchmarks have led to off-the-shelf tools for build-\ning representations rich enough to identify tens of\nthousands of objects, scenes, and individuals.\nA WS3 agent, having access to potentially end-\nless hours of video data showing the intricate de-\ntails of daily comings and goings, procedures, and\nevents, reduces susceptibility to the reporting bias\nof WS2. An ideal WS3 agent will exhibit bet-\nter long-tail generalization and understanding than\nany language-only system could. This generaliza-\ntion should manifest in existing benchmarks, but\nwould be most prominent in a test of zero-shot cir-\ncumstances, such as “Will this car ﬁt through that\ntunnel?,” and rarely documented behaviors as ex-\namined in script learning. Yet the WS3 agent will\nlikely fail to answer, \"Would a ceramic or paper\nplate make a better frisbee?\" The agent has not tried\nto throw various objects and understand how their\nvelocity and shape interact with the atmosphere to\ncreate lift. The agent cannot test novel hypotheses\nby intervention and action in the world.\nIf A and B have some environments in common and\nsome not ... we say that they have different meanings,\nthe amount of meaning difference corresponding\nroughly to the amount of difference in their\nenvironments ...\nZellig S. Harris (Distributional Structure 1954)\n4\nWS4: Embodiment and Action\nIn human development, interactive multimodal sen-\nsory experience forms the basis of action-oriented\ncategories (Thelen and Smith, 1996) as children\nlearn how to manipulate their perception by ma-\nnipulating their environment. Language grounding\nenables an agent to connect words to these action-\noriented categories for communication (Smith and\nGasser, 2005), but requires action to fully discover\nsuch connections. Embodiment—situated action\ntaking—is therefore a natural next broader context.\nAn embodied agent, whether in a virtual world,\nsuch as a 2D Maze (MacMahon et al., 2006), a\ngrid world (Chevalier-Boisvert et al., 2019), a sim-\nulated house (Anderson et al., 2018; Thomason\net al., 2019b; Shridhar et al., 2020), or the real\nworld (Tellex et al., 2011; Matuszek, 2018; Thoma-\nson et al., 2020; Tellex et al., 2020) must translate\nfrom language to action. Control and action taking\nopen several new dimensions to understanding and\nactively learning about the world. Queries can be\nresolved via dialog-based exploration with a hu-\nman interlocutor (Liu and Chai, 2015), even as new\nobject properties, like texture and weight (Thoma-\nson et al., 2017), or feedback, like muscle activa-\ntions (Moro and Kennington, 2018), become avail-\nable. We see the need for embodied language with\ncomplex meaning when thinking deeply about even\nthe most innocuous of questions:\nIs an orange more like a baseball or more\nlike a banana?\nWS1 is likely not to have an answer beyond that\nthe objects are common nouns that can both be held.\nWS2 may capture that oranges and baseballs both\nroll, but is not the deformation strength, surface tex-\nture, or relative sizes of these objects (Elazar et al.,\n2019). WS3 may realize the relative deformability\nof these objects, but is likely to confuse how much\nforce is necessary given that baseballs are used\nmuch more roughly than oranges. WS4 can appre-\nciate the nuances of the question—the orange and\nbaseball afford similar manipulation because they\nhave similar texture and weight, while the orange\nand banana both contain peels, deform, and are\nedible. People can reason over rich representations\nof common objects that these words evoke.\nPlanning is where people ﬁrst learn abstraction\nand simple examples of post-conditions through\ntrial and error. The most basic scripts humans learn\nstart with moving our own bodies and achieving\nsimple goals as children, such as stacking blocks.\nIn this space, we have unlimited supervision from\nthe environment and can learn to generalize across\nplans and actions. In general, simple worlds do\nnot entail simple concepts: even in a block world\nconcepts like “mirroring” appear (Bisk et al., 2018).\nHumans generalize and apply physical phenomena\nto abstract concepts with ease.\nIn addition to learning basic physical proper-\nties of the world from interaction, WS4 also al-\nlows the agent to construct rich pre-linguistic rep-\nresentations from which to generalize. Hespos and\nSpelke (2004) show pre-linguistic category forma-\ntion within children that are then later codiﬁed by\nsocial constructs. Mounting evidence seems to indi-\ncate that children have trouble transferring knowl-\nedge from the 2D world of books (Barr, 2013) and\niPads (Lin et al., 2017) to the physical 3D world.\nSo while we might choose to believe that we can en-\ncode parameters (Chomsky, 1981) more effectively\nand efﬁciently than evolution provided us, develop-\nmental experiments indicate doing so without 3D\ninteraction may prove difﬁcult.\nPart of the problem is that much of the knowl-\nedge humans hold about the world is intuitive,\npossibly incommunicable by language, but still\nrequired to understand language. Much of this\nknowledge revolves around physical realities that\nreal-world agents will encounter. Consider how\nmany explicit and implicit metaphors are based on\nthe idea that far-away things have little inﬂuence\non manipulating local space: “a distant concern”\nand “we’ll cross that bridge when we come to it.”\nRobotics and embodiment are not available in\nthe same off-the-shelf manner as computer vision\nmodels. However, there is rapid progress in simu-\nlators and commercial robotics, and as language re-\nsearchers we should match these advances at every\nstep. As action spaces grow, we can study complex\nlanguage instructions in simulated homes (Shrid-\nhar et al., 2020) or map language to physical robot\ncontrol (Blukis et al., 2019; Chai et al., 2018). The\nlast few years have seen massive advances in both\nIn order to talk about concepts, we must understand the\nimportance of mental models... we set up a model of\nthe world which serves as a framework in which to\norganize our thoughts. We abstract the presence of\nparticular objects, having properties, and entering into\nevents and relationships.\nTerry Winograd - 1971\nhigh ﬁdelity simulators for robotics (Todorov et al.,\n2012; Coumans and Bai, 2016–2019; NVIDIA,\n2019; Xiang et al., 2020) and the cost and avail-\nability of commodity hardware (Fitzgerald, 2013;\nCampeau-Lecours et al., 2019; Murali et al., 2019).\nAs computers transition from desktops to perva-\nsive mobile and edge devices, we must make and\nmeet the expectation that NLP can be deployed in\nany of these contexts. Current representations have\nvery limited utility in even the most basic robotic\nsettings (Scalise et al., 2019), making collaborative\nrobotics (Rosenthal et al., 2010) largely a domain\nof custom engineering rather than science.\n5\nWS5: The Social World\nInterpersonal communication is the foundational\nuse case of natural language (Dunbar, 1993). The\nphysical world gives meaning to metaphors and\ninstructions, but utterances come from a source\nwith a purpose. Take J.L. Austin’s classic example\nof “BULL” being written on the side of a fence in\na large ﬁeld (Austin, 1975). It is a fundamentally\nsocial inference to realize that this word indicates\nthe presence of a dangerous creature, and that the\nword is written on the opposite side of the fence\nfrom where that creature lives.\nInterpersonal dialogue as a grand test for AI is\nolder than the term “artiﬁcial intelligence,” begin-\nning at least with Turing (1950)’s Imitation Game.\nTuring was careful to show how easily a naïve tester\ncould be tricked. Framing, such as suggesting that a\nchatbot speaks English as a second language (Sam-\nple and Hern, 2014), can create the appearance of\ngenuine content where there is none (Weizenbaum,\n1966). This phenomenon has been noted countless\ntimes, from criticisms of Speech Recognition as\n“deceit and glamour” (Pierce, 1969) to complaints\nof humanity’s “gullibility gap” (Marcus and Davis,\n2019). We instead focus on why the social world\nis vital to language learning.\nLanguage that Does Something\nWork in the\nphilosophy of language has long suggested that\nfunction is the source of meaning, as famously il-\nlustrated through Wittgenstein’s “language games”\n(Wittgenstein, 1953, 1958).\nIn linguistics, the\nusage-based theory of language acquisition sug-\ngests that constructions that are useful are the build-\ning blocks for everything else (Langacker, 1987,\n1991).\nThe economy of this notion of use has\nbeen the subject of much inquiry and debate (Grice,\n1975). In recent years, these threads have begun to\nshed light on what use-cases language presents in\nboth acquisition and its initial origins in our species\n(Tomasello, 2009; Barsalou, 2008), indicating the\nfundamental role of the social world.\nWS1, WS2, WS3, and WS4 expand the fac-\ntorizations of information available to linguistic\nmeaning. allows language to be a cause instead of\njust a source of data. This is the ultimate goal for\na language learner: to generate language that does\nsomething to the world.\nPassive creation and evaluation of generated lan-\nguage separates generated utterances from their\neffects on other people, and while the latter is\na rich learning signal it is inherently difﬁcult to\nannotate. In order to learn the effects language\nhas on the world, an agent must participate in lin-\nguistic activity, such as negotiation (Yang et al.,\n2019a; He et al., 2018; Lewis et al., 2017), collab-\noration (Chai et al., 2017), visual disambiguation\n(Anderson et al., 2018; Lazaridou et al., 2017; Liu\nand Chai, 2015), or providing emotional support\n(Rashkin et al., 2019). These activities require in-\nferring mental states and social outcomes—a key\narea of interest in itself (Zadeh et al., 2019).\nWhat “lame” means in terms of discriminative\ninformation is always at question: it can be deﬁned\nas “undesirable,” but what it tells one about the\nprocesses operating in the environment requires\nsocial context to determine (Bloom, 2002). It is\nthe toddler’s social experimentation with “You’re\nso lame!” that gives the word weight and deﬁnite\nintent (Ornaghi et al., 2011). In other words, the\ndiscriminative signal for the most foundational part\nof a word’s meaning can only be observed by its ef-\nfect on the world, and active experimentation is key\nto learning that effect. Active experimentation with\nlanguage starkly contrasts with the disembodied\nchat bots that are the focus of the current dialogue\ncommunity (Roller et al., 2020; Adiwardana et al.,\n2020; Zhou et al., 2020; Chen et al., 2018; Serban\net al., 2017), which often do not learn from individ-\nual experiences and whose environments are not\npersistent enough to learn the effects of actions.\nTheory of Mind\nWhen attempting to get what\nwe want, we confront people who have their own\ndesires and identities. The ability to consider the\nfeelings and knowledge of others is now com-\nmonly referred to as the “Theory of Mind” (Ne-\nmatzadeh et al., 2018). This paradigm has also\nbeen described under the “Speaker-Listener” model\n(Stephens et al., 2010), and a rich theory to describe\nthis computationally is being actively developed\nunder the Rational Speech Act Model (Frank and\nGoodman, 2012; Bergen et al., 2016).\nA series of challenges that attempt to address this\nfundamental aspect of communication have been\nintroduced (Nematzadeh et al., 2018; Sap et al.,\n2019). These works are a great start towards deeper\nunderstanding, but static datasets can be problem-\natic due to the risk of embedding spurious patterns\nand bias (de Vries et al., 2020; Le et al., 2019;\nGururangan et al., 2018; Glockner et al., 2018),\nespecially because examples where annotators can-\nnot agree (which are usually thrown out before\nthe dataset is released) still occur in real use cases.\nMore ﬂexible, dynamic evaluation (Zellers et al.,\n2020; Dinan et al., 2019) are a partial solution, but\ntrue persistence of identity and adaption to change\nare both necessary and still a long way off.\nTraining data in WS1-4, complex and large as\nit can be, does not offer the discriminatory signals\nthat make the hypothesizing of consistent identity\nor mental states an efﬁcient path towards lowering\nperplexity or raising accuracy (Liu et al., 2016; De-\nVault et al., 2006). First, there is a lack of inductive\nbias (Martin et al., 2018). Models learn what they\nneed to discriminate between potential labels, and\nit is unlikely that universal function approximators\nsuch as neural networks would ever reliably posit\nthat people, events, and causality exist without be-\ning biased towards such solutions (Mitchell, 1980).\nSecond, current cross entropy training losses ac-\ntively discourage learning the tail of the distribu-\ntion properly, as statistically infrequent events are\ndrowned out (Pennington et al., 2014; Holtzman\net al., 2020). Meanwhile, it is precisely human’s\nability to draw on past experience and make zero-\nshot decisions that AI aims to emulate.\nLanguage in a Social Context\nWhenever lan-\nguage is used between people, it exists in a concrete\nsocial context: status, role, intention, and countless\nother variables intersect at a speciﬁc point (Ward-\nhaugh, 2011). These complexities are overlooked\nthrough selecting labels on which crowd workers\nagree. Current notions of ground truth in dataset\nconstruction are based on crowd consensus bereft\nof social context. We posit that ecologically valid\nevaluation of generative models will require the\nconstruction of situations where artiﬁcial agents are\nconsidered to have enough identity to be granted\nsocial standing for these interactions.\nSocial interaction is a precious signal, but ini-\ntial studies have been strained by the training-\nvalidation-test set scenario and reference-backed\nevaluations. Collecting data about rich natural sit-\nuations is often impossible. To address this gap,\nlearning by participation, where users can freely\ninteract with an agent, is a necessary step to the\nultimately social venture of communication. By\nexhibiting different attributes and sending varying\nsignals, the sociolinguistic construction of identity\n(Ochs, 1993) could be examined more deeply. Such\nexperimentation in social intelligence is simply not\npossible with a ﬁxed corpus. Once models are ex-\npected to be interacted with when tested, probing\ntheir decision boundaries for simpliﬁcations of re-\nality and a lack of commonsense knowledge as in\nGardner et al.; Kaushik et al. will become natural.\n6\nSelf-Evaluation\nWe use the notion of World Scopes to make the\nfollowing concrete claims:\nYou can’t learn language ...\n... from the radio (Internet).\nWS2 ⊂WS3\nA task learner cannot be said to be in\nWS3 if it can succeed without perception\n(e.g., visual, auditory).\n... from a television.\nWS3 ⊂WS4\nA task learner cannot be said to be in\nWS4 if the space of its world actions\nand consequences can be enumerated.\n... by yourself.\nWS4 ⊂WS5\nA task learner cannot be said to be in\nWS5 unless achieving its goals requires\ncooperating with a human in the loop.\nBy these deﬁnitions, most of NLP research still\nresides in WS2. This fact does not invalidate the\nutility or need for any of the research within NLP,\nbut it is to say that much of that existing research\ntargets a different goal than language learning.\nThese problems include the need to bring meaning\nand reasoning into systems that perform natural\nlanguage processing, the need to infer and\nrepresent causality, the need to develop\ncomputationally-tractable representations of\nuncertainty and the need to develop systems that\nformulate and pursue long-term goals.\nMichael Jordan (Artiﬁcial intelligence – the\nrevolution hasn’t happened yet, 2019)\nWhere Should We Start?\nMany in our commu-\nnity are already examining phenomena in WSs\n3-5. Note that research can explore higher WS\nphenomena without a resultant learner being in a\nhigher WS. For example, a chatbot can investigate\nprinciples of the social world, but still lack the un-\nderlying social standing required for WS5. Next\nwe describe four language use contexts which we\nbelieve are both research questions to be tackled\nand help illustrate the need to move beyond WS2.\nSecond language acquisition when visiting a\nforeign country leverages a shared, social world\nmodel that allows pointing to referent objects and\nmiming internal states like hunger. The interlingua\nis physical and experiential. Such a rich internal\nworld model should also be the goal for MT models:\nstarting with images (Huang et al., 2020), moving\nthrough simulation, and then to the real world.\nCoreference and WSD leverage a shared scene\nand theory of mind. To what extent are current\ncoreference resolution issues resolved if an agent\nmodels the listener’s desires and experiences explic-\nitly rather than looking solely for adjacent lexical\nitems? This setting is easiest to explore in embod-\nied environments, but is not exclusive to them (e.g.,\nTextWorld (Côté et al., 2018)).\nNovel word learning from tactile knowledge\nand use: What is the instrument that you wear like\na guitar but play like a piano? Objects can be de-\nscribed with both gestures and words about appear-\nance and function. Such knowledge could begin\nto tackle physical metaphors that current NLP sys-\ntems struggle with.\nPersonally charged language: How should a\ndialogue agent learn what is hurtful to a speciﬁc\nperson? To someone who is sensitive about their\ngrades because they had a period of struggle in\nschool, the sentiment of “Don’t be a fool!” can be\nhurtful, while for others it may seem playful. Social\nknowledge is requisite for realistic understanding\nof sentiment in situated human contexts.\nRelevant recent work\nThe move from WS2 to\nWS3 requires rethinking existing tasks and investi-\ngating where their semantics can be expanded and\ngrounded. This idea is not new (Chen and Mooney,\n2008; Feng and Lapata, 2010; Bruni et al., 2014;\nLazaridou et al., 2016) and has accelerated in the\nlast few years. Elliott et al. (2016) reframes ma-\nchine translation with visual observations, a trend\nextended into videos (Wang et al., 2019b). Regneri\net al. (2013) introduce a foundational dataset align-\ning text descriptions and semantic annotations of\nactions with videos. Vision can even inform core\ntasks like syntax (Shi et al., 2019) and language\nmodeling (Ororbia et al., 2019). Careful design is\nkey, as visually augmented tasks can fail to require\nsensory perception (Thomason et al., 2019a).\nLanguage-guided, embodied agents invoke many\nof the challenges of WS4. Language-based nav-\nigation (Anderson et al., 2018) and task comple-\ntion (Shridhar et al., 2020) in simulation environ-\nments ground language to actions, but even com-\nplex simulation action spaces can be discretized\nand enumerated.\nReal world, language-guided\nrobots for task completion (Tellex et al., 2014) and\nlearning (She et al., 2014) face challenging, con-\ntinuous perception and control (Tellex et al., 2020).\nConsequently, research in this space is often re-\nstricted to small grammars (Paul et al., 2018; Walter\net al., 2013) or controlled dialog responses (Thoma-\nson et al., 2020). These efforts to translate language\ninstructions to actions build towards using language\nfor end-to-end, continuous control (WS4).\nCollaborative games have long served as a\ntestbed for studying language (Werner and Dyer,\n1991) and emergent communication (Schlangen,\n2019a; Lazaridou et al., 2018; Chaabouni et al.,\n2020). Suhr et al. (2019a) introduced an environ-\nment for evaluating language understanding in the\nservice of a shared goal, and Andreas and Klein\n(2016) use a visual paradigm for studying pragmat-\nics. Such efforts help us examine how inductive\nbiases and environmental pressures build towards\nsocialization (WS5), even if full social context is\nstill too difﬁcult and expensive to be practical.\nMost of these works provide resources such as\ndata, code, simulators and methodology for evaluat-\ning the multimodal content of linguistic representa-\ntions (Schlangen, 2019b; Silberer and Lapata, 2014;\nBruni et al., 2012). Moving forward, we encourage\na broad re-examination of how NLP frames the rela-\ntionship between meaning and context (Bender and\nKoller, 2020) and how pretraining obfuscates our\nability to measure generalization (Linzen, 2020).\n7\nConclusions\nOur World Scopes are steep steps. WS5 implies a\npersistent agent experiencing time and a personal-\nized set of experiences. With few exceptions (Carl-\nson et al., 2010), machine learning models have\nbeen conﬁned to IID datasets that lack the structure\nin time from which humans draw correlations about\nlong-range causal dependencies. What if a machine\nwas allowed to participate consistently? This is dif-\nﬁcult to test under current evaluation paradigms for\ngeneralization. Yet, this is the structure of gener-\nalization in human development: drawing analo-\ngies to episodic memories and gathering new data\nthrough non-independent experiments.\nAs with many who have analyzed the history\nof NLP, its trends (Church, 2007), its maturation\ntoward a science (Steedman, 2008), and its major\nchallenges (Hirschberg and Manning, 2015; Mc-\nClelland et al., 2019), we hope to provide momen-\ntum for a direction many are already heading. We\ncall for and embrace the incremental, but purpose-\nful, contextualization of language in human expe-\nrience. With all that we have learned about what\nwords can tell us and what they keep implicit, now\nis the time to ask: What tasks, representations, and\ninductive-biases will ﬁll the gaps?\nComputer vision and speech recognition are ma-\nture enough for investigation of broader linguistic\ncontexts (WS3). The robotics industry is rapidly\ndeveloping commodity hardware and sophisticated\nsoftware that both facilitate new research and ex-\npect to incorporate language technologies (WS4).\nSimulators and videogames provide potential envi-\nronments for social language learners (WS5). Our\ncall to action is to encourage the community to lean\nin to trends prioritizing grounding and agency, and\nexplicitly aim to broaden the corresponding World\nScopes available to our models.\nAcknowledgements\nThanks to Raymond Mooney for suggestions, Paul\nSmolensky for disagreements, Catriona Silvey for\ndevelopmental psychology help, and to a superset\nof: Emily Bender, Ryan Cotterel, Jesse Dunietz,\nEdward Grefenstette, Dirk Hovy, Casey Kenning-\nton, Ajay Divakaran, David Schlangend, Diyi Yang,\nand Semih Yagcioglu for pointers and suggestions.\nReferences\nDaniel Adiwardana, Minh-Thang Luong, David R So,\nJamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,\nApoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,\net al. 2020.\nTowards a human-like open-domain\nchatbot. arXiv preprint arXiv:2001.09977.\nPeter Anderson, Xiaodong He, Chris Buehler, Damien\nTeney, Mark Johnson, Stephen Gould, and Lei\nZhang. 2017. Bottom-up and top-down attention for\nimage captioning and visual question answering. Vi-\nsual Question Answering Challenge at CVPR 2017.\nPeter Anderson, Qi Wu, Damien Teney, Jake Bruce,\nMark Johnson, Niko Sünderhauf, Ian Reid, Stephen\nGould, and Anton van den Hengel. 2018. Vision-\nand-Language Navigation:\nInterpreting visually-\ngrounded navigation instructions in real environ-\nments. In Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR).\nJacob Andreas and Dan Klein. 2016. Reasoning about\npragmatics with neural listeners and speakers.\nIn\nProceedings of the 2016 Conference on Empirical\nMethods in Natural Language Processing, pages\n1173–1182, Austin, Texas.\nStanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-\ngaret Mitchell, Dhruv Batra, C Lawrence Zitnick,\nand Devi Parikh. 2015.\nVqa: Visual question an-\nswering. In Proceedings of the IEEE international\nconference on computer vision, pages 2425–2433.\nJohn Langshaw Austin. 1975. How to do things with\nwords. Oxford university press.\nPhilip Bachman, R Devon Hjelm, and William Buch-\nwalter. 2019. Learning representations by maximiz-\ning mutual information across views. In Advances\nin Neural Information Processing Systems 32.\nAnton Bakhtin, Laurens van der Maaten, Justin John-\nson, Laura Gustafson, and Ross Girshick. 2019.\nPhyre: A new benchmark for physical reasoning. In\nAdvances in Neural Information Processing Systems\n32 (NIPS 2019).\nDare A. Baldwin, Ellen M. Markman, Brigitte Bill, Re-\nnee N. Desjardins, Jane M. Irwin, and Glynnis Tid-\nball. 1996. Infants’ reliance on a social criterion for\nestablishing word-object relations. Child Develop-\nment, 67(6):3135–3153.\nH.B. Barlow. 1989.\nUnsupervised learning.\nNeural\nComputation, 1(3):295–311.\nMarco Baroni, Silvia Bernardini, Adriano Ferraresi,\nand Eros Zanchetta. 2009. The wacky wide web: a\ncollection of very large linguistically processed web-\ncrawled corpora. Language resources and evalua-\ntion, 43(3):209–226.\nRachel Barr. 2013. Memory constraints on infant learn-\ning from picture books, television, and touchscreens.\nChild Development Perspectives, 7(4):205–210.\nLawrence W Barsalou. 2008.\nGrounded cognition.\nAnnu. Rev. Psychol., 59:617–645.\nEmily M Bender and Alexander Koller. 2020. Climb-\ning towards nlu: On meaning, form, and understand-\ning in the age of data. In Association for Computa-\ntional Linguistics (ACL).\nYoshua Bengio, Réjean Ducharme, Pascal Vincent, and\nChristian Jauvin. 2003. A neural probabilistic lan-\nguage model.\nJournal of Machine Learning Re-\nsearch, 3:1137–1155.\nLeon Bergen, Roger Levy, and Noah Goodman. 2016.\nPragmatic reasoning through semantic inference.\nSemantics and Pragmatics, 9.\nYonatan Bisk, Kevin Shih, Yejin Choi, and Daniel\nMarcu. 2018. Learning Interpretable Spatial Oper-\nations in a Rich 3D Blocks World . In Proceedings\nof the Thirty-Second Conference on Artiﬁcial Intelli-\ngence (AAAI-18).\nYonatan Bisk, Rowan Zellers, Ronan Le Bras, Jian-\nfeng Gao, and Yejin Choi. 2020. PIQA: Reasoning\nabout physical commonsense in natural language. In\nThirty-Fourth AAAI Conference on Artiﬁcial Intelli-\ngence.\nDavid M. Blei, Andrew Y. Ng, and Michael I. Jordan.\n2003. Latent dirichlet allocation. Journal of Ma-\nchine Learning Research, 3:993–1022.\nPaul Bloom. 2002. How children learn the meanings\nof words. MIT press.\nValts Blukis,\nYannick Terme,\nEyvind Niklasson,\nRoss A. Knepper, and Yoav Artzi. 2019. Learning to\nmap natural language instructions to physical quad-\ncopter control using simulated ﬂight. In 3rd Confer-\nence on Robot Learning (CoRL).\nPeter F Brown, Peter V deSouza, Robert L Mercer, Vin-\ncent J Della Pietra, and Jenifer C Lai. 1992. Class-\nbased n-gram models of natural language. Compu-\ntational Linguistics, 18.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell,\nSandhini Agarwal,\nAriel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learn-\ners. In preprint.\nElia Bruni, Gemma Boleda, Marco Baroni, and Nam-\nKhanh Tran. 2012. Distributional semantics in tech-\nnicolor. In Proceedings of the 50th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 136–145, Jeju Is-\nland, Korea.\nElia Bruni, Nam Khanh Tran, and Marco Baroni. 2014.\nMultimodal distributional semantics. Journal of Ar-\ntiﬁcial Intelligence Research, 49:1–47.\nAlexandre Campeau-Lecours, Hugo Lamontagne, Si-\nmon Latour, Philippe Fauteux, Véronique Maheu,\nFrançois Boucher, Charles Deguire, and Louis-\nJoseph Caron L’Ecuyer. 2019.\nKinova modular\nrobot arms for service robotics applications.\nIn\nRapid Automation: Concepts, Methodologies, Tools,\nand Applications, pages 693–719. IGI Global.\nAndrew Carlson, Justin Betteridge, Bryan Kisiel, Burr\nSettles, Estevam R Hruschka, and Tom M Mitchell.\n2010. Toward an architecture for never-ending lan-\nguage learning. In Twenty-Fourth AAAI Conference\non Artiﬁcial Intelligence.\nRahma Chaabouni, Eugene Kharitonov, Diane Boucha-\ncourt, Emmanuel Dupoux, and Marco Baroni. 2020.\nCompositionality and generalization in emergent\nlanguages.\nIn Association for Computational Lin-\nguistics (ACL).\nJoyce Y. Chai, Rui Fang, Changsong Liu, and Lanbo\nShe. 2017.\nCollaborative language grounding to-\nward situated human-robot dialogue. AI Magazine,\n37(4):32–45.\nJoyce Y. Chai, Qiaozi Gao, Lanbo She, Shaohua Yang,\nSari Saba-Sadiya, and Guangyue Xu. 2018.\nLan-\nguage to action: Towards interactive task learning\nwith physical agents. In Proceedings of the Twenty-\nSeventh International Joint Conference on Artiﬁcial\nIntelligence (IJCAI-18).\nSoravit Changpinyo, Wei-Lun Chao, and Fei Sha. 2017.\nPredicting visual exemplars of unseen classes for\nzero-shot learning. In ICCV.\nWei-Lun Chao, Soravit Changpinyo, Boqing Gong,\nand Fei Sha. 2016. An empirical study and analysis\nof generalized zero-shot learning for object recog-\nnition in the wild. In ECCV, pages 52–68, Cham.\nSpringer International Publishing.\nEugene Charniak. 1977. A framed painting: The rep-\nresentation of a common sense knowledge fragment.\nCognitive Science, 1(4):355–394.\nChun-Yen Chen, Dian Yu, Weiming Wen, Yi Mang\nYang, Jiaping Zhang, Mingyang Zhou, Kevin Jesse,\nAustin Chau, Antara Bhowmick, Shreenath Iyer,\net al. 2018. Gunrock: Building a human-like social\nbot by leveraging large scale real user data. Alexa\nPrize Proceedings.\nDavid L. Chen and Raymond J. Mooney. 2008. Learn-\ning to sportscast: A test of grounded language ac-\nquisition. In Proceedings of the 25th International\nConference on Machine Learning (ICML), Helsinki,\nFinland.\nSF Chen and Joshua Goodman. 1996. An empirical\nstudy of smoothing techniques for language model-\ning. In Association for Computational Linguistics,\npages 310–318.\nMaxime\nChevalier-Boisvert,\nDzmitry\nBahdanau,\nSalem Lahlou, Lucas Willems, Chitwan Saharia,\nThien Huu Nguyen, and Yoshua Bengio. 2019.\nBabyai:\nFirst steps towards grounded language\nlearning with a human in the loop. In ICLR’2019.\nNoam Chomsky. 1965. Aspects of the Theory of Syntax.\nMIT Press.\nNoam Chomsky. 1980. Language and learning: the de-\nbate between Jean Piaget and Noam Chomsky. Har-\nvard University Press.\nNoam Chomsky. 1981. Lectures on Government and\nBinding. Mouton de Gruyter.\nKenneth Church. 2007.\nA pendulum swung too far.\nLinguistic Issues in Language Technology – LiLT, 2.\nL. Coleman and P. Kay. 1981. The english word “lie\".\nLinguistics, 57.\nRonan Collobert and Jason Weston. 2008. A uniﬁed\narchitecture for natural language processing: deep\nneural networks with multitask learning. In ICML.\nMarc-Alexandre Côté, Ákos Kádár, Xingdi Yuan, Ben\nKybartas, Tavian Barnes, Emery Fine, James Moore,\nRuo Yu Tao, Matthew Hausknecht, Layla El Asri,\nMahmoud Adada, Wendy Tay, and Adam Trischler.\n2018. Textworld: A learning environment for text-\nbased games. ArXiv, abs/1806.11532.\nErwin Coumans and Yunfei Bai. 2016–2019. Pybullet,\na python module for physics simulation for games,\nrobotics and machine learning. http://pybullet.\norg.\nAbhishek Das, Samyak Datta, Georgia Gkioxari, Ste-\nfan Lee, Devi Parikh, and Dhruv Batra. 2018. Em-\nbodied question answering. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern\nRecognition Workshops, pages 2054–2063.\nScott Deerwester, Susan T. Dumais, George W. Furnas,\nThomas K. Landauer, and Richard Harshman. 1988.\nImproving information retrieval with latent semantic\nindexing. In Proceedings of the 51st Annual Meet-\ning of the American Society for Information Science\n25, pages 36 – 40.\nScott Deerwester, Susan T. Dumais, George W. Fur-\nnas, Thomas K. Landauer, and Richard Harshman.\n1990. Indexing by latent semantic analysis. Jour-\nnal of the American Society for Information Science,\n41(6):391–407.\nGerald Dejong. 1981. Generalizations based on expla-\nnations. In Proceedings of the 7th international joint\nconference on Artiﬁcial intelligence (IJCAI).\nDavid DeVault, Iris Oved, and Matthew Stone. 2006.\nSocietal grounding is essential to meaningful lan-\nguage use. In Proceedings of the National Confer-\nence on Artiﬁcial Intelligence, volume 21, page 747.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019.\nBERT: Pre-training of\nDeep Bidirectional Transformers for Language Un-\nderstanding. In North American Chapter of the As-\nsociation for Computational Linguistics (NAACL).\nEmily Dinan, Samuel Humeau, Bharath Chintagunta,\nand Jason Weston. 2019. Build it break it ﬁx it for\ndialogue safety: Robustness from adversarial human\nattack. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n4529–4538.\nSusan T. Dumais. 2004. Latent semantic analysis. An-\nnual Review of Information Science and Technology,\n38(1):188–230.\nRobin IM Dunbar. 1993. Coevolution of neocortical\nsize, group size and language in humans.\nBehav-\nioral and brain sciences, 16(4):681–694.\nYanai Elazar, Abhijit Mahabal, Deepak Ramachandran,\nTania Bedrax-Weiss, and Dan Roth. 2019.\nHow\nlarge are lions? inducing distributions over quanti-\ntative attributes. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 3973–3983.\nDesmond Elliott, Stella Frank, Khalil Sima’an, and Lu-\ncia Specia. 2016. Multi30k: Multilingual english-\ngerman image descriptions. In Workshop on Vision\nand Langauge at ACL ’16.\nJ Elman. 1990. Finding structure in time. Cognitive\nScience, 14(2):179–211.\nKatrin Erk and Sebastian Padó. 2008.\nA structured\nvector space model for word meaning in context.\nIn Proceedings of the 2008 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n897–906, Honolulu, Hawaii.\nSusan Ervin-Tripp. 1973. Some strategies for the ﬁrst\ntwo years. In Timothy E. Moore, editor, Cognitive\nDevelopment and Acquisition of Language, pages\n261 – 286. Academic Press, San Diego.\nAli Farhadi, M Hejrati, M Sadeghi, Peter Young, Cyrus\nRashtchian, Julia Hockenmaier, and David Forsyth.\n2010. Every picture tells a story: Generating sen-\ntences from images.\nIn European Conference on\nComputer Vision. Springer.\nYansong Feng and Mirella Lapata. 2010. Topic models\nfor image annotation and text illustration. In Human\nLanguage Technologies: The 2010 Annual Confer-\nence of the North American Chapter of the Associa-\ntion for Computational Linguistics, pages 831–839,\nLos Angeles, California.\nJ. R. Firth. 1957. A synopsis of linguistic theory, 1930-\n1955. Studies in Linguistic Analysis.\nCliff Fitzgerald. 2013.\nDeveloping baxter.\nIn 2013\nIEEE Conference on Technologies for Practical\nRobot Applications (TePRA).\nW. Nelson Francis. 1964.\nA standard sample of\npresent-day english for use with digital computers.\nReport to the U.S Ofﬁce of Education on Coopera-\ntive Research Project No. E-007.\nMichael C Frank and Noah D Goodman. 2012. Pre-\ndicting pragmatic reasoning in language games. Sci-\nence, 336(6084):998–998.\nRuiji Fu, Jiang Guo, Bing Qin, Wanxiang Che, Haifeng\nWang, and Ting Liu. 2014. Learning semantic hier-\narchies via word embeddings. In Proceedings of the\n52nd Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n1199–1209.\nMatt Gardner, Yoav Artzi, Victoria Basmova, Jonathan\nBerant, Ben Bogin, Sihao Chen, Pradeep Dasigi,\nDheeru Dua, Yanai Elazar, Ananth Gottumukkala,\nNitish Gupta, Hanna Hajishirzi, Gabriel Ilharco,\nDaniel Khashabi, Kevin Lin, Jiangming Liu, Nel-\nson F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer\nSingh, Noah A. Smith, Sanjay Subramanian, Reut\nTsarfaty, Eric Wallace, Ally Zhang, and Ben Zhou.\n2020.\nEvaluating NLP Models via Contrast Sets.\narXiv:2004.02709.\nMax Glockner, Vered Shwartz, and Yoav Goldberg.\n2018. Breaking nli systems with sentences that re-\nquire simple lexical inferences. In Proceedings of\nthe 56th Annual Meeting of the Association for Com-\nputational Linguistics (Volume 2:\nShort Papers),\npages 650–655.\nI J Good. 1953.\nThe population frequencies of\nspecies and the estimation of population parameters.\nBiometrika, 40:237–264.\nHerbert P Grice. 1975.\nLogic and conversation.\nIn\nSpeech acts, pages 41–58. Brill.\nSuchin Gururangan,\nSwabha Swayamdipta,\nOmer\nLevy, Roy Schwartz, Samuel Bowman, and Noah A\nSmith. 2018.\nAnnotation artifacts in natural lan-\nguage inference data. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 2 (Short Papers),\npages 107–112.\nStevan Harnad. 1990. The symbol grounding problem.\nPhysica D, 42:335–346.\nZellig S Harris. 1954. Distributional structure. Word,\n10:146–162.\nDavid Harwath, Wei-Ning Hsu, and James Glass. 2020.\nLearning hierarchical discrete linguistic units from\nvisually-grounded speech. In ICLR 2020.\nDavid Harwath, Adrià Recasens, Dídac Surís, Galen\nChuang, Antonio Torralba, and James Glass. 2019.\nJointly discovering visual objects and spoken words\nfrom raw sensory input.\nInternational Journal of\nComputer Vision.\nHe He, Derek Chen, Anusha Balakrishnan, and Percy\nLiang. 2018. Decoupling strategy and generation in\nnegotiation dialogues. In Proceedings of the 2018\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 2333–2343.\nSusan J. Hespos and Elizabeth S. Spelke. 2004. Con-\nceptual precursors to language. Nature, 430.\nG. E. Hinton, J. L. McClelland, and D. E. Rumelhart.\n1986.\nDistributed representations.\nParallel Dis-\ntributed Processing: Explorations in the Microstruc-\nture of Cognition, Volume 1: Foundations.\nGeoffrey E. Hinton. 1990. Preface to the special issue\non connectionist symbol processing. Artiﬁcial Intel-\nligence, 46(1):1 – 4.\nJulia Hirschberg and Christopher D Manning. 2015.\nAdvances in natural language processing. Science,\n349(6245):261–266.\nDouglas Hofstadter and Emmanuel Sander. 2013. Sur-\nfaces and essences: Analogy as the fuel and ﬁre of\nthinking. Basic Books.\nAri Holtzman, Jan Buys, Maxwell Forbes, and Yejin\nChoi. 2020. The curious case of neural text degener-\nation. In ICLR 2020.\nPo-Yao Huang, Junjie Hu, Xiaojun Chang, and Alexan-\nder Hauptmann. 2020.\nUnsupervised multimodal\nneural machine translation with pseudo visual piv-\noting.\nIn Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 8226–8237, Online.\nGabriel Ilharco, Yuan Zhang, and Jason Baldridge.\n2019. Large-scale representation learning from visu-\nally grounded untranscribed speech. In Proceedings\nof the 23rd Conference on Computational Natural\nLanguage Learning (CoNLL), pages 55–65, Hong\nKong, China.\nDaniel L. James and Risto Miikkulainen. 1995. Sard-\nnet: A self-organizing feature map for sequences. In\nAdvances in Neural Information Processing Systems\n7 (NIPS’94), pages 577–584, Denver, CO. Cam-\nbridge, MA: MIT Press.\nMichael I Jordan. 2019. Artiﬁcial intelligence – the rev-\nolution hasn’t happened yet. Harvard Data Science\nReview.\nDivyansh Kaushik, Eduard Hovy, and Zachary Lipton.\n2020. Learning the difference that makes a differ-\nence with counterfactually-augmented data. In Inter-\nnational Conference on Learning Representations.\nNitish\nShirish\nKeskar,\nBryan\nMcCann,\nLav\nR\nVarshney, Caiming Xiong, and Richard Socher.\n2019. CTRL: A conditional transformer language\nmodel for controllable generation.\narXiv preprint\narXiv:1909.05858.\nReinhard Kneser and Hermann Ney. 1995. Improved\nbacking-off for m-gram language modeling. In Pro-\nceedings of the IEEE International Conference on\nAcoustics, Speech and Signal Processing.\nTeuvo Kohonen. 1984. Self-Organization and Associa-\ntive Memory. Springer.\nRanjay Krishna, Yuke Zhu, Oliver Groth, Justin John-\nson, Kenji Hata, Joshua Kravitz, Stephanie Chen,\nYannis Kalantidis, Li-Jia Li, David A Shamma,\nMichael S. Bernstein, and Fei-Fei Li. 2017.\nVi-\nsual genome: Connecting language and vision us-\ning crowdsourced dense image annotations. Interna-\ntional Journal of Computer Vision, 123(1):32–73.\nAlex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-\nton. 2012.\nImagenet classiﬁcation with deep con-\nvolutional neural networks. In F. Pereira, C. J. C.\nBurges, L. Bottou, and K. Q. Weinberger, editors,\nAdvances in Neural Information Processing Systems\n25, pages 1097–1105. Curran Associates, Inc.\nGeorge Lakoff. 1973.\nHedges: A study in meaning\ncriteria and the logic of fuzzy concepts. Journal of\nPhilosophical Logic, 2:458–508.\nGeorge Lakoff. 1980. Metaphors We Live By. Univer-\nsity of Chicago Press.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2020. Albert: A lite bert for self-supervised learning\nof language representations. In International Con-\nference on Learning Representations.\nRonald W Langacker. 1987.\nFoundations of cogni-\ntive grammar: Theoretical prerequisites, volume 1.\nStanford university press.\nRonald W Langacker. 1991. Foundations of Cognitive\nGrammar: descriptive application., volume 2. Stan-\nford university press.\nAngeliki Lazaridou, Karl Moritz Hermann, Karl Tuyls,\nand Stephen Clark. 2018.\nEmergence of linguis-\ntic communication from referential games with sym-\nbolic and pixel input. In Internationl Conference on\nLearning Representations.\nAngeliki Lazaridou, Alexander Peysakhovich, and\nMarco Baroni. 2017. Multi-agent cooperation and\nthe emergence of (natural) language. In ICLR 2017.\nAngeliki Lazaridou, Nghia The Pham, and Marco Ba-\nroni. 2016. The red one!: On learning to refer to\nthings based on discriminative properties. In Pro-\nceedings of the 54th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 2: Short\nPapers), pages 213–218, Berlin, Germany.\nMatthew Le, Y-Lan Boureau, and Maximilian Nickel.\n2019. Revisiting the evaluation of theory of mind\nthrough question answering. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 5871–5876, Hong Kong,\nChina.\nMike Lewis, Denis Yarats, Yann Dauphin, Devi Parikh,\nand Dhruv Batra. 2017. Deal or no deal? end-to-end\nlearning of negotiation dialogues. In Proceedings of\nthe 2017 Conference on Empirical Methods in Natu-\nral Language Processing, pages 2443–2453.\nLiunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui\nHsieh, and Kai-Wei Chang. 2019a. VisualBERT: A\nSimple and Performant Baseline for Vision and Lan-\nguage. In Work in Progress.\nYong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue\nXu, Mingyang Chen, Ze Ma, Shiyi Wang, Hao-Shu\nFang, and Cewu Lu. 2019b. HAKE: Human Activ-\nity Knowledge Engine. arXiv:1904.06539.\nLing-Yi Lin, Rong-Ju Cherng, and Yung-Jung Chen.\n2017. Effect of touch screen tablet use on ﬁne motor\ndevelopment of young children. Physical & Occupa-\ntional Therapy In Pediatrics, 37(5):457–467. PMID:\n28071977.\nTal Linzen. 2020. How can we accelerate progress to-\nwards human-like linguistic generalization?\nIn As-\nsociation for Computational Linguistics (ACL).\nChangsong Liu and Joyce Yue Chai. 2015. Learning\nto mediate perceptual differences in situated human-\nrobot dialogue.\nIn Proceedings of the 29th AAAI\nConference on Artiﬁcial Intelligence, pages 2288–\n2294.\nChia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Nose-\nworthy, Laurent Charlin, and Joelle Pineau. 2016.\nHow not to evaluate your dialogue system: An em-\npirical study of unsupervised evaluation metrics for\ndialogue response generation. In Proceedings of the\n2016 Conference on Empirical Methods in Natural\nLanguage Processing, pages 2122–2132.\nZiwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou\nTang. 2015. Deep learning face attributes in the wild.\nIn Proceedings of International Conference on Com-\nputer Vision (ICCV).\nJiasen Lu, Dhruv Batra, Devi Parikh, and Stefan\nLee. 2019. Vilbert: Pretraining task-agnostic visi-\nolinguistic representations for vision-and-language\ntasks. In Advances in Neural Information Process-\ning Systems, pages 13–23.\nLi Lucy and Jon Gauthier. 2017.\nAre distributional\nrepresentations ready for the real world?\nevaluat-\ning word vectors for grounded perceptual meaning.\nIn Proceedings of the First Workshop on Language\nGrounding for Robotics, pages 76–85, Vancouver,\nCanada. Association for Computational Linguistics.\nMatt MacMahon, Brian Stankiewicz, and Benjamin\nKuipers. 2006. Walk the talk: Connecting language,\nknowledge, and action in route instructions. In Pro-\nceedings of the 21st National Conference on Artiﬁ-\ncial Intelligence (AAAI-2006), Boston, MA, USA.\nGary Marcus and Ernest Davis. 2019. Rebooting AI:\nBuilding Artiﬁcial Intelligence We Can Trust. Pan-\ntheon.\nMitchell P Marcus, Beatrice Santorini, and Mary Ann\nMarcinkiewicz. 1993.\nBuilding a large annotated\ncorpus of english: The penn treebank.\nComputa-\ntional Linguistics, 19:313–330.\nLara J Martin, Prithviraj Ammanabrolu, Xinyu Wang,\nWilliam Hancock, Shruti Singh, Brent Harrison, and\nMark O Riedl. 2018. Event representations for au-\ntomated story generation with deep neural nets. In\nThirty-Second AAAI Conference on Artiﬁcial Intelli-\ngence.\nCynthia Matuszek. 2018.\nGrounded language learn-\ning: Where robotics and nlp meet (early career spot-\nlight). In Proceedings of the 27th International Joint\nConference on Artiﬁcial Intelligence (IJCAI), Stock-\nholm, Sweden.\nBryan McCann, James Bradbury, Caiming Xiong, and\nRichard Socher. 2017. Learned in translation: Con-\ntextualized word vectors. In Advances in Neural In-\nformation Processing Systems, pages 6297–6308.\nJames L. McClelland, Felix Hill, Maja Rudolph, Ja-\nson Baldridge, and Hinrich Schütze. 2019.\nEx-\ntending Machine Language Models toward Human-\nLevel Language Understanding. arXiv:1912.05877.\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-\nrado, and Jeffrey Dean. 2013. Distributed represen-\ntations of words and phrases and their composition-\nality. Advances in Neural Information Processing\nSystems, 26.\nMargaret Mitchell, Jesse Dodge, Amit Goyal, Kota Ya-\nmaguchi, Karl Stratos, Xufeng Han, Alyssa Men-\nsch, Alexander C. Berg, Tamara L. Berg, and Hal\nDaumé III. 2012. Midge: Generating image descrip-\ntions from computer vision detections. In European\nChapter of the Association for Computational Lin-\nguistics (EACL).\nTom M Mitchell. 1980. The need for biases in learning\ngeneralizations. Department of Computer Science,\nLaboratory for Computer Science Research.\nRaymond J. Mooney. 2008. Learning to connect lan-\nguage and perception. In Proceedings of the 23rd\nAAAI Conference on Artiﬁcial Intelligence (AAAI),\npages 1598–1601, Chicago, IL. Senior Member Pa-\nper.\nRaymond J Mooney and Gerald Dejong. 1985. Learn-\ning schemata for natural language processing.\nIn\nProceedings of the Ninth International Joint Confer-\nence on Artiﬁcial Intelligence (IJCAI-85).\nDaniele Moro and Casey Kennington. 2018.\nMulti-\nmodal visual and simulated muscle activations for\ngrounded semantics of hand-related descriptions. In\nWorkshop on the Semantics and Pragmatics of Dia-\nlogue. SEMDIAL.\nRoozbeh Mottaghi, Mohammad Rastegari, Abhinav\nGupta, and Ali Farhadi. 2016. “what happens if...”\nlearning to predict the effect of forces in images.\nIn Computer Vision – ECCV 2016, pages 269–285,\nCham. Springer International Publishing.\nAdithyavairavan Murali, Tao Chen, Kalyan Vasudev\nAlwala, Dhiraj Gandhi, Lerrel Pinto, Saurabh Gupta,\nand Abhinav Gupta. 2019. Pyrobot: An open-source\nrobotics framework for research and benchmarking.\narXiv preprint arXiv:1906.08236.\nAida Nematzadeh, Kaylee Burns, Erin Grant, Alison\nGopnik, and Tom Grifﬁths. 2018. Evaluating theory\nof mind in question answering. In Proceedings of\nthe 2018 Conference on Empirical Methods in Natu-\nral Language Processing, pages 2392–2400.\nNVIDIA. 2019.\nNVIDIA Isaac software develop-\nment kit.\nhttps://developer.nvidia.com/\nisaac-sdk. Accessed 2019-12-09.\nElinor Ochs. 1993. Constructing social identity: A lan-\nguage socialization perspective.\nResearch on lan-\nguage and social interaction, 26(3):287–306.\nWilliam O’Grady. 2005.\nHow Children Learn Lan-\nguage. Cambridge University Press.\nVeronica Ornaghi, Jens Brockmeier, and Ilaria Graz-\nzani Gavazzi. 2011. The role of language games in\nchildren’s understanding of mental states: A train-\ning study.\nJournal of cognition and development,\n12(2):239–259.\nAlexander Ororbia, Ankur Mali, Matthew Kelly, and\nDavid Reitter. 2019. Like a baby: Visually situated\nneural language acquisition. In Proceedings of the\n57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 5127–5136, Florence,\nItaly.\nDenis Paperno, Germán Kruszewski, Angeliki Lazari-\ndou, Ngoc-Quan Pham, Raffaella Bernardi, San-\ndro Pezzelle, Marco Baroni, Gemma Boleda, and\nRaquel Fernández. 2016. The LAMBADA dataset:\nWord prediction requiring a broad discourse context.\nIn Proceedings of the 54th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 1525–1534.\nRohan Paul, Jacob Arkin, Derya Aksaray, Nicholas\nRoy, and Thomas M Howard. 2018.\nEfﬁcient\ngrounding of abstract spatial concepts for nat-\nural language interaction with robot platforms.\nThe International Journal of Robotics Research,\n37(10):1269–1299.\nHaoruo Peng, Daniel Khashabi, and Dan Roth. 2015.\nSolving hard coreference problems. In Proceedings\nof the 2015 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 809–819.\nJeffrey Pennington, Richard Socher, and Christopher\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In Proceedings of the 2014 Conference\non Empirical Methods in Natural Language Process-\ning (EMNLP), pages 1532–1543, Doha, Qatar.\nDon Perlis. 2016. Five dimensions of reasoning in the\nwild. In Association for the Advancement of Artiﬁ-\ncial Intelligence (AAAI).\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word repre-\nsentations. In North American Chapter of the Asso-\nciation for Computational Linguistics (NAACL).\nJohn R Pierce. 1969.\nWhither speech recognition?\nThe journal of the acoustical society of america,\n46(4B):1049–1051.\nNicolas Pinto, David Doukhan, James J DiCarlo, and\nDavid D Cox. 2009. A high-throughput screening\napproach to discovering good forms of biologically\ninspired visual representation. PLoS computational\nbiology, 5(11):e1000579.\nJordan B. Pollack. 1987. On Connectionist Models of\nNatural Language Processing. Ph.D. thesis, Univer-\nsity of Illinois.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nPranav Rajpurkar, Robin Jia, and Percy Liang. 2018.\nKnow what you don’t know: Unanswerable ques-\ntions for SQuAD. In Proceedings of the 56th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 2: Short Papers), pages 784–789.\nHannah Rashkin, Eric Michael Smith, Margaret Li, and\nY-Lan Boureau. 2019.\nTowards empathetic open-\ndomain conversation models: A new benchmark and\ndataset.\nIn Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 5370–5381, Florence, Italy.\nMichaela Regneri, Marcus Rohrbach, Dominikus Wet-\nzel, Stefan Thater, Bernt Schiele, and Manfred\nPinkal. 2013.\nGrounding action descriptions in\nvideos. Transactions of the Association for Compu-\ntational Linguistics (TACL), 1:25–36.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju,\nMary Williamson, Yinhan Liu, Jing Xu, Myle Ott,\nKurt Shuster, Eric M. Smith, Y-Lan Boureau, and\nJason Weston. 2020. Recipes for building an open-\ndomain chatbot. In arXiv.\nStephanie Rosenthal, Joydeep Biswas, and Manuela\nVeloso. 2010. An effective personal mobile robot\nagent through symbiotic human-robot interaction.\nIn Proceedings of the 9th International Conference\non Autonomous Agents and Multiagent Systems: vol-\nume 1-Volume 1, pages 915–922. International Foun-\ndation for Autonomous Agents and Multiagent Sys-\ntems.\nCorby Rosset. 2020.\nTuring-NLG: A 17-billion-\nparameter language model by Microsoft.\nOlga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,\nSanjeev Satheesh, Sean Ma, Zhiheng Huang, An-\ndrej Karpathy, Aditya Khosla, Michael Bernstein,\nAlexander C. Berg, and Li Fei-Fei. 2015.\nIma-\ngeNet Large Scale Visual Recognition Challenge.\nInternational Journal of Computer Vision (IJCV),\n115(3):211–252.\nJacqueline Sachs, Barbara Bard, and Marie L Johnson.\n1981. Language learning with restricted input: Case\nstudies of two hearing children of deaf parents. Ap-\nplied Psycholinguistics, 2(1):33–54.\nIan Sample and Alex Hern. 2014. Scientists dispute\nwhether computer ‘eugene goostman‘ passed turing\ntest. The Guardian, 9.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan\nLe Bras, and Yejin Choi. 2019. Social IQa: Com-\nmonsense reasoning about social interactions.\nIn\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 4462–\n4472, Hong Kong, China.\nRosario Scalise, Jesse Thomason, Yonatan Bisk, and\nSiddhartha Srinivasa. 2019.\nImproving robot suc-\ncess detection using static object data. In Proceed-\nings of the 2019 IEEE/RSJ International Conference\non Intelligent Robots and Systems.\nRoger C. Schank and Robert P. Abelson. 1977. Scripts,\nPlans, Goals and Understanding: an Inquiry into\nHuman Knowledge Structures.\nL. Erlbaum, Hills-\ndale, NJ.\nMarten van Schijndel,\nAaron Mueller,\nand Tal\nLinzen. 2019.\nQuantity doesn’t buy quality syn-\ntax with neural language models.\narXiv preprint\narXiv:1909.00111.\nDavid Schlangen. 2019a. Grounded agreement games:\nEmphasizing conversational grounding in visual dia-\nlogue settings. arXiv.\nDavid Schlangen. 2019b. Language tasks and language\ngames: On methodology in current natural language\nprocessing research. arXiv.\nIulian V. Serban, Chinnadhurai Sankar, Mathieu Ger-\nmain, Saizheng Zhang, Zhouhan Lin, Sandeep Sub-\nramanian, Taesup Kim, Michael Pieper, Sarath\nChandar, Nan Rosemary Ke, Sai Rajeshwar, Alexan-\ndre de Brebisson,\nJose M. R. Sotelo,\nDendi\nSuhubdy, Vincent Michalski, Alexandre Nguyen,\nJoelle Pineau, and Yoshua Bengio. 2017. A deep\nreinforcement learning chatbot.\narXiv preprint\narXiv:1709.02349.\nPiyush Sharma, Nan Ding, Sebastian Goodman, and\nRadu Soricut. 2018.\nConceptual captions:\nA\ncleaned, hypernymed, image alt-text dataset for au-\ntomatic image captioning.\nIn Proceedings of the\n56th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n2556–2565, Melbourne, Australia.\nLanbo She, Shaohua Yang, Yu Cheng, Yunyi Jia,\nJoyce Y. Chai, and Ning Xi. 2014.\nBack to the\nblocks world: Learning new actions through situated\nhuman-robot dialogue. In Proceedings of 15th SIG-\nDIAL Meeting on Discourse and Dialogue.\nHaoyue Shi, Jiayuan Mao, Kevin Gimpel, and Karen\nLivescu. 2019. Visually grounded neural syntax ac-\nquisition. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 1842–1861, Florence, Italy.\nMohammad Shoeybi, Mostofa Patwary, Raul Puri,\nPatrick LeGresley, Jared Casper, and Bryan Catan-\nzaro. 2019.\nMegatron-lm: Training multi-billion\nparameter language models using gpu model paral-\nlelism. arXiv preprint arXiv:1909.08053.\nMohit Shridhar, Jesse Thomason, Daniel Gordon,\nYonatan Bisk, Winson Han, Roozbeh Mottaghi,\nLuke Zettlemoyer, and Dieter Fox. 2020. ALFRED:\nA benchmark for interpreting grounded instructions\nfor everyday tasks.\nComputer Vision and Pattern\nRecognition (CVPR).\nCarina Silberer and Mirella Lapata. 2014.\nLearn-\ning grounded meaning representations with autoen-\ncoders. In Proceedings of the 52nd Annual Meet-\ning of the Association for Computational Linguis-\ntics (Volume 1: Long Papers), pages 721–732, Balti-\nmore, Maryland.\nJivko Sinapov,\nConnor Schenck,\nand Alexander\nStoytchev. 2014.\nLearning relational object cate-\ngories using behavioral exploration and multimodal\nperception.\nIn IEEE International Conference on\nRobotics and Automation.\nLinda Smith and Michael Gasser. 2005. The develop-\nment of embodied cognition: Six lessons from ba-\nbies. Artiﬁcial life, 11(1-2):13–29.\nPaul Smolensky. 1990. Tensor product variable bind-\ning and the representation of symbolic structures\nin connectionist systems.\nArtiﬁcial Intelligence,\n46:159–216.\nRichard Socher, Brody Huval, Christopher Manning,\nand Andrew Ng. 2012.\nSemantic compositional-\nity through recursive matrix-vector spaces. In Em-\npirical Methods in Natural Language Processing\n(EMNLP).\nT. Srinivasan, R. Sanabria, and F. Metze. 2020. Look-\ning enhances listening: Recovering missing speech\nusing images. In ICASSP 2020 - 2020 IEEE Interna-\ntional Conference on Acoustics, Speech and Signal\nProcessing (ICASSP), pages 6304–6308.\nMark Steedman. 2008. Last words: On becoming a dis-\ncipline. Computational Linguistics, 34(1):137–144.\nGreg J Stephens, Lauren J Silbert, and Uri Hasson.\n2010.\nSpeaker–listener neural coupling underlies\nsuccessful communication. Proceedings of the Na-\ntional Academy of Sciences, 107(32):14425–14430.\nAlane Suhr, Claudia Yan, Jack Schluger, Stanley Yu,\nHadi Khader, Marwa Mouallem, Iris Zhang, and\nYoav Artzi. 2019a. Executing instructions in situ-\nated collaborative interactions.\nIn Proceedings of\nthe 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 2119–2130, Hong Kong,\nChina.\nAlane Suhr, Stephanie Zhou, Ally Zhang, Iris Zhang,\nHuajun Bai, and Yoav Artzi. 2019b. A corpus for\nreasoning about natural language grounded in pho-\ntographs. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 6418–6428, Florence, Italy.\nChen Sun,\nFabien Baradel,\nKevin Murphy,\nand\nCordelia Schmid. 2019a. Contrastive bidirectional\ntransformer for temporal representation learning.\narxiv:1906.05743.\nChen Sun, Austin Myers, Carl Vondrick, Kevin Mur-\nphy, and Cordelia Schmid. 2019b. VideoBERT: A\nJoint Model for Video and Language Representation\nLearning. In International Conference on Computer\nvision.\nYee-Whye Teh. 2006.\nA hierarchical bayesian lan-\nguage model based on pitman-yor processes.\nIn\nProceedings of the 21st International Conference on\nComputational Linguistics and 44th Annual Meet-\ning of the Association for Computational Linguistics,\npages 985–992, Sydney, Australia.\nStefanie Tellex, Nakul Gopalan, Hadas Kress-Gazit,\nand Cynthia Matuszek. 2020. Robots that use lan-\nguage. The Annual Review of Control, Robotics, and\nAutonomous Systems, 15.\nStefanie Tellex, Ross Knepper, Adrian Li, Daniela Rus,\nand Nicholas Roy. 2014. Asking for help using in-\nverse semantics. In Proceedings of Robotics: Sci-\nence and Systems (RSS), Berkeley, California.\nStefanie Tellex, Thomas Kollar, Steven Dickerson,\nMatthew R Walter, Ashis Gopal Banerjee, Seth\nTeller, and Nicholas Roy. 2011. Understanding nat-\nural language commands for robotic navigation and\nmobile manipulation.\nIn Proceedings of the Na-\ntional Conference on Artiﬁcial Intelligence.\nIan Tenney, Dipanjan Das, and Ellie Pavlick. 2019.\nBERT rediscovers the classical NLP pipeline.\nIn\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 4593–\n4601, Florence, Italy.\nEsther Thelen and Linda B. Smith. 1996. A Dynamic\nSystems Approach to the Development of Cognition\nand Action. MIT Press.\nJesse Thomason, Daniel Gordon, and Yonatan Bisk.\n2019a. Shifting the baseline: Single modality perfor-\nmance on visual navigation & QA. In North Amer-\nican Chapter of the Association for Computational\nLinguistics (NAACL).\nJesse Thomason, Michael Murray, Maya Cakmak, and\nLuke Zettlemoyer. 2019b. Vision-and-dialog navi-\ngation. In Conference on Robot Learning (CoRL).\nJesse Thomason,\nAishwarya Padmakumar,\nJivko\nSinapov, Justin Hart, Peter Stone, and Raymond J.\nMooney. 2017.\nOpportunistic active learning for\ngrounding natural language descriptions.\nIn Pro-\nceedings of the 1st Annual Conference on Robot\nLearning (CoRL).\nJesse Thomason,\nAishwarya Padmakumar,\nJivko\nSinapov, Nick Walker, Yuqian Jiang, Harel Yedid-\nsion, Justin Hart, Peter Stone, and Raymond J.\nMooney. 2020. Jointly improving parsing and per-\nception for natural language commands through\nhuman-robot dialog. The Journal of Artiﬁcial Intel-\nligence Research (JAIR), 67.\nJesse Thomason, Jivko Sinapov, Maxwell Svetlik, Pe-\nter Stone, and Raymond J. Mooney. 2016. Learning\nmulti-modal grounded linguistic semantics by play-\ning “I spy”. In International Joint Conference on\nArtiﬁcial Intelligence (IJCAI).\nEmanuel Todorov, Tom Erez, and Yuval Tassa. 2012.\nMujoco: A physics engine for model-based con-\ntrol.\nIn 2012 IEEE/RSJ International Conference\non Intelligent Robots and Systems, pages 5026–5033.\nIEEE.\nMichael Tomasello. 2009.\nConstructing a language.\nHarvard university press.\nYao-Hung Hubert Tsai, Shaojie Bai, Paul Pu Liang,\nJ. Zico Kolter, Louis-Philippe Morency, and Rus-\nlan Salakhutdinov. 2019.\nMultimodal transformer\nfor unaligned multimodal language sequences. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 6558–\n6569, Florence, Italy.\nJoseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.\n2010. Word representations: A simple and general\nmethod for semi-supervised learning. In Proceed-\nings of the 48th Annual Meeting of the Association\nfor Computational Linguistics, pages 384–394.\nAlan M Turing. 1950. Computing machinery and intel-\nligence. Mind.\nPeter D Turney and Patrick Pantel. 2010.\nFrom fre-\nquency to meaning:\nVector space models of se-\nmantics. Journal of artiﬁcial intelligence research,\n37:141–188.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998–6008.\nGabriella Vigliocco, Pamela Perniss, and David Vinson.\n2014. Language as a multimodal phenomenon: im-\nplications for language learning, processing and evo-\nlution.\nHarm de Vries, Dzmitry Bahdanau, and Christopher\nManning. 2020.\nTowards ecologically valid re-\nsearch on language user interfaces. In arXiv.\nMatthew Walter,\nSachithra Hemachandra,\nBianca\nHomberg, Stefanie Tellex, and Seth Teller. 2013.\nLearning semantic maps from natural language de-\nscriptions. In Proceedings of Robotics: Science and\nSystems (RSS), Berlin, Germany.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R Bowman. 2019a.\nGLUE: A multi-task benchmark and analysis plat-\nform for natural language understanding. In Inter-\nnational Conference on Learning Representations.\nXin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan-\nFang Wang, and William Yang Wang. 2019b. Vatex:\nA large-scale, high-quality multilingual dataset for\nvideo-and-language research. In The IEEE Interna-\ntional Conference on Computer Vision (ICCV).\nRonald Wardhaugh. 2011. An introduction to sociolin-\nguistics, volume 28. John Wiley & Sons.\nJoseph Weizenbaum. 1966.\nEliza – a computer pro-\ngram for the study of natural language communica-\ntion between man and machine. Communications of\nthe ACM, 9(1):36–45.\nLloyd R Welch. 2003. Hidden markov models and the\nbaum-welch algorithm. IEEE Information Theory\nSociety Newsletter, 53(4):1–24.\nGregory M Werner and Michael G Dyer. 1991. Evolu-\ntion of communication in artiﬁcial organisms. ALife.\nTerry Winograd. 1971. Procedures as a representation\nfor data in a computer program for understanding\nnatural language. Technical report, Massachusetts\nInstitute of Technology, Project MAC.\nLudwig Wittgenstein. 1953. Philosophical Investiga-\ntions. Macmillan.\nLudwig Wittgenstein. 1958. The blue and brown books.\nBasil Blackwell.\nFanbo Xiang, Yuzhe Qin, Kaichun Mo, Yikuan Xia,\nHao Zhu, Fangchen Liu, Minghua Liu, Hanxiao\nJiang, Yifu Yuan, He Wang, Li Yi, Angel X. Chang,\nLeonidas J. Guibas, and Hao Su. 2020. SAPIEN:\nA simulated part-based interactive environment. In\nComputer Vision and Pattern Recognition (CVPR).\nSemih Yagcioglu, Aykut Erdem, Erkut Erdem, and Na-\nzli Ikizler-Cinbis. 2018.\nRecipeQA: A challenge\ndataset for multimodal comprehension of cooking\nrecipes. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1358–1368, Brussels, Belgium.\nDiyi Yang, Jiaao Chen, Zichao Yang, Dan Jurafsky, and\nEduard Hovy. 2019a. Let’s make your request more\npersuasive: Modeling persuasive strategies via semi-\nsupervised neural nets on crowdfunding platforms.\nIn Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long and Short Papers).\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Ruslan Salakhutdinov, and Quoc V Le.\n2019b. Xlnet: Generalized autoregressive pretrain-\ning for language understanding. In Advances in Neu-\nral Information Processing Systems 32 (NIPS 2019).\nMark Yatskar, Luke Zettlemoyer, and Ali Farhadi.\n2016. Situation recognition: Visual semantic role\nlabeling for image understanding. In Conference on\nComputer Vision and Pattern Recognition.\nAmir Zadeh, Michael Chan, Paul Pu Liang, Edmund\nTong, and Louis-Philippe Morency. 2019. Social-iq:\nA question answering benchmark for artiﬁcial social\nintelligence. In The IEEE Conference on Computer\nVision and Pattern Recognition (CVPR).\nRowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin\nChoi. 2019a.\nFrom recognition to cognition: Vi-\nsual commonsense reasoning. In The IEEE Confer-\nence on Computer Vision and Pattern Recognition\n(CVPR).\nRowan Zellers, Ari Holtzman, Elizabeth Clark, Lianhui\nQin, Ali Farhadi, and Yejin Choi. 2020. Evaluating\nmachines by their real-world language use. arXiv\npreprint arXiv:2004.03607.\nRowan Zellers,\nAri Holtzman,\nHannah Rashkin,\nYonatan Bisk, Ali Farhadi, Franziska Roesner, and\nYejin Choi. 2019b. Defending against neural fake\nnews. In Thirty-third Conference on Neural Infor-\nmation Processing Systems.\nLi Zhou, Jianfeng Gao, Di Li, and Heung-Yeung Shum.\n2020. The design and implementation of xiaoice, an\nempathetic social chatbot. Computational Linguis-\ntics, 46(1):53–93.\nLuowei Zhou, Hamid Palangi, Lei Zhang, Houdong\nHu, Jason J. Corso, and Jianfeng Gao. 2019. Uni-\nﬁed vision-language pre-training for image caption-\ning and vqa. In Thirty-Fourth AAAI Conference on\nArtiﬁcial Intelligence.\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG"
  ],
  "published": "2020-04-21",
  "updated": "2020-11-02"
}