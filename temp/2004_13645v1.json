{
  "id": "http://arxiv.org/abs/2004.13645v1",
  "title": "Unnatural Language Processing: Bridging the Gap Between Synthetic and Natural Language Data",
  "authors": [
    "Alana Marzoev",
    "Samuel Madden",
    "M. Frans Kaashoek",
    "Michael Cafarella",
    "Jacob Andreas"
  ],
  "abstract": "Large, human-annotated datasets are central to the development of natural\nlanguage processing models. Collecting these datasets can be the most\nchallenging part of the development process. We address this problem by\nintroducing a general purpose technique for ``simulation-to-real'' transfer in\nlanguage understanding problems with a delimited set of target behaviors,\nmaking it possible to develop models that can interpret natural utterances\nwithout natural training data. We begin with a synthetic data generation\nprocedure, and train a model that can accurately interpret utterances produced\nby the data generator. To generalize to natural utterances, we automatically\nfind projections of natural language utterances onto the support of the\nsynthetic language, using learned sentence embeddings to define a distance\nmetric. With only synthetic training data, our approach matches or outperforms\nstate-of-the-art models trained on natural language data in several domains.\nThese results suggest that simulation-to-real transfer is a practical framework\nfor developing NLP applications, and that improved models for transfer might\nprovide wide-ranging improvements in downstream tasks.",
  "text": "Unnatural Language Processing:\nBridging the Gap Between Synthetic and Natural Language Data\nAlana Marzoev 1 Samuel Madden 1 M. Frans Kaashoek 1 Michael Cafarella 2 Jacob Andreas 1\nAbstract\nLarge, human-annotated datasets are central to\nthe development of natural language processing\nmodels. Collecting these datasets can be the most\nchallenging part of the development process. We\naddress this problem by introducing a general-\npurpose technique for “simulation-to-real\" trans-\nfer in language understanding problems with a\ndelimited set of target behaviors, making it pos-\nsible to develop models that can interpret natural\nutterances without natural training data.\nWe begin with a synthetic data generation proce-\ndure, and train a model that can accurately inter-\npret utterances produced by the data generator. To\ngeneralize to natural utterances, we automatically\nﬁnd projections of natural language utterances\nonto the support of the synthetic language, using\nlearned sentence embeddings to deﬁne a distance\nmetric. With only synthetic training data, our ap-\nproach matches or outperforms state-of-the-art\nmodels trained on natural language data in several\ndomains. These results suggest that simulation-\nto-real transfer is a practical framework for de-\nveloping NLP applications, and that improved\nmodels for transfer might provide wide-ranging\nimprovements in downstream tasks.\n1. Introduction\nData collection remains a major obstacle to the develop-\nment of learned models for new language processing appli-\ncations. Large text corpora are available for learning tasks\nlike language modeling and machine translation (Callison-\nBurch et al., 2011; Chelba et al., 2013). But other classes of\nNLP models—especially those that interact with the outside\nworld, whether via API calls (e.g., for question answering)\nor physical actuators (e.g., for personal robotics)—require\ncustom datasets that capture both the full scope of desired\n1Massachusetts Institute of Technology 2University of Michi-\ngan. Correspondence to: Alana Marzoev <marzoev@mit.edu>.\nbehavior in addition to the possible variation in human lan-\nguage. Collecting these large, human-annotated training\nsets can be an expensive and time-consuming undertaking\n(Zelle, 1995). In domains governed by well-deﬁned math-\nematical models, such as physics simulators and graphics\nengines, one solution to the data scarcity problem prob-\nlem is “simulation-to-real\" transfer (Tzeng et al., 2016). In\nsim-to-real approaches, knowledge gained in a simulated\nenvironment is later applied in the real world with the ulti-\nmate aim of generalizing despite discrepancies between the\nsimulated environment and reality.\nIn this paper, we explore sim-to-real transfer for natural\nlanguage processing. We use simple, high-precision gram-\nmars as “simulators\" to generate synthetic training data\nfor question answering and instruction following problems.\nWhile synthetic data generation provides potentially un-\nlimited supervision for the learning of these behaviors, in-\nterpretation of synthetic utterances may itself constitute a\nchallenging machine learning problem when the desired\noutputs require nontrivial inference for parsing, planning\nor perception (Luketina et al., 2019). Given a model with\nhigh accuracy on the synthetic training distribution, we in-\nterpret natural user utterances from outside this distribution\nby mapping each natural utterance to a synthetic one and\ninterpreting the synthetic utterance with the learned model.\nUsing pretrained sentence embeddings (Devlin et al., 2018),\nwe deﬁne an (approximately) meaning-preserving projec-\ntion operation from the set of all sentences to those the\nmodel has been trained to interpret. Together, labeled syn-\nthetic utterances and unsupervised representation learning\nenable generalization to real language.\nThrough experiments, we demonstrate the effectiveness of\nsim-to-real transfer on a variety of domains. On a suite of\neight semantic parsing datasets (Wang et al., 2015), sim-\nto-real matches the performance of a supervised seman-\ntic parser on three of eight tasks using no natural training\ndata. On a grounded instruction following benchmark in-\nvolving challenging navigation in a gridworld environment\n(Chevalier-Boisvert et al., 2018), our approach to sim-to-\nreal transfer again surpasses the performance of a standard\nmodel ﬁne-tuned with human annotations.\nThese results indicate the promise of sim-to-real as a devel-\narXiv:2004.13645v1  [cs.CL]  28 Apr 2020\nUnnatural Language Processing\n(a) Synthetic data generation\n(b) Base model training\n(c) Representation learning\n(d) Projection\ngrammar\nsynthetic \ndataset\nput the blue ball next to the red box \ngrasp turn move move turn …\npick up the blue ball \nmove grasp …\nI want the dark blue  \ncrate adjacent to the  \nopening \nput the blue box  \nnext to the door\npick up the  \nblue ball\nmove grasp …\nhis milk used to arrive in blue plastic crates\nthe red sun is high, the blue low\n…\nmove …\nFigure 1. Overview of our approach to synthetic-to-real transfer in language understanding tasks. (a) Training examples are generated\nfrom a synthetic data generation procedure that covers desired model behaviors but a limited range of linguistic variation. (b) This data is\nused to train a model that can correctly interpret synthetic utterances. (c) Separately, sentence representations are learned using a masked\nlanguage modeling scheme like BERT. (d) To interpret human-generated model inputs from a broader distribution, we ﬁrst project onto\nthe set of sentences reachable by the synthetic data generation procedure, and then interpret the projected sentence with the trained model.\nopment paradigm for natural language processing applica-\ntions. By leveraging two cheap, readily-available sources\nof supervision—unaligned natural language text and syn-\nthetic language about target tasks—it is possible to build\nbroad-coverage systems for language understanding with-\nout a labor-intensive annotation process. Improved models\nfor sim-to-real could lead to positive and wide-ranging ef-\nfects on downstream tasks and applications. To encourage\nprogress on models for transfer and to further reduce the\ndeveloper effort associated with building new grounded\nlanguage understanding, we release (1) a set of new hu-\nman annotations for a popular policy learning benchmark\nwith synthetic instructions and (2) code implementing the\nsentence-projection operation.1\n2. Grammar engineering for grounded\nlanguage learning\nSim-to-real transfer requires to a simulator: an automated\nprocedure that can generate labeled input–output examples.\nThe experiments in this paper focus on two language un-\nderstanding problems: question answering and instruction\nfollowing. Both problems require mapping natural language\ninputs (e.g., go to the red door) to concrete interpretations\n(e.g., a program (go-to (location red_door)), which\nmay be executed to produce a sequence of situated low-level\nactions (move, turn_r, move, move)). Many different\nsentences may be associated with the same program (ﬁnd a\nred door, navigate to the red door, etc.).\nA simulator for situated language understanding can be\n1Available at https://github.com/unnatural-language/sim2real.\nimplemented as an injective expert-designed inverse func-\ntion, possibly multi-valued, mapping each program (e.g.,\n(go-to (location yellow_door)) to a set of distinct in-\nput sentences that induce the program (e.g., “go to the lo-\ncation of the yellow door”). This inverse function deﬁnes\na synthetic data generation procedure for the task, a direct\nmapping between canonical programs and plausible input\nsentences which can be used to generate training data. Ma-\nture tools exist for designing such mappings, generally by\nadapting domain-general grammars (Bender et al., 2015).\nSynthetic grammars can be engineered to provide full cov-\nerage of the learner’s output space, generating a plausible\ninput sentence for any target program. Closely related pre-\nvious work (Berant & Liang, 2014) has shown that, even\nwithout full coverage of the input space, such grammars can\nprovide useful features for downstream learning.\nWhile engineered grammars make it possible to generate\nlarge amounts labeled training data, they can provide at best\nlimited coverage of natural language (Erbach & Uszkor-\neit, 1990): each program is mapped to a small number of\nplausible input sentences (as deﬁned by the expert-written\ninverse function), meaning that the full spectrum of linguis-\ntic variation is not observed in the generated data. This\nleads to catastrophic distributional shifts for models trained\nexclusively on this generated synthetic data: for example,\non a drone instruction following benchmark, Blukis et al.\nreport a test-time accuracy gap of over 54% between mod-\nels trained on synthetic data and those trained on real user\nutterances (2018). In the next section, we describe a simple\nmodeling approach that allows system-builders to use syn-\nthetic data to train models that are robust to natural inputs.\nUnnatural Language Processing\n3. Sim-to-real transfer for NLP\nUsing data from a synthetic grammar as described in Sec-\ntion 2, we can train a model such that for any desired output,\nthere is some input sentence that produces that prediction.\nThe behavior of this model will be undetermined on most\ninputs. To interpret an out-of-scope utterance x using a\nmodel trained on synthetic data, it is sufﬁcient to ﬁnd some\nsynthetic ˜x with the same meaning as x, and ensure that\nthe model’s prediction is the same for x and ˜x. In other\nwords, all that is required for sim-to-real transfer is a model\nof paraphrase relations and a synthetic data distribution rich\nenough to contain a paraphrase of every task-relevant input.\nIn this framework, one possible approach to the sim-to-real\nproblem would involve building a paraphrase generation\nmodel that could generate natural paraphrases of synthetic\nsentence, then training the language understanding model\non a dataset augmented with paraphrases (Basik et al., 2018;\nSu & Yan, 2017). However, collecting training data for\nsuch a paraphrase model might be nearly as challenging\nas collecting task-speciﬁc annotations directly. Instead, we\npropose to ﬁnd synthetic paraphrases of natural sentences, a\nprocess which requires only a model of sentence similarity\nand no supervised paraphrase data at all.\nFormally, we wish to produce a wide-coverage model f :\nX →Y, where X is the space of of natural language inputs\n(e.g., questions or instructions) and Y is the space of outputs\n(e.g., meaning representations, action sequences, or dialogue\nresponses). We accomplish this by deﬁning a space of\nsynthetic sentences, e\nX. and train a synthetic model ˜f :\ne\nX →Y on an arbitrarily large dataset of synthetic training\nexamples eD = {(˜xi, ˜yi)}. To generalize to real sentences,\nall that is necessary is a function π : X →e\nX that “projects”\nreal sentences onto their synthetic paraphrases. We then\ndeﬁne:\nf(x) = ˜f(π(x)) .\n(1)\nThe synthetic model ˜f can be trained using standard ma-\nchine learning techniques as appropriate for the task. It\nremains only to deﬁne the projection function π. Inspired\nby recent advances in language modeling and representation\nlearning, we choose to use pretrained sentence represen-\ntations as the basis for this projection function, mapping\nfrom natural language to synthetic utterances based on simi-\nlarity in embedding space, under the assumption that rich\ncontextual representations of language can be used to cope\nwith distributional differences between natural and synthetic\nlanguage.\nIn the remainder of section, we describe the steps needed\nto construct a working implementation of the projection\nfunction π for language understanding problems of increas-\ning complexity. Concretely, in Section 3.1, we introduce\na reformulation of the problem of ﬁnding paraphrases as\none of similarity search in embedding space. In Section 3.2,\nwe reduce the computational complexity of the proposed\nsimilarity search, amortizing much of the cost into a single\nO(| e\nX|) preprocessing step. Then, in Section 3.3, we in-\ntroduce hierarchical projections, which facilitate the use of\nthis approach in domains with complex grammars, in which\neven a single enumeration of e\nX is intractable. Finally, Sec-\ntion 3.4 describes an improvement to our model that helps\nto capture attribute-value distinctions that are nontrivial to\nextract from top-level sentence embeddings alone.\n3.1. Paraphrase via similarity search\nMany\nself-supervised\npretraining\nschemes\nfor\nNLP\nproduce\nvector\nrepresentations of sentences in which\ndistance in vector space closely tracks\nsemantic similarity (see e.g. recent\nresults on the semantic textual similarity\nbenchmark; Agirre et al., 2016). We\npropose to project from the natural data distribution D onto\nthe set of synthetic sentences e\nX with respect to a distance\nfunction δ deﬁned by a pretrained sentence embedding\nmodel embed : X →Rd. That is, given a natural language\ninput x, we deﬁne:\nπfull(x) = arg min\n˜x∈e\nX\nδ(embed(x), embed(˜x))\n(2)\nand ﬁnally predict f(x) = ˜f(πfull(x)) as in Equation 1.\nThis framework is agnostic to choice of embedding model\nand distance metric. For all experiments in this paper, embed\nreturns the average of contextual word representations pro-\nduced by the bert-base-uncased model (Devlin et al.,\n2018), and δ(u, v) is the cosine distance 1−u⊤v/(∥u∥∥v∥)\n(or the variant described in Section 3.4).\nThis projection method is straightforward but computation-\nally expensive: each projection requires enumerating and\nembedding every utterance that can be generated by the syn-\nthetic grammar. Depending on the problem domain, the size\nof e\nX can vary signiﬁcantly. For simpler problems, there may\nbe hundreds to thousands of examples. For complex prob-\nlems; | e\nX| might be larger or even inﬁnite, making explicit\nenumeration intractable or impossible.\n3.2. Amortized inference with locality sensitive hashing\nTo reduce the O(n) search cost of the\narg min in Equation 2, we use locality\nsensitive hashing (LSH; Gionis et al.,\n1999) to reduce the search space. Rather\nthan requiring a search across every can-\ndidate synthetic sentence for each new\nnatural language input, locality sensitive\nhashing allows for a one-time O(| e\nX|) preprocessing step to\nUnnatural Language Processing\ncompute hashes for synthetic sentences, such that sentences\nwith similar embeddings fall into nearby buckets. We then\nneed search over only a constant number of nearby buck-\nets of any given input natural language sentence to ﬁnd all\ncandidate synthetic sentences.\nTo\nimplement\nlocality\nsensitive\nhashing\nwe\nuse\nSimhash (Charikar, 2002), an LSH technique based\non random projections of vectors.\nSimhash takes as\ninput a high dimensional vector in Rd and outputs an\nf-dimensional vectors of bits, called a ﬁngerprint, with the\nproperty that similar input vectors with regards to cosine\nsimilarity generate similar ﬁngerprints. To accomplish this,\nSimhash generates f random hyperplanes in d-dimensional\nspace (denoted ℓ1 · · · ℓf), computes the dot product of each\nhyperplane with the input vector, and outputs an f-bit hash\ncorresponding to the sign of each dot product:\nh(x) = [sgn(ℓ⊤\n1 embed(x)), · · · , sgn(ℓ⊤\nf embed(x))] (3)\nSince nearby points tend to lie on the same side of ran-\ndom hyperplanes, the probability that two points have the\nsame ﬁngerprint is proportional to the angle between them,\nand thus directly related to their cosine similarity (Charikar,\n2002). By bucketing datapoints according to their ﬁnger-\nprints, the exhaustive search in Equation 2 can be restricted\nto those points with the same signature as x:\nπlsh(x) =\narg min\n˜x∈e\nX: h(˜x)=h(x)\nδ(embed(x), embed(˜x))\n(4)\nConstructing a data structure to support LSH still requires\nexhaustively enumerating the full set of candidate synthetic\nutterances once, but reduces each subsequent lookup to time\nproportional to bucket size (controlled by f), which can be\ntuned to trade off between speed and recall.\n3.3. Fast inference with hierarchical projection\nTo further optimize the search pro-\ncess of the arg min within π, and to\nextend the projection techniques to\ndomains where even a single enu-\nmeration of e\nX is intractable, we in-\ntroduce a hierarchical procedure for computing π. Rather\nthan construct the LSH search data structure ahead of time,\nwe construct a subset of it dynamically for each input query.\nThis procedure is not possible for general nearest neighbor\nsearch problems, but here we can rely on special structure:\nsynthetic utterances are generated from a grammar, and the\nembed function can be trained to provide a meaningful mea-\nsure of similarity even for incomplete derivations under the\ngrammar.\nTo perform hierarchical search, we assume that our synthetic\ndata is generated from a context-free grammar (Hopcroft\net al., 2001). For example, the example sentence pick up\nthe red ball may be generated by the sequence of derivation\nsteps $root →pick up the $item →pick up the ball (arrows\n→denote reachability in one step and $dollar signs denote\nnonterminal symbols).\nWe use this derivation process to compute the arg min from\nprevious equations iteratively, by repeatedly selecting a non-\nterminal to instantiate, instantiating it, and repeating the\nprocess until a complete synthetic sentence is generated.\nWe illustrate our approach through an example:\nGiven an input natural language utterance, I want the dark\nblue crate adjacent to the opening (Figure 1), we ﬁrst rank\nexpansions of the root symbol of the synthetic grammar.\nHere we rely speciﬁcally on the use of a masked language\nmodel for sentence representations: we replace each non-\nterminal symbol with a [MASK] token to obtain meaningful\nsimilarity between complete real sentences and partially\ninstantiated synthetic ones.\nLetting e\nX($root) denote the set of (complete or incom-\nplete) sentences that can be derived from the incomplete\nderivation $root in a single step, we have:\nπ(1)\nhier(x) = arg min\n˜x∈e\nD($root)\nδ(embed(x), embed(˜x))\n(5)\nas before. For the example in Figure 2, π(1)\nhier(x) = put the\n$item next to $item.\nThe process is then repeated for all unexpanded nontermi-\nnals in the partial derivation until a complete sentence is\ngenerated. This procedure corresponds to greedy search\nover sentences generated by the CFG, with measured simi-\nlarity between partial derivations and the target string x as a\nsearch heuristic. This procedure can be straightforwardly ex-\ntended to a beam search by computing the k lowest-scoring\nexpansions rather than just the arg min at each step.\nIf the grammar has a high branching factor (i.e. the number\nI want [the dark blue crate]1 adjacent to [the opening]2\n$root\n    ! Put $NP next to $NP ✔\n    ! Open $NP\n! Put a blue box next to $NP ✔\n! Go to $NP\n! …\nπ(1)\nhier\nπ(2)\nhier\n{blue sphere, blue box}1\nFigure 2. Hierarchical projection. Given a natural language input,\nwe search for a high-scoring utterance generated by a ﬁxed CFG,\nusing similarity between sentences and partial derivations as a\nsearch heuristic. An additional heuristic scores noun phrases lo-\ncally by measuring their similarity with noun chunks extracted\nfrom the input sentence.\nUnnatural Language Processing\nof expansions for each nonterminal symbol is large), it may\nalso be useful to incorporate other search heuristics. For\nall experiments in this paper, we restrict the set of expan-\nsions for noun phrase nonterminals. We begin by using a\npretrained chunker (Sang & Buchholz, 2000) to label noun\nphrases in the natural language input x (in Figure 2 running\nexample this gives the dark blue crate and the opening).\nWhen expanding noun phrase nonterminals, we ﬁrst align\nthe nonterminal to a noun chunk in x based on similarity\nbetween the chunk and all right-hand sides for the nonter-\nminal, and ﬁnally select the single right-hand side that is\nmost similar to the aligned noun chunk. Greedy population\nof noun phrases ensures greater beam diversity of sentence-\nlevel templates in beam hypotheses. We additionally discard\nany hypotheses in which there is a mismatch between the\nnumber of noun phrases in the query sentence x and the\nnumber of groups of adjacent nonterminals in the top-level\npartial derivation eD(1). For example, if the template calls for\ntwo distinct entities, but the natural language utterance only\ncontains one (e.g. go to the green door), then the derivation\nis immediately discarded.\nGiven a grammar of size g, derivations of size d, and\nSimHash bucket size b, hierarchical projections reduce in-\nference cost from O(| eD|) to O(bd < gd).\n3.4. Tunable models with matching scores\nHierarchical representations of syn-\nthetic utterances makes it possible\nto improve scoring as well as search.\nConsider the set of candidates:\n1. go through the yellow door and pick up the red ball\n2. go through the red door and pick up the yellow ball\nand a natural language input referencing a red ball and\nyellow door. Candidate (1) should be prioritized over candi-\ndate (2), but in early experiments we found that ﬁne-grained\nattribute–value distinctions are not always captured by top-\nlevel sentence embedding similarities. To improve this, we\nalso experiment with a modiﬁed version of the similarity\nmeasure δ that incorporates ﬁne-grained lexical similarity\nin addition to sentence similarity.\nTo compute this new distance function δ′, we model the\nproblem as one in ﬁnding a minimum weight matching in\nbipartite graphs. Suppose we have a set of (complete) candi-\ndate synthetic utterances derived from either a ﬂat or hierar-\nchical projection procedure as deﬁned above. As above, we\nextract noun chunks from the natural language query and\neach synthetic utterance, representing each chunk as a node\nin a graph connected to each node from the utterance with\nedge weights equivalent to the distance between the respec-\ntive phrases in embedding space. We use the Hungarian\nalgorithm (Kuhn, 1955) to solve this matching problem, and\nincorporate the computed minimum syntactic cost δsub from\neach candidate sentence into the overall distance function δ.\nIn particular, we redeﬁne the similarity function as\nδ′(x, ˜x) =δ(embed(x), embed(˜x))\n+ α\nX\n(x′,˜x′)∈M\nδ(embed(x′), embed(˜x′)\n(6)\nwhere M is the matching found by the Hungarian algorithm\nand α is a hyperparameter that can be tuned as required\nbased on the grammar of the problem domain.\nThis scoring strategy can have detrimental effect if α is set\ntoo high — one example of a where δsub incorrectly over-\npowers δ is when “go through the yellow door and pick\nup the red ball” is projected onto an utterance containing\nthose extra details that is not semantically equivalent, such\nas “put the red ball next to the yellow door”. However, in\nearly experiments on BABYAI dataset we found the addi-\ntional ﬁne-grained control provided by matching scores led\nto slight improvements in projection accuracy: see Section 4\nfor experiments.\n4. Evaluation\nWe evaluate our approach on two tasks with markedly differ-\nent output spaces and data requirements: the OVERNIGHT\nsemantic parsing benchmark (Wang et al., 2015) and\nthe BABYAI instruction following benchmark (Chevalier-\nBoisvert et al., 2018). These experiments aim (1) to test\nthe ﬂexibility of the general sim-to-real framework across\nproblems with complex compositionality and complex in-\nteraction, and (2) to measure the effectiveness of projection-\nbased sentence interpretation relative to other ways of learn-\ning from pretrained representations and synthetic data.\nBoth tasks come with predeﬁned synthetic data generators\nintended for uses other than our projection procedure. The\neffectiveness of the approach described in this paper in-\nevitably depends on the quality of the data synthesizer; by\ndemonstrating good performance using off-the-shelf syn-\nthesizers from previous work, we hope to demonstrate the\ngenerality and robustness of the proposed approach. We\nexpect that better results could be obtained using a grammar\noptimized for peformance; we leave this for future work.\n4.1. Models\nExperiments on both benchmarks use the following models:\nseq2seq\nA baseline neural sequence model. For the se-\nmantic parsing task, this is a standard LSTM encoder–\ndecoder architecture with attention (Bahdanau et al., 2015).\n(This model achieves comparable average performance to\nthe dependency-based semantic parsing approach of Wang\nUnnatural Language Processing\net al..) We use a 256-dimensional embedding layer and\na 1024-dimensional hidden state. For the instruction fol-\nlowing task, we reuse the agent implementation provided\nwith the BABYAI dataset, which jointly encodes instruc-\ntions and environments states with a FiLM module (Perez\net al., 2018), and generates sequences of actions with an\nLSTM decoder. More details are provided in the original\nwork of Chevalier-Boisvert et al. (2018). The seq2seq base-\nline measures the extent to which available synthetic data in\neach domain is already good enough to obtain sim-to-real\ntransfer from standard models without specialization.\nseq2seq+BERT\nAs discussed in Artetxe & Schwenk\n(2019), the standard approach to the sort of zero-shot trans-\nfer investigated here is to train models of the kind described\nabove not on raw sequences of input tokens, but rather on se-\nquences of contextual embeddings provided by a pretrained\nrepresentation model. The intuition is that these represen-\ntations capture enough language-general information—e.g.\nabout which words are similar and which syntactic distinc-\ntions are meaningful—that a learned model of the relation-\nship between input representations and task predictions in\nthe source (synthetic) domain will carry over to input repre-\nsentations in the target domain.\nConcretely, seq2seq+BERT models are constructed for both\ntasks by taking the language encoder and replacing its\nlearned word embedding layer with contextual embeddings\nprovided by the bert-base-uncased model of Devlin et al..\nThis is analogous to the strategy employed by Lindemann\net al. (2019) and has been shown to be an effective way to\nincorporate pretraining into a variety of semantic prediction\ntasks. Though the bulk of this paper focuses on the pro-\njection technique, the experiments we present are also, to\nthe best of our knowledge, the ﬁrst to systematically eval-\nuate even this basic pretraining and transfer scheme in the\ncontext of synthetic data.\nprojection\nThe ﬁnal model we evaluate is our projection\napproach described in Section 3. As discussed above, the\nprojection model is built from the same pieces as the base-\nlines: it relies on the base seq2seq model for interpreting\nsynthetic data, the similarity function induced by BERT\nembeddings in the projection step. The set of synthetic\nsentences in the OVERNIGHT dataset is relatively small (a\nfew hundred for the largest domains) so we apply the “ﬂat\nprojections” approach directly. BABYAI, on the other hand,\ncontains many more sentences (approximately 40K), so we\nuse hierarchical projections, evaluating the approach both\nwith and without the linear sum assignment strategy applied.\n4.2. Experiments\nSemantic parsing\nIn semantic parsing, the goal is to learn\na mapping from natural language utterances to formal, exe-\nreal\nshow me the meeting starting latest in the day\nsynth\nmeeting that has the largest start time\nLF\n(max meeting (get start_time))\nreal\nwhat recipes posting date is at least the same as rice\npudding\nsynth\nrecipe whose posting date is at least posting date of\nrice pudding\nLF\n(filter recipe (≥\n(get posting-date)\n((get posting-date) RICE-PUDDING)))\nFigure 3. Example sentences from the calendar and recipe\nOVERNIGHT domains. real is a human-generated utterance, synth\nis a synthetic utterance from the domain grammar of calendar, and\nLF is the target logical expression.\ncutable representations of meaning (Figure 3). These mean-\ning representations can then be used to as inputs to database\nengines or formal reasoning systems. The OVERNIGHT\nbenchmark consists of eight semantic parsing datasets cov-\nering a range of semantic phenomena, and is designed to\ntest efﬁcient learning from small numbers of examples—\nindividual datasets range in size from 640–3535 examples.\nThe semantic originally described by Wang et al. for this\ntask was equipped with a “canonical grammar”—a compact\nset of rules describing a mapping from logical forms to\n(somewhat stilted) natural language strings (meeting whose\nend time is smaller than start time of weekly standup). In\nthe original work, this grammar was used as a source of\nfeatures for reranking logical forms. Here we instead use it\nas a source of synthetic training data, enumerating strings\nfrom the grammar paired with logical forms, and using\nthese pairs to train the base seq2seq model. The dataset also\ncomes with a set of natural language annotations on train-\nand test-set logical forms.\nResults are shown in Table 1. We report logical form exact\nmatch accuracies for the eight OVERNIGHT datasets.2 Three\ndata conditions are evaluated: synth, which uses synthetic-\nonly training data, real, which uses only human-annotated\ntraining data, and both, which combines the two. Human\nannotations are used for the test evaluation in all data con-\nditions. For the both condition, we found that simply con-\ncatenating the two datasets was reliably better than any\nﬁne-tuning scheme.\nModels in the real and both sections have access to signiﬁ-\ncantly richer supervision than the projections approach, and\nare intended to characterize a best-case data condition. It\ncan be seen that the projection-based approach to learning\nfrom synthetic data consistently outperforms sequence-to-\nsequence models with or without pretrained representations.\nIn fact, projection is comparable to a supervised approach\n2The original work used a coarser-grained denotation match\nevaluation.\nUnnatural Language Processing\nData\nModel\nbasketball\nblocks\ncalendar\nhousing\npubs\nrecipes\nrestaurants social\nmean\nsynth\nprojection\n0.47\n0.27\n0.32\n0.36\n0.34\n0.49\n0.43\n0.28\n0.37\nseq2seq\n0.27\n0.08\n0.22\n0.16\n0.24\n0.21\n0.23\n0.07\n0.19\nseq2seq+BERT\n0.60\n0.21\n0.31\n0.31\n0.34\n0.36\n0.36\n0.31\n0.35\nreal\nseq2seq\n0.45\n0.10\n0.27\n0.19\n0.30\n0.38\n0.25\n0.20\n0.27\nseq2seq+BERT\n0.63\n0.26\n0.37\n0.29\n0.44\n0.53\n0.43\n0.42\n0.42\nboth\nseq2seq\n0.01\n0.25\n0.13\n0.10\n0.52\n0.18\n0.42\n0.36\n0.25\nseq2seq+BERT\n0.67\n0.23\n0.43\n0.29\n0.48\n0.29\n0.36\n0.38\n0.39\nTable 1. OVERNIGHT semantic parsing logical form accuracies on human-generated questions for models trained with synthetic data,\nreal data, or both. Bold values indicate the best-performing model under the synth data condition, while underlined values indicate the\nbest-performing model under any data condition. The projection approach consistently outperforms other models in the synthetic-only\ncondition, and is comparable to a fully-supervised model in three domains.\nData\nModel\nsuccess\nreward\nsynth\nprojection (α = 0.1)\n0.63\n0.72\nprojection (α = 0.0)\n0.59\n0.70\nseq2seq\n0.56\n0.67\nseq2seq+BERT\n0.54\n0.66\nboth\nseq2seq\n0.59\n0.71\nseq2seq+BERT\n0.53\n0.65\nTable 2.\nInstruction following accuracies on the BABYAI\nSynthLoc task with human-generated instructions and models\ntrained on synthetic or a mix of synthetic and real data. Bold val-\nues indicate the best-performing model for a given data condition\nand underlined values indicate the best-performing model under\nany data condition. Projection (α = 0.1) gives the best results\non both success (task completion) and discounted reward metrics,\noutperforming other models trained on only synthetic data as well\nas models ﬁne-tuned on 2048 real examples.\n(in the real and both data conditions) in three domains.\nThese results demonstrate that projection is an effective\nmechanism for sim-to-real transfer in tasks with a challeng-\ning language understanding component, enabling the use\nof synthetic strings to bootstrap a model that can perform\nﬁne-grained linguistic analysis of real ones.\nInstruction following\nThe BABYAI instruction follow-\ning dataset presents a range of challenging manipula-\ntion and navigation tasks in two-dimensional gridworld\nenvironments—agents are trained to achieve a wide variety\nof compositional goals (e.g. put a yellow box next to a gray\ndoor, Figure 4) speciﬁed by sentences from an artiﬁcial\ngrammar.\nThis dataset was originally designed to explore generaliza-\ntion in reinforcement and imitation learning, not natural\nlanguage understanding, but it provides a ﬂexible and ex-\ntensible test-bed for studying questions around generaliza-\ntion in natural language as well. We collected a dataset\nof roughly 5000 natural language utterances by showing\nMechanical Turk workers videos of agents executing plans\nsynth: put a yellow box next to a gray door\nreal: drive around and put the yellow block beside the top door\nFigure 4. Example from the BABYAI dataset. Agents are given\ntasks with language-like speciﬁcations, and must execute a se-\nquence of low-level actions in the environment to complete them.\nWe augment this dataset with a set of human instructions, and\nevaluate generalization of agents trained only on synthetic goal\nspeciﬁcations to novel human requests.\nin BABYAI environments (speciﬁcally from the SynthLoc\ntraining set). Workers did not see the original BABYAI\ncommands, but were asked to generate new instructions that\nwould cause a robot to accomplish the goal displayed in the\nvideo. The dataset of human annotations is released with\nthis paper.\nAs in the OVERNIGHT experiments, we train (in this case\nvia imitation learning) on either the underlying synthetic\ninstructions alone, or a mix of synthetic and real instruc-\ntions. We evaluate various models’ ability to generalize to a\nhuman-annotated test set. Unlike the OVERNIGHT datasets,\nbootstrapping even a seq2seq model that achieves good per-\nformance on a test set with synthetic instructions requires\nenormous amounts of data: the existing synthetic training\nset contains a million demonstrations. To adapt to human\ninstructions, we ﬁne-tune this baseline model (rather than\nconcatenating training sets as above).\nResults are shown in Table 2. Again, projection is the best\nway to incorporate pretrained representations: introducing\nUnnatural Language Processing\nBERT embeddings into the underlying sequence-to-sequence\nmodel makes performance worse. (We attribute this to over-\nﬁtting to the limited set of word embeddings observed dur-\ning training.) Again, as well, projection is effective enough\nto allow synthetic-only training to outperform ﬁne-tuning\non a small amount of human data. These results indicate\nthat sim-to-real transfer is also an effective strategy for tasks\nwhose sample complexity results from the difﬁculty of an\nunderlying planning problem rather than language under-\nstanding as such.\n5. Related work\nThe technique described in this paper brings together three\noverlapping lines of work in machine learning and natural\nlanguage processing:\nSim-to-real transfer in robotics\nThe most immediate in-\nspiration for the present work comes from work on simu-\nlation in robotics and other challenging control problems\n(Tzeng et al., 2016). Simulators provide convenient environ-\nments for training agents because the poor sample efﬁciency\nof current policy learning algorithms are mitigated by faster-\nthan-real-time interaction and unlimited data. “Learning”\nin simulation amounts to amortizing the inference prob-\nlem associated with optimal control (Levine, 2018): correct\nbehavior is fully determined by the speciﬁcation of the envi-\nronment but poses a hard search problem.\nHowever, simulators do not represent reality with complete\naccuracy, and agents trained to perform speciﬁc tasks in\nsimulators often fail to perform these same tasks in the real\nworld. Various techniques have been proposed for bridg-\ning this this “reality gap\" (Tobin et al., 2017). Language\nprocessing applications suffer from similar data availability\nissues. For grounded language learning in particular, “end-\nto-end” architectures make it hard to disentangle challeng-\ning language learning problems from challenging inference\nproblems of the kind discussed above (Andreas & Klein,\n2015). Our approach aims to ofﬂoad most learning of lin-\nguistic representations to pretraining without sacriﬁcing the\nexpressive power of models for either part of the problem.\nRepresentation learning\nThe last two years have seen\nremarkable success at learning general-purpose representa-\ntions of language from proxy tasks like masked language\nmodeling (Peters et al., 2018; Devlin et al., 2018). For tasks\nwith limited in-domain training data available, a widespread\napproach has been to begin with these pretrained represen-\ntations, train on data from related source domains in which\nlabels are available, and rely on similarity of pretrained rep-\nresentations in source and target domains to achieve transfer\n(Artetxe & Schwenk, 2019). One surprising ﬁnding in the\ncurrent work is that this strategy is of only limited effective-\nness in the speciﬁc case of synthetic-to-real transfer: it is\nbetter to use these pretrained representations to ﬁnd para-\nphrases from the target domain back to the synthetic source\ndomain, and interpret sentences normally after paraphrasing,\nthan it is to rely on transfer of representations themselves\nwithin a larger learned model.\nGrammar engineering\nFinally, we view our work as of-\nfering a new perspective in a longstanding conversation\naround the role of grammar engineering and other rule-based\napproaches in NLP (Chiticariu et al., 2013). Rule-based ap-\nproaches are criticized for being impossible to scale to the\nfull complexity of real language data, providing good cov-\nerage of “standard” phenomena but requiring prohibitive\nadditional to model the numerous special cases and excep-\ntions that characterize human language (Norvig, 2017).\nHowever, engineered grammars and synthetic data genera-\ntion procedures also offer a number of advantages. Mature\nengineering tools and syntactic resources are available for\nmany major languages (Flickinger, 2011). Hand-written\ngrammars are straightforward to implement and can serve\nas cost-effective tools for language generation in larger data-\nsynthesis pipelines; they also enable developers to quickly\nincorporate new linguistic phenomena when they are found\nto be outside model capacity. Moreover, since the relative\nfrequency syntactic and semantic phenomena can be speci-\nﬁed by engineers, the poor accuracy on long-tail pheonom-\nena that is observed in models trained on natural datasets\n(Bamman, 2017) can be mitigated by ﬂattening out the rele-\nvant distributions in the data generation process.\nThe approach presented in this paper, and the prospect of\nmore general sim-to-real transfer in NLP, offers to turn the\npartial solution offered by current grammar engineering ap-\nproaches into a more complete one: model builders with\nlimited data collection ability can construct high-quality\nsynthetic data distributions with general-purpose language\nresources, project project onto these distributions with high\naccuracy, and eventually obtain good end-to-end perfor-\nmance without end-to-end data collection or training.\n6. Discussion\nWe have described a family of techniques for sim-to-real\ntransfer in natural language processing contexts, a compar-\native analysis of these techniques, a new benchmark for\nmeasuring sim-to-real transfer performance, and a practical\nsoftware framework for bootstrapping synthetic grammars.\nThe projection procedure described in this paper suggests\na new approach to bootstrapping natural language applica-\ntions. In this paradigm, key insights about the relationship\nbetween the world and language are explicitly encoded into\nthe declarative synthetic data generation procedure rather\nUnnatural Language Processing\nthan implicitly in the model’s structure or through the use\nof a human-annotated dataset, and can take advantage of ad-\nvances in machine learning and structured knowledge about\nhuman language. Developers who want to build applica-\ntions in new domains can therefore hand-engineer synthetic\ngrammars, use the generated data to train domain-speciﬁc\nmachine learning models, and use projections to paraphrase\ntest time natural language examples into their synthetic\ncounterparts. This makes it possible to recover substantial\namounts of model accuracy that otherwise would have been\nlost when switching from the distribution of synthetic to\nnatural language utterances.\nReferences\nAgirre, E., Banea, C., Cer, D., Diab, M., Gonzalez Agirre,\nA., Mihalcea, R., Rigau Claramunt, G., and Wiebe, J.\nSemeval-2016 task 1: Semantic textual similarity, mono-\nlingual and cross-lingual evaluation. In SemEval-2016.\n10th International Workshop on Semantic Evaluation;\n2016 Jun 16-17; San Diego, CA. Stroudsburg (PA): ACL;\n2016. p. 497-511. ACL (Association for Computational\nLinguistics), 2016.\nAndreas, J. and Klein, D. Alignment-based compositional\nsemantics for instruction following. In Proceedings of the\nConference on Empirical Methods in Natural Language\nProcessing, 2015.\nArtetxe, M. and Schwenk, H. Massively multilingual sen-\ntence embeddings for zero-shot cross-lingual transfer and\nbeyond. Transactions of the Association for Computa-\ntional Linguistics, 7:597–610, 2019.\nBahdanau, D., Cho, K., and Bengio, Y. Neural machine\ntranslation by jointly learning to align and translate. In\nProceedings of the International Conference on Learning\nRepresentations, 2015.\nBamman, D. Natural language processing for the long tail.\nIn DH, 2017.\nBasik, F., Hattasch, B., Ilkhechi, A. R., Usta, A., Ra-\nmaswamy, S., Utama, P., Weir, N., Binnig, C., and Çet-\nintemel, U. Dbpal: A learned NL-interface for databases.\nIn Proceedings of the 2018 International Conference on\nManagement of Data, pp. 1765–1768, Houston, TX, USA,\n2018.\nBender, E. M., Levin, L., Müller, S., Parmentier, Y., and\nRanta, A. Proceedings of the grammar engineering across\nframeworks (GEAF) 2015 workshop. In Proceedings of\nthe Grammar Engineering Across Frameworks (GEAF)\n2015 Workshop, 2015.\nBerant, J. and Liang, P. Semantic parsing via paraphrasing.\nIn Proceedings of the 52nd Annual Meeting of the Asso-\nciation for Computational Linguistics (Volume 1: Long\nPapers), pp. 1415–1425, 2014.\nBlukis, V., Misra, D., Knepper, R. A., and Artzi, Y. Map-\nping navigation instructions to continuous control ac-\ntions with position-visitation prediction. arXiv preprint\narXiv:1811.04179, 2018.\nCallison-Burch, C., Koehn, P., Monz, C., and Zaidan, O. F.\nFindings of the 2011 Workshop on Statistical Machine\nTranslation. In WMT. Association for Computational\nLinguistics, 2011.\nCharikar, M. S. Similarity estimation techniques from round-\ning algorithms. In Proceedings of the Thiry-Fourth An-\nnual ACM Symposium on Theory of Computing, STOC\n’02, pp. 380–388, New York, NY, USA, 2002. Associa-\ntion for Computing Machinery. ISBN 1581134959. doi:\n10.1145/509907.509965. URL https://doi.org/10.\n1145/509907.509965.\nChelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T.,\nKoehn, P., and Robinson, T. One billion word benchmark\nfor measuring progress in statistical language modeling.\narXiv preprint arXiv:1312.3005, 2013.\nChevalier-Boisvert, M., Bahdanau, D., Lahlou, S., Willems,\nL., Saharia, C., Nguyen, T. H., and Bengio, Y. BabyAI: A\nplatform to study the sample efﬁciency of grounded lan-\nguage learning. In International Conference on Learning\nRepresentations, 2018.\nChiticariu, L., Li, Y., and Reiss, F. Rule-based information\nextraction is dead! Long live rule-based information ex-\ntraction systems! In Proceedings of the 2013 conference\non empirical methods in natural language processing, pp.\n827–832, 2013.\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. BERT:\nPre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805,\n2018.\nErbach, G. and Uszkoreit, H. Grammar engineering: Prob-\nlems and prospects. CLAUS report, 1, 1990.\nFlickinger, D. Accuracy vs. robustness in grammar engineer-\ning. Language from a cognitive perspective: Grammar,\nusage, and processing, 201:31–50, 2011.\nGionis, A., Indyk, P., Motwani, R., et al. Similarity search\nin high dimensions via hashing. In VLDB, volume 99, pp.\n518–529, 1999.\nHopcroft, J. E., Motwani, R., and Ullman, J. D. Introduction\nto automata theory, languages, and computation. Acm\nSigact News, 32(1):60–65, 2001.\nUnnatural Language Processing\nKuhn, H. W.\nThe Hungarian method for the assign-\nment problem.\nNaval Research Logistics Quarterly,\n2(1-2):83–97, 1955.\ndoi:\n10.1002/nav.3800020109.\nURL https://onlinelibrary.wiley.com/doi/abs/\n10.1002/nav.3800020109.\nLevine, S. Reinforcement learning and control as proba-\nbilistic inference: Tutorial and review. arXiv preprint\narXiv:1805.00909, 2018.\nLindemann, M., Groschwitz, J., and Koller, A. Composi-\ntional semantic parsing across graphbanks. arXiv preprint\narXiv:1906.11746, 2019.\nLuketina, J., Nardelli, N., Farquhar, G., Foerster, J., Andreas,\nJ., Grefenstette, E., Whiteson, S., and Rocktäschel, T. A\nsurvey of reinforcement learning informed by natural\nlanguage. In International Joint Conference on Artiﬁcial\nIntelligence, 2019.\nNorvig, P. On Chomsky and the two cultures of statisti-\ncal learning. In Berechenbarkeit der Welt?, pp. 61–83.\nSpringer, 2017.\nPerez, E., Strub, F., De Vries, H., Dumoulin, V., and\nCourville, A. FiLM: Visual reasoning with a general\nconditioning layer. In Thirty-Second AAAI Conference\non Artiﬁcial Intelligence, 2018.\nPeters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark,\nC., Lee, K., and Zettlemoyer, L. Deep contextualized\nword representations. In Proceedings of the Annual Meet-\ning of the North American Chapter of the Association for\nComputational Linguistics, 2018.\nSang, E. F. and Buchholz, S. Introduction to the CoNLL-\n2000 shared task: Chunking. arXiv preprint cs/0009008,\n2000.\nSu, Y. and Yan, X. Cross-domain semantic parsing via\nparaphrasing. In Proceedings of the 2017 Conference on\nEmpirical Methods in Natural Language Processing, pp.\n1235–1246, Copenhagen, Denmark, 2017.\nTobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W.,\nand Abbeel, P. Domain randomization for transferring\ndeep neural networks from simulation to the real world.\nIn 2017 IEEE/RSJ international conference on intelligent\nrobots and systems (IROS), pp. 23–30. IEEE, 2017.\nTzeng, E., Devin, C., Hoffman, J., Finn, C., Peng, X.,\nLevine, S., Saenko, K., and Darrell, T. Towards adapting\ndeep visuomotor representations from simulated to real\nenvironments. In WAFR, 2016.\nWang, Y., Berant, J., and Liang, P. Building a semantic\nparser overnight. In ACL, 2015.\nZelle, J. Using Inductive Logic Programming to Automate\nthe Construction of Natural Language Parsers.\nPhD\nthesis, Department of Computer Sciences, The University\nof Texas at Austin, 1995.\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2020-04-28",
  "updated": "2020-04-28"
}