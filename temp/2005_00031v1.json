{
  "id": "http://arxiv.org/abs/2005.00031v1",
  "title": "Unsupervised Lesion Detection via Image Restoration with a Normative Prior",
  "authors": [
    "Xiaoran Chen",
    "Suhang You",
    "Kerem Can Tezcan",
    "Ender Konukoglu"
  ],
  "abstract": "Unsupervised lesion detection is a challenging problem that requires\naccurately estimating normative distributions of healthy anatomy and detecting\nlesions as outliers without training examples. Recently, this problem has\nreceived increased attention from the research community following the advances\nin unsupervised learning with deep learning. Such advances allow the estimation\nof high-dimensional distributions, such as normative distributions, with higher\naccuracy than previous methods.The main approach of the recently proposed\nmethods is to learn a latent-variable model parameterized with networks to\napproximate the normative distribution using example images showing healthy\nanatomy, perform prior-projection, i.e. reconstruct the image with lesions\nusing the latent-variable model, and determine lesions based on the differences\nbetween the reconstructed and original images. While being promising, the\nprior-projection step often leads to a large number of false positives. In this\nwork, we approach unsupervised lesion detection as an image restoration problem\nand propose a probabilistic model that uses a network-based prior as the\nnormative distribution and detect lesions pixel-wise using MAP estimation. The\nprobabilistic model punishes large deviations between restored and original\nimages, reducing false positives in pixel-wise detections. Experiments with\ngliomas and stroke lesions in brain MRI using publicly available datasets show\nthat the proposed approach outperforms the state-of-the-art unsupervised\nmethods by a substantial margin, +0.13 (AUC), for both glioma and stroke\ndetection. Extensive model analysis confirms the effectiveness of MAP-based\nimage restoration.",
  "text": "Unsupervised Lesion Detection via Image Restoration\nwith a Normative Prior\nXiaoran Chen1∗\nSuhang You2†\nKerem Can Tezcan 1\nEnder Konukoglu1\n1Computer Vision Laboratory, ETH Z¨urich\n2ARTORG, University of Bern\n1 {chenx,tezcan,ender.konukoglu}@vision.ee.ethz.ch\n2suhang.you@artorg.unibe.ch\nAbstract\nUnsupervised lesion detection is a challenging problem\nthat requires accurately estimating normative distributions\nof healthy anatomy and detecting lesions as outliers with-\nout training examples. Recently, this problem has received\nincreased attention from the research community following\nthe advances in unsupervised learning with deep learning.\nSuch advances allow the estimation of high-dimensional\ndistributions, such as normative distributions, with higher\naccuracy than previous methods. The main approach of\nthe recently proposed methods is to learn a latent-variable\nmodel parameterized with networks to approximate the nor-\nmative distribution using example images showing healthy\nanatomy, perform prior-projection, i.e. reconstruct the im-\nage with lesions using the latent-variable model, and de-\ntermine lesions based on the differences between the re-\nconstructed and original images. While being promising,\nthe prior-projection step often leads to a large number of\nfalse positives.\nIn this work, we approach unsupervised\nlesion detection as an image restoration problem and pro-\npose a probabilistic model that uses a network-based prior\nas the normative distribution and detect lesions pixel-wise\nusing MAP estimation. The probabilistic model punishes\nlarge deviations between restored and original images, re-\nducing false positives in pixel-wise detections. Experiments\nwith gliomas and stroke lesions in brain MRI using publicly\navailable datasets show that the proposed approach outper-\nforms the state-of-the-art unsupervised methods by a sub-\nstantial margin, +0.13 (AUC), for both glioma and stroke\ndetection. Extensive model analysis conﬁrms the effective-\nness of MAP-based image restoration.\n∗Corresponding author. This work was partly supported by the Swiss\nNational Science Foundation under grant 205321 173016 and Platform for\nAdvanced Scientiﬁc Computing under grant HPC-Predict.\n†Work done while at ETH Z¨urich.\n1. Introduction\nDetecting lesions plays a critical role in radiological as-\nsessment; it is often the ﬁrst step in the diagnosis pipeline.\nManual detection, the dominant current practice, relies\non an exceptional understanding of the normal anatomy.\nSpeciﬁcally, radiologists detect lesions as regions that de-\nviate from the normal variation of the healthy anatomy, and\nthen identify the disease based on the features of the lesion\nas well as other patient information. This detection process\nis unsupervised in the sense that the radiologist is not look-\ning for a speciﬁc lesion but for any abnormal variation.\nDeveloping algorithmic approaches for automatic unsu-\npervised lesion detection is important for both algorithm\ndevelopment and clinical practice. For algorithm develop-\nment, accurate unsupervised lesion detection would allow\ndeveloping further algorithms that are robust to lesions un-\nseen in the training set. For instance, a machine learning-\nbased segmentation algorithm that is aware of the presence\nof an outlier can take this into account while segmenting the\nrest of the image avoiding being affected by the abnormal\nfeature responses of the outlier area. Such robustness would\nbe extremely helpful for a variety of tasks researchers are\ntackling with machine learning methods, such as segmen-\ntation, localization, reconstruction and restoration. Good\nunsupervised lesion detection methods can also be applied\nto detecting artifacts and furthermore developing methods\nrobust to such artifacts.\nOn the other hand, for clinical\npractice, a generic and accurate unsupervised lesion detec-\ntion would be a useful pre-screening tool to improve efﬁ-\nciency in radiological assessment by focusing expert effort\ndirectly on abnormal areas. This aspect is becoming partic-\nularly critical considering the increase in image resolution\nand number of modalities used in clinical routines, which on\none hand have the potential to improve diagnostic accuracy\nbut on the other hand result in drastically larger image vol-\numes and number of images to be examined for each study,\nthus more effort.\nMachine learning-based approaches have attracted con-\nsiderable attention for lesion detection in the last decade.\n1\narXiv:2005.00031v1  [eess.IV]  30 Apr 2020\nMajority of the research effort in this direction focus on de-\nveloping supervised algorithms [1, 34, 9, 7, 23, 13, 16]. In\nthis approach, algorithms are optimized during the training\nphase to detect lesions of pre-speciﬁed types based on ex-\namples in the training set. When tested on the same le-\nsion types, these methods yielded state-of-the-art detection\nand segmentation performance. However, being optimized\nto detect pre-speciﬁed lesion types limits their applicability\nto unseen lesions. In theory, adding examples of all pos-\nsible types of lesions in training can address this issue but\nthis option, even when feasible, would be very expensive in\nmanual effort and time.\nUnsupervised lesion detection methods take another ap-\nproach. They focus on learning prior knowledge on the ap-\npearance of healthy anatomy in order to detect lesions as\nareas that disagree with the prior knowledge, mimicking ra-\ndiologists. In one of the ﬁrst works, a probabilistic atlas\nof healthy anatomy is utilized as the prior knowledge and\nbuilt tissue-speciﬁc mixture models with an outlier class to\nsegment healthy tissue while identifying areas that do not\nﬁt the other tissue classes [30]. In similar approaches, an\natlas with spatial features instead of intensities is used [20]\nand combines spatial and intensity atlases [24]. More re-\ncent works use prior models of patches of images to include\ncontextual information around a pixel in the detection pro-\ncess. Considering the curse of dimensionality in modeling\nhigh dimensional distributions, such works adopt dimen-\nsionality reduction methods, such as principle component\nanalysis [32, 8], patch-based mixture model [3] and sparse\nrepresentation [33].\nAdvances in deep learning (DL)-based unsupervised\nlearning methods provided strong alternatives for approx-\nimating distributions in high dimensions. Neural samplers,\nsuch as Generative Adversarial Networks (GAN) [10], can\nlearn to generate realistic high-dimensional images sim-\nilar to the ones seen in the training set starting from a\nlower-dimensional latent space, and DL-based non-linear\nlatent variable models, such as Variational Autoencoders\n(VAE) [14], approximate the distribution from the samples\nin a training set, using networks to map from images to la-\ntent space and back, implementing the original idea [18]\nefﬁciently. DL-based approaches yield better approxima-\ntions to the high-dimensional distributions, as evidenced\nby the realistic samples they can generate. Recently pro-\nposed works [26, 2, 22, 4] already apply DL-based mod-\nels to approximating normative distributions with only im-\nages showing healthy anatomy and then detect lesions as\nthe outliers. These methods typically has three steps. First,\na given image with a lesion is projected to the latent space\nof the model, which in other words is to ﬁnd the latent\nspace representation of the image. Since the models have\nonly seen healthy anatomy during training, the most likely\nlatent representations correspond to images with healthy\nanatomy. Based on this assumption, the original image is\nreconstructed from its latent representation, with the lesion\nreconstructed with large errors and the rest of the image re-\nconstructed faithfully. Hence, the difference between the\nreconstruction and the original image will highlight the le-\nsion. While using this prior projection is a sound idea, it re-\nlies on the assumption that healthy areas in the images will\nremain the same in the reconstructed image, meaning that\nthe latent space representations of the image with lesion and\nits lesion-free version are very similar. Unfortunately, this\nassumption may not hold since the intensities in the lesion\narea may greatly affect the projection step, causing large\ndeviations between the mentioned latent space representa-\ntions. In contrast, a method that directly takes such possible\ndeviations into account can lead to improved detection ac-\ncuracy.\nIn this work, we propose an approach that casts the un-\nsupervised detection problem as an image restoration prob-\nlem. The proposed method also uses DL-based non-linear\nlatent variable models to approximate the normative distri-\nbution of healthy anatomy from example images. However,\ninstead of using prior projection, we formulate the detec-\ntion as a Maximum-A-Posteriori (MAP) image restoration\nproblem with the normative image prior estimated by a DL-\nbased model, in the same spirit as the method [28], and a\nlikelihood model that places minimal assumptions on the\nlesion. The MAP estimation is then solved using gradi-\nent ascent. The proposed image restoration method is ag-\nnostic to the choice of the priors and therefore can be ap-\nplied with any DL-based latent variable model. To learn the\nimage prior for image restoration, we use VAE as well as\nGMVAE [6, 12], an extension of VAE that uses Gaussian\nmixture modeling in the latent space. We evaluate and an-\nalyze the proposed method on two different Magnetic Res-\nonance Imaging (MRI) lesion datasets, one showing brain\ntumors and the other showing lesions due to stroke. A pre-\nliminary version of this work [31] was presented at Interna-\ntional Conference on Medical Imaging with Deep Learning.\nIn this extended version, we present an in-depth analysis of\nthe model and evaluations on an additional dataset.\nWe note that unsupervised lesion detection approaches,\nincluding the method proposed here, currently yield lower\ndetection accuracy compared to the supervised approaches.\nThis is due to the fact that unsupervised lesion detection is\na much more challenging task. The method we present here\nimproves the state-of-the-art in unsupervised lesion detec-\ntion and closes the accuracy gap between supervised and\nunsupervised approaches a bit further, taking a step towards\nmaking unsupervised lesion detection a viable alternative to\nsupervised approaches with important beneﬁts as described\nabove.\nFigure 1: Overview of the detection method. (a) Training\nVAE/GMVAE as the image prior model. (b) Restoring le-\nsioned subjects with the image prior model and MAP es-\ntimation. The images shown above are for the illustration\npurpose only.\n2. Method\nWe start this section with a brief review on normative\ndistribution estimation using latent variable models, partic-\nularly VAE and GMVAE, and move on to give more details\non MAP-based image restoration for unsupervised lesion\ndetection. For an overview of the method, please refer to\nFigure 1\n2.1. Learning Prior Normative Distribution\nLatent variables models have been a popular choice for\napproximating high-dimensional distributions from a set of\nexamples. Let us denote an image with N pixels with X ∈\nRN, a latent variable model for the distribution of X in its\nmost generic form is given as\nP(X) =\nZ\nP(X|z)P(z)dz,\nwhere z ∈RM is the latent variable, P(z) is the prior dis-\ntribution in the latent space. M is the dimension of the la-\ntent space and often a much smaller M than N is used, i.e.\nM ≪N, assuming images can be represented in a lower\ndimensional sub-space of RN. The conditional distribution\nP(X|z) encodes the mapping between the latent space and\nthe image space.\nThe simplest example of a latent variable model is the\nprobabilistic principal component analysis proposed [29],\nwhere P(X|z) encodes a linear map between the latent and\nimage spaces within a Gaussian distribution, i.e. P(X|z) =\nN\n\u0000X; zT U, σ2\u0001\nwith U ∈RM×N and σ variance of the as-\nsumed noise in the data. Being powerful already, this model\nhas been used as a normative distribution in unsupervised\nlesion detection [8]. However, a linear mapping can be lim-\niting and a non-linear latent variable model with the map-\nping parameterized by neural networks [18] has been pro-\nposed to address the limitations. The version of this model\nusing Gaussian conditional distributions can be given as\nP(X|z) = N (X; µX(z; θ), ΣX(z; θ)) ,\nwhere µX(z; θ) and ΣX(z; θ) are neural networks and\nθ represents the entire set of parameters.\nGiven this\nmodel, learning is modeled as maximizing the evidence\nmaxθ\nP\nn log P(Xn), where the subscript n goes over the\nsamples.\nThe optimization of P(X) requires solving the integral\nover z either analytically or numerically. The former is not\npossible and the latter becomes infeasible for even modestly\nlarge M. MacKay in his article proposes to use importance\nsampling to address the issue [18]. VAE [14] takes this\napproach and deﬁnes a distribution Q(z|X) parameterized\nwith another neural network to approximate the true pos-\nterior P(z|X), and maximizes the evidence lower bound\n(ELBO) rather than the evidence itself\nlog P(X)\n≥\nEQ(z|X) [log P(X|z)] −KL [Q(z|X)∥P(z)]\nELBO(X)\n=\nEQ(z|X) [log P(X|z)] −KL [Q(z|X)∥P(z)] ,\nwhere P(X|z) and Q(z|X) are modeled with two net-\nworks, with the former parameterized with θ and the latter\nwith φ, and KL represents the Kullback-Leibler divergence.\nIn VAE, learning is deﬁned as\nmax\nθ,φ\nX\nn\nELBO(Xn),\nand is implemented with stochastic sampling to compute the\nexpectations in the ELBO. For further information regard-\ning the optimization of the VAE objective function, we refer\nthe readers to the original paper [14].\nFollowing the modeling choices of the original work,\nhere we use the VAE model with the following\n- P(X|z) = N\n\u0000X; µX(z), diag\n\u0000σ2\nX\n\u0001\u0001\n,\n- Q(z|X) = N\n\u0000z; µz(X), diag\n\u0000σ2\nz(X)\n\u0001\u0001\n, and\n- P(z) = N (0, IM),\nwhere diag(σ2\nX) denotes a diagonal matrix with σ2\nX ele-\nments on the diagonal.\nIM is the identity matrix in M\ndimensions, and µX(z), µz(X) and σz(X) are parameter-\nized as neural networks, whose architectures are described\nin Section 3.\nRemark: Note that with the Gaussian distribution models,\nlog P(X|z) is a computed as ℓ2 loss between the image X\nand its mean reconstruction. The ℓ2 loss is derived from\nGaussian distribution with the mean µX(z) and the ho-\nmoscedatic variance 1/σ2\nX. The variance is set as a con-\nstant value of\nq\n1\n2 for each pixel. The approaches that uses\nprior projection with VAE, or other latent-variable models,\noften ﬁrst project the image to its latent representation z and\nand then reconstruct the image with µX(z). The difference\nbetween µX(z) and X is then assumed to be the lesion.\nThe original VAE model uses a unimodal distribution as\nthe prior in the latent space. A more expressive prior can\npotentially allow the latent variable model to ﬁt more com-\nplicated distributions to the samples. With this motivation,\nGaussian Mixture VAE (GMVAE) [6] is proposed and uses\nGaussian mixture models as the prior in the latent space.\nTo model the latent distribution as Gaussian mixtures,\nthe authors introduce two additional latent variables in GM-\nVAE: k for mixture assignment and ω for mixture model co-\nefﬁcients. The prior distribution in the latent space is given\nas\nP(z|ω, k) =\nC\nY\nc=1\nN\n\u0000µkc(ω), diag(σ2\nkc(ω))\n\u0001kc ,\n(1)\nwhere c is the pre-speciﬁed number of Gaussian mixture\ncomponents, k ∼Mult( 1\nc) is a one-hot vector and ω ∼\nN(0, IM). µck(ω) and σ2\nkc(ω) are functions of ω parame-\nterized as neural networks.\nSimilar to VAE, an ELBO can be derived for GM-\nVAE [6], using multiple approximations for the posterior\ndistributions\nELBO(X)\n=\nEQ(z|X) [log P(X|z)]\n(2)\n−\nEQ(ω|X)P (k|z,ω) [KL [Q(z|X)||P(z|ω, k)]]\n−\nKL [Q(ω|X)||P(ω)]\n−\nEQ(z|X)Q(ω|X) [KL [P(k|z, ω)||P(k)]] .\nThe mixture model in the latent space gives rise to two addi-\ntional distributions Q(ω|X) and P(c|z, ω). We use a Gaus-\nsian distribution with diagonal covariance for the ﬁrst one,\nQ(ω|X) = N\n\u0000ω; µω(X), diag\n\u0000σ2\nω(X)\n\u0001\u0001\n, while the poste-\nrior for c can be computed analytically for a given ω and\nz. We use the same models for P(X|z) and Q(z|X) as in\nthe VAE model. Training of the GMVAE model follows a\nsimilar approach as VAE, and we refer the interested reader\nto the original paper [6] for details.\nWe use convolutional neural networks to parameterize\nthe necessary distributions in the VAE and the GMVAE\nmodels and train the models with MR images acquired\nfrom healthy individuals to obtain the normative distribu-\ntion, which is used in the restoration framework as ex-\nplained next. The details on the architectures and datasets\nare presented in Section 3. While the VAE and GMVAE\nmodels are used for demonstrations, the MAP-based outlier\ndetection described next can be combined with any latent\nvariable models, such as the ﬂow-based unsupervised learn-\ning approaches [11]. An illustrated reconstruction process\ncan be found in Figure 2.\n2.2. Detecting outliers with MAP-based restoration\nThe restoration framework assumes the image with the\nlesion is a “normal” image, i.e. one that is coming from the\nnormative distribution, but with an additional “noise” com-\nponent, the lesion. The goal is to restore the normal image\nfrom the “noisy” observation and in the meanwhile detect\nthe lesion as noise. This is fundamentally different from\nthe prior projection model or detecting outliers in the latent\nspace with another metric. The approach here speciﬁcally\naims to retain the normal anatomy in the images and only\nchange the outlier lesion part during the restoration. Next\nwe describe how we achieve this with a probabilistic model\nand MAP estimation.\nLet us denote an image with a lesion as Y ∈RN. We\nassume that Y is a noisy version of X ∈RN, Y = X +\nD, modeling the lesion with D ∈RN and the noise-free,\nwhich corresponds to lesion-free, version of Y with X. In\nareas of the image where no lesion is present, D = 0 should\nhold at those pixels. In cases with no lesion at all, Y = X\nshould hold in the entire image, i.e. the model should ﬁnd\nno lesion.\nThe usual MAP estimation maximizes the posterior dis-\ntribution of X given Y\narg max\nX log P(X|Y ) = arg max\nX [log P(Y |X) + log P(X)] ,\nwhere P(Y |X) is the likelihood term, which can be inter-\npreted as the data consistency term. This term reﬂects the\nassumptions on D, which we detail in Section 2.2.1. P(X)\nis the normative prior, i.e. distribution of healthy images.\nThese two terms form a balanced optimization problem.\nThe ﬁrst term aims to preserve the image by penalizing de-\nviations between the observed image and its restored ver-\nsion X. Maximizing that term alone would not change the\nimage. The second term, however, yields higher values for\nimages that ﬁt the normative distribution. An image with\nlesions has a lower probability in the normative distribution\nand consequently gives a lower log P(X). For such images,\nthe optimal point is to remove the outlier lesion that does\nnot ﬁt the normative distribution, assigning it to D, while\nkeeping the normal anatomy ﬁxed between Y and X. For\nFigure 2: Overview of the reconstruction process of VAE/GMVAE. Images are only for illustration purpose.\nan image without lesions, leaving the image unchanged is\nthe optimal solution.\nThe MAP estimation optimizes log P(X), but this term\nis neither analytically tractable nor easy to compute via\nsampling for most non-linear latent variable models. In-\nstead, for VAE and GMVAE, we propose to optimize the\nevidence lower bound, or in other words, to solve the ap-\nproximated MAP estimation problem\narg max\nX log P(X|Y ) ≈arg max\nX [log P(Y |X) + ELBO(X)] .\n(3)\nThe difference between ELBO(X) and log P(X) is given\nwith KL [Q(z|X)∥P(z|X)].\nTherefore, as the approxi-\nmation Q(z|X) gets better, the KL-divergence will go to\nzero and maximizing ELBO will get closer to maximizing\nlog P(X). An important advantage of using ELBO(X) is\nthat, it is formed of differentiable functions allowing for a\ngradient-based optimization scheme to solve the approxi-\nmate MAP problem.\nTo optimize the objective formulated in Equation 3, we\nadopt a gradient ascent method and perform iterative opti-\nmization to obtain the restored image. Speciﬁcally, in each\niteration, we approximate the gradients of P(X|Y ) by tak-\ning the gradient of Equation (3)\nGXi = ∂[log P(Y |X) + ELBO(X)]\n∂X\n\f\f\nX=Xi,\n(4)\nXi+1 = Xi + αi · GXi,\n(5)\nwhere αi is the step size at the i-th iteration, and X0 = Y .\nAssume the optimization convergences at N-th iteration, we\nthen obtain the restored image ˆX as ˆX = XN, which is an\nestimate of the lesion-free version of the observed image\nY . As we assumed an additive model, the estimated outlier\nlesion can be revealed as ˆD = Y −ˆX, providing a pixel-\nwise detection of the lesion. Taking both hypo-intense and\nhyper-intense areas into account, the absolute value of the\ndifference can also be used as the ﬁnal detected lesion, as\n| ˆD| = |Y −ˆX|.\n2.2.1\nData consistency\nThe likelihood P(Y |X) is a critical component in the MAP\nestimation. As explained in the previous section, it reﬂects\nthe modeling assumptions on D through how it measures\nthe deviation between X and Y . Penalizing certain type of\ndeviations more than the others, the likelihood term encodes\na preference over D and, thus inﬂuence the entire MAP es-\ntimation. In the unsupervised detection setting, we are aim-\ning for detecting any type of lesions in contrast to the super-\nvised detection setting, where the goal is to detect speciﬁc\ntype of lesions. As a result, P(Y |X) should not be based\non lesion-speciﬁc information, such as intensity or speciﬁc\nshape features.\nGeneric and mathematically driven like-\nlihood terms, instead of data-driven likelihood terms, can\nprovide the generality required for unsupervised detection.\nIn this work, we adopt a likelihood term that prefers D\nto be composed of larger, continuous blocks over many iso-\nlated islands. Total Variation (TV) norm [25] formulates\nthis preference and can be easily used as the likelihood term\nin the MAP estimation. Using TV norm, we deﬁne the ﬁnal\nrestoration problem as\nˆX = arg max\nX [−λ||X −Y ||T V + ELBO(X)] , λ > 0.\n(6)\nThe TV norm is weighted by λ, which balances the mag-\nnitudes of gradients from the two terms during the gradi-\nent ascent optimization. An effective weight prevents large\ndeviation between X and Y , and results in accurate detec-\ntion performance. Determining λ weight is not trivial in\nthe most generic setting. Instead, we propose a heuristic\nmethod to tune the weight using images from healthy indi-\nviduals.\n2.2.2\nDetermining the weight parameter λ\nIntuitively, images from healthy individuals are lesion-free\nand, ideally, the detection method should not detect lesions\nin them. Based on this intuition, we determine λ that mini-\nmizes the change caused by the MAP estimation on healthy\nimages. We measure the change caused by the restoration\nusing the ℓ1 distance between the restored image and the\ninput images for a small validation set composed only of\nhealthy images,\nϵ(λ) = 1\nS\nX\ns\n\f\f\fYs −ˆXλ,s\n\f\f\f ,\n(7)\nwhere we denote dependence of the restoration to λ with\nthe subscript and S denotes the number of validation images\nused for the measurement. We perform a parameter search\nin a wide range of possible values to determine the smallest\nλ that yields the smallest ϵ(λ).\nThe described heuristic approach relies on the fact that\neven lesion-free images will be changed during the restora-\ntion. This happens if the ELBO term yields non-zero gradi-\nents for images composed only of healthy anatomy. There\nare three reasons why this can happen: 1) log P(X) as mod-\neled with a latent variable model is not a perfect approxi-\nmation, 2) ELBO is an approximation to the log P(X), and\n3) P(X) may assign higher probability to certain anatom-\nical formations and appearance. Most likely, all these rea-\nsons are affecting the restoration simultaneously, and even\nhealthy images incur change during restoration. As a re-\nsult, in lesion-free images, we expect very low λ values to\nyield large number of changes in the images. Moreover,\nvery large λ values may also yield changes that have low TV\nnorm and slightly higher ELBO. In our experiments, this is\nindeed what we observed empirically. Examples of the pa-\nrameter search are plotted in Figure 10a and 11a showing\nan optimal λ value that minimizes ϵ(λ) for different prior\nmodels and datasets. More details are given in Section 3.\n2.2.3\nBinary detections by thresholding difference\nmaps\nThe described MAP estimation will yield a restored image\nˆX and the outlier area as the difference map ˆD, which is\na pixel-wise continuous map. To obtain a pixel-wise lesion\nsegmentation, which is a binary map, we need to determine\na threshold T and label pixels with differences larger than\nT as lesion and others as normal anatomy. Similar to the\ncase described in the previous section, we need to ﬁnd the\nthreshold using only healthy images in the unsupervised set-\nting. Once again, we assume that healthy images show only\nnormal anatomy and the detection method should not ﬁnd\nany lesion in a set of validation healthy images. The naive\napproach of setting the threshold to the maximal pixel-wise\ndifference in the healthy images may yield very conserva-\ntive method with high speciﬁcity but low sensitivity. In-\nstead, we adopt the approach as in [15] that implements a\ncompromise by setting a limit to the permitted False Pos-\nitive Rate (FPR) in the detection results.\nAny detection\nin the lesion-free healthy images will be a false positive.\nThe method proposed in [15] uses detections in lesion-free\nhealthy images to estimate the FPR for any threshold, and\ndetermines the smallest threshold that satisﬁes a user de-\nﬁned FPR limit. This FPR limit dependent threshold can\nthen be used to convert the difference maps ˆD into binary\nsegmentations by determining the pixels with | ˆD| > T.\nTo test the effectiveness of this approach, we addition-\nally experimented with determining the threshold using the\nROC curve as a baseline.\nIn this approach, the thresh-\nold can be determined by ﬁnding the pixel-wise difference\nvalue that maximizes the difference between true positive\nand false positive rates, i.e. TPR −FPR, on the ROC\ncurve. Note that this selection method makes use of ground-\ntruth lesion annotation to obtain the ROC curve using the\ndifference maps between detections and lesion annotations,\ntherefore, it is not unsupervised. Nonetheless, this baseline\ngives optimistic detection results to compare to the results\nusing FPR-based threshold selection.\n3. Experiments\n3.1. Datasets & Preprocessing\nWe used three different MRI datasets, one for training\nthe prior normative distribution and determining the hyper-\nparameters of the model, i.e. λ and Tls, and the other two\nfor evaluating the proposed approach for detecting lesions.\nCamCAN1: Cambridge Centre for Ageing and Neuro-\nscience dataset, described in [27], contains T1-weighted\n(CamCANT1) and T2-weighted (CamCANT2) brain scans\nof 652 healthy subjects of ages ranging from 18 to 87,\namong which 600 subjects were randomly selected as the\n1http://www.cam-can.org/\ndata for training the prior models VAE and GMVAE, and 52\nas the validation data for determining the hyper-parameters.\nBRATS172: Multimodal Brain Tumor Image Segmentation\nChallenge dataset, described in [19], contains T1-weighted\nand T2-weighted brain scans of 285 subjects with brain tu-\nmors. Among them, 210 subjects show high-grade glioblas-\ntomas and 75 subjects show low-grade gliomas. We down-\nloaded the version of the dataset published in 2017 and only\nused the T2-weighted images in this dataset, where the le-\nsions appear as hyper-intensity areas. For all the subjects in\nthis dataset, ground truth segmentations of the tumors visi-\nble in the T2-weighted images are also available.\nATLAS3: Anatomical Tracings of Lesions After Stroke\n(ATLAS) dataset , described in [17], contains 220 T1-\nweighted brain scans of stroke patients. In these images,\nthe lesions appear as hypo-intensity areas. Similar to the\nBRATS17 dataset, this dataset also has the ground truth\npixel-wise segmentations available.\nWe trained two sets of prior models, one using T2-\nweighted and the other using T1-weighted images in the\nCamCAN datasets. The former is used for the evaluations\non the BRATS17 dataset and the latter for ATLAS dataset.\nAll datasets were preprocessed before training.\nWe per-\nformed skull stripping to compute brain masks and remove\nthe skulls, registered the images to MNI space, histogram\nmatching among the CamCAN subjects using the method\nproposed in [21], and normalized pixel intensities for each\nsubject by scaling them as (I −µ(I))/(σ(I)), with I in-\ndicating the intensity values and µ(I) and σ(I) were com-\nputed on a randomly selected subject and then ﬁxed for the\nother subjects, the background pixel intensities were set to\n−3.5.\nEspecially for histogram matching, the choice of\nthe reference subject that the other subjects are matched\nto will not signiﬁcantly affect the detection results.\nTo\nmitigate possible domain gaps caused by different acqui-\nsition protocols between CamCANT2 and BRATS17 and\nbetween CamCANT1 and ATLAS, we matched histograms\nof the BRATS17 subjects to the same CamCAN subject’s\nT2-weighted image as for CamCANT2 and ATLAS sub-\njects to the same CamCAN subject’s T1-weighted image\nas for CamCANT1, both after normalizing the CamCAN\nsubjects among themselves for each modality respectively.\nBRATS17 and ATLAS are normalized in the same way as\nCamCAN.\nAll computations were done in 2D using transversal\nslices. For the sake of computation efﬁciency, we excluded\nfrom the training data the slices in the beginning and end\nof a scan in the CamCAN datasets, where no brains struc-\ntures were present. We also removed excessive background\nin all scans of CamCAN, BRATS17 and ATLAS datasets\n2https://www.med.upenn.edu/sbia/brats2018.html\n3http://fcon_1000.projects.nitrc.org/indi/\nretro/atlas.html\nto obtain transversal slices of size 200 × 200. During test-\ning, detection was applied to all the slices of a test subject\nindependently while the evaluation metrics were computed\nsubject-wise.\n3.2. Implementation Details\nWe trained two sets of normative prior models using\nthe VAE and GMVAE respectively. For each method, a\nprior model was trained for T1-weighted images and an-\nother model for T2-weighted images using the CamCAN\ndataset. The BRATS17 and ATLAS images were not used\nduring the training of the prior models.\nOur VAE architecture consists of an encoder network\nand a decoder network. The encoder consists of 6 down-\nsampling residual blocks (illustrated in Fig.3) with 16, 32,\n64, 128, 256 and 512 ﬁlters. Down-sampling is done by\ntaking a stride of 2 and up-sampling is done by bilinear up-\nsampling. The decoder network is symmetrical to the en-\ncoder network. The latent variable has a size of 2×2×512.\nWe implemented GMVAE following the repository [6]4, ex-\ncept that the GMVAE shared the same network structures\nfor the encoder and decoder as the VAE model to ensure a\nfair comparison between the two models. The latent space\nof GMAVE was therefore of the same dimension as the\nVAE. To extensively evaluate the model performance, we\nalso trained the GMVAE model with different numbers of\nGaussian mixtures and different latent dimensions, see Sec-\ntion 3.6.2. leaky-relu activation is applied to all hidden\nlayers while identity activation is applied only to output\nlayers and layers that connect to the latent variables.\nTo provide the baseline achieved by supervised methods,\na U-Net is implemented with the same encoder and decoder\nstructure while the encoder and decoder are connected by\nskip connections. Cross-entropy loss is used to train the\nnetwork. The choice of the U-Net structure is to ensure\nconsistency among experiments and may not over-perform\nthe state-of-the-art accuracy on the BRATS17 leaderboard.\nFigure 3: Down-sampling residual block. CONV: convolu-\ntional layer, BN: batch normalization, DS-CONV: down-\nsampling convolution layer.\nThe up-sampling block re-\nplaces the down-sampling convolutional layer with up-\nsampling convolutional layer.\nWe applied the proposed MAP-based detection method\nto the test images using the appropriate prior models. By\nobserving the convergence of gradient ascent optimization,\nwe performed 500 steps of restoration, with a step size of\n4https://github.com/Nat-D/GMVAE\n5 × 10−3 in the ﬁrst 100 iterations and 3 × 10−3 in the\nfollowing iterations. This training strategy was observed to\nlead to higher MAP values at the end of the optimization,\nevaluation metrics were not used to determine the strategy.\nWe refer to our proposed versions as VAE (TV) and GM-\nVAE (TV) while presenting the results.\nFor model comparison, we implemented four different\nmethods that uses prior projection approach explained in\nthe introduction.\nThese are VAE-256, VAE-128, AAE-\n128, which corresponding to models trained with images\nresized to 256×256 and 128×128, as described in [5],\nand AnoGAN proposed by [26], with all hyper-paremeters\ntuned with our datasets. We compared the detection accu-\nracy of the proposed MAP-based restoration approach using\nVAE and GMVAE to these prior works.\nLastly, we used different evaluation metrics to present\na better picture of the performance of the proposed model\nand the ones we used as comparison. First, we computed\nthe ROC curves using the continuous valued detections ˆD.\nROC curves were computed using the detections in the en-\ntire dataset. From the ROC curve, we extracted the Area-\nUnder-the-Curve (AUC), which was used as the ﬁrst metric.\nUsing the procedure explained in Section 2.2.3 we also\ncomputed thresholds at different FPR limits for all the algo-\nrithms, at 1%, 5% and 10%. We thresholded the absolute\nvalued detection maps, e.g. ˆD for our model, to construct\nbinary detection maps and computed the Dice’s Similarity\nCoefﬁcient between the ground truth segmentations and the\ndetections, referred to as DSC1, DSC5 and DSC10, respec-\ntively. The DSC values were computed subject-wise, pool-\ning all the transversal slices of the subject together. To un-\nderstand the efﬁcacy of the threshold determining method,\nwe also extracted the threshold from the ROC curve that\nyielded the biggest difference between the true positive and\nfalse positive rates, as explained previously. This thresh-\nold was also used to compute the DSC for all the methods\nand forms a baseline, and we refer to it as DSC AUC while\npresenting the results.\n3.3. Results\n3.3.1\nModel Performance and Comparisons\nWe present the quantitative results in Tables 1 and 2 with\nsummary metrics. The tables present a single AUC value\nfor each method as this metric was computed over the en-\ntire datasets, while DSC values were computed subject-\nwise and the table presents mean and standard-deviations.\nThe two variations of the proposed MAP-based detection\nmethod, with VAE and GMVAE as the prior models, are\nshown in the top rows. For GMVAE, we show results for\ndifferent number of clusters, i.e. c = 3, 6 and 9. The base-\nline methods are shown in the following rows.\nIn our experiments with the BRATS17 dataset, the base-\nline methods, namely VAE-256, VAE-128, AAE-128 and\nAnoGAN, yielded values of 0.70 or lower. In comparison,\nthe proposed method improved the AUC score to over 0.80\nfor all the prior models. Similar results were obtained in\nthe experiments with the ATLAS dataset. The variations of\nthe proposed MAP-based detection method yielded higher\nAUC for both prior terms. The GMVAE prior model yielded\na modestly higher AUC than the VAE prior model in the\nBRATS17 dataset and the same AUC values in the Atlas\ndataset. The ROC curves for both the datasets are presented\nin Figure 4.\nThe DSC values revealed a similar picture as the AUC\nwith respect to baseline methods. In the experiments with\nthe BRATS17 dataset, in a setting with conservative FPR\nlimit, i.e. 1%, baseline methods achieved DSC values lower\nthan 0.10. The proposed method improved the DSC to 0.34\nwith VAE and more than 0.20 for all the GMVAE variations\non average. When the FPR limit was increased to 5%, a less\nconservative limit, all the methods yielded higher DSC than\nin the 1% limit setting. Despite the increase, the DSC of\nthe baseline methods remained lower than 0.20. The pro-\nposed method improved mean DSC substantially for all the\nprior terms over the best baseline methods. In the least con-\nservative setting with FPR limit at 10%, DSC value of the\nbest baseline method (VAE-128) increased to 0.26, which\nis comparable to the DSC the proposed method with GM-\nVAE at 1% FPR limit. The DSC values of the other baseline\nmethods were also higher at this FPR limit.\nSimilar trends were also observed in the experiments\nwith the ATLAS dataset. DSC values of the proposed meth-\nods were substantially higher than the ones yielded by base-\nline methods for both prior terms. However, the DSC val-\nues were substantially lower for all the methods in the AT-\nLAS dataset compared to those in the BRATS17 dataset.\nThe lower DSC values are due to the difﬁculty of the de-\ntection task in the ATLAS dataset. As can be seen in the\nvisual examples shown in Figure 6, lesions can be smaller\nand have similar intensities as the normal structures. These\nlower DSC values also demonstrate the current limitations\nin the performance of the unsupervised lesion detection ap-\nproaches, and suggests substantial room for improvement.\nIn our experiments, there was not a clear winner between\nVAE and GMVAE priors in the MAP restoration approach.\nGMVAE prior with c = 9 yielded higher AUC and mean\nDSC at 5% and 10% FPR limits than using VAE prior on the\nBRATS17 dataset. However, the increase was not observed\nin the ATLAS dataset.\nThe DSC AUC values are presented at the left most col-\numn in both the tables. These scores were obtained with\nthresholds computed retrospectively with the knowledge of\nthe ROC curves, therefore, they cannot be used for evalu-\nation. However, they are useful for evaluating the efﬁcacy\nof the method for identifying the thresholds automatically,\nwhich was described in Section 2.2.3. We observe that DSC\nTable 1: Quantitative results on the BRATS17 dataset: Summarized AUC and DSC values for the proposed MAP-based\ndetection with VAE and GMVAE as prior models, and other baseline methods are presented in the table. DSC1, DSC5,\nDSC10 are DSC values calculated with automatically determined thresholds that corresponds to limiting FPR to 1%, 5% and\n10% on the training set, respectively. For GMVAE (TV) the automatically determined weighting parameter λ was 5.0 for\nc = 3, 4.8 for c = 6 and 4.0 for c = 9 . For VAE (TV) this value was 2.4. *shows the DICE score for U-Net. The best results\nare indicated in bold, higher results are better.\nMethods\nAUC\nDSC1\nDSC5\nDSC10\nDSC AUC\nVAE (TV) (ours)\n0.80\n0.34±0.20\n0.36±0.27\n0.40±0.24\n0.34±0.18\nGMVAE (TV), c=3 (ours)\n0.82\n0.21±0.20\n0.39±0.22\n0.38±0.20\n0.35±0.20\nGMVAE (TV), c=6 (ours)\n0.81\n0.31±0.14\n0.40±0.22\n0.37±0.16\n0.33±0.19\nGMVAE (TV), c=9 (ours)\n0.83\n0.32±0.23\n0.45±0.20\n0.42±0.19\n0.36±0.19\nVAE-256\n0.67\n0.06±0.06\n0.18±0.13\n0.25±0.20\n0.20±0.14\nVAE-128\n0.69\n0.09±0.06\n0.19±0.15\n0.26±0.17\n0.22±0.14\nAAE-128\n0.70\n0.03±0.03\n0.18±0.14\n0.23±0.15\n0.23±0.13\nAnoGAN\n0.65\n0.02±0.02\n0.10±0.06\n0.19±0.13\n0.19±0.10\nU-Net (supervised)\n/\n/\n/\n/\n0.85*\nTable 2: Qualitative results on the ATLAS dataset. Summarized AUC and DSC for GMVAE(TV) and baseline methods. Same\nmetrics as in Table 1 are presented in this table. For the ATLAS dataset, for GMVAE (TV) the automatically determined λ\nwas 3.0 for c = 3, 4.0 for c = 6 and 6.0 for c = 9. For VAE (TV) this value was 3.0. *shows the DICE score for U-Net. The\nbest results are indicated in bold, higher results are better.\nMethods\nAUC\nDSC1\nDSC5\nDSC10\nDSC AUC\nVAE(TV) (ours)\n0.79\n0.10±0.06\n0.11±0.05\n0.11±0.05\n0.11±0.07\nGMVAE(TV), c=3 (ours)\n0.79\n0.06±0.06\n0.09±0.07\n0.08±0.07\n0.07±0.07\nGMVAE(TV), c=6 (ours)\n0.79\n0.10±0.09\n0.12±0.12\n0.08±0.07\n0.08±0.08\nGMVAE(TV), c=9 (ours)\n0.77\n0.08±0.07\n0.10±0.08\n0.07±0.07\n0.08±0.07\nVAE-256\n0.66\n0.00±0.00\n0.01±0.01\n0.02±0.02\n0.02±0.02\nVAE-128\n0.64\n0.00±0.00\n0.01±0.01\n0.01±0.01\n0.01±0.01\nAAE-128\n0.63\n0.00±0.00\n0.01±0.01\n0.01±0.01\n0.01±0.01\nAnoGAN\n0.64\n0.00±0.00\n0.01±0.01\n0.02±0.02\n0.01±0.01\nU-Net (supervised)\n/\n/\n/\n/\n0.50*\nvalues obtained with the automatic method were similar to\nthose set using ROC curves for all the methods, suggesting\nthat the automatic method is indeed appropriate for identi-\nfying thresholds for generating binary detection maps.\nLastly, we present visual results obtained by the pro-\nposed method using the GMVAE prior model in Figures 5\nand 6. Figures show both continuous valued detections, ˆD,\nand binary detection maps thresholded at the selected FPR\nlimits. From the BRATS17 dataset, to give a better per-\nspective of the performance, we selected images with large\nand small tumors, and show how the detection performance\nwas affected by tumor sizes. Cases with large tumors are\nshown in columns A to D and small tumors in columns E\nto G in Figure 5. In the restored images (row 2), the abnor-\nmal intensities have been substantially reduced to a normal\nrange, resulting in detectable intensity changes in the differ-\nence images (row 3). For tumors of large sizes, the thresh-\nolded detection results matches well with the ground truth\nsegmentations. Smaller tumors were more difﬁcult for the\nmethod to detect accurately. Particularly, the method may\ninclude ”abnormal-looking” healthy tissues in the detection\nin addition to the small tumors (column F) or produce no\ndetections, overlooking the tumors. We also note that al-\nthough the detection becomes less accurate on small tumors,\nFigure 4: ROC curves of proposed methods against baselines. Left: ROC curves of all methods computed on the BRATS17\ndataset. Right: ROC curves of all methods computed on the ATLAS dataset. ROC curves were computed with the entire\ndatasets. Dashed line indicates the random detection.\nFigure 5: Visual examples of lesion detection with the GMVAE (TV) model with c = 9 for the BRATS17 dataset. Rows 1\nto 7 show the input images, restored images, continuous detection maps ˆD, binary detection maps based on automatically\ndetermined thresholds at %1, %5 and %10 FPR limits, and ground-truth lesion segmentation, respectively. Columns A to G\nare images of 7 randomly selected subjects from the dataset.\nthe method does not detect healthy pixels in a large region\nto be abnormal. Comparing binary detections at different\nFPR limits, we observe that as the FPR limit is higher the\ndetections include more tumor pixels as well as non-tumor\npixels, as expected.\nVisual results for the ATLAS dataset are shown in Fig-\nure 6. This problem is much harder due to the size and\nintensity characteristics of the lesions. Comparing the con-\nFigure 6: Lesion detection with GMVAE(TV) with c = 6 for ATLAS dataset. Visualization is the same as Figure 5.\n(a)\n(b)\nFigure 7: Lesion size vs. Accuracy. The accuracy is measured as DSC5 and plotted on the y-axis, and the lesion size is\nmeasured as the number of annotated pixels for the lesion and is plotted on the x-axis. The model and parameters that\nachieve the highest DSC on each dataset are used. (a) BRATS17 dataset, results obtained by the trained GMVAE(TV, c=9).\n(b) ATLAS dataset, results obtained by the trained GMVAE(TV, c=6).\ntinuous valued detection maps shown in the third row and\nthe ground truth segmentations in the last row shows that\nthe model is able to highlight the lesions but with additional\nareas including normal structures. Binary detections pre-\nsented in the fourth-to-sixth rows show this more clearly.\nWhile the lesion pixels are often captured in the outlier\n(a)\n(b)\nFigure 8: Lesion size vs. FPR. FPR is computed for each subject with the threshold ˆD and ground truth lesion segmentation\nand is plotted on the y-axis, and the lesion size is measured as the number of annotated pixels for the lesion and is plotted on\nthe x-axis. The model and parameters that achieve the highest DSC on each dataset are used. (a) BRATS17 dataset, results\nobtained by the trained GMVAE(TV, c=9). (b) ATLAS dataset, results obtained by the trained GMVAE(TV, c=6).\n(a)\n(b)\nFigure 9: Detection on consecutive slices on (a) slices 72-80 from subject Brats17 TCIA 490 1 from BRATS17, prior model\ntrained with GMVAE (TV, c=9) and (b) slices 55-63 from subject 031859 t1w deface stx from ATLAS, prior model trained\nwith GMVAE (TV, c=6). We notice that the visualised ATLAS images are horizontally ﬂipped, and yet this does not affect\ntraining or evaluation.\nmaps, multiple areas displaying normal anatomy are also\ncaptured, yielding lower DSC values at the end.\n3.4. Accuracy Analysis with Lesion Size\nTo observe the relation between detection accuracy and\ntumor size, we calculated the dice scores for all test sub-\njects in BRATS17 and ATLAS respectively. Speciﬁcally,\nwe measured the lesion size as the annotated lesion pixels.\nThe relation is visualized as scatter-plots in Figure 5 using\nthe best-performing model for the two datasets.\nThe scatter-plots for the two dataset both indicate a ten-\ndency that higher dice scores are often obtained on subjects\nwith larger lesions. The tendency is more obvious on AT-\nLAS dataset while it is weak on BRATS17. As shown as\nFigure 6(a) ad (b), the FPR for BRATS17 is mostly between\n0.10 and 0.20 while the FPR for ATLAS is mostly lower\nthan 0.10. Although the accuracy on BRATS is signiﬁcantly\nhigher than ATLAS, the low FPR on ATLAS may be caused\nby the large amount of true negatives. On the other hand, as\nin Figure 5(b), the higher dice score achieved on ATLAS is\nfor a subject with the largest lesion and very small lesions\nwith size < 25000 pixels mostly give dice scores lower than\nthe best average dice of 0.12. However, in Figure 5(a),this\naccuracy-size relation is less obvious on BRATS17 than AT-\nLAS. With the size larger than approximately 25000, dice\nscores higher than the optimal average dice, 0.45, can be\nachieved. As the lesion size increases, the dice scores can\nvary from 0.1 to 0.8. The highest dice score is also not\nobtained for the relatively larger lesions with more than\n200,000 pixels. Besides the lesion size, other characteris-\ntics of the lesion, such as intensity, location and shape, may\nalso affect the accuracy in a complicated way.\n3.5. 3D consistency in detection\nAs the scans come as 3D volumes, we would like to ob-\nserve if the purposed model has detection consistency in the\n3D manner. As shown in Figure 9a and 9b, the detected le-\nsions are consistent across the slices.\n3.6. Model Analysis with GMVAE prior\nTo further analyze the behavior of the method, we in-\nvestigated the effects of the model hyperparameters on the\nperformance and the convergence behavior of the optimiza-\ntion. Our analyses focuses on the proposed method used\nwith GMVAE, as this version lead to slightly higher per-\nformance and it also has additional hyperparameters. We\nexperimented with data consistency weight λ, the number\nof Gaussian mixtures c and the dimension of the latent vari-\nable dimz.\n3.6.1\nData Consistency Weighed with Different λ Val-\nues\nThe weight parameter λ is actually selected automatically\nusing the method described in Section 2.2.2. For this selec-\ntion, the method relies on the error term ϵ(λ) computed us-\ning a set of validation images. Here we investigate how ϵ(λ)\nchanges. First, we plot λ vs ϵ(λ) in Figures 10a and 11a\nto show the behavior of this term. The plots are generated\nusing GMVAE prior models that was trained with T2- and\nT1-weighted images from the CamCANT2 dataset, respec-\ntively. ϵ(λ) was evaluated using the validation images for\ndifferent λ values. We observe a dip in the curves indicat-\ning optimal λ values that yielded the least amount of change\non validation images consisting only of healthy anatomy\nfor each c. These values were used in the experiments on\nthe BRATS17 and ATLAS dataset with the GMVAE prior\nmodel presented previously.\nA natural question that arises is whether choosing λ ac-\ncording to ϵ(λ) corresponds to choosing the best λ accord-\ning to the detection accuracy on a speciﬁc lesion dataset. To\nanswer this question and analyze the sensitivity of the de-\ntection results to the λ parameter, we repeated the detection\nexperiments with multiple λ values in the [1.0, 9.0] range\nand evaluated the performance of these different models us-\ning AUCs. Figures 10b and 11b plots the results of these\nexperiments.\nFirst, we observe that λ value can inﬂuence the AUC.\nVery low λ values yielded lower AUC values in both the\ndatasets. Second, we see that the λ values chosen using\nϵ(λ) are not very far from the λ values that yielded the maxi-\nmum AUC values for all the prior terms in both the datasets.\nChoosing the λ using the method described in Section 2.2.2\nled to at most 0.01 less than the maximum AUC values.\n3.6.2\nAnalysis of the Gaussian Mixture Prior\nGMVAE uses a Gaussian mixture model as the prior distri-\nbution in the latent space to allow ﬁtting more complex nor-\nmative distributions. This model has two hyper-parameters:\nnumber of Gaussian mixtures c and the dimension of the la-\ntent space. In this section, we present analysis showing the\neffect of these parameters on the detection performance on\nthe BRATS17 dataset.\nFor a range of the cluster number c and latent space di-\nmension dimz, we trained multiple prior models and de-\ntected lesions on the BRATS17 datasets. In Table 3 we\npresent the detection results for the different ranges. We\nnotice that in terms of AUC, the parameters have minimal\neffect. For DSC, 512 latent dimensions seems to provide\nthe highest scores for all the FPR limits and c. The numer-\nical differences, however, are small compared to the stan-\ndard deviations. The biggest difference is arguably between\nc = 3 and the others in DSC1 and DSC5. Increasing c\nseems to improve DSC at these FPR limits. Additionally,\nGMVAE with c = 1 is a special case of GMVAE and is\nsimilar to VAE. We empirically validate this by reporting\nthe results of GMVAE (c = 1) in Table 3 and Figure 10 and\n11. GMVAE(TV) with c = 1 give very similar results to\nVAE(TV).\n3.6.3\nConvergence of Image Restoration\nAs the image restoration is performed in an iterative man-\nner, it is important to show that the restoration stably con-\nverges at an optimal point. We experimentally show the\nconvergence of the restoration process. We evaluated the\nAUC using the BRATS17 and ATLAS datasets at each 50\nsteps during the MAP-optimization and plot the evolution\nof AUC with respect to gradient-ascent steps in Figures 10c\nand 11c. For the restoration on BRATS17, the plot shows a\nsharp increase in the ﬁrst 100 iterations and then increases\nto stable values until 500th iterations at around AUC=0.8\nfor all the selected c values. For the restoration on ATLAS,\nthe plot shows similar increases where the AUC values in-\ncreases in the ﬁrst 300 iterations and stabilizes around 0.80.\nThe plots indicate that the iterative restoration converged\nand the model performance stably improved with increas-\ning restoration steps.\n4. Conclusions\nWe proposed an unsupervised detection method which\nrestores images using an estimated normative prior for\nhealthy images. Speciﬁcally, the image prior was learned\nwith autoencoding-based methods, VAE and GMVAE, and\nTable 3: AUC/DSC values for varying latent space dimension dimz and number of clusters c in GMVAE (TV). Mean and\nstandard deviations are shown for DSC at different FPR limits. Results are shown for the BRATS17 dataset. Best results are\nindicated in bold.\nc\ndimz\nAUC\nDSC1\nDSC5\nDSC10\nDSC AUC\nc=1\n256\n0.80\n0.32±0.22\n0.34±0.24\n0.36±0.24\n0.32±0.19\n512\n0.80\n0.33±0.24\n0.36±0.24\n0.39±0.23\n0.35±0.19\n1024\n0.79\n0.30±0.22\n0.31±0.23\n0.33±0.23\n0.31±0.18\nc=3\n256\n0.82\n0.20±0.18\n0.32±0.23\n0.30±0.21\n0.30±0.18\n512\n0.82\n0.21±0.20\n0.39±0.22\n0.38±0.20\n0.35±0.20\n1024\n0.82\n0.20±0.19\n0.34±0.19\n0.33±0.19\n0.32±0.20\nc=6\n256\n0.81\n0.30±0.21\n0.40±0.18\n0.35±0.20\n0.34±0.18\n512\n0.81\n0.32±0.23\n0.44±0.21\n0.41±0.20\n0.35±0.18\n1024\n0.81\n0.29±0.22\n0.38±0.23\n0.35±0.19\n0.33±0.19\nc=9\n256\n0.82\n0.32±0.30\n0.38±0.19\n0.36±0.15\n0.31±0.15\n512\n0.83\n0.31±0.23\n0.45±0.20\n0.42±0.19\n0.36±0.19\n1024\n0.82\n0.30±0.14\n0.38±0.22\n0.35±0.20\n0.34±0.18\n(a)\n(b)\n(c)\nFigure 10: Analysis graphs obtained using the proposed method with the GMVAE prior trained with T2-weighted images\nin the CamCANT2 dataset. (a) ϵ(λ) vs. λ curve used to determine the optimal hyperparameter λ value using the validation\nimages from the CamCANT2 dataset consisting only of normal anatomy. (b) AUC vs. λ curve showing stable performance\non the BRATS17 dataset over a range of λ values. This curve is not used to determine the hyperparameter but only for\nanalysis. (c) Evolution of the AUC over the gradient-ascent iterations during MAP-optimization showing convergence. The\nAUC values are computed on the BRATS17 dataset.\nthe images were iteratively restored with MAP estimation.\nDetection on brain lesion datasets showed that the proposed\nmethod achieved better AUC and Dice scores, signiﬁcantly\noutperforming the existing methods. Extended model anal-\nysis on GMVAE indicated that the prior learned by this\nmodel is robust to parameter selection and the model shows\nstable convergence. Meanwhile, the model has limited ca-\npability when applied to detect small and unobvious lesions.\nOn the other hand, some lesions may cause large defor-\nmations in the surrounding healthy structures. Although\nthe data consistency term prevents the model from detect-\ning such deformations as abnormal lesions, there is limited\nguarantee that large deformations will not be detected as\nabnormalities. We have not observed this in our experi-\nments, however, this remains a limitation. To improve the\nperformance, future works may impose noise assumption\nthat better describes the lesions and use adaptive threshold-\ning selection.\nAcknowledgments\nWe thank Swiss National Science Foundation (SNSF)\nand Platform for Advanced Scientiﬁc Computing (PASC)\nfor funding this project (project no. 205321 173016), as\n(a)\n(b)\n(c)\nFigure 11: Similar plots are shown for T1-weighted images as in Figure 10, (a) ϵ(λ) vs. λ curve. (b) AUC vs. λ curve. (c)\nEvolution of the AUC over the gradient-ascent iterations during MAP-optimization showing convergence. GMVAE priors\nare trained with the T1-weighted images in the CamCANT1 dataset and the detections are evaluated on the ATLAS dataset.\nwell as Nvidia for GPU donations.\nReferences\n[1] R. Ayachi and N. B. Amor. Brain tumor segmenta-\ntion using support vector machines. In European Con-\nference on Symbolic and Quantitative Approaches to\nReasoning and Uncertainty, pages 736–747. Springer,\n2009.\n[2] C. Baur, B. Wiestler, S. Albarqouni, and N. Navab.\nDeep autoencoding models for unsupervised anomaly\nsegmentation in brain mr images.\narXiv preprint\narXiv:1804.04488, 2018.\n[3] M. J. Cardoso,\nC. H. Sudre,\nM. Modat,\nand\nS. Ourselin. Template-based multimodal joint genera-\ntive model of brain data. In International Conference\non Information Processing in Medical Imaging, pages\n17–29. Springer, 2015.\n[4] X. Chen and E. Konukoglu. Unsupervised detection of\nlesions in brain mri using constrained adversarial auto-\nencoders. arXiv preprint arXiv:1806.04972, 2018.\n[5] X. Chen, N. Pawlowski, M. Rajchl, B. Glocker, and\nE. Konukoglu. Deep generative models in the real-\nworld:\nAn open challenge from medical imaging.\narXiv preprint arXiv:1806.05452, 2018.\n[6] N. Dilokthanakul, P. A. Mediano, M. Garnelo, M. C.\nLee, H. Salimbeni, K. Arulkumaran, and M. Shana-\nhan.\nDeep unsupervised clustering with gaussian\nmixture variational autoencoders.\narXiv preprint\narXiv:1611.02648, 2016.\n[7] H. Dong, G. Yang, F. Liu, Y. Mo, and Y. Guo. Au-\ntomatic brain tumor detection and segmentation us-\ning u-net based fully convolutional networks. In An-\nnual Conference on Medical Image Understanding\nand Analysis, pages 506–517. Springer, 2017.\n[8] G. Erus, E. I. Zacharaki, and C. Davatzikos.\nIn-\ndividualized statistical learning from medical image\ndatabases: Application to identiﬁcation of brain le-\nsions. Medical image analysis, 18(3):542–554, 2014.\n[9] E. Geremia, O. Clatz, B. H. Menze, E. Konukoglu,\nA. Criminisi, and N. Ayache. Spatial decision forests\nfor ms lesion segmentation in multi-channel magnetic\nresonance images. NeuroImage, 57(2):378–390, 2011.\n[10] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu,\nD. Warde-Farley, S. Ozair, A. Courville, and Y. Ben-\ngio. Generative adversarial nets. In Advances in neu-\nral information processing systems, pages 2672–2680,\n2014.\n[11] W.\nGrathwohl,\nR.\nT.\nChen,\nJ.\nBetterncourt,\nI. Sutskever, and D. Duvenaud.\nFfjord:\nFree-\nform continuous dynamics for scalable reversible\ngenerative models. arXiv preprint arXiv:1810.01367,\n2018.\n[12] M. J. Johnson, D. Duvenaud, A. B. Wiltschko, S. R.\nDatta, and R. P. Adams. Structured vaes: Composing\nprobabilistic graphical models and variational autoen-\ncoders. arXiv preprint arXiv:1603.06277, 2, 2016.\n[13] K. Kamnitsas, C. Ledig, V. F. Newcombe, J. P. Simp-\nson, A. D. Kane, D. K. Menon, D. Rueckert, and\nB. Glocker.\nEfﬁcient multi-scale 3d cnn with fully\nconnected crf for accurate brain lesion segmentation.\nMedical image analysis, 36:61–78, 2017.\n[14] D. P. Kingma and M. Welling. Auto-encoding varia-\ntional bayes. arXiv preprint arXiv:1312.6114, 2013.\n[15] E. Konukoglu, B. Glocker, A. D. N. Initiative, et al.\nReconstructing subject-speciﬁc effect maps. NeuroIm-\nage, 181:521–538, 2018.\n[16] H. Li, G. Jiang, J. Zhang, R. Wang, Z. Wang, W.-S.\nZheng, and B. Menze. Fully convolutional network\nensembles for white matter hyperintensities segmen-\ntation in mr images. NeuroImage, 183:650–665, 2018.\n[17] S.-L. Liew, J. M. Anglin, N. W. Banks, M. Sondag,\nK. L. Ito, H. Kim, J. Chan, J. Ito, C. Jung, N. Khoshab,\net al. A large, open source dataset of stroke anatomical\nbrain images and manual lesion segmentations. Scien-\ntiﬁc data, 5:180011, 2018.\n[18] D. J. MacKay.\nBayesian neural networks and den-\nsity networks. Nuclear Instruments and Methods in\nPhysics Research Section A: Accelerators, Spectrome-\nters, Detectors and Associated Equipment, 354(1):73–\n80, 1995.\n[19] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer,\nK. Farahani, J. Kirby, Y. Burren, N. Porz, J. Slotboom,\nR. Wiest, et al. The multimodal brain tumor image\nsegmentation benchmark (brats). IEEE transactions\non medical imaging, 34(10):1993, 2015.\n[20] N. Moon, E. Bullitt, K. Van Leemput, and G. Gerig.\nAutomatic brain and tumor segmentation.\nIn Inter-\nnational Conference on Medical Image Computing\nand Computer-Assisted Intervention, pages 372–379.\nSpringer, 2002.\n[21] L. G. Ny´ul, J. K. Udupa, and X. Zhang. New variants\nof a method of mri scale standardization. IEEE trans-\nactions on medical imaging, 19(2):143–150, 2000.\n[22] N. Pawlowski, M. C. H. Lee, M. Rajchl, S. Mc-\nDonagh, E. Ferrante, K. Kamnitsas, S. Cooke, S. K.\nStevenson, A. M. Khetani, T. Newman, F. A. Zeiler,\nR. J. Digby, J. P. Coles, D. Rueckert, D. K. Menon,\nV. F. J. Newcombe, and B. Glocker. Unsupervised le-\nsion detection in brain ct using bayesian convolutional\nautoencoders. 2018.\n[23] S. Pereira, A. Pinto, V. Alves, and C. A. Silva. Brain\ntumor segmentation using convolutional neural net-\nworks in mri images. IEEE transactions on medical\nimaging, 35(5):1240–1251, 2016.\n[24] M. Prastawa, E. Bullitt, S. Ho, and G. Gerig. A brain\ntumor segmentation framework based on outlier de-\ntection. Medical image analysis, 8(3):275–283, 2004.\n[25] L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total\nvariation based noise removal algorithms. Physica D:\nnonlinear phenomena, 60(1-4):259–268, 1992.\n[26] T. Schlegl, P. Seeb¨ock, S. M. Waldstein, U. Schmidt-\nErfurth, and G. Langs.\nUnsupervised anomaly de-\ntection with generative adversarial networks to guide\nmarker discovery. In International Conference on In-\nformation Processing in Medical Imaging, pages 146–\n157. Springer, 2017.\n[27] J. R. Taylor, N. Williams, R. Cusack, T. Auer, M. A.\nShafto, M. Dixon, L. K. Tyler, R. N. Henson, et al. The\ncambridge centre for ageing and neuroscience (cam-\ncan) data repository: structural and functional mri,\nmeg, and cognitive data from a cross-sectional adult\nlifespan sample. Neuroimage, 144:262–269, 2017.\n[28] K. C. Tezcan, C. F. Baumgartner, R. Luechinger, K. P.\nPruessmann, and E. Konukoglu. Mr image reconstruc-\ntion using deep density priors. IEEE transactions on\nmedical imaging, 2018.\n[29] M. E. Tipping and C. M. Bishop. Probabilistic prin-\ncipal component analysis. Journal of the Royal Sta-\ntistical Society: Series B (Statistical Methodology),\n61(3):611–622, 1999.\n[30] K.\nVan\nLeemput,\nF.\nMaes,\nD.\nVandermeulen,\nA. Colchester, and P. Suetens.\nAutomated segmen-\ntation of multiple sclerosis lesions by model outlier\ndetection.\nIEEE transactions on medical imaging,\n20(8):677–688, 2001.\n[31] S. You, K. Tezcan, X. Chen, and E. Konukoglu. Unsu-\npervised lesion detection via image restoration with a\nnormative prior. In International Conference on Med-\nical Image with Deep Learning, 2019.\n[32] E. I. Zacharaki and A. Bezerianos.\nAbnormality\nsegmentation in brain images via distributed estima-\ntion. IEEE Transactions on Information Technology\nin Biomedicine, 16(3):330–338, 2012.\n[33] K. Zeng, G. Erus, A. Sotiras, R. T. Shinohara, and\nC. Davatzikos.\nAbnormality detection via itera-\ntive deformable registration and basis-pursuit decom-\nposition.\nIEEE transactions on medical imaging,\n35(8):1937–1951, 2016.\n[34] D. Zikic, B. Glocker, E. Konukoglu, J. Shotton,\nA. Criminisi, D. Ye, C. Demiralp, O. Thomas,\nT. Das, R. Jena, et al. Context-sensitive classiﬁcation\nforests for segmentation of brain tumor tissues. Proc\nMICCAI-BraTS, pages 1–9, 2012.\n",
  "categories": [
    "eess.IV",
    "cs.CV"
  ],
  "published": "2020-04-30",
  "updated": "2020-04-30"
}