{
  "id": "http://arxiv.org/abs/2005.06068v1",
  "title": "Deep Learning for Wireless Communications",
  "authors": [
    "Tugba Erpek",
    "Timothy J. O'Shea",
    "Yalin E. Sagduyu",
    "Yi Shi",
    "T. Charles Clancy"
  ],
  "abstract": "Existing communication systems exhibit inherent limitations in translating\ntheory to practice when handling the complexity of optimization for emerging\nwireless applications with high degrees of freedom. Deep learning has a strong\npotential to overcome this challenge via data-driven solutions and improve the\nperformance of wireless systems in utilizing limited spectrum resources. In\nthis chapter, we first describe how deep learning is used to design an\nend-to-end communication system using autoencoders. This flexible design\neffectively captures channel impairments and optimizes transmitter and receiver\noperations jointly in single-antenna, multiple-antenna, and multiuser\ncommunications. Next, we present the benefits of deep learning in spectrum\nsituation awareness ranging from channel modeling and estimation to signal\ndetection and classification tasks. Deep learning improves the performance when\nthe model-based methods fail. Finally, we discuss how deep learning applies to\nwireless communication security. In this context, adversarial machine learning\nprovides novel means to launch and defend against wireless attacks. These\napplications demonstrate the power of deep learning in providing novel means to\ndesign, optimize, adapt, and secure wireless communications.",
  "text": "1\nDeep Learning for Wireless Communications\nTugba Erpek, Timothy J. O‚ÄôShea, Yalin E. Sagduyu, Yi Shi, T. Charles Clancy\nAbstract\nExisting communication systems exhibit inherent limitations in translating theory to practice when handling\nthe complexity of optimization for emerging wireless applications with high degrees of freedom. Deep learning\nhas a strong potential to overcome this challenge via data-driven solutions and improve the performance of\nwireless systems in utilizing limited spectrum resources. In this chapter, we Ô¨Årst describe how deep learning is\nused to design an end-to-end communication system using autoencoders. This Ô¨Çexible design effectively captures\nchannel impairments and optimizes transmitter and receiver operations jointly in single-antenna, multiple-antenna,\nand multiuser communications. Next, we present the beneÔ¨Åts of deep learning in spectrum situation awareness\nranging from channel modeling and estimation to signal detection and classiÔ¨Åcation tasks. Deep learning improves\nthe performance when the model-based methods fail. Finally, we discuss how deep learning applies to wireless\ncommunication security. In this context, adversarial machine learning provides novel means to launch and defend\nagainst wireless attacks. These applications demonstrate the power of deep learning in providing novel means to\ndesign, optimize, adapt, and secure wireless communications.\nIndex Terms\nDeep learning, wireless systems, physical layer, end-to-end communication, signal detection and classiÔ¨Åcation,\nwireless security.\nI. INTRODUCTION\nIt is of paramount importance to deliver information in wireless medium from one point to another\nquickly, reliably, and securely. Wireless communications is a Ô¨Åeld of rich expert knowledge that involves\ndesigning waveforms (e.g., long-term evolution (LTE) and Ô¨Åfth generation mobile communications systems\n(5G)), modeling channels (e.g., multipath fading), handling interference (e.g., jamming) and trafÔ¨Åc (e.g.,\nnetwork congestion) effects, compensating for radio hardware imperfections (e.g., RF front end non-\nlinearity), developing communication chains (i.e., transmitter and receiver), recovering distorted symbols\nand bits (e.g., forward error correction), and supporting wireless security (e.g., jammer detection). The\ndesign and implementation of conventional communication systems are built upon strong probabilistic\nanalytic models and assumptions. However, existing communication theories exhibit strong limitations in\nutilizing limited spectrum resources and handling the complexity of optimization for emerging wireless\napplications (such as spectrum sharing, multimedia, Internet of Things (IoT), virtual and augmented\nreality), each with high degrees of freedom. Instead of following a rigid design, new generations of\nwireless systems empowered by cognitive radio [1] can learn from spectrum data, and optimize their\nspectrum utilization to enhance their performance. These smart communication systems rely on various\ndetection, classiÔ¨Åcation, and prediction tasks such as signal detection and signal type identiÔ¨Åcation in\nspectrum sensing to increase situational awareness. To achieve the tasks set forth in this vision, machine\nlearning (especially deep learning) provides powerful automated means for communication systems to\nlearn from spectrum data and adapt to spectrum dynamics [2].\nWireless communications combine various waveform, channel, trafÔ¨Åc, and interference effects, each with\nits own complex structures that quickly change over time, as illustrated in Fig. 1. The data underlying\nwireless communications come in large volumes and at high rates, e.g., gigabits per second in 5G, and\nT. Erpek and T. C. Clancy are with Virginia Tech, Arlington, VA, USA. E-mail: {terpek,tcc}@vt.edu\nT. J. O‚ÄôShea is with Virginia Tech, Arlington, VA and DeepSig, Inc., Arlington, VA, USA. E-mail: oshea@vt.edu\nY. E. Sagduyu is with Intelligent Automation, Inc., Rockville, MD, USA. E-mail: ysagduyu@i-a-i.com\nY. Shi is with Virginia Tech, Blacksburg, VA, USA. E-mail: yshi@vt.edu\narXiv:2005.06068v1  [cs.NI]  12 May 2020\n2\nFig. 1. Example of dynamic spectrum data from several frequency bands.\nis subject to harsh interference and various security threats due to the shared nature of wireless medium.\nTraditional modeling and machine learning techniques often fall short of capturing the delicate relationship\nbetween highly complex spectrum data and communication design, while deep learning has emerged as\na viable means to meet data rate, speed, reliability, and security requirements of wireless communication\nsystems. One motivating example in this regard is from signal classiÔ¨Åcation where a receiver needs to\nclassify the received signals [3] based on waveform features, e.g., modulation used at the transmitter\nthat adds the information to the carrier signal by varying its properties (e.g., amplitude, frequency, or\nphase). This signal classiÔ¨Åcation task is essential in dynamic spectrum access (DSA) where a transmitter\n(secondary user) needs to Ô¨Årst identify signals of primary users (such as TV broadcast networks) who\nhas the license to operate on that frequency and then avoid interference with them (by not transmitting\nat the same time on the same frequency). Fig. 2 shows that deep learning based on convolutional neural\nnetworks (CNN) achieves signiÔ¨Åcantly higher accuracy in signal classiÔ¨Åcation compared to feature based\nclassiÔ¨Åers using support vector machine (SVM) or Naive Bayes. This performance gain is consistent\nacross different signal-to-noise ratio (SNR) levels that capture the distance from transmitter to receiver\nand the transmit power. One particular reason is that conventional machine learning algorithms rely on\nthe representative value of inherent features that cannot be reliably extracted from spectrum data, where\ndeep learning can be readily applied to raw signals and can effectively operate using feature learning and\nlatent representations.\n-20\n-10\n0\n10\nEvaluation SNR (dB)\n0\n0.2\n0.4\n0.6\n0.8\n1\nClassification Accuracy\nExpert-Naive Bayes\nExpert-SVM\nCNN\nFig. 2.\nExample of deep learning outperforming conventional machine learning in wireless domain. CNN is more successful than SVM\nand Naive Bayes in classifying a variety of digital modulations (BPSK, QPSK, 8PSK, 16-QAM, 64-QAM, BFSK, CPFSK, and PAM4) and\nanalog modulations (WB-FM, AM-SSB, and AM-DSB) [3].\nThis chapter presents methodologies and algorithms to apply deep learning to wireless communications\nin three main areas.\n3\n1) Deep learning to design end-to-end (physical layer) communication chain (Sec. II).\n2) Deep learning to support spectrum situation awareness (Sec. III).\n3) Deep learning for wireless security to launch and defend wireless attacks (Sec. IV).\nIn Sec. II, we formulate an end-to-end physical layer communications chain (transmitter and receiver)\nas an autoencoder that is based on two deep neural networks (DNNs), namely an encoder for the\ntransmitter functionalities such as modulation and coding, and a decoder for the receiver functionalities\nsuch as demodulation and decoding. By incorporating the channel impairments in the design process\nof autoencoder, we demonstrate the performance gains over conventional communication schemes. In\nSec. III, we present how to use different DNNs such as feedforward, convolutional, and recurrent neural\nnetworks for a variety of spectrum awareness applications ranging from channel modeling and estimation\nto spectrum sensing and signal classiÔ¨Åcation. To support fast response to spectrum changes, we discuss the\nuse of autoencoder to extract latent features from wireless communications data and the use of generative\nadversarial networks (GANs) for spectrum data augmentation to shorten spectrum sensing period. Due to\nthe open and broadcast nature of wireless medium, wireless communications are prone to various attacks\nsuch as jamming. In Sec. IV, we present emerging techniques built upon adversarial deep learning to\ngain new insights on how to attack wireless communication systems more intelligently compared to\nconventional wireless attack such as jamming data transmissions. We also discuss a defense mechanism\nwhere the adversary can be fooled when adversarial deep learning is applied by the wireless system itself.\nII. DEEP LEARNING FOR END-TO-END COMMUNICATION CHAIN\nThe fundamental problem of communication systems is to transmit a message such as a bit stream from\na transmitter using radio waves and reproduce it either exactly or approximately at a receiver [4]. The focus\nin this section is on the physical layer of the Open Systems Interconnection (OSI) model. Conventional\ncommunication systems split signal processing into a chain of multiple independent blocks separately\nat the transmitter and receiver, and optimize each block individually for a different functionality. Fig. 3\nshows the block diagram of a conventional communication system. The source encoder compresses the\ninput data and removes redundancy. Channel encoder adds redundancy on the output of the source encoder\nin a controlled way to cope with the negative effects of the communication medium. Modulator block\nchanges the signal characteristics based on the desired data rate and received signal level at the receiver\n(if adaptive modulation is used at the transmitter). The communication channel distorts and attenuates the\ntransmitted signal. Furthermore, noise is added to the signal at the receiver due to the receiver hardware\nimpairments. Each communication block at the transmitter prepares the signal to the negative effects\nof the communication medium and receiver noise while still trying to maximize the system efÔ¨Åciency.\nThese operations are reversed at the receiver in the same order to reconstruct the information sent by the\ntransmitter. This approach has led to efÔ¨Åcient, versatile, and controllable communication systems that we\nhave today with individually optimized processing blocks. However, this individual optimization process\ndoes not necessarily optimize the overall communication system. For example, the separation of source\nand channel coding (at the physical layer) is known to be sub-optimal [5]. The beneÔ¨Åt in joint design\nof communication blocks is not limited to physical layer but spans other layers such as medium access\ncontrol at link layer and routing at network layer [6]. Motivated by this Ô¨Çexible design paradigm, deep\nlearning provides automated means to treat multiple communications blocks at the transmitter and the\nreceiver jointly by training them as combinations of DNNs.\nMIMO systems improve spectral efÔ¨Åciency by using multiple antennas at both transmitter and receiver\nto increase the communication range and data rate. Different signals are transmitted from each antenna at\nthe same frequency. Then each antenna at the receiver receives superposition (namely, interference) of the\nsignals from transmitter antennas in addition to the channel impairments (also observed for single antenna\nsystems). The traditional algorithms developed for MIMO signal detection are iterative reconstruction\napproaches and their computational complexity is impractical for many fast-paced applications that require\neffective and fast signal processing to provide high data rates [7], [8]. Model-driven MIMO detection\n4\ntechniques can be applied to optimize the trainable parameters with deep learning and improve the detection\nperformance. As an example, a MIMO detector was built in [7] by unfolding a projected gradient descent\nmethod. The deep learning architecture used a compressed sufÔ¨Åcient statistic as an input in this scheme.\nAnother model-driven deep learning network was used in [9] for the orthogonal approximate message\npassing algorithm.\nMultiuser communication systems, where multiple transmitters and/or receivers communicate at the\nsame time on the same frequency, allow efÔ¨Åcient use of the spectrum, e.g., in an interference channel\n(IC), multiple transmitters communicate with their intended receivers on the same channel. The signals\nreceived from unintended transmitters introduce additional interference which needs to be eliminated\nwith precoding at the transmitters and signal processing at the receivers. The capacity region for IC in\nweak, strong and very strong interference regimes has been studied extensively [11]‚Äì[13]. Non-orthogonal\nmultiple access (NOMA) has emerged to improve the spectral efÔ¨Åciency by allowing some degree of\ninterference at receivers that can be efÔ¨Åciently controlled across interference regimes [14]. However, the\ncomputational complexity of such capacity-achieving schemes is typically high to be realized in practical\nsystems.\nRecently, deep learning-based end-to-end communication systems have been developed for single an-\ntenna [15], [16], multiple antenna [17], and multiuser [15], [18] systems to improve the performance\nof the traditional approaches by jointly optimizing the transmitter and the receiver as an autoencoder\ninstead of optimizing individual modules both at the transmitter and receiver. Autoencoder is a DNN\nthat consists of an encoder that learns a (latent) representation of the given data and a decoder that\nreconstructs the input data from the encoded data [19]. In this setting, joint modulation and coding at the\ntransmitter corresponds to the encoder, and joint decoding and demodulation at the receiver corresponds\nto the decoder. The joint optimization includes multiple transmitter and receivers for the multiuser case to\nlearn and eliminate the additional interference caused by multiple transmitters. The following sections will\npresent the autoencoder-based communication system implementations and their performance evaluation.\nSource of \nInformation\nSource \nEncoder\nChannel \nEncoder\nModulator\nChannel\nDemodulator\nChannel \nDecoder\nSource \nDecoder\nReconstructed \nInformation\nTransmitter\nReceiver\nDetection\nChannel \nEstimation\n0 1 0 0\n0\n1 1 0\nX\nFig. 3. Conventional communication system block diagram.\nA. Single Antenna Systems\nA communication system consists of a transmitter, a receiver, and channel that carries information from\nthe transmitter to the receiver. A fundamental new way to think about communication system design is\nto formulate it as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver\ncomponents in a single process using autoencoders [15]. As in the conventional communication systems,\nthe transmitter wants to communicate one out of M possible messages s ‚ààM = {1, 2, ..., M} to the receiver\nmaking n discrete uses of the channel. It applies the modulation process f : M 7‚ÜíRn to the message s\nto generate the transmitted signal x = f (s) ‚ààRn. The input symbols from a discrete alphabet are mapped\n5\nto the points (complex numbers) on the constellation diagram as part of digital modulation. The digital\nmodulation schemes for conventional communication systems have pre-deÔ¨Åned constellation diagrams.\nThe symbols are constructed by grouping the input bits based on the desired data rate. The desired data\nrate determines the constellation scheme to be used. Fig. 4 shows the constellation diagrams for the\nbinary phase shift keying (BPSK), quadrature phase shift keying (QPSK), and 16-quadrature amplitude\nmodulation (QAM) as example of digital modulation schemes and their symbol mapping. Linear decision\nregions make the decoding task relatively simpler at the receiver. For the autoencoder system, the output\nconstellation diagrams are not pre-deÔ¨Åned. They are optimized based on the desired performance metric,\ni.e., the symbol error rate to be reduced at the receiver.\n(a)\n(b)\n(c)\nFig. 4. Example of digital modulation constellations (a) BPSK, (b) QPSK, (c) 16-QAM.\nThe hardware of the transmitter imposes an energy constraint ‚à•x‚à•2\n2 ‚â§n, amplitude constraint |xi| ‚â§1 ‚àÄi,\nor an average power constraint E\n\u0002\n|xi|2\u0003\n‚â§1 ‚àÄi on x. The data rate of this communication system is\ncalculated as R = k/n [bit/channel use], where k = log2(M) is the number of input bits and n can be\nconsidered as the output of a forward error correction scheme where it includes both the input bits and\nredundant bits to mitigate the channel effects. As a result, the notation (n,k) means that a communication\nsystem sends one out of M = 2k messages (i.e., k bits) through n channel uses. The communication\nchannel is described by the conditional probability density function p(y|x), where y ‚ààRn denotes the\nreceived signal. Upon reception of y, the receiver applies the transformation g : Rn 7‚ÜíM to produce the\nestimate ÀÜs of the transmitted message s. Mapping x to y is optimized in a channel autoencoder so that\nthe transmitted message can be recovered with a small probability of error. In other words, autoencoders\nused in many other deep learning application areas typically remove redundancy from input data by\ncompressing it; however, the channel autoencoder adds controlled redundancy to learn an intermediate\nrepresentation robust to channel perturbations.\nThe block diagram of the channel autoencoder scheme is shown in Fig. 5. The input symbol is\nrepresented as a one-hot vector. The transmitter consists of a feedforward neural network (FNN) with\nmultiple dense layers. The output of the last dense layer is reshaped to have two values that represent\ncomplex numbers with real (in-phase, I) and imaginary (quadrature, Q) parts for each modulated input\nsymbol. The normalization layer ensures that physical constraints on x are met. The channel is represented\nby an additive noise layer with a Ô¨Åxed variance Œ≤ = (2REb/N0)‚àí1, where Eb/N0 denotes the energy per bit\n(Eb) to noise power spectral density (N0) ratio. The receiver is also implemented as an FNN. Its last layer\nuses a softmax activation whose output p ‚àà(0, 1)M is a probability vector over all possible messages. The\nindex of the element of p with the highest probability is selected as the decoded message. The autoencoder\nis trained using stochastic gradient descent (SGD) algorithm on the set of all possible messages s ‚ààM\nusing the well suited categorical cross-entropy loss function between 1s and p. The noise value changes\nin every training instance. Noise layer is used in the forward pass to distort the transmitted signal. It is\nignored in the backward pass.\nFig. 6 (a) compares the block error rate (ABLER), i.e., Pr(ÀÜs , s), of a communication system employing\nBPSK modulation and a Hamming (7,4) code with either binary hard-decision decoding or maximum\nlikelihood decoding (MLD) against the ABLER achieved by the trained autoencoder (7,4) (with Ô¨Åxed\n6\nMultiple dense layers\n‚Ñù\n‚ÑÇ\nNormalization\nTransmitter\nAWGN, ùêß\nChannel\nMultiple dense layers\nDense layer with \nsoftmax activation\nReceiver\nùê©\nargmax\nùë†\n∆∏ùë†\n0\n.\n.\n.\n0\n1\n0\n.\n.\n.\n0\nùëì(ùë†)\nùê±\nùëù(ùê≤|ùê±)\ng(ùê≤)\nùíö\nFig. 5.\nA communication system over an additive white Gaussian noise (AWGN) channel represented as an autoencoder. The input s is\nencoded as a one-hot vector, the output is a probability distribution over all possible messages. The message with the highest probability is\nselected as output ÀÜs.\nenergy constraint ‚à•x‚à•2\n2 = n). Autoencoder is trained at Eb/N0 = 7 dB using Adam [21] optimizer with\nlearning rate 0.001. Both systems operate at rate R = 4/7. The ABLER of uncoded BPSK (4,4) is\nalso included for comparison. The autoencoder learns encoder and decoder functions without any prior\nknowledge that achieve the same performance as the Hamming (7,4) code with MLD. Table I shows the\nnumber of neural network layers used at the encoder (transmitter) and decoder (receiver) of the autoencoder\nsystem.\n-4\n-2\n0\n2\n4\n6\n8\n10-4\n10-3\n10-2\n10-1\n100\nBlock error rate\nUncoded BPSK (4,4)\nHamming (7,4) Hard Decision\nAutoencoder (7,4)\nHamming (7,4) MLD\n-2\n0\n2\n4\n6\n8\n10\n10-4\n10-3\n10-2\n10-1\n100\nBlock error rate\nUncoded BPSK (8,8)\nAutoencoder (8,8)\nUncoded BPSK (2,2)\nAutoencoder (2,2)\n(a)\n(b)\nFig. 6. BLER versus Eb/N0 for the autoencoder and several baseline communication schemes [15].\nFig. 6 (b) shows the performance curves for (8,8) and (2,2) communication systems when R = 1.\nThe autoencoder achieves the same ABLER as uncoded BPSK for (2,2) system and it outperforms the\nlatter for (8,8) system, implying that it has learned a joint coding and modulation scheme, such that a\ncoding gain is achieved. Fig. 7 shows the constellations x of all messages for different values of (n, k)\nas complex constellation points, i.e., the x- and y-axes correspond to the Ô¨Årst and second transmitted\nsymbols, respectively. Fig. 7 (a) shows the simple (2, 2) system that converges rapidly to a classical\nAQPSK constellation (see Fig. 4 (b)) with some arbitrary rotation. Similarly, Fig. 7 (b) shows a (4, 2)\nsystem that leads to a rotated 16-PSK constellation where each constellation point has the same amplitude.\nOnce an average power normalization is used instead of a Ô¨Åxed energy constraint, the constellation plot\nresults in a mixed pentagonal/hexagonal grid arrangement as shown in Fig. 7 (c). This diagram can be\n7\nTABLE I\nLAYOUT OF THE AUTOENCODER USED IN FIGS. 6 (A) AND (B).\nTransmitter\nReceiver\nLayer\nOutput dimensions\nLayer\nOutput dimensions\nInput\nM\nInput\nn\nDense + ReLU\nM\nDense + ReLU\nM\nDense + linear\nn\nDense + softmax\nM\ncompared to the 16-QAM constellation as shown in Fig. 4 (c).\n(a)\n(b)\n(c)\nFig. 7. Constellations produced by autoencoders using parameters (n, k): (a) (2, 2) (b) (2, 4), (c) (2, 4) with average power constraint.\nIn addition to promising results for the channel autoencoder implementation with simulated channels,\nover-the-air transmissions have also veriÔ¨Åed the feasibility of building, training, and running a complete\ncommunication system solely composed of DNNs using unsynchronized off-the-shelf software-deÔ¨Åned\nradios (SDRs) and open-source deep learning software libraries [16]. Hardware implementation introduces\nadditional challenges to the system such as the unknown channel transfer function. The autoencoder\nconcept works when there is a differentiable mathematical expression of the channel‚Äôs transfer function\nfor each training example. A two-step training strategy is used to overcome this issue where the autoen-\ncoder is Ô¨Årst trained with a stochastic channel model that closely approximates the real channel model.\nDuring operation time, the receiver‚Äôs DNN parameters are Ô¨Åne-tuned using transfer learning approach.\nA comparison of the BLER performance of the channel autoencoder system implemented on the SDR\nplatform with that of a conventional communication scheme shows competitive performance close to 1\ndB without extensive hyperparameter tuning [16].\nTransfer learning approach still provides suboptimal performance for the channel autoencoder since\nthe channel model used during the training differs from the one experienced during operation time. A\ntraining algorithm that iterates between the supervised training of the receiver and reinforcement learning-\nbased training of the transmitter was developed in [22] for different channel models including AWGN\nand Rayleigh block-fading (RBF) channels.\nB. Multiple Antenna Systems\nMIMO wireless systems are widely used today in cellular and wireless local area network (LAN)\ncommunications. A MIMO system exploits multipath propagation through multiple antennas at the trans-\nmitter and receiver to achieve different types of gains including beamforming, spatial diversity, spatial\nmultiplexing gains, and interference reduction. Spatial diversity is used to increase coverage and robustness\nby using space-time block codes (STBC) [23], [24]. Same information is precoded and transmitted in\nmultiple time slots in this approach. Spatial multiplexing is used to increase the throughput by sending\ndifferent symbols from each antenna element [25], [26]. In a closed-loop system, the receiver performs\n8\nchannel estimation and sends this channel state information (CSI) back to the transmitter. The CSI is used\nat the transmitter to precode the signal due to interference created by the additional antenna elements\noperating at the same frequency. The developed MIMO schemes for both spatial diversity and multiplexing\nrely on analytically obtained (typically Ô¨Åxed) precoding and decoding schemes.\nDeep learning has been used for MIMO detection at the receivers to improve the performance using\nmodel-driven deep learning networks [7], [9], [10]. In Sec. II-A, the channel autoencoder was used to train\na communication system with a single antenna. The autoencoder concept is also applied to the MIMO\nsystems where many MIMO tasks are combined into a single end-to-end encoding and decoding process\nwhich can be jointly optimized to minimize symbol error rate (SER) for speciÔ¨Åc channel conditions [17].\nA MIMO autoencoder system with Nt antennas at the transmitter and Nr antennas at the receiver is\nshown in Fig. 8. Symbols si, i = 1, . . ., Nt, are inputs to the communication system. Each symbol has\nk bits of information. By varying k, the data rate of the autoencoder system can be adjusted. The input\nsymbols are combined and represented with a single integer in the range of [0, 2kNt) as an input to the\nencoder (transmitter) and are encoded to form Nt parallel complex transmit streams, xi, as output, where\ni = 1, . . ., Nt. There are different channel models developed for MIMO systems such as [27]. A Rayleigh\nfading channel is used in this example which leads to a full rank channel matrix. In this case, full beneÔ¨Åt\nis achieved from the MIMO system since the received signal paths for each antenna are uncorrelated.\nThe signal received at the decoder (receiver) can be modeled as y = hx + n where h is an Nr √ó Nt\nchannel matrix with circularly symmetric complex Gaussian entries of zero mean and unit variance, x is\nan Nt √ó 1 vector with modulated symbols with an average power constraint of P such that E [x‚àóx] ‚â§P\nwhere x‚àódenotes the Hermitian of x, and n is an (Nr √ó 1) vector which is the AWGN at the receiver with\nE [nn‚àó] = œÉ2INr√óNr. Estimated symbols ÀÜsi, where i = 1, . . ., Nr, are the outputs. Every modulated symbol\nat the transmitter corresponds to a single discrete use of the channel and the communication rate of the\nsystem is min(Nt, Nr) ¬∑ k bits.\n.\n.\n.\nùê±ùüè\nùê±ùüê\nùê±ùüë\nMIMO channel, ùê°\nAWGN, ùêß\nùê°ùê±+ ùêß\n.\n.\n.\nùê±ùêçùê≠\nùê≤ùüè\nùê≤ùüê\nùê≤ùüë\nùê≤ùêçùê´\nChannel Estimation, ·àòùê°\nEncoding index\nMultiple dense layers\nDense layer with \nsoftmax activation\nReceiver\n.\n.\n.\n∆∏ùë†1\n∆∏ùë†2\n∆∏ùë†3\n∆∏ùë†ùëÅùëü\nùê©\nargmax\nConvert to individual symbols\n∆∏ùë†\nFlatten\nMultiple dense layers\n‚Ñù\n‚ÑÇ\nNormalization\nTransmitter\nEmbedding\nùë†ùëÅùë°\n.\n.\n.\nùë†2\nùë†3\nùë†1\nRepresent with an integer\nùë†\nFig. 8. MIMO channel autoencoder trained using a constant channel.\nThe autoencoder is trained using channel realizations drawn from Rayleigh distribution. The transmitter\ncommunicates one out of 2k possible messages from each antenna. The transmitter is designed using an\nFNN architecture. The input symbols go through an embedding layer followed by dense layers. Embedding\nlayer turns positive integers to dense vectors of Ô¨Åxed size. The output of the embedding layer is converted\nto a one-dimensional tensor before going in to the dense layers using a Ô¨Çatten layer. Batch normalization\n[28] is used after embedding layer and every dense layer. The output of the last dense layer is reshaped\nto generate complex numbers as the output; i.e., even indices as the real part and odd indices as the\nimaginary part.\nThe transmitter has an average power constraint. The normalization layer normalizes the transmitter\n9\noutput so that the average power constraint is satisÔ¨Åed; i.e., E[x‚àóx] ‚â§P. As in the single antenna case, the\ntransmitter output, x can be thought as modulated symbols as in conventional communication systems.\nInstead of using a known constellation scheme with linear decision regions such as BPSK or QPSK, the\noptimal constellation points are learned by the autoencoder system over time.\nA multiplication layer is built to perform complex multiplication, hx, and the noise layer introduces\nnoise, n, to the autoencoder system. The input symbols and the noise change in every training instance\nand the noise variance œÉ is adjusted at both training and test time to simulate varying levels of SNR.\nThe receiver is also designed using an FNN architecture. The symbols received at the receiver, yi, where\ni = 1, . . ., Nr, go through multiple dense layers with the last layer with softmax activation that provides a\nprobability for each symbol with a sum equal to 1. The codeword with the highest probability is selected\nas the output.\nDuring training, the transmitter and receiver are optimized jointly to determine the weights and biases for\nboth of the FNNs that minimize the reconstruction loss. There are total of 2kNt output classes. Categorical\ncross-entropy loss function (‚ÑìCE) is used for optimization using gradient descent which is given by\n‚ÑìCE(Œ∏) = ‚àí1\nM\nM\n√ï\ni=1\n2kNt ‚àí1\n√ï\nj=0\np‚Ä≤\no,j log(po,j),\n(1)\nwhere M is the mini-batch size, Œ∏ is the set of neural network parameters, po,j is the softmax layer‚Äôs\noutput probability for output class j for observation o, and p‚Ä≤\no,j is the binary indicator (0 or 1) if class label\nj is the correct classiÔ¨Åcation for observation o. Weight updates are computed based on the loss gradient\nusing back-propagation algorithm with Adam [21] optimizer. In this case, a forward pass, f (s, Œ∏), and a\nbackward pass, ‚àÇ‚ÑìCE(Œ∏)\n‚àÇŒ∏\n, are iteratively computed and a weight update is given by Œ¥w = ‚àíŒ∑ ‚àÇ‚ÑìCE(Œ∏)\n‚àÇŒ∏\nwith Œ∑\nrepresenting the learning rate.\nChannel estimation can be performed either using conventional or machine learning-based methods\nduring test phase (channel estimation block in Fig. 8). h is the channel matrix and ÀÜh is the channel\nestimation at the receiver. During real-time operation, the receiver performs channel estimation and sends\nthe index of the best encoding to the transmitter through the designated feedback channel. The cognitive\ntransmitter will change the encoding scheme on-the-Ô¨Çy to minimize SER. As a result, a closed-loop system\nwill be used during operation time as shown in Fig. 8.\nChannel estimation error at the receiver leads to a sub-optimal encoding scheme to be selected both\nat the transmitter and the receiver, and translates to a performance loss. A minimum mean square error\n(MMSE) channel estimator is used at the receiver. Assuming h = ÀÜh + Àúh where ÀÜh is the channel estimation\nmatrix and Àúh is the channel estimation error, the variance of Àúh using an MMSE channel estimator is given\nas [29]:\nœÉ2\nÀúh =\n1\n1 + œÅœÑ\nNt TœÑ\n,\n(2)\nwhere œÅœÑ is the SNR during the training phase and TœÑ is the number of training samples. (2) was used in\n[30], [31] for closed-loop MIMO systems with both channel estimation and feedback (from receiver to\ntransmitter) to perform channel-guided precoding at the transmitter. Different error variances are introduced\nto the channels (originally used for training) in test time to measure the impact of channel estimation\nerror.\nA closed-loop MIMO system using singular value decomposition (SVD)-based precoding technique at\nthe transmitter [25] is implemented as the baseline. The channel matrix, h, can be written as h = UŒõV‚àó\nwhere U and V are Nr √ó Nr and Nt √ó Nt unitary matrices, respectively. Œõ is a diagonal matrix with\nthe singular values of h. To eliminate the interference at each antenna, the channel is diagonalized by\nprecoding the symbols at the transmitter and decoding at the receiver using the CSI. In this model, the\n10\nTABLE II\nFNN STRUCTURES USED AT THE TRANSMITTER AND RECEIVER.\nTransmitter\nReceiver\nLayers\n# neurons\nActivation function\n# neurons\nActivation function\nInput\n2\n4\n1\n32\nReLU\n8\nReLU\n2\n16\nReLU\n16\nReLU\n3\n8\nReLU\n32\nReLU\nOutput\n4\nLinear\n16\nSoftmax\nreceived signal is written as Àúy = ŒõÀúx + Àún where Àúx = Vx, Àúy = U‚àóy and Àún = U‚àón. The distribution of Àún is\nthe same as n with Àún ‚àºN(¬µ, œÉ2INr).\nThe performance of a 2√ó2 autoencoder system is evaluated and compared with the baseline performance.\nThe noise variance, œÉ2, is set to 1 and Nt = Nr. A closed-loop system with perfect CSI (no channel\nestimation error) at the transmitter is assumed for the baseline simulation. QPSK modulation is used to\nmodulate the input bits. Equal power is used at each antenna during transmission. A 2 √ó 2 autoencoder\nsystem is developed using 2 bits per symbol to match the bit rate with the baseline. The FNN structures\nfor the transmitter and receiver are shown in Table II.\nFig. 9 (a) shows the SNR vs. SER curves of the learned communication system compared to the baseline\nwhen no channel estimation error is assumed for both of the schemes. Promising results are obtained with\nthe autoencoder approach when nonlinear constellation schemes are allowed at the transmitter. There is\nmore than 10 dB gain at an SER of 10‚àí2 when the autoencoder is used.\n0\n5\n10\n15\n20\nSignal to Noise Ratio (dB)\n10 -4\n10 -3\n10 -2\n10 -1\n10 0\nSymbol Error Rate (SER)\n2\n2 AE\n2\n2 SVD-based\n0\n5\n10\n15\n20\nSignal to Noise Ratio (dB)\n10 -4\n10 -3\n10 -2\n10 -1\n10 0\nSymbol Error Rate (SER)\n2\n2 AE\n2\n2 SVD-based\n2\n2 AE Err. var. 0.01\n2\n2 AE Err.var. 0.02\n2\n2 AE Err.var. 0.04\n(a)\n(b)\nFig. 9. (a) SER performance comparison of conventional and learned 2 √ó 2 spatial multiplexing schemes for a constant channel with perfect\nCSI, (b) The effect of channel estimation error on the performance of learned 2 √ó 2 spatial multiplexing scheme for constant channel.\nIt is assumed that the transmitter and receiver will be trained for speciÔ¨Åc channel instances and resulting\nneural network parameters (weights and biases) will be stored in the memory. During operation time,\nthe receiver will perform channel estimation and send the index of the encodings that will be used to\nthe transmitter. There will be channel estimation error at the receiver, which increases with decreasing\nnumber of training symbols [29]. Next, the performance of the developed autoencoder system when there\nis channel estimation error is analyzed using an MMSE channel estimator at the receiver. It is assumed\nthat the training time increases with decreasing SNR and the system performance is analyzed when the\nchannel estimation error variances are 0.01, 0.02 and 0.04. The autoencoder system is Ô¨Årst trained with\na given channel matrix, h. Then the output of the autoencoder architecture, weights, and biases are saved\n11\nand the channel with the estimation error is provided during the operation time. Fig. 9 (b) shows the\nperformance results. The autoencoder performance degrades with increasing channel estimation error, as\nexpected. Error variance of 0.04 is the maximum that the system can tolerate.\nC. Multiple User Systems\nThe autoencoder concept described in Sec. II-A was extended to multiple transmitters and receivers\nthat operate at the same frequency for single antenna systems in [15] and for multiple antenna systems\nin [18]. A two-user AAWGN interference channel was considered in [15] as shown in Fig. 10 (a).\n0\n2\n4\n6\n8\n10\n12\n14\n10-4\n10-3\n10-2\n10-1\n100\nBlock error rate\nTS/AE (1,1)\nTS/AE (2,2)\nTS (4,4)\nAE (4,4)\nTS (4,8)\nAE (4,8)\n(a)\n(b)\nFig. 10.\n(a) The two-user interference channel seen as a combination of two interfering autoencoders (AEs) that try to reconstruct their\nrespective messages, (b) ABLER versus Eb/N0 for the two-user interference channel achieved by the autoencoder and 22k/n-AQAM time-\nsharing (TS) for different parameters (n, k).\nTransmitter 1 wants to communicate message s1 ‚ààM to Receiver 1 and simultaneously, Transmitter 2\nwants to communicate message s2 ‚ààM to Receiver 2. Extensions to K users with possibly different rates\nand other channel types are straightforward. Both transmitter-receiver pairs are implemented as FNNs.\nThe encoder and decoder architectures are the same as described in Sec. II-A. However, the transmitted\nmessages interfere at the receivers in this case. The signal received at each receiver is given by\ny1 = x1 + x2 + n1,\ny2 = x2 + x1 + n2,\n(3)\nwhere x1, x2 ‚ààCn are the transmitted messages and n1, n2 ‚àºCN(0, Œ≤In) is Gaussian noise. No fading\nis assumed in this scenario; i.e., h values are set to 1 for each link. The individual cross-entropy loss\nfunctions of the Ô¨Årst and second transmitter-receiver pairs are l1 = ‚àílog \u0000[ÀÜs1]s1\n\u0001 and l2 = ‚àílog \u0000[ÀÜs2]s2\n\u0001 for\nthe Ô¨Årst and second autoencoder, respectively.\nÀúL1(Œ∏t), and ÀúL2(Œ∏t) correspond to the associated losses for mini-batch t. For joint training, dynamic\nweights Œ±t are adapted for each mini-batch t as\nŒ±t+1 =\nÀúL1(Œ∏t)\nÀúL1(Œ∏t) + ÀúL2(Œ∏t),\nt > 0 ,\n(4)\nwhere Œ±0 = 0.5. Thus, the smaller ÀúL1(Œ∏t) is compared to ÀúL2(Œ∏t), the smaller is its weight Œ±t+1 for the next\nmini-batch.\nFig. 10 (b) shows the ABLER of one of the autoencoders as a function of Eb/N0 for the sets of\nparameters (n, k) = {(1, 1), (2, 2), (4, 4), (4, 8)}. The DNN architecture for both autoencoders is the same as\nthat provided in Table I by replacing n by 2n. An average power constraint is used to be competitive with\n12\n(a)\n(b)\n(c)\n(d)\nFig. 11.\nLearned constellations for the two-user interference channel with parameters (a) (1, 1), (b) (2, 2), (c) (4, 4), and (d) (4, 8). The\nconstellation points of Transmitters 1 and 2 are represented by red dots and black crosses, respectively [15].\nhigher-order modulation schemes; i.e., allow varying amplitude in the constellation points for increasing\ndata rate. As a baseline, uncoded 22k/n- AQAM (which has the same rate when used together with\ntime-sharing between both transmitters) is considered. For (1, 1), (2, 2), and (4, 4), each transmitter sends\na 4-AQAM (i.e., AQPSK) symbol on every other channel use. For (4, 8), 16-AQAM is used instead.\nWhile the autoencoder and time-sharing have identical ABLER for (1, 1) and (2, 2), the former achieves\nsubstantial gains of around 0.7 dB for (4, 4) and 1 dB for (4, 8) at a ABLER of 10‚àí3.\nThe learned message representations at each receiver are shown in Fig. 11. For (1, 1), the transmitters\nhave learned to use ABPSK-like constellations (see Fig. 4 (a)) in orthogonal directions (with an arbitrary\nrotation around the origin). This achieves the same performance as AQPSK with time-sharing. However,\nfor (2, 2), the learned constellations are not orthogonal anymore and can be interpreted as some form of\nsuperposition coding. For the Ô¨Årst symbol, Transmitter 1 uses high power and Transmitter 2 uses low\npower. For the second symbol, the roles are changed. For (4, 4) and (4, 8), the constellations are more\ndifÔ¨Åcult to interpret, but it can be seen that the constellations of both transmitters resemble ellipses with\northogonal major axes and varying focal distances. This effect is more visible for (4, 8) than for (4, 4)\nbecause of the increased number of constellation points.\nTake-away: This section showed that deep learning-based autoenconder can be effectively used to\ndevelop transmitter (modulation and coding) and receiver (demodulation and decoding) functions jointly\nby combating channel impairments and optimizing end-to-end communication performance in terms of\nerror rates. This approach applies to single, multiple antenna, and multiuser systems.\nIII. DEEP LEARNING FOR SPECTRUM SITUATION AWARENESS\nCognitive radio has emerged as a programmable radio that aims to learn from wireless communication\ndata and adapt to spectrum dynamics. For that purpose, cognitive radio senses its operational radio\nfrequency (RF) environment and adjusts its operating parameters (e.g., frequency, power, and rate) dynam-\nically and autonomously to modify system operation and improve its performance, such as maximizing\nthroughput, mitigating interference, facilitating interoperability, or accessing spectrum as a secondary user\n[32].\n13\nChannel modeling is important while developing algorithms to enable cognitive capabilities and evaluat-\ning the performance of the communication systems. Most signal processing algorithms applied to wireless\ncommunications assume compact mathematically convenient channel models such as AWGN, Rayleigh, or\nRician fading channel (or Ô¨Åxed delay/Doppler proÔ¨Åles consisting of Rayleigh fading taps). These existing\nchannel models generally parameterize channel effects in a relatively rigid way which does not consider\nthe exact statistics of deployment scenarios. Furthermore, practical systems often involve many hardware\nimperfections and non-linearities that are not captured by these existing channel models [15]. Channel\nestimation is also an important task for a communication system to recover and equalize the received signal\n(reversing the channel effects). A known training sequence is often transmitted at the transmitter and the\nreceiver typically uses methods such as maximum likelihood or MMSE channel estimation techniques,\nderived under compact mathematical channel models, to estimate the channel, e.g., MMSE estimator is\napplied in (2) for channel estimation in Sec. II-B.\nTo support situational awareness, it is important for cognitive radios to quickly and accurately perform\nsignal detection and classiÔ¨Åcation tasks across a wide range of phenomena. One example is the DSA\napplication where there are primary (legacy) and secondary (cognitive) users. Secondary users use the\nspectrum in an opportunistic manner by avoiding or limiting their destructive levels of interference to\nthe primary users in a given frequency band. Therefore, secondary users need to detect and classify the\nsignals received during spectrum sensing reliably to identify whether there is any primary user activity,\nother secondary users, or vacant spectrum opportunities. Conventional signal detection and classiÔ¨Åcation\nalgorithms aim to capture speciÔ¨Åc signal features (i.e., expert features) such as cyclostationary features and\nare typically developed to achieve performance goals such as detection against speciÔ¨Åc signal types and\nunder speciÔ¨Åc channel model assumptions (e.g., AWGN). Therefore, these conventional algorithms often\nlack the ability to generalize to different signal types and channel conditions, while deep learning can\ncapture and adapt its operation to raw and dynamic spectrum data of a wide variety of signal signatures\nand channel effects (that feature-based machine learning algorithms may struggle to capture).\nDeep learning approaches have been used to address the challenges associated with both channel\nmodeling and estimation as well as signal detection and classiÔ¨Åcation tasks. In the following subsections\nwe Ô¨Årst describe how channel modeling and estimation can be performed using deep learning methods.\nNext, we describe the CNN architectures that are used for signal detection and modulation classiÔ¨Åcation.\nFinally, we describe how to use GANs to augment training data in spectrum sensing applications.\nA. Channel Modeling and Estimation\nThe performance of communication systems can often beneÔ¨Åt from being optimized for speciÔ¨Åc scenar-\nios which exhibit structured channel effects such as hardware responses, interference, distortion, multi-path\nand noise effects beyond simpliÔ¨Åed analytic models or distributions. Moreover, the channel autoencoder\nsystems described in Sec. II requires the statistical model for the channel be as close as possible to\nwhat the operational system will experience during training in order to achieve optimal performance (i.e.,\nthe phenomena during training should accurately match the phenomena during deployment). However,\naccurately capturing all these effects in a closed-form analytical model is a challenging (and often infea-\nsible) task. As a result, the channel is often represented using simpliÔ¨Åed models without taking real-world\ncomplexities into account. Recently, model-free approaches where the channel response is learned from\ndata are proposed for real-time channel modeling using deep learning techniques. In particular, stochastic\nchannel response functions are approximated using GANs [33], [34], variational GANs [35], reinforcement\nlearning and sampling approach [36], stochastic perturbation techniques [37], and reinforcement learning\npolicy gradient methods [38].\nGANs [40] have been successfully used for a number of applications such as generating fake images\n(e.g., faces, cats) to confuse image recognition systems. Recently, GANs have also been used in a\nwide range of applications such as audio generation, approximation of difÔ¨Åcult distributions, and even\nthe (human-guided) generation of novel art. Building upon this same idea, the GAN was applied to\n14\napproximate the response of the channel in any arbitrary communication system in [33] and the resulting\nsystem was generally called a Communications GAN. The block diagram of the Communications GAN\nthat learns a communication system over a physical channel with no closed-form model or expression is\nshown in Fig. 12.\nMultiple dense layers\n‚Ñù\n‚ÑÇ\nNormalization\nTransmitter\nùë†\n0\n.\n.\n.\n0\n1\n0\n.\n.\n.\n0\nùëì(ùë†, ùõâùêü)\nùê±\nMultiple dense layers\nDense layer with \nsoftmax activation\nReceiver\nùê©\nargmax\n∆∏ùë†\ng(ùê≤, ùõâùíà)\nùíö\nD/A Conversion\nLO/Mixer(s)\nA/D Conversion\nAntenna(s)\nPropagation\n‚Ä¶\nAmplifier(s)\nPhysical Channel: ‚Ñé0(ùê±)\nNoise \nConcatenate\nReLU Layer\nReLU Layer\nReLU Layer\nLinear Layer\nChannel Approximation: \n‚Ñé1(ùê±, ùõâùíâ)\nFig. 12. A GAN for learning a communication system over a physical channel with no-closed form model.\nAs opposed to the original autoencoder shown in Fig. 5, a channel model with an analytic expression\nis not included in the autoencoder in Fig. 12. Two forms of the channel h(x) are included instead to\nencompass modeling of any black-box channel transform where x is the transmitter output: h0(x) is a\nreal-world physical measurement of the response of a communication system comprising a transmitter, a\nreceiver, and a channel and h1(x, Œ∏h) is a non-linear DNN which seeks to mimic the channel response of h0\nsynthetically, and is differentiable. Œ∏h is the channel approximation of neural network parameters. During\ntraining, an iterative approach is used to reach an optimized solution, cycling between competing training\nobjectives, updating weights for each network during the appropriate stage with manually tuned learning\nrates and relatively small networks for f , g, and h, and employing several fully connected ReLU layers for\neach. The physical channel h0(x) was implemented using an SDR (Universal Software Radio Peripheral,\nUSRP B210 [39]), for over-the-air transmission tests. It was shown that an effective autoencoder-based\ncommunication system with robust performance can be learned by using an adversarial approach to\napproximate channel functions for arbitrary communications channel. This approach eliminates the need\nfor a closed-form channel model reducing the need for assumptions on the form it takes.\nThe channel network y = h(x) is treated as a stochastic function approximation and the accuracy of\nthe resulting conditional probability distribution p(y|x) is optimized in [35]. The channel approximation\nnetwork ÀÜy = h(x, Œ∏h) is considered to be a conditional probability distribution, p(ÀÜy|x) and the distance\nbetween the conditional probability distributions p(y|x) and p(ÀÜy|x) resulting from the measurement and\nfrom the variational channel approximation network are minimized. As in [40], the parameters of each\nnetwork are minimized using the two stochastic gradients given in (5) and (6).\n‚àáŒ∏D\n1\nN\nN\n√ï\ni=0\n[log (D(xi, yi, Œ∏D)) + log (1 ‚àíD(xi, h(xi, Œ∏h), Œ∏D))],\n(5)\n‚àáŒ∏h\n1\nN\nN\n√ï\ni=0\nlog (1 ‚àíD(xi, h(xi, Œ∏h), Œ∏D)) .\n(6)\nA new discriminative network D(xi, yi, Œ∏D) is introduced to classify between real samples, y, and synthetic\nsamples, ÀÜy, from the channel given its input, x. Œ∏D is the discriminative network parameters. h(x, Œ∏h) takes\n15\nthe place of the generative network, G(z), where x reÔ¨Çects conditional transmitted symbols/samples. N is\nthe number of samples. Additional stochasticity in the function is introduced through variational layers.\nFurthermore, training such an arrangement using the improved Wasserstein GAN approach with gradient\npenalty (WGAN-GP) [20] allows convergence with minimal tuning.\nAdam [21] optimizer is used with a learning rate between 10‚àí4 and 5 √ó 10‚àí4 to iteratively update\nthe network parameters. The variational architecture for the stochastic channel approximation network is\nshown in Fig. 13 (a).\nReLU Layer\nReLU Layer\nReLU Layer\nLinear Layer\nSampler\nReLU Layer\nLinear Layer\nùê±\n‡∑úùê≤\nh(ùê±, ùõâùê°)\n(a)\n(b)\nFig. 13. (a) Variational architecture for the stochastic channel approximation network (conditional generator), (b) Learned one-dimensional\ndistributions of conditional density on non-Gaussian (Chi-Squared) channel effects using variational GAN training [35].\nFor performance evaluation, a communication system that transmits 1 bit/symbol is considered. A\nChi-squared distributed channel model is assumed to explore a more uncommon channel scenario. The\nmeasured and approximated conditional distributions from the black box channel model are shown in\nFig. 13 (b). There is some difference between the original distribution and its approximation, resulting\npartially from its representation as a mixture of Gaussian latent variables; however, this can be alleviated\nby choosing different sampling distributions and by increasing the dimensions of the latent space (at the\ncost of increased model complexity).\nThis approach can also capture more complex distributions such as the channel responses of cascades of\nstochastic effects by jointly approximating the aggregate distribution with the network. Consider a 16-QAM\nsystem that includes AWGN effects along with phase noise, phase offset, and non-linear AM/AM and\nAM/PM distortion effects introduced by a hardware ampliÔ¨Åer model. Fig. 14 illustrates the marginalized\np(x) distribution for both the measured version of the received signal, and the approximated version of\nthe distribution when a stochastic channel approximation model is learned with variational GANs. It is\nobserved that each constellation point‚Äôs distribution, circumferential elongation of these distributions due\nto phase noise at higher amplitudes, and generally the Ô¨Årst order approximation of the distribution are\nlearned successfully.\nOn the receiver side, typically synchronization is performed on the signal (timing estimation, frequency\noffset estimation, etc.) before performing additional signal processing steps for conventional communica-\ntion systems (e.g., symbol detection). Synchronization typically estimates these time, frequency, phase, and\nrate errors in the received data and corrects for them to create a normalized version of the signal. Learned\ncommunication systems described in Sec. II can in some instances perform implicit synchronization\nand channel estimation since hardware and channel impairments such as synchronization offsets can\nbe included during training. From a learning perspective, we can treat these corrections as transforms,\nleveraging expert knowledge about the transforms to simplify the end-to-end task, but still allowing the\nestimators to be fully learned. This approach of radio transformer networks (RTNs), as explored in both\nof [15], [41], are shown to reduce training time and complexity and improve generalization by leveraging\ndomain knowledge.\n16\nFig. 14. Learned two-dimensional distributions of received 16-QAM constellation non-linear channel effects using variational GAN [35].\nThese offset effects exist in any real system containing transmitters and receivers whose oscillators and\nclocks are not locked together.\nTiming and symbol-rate recovery processes involve the estimation and re-sampling of the input signal\nat correct timing offsets and sampling increments, which has a direct analogue to the extraction of visual\npixels at the correct offset, shift or scale (e.g., applying the correct AfÔ¨Åne transformation) in computer\nvision using transformer networks. The input data can be represented as a two-dimensional input, with the\nrows containing in-phase (I) and quadrature (Q) samples and N columns containing samples in time. A\nfull 2D AfÔ¨Åne transformation allows for translation, rotation, and scaling in 2D given by a 2 √ó 3 element\nparameter vector. To restrict this to 1D translation and scaling in the time dimension, the mask in (7) is\nintroduced such that a normal 2D AfÔ¨Åne transform implementation may be used from the image domain.\nŒ∏0, Œ∏1, and Œ∏2 are the remaining unmasked parameters for the 1D AfÔ¨Åne transform:\n\u0014\nŒ∏0\n0\nŒ∏2\n0\nŒ∏1\n0\n\u0015\n(7)\nPhase and frequency offset recovery tasks do not have an immediate analogue in the vision domain.\nHowever, a simple signal processing transform can be applied to accomplish these. The input signal is\nmixed with a complex sinusoid with phase and frequency as deÔ¨Åned by two new unknown parameters as\nshown in (8).\nyn = xn e j(nŒ∏3+Œ∏4)\n(8)\nThis transform can be directly implemented as a new layer in Keras [42], cascaded before the AfÔ¨Åne\ntransform module for timing and symbol-rate recovery.\nThe task of synchronization then becomes the task of parameter estimation of Œ∏i values passed into\nthe transformer modules. Domain appropriate layers are used to assist in estimation of these parameters,\nnamely, complex convolutional 1D layer and complex to power and phase layers. Although many archi-\ntectures are possible, both the complex convolution operation and the differentiable Cartesian to Polar\noperation are used to simplify the learning task. Fig. 15 shows one example of an RTN architecture. A\ndropout rate such as 0.5 can used between layers to prevent over-Ô¨Åtting, and Adam [21] SGD can be used\nto optimize network parameters on the training set, in this case with batch size 1024, and learning rate\n0.001.\n17\nFig. 15. RTN architecture [41].\nThe density plots for pre- and post-transformed input constellations are shown in Fig. 16. When the\nconstellation density for 50 test examples over a range of 20 time samples are observed, the density starts\nto form around the constellation points after using the radio attention model.\nFig. 16. Density plots of the pre- and post-transformed input constellations [41].\nIn both [15], [22], Rayleigh block fading channel is considered as the channel and RTNs are used for\nchannel estimation. Then the received signal is divided by the learned channel response to equalize the\ninput signal, which leads to improved SER performance, providing a more quantitative study of the RTN\nefÔ¨Åcacy.\nThe described channel modeling approaches may be used broadly for enhanced optimization, test,\nand measurement of communication systems and speciÔ¨Åcally to provide effective model-free methods\nfor various wireless tasks such as channel learning in autoencoder-based communications (see Sec. II)\nand signal classiÔ¨Åcation (see Sec. III-B). Moreover, the developed RTN models can be used to extract the\nchannel features, similar to channel estimation in conventional systems, and perform equalization by using\na transformation layer which allows for imparting of expert knowledge without over-specifying learned\nmodels (e.g., writing estimators for speciÔ¨Åc protocols or references).\n18\nB. Signal Detection and Modulation ClassiÔ¨Åcation\nSignal detection and classiÔ¨Åcation functionalities deÔ¨Åne the ability of a wireless communication system\nto accurately build and maintain an up-to-date view of their current operating environment. Detecting\nand coexisting with other users of the spectrum, detecting and isolating sources of interference, Ô¨Çagging\nsigniÔ¨Åcant spectral events, or identifying spectral vacancies within the radio spectrum rely on signal\ndetection and classiÔ¨Åcation. The probability of detection is proportional to the SNR at the receiver.\nTraditionally, speciÔ¨Åc signal detectors are needed for each waveform, developed based on its analytic\nproperties, resulting in systems which can be difÔ¨Åcult to develop and deploy robustly in real-world wireless\napplications largely due to their over-speciÔ¨Åcity, complexity, or sub-optimal performance in real world\nconditions. [44].\nThe RF spectrum is shared with many different signal types ranging from TV broadcast to radar.\nSignal detection and classiÔ¨Åcation tasks are particularly challenging in the presence of multiple waveforms\noperating at the same frequency and at low SNR. Conventional signal detection and classiÔ¨Åcation methods\ncan be categorized as:\n‚Ä¢ General methods: These methods do not require any prior information on the signal types. They detect\nmultiple signal types; however, their constant false alarm rate (CFAR) performance is relatively poor.\nEnergy detector [45] is an example of detectors which do not require prior information. These type\nof detectors can be easily cast into convenient probabilistic form for analysis, but they are severely\nconstrained in their abilities to leverage additional information about signal context or structure to\nimprove performance.\n‚Ä¢ Specialized methods: These methods provide sensitive detectors for speciÔ¨Åc signal types. The detection\nand classiÔ¨Åcation methods are developed using speciÔ¨Åc features of the signal of interest. Matched\nÔ¨Ålters and cyclostationary signal detectors [45] are examples to this type. These methods are often\nnot scalable since a new type of classiÔ¨Åer is required for each new waveform.\nA new class of deep learning-based radio waveform detectors that leverages the powerful new techniques\ndeveloped in computer vision, especially convolutional feature learning, holds the potential to improve the\nsignal detection and classiÔ¨Åcation performance of practical systems by generalizing well and remaining\nsensitive to very low power signals [44]. A strong analogy of this task exists in computer vision with\nobject identiÔ¨Åcation and localization tasks. Recent object detection and localization approaches associate\nspeciÔ¨Åc object classes with bounding box labels within the image. A similar approach was followed in\n[46], where the RF spectrum is represented as an image and CNNs are used to detect, localize and identify\nradio transmissions within wide-band time-frequency power spectrograms using feature learning on 2D\nimages.\nGradient-weighted Class Activation Mapping (Grad-CAM) uses the gradients of any target concept\nÔ¨Çowing into the Ô¨Ånal convolutional layer to produce a coarse localization map highlighting the important\nregions in the image that aids to predict the concept [47]. Grad-CAM is used to perform the spectral\nevent localization in [46]. Fig. 17 shows the block-diagram of the Grad-CAM, which is used for spectral\nevent localization. The gradient of activation score yC (instead of the class probability) is calculated with\nrespect to all the feature maps of a given convolution layer based on the provided input label C. The\nglobal average pooling [48] of the gradients gives the corresponding weight associated with the feature\nmap. Finally, the weighted sum of the feature maps is passed through an element-wise ReLU unit to get\nthe class activation map.\nTo demonstrate the performance in this work, a dataset was collected in 13 different frequency bands\nusing a USRP B205 transceiver at eight different locations across Ô¨Åve distinct cities and across a range\nof different bands and trafÔ¨Åc patterns. Signal types in the dataset include GSM, LTE, ISM, TV, and\nFM among others. Spectrogram plots shown in Fig. 18, labeled as input spectrum, are generated using\nthe collected data to show the signal strength over time and frequency. The x-axis shows the time and\nthe y-axis shows the signal frequency. These images are used as an input to the CNN architecture. The\nGrad-CAM implementation results are also shown in Fig. 18. A hot region of activation is observed on\n19\nFig. 17. Block Diagram of Grad-CAM [47].\ntop of the signal bursts, as expected. The trained feature objective was to classify the band instead of\nactivating all instances of a certain emission type since the labels for every signal activity in a band are\nnot provided; i.e., each spectrogram is assigned only one label even though there may be some other\nnarrow band signals in the same spectrogram. For this reason, for some examples, the activation map\nhighlights only strong parts of the signal and some parts of the signals are favored for identiÔ¨Åcation.\nFig. 18. GradCAM based activation maps and corresponding input spectrograms for 12 test examples from the dataset [46].\nFig. 19 (a) shows the confusion matrix for the classiÔ¨Åcation results. This method for detecting, classi-\nfying and localizing emissions within a spectrogram provides reasonable classiÔ¨Åcation performance and\nreasonable class activation maps corresponding to activity regions in most cases as pictured.\nFor the task of supervised modulation recognition, a number of other non-NN based machine learning\ntechniques from literature were compared with that of a convolutional deep learning architecture in terms of\nperformance. In [3], the generated data set consists of 11 modulations: 8 digital and 3 analog modulations,\nwhich are all widely used in wireless communication systems. These consist of BPSK, QPSK, 8PSK, 16-\nQAM, 64-QAM, BFSK, CPFSK, and PAM4 as digital modulations, and WB-FM, AM-SSB, and AM-DSB\n20\n(a)\n(b)\nFig. 19. (a) Confusion matrix for RF band classiÔ¨Åcation [46], (b) CNN Architecture [3].\nas analog modulations. Data is modulated at a rate of roughly 8 samples per symbol with a normalized\naverage transmit power of 0 dB. These signals are exposed to realistic channel effects. Thermal noise results\nin relatively Ô¨Çat white Gaussian noise at the receiver which forms a noise Ô¨Çoor or sensitivity level and\nSNR. Oscillator drift due to temperature and other semiconductor physics differing at the transmitter and\nreceiver result in symbol timing offset, sample rate offset, carrier frequency offset, and phase difference.\nThese effects lead to a temporal shifting, scaling, linear mixing/rotating between channels, and spinning of\nthe received signal based on unknown time varying processes. Moreover, real channels undergo random\nÔ¨Åltering based on the arriving modes of the transmitted signal at the receiver with varying amplitude,\nphase, Doppler, and delay. This is a phenomenon commonly known as multi-path fading or frequency\nselective fading, which occurs in any environment where signals may reÔ¨Çect off buildings, vehicles, or\nany form of reÔ¨Çector in the environment.\nFig. 19 (b) shows a simple CNN architecture used for the modulation classiÔ¨Åcation task, an un-tuned\n4-layer network utilizing two convolutional layers and two (overly sized) dense fully connected layers.\nLayers use ReLU activation functions except for a softmax activation on the output layer to act as a\nclassiÔ¨Åer. Dropout regularization is used to prevent over-Ô¨Åtting, while a ‚à•W‚à•2 norm regularization on\nweights and ‚à•h‚à•1 norm penalty on dense layer activations can also encourage sparsity of solutions [49],\n[50]. Training is conducted using a categorical cross-entropy loss and an Adam [21] solver.\nExpert features (higher order moments, and cumulants) are used by the baseline classiÔ¨Åers. Fig. 2 shows\nthe performance results of the Naive Bayes, SVM and CNN network architecture results where the CNN\nclassiÔ¨Åer outperforms the Naive Bayes and SVM classiÔ¨Åers at all SNRs.\nFor more realistic evaluations, over-the-air dataset was generated in [51] and the modulation classiÔ¨Å-\ncation performance was compared between virtual geometry group (VGG) and residual networks (RNs)\nwith better architecture tuning, as well as a stronger XGBoost based baseline. It was shown that the RN\napproach achieves state-of-the-art modulation classiÔ¨Åcation performance on for both synthetic and over-\nthe-air signals using datasets consisting of 1 million examples, each 1024 samples long. The RN achieves\nroughly 5 dB higher sensitivity for equivalent classiÔ¨Åcation accuracy than the XGBoost baseline at low\nSNRs while performances are identical at low SNRs. At high SNRs, a maximum classiÔ¨Åcation accuracy\nrate of 99.8% is achieved by the RN, while the VGG network achieves 98.3% and the baseline method\nachieves a 94.6% accuracy.\nC. Generative Adversarial Methods for Situation Awareness\nRadios collect spectrum data samples such as raw (complex-valued) data samples or received signal\nstrength indicator (RSSI) values through spectrum sensing, and use them to train DNNs for various\n21\napplications such as channel estimation or waveform classiÔ¨Åcation, as discussed in previous sections.\nThere are two important hurdles to overcome before using spectrum data for deep learning purposes.\n1) Deep learning requires a large number of data samples to be able to train the complex structures of\nDNNs. This may not be readily available via spectrum sensing, since a wireless user who spends too\nmuch time on spectrum sensing may not have enough time left for other tasks such as transmitting\nits data packets. Therefore, there may not be enough number of wireless data samples available to\ntrain a DNN. Training data augmentation is needed to expand the training data collected in spectrum\nsensing.\n2) Characteristics of spectrum data change over time as the underlying channels, interference and trafÔ¨Åc\neffects, as well as transmit patterns of wireless users change. Therefore, training data collected for\none instant may not be fully applicable in another instant. One example is the channel change\nwhen the wireless nodes move from outdoors to indoors, where more multipaths and therefore\ndifferent channel conditions are expected. Domain adaptation is needed to change test or training\ndata collected in spectrum sensing from one domain (e.g., low mobility) to another domain (high\nmobility).\nThe GAN has emerged as a viable approach to generate synthetic data samples based on a small number\nof real data samples in a short learning period and augment the training data with these synthetic data\nsamples for computer vision, text, and cyber applications [52]‚Äì[54]. The GAN consists of a generator\nand a discriminator playing a minimax game. The generator aims to generate realistic data (with labels),\nwhile the discriminator aims to distinguish data generated by the generator as real or synthetic. Conditional\nGAN extends the GAN concept such that the generator can generate synthetic data samples with labels\n[55]. Fig. 20 shows the conditional GAN architecture. When applied to wireless communications, the\nGAN needs to capture external effects of channel patterns, interference, and trafÔ¨Åc proÔ¨Åles in addition to\nwaveform features. The GAN has been applied for training data augmentation for channel measurements\nin spectrum sensing [56], modulation classiÔ¨Åcation [57], jamming [58], [59], and call data records for 5G\nnetworks [60].\nDiscriminator, ùê∑\nGenerator, ùê∫\nNoise: ùíõ\nLabels: ùíö\nReal or \nSynthetic\nSynthetic data \nùê∫(ùíõ, ùíö)\nReal Data: ùíô\nLabels: ùíö\nFig. 20. Conditional GAN for training data augmentation.\nAs an example, consider an adversary that senses the spectrum and observes transmissions of another\nnode (hidden in channel impairments, trafÔ¨Åc on/off patterns and other background transmissions). Based\non these observations, the adversary trains a DNN to predict when there will be a successful transmission\nand jams it. See Sec. IV for details of this setting when deep learning for wireless communications\nsecurity is discussed. If the adversary waits too long to collect data, it may lose the opportunity to jam\ntransmissions. Therefore, the adversary collects a small number of sensing samples and then augments\nthem through GAN.\nThe wireless application of GAN for domain adaptation has remained limited so far. [56] studied the\nadaptation of training data for spectrum sensing, where a wireless receiver decides if there is an active\ntransmitter (label 1) or not (label 2). There are two environments corresponding to two different channel\ntypes, namely Rayleigh fading distributions with variance 0.2 (environment 1) and 2 (environment 2).\nAssume the receiver has training data for environment 1 and trained a classiÔ¨Åer, whereas there is no\ntraining data for environment 2. Therefore, the receiver generates synthetic training data samples for\n22\nenvironment 2. Training data adaptation consists of a bidirectional GAN [61], a conditional GAN [55],\nand a classiÔ¨Åer. Bidirectional GAN obtains the inverse mapping from data to the conditioned noise by using\na GAN and an autoencoder that together learn to take the inverse of a neural network. As the environment\nchanges from 1 to 2, a new conditional GAN is trained that takes the new samples in environment 2 as\nreal inputs. Instead of random noise as synthetic inputs, the inverse mapping of the bidirectional GAN\nis used and the labels in environment 1 is carried to environment 2 to train the CGAN. After CGAN\ntraining, a classiÔ¨Åer is trained with domain adapted samples and used to label new samples collected in\nenvironment 2. This approach prevents 42% drop in accuracy of SVM-based spectrum sensor operating\nat 5 dB SNR [56].\nSeparately, the GAN was used in [62] to match waveform, channel, and radio characteristics, and spoof\nwireless signals that cannot be reliably distinguished from legitimate signals. This attack can be used\nagainst signal authentication systems and can be launched to emulate primary user behavior in primary\nuser emulation (PUE) attacks.\nTake-away: This section showed that deep learning provides novel means to characterize and analyze\nthe spectrum. By outperforming conventional machine learning algorithms, DNNs signiÔ¨Åcantly contribute\nto spectrum situation awareness for channel modeling and estimation with GANs and FNNs and signal\ndetection and classiÔ¨Åcation with CNNs.\nIV. DEEP LEARNING FOR WIRELESS COMMUNICATIONS SECURITY\nWireless communications are highly susceptible to security threats due to the shared medium of wireless\ntransmissions. A typical example of wireless attacks is the jamming attack that aims to disrupt wireless\ncommunications by imposing interference at receivers (e.g., see [63]) and causing denial of service (DoS)\n[64]. These attacks use different communication means (e.g., power control [65] or random access [66])\nand apply at different levels of prior information on attacker‚Äôs intent [67]. As radios become smarter\nby performing more sophisticated tasks, they also become vulnerable to advanced attacks that target\ntheir underlying tasks. One example is the spectrum sensing data falsiÔ¨Åcation (SSDF) attack, where an\nadversary that participates in cooperative spectrum sensing deliberately falsiÔ¨Åes its spectrum sensing result\n(namely, whether the channel is busy or idle) [68]. This way, the adversary aims to change the channel\noccupancy decision from busy to idle (such that the subsequent transmission fails) or from idle to busy\n(such that no other radio transmits and either the transmission opportunity is wasted or the adversary gets\nthe opportunity to transmit). Data falsiÔ¨Åcation may also occur at other network functions. One example\nis that routing decisions are manipulated by falsifying measures of trafÔ¨Åc congestion (such as queue\nbacklogs) exchanged throughout the wireless network [69], [70].\nBeyond these security threats, the increasing use of deep learning by radios opens up opportunities for\nan adversary to launch new types of attacks on wireless communications. In particular, deep learning itself\nbecomes the primary target of the adversary. The paradigm of learning in the presence of an adversary is\nthe subject of the emerging Ô¨Åeld of adversarial machine learning [71] that has been traditionally applied\nto other data domains such as computer vision. The exploratory (inference) attack [72] is one example,\nwhere the adversary tries to learn the inner-workings of a machine learning classiÔ¨Åer (such as a DNN) by\nquerying it with some data samples, collecting the returned labels, and building a functionally equivalent\nclassiÔ¨Åer.\nAdversarial machine learning provides the necessary optimization mechanisms to launch and mitigate\nattacks on machine learning. In addition to exploratory attacks, two other popular types of attacks are\nevasion and causative (poisoning) attacks. In evasion attacks, the adversary selects or generates data\nsamples to query a machine learning algorithm such as a deep learning classiÔ¨Åer and fool it into making\nwrong decisions [73]. In causative attacks, the adversary targets the training process and tampers with\nthe training data (i.e., modiÔ¨Åes the corresponding labels) such that the machine learning algorithm is not\ntrained adequately [74]. As deep learning is sensitive to errors in training data, this attack is effective\nagainst DNNs. While these attacks have been successfully applied in different data domains such as\n23\ncomputer vision (such as image classiÔ¨Åcation [54]) and natural language processing (such as document\nclassiÔ¨Åcation [75]), they cannot be readily applied in wireless communications. The reasons are multi-fold:\n‚Ä¢ The adversary does not have a mechanism to directly query a wireless transmitter but it can only\nobserve its transmission characteristics over the air.\n‚Ä¢ The collection of training data by the adversary is through a noisy channel, i.e., the training data of\nthe adversary is imperfect by default.\n‚Ä¢ The training data and labels of the adversary and its target are different in wireless domain. Their\ndata samples are different because they are received through different channels, whereas their labels\nare different because their machine learning objectives are different. For example, a transmitter may\ntry to detect whether the channel is busy, while the jammer may try to predict when there will be a\nsuccessful transmission.\nHence, the application of adversarial machine learning to wireless domain is not trivial and needs to\naccount for the aforementioned differences, both from the attacker and defender perspectives [58], [59],\n[76]. As shown in Fig. 21, a basic communication scenario is used to illustrate wireless attacks based on\nadversarial machine learning [58]. There is one cognitive transmitter T that acts as a secondary user and\ndynamically accesses the spectrum to communicate with its receiver R while avoiding interference from\na background transmitter B that acts as a primary user (e.g., TV broadcast network). T uses a decision\nfunction such as a deep learning classiÔ¨Åer for its transmissions to capture B‚Äôs transmission pattern as well\nas channel effects. There is also an adversary A that does not know the decision function of T and tries\nto learn it by sensing the spectrum. This corresponds to a black-box exploratory attack that is followed\nby other attacks such as jamming to reduce the performance of T. In the following, we will describe\nthe exploratory attack on wireless communications and how it is used to launch an effective jamming\nattack [58]. Then we will present other wireless attacks motivated by adversarial deep learning and discuss\ndefense strategies.\nAdversary collects spectrum sensing data and \ntrains another classifier that decides when to jam.\nTransmitter collects spectrum sensing data and \ntrains a classifier that decides on when to transmit.\n‚Äútransmit‚Äù \nor ‚Äúwait‚Äù\nBefore Attack                                                                  Attack\nReceiver ùëπ\nCognitive \nTransmitter ùëª\nBackground \nTransmitter ùë©\nReceiver ùëπ\nAdversary ùë®\nBackground \nTransmitter ùë©\nData\nACK\nJamming\nSignal\n‚Äújam‚Äù \nor ‚Äúwait‚Äù\nCognitive \nTransmitter ùëª\nFig. 21. Adversarial deep learning to launch a wireless attack.\nA. Operational Modes for Transmitter and Adversary\nA synchronized slotted time is assumed where all nodes operate on a single channel (with Ô¨Åxed center\nfrequency and instantaneous bandwidth). Channel gain between any transmitting node i (T, B, or A) and\nany receiving node j (R, T, or A) is given by hij(t) in time slot t. Then, j receives signal\nyj(t) =\n√ï\ni‚ààT(t)\nhij(t)xi(t) + nj(t)\n(9)\n24\nin time slot t, where T(t) is the set of transmitting nodes, nj(t) is the receiver noise at j, and xi(t) carries\na signal if i ‚ààT(t), otherwise xi(t) = 0. Since channel and noise realizations at A (namely, hBA(t) and\nnA(t)) and T (namely, hBA(t) and nA(t)) are different, they observe different data input for their tasks. It\nis assumed that nj(t) is random according to a zero-mean Gaussian distribution with power normalized\nas one, and hij(t) depends on the distance dij between i and j and type of fading. It is also assumed that\nsignal strength diminishes proportionally to 1/d2\nij and log-normal shadowing is used as the shadowing\nmodel (namely, Ô¨Çat fading is considered such that the coherence bandwidth of the channel is larger than\nthe bandwidth of the signal and all frequency components of the signal experience the same magnitude\nof fading). Note that yj(t) is the signal received during data transmission or sensing periods. In the latter\ncase, yj(t) is denoted as sj(t). Next, the operation modes of background transmitter B, transmitter T,\nreceiver R, and adversary A are discussed, as illustrated in Fig. 21.\n1) Background transmitter B: The transmit behavior (idle or busy) of B determines the channel status\n(idle or busy) in each time slot. There are random packet arrivals at B according to the Bernoulli process\nwith rate Œª (packet/slot). If B is in idle status and has a packet to transmit, it is activated with certain\nprobability and keeps transmitting until there is no packet anymore in its queue. Since B‚Äôs busy/idle states\nare correlated over time, both T and J need to observe not only the last channel status but the past channel\nstates over several time slots to predict the current channel status.\n2) Transmitter T: In each time slot, T senses the channel and detects whether the channel status is\nidle or busy, i.e., whether B remains idle or transmits. If idle, T transmits data (a packet) to R in this\ntime slot. T has trained a DNN (unknown to J) as the classiÔ¨Åer CT that classiÔ¨Åes the current time slot t\nas idle or busy based on recent KT sensing results (sT(t ‚àíKT + 1), ¬∑ ¬∑ ¬∑ , sT(t ‚àí1), sT(t)). In time slot t, the\ndata sample for CT is\nsT(t) = (sT(t ‚àíKT + 1), ¬∑ ¬∑ ¬∑ , sT(t ‚àí1), sT(t))\n(10)\nand the corresponding label is\nLT(t) = {‚Äúidle‚Äù, ‚Äúbusy‚Äù},\n(11)\nwhere ‚Äúidle‚Äù or ‚Äúbusy‚Äù means that the channel is idle or busy, respectively. Thus, the training data for\nCT is built as {(sT(t), LT(t))}t. T obtains the label LT(t) of a sample only indirectly by observing whether\nits transmission (if any) is successful or not. A successful transmission indicates an idle channel and a\nfailure indicates a busy channel. Note that this is a noisy observation since a transmission of T may fail\nor succeed depending on channel conditions even when B does not transmit or transmits, respectively. T\ndeems a transmission as successful if it receives an acknowledgment (ACK) from R. If there is no ACK\nreceived, then T deems the transmission as failed. Note that T uses multiple sensing results as its features\nsince features should be able to capture time correlation and help achieve a high sensing accuracy in\na short period of time. Then classiÔ¨Åer CT : sT(t) 7‚ÜíLT(t) deÔ¨Ånes the mapping from sensing results to\noccupancy decision and consequently to transmission decision in time slot t.\n3) Adversary A: Due to the open nature of wireless spectrum, A can also sense the spectrum and\nthen predict whether there will be a successful transmission (with feedback ACK), or not (without a\nfeedback) in a time slot. In the former case, A transmits to jam the channel in this time slot. In the\nlatter case, A remains idle. Without knowing CT, A builds another classiÔ¨Åer CA itself, which predicts\nwhether there will be a successful transmission, or not, in time slot t based on recent KA sensing results\n(sA(t ‚àíKA + 1), ¬∑ ¬∑ ¬∑ , sA(t ‚àí1), sA(t)). The goal of A is to infer CT by building a surrogate classiÔ¨Åer CA.\nNote that A needs to learn relative channel effects and T‚Äôs transmit behavior that in turn depends on\nB‚Äôs transmit behavior and corresponding channel effects. This is a difÔ¨Åcult learning task that needs to be\nhandled in a black-box manner without any prior knowledge. Therefore, it is imperative for A to use a\nDNN as CA. In time slot t, the data sample for CA is\nsA(t) = (sA(t ‚àíKA + 1), ¬∑ ¬∑ ¬∑ , sA(t ‚àí1), sA(t))\n(12)\nand the corresponding label is\nLA(t) = {‚ÄúACK‚Äù, ‚Äúno ACK‚Äù},\n(13)\n25\nwhere ‚ÄúACK‚Äù or ‚Äúno ACK‚Äù means that there is an ACK following a transmission, or not respectively.\nThus, the training data for CA is built as {(sA(t), LA(t))}t. CA is deÔ¨Åned as the mapping from sensing\nresults to prediction of successful transmission and consequently to jamming decision in each time slot.\nA does not jam all time slots, although doing so can maximize the success of jamming, since A will be\neasily detected if it is jamming in all time slots due to the high false alarm rate and J may have power\nbudget in terms of the average jamming power (thus it cannot jam all time slots).\n4) Receiver R: R receives a transmission of T successfully if the signal-to-interference-and-noise-ratio\n(SINR) is larger than some threshold Œ≤. SINR captures transmit power, channel, and interference effects.\nWhenever a transmission is successfully received, R sends an ACK back to T over the short ending period\nof the time slot. In the meantime, A senses the spectrum and potentially detects the presence of ACK\n(without decoding it) by considering the fact that ACK messages are typically distinct from data messages\n(they are short and they follow the data transmission with some Ô¨Åxed time lag).\nB. Jamming based on Exploratory Attack\n1) Deep Learning by Transmitter T: 1000 samples are collected by T and split by half to build its\ntraining and test data. 10 most recent sensing results are used to build one data sample (i.e., KT = 10). T\ntrains an FNN as CT. The Microsoft Cognitive Toolkit (CNTK) [77] is used to train the FNN. T optimizes\nthe hyperparameters of the DNN to minimize eT = max{eMD\nT\n, eFA\nT }, where eMD\nT\nis the error probability for\nmisdetection (a time slot is idle, but T predicts it as busy) and eFA\nT\nis the error probability for false alarm (a\ntime slot is busy, but T predicts it as idle). When the arrival rate Œª for B is 0.2 (packet/slot), the optimized\nhyperparameters of CT are found as follows. The neural network consists of one hidden layer with 100\nneurons. The cross-entropy loss function is minimized to train the neural network with backpropagation\nalgorithm. The output layer uses softmax activation. The hidden layers are activated using the sigmoid\nfunction. All weights and biases are initialized to random values in [‚àí1.0, 1.0]. The input values are unit\nnormalized in the Ô¨Årst training pass. The minibatch size is 25. The momentum coefÔ¨Åcient to update the\ngradient is 0.9. The number of epochs per time slot is 10.\nIn test time, CT is run over 500 time slots to evaluate its performance. The positions of the T, R and\nB are Ô¨Åxed at locations (0, 0), (10, 0), and (0, 10), respectively. All transmit powers are set 30 dB above\nnoise power. The SINR threshold Œ≤ is set as 3. For these scenario parameters, eMD\nT\n= eFA\nT\n= 0. T makes\n400 transmissions and 383 of them are successful. Note that 17 transmissions on idle channels fail due\nto random channel conditions. Thus, the throughput is 383/500 = 0.766 packet/slot and the success ratio\nis 383/400 = 95.75%. Next, we will show how adversarial deep learning-based jammer can signiÔ¨Åcantly\nreduce this performance.\n2) Adversarial Deep Learning by Adversary A: Exploratory attack aims to infer a machine learning\n(including deep learning) classiÔ¨Åer and has been applied to other data domains such as text classiÔ¨Åcation\nin [72] and to image classiÔ¨Åcation in [73]. In these previous works, the adversary queries the target\nclassiÔ¨Åer, obtains labels of a number of samples and then trains a functionally equivalent classiÔ¨Åer using\ndeep learning. Two classiÔ¨Åers are functionally equivalent if they provide the same labels for the same\nsample. However, this approach cannot be applied to the wireless setting due to the differences in data\nsamples and labels.\n‚Ä¢ Data samples at a given time are different, as T and A receive signals through different channels\n(i.e., due to different distances from B and realizations), such that spectrum sensing results sT(t) and\nsA(t) are different at any time t. At a given time t, the signal from B is received at T, R, and A as\nyT(t) = hBT xB(t) + nT(t), yR(t) = hBRxB(t) + nR(t), and yA(t) = hBAxB(t) + nA(t), respectively where\nhBT, hBR, and hBA are the channel gains and nT(t), nR(t), and nA(t) are the receiver noises.\n‚Ä¢ ClassiÔ¨Åers of T and A have different types of labels. T‚Äôs labels indicate whether the channel is busy\nor idle, whereas A‚Äôs labels indicate whether T will have a successful transmission, or not.\nA trains an FNN as the deep learning classiÔ¨Åer CA. For that purpose, 1000 samples are collected by A\nand split by half to build its training and test data. J uses the most recent 10 sensing results to build one\n26\nTABLE III\nEFFECT OF DIFFERENT ATTACK TYPES ON THE TRANSMITTER‚ÄôS PERFORMANCE [58].\nAttack type\nThroughput\nSuccess ratio\nNo attack\n0.766\n95.75%\nAdversarial deep learning\n0.050\n6.25%\nSensing-based attack (œÑ = 3.4)\n0.140\n16.99%\nSensing-based attack (œÑ = 4.7)\n0.576\n69.90%\ndata sample (i.e., KA = 10). J aims to jam successful transmissions (with received ACK feedback) only.\nA optimizes the hyperparameters to minimize eA = max{eMD\nA , eFA\nA }, where eMD\nA\nis the error probability\nfor misdetection (T‚Äôs transmission is successful, but A predicts there will not be an ACK) and eFA\nA\nis the\nerror probability for false alarm (T does not transmit or T‚Äôs transmission fails (even without jamming), but\nA predicts that there will be an ACK). The training time (including hyperparameter optimization) is 67\nseconds and the test time per sample is 0.024 milliseconds. The optimized hyperparameters of the CA are\nfound as follows. The neural network consists of two hidden layers with 50 neurons. The cross-entropy\nloss function is used to train the DNN with backpropagation algorithm. The output layer uses softmax\nactivation. The hidden layers are activated using the hyperbolic tangent (Tanh) function. All weights and\nbiases are initialized to random values in [‚àí1.0, 1.0]. The input values are unit normalized in the Ô¨Årst\ntraining pass. The minibatch size is 25. The momentum coefÔ¨Åcient to update the gradient is 0.9. The\nnumber of epochs per time slot is 10. With these hyperparemeters, the error eA is minimized to 1.48%.\nNote that the hyperparameter optimization affects the accuracy. For instance, if the number of layers is\ndecreased to 1, the error eA increases to 1.73%. Similarly, if the number of neurons per layer is changed\nto 30, the error eA increases to 2.22%.\nIn test time, CA is run over 500 time slots to evaluate its performance. The position of A is Ô¨Åxed at\nlocation (10, 10) and its jamming power is 30 dB above noise power. If there is no jamming, T will\nhave 383 successful transmissions. Under A‚Äôs attack, the number of misdetections is 16, i.e., misdetection\nprobability is eMD\nA\n= 16/383 = 4.18% (majority of successful transmissions are jammed), and the number\nof false alarms is 17, i.e., false alarm probability is eFA\nA\n= 17/(500 ‚àí383) = 14.53%. As the signiÔ¨Åcant\nimpact of this attack, there are only 25 successful transmissions among 400 transmissions. Thus, the\nthroughput of T is reduced from 0.766 packet/slot to 25/500 = 0.05 packet/slot and the success ratio of\nT is reduced from 95.75% to 25/400 = 6.25%.\nAs a benchmark, a conventional attack without adversarial deep learning is also considered. In this\nsensing-based jamming, A jams the channel if its received power during spectrum sensing in the current\nslot is greater than a threshold œÑ. Note that the performance of a sensing-based jammer relies on proper\nselection of œÑ. If œÑ is too low, the number of false alarms increases. If œÑ is too high, then the number of\nmisdetections increases. Note that œÑ is usually given as a Ô¨Åxed value since there is no clear mechanism\nto select œÑ. For a performance upper bound, œÑ is selected as 3.4 that minimizes eA and used to compute\nthe throughput and the success ratio of the transmitter in the presence of sensing-based jammer. Then\neMD\nA\n= 12.8% and eFA\nA\n= 12.6%. Note that eMD\nA\ngrows quickly to 30.0% when œÑ is increased to 5,\nwhereas eFA\nA\ngrows to 14.0% when œÑ is reduced to 2. With the best selection of œÑ, the throughput of T\nis reduced to 0.140 packet/slot and the success ratio of T is reduced from 16.99%. On the other hand, if\nœÑ is selected arbitrarily (say, 4.7), the throughput of T becomes 0.576 packet/slot and the success ratio\nof T becomes 69.90% (i.e., the attack is not as effective). The results which are summarized in Table III\nshow the importance of adversarial deep learning in launching wireless jamming attacks.\n3) Generative Adversarial Learning for Wireless Attacks: In the training process of adversarial deep\nlearning, A collected 500 samples to build its classiÔ¨Åer CA. From a practical attack point of view, it is\ncritical to shorten this initial learning period of A before jamming starts. For that purpose, J builds the\nGAN to generate synthetic data samples based on a small number of real data samples in a short learning\nperiod. Then it uses these synthetic data samples to augment its training data, as discussed in Sec. III-C.\n27\n0\n500\n1000\n1500\n2000\n2500\n3000\n3500\nNumber of iterations\n0.5\n1\n1.5\n2\nLoss\nGenerator loss\nDiscriminator loss\nFig. 22. Discriminator and generator losses during training [58].\nThe conditional GAN is implemented in TensorFlow [43] by using the FNNs with three hidden layers\neach with 128 neurons for both generator and discriminator of the GAN. Leaky ReLu is used as the\nactivation function. Adam optimizer [21] is used as the optimizer to update the weights and biases. The\noutput of each hidden layer is normalized (via batch normalization). Fig. 22 shows the losses of generator\nand discriminator. Note that the losses Ô¨Çuctuate signiÔ¨Åcantly when the GAN training starts and eventually\nconverges after 3000 iterations of the GAN training process.\nThe similarity between real and synthetic data distributions are measured by the Kullback-Leibler (KL)\ndivergence. The KL divergence is given by\nDKL(P‚à•Q) = ‚àí\n√ï\nx‚ààX\nP(x) log\n\u0012Q(x)\nP(x)\n\u0013\n(14)\nfor two distributions P and Q with the support over X. Denote P as the distribution of synthetic data\nsamples (generated by the GAN), Q as the distribution of real samples, and c as the random variable\nfor the channel status (c = 0 if idle and c = 1 if busy). DeÔ¨Åne Pi(x) = P(x|c = i) for i = 0, 1.\nThen, DKL(P0‚à•Q0) = 0.1117 and DKL(P1‚à•Q1) = 0.1109. The test time per sample is measured as 0.024\nmilliseconds (much smaller than the channel coherence time). If sensing results are obtained per second\nand 500 measurements are made, it takes 500 seconds to collect 500 RSSI levels without using the GAN.\nIt takes 23 seconds to train the GAN using a GeForce GTX 1080 GPU and generate 500 synthetic samples\nfrom the GAN. Since 10 real samples are collected over 10 seconds, it takes 33 seconds to prepare data\nwith the GAN. Hence, the GAN signiÔ¨Åcantly reduces the data collection time before A starts jamming.\nWhen A builds its classiÔ¨Åer CA based on 10 real data samples, the error probabilities are 19.80% for false\nalarm and 21.41% for misdetection. After adding 500 synthetic data samples, the error probabilities drop\nto 7.62% for false alarm and to 10.71% for misdetection, namely close to the levels when 500 real data\nsamples are used to train the DNN.\nC. Other Attacks based on Adversarial Deep Learning\nThere are various other wireless attacks that can be launched through adversarial machine learning.\nA brief taxonomy of attacks from the conventional settings to adversarial machine learning is shown in\nFig. 23.\n28\nConventional Wireless \nAttacks\n‚Ä¢\nJamming\n‚Ä¢\nEavesdropping\n‚Ä¢\nSpoofing\nAML-Driven Wireless \nAttacks\n‚Ä¢\nInference-based jamming\n‚Ä¢\nSpectrum poisoning\n‚Ä¢\nSignal classifier evasion\nAdversarial Machine \nLearning (AML) Attacks \n‚Ä¢\nExploratory attacks\n‚Ä¢\nEvasion attacks\n‚Ä¢\nCausative attacks \nAttacks on Cognitive \nRadio\n‚Ä¢\nProtocol violation\n‚Ä¢\nSSDF\n‚Ä¢\nPrimary user emulation\nFig. 23. From conventional wireless attacks to adversarial machine learning.\n1) Spectrum Poisoning Attack: Adversarial deep learning can be also used to launch over-the-air\nspectrum poisoning attacks [76]. Using the results of exploratory attack, the adversary falsiÔ¨Åes the\ntransmitter‚Äôs spectrum sensing data over the air by transmitting during transmitter‚Äôs short spectrum sensing\nperiod. Depending on whether the transmitter uses the sensing data as test data to make transmit decisions\nor for retraining purposes, either it is fooled into making incorrect decisions (evasion attack), or the\ntransmitter‚Äôs algorithm is retrained incorrectly (causative attack). Both attacks substantially reduce the\ntransmitter‚Äôs throughput. Note that these attacks differ from the SSDF attack, since the adversary does\nnot participate in cooperative spectrum sensing and does not try to change channel status labels directly.\nInstead, the adversary injects adversarial perturbations to the channel and aims to fool the transmitter\ninto making wrong spectrum access decisions. A defense scheme can be applied by the transmitter that\ndeliberately makes a small number of incorrect transmissions (selected by the conÔ¨Ådence score on channel\nclassiÔ¨Åcation) to manipulate the adversary‚Äôs training data. This defense effectively fools the adversary and\nhelps the transmitter sustain its throughput [76].\nAnother attack that targets spectrum sensing is priority violation attack [82], where the adversary\ntransmits during the sensing phase by pretending to have higher priority (e.g., emulating primary user\nbehavior) and forces a target transmitter into making wrong decisions in an evasion attack.\n2) Evasion Attack Against Signal ClassiÔ¨Åers: Adversarial perturbations can be added to data samples\nin the test phase for other wireless communications tasks such as signal classiÔ¨Åcation [78]‚Äì[81]. In this\nevasion attack, a receiver aims to classify the incoming signals with respect to waveform characteristics.\nIn the meantime, an adversary transmits as well such that a carefully controlled interference signal is\nadded to the received signal and causes the classiÔ¨Åer to misclassify the received signal. This problem\nwas studied in [78], [79] for modulation classiÔ¨Åcation using a CNN-based classiÔ¨Åer. Both white-box and\nblack-box attacks on the deep learning classiÔ¨Åer are shown to be effective in terms of increasing the\nclassiÔ¨Åcation error with small over-the-air perturbations added to the received signal. [80], [81] developed\nmeans to prevent an intruder from successfully identifying the modulation scheme being used.\nOverall, the attacks that target spectrum sensing or signal classiÔ¨Åcation transmit short signals with low\npower. Therefore, they are more energy efÔ¨Åcient and harder to detect compared to conventional attacks\nthat jam the long data transmission period.\n3) Deep Learning-based Defense Against Wireless Threats: In addition to adversarial deep learning,\nwireless security threats have been studied with defense mechanisms based on deep learning. Against\njamming attacks, [83] developed a deep Q-network algorithm for cognitive radios to decide whether to\nleave an area of heavy jamming or choose a frequency-hopping pattern to defeat smart jammers. [84]\ntrained a CNN network to classify signals to audio jamming, narrowband jamming, pulse jamming, sweep\njamming, and spread spectrum jamming. [85] applied a wavelet-based pre-processing step that highlights\n29\nthe disrupted parts of the signal before classifying signals as jammers using a CNN. Another example is\nsignal authentication with deep learning as an IoT application. [86] presented a deep learning solution\nbased on a long short-term memory (LSTM) structure to extract a set of stochastic features from signals\ngenerated by IoT devices and dynamically watermark these features into the signal. This method was\nshown to effectively authenticate the reliability of the signals.\nD. Defense Against Adversarial Deep Learning\nA typical Ô¨Årst step of adversarial deep learning is the exploratory attack where A builds the surrogate\nclassiÔ¨Åer CA to infer the transmit behavior of T. An effective defense follows from disrupting the training\nprocess of CA. In this defense, T does not always follow the labels returned by CA and changes them for\nsome of its data samples when making transmit decisions [58]. In particular, T changes the label ‚ÄúACK‚Äù\n(i.e., ‚Äúa successful transmission‚Äù) to ‚ÄúNo ACK‚Äù (i.e., ‚Äúno successful transmission‚Äù), and vice versa. This\nway, A‚Äôs training data is manipulated and A cannot build a reliable classiÔ¨Åer in the exploratory attack.\nAs T poisons the training process of A by providing wrong training data, this defense corresponds to a\ncausative (or poisoning) attack of T back at J. By deliberately taking wrong decisions in certain time\nslots, T does not transmit even if channel is predicted as idle, and transmits even if channel is predicted\nas busy.\nWhile this defense increases the uncertainty at A, there is a trade-off in the sense that wrong transmit\ndecisions would reduce the transmission success of T. Therefore, T needs to decide to Ô¨Çip its decision\nin a small number of carefully selected time slots. Let pd denote the percentage (%) of time slots in\nwhich T decides to Ô¨Çip labels. pd is considered as a defense budget. T uses the likelihood score ST(t)\n(namely the likelihood of whether a channel is idle) returned by DNN to decide when to take the defense\naction. If ST(t) is less than a threshold Œ∑, T classiÔ¨Åes a given time slot t as idle; otherwise T classiÔ¨Åes\nit as busy. When ST(t) is far away from Œ∑, then such a classiÔ¨Åcation has a high conÔ¨Ådence; otherwise\nthe conÔ¨Ådence is low. For the FNN structure used in previous subsection, Œ∑ = 0.25, which is chosen to\nminimize eT. To optimize the defense mechanism, T performs defense operations in a time slot t when\nST(t) is close to 0 or 1, since T‚Äôs transmission decisions are more predictable in such a time slot. Subject\nto pd values, T changes labels in different time slots and A ends up building different classiÔ¨Åers with\ndifferent hyperparameters compared to the previous case of no defense.\n0\n10\n20\n30\n40\n50\nDefense budget pd (%)\n0\n0.025\n0.05\n0.075\n0.1\n0.125\n0.15\n0.175\n0.2\n0.225\n0.25\nThroughput\neA = 14.53%\neA = 33.33%\neA = 37.31%\neA = 38.97%\neA = 38.25%\neA = 23.68%\nBest\n Defense\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nIteration number\n0\n5\n10\n15\n20\n25\n30\n35\nDefense budget pd (%)\nBest\n Defense\nNo Defense\n(a)\n(b)\nFig. 24.\n(a) Effects of transmitter‚Äôs defense on the adversary [58], (b) Dynamic adaptation of transmitter‚Äôs defense against the adversary\n[58].\nFig. 24 (a) shows the results when T operates with different defense budgets. As pd increases, A‚Äôs error\nprobabilities and T‚Äôs throughput start increasing signiÔ¨Åcantly. T‚Äôs throughput reaches maximum when\npd = 10%. As pd increases further, the growth in A‚Äôs error probabilities saturates and cannot compensate\nthe errors in channel access decisions anymore. As a result, T‚Ä≤s throughput starts decreasing. To determine\nthe best value of pd, T can start attack mitigation with a Ô¨Åxed level of pd and then gradually increase or\n30\ndecrease pd in response to changes in its throughput that is measured through the received ACK messages.\nFig. 24 (b) shows how pd is adapted over time to optimize the throughput.\nTake-away: This section showed that deep learning can be effectively used in an adversarial setting\nto launch successful attacks to reduce communication performance. In turn, the adversary can be fooled\nby manipulating its sensing data samples at certain time instances that are selected by deep learning\nprediction results.\nV. CONCLUSION\nDeep learning has made rapid strides in addressing unique challenges encountered in wireless com-\nmunications that need to learn from and adapt to spectrum dynamics quickly, reliably, and securely. We\npresented the recent progress made in applying deep learning to end-to-end (physical layer) communica-\ntions, spectrum situation awareness, and wireless security. First, we discussed how to formulate transmitter\nand receiver design at the physical layer as an autoencoder that is constructed as DNNs. We showed that\nthis formulation captures channel impairments effectively and improves performance of single and multiple\nantenna, and multiuser systems signiÔ¨Åcantly compared to conventional communication systems. Second,\nwe showed that deep learning can help with channel modeling and estimation as well as signal detection\nand classiÔ¨Åcation when model-based methods fail. The GAN can be applied to reliably capture the complex\nchannel characteristics for the purpose of channel estimation or spectrum data augmentation, while CNNs\ncan improve the signal classiÔ¨Åcation accuracy signiÔ¨Åcantly compared to conventional machine learning\ntechniques. Third, we discussed the application of adversarial deep learning to launch jamming attacks\nagainst wireless communications. Starting with an exploratory attack, the adversary can use DNNs to\nreliably learn the transmit behavior of a target communication system and effectively jam it, whereas a\ndefense mechanism can fool the adversary by poisoning its DNN training process.\nThe research topics discussed in this chapter illustrated key areas where deep learning can address model\nand algorithm deÔ¨Åcits, enhancing wireless communications. The progress so far clearly demonstrated that\ndeep learning offers new design options for wireless communications and enhances spectrum situational\nawareness, while adversarial use of deep learning poses an emerging threat to wireless communications\nand casts communications and sensing into an interesting adversarial game. Numerous additional deep\nlearning applications in wireless communications are on the horizon, which will potentially change the\nway we model, design, implement, and operate new generations of wireless systems, and shift the Ô¨Åeld\nto be more data-centric than ever before.\nREFERENCES\n[1] S. Haykin, ‚ÄúCognitive radio: brain-empowered wireless communications,‚Äù IEEE J. Sel. Areas Commun., vol.23, no. 2, pp. 201-220,\n2005.\n[2] C. Clancy, H. J. Stuntebeck, and T. O‚ÄôShea, ‚ÄúApplications of machine learning to cognitive radio networks,‚Äù IEEE Trans. Wireless\nCommun., vol. 14, no. 4, pp. 47-52, 2007.\n[3] T. J. O‚ÄôShea, J. Corgan, and T. C. Clancy, ‚ÄúConvolutional radio modulation recognition networks,‚Äù Int. Conf. on Engineering\nApplications of Neural Networks, 2016.\n[4] C. E. Shannon, ‚ÄúA mathematical theory of communication,‚Äù Bell Syst. Tech. Journal, vol. 27, pp. 379-423, 623-656, 1948.\n[5] A. Goldsmith, ‚ÄúJoint source/channel coding for wireless channels,‚Äù IEEE Vehicular Technology Conf. (VTC), 1995.\n[6] Y. E. Sagduyu and A. Ephremides, ‚ÄúCross-layer optimization of MAC and network coding in wireless queueing tandem networks,‚Äù\nIEEE Trans. Inf. Theory, vol. 54, no. 2, pp. 554-571, Feb. 2008.\n[7] N. Samuel, T. Diskin, and A. Wiesel, ‚ÄúDeep MIMO detection,‚Äù IEEE Int. Workshop on Signal Processing Advances in Wireless\nCommunications, 2017.\n[8] T. Wang, C. Wen, H. Wang, F. Gao, T. Jiang, and S. Jin, ‚ÄúDeep learning for wireless physical layer: opportunities and challenges,‚Äù\nChina Communications,vol. 14, no. 11, pp. 92-111, 2017.\n[9] H. He, C.-K. Wen, S. Jin, and G. Y. Li, ‚ÄúA model-driven deep learning network for MIMO detection,‚Äù arXiv preprint, arXiv:1809.09336,\n2018.\n[10] X. Tan, W. Xu, Y. Be‚Äôery, Z. Zhang, X. You, and C. Zhang, ‚ÄúImproving Massive MIMO Belief Propagation Detector with Deep\nNeural Network,‚Äù arxiv preprint, arXiv:1804.01002, 2018.\n[11] V. V. Veeravalli and V. S. Annapureddy, ‚ÄúGaussian interference networks: Sum capacity in the low interference regime and new outer\nbounds on the capacity region,‚Äù IEEE Trans. Inf. Theory, vol. 55, no. 7, pp. 3032-3050, 2009.\n31\n[12] T. S. Han and K. Kobayashi, ‚ÄúA new achievable rate region for the interference channel,‚Äù IEEE Trans. Inf. Theory, vol. 27, no. 1, pp.\n49-60, 1981.\n[13] A. B. Carleial, ‚ÄúA case where interference does not reduce capacity,‚Äù IEEE Trans. Inf. Theory, vol. 21, no. 5, pp. 569-570, 1975.\n[14] T. Erpek, S. Ulukus, and Y. E. Sagduyu, ‚ÄúInterference regime enforcing rate maximization for Non-Orthogonal Multiple Access\n(NOMA),‚Äù IEEE Int. Conf. on Computing, Networking and Communications (ICNC), 2019.\n[15] T. J. O‚ÄôShea, and J. Hoydis, ‚ÄúAn introduction to deep learning for the physical layer,‚Äù IEEE Trans. Cogn. Commun. Netw., vol. 3, no.\n4, pp. 563-575, 2017.\n[16] S. D¬®orner, S. Cammerer, J. Hoydis, and S. Brink, ‚ÄúDeep learning based communication over the air,‚Äù IEEE J. Sel. Topics Signal\nProcess., vol. 12, no. 1, pp. 132-143, 2018.\n[17] T. J. O‚ÄôShea, T. Erpek, and T. C. Clancy, ‚ÄúPhysical layer deep learning of encodings for the MIMO fading channel,‚Äù IEEE Annual\nAllerton Conf. on Communication, Control, and Computing (Allerton), 2017.\n[18] T. Erpek, T. J. O‚ÄôShea, and T. C. Clancy, ‚ÄúLearning a physical layer scheme for the MIMO interference channel,‚Äù IEEE Int. Conf.\non Communications (ICC), 2018.\n[19] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning, MIT Press, 2016.\n[20] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, A. Courville, ‚ÄúImproved training of Wasserstein GANs,‚Äù Advances in Neural\nInformation Processing Systems (NeurIPS), 2017.\n[21] D. P. Kingma, and J. Ba, ‚ÄúAdam: A method for stochastic optimization,‚Äù arXiv preprint, arXiv:1412.6980, 2014.\n[22] F. A. Aoudia and J. Hoydis. ‚ÄùEnd-to-end learning of communications systems without a channel model,‚Äù arXiv preprint,\narXiv:1804.02276, 2018.\n[23] S. M. Alamouti, ‚ÄúA simple transmit diversity technique for wireless communications,‚Äù IEEE J. Sel. Areas Commun., vol. 16, no. 8,\npp. 1451-1458, 1998.\n[24] V. Tarokh, N. Seshadri, and A. R. Calderbank, ‚ÄúSpace-time codes for high data rate wireless communication: performance criterion\nand code construction,‚Äù IEEE Trans. Inf. Theory, vol. 44, no. 2, pp. 744-765, 1998.\n[25] E. Telatar, ‚ÄúCapacity of multi-antenna Gaussian channels,‚Äù European Trans. on Telecommunications, vol. 10, no. 6, pp. 585-595, 1999.\n[26] W. Yu, W. Rhee, S. Boyd, and J. M. CiofÔ¨Å, ‚ÄúIterative water-Ô¨Ålling for Gaussian vector multiple access channels,‚Äù IEEE Trans. Inf.\nTheory, vol. 50, no. 1, pp. 145-151, 2004.\n[27] L. Liu, C. Oestges, J. Poutanen, K. Haneda, P. Vainikainen, F. Quitin, F. Tufvesson, and P. D. Doncker, ‚ÄúThe COST 2100 MIMO\nchannel model,‚Äù IEEE Trans. Wireless Commun., vol. 19, no. 6, pp. 92-99, 2012.\n[28] S. Ioffe, and C. Szegedy, ‚ÄúBatch normalization: Accelerating deep network training by reducing internal covariate shift,‚Äù arXiv preprint,\narXiv:1502.03167, 2015.\n[29] B. Hassibi and B. M. Hochwald, ‚ÄúHow much training is needed in multiple-antenna wireless links?‚Äù IEEE Trans. Inf. Theory, vol.\n49, no. 4, pp. 951-963, 2003.\n[30] T. Erpek, Y. E. Sagduyu, Y. Shi, and S. Ponnaluri,‚ÄúRate optimization with distributed network coordination of multiuser MIMO\ncommunications,‚Äù IEEE Vehicular Technology Conf. (VTC), 2018.\n[31] T. Erpek, Y. E. Sagduyu, Y. Shi, and S. Ponnaluri, ‚ÄúNetwork control and rate optimization for multiuser MIMO communications,‚Äù\nAd Hoc Networks, vol. 85, pp. 92-102, 2019.\n[32] Federal Communications Commission, ‚ÄúNotice of proposed rule making and order: facilitating opportunities for Ô¨Çexible, efÔ¨Åcient,\nand reliable spectrum use employing cognitive radio technologies,‚Äù ET Docket No., 03-108, 2005.\n[33] T. J. O‚ÄôShea, T. Roy, N. West, and B. C. Hilburn, ‚ÄúPhysical layer communications system design over-the-air using adversarial\nnetworks,‚Äù arXiv preprint, arXiv:1803.03145, 2018.\n[34] H. Ye, G. Y. Li, B.-H. F. Juang, and K. Sivanesan, ‚ÄúChannel agnostic end-to-end learning based communication systems with\nconditional GAN,‚Äù IEEE Global Communications Conf. (Globecom) Workshops, 2018.\n[35] T. J. O‚ÄôShea, T. Roy, and N. West, ‚ÄúApproximating the void: learning stochastic channel models from observation with variational\ngenerative adversarial networks,‚Äù arXiv preprint, arXiv:1805.06350, 2018.\n[36] W. Grathwohl, D. Choi, Y. Wu, G. Roeder, and D. Duvenaud, ‚ÄúBackpropagation through the void: Optimizing control variates for\nblack-box gradient estimation,‚Äù arXiv preprint, arXiv:1711.00123, 2017.\n[37] V. Raj, and S. Kalyani, ‚ÄúBackpropagating through the air: deep learning at physical layer without channel models,‚Äù IEEE Commun.\nLett., vol. 22, no. 11, pp. 2278-2281, 2018.\n[38] F. A. Aoudia, and J. Hoydis, ‚ÄúEnd-to-End learning of communications systems without a channel model,‚Äù arXiv preprint,\narXiv:1804.02276, 2018.\n[39] M. Ettus, Universal software radio peripheral, 2009.\n[40] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, ‚ÄúGenerative adversarial\nnets,‚Äù Advances in Neural Information Processing Systems (NeurIPS), 2014.\n[41] T. J. O‚ÄôShea, L. Pemula, D. Batra, T. C. Clancy, ‚ÄúRadio transformer networks: attention models for learning to synchronize in wireless\nsystems,‚Äù arXiv preprint, arXiv:1805.06350, 2018.\n[42] F. Chollet, Keras, https://github.com/fchollet/keras, 2015.\n[43] M. Abadi, et al., ‚ÄúTensorFlow: large-scale machine learning on heterogeneous systems,‚Äù https://tensorÔ¨Çow.org.\n[44] T. J. O‚ÄôShea, T. Roy, and T. C. Clancy, ‚ÄúLearning robust general radio signal detection using computer vision methods,‚Äù Asilomar\nConf. on Signals, Systems, and Computers, 2017.\n[45] I. F. Akyildiz, W.-Y. Lee, M. C. Vuran, S. Mohanty,‚ÄúA survey on spectrum management in cognitive radio networks,‚Äù IEEE\nCommunications Magazine, vol. 46, no. 4, pp. 40-48, 2008.\n[46] T. J. O‚ÄôShea, T. Roy and T. Erpek, ‚ÄúSpectral detection and localization of radio events with convolutional neural features,‚Äù European\nSignal Processing Conf., 2017.\n[47] R. R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, and D. Batra, ‚ÄúGrad-CAM: Why did you say that?‚Äù arXiv preprint,\narXiv:1611.07450, 2016.\n32\n[48] M. Lin, Q. Chen, and S. Yan, ‚ÄúNetwork in network,‚Äù arXiv preprint, arXiv:1312.4400, 2013.\n[49] H. Lee, A. Battle, R. Raina, A. Y. Ng, ‚ÄúEfÔ¨Åcient sparse coding algorithms,‚Äù Advances in Neural Information Processing Systems\n(NeurIPS), 2006.\n[50] M. D. Zeiler, D. Krishnan, G. W. Taylor, and R. Fergus, ‚ÄúDeconvolutional networks,‚Äù IEEE Conf. on Computer Vision and Pattern\nRecognition (CVPR), 2010.\n[51] T. J. O‚ÄôShea, T. Roy, and T. C. Clancy, ‚ÄúOver-the-air deep learning based radio signal classiÔ¨Åcation,‚Äù IEEE J. Sel. Topics Signal\nProcess., vol. 12, no. 1, pp. 168-179, 2018.\n[52] A. Shrivastava, T. PÔ¨Åster, O. Tuzel, J. Susskind, W. Wang, and R. Webb, ‚ÄúLearning from simulated and unsupervised images through\nadversarial training,‚Äù Conf. on Computer Vision and Pattern Recognition (CVPR), 2017.\n[53] Y. Shi, Y. E. Sagduyu, K. Davaslioglu, and J. Li, ‚ÄúGenerative adversarial networks for black-box API attacks with limited training\ndata,‚Äù IEEE Symposium on Signal Processing and Information Technology, 2018.\n[54] Y. Shi, Y. E. Sagduyu, K. Davaslioglu, and R. Levy, ‚ÄúVulnerability detection and analysis in adversarial deep learning,‚Äù in Guide to\nVulnerability Analysis for Computer Networks and Systems - An ArtiÔ¨Åcial Intelligence Approach. Computer Communications and\nNetworks. Springer, Cham, 2018.\n[55] M. Mirza and S. Osindero, ‚ÄúConditional generative adversarial nets,‚Äù arXiv preprint, arXiv:1411.1784, 2014.\n[56] K. Davaslioglu and Y. E. Sagduyu, ‚ÄúGenerative adversarial learning for spectrum sensing,‚Äù IEEE Int. Conf. on Communication (ICC),\n2018.\n[57] B. Tang, Y. Tu, Z. Zhang, and Y. Lin, ‚ÄúDigital signal modulation classiÔ¨Åcation with data augmentation using generative adversarial\nnets in cognitive radio networks,‚Äù IEEE Access, vol. 6, pp. 15713‚Äì15722, 2018.\n[58] T. Erpek, Y. E. Sagduyu, and Y. Shi, ‚ÄúDeep learning for launching and mitigating wireless jamming attacks,‚Äù IEEE Trans. Cogn.\nCommun. Netw., vol. 5, no. 1, pp. 2-14, 2019.\n[59] Y. Shi, Y. E. Sagduyu, T. Erpek, K. Davaslioglu, Z. Lu, and J. Li, ‚ÄúAdversarial deep learning for cognitive radio security: jamming\nattack and defense strategies,‚Äù IEEE ICC 2018 Workshop - Promises and Challenges of Machine Learning in Comm. Networks, 2018.\n[60] B. Hughes, S. Bothe, H. Farooq, and A. Imran, ‚ÄúGenerative adversarial learning for machine learning empowered self organizing 5G\nnetworks,‚Äù IEEE Int. Conf. on Computing, Networking and Communications (ICNC), 2019.\n[61] J. Donahue, P. Krahenbuhl and T. Darrell, ‚ÄúAdversarial feature learning,‚Äù arXiv preprint, arXiv:1605.09782, 2016.\n[62] Y. Shi and K. Davaslioglu and Y. E. Sagduyu, ‚ÄúGenerative adversarial network for wireless signal spooÔ¨Ång,‚Äù ACM WiSec Workshop\non Wireless Security and Machine Learning (WiseML), 2019.\n[63] Y. E. Sagduyu, R. Berry, and A. Ephremides, ‚ÄúJamming games in wireless networks with incomplete information,‚Äù IEEE\nCommunications Magazine, vol. 49, no. 8, pp. 112-118, 2011.\n[64] Y. E. Sagduyu and A. Ephremides, ‚ÄúA game-theoretic analysis of denial of service attacks in wireless random access,‚Äù Journal of\nWireless Networks, vol. 15, no. 5, pp. 651-666, 2009.\n[65] Y. E. Sagduyu, R. Berry and A. Ephremides, ‚ÄúJamming games for power controlled medium access with dynamic trafÔ¨Åc,‚Äù IEEE Int.\nSymposium on Information Theory (ISIT), 2010.\n[66] Y. E. Sagduyu, R. Berry and A. Ephremides, ‚ÄúWireless jamming attacks under dynamic trafÔ¨Åc uncertainty,‚Äù IEEE Int. Symposium on\nModeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WIOPT), 2010.\n[67] Y. E. Sagduyu, R. Berry, and A. Ephremides, ‚ÄúMAC games for distributed wireless network security with incomplete information of\nselÔ¨Åsh and malicious user types,‚Äù IEEE Int. Conf. on Game Theory for Networks (GameNets), 2009.\n[68] Y. E. Sagduyu, ‚ÄúSecuring cognitive radio networks with dynamic trust against spectrum sensing data falsiÔ¨Åcation,‚Äù IEEE Military\nCommunications Conf. (MILCOM), 2014.\n[69] Z. Lu, Y. E. Sagduyu, and J. Li, ‚ÄùSecuring the backpressure algorithm for wireless networks,‚Äù IEEE Trans. Mobile Comput., vol. 16,\nno. 4, pp. 1136-1148, 2017.\n[70] Z. Lu, Y. E. Sagduyu, and J. Li, ‚ÄùQueuing the trust: secure backpressure algorithm against insider threats in wireless networks‚Äù, IEEE\nConf. on Computer Communications (INFOCOM), 2015.\n[71] Y. Vorobeychik and M. Kantarcioglu, Adversarial machine learning, Morgan & Claypool, 2018.\n[72] Y. Shi, Y. E. Sagduyu, and A. Grushin, ‚ÄúHow to steal a machine learning classiÔ¨Åer with deep learning,‚Äù IEEE Symposium on Tech.\nfor Homeland Security, 2017.\n[73] Y. Shi and Y. E. Sagduyu, ‚ÄúEvasion and causative attacks with adversarial deep learning,‚Äù IEEE Military Communications Conf.\n(MILCOM), 2017.\n[74] L. Pi, Z. Lu, Y. E. Sagduyu, and S. Chen, ‚ÄúDefending active learning against adversarial inputs in automated document classiÔ¨Åcation,‚Äù\nIEEE Global Conf. on Signal and Information Processing (GlobalSIP) Symposium on Compressed Sensing, Deep Learning, 2016.\n[75] Y. Shi, Y. E. Sagduyu, K. Davaslioglu, and J. Li, ‚ÄúActive deep learning attacks under strict rate limitations for online API calls,‚Äù\nIEEE Symposium Tech. for Homeland Security, 2018.\n[76] Y. Shi, T. Erpek, Y. E. Sagduyu, and J. Li, ‚ÄúSpectrum data poisoning with adversarial deep learning,‚Äù IEEE Military Communications\nConf. (MILCOM), 2018.\n[77] Microsoft Cognitive Toolkit (CNTK), https://docs.microsoft.com/en-us/cognitive-toolkit\n[78] M. Sadeghi and Erik G. Larsson, ‚ÄúAdversarial attacks on deep-learning based radio signal classiÔ¨Åcation,‚Äù IEEE Wireless Commun.\nLett., vol. 8, no. 1, pp. 213-216, 2019.\n[79] B. Flowers, R. M. Buehrer, and W. C. Headley, ‚ÄúEvaluating adversarial evasion attacks in the context of wireless communications,‚Äù\narXiv preprint, arXiv:1903.01563, 2019.\n[80] M. Z. Hameed, A. Gyorgy, and D. Gunduz, ‚ÄúCommunication without interception: defense against deep-learning-based modulation\ndetection,‚Äù arXiv preprint, arXiv:1902.10674, 2019.\n[81] S. Kokalj-Filipovic and R. Miller, ‚ÄúAdversarial examples in RF deep learning: detection of the attack and its physical robustness,‚Äù\narXiv preprint, arXiv:1902.06044, 2019.\n33\n[82] Y. E. Sagduyu, Y. Shi, and T. Erpek, ‚ÄúIoT network security from the perspective of adversarial deep learning,‚Äù IEEE Int. Conf. on\nSensing, Communication and Networking (SECON) Workshop on Machine Learning for Communication and Networking in IoT, 2019.\n[83] G. Han, L. Xiao, and H. V. Poor, ‚ÄúTwo-dimensional anti-jamming communication based on deep reinforcement learning,‚Äù IEEE Int.\nConf. on Acoustics, Speech and Signal Processing (ICASSP), 2017.\n[84] Z. Wu, Y. Zhao, Z. Yin, and H. Luo, ‚ÄúJamming signals classiÔ¨Åcation using convolutional neural network,‚Äù IEEE Symposium on Signal\nProcessing and Information Technology (ISSPIT), 2017.\n[85] O. A. Topal, S. Gecgel, E. M. Eksioglu, G. Kurt, ‚ÄúIdentiÔ¨Åcation of smart jammers: Learning based approaches using Wavelet\nrepresentation,‚Äù arXiv preprint, arXiv:1901.09424, 2019.\n[86] A. Ferdowsi and W. Saad, ‚ÄúDeep learning for signal authentication and security in massive internet of things systems,‚Äù arXiv preprint,\narXiv:1803.00916, 2018.\n",
  "categories": [
    "cs.NI",
    "cs.LG"
  ],
  "published": "2020-05-12",
  "updated": "2020-05-12"
}