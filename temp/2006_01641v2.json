{
  "id": "http://arxiv.org/abs/2006.01641v2",
  "title": "Unsupervised Deep Learning for Optimizing Wireless Systems with Instantaneous and Statistic Constraints",
  "authors": [
    "Chengjian Sun",
    "Changyang She",
    "Chenyang Yang"
  ],
  "abstract": "Deep neural networks (DNNs) have been introduced for designing wireless\npolicies by approximating the mappings from environmental parameters to\nsolutions of optimization problems. Considering that labeled training samples\nare hard to obtain, unsupervised deep learning has been proposed to solve\nfunctional optimization problems with statistical constraints recently.\nHowever, most existing problems in wireless communications are variable\noptimizations, and many problems are with instantaneous constraints. In this\npaper, we establish a unified framework of using unsupervised deep learning to\nsolve both kinds of problems with both instantaneous and statistic constraints.\nFor a constrained variable optimization, we first convert it into an equivalent\nfunctional optimization problem with instantaneous constraints. Then, to ensure\nthe instantaneous constraints in the functional optimization problems, we use\nDNN to approximate the Lagrange multiplier functions, which is trained together\nwith a DNN to approximate the policy. We take two resource allocation problems\nin ultra-reliable and low-latency communications as examples to illustrate how\nto guarantee the complex and stringent quality-of-service (QoS) constraints\nwith the framework. Simulation results show that unsupervised learning\noutperforms supervised learning in terms of QoS violation probability and\napproximation accuracy of the optimal policy, and can converge rapidly with\npre-training.",
  "text": "arXiv:2006.01641v2  [cs.IT]  11 Aug 2020\n1\nUnsupervised Deep Learning for Optimizing\nWireless Systems with Instantaneous and\nStatistic Constraints\nChengjian Sun, Changyang She and Chenyang Yang\nAbstract\nDeep neural networks (DNNs) have been introduced for designing wireless policies by approximat-\ning the mappings from environmental parameters to solutions of optimization problems. Considering\nthat labeled training samples are hard to obtain, unsupervised deep learning has been proposed to solve\nfunctional optimization problems with statistical constraints recently. However, most existing problems\nin wireless communications are variable optimizations, and many problems are with instantaneous\nconstraints. In this paper, we establish a uniﬁed framework of using unsupervised deep learning to\nsolve both kinds of problems with both instantaneous and statistic constraints. For a constrained variable\noptimization, we ﬁrst convert it into an equivalent functional optimization problem with instantaneous\nconstraints. Then, to ensure the instantaneous constraints in the functional optimization problems, we\nuse DNN to approximate the Lagrange multiplier functions, which is trained together with a DNN\nto approximate the policy. We take two resource allocation problems in ultra-reliable and low-latency\ncommunications as examples to illustrate how to guarantee the complex and stringent quality-of-service\n(QoS) constraints with the framework. Simulation results show that unsupervised learning outperforms\nsupervised learning in terms of QoS violation probability and approximation accuracy of the optimal\npolicy, and can converge rapidly with pre-training.\nIndex Terms\nUnsupervised deep learning, variable optimization, functional optimization, constraints, ultra-reliable\nand low-latency communications\nThis paper has been presented in part at the IEEE Global Communications Conference 2019 [1] and in part at the IEEE\nInternational Symposium on Personal, Indoor and Mobile Radio Communications 2019 [2].\nC. Sun and C. Yang are with the School of Electronics and Information Engineering, Beihang University, Beijing 100191,\nChina (email:{sunchengjian,cyyang}@buaa.edu.cn).\nC. She is with the School of Electrical and Information Engineering, University of Sydney, Sydney, NSW 2006, Australia\n(e-mail: shechangyang@gmail.com).\nAugust 12, 2020\nDRAFT\n2\nI. INTRODUCTION\nBeyond ﬁfth generation (B5G) cellular systems are expected to support diverse quality-of-\nservice (QoS) requirements of various applications, say video streaming and ultra-reliable and\nlow-latency communications (URLLC) [3]. To efﬁciently use network resources to satisfy the\nQoS requirements in a dynamic environment, a base station (BS) needs to optimize its trans-\nmission policy according to the environment parameters before they change. A typical wireless\npolicy adapts to small-scale channels, e.g., power allocation, beamforming, and user scheduling,\nwhere the BS needs to ﬁnd the optimal policy every few milliseconds, depending on the channel\ncoherence time. If the policy cannot be obtained in closed-form, which is the case for many\nproblems in wireless communications, numerical algorithms (e.g., interior-point method) have to\nbe used for ﬁnding the solution. This incurs high computational overheads. If the computing time\nused for searching the optimal solution is longer than the channel coherence time, the obtained\nsolution cannot guarantee the QoS with the current channel realization. This issue becomes more\ncritical for URLLC with 1 ms end-to-end (E2E) latency [4].\nTo avoid executing traditional numerical algorithms repeatedly whenever the environment\nstatus changes, a novel idea of “learning to optimize” was proposed in [5], which ﬁnds a mapping\nfrom the environmental parameters to the optimal decision by approximating the mapping with\na deep neural network (DNN). While promising, the method proposed therein needs a large\nnumber of labels to train the DNN, which are obtained by ﬁnding the solutions of the original\noptimization problem for given realizations of random environment parameters. This is possible\nif the original problem is a variable optimization problem, which aims to ﬁnd a scalar (e.g.,\ntransmit power) or a vector (e.g., beamforming vector), but is very hard if not impossible when\nthe original problem should be formulated as functional optimization problem [6].\nMost of existing problems in wireless communications are formulated as constrained variable\noptimization problems, e.g., ﬁnding beamforming vectors to maximize the sum-rate or minimize\nthe total power subjects to the maximal transmit power constraint and the QoS constraint such\nas the data rate or the signal-to-noise ratio (SNR) exceeding a threshold. In these variable\noptimization problems, the objective function, constraints, and the variables to be optimized\nchange in the same timescale. If they change in different timescales, the problems turn out to\nbe functional optimization problems [7].\nAn optimization problem that ﬁnds a function to maximize or minimize an objective belongs\nAugust 12, 2020\nDRAFT\n3\nto functional optimization problems [6], which are quite common for optimal control problems\nbut are less familiar to the wireless community. When the timescale of the performance metric\nconcerned by a wireless policy is much longer than the timescale of the environment parameters\nthat the optimization depends on or the policy itself is in multi-timescale, which is often the\ncase in cross-layer design, the policy should be found from a functional optimization problem.\nIn general, the solutions of functional optimization problems can hardly be obtained in closed-\nform, which are usually obtained numerically. One of the widely applied numerical methods for\nsolving functional optimization problems is ﬁnite element method (FEM) [8]. As a mesh-based\nmethod, FEM suffers from the curse of dimensionality, especially in the multi-user scenarios in\nwireless networks, where the dimension increases with the number of users. To overcome the\ndifﬁculty in generating labels for training, unsupervised learning approach has been proposed to\nsolve functional optimization problems with statistical constraints recently [9].\nA. Related Works\nTwo branches of deep learning techniques have been proposed to solve the wireless optimiza-\ntion problems: supervised deep learning [5,10–12] and unsupervised deep learning [7,9,13].\nThe idea of “learning to optimize” was ﬁrst proposed for variable optimization problems by\nthe authors in [5], where approximated solutions were proved able to be obtained from fully-\nconnected DNNs. A deep learning framework was proposed in [10] to ﬁnd the relationship\nbetween ﬂow information and link usage by learning from past computation experience. To\nlearn the optimal predictive resource allocation under the QoS constraint of video streaming,\na DNN was designed and active learning was used to decrease the required labels in [11]. To\nimprove the approximation accuracy, a cascaded neural network was introduced to approximate\noptimal resource allocation policies and deep transfer learning was applied to ﬁne-tune the DNN\nin non-stationary wireless networks [12]. By training the DNNs ofﬂine, an approximated decision\ncan be obtained with low complexity online [5,10–12], say about 1% of the original numerical\noptimization [11]. Such an idea can be regarded as a kind of computing ofﬂoading over time,\nwhich shifts the computations from online to ofﬂine. However, two issues remain to resolve in\nthis approach of supervised learning: 1) the labels may be obtained in unaffordable complexity,\nwhich is especially true for functional optimization problems, and 2) the QoS violations caused\nby the approximation errors are not controlled, which makes the approach inapplicable for the\nwireless systems requiring stringent QoS such as URLLC.\nAugust 12, 2020\nDRAFT\n4\nTo ﬁnd the optimal policy without labeled training samples, unsupervised deep learning was\nintroduced in [14] to solve a variable optimization problem with maximal power constraint and\nproposed in [9,13] to solve functional optimization problems subject to statistic constraints. In\n[14], the previous two issues are circumvented by using the empirical average of the objective\nfunction of the optimization problem as the cost function for training a DNN and by selecting\na proper activation function in the output layer of the DNN. However, whether or not using the\nempirically averaged objective function as the cost function can give rise to the optimal solution\nwas not explained, and using activation function can only satisfy simple constraints such as\nmaximum or non-negative resource constraints. In [9], the primal-dual method was applied to\nmaximize and minimize the Lagrangian function of the constrained optimization problem in\nthe primal domain and the dual domain, respectively. In the primal domain, the optimal policy\nis approximated by a DNN. The parameters of the DNN and the Lagrangian multipliers, i.e.,\nthe optimization variable in the dual domain, are updated iteratively. The same method was\nintroduced to solve distributed optimization in [13]. By considering the original problems in its\ndual domain, complex constraints can be satisﬁed. However, the proposed method in [9,13] is\nonly applicable to the functional optimization problems with statistical constraints.\nWhen optimizing transmission policies in wireless communications, there exist both variable\noptimizations and functional optimizations, and exist both instantaneous constraints and statistic\nconstraints. A theoretic interpretation of why variable optimization problems can be learned\nwithout supervision remains unclear. While some resource constraints can be satisﬁed by choos-\ning proper activation functions [9], many (especially QoS) constraints are complex and hence\ncannot be satisﬁed by activation functions. How to guarantee instantaneous constraints with\nunsupervised deep learning remains an open problem.\nB. Motivation and Contributions\nIn this paper, we investigate how to establish a uniﬁed framework for learning to optimize\nboth variable and functional optimizations subject to both instantaneous and statistic constraints,\nand for solving functional optimizations subject to both types of constraints with unsupervised\ndeep learning.\nSince the QoS requirement in URLLC is complex and stringent, we take a downlink (DL)\nURLLC system as an example to show how to apply the proposed framework. In particular, we\nformulate two resource allocation problems with delay and reliability constraint. One is variable\nAugust 12, 2020\nDRAFT\n5\noptimization, where a BS allocates bandwidth according to large-scale channel gains. Another\nis a hybrid variable and functional optimization with both instantaneous and statistic constraints,\nwhere a BS jointly allocates bandwidth according to large-scale channel gains and transmit power\naccording to small-scale channel gains. The main contributions are summarized as follows.\n• We prove that the mapping from environment parameters to the solution of a constrained\nvariable optimization problem can be formulated as a proper functional optimization problem\nwith instantaneous constraints. Then, we develop a uniﬁed framework for using unsupervised\ndeep learning to ﬁnd the approximated optimal policy from both variable and functional\noptimization problems. Different from the method in [9, 13] that only considers statistic\nconstraints, both instantaneous and statistic constraints are considered in our framework.\n• We illustrate how to solve functional optimization problems with the bandwidth and power\nallocation problem in URLLC. We derive global optimal solution of the problem from\nits ﬁrst-order necessary conditions in a symmetric scenario, where the QoS requirements,\npacket arrival rates, and large-scale channel gains of all users are identical. Simulation and\nnumerical results show that performance achieved by the unsupervised learning is very close\nto that of the optimal policy, and is superior to supervised deep learning in terms of QoS\nguarantee and the policy approximation accuracy.\nThe rest of the paper is organized as follows. In Section II, we show how to convert a\nvariable optimization problem into a functional optimization problem and how to solve functional\noptimization problems subject to both instantaneous and statistic constraints with unsupervised\ndeep learning. In Section III, we consider two resource allocation problems in URLLC systems\nto illustrate how to use the proposed framework. Simulation and numerical results are provided\nin Section IV. We conclude this paper in Section V.\nII. UNSUPERVISED DEEP LEARNING FOR VARIABLE AND FUNCTIONAL OPTIMIZATIONS\nIn this section, we ﬁrst introduce the deﬁnitions of functional and functional optimization.\nThen, we prove that a constrained continuous variable optimization problem can be equiva-\nlently converted into a functional optimization problem with instantaneous constraints. Next,\nwe introduce functional optimization problem with statistic constraint in wireless networks\nby an example, the classical water-ﬁlling power control. Finally, we present a framework to\nsolve functional optimization problems with both instantaneous and statistic constraints using\nunsupervised deep learning.\nAugust 12, 2020\nDRAFT\n6\nA. Functional and Functional Optimization\nAccording to the deﬁnition in [15], a functional is a function of a function, which maps a\nfunction into a scalar. Functional is a kind of functions, where the “variable” itself is a function.\nA general type of functionals can be expressed as an integral of functions, say\nF[x(θ)] =\nZ\nθ∈Dθ\nF0 [x(θ); θ] dθ,\nwhere F[x(θ)] is a functional since its “variable” x(θ) is a function of θ, and F0 [x(θ); θ] is a\nfunction of two group of variables, a speciﬁc value of θ and the corresponding value of x(θ).\nAn optimization problem is a functional optimization problem if either the objective function\nor the constraint is a functional.\nB. Functional Optimization Problem with Instantaneous Constraints\nConsider a continuous variable optimization problem that ﬁnds a vector x ∈Dx ⊆RNx\nconsisting of Nx variables to minimize objective f (x; θ) under constraints Ci (x; θ),\nmin\nx\nf (x; θ)\n(1)\ns.t.\nCi (x; θ) ≤0, i = 1, ..., I,\n(1a)\nwhere θ ∈Dθ ⊆RNθ is a vector of Nθ environmental parameters, which is a realization of\ncontinuous random variables and is assumed known for optimization, Dθ is a compact set, and\nf (x; θ) and Ci (x; θ) are differentiable with respect to (w.r.t.) x and θ. Since the constraint\nx∈Dx can be considered as a special case of (1a), it is not listed explicitly.\nFor example, x is a beamforming vector, and θ is a channel vector that is known by estimation\nat the BS before optimizing beamforming. Another example is the predictive resource allocation\nproblem in [11], where x is a matrix composing of the fractions of bandwidth assigned to several\nmobile users in the frames of a prediction window, and θ is a matrix consisting of future average\ndata rates in the frames of these users that are known by prediction before the optimization. In\nmost of the cases, the closed-form optimal solution of problem (1) can hardly be obtained from\nthe Karush-Kuhn-Tucker (KKT) conditions. As a result, one needs to search for the optimal\nsolution numerically again whenever the value of θ changes and hence needs to be updated by\nestimation or prediction. For the example of beamforming, the update duration is the channel\ncoherence time. For the example in [11], the update duration is the duration of the prediction\nAugust 12, 2020\nDRAFT\n7\nwindow, within which the large scale channel gains (and hence the average data rates) may\nchange among frames. To facilitate practical use for wireless applications with fast changing\nenvironmental parameters, a promising approach is to ﬁnd the mapping from θ to the optimal\nsolution, i.e., ﬁnd the function x∗(θ). This can be obtained by supervised learning, where a\nDNN is used to approximate x∗(θ) and is trained with the labels generated by solving problem\n(1) for a large number of realizations of θ [5].\nTo avoid generating labels by solving a variable optimization problem, one can resort to\nunsupervised deep learning by using the objective function of the problem as the loss function\nfor training the DNN. Yet this is not straightforward since the objective function in (1) is a\nfunction of x and θ, rather than a function of the function to be optimized, i.e., x(θ).\nIn fact, the mapping from the environmental parameters to the optimal solution of problem (1)\ncan be found from a functional optimization problem. Then, the issue becomes: how to formulate\nsuch a functional optimization problem?\nIn order to ﬁnd the function x∗(θ), we construct the following functional optimization problem,\nmin\nx(θ)\nEθ {f [x(θ); θ]} =\nZ\nθ∈Dθ\nf [x(θ); θ] p(θ)dθ\n(2)\ns.t.\nCi [x(θ); θ] ≤0, ∀θ ∈Dθ, i = 1, ..., I,\n(2a)\nwhere x(θ) is optimized to minimize the expectation of the objective function in problem (1)\nover θ, and p(θ) is the probability density function (PDF) of θ. This is a functional optimization\nproblem since the objective function in (2) is a function of the function x(θ).\nThe constraints in problems (1) and (2) are not functionals, because the left-hand sides of\nthem only depend on the realizations of the random environment parameters θ. We refer to this\nkind of constraints as instantaneous constraints. For example, when the beamforming vector is\noptimized according to the channel vector known at a BS, the instantaneous data rate constraint\nor the transmit power constraint belongs to the instantaneous constraints.\nIt is worth noting that the constraints in the two problems are different. The constraints in (1a)\nneeds to be ensured for a speciﬁc realization of θ. As a result, the solution of problem (1) is\noptimal only for the given realization of θ. Once the value of θ varies, the problem needs to be\nsolved again. However, the constraints in (2a) should be satisﬁed for all the possible realizations\nof θ ∈Dθ. Therefore, the solution of problem (2), denoted by xopt(θ), is optimal for arbitrary\nrealization of θ. When the environment status changes, the optimal solution can be immediately\nAugust 12, 2020\nDRAFT\n8\nobtained from xopt(θ), and there is no need to solve the problem again.\nProposition 1. x∗(θ) is optimal for problem (2), and the value of xopt(θ) given arbitrary\nrealization of θ is optimal for problem (1) with probability one.\nThis proposition is proved in Appendix A. It indicates that a constrained continuous variable\noptimization problem can be equivalently converted into a functional optimization problem with\ninstantaneous constraints in the sense of almost surely ﬁnding the same mapping.\nC. Functional Optimization Problem with Statistic Constraints\nIf the timescale in a wireless application for measuring the system performance or the QoS\nis much longer than the update duration of the environment parameters for the optimization,\nor the timescales of the “variables” to be optimized differ, then the objective function or the\nconstraint will be a functional. To help understand, we re-visit the classic power control problem\n[16], which adjusts transmit power P(g) according to small-scale channel gain g. The goal is\nto maximize the ergodic capacity subject to the average transmit power constraint,\nmax\nP (g)\nEg\n\u001a\nWlog2\n\u0014\n1 + αgP (g)\nN0W\n\u0015\u001b\n=\nZ ∞\n0\nWlog2\n\u0014\n1 + αgP (g)\nN0W\n\u0015\np (g) dg,\n(3)\ns.t.\nZ ∞\n0\nP (g)p (g) dg ≤Pave,\n(3a)\nwhere W is the bandwidth, Pave is the maximal average transmit power, α is the large-scale\nchannel gain, p(g) is the PDF of the small-scale channel gain, and N0 is the single-side noise\nspectral density. This is a functional optimization problem, since both the objective and the\nconstraint are functional, which are measured in a timescale much longer than the update duration\nof the environment parameter for the optimization, i.e., channel coherence time.\nUnlike the instantaneous constraints in (1a) and (2a), the left-hand side of constraint in (3a)\nrelies on the distribution rather than a speciﬁc realization of the environmental parameter g.\nWe referred to the constraints depending on the distribution of θ as statistic constraints.\nD. A Framework of Solving Functional Optimization with Both Types of Constraints\nA functional optimization problem with I instantaneous constraints and J statistic constraints\ncan be expressed as follows,\nmin\nx(θ)\nEθ{f [x(θ), θ]}\n(4)\nAugust 12, 2020\nDRAFT\n9\ns.t.\nCi [x(θ), θ] ≤0, ∀θ ∈Dθ, i = 1, ..., I,\n(4a)\nEθ {Cj [x(θ), θ]} ≤0, j = I + 1, ..., I + J.\n(4b)\nTo ﬁnd the optimal solution of problem (4), we ﬁrst deﬁne the Lagrangian of the problem as\nL ≜\nZ\nθ∈Dθ\nf [x(θ), θ] p(θ)dθ +\nI\nX\ni=1\nZ\nθ∈Dθ\nvi(θ)Ci [x(θ), θ]p(θ)dθ +\nI+J\nX\nj=I+1\nλj\nZ\nθ∈Dθ\nCj [x(θ), θ]p(θ)dθ,\nwhere vi(θ) ≥0, ∀θ ∈Dθ, and λj ≥0 are the Lagrange multipliers. Noting that every Lagrange\nmultiplier related to each instantaneous constraint in (4a) is a function of θ, because the constraint\nshould be satisﬁed for all the possible values of θ.\n1) Theoretical Approach: The theory of calculus of variations in [6] indicates that the optimal\nsolution of problem (4) should satisfy the following conditions,\nδL\nδx(θ) = 0,\n(5)\nvi(θ)Ci [x(θ), θ] = 0, ∀θ ∈Dθ,\n(6)\nλjEθ {Cj [x(θ), θ]} = 0,\n(7)\nvi(θ) ≥0, ∀θ ∈Dθ, λj ≥0,\n(8)\n(4a), (4b), ∀θ ∈Dθ.\nFrom the deﬁnition of the Lagrangian, (5) can be derived as follows,\n(\n∂f [x(θ), θ]\n∂x(θ)\n+\nI\nX\ni=1\nvi(θ)∂Ci [x(θ), θ]\n∂x(θ)\n+\nI+J\nX\nj=I+1\nλj\n∂Cj [x(θ), θ]\n∂x(θ)\n)\np(θ) = 0, ∀θ ∈Dθ,\n(9)\nwhich is the simpliﬁed form of the Eular-Lagrange equation deﬁned in [6].\nThese conditions are the ﬁrst-order necessary conditions to achieve the optimality of functional\noptimization problems, like the KKT conditions of variable optimization problems [17]. However,\nthe condition in (7) is an integral equation, which comes from the statistic constraints. This makes\nsolving functional optimization problems rather challenging. In particular, even if the closed-form\nexpression of x(θ) can be obtained from (5), (6), (8), (4a) and (4b), the closed-form expressions\nof Lagrange multiplier for the statistic constraints λj, j = I +1, ..., I +J are hard to derive since\nintegral equations are in general difﬁcult to solve. For example, the optimal solution of problem\n(3) is the well-known “water-ﬁlling” policy, where the water level satisfying (7) and (4b) does\nAugust 12, 2020\nDRAFT\n10\nnot have closed-form expression and has to be obtained from binary search in [16]. On the other\nhand, if the closed-form expression of x(θ) cannot be obtained, one has to employ the FEM\nwith extremely high complexity for ﬁnding the numerical result of the integration in (7).\nIn what follows, we resort to unsupervised deep learning to solve problem (4).\n2) Learning Approach: To deal with the constraints of a problem, one can solve its primal-\ndual problem. In particular, if problem (4) is convex and the Slater’s condition holds, then it is\nequivalent to the following problem [6,17],\nmax\nvi(θ),λj min\nx(θ) L\n(10)\ns.t. (8)\nThe Slater’s condition generally holds in optimization problems with continues variables.\nHowever, the convexity does not hold in many cases. If the problem is non-convex, a local\noptimal solution of problem (4) can be obtained by solving problem (10) [18].\nTo ﬁnd the solution with unsupervised deep learning, we approximate the two functions in\nL, x(θ) and v(θ) ≜[v1(θ), ..., vI(θ)]T, by two DNNs denoted as Nx(θ; ωx) and Nv(θ; ωv)\nrespectively with model parameters ωx and ωv. According to the Universal Approximation\nTheory, a deterministic continuous function deﬁned over a compact set can be approximated\nby a DNN, and the approximation can be arbitrarily accurate [19]. By replacing x(θ) and v(θ)\nwith ˆx(θ)≜Nx(θ; ωx) and ˆv(θ)≜Nv(θ; ωv), problem (10) can be re-written as,\nmax\nωv,λj min\nωx\nˆL = Eθ\n(\nf [ˆx(θ), θ] +\nI\nX\ni=1\nˆvi(θ)Ci [ˆx(θ), θ] +\nI+J\nX\nj=I+1\nλj{Cj [ˆx(θ), θ]}\n)\n(11)\ns.t.\nˆvi(θ) ≥0, ∀θ ∈Dθ, λj ≥0.\n(11a)\nThen, the primal-dual method can be used to update primal variables ωx, dual variables ωv,\nand the Lagrange multiplier for statistical constraint λj iteratively to ﬁnd a solution of problem\n(11). At the tth iteration, these variables can be updated by the stochastic gradient descent (SGD)\nmethod and the stochastic gradient ascent (SGA) method as\nω(t+1)\nx\n= ω(t)\nx −φωx(t)∇ωx ˆL(t),\n(12)\nω(t+1)\nv\n= ω(t)\nv + φωv(t)∇ωv ˆL(t),\n(13)\nAugust 12, 2020\nDRAFT\n11\nλ(t+1)\nj\n=\n \nλ(t)\nj + φλj(t)∂ˆL(t)\n∂λj\n!+\n,\n(14)\nwhere (x)+ ≜max{x, 0} ensures λ(t+1)\nj\n> 0, φωx(t), φωv(t) and φλj(t) are the learning rates\nfor updating ωx, ωv and λj, and ∇ωx ˆL(t) and ∇ωv ˆL(t) are the gradients of ˆL w.r.t. ωx and ωv,\nrespectively.1 The method to compute the gradient and derivative is provided in Appendix B.\nTo guarantee ˆvi(θ) ≥0, ∀θ ∈Dθ, we need to choose a proper activation function in the output\nlayer of Nv(θ; ωv), e.g., ReLU(x) ≜max(x, 0) or SoftPlus(x) ≜ln[1 + exp(x)] [20,21].\nThe DNNs are trained by optimizing ωx, ωv, λj, j = I + 1, ..., I + J respectively with the\nSGD and SGA methods. As shown in [9], the primal-dual method converges at least to a local\noptimal solution of the primal-dual problem of the original problem. A local optimal solution is\neither at a stationary point of ˆL or on the boundary of the feasible region. Thus, the following\nproperties hold for the obtained solutions: ∇ωx ˆL = 0, ∇ωv ˆL = 0 (or ˆvi(θ) = 0) and ∂ˆL/∂λj = 0\n(or λj = 0), j = I + 1, ..., I + J. These properties implicitly serve as the “supervised signal” of\nthe DNNs. Since the DNNs are trained without labels, it belongs to unsupervised learning.\nIII. RESOURCE ALLOCATION WITH UNSUPERVISED LEARNING IN URLLC\nIn this section, we illustrate how to apply the framework presented in previous section. To\nthis end, we minimize the bandwidth required by satisfying the QoS of every user with URLLC\nby optimizing bandwidth allocation with or without dynamic power allocation.\nFor the policy without power allocation, the BS only allocates bandwidth among users accord-\ning to their large-scale channel gains, which is formulated as a variable optimization problem. For\nthe policy with power allocation, the BS also adjusts transmit power according to the small-scale\nchannel gains of the users, which is formulated as a hybrid variable and functional optimization\nproblem, where the “variables” are in two timescales.\nA. System Model and QoS Constraints\n1) System, Trafﬁc and Channel models: Consider a DL orthogonal frequency division multiple\naccess system, where a BS with Nt antennas serves K single-antenna users. The maximal\ntransmit power and the total bandwidth of the BS are denoted by Pmax and Wmax, respectively.\n1The gradient of a scalar x w.r.t. to a vector yNy×1 is deﬁned as ∇yx ≜[∂x/∂y1, ..., ∂x/∂yNy]T and the gradient of a\nvector xNx×1 w.r.t. to a vector yNy×1 is deﬁned as ∇yx ≜[∇yx1, ..., ∇yxNx].\nAugust 12, 2020\nDRAFT\n12\nThe packets for each user arrive at the buffer of the BS randomly. The inter-arrival time\nbetween packets could be shorter than the service time of each packet. Therefore, the packets\nmay wait in the buffer of the BS. We consider a queueing model that the packets for different\nusers wait in different queues and are served according to a ﬁrst-come-ﬁrst-serve order.\nTime is discretized into slots, each with duration Ts. The duration for DL data transmission in\none time slot is τ < Ts. Since the E2E delay requirement in URLLC is typically shorter than the\ncoherence time of small-scale channel, the channel is quasi-static and time diversity cannot be\nexploited. To improve the transmission reliability within the delay bound, we consider frequency\nhopping, where each user is assigned with different subchannels in adjacent slots. When the\nfrequency interval between adjacent subchannels is larger than the coherence bandwidth, the\nsmall-scale channel gains of a user among slots are mutual independent. Since the packet size\nu in URLLC is typically small (e.g., 20 bytes or 32 bytes [22]), the bandwidth required for\ntransmitting each packet is less than the channel coherence bandwidth. Therefore, the small-\nscale channel is ﬂat fading.\nAs shown in [16], the large-scale channel gain of a user varies when its moving distance is\ncomparable to the decorrelation distance of shadowing, i.e., 50 ∼100 m. Thus, the coherence\ntime of the large-scale channel gain is around a few seconds, much longer than the delay bound\nDmax and the slot duration Ts (e.g., in 5G New Radio, Ts can be much shorter than 1 ms [3]).\nWe assume that large-scale channel gains stay constant in each frame that consists of Nf time\nslots, and may vary in different frames. The relations among the timescales of the frames, slots,\nand the required delay bound are illustrated in Fig. 1.\n…\n…\nFrame\nSlot\nTime\n…\nRequired delay bound\nFig. 1. Large-scale channels change among frames, and small-scale channels change among time slots due to frequency hopping.\nIn URLLC, the blocklength of channel coding is short due to the short transmission duration,\nand hence the impact of decoding errors on reliability cannot be ignored. Since Shannon’s\ncapacity formula cannot be employed to characterize the probability of decoding errors [23],\nwe consider the achievable rate in ﬁnite blocklength regime. In quasi-static ﬂat fading channels,\nwhen small-scale channel gain is available at the transmitter and receiver, the achievable rate of\nAugust 12, 2020\nDRAFT\n13\nthe kth user can be accurately approximated by [24],\nsk ≈τWk\nu ln 2\n\"\nln\n\u0012\n1 + αkgkPk\nN0Wk\n\u0013\n−\nr\nVk\nτWk\nQ−1\nG (εc\nk)\n#\n( packets/slot),\n(15)\nwhere Wk and Pk are the bandwidth and the transmit power allocated to the kth user, respectively,\nεc\nk is the decoding error probability of the kth user, αk and gk are the large-scale channel gain\nand small-scale channel gain of the kth user, respectively, Q−1\nG (x) is the inverse of the Gaussian\nQ-function, and Vk is the channel dispersion given by Vk = 1 −\n1\nh\n1+ αkgkPk\nN0Wk\ni2 [24].\nAlthough the achievable rate is in closed-form, it is still too complicated to obtain graceful\nresults. As shown in [23], if the SNR αkgkPk\nN0Wk ≥5 dB, Vk ≈1 is accurate. Since high SNR is\nrequired to ensure ultra-high reliability and ultra-low latency, such approximation is reasonable.\nEven when the SNR is not high, we can obtain a lower bound of the achievable rate by\nsubstituting Vk ≈1 into sk. Then, the required εc can be satisﬁed if the lower bound of (15) is\nused to characterize the achievable rate.\n2) Reliability and Delay Constraints: The QoS requirement of each user can be characterized\nby an E2E delay bound Dmax for each packet and the overall packet loss probability εmax.\nThe uplink transmission delay, backhaul delay and processing delay have been studied in [25],\n[26] and [27], respectively, and can be subtracted from the E2E delay. In this paper, Dmax is the\nDL delay, which consists of the queueing delay (denoted as Dq\nk for the kth user), transmission\ndelay Dt (which equals to Ts, including the data transmission time τ and the channel training\ntime) and decoding delay Dc.\nDt and Dc are constant values depending on the standardization and hardware [28]. Due to the\nrandom packet arrival, Dq\nk is random. To ensure the delay requirement, Dq\nk should be bounded\nby Dq\nmax ≜Dmax−Dt−Dc with a very low probability, because a packet will be useless if the\nqueueing delay of the packet exceeds Dq\nmax.\nDenote εq\nk ≜Pr{Dq\nk > Dq\nmax} as the queueing delay violation probability. Then, the overall\nreliability requirement can be characterized by 1 −(1 −εc\nk)(1 −εq\nk) ≈εc\nk + εq\nk ≤εmax. This\napproximation is very accurate, because the values of εc and εq are very small in URLLC.\nEffective bandwidth and effective capacity have been widely used to analyze the tail probability\nof queueing delay, i.e., Dq\nmax is large or εq\nk is extremely small [29, 30]. As analyzed in [31],\nif the slot duration is much shorter than the delay bound, which is true in URLLC, effective\nbandwidth can be used to analyze the queueing delay at the BS for Poisson, interrupted Poisson\nAugust 12, 2020\nDRAFT\n14\nand switched Poisson arrival processes.\nWe take the Poisson arrival process with the average packet arrival rate ak packets/slot as an\nexample, whose effective bandwidth can be expressed as [31]\nBE\nk =\nln (εmax/2)\nDq\nmax ln\nh\n1 −ln (εmax/2)\nakDq\nmax\ni (packets/slot).\n(16)\nIf the constant packet service rate (i.e., the achievable rate) of the kth user is no less than BE\nk ,\nthen we have Pr{Dq\nk > Dq\nmax} ≤exp{−ϑkBE\nk Dq\nmax}, where ϑk is the QoS component, which\nreﬂects the decay rate of the tail probability of the queueing delay. By setting the upper bound\nin the inequity equals to εmax/2, we can obtain\nϑk = ln\n\u0014\n1 −ln (εmax/2)\nakDq\nmax\n\u0015\n.\n(17)\nSince the small-scale channel gains of a user are independent among slots owing to frequency\nhopping, the effective capacity of the kth user can be expressed as [32]\nCE\nk = −1\nϑk\nln Egk\n\b\ne−ϑksk\t\n(packets/slot).\n(18)\nWhen both the packet arrival process and the packet service process are stochastic, Dq\nmax and\nεq\nk can be satisﬁed if [33]\nCE\nk ≥BE\nk .\n(19)\nTo simplify the optimization problem, we set εc\nk = εq\nk = εmax/2. The results in [25, 31] show\nthat the optimal values of εc\nk and εq\nk are in the same order of magnitude, and the simpliﬁcation\nwill only lead to a negligible performance loss. Then, the QoS of each user, characterized by\nDmax and εmax, can be satisﬁed if (19) holds after substituting the expression of sk in (15) into\n(18). Such a QoS constraint is complicated and may not be expressed in closed-form.\nB. Bandwidth Allocation: A Variable Optimization Problem\nIn this subsection, we assume that the transmit power does not change according to small-\nscale channel gains, which is reasonable in practical cellular networks where modulation and\ncoding schemes are adjusted according to channel realizations with ﬁxed power allocation [34].\nWe optimize the bandwidth allocation policy according to the large-scale channel gains of users.\nHence, the environmental parameters can be expressed as θ = α≜[α1, · · ·, αK]T.\nAugust 12, 2020\nDRAFT\n15\n1) Problem Formulation: In particular, assume that P0 = Pmax/Wmax. Then, by substituting\nεc\nk =εmax/2 into (15), the achievable rate of the kth user can be re-written as follows,\nsk = τWk\nu ln 2\n\u0014\nln\n\u0012\n1+ αkgk\nN0\nP0\n\u0013\n−Q−1\nG (εmax/2)\n√τWk\n\u0015\n.\n(20)\nThe bandwidth allocation problem can be formulated as a variable optimization problem that\nminimizes the total bandwidth required to ensure the QoS of every user, i.e.,\nmin\nWk,k=1,...,K\nK\nX\nk=1\nWk\n(21)\ns.t.\nEgk\n\b\ne−ϑksk\t\n−e−ϑkBE\nk ≤0, k = 1, ..., K\n(21a)\nK\nX\nk=1\nWk ≤Wmax,\n(21b)\nWk ≥0, k = 1, ..., K,\nwhere (21a) is obtained by substituting (18) into (19), sk is given by (20), and Wmax is the\nmaximal total bandwidth.\nSince the left-hand side of the constraint in (21b) is the same as the objective function, we\ncan remove it when solving problem (21). If the minimal bandwidth required to guarantee the\nQoS requirement of every user exceeds Wmax, problem (21) will be infeasible. After removing\nthe constraint in (21b), the bandwidth allocation of every user is mutually independent among\neach other. Thus, problem (21) can be equivalently decomposed into K single-user problems,\nmin\nWk\nWk\n(22)\ns.t.\n(21a), Wk ≥0.\nIn the rest part of this subsection, the index k is omitted for notational simplicity.\n2) Optimizing W from the Variable Optimization Problem: To provide a baseline for the\nunsupervised deep learning method, we ﬁrst ﬁnd the optimal solution of problem in (22) for any\ngiven realizations of the environmental parameters.\nSince sk in (20) increases with W, the left-hand side of (21a) decreases with W, and the\nminimal bandwidth is obtained when the equality in (21a) holds. If effective capacity can be\nderived as a closed-form expression, say in large-scale antenna systems [35], then we can use\nbinary search to ﬁnd the minimal bandwidth. In general wireless systems, the effective capacity\nAugust 12, 2020\nDRAFT\n16\ndoes not have closed-form expression, and hence (21a) cannot be expressed in closed form. To\nﬁnd the optimal bandwidth allocated to each user, one can use stochastic optimization through\nthe following iterations,\nW (t+1) =\nh\nW (t) + φ(t)\n\u0010\ne−ϑs(t) −e−ϑBE\u0011i+\n,\n(23)\nwhere φ(t) > 0 is the learning rate, s(t) is the achievable rate computed from (20) given the\nrealization of g in the tth iteration, and one realization of g can be obtained in each slot. With\nφ(t)∼O\n\u0000 1\nt\n\u0001\n, {W (t)} converges to the unique optimal bandwidth [36] thanks to the monotonicity\nof the function of the left-hand side of (21a).\n3) Optimizing W(α) with Unsupervised Deep Learning: For the sake of learning to optimize\nproblem (22), we ﬁrst formulate a functional optimization problem of ﬁnding the mapping from\nα to the optimal solution of problem (22) as follows,\nmin\nW (α)\nEα {W(α)}\n(24)\ns.t.\nEg\n\b\ne−ϑs[W (α);α]\t\n−e−ϑBE ≤0,\n(24a)\nW(α) ≥0,\nwhere s[W(α); α]= τW (α)\nu ln 2\n\u0014\nln\n\u0010\n1+ αg\nN0P0\n\u0011\n−\nQ−1\nG (εmax/2)\n√\nτW (α)\n\u0015\nis the re-written expression of (20), and\n(24a) is an instantaneous constraint although it consists of expectation, because the expectation\nis taken over small-scale channel gains for a given realization of the environment parameter\nα. The constraint in (24a) is non-convex, hence problem (24) is non-convex. According to the\ndiscussion in Section II-D, a local optimal solution of problem (24) can be found by solving its\nprimal-dual problem,\nmax\nv(α) min\nW (α) L1 ≜Eα\nn\nW(α)+v(α)\n\u0010\nEg\n\b\ne−ϑs[W (α);α]\t\n−e−ϑBE\u0011o\n(25)\ns.t. W(α)≥0, v(α) > 0, ∀α > 0,\nwhere v(α) is the Lagrange multiplier function. The constraint W(α)≥0 and the corresponding\nLagrange multiplier are not included in L1, because the optimal bandwidth is always positive\nand the corresponding Lagrange multiplier is always zero.\nTo apply the framework in Section II-D to solve problem (25), we approximate the functions\nW(α) and v(α) by two DNNs, denoted as ˆW ≜NW (α; ωW) and ˆv≜Nv (α; ωv), respectively. By\nAugust 12, 2020\nDRAFT\n17\nusing appropriate activation function in the output layers of both DNNs, ˆW and ˆv are positive.\nThe model parameters of the DNNs, ωW and ωv, can be obtained iteratively as follows,\nω(t+1)\nW\n=ω(t)\nW −φωW (t)∇ωW ˆL(t)\n1 = ω(t)\nW −φωW (t)\nNb\nNb\nX\nn=1\n\"\n∇ωW NW\n\u0010\nα(t,n); ω(t)\nW\n\u0011 dˆL(t)\n1\nd ˆW (t,n)\n#\n,\n(26)\nω(t+1)\nv\n=ω(t)\nv +φωv(t)∇ωv ˆL(t)\n1 = ω(t)\nv + φωv(t)\nNb\nNb\nX\nn=1\n\"\n∇ωvNv\n\u0010\nα(t,n); ω(t)\nW\n\u0011 dˆL(t)\n1\ndˆv(t,n)\n#\n,\n(27)\nwhere ˆL(t)\n1 ≜\n1\nNb\nPNb\nn=1\nh\nˆW (t,n)+ˆv(t,n)\u0010\ne−ϑˆs(t,n)−e−ϑBE\u0011i\nis the estimated objective function in\n(25) with Nb realizations of large-scale channel gains while α(t,n) and ˆs(t,n) are respectively\nthe nth realizations of the large-scale channel gain and the achievable rate in the tth iteration,\nˆW (t,n) ≜NW\n\u0010\nα(t,n); ω(t)\nW\n\u0011\nand ˆv(t,n) ≜Nv\n\u0010\nα(t,n); ω(t)\nv\n\u0011\n. In (26) and (26), the derivative of ˆL(t)\n1\nw.r.t. ˆW (t,n) and ˆv(t,n) can be derived as follows,\ndˆL(t)\n1\nd ˆW (t,n) = 1 −ˆv(t,n)ϑ ∂ˆs(t,n)\n∂ˆW (t,n) e−ϑˆs(t,n),\ndˆL(t)\n1\ndˆv(t,n) = e−ϑˆs(t,n)−e−ϑBE,\nwhere the values of BE and ϑ are computed according to (16) and (17), respectively, and\n∂ˆs(t,n)\n∂ˆW (t,n) =\n1\nu ln 2\n\u0014\nτ ln\n\u0012\n1 + α(t,n)gP0\nN0\n\u0013\n−Q−1\nG (εmax/2)\n2\nr\nτ\nˆW (t,n)\n\u0015\n.\nThe gradient matrices ∇ωW NW\n\u0010\nα(t,n); ω(t)\nW\n\u0011\nand ∇ωvNv\n\u0010\nα(t,n); ω(t)\nv\n\u0011\ncan be computed by\nbackward propagation.\nAfter the iterations converge, we can obtain a well-trained DNN NW (α; ωW), which can\napproximate the optimal function of W(α). Then, the BS only needs to compute the bandwidth\nallocated to each user from NW (α; ωW) after obtaining the large-scale channel gain of each\nuser at the beginning of each frame.\nC. Bandwidth and Power Allocation: A Hybrid Variable and Functional Optimization Problem\nIn this subsection, we illustrate how to solve a functional optimization problem subject to both\ninstantaneous and statistic constraints. Although the BSs in the fourth generation cellular systems\ndo not adjust transmit power according to small-scale channel, the total bandwidth required by\nURLLC can be further reduced with dynamic power allocation. We optimize bandwidth allocation\naccording to the large-scale channel gains of multiple users (i.e., θ = α) and power allocation\naccording to their small-scale channel gains (i.e., θ = g) ≜[g1, · · ·, gK]T). Hence, the jointly\noptimized policy operates in two timescales.\nAugust 12, 2020\nDRAFT\n18\n1) Problem Formulation: To reﬂect the impact of the two-timescale resource allocation, we\nre-write the achievable rate of the kth user in (15) to satisfy εc\nk = εmax/2 as,\nsk[Wk, Pk(g); gk]= τWk\nu ln 2\n\u0014\nln\n\u0012\n1+ αkgkPk(g)\nN0Wk\n\u0013\n−Q−1\nG (εmax/2)\n√τWk\n\u0015\n.\n(28)\nThe problem of joint bandwidth and power allocation that minimizes the total bandwidth\nrequired to ensure the QoS under the constraint of maximal power Pmax can be formulated as,\nmin\nWk,Pk(g)\nK\nX\nk=1\nWk\n(29)\ns.t.\nEg\n\b\ne−ϑksk[Wk,Pk(g);gk]\t\n−e−ϑkBE\nk ≤0, k = 1, · · · , K\n(29a)\nK\nX\nk=1\nPk(g) ≤Pmax,\n(29b)\nWk ≥0, Pk(g) ≥0, k = 1, · · · , K.\n(29c)\nThe left-hand side of (29a) is a function of Pk(g), which measures the QoS requirement in each\nframe and depends on the distribution of environmental parameters g. Thus, (29a) are the statistic\nconstraints for the functional optimization. The constraints in (29b) and (29c) only depend on\nspeciﬁc realizations of environmental parameters, and hence are instantaneous constraints. The\ntotal bandwidth constraint is removed as explained in previous subsection. If the minimal total\nbandwidth is higher than Wmax, then the problem is infeasible.\nThis a generic functional optimization problem, including both functional optimization for\nPk(g) and variable optimization for Wk. In what follows, we apply the proposed framework to\nsolve this hybrid variable and functional optimization problem.\n2) Optimizing Wk and Pk(g) from Necessary Conditions: To provide a baseline for the\nlearning-based solution, we ﬁrst derive the optimal solution of problem (29) from the necessary\nconditions. To simplify the notation, in the sequel we again use sk to denote sk[Wk, Pk(g); gk]\nin (28).\nThe Lagrangian of problem (29) can be expressed as follows,\nL2 ≜\nK\nX\nk=1\nWk+\nK\nX\nk=1\nλk\n\u0010\nEg\n\b\ne−ϑksk\t\n−e−ϑkBE\nk\n\u0011\n+\nZ\nRK\n+\n\"\nh(g)\n K\nX\nk=1\nPk(g)−Pmax\n!\n−\nK\nX\nk=1\nvk(g)Pk(g)\n#\ndg\nwhere λk, h(g) and vk(g) are the Lagrange multipliers. Similar to the Lagrangian in (25), the\nconstraint Wk ≥0 and the corresponding Lagrange multiplier are omitted in L2.\nAugust 12, 2020\nDRAFT\n19\nThen, the optimal solution of problem (29) should satisfy its ﬁrst-order necessary conditions,\nwhich can be derived as [6],\n∂L2\n∂Pk(g) = h(g) −vk(g) −λkϑk\n∂sk\n∂Pk(g)e−ϑskp(g) = 0,\n(30)\n∂L2\n∂Wk\n= 1 −λkϑkEg\n\u001a ∂sk\n∂Wk\ne−ϑsk\n\u001b\n= 0,\n(31)\nλk\n\u0010\nEg\n\b\ne−ϑksk\t\n−e−ϑkBE\nk\n\u0011\n= 0,\n(32)\nh(g)\n K\nX\nk=1\nPk(g)−Pmax\n!\n= 0, ∀g ∈RK\n+,\n(33)\nvk(g)Pk(g) = 0, ∀g ∈RK\n+,\n(34)\nWk ≥0, λk ≥0, Pk(g) ≥0, h(g) ≥0, vk(g) ≥0, ∀g ∈RK\n+,\n(35)\n(29a) and (29b),\nwhere p(g) is the joint PDF of g.\nOptimal Power Allocation: From (30) and (28) we have\nh(g)=λkϑk\n∂sk\n∂Pk(g)e−ϑskp(g) + vk(g)\n=λkϑk\nτWk\nu ln 2\nαkgk\nN0Wk\n1\n(1+γk)e−ϑskp(g) + vk(g)\n=\nλkϑkαkgkτ\nN0u ln2 (1+γk)(1+γk)−ϑkτWk\nu ln2 e\nϑk\n√\nτWkQ−1\nG (εmax/2)\nu ln2\np(g) + vk(g)\n= βkgkp(g)\n(1+γk)\n1\nηk\n+ vk(g),\n(36)\nwhere γk ≜αkgkPk(g)\nN0Wk\nis the SNR of the kth user, βk ≜λkϑkαkτ\nN0u ln2 e\nϑk\n√\nτWkQ−1\nG (εmax/2)\nu ln2\n, and ηk ≜\n1/\n\u00001 + ϑkτWk\nu ln2\n\u0001\n.\nFrom (36), we can see that if h(g) > βkgkp(g) ≥βkgkp(g)/(1 + γk)1/ηk, then vk(g) > 0. To\nsatisfy the condition in (34), we have Pk(g)=0. In the case that h(g)<βkgkp(g), if Pk(g)=0,\nthen vk(g) will be negative, which contradicts with the constraint vk(g) ≥0 in (35). Thus, we\nhave Pk(g) > 0. To meet the constraint in (34), vk(g) = 0. It is not hard to see that when\nh(g)=βkgkp(g), the solution is Pk(g)=0 and vk(g)=0. Given the solutions in the above cases,\nAugust 12, 2020\nDRAFT\n20\nthe optimal power allocation policy can be expressed as,\nPk(g) = N0Wk\nαkgk\n\u0014\u0012\ngk\ngth\nk (g)\n\u0013ηk\n−1\n\u0015+\n,\n(37)\nwhere gth\nk (g) ≜\nh(g)\nβkp(g). Since the bandwidth required to guarantee the QoS of each user decreases\nwith the transmit power allocated to the user, the optimal solution of problem (29) is obtained\nwhen the equality in (29b) holds. Substituting (37) into PK\nk=1 Pk(g) = Pmax, we have\nK\nX\nk=1\nN0Wk\nαkgk\n\u0014\u0012\ngk\ngth\nk (g)\n\u0013ηk\n−1\n\u0015+\n=\nX\nk∈K+\nN0Wk\nαkgk\n\u0014\u0012\ngk\ngth\nk (g)\n\u0013ηk\n−1\n\u0015\n= Pmax,\n(38)\nwhere K+ denotes the set of users with positive transmit power. Since the values of ηk, k =\n1, · · ·, K, differ among users, gth\nk (g) can not be obtained in a closed-form expression.\nA Symmetric Case: When all users have identical large-scale channel gains (i.e., αk =α) and\nhave the same average packet arrival rate (i.e., ak = a, and hence ϑk = ϑ), Wk and ηk are\nidentical for different users (i.e., Wk = W and ηk =η). In this case, gth\nk (g)=gth(g), which can\nbe derived as follows,\ngth(g) =\n αPmax\nN0W +P\nk∈K+ gk−1\nP\nk∈K+ gkη−1\n!−1\nη\n.\n(39)\nSubstituting (39) into (37), we can derive the optimal power allocation policy as\nPk(g) = N0W\nαgk\n αgkPmax\nN0W\n+ gk\nP\nk∈K+ gi−1\ngk1−η P\nk∈K+ giη−1\n−1\n!+\n.\n(40)\nIt is worth noting that the elements in K+ and the function Pk(g) rely on each other. To ﬁnd\nthe solution, for each given realization of g we compute (40) and update K+ iteratively from\nthe initial user set K+\n0 = {1, 2,· · · , K}. According to the results of Pk(g) obtained from (40),\nthe users with negative transmit power are removed from K+. By repeating this procedure until\nPk(g)≥0 for all k∈K+, we can obtain the optimal power allocation policy.\nOptimal Bandwidth Allocation: Due to the expectation in (29a) and the complex expression\nof sk in (28), the optimal bandwidth allocation cannot be obtained in closed-form. The solution\ncan be found with stochastic optimization using the iteration formula in (23), where s(t)\nk\nis\nobtained by substituting the optimal power control policy in (40) into (28) (instead of (20) with\nP0 = Pmax/Wmax as in Section (III-B)).\nAugust 12, 2020\nDRAFT\n21\nRemark 1. Since the power allocation in (40) and the bandwidth allocation found with stochastic\noptimization yield the unique solution that satisﬁes the necessary conditions, the obtained solution\nis globally optimal to problem (29) in the symmetric scenario.\n3) Optimizing Wk and Pk(g) with Unsupervised Learning: Even in the symmetric scenario,\nthe optimal power allocation policy in (40) is not in closed-form. In general asymmetric cases,\nthe expression of gth\nk (g) cannot be derived from (38), and again there is no closed-form solution\nof Pk(g). To avoid to use high complexity numerical method such as FEM to ﬁnd the solution\nof the functional optimization for Pk(g), we apply the method in Section II-D to solve problem\n(29), i.e., we turn to solving the following problem,\nmax\nλk,h(g),vk(g)\nmin\nWk,Pk(g) L2\n(41)\ns.t. Pk(g)≥0, h(g)≥0, λk ≥0.\nWe approximate Pk(g) by NP(g; ωP), which is a DNN with model parameters ωP, input g,\nand output\nh\nˆP1(g; ωP), · · ·, ˆPK(g; ωP)\niT\n. In order not to lose any information during the forward\npropagation, the dimension of each hidden layer is set to be the number of users, which is the\nsame as the input and output dimensions. As mentioned before (38), the optimal solution of prob-\nlem (29) is obtained when the equality in (29b) holds. By applying Softmax function as the ac-\ntivation function in the output layer, we can guarantee that ˆPk(g; ωP) ≥0 and PK\nk=1 ˆPk(g; ωP) =\nPmax. Thereby, the term\nR\nRK\n+\nh\nh(g)\n\u0010PK\nk=1 Pk(g)−Pmax\n\u0011\n−PK\nk=1 vk(g)Pk(g)\ni\ndg can be removed\nfrom the Lagrangian, and the corresponding Lagrange multiplier functions h(g) and vk(g) can\nalso be removed. By replacing Pk(g) in (41) with ˆPk(g; ωP), the joint power and bandwidth\nallocation optimization problem then becomes,\nmax\nλk\nmin\nWk,ωP\nˆL2 ≜\nK\nX\nk=1\nh\nWk+λk\n\u0010\nEg\n\b\ne−ϑkˆsk\t\n−e−ϑkBE\nk\n\u0011i\n(42)\ns.t. λk ≥0,\nwhere ˆsk = τWk\nu ln2\n\u0014\nln\n\u0010\n1+ αkgk ˆPk(g;ωP )\nN0Wk\n\u0011\n−\nQ−1\nG (εc\nk)\n√τWk\n\u0015\n.\nThe model parameters of the DNN ωP, the allocated bandwidth Wk, k = 1, ..., K, and the\nLagrange multipliers λk, k = 1, ..., K can be obtained from the following iterations,\nω(t+1)\nP\n=ω(t)\nP −φωP (t)∇ωP ˆL(t)\n2 =ω(t)\nP −φωP (t)Pmax∇ωP N\n\u0010\ng; ω(t)\nP\n\u0011\n∇ˆ\nP ˆL(t)\n2 ,\n(43)\nAugust 12, 2020\nDRAFT\n22\nW (t+1)\nk\n=\n\"\nW (t)\nk −φW(t)∂ˆL(t)\n2\n∂Wk\n#+\n,\n(44)\nλ(t+1)\nk\n=\n\"\nλ(t)\nk +φλ(t)∂ˆL(t)\n2\n∂λk\n#+\n=\n\"\nλ(t)\nk +φλ(t) 1\nNb\nNb\nX\nn=1\n\u0010\ne−ϑkˆs(t,n)\nk\n−e−ϑkBE\nk\n\u0011#+\n,\n(45)\nwhere ˆL(t)\n2 ≜\n1\nNb\nPNb\nn=1\nPK\nk=1\nh\nWk+λk\n\u0010\ne−ϑkˆs(t,n)\nk\n−e−ϑkBE\nk\n\u0011i\n, ˆs(t,n)\nk\nis the nth realization of the\nachievable rate in the tth iteration, and Nb is number of realizations of small-scale channel gains\nin each iteration. The gradient matrix of the DNN w.r.t. the model parameters ∇ωP N\n\u0010\ng; ω(t)\nP\n\u0011\ncan be computed through backward propagation, and the gradient vector ∇ˆ\nP ˆL(t)\n2\nis with the\ndimension of K and the kth element of −1\nNb\nPNb\nn=1 λ(t)\nk ϑk\n∂ˆs(t,n)\nk\n∂ˆPk e−ϑkˆs(t,n)\nk\n.\nRemark 2. From (45), we can ﬁnd that the iteration converges only if\n1\nNb\nPNb\nn=1\n\u0010\ne−ϑkˆs(t,n)\nk\n−e−ϑkBE\nk\n\u0011\n→0. This means that the QoS requirement in (29a) can be ensured when the iterations converge,\nbecause the constraints are judiciously controlled by the unsupervised learning framework.\nRemark 3. For mobile users, ωP, Wk and λk, k = 1, ..., K need to be found again whenever their\nlarge-scale channel gains vary, say from the iterations in (43), (44) and (45) with random initial\nvalues. To accelerate convergence, we can employ pre-training, where the well-trained values\nof ωP, Wk and λk, k = 1, ..., K with ﬁxed user locations are used to initialize the iteration for\nre-training when the user locations change. Alternatively, we can also ﬁnd the mapping from all\nenvironment parameters to the bandwidth and power allocation by further converting the variable\noptimization for Wk into a functional optimization problem as in Section II-B.\nIV. SIMULATION RESULTS\nIn this section, we evaluate the performance achieved by the unsupervised deep learning\nwhen solving the variable and functional optimization problems in the previous section. For\nthe bandwidth allocation problem without power allocation, we compare the performance of\nunsupervised learning with supervised learning in terms of approximation accuracy of the policy\nsolution and the QoS violation. For the two-timescale bandwidth and power allocation problem,\nwe compare the unsupervised learning with the global optimal solution in the symmetric scenario,\nconsidering that obtaining the labels for supervised learning is prohibitive.\nWe consider multiple users in a cell with radius of 250 m. At the beginning of each slot, the\nsmall-scale channel gains of all the users are randomly generated from Rayleigh distribution.\nOther simulation parameters are listed in Table I, unless otherwise speciﬁed.\nAugust 12, 2020\nDRAFT\n23\nTABLE I\nSIMULATION PARAMETERS\nDuration of each slot Ts\n0.1 ms\nDuration of DL transmission τ\n0.05 ms\nTransmission delay Dt\n1 slot (0.1 ms) [28]\nDecoding delay Dc\n1 slot (0.1 ms) [28]\nOverall packet loss probability εmax\n10−5\nDL delay bound Dmax\n10 slots (1 ms)\nMaximal transmit power of BS Pmax\n43 dBm\nPath loss model −10 lg(α)\n35.3 + 37.6 lg(dk)\nNumber of antennas Nt\n8\nSingle-sided noise spectral density N0\n−173 dBm/Hz\nPacket size u\n20 bytes (160 bits)\n[22]\nAverage packet arrival rate a\n0.2 packets/slot\nWe apply fully-connected DNNs in learning algorithms, and use TanH in the input layer and\nthe hidden layers as an example activation function, where similar results can be obtained with\nother activation functions. The activation functions for the output layers will be introduced later.\nThe ﬁne-tuned batch size for learning is Nb=100.\nA. Bandwidth Allocation without Power Allocation\nThe users uniformly distributed along a road, which is with 50 m minimal distance away from\nthe BS. Since the bandwidth allocation without power allocation is independent for each user,\nwe only consider the bandwidth and QoS constraint of one user.\nThe two DNNs have six hidden layers, and each layer has 16 neurons. We use Softplus\nin the output layers in all DNNs to ensure that the outputs are positive. The learning rate is\nφ(t) = 0.5/(1+10−4t). To evaluate the performance of learning in terms of the approximation\naccuracy to the optimal policy and the QoS guarantee, we deﬁne the relative error of the learnt\nbandwidth allocation to the optimal solution as σ ≜\n\f\f\f ˆW(α)/W ∗(α)−1\n\f\f\f, and the QoS violation\nof the learnt solution as ν ≜\n\u0010\nEg\nn\neϑ(BE−ˆs)o\n−1\n\u0011+\n.\nIn Fig. 2, we show the complementary cumulative distributions (CCDF) of σ and ν achieved by\nthe unsupervised learning approach in Section III-B3, and those obtained by supervised learning\napproach where a DNN is used to learn the optimal policy W ∗(α) and is trained by taking the\noptimal solutions of problem in (22) as labels. The results are obtained through 100 trails, where\nAugust 12, 2020\nDRAFT\n24\nin each trail the NNs are trained through 10 000 iterations and are tested on 1 000 realizations of\nthe large-scale channel gains. It is shown that the unsupervised learning approach outperforms\nthe supervised learning approach. With unsupervised learning, the relative approximation error\nof the allocated bandwidth is less than 1% and the QoS violation probability is less than 2%\nwith a probability of 99.999%.\n10-4\n10-3\n10-2\n10-1\n10-5\n10-4\n10-3\n10-2\n10-1\n100\nFig. 2. Complementary cumulative distributions of the relative approximation error of ˆ\nW and the QoS violation.\nB. Joint Bandwidth and Power Allocation\nTo show the performance gap of the solution obtained with unsupervised learning from the\nglobal optimal solution, we ﬁrst consider a symmetric scenario, where all users are in the cell-\nedge, i.e., the user-BS distances are 250 m. Then, we evaluate the performance considering an\nasymmetric scenario, where the users are uniformly located in the road with 50 m minimal\ndistance away from the BS, i.e., the user-BS distances are distributed from 50 m to 250 m. The\nDNN has two hidden layers, and the number of neurons in each layer equals to the number of\nusers. We use Softmax in the output layer to ensure the maximum transmit power constraint\nand Pk(g)≥0 for all k=1, · · ·, K. The learning rate is set to be φ(t)=1/(1+0.1t), which turns\nout to be a good setting according to our experience.\nThe joint optimal policy (with legend “w MUD w FD”) is obtained from the method in\nSection III-C2 with around 200 iterations in the symmetric scenario, which exploits multi-user\ndiversity by dynamically adjusting the transmit power according the small-scale channel gains\nof users, and exploits frequency diversity by frequency hopping. The learning-based bandwidth\nand power allocation policy (with legend “w MUD w FD (NN)”) is obtained from the iterations\nAugust 12, 2020\nDRAFT\n25\nin (43), (44) and (45) with random initial values. In each slot, the channel realizations in recent\nNb slots are taken as a batch, which is used for 10 iterations in each slot. The training procedure\nconverges after 100 slots, unless otherwise speciﬁed.\nTo show the gain from multi-user diversity, we compare the joint optimal policy with the\noptimal bandwidth allocation policy obtained through (23) after sufﬁcient iterations, where\nthe transmit power is equally allocated in the frequency domain without exploiting multi-user\ndiversity (with legend “w/o MUD w FD”). To show the gain from frequency diversity, we\ncompare with a heuristic policy in [37], which also exploits multi-user diversity by scheduling\nthe users according to their small-scale channel gains but does not exploit frequency diversity\n(with legend “w MUD w/o FD”). Finally, we show the performance of the policy in [31] as a\nbaseline, which optimizes the bandwidth allocation, but exploits neither multi-user diversity nor\nfrequency diversity (with legend “w/o MUD w/o FD”).\n10\n20\n30\n40\n0\n5\n10\n15\n20\n25\n30\n(a) Symmetric scenario.\n10\n20\n30\n40\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n(b) Asymmetric scenario.\nFig. 3. Total bandwidth required to support the QoS of each user.\nIn Fig. 3(a), we provide the results in the symmetric scenario. It shows that the performance of\nlearning-based policy (i.e., “w MUD w FD (NN)”) is almost the same as the global optimal policy\nderived in (40) (i.e., “w MUD w FD”). In Fig. 3(b), we provide the results in the asymmetric\nscenario, where only the learning-based policy is simulated since the optimal solution is not\navailable in this scenario. From both scenarios we can see that exploiting multi-user diversity\nor frequency diversity individually can signiﬁcantly improve the bandwidth efﬁciency, while the\nAugust 12, 2020\nDRAFT\n26\ngain from frequency diversity is larger. Once the frequency diversity is exploited, multi-user\ndiversity only provides marginal performance gain.\nTo show the convergency of the learning-based solution, we consider the sum of the absolute\nvalues of average gradients ζ(t) ≜\n\r\r\rEg\nn\n∇ωP ˆL(t)o\r\r\r\n1+PK\nk=1\n\f\f\fEg\nn\n∂ˆL(t)\n∂Wk\no\f\f\f+PK\nk=1\n\f\f\fEg\nn\n∂ˆL(t)\n∂λk\no\f\f\f and\nthe QoS constraint violation ξ(t) ≜PK\nk=1\n\u0014\nEg\n\u001a\ne\nϑk\n\u0010\nBE\nk −ˆs(t)\nk\n\u0011\u001b\n−1\n\u0015+.\nK. The training algorithm in\n(43), (44) and (45) is considered to be converged at the tth slot if ζ(t) <1% and ξ(t) <1%.\nTABLE II\nNUMBER OF TIME SLOTS FOR CONVERGENCE, ASYMMETRIC SCENARIO, Ts = 0.1 MILLISECONDS\nConvergence percentage\n99.9%\n99.99%\nw/o pre-training\n5 000\n>10 000\nw pre-training\n3\n1 000\nThe convergence speeds with and without pre-training are shown in Table II, which are\nobtained from 100 000 trails. For the results without pre-training, 40 users are randomly dropped\nin the road in each trail and the realizations of their large- and small-scale channel gains are\nused to train ωP, Wk and λk, k = 1, · · ·, K, with random initializations. For the results with\npre-training, all users move at the velocity of 72 kph along the road in the same direction.\nThe well-trained values of ωP, Wk and λk, k = 1, · · ·, K, are ﬁne-tuned every 0.1 s using the\nchannels at the new locations. Without pre-training, 10 000 time slots (i.e., 1 s) are required to\nachieve 99.99% convergence percentage, i.e., the QoS of each user is ensured with a probability\nof 99.99% according to Remark 2. We can see that the pre-training, which can be accomplished\noff-line, shortens the convergence time signiﬁcantly. The complexity of the training is low. A\ncomputer with Intel® Core™i7-6700 CPU is able to ﬁnish around 1 000 iterations in 0.1 s\nwithout using the acceleration from GPU.\nV. CONCLUSION\nIn this paper, we proved that the problem of ﬁnding the mapping from environment parameters\nto the solutions of constrained variable optimizations can be formulated as functional opti-\nmizations with instantaneous constraints, and established a uniﬁed unsupervised deep learning\nframework to solve functional optimizations with both instantaneous and statistic constraints.\nWe considered two example problems in downlink URLLC to illustrate how to apply this\nframework. The ﬁrst problem is variable optimization, where bandwidth allocation is optimized\nAugust 12, 2020\nDRAFT\n27\naccording to large-scale channel gains. The second problem is a hybrid variable and functional\noptimization with two types of constraints, where we jointly optimized bandwidth allocation\naccording to large-scale channel gains and power allocation according to small-scale channel\ngains. Simulations results showed that, for the bandwidth allocation problem, unsupervised\nlearning is superior to the supervised learning in both the accuracy of approximating the optimal\nsolution and the guarantee of the QoS constraint. For the joint bandwidth allocation and power\nallocation problem, the learning-based solution performs almost the same as the global optimal\nsolution in a symmetric scenario. For both problems, the QoS achieved by the solution using\nunsupervised learning can be guaranteed with very high probability. The training algorithm\nconverges rapidly with pre-training, and is with low computational complexity. As a byproduct,\nthe optimization results also showed that the bandwidth utilization efﬁciency of URLLC can be\nimproved more signiﬁcantly by exploiting frequency diversity than by multi-user diversity.\nAPPENDIX A\nPROOF OF PROPOSITION 1\nProof. We ﬁrst prove that x∗(θ) is optimal for problem (2). Denote x∗(θ1) as an optimal solution\nof problem (1) given an arbitrary realization θ1∈Dθ, and denote the objective function in problem\n(2) as F [x(θ)]≜\nR\nθ∈Dθ f [x(θ); θ] p(θ)dθ. Let x1(θ), θ∈Dθ be an arbitrary feasible solution of\nproblem (2). Since problems (1) and (2) have the same constraints, they have the same feasible\nregion. Thus, x1(θ1) is a feasible solution of problem (1). Given the realization θ1, the optimal\nsolution of problem (1) is better than any feasible solutions of problem (1), i.e.,\nf [x∗(θ1); θ1] −f [x1(θ1); θ1] ≤0, ∀θ1 ∈Dθ.\n(A.1)\nSince p(θ)≥0, we further have,\nF [x∗(θ)] −F [x0(θ)] =\nZ\nθ∈Dθ\n[f [x∗(θ); θ] −f [x0(θ); θ]] p(θ)dθ ≤0.\n(A.2)\nSince x∗(θ), θ ∈Dθ, satisﬁes all the constraints in problem (2), it is a feasible solution of\nproblem (2). (A.2) indicates that x∗(θ), θ ∈Dθ is better than an arbitrary solution of problem\n(2). Thus, it is optimal for problem (2).\nIn what follows, we prove that the value of xopt(θ) for arbitrary realization of θ is optimal\nAugust 12, 2020\nDRAFT\n28\nfor problem (1) with probability one. From the deﬁnition of xopt(θ) and x∗(θ), we have\nf [xopt(θ); θ] −f [x∗(θ), θ] ≥0, ∀θ ∈Dθ.\n(A.3)\nSuppose there exists a non-zero measure set, D+\nθ , such that for any θ′ ∈D+\nθ , xopt(θ′) is not\noptimal for problem (1). In other words, there exists a δ0 such that\nf [xopt(θ′); θ′] −f [x∗(θ′), θ′] ≥δ0 > 0, ∀θ′ ∈D+\nθ .\n(A.4)\nHere, a non-zero measure set is a set that Pr{θ′ ∈D+\nθ } > 0.\nFrom (A.3) and (A.4), we can derive that\nF [xopt(θ)] −F [x∗(θ)]\n=\nZ\nθ∈Dθ\n[f [xopt(θ); θ] −f [x∗(θ), θ]] p(θ)dθ\n≥\nZ\nθ∈D+\nθ\n[f [xopt(θ); θ] −f [x∗(θ), θ]] p(θ)dθ\n≥\nZ\nθ∈D+\nθ\nδ0p(θ)dθ\n= δ0 Pr{θ ∈D+\nθ } > 0.\n(A.5)\nThis contradicts with the fact that xopt(θ) is the optimal solution of problem (2).\nThis completes the proof.\nAPPENDIX B\nTHE METHOD TO COMPUTE (12), (13) AND (14)\nProof. For notational simplicity, we omitted the index of iteration t in this appendix. To compute\n(12), (13) and (14), we only need to compute ∇ωx ˆL, ∇ωv ˆL and ∂ˆL/∂λj.\nThe value of ∇ωx ˆL can be obtained from the following expression,\n∇ωx ˆL =\nZ\nθ∈Dθ\n[∇ωx ˆx(θ)]\n\u0002\n∇ˆx(θ)f (ˆx(θ); θ)\n\u0003\np (θ) dθ\n+\nJ\nX\nj=I+1\nλj\nZ\nθ∈Dθ\n[∇ωx ˆx(θ)]\n\u0002\n∇ˆx(θ)Cj (ˆx(θ); θ)\n\u0003\np (θ) dθ\n+\nI\nX\ni=1\nZ\nθ∈Dθ\nˆλj (θ) [∇ωx ˆx(θ)]\n\u0002\n∇ˆx(θ)Ci (ˆx(θ); θ)\n\u0003\ndθ,\n(B.1)\nAugust 12, 2020\nDRAFT\n29\nwhere ∇ωx ˆx(θ) ≜[∇ωxˆx1(θ), ..., ∇ωxˆxNx(θ)] can be obtained via backward propagation.\nThe values of ∇ωv ˆL and ∂ˆL/∂λj can be obtained from\n∇ωv ˆL =\nI\nX\ni=1\nZ\nθ∈Dθ\n[∇ωv ˆvi(θ)] [Ci (ˆx(θ); θ)] dθ,\n(B.2)\n∂ˆL\n∂λj\n=\nZ\nθ∈Dθ\nCj (ˆx(θ); θ) p (θ) dθ,\n(B.3)\nwhere ∇ωλ ˆλi(θ), i = 1, ..., I, can be obtained via backward propagation.\nREFERENCES\n[1] C. Sun and C. Yang, “Unsupervised deep learning for ultra-reliable and low-latency communications,” in Proc. IEEE\nGlobecom, 2019.\n[2] ——, “Learning to optimize with unsupervised learning: Training deep neural networks for URLLC,” in Proc. IEEE\nPIMRC, 2019.\n[3] 3GPP, “Study on New Radio (NR) access technology; physical layer aspects (Release 14),” 3GPP, TR 38.802, 2017, v2.0.0.\n[4] C. She, R. Dong, Z. Gu, Z. Hou, Y. Li, W. Hardjawana, C. Yang, L. Song, and B. Vucetic, “Deep learning for ultra-reliable\nand low-latency communications in 6G networks,” IEEE Network, accepted, 2020.\n[5] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos, “Learning to optimize: Training deep neural networks\nfor interference management,” IEEE Trans. on Signal Proc., vol. 66, no. 20, pp. 5348–5453, Oct. 2018.\n[6] J. Gregory, Constrained optimization in the calculus of variations and optimal control theory.\nChapman and Hall/CRC,\n2018.\n[7] D. Liu, C. Sun, C. Yang, and L. Hanzo, “Optimizing wireless systems using unsupervised and reinforced-unsupervised\ndeep learning,” IEEE Network, vol. 34, no. 4, pp. 270–277, July 2020.\n[8] O. C. Zienkiewicz, R. L. Taylor, P. Nithiarasu, and J. Zhu, The ﬁnite element method.\nMcGraw-hill London, 1977, vol. 3.\n[9] M. Eisen, C. Zhang, L. F. O. Chamon, D. D. Lee, and A. Ribeiro, “Learning optimal resource allocations in wireless\nsystems,” IEEE Trans. Signal Process., vol. 67, no. 10, pp. 2775–2790, May 2019.\n[10] L. Liu, B. Yin, S. Zhang, X. Cao, and Y. Cheng, “Deep learning meets wireless network optimization: Identify critical\nlinks,” IEEE Transactions on Network Science and Engineering, vol. 7, no. 1, pp. 167–180, 2020.\n[11] J. Guo and C. Yang, “Predictive resource allocation with deep learning,” in Proc. IEEE VTC Fall, 2018.\n[12] R. Dong, C. She, W. Hardjawana, Y. Li, and B. Vucetic, “Deep learning for radio resource allocation with diverse\nquality-of-service requirements in 5G,” IEEE Trans. Wireless Commun., minor revision, 2020. [Online]. Available:\nhttps://arxiv.org/pdf/2004.00507.pdf\n[13] H. Lee, S. H. Lee, and T. Q. S. Quek, “Deep learning for distributed optimization: Applications to wireless resource\nmanagement,” IEEE J. Sel. Areas Commun., vol. 37, no. 10, pp. 2251–2266, 2019.\n[14] W. Cui, S. Kaiming, and W. Yu, “Spatial deep learning for wireless scheduling,” IEEE J. Sel. Areas Commun., vol. 37,\nno. 6, pp. 1248–1261, June 2019.\n[15] D. Liberzon, Calculus of Variations and Optimal Control Theory: A Concise Introduction.\nPrinceton University Press,\n2012.\n[16] A. Goldsmith, Wireless Communications.\nCambridge University Press, 2005.\nAugust 12, 2020\nDRAFT\n30\n[17] S. Boyd and L. Vandanberghe, Convex Optimization.\nCambridge University Press, 2004.\n[18] D. G. Luenberger, Optimization by vector space methods.\nJohn Wiley & Sons, 1997.\n[19] K. Hornik, M. B. Stinchcombe, and H. White, “Multilayer feedforward networks are universal approximators,” Neural\nNetworks, vol. 2, no. 5, pp. 359–366, 1989.\n[20] V. Nair and G. E. Hinton, “Rectiﬁed linear units improve restricted boltzmann machines,” in Proc. ICML, 2010, pp.\n807–814.\n[21] X. Glorot, A. Bordes, and Y. Bengio, “Deep sparse rectiﬁer neural networks,” in Proc. AISTATS, 2011, pp. 315–323.\n[22] 3GPP, Study on Scenarios and Requirements for Next Generation Access Technologies.\nTechnical Speciﬁcation Group\nRadio Access Network, Technical Report 38.913, Release 14, Oct. 2016.\n[23] S. Schiessl, J. Gross, and H. Al-Zubaidy, “Delay analysis for wireless fading channels with ﬁnite blocklength channel\ncoding,” in Proc. ACM MSWiM, 2015, pp. 13–22. [Online]. Available: https://doi.org/10.1145/2811587.2811596\n[24] W. Yang, G. Durisi, T. Koch, and Y. Polyanskiy, “Quasi-static multiple-antenna fading channels at ﬁnite blocklength,”\nIEEE Trans. Inf. Theory, vol. 60, no. 7, pp. 4232–4264, Jul. 2014.\n[25] C. She, C. Yang, and T. Q. S. Quek, “Joint uplink and downlink resource conﬁguration for ultra-reliable and low-latency\ncommunications,” IEEE Trans. Commun., vol. 66, no. 5, pp. 2266–2280, May 2018.\n[26] G. Zhang, T. Q. S. Quek, M. Kountouris, et al., “Fundamentals of heterogeneous backhaul design—analysis and\noptimization,” IEEE Trans. Commun., vol. 64, no. 2, pp. 876–889, Feb. 2016.\n[27] B. Makki, T. Svensson, G. Caire, and M. Zorzi, “Fast HARQ over ﬁnite blocklength codes: A technique for low-latency\nreliable communication,” IEEE Trans. Wireless Commun., vol. 18, no. 1, pp. 194–209, Jan 2019.\n[28] M. Condoluci, T. Mahmoodi, E. Steinbach, and M. Dohler, “Soft resource reservation for low-delayed teleoperation over\nmobile networks,” IEEE Access, vol. 5, pp. 10 445–10 455, May 2017.\n[29] C. Chang and J. A. Thomas, “Effective bandwidth in high-speed digital networks,” IEEE J. Sel. Areas Commun., vol. 13,\nno. 6, pp. 1091–1100, Aug. 1995.\n[30] D. Wu and R. Negi, “Effective capacity: A wireless link model for support of quality of service,” IEEE Trans. Wireless\nCommun., vol. 2, no. 4, pp. 630–643, July 2003.\n[31] C. She, C. Yang, and T. Q. S. Quek, “Cross-layer optimization for ultra-reliable and low-latency radio access networks,”\nIEEE Trans. Wireless Commun., vol. 17, no. 1, pp. 127–141, Jan 2018.\n[32] J. Tang and X. Zhang, “Quality-of-service driven power and rate adaptation over wireless links,” IEEE Trans. Wireless\nCommun., vol. 6, no. 8, pp. 3058–3068, August 2007.\n[33] L. Liu, P. Parag, J. Tang, W. Y. Chen, and J. F. Chamberland, “Resource allocation and quality of service evaluation for\nwireless communication systems using ﬂuid models,” IEEE Trans. on Inf. Theory, vol. 53, no. 5, pp. 1767–1777, May\n2007.\n[34] 3GPP, LTE; E-UTRA; Physical layer procedures.\nTS 36.213 v. 8.8.0 Release 8, Oct. 2009.\n[35] C. She, C. Yang, and L. Liu, “Energy-efﬁcient resource allocation for MIMO-OFDM systems serving random sources with\nstatistical QoS requirement,” IEEE Trans. Commun., vol. 63, no. 11, pp. 4125–4141, Nov 2015.\n[36] L.\nBottou,\n“Online\nalgorithms\nand\nstochastic\napproximations,”\nin\nOnline\nLearning\nand\nNeural\nNetworks,\nD. Saad,\nEd.\nCambridge,\nUK: Cambridge\nUniversity Press, 1998,\nrevised,\nOct. 2012.\n[Online]. Available:\nhttp://leon.bottou.org/papers/bottou-98x\n[37] C. Sun, C. She, and C. Yang, “Exploiting multi-user diversity for ultra-reliable and low-latency communications,” in Proc.\nIEEE Globecom Workshops, 2017.\nAugust 12, 2020\nDRAFT\n",
  "categories": [
    "cs.IT",
    "cs.LG",
    "eess.SP",
    "math.IT"
  ],
  "published": "2020-05-30",
  "updated": "2020-08-11"
}