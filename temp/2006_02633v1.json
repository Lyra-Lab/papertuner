{
  "id": "http://arxiv.org/abs/2006.02633v1",
  "title": "Stopwords in Technical Language Processing",
  "authors": [
    "Serhad Sarica",
    "Jianxi Luo"
  ],
  "abstract": "There are increasingly applications of natural language processing techniques\nfor information retrieval, indexing and topic modelling in the engineering\ncontexts. A standard component of such tasks is the removal of stopwords, which\nare uninformative components of the data. While researchers use readily\navailable stopword lists which are derived for general English language, the\ntechnical jargon of engineering fields contains their own highly frequent and\nuninformative words and there exists no standard stopword list for technical\nlanguage processing applications. Here we address this gap by rigorously\nidentifying generic, insignificant, uninformative stopwords in engineering\ntexts beyond the stopwords in general texts, based on the synthesis of\nalternative data-driven approaches, and curating a stopword list ready for\ntechnical language processing applications.",
  "text": "arXiv:2006.02633v1  [cs.IR]  4 Jun 2020\nSTOPWORDS IN TECHNICAL LANGUAGE PROCESSING\nA PREPRINT\nSerhad Sarica\nData-Driven Innovation Lab\nSingapore University of Technology and Design\nSingapore, 487372\nserhad_sarica@mymail.sutd.edu.sg\nJianxi Luo\nData-Driven Innovation Lab\nSingapore University of Technology and Design\nSingapore, 487372\nluo@sutd.edu.sg\nJune 5, 2020\nABSTRACT\nThere are increasingly applications of natural language processing techniques for information re-\ntrieval, indexing and topic modelling in the engineering contexts. A standard component of such\ntasks is the removal of stopwords, which are uninformative components of the data. While re-\nsearchers use readily available stopwords lists which are derived for general English language, the\ntechnical jargon of engineering ﬁelds contains their own highly frequent and uninformative words\nand there exists no standard stopwords list for technical language processing applications. Here we\naddress this gap by rigorously identifying generic, insigniﬁcant, uninformative stopwords in engi-\nneering texts beyond the stopwords in general texts, based on the synthesis of alternative data-driven\napproaches, and curating a stopwords list ready for technical language processing applications.\nKeywords Stopwords · Technical language · Data-driven\n1\nIntroduction\nNatural language processing (NLP) and text analysis have been growingly popular in engineering analytics [1, 2, 3, 4].\nTo ensure the accuracy and efﬁciency of such NLP tasks as indexing, topic modelling and information retrieval [5,\n6, 7, 8, 9], the uninformative words, often referred to as “stopwords”, need to be removed in the pre-processing step,\nin order to increase signal-to-noise ratio in the unstructured text data. Example stopwords include ”each”, ”about”,\n”such” and ”the”. Stopwords often appear frequently in many different natural language documents or parts of the text\nin a document but carry little information about the part of the text they belong to.\nThe use of a standard stopword list, such as the one distributed with popular Natural Language Tool Kit (NLTK) [10]\npython package, for removal in data pre-processing has become an NLP standard in both research and industry. There\nhave been efforts to identify stopwords from generic knowledge sources such as Brown Corpus [8, 11], 20 newsgroup\ncorpus [6], books corpus [12], etc, and curate a generic stopword list for removal in NLP applications across ﬁelds.\nHowever, the technical language used in engineering or technical texts is different from layman languages and may\nuse stopwords that are less prevalent in layperson languages. When it comes to engineering or technical text analysis,\nresearchers and engineers either just adopt the readily available generic stopword lists for removal [1, 2, 3, 4] leaving\nmany noises in the data or identify additional stopwords in a manual, ad hoc or heuristic manner [5, 13, 14, 15]. There\nexist no standard stopword list for technical language processing applications.\nHere, we address this gap by rigorously identifying generic, insigniﬁcant, uninformative stopwords in engineering\ntexts beyond the stopwords in general texts, based on the synthesis of alternative data-driven approaches. The re-\nsultant stopword list is statistically identiﬁed and human-evaluated. Researchers, analysts and engineers working on\ntechnology-related textual data and technical language analysis can directly apply it for denoising and ﬁltering of their\ntechnical textual data, without conducting the manual and ad hoc discovery and removal of uninformative words by\nthemselves.\nA PREPRINT - JUNE 5, 2020\n2\nOur approach\nTo identify stopwords in technical language texts, we statistically analyse the natural texts in patent documents which\nare descriptions of technologies at all levels. The patent database is vast and provides the most comprehensive coverage\nof technological domains. Speciﬁcally, our patent text corpus contains 781,156,082 tokens (words, bi-, tri- and four-\ngrams) from 30,265,976 sentences of the titles and abstracts of 6,559,305 of utility patents in the complete USPTO\npatent database from 1976 to 31st December 2019 (access date: 23 March 2020). Non-technical design patents\nare excluded. Technical description ﬁelds are avoided because they include information on contexts, backgrounds\nand prior arts that may be non-relevant to the speciﬁc invention and repetitive, lead to statistical bias and increase\ncomputational requirements. We also avoided legal claim sections which are written in repetitive, disguising and legal\nterms.\nIn general text analysis for topic modelling or information retrieval, various statistical metrics, such as term frequency\n(TF) [7, 9], inverse-document frequency (IDF) [7], term-frequency-inverse-document-frequency (TFIDF) [5], entropy\n[6, 12], information content [6], information gain [16] and Kullback-Leibler (KL) divergence [7], are employed to sort\nthe words in a corpus [6, 16]. Herein we use TF, TFIDF and information entropy to automatically identify candidate\nstopwords.\nFurthermore, some of the technically signiﬁcant terms such as “composite wall”, “driving motion” and “hose adapter”\nare statistically indistinguishable from such stopwords “be”, “and” and “for”, regardless of the statistic metrics for\nsorting. That is, automatic and data-driven methods by themselves are not accurate and reliable enough to return\nstopwords. Therefore, we also use a human-reliant step to further evaluate the automatically identiﬁed candidate\nstopwords and conﬁrm a ﬁnal set of stopwords which do not carry information on engineering and technology.\nIn brief, the overall procedure as depicted in Figure 1 consists of three major steps: 1) basic pre-processing of the patent\nnatural texts, including punctuation removal, lower-casing, phrase detection and lemmatization; 2) using multiple\nstatistic metrics from NLP and information theory to identify a ranked list of candidate stopwords; 3) term-by-term\nevaluation by human experts on their insigniﬁcance for technical texts to conﬁrm stopwords that are uninformative\nabout engineering and technology. In the following, we describe implementation details of these three steps.\nFigure 1: Overall procedure\n3\nImplementation\n3.1\nPre-processing\nThe patent texts in the corpus are ﬁrst transformed into a line-sentence format, utilizing the sentence tokeniza-\ntion method in the NLTK, and normalized to lowercase letters to avoid additional vocabulary caused by lower-\ncase/uppercase differences of the same words. The punctuation marks in sentences are removed except “-” and “/”.\nThese two special characters are frequently used in word-tuples, such as “AC/DC” and “inter-link”, which can be\nregarded as a single term. The original raw texts are transformed into a collection of 30,265,976 sentences, including\n796,953,246 unigrams.\n2\nA PREPRINT - JUNE 5, 2020\nPhrases are detected with the algorithm of Mikolov et al [17] that ﬁnds words that frequently appear together, and in\nother contexts infrequently, by using a simple statistical method based on the count of words to give a score to each\nbigram such that:\nscore(wi, wj) = (count(wiwj) −δ)|N|\ncount(wi)count(wj)\n(1)\nwhere count(wiwj) is the count of wi and wj appearing together as bigrams in the collection of sentences and\ncount(wi) is the count of wi in the collection of sentences. δ is the discounting coefﬁcient to prevent too many\nphrases consisting of very infrequent words, and set δ = 1 to prevent having scores higher than 0 for phrases occur-\nring less than twice. The term N =\nP\nt,p∈P\nn(t, p) represents the total number of tokens in the patent database where\nn(t, p) is the count of the term t in the patent p. Bigrams with a score over a deﬁned threshold (Tphrase) are considered\nas phrases and joined with a “_” character in the corpus, to be treated as a single term. We run the phrasing algorithm\nof Mikolov et al. [17] on the pre-processed corpus twice to detect n-grams, where n = [2,4]. The ﬁrst run detects\nonly bigrams by employing a higher threshold value T 1\nphrase, while the second run can detect n-grams up to n = 4 by\nusing a lower threshold value T 2\nphrase to enable combinations of bigrams. Via this procedure of repeating the phrasing\nprocess with decreasing threshold values of Tphrase, we detected phrases that appear more frequently in the ﬁrst step\nusing the higher threshold value, e.g., “autonomous vehicle”, and detected phrases that are comparatively less frequent\nin the second step using the lower threshold value, e.g., “autonomous vehicle platooning”. In this study, we used the\nbest performing thresholds (5, 2.5) found in a previous study [13].\nThe phase detection computation resulted in a vocabulary of 15,435,308 terms, including 13,730,320 phrases. Since\nthe adopted phrase detection algorithm is purely based on cooccurrence statistics, the detection of some faulty phrases\nincluding stopwords such as “the_”, “a_”, “and_”, and “to_” is inevitable. Therefore, the detected phrases are pro-\ncessed one more time to split the known stopwords from the NLTK [10] and USPTO [18] stopwords lists. For example,\n“an_internal_combustion_engine” is replaced with “an internal_combustion_engine”. Then the vocabulary is reduced\nto 8,641,337 terms, including 6,900,263 phrases.\nNext, all the words are represented with their regularized forms to avoid having multiple terms representing the same\nword or phrase and thus decrease the vocabulary size. This step is achieved by ﬁrst using a part-of-speech (POS)\ntagger [19] to detect the type of words in the sentences and lemmatize those words accordingly. For example, if the\nword “learning” is tagged as a VERB, it would be regularized as “learn” while it would be regularized as “learning” if\nit is tagged as a NOUN. The lemmatization procedure further decreased the vocabulary to 8,144,852 terms including\n6,418,992 phrases.\nAs a last step, we removed the words contained in famous NLTK [10] and USPTO [18] stopwords lists. The NLTK\nstopwords list focuses more on general stopwords that can be encountered in daily English language such as “a, an,\nthe, ..., he, she, his, her, ..., what, which, who, ...”, in total 179 words. On the other hand, USPTO stopwords list\ninclude words that occur very frequently in patent documents and do not contain critical meaning within patent texts,\nsuch as “claim, comprise, ... embodiment, ... provide, respectively, therefore, thereby, thereof, thereto, ...”, in total\n99 words. The union of these two lists contains 220 stopwords.\nAdditionally, we also discarded the words appearing only 1 time in the whole patent database, which leads to a ﬁnal\nset of 6,645,391 terms including 5,834,072 phrases.\n3.2\nTerm Statistics\nTo identify the frequently occurring words or phrases that carry little information content about engineering and\ntechnology, we use four metrics together: 1) direct term frequency (TF), 2) inverse-document frequency (IDF), 3)\nterm-frequency-inverse-document-frequency (TFIDF) and 4) Shannon’s information entropy [20].\nWe use f(t) to denote direct frequency of term t. Consider a corpus C of P patents.\nT F(t) = n(t)\nn(p)\n(2)\nwhere n(p) = P\nt\nn(t, p) is the number of terms in the patent p, n(t) = P\np∈P\nn(t, p) is total count of term t in all patents.\nThe term frequency is an important indicator of commonality of a term within a collection of documents. Stopwords\nare expected to have high term frequency.\n3\nA PREPRINT - JUNE 5, 2020\nInverse-document-frequency (IDF) is calculated as follows\nIDF(t) = log\n|C|\nDF(t)\n(3)\nwhere DF(t) = |{p ∈C : t ∈p}| is the number of patents containing term t and |C| represents the number of\npatents in the database. This metric penalizes the frequently occurring terms and favours the ones occurring in a few\ndocuments only. The metric’s lower bound is 0 which refers to the terms that appear in every single document in the\ndatabase. The upper bound is deﬁned by the terms appearing only in one document, which is log |C|.\nTerm frequency-inverse-document-frequency (TFIDF) is calculated as follows\nT FIDF(t) =\n1\nDF(t)\nX\np\nn(t, p)\nn(p)\n|C|\nDF(t)\n(4)\nThis metric favours the terms that appear in a few documents, with a considerably high term frequency within the\ndocument. If a term appears in many documents, its TFIDF score will be penalized by IDF score due to its common-\nality. Here, we did not use the traditional IDF metric but removed the log normalizing function to penalize the terms\ncommonly occurring in the entire patent database harder regardless of their in-document (patent) term frequencies.\nWe eventually used the mean of the single document TFIDF scores for each term.\nThe entropy of term t is calculated as follows. The metric indicates how uneven the distribution of term t is in the\ncorpus C.\nH(t|C) = −\nX\np\nP(p|t) log P(p|t)\n(5)\nwhere P(p|t) = n(t,p)\nn(t) is the distribution of term t over patent documents. This indicates how evenly distributed a term\nis in the patent database. Maximum attainable entropy value for a given collection of documents is basically an even\ndistribution to all patents which leads to log |C|. Therefore, the terms having higher entropy values will contain less\ninformation about the patents where they appear, compared to other terms with lower entropy.\nWe reported the distributions of terms in our corpus according to these four metrics in the Appendix (see Figure A1).\nThe term-frequency distribution has a very long right tail, indicating most of the terms appear a few times in the patent\ndatabase while some words appear so frequently. Our further tests found that the distribution follows the a power\nlaw [21, 22]. By contrast, the distribution by IDF has a long left tail, indicating the existence of a few terms that\nappears commonly in all patents. The TFIDF distribution also has a long right tail that indicates the existence of\nhighly common terms in each patent and highly strong domain-speciﬁc terms dominating a set of patents. Moreover,\nthe long right tail of entropy distribution indicates comparingly few high valued terms that are appearing commonly\nin the entire database. Therefore, assessing the four metrics together will allow us to detect the stopwords with varied\noccurrence patterns.\n3.3\nHuman Evaluation\nWe formed 4 different lists of terms sorted by their decreasing TF, increasing IDF, increasing TFIDF, and decreasing\nentropy. Table A1 in the appendix presents the top ranked 30 terms in respective lists. Then the top 2,000 terms in each\nof the four lists are used to form a union set of terms. The union only includes 2,305 terms, which indicates that the\nlists based on four alternative statistic metrics overlap signiﬁcantly. Then the terms in the union set are evaluated by\ntwo researchers with more than 20 years of engineering experience each, in terms of whether a term carries information\nabout engineering and technology, to identify stopwords. The researchers initially achieved an inter-rater reliability of\n0.83 [23] and then discussed the discrepancy to reach the consensus on a ﬁnal list of 62 insigniﬁcant terms.\n3.4\nFinal List\nThis list, compared to our previous study which identiﬁed a list of stopwords [13] (see Table A2 in the Appendices) by\nmanually reading 1,000 randomly selected sentences from the same patent text corpus, includes 26 new uninformative\nstopwords that the previous list did not cover. In the meantime, we also found the previous list contains other 25\nstopwords, which are still deemed qualiﬁed stopwords in this study. Therefore, we integrate these 25 stopwords from\nthe previous study with the 62 stopwords identiﬁed here to derive a ﬁnal list of 87 stopwords for technical language\n4\nA PREPRINT - JUNE 5, 2020\nanalysis. The ﬁnal list is presented in Table 1 together with the NLTK stopwords list and the USPTO stopwords list1. It\nis suggested to apply the three stopwords lists together in technical language processing applications across technical\nﬁelds.\nTable 1: Stopwords lists for technical language processing applications\nNLTK Stopword List [10]\n(179 words)\nUSPTO Stopword List [18]\n(99 words)\nThis Study\n(87 words)\na\nhadn’t\non\nwasn’t\na\nonto\nable\nothers\nabout\nhas\nonce\nwe\naccordance\nor\nabove-mentioned\notherwise\nabove\nhasn\nonly\nwere\naccording\nother\naccordingly\noverall\nafter\nhasn’t\nor\nweren\nall\nparticularly\nacross\nrather\nagain\nhave\nother\nweren’t\nalso\npreferably\nalong\nremarkably\nagainst\nhaven\nour\nwhat\nan\npreferred\nalready\nsigniﬁcantly\nain\nhaven’t\nours\nwhen\nand\npresent\nalternatively\nsimply\nall\nhaving\nourselves\nwhere\nanother\nprovide\nalways\nsometimes\nam\nhe\nout\nwhich\nare\nprovided\namong\nspeciﬁcally\nan\nher\nover\nwhile\nas\nprovides\nand/or\nstraight forward\nand\nhere\nown\nwho\nat\nrelatively\nanything\nsubstantially\nany\nhers\nre\nwhom\nbe\nrespectively\nanywhere\nthereafter\nare\nherself\ns\nwhy\nbecause\nsaid\nbetter\ntherebetween\naren\nhim\nsame\nwill\nbeen\nshould\ndisclosure\ntherefor\naren’t\nhimself\nshan\nwith\nbeing\nsince\ndue\ntherefrom\nas\nhis\nshan’t\nwon\nby\nsome\neasily\ntherein\nat\nhow\nshe\nwon’t\nclaim\nsuch\neasy\nthereinto+\nbe\ni\nshe’s\nwouldn\ncomprises\nsuitable\neg\nthereon\nbecause\nif\nshould\nwouldn’t\ncorresponding\nthan\neither\ntherethrough\nbeen\nin\nshould’ve\ny\ncould\nthat\nelsewhere\ntherewith\nbefore\ninto\nshouldn\nyou\ndescribed\nthe\nenough\ntogether\nbeing\nis\nshouldn’t\nyou’d\ndesired\ntheir\nespecially\ntoward\nbelow\nisn\nso\nyou’ll\ndo\nthen\nessentially\ntowards\nbetween\nisn’t\nsome\nyou’re\ndoes\nthere\net al\ntypical\nboth\nit\nsuch\nyou’ve\neach\nthereby\netc\ntypically\nbut\nit’s\nt\nyour\nembodiment\ntherefore\neventually\nupon\nby\nits\nthan\nyours\nﬁg\nthereof\nexcellent\nvia\ncan\nitself\nthat\nyourself\nﬁgs\nthereto\nﬁnally\nvice versa\ncouldn\njust\nthat’ll\nyourselves\nfor\nthese\nfurthermore\nwhatever\ncouldn’t\nll\nthe\nfrom\nthey\ngood\nwhereas\nd\nm\ntheir\nfurther\nthis\nhence\nwhereat\ndid\nma\ntheirs\ngenerally\nthose\nhe/she\nwherever\ndidn\nme\nthem\nhad\nthus\nhim/her\nwhether\ndidn’t\nmightn\nthemselves\nhas\nto\nhis/her\nwhose\ndo\nmightn’t\nthen\nhave\nuse\nie\nwithin\ndoes\nmore\nthere\nhaving\nvarious\nii\nwithout\ndoesn\nmost\nthese\nherein\nwas\niii\nyet\ndoesn’t\nmustn\nthey\nhowever\nwere\ninstead\ndoing\nmustn’t\nthis\nif\nwhat\nlater\ndon\nmy\nthose\nin\nwhen\nlike\ndon’t\nmyself\nthrough\ninto\nwhere\nlittle\ndown\nneedn\nto\ninvention\nwhereby\nmany\nduring\nneedn’t\ntoo\nis\nwherein\nmay\neach\nno\nunder\nit\nwhich\nmeanwhile\nfew\nnor\nuntil\nits\nwhile\nmight\nfor\nnot\nup\nmeans\nwho\nmoreover\nfrom\nnow\nve\nnot\nwill\nmuch\nfurther\no\nvery\nnow\nwith\nmust\nhad\nof\nwas\nof\nwould\nnever\nhadn\noff\nwasn\non\noften\n1This list can be downloaded from our GitHub repository https://github.com/SerhadS/TechNet\n5\nA PREPRINT - JUNE 5, 2020\n4\nConcluding Remarks\nTo develop a comprehensive list of stopwords in engineering and technology-related texts, we mined the patent text\ndatabase with several statistical metrics from term frequency to entropy together to automatically identify candidate\nstopwords and use human evaluation to validate, screen and ﬁnalize stopwords from the candidates. In this procedure,\nthe automatic data-driven detection of four statistic metrics yield highly overlapping results, and the human evaluations\nalso came with high inter-rater reliability, suggesting evaluator independence. Our ﬁnal stopwords list can be used as\na complementary list to NLTK and USPTO stopwords lists in NLP and text analysis tasks related to technology,\nengineering design, and innovation.\nReferences\n[1] Danni Chang and Chun-hsien Chen. Product concept evaluation and selection using data mining and domain\nontology in a crowdsourcing environment. Advanced Engineering Informatics, 29(4):759–774, oct 2015.\n[2] Yi Zhang, Alan L. Porter, Zhengyin Hu, Ying Guo, and Nils C. Newman. \"Term clumping\" for technical intel-\nligence: A case study on dye-sensitized solar cells. Technological Forecasting and Social Change, 85:26–39,\n2014.\n[3] Mattyws F Grawe, Claudia A Martins, and Andreia G Bonfante. Automated Patent Classiﬁcation Using Word\nEmbedding. In 2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA),\npages 408–411. IEEE, dec 2017.\n[4] Qiyu Liu, Kai Wang, Yan Li, and Ying Liu. Data-driven Concept Network for Inspiring Designers’ Idea Genera-\ntion. Journal of Computing and Information Science in Engineering, pages 1–39, 2020.\n[5] Antoine Blanchard. Understanding and customizing stopword lists for enhanced patent mapping. World Patent\nInformation, 29(4):308–316, 2007.\n[6] Martin Gerlach, Hanyu Shi, and Luis A.Nunes Amaral. A universal information theoretic approach to the identi-\nﬁcation of stopwords. Nature Machine Intelligence, 2019.\n[7] Rachel Tsz-Wai Lo, Ben He, and Iadh Ounis.\nAutomatically Building a Stopword List for an Information\nRetrieval System. In 5th Dutch-Belgium Information Retrieval Workshop, Utrecht, 2005.\n[8] Christopher Fox. A stop list for general text. ACM SIGIR Forum, 24(1-2):19–21, sep 1989.\n[9] W. John Wilbur and Karl Sirotkin. The automatic identiﬁcation of stop words. Journal of Information Science,\n18(1):45–55, 1992.\n[10] Steven Bird, Ewan Klein, and Edward Loper. Natural language processing with Python: analyzing text with the\nnatural language toolkit. O’Reilly Media, Inc., 2009.\n[11] Henry Kuˇcera and Winthrop Nelson Francis. Computational analysis of present-day American English. Interna-\ntional Journal of American Linguistics, 35(1):71–75, 1969.\n[12] Marcelo A. Montemurro and Damián H. Zanette. Towards the quantiﬁcation of the semantic information encoded\nin written language. Advances in Complex Systems, 13(2):135–153, 2010.\n[13] Serhad Sarica, Jianxi Luo, and Kristin L. Wood. TechNet: Technology semantic network based on patent data.\nExpert Systems with Applications, 142, 2020.\n[14] Kazuhiro Seki and Javed Mostafa. An application of text categorization methods to gene ontology annotation. SI-\nGIR 2005 - Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development\nin Information Retrieval, pages 138–145, 2005.\n[15] Dan Crow and John Desanto. A hybrid approach to concept extraction and recognition-based matching in the\ndomain of human resources. Proceedings - International Conference on Tools with Artiﬁcial Intelligence, ICTAI,\n(Ictai):535–539, 2004.\n[16] Masoud Makrehchi and Mohamed S. Kamel. Automatic extraction of domain-speciﬁc stopwords from labeled\ndocuments. Lecture Notes in Computer Science (including subseries Lecture Notes in Artiﬁcial Intelligence and\nLecture Notes in Bioinformatics), 4956 LNCS:222–233, 2008.\n[17] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Distributed Representations of Words and Phrases\nand their Compositionality. In Advances in Neural Information Processing Systems (NIPS) 26, pages 1–9, 2013.\n[18] USPTO. Stopwords, USPTO Full-Text Database.\n6\nA PREPRINT - JUNE 5, 2020\n[19] Kristina Toutanova and Christopher D. Manning. Enriching the knowledge sources used in a maximum entropy\npart-of-speech tagger. In EMNLP ’00 Proceedings of the 2000 Joint SIGDAT conference on Empirical methods\nin natural language processing and very large corpora, pages 63–70, 2007.\n[20] C. E. Shannon. A Mathematical Theory of Communication. Bell System Technical Journal, 27(3):379–423, jul\n1948.\n[21] George Kingsley Zipf. The Psychobiology of Language. Routledge, London, 1936.\n[22] George Kingsley Zipf. Human Behavior and the Principle of Least Effort. Addison-Wesley, New York, 1949.\n[23] Lee J. Cronbach. Coefﬁcient alpha and the internal structure of tests. Psychometrika, 16(3):297–334, sep 1951.\nAppendices\nTable A1: Top 30 terms for term-frequency, IDF, TFIDF and entropy\nTerm-Frequency\nIDF\nTFIDF\nEntropy\n1\nmethod\nmethod\ninclude\nmethod\n2\nﬁrst\ninclude\nmethod\ninclude\n3\ninclude\none\none\none\n4\nsecond\nﬁrst\ncomprise\nform\n5\nform\nform\nform\nﬁrst\n6\none\ncomprise\nsystem\ncomprise\n7\nsystem\nsystem\nﬁrst\nsystem\n8\nplurality\nsecond\nleast\nsecond\n9\ndevice\nplurality\nsecond\napparatus\n10\ncomprise\napparatus\napparatus\nplurality\n11\napparatus\ndevice\nplurality\nleast\n12\nleast\nleast\nreceive\ndisclose\n13\nleast_one\ndisclose\ndisclose\ndevice\n14\nmay\nreceive\ndevice\nreceive\n15\nconnect\nmay\nconnect\nmay\n16\nprocess\nleast_one\nmay\nconnect\n17\ncontrol\nconnect\nposition\nleast_one\n18\nportion\ncontrol\ncontrol\ncontrol\n19\nreceive\nprocess\nleast_one\nprocess\n20\nposition\nposition\nportion\nposition\n21\nmean\nportion\nbase\nbase\n22\nsurface\nbase\ndetermine\nportion\n23\nsay\nsurface\ngenerate\nsurface\n24\nbase\ndetermine\nmake\ndetermine\n25\ndisclose\ngenerate\nsurface\nmake\n26\nconﬁgure\nmake\nwithin\ngenerate\n27\ndetermine\nmean\nprocess\nrelate\n28\ngenerate\nproduce\naccord\nproduce\n29\nsubstrate\nconﬁgure\nend\nconﬁgure\n30\nsignal\nrelate\nallow\nwithin\n7\nA PREPRINT - JUNE 5, 2020\nTable A2: The stopwords identiﬁed in the previous study. * indicates that the term is also identiﬁed in the current\nstudy. + indicates that the term is a stopword as deﬁned in the current study. Rest of the terms are no longer considered\nas stopwords as deﬁned in the current study.\nable*\netc*\none another\ntherethrough*\nabove-mentioned+\neventually+\notherwise*\ntherewith*\nalready*\nﬁnally*\npossibly\ntowards*\nalways*\nfurthermore*\nrather*\ntypical+\nand/or*\nhe/she+\nremarkably+\nvia*\nanything+\nhence*\nsigniﬁcantly+\nvice versa+\nanywhere+\nhim/her+\nsimply*\nwhatever+\nbetter*\nhis/her+\nsometimes+\nwhereat+\ndisclosure+\ninstead*\nstraight forward+\nwherever+\neasily*\nmay*\nsubstantially\nwhether*\neg*\nmeanwhile+\ntherebetween*\nwhose*\neither*\nmight+\ntherefor*\nwithin*\nelsewhere+\nmoreover+\ntherefrom*\nwithout*\nenough+\nmust*\ntherein*\nwrt\nespecially*\noften+\nthereinto+\nyet*\net al+\none\nthereon*\nFigure A1: Distribution of terms by (a) term-frequency, (b) IDF, (c) TFIDF and (d) entropy. Term-frequency and\nTFIDF histograms arbitrarily ﬁltered (term-count<=1000, TFIDF score<= 106) for visualization purposes. In fact,\nthey have longer right tails.\n8\n",
  "categories": [
    "cs.IR",
    "cs.CL"
  ],
  "published": "2020-06-04",
  "updated": "2020-06-04"
}