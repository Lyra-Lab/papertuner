{
  "id": "http://arxiv.org/abs/2006.08841v1",
  "title": "ECG Language Processing (ELP): a New Technique to Analyze ECG Signals",
  "authors": [
    "Sajad Mousavi",
    "Fatemeh Afghah",
    "Fatemeh Khadem",
    "U. Rajendra Acharya"
  ],
  "abstract": "A language is constructed of a finite/infinite set of sentences composing of\nwords. Similar to natural languages, Electrocardiogram (ECG) signal, the most\ncommon noninvasive tool to study the functionality of the heart and diagnose\nseveral abnormal arrhythmias, is made up of sequences of three or four distinct\nwaves including the P-wave, QRS complex, T-wave and U-wave. An ECG signal may\ncontain several different varieties of each wave (e.g., the QRS complex can\nhave various appearances). For this reason, the ECG signal is a sequence of\nheartbeats similar to sentences in natural languages) and each heartbeat is\ncomposed of a set of waves (similar to words in a sentence) of different\nmorphologies. Analogous to natural language processing (NLP) which is used to\nhelp computers understand and interpret the human's natural language, it is\npossible to develop methods inspired by NLP to aid computers to gain a deeper\nunderstanding of Electrocardiogram signals. In this work, our goal is to\npropose a novel ECG analysis technique, \\textit{ECG language processing (ELP)},\nfocusing on empowering computers to understand ECG signals in a way physicians\ndo. We evaluated the proposed method on two tasks including the classification\nof heartbeats and the detection of atrial fibrillation in the ECG signals.\nExperimental results on three databases (i.e., PhysionNet's MIT-BIH, MIT-BIH\nAFIB and PhysioNet Challenge 2017 AFIB Dataset databases) reveal that the\nproposed method is a general idea that can be applied to a variety of\nbiomedical applications and is able to achieve remarkable performance.",
  "text": "1\nECG Language Processing (ELP): a New Technique\nto Analyze ECG Signals\nSajad Mousavi, Fatemeh Afghah, Fatemeh Khadem, and U. Rajendra Acharya\nAbstract\nA language is constructed of a ﬁnite/inﬁnite set of sentences composing of words. Similar to natural languages, Electro-\ncardiogram (ECG) signal, the most common noninvasive tool to study the functionality of heart and diagnose several abnormal\narrhythmia, is made up of sequences of three or four distinct waves including the P-wave, QRS complex, T-wave and U-wave. An\nECG signal may contain several different varieties of each wave (e.g., the QRS complex can have various appearances). For this\nreason, the ECG signal is a sequence of heartbeats similar to sentences in natural languages) and each heartbeat is composed of a\nset of waves (similar to words in a sentence) of different morphologies. Analogous to natural language processing (NLP) which\nis used to help computers understand and interpret the human’s natural language, it is possible to develop methods inspired by\nNLP to aid computers to gain a deeper understanding of Electrocardiogram signals. In this work, our goal is to propose a novel\nECG analysis technique, ECG language processing (ELP), focusing on empowering computers to understand ECG signals in a\nway physicians do. We evaluated the proposed method on two tasks including the classiﬁcation of heartbeats and the detection of\natrial ﬁbrillation in the ECG signals. Experimental results on three databases (i.e., PhysionNet’s MIT-BIH, MIT-BIH AFIB and\nPhysioNet Challenge 2017 AFIB Dataset databases) reveal that the proposed method is a general idea that can be applied to a\nvariety of biomedical applications and is able to achieve remarkable performance.\nIndex Terms\nECG Analysis, ECG Language Processing, Deep learning, Heart Arrhythmia.\nI. INTRODUCTION\nECG is the most common signal used by physicians and cardiologists to monitor the functionality of the heart. Manual\nanalysis of ECG signals by a human is a very challenging and time-consuming task due to dealing with long ECG recordings and\nthe existence of complex patterns associated with different heart arrhythmia in the ECG signal. Therefore, to deal with the issues\nrelated to the manual analysis of ECG signals, several studies focus on developing automatic ECG analysis techniques to perform\nthis task with high accuracy and in a real-time manner. Machine learning algorithms are commonly used to detect the arrhythmia\nin the ECG signals [1], [2], [3], [4]. Typically, these methods consider four main steps in their workﬂows: (1) Pre-possessing\nsignal that includes re-sampling the signals, noise removal (using band-pass ﬁlters, etc.), signal normalization/standardization,\netc., (2) Heartbeat segmentation that involves detection of the R-peak (i.e., the QRS complex) using some algorithms such as\nPan and Tompkins’s algorithm [5], open-source gqrs package provided by Physioent community [6], etc., (3) Feature extraction\nthat includes transforming raw signal to features best suited to the speciﬁc task (i.e., classiﬁcation, prediction, regression, etc.).\nand (4) Learning that considers classical machine learning techniques such as multilayer perceptron (MLP) and decision trees\nfor analysing ECG signals [4].\nEven though conventional machine learning algorithms with the handcrafted features have achieved acceptable performance\nfor ECG analysis, deep learning models with the power of automated feature extraction and representation learning have proven\nto get human-level performance in analyzing biomedical signals [7], [8], [9]. However, deep learning techniques need a large\namount of data and are composed of huge parameters to be learned. In addition, most of the suggested methods and workﬂows\nfor analyzing ECG signals are tailored to the speciﬁc task and are not generalizable to other biomedical problems.\nIn this study, we open a new research avenue for ECG signal analysis by introducing a novel framework called ECG language\nprocessing (ELP) that processes the ECG signal in a way a text document is treated in natural language processing (NLP)\nframework. The proposed framework is applicable to various biomedical applications and also can improve the performance\nof the shallow machine learning algorithms. A language is constructed of a ﬁnite/inﬁnite set of sentences composing of words.\nSimilar to natural languages, an ECG signal is made up of sequences of three or four distinct waves including the P-wave,\nQRS complex, T-wave and U-wave [10], [11] (refer to Figure 1). Each normal ECG includes different varieties of each wave.\nFor instance, the QRS complex can have various shapes as shown in Figure 2. Hence, an ECG signal is a sequence of\nheartbeats (like sentences in natural languages) and each heartbeat is composed of a set of waves (like words in a sentence) of\ndifferent morphologies. Analogous to NLP which is utilized to help computers/machines to understand and interpret the human’s\nS. Mousavi and F. Afghah are with the School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, AZ, 86011 USA\n(e-mail: SajadMousavi@nau.edu, Fatemeh.Afghah@nau.edu).\nF. Khadem is an independent researcher (e-mail: Fatemeh.Khadem019@gmail.com).\nU. R. Acharya is with the School of Engineering, Ngee Ann Polytechnic, Singapore, the School of Science and Technology, Singapore University of\nSocial Sciences, 463 Clementi Road, 599494, Singapore, and the Department Bioinformatics and Medical Engineering, Asia University, Taiwan (e-mail:\naru@np.edu.sg).\narXiv:2006.08841v1  [eess.SP]  13 Jun 2020\n2\nnatural language, our proposed NLP-inspired ECG language processing can aid the computers to gain a deeper understanding\nof Electrocardiogram signals.\nThe rest of this work is structured as follows. Section II explains the proposed ELP method. Section III introduces potential\napplications of the ELP method. Section IV presents the experimental setup, the used datasets to assess the suggested method,\nand gives a performance comparison of the proposed approach against the existing algorithms in the literature, following by\na discussion. Finally, Section V concludes the study.\nFigure 1: Illustration of an ECG signal; Red circles indicate R peaks; green, blue and black curves illustrate P, QRS and T\nwaves respectively.\nFigure 2: the QRS complex morphology; adopted from [12].\nII. METHODOLOGY\nIn this section, we describe main components of ECG Language Processing. Figure 3 shows the ELP pipeline. The ELP\nincludes two main steps as follows:\nInput ECG Signals\nPeak Detection\nBeat and Wave\nSegmentation\nCreating a\nVocabulary\nWave Assignment\nWave Embedding\nTraining and Deploying\nFigure 3: ECG language processing Pipeline.\n3\nStep 1: Creating a Wave Vocabulary\n• Peak Detection: it includes detecting the R-peaks of given ECG signal or detecting the QRS complexes. The commonly\nused algorithms for such purpose are the Pan–Tompkins algorithm [5], [13] and one proposed by [14]. The red circles in\nFigure 1 depicts the R-peaks of a sample ECG signal.\n• Beat and Wave Segmentation: it involves dividing continuous ECG signal into a sequence of heartbeats, and split the\nheartbeats into distinct units called waves. After detecting R-peaks, the presence of other building waves (i.e., P, QRS\nand T waves) in the ECG signal can be extracted using adaptive searching windows. To do heartbeat segmentation, one\ncan identify a segment as a ﬁxed number of samples before the R-peak location to the ﬁxed number of samples after the\nR-peak location or from the onset of the P-wave to the offset of consecutive T-wave. Figure 1 depicts a segmented ECG\nsignal annotated with the R-peaks, P, QRS and T waves.\n• Creating a Vocabulary: it includes building a vocabulary of the waves based on the extracted waves from the ECG\nsignals. We can cluster all the waves, then consider the mean of each cluster as an entry of the vocabulary. This can be\ndone by feeding all waves into off-the-shelf clustering algorithms such as K-means, spectral clustering or agglomerative\nclustering algorithms [15], [16], [17]. After doing wave clustering, the mean of each cluster can represent a distinct wave\nof the vocabulary. Figure 4 visualizes the extracted waves of an ECG signal dataset and extracted clusters (20 clusters)\nusing t-Distributed Stochastic Neighbor Embedding (t-SNE) technique [18]. Figure 6 shows a wave clustering results on\nthe dataset of PhysioNet Computing in Cardiology Challenge 2017 [19]. Each row of the ﬁgure presents 10 sample waves\nof a speciﬁc extracted cluster.\nFigure 4: Visualizations of thousands of extracted waves along with their 20 clusters from the PhysioNet Computing in\nCardiology Challenge 2017 dataset.\nStep 2: Training and Deploying\n• Wave Assignment the beat and wave segmentation process produce a sequence of waves for each ECG signal. Then, the\ncluster of each wave of the sequence is identiﬁed using the output of the previous step (i.e., the step II of pipeline). In\nother words, it assigns a unique integer value (the cluster number) to each wave of the sequence. In this way, each ECG\nsignal is integer-encoded, so that each integer represents a speciﬁc wave (or cluster) in the vocabulary.\n• Wave Embedding or Wave Vectorization it takes the integer-encoded vocabulary and builds the embedding vector (i.e., a\nvector of a speciﬁed length) for each wave of the vocabulary. The main reason behind word embedding is that it allows us\nto apply advanced machine leaning like artiﬁcial neural networks on the integer-encoded ECG signals for a speciﬁc task.\n4\nInspired by natural language processing, we can use several approaches such as Count Vectorizer in which a sequence\nof waves is converted into a ﬁxed-length vector with the size of the vocabulary. The value in each position in the vector\nwould be a count of each wave in the encoded signal, or Word2Vec approach that uses neural network techniques to\nrepresent waves in a vector space. The latter approach is more efﬁcient so that it recognizes context, relation and similarity\nbetween waves [20].\n• Training and Deploying it involves using machine learning and deep learning techniques to train models on output of\nthe wave embedding step for any learning tasks including classiﬁcation, prediction, etc. To give a better understanding of\nELP applications, we outline some main ECG language processing examples in the following section.\nIII. ECG LANGUAGE PROCESSING EXAMPLES\nECG Language Processing (ELP) can be used in a variety of biomedical applications where the collected data are ECG\nsignals. Below are the most common applications of ELP:\n• Heartbeat classiﬁcation/detection it involves assigning a speciﬁc label to heartbeats of a given ECG signal.\n• Arrhythmia prediction it includes predicting onset of life-threatening arrhythmia such as Atrial Fibrillation (AFib) in\npatients based on their current and past states.\n• Automatic heartbeat annotation it involves automatic annotation of the heartbeats in a sequence of heartbeats (i.e., an\nECG signal). This problem is also called automatic sequence labeling [21], [22].\n• Summarize a long ECG signal ECG signals are typically 8 hours (or more) long (e.g., in sleep stage detection task).\nThus, interpreting such a long ECG signal by cardiologists and physicians is a very time-consuming and prone to error\ntask. One way to tackle this problem is summarizing the ECG signal and only extracting the most related regions of the\nECG signal which contribute to a speciﬁc event. This can be done by using attention mechanisms [23], [24].\n• Translate ECG to other physiological signals it involves estimating other physiological signals such as Arterial Blood\nPressure (ABP) and photoplethysmography (PPG) from ECG signals. The main application of such translations is\nimputation in which the missing values (may be caused by the device inadvertent detachment) of the signals can be\nestimated.\nIV. EXPERIMENTS\nIn this section, we evaluate our proposed ECG analysis approach (i.e., ECG Language Processing) using two different clinical\ntasks including atrial ﬁbrillation detection and automatic heartbeat classiﬁcation. We show performing the ELP pipeline to\nprocess ECG signals results in better performance compared to the existing methods.\nA. Data Description\nTwo datasets including the MIT-BIH AFIB database [25] and the PhysioNet Computing in Cardiology Challenge 2017 dataset\n[19] were utilized to build models to perform the detection of atrial ﬁbrillation, and the PhysioNet MIT-BIH Arrhythmia database\n[26] was used to build an automatic heartbeat annotation model.\nMIT-BIH AFIB Dataset: This dataset includes 23 long-term ECG recordings of subjects with mostly AFIB arrhythmia.\nEach subject of the MIT-BIH AFIB contains two 10-hours long ECG recordings (ECG1 and ECG2). The ECG recordings\nare sampled at 250 Hz with 12-bit resolution over a range of ±10 millivolts. In this paper, we split each ECG signal into\n5-s data segments and annotated each one based on a threshold parameter, p. We considered the labeling method used by\n[27], [28]. Indeed, a 5-s data segment is considered as AFIB if the percentage of labeled AFIB heartbeats of the segment is\ngreater than or equal to p, otherwise it is labeled as a non-AFIB arrhythmia. Similar to the literature, the parameter p was set\nto 50%. We extracted a total of 167, 422 5-s data segments from the ECG1 recordings of the dataset. The number of AFIB\nand non-AFIB samples were 66, 939 and 100, 483, respectively. To cope with the class imbalance problem existing in the\nextracted data segments, we randomly selected the same number of segments for both AFIB and non-AFIB classes in which\nwe considered 66, 939 data segments for both classes.\nPhysioNet Challenge AFIB Dataset: This dataset was applied for the PhysioNet Challenge 2017 in which the purpose\nwas to propose algorithms to classify a single-short-ECG lead recording (with duration 30-60s) to normal sinus rhythm (N),\natrial ﬁbrillation (AFIB), an alternative rhythm (O), or too noisy (∼) classes. The training set contains 8,528 single lead ECG\nrecordings and the test set includes 3,658 ECG recordings. Because the test set has not been publicly available, we utilized the\ntraining set for building and evaluating the model. The ECG recordings were recorded by AliveCor devices, sampled as 300\nHz and ﬁltered by a band pass ﬁlter. Table I shows the statistics of the numbers of each classiﬁcation type in the PhysioNet\nChallenge AFIB database (i.e., the training set).\nPhysioNet MIT-BIH: This arrhythmia’s dataset contains the ECG signals for 48 different subjects. The signals were recorded\nat the sampling rate of 360Hz, and each record includes two ECG leads; ECG lead II and lead V1. In this study, to be consistent\nwith the previous works in the literature, the ECG lead II is used to build the heartbeat annotator. The dataset is recommended\nby the American association of medical instrumentation (AAMI) [29] and is composed of the ﬁve essential arrhythmia groups.\nTable II presents the categories of heartbeats existed in the database and Table III shows the statistics of the numbers of each\nheartbeat group in the MIT-BIH database.\n5\nTable I: Details of number of each classiﬁcation type in the PhysioNet Challenge AFIB dataset.\nDataset\nN\nAFIB\nO\n∼\nTotal\nPhysioNet Challenge AFIB\n5,154\n771\n2,557\n46\n8,528\nTable II: Groups of heartbeats presented in the MIT-BIH database based on AAMI.\nCategory\nClass\nN\n• Normal beat (N)\n• Left and right bundle branch block beats (L,R)\n• Atrial escape beat (e)\n• Nodal (junctional) escape beat (j)\nS\n• Atrial premature beat (A)\n• Aberrated atrial premature beat (a)\n• Nodal (junctional) premature beat (J)\n• Supraventricular premature beat (S)\nV\n• Premature ventricular contraction (V)\n• Ventricular escape beat (E)\nF\n• Fusion of ventricular and normal beat (F)\nQ\n• Paced beat (/)\n• Fusion of paced and normal beat (f)\n• Unclassiﬁable beat (U)\nTable III: Details of number of each heartbeat group in the MIT-BIH database.\nDataset\nN\nS\nV\nF\nQ\nTotal\nMIT-BIH Arrhythmia\n90,462\n2,777\n7,223\n802\n8,027\n109,291\nB. Experimental setup\nWe built three different neural networks for each clinical task and compared them to the state-of-the-art algorithms. Below\nis list of the models we used to build the detective models.\n• Convolutional neural network (CNN) we use three consecutive 1D convolutional layers in which each layer is composed\nof 128 ﬁlters with a kernel size of 5×1, a stride 1 and a Rectiﬁed Linear Unit (ReLU) activation function. All convolutional\nlayers are followed by max-pooling layers with pooling regions of size 5 × 1 with stride sizes of 5. The output of the last\nconvolutional layer is passed through a dropout layer followed by a fully-connected layer with a size of 64 followed by a\nsoftmax layer to perform the classiﬁcation task (see Figure 5a). Because the length of input signals in the MIT-BIH AFIB\nand PhysioNet MIT-BIH databases were too short, we use two consecutive 1D convolutional layers for both datasets with\nsmall pooling regions of sizes 3 × 1 with a stride 3 and 2 × 1 with a stride 2, respectfully.\n• Recurrent neural network (RNN) we utilize 2-layer bi-directional long short term memory (LSTM) with 128 neurons\nfollowed by a dropout layer and a fully-connected layer of 64 neurons. Again, to do classiﬁcation, a softmax layer is used\non top of the last dense layer (see Figure 5b).\n• RNN-Attention we added an attention layer on top an RNN model analogous to the one mentioned above to put more\nemphasis on the important waves of the input signal(s) that have most contribution in detecting the arrhythmia (see Figure\n5c). The attention layer assigns a probability value to each feature vector extracted from the input by the RNN. In the\nprobability vector, each value is the importance of the corresponding feature vector. Then, an expected value (i.e., it is a\nlinear weighted vector) of the input feature vectors is computed according to the weights provided by the attention layer.\nFinally, the weighted vector is fed into a softmax layer to perform the classiﬁcation task.\n6\nConv1d \nstride (1,1), ReLU\n5 × 1, 128\nEmbedding Layer\nInteger-encoded Vector of ECG Waves\nMaxPool \nstride (5,1)\n5 × 1\nConv1d \nstride (1,1), ReLU\n5 × 1, 128\nMaxPool \nstride (5,1)\n5 × 1\nConv1d \nstride (1,1), ReLU\n5 × 1, 128\nMaxPool \nstride (5,1)\n5 × 1\nDropout 0.8\nSoftmax\n(a) CNN\nBiRNN (128)\nEmbedding Layer\nInteger-encoded Vector of ECG Waves\nBiRNN (128)\nDropout 0.8\nSoftmax\n(b) RNN\nBiRNN (128)\nEmbedding Layer\nInteger-encoded Vector of ECG Waves\nBiRNN (128)\nDropout 0.8\nSoftmax\nAttention\n(c) RNN-Attention\nFigure 5: Architectures of the used networks in the experiments.\nWe followed the aforementioned steps of the ELP pipeline in Section II in which we converted each input signal to an\ninteger encoded vector and computed its corresponding embedding vector using a shallow neural network. Then, we used the\nembedding vectors as input for the mentioned models (i.e., the CNN, RNN and RNN-Attention) for building the detective\nmodels.\nImplementation details We trained all models with a maximum number of 25 epochs and batch size of 64 samples. The\nAdam optimizer was applied to minimize the loss with a learning rate α = 0.001. To mitigate the effect of the overﬁtting\nproblem, an L2 regularization with a coefﬁcient β = 1e −5 and a dropout approach with a probability of keeping input units of\n0.8 were used. We implemented the models using Python programming language and Google Tensorﬂow deep learning library\non a machine equipped with 8 CPUs (Intel(R) Xeon(R) CPU @ 3.60 GHz), 32 GB memory and Ubuntu 18.04. Also, in all\nexperiments, we reported the best performance.\nC. Results and discussion\nWe report the performance of all built models using all databases and show that following the ELP steps lead to better\nperformance compared to the existing algorithms. We evaluate the models in terms of the overall accuracy, precision (positive\npredictive value (PPV)), recall (sensitivity), speciﬁcity, and F1-score. We also computed macro-averaging of F1-score (MF1)\nwhich is the sum of per-class F1-score over the number of classes.\nWe used a ten-fold cross-validation to assess the performance of the proposed method for the heartbeat classiﬁcation task\nusing the MIT-BIH arrhythmia database. Table IV presents the detection scores on the MIT-BIH arrhythmia database. We\nsee that ELP work with the CNN, RNN and RNN-Attention approaches outperforms all other methods listed in the table.\nThe RNN-Attention model performs as good as the CNN model indicating the attention mechanism helps in getting better\nperformance. Furthermore, Table V reports a confusion matrix of classiﬁed heartbeats and performance of each class achieved\nby the ELP while we use the CNN approach to build the classiﬁer. According to Table V, the smallest sensitivity values are\nobtained for the categories F and S. The reason is the class imbalance problem existed in the database where the group F has\nonly 802 heartbeats and the group S has 2,777 heartbeats. An imbalanced dataset can negatively affect the performance of an\nmachine learning algorithm. Typically, generating synthetic data or tweaking loss functions are used to mitigate this problem\n[30].\n7\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n6\n6\n6\n6\n6\n6\n6\n6\n6\n6\n7\n7\n7\n7\n7\n7\n7\n7\n7\n7\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n12\n12\n12\n12\n12\n12\n12\n12\n12\n12\n13\n13\n13\n13\n13\n13\n13\n13\n13\n13\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n15\n15\n15\n15\n15\n15\n15\n15\n15\n15\n16\n16\n16\n16\n16\n16\n16\n16\n16\n16\n17\n17\n17\n17\n17\n17\n17\n17\n17\n17\n18\n18\n18\n18\n18\n18\n18\n18\n18\n18\n19\n19\n19\n19\n19\n19\n19\n19\n19\n19\nFigure 6: Visualization of extracted waves using a clustering algorithm and their corresponding clusters; the numbers above\nwaves indicate their cluster number.\n8\nTable IV: Comparison of performance of the proposed approach against other existing algorithms on the MIT-BIH arrhythmia\ndatabase.\nWork\nApproach\nAccuracy (%)\nELP\nCNN\n97.00\nELP\nRNN\n96.96\nELP\nRNN-Attention\n97.00\nKachuee et al. [2]\nDeep residual CNN\n93.4\nAcharya et al. [1]\nAugmentation + CNN\n93.47\nLi et al. [31]\nDWT + random forest\n94.61\nMartis et al. [32]\nDWT + SVM\n93.8\nDWT: Discrete wavelet transform; SVM: Support vector machine\nTable V: Confusion matrix and per-class performance achieved by the proposed method across all ten-folds using the CNN\nmodel and based on the MIT-BIH arrhythmia database.\nPredicted\nPer-class Performance (%)\nN\nS\nV\nF\nQ\nacc\nppv\nsen\nspec\nActual\nN\n89774\n203\n357\n37\n91\n97.35\n97.60\n99.24\n88.30\nS\n757\n1945\n56\n1\n18\n98.99\n87.89\n70.04\n99.75\nV\n632\n51\n6449\n44\n47\n98.77\n91.88\n89.28\n99.94\nF\n175\n3\n95\n527\n2\n99.67\n86.39\n65.71\n99.92\nQ\n639\n11\n62\n1\n7314\n99.20\n97.89\n91.12\n99.84\nacc: accuracy; ppv: positive predictive value; sen: sensitivity; spec: speciﬁcity\nWe employed a ﬁve-fold cross-validation to evaluate the performance of the proposed method for the atrial ﬁbrillation\nclassiﬁcation task using the PhysioNet Computing in Cardiology Challenge 2017 dataset. Table VI shows a performance\ncomparison of the 3 models (i.e., the CNN, RNN and RNN-Attention) following our proposed method on detecting atrial\nﬁbrillation against the state-of-the-art algorithms. From the table, we can observe that the ELP work with the CNN approach\noutperforms other methods listed in Table VI, obtaining an MF1 score of 64.40%. As it is shown in the table, the RNN-attention\nachieves better performance compared to the RNN, showing the attention mechanism leads to performance improvement.\nApplying the attention approach to the RNN (or other deep learning models) not only improves the model performance but\nalso it provides interpretability into the model [33], [34], [24], [35]. Table VII presents a confusion matrix and per-class\nperformance of the atrial ﬁbrillation classiﬁcation task on the PhysioNet challenge AFIB dataset. Herein, we reported the\nmodel’s results with the best performance (i.e., the CNN model). Even though the number of samples for class O (2,557) is\nlarger than the number samples for class A (771), the model performs better for class A. This may be because the class Other\nrhythm (O) contains a variety of rhythms with different morphologies that make it hard for the network to learn the associated\npatterns to the class O.\nTo evaluate the performance of our method for another AFIB classiﬁcation task, we utilized a ten-fold cross-validation\nprocedure on the MIT-BIH AFIB database with the ECG segment of size 5-s. Table VIII reports the detection scores on the\nAFIB detection task. We see that the proposed work with the CNN model achieves a good performance but slightly low\nperformance compared the Xia et al. [27] work.\nFrom all experiments for three database, we can see that our method can result in better performance or comparable\nperformance with smaller neural networks compared to other deep neural networks and existing algorithms. Therefore, this\nmake the proposed method implementable on the devices with a limited hardware such as wearable devices. It is worth\nmentioning that in the ﬁrst step of the ELP pipeline (Step 1: Creating a Wave Vocabulary), we extracted the waves in the ECG\n9\nTable VI: Comparison of performance of the proposed approach against other algorithms for the atrial ﬁbrillation (AFIB)\nclassiﬁcation task on the PhysioNet Computing in Cardiology Challenge 2017 dataset.\nWork\nApproach\nPer-class Performance (F1%)\nOverall Performance\nN\nA\nO\n∼\nMF1\nAccuracy\nELP\nCNN\n82.26\n63.47\n56.69\n55.18\n64.40\n72.62\nELP\nRNN\n79.88\n56.06\n44.32\n43.31\n55.89\n67.66\nELP\nRNN-Attention\n83.98\n64.57\n55.84\n52.58\n64.24\n74.22\nAndreotti et al. [36]\nDeep residual CNN\n82.6\n46.6\n60.0\n60.2\n62.4\n-\nMF1: Macro-averaging of F1-score\nTable VII: Confusion matrix and per-class performance achieved by the proposed method across all ﬁve-folds for the atrial\nﬁbrillation (AFIB) classiﬁcation task on the PhysioNet Computing in Cardiology Challenge 2017 database.\nPredicted\nPer-class Performance (%)\nN\nA\nO\n∼\nacc\nppv\nsen\nspec\nActual\nN\n4221\n53\n738\n63\n78.65\n81.83\n83.17\n71.98\nA\n70\n463\n207\n18\n93.75\n66.05\n61.08\n96.93\nO\n839\n172\n1348\n53\n75.83\n57.51\n55.89\n83.70\n∼\n57\n13\n51\n157\n97.01\n53.95\n56.47\n98.37\nacc: accuracy; ppv: positive predictive value; sen: sensitivity; spec: speciﬁcity\nsignals based on the extracted R-peaks and employing adaptive searching windows, and used a K-means clustering algorithm\nto cluster waves to build the vocabulary. We believe, applying better segmentation algorithms or more sophisticated clustering\nmethods can yield to higher detection scores.\nV. CONCLUSION\nIn this study, we proposed a new technique to analyze ECG signals named ECG language processing (ELP). The proposed\napproach is composed of two main steps: 1) Creating a Wave Vocabulary, building a vocabulary of waves based on the extracted\nwaves from the ECG signals, and 2) Training and Deploying, developing predictive and detective models using the extracted\nvocabulary and machine learning algorithms for different clinical tasks. The experiment results on two different tasks, including\nthe heartbeat classiﬁcation and atrial ﬁbrillation tasks with three databases show that our method results in the state-of-the-art\nperformance. Future work includes, but not limited to, improving the segmentation and creating the vocabulary steps to improve\nthe performance of the detection process and applying the ELP method for other biomedical applications such as the prediction\nof arrhythmia (see Section III for more examples).\nACKNOWLEDGMENT\nThis study is based upon work supported by the National Science Foundation under Grant Number 1657260. Research\nreported in this publication was supported by the National Institute On Minority Health And Health Disparities of the National\nInstitutes of Health under Award Number U54MD012388.\nREFERENCES\n[1] U. R. Acharya, S. L. Oh, Y. Hagiwara, J. H. Tan, M. Adam, A. Gertych, and R. San Tan, “A deep convolutional neural network model to classify\nheartbeats,” Computers in biology and medicine, vol. 89, pp. 389–396, 2017.\n[2] M. Kachuee, S. Fazeli, and M. Sarrafzadeh, “Ecg heartbeat classiﬁcation: A deep transferable representation,” in 2018 IEEE International Conference\non Healthcare Informatics (ICHI).\nIEEE, 2018, pp. 443–444.\n10\nTable VIII: Comparison of performance of the proposed approach against other state-of-the-art algorithms for the AFIB detection\ntask on the MIT-BIH AFIB database with the ECG segment of size 5-s.\nWork\nApproach\nBest Performance (%)\naccuracy\nppv\nsensitivity\nspeciﬁcity\nELP\nCNN\n98.17\n97.78\n98.57\n97.76\nELP\nRNN\n97.93\n97.63\n98.24\n97.61\nELP\nRNN-Attention\n97.96\n97.87\n98.08\n97.84\nXia et al. [27]\nSWT + CNN\n98.63\n-\n98.79\n97.87\nAsgari et al. [28]\nSWT + SVM\n-\n-\n97.00\n97.10\nJiang et al. [37]\nRR interval irregularity +\nP-wave absence\n-\n-\n98.20\n97.50\nppv: positive predictive value; SWT: stationary wavelet transform\n[3] S. Mousavi, A. Fotoohinasab, and F. Afghah, “Single-modal and multi-modal false arrhythmia alarm reduction using attention-based convolutional and\nrecurrent neural networks,” PloS one, vol. 15, no. 1, p. e0226990, 2020.\n[4] M. Zaeri-Amirani, F. Afghah, and S. Mousavi, “A feature selection method based on shapley value to false alarm reduction in icus a genetic-algorithm\napproach,” in 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). IEEE, 2018, pp. 319–323.\n[5] J. Pan and W. J. Tompkins, “A real-time qrs detection algorithm,” IEEE Trans. Biomed. Eng, vol. 32, no. 3, pp. 230–236, 1985.\n[6] PhysioNet, PhysioNet community, 2000. [Online]. Available: https://www.physionet.org/\n[7] P. Rajpurkar, A. Y. Hannun, M. Haghpanahi, C. Bourn, and A. Y. Ng, “Cardiologist-level arrhythmia detection with convolutional neural networks,”\narXiv preprint arXiv:1707.01836, 2017.\n[8] Ö. Yıldırım, P. Pławiak, R.-S. Tan, and U. R. Acharya, “Arrhythmia detection using deep convolutional neural network with long duration ecg signals,”\nComputers in biology and medicine, vol. 102, pp. 411–420, 2018.\n[9] F. Murat, O. Yildirim, M. Talo, U. B. Baloglu, Y. Demir, and U. R. Acharya, “Application of deep learning techniques for heartbeats detection using\necg signals-analysis and review,” Computers in Biology and Medicine, p. 103726, 2020.\n[10] J. W. Hurst, “Naming of the waves in the ecg, with a brief account of their genesis,” Circulation, vol. 98, no. 18, pp. 1937–1942, 1998.\n[11] Harvard,\n“Understanding\nThe\nECG\nReading\nThe\nWaves,”\n2018.\n[Online].\nAvailable:\nhttps://www.health.harvard.edu/heart-health/\nunderstanding-the-ecg-reading-the-waves\n[12] J. Esquillo, “EKG: Waves, Complexes, Straight Lines, and Intervals/Labeling and Interpreting,” 2017. [Online]. Available: https://brilliantnurse.com\n[13] L. Sathyapriya, L. Murali, and T. Manigandan, “Analysis and detection r-peak detection using modiﬁed pan-tompkins algorithm,” in 2014 IEEE\nInternational Conference on Advanced Communications, Control and Computing Technologies.\nIEEE, 2014, pp. 483–487.\n[14] M. S. Manikandan and K. Soman, “A novel method for detecting r-peaks in electrocardiogram (ecg) signal,” Biomedical Signal Processing and Control,\nvol. 7, no. 2, pp. 118–128, 2012.\n[15] T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. Piatko, R. Silverman, and A. Y. Wu, “An efﬁcient k-means clustering algorithm: Analysis and\nimplementation,” IEEE Transactions on Pattern Analysis & Machine Intelligence, no. 7, pp. 881–892, 2002.\n[16] R. Xu and D. C. Wunsch, “Survey of clustering algorithms,” 2005.\n[17] A. Y. Ng, M. I. Jordan, and Y. Weiss, “On spectral clustering: Analysis and an algorithm,” in Advances in neural information processing systems, 2002,\npp. 849–856.\n[18] L. v. d. Maaten and G. Hinton, “Visualizing data using t-sne,” Journal of machine learning research, vol. 9, no. Nov, pp. 2579–2605, 2008.\n[19] PhysioNet, “AF Classiﬁcation from a Short Single Lead ECG Recording - The PhysioNet Computing in Cardiology Challenge 2017,” 2001. [Online].\nAvailable: https://physionet.org/physiobank/database/mitdb/\n[20] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, “Distributed representations of words and phrases and their compositionality,” in Advances\nin neural information processing systems, 2013, pp. 3111–3119.\n[21] X. Ma and E. Hovy, “End-to-end sequence labeling via bi-directional lstm-cnns-crf,” arXiv preprint arXiv:1603.01354, 2016.\n[22] S. Mousavi and F. Afghah, “Inter-and intra-patient ecg heartbeat classiﬁcation for arrhythmia detection: a sequence to sequence deep learning approach,”\nin ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2019, pp. 1308–1312.\n[23] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, and Y. Bengio, “Show, attend and tell: Neural image caption generation with\nvisual attention,” in International conference on machine learning, 2015, pp. 2048–2057.\n[24] S. Mousavi, F. Afghah, A. Razi, and U. R. Acharya, “ECGNET: Learning where to attend for detection of atrial ﬁbrillation with deep visual attention,”\nin 2019 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI).\nIEEE, 2019, pp. 1–4.\n[25] PhysioNet, “PhysioNet MIT-BIH Atrial Fibrillation Database,” 2000. [Online]. Available: https://physionet.org/content/afdb/1.0.0/\n[26] PhysioNet, “Physionet MIT-BIH arrhythmia database,” 2001. [Online]. Available: https://physionet.org/physiobank/database/mitdb/\n[27] Y. Xia, N. Wulan, K. Wang, and H. Zhang, “Detecting atrial ﬁbrillation by deep convolutional neural networks,” Computers in biology and medicine,\nvol. 93, pp. 84–92, 2018.\n[28] S. Asgari, A. Mehrnia, and M. Moussavi, “Automatic detection of atrial ﬁbrillation using stationary wavelet transform and support vector machine,”\nComputers in biology and medicine, vol. 60, pp. 132–142, 2015.\n[29] ANSI-AAMI, “Testing and reporting performance results of cardiac rhythm and st segment measurement algorithms,” American National Standards\nInstitute, Inc. (ANSI), Association for the Advancement of Medical Instrumentation (AAMI), ANSI/AAMI/ISO, 1998-2008.\n[30] S. Mousavi, F. Afghah, and U. R. Acharya, “SleepEEGNet: Automated sleep stage scoring with sequence to sequence deep learning approach,” PloS\none, vol. 14, no. 5, 2019.\n11\n[31] T. Li and M. Zhou, “Ecg classiﬁcation using wavelet packet entropy and random forests,” Entropy, vol. 18, no. 8, p. 285, 2016.\n[32] R. J. Martis, U. R. Acharya, C. M. Lim, K. Mandana, A. K. Ray, and C. Chakraborty, “Application of higher order cumulant features for cardiac health\ndiagnosis using ecg signals,” International journal of neural systems, vol. 23, no. 04, p. 1350014, 2013.\n[33] S. Mousavi, F. Afghah, and U. R. Acharya, “HAN-ECG: An interpretable atrial ﬁbrillation detection model using hierarchical attention networks,” arXiv\npreprint arXiv:2002.05262, 2020.\n[34] E. Choi, M. T. Bahadori, J. Sun, J. Kulas, A. Schuetz, and W. Stewart, “Retain: An interpretable predictive model for healthcare using reverse time\nattention mechanism,” in Advances in Neural Information Processing Systems, 2016, pp. 3504–3512.\n[35] S. Mousavi, M. Schukat, E. Howley, A. Borji, and N. Mozayani, “Learning to predict where to look in interactive environments using deep recurrent\nq-learning,” arXiv preprint arXiv:1612.05753, 2016.\n[36] F. Andreotti, O. Carr, M. A. Pimentel, A. Mahdi, and M. De Vos, “Comparing feature-based classiﬁers and convolutional neural networks to detect\narrhythmia from short segments of ecg,” in 2017 Computing in Cardiology (CinC).\nIEEE, 2017, pp. 1–4.\n[37] K. Jiang, C. Huang, S.-m. Ye, and H. Chen, “High accuracy in automatic detection of atrial ﬁbrillation for holter monitoring,” Journal of Zhejiang\nUniversity SCIENCE B, vol. 13, no. 9, pp. 751–756, 2012.\n",
  "categories": [
    "eess.SP",
    "q-bio.QM"
  ],
  "published": "2020-06-13",
  "updated": "2020-06-13"
}