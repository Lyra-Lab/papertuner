{
  "id": "http://arxiv.org/abs/2006.11364v1",
  "title": "Manifolds for Unsupervised Visual Anomaly Detection",
  "authors": [
    "Louise Naud",
    "Alexander Lavin"
  ],
  "abstract": "Anomalies are by definition rare, thus labeled examples are very limited or\nnonexistent, and likely do not cover unforeseen scenarios. Unsupervised\nlearning methods that don't necessarily encounter anomalies in training would\nbe immensely useful. Generative vision models can be useful in this regard but\ndo not sufficiently represent normal and abnormal data distributions. To this\nend, we propose constant curvature manifolds for embedding data distributions\nin unsupervised visual anomaly detection. Through theoretical and empirical\nexplorations of manifold shapes, we develop a novel hyperspherical Variational\nAuto-Encoder (VAE) via stereographic projections with a gyroplane layer - a\ncomplete equivalent to the Poincar\\'e VAE. This approach with manifold\nprojections is beneficial in terms of model generalization and can yield more\ninterpretable representations. We present state-of-the-art results on visual\nanomaly benchmarks in precision manufacturing and inspection, demonstrating\nreal-world utility in industrial AI scenarios. We further demonstrate the\napproach on the challenging problem of histopathology: our unsupervised\napproach effectively detects cancerous brain tissue from noisy whole-slide\nimages, learning a smooth, latent organization of tissue types that provides an\ninterpretable decisions tool for medical professionals.",
  "text": "Manifolds for Unsupervised Visual Anomaly\nDetection\nLouise Naud\nAugustus Intelligence\nNew York City, NY 10014\nlouise.naud@augustusai.com\nAlexander Lavin\nAugustus Intelligence\nNew York City, NY 10014\nalexander.lavin@augustusai.com\nAbstract\nAnomalies are by deﬁnition rare, thus labeled examples are very limited or nonexis-\ntent, and likely do not cover unforeseen scenarios. Unsupervised learning methods\nthat don’t necessarily encounter anomalies in training would be immensely use-\nful. Generative vision models can be useful in this regard but do not sufﬁciently\nrepresent normal and abnormal data distributions. To this end, we propose con-\nstant curvature manifolds for embedding data distributions in unsupervised visual\nanomaly detection. Through theoretical and empirical explorations of manifold\nshapes, we develop a novel hyperspherical Variational Auto-Encoder (VAE) via\nstereographic projections with a gyroplane layer - a complete equivalent to the\nPoincaré VAE. This approach with manifold projections is beneﬁcial in terms of\nmodel generalization and can yield more interpretable representations. We present\nstate-of-the-art results on visual anomaly benchmarks in precision manufacturing\nand inspection, demonstrating real-world utility in industrial AI scenarios. We\nfurther demonstrate the approach on the challenging problem of histopathology:\nour unsupervised approach effectively detects cancerous brain tissue from noisy\nwhole-slide images, learning a smooth, latent organization of tissue types that\nprovides an interpretable decisions tool for medical professionals.\n1\nIntroduction\nAnnotating visual data can be burdensome and expensive in most real-world applications; for\nexample, medical professionals manually inspecting and labeling massive whole-slide images (WSI)\nfor thousands of nucleotides, lymphocytes, tumors, etc. This is exponentially so when trying to label\na sufﬁcient amount of anomalous data, as anomalies are by deﬁnition rare; even more, we have to\nassume there are unforeseen anomalous scenarios to arise in the future. Unsupervised methods are\nthus advantageous, and have seen promising advances with deep generative vision models. Recent\nand noteworthy work has been developing methods with Variational Auto-Encoders (VAE) [24, 38]\nand Generative Adverserial Networks (GAN) [15] towards these tasks [4, 52, 40, 35, 10].\nDeep generative models learn a mapping from a low-dimensional latent space to a high-dimensional\ndata space, centered around the manifold hypothesis: high-dimensional observations are concentrated\naround a manifold of much lower dimensionality. It follows that by learning the proper manifold we\ncan model the observed data with high-ﬁdelity. It is our aim to investigate properties of nonlinear\nmanifolds and regularity conditions that behoove visual data representation for anomaly detection.\nWe hypothesize Riemannian manifold curvatures other than the typical ﬂat, Euclidean space can\nprovide a more natural embedding on which to infer anomalous data in images.\nNon-Euclidean latent spaces have recently been proposed in deep generative models, namely hyper-\nbolic and hyperspherical metric spaces. With the former, the latent Poincaré space is shown to learn\nhierarchical representations from textual and graph-structured data [33, 43], and from images with\nPreprint. Work in progress.\narXiv:2006.11364v1  [cs.CV]  19 Jun 2020\nthe Poincaré VAE of Mathieu et al. [30]. Spherical embedding spaces have been shown useful for\nclass separation and smooth interpolation in the manifold towards computer vision tasks [32, 9, 17].\nWe hypothesize these manifold geometries naturally represent distinct normal and abnormal visual\ndata distributions, and can be learnt from data without labels via latent manifold mappings in deep\ngenerative models. We take care to investigate the properties of these manifolds most relevant to\nlearning and inferring on unlabeled visual data, and carry out thorough experiments to understand the\neffects of various Riemannian manifold regimes. We indeed conﬁrm our hypotheses and develop\nnovel VAE methods for utilizing the various manifold curvatures.\nOur main contributions1:\n1. Theoretical utilities of Riemannian manifolds for the generative model latent space, towards\nnaturally and efﬁciently embedding both normal data and sparse anomalous data.\n2. Proposal of Stereographic Projection Variational Auto-Encoders, towards unsupervised\nvisual anomaly detection. We derive a novel gyroplane layer for a neural network to be\ncapable of stereographic projections across hyperspherical and hyperbolic manifold shapes.\n3. Empirical analyses of our approach vs comparable methods on challenging benchmark\ndatasets for unsupervised visual anomaly detection, achieving state-of-the-art results.\n4. Neuropathology experiments that show our VAE method can reliably organize the various\nsubtypes of brain tissue without labels, and identify anomalous tissues samples as cancerous.\nWe further motivate the hyperbolic latent space by demonstrating Poincaré mapping, to\nvisualize the latent organization and reliably interpolate between regions of normal and\nabnormal brain tissue.\n2\nRepresentation Learning in Generative Vision\nFigure 1: The three regimes of constant curvature Riemannian manifolds, for which we can utilize the stereo-\ngraphic projections of the hyperboloid Hd\nc (left) and hypersphere Sd\nc (right) to respectively yield the Poincaré\nball Pd\nc and projected sphere Dd\nc manifolds. Example geodesic arcs of this projection are shown. The mapping is\nsmooth, bijective, and conformal (preserving the angles at which curves meet). This projection is necessary to\nyield manifolds with consistent modeling properties across the spectrum of curvatures c (see text for details).\n2.1\nProperties of Manifold Curvatures\nConsider a true data-generating process that draws samples x ∈M∗⊂RD according to x ∼p∗(x),\nwhere M∗is a d-dimensional Riemannian manifold embedded in the D-dimensional data space X,\n1Code will be open-sourced with camera-ready publication.\n2\nand d ≪D. We consider the two problems of estimating the density p∗(x) as well as the manifold\nM∗given some training samples {xi} ∼p∗(x).\nA deep generative model represents a mapping, g : Z →X, from a relatively low-dimensional\nlatent space Z ⊆Rd to a high-dimensional data space X ⊆RD. The learned manifold M is\na lower dimensional subset of X, the input space of images, and is embedded in Z under fairly\nweak assumptions on the generative model itself; a generative model with a suitable capacity of\nrepresentation will recover this smoothed approximation of M∗.\nWith respect to the (constant) curvature of M there are three regimes of Riemannian manifolds to\nconsider: Euclidean, \"ﬂat\" space Ed, with curvature c = 0; hyperspherical, positively curved space\nSd\nc, with c > 0; and hyperbolic, negatively curved space Hd\nc, with c < 0.\nBy deﬁnition of Riemannian geometry, the inner-product ⟨x, x⟩2 = 1\nc for both curved regimes Sd\nand Hd. So as c →0, both hyperspherical and hyperbolic spaces grow and become locally ﬂatter,\nand ⟨x, x⟩2 →±∞. This \"non-convergence\" property of constant curvature manifolds sends points\naway from the coordinate space origin in order to maintain the deﬁned curvature of M. We also\nobserve an instability as c →0: the hyperspherical and hyperbolic geodesic distance metrics do not\nconverge to the Euclidean distance metric. This is an undesirable property because we a priori must\nrestrict the manifold curvature while learning a deep generative model.\nOn the other hand, stereographically projected spaces for both the hypersphere and hyperboloid\nmanifold classes inherit the desirable properties from hyperspherical and hyperbolic spaces, while\navoiding this property of sending a point to inﬁnity when the curvature of the space has a small\nabsolute value. This projection function is deﬁned as follows, for a manifold Mk of curvature k ∈R:\nπk : R × Rn →Mk\n(ξ, x) 7→\nx\n1 +\np\n|k|ξ\nπ−1\nk : Mk →R × Rn\ny 7→(\n1\np\n|k|\n1 −k∥y∥2\n2\n1 + k∥y∥2\n2\n,\n2y\n1 + k∥y∥2\n2\n)\n(1)\nwhere (ξ, x) is a point in the ambient space of Mk, Rn+1.2\nThe stereographic projections relative to the three Riemannian manifold regimes are illustrated in Fig.\n1. Later we detail a novel gyroplane layer for performing the stereographic projections in the context\nof a deep generative neural network.\nFrom Eq. 1 we realize several advantageous properties on these two projected spaces:\nThe Möbius sum of two elements has the same structure for both projected spaces, returns an\nelement of the same space, and only involves the Euclidean inner product (identical for every\npoint). This has the nice consequence that the distance function in projected spaces only uses\nthe Euclidean inner product, instead of the inner product induced by the metric tensors of the\nmanifold, which varies on each point of the manifold.\nThe conformal projection preserves angles, and the distance functions in the hyperbolic and\nhyperspherical spaces only depend on angles between vectors. This implies the hyperbolic (resp.\nhyperspherical) space and the Poincaré ball (resp. projected hypersphere) are isometric.\nIt is for these reasons we develop deep generative models with these two projected spaces.\nIf we denote cosk the function that corresponds to cos if k > 0 and cosh if k < 0 (and similarly for\nsink and tank), the distance function on stereographically projected spaces is:\n∆Mk (zi, zj) =\n1\np\n|k|\ncos−1\nk\n\n1 + 2k\n∥zi −zj∥2\n\u0010\n1 + k ∥zi∥2\u0011 \u0010\n1 + k ∥zj∥2\u0011\n\n\n2Skopek et al. [42] similarly deﬁne such a projection function. We note our work was done concurrently, and\nindeed much of the ﬁndings are complimentary.\n3\nwhereas the gyroscopic distance function on stereographically projected spaces takes a simpler form:\n∆Mk (zi, zj) =\n2\np\n|k|\ntan−1\nk\n\u0010p\n|k|∥−x ⊕k y∥2\n\u0011\n(2)\nwith ⊕k representing the Mobius addition.\nAn advantage of a smooth, regularized latent embedding space is the ability to interpolate between\ndata points; see Fig. 2. Interestingly, Shao et al. [41] show straight lines in the latent space are\nrelatively close to geodesic curves on the manifold, explaining why traversal in the latent space results\nin visually plausible changes to the generated data. This may work for toy datasets such as MNIST\nand low-quality natural images (such as CelebA faces dataset). However, in real-world images we\nsuggest the curvilinear distances in the original data metric are not well enough preserved. Even more,\nwe hypothesize the observations of Shao et al. [41] will not extend beyond the standard Euclidean\nmanifold to c ̸= 0. We explore this empirically with large, complex images in histopathology datasets\nlater.\nFigure 2: The Poincaré ball provides meaningful geodesics for latent hierarchies, and a well-regularized space\nwhere interpolating along hyperbolic geodesics allows for reliable intermediate sampling and the prediction of\nunseen samples. Figure is revised from [25].\n2.2\nManifold Learning with VAEs\nOur aim is learning manifolds for unsupervised anomaly detection. As such we focus on the\nVariational Auto-Encoder (VAE) [24, 38] class of deep generative models. We refer the reader to our\nRelated Work section later for treatment on comparable Generative Adversarial Networks (GANs)\n[15, 37].\nThe VAE is a latent variable model representing the mapping Z →X, with an encoder gφ stochasti-\ncally embedding observations in the low-dimensional latent space Z, and a decoder fθ generating\nobservations x ∈X from encodings z ∈Z. The model uses two neural networks to respectively\nparameterize the likelihood p(·|fθ(z)) and the variational posterior q(·|gφ(x)).\nTypically the prior distribution p(z) assigned to the latent variables is a standard Gaussian. Recent\nwork suggests this limits the capacity to learn a representative latent space (such as [30, 9], and others\ndiscussed later in the Related Work section). We consider that the limitations of the prior are not due\nto a limitation in terms of capacity of representation, but more so in terms of principle. Similar to\n[22], we identify two major drawbacks of using the Euclidean manifold for the latent space:\nLack of learned semantics.\nThe ﬁrst drawback resides in the fact that a Normal distribution\nor a Gaussian mixture (in a Euclidean space) can be re-parameterized in a manner that does\nnot portray any semantic meaning for the latent data. For instance, a mixture of Gaussians can\nbe simply re-parameterized by a random permutation of the indices of each component in the\nmixture ([7]); while the re-parameterization is valid, the semantic meaning we associate to it is\ndrastically different. This can rotate arbitrarily the principal components of the Euclidean latent\nspace, and the Euclidean distance will not have a relevant meaning in terms of visual or semantic\ncloseness in the latent space. Moreover, as has been described in [5, 18], if the decoder has a\nsufﬁcient capacity of representation, it will be able to revert any re-parameterization applied in\nthe latent space. This has the consequence that a speciﬁc value in the latent space Z may not\nbe associated with a unique speciﬁc value in X. In the context of anomaly detection, this could\n4\nresult in anomalous samples aligning closer to the larger groups of normal samples rather than to\nother anomalous samples, resulting in false negatives for entire subgroups of anomalies.\nIrrelevant isotropic sampling.\nSecondly, Zhu et al. [51] suggest that human interpretable\nimages live on a speciﬁc manifold, the \"natural images manifold\", noted M here. This manifold\nis a lower dimensional subset of X, the input space of images, and is embedded in Z under\nfairly weak assumptions on the network architecture. An encoder with a suitable capacity of\nrepresentation will recover a smoothed approximation of M. This can create a latent space\nwith a signiﬁcant variable density in terms of latent samples; if our prior distribution is an\nisotropic Gaussian for instance, samples will be drawn in a rather isotropic manner, even though\nthe distribution of latent samples may not have any sample in this speciﬁc area. As such, the\nsampling procedure in the latent space can return samples that are not relevant. Moreover, a likely\nconsequence of this aforementioned embedding is the \"manifold mismatch\", or its statistical\nequivalent \"density mismatch\" [9, 12]. Under the assumption of a prior distribution with an inﬁnite\nsupport, the VAE may try to map M anywhere in the space Z, and could lead to convergence\nissues.\nGiven the requirements of the visual anomaly detection problem, it is highly desirable to have\na semantically meaningful topology which automatically embeds data according to hidden data\nstructure, and from which we can reliably sample despite empty regions due to sparsely distributed\ndata points. This leads us to think that an Euclidean latent space may not capture enough topological\nproperties for visual anomaly detection.\n3\nStereographic Projections VAE\nOur aim is to construct a Poincaré ball latent space Z = Pd\nc (as shown in Fig. 1), and supporting\nencoder gφ(z|x) and decoder fθ(x|z) networks in order to learn a mapping from this latent space to\nthe observation space X.\nParametrising distributions on the Poincaré ball\nThe choice of the probability distribution\nfamily for both the prior and the posterior (as the likelihood still lives in the Euclidean space), can\nbe done similarly as in the Euclidean space. There are two distinct philosophies for adapting the\nNormal distribution to a Riemannian space. The ﬁrst approach is to consider the Euclidean space\nthat is tangent at every point z in the manifold, and sample from a zero-mean Euclidean Normal\ndistribution in this tangent space. Then, the sampled point on the tangent space is mapped to the\nmanifold through parallel transport and the exponential map. This is known as as the \"wrapping\"\napproach. In the second approach, we can maximize the entropy of the distribution to derive what is\nknown as the Riemannian Normal. While the latter is the only form of distribution that is proven to\nmaximize the entropy, both distributions perform similarly in practice. Hence, we choose to use the\nWrapped Normal, as it is easier to sample from. We refer to both as Hyperbolic Normal distributions\nwith pdf NBdc\n\u0000z|µ, σ2\u0001\n. We also deﬁne the prior on Z as the Hyperbolic Normal, with mean zero:\np(z) = NBd\nc\n\u0000·|0, σ2\n0\n\u0001\n.\nSP-VAE Architecture\nJust as in the case of a Euclidean latent space, this network is optimized by\nmaximizing the evidence lower bound (ELBO), via an unbiased Monte Carlo (MC) estimator thanks\nto reparametrisable sampling schemes introduced in [30, 14]. It was proven in [30] that the ELBO\ncan be extended to Riemannian latent spaces by applying Jensen’s inequality w.r.t. the measure on the\nmanifold. We use β-VAE [20], a variant of VAE that applies a scalar weight β to the KL term in the\nobjective function, as it has been shown empirically that the β-VAE improves the disentanglement\nof different components of the latent space when β > 1. As we want to compare the shape of the\nlatent manifold for visual anomaly detection in real-world applications, we chose the encoder and\ndecoder backbones as a 4-layer convolutional network; simple enough to be able to compare all three\ncurvature conﬁgurations, but able to learn the representation of complex images. Just as in [30, 42],\nwe use an exponential map to transform the mean of the distribution from the encoder, and then use a\ngyroplane layer to go back from the Riemannian latent space to the Euclidean space, in order to take\ninto account the shape of the manifold when applying a linear layer.\n5\n3.1\nGyroplane Layer\nAs described in [14] and [30], the ﬁrst layer of a decoder in a VAE whose latent manifold is Euclidean\nand n-dimensional is often a linear layer. A linear layer is an afﬁne transform, and can be written\nin the form fa,b : x 7→⟨a, x −b⟩, with x, a the orientation parameter, and b the offset parameter,\nelements of Rn. This expression can be rewritten as fa,b(x) = sgn(⟨a, x −b⟩)∥a∥∆E(x, Ha,b),\nwhere Ha,b = {x ∈Rn|⟨a, x −b⟩= 0} = b + {a}T is the hyperplane oriented by a with offset b.\nIn the stereographically projected sphere manifold Dn\nk, the hyperplane is of the form Hk\na,p = {z ∈\nDn\nk|⟨a, −p ⊕k z⟩= 0}; we provide the full proof in Supplementary materials. The distance of a point\nz ∈Dn\nk to Hk\na,p takes the following form:\n∆k(x, Hk\na,p) =\n1\n√\nk\narcsin\n \n2\n√\nk|⟨−p ⊕k z, a⟩|\n(1 −k∥−p ⊕k z∥2)∥a∥\n!\n(3)\nThis expression was intuitively attainable from [30, 14], but here we provide thorough derivation and\nrationale.\n4\nRelated Work\nVAE and Riemannian Manifolds\nIn Variational Auto-Encoders (VAEs) [24, 38], the prior distri-\nbution p(z) assigned to the latent variables is typically a standard Gaussian. It has, unfortunately,\nturned out that this choice of prior is limiting the modeling capacity of VAEs and richer priors have\nbeen proposed: Tomczak and Welling [44] propose VampPrior, a method for the latent distribution to\ninstead be a mixture of Gaussians. van den Oord et al. [46] propose VQ-VAE, a way to encode more\ncomplex latent distributions with a vector quantization technique. In [27], Klushyn et al. proposed a\nhierarchical prior through an alternative formulation of the objective. In [6], Bauer et al. propose to\nreﬁne the prior through a sampling technique. Several notable VAEs with non-Euclidean latent spaces\nhave been developed recently: Davidson et al. [9] make use of hyperspherical geometry, Falorsi\net al. [12] endow the latent space with a SO(3) group structure, Grattarola et al. [16] introduce an\nadversarial auto-encoder framework with constant curvature manifold. However, in these methods\nthe encoder and decoder are not designed to explicitly take into account the latent space geometries.\nSame goes for Ovinnikov [34], who proposed to use a Poincaré ball latent space, but were not able to\nderive a closed-form solution of the ELBO’s entropy term. Mathieu et al. [30] propose the Poincaré\nVAE, closely aligned with our work. We extend it mainly to consider practical properties of the\nmanifold geometries towards real applications, arriving at the stereographic projection mechanisms.\nThe method most related to the current paper is mixed-curvature VAE from Skopek et al. [42]. They\nsimilarly deﬁne a projection across hyperboloid and hypersphere spaces for use in VAEs. Our work\nwas done concurrently, and much of the ﬁndings are complimentary.\nVisual Anomaly Detection\nAnomaly detection is a deep ﬁeld with many application areas in\nmachine learning. We focus on the image domain, referring the reader to Chandola et al. [8], Pimentel\net al. [36] and references therein for full surveys of the ﬁeld. A promising area in visual anomaly\ndetection is reconstruction-based methods, with recent works that train deep autoencoders to detect\nanomalies based on reconstruction error [50, 48, 52]. For example, Zhai et al. [48] use a structured\nenergy based deep neural network to model the training samples, and Zong et al. [52] proposed to\njointly model the encoded features and the reconstruction error in a deep autoencoder. Although\nthe reconstruction-based methods have shown promising results, their performances are ultimately\nrestricted by the under-designed representation of the latent space. While we focus on images,\nthere exist methods for videos such as applying PCA with optical ﬂow methods [23] and RNNs for\nnext-frame predictions [29]. Schlegl et al. [40] applied Generative Adverserial Networks (GANs) to\nthe task of VAD. Their AnoGAN was succeeded my the more efﬁcient EGBAD that uses a BiGAN\napproach [47]. In [1],the combination of a GAN and autoencoder was introduced. For more on GANs\nin anomaly detection please refer to [31]. We compare against GANs in the Experiments section,\nand show superior results with our VAE method. Even more, VAEs are a preferable class of deep\ngenerative models because they provide a natural probabilistic formulation, readily work with various\npriors, and are easier to train.\n6\n5\nExperiments\n5.1\nVisual Anomaly Detection Problem Setup\nIn this paper we consider two related but distinct problems of unsupervised anomaly detection\nin images: scoring and localization. Let X be the space of all images in our domain of interest,\nand let X ⊆X be the set of images deﬁned as normal. We investigate two different metrics: the\nreconstruction error probability, which can be used for both tasks, as well as the ELBO derivative\nwith respect to the input. For scoring, we use the average value (µrec) and standard deviation (σrec)\nof the reconstruction error on all pixels on the test set, and take a threshold at µrec + 1.5σrec. The\nproducing a mask from this result gives us the anomaly localization.\nWe evaluated our approach on several benchmark datasets for visual anomaly detection. Importantly,\nwe focus on those with real-world images. Prior works limit evaluations to MNIST and Omniglot\ndatasets, which are not representative of natural images.\n5.2\nCrack Segmentation & PCB Defects Benchmarks\nWe experiment on two benchmark anomaly detection datasets of real-world images. The Crack\nSegmentation dataset contains images of cracked surfaces (brick walls, concrete roads, lumpy surfaces,\netc.), concatenating images from several datasets: Crack 500 [49], CrackTree200 [53] and AELLT\n[3], and others.3 We also experiment with the PCB Dataset [21] for defect detection in precision\nmanufacturing. The dataset contains 3597 training images, 1161 validation images, and 1148 testing\nimages, at various resolutions. The dataset is made from defect-free images, and defects are added in\nimages with annotations, including positions of the six most common types of PCB defects (open,\nshort, mousebite, spur, pin hole, and spurious copper).\nFigure 3: 2-D Poincaré Ball Embeddings for the PCB dataset, with SVDD scores level lines. Purple points are\nnormal instances, others are anomalous instances.\nIn constructing the PCB dataset, PCB images were divided in non-overlapping 128 × 128 patches.\nPatches that contain anomalous pixels where stored in the anomalous set of patches and the remaining\npatches in the \"normal\" set Dnormal. Due to the creation process for this dataset, the \"anomaly\" set has\n3Crack Segmentation dataset is available at github.com/khanhha/crack_segmentation.\n7\na larger amount of elements than the \"normal\" set. In order to ﬁt usual real industrial inspection data\ndistribution, a random subset of the anomalous samples was selected, with nanomaly = 0.1|Dnormal|.\nIn order to obtain the Poincaré embeddings for the PCB dataset, we adapted unsupervised anomaly\ndetection method Deep SVDD [39] for the Poincaré ball latent space. The Auto-Encoder (AE) used a\nResNet-18 ([19]) backbone for the encoder, followed by a logk\n0-map and two hyperbolic linear layers\nto obtain feature vectors in the Poincaré ball manifold; the latent space is 2-dimensional. The decoder\nwas composed of an expk\n0-operator followed by a deconvolutional ResNet-18 as the backbone. The\nAE was pretrained for 350 epochs, with the Riemannian Adam optimizer from the Geoopt library\n([28]), and a learning rate of 10−4 in the ﬁrst 250 epochs and 10−5 for the remaining epochs.\nThe second step of the Deep SVDD method starts with center-initialization. In the Euclidean case,\nthe initialization is accomplished by averaging all the features vectors from the training set as output\nby the trained encoder. In the hyperbolic case, with feature vectors on the Poincaré ball, we computed\nthe gyrobarycenter instead of the Euclidean average. Then, the encoder was ﬁne-tuned with the\nfollowing loss:\nL =\nn\nX\ni=1\n∆k(x, c)2 + λ\nW\nX\nk=1\n∥wk∥2\n(4)\nwith c, the initialized center, {wk}k∈{0,...,W } the weights of the encoder, and λ = 5 × 10−7 the L2\nregularization parameter. The encoder was then trained with the SVDD objective, formulated for the\nPoincaré ball manifold, also with the Riemannian Adam optimizer and the optimization parameters\nfrom the original paper for 150 epochs.\nAnomaly scores were computed as: dk(φ(x), c), with x an input sample, c the center as deﬁned in\nour previous gryrobarycenter calculation, and φ the mapping learning by the encoder. The radius of\nthe hyperbolic \"sphere\" was selected similarly to the Deep SVDD paper, as the 90%-ile of the the\ncomputed scores on the testing set. All samples whose score exceeded this radius were classiﬁed as\nanomalies, as shown in Fig. 3. We applied the hyperbolic UMAP algorithm (with nneighbors = 50\nand distmin = 0.001) to produce easily interpretable ﬁgures for the Poincaré embeddings, with level\nlines of the anomaly score function inside the ball.\nBelow are results for both visual anomaly detection tasks, on these two datasets:\nDatasets\nPrecision\nRecall\nF1\nIoU\nCrack segmentation\n0.4206\n1.0\n0.5921\n0.5470\nPCB\n0.4514\n0.9228\n0.6063\n0.2942\nTable 1: Euclidean, dimension 6\nDatasets\nPrecision\nRecall\nF1\nIoU\nCrack segmentation\n0.4205\n1.0\n0.4205\n0.5083\nPCB\n0.4462\n0.9520\n0.6076\n0.2911\nTable 2: Projected Sphere, dimension 6\nDatasets\nPrecision\nRecall\nF1\nIoU\nCrack segmentation\n0.42055\n0.9994\n0.59199\n0.5087\nPCB\n0.4264\n0.9530\n0.5801\n0.2950\nTable 3: Poincaré Ball, dimension 6\nOverall, all three manifolds perform similarly across datasets. On images with very orthogonal\nfeatures, the Euclidean manifold seems to perform better, both on the scoring and segmentation\ntasks. For crack images, which contain very non-linear cracks, the Poincaré ball performs best for the\nlocalization tasks.\n5.3\nApplication in Histopathology\nWe investigated the applicability of our approach to the challenging task of diagnostic neuropathology,\nthe branch of pathology focused on the microscopic examination of neurosurgical specimens. We\nexperimented with a dataset of H&E-stained whole-slide images (WSI) of a glioblastoma containing\n8\nFigure 4: Poincaré ball of the learned latent embedding, showing a structure that separates cancerous tissue (top)\nfrom normal tissue (bottom) and non-tissue (e.g. surgical material). We also see some semantically meaningful\nhierarchy develop; the manifold center splits normal and ab-normal tissues, and progressing down the branch of\ncancerous tissue we see patterns such as cohesive lesions (meningioma and metastasis) being arranged close\ntogether. Importantly this organization is learned unsupervised. Figure is best viewed in color.\na heterogeneous mixture of tumor, necrosis, brain tissue, blood and surgical material. See the\nSupplement for dataset details.\nManual inspection of WSI to sufﬁciently search for metastatic cells amongst normal cells is infeasible;\na single WSI may contain millions of lymphocytes, nucleotides, and other cells for inspection.\nAutomated and unsupervised computer vision methods could prove invaluable. Even more, the\ntask of diagnosis can be error-prone and subjective. For one, overlapping patterns of the most\ncommon brain tumor types – gliomas, meningiomas, schwannomas, metastases, and lymphomas\n– present a challenge. Even more, although these ﬁve tumor types represent the majority of cases\nencountered in clinical practice (∼75–80%), there are over 100 different brains tumor subtypes to be\nconsidered, many of which are exceedingly rare [11]. Similarly, new diseases (e.g. Zika encephalitis)\ncontinually arise. For these reasons, we hypothesize the latent hierarchical representation learned by\nour Stereographic Projection VAE can delineate these complex subtypes while providing a continuous\ntrajectory relating any two points.\nThe experiment setup was as follows: We trained unsupervised on a dataset of 1024 x 1024 pixel\nimages tiled from WSIs, representing eight non-lesional categories (hemorrhage, surgical material,\ndura, necrosis, blank slide space, and normal cortical gray, white, and cerebellar brain tissue), and the\naforementioned ﬁve common lesional subtypes (gliomas, meningiomas, schwannomas, metastases,\nand lymphomas). Fig. 4 shows example patches from each of these categories, displayed across the\nlearned hyperbolic manifold. The Supplement additionally contains WSI examples and data details.\nThe model used here is the same as in the experiments described earlier, but for a slight change in the\nβ parameter: We used a simulated annealing approach to progressively update β as a function of the\nreconstruction loss during training. Some methods simply use a linear increase schedule for β, but\nsuch predeﬁned schedules may be suboptimal. The method is not unlike that of Klushyn et al. [26],\nfor which we provide details in the Supplementary materials.\n9\nFigure 5: Interpolation along the learned manifold from normal grey matter brain tissue (left) to cancerous glioma\ntissue (right). The top row represents samples along the geodesic path, while the bottom represents samples\nfrom the linear approximation. We ﬁnd that interpolating along the curved manifold yields intermediary samples\nthat are reasonable tissue images, perhaps representing true intermediate cellular states. Linear interpolation\ncomparatively yields blurred intermediary structures. For example, notice the center-top white gap structure\nthat grows organically as the geodesic samples progress from normal to cancerous. Comparatively, the linear\nsamples on the bottom row show unnatural blending. Note both rows are sub-sampled from the latent space\nlearned by our Stereographic Projection VAE, but along different interpolation paths. The Euclidean latent space\nof a β-VAE yielded blurry samples without cellular structures.\nWe ﬁnd that our model learns a latent hierarchical embedding that organizes the distributions of normal\ntissue, non-tissue materials, and cancerous tissue, shown in Fig. 4. Not to mention the manifold\nembedding reveals interpretable semantics of known and potentially unknown tissue relationships.\nIn the context of unsupervised visual anomaly detection, we learn this latent embedding without\nlabels, and identify cancerous tissues as sparse anomalies that are distributed on Poincaré ball regions\nopposite normal tissue. If we then train a classiﬁer on the anomalous samples that are discretized by\nthe unsupervised embedding, we achieve a classiﬁcation performance of > 0.97 across the ﬁve disease\nsubtypes, as assessed by the areas under the multi-class receiver operator curve (AUC, mROC); this is\nconsistent with the classiﬁcation scheme and state-of-the-art results in the fully supervised approach\nof [13]).\nAs mentioned earlier, interpolation in the latent space of a Euclidean VAE is possible because,\nfor simple data regimes, the linear interpolation metric closely approximates the true geodesic\ncurves. We suggest this approximation does not necessarily hold when using a non-Euclidean latent\nspace, particularly when the deep generative model is learning in a complex image space where\ncurvature plays a more prominent role. We investigate this by carrying out geodesic interpolations and\ncomparing these with the corresponding linear counterparts in Z space. We use Eqn. 2 to estimate the\ngeodesic curve connecting a given pair of images on the generated manifold, discretizing the curve at\n10 points. To get an image on the generated manifold, we pick a real image x from the dataset and\nuse g(h(x)) to get the corresponding point on the generated manifold. Fig. 5 shows example linear\nand geodesic interpolations between the same endpoints on Z. We ﬁnd the linear approximations\nto be unreliable, counter to prior ﬁndings that focused on Euclidean manifolds [41] and relatively\nsimple images.\nEven more, we suggest the linear approximation can yield calibration errors when probing for speciﬁc\npoints along an interpolation \"arc\", particularly with long-range interpolations between sparse data\npoints that arise in anomaly detection settings. We elucidate this in Fig. 5. In scientiﬁc endeavors such\nas interpolating between known and rare brain tumor representations, we need points that reliably lie\non the manifold surface such that generated images represent plausible samples.\n6\nConclusion\nIn this paper we explored Riemannian manifolds in deep generative neural networks towards unsuper-\nvised visual anomaly detection. Key insights were derived from investigations into speciﬁc properties\nof Riemannian curvatures that best enable natural and efﬁcient embedding of both normal data and\nsparse anomalous data. To work with such manifolds in the context of Variational Auto-Encoders\n10\n(VAEs), we derived a gyroplane layer that enables stereographic projections between hyperspherical\nand hyperbolic latent spaces: a Stereographic Projection VAE. Empirically we found our hypotheses\nto be valid, and matched state-of-the-art results on real world benchmarks. We also made valu-\nable observations regarding manifold interpolations and sampling, ﬁnding linear approximations of\ngeodesic curves to be unreliable. In the challenging domain of neuropathology, our model learns a\nlatent hierarchical organization of brain cancer subtypes and other tissues, despite not using labels.\nUsing Poincaré mapping we effectively interpolate across the manifold, yielding reliable intermediate\nsamples from the manifold. Without this capability, a deep generative model does not necessarily\nsatisfy the manifold hypothesis for natural images. Future work would be to continue development\nof our approach in histopathology, as this can be a valuable decision support tool for pathologists,\nand can theoretically be applied to diverse tissue and disease classes. We would also like to continue\nworking with Poincaré mapping and other methods that can derive insights directly from the rich\nlatent space.\nReferences\n[1] Samet Akçay, Amir Atapour Abarghouei, and Toby P. Breckon. Ganomaly: Semi-supervised\nanomaly detection via adversarial training. ArXiv, abs/1805.06725, 2018.\n[2] Alexander A. Alemi, Ben Poole, Ian S. Fischer, Joshua V. Dillon, Rif A. Saurous, and Kevin\nMurphy. Fixing a broken elbo. In ICML, 2018.\n[3] Rabih Amhaz, Sylvie Chambon, Jérôme Idier, and Vincent Baltazart. Automatic crack detection\non two-dimensional pavement images: An algorithm based on minimal path selection. IEEE\nTransactions on Intelligent Transportation Systems, 17:2718–2729, 2016.\n[4] Jinwon An and Sungzoon Cho. Variational autoencoder based anomaly detection using recon-\nstruction probability. 2015.\n[5] Georgios Arvanitidis, Lars Kai Hansen, and Søren Hauberg. A locally adaptive normal distribu-\ntion, 2016.\n[6] Matthias Bauer and Andriy Mnih. Resampled priors for variational autoencoders, 2018.\n[7] Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and\nStatistics). Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738.\n[8] Varun Chandola, Arindam Banerjee, and Vipin Kumar. Anomaly detection: A survey. ACM\nComput. Surv., 41:15:1–15:58, 2009.\n[9] Tim R. Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, and Jakub M. Tomczak. Hyper-\nspherical variational auto-encoders. In UAI, 2018.\n[10] Lucas Deecke, Robert A. Vandermeulen, Lukas Ruff, Stephan Mandt, and Marius Kloft. Image\nanomaly detection with generative adversarial networks. In ECML/PKDD, 2018.\n[11] Quinn Ostrom et al. Cbtrus statistical report: primary brain and central nervous system tumors\ndiagnosed in the united states in 2007-2011. Neuro Oncol, 16 Suppl 4:iv1–63, 2014.\n[12] Luca Falorsi, Pim de Haan, Tim R. Davidson, Nicola De Cao, Maurice Weiler, Patrick Forré,\nand Taco S. Cohen. Explorations in homeomorphic variational auto-encoding, 2018.\n[13] Kevin Faust, Quin Xie, Dominick Han, Kartikay Goyle, Zoya I. Volynskaya, Ugljesa Djuric,\nand Phedias Diamandis. Visualizing histopathologic deep learning classiﬁcation and anomaly\ndetection using nonlinear feature space dimensionality reduction. BMC Bioinformatics, 19,\n2018.\n[14] Octavian-Eugen Ganea, Gary Bécigneul, and Thomas Hofmann. Hyperbolic neural networks,\n2018.\n[15] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil\nOzair, Aaron C. Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.\n11\n[16] Daniele Grattarola, Lorenzo Livi, and Cesare Alippi. Adversarial autoencoders with constant-\ncurvature latent manifolds. Appl. Soft Comput., 81, 2019.\n[17] Bijan Haney and Alexander Lavin. Fine-grain few-shot vision via domain knowledge as\nhyperspherical priors. In CVPR Workshop on Fine-grained Categorization, 2020.\n[18] Søren Hauberg. Only bayes should learn a manifold (on the estimation of differential geometric\nstructure from data), 2018.\n[19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image\nrecognition. CoRR, abs/1512.03385, 2015. URL http://arxiv.org/abs/1512.03385.\n[20] Irina Higgins, Loïc Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew M\nBotvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts\nwith a constrained variational framework. In ICLR, 2017.\n[21] Weibo Huang and Peng Wei. A pcb dataset for defects detection and classiﬁcation, 2019.\n[22] Dimitris Kalatzis, David Eklund, Georgios Arvanitidis, and Søren Hauberg. Variational autoen-\ncoders with riemannian brownian motion priors, 2020.\n[23] Jaechul Kim and Kristen Grauman. Observe locally, infer globally: A space-time mrf for\ndetecting abnormal activities with incremental updates. In CVPR, 2009.\n[24] Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114,\n2014.\n[25] Anna Klimovskaia, David Lopez-Paz, Léon Bottou, and Maximilian Nickel. Poincaré maps for\nanalyzing complex hierarchies in single-cell data. bioRxiv, 2019.\n[26] Alexej Klushyn, Nutan Chen, Richard Kurle, Botond Cseke, and Patrick van der Smagt. Learn-\ning hierarchical priors in vaes. ArXiv, abs/1905.04982, 2019.\n[27] Alexej Klushyn, Nutan Chen, Richard Kurle, Botond Cseke, and Patrick van der Smagt. Learn-\ning hierarchical priors in vaes, 2019.\n[28] Max Kochurov, Rasul Karimov, and Serge Kozlukov. Geoopt: Riemannian optimization in\npytorch, 2020.\n[29] Weixin Luo, Wen Liu, and Shenghua Gao. A revisit of sparse coding based anomaly detection\nin stacked rnn framework. 2017 IEEE International Conference on Computer Vision (ICCV),\npages 341–349, 2017.\n[30] Emile Mathieu, Charline Le Lan, Chris J. Maddison, Ryota Tomioka, and Yee Whye Teh.\nContinuous hierarchical representations with poincaré variational auto-encoders. In NeurIPS,\n2019.\n[31] Federico Di Mattia, Paolo Galeone, Michele D. Simoni, and Emanuele Ghelﬁ. A survey on\ngans for anomaly detection. ArXiv, abs/1906.11632, 2019.\n[32] Pascal Mettes, Elise van der Pol, and Cees G. M. Snoek. Hyperspherical prototype networks.\nIn NeurIPS, 2019.\n[33] Maximilian Nickel and Douwe Kiela. Poincaré embeddings for learning hierarchical represen-\ntations. ArXiv, abs/1705.08039, 2017.\n[34] Ivan Ovinnikov. Poincaré wasserstein autoencoder. ArXiv, abs/1901.01427, 2019.\n[35] Stanislav Pidhorskyi, Ranya Almohsen, Donald A. Adjeroh, and Gianfranco Doretto. Generative\nprobabilistic novelty detection with adversarial autoencoders. In NeurIPS, 2018.\n[36] Marco A. F. Pimentel, David A. Clifton, Lei A. Clifton, and Lionel Tarassenko. A review of\nnovelty detection. Signal Process., 99:215–249, 2014.\n[37] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with\ndeep convolutional generative adversarial networks. CoRR, abs/1511.06434, 2015.\n12\n[38] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation\nand approximate inference in deep generative models. In ICML, 2014.\n[39] Lukas Ruff, Nico Görnitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Robert A. Vandermeulen,\nAlexander Binder, Emmanuel Müller, and Marius Kloft. Deep one-class classiﬁcation. In ICML,\n2018.\n[40] Thomas Schlegl, Philipp Seeböck, Sebastian M. Waldstein, Ursula Schmidt-Erfurth, and Georg\nLangs. Unsupervised anomaly detection with generative adversarial networks to guide marker\ndiscovery. In IPMI, 2017.\n[41] Hang Shao, Abhishek Kumar, and P. Thomas Fletcher. The riemannian geometry of deep\ngenerative models. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\nWorkshops (CVPRW), pages 428–4288, 2018.\n[42] Ondrej Skopek, Octavian-Eugen Ganea, and Gary Bécigneul. Mixed-curvature variational\nautoencoders. arXiv preprint arXiv:1911.08411, 2019.\n[43] Alexandru Tifrea, Gary Becigneul, and Octavian-Eugen Ganea. Poincare glove: Hyperbolic\nword embeddings. In International Conference on Learning Representations, 2019.\n[44] Jakub M. Tomczak and Max Welling. VAE with a vampprior. CoRR, abs/1705.07120, 2017.\nURL http://arxiv.org/abs/1705.07120.\n[45] Abraham Ungar. A Gyrovector Space Approach to Hyperbolic Geometry, volume 1. 01 2009.\ndoi: 10.2200/S00175ED1V01Y200901MAS004.\n[46] Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. Neural discrete representation\nlearning, 2017.\n[47] Houssam Zenati, Chuan Sheng Foo, Bruno Lecouat, Gaurav Manek, and Vijay Ramaseshan\nChandrasekhar. Efﬁcient gan-based anomaly detection. ArXiv, abs/1802.06222, 2018.\n[48] Shuangfei Zhai, Yu Cheng, Weining Lu, and Zhongfei Zhang. Deep structured energy based\nmodels for anomaly detection. ArXiv, abs/1605.07717, 2016.\n[49] Lei Zhang, Fan Yang, Yimin Daniel Zhang, and Ying Julie Zhu. Road crack detection using\ndeep convolutional neural network. In Image Processing (ICIP), 2016 IEEE International\nConference on, pages 3708–3712. IEEE, 2016.\n[50] Chong Zhou and Randy C. Paffenroth. Anomaly detection with robust deep autoencoders.\nProceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and\nData Mining, 2017.\n[51] Jun-Yan Zhu, Philipp Krähenbühl, Eli Shechtman, and Alexei A. Efros. Generative visual\nmanipulation on the natural image manifold. Lecture Notes in Computer Science, page 597–613,\n2016.\n[52] Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Dae ki Cho, and\nHaifeng Chen. Deep autoencoding gaussian mixture model for unsupervised anomaly detection.\nIn ICLR, 2018.\n[53] Qin Zou, Yu Cao, Qingquan Li, Qingzhou Mao, and Song Wang. Cracktree: Automatic crack\ndetection from pavement images. Pattern Recognition Letters, 33(3):227–238, 2012.\nSupplementary Materials\nA\nNotations\n• (H, W) ∈N2: height and width of input images\n• X: input image space, included in RH×W , considered Euclidean\n• Z ∈N: latent dimension\n13\n• Z: latent space, included in RZ, with Z ≪H × W\n• pdata : X →[0, 1]: probability distribution of the data\n• x ∼pdata: random variable draw in input space\n• pz : Z →[0, 1] prior probability\n• pφ(z|x): posterior probability distribution, learned by the encoder\n• pθ(x|z): likelihood distribution, learned by the decoder\nB\nGyroplane layer derivation\nHere we provide the proof of the gyroplane layer; it is similar to the one in [14], with the following\nexpression:\nThe distance of a point z ∈Dn\nk to Hk\na,p takes the form:\n∆k(x, Hk\na,p) =\n1\n√\nk\narcsin\n \n2\n√\nk|⟨−p ⊕k z, a⟩|\n(1 −k∥−p ⊕k z∥2)∥a∥\n!\n(5)\nB.1\nA few deﬁnitions\nHere are some deﬁnitions of notions we are going to use in the proof. They come from Riemannian\ngeometry and [45].\nDn\nk is a n-dimensional manifold. The tangent space at a point z ∈Dn\nk is noted TzDn\nk. The Riemannian\nmetric g = (gz)z∈Dn\nk is a set of inner products gz : TzDn\nk × TzDn\nk →R, varying in a smooth manner\nwith z.\nDeﬁnition .1 (Mobius addition). The Mobius addition is deﬁned as follows, for two points x, y ∈\nDn\nk:\nx ⊕k y = (1 −2k⟨x, y⟩−k∥y∥2)x + (1 + k∥x∥2)y\n1 −2k⟨x, y⟩+ k2∥x∥2∥y∥2\n(6)\nIt is worth noting that this addition is neither commutative nor associative, but it does have the\nfollowing properties, ∀x ∈Dn\nk:\n• x ⊕k 0Dk = 0Dk ⊕k x = x\n• (−x) ⊕k x = x ⊕k (−x) = 0Dk\n• ∀y ∈Dk, (−x) ⊕k (x ⊕k y) = y (left cancellation law)\nThe Mobius subtraction is simply deﬁned as x ⊖k y = x ⊕k (−y).\nDeﬁnition .2 (Gyroangle). For x, y, z ∈Dn\nk, we will denote by\nˆ\nyxz the angle between the two\ngeodesics starting from x and ending at y and z respectively. This angle, named the gyroangle can be\ndeﬁned either by the angle between the two initial velocities of each geodesic, u and v:\ncos ( [\n(u, v)) = ⟨u, v⟩\n∥u∥∥v∥\n(7)\nOr as:\ncos (d\nyxz) = ⟨\n−x ⊕k y\n∥−x ⊕k y∥,\n−x ⊕k z\n∥−x ⊕k z∥⟩\n(8)\nDeﬁnition .3. The Gyrodistance between two points x, y ∈Dn\nk is deﬁned as: d⊕k(x, y) = ∥y⊖kx∥.\nDeﬁnition .4. In [45], Ungar deﬁned a Gyroline as: ∀x, y ∈Dn\nk, ∀t ∈[0, 1], γ(t) = x ⊕k (⊖kx ⊕k\ny) ⊗k t, where ⊗k is the Mobius Scalar mutliplication in the Gyrogroup (Dn\nk, ⊕k), deﬁned as:\nt ⊗k v = ((1 +\n√\nk∥v∥)t −(1 −\n√\nk∥v∥)t)\n((1 +\n√\nk∥v∥)t + (1 −\n√\nk∥v∥)t)\n×\nv\n∥v∥\n(9)\n=\n1\n√\nk\ntan(t arctan(\n√\nk∥v∥)) v\n∥v∥\n(10)\n14\nSo the geodesic γx→y(t) = x ⊕k (⊖kx ⊕k y) ⊗k t, with γx→y : R →Dn\nk, that satisﬁes the following\nconstraints: γx→y(0) = x and γx→y(1) = y. If we use this deﬁnition, and do a reparametrization\nusing the gyrodistance deﬁnition to make this geodesic of constant speed, we obtain that the unit\nspeed geodesic starting at x ∈Dn\nk with direction v ∈TxDn\nk is:\nγx,v(t) = x ⊕k\n\u0012\ntan\n√\nk t\n2\nv\n√\nk∥v∥\n\u0013\n(11)\nwith γx,v : R →Dn\nk, that satisﬁes the following constraints: γx,v(0) = x and ˙γx,v(0) = v.\nDeﬁnition .5 (Log Map). The Log Map of the stereographically projected sphere is deﬁned, for x\nand y in Dn\nk:\nlogk\nx(y) =\n2\n√\nkλkx\narctan(\n√\nk∥−x ⊕k y∥)\n−x ⊕k y\n∥−x ⊕k y∥\n(12)\nDeﬁnition .6 (Exp Map). The Log Map of the stereographically projected sphere is deﬁned, for\nx ∈Dn\nk and v ∈TxDn\nk:\nexpk\nx(v) = x ⊕k tan(\n√\nk λk\nx∥v∥\n2\nv\n√\nk∥v∥\n)\n(13)\nB.2\nStereographically projected sphere hyperplane\nWe are deﬁning what an hyperplane in the stereographically projected sphere; the ﬁnal expression\nneeds justiﬁcation, so the proof follows the deﬁnition.\nDeﬁnition .7 (Stereographically projected sphere hyperplane). For a point p ∈Dn\nk, a point a ∈\nTpDn\nk \\{0}, let {a}⊥= {z ∈TpDn\nk|gp\nk(z, a) = 0}. Since gp\nk(z, a) = λk\nx\n2⟨z, a⟩and λk\np =\n2\n1+k∥p∥2 >\n0, ∀p ∈Dn\nk, we have that: {a}⊥= {z ∈TpDn\nk|⟨z, a⟩= 0}. The hyperplane in the stereographically\nprojected sphere is deﬁned as:\nHa,p = {z ∈TpDn\nk|⟨z, a⟩= 0}\n= {x ∈Dn\nk \\ p|⟨logk\np(x), a⟩p = 0}\n[\n{p}\n(14)\n= {x ∈Dn\nk|⟨−p ⊕k x, a⟩= 0}\n(15)\nProof. If z = p, ⟨z, a⟩= 0 by deﬁnition of the tangent space.\nIf z ̸= p, since arctan is a strictly increasing function on ] −π/2, π/2[→R, it is a bijection from\nR to [−π/2, π/2]. For a ﬁxed p ∈Dn\nk, f : x 7→−p ⊕k x is also a bijection so ∀z ∈TpDn\nk, ∃!x ∈\nDn\nk s.t. z = logk\np(x), which proves equality 14.\nStill in the case of z ̸= p:\n⟨logk\np(x), a⟩p = 0 ⇔\n2\n√\nkλkp\narctan\n√\nk∥−p ⊕k x∥⟨\n−p ⊕k x\n∥−p ⊕k x∥, a⟩= 0\n(16)\n⇔arctan (\n√\nk∥−p ⊕k x∥) = 0 or ⟨\n−p ⊕k x\n∥−p ⊕k x∥, a⟩= 0\n(17)\n⇔⟨\n−p ⊕k x\n∥−p ⊕k x∥, a⟩= 0\n(18)\n16 is obtained by deﬁnition of the logarithm map of Dn\nk. Since\n2\n√\nkλkp > 0 , we obtain 17. Finally,\nsince\n√\nk∥−p ⊕k x∥> 0 (x ̸= p), then arctan (\n√\nk∥−p ⊕k x∥) > 0, so we obtain 18. Lastly, if\nx = p, 15 is still true, which achieves the proof.\n15\nB.3\nDistance to hyperplane\nWe are going to proceed in four steps: ﬁrstly, we need to prove the existence and unicity of the\northogonal projection of a point in the manifold on a geodesic that does not go through this point.\nThen, we will prove that this projection in fact minimizes the distance between the point and the\ngeodesic. Then, we will prove that geodesics that pass through 2 points of an hyperplane belong\nentirely to that hyperplane, and ﬁnally, we will ﬁnd the explicit expression of this distance.\nExistence and Unicity of an orthogonal projection on a geodesic\nThanks to the preliminary\ntheorem, we know that the orthogonal projection of a point x ∈Dn\nk on a given geodesic γ of Dn\nk that\ndoes not include x exists and is unique.\nMinimizing distance between a point and a geodesic\nThis projection minimizes the distance\nbetween the point x and the geodesic γ, since the hypotenuse in a spherical right triangle is strictly\nlonger than the two other sides of the rectangle (constant curvature space sine law).\nGeodesics in Hk\na,p\nLet Hk\na,p be an hyperplane in the stereographically projected sphere. Let w be a\npoint in Hk\na,p, such that w ̸= p. Let us consider the geodesic γp→w (it exists since w ̸= p). As we\nhave previously seen in ??, this geodesic is of the form, ∀t ∈R:\nγp→w(t) = p ⊕k (−p ⊕k w) ⊗k t\n(19)\nWe want to see if, ∀t ∈R, γp→w(t) belongs to Hk\na,p, that is to say: ⟨−p ⊕k γp→w(t), a⟩= 0 :\n⟨−p ⊕k γp→w(t), a⟩= ⟨(−p ⊕k w) ⊗k t, a⟩\n(20)\n=\n1\n√\nk\ntan(t arctan(\n√\nk∥−p ⊕k w∥))⟨−p ⊕k w, a⟩\n(21)\n= 0\n(22)\nWe obtain 20 by the use of the left cancellation law; then, by deﬁnition of the Möbius scalar product,\nwe obtain 21. And we ﬁnally obtain 22 since w ∈Hk\na,p.\nDistance to hyperplane expression\nLet x be a point in Dn\nk, and Hk\na,p be an hyperplane in Dn\nk. Let\nus denote w∗the point that minimizes dk(x, w) (it exists since dk is continuous in both variables and\nbounded below). For a w ∈Hk\na,p, then x, w and p form a gyrotriangle in Dn\nk, noted ∆xwp. Let us\nsuppose now that d\nxwp ̸== π/2, then w ̸= w∗(by B.3).\nFrom now on, in order to ﬁnd w∗, we are hence going to consider points w such that d\nxwp = π/2\n(we know w∗in the set {w ∈Hk\na,p| d\nxwp ̸= π/2}). By applying the constant curvature sine law in the\nright triangle ∆xwp, we obtain:\ndk(x, w) =\n1\n√\nk\narcsin(sin(\n√\nkdk(x, p)) sin( d\nxwp))\n(23)\nBut we have that:\nsin(\n√\nkdk(x, p)) = sin(2 arctan(\n√\nk∥−p ⊕k x∥))\n(24)\nBy using the trigonometric property : sin(2x) =\n2 tan(x)\n1+tan2(x), we obtain that:\nsin(\n√\nkdk(x, p)) =\n2\n√\nk∥−p ⊕k x∥\n1 + k∥−p ⊕k x∥2\n(25)\nand does not depend on w.\nThe term inside the arcsin that inﬂuences the minimization of dk(x, w) is sin( d\nxwp). Since sin(x) =\np\n1 −cos2(x), minimizing sin( d\nxwp) is equivalent to maximizing cos( d\nxwp), to which we know the\nexpression:\n16\ncos( d\nxwp) =\n⟨−p ⊕k x, −p ⊕k w⟩\n∥−p ⊕k x∥∥−p ⊕k w∥\n(26)\nIt is quite straightforward to prove that {logk\np(w)|w ∈Hk\na,p} = {a}⊥.\nSince logk\np(w) =\n2\n√\nkλkp arctan(\n√\nk∥−p⊕kw∥) −p⊕kw\n∥−p⊕kw∥, we have that: ∥logk\np(w)∥= ∥\n2\n√\nkλkp arctan(\n√\nk∥−p⊕kw∥)∥.\nSince\n√\nk∥−p ⊕k w∥> 0, then arctan(\n√\nk∥−p ⊕k w∥) > 0. We know that\n2\n√\nkλkp > 0, so the real\nnumber ∥\n2\n√\nkλkp arctan(\n√\nk∥−p ⊕k w∥)∥=\n2\n√\nkλkp arctan(\n√\nk∥−p ⊕k w∥). We can deduce that:\nlogk\np(w)\n∥logk\np(w)∥\n=\n−p ⊕k w\n∥−p ⊕k w∥\n(27)\nAnd our optimization problem becomes:\nmax\nz∈{a}⊥\n⟨−p ⊕k x, z⟩\n∥−p ⊕k x∥∥z∥\n(28)\nWhich is a Euclidean optimization problem, whose solution is well known; we obtain:\nsin( [\nxpw∗) = |⟨−p ⊕k x, a⟩|\n∥−p ⊕k x∥∥a∥\n(29)\nSo, w∗exists by construction, and by re-injecting the expression of sin( [\nxpw∗) in dk(x, w∗), we\nobtain the expression in 5.\nC\nDatasets details\nNeuropathology\nWe us the digitized brain tissue dataset as described in [13]: Brain tissue slides\nwere digitized into whole-slide images (WSI), as shown in Fig. 5. Each WSI is tiled into an image\npatch of 1024 x 1024 pixels (0.504 µm per pixel, 516 µm2) to carry out training and inference, a\ntile size over 10 times larger than most other approaches. This larger size was chosen because it\ncontains multiple levels of morphologic detail (single cell-level and overall tumor structure) without\nsigniﬁcantly affecting computation times. The size of WSI varies, most with length and width of\napproximately 50,000 pixels. In the construction of the dataset by Faust et al. [13], all samples were\nanonymized and annotations carried out by board-certiﬁed pathologists. Slides were annotated with\neight non-lesional categories (hemorrhage, surgical material, dura, necrosis, blank slide space, and\nnormal cortical gray, white, and cerebellar brain tissue), and ﬁve common lesional subtypes (gliomas,\nmeningiomas, schwannomas, metastases, and lymphomas). The training image dataset and WSI\ntesting cases are available for download in the Zenodo repository at https://doi.org/10.5281/\nzenodo.1237976 and https://doi.org/10.5281/zenodo.1238084, respectively. Below in\nTable S1 we breakdown the tissue types in the dataset.\nD\nModel hyperparameters and setup\nTODO (Louise): params for the models used in experiments\nFor all experiments we use β-VAE [20], a variant of VAE that applies a scalar weight β to the KL\nterm in the objective function. In the histopathology experiments we found stronger reconstruction\nresults with a weighting schedule applied to the KL term of the ELBO. This is because a different\nratio targets different regions in the rate-distortion plane, either favouring better compression or\nreconstruction [2].\nWe start with β ≪1 to enforce a reconstruction optimization. When the average reconstruction error\nCθ(x, z) hits a predeﬁned parameter κ2 we initiate the following update scheme:\n17\nTable S1. Distribution of tissue types and images used for training. These numbers represent the aforementioned\n1024 x 1024 pixel images. Reproduced from [13].\nFigure 6: Two example H&E-stained whole-slide images (WSI) of glioblastoma from the neuropathology test\nset, each containing a heterogeneous mixture of tumor, necrosis, brain tissue, blood, and surgical material. Each\nWSI contains several thousand 1024 x 1024 tiles, as shown in Fig. 4.\nβt = βt−1 · exp(ν · ( ˆCt −ν2))\n(30)\nwhere ν is the update’s learning rate.\nFor the experiments in section 5.2, the backbone encoder consisted of 4-convolutional layers (2D\nConvolution + Batch Normalization + Leaky ReLU), with a hidden Euclidean dimension of 400. The\noptimization was done with the Adam optimizer, with a constant learning rate of 10−4, and a batch\nsize of 128. The maximum number of epochs was set to 250, with an early stopping mechanism,\nwith 150 warm-up epochs and 80 epochs for the lookahead.\n18\n",
  "categories": [
    "cs.CV",
    "cs.LG",
    "stat.ML"
  ],
  "published": "2020-06-19",
  "updated": "2020-06-19"
}