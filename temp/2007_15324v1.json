{
  "id": "http://arxiv.org/abs/2007.15324v1",
  "title": "Unsupervised deep learning for super-resolution reconstruction of turbulence",
  "authors": [
    "Hyojin Kim",
    "Junhyuk Kim",
    "Sungjin Won",
    "Changghoon Lee"
  ],
  "abstract": "Recent attempts to use deep learning for super-resolution reconstruction of\nturbulent flows have used supervised learning, which requires paired data for\ntraining. This limitation hinders more practical applications of\nsuper-resolution reconstruction. Therefore, we present an unsupervised learning\nmodel that adopts a cycle-consistent generative adversarial network that can be\ntrained with unpaired turbulence data for super-resolution reconstruction. Our\nmodel is validated using three examples: (i) recovering the original flow field\nfrom filtered data using direct numerical simulation (DNS) of homogeneous\nisotropic turbulence; (ii) reconstructing full-resolution fields using\npartially measured data from the DNS of turbulent channel flows; and (iii)\ngenerating a DNS-resolution flow field from large eddy simulation (LES) data\nfor turbulent channel flows. In examples (i) and (ii), for which paired data\nare available for supervised learning, our unsupervised model demonstrates\nqualitatively and quantitatively similar performance as that of the best\nsupervised-learning model. More importantly, in example (iii), where supervised\nlearning is impossible, our model successfully reconstructs the high-resolution\nflow field of statistical DNS quality from the LES data. This demonstrates that\nunsupervised learning of turbulence data is indeed possible, opening a new door\nfor the wide application of super-resolution reconstruction of turbulent\nfields.",
  "text": "This draft was prepared using the LaTeX style ﬁle belonging to the Journal of Fluid Mechanics\n1\nUnsupervised deep learning for\nsuper-resolution reconstruction of turbulence\nHyojin Kim1, Junhyuk Kim1†, Sungjin Won2 and Changhoon Lee1,2‡\n1Department of Mechanical Engineering, Yonsei University, Seoul 03722, Korea\n2Department of Computational Science and Engineering, Yonsei University, Seoul 03722, Korea\n(Received xx; revised xx; accepted xx)\nRecent attempts to use deep learning for super-resolution reconstruction of turbulent\nﬂows have used supervised learning, which requires paired data for training. This limi-\ntation hinders more practical applications of super-resolution reconstruction. Therefore,\nwe present an unsupervised learning model that adopts a cycle-consistent generative ad-\nversarial network that can be trained with unpaired turbulence data for super-resolution\nreconstruction. Our model is validated using three examples: (i) recovering the original\nﬂow ﬁeld from ﬁltered data using direct numerical simulation (DNS) of homogeneous\nisotropic turbulence; (ii) reconstructing full-resolution ﬁelds using partially measured\ndata from the DNS of turbulent channel ﬂows; and (iii) generating a DNS-resolution ﬂow\nﬁeld from large eddy simulation (LES) data for turbulent channel ﬂows. In examples (i)\nand (ii), for which paired data are available for supervised learning, our unsupervised\nmodel demonstrates qualitatively and quantitatively similar performance as that of the\nbest supervised-learning model. More importantly, in example (iii), where supervised\nlearning is impossible, our model successfully reconstructs the high-resolution ﬂow ﬁeld of\nstatistical DNS quality from the LES data. This demonstrates that unsupervised learning\nof turbulence data is indeed possible, opening a new door for the wide application of\nsuper-resolution reconstruction of turbulent ﬁelds.\nKey words: Authors should not enter keywords on the manuscript, as these must\nbe chosen by the author during the online submission process and will then be added\nduring the typesetting process (see http://journals.cambridge.org/data/relatedlink/jfm-\nkeywords.pdf for the full list)\n1. Introduction\nTurbulence is a chaotic, spatio-temporal multi-scale nonlinear phenomenon. Thus, it\ngenerally requires huge costs to accurately measure or simulate with suﬃciently high\nresolution. In particular, direct numerical simulation has been actively used in the study\nof turbulence. However, securing the computational resources needed to resolve even\nthe smallest-scale motions of turbulence is progressively challenging with high Reynolds\nnumbers. To help resolve this problem, a neural network (NN) having the capability\nto approximate arbitrary nonlinear functions (Hornik et al. 1989) has been examined.\nIndeed, there have been attempts to apply NNs to the representation of turbulence (Lee\net al. 1997; Milano & Koumoutsakos 2002). However, those applications were based\n† Co-ﬁrst author\n‡ Email address for correspondence: clee@yonsei.ac.kr\narXiv:2007.15324v1  [physics.flu-dyn]  30 Jul 2020\n2\nH. Kim, J. Kim, S. Won and C. Lee\non shallow learning and, thus, were restricted to the extraction of simple correlations\nbetween turbulence quantities at two close locations in a near-wall ﬂow. In recent years,\ndeep NNs (DNN) have been extended to various ﬁelds of turbulence research, owing to\nthe development of data-driven learning algorithms (e.g., deep learning (LeCun et al.\n2015)), computational equipment (e.g., graphical process units), big data (e.g., Johns–\nHopkins Turbulence Database (JHTDB) (Perlman et al. 2007)), and open-source code\n(e.g., TensorFlow (Abadi et al. 2015)).\nVarious deep-learning applications have recently been developed for wide areas of\nturbulence research. Ling et al. (2016) proposed a tensor-based NN by embedding the\nGalilean invariance of a Reynolds-averaged Navier–Stokes (RANS) model, showing a\ngreater performance improvement than linear and nonlinear eddy viscosity models. Parish\n& Duraisamy (2016), Wang et al. (2017), and other researchers have actively engaged\nin improving RANS models (e.g., Kutz (2017); Duraisamy et al. (2019)). On the other\nhand, Gamahara & Hattori (2017) proposed a large eddy simulation (LES)-closure model\nbased on DNN for wall-bounded turbulence. It was then extended to other ﬂows, such as\n2D turbulence (Maulik et al. 2019) and homogeneous isotropic turbulence (Beck et al.\n2019; Xie et al. 2019). Additionally, the prediction of the temporal evolution of turbulent\nﬂows has been actively pursued. As a fundamental example, Lee & You (2019) studied\nthe historical prediction of ﬂow around a cylinder using generative adversarial networks\n(GAN). Srinivasan et al. (2019) predicted the temporal behavior of simpliﬁed shear\nturbulence expressed as solutions of nine ordinary diﬀerential equations using a recurrent\nNN (RNN). Kim & Lee (2020a) proposed a high-resolution inﬂow turbulence generator\nat various Reynolds numbers, combining a GAN and an RNN. As another noticeable\nattempt to apply machine learning to ﬂuid dynamics, Raissi et al. (2020) reconstructed\nvelocity and pressure ﬁelds from only visualizable concentration data based on a physics-\ninformed NN framework. Recently, deep-reinforcement learning has been applied to ﬂuid\ndynamics, such as observations of how swimmers eﬃciently use energy (Verma et al.\n2018) and the development of a new ﬂow-control scheme (Rabault et al. 2019).\nApart from the above studies, the super-resolution reconstruction of turbulent ﬂows\nhas recently emerged as an interesting topic. This capability would help researchers\novercome environments in which only partial or low-resolution spatio-temporal data are\navailable, owing to the limitations of measurement equipment or computational resources.\nParticularly, if DNS-quality data could be reconstructed from data obtained via LES, it\nwould be very helpful for sub-grid scale modeling. Maulik & San (2017) proposed a\nshallow NN model that could recover a turbulent ﬂow ﬁeld from a ﬁltered or noise-added\none. Fukami et al. (2019) reconstructed a ﬂow ﬁeld from a low-resolution ﬁltered one\nusing a convolutional NN (CNN) for 2D decaying isotropic turbulence. Liu et al. (2020)\napplied temporal eﬀects to a CNN model, showing better performance than a static\nmodel. Both Fukami et al. (2019) and Liu et al. (2020) trained CNNs in the direction of\nreducing the mean-squared error (MSE) of target quantities between prediction and true\ndata. However, small-scale structures were not represented well when the resolution ratio\nbetween target and input ﬁelds was large. Deng et al. (2019) considered ﬂow data around\na cylinder measured using particle image velocimetry (PIV) in a learning network using\na GAN in which the small-scale structures were better expressed than when only MSE\nwas used. In all these prior studies, researchers used a supervised deep-learning model,\nwhich required labeled low- and high-resolution data for training. Therefore, paired data\nwere artiﬁcially generated by ﬁltering or averaging so that supervised learning could\nbe made possible. In a more practical environment, however, only unpaired data are\navailable (e.g., LES data in the absence of corresponding DNS data or measured data\nusing PIV with limited resolution). For more practical and wider applications, a more\nUnsupervised deep learning for super-resolution reconstruction\n3\nFigure 1. Illustration of present work\ngeneralized model that can be applied, even when paired data are not available, is needed.\nKim & Lee (2020a) recently showed that unsupervised learning networks could generate\nturbulent ﬂow ﬁelds for inﬂow boundary conditions from random initial seeds. This indeed\ndemonstrates that a DNN can learn and reﬂect hidden similarities in unpaired turbulence.\nBased on this evidence, we presume that super-resolution reconstruction of unpaired\nturbulence is now possible by learning the similarities among the unpaired data.\nIn this paper, we propose an unsupervised deep-learning model that can be used, even\nin the absence of labeled turbulent data. For a super-resolution reconstruction using\nunpaired data, we apply a cycle-consistent GAN (CycleGAN) (Zhu et al. 2017) to various\nturbulent ﬂows as an unsupervised learning model. The detailed methodology is presented\nin Section 2. For comparison, we use bicubic interpolation and supervised learning models\n(i.e., CNN and conditional GAN (cGAN)). The models are applied to three examples,\nas shown in ﬁgure 1. First, with homogeneous isotropic turbulence, a reconstruction\nof the DNS ﬂow ﬁeld from a top-hat-ﬁltered (i.e., low-resolution) one is considered in\nSection 3.1. Next, in Section 3.2, we cover the reconstruction of full DNS data from a\npartially measured (i.e., low-resolution) one in wall-bounded turbulence. In Sections 3.1\nand 3.2, we train our CycleGAN model using unpaired datasets with supervised learning\nmodels using paired ones. Finally, in Section 3.3, DNS-quality reconstruction from LES is\naddressed using independently obtained LES and DNS data of wall-bounded turbulence.\nIn this case, only the unsupervised learning model is applicable. We conclude our study\nwith a discussion in Section 4.\n2. Methodology\nIn this study, we apply CycleGAN to an unsupervised learning task. A typical GAN\nmodel consists of two networks: a generator network, (G), and a discriminator network,\n(D)(Goodfellow et al. 2014). In the ﬁeld of image generation, G generates a fake image\nsimilar to the real one by applying convolution and up-sampling to random noise z. D\ndistinguishes between the fake image and the real one and returns a probability value\n4\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 2. GAN architecture\nFigure 3. CycleGAN architecture consisting of (a) forward GAN and (b) backward GAN. G\nand F are generators, and DY and DX are discriminators. (c) Forward cycle-consistency loss:\nx →G(x) →F(G(x)) ≈x, and backward cycle-consistency loss: y →F(y) →G(F(y)) ≈y.\nbetween 0 and 1 by applying convolution and down-sampling. The ﬁnal goal is to obtain\nG, which can generate fake images that are diﬃcult to distinguish from real ones. This\nprocess is similar to a min–max two-player game for the value function, V (D, G), as\nfollows:\nmin\nG max\nD V (D, G) = Ex∼PX[log D(x)] + Ez∼PZ[log(1 −D(G(z)))],\n(2.1)\nwhere X is a real image set, and x ∼PX means that x is sampled from the real image\ndistribution. z is a random noise vector of latent space used as the input to the generator.\nG is expected to generate a fake image similar to the real one. Thus, trainable parameters\nin G are trained in the direction of D(G(z)), having a value close to 1. On the other hand,\nthose in D are trained in the direction of D(x), returning a value close to 1. D(G(z))\nreturns a value close to 0. Thus, even a slight diﬀerence between the real image and the\ngenerated one can be distinguished. In other words, the G parameters are adjusted in\na direction that minimizes V (D, G), and D parameters are adjusted in a direction that\nmaximizes V (D, G). From this competitive learning, we can expect to obtain a generator,\nG, capable of providing a new image having a distribution similar to a real one. In the\npresent work, GAN is applied to super-resolution reconstruction in the frame of ﬁnding\nan input–output mapping function, and, instead of random noise, low-resolution image\ndata are used as the input of G, as illustrated in Figure 2.\nUnsupervised deep learning for super-resolution reconstruction\n5\nFor an unsupervised learning model of unpaired turbulence, we adopt CycleGAN (Zhu\net al. 2017) to ﬁnd a mapping function between unpaired data, X and Y . We aim to obtain\na model that performs super-resolution reconstruction when the low- and high-resolution\nﬂow ﬁelds are not matched. X and Y are low- and high-resolution datasets, respectively.\nCycleGAN consists of two generator networks, (G, F), and two discriminator networks,\n(DY , DX), as shown in Figure 3(a,b). G and F are networks mapping X −→Y and\nY −→X, respectively. DY and DX distinguish between a fake image from generators\nand a real image, returning a probability value. DY distinguishes between G(x) generated\nby G and y from Y , whereas DX distinguishes between F(y) generated by F and x from\nX. The objective function of CycleGAN consists of the GAN and cycle-consistency losses.\nThe GAN loss helps the generators ﬁnd the distribution of the target image. The cycle-\nconsistency loss connects two generators, (G, F), and reﬂects the dependency of input\non them. First, the GAN loss function is used as follows:\nLGAN(G, DY ) = Ey∼PY [log DY (y)] + Ex∼PX[log(1 −DY (G(x)))],\n(2.2)\nLGAN(F, DX) = Ex∼PX[log DX(x)] + Ey∼PY [log(1 −DX(F(y)))],\n(2.3)\nwhere x and y are the images sampled from X and Y datasets, respectively. G is trained\nin a direction to minimize LGAN(DY , G), and discriminator DY is trained in a direction\nto maximize LGAN(DY , G). F and DX in Equation 2.3 are trained in the same way.\nIn principle, the properly trained generators, G and F, can provide data having a\nsimilar distributions as the target data, Y and X. However, the above loss cannot\nguarantee that the generated image will be properly dependent upon the input image. In\nother words, the high-resolution image, G(x), from the low-resolution one, x, could have\nthe characteristics of target datasets, Y , and the reconstructed image, G(x), might not\nhave a large-scale similarity to the low-resolution one, x. This may reﬂect a dependency\nof input on generated data. Therefore, a cycle-consistent loss that reduces the space of\nthe mapping function with G and F is additionally used (see Figure 3(c)). This loss\nfunction consists of two terms for domains X and Y . In the left panel of Figure 3(c), the\nforward cycle-consistency loss reduces the space of image x and F(G(x)) in domain X. It\nmakes G(x) dependent upon x (x →G(x) →F(G(x)) ≈x). Similarly, in the right panel\nof Figure 3(c), the backward cycle-consistency loss reduces the space of image y and\nG(F(y)) in domain Y and makes F(y) dependent upon y (y →F(y) →G(F(y)) ≈y).\nThe cycle-consistency losses can be expressed as\nLcycle(G, F) = Ex∼PX[∥F(G(x)) −x ∥2\n2] + Ey∼PY [∥G(F(y)) −y ∥2\n2],\n(2.4)\nwhere the ﬁrst term on the right-hand side is the forward cycle-consistency loss, and\nthe second term is the backward cycle-consistency loss. ∥∥2\n2 denotes mean-squared error,\nwhich is normalized by vector size. The MSE between F(G(x)) and x and that between\nG(F(y)) and y are used. The cycle-consistency loss provides a decisive eﬀect on learning\nthe unpaired data. The ﬁnal objective function used in this study is as follows:\nL(G, F, DY , DX) = LGAN(G, DY ) + LGAN(F, DX) + λLcycle(G, F),\n(2.5)\nwhere λ is a weight factor and is ﬁxed at 10. Generators G and F are trained in the\ndirection of minimizing L(G, F, DY , DX), whereas discriminators DY and DX are trained\nin the direction of maximizing L(G, F, DY , DX). Learning with the above GAN loss often\ndiverges, because the discriminator easily distinguishes between the generated image and\nthe target one before parameters in the generator are suﬃciently trained. Additionally,\nthere is a well-known problem (i.e., mode collapse) in which the generation distribution is\nrestricted to a small domain, although training does not diverge. To solve this problem, we\n6\nH. Kim, J. Kim, S. Won and C. Lee\nchange the above GAN loss to a Wasserstein GAN (WGAN) having a gradient penalty\n(GP) loss (Gulrajani et al. 2017). With the WGAN-GP loss, the GP term is added,\nand the probabilistic divergence between the real image and the generated one becomes\ncontinuous with respect to the parameters of the generator. Training and performance\ncan, therefore, be stabilized and improved.\nTo eﬀectively handle the spatial structures of turbulence, a CNN comprising discrete\nconvolution operations and nonlinear functions is used as generators G and F and\ndiscriminators DY and DX, respectively. To change the dimension of the image (i.e.,\nthe ﬂow ﬁeld), up- and down-sampling are applied to generators G and F, respectively.\nDown-sampling is used for discriminators DX and DY . Additionally, the fully-connected\nlayer is used in the last two layers for the discriminators. As a nonlinear function, a leaky\nrectiﬁed linear unit ReLU is used:\nf(x) =\n\u001a x,\nx ⩾0\nαx,\nx < 0\n(2.6)\nwhere α = 0.2. This nonlinear function reliably updates the weight by avoiding the\ndead-ReLU problem that produces an output, 0, for the negative input. Detailed hyper-\nparameters used for training and network architecture are provided in Appendix A. For\nimplementation, we use the TensorFlow open-source library (Abadi et al. 2015).\nTo assess our unsupervised learning, we consider supervised learning that adopts CNN\nand a cGAN. Their generators comprise the same network as does G in the CycleGAN.\nThe CNN is trained with the MSE that represents the pixel loss between the target ﬂow\nﬁeld and the reconstructed one. With an L2 regularization added to prevent overﬁtting,\nthe objective function of the CNN consists of the sum of MSE and L2 regularization loss,\nas follows:\nLCNN = Ex∼PX[∥G(x) −y ∥2\n2] + λ\n2\nX\nk\nw2\nk,\n(2.7)\nwhere, in the MSE of the data sampled during training, y and G(x) are the DNS ﬂow\nﬁeld and the predicted one, respectively. The second term is the L2 regularization loss,\nwhere w represents trainable weights. λ denotes the strength of the regularization, ﬁxed\nat 0.0001. The CNN is trained in the direction of minimizing LCNN to accurately predict\nthe target ﬂow ﬁeld.\ncGAN, as proposed by Mirza & Osindero (2014), is similar to GAN. the cGAN model\napplies the generator input as a condition to the discriminator to constrain the output\nof the generator to be dependent upon the input. In this study, the dependency of\nlow-resolution data is eﬀectively reﬂected in the reconstruction of high-resolution data\nusing low-resolution data as the condition. Thus, the correlation between the large-\nscale structure and the reconstructed small-scale structures of turbulence can be more\naccurately represented. The objective function of the cGAN is as follows:\nLcGAN = Ey∼PY [log D(y|x)] + Ex∼PX[log(1 −D(G(x)|x))],\n(2.8)\nwhere x and y are sampled low- and high-resolution turbulent ﬂow ﬁelds, respectively.\nA low-resolution ﬁeld is used as the input of the discriminator in addition to the high-\nresolution one (y or G(x)). For example, ﬂow-ﬁeld information, comprising a total of six\nchannels, including high-resolution velocity vector ﬁelds and paired low-resolution ﬁelds,\nare used as input. Note that we can use cGAN only when paired data are provided.\nIn this study, the unpaired low- and high-resolution turbulent ﬁelds are used when\ntraining the CycleGAN, whereas the paired data are used when training the CNN and\nthe cGAN. In the ﬁrst two examples,(Sections, 3.1 and 3.2), paired data exist, because\nUnsupervised deep learning for super-resolution reconstruction\n7\nlow-resolution data are obtained from high-resolution DNS data. When learning the\nCycleGAN, low- and high-resolution data are shuﬄed and unpaired intentionally. In\nSection 3.3, LES and DNS data are unpaired naturally. Thus, we cannot train the CNN\nand the cGAN, whereas we can train the CycleGAN in the same way as explained in\nSections 3.1 and 3.2.\n3. Results and discussion\n3.1. Example 1: ﬁltered homogeneous isotropic turbulence\nIn this section, using various resolution ratios, super-resolution reconstruction leverag-\ning both supervised and unsupervised learning are considered for homogeneous isotropic\nturbulence at a Taylor-scale Reynolds number, Reλ = 418. Data were obtained from the\nJHTDB. The governing equations were incompressible Navier–Stokes equations. DNS\nwas performed based on the pseudo-spectral method, and the domain and mesh size were\n2π × 2π × 2π and 1024 × 1024 × 1024, respectively. Details are given in Perlman et al.\n(2007) and Li et al. (2008). We used 200 ﬁelds with ∆t = 0.02 for training and 10 ﬁelds\nwith ∆t = 0.2 for validation. For testing, 10 ﬁelds with ∆t = 0.2 were used independently\nof training data. In the current study, we restricted our scope to the reconstruction of 2D\nﬁelds of 3D turbulent ﬁelds to conﬁrm the plausibility of reconstructing turbulence using\nan unsupervised learning. Input and output data were 2D velocity ﬁelds (u, v, w) in an\nx −y plane. Low-resolution velocity ﬁelds and ﬁltered DNS (fDNS) data were obtained\nby applying down-sampling and average pooling (i.e., top-hat ﬁlter) to high-resolution\nDNS data. Average pooling is a local average operation that extracts the mean value\nover some area of the velocity ﬁelds. The size of DNS data was Nx × Ny, and that\nof the low resolution was Nx/r × Ny/r, where r is the resolution ratio. We considered\nthree cases: r = 4, 8, and 16. For training, the target (high-resolution) size was ﬁxed\nat Nx × Ny = 128 × 128, which was a sub-region extracted from the training ﬁelds.\nThis choice of input and target-domain sizes was made based on our observation that\nthe domain length of 128∆x(= 0.785) was greater than the integral length scale of the\nlongitudinal two-point velocity autocorrelation of 0.373. This condition is an important\nguideline for the choice of the input domain, because high-resolution data at any point in\nthe same domain can be reconstructed restrictively based on all of the data in the input\ndomain.\nTo demonstrate the performance of unsupervised learning using CycleGAN for the\nsuper-resolution reconstruction of turbulent ﬂows, we tested a bicubic interpolation and\ntwo kinds of supervised learning by adopting CNN and cGAN. Bicubic interpolation is\na simple method of generating high-resolution images through interpolation using data\nat 16 adjacent pixels without learning. CycleGAN was trained using unpaired fDNS and\nDNS ﬁelds, and CNN and cGAN were trained using paired fDNS and DNS ﬁelds. Three\nvelocity components, u, v, w, were trained simultaneously. The same hyperparameters, ex-\ncept those of the network architecture, were used for each resolution ratio, r. The velocity,\nu, of the reconstructed 2D ﬁeld, using the test data, is presented in Figure 4. Bicubic\ninterpolation tends to blur the target turbulence and thus cannot well-reconstruct the\nsmall scales of the target ﬂow ﬁeld, regardless of resolution ratio. This obviously indicates\nthat the bicubic interpolation is unsuitable for small-scale reconstruction of turbulence.\nHowever, data-driven approaches can fairly well-reconstruct small-scale structures that\nare not included in the input data. CNN can reconstruct a velocity ﬁeld similar to that of\nthe target data when r = 4. As r increases, the CNN shows only slight improvement over\n8\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 4. Reconstructed instantaneous velocity ﬁeld (u) obtained by various deep-learning\nactivities from a given low-resolution input ﬁeld in the homogeneous isotropic turbulence.\nUnsupervised deep learning for super-resolution reconstruction\n9\nr\nDeep learning models\nBicubic\nCNN\ncGAN\nCycleGAN\n4\n0.00254 0.00168 0.00230\n0.00548\n8\n0.01387 0.01019 0.01840\n0.02672\n16 0.04140 0.03539 0.06440\n0.08677\nTable 1. MSE of generated velocity ﬁeld for the resolution ratio, r. The velocity is normalized\nusing the standard deviation of the DNS ﬁeld.\nbicubic interpolation. Meanwhile, cGAN can generate high-quality velocity ﬁelds similar\nto the DNS ones, regardless of input data resolution.\nAs also shown in Figure 4, CycleGAN showed excellent performance in reconstructing\nthe velocity ﬁeld, reﬂecting the characteristics of the target, given that it used unsu-\npervised learning. When r = 4 and 8, our model produced a ﬂow ﬁeld quite similar to\nthat of the target and that of the cGAN reconstruction trained using paired data. When\nr = 16, the generated ﬁeld by CycleGAN had a slightly diﬀerent point-by-point value\nfrom the target. However, our model showed similar performance as cGAN. We used\nMSE to rigorously compare the diﬀerence between the target and the reconstructed ﬂow\nﬁeld, as shown in Table 1. The CNN had the lowest error, whereas cGAN and CycleGAN\nhad relatively high errors for all r. The reason is that the CNN model was trained in\nthe direction of minimizing only the MSE during the training process. Other learning\nmodels that adopted GAN were trained by minimizing more sophisticated loss for proper\npurposes. However, as we conﬁrm in Figure 4, cGAN and CycleGAN had superior ability\nto reconstruct small scales, compared with CNN. It appears that MSE was not suitable\nto measure performance for super-resolution reconstruction of turbulent ﬂows, because\na bicubic interpolation produces a smaller MSE than does cGAN and CycleGAN.\nVorticity ﬁeld (ωz), obtained from the reconstructed velocity information, is presented\nin Figure 5. Vorticity was not directly considered during the training process. Similar\nto velocity ﬁelds, bicubic interpolation and CNN were unable to reconstruct vorticity\nstructures shown in the DNS, because the resolution of the input data decreased.\nHowever, both cGAN and CycleGAN generated vorticity structures similar to the DNS\nones. However, performance was a bit deteriorated when r = 16.\nFor more quantitative assessment of the performance of learning models, the probabil-\nity density function of vorticity, p.d.f.(ωz), for three resolution ratios are given in Figure\n6(a), (b) and (c). For obvious reasons, bicubic interpolation could not produce a wider\ndistribution of the p.d.f. of vorticity for DNS data, and CNN performed very poorly. On\nthe other hand, the p.d.f. of cGAN and CycleGAN recovered the DNS well, regardless of\nr. The performance of learning models in representing small-scale structures of turbulence\ncan be better investigated using an energy spectrum. The x-directional energy spectrum\nis deﬁned as follows:\nE(κx) = 1\n2π\nZ ∞\n−∞\ne−ipκxRViVi(p)dp,\n(3.1)\nwhere\nRViVi(p) = ⟨Vi(x, y)Vi(x + p, y)⟩.\n(3.2)\nHere, ⟨⟩denotes an average operation, and Vi represents the velocity components.\nRViVi(p) is the x-directional two-point correlation of velocity. The transverse energy\n10\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 5. Vorticity ﬁeld calculated from the reconstructed velocity ﬁelds obtained by various\ndeep-learning models.\nUnsupervised deep learning for super-resolution reconstruction\n11\nspectrum is obtained by the average of the y-directional spectrum of u, the x-directional\nspectrum of v, and the x- and y-directional spectra of w. The transverse energy spectra\nfor r = 4, 8 and 16 are presented in Figure 6 (d), (e) and (f ), respectively. The vertical\ndotted line indicates the cutoﬀwave number, which is the maximum wave number of\nlow-resolution ﬁelds. Bicubic interpolation and CNN cannot represent the energy of wave\nnumbers higher than the cutoﬀone. However, cGAN and unsupervised CycleGAN show\ngreat performance in recovering the energy of the DNS in the high-wave number regions,\nwhich is not included in the input data.\nTest results in this section clearly indicate that CycleGAN is an eﬀective model for\nsuper-resolution reconstruction of turbulent ﬂows when low- and high-resolution data\nare unpaired. The CycleGAN model can provide statistically accurate high-resolution\nﬁelds for various resolution ratios. Reconstructed velocities are very similar to targets\nat all r. Although training with unpaired data, CycleGAN performs nearly equally to\ncGAN, showing the best performance among supervised learning models. It appears that\nrepetitive convolution operations and up- or down-sampling of turbulence ﬁelds in the\ngenerator and discriminator capture the essential characteristics of turbulence, which are\notherwise diﬃcult to describe.\n3.2. Example 2: measured wall-bounded turbulence\nTo evaluate the performance of our model for anisotropic turbulence, in this section, we\nattempt a high-resolution reconstruction of low-resolution data for wall-bounded ﬂows.\nThis time, the low-resolution data were extracted from high-resolution DNS data from\npoint-wise measurement at sparse grids instead of the local average. This is similar\nto experimental situations in which PIV measurements had limited spatial resolution.\nWe used JHTDB data collected through DNS of turbulent channel ﬂows for solving\nincompressible Navier–Stokes equations. The ﬂow was driven by the mean pressure\ngradient in the streamwise (x) direction, and a no-slip condition was imposed on the\ntop and bottom walls. Periodicity was imposed in the streamwise, x, and spanwise, z,\ndirections, and a non-uniform grid was used in the wall-normal direction, y. Detailed\nnumerical methods were provided in Graham et al. (2015). The friction Reynolds number,\nReτ = uτδ/ν, was deﬁned by the friction velocity uτ, channel half-width δ, and kinetic\nviscosity ν is 1,000. Velocity and length were normalized by uτ and δ, respectively,\nand superscript (+) was a quantity non-dimensionalized with uτ and ν. The domain\nlength and grid resolution were Lx × Ly × Lz = 8πδ × 2δ × 3πδ and Nx × Ny × Nz\n= 2048 × 512 × 1536, respectively. The simulation time step, ∆t, which was non-\ndimensionalized by uτ and δ, was 6.5 × 10−5. The learning target was the streamwise\nvelocity, u, the wall-normal velocity, v, and the spanwise velocity, w, in the x −z plane\nat y+ = 15 and y+ = 100. y+ = 15 is the near-wall location with maximum ﬂuctuation\nintensity of u, and y+ = 100 (y/δ = 0.1) is in the outer-region. For training and validation\ndata, 100 ﬁelds separated by an interval, ∆t = 3.25 × 10−3, and 10 ﬁelds separated by\n∆t = 3.25 × 10−2 were used, respectively. After training, we veriﬁed the trained model\nusing 10 ﬁelds separated by an interval of ∆t = 3.25 × 10−2 as test data. This is because\nthey were far enough from the training data. Low-resolution partially measured data\nwere extracted at eight-grid intervals in the streamwise and spanwise directions in the\nDNS fully measured data. Similar to the previous learning example in Section 3.1, during\ntraining, input and target sizes were ﬁxed at 16 × 16 and 128 × 128, respectively. They\nwere sub-region extracted from training ﬁelds. Here, the streamwise input domain length\nwas 128∆x = 1.57, which was greater than the integral length scale of the two-point\ncorrelation of the streamwise velocity, 1.14.\nIn this example, because the low-resolution data were point-wise accurate, reconstruc-\n12\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 6. Probability density function of vorticity and transverse energy spectra for various\nresolution ratio, r. (a), (b) and (c) are p.d.f. of vorticity corresponding to r = 4, 8, and 16,\nrespectively. (d), (e) and (f ) are energy spectra for r = 4, 8, and 16.\nUnsupervised deep learning for super-resolution reconstruction\n13\nWithout Lpixel\nWith Lpixel\npixel error entire error pixel error entire error\ny+ = 15\n1.403\n1.390\n0.124\n0.595\ny+ = 100\n0.871\n0.768\n0.075\n0.477\nTable 2. Error of measured positions (i.e., pixel error) and error of entirety (i.e., entire error)\nfor CycleGAN with and without pixel loss. The error is normalized by the standard deviation\nof the velocity of DNS.\ntion implies the restoration of data in-between grids where low-resolution data are given.\nTherefore, a stabler model can be obtained by utilizing the known values of the ﬂow ﬁeld\nduring reconstruction. To account for the known information, a new loss term (i.e., pixel\nloss) is added to the existing loss function (see Equation 2.5). The pixel-loss function\nused in the unsupervised learning model, CycleGAN, is expressed as\nLpixel = λEx∼PX[ 1\nNp\nNp\nX\ni=1\n(xLR(pi) −yDL(pi))2],\n(3.3)\nwhere yDL is the reconstructed velocity ﬁeld, and xLR is the low-resolution one. pi is a\nmeasured position, and Np is the number of measured points. λ is a weight value, and we\nﬁx it to 10. CycleGAN is trained to minimize Lpixel. Table 2 shows the error of the test\ndataset, depending on the use of the pixel loss. When the pixel loss is used, the smaller\nerror occurs at the position where exact values are known. Thus, the entire error of the\nreconstructed ﬁeld becomes small. In the situation where a partial region is measured, a\nsimple pixel loss could improve reconstruction accuracy for entire positions in addition\nto measured ones. The point-by-point accuracy can be further improved through the ﬁne\ntuning of λ.\nThe absolute phase error of the Fourier coeﬃcients in an instantaneous ﬂow ﬁeld\nreconstructed from test data using CycleGAN is given in Figure 7. The phase error\nobtained without pixel loss at y+ = 15, that with pixel loss at y+ = 15, and that with\npixel loss at y+ = 100 are shown in Figure 7(a), (b), and (c), respectively. The maximum\nwave numbers of the low-resolution ﬁeld, κx,cutoff and κz,cutoff, are indicated by a white\nline. When pixel loss was not used, a large phase error and a phase-shift occurred for\nspeciﬁc-size structures. This happened, because, when spatially homogeneous data are\nused for unsupervised learning, the discriminator cannot prevent the phase shift of high-\nresolution data. On the other hand, when pixel loss is used for training, the phase of\nall velocity components (u, v, w) is accurate in the area satisfying κ ⩽κcutoff. This\nmeans that, although the large-scale structures located in the low-resolution ﬁeld were\nwell captured, the small-scale structures were reconstructed. We also noticed that the\nreconstructed ﬂow ﬁeld near the wall (y+ = 15) had higher accuracy than that away from\nthe wall (y+ = 100) in the spanwise direction (as shown in Figure 7(b) and (c)). This\nmight be related to the fact that the energy of the spanwise small scale was larger in the\nﬂow ﬁeld near the wall. Furthermore, as shown in Figure 7(b), the streamwise velocity,\n(u), at y+ = 15 had a higher-phase accuracy in the spanwise direction compared with\nother velocity components, (v, w). The reason might be that the energy of the streamwise\nvelocity in high spanwise wave numbers was higher. Overall, the higher the root-mean-\n14\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 7. Phase error deﬁned by |phase(ˆuCycleGAN\ni\n)−phase(ˆuDNS\ni\n)| between the Fourier\ncoeﬃcients of the DNS ﬁeld and the generated one by CycleGAN. (a) CycleGAN without\npixel loss at y+ = 15, (b) CycleGAN with pixel loss at y+ = 15, and (c) CycleGAN with pixel\nloss at y+ = 100. The box with the white line denotes the range of low-resolution input ﬁelds,\n|κx| ⩽κx,cutoff and |κz| ⩽κz,cutoff.\nsquare (RMS) of ﬂuctuation, the higher the phase accuracy of the reconstructed ﬂow\nﬁeld.\nFigure 8 shows the velocity ﬁeld (u, v, w) reconstructed by various deep-learning\nprocesses from partially measured test data at y+ = 15. For CycleGAN, an unsupervised\nlearning model, the network was trained using unpaired data with pixel loss, and the\nsupervised learning models (i.e., CNN and cGAN) were trained using paired data with the\nUnsupervised deep learning for super-resolution reconstruction\n15\nFigure 8. Reconstructed instantaneous velocity ﬁeld at y+ = 15 obtained by various deep\nlearning models.\nloss function presented in Section 2. Bicubic interpolation smoothed the low-resolution\ndata. Thus, it could not at all capture the characteristics of the wall-normal velocity of\nthe DNS (target). CNN yielded slightly better results, but it had limitations in generating\na ﬂow ﬁeld that reﬂected small-scale structures observed in the DNS ﬁeld. On the other\nhand, cGAN demonstrated excellent capability to reconstruct the ﬂow ﬁeld, including\nfeatures of each velocity value. It accurately produced a wall-normal velocity, where small\nscales were especially prominent. CycleGAN, an unsupervised learning model, showed\nsimilar results as cGAN, although unpaired data were used. CycleGAN reconstructed\nboth streak structures of the streamwise velocity and small strong structures of the wall-\nnormal velocity, similar to the DNS ﬁeld.\nThe streamwise and spanwise energy spectrum of each velocity component are shown in\nFigure 9(a,b,c) and (d,e,f ), respectively. Statistics are averaged using test datasets. In the\n16\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 9. 1D energy spectra of reconstructed ﬂow ﬁeld using deep-learning models at y+ = 15.\nStreamwise energy spectra for (a) streamwise velocity, (b) wall-normal velocity and (c) spanwise\nvelocity; spanwise energy spectra for (d) streamwise velocity, (e) wall-normal velocity, and (f )\nspanwise velocity.\nstreamwise energy spectrum, bicubic interpolation and CNN could not reproduce DNS\nstatistics at high wave numbers. On the other hand, cGAN accurately expressed DNS\nstatistics at high wavenumbers. Despite using unpaired data, CycleGAN, an unsupervised\nlearning model, showed similar results as cGAN. The spanwise energy spectrum showed\nUnsupervised deep learning for super-resolution reconstruction\n17\nsimilar results as the streamwise one. However, both low-resolution data and bicubic\ninterpolation had higher energies than did DNS statistics at low wave numbers, as shown\nin Figure 9(e). These results are closely related to the structure size of the reconstructed\nvelocity ﬁeld. In Figure 8, the reconstructed ﬁeld through bicubic interpolation includes\nstructures larger than those observed in the DNS ﬂow ﬁeld in the spanwise direction.\nNotably, an artiﬁcial large-scale structure can be generated by interpolation if the\nmeasuring is not carried out with suﬃcient density. The predicted ﬂow through the\nCNN requires overall smaller energy than does the DNS statistics. Particularly, this\nphenomenon is prominent at a relatively high wave numbers. When the input (i.e.,\nlow-resolution ﬁeld) and target (i.e., high-resolution ﬁeld) are not uniquely connected,\nCNN tends to underestimate the energy. On the other hand, cGAN and CycleGAN can\naccurately describe the statistics of the DNS at both low and high wave numbers. The\nreconstructed ﬂow ﬁeld and statistics of the energy spectrum at y+ = 100 show similar\nresults (see Appendix B).\nWhen using partially measured data, as with experimental situations, our model can\nreconstruct fully measured data in wall-bounded turbulences and probably other types.\nBy considering the pixel loss in the unsupervised learning of the homogeneous data, the\npoint-by-point error and phase error can be reduced eﬀectively. Compared to cGAN,\nwhich shows excellent performance among supervised learning models, CycleGAN shows\nsimilar results despite using unpaired data. CycleGAN can reconstruct the ﬂow ﬁelds that\nreﬂect the characteristics of each velocity component, and they are statistically similar\nto the target DNS.\n3.3. Example 3: application to large-eddy simulation data\nIn this section, we apply CycleGAN to a more practical situation in which supervised\nlearning is impossible, because paired data are not available. We investigate whether\nCycleGAN can reconstruct high-resolution ﬂow ﬁelds having DNS-quality from LES data.\nFor unsupervised learning, we chose the same DNS data of channel turbulence as those\nused in Section 3.2. For LES data, we numerically solved ﬁltered Navier–Stokes equations\nand collected two types of data obtained using the Smagorinsky subgrid-scale model\n(Smagorinsky 1963) and the Vreman subgrid-scale model (Vreman 2004). We validated\nthat the basic statistics of LES, such as mean and RMS proﬁle of velocities, showed\nsimilar tendencies as those of the DNS. The detailed LES setup is given in Appendix C.\nThe LES and DNS data used in the training process were 2D velocity ﬁelds (u, v, w) in\nan x −z plane at y+ = 15 at Reτ = 1, 000. DNS training data contained 100 velocity\nﬁelds of 2, 048 × 1, 536 size, and LES training data contained 10,000 velocity ﬁelds of\n128 × 128 size. LES data were collected per ∆t = 0.004 non-dimensionalized by uτ and\nδ. The domain size of DNS was Lx × Ly × Lz = 8πδ × 2δ × 3πδ, and that of LES was\nLx × Ly × Lz = 2πδ × 2δ × πδ. Based on the same length scale, the resolution ratio\nbetween LES and DNS was four in both x and z directions.\nDuring the training of CycleGAN, input (LES) and the output size of the generator\nG were ﬁxed as 32 × 32 and 128 × 128, respectively. After training, the input size was\nnot ﬁxed, and the output had 4 × 4 higher resolution than the input. The trained model\nwas tested using 100 LES ﬁelds independent from the training data. In Section 3.2, it\nwas conﬁrmed that the phase shift of structures might occur in the reconstructed ﬂow\nﬁeld when statistically homogeneous data are used in learning CycleGAN. This can be\nprevented by introducing pixel loss. Similarly, in this section, a new loss (LLR) is added\nto the existing loss function (Equation 2.5) in unsupervised learning. The added loss\n18\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 10. Reconstructed instantaneous velocity ﬁelds (u, v, w) at y+ = 15 obtained by various\ndeep-learning models. During the training of CycleGAN, the ﬂow ﬁeld of LES with theVreman\nmodel is used, and a new LES ﬁeld having the same model is used for testing.\nterm is deﬁned as\nLLR = λEx∼PX[ 1\nNp\nNp\nX\ni=1\n(x(pi) −IG(pi))2],\n(3.4)\nwhere x is the LES data used as input data, I is top-hat ﬁlter operation, IG(pi) is the\nﬁltered ﬂow ﬁeld after reconstruction through G (the same size as the input data), and\npi and Np are the position and size of the low-resolution ﬁeld, respectively. The value\nof λ is 10. This loss is proposed based on the assumption that the ﬁltered ﬂow ﬁeld has\na similar distribution as LES data. Using this, we expect that the small-scales will be\nreconstructed while the phase of the large-scale structures is maintained.\nFor the ﬁrst test, we used data obtained using the same subgrid-scale model as those\nUnsupervised deep learning for super-resolution reconstruction\n19\nFigure 11. Instantaneous wall-normal vorticity ﬁeld calculated from reconstructed velocity\nﬁelds at y+ = 15 by cGAN and CycleGAN with input LES and target DNS ﬁelds.\nused for training, the Vreman model. An example of the reconstructed velocity ﬁelds with\nDNS resolution from the LES data is shown in Figure 10. Learning both LES and DNS\ndata was possible only with the cycle-structured GAN. For comparison, we presented\nvelocity ﬁelds reconstructed by supervised learning models (i.e., CNN and cGAN) that\nwere trained using ﬁltered DNS data. As shown in Figure 10, only the CycleGAN could\nreconstruct a ﬂow ﬁeld that captured the features of each velocity component of the DNS\nﬁeld. Meanwhile, CycleGAN maintains the large-scale structure observed in LES data.\nOn the other hand, neither bicubic interpolation nor the CNN could generate small-scale\nstructures of DNS at all. Although cGAN demonstrated the best performance among\nsupervised learning models (Sections 3.1 and 3.2), it provided a slightly better ﬂow ﬁeld\nthan did the CNN, and it was diﬃcult to acknowledge that the generated ﬁelds correctly\nreﬂected DNS characteristics. In particular, the structure of the wall-normal velocity did\nnot represent the tilted feature in the spanwise direction frequently observed in DNS\ndata. This clearly suggests that the deep-learning model that trained the fDNS will\nnot likely work well in the super-resolution reconstruction of LES data. We assumed\nthat this would occur, because the DNN is overﬁtted to the training environment and\nbecomes very sensitive to the input data distribution. Therefore, to successfully apply\na deep-learning model to LES, an environment and a methodology capable of learning\nLES data are required. CycleGAN indeed meets this requirement for our super-resolution\nreconstruction of LES data.\nThe wall-normal vorticity ﬁeld obtained from the reconstructed velocity is presented\nwith the vorticity of the input LES ﬁeld in Figure 11. Because vorticity is not directly\nconsidered in training, it can be a good measure for assessing the performance of\nlearning. The vorticity of LES data was much weaker than that of DNS, and the cGAN\nreconstructed the vorticity ﬁeld much stronger than that of DNS. The thin streaky\nstructures of vorticity found in DNS data were not captured by cGAN. Recall that\ncGAN was trained using ﬁltered DNS, not LES, because the cGAN required paired\ndata. However, structures of the vorticity ﬁeld reconstructed by CycleGAN showed a\n20\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 12. Probability density function of (a) streamwise velocity, (b) wall-normal velocity, (c)\nspanwise velocity, and (d) wall-normal vorticity obtained from reconstructed velocity ﬁelds by\nvarious deep-learning models.\nstriking similarity to that of the DNS. CycleGAN indeed showed an ability to accurately\nreconstruct the high-order component obtained through diﬀerentiation.\nP.d.f. of the reconstructed velocities and wall-normal vorticity, ωy, is presented in\nFigure 12. The velocity p.d.f. obtained by bicubic interpolation was similar to the LES\nstatistics, not the DNS statistics. Additionally, the p.d.f. by either CNN or cGAN\ndid not well approximate that of DNS, except for the spanwise velocity, especially\nin a high-magnitude range. cGAN overestimated the range of the vorticity, as shown\nin Figure 12(d). On the other hand, the p.d.f. of all velocity components and the\nvorticity by CycleGAN closely reproduced that of DNS, except only for the low-speed\nrange of streamwise velocities. Additional quantitative statistics obtained from test data,\nincluding mean, RMS, Reynolds stress, skewness, and ﬂatness, are presented in Table 3.\nLikewise, bicubic interpolation had nearly the same value as did LES in all statistics,\nexcept for vorticity statistics. The supervised learning models (i.e., CNN and cGAN)\ngenerally showed results closer to the DNS statistics than did bicubic interpolation.\nHowever, they diﬀered signiﬁcantly from DNS in skewness of velocities and RMS of wall-\nnormal velocity and vorticity. On the other hand, CycleGAN shows similar results to\nDNS in all statistics.\nFurther assessment of learnings can be carried out with an investigation of energy\nUnsupervised deep learning for super-resolution reconstruction\n21\nDeep-learning models\nLES\nBicubic\nCNN\ncGAN CycleGAN\nDNS\nMean\nu\n10.255\n10.397\n10.878 10.833\n10.749\n10.725\nv\n0\n0\n0.001\n-0.002\n0.002\n0\nw\n-0.015\n-0.014\n-0.021\n-0.011\n-0.0193\n-0.007\nRMS\nu\n3.115\n3.119\n2.826\n3.102\n2.940\n2.831\nv\n0.324\n0.339\n0.487\n0.652\n0.598\n0.570\nw\n0.945\n0.966\n1.298\n1.361\n1.341\n1.292\nωy\n90.0\n147.5\n142.1\n185.7\n168.5\n161.6\nReynolds stress uv -0.543\n-0.531\n-0.714\n-0.990\n-0.745\n-0.661\nskewness\nu\n0.451\n0.444\n0.338\n0.341\n-0.056\n-0.050\nv\n-1.033\n-1.049\n-0.852\n-1.078\n-0.231\n-0.212\nw\n-0.035\n-0.019\n0.040\n-0.340\n-0.081\n-0.005\nωy\n0.001\n-0.017\n0.001\n-0.119\n-0.081\n-0.008\nﬂatness\nu\n2.731\n2.667\n2.508\n2.650\n2.375\n2.378\nv\n7.702\n6.871\n6.597\n8.809\n6.022\n6.620\nw\n3.695\n3.687\n3.685\n3.761\n3.536\n3.691\nωy\n2.738\n3.306\n3.826\n4.526\n3.570\n3.706\nTable 3. Velocity and vorticity statistics of reconstructed ﬂow ﬁeld at y+ = 15 obtained by\nvarious deep-learning models.\nspectra. The spectrum of the velocity ﬁeld at y+ = 15 is presented in Figure 13, where\nthe streamwise and spanwise spectrum of each component of velocity are shown in\nFigure 13(a),(b), and (c) and Figure 13(d),(e), and (f ), respectively. For comparison,\nthe LES statistics used as input data are presented together, and the vertical dotted\nline indicates the maximum wave number of the LES. Overall, bicubic interpolation\ncould not improve the spectrum of LES. Additionally, the supervised learning models\n(i.e., CNN and cGAN) tended to underestimate DNS statistics at high wave numbers.\nAlthough cGAN appeared to represent small-scale energies in the streamwise and wall-\nnormal directions well (Figure 13(d,e)), it seemed to be a coincidence, given the ﬂow\nﬁeld comparison in Figure 10. It is noteworthy that, for the wall-normal velocity (Figure\n13(b,e)), the supervised learning models could cause large errors, even at low-wave\nnumbers. On the other hand, CycleGAN showed excellent performance in recovering\noverall DNS statistics via the learning of unpaired LES and DNS data. In particular,\neven when there was a diﬀerence in energy between LES and DNS at low wave numbers,\nCycleGAN reproduced DNS statistics properly (Figure 13(b,e)). This indicates that the\nsupervised learning models were sensitive to input data. Thus, it was diﬃcult to expect\ngood performance for new data having distributions diﬀerent from the training data.\nMeanwhile, CycleGAN reconstructed the ﬂow ﬁeld with the statistics of the target ﬁeld\nby reﬂecting the statistical diﬀerences between LES and DNS.\nWe also checked two-point correlations of the reconstructed velocity ﬁeld in Figure 14,\nin which the streamwise and spanwise correlations for various learnings were compared in\n22\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 13. 1D energy spectra for reconstructed velocity ﬁeld at y+ = 15. Streamwise energy\nspectra of (a) streamwise velocity, (b) wall-normal velocity, and (c) spanwise velocity; spanwise\nenergy spectra of (d) streamwise velocity, (e) wall-normal velocity, and (f ) spanwise velocity.\nFigure 14(a),(b), and (c), and ﬁgure 14(d),(e), and (f ). The distribution of all correlations\nby CycleGAN was nearly indiscernible from that of DNS. On the other hand, prediction\nby bicubic interpolation and supervised learning models (i.e., CNN and cGAN) could not\nmimic the DNS statistics, and they tended to be close to the LES statistics. The two-point\ncorrelation of LES data was mostly higher than that of DNS data, because the near-wall\nUnsupervised deep learning for super-resolution reconstruction\n23\nFigure 14. Two-point correlation for reconstructed velocity ﬁeld from LES data at y+ = 15: (a)\nstreamwise velocity, (b) wall-normal velocity, and (c) spanwise velocity in streamwise statistics;\n(d) streamwise velocity, (e) wall-normal velocity, and (f ) spanwise velocity in spanwise ones.\nstructures elongated in the streamwise direction were less tilted in the spanwise direction.\nThe reconstructed ﬂow ﬁelds using supervised learning models could not capture this\ntilted feature, as shown in Figure 10. Additionally, as shown in Figure 14(d,e,f ), the\nminimum position of the spanwise correlation by bicubic interpolation and supervised\nlearning models was quite diﬀerent from that of the DNS. This position as known to be\n24\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 15. (a) Temporal correlation velocities for LES, CycleGAN, and DNS. Right panel of\n(a) is a magniﬁed view of left one near the origin. (b) Temporal behavior of the streamwise\nvelocity ﬁeld at y+ = 15.\nrelated to the spacing of high- and low-speed streak and diameter of streamwise vertical\nstructures (Kim et al. 1987). Therefore, this means that the ﬂow ﬁeld reconstructed\nby supervised learning models contained non-physical structures. However, the accurate\nstatistics of CycleGAN indicated that it could represent physically reasonable structures.\nOur CycleGAN model successfully reconstructed the super-resolution ﬁeld of instanta-\nneous the low-resolution turbulence ﬁeld obtained by ﬁltering, pointwise measurement,\nand independent LES. However, temporal information was not considered during train-\ning. Here, we investigate whether the trained network can reproduce correct temporal\nbehavior of turbulent ﬁeld by testing our model in the reconstruction of temporally\nconsecutive ﬁelds. Temporal correlation, deﬁned as Rt\nViVi(p) = ⟨Vi(t)Vi(t + p)⟩of the\nreconstructed ﬁelds by CycleGAN, is demonstrated with that of DNS and LES data in\nFigure 15, where ⟨⟩denotes an average operation. Clearly, the correlation by CycleGAN\nrecovered that of the DNS, which was quite diﬀerent than that of the LES in the early\nperiod shown in the right panel of ﬁgure 15(a). In Figure 15(b), the spatio-temporal\nbehavior of the streamwise velocity ﬁeld shows that the structures by CycleGAN were\ntilted in the spanwise direction, resembling that of the DNS. This is an encouraging\nresult, because it showed that the temporal information was not necessary for successful\ntraining of super-resolution reconstruction.\nFinally, we investigated the performance of CycleGAN in a test against diﬀerent kinds\nof input LES data. Our CycleGAN was trained and tested using the input LES data\nobtained by the Vreman subgrid-scale model. Here, we tested this CycleGAN for the\ninput LES data obtained by a diﬀerent subgrid-scale model: the Smagorinskly model.\nAs shown in Figure 16, the CycleGAN reconstructed the velocity ﬁelds that reﬂect the\ncharacteristics of DNS, despite the use of data from diﬀerent LES models. Quantitatively,\nthe comparison of the 1D energy spectra of the reconstructed wall-normal velocity\nUnsupervised deep learning for super-resolution reconstruction\n25\nFigure 16. Reconstructed instantaneous velocity ﬁeld (u, v, w) at y+ = 15 from testing the\nCycleGAN model against data obtained using a diﬀerent LES model. The LES model used in\nthe training process is the Vreman model, and the test data contain the velocity ﬁeld from the\nSmagorinsky model.\nbetween LES input data obtained by the Vreman model and the Smagorinsky model\nclearly demonstrates that both yielded nearly the same distribution as that of DNS,\nalthough that from the Smagroinsky LES data showed a slight overestimation for most\nwave numbers, as shown in Figure 17(a). As a cross validation, CycleGAN was trained\nusing LES data obtained by the Smagorinsky model, and it was tested with LES data\nobtained by the Vreman model. As shown in Figure 17(b), CycleGAN reproduced DNS-\nquality reconstructed ﬁelds for both input data. Recall that the cGAN, which was trained\nusing ﬁltered DNS data, could not well-reconstruct DNS-quality data from LES data.\nThis clearly shows the advantage of unsupervised learning in a situation where paired\ndata are not available.\n4. Conclusion\nWe presented an unsupervised learning model that adopted CycleGAN to reconstruct\nsmall-scale turbulence structures when low- and high-resolution ﬁelds were unpaired.\nTo investigate the performance of CycleGAN, an interpolation method (i.e., bicubic\ninterpolation) and supervised learning models (i.e., CNN and cGAN) were considered.\nThe supervised learning models were trained using paired low- and high-resolution data.\nWe considered homogeneous isotropic turbulence and a turbulent channel ﬂow where\npaired data existed. Finally, we demonstrated super-resolution reconstruction with DNS\ncharacteristics from LES ﬁelds in a channel ﬂow where only unpaired data exist.\nFirst, we investigated the performance of various learning models for diﬀerent resolu-\ntion ratios, r, between input ﬁelds obtained by applying a top-hat ﬁlter to DNS data,\nand we output DNS ﬁelds in homogeneous isotropic turbulence. Bicubic interpolation\n26\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 17. 1D energy spectra for reconstructed wall-normal velocity ﬁeld at y+ = 15. (a)\nTest results of the CycleGAN trained using LES data obtained from the Vreman subgrid-scale\nmodel; (b) test results of the CycleGAN trained using LES data obtained from the Smagorinsky\nsubgrid-scale model. CycleGANVR and CycleGANSM denote CycleGAN models trained using\nLES data of Vreman and Smagorinsky models, respectively. LESVR and LESSM are LES input\ndata from the Vreman and Smagorinsky models, respectively.\nand CNN did not well reconstruct the small-scale structures. The energy spectrum and\nvorticity p.d.f. statistics yielded by bicubic interpolation and CNN were rather similar\nto those of low-resolution input data. On the other hand, cGAN showed excellent ability\nto recover small scales, even for large r. Similarly, our CycleGAN provided excellent\nperformance in the reproduction of energy spectrum and p.d.f. of vorticity, despite using\nunpaired data.\nNext, we assessed the performance of the super-resolution reconstruction of anisotropic\nturbulence in a limited measurement environment. Low-resolution data were extracted\nby pointwise measurement of high-resolution DNS data at y+ = 15 and 100 of channel\nturbulence. The phase shift of structures in the reconstructed ﬂow ﬁeld from unsupervised\nlearning in spatially homogeneous data was eliminated by introducing pixel loss, which is\nthe point-by-point MSE of the measured information. As predicted, bicubic interpolation\nand CNN did not reconstruct small-scale structures, similar to the previous example.\nOn the other hand, the cGAN showed high accuracy in reconstruction, reﬂecting the\nUnsupervised deep learning for super-resolution reconstruction\n27\ncharacteristics of the DNS. The ﬂow ﬁelds reconstructed through CycleGAN were good\nas those provided by the cGAN, and their statistics were similar to those of DNS.\nFinally, CycleGAN was applied to a more practical problem of reconstructing a ﬂow\nﬁeld with DNS quality from LES data unpaired from DNS data. Supervised learning\nmodels (i.e., CNN and cGAN) were trained using ﬁltered DNS data, because paired\ndata were not available. Trained CNN and cGAN did not produce small scales, and\nthe reconstructed ﬂow ﬁeld had diﬀerent structures from the DNS data. All statistics,\nincluding the p.d.f. of velocity and vorticity, the energy spectrum, and the two-point\ncorrelations, showed a completely diﬀerent distribution from those of DNS. On the other\nhand, CycleGAN eﬀectively reconstructed the ﬂow ﬁeld that reﬂected the structures\nof each velocity and vorticity observed in DNS. All statistical quantities produced by\nCycleGAN were consistent with those of DNS. The temporal behavior of turbulent ﬁelds\nwere correctly captured by the reproduced ﬁelds obtained by the application of CycleGAN\nto consecutive LES ﬁelds. Finally, we applied CycleGAN to LES data using a diﬀerent\nsubgrid-scale model that was not used for training, and it showed excellent performance.\nThere are several remaining issues that should be considered in future works. First,\nlow-resolution data lack information required to uniquely reproduce high-resolution data\nin general. When the resolution ratio is large, diﬀerent high-resolution data can be\ngenerated, depending on the initial value of trainable parameters in the network, and\ntrained networks randomly map only one of many possible high-resolution solutions.\nHowever, this might be unavoidable because of the intrinsic nature of turbulence and its\nstrong sensitivity to small disturbances. Second, when low-resolution data are provided\non an irregular mesh rather than on a uniform mesh, it is inappropriate to apply the\ncurrent convolution operation. A technique, such as graph CNN (Kipf & Welling 2016),\ncould be used to resolve this problem. Third, the present study assumed that there was\na suﬃcient amount of high-resolution data for training. There might be some situations\nin which only limited amount of high-resolution data or even no data are available. Good\nsolutions should include data augmentation using symmetry, physics-informed NNs that\nimpose constraints of governing equation (continuity or momentum equations) (Raissi\net al. 2019), and physical constraints added to the NN (Mohan et al. 2020). Fourth, the\ncurrent study was limited to the super-resolution reconstruction of the instantaneous 2D\nﬂow ﬁeld, but a consideration of the temporal behavior or 3D information of the ﬂow\nmight yield better or more eﬃcient reconstructions. For example, it is possible to account\nfor temporally successive data by adding a discriminator that considers temporal eﬀects\n(Xie et al. 2018; Kim & Lee 2020a). Finally, the analysis of trained network was diﬃcult\nbecause of the large number of parameters. Kim & Lee (2020b), for example, identiﬁed\nthat the gradient map of trained model could be used to extract the physics implied in\nthe training data. This progress, with respect to super-resolution reconstruction, might\nhelp identify a nonlinear relationship between large-scale structures and small-scale ones.\nWe have shown that super-resolution reconstruction of turbulence using CycleGAN is\npossible in situations where paired data are not available. We expect that the proposed\nnetwork will be of great assistance to LES modeling, including the production of pair data\nfor the development of subgrid-scale models and synchronizations for model evaluation.\nFurthermore, our model can be utilized to support high-resolution reconstruction of\nmeasurement data, such as PIV (Rabault et al. 2017; Cai et al. 2020), synchronization of\ndiﬀerent experiments, removal of experimental noise, and data assimilation (Leoni et al.\n2020).\nAcknowledgments\n28\nH. Kim, J. Kim, S. Won and C. Lee\nThis work was supported by a National Research Foundation of Korea (NRF) grant\nfunded by the Korea government (MSIP) (2017R1E1A1A03070282).\nAppendix A. Network architecture and hyperparameters of deep\nlearning model\nFigure 18 shows the network architecture of components of CycleGAN when the\nresolution ratio was eight. A CycleGAN consisted of two generators (Figure 18(a) G\nand (b) F) and two discriminators (Figure 18(c) DX and (d) DY ). The objective of\nlearning was to obtain G that could reconstruct the high-resolution turbulent ﬁeld. G\ncomprised convolution (Conv. in Figure 18) and up-sampling operations, repetitively. F,\nDX, and DY comprised convolution and down-sampling operations. In DX and DY , a\nfully connected layer (FC in Figure 18) was additionally used to yield one value. The\nsize of the discrete convolution operation was ﬁxed at 3 × 3. During this process, a\npadding was used to maintain the size of input data. Zero padding was used during\nthe training process, and periodic padding was used during testing to automatically\nsatisfy the periodic boundary condition. Nearest-neighborhood interpolation and average\npooling were used for up- and down-sampling with 2 × 2 size, respectively. Following the\nconvolutions and fully connected layers, except for the last layer, a nonlinear activation\nfunction (Leaky ReLU in Equation 2.6) was applied. Depending on the resolution ratio,\nthe number of convolution layers, up- and down-sampling operations in the network\nchanged slightly. Trainable parameters were randomly initialized (He et al. 2015b).\nDuring training, learning rate, batch size, and total iterations were 0.0001, 16, and\n500,000, respectively. The Adam optimizer (Kingma & Ba 2014) was used for minimizing\nand maximizing the objective function. There was room for improvement via changes in\narchitecture, such as batch normalization (Ioﬀe & Szegedy 2015), residual networks (He\net al. 2015a), and ﬁne-tuning of hyperparameters.\nThe supervised learning models (i.e., CNN and cGAN), which were used for compar-\nison, comprised the same generator network as G of CycleGAN. The discriminator of\ncGAN was nearly the same as DY of CycleGAN, except for the channel size of the input.\nThe same hyperparameters were used for CNN, cGAN, and CycleGAN, except for the\nlearning rate and total iterations of the CNN. The initial learning rate of CNN was\n0.0005, and we reduced it by 1/5 when the validation error did not decrease.\nAppendix B. Test in the outer-region of wall-bounded turbulent ﬂows\nIn section 3.2, we applied CycleGAN to the reconstruction of the velocity ﬁelds\n(u, v, w) from partially measured data at y+ = 15 and 100. Considering that the input\nwas pointwise measurement data, we additionally used point-by-point pixel loss during\ntraining. The phase of the high wave-number components in the reconstructed velocity\nﬁeld at y+ = 15 was more accurate than that at y+ = 100, as shown in ﬁgure 7. The\nreason might be that ﬂuctuation intensity in the near-wall region was stronger than that\nof the outer-region. However, at y+ = 100, the reconstructed velocity ﬁeld of CycleGAN\nwas as accurate as that of cGAN, which showed the best performance among supervised\nlearning models, as shown in Figure 19. The bicubic interpolation and CNN captured\nonly large-scale structures, compared with DNS. In 1D energy spectra of reconstructed\nvelocity ﬁelds (Figure 20), our model showed excellent performance, similar to DNS and\ncGAN. There was only a slight error with the DNS for a few speciﬁc wave numbers. The\nerror was related to the up-sampling scheme in generator G. The error could be avoided\nby changing the nearest-neighborhood interpolation using only linear data (Karras et al.\nUnsupervised deep learning for super-resolution reconstruction\n29\nFigure 18. Network architecture of generators and discriminators of CycleGAN for resolution\nratio r = 8. (a) generator G. (b) generator F. (b) discriminator DY . (d) discriminator DX.\n30\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 19. Reconstructed instantaneous velocity ﬁelds at y+ = 100 obtained by various deep\nlearning models.\n2018). On the other hand, the statistics of the bicubic interpolation and CNN did not\nfollow those of the DNS at high wave numbers. These results indicate that the CycleGAN\nwas good enough to replace supervised learning models, which require paired datasets.\nAppendix C. Validation of large eddy simulation\nFor the development of an unsupervised learning model, we required LES data, which\nwas obtained by carrying out a large-eddy simulation of turbulent channel ﬂow. A periodic\nboundary condition was imposed in the streamwise and spanwise directions. The constant\nmean pressure gradient drove a mean ﬂow in the streamwise direction. The boundary\nlayer was developed using a no-slip boundary condition at the top and bottom walls.\nGoverning equations were those of ﬁltered incompressible Navier–Stokes equations, which\nUnsupervised deep learning for super-resolution reconstruction\n31\nFigure 20. One-dimensional energy spectra for reconstructed velocity ﬁeld at y+ = 100:\nStreamwise energy spectra of (a) streamwise velocity, (b) wall-normal velocity and (c) spanwise\nvelocity. Spanwise energy spectra of (d) streamwise velocity, (e) wall-normal velocity and (f )\nspanwise velocity.\ncan be written as follows:\n∂¯ui\n∂xi\n= 0,\n(C 1)\n32\nH. Kim, J. Kim, S. Won and C. Lee\nFigure 21. (a) Mean velocity proﬁle in wall units, and (b) RMS velocity proﬁles obtained by\nLES with the Vreman and Smagorinsky models.\n∂¯ui\n∂t + ∂¯uj ¯ui\n∂xj\n= −∂¯p\n∂xi\n+\n1\nReτ\n∂2¯ui\n∂xj∂xj\n−∂τij\n∂xj\n.\n(C 2)\nEquations were made dimensionless using the friction velocity, uτ, and the channel half-\nwidth, δ. Here, ¯ui was the ﬁltered velocity, and τij was the subgrid-scale stress that should\nbe modeled. We used two kinds of subgrid-scale models: Smagorinsky (Smagorinsky 1963)\nand Vreman (Vreman 2004). Furthermore, the Van Driest damping, which multiplies\nthe subgrid-scale stress by (1 −e−y+/25)2, was applied to the Smagorinsky model. We\ncontrolled the Smagorinsky constant, Cs, to ﬁt the mean proﬁle of the LES to that of\nthe DNS. As a result, Cs = 0.17 for both models. The third-order hybrid Runge–Kutta\nscheme was used for time integration (Rai & Moin 1991), and the second-order central\ndiﬀerence scheme was used for spatial discretization. We distributed a uniform grid in\nthe horizontal direction, and a non-uniform grid with a hyperbolic tangent function in\nthe wall-normal direction. We carried out LES with both subgrid-scale models using the\nsame grid resolution of 128 × 256 × 128 and the same domain size of 2πδ × 2δ × πδ at\nReτ = 1, 000. The resolution ratio, r, between our LES and the DNS of the JHTDB at\nthe same Reynolds number as four for in both steamwise and spanwise directions. The\ntime-interval, ∆t = 0.0004, which was non-dimensionalized with uτ and δ. The time-\naveraged mean and RMS proﬁles are given in Figure 21. Although there is a slight gap in\nthe RMS proﬁle, owing to the low grid-resolution, the trend of statistics was consistent\nwith that of the DNS. For training, we collected 10,000 velocity ﬁelds in the x −z plane\nat y+ = 15. The time-interval between temporally successive ﬁelds was ∆t = 0.004. For\ntesting, we used new data suﬃciently far from the training data.\nREFERENCES\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S.,\nDavis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving,\nG., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J.,\nMan´e, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J.,\nSteiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan,\nV., Vi´egas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y.\n& Zheng, X. 2015 Tensorﬂow: Large-scale machine learning on heterogeneous systems.\nSoftware available from tensorﬂow.org.\nUnsupervised deep learning for super-resolution reconstruction\n33\nBeck, A., Flad, D. & Munz, C.-D. 2019 Deep neural networks for data-driven LES closure\nmodels. J. Comput. Phys. 398, 108910.\nCai, S., Liang, J., Gao, Q., Xu, C. & Wei, R. 2020 Particle image velocimetry based on a\ndeep learning motion estimator. IEEE Trans. Instrum. Meas. 69 (6), 3538–3554.\nDeng, Z., He, C., Liu, Y. & Kim, K. 2019 Super-resolution reconstruction of turbulent velocity\nﬁelds using a generative adversarial network-based artiﬁcial intelligence framework. Phys.\nFluids 31 (12), 125111.\nDuraisamy, K., Iaccarino, G. & Xiao, H. 2019 Turbulence modeling in the age of data.\nAnnu. Rev. Fluid Mech. 51 (1), 357–377.\nFukami, K., Fukagata, K. & Taira, K. 2019 Super-resolution reconstruction of turbulent\nﬂows with machine learning. J. Fluid Mech. 870, 106–120.\nGamahara, M. & Hattori, Y. 2017 Searching for turbulence models by artiﬁcial neural\nnetwork. Phys. Rev. Fluids 2 (5), 054604.\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,\nCourville, A. & Bengio, Y. 2014 Generative adversarial nets. In NIPS, pp. 2672–2680.\nGraham, J., Kanov, K., Yang, X. I. A., Lee, M., Malaya, N., Lalescu, C. C., Burns, R.,\nEyink, G., Szalay, A., Moser, R. D. & Meneveau, C. 2015 A web services accessible\ndatabase of turbulent channel ﬂow and its use for testing a new integral wall model for\nLES. J. Turbul. 17 (2), 181–215.\nGulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V. & Courville, A. 2017 Improved\ntraining of Wasserstein GANs. In NIPS, pp. 5767–5777.\nHe, K., Zhang, X., Ren, S. & Sun, J. 2015a Deep residual learning for image recognition.\narXiv preprint arXiv:1512.03385v1 .\nHe, K., Zhang, X., Ren, S. & Sun, J. 2015b Delving deep into rectiﬁers: Surpassing human-\nlevel performance on ImageNet classiﬁcation. In ICCV . IEEE.\nHornik, K., Stinchcombe, M. & White, H. 1989 Multilayer feedforward networks are\nuniversal approximators. Neural Netw. 2 (5), 359–366.\nIoffe, S. & Szegedy, C. 2015 Batch normalization: Accelerating deep network training by\nreducing internal covariate shift. arXiv preprint arXiv:1502.03167 .\nKarras, T., Laine, S. & Aila, T. 2018 A style-based generator architecture for generative\nadversarial networks. arXiv preprint arXiv:1812.04948v3 .\nKim, J. & Lee, C. 2020a Deep unsupervised learning of turbulence for inﬂow generation at\nvarious Reynolds numbers. J. Comput. Phys. 406, 109216.\nKim, J. & Lee, C. 2020b Prediction of turbulent heat transfer using convolutional neural\nnetworks. J. Fluid Mech. 882, A18.\nKim, J., Moin, P. & Moser, R. 1987 Turbulence statistics in fully developed channel ﬂow at\nlow Reynolds number. J. Fluid Mech. 177, 133–166.\nKingma, D. P. & Ba, J. L. 2014 Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980 .\nKipf,\nThomas\nN.\n&\nWelling,\nMax 2016 Semi-supervised classiﬁcation with graph\nconvolutional networks , arXiv: http://arxiv.org/abs/1609.02907v4.\nKutz, J. N. 2017 Deep learning in ﬂuid dynamics. J. Fluid Mech. 814, 1–4.\nLeCun, Y., Bengio, Y. & Hinton, G 2015 Deep learning. Nature 521 (7553), 436–444.\nLee, C., Kim, J., Babcock, D. & Goodman, R. 1997 Application of neural networks to\nturbulence control for drag reduction. Phys. Fluids 9 (6), 1740–1747.\nLee, S. & You, D. 2019 Data-driven prediction of unsteady ﬂow over a circular cylinder using\ndeep learning. J. Fluid Mech. 879, 217–254.\nLeoni, P. C. Di, Mazzino, A. & Biferale, L. 2020 Synchronization to big data: Nudging\nthe navier-stokes equations for data assimilation of turbulent ﬂows. Phys. Rev. X 10 (1).\nLi, Y., Perlman, E., Wan, M., Yang, Y., Meneveau, C., Burns, R., Chen, S., Szalay,\nA. & Eyink, G. 2008 A public turbulence database cluster and applications to study\nLagrangian evolution of velocity increments in turbulence. J. Turbul. 9, N31.\nLing, J., Kurzawski, A. & Templeton, J. 2016 Reynolds averaged turbulence modelling\nusing deep neural networks with embedded invariance. J. Fluid Mech. 807, 155–166.\nLiu, Bo, Tang, Jiupeng, Huang, Haibo & Lu, Xi-Yun 2020 Deep learning methods for\nsuper-resolution reconstruction of turbulent ﬂows. Phys. Fluids 32 (2), 025105.\n34\nH. Kim, J. Kim, S. Won and C. Lee\nMaulik, R. & San, O. 2017 A neural network approach for the blind deconvolution of turbulent\nﬂows. J. Fluid Mech. 831, 151–181.\nMaulik, R., San, O., Rasheed, A. & Vedula, P. 2019 Subgrid modelling for two-dimensional\nturbulence using neural networks. J. Fluid Mech. 858, 122–144.\nMilano, M. & Koumoutsakos, P. 2002 Neural network modeling for near wall turbulent ﬂow.\nJ. Comput. Phys. 182 (1), 1–26.\nMirza,\nM.\n&\nOsindero,\nS.\n2014\nConditional\ngenerative\nadversarial\nnets.\nhttp://arxiv.org/abs/1411.1784v1 .\nMohan,\nA.\nT.,\nLubbers,\nN.,\nLivescu,\nD.\n&\nChertkov,\nM.\n2020\nEmbedding\nhard\nphysical\nconstraints\nin\nneural\nnetwork\ncoarse-graining\nof\n3d\nturbulence.\nhttp://arxiv.org/abs/2002.00021v2 .\nParish, E. J. & Duraisamy, K. 2016 A paradigm for data-driven predictive modeling using\nﬁeld inversion and machine learning. J. Comput. Phys. 305, 758–774.\nPerlman, E., Burns, R., Li, Y. & Meneveau, C. 2007 Data exploration of turbulence\nsimulations using a database cluster. In Proceedings of the 2007 ACM/IEEE Conference\non Supercomputing. ACM Press.\nRabault, J., Kolaas, J. & Jensen, A. 2017 Performing particle image velocimetry using\nartiﬁcial neural networks: a proof-of-concept. Meas. Sci. Technol. 28 (12), 125301.\nRabault, J., Kuchta, M., Jensen, A., R´eglade, U. & Cerardi, N. 2019 Artiﬁcial neural\nnetworks trained through deep reinforcement learning discover control strategies for active\nﬂow control. J. Fluid Mech. 865, 281–302.\nRai, M. M. & Moin, P 1991 Direct simulations of turbulent ﬂow using ﬁnite-diﬀerence schemes.\nJ. Comput. Phys. 96 (1), 15–53.\nRaissi, M., Perdikaris, P. & Karniadakis, G.E. 2019 Physics-informed neural networks:\nA deep learning framework for solving forward and inverse problems involving nonlinear\npartial diﬀerential equations. J. Comput. Phys. 378, 686–707.\nRaissi, M., Yazdani, A. & Karniadakis, G. E. 2020 Hidden ﬂuid mechanics: Learning velocity\nand pressure ﬁelds from ﬂow visualizations. Science 367 (6481), 1026–1030.\nSmagorinsky, J. 1963 General circulation experiments with primitive equations. Mon. Weath.\nRev. 91 (3), 99–164.\nSrinivasan, P. A., Guastoni, L., Azizpour, H., Schlatter, P. & Vinuesa, R. 2019\nPredictions of turbulent shear ﬂows using deep neural networks. Phys. Rev. Fluids 4 (5).\nVerma, S., Novati, G. & Koumoutsakos, P. 2018 Eﬃcient collective swimming by harnessing\nvortices through deep reinforcement learning. Proc. Natl. Acad. Sci. 115 (23), 5849–5854.\nVreman, A. W. 2004 An eddy-viscosity subgrid-scale model for turbulent shear ﬂow: Algebraic\ntheory and applications. Phys. Fluids 16 (10), 3670–3681.\nWang, J.-X., Wu, J.-L. & Xiao, H. 2017 Physics-informed machine learning approach for\nreconstructing Reynolds stress modeling discrepancies based on DNS data. Phys. Rev.\nFluids 2 (3).\nXie, C., Wang, J., Li, K. & Ma, C. 2019 Artiﬁcial neural network approach to large-eddy\nsimulation of compressible isotropic turbulence. Phys. Rev. E 99 (5).\nXie, Y., Franz, E., Chu, M. & Thuerey, N. 2018 tempoGAN: A temporally coherent,\nvolumetric GAN for super-resolution ﬂuid ﬂow. arXiv preprint arXiv:1801.09710v2 .\nZhu, J.-Y., Park, T., Isola, P. & Efros, A. A. 2017 Unpaired image-to-image translation\nusing cycle-consistent adversarial networks. In ICCV . IEEE.\n",
  "categories": [
    "physics.flu-dyn"
  ],
  "published": "2020-07-30",
  "updated": "2020-07-30"
}