{
  "id": "http://arxiv.org/abs/2009.03394v3",
  "title": "Deep Learning, Predictability, and Optimal Portfolio Returns",
  "authors": [
    "Mykola Babiak",
    "Jozef Barunik"
  ],
  "abstract": "We study dynamic portfolio choice of a long-horizon investor who uses deep\nlearning methods to predict equity returns when forming optimal portfolios. Our\nresults show statistically and economically significant benefits from using\ndeep learning to form optimal portfolios through certainty equivalent returns\nand Sharpe ratios. We demonstrate that a long-short-term-memory recurrent\nneural network, which excels in learning complex time-series dependencies,\ngenerates a superior performance among a variety of networks considered. Return\npredictability via deep learning generates substantially improved portfolio\nperformance across different subsamples, particularly during recessionary\nperiods. These gains are robust to including transaction costs, short-selling\nand borrowing constraints.",
  "text": "Deep Learning, Predictability, and Optimal\nPortfolio Returns∗\nMykola Babiak†\nJozef Baruník‡\nAbstract\nWe study dynamic portfolio choice of a long-horizon investor who uses deep learning methods to\npredict equity returns when forming optimal portfolios.\nOur results show statistically and eco-\nnomically signiﬁcant beneﬁts from using deep learning to form optimal portfolios through certainty\nequivalent returns and Sharpe ratios. We demonstrate that a long-short-term-memory recurrent\nneural network, which excels in learning complex time-series dependencies, generates a superior\nperformance among a variety of networks considered. Return predictability via deep learning gen-\nerates substantially improved portfolio performance across diﬀerent subsamples, particularly during\nrecessionary periods. These gains are robust to including transaction costs, short-selling and bor-\nrowing constraints.\nKeywords: Return Predictability, Portfolio Allocation, Machine Learning, Neural Networks, Em-\npirical Asset Pricing\nJEL codes: C45, C53, E37, G11, G17\n∗Jozef Barunik gratefully acknowledges support from the Czech Science Foundation under the EXPRO\nGX19-28231X project.\n†Department of Accounting and Finance, Lancaster University Management School, Lancaster, LA1 4YX,\nUK. E-mail: m.babiak@lancaster.ac.uk Web: sites.google.com/site/mykolababiak\n‡Institute of Economic Studies, Charles University, Opletalova 26, 110 00, Prague, CR and Institute of\nInformation Theory and Automation, Academy of Sciences of the Czech Republic, Pod Vodarenskou Vezi 4,\n18200, Prague, Czech Republic. E-mail: barunik@utia.cas.cz Web: barunik.github.io\n1\narXiv:2009.03394v3  [q-fin.GN]  21 Jul 2021\n1\nIntroduction\nExtensive empirical asset pricing literature has documented supportive evidence for equity\nreturn predictability.1 With an ever increasing number of potential predictors, the practice\nof applying machine learning methods to make the most accurate predictions using large\ndatasets is gaining further traction.2 This new literature demonstrates superior performance\nof machine learning approaches relative to the linear regression analysis researchers favor\ndue to its simplicity.3 However, it is unclear whether sound statistical performance of ma-\nchine learning leads to portfolio gains for an investor who applies these models of return\npredictability when forming optimal portfolios.4\nIn this paper, we examine the economic value of non-linear machine learning methods,\nsuch as neural networks (NNs), for an investor forming optimal portfolios. We study the asset\nallocation of a long-horizon investor with a power utility choosing between a market portfolio\nand a risk-free asset. Our optimal portfolio design exercise follows Johannes et al. (2014) and\nour statistical comparison is similar to Gu et al. (2020). To this end, we implement a variety\nof machine learning architectures including shallow and deep feedforward NNs, as well as\nlong-short-term-memory (LSTM) recurrent NNs. On the methodology side, while there is\nan extensive literature on statistical and economic signiﬁcance of standard feedforward NNs\nexploring information contained in cross-section of returns, we are the ﬁrst to explore the\n1See, for example, Campbell (1987); Campbell and Shiller (1988); Fama and French (1988, 1989); Ferson\nand Harvey (1991); Pesaran and Timmermann (1995); Lettau and Ludvigson (2001); Lewellen (2004) and\nAng and Bekaert (2007) among many others.\n2See, for example, Rapach et al. (2010); Kelly and Pruitt (2013, 2015); Sirignano et al. (2016); Giannone\net al. (2017); Giglio and Xiu (2017); Heaton et al. (2017); Messmer (2017); Feng et al. (2018); Fuster et al.\n(2018); Chen et al. (2019); Feng et al. (2019); Kelly et al. (2019); Bianchi et al. (2020); Freyberger et al.\n(2020); Gu et al. (2020); Kozak et al. (2020).\n3Goyal and Welch (2008) use around 20 ﬁnancial and macroeconomic variables for the aggregate market\nreturns. Green et al. (2013) list more than 330 return predictive signals used by the existing literature over\nthe 1970-2010 period. Harvey et al. (2016) report 316 “factors” useful for predicting stock returns.\n4The existing evidence on using linear models indicates that an ensemble of additional features are required\nto improve portfolio performance that stems from linear predictive regressions. Additional ingredients include\nlearning about predictability with informative priors (Wachter and Warusawitharana, 2009) and an ensemble\nof estimation risk and time-varying volatility (Johannes et al., 2014).\n2\nLSTM recurrent NNs that are more suitable for prediction of time series.5 We argue that time\nseries dependence is important feature to be explored and we document that LSTM recurrent\nNNs being able to identify time-series dependence deliver larger portfolio gains. The reason\nfor the documented gains is that an LSTM is a specialized form of a neural network, which is\ncapable of learning complex long-term temporal dynamics and hence explore the time series\ndependence that vanilla NN is unable to learn.\nOur contribution to the portfolio literature is threefold. First, we show that using ma-\nchine learning methods for the construction of optimal portfolios generates economically\nsigniﬁcant gains. Speciﬁcally, we document that deviating from the Expectations Hypothe-\nsis and using NNs to forecast excess returns results in three times higher Sharpe ratios (SRs)\nand twice as high certainty equivalent returns (CERs). This evidence contributes to the\ndebate on the economic value of equity return predictability (Goyal and Welch, 2008; Jo-\nhannes et al., 2014; Rossi, 2018). Furthermore, our evidence on the beneﬁts of NNs is robust\nto alternative measures of portfolio performance (cumulative return, maximum drawdown,\nand maximum one-month loss) and to the inclusion of transaction costs, short-selling and\nborrowing constraints. Our results are consistent with Johannes et al. (2014) who report\nsigniﬁcant portfolio beneﬁts from second-moment temporal dependence in equity returns.\nUsing machine learning allows us to explore even more complex dependencies in a model-\nfree way.\nMoreover, dissecting the economic gains of NNs across subsamples, we ﬁnd that, histor-\nically, machine learning methods generate the highest CERs in each of the seven decades\nin the post-WWII period. Interestingly, NNs generate on average twice larger SRs during\nNBER recessions compared to the periods of expansion. In particular, we ﬁnd that all NNs\nare able to generate signiﬁcant gains during the 2007-2008 Financial Crisis. Finally, an in-\nvestor beneﬁts more from NNs by rebalancing her portfolio more frequently, as opposed to\n5Recently, Jiang et al. (2020) demonstrate in a very diﬀerent setting how convolutional NNs, a class of\nrecurrent NNs, can be used to learn price patterns from images.\n3\napplying a passive strategy. We show that the gains are not eliminated by the increased\nturnover.\nSecond, compared to the existing evidence for linear models, deep learning methods pro-\nvide a single “silver bullet” by generating out-of-sample gains without relying on additional\ningredients. We demonstrate that portfolio performance when using NNs dominates strate-\ngies using the linear predictive models even when time-varying return volatility is omitted.\nOur evidence is consistent with Goyal and Welch (2008) and Johannes et al. (2014) in that\nwe also do not identify beneﬁts from using linear models without estimation risk and time-\nvarying volatility. We contribute to the literature by showing that the empirical evidence for\nthe predictability of equity returns is economically signiﬁcant even in the absence of these\nadditional ingredients, provided the investor uses non-linear machine learning methods to\ndetect this predictive variation.\nOur third contribution is related to the properties of economic gains implied by NNs.\nWe ﬁnd that increasing the complexity of deep learning architectures does not necessarily\ntranslate into improved portfolio performance.\nWe document that moving from shallow\nsettings with one hidden layer to deeper speciﬁcations does not result in additional gains.\nThis seems to be a surprising result, but ﬁnance and return predictions in particular operate\nin a challenging data environment that diﬀers substantially from other domains where deep\nlearning results in large improvements.\nSpeciﬁcally, return predictions with the goal of\noptimal portfolio construction is a small sample problem with the data facing very low signal-\nto-noise ratio (Israel et al., 2020) and increased network complexity does not necessarily help.\nImportantly, we document that inclusion of deep recurrent LSTM networks that capture\nimportant temporal dynamics improves performance according to all portfolio performance\nmeasures we consider. In this respect, our paper contributes to the evidence on economic\ninformation captured by NNs. Speciﬁcally, we extend the evidence presented by Rossi (2018)\nfor boosted regression trees and show that, apart from the important non-linear relationship,\nlong-term memory eﬀects are particularly beneﬁcial in short samples.\n4\nThe remainder of this paper is organized as follows. Section 2 discusses standard ap-\nproaches to assessing expected return predictability, introduces non-linear machine learning\nmethods we consider, describes the portfolio choice problem of an investor, and outlines a\nvariety of performance measures. Section 3 describes the data and summarizes the results.\nSection 4 dissects the economic gains from using NNs across subperiods and provides ro-\nbustness checks to using alternative performance measures or including transaction costs,\nborrowing and short-selling constraints. Section 5 concludes.\n2\nEvaluating Predictability via Portfolio Performance\n2.1\nThe Simple Linear Approach\nThe standard approach used to forecast excess equity returns is a linear model of the form\nrt+1 = α + βxt + εr\nt+1,\n(1)\nwhere rt+1 are monthly log excess returns, α and β are coeﬃcients to be estimated, xt =\n(x1\nt, ..., xn\nt ) is a set of predictor variables, and εr\nt+1 is a normal error term. A large strand of\nempirical literature has examined linear regression models with multiple predictors including\nprominent variables such as the dividend yield, valuation ratios, various interest rates and\nspreads, among others.6 Although researchers have proposed numerous variables for predict-\ning stock market returns, empirical evidence on the degree of predictability is mixed at best.\nGoyal and Welch (2008) ﬁnd that most linear speciﬁcations with multiple predictors perform\npoorly and remain insigniﬁcant even in-sample. They further show that an investor using\nlinear models to forecast equity returns would not be able to improve portfolio performance\ncompared to no predictability benchmark.\n6See, for example, Shiller (1981); Hodrick (1992); Stambaugh (1999); Avramov (2002); Cremers (2002);\nFerson et al. (2003); Lewellen (2004); Torous et al. (2004); Campbell and Yogo (2006); Ang and Bekaert\n(2007); Campbell and Thompson (2008); Cochrane (2008); Lettau and Van Nieuwerburgh (2008); Pástor\nand Stambaugh (2009).\n5\nThere are several reasons for the lack of robust evidence on the predictability equity\nreturns and its beneﬁts for portfolio construction. The speciﬁcation deﬁned by Eq.(1) as-\nsumes a linear and time-invariant relationship between log excess returns and predictors,\nwhich is at odds with the theoretical and empirical evidence.7\nBayesian learning about\nuncertain parameters in the linear regression has been proposed as a way to introduce a\ntime-varying relationship between the returns and predictor variables. However, sequential\nparameter learning leads to signiﬁcant portfolio beneﬁts only in the presence of a highly\ninformative prior (Wachter and Warusawitharana, 2009) or a combination of estimation risk\nand time-varying volatility (Johannes et al., 2014). Thus, prior knowledge about the nature\nof expected return predictability or careful modeling of its conditional features, especially\ntime variation in return volatility, are critical for generating economic gains.\nThis paper follows an alternative approach inspired by the recent development of ma-\nchine learning in empirical asset pricing literature.8 Speciﬁcally, we apply neural networks to\napproximate the functional association between the set of predictors and returns for optimal\nportfolio construction. In doing so, we do not impose a known form of this relationship, but\ninstead allow for ﬂexible identiﬁcation of potentially nonlinear interactions from the data.\nOur choice of neural networks over other machine learning methods (for instance, tree-based\napproaches) is motivated by the fact that they deliver the most accurate statistical perfor-\nmance, as documented by the existing literature. The aim of this paper is to revisit the\nevidence documented by Goyal and Welch (2008) and to show that, unlike linear predictive\nregressions, sound statistical performance of neural networks indeed translates into substan-\ntial portfolio improvements for an investor using these novel methods when dynamically\nforming an optimal portfolio.\n7Leading examples of this literature include Menzly et al. (2004); Paye and Timmermann (2006); Santos\nand Veronesi (2006); Lettau and Van Nieuwerburgh (2008); Henkel et al. (2011); Dangl and Halling (2012).\n8Leading studies include Giglio and Xiu (2017); Heaton et al. (2017); Feng et al. (2018, 2019); Chen et al.\n(2019); Kelly et al. (2019); Freyberger et al. (2020); Gu et al. (2020); Kozak et al. (2020).\n6\n2.2\nFrom Linear Regression Towards Deep Learning\nMachine learning has a long history in economics and ﬁnance (Hutchinson et al., 1994;\nKuan and White, 1994; Racine, 2001; Baillie and Kapetanios, 2007). At its core, one may\nperceive machine learning as a general statistical analysis that economists can use to capture\ncomplex relationships that are hidden when using simple linear methods. Breiman et al.\n(2001) emphasize that maximizing prediction accuracy in the face of an unknown model\ndiﬀerentiates machine learning from the more traditional statistical objective of estimating a\nmodel assuming a data generating process. Building on this, machine learning seeks to choose\nthe most preferable model from an unknown pool of models using innovative optimization\ntechniques. As opposed to traditional measures of ﬁt, machine learning focuses on the out-\nof-sample forecasting performance and understanding the bias-variance tradeoﬀ; as well as\nusing data driven techniques that concentrate on ﬁnding structures in large datasets.\nWhile ﬁnance is focused on expected return predictability, the ability of machine learning\ntechniques to ﬁnd relationships in data seems well-suited for ﬁnancial applications. Further,\nif one dismisses the “black-box” view of machine learning as a misconception (Lopez de\nPrado, 2019), it seems nothing should stop a researcher from exploring the power of these\nmethods in ﬁnancial data. However, problems in ﬁnance diﬀer from typical machine learning\napplications in many aspects. In order to enjoy the beneﬁts of machine learning, a user needs\nto understand key challenges brought by ﬁnancial data.\nIsrael et al. (2020) note that machine learning applied to ﬁnance is challenged by small\nsample sizes, naturally low signal-to-noise ratios making market behavior diﬃcult to predict\nand the dynamic character of markets.\nBecause of these critical issues, the beneﬁts of\nmachine learning are not so obvious as in other ﬁelds and research into understanding how\nimpactful machine learning can be for asset management is just emerging. With the surge\nin deep learning literature, machine learning applications in ﬁnance have begun to emerge\n(Heaton et al., 2017; Feng et al., 2018; Bryzgalova et al., 2019; Bianchi et al., 2020; Chen\n7\nFigure 1. (Deep) Feedforward Network\nThis ﬁgure illustrates a deep neural network model rt+1 = fW,b(xt) + εr\nt+1 that predicts output return rt+1\nusing a set of predictor variables xt = (x1\nt, ..., xn\nt ). The network is deep, with a number of hidden layers L.\n...\n...\n...\nx1\nt\nx2\nt\nx3\nt\nxn\nt\nf (1)\nw(1)\n1,·\nf (1)\nw(1)\n2,·\nf (1)\nw(1)\n3,·\nf (1)\nw(1)\nm−2,·\nf (1)\nw(1)\nm−1,·\nf (1)\nw(1)\nm,·\nf (L)\nw(L)\n1,·\nf (L)\nw(L)\n2,·\nf (L)\nw(L)\nk,·\nrt+1\n. . .\nInput\nlayer\nxt\nW (1), b(1)\nHidden\nlayer\nf (1)\nW (1),b(1)\n. . .\nW (L), b(L)\nHidden\nlayer\nf (L)\nW (L),b(L)\nOutput\nlayer\nrt+1\net al., 2020; Gu et al., 2020; Tobek and Hronec, 2020; Zhang et al., 2020). Here we describe\nthe core ideas we use for building deep learning models to predict the returns.\n2.2.1\n(Deep) Feedforward Networks. Deep feedforward networks, also often called\nfeedforward neural networks, or multilayer perceptrons lie at heart of deep learning models\nand are universal approximators that can learn any functional relationship between input\nand output variables with suﬃcient data.\nA feedforward network is a form of supervised machine learning that uses hierarchical\nlayers to represent high-dimensional non-linear predictors in order to predict an output\nvariable. Figure 1 illustrates how ℓ∈{1, . . . , L} hidden layers transform input data xt =\n(x1\nt, ..., xn\nt ) in a chain using a collection of non-linear activation functions f (1), . . . , f (L). More\n8\nformally, we can deﬁne our prediction problem by characterizing excess equity returns as:\nrt+1 = fW,b(xt) + εr\nt+1,\n(2)\nwhere xt = (x1\nt, ..., xn\nt ) is a set of predictor variables that enter an input layer, and εr\nt+1 is\ni.i.d. error term, fW,b is a neural network with L hidden layers such as\nbrt+1 := fW,b(xt) = f (L)\nW (L),b(L) ◦. . . ◦f (1)\nW (1),b(1) (xt) ,\n(3)\nand W =\n\u0000W (1), . . . , W (L)\u0001\nand b =\n\u0000b(1), . . . , b(L)\u0001\nare weight matrices and bias vector. Any\nweight matrix W (ℓ) ∈Rm×n contains m neurons as n column vectors W (ℓ) = [w(ℓ)\n·,1 , . . . , w(ℓ)\n·,n],\nand b(ℓ) are a threshold or activation level that contribute to the output of a hidden layer,\nallowing the function to be shifted. Commonly used activation function f (ℓ)\nW (ℓ),b(ℓ)\nf (ℓ)\nW (ℓ),b(ℓ) := fℓ\n\u0000W (ℓ)xt + b(ℓ)\u0001\n= fℓ\n m\nX\ni=1\nW (ℓ)\ni xt + b(ℓ)\ni\n!\n(4)\nare sigmoidal (e.g. fℓ(z) = 1/(1 + exp(−z))) or fℓ(z) = tanh(z), or rectiﬁed linear units\n(ReLU) (fℓ(z) = max{z, 0}). Note that in case functions f are linear, fW,b(xt) is a simple\nlinear regression, regardless of the number of layers L, and hidden layers are redundant.\nFor example with L = 2, the model becomes a reparametrized simple linear regression:\nbrt+1 = W (2)(W (1)xt + b(1)) + b(2) = βxt + α. In case fW,b(xt) is non-linear, neural network\ncomplexity grows with increasing m, and with increasing the number of hidden layers L, or\ngrowing deepness of the network, we have a deep neural network.\n2.2.2\n(Deep) Recurrent Networks. Many predictors used in ﬁnance are non-i.i.d., and\ndynamically evolve in time, and hence traditional neural networks assuming independence\nof data may not approximate relationships suﬃciently well. Instead, a Recurrent Neural\nNetwork (RNN) that takes into account time series behavior may help in the prediction task.\n9\nIn addition, Long-Short-Term-Memory (LSTM) is designed to ﬁnd hidden state processes\nallowing for lags of unknown and potentially long time dynamics in the time series. Figure\n2 illustrates how the network structure additionally uses lagged information.\nMore formally, RNNs are a family of neural networks used for processing sequences of\ndata. They transform a sequence of input predictors to another output sequence introducing\nlagged hidden states as\nht = f(Whht−1 + Wxxt + b0).\n(5)\nIntuitively, RNN is a non-linear generalization of an autoregressive process where lagged\nvariables are transformations of the lagged observed variables. Figure 2 depicts Wh using\ndashed lines and Wx using solid lines. Nevertheless, this structure is only useful when the\nimmediate past is relevant. In case the time series dynamics are driven by events that are\nfurther back in the past, the addition of complex LSTMs is required.\n2.2.3\nLong-Short-Term-Memory (LSTM). An LSTM is a particular form of recur-\nrent networks, which provides a solution to the short memory problem by incorporating\nmemory units (Hochreiter and Schmidhuber, 1997). Memory units allow the network to\nlearn when to forget previous hidden states and when to update hidden states given new\ninformation. Speciﬁcally, in addition to a hidden state, LSTM includes an input gate, a\nforget gate, an input modulation gate, and a memory cell. The memory cell unit combines\nthe previous memory cell unit, which is modulated by the forget and input modulation gates\ntogether with the previous hidden state, modulated by the input gate. These additional cells\nenable an LSTM to learn extremely complex long-term temporal dynamics that a vanilla\nRNN is not capable of. Such structures can be viewed as a ﬂexible hidden state space model\nfor a large dimensional system. Additional depth can be added to an LSTM by stacking\nthem on top of each other, using the hidden state of the LSTM as the input to the next\nlayer.\nMore formally, at each step a new memory cell ct is created with current input xt and\n10\nFigure 2. (Deep) Recurrent Network\nThis ﬁgure illustrates a deep recurrent neural network model.\n...\n...\n...\nx1\nt\nx2\nt\nx3\nt\nxn\nt\nf (1)\nw(1)\n1,·\nf (1)\nw(1)\n2,·\nf (1)\nw(1)\n3,·\nf (1)\nw(1)\nm−2,·\nf (1)\nw(1)\nm−1,·\nf (1)\nw(1)\nm,·\nf (L)\nw(L)\n1,·\nf (L)\nw(L)\n2,·\nf (L)\nw(L)\nk,·\nrt+1\n. . .\nInput\nlayer\nxt\nW (1), b(1)\nHidden\nlayer\nf (1)\nW (1),b(1)\n. . .\nW (L), b(L)\nHidden\nlayer\nf (L)\nW (L),b(L)\nOutput\nlayer\nrt+1\nprevious hidden state ht−1 and it is then combined with a forget gate controlling the amount\nof information stored in the hidden state as\nht\n=\nσ\n\nW (o)\nh ht−1 + W (o)\nx xt + b(o)\n0\n|\n{z\n}\noutput gate\n\n◦tanh(ct)\n(6)\nct\n=\nσ\n\n\nW (g)\nh ht−1 + W (g)\nx xt + b(g)\n0\n|\n{z\n}\nforget gate\n\n\n◦ct−1 + σ\n\nW (i)\nh ht−1 + W (i)\nx + b(i)\n0\n|\n{z\n}\ninput gate\n\n◦tanh(kt).(7)\nThe term σ(·) ◦ct−1 introduces the long-range dependence, and kt is new information ﬂow\nto the current cell. The states of forget and input gates control weights of past memory and\nnew information. In Figure 2, ct is the memory pass through multiple hidden states in the\nrecurrent network.\n11\n2.2.4\nEstimation, Hyperparameters, Details. Due to the high dimensionality and\nnon-linearity of the problem, estimation of a deep neural network is a complex task. Here,\nwe provide a detailed summary of the model architectures and their estimations. We work\nwith a variety of deep learning structures and compare them with a recurrent LSTM network\nand regularized OLS. We consider NN1, NN2 and NN3 models that contain 16, 32–16 and\n32–16–8 neurons in the one, two, and three hidden layer structures, respectively, and an\nLSTM model which is a NN with 3 recurrent layers with 32-16-8 neurons in each and LSTM\ncells introduced into the last layer.\nTo prevent the model from over-ﬁtting and to the reduce large number of parameters, we\nuse dropout, which is a common form of regularization that has generally better performance\nin comparison to traditional l1 or l2 regularization. The term dropout refers to dropping out\nunits in neural networks and can be shown to be a form of ridge regularization. To ﬁt the\nnetworks, we adopt a popular and robust adaptive moment estimation algorithm (Adam)\nwith weight decay regularization introduced by Kingma and Ba (2014) and we use the Huber\nloss function in the estimation.\nFurther, we follow the most common approach in the literature and select tuning pa-\nrameters adaptively from the data in a validation sample. We split the data into training\nand validation samples that maintain temporal ordering of the data and tune hyperparam-\neters with respect to the statistical and economic criteria. We search the optimal models in\nthe following grid of 100 randomly chosen combinations of the following hyperparameters:\nlearning rate ∈[0.001, 0.02], decay regularization ∈[0, 0.001], dropout ∈[0%, 60%] of weights\nand activation function ∈{sigmoid, ReLU} with 1000 epochs with early stopping. Since the\nsample at each window is rather small, and ﬁnal models can depend on initial values in the\noptimization, we use ensemble averaging of ﬁve models with randomly chosen initial values.9\n9We have estimated our models on two servers with 48 core Intel® Xeon® Gold 6126 CPU@ 2.60GHz\nand 24 core Intel® Xeon® CPU E5-2643 v4 @ 3.40GHz, 768GB memory and two NVIDIA GeForce RTX\n2080 Ti GPUs. We have used Flux.jl with JULIA 1.4.0. for the model ﬁtting. A complete rolling window\nestimation with hyperparameter tuning takes around two days. We have conﬁrmed that our estimation\nresults are robust to using a larger hyperparameter space. As a full hyperparameter search on a larger\n12\n2.3\nOptimal Portfolios\nWe consider a portfolio choice problem of an agent with the investment horizon of T periods\nin the future who maximizes her expected utility over the cumulative portfolio return. There\nare two assets: a one-period Treasury bill and a stock index.10 If ωt+τ is the allocation to\nthe stock index at time t + τ, the investor solves the following optimization problem at time\nt\nmax\nω\nEt [U(rp,t+T)]\n(8)\nin which the end-of-horizon portfolio return rp,t+T is deﬁned as\nrp,t+T =\nTY\nτ=1\nh\n(1 −ωt+τ−1) exp(rf\nt+τ) + ωt+τ−1 exp(rf\nt+τ + rt+τ)\ni\n,\n(9)\nand rf\nt+τ denotes a zero-coupon default-free log bond yield between t + τ −1 and t + τ.\nFollowing Johannes et al. (2014), we consider various choices of horizons T to assess the\nimpact of the length of the investment period. Speciﬁcally, we report the results for the two\ncases of six months (T = 6) and two years (T = 24). Furthermore, we allow the investor to\nrebalance portfolio weights with diﬀerent frequencies. The allocations between a Treasury bill\nand a stock index are updated every three months, or once per year for the shorter or longer\ninvestment horizons, respectively. These choices of horizons and rebalancing periods allow us\nto compare two investment strategies. The former reﬂects a more actively managed portfolio\nwith frequent changes in the allocations, whereas the latter corresponds to a relatively passive\ninvestment portfolio with less frequent rebalancing. We further winsorize the weights for the\nstock index to −1 ≤ωt+τ ≤2 to prevent extreme investments. In the sensitivity analysis, we\ncheck the robustness of our results to alternative assumptions about the portfolio weights,\nhyperparameter space can easily take weeks or months even on our fast GPU cluster, we have selectively\ntested further hyperparameters.\n10Extending our analysis to multiple assets is straightforward; however, we consider a portfolio choice\nproblem with two assets as in Barberis (2000) and more recently Johannes et al. (2014) and Rossi (2018) to\nmake our results directly comparable to other studies.\n13\nparticularly incorporating the borrowing and short-selling constraints.\nWe also assume a power utility investor\nU(rp,t+τ) = r1−γ\np,t+τ\n1 −γ ,\nwhere γ is the coeﬃcient of risk aversion. The expected utility is deﬁned by the predictive\ndistribution of cumulative portfolio returns rp,t+τ given by Eq.(9), which in turn depends on\nthe corresponding model used to predict future excess returns rt+τ and the law of motion\nof predictor variables xt. For xt, we adopt a parsimonious AR(1) framework, that is, each\nvariable xi\nt satisﬁes\nxi\nt = αxi + βxixi\nt−1 + εxi\nt .\nwhere αxi and βxi are coeﬃcients, and εxi\nt\nare normal error terms. To proxy for the joint\nvariance-covariance matrix of the error terms εt = (εr\nt, εx\nt ), we employ a sample variance\nestimator ˆΣt = ˆεtˆε\n′\nt, where εt are forecast errors. Finally, we set the risk aversion parameter\nγ = 4 to compare our results to the existing literature (Johannes et al., 2014; Rossi, 2018).\nIn sum, the investor maximizes her expected utility and optimally rebalances her portfolio\nweights quarterly or annually for investment horizons of six months and two years, respec-\ntively. To compute her expected utility, she uses the distribution of returns predicted by the\nlinear regressions or the neural networks. To evaluate the impact of the investor’s condition-\ning information, we consider diﬀerent assumptions about the set of predictors and sample\nperiods used to estimate the models. In particular, we consider the following speciﬁcations:\n1. The no-predictability expectations hypothesis (EH) framework assumes a constant\nmean and constant variance framework with no predictors in Eq.(1), that is, β = 0.\n2. A simple linear regression of excess log returns with the dividend yield as a single\npredictor and a “kitchen sink” linear regression with all available variables. For each of\nthe two cases, we further implement OLS regressions using all data up to time t or over\n14\na 10-year rolling window, as in Johannes et al. (2014). The univariate models with\nthe expanding and rolling windows are denoted OLS1 and OLS2, and the multivariate\nversions are OLS3 and OLS4.\n3. A set of machine learning architectures including neural networks with 1 layer of 16\nneurons (NN1), 2 layers of 32-16 neurons (NN2), 3 layers of 32-16-8 neurons (NN3)\nand an LSTM model with 3 recurrent layers and 32-16-8 neurons and LSTM cells\nintroduced in the last layer. All NNs use a “kitchen sink” approach by utilizing all\navailable data to predict log excess returns and are trained on a 10-year rolling window\nto account for a time-varying relationship between the predictors and returns.\nThere are many dimensions that can be used to generalize our modelling approach. More\ngeneral speciﬁcations could add additional predictor variables (McCracken and Ng, 2016),\nparameter uncertainty (Wachter and Warusawitharana, 2009; Johannes et al., 2014; Bianchi\nand Tamoni, 2020), economic restrictions (Van Binsbergen and Koijen, 2010), or consider a\nlarger set of investable assests and alternative preferences (Dangl and Weissensteiner, 2020)\namong other extensions. Most notably, modelling stochastic volatility via a parsimonious\nmean-reverting process (Johannes et al., 2014) or more complex GARCH- and MIDAS-type\nvolatility estimators (Rossi, 2018) would certainly improve the performance of our strategies.\nInstead, we consider all speciﬁcations with a constant volatility setting to solely evaluate the\nimpact of neural networks on the performance of dynamic allocation strategies. Our aim is\nto demonstrate out-of-sample portfolio gains from using deep learning in the most restrictive\nsetting.\n2.4\nPerformance Evaluation\nIn our analysis, we employ a number of metrics measuring the statistical accuracy of the\nmethods considered and their economic gains for the investor. With respect to the statistical\nperformance, we ﬁrst consider a common measure of mean squared prediction error (MSPE)\n15\ndeﬁned as\nMSPE =\n1\nT0 −t0 + 1\nT0\nX\nt=t0\n\u0010\nrt −ˆrMs\nt\n\u00112\n,\n(10)\nwhere rt denotes the observed excess log return, ˆrMs\nt\nis the return predicted by a particular\nframework Ms, and t0 and T0 are the months of the ﬁrst and last predictions. Notice that the\ninvestor rebalances her allocations at varying frequency. Thus, we compute the prediction\nerrors only in those periods when she reoptimizes her portfolio.\nAs in Campbell and Thompson (2008), we compute the out-of-sample predictive R2\noos\nR2\noos = 1 −\nPT0\nt=t0\n\u0000rt −ˆrMs\nt\n\u00012\nPT0\nt=t0\n\u0000rt −¯rt\n\u00012 ,\nwhere ¯rt is the historical mean of returns.\nBy construction, the R2\noos statistic compares\nthe out-of-sample performance of the chosen model Ms relative to the historical average\nforecast. Notice that we compute the historical mean over the same sample used to estimate\nMs, which corresponds to either an expanding sample or a 10-year rolling window. The\npositive value of R2\noos indicates that the model-implied forecast has smaller mean squared\npredictive error compared to the error implied by the historical average forecast. Thus, we\nperform a formal test of the null hypothesis R2\noos ≤0 against the alternative hypothesis\nR2\noos > 0 by implementing the MSPE-adjusted Clark and West (2007) test. Note that we\ncalculate the Clark and West (2007) test only if R2\noos is positive.\nAfter we compare diﬀerent models in terms of the statistical accuracy of their predictions,\nwe assess whether superior statistical ﬁt translates into economic gains. It is worth noting\nthat this relationship is non-trivial. Indeed, Campbell and Thompson (2008) and Rapach\net al. (2010) note that seemingly small improvements in R2\noos could generate large beneﬁts\nin practice. We start our investigation of the size of the improvements by calculating the\naverage Sharpe ratio of portfolio returns as a common measure of portfolio performance used\nin ﬁnance. The drawback of this metric is that it does not take tail behaviour into account.\n16\nConsequently, we follow Fleming et al. (2001) and compute the certainty equivalent return\n(CER) by equating the utility from CER to the average utility implied by an alternative\nmodel. Finally, we visualize the performance of all speciﬁcations by plotting the cumulative\nlog portfolio returns over the sample period considered. This allows us to clearly see the\ntime intervals in which the investor beneﬁts the most from using diﬀerent frameworks.\nTo evaluate the statistical signiﬁcance of portfolio gains, we follow Bianchi et al. (2020)\nand implement the test á la Diebold and Mariano (2002) . Speciﬁcally, we perform a pairwise\ncomparison between the CERs generated by each framework under consideration and those\nyielded by the EH speciﬁcation.11 For each model Ms, we estimate the regression\nUMs\nt+T −UEH\nt+T = αMs + εt+T,\nwhere UX\nt+T = (rX\np,t+T)\n1−γ\n1−γ\nand rX\np,t+T is the cumulative portfolio return with the horizon T.\nTesting for the diﬀerence in the CERs boils down to a test for the signiﬁcance in αMs.\n3\nEmpirical Results\n3.1\nData and preliminary results\nOur empirical analysis of the S&P 500 excess return predictability is based on the applications\nof a variety of linear models and non-linear machine learning methods as discussed in Section\n2.3. We use a set of economic predictor variables considered by Goyal and Welch (2008) to\nmake our results directly comparable to the literature. Speciﬁcally, we focus on the monthly\nhistorical data of twelve predictors including dividend yield, log earning price ratio, dividend\n11For the signiﬁcance of SRs, we ﬁrst need to simulate artiﬁcial returns under a null model of no pre-\ndictability, that is, a model with constant mean and constant volatility. For each simulation, we need to\nobtain the forecasts for all models considered and construct optimal portfolios. Since a complete exercise of\nhyperparameter tuning takes around 2 days on the supercomputer cluster, repeating it, say, 500 times will\nincrease cluster computing time proportionally. This makes the task computationally infeasible given the\ncurrent computing capacity, unless more resources for parallel computing become available.\n17\nTable 1. Statistical Accuracy of Excess Return Forecasts\nThis table reports the mean squared prediction error and out-of-sample R2\noos obtained from using diﬀerent\nmethodologies to predict future S&P 500 excess returns as outlined in Section 2.3. We compute the out-of-\nsample R2\noos in comparison to the expectations hypothesis using the historical mean to predict returns. Panel\nA shows the results when the investor maximizes a 6-month portfolio return and changes the allocations\nquarterly.\nPanel B demonstrates the results for a 2-year horizon and annual rebalancing.\nWe compute\nstatistical accuracy measures in those periods when the investor reevaluates her allocations with quarterly or\nannual frequency. We also report a p-value (in parentheses) of the null hypothesis R2\noos ≤0 following Clark\nand West (2007). We report statistical signiﬁcance only if R2\noos is positive. The forecast starts in February\n1955. The sample period spans from January 1945 to December 2018.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\nPanel A: 6-month horizon and quarterly rebalancing\nMSPE×104\n17.4\n18.0\n18.2\n18.9\n18.0\n16.3\n16.6\n16.6\n17.3\nR2\noos\n0.5%\n-2.5%\n-3.6%\n-8.0%\n-2.5%\n7.1%\n5.1%\n5.6%\n1.6%\np-value\n(0.152)\n(0.006)\n(0.007)\n(0.002)\n(0.002)\nPanel B: 2-year horizon and annual rebalancing\nMSPE×104\n14.2\n15.0\n14.7\n16.7\n19.9\n12.2\n11.1\n11.9\n12.1\nR2\noos\n2.2%\n-2.8%\n-0.8%\n-15.0%\n-36.9%\n16.0%\n23.8%\n17.6%\n17.2%\np-value\n(0.171)\n(0.001)\n(0.014)\n(0.007)\n(0.008)\npayout ratio, book to market ratio, net equity expansion, treasury bill rates, term spread,\ndefault yield spread, default return spread, cross-sectional premium, inﬂation growth, and\nmonthly stock variance.12\nTable 1 reports the statistical accuracy of the models considered. Panels A and B show the\nMSPEs and R2\noos based on those periods when quarterly and annual rebalancing is occurring.\nAs shown in Panel A, all linear regressions generate larger MSPEs compared to the constant\nmean and constant volatility model, while neural networks provide the best ﬁt with the data.\nA multivariate linear regression does not necessarily outperform a univariate model. In-\ndeed, a linear regression estimated on the rolling window (OLS3) is noisier and generates a\nlarger MSPE than regressions using only dividend yield (OLS1), whereas the “kitchen sink”\nlinear regression with an expanding window estimation (OLS4) slightly outperforms a single\npredictor model (OLS2). Furthermore, consistent with Goyal and Welch (2008), none of the\nlinear regressions can beat the simple historical mean, as indicated by the negative R2\noos.\n12The data are retrieved from Amit Goyal’s website and are available via the following link\nhttp://www.hec.unil.ch/agoyal/docs/PredictorData2019.xlsx as of 26th August 2020.\n18\nIn contrast, we ﬁnd that deep learning methods achieve the positive R2\noos, indicating the\nstatistical beneﬁts of accounting for the nonlinear relationship between stock market returns\nand predictors, similarly to Feng et al. (2018) and Rossi (2018). A formal test conﬁrms that\nexpected return predictability generated by NNs is statistically diﬀerent from a naive his-\ntorical mean forecast. In unreported results, we verify that the performance of all machine\nlearning methods is statistically the same. Panel B also shows the results in favor of NNs in\na setting with less frequent rebalancing.\n3.2\nPortfolio Results\nTable 2 provides a summary of annualized CERs and monthly SRs of portfolio returns for\neach model assuming a 6-month (Panel A) and 2-year (Panel B) investment horizon. The\nsummary statistics in each panel are computed for the whole sample and for recession and\nexpansion periods as deﬁned by the NBER recession indicator. The risk aversion parameter\nis γ = 4.\nFor traditional methods, we recover a standard result: linear regressions do not generate\nout-of-sample improvements as measured by the CERs compared to the constant mean\nand constant volatility model.\nIn terms of model-generated SRs, linear models perform\nslightly better than the expectations hypothesis model, with higher Sharpe ratios in case\nof more predictor variables. The rolling-window estimation introduces time-varying slope\ncoeﬃcients and leads to modest improvements. However, ignoring the estimation risk and\nstochastic volatility of returns results in lower CERs relative to a constant mean and volatility\nspeciﬁcation, which is consistent with Johannes et al. (2014).\nTurning to NNs, we observe that the improved R2\noos obtained using machine learn-\ning methods directly translate into economic gains for an investor. Speciﬁcally, the best-\nperforming NN – the LSTM model – generates more than two- and three-fold increases in\nthe annual CER (around 10% vs 4.7%) and monthly SR (0.175 vs 0.049) relative to the model\n19\nTable 2. Certainty Equivalent Returns and Sharpe Ratios\nThis table reports the annualized certainty equivalent returns and monthly Sharpe ratios for diﬀerent models\noutlined in Section 2.3. Panel A shows the results when the investor maximizes a 6-month portfolio return\nand changes the allocations quarterly. Panel B shows the results for a 2-year horizon and annual rebalancing.\nEach panel computes the statistics for the whole sample, with expansion and recession periods as deﬁned by\nNBER. For the statistical signiﬁcance of CERs, we report a one-sided p-value (in parentheses) of the test á\nla Diebold and Mariano (2002). In particular, we regress the diﬀerence in utilities for each model Ms and\nEH: UMs\nt+T −UEH\nt+T = αMs +εt+T , where UX\nt+T = (rX\np,t+T)\n1−γ\n1−γ\nand rX\np,t+T is the cumulative portfolio return with\nthe horizon T. Testing for the diﬀerence in the CERs boils down to a test for the signiﬁcance in αMs. We\nﬂag in bold font CER values that are signiﬁcant at the 10% conﬁdence level. The portfolio construction\nstarts in February 1955. The sample period spans from January 1945 to December 2018.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\nPanel A: 6-month horizon and quarterly rebalancing\n1955-2018\nCER\n4.737\n2.643\n-0.030\n2.781\n2.491\n7.295\n6.984\n5.491\n10.007\np-value\n(1.000)\n(1.000)\n(0.935)\n(0.954)\n(0.027)\n(0.032)\n(0.292)\n(0.000)\nSR\n0.049\n0.046\n0.062\n0.088\n0.095\n0.166\n0.157\n0.144\n0.175\nExpansions\nCER\n4.948\n3.073\n-0.173\n4.598\n2.045\n5.873\n5.280\n5.304\n7.998\np-value\n(0.998)\n(1.000)\n(0.654)\n(0.982)\n(0.258)\n(0.398)\n(0.403)\n(0.000)\nSR\n0.100\n0.077\n0.048\n0.092\n0.108\n0.149\n0.143\n0.135\n0.149\nRecessions\nCER\n3.311\n-0.274\n1.401\n-9.079\n6.752\n19.024\n20.806\n6.936\n26.770\np-value\n(0.995)\n(0.648)\n(0.944)\n(0.221)\n(0.000)\n(0.000)\n(0.200)\n(0.000)\nSR\n-0.193\n-0.182\n0.154\n0.091\n0.036\n0.284\n0.255\n0.204\n0.358\nPanel B: 2-year horizon and annual rebalancing\n1955-2018\nCER\n4.542\n1.068\n0.040\n0.923\n-0.067\n6.342\n6.879\n6.437\n5.622\np-value\n(1.000)\n(1.000)\n(0.999)\n(0.997)\n(0.000)\n(0.000)\n(0.000)\n(0.012)\nSR\n0.048\n0.044\n0.046\n0.083\n0.081\n0.138\n0.136\n0.129\n0.118\nExpansions\nCER\n4.448\n0.826\n0.514\n0.321\n0.231\n6.051\n6.390\n5.913\n5.537\np-value\n(1.000)\n(1.000)\n(0.999)\n(0.987)\n(0.002)\n(0.000)\n(0.000)\n(0.011)\nSR\n0.100\n0.076\n0.037\n0.097\n0.137\n0.136\n0.149\n0.132\n0.112\nRecessions\nCER\n5.235\n2.866\n-2.924\n5.930\n-2.138\n8.611\n10.975\n10.836\n6.353\np-value\n(0.997)\n(1.000)\n(0.262)\n(1.000)\n(0.006)\n(0.000)\n(0.000)\n(0.284)\nSR\n-0.190\n-0.170\n0.102\n0.017\n-0.104\n0.160\n0.111\n0.149\n0.154\nignoring expected return predictability. The LSTM model, which is a three-layer network,\nis directly comparable to NN3 in terms of its structure complexity. Nevertheless, LSTM\ndominates a standard network, emphasizing the importance of learning complex long-term\n20\ntemporal dynamics in addition to non-linear predictive relationships. In general, comparing\nNN1 through NN3, we observe that increasing the complexity of NNs does not necessarily\nimprove portfolio performance, although all machine learning structures remain statistically\nequivalent to each other. A formal one-sided test conﬁrms that, except for NN3, the port-\nfolio performance of NNs is signiﬁcantly better than the performance generated by the EH\nmodel. Further, a comparison of the results in Panels A and B demonstrates that the in-\nvestor beneﬁts more from using NNs when she manages her portfolio more actively. Overall,\nthese results indicate that expected return predictability generated by applying nonlinear\nmethods provides valuable information for portfolio construction.\nWe dissect this superior performance by looking at portfolio return statistics in periods\nof expansion and recession. Table 2 shows that economic gains generated by NNs are large\nduring both regimes and are especially pronounced in recessions. For instance, the annualized\nCER generated by the LSTM is, on average, around 8% in good times, which is more than\nthe 5% predicted by the EH model. In bad times, the diﬀerence in performance is extremely\nlarge, with around 26% and 3% CERs in the LSTM and EH models, respectively. A pairwise\ntest conﬁrms that the improvement of LSTM over EH is statistically signiﬁcant during\nboth expansions and recessions.\nIn contrast, the portfolio returns of NN1 through NN3\nare indistinguishable from EH in expansions, while shallower networks exhibit signiﬁcantly\nbetter performance in recessions.\nThe investor who ignores expected return predictability experiences, on average, around\n-19% Sharpe ratios in recessions. In contrast, the LSTM model helps generate signiﬁcant\nportfolio gains around 36% SRs, with other NNs generating at least 20% SRs on a monthly\nbasis. Further, all NNs outperform linear regressions across good and bad times. The existing\nevidence for equities (Rapach et al., 2010; Dangl and Halling, 2012) indicates that return\npredictability is concentrated in bad times.13 Our ﬁndings extend the existing literature by\n13Gargano et al. (2019) report a similar result for bond returns. Recently, Bianchi et al. (2020) show that\nbond return predictability is also present in expansions when machine learning methods are employed.\n21\nTable 3. Portfolio Return Statistics\nThis table reports mean, standard deviation, skewness, and kurtosis of optimal portfolio returns for diﬀerent\nmodels as outlined in Section 2.3. All statistics are expressed in monthly terms. Panel A shows the results\nfor the case when the investor maximizes a 6-month portfolio return and changes the allocations quarterly.\nPanel B shows the results for a 2-year horizon and annual rebalancing. The portfolio construction starts in\nFebruary 1955. The sample period spans from January 1945 to December 2018.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\nPanel A: 6-month horizon and quarterly rebalancing\nMean\n0.937\n2.213\n4.138\n4.676\n6.762\n10.728\n9.605\n9.533\n11.715\nSt.dev.\n5.504\n13.871\n19.122\n15.353\n20.502\n18.601\n17.641\n19.121\n19.343\nSkew\n-0.472\n-0.615\n-0.893\n-0.332\n-0.881\n-0.844\n-0.816\n-0.786\n-0.046\nKurt\n4.353\n8.609\n10.400\n7.631\n9.182\n11.707\n12.237\n11.172\n4.860\nPanel B: 2-year horizon and annual rebalancing\nMean\n0.978\n2.184\n3.058\n5.093\n4.908\n7.333\n5.634\n4.445\n7.722\nSt.dev.\n5.849\n14.443\n19.189\n17.655\n17.512\n15.331\n11.937\n9.916\n18.87\nSkew\n-0.452\n-0.492\n-1.058\n-0.989\n-0.787\n-0.275\n0.469\n0.799\n-0.013\nKurt\n4.386\n7.104\n10.566\n13.550\n10.737\n9.113\n10.416\n14.775\n6.433\nshowing that, unlike linear models, NNs help the investor to eﬀectively convert predictive\nvariation in stock market returns into substantial economic gains across diﬀerent business\ncycle conditions.\nTable 3 presents additional statistics of portfolio returns for diﬀerent methodologies. The\nmodels using NNs generate out-of-sample returns with signiﬁcantly larger means. Intuitively,\nthis occurs because machine learning methods speciﬁcally excel in risk premium prediction,\nthat is, the conditional expectation of returns. The linear regressions and vanilla NNs do\nnot take the time-varying volatility of returns into account and hence these models predict\nnegative skewness and excess kurtosis (since they ignore a fat-tailed return distribution).\nInterestingly, although an LSTM network does not consider time variation in return volatility,\nit is able to identify the periods of high return variance using the long-term memory of its\ncells (including realized return variance as one of the predictors also helps). This results\nin better skewness and lower excess kurtosis. The statistics for the longer horizon portfolio\nare improved for the standard neural networks, where properties remain largely the same or\nslightly deteriorate for other models.\n22\nFigure 3. Cumulative Returns\nThis ﬁgure illustrates the cumulative log returns of optimal portfolio strategies from diﬀerent models outlined\nin Section 2.3. The left panel shows the results when the investor maximizes a 6-month portfolio return\nand changes the allocations quarterly. The right panel shows the results for a 2-year horizon and annual\nrebalancing. The shaded areas denote recession periods as deﬁned by NBER. The portfolio construction\nstarts in February 1955. The sample period spans from January 1945 to December 2018.\n(a) 6-month horizon and quarterly rebalancing\n(b) 2-year horizon and annual rebalancing\nWe visually summarize the previous results in Figure 3, which shows the cumulative sum\nof log portfolio returns. The left panel shows that NNs outperform other models by a large\nmargin. The LSTM dominates remaining networks by the end of the period considered,\nwith a particularly pronounced diﬀerence in the second half of the sample. In relation to\nspeciﬁc historical events, all NNs produce steady positive portfolio performance during the\n2007-2008 Financial Crisis. Interestingly, the LSTM network additionally avoids a largely\nunexpected stock market crash, Black Monday, on October 19, 1987. Figure 3 also shows\nthat weaker statistical performances for the passive strategy with annual rebalancing leads\nto lower cumulative returns across all models.\n4\nFurther Analysis\nThis section dissects the performance of portfolio returns constructed in the previous section\nacross seven decades in the post-WWII period considered. Further, this section connects\neconomic gains of the best-performing model to common drivers of asset prices. Finally,\n23\nit also provides the robustness of our conclusions to alternative measures of portfolio per-\nformance, transaction costs, borrowing and short-selling constraints, and a larger size of a\nrolliing window used to train NNs.\n4.1\nSubsample Analysis\nWe start by examining whether superior portfolio performance implied by NNs varies over\nsubsamples other than expansions and recessions. Table 4 shows the certainty equivalent\nyields and Sharpe ratios computed separately for each decade in our sample. For the CERs,\nwe extend the main ﬁnding of the paper: NNs, particularly LSTM, outperform the expec-\ntations hypothesis model in most cases. Speciﬁcally, the table shows that, except for the\nlast decade, the LSTM network generates certainty equivalent values above those implied by\nno predictability framework. Interestingly, the formal test indicates that the improvement\nof LSTM over EH is signiﬁcant during the ﬁrst three decades, while higher CERs in later\nperiods are statistically equivalent to those from the EH model.\nThe linear models perform well across the 1990s and 2010s during which the stock market\ngrew steadily. Also, the rolling-window linear regressions tend to perform better than those\nusing the expanding-window estimation, emphasizing the role of time-varying betas and\nchanging information sets. For instance, Goyal and Welch (2008) show that dividend-yield\nexhibited a strong predictive power for stock market returns from 1970 to mid-1990, with\na weaker but mostly positive out-of-sample performance during the ﬁrst two decades after\nWorld War II. In contrast, it produced large prediction errors during the 1995-2000 and\n2000s. As a result, Table 4 shows that the OLS3 model generates high CERs from 1955\nto 1989, exhibiting statistically better performance than EH in some case, but the model is\nweaker in later years when the forecast based on dividend yield had strong underperformance.\nTurning to the SRs, NNs provide the investor with substantially higher Sharpe ratios\nwith the exception of the 1990s and 2010s when they perform slightly worse. These results\n24\nTable 4. Portfolio Performance across Subsamples\nThis table reports the annualized certainty equivalent returns and monthly Sharpe ratios for diﬀerent models\noutlined in Section 2.3. The table shows the results when the investor maximizes a 6-month portfolio return\nand changes the allocations quarterly. The table computes the statistics for each of the seven decades since\nWWII. For the statistical signiﬁcance of CERs, we report a one-sided p-value (in parentheses) of the test á\nla Diebold and Mariano (2002). In particular, we regress the diﬀerence in utilities for each model Ms and\nEH: UMs\nt+T −UEH\nt+T = αMs +εt+T , where UX\nt+T = (rX\np,t+T)\n1−γ\n1−γ\nand rX\np,t+T is the cumulative portfolio return with\nthe horizon T. Testing for the diﬀerence in the CERs boils down to a test for the signiﬁcance in αMs. We\nﬂag in bold font CER values that are signiﬁcant at the 10% conﬁdence level. The portfolio construction\nstarts in February 1955. The sample period spans from January 1945 to December 2018.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\n1955-1959\nCER\n5.467\n4.376\n3.219\n9.495\n5.545\n15.611\n12.220\n23.120\n15.455\np-value\n(0.631)\n(0.707)\n(0.149)\n(0.490)\n(0.000)\n(0.017)\n(0.000)\n(0.001)\nSR\n0.225\n0.188\n0.209\n0.258\n0.154\n0.319\n0.278\n0.431\n0.341\n1960-1969\nCER\n4.197\n0.580\n-4.193\n8.354\n0.619\n7.498\n7.608\n5.627\n14.015\np-value\n(0.959)\n(0.991)\n(0.024)\n(0.931)\n(0.094)\n(0.042)\n(0.360)\n(0.000)\nSR\n0.062\n0.064\n0.030\n0.157\n0.067\n0.164\n0.148\n0.181\n0.241\n1970-1979\nCER\n3.312\n0.599\n0.223\n9.275\n8.580\n17.750\n15.690\n13.618\n20.658\np-value\n(1.000)\n(0.847)\n(0.015)\n(0.026)\n(0.000)\n(0.000)\n(0.000)\n(0.000)\nSR\n-0.107\n-0.097\n0.005\n0.149\n0.180\n0.274\n0.248\n0.224\n0.309\n1980-1989\nCER\n9.215\n7.243\n-3.130\n11.276\n-1.450\n3.315\n1.216\n2.603\n10.241\np-value\n(0.992)\n(0.983)\n(0.148)\n(0.969)\n(0.820)\n(0.906)\n(0.864)\n(0.282)\nSR\n0.048\n-0.005\n0.072\n0.139\n0.055\n0.166\n0.123\n0.142\n0.112\n1990-1999\nCER\n8.101\n11.808\n13.704\n-4.393\n12.085\n10.817\n10.301\n6.429\n9.815\np-value\n(0.002)\n(0.002)\n(1.000)\n(0.039)\n(0.052)\n(0.099)\n(0.842)\n(0.202)\nSR\n0.222\n0.185\n0.219\n-0.168\n0.218\n0.168\n0.172\n0.100\n0.150\n2000-2009\nCER\n0.000\n-7.445\n-7.091\n-15.834\n-10.520\n-3.889\n-0.205\n-7.991\n1.726\np-value\n(1.000)\n(0.990)\n(0.998)\n(0.998)\n(0.869)\n(0.531)\n(0.995)\n(0.238)\nSR\n-0.091\n-0.125\n-0.055\n-0.039\n-0.040\n0.028\n0.060\n-0.062\n0.084\n2010-2018\nCER\n4.230\n6.268\n0.997\n9.757\n9.508\n6.642\n5.690\n7.241\n2.074\np-value\n(0.000)\n(0.999)\n(0.000)\n(0.000)\n(0.004)\n(0.049)\n(0.023)\n(0.842)\nSR\n0.237\n0.220\n-0.020\n0.255\n0.161\n0.150\n0.175\n0.213\n0.096\nare consistent with our previous ﬁndings. Indeed, the U.S. stock market was strongly bullish\nin these two decades, which are marked by prolonged stock market expansions. In contrast,\nthe Black Monday crash occurred in 1987 and the S&P 500 index recovered slowly, only by\n25\nthe end of the 1980s. Further, the beginning of the new millennium experienced two major\ncrashes driven by the burst of the dot-com bubble and the subprime mortgage crisis. Table\n4 shows that NNs perform signiﬁcantly better than other speciﬁcations during decades with\nmajor stock bear markets and provide statistically equal results during bull markets, which\nis consistent with our previous results across expansions and recessions.\n4.2\nDrivers of Portfolio Performance\nThis section explores the link between the economic gains implied by the best-performing\nmachine learning framework and prominent drivers of asset prices. In particular, we focus\non the portfolio choice problem of the investor with a 6-month investment horizon and\nquarterly rebalancing who uses the LSTM to forecast future stock market returns. Formally,\nwe establish this link by running a set of univariate regressions of the investor’s utility from\nfuture portfolio returns on the set of structural determinants of risk premia.\nOur choice of variables is motivated by existing studies. For instance, a large strand of the\nliterature (see Buraschi and Jiltsov (2007) and Dumas et al. (2009) among others) emphasizes\nthe importance of disagreement for asset prices. In our analysis, we employ the Survey of\nProfessional Forecasters to proxy for real disagreement (DiB(g)) and nominal disagreement\n(DiB(π)), which are constructed as the interquartile range of 6-month-ahead forecasts of\nGDP and CPI growth.\nMotivated by the well-established link between asset prices and\nuncertainty, we employ a novel measure of economic uncertainty (UNbex) constructed from\nﬁnancial variables at high frequencies (Bekaert et al., 2019).\nWe next examine the relationship between portfolio gains and time-varying risk aver-\nsion of investors. Following Wachter (2006), we approximate risk aversion via the negative\nweighted average of consumption growth rates over a moving window of 10 years (−Surplus).\nWe compare the results to an alternative measure of risk aversion extracted from ﬁnancial\nvariables (Bekaert et al., 2019). Finally, we relate portfolio utilities to stock market volatil-\n26\nTable 5. Drivers of Portfolio Performance\nThis table reports the regression estimates, Newey-West p-values (in parentheses) and R2 of economic gains\non a set of selected variables determining risk premia. Economic gains are computed for portfolio returns\nfor the best performing model employing the LSTM prediction of stock market returns. The independent\nvariables proxy for real disagreement DiB(g), nominal disagreement DiB(π), economic uncertainty UNbex,\nrisk aversion via consumption growth −Surplus or ﬁnancial variables RAbex, the VIX index V IX, and\nrealized stock market volatility σ. The variables on the left and right sides are standardized. We ﬂag in bold\nfont regression estimates that are signiﬁcant at the 10% conﬁdence level.\nDiB(g)\nDiB(π)\nUNbex\n−Surplus\nRAbex\nV IX\nσ\nR2(%)\n(i)\n0.198\n3.907\n(0.002)\n(ii)\n0.188\n3.523\n(0.019)\n(iii)\n0.115\n1.318\n(0.127)\n(iv)\n0.037\n0.141\n(0.561)\n(v)\n0.098\n0.962\n(0.144)\n(vi)\n0.104\n1.084\n(0.177)\n(vii)\n0.004\n0.002\n(0.908)\nity by using the risk-neutral volatility (V IX) as measured by the VIX index and by using\nthe realized volatility (σ) as measured by the root of the intra-month sum of squared daily\nS&P500 returns.\nTable 5 presents the regression results. Overall, the relationship between future realized\nportfolio gains and most structural risk factors is rather weak. Indeed, we document that\nonly dispersion in beliefs about a real or nominal growth is positively and statistically sig-\nniﬁcantly linked to the investor’s utilities. Intuitively, this result is expected since machine\nlearning methods signiﬁcantly outperform competing models during recessionary periods,\nwhen uncertainty and disagreement in forecasts are large. The third panel in Table 5 further\nconﬁrms this positive association between economic uncertainty and portfolio gains, how-\never, the link is statistically weaker compared to disagreement measures. Except for realized\nstock market volatility, we obtain positive coeﬃcients on the remaining risk factors.\n27\n4.3\nAlternative Measures of Performance\nAlthough certainty equivalent yields and Sharpe ratios are common measures of portfolio\nperformance considered in the literature, the investor may use alternative statistics to eval-\nuate their investment strategies, including maximum drawdown, maximum one-month loss,\nand average monthly turnover. For each model Ms, we deﬁne maximum drawdown\nMax DD =\nmax\nt0≤t1≤t2≤T0\nh\nˆrt1,Ms\nt0\n−ˆrt2,Ms\nt0\ni\n,\n(11)\nin which ˆrt,Ms\nt0\ndenotes the cumulative portfolio return from time t0 through t, while t0 and\nT0 are the months of the ﬁrst and last predictions. The maximum one-month loss measures\nthe largest portfolio decline during the period considered. The average monthly turnover is\ndeﬁned as\nTurnover =\n1\nT0 −t0\nT0\nX\nt=t0+1\n\f\f\fωt −ωt−1 · ˆrMs\nt−1\n\f\f\f,\n(12)\nwhere ωt−1 is the weight of the stock index.\nTable 6 shows the results for alternative performance statistics. We ﬁrst focus on actively\nmanaged portfolios with quarterly rebalancing and then move to more passive investment\nstrategies with annual rebalancing. The maximum drawdown experienced by NN1 through\nNN3 is between 68% and 83% on the monthly basis. The linear models predict comparable\nor even larger drawdowns, whereas the constant mean and constant volatility model delivers\na mild loss of around 23%. In contrast, the maximum drawdown for LSTM is around 46%,\nthe mildest decline among the predictive models. Panel A further shows a similar picture for\nthe maximum one-month loss of the portfolio: linear models and NNs tend to generate the\nworst one-period performance, while the LSTM strategy experiences a milder loss. Thus, the\nLSTM speciﬁcation is the most successful in avoiding large losses over short- and long-term\nperiods, even though it comes at the expense of the higher turnover.\nPanel B in Table 6 shows that the investor engaging in less frequent portfolio rebalancing\n28\nTable 6. Drawdowns, Maximum Loss, and Turnover\nThis table reports alternative out-of-sample performance measures — maximum drawdown, maximum 1-\nmonth loss, and turnover — of optimal portfolio returns for diﬀerent methodologies used to predict future\nS&P 500 excess returns as outlined in Section 2.3. All statistics are expressed in percentages. Panel A shows\nthe results when the investor maximizes a 6-month portfolio return and changes the allocations quarterly.\nPanel B demonstrates the results for a 2-year horizon and annual rebalancing. The portfolio construction\nstarts in February 1955. The sample period spans from January 1945 to December 2018.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\nPanel A: 6-month horizon and quarterly rebalancing\nMax DD\n22.795\n76.236\n74.251\n144.760\n100.956\n74.572\n68.248\n82.72\n45.995\nMax 1M Loss\n7.795\n33.325\n57.974\n31.756\n57.974\n57.974\n57.974\n57.974\n35.011\nTurnover\n0.506\n4.286\n10.968\n17.890\n34.531\n23.008\n23.407\n29.616\n32.814\nPanel B: 2-year horizon and annual rebalancing\nMax DD\n25.002\n90.896\n83.370\n123.279\n145.663\n74.972\n34.562\n25.136\n64.433\nMax 1M Loss\n8.036\n29.431\n57.974\n57.974\n38.862\n34.375\n24.419\n25.136\n35.011\nTurnover\n0.584\n4.289\n8.804\n10.773\n11.329\n11.352\n8.725\n6.771\n17.459\nis generally less eﬃcient in forming the optimal portfolio if he relies on the linear regressions.\nInterestingly, the beneﬁts of deep learning methods remain similar and even improve in\nsome cases. For instance, the maximum one-month and drawdown losses tend to increase\nfrom 83% to more than 140% for the linear models, while NNs produce the largest declines,\nfrom 25% to 35% per month. Furthermore, as the portfolio weights are kept unchanged for\nlonger investment periods, the turnover is reduced. Thus, the passive investor who is mainly\ninterested in reducing his short- and long-term tail risks would still ﬁnd NNs useful, while\nhe does not beneﬁt from linear predictive models.\nIn sum, exploiting expected return predictability via NNs for portfolio construction leads\nto riskier investments. It also generates increased turnover, especially for the best-performing\nmodel using the LSTM network. A natural question arises if these beneﬁts are oﬀset by the\nlarge transaction costs implied by more aggressive buying and selling stocks\n4.4\nPortfolio Performance with Transaction Costs\nThis subsection extends the main analysis by accounting for the eﬀect of transaction costs.\nSpeciﬁcally, we consider low and high transaction costs that are equal to the percentage paid\n29\nTable 7. Portfolio Performance with Transaction Costs\nThis table reports the annualized certainty equivalent returns and Sharpe ratios for diﬀerent models outlined\nin Section 2.3. The top and bottom sections of the table compute optimal returns with low (τ = 0.1%) and\nhigh (τ = 0.5%) transaction costs. Panels A and C show the results when the investor maximizes a 6-month\nportfolio return and changes the allocations quarterly. Panel B and D show the results for a 2-year horizon and\nannual rebalancing. Each panel computes the statistics for the whole sample. For the statistical signiﬁcance\nof CERs, we report a one-sided p-value (in parentheses) of the test á la Diebold and Mariano (2002). In\nparticular, we regress the diﬀerence in utilities for each model Ms and EH:UMs\nt+T −UEH\nt+T = αMs + εt+T ,\nwhere UX\nt+T = (rX\np,t+T)\n1−γ\n1−γ\nand rX\np,t+T is the cumulative portfolio return with the horizon T. Testing for the\ndiﬀerence in the CERs boils down to a test for the signiﬁcance in αMs. We ﬂag in bold font those CER\nvalues that are signiﬁcant at the 10% conﬁdence level. The portfolio construction starts in February 1955.\nThe sample period spans from January 1945 to December 2018.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\nLow Transaction Costs\nPanel A: 6-month horizon and quarterly rebalancing\nCER\n4.731\n2.589\n-0.171\n2.548\n2.036\n6.996\n6.689\n5.115\n9.592\np-value\n(1.000)\n(1.000)\n(0.953)\n(0.978)\n(0.045)\n(0.054)\n(0.391)\n(0.000)\nSR\n0.049\n0.045\n0.060\n0.084\n0.089\n0.162\n0.153\n0.139\n0.169\nPanel B: 2-year horizon and annual rebalancing\nCER\n4.535\n0.998\n-0.085\n0.765\n-0.241\n6.191\n6.783\n6.366\n5.413\np-value\n(1.000)\n(1.000)\n(0.999)\n(0.998)\n(0.001)\n(0.000)\n(0.000)\n(0.033)\nSR\n0.048\n0.043\n0.044\n0.081\n0.079\n0.135\n0.134\n0.127\n0.115\nHigh Transaction Costs\nPanel C: 6-month horizon and quarterly rebalancing\nCE\n4.706\n2.370\n-0.736\n1.609\n0.193\n5.791\n5.501\n3.592\n7.910\np-value\n(1.000)\n(1.000)\n(0.990)\n(0.999)\n(0.214)\n(0.263)\n(0.784)\n(0.000)\nSR\n0.048\n0.041\n0.053\n0.068\n0.066\n0.145\n0.134\n0.117\n0.145\nPanel D: 2-year horizon and annual rebalancing\nCE\n4.506\n0.717\n-0.586\n0.129\n-0.943\n5.579\n6.396\n6.080\n4.563\np-value\n(1.000)\n(1.000)\n(1.000)\n(0.999)\n(0.022)\n(0.000)\n(0.000)\n(0.453)\nSR\n0.047\n0.039\n0.038\n0.073\n0.070\n0.125\n0.123\n0.117\n0.102\nby the investor for the change in value traded. Let τ denote a transaction cost parameter.\nThen the transaction-costs adjusted returns are deﬁned as\nˆrτ,Ms\nt\n= ˆrMs\nt\n−τ\n\f\fωt −ωt−1 · ˆrMs\nt−1\n\f\f,\nwhere τ can attain one of the two possible values τl = 0.1% or τh = 0.5%.\n30\nTable 7 presents summary statistics of the out-of-sample portfolio returns with low (Pan-\nels A and B) and high (Panels C and D) transaction costs. The results show that: (1)\nportfolio performance is monotonically decreasing in terms of the percentage paid in trans-\naction costs (2) the key ﬁndings reported in the main analysis remain the same; that is, the\nNNs consistently outperform the traditional linear predictive regressions and the expecta-\ntions hypothesis framework by generating substantially higher CER and SR values; and (3)\namong the NNs considered, the LSTM architecture remains a dominant speciﬁcation. Quan-\ntitatively, the annualized CERs for all NNs decline by less than 0.5% and 2.1% for the low and\nhigh transaction cost parameters, respectively. In terms of SRs, the decline in performance\nnever exceeds 2% and 3% on a monthly basis for basic NNs and LSTM. However, despite a\nslightly detrimental eﬀect of transaction costs, the best-performing models (NN1 and LSTM)\nwith an actively managed portfolio generate more than two- and three-fold increases in the\nCERs and SRs compared to the scenario in which expected return predictability is ignored.\nThe formal test shows that the CER gains are also statistically signiﬁcant.\n4.5\nBorrowing and Short-selling Constraints\nWe consider an additional robustness check of the alternative assumptions about the portfolio\nweights. The main analysis allows the investor to borrow the money or to short-sell the stock\nby considering the weights in the interval −1 ≤ωt ≤2. In this subsection, we perform a\ntwo-step analysis: we ﬁrst impose borrowing constraints by restricting the optimal weight\non the risk-free investment to be non-negative and then additionally imposing short-selling\nconstrains with the weights 0 ≤ωt ≤1.\nTable 8 reports the results for the two scenarios. We focus on the quarterly rebalanc-\ning case reported in Panels A and C. The corresponding results for the passive portfolios,\nwhich are shown in Panels B and D, remain qualitatively similar. Several observations are\nnoteworthy. First, winsorizing the weights to narrower intervals leads to ambiguous conclu-\nsions about the performance of linear predictive models. On the one hand, the constraints\n31\nprevent optimal investments and hence lead to smaller out-of-sample Sharpe ratios. On the\nother hand, using the certainty equivalent as a measure of portfolio performance, the lin-\near speciﬁcations consistently generate improved results, with the CERs above 3.5% in all\ncases. Thus, constraints on the optimal weights result in higher CERs. The reason for this\nseemingly counterintuitive result is that such restrictions prevent the expected utility from\nachieving unbounded large values (Johannes et al., 2014) and, therefore, avoid extreme in-\nvestments based on unstable predictions of linear regressions (Goyal and Welch, 2008). Since\nthe certainty equivalent measure takes tail behaviour of returns into account, less extreme\ninvestments ultimately yield improved results.\nSecond, unlike the linear regressions, we document a negative impact of imposing bor-\nrowing and short-selling constraints on portfolio performance implied by NNs. For instance,\nPanels A and B in Table 8 demonstrate a decline in both CERs and SRs for all NNs, with\na larger drop in performance measures in response to more stringent assumptions about the\nweights. Nevertheless, despite weaker performance of machine learning methods, the table\nconﬁrms the key results of the main analysis.\nSpeciﬁcally, traditional predictive models\nbarely generate a positive value for the investor, whereas there is robust statistical evidence\nof substantial improvements from using NNs.\n4.6\nDiﬀerent Rolling Window Sizes\nThe subperiod analysis presented in Table 4 reveals a slightly declining performance of NNs\nby the end of the sample. In particular, the LSTM generates higher CERs than the EH\nmodel, however, the diﬀerence proves to be statistically indistinguishable over the last four\ndecades. This raises the question whether the evidence in this paper holds for more recent\ndata. This subsection demonstrates that the main conclusions of this paper indeed remain\nintact.\nTable 9 reports summary statistics of the out-of-sample portfolio returns, which are ob-\n32\nTable 8. Portfolio Performance with Borrowing and Short-Selling Constraints\nThis table reports the annualized certainty equivalent returns and Sharpe ratios for diﬀerent models outlined\nin Section 2.3. The top section of the table imposes borrowing constrains, while the bottom section addi-\ntionally assumes short-selling constraints. Panels A and C show the results when the investor maximizes a\n6-month portfolio return and changes the allocations quarterly. Panels B and D show the results for a 2-year\nhorizon and annual rebalancing. For the statistical signiﬁcance of CERs, we report a one-sided p-value (in\nparentheses) of the test á la Diebold and Mariano (2002). In particular, we regress the diﬀerence in utilities\nfor each model Ms and EH: UMs\nt+T −UEH\nt+T = αMs + εt+T , where UX\nt+T = (rX\np,t+T)\n1−γ\n1−γ\nand rX\np,t+T is the cumu-\nlative portfolio return with the horizon T. Testing for the diﬀerence in the CERs boils down to a test for the\nsigniﬁcance in αMs. We ﬂag in bold font CER values that are signiﬁcant at the 10% conﬁdence level. The\nportfolio construction starts in February 1955. The sample period spans from January 1945 to December\n2018.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\nBorrowing Constraint\nPanel A: 6-month horizon and quarterly rebalancing\nCER\n4.737\n3.662\n3.371\n4.149\n4.560\n9.122\n7.632\n6.900\n8.560\np-value\n(0.999)\n(0.958)\n(0.770)\n(0.591)\n(0.000)\n(0.000)\n(0.003)\n(0.000)\nSR\n0.049\n0.046\n0.061\n0.074\n0.080\n0.176\n0.146\n0.135\n0.157\nPanel B: 2-year horizon and annual rebalancing\nCER\n4.542\n2.780\n2.936\n2.974\n1.560\n4.964\n5.336\n5.275\n5.321\np-value\n(1.000)\n(1.000)\n(1.000)\n(1.000)\n(0.147)\n(0.007)\n(0.008)\n(0.033)\nSR\n0.048\n0.044\n0.051\n0.049\n0.013\n0.101\n0.094\n0.087\n0.100\nBorrowing and Short-Selling Constraints\nPanel C: 6-month horizon and quarterly rebalancing\nCER\n4.737\n3.704\n4.707\n5.353\n5.708\n7.500\n6.758\n7.128\n7.775\np-value\n(0.998)\n(0.528)\n(0.080)\n(0.004)\n(0.000)\n(0.000)\n(0.000)\n(0.000)\nSR\n0.049\n0.047\n0.066\n0.093\n0.093\n0.146\n0.129\n0.138\n0.150\nPanel D: 2-year horizon and annual rebalancing\nCER\n4.542\n2.780\n3.757\n4.261\n5.010\n5.809\n5.320\n5.408\n6.117\np-value\n(1.000)\n(1.000)\n(0.859)\n(0.004)\n(0.000)\n(0.000)\n(0.000)\n(0.000)\nSR\n0.048\n0.044\n0.054\n0.054\n0.071\n0.107\n0.109\n0.098\n0.107\ntained for the subperiod from February 1969 to December 2018 as in Rossi (2018). In relation\nto the models using the rolling-window estimation, we assume a 20-year horizon to assess the\nimpact of longer history on the performance of diﬀerent methodologies, particularly machine\nlearning methods that are assumed to work better with larger samples. Notice that the\nquantitative predictions of this exercise are not directly comparable to the previous results\ndue to diﬀerence in the historical data. In particular, the period from February 1969 to\n33\nDecember 2018 is characterized by slightly weaker market performance, which ultimately\ntranslates into a less favorable opportunity set for the investor. The returns statistics in\nTable 9 are consistent with this intuition. The average Sharpe ratio implied by the model\nwith no predictability shrinks to half the size of that in the benchmark analysis. The linear\nmodels experience comparable deterioration in results.\nFor NNs with quarterly rebalancing, we document several interesting observations. First,\ndespite a weaker performance of the stock market during the period considered, monthly\nSharpe ratios implied by NNs decrease marginally, with the drop approximately equal to\n0.01 to 0.03 relative to the main results. Second, comparing NN1 through NN3 in terms\nof certainty equivalent returns, NNs yield statistically the same results. Although deeper\nnetworks generate slightly lower CERs than those predicted by shallower networks, the p-\nvalues indicate that these model-based values remain in the same equivalence class. Third,\nthe LSTM still produces the most signiﬁcant economic gains. Speciﬁcally, the annualized\ncertainty equivalent yield is above 7% and monthly Sharpe ratios remain as high as 0.165.\nFinally, unlike weak statistical evidence of the main results with recent data, the formal test\nof the results in this subsection demonstrates strong statistical evidence in favor of NNs.\nThe reason is that NNs use a 20-year rolling window for hyperparameter tuning, which helps\nthem to better learn non-linear relationships, and short- and long-term dependencies (in case\nof LSTM) from the data.\n5\nConclusion\nIn this paper, we evaluate the economic gains of using deep learning methods for the con-\nstruction of optimal portfolios. We study the portfolio allocation of a long-horizon investor\nwho uses neural networks to predict future returns when choosing an optimal allocation\nbetween a market portfolio and a risk-free asset. We propose and compare various architec-\ntures of neural networks including shallow and deep feedforward NNs as well as the LSTM\n34\nTable 9. Portfolio Performance from Feb 1969:02 to Dec 2018: 20-year rolling window\nThis table reports the annualized certainty equivalent returns and Sharpe ratios for diﬀerent models outlined\nin Section 2.3. The rolling window estimation uses 20 years of recent data. Panel A shows the results when\nthe investor maximizes a 6-month portfolio return and changes the allocations quarterly. Panel B shows the\nresults for a 2-year horizon and annual rebalancing. Each panel computes the statistics for the whole sample,\nexpansion and recession periods as deﬁned by the NBER. For the statistical signiﬁcance of CERs, we report\na one-sided p-value (in parentheses) of the test á la Diebold and Mariano (2002). In particular, we regress\nthe diﬀerence in utilities for each model Ms and EH: UMs\nt+T −UEH\nt+T = αMs + εt+T , where UX\nt+T = (rX\np,t+T)\n1−γ\n1−γ\nand rX\np,t+T is the cumulative portfolio return with the horizon T. Testing for the diﬀerence in the CERs boils\ndown to a test for the signiﬁcance in αMs. We ﬂag in bold font CER values that are signiﬁcant at the 10%\nconﬁdence level. The portfolio construction starts in February 1969.\nEH\nOLS1\nOLS2\nOLS3\nOLS4\nNN1\nNN2\nNN3\nLSTM\nPanel A: 6-month horizon and quarterly rebalancing\n1969-2018\nCER\n4.600\n1.763\n0.791\n1.025\n3.707\n6.762\n6.601\n6.236\n7.253\np-value\n1.000\n1.000\n0.984\n0.811\n0.018\n0.053\n0.061\n0.016\nSR\n0.025\n0.010\n0.018\n0.059\n0.057\n0.135\n0.140\n0.132\n0.165\nExpansions\nCER\n5.038\n3.158\n2.479\n4.551\n5.846\n7.237\n7.314\n5.673\n6.734\np-value\n0.999\n0.997\n0.694\n0.158\n0.008\n0.022\n0.335\n0.039\nSR\n0.090\n0.059\n0.045\n0.070\n0.068\n0.139\n0.138\n0.141\n0.161\nRecessions\nCER\n1.846\n-6.771\n-9.496\n-18.688\n-8.560\n3.819\n2.347\n4.423\n17.657\np-value\n1.000\n0.999\n0.985\n0.980\n0.345\n0.465\n0.287\n0.002\nSR\n-0.251\n-0.253\n-0.123\n0.034\n0.023\n0.123\n0.156\n0.061\n0.226\nPanel B: 2-year horizon and annual rebalancing\n1969-2018\nCER\n4.530\n0.508\n-2.573\n-2.558\n2.080\n5.788\n5.136\n7.038\n6.477\np-value\n(1.000)\n(1.000)\n(1.000)\n(1.000)\n(0.026)\n(0.068)\n(0.000)\n(0.000)\nSR\n0.023\n0.008\n-0.002\n0.008\n0.025\n0.126\n0.084\n0.117\n0.135\nExpansions\nCER\n4.448\n0.246\n-2.160\n-2.174\n3.324\n5.465\n4.675\n6.739\n6.185\np-value\n(1.000)\n(1.000)\n(1.000)\n(0.992)\n(0.076)\n(0.297)\n(0.000)\n(0.001)\nSR\n0.089\n0.059\n0.035\n0.008\n0.021\n0.108\n0.054\n0.100\n0.127\nRecessions\nCER\n5.089\n2.275\n-5.061\n-4.914\n-4.333\n8.133\n8.538\n9.073\n8.409\np-value\n(0.999)\n(1.000)\n(1.000)\n(1.000)\n(0.023)\n(0.004)\n(0.003)\n(0.009)\nSR\n-0.248\n-0.259\n-0.194\n0.010\n0.045\n0.216\n0.211\n0.210\n0.181\nspeciﬁcation, which is capable of learning the long-term relationships. Three key ﬁndings\nemerge from our investigation.\n35\nFirst, we demonstrate that sound statistical performance of non-linear machine learning\nmethods, such as neural networks, leads to large and signiﬁcant out-of-sample portfolio\ngains. These gains are robust to a variety of portfolio performance measures, the inclusion\nof transaction costs, borrowing and short-selling constraints. Second, we ﬁnd that employing\nthe forecasts of deeper networks does not necessarily translate into larger economic gains. In\norder to identify and beneﬁt from a complex non-linear predictive relationship, the investor\nneeds to harvest more data, while shallower NNs might be a better option in a setting with\nsmall samples. In terms of NNs, we further show that the novel LSTM is the best-performing\nspeciﬁcation. This emphasizes the critical role of short- and long-term order dependencies in\npredicting stock returns, in addition to approximating the non-linear relationship. Finally,\nwe document that NNs perform well even in the absence of additional ingredients, such\nas time-varying return volatility, which are commonly proposed by the literature studying\nlinear predictive regressions. Our results show that NNs are capable of identifying these\ncomplex features from the data in a non-parametric way and without any speciﬁc modelling\nassumptions.\nOur analysis can be extended in a number of ways. It would be interesting to examine\nthe interaction between NNs and alternative preference speciﬁcations. In particular, it is\nnot clear whether an investor with a tail sensitive utility function or a preference for early\nresolution of uncertainty would be able to generate comparable economic gains. Van Binsber-\ngen and Koijen (2010) present evidence that additional economic restrictions can actually\nimprove the model’s performance. Our results point out a negative impact of restricting\nportfolio weights on the gains of the NNs. It would be interesting to examine if our evidence\nholds in a setting with other restrictions, in particular those proposed by Van Binsbergen\nand Koijen (2010). Finally, extending our analysis to multiple assets is a straightforward ex-\nercise, which would shed light on the economic signiﬁcance of forecasting returns of diﬀerent\nasset classes via NNs.\n36\nReferences\nAng, A. and Bekaert, G. (2007). Stock return predictability: Is it there?\nThe Review of\nFinancial Studies, 20(3):651–707.\nAvramov, D. (2002). Stock return predictability and model uncertainty. Journal of Financial\nEconomics, 64(3):423–458.\nBaillie, R. T. and Kapetanios, G. (2007). Testing for neglected nonlinearity in long-memory\nmodels. Journal of Business & Economic Statistics, 25(4):447–461.\nBarberis, N. (2000). Investing for the long run when returns are predictable. The Journal\nof Finance, 55(1):225–264.\nBekaert, G., Engstrom, E. C., and Xu, N. R. (2019). The time variation in risk appetite and\nuncertainty. Technical report, National Bureau of Economic Research.\nBianchi, D., Büchner, M., and Tamoni, A. (2020). Bond risk premia with machine learning.\nReview of Financial Studies, (forthcoming).\nBianchi, D. and Tamoni, A. (2020). Sparse predictive regressions: Statistical performance\nand economic signiﬁcance. Machine Learning for Asset Management: New Developments\nand Financial Applications, pages 75–113.\nBreiman, L. et al. (2001). Statistical modeling: The two cultures (with comments and a\nrejoinder by the author). Statistical science, 16(3):199–231.\nBryzgalova, S., Pelger, M., and Zhu, J. (2019). Forest through the trees: Building cross-\nsections of stock returns. Available at SSRN 3493458.\nBuraschi, A. and Jiltsov, A. (2007). Habit formation and macroeconomic models of the term\nstructure of interest rates. The Journal of Finance, 62(6):3009–3063.\nCampbell, J. Y. (1987). Stock returns and the term structure. Journal of ﬁnancial economics,\n18(2):373–399.\nCampbell, J. Y. and Shiller, R. J. (1988). The dividend-price ratio and expectations of future\ndividends and discount factors. The Review of Financial Studies, 1(3):195–228.\nCampbell, J. Y. and Thompson, S. B. (2008). Predicting excess stock returns out of sample:\nCan anything beat the historical average? The Review of Financial Studies, 21(4):1509–\n1531.\n37\nCampbell, J. Y. and Yogo, M. (2006). Eﬃcient tests of stock return predictability. Journal\nof ﬁnancial economics, 81(1):27–60.\nChen, L., Pelger, M., and Zhu, J. (2019). Deep learning in asset pricing. Available at SSRN\n3350138.\nChen, L., Pelger, M., and Zhu, J. (2020). Deep learning in asset pricing. Available at SSRN\n3350138.\nClark, T. and West, K. (2007). Approximately normal tests for equal predictive accuracy in\nnested models. Journal of econometrics, 138(1):291–311.\nCochrane, J. H. (2008). The dog that did not bark: A defense of return predictability. The\nReview of Financial Studies, 21(4):1533–1575.\nCremers, K. M. (2002). Stock return predictability: A bayesian model selection perspective.\nThe Review of Financial Studies, 15(4):1223–1249.\nDangl, T. and Halling, M. (2012).\nPredictive regressions with time-varying coeﬃcients.\nJournal of Financial Economics, 106(1):157–181.\nDangl, T. and Weissensteiner, A. (2020). Optimal portfolios under time-varying investment\nopportunities, parameter uncertainty, and ambiguity aversion. Journal of Financial and\nQuantitative Analysis, 55(4):1163–1198.\nDiebold, F. X. and Mariano, R. S. (2002).\nComparing predictive accuracy.\nJournal of\nBusiness & economic statistics, 20(1):134–144.\nDumas, B., Kurshev, A., and Uppal, R. (2009).\nEquilibrium portfolio strategies in the\npresence of sentiment risk and excess volatility. The Journal of Finance, 64(2):579–629.\nFama, E. F. and French, K. R. (1988). Dividend yields and expected stock returns. Journal\nof ﬁnancial economics, 22(1):3–25.\nFama, E. F. and French, K. R. (1989). Business conditions and expected returns on stocks\nand bonds. Journal of ﬁnancial economics, 25(1):23–49.\nFeng, G., He, J., and Polson, N. G. (2018). Deep learning for predicting asset returns. arXiv\npreprint arXiv:1804.09314.\nFeng, G., Polson, N., and Xu, J. (2019). Deep learning in characteristics-sorted factor models.\nAvailable at SSRN 3243683.\n38\nFerson, W. E. and Harvey, C. R. (1991). The variation of economic risk premiums. Journal\nof Political Economy, 99(2):385–415.\nFerson, W. E., Sarkissian, S., and Simin, T. T. (2003). Spurious regressions in ﬁnancial\neconomics? The Journal of Finance, 58(4):1393–1413.\nFleming, J., Kirby, C., and Ostdiek, B. (2001). The economic value of volatility timing. The\nJournal of Finance, 56(1):329–352.\nFreyberger, J., Neuhierl, A., and Weber, M. (2020). Dissecting characteristics nonparamet-\nrically. The Review of Financial Studies, 33(5):2326–2377.\nFuster, A., Goldsmith-Pinkham, P., Ramadorai, T., and Walther, A. (2018). Predictably\nunequal?\nthe eﬀects of machine learning on credit markets.\nThe Eﬀects of Machine\nLearning on Credit Markets (November 6, 2018).\nGargano, A., Pettenuzzo, D., and Timmermann, A. (2019).\nBond return predictability:\nEconomic value and links to the macroeconomy. Management Science, 65(2):508–540.\nGiannone, D., Lenza, M., and Primiceri, G. E. (2017). Economic predictions with big data:\nThe illusion of sparsity.\nGiglio, S. and Xiu, D. (2017). Inference on risk premia in the presence of omitted factors.\nTechnical report, National Bureau of Economic Research.\nGoyal, A. and Welch, I. (2008). A comprehensive look at the empirical performance of equity\npremium prediction. The Review of Financial Studies, 21(4):1455–1508.\nGreen, J., Hand, J. R., and Zhang, X. F. (2013). The supraview of return predictive signals.\nReview of Accounting Studies, 18(3):692–730.\nGu, S., Kelly, B., and Xiu, D. (2020). Empirical asset pricing via machine learning. The\nReview of Financial Studies, 33(5):2223–2273.\nHarvey, C. R., Liu, Y., and Zhu, H. (2016). ... and the cross-section of expected returns.\nThe Review of Financial Studies, 29(1):5–68.\nHeaton, J. B., Polson, N. G., and Witte, J. H. (2017). Deep learning for ﬁnance: deep\nportfolios. Applied Stochastic Models in Business and Industry, 33(1):3–12.\nHenkel, S. J., Martin, J. S., and Nardari, F. (2011). Time-varying short-horizon predictabil-\nity. Journal of ﬁnancial economics, 99(3):560–580.\n39\nHochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural computation,\n9(8):1735–1780.\nHodrick, R. J. (1992). Dividend yields and expected stock returns: Alternative procedures\nfor inference and measurement. The Review of Financial Studies, 5(3):357–386.\nHutchinson, J. M., Lo, A. W., and Poggio, T. (1994). A nonparametric approach to pricing\nand hedging derivative securities via learning networks. The Journal of Finance, 49(3):851–\n889.\nIsrael, R., Kelly, B. T., and Moskowitz, T. J. (2020). Can machines ’learn’ ﬁnance? Available\nat SSRN 3624052.\nJiang, J., Kelly, B. T., and Xiu, D. (2020). (re-) imag (in) ing price trends. Chicago Booth\nResearch Paper, (21-01).\nJohannes, M., Korteweg, A., and Polson, N. (2014). Sequential learning, predictability, and\noptimal portfolio returns. The Journal of Finance, 69(2):611–644.\nKelly, B. and Pruitt, S. (2013). Market expectations in the cross-section of present values.\nThe Journal of Finance, 68(5):1721–1756.\nKelly, B. and Pruitt, S. (2015). The three-pass regression ﬁlter: A new approach to fore-\ncasting using many predictors. Journal of Econometrics, 186(2):294–316.\nKelly, B. T., Pruitt, S., and Su, Y. (2019). Characteristics are covariances: A uniﬁed model\nof risk and return. Journal of Financial Economics, 134(3):501–524.\nKingma, D. P. and Ba, J. (2014). Adam: A method for stochastic optimization. arXiv\npreprint arXiv:1412.6980.\nKozak, S., Nagel, S., and Santosh, S. (2020). Shrinking the cross-section. Journal of Financial\nEconomics, 135(2):271–292.\nKuan, C.-M. and White, H. (1994). Artiﬁcial neural networks: An econometric perspective.\nEconometric reviews, 13(1):1–91.\nLettau, M. and Ludvigson, S. (2001). Consumption, aggregate wealth, and expected stock\nreturns. the Journal of Finance, 56(3):815–849.\nLettau, M. and Van Nieuwerburgh, S. (2008). Reconciling the return predictability evidence:\nThe review of ﬁnancial studies: Reconciling the return predictability evidence. The Review\nof Financial Studies, 21(4):1607–1652.\n40\nLewellen, J. (2004). Predicting returns with ﬁnancial ratios. Journal of Financial Economics,\n74(2):209–235.\nLopez de Prado, M. (2019). Beyond econometrics: A roadmap towards ﬁnancial machine\nlearning. Available at SSRN 3365282.\nMcCracken, M. W. and Ng, S. (2016). Fred-md: A monthly database for macroeconomic\nresearch. Journal of Business & Economic Statistics, 34(4):574–589.\nMenzly, L., Santos, T., and Veronesi, P. (2004). Understanding predictability. Journal of\nPolitical Economy, 112(1):1–47.\nMessmer, M. (2017). Deep learning and the cross-section of expected returns. Available at\nSSRN 3081555.\nPástor, L. and Stambaugh, R. F. (2009). Predictive systems: Living with imperfect predic-\ntors. The Journal of Finance, 64(4):1583–1628.\nPaye, B. S. and Timmermann, A. (2006). Instability of return prediction models. Journal\nof Empirical Finance, 13(3):274–315.\nPesaran, M. H. and Timmermann, A. (1995). Predictability of stock returns: Robustness\nand economic signiﬁcance. The Journal of Finance, 50(4):1201–1228.\nRacine, J. (2001). On the nonlinear predictability of stock returns using ﬁnancial and eco-\nnomic variables. Journal of Business & Economic Statistics, 19(3):380–382.\nRapach, D., Strauss, J., and Zhou, G. (2010).\nOut-of-sample equity premium predic-\ntion: Combination forecasts and links to the real economy. Review of Financial Studies,\n23(2):821–862.\nRossi, A. G. (2018).\nPredicting stock market returns with machine learning.\nTechnical\nreport, Working paper.\nSantos, T. and Veronesi, P. (2006). Labor income and predictable stock returns. The Review\nof Financial Studies, 19(1):1–44.\nShiller, R. (1981). Do stock prices move too much to be justiﬁed by subsequent changes in\ndividends? American Economic Review, 71:421–436.\nSirignano, J., Sadhwani, A., and Giesecke, K. (2016). Deep learning for mortgage risk. arXiv\npreprint arXiv:1607.02470.\n41\nStambaugh, R. F. (1999). Predictive regressions. Journal of Financial Economics, 54(3):375–\n421.\nTobek, O. and Hronec, M. (2020). Does it pay to follow anomalies research? machine learning\napproach with international evidence. Journal of Financial Markets, page 100588.\nTorous, W., Valkanov, R., and Yan, S. (2004). On predicting stock returns with nearly\nintegrated explanatory variables. The Journal of Business, 77(4):937–966.\nVan Binsbergen, J. H. and Koijen, R. S. (2010). Predictive regressions: A present-value\napproach. The Journal of Finance, 65(4):1439–1471.\nWachter, J. A. (2006). A consumption-based model of the term structure of interest rates.\nJournal of Financial economics, 79(2):365–399.\nWachter, J. A. and Warusawitharana, M. (2009). Predictable returns and asset allocation:\nShould a skeptical investor time the market? Journal of Econometrics, 148(2):162–178.\nZhang, Z., Zohren, S., and Roberts, S. (2020). Deep learning for portfolio optimisation.\narXiv preprint arXiv:2005.13665.\n42\n",
  "categories": [
    "q-fin.GN",
    "q-fin.PM"
  ],
  "published": "2020-09-07",
  "updated": "2021-07-21"
}