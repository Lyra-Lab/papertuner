{
  "id": "http://arxiv.org/abs/2009.11832v1",
  "title": "Novel Keyword Extraction and Language Detection Approaches",
  "authors": [
    "Malgorzata Pikies",
    "Andronicus Riyono",
    "Junade Ali"
  ],
  "abstract": "Fuzzy string matching and language classification are important tools in\nNatural Language Processing pipelines, this paper provides advances in both\nareas. We propose a fast novel approach to string tokenisation for fuzzy\nlanguage matching and experimentally demonstrate an 83.6% decrease in\nprocessing time with an estimated improvement in recall of 3.1% at the cost of\na 2.6% decrease in precision. This approach is able to work even where keywords\nare subdivided into multiple words, without needing to scan\ncharacter-to-character. So far there has been little work considering using\nmetadata to enhance language classification algorithms. We provide\nobservational data and find the Accept-Language header is 14% more likely to\nmatch the classification than the IP Address.",
  "text": "Novel Keyword Extraction & Language Detection Approaches\nMalgorzata Pikies\nmalgorzata@cloudflare.com\nCloudflare\nLondon, United Kingdom\nAndronicus Riyono\nandronicus@cloudflare.com\nCloudflare\nSingapore, Singapore\nJunade Ali\njunade@cloudflare.com\nCloudflare\nLondon, United Kingdom\nABSTRACT\nFuzzy string matching and language classification are important\ntools in Natural Language Processing pipelines, this paper pro-\nvides advances in both areas. We propose a fast novel approach to\nstring tokenisation for fuzzy language matching and experimentally\ndemonstrate an 83.6% decrease in processing time with an estimated\nimprovement in recall of 3.1% at the cost of a 2.6% decrease in pre-\ncision. This approach is able to work even where keywords are\nsubdivided into multiple words, without needing to scan character-\nto-character. So far there has been little work considering using\nmetadata to enhance language classification algorithms. We provide\nobservational data and find the Accept-Language header is 14%\nmore likely to match the classification than the country language\nassociated to the IP Address.\nCCS CONCEPTS\n• Human-centered computing →Natural language interfaces;\nWeb-based interaction.\nKEYWORDS\nstring tokenisation, fuzzy string matching, language classification\n1\nINTRODUCTION\nFeature extraction is an important part of Natural Language Pro-\ncessing pipelines, whether extracting important keywords [1] or\nlanguage detection [2].\nDuring analysis; text data can be divided into sentences, words,\nor characters, which can then later be treated individually or can\nbe gathered into groups of n-grams [3]. Fuzzy string matching com-\npares tokenised text to keywords using string similarity algorithms.\nFor example; the Edit Distance (also known as the Levenshtein dis-\ntance) [4] measures the number of elementary changes necessary\nneeded to transform one string into another, using the following\nelementary edit operations:\n• a change operation, if X , ∅and Y , ∅;\n• a delete operation, if Y = ∅;\n• an insert operation, if X = ∅.\nOther string similarity algorithms like Cosine similarity [5] and\nDice [3], divide strings into sets of letters known as n-grams. Given\nthese algorithms are not sensitive to the order of characters and\nn-grams, the size of the n-gramcan dramatically alter the accuracy\nof the algorithm. Equation 1 shows a formula for calculating the\nCosine similarity between strings X and Y. Strings are divided into\nn-grams, where each unique n-gram is a separate dimension in a\nmulti-dimensional vector space. The two vectors made of strings X\nand Y are then used to calculate the cosine of the angle between\nthem:\ns(X,Y) =\n®U (X) · ®V (Y)\n| ®U (X)|| ®V (Y)|\n= cosθ.\n(1)\nn-gram based approaches can also be used for language detection,\nbut are notably unreliable on short corpuses of text [2]. Whilst\ninternet standards and web browsers have sought to standardise\ncontent language headers [6], there has been little study on the\naccuracy of these fields.\nOur prior work [1] provided a more detailed definition of vari-\nous string similarity algorithms and provided empirical analysis of\ntheir performance for fuzzy string matching. We extend upon this\nwork here by developing a novel tokenisation approach for fuzzy\nstring matching. We propose a novel hybrid approach to approxi-\nmate keyword search. Our focus is on the impact on accuracy and\ncomputation speed while using a greedy approach for sub-string\nselection prior to its tokenisation. We further explore using internet\nuser metadata to improve language classification.\nIn Section 2 we describe research papers related to language\ndetection and keyword search including n-grams. In Section 3 we\ndescribe our hybrid method to a keyword search text classification.\nSection 4 explores how metadata like web browser headers and\nIP Addresses can be used to improve the accuracy of language\nclassification algorithms. We summarise our research and present\nconclusions in Section 5.\n2\nLITERATURE REVIEW\nThere are many algorithms designed to find exact matches of strings,\nsuch as Knuth-Morris-Pratt [7] or the Boyer Moore algorithm [8].\n[9] developed a novel technique to generate variable-length grams\n(VGRAMs) and showed that VGRAM tokenisation improved per-\nformance of three chosen algorithms. Additionally, [10] describe\na novel approach for n-gram - based string search in the ’write\nonce read many’ context. Their algorithm uses n-gram signatures\ntogether with an algorithm similar to the Boyer Moore algorithm\nthus their technique is also focused on exact string matching.\nIn our approach, we instead wish to perform fuzzy string match-\ning rather than exact matching. [11] proposed a fuzzy-token simi-\nlarity metric, which is a combination of token and character based\nsimilarities. The algorithm looks for a maximum sum of weights\nbetween pairs of tokens in two strings from a weighted bigraph.\nThey also proposed an efficient method based on tokens’ signatures\ncalled Fast-Join.\n[12] proposed using a wildcard symbol (it can represent any\ncharacter from the alphabet) in q-grams. They proposed two algo-\nrithms, BasicEQ and OptEQ, that use a concept of string hierarchy,\ncombinatorial analysis, and semi-lattice for selectivity estimation.\nIn [13] authors proposed two algorithms, The MOst Frequent Mini-\nmal Base String Method (MOF) and Lower Bound Estimation (LBS),\narXiv:2009.11832v1  [cs.CL]  24 Sep 2020\nto perform an estimation of selectivity of approximate substring\nqueries based an extended n-gram table with wildcards.\n[14] showed that the n-gram based frequency method is both\ninexpensive and effective in documents classification. They split\nthe text into n-grams of sizes from one to five (letters) and counted\ntheir occurrences using a hash table.\nn-grams can also be used in language classification. [2] considers\nusing smoothed n-gram based models for language identification of\nTwitter messages - the authors compared a smoothed n-gram lan-\nguage model with a TF-IDF weighting scheme alongside comparing\nvarious classifiers (Naive-Bayes, Logistic Regression, SVM, and LLR\nclassifiers). The authors conclude that: \"This study validates the\nfact that when it comes to dealing with very short texts we need to\nconduct deep investigations based on this domain.\"\n[15] incorporates entity level information into a pre-trained lan-\nguage model, but to the best of our knowledge there is no such\nwork incorporating metadata into language classification models.\n[16] found that \"found that there are significant challenges to accu-\nrately determining the language of tweets in an automated manner\"\nbut notes challenges of using purely geolocation data for language\nclassification.\n[6] provides that web browsers may pass language preferences to\nwebsites using the Accept-Language header; whilst this has been\nimplemented in modern web browsers, there has been no empirical\nstudy of the accuracy of such language headers.\n[17] experimented with using IP Address information and user\ninterface language to predict the language used in user input forms\non a small sample of 510 logs; the authors note that these features\nalone are not strong indicators for determining query language\nand more robust dimensions are needed. [18] found a correlation\nbetween country language, interface language and input language;\nbut to the authors surprise, found only 24% of queries were in a\nlanguage associated with the user’s country (obtained from their IP\nAddress), the work did not consider other browser headers and the\nlogs were from a pan-European online library (it is not understood\nif the context affected the language input of users). We could not\nidentify prior work seeking to use the output of a language classifi-\ncation algorithm together with geolocation data. No prior work has\nconsidered using the web browser’s Accept-Language as a feature\nof language classification.\nTo the best of our knowledge, there exists a gap in the literature\nthat we want to fill. This paper is first to present the performance\nof a keyword search using a hybrid method with strings tokenised\ninto words and character based n-grams and to present a potential\nimprovement to language prediction in short messages by including\ncountry and Accept-Language header as predictor variables.\n3\nGREEDY TOKENISATION ALGORITHM\nIn our prior work [1] we described our approach to a ticket classifi-\ncation system based on fuzzy string matching. A keyword search\nwas performed by scanning a corpus of text in windows of the\nkeyword’s length. The string similarity was estimated using Cosine\nsimilarity, where both text and keyword were divided in n-gram\ns of size 2 (characters). Our prior work [1] found that the Cosine\nalgorithm was not only the most accurate but significantly faster\n(for two strings n and m, the computational difficulty of the Cosine\nalgorithm is O(n + m) whilst the Edit Distance is O(n × n)). The\nmethod was not sensitive to beginning and end of the string. In\nthis Section we would like to present our solution to this issue.\n3.1\nDefinition\nAlgorithm 1 The Greedy algorithm for a keyword search. * The\nsimilarity function runs only if the number of characters in PYj is\nwithin bounds (1 −θ) ∗cX ≤cPYj ≤(1 + θ) ∗cX , with j = −1, 0, 1.\nINPUT: searched string X, text Y, similarity threshold θ\nOUTPUT: a similarity S of the first match\nlX ←length of X\nlY ←length of Y\ncX ←word count of X\npX ←profile of X\npY ←profile of Y\nfor i ←word from PY do\nPY−1 ←cX −1 consecutive words in PY , starting with i\nPY0 ←cX consecutive words in PY , starting with i\nPY+1 ←cX + 1 consecutive words in PY , starting with i\nw−1 ←Cosine similarity of PX and PY−1\n▷*\nw0 ←Cosine similarity of PX and PY0\nw+1 ←Cosine similarity of PX and PY+1\nS ←max{w−1,w0,w+1}\nif S ≥θ then\nreturn S\nend if\nend for\nOur novel approach to fuzzy string matching consists of two\ntokenisation steps. In the first part we divide both strings into words\nby white spaces. We create a profile for both strings, which stores\nall words in the right order with the information of their lengths. In\norder to match on keywords which are divided into multiple words\n(e.g. nameservers and name-servers) we calculate the similarity for\nthree cases:\n• the searched string and a part of the scanned string one word\nshorter than the searched string,\n• the searched string and a part of the scanned string of the\nsame length as the searched string,\n• the searched string and a part of the scanned string one word\nlonger than the searched string.\nWe calculate a similarity only if the number of characters of the\npart of the scanned string is within the acceptable bounds wrt. to\nthe similarity threshold θ. We scan the ticket body (Y) word by\nword. In every iteration we choose the highest similarity S from\nthe three above-mentioned cases. If the condition S ≥θ if fulfilled,\nthe scan stops and the function returns the similarity value.\n3.2\nExperiments\nIn order to measure accuracy of our new approach we gathered 1790\ntickets falling into a chosen product category (known as \"DNS\").\nThe tickets were processed using the multi-classifier outlined in [1]\nboth before and after modification with our novel approach.\n2\nWith our novel approach; of the 1790 tickets, 1286 were properly\nclassified as DNS, 249 were left unclassified, and 255 were misclassi-\nfied (with majority being in three other product areas; Crypto (99),\nServer Errors (81) and Registrar (25)). The mean processing time\nwas 0.012 seconds per ticket and median 0.00934 seconds per ticket.\nWith our old method 1324 tickets we classified as DNS, 236 were\nleft unclassified and 230 were misclassified. The mean processing\ntime of the old approach was 0.073 seconds per ticket and median\n0.056 seconds per ticket. As the new approach is sensitive to the\nbeginning and the end of the string we miss a little on the coverage\nyet the improvement in computing time is valuable (the new ap-\nproach is more than 6 times faster). In order to estimate precision\nand recall we gathered 1208 tickets from a product category known\nas \"Crypto\". The same multi-classifier was applied.\nTable 1: Precision and recall.\nMethod\nPrecision\nRecall\nOld\n0.878\n0.718\nGreedy Approach\n0.855\n0.740\n4\nMETADATA-ENHANCED LANGUAGE\nCLASSIFICATION\nSo far, we have outlined an improved algorithm for fuzzy string\nmatching, however improved language classification can be im-\nportant to improving the accuracy of a given Natural Language\nProcessing pipeline. In this instance, we take chat messages from\nreal world customer support chatbot which is using the [19] library\nfor language classification. The classification is run on the first\nmessage sent by a user, given the need to understand if the user is\nusing a supported language as early as possible in the conversation.\nWe gathered 3204 chats tickets alongside the language classifica-\ntion, the HTTP Accept-Language header presented by the users\nweb browser and list the languages common to the visitor’s coun-\ntry (using MaxMind GeoIP [20] for geolocation based on their IP\nAddress and open-source data [21] to get the languages associated\nwith a given country).\nPredicting language from the first chat message, as we do here,\ncan be challenging and will not replicate all use-cases. The first\nmessage could be just a simple greeting or could be a lengthy\ndescription of the issue the customer experiencing. As the chatbot\nis used for support purposes on a internet infrastructure product;\nin some cases visitors even included some software log lines on\ntheir first message on chat, making it harder to flag whether the\nvisitor would like to get support in a non-English language.\nIn Fig 1, we observe that as the length of a message increases\nin length - so does the probability that classified language will match\nthe visitor’s country language and their browsers Accept-Language\nheader.\nWe do also observe correlation between the classified language\nand Accept-Language header, as shown in Fig 2. Although harder\nto visualise, a similar correlation can be observed between the\nclassified language and the visitor’s country in Fig 3. In 67% of chats,\nall parameters were in agreement. In 15%, the classified language\nFigure 1: Message Length and Language Classification Match\nonly matched Accept-Language header and a further 5% matched\nonly the country languages. 13% had no agreement between these\nthree parameters. These results are visualised in Fig 3.\nFigure 2: Classified Languages and Top 10 Accept-Language\nThe Accept-Language header was 14% more likely to match\nthe language classification than IP Address but 23% more coverage\nwas obtained by allowing either parameter to match the classified\nlanguage than both, indicating both data sources can add value in a\nclassification system. This observational evidence may be leveraged\nby future work to experiment different approaches to incorporate\nsuch metadata into novel language classification approaches.\n5\nCONCLUSIONS\nIn this paper, we presented a novel greedy tokenisation approach\nof strings for use in fuzzy keyword search. Our approach allows\nfor efficient search of keywords using n-gram string similarity\nalgorithms, even where keywords are subdivided into multiple\nwords in the corpus text. Experimental results show that greedy\ntokenisation decreased processing time by 83.6%, we estimated an\nimprovement in recall of 3.1% with a decrease in precision of 2.6%.\nFurther; we provide real-world observational data comparing\nclassified languages to user metadata. Consistent with other re-\nports of low classification accuracy on short strings, observed that\nthe likelihood of the classified language matching the metadata\n3\nFigure 3: Classified Languages and Top 20 Countries\nFigure 4: Classified Language Matches\nincreases with the message length. Whilst the Accept-Language\nmatched the classified language in 82% of instances, the country\nlanguages (extracted from the user’s IP Address) only matched in\n72% of instances. This indicates that Accept-Language likely pro-\nvides a better signal than IP Address for user language, but whilst\nall three signals only matched in 67% of instances, 87% coverage\ncan be obtained if the classified language is allowed to match either\nAccept-Language header or the country language.\nWhilst further research is needed; our data supports future re-\nsearch into using metadata to support language classification algo-\nrithms, particularly for short messages or instances where higher\ncertainty is needed before making language classification decisions.\nOne potential area of study is the creation of a model that receives\ninput from language classification algorithms as well as different\nsources of metadata, with message length potentially being a further\ndimension.\nREFERENCES\n[1] Malgorzata Pikies and Junade Ali. String similarity algorithms for a ticket\nclassification system. In 2019 6th International Conference on Control, Decision\nand Information Technologies (CoDIT), pages 36–41, April 2019.\n[2] Dayvid W Castro, Ellen Souza, Douglas Vitório, Diego Santos, and Adriano LI\nOliveira. Smoothed n-gram based models for tweet language identification: A\ncase study of the brazilian and european portuguese national varieties. Applied\nSoft Computing, 61:1160–1172, 2017.\n[3] Grzegorz Kondrak. N-gram similarity and distance. In Proceedings of the 12th\nInternational Conference on String Processing and Information Retrieval, SPIRE’05,\npages 115–126, Berlin, Heidelberg, 2005. Springer-Verlag.\n[4] VI Levenshtein. Binary Codes Capable of Correcting Deletions, Insertions and\nReversals. Soviet Physics Doklady, 10:707, 1966.\n[5] C. D. Manning. Introduction to Information Retrieval.\n[6] H. Alvestrand. Content Language Headers. 3282 1654, Internet Engineering Task\nForce, May 2002.\n[7] Donald E. Knuthf, James H. Morris, Jr. :l, and Vaughan R. Pratt. Fast pattern\nmatching in strings*, 1974.\n[8] Robert S. Boyer and J. Strother Moore. A fast string searching algorithm. Commun.\nACM, 20(10):762–772, October 1977.\n[9] Chen Li, Bin Wang, and Xiaochun Yang. Vgram: Improving performance of\napproximate queries on string collections using variable-length grams. In VLDB,\n2007.\n[10] Witold Litwin, Riad Mokadem, Philippe Rigaux, and Thomas Schwarz. Fast\nngram-based string search over data encoded using algebraic signatures. In\nProceedings of the 33rd International Conference on Very Large Data Bases, VLDB\n’07, pages 207–218. VLDB Endowment, 2007.\n[11] Jiannan Wang, Guoliang Li, and Jianhua Feng. Fast-join: An efficient method for\nfuzzy token matching based string similarity join. pages 458–469, 04 2011.\n[12] Hongrae Lee, Raymond Ng, and Kyuseok Shim. Extending q-grams to estimate\nselectivity of string matching with low edit distance. pages 195–206, 01 2007.\n[13] Hongrae Lee, Raymond Ng, and Kyuseok Shim. Approximate substring selectivity\nestimation. pages 827–838, 01 2009.\n[14] William B. Cavnar and John M. Trenkle. N-gram-based text categorization. 1994.\n[15] Shanchan Wu and Yifan He. Enriching pre-trained language model with entity\ninformation for relation classification. In Proceedings of the 28th ACM International\nConference on Information and Knowledge Management, pages 2361–2364, 2019.\n[16] Mark Graham, Scott A Hale, and Devin Gaffney. Where in the world are you?\ngeolocation and language identification in twitter. The Professional Geographer,\n66(4):568–578, 2014.\n[17] Juliane Stiller, Maria Gäde, and Vivien Petras. Ambiguity of queries and the\nchallenges for query language detection. 2010.\n[18] Johannes Leveling, M Rami Ghorab, Walid Magdy, Gareth JF Jones, and Vincent\nWade. Dcu-tcd@ logclef 2010: Re-ranking document collections and query\nperformance estimation. 2010.\n[19] AXA Group Operations Spain S.A. Nlp.js. https://github.com/axa-group/nlp.js.\nAccessed: 2020-09-23.\n[20] MaxMind, LLC. Geoip2 country database. https://www.maxmind.com/en/geoip2-\ncountry-database. Accessed: 2020-09-23.\n[21] Annexare Studio. Countries, languages & continents data. https://github.com/\nannexare/Countries. Accessed: 2020-09-23.\n4\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2020-09-24",
  "updated": "2020-09-24"
}