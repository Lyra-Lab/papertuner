{
  "id": "http://arxiv.org/abs/2009.12414v1",
  "title": "Towards a Natural Language Query Processing System",
  "authors": [
    "Chantal Montgomery",
    "Haruna Isah",
    "Farhana Zulkernine"
  ],
  "abstract": "Tackling the information retrieval gap between non-technical database\nend-users and those with the knowledge of formal query languages has been an\ninteresting area of data management and analytics research. The use of natural\nlanguage interfaces to query information from databases offers the opportunity\nto bridge the communication challenges between end-users and systems that use\nformal query languages. Previous research efforts mainly focused on developing\nstructured query interfaces to relational databases. However, the evolution of\nunstructured big data such as text, images, and video has exposed the\nlimitations of traditional structured query interfaces. While the existing web\nsearch tools prove the popularity and usability of natural language query, they\nreturn complete documents and web pages instead of focused query responses and\nare not applicable to database systems. This paper reports our study on the\ndesign and development of a natural language query interface to a backend\nrelational database. The novelty in the study lies in defining a graph database\nas a middle layer to store necessary metadata needed to transform a natural\nlanguage query into structured query language that can be executed on backend\ndatabases. We implemented and evaluated our approach using a restaurant\ndataset. The translation results for some sample queries yielded a 90% accuracy\nrate.",
  "text": "XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE \nTowards a Natural Language Query Processing System \n \nChantal Montgomery \nSchool of Computing \nQueen’s University \nKingston, Canada \n15clm1@queensu.ca \nHaruna Isah \nSchool of Computing \nQueen’s University \nKingston, Canada \nh.isah@cs.queensu.ca \nFarhana Zulkernine \nSchool of Computing \nQueen’s University \nKingston, Canada \nfarhana@cs.queensu.ca\nAbstract — Tackling the information retrieval gap between \nnon-technical database end-users and those with the knowledge of \nformal query languages has been an interesting area of data \nmanagement and analytics research. The use of natural language \ninterfaces to query information from databases offers the \nopportunity to bridge the communication challenges between end-\nusers and systems that use formal query languages. Previous \nresearch efforts mainly focused on developing structured query \ninterfaces to relational databases. However, the evolution of \nunstructured big data such as text, images, and video has exposed \nthe limitations of traditional structured query interfaces. While \nthe existing web search tools prove the popularity and usability of \nnatural language query, they return complete documents and web \npages instead of focused query responses and are not applicable to \ndatabase systems. This paper reports our study on the design and \ndevelopment of a  natural language query interface to a backend \nrelational database. The novelty in the study lies in defining a \ngraph database as a middle layer to store necessary metadata \nneeded to transform a natural language query into structured \nquery language that can be executed on backend databases. We \nimplemented and evaluated our approach using a restaurant \ndataset. The translation results for some sample queries yielded a \n90% accuracy rate. \nKeywords—Cypher, graph database, natural language interface, \nNeo4j, queries \nI. INTRODUCTION \nIn the real world, humans communicate using natural \nlanguages such as English or French. The query-response cycle \nin a human-to-human communication is often very effective \nsince the person responding to the query can ask for further \nclarification if the query is not clear. This is, however, different \nin human-to-computer settings such as querying a database [1]. \nWhile databases have been around for decades, query languages \nfor accessing such databases are unlikely to ever become \ncommon knowledge for the average end-user. For instance, \nStructured Query Language (SQL), despite its expressiveness, \nmay hinder users with little or no relational database knowledge \nfrom exploring and making use of the data stored in an RDBMS \n[2]. Furthermore, different databases have different query \nlanguages and require that the user understand the exact schema \nof the database and the roles of various entities in a query [3, 4]. \nThese challenges have led to an increasing interest in research \nand development of tools such as the natural language interface \nto databases to enhance human-to-database communications.  \nCommonly used natural language query interfaces according \nto Li and Jagadish [3] include (i) keyword-based search \ninterfaces such as Google Scholar, a web-based search engine \nthat indexes the full text or metadata of scholarly literature \nacross many publishing formats and disciplines, (ii) form-based \ninterface such as Web of Science and Scopus in which users first \nselect fields such as topic or author and then type appropriate \nvalues for each field, and (iii) visual query builder, a web-based \nframework that helps researchers in various domains search \nthrough database records to identify and correlate data based on \nsemantic concepts. Besides, keywords are insufficient in \nconveying complex query intent, form-based interfaces are only \nsuitable in cases where queries are predictable and limited to the \nencoded logic, while visual query builders require users to have \nextensive knowledge of the schema [3].  \nA Natural Language Interface to Databases (NLIDB) is a \nsystem that allows users to access information stored in a \ndatabase by typing requests expressed in some natural language \nsuch as English [6, 7]. NLIDBs are designed to simplify the \ninteraction between users and computers. Through a natural \nlanguage interface, users can express queries using natural \nlanguage and get relevant results in one step without the need to \nfill out forms or trying different keywords which only returns a \nranked list of relevant documents instead of a concise reply \ncontaining the specific information [5]. NLIDB enables the \nretrieval of useful information from any database without the \nknowledge of specific query languages such as Structured Query \nLanguage (SQL) for relational databases [8].  \nQuery-response task in NLIDB is often approached by \nmapping natural language queries to logical forms or programs \nthat provide the desired response when executed on a database \n[4]. These interfaces use intermediate representation languages \nto parse and transform the query from users to formal languages \nsupported by the database [9]. Modern NLIDB systems are \nincreasingly leveraging recent advances in deep learning to \nparse and translate natural language queries to a corresponding \nquery language such as SQL query over a given database [10]. \nA major limitation, however, is that training data is assumed to \nhave been acquired a priori and crafted to be well-representative \nof the types of queries one might ask in the target domain  [2]. \nNLIDBs rely on techniques such as pattern matching, \nsyntactic parsing, and semantic grammar interpretation for \nnatural language queries [3, 4]. Research and development \nefforts in NLIDB were initially focused on relational databases \nwhich are useful in storing structured information, however, \nthere is currently an increasing interest in building natural \nlanguage interfaces for non-relational databases such as RDF-\ntriple stores or knowledge bases and graph databases [5]. Other \nexisting studies surveyed by Affolter et al. [10] focus on \ngenerating a distribution of data values stored in the databases \nto match values in the user queries to database field names to \nconstruct SQL queries. However, as we are currently in the era \nof big data, such approaches of generating a subset of possible \nvalues by applying statistical distribution methods have become \nimpractical and inefficient. This study, therefore, focuses on the \ndevelopment of an interface to a backend relational database for \ntranslating natural language queries to SQL queries. Related \ninformation about the relational database is kept in a graph \ndatabase to extend the backend to support multiple distributed \ndatabases in the future and be able to compose a query that joins \nfields from multiple data sources.  \nQuery over graph databases is increasingly attracting much \nattention [13]. Storing and managing connected semi-structured \ndatasets within relational databases is very challenging because \nrelational databases were originally designed to store and \nprocess data in tabular structures. The strength of relational \ndatabases lies in their abstraction, however, in practice, \nmaintaining foreign key constraints and computing many JOINs \nbecomes prohibitively expensive [12]. The underlying data \nlayout in graph databases usually does not follow the fixed \nschema based on tables that implement relations. Multiple types \nof relational and complex data can be mapped and organized in \na non-rigid structure in graph databases [14]. The benefit of \nusing a graph database is the ability to quickly traverse nodes \nand relationships to find relevant data [11]. \nA. Use Case Scenario \nThe use case considered in this study is a large restaurant with \nan existing relational database which is the primary system for \nstoring all transaction records. The data is linked in nature and \nthe restaurant is looking to optimize its data management \nstrategies by developing a cloud-based interface for its \ncustomers to effectively access and query information from its \ndatabase. The proposed interface is aimed at answering \nquestions such as: which restaurants have excellent ratings?  \nThis natural language query should be translated into the \nfollowing SQL query: \nSELECT DISTINCT restaurant_name FROM restaurants \nWHERE rating_text= “excellent”; \nAn example of the expected result should look as follows: \nRestaurant_name \nCity \nAverage_rating\nAtlantic Dishes \nKingston \n4.8 \nNorthern Buffet \nOttawa \n4.7 \nLunch Basics \nToronto \n4.6 \nB. Key Contributions \nThe key contributions in this study include (i) background \nconcepts on NLIDB design strategies, (ii) literature review on \ntranslating natural language inputs into SQL queries, and (iii) \ndesign and implementation of a 3-layered architecture for \nexecuting natural language queries on a relational database. The \nfirst layer is a cloud-based text entry platform for the users to \nenter the query text. The middle layer consists of a graph \ndatabase and algorithms to transform the natural language query \ninto an SQL query. Finally, the third layer consists of a relational \ndatabase to run the SLQ query on. The novelty of this study is \nthe use of a graph database to store the schema of the backend \ndatabases in a way to enable graph search for semantic matching \nof the natural language query text with database field names. \nAdditional algorithms use the search results and predefined SQL \nquery templates to transform the user query into a SQL query.  \nC. Organization \nThe paper is organized as follows. Section II presents a \nbackground study on approaches to designing NLIDBs and a \nliterature review of recent studies on natural language interfaces \nto graph databases. Section III presents the architecture and \ndescribes the components of the cloud-based interface. Section \nIV provides details about the implementation and evaluation of \nthe proposed system. Finally, Section V presents concluding \nremarks and a list of future work. \nII. BACKGROUND STUDY \nA. NLIDB Research Challenges \nThere have been numerous attempts towards supporting \narbitrary natural language query processing on databases [15]. \nThe use of natural language interfaces for querying databases \noffers the opportunity to bridge the technological gap between \nend-users and systems that use formal query languages [6]. The \nkey research problems in this area are depicted in Fig. 1.  \n \nUser queries accepted through voice or chat must be (1) first \ntransformed into natural language text from which (2) word \ntokens have to be extracted and mapped to the backend database \nschema. Typically, organizations have a hybrid distributed \nstorage system and (3) ideally queries should support existing \nstorage architecture. (4) The next challenge is to find DB \nrelations to join DBs through one or more subqueries and deduce \nthe response. (5) Once relations are mapped, queries must be \nformulated using appropriate languages for specific storage \nsystems and (6) executed in a distributed manner to optimize \nquery response. (7) Finally, responses must be presented using \nthe preferred format and visualization tools. \nB. Literature Survey \nAffolter et al. [10] identified five different approaches to \ndesigning NLIDBs: (i) Keyword-based, (ii) Pattern-based, (iii) \nParsing-based, (iv) Grammar-based, and (v) Neural machine \ntranslation-based approaches as described below.  \n1) Keyword-based  \nThe keyword-based approach is the most widely used \ninterface for information retrieval [5]. At the core of the \nkeyword-based NLIDB is a token lookup step where the system \ntries to match the given keywords against an inverted index of \nthe base and metadata [13].  \n2) Pattern-based \nThe pattern-based NLIDB is an extension of the keyword-\nbased approach with natural language patterns for answering \nmore complex questions such as concepts or aggregations. This \napproach focuses on the optimization of user interaction. \n3) Parsing-based \nIn the parsing-based approach, the input query is first parsed, \nthen the information generated is used to understand the \ngrammatical structure and dependencies in the query. \n4) Grammar-based  \nAt the core of the grammar-based NLIDB is a set of rules \nthat defines the questions that can be understood and answered \nFig. 1. NLIDB research challenges. \nAccept user\nquery text\nMap text \ntokens to \nDB schema\nSupport a \nvariety of \nbackend DB \nResolve DB \nrelations for \ncomplex query\nFormulate \nstructured query\nExecute multi-DB \ndistributed query \nPresent response / \nvisualization\n1\n2\n3 \n4\n6 \n7\n5\nby the system. Using rules which may have to be written by hand \nand are highly domain-dependent, the system can give the users \nsuggestions on how to complete their questions during typing. \nThis supports users to write understandable questions.  \n5) Neural machine translation-based \nNeural machine translation-based NLIDB is a recent \napproach with a focus on applying supervised machine learning \ntechniques on a set of query-response pairs where the queries are \nthe natural language inputs from the user while the responses are \nthe output SQL or SPARQL statements. This approach is highly \ndependent on data availability. \nResearch on natural language interfaces to relational \ndatabases has spanned several decades [7]. This study focuses \non graph databases which excel in traversing through the nodes \nin a graph data by following relationships between nodes to find \nrelevant data [11]. Many applications of the future will be built \nusing graph databases [12]. According to Robinson et al. [14], \nthere are three dominant graph data models, the property graph, \nResource \nDescription \nFramework \n(RDF) \ntriples, \nand \nhypergraphs. Furthermore, graph databases such as Neo4j and \nJanusGraph use a variant of the property graph model. An \nimportant difference between relational and graph databases is \nthe query language for retrieving information. While SQL is the \nde facto language in relational databases, a variety of declarative \nquery languages have recently emerged for querying graph \ndatabases. SPARQL is one such language that was adopted by \nmany vendors for querying RDF graphs while Cypher and \nGremlin are the query languages for property graphs [16]. \nAccording to Park and Lim [13], a keyword-based search on \na graph database usually returns a set of connected structures \nthat represent how the data containing query keywords are \ninterconnected in the database. The authors propose and \nevaluate a new ranked keyword search method for graph \ndatabases by adopting a tree-based approach in their study for \nefficient query processing over a large volume of graph data. \nThey also observe that top-k answer trees based on their \nproposed structure and relevance measures can satisfy users’ \ninformation needs better than conventional answer structures. \nOro and Ruffolo [6] designed a modular system capable of \ntranslating natural language questions into different formal \nqueries such as SPARQL and Cypher to exploit various \nknowledge bases and databases. Given a specific domain, \nqueries submitted by users contain concepts that can be \ncategorized into ontological classes and relations. \nZhu et al. [5] propose and evaluate a natural language \ninterface to graph-based bibliographic information retrieval. The \ninterface can parse and interpret natural language queries by \nrecognizing bibliographic named entities and dependency \nrelations among the entities. The authors reported that the \nsystem can correctly answer 39 out of 40 annotated queries with \nvarying lengths and complexities. These interfaces were \nfundamental to our study. Next, we describe the design of our \nproposed cloud-based customer query interface. \nIII. SYSTEM DESIGN  \nA. Design Decisions  \nWe aimed to address the NLIDB challenges depicted in Fig. \n1 and develop a proof of concept to assess the feasibility of using \n                                                           \n1 https://www.zomato.com/ncr \na multi-layered architecture with a graph database to serve \nqueries involving multiple different distributed databases. \nAlthough in this paper we illustrate a simple use case solution \ninvolving only one relational database and a few simple queries, \nour architecture is designed to address multi-DB backends and \ncomplex queries which we will demonstrate in our future work.  \nWe provide a flexible chat interface to enter a natural language \nquery and transform it into an SQL query that is executed on a \nbackend MySQL restaurant database. Following the guidelines \nfrom Perkins et al. [11] to choose the data management and \nanalytics use cases, we built our multi-layered solution using \nNeo4j as the graph database as it is open-source, fast, typeless, \nschemaless, and puts no constraints on relations in the data. \nB. Workflow \nOur NLIDB workflow is shown in Fig. 2. A user can type a \nquestion into the system and will be returned either a ranked list \nof results from the main transactional database or a response \nindicating that the question cannot be answered. The user input \nis first lemmatized for improved database element selection. \nParts of speeches are tagged and semantic analysis is done for \nnoun phrase extraction. The nouns, adjectives, and noun phrases \nare extracted for a mapping operation. A mapping table is used \nto find associations between tokens and data values, while a \ngraph database is used to find matching schema components or \nattributes (columns in tables) and relations (connections) \nbetween the graph nodes. Once these mappings are done, the \nextracted information is inserted into predefined SQL templates \nto formulate and execute the SQL query. \n \nFig.2. Data processing workflow. \nIV. SYSTEM IMPLEMENTATION \nA. Data \nThe data used in this project was collected from Zomato1, a \nrestaurant search engine, and available on Kaggle, a public data \nplatform. The data was extracted in CSV files and inserted into \nMySQL. Although this system is not independent of the \ndatabase, it could be adapted to other databases by refactoring \nthe mapping table and graph database to reflect the altered \nschema. The schema for the SQL database is shown in Fig. 3. \nB. Implementation Details \nPython 3.7 was chosen as the implementation language as its \nclean syntax makes it a popular choice for most data processing \nand analytics tasks. There are also many NLP libraries \ncompatible with Python. TextBlob 2 was chosen as the NLP \nlibrary as it is lightweight and provides various standard \n2 https://textblob.readthedocs.io/en/dev/ \nfunctions such as part-of-speech tagging and lemmatization \nNeo4j was chosen as the graph database to represent the schema. \n \nFig.3. The database schema.  \nThe system was implemented on a Mac OS but the source \ncode (Python) can be easily ported to any operating systems. The \nPyCharm integrated development environment (IDE) was used \nto develop the source to help with quicker development time and \nfast compilation. The Python unit testing framework unittest3 \nwas chosen for testing as it supports test automation, sharing of \nsetup, and shutdown code for tests.  \nThe implementation architecture of the system is shown in \nFig. 4 and consists of three layers: User Interface, Query \nAnalysis and SQL Mapping, and Backend DBs layers. We used \na simple text input in this proof of concept implementation for \nthe user query interface which can be extended to support web-\nbased query interface in the future. The SQL Mapping layer \ncontains several components as described below. \n \nFig. 4. The system architecture.  \n1) Graph Database \nA Neo4j graph database was used to represent the schema of \nthe backend MySQL database which can be extended to support \nmultiple distributed and hybrid data sources. It was used to \nrepresent the tables, attributes and columns as nodes and \nrelationships as edges. We assigned Neo4j node values as table \n                                                           \n3 https://docs.python.org/3/library/unittest.html \nnames (e.g., code), attribute names, and synonyms according to \nthe schema and node property values to indicate the type of \nschema component as table, attribute or synonym (e.g., table). \nSimilarly, edges were also assigned values to indicate \nrelationships and properties to indicate the types of \nrelationships. Thus, a search through the node values based on \nquery words (e.g., country) would lead to the matching schema \ncomponent, an attribute or table or synonym, that could be used \nin formulating the SQL query. For example, when given the \ntoken 'country', our graph query would return all nodes having \nvalue=country and the property would indicate the node type, \nwhich would be processed further and handled based on the \nnode type. Synonyms helped find similar terms as the query \nwords which can be linked to an attribute or value.  \nTherefore, the graph in parts forms a word ontology to help \nmap query text to SQL query which can be easily partitioned if \nnecessary, for scalability based on the property values. Fig. 5 \nshows the Neo4j data model.  \n \nFig.5. The Neo4j data model.  \n2) Query Analysis and Mapping \nThe part of the query text analysis phase consists of \ntokenization, mapping, and mapping table.  \na) Tokenization \nThe first task of tokenization is to lemmatize the words in \nthe given input text. Lemmatization is the process of removing \ninflectional endings from words and returning its base form. \nThis transforms words such as 'restaurants' into 'restaurant' and \n'deliveries' into 'delivery', making it easier for the database to \ncorrectly distinguish a concept or topic. After lemmatization, we \nperformed part-of-speech (POS) tagging using the TextBlob \nNLP library to extract adjectives and nouns from the query text. \nSubsequently, noun phrase extraction is performed to capture \nmulti-token semantics. To extract noun phrases from a cohesive \ntext, a process called chunking is used to compose semantic \nphrases of multi-token sequences from the original text. If noun \nphrases are neglected, the system would not recognize words \nsuch as 'dim sum' as a cohesive entity. From the POS tagging, \nnouns, adjectives, and noun phrases are extracted and used in the \nmapping phase as these elements are most commonly used to \ndescribe database elements.  \nb) Mapping \nThe role of mapping is to attempt to map each token to a \ndatabase element. Each token can have a set of possible \ncorresponding elements: relation, attribute, or value. First, a \nmapping table is used to find if the token corresponds to a value \nin the database. If the value is found, then the attribute and \nsubsequent relation will be known. If the token does not \ncorrespond to a value, it is checked to be either a relation or \nattribute by querying the graph database. The mapping steps for \nthe tokens “restaurant” and “italian” is shown in Fig. 6. \n \nFig. 6. The mapping steps for the tokens “restaurant” and “italian”. \nc) Mapping Table \nThe mapping table was designed to recognize a small \nnumber of unique values in the database from columns that \nwould be queried often. In the future, we plan to apply machine \nlearning algorithms to populate and update this table. We built \nthe table using Python dictionary type which is in the form:  \nmapping_table [x]  = y \nwhere x is a unique value and y is the column name \n(attribute) that it corresponds to. Python dictionary was chosen \nbecause it has O(1) access time since the keys are accessed \nthrough a hashing function. The current mapping table contains \nall the unique values from the columns: cuisine, city, \ncountry_name, rating_text, currency. The mapping table in this \nstudy is relatively small (12KB) and fast to query, but with a \nlarger database, this may become a limitation on the system \nresources.  \n3) MySQL Database \nThe SQL queries generated were restricted to the form:  \nSELECT {attributes} FROM {table} [, {table}] (WHERE \n{attribute=value} [and {attribute=value}])             …             (1)  \nwhere elements in curly braces occur once, elements in \nround brackets may occur once, and elements in square brackets \nmay occur zero or more times. The mapped tokens were \ncompiled into three lists: tables, attributes, and attribute-value \npairs as follows. \n1. All tables in any mapped token will be in {tables}. \n2. Attributes that are not a part of an attribute-value pair will be \nin {attributes}. \n3. All tokens which have been mapped to a table, attribute, and \nvalue will be in {attribute=value}. \nWe defined template strings with placeholders as shown in \nEq. 1. Data from the 3 lists were used to replace the placeholders \nto formulate SQL queries. We used the DISTINCT keyword in \nthe template for clarity.  \nAs the last step, the system executed the generated SQL \nquery on the database. Fig. 7 shows the workflow to process the \nnatural language query “What are the restaurants and cities in \nIndia that serve fast food” and translate it into an SQL query. \nThe text in italics describes the operation carried out at each step. \n4) Results and Validation \nThe purpose of this study was to devise an algorithm to \nconvert a natural language query into an SQL query to be \nexecuted on backend databases. Currently, the most reliable \nmethod of creating SQL queries is manual query generation by \ndatabase experts. Two experiments were performed to validate \nour approach. The first experiment involved running multiple \nEnglish queries and verifying the outputs against the human-\ngenerated SQL queries. \n \nFig. 7. A full breakdown of natural language query to SQL query. \nThe system was tested on numerous queries and the results \nof three queries are shown in TABLE I grouped by questions \n(Q#), human and system generated queries. Since the same \nquery can sometimes be formulated differently, our approach \nwas validated both quantitatively based on the accuracy in 1) \nretrieving the desired information, 2) extracting the correct \nrelations, attributes, and values given the natural language \nquery, and qualitatively based on 3) the optimality of the \nformulated query. Test cases were defined to validate the \nfunctionality at different phases. The translation results for ten \nquestions yielded a 90% accuracy rate. \n5) Discussion \nThe qualitative analysis for the simple correct queries proved \nthat our approach, in comparison with previous approaches \ndescribed in the literature survey section, was near-optimal. As \nshown in Q3, an additional column is included in the query, \nhowever, it is contextually relevant and generated the correct \nresult. The reason behind this is that a synonym node existed in \nthe graph database which related the word 'rating' to \n'aggregate_rating', and thereby caused the selection of this \ncolumn in the SQL query. Some queries did not produce correct \nresults such as Q2, where the system generated query failed to \nrecognize and map the adjective ‘chinese’ into a WHERE \nclause. Other queries such as Q4: “which chinese restaurants are \nin mumbai” also failed for the same reason, which has a similar \nmeaning as Q2 and should produce the same SQL query and \nresult. In Q2, the system recognized and tagged the word \n'chinese' as a past participle verb, whereas for Q4 above, it was \ntagged as an adjective. As the system uses adjectives, nouns, and \nnoun phrases to map to database elements, Q2 and Q4 resulted \nin wrong/incomplete queries.  This study was exploratory to \nlearn the challenges and develop a prototype architecture for \nNLI to database systems. It revealed the following key \nchallenges which we plan to address in the future work: a) \nambiguity in mapping natural language words to database \nschema i.e., table and column names, b) composing complex \nqueries with multiple joins, parts and nested queries, c) \ndistinguishing between item names and values to compose \nqueries, and d) resolving parts of speech and error in NL query. \nSome of the options we would like to consider for our future \nwork are to use an interactive NLI to resolve ambiguity, missing \nvalue and noise in query, apply machine learning methods to \nidentify frequent queries and relationships among query items to \ncreate a rich metadata table, and extend the graph database and \nthe architecture to support queries over hybrid distributed \ndatabases.      \nTABLE I: Questions (Q) and generated SQL queries  \nSymbol \nSQL Queries \nQ1 \nHuman \n \nSystem \nwhat are the italian restaurants? \nSELECT DISTINCT restaurant_name FROM \nrestaurants NATURAL JOIN cuisines WHERE \ncuisine='italian' \nSELECT DISTINCT restaurant_name FROM \nrestaurants NATURAL JOIN cuisines WHERE \ncuisine='italian' \nQ2 \nHuman \n \nSystem \nwhat restaurants in mumbai have chinese food? \nSELECT DISTINCT restaurant_name FROM \nrestaurants NATURAL JOIN cuisines WHERE \ncity='mumbai' and cuisine='chinese' \nSELECT DISTINCT cuisine, restaurant_name FROM \ncuisines NATURAL JOIN restaurants WHERE \ncity='mumbai' \nQ3 \nHuman \nSystem \nwhich restaurants have an excellent rating? \nSELECT DISTINCT restaurant_name FROM \nrestaurants WHERE rating_text='excellent' \nSELECT DISTINCT aggregate_rating, \nrestaurant_name FROM restaurants WHERE \nrating_text='excellent' \n \nV. CONCLUSION \nThis paper reports a feasibility study on designing an NLIDB \nsystem for translating natural language queries to SQL. We \ndefine a graph model based on the schema of the backend \nrelational database and synonymous terms, which is searched \nusing query terms to find matching schema elements. Values in \nthe query are searched for in a metadata table to recognize \nrelevant schema elements. These search results are used to \nformulate the SQL query using predefined templates through a \nthree-level system architecture. The test results were promising \nalthough much work is needed to support more complex queries \nand distributed database backends.  \nThe future work will focus on exploring machine learning \nalgorithms to define the metadata table, replace synonyms with \nexisting ontologies, define complex SQL templates, for \nexample, to support the aggregate function and nested queries \nsuch as ‘how many restaurants in Canada has Mexican cuisine’, \nand allow hybrid distributed storage systems.  Recent deep \nlearning models have shown great success in identifying phrases \nin natural language which can be used to process the query text \nto correctly identify the parts of speech and correct ill-formed \nqueries. Although we implemented a very simple proof of \nconcept prototype in this study, we validated the feasibility of \nusing the graph database in a multi-tiered architecture to \nimplement an NLIDB system that can support multiple backend \ndatabases. The architecture can be further leveraged using \nmachine learning techniques to learn query patterns, frequent \nqueries and cache the responses to reduce response time and \nimprove the overall system performance. Artificial intelligence \nconversation techniques can be used to enable interactive query \nprocessing which can also help disambiguate the query \nobjectives and enable prediction of the next query for efficient \nquery processing.  \nREFERENCES \n[1] C. Baik, H. V. Jagadish, and Y. Li, \"Bridging the semantic gap with SQL \nquery logs in natural language interfaces to databases,\" 35th International \nConference on Data Engineering (ICDE), 2019: IEEE, pp. 374-385.  \n[2] P. Utama et al., \"An End-to-end Neural Natural Language Interface for \nDatabases,\" arXiv preprint arXiv:1804.00401, 2018. \n[3] F. Li and H. Jagadish, \"Constructing an interactive natural language \ninterface for relational databases,\" Proceedings of the VLDB Endowment, \nvol. 8, no. 1, pp. 73-84, 2014. \n[4] A. Neelakantan, Q. V. Le, M. Abadi, A. McCallum, and D. Amodei, \n\"Learning a natural language interface with neural programmer,\" arXiv \npreprint arXiv:1611.08945, 2016. \n[5] Y. Zhu, E. Yan, and I.-Y. Song, \"A natural language interface to a graph-\nbased bibliographic information retrieval system,\" Data & Knowledge \nEngineering, vol. 111, pp. 73-89, 2017. \n[6] E. Oro and M. Ruffolo, \"A Natural Language Interface for Querying RDF \nand Graph Databases,\" in Consiglio Nazionale delle Ricerche Istituto di \nCalcoloe Reti and Alte Prestazioni, 2015. \n[7] I. Androutsopoulos, G. D. Ritchie, and P. Thanisch, \"Natural language \ninterfaces to databases–an introduction,\" Natural language engineering, \nvol. 1, no. 1, pp. 29-81, 1995. \n[8] F. Brad, R. C. A. Iacob, I. A. Hosu, and T. Rebedea, \"Dataset for a Neural \nNatural Language Interface for Databases (NNLIDB),\" in Proceedings of \nthe Eighth International Joint Conference on Natural Language \nProcessing (Volume 1: Long Papers), 2017, pp. 906-914.  \n[9] H. Li and Y. Shi, \"A wordnet-based natural language interface to \nrelational databases,\" in 2010 The 2nd International Conference on \nComputer and Automation Engineering (ICCAE), 2010, pp. 514-518.  \n[10] K. Affolter, K. Stockinger, and A. Bernstein, \"A Comparative Survey of \nRecent Natural Language Interfaces for Databases,\" arXiv preprint \narXiv:1906.08990, 2019. \n[11] L. Perkins, E. Redmond, and J. Wilson, Seven databases in seven weeks: \na guide to modern databases and the NoSQL movement. Pragmatic \nBookshelf, 2018. \n[12] M. Hunger, \"From Relational to Graph: A Developer's Guide,\" in DZone, \ned, 2016. \n[13] C.-S. Park and S. Lim, \"Efficient processing of keyword queries over \ngraph databases for finding effective answers,\" Information Processing & \nManagement, vol. 51, no. 1, pp. 42-57, 2015. \n[14] I. Robinson, J. Webber, and E. Eifrem, Graph databases: new \nopportunities for connected data. \" O'Reilly Media, Inc.\", 2015. \n[15] Y. Li, H. Yang, and H. Jagadish, \"NaLIX: A generic natural language \nsearch environment for XML data,\" ACM Transactions on database \nsystems (TODS), vol. 32, no. 4, p. 30, 2007. \n[16] R. Angles, M. Arenas, P. Barceló, A. Hogan, J. Reutter, and D. Vrgoč, \n\"Foundations of modern query languages for graph databases,\" ACM \nComputing Surveys (CSUR), vol. 50, no. 5, p. 68, 2017. \n",
  "categories": [
    "cs.IR",
    "cs.AI",
    "cs.DB"
  ],
  "published": "2020-09-25",
  "updated": "2020-09-25"
}