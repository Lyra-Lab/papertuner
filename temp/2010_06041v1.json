{
  "id": "http://arxiv.org/abs/2010.06041v1",
  "title": "Towards Machine Translation for the Kurdish Language",
  "authors": [
    "Sina Ahmadi",
    "Mariam Masoud"
  ],
  "abstract": "Machine translation is the task of translating texts from one language to\nanother using computers. It has been one of the major tasks in natural language\nprocessing and computational linguistics and has been motivating to facilitate\nhuman communication. Kurdish, an Indo-European language, has received little\nattention in this realm due to the language being less-resourced. Therefore, in\nthis paper, we are addressing the main issues in creating a machine translation\nsystem for the Kurdish language, with a focus on the Sorani dialect. We\ndescribe the available scarce parallel data suitable for training a neural\nmachine translation model for Sorani Kurdish-English translation. We also\ndiscuss some of the major challenges in Kurdish language translation and\ndemonstrate how fundamental text processing tasks, such as tokenization, can\nimprove translation performance.",
  "text": "Towards Machine Translation for the Kurdish Language\nSina Ahmadi\nInsight Centre for Data Analytics\nNational University of Ireland Galway\nahmadi.sina@outlook.com\nMariam Masoud\nInsight Centre for Data Analytics\nNational University of Ireland Galway\nmaraim.elbadri@gmail.com\nAbstract\nMachine translation is the task of translating\ntexts from one language to another using com-\nputers. It has been one of the major tasks in\nnatural language processing and computational\nlinguistics and has been motivating to facili-\ntate human communication. Kurdish, an Indo-\nEuropean language, has received little atten-\ntion in this realm due to the language being\nless-resourced. Therefore, in this paper, we are\naddressing the main issues in creating a ma-\nchine translation system for the Kurdish lan-\nguage, with a focus on the Sorani dialect. We\ndescribe the available scarce parallel data suit-\nable for training a neural machine translation\nmodel for Sorani Kurdish-English translation.\nWe also discuss some of the major challenges\nin Kurdish language translation and demon-\nstrate how fundamental text processing tasks,\nsuch as tokenization, can improve translation\nperformance.\n1\nIntroduction\nSince the early advances in the field of natural lan-\nguage processing (NLP), one major task that moti-\nvated researchers to use machines for natural lan-\nguages has been Machine Translation (MT). Natu-\nral language is notoriously complex and irregular\nwith a great variability in the type of morphemes\nand their meanings as well as their syntactic and\nsemantic dependencies in the context. Therefore,\nmanual translation has proved to be inviable for\nsuch a task.\nOver half a century, MT techniques have\nbeen getting more efficient and less language-\ndependent.\nDictionary-based and rule-based\napproaches, which are deemed traditional ap-\nproaches in the field, carry out the task of trans-\nlation using manually-defined rules and resources\n(Tripathi and Sarkhel, 2010). Later, statistical ma-\nchine translation further paved the way for dimin-\nishing the role of a linguist in the loop and de-\ncrease language dependency (Koehn, 2009). With\nthe current advances in machine learning, par-\nticularly recurrent neural networks, neural ma-\nchine translation (NMT) has been successfully\nused with state-of-the-art results for many lan-\nguages (Koehn, 2020).\nThat being said, MT is not similarly challenging\nfor all languages due to language-specific features.\nFor instance, the translation of a morphologically-\nrich language, such as Czech or German, repre-\nsents further challenges in alignment in compar-\nison to a less morphologically-rich language like\nEnglish (Passban, 2017; Mi et al., 2020). More-\nover, MT systems require reasonably large aligned\ndatasets and performant language processing tools\nsuch as tokenizer, stemmer and morphological an-\nalyzer (Koehn and Knowles, 2017).\nSuch re-\nsources and tools are not always available, particu-\nlarly for less-resourced languages. Languages are\nclassified as less-resourced where general-purpose\ngrammars and raw internet-based corpora are the\nonly existing resources, lacking manually crafted\nlinguistic resources and large monolingual or par-\nallel corpora.\nExcept the richer-resourced lan-\nguages, the majority of the human languages are\nconsidered less-resourced (Cieri et al., 2016). This\nis also the current status of the Kurdish language,\nan Indo-European language spoken by 20-30 mil-\nlion speakers (Ahmadi et al., 2019; Esmaili and\nSalavati, 2013).\nIn this paper, we discuss the major challenges in\nMT for Sorani Kurdish, including the lack of ba-\nsic language processing tools such a tokenization.\nTo further highlight the challenges, we report the\nperformance of two NMT models in various ex-\nperimental setups based on the tokenization meth-\nods and resources. Despite the scarcity of paral-\nlel corpora for Kurdish, there are a few parallel\nresources which can be used for the task, partic-\nularly the Tanzil corpus (Tiedemann, 2012) which\ncontains 92,354 parallel sentences, the TED cor-\npus (Cettolo et al., 2012) and KurdNet–the Kurdish\nwordnet (Aliabadi et al., 2014).\n2\nRelated Work\nThere have been very few previous studies that ad-\ndress the Kurdish language in the MT realm. One\nof the outstanding projects in creating a rule-based\nmachine translation system for Kurmanji and So-\nrani is the Apertium project (Forcada et al., 2011).\nIn this open-source project, various tools and re-\nsources are developed for the Kurdish language,\nincluding bilingual and morphological dictionar-\nies, structural transfer rules and grammars. An-\nother initial attempt to create a machine transla-\ntion system for Kurdish is inKurdish1 which uses\ndictionary-based methods for translation.\nTaher\net al. (2017) report that this system fails to trans-\nlate based on the length of the input sentences and\nthe degree of idiomaticity. As the two major exist-\ning machine translation tools for Sorani Kurdish,\nKaka-Khan (2018) states that although the rule-\nbased method of Apertium performs significantly\nbetter, limitations of the lexicon and transfer rules\nlead to incorrect translations and therefore, gener-\nalization across domains becomes difficult.\nKurdish language translation has been also of\ninterest to many humanitarian organizations due\nto the refugee crisis in the current years, Trans-\nlators without Borders (TWB)2 and Tarjimly3, to\nmention but a few (Balkul, 2018). Some of these\norganizations use mobile applications to enable\nrefugees to get in touch with translators for their\ntranslation needs such as appointments with au-\nthorities. In the case of TWB, a machine trans-\nlation system is created based on the Apertium\nproject. However, the performance of the tool is\nnot reported.\nMore recently, there has been an increasing\nnumber of resources created for the Kurdish\nlanguage, such as dictionaries (Ahmadi et al.,\n2019), domain-specific corpora (Abdulrahman\net al., 2019), folkloric corpus (Ahmadi et al.,\n2020a) and KurdNet–the Kurdish WordNet (Ali-\nabadi et al., 2014). However, parallel corpora are\nmore scarcely available. Bianet (Ataman, 2018) is\na parallel news corpus containing 6,486 English-\n1https://inkurdish.com\n2https://translatorswithoutborders.org\n3https://www.tarjim.ly\nKurmanji Kurdish and 7,390 Turkish-Kurmanji\nKurdish sentences.\nOpus4 also contains paral-\nlel translations in Kurmanji and Sorani for the\nGNOME and Ubuntu localization files5(Espla-\nGomis et al., 2019). More importantly, the Tanzil\ncorpus provides translation of Qoranic verses in\nSorani Kurdish.\nIn 2016, the translation service of Google, i.e.\nGoogle Translate6, added Kurmanji Kurdish to its\nlist of languages7. Motivated to explore this field\nfor Sorani Kurdish, in this paper, we focus on cre-\nating a neural machine translation system for So-\nrani.\n3\nSorani Kurdish\nSorani Kurdish is one of main dialects of Kurdish\nalong with Kurmanji Kurdish and Southern Kur-\ndish (Edmonds, 2013). This dialect is mainly spo-\nken by the Kurdish populations in the Kurdish re-\ngions of Iran and Iraq. Unlike Kurmanji dialect\nfor which a Latin-based script is used, Sorani Kur-\ndish is mostly written in the Arabic-based script of\nKurdish with no universally accepted orthography\nupon which scholars agree and is use by the public\n(Abdulrahman et al., 2019).\nKurdish has a subject-object-verb word order\nwith a system of tense-aspect-modality and per-\nson marking (Haig and Matras, 2002). Moreover,\nSorani Kurdish is a split-ergative language where\ntransitive verbs in the past tenses are marked with\nan agentive case different from the nominative\ncase (Manzini et al., 2015). The agentive case in\nKurmanji Kurdish is the oblique case while So-\nrani Kurdish only uses different pronominal encli-\ntics for ergative-absolutive alignment (Esmaili and\nSalavati, 2013). For further clarification, a few ex-\namples in Sorani Kurdish are provided below. In\nExample 1 in the past tense, the pronominal en-\nclitic =man (in red) is used as the agentive marker\nand the suffix in (in green) is used for patient mark-\ning. In contrast, in Example 3, the same patient\nmarker -in (in green) is used with a present tense\nas the subject marker with a nominative-accusative\nalignment and the pronominal enclitic =man (in\nred) is used in małman ‘our house’.\n4http://opus.nlpl.eu\n5https://l10n.gnome.org\n6https://translate.google.com\n7Shortly after our project in August 2020, the Microsoft\nTranslation service added Sorani and Kurmanji as well. See\nhttps://www.bing.com/translator\n(1)\ngułekanman hênan.\ngułekanman hênan\n/.گوڵەکانمان هێنان\n.\nguł=ek-an=man hêna-in\nflower.def.pl.1pl bring.pst.tr.erg.3sg\n‘we brought the flowers.’\n(2)\nhênamanin.\nhênamanin\n/.هێنامانن\n.\nhêna=man-in\nbring.pst.tr.erg.1pl.3sg\n‘we brought them.’\n(3)\ndeçine\ndeçin\nmałman.\ne\n/.دەچنە ماڵمان\nmałman.\nde-çi-in=e mał=man.\ngo-prs.prog.3pl=to house.n.1pl.\n‘(they) go/are going to our house.’\n(4)\neme gułêke.\neme gułêk e .\n/.ئەمە گوڵێکە\nem=e guł=êk e .\nthis.dem flower.ind is.3sg.cop.pres .\n‘this is a flower.’\nOn the placement of agent markers, unlike pa-\ntient markers, i.e. -in, which always appear im-\nmediately after the verb, the agentive markers fol-\nlow an erratic pattern where they tend to appear\nimmediately after the first prefix in verb forms,\ne.g. Example 2, or they attach to the leftmost mor-\npheme in verbal phrases, if present, as in Exam-\nple 1 (Walther, 2012; W. Smith, 2014). Moreover,\nSorani Kurdish morphology is known to be com-\nplex, particularly due to the variety of affixes, cli-\ntics and the pattern in which they appear within the\nword and the phrase (Ahmadi and Hassani, 2020).\nMoreover, the stringing property of the Arabic-\nbased script along with the lack of a unified or-\nthography creates further complexity in a way that\nmany word forms are concatenated into a single\none. This is particularly the case of copula when\nemerges as an enclitic, as shown in Example 4.\nThis yields further complications in the alignment\nof Kurdish and other languages.\nFigure 1 illustrates the alignment of the En-\nglish sentence ”this is a woman from Canada”\nwith its Sorani Kurdish translation eme jinêke le\nKanadawe. The alignment is carried out at var-\nious levels, namely word-level, token-level and\nmorpheme-level. This demonstrates how the gran-\nularity of the alignment varies depending on the\nlevel, ranging from a coarse-grained alignment at\nword-level where “is a woman” is aligned with\nonly one word jinêke, to a more fine-grained align-\nment at token-level.\nUltimately, at morpheme-\nlevel, circumposition le ... ewe and indefinite arti-\ncle -êk are alignable with their English equivalents,\n‘from’ and ‘a’, respectively. To facilitate the read-\ning, this example is provided in the Latin-based\nscript of Kurdish.\n4\nData Description\nGiven the scarcity of parallel corpora for Kurdish,\nwe used all the available parallel corpora, despite\ntheir limited topic coverage and size. In this sec-\ntion, we describe the data used for this study.\n4.1\nTanzil Corpus\nTanzil is a collection of Quran translations com-\npiled by the Tanzil project8. There is one trans-\nlation in Sorani Kurdish which is aligned with 11\ntranslations in English making a total number of\n92,354 parallel sentences with 3.15M words in the\nSorani Kurdish side and 2.36M words in the En-\nglish side. The corpus is available in Translation\nMemory Exchange (TMX) format where aligned\nverses are provided.\nIn the Kurdish translation, in addition to the\ntranslation of the verses, the interpretation of what\nis meant by the verse from the interpreter’s point of\nview is provided. In addition, the Kurdish transla-\ntion contains further idiomatic translations. These\nadd to the granularity of the translations in the\nKurdish side, while the translations in English are\nmore conservative of the literal meaning. The in-\nterpretational texts are mostly specified in paren-\ntheses which make it feasible to remove automati-\ncally.\nSome of the verses contain disjoined letters\nknown as Muqatta‘at. Although the English trans-\nlation provides only a phonetic transliteration of\nsuch disjoined letters, the Sorani Kurdish one\ncomes with chunks of text explaining the inter-\npretation of such verses. For instance, the verse\n” ّۤ”الۤمin Arabic, is translated as ”ALIF LAM MIM”\nin English, while the Kurdish verse contains ex-\nplanatory sentences.\nIn the same vein, compli-\nmentary phrases such as ”peace be upon him”\nare mentioned throughout the English text, mostly\nin parentheses, while in the Kurdish translation,\nthey are only partially specified from the actual\ncontent.\n8http://tanzil.net\neme jinêke le Kanadawe\nthis is a woman from Canada\n(a) alignment at word level\neme jinêk e le Kanadawe\nthis is a woman from Canada\n(b) alignment at token level\nem =e jin -êk e le Kanada =ewe\nthis\nis\na\nwoman\nfrom\nCanada\n(c) alignment at morpheme level\nFigure 1: Alignment of a Sorani Kurdish-English translation pair. The Latin-based script of Kurdish is used for\nfacilitating the reading\nOne particular challenge regarding this corpus\nis the inconsistencies in writing Kurdish in the\nArabic-based script. For instance, the conjunction\n”( ”وand) (written as ”û” in the Latin script), is fre-\nquently merged with the preceding word without\nconsidering the space between them. Moreover,\nthe usage of punctuation marks is not thoroughly\nrespected throughout the text. Due to the religious\ncontent of the data in Tanzil, there are many words\nwhich are written in Arabic in the Kurdish trans-\nlation, particularly proper names like ”( ”لوطLot)\nwhich should be written as ””لوتin the Kurdish\nscript.\n4.2\nTED Corpus\nThe TED corpus9 (Cettolo et al., 2012) is the col-\nlection of subtitles from TED Talks which are a\nseries of high quality talks on ”Technology, En-\ntertainment, and Design”. The Sorani Kurdish di-\nalect is the only Kurdish dialect for which these\nsubtitles are translated. Despite the small size of\n2358 parallel sentences, the TED collection con-\ntains translations in a wider range of topics in com-\nparison to Tanzil. Moreover, regarding the punc-\ntuation marks and orthography, this resource fol-\nlows a more consistent approach. Although the\nsentences are aligned between Sorani and English,\nthe alignments do not essentially correspond to a\nsentence. In some cases, a full paragraph contain-\ning many smaller phrases are aligned together. To\nfurther clarify this, Table 1 provides the average\n9https://wit3.fbk.eu\nnumber of tokens per line where the average num-\nber of characters in the TED corpus is thrice the\naverage of translations in Tanzil.\nCorpus\nLanguage\ntokens per line\ncharacters per line\nTanzil\nKurdish\n25.82\n159.36\nEnglish\n27.96\n134.72\nTed\nKurdish\n69.21\n441.93\nEnglish\n93.54\n452.88\nKurdNet\nKurdish\n7.51\n44.27\nEnglish\n8.51\n49.14\nTable 1: Average number of tokens and characters per\nline in the English and Kurdish data\n4.3\nKurdNet–the Kurdish WordNet\nWordNet (Miller, 1998) is a lexical-semantic re-\nsource which has been used in numerous natural\nlanguage processing tasks such as word sense dis-\nambiguation and information extraction. In addi-\ntion to semantic relationships such as synonymy,\nhyponymy, and meronymy, WordNet provides\nshort definitions and usage examples for groups\nof synonyms, also known as synsets. KurdNet–\nthe Kurdish WordNet (Aliabadi et al., 2014) is\ncreated based on a semi-automatic approach cen-\ntred around building a Kurdish alignment for Base\nConcepts, which is a core subset of major mean-\nings in WordNet. The current version of KurdNet\ncontains 4,663 definitions which are directly trans-\nlated from the Princeton WordNet (version 3.0).\nAlthough the number of the translated definitions\nis trivial for the task of machine translation, we in-\ncluded this resource as it contains more domain-\nspecific terms, for instance in biology or philoso-\nphy, and it also reflects a more modern usage of the\nlanguage in comparison to the religious content of\nTanzil corpus.\n5\nExperiment Settings\n5.1\nData Preparation\nIn order to remove non-relevant characters and\nclean the data, we unify the encoding of the char-\nacters by converting similar graphemes to unique\nones, as described in (Ahmadi, 2019). The Ara-\nbic script is adapted to many languages, including\nKurdish, where many graphemes may look alike\nbut have different encoding. For instance, despite\nthe similarity of ””كand ””يrespectively to ””ک\nand ”, ”یonly the latter ones are used in Kur-\ndish. Moreover, zero-width non-joiner character\n(U+200C) are removed and non-Kurdish characters\nused in proper names are replaced with the Kur-\ndish equivalents, e.g. ””طwith ”.”تWe also car-\nried out an orthographic normalization throughout\nall the corpora by replacing initial ”( ”رr) with ””ڕ\n(ř). Although the first one does not occur in Sorani\nKurdish, some orthographies suggest using it and\ntherefore, create variations in Sorani Kurdish texts.\nMoreover, interpretational texts provided between\nparentheses are removed.\nOn the English side of the data, the normaliza-\ntion step is consisted of removal of text within\nparentheses and truecasing. It should be noted that\nthe Arabic script does not have character case.\n5.2\nTokenization\nThe task of tokenization is of high importance\nin various tasks in NLP, particularly in machine\ntranslation (Domingo et al., 2018). In many lan-\nguages including Kurdish, spaces are used to deter-\nmine the boundary of tokens. However, due to the\nlack of a universal orthography and the complexity\nof Kurdish morphology, more than one token can\nsometimes be concatenated into one without any\nspace.\nAt the time of carrying out this research, no tok-\nenization tool was available for Kurdish language.\nTherefore, we trained three tokenization models\nusing the state-of-the-art unsupervised tokeniza-\ntion methods provided by HuggingFace Tokeniz-\ners 10 and SentencePiece11 (Wu et al., 2016). In\n10https://github.com/huggingface/tokenizers\n11https://github.com/google/sentencepiece\nthe first case, we used WordPiece which is a sub-\nword tokenization algorithm used for BERT lan-\nguage model (Devlin et al., 2018). In the latter, we\ntrained two models: byte-pair-encoding (BPE) and\nunigram language model (Unigram). All the mod-\nels are trained with the vocabulary_size=50000\nand character_coverage=1.0 using the avail-\nable Sorani Kurdish raw corpora, namely Pe-\nwan corpus containing 18M words (Esmaili et al.,\n2013), the Kurdish Textbooks Corpus (KTC)\ncontaining 693,800 words, (Abdulrahman et al.,\n2019), Veisi et al’s corpus containing 8.1M words\n(Veisi et al., 2020) and Sorani Kurdish folkloric\nlyrics corpus containing 49,582 words (Ahmadi\net al., 2020a). We preprocessed these corpora fol-\nlowing the text normalization step described ear-\nlier. Additionally, we used a regular expression\ntokenisation method based on the WordPunct tok-\nenizer of NLTK (Loper and Bird, 2002).\nTo remedy the systematic concatenation of con-\njunction ”( ”وand) in the Tanzil corpus, we carried\nout an additional step where the frequency of the\nwords ending with and without ”( ”وû) is calcu-\nlated in the Pewan corpus (Esmaili et al., 2013).\nIf the frequency of the word form without ””وis\nhigher than the word form with ”,”وwe consider\nthat the conjunction is meant and therefore we split\nthe word into two tokens. For instance, ””تاوانباروis\nan incorrect word composed of two words ””تاوانبار\n(guilty) and ”( ”وand). In Pewan, the original word\nhas a frequency of 5 against 1218 for ””تاوانبارin the\nsame corpus. Therefore, applying this step yields a\nspace between the two words and replaces them by\nthe initial incorrect word. Figure A.3 in Appendix\nA provides normalized example pairs in English\nand Kurdish and their changes after this step.\n5.3\nModels\nThe experiment was performed using py-Torch\nversion of OpenNMT (Klein et al., 2017), which\nis an open source library for training and deploy-\ning sequence to sequence NMT models. We de-\nployed two variations of model settings: Model 1\nand Model 2. The base model, Model 1, is set with\nthe following hyper-parameters: two LSTM (Long\nShort Term Memory) layers with 200 hidden units\nfor both the encoder and the decoder. The second\nmodel, Model 2, is the default OpenNMT model\nwith two hidden LSTM (Long Short Term Mem-\nory) layers and 500 hidden units per layer on both\nthe encoder and the decoder, batch size of 64, and\n0.3 dropout probability and word embeddings of\nTokenizer\nDataset\nNumber of sentences (tokens)\nAll\nTrain\nValidation\nTest 1\nTest 2\nBPE\nTanzil\n92325 (3335725)\n66476 (2406706)\n8308 (296874)\n8309 (297237)\n9232 (334908)\nTED\n2355 (253777)\n1697 (185258)\n212 (22324)\n211 (21879)\n235 (24316)\nKurdNet\n4659 (46384)\n3357 (33542)\n418 (4054)\n419 (4178)\n465 (4610)\nAll\n71532 (2625506)\n8940 (323252)\n8941 (323294)\n9932 (363834)\nUnigram\nTanzil\n92325 (3365517)\n66476 (2428059)\n8308 (299634)\n8309 (299765)\n9232 (338059)\nTED\n2355 (260015)\n1697 (189879\n212 (22860)\n211 (22377)\n235 (24899)\nKurdNet\n4659 (46336)\n3357 (33491)\n418 (4055)\n419 (4171)\n465 (4619)\nAll\n71532 (2651429)\n8940 (326549)\n8941 (326313)\n9932 (367577)\nWordPiece\nTanzil\n92325 (3348264)\n66476 (2415538)\n8308 (298174)\n8309 (298321)\n9232 (336231)\nTED\n2355 (247865)\n1697 (180822)\n212 (21773)\n211 (21615)\n235 (23655)\nKurdNet\n4659 (46228)\n3357 (33391)\n418 (4063)\n419 (4168)\n465 (4606)\nAll\n71532 (2629751)\n8940 (324010)\n8941 (324104)\n9932 (363742)\nWordPunct\nTanzil\n92325 (2909512)\n66476 (2098910)\n8308 (258926)\n8309 (259381)\n9232 (292295)\nTED\n2355 (250617)\n1697 (183596)\n212 (21886)\n211 (21353)\n235 (23782)\nKurdNet\n4659 (38950)\n3357 (28130)\n418 (3450)\n419 (3514)\n465 (3856)\nAll\n71532 (2310636)\n8940 (284262)\n8941 (284248)\n9932 (319933)\nTable 2: Number of sentences and tokens (in parentheses) of the Kurdish datasets based on various tokenization\nmodels and testing scenario\n100 dimension. Regarding the word embeddings,\nwe used the FastText pre-trained word vectors for\nKurdish (Mikolov et al., 2018) and GloVe word\nembeddings trained on 6B tokens for English (Pen-\nnington et al., 2014).\n5.4\nEvaluation\nThe performance of the models is evaluated using\nthe following three evaluation metrics; BLEU (Pa-\npineni et al., 2002), METEOR (Lavie and Agar-\nwal, 2007) and TER (Snover et al., 2006). BLEU\n(Bilingual Evaluation Understudy) is an evaluation\nmetric that matches n-grams from multiple metric\nfor evaluation of translation with explicit ordering,\nand METEOR (Metric for Evaluation of Transla-\ntion with Explicit ORdering) is based on the har-\nmonic mean of precision and recall. TER (Transla-\ntion Error Rate) is a metric that represents the cost\nof editing the output of the MT systems to match\nthe reference. High score of BLEU and METEOR\nmeans the system produces a highly fluent trans-\nlation, but a high score of TER is a sign of more\npost-editing effort and thus the lower the score the\nbetter.\n6\nResults and Analysis\nTo analyze the performance of the models and\nevaluate the impact of tokenization on the trans-\nlation quality, we create various datasets based\non the tokenization techniques, namely BPE, Uni-\ngram, WordPiece and WordPunct. As the Tanzil\ncorpus is remarkably larger, we create two sets\nof testing scenarios where initially 10% of each\ndataset is set aside as the first testing set (Test 2 in\nTable 2). This way, the performance of the model\nwith respect to each dataset can be evaluated sepa-\nrately as well. The remaining data are then merged\nall together and split into train, test and validation\nsets with 80%, 10% and 10% proportions respec-\ntively. The test set in the latter scenario is specified\nas Test 1 in Table 212.\n6.1\nQuantitative Analysis\nTable 3 presents the performance of our two neu-\nral translation models, Model 1 and Model 2, with\nrespect to the two test sets, Test 1 and Test 2, and\nvarious unsupervised neural tokenization models.\nRegarding Test 1, in both Kurdish to English and\nEnglish to Kurdish translations, the WordPunct to-\nkenization model has the highest results in BLEU\nand METEOR and the lowest with respect to TER.\nSurprisingly, Model 2 which is trained with better\nhyper-parameters, performs better only in English\nto Kurdish translation while Model 1 provides the\nbest results for Sorani and English translation.\nRegarding Test 2 where 10% of each parallel\ncorpus is used for testing purpose, our trained mod-\nels perform relatively good with respect to the\nTanzil corpus. However, all the setups fail to trans-\nlate KurdNet and TED corpora efficiently, in such\n12All the datasets are available at https://github.com/\nsinaahmadi/KurdishMT\nCorpus\nTokenization\nModel 1\nModel 2\nckb-en\nen-ckb\nckb-en\nen-ckb\nBLEU\nMETEOR\nTER\nBLEU\nMETEOR\nTER\nBLEU\nMETEOR\nTER\nBLEU\nMETEOR\nTER\nTest 2\nTanzil\nWordPiece\n21.02\n0.24\n0.61\n51.44\n0.3635\n0.32\n19.48\n0.231\n0.64\n50.48\n0.3616\n0.32\nUnigram\n20.71\n0.2381\n0.6\n50.21\n0.3582\n0.32\n19.53\n0.232\n0.63\n50.95\n0.3613\n0.32\nWordPunct\n22.03\n0.2454\n0.58\n58.36\n0.412\n0.27\n20.42\n0.2384\n0.61\n59.28\n0.4156\n0.27\nBPE\n21.03\n0.2392\n0.61\n50.04\n0.3588\n0.32\n19.49\n0.2315\n0.63\n50.28\n0.358\n0.33\nKurdNet\nWordPiece\n5.86\n0.1245\n0.93\n3.9\n0.091\n0.99\n6.47\n0.1297\n0.9\n3.25\n0.0904\n1.01\nUnigram\n5.88\n0.1216\n0.91\n3.38\n0.0884\n1\n6.15\n0.1269\n0.89\n3.82\n0.0923\n1\nWordPunct\n5.81\n0.1169\n0.9\n2.57\n0.082\n1\n5.16\n0.1242\n0.9\n2.82\n0.0867\n1\nBPE\n6.32\n0.1209\n0.92\n3.5\n0.0853\n1\n6.39\n0.133\n0.9\n3.05\n0.0826\n0.99\nTED\nWordPiece\n1\n0.0875\n0.9\n0\n0.0378\n0.99\n0.74\n0.0758\n0.9\n0.05\n0.0383\n0.99\nUnigram\n0.88\n0.0775\n0.91\n0\n0.0415\n0.97\n0.89\n0.0863\n0.89\n0\n0.0397\n0.99\nWordPunct\n0.62\n0.072\n0.89\n0\n0.0295\n1\n0.59\n0.0712\n0.9\n0\n0.0289\n0.99\nBPE\n0.92\n0.0853\n0.91\n0\n0.0353\n0.99\n0.75\n0.0803\n0.9\n0\n0.0298\n0.99\nTest 1\nWordPiece\n19.05\n0.2242\n0.65\n46.47\n0.3322\n0.37\n17.49\n0.2153\n0.67\n45.23\n0.328\n0.38\nUnigram\n18.95\n0.2235\n0.63\n45.24\n0.3275\n0.38\n17.47\n0.2156\n0.66\n45.83\n0.3299\n0.38\nWordPunct\n19.95\n0.2276\n0.61\n52.21\n0.3726\n0.33\n18.5\n0.2222\n0.65\n52.94\n0.3753\n0.33\nBPE\n19.06\n0.2233\n0.63\n45.13\n0.3282\n0.38\n17.51\n0.2157\n0.66\n45.14\n0.3269\n0.38\nTable 3: Quantitative results for the evaluation of Kurdish ↔English using various test sets. Results in bold\nrepresent the best system within the given models\na way that the TER score is 1 in almost all cases.\nWe believe that such a mediocre performance is\ndue to (a) imbalance of the data, as most of the par-\nallel sentences are provided from the Tanzil cor-\npus, (b) type of sentences in KurdNet and the qual-\nity of alignments in TED (see Table 1), and (c)\ndomain-specific terms which are used in the Kurd-\nNet and TED corpora while more generic words\nare used in the Tanzil corpus. In comparison to the\nTanzil and TED corpora, WordNet definitions are\nsignificantly short. Moreover, synsets definitions\nare more objective and contain technical words.\nIn other words, words which are more frequently\nused in subjective texts, such as pronouns, are less\nobserved in this resource.\nTo further clarify the poor results of TED which\nparticularly has a large number of tokens per sen-\ntence, we carried out a set of experiments by fil-\ntering sentences based on their number of tokens.\nFor this purpose, we created four smaller datasets\nbased on the TED test sets (Test 2) containing a\nmaximum number of 25, 50, 75 and above 75 to-\nkens and evaluated the performance of the models\nusing various n-grams for the BLEU score. Figure\n2 demonstrates how a lower number of tokens per\nsentence improves the BLEU score significantly.\nThat said, the overall performance of the models\nis still not satisfying, with the best model\nIn all the testing scenarios, the English-Kurdish\nmodels significantly outperform the Kurdish-\nEnglish translation. This is explainable as there is\nonly one translation available for Kurdish in Tanzil\nbut 11 translations for English. In other word, a\nsentence in Kurdish is aligned with 11 different\nsentences in English.\n6.2\nQualitative Analysis\nFigures A.4 and A.5 illustrate a few translations\nin our parallel corpora along with their back-\ntranslation. Despite the poor performance of the\nmodels with respect to TED and KurdNet, the sys-\ntem translations often carry meaning in a compre-\nhensible way.\nIn other words, even if the sys-\ntem translations do not correspond to the reference\nones, they are not completely nonsensical, depend-\ning on the tokenization method.\nInterestingly, some of the system translations\nare correct, even if the reference translations were\nnot originally correctly-written. This is particu-\nlarly the case of the Tanzil corpus. For instance,\n“you are a people unknown to me” in Figure A.4,\nis correctly translated in Kurdish while the Kur-\ndish translation is written without any space in\nboth the system output and the reference trans-\nlation.\nIn the same vein, we observe that the\ntrained models capture information regarding syn-\nonyms or semantically-related words.\nFor in-\nstance, ‘knowledge’ is translated as( زانستzanist)\n‘science’ in a reference translation, whileزانیاری\n(zanyarî) ‘knowledge’ is used for the same word\nby our models.\n7\nConclusion and Future Work\nIn this paper, we present our efforts to develop\na neural machine translation system for the So-\nrani dialect of Kurdish. We describe how due to\nscarcity of parallel corpora, we used translations\nof religious texts as the material for training a ma-\nchine translation system. Moreover, we created\nbasic language processing tools, such as tokeniza-\nFigure 2: The performance of Model 1 in translating Kurdish to English with respect to certain length-limited\nsentences in the Kurdish TED corpus in terms of various BLEU scores\ntion, by using unsupervised techniques, namely\nWordPiece, byte-pair-encoding and unigram lan-\nguage model. We train two neural machine transla-\ntion models using different hyper-parameters and\nevaluate the models based on the datasets and the\ntokenization techniques. Although the imbalanced\ndata makes the models over-fit, our qualitative\nanalysis indicates that some syntactic and lexical\nproperties of Kurdish are correctly learnt in the\ntranslation outputs.\nThere are two major limitations in the current\nproject which could not be addressed due to our\nfocus being on the preprocessing steps: a base-\nline system and further experiments with respect\nto hyper-parameters.\nGiven the current state of\nlack of parallel corpora, we were not able to extend\nthe study the other dialects. We strongly believe\nthat this should be a motivation to create more re-\nsources for the Kurdish language13. Moreover, as\nan initial work of its kind for the machine trans-\nlation of Kurdish, we dealt with many basic lan-\nguage processing tasks which were not properly\naddressed. Developing such tools should be a pri-\nority in the field of Kurdish language processing.\nRegarding future work, we would like to sug-\ngest morpheme-based translation (Luong et al.,\n2019). As Kurdish is a morphologically-rich lan-\n13Shortly after this project, Ahmadi et al. (2020b) present\na parallel corpus created based on multilingual news websites\ncontent.\nguage, it might be beneficial to go beyond tokens\nand carry out the alignment task at morpheme-\nlevel. We also believe that lexicons can be effi-\nciently incorporated for compensating the scarcity\nof resources for Kurdish (Zhang and Zong, 2016).\nWe also propose the usage of other dialects of\nKurdish, such as Kurmanji, and closely-related\nlanguages, like Persian, for improving the per-\nformance of future machine translation models\n(Nakov and Tiedemann, 2012).\nAnother recent\npromising direction for a low-resource setup like\nKurdish is monolingual sequence-to-sequence pre-\ntraining techniques, such as MAsked Sequence to\nSequence pre-training (MASS) (Song et al., 2019)\nor mBART (Liu et al., 2020).\n8\nAcknowledgements\nThe authors would like to thank Dr. Diego Mous-\nsallem for his collaboration at the initial stages of\nthis work.\nReferences\nRoshna Omer Abdulrahman, Hossein Hassani, and\nSina Ahmadi. 2019.\nDeveloping a Fine-Grained\nCorpus for a Less-resourced Language: the case of\nKurdish. arXiv preprint arXiv:1909.11467.\nSina Ahmadi. 2019. A rule-based Kurdish text translit-\neration system. Asian and Low-Resource Language\nInformation Processing (TALLIP), 18(2):18:1–18:8.\nSina Ahmadi and Hossein Hassani. 2020.\nTowards\nFinite-State Morphology of Kurdish. arXiv preprint\narXiv:2005.10652.\nSina Ahmadi,\nHossein Hassani,\nand Kamaladdin\nAbedi. 2020a. A Corpus of the Sorani Kurdish Folk-\nloric Lyrics. In Proceedings of the 1st Joint Spoken\nLanguage Technologies for Under-resourced lan-\nguages (SLTU) and Collaboration and Computing\nfor Under-Resourced Languages (CCURL) Work-\nshop at the 12th International Conference on Lan-\nguage Resources and Evaluation (LREC), Marseille,\nFrance.\nSina Ahmadi, Hossein Hassani, and Daban Q Jaff.\n2020b. Leveraging Multilingual News Websites for\nBuilding a Kurdish Parallel Corpus. arXiv preprint\narXiv:2010.01554.\nSina Ahmadi, Hossein Hassani, and John P. McCrae.\n2019. Towards electronic lexicography for the Kur-\ndish language. In Proceedings of the sixth biennial\nconference on electronic lexicography (eLex), pages\n881–906, Sintra, Portugal.\nPurya Aliabadi, Mohammad Sina Ahmadi, Shahin\nSalavati, and Kyumars Sheykh Esmaili. 2014. To-\nwards building kurdnet, the kurdish wordnet. In Pro-\nceedings of the Seventh Global Wordnet Conference,\npages 1–6.\nDuygu Ataman. 2018.\nBianet: A parallel news cor-\npus in turkish, kurdish and english. arXiv preprint\narXiv:1805.05095.\nHalil İbrahim Balkul. 2018.\nA Comparative Analy-\nsis Of Translation/interpreting Tools Developed For\nSyrian Refugee Crisis. International Journal of Lan-\nguage Academy.\nMauro Cettolo, Christian Girardi, and Marcello Fed-\nerico. 2012. Wit3: Web inventory of transcribed and\ntranslated talks. In Conference of european associa-\ntion for machine translation, pages 261–268.\nChristopher Cieri, Mike Maxwell, Stephanie Strassel,\nand Jennifer Tracey. 2016.\nSelection criteria for\nlow resource language programs.\nIn Proceedings\nof the Tenth International Conference on Language\nResources and Evaluation (LREC’16), pages 4543–\n4549.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nMiguel Domingo, Mercedes Garcıa-Martınez, Alexan-\ndre Helle, Francisco Casacuberta, and Manuel Her-\nranz. 2018.\nHow much does tokenization af-\nfect neural machine translation?\narXiv preprint\narXiv:1812.08621.\nAlexander Johannes Edmonds. 2013. The Dialects of\nKurdish. Ruprecht-Karls-Universität Heidelberg.\nKyumars Sheykh Esmaili, Donya Eliassi, Shahin\nSalavati, Purya Aliabadi, Asrin Mohammadi, So-\nmayeh Yosefi, and Shownem Hakimi. 2013. Build-\ning a test collection for sorani kurdish. In 2013 ACS\nInternational Conference on Computer Systems and\nApplications (AICCSA), pages 1–7. IEEE.\nKyumars Sheykh Esmaili and Shahin Salavati. 2013.\nSorani Kurdish versus Kurmanji Kurdish: an empir-\nical comparison. In Proceedings of the 51st Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 2: Short Papers), pages 300–305.\nCo-authors\nMiquel\nEspla-Gomis,\nJuan\nAntonio\nPérez-Ortiz, Vıctor M Sánchez-Cartagena, Felipe\nSánchez-Martınez, and Reviewers Alexandra Birch.\n2019. Global Under-Resourced MEdia Translation\n(GoURMET).\nH2020 Research and Innovation\nActionNumber: 825299 - D1.1 – Survey of relevant\nlow-resource languages.\nMikel L Forcada, Mireia Ginestí-Rosell, Jacob Nord-\nfalk, Jim O’Regan, Sergio Ortiz-Rojas, Juan An-\ntonio Pérez-Ortiz, Felipe Sánchez-Martínez, Gema\nRamírez-Sánchez, and Francis M Tyers. 2011. Aper-\ntium: a free/open-source platform for rule-based ma-\nchine translation. Machine translation, 25(2):127–\n144.\nGeoffrey Haig and Yaron Matras. 2002. Kurdish lin-\nguistics: a brief overview. STUF-Language Typol-\nogy and Universals, 55(1):3–14.\nKanaan M Kaka-Khan. 2018. English to Kurdish Rule-\nbased Machine Translation System. UHD Journal of\nScience and Technology.\nGuillaume Klein, Yoon Kim, Yuntian Deng, Jean\nSenellart, and Alexander M Rush. 2017. Opennmt:\nOpen-source toolkit for neural machine translation.\nIn Proceedings of ACL 2017, System Demonstra-\ntions, pages 67–72.\nPhilipp Koehn. 2009. Statistical machine translation.\nCambridge University Press.\nPhilipp Koehn. 2020.\nNeural machine translation.\nCambridge University Press.\nPhilipp Koehn and Rebecca Knowles. 2017. Six chal-\nlenges for neural machine translation. In Proceed-\nings of the First Workshop on Neural Machine Trans-\nlation, pages 28–39.\nAlon Lavie and Abhaya Agarwal. 2007. METEOR: An\nautomatic metric for MT evaluation with high levels\nof correlation with human judgments. In Proceed-\nings of the second workshop on statistical machine\ntranslation, pages 228–231.\nYinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey\nEdunov, Marjan Ghazvininejad, Mike Lewis, and\nLuke Zettlemoyer. 2020.\nMultilingual Denoising\nPre-training for Neural Machine Translation.\nEdward Loper and Steven Bird. 2002. Nltk: the natural\nlanguage toolkit. arXiv preprint cs/0205028.\nMinh-Thang Luong, Preslav Nakov, and Min-Yen Kan.\n2019.\nA hybrid morpheme-word representation\nfor machine translation of morphologically rich lan-\nguages. arXiv preprint arXiv:1911.08117.\nM. Rita Manzini, Leonardo M. Savoia, and Ludovico\nFranco. 2015.\nErgative case, aspect and person\nsplits: Two case studies. Acta Linguistica Hungar-\nica Acta Linguistica Hungarica, 62(3):297 – 351.\nChenggang Mi, Lei Xie, and Yanning Zhang. 2020. Im-\nproving adversarial neural machine translation for\nmorphologically rich language. IEEE Transactions\non Emerging Topics in Computational Intelligence.\nTomas Mikolov, Edouard Grave, Piotr Bojanowski,\nChristian Puhrsch, and Armand Joulin. 2018. Ad-\nvances in Pre-Training Distributed Word Represen-\ntations. In Proceedings of the International Confer-\nence on Language Resources and Evaluation (LREC\n2018).\nGeorge A Miller. 1998. WordNet: An electronic lexical\ndatabase. MIT press.\nPreslav Nakov and Jörg Tiedemann. 2012. Combin-\ning word-level and character-level models for ma-\nchine translation between closely-related languages.\nIn Proceedings of the 50th Annual Meeting of the\nAssociation for Computational Linguistics: Short\nPapers-Volume 2, pages 301–305. Association for\nComputational Linguistics.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation.\nIn Proceedings of\nthe 40th annual meeting on association for compu-\ntational linguistics, pages 311–318. Association for\nComputational Linguistics.\nPeyman Passban. 2017. Machine translation of mor-\nphologically rich languages using deep neural net-\nworks. Ph.D. thesis, Dublin City University.\nJeffrey Pennington, Richard Socher, and Christopher D\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In Proceedings of the 2014 conference\non empirical methods in natural language process-\ning (EMNLP), pages 1532–1543.\nMatthew Snover, Bonnie Dorr, Richard Schwartz, Lin-\nnea Micciulla, and John Makhoul. 2006. A study of\ntranslation edit rate with targeted human annotation.\nIn Proceedings of association for machine transla-\ntion in the Americas, volume 200. Cambridge, MA.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-\nYan Liu. 2019.\nMASS: Masked Sequence to Se-\nquence Pre-training for Language Generation.\nFatima Jalal Taher et al. 2017. Evaluation of inkurdish\nMachine Translation System. Journal of University\nof Human Development, 3(2):862–868.\nJörg Tiedemann. 2012. Parallel data, tools and inter-\nfaces in opus. In Proceedings of the Eight Interna-\ntional Conference on Language Resources and Eval-\nuation (LREC’12), Istanbul, Turkey. European Lan-\nguage Resources Association (ELRA).\nSneha Tripathi and Juran Krishna Sarkhel. 2010. Ap-\nproaches to machine translation. Annals of Library\nand Information Studies, 57:388–393.\nHadi Veisi, Mohammad MohammadAmini, and Hawre\nHosseini. 2020. Toward Kurdish language process-\ning: Experiments in collecting and processing the\nAsoSoft text corpus. Digital Scholarship in the Hu-\nmanities, 35(1):176–193.\nPeter\nW.\nSmith.\n2014.\nNon-peripheral\ncliti-\ncization and second position in Udi and So-\nrani Kurdish.\nIn Paper under revision at\nNatural\nLanguage\nand\nLinguistic\nTheory,\nhttps://user.uni-frankfurt.de/~psmith/\ndocs/smith_non_peripheral_cliticization.pdf\nedition. (Date accessed: 12.05.2020).\nGéraldine Walther. 2012.\nFitting into morphological\nstructure: accounting for Sorani Kurdish endoclitics.\nIn Mediterranean Morphology Meetings, volume 8,\npages 299–321. [Online; accessed 19-Mar-2019].\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V\nLe,\nMohammad Norouzi,\nWolfgang Macherey,\nMaxim Krikun,\nYuan Cao,\nQin Gao,\nKlaus\nMacherey, et al. 2016.\nGoogle’s neural machine\ntranslation system:\nBridging the gap between\nhuman and machine translation.\narXiv preprint\narXiv:1609.08144.\nJiajun Zhang and Chengqing Zong. 2016.\nBridging\nneural machine translation and bilingual dictionar-\nies. arXiv preprint arXiv:1610.07272.\nA\nAppendix\nTED Corpus\nen\nSo that instead of spending it the way you usually spend it, maybe if you spent it differently, that \nmight work a little bit better. \nckb\n ﮐەواﺗە ﺋەﮔەر ﻟە ﺑﺮی ﺋەوەی ﺑەو ﺷێﻮازەی ﺋێﺴﺘﺎت ﭘﺎرەﮐە ﺧەرج ﺑﮑەﯾﺖ ڕەﻧﮕە ﺋەﮔەر ﺑە ﺷێﻮەﯾەﮐﯽ ﺗﺮ ﺧەرﺟﯽ ﺑﮑەﯾﺖ ڕەﻧﮕە ﺗۆزێﮏ\n .ﺑﺎﺷﺘﺮ ﺑێﺖ\nckb norm.\n ﮐەواﺗە ﺋەﮔەر ﻟە ﺑﺮی ﺋەوەی ﺑەو ﺷێﻮازەی ﺋێﺴﺘﺎت ﭘﺎرەﮐە ﺧەرج ﺑﮑەﯾﺖ ڕەﻧﮕە ﺋەﮔەر ﺑە ﺷێﻮەﯾەﮐﯽ ﺗﺮ ﺧەرﺟﯽ ﺑﮑەﯾﺖ ڕەﻧﮕە ﺗۆزێﮏ\n. ﺑﺎﺷﺘﺮ ﺑێﺖ\nckb norm. \n(WordPunct)\n ﮐەواﺗە ﺋەﮔەر ﻟە ﺑﺮی ﺋەوەی ﺑەو ﺷێﻮازەی ﺋێﺴﺘﺎ ت ﭘﺎرەﮐە ﺧەرج ﺑﮑەﯾﺖ ڕ ەﻧﮕە ﺋەﮔەر ﺑە ﺷێﻮەﯾەﮐﯽ ﺗﺮ ﺧەرﺟﯽ ﺑﮑەﯾﺖ ڕەﻧﮕە ﺗۆزێﮏ\n. ﺑﺎﺷﺘﺮ ﺑێﺖ\nckb norm. \n(Unigram)\n ﮐەواﺗە ﺋەﮔەر ﻟە ﺑﺮی ﺋەوەی ﺑەو ﺷێﻮازەی ﺋێﺴﺘﺎ ت ﭘﺎرەﮐە ﺧەرج ﺑﮑەﯾﺖ ڕە ﻧﮕە ﺋەﮔەر ﺑە ﺷێﻮەﯾەﮐﯽ ﺗﺮ ﺧەرﺟﯽ ﺑﮑەﯾﺖ ڕە ﻧﮕە ﺗۆزێﮏ\n. ﺑﺎﺷﺘﺮ ﺑێﺖ\nckb norm. \n(BPE)\n ﮐەواﺗە ﺋەﮔەر ﻟە ﺑﺮی ﺋەوەی ﺑەو ﺷێﻮازەی ﺋێﺴﺖ ات ﭘﺎرەﮐە ﺧەرج ﺑﮑەﯾﺖ ڕ ەﻧﮕە ﺋەﮔەر ﺑە ﺷێﻮەﯾەﮐﯽ ﺗﺮ ﺧەرﺟﯽ ﺑﮑەﯾﺖ ڕ ەﻧﮕە ﺗۆزێﮏ\n. ﺑﺎﺷﺘﺮ ﺑێﺖ\nKurdNet\nen\nmake less lively, intense, or vigorous; impair in vigor, force, activity, or sensation\nckbﮐەﻣﺘﺮ ﮐﺮدﻧەوەی وﺷﯿﺎری، زﯾﻨﺪوواﯾەﺗﯽ ﯾﺎن ﻫێﺰ؛ ﻧﺎﮐۆﮐﯽ ﻟە ﺑڕﺳﺖ، ﻫێﺰ، ﺑەﮐﺎرﺑﻮون ﯾﺎن ﻫەﺳﺘﯿﺎری\nckb norm.ﮐەﻣﺘﺮ ﮐﺮدﻧەوەی وﺷﯿﺎری، زﯾﻨﺪوواﯾەﺗﯽ ﯾﺎن ﻫێﺰ؛ ﻧﺎﮐۆﮐﯽ ﻟە ﺑڕﺳﺖ، ﻫێﺰ، ﺑەﮐﺎرﺑﻮون ﯾﺎن ﻫەﺳﺘﯿﺎری\nckb norm. \n(WordPunct)\nﮐەﻣﺘﺮ ﮐﺮدﻧەوەی وﺷﯿﺎری ، زﯾﻨﺪوواﯾەﺗﯽ ﯾﺎن ﻫێﺰ ؛ ﻧﺎﮐۆﮐﯽ ﻟە ﺑڕﺳﺖ ، ﻫێﺰ ، ﺑەﮐﺎرﺑﻮون ﯾﺎن ﻫەﺳﺘﯿﺎری\nckb norm. \n(Unigram)\nﮐەﻣﺘﺮ ﮐﺮدﻧەوەی وﺷﯿﺎری ، زﯾﻨﺪوو اﯾەﺗﯽ ﯾﺎن ﻫێﺰ ؛ ﻧﺎﮐۆﮐﯽ ﻟە ﺑڕ ﺳﺖ ، ﻫێﺰ ، ﺑەﮐﺎر ﺑﻮون ﯾﺎن ﻫەﺳﺘﯿﺎری\nckb norm. \n(BPE)\nﮐەﻣﺘﺮ ﮐﺮدﻧەوەی وﺷﯿﺎری ، زﯾﻨﺪوو اﯾەﺗﯽ ﯾﺎن ﻫێﺰ ؛ ﻧﺎﮐۆﮐﯽ ﻟە ﺑڕ ﺳﺖ ، ﻫێﺰ ، ﺑەﮐﺎر ﺑﻮون ﯾﺎن ﻫەﺳﺘﯿﺎری\nckb norm. \n(WordPiece)\nﮐەﻣﺘﺮ ﮐﺮدﻧەوەی وﺷﯿﺎری ، زﯾﻨﺪوو اﯾەﺗﯽ ﯾﺎن ﻫێﺰ ؛ ﻧﺎﮐۆﮐﯽ ﻟە ﺑڕ ﺳﺖ ، ﻫێﺰ ، ﺑەﮐﺎرب وون ﯾﺎن ﻫەﺳﺘﯿﺎری\nTanzil Corpus\nen\nThey are the patient, the sincere and devout, full of charity, who pray for forgiveness in the \nhours of dawn.\nckb\n ڕاﺳﺘﮕۆو ،(ﺧۆﮔﺮو ﺋﺎراﻣﮕﺮن )ﻟﻪ ﺑەراﻣﺒەر ﻧﺎﺳۆر و ﻧﺎﺧۆﺷﯿەﮐﺎﻧﯽ ژﯾﺎﻧەوە ()ﺟﺎ ﺋەو ﺋﯿﻤﺎﻧﺪاراﻧە، ﺋەﻣﻪ ﺳﯿﻔەﺗﯿﺎﻧە\n ﺧﻮاﭘەرﺳﺘﻦ، ﻣﺎڵ و ﺳﺎﻣﺎن دەﺑەﺧﺸﻦ و، ﻟﻪ ﺑەرەﺑەﯾﺎﻧەﮐﺎﻧﺪا داوای ﻟێﺨۆﺷﺒﻮون دەﮐەن )ﻟﻪ ﭘەروەردﮔﺎرﯾﺎن ﭼﻮﻧﮑﻪ واﻫەﺳﺖ\n.(دەﮐەن ﮐﻪ وەک ﭘێﻮﯾﺴﺖ ﺧﻮاﭘەرﺳﺘﯿﺎن ﻧەﮐﺮدووە\nckb norm.ﺧۆﮔﺮ و ﺋﺎراﻣﮕﺮن، ڕاﺳﺘﮕۆ و ﺧﻮاﭘەرﺳﺘﻦ، ﻣﺎڵ و ﺳﺎﻣﺎن دەﺑەﺧﺸﻦ و، ﻟﻪ ﺑەرەﺑەﯾﺎﻧەﮐﺎﻧﺪا داوای ﻟێﺨۆﺷﺒﻮون دەﮐەن\nckb norm. \n(WordPunct)\n ﺧۆﮔﺮ و ﺋﺎراﻣﮕﺮن ، ڕاﺳﺘﮕۆ و ﺧﻮاﭘەرﺳﺘﻦ ، ﻣﺎڵ و ﺳﺎﻣﺎن دەﺑەﺧﺸﻦ و ، ﻟە ﺑەرەﺑەﯾﺎﻧەﮐﺎﻧﺪا داوای ﻟێﺨۆﺷﺒﻮون دەﮐەن\nckb norm. \n(Unigram)\nﺧۆﮔﺮ و ﺋﺎراﻣﮕﺮ ن ، ڕاﺳﺘﮕۆ و ﺧﻮاﭘەرﺳﺖ ن ، ﻣﺎڵ و ﺳﺎﻣﺎن دەﺑەﺧﺸﻦ و ، ﻟە ﺑەرەﺑەﯾﺎن ەﮐﺎﻧﺪا داوای ﻟێﺨۆﺷﺒﻮون دەﮐەن\nckb norm. \n(BPE)\nﺧۆﮔﺮ و ﺋﺎرام ﮔﺮن ، ڕاﺳﺘﮕۆ و ﺧﻮا ﭘەرﺳﺘﻦ ، ﻣﺎڵ و ﺳﺎﻣﺎن دەﺑەﺧﺸﻦ و ، ﻟە ﺑەرەﺑەﯾﺎن ەﮐﺎﻧﺪا داوای ﻟێﺨۆﺷﺒﻮون دەﮐەن\nckb norm. \n(WordPiece)\nﺧۆﮔﺮ و ﺋﺎراﻣﮕﺮ ن ، ڕاﺳﺘﮕۆ و ﺧﻮا ﭘەرﺳﺘﻦ ، ﻣﺎڵ و ﺳﺎﻣﺎن دەﺑەﺧﺸﻦ و ، ﻟە ﺑەرەﺑەﯾﺎن ەﮐﺎﻧﺪا داوای ﻟێﺨۆﺷﺒﻮون دەﮐەن\nFigure A.3: The tokenization of parallel translations of English (en) and Sorani Kurdish (ckb) in the Tanzil, TED\nand KurdNet–the Kurdish Wordnet. The incorrectly-merged words are indicated in bold and are corrected in the\nnormalized (norm.) step. Tokenization models are specified in parentheses\nInput (Tanzil)\nwhen they came in to him , and said ,  salam !  he answered ;  salam ,  and said :  you are a people unknown to me .\nReference\n. ﮐﺎﺗێﮏ ﮐﺘﻮﭘﺮ ﺧۆﯾﺎن ﮐﺮد ﺑە ﻣﺎڵﺪا و وﺗﯿﺎن : ﺳڵﺎو ، ﺋەوﯾﺶ وﺗﯽ ، ﺳڵﺎو ﻟەﺋێﻮەش ﺑێﺖ ، ﻫەرﭼەﻧﺪەﻧﺎﺗﺎﻧﻨﺎﺳﻢ\nSystem translation\n. ﮐﺎﺗێﮏ ﭼﻮون ﺑۆ ﺳەرداﻧﯽ و وﺗﯿﺎن : ﺳڵﺎو ، ﺋەوﯾﺶ وﺗﯽ ، ﺳڵﺎو ﻟەﺋێﻮەش ﺑێﺖ ، ﻫەرﭼەﻧﺪەﻧﺎﺗﺎﻧﻨﺎﺳﻢ\nBack-translation\nwhen (they) went to visit him/her and said : hi , then (he) said, hi to you too, although(I)donotknowyou  .\nInput (TED)\nall the knowledge and values shared by a society\nReferenceﺗەواوی زاﻧﺴﺖ و ﺑەﻫﺎﯾﺎﻧەی ﮐە ﮐۆﻣەڵ ﺗێﺪا ﻫﺎوﺑەﺷﻦ\nSystem translation\n. ﻫەر زاﻧﯿﺎری و ﺋﺎﻣێﺮێﮑﯽ ﺗەواو ﺑﻮون\nBack-translation\nall the knowledge and a tool of ﬁnishing . \nInput (KurdNet)\na structure consisting of a room or set of rooms comprising a single level of a multilevel building\nReferenceﭘێﮑﻬﺎﺗەﯾەک ﮐە ﻟە ژوورێﮏ ﯾﺎن ﭼەﻧﺪ ژوور درووﺳﺖ ﺑﻮوە و ﻟە ﺳەر ﻧﻬۆﻣێﮑﯽ ﺑﯿﻨﺎێﮑﯽ ﭼەﻧﺪ ﻧﻬۆﻣﯿە\nSystem translationﭘێﮑﻬﺎﺗەﯾەک ﮐە ﻟە زﻧﺠﯿﺮەﯾەک ﯾﺎن ﻟە دﯾﻮارێ ﻫﺎﺗۆﺗە دەرێ ﮐە ﻟە ﺋﺎﺳﺘێﮑﯽ ﮔەورەﺗﺮداﯾە\nBack-translation\na structure that has come out from a chain/a set or a wall that is within a bigger level\nFigure A.4: A few translation examples from English to Sorani Kurdish using the model with the highest BLEU\nscores (Model 2, WordPunct)\nInput (Tanzil)\n. ﺷەراﺑێﮑﯿﺎن ﭘێﺸﮑەش دەﮐﺮێﺖ ، ﮐە ﭘﺎک و ﺳەرﻣۆرە\nReference\nthey will be given to drink a sealed wine . \nSystem translation\nthey will be given to drink of pure wine , sealed .\nBack-translation\n. ﺷەراﺑێﮑﯽ ﺧﺎوێﻨﯿﺎن ﭘێﺸﮑەش دەﮐﺮێﺖ، ﺳەرﻣۆر\nInput (TED)\n دەزاﻧﯿﺖ ﭘێﻮﯾﺴﺘﺖ ﺑە ﭼﯿﯿە ﺋەﻧﺠﺎﻣﯽ ﺑﺪەﯾﺖ ﭼﯽ ﻣﻮﻣﮑﯿﻨە ﺑﮑﺮێﺖ ، ﻫەرﭼەﻧﺪە ﺳەﺧﺘﯿﺶ ﺑێﺖ و ﻫەﺳﺖ دەﮐەﯾﺖ ﮐﺎت دﯾﺎر ﻧﺎﻣێﻨێﺖ ، ﺧۆﺗﺖ ﺑﯿﺮ\n. دەﭼێﺘەوە ﻫەﺳﺖ دەﮐەﯾﺖ ﺑەﺷێﮑﯿﺖ ﻟە ﺷﺘێﮑﯽ ﮔەورەﺗﺮ و ﮐﺎﺗێ ﻣەرﺟەﮐﺎن ﺋﺎﻣﺎدە ﺑﻦ ﺋەو ﮐﺎرەی دەﯾﮑەﯾﺖ ﺧۆی ﻟە ﺧۆﯾﺪا دەﺑێﺘە ﺷﺎﯾﺴﺘەی ﺋەﻧﺠﺎﻣﺪان\nReference\nyou know that what you need to do is possible to do , even though difﬁcult , and sense of time disappears , you \nforget yourself , you feel part of something larger . and once the conditions are present , what you are doing \nbecomes worth doing for its own sake .\nSystem translation\nand to show what is said , if you are going to speak , even though you are , even though you are , in fact , a matter \nis decided , and you will be a leader .\nBack-translation\n و ﺑۆ ﻧﯿﺸﺎن داﻧﯽ ﺋەوﺷﺘەی ﮔﻮﺗﺮاوە ، ﺋەﮔەر دەﺗﻬەوێ ﻗﺴە ﺑﮑەی ، ﺗەﻧﺎﻧەت ﺋەﮔەر ﻗﺴەش دەﮐەی ، ﺗەﻧﺎﻧەت ﺋەﮔەر ﻗﺴەش دەﮐەی ، ﻟە ڕاﺳﺘﯿﺪا ، ﺑﺎﺑەﺗێﮏ\n. ﺑڕﯾﺎر دراوە ، و ﺗۆ دەﺑﯽ ﺑە ڕاﺑەرێﮏ\nInput (KurdNet)ﻧﺎڕەزاﯾﯽ دەرﺑڕﯾﻨﯽ ﮐﺎرﯾﮕەران ﯾﺎن ﮐۆﻣەﻻﻧﯽ ﮐەﻣﯿﻨە ﺑۆ وە دەﺳﺖ ﺧﺴﺘﻨﯽ داﺧﻮازﯾەﮐﺎﻧﯿﺎن\nReference\na protest action by labor or minority groups to obtain their demands\nSystem translation\nthe act of expressing a word or phrase or argument for\nBack-translationﺋەرﮐﯽ دەﺑڕﯾﻨﯽ وﺷەﯾەک ﯾﺎن ڕﺳﺘەﯾەک ﯾﺎن وﺗﻮوێﮋێﮏ\nFigure A.5: A few translation examples from Sorani Kurdish to English using the model with the highest BLEU\nscores (Model 1, WordPunct)\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2020-10-12",
  "updated": "2020-10-12"
}