{
  "id": "http://arxiv.org/abs/2010.12433v1",
  "title": "Natural Language Processing Chains Inside a Cross-lingual Event-Centric Knowledge Pipeline for European Union Under-resourced Languages",
  "authors": [
    "Diego Alves",
    "Gaurish Thakkar",
    "Marko Tadić"
  ],
  "abstract": "This article presents the strategy for developing a platform containing\nLanguage Processing Chains for European Union languages, consisting of\nTokenization to Parsing, also including Named Entity recognition andwith\naddition ofSentiment Analysis. These chains are part of the first step of an\nevent-centric knowledge processing pipeline whose aim is to process\nmultilingual media information about major events that can cause an impactin\nEurope and the rest of the world. Due to the differences in terms of\navailability of language resources for each language, we have built this\nstrategy in three steps, starting with processing chains for the well-resourced\nlanguages and finishing with the development of new modules for the\nunder-resourced ones. In order to classify all European Union official\nlanguages in terms of resources, we have analysed the size of annotated corpora\nas well as the existence of pre-trained models in mainstream Language\nProcessing tools, and we have combined this information with the proposed\nclassification published at META-NETwhitepaper series.",
  "text": "Natural Language Processing Chains Inside a Cross-lingual Event-Centric \nKnowledge Pipeline for European Union Under-resourced Languages \nDiego Alves, Gaurish Thakkar, Marko Tadić \nUniversity of Zagreb, Faculty of Humanities and Social Sciences \nIvana Lučića 3, 10000 Zagreb, Croatia \ndfvalio@ffzg.hr, gthakkar@m.ffzg.hr, marko.tadic@ffzg.hr \nAbstract \nThis article presents the strategy for developing a platform containing Language Processing Chains for European Union languages, \nconsisting of Tokenization to Parsing, also including Named Entity recognition and with addition of Sentiment Analysis. These chains \nare part of the first step of an event-centric knowledge processing pipeline whose aim is to process multilingual media information about \nmajor events that can cause an impact in Europe and the rest of the world. Due to the differences in terms of availability of language \nresources for each language, we have built this strategy in three steps, starting with processing chains for the well-resourced languages \nand finishing with the development of new modules for the under-resourced ones. In order to classify all European Union official \nlanguages in terms of resources, we have analysed the size of annotated corpora as well as the existence of pre-trained models in \nmainstream Language Processing tools, and we have combined this information with the proposed classification published at META-\nNET whitepaper series. \nKeywords: language processing chains, under-resourced languages, European languages resources. \n \n1. Introduction \nIt is indisputable that major events such as Brexit and the \nrecent migration crisis affect countries inside the European \nUnion (EU) in several different ways. Due to the impact of \nmajor events inside local communities, with different \nlanguages, \nan \nenormous \namount \nof \nevent-centric \nmultilingual information is available from different media \nsources. This diversity reflects community-specific \naspects, opinions, sentiments, and bias (Annex 1 to the \nGrant Agreement of Cleopatra – 812997).  \nThis multicultural data is potentially useful for a great \nvariety of stakeholders, including digital humanities \nresearchers, memory institutions, media monitoring \ncompanies, and journalists. However, in order to provide \nall the presented information in a valuable way, it must \nundergo first through a sequence of automatic processing: \neffective interlinking, verification, and analytics. The aim \nof CLEOPATRA1 MSC Innovative Training Network \n(ITN) is to address these needs by bringing the cross-\nlingual event-centric information analytics technology to a \nhigher level. \nTo achieve its objective, CLEOPATRA initiative focuses \non three main dimensions: \n- \nAlignment, validation, and contextualization of \nevent-centric multilingual information across \nheterogeneous sources for all twenty-four EU \nofficial languages. \n- \nDevelopment of new interactive user access \nmodels to cross-lingual information to optimize \nthe way to interact with the diverse data at \ndifferent levels. \n- \nDevelopment of models that describe cross-\ncultural information propagation in a data-driven, \napplication-centric manner. \nThe European Union (EU) has around 513 million  \ninhabitants (Eurostat2, 2020) and twenty-four official \nlanguages: Bulgarian, Croatian, Czech, Danish, Dutch, \nEnglish, Estonian, Finnish, French, German, Greek, \nHungarian, Irish, Italian, Latvian, Lithuanian, Maltese, \nPolish, Portuguese, Romanian, Slovak, Slovene, Spanish \n                                                           \n1 CLEOPATRA is the acronym for “Cross-lingual Event-\ncentric Open Analytics Research Academy”. Website: \nhttp://cleopatra-project.eu/ \nand Swedish (European Union3, 2020). One of the main \nchallenges of CLEOPATRA ITN is the discrepancy of \navailable data and resources between EU languages. This \ndifference has an impact on the automatic extraction and \nprocessing of the information coming from different \nsources in different languages. Therefore, enhancing tools \nand resources for under-resourced language is in the core \nof this initiative activities.  \nThe aim of this article is to present this project focusing on \nthe main strategy behind the development of new resources \nfor under-resourced EU languages in terms of Language \nProcessing Chains (LPC’s). The paper is organized as \nfollows: the core CLEOPATRA Knowledge Processing \nPipeline (CKPP) will be presented in section 2. In section \n3, the role of NLP treatments through LPC’s will be \ndescribed, while the section 4 will encompass a brief \nanalysis of the state of the art of basic tools for under-\nresourced EU languages. In section 5, the strategy for \nbuilding enhanced LPC’s will be detailed, while the \nSection 6 will come up with the conclusion and possible \nfuture steps \n2. CLEOPATRA Knowledge Processing \nPipeline (CKPP) \nThe Cleopatra Knowledge Processing Pipeline is \ncomposed of four steps as presented in Figure 1 and it \ncomprises the whole event-centric analytics multilingual \nprocessing.  \nThe first step refers to the extraction and alignment of \nevent-related information from the varied multilingual \nmedia sources to obtain data providing enough linguistic \ninformation that will allow further analytics. It concerns the \nmain Language Processing Chains that include tasks from \ntokenization to parsing and Named Entity Recognition and \nClassification. \nValidation and contextualization of extracted data are part \nof the second step. For this, textual and visual information \nwill be used to provide fact validation, relation between \ntext and image and sentiment analysis.  \n \n2 https://ec.europa.eu/eurostat/home? \n3https://europa.eu/european-union/about-eu/eu-\nlanguages_en \n \n \n \n \n \nThe third step involves user interaction with multilingual \ninformation to provide an efficient and intuitive search \nengine relying on the extracted information. Question \nAnswering methods will also be developed to guarantee an \neffective cross-lingual analysis. \nThe aim of the fourth and final step of the CKPP is to \nprovide examples of several analytics applications of the \npipeline with respect to information propagation and bias, \nto conduct case studies in politics and sports topical areas, \nand to analyse community created data sources.  \nThis article will focus on the Language Processing Chains \ninside steps one and two, which will be responsible for \nenriching the multilingual data with linguistic information.  \n3. LPCs inside the CKPP \n3.1 \nFrom Tokenisation to Parsing and Named \nEntity Recognition and Classification \nThe main NLP tasks that will be considered are: Sentence \nsplitting, Tokenisation, Lemmatisation, Part-of-Speech and \nMorphosyntactic tagging, Parsing and NERC. The idea is \nto provide an online multilingual platform with different \ntools and pre-trained models that will allow to analyse raw \ntexts from the twenty-four official languages of the \nEuropean Union. \nThe platform will contain, for each language, enhanced \nLPC composed by different existing and newly modules, \ncombining different NLP strategies and methods for \ndifferent languages aligned with the BLARK (Basic \nLAnguage Resource Kit)/ELARK (Extended LAnguage \nResource Kit) concept defined by ELRA and CLARIN \n(Krauwer 1998, Maegaard et al. 2005, Arppe et al. 2010). \nSuch an example of NLP online platform is the Web-based \nLinguistic Chaining Tool (WebLicht) website4 developed \nby the German partners in the CLARIN-ERIC, proposing \ndifferent NLP pre-trained modules that can be combined to \nannotate texts from forty-one different world-wide \nlanguages. Our platform will differ from WebLicht as we \naim to propose enhanced processing chains focusing on \nevent-centric media data and to offer new optimized tools \nusing deep learning for under-resourced languages.  \nFor the tasks concerning tokenisation to parsing, in terms \nof reliable and homogeneous linguistic information to be \nused as training, development and test data, we will rely \nmostly on the corpora provided by the Universal \nDependencies5 framework (UD) and use the CoNLL-U \nformat. \n \n                                                           \n4https://weblicht.sfs.uni-\ntuebingen.de/weblichtwiki/index.php/Main_Page \n \n \n \n \n \nAll twenty-four official EU languages have available \ncorpora inside UD, however, the amount of data varies \nenormously between them. This will be analysed further in \nthis article. \nFor the evaluation of the different LPC’s in order to \ndetermine the most optimized one, we will follow the \nstandard metrics described in the CoNLL 2018 Shared \nTask.  \nThe proposed metrics concern each task of the chain \nindividually but also include some combined metrics such \nas MLAS and BLEX (Straka et al., 2016). \nThe task of NERC does not have an equivalent framework \nto the Universal Dependencies one. Instead, many different \ntools propose different corpora and different types of \nclassification schemes with different complexity in levels \nand number of predefined categories. However, to \nguarantee some homogeneity inside the platform to be \ncreated, in the beginning, we will base our annotations \naccording to the guidelines of the Seventh Message \nUnderstanding Conference (MUC-7) as presented in \nMikheev et al. (1997), while the proposal for Universal \nNER (UNER) scheme is presented in Alves et al. (in press). \n3.2 \nCross-lingual Sentiment Analysis  \nFor the CKPP, we would like to associate sentiment values \nwith the entities playing pivotal roles in the event. The aim \nis to process text using the various tools defined in the \nprevious section and perform subjective analysis of the \nsame.  \nWe plan to run this process in two levels of granularities. \nThe first cycle would be sentence-level sentiment analysis \nand second would be aspect/concept-based sentiment \nanalysis. We assume 3-class (positive, neutral and \nnegative) and 5 class (very-negative, negative, neutral, \npositive and very positive) classification schemes for \nsentence-based and aspect-based respectively. The former \nis easier to begin with and less-prone to phenomena like \nclass-imbalance.   \nThe main Sentiment Analysis tasks that will be considered \nare: Subjectivity Detection and Subjectivity Classification. \nFor aspect-based sentiment analysis additional detection \nsteps for Opinion Target/s (Aspects/Entities), Opinion \nHolders, Sentiment Phrase and its classification are \nforeseen. \nSince not all the languages under study have uniform \ndistribution for training data, our main focus in this study \nwould be to employ cross-lingual knowledge transfer \n5 https://universaldependencies.org/ \nFigure 1: Steps of the Cleopatra Knowledge Processing Pipeline. \nmethods that have shown good performance on some NLP \ntasks (Chen et al., 2018; Chidambaram et al., 2019). The \ncreation of resources via the means of crowd-sourcing \n(implicit as well as explicit) (Nakov et al., 2016) is another \nviable option in the absence of annotated resources. The \nsystems will be reported in terms of Accuracy, Precision-\nRecall, and F-Score.   \n4.  Under-resourced European Union \nLanguages \nAs previously mentioned, one of the main challenges when \nproposing enhanced and robust LPC’s in a multilingual \nplatform is the different status of each language in terms of \nlanguage resources.  \nAccording to the META-NET Language Whitepaper \nseries6 (META-NET LWS 2012), which described a state \nof the art of NLP development for 31 European languages, \nthere is an enormous discrepancy between them concerning \nthe availability of languages resources and processing \ntools. \nIn the following subsections, META-NET Classification \nwill be presented as well as other State of the Art \ninformation that allows us to identify the languages that can \nbe considered as under-resourced ones between the EU \nofficial languages.  \n4.1 \nMETA-NET White Book Series \nIn the META-NET White Book series (Rehm et al. 2012) \na classification of 30 European languages in four different \naspects of the development of the respective language \ntechnologies was proposed: \n- \nMachine Translation. \n- \nSpeech Processing. \n- \nText Analysis (tools). \n- \nSpeech and text resources (data). \nFor each aspect languages were sorted into five different \nlevels: \n- \nExcellent. \n- \nGood. \n- \nModerate. \n- \nFragmentary. \n- \nWeak / No Support. \nFor CLEOPATRA ITN, the most relevant META-NET \ncategories are “Text Analysis” and “Speech and Text \nresources”. Therefore, considering as under-resourced the \nlanguages that are classified as “Fragmentary” or “Weak / \nNo Support” in at least one of these two aspects, the under-\nresourced EU languages are: Bulgarian, Croatian, Czech, \nDanish, Estonian, Finnish, Greek, Hungarian, Irish, \nLatvian, \nLithuanian, \nMaltese, \nPolish, \nPortuguese, \nRomanian, Slovak, Slovenian, Swedish. Eighteen out of \ntwenty-four EU languages. \nIt is important to mention, however, that this whitepaper \nseries has been published in 2012 and since then some \nprogress has been made in most of these languages. \nTherefore, an additional contribution of this work will also \nbe an update of META-NET white-papers series \ninformation for the selected languages. \n \n                                                           \n6 http://www.meta-net.eu/whitepapers/overview \nAdditionally, these two levels actually encompass a wider \nrange of development of language technologies since both, \nCzech \nand \nMaltese \nappear \nthere \nalthough \ntheir \ndevelopments are quite distinct.    \n4.2 \nUniversal Dependencies Corpora \nAs Universal Dependencies Corpora will be used as a \nreference for our project, it is also crucial to analyse the \nlanguages in terms of the quantity and size of UD corpora. \nThe following table presents a list of all EU languages and \nthe size of the available data in number of tokens. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTable 1: EU Languages and the size of their available UD \nCorpora (version 2.5)7. \n \nIt is possible to notice that while some languages such as \nGerman, Czech and French have more than one million \ntokens corpora, some under-resourced ones have less than \nfifty thousand tokens datasets. It is the case for Maltese, \nHungarian and Irish.  \nConsidering as under-resourced languages the ones with \nless than five hundred thousand tokens corpora, sixteen can \nbe classified as such: Irish, Hungarian, Maltese, Greek, \nLithuanian, \nDanish, \nSlovak, \nBulgarian, \nSlovenian, \nCroatian, Swedish, Latvian, Dutch, Estonian, Finnish, \nPolish. \n7 https://universaldependencies.org/ \nIn comparison with META-NET information, Portuguese \nand Romanian are classified differently as they have \nconsiderable UD corpora.  \nAn important point to consider when using UD datasets is \nthat \nwhile \nthe \nframework \nproposes \nstable \nand \nhomogeneous guidelines, still, it is possible to identify \nsome heterogeneity comparing different UD corpora of the \nsame language: different number of tags used especially for \nmorphological features but also for part-of-speech and \ndependency relations and different tokenisation strategies \nfor treating contracted words.  \n4.3 \nMainstream NLP tools \nFor this article, a tool is considered mainstream if it \nproposes pre-trained models for numerous EU languages \nconcerning multiple NLP tasks (mainly from raw text to \ndependency parsing). \nThe selected tools that were tested are: Stanford NLP \n(Manning et al. 2014), UDPipe (Straka et al. 2016), NLP-\nCube (Boros et al. 2018), Freeling (Padró & Staniloysky \n2012), OpenNLP and spaCy8.  \nOnly UDPipe have pre-trained models for all EU \nlanguages. StandfordNLP and NLP-Cube do not propose \ndownloadable models for Lithuanian or Maltese. The other \ntools are more limited in terms of multilingual coverage.  \nConsidering the listed tools and their published results and \nconcerning the evaluation metrics of their available \nmodels, it is possible to observe that the official results tend \nto be quite favorable in most of the cases for tasks before \nparsing. UAS and LAS metrics show more disparity and, \nthus, will be used here as a criterion for identifying under-\nresourced languages. If we consider as well-resourced \nlanguages the ones with at least one case where UAS is \nupper than 90, then, we have the following list of nine \nunder-resourced \nEU \nlanguages: \nDanish, \nEstonian, \nHungarian, Irish, Latvian, Lithuanian, Maltese, Slovak and \nSwedish. \nComparing UAS values with UD data size information, it \nis possible to observe that in almost all cases of language \nwith corpora size below one hundred and fifty thousand \ntokens, UAS values are lower than 90. The only exception \nbeing Greek (low size dataset but UAS higher than 90) and \nEstonian (higher corpora size but low UAS). \nAll these criteria used to identify EU under-resourced \nlanguages were relevant to define the campaign strategy \nthat will be used to build the LPC’s and which will be \npresented in section 5. \n4.4 \nSentiment Analysis \nUnlike the other tasks defined in the LPC’s, there exist no \nopen-source tools that handle multilingual sentiment \nanalysis for under-resourced languages.  The very essential \nresources required for performing sentiment analysis are \nsentiment lexicons, which are composed of words and/or \nmulti-word expressions tagged with sentiment scores. \nSentiment lexicon alone cannot achieve state of the art as \nthe presence or the absence of intensifier, negations and \nsarcasm phenomenon can completely modify the expressed \nsentiment. Hence this type of resource is necessary but not \nsufficient. However, there have been various attempts in \n                                                           \n8 https://spacy.io/ \nusing Machine Translation (MT) as the core tool in \ngenerating or aiding the sentiment analysis process. \nNevertheless, these MT systems are also prone to inducing \ntranslation errors and semantic shift in the translated text. \nThe data (in-domain and out-domain) used for cross-\nlingual knowledge transfer play a major role in the final \nperformance due to the inherent divergence present \n(Demirtas et al. 2013).  Hence it would be interesting to \nstudy the cross-domain, cross-lingual setup for solving the \ntask of sentiment analysis using the LPCs. \n5. Campaign Strategy \nThe strategy that will be adopted can be divided in three \nparts that will be described in the following subsection. \nFirst, the idea is to start by developing LPCs for well-\nresourced languages, secondly, add gradually new \nprocessing chains for languages with lesser available data, \nand, finally, work on the development of modules for most \nunder-resourced languages and integrate them in the \nplatform. \n5.1 \nNLP for Well-resourced Languages \nIn the first phase of the development of the online LPC \nplatform, the focus will be on languages considered well-\nresourced ones. Taking into consideration the information \npresented in the previous section, these languages rich in \nresources and tools are: Dutch, English, French, German, \nItalian, Spanish. \nConsidering the existing tools and datasets, the objective is \nto analyse how all available resources, with different \nalgorithms and methods, can be combined to optimise the \nprocessing of event-centric information. \nBy focusing on existing tools and models trained with \nsufficient data, our aim is to understand how well different \nmethods work for different tasks and to identify possible \nsynergies between them. \nDuring this phase, the first processing chains will be shared \nwith future CLEOPATRA users so that the possible \nenhancements concerning formats and interface will be \nidentified. \n5.2 \nDeployment to other Languages \nIn the second step, the idea is to use all the knowledge \nacquired during the first phase and apply it wisely in the \ndevelopment of LPC’s for languages with less resources \nthan the ones listed in the previous section but which are \nnot considered as the most under-resourced ones: \nBulgarian, Croatian, Czech, Finnish, Greek, Polish, \nPortuguese, Romanian and Slovenian. \nExisting tools and data will be used and combined in order \nto achieve the best possible metrics throughout the whole \nprocessing chain. \n5.3 \nDevelopment of New Modules for Under-\nresourced Languages \nDuring the last phase, besides testing existing tools, new \nmodels based on different deep learning techniques will be \ndeveloped to all remaining languages, the ones \nconditionally considered as the most under-resourced ones \nin the EU: Danish, Estonian, Hungarian, Irish, Latvian, \nLithuanian, Maltese, Slovak and Swedish. The results \nobtained in this step will allow us to compare all techniques \nand decide which methodology will prevail, not just for \nparticular module design, but for the whole LPCs.  \nAll the results obtained will also allow for a deeper \nunderstanding of how different deep learning or statistical \napproaches deal with specific linguistic phenomena of the \nlisted languages.  \n6. Conclusions and Future Directions \nThe development of robust and effective multilingual \nLanguage Processing Chains is crucial for achieving the \nmain objective of CLEOPATRA ITN as text processing is \ninside the first step of its Knowledge Processing Pipeline. \nHowever, due to the difference in available resources of \ntwenty-four official EU languages, an effective strategy \nmust be put in place. Although there is no exact and unique \nway of classifying a language as under-resourced, we have \nproposed the division of EU languages into three different \nclusters, from languages having a good number of \nresources and tools to languages that could be called the \nmost under-resourced ones in the EU.  \nThis classification is important in our strategy for the \ndevelopment of LPC’s as our idea is to start working with \nvery well-resourced languages in the first step, following \nby the ones with less amount of language resources and \nfinally, in a final phase, take advantage of all the learnings \ncollected in the previous steps together with testing \ndifferent machine learning methods to create the optimal \nLPC’s for the languages with the lowest number and size \nof available resources.  \nAlthough this work is, primarily, focused on official \nEuropean Union languages, the main findings could \npossibly be applied, in further steps, to other under-\nresources languages in Europe and worldwide.  \n7. Acknowledgements \nThe work presented in this paper has received funding from \nthe European Union’s Horizon 2020 research and \ninnovation program under the Marie Kłodowska-Curie \ngrant agreement no. 812997 and under the name \nCLEOPATRA \n(Cross-lingual \nEvent-centric \nOpen \nAnalytics Research Academy). \n8. Bibliographical References \nAlves, D., Kuculo, T., Amaral, G., Thakkar, G., Tadić, M. \n(in press) UNER: Universal Named-Entity Recognition \nFramework, In Proceedings of the 1st international \nworkshop on cross-lingual, event-centric open analytics, \nEuropean Semantic Web Conference (ESWC2020). \nArppe, A., Beck, K., Branco, A., Camilleri, V., Caselli, T., \nCristea, D., Hinrichs, E., Liin, K., Nissinen, M., Parra, \nC., Rosner, M. Schuurman, I., Skadina, I., Quochi, V., \nvan Uytvanck, D., Vogel, I., “Description of the \nBLARK, the Situation of Individual Languages”, \nCLARIN \ndeliverable \nD5C-4, \n[https://office.clarin.eu/pp/D5C-4.pdf, accessed 2020-\n02-13]. \n \n \nChen, X., Sun, Y., Athiwaratkun, B., Cardie, C., \nWeinberger, K. \"Adversarial deep averaging networks \nfor cross-lingual sentiment classification.\" Transactions \nof the Association for Computational Linguistics 6, p. \n557-570, 2018. \nChidambaram, M., Yang, Y., Cer, D., Yuan, S., Sung, Y., \nStrope, B., & Kurzweil, R. (2019, August). Learning \nCross-Lingual Sentence Representations via a Multi-task \nDual-Encoder Model. In Proceedings of the 4th \nWorkshop on Representation Learning for NLP \n(RepL4NLP-2019) (pp. 250-259). \nChinchor, A. “Overview of MUC-7”. Proceedings of the \nSeventh Message Understanding Conference (MUC-7). \n1998. \nDemirtas, Erkin, and Mykola Pechenizkiy. \"Cross-lingual \npolarity detection with machine translation.\" In \nProceedings of the Second International Workshop on \nIssues of Sentiment Discovery and Opinion Mining, pp. \n1-8. 2013. \nEuropean \nUnion. \nRetrieved \nfrom: \nhttps://europa.eu/european-union/about-eu/eu-\nlanguages_en. Last visited on 13/02/2020.  \nEurostat - Your key to European Statistics. Retrieved from: \nhttps://ec.europa.eu/eurostat/web/products-press-\nreleases/-/3-10072019-BP. Last visited on 13/02/2020. \nKrauwer S., “ELSNET and ELRA: A Common Past and a \nCommon Future”. ELRA Newsletter, vol. 3, n. 2, 1998. \nMaegaard, B., Choukri, K., Calzolari, N., Odijk, J., “ELRA \n– \nEuropean \nLanguage \nResources \nAssociation-\nBackground, \nRecent \nDevelopments \nand \nFuture \nPerspectives”, Language Resources and Evaluation, v. \n39, p. 9-23, 2005. \nManning, C. D., Surdeanu, M., Bauer, J., Finkel, J., \nBethard, S. J., McClosky, D., “The Stanford CoreNLP \nNatural Language Processing Toolkit”, Proceedings of \nthe 52nd Annual Meeting of the Association for \nComputational Linguistics: System Demonstrations, p. \n55-60, 2014. \nMETANET Language Whitepaper series. (2012) Retrieved \nfrom:  http://www.meta-net.eu/whitepapers/overview. \nLast visited on 10/02/2020. \nPadró, L., Stanilovysky, E., “FreeLing 3.0: Towards Wider \nMultilinguality”, \nProceedings \nof \nthe \nLanguage \nResources and Evaluation Conference (LREC 2012) \nELRA, 2012. \nSpeecon Consortium. Dutch Speecon Database. Speecon \nProject, distributed via ELRA, Speecon resources, 1.0, \n2014. \nStraka, M., Hajič, J., Straková, J., “UDPipe: Trainable \nPipeline for Processing CoNLL-U Files Performing \nTokenization, Morphological Analysis, POS Tagging \nand Parsing”, Proceedings of the Tenth International \nConference on Language Resources and Evaluation \n(LREC 2016), Slovenia, 2016. \nZeman, D., Hajič, J., Popel, M., Potthtyersast, M., Straka, \nM., Ginter, F., Nivre, J., and Petrov, S. “Conll 2018 \nshared task: Multilingual parsing from raw text to \nuniversal dependencies”. Proceedings of the CoNLL \n2018 Shared Task: Multilingual Parsing from Raw Text \nto \nUniversal \nDependencies. \nAssociation \nfor \nComputational Linguistics, pp. 1–21, 2018. \n \n \n \nNakov, Preslav, Alan Ritter, Sara Rosenthal, Fabrizio \nSebastiani, and Veselin Stoyanov. \"SemEval-2016 Task \n4: Sentiment Analysis in Twitter.\" In Proceedings of the \n10th International Workshop on Semantic Evaluation \n(SemEval-2016), pp. 1-18. 2016 \n9. Language Resource References  \nSpeecon Consortium. Dutch Speecon Database. Speecon \nProject, distributed via ELRA, Speecon resources, 1.0, \n2014. \nUniversal \nDependencies. \nRetrieved \nfrom: \nhttps://universaldependencies.org/. \nLast \nvisited \non \n24/09/2019. \nWebLicht. \nRetrieved \nfrom: \nhttps://weblicht.sfs.uni-\ntuebingen.de/weblichtwiki/index.php/Main_Page .  \n",
  "categories": [
    "cs.CL"
  ],
  "published": "2020-10-23",
  "updated": "2020-10-23"
}