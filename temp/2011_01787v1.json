{
  "id": "http://arxiv.org/abs/2011.01787v1",
  "title": "Predicting intubation support requirement of patients using Chest X-ray with Deep Representation Learning",
  "authors": [
    "Aniket Maurya"
  ],
  "abstract": "Recent developments in medical imaging with Deep Learning presents evidence\nof automated diagnosis and prognosis. It can also be a complement to currently\navailable diagnosis methods. Deep Learning can be leveraged for diagnosis,\nseverity prediction, intubation support prediction and many similar tasks. We\npresent prediction of intubation support requirement for patients from the\nChest X-ray using Deep representation learning. We release our source code\npublicly at https://github.com/aniketmaurya/covid-research.",
  "text": "Predicting intubation support requirement of patients using\nChest X-ray with Deep Representation Learning\nMaurya, Aniket\ntheaniketmaurya@gmail.com\nNovember 4, 2020\nAbstract\nRecent developments in medical imaging with Deep Learning presents an evidence of au-\ntomated diagnosis and prognosis. It can also be a complement to currently available diagnosis\nmethods. Deep Learning can be leveraged for diagnosis, severity prediction, intubation support\nprediction and many similar tasks. We present prediction of intubation support requirement\nfor patients from the Chest X-ray using Deep representation learning. We release our source\ncode publicly on https://github.com/aniketmaurya/covid-research.\n1\nIntroduction\nAccording to [who, 2014] the world is to see a short of 12.9 million health-care workers by 2035.\nThis problem of shortage of medical experts and medical equipment is more visible in this COVID-\n19 pandemic [Byatnal, 2020] [Ranney et al., 2020]. COVID-19 test result time has not improved\nmuch to help slow the spread of the virus [Stein, 2020]. There is an urgent need to upgrade the\ncurrent healthcare system with recent technology advancements [who, 2020].\nApproximately 3.2% of COVID-19 patients required intubation and invasive ventilation support\nin some point of their illness [Meng et al., 2020]. Sometimes COVID-19 patients crash suddenly\nand require immediate care for intubation and ventilation [Strickland, 2020]. Providing intubation\ncan put infection risk to the provider and every person in the room. Some delay may occur during\nintubation process due to heightened anxiety and rush, this can increase the infection risk.\nIn this work, we present prediction of intubation support requirement to patients using Deep\nRepresentation Learning. We show that how we can leverage deep learning for taking proactive\nmeasures like arranging beds, ventilators, oxygen cylinders. It can give enough time to healthcare\nprovider to be prepared with personal protective equipment properly. We produce Chest X-ray\nrepresentation of patients and train our learning algorithm to classify whether the person will need\nintubation support during the duration of his illness.\n2\nRelated Work and Background\nRecently a lot of work has been started in automating the disease prognosis and diagnosis task with\nDeep Learning. It is mainly due to recent advancements in Deep learning. Convolutional Neural\nNetworks [Lecun et al., 1998] are now able to reach human level performance in classiﬁcation and\ndetection tasks [Geirhos et al., 2018]. [Rajpurkar et al., 2017] [Irvin et al., 2019] [Lu et al., 2020]\ndetects chest pneumonia with radiologist level accuracy. Image recognition with deep learning\nis being used for detecting diﬀerent type of diseases like diabetic retinopathy and skin cancer\n[Tymchenko et al., 2020].\n2.1\nRadiologist level Pneumonia Detection using Chest X-ray images\nChexNet [Rajpurkar et al., 2017] can predict Pneumonia from CXRs with better F1 score than a\ngroup of experienced radiologists. It is a 121-layered deep convolutional neural network trained\non ChestX-ray14 dataset [Wang et al., 2017] for classifying Chest X-ray image as Pneumatic. The\ndataset is comprised of 112,120 frontal-view Chest X-ray images of 30,805 unique patients. To\ntrain this network, images are ﬁrst resized to 224x224 dimension and normalized by the ImageNet\n1\narXiv:2011.01787v1  [eess.IV]  28 Oct 2020\n[Russakovsky et al., 2015] mean and standard deviation. This sets a benchmark for other similar\nlungs disease diagnosis task. The network is able to achieve state of the art score on total 14\ndiﬀerent lungs disease diagnosis task. It achieves F1 score of 0.435 which is higher than achieved\nby a group of radiologists that is 0.385.\n2.2\nCOVID-19 Severity prediction\n[Cohen et al., 2020a] predicts severity of COVID-19 from the chest x-ray of patients. To train this\nnetwork, a representation of 1024 dimensional vector is produced from non-covid CXR pre-trained\nnetwork, 18 outputs (from classiﬁcation layer), 4 outputs as subset of 18 outputs (lung opacity,\npneumonia, inﬁltration, and consolidation) and Lung opacity output is used for creating ﬁnal data\nrepresentation. It further evaluates the input data features for overﬁtting & bias and analyses the\nmodel with Saliency map. Knowing severity can help COVID-19 patients and hospitals so that\nthey can arrange themselves.\n3\nDataset\nWe use covid-chestxray-dataset [Cohen et al., 2020b] (Figure 1), an open dataset collected from\npublic and indirect collection from hospitals and physicians. The dataset is available on GitHub.\nIt has a total of 535 AP and PA view of X-ray images in PNG format, which is a lossless image\nformat. The ratio of COVID-19 positive and negative is 63.9% and 36%, where total positive labels\nare 342 and non-positives are 193. The metadata of this dataset contains labels of 25 lungs disease,\nshown in Table 1. To avoid issues with ﬂoat round oﬀthe image pixels are normalized to be in\nrange of [-1024,1024].\nFigure 1: 1 means COVID-19 +Ve and 0 means -Ve.\n4\nExperiments\n4.1\nDiagnosing COVID-19 using Deep Representation Learning of CXRs\nConvolutional Neural Networks once trained on a huge dataset are frequently used for training on\nnew task using transfer-learning [Tan et al., 2018], a method where weights of neural networks are\ninitialised from the weights of pre-trained network. Deep Neural Networks learn the representation\nof the dataset and the data representation can be used for other tasks as well [Huang et al., 2016].\nTorchXRayVision [Cohen et al., 2020c], an open-source library for Chest X-ray datasets and mod-\nels is used for ease of experiment. We use the DenseNet-121 [Huang et al., 2018] from TorchXRayVi-\nsion library which is pre-trained on non-covid to produce 1024 dimensional vector representation\nof CXRs.\n2\nPathalogy\nNegative\nPositive\nAspergillosis\n534\n1\nAspiration\n534\n1\nBacterial\n487\n48\nCOVID-19\n193\n342\nChlamydophila\n534\n1\nFungal\n512\n23\nH1N1\n534\n1\nHerpes\n532\n3\nInﬂuenza\n531\n4\nKlebsiella\n526\n9\nLegionella\n526\n9\nLipoid\n527\n8\nMERS-CoV\n527\n8\nMRSA\n534\n1\nMycoplasma\n530\n5\nNo Finding\n520\n15\nNocardia\n531\n4\nPneumocystis\n513\n22\nPneumonia\n26\n509\nSARS\n519\n16\nStaphylococcus\n534\n1\nStreptococcus\n518\n17\nTuberculosis\n524\n11\nVaricella\n530\n5\nViral\n157\n378\nTable 1: covid-chestxray-datset pathology negative and positive frequency\nThe pre-trained DenseNet-121 model has been trained on large amount of chest x-ray dataset\nfor diﬀerent chest abnormality classiﬁcation.\nWe use this model for creating representation of\nCOVID-19 CXR image data. We remove the last layer of the network, i.e. the classiﬁcation layer,\nand extract the embedding from the last convolution layer. The obtained features are of dimension\n7x7x1024, we applied 2D average pooling to convert it into 1x1x1024 dimension.\nWe use this\nembedding to train k-nearest neighbors classiﬁcation algorithm (KNN) with scikit-learn Python\nlibrary [Pedregosa et al., 2011], where k is the number of neighbors. We split the dataset into train\nand test using random sampling. Our train data consisted of 428 images and test data consisted\nof 107 images.\nWe train the KNN model with K=8 and took euclidean distance as distance metric d =\npP(X1 −X2)2. We get 73% precision and 83% recall. We plot confusion matrix of our clas-\nsiﬁcation outputs in Figure 2.\n4.2\nPredicting intubation requirement of patients\n[Cohen et al., 2020b] intubated attribute represents whether the patient was intubated at any\npoint during his illness. Given a CXR, we predict whether the patient will need intubation, Figure\n3.\nFor this task we used AP and PA view of Chest X-ray of COVID and other Chest diseases, total\nof 25 diﬀerent pathology, Table 1. We produce our feature representation similar to section 4.1\nand labels are 1 and 0 where 1 is intubation was required for the patient and 0 means intubation\nwas not required.\nWe randomly split dataset into train and test set. Our training set comprised of 75% of the\ntotal data. Train dataset length is 119 and test dataset length is 40. We experiment with number\nof neighbors (k) from 2 to 14 inclusively. We ﬁnd that k=5 gives the best precision and recall.\nAfter training, we plot the confusion matrix of the test result as in Figure 3 20 intubated and 10\nnon-intubated patients are classiﬁed correctly as intubated and non-intubated respectively while\n6 intubated and 4 non-intubated patients are classiﬁed incorrectly. We calculate 0.84 (95% CI\n0.62, 0.86) AUC on the test set, Figure 4. We use bootstrap method to create 95% CI with 10,000\n3\nFigure 2: Confusion matrix of COVID-19 classiﬁcation from CXR.\nFigure 3: Confusion Matrix of patient intubation classiﬁcation.\nbootstrap samples with replacement from the test dataset. We observe 0.84 (95% CI 0.615, 0.863)\nROC-AUC for our KNN classiﬁer. This shows how we can use representations when dataset is\nlimited.\n5\nConclusion\nWe need to leverage Deep learning methods to automate our healthcare system wherever possible.\nDeep learning methods can assist in better resource management. X-rays are economical to CT\nscan and is available most of the places. It can be used to get an instant prognosis which can help in\ndeciding quarantine and triaging. Severity prediction can be used to check if the current resources\ncan support the patient status. Intubation support prediction can help hospital in managing the\nbed, ventilator and oxygen cylinders in advance.\nHowever, due to COVID-19 there has been a lot of research that has come up with diﬀerent\nsolution and suggestion for disease diagnosis. But before deploying any machine automated solution\nwe must need to test it thoroughly for any kind of bias.\nReferences\n[who, 2014] (2014). Global health workforce shortage to reach 12.9 million in coming decades.\n[who, 2020] (2020). Push for stronger health systems as africa battles covid-19.\n4\nFigure 4: Intubation classiﬁcation ROC curve. 95% Conﬁdence interval for score 0.615, 0.863\n[Byatnal, 2020] Byatnal, A. (2020). Shortage of health care workers plagues india’s ﬁght against\ncovid-19.\n[Cohen et al., 2020a] Cohen, J. P., Dao, L., Morrison, P., Roth, K., Bengio, Y., Shen, B., Abbasi,\nA., Hoshmand-Kochi, M., Ghassemi, M., Li, H., and Duong, T. Q. (2020a). Predicting covid-19\npneumonia severity on chest x-ray with deep learning.\n[Cohen et al., 2020b] Cohen, J. P., Morrison, P., and Dao, L. (2020b). Covid-19 image data col-\nlection. arXiv 2003.11597.\n[Cohen et al., 2020c] Cohen,\nJ.\nP.,\nViviano,\nJ.,\nHashir,\nM.,\nand\nBertrand,\nH.\n(2020c).\nTorchXRayVision:\nA\nlibrary\nof\nchest\nX-ray\ndatasets\nand\nmodels.\nhttps://github.com/mlmed/torchxrayvision.\n[Geirhos et al., 2018] Geirhos, R., Janssen, D. H. J., Schütt, H. H., Rauber, J., Bethge, M., and\nWichmann, F. A. (2018). Comparing deep neural networks against humans: object recognition\nwhen the signal gets weaker.\n[Huang et al., 2016] Huang, C., Li, Y., Loy, C. C., and Tang, X. (2016). Learning deep represen-\ntation for imbalanced classiﬁcation. In 2016 IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), pages 5375–5384.\n[Huang et al., 2018] Huang, G., Liu, Z., van der Maaten, L., and Weinberger, K. Q. (2018). Densely\nconnected convolutional networks.\n[Irvin et al., 2019] Irvin, J., Rajpurkar, P., Ko, M., Yu, Y., Ciurea-Ilcus, S., Chute, C., Marklund,\nH., Haghgoo, B., Ball, R., Shpanskaya, K., Seekins, J., Mong, D. A., Halabi, S. S., Sandberg,\nJ. K., Jones, R., Larson, D. B., Langlotz, C. P., Patel, B. N., Lungren, M. P., and Ng, A. Y.\n(2019). Chexpert: A large chest radiograph dataset with uncertainty labels and expert compar-\nison.\n[Lecun et al., 1998] Lecun, Y., Bottou, L., Bengio, Y., and Haﬀner, P. (1998). Gradient-based\nlearning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324.\n[Lu et al., 2020] Lu, Z., Whalen, I., Dhebar, Y., Deb, K., Goodman, E., Banzhaf, W., and Boddeti,\nV. N. (2020). Multi-objective evolutionary design of deep convolutional neural networks for image\nclassiﬁcation.\n[Meng et al., 2020] Meng, L., Qiu, H., Wan, L., Ai, Y., Xue, Z., Guo, Q., Deshpande, R., Zhang,\nL., Meng, J., Tong, C., Liu, H., and Xiong, L. (2020). Intubation and Ventilation amid the\nCOVID-19 Outbreak: Wuhan’s Experience. Anesthesiology, 132(6):1317–1332.\n[Pedregosa et al., 2011] Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B.,\nGrisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A.,\n5\nCournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. (2011). Scikit-learn: Machine\nlearning in Python. Journal of Machine Learning Research, 12:2825–2830.\n[Rajpurkar et al., 2017] Rajpurkar, P., Irvin, J., Zhu, K., Yang, B., Mehta, H., Duan, T., Ding,\nD., Bagul, A., Langlotz, C., Shpanskaya, K., Lungren, M. P., and Ng, A. Y. (2017). Chexnet:\nRadiologist-level pneumonia detection on chest x-rays with deep learning.\n[Ranney et al., 2020] Ranney, M. L., School, A. A. A. M., Editors, T., Beigel, J. H., Others, Walsh,\nE. E., and Others (2020).\nCritical supply shortages - the need for ventilators and personal\nprotective equipment during the covid-19 pandemic: Nejm.\n[Russakovsky et al., 2015] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S.,\nHuang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. (2015). Imagenet\nlarge scale visual recognition challenge.\n[Stein, 2020] Stein, R. (2020). Coronavirus test results get faster, but still too slow to help slow\ndisease spread.\n[Strickland, 2020] Strickland, E. (2020). Ai can help hospitals triage covid-19 patients.\n[Tan et al., 2018] Tan, C., Sun, F., Kong, T., Zhang, W., Yang, C., and Liu, C. (2018). A survey\non deep transfer learning.\n[Tymchenko et al., 2020] Tymchenko, B., Marchenko, P., and Spodarets, D. (2020). Deep learning\napproach to diabetic retinopathy detection.\n[Wang et al., 2017] Wang, X., Peng, Y., Lu, L., Lu, Z., Bagheri, M., and Summers, R. M. (2017).\nChestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classiﬁ-\ncation and localization of common thorax diseases. 2017 IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR).\n6\n",
  "categories": [
    "eess.IV",
    "cs.CV",
    "cs.LG"
  ],
  "published": "2020-10-28",
  "updated": "2020-10-28"
}