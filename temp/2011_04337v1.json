{
  "id": "http://arxiv.org/abs/2011.04337v1",
  "title": "DeConFuse : A Deep Convolutional Transform based Unsupervised Fusion Framework",
  "authors": [
    "Pooja Gupta",
    "Jyoti Maggu",
    "Angshul Majumdar",
    "Emilie Chouzenoux",
    "Giovanni Chierchia"
  ],
  "abstract": "This work proposes an unsupervised fusion framework based on deep\nconvolutional transform learning. The great learning ability of convolutional\nfilters for data analysis is well acknowledged. The success of convolutive\nfeatures owes to convolutional neural network (CNN). However, CNN cannot\nperform learning tasks in an unsupervised fashion. In a recent work, we show\nthat such shortcoming can be addressed by adopting a convolutional transform\nlearning (CTL) approach, where convolutional filters are learnt in an\nunsupervised fashion. The present paper aims at (i) proposing a deep version of\nCTL; (ii) proposing an unsupervised fusion formulation taking advantage of the\nproposed deep CTL representation; (iii) developing a mathematically sounded\noptimization strategy for performing the learning task. We apply the proposed\ntechnique, named DeConFuse, on the problem of stock forecasting and trading.\nComparison with state-of-the-art methods (based on CNN and long short-term\nmemory network) shows the superiority of our method for performing a reliable\nfeature extraction.",
  "text": "DeConFuse : A Deep Convolutional Transform\nbased Unsupervised Fusion Framework\nPooja Gupta1, Jyoti Maggu1, Angshul Majumdar1,2, Emilie Chouzenoux3, and\nGiovanni Chierchia4\n1 Indraprastha Institute of Information Technology, Delhi, India\n2 TCS Research, Kolkata, India\n3 Universit´e Paris-Saclay, CentraleSup´elec, Inria, CVN, Gif-sur-Yvette, France\n4 LIGM, Universit´e Gustave Eiﬀel, CNRS, ESIEE Paris, Noisy-le-Grand, France\nAbstract. This work proposes an unsupervised fusion framework based\non deep convolutional transform learning. The great learning ability of\nconvolutional ﬁlters for data analysis is well acknowledged. The suc-\ncess of convolutive features owes to convolutional neural network (CNN).\nHowever, CNN cannot perform learning tasks in an unsupervised fash-\nion. In a recent work, we show that such shortcoming can be addressed\nby adopting a convolutional transform learning (CTL) approach, where\nconvolutional ﬁlters are learnt in an unsupervised fashion. The present\npaper aims at (i) proposing a deep version of CTL; (ii) proposing an\nunsupervised fusion formulation taking advantage of the proposed deep\nCTL representation; (iii) developing a mathematically sounded optimiza-\ntion strategy for performing the learning task. We apply the proposed\ntechnique, named DeConFuse, on the problem of stock forecasting and\ntrading. Comparison with state-of-the-art methods (based on CNN and\nlong short-term memory network) shows the superiority of our method\nfor performing a reliable feature extraction.\nKeywords: information fusion, deep learning, convolution, stock trad-\ning, ﬁnancial forecasting.\n1\nIntroduction\nIn the last decade, Convolutional Neural Network (CNN) has enjoyed tremen-\ndous success in diﬀerent types of data analysis. It was initially applied for images\nin computer vision tasks. The operations within the CNN were believed to mimic\nthe human visual system. Although such a link between human vision and CNN\nmay be present, it has been observed that deep CNNs are not exact models for\nhuman vision [1]. For instance, biologists consider that the human visual system\nwould consist of 6 layers [2, 3] and not 20+ layers used in GoogleNet [4].\nNeural network models have also been used for analyzing time series data.\nUntil recently, long short-term memory (LSTM) networks were the almost exclu-\nsively used neural network models for time series analysis as they were supposed\nto mimic memory and hence were deemed suitable for such tasks. However,\narXiv:2011.04337v1  [cs.LG]  9 Nov 2020\nLSTM are not able to model very long sequences, and their training is hardware\nintensive. Owing to these shortcomings, LSTMs are being replaced by CNNs.\nThe reason for the great results of CNN methods for time series analysis (1D\ndata processing in general) is not well understood. One possibility may lie in the\nuniversal function approximation capacity of deep neural networks [5, 6] rather\nthan its biological semblance. The research in this area is primarily led by its\nsuccess rather than its understanding.\nAn important point to mention is that the performance of CNN is largely\ndriven by the availability of very large labeled datasets. This probably explains\ntheir tremendous success in facial recognition tasks. Google’s FaceNet [7] and\nFacebook’s DeepFace [8] architectures are trained on 400 million facial images, a\nsigniﬁcant proportion of world’s population. These companies are easily equipped\nwith gigantic labeled facial images data as these are ‘tagged’ by their respective\nusers. In the said problem, deep networks reach almost 100% accuracy, even sur-\npassing human capabilities. However, when it comes to tasks that require expert\nlabeling, such as facial recognition from sketches (requiring forensic expertise)\n[8] or ischemic attack detection from EEG (requiring medical expertise) [9], the\naccuracies become modest. Indeed, such tasks require expert labeling that is\ndiﬃcult to acquire, thus limiting the size of available labeled dataset.\nThe same is believed by a number of machine learning researchers, including\nHinton himself, are wary of supervised learning. In an interview with Axios,1\nHinton mentioned his ‘deep suspicion’ on backpropagation, the workhorse behind\nall supervised deep neural networks. He even added that “I don’t think it’s how\nthe brain works,” and “We clearly don’t need all the labeled data”. It seems\nthat Hinton is hinting towards unsupervised learning frameworks. Unsupervised\nLearning technique does not require targets / labels to learn from data. This\napproach typically takes beneﬁt from the fact that data is inherently very rich\nin its structure, unlike targets that are sparse in nature. Thus, it does not take\ninto account the task to be performed while learning about the data, saving\nfrom the need of human expertise that is required in supervised learning. More\non the topic of unsupervised versus supervised learning can be found in a blog\nby DeepMind.2\nIn this work, we would like to keep the best of both worlds, i.e. the success\nof convolutive models from CNN and the promises of unsupervised learning\nformulations. With this goal in mind, we developed convolutional transform\nlearning (CTL) [10]. This is a representation learning technique that learns a\nset of convolutional ﬁlters from the data without label information. Instead of\nlearning the ﬁlters (by backpropagating) from data labels, CTL learns them by\nminimizing a data ﬁdelity loss, thus making the technique unsupervised. CTL\nhas been shown to outperform several supervised and unsupervised learning\nschemes in the context of image classiﬁcation. In the present work, we propose\nto extend the shallow CTL version to deeper layers, with the aim to generate a\n1https://www.axios.com/artiﬁcial-intelligence-pioneer-says-we-need-to-start-over-\n1513305524-f619efbd-9db0-4947-a9b2-7a4c310a28fe.html\n2https://deepmind.com/blog/article/unsupervised-learning\n2\nfeature extraction strategy that is well suited for 1D time series analysis. This is\nthe ﬁrst major contribution of this work - deep convolutional transform learning.\nIn most applications, time series signals are multivariate, as they arise from\nmultiple sources/sensors. For example, biomedical signals like ECG and EEG\ncome from multiple leads; ﬁnancial data from stocks are recorded with diﬀerent\ninputs (open, close, low, high and net asset value), demand forecasting problems\nin smartgrids come with multiple types of data (power consumption, tempera-\nture, humidity, occupancy, etc.). In all such cases, the ﬁnal goal is to perform\nprediction/classiﬁcation task from such multivariate time series. We propose to\naddress such problem as one of feature fusion. The information from each of the\nsources will be processed by the proposed deep CTL pipeline, and the generated\ndeep features will be ﬁnally fused by an unsupervised fully connected layer. This\nis the second major contribution of this work - an unsupervised fusion framework\nwith deep CTL.\nThe resulting features can be used for diﬀerent applicative tasks. In this\npaper, we will focus on the applicative problem of ﬁnancial stock analysis. The\nultimate goal may be either to forecast the stock price (regression problem) or to\ndecide whether to buy or sell (classiﬁcation problem). Depending on the consid-\nered task, we can pass the generated features into suitable machine learning tool,\nthat may not be as data hungry as deep neural networks. Therefore, by adopting\nsuch a processing architecture, we expect to yield better results than traditional\ndeep learning especially in cases where access to labeled data is limited.\n2\nLiterature Review\n2.1\nCNN for Time Series Analysis\nLet us brieﬂy review and discuss CNN based methods for time series analysis.\nFor a more detailed review, the interested reader can peruse [22]. We mainly\nfocus on studies on stock forecasting as it will be our use case for experimental\nvalidation.\nThe traditional choice for processing time series with neural network is to\nadopt a recurrent neural network (RNN) architecture. Variants of RNN like\nlong-short term memory (LSTM) [38] and gated recurrent unit (GRU) [39] have\nbeen proposed. However, due to the complexity of training such networks via\nbackpropagation through time, they have been progressively replaced with 1D\nCNN [11]. For example, in [12], a generic time series analysis framework was built\nbased on LSTM, with assessed performance on the UCR time series classiﬁcation\ndatasets [14]. The later study from the same group [13], based on 1D CNN,\nshowed considerable improvement over the prior model on the same datasets.\nThere are also several studies that convert 1D time series data into a matrix\nform so as to be able to use 2D CNNs [15–17]. Each column of the matrix\ncorresponds to a subset of the 1D series within a given time window and the\nresulting matrix is processed as an image. The 2D CNN model has been especially\npopular in stock forecasting. In [17], the said techniques have been used on\n3\nstock prices for forecasting. A slightly diﬀerent input is used in [18]: instead\nof using the standard stock variables (open, close, high, low and NAV), it uses\nhigh frequency data for forecasting major points of inﬂection in the ﬁnancial\nmarket. In another work [19], a similar approach is used for modeling Exchange\nTraded Fund (ETF). It has been seen that the 2D CNN model performs the\nsame as LSTM or the standard multi-layer perceptron [20, 21]. The apparent\nlack of performance improvement in the aforementioned studies may be due to\nan incorrect choice of CNN model, since an inherently 1D time series is modeled\nas an image.\n2.2\nDeep Learning and Fusion\nWe now review existing works for processing multivariate data inputs, within the\ndeep learning framework. Since the present work aims at being applied to stock\nprice forecasting / trading, we will mostly focus our review on the multi-channel /\nmulti-sensor fusion framework. Multimodal data and fusion for image processing,\nless related to our work, will be mentioned at the end of this subsection for the\nsake of completeness.\nDeep learning has been widely used recently for analyzing multi-channel /\nmulti-sensor signals. In several of such studies, all the sensors are stacked one\nafter the other to form a matrix and 2D CNN is used for analyzing these signals.\nFor example, [23] uses this strategy for analyzing human activity recognition\nfrom multiple body sensors. It is important to distinguish such an approach\nfrom the aforementioned studies [17–21]. Here, the images are not formed from\nstacking windowed signals from the same signal one after the other, but by\nstacking signals from diﬀerent sensors. The said study [23] does not account for\nany temporal modeling; this is rectiﬁed in [24]. In there, 2D CNN is used on\na time series window; but the diﬀerent windows are ﬁnally processed by GRU,\nthus explicitly incorporating time series modeling. There is however no explicit\nfusion framework in [23, 24]. The information from raw multivariate signals is\nsimply fused to form matrices and treated by 2D convolutions. A true fusion\nframework was proposed in [25]. Each signal channel is processed by a deep 1D\nCNN and the output from the diﬀerent signal processing pipelines are then fused\nby a fully connected layer. Thus, the fusion is happening at the feature level and\nnot in the raw signal level as it was in [23, 24].\nAnother area that routinely uses deep learning based fusion is multi-modal\ndata processing. This area is not as well deﬁned as multi-channel data process-\ning; nevertheless, we will brieﬂy discuss some studies on this topic. In [26] a\nfusion scheme is shown for audio-visual analysis that uses a fusion scheme for\ndeep belief network (DBN) and stacked autoencoder (SAE) for fusing audio\nand video channels. Each channel is processed separately and connected by a\nfully connected layer to produce fused features. These fused features are further\nprocessed for inference. We can also mention the work on video based action\nrecognition addressed in [27], which proposes a fusion scheme for incorporating\ntemporal information (processed by CNN) and spatial information (also pro-\ncessed by CNN).\n4\nThere are several other such works on image analysis [28–30]. In [28], a fusion\nscheme is proposed for processing color and depth information (via 3D and\n2D convolutions respectively) with the objective of action recognition. In [29],\nit was shown that by fusing hyperspectral data (high spatial resolution) with\nLidar (depth information), better classiﬁcation results can be achieved. In [30],\nit was shown that by fusing deeply learnt features (from CNN) with handcrafted\nfeatures via a fully connected layer, can improve analysis tasks. In this work, our\ninterest lies in the ﬁrst problem; that of inference from 1d / time-series multi-\nchannel signals. To the best of our knowledge, all prior deep learning based\nstudies on this topic are supervised. In keeping with the vision of Hinton and\nothers, our goal is to develop an unsupervised fusion framework using deeply\nlearn convolutive ﬁlters.\n2.3\nConvolutional Transform Learning\nConvolutional Transform Learning (CTL) has been introduced in our seminal\npaper [10]. Since it is a recent work, we present it in detail in the current paper, to\nmake it self-content. CTL learns a set of ﬁlters (tm)1≤m≤M operated on observed\nsamples\n\u0000s(k)\u0001\n1≤k≤K to generate a set of features (x(k)\nm )1≤m≤M,1≤k≤K. Formally,\nthe inherent learning model is expressed through convolution operations deﬁned\nas\n(∀m ∈{1, . . . , M} , ∀k ∈{1, . . . , K})\ntm ∗s(k) = x(k)\nm .\n(1)\nFollowing the original study on transform learning [34], a sparsity penalty is\nimposed on the features for improving representation ability and limit overﬁtting\nissues. Moreover, in the same line as CNN models, the non-negativity constraint\nis imposed on the features. Training then consists of learning the convolutional\nﬁlters and the representation coeﬃcients from the data. This is expressed as the\nthe following optimization problem\nminimize\n(tm)m,(x(k)\nm )m,k\n1\n2\nK\nX\nk=1\nM\nX\nm=1\n\u0010\n∥tm ∗s(k) −x(k)\nm ∥2\n2 + ψ(x(k)\nm )\n\u0011\n+ µ\nM\nX\nm=1\n∥tm∥2\n2 −λ log det ([t1|. . . |tM]),\n(2)\nwhere ψ is a suitable penalization function. Note that the regularization term\n“µ ∥·∥2\nF −λ log det” ensures that the learnt ﬁlters are unique, something that is\nnot guaranteed in CNN. Let us introduce the matrix notation\nT ∗S −X =\n\n\nt1 ∗s(1) −x(1)\n1\n. . . tM ∗s(1) −x(1)\nM\n...\n...\n...\nt1 ∗s(K) −x(K)\n1\n. . . tM ∗s(K) −x(K)\nM\n\n\n(3)\n5\nwhere T =\n\u0002t1 . . . tM\n\u0003\n, S =\n\u0002\ns(1) . . . s(K)\u0003⊤, and X =\nh\nx(k)\n1\n. . . x(k)\nM\ni\n1≤k≤K.\nThe cost function in Problem (2) can be compactly rewritten as5\nF(T, X) = 1\n2 ∥T ∗S −X∥2\nF + Ψ(X) + µ ∥T∥2\nF −λ log det (T) ,\n(4)\nwhere Ψ applies the penalty term ψ column-wise on X.\nA local minimizer to (4) can be reached eﬃciently using the alternating prox-\nimal algorithm [31–33], which alternates between proximal updates on variables\nT and X. More precisely, set a Hilbert space (H, ∥·∥), and deﬁne the proxim-\nity operator [21] at ˜x ∈H of a proper lower-semi-continuous convex function\nϕ : H →] −∞, +∞] as\nproxϕ(˜x) = arg min\nx∈H\nϕ(x) + 1\n2 ∥x −˜x∥2 .\n(5)\nThen, the alternating proximal algorithm reads\nFor n = 0, 1, ...\n\u0016 T [n+1] = proxγ1F (·,X[n])\n\u0000T [n]\u0001\nX[n+1] = proxγ2F (T [n+1],·)\n\u0000X[n]\u0001\n(6)\nwith initializations T [0], X[0] and γ1, γ2 positive constants. For more details on\nthe derivations and the convergence guarantees, the readers can refer to [10].\n3\nFusion based on Deep Convolutional Transform\nLearning\nIn this section, we discuss our proposed formulation. First, we extend the afore-\nmentioned CTL formulation to a deeper version. Next, we develop the fusion\nframework based on transform learning, leading to our DeConFuse3 strategy.\n3.1\nDeep Convolutional Transform Learning\nDeep CTL consists of stacking multiple convolutional layers on top of each other\nto generate the features, as shown in Figure 1. To learn all the variables in an\nend-to-end fashion, deep CTL relies on the key property that the solution b\nX to\nthe CTL problem, assuming ﬁxed ﬁlters T, can be reformulated as the simple\napplication of an element-wise activation function, that is\nargmin\nX\nF(T, X) = φ(T ∗S),\n(7)\n5Note that T is not necessarily a square matrix. By an abuse of notation, we deﬁne\nthe “log-det” of a rectangular matrix as the sum of logarithms of its singular values.\n3Code available at: https://github.com/pooja290992/DeConFuse.git\n6\nFig. 1: Deep CTL architecture. The illustration is given for L = 2 layers, with\nthe ﬁrst layer T1 composed of M1 = 4 ﬁlters of size 5 × 1, and the second layer\ncomposed of M2 = 8 ﬁlters of size 3 × 1.\nwith φ the proximity operator of Ψ [41]. For example, if Ψ is the indicator\nfunction of the positive orthant, then φ identiﬁes with the famous rectiﬁed linear\nunit (ReLU) activation function. Many other examples are provided in [41].\nConsequently, deep features can be computed by stacking many such layers\n(∀ℓ∈{1, . . . , L −1})\nXℓ= φℓ(Tℓ∗Xℓ−1),\n(8)\nwhere X0 = S and φℓa given activation function for layer ℓ.\nPutting all together, deep CTL amounts to\nminimize\nT1,...,TL,X Fconv(T1, . . . , TL, X | S)\n(9)\nwhere\nFconv(T1, . . . , TL, X | S) = 1\n2∥TL ∗φL−1(TL−1 ∗. . . φ1(T1 ∗S)) −X∥2\nF\n+ Ψ(X) +\nL\nX\nℓ=1\n(µ||Tℓ||2\nF −λ log det(Tℓ)).\n(10)\nThis is a direct extension of the one-layer formulation in (4).\n3.2\nMulti-Channel Fusion Framework\nWe now propose a fusion framework to learn in an unsupervised fashion a suitable\nrepresentation of multi-channel data that can then be utilised for a multitude\nof tasks. This framework takes the channels of input data samples to separate\nbranches of convolutional layers, leading to multiple sets of channel-wise features.\nThese decoupled features are then concatenated and passed to a fully-connected\nlayer, which yields a unique set of coupled features. The complete architecture,\ncalled DeConFuse, is shown in Fig 2.\nSince we have multi-channel data, for each channel c ∈{1, . . . , C}, we learn a\ndiﬀerent set of convolutional ﬁlters T (c)\n1 , . . . , T (c)\nL\nand features X(c). At the same\n7\ntime, we learn the (not convolutional) linear transform eT = ( eTc)1≤c≤C to fuse\nthe channel-wise features X = (X(c))1≤c≤C, along with the corresponding fused\nfeatures Z, which constitute the ﬁnal output of the proposed DeConFuse model,\nas shown in Fig 2. This leads to the joint optimization problem\nminimize\nT,X, e\nT ,Z\nFfusion( eT, Z, X) +\nC\nX\nc=1\nFconv(T (c)\n1 , . . . , T (c)\nL , X(c) | S(c))\n|\n{z\n}\nJ(T,X, e\nT ,Z)\n(11)\nwhere\nFfusion( eT, Z, X) = 1\n2\n\r\r\rZ−\nC\nX\nc=1\nﬂat(X(c)) eTc\n\r\r\r\n2\nF +ι+(Z)+\nC\nX\nc=1\n(µ∥eTc∥2\nF −λ log det( eTc)),\n(12)\nwhere the operator “ﬂat” transforms X(c) into a matrix where each row contains\nthe “ﬂattened” features of a sample.\nTo summarize, our formulation aims to jointly train the channel-wise con-\nvolutional ﬁlters T (c)\nℓ\nand the fusion coeﬃcients eT in an end-to-end fashion.\nWe explicitly learn the features X and Z subject to non-negativity constraints\nso as to avoid trivial solutions and make our approach completely unsupervised.\nMoreover, the “log-det” regularization on both T (c)\nℓ\nand eT breaks symmetry and\nforces diversity in the learnt transforms, whereas the Frobenius regularization\nensures that the transform coeﬃcients are bounded.\n3.3\nOptimization algorithm\nAs for the solution of Problem (11), we remark that all terms of the cost function\nare diﬀerentiable, except the indicator function of the non-negativity constraint.\nWe can, therefore, ﬁnd a local minimizer to (11) by employing the projected\ngradient descent, whose iterations read\nFor n = 0, 1, ...\n\nT [n+1] = T [n] −γ∇T J(T [n], X[n], eT [n], Z[n])\nX[n+1] = P+(X[n] −γ∇XJ(T [n], X[n], eT [n], Z[n]))\neT [n+1] = eT [n] −γ∇e\nT J(T [n], X[n], eT [n], Z[n])\nZ[n+1] = P+(Z[n] −γ∇ZJ(T [n], X[n], eT [n], Z[n]))\n(13)\nwith initialization T [0], X[0], eT [0], Z[0], γ > 0, and P+ = max{·, 0}. In practice,\nwe make use of accelerated strategies [36] within each step of this algorithm to\nspeed up learning.\nThere are two notable advantages with the proposed optimization approach.\nFirstly, we rely on automatic diﬀerentiation [37] and stochastic gradient approx-\nimations to eﬃciently solve Problem (11). Secondly, we are not limited to ReLU\nactivation in (8), but rather we can use more advanced ones, such as SELU [35].\nThis is beneﬁcial for the performance, as shown by our numerical results.\n8\nFig. 2: DeConFuse architecture.\n3.4\nComputational Complexity of Proposed Framework -\nDeConFuse\nTable 1 summarizes the computational complexity of DeconFuse architecture,\nboth for training and test phases. Speciﬁcally, it is reported the cost incurred for\nevery input sample at each iteration of gradient descent in the training phase,\nand for the output computation in testing phase. The computational complexity\nof DeConFuse architecture is comparable to a regular CNN. The only addition\nis the log-det regularization, which requires to compute the truncated singular\nvalue decomposition of T (c)\nℓ\nand eTc. However, as the size of these matrices is\ndetermined by the ﬁlter size, the number of ﬁlters, and the number of output\nfeatures per sample, the training complexity is not worse than that of a CNN.\n9\nTable 1: Time complexity in training and test phases (for one input\nsample)\nPhase\nSteps\nTime Complexity Dimension\nDescription\nTraining 1. Convolution layers\nO(PℓDℓMℓC)\nphase\n2. Fully-connected (f.-c.) layer\nO(I2C2)\nS(c) ∈RK×D\n3. Frobenius norm on conv. layers\nO(PℓMℓC)\nT (c)\nℓ\n∈RPℓ×Mℓ\n4. Frobenius norm on f.-c. layer\nO(I2C2)\nﬂat(X(c)) ∈RK×I\n5. log-det on conv. layers\nO(P 2\nℓMℓC)\nf\nTc ∈RI×O\n6. log-det on f.-c. layer\nO(I3C2)\nTesting\nphase\nStep 1. + Step 2.\nStep 1. + Step 2.\nD = input sample size – K = num. of samples – C = num. of channels – L = num. of layers\nPℓ= ﬁlter size at layer ℓ– Mℓ= num. of ﬁlters at layer ℓ– Dℓ= output sample size at layer ℓ\nI = DLML is the num. of output features per sample and per channel at last convolution layer\nO = αIC (with α ∈]0, 1]) is the num. of output features per sample at the fully-connected layer\n4\nExperimental Evaluation\nWe carry out experiments on the real world problem of stock forecasting and\ntrading. The problem of stock forecasting is a regression problem aiming at\nestimating the price of a stock at a future date (next day for our problem) given\ninputs till the current date. Stock trading is a classiﬁcation problem, where the\ndecision whether to buy or sell a stock has to be taken at each time. The two\nproblems are related by the fact that simple logic dictates that if the price of a\nstock at a later date is expected to increase, the stock must be bought; and if\nthe stock price is expected to go down, the stock must be sold.\nWe will use the ﬁve raw inputs for both the tasks, namely open price, close\nprice, high, low and net asset value (NAV). One could compute technical in-\ndicators based on the raw inputs [17] but, in keeping with the essence of true\nrepresentation learning, we chose to stay with those raw values. Each of the ﬁve\ninputs is processed by a separate 1D processing pipeline. Each of the pipelines\nproduces a ﬂattened output (Fig. 1). The ﬂattened outputs are then concate-\nnated and fed into the Transform Learning layer acting as the fully connected\nlayer (Fig. 2) for fusion. While our processing pipeline ends here (being unsuper-\nvised), the benchmark techniques are supervised and have an output node. The\nnode is binary (buy / sell) for classiﬁcation and real valued for regression. More\nprecisely, we will compare with two state-of-the-art time series analysis models,\nnamely TimeNet [12] and ConvTimeNet [13]. In the former, the processing in-\ndividual processing pipelines are based on LSTM and in the later they use 1D\nCNN.\nWe make use of a real dataset from the National Stock Exchange (NSE) of\nIndia. The dataset contains information of 150 symbols between 2014 and 2018;\nthese stocks were chosen after ﬁltering out stocks that had less than three years of\ndata. The companies available in the dataset are from various sectors such as IT\n10\n(e.g., TCS, INFY), automobile (e.g., HEROMOTOCO, TATAMOTORS), bank\n(e.g., HDFCBANK, ICICIBANK), coal and petroleum (e.g., OIL, ONGC), steel\n(e.g., JSWSTEEL, TATASTEEL), construction (e.g., ABIRLANUVO, ACC),\npublic sector units (e.g., POWERGRID, GAIL). The detailed architectures for\neach tested techniques, namely DeConFuse, ConvTimeNet and TimeNet are pre-\nsented in the Table 2. For DeConFuse, TimeNet and ConvTimeNet, we have\ntuned the architectures to yield the best performance and have randomly ini-\ntialized the weights for each stock’s training.\nTable 2: Description of compared models\nMethod\nArchitecture Description\nOther Parameters\nDeConFuse\n5 ×\n\n\n\n\n\n\n\n\n\nlayer1 : 1D Conv(1, 4, 5, 1, 2)1\nMaxpool(2, 2)2\nSELU\nlayer2 : 1D Conv(5, 8, 3, 1, 1)1\nlayer3 : Fully Connected\nLearning Rate = 0.001,\nµ = 0.01, ϵ = 0.0001\nOptimizer Used: Adam\n**with parameters**\n(β1, β2) = (0.9, 0.999),\nweight decay = 5e-5,\nepsilon = 1e-8\nConvTimeNet 5×\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlayer1 : 1D Convolution(1, 32, 9, 1, 4)1\nBatch Normalization + SELU\nlayer2 : 1D Convolution(32, 32, 3, 1, 1)1\nBatch Normalization + SELU + SC3\nlayer3 : 1D Convolution(32, 64, 9, 1, 4)1\nBatch Normalization + SELU\nlayer4 : 1D Convolution(64, 64, 3, 1, 1)1\nBatch Normalization + SELU + SC3\nlayer3 : Global Average Pooling\nlayer4 : Fully Connected\nFor Trading, added layer5 : Softmax\nFor Forecasting:\nLearning Rate = 0.001,\nFor Trading:\nLearning Rate = 0.0001,\nOptimizer Used: Adam\n**with parameters**\n(β1, β2) = (0.9, 0.999),\nweight decay = 1e-4,\nepsilon = 1e-8\nTimeNet\n5 ×\n(\nlayer1 : LSTM unit(1, 12, 2, True)4\nlayer2 : Global Average Pooling\nlayer3 : Fully Connected\nFor Trading, added layer4 : Softmax\nFor Forecasting:\nLearning Rate = 0.001,\nFor Trading:\nLearning Rate = 0.0005,\nOptimizer Used: Adam\n**with parameters**\n(β1, β2) = (0.9, 0.999),\nweight decay = 5e-5,\nepsilon = 1e-8\n1 (in˙planes, out˙planes, kernel size, stride, padding)\n2 (kernel size, stride)\n3 SC - Skip-Connection\n4 (input size,hidden size,#layers,bidirectional)\n11\n4.1\nStock Forecasting – Regression\nLet us start with the stock forecasting problem. We feed the generated un-\nsupervised features from the proposed architecture into an external regressor,\nnamely ridge regression. Evaluation is carried out in terms of mean absolute\nerror (MAE) between the predicted and actual stock prices for all 150 stocks.\nThe stock forecasting results are shown in Table 5 in appendix section A. The\nMAE for individual stocks are presented for each of close price, open price, high\nprice, low price and net asset value.\nFrom Table 5, it can be seen that the MAE values reached for the proposed\nDeConFuse solution for the four ﬁrst prices (open, close, high, low) are excep-\ntionally good for all of the 150 stocks. Regarding NAV prediction, the proposed\nmethod performs extremely well for 128 stocks. For the remaining 22 stocks,\nthere are 13 stocks, highlighted in red, for which DeConFuse does not give the\nlowest MAE but it is still very close to the best results given by the TimeNet\napproach.\nFor a concise summary of the results, the average values over all stocks are\nshown in Table 3. For a concise summary of the results, the average values over\nall stocks are shown in Table 3.\nTable 3: Summary of Forecasting Results\nMethod\nClose Open High Low NAV\nDeConFuse\n0.016 0.007 0.012 0.013 0.410\nConvTimeNet 1.550 1.550 1.530 1.560 2.350\nTimeNet\n0.295 0.295 0.294 0.295 0.511\nFrom the summary Table 3, it can be observed that our error is more than\nan order of magnitude better than the state-of-the-arts. The plots for one of the\nregressed prices (close price) for some examples of stocks in Fig. 3 show that the\npredicted close prices from DeConFuse are closer to the true close prices than\nbenchmarks predictions.\n4.2\nStock Trading – Classiﬁcation\nWe now focus on the stock trading task. In this case, the generated unsupervised\nfeatures from DeConFuse are inputs to an external classiﬁer based on Random\nDecision Forest (RDF) with 5 decision tree classiﬁers and depth 3. Even though\nwe used this architecture, we found that the results from RDF are robust to\nchanges in architecture. This is a well known phenomenon about RDFs [40]. We\nevaluate the results in terms of precision, recall, F1 score, and area under the\nROC curve (AUC). From the ﬁnancial viewpoint, we also calculate annualized\nreturns (AR) using the predicted trading signals / labels as well as using true\ntrading signals / labels named as Predicted AR and True AR respectively. The\n12\n(a) ABIRLANUVO and ALBK\n(b) JPASSOCIAT and JSWENERGY\nFig. 3: Stock Forecasting Performance\nstarting capital used for calculating AR values for every stock is Rs. 1,00,000\nand the transaction charges are Rs 10. The stock trading results are shown in\nthe Table 6 in appendix section B.\nCertain results from Table 6 are highlighted in bold or red. The ﬁrst set of re-\nsults, marked in bold, are the ones where one of the techniques for each metric\ngives the best performance for each stock. The proposed solution DeConFuse\ngives the best results for 89 stocks for precision score, 85 stocks for recall score,\n125 stocks for F1 score, 91 stocks for AUC measure, and 56 stocks in case of\nthe AR metric. The other set marked in red highlights the cases where DeCon-\nfuse has not performed the best but performs nearly equal (here, a diﬀerence of\nmaximum 0.05 in the metric is considered) to the best performance given by one\nof the benchmarks i.e. DeConFuse gives the next best performance. We noticed\n13\nthat there are 24 stocks for which DeConFuse gives the next best precision met-\nric value. Likewise, 18 stocks in case of recall, 22 stocks for F1 score, 26 stocks\nfor AUC values, and 1 stock in case of AR. Overall, DeConfuse reaches very sat-\nisfying performance over the benchmark techniques. This is also corroborated\nfrom the summary of trading results in Table 4.\nTable 4: Summary of Trading Results\nMethod\nPrecision Recall\nF1\nScore\nAUC MAE\nAR\nDeConFuse\n0.520\n0.810 0.628 0.543 17.350\nConvTimeNet\n0.510\n0.457\n0.413\n0.524 19.410\nTimeNet\n0.470\n0.648\n0.490\n0.513 18.760\nWe also display empirical convergence plots for few stocks, namely RELIANCE,\nONGC, HINDUNILVR and ICICIBANK, in Fig.4. We can see that the training\nloss decreases to a point of stability for each example.\n14\n(a) RELIANCE and ONGC\n(b) HINDUNILVR and ICICIBANK\nFig. 4: Empirical Convergence Plots\n5\nConclusion\nIn this work, we propose DeConFuse, a deep fusion end-to-end framework for\nthe processing of 1D multi-channel data. Unlike other deep learning models, our\nframework is unsupervised. It is based on a novel deep version of our recently\nproposed convolutional transform learning model. We have applied the proposed\nmodel for stock forecasting / trading leading to very good performance. The\nframework is generic enough to handle other multi-channel fusion problems as\nwell.\nThe advantage of our framework is its ability to learn in an unsupervised\nfashion. For example, consider the problem we address. For traditional deep\nlearning based models, we need to retrain to deep networks for regression and\nclassiﬁcation. But we can reuse our features for both the tasks, without the\nrequirement of re-training, for speciﬁc tasks. This has advantages in other areas\nas well. For example, one can either do ischemia detection, i.e. detect whether\none is having a stroke at the current time instant (from EEG); or one can do\nischemia prediction, i.e. forecast if a stroke is going to happen. In standard\n15\ndeep learning, two networks need to be retrained and tuned to tackle these two\nproblems. With our proposed method, there is no need for this double eﬀort.\nIn the future, we would work on extending the framework for supervised /\nsemi-supervised formulations. We believe that the semi-supervised formulation\nwill be of immense practical importance. We would also like to extend it to 2D\nconvolutions in order to handle image data.\n6\nDeclarations\n6.1\nList of abbreviations\n– TL : Transform Learning\n– CTL : Convolutional Transform Learning\n– CNN : Convolutional Neural Network\n– LSTM : Long Short Term Memory\n– GRU : Gated Recurrent Unit\n– ReLU : Rectiﬁed Linear Unit\n– SELU : Scaled Exponential Linear Units\n– NSE : National Stock Exchange\n– AUC : Area Under Curve\n– ROC : Receiver Operating Characteristics\n– NAV : Net Asset Value\n– RDF : Random Decision Forest\n– EEG : Electroencephalogram\n– ECG : Electrocardiogram\n– AR : Annualized Returns\n– MAE : Mean Absolute Error\n6.2\nEthics approval and consent to participate\nNot Applicable.\n6.3\nConsent for publication\nNot Applicable.\n6.4\nAvailability of data and materials\nThe dataset used is a real dataset of the Indian National Stock Exchange (NSE)\nof past four years and is publicly available. We have shared the data with our\nimplementation available at: https://github.com/pooja290992/DeConFuse.git.\n6.5\nCompeting interests\nThe authors declare that they have no competing interests.\n16\n6.6\nFunding\nThis work was supported by the CNRS-CEFIPRA project under grant NextGenBP\nPRC2017.\n6.7\nAuthors’ contributions\n– Ms. Pooja Gupta has introduced the CTL within the fusion framework and\nperformed all the numerical experiments.\n– Ms. Jyoti Maggu originally formulated the transform learning model and the\ndeep version for it.\n– Dr. Angshul Majumdar has helped with the model formulation and the as-\nsessment of the experimental part.\n– Dr. Emilie Chouzenoux and Dr. Giovanni Chierchia have contributed in the\nformulation of the model and the optimization algorithms.\n– All the authors have contributed to the writing and proofreading of the\npaper.\n17\nBibliography\n[1] Kriegeskorte, N., 2015. Deep neural networks: a new framework for modeling\nbiological vision and brain information processing. Annual review of vision\nscience, 1, (pp. 417-446).\n[2] Guillery, R.W. and Sherman, S.M., 2002. Thalamic relay functions and their\nrole in corticocortical communication: generalizations from the visual system.\nNeuron, 33(2), (pp.163-175).\n[3] Cudeiro, J. and Sillito, A.M., 2006. Looking back: corticothalamic feedback\nand early visual processing. Trends in neurosciences, 29(6), (pp.298-306).\n[4] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan,\nD., Vanhoucke, V. and Rabinovich, A., 2015. Going deeper with convolu-\ntions. In Proceedings of the IEEE conference on computer vision and pattern\nrecognition (pp. 1-9).\n[5] Daubechies, I., DeVore, R., Foucart, S., Hanin, B. and Petrova, G.,\n2019. Nonlinear approximation and (deep) relu networks. arXiv preprint\narXiv:1905.02199.\n[6] Petersen, P. and Voigtlaender, F., 2018. Optimal approximation of piecewise\nsmooth functions using deep ReLU neural networks. Neural Networks, 108,\n(pp. 296-330).\n[7] Schroﬀ, F., Kalenichenko, D. and Philbin, J., 2015. Facenet: A uniﬁed em-\nbedding for face recognition and clustering. In Proceedings of the IEEE con-\nference on computer vision and pattern recognition (pp. 815-823).\n[8] Taigman, Y., Yang, M., Ranzato, M.A. and Wolf, L., 2014. Deepface: close\nthe gap to human-level performance in face veriﬁcation. In Proceedings of\nthe IEEE conference on computer vision and pattern recognition (pp. 1701-\n1708).\n[9] Nagpal, S., Singh, M., Singh, R., Vatsa, M., Noore, A. and Majumdar, A.,\n2017. Face sketch matching via coupled deep transform learning. In Pro-\nceedings of the IEEE International Conference on Computer Vision (pp.\n5419-5428).\n[10] Maggu, J., Chouzenoux, E., Chierchia, G. and Majumdar, A., 2018, De-\ncember. Convolutional Transform learning. In International Conference on\nNeural Information Processing (pp. 162-174). Springer, Cham.\n[11] Wang, Z., Yan, W. and Oates, T., 2017, May. Time series classiﬁcation from\nscratch with deep neural networks: A strong baseline. In 2017 international\njoint conference on neural networks (IJCNN) (pp. 1578-1585), IEEE.\n[12] Malhotra, P., TV, V., Vig, L., Agarwal, P. and Shroﬀ, G., 2017. TimeNet:\nPre-trained deep recurrent neural network for time series classiﬁcation. arXiv\npreprint arXiv:1706.08838.\n[13] Kashiparekh, K., Narwariya, J., Malhotra, P., Vig, L. and Shroﬀ, G., 2019.\nConvTimeNet: A Pre-trained Deep Convolutional Neural Network for Time\nSeries Classiﬁcation. arXiv preprint arXiv:1904.12546.\n[14] https://www.cs.ucr.edu/∼eamonn/time series data/\n[15] Hatami, N., Gavet, Y. and Debayle, J., 2018, April. Classiﬁcation of time-\nseries images using deep convolutional neural networks. In Tenth Interna-\ntional Conference on Machine Vision (ICMV 2017), vol. 10696, p. 106960Y.\nInternational Society for Optics and Photonics.\n[16] Wang, Z. and Oates, T., 2015, June. Imaging time-series to improve clas-\nsiﬁcation and imputation. In Twenty-Fourth International Joint Conference\non Artiﬁcial Intelligence.\n[17] Sezer, O.B. and Ozbayoglu, A.M., 2018. Algorithmic ﬁnancial trading with\ndeep convolutional neural networks: Time series to image conversion ap-\nproach. Applied Soft Computing, vol. 70, (pp.525-538).\n[18] Tsantekidis, A., Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M. and\nIosiﬁdis, A., 2017, July. Forecasting stock prices from the limit order book\nusing convolutional neural networks. In 2017 IEEE 19th Conference on Busi-\nness Informatics (CBI) vol. 1, (pp. 7-12). IEEE.\n[19] Gudelek, M.U., Boluk, S.A. and Ozbayoglu, A.M., 2017, November. A deep\nlearning based stock trading model with 2-D CNN trend detection. In 2017\nIEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1-8).\nIEEE.\n[20] Ravishankar S. and Bresler Y., May,2015. Sparsifying Transform Learn-\ning With Eﬃcient Optimal Updates and Convergence Guarantees. in IEEE\nTransactions on Signal Processing, vol. 63, no. 9, (pp. 2389-2404).\n[21] Combettes P.L. and Pesquet JC., 2011. Proximal Splitting Methods in Sig-\nnal Processing. In: Bauschke H., Burachik R., Combettes P., Elser V., Luke\nD., Wolkowicz H. (eds) Fixed-Point Algorithms for Inverse Problems in Sci-\nence and Engineering. Springer Optimization and Its Applications, vol 49.\nSpringer, New York, NY.\n[22] Fawaz, H.I., Forestier, G., Weber, J., Idoumghar, L. and Muller, P.A., 2019.\nDeep learning for time series classiﬁcation: a review. Data Mining and Knowl-\nedge Discovery, 33(4), (pp. 917-963).\n[23] Yang, J., Nguyen, M.N., San, P.P., Li, X.L. and Krishnaswamy, S., 2015,\nJune. Deep convolutional neural networks on multichannel time series for\nhuman activity recognition. In Twenty-Fourth International Joint Conference\non Artiﬁcial Intelligence.\n[24] Yao, S., Hu, S., Zhao, Y., Zhang, A. and Abdelzaher, T., 2017, April.\nDeepsense: A uniﬁed deep learning framework for time-series mobile sens-\ning data processing. In Proceedings of the 26th International Conference on\nWorld Wide Web (pp. 351-360).\n[25] Zheng, Y., Liu, Q., Chen, E., Ge, Y. and Zhao, J.L., 2014, June. Time\nseries classiﬁcation using multi-channels deep convolutional neural networks.\nIn International Conference on Web-Age Information Management (pp. 298-\n310). Springer, Cham.\n[26] Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H. and Ng, A.Y., 2011. Mul-\ntimodal deep learning. In Proceedings of the 28th international conference\non machine learning (ICML-11) (pp. 689-696).\n19\n[27] Feichtenhofer, C., Pinz, A. and Zisserman, A., 2016. Convolutional two-\nstream network fusion for video action recognition. In Proceedings of the\nIEEE conference on computer vision and pattern recognition (pp. 1933-1941).\n[28] Eitel, A., Springenberg, J.T., Spinello, L., Riedmiller, M. and Burgard, W.,\n2015, September. Multimodal deep learning for robust RGB-D object recog-\nnition. In 2015 IEEE/RSJ International Conference on Intelligent Robots\nand Systems (IROS) (pp. 681-687). IEEE.\n[29] Chen, Y., Li, C., Ghamisi, P., Jia, X. and Gu, Y., 2017. Deep fusion of\nremote sensing data for accurate classiﬁcation. IEEE Geoscience and Remote\nSensing Letters, 14(8), (pp.1253-1257).\n[30] Antropova, N., Huynh, B.Q. and Giger, M.L., 2017. A deep feature fu-\nsion methodology for breast cancer diagnosis demonstrated on three imaging\nmodality datasets. Medical physics, vol. 44(10), (pp. 5162-5171).\n[31] H. Attouch, J. Bolte, and B. F. Svaiter. 2011. Convergence of descent\nmethods for semi-algebraic and tame problems: proximal algorithms,forward-\nbackward splitting, and regularized Gauss-Seidel methods.Mathematical\nProgramming137 (Feb. 2011), (pp. 91–129).\n[32] Chouzenoux, E. and Pesquet, J.C. and Repetti, A., 2016. A Block Co-\nordinate Variable Metric Forward-Backward Algorithm. Journal on Global\nOptimization 66, 3(2016), (pp. 457-485).\n[33] J. Bolte, S. Sabach, and M. Teboulle, 2014. Proximal alternating linearized\nminimization for nonconvex and non-smooth problems. Mathematical Pro-\ngramming, vol.146, no. 1-2, (pp. 459–494).\n[34] S. Ravishankar and Y. Bresler,2012. Learning sparsifying transforms. IEEE\nTransactions on Signal Processing,vol. 61(5), (pp. 1072–1086).\n[35] G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter, 2017. Self-\nnormalizing neural networks. Advances in Neural Information Processing\nSystems 30, (pp. 971–980).\n[36] S.J. Reddi, S. Kale, and S. Kumar, 2018. On the convergence of adam and\nbeyond. Proc. ICLR.\n[37] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin,\nA. Desmaison, L. Antiga, and A. Lerer, 2017. Automatic diﬀerentiation in\nPyTorch. NIPS AutodiﬀWorkshop.\n[38] Hochreiter, S. and Schmidhuber, J., 1997. Long short-term memory. Neural\ncomputation, 9(8), (pp. 1735-1780).\n[39] Chung, J., Gulcehre, C., Cho, K. and Bengio, Y., 2015, June. Gated feed-\nback recurrent neural networks. In International Conference on Machine\nLearning (pp. 2067-2075).\n[40] Criminisi, A., Shotton, J. and Konukoglu, E., 2012. Decision forests: A\nuniﬁed framework for classiﬁcation, regression, density estimation, manifold\nlearning and semi-supervised learning. Foundations and Trends in Computer\nGraphics and Vision, 7(2–3), (pp. 81-227).\n[41] Combettes, P.L. and Pesquet, J.-C., 2018. Deep Neural Network Struc-\ntures Solving Variational Inequalities. Set-Valued and Variational Analysis,\nhttps://arxiv.org/abs/1808.07526.\n20\nAppendix\n21\nA\nDetailed Stock Forecasting Results\nTable 5: Stock-wise Forecasting Results\nStock Name\nMethod\nMAE\nClose\nMAE\nOpen\nMAE\nHigh\nMAE\nLow\nMAE\nNAV\nABIRLANUVO\nDeConFuse\n0.021\n0.015\n0.019\n0.017\n0.416\nConvTimeNet\n0.204\n0.212\n0.219\n0.195\n1.804\nTimeNet\n0.112\n0.111\n0.111\n0.112\n0.467\nACC\nDeConFuse\n0.012\n0.016\n0.014\n0.017\n0.580\nConvTimeNet\n0.158\n0.161\n0.159\n0.158\n0.765\nTimeNet\n0.116\n0.116\n0.115\n0.118\n0.388\nADANIENT\nDeConFuse\n0.041\n0.015\n0.024\n0.038\n0.359\nConvTimeNet\n4.656\n4.795\n4.654\n4.800\n0.748\nTimeNet\n0.538\n0.549\n0.540\n0.551\n0.475\nADANIPORTS\nDeConFuse\n0.012\n0.005\n0.009\n0.010\n0.391\nConvTimeNet\n0.124\n0.122\n0.122\n0.123\n1.258\nTimeNet\n0.283\n0.283\n0.280\n0.285\n0.43\nADANIPOWER\nDeConFuse\n0.026\n0.010\n0.019\n0.020\n0.405\nConvTimeNet\n0.610\n0.600\n0.590\n0.602\n1.796\nTimeNet\n0.205\n0.205\n0.204\n0.206\n0.448\nAJANTPHARM\nDeConFuse\n0.016\n0.007\n0.012\n0.012\n0.418\nConvTimeNet\n0.401\n0.374\n0.384\n0.400\n0.867\nTimeNet\n0.262\n0.261\n0.258\n0.264\n0.480\nALBK\nDeConFuse\n0.020\n0.009\n0.015\n0.015\n0.362\nConvTimeNet\n0.908\n1.029\n0.995\n0.953\n1.020\nTimeNet\n0.184\n0.181\n0.180\n0.185\n0.448\nAMARAJABAT\nDeConFuse\n0.015\n0.007\n0.011\n0.012\n0.435\nConvTimeNet\n0.047\n0.046\n0.047\n0.047\n0.631\nTimeNet\n0.087\n0.088\n0.086\n0.089\n0.386\nAMBUJACEM\nDeConFuse\n0.012\n0.005\n0.008\n0.009\n0.355\nConvTimeNet\n2.283\n2.272\n2.280\n2.267\n3.132\nTimeNet\n0.106\n0.107\n0.105\n0.107\n0.414\nANDHRABANK\nDeConFuse\n0.022\n0.009\n0.016\n0.016\n0.373\nConvTimeNet\n5.095\n5.074\n5.008\n5.158\n2.200\nTimeNet\n0.144\n0.140\n0.138\n0.148\n0.471\nAPOLLOHOSP\nDeConFuse\n0.025\n0.009\n0.015\n0.021\n0.687\nConvTimeNet\n0.268\n0.240\n0.258\n0.254\n0.719\nTimeNet\n0.153\n0.155\n0.151\n0.156\n0.536\nAPOLLOTYRE\nDeConFuse\n0.014\n0.006\n0.010\n0.011\n0.391\nConvTimeNet\n0.552\n0.547\n0.543\n0.558\n1.267\nTimeNet\n0.283\n0.283\n0.281\n0.284\n0.346\nARVIND\nDeConFuse\n0.015\n0.006\n0.010\n0.011\n0.423\nConvTimeNet\n0.302\n0.278\n0.294\n0.290\n1.251\nTimeNet\n0.268\n0.268\n0.267\n0.269\n0.465\n22\nASHOKLEY\nDeConFuse\n0.017\n0.005\n0.010\n0.013\n0.376\nConvTimeNet\n1.042\n1.018\n0.987\n1.096\n0.586\nTimeNet\n0.343\n0.343\n0.344\n0.342\n0.451\nASIANPAINT\nDeConFuse\n0.008\n0.004\n0.007\n0.006\n0.370\nConvTimeNet\n0.816\n0.801\n0.804\n0.816\n1.272\nTimeNet\n0.290\n0.289\n0.288\n0.290\n0.465\nAUROPHARMA\nDeConFuse\n0.015\n0.005\n0.009\n0.010\n0.312\nConvTimeNet\n1.802\n1.847\n1.801\n1.829\n1.034\nTimeNet\n0.075\n0.076\n0.075\n0.076\n0.393\nBAJAJ-AUTO\nDeConFuse\n0.012\n0.007\n0.009\n0.010\n0.392\nConvTimeNet\n0.329\n0.326\n0.328\n0.327\n0.580\nTimeNet\n0.175\n0.176\n0.175\n0.176\n0.466\nBAJFINANCE\nDeConFuse\n0.013\n0.004\n0.009\n0.009\n0.361\nConvTimeNet\n2.519\n2.518\n2.534\n2.506\n2.575\nTimeNet\n0.509\n0.509\n0.508\n0.510\n0.693\nBANKBARODA\nDeConFuse\n0.021\n0.007\n0.015\n0.014\n0.299\nConvTimeNet\n0.891\n0.860\n0.849\n0.887\n0.845\nTimeNet\n0.130\n0.131\n0.130\n0.132\n0.402\nBANKINDIA\nDeConFuse\n0.022\n0.009\n0.016\n0.016\n0.354\nConvTimeNet\n2.451\n2.437\n2.449\n2.441\n1.351\nTimeNet\n0.374\n0.375\n0.373\n0.375\n0.384\nBATAINDIA\nDeConFuse\n0.015\n0.009\n0.012\n0.011\n0.391\nConvTimeNet\n0.143\n0.111\n0.129\n0.125\n1.095\nTimeNet\n0.301\n0.299\n0.299\n0.301\n0.477\nBEL\nDeConFuse\n0.019\n0.007\n0.013\n0.014\n0.366\nConvTimeNet\n1.576\n1.537\n1.524\n1.622\n3.338\nTimeNet\n0.145\n0.146\n0.142\n0.148\n0.410\nBHARATFORG\nDeConFuse\n0.013\n0.006\n0.009\n0.01\n0.567\nConvTimeNet\n3.207\n3.178\n3.162\n3.219\n7.468\nTimeNet\n0.345\n0.345\n0.343\n0.347\n0.555\nBHARTIARTL\nDeConFuse\n0.019\n0.012\n0.015\n0.016\n0.381\nConvTimeNet\n1.849\n1.809\n1.817\n1.841\n1.042\nTimeNet\n0.167\n0.167\n0.168\n0.166\n0.500\nBHEL\nDeConFuse\n0.016\n0.007\n0.012\n0.012\n0.765\nConvTimeNet\n2.664\n2.613\n2.660\n2.617\n8.514\nTimeNet\n0.389\n0.389\n0.391\n0.386\n0.928\nBIOCON\nDeConFuse\n0.016\n0.007\n0.013\n0.012\n0.450\nConvTimeNet\n1.338\n1.287\n1.303\n1.330\n1.031\nTimeNet\n0.604\n0.603\n0.604\n0.602\n0.470\nBOSCHLTD\nDeConFuse\n0.012\n0.005\n0.009\n0.007\n0.516\nConvTimeNet\n0.158\n0.158\n0.159\n0.155\n0.600\nTimeNet\n0.724\n0.723\n0.727\n0.721\n0.551\nBPCL\nDeConFuse\n0.014\n0.006\n0.010\n0.011\n0.323\nConvTimeNet\n0.243\n0.267\n0.267\n0.244\n1.614\n23\nTimeNet\n0.276\n0.277\n0.276\n0.276\n0.374\nBRITANNIA\nDeConFuse\n0.009\n0.004\n0.006\n0.006\n0.367\nConvTimeNet\n0.800\n0.828\n0.813\n0.812\n1.442\nTimeNet\n0.414\n0.413\n0.413\n0.413\n0.450\nCAIRN\nDeConFuse\n0.016\n0.008\n0.011\n0.013\n0.334\nConvTimeNet\n3.945\n3.988\n3.939\n4.025\n0.969\nTimeNet\n0.159\n0.159\n0.159\n0.158\n0.345\nCANBK\nDeConFuse\n0.021\n0.008\n0.015\n0.015\n0.276\nConvTimeNet\n2.140\n2.023\n2.065\n2.100\n0.806\nTimeNet\n0.151\n0.153\n0.151\n0.154\n0.444\nCASTROLIND\nDeConFuse\n0.014\n0.005\n0.010\n0.011\n0.523\nConvTimeNet\n2.055\n2.107\n2.036\n2.162\n12.249\nTimeNet\n0.141\n0.141\n0.141\n0.143\n0.527\nCEATLTD\nDeConFuse\n0.015\n0.006\n0.010\n0.011\n0.319\nConvTimeNet\n2.341\n2.308\n2.295\n2.344\n1.118\nTimeNet\n0.160\n0.163\n0.161\n0.162\n0.326\nCENTURYTEX\nDeConFuse\n0.015\n0.006\n0.010\n0.013\n0.404\nConvTimeNet\n1.111\n1.072\n1.106\n1.083\n2.685\nTimeNet\n0.405\n0.406\n0.404\n0.407\n0.352\nCESC\nDeConFuse\n0.013\n0.005\n0.009\n0.010\n0.404\nConvTimeNet\n0.390\n0.377\n0.374\n0.395\n0.602\nTimeNet\n0.364\n0.363\n0.362\n0.364\n0.477\nCIPLA\nDeConFuse\n0.012\n0.004\n0.009\n0.008\n0.408\nConvTimeNet\n2.063\n2.074\n2.052\n2.066\n0.695\nTimeNet\n0.064\n0.064\n0.063\n0.065\n0.476\nCOALINDIA\nDeConFuse\n0.012\n0.005\n0.009\n0.009\n0.393\nConvTimeNet\n1.635\n1.737\n1.632\n1.723\n2.791\nTimeNet\n0.154\n0.156\n0.155\n0.154\n0.474\nCOLPAL\nDeConFuse\n0.009\n0.004\n0.006\n0.007\n0.553\nConvTimeNet\n0.115\n0.119\n0.114\n0.117\n1.158\nTimeNet\n0.164\n0.164\n0.164\n0.165\n0.566\nDABUR\nDeConFuse\n0.010\n0.005\n0.008\n0.008\n0.474\nConvTimeNet\n1.369\n1.398\n1.360\n1.409\n1.530\nTimeNet\n0.271\n0.269\n0.270\n0.271\n0.539\nDHFL\nDeConFuse\n0.016\n0.007\n0.012\n0.012\n0.471\nConvTimeNet\n0.302\n0.285\n0.291\n0.289\n1.118\nTimeNet\n0.456\n0.456\n0.457\n0.457\n0.657\nDISHTV\nDeConFuse\n0.016\n0.006\n0.013\n0.012\n0.478\nConvTimeNet\n0.722\n0.733\n0.742\n0.708\n1.948\nTimeNet\n0.224\n0.225\n0.225\n0.224\n0.586\nDIVISLAB\nDeConFuse\n0.014\n0.006\n0.012\n0.010\n0.508\nConvTimeNet\n0.183\n0.195\n0.190\n0.190\n0.871\nTimeNet\n0.160\n0.159\n0.161\n0.159\n0.422\nDLF\nDeConFuse\n0.021\n0.012\n0.015\n0.018\n0.318\nConvTimeNet\n1.053\n1.104\n1.053\n1.100\n0.590\n24\nTimeNet\n0.311\n0.309\n0.308\n0.312\n0.402\nDRREDDY\nDeConFuse\n0.013\n0.006\n0.010\n0.010\n0.393\nConvTimeNet\n0.213\n0.210\n0.210\n0.210\n0.628\nTimeNet\n0.373\n0.373\n0.37\n0.374\n0.505\nEICHERMOT\nDeConFuse\n0.012\n0.004\n0.008\n0.008\n0.363\nConvTimeNet\n0.295\n0.296\n0.295\n0.297\n0.452\nTimeNet\n0.816\n0.816\n0.818\n0.814\n0.393\nENGINERSIN\nDeConFuse\n0.023\n0.019\n0.020\n0.022\n0.452\nConvTimeNet\n0.265\n0.260\n0.258\n0.260\n2.059\nTimeNet\n0.128\n0.128\n0.128\n0.128\n0.500\nEXIDEIND\nDeConFuse\n0.012\n0.005\n0.009\n0.009\n0.418\nConvTimeNet\n0.442\n0.453\n0.449\n0.448\n1.209\nTimeNet\n0.265\n0.263\n0.263\n0.265\n0.420\nFEDERALBNK\nDeConFuse\n0.015\n0.006\n0.010\n0.012\n0.407\nConvTimeNet\n2.405\n2.345\n2.360\n2.378\n1.292\nTimeNet\n0.146\n0.148\n0.147\n0.147\n0.502\nGAIL\nDeConFuse\n0.014\n0.009\n0.011\n0.012\n0.369\nConvTimeNet\n0.209\n0.169\n0.182\n0.195\n1.070\nTimeNet\n0.330\n0.330\n0.330\n0.330\n0.394\nGLENMARK\nDeConFuse\n0.013\n0.005\n0.010\n0.009\n0.374\nConvTimeNet\n0.614\n0.675\n0.612\n0.666\n2.597\nTimeNet\n0.399\n0.401\n0.402\n0.397\n0.448\nGMRINFRA\nDeConFuse\n0.029\n0.017\n0.023\n0.024\n0.616\nConvTimeNet\n0.101\n0.137\n0.118\n0.116\n1.044\nTimeNet\n0.094\n0.092\n0.095\n0.094\n0.799\nGODREJIND\nDeConFuse\n0.012\n0.008\n0.010\n0.011\n0.376\nConvTimeNet\n0.287\n0.298\n0.28\n0.296\n1.647\nTimeNet\n0.327\n0.326\n0.325\n0.328\n0.362\nGRASIM\nDeConFuse\n0.014\n0.008\n0.011\n0.011\n0.445\nConvTimeNet\n0.307\n0.318\n0.309\n0.312\n1.289\nTimeNet\n0.259\n0.259\n0.259\n0.257\n0.386\nHAVELLS\nDeConFuse\n0.012\n0.005\n0.009\n0.009\n0.377\nConvTimeNet\n0.426\n0.410\n0.422\n0.421\n1.182\nTimeNet\n0.403\n0.402\n0.402\n0.404\n0.400\nHCLTECH\nDeConFuse\n0.014\n0.010\n0.011\n0.014\n0.383\nConvTimeNet\n1.854\n1.839\n1.818\n1.853\n1.457\nTimeNet\n0.113\n0.113\n0.113\n0.114\n0.442\nHDFC\nDeConFuse\n0.009\n0.004\n0.006\n0.006\n0.314\nConvTimeNet\n0.747\n0.713\n0.734\n0.746\n1.239\nTimeNet\n0.318\n0.319\n0.317\n0.321\n0.383\nHDFCBANK\nDeConFuse\n0.007\n0.003\n0.005\n0.005\n0.330\nConvTimeNet\n0.529\n0.533\n0.533\n0.544\n3.680\nTimeNet\n0.422\n0.422\n0.421\n0.423\n0.576\nHDIL\nDeConFuse\n0.027\n0.014\n0.021\n0.022\n0.624\nConvTimeNet\n0.300\n0.560\n0.352\n0.439\n10.715\n25\nTimeNet\n0.297\n0.291\n0.290\n0.296\n1.106\nHEROMOTOCO\nDeConFuse\n0.009\n0.004\n0.006\n0.006\n0.322\nConvTimeNet\n0.129\n0.134\n0.129\n0.134\n0.810\nTimeNet\n0.191\n0.192\n0.190\n0.193\n0.416\nHEXAWARE\nDeConFuse\n0.017\n0.007\n0.012\n0.013\n0.496\nConvTimeNet\n2.798\n2.710\n2.691\n2.769\n1.050\nTimeNet\n0.425\n0.422\n0.424\n0.423\n0.473\nHINDALCO\nDeConFuse\n0.016\n0.007\n0.012\n0.012\n0.310\nConvTimeNet\n0.984\n0.995\n0.979\n1.002\n1.159\nTimeNet\n0.403\n0.403\n0.402\n0.404\n0.388\nHINDPETRO\nDeConFuse\n0.016\n0.007\n0.012\n0.012\n0.37\nConvTimeNet\n0.998\n0.961\n0.965\n0.999\n1.545\nTimeNet\n0.375\n0.377\n0.376\n0.376\n0.397\nHINDUNILVR\nDeConFuse\n0.008\n0.003\n0.006\n0.006\n0.413\nConvTimeNet\n0.181\n0.153\n0.151\n0.183\n0.997\nTimeNet\n0.414\n0.413\n0.413\n0.415\n0.427\nHINDZINC\nDeConFuse\n0.012\n0.006\n0.009\n0.010\n0.333\nConvTimeNet\n0.057\n0.063\n0.062\n0.055\n2.246\nTimeNet\n0.346\n0.346\n0.344\n0.347\n0.362\nIBREALEST\nDeConFuse\n0.033\n0.026\n0.031\n0.028\n0.694\nConvTimeNet\n6.230\n6.588\n6.338\n6.375\n6.639\nTimeNet\n0.612\n0.611\n0.613\n0.611\n0.662\nIBULHSGFIN\nDeConFuse\n0.014\n0.006\n0.011\n0.011\n0.381\nConvTimeNet\n0.352\n0.341\n0.343\n0.354\n0.556\nTimeNet\n0.357\n0.358\n0.356\n0.358\n0.584\nICICIBANK\nDeConFuse\n0.016\n0.012\n0.014\n0.014\n0.314\nConvTimeNet\n2.773\n2.801\n2.766\n2.784\n1.126\nTimeNet\n0.156\n0.155\n0.156\n0.155\n0.609\nIDBI\nDeConFuse\n0.026\n0.010\n0.019\n0.018\n0.408\nConvTimeNet\n0.900\n0.909\n0.846\n0.952\n1.995\nTimeNet\n0.135\n0.137\n0.134\n0.138\n0.550\nIDEA\nDeConFuse\n0.022\n0.008\n0.015\n0.015\n0.396\nConvTimeNet\n1.612\n1.684\n1.629\n1.671\n1.676\nTimeNet\n0.576\n0.575\n0.569\n0.580\n0.454\nIDFC\nDeConFuse\n0.017\n0.008\n0.012\n0.013\n0.523\nConvTimeNet\n0.693\n0.674\n0.629\n0.748\n5.201\nTimeNet\n0.134\n0.135\n0.134\n0.134\n0.680\nIFCI\nDeConFuse\n0.024\n0.009\n0.020\n0.016\n0.623\nConvTimeNet\n0.807\n0.744\n0.837\n0.755\n10.316\nTimeNet\n0.244\n0.243\n0.246\n0.245\n0.967\nIGL\nDeConFuse\n0.015\n0.005\n0.011\n0.011\n0.490\nConvTimeNet\n0.264\n0.255\n0.257\n0.264\n1.324\nTimeNet\n0.348\n0.350\n0.350\n0.346\n0.369\nINDIACEM\nDeConFuse\n0.023\n0.014\n0.018\n0.020\n0.360\nConvTimeNet\n0.712\n0.689\n0.692\n0.705\n1.012\n26\nTimeNet\n0.149\n0.150\n0.148\n0.150\n0.360\nINDUSINDBK\nDeConFuse\n0.009\n0.004\n0.006\n0.006\n0.315\nConvTimeNet\n0.502\n0.509\n0.507\n0.500\n1.253\nTimeNet\n0.453\n0.453\n0.452\n0.454\n0.419\nINFY\nDeConFuse\n0.010\n0.005\n0.008\n0.008\n0.405\nConvTimeNet\n2.417\n2.415\n2.410\n2.409\n1.837\nTimeNet\n0.140\n0.139\n0.14\n0.139\n0.605\nIOC\nDeConFuse\n0.012\n0.006\n0.010\n0.011\n0.369\nConvTimeNet\n0.334\n0.285\n0.309\n0.327\n1.359\nTimeNet\n0.205\n0.206\n0.204\n0.206\n0.392\nIRB\nDeConFuse\n0.019\n0.007\n0.014\n0.014\n0.475\nConvTimeNet\n0.365\n0.360\n0.355\n0.380\n1.583\nTimeNet\n0.076\n0.076\n0.077\n0.076\n0.580\nITC\nDeConFuse\n0.009\n0.004\n0.007\n0.006\n0.383\nConvTimeNet\n0.539\n0.545\n0.549\n0.540\n1.089\nTimeNet\n0.106\n0.106\n0.105\n0.108\n0.457\nJINDALSTEL\nDeConFuse\n0.029\n0.017\n0.023\n0.024\n0.337\nConvTimeNet\n6.234\n6.467\n6.223\n6.34\n5.342\nTimeNet\n0.394\n0.392\n0.392\n0.394\n0.565\nJISLJALEQS\nDeConFuse\n0.022\n0.008\n0.014\n0.018\n0.461\nConvTimeNet\n0.965\n0.969\n0.953\n0.976\n1.066\nTimeNet\n0.238\n0.237\n0.238\n0.236\n0.474\nJPASSOCIAT\nDeConFuse\n0.046\n0.028\n0.035\n0.040\n0.675\nConvTimeNet\n0.321\n0.318\n0.309\n0.321\n1.660\nTimeNet\n0.565\n0.567\n0.563\n0.568\n1.227\nJSWENERGY\nDeConFuse\n0.024\n0.019\n0.023\n0.021\n0.610\nConvTimeNet\n0.453\n0.462\n0.438\n0.469\n1.320\nTimeNet\n0.045\n0.044\n0.044\n0.044\n0.621\nJSWSTEEL\nDeConFuse\n0.014\n0.006\n0.011\n0.010\n0.304\nConvTimeNet\n1.093\n1.206\n1.093\n1.135\n1.895\nTimeNet\n0.535\n0.534\n0.535\n0.535\n0.365\nJUBLFOOD\nDeConFuse\n0.013\n0.006\n0.010\n0.011\n0.409\nConvTimeNet\n7.716\n7.395\n7.521\n7.733\n3.604\nTimeNet\n0.442\n0.441\n0.44\n0.443\n0.672\nJUSTDIAL\nDeConFuse\n0.026\n0.009\n0.018\n0.020\n0.473\nConvTimeNet\n7.726\n7.839\n7.787\n7.856\n3.06\nTimeNet\n0.738\n0.745\n0.735\n0.750\n0.505\nKOTAKBANK\nDeConFuse\n0.009\n0.004\n0.007\n0.007\n0.342\nConvTimeNet\n0.278\n0.294\n0.258\n0.307\n5.970\nTimeNet\n0.401\n0.400\n0.399\n0.402\n0.349\nKSCL\nDeConFuse\n0.016\n0.006\n0.011\n0.012\n0.503\nConvTimeNet\n0.240\n0.252\n0.235\n0.242\n1.831\nTimeNet\n0.089\n0.086\n0.085\n0.090\n0.739\nKTKBANK\nDeConFuse\n0.016\n0.006\n0.012\n0.013\n0.452\nConvTimeNet\n2.447\n2.452\n2.430\n2.464\n1.224\n27\nTimeNet\n0.124\n0.125\n0.123\n0.126\n0.504\nL&TFH\nDeConFuse\n0.017\n0.006\n0.011\n0.012\n0.366\nConvTimeNet\n0.343\n0.345\n0.339\n0.351\n0.741\nTimeNet\n0.466\n0.467\n0.468\n0.465\n0.416\nLICHSGFIN\nDeConFuse\n0.013\n0.005\n0.009\n0.010\n0.354\nConvTimeNet\n1.587\n1.604\n1.591\n1.584\n1.971\nTimeNet\n0.126\n0.127\n0.126\n0.128\n0.400\nLT\nDeConFuse\n0.010\n0.005\n0.007\n0.008\n0.372\nConvTimeNet\n0.877\n0.858\n0.851\n0.877\n0.732\nTimeNet\n0.222\n0.222\n0.221\n0.224\n0.338\nLUPIN\nDeConFuse\n0.014\n0.004\n0.009\n0.010\n0.406\nConvTimeNet\n0.687\n0.658\n0.678\n0.663\n1.229\nTimeNet\n0.707\n0.706\n0.705\n0.706\n0.514\nM&M\nDeConFuse\n0.014\n0.008\n0.010\n0.011\n0.361\nConvTimeNet\n2.729\n2.723\n2.713\n2.684\n1.088\nTimeNet\n0.207\n0.207\n0.206\n0.208\n0.413\nM&MFIN\nDeConFuse\n0.018\n0.011\n0.014\n0.016\n0.356\nConvTimeNet\n1.800\n1.789\n1.795\n1.807\n1.489\nTimeNet\n0.371\n0.370\n0.371\n0.372\n0.358\nMARUTI\nDeConFuse\n0.009\n0.003\n0.006\n0.006\n0.356\nConvTimeNet\n0.253\n0.249\n0.248\n0.254\n1.103\nTimeNet\n0.542\n0.542\n0.542\n0.542\n0.546\nMINDTREE\nDeConFuse\n0.019\n0.010\n0.015\n0.013\n0.491\nConvTimeNet\n0.594\n0.559\n0.545\n0.599\n1.058\nTimeNet\n0.319\n0.318\n0.319\n0.317\n0.770\nMOTHERSUMI\nDeConFuse\n0.014\n0.005\n0.009\n0.011\n0.381\nConvTimeNet\n0.954\n0.995\n0.962\n0.964\n0.955\nTimeNet\n0.388\n0.389\n0.388\n0.39\n0.413\nMRF\nDeConFuse\n0.010\n0.004\n0.007\n0.008\n0.597\nConvTimeNet\n0.422\n0.421\n0.420\n0.423\n0.618\nTimeNet\n0.915\n0.915\n0.916\n0.914\n0.489\nNHPC\nDeConFuse\n0.012\n0.006\n0.010\n0.010\n0.608\nConvTimeNet\n2.957\n3.029\n2.986\n3.006\n9.161\nTimeNet\n0.083\n0.082\n0.083\n0.084\n0.706\nNMDC\nDeConFuse\n0.018\n0.012\n0.015\n0.016\n0.385\nConvTimeNet\n0.747\n0.743\n0.741\n0.746\n1.214\nTimeNet\n0.103\n0.103\n0.105\n0.101\n0.491\nNTPC\nDeConFuse\n0.009\n0.007\n0.008\n0.008\n0.370\nConvTimeNet\n0.507\n0.507\n0.515\n0.499\n1.082\nTimeNet\n0.111\n0.110\n0.110\n0.112\n0.563\nOFSS\nDeConFuse\n0.012\n0.007\n0.009\n0.009\n0.590\nConvTimeNet\n0.144\n0.158\n0.150\n0.152\n0.727\nTimeNet\n0.105\n0.103\n0.105\n0.103\n0.552\nOIL\nDeConFuse\n0.014\n0.007\n0.010\n0.012\n0.441\nConvTimeNet\n0.294\n0.271\n0.283\n0.279\n1.602\n28\nTimeNet\n0.068\n0.070\n0.070\n0.069\n0.455\nONGC\nDeConFuse\n0.012\n0.006\n0.009\n0.010\n0.467\nConvTimeNet\n5.154\n5.167\n5.140\n5.171\n1.673\nTimeNet\n0.074\n0.075\n0.076\n0.073\n0.548\nORIENTBANK\nDeConFuse\n0.023\n0.009\n0.017\n0.016\n0.378\nConvTimeNet\n1.706\n1.565\n1.632\n1.63\n6.662\nTimeNet\n0.673\n0.675\n0.674\n0.674\n0.725\nPAGEIND\nDeConFuse\n0.017\n0.006\n0.013\n0.010\n0.431\nConvTimeNet\n0.377\n0.376\n0.377\n0.377\n0.862\nTimeNet\n0.824\n0.823\n0.826\n0.821\n0.655\nPETRONET\nDeConFuse\n0.014\n0.006\n0.011\n0.011\n0.494\nConvTimeNet\n0.785\n0.793\n0.793\n0.787\n3.480\nTimeNet\n0.119\n0.118\n0.118\n0.118\n0.455\nPFC\nDeConFuse\n0.019\n0.011\n0.015\n0.016\n0.335\nConvTimeNet\n6.082\n6.160\n6.127\n6.107\n5.328\nTimeNet\n0.208\n0.208\n0.206\n0.209\n0.377\nPIDILITIND\nDeConFuse\n0.011\n0.006\n0.008\n0.008\n0.339\nConvTimeNet\n0.148\n0.159\n0.158\n0.148\n1.693\nTimeNet\n0.328\n0.327\n0.328\n0.328\n0.514\nPNB\nDeConFuse\n0.025\n0.010\n0.019\n0.017\n0.402\nConvTimeNet\n9.020\n9.009\n8.898\n9.059\n4.502\nTimeNet\n0.358\n0.357\n0.357\n0.358\n0.593\nPOWERGRID\nDeConFuse\n0.009\n0.006\n0.007\n0.008\n0.351\nConvTimeNet\n1.329\n1.354\n1.321\n1.359\n4.055\nTimeNet\n0.196\n0.196\n0.194\n0.197\n0.412\nPTC\nDeConFuse\n0.016\n0.007\n0.011\n0.012\n0.385\nConvTimeNet\n1.190\n1.146\n1.140\n1.190\n1.877\nTimeNet\n0.187\n0.188\n0.187\n0.187\n0.353\nRCOM\nDeConFuse\n0.049\n0.019\n0.040\n0.033\n0.515\nConvTimeNet 11.473\n11.273\n11.142\n11.890\n2.267\nTimeNet\n0.363\n0.360\n0.344\n0.377\n0.581\nRECLTD\nDeConFuse\n0.017\n0.005\n0.012\n0.012\n0.401\nConvTimeNet\n7.043\n6.659\n6.798\n6.912\n12.186\nTimeNet\n0.145\n0.145\n0.144\n0.147\n0.521\nRELCAPITAL\nDeConFuse\n0.025\n0.014\n0.018\n0.021\n0.302\nConvTimeNet\n2.394\n2.359\n2.289\n2.428\n0.498\nTimeNet\n0.127\n0.130\n0.128\n0.131\n0.474\nRELIANCE\nDeConFuse\n0.011\n0.004\n0.008\n0.008\n0.305\nConvTimeNet\n0.251\n0.234\n0.245\n0.239\n1.609\nTimeNet\n0.459\n0.458\n0.458\n0.459\n0.654\nRELINFRA\nDeConFuse\n0.019\n0.007\n0.013\n0.014\n0.270\nConvTimeNet\n2.045\n2.032\n1.998\n2.084\n0.970\nTimeNet\n0.157\n0.159\n0.157\n0.159\n0.320\nRPOWER\nDeConFuse\n0.024\n0.007\n0.018\n0.016\n0.475\nConvTimeNet\n2.229\n2.178\n2.159\n2.268\n2.384\n29\nTimeNet\n0.296\n0.297\n0.295\n0.302\n0.757\nSAIL\nDeConFuse\n0.023\n0.008\n0.014\n0.016\n0.284\nConvTimeNet\n1.319\n1.225\n1.274\n1.276\n1.399\nTimeNet\n0.161\n0.160\n0.163\n0.158\n0.495\nSBIN\nDeConFuse\n0.015\n0.006\n0.011\n0.01\n0.339\nConvTimeNet\n0.663\n0.661\n0.675\n0.648\n1.428\nTimeNet\n0.120\n0.118\n0.120\n0.118\n0.696\nSIEMENS\nDeConFuse\n0.011\n0.006\n0.008\n0.009\n0.452\nConvTimeNet\n0.289\n0.212\n0.292\n0.245\n8.495\nTimeNet\n0.085\n0.086\n0.085\n0.086\n0.763\nSOUTHBANK\nDeConFuse\n0.018\n0.008\n0.013\n0.013\n0.539\nConvTimeNet\n7.863\n7.712\n7.795\n7.788\n10.684\nTimeNet\n0.162\n0.161\n0.161\n0.163\n0.534\nSRF\nDeConFuse\n0.016\n0.006\n0.011\n0.012\n0.396\nConvTimeNet\n0.373\n0.318\n0.339\n0.359\n0.791\nTimeNet\n0.226\n0.225\n0.225\n0.225\n0.508\nSRTRANSFIN\nDeConFuse\n0.019\n0.011\n0.015\n0.017\n0.445\nConvTimeNet\n2.900\n2.892\n2.838\n2.946\n0.667\nTimeNet\n0.297\n0.295\n0.296\n0.297\n0.482\nSTAR\nDeConFuse\n0.027\n0.015\n0.022\n0.025\n0.464\nConvTimeNet\n2.461\n2.586\n2.307\n2.629\n6.115\nTimeNet\n0.827\n0.820\n0.821\n0.825\n0.642\nSUNPHARMA\nDeConFuse\n0.016\n0.006\n0.011\n0.011\n0.368\nConvTimeNet\n0.203\n0.202\n0.203\n0.203\n0.655\nTimeNet\n0.388\n0.390\n0.385\n0.391\n0.645\nSUNTV\nDeConFuse\n0.015\n0.005\n0.010\n0.011\n0.356\nConvTimeNet\n0.175\n0.172\n0.173\n0.176\n1.482\nTimeNet\n0.471\n0.472\n0.470\n0.472\n0.483\nSYNDIBANK\nDeConFuse\n0.024\n0.009\n0.017\n0.017\n0.361\nConvTimeNet\n1.405\n1.391\n1.271\n1.521\n4.672\nTimeNet\n0.176\n0.175\n0.174\n0.177\n0.410\nTATACHEM\nDeConFuse\n0.011\n0.005\n0.008\n0.009\n0.392\nConvTimeNet\n1.044\n1.066\n1.044\n1.025\n0.690\nTimeNet\n0.368\n0.368\n0.367\n0.368\n0.412\nTATACOMM\nDeConFuse\n0.013\n0.006\n0.009\n0.010\n0.443\nConvTimeNet\n0.231\n0.249\n0.239\n0.241\n0.835\nTimeNet\n0.241\n0.241\n0.239\n0.243\n0.541\nTATAGLOBAL\nDeConFuse\n0.017\n0.006\n0.013\n0.012\n0.599\nConvTimeNet\n1.724\n1.807\n1.737\n1.813\n4.354\nTimeNet\n0.418\n0.417\n0.418\n0.416\n0.477\nTATAMOTORS\nDeConFuse\n0.015\n0.007\n0.012\n0.011\n0.333\nConvTimeNet\n0.644\n0.688\n0.660\n0.650\n1.844\nTimeNet\n0.279\n0.278\n0.278\n0.277\n0.659\nTATAMTRDVR\nDeConFuse\n0.015\n0.006\n0.013\n0.011\n0.380\nConvTimeNet\n1.153\n1.213\n1.161\n1.153\n1.219\n30\nTimeNet\n0.444\n0.443\n0.445\n0.440\n0.455\nTATAPOWER\nDeConFuse\n0.012\n0.005\n0.009\n0.010\n0.413\nConvTimeNet\n0.435\n0.442\n0.431\n0.452\n1.265\nTimeNet\n0.096\n0.096\n0.096\n0.096\n0.571\nTATASTEEL\nDeConFuse\n0.015\n0.005\n0.009\n0.012\n0.258\nConvTimeNet\n1.363\n1.390\n1.369\n1.365\n0.862\nTimeNet\n0.381\n0.381\n0.380\n0.381\n0.662\nTCS\nDeConFuse\n0.012\n0.005\n0.009\n0.008\n0.445\nConvTimeNet\n1.481\n1.337\n1.409\n1.323\n6.096\nTimeNet\n0.231\n0.229\n0.230\n0.231\n0.525\nTECHM\nDeConFuse\n0.014\n0.005\n0.009\n0.009\n0.386\nConvTimeNet\n1.857\n1.634\n1.753\n1.746\n6.126\nTimeNet\n0.175\n0.174\n0.176\n0.173\n0.416\nTITAN\nDeConFuse\n0.014\n0.005\n0.010\n0.010\n0.419\nConvTimeNet\n2.649\n2.676\n2.698\n2.633\n3.126\nTimeNet\n0.548\n0.548\n0.547\n0.548\n0.630\nTVSMOTOR\nDeConFuse\n0.014\n0.005\n0.009\n0.011\n0.385\nConvTimeNet\n1.120\n1.120\n1.108\n1.129\n0.848\nTimeNet\n0.441\n0.441\n0.441\n0.441\n0.403\nUBL\nDeConFuse\n0.018\n0.008\n0.014\n0.013\n0.418\nConvTimeNet\n0.144\n0.191\n0.157\n0.173\n0.915\nTimeNet\n0.246\n0.244\n0.248\n0.241\n0.593\nULTRACEMCO\nDeConFuse\n0.011\n0.005\n0.008\n0.007\n0.408\nConvTimeNet\n0.088\n0.086\n0.086\n0.088\n0.712\nTimeNet\n0.237\n0.236\n0.236\n0.237\n0.483\nUNIONBANK\nDeConFuse\n0.023\n0.009\n0.017\n0.016\n0.307\nConvTimeNet\n8.195\n8.076\n8.034\n8.207\n11.330\nTimeNet\n0.395\n0.395\n0.396\n0.394\n0.394\nUPL\nDeConFuse\n0.014\n0.004\n0.009\n0.010\n0.391\nConvTimeNet\n1.182\n1.034\n1.122\n1.101\n2.592\nTimeNet\n0.275\n0.276\n0.274\n0.277\n0.410\nVEDL\nDeConFuse\n0.018\n0.010\n0.014\n0.015\n0.235\nConvTimeNet\n2.904\n3.024\n2.967\n2.959\n0.605\nTimeNet\n0.295\n0.295\n0.295\n0.295\n0.720\nVOLTAS\nDeConFuse\n0.016\n0.009\n0.012\n0.013\n0.369\nConvTimeNet\n1.244\n1.272\n1.268\n1.254\n4.493\nTimeNet\n0.475\n0.475\n0.474\n0.476\n0.354\nWIPRO\nDeConFuse\n0.009\n0.005\n0.007\n0.007\n0.456\nConvTimeNet\n0.301\n0.290\n0.298\n0.295\n0.799\nTimeNet\n0.067\n0.065\n0.067\n0.066\n0.647\nWOCKPHARMA\nDeConFuse\n0.021\n0.009\n0.015\n0.016\n0.504\nConvTimeNet\n2.407\n2.486\n2.335\n2.582\n5.903\nTimeNet\n0.394\n0.395\n0.394\n0.393\n0.492\nYESBANK\nDeConFuse\n0.014\n0.006\n0.01\n0.011\n0.335\nConvTimeNet\n0.875\n0.868\n0.866\n0.879\n1.066\n31\nTimeNet\n0.422\n0.423\n0.424\n0.422\n0.599\nZEEL\nDeConFuse\n0.010\n0.005\n0.008\n0.008\n0.400\nConvTimeNet\n1.132\n1.135\n1.136\n1.123\n1.449\nTimeNet\n0.265\n0.265\n0.264\n0.267\n0.513\nB\nDetailed Stock Trading Results\nTable 6: Stock-wise Trading Results\nStock Name\nMethod\nComputational\nModel Performance\nFinancial\nEvaluation\nPrecision Recall\nF1\nScore\nAUC\nTrue\nAR\nPredicted\nAR\nABIRLANUVO\nDeConFuse\n0.553\n0.886\n0.681 0.558 41.950\n15.600\nConvTimeNet\n0.515\n0.966\n0.672\n0.541\n3.090\nTimeNet\n0.512\n0.989\n0.674\n0.478\n8.340\nACC\nDeConFuse\n0.449\n0.761 0.565 0.600 -7.090\n-1.070\nConvTimeNet\n0.449\n0.337\n0.385\n0.529\n-4.100\nTimeNet\n0.389\n0.152\n0.219\n0.506\n-9.020\nADANIENT\nDeConFuse\n0.581\n0.962 0.724 0.560 20.690\n4.570\nConvTimeNet\n0.594\n0.145\n0.233\n0.504\n69.400\nTimeNet\n0.565\n0.962\n0.712 0.571\n-3.610\nADANIPORTS\nDeConFuse\n0.520\n0.919 0.660 0.546\n0.900\n0.010\nConvTimeNet\n0.503\n0.694\n0.583 0.570\n2.560\nTimeNet\n0.534\n0.568\n0.550\n0.559\n17.750\nADANIPOWER\nDeConFuse\n0.461\n0.862\n0.601\n0.492 -34.600\n10.840\nConvTimeNet\n0.473\n0.569\n0.517\n0.460\n-28.930\nTimeNet\n0.495\n0.872 0.631 0.495\n-19.110\nAJANTPHARM\nDeConFuse\n0.449\n0.757\n0.564\n0.514 -44.660\n-29.150\nConvTimeNet\n0.469\n0.757 0.579 0.498\n-22.320\nTimeNet\n0.577\n0.214\n0.312 0.603\n-35.460\nALBK\nDeConFuse\n0.485\n0.776 0.597 0.550 -23.800\n-5.890\nConvTimeNet\n0.461\n0.766\n0.575\n0.495\n-17.440\nTimeNet\n0.478\n0.411\n0.442\n0.516\n29.660\nAMARAJABAT\nDeConFuse\n0.549\n0.718 0.622 0.568 19.460\n41.830\nConvTimeNet\n0.463\n0.321\n0.379\n0.502\n-19.990\nTimeNet\n0.667\n0.026\n0.049\n0.549\n-27.870\nAMBUJACEM\nDeConFuse\n0.486\n0.829 0.613 0.576 -8.970\n-10.080\nConvTimeNet\n0.457\n0.410\n0.432\n0.503\n-1.310\nTimeNet\n0.448\n0.533\n0.487\n0.470\n16.490\nANDHRABANK\nDeConFuse\n0.391\n0.753\n0.515\n0.479 -21.850\n4.660\nConvTimeNet\n0.401\n0.763 0.526 0.513\n1.060\nTimeNet\n0.446\n0.484\n0.464 0.548\n-18.610\nAPOLLOHOSP\nDeConFuse\n0.447\n0.921\n0.602 0.510 23.140\n6.820\n32\nConvTimeNet\n0.432\n0.812\n0.564\n0.509\n1.440\nTimeNet\n0.436\n0.941\n0.596\n0.493\n4.630\nAPOLLOTYRE\nDeConFuse\n0.502\n0.920\n0.650 0.536 -13.140\n2.730\nConvTimeNet\n0.600\n0.027\n0.051 0.606\n-2.810\nTimeNet\n0.482\n0.973\n0.645\n0.468\n0.950\nARVIND\nDeConFuse\n0.513\n0.936\n0.662 0.571 16.320\n19.560\nConvTimeNet\n0.603\n0.376\n0.463 0.637\n-33.780\nTimeNet\n0.476\n1.000\n0.645\n0.445\n0.000\nASHOKLEY\nDeConFuse\n0.532\n0.849 0.654 0.520 47.650\n-16.530\nConvTimeNet\n0.524\n0.092\n0.157\n0.502\n-14.800\nTimeNet\n0.522\n0.798\n0.631 0.551\n-13.550\nASIANPAINT\nDeConFuse\n0.523\n0.868\n0.652 0.595 32.770\n1.250\nConvTimeNet\n0.500\n0.245\n0.329\n0.539\n4.400\nTimeNet\n0.463\n1.000\n0.633\n0.487\n0.000\nAUROPHARMA\nDeConFuse\n0.511\n0.835\n0.634 0.532\n3.370\n4.430\nConvTimeNet\n0.484\n0.679\n0.565\n0.509\n-5.900\nTimeNet\n0.468\n0.954\n0.628 0.548\n-8.060\nAXISBANK\nDeConFuse\n0.527\n0.843 0.649 0.535 3.830\n26.440\nConvTimeNet\n0.503\n0.643\n0.565\n0.485\n12.060\nTimeNet\n0.500\n0.835\n0.625\n0.525\n-6.970\nBAJAJ-AUTO\nDeConFuse\n0.491\n0.776 0.601 0.552 12.590\n15.430\nConvTimeNet\n0.431\n0.234\n0.303\n0.518\n-9.380\nTimeNet\n0.463\n0.355\n0.402\n0.512\n-10.670\nBAJFINANCE\nDeConFuse\n0.570\n0.934\n0.708\n0.487 21.610\n-4.050\nConvTimeNet\n0.526\n0.440\n0.479\n0.441\n16.480\nTimeNet\n0.569\n1.000 0.725 0.568\n0.000\nBANKBARODA\nDeConFuse\n0.584\n0.473\n0.523 0.569 -21.990\n2.880\nConvTimeNet\n0.485\n0.573 0.525 0.495\n-3.680\nTimeNet\n0.286\n0.018\n0.034\n0.539\n-16.310\nBANKINDIA\nDeConFuse\n0.463\n0.925 0.617 0.428 -29.380\n-2.880\nConvTimeNet\n0.491\n0.757\n0.596\n0.500\n-25.090\nTimeNet\n0.571\n0.224\n0.322 0.567\n-19.800\nBATAINDIA\nDeConFuse\n0.523\n0.693 0.596 0.494 63.650\n34.340\nConvTimeNet\n0.000\n0.000\n0.000\n0.522\n0.000\nTimeNet\n0.520\n0.456\n0.486 0.547\n6.090\nBEL\nDeConFuse\n0.457\n0.892\n0.604 0.592 -17.530\n-22.310\nConvTimeNet\n0.421\n0.785\n0.548\n0.560\n-18.020\nTimeNet\n0.405\n0.985\n0.574\n0.566\n1.220\nBHARATFORG\nDeConFuse\n0.496\n1.000 0.663 0.507 -2.210\n3.800\nConvTimeNet\n0.400\n0.035\n0.065 0.578\n-3.510\nTimeNet\n0.493\n0.982\n0.657\n0.496\n1.500\nBHARTIARTL\nDeConFuse\n0.486\n0.817 0.609 0.563 9.350\n-10.08\nConvTimeNet\n0.580\n0.279\n0.377\n0.527\n-7.500\nTimeNet\n0.493\n0.327\n0.393\n0.535\n-7.670\nBHEL\nDeConFuse\n0.540\n0.857 0.662 0.578 -3.050\n10.340\n33\nConvTimeNet\n0.555\n0.589\n0.571\n0.576\n-32.780\nTimeNet\n0.481\n0.562\n0.519\n0.494\n-7.340\nBIOCON\nDeConFuse\n0.523\n0.780 0.626 0.487 30.340\n-9.750\nConvTimeNet\n1.000\n0.051\n0.097 0.540\n11.350\nTimeNet\n0.539\n0.407\n0.464\n0.520\n-0.280\nBOSCHLTD\nDeConFuse\n0.437\n0.938 0.596 0.550 -5.430\n4.380\nConvTimeNet\n0.464\n0.481\n0.473\n0.513\n3.330\nTimeNet\n0.000\n0.000\n0.000\n0.496\n0.000\nBPCL\nDeConFuse\n0.525\n0.850\n0.649 0.509 -0.640\n-0.740\nConvTimeNet\n0.535\n0.611\n0.570 0.561\n-2.290\nTimeNet\n0.482\n0.956\n0.641\n0.466\n-1.660\nBRITANNIA\nDeConFuse\n0.604\n0.871 0.714 0.550 17.710\n4.930\nConvTimeNet\n0.558\n0.258\n0.353\n0.492\n17.400\nTimeNet\n0.500\n0.043\n0.079 0.572\n42.380\nCAIRN\nDeConFuse\n0.558\n0.682 0.614 0.540 38.310\n-14.830\nConvTimeNet\n0.833\n0.059\n0.110\n0.483\n69.850\nTimeNet\n0.000\n0.000\n0.000\n0.480\n63.040\nCANBK\nDeConFuse\n0.500\n0.798\n0.615 0.552 -2.440\n-9.350\nConvTimeNet\n0.472\n0.862\n0.610\n0.471\n15.920\nTimeNet\n0.485\n0.908 0.633 0.528\n-20.500\nCASTROLIND\nDeConFuse\n0.468\n0.843 0.602 0.502 -12.570\n-17.840\nConvTimeNet\n0.427\n0.800\n0.557\n0.464\n-15.310\nTimeNet\n0.800\n0.057\n0.107 0.516\n-20.970\nCEATLTD\nDeConFuse\n0.474\n0.797\n0.595 0.598 -10.760\n5.010\nConvTimeNet\n0.413\n0.725\n0.526\n0.509\n-27.600\nTimeNet\n0.434\n0.957 0.597 0.520\n-10.180\nCENTURYTEX\nDeConFuse\n0.575\n0.807\n0.672 0.602 -18.430\n-21.330\nConvTimeNet\n0.513\n0.675\n0.583\n0.535\n-16.620\nTimeNet\n0.498\n1.000\n0.665\n0.483\n0.000\nCESC\nDeConFuse\n0.489\n0.789\n0.604 0.562 2.300\n-4.980\nConvTimeNet\n0.550\n0.101\n0.171\n0.535\n-5.930\nTimeNet\n0.458\n0.844\n0.594\n0.476\n-7.060\nCIPLA\nDeConFuse\n0.472\n0.810\n0.596 0.564 -3.130\n-12.260\nConvTimeNet\n0.508\n0.619\n0.558\n0.541\n-7.370\nTimeNet\n0.462\n0.867 0.603 0.536\n-3.270\nCOALINDIA\nDeConFuse\n0.557\n0.462 0.505 0.528 -2.370\n-1.030\nConvTimeNet\n0.500\n0.051\n0.093\n0.433\n-5.210\nTimeNet\n0.667\n0.051\n0.095\n0.489\n6.380\nCOLPAL\nDeConFuse\n0.519\n0.893 0.657 0.436 16.070\n6.000\nConvTimeNet\n0.643\n0.074\n0.133 0.562\n1.580\nTimeNet\n0.566\n0.355\n0.437\n0.524\n-3.180\nDABUR\nDeConFuse\n0.542\n0.791\n0.643 0.560 21.590\n-3.260\nConvTimeNet\n0.500\n0.026\n0.050\n0.503\n41.300\nTimeNet\n0.500\n0.983 0.663 0.560\n-4.800\nDHFL\nDeConFuse\n0.513\n0.836\n0.635 0.553 -8.590\n-8.510\n34\nConvTimeNet\n0.449\n0.726\n0.555\n0.501\n7.130\nTimeNet\n0.456\n1.000\n0.627\n0.547\n0.000\nDISHTV\nDeConFuse\n0.497\n0.815\n0.618\n0.512 -14.010\n20.570\nConvTimeNet\n0.507\n0.954\n0.662 0.536\n-12.220\nTimeNet\n0.469\n0.981\n0.635 0.539\n0.700\nDIVISLAB\nDeConFuse\n0.505\n0.867\n0.638\n0.485\n2.800\n-0.920\nConvTimeNet\n0.460\n0.513\n0.485\n0.474\n14.960\nTimeNet\n0.489\n0.973 0.651 0.567\n-4.620\nDLF\nDeConFuse\n0.583\n0.903\n0.709 0.545 14.530\n32.160\nConvTimeNet\n0.605\n0.395\n0.478 0.565\n3.060\nTimeNet\n0.539\n0.992\n0.699\n0.524\n2.690\nDRREDDY\nDeConFuse\n0.518\n0.870\n0.649 0.586 -2.060\n10.640\nConvTimeNet\n0.492\n0.774\n0.601\n0.470\n5.080\nTimeNet\n0.507\n0.991 0.671 0.487\n-10.530\nEICHERMOT\nDeConFuse\n0.515\n0.936 0.664 0.519 -7.280\n-1.070\nConvTimeNet\n0.478\n0.681\n0.561\n0.494\n-7.780\nTimeNet\n0.503\n0.904\n0.646 0.553\n0.750\nENGINERSIN\nDeConFuse\n0.568\n0.659 0.610 0.612 -3.150\n-40.820\nConvTimeNet\n0.456\n0.439\n0.447\n0.508\n-9.830\nTimeNet\n0.500\n0.085\n0.146\n0.473\n-27.400\nEXIDEIND\nDeConFuse\n0.525\n0.850 0.649 0.603 22.020\n9.570\nConvTimeNet\n0.629\n0.195\n0.297\n0.542\n2.170\nTimeNet\n0.484\n0.788\n0.599\n0.506\n17.840\nFEDERALBNK\nDeConFuse\n0.479\n0.810\n0.600 0.551 -23.270\n-20.170\nConvTimeNet\n0.434\n0.790\n0.560\n0.511\n16.480\nTimeNet\n0.428\n0.860\n0.571\n0.508\n-9.940\nGAIL\nDeConFuse\n0.554\n0.683 0.612 0.496 35.420\n1.670\nConvTimeNet\n0.000\n0.000\n0.000 0.564\n0.000\nTimeNet\n0.714\n0.083\n0.149\n0.521\n29.550\nGLENMARK\nDeConFuse\n0.543\n0.847 0.662 0.546 -12.340\n7.550\nConvTimeNet\n0.640\n0.483\n0.551 0.580\n-14.500\nTimeNet\n0.529\n0.780\n0.630\n0.490\n4.890\nGMRINFRA\nDeConFuse\n0.512\n0.792 0.622 0.547 8.230\n3.520\nConvTimeNet\n0.424\n0.132\n0.201\n0.537\n46.980\nTimeNet\n0.000\n0.000\n0.000\n0.523\n0.000\nGODREJIND\nDeConFuse\n0.551\n0.932\n0.692 0.572 12.190\n6.320\nConvTimeNet\n0.528\n0.957\n0.681\n0.569\n-4.980\nTimeNet\n0.515\n1.000\n0.680 0.584\n1.560\nGRASIM\nDeConFuse\n0.451\n0.854\n0.590 0.571 11.750\n31.030\nConvTimeNet\n0.457\n0.552\n0.500\n0.563\n4.060\nTimeNet\n0.421\n1.000\n0.590\n0.563\n-0.660\nHAVELLS\nDeConFuse\n0.562\n0.886 0.688 0.534 25.080\n4.960\nConvTimeNet\n0.929\n0.106\n0.190\n0.553\n1.110\nTimeNet\n0.586\n0.724\n0.647 0.621\n28.710\nHCLTECH\nDeConFuse\n0.596\n0.862\n0.704\n0.510 26.700\n-4.330\n35\nConvTimeNet\n0.573\n0.331\n0.42\n0.477\n13.730\nTimeNet\n0.566\n0.985 0.719 0.529\n1.090\nHDFC\nDeConFuse\n0.557\n0.817 0.662 0.530 -13.020\n11.470\nConvTimeNet\n0.677\n0.175\n0.278 0.551\n7.020\nTimeNet\n0.515\n0.575\n0.543\n0.492\n18.220\nHDFCBANK\nDeConFuse\n0.551\n0.851\n0.669 0.561 -0.470\n9.890\nConvTimeNet\n0.569\n0.306\n0.398\n0.510\n-7.500\nTimeNet\n0.529\n0.992 0.690 0.522\n0.520\nHDIL\nDeConFuse\n0.466\n0.883\n0.610 0.565 -51.190\n-11.390\nConvTimeNet\n0.448\n0.915\n0.601\n0.482\n27.120\nTimeNet\n0.445\n1.000\n0.610\n0.474\n0.000\nHEROMOTOCO\nDeConFuse\n0.482\n0.796 0.601 0.556 -19.99\n-1.530\nConvTimeNet\n0.529\n0.350\n0.421 0.570\n-18.100\nTimeNet\n0.418\n0.573\n0.484\n0.442\n-0.910\nHEXAWARE\nDeConFuse\n0.577\n0.879\n0.697 0.518 41.150\n-3.690\nConvTimeNet\n1.000\n0.015\n0.030\n0.495\n20.850\nTimeNet\n0.570\n0.955 0.714 0.458\n5.010\nHINDALCO\nDeConFuse\n0.495\n0.872 0.631 0.547 6.020\n-6.310\nConvTimeNet\n0.474\n0.679\n0.558\n0.524\n1.110\nTimeNet\n0.494\n0.807\n0.613\n0.540\n-19.450\nHINDPETRO\nDeConFuse\n0.459\n0.931\n0.615 0.507 -18.980\n-1.200\nConvTimeNet\n0.446\n0.775\n0.566 0.549\n-14.200\nTimeNet\n0.445\n1.000\n0.615\n0.457\n0.000\nHINDUNILVR\nDeConFuse\n0.594\n0.956 0.733 0.512\n8.010\n2.820\nConvTimeNet\n0.500\n0.030\n0.056\n0.497\n10.740\nTimeNet\n0.623\n0.696\n0.657 0.578\n20.200\nHINDZINC\nDeConFuse\n0.529\n0.894\n0.664 0.581 -8.970\n7.870\nConvTimeNet\n0.617\n0.257\n0.362\n0.570\n-26.230\nTimeNet\n0.495\n0.938\n0.648\n0.511\n0.920\nIBREALEST\nDeConFuse\n0.613\n0.642 0.627 0.562 50.250\n4.550\nConvTimeNet\n0.750\n0.028\n0.055\n0.560\n2.720\nTimeNet\n0.000\n0.000\n0.000\n0.455\n0.000\nIBULHSGFIN\nDeConFuse\n0.534\n0.814\n0.645 0.574 -33.740\n3.660\nConvTimeNet\n0.488\n0.907\n0.634\n0.562\n2.130\nTimeNet\n0.447\n0.837\n0.583\n0.491\n4.990\nICICIBANK\nDeConFuse\n0.514\n0.664 0.580 0.554 -15.240\n-7.840\nConvTimeNet\n0.528\n0.262\n0.350\n0.530\n7.090\nTimeNet\n0.455\n0.047\n0.085\n0.471\n32.410\nIDBI\nDeConFuse\n0.545\n0.757\n0.634 0.596 -38.100\n-4.320\nConvTimeNet\n0.503\n0.775\n0.610\n0.529\n-14.250\nTimeNet\n0.577\n0.505\n0.538\n0.538\n-11.360\nIDEA\nDeConFuse\n0.450\n0.949 0.610 0.571 -26.870\n-12.280\nConvTimeNet\n0.415\n0.667\n0.512\n0.549\n10.310\nTimeNet\n0.395\n0.495\n0.439\n0.414\n26.380\nIDFC\nDeConFuse\n0.460\n0.737 0.566 0.500 10.310\n7.640\n36\nConvTimeNet\n0.511\n0.232\n0.319 0.550\n-28.470\nTimeNet\n0.444\n0.040\n0.074\n0.538\n-11.310\nIFCI\nDeConFuse\n0.541\n0.653\n0.592 0.612 -21.380\n-10.090\nConvTimeNet\n0.429\n0.713\n0.535\n0.489\n9.880\nTimeNet\n0.450\n0.178\n0.255\n0.542\n1.240\nIGL\nDeConFuse\n0.505\n0.955\n0.660 0.545 -17.220\n-4.580\nConvTimeNet\n0.489\n1.000\n0.657\n0.425\n0.000\nTimeNet\n0.483\n0.902\n0.629\n0.500\n3.870\nINDIACEM\nDeConFuse\n0.512\n0.796\n0.623 0.607 3.720\n-15.030\nConvTimeNet\n0.450\n0.537\n0.489\n0.452\n-17.100\nTimeNet\n0.473\n0.907\n0.622\n0.541\n-1.060\nINDUSINDBK\nDeConFuse\n0.510\n0.896\n0.650 0.485 2.350\n-2.270\nConvTimeNet\n0.250\n0.026\n0.047\n0.483\n7.450\nTimeNet\n0.502\n1.000 0.669 0.455\n0.000\nINFY\nDeConFuse\n0.590\n0.803 0.677 0.519 19.370\n23.970\nConvTimeNet\n0.590\n0.348\n0.440\n0.501\n23.650\nTimeNet\n0.577\n0.598\n0.587\n0.482\n33.220\nIOC\nDeConFuse\n0.546\n0.848\n0.664 0.560 7.260\n-8.670\nConvTimeNet\n0.495\n0.938\n0.648\n0.527\n-11.190\nTimeNet\n0.477\n0.946\n0.635\n0.452\n1.350\nIRB\nDeConFuse\n0.528\n0.920\n0.671 0.567 -14.090\n-15.820\nConvTimeNet\n0.517\n0.821\n0.634\n0.509\n-20.420\nTimeNet\n0.489\n1.000\n0.657\n0.491\n0.000\nITC\nDeConFuse\n0.515\n0.785 0.622 0.550 16.580\n8.780\nConvTimeNet\n0.482\n0.383\n0.427\n0.509\n16.990\nTimeNet\n0.465\n0.935\n0.621\n0.550\n-2.330\nJINDALSTEL\nDeConFuse\n0.547\n0.894 0.679 0.497 34.970\n19.940\nConvTimeNet\n0.440\n0.089\n0.149\n0.434\n114.370\nTimeNet\n0.535\n0.187\n0.277 0.548\n35.170\nJISLJALEQS\nDeConFuse\n0.495\n0.877 0.633 0.480 -26.510\n-9.490\nConvTimeNet\n0.495\n0.412\n0.450 0.521\n-6.950\nTimeNet\n0.477\n0.623\n0.540\n0.455\n18.140\nJPASSOCIAT\nDeConFuse\n0.467\n0.324 0.383 0.465 -15.680\n-7.23\nConvTimeNet\n0.545\n0.056\n0.101\n0.503\n-22.480\nTimeNet\n0.000\n0.000\n0.000 0.504\n0.000\nJSWENERGY\nDeConFuse\n0.537\n0.784\n0.637 0.573 28.740\n25.080\nConvTimeNet\n0.509\n0.569\n0.537\n0.512\n-2.810\nTimeNet\n0.494\n0.873\n0.631\n0.472\n11.840\nJSWSTEEL\nDeConFuse\n0.567\n0.850\n0.680 0.559 17.590\n3.040\nConvTimeNet\n0.560\n0.425\n0.483\n0.522\n-20.500\nTimeNet\n0.520\n0.975\n0.678\n0.476\n-4.980\nJUBLFOOD\nDeConFuse\n0.586\n0.882 0.704 0.554 24.580\n7.970\nConvTimeNet\n0.520\n0.205\n0.294\n0.501\n22.900\nTimeNet\n0.750\n0.071\n0.129 0.582\n110.88\nJUSTDIAL\nDeConFuse\n0.570\n0.450 0.503 0.560 29.030\n1.600\n37\nConvTimeNet\n0.643\n0.248\n0.358 0.560\n-20.230\nTimeNet\n0.000\n0.000\n0.000\n0.439\n0.000\nKOTAKBANK\nDeConFuse\n0.584\n0.910\n0.711 0.526 27.020\n-5.120\nConvTimeNet\n0.000\n0.000\n0.000\n0.502\n0.000\nTimeNet\n0.579\n0.955 0.721 0.511\n0.900\nKSCL\nDeConFuse\n0.545\n0.838 0.660 0.572 4.420\n-15.790\nConvTimeNet\n0.535\n0.575\n0.554\n0.545\n46.130\nTimeNet\n0.522\n0.300\n0.381\n0.473\n30.920\nKTKBANK\nDeConFuse\n0.494\n0.784 0.606 0.518 -16.590\n-15.610\nConvTimeNet\n0.488\n0.532\n0.509\n0.530\n-6.400\nTimeNet\n0.491\n0.730\n0.587 0.545\n-13.540\nL&TFH\nDeConFuse\n0.468\n0.906\n0.617 0.550 -20.710\n-7.570\nConvTimeNet\n0.453\n0.906\n0.604 0.550\n-19.540\nTimeNet\n0.432\n0.958\n0.595\n0.478\n-1.020\nLICHSGFIN\nDeConFuse\n0.517\n0.852\n0.640 0.549 -21.250\n12.680\nConvTimeNet\n0.471\n0.676\n0.555\n0.514\n14.560\nTimeNet\n0.476\n0.980 0.640 0.530\n-1.150\nLT\nDeConFuse\n0.525\n0.810 0.637 0.524\n7.670\n-3.420\nConvTimeNet\n0.562\n0.078\n0.136 0.553\n-1.190\nTimeNet\n0.519\n0.241\n0.329\n0.534\n21.790\nLUPIN\nDeConFuse\n0.562\n0.860 0.680 0.545 -46.000\n-13.900\nConvTimeNet\n0.534\n0.645\n0.584\n0.504\n-9.170\nTimeNet\n0.518\n0.702\n0.596\n0.515\n-13.000\nM&M\nDeConFuse\n0.576\n0.760\n0.656\n0.556 26.670\n-5.130\nConvTimeNet\n1.000\n0.062\n0.117\n0.550\n9.230\nTimeNet\n0.596\n0.791 0.680 0.570\n5.390\nM&MFIN\nDeConFuse\n0.505\n0.819 0.625 0.435 57.200\n3.640\nConvTimeNet\n0.000\n0.000\n0.000 0.539\n0.000\nTimeNet\n0.590\n0.310\n0.407\n0.519\n26.820\nMARUTI\nDeConFuse\n0.527\n0.883\n0.660 0.574 10.200\n3.950\nConvTimeNet\n0.508\n0.559\n0.532\n0.562\n6.680\nTimeNet\n0.485\n1.000\n0.653\n0.500\n0.000\nMINDTREE\nDeConFuse\n0.521\n0.718 0.604 0.483 51.140\n34.170\nConvTimeNet\n0.625\n0.097\n0.168 0.528\n1.180\nTimeNet\n0.577\n0.291\n0.387\n0.498\n37.020\nMOTHERSUMI\nDeConFuse\n0.510\n0.863\n0.641\n0.504 -0.320\n4.730\nConvTimeNet\n0.510\n0.537\n0.526\n0.519\n-22.050\nTimeNet\n0.489\n0.979 0.653 0.535\n2.480\nMRF\nDeConFuse\n0.489\n0.571\n0.527\n0.463 -3.020\n2.370\nConvTimeNet\n0.500\n0.089\n0.152 0.520\n-6.320\nTimeNet\n0.482\n0.964 0.643 0.480\n-3.050\nNHPC\nDeConFuse\n0.531\n0.520 0.526 0.598 -10.570\n-3.130\nConvTimeNet\n0.556\n0.255\n0.350\n0.564\n13.660\nTimeNet\n0.000\n0.000\n0.000\n0.474\n0.000\nNMDC\nDeConFuse\n0.550\n0.783 0.646 0.557 -10.800\n5.560\n38\nConvTimeNet\n0.540\n0.558\n0.549\n0.528\n-16.940\nTimeNet\n0.528\n0.633\n0.576\n0.500\n-10.610\nNTPC\nDeConFuse\n0.487\n0.862 0.623 0.480\n1.690\n-4.410\nConvTimeNet\n0.535\n0.349\n0.422\n0.560\n-7.440\nTimeNet\n0.497\n0.789\n0.610 0.534\n3.830\nOFSS\nDeConFuse\n0.500\n0.723 0.591 0.453 21.390\n33.070\nConvTimeNet\n0.593\n0.134\n0.219 0.518\n6.100\nTimeNet\n0.667\n0.017\n0.033\n0.419\n6.190\nOIL\nDeConFuse\n0.533\n0.731\n0.616 0.525 -21.220\n-15.240\nConvTimeNet\n0.495\n0.577\n0.533 0.541\n-17.520\nTimeNet\n0.496\n0.769\n0.603\n0.465\n-13.470\nONGC\nDeConFuse\n0.526\n0.750 0.618 0.604 20.320\n13.740\nConvTimeNet\n0.496\n0.519\n0.507\n0.498\n-13.270\nTimeNet\n0.447\n0.704\n0.547\n0.543\n11.750\nORIENTBANK\nDeConFuse\n0.466\n0.880 0.609 0.553 -10.110\n-17.560\nConvTimeNet\n0.435\n0.740\n0.548\n0.492\n16.580\nTimeNet\n0.430\n0.490\n0.458\n0.518\n38.720\nPAGEIND\nDeConFuse\n0.503\n0.935 0.655 0.489 39.910\n8.130\nConvTimeNet\n0.375\n0.195\n0.256\n0.400\n0.630\nTimeNet\n0.447\n0.545\n0.491 0.521\n1.050\nPETRONET\nDeConFuse\n0.520\n0.929 0.669 0.525 12.330\n-9.760\nConvTimeNet\n0.520\n0.241\n0.331\n0.539\n-12.190\nTimeNet\n0.485\n0.982\n0.649 0.546\n1.450\nPFC\nDeConFuse\n0.503\n0.733 0.597 0.532\n2.150\n7.310\nConvTimeNet\n0.479\n0.657\n0.554 0.551\n11.310\nTimeNet\n0.458\n0.667\n0.543\n0.497\n-14.680\nPIDILITIND\nDeConFuse\n0.602\n0.773\n0.677 0.596 30.150\n11.440\nConvTimeNet\n0.564\n0.500\n0.530\n0.501\n12.880\nTimeNet\n0.550\n1.000 0.710 0.518\n0.000\nPNB\nDeConFuse\n0.512\n0.644 0.570 0.572 -23.580\n-14.500\nConvTimeNet\n0.496\n0.634\n0.557\n0.560\n-18.650\nTimeNet\n0.495\n0.455\n0.474\n0.550\n-6.780\nPOWERGRID\nDeConFuse\n0.491\n0.757\n0.595 0.560 10.340\n-5.810\nConvTimeNet\n0.473\n0.777\n0.588\n0.531\n-6.230\nTimeNet\n0.481\n0.495\n0.488\n0.511\n0.420\nPTC\nDeConFuse\n0.526\n0.766\n0.624 0.610 -19.080\n-30.920\nConvTimeNet\n0.471\n0.607\n0.531\n0.518\n-34.44\nTimeNet\n0.449\n0.907\n0.601\n0.537\n-5.060\nRCOM\nDeConFuse\n0.474\n0.540 0.505 0.524 -29.600\n-38.130\nConvTimeNet\n0.091\n0.010\n0.018\n0.489\n-39.190\nTimeNet\n0.000\n0.000\n0.000\n0.495\n0.000\nRECLTD\nDeConFuse\n0.439\n0.863 0.582 0.511 -29.540\n-32.010\nConvTimeNet\n0.407\n0.621\n0.492\n0.491\n-2.110\nTimeNet\n0.420\n0.495\n0.454\n0.500\n-25.420\nRELCAPITAL\nDeConFuse\n0.497\n0.843\n0.625 0.575 -31.650\n12.140\n39\nConvTimeNet\n0.481\n0.704\n0.571\n0.563\n-14.590\nTimeNet\n0.471\n0.981 0.637 0.491\n-15.740\nRELIANCE\nDeConFuse\n0.588\n0.870 0.702 0.574 4.780\n9.430\nConvTimeNet\n0.000\n0.000\n0.000\n0.524\n0.000\nTimeNet\n0.571\n0.802\n0.667\n0.506\n4.880\nRELINFRA\nDeConFuse\n0.535\n0.868\n0.662 0.528 -12.910\n-11.870\nConvTimeNet\n0.493\n0.930\n0.644\n0.505\n-3.650\nTimeNet\n0.493\n0.974\n0.655\n0.482\n1.860\nRPOWER\nDeConFuse\n0.541\n0.860\n0.660 0.588 -40.030\n2.300\nConvTimeNet\n0.512\n0.947 0.660 0.605\n9.490\nTimeNet\n0.500\n0.904\n0.644\n0.529\n-15.860\nSAIL\nDeConFuse\n0.541\n0.748 0.628 0.498 10.540\n41.720\nConvTimeNet\n0.576\n0.276\n0.374\n0.498\n12.370\nTimeNet\n0.562\n0.146\n0.232\n0.482\n11.190\nSBIN\nDeConFuse\n0.518\n0.673 0.585 0.569 -1.370\n-3.740\nConvTimeNet\n0.491\n0.486\n0.488\n0.545\n6.730\nTimeNet\n0.463\n0.467\n0.465\n0.484\n29.460\nSIEMENS\nDeConFuse\n0.520\n0.919\n0.664 0.574 -6.930\n3.220\nConvTimeNet\n0.540\n0.613\n0.574\n0.559\n8.280\nTimeNet\n0.485\n0.991\n0.651\n0.505\n-1.080\nSOUTHBANK\nDeConFuse\n0.492\n0.492\n0.492 0.628 -34.640\n-42.640\nConvTimeNet\n0.407\n0.559\n0.471\n0.542\n-48.180\nTimeNet\n0.000\n0.000\n0.000\n0.568\n0.000\nSRF\nDeConFuse\n0.543\n0.809\n0.649 0.569 -15.350\n42.110\nConvTimeNet\n0.471\n0.205\n0.286\n0.484\n-37.280\nTimeNet\n0.479\n0.859\n0.615\n0.487\n-19.230\nSRTRANSFIN\nDeConFuse\n0.575\n0.780\n0.662 0.564\n2.810\n32.140\nConvTimeNet\n0.765\n0.106\n0.186 0.578\n-0.030\nTimeNet\n0.517\n0.862\n0.646\n0.441\n9.070\nSTAR\nDeConFuse\n0.474\n0.881 0.617 0.581 -38.200\n-34.590\nConvTimeNet\n0.453\n0.631\n0.527\n0.531\n-50.680\nTimeNet\n0.462\n0.512\n0.486\n0.482\n-56.200\nSUNPHARMA\nDeConFuse\n0.476\n0.908 0.625 0.521 24.640\n-0.220\nConvTimeNet\n0.468\n0.743\n0.574\n0.472\n15.310\nTimeNet\n0.476\n0.734\n0.578\n0.520\n-15.150\nSUNTV\nDeConFuse\n0.502\n0.928 0.652 0.513 -9.190\n-7.630\nConvTimeNet\n0.588\n0.423\n0.492 0.600\n-16.630\nTimeNet\n0.485\n0.892\n0.629\n0.533\n-6.620\nSYNDIBANK\nDeConFuse\n0.450\n0.786 0.572 0.552 -52.140\n-9.720\nConvTimeNet\n0.443\n0.755\n0.558\n0.540\n-17.660\nTimeNet\n0.222\n0.020\n0.037\n0.533\n-34.330\nTATACHEM\nDeConFuse\n0.538\n0.739\n0.620 0.565 8.710\n8.700\nConvTimeNet\n0.700\n0.061\n0.112\n0.504\n3.210\nTimeNet\n0.530\n0.765\n0.620\n0.548\n2.060\nTATACOMM\nDeConFuse\n0.516\n0.855\n0.644 0.581 2.020\n-9.330\n40\nConvTimeNet\n0.488\n0.936\n0.642\n0.537\n-14.430\nTimeNet\n0.480\n0.964\n0.640\n0.562\n-4.480\nTATAGLOBAL\nDeConFuse\n0.573\n0.850 0.685 0.574 29.440\n14.710\nConvTimeNet\n0.530\n0.733\n0.615\n0.564\n-6.740\nTimeNet\n0.536\n0.850\n0.660\n0.534\n-9.600\nTATAMOTORS\nDeConFuse\n0.522\n0.761 0.619 0.576 -30.220\n-1.920\nConvTimeNet\n0.483\n0.633\n0.548\n0.511\n-6.140\nTimeNet\n0.450\n0.450\n0.450\n0.491\n-2.090\nTATAMTRDVR\nDeConFuse\n0.478\n0.854\n0.610 0.518 -35.66\n-1.030\nConvTimeNet\n0.447\n0.738\n0.557\n0.502\n-17.550\nTimeNet\n0.455\n0.971 0.610 0.502\n-8.180\nTATAPOWER\nDeConFuse\n0.540\n0.514 0.527 0.564 -4.090\n-17.580\nConvTimeNet\n0.558\n0.276\n0.369\n0.549\n-25.530\nTimeNet\n0.333\n0.010\n0.019\n0.450\n-8.550\nTATASTEEL\nDeConFuse\n0.552\n0.807\n0.655 0.528 17.240\n-10.030\nConvTimeNet\n0.562\n0.613\n0.586 0.551\n-22.210\nTimeNet\n0.518\n0.958\n0.673\n0.474\n-13.700\nTCS\nDeConFuse\n0.573\n0.746 0.648 0.557 33.910\n2.550\nConvTimeNet\n0.636\n0.056\n0.102\n0.453\n2.990\nTimeNet\n0.573\n0.714\n0.636 0.565\n6.360\nTECHM\nDeConFuse\n0.555\n0.835 0.667 0.480 49.080\n29.110\nConvTimeNet\n0.578\n0.496\n0.534\n0.507\n47.820\nTimeNet\n0.572\n0.685\n0.624 0.563\n-5.130\nTITAN\nDeConFuse\n0.562\n0.744 0.641 0.562 18.960\n4.930\nConvTimeNet\n0.000\n0.000\n0.000\n0.560\n0.000\nTimeNet\n0.528\n0.628\n0.574\n0.477\n24.260\nTVSMOTOR\nDeConFuse\n0.453\n0.953\n0.614 0.504 -4.950\n-11.570\nConvTimeNet\n0.431\n0.802\n0.561\n0.438\n-19.260\nTimeNet\n0.441\n1.000\n0.612\n0.473\n0.000\nUBL\nDeConFuse\n0.609\n0.664 0.635 0.550 59.870\n32.690\nConvTimeNet\n1.000\n0.049\n0.094 0.568\n17.720\nTimeNet\n0.600\n0.221\n0.323\n0.515\n47.160\nULTRACEMCO\nDeConFuse\n0.569\n0.757\n0.649 0.585 26.850\n-0.390\nConvTimeNet\n0.556\n0.522\n0.538\n0.581\n-16.410\nTimeNet\n0.500\n0.991\n0.665 0.542\n0.860\nUNIONBANK\nDeConFuse\n0.497\n0.689\n0.577 0.553 -4.350\n30.000\nConvTimeNet\n0.453\n0.709\n0.553\n0.494\n-25.830\nTimeNet\n0.408\n0.194\n0.263\n0.511\n-34.140\nUPL\nDeConFuse\n0.480\n0.897 0.627 0.553 5.600\n2.450\nConvTimeNet\n0.480\n0.738\n0.585\n0.526\n5.010\nTimeNet\n0.459\n0.841\n0.594\n0.501\n-3.330\nVEDL\nDeConFuse\n0.475\n0.864 0.613 0.599 3.610\n-4.550\nConvTimeNet\n0.433\n0.636\n0.515\n0.570\n-28.800\nTimeNet\n0.360\n0.136\n0.198\n0.491\n-18.810\nVOLTAS\nDeConFuse\n0.497\n0.864\n0.631\n0.483 60.280\n8.460\n41\nConvTimeNet\n1.000\n0.009\n0.018 0.541\n4.970\nTimeNet\n0.480\n1.000 0.649 0.528\n0.000\nWIPRO\nDeConFuse\n0.503\n0.780\n0.612\n0.535 -11.360\n3.560\nConvTimeNet\n0.532\n0.615\n0.570\n0.562\n-13.570\nTimeNet\n0.492\n0.872\n0.629 0.575\n8.590\nWOCKPHARMA\nDeConFuse\n0.516\n0.899 0.656 0.559 -7.170\n18.620\nConvTimeNet\n0.523\n0.517\n0.520\n0.515\n59.110\nTimeNet\n0.487\n0.865\n0.623\n0.524\n-2.650\nYESBANK\nDeConFuse\n0.522\n0.828\n0.640 0.565 0.050\n3.180\nConvTimeNet\n0.494\n0.664\n0.566\n0.523\n-7.690\nTimeNet\n0.507\n1.000\n0.672\n0.559\n0.000\nZEEL\nDeConFuse\n0.557\n0.900 0.688 0.535\n4.660\n-8.240\nConvTimeNet\n0.607\n0.375\n0.464 0.622\n-6.830\nTimeNet\n0.527\n0.900\n0.667\n0.569\n12.100\n42\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2020-11-09",
  "updated": "2020-11-09"
}