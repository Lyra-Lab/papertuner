{
  "id": "http://arxiv.org/abs/2012.05715v1",
  "title": "Towards Coinductive Models for Natural Language Understanding. Bringing together Deep Learning and Deep Semantics",
  "authors": [
    "Wlodek W. Zadrozny"
  ],
  "abstract": "This article contains a proposal to add coinduction to the computational\napparatus of natural language understanding. This, we argue, will provide a\nbasis for more realistic, computationally sound, and scalable models of natural\nlanguage dialogue, syntax and semantics. Given that the bottom up, inductively\nconstructed, semantic and syntactic structures are brittle, and seemingly\nincapable of adequately representing the meaning of longer sentences or\nrealistic dialogues, natural language understanding is in need of a new\nfoundation. Coinduction, which uses top down constraints, has been successfully\nused in the design of operating systems and programming languages. Moreover,\nimplicitly it has been present in text mining, machine translation, and in some\nattempts to model intensionality and modalities, which provides evidence that\nit works. This article shows high level formalizations of some of such uses.\n  Since coinduction and induction can coexist, they can provide a common\nlanguage and a conceptual model for research in natural language understanding.\nIn particular, such an opportunity seems to be emerging in research on\ncompositionality. This article shows several examples of the joint appearance\nof induction and coinduction in natural language processing. We argue that the\nknown individual limitations of induction and coinduction can be overcome in\nempirical settings by a combination of the the two methods. We see an open\nproblem in providing a theory of their joint use.",
  "text": "Towards Coinductive Models for Natural Language\nUnderstanding\nBringing together Deep Learning and Deep Semantics\nWlodek Zadrozny1,2,\nwzadrozn@uncc.edu\n1 College of Computing, University of North Carolina at Charlotte\n2 School of Data Science, University of North Carolina at Charlotte\nMay-November 2020; version 1.0\nAbstract\nThis article contains a proposal to add coinduction to the computational appa-\nratus of natural language understanding.\nThis, we argue, will provide a basis for\nmore realistic, computationally sound, and scalable models of natural language di-\nalogue, syntax and semantics. Given that the bottom up, inductively constructed,\nsemantic and syntactic structures are brittle, and seemingly incapable of adequately\nrepresenting the meaning of longer sentences or realistic dialogues, natural language\nunderstanding is in need of a new foundation. Coinduction, which uses top down\nconstraints, has been successfully used in the design of operating systems and pro-\ngramming languages. Moreover, implicitly it has been present in text mining, machine\ntranslation, and in some attempts to model intensionality and modalities, which pro-\nvides evidence that it works. This article shows high level formalizations of some of\nsuch uses.\nSince coinduction and induction can coexist, they can provide a common language\nand a conceptual model for research in natural language understanding. In particular,\nsuch an opportunity seems to be emerging in research on compositionality. This article\nshows several examples of the joint appearance of induction and coinduction in natural\nlanguage processing. We argue that the known individual limitations of induction and\ncoinduction can be overcome in empirical settings by a combination of the the two\nmethods. We see an open problem in providing a theory of their joint use.\nKeywords:\ncoinduction; coalgebra; natural language understanding; deep learning;\nsemantics; compositionality; natural language processing; NLP;\n1\narXiv:2012.05715v1  [cs.CL]  9 Dec 2020\nContents\n1\nIntroduction and Motivation\n2\n1.1\nMotivation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\nMotivation #1: The conceptual gap between deep neural networks and deep\nsemantic analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\nMotivation #2: Accuracy gap for long sentences between deep learning and\ndeep semantic models\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.2\nHypothesis\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2\nWhat is coinduction? Informally.\n8\n2.1\nCoinductive data, coinductive functions, coinductive proofs\n. . . . . . . . . . . . .\n9\n2.2\nWhat are coalgebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.2.1\nAlgebras describe constructions . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.2.2\nCoalgebras describe observations . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.3\nA few words about related concepts\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3\nNatural language processing is intuitively coinductive\n14\n3.1\nAutomata as a coalgebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2\nDialogue: why it matters that interaction is coinductive . . . . . . . . . . . . . . .\n15\n3.3\nMultimodal interaction coinductively . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.1\nRelating process algebras and coinduction . . . . . . . . . . . . . . . . . . .\n17\n4\nNL understanding: coinduction and induction together\n18\n4.1\nA motivating example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n4.2\nRecent examples of rules (induction) and neural networks (coinduction) working\ntogether . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.3\nComments and unresolved issues . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n5\nNot everything should be done via coinduction\n24\n5.1\nCompositionality is a challenge for neural networks . . . . . . . . . . . . . . . . . .\n24\n5.2\nDiﬃculties in learning algebra, arithmetic and formal reasoning . . . . . . . . . . .\n25\n5.3\nLimitations of coinductive view of human cognition . . . . . . . . . . . . . . . . . .\n26\n6\nDiscussion and summary\n26\n1\nIntroduction and Motivation\nIn this article we are proposing to add coinduction1 to the computational apparatus of\nnatural language semantics. This, we argue, will provide a basis for a more realistic, com-\nputationally sound, and scalable model of natural language understanding. Given that\nthe bottom up, inductively2 constructed, semantic structures are brittle, and seemingly\nincapable of correctly representing the meanings of longer sentences or realistic dialogues,\n1Throughout this article we use the term ‘coinduction’ in its most generic meaning, encompassing also\ncoalgebra, corecursion, and bisimulation. This terminology will be explained.\n2We use the terms ‘induction’ and ‘inductive’ in their logical and mathematical sense, e.g.\nas in\n‘deﬁnition by induction’ or ‘proof by induction,’ and not in the philosophical sense of deriving general\nknowledge from speciﬁc cases, as in ‘inductive reasoning.’\n2\nsemantics is in the need of a new foundation. Coinduction, which uses top down con-\nstraints, has been successfully used in the design of operating systems and programming\nlanguages. Moreover, implicitly it has been present in text mining, machine translation,\nand in some attempts to model intensionality and modalities. So, there is scattered evi-\ndence it works. Since coinduction and induction can coexist, they can provide a common\nlanguage and a conceptual model for research in natural language (NL) understanding.\nWe elaborate on this proposal in several ways.\nWe motivate it by discussing the\naccuracy and conceptual gaps between inductive and coinductive views of NL semantics.\nWe introduce the coinduction, coalgebras and related concepts focusing on intuitions\nand referring the reader to other works for in depth treatments. We show the natural\nmatch between coinduction and several natural language processing (NLP) tasks such\nas modeling dialogue and text mining.\nAnd we show examples of how induction and\ncoinduction can jointly improve the process of assigning representations to text.\nWe argue for the joint use of deep learning and deep semantics in natural language\nunderstanding. Just as the tensor product allows us to jointly explore and use two diﬀerent\nbut related algebras or vector spaces, we imagine induction and coinduction as jointly\nproviding a better foundation for NL understanding. Although in the remainder of this\narticle we try to convey some intuitions about their joint use, the mathematical and\ncomputational requirements for their optimal joint use are not at this point clear to us.\n1.1\nMotivation\nOur motivation to pursue this topic comes from two sources, which we elaborate below.\nThe ﬁrst one is the diﬀerence in concepts used in deep learning vs. traditional seman-\ntics. The second one has to do with the limitations of processing of long sentences using\nthe traditional semantic representation vs. the relatively successful assignment of much\nshallower structures using deep learning. Our proposal to think coinductively about the\nlatter allows us to incorporate both methodologies within a single conceptual framework.\n1.1.1\nMotivation #1: The conceptual gap between deep neural networks and\ndeep semantic analysis\nIntuitively there is a gap between using deep neural networks for natural language process-\ning (NLP) and using deep semantic analysis for natural language understanding (NLU). If\nwe dig deeper into this gap we might observe that their conceptual apparatus is diﬀerent.\nReading the textbooks. This can be perhaps most clearly seen in the new version of\na leading NLP textbook. Looking at Chapter 16 “Logical Representations of Sentence\nMeaning”3 we notice it not sharing the vocabulary of the encoder-decoder and embedding\nmodels introduced earlier in the book. This is not a criticism of the book: ﬁrst, this is\nwork on progress; second, a currently missing section might create a bridge. Our point is\nthat a bridge is needed.\nTo reverse the perspective, logical representations do not appear in deep learning\nfocused NLP books such as Hapke et al. [2019] and Zhang et al. [2020], and NLP doesn’t\n3We are using here the manuscript from https://web.stanford.edu/~jurafsky/slp3/, version from\nOctober 16, 2019\n3\nappear as topic in Goodfellow et al. [2016].\nA similar gap can be seen in Bird et al. [2009], where lambda calculus and discourse\nrepresentation is avoided in the sections mentioning the applications of logistic regression\nand Naive Bayes to NLP, and vice versa.\nEven much earlier the problem of bridging the two views of language, one governed\nby rules and the other by observations was discussed at length (e.g. Klavans and Resnik\n[1996]), but arguably with little impact on the ﬁeld. Somewhat similar sentiment has been\nexpressed more recently in Manning [2015], commenting on capabilities of deep learning:\n“really dramatic gains may only have been possible on true signal processing tasks.”\nThis article takes the position that such bridge should be formed by creating an\nabstraction of both approaches, and not by an ad hoc combination. The value of this\nabstraction could lie in informing the theory, i.e. models of meaning, but it could also\nbe in guiding the process of creation of better tools for human-computer interaction and\nnatural language understanding.\nThe historical analogy we might keep in mind is the creation of modern computer\narchitectures and operating systems (e.g. Auslander et al. [1981]), which introduced new\nlayers of abstraction (e.g. process streams) and new disciplines (e.g. software engineering).\nWhat about recent research? There was no research article on Google Scholar, as of early\nJune 2020, mentioning “mathematics of deep learning” and “logical inference,” although\naspects of both are covered in experimental research – “deep learning” + “logical infer-\nence” produces about 800 hits. Thus, combining logical and neural model is an active area\nof research. For example, Hudson and Manning [2019] presents a data set for question\nanswering using both scene graphs modeling of elements present in images and challenging\nquestions about them. In context of a diﬀerent problem, Zhang et al. [2019] discuss en-\nsuring factual correctness of summaries, using two models, one logical (to attend to facts)\nand one neural (for reducing the size of the document). In our third example, Richardson\net al. [2020] show that neural attention based models such as BERT [Devlin et al., 2018]\ncan be retrained to master aspects of natural language inference. On the other hand, the\nexamples we present in Section 5 show that deep neural networks still seem incapable of\ndeeper reasoning without special purpose architectures, and even modeling elementary\narithmetical operations is a challenge.\n1.1.2\nMotivation #2: Accuracy gap for long sentences between deep learning\nand deep semantic models\nThere is a gap in the accuracy between deep neural networks and deep semantic analysis,\nirrespective of the fact that they try to address diﬀerent aspects of natural language\nunderstanding.\nTable 1, viewed through the lenses of the systems’ ability to successfully attend to long\nsentences, shows in the left column intuitively ‘successful’ NLP applications; and in the\nright the areas where in our view we have seen limited progress in the last 30 years.\nObviously, metrics used by the applications mentioned in the two columns are diﬀerent.\nFor example, one can argue that computational pragmatics did not exist 30 years ago, and\nonly recently we have started to see computational, probabilistic models of pragmatics\n4\n“Automata”\n“Structures”\nPOS Tagging\nParsing\nText Mining (e.g. Person, Date, ... )\nComputational Semantics\nGoogle Search\nComputational Pragmatics\nGist Translation\nGood Translation\nTable 1: On the left, one intuitive computational model is that of an automaton, with\ndata coming as inﬁnite streams (esp. for training). On the right the models are assembled\ninto structures (often by hand) from previously deﬁned components. The accuracy of the\nmodels on the left is higher. However, the automata-based approach has problems dealing\nwith task requiring deeper inference.\n[Franke and J¨ager, 2016] [Scontras et al., 2017],4, which suggests a big jump. Nevertheless,\nthe areas on the right do not scale with sentence length. And later, in Sections 2 and 3,\nwe will argue, from a more abstract perspective, that the diﬀerences between the columns\ncan be attributed to the diﬀerences in their respective computational models.\nLet us discuss long sentences. Prior research in this area shows how parsing accuracy\ndecreases with the length of the sentence.\nFor example, McDonald and Nivre [2007]\nobserve fast drop in precision and recall of dependency parsing with the increase of the\ndependency length, the distance to the root, and length of sentences.\nSimilar results\nappear in Fig.4 of Choi et al. [2015]. Actually the situation might be worse than these\nsources suggests. In an analysis of parsing of sentences up to the length of 156, Boullier\nand Sagot [2005] entertain a possibility that “(full) parsing of long sentences would be\nintractable.” Clearly, deep neural networks improved the accuracy of parsing. However,\neven with the attention-based models, Nivre [2020](Fig.4) reports a ∼20% drop in the\nlabeled attachment scores when the dependency length increases from 1 to 5.\nThis is clearly a problem, even for linguistically oriented data sets. A recent statistics\ngiven in Borb´ely and Kornai [2019] shows that depending on the language and the corpus\nthe average sentence length is 19-38 words.\nHowever, thousands of sentences in each\ncorpus are longer than 100 words. The average sentence length in the Penn Treebank is\n20.54 words (and the standard deviation of 8.6); in Genesis, 34 words; but, per classic\nYule [1939], in “Biographia Literaria” 10% of sentences are long and have the average\nlength of about 70 words.\nThe situation is even more problematic when we switch from general corpora to speciﬁc\nones. In our previous work [Rajshekhar et al., 2016], we discussed the problem of parsing\nlong sentences in the context of legal text corpora, namely patents. Fig. 1 (op.cit.) shows\nthe distribution of the lengths of the main patent claim (Claim 1).\nThese claims are\nexpressed as single long sentences. The sentences of Claim 1 average 150-180, and can\nbe up to 1400 words long (diﬀerent weekly data introduce the variation). Although the\nextreme length is due to legal rules, nevertheless we note that 93% of the claims in this\nseries are longer than 50 words. This means that any analysis of an average Claim 1 is\nlikely to be wrong. (In our unreported experiments in 2018 on a handful of claims about\n4https://michael-franke.github.io/probLang/\nhttp://www.mit.edu/~tessler/short-courses/\n2017-computational-pragmatics/ last retrieved on May 13 2020\n5\nFigure 1: Distribution of Claim 1 sentences lengths in 4000 patents related to sustainabil-\nity. Note that over 90% of sentences are longer than 50 words. (From Rajshekhar et al.\n[2016]).\n30 words long, using diﬀerent dependency parsers, we did not get even a single correct\nparse).\nWhat about semantic parsing? Semantic representations are diﬃcult to build even for\nshort sentences, as shown in Fig. 2, from Abzianidze et al. [2020]. All systems submitted\nto the competition on the shared task on semantic parsing show a drop in accuracy as the\nlength of the sentence increases.\n6\nFigure 2: Semantic representations are diﬃcult to build even for short sentences, as shown\nby Abzianidze et al. [2020]. All systems report drop in performance with the sentence\nlength.\n1.2\nHypothesis\nAdding coinduction to semantics can provide a foundation for a more realistic, computa-\ntionally sound and scalable model of natural language understanding.\nWe are proposing adding coinduction to the computational apparatus of semantics.\nThis we argue, will provide a basis for a more realistic, computationally sound and scalable\nmodel of natural language understanding. Given that the bottom up, inductively con-\nstructed semantic structures are brittle, and seemingly incapable of representing longer\nsentences or realistic dialogues, semantics is in the need of a new foundation. Coinduction,\nwhich uses top down constraints, has been successful in the design of operating systems\nand programming languages. Moreover, one can argue that implicitly it has been present\nin text mining, machine translation and in some attempts to model intensionality (even\nthough the term itself does not appear in any articles on aclweb.org). In Barwise and\nMoss [1996], which is a good introductory textbook, it is used to describe self reference,\nparadoxes and modal logics.\nSo, there is scattered evidence coinduction works. Since coinduction and induction\ncan coexist, they can provide a common language and conceptual model for research in\nNL understanding.\nWe should mention that one of the ﬁrst theoretical proposals to look at agent interac-\ntion as coinduction appeared in Wegner and Goldin [1999], and it included explicit men-\ntion of NL dialogue and question answering. Within the following twenty years, as argued\nin the present article, the focus of NLP shifted towards coinductive methods5, namely\n5This shift occurred without ever mentioning the concept itself. There are literally 12 entries mention-\ning ”deep learning” and ”coinduction”, mostly accidentally, although Elliott [2019] (a formal analysis of\nconvolutions) is an exception. (As of October 2020).\n7\ndeep learning, with the theoretical justiﬁcation coming from the universal approxima-\ntion properties of neural networks. This article summarizes some of these developments\nand argues for an explicit introduction of the term ‘coinduction’ to the vocabulary of NLP.\nTo make the argument, we will focus on the following questions:\n1. What is coinduction?\nThat is, we will discuss coinductive data, coinductive functions, coalgebras and\ncoinductive proofs (only marginally). See Sections 2 and 3.\n2. Do we need it?\nWe have already started to argue that we do.\nBut we’ll expand on it below in\nSections 4 and 5, where the main point will be the advantages of combining inductive\nand coinductive information, and contrast it with the inadequacies of only using a\nsingle approach. The empirical arguments presented there are based on results taken\nfrom the work of other researchers and recast in the language of coinduction.\n3. What can be our next steps?\nIn Section 6 we hypothesize that the practical and theoretical importance of the\njoint inductive-coinductive approach to natural language understanding will most\nlikely be seen in models of compositionality.\n2\nWhat is coinduction? Informally.\nAlthough coinduction and coalgebra do not appear in the aclweb.org repository of NLP\narticles. We will argue that there is already quite a bit of research in NLU and in semantics\ndone in the co-inductive style; it just hasn’t been named ‘co-inductive’. We want to argue\nthe “classical”-style formal semantics can be extended with new problems to bridge the\ngap between “coinductive” and “inductive” views of the data.\nBefore we attempt to answer the question “what is coinduction,” we want to infor-\nmally discuss what this speculative paper is about?\nNamely, in theoretical computer\nscience we have the concept of co-induction, or coinduction (which is the spelling we will\nuse).\nInduction builds structures bottom up and can be viewed as a reductionist pro-\ncess,6 while coinduction provides top down constraints. Our main idea is to base NLU\npartly on coinduction, for example to provide better models of dialogue and to address\nthe problem of parsing and understanding of long sentences. We believe, coinduction can\nbe incorporated into NL semantics, helped by the fact induction-coinduction relationships\nare relatively well investigated in formal logic and theoretical computer science. Empirical\nevidence suggests we will be more successful in addressing diﬃcult problems.\nFive questions about coinduction we need to answer\n• What is coinduction?\n6Objects are reduced to their parts.\n8\n• How might coinduction be applicable to semantics?\n• Has coinduction been applied to formal semantics of NL?\n• What are the limitations of coinductive view of NLP?\n• What kind of problems might be amenable to progress using a joint induction-\ncoinduction approach?\nThis exposition will be a bit less formal than in a properly technical article, but\nit’s good to start somewhere, and we’ll provide complementary references explaining the\nlogic(s) of coinduction.\nAs we said earlier, applying coinduction to natural language\nprocessing is an open problem, and this article only intends to show likely places of\nintersection between the two ﬁelds.\n2.1\nCoinductive data, coinductive functions, coinductive proofs\nWe will use ”coinduction” in the most generic meaning, to mean the three aspects of\ncoinduction:\n• coinductive data\n• coinductive functions\n• coinductive inference: models and proofs\nWe will mostly focus on the ﬁrst two bullets. We will not be breaking any new grounds\nhere, either in having any insights or in arranging the material; we simply will reuse well\nknown examples. These examples will later be used as formal models for various natural\nlanguage phenomena, such as turn taking in modeling NL dialogue (Section 3.2.\nTo develop computational intuitions about coinduction, we start with two very generic\nand known examples from programming, appearing e.g. in Python, Haskell and Prolog.\nThe examples introduce the concepts of codata, coinductive program, constructor and\ndestructor, see e.g. Gordon [2017].\nExample 1. Coinductive data: two styles of list\nData: The 4-element ﬁnite list L4 = [1, 1, 1, 1] is built by specifying\nL4 = cons(1, cons(1, cons(1, cons(1, nil))))\nwhere cons is a list constructor and nil, the empty list, a nullary constructor.\nCodata: The inﬁnite list\nL1 = [1, 1, 1, 1, ...]\nis deﬁned by specifying hd(L1) = 1 and tl(L1) = L1, where hd and tl are destructors.\n9\nExample 2. Coinductive programs: two styles of addOne\nRecursion (ﬁnite lists, step by step):\nAddOne(nil) = nil\nAddOne(cons(n, l)) = cons(n+1, AddOne(l))\nCorecursion (inﬁnite lists with lazy evaluation):\nnull(AddOne(l))=(l=nil)\nhd(AddOne(l))=hd(l)+1\ntl(AddOne(l))=AddOne(tl(l))\nThe recursively deﬁned AddOne maps ﬁnite lists to ﬁnite lists; the corecursively deﬁned\nAddOne maps ﬁnite lists to ﬁnite lists and inﬁnite lists to inﬁnite lists.\nMore generally, recursion deﬁnes a function mapping values from a datatype by invok-\ning itself on the components of the constructors used to build data values. Corecursion\ndeﬁnes a function mapping to a codatatype by specifying the results of applying destruc-\ntors to the results of the function.\n2.2\nWhat are coalgebras\nWe will introduce the concept of coalgebra informally, through a few examples, and we\nwill mostly follow the exposition from Jacobs [2017], Jacobs [2011] and Rutten [2000]. We\nwill illustrate the concepts using well known examples from natural language processing\n(NLP).\n2.2.1\nAlgebras describe constructions\nWe are assuming the reader is familiar with the concepts of an algebra. An algebra, for\nexample, an algebra of sets, a Boolean algebra, a group or a vector space, is deﬁned by\nspecifying its domain and its operations. Well known examples include set union and set\ndiﬀerence; conjunction, disjunction and negation for Boolean algebras; multiplication and\ninverse for groups; and vector addition for vector spaces. In all these cases, the operations\nconstruct new elements from the elements of the algebra. Pictorially, algebras with a\n”carrier” X are maps into X from some type of system or structure or an expression\ncontaining X (shown as a box below).\nX ... X\nc\n−→X\n10\nFigure 3: A grammar can be viewed as an algebra on trees, where two trees can be\ncombined through adjunction, pictured here, or substitution (not shown). The ﬁgure is\nreproduced from Joshi and Rambow [2003], Figure 3.\nIn NLP, we can view a grammar as an algebra deﬁning how smaller parse trees can\nbe combined into bigger trees; perhaps this is best shown in the case of tree adjoining\ngrammars (TAGs), in Fig.3, where the operation of adjunction a of pairs of trees can be\nrepresented as\nTrees × Trees\na\n−→Trees\nor simply a : Trees × Trees −→Trees.\nThis representation focuses only on types in\nthe domain and codomain (range) of the function a, and we will see in a moment that\nin coinduction, which we will use to represent named entity recognition (NER) in NLP,\nwe simply reverse the arrow. Notice that this representation tells us nothing about any\nconstraints that the pair of trees has to satisfy for a being applicable. Such constraints\nhave to be speciﬁed separately, as they usually are.\n2.2.2\nCoalgebras describe observations\nIf we were to create an ”algebraic” view of the standard named entity extraction operation,\nwe would need to put the box on the other side.\nX\nc\n−→\nX ... X\n11\nFigure 4: Named entity recognition adds annotations to the text. In this example, the\nsemantic types organization, .... are added to a fragment of a Wikipedia article. Note\nthe imperfections. (We used http://corenlp.run/ Stanford CoreNLP 4.0.0, updated\n2020-04-16, to obtain these annotations, but such annotations are never perfect).\nFor example, let us take X = Sentences to consist of lists of words produced by a\nsentence ﬁnding algorithm on a corpus of text data. Finding named entities or seman-\ntics types in the sentences, e.g. person, city, geopolitical entity, cardinal etc.,\nproduces new lists of words together with IOB tags, indicating positions of the substring\nwith speciﬁc properties and these tags, as shown below in formula (1), appear instead of\nthe ”...” ellipsis.\nAs shown in Figure 4 and Table 2, ﬁnding entities of interest in this model consists in\nadding information to the original, that is creating a table with observations.\nNotice we are not constructing new strings, we are observing the text and ﬁnding items\nof interest, i.e. named entities, and we are adding annotations to the text. This change\nof perspective creates a co-algebraic view of the text. Notice the diﬀerence: sets of trees\nwere combined into new trees in the previous example; however, for NER we transform\nsentences into expressions containing the words of the original sentences and the IOB\nannotations.\nReplacing the box by the actual types involved in producing the annotations we get,\nfor the simple case of looking for the person type:\n(Words)<ω\nner:city\n−−−−−→(Words × {I, O, B})<ω\n(1)\nThat is, ner:city takes ﬁnite lists of words and produces ﬁnite lists of words with the\nI,O,B labels. The speciﬁcation of a more complex NER task will be more complex, but\nour point here is that we are not building new structures but annotating existing entities;\ni.e. we are not constructing but observing.\noﬃcially\nLeland\nStanford\nJunior\nUniversity\n[12]\nO\nB\nI\nI\nI\nO\nORGANIZATION\nTable 2: Looking at the details of annotations in Fig.4, the IOB annotations show the\nbeginning B, inside I and outside O of the entity.\n12\nFigure 5: Named entity recognition or semantic type recognition adds annotations to the\ntext. In this example, the semantic type cardinal is added to a fragment of a patent\nclaim. Note that although “at least one” is annotated properly, “one or more” is not.\n(We used http://stanza.run/ to obtain these annotations in June 2020).\nAlso, as shown in Fig. 5, observations can be incomplete or contain errors. The point\nof using coalgebraic (or coinductive) speciﬁcations is to make analysis resilient to errors,\nand produce partial useful output.\n2.3\nA few words about related concepts\nThroughout this article we are using the words “coinduction” and “coinductive” in their\nwidest meaning, because we see it as name for a point of view and a generic computational\napproach7.\nWe will also use these terms in a narrower technical sense referring to a\nspeciﬁcation of how data can be broken down into simpler items or annotations added to\nthem by observation. There is also another narrower meaning of these words, referring to\na proof technique, which is a “dual” of familiar proofs by induction – we will not concern\nourselves with this speciﬁc sense.\nThere are a few other related concepts which are mathematically important, but here\nwe only want to acknowledge their existence, and perhaps provide additional intuitions.\nFor the readers familiar with logic programming it might be helpful to think in terms\nof largest vs. smallest models.\nWhen we give an inductive deﬁnition, we mean the smallest set that satis-\nﬁes the given constraints; everything that’s in the set has some justiﬁcation.\nWe build the smallest model (i.e. the smallest ﬁxpoint of the construction).\nCoinductive deﬁnitions specify the largest set that is consistent with them.\nThe construction of a model proceeds by ﬁnding the largest ﬁxpoint consistent\nwith the speciﬁcations8.\nA question worth asking is: which of the two constructions will be more robust in\nreal applications? It is our intuition that largest models might tolerate better noise and\nnovel data, including new expressions and errors in text. Usually, irrelevant things are\n7An alternative could be to use the words ”coalgebra” and ”coalgebraic”\n8This particular reference might be helpful for the reader struggling with intuitions: https://ask.\nmetafilter.com/42858/What-the-heck-is-coinduction\n13\nconsistent with speciﬁcation, so with coinductive constructions, we do not have to predict\nin advance all possible cases.\nFor other potentially relevant concepts such as corecursion and bisimulation (which\nwe are not using in this article), as well as in depth treatment of ﬁxpoints and coinduction,\nwe would like to refer the reader to Barwise and Moss [1996].\nIn the next section we will informally introduce process algebras, in the context of\nmultimodal dialogue, and informally describe their connection to coalgebras.\n3\nNatural language processing is intuitively coinductive\nWe saw a moment ago that a formal deﬁnition of named entity recognition, a common\nNLP task is coinductive in its form. Now we will go through a list of standard NLP\ntasks and talk about them using the jargon of coinduction. The point of this exercise\nis twofold: to get used to coinductive deﬁnitions and to show that there is a common\nthread to solving natural language processing and understanding problems that require\nabandoning the standard inductive, build step-by-step construction of meaning.\n3.1\nAutomata as a coalgebra\nFinite state automata are widely used in NLP, as shown in the list and discussion below.\nThey are naturally described in the language of coalgebras:\nc : S →{halt} ∪(A × S)\n(2)\nHere, S is a set of states, c is a transition function, and A are outputs (or observables).\nNote that this formula does not constrain us to ﬁnite state automata, that is this speciﬁ-\ncation is more general.\nExamples of ”automata” used in NLP with coinductive representations:\n• Any regex\n• Chunkers that can operate with limited information; e.g. sentence splitters, phrase\nﬁnders, ”,”-ﬁnders, part of speech taggers, etc.\n• Binary neural networks\n• RNNs (LSTMs, BERT encoders)\nWith some modiﬁcation of the above transition function, and making the outputs\nA more speciﬁc, along the lines of formula (1), we can intuitively see the coinductive\ncharacter of the ﬁrst two items on the list. The other two items are perhaps less intuitive.\nHowever, binary neural networks are ﬁnite state automata (see ˇS´ıma [2020] for a more\nin depth recent discussion); recurrent neural networks (RNNs) share the same spirit but\nwould have more complex deﬁnitions (see e.g.\nCarlsson and Gabrielsson [2020] for a\nmathematical description of feed forward NNs). Actually, Sprunger and Jacobs [2019]\nshow that learning in artiﬁcial neural networks is coinductive (at least for some types of\nRNNs). The above list covers perhaps the majority of techniques used in NLP. Moreover it\n14\nexempliﬁes the techniques used to address the NLP problems in the left hand side column\nof Table 1. However, we want more, that is an argument that coinduction provides a\nnatural description of several unaddressed problems in language understanding, and in\nparticular the right hand side of the same table.\n3.2\nDialogue: why it matters that interaction is coinductive\nA conversation can be viewed as an unbounded sequence of turns modifying the internal\nstates of the interlocutors. Note that only the exchanged words are observable, but ob-\nviously conversations change us. Some conversations are ﬁnite (e.g. hotel reservations),\nbut some are ”inﬁnite”, for example between members of the same family.\nEven our\nGoogle searches are better viewed as inﬁnite conversations, where our past interactions\nand current states (e.g. location) together with the query produce a list of results but\nalso modify the state of the Google search engine (which cannot be observed).\nDialogue coinductively. Natural language dialogue can be described as a very simple\ncoinductive process consisting of a ﬁnite or inﬁnite collection of utterances, using the\nautomaton equation (2).\nturn: States −→{halt} ∪(Who × Words<ω × States)\n(3)\nStates are not observable and are the internal states of interlocutors, labeled by Who.\nLabels and utterances can be observed.\nThis model is perhaps too simplistic. However it is ﬂexible enough to capture both\nrecent attention-based neural network models of dialogue ([Budzianowski and Vuli´c, 2019])\nand recent challenges to standard views of dialogue in linguistics (Gregoromichelaki et al.\n[2020]).\nThis correspondence deserves a longer discussion. In a ”classical” view of NL dialogue\n(e.g. Bird et al. [2009], Chapter 1), each utterance is a sentence or full phrase that can\nbe assigned linguistic meaning independently of other utterances. This conceptual model\nadmits exceptions, e.g. fragments that had to be interpreted using other, context driven\nmechanisms. A more recent view Gregoromichelaki et al. [2020] postulates a model in\nwhich a single sentence structures can be emerging across participants, and where speaker\nand hearer can exchange roles across all syntactic and semantic dependencies:\nRuth: I’m afraid I burned the kitchen ceiling.\nMichael: Did you burn\nRuth: myself? No, fortunately not.\nA: Have all the students handed in\nB: their term papers?\nA: or even any assignments?\nObviously, formula (3) is a good high level model of such exchanges. But it needs\nto be augmented to correctly model the linguistic acceptability of the above and the un-\ngrammatical nature of e.g. any even assignments or?. A general linguistically motivated\n15\nmethod of doing so, given by Gregoromichelaki et al. [2020], is based on ”dynamic syntax”,\nKempson et al. [2000]. In a very practical setting of task oriented dialogues, our earlier\nwork, Zadrozny et al. [2000, 1998], handled similar fragments by ﬁnding most likely seman-\ntic representations, derived from an implementation of a construction grammar (Goldberg\n[1995], Zadrozny et al. [1994], Zadrozny and Manaster-Ramer [1995]). Thus both theory\nand practice seem support this abstraction.\nIt is our view that for practical applications, and, in particular, to be able to correctly\nassign semantic structures to long sentences, as discussed earlier in Section 1.1.2, a com-\nbination of coinductive and syntactic constraints is necessary. The exact proportion and\nformal role of each is an open issue. It might be the case though that they would have\ncomplementary origins, where the coinductive constraints are learned from observations\nusing machine learning mechanisms, and the grammatical constraints would come from\nhuman designed formal grammars. We will return to this later in Section 4, providing\nexamples of coinduction and induction working together and in Section 5 to argue that\nnot everything should be done by coinduction.\n3.3\nMultimodal interaction coinductively\nA natural extension of spoken dialogue is multimodal dialogue between people, involving\nboth speech and gesture. More broadly multimodal interaction can involve humans and\nmachines communicating using speech, handwriting, hand gesture and gaze.\nInterestingly, there is already an explicit use of coinduction to account for speech-\ngesture interaction Rieser [2017], even though the term ”coinduction” does not appear\nthere. However, the term “process algebra” is in the title, and the particular version of\nprocess algebra, the ψ-calculi are closely related to coinduction (see below). The cited ar-\nticle argues that to account for split utterances, in the spirit of examples shown in Section\n3.2, and to account for the asynchronous multimodal communication and coordination, a\nbetter model is required than “naive compositional” models canonically employed in NL\nsemantics. Namely, a model in which we have:\n— channels on which information (data, agents or procedures) can be sent;\n— procedures operating concurrently;\n— interfaces enabling communication among processes;\n— active and non-active processes;\n— communication among agents organized via an i-o-mechanism, and where\n— “composition does play a role ﬁnally, when the speech-gesture contact points have\nbeen identiﬁed.”\nThese are natural postulates in context of multimodal interaction. Semantically, they\nsignify a transition from a static model of semantics to a dynamic one. This is similar\nin spirit to the “dynamic syntax” approach to dialogue mentioned above, except that\nconcurrency is allowed.\nCompositionality plays an important role but needs to be modiﬁed, because gestures\ncan last over any sequence of words in the sentence, and therefore there is no natural place\nfor integrating the two modalities. Therefore, description of speech-gesture coordination\ncannot be given solely in a naive/static compositional way. Instead, as described in Lawler\net al. [2017], Rieser [2017], speech and gesture processes operate in parallel to create initial\n16\nFigure 6: Application areas for coalgebras, based on a table in Kurz [2001]. The arrows,\nadded by us, point to the areas directly applicable to computational linguistics.\nrepresentation for the meaning of the gesture and a partial semantic representation of\nthe speech. Final meaning of the gesture is derived from the constraints present in the\nsemantic representation of the speech. The latter is combined with the ﬁnal meaning of\nthe gesture compositionally.\nNotice that initially the two channels are observed separately, and annotated. This\nshould remind us of the {I,O,B} annotations. In other words, we see a productive use of\nboth compositional/inductive and process algebra/coinductive methods.\nFinally, we should mention that one of the ﬁrst theoretical proposals to look at agent\ninteraction as coinduction appeared in Wegner and Goldin [1999], and it included explicit\nmentions of NL dialogue and question answering. Within the following twenty years, as\nargued in in this article, the focus of NLP shifted towards coinductive methods, without\never mentioning the concept.9\n3.3.1\nRelating process algebras and coinduction\nIntuitively, process algebras are connected to coinduction as follows:\n— A process algebra, from a very abstract level is a collection of processes, and can\nbe viewed as a very complex automaton;\n— As we have above in Section 3.1, an automaton can be viewed as a coalgebra;\nThe tutorial Kurz [2001] discusses this relationship in details; see also Ribeiro et al.\n[2006] for “a coinductive rephrasal of classic process algebra.” Based on the cited sources,\nwe can say:\nProcess algebra ≃Coalgebra ≃Coinduction\n9There are literally 12 entries mentioning ”deep learning” and ”coinduction”, mostly accidentally,\nalthough Elliott [2019] (a formal analysis of convolutions) is an exception\n17\nThat is, we can map between the three formalizations, even if such mappings could\ninvolve some subtle points. Informally, the formalisms can be viewed as roughly equiva-\nlent. This can also be seen in Figure 6, based on Kurz [2001], showing application areas\nof the coalgebra approach (we added the arrows to point to the areas relevant for NLP).\n4\nNL understanding: coinduction and induction together\nThe hypothesis we are pursuing in this paper is that coinduction and induction are both\nneeded for NL understanding. The argument we are making is based on computational\nand linguistic intuitions, and on circumstantial evidence. We would view the hypothesis as\nexperimentally proven if NL models employing both approaches outperform other models\nfor most tasks.\nAs shown in Section 4.2, indeed there are relatively strong empirical\narguments that this might be the case, although of course our selection of examples is\nbiased.\nBefore we look at the empirical results, let’s start with a manual analysis to\ndevelop an intuition for their joint use.\n4.1\nA motivating example\nIn this section we want to show how coinduction and induction could work together in as-\nsigning meaning to a poorly formed sentence. This is a ﬁctional example, perhaps beyond\ncapabilities of real systems. In the subsequent subsection, we will discuss implemented\nsystems that combine neural and grammatical information.\nExample 3. Understanding a sentence from The Corpus of Linguistic Acceptability\n(CoLA)10 [Warstadt et al., 2018]. Consider one of the longer sentences from CoLA:\n*The younger woman might have been tall and, and the older one deﬁnitely was,\nblond.\nLet us assume the sentence comes from a dialogue transcript.\nDialogue sentences\noften have surprising structures.11 Even though marked “ungrammatical” the sentence is\nunderstandable, and parses (perfectly?) with Stanford Stanza v.1.0.0 dependency parser12\n[Qi et al., 2020]. However, the parse only has relationships between pairs words, so an\ninterpretation of the sentence needs to be constructed. The construction story, as we\n10https://nyu-mll.github.io/CoLA/\n11A well known example is “John thinks bananas.” The sentence is ‘ungrammatical’ without the pre-\nceding “What will Jane have for breakfast?”\n12http://stanza.run/\n18\nare imagining it, would be of coinductive and inductive composition, shown in the steps\n1-6 below. We can imagine the following sequence leading to an interpretation. For the\nsake of the argument, let us assume the interpretation will be a discourse representation\nstructure (DRS).13\n1. Coinductively we ﬁnd the boundaries of the sentence and sentence chunks.\nNote. Pattern matching works well here, e.g. probabilistic automata, or equivalent\nhidden Markov models for chunking; another option being a combination of pattern\nmatching and a neural network Qi et al. [2020].\n2. Inductively (CFG) or coinductively (data trained dependency parser), structures\nare assigned to the parts and/or the whole.\n3. Some predicate(argument) semantics is assigned to the structures using pattern\nmatching or attributed grammars (e.g. Bird et al. [2009] McCord et al. [2012]. This\nproduces constraints on a resulting DRS.\nNote. The method for assigning the constraints is not important; the point is that\nwe do not have a full speciﬁcation of semantics, but perhaps we have a partial one.\n4. Coinductively (in written text), we ﬁnd the “, phrase,” pattern (or construction)\nof a string between two commas.\n5. Inductively, we try to apply the ellipsis as a possible meaning frame.\nNote: Actually several frames could be applied in parallel, e.g. apposition.\n6. Inductively, we see that younger woman:tall and blond is a possible interpreta-\ntion. We add it to the DRS (and check its consistency).\nThe main point of this example is to show the plausibility of using both pattern\nrecognition (Steps 1, 3 and 4) and inductive steps (2, 5 and 6). Speciﬁcally, the possible\nmeanings of ellipsis are usually given by a grammar.14\n4.2\nRecent examples of rules (induction) and neural networks (coinduc-\ntion) working together\nIn this section we present a few selected results in various subdomains of natural language\nprocessing showing superior performance of a combination of inductive and coinductive\nmethods. We interpret them as supporting our view that induction and coinduction should\nboth be used in the process of language understanding. Obviously, our selection is biased,\n13https://plato.stanford.edu/entries/discourse-representation-theory/\n14We also note that the process described above seems roughly consistent with the chunk-and-pass\nmechanism postulated by Christiansen and Chater [2016]. In view of that mechanism, the ungrammati-\ncality of the sentence could be attributed to the need to backtrack to apply the ellipsis, since the grammar\ndoes not license the ellipsis in the middle of the phrase. An alternative interpretation would give us a\nrepair, corresponding to The younger woman might have been tall and the older one deﬁnitely was blond\n(a less interesting possibility, although more plausible if the sentence was spoken, with commas standing\nfor pauses).\n19\nFigure 7: Like earlier, in Fig.2, we see a quick drop in performance with longer sentences,\nwhen dependencies become longer distance. The task is semantic role labeling and this\nﬁgure is taken from the cited paper He et al. [2017].\nbut the examples are worth noting. In the next section, we discuss examples which seem\nto be uniquely hard for NN, but are extremely easily formalized inductively; namely, we\nwill switch to the world of mathematics.\nExample 4. Predicate argument structure. Our ﬁrst example, from He et al. [2017],\nis a classical task of semantic role labeling (SRL) which is determining the predicate-\nargument structure of a sentence, i.e. “who did what to whom.” The authors also discuss\nthe impact of using “gold syntax” (hand-annotated text data) and syntactic parsers on\nSRL. Their best model uses “gold syntax.”\nThey observe the following relation between deep learning models and parsers:\nExtensive empirical analysis of these gains show that (1) deep models excel at\nrecovering long-distance dependencies but can still make surprisingly obvious\nerrors, and (2) there is still room for syntactic parsers to improve these results.\nHowever, and similarly to Fig. 2, they observe a quick drop in performance for longer\nargument dependencies. This is shown in Figure 7.\nTheir result and cited analysis can be viewed as supporting our thesis on the potential\nsuperiority of hybrid models. The cited paper uses a deep learning model (coinductive,\nby Section 3.1) and an inductive complement, namely, a syntactic parser for encoding\nstructure and the raw “gold syntax” (from hand annotated data). When discussing the\nrole of syntax in SRL, the article also says “there is signiﬁcant room for improvement\ngiven oracle syntax but errors from existing automatic parsers prevent eﬀective use in\nSRL.”\nThis suggests to us that more research is needed on how to eﬀectively combine syntax\nand deep learning methods. Although the performance of hybrid methods is superior, the\nground level problem of understanding the structure and meaning of longer sentences has\nnot been solved. Likely, a solution to this problem will require a subtle interaction be-\ntween the knowledge encoded in inductive structures and the statistical patterns encoded\n20\nFigure 8: Tseo et al. [2020] proposes another hybrid systems combining attention, word\nembeddings, context free grammars and several knowledge bases.\nin weights of the deep learning model.\nExample 5. Information extraction:\nOur next example also focuses on semantics. A\nrecent article by Tseo et al. [2020] addresses the problem of extracting criteria for clinical\ntrials using a novel architecture shown in Fig.8. It combines attention-based conditional\nrandom ﬁelds for named entity recognition (NER), word2vec embedding clustering for\nnamed entity linking (NEL), a context free grammar and a knowledge base. This system\nachieves a state of the art performance.\nThe point of this examples, and the similar ones cited in this article, is to show that in\npractice we often beneﬁt from a combination of methods. The other reason is to show that\nthese are not one-oﬀexamples. Instead, they suggest, there is potential to generalize this\npractice using the tools of theoretical computer science, i.e. induction and coinduction.\nExample 6. Machine translation: comma analysis for rule-based machine trans-\nlation and for patent translation. Even though the two examples we cite below pertain\nto machine translation, they also touch upon two topics discussed earlier: the diﬃculty\nof parsing long sentences and the complex structure of patents (Section 1.1.2, as well as\nFig.5 in Section 2.2.2).\n• Long sentences are not only diﬃcult to parse and interpret, but also diﬃcult to trans-\nlate. In building an English to Korean machine translation system, Kim [2019] ﬁrst\nclassiﬁes the usages of commas into nine standard grammatical functions, including\nvarious types of series (e.g. adjectives and conjuctions), parenthetical, appositives\netc. This is done using a support vector machine. The syntactic analysis is then\nperformed according to the roles of the commas. The result of these preprocessing\nsteps is improved quality of machine translation.\n21\n• The second example comes from the domain of Chinese-English patent machine\ntranslation. Li and Zhu [2016] identify commas which separate sub-sentences and\nnon-sub-sentences, using two methods, one employing word knowledge and formal\nrules and the other machine learning. The rule-based method achieves over 93%\naccuracy (F1) improves translation accuracy. As in the above examples, diﬀerent\nfunctions of commas are discussed.\nExample 7. Parsing coinductively.\nThere is a tradition in linguistics to view syntax as a set of constraints, for example,\nDalrymple et al. [1993], Frank and Reyle [1995]. This tradition is alive and well in more\nrecent work, such as Gotham and Haug [2019], who view syntax as constraining possible\nsemantic interpretations. In a presentation,15 they explain their reasons for viewing syntax\nas constraints:\n• What the approaches just mentioned (i.e. Minimalism, Montague) have in common\nis the view that syntactic structure plus lexical semantics determines interpretation.\n• From this it follows that if a sentence is ambiguous, (...), then that ambiguity must\nbe either lexical or syntactic.\n• The Glue approach is that syntax constrains what can combine with what, and\nhow.\nIn our view, these points also explain why constraint-driven approaches to semantics\nare less brittle. Constraints are not deterministic and they occasionally can be violated;\nthe violations result in a penalty (i.e. higher value of the loss function), but without\ncompletely breaking of the parsing process. And although, bottom up parsing with a\ntraditional, context free, grammar can be relatively robust and produce partial parses,\nthe newer constraint-based parsers work better.\nFor semantic dependency parsing, a good discussion and details of the constraint-based\napproach, used with three diﬀerent dependency parsing formalisms, can be found in Peng\net al. [2017], where constraints are applied to a decoder in a bidirectional LSTM neural\nnetwork.\nFinally, we note the proposal for a more robust semantic parsing, based on a Type\nTheory with Records (TTR) [Cooper, 2005]. Interestingly enough, the lemma constrain(t)\nappears 36 times in the follow up work of Dobnik et al. [2012]. And we only need a small\nstep to make it explicitly coinductive: TTR is based on a stratiﬁed type system, and\nis built bottom up to avoid the Russell paradox [Cooper, 2012], but the stratiﬁcation is\nalready omitted in Larsson [2015] to ease the exposition. We know, from e.g. already cited\nBarwise and Moss [1996], that stratiﬁcation can be replaced with constraints; therefore,\npurely constraint-based models of TTR should be consistent.\n15We are citing almost verbatim from: Glue semantics for Universal Dependencies, Matthew Gotham\nand Dag Haug, CLASP seminar, Gothenburg, 8 March 2018. The parentheticals and emphasis are ours.\n22\nExample 8. Morphology.\nOur ﬁnal example of the use of hybrid methods comes from a recent article by Shmid-\nman et al. [2020]. To quote:\n“The system combines modern neural models with carefully curated declara-\ntive linguistic knowledge and comprehensive manually constructed tables and\ndictionaries.”\n“Our approach (...) uses several bi-LSTM based deep-learning modules for\ndisambiguating the correct diacritization in context. However, it is also sup-\nplemented by comprehensive inﬂection tables and lexicons, when appropriate.”\nThe problem the paper addresses is adding Hebrew diacritic markers. These markers\nare typically omitted in modern Hebrew, but have to be either implicitly understood or\nexplicitly added to remove ambiguities.\n4.3\nComments and unresolved issues\nWe have presented examples where combinations of methods improves performance on\ntasks ranging from semantics to morphology. The inductive parts varied, from facts, such\nas ‘gold syntax,’ to tables and rules. The coinductive parts also varied. Clearly, much of\nthe work described here is driven by experiments. And it seems that with enough eﬀort and\ndata almost any combination of architecture boxes can made to perform. What is missing,\nhowever, is our understanding: under what constraints, a combination of inductive and\ncoinductive methods will achieve an optimum performance?\nIn other words, is there a principled way of building hybrid, inductive/coinductive\nor neuro-symbolic architectures? Or, do such combinations of methods simply address\ndeﬁciencies of speciﬁc neural networks, and with better NN systems, we can remove the\ninductive parts? Again we have some anecdotal evidence that not everything should be\ndone by coinduction, i.e. existing NN architectures show serious deﬁciencies for some\ntasks.\nThe question that arises seems to be: are these examples suggesting something deeper?\nIn other words, is there a math underlying the practice? — We know a few important\nmathematical facts about deep learning, starting with the classical result that neural\nnetworks can approximate any function. More recently, the superiority of deep neural\nnetworks over networks with only one hidden layer has been established (e.g. Telgarsky\n[2016]), and complementing it are results about the limitations of feed forward networks\n(e.g. Mehrabi et al. [2018]). These three facts suggest to us a technical problem: is there\na formula balancing the inductive and coinductive contributions to understanding?\nPerhaps this is the main question raised by the material discussed so far. We would\nlike to know a formula quantifying the dependence of the accuracy of the neural network\nbased on three factors: 1. the number of available hard coded facts/values; 2. amounts\nof available training data; and 3. diﬃculty of the problem.\nNote that there are experimental results in this spirit.\nFor example, Sun et al.\n[2017] observe that performance improves logarithmically based on volume of training\n23\ndata, which for some problems might be prohibitive. There is also interest in combin-\ning logic/rules with neural networks (see e.g. Fischer et al. [2019] and the next section).\nRecently, there appeared an analysis for a “class of hierarchically local compositional func-\ntions” [Poggio et al., 2020], where it is hypothesized “local hierarchical compositionality\nis imposed by the wiring of our sensory cortex and, critically, is reﬂected in language.”\nHowever, there are also interesting questions possibly amenable to yes/no answers.\nFor example, (1) Can a network with certain restriction on the learning function and\nparameters (depth, activation etc.) learn ten thousand natural language constructions\nof, say, depth-ﬁve from some ﬁxed amount of data? – This could perhaps be assessed\nusing an artiﬁcial language approach in the spirit of Baroni et al. [2012] and Feinman\nand Lake [2020]. An answer would perhaps shed some light on how diﬃcult it is to create\ncompositional semantics, given we have about ten thousand frequently used English verbs,\neach potentially having arguments and adjuncts. (2) Same question, for long “iterative”\nsentences with many sub-clauses, such as appearing in patents and legal documents, as\ndiscussed in Section 1.1.2.\nSystems improve by learning from interaction, and we have provided argument for\nprocess-based, that is coinductive, approach to NL and multimodal dialogue. Having one\nformal view of diﬀerent components of a NL understanding process should be helpful\nwith integrating them. To us, it seems the best candidate for such formalism is coinduc-\ntion/coalgebra.\n5\nNot everything should be done via coinduction\nGiven the success of deep learning models, the obvious question is whether “everything\nshould be done via coinduction”, that is, using deep learning to ﬁnd patterns in text,\nand create annotations representing the meaning of text. On the one hand, our common\nsense and intuitions contradict the idea of always doing pattern recognition from scratch,\ni.e.\nraw data.\nAfter all, there are databases of facts, many of them, e.g.\nﬁnancial\nand legal events, have been checked for accuracy. There are terabytes of texts containing\nuseful information, including vocabulary deﬁnitions, and, ﬁnally, there are formal theories,\ncreated at great cost and eﬀort, in mathematics, physics, biology etc.\nMoreover, even though in theory, neural networks can approximate any function with\narbitrary accuracy, in practice they show limitations. We will go over some of them using\na few examples. So, this section can be viewed as complementing the previous one by\nadding ‘negative’ examples.\n5.1\nCompositionality is a challenge for neural networks\nAs shown in Zadrozny [1994], in theory, any semantics can be encoded in a compositional\nfashion, and the encoding method is explicitly coinductive (via bisimulation). However,\nin practice, compositionality is a challenge for neural networks. Moreover, the lack of\ncompositionality is an impediment to progress in NLP and cognitive modeling.\nOur ﬁrst set of observations come from M.Baroni’s 2018 CLASP seminar.16 and the\n16https://gu-clasp.github.io/static/fe1b398a82e63dd71c99e0668d706b79/1704969_\n24\nfollow up article [Baroni, 2020] His carefully designed experiment, using a simpliﬁed model\nof language understanding and trying to model language acquisition and compositionality,\nconcludes with the following observations:\n• (Recurrent) neural networks are remarkably powerful and general (as agnostic “end-\nto-end” learners from input-output pairs).\n• They can generalize to new inputs that are diﬀerent from those they were trained\non...\n• ... but their generalization skills do not display systematic compositionality.\n• Thus, they cannot adapt fast to continuous stream of new inputs in domains such\nas language, math and, more generally, reasoning.\nWe can ask why this is the case that RNNs “generalization skills do not display systematic\ncompositionality”? — An answer perhaps is that it is not their function. Most modern\nNN architectures incorporate sophisticated ways of computing correlations. In contrast,\ncompositionality requires an association of a discrete construction with a speciﬁc meaning\ntype, e.g. Goldberg [2006] and Cooper et al. [2015], and often access to background knowl-\nedge. In the process of understanding, the catalog of constructions is used to decompose\na sentence into meaningful pieces (and the world knowledge helps with disambiguation).\nIn principle such a catalog of constructions can be learned from data. But the practice\nis more complicated. Even in branches of mathematics, where the compositionality is\ntrivially obvious to a human, neural networks have trouble learning it from data.\nEven on relatively simple, strictly compositional data sets, compositionality seems to\nelude standard NN architectures. After performing a detailed analysis of latent compo-\nsitionality, from several natural points of view, Hupkes et al. [2020] say “high scores do\nstill not necessarily imply that the trained models fully represent the true underlying\ngenerative system.”\n5.2\nDiﬃculties in learning algebra, arithmetic and formal reasoning\nAlgebra and arithmetic: Even with special neural architectures, the performance on\nmathematical tasks is limited, and for general purpose NN (even out of the box trans-\nformers) it can be really disappointing [Saxton et al., 2019, Hupkes et al., 2020]. Madsen\nand Johansen [2020] attribute it to the “lack of inductive bias” in NN:\n“Neural networks can approximate complex functions, but they struggle to perform\nexact arithmetic operations over real numbers. The lack of inductive bias for arithmetic\noperations leaves neural networks without the underlying logic necessary to extrapolate\non tasks such as addition, subtraction, and multiplication.”\nThe authors then proceed to create a special purpose architecture which provides bet-\nter approximation of the three operations, but leave division as an open problem.\nmarco-clasp-oct2018-composition.pdf\n25\nFormal reasoning: Reimann and Schwung [2019] create a special purpose architecture,\n“Neural Logic Rule Layers,” to represent arbitrary logic rules in terms of their conjunctive\nand disjunctive normal forms. Their experiment shown relatively high accuracy (up to\n98% on a limited data set). The authors claim their approach might help create more\nexplainable neural networks, as well as implement variants of fuzzy logic. Slightly earlier,\nGranmo [2018] proposed Tsetlin Machines for a similar task.\nWhile these are interesting experiments, the question we want to ask is whether, from a\npractical point of view, hybrid systems, along the lines discussed in Section 4.2, combining\ngeneral purpose neural architectures with an inductive component, are better suited for\nbuilding applications.\n5.3\nLimitations of coinductive view of human cognition\nLake et al. [2015] discussed the challenge of generalizing from a small number of exam-\nples, and introduced the Omniglot dataset for one-shot learning. Their progress report\n[Lake et al., 2019] concludes that “recent approaches are still far from human-like con-\ncept learning on Omniglot, a challenge that requires performing many tasks with a single\nmodel.”\nIn a related article, Lake et al. [2017] observe that deep neural networks have diﬃculties\nwith tasks requiring common sense, causality and depth. The article gives an example of\nthe diﬃculty neural networks have in generalizing in playing computer games by discussing\nmodiﬁed objectives, such as these:\n• Get the lowest possible score;\n• Get closest to 100, or any level, without going over;\n• Beat your friend, but just barely, not by too much;\n• Go as long as you can without dying;\n• Die as quickly as you can; and\n• Pass each level at the last possible minute.\nThe limitations of deep neural networks in modeling formal systems and human cogni-\ntion suggest that further progress requires better accounts of grounding, compositionality\nand causality. To us, as the reader might already expect, it suggests the need for an inter-\nplay between the formal reasoning (inductive) and the data driven (coinductive) systems\nof reasoning.\n6\nDiscussion and summary\nThis article tries to reconcile two clashing paradigms by observing that a combination of\ninductive and coinductive methods produces superior results in many NLP tasks. It casts\nthe observed empirical results within a common mathematical framework, a framework\n26\nthat has not been used so far in NL understanding, even though it has proven useful in\nother branches of computer science. This obviously leads to many questions of practical\nand theoretical importance. For example, we can ask how chunking and other cognitive\nphenomena ﬁt into this formalized picture. And what about reasoning, generalization and\nabduction? However, in our view, the two key and most obvious concerns are:\n1. Practical importance:\nThe main question is whether having a common con-\nceptual framework of coinduction + induction leads to better practical results, or\nbetter theoretical models of language understanding?\n— We hope so, and this is a reason for writing this article. Perhaps an intuition can\ncome from another, very diﬀerent context. In the works on the traveling salesman\nand related NP-complete problems, it has been observed [Monasson et al., 1999]\n“many NP-complete problems occurring in practice contain a mix of tractable and\nintractable constraints.” This parallels the examples cited in this article that have\nsuccessfully combined inductive and coinductive methods.\n2. Theoretical justiﬁcation: We have argued from empirical evidence that a com-\nbination of inductive and coinductive methods often produces superior results. Is\nthere theoretical justiﬁcation supporting these observations? For example, we have\na theory proving that deeper neural networks produce better accuracy per number\nof neurons (Section 4.3), if vanishing gradients can be controlled. In the more math-\nematical domain, it has been shown that NP-complete problems mentioned above,\nsuch as the traveling salesman problem’ and the boolean satisﬁability (SAT) exhibit\nphase transitions (cf. Cheeseman et al. [1991], Gent and Walsh [1994], Monasson\net al. [1999]). Therefore, we ask whether there are “phase transition” regions be-\ntween applicability of inductive and coinductive methods.\nInterestingly enough, compositionality might be the key to progress in both issues.\nTraditionally, compositional semantics has taken its inspiration from mathematics, and\nhas been speciﬁed by inductive deﬁnitions. This tradition is very strong in logic, linguistics\nand even computational linguistics. However, we see the emergence of compositionality in\nneural networks as a very active area of research. As of October 2020, per Google Scholar,\nwe note about half of all the articles on deep learning and compositionality appeared in\n2019 or later. We are seeing this increased interest because compositional systems are\nmore interpretable, and can incorporate domain knowledge and known causal relation-\nships. But since the world, knowledge and data are always changing, machine learning\nhas to be part of the picture. We discussed in Section 5 some of the limitations of the\npurely data driven attempts to derive compositionality from data, and earlier in Section\n4 empirical advantages of combining the two.\nSummary:\nCoinduction is a mathematical and computational tool for specifying con-\nstraints on program behavior and data.\nIt is a natural complement to standard (i.e.\nbottom up) ways of deﬁning compositional semantics or syntactic correctness. It provides\na principled (formal) view of the current practice in human-computer interaction, pars-\ning, machine translation and others. It covers possible worlds semantics, and, in theory,\n27\ncan encode any semantics. However, coinductive methods have practical limitations, as\npartial observations do not resolve all questions about interpretations, even though such\nmethods are less brittle for longer texts.\nIn this article, we argued that a combination of inductive (e.g. traditional semantics)\nand coinductive (e.g.\ndeep learning) methods is showing practical promise, and both\napproaches belong to the same computational paradigm. Perhaps now is the time for an\nexplicit introduction of the term ‘coinduction’ to the vocabulary of NLP.\nAcknowledgments: The impetus for writing up these ideas about the potential of coin-\nduction as a theoretical framework for natural language understanding came from a dis-\ncussion with CLASP researchers during IWCS 2019 (although coinduction guided some of\nmy work work on dialogue systems in the second half of 1990s). This article organizes and\nexpands on the main themes of the CLASP seminar talk given in May of 2020. In partic-\nular, I beneﬁted from personal communications and comments of S. Lappin, L. Moss, N.\nRuozzi, N. Correa, R. Cooper, M. Steedman, and others. Thanks are due to O. Rambow\nfor permission to reproduce Fig. 3; to the authors of Abzianidze et al. [2020] for Fig. 2;\nto the authors of He et al. [2017] for Fig.5; and to the authors of Tseo et al. [2020] for\nFig. 8. Obviously, all the faults of this article are mine.\nReferences\nL. Abzianidze, R. van Noord, H. Haagsma, and J. Bos. The ﬁrst shared task on discourse repre-\nsentation structure parsing. arXiv preprint arXiv:2005.13399, 2020.\nM. A. Auslander, D. C. Larkin, and A. L. Scherr. The evolution of the mvs operating system.\nIBM Journal of Research and Development, 25(5):471–482, 1981.\nM. Baroni. Linguistic generalization and compositionality in modern artiﬁcial neural networks.\nPhilosophical Transactions of the Royal Society B, 375(1791):20190307, 2020.\nM. Baroni, R. Bernardi, N.-Q. Do, and C.-c. Shan. Entailment above the word level in distribu-\ntional semantics. In Proceedings of the 13th Conference of the European Chapter of the Asso-\nciation for Computational Linguistics, pages 23–32. Association for Computational Linguistics,\n2012.\nJ. Barwise and L. Moss. Vicious circles: on the mathematics of non-wellfounded phenomena.\nCenter for the Study of Language and Information, 1996.\nS. Bird, E. Klein, and E. Loper. Natural Language Processing with Python. O’Reilly Media, Inc.,\n1st edition, 2009. ISBN 0596516495, 9780596516499.\nG. Borb´ely and A. Kornai. Sentence length. arXiv preprint arXiv:1905.09139, 2019.\nP. Boullier and B. Sagot. Eﬃcient and robust lfg parsing: Sxlfg. In Proceedings of the Ninth\nInternational Workshop on Parsing Technology, pages 1–10. Association for Computational\nLinguistics, 2005.\nP. Budzianowski and I. Vuli´c. Hello, it’s gpt-2–how can i help you? towards the use of pretrained\nlanguage models for task-oriented dialogue systems. arXiv preprint arXiv:1907.05774, 2019.\n28\nG. Carlsson and R. B. Gabrielsson. Topological approaches to deep learning. In Topological Data\nAnalysis, pages 119–146. Springer, 2020.\nP. C. Cheeseman, B. Kanefsky, and W. M. Taylor. Where the really hard problems are. In IJCAI,\nvolume 91, pages 331–337, 1991.\nJ. D. Choi, J. Tetreault, and A. Stent.\nIt depends: Dependency parser comparison using a\nweb-based evaluation tool. In Proceedings of the 53rd Annual Meeting of the Association for\nComputational Linguistics and the 7th International Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers), pages 387–396, 2015.\nM. H. Christiansen and N. Chater. The now-or-never bottleneck: A fundamental constraint on\nlanguage. Behavioral and brain sciences, 39, 2016.\nR. Cooper. Records and record types in semantic theory. Journal of Logic and Computation, 15\n(2):99–112, 2005.\nR. Cooper. Type theory and semantics in ﬂux. Handbook of the Philosophy of Science, 14(2012):\n271–323, 2012.\nR. Cooper, S. Dobnik, S. Lappin, and S. Larsson. Probabilistic type theory and natural language\nsemantics. In Linguistic Issues in Language Technology, Volume 10, 2015, 2015.\nM. Dalrymple, J. Lamping, and V. Saraswat. Lfg semantics via constraints. In Sixth Conference\nof the European Chapter of the Association for Computational Linguistics, 1993.\nJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional\ntransformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\nS. Dobnik, R. Cooper, and S. Larsson. Modelling language, action, and perception in type theory\nwith records. In International Workshop on Constraint Solving and Language Processing, pages\n70–91. Springer, 2012.\nC. Elliott.\nGeneralized convolution and eﬃcient language recognition.\narXiv preprint\narXiv:1903.10677, 2019.\nR. Feinman and B. M. Lake. Learning task-general representations with generative neuro-symbolic\nmodeling. arXiv preprint arXiv:2006.14448, 2020.\nM. Fischer, M. Balunovic, D. Drachsler-Cohen, T. Gehr, C. Zhang, and M. Vechev. Dl2: Training\nand querying neural networks with logic. In International Conference on Machine Learning,\npages 1931–1941, 2019.\nA. Frank and U. Reyle. Principle based semantics for hpsg. In Seventh Conference of the European\nChapter of the Association for Computational Linguistics, 1995.\nM. Franke and G. J¨ager.\nProbabilistic pragmatics, or why bayes’ rule is probably important\nfor pragmatics.\nZeitschrift f¨ur Sprachwissenschaft, 35(1):3 – 44, 2016.\nURL https://www.\ndegruyter.com/view/journals/zfsw/35/1/article-p3.xml.\nI. P. Gent and T. Walsh. The sat phase transition. In ECAI, volume 94, pages 105–109. PITMAN,\n1994.\nA. E. Goldberg. Constructions: A construction grammar approach to argument structure. Uni-\nversity of Chicago Press, 1995.\n29\nA. E. Goldberg. Constructions at work: The nature of generalization in language. Oxford Univer-\nsity Press on Demand, 2006.\nI. Goodfellow, Y. Bengio, and A. Courville.\nDeep Learning.\nMIT Press, 2016.\nhttp://www.\ndeeplearningbook.org.\nM. Gordon. Corecursion and coinduction: what they are and how they relate to recursion and\ninduction. 2017.\nM. Gotham and D. T. T. Haug. Glue semantics for universal dependencies. 2019.\nO.-C. Granmo. The tsetlin machine-a game theoretic bandit driven approach to optimal pattern\nrecognition with propositional logic. arXiv preprint arXiv:1804.01508, 2018.\nE. Gregoromichelaki, R. Kempson, and C. Howes. Actionism in syntax and semantics. CLASP\nPapers in Computational Linguistics, page 12, 2020.\nH. M. Hapke, H. Lane, and C. Howard. Natural language processing in action. Manning, 2019.\nL. He, K. Lee, M. Lewis, and L. Zettlemoyer. Deep semantic role labeling: What works and\nwhat’s next. In Proceedings of the 55th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 473–483, 2017.\nD. A. Hudson and C. D. Manning.\nGqa: A new dataset for real-world visual reasoning and\ncompositional question answering. arXiv preprint arXiv:1902.09506, 2019.\nD. Hupkes, V. Dankers, M. Mul, and E. Bruni. Compositionality decomposed: How do neural\nnetworks generalise? Journal of Artiﬁcial Intelligence Research, 67:757–795, 2020.\nB. Jacobs. Introduction to Coalgebra. Slides at EWSCS 2011: 16th Estonian Winter School in\nComputer Science 28 feb.-4 march, Estonia, 2011.\nB. Jacobs. Introduction to Coalgebra, volume 59. Cambridge University Press, 2017.\nA. Joshi and O. Rambow. A formalism for dependency grammar based on tree adjoining grammar.\nIn Proceedings of the Conference on Meaning-text Theory, pages 207–216, 2003.\nR. Kempson, W. Meyer-Viol, and D. M. Gabbay. Dynamic syntax: The ﬂow of language under-\nstanding. Wiley-Blackwell, 2000.\nS.-D. Kim. Comma analysis and processing for improving translation quality of long sentences in\nrule-based english-korean machine translation. In ICAART (2), pages 474–479, 2019.\nJ. L. Klavans and P. Resnik. The balancing act: combining symbolic and statistical approaches to\nlanguage, volume 32. MIT press, 1996.\nA. Kurz. Coalgebras and modal logic. ESSLI tutorial, pages 1–100, 2001.\nB. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum.\nHuman-level concept learning through\nprobabilistic program induction. Science, 350(6266):1332–1338, 2015.\nB. M. Lake, T. D. Ullman, J. B. Tenenbaum, and S. J. Gershman. Building machines that learn\nand think like people. Behavioral and brain sciences, 40, 2017.\nB. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum. The omniglot challenge: a 3-year progress\nreport. Current Opinion in Behavioral Sciences, 29:97–104, 2019.\n30\nS. Larsson. Formal semantics for perceptual classiﬁcation. Journal of logic and computation, 25\n(2):335–369, 2015.\nI. Lawler, F. Hahn, and H. Rieser. Gesture meaning needs speech meaning to denote-a case of\nspeech-gesture meaning interaction. In FADLI@ ESSLLI, pages 42–46, 2017.\nH. Li and Y. Zhu. Classifying commas for patent machine translation. In China Workshop on\nMachine Translation, pages 91–101. Springer, 2016.\nA. Madsen and A. R. Johansen. Neural arithmetic units. arXiv preprint arXiv:2001.05016, 2020.\nC. D. Manning. Computational linguistics and deep learning. Computational Linguistics, 41(4):\n701–707, 2015.\nM. C. McCord, J. W. Murdock, and B. K. Boguraev. Deep parsing in Watson. IBM Journal of\nResearch and Development, 56(3.4):3–1, 2012.\nR. McDonald and J. Nivre. Characterizing the errors of data-driven dependency parsers. 2007.\nM. Mehrabi, A. Tchamkerten, and M. I. Youseﬁ. Bounds on the approximation power of feedfor-\nward neural networks. arXiv preprint arXiv:1806.11416, 2018.\nR. Monasson, R. Zecchina, S. Kirkpatrick, B. Selman, and L. Troyansky. Determining computa-\ntional complexity from characteristic ‘phase transitions’. Nature, 400(6740):133–137, 1999.\nJ. Nivre.\nMultilingual dependency parsing from universal dependencies to sesame street.\nIn\nP. Sojka, I. Kopeˇcek, K. Pala, and A. Hor´ak, editors, Text, Speech, and Dialogue, pages 11–29,\nCham, 2020. Springer International Publishing. ISBN 978-3-030-58323-1.\nH. Peng, S. Thomson, and N. A. Smith. Deep multitask learning for semantic dependency parsing.\narXiv preprint arXiv:1704.06855, 2017.\nT. Poggio, A. Banburski, and Q. Liao. Theoretical issues in deep networks. Proceedings of the\nNational Academy of Sciences, 2020.\nP. Qi, Y. Zhang, Y. Zhang, J. Bolton, and C. D. Manning. Stanza: A python natural language\nprocessing toolkit for many human languages. arXiv preprint arXiv:2003.07082, 2020.\nK. Rajshekhar, W. Shalaby, and W. Zadrozny. Analytics in post-grant patent review: Possibilities\nand challenges (preliminary report). In Proceedings of the American Society for Engineering\nManagement 2016 International Annual Conference S. Long, EH. Ng, C. Downing, & B. Nepal\neds, 2016.\nJ. N. Reimann and A. Schwung. Neural logic rule layers. arXiv preprint arXiv:1907.00878, 2019.\nP. R. Ribeiro, M. A. Barbosa, and L. S. Barbosa.\nGeneric process algebra: A programming\nchallenge. J. UCS, 12(7):922–937, 2006.\nK. Richardson, H. Hu, L. S. Moss, and A. Sabharwal. Probing natural language inference models\nthrough semantic fragments.\nIn Proc. AAAI 2020; see also: arXiv:1909.07521, 2020.\ndoi:\n\\url{https://doi.org/10.1609/aaai.v34i05.6397}.\nH. Rieser. A process algebra account of speech-gesture interaction. revised and updated version.\nFADLI 2017, page 67, 2017.\n31\nJ. J. Rutten. Universal coalgebra: a theory of systems. Theoretical computer science, 249(1):3–80,\n2000.\nD. Saxton, E. Grefenstette, F. Hill, and P. Kohli. Analysing mathematical reasoning abilities of\nneural models. arXiv preprint arXiv:1904.01557, 2019.\nG. Scontras, M. H. Tessler, and M. Franke. Probabilistic language understanding: An introduction\nto the rational speech act framework, 2017.\nA. Shmidman, S. Shmidman, M. Koppel, and Y. Goldberg. Nakdan: Professional hebrew dia-\ncritizer. arXiv preprint arXiv:2005.03312, 2020.\nJ. ˇS´ıma. Analog neuron hierarchy. Neural Networks, 2020.\nD. Sprunger and B. Jacobs.\nThe diﬀerential calculus of causal functions.\narXiv preprint\narXiv:1904.10611, 2019.\nC. Sun, A. Shrivastava, S. Singh, and A. Gupta. Revisiting unreasonable eﬀectiveness of data\nin deep learning era. In Proceedings of the IEEE international conference on computer vision,\npages 843–852, 2017.\nM. Telgarsky. Beneﬁts of depth in neural networks. Journal of Machine Learning Research, 49\n(June):1517–1539, 2016.\nY. Tseo, M. Salkola, A. Mohamed, A. Kumar, and F. Abnousi. Information extraction of clinical\ntrial eligibility criteria. arXiv preprint arXiv:2006.07296, 2020.\nA. Warstadt, A. Singh, and S. R. Bowman. Neural network acceptability judgments. arXiv preprint\narXiv:1805.12471, 2018.\nP. Wegner and D. Goldin. Coinductive models of ﬁnite computing agents. Electronic Notes in\nTheoretical Computer Science, 19:81–101, 1999.\nG. U. Yule. On sentence-length as a statistical characteristic of style in prose: With application\nto two cases of disputed authorship. Biometrika, 30(3/4):363–390, 1939.\nW. Zadrozny. From compositional to systematic semantics. Linguistics and philosophy, 17(4):\n329–342, 1994.\nW. Zadrozny and A. Manaster-Ramer. The signiﬁcance of constructions. IBM TJ Watson Research\nCenter, Technical Report, 1995.\nW. Zadrozny, M. Szummer, S. Jarecki, D. E. Johnson, and L. Morgenstern. Nl understanding\nwith a grammar of constructions.\nIn Proceedings of the 15th conference on Computational\nlinguistics-Volume 2, pages 1289–1293, 1994.\nW. Zadrozny, C. Wolf, N. Kambhatla, and Y. Ye. Conversation machines for transaction process-\ning. Proceedings IAAI-98, 1998.\nW. Zadrozny, M. Budzikowska, J. Chai, N. Kambhatla, S. Levesque, and N. Nicolov. Natural\nlanguage dialogue for personalized interaction. Communications of the ACM, 43(8):116–120,\n2000.\nA. Zhang, Z. C. Lipton, M. Li, and A. J. Smola. Dive into Deep Learning, volume 3. 2020.\nY. Zhang, D. Merck, E. B. Tsai, C. D. Manning, and C. P. Langlotz. Optimizing the factual correct-\nness of a summary: A study of summarizing radiology reports. arXiv preprint arXiv:1911.02541,\n2019.\n32\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG",
    "I.2.7"
  ],
  "published": "2020-12-09",
  "updated": "2020-12-09"
}