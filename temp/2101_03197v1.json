{
  "id": "http://arxiv.org/abs/2101.03197v1",
  "title": "Deep Diffusion Processes for Active Learning of Hyperspectral Images",
  "authors": [
    "Abiy Tasissa",
    "Duc Nguyen",
    "James Murphy"
  ],
  "abstract": "A method for active learning of hyperspectral images (HSI) is proposed, which\ncombines deep learning with diffusion processes on graphs. A deep variational\nautoencoder extracts smoothed, denoised features from a high-dimensional HSI,\nwhich are then used to make labeling queries based on graph diffusion\nprocesses. The proposed method combines the robust representations of deep\nlearning with the mathematical tractability of diffusion geometry, and leads to\nstrong performance on real HSI.",
  "text": "Deep Diﬀusion Processes for Active Learning of Hyperspectral Images\nAbiy Tasissa1, Duc Nguyen2, and James Murphy∗1\n1Department of Mathematics, Tufts University, Medford, MA\n2Department of Mathematics, University of Maryland, College Park, USA\nAbstract\nA method for active learning of hyperspectral images (HSI) is proposed, which combines deep learn-\ning with diﬀusion processes on graphs.\nA deep variational autoencoder extracts smoothed, denoised\nfeatures from a high-dimensional HSI, which are then used to make labeling queries based on graph\ndiﬀusion processes. The proposed method combines the robust representations of deep learning with the\nmathematical tractability of diﬀusion geometry, and leads to strong performance on real HSI.\n1\nIntroduction\nMachine learning has provided revolutionary new tools for remote sensing, but state-of-the-art methods often\nrequire huge labeled training sets. In particular, supervised deep learning methods can achieve near-perfect\nlabeling accuracy on high-dimensional hyperspectral images (HSI), provided large libraries of labeled pixels\nare available [1]. This hinders the practicality of these methods, as in many settings, data is collected at a\npace that far exceeds human ability to generate corresponding labeled training data.\nIn order to account for this, methods that require only a very small number of labels are needed. The\nactive learning regime is particularly attractive for HSI labeling problems. In active learning, an algorithm\nis provided with an unlabeled dataset, and the algorithm iteratively queries points for labels. By choosing\nquery points intelligently, the active learning algorithm can yield the classiﬁcation performance of a much\nlarger training set chosen uniformly at random.\nWe propose an active learning method for HSI based on deep feature extraction and random walks on\ngraphs. First, an unsupervised variational autoencoder is used to nonlinearly denoise and compress the high-\ndimensional HSI. Then, the resulting features are considered as vertices of a graph, and a Markov diﬀusion\nprocess on the graph is used to determine label queries and label all data points. The proposed method\ncombines the eﬃcient feature learning of deep autoencoders with the mathematical interpretability of graph\ndiﬀusion processes, and leads to strong empirical performance on real HSI.\n2\nBackground\n2.1\nVariational Autoencoders\nIn an autoencoder architecture, input data is cascaded through nonlinear layers to obtain a latent represen-\ntation. The latent representation is then cascaded through nonlinear layers to obtain output data. These two\nstages respectively deﬁne the encoder and decoder. Typically, a loss function that enforces the reconstructed\noutput to be similar to the input is minimized and the trained autoencoder learns a low-dimensional latent\nfeature useful for downstream tasks. In contrast to the autoencoder, in the variational autoencoder (VAE)\n[2], the output of the encoder is not a deterministic map but parameters of a distribution. In particular,\nan encoding network maps x ∈RN and obtains parameters of the latent variable distribution q(z|x). A\nlatent feature z sampled from this distribution is an input to a decoder that outputs ˆx ∼p(x|z). A typical\nprior for the distribution of the latent variable is a Gaussian random variable p(z) ∼N(0, I). Given this,\nthe VAE optimization consists of two terms: (i) a reconstruction loss L1 = Ez∼q(z|x) log(p(x|z)) that en-\nforces that the reconstructed output ˆx is similar to the input x; and (ii) a Kullback-Leibler divergence loss\nL2 = KL(q(z|x), N(0, I)) that enforces that q(z|x) agrees with p(z). The encoder and decoder are jointly\ntrained by maximizing the total loss L1 + L2.\n2.2\nLearning by Active Nonlinear Diﬀusion\nThe active learning algorithm employed in this paper is based on the ideas in [3, 4, 5]. In [6], the authors\npropose a semisupervised algorithm, learning by active nonlinear diﬀusion (LAND), that obtains the most\nimportant data points to query for labels. Important features of LAND are (i) it is a principled algorithm\nwith provable performance guarantees; (ii) it accounts for nonlinear clusters possibly in high dimensions;\nand (iii) it is robust to noise and outliers [6].\nWe represent an HSI as X = {xi}n\ni=1 ⊂RN where each pixel is a point in RN where N is the number of\nspectral bands. Let NNk(xi) denote the set of k-nearest neighbors of xi in X using the Euclidean distance\nmetric. The n×n weight matrix W is deﬁned as Wij = exp(−∥xi −xj∥2\n2/σ2), xj ∈NNk(xi) with σ denoting\n∗This research is partially supported by the US National Science Foundation grants NSF-DMS 1912737, NSF-DMS 1924513,\nand NSF-CCF 1934553.\n1\narXiv:2101.03197v1  [cs.CV]  8 Jan 2021\na scale parameter. With this, the notion of the degree of xi naturally follows as deg(xi) := P\nxj∈X Wij. To\ndeﬁne a random walk on X, we employ the n×n transition matrix Pij = Wij\n\u000e\ndeg(xi). It can be easily veriﬁed\nthat P has a spectral decomposition {(λℓ, Ψℓ)}n\nℓ=1. The diﬀusion distance at time t between xi, xj ∈X is\ndeﬁned as Dt(xi, xj) =\npPn\nℓ=1 λ2t\nℓ(Ψℓ(xi) −Ψℓ(xj))2. We note that t tells us how long the diﬀusion process\nruns. In this paper, we use t = 30 for experiments.\nThe main part of the LAND algorithm is to identify points to query for labels. LAND uses a kernel\ndensity estimator (KDE) and diﬀusion geometry for this task. In particular, the KDE is deﬁned as p(x) =\nP\ny∈NNk(x) exp(−∥x −y∥2\n2/σ2\n0) with σ0 denoting a scale parameter. For x ∈X, let\nρt(x) =\n\n\n\nmin\np(y)≥p(x),x̸=y Dt(x, y),\nx ̸= argmax\nz\np(z),\nmax\ny∈X Dt(x, y),\nx = argmax\nz\np(z),\n(1)\nbe the diﬀusion distance to the nearest neighbor of higher density. The maximizers of Dt(x) = p(x)ρt(x)\nare queried for labels. These labels are propagated to other data points by proceeding from high to low\ndensity and assigning each unlabeled point the same label as its Dt-nearest neighbor of higher density that\nis labeled; see Algorithm 1 and [6] for details.\n2.3\nRelated Work\nIn recent years, deep generative methods, such as generative adversarial network (GANs) and variational\nautoencoder networks (VAEs), have been used for feature extraction in many machine learning tasks [7, 8].\nIn the context of clustering, a set of methods, known as deep clustering, propose learning features of the data\nand clustering simultaneously, showing strong empirical results [9, 10, 11]. For HSI images, several works\nhave employed diﬀerent deep learning architectures to extract essential features for downstream tasks such\nas classiﬁcation [12, 13, 14, 15, 16].\nActive learning is a learning paradigm where the user has the ability to select the training data [17, 18].\nThe underlying idea is that a few informative training samples could be suﬃcient for training an algorithm\nand obtaining accurate results. This framework has been used in remote sensing for HSI image classiﬁcation\n[19, 20, 21, 22]. The main idea in this paper is that the active learning process depends on the representation\nand geometry of the data. The closest work to ours is [23] where the authors combine active learning with\nVAEs. Therein, K-means clustering is ﬁrst used to partition the space and then labels are acquired using\nuniform random sampling in each partition. Given the labels, a classiﬁer is then trained in the latent space\nfor the prediction task. One of the highlights of the proposed method is that the clustering algorithm LAND\nhandles a broader class of cluster geometries than K-means does.\nWe note that in contrast to the similar work [24], our method is in the active learning framework and\nthe feature extraction and diﬀusion process via LAND are decoupled.\n3\nProposed Algorithm\nWe propose an active learning algorithm, VAE-LAND (see Algorithm 1), which has two main stages. The\nﬁrst stage is feature extraction of an unlabeled high-dimensional dataset using a VAE. The second stage\nemploys the LAND algorithm to infer the true labels. The proposed algorithm combines the power of VAEs\nto extract features with diﬀusion geometry on graphs to ﬁnd impactful labels to query, which then propagate\nto other points.\nAlgorithm 1: Variational Autoencoder Learning by Active Nonlinear Diﬀusion (VAE-LAND)\nInput: {xi}n\ni=1 (Unlabeled Data); t (Time Parameter); B (Budget); O (Labeling Oracle)\nOutput: Y (Labels)\n1: Run VAE on unlabeled data to obtain the latent representation {ˆxi}n\ni=1.\n2: Compute P and {(λℓ, ψℓ)}M\nℓ=1 using {ˆxi}n\ni=1.\n3: Compute kernel density estimate {p(ˆxi)}n\ni=1 and {ρt(ˆxi)}n\ni=1 (1);\n4: Compute Dt(ˆxi) = p(ˆxi)ρt(ˆxi).\n5: Sort the data in decreasing Dt value to acquire the ordering {ˆxmi}n\ni=1.\n6: for i = 1 : B do\n7:\nQuery O for the label L(ˆxmi) of ˆxmi.\n8:\nSet Y (ˆxmi) = L(ˆxmi).\n9: end for\n10: Sort X according to p in decreasing order as\n{ˆxℓi}n\ni=1.\n11: for i = 1 : n do\n12:\nif Y (ˆxℓi) = 0 then\n13:\nY (ˆxℓi) = Y (zi), zi = argmin\nz\n{Dt(z, ˆxℓi) | p(z) > p(ˆxℓi) and Y (z) > 0}.\n14:\nend if\n15: end for\n2\n4\nExperimental Results\nWe demonstrate the accuracy of the proposed algorithm experimentally. The training of the VAE is done\nusing Tensorﬂow in Python. For doing the active learning via LAND, we use the publicly available MATLAB\ncode at https://jmurphy.math.tufts.edu/Code/. Our code can be found at https://github.com/abiy-tasissa/\nVAE-LAND. Our test HSI dataset is the Salinas A hyperspectral dataset. The Salinas scene was captured\nover Salinas Valley, California. The image has a spatial resolution of 3.7-meter pixels and contains 224\nspectral bands. The ground truth consists of 16 classes. We consider the Salinas A dataset, which is a subset\nof the Salinas dataset, and contains 6 classes. The Salinas A dataset and the ground truth data are pub-\nlicly available (http://www.ehu.eus/ccwintco/index.php/Hyperspectral Remote Sensing Scenes#Salinas-A\nscene). Figure 1 shows a visual of the high-dimensional data and the ground truth labels. The performance\nof the algorithm is assessed using overall accuracy, deﬁned as the ratio of correctly estimated labels to to-\ntal number of labels after optimally aligning with the ground truth.\nThe Salinas A HSI dataset of size\nFigure 1: The 86 × 83 Salinas A HSI data consists of 6 classes. Left: the sum of all spectral bands. Right: the\nground truth.\nFigure 2: A schematic of the VAE architecture.\nInput is a vector in R224.\nThe encoder and decoder are fully\nconnected neural networks. Both have three layers with 128 neurons in each layer. For all layers, the activation\nfunction is the rectiﬁed linear unit (ReLU). The input is cascaded through an encoder. The extracted latent feature\nin R40 is then cascaded through the decoder to obtain the output vector in R224. Unlike the standard autoencoder,\nthe extraction of the latent feature is not deterministic (see Section 2.1 for discussion.)\n83 × 86 × 224 is represented as a point cloud of size 7138 × 224. We use the unlabeled data to learn a\nlatent space representation of Salinas A in R40 dimensions. A schematic of the VAE architecture is shown\nin Figure 2. We optimize the VAE loss function using the Adam algorithm with learning rate set to 10−4.\nAfter training the VAE, we input the optimal latent space representation of the Salinas A dataset to the\nLAND algorithm for the task of inferring the ground truth labels of the HSI data. We compare our result to\nthe standard LAND algorithm that labels the Salinas A dataset in its original representation. Since LAND\nis an active learning framework, we consider varying number of labeled data points ranging from 10 to 2000.\nIn addition, we compare the active learning methods to query the samples with randomly selected training\ndata. Figure 1 compares the performance of LAND and performance of VAE-LAND. First, for both VAE-\nLAND and standard LAND, LAND queries lead to signiﬁcantly better accuracy than random queries. The\nproposed algorithm, VAE-LAND, attains an accuracy of 96.97% with just 10 labeled points. This is a 12.5%\nimprovement to the accuracy of the standard LAND algorithm for the same number of labeled points. The\nstandard LAND algorithm requires 400 labeled points to reach accuracy of 90% while for the same number\nof labeled points, VAE-LAND has an accuracy of 98.35%.\nComplexity and run time: The complexity of LAND is O(CNN + nKNN + n log(n)) where CNN is the\ncost of computing all KNN nearest neighbours [6]. The computational cost of VAE is diﬃcult to estimate\nas it depends on several factors (e.g architecture, activation function, choice of SGD algorithm). In our\nnumerical experiments, the cost of VAE is the dominating cost.\nSince LAND runs on low-dimensional\nfeatures extracted from VAE, it is eﬃcient.\n5\nConclusions and Future Directions\nThe proposed active learning algorithm, VAE-LAND, improves over the standard LAND and gives accurate\nresults even when the number of queries are limited. The method uses VAE to generate good features, and\nuses the diﬀusion geometry-based LAND algorithm to determine query points. The LAND algorithm then\nuses these queried labels to predict the labels of the unlabeled data samples. In future work, we shall explore\ndata models for which the algorithm has theoretical performance guarantees.\n3\n10\n20\n100\n200\n400\n600\n800\n1000\n1200\n1400\n1600\n1800\n2000\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nFigure 3: For the Salinas A dataset, the performance of VAE-LAND learning achieves a higher accuracy\nthan the standard LAND algorithm. With just 10 points, the overall accuracy of VAE-LAND is 96.97%, a\n12.5% improvement to the competitive LAND algorithm. Both VAE-LAND and LAND obtain signiﬁcantly\nbetter results than using randomly selected training instances.\nReferences\n[1] X.X. Zhu, D. Tuia, L. Mou, G.-S. Xia, L. Zhang, F. Xu, and F. Fraundorfer, “Deep learning in remote\nsensing: A comprehensive review and list of resources,” IEEE Geosci. Remote Sens. Mag., vol. 5, no.\n4, 2017.\n[2] D.P. Kingma and M. Welling, “Auto-encoding variational Bayes,” Stat, vol. 1050, 2014.\n[3] J.M. Murphy and M. Maggioni, “Unsupervised clustering and active learning of hyperspectral images\nwith nonlinear diﬀusion,” IEEE Trans. Geosci. Remote Sens., vol. 57, no. 3, 2019.\n[4] M. Maggioni and J.M. Murphy, “Learning by unsupervised nonlinear diﬀusion,” J. Mach. Learn. Res.,\nvol. 20, no. 160, 2019.\n[5] J.M. Murphy and M. Maggioni, “Spectral-spatial diﬀusion geometry for hyperspectral image clustering,”\nIEEE Geosci. Remote Sens. Lett., vol. 17, no. 7, 2020.\n[6] M. Maggioni and J.M. Murphy, “Learning by active nonlinear diﬀusion,” Foundations of Data Sci.,\nvol. 1, no. 3, 2019.\n[7] M.E. Abbasnejad, A. Dick, and A. van den Hengel, “Inﬁnite variational autoencoder for semi-supervised\nlearning,” in CVPR, 2017.\n[8] A. Makhzani, J. Shlens, N. Jaitly, I. Goodfellow, and B. Frey,\n“Adversarial autoencoders,”\narXiv\npreprint arXiv:1511.05644, 2015.\n[9] F. Tian, B. Gao, Q. Cui, E. Chen, and T.-Y. Liu, “Learning deep representations for graph clustering,”\nin AAAI, 2014.\n[10] C. Song, F. Liu, Y. Huang, L. Wang, and T. Tan, “Auto-encoder based data clustering,” in Iberoamer-\nican Congress Pattern Recognit. Springer, 2013.\n[11] J. Xie, R. Girshick, and A. Farhadi, “Unsupervised deep embedding for clustering analysis,” in ICML,\n2016.\n[12] Y. Chen, Z. Lin, X. Zhao, G. Wang, and Y. Gu, “Deep learning-based classiﬁcation of hyperspectral\ndata,” IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 7, no. 6, 2014.\n[13] Y. Chen, H. Jiang, C. Li, X. Jia, and P. Ghamisi,\n“Deep feature extraction and classiﬁcation of\nhyperspectral images based on convolutional neural networks,” IEEE Trans. Geosci. Remote Sens., vol.\n54, no. 10, 2016.\n[14] Y. Li, H. Zhang, and Q. Shen, “Spectral–spatial classiﬁcation of hyperspectral imagery with 3D convo-\nlutional neural network,” Remote Sens., vol. 9, no. 1, 2017.\n[15] M. He, B. Li, and H. Chen, “Multi-scale 3D deep convolutional neural network for hyperspectral image\nclassiﬁcation,” in ICIP. IEEE, 2017.\n[16] M.E. Paoletti, J..M. Haut, J. Plaza, and A. Plaza, “Deep learning classiﬁers for hyperspectral imaging:\nA review,” ISPRS J. Photogram. Remote Sens., vol. 158, 2019.\n[17] D.A. Cohn, Z. Ghahramani, and M.I. Jordan, “Active learning with statistical models,” in NIPS, 1995.\n[18] D. MacKay, “Information-based objective functions for active data selection,” Neural Comput., vol. 4,\nno. 4, 1992.\n[19] P. Liu, H. Zhang, and K.B. Eom, “Active deep learning for classiﬁcation of hyperspectral images,”\nIEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 10, no. 2, 2016.\n4\n[20] Z. Wang, B. Du, L. Zhang, L. Zhang, and X. Jia, “A novel semisupervised active-learning algorithm\nfor hyperspectral image classiﬁcation,” IEEE Geosci. Remote Sens. Lett., vol. 55, no. 6, 2017.\n[21] J.M. Murphy and M. Maggioni, “Iterative active learning with diﬀusion geometry for hyperspectral\nimages,” in WHISPERS. 2018, IEEE.\n[22] D. Tuia, F. Ratle, F. Paciﬁci, M.F. Kanevski, and W.J. Emery, “Active learning methods for remote\nsensing image classiﬁcation,” IEEE Trans. Geosci. Remote Sens., vol. 47, no. 7, 2009.\n[23] F. Pourkamali-Anaraki and M.B. Wakin,\n“The eﬀectiveness of variational autoencoders for active\nlearning,” arXiv preprint arXiv:1911.07716, 2019.\n[24] H. Li, O. Lindenbaum, X. Cheng, and A. Cloninger, “Variational diﬀusion autoencoders with random\nwalk sampling,” in ECCV. Springer, 2020.\n5\n",
  "categories": [
    "cs.CV",
    "cs.LG",
    "eess.IV"
  ],
  "published": "2021-01-08",
  "updated": "2021-01-08"
}