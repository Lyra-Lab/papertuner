{
  "id": "http://arxiv.org/abs/2101.06749v1",
  "title": "A Layer-Wise Information Reinforcement Approach to Improve Learning in Deep Belief Networks",
  "authors": [
    "Mateus Roder",
    "Leandro A. Passos",
    "Luiz Carlos Felix Ribeiro",
    "Clayton Pereira",
    "João Paulo Papa"
  ],
  "abstract": "With the advent of deep learning, the number of works proposing new methods\nor improving existent ones has grown exponentially in the last years. In this\nscenario, \"very deep\" models were emerging, once they were expected to extract\nmore intrinsic and abstract features while supporting a better performance.\nHowever, such models suffer from the gradient vanishing problem, i.e.,\nbackpropagation values become too close to zero in their shallower layers,\nultimately causing learning to stagnate. Such an issue was overcome in the\ncontext of convolution neural networks by creating \"shortcut connections\"\nbetween layers, in a so-called deep residual learning framework. Nonetheless, a\nvery popular deep learning technique called Deep Belief Network still suffers\nfrom gradient vanishing when dealing with discriminative tasks. Therefore, this\npaper proposes the Residual Deep Belief Network, which considers the\ninformation reinforcement layer-by-layer to improve the feature extraction and\nknowledge retaining, that support better discriminative performance.\nExperiments conducted over three public datasets demonstrate its robustness\nconcerning the task of binary image classification.",
  "text": "A Layer-Wise Information Reinforcement\nApproach to Improve Learning in Deep Belief\nNetworks\nMateus Roder1,2[0000−0002−3112−5290], Leandro A. Passos1,2[0000−0003−3529−3109],\nLuiz Carlos Felix Ribeiro1,2[0000−0003−1265−0273], Clayton\nPereira1,2[0000−0002−0427−4880], and Jo˜ao Paulo Papa1,2[0000−0002−6494−7514]\n1 S˜ao Paulo State University - UNESP, Bauru, Brasil {mateus.roder,\nclayton.pereira, leandro.passos, luiz.felix, joao.papa}@unesp.br\nhttps://www.fc.unesp.br/\n2 Recogna Laboratory - www.recogna.tech\nAbstract. With the advent of deep learning, the number of works propos-\ning new methods or improving existent ones has grown exponentially\nin the last years. In this scenario, “very deep” models were emerging,\nonce they were expected to extract more intrinsic and abstract features\nwhile supporting a better performance. However, such models suﬀer from\nthe gradient vanishing problem, i.e., backpropagation values become too\nclose to zero in their shallower layers, ultimately causing learning to\nstagnate. Such an issue was overcome in the context of convolution neu-\nral networks by creating “shortcut connections” between layers, in a\nso-called deep residual learning framework. Nonetheless, a very popular\ndeep learning technique called Deep Belief Network still suﬀers from gra-\ndient vanishing when dealing with discriminative tasks. Therefore, this\npaper proposes the Residual Deep Belief Network, which considers the\ninformation reinforcement layer-by-layer to improve the feature extrac-\ntion and knowledge retaining, that support better discriminative perfor-\nmance. Experiments conducted over three public datasets demonstrate\nits robustness concerning the task of binary image classiﬁcation.\nKeywords: Deep Belief Networks · Residual Networks · Restricted Boltz-\nmann Machines.\n1\nIntroduction\nMachine learning-based approaches have been massively studied and applied to\ndaily tasks in the last decades, mostly due to the remarkable accomplishments\nachieved by deep learning models. Despite the success attained by these tech-\nniques, they still suﬀer from a well-known drawback regarding the backpropagation-\nbased learning procedure: the vanishing gradient. This kind of problem becomes\nmore prominent on deeper models since the gradient vanishes and is not propa-\ngated adequately to former layers, thus, preventing a proper parameter update.\narXiv:2101.06749v1  [cs.AI]  17 Jan 2021\n2\nM. Roder et al.\nTo tackle such an issue, He et al. [4] proposed the ResNet, a framework where\nthe layers learn residual functions concerning the layer inputs, instead of learning\nunreferenced functions. In short, the idea is mapping a set of stacked layers to\na residual map, which comprises a combination of the set input and output and\nthen mapping it back to the desired underlying mapping.\nThe model achieved fast popularity, being applied in a wide range of applica-\ntions, such as traﬃc surveillance [7], medicine [12, 8], and action recognition [2],\nto cite a few. Moreover, many works proposed diﬀerent approaches using the\nidea of residual functions. Lin et al. [11], for instance, proposed the RetinaNet,\na pyramidal-shaped network that employs residual stages to deal with one-shot\nsmall object detection over unbalanced datasets. Meanwhile, Szegedy et al. [17]\nproposed the Inception-ResNet for object recognition. Later, Santos et al. [16]\nproposed the Cascade Residual Convolutional Neural Network for video segmen-\ntation.\nIn the context of deep neural networks, there exist another class of methods\nthat are composed of Restricted Boltzmann Machines (RBMs) [6], a stochas-\ntic approach represented by a bipartite graph whose training is given by the\nminimization of the energy between a visible and a latent layer. Among these\nmethods, Deep Belief Networks (DBNs) [5] and Deep Boltzmann Machines [15,\n13] achieved a considerable popularity in the last years due the satisfactory re-\nsults over a wide variety of applications [14, 3, 18].\nHowever, as far as we are concerned, no work addressed the concept of re-\ninforcing the feature extraction over those models in a layer-by-layer fashion.\nTherefore, the main contributions of this paper are twofold: (i) to propose the\nResidual Deep Belief Network (Res-DBN), a novel approach that combines each\nlayer input and output to reinforce the information conveyed through it, and (ii)\nto support the literature concerning both DBNs and residual-based models.\nThe remainder of this paper is presented as follows: Section 2 introduces the\nmain concepts regarding RBMs and DBNs, while Section 3 proposes the Residual\nDeep Belief Network. Further, Section 4 describes the methodology and datasets\nemployed in this work. Finally, Sections 5 and 6 provide the experimental results\nand conclusions, respectively.\n2\nTheoretical Background\nThis section introduces a brief theoretical background regarding Restricted Boltz-\nmann Machines and Deep Belief Networks.\n2.1\nRestricted Boltzmann Machines\nRestricted Boltzmann Machine stands for a stochastic physics-inspired computa-\ntional model capable of learning data distribution intrinsic patterns. The process\nis represented as a bipartite graph where the data composes a visible input-like\nlayer v, and a latent n-dimensional vector h, composed of a set of hidden neurons\nA Layer Wise Information Reinforcement in Deep Belief Networks\n3\nwhose the model tries to map such inputs onto. The model’s training procedure\ndwells on the minimization of the system’s energy, given as follows:\nE(v, h) = −\nm\nX\ni=1\nbivi −\nn\nX\nj=1\ncjhj −\nm\nX\ni=1\nn\nX\nj=1\nwijvihj,\n(1)\nwhere m and n stand for the dimensions of the visible and hidden layers, respec-\ntively, while b and c denote their respective bias vectors, further, W corresponds\nto the weight matrix connecting both layers, in which wij stands for the connec-\ntion between visible unit i and the j hidden one. Notice the model is restricted,\nthus implying no connection is allowed among the same layer neurons.\nIdeally, the model was supposed to be solved by computing the joint proba-\nbility of the visible and hidden neurons in an analytic fashion. However, such an\napproach is intractable since it requires the partition function calculation, i.e.,\ncomputing every possible conﬁguration of the system. Therefore, Hinton pro-\nposed the Contrastive Divergence (CD) [6], an alternative method to estimate\nthe conditional probabilities of the visible and hidden neurons using Gibbs sam-\npling over a Monte Carlo Markov Chain (MCMC). Hence, the probabilities of\nboth input and hidden units are computed as follows:\np(hj = 1|v) = σ\n \ncj +\nm\nX\ni=1\nwijvi\n!\n,\n(2)\nand\np(vi = 1|h) = σ\n\nbi +\nn\nX\nj=1\nwijhj\n\n,\n(3)\nwhere σ stands for the logistic-sigmoid function.\n2.2\nDeep Belief Networks\nConceptually, Deep Belief Networks are graph-based generative models com-\nposed of a visible and a set of hidden layers connected by weight matrices, with\nno connection between neurons in the same layer. In practice, the model com-\nprises a set of stacked RBMs whose hidden layers greedily feeds the subsequent\nRBM visible layer. Finally, a softmax layer is attached at the top of the model,\nand the weights are ﬁne-tuned using backpropagation for classiﬁcation purposes.\nFigure 1 depicts the model. Notice that W(l), l ∈[1, L], stands for the weight\nmatrix at layer l, where L denotes the number of hidden layers. Moreover, v\nstands for the visible layer, as well as h(l) represents the lth hidden layer.\n3\nInformation Reinforcement in DBNs\nIn this section, we present the proposed approach concerning the residual rein-\nforcement layer-by-layer in Deep Belief Networks, from now on called Res-DBN.\n4\nM. Roder et al.\nFig. 1. DBN architecture with two hidden layers for classiﬁcation purposes.\nW\n(2)\nW\n(1)\nh\n(2)\nh\n(1)\n...\nv\nSoftmax\nSoftmax\ny^\nSince such a network is a hybrid model between sigmoid belief networks and\nbinary RBMs [5], it is important to highlight some “tricks” to make use of the\ninformation provided layer-by-layer.\nAs aforementioned, DBNs can be viewed as hybrid networks that model\nthe data’s prior distribution in a layer-by-layer fashion to improve the lower\nbound from model distribution. Such a fact motivated us to make use of the\ninformation learned in each stack of RBM for reinforcement since the greedy-\nlayer pre-training uses the activation of latent binary variables as the input of\nthe next visible layer. Generally speaking, such activation is deﬁned by Eq. 2,\nand its pre-activation vector, a(l), as follows:\na(l)\nj\n= c(l)\nj\n+\nm\nX\ni=1\nw(l)\nij x(l−1)\ni\n,\n(4)\nwhere, c(l)\nj\nstands for the bias from hidden layer l, m is the number of units\npresent on the previous layer, w(l)\nij represents the weight matrix for layer l, and\nx(l−1)\ni\nstands for the input data from layer l −1, where x0\ni = vi.\nTherefore, it is possible to use the “reinforcement pre-activation” vector,\ndenoted as ˆa(l), from layer l, ∀l > 1. Since the standard RBM output of post-\nactivation (provided by Eq. 2) is in [0, 1] interval, it is necessary to limit the\nreinforcement term of the proposed approach as follows:\nˆa(l) =\nδ(a(l−1))\nmax{δ(a(l−1)\nj\n)}\n,\n(5)\nwhere, δ stands for the Rectiﬁer3 function, while max returns the maximum\nvalue from the δ output vector for normalization purposes. Then, the new input\ndata and the information aggregation for layer l is deﬁned by adding the values\nobtained from Eq. 5 to the post-activation, i.e., applying σ(a(l−1)), as follows:\nx(l−1)\ni\n= σ(a(l−1)\nj\n) + ˆa(l)\nj ,\n(6)\n3 δ(z) = max(0, z).\nA Layer Wise Information Reinforcement in Deep Belief Networks\n5\nwhere x(l−1)\ni\nstands for the new input data to layer l, ∀l > 1, and its normalized\nand vectorized form can be obtained as follows:\nx(l−1) =\nx(l−1)\nmax{x(l−1)\ni\n}\n.\n(7)\nIt is important to highlight that, in Eq. 5, we only use the positive pre-\nactivations to retrieve and propagate the signal that is meaningful for neurons\nexcitation, i.e., values greater than 0, which generates a probability of more than\n50% after applying sigmoid activation.\nFig. 2. Res-DBN architecture with 3 hidden layers.\nv\n...\n...\n...\nh\n(1)\nh\n(2)\nh\n(3)\nW\n(1)\nW\n(2)\nW\n(3)\n...\ny^\nSoftmax\nSoftmax\na\n(2)\n^\na\n(1)\na\n(3)\n^\na\n(2)\nThe Figure 2 depicts the Res-DBN architecture, with hidden layers connected\nby the weights W(l). The dashed connections stand for the reinforcement ap-\nproach, with the information aggregation occuring as covered by the Eqs. 4 to\n7, from a generic hidden layer to the next one (h(1) →h(2), for instance).\n4\nMethodology\nIn this section, we present details regarding the datasets employed in our exper-\niments, as well as the experimental setup applied for this paper.\n4.1\nDatasets\nThree well-known image datasets were employed throughout the experiments:\n• MNIST4 [10]: set of 28 × 28 binary images of handwritten digits (0-9), i.e.,\n10 classes. The original version contains a training set with 60, 000 images\nfrom digits ‘0’-‘9’, as well as a test set with 10, 000 images.\n4 http://yann.lecun.com/exdb/mnist\n6\nM. Roder et al.\n• Fashion-MNIST5 [20]: set of 28 × 28 binary images of clothing objects. The\noriginal version contains a training set with 60, 000 images from 10 distinct\nobjects (t-shirt, trouser, pullover, dress, coat, sandal, shirt, sneaker, bag, and\nankle boot), and a test set with 10, 000 images.\n• Kuzushiji-MNIST6 [1]: set of 28 × 28 binary images of hiragana characters.\nThe original version contains a training set with 60, 000 images from 10\npreviously selected hiragana characters, and a test set with 10, 000 images.\n4.2\nExperimental Setup\nConcerning the experiments, we employed the concepts mentioned in Section 3,\nconsidering two main phases: (i) the DBN pre-training and (ii) the discrimi-\nnative ﬁne-tuning. Regarding the former, it is important to highlight that the\ninformation reinforcement is performed during the greedy layer-wise process, in\nwhich the hidden layers (l = 1, 2, . . . , L) receive the positive “residual” informa-\ntion. Such a process takes into account a mini-batch of size 128, a learning rate\nof 0.1, 50 epochs for the bottommost RBM convergence, and 25 epochs for the\nintermediate and top layers convergence7.\nMoreover, regarding the classiﬁcation phase, a softmax layer was attached\nat the top of the model after the DBN pre-training, performing the ﬁne-tuning\nprocess for 20 epochs through backpropagation using the well-known ADAM [9]\noptimizer. The process employed a learning rate of 10−3 for all layers. Further-\nmore, it was performed 15 independent executions for each model to provide\nstatistical analysis. To assess the robustness of the proposed approach, we em-\nployed seven diﬀerent DBN architectures changing the number of hidden neurons\nand layers, as denoted in Table 1.\nModel\nRes-DBN\nDBN\n(a)\ni:500:500:10\ni:500:500:10\n(b)\ni:500:500:500:10\ni:500:500:500:10\n(c)\ni:500:500:500:500:10\ni:500:500:500:500:10\n(d)\ni:1000:1000:10\ni:1000:1000:10\n(e)\ni:1000:1000:1000:10\ni:1000:1000:1000:10\n(f)\ni:1000:1000:1000:1000:10 i:1000:1000:1000:1000:10\n(g)\ni:2000:2000:2000:2000:10 i:2000:2000:2000:2000:10\nTable 1. Diﬀerent setups, where i stands for the number of neurons on the input layer.\n5 https://github.com/zalandoresearch/fashion-mnist\n6 https://github.com/rois-codh/kmnist\n7 Such a value is half of the initial one to evaluate Res-DBN earlier convergence.\nA Layer Wise Information Reinforcement in Deep Belief Networks\n7\n5\nExperiments\nIn this Section, we present the experimental results concerning seven distinct\nDBN architectures, i.e., (a), (b), (c), (d), (e), (f) and (g), over the aforemen-\ntioned datasets. Table 2 provides the average accuracies and standard deviations\nfor each conﬁguration on 15 trials, where the proposed approach is compared\nagainst the standard DBN formulation in each dataset for each conﬁguration.\nFurther, results in bold represent the best values according to the statistical\nWilcoxon signed-rank test [19] with signiﬁcance p ≤0.05 concerning each model\nconﬁguration. On the other hand, underlined values represent the best results\noverall models regarding each dataset, without a statistical diﬀerence, i.e., results\nsimilar to the best one achieved.\nExperiment\nMNIST\nFashion MNIST\nKuzushiji MNIST\nRes-DBN\nDBN\nRes-DBN\nDBN\nRes-DBN\nDBN\n(a)\n97.39 ± 0.08\n97.23 ± 0.09\n81.13 ± 0.33\n81.52 ± 0.27\n86.49 ± 0.18\n84.78 ± 0.29\n(b)\n97.61 ± 0.07\n97.44 ± 0.11\n81.49 ± 0.50\n81.41 ± 0.57\n87.75 ± 0.20\n85.81 ± 0.18\n(c)\n97.59 ± 0.10\n97.57 ± 0.09\n81.66 ± 0.33\n81.51 ± 0.60\n88.21 ± 0.18\n86.97 ± 0.30\n(d)\n97.66 ± 0.10\n97.40 ± 0.10\n81.55 ± 0.35\n81.15 ± 0.64\n87.67 ± 0.19\n86.24 ± 0.21\n(e)\n97.85 ± 0.06\n97.48 ± 0.12\n82.05 ± 0.48\n81.59 ± 0.51\n88.95 ± 0.16\n87.57 ± 0.20\n(f)\n97.80 ± 0.37\n97.68 ± 0.29\n82.16 ± 0.50\n82.19 ± 0.46\n89.63 ± 0.23\n88.81 ± 0.40\n(g)\n97.88 ± 0.19\n97.51 ± 0.30\n82.73 ± 0.53\n82.63 ± 0.36\n89.45 ± 0.78\n88.70 ± 0.60\nTable 2. Experimental results on diﬀerent datasets.\nRegarding the original MNIST dataset, the preeminence of the proposed\nmodel over the standard version of the RBM is evident, since the best results\nwere obtained exclusively by Res-DBN and, from these, ﬁve out of seven scenarios\npresented statistical signiﬁcance. Such a behavior is stressed in the Kuzushiji\nMNIST dataset, where the best results were obtained solely by the Res-DBN\nover every possible conﬁguration. The results’ similarity between these datasets\nis somehow expected since both are composed of handwritten digits or letters.\nThe Fashion MNIST dataset presents the single experimental scenario, i.e.,\nmodel (a), where the proposed model was outperformed by the traditional DBN,\nalthough by a small margin. In all other cases Res-DBN presented results supe-\nrior or equal to the traditional formulation, which favors the Res-DBN use over\nthe DBNs.\nFinally, one can observe the best results overall were obtained using a more\ncomplex model, i.e., with a higher number of layers and neurons, as denoted\nby the underlined values. Additionally, the proposed model outperformed or at\nleast is equivalent, to the standard DBN in virtually all scenarios, except one\nconcerning the Fashion-MNIST dataset.\n8\nM. Roder et al.\n5.1\nTraining Evaluation\nFigures 3, 4, and 5 depict the models’ learning curves over the test sets regarding\nMNIST, Fashion MNIST, and Kuzushiji MNIST, respectively. In Figure 3, one\ncan observe that Res-DBN(e) converged faster than the remaining approaches,\nobtained reasonably good results after seven iterations. At the end of the process,\nRes-DBN(f) and (g) boosted and outperformed Res-DBN(e), as well as any of\nstandard DBN approaches, depicted as dashed lines.\nFig. 3. Accuracy on MNIST test set.\nRegarding Fashion MNIST, it can be observed in Figure 4 that Res-DBN(e)\nwas once again the fastest technique to converge, obtaining acceptable results\nafter ﬁve iterations. However, after iteration number ﬁve, all models seem to\noverﬁt, explaining the performance decrease observed over the testing samples.\nFinally, after 14 iterations, the results start increasing once again, being Res-\nDBN(g) the most accurate technique after 20 iterations.\nFinally, the Kuzushiji learning curve, depicted in Figure 5, displays a behavior\nsilimiar to the MNIST dataset. Moreover, it shows that Res-DBN provided better\nresults than its traditional variant in all cases right from the beginning of the\ntraining. In some cases with a margin greater than 2%, showing a promissing\nimprovement.\n6\nConclusions\nIn this paper, we proposed a novel approach based on reinforcing DBN’s layer-\nby-layer feature extraction in a residual fashion, the so-called Residual Deep\nA Layer Wise Information Reinforcement in Deep Belief Networks\n9\nFig. 4. Accuracy on Fashion MNIST test set.\nFig. 5. Accuracy on Kuzushiji MNIST test set.\n10\nM. Roder et al.\nBelief Network. Experiments conducted over three public datasets conﬁrm the\nsturdiness of the model. Moreover, it is important to highlight faster convergence\nachieved by Res-DBN in front of DBN, once half of the epochs were employed\nfor pre-training hidden layers, and the results outperformed the latter model.\nRegarding future work, we intend to investigate the model in the video do-\nmain, applying it to classiﬁcation and recognition tasks, as well as to propose a\nsimilar approach regarding Deep Boltzmann Machines.\nAcknowledgments\nThe authors are grateful to FAPESP grants #2013/07375-0, #2014/12236-1,\n#2017/25908-6, #2019/07825-1, and #2019/07665-4, as well as CNPq grants\n#307066/2017-7, and #427968/2018-6.\nReferences\n1. Clanuwat, T., Bober-Irizar, M., Kitamoto, A., Lamb, A., Yamamoto, K., Ha, D.:\nDeep learning for classical japanese literature. arXiv preprint arXiv:1812.01718\n(2018)\n2. Feichtenhofer, C., Pinz, A., Wildes, R.: Spatiotemporal residual networks for video\naction recognition. In: Advances in neural information processing systems. pp.\n3468–3476 (2016)\n3. Hassan, M.M., Alam, M.G.R., Uddin, M.Z., Huda, S., Almogren, A., Fortino, G.:\nHuman emotion recognition using deep belief network architecture. Information\nFusion 51, 10–18 (2019)\n4. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.\nIn: IEEE CVPR. pp. 770–778 (2016)\n5. Hinton, G.E., Osindero, S., Teh, Y.W.: A fast learning algorithm for deep belief\nnets. Neural Computation 18(7), 1527–1554 (2006)\n6. Hinton, G.: Training products of experts by minimizing contrastive divergence.\nNeural Computation 14(8), 1771–1800 (2002)\n7. Jung, H., Choi, M.K., Jung, J., Lee, J.H., Kwon, S., Young Jung, W.: Resnet-based\nvehicle classiﬁcation and localization in traﬃc surveillance systems. In: Proceedings\nof the IEEE Conference on Computer Vision and Pattern Recognition Workshops.\npp. 61–67 (2017)\n8. Khojasteh, P., Passos, L.A., Carvalho, T., Rezende, E., Aliahmad, B., Papa, J.P.,\nKumar, D.K.: Exudate detection in fundus images using deeply-learnable features.\nComputers in biology and medicine 104, 62–69 (2019)\n9. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980 (2014)\n10. LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P.: Gradient-based learning applied to\ndocument recognition. Proceedings of the IEEE 86(11), 2278–2324 (1998)\n11. Lin, T.Y., Goyal, P., Girshick, R., He, K., Doll´ar, P.: Focal loss for dense object\ndetection. In: Proceedings of the IEEE international conference on computer vision.\npp. 2980–2988 (2017)\n12. Passos, L.A., Pereira, C.R., Rezende, E.R., Carvalho, T.J., Weber, S.A., Hook, C.,\nPapa, J.P.: Parkinson disease identiﬁcation using residual networks and optimum-\npath forest. In: 2018 IEEE 12th International Symposium on Applied Computa-\ntional Intelligence and Informatics (SACI). pp. 000325–000330. IEEE (2018)\nA Layer Wise Information Reinforcement in Deep Belief Networks\n11\n13. Passos, L.A., Papa, J.P.: A metaheuristic-driven approach to ﬁne-tune deep boltz-\nmann machines. Applied Soft Computing p. 105717 (2019)\n14. Pereira, C.R., Passos, L.A., Lopes, R.R., Weber, S.A., Hook, C., Papa, J.P.: Parkin-\nson’s disease identiﬁcation using restricted boltzmann machines. In: International\nConference on Computer Analysis of Images and Patterns. pp. 70–80. Springer\n(2017)\n15. Salakhutdinov, R., Hinton, G.E.: Deep boltzmann machines. In: AISTATS. vol. 1,\np. 3 (2009)\n16. Santos, D.F., Pires, R.G., Colombo, D., Papa, J.P.: Video segmentation learning\nusing cascade residual convolutional neural network. In: 2019 32nd SIBGRAPI\nConference on Graphics, Patterns and Images (SIBGRAPI). pp. 1–7. IEEE (2019)\n17. Szegedy, C., Ioﬀe, S., Vanhoucke, V., Alemi, A.A.: Inception-v4, inception-resnet\nand the impact of residual connections on learning. In: Thirty-First AAAI Confer-\nence on Artiﬁcial Intelligence (2017)\n18. Wang, J., Wang, K., Wang, Y., Huang, Z., Xue, R.: Deep boltzmann machine based\ncondition prediction for smart manufacturing. Journal of Ambient Intelligence and\nHumanized Computing 10(3), 851–861 (2019)\n19. Wilcoxon, F.: Individual comparisons by ranking methods. Biometrics Bulletin\n1(6), 80–83 (1945)\n20. Xiao, H., Rasul, K., Vollgraf, R.: Fashion-mnist: a novel image dataset for bench-\nmarking machine learning algorithms. arXiv preprint arXiv:1708.07747 (2017)\n",
  "categories": [
    "cs.AI",
    "cs.LG"
  ],
  "published": "2021-01-17",
  "updated": "2021-01-17"
}