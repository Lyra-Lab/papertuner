{
  "id": "http://arxiv.org/abs/2102.06285v2",
  "title": "COVID-19 detection from scarce chest x-ray image data using few-shot deep learning approach",
  "authors": [
    "Shruti Jadon"
  ],
  "abstract": "In the current COVID-19 pandemic situation, there is an urgent need to screen\ninfected patients quickly and accurately. Using deep learning models trained on\nchest X-ray images can become an efficient method for screening COVID-19\npatients in these situations. Deep learning approaches are already widely used\nin the medical community. However, they require a large amount of data to be\naccurate. The open-source community collectively has made efforts to collect\nand annotate the data, but it is not enough to train an accurate deep learning\nmodel. Few-shot learning is a sub-field of machine learning that aims to learn\nthe objective with less amount of data. In this work, we have experimented with\nwell-known solutions for data scarcity in deep learning to detect COVID-19.\nThese include data augmentation, transfer learning, and few-shot learning, and\nunsupervised learning. We have also proposed a custom few-shot learning\napproach to detect COVID-19 using siamese networks. Our experimental results\nshowcased that we can implement an efficient and accurate deep learning model\nfor COVID-19 detection by adopting the few-shot learning approaches even with\nless amount of data. Using our proposed approach we were able to achieve 96.4%\naccuracy an improvement from 83% using baseline models.",
  "text": "COVID-19 detection from scarce chest x-ray image data\nusing few-shot deep learning approach\nShruti Jadon M.S.*\n1SPIE member; IEEE member; Sunnyvale, CA 95134\nABSTRACT\nIn the current COVID-19 pandemic situation, there is an urgent need to screen infected patients quickly and\naccurately.\nUsing deep learning models trained on chest X-ray images can become an eﬃcient method for\nscreening COVID-19 patients in these situations.\nDeep learning approaches are already widely used in the\nmedical community. However, they require a large amount of data to be accurate. The open-source community1\ncollectively has made eﬀorts to collect and annotate the data, but it is not enough to train an accurate deep\nlearning model.\nFew-shot learning2 is a sub-ﬁeld of machine learning that aims to learn the objective with\nless amount of data. In this work, we have experimented with well-known solutions for data scarcity in deep\nlearning to detect COVID-19. These include data augmentation, transfer learning, and few-shot learning, and\nunsupervised learning. We have also proposed a custom few-shot learning approach to detect COVID-19 using\nsiamese networks.3 Our experimental results showcased that we can implement an eﬃcient and accurate deep\nlearning model for COVID-19 detection by adopting the few-shot learning approaches even with less amount of\ndata. Using our proposed approach we were able to achieve 96.4% accuracy an improvement from 83% using\nbaseline models. Our code is available on github: https://github.com/shruti-jadon/Covid-19-Detection\nKeywords: Deep Learning, COVID-19, Image Classiﬁcation, X-ray, Medical imaging, Few-shot learning.\n1. INTRODUCTION\nA new coronavirus designated Covid-194 was ﬁrst identiﬁed in Wuhan, the capital of China’s Hubei province.\nIt has been reported that people started developing pneumonia5 without a clear cause and for which existing\nvaccines or treatments were not eﬀective. The virus has shown evidence of human-to-human transmission. As of\n24 January 2021, approximately 99 million people have contracted the virus and 2 million have lost their lives.\nAs ripple aﬀect, a lot of people have lost their livelihood and about 40%6 of small businesses have closed down.\nMajority of the countries weren’t prepared for such pandemic situation in their hospitality domain which led\nto situation of a lot of doctors’ risking their lives and working on multiple cases. With the help of technology,\nCovid-19 detection through CT scans can be automated to reduce up to 2 minutes per scan basis which generally\ntake close to 10-15 minutes. A lot of recent research papers7–9 have suggested to tackle this issue with the help\nof deep learning, but with less amount of data and biased data scenarios, its tough to make a good inference on\ntheir results.\nIn this work, we have experimented with some deep learning based techniques for training a model in low-data\nregime. We have also proposed a custom metrics based few-shot learning approach using siamese networks.10\nOur proposed architecture has proven to perform well on scarce data. To validate the eﬀectiveness and compare\nthe performance of models, we have performed extensive set of experiments and showcased results. The paper\nis organized as follows: Section 2 explains the classiﬁcation modeling approaches we have experimented with.\nIn Section 3, we discuss about the evaluation metrics used to assess the performance of models on a given\ndataset.\nOur experimental results are listed in Section 4 on several real-world data-sets.\nWe then ﬁnally\nconclude the outcomes in section 5. The project code has been made available for validation and replication of\nthese experiments and can be found at: https://github.com/shruti-jadon/Covid-19-Detection\nShruti Jadon, shrutijadon@ieee.org\narXiv:2102.06285v2  [eess.IV]  1 Mar 2021\nFigure 1. Sample Covid-19 CT scan dataset1, 8 images\n1.1 Dataset\nFor our research purposes, we have decided to experiment on two popular labeled datasets:\n1. dataset-1: Covid-19 Radiography database11 is a collaborative eﬀorts by various universities in Asia. It\nconsists of 1200 COVID-19 positive images, 1341 normal images, and 1345 viral pneumonia images. And,\n2. dataset-2: Covid-19 data collected with the help of University of Montreal.1,8 This data consists of 317\nlabeled images into three categories: Viral Pneumonia, Normal, and Covid.\nAfter analyzing the open-source data-set for Covid-19, we realized that it’s a case of scarce data and therefore\nto train a high capacity model from scratch wouldn’t be a good idea. To increase our dataset, we have taken\nhelp of data augmentation, but medical image augmentation have certain constraints, unlike generic vision based\ndataset we can’t manipulate medical images. Therefore, we have used augmentation techniques such as shear,\nzoom, and rotation of smaller respective values.\n2. MODELING APPROACHES\nThe data scarcity situation is not new in the medical ﬁeld. The medical community, in general, suﬀers from\ndata-scarcity problems leading to the slow development of automation towards disease detection. The problem\nwith less data is that if we train a good capacity model, we get underﬁtting, whereas if we train a low capacity\nmodel, our performance fails. To mitigate the eﬀects of scarce data: the data augmentation approach generally\nworks well, but if the data distribution is not a representation of real world data, it could lead to a biased model.\nFor this research, we have selected certain widely used deep learning approaches to tackle scarce data situation.\n1. Transfer Learning\n2. Unsupervised Learning\n3. Semi-Supervised Learning\n4. Few-Shot Learning\nFigure 2.\nSample Convolutional Neural Network architecture followed by non-linear layers and sigmoid function to\nconvert embeddings into probabilistic output of possible categories.\nCreating an eﬃcient performance model requires two main properties: Good Embeddings and better objective\nfunction. For image-based features, a model needs to have a high capacity or learned weights to extract high-level\nfeatures. Similarly, the objective function should create clearer deﬁned segregation among classes even in case\nof scarce or biased data.\n2.1 Baseline Model: Logistic Regression\nFor this research, we have taken logistic regression as a baseline model for Covid classiﬁcation. Logistic regression\nconsists of one layer of non-linearity using softmax followed by cross-entropy objective function. The logistic\nRegression model generally works best when the objective focuses on some low-level feature such as binary\nclassiﬁcation of a house-sale or color-basis classiﬁcation.\n2.2 Convolutional Neural Networks based model12\nDeep Learning has transformed many industries ranging from the manufacturing industry, food industry, and\nnow medical industry. Among all architectures, Convolutional Neural networks12 played an important role in\nthe computer vision domain. Convolutional Neural Networks are inspired by mammals’ visual cortex and how\ntheir vision system uses a layered architecture of neurons in the brain. Just like humans have a group of neurons\nto recognize shapes and sizes, Convolutional neural network layers extract speciﬁc forms of features from image\ninput to analyze the object in an image. Convolutional layers are also called feature extractor layer because a\nrange of features of the image is extracted within each layer. In this work, we have implemented a ten layered\nconvolutional neural network for Covid classiﬁcation. For our experiments, we used a 5 layer convolutional neural\nnetwork followed by 5 linear layers with cross entropy loss function as objective.\n2.3 Transfer Learning13\nTransfer learning refers to a scenario where an architecture that has been optimized on a similar domain data-\nset, can be used to learn a low-data regime objective. It uses one trained neural network for generalization\nand then uses the current data-set to improve those parameters. Transfer learning13 became popular and has\nhelped resolve scarce data situations in many cases, but we generally do not get similar domain data with\nmedical images. In this research, we have taken one of the leading VGG-16 architecture trained on Image-Net\nfor transfer learning. We have chosen diﬀerent domain for pre-training as training a VGG-16 level of architecture\nfrom scratch requires more than 10k images properly annotated and access to good computation power. For\nour experiments, we extracted the features of the ﬁnal convolutional layer of VGG-16 Net and added a logistic\nregression layer followed by cross-entropy loss for Covid classiﬁcation.\nFigure 3.\nAn Example of how transfer learning can be utlized in various sub-ﬁelds of medical industry with help of\nsimilar domain supervised data.\n2.4 Unsupervised Learning based models14\n2.4.1 t-SNE15 and PCA\nt-Distributed Stochastic Neighbor Embedding (t-SNE) is a widely used technique for dimensionality reduction.\nIt is particularly used for the visualization and analysis of high-dimensional data-sets. t-Distributed stochastic\nneighbor embedding (t-SNE) minimizes the divergence between two distributions: a distribution that measures\npairwise similarities of the input objects and a distribution that measures pairwise similarities corresponding\nto low-dimensional points in the embedding. In simpler terms, t-SNE analyzes the original data entered into\nthe algorithm and hypothesizes the best representation of data in lower dimensions by matching both distri-\nbutions. The hypothesizing process is computationally expensive; therefore, there are certain limitations to its\nusage with real data. For example, in very high dimensional data, to avoid the heavy computation, we can add\nanother dimensionality reduction technique before using t-SNE. In this research, as our data comes under high\ndimensional data (251X224X224X3), we have used another popular dimensionality reduction approach known as\nPCA(Principal Component Analysis). PCA attempts to reduce the size of feature dimensions with eigen vectors’\nhelp while ensuring we are not losing essential information. For our experiments, we have ﬁrst used PCA to\nbring the dimensions down to 180 and later used t-SNE for visualization, as shown in ﬁg 5.\n2.4.2 K-Means Clustering\nK-Means clustering is a 3-step process.\n1. initialize K centroids in the embedding space.\n2. Compute the distance of each point from each centroid and assign a point to that cluster whose centroid\nis closest to it. Do this for every point until preliminary clusters have been formed.\n3. Within each cluster, recompute the centroid and repeat step 2 until clusters stop changing. Here, K is the\nnumber of clusters that the user wants.\nThe objective of K-Means is to partition N data points into K clusters in such a manner that the within-cluster\nsum of squares or variance is minimized. We used scikit-learn’s available k-means clustering algorithm for our\nimplementation, with randomly initialized centroids.\n2.4.3 Gaussian Mixture Models Clustering\nIn Gaussian Mixture Model clustering, clusters are modeled with Gaussian distributions, which means that we\nuse variance and the mean to deﬁne each cluster.GMM allows for overlapping clusters, with the mixture model\nbeing parameterized by three values - each cluster’s weight, the mean of each cluster, and the variance of each\ncluster. The probability of belonging to a particular cluster is assigned to each data point using the Expectation-\nMaximization algorithm. Given the number of component gaussians or clusters (K), this algorithm consists of\nthe following two steps:1. Expectation:\n1. Expectation: In the ﬁrst step, the probability of each point belonging to a cluster calculated for the current\nvalues of weight, mean, and variance of that cluster.\n2. Maximization: In this step, the expectation calculated in the previous step is maximized by modifying the\nvalues of weight, mean, and variance of clusters.\nThis iterative model runs until convergence, at which point the maximum likelihood estimate is provided.\nOnce the model parameters have been estimated, the ﬁtted model can be used for clustering. A point is assigned\nto that cluster for which the probability of it belonging to the cluster is maximum.\n2.5 Few-Shot Learning using Siamese Networks10\nFew-shot learning is a sub-ﬁeld of machine learning which aims to develop models that can be trained with less\namount of data-set and provide the required performance. For a model to be eﬃcient, it requires good embeddings\nor better optimization approach which can reach the desired objective within less steps. There are three types of\nfew-shot learning apporoaches: Metrics based, Models based, and Optimization based; Metric based approaches\nfocuses of learning better embeddings whereas Models based and Optimization based approaches focuses on\nimproving the architectural components and optimization algorithms respectively. In this work, we have taken\nadvantage of one of these Metrics based approach known as Siamese Networks. Siamese stands for ‘twins‘, and\nas the name suggests Siamese Networks consists of two architectures similar in all features and shares weights\namong it. For image type data, these similar architectures are generally chosen to be of Convolutional Neural\nNetwork type followed by contrastive loss function. For training a siamese network, we pass the input in set of\npairs, e.g; we take 2 input images and label them if they are similar or not, then these two input images (x1\nand x2) are passed through the ConvNet to generate a ﬁxed length feature vector for each (h(x1) and h(x2)).\nAssuming the neural network model is trained properly, we can make the following hypothesis: If the two input\nimages belong to the same character, then their feature vectors must also be similar, while if the two input\nimages belong to the diﬀerent characters, then their feature vectors will also be diﬀerent. This idea of extracting\nembeddings on basis of similarity and dissimilarity helps model to train with less number of examples and even\ntake advantage of transfer learning approach.For our research, we further modiﬁed the Siamese network to get\nfeatures followed by VGG16 layers (trained on Image Net).\n3. EVALUATION METRICS\nTo assess the performance and understand machine learning models, we needed a good set of evaluation metrics.\nFor this work, we have used ﬁve metrics: Accuracy, Precision, Recall, F1-score, and the Silhouette score.\n3.1 Accuracy\nAccuracy is the most intuitive performance measure, and it is merely a ratio of correctly predicted observations\nto the total observations. One may think that if we have high accuracy, then our model is best. Yes, accuracy is\nan excellent measure only when we have symmetric data-sets where false positives and false negatives are almost\nthe same. Therefore, we have to look at other parameters to evaluate the performance of our model.\nAccuracy =\nTP + TN\nTP + TN + FP + FN\n(1)\nFigure 4. An architectural representation of Siamese Networks with case of two diﬀerent class input.\n3.2 Precision\nPrecision is the ratio of correctly predicted positive observations to the total predicted positive observations.\nFor each category/class, there is one precision value. We focus on precision when we need the predictions to be\ncorrect, i.e., ideally, we want to make sure the model is right when we predict a label.\nPrecision =\nTP\nTP + FP\n(2)\n3.3 Recall\nRecall is the ratio of what the model predicted correctly to what the actual labels are.\nSimilarly, for each\ncategory/class, there is one recall value. We care about recall when we want to maximize the prediction of a\nparticular class, i.e., ideally, we want the model to capture all the class examples.\nRecall =\nTP\nTP + FN\n(3)\n3.4 F1 Score\nF1 score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and\nfalse negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful\nthan accuracy, especially if we have an uneven class distribution. Accuracy works best if false positives and false\nnegatives have similar costs. If the cost of false positives and false negatives is very diﬀerent, it’s better to look\nat Precision and Recall.\nF1 −Score = 2 ∗Precision ∗Recall\nPrecision + Recall\n(4)\n3.5 Silhouette Score\nSilhouette score is used to analyze the clustering-based approaches. It analyzes the mean of intra-cluster vs.\nmean of inter-cluster distance using the formula:\nSilhouetteScore =\n(b −a)\nmax(a, b)\n(5)\nThere is one condition that the number of clusters’ should be less than the number of samples - 1. It ranges\nfrom -1 to 1, where 1 represents the best value.\n4. EXPERIMENTS AND RESULTS\nIn this paper, we have performed experiments using listed models and evaluated them based on well-known\nmetrics listed in the above section. We used the TensorFlow library for the implementation of our models on\nCPU: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\nRAM: 4x 8GB, 2133 MT/s\nGPU: GeForce GTX 1060, 6GB\nTo validate the eﬀectiveness of the proposed Siamese based approach with transfer learning features, which is\ninspired by VGG16 architecture. We ﬁrst explored some image augmentation and increase the data-size by\n10% making our data-set of\n3800 and\n4200, respectively. After further pre-processing such as normalizing\nand reshaping the CT-scan images to (224X224), we divided the data-set for training 60%, validation 20% and\ntesting 20% which belonged to 3 classes: Covid, Viral Pneumonia, and Normal.\nTable 1. Accuracy, Precision, Recall and F1-Score using mentioned classiﬁcation based modeling approaches trained and\ntested on combined datset-1 and dataset-2.\nModel Name\nAccuracy\nPrecision\nRecall\nF1-score\nLogistic Regression\n82.4%\n0.822\n0.828\n0.828\nConvolutional Neural Network\n90.2%\n0.912\n0.901\n0.904\nTransfer Learning(VGG16)\n93.3%\n0.931\n0.932\n0.928\nSiamese Networks\n94.6%\n0.945\n0.941\n0.947\nSiamese Networks(Transfer Learning)\n96.4%\n0.965\n0.962\n0.959\nTable 2. Analysis of Clusters formed by K-Means and GMM algorithms with Silhouette Score using input as extracted\nembeddings of mentioned classiﬁcation approaches.\nModel Name / Clustering Approach\nK-Means\nGaussian Mixture Models\nLogistic Regression\n0.156\n0.158\nConvolutional Neural Network\n0.165\n0.171\nTransfer Learning\n0.189\n0.185\nPCA+TSNE\n0.578\n0.575\nSiamese Networks\n0.490\n0.487\nSiamese Networks (Transfer Learning)\n0.592\n0.583\n4.1 Observations\nAfter performing experiments and analyzing outcomes we have come to two major conclusions on training models\nin scarce data situations.\n1. Change is data distribution may result in low accuracy: When data is scarce, it’s tough to determine\nthe real distribution of data, even if we segregate data into train, test, and val. We might not be able to\ncapture the performance of model on real data distribution.\n2. General Classiﬁcation models might not work: In case of less data, generally unsupervised based\napproaches perform well. In our experiments, we have observed that the decision boundaries were more\nsegregated in the PCA+TSNE and Siamese Network approach, whereas for Logistic Regression, CNN, and\nTransfer Learning score observed is below 0.2 for both K Means and GMM clustering approaches.\nFigure 5.\n2-D Visualization of formed clusters using K-Means approach by extracting the feature embeddings using\ndimensionality reduction approach of PCA followed by t-SNE\n5. CONCLUSION\nIn this research article, we have experimented with deep learning architectures for the low-data regime. We also\nproposed a custom metrics based few-shot learning model to predict the multi-class classiﬁcation of Covid-19.\nWe approve our model with detailed experiments on the combined Covid-19 radiography collected dataset, where\nCT scan image belongs to 3 categories as Normal, Viral Pneumonia, and Covid is used to obtain the highest\naccuracy of our proposed approach. We also investigate the reduction of overﬁtting and regularization of the\nmodel eﬀect on our application performance. For this purpose, we used embedding analysis using silhouette\nscore and clustering approaches. Finally, we compare our proposed technique to the existing three widely used\nclassiﬁcation approaches, where our proposed model signiﬁcantly performed better than the others. We can see\nour proposed approach providing a 3% increment in accuracy for classiﬁcation and 0.42 increment in clustering\nscore. In the future, we plan to examine whether the same model can be employed on the other computer-aided\ndiagnostic problems.\nREFERENCES\n[1] Zhao, J., Zhang, Y., He, X., and Xie, P., “Covid-ct-dataset: a ct scan dataset about covid-19,” arXiv\npreprint arXiv:2003.13865 (2020).\n[2] Jadon, S., “An overview of deep learning architectures in few-shot learning domain,” arXiv preprint\narXiv:2008.06365 (2020).\n[3] Yuan, J., Guo, H., Jin, Z., Jin, H., Zhang, X., and Luo, J., “One-shot learning for ﬁne-grained relation\nextraction via convolutional siamese neural network,” in [2017 IEEE International Conference on Big Data\n(Big Data)], 2194–2199, IEEE (2017).\n[4] Mo, P., Xing, Y., Xiao, Y., Deng, L., Zhao, Q., Wang, H., Xiong, Y., Cheng, Z., Gao, S., Liang, K., et al.,\n“Clinical characteristics of refractory covid-19 pneumonia in wuhan, china,” Clinical Infectious Diseases\n(2020).\n[5] Zhang, L., Zhu, F., Xie, L., Wang, C., Wang, J., Chen, R., Jia, P., Guan, H., Peng, L., Chen, Y., et al.,\n“Clinical characteristics of covid-19-infected cancer patients: a retrospective case study in three hospitals\nwithin wuhan, china,” Annals of oncology 31(7), 894–901 (2020).\n[6] Crayne, M. P., “The traumatic impact of job loss and job search in the aftermath of covid-19.,” Psychological\nTrauma: Theory, Research, Practice, and Policy 12(S1), S180 (2020).\n[7] Afshar, P., Heidarian, S., Enshaei, N., Naderkhani, F., Raﬁee, M. J., Oikonomou, A., Fard, F. B., Samimi,\nK., Plataniotis, K. N., and Mohammadi, A., “Covid-ct-md: Covid-19 computed tomography (ct) scan\ndataset applicable in machine learning and deep learning,” arXiv preprint arXiv:2009.14623 (2020).\n[8] Cohen, J. P., Morrison, P., and Dao, L., “Covid-19 image data collection,” arXiv 2003.11597 (2020).\n[9] Horry, M. J., Chakraborty, S., Paul, M., Ulhaq, A., Pradhan, B., Saha, M., and Shukla, N., “Covid-\n19 detection through transfer learning using multimodal imaging data,” IEEE Access 8, 149808–149824\n(2020).\n[10] Jadon, S. and Srinivasan, A. A., “Improving siamese networks for one-shot learning using kernel-based\nactivation functions,” in [Data Management, Analytics and Innovation], 353–367, Springer (2021).\n[11] Chowdhury, M. E. H., Rahman, T., Khandakar, A., Mazhar, R., Kadir, M. A., Mahbub, Z. B., Islam, K. R.,\nKhan, M. S., Iqbal, A., Emadi, N. A., Reaz, M. B. I., and Islam, M. T., “Can ai help in screening viral and\ncovid-19 pneumonia?,” IEEE Access 8, 132665–132676 (2020).\n[12] LeCun, Y., Bengio, Y., et al., “Convolutional networks for images, speech, and time series,” The handbook\nof brain theory and neural networks 3361(10), 1995 (1995).\n[13] Alzubaidi, L., Fadhel, M. A., Al-Shamma, O., Zhang, J., Santamar´ıa, J., Duan, Y., and Oleiwi, S. R.,\n“Towards a better understanding of transfer learning for medical imaging: a case study,” Applied Sci-\nences 10(13), 4523 (2020).\n[14] Chen, H., Li, J., Wang, R., Huang, Y., Meng, F., Meng, D., Peng, Q., and Wang, L., “Unsupervised learning\nof local discriminative representation for medical images,” arXiv preprint arXiv:2012.09333 (2020).\n[15] Perez, H. and Tah, J. H., “Improving the accuracy of convolutional neural networks by identifying and\nremoving outlier images in datasets using t-sne,” Mathematics 8(5), 662 (2020).\n[16] Narin, A., Kaya, C., and Pamuk, Z., “Automatic detection of coronavirus disease (covid-19) using x-ray\nimages and deep convolutional neural networks,” arXiv preprint arXiv:2003.10849 (2020).\n[17] West, C. P., Montori, V. M., and Sampathkumar, P., “Covid-19 testing: the threat of false-negative results,”\nin [Mayo Clinic Proceedings], 95(6), 1127–1129, Elsevier (2020).\n[18] Shi, F., Wang, J., Shi, J., Wu, Z., Wang, Q., Tang, Z., He, K., Shi, Y., and Shen, D., “Review of artiﬁcial\nintelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19,” IEEE reviews\nin biomedical engineering (2020).\n[19] Ozturk, T., Talo, M., Yildirim, E. A., Baloglu, U. B., Yildirim, O., and Acharya, U. R., “Automated\ndetection of covid-19 cases using deep neural networks with x-ray images,” Computers in Biology and\nMedicine , 103792 (2020).\n[20] Luz, E., Silva, P. L., Silva, R., and Moreira, G., “Towards an eﬃcient deep learning model for covid-19\npatterns detection in x-ray images,” arXiv preprint arXiv:2004.05717 (2020).\n[21] Ghoshal, B. and Tucker, A., “Estimating uncertainty and interpretability in deep learning for coronavirus\n(covid-19) detection,” arXiv preprint arXiv:2003.10769 (2020).\n[22] Jadon, S., Leary, O. P., Pan, I., Harder, T. J., Wright, D. W., Merck, L. H., and Merck, D. L., “A\ncomparative study of 2d image segmentation algorithms for traumatic brain lesions using ct data from\nthe protectiii multicenter clinical trial,” in [Medical Imaging 2020: Imaging Informatics for Healthcare,\nResearch, and Applications], 11318, 113180Q, International Society for Optics and Photonics (2020).\n[23] Jadon, S., “A survey of loss functions for semantic segmentation,” in [2020 IEEE Conference on Computa-\ntional Intelligence in Bioinformatics and Computational Biology (CIBCB)], 1–7, IEEE (2020).\n[24] Jun, M., Cheng, G., Yixin, W., Xingle, A., Jiantao, G., Ziqi, Y., Minqing, Z., Xin, L., Xueyuan, D.,\nShucheng, C., Hao, W., Sen, M., Xiaoyu, Y., Ziwei, N., Chen, L., Lu, T., Yuntao, Z., Qiongjie, Z., Guoqiang,\nD., and Jian, H., “COVID-19 CT Lung and Infection Segmentation Dataset,” (Apr. 2020).\n[25] Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al., “Matching networks for one shot learning,” in\n[Advances in neural information processing systems], 3630–3638 (2016).\n[26] Alshazly, H., Linse, C., Barth, E., and Martinetz, T., “Explainable covid-19 detection using chest ct scans\nand deep learning,” Sensors 21(2), 455 (2021).\n[27] Ahuja, S., Panigrahi, B. K., Dey, N., Rajinikanth, V., and Gandhi, T. K., “Deep transfer learning-based\nautomated detection of covid-19 from lung ct scan slices,” Applied Intelligence 51(1), 571–585 (2021).\n[28] Maghdid, H. S., Asaad, A. T., Ghafoor, K. Z., Sadiq, A. S., and Khan, M. K., “Diagnosing covid-19\npneumonia from x-ray and ct images using deep learning and transfer learning algorithms,” arXiv preprint\narXiv:2004.00038 (2020).\n[29] Panwar, H., Gupta, P., Siddiqui, M. K., Morales-Menendez, R., Bhardwaj, P., and Singh, V., “A deep\nlearning and grad-cam based color visualization approach for fast detection of covid-19 cases using chest\nx-ray and ct-scan images,” Chaos, Solitons & Fractals 140, 110190 (2020).\n[30] Fu, M., Yi, S.-L., Zeng, Y., Ye, F., Li, Y., Dong, X., Ren, Y.-D., Luo, L., Pan, J.-S., and Zhang, Q.,\n“Deep learning-based recognizing covid-19 and other common infectious diseases of the lung by chest ct\nscan images,” medRxiv (2020).\n[31] Rahimzadeh, M., Attar, A., and Sakhaei, S. M., “A fully automated deep learning-based network for\ndetecting covid-19 from a new and large lung ct scan dataset,” medRxiv (2020).\n[32] Jain, R., Gupta, M., Jain, K., and Kang, S., “Deep learning based prediction of covid-19 virus using chest\nx-ray,” Journal of Interdisciplinary Mathematics , 1–19 (2021).\n[33] Omoniyi, T., Alabere, H., and Sule, E., “Diagnosis of covid-19 using artiﬁcial intelligence based model,” in\n[Journal of Physics: Conference Series], 1734(1), 012007, IOP Publishing (2021).\n[34] Liu, Y. and Ji, S., “A multi-stage attentive transfer learning framework for improving covid-19 diagnosis,”\narXiv preprint arXiv:2101.05410 .\n[35] Purohit, K., Kesarwani, A., Kisku, D. R., and Dalui, M., “Covid-19 detection on chest x-ray and ct scan\nimages using multi-image augmented deep learning model,” BioRxiv (2020).\n[36] Jain, G., Mittal, D., Thakur, D., and Mittal, M. K., “A deep learning approach to detect covid-19 coron-\navirus with x-ray images,” Biocybernetics and biomedical engineering 40(4), 1391–1405 (2020).\n[37] Elharrouss, O., Subramanian, N., and Al-Maadeed, S., “An encoder-decoder-based method for covid-19\nlung infection segmentation,” arXiv preprint arXiv:2007.00861 (2020).\n[38] Shorfuzzaman, M. and Hossain, M. S., “Metacovid: A siamese neural network framework with contrastive\nloss for n-shot diagnosis of covid-19 patients,” Pattern Recognition , 107700 (2020).\n",
  "categories": [
    "eess.IV",
    "cs.CV",
    "cs.LG"
  ],
  "published": "2021-02-11",
  "updated": "2021-03-01"
}