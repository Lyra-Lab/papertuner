{
  "id": "http://arxiv.org/abs/2103.09750v1",
  "title": "A Survey of Forex and Stock Price Prediction Using Deep Learning",
  "authors": [
    "Zexin Hu",
    "Yiqi Zhao",
    "Matloob Khushi"
  ],
  "abstract": "The prediction of stock and foreign exchange (Forex) had always been a hot\nand profitable area of study. Deep learning application had proven to yields\nbetter accuracy and return in the field of financial prediction and\nforecasting. In this survey we selected papers from the DBLP database for\ncomparison and analysis. We classified papers according to different deep\nlearning methods, which included: Convolutional neural network (CNN), Long\nShort-Term Memory (LSTM), Deep neural network (DNN), Recurrent Neural Network\n(RNN), Reinforcement Learning, and other deep learning methods such as HAN,\nNLP, and Wavenet. Furthermore, this paper reviewed the dataset, variable,\nmodel, and results of each article. The survey presented the results through\nthe most used performance metrics: RMSE, MAPE, MAE, MSE, accuracy, Sharpe\nratio, and return rate. We identified that recent models that combined LSTM\nwith other methods, for example, DNN, are widely researched. Reinforcement\nlearning and other deep learning method yielded great returns and performances.\nWe conclude that in recent years the trend of using deep-learning based method\nfor financial modeling is exponentially rising.",
  "text": " \n \n \n \n \nAppl. Syst. Innov. 2021, 4, x. https://doi.org/10.3390/xxxxx \nwww.mdpi.com/journal/asi \nReview \nA Survey of Forex and Stock Price Prediction Using Deep \nLearning \nZexin Hu1^ , Yiqi Zhao2^ and Matloob Khushi3,* \n^ authors contributed equally both authors should be considered first-author \n1 Affiliation 1; zehu4485@uni.sydney.edu.au \n2 Affiliation 2; yzha9512@uni.sydney.edu.au  \n2 Affiliation 3; mkhushi@uni.sydney.edu.au \n* Correspondence mkhushi@uni.sydney.edu.au;  \nAbstract: The prediction of stock and foreign exchange (Forex) had always been a hot and profitable \narea of study. Deep learning application had proven to yields better accuracy and return in the field \nof financial prediction and forecasting. In this survey we selected papers from the DBLP database \nfor comparison and analysis. We classified papers according to different deep learning methods, \nwhich included: Convolutional neural network (CNN), Long Short-Term Memory (LSTM), Deep \nneural network (DNN), Recurrent Neural Network (RNN), Reinforcement Learning, and other deep \nlearning methods such as HAN, NLP, and Wavenet. Furthermore, this paper reviewed the dataset, \nvariable, model, and results of each article. The survey presented the results through the most used \nperformance metrics: RMSE, MAPE, MAE, MSE, accuracy, Sharpe ratio, and return rate. We identi-\nfied that recent models that combined LSTM with other methods, for example, DNN, are widely \nresearched. Reinforcement learning and other deep learning method yielded great returns and per-\nformances. We conclude that in recent years the trend of using deep-learning based method for \nfinancial modeling is exponentially rising. \nKeywords: Deep Learning; Stock; Foreign Exchange; Financial Prediction; Survey \n \n1. Introduction \nThe share market is a snapshot of future growth expectation of the companies as well \nas the economy. Many factors have attributed to the stock's price fluctuation, which in-\ncludes but not limited to macro-economic factors, the market anticipation and confidence \nin the company's management and operation. The advancement of technology allows the \npublic to access a larger quantity of information in a timelier manner. It means that stock \nanalysis has become more and more difficult as a considerable amount of data has to be \nprocessed in a relatively short time. People hope that the progress made in big data, es-\npecially in the Deep Learning field, can help them analyses stock information [1]. \nForex is one of the largest financial markets in the world. The prediction of the ex-\nchange rate can provide investors with useful decision-making references to increase re-\nturn and reduce risk. However, the exchange rate is always under the influence of many \nfactors, such as countries' economy, politics, society, international situation, etc., so the \ncomplexity of the matter has made Forex prediction and forecasting a challenging re-\nsearch topic.[2] Nowadays, Forex Forecasting tasks apply many different deep learning \nmodels as the computer, and artificial intelligence technology matures. \nForex and stock are similar in many aspects. For example, they both have comparable \ntechnical indicators, both have similar charts (candle chart), and they would both be af-\nfected by its country's market sentiment. Therefore, this paper will discuss the application \nCitation: Lastname, F.; Lastname, F.; \nLast-name, F. Title. Appl. Syst. Innov. \n2021, 4, x. \nhttps://doi.org/10.3390/xxxxx \nReceived: date \nAccepted: date \nPublished: date \nPublisher's Note: MDPI stays neu-\ntral with regard to jurisdictional \nclaims in published maps and insti-\ntutional affiliations. \n \nCopyright: Â© 2020 by the authors. \nSubmitted for possible open access \npublication under the terms and \nconditions of the Creative Commons \nAttribution (CC BY) license \n(http://creativecommons.org/licenses\n/by/4.0/). \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n2 of 34 \n \n \n \nof deep learning to both Forex and the stock market and explore the impact of different \ndeep learning methods on their price trend prediction accuracy. \nThe continuous development in the AI field leads to the wide use of deep learning \ntechniques in many research fields and practical scenarios. Applications include natural \nlanguage processing, image recognition, medical predictions, and more. The neural net-\nworks used in these applications have also developed and improved due to the rise of \ndeep learning. For example, reinforcement learning has gained popularity since AlphaGo \ndefeated the best chess player at the time using it, and reinforcement learning has been \nimplemented in the financial prediction field since then [76]. These technological break-\nthroughs have given the stock and Forex prediction models a solid foundation to start and \na greater room to improve. \nThe highly complex nonlinear relationship of deep learning can fully describe the \ncomplex characteristics of the influencing factors. Besides, many other fields have verified \nthe accuracy of a deep learning model for prediction accuracy, such as image classifica-\ntion, gene analysis. Research results are also obtained for Time-series data analysis and \nprediction with a deep learning algorithm; for example, deep learning is used to predict \nthe offline store traffic [3]. Overall, deep learning models have excellent performance in \nother research fields. Therefore, it is feasible to predict stock and Forex trends with deep \nlearning. \nFinancial researchers around the world have been studying and analysing the \nchanges in the stock and Forex market. The broadening application of artificial intelli-\ngence has led to an increasing number of investors using deep learning model to predict \nand study the stock and Forex price. It has been proven that the fluctuation of stock and \nForex price could be predicted [4]. Different from the traditional statistical and economet-\nric models, deep learning can describe complex influencing factors. \nTherefore, this paper will investigate the different effects of different deep learning \nmethods on stock and Forex forecasting according to the existing published papers. This \nsurvey will analyse each paper from the following aspects: 1. What is the dataset of this \npaper; 2.What is the variable of this paper;3. What kind of deep learning model had been \nadopted; 4. What is the result of the prediction model?  \nThe structure of this paper will be as follows: firstly, the introduction of Forex and \nstock combined with deep learning; secondly, the criteria and research methods of the \narticle selected by the survey, thirdly, the impact and analysis of different deep learning \nmethods on stocks and Forex prediction; fourthly, the discussion and analysis of the above \nmethods; finally, the conclusion of the whole paper. \n \n2 Related deep learning methods and input introduction \n2.1 Convolutional neural network (CNN) \nCNN was widely used in the field of image recognition because of its powerful pat-\ntern recognition ability; its use was also extended to the field of economic prediction. Sim-\nilar to the traditional neural network, CNN was composed of multiple neurons connected \nby a hierarchical structure, and the weights and bias between layers can be trained. CNN \nwas different from the network structure of Fully Connected network such as \nDBN/SAE/BP, as the CNN could share the weight among the neurons in each layer of the \nnetwork. Hence the model significantly reduced the weight of the network and avoided \nfalling into dimensional disaster and local minimisation [5]. \nIf the characteristics of the stock market at a specific time point were regarded as a \nfeature graph, CNN had the potential to extract the characteristics of the stock market at \nthe corresponding period from these feature graphs. Therefore, CNN could be used to \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n3 of 34 \n \n \n \nbuild a timing-selection model and ultimately used to complete the construction of the \ntiming-selection strategy. \n \n2.2 Recurrent Neural Network (RNN) \nRNN belonged to the neural network, and it was good at modelling and processing \nsequential data. The specific expression was that the RNN was able to memorise the pre-\nvious state, and the previous state could be used in the current state calculation. The dif-\nferent hidden layers were non-independent, and the input of the current hidden layer \nincluded not only the output of the input layer but also the output of the previously hid-\nden layer. For this reason, RNN would have a good performance in dealing with the se-\nquential data. \nThe advantage of RNN was that it would consider the context of data in the process \nof training, which is very suitable for the scenario of stocks and Forex because the fluctu-\nation at a particular time often contains some connection with the previous trend. \n2.1.3 Long Short-Term Memory (LSTM) \nLSTM model is one of the variants of the RNN. Its core contribution was to introduce \nthe design of self-loop to generate the path of the gradient, which could continuously flow \nfor an extended period. The weight of the self-loop was also updated in each iteration, \nwhich solved the gradient vanishing problem that was easily generated when the RNN \nmodel updated the weights [6]. \nThe modelling of time series was essentially a process of nonlinear parameter fitting. \nThe LSTM model could perform well to reveal the correlation of nonlinear time series in \nthe delay state space, and to realise the purpose of stock prediction [7]. In the stock or \nForex trend prediction model based on LSTM, it obtained the corresponding data charac-\nteristics from the stock or Forex history data. \n \n2.4 Deep neural network (DNN) \nDNN was a neural network with at least one hidden layer. It could provide model-\nling for complicated nonlinear functions and own a high-level abstraction ability which \nmeant the fitting power of the model would be significantly improved. Meanwhile, it was \na kind of discriminant model, which could be trained through the backpropagation algo-\nrithm. \nSince the DNN was good at dealing with prediction problems with sizable data and \ncomplicated nonlinear mapping relations, an intelligent stock and Forex prediction sys-\ntem can be designed based on a DNN to predict stock and Forex trend. Hopefully, the \nmodel was able to achieve far higher accuracy than human beings. \n \n2.5 Reinforcement learning \nReinforcement learning was one of the deep learning methods that focus on how to \nact according to the current situation to profit maximisation. In reinforcement learning, \nthere were two basic elements: state and action. A strategy was defined as performing a \nparticular action in a specific state. All the learner had to do was to learn a good strategy \nby continually exploring and learning. \nIf the state is regarded as the attribute and the action as the label, it was easy to know \nthat both supervised learning and reinforcement learning was trying to find a map and \ninferred the label/action from the known attribute/state. In this way, the strategy in rein-\nforcement learning was equivalent to the classification/regression in supervised learning. \nHowever, in practical problems, reinforcement learning did not have such labelling infor-\nmation as supervised learning, and the results were often obtained after the attempt of the \naction. Therefore, reinforcement learning would continuously adjust the previous \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n4 of 34 \n \n \n \nstrategy through the feedback of the result information, for this reason, the algorithm \nwould learn: in which state to take which step would have the most beneficial result. \nTherefore, reinforcement learning could learn the best timing trading action (select-\ning the best price, trading duration, and order size) according to the market response. It \ncan view the contextual information (price, news, public opinion, interest rate, fees, trad-\ning action, returns, losses, etc.) of the transaction as an environment of reinforcement \nlearning. Gains or losses could be thought as the reward for learning, trading actions as \nactions, and factors as states or observations to realise the prediction of the stock and Forex \ntrend. \n \n2.5 Other deep learning methods \nIn this paper, we will discuss the prediction of stock and Forex trend by other deep \nlearning methods, for example, Hybrid Attention Networks (HAN) and self-paced learn-\ning mechanism (NLP); multi-filters neural network (MFNN), and Wavenet. The frequency \nof these methods in the selected articles is not high so that they will be discussed in section \n4.7. \n3. Review methodology and criteria \n3.1 Paper selection methods \nIn the past few years, there had been many deep learning model papers on stock and \nForex forecasting. In this paper, the articles analysed in this paper were all from the DBLP \ncomputer science bibliography and Microsoft Academic. \nFirstly, the keywords were searched in DBLP are:' CNN stock/Forex';' LSTM \nstock/Forex';' Deep learning stock/ Forex';' RNN stock/Forex' and' Reinforcement learning \nstock/Forex'. The keywords were searched in Microsoft Academic, then the filter of â2015-\n2021â and âDeep learningâ were applied. \nSecondly, The quality of the selected articles from DBLP was ensured by excluding \nall the journals and conferences that were informally published. The quality of the selected \narticles from Microsoft Academic were controlled by excluding all the journals and con-\nferences that were informally published as well as a minimum of 5 citations. Filtering on \ncitations as the searching method was designed to detect under-study area with in this \nfield, the paper with 5 more citations can be an indication that the area could be potentially \nexplored. Furthermore, it should be noted that we only consider papers with a novel \nmodel, implementing existing model would not be analysised in this review. \nAt the same time, the timeliness of the survey was provided by focusing on publica-\ntions after 2015. Among them, there were 4 papers in 2015,1 papers in 2016, 15 papers in \n2017, 30 papers in 2018, 28 papers in 2019, and 10 papers in 2020, in total 88 existing papers \nwould be reviewed. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n5 of 34 \n \n \n \n \nFigure 1 The systematic literature review in this paper \n3.2 Selected paper statistics \nIn this paper, the goal was to study the use of six different deep learning methods in \nForex/stock (which are CNN, LSTM, DNN, RNN, Reinforcement learning, and other deep \nlearning methods) with different datasets, input variables, and model type. All the results \nwere compared together for discussion and for concluding after individually analysed.  \nFigure 1 showed the annual distribution of papers collected and reviewed. Figure 2 \nshowed the distribution of the different methods in this paper. Figure 3 showed the sys-\ntematic literature review in this paper. Table 1 showed the distribution of different types \nof \narticles \nin \nthis \npaper. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n6 of 34 \n \n \n \n \nFigure 2 The annual distribution of papers collected and reviewed \n0\n5\n10\n15\n20\n25\n30\n35\n2015\n2016\n2017\n2018\n2019\n2020\nCNN\nLSTM\nDNN\nRNN\nReinforcement learning\nOther deep learning methods\n0\n5\n10\n15\n20\n25\n30\n2015\n2016\n2017\n2018\n2019\n2020\nCNN\nLSTM\nDNN\nRNN\nReinforcement learning\nOther deep learning methods\nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n7 of 34 \n \n \n \n \nFigure 3 The distribution of the different methods in this paper \nTable1. The distribution of different types of articles in this paper \nType of Method \nTotal paper \nNumber of papers in journals \nNumber of papers in conferences \nCNN \n18 \n6 \n12 \nLSTM \n38 \n13 \n25 \nDNN \n9 \n5 \n4 \nRNN \n5 \n2 \n3 \nReinforcement Learning \n8 \n1 \n7 \nOther deep learning methods \n10 \n3 \n7 \n \n \n4. Results \n4.1 Papers Descriptions \n4.1.1 CNN \n19%\n40%\n10%\n7%\n12%\n12%\nCNN\nLSTM\nDNN\nRNN\nReinforcement learning\nOther deep learning methods\n21%\n43%\n10%\n6%\n9%\n11%\nCNN\nLSTM\nDNN\nRNN\nReinforcement learning\nOther deep learning methods\nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n8 of 34 \n \n \n \n17 articles that used CNN technology for the stock and Forex prediction were briefly \ndescribed below, and as shown in the table. Table 2 shows the author, variables, dataset, \nand model of all the papers mentioned. \nTable 2 The overall information for the papers which used the CNN model \nReference No. \nAuthor \nDataset \nVariables \nModel \n[8] \nMaqsood, H. \n1.Top 4 perform-\ning companies of \nUS, Hong \nKong, Turkey, and \nPakistan \n2.Twitter dataset \n1.Open price, \nhigh price, low price, \nAdjClose price, Volume, \nand Close price \n2.sentiment(Positive, neu-\ntral and negative senti-\nment). \n \nCNN \n[9] \nPatil, P. \n1. News collected \non a financial \nwebsite. \n2.30 stocks of for-\ntune 500 compa-\nnies, such as \nWMT, XOM, and \nAAPL \nAdjacency matrix calcu-\nlated by the correlation  \ncoefficient and using news \nco-mentions \nGraph convolu-\ntion neural net-\nwork (GCN) \n[10] \nSim, HS. \nS&P 500 minute \ndata \nClose price  \nCNN \n[11] \nHoseinzade, E. \nS & P 500, \nNASDAQ, Dow \nJones industrial \naverage, NYSE, \nand Russell \n82 variables including high, \nlow, close price; Volume, \nRSI, KD, WR.etc   \n2D-CNN \nAnd 3D-CNN \n[12] \nEapen, J. \nStandard and \nPoor's (S&P) 500 \nstock dataset \nClose price \nCNN--Bi-Direc-\ntional  \nLSTM \n[13] \nYang, H. \nS&P 500 Index \nETF (SPY) \nhigh, low,close price;Vol-\nume,RSI,KD,WR,ROC,CCI \nCNN with MICFS \n[14] \nCai, S. \n1.Crawling finan-\ncial news \n2.Baidu Index \n1.word vector; headline and \nkeyword training set in the \nnews \n2.Close price \nCNN-LSTM \n[15] \nOncharoen, P. \nReuters and Red-\ndit \nStandard & Poor's \n500 Index \n(S&P500) and \nDow Jones Indus-\ntrial Average \n(DJIA) \nWord vectors of headlines \nClose prices, Bollinger \nband, RSI, and Stochastic \nOscillator \nCNN-LSTM \n[16] \nLiu, Y. \n1.Thomson Reu-\nters \n2.Standard & \nPoorâs 500 index \n(S&P 500) \n1.Financial news corpus \nwith headlines from Apple \n2.. Open price;  Close \nprice; High price; Low \nprice; Volume; Stochastic \nOscillator (%K); Larry Wil-\nliam (LW) %R indicator; \nand Relative Strength \nIndex (RSI) \nTransE-CNN-\nLSTM \n[17] \nSelvin, S. \nNSE listed com-\npanies \n: Infosys, TCS, \nand CIPLA \nClose price \nCNN Sliding-win-\ndow model \n[18] \nLiu, S. \nChinese stocks \nfrom the SINA FI-\nNANCE(Not \ngiven specific \ndata) \nClose price \nCNN-LSTM \n[19] \nGudelek, M.U. \n Exchange-\nTraded \nFunds(ETF) \nClose price, RSI, SMA, \nMACD, MFI, Wil-\nliams %R, the stochastic os-\ncillator, the ultimate oscilla-\ntor \n2D-CNN \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n9 of 34 \n \n \n \n[20] \nDing, X. \n1.S&P 500 index \n2.Reuters and \nBloomberg \n1.close price \n2.long-term, mid-term and \nshort-term feature vectors \nof news headlines \nNTN-CNN \n[71] \nZhao, Y. and Khu-\nshi \nUSDJPY Ex-\nchange rate \n1. Momentum Indicators: \nRSI5, RSI10, RSI20, \nMACD, MACDhist, MAC-\nDsignal, Slowk, Slowd, \nFastk, Fastd, WR5, WR10, \nWR20, ROC5, ROC10, \nROC20, CCI5, CCI10, \nCCI20  \n2. Volume Indicators: \nATR5, ATR10, ATR20 , \nNATR5, NATR10, \nNATR20, TRANGE \nWavelet De-\nnoised-ResNet \nCNN with light \nGBM \n[76] \nChen, S. and He, \nH.  \nChinese stock \nmarket \nClosing price \nCNN \n[77] \nUgur Gudelek, M. \nSPDR ETF \nClosing price and technical \nindicators \nCNN \n[78] \nChen, Jou-Fan \nTaiwan index fu-\ntures \nOpen, high, low, closing \nprice \nGAF+CNN \n[90] \nWen, M \nS%P500 \nOpen, High, Low, Close, \nAdjusted Close, and Vol-\nume. \nCNN \n \nMaqsood, H. proposed a CNN model that made use of the price and sentiment anal-\nysis as input and compared the proposed model with the Linear Regression and SVM. He \nconcluded that not all the significant events have a serious impact on stock exchange pre-\ndiction. However, more important local events could affect the performance of prediction \nalgorithms [8]. \nPatil, P. proposed a new network using graph theory and CNN, which leveraged \nSpatio-temporal relationship information between different stocks by modelling the stock \nmarket as a complex network. Meanwhile, the model used both stock indicators and fi-\nnancial news as input [9]. \nSim, HS proposed a CNN network that using the 9 technical indicators (Close Price, \nSMA, EMA, ROC, MACD, Fast%K, Slow%D, Upper Band, Lower Band) to verify the ap-\nplicability of the CNN method in the stock market. And he concluded that the use of tech-\nnical indicators in stock price forecasting by CNN has no positive effect [10]. \nHoseinzade, E. proposed two models: 2D-CNN and 3D-CNN using 82 different tech-\nnical indicators. And These two structures could improve the predictive performance of \nthe baseline algorithm by about 3% to 11% [11]. \nEapen, J.proposed a model that had multiple pipelines of CNN and bi-directional \nLSTM units. And it could improve prediction performance by 9% using a single pipeline \ndeep learning model and by over a factor of six using support vector machine regressor \nmodel on S&P 500 grand challenge dataset [12].  \nYang, H.m, proposed a multi-indicator feature selection for stock index prediction \nbased on a multichannel CNN structure without sub-sampling, named MI-CNN frame-\nwork. In this method, candidate indicators were selected by the maximal information co-\nefficient feature selection (MICFS) approach, to ensure the correlation with stock move-\nments whilst reducing redundancy between different indicators [13].  \nCai, S. proposed the CNN and LSTM forecasting system with financial news and \nhistorical data of the stock market. It had generated seven prediction models. According \nto the ensemble learning method, the seven models are constructed into one ensemble \nmodel to obtain an aggregated model. Unfortunately, all models had a lower prediction \naccuracy [14].  \nOncharoen, P.  proposed a new framework to train a DNN for stock market predic-\ntion. A new loss function was developed by adding a risk-reward function, which was \nderived from the trading simulation results [15]. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n10 of 34 \n \n \n \nLiu, Y. proposed to incorporate a joint model using the TransE model for representa-\ntion learning and a CNN, which extracted features from financial news articles. And then \nhe combined the model with LSTM to predict the price movement. The model could im-\nprove the accuracy of text feature extraction while reducing the sparseness of news head-\nlines [16]. \nSelvin, S. used CNN, LSTM, and RNN architectures to forecast the price of NSE listed \ncompanies and compares their performance. The final results showed that CNN is the best \narchitecture to predict the price of the stock because it could identify the trend of the di-\nrectional change [17]. \nLiu, S.proposed a CNN-LSTM model, and the model performed basic Momentum \nstrategy and Benchmark model whose return rates were 0.882 and 1.136 respectively. The \nCNN part could extract useful features even from low signal-to-noise time-series data, \nand the LSTM part could predict future stock prices with high accuracy, then the predict-\ning outcomes were used as timing signals [18]. \nGudelek, M.U. proposed a 2D-CNN model. This model adopted a sliding window \napproach then generated images by taking snapshots that are bounded by the window \nover a daily period. The model could predict the next day's prices with 72% accuracy and \nend up with 5:1 of our initial capital [19]. \nDing, X. proposed a deep learning method for the event-driven stock market predic-\ntion. Firstly, events were extracted from news text and represented as dense vectors, \ntrained using a novel neural tensor Network(NTN). Secondly, CNN was used to model \nboth short-term and long-term influences of events on stock price movements [20]. \nZhao, Y. proposed a Wavelet Denoised-ResNet CNN for Forex exchange rate predic-\ntion. The technical indicators were treated as an image matrix, the image matrix was first \ndenoised using Wavelet method, then processed by ResNet CNN, and lastly, LightGBM \nwas used to replace the softmax layer to output a prediction. [71] \nChen, S. and He, H. proposed a CNN model with a novel architecture, where it gen-\nerated better results than benchmark RNN model. [76] \nUgur Gudelek, M proposed a CNN model where financial data is taken as a image, \nthen using CNN to predict the desired trading action, the model yielded reasonable re-\nsults. [77] \nChen, Jou-Fan proposed a novel CNN model which utilized the power of Gramian \nAngular Field, the results produced were average, but it is a interesting research direction. \n[78] \nWen, M proposed a CNN model which relied on the reconstructed of time series, it \nturned the time series into segment, then CNN was used to classify each segment. The \nmodel generated good results.[90] \n4.1.2 RNN \n5 articles that used RNN technology for the stock and Forex prediction were briefly \ndescribed below, and as shown in the table. Table 3 showed the author, variables, dataset, \nand model of all the papers mentioned above. \nTable 3 The overall information for the papers which used RNN model \nReference no. \nAuthor \nDataset \nVariables \nModel \n[53] \nNi, L. \nEURUSD,AU-\nDUSD,XAU-\nUSD,GBPJPY,EUR-\nJPY,GBPUSD,USD\nCHF,USDJPY and \nUSDCAD \nopen price, close \nprice, \nhighest price and \nlowest price \nC-RNN \n[54] \nLi, C. \nCSI300,CSI200and \nCSI500 \nOpen price, high \nprice, low price, \nclose price, Volume, \nand amount. \nMulti-task RNN with \nMRFs \n[55] \nChen, W \nHS300 \n1.Technical features: \nopen price, high \nprice, low price, \nRNN-Boost \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n11 of 34 \n \n \n \nclose price, Volume, \nprice change, price \nlimit, Volume \nchange, Volume \nlimit, Amplitude, and \ndifference. \n2.Content features: \nsentiment features \nand LDA features \n[56] \nZhang, R. \nSandstorm sector of \nShanghai Stock Ex-\nchange \nOpen price, close \nprice, highest price, \nlowest price, and the \ndaily trading volume \nC-RNN(DWNN) \n[73] \nZeng, Z. and Khushi \nUSDJPY Exchange \nrate \nMomentum indica-\ntors: average direc-\ntional movement in-\ndex, absolute price \noscillator, arron os-\ncillator, balance of \npower, commodity \nchannel index, \nchande momentum \noscillator, percentage \nprice oscillator, mov-\ning average conver-\ngence divergence, \nWilliams, momen-\ntum, relative strength \nindex, stochastic os-\ncillator, triple expo-\nnential average. â¢ \nVolatility indicators: \naverage true range, \nnormalised average \ntrue range, true \nrange. \nAttention-based \nRNN-ARIMA \n \nNi, L. proposed a CRNN model to predict the price of 9 kinds of forex pair. The results showed \nthat the proposed model performed much better than the LSTM model and the CNN model[53]. \nLi, C. proposed a Multi-task RNN model with MRFs. The MMPL is proposed to automati-\ncally extract diversified and complementary features from individual stock price sequences which \nmeans there is no need for the technical indicators. Features learned by MMPL were passed to a \nbinary MRF with a weighted lower linear envelope energy function to utilise intra-clique higher-\norder consistency between stocks[54]. \nChen, W proposed an RNN-Boost model that made use of the technical indicators and senti-\nment features, and Latent Dirichlet allocation (LDA) features to predict the price of stocks. Its \nresults showed that the proposed model outperformed the single-RNN model[55]. \nZhang, R. proposed a Deep and Wide Neural Networks (DWNN) model where CNN's con-\nvolution layer was added to the RNN's hidden state transfer process. The results showed that the \nDWNN model could reduce the prediction mean squared error by 30% compared with the general \nRNN model[56]. \nZeng. Z proposed a novel Attention-based RNN (ARNN) where wavelet denoised input was \npassed to ARNN. The forecast was calculated using the ARIMA and the output of ARNN model. \n[73] \n4.1.3 LSTM \n27 articles that used LSTM technology for the stock and Forex prediction were briefly \ndescribed below, and as shown in the table. Table 4 showed the author, variables, dataset, \nand model of all the papers mentioned. \nTable 4 The overall information for the papers which used LSTM model \n# \nAuthor \nDataset \nVariables \nModel \n[21] \nNikou, M. \niShares MSCI United \nKingdom \nClose price \nLSTM \n[22] \nFazeli, A. \nS&P 500 \nOpen price, high \nprice, low price, \nclose price, adjusted \nclose price, Volume, \nvolatility, \nLSTM \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n12 of 34 \n \n \n \nWilliams %R and \nRSI \n[23] \nXu, Y. \nMicrosoft (MSFT)ã\nPO logistics (XPO) \nand AMD Daily \nstock price data are \ncollected from Yahoo \nFinance from 11 in-\ndustries \nFinance tweets from \na social media com-\npany StockTwits \nOpen price, high \nprice, low price, \nclose \nprice,AD,ADX,EMA\n,KAMA,MA,MACD,\nRSI,SAR,AMA .etc \nand finance tweet \nsentiment \nAttention-based \nLSTM \n[24] \nLakshminarayanan, \nS.K. \nDow Jones Industrial \nAverage (DJIA) \nClose price, moving \naverage, Crud oil \nprice, gold price \nLSTM \n[25] \nRana, M. \nSpanish stock com-\npany Acciona \nClose price \nLSTM \n[26] \nNaik, N.  \nCIPLA stock, ITC \nstock, \nTCS stock, ONGC \nstock, and Nifty in-\ndex \nClose price \nRNN with LSTM \n[27] \nNguyen, D.H.D \nNASDAQ stock mar-\nket:GE,AAPL,SNP \nand FB \nTrade volume, open, \nclose, high, low, and \nadjusted close prices \nDynamic LSTM \n[28] \nLai, C.Y. \nFoxconn, Quanta, \nFormosa  \nTaiwan Cement and \nTaiwan Semiconduc-\ntor \nKD, OBV, MACD, \nRSI, and the average \nof the previous five \ndays stock market in-\nformation (open, \nhigh, low, Volume, \nclose) \nLSTM \n[29] \nHossain, M.A. \nS&P500 \nOpen price, close \nprice, \nvolume \nLSTM with GRU \n[30] \nBaek, Y.  \nKOSPI200 and \nS&P500 \nClose price \nLSTM with preven-\ntion module, predic-\ntion module \n[31] \nKim, H.Y. \nKOSPI 200 \nClose price \nGEW-LSTM \n[32] \nLi, H. \nCSI-300 \nOpen price \nAttention-based \nMulti-Input LSTM \n[33] \nCheng, L.-C. \nData from Taiwan \nStock Exchange Cor-\nporation((Not given \nspecific data) \nOpen price, close \nprice, low price, high \nprice, Volume, KD, \nMA, RSV, etc. \nAttention-based \nLSTM \n[34] \nShah, D. \nTech Mahindra \n(NSE: TECHM) \nBSESensex \nClose price \nLSTM  \n[35] \nLin, B.-S. \nTaiwan Stock Ex-\nchange Corporation \n(TWSE) \nTrade volume, trans-\naction, open price, \nhighest price, lowest \nprice, close price, \nKD, RSI, and  Bol-\nlinger \nBands(BBands) \nLSTM \n[36] \nSkehin, T. \nFacebook Inc. (FB), \nApple Inc. (AAPL), \nAmazon.com Inc \n(AMZN), Netflix \nInc. \n(NFLX) and Alpha-\nbet Inc. (GOOG) in \nNASDAQ of S&P \n500 \nClose price \nARIMA-LSTM-\nWavelet \n[37] \nZhang, X. \nChina's A-share mar-\nket \nThe open price, close \nprice, highest price, \nlowest price, and \ntrading volume and \n11 indicators \nRNN with LSTM \n[38]  \nAchkar, R. \n Facebook \nstocks, Google \nstocks, and Bitcoin \nClose price \nRNN with LSTM \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n13 of 34 \n \n \n \nstocks collected from \nYahoo finance \n[39] \nZeng, Y. \nSSE50 index \nN/A \nLSTM \n[40] \nShao, X. \nPing An Bank \nClose price \nKmeans-LSTM \n[41] \nZhao, Z. \nSSE Composite In-\ndex,SSE 50,CSI \n500,CSI 300 and \nSZSE Composite In-\ndex \nClose price \nTime-weighted \nLSTM  \n[42] \nNelson, D.M. \nIBovespa index from \nthe BM&F Bovespa \nstock exchange \nOpen price, close \nprice, high price, low \nprice and Volume ex-\nponentially weighted \nmoving averages, \netc.(175 indicators in \ntotal) \nLSTM \n[43] \ndos Santos Pinheiro \n1.Standard&Poor's \n500 index \n2.Reuters and \nBloomberg \n1.financial domain \nnews text(headlines \ninstead of the full \ncontent); 2.Close \nprice \nNLP+LSTM \n[44] \nBuczkowski, P. \nExpert recommenda-\ntion from TipRanks \ncompany \nA stock identifier, a \nlist of expert recom-\nmendations of vary-\ning length, and op-\ntional target labels \n(class) \nLSTM with GRU \n[3] \nAkita, R. \nMorning edition of \nthe Nikkei newspa-\nper \nNikkei 225 \n1.Paragraph Vector; \n2open, close, highest \nand lowest price \nLSTM \n[45] \nChen, K \nChina stock market \nin Shanghai and \nShenzhen from Ya-\nhoo finance \nvolume, high, low, \nopen, close price \nLSTM \n[75] \nQi, Ling and Khushi \nForex Exchange rate \nTechnical indicators \nLSTM \n[80] \nPang, Xiong Wen \nChinese stock \nstock data, stock \nnews, capital stock \nand shareholders, and \nfinancial analysis \nDeepLSTM with en-\ncoder \n[81] \nFeng, Fuli, et al. \nNASDAQ and \nNYSE \nStock data \nLSTM with ranking \nrelation \n[82] \nChung, Hyejung, and \nKyung-shik Shin. \nKorea Stock Price In-\ndex \nOpen, High, low, \nclosing, volume and \ntechnical indicators. \nLSTM with GA \n[83] \nLi, Jiahong, et al. \nChinese Stock Mar-\nket \nClosing price and \nsentiment data \nLSTM with NaÃ¯ve \nBayes \n[84] \nZhang, Kang, et al. \nS&P 500 Index, \nShanghaiComposite \nIndex, IBM from \nNYSE, MSFT from \nNASDAQ, PingAn \nInsurance Company \nof China (PAICC) \nOpen, High, low, \nclosing, volume and \ntechnical indicators. \nLSTM with Genera-\ntive Adversarial Net-\nwork (GAN) \n[91] \nJin, Zhigang, et al. \nApple stock price \nSentiment and stock \nprice data \nLSTM with senti-\nment analysis model \n[92] \nLong, Jiawei, et al. \nChinese Stock mar-\nket \nMarket information \nincluding transaction \nrecords \nLSTM with CNN \n[93] \nChen,M. \nChinese stock market \nSentiment infor-\nmation \nLSTM \n[94] \nQian,F. Chen,X \nChinese stock market \nClosing price \nLSTM with ARIMA \n[95] \nLi,Z. Tam,V. \nAsian stock indexes  \nClosing price and \ntechnical indicators \nLSTM with Wavelet \nDenosing \n \nNikou, M. proposed an LSTM model and compared it with the ANN model, SVR \nmodel, and RF model. The results showed that the LSTM model performed better in the \nprediction of the close price of iShares MSCI United Kingdom than the other models men-\ntioned in the paper[21]. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n14 of 34 \n \n \n \nFazeli, A. proposed an LSTM model; his result showed an improve through using \nLeakyReLU. MSE came below 0.1. Whilst compared with the ReLU function; the MSE \nwent well above 0.2. He examined the effect of RSI, Williams %R, and volatility on the loss \nof the model. It was shown that the model's loss was reduced by using only RSI, which \ncontributed to the performance of the model[22]. \nXu, Y. proposed an attention-based LSTM model that performs better than the regu-\nlar LSTM. It was found that finance tweets that were posted from market closure to market \nopen the next day had more predictive power on the next day's stock movement. The \nweighted sentiment on the max follower on StockTwits also performed much better than \nother methods[23]. \nLakshminarayanan, S.K. proposed an LSTM model combined with Crud oil price, \ngold price, and moving average, which performed much better than the LSTM model \nwithout them and the SVM model. It showed that the Crud oil and gold price had some \nimpact on the stock price prediction[24]. \nRana, M. proposed an LSTM model that outperformed the LR and SVR model. He \nalso compared the different activation functions with different optimisers and concluded \nthat the tanh activation with the adam algorithm performs best with the accuracy of \n98.49%[25].  \nNaik, N. proposed an RNN with the LSTM model. The model had the ability to keep \nthe memory of historical stock returns in order to forecast future stock return output. It \nwas worth noting that the recent stock information rather than old related stock infor-\nmation was stored and used. The network also outperformed the Feed Forward ANN \nmodel[26]. \nLai, C.Y. proposed a Dynamic LSTM model The results showed that stock prediction \naccuracy based on MAE, MAPE, RMSE, and MSE obtained by the dynamic LSTM model \nwas much better than that by the static LSTM model. The dynamic model also consistently \noutperformed the linear models SA-5 and EMA-0.5 when predicting four stocks[27]. \nLai, C.Y. proposed an LSTM model which used average previous five days stock \nmarket information (open, high, low, Volume, close) as the input value. The initial predic-\ntion was calculated using the value. The prediction was then used as part of the average \nof the stock price information for the next five days through the ARIMA method. Moreo-\nver, he utilised Technical Analysis Indicators to consider whether to buy stocks or con-\ntinue to hold stocks or sell stocks[28].  \nHossain, M.A. proposed an LSTM model followed by GRU. Both of the LSTM and \nGRU were powerful recurrent networks that could perform better and faster in terms of \naccuracy in regression-based prediction. And the proposed model outperformed the \nLSTM only, GRU only, and GRU followed by the LSTM model[29]. \nBaek, Y. proposed a novel data augmentation approach for stock market index fore-\ncasting through ModAugNet framework, which consisted of two modules: an overfitting \nprevention LSTM module and a prediction LSTM module. The overfitting problems \nmainly caused by the limited availability of data points for training[30]. \nKim, H.Y. proposed some LSTM model to forecast stock price volatility that com-\nbined the LSTM model with various generalised autoregressive conditional heteroscedas-\nticity (GARCH) -type models. He found that the GEW-LSTM model, which combined all \nthree models, GARCH, EGARCH, and EWMA, with LSTM, performed best[31]. \nLi, H. proposed an improved MI- LSTM based on LSTM and attention mechanism, \nwhich achieved better performance in extracting potential information and filtering noise. \nThe model could assign different weights to different input series to keep the dominant \nstatus of the mainstream while absorbing information from leaky input gates[32]. \nCheng, L.-C. proposed an Attention-based LSTM model that could solve the problem \nof exploding and vanishing gradients and thus did not effectively capture long-term de-\npendencies[33]. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n15 of 34 \n \n \n \nShah, D. proposed an LSTM model which was compared with the DNN model. The \nproposed model was able to predict volatile movements in the true data. In general, it was \nable to recognise the directionality of the changes in the true data more accurately than \nthe DNN[34]. \nLin, B.-S. proposed an LSTM model to predict the price of the top 10 industries in-\ncluded in Taiwan Stock Exchange Corporation (TWSE).In the experimental results, most \nof the results were reasonable except for the MTK stock[35]. \nSkehin, T. proposed a linear Autoregressive Integrated Moving Average (ARIMA) \nmodel and LSTM network for each series to produce next-day predictions. Wavelet meth-\nods decomposed a series into approximation and detail components to better explain be-\nhaviour over time. He combined these techniques in a novel ensemble model in an at-\ntempt to increase forecast accuracy[36]. \nZhang, X. proposed a simple but efficient method to predict future stock return rank-\ning without handcrafted features[37]. \nAchkar, R. proposed an approach to predict stock market ratios using artificial neural \nnetworks. It considered two different techniques BPA-MLP and LSTM-RNN their poten-\ntial, and their limitations. And the LSTM-RNN model outperformed the other one \nslightly[38].  \nZeng, Y. proposed an LSTM model which is based on the dataset SSE50, and the re-\nsults showed that the accuracy is above 65%[39]. \nShao, X. proposed a Kmeans-LSTM model that used the time window to divide the \nstock price sequential data into several equal sub-sequences. And the K-means algorithm \nis used to cluster the stock price sub-sequence (He did not give the specific result data.) \n[40]. \nZhao, Z. proposed a time-weighted LSTM. Unlike other models which treat data in-\ndiscriminately, the proposed model could carefully assign weights to data according to \ntheir temporal nearness towards the data that was used for prediction. And the results \nshowed that the proposed model outperformed the SVM, RNN, and Random Forest, \nmodel[41]. \nNelson, D.M. proposed an LSTM model which was based on the price history and \ntechnical analysis indicators. And the results showed that the proposed model was better \nthan the MLP and Random Forest model[42]. \nDos Santos Pinheiro proposed a character-based neural language model for an event-\nbased trading model that was combined with NLP and LSTM. The results showed that \nthe proposed model performed better than some model proposed in other papers such as \nWI-RCNN and SI-RCNN[43]. \nBuczkowski, P. tackled the problem of stock market predicting feasibility, especially \nwhen predictions were based only on a subset of available information, namely: financial \nexperts' recommendations. The analysis was based on data and results from the ISMIS \n2017 Data Mining Competition[44]. \nAkita, R. proposed an approach that converted newspaper articles into their distrib-\nuted representations via Paragraph Vector and modelled the temporal effects of past \nevents on open prices about multiple companies with LSTM[3]. \nChen, K proposed an LSTM model to predict the price of the Chinese stock. But the \nresults showed that the accuracy is only 27.2%[45].  \nQi, L. proposed an LSTM model to predict the price of the forex exchange rate. The \nmodel used technical indicators to calculate events then LSTM is used to make the predic-\ntion based on the events. [75] \nPang, Xiong Wen propsed two improved deep LSTM model with embedded layers. \nThe results showed its improvement over the benchmark. [80] \nFeng, Fuli, et al. proposed a noval LSTM model that combined with stock relational \nmodel, it had a great performance compared with its benchmarks. [81] \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n16 of 34 \n \n \n \nChung, Hyejung, and Kyung-shik Shin proposed a LSTM model which is optimized \nby genetic algorithm (GA). The novel hybrid model had outperformed the benchmark.[82] \nLi, Jiahong, et al. proposed a LSTM model that was combined with a NaÃ¯ve Bayneâs \nmodel. This hybrid model had outperformed benchmarks, and delivered promising re-\nsults. [83] \nZhang, Kang, et al. propsed a novel generative adversarial network based on MLP \nand LSTM. The model is able to better results than some of the vanilla models. [84] \nJin, Zhigang, et al. propsed to incorporate sentiment analysis model into LSTM, they \nsuccessfully created a novel model which deliver a reasonable result. [91] \nLong, Jiawei, et al. propsed a hybrid model, which utilised CNN to extract transac-\ntional information, then it was passed through a LSTM to predict the stock price. The \nmodel showed improvement over some of the vanilla benchmarks.[92] \nChen,M proposed a LSTM model which uses the sentiment data collected. It com-\nbined both sentimental model as well as LSTM to produce a good result. [93] \nQian,Fei. Proposed a LSTM model which used ARIMA to improve its prediction \npower. The model yielded a reasonable result.[94] \nLi.Z and Tam, V proposed a LSTM model that used wavelet denoising technique \nbefore passing through the LSTM model, the model had produced good result. [95] \n4.1.4 DNN \n13 articles that used DNN technology for the stock and Forex prediction were briefly \ndescribed below, and as shown in the table. Table 5 shows the author, variables, dataset, \nand model of all the papers mentioned. \nTable 6 The overall information for the papers which used DNN model \n# \nAuthor \nDataset \nVariables \nModel \n[46] \nSong, Y. \nKOSPI and \nKOSDAQ \n715 novel input-fea-\ntures(such as (mov-\ning average and dis-\nparity of stock price) \nDNN \n[47] \nNaik, N. \nNSE \nICICI Bank \nSBI Bank \nKotak Bank \nYes Bank \nSMA, Exponential \nmoving average, Mo-\nmentum indicator, \nStochastic oscillator, \nMoving average con-\nvergence divergence, \nRelative strength in-\ndex, Williams R, Ac-\ncumulation \nDistribution index, \nCommodity channel \nindex \nDNN \n[48] \nChatzis, S.P. \nFRED database and \nthe SNL \nStock price, Ex-\nchange ratesï¼VIX \nindexï¼Gold price, \nTED spread, Oil \nprice, Effective Fed-\neral Funds Rate, \nHigh yield bond re-\nturns \nDNN \n[49] \nAbe, M. \nMSCI \n25 variables:1.Book-\nto-market ratio \n2.Earnings-to-price \nratio3.Dividend \nyield4.Sales-to-price \nratio5.Cash flow-to-\nprice ratio 6.Return \non equity 7.Return \non asset  \n8.Return on invested \ncapital 9.Accru-\nals10.Sales-to-total \nassets ratio 11.Cur-\nrent ratio12.Equity \nratio13.Total asset \nDNN \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n17 of 34 \n \n \n \ngrowth14.Investment \ngrowth15.Invest-\nment-to-assets ratio \n16.EPS Revision(1 \nmonth) 17.EPS Revi-\nsion(3 months) \n18.Market beta19. \nMarket value 20. \nPast stock return(1 \nmonth) 21.Past stock \nreturn(12 months) \n22 .Volatil-\nity23.Skewness24.Id-\niosyncratic volatil-\nity25. Trading turno-\nver \n[50] \nNakagawa, K. \nTOPIX index \n16varia-\nbles:60VOL,BETA,S\nKEW,ROE,ROA,AC\nCRUALS,LEVER-\nAGE,12-\n1MOM,1MOM,60M\nOM,PSR,PER,PBR,P\nCFR,CAP,ILIQ \nDeep factor \nmodel(DNN) with \nlayer-wise relevance \npropagation and mul-\ntiple factors) \n[51] \nChong, E. \nKOSPI \nClose price \nDNN with autoen-\ncoder \n[52] \nSingh, R. \nNASDAQ \n36variables:Open \nprice,high price, low \nprice, close price, \nMA5,MA10,MA20,\nBIAS5,BIAS10,DIF\nF,BU,BL,K,D,ROC,\nTR,MTM6,MTM12,\nWR%10,WR%5,OS\nC6,OSC12,RSI6,RSI\n12,PSY and the deri-\nvation of their calcu-\nlation \n(2DÂ²PCA) \n+DNN \n[87] \nYu, Pengfei, and \nXuesong Yan \nS&P 500, DJIA, the \nNikkei 225 (N 225), \nthe \nHang Seng index \n(HSI), the China Se-\ncurities index 300 \n(CSI 300) and the \nChiNext index \nClosing price \nDNN with phase-\nspace reconstruction \n(PSR) and LSTM \n[89] \nYong, Bang Xiang, et \nal. \nSingapore stock mar-\nket \nIntraday prices \nDNN \n \nSong, Y. proposed a DNN model with 715 novel input-features configured on the basis of \ntechnical analysis. He also had proposed a plunge filtering technique to improve the accuracy of \nthe training model by collecting similar stocks. It was worth noting that the proposed model had \ngreat profitability[46]. \n \nNaik, N. proposed a DNN model that used the Boruta feature selection technique to solve the \nproblem of technical indicator feature selection and identification of the relevant technical indica-\ntors. And the results showed that his model performed much better than ANN and SVM model[47]. \n \nChatzis, S.P. proposed a DNN model in which it used Boosted approaches to predict stock \nmarket crisis episodes. According to his research, it was meaningful to know the stock market crisis \nto predict the price, even though his research was not specific to certain prediction methods[48].  \nAbe, M. proposed a DNN network and his results showed that DNNs generally outperform \nshallow neural networks, and the best networks also outperformed representative machine learning \nmodels[49]. \nNakagawa, K. proposed a deep factor model and a shallow model with DNN. The deep factor \nmodel outperformed the linear model. This implied that the relationship between the stock returns \nin the financial market and the factors is nonlinear, rather than linear. The deep factor model also \noutperformed other machine learning methods including SVR and random forest. The shallow \nmodel was superior in accuracy, while the deep model was more profitable[50]. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n18 of 34 \n \n \n \nChong, E. proposed DNN networks and examined the effects of three unsupervised feature \nextraction methods including principal component analysis, auto-encoder, and the restricted Boltz-\nmann machine, on the network's overall ability to predict future market behaviour. Empirical results \nsuggested that DNNs could extract additional information from the residuals of the auto-regressive \nmodel and improve prediction performance; the same could not be said when the auto-regressive \nmodel is applied to the residuals of the network[51]. \nSingh, R. proposed a 2-Directional 2-Dimensional Principal Component Analysis \n(2DÂ²PCA)+DNN which outperformed than the RNN and (2DÂ²PCA) +RBFNN. The paper found \nthat the best results were generated from a window size  of 20 and a dimension of 10 Ã 10. The \ndeep learning method for higher dimensions and large window sizes was giving a limited perfor-\nmance[52]. \nYu, Pengfei, and Xuesong Yan proposed a novel DNN model which incorporated LSTM as \nwell as phase-space recognition. The model had produce promising results. [87] \nYong, Bang Xiang, et al. propsed a DNN model with 40 nodes which showed a rea-\nsonable results and appear to be a highly profitable model. [89] \n \n4.1.5 Reinforcement learning \n8 articles that used reinforcement learning technology for the stock and Forex predic-\ntion were briefly described below, and as shown in the table. Table 6 showed the author, \nvariables, dataset, and model of all the papers mentioned. \nTable 6 The overall information for the papers which used Reinforcement learning model \n# \nAuthor \nDataset \nVariables \nModel \n[57] \nLi, Y. \nUS stock dataset \nClose price and Vol-\nume \nDQN \n[58] \nShin, H.-G. \nKOSPI \na candlestick  chart, \nfour moving average \ncurves (5, 20, 60, \nand 120 days),  \n, a bar graph of trad-\ning volume, DMI, \nand SSO \nReinforcement \nLearning combined \nwith LSTM and \nCNN \n[59] \nJia, W. \nChinese stock codes: \n002415, 600016, \n600028, 600547, \n600999 and 601988 \nOpen price,high \nprice, low price, \nclose price, vol-\nume,DEA ,MACD  \nEXPMA,CDP ,TRIX\n,BBI, \nASI ,KDJ ,RSI , \nPSY \nVR ,ADX ,CCI ,WR\n,dm up,dm down \nReinforcement \nLearning with \nLSTM-based agent \n[60] \nCarapuÃ§o, J. \nEUR/USD \nbid/ask prices and \nvolumes \nReinforcement \nLearning \n[61] \nKang, Q. \nS&P500 index \nopen, low, high, \nclose price and trad-\ning volume \nReinforcement \nLearning with A3C \nalgorithm \n[62] \nZhu, Y. \nS&P500 index \nopen, low, high, \nclose price ,vol-\nume,MACD,MA6,M\nA12,RSI6,RSI12 and \nKD \nReinforcement \nLearning with ABN \n[63] \nSi, W. \nStock-IF,stock-\nIC,stock-IF \nClose price \nmulti-objective deep \nreinforcement learn-\ning with LSTM \n[64] \nPastore, A. \nFTSE100 stock in-\ndex \nDate, Type, Stock, \nVolume, Price, and \nTotal \nReinforcement learn-\ning \n \nLi, Y. proposed three different reinforcement learning methods to predict the price of the \nstock. The results showed that the best-performing Deep Reinforcement Learning model is DQN, \nnot Double DQN. The paper also demonstrated Duelling DQN, which was an improved model \nbased on DQN[57]. \nShin, H.-G. proposed a Reinforcement Learning model that combined with LSTM and CNN. \nThe model generated various charts from stock trading data and used them as inputs to the CNN \nlayer. The features extracted through the CNN layer were divided into column vectors and inputted \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n19 of 34 \n \n \n \nto the LSTM layer. The reinforcement learning defines agents' policy neural network structure, \nreward, and action, and provides buying, selling, and holding probabilities as final output[58]. \nJia, W. proposed a Reinforcement Learning with an LSTM-based agent who could automati-\ncally sense the dynamics of the stock market and alleviate the difficulty of manually designing \nindicators from massive data. The paper had compared a wide range of different input sets[59].  \nCarapuÃ§o, J. proposed a reinforcement learning-Q network model, Three hidden layers of \nReLU neutrons were trained as RL agents through the Q-learning algorithm under a novel simu-\nlated market environment framework. The framework was able to consistently induce stable learn-\ning that generalised to out-of-sample data[60]. \nKang, Q. proposed to apply the state-of-art Asynchronous Advantage Actor-Critic algo-\nrithm(A3C algorithm) to solve the portfolio management problem and designed a standalone deep \nreinforcement learning model[61]. \nZhu, Y. proposed an adaptive box-normalisation (ABN) stock trading strategy based on rein-\nforcement learning, which improved the original box theory. In his ABN strategy, the stock market \ndata was independently normalised inside each oscillation box[62]. \nSi, W. proposed a reinforcement learning model which had multi-objective and LSTM agent. \nIt could be found that feature learning could contribute to better performances. The LSTM network \nmade continuous decisions and could change positions at the right time, which reduced the trans-\naction cost, and the multi-objective structure made good profits within the acceptable risk[63]. \nPastore, A. analysed data for 46 players extracted from a financial market online game and \ntested whether Reinforcement Learning could capture these players' behaviour using a riskiness \nmeasure based on financial modelling[64]. \n \n4.1.6 Other Deep Learning Methods \n8 articles that used other deep learning technology for the stock and Forex prediction \nwere briefly described below, and as shown in the table. Table 7 showed the author, var-\niables, dataset, and model of all the papers mentioned. \nTable 7 The overall information for the papers which used other deep learning methods \n# \nAuthor \nDataset \nVariables \nModel \n[65] \nLong, W. \nCSI300 \nOpen price, high \nprice, low price, \nclose price, Volume \nMNFF \n[66] \nWu, J.-L. \nANUE \nstock message as in-\nformation to form \nthe text feature of \neach stock news(ti-\ntle, summary, and \nkeywords) \nHAN \n[67] \nCho, C.-H. \nCATHAY HOLD-\nINGS, Fubon Finan-\ncial, CTBC HOLD-\nINGS, ESFH, and \nFFHC \nOpen price,high \nprice, low price, \nclose price, vol-\nume,MACD,CCI,AT\nR,BOLL,EMA12/20,\nMA5,MA1MOM6,\nMOM12,ROC,RSI,\nWVAD,Exchange \nrate and Interest rate  \nWavenet \n[68] \nMinh, D.L \nS&P 500, VN-index \nand cophieu68; \nBloomberg, Reuters \nOpen price, high \nprice, low price, \nclose price, Volume, \nStochastic oscillator, \nWilliam (%R), and \nRSI \nProcessed news arti-\ncle \nDocuments prepro-\ncessing-Documents \nlabeling -Stock2Vec \nembedding-BGRU \n[69] \nHu, G. \nFinancial Times \nStock; Exchange 100 \nIndex (FTSE 100) \nCandlestick \ncharts(images rather \nthan annotation data) \nConvolutional Auto-\nEncoder(CAE) \n[70] \nHu, Z. \nChinese stock price; \nNews(Not given spe-\ncific data) \n1.Close price and \nvolume; 2.news cor-\npus sequence \nHAN with SPL \n[72] \nKim, T. and Khushi \nNine Dow Jones \ncompanies represent-\ning each sector - in-\ndustrials (MMM), fi-\nnancials (JPM), \nOpen price, high \nprice, low price, \nclose price, Volume \n2D Relative-Atten-\ntional Gated Trans-\nformer \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n20 of 34 \n \n \n \nconsumer services \n(PG), technology \n(AAPL), health care \n(UNH), consumer \ngoods (WMT), oil & \ngas (XOM), basic \nmaterials (DD) and \ntelecommunications \n(VZ) From Yahoo. \n[74] \nZhang, and Khushi \nForex Exchange \nrates \nTrend indicators: \nMoving average, Ex-\nponential moving av-\nerage, Double expo-\nnential moving aver-\nage, Triple exponen-\ntial moving average, \nVortex indicators  \nMomentum indica-\ntors: Relative \nstrength index, Sto-\nchastic oscillators, \nVolatility indicators: \nBollinger bands, \nIchimoku indicators \nGenetic Algorithm \n[79] \nHu, Ziniu \nChinese stiock data \nand economic news \nNews and financial \ndata \nHybird attention net-\nworks \n[86] \nShi, Lei, et al. \nApple Inc. and S&P \n500 \nNews and financial \ndata \nHybrid of RNN, \nLSTM and CNN \n \nLong, W. proposed a novel end-to-end model named multi-filters neural network \n(MFNN) specifically for feature extraction on financial time series samples and price \nmovement prediction task. Both convolutional and recurrent neurons are integrated to \nbuild the multi-filters structure. And the results showed that the proposed model is better \nthan the RNN, CNN, and traditional machine learning methods[65]. \nWu, J.-L. proposed a keyword-based attention network into Hierarchical Attention \nNetworks (HAN), namely the HKAN model, to learn the relationships between dimen-\nsional sentiments (trend and trading) and stock messages which outperformed the HAN \nnetwork[66]. \nCho, C.-H.proposed three different models to predict the price of the stock, they \nwere: LSTMï¼Seq2seq and Wavenet. According to his experiments, Wavenet outper-\nformed the other two models[67]. \nMinh, D.L proposed a network to predict the directions of stock prices by using both \nfinancial news and sentiment dictionary. His results showed that TGRU achieved better \nperformance than GRU and LSTM and Stock2Vec is more efficient in dealing with finan-\ncial datasets[68]. \nHu, G. proposed a Convolutional AutoEncoder model to learn a stock representation \nand converted a 4-channel stock time series (lowest, highest, open, and close price for the \nday) to candlestick charts by using synthesis technique to present price history as images. \nThis method had successfully avoided expensive annotation. And the proposed model \noutperformed the FTSE 100 index and many well-known funds in terms of total re-\nturn[69]. \nHu, G. proposed a Hybrid Attention Networks (HAN) to predict the stock trend \nbased on the sequence of recent related news. Moreover, he applied the self-paced learn-\ning(SPL) mechanism to achieve effective and efficient learning. The results showed the \nproposed model outperforms than RNN, Temporal- Attention-RNN, News-Attention-\nRNN, and HAN[70]. \nKim, T. proposed a 2D relative-attentional gated transformer which was used to op-\ntimise portfolio return. It used general reinforcement learning with the agent incorporat-\ning 2D Relative-attentional Gated Transformer. [72] \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n21 of 34 \n \n \n \nZhang, Z. proposed a genetic algorithm using a crossover of technique indicators as \ninput. It had successfully outperformed some of the traditional trading strategies.[74] \nHu, Ziniu proposed hybrid attention networks which is a novel way of combining \nfinancial time-series information and news nature language information. [79] \nShi, Lei, et al. propsed a system where it perform factor analysis then utilise multiple \ndepp learning method to design a model which outperformed benmark. [86] \n \n4.2 Papers Results grouped by the method used \n4.2.1 CNN \nSince the performance metrics used in different articles were different, our survey \nanalysed them based on various metrics. Results used were the average performance of \nthe best performing models in the mentioned papers. Table 8 showed the metrics and \nresults for the papers which used the CNN model. \nTable 8 The metrics and results for the papers which used the CNN model \nPerformance Metrics Reference no. Corresponding valuePerformance Metrics Reference no. Corresponding value \nRMSE \n[8] \n0.043+/- .007 \nMAPE \n[9] \n5 \n[9] \n[71] \n11 \n0.395185*10^-3 \nSharpe ratio \n[11] \n[11]2D:0.1422, 3D:0.1413 \nMAE \n[9] \n[71] \n6 \n0.240977*10^-3 \n[15] \n[15]0.611 \nAccuracy \n[10] \n71% \nCEQ \n[11] \n2D:0.0006681 3D:0.000664 \n \n[13] \n[16] \n60.02% \n55.44% \nReturn rate \n[11] \n[11](2D:1.2312 \n \n[19] \n71.72% \n \n3D:1.2604) \n \n[20] \n65.08% \n[13] \n[13](1.3107) \n \n[76] \n75.2% \n \n \n \n[77] \n78.46% \n \n \n \n[78] \n57.88% \n \n \n \n[90] \n74.753% \n \n \nError Percentage \n[17] \n95.02% \n[15] \n[15](1.2156) \nF-measure \n[11] \n2D:0.4944 \n[18] \n[18](1.309) \n \n3D:0.4931 \nMean Test Score \n[12] \n0.000281317 \n[15] \n0.6227 \nMSE \n[19] \n[71] \n0.2631 \n0.156*10^-6 \n[16] \n0.7133 \nAE \n[8] \n0.029+/-.005 \n \n[76] \n0.73 \n \n \n \n[90] \n0.6367 \n \n \n4.2.2 RNN \nSince the performance metrics used in different articles were different, our survey \nanalysed them based on different metrics. Results used were the average performance of \nthe best performing models in the mentioned papers. Table 9 shows the metrics and re-\nsults for the papers which used the RNN model. \nTable 9 The metrics and results for the papers which used RNN model \nPerformance Metrics  \nReference no. \nCorresponding value \nRMSE \n[53] \n[55] \n[73] \n512-530 \n0.0205 \n0.00165 \nMAPE \n[55] \n[73] \n0.2431 \n0.232 \nMAE \n[55] \n0.0132 \nAccuracy \n[54] \n[55] \n68.95% \n66.54% \nF-measure \n[54] \n0.7658 \nRecall \n[54] \n0.7471 \nPrecision \n[54] \n0.7855 \nMSE \n[56] \n0.057443 \n \n4.2.3 LSTM \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n22 of 34 \n \n \n \nSince the performance metrics used were different in different articles, our survey \nwould analyse them based on different metrics. Results used were the average perfor-\nmance of the best performing models in the mentioned papers. Table 10 showed the met-\nrics and results for the papers which used the LSTM model. \nTable 10 The metrics and results for the papers which used LSTM model \nPerformance Met-\nrics \nReference no. \nCorresponding \nvalue \nPerformance Met-\nrics \nReference no. \nCorresponding \nvalue \nRMSE \n[21] \n0.306543 \nMAPE \n[24] \n1.03 \n[24] \n347.46 \n[27] \n1.6905 \n[25] \n0.0151 \n[29] \n4.13 \n[26] \n25.90 \n[30] \n[75] \n1.0077 \n0.119 \n \n \n[82] \n0.91 \n \n \n[84] \n1.37 \n \n \n[91] \n1.65 \n \n \n[95] \n0.6346 \n[27] \n0.0242 \nPrecision \n[42] \n0.553 \n[28] \n1.3 \nRecall \n[42] \n0.129 \n[34] \n9.72 \nReturn rate \n[22] \n1.0667 \n[35] \n4.24(Average) \nMSE \n[21] \n0.093969 \n[36] \n[75] \n1-10 \n0.0015 \n[22] \n0.004845492 \n \n[94] \n0.02295 \n \n \n \n \n \n[81] \n0.000379 \nMAE \n[21] \n0.21035 \n[24] \n120731.4 \n[24] \n262.42 \n[27] \n19.7096 \n[26] \n0.1895 \n[28] \n0.019 \n[27] \n0.0169 \n[29] \n0.00098 \n[29] \n0.023 \n[30] \n7.56 \n[31] \n0.01069 \n[31] \n0.00149 \n[30] \n1.975 \n[32] \n1.012 \nAccuracy \n[23] \n54.58% \nMCC \n[23] \n0.0478 \n[25] \n98.49% \nR2 \n[24] \n0.83 \n[34] \n60.60% \nHMAE \n[31] \n0.42911 \n[39] \n65% \nHMSE \n[31] \n0.23492 \n[41] \n83.91% \nIC \n[37] \n0.1259 \n[42] \n55.90% \nAR \n[37] \n0.2015 \n[43] \n63.34% \nIR \n[37] \n3.0521 \n[45] \n27.20% \nScore \n[44] \n0.4271 \n \n[80] \n53.2% \n \n[83] \n87.86% \n \n[91] \n70.56% \n \n[92] \n75.89% \n \n[93] \n75.58% \nF-measure \n[42] \n0.209 \n \n4.2.4 DNN \nSince the performance metrics used in different articles were different, our survey \nanalysed them based on different metrics. Results used were the average performance of \nthe best performing models in the mentioned papers. Table 11 showed the metrics and \nresults for the papers which used the DNN model. \nTable 11 The metrics and results for the papers which used DNN model \nPerformance Met-\nrics \nReference no. \nCorresponding  \nvalue \nPerformance Met-\nrics \nReference no. \nCorresponding  \nvalue \nRMSE \n[50] \n0.0951 \nSharpe ratio \n[50] \n1.41 \n \n \n[89] \n5.34 \n[51] \n0.8214 \nReturn rate \n[49] \n1.0952 \n[52] \n0.00674 \n[50] \n1.1081 \nMAE \n[50] \n0.0663 \nCORR \n[49] \n0.0582 \n[51] \n0.5852 \nMSE \n[49] \n0.0836 \nAccuracy \n[46] \n61.90% \n[51] \n0.9621 \n[47] \n84.50% \nSMAPE \n[52] \n0.0696 \n \n[87] \n58.07% \n \n \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n23 of 34 \n \n \n \nF-measure \n[47] \n0.824 \nMAPE \n[52] \n0.080059 \n[89] \n1.84 \nVolatility \n[50] \n7.65% \n \n4.2.5 Reinforcement learning \nSince the performance metrics used were different in different articles, our survey \nwould analyse them based on different metrics. Results used were the average perfor-\nmance of the best performing models in the mentioned papers. Table 12 showed the met-\nrics and results for the papers which used the Reinforcement learning model. \nTable 12 The metrics and results for the papers which used Reinforcement learning model \nPerformance Metrics  \nReference no. \nCorresponding value \nSharpe ratio \n[58] \n[63] \n2.77 \n0.12 \nReturn rate \n[59] \n[60] \n[62] \n1.948 \n1.163 Â± 2.8% \n2.442 \nMSE \n[62] \n0.000412 \n \n4.2.6 Other Deep Learning Methods \nSince the performance metrics used in different articles were different, our survey analysed \nthem based on different metrics that were used. Results used were the average performance \nof the best performing models in the mentioned papers. Table 13 showed the metrics and \nresults for the papers which used other deep learning methods. \nTable 13 The metrics and results for the papers which used other deep learning methods \nPerformance Metrics  \nReference no. \nCorresponding value \nRMSE \n[67] \n0.6866 \nAccuracy \n[68] \n[70] \n66.32% \n47.8% \n \n[86] \n79.7% \nSharpe ratio \n[65] \n[69] \n[72] \n[74] \n4.49. \n0.8 \n0.6418 \n6.68 on EURUSD currency \nReturn rate \n[65] \n[68] \n[69] \n[70] \n[72] \n[74] \n1.4228 \n1.0531(0.25%) \n1.118 \n1.611(0.3%) \n1.4316 \n1.0968 on EURUSD currency \n \n[79] \n1.52 \nMSE \n[66] \n1.05 \nMDAE \n[66] \n0.71 \nCorrelation \n[67] \n0.9564 \nPrecision \n[68] \n72.1% \nRecall \n[68] \n77.32% \n \n5. Discussion \n5.1 Analysis based on the method used \n5.1.1 CNN \nSome findings can be drawn from reviewing the CNN models: \n1. According to the datasets that all the paper used, 6 papers used the combination \nof technical analysis and sentiment and news analysis to predict the stock. The rest of \nthem used the method of technical analysis only.  \n2. As for the variables, the close price was the choice of all CNN models, and five \npapers were using close price only. \n3. It could be found that 12 of the papers changed the traditional CNN model to pur-\nsue higher performance of prediction. And the combination of CNN and LSTM was the \nmost common model. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n24 of 34 \n \n \n \n4. The metrics used in each paper were different; there were 11 metrics used for meas-\nuring the performance of the CNN model. \n5.Multiple articles selected RMSE, Return rate, F-measure, Sharpe ratio, and accu-\nracy. We could find that the paper [19] had the highest accuracy than any other papers, \npaper [13] had the highest return rate followed by the paper [18], [11] and [15]. Paper [71] \nhad the lowest RMSE. Paper [16] had a higher F-measure than paper [11], and [15], but \npaper [15] achieved a higher Sharpe ratio than paper [11]. \n \n5.1.2 RNN \nIn the section of the RNN based model, the following conclusions could be drawn: \n1. According to the datasets that all the paper used, there was 1 paper that used the \ncombination of technical analysis and sentiment and news analysis to predict the stock. \nAnd the rest of them used technical analysis only. \n2. For the variables, all the RNN based models used the multivariable input and open \nprice, close price, highest price, and the lowest price are used in all models as an input. \n3. It could be found that all the papers changed the traditional RNN model to pursue \nhigher performance of prediction. Two of the papers chose the C-RNN based model. \n4. The metrics used in each paper were different; in total, there were 8 metrics used \nfor measuring the performance of the RNN based model. \n5.RMSE and accuracy were selected by multiple articles. We could note that paper \n[55] has a much lower RMSE than paper [53], and paper [54] had higher accuracy than \npaper [55]. \n \n5.1.3 LSTM \nFollowing points were worth discussing from reviewing the LSTM papers: \n1. According to the datasets that all the paper used, 3 papers used a combination of \ntechnical analysis and sentiment and news analysis to predict the stock. The rest of them \nused technical analysis only with the exception of one paper which used expert recom-\nmendations. \n2. As for the variables, the close price was the choice of 23 LSTM based models, there \nwere 8 papers using close price only, and 12 papers selected to include close price, open \nprice, high price, and low price in their input. \n3. It could be found that 15 of the papers changed the traditional LSTM model to \npursue higher performance of prediction. Attention-based LSTM and LSTM with RNN \nwere the most frequent models that showed up in three different papers. Two papers \nchose the method of LSTM with GRU to improve the model. \n4.The metrics used in each paper were different; there were 17 metrics used for meas-\nuring the performance of the LSTM based model. \nMultiple articles selected 5.RMSE, MAPE, MAE, accuracy, and MSE, we could find \nthat Paper [25], paper [94] and paper [27] was in the lowest order of magnitude with paper \n[25] achieving the lowest RMSE; paper [21] was in the second-lowest order of magnitude; \npaper [28],[35],[36] and paper [34] were in the third lowest order of magnitude. Paper [26] \nwas in the fourth lowest order of magnitude and paper [24] had the highest order of mag-\nnitude. \n6. As for MAPE, paper [75] had the lowest order of magnitude followed by the paper \n[30] ,[24], [82], [84],[91],[95] and [27]. And paper [29] had the highest order of magnitude \nof MAPE. \n7. As for MAE, paper [75], [31], [27] and [29] had the lowest order of magnitude MAE \nwith paper [75] having the best performance; paper[26] and [21] were in the second-lowest \norder of magnitude while paper [30] was in the third lowest order of magnitude. Paper \n[24] had the highest order of magnitude. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n25 of 34 \n \n \n \n8. As for MSE, paper  [81]had the lowest MSE and was in the lowest order of mag-\nnitude; paper [29] , [31] and [22] were in the second-lowest order of magnitude while pa-\nper [28] and [21] were in the third lowest order of magnitude. Paper [32] and [30] were in \nthe fourth lowest order of magnitude, paper [27] was in the fifth-lowest order of magni-\ntude, and paper [24] had the highest order of magnitude of MAE. \n9.As for accuracy, paper [25] had the highest accuracy followed by [83], [41],[39], [43], \n[34], [42], [23] and paper [45] had the lowest accuracy. \n \n5.1.4 DNN \nIn the section of DNN-based model, the following conclusions could be drawn: \n1. According to the datasets that all the paper used, no paper used the combination \nof technical analysis and sentiment and news analysis to predict the stock. All of them \nused the method of technical analysis only. \n2. As for the variables, six of the seven DNN-based models used multivariable input, \nand only one paper used close price as its sole input. \n3. It could be found that 3 of the papers changed the traditional DNN model to pursue \nhigher performance of prediction. All of the improved models were not duplicated. \n4. Because the metrics used in each paper were different; there were 11 different met-\nrics used for measuring the performance of the DNN-based model. \n5. Multiple articles selected 5.RMSE, MAE, accuracy, return rate, and MSE. We could \nfind that the paper [52] had the lowest RMSE followed by the paper [50] and [51], with \nthe latter two in different orders of magnitude. \n6. As for MAE, paper [50] had a lower MAE than paper [51], and the accuracy of the \npaper [47] was higher than paper [46] and [87]. Furthermore, paper [50] had a higher re-\nturn rate than paper [49]. And paper [49] had a lower MSE than paper [51]. \n \n5.1.5 Reinforcement learning \nIn the section of Reinforcement learning-based model, the following conclusions \ncould be drawn: \n1. According to the datasets that all the paper used, no paper used the combination \nof technical analysis and sentiment and news analysis to predict the stock. All of them \nused technical analysis only. \n2. As for the variables, 7 of the reinforcement learning-based models used the multi-\nvariable input, and only one paper solely used close price as input. \n3. It could be found that three of 6 papers changed the traditional Reinforcement \nlearning model to pursue higher performance of prediction. 3 of the improved models \nwere combined with LSTM. \n4. The metrics used in each paper were different; in total, there were 3 metrics used \nin the measurement performance of the Reinforcement learning-based model. \n5. Multiple articles selected 5. Sharpe ratio and return rate, we could find that paper \n[58] had a much higher Sharpe ratio than paper [63]; paper [62] had a higher return rate \nthan paper [59] then followed by the paper[60]. \n \n5.1.6 Other Deep Learning Methods \nIn the section of other deep learning methods based model, the following conclusions \ncould be drawn: \n1. According to the datasets that all the paper used, 4 papers made use of sentiment \nand news analysis to predict the stock. The rest of them used the method of technical \nanalysis only. \n2. As for the variables, five of the other deep learning methods models used the mul-\ntivariable input and only one paper used candlestick charts alone as input. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n26 of 34 \n \n \n \n3. It could be found that there were 5 different models in the other deep learning \nmethods section. The only model that appeared three times was HAN, which consist of \nan ordinary HAN model and two modified HAN models. The rest of the models were not \nduplicated. \n4. Because the metrics used in each paper were different, there were 9 metrics used \nin the measurement performance of this section. \n5. Multiple articles selected 5. Accuracy, Sharpe ratio, and Return rate, we could find \nthat the paper [86] had the highest accuracy.Paper [65] had a much higher Sharpe ratio \nthan paper [69]. \n6. As for the return rate, paper [70] had the highest return rate followed by the paper \n[65], [69]and paper [68] had the lowest return rate. \n \n5.2 Discussion and Analysis based on performance metrics \nIn this part, all of Forex/Stock price prediction models mentioned above, which made \nuse of the deep learning, would be discussed and analysed. All analysis of the perfor-\nmance metric data was shown in Table 14. It could be found that the most commonly used \nperformance metrics were RMSE, MAPE, MAE, MSE, Accuracy, Sharpe ratio, and Return \nrate. Hence our review would analyse the papers in terms of its performance metrics used. \nTable 14 Analysis based on Performance Metrics \nPerformance Metrics  \nReference no. \nRMSE \n[8], [9], [21], [24], [25], [26], [27], [28], [34], \n[35],[36],[50], [51], [52], [53], [55], [67],[71],[73] \nMAPE \n[9], [24], [27], [29], [30], [52], [55],[73],[82],[84],[94] \nMAE \n[9], [21], [24], [26], [27], [29], [31], [30], [50], [51], \n[55],[71],[95] \nAccuracy \n[10],[13],[16], [19], [20],[23], [25], [34],[39], [41], [42], \n[43], [45],[46], [47], [54], [55], [68], \n[70],[76],[77],[78],[80],[83],[87],[90],[91],[92],[93] \nF-measure \n[11], [42], [47], [54],[15],[16],[76],[90] \nSharpe ratio \n[11], [15],[50],[58], [63], [65], [69], [72],[74] \nCEQ \n[11] \nReturn rate \n[11], [13],[15],[18], [22], [49], [50],[59], [60], \n[65],[68],[69],[70] , [72],[74],[79] \nMean Test Score \n[12] \nMSE \n[19], [21], [22], [24], [27], [28], [29], [30], [31], [32], [49], \n[51],[56],[62],[71],[81] \nAE \n[8] \nPrecision \n[42], [54] \nRecall \n[42], [54] \nR2 \n[24] \nError Percentage \n[17] \n \n \nMCC \n[23] \nHMAE \n[31] \nHMSE \n[31] \nCORR \n[49] \nSMAPE \n[52] \nVolatility \n[50] \nIC \n[37] \nAR \n[37] \nIR \n[37] \nScore \n[44] \n \n5.2.1 analysis based on RMSE \nIn this part, the value of the RMSE in the papers would be discussed. Table 15 showed \nthe details of each paperâs RMSE based on the numerical range. In this table, paper [8], \n[9], [71] used CNN based model; paper  [21], [24], [25], [26], [27], [28], [34],[35],[36], \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n27 of 34 \n \n \n \n[75],[94] used LSTM based model; paper [50], [51], [52] used DNN based model; paper \n[53], [55], [73] used RNN based model and paper [67] used other deep learning method. \nTable 15 Analysis based on RMSE \nRMSE \nrange \nReference no. \nRMSE \n \n \n<0.001 \n[8], [9], [21], [24], [25], [26], [27], \n[28], [34], [35],[36],[50], [51], \n[52], [53], [55], [67],[71],[75],[94] \n[71], [75] \n0.001-0.01 \n[52], [73] \n0.01-0.1 \n[8], [21], [25],[27],[50], [55],[94] \n0.1-1 \n[9],[51],[67] \n1-10 \n[28],[34],[35],[36] \n10-100 \n[26] \n>100 \n[24], [53] \n \nIt was clear that paper [71], [75] achieved the best performance using DNN model. \nPapers that had a RMSE smaller than 0.001, paper [52], [73], [8], [21], [25], [27], [50], [55] \nhad great performance while paper [26], [24], [53] didnât have the low RMSE . \nAmong all the papers, 33% of the CNN papers had an RMSE below 0.001, 33% of the \nCNN papers were in the range of 0.01-0.1, and 33% of the CNN papers were in the range \nof 0.1-1. 36% of the LSTM papers were in the range of 0.01-0.1 and 1-10 respectively, , the \nrest LSTM papers were distributed equally in range of <0.001, 10-100 and above 100 with \n9%in each range. 33.3% of the DNN papers were in the range of 0.001-0.01, 0.01-0.1 and \n0.1-1 respectively. The RNN papers were distributed equally in the range of 0.001-0.01, \n0.01-0.1 and above 100, i.e. 33% in each range. The only paper that used other deep learn-\ning method had an RMSE in the range of 0.01-0.1. \n \n \n5.2.2 analysis based on MAPE \nIn this part, the value of the MAPE would be discussed. Table 16 showed the papers' \nMAPE performance based on the numerical range. In this table, paper [9] used CNN based \nmodel; paper [24], [27], [29], [30], [75], [82], [84], [95] used LSTM based model; paper \n[52],[89] used DNN based model; paper [55] used RNN based model. \nTable 16 Analysis based on MAPE \nMAPE range \nReference no. \nMAPE \n[9], [24], [27], [29], [30], [52], \n[55],[75],[82],[84],[89], [95] \n0-0.5 \n[52],[55],[75], [95] \n0.5-1 \n[82] \n1-1.5 \n[24],[30],[84],[89] \n1.5-2 \n[27] \n2-10 \n[9],[29] \n \nIt could be found that paper [52], [55],[75] performed best which used the DNN \nmodel and RNN model and LSTM respectively, and both were in the range of 1-1.5, paper \n[24],[30],[82] had great performance while paper [9], [29] didn't have a low MAPE. \nAmong all the papers, the only CNN paper was in the range of 2-10. 37.5% of the \nLSTM papers were in the range of 1-1.5, 12.5% of the LSTM papers were in the range of \n0.5-1, 1.5-2, and 2-10 respectively, 25% of LSTM papers in a range of 0-0.5. The two DNN \npapers were in the range 0-0.5, and 1-1.5. Lastly, the only one RNN paper was in the range \nof 0-0.5. \n \n5.2.3 analysis based on MAE \nIn this part, the value of the MAE would be discussed. Table 17 showed the details \nof papersâ MAE. In this table, paper [9], [71] used CNN based model; paper  [23], [26], \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n28 of 34 \n \n \n \n[28], [29], [31], [33], [32] used LSTM based model; paper [50], [51] used DNN based model \nand paper [55] , [73] used RNN based model.  \nTable 17 Analysis based on MAE \nMAE range \nReference no. \nMAE \n \n \n<0.01 \n[9], [21], [24], [26], [27], [29], \n[31], [30], [50], [51], [55], \n[71] \n[71] \n0.01-0.1 \n[27],[29],[31],[50],[55] \n0.1-1 \n[21],[26],[51],[73] \n1-10 \n[9],[30] \n10-100 \nN/A \n>100 \n[24], \n \nIt could be found that paper [71] performed best which used CNN model. Papers' \nMAE were in the range of 0.1-1. Paper [27], [29], [31], [50], [55] also had good performance, \nhowever, paper [24] didnât have a low MAE. \nAmong all the papers that used MAE as measurement, 50% of CNN paper was in the \nrange of 1-10; the other 50% had an MAE small than 0.01. 42.9% of the LSTM papers were \nin the range of 0.01-0.1, 28.6% of the LSTM papers were in the range of 0.1-1, 14.2% of the \nLSTM papers were in the range of 1-10 and above 100 respectively, 50% of the DNN pa-\npers were in the range of 0.01-0.1 and 0.1-1 respectively. The two RNN papers were in the \nrange of 0.01-0.1 and 0.1-1. \n \n5.2.4 analysis based on MSE \nIn this part, the value of the MSE would be discussed. Table 18 showed the details of \npapersâ MSE. In this table, paper [19], [71] used CNN based model; paper [21], [22], [24], \n[27], [28], [29], [30], [31], [32], [81] used LSTM based model and paper [49], [51] used DNN \nbased model. Paper,[56] used RNN based model, and paper [62] used the Reinforcement \nlearning based model.  \nTable 18 Analysis based on MSE \nMSE range \nReference no. \nMSE \n \n \n<0.01 \n[19], [21], [22], [24], [27], [28], \n[29], [30], [31], [32], [49], \n[51],[56],[62],[71] \n[71],[81] \n0-0.01 \n[22],[29],[31],[62] \n0.01-0.1 \n[21],[28],[49],[56] \n0.1-1 \n[19],[32],[51] \n1-10 \n[30] \n10-100 \n[27] \n>100 \n[24] \n \nIt could be found that paper [81] performed the best which used the LSTM model; its \nMSE was smaller than 0.01. Paper [71], [22], [29], [31],[62] also had good performance, \nhowever, paper [24], [27] didnât have the low MSE. \nAmong all the papers that used MSE as performance measurement, the only CNN \npaper was in the range of 0.1-1, 40% of the LSTM papers were in the range of 0-0.01, 20%of \nthe LSTM papers were in the range of 0.01-0.1, 10% of the LSTM papers were in the range \nof 0.1-1, 1-10, 10-100 and above 100 respectively, 50% of the DNN papers were in the range \nof 0.01-0.1 and 0.1-1 respectively. The only RNN based model and reinforcement learning-\nbased model was in the range of 0-0.01 and 0.01-0.1 respectively. \n \n5.2.4 analysis based on the accuracy \nIn this part, the value of the accuracy would be discussed. Table 19 shows the details \nof papersâ accuracy. In this table, paper [10], [13],[16], [19],[20],[76],[77],[78],[90] used \nCNN based model; paper [23], [25], [34], [39],[41], [42], [43],[45], [80], [83], [91],[92],[93] \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n29 of 34 \n \n \n \nused LSTM based model;paper [46], [47], [87] used DNN based model; paper [54], [55] \nused RNN based model and paper [68], [70],[86] used other deep learning method. \nTable 19 Analysis based on the accuracy \nAccuracy range \nReference no. \nAccuracy \n[10],[13],[16], [19], [20],[23], [25], \n[34],[39], [41], [42], [43], [45],[46], [47], \n[54], [55], [68], \n[70],[76],[77],[78],[80],[83],[86],[87], \n[90],[91],[92],[93] \n0-50% \n[45],[70] \n50%-60% \n[16],[23],[42],[78],[80],[87] \n60%-70% \n[13], [20],[34],[39],[43],[46],[54], \n[55],[68] \n70%-80% \n[10],[19],[76],[77],[86],[90],[91],[92],[93] \n80%-90% \n[41],[47].[83] \n90%-100% \n[25] \n \nIt could be found that paper [25] performed best, which used LSTM model, and the \npaper's accuracy was in the range of 90%-100%. Paper  [41], [47] ,[83] also had great per-\nformance, but paper [45], [70] didnât have the high accuracy. \nAmong all the papers that had accuracy measure metric, 22% of the CNN papers \nwere in the range of 50%-60%, and 22% of the CNN papers were in the range of 60%-70% \nand 55% of the CNN papers were in the range of 70%-80%. 8% of the LSTM papers were \nin the range of 0-50%, and 90%-100% respectively,15% of the LSTM papers were in the \nrange of 80%-90%, 23% of the LSTM papers were in the range of 50%-60%, 60%-70% and \n70%-80% respectively. 33% of the DNN papers were in the range of 50%-60%, 60%-70% \nand 80%-90% respectively. All the RNN papers were in the range of 60%-70%. 33% of \nother deep learning methods were in the range of 40%-50%, 60%-70% and 70-80% respec-\ntively. \n \n5.2.5 analysis based on Sharpe ratio \nIn this part, the value of the Sharpe ratio would be discussed. Sharpe ratio referred \nto the amount of return generated relative to the risk taken, where risk was calculated \nusing the standard deviation of return. Table 20 showed the details of the papers' that \nused the Sharpe ratio as a preformance metric. In this table, paper [11] and  [15] used \nCNN based model; paper [50], [89] used DNN based model; paper [58], [63] used Rein-\nforcement learning-based model, and paper [65], [69], [72], [74] used other deep learning \nmethod. \nTable 20 Analysis based on Sharpe ratio \nSharpe ratio range \nReference no. \nSharpe ratio \n[11], [15],[50],[58], [63], [65], \n[69],[72],[74] \n0.1-1 \n[11], [15],[63],[69],[72] \n1-2 \n[50] \n2-5 \n[58] \n5-10 \n[65],[74],[89] \n \nIt could be found that paper [65], [74],[89] performed best, which used DNN model, \nand Sharpe ratio was in the range of 5-10. Paper [58] also had a great performance, but \npaper [11], [15],[63], [69], [72] didnât have the high Sharpe ratio. \nAmong all the paper that used the Sharpe ratio, all CNN papers were in the range of \n0.1-1. The two DNN papers were in the range of 1-2 and 5-10. 50% of the Reinforcement \nlearning paper was in the range of 0.1-1, and 50% of the Reinforcement learning paper \nwas in the range of 2-5. 50% of the other deep learning method paper was in the range of \n0.1-1, and 50% of the other deep learning method paper was in the range of 5-10. \n \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n30 of 34 \n \n \n \n5.2.6 analysis based on the Return rate \nIn this part, the value of the return rate would be discussed. Table 21 showed the \ndetails of papersâ return rate. In this table, paper [11],[13],[15], [18] used CNN based \nmodel; paper [22] used LSTM based model; paper [49], [50] used DNN based model; pa-\nper [59], [60] used Reinforcement learning based model and paper [65], [68], [69], [70], \n[72], [74], [79] used other deep learning method. \nTable 21 Analysis based on the return rate \nReturn rate range \nReference no. \nReturn rate \n[11], [13],[15],[18], [22], [49], \n[50],[59], [60], [65],[68],[69],[70] \n1.0-1.2 \n[22], [49], [50],[60],[68],[69], [74] \n1.2-1.4 \n[11],[13],[15],[18] \n1.4-1.6 \n[65],[72],[79] \n1.6-1.8 \n[70] \n1.8-2.0 \n[59] \n \nIt could be found that paper [59] performed the best which used Reinforcement learn-\ning model, and the paper's return rate was in the range of 1.4-1.8. Paper [65] and [70] had \ngood performance but paper [22], [49], [50], [60], [68], [69], [74] didnât have the high return \nrate. \nAmong all the papers that used return rate as a performance measurement, all the \nCNN papers were in the range of 1.2-1.4, and the only LSTM paper was in the range of \n1.0-1.2, all the DNN papers were in the range of 1.0-1.2. 50% of the Reinforcement learning \npapers were in the range of 1.0-1.2, and 50% of the Reinforcement learning papers were \nin the range of 1.8-2. The other deep learning method papers performed well with 14% \npaper in the range of 1.0-1.2, 42% paper in the range of 1.4-1.6 , and 42% paper in the range \nof 1.6-1.8. \n \n6. Conclusions \nThis paper provided a detailed review of 88 papers from 2015 to the present on pre-\ndicting stock /Forex price movements through deep learning methods. The existing \nstock/Forex models were evaluated through analysing data sets, variables, the use of dif-\nferent models, and the metrics of evaluation. The research review included a wide range \nof techniques: CNN, LSTM, DNN, RNN, Reinforcement learning, and other deep learning \nmethods such as HAN, NLP, and Wavenet. Furthermore, the data sets, variables, models, \nand their different results were analysed and compared within each technique. Then our \npaper discusses the main performance metrics of all models. They are RMSE, MAPE, \nMAE, MSE, Accuracy, Sharpe ratio and Return rate. \nThis paper aimed to contribute to the research of stock/ Forex market prediction \nthrough the analysis of the above different deep learning prediction models. Through the \nreview, It can be identified that there is a lack of studies on the combination of multiple \ndeep learning methods, espically in respect to other deep learning methods. The hybrid \nnetworks are showing promising signs for future research. In the future, we would design \na specific hybrid model based on the above analysis, incorporating latest technology such \nas advanced genetic algorithms, self attention neural networks to predict the stock/Forex \nmarket. \nAuthor Contributions: First two authors contributed equally, MK conceived & designed the study \nsupervised the work and revised the manuscript.  \nFunding: This research received no external funding.  \nConflicts of Interest: The authors declare no conflict of interest. \nReferences \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n31 of 34 \n \n \n \n \n \n1. \n Tsai, C.-F. and Y.-C. Hsiao, Combining multiple feature selection methods for stock prediction: Union, intersection, and \nmulti-intersection approaches. Decision Support Systems, 2010. 50(1): p. 258-269. \n2. \n Nassirtoussi, A.K., et al., Text mining of news-headlines for FOREX market prediction: A Multi-layer Dimension Reduc-\ntion Algorithm with semantics and sentiment. Expert Systems with Applications, 2015. 42(1): p. 306-324. \n3. \n Akita, R., et al. Deep learning for stock prediction using numerical and textual information. in 2016 IEEE/ACIS 15th Inter-\nnational Conference on Computer and Information Science (ICIS). 2016. IEEE. \n4. \n Sirignano, J. and R. Cont, Universal features of price formation in financial markets: perspectives from deep learning. \nQuantitative Finance, 2019. 19(9): p. 1449-1459. \n5. \n Hu, B., et al. Convolutional neural network architectures for matching natural language sentences. in Advances in neural \ninformation processing systems. 2014. \n6. \n Sundermeyer, M., R. SchlÃ¼ter, and H. Ney. LSTM neural networks for language modeling. in Thirteenth annual conference \nof the international speech communication association. 2012. \n7. \n He, T. and J. Droppo. Exploiting LSTM structure in deep neural networks for speech recognition. in 2016 IEEE Interna-\ntional Conference on Acoustics, Speech and Signal Processing (ICASSP). 2016. IEEE. \n8. \n Maqsood, H., et al., A local and global event sentiment based efficient stock exchange forecasting using deep learning. \nInternational Journal of Information Management, 2020. 50: p. 432-451. \n9. \n Patil, P., et al. Stock Market Prediction Using Ensemble of Graph Theory, Machine Learning and Deep Learning Models. \nin Proceedings of the 3rd International Conference on Software Engineering and Information Management. 2020. \n10. \nSim, HS, H.I. Kim, and JJ Ahn, Is deep learning for image recognition applicable to stock market prediction? Complexity, \n2019. 2019. \n11. \nHoseinzade, E. and S. Haratizadeh, CNNpred: CNN-based stock market prediction using a diverse set of variables. Expert \nSystems with Applications, 2019. 129: p. 273-285. \n12. \nEapen, J., D. Bein, and A. Verma. Novel deep learning model with CNN and bi-directional LSTM for improved stock market \nindex prediction. in 2019 IEEE 9th annual computing and communication workshop and conference (CCWC). 2019. IEEE. \n13. \nYang, H., Y. Zhu, and Q. Huang. A multi-indicator feature selection for CNN-driven stock index prediction. in International \nconference on neural information processing. 2018. Springer. \n14. \nCai, S., et al. Financial News Quantization and Stock Market Forecast Research Based on CNN and LSTM. in International \nConference on Smart Computing and Communication. 2018. Springer. \n15. \nOncharoen, P. and P. Vateekul. Deep Learning Using Risk-Reward Function for Stock Market Prediction. in Proceedings \nof the 2018 2nd International Conference on Computer Science and Artificial Intelligence. 2018. \n16. \nLiu, Y., et al. Stock price movement prediction from financial news with deep learning and knowledge graph embedding. \nin Pacific Rim Knowledge Acquisition Workshop. 2018. Springer. \n17. \nSelvin, S., et al. Stock price prediction using LSTM, RNN and CNN-sliding window model. in 2017 international conference \non advances in computing, communications and informatics (icacci). 2017. IEEE. \n18. \nLiu, S., C. Zhang, and J. Ma. CNN-LSTM neural network model for quantitative strategy analysis in stock markets. in \nInternational Conference on Neural Information Processing. 2017. Springer. \n19. \nGudelek, M.U., S.A. Boluk, and A.M. Ozbayoglu. A deep learning based stock trading model with 2-D CNN trend detec-\ntion. in 2017 IEEE Symposium Series on Computational Intelligence (SSCI). 2017. IEEE. \n20. \nDing, X., et al. Deep learning for event-driven stock prediction. in Twenty-fourth international joint conference on artificial \nintelligence. 2015. \n21. \nNikou, M., G. Mansourfar, and J. Bagherzadeh, Stock price prediction using DEEP learning algorithm and its comparison \nwith machine learning algorithms. Intelligent Systems in Accounting, Finance and Management, 2019. 26(4): p. 164-174. \n22. \nFazeli, A. and S. Houghten. Deep Learning for the Prediction of Stock Market Trends. in 2019 IEEE International Conference \non Big Data (Big Data). 2019. IEEE. \n23. \nXu, Y. and V. Keselj. Stock Prediction using Deep Learning and Sentiment Analysis. in 2019 IEEE International Conference \non Big Data (Big Data). 2019. IEEE. \n24. \nLakshminarayanan, S.K. and J. McCrae, A Comparative Study of SVM and LSTM Deep Learning Algorithms for Stock \nMarket Prediction. 2019. \n25. \nRana, M., M.M. Uddin, and M.M. Hoque. Effects of Activation Functions and Optimisers on Stock Price Prediction using \nLSTM Recurrent Networks. in Proceedings of the 2019 3rd International Conference on Computer Science and Artificial \nIntelligence. 2019. \n26. \nNaik, N. and B.R. Mohan. Study of Stock Return Predictions Using Recurrent Neural Networks with LSTM. in International \nConference on Engineering Applications of Neural Networks. 2019. Springer. \n27. \nNguyen, D.H.D., L.P. Tran, and V. Nguyen. Predicting Stock Prices Using Dynamic LSTM Models. in International Con-\nference on Applied Informatics. 2019. Springer. \n28. \nLai, C.Y., R.-C. Chen, and R.E. Caraka. Prediction Stock Price Based on Different Index Factors Using LSTM. in 2019 Inter-\nnational Conference on Machine Learning and Cybernetics (ICMLC). 2019. IEEE. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n32 of 34 \n \n \n \n29. \nHossain, M.A., et al. Hybrid Deep Learning Model for Stock Price Prediction. in 2018 IEEE Symposium Series on Compu-\ntational Intelligence (SSCI). 2018. IEEE. \n30. \nBaek, Y. and H.Y. Kim, ModAugNet: A new forecasting framework for stock market index value with an overfitting pre-\nvention LSTM module and a prediction LSTM module. Expert Systems with Applications, 2018. 113: p. 457-480. \n31. \nKim, H.Y. and CH Won, Forecasting the volatility of stock price index: A hybrid model integrating LSTM with multiple \nGARCH-type models. Expert Systems with Applications, 2018. 103: p. 25-37. \n32. \nLi, H., Y. Shen, and Y. Zhu. Stock price prediction using attention-based multi-input LSTM. in Asian Conference on Ma-\nchine Learning. 2018. \n33. \nCheng, L.-C., Y.-H. Huang, and M.-E. Wu. Applied attention-based LSTM neural networks in stock prediction. in 2018 IEEE \nInternational Conference on Big Data (Big Data). 2018. IEEE. \n34. \nShah, D., W. Campbell, and F.H. Zulkernine. A Comparative Study of LSTM and DNN for Stock Market Forecasting. in \n2018 IEEE International Conference on Big Data (Big Data). 2018. IEEE. \n35. \nLin, B.-S., W.-T. Chu, and C.-M. Wang. Application of Stock Analysis Using Deep Learning. in 2018 7th International Con-\ngress on Advanced Applied Informatics (IIAI-AAI). 2018. IEEE. \n36. \nSkehin, T., M. Crane, and M. Bezbradica. Day ahead forecasting of FAANG stocks using ARIMA, LSTM networks and \nwavelets. 2018. CEUR Workshop Proceedings. \n37. \nZhang, X. and Y. Tan. Deep Stock Ranker: A LSTM Neural Network Model for Stock Selection. in International Conference \non Data Mining and Big Data. 2018. Springer. \n38. \nAchkar, R., et al. Comparison of BPA-MLP and LSTM-RNN for Stocks Prediction. in 2018 6th International Symposium on \nComputational and Business Intelligence (ISCBI). 2018. IEEE. \n39. \nZeng, Y. and X. Liu. A-Stock Price Fluctuation Forecast Model Based on LSTM. in 2018 14th International Conference on \nSemantics, Knowledge and Grids (SKG). 2018. IEEE. \n40. \nShao, X., et al. Short-term forecast of stock price of multi-branch LSTM based on K-means. in 2017 4th International Con-\nference on Systems and Informatics (ICSAI). 2017. IEEE. \n41. \nZhao, Z., et al. Time-weighted lstm model with redefined labeling for stock trend prediction. in 2017 ieee 29th international \nconference on tools with artificial intelligence (ictai). 2017. IEEE. \n42. \nNelson, D.M., A.C. Pereira, and RA de Oliveira. Stock market's price movement prediction with LSTM neural networks. in \n2017 International joint conference on neural networks (IJCNN). 2017. IEEE. \n43. \ndos Santos Pinheiro, L. and M. Dras. Stock market prediction with deep learning: A character-based neural language model \nfor event-based trading. in Proceedings of the Australasian Language Technology Association Workshop 2017.  \n44. \nBuczkowski, P. Predicting stock trends based on expert recommendations using gru/lstm neural networks. in International \nSymposium on Methodologies for Intelligent Systems. 2017. Springer. \n45. \nChen, K., Y. Zhou, and F. Dai. A LSTM-based method for stock returns prediction: A case study of China stock market. in \n2015 IEEE international conference on big data (big data). 2015. IEEE. \n46. \nSong, Y., J.W. Lee, and J. Lee, A study on novel filtering and relationship between input-features and target-vectors in a \ndeep learning model for stock price prediction. Applied Intelligence, 2019. 49(3): p. 897-911. \n47. \nNaik, N. and B.R. Mohan. Stock Price Movements Classification Using Machine and Deep Learning Techniques-The Case \nStudy of Indian Stock Market. in International Conference on Engineering Applications of Neural Networks. 2019. \nSpringer. \n48. \nChatzis, S.P., et al., Forecasting stock market crisis events using deep and statistical machine learning techniques. Expert \nSystems with Applications, 2018. 112: p. 353-371. \n49. \nAbe, M. and H. Nakayama. Deep learning for forecasting stock returns in the cross-section. in Pacific-Asia Conference on \nKnowledge Discovery and Data Mining. 2018. Springer. \n50. \nNakagawa, K., T. Uchida, and T. Aoshima. Deep factor model. in ECML PKDD 2018 Workshops. 2018. Springer. \n51. \nChong, E., C. Han, and F.C. Park, Deep learning networks for stock market analysis and prediction: Methodology, data \nrepresentations, and case studies. Expert Systems with Applications, 2017. 83: p. 187-205. \n52. \nSingh, R. and S. Srivastava, Stock prediction using deep learning. Multimedia Tools and Applications, 2017. 76(18): p. \n18569-18584. \n53. \nNi, L., et al., forecasting of forex time series data based on deep learning. Procedia computer science, 2019. 147: p. 647-652. \n54. \nLi, C., D. Song, and D. Tao. Multi-task recurrent neural networks and higher-order Markov random fields for stock price \nmovement prediction: Multi-task RNN and higer-order MRFs for stock price classification. in Proceedings of the 25th ACM \nSIGKDD International Conference on Knowledge Discovery & Data Mining. 2019. \n55. \nChen, W., et al., Leveraging social media news to predict stock index movement using RNN-boost. Data & Knowledge \nEngineering, 2018. 118: p. 14-24. \n56. \nZhang, R., Z. Yuan, and X. Shao. A New Combined CNN-RNN Model for Sector Stock Price Analysis. in 2018 IEEE 42nd \nAnnual Computer Software and Applications Conference (COMPSAC). 2018. IEEE. \n57. \nLi, Y., P. Ni, and V. Chang. An empirical research on the investment strategy of stock market based on deep reinforcement \nlearning model. in 4th International Conference on Complexity, Future Information Systems and Risk. 2019. SciTePress. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n33 of 34 \n \n \n \n58. \nShin, H.-G., I. Ra, and Y.-H. Choi. A Deep Multimodal Reinforcement Learning System Combined with CNN and LSTM \nfor Stock Trading. in 2019 International Conference on Information and Communication Technology Convergence (ICTC). \n2019. IEEE. \n59. \nJia, W., et al. Quantitative Trading on Stock Market Based on Deep Reinforcement Learning. in 2019 International Joint \nConference on Neural Networks (IJCNN). 2019. IEEE. \n60. \nCarapuÃ§o, J., R. Neves, and N. Horta, Reinforcement learning applied to Forex trading. Applied Soft Computing, 2018. 73: \np. 783-794. \n61. \nKang, Q., H. Zhou, and Y. Kang. An Asynchronous Advantage Actor-Critic Reinforcement Learning Method for Stock \nSelection and Portfolio Management. in Proceedings of the 2nd International Conference on Big Data Research. 2018. \n62. \nZhu, Y., et al. An Adaptive Box-Normalization Stock Index Trading Strategy Based on Reinforcement Learning. in Interna-\ntional Conference on Neural Information Processing. 2018. Springer. \n63. \nSi, W., et al. A multi-objective deep reinforcement learning approach for stock index future's intraday trading. in 2017 10th \nInternational symposium on computational intelligence and design (ISCID). 2017. IEEE. \n64. \nPastore, A., U. Esposito, and E. Vasilaki. Modelling stock-market investors as reinforcement learning agents. in 2015 IEEE \nInternational Conference on Evolving and Adaptive Intelligent Systems (EAIS). 2015. IEEE. \n65. \nLong, W., Z. Lu, and L. Cui, Deep learning-based feature engineering for stock price movement prediction. Knowledge-\nBased Systems, 2019. 164: p. 163-173. \n66. \nWu, J.-L., et al. A Deep Learning Model for Dimensional ValenceArousal Intensity Prediction in Stock Market. in 2019 IEEE \n10th International Conference on Awareness Science and Technology (iCAST). 2019. IEEE. \n67. \nCho, C.-H., et al. Toward Stock Price Prediction using Deep Learning. in Proceedings of the 12th IEEE/ACM International \nConference on Utility and Cloud Computing Companion. 2019. \n68. \nMinh, D.L., et al., Deep learning approach for short-term stock trends prediction based on two-stream gated recurrent unit \nnetwork. IEEE Access, 2018. 6: p. 55392-55404. \n69. \nHu, G., et al. Deep stock representation learning: from candlestick charts to investment decisions. in 2018 IEEE International \nConference on Acoustics, Speech and Signal Processing (ICASSP). 2018. IEEE. \n70. \nHu, Z., et al. Listening to chaotic whispers: A deep learning framework for news-oriented stock trend prediction. in Pro-\nceedings of the eleventh ACM international conference on web search and data mining. 2018. \n71. \nYiqi Zhao and Matloob Khushi. Wavelet Denoised-ResNet CNN and LightGBM Method to Predict Forex Rate of Change, \nin 2020 IEEE International Conference on Data Mining Workshops (ICDMW), Sorrento, Italy, 2020 \n72. \nTae Wan Kim and  Matloob Khushi. Portfolio Optimization with 2D Relative-Attentional Gated Transformer, in 2020 IEEE \nAsia-Pacific Conference on Computer Science and Data Engineering (CSDE), Gold Coast, Australia, 2020 \n73. \nZ. Zeng and M. Khushi, \"Wavelet Denoising and Attention-based RNN- ARIMA Model to Predict Forex Price,\" 2020 Inter-\nnational Joint Conference on Neural Networks (IJCNN), Glasgow, United Kingdom, 2020, pp. 1-7, doi: \n10.1109/IJCNN48605.2020.9206832.  \n74. \nZ. Zhang and M. Khushi, \"GA-MSSR: Genetic Algorithm Maximizing Sharpe and Sterling Ratio Method for RoboTrading,\" \n2020 International Joint Conference on Neural Networks (IJCNN), Glasgow, United Kingdom, 2020, pp. 1-8, doi: \n10.1109/IJCNN48605.2020.9206647. \n75. \nLing Qi,  Matloob Khushi and Josiah Poon. Event-Driven LSTM For Forex Price Prediction, in 2020 IEEE Asia-Pacific Con-\nference on Computer Science and Data Engineering (CSDE), Gold Coast, Australia, 2020Meng, TL; Khushi, M. Reinforce-\nment Learning in Financial Markets. Data 2019, 4, 110. \n76. \nChen, Sheng, and Hongxiang He. âStock Prediction Using Convolutional Neural Network.â IOP Conference Series: Mate-\nrials Science and Engineering, vol. 435, no. 1, 2018, p. 12026. \n77. \nGudelek, M. U., Boluk, S. A., & Ozbayoglu, A. M. (2017). A deep learning based stock trading model with 2-D CNN trend \ndetection. In 2017 IEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1â8). \n78. \nChen, Jou-Fan, et al. âFinancial Time-Series Data Analysis Using Deep Convolutional Neural Networks.â 2016 7th Interna-\ntional Conference on Cloud Computing and Big Data (CCBD), 2016, pp. 87â92. \n79. \nHu, Ziniu, et al. âListening to Chaotic Whispers: A Deep Learning Framework for News-Oriented Stock Trend Prediction.â \nProceedings of the Eleventh ACM International Conference on Web Search and Data Mining, 2018, pp. 261â269. \n80. \nPang, Xiong Wen, et al. âAn Innovative Neural Network Approach for Stock Market Prediction.â The Journal of Super-\ncomputing, vol. 76, no. 3, 2020, pp. 2098â2118. \n81. \nFeng, Fuli, et al. âTemporal Relational Ranking for Stock Prediction.â ACM Transactions on Information Systems, vol. 37, \nno. 2, 2019, pp. 1â30. \n82. \nChung, Hyejung, and Kyung-shik Shin. âGenetic Algorithm-Optimized Long Short-Term Memory Network for Stock Mar-\nket Prediction.â Sustainability, vol. 10, no. 10, 2018, p. 3765. \n83. \nLi, Jiahong, et al. âSentiment-Aware Stock Market Prediction: A Deep Learning Method.â 2017 International Conference \non Service Systems and Service Management, 2017, pp. 1â6. \n84. \nZhang, Kang, et al. âStock Market Prediction Based on Generative Adversarial Network.â Procedia Computer Science, vol. \n147, 2019, pp. 400â406. \nAppl. Syst. Innov. 2021, 4, x FOR PEER REVIEW \n34 of 34 \n \n \n \n85. \nZhong, X., and David Lee Enke. âPredicting the Daily Return Direction of the Stock Market Using Hybrid Machine Learn-\ning Algorithms.â Financial Innovation, vol. 5, no. 1, 2019, pp. 1â20. \n86. \nShi, Lei, et al. âDeepClue: Visual Interpretation of Text-Based Deep Stock Prediction.â IEEE Transactions on Knowledge \nand Data Engineering, vol. 31, no. 6, 2019, pp. 1094â1108. \n87. \nYu, Pengfei, and Xuesong Yan. âStock Price Prediction Based on Deep Neural Networks.â Neural Computing and Appli-\ncations, vol. 32, no. 6, 2020, pp. 1609â1628. \n88. \nSouma, Wataru, et al. âEnhanced News Sentiment Analysis Using Deep Learning Methods.â Journal of Computational \nSocial Science, vol. 2, no. 1, 2019, pp. 33â46. \n89. \nYong, Bang Xiang, et al. âA Stock Market Trading System Using Deep Neural Network.â Asian Simulation Conference, \n2017, pp. 356â364. \n90. \nWen, Min, et al. âStock Market Trend Prediction Using High-Order Information of Time Series.â IEEE Access, vol. 7, 2019, \npp. 28299â28308. \n91. \nJin, Zhigang, et al. âStock Closing Price Prediction Based on Sentiment Analysis and LSTM.â Neural Computing and Ap-\nplications, vol. 32, no. 13, 2020, pp. 9713â9729. \n92. \nLong, Jiawei, et al. âAn Integrated Framework of Deep Learning and Knowledge Graph for Prediction of Stock Price Trend: \nAn Application in Chinese Stock Exchange Market.â Applied Soft Computing, vol. 91, 2020, p. 106205. \n93. \nChen, Mu-Yen, et al. âModeling Public Mood and Emotion: Stock Market Trend Prediction with Anticipatory Computing \nApproach.â Computers in Human Behavior, vol. 101, 2019, pp. 402â408. \n94. \nQian, Fei, and Xianfu Chen. âStock Prediction Based on LSTM under Different Stability.â 2019 IEEE 4th International Con-\nference on Cloud Computing and Big Data Analysis (ICCCBDA), 2019. \n95. \nLi, Zhixi, and Vincent Tam. âCombining the Real-Time Wavelet Denoising and Long-Short-Term-Memory Neural Network \nfor Predicting Stock Indexes.â 2017 IEEE Symposium Series on Computational Intelligence (SSCI), 2017, pp. 1â8. \n",
  "categories": [
    "q-fin.ST"
  ],
  "published": "2021-03-13",
  "updated": "2021-03-13"
}