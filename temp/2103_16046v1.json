{
  "id": "http://arxiv.org/abs/2103.16046v1",
  "title": "Unsupervised Hyperbolic Representation Learning via Message Passing Auto-Encoders",
  "authors": [
    "Jiwoong Park",
    "Junho Cho",
    "Hyung Jin Chang",
    "Jin Young Choi"
  ],
  "abstract": "Most of the existing literature regarding hyperbolic embedding concentrate\nupon supervised learning, whereas the use of unsupervised hyperbolic embedding\nis less well explored. In this paper, we analyze how unsupervised tasks can\nbenefit from learned representations in hyperbolic space. To explore how well\nthe hierarchical structure of unlabeled data can be represented in hyperbolic\nspaces, we design a novel hyperbolic message passing auto-encoder whose overall\nauto-encoding is performed in hyperbolic space. The proposed model conducts\nauto-encoding the networks via fully utilizing hyperbolic geometry in message\npassing. Through extensive quantitative and qualitative analyses, we validate\nthe properties and benefits of the unsupervised hyperbolic representations.\nCodes are available at https://github.com/junhocho/HGCAE.",
  "text": "Unsupervised Hyperbolic Representation Learning\nvia Message Passing Auto-Encoders\nJiwoong Park*1\nJunho Cho*1\nHyung Jin Chang2\nJin Young Choi1\n1ASRI, Dept. of ECE., Seoul National University\n2School of Computer Science, University of Birmingham\n{ptywoong,junhocho,jychoi}@snu.ac.kr, h.j.chang@bham.ac.uk\nAbstract\nMost of the existing literature regarding hyperbolic em-\nbedding concentrate upon supervised learning, whereas the\nuse of unsupervised hyperbolic embedding is less well ex-\nplored. In this paper, we analyze how unsupervised tasks\ncan beneﬁt from learned representations in hyperbolic\nspace. To explore how well the hierarchical structure of un-\nlabeled data can be represented in hyperbolic spaces, we\ndesign a novel hyperbolic message passing auto-encoder\nwhose overall auto-encoding is performed in hyperbolic\nspace. The proposed model conducts auto-encoding the\nnetworks via fully utilizing hyperbolic geometry in mes-\nsage passing. Through extensive quantitative and qualita-\ntive analyses, we validate the properties and beneﬁts of the\nunsupervised hyperbolic representations. Codes are avail-\nable at https://github.com/junhocho/HGCAE.\n1. Introduction\nA fundamental problem of machine learning is learning\nuseful representations from high-dimensional data. There\nare many supervised representation learning methods which\nachieve good performances for downstream tasks [31, 28,\n36, 69] on several data domains such as images and graphs.\nIn recent years, with the success of deep learning, various\nlarge-scale real-world datasets have been collated [31, 30,\n65, 57]. However, the larger these datasets and the closer\nthey are to the real world, the expense and effort required to\nlabel the data increases proportionally. Thus, unsupervised\nrepresentation learning is an increasingly viable approach\nto extract useful representation from real-world datasets.\nRecently, many works [45, 46, 16, 21, 7, 1, 24] utilize\nhyperbolic geometry [29] to learn representations by under-\nstanding the underlying nature of the data domains. It is well\nknown that complex networks contain latent hierarchies be-\ntween large groups and the divided subgroups of nodes, and\n*equally contributed.\ncan be approximated as trees that grow exponentially with\ntheir depth [29]. Based on this fact, previous works which\ninvolve graphs [5, 44, 45, 46, 16, 42] showed the effective-\nness of learning representation using hyperbolic spaces (a\ncontinuous version of trees) where distances increase expo-\nnentially when moving away from the origin. More recently,\nworks [7, 33, 1] have been conducted which learn more\npowerful representations via conducting message passing\n(graph convolution) [17, 28, 63] in hyperbolic spaces.\nIn addition, it has been successfully shown that grafting\nhyperbolic geometry onto computer vision tasks is promis-\ning [24]. They observed a high degree of hyperbolicity\n[15] in the activations of image datasets obtained from pre-\ntrained convolutional networks. Also, it has been shown\nthat the hyperbolic distance between learned embeddings\nand the origin of the Poincar´e ball could be considered as a\nmeasurement of the model’s conﬁdence. Using these analy-\nses, [24] added a single layer of hyperbolic neural networks\n[16] to deep convolutional networks and showed the bene-\nﬁts of hyperbolic embeddings on few-shot learning and per-\nson re-identiﬁcation. Another work [34] also demonstrated\nthe suitability of hyperbolic embeddings on zero-shot learn-\ning. However, most of the existing hyperbolic representa-\ntion learning works [24, 34, 7, 33, 1] mainly focus on a su-\npervised setting, and the effect of hyperbolic geometry on\nunsupervised representation learning has not been explored\ndeeply so far [38, 20, 42].\nIn this paper, we explore the beneﬁts of hyperbolic ge-\nometry to carry out unsupervised representation learning\nupon various data domains. Our motivation is to learn high-\nquality node embeddings of the graphs that are hierarchical\nand tree-like without supervision via considering the geom-\netry of the embedding space. To do so, we present a novel\nhyperbolic graph convolutional auto-encoder (HGCAE) by\ncombining hyperbolic geometry and message passing [17].\nEvery layer of HGCAE performs message passing in the hy-\nperbolic space and its corresponding tangent space where\ncurvature values can be trained. This is primarily in con-\ntrast to the Poincar´e variational auto-encoder (P-VAE) [38]\nwhose latent space is the Poincar´e ball and conducts mes-\n1\narXiv:2103.16046v1  [cs.LG]  30 Mar 2021\nsage passing in Euclidean space. The HGCAE conducts\nauto-encoding the graphs from diverse data domains, such\nas images or social networks, in the hyperbolic space such\nas the Poincar´e ball and hyperboloid. To fully utilize hy-\nperbolic geometry for representation learning, we adopt a\ngeometry-aware attention mechanism [21] when conduct-\ning message passing. Through extensive experiments and\nanalyses using the learned representation in the hyperbolic\nlatent spaces, we present the following observations on hi-\nerarchically structured data:\n• The proposed auto-encoder, which combines message\npassing based on geometry-aware attention and hyper-\nbolic spaces, can learn useful representations for down-\nstream tasks. On various networks, the proposed method\nachieves state-of-the-art results on node clustering and\nlink prediction tasks.\n• Image clustering tasks can beneﬁt from embeddings in\nhyperbolic latent spaces. We achieve comparable results\nto state-of-the-art image clustering results by learning\nrepresentations from the activations of neural networks.\n• Hyperbolic embeddings of images, the results of unsuper-\nvised learning, can recognize the underlying data struc-\ntures such as a class hierarchy without any supervision of\nground-truth class hierarchy.\n• We show that the sample’s hyperbolic distance from the\norigin in hyperbolic space can be utilized as a criterion to\nchoose samples, therefore improving the generalization\nability of a model for a given dataset.\n2. Related Works\nHyperbolic embedding of images. Khrulkov et al. [24]\nvalidated hyperbolic embeddings of images via measur-\ning the degree of hyperbolicity of image datasets. Many\ndatasets such as CIFAR10/100 [30], CUB [65] and MiniIm-\nageNet [51] showed high degrees of hyperbolicity. In par-\nticular, the ImageNet dataset [54] is organized by following\nthe hierarchical structure of WordNet [41]. These observa-\ntions suggest that hyperbolic geometry can be beneﬁcial in\nanalyzing image manifolds by capturing not only semantic\nsimilarities but also hierarchical relationships between im-\nages. Furthermore, Khrulkov et al. [24] empirically showed\nthat the distance between the origin and the image embed-\ndings in the Poincar´e ball can be regarded as the measure of\nmodel’s conﬁdence. They observed that the samples which\nare easily classiﬁed are located near the boundary while\nthose more ambiguous samples lie near the origin of the hy-\nperbolic space. Recent works of hyperbolic image embed-\ndings [24, 34] add one or two layers of hyperbolic layers\n[16] after an Euclidean convolutional network.\nGraph auto-encoding via hyperbolic geometry. Some re-\ncent works [20, 38, 59] attempted to auto-encode graphs\nin hyperbolic space. Their models attempted to learn latent\nrepresentations in the hyperbolic space via grafting hyper-\nbolic geometry onto a variational auto-encoder model [26].\n[20, 38] encoded the node representation via message pass-\ning [28] in Euclidean space, then the encoded representation\nwas projected onto the hyperbolic space. Similar to these\nconcurrent models, our auto-encoder framework learns la-\ntent node representations of the graph in hyperbolic latent\nspaces. Differing from these models, our work considers\nhyperbolic geometry throughout the auto-encoding process.\nEach encoder and decoder layer of the proposed model con-\nducts message passing by utilizing geometry-aware atten-\ntion in the hyperbolic space and its tangent space.\n3. Hyperbolic Geometry\nA real, smooth manifold M is a set of points x, that\nis locally similar to linear space. At each point x ∈M,\nthe tangent space at x, TxM, is a real vector space whose\ndimensionality is same as M. A Riemannian manifold is\ndeﬁned as a tuple (M, g) that is possessing metric tensor\ngx : TxM × TxM →R on the tangent space TxM at\neach point x ∈M [49]. The metric tensor provides geo-\nmetric notions such as geodesic, angle and volume. There\nexist mapping between the manifold and the tangent space:\nexponential map and logarithmic map. The exponential map\nexpx : TxM →M projects the vector on the tangent space\nTxM back to the manifold M, while the logarithmic map\nlogx : M →TxM is the inverse mapping of the exponen-\ntial map as logx(expx(v)) = v.\nThe hyperbolic space is a Riemannian manifold with\nconstant negative sectional curvature equipped with hy-\nperbolic geometry. This paper deals with two hyperbolic\nspaces; ‘Poincar´e ball’ and ‘hyperboloid’. The Poincar´e\nball P is highly effective for visualizing and analyzing the\nhyperbolic latent space. Meanwhile, the hyperboloid H can\nprovide stable optimization since, unlike distance function\nof Poincar´e ball, there is no division in the distance func-\ntion [46]. A review of Riemannian geometry and details of\nhyperboloid model are presented in the supplementary ma-\nterial.\nPoincar´e ball. The n-dimensional Poincar´e ball with con-\nstant negative curvature K(K < 0) (Pn\nK, gPK\nx ) is deﬁned:\nPn\nK = {x ∈Rn : ∥x∥2 < −1/K},\n(1)\nwhere ∥· ∥denotes Euclidean norm. The metric tensor is\ngPK\nx\n= (λK\nx )2gE\nx, where λK\nx =\n2\n1+K∥x∥2 is the conformal\nfactor and gE\nx = diag([1, 1, . . . 1]) denotes Euclidean met-\nric tensor. The origin of Pn\nK is o = (0, . . . , 0) ∈Rn. The\ndistance between two points x, y ∈Pn\nK is deﬁned as\ndPn\nK(x, y) =\n1\n√\n−K arcosh\n\u0012\n1 −\n2K∥x −y∥2\n(1 + K∥x∥2)(1 + K∥y∥2)\n\u0013\n.\n(2)\n2\nFigure 1: The overall architecture of HGCAE in a two-layer auto-encoder (i.e. the encoder and decoder have two layers each)\nwhose hyperbolic space is hyperboloid. This ﬁgure describes three things: 1) how the node of the graph (red dot) conducts\nmessage passing (Eq. (8) and (11)) with its neighbors (yellow dot), 2) the process of embedding the output of encoder in\nhyperboloid latent space (blue-purple space), and 3) reconstruction of Euclidean node attributes at the end of the decoder.\nFor points x ∈Pn\nK, tangent vector v ∈TxPn\nK, and y ̸= 0,\nthe exponential map expx : TxPn\nK →Pn\nK and the logarith-\nmic map logx : Pn\nK →TxPn\nK are deﬁned as:\nexpK\nx (v) = x ⊕K\n\u0012\ntanh(\n√\n−KλK\nx ∥v∥\n2\n)\nv\n√\n−K∥v∥\n\u0013\n,\n(3)\nlogK\nx (y) =\n2\n√\n−KλK\nx\narctanh\n\u0010√\n−K∥u∥\n\u0011\nu\n∥u∥,\n(4)\nwhere u = −x⊕K y and ⊕K denotes M¨obius addition [62]\nfor x, y ∈Pn\nK as\nx ⊕K y = (1 −2K⟨x, y⟩−K∥y∥2)x + (1 + K∥x∥2)y\n1 −2K⟨x, y⟩+ K2∥x∥2∥y∥2\n. (5)\nMapping between two models. Two hyperbolic models,\nPoincar´e ball and hyperboloid, are equivalent and transfor-\nmations between two models retain many geometric proper-\nties including isometry. There exist diffeomorphisms pH→P\nand pP→H between the two models, Poincar´e ball Pn\nK and\nhyperboloid Hn\nK [33, 7], as follows:\npH→P(x0, x1, . . . , xn) = (x1, . . . , xn)\np\n|K|x0 + 1\n,\n(6)\npP→H(x1, . . . , xn) =\n(\n1\n√\n|K|(1 −K∥x∥2), 2x1, . . . , 2xn)\n1 + K∥x∥2\n.\n(7)\n4. Methodology\nHGCAE is designed to fully utilize hyperbolic geome-\ntry in the auto-encoding process along with leveraging the\npower of graph convolutions via geometry-aware attention\nmechanism. Each layer conducts message passing in hyper-\nbolic space whose curvature value is trainable. Before con-\nducting message passing, we need to map the given input\ndata points, xEuc, deﬁned in Euclidean space to the hyper-\nbolic manifold. We map the Euclidean feature into hyper-\nbolic manifold via h1\ni = expK1\no (xEuc\ni\n), where K1 and h1\ni\ndenote a trainable curvature value and the i-th node’s repre-\nsentation of the ﬁrst layer respectively. When the hyperbolic\nspace is hyperboloid model, we use (0, xEuc) ∈Rn+1 as an\ninput of an exponential map as [7] did. The overall architec-\nture of HGCAE is presented in Fig. 1.\n4.1. Geometry-Aware Message Passing\nLinear transformation. Message passing in the HGCAE\nconsists of two steps: the linear transformation of a message\nand aggregating messages from neighbors. The i-th node’s\nmessage passing result at the l-th layer zl\ni is as follows:\nzl\ni = expKl\no\n\nX\nj∈N(i)\nαl\nij\n\u0010\nW l logKl\no (hl\nj) + bl\u0011\n\n,\n(8)\nwhere W l, bl, N(i), and αl\nij denote a weight matrix, a bias\nterm, the set of direct neighbors of node i including itself,\nand the relative importance (attention score) of the neigh-\nbor node j to the node i at the l-th layer respectively. Based\non [16], we map the points in the hyperbolic manifold to\nthe tangent space via the logarithmic map, since the linear\ntransformation cannot be performed directly in hyperbolic\nspaces. Then, the messages are linearly transformed on the\ntangent space of the origin in which inherits many proper-\nties of the ambient Euclidean space.\nAggregation. After performing linear transformation, we\naggregate messages from neighbors via an attention mech-\nanism. The majority of message passing algorithms which\nuse attention mechanisms learn the relative importance of\neach node’s neighbors based on node feature not only in\nEuclidean space [63] but also in hyperbolic space [7]. How-\never, only considering node features for learning their rel-\native importance does not take into account the geometry\nof the space, and this might result in an imprecise atten-\ntion score. To make full use of the Riemannian metric of\nthe hyperbolic manifolds, we adopt a geometry-aware at-\ntention mechanism [21] by utilizing the distance between\n3\nlinearly transformed node features on the hyperbolic space.\nLet yl\ni = W l logKl\no (hl\ni) + bl, then the attention score at the\nl-th layer in Eq. (8) is:\nαl\nij =\nexp(−βld2\nMKl (yl\ni, yl\nj) −γl)\nP\np∈N(i) exp(−βld2\nMKl (yl\ni, ylp) −γl),\n(9)\nwhere dMKl (·, ·), βl, and γl denote the distance on the hy-\nperbolic space with curvature value Kl, and trainable pa-\nrameters of the l-th layer respectively. After every step of\nmessage passing, we map the representation on the tangent\nspace to the hyperbolic manifold via the exponential map.\n4.2. Nonlinear Activation\nThe nonlinear activations, σ, such as ReLU can be di-\nrectly applied to the points in the Poincar´e ball, in contrast\nto the points on the hyperboloid [33]. Thus, when the hy-\nperboloid model is used, we map the points to the Poincar´e\nball using Eq. (6) ﬁrst. Next, we apply the nonlinear acti-\nvation in the Poincar´e ball, and then return the result to the\nhyperboloid using the Eq. (7).\nSince the curvature value of each layer in HGCAE is\ntrainable, each layer can have different curvature values\nfrom other layers. Thus, a step for locating the result of the\nnonlinear activation in the hyperbolic space having a curva-\nture value of the next layer is required. First, we map the\nresults of the nonlinear activation to the tangent space of\nthe current layer, ToMKl, using logarithmic map, logKl\no .\nNext, the points in the tangent space are mapped to the next\nlayer’s hyperbolic space via an exponential map of the next\nlayer expKl+1\no\n. The equations for performing such nonlin-\near activation and mapping to the hyperbolic space of the\nnext layer in the cases of Poincar´e ball and hyperboloid are\nas follows respectively:\nhl+1\ni\n= exp\nKl+1\no\n\u0010\nlogKl\no\n\u0000σ(zl\ni)\n\u0001\u0011\n,\n(10)\nhl+1\ni\n= exp\nKl+1\no\n\u0010\nlogKl\no\n\u0000pP→H(σ(pH→P(zl\ni)))\n\u0001\u0011\n.\n(11)\n4.3. Loss Function\nOur HGCAE reconstructs both the afﬁnity matrix (graph\nstructure) A and the Euclidean node attributes XEuc, at the\nend of the encoder and the decoder respectively. To recon-\nstruct the Euclidean node attributes ˆXEuc, the aggregated\nrepresentations in the hyperbolic space of the decoder’s\nlast layer are mapped to the tangent space of the origin\nToM. Then, the loss of representations LREC−X is de-\nﬁned as the mean square error between XEuc and ˆXEuc:\n1\nN ∥XEuc −ˆXEuc∥2. For reconstructing the structure of\nthe graph, the hyperbolic distance between the latent rep-\nresentations (the output of the encoder) of two nodes is uti-\nlized. To calculate the probability score of an edge which\nlinks between two nodes, we adopt the Fermi-Dirac distri-\nbution [29, 45], ˆAij = [e(d2\nMK (hi,hj)−r)/t + 1]−1, where\nTable 1: Dataset statistics.\nDataset\nNode\nEdge\nAttribute\nClass\nPhylogenetic [22, 56]\n344\n343\n-\n-\nCS PhDs [13]\n1,025\n1,043\n-\n-\nDiseases [18, 53]\n516\n1,188\n-\n-\nCora [57]\n2,708\n5,429\n1,433\n7\nCiteseer [57]\n3,312\n4,552\n3,703\n6\nWiki [70]\n2,405\n17,981\n4,973\n17\nPubmed [57]\n19,717\n44,338\n500\n3\nBlogCatalog [60]\n5,196\n171,743\n8,189\n6\nAmazon Photo [39]\n7,650\n119,081\n745\n8\nImageNet-10 [9]\n13,000\n-\n27,648\n10\nImageNet-Dogs [9]\n19,500\n-\n27,648\n15\nImageNet-BNCR\n11,700\n-\n27,648\n9\nhi, ˆA, r, and t denote the latent representation of node i,\nthe reconstructed afﬁnity matrix, and hyperparameters re-\nspectively. The loss function for the afﬁnity matrix is de-\nﬁned by the cross entropy loss with negative sampling:\nLREC−A = Eq(H|X,A)[log p( ˆA|H)], where q(H|X, A) =\nQN\ni=1 q(hi|X, A). The overall loss function of HGCAE is\nL = LREC−A + λLREC−X,\n(12)\nwhere λ is a regularization parameter. λ serves to control\nthe relative importance between the attributes and structure.\n5. Experiments\nIn this section, we explore the effectiveness of unsuper-\nvised hyperbolic embeddings on various data domains via\nquantitative and qualitative analyses. We use 9 real-world\ncomplex network datasets and 3 image datasets. The statis-\ntics of the datasets are summarized in Table 1. The details\nof the datasets, the compared methods, and the experimen-\ntal details are described in the supplementary material. For\nnode clustering and link prediction tasks on the 9 network\ndatasets, we evaluate HGCAE-P and HGCAE-H, which de-\nnote HGCAE models whose latent spaces are Poincar´e ball\nand hyperboloid respectively. For the tasks of image clus-\ntering and visual data analysis, we use HGCAE-P because\nPoincar´e ball is a powerful tool for visualizing and analyz-\ning properties of hyperbolic visual embeddings.\n5.1. Node Clustering and Link Prediction\nComparison to embeddings in Euclidean latent space.\nWe evaluated the usefulness of hyperbolic representations\nby the performances of downstream tasks on citation [57,\n70], social [60], and co-purchase [39] networks. We com-\npared against the state-of-the-art unsupervised message\npassing models [27, 47, 66, 48, 76] which mainly conduct\nin Euclidean space. Similar to evaluation metrics used in\n[48], we used area under curve (AUC) and average preci-\nsion (AP) to evaluate the performance of the link prediction\ntask, while using accuracy (ACC) and normalized mutual\ninformation (NMI) for evaluating the node clustering task.\n4\nTable 2: Link prediction performances.\nCora\nCiteseer\nWiki\nPubmed\nBlogCatalog\nAmazon Photo\nAUC\nAP\nAUC\nAP\nAUC\nAP\nAUC\nAP\nAUC\nAP\nAUC\nAP\nGAE [27]\n0.910\n0.920\n0.895\n0.899\n0.930\n0.948\n0.964\n0.965\n0.840\n0.841\n0.956\n0.948\nVGAE [27]\n0.914\n0.926\n0.908\n0.920\n0.936\n0.950\n0.944\n0.947\n0.844\n0.846\n0.971\n0.966\nARGA [47]\n0.924\n0.932\n0.919\n0.930\n0.934\n0.947\n0.968\n0.971\n0.857\n0.850\n0.961\n0.954\nARVGA [47]\n0.924\n0.926\n0.924\n0.930\n0.947\n0.948\n0.965\n0.968\n0.837\n0.828\n0.927\n0.909\nGALA [48]\n0.929\n0.937\n0.944\n0.948\n0.936\n0.931\n0.915\n0.897\n0.774\n0.765\n0.918\n0.910\nDBGAN [76]\n0.945\n0.951\n0.945\n0.958\n-\n-\n0.968\n0.973\n-\n-\n-\n-\nHGCAE-P\n0.948\n0.947\n0.960\n0.963\n0.955\n0.962\n0.962\n0.960\n0.896\n0.886\n0.982\n0.976\nHGCAE-H\n0.956\n0.955\n0.967\n0.970\n0.952\n0.958\n0.962\n0.960\n0.857\n0.850\n0.972\n0.966\nTable 3: Node clustering performances.\nCora\nCiteseer\nWiki\nPubmed\nBlogCatalog\nAmazon Photo\nACC\nNMI\nACC\nNMI\nACC\nNMI\nACC\nNMI\nACC\nNMI\nACC\nNMI\nKmeans [35]\n0.492\n0.321\n0.540\n0.305\n0.417\n0.440\n0.595\n0.315\n0.180\n0.007\n0.267\n0.122\nGAE [27]\n0.532\n0.434\n0.505\n0.246\n0.460\n0.468\n0.686\n0.295\n0.284\n0.112\n0.390\n0.337\nVGAE [27]\n0.595\n0.446\n0.467\n0.260\n0.450\n0.467\n0.688\n0.310\n0.269\n0.097\n0.418\n0.376\nMGAE [66]\n0.684\n0.511\n0.660\n0.412\n0.514\n0.485\n0.593\n0.282\n0.423\n0.202\n0.594\n0.475\nARGA [47]\n0.640\n0.449\n0.573\n0.350\n0.458\n0.437\n0.680\n0.275\n0.464\n0.270\n0.577\n0.499\nARVGA [47]\n0.638\n0.450\n0.544\n0.261\n0.386\n0.338\n0.513\n0.116\n0.450\n0.250\n0.455\n0.395\nGALA [48]\n0.745\n0.576\n0.693\n0.441\n0.544\n0.503\n0.693\n0.327\n0.400\n0.251\n0.512\n0.485\nDBGAN [76]\n0.748\n0.560\n0.670\n0.407\n-\n-\n0.694\n0.324\n-\n-\n-\n-\nHGCAE-P\n0.746\n0.572\n0.693\n0.422\n0.459\n0.467\n0.748\n0.377\n0.550\n0.325\n0.781\n0.696\nHGCAE-H\n0.767\n0.599\n0.715\n0.453\n0.530\n0.435\n0.711\n0.347\n0.741\n0.578\n0.817\n0.722\nTable 4: Link prediction task compared with P-VAE.\nPhylogenetic\nCS PhDs\nDiseases\nAUC\nAP\nAUC\nAP\nAUC\nAP\nVGAE [27]\n0.542\n0.540\n0.565\n0.564\n0.898\n0.918\nP-VAE [38]\n0.590\n0.555\n0.598\n0.567\n0.923\n0.936\nHGCAE-P\n0.688\n0.712\n0.673\n0.640\n0.926\n0.914\nThe results of link prediction and node clustering are pre-\nsented in Tables 2 and 3 respectively. From the results, we\ncan see that our HGCAE, with the representations of hy-\nperbolic latent spaces, outperforms the existing methods,\nwhich use Euclidean latent spaces. Our superior results over\ntheir Euclidean counterparts support the fact that unsuper-\nvised learning with message passing beneﬁt from the geom-\netry of hyperbolic spaces. Due to space constraints, further\nanalysis of the ablation study on the proposed architecture\nand the effectiveness of low-dimensional hyperbolic latent\nspace are reported in the supplementary material.\nComparison to embeddings of hyperbolic graph auto-\nencoder. To validate the architecture of HGCAE, we com-\npared its performance with the Poincar´e variational auto-\nencoder (P-VAE) [38], whose latent space is the Poincar´e\nball and conducts its message passing in Euclidean space.\nThree networks, phylogenetic tree [22, 56], Ph.D. advisor-\nstudent relationships [13], and disease relationships [18,\n53], were used for evaluating performance on link predic-\ntion. The latent space of both P-VAE and HGCAE-P is a\n5-dimensional Poincar´e ball. We report the results in Table\n4. The proposed HGCAE-P outperforms P-VAE for most\ncases of the datasets since HGCAE-P considers hyperbolic\ngeometry in the whole auto-encoding processes.\nVisualization of citation network. We explored the la-\nGAE\nHGCAE-P\nHGCAE-H\nFigure 2: 2-dimensional embeddings in Euclidean, Poincar´e\nball, and hyperboloid latent space on Cora dataset. Same\ncolor indicates same class. On hyperbolic latent spaces,\nmost of the nodes are located on the boundary and well-\nclustered with the nodes in the same class.\ntent representations of GAE [27] and our models on the\nCora dataset [57] by constraining the latent space as a 2-\ndimensional hyperbolic or Euclidean space. The result is\ngiven in Fig. 2. On the results of HGCAE, most of the nodes\nare located on the boundary of hyperbolic spaces and well-\nclustered with the nodes in the same class. Further visual-\nization of the network datasets is presented in the supple-\nmentary material.\n5.2. Image Clustering\nIn this experiment, we illustrate that image clustering\ncan beneﬁt from hyperbolic geometry. The training sets of\nImageNet-10 and ImageNet-Dogs [9], which are subsets of\nImageNet [31], are used for evaluation. In the manner of the\nresearches [16, 21, 24] which impose hyperbolic geometry\non the activations of neural networks, we used the activa-\ntions of PICA [23], one of the most recent models devel-\n1http://image-net.org/index\n5\nArtifact\nPlant part\nAirship\nAirliner\nContainer \nship\nSports \ncar\nTrailer \ntruck\nSoccer \nball\nOrange\nMaltese \ndog\nSnow \nleopard\nKing \npenguin\nConveyance\nInstrumentality\nVehicle\nEquipment\nEdible fruit\nCitrus\nNatural object\nAnimal\nPlant organ\nReproductive \nstructure\nFruit\nGame \nequipment\nBall\nCraft\nWheeled \nvehicle\nAircraft\nSelf-propelled \nvehicle\nMotor \nvehicle\nHeavier-\nthan-air \ncraft\nAirplane\nTruck\nCar\nVessel\nShip\nCargo-\nship\nChordate\nVertebrate\nMammal\nBird\nPlacental\nAquatic bird\nCarnivore\nCanine\nFeline\nToy dog\nBig cat\nSea bird\nSphenisciform \nseabird\nPenguin\nDog\nLighter-\nthan-air \ncraft\n(a) ImageNet-10\nArtifact\nPlant part\nDogsled\nAmbulance\nSchool \nbus\nGranny \nSmith\nBald \neagle\nFlamingo\nLionfish\nConveyance\nInstrumentality\nVehicle\nPublic \ntransport\nEdible fruit\nCitrus\nNatural object\nAnimal\nPlant organ\nReproductive \nstructure\nFruit\nWheeled \nvehicle\nSelf-propelled \nvehicle\nMotor \nvehicle\nCar\nChordate\nVertebrate\nBird\nAquatic \nbird\nWading \nbird\nSpiny-finned \nfish\nEagle\nJackfruit\nLemon\nSled\nBus\nApple\nEating \napple\nBird of \nprey\nFish\nBony fish\nTeleost fish\nScorpaenoid\nScorpaenid\nAquatic \nvertebrate\n(b) ImageNet-BNCR\nFigure 3: Class hierarchy of ImageNet-10 and ImageNet-BNCR1.\nTable 5: Image clustering performances.\nImageNet-10\nImageNet-Dogs\nACC\nNMI\nARI\nACC\nNMI\nARI\nKmeans [35]\n0.241\n0.119\n0.057\n0.105\n0.055\n0.020\nSC [74]\n0.274\n0.151\n0.076\n0.111\n0.038\n0.013\nAC [19]\n0.242\n0.138\n0.067\n0.139\n0.037\n0.021\nNMF [6]\n0.230\n0.132\n0.065\n0.118\n0.044\n0.016\nAE [3]\n0.317\n0.210\n0.152\n0.185\n0.104\n0.073\nCAE [37]\n0.253\n0.134\n0.068\n0.134\n0.059\n0.022\nSAE [43]\n0.325\n0.212\n0.174\n0.183\n0.112\n0.072\nDAE [64]\n0.304\n0.206\n0.138\n0.190\n0.104\n0.078\nDCGAN [50]\n0.346\n0.225\n0.157\n0.174\n0.121\n0.078\nDeCNN [73]\n0.313\n0.186\n0.142\n0.175\n0.098\n0.073\nSWWAE [75]\n0.323\n0.176\n0.160\n0.158\n0.093\n0.076\nVAE [26]\n0.334\n0.193\n0.168\n0.179\n0.107\n0.079\nJULE [71]\n0.300\n0.175\n0.138\n0.138\n0.054\n0.028\nDEC [68]\n0.381\n0.282\n0.203\n0.195\n0.122\n0.079\nDAC [9]\n0.527\n0.394\n0.302\n0.275\n0.219\n0.111\nDDC [8]\n0.577\n0.433\n0.345\n-\n-\n-\nDCCM [67]\n0.710\n0.608\n0.555\n0.383\n0.321\n0.182\nPICA†[23]\n0.850\n0.782\n0.733\n0.324\n0.336\n0.179\nPICA‡[23]\n0.828\n0.763\n0.692\n0.352\n0.353\n0.201\nPICA‡[23]+HAE\n0.821\n0.759\n0.686\n0.338\n0.347\n0.200\nPICA‡[23]+GAE [27]\n0.854\n0.792\n0.737\n0.344\n0.350\n0.199\nPICA‡[23]+HGCAE-P\n0.855\n0.790\n0.741\n0.387\n0.360\n0.226\n† Numbers from literature.\n‡ Numbers from our experiments on the ofﬁcial pre-trained networks2.\noped for deep image clustering. After obtaining activations\nfrom the pre-trained networks of PICA, we built the graph\nby mutual k nearest neighbors between activations. Then,\nboth the activations and the graph were used as inputs of\nHGCAE-P. Extensive baselines and state-of-the-art image\nclustering methods [35, 74, 19, 6, 3, 37, 43, 64, 50, 73,\n75, 26, 71, 68, 9, 8, 67, 23] were compared. Furthermore,\nwe also trained two auto-encoder models, GAE [27], and\nhyperbolic auto-encoder (HAE) whose layers are hyper-\nbolic feed-forward layers [16]. The image clustering results\nare reported in Table 5. The metrics, ACC, NMI and Ad-\njusted Rand Index (ARI), were used for evaluation. The re-\nsults demonstrate that applying hyperbolic geometry along\nwith using additional information of the approximated im-\nage manifold via nearest neighbor graphs can achieve better\nresults than the Euclidean counterparts. We can also observe\n2https://github.com/Raymond-sci/PICA\nthat HAE, the auto-encoder which naively applies hyper-\nbolic geometry, does not work well, while our model per-\nforms better via the message passing fully utilizing hyper-\nbolic geometry.\n5.3. Structure-Aware Unsupervised Embeddings\nIn this experiment, we observe the unsupervised hy-\nperbolic image embeddings’ ability to recognize the la-\ntent structure of visual datasets that have hierarchical struc-\ntures. ImageNet [31] is constructed following the hierar-\nchy of WordNet [41], therefore, its classes of ImageNet-\n10 [9] also have hierarchical structures. However, it is difﬁ-\ncult to explore the effectiveness of hyperbolic embeddings\nsince the classes of ImageNet-10 are biased to a certain\nroot. Thus, we have constructed a new dataset, ImageNet-\nBNCR, that has a Balanced Number of Classes across Roots.\nFor ImageNet-BNCR, we have chosen three roots, Artifact,\nNatural objects, and Animal, which have a large number\nof leaf classes. Each root contains balanced child nodes\nof {Ambulance, Dogsled, School bus}, {Lemon, Jackfruit,\nGranny Smith}, and {Flamingo, Bald eagle, Lionﬁsh}, re-\nspectively. On the leaf classes of ImageNet-10, {Container\nship, Airliner, Airship, Sports car, Trailer truck, Soccer\nball}, {Orange}, and {Maltese dog, Snow leopard, King\npenguin} are the child nodes of the roots Artifact, Natural\nobjects, and Animal, respectively. The class hierarchies of\nImageNet-10 and ImageNet-BNCR are shown in Fig. 3.\nWe extracted 1000-dimensional features by training a\nconvolutional auto-encoder (CAE) [37] on the ImageNet-\n10 and ImageNet-BNCR datasets. Then, after building the\ngraph using mutual k nearest neighbors between extracted\nfeatures, we trained three auto-encoder models (HGCAE-P,\nGAE [27], and HAE) whose latent space is 2-dimensional\nwithout the ground truth hierarchy structure of labels. The\nembedding results of the 1000-dimensional CAE features\nvia UMAP [40] and three auto-encoders are presented in\nFig. 4. We can observe that the embeddings of HGCAE-\nP are better clustered than others, according to the classes\nof each root in Fig. 3. On the ImageNet-10, in the same\nroot Artifact, the embeddings of descendants of Craft and\n6\n(a) ImageNet-10\n(b) ImageNet-BNCR\nCAE\nGAE\nHAE\nHGCAE-P\nGranny Smith\nLemon\nJackfruit\nAmbulance\nSchool bus\nDogsled\nBald eagle\nLionfish\nFlamingo\nContainer ship\nAirliner\nAirship\nSports car\nTrailer truck\nSoccer ball\nOrange\nSnow leopard\nMaltese dog\nKing penguin\nCAE\nGAE\nHAE\nHGCAE-P\nFigure 4: 2-dimensional embeddings of CAE, GAE, HAE,\nand HGCAE-P on ImageNet-10 and ImageNet-BNCR. Hy-\nperbolic representations belonging to the same root are\nclose to each other near the boundary of the space.\nWheeled vehicle are clustered respectively. The embeddings\nof the ImageNet-BNCR are clustered more distinctly ac-\ncording to the root of class hierarchy than with ImageNet-\n10. On the other hand, the embeddings of the root Natu-\nral objects, {Lemon, Jackfruit, Granny Smith}, are located\ncloser to each other, since geodesic distance between each\nleaf label is small. Our distinction from HAE implies that\nthe additional information on image manifolds approxi-\nmated by nearest neighbor graphs is helpful. In contrast to\nthe representations of CAE and GAE, we can see that the\nhyperbolic representations belonging to the same root are\nlocated near the boundary of the space. In addition, to quan-\ntitatively validate the ability to recognize latent hierarchical\nstructure of the data without direct learning of label hierar-\nchy, we cluster 2-dimensional embeddings of the three auto-\n(a) ImageNet-10\n15\n20.5\n26\n31.5\n37\n42.5\n48\n53.5\n59\n64.5\n70\nI\nII\nIII\nGAE\nHAE\nHGCAE-P\n(b) ImageNet-BNCR\n20\n26\n32\n38\n44\n50\n56\n62\n68\n74\n80\nI\nII\nIII\nGAE\nHAE\nHGCAE-P\nI. Artifact, Natural object, Animal\nII. Craft, Wheeled vehicle,    \n    Equipment, Citrus, Mammal, Bird\nIII. 10 leaf classes\nI. Artifact, Natural object, Animal\nII. Vehicle, Public transport, Edible     \n    fruit, Bird, Aquatic vertebrate\nIII. 9 leaf classes\nFigure 5: Clustering accuracy (%) according to the hierar-\nchy of classes on ImageNet-10 and ImageNet-BNCR.\nencoders with three ground truth label settings according\nto the class hierarchy in Fig. 3: I. Root nodes, II. Internal\nnodes, and III. Leaf nodes. The quantitative results (clus-\ntering accuracy) on ImageNet-10 and ImageNet-BNCR are\nreported in Fig. 5. HGCAE-P outperforms GAE and HAE\nin every label hierarchy settings. This might be because the\nleaf classes whose parent is the same are closely embedded\nwith each other. This analysis empirically demonstrates that\nunsupervised hyperbolic image embeddings can recognize\nthe latent structure of the visual data that has a hierarchical\nstructure.\n5.4. Hyperbolic Distance to Filter Training Samples\nIn this experiment, we show that hyperbolic distance can\nhelp to choose training samples beneﬁcial to the general-\nization ability of neural networks. To this end, we obtained\nthe latent embeddings of ImageNet-10 [9] and ImageNet-\nBNCR via HGCAE-P model. Then, the hyperbolic distance\n(Eq. (2)) of each embedding from the origin was computed.\nFig. 6 shows some samples near the boundary or near the\norigin in the histogram of the hyperbolic distance from em-\nbeddings to the origin. We can see that the samples near the\nboundary can be easily classiﬁed, whereas those near the\norigin are harder to classify. In general, the easy samples\nare not inﬂuential to learn an exact decision boundary. On\nthe other hand, the hard samples make the decision bound-\nary over-ﬁtted, i.e., they work like noises located at the soft\nmargin region near the decision boundary [12]. This illus-\ntration intuitively shows that the Hyperbolic Distance from\nthe Origin (HDO) of a sample could give a clue which sam-\nples are inﬂuential or beneﬁcial to learn the decision bound-\nary crucial for the generalization ability of a classiﬁer.\nTo verify this intuition, we conducted an experiment\non the image classiﬁcation task. On ImageNet-10 and\n7\nContainer ship\nKing penguin\nSports car\nSnow leopard\nAirship\nKing penguin\nTrailer truck\nTrailer truck\nMaltese dog\nMaltese dog\nMaltese dog\nOrange\nOrange\nOrange\nSports car\nSports car\nAirliner\nSoccer ball\nAirship\nContainer ship\n(a) ImageNet-10\n(b) ImageNet-BNCR\nGranny Smith\nSchool bus\nDogsled\nGranny Smith\nDogsled\nGranny Smith\nGranny Smith\nAmbulance\nAmbulance\nFlamingo\nFlamingo\nGranny Smith Granny Smith Granny Smith\nJackfruit\nBald eagle\nLemon\nLemon\nDogsled\nDistance from origin\n0\n0.5\n1\n1.5\n2\n0\n500\n1000\n1500\nDistance from origin\n0\n0.5\n1\n1.5\n2\n0\n400\n800\n1200\n2.5\nSchool bus\nFigure 6: Histogram and images according to the hyper-\nbolic distance from the origin (HDO) on ImageNet-10 and\nImageNet-BNCR. The feature of images inside red (blue)\ncolor box have high (low) HDO, so are located near the\nboundary (origin) of hyperbolic space.\nImageNet-BNCR, we trained the VGG-11 [58] classiﬁer by\nadding further samples near the boundary/median of the dis-\ntance histogram/origin to the original dataset in every train-\ning epoch and evaluated the network via each class’ valida-\ntion set in ImageNet [31]. We compared our results with six\nsettings: I. Baseline: original data with cross entropy loss,\nII. BaselineFL: original data with focal loss (FL) [32]3, III.\nBaseline + Random data adding, IV. Baseline + High HDO\ndata adding, V. Baseline + Low HDO data adding, and VI.\nBaseline + Middle HDO data adding.\nThe image classiﬁcation results are given in Fig. 7. As\nexpected, the case V of adding low HDO data in the his-\ntogram show similar performances with the baseline. The\ncase IV of adding high HDO data contributes the per-\n3The focal loss tries to focus gradient updates on the samples that the\nclassiﬁer hard to classify.\nI. Baseline.\nII. BaselineFL.\nIV. Baseline + High HDO data.\nV. Baseline + Low HDO data.\nVI. Baseline + Middle HDO data.\nIII. Baseline + Random data.​\nI\nII\nIII\nIV\nV\nVI\n10\n10.25\n10.5\n10.75\n11\n11.25\n11.5\n11.75\n12\n12.25\n12.5\n10.14\n10.92\n10.94\n10.96\n12.02\n11.18\n(a) ImageNet-10​\nI\nII\nIII\nIV\nV\nVI\n8\n8.15\n8.3\n8.45\n8.6\n8.75\n8.9\n9.05\n9.2\n9.35\n9.5\n8.155\n8.977\n8.533\n8.911\n9.111\n8.977\n(b) ImageNet-BNCR\nFigure 7: Top-1 classiﬁcation error (%) on ImageNet-10 and\nImageNet-BNCR.\nformance improvements, but the case VI of adding mid-\ndle HDO data demonstrates the best performance among\nthe compared settings. This result empirically veriﬁes that\nthe middle HDO samples are beneﬁcial to learn a reason-\nable decision boundary which increases the generalization\nability of a neural network. Since the supporting samples\nmarginally apart from the decision boundary are crucial for\nthe generalization performance [12], the HDO related with\nthe generalization performance can be interpreted as a mea-\nsure proportional to the distance of a sample from the deci-\nsion boundary for a given classiﬁcation task. In conclusion,\nwe can utilize HDO as a criterion to choose samples for\nimproving the generalization ability of a model for a given\ndataset.\n6. Conclusion\nIn this paper, we explored the properties of unsuper-\nvised hyperbolic representations. We derived the repre-\nsentations from geometry-aware message passing auto-\nencoders whose whole operations were conducted in hy-\nperbolic spaces. Then, we conducted extensive experiments\nand analyses on the low-dimensional latent representations\nin hyperbolic spaces. The experimental results support the\nconclusion that taking advantage of hyperbolic geometry\ncan improve the performances of unsupervised tasks; node\nclustering, link prediction, and image clustering. We ob-\nserved that the proposed method could yield unsupervised\nhyperbolic image embeddings reﬂecting the latent structure\nof the visual datasets that have hierarchical structure. Lastly,\nwe demonstrated that the hyperbolic distance from origin\nfor a sample could be utilized to determine the additional\ndata crucial for generalization ability of a classiﬁer.\nAcknowledgement: We thank Esha Dasgupta for careful reading and in-\nsightful comments on our manuscript. This work was supported by Min-\n8\nistry of Science and ICT, Korea: IITP grant [No.2014-3-00123, Develop-\nment of High Performance Visual BigData Discovery Platform] and ITRC\nsupport program [IITP-2020-2020-0-01789] supervised by the IITP.\nReferences\n[1] Gregor Bachmann, Gary B´ecigneul, and Octavian-Eugen\nGanea.\nConstant curvature graph convolutional networks.\narXiv preprint arXiv:1911.05076, 2019. 1\n[2] Gary Becigneul and Octavian-Eugen Ganea.\nRiemannian\nadaptive optimization methods. In International Conference\non Learning Representations, 2019. 14\n[3] Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo\nLarochelle. Greedy layer-wise training of deep networks. In\nAdvances in Neural Information Processing Systems, pages\n153–160, 2007. 6, 13\n[4] L´eon Bottou. Online learning and stochastic approximations.\nOn-line learning in neural networks, 17(9):142, 1998. 14\n[5] Guillaume Bouchard, Sameer Singh, and Theo Trouillon.\nOn approximate reasoning capabilities of low-rank vector\nspaces. In 2015 AAAI Spring Symposium Series, 2015. 1\n[6] Deng Cai, Xiaofei He, Xuanhui Wang, Hujun Bao, and Ji-\nawei Han. Locality preserving nonnegative matrix factoriza-\ntion. In IJCAI, volume 9, pages 1010–1015, 2009. 6, 13\n[7] Ines Chami, Zhitao Ying, Christopher R´e, and Jure\nLeskovec. Hyperbolic graph convolutional neural networks.\nIn Advances in Neural Information Processing Systems,\npages 4869–4880, 2019. 1, 3, 14\n[8] Jianlong Chang, Yiwen Guo, Lingfeng Wang, Gaofeng\nMeng, Shiming Xiang, and Chunhong Pan. Deep discrimi-\nnative clustering analysis. arXiv preprint arXiv:1905.01681,\n2019. 6, 13\n[9] Jianlong Chang, Lingfeng Wang, Gaofeng Meng, Shiming\nXiang, and Chunhong Pan.\nDeep adaptive image cluster-\ning. In Proceedings of the IEEE International Conference\non Computer Vision, pages 5879–5887, 2017. 4, 5, 6, 7, 12,\n13, 14\n[10] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge-\noffrey Hinton. A simple framework for contrastive learn-\ning of visual representations. In International Conference on\nMachine Learning, pages 1597–1607, 2020. 16\n[11] Taco S Cohen, Mario Geiger, Jonas K¨ohler, and Max\nWelling.\nSpherical cnns.\nIn International Conference on\nLearning Representations, 2018. 16\n[12] Corinna Cortes and Vladimir Vapnik. Support-vector net-\nworks. Machine Learning, 20(3):273–297, 1995. 7, 8\n[13] Wouter De Nooy, Andrej Mrvar, and Vladimir Batagelj. Ex-\nploratory social network analysis with Pajek: Revised and\nexpanded edition for updated software, volume 46. Cam-\nbridge University Press, 2018. 4, 5, 12\n[14] Christopher De Sa, Albert Gu, Christopher R´e, and Frederic\nSala. Representation tradeoffs for hyperbolic embeddings.\nProceedings of machine learning research, 80:4460, 2018.\n15\n[15] Herv´e Fournier, Anas Ismail, and Antoine Vigneron. Com-\nputing the gromov hyperbolicity of a discrete metric space.\nInformation Processing Letters, 115(6-8):576–579, 2015. 1\n[16] Octavian Ganea, Gary B´ecigneul, and Thomas Hofmann.\nHyperbolic neural networks. In Advances in Neural Infor-\nmation Processing Systems, pages 5345–5355, 2018. 1, 2, 3,\n5, 6\n[17] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol\nVinyals, and George E Dahl. Neural message passing for\nquantum chemistry. In International Conference on Machine\nLearning, pages 1263–1272, 2017. 1\n[18] Kwang-Il Goh, Michael E Cusick, David Valle, Barton\nChilds, Marc Vidal, and Albert-L´aszl´o Barab´asi. The hu-\nman disease network. Proceedings of the National Academy\nof Sciences, 104(21):8685–8690, 2007. 4, 5, 12\n[19] K Chidananda Gowda and G Krishna. Agglomerative clus-\ntering using the concept of mutual nearest neighbourhood.\nPattern Recognition, 10(2):105–112, 1978. 6, 13\n[20] Daniele Grattarola, Lorenzo Livi, and Cesare Alippi. Adver-\nsarial autoencoders with constant-curvature latent manifolds.\nApplied Soft Computing, 81:105511, 2019. 1, 2\n[21] Caglar Gulcehre, Misha Denil, Mateusz Malinowski, Ali\nRazavi, Razvan Pascanu, Karl Moritz Hermann, Peter\nBattaglia, Victor Bapst, David Raposo, Adam Santoro, and\nNando de Freitas. Hyperbolic attention networks. In Inter-\nnational Conference on Learning Representations, 2019. 1,\n2, 3, 5\n[22] Wolfgang Karl Hofbauer, Laura Lowe Forrest, Peter M\nHollingsworth, and Michelle L Hart. Preliminary insights\nfrom dna barcoding into the diversity of mosses colonising\nmodern building surfaces. Bryophyte Diversity and Evolu-\ntion, 38(1):1–22, 2016. 4, 5, 12\n[23] Jiabo Huang, Shaogang Gong, and Xiatian Zhu. Deep se-\nmantic clustering by partition conﬁdence maximisation. In\nProceedings of the IEEE/CVF Conference on Computer Vi-\nsion and Pattern Recognition, pages 8849–8858, 2020. 5, 6,\n13\n[24] Valentin Khrulkov, Leyla Mirvakhabova, Evgeniya Usti-\nnova, Ivan Oseledets, and Victor Lempitsky.\nHyperbolic\nimage embeddings. In Proceedings of the IEEE/CVF Con-\nference on Computer Vision and Pattern Recognition, pages\n6418–6428, 2020. 1, 2, 5\n[25] Diederick P Kingma and Jimmy Ba.\nAdam: A method\nfor stochastic optimization. In International Conference on\nLearning Representations (ICLR), 2015. 14\n[26] Diederik P Kingma and Max Welling. Auto-encoding vari-\national bayes. arXiv preprint arXiv:1312.6114, 2013. 2, 6,\n13\n[27] Thomas N Kipf and Max Welling. Variational graph auto-\nencoders.\nNIPS Workshop on Bayesian Deep Learning,\n2016. 4, 5, 6, 13, 14, 15\n[28] Thomas N. Kipf and Max Welling. Semi-supervised classi-\nﬁcation with graph convolutional networks. In International\nConference on Learning Representations, 2017. 1, 2\n[29] Dmitri Krioukov, Fragkiskos Papadopoulos, Maksim Kitsak,\nAmin Vahdat, and Mari´an Bogun´a. Hyperbolic geometry of\ncomplex networks. Physical Review E, 82(3):036106, 2010.\n1, 4\n[30] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple\nlayers of features from tiny images. 2009. 1, 2\n9\n[31] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.\nImagenet classiﬁcation with deep convolutional neural net-\nworks. In Advances in Neural Information Processing Sys-\ntems, pages 1097–1105, 2012. 1, 5, 6, 8, 12\n[32] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and\nPiotr Doll´ar. Focal loss for dense object detection. In Pro-\nceedings of the IEEE International Conference on Computer\nVision, pages 2980–2988, 2017. 8, 14\n[33] Qi Liu, Maximilian Nickel, and Douwe Kiela. Hyperbolic\ngraph neural networks. In Advances in Neural Information\nProcessing Systems, pages 8228–8239, 2019. 1, 3, 4\n[34] Shaoteng Liu, Jingjing Chen, Liangming Pan, Chong-Wah\nNgo, Tat-Seng Chua, and Yu-Gang Jiang. Hyperbolic visual\nembedding learning for zero-shot recognition. In Proceed-\nings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, pages 9273–9281, 2020. 1, 2\n[35] Stuart Lloyd.\nLeast squares quantization in pcm.\nIEEE\nTransactions on Information Theory, 28(2):129–137, 1982.\n5, 6, 13, 14\n[36] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully\nconvolutional networks for semantic segmentation. In Pro-\nceedings of the IEEE Conference on Computer Vision and\nPattern Recognition, pages 3431–3440, 2015. 1\n[37] Jonathan Masci, Ueli Meier, Dan Cires¸an, and J¨urgen\nSchmidhuber. Stacked convolutional auto-encoders for hi-\nerarchical feature extraction. In International Conference on\nArtiﬁcial Neural Networks, pages 52–59. Springer, 2011. 6,\n13, 14\n[38] Emile Mathieu, Charline Le Lan, Chris J. Maddison, Ryota\nTomioka, and Yee Whye Teh. Continuous hierarchical rep-\nresentations with poincar´e variational auto-encoders. In Ad-\nvances in Neural Information Processing Systems, 2019. 1,\n2, 5\n[39] Julian McAuley, Christopher Targett, Qinfeng Shi, and An-\nton Van Den Hengel.\nImage-based recommendations on\nstyles and substitutes. In Proceedings of the 38th Interna-\ntional ACM SIGIR Conference on Research and Develop-\nment in Information Retrieval, pages 43–52. ACM, 2015. 4,\n12, 15\n[40] Leland McInnes, John Healy, and James Melville. Umap:\nUniform manifold approximation and projection for dimen-\nsion reduction. arXiv preprint arXiv:1802.03426, 2018. 6\n[41] George A Miller. WordNet: An electronic lexical database.\nMIT press, 1998. 2, 6\n[42] Yoshihiro Nagano, Shoichiro Yamaguchi, Yasuhiro Fujita,\nand Masanori Koyama. A wrapped normal distribution on\nhyperbolic space for gradient-based learning.\nIn Interna-\ntional Conference on Machine Learning, pages 4693–4702,\n2019. 1\n[43] Andrew Ng et al. Sparse autoencoder. CS294A Lecture notes,\n72(2011):1–19, 2011. 6, 13\n[44] Maximilian Nickel, Xueyan Jiang, and Volker Tresp. Reduc-\ning the rank in relational factorization models by including\nobservable patterns. In Advances in Neural Information Pro-\ncessing Systems, pages 1179–1187, 2014. 1\n[45] Maximillian Nickel and Douwe Kiela. Poincar´e embeddings\nfor learning hierarchical representations.\nIn Advances in\nNeural Information Processing Systems, pages 6338–6347,\n2017. 1, 4\n[46] Maximillian Nickel and Douwe Kiela.\nLearning continu-\nous hierarchies in the lorentz model of hyperbolic geome-\ntry. In International Conference on Machine Learning, pages\n3779–3788, 2018. 1, 2\n[47] Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, Lina Yao,\nand Chengqi Zhang. Adversarially regularized graph autoen-\ncoder for graph embedding. In Proceedings of the 27th In-\nternational Joint Conference on Artiﬁcial Intelligence, pages\n2609–2615, 2018. 4, 5, 13, 15\n[48] Jiwoong Park, Minsik Lee, Hyung Jin Chang, Kyuewang\nLee, and Jin Young Choi. Symmetric graph convolutional au-\ntoencoder for unsupervised graph representation learning. In\nProceedings of the IEEE International Conference on Com-\nputer Vision, pages 6519–6528, 2019. 4, 5, 13, 15\n[49] Peter Petersen, S Axler, and KA Ribet. Riemannian geome-\ntry, volume 171. Springer, 2006. 2, 12\n[50] Alec Radford, Luke Metz, and Soumith Chintala.\nUn-\nsupervised representation learning with deep convolu-\ntional generative adversarial networks.\narXiv preprint\narXiv:1511.06434, 2015. 6, 13\n[51] Sachin Ravi and Hugo Larochelle. Optimization as a model\nfor few-shot learning. 2016. 2\n[52] Joshua David Robinson, Ching-Yao Chuang, Suvrit Sra, and\nStefanie Jegelka.\nContrastive learning with hard negative\nsamples. In International Conference on Learning Repre-\nsentations, 2021. 16\n[53] Ryan A. Rossi and Nesreen K. Ahmed. The network data\nrepository with interactive graph analytics and visualization.\nIn Proceedings of the Twenty-Ninth AAAI Conference on Ar-\ntiﬁcial Intelligence, 2015. 4, 5, 12\n[54] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-\njeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,\nAditya Khosla, Michael Bernstein, et al. Imagenet large scale\nvisual recognition challenge. International Journal of Com-\nputer Vision, 115(3):211–252, 2015. 2\n[55] Serim Ryou, Seong-Gyun Jeong, and Pietro Perona. Anchor\nloss: Modulating loss scale based on prediction difﬁculty. In\nProceedings of the IEEE/CVF International Conference on\nComputer Vision, pages 5992–6001, 2019. 14\n[56] MJ Sanderson, MJ Donoghue, W Piel, and T Eriksson. Tree-\nbase: a prototype database of phylogenetic analyses and an\ninteractive tool for browsing the phylogeny of life. American\nJournal of Botany, 81(6):183, 1994. 4, 5, 12\n[57] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor,\nBrian Galligher, and Tina Eliassi-Rad. Collective classiﬁca-\ntion in network data. AI magazine, 29(3):93–93, 2008. 1, 4,\n5, 12, 14, 15\n[58] Karen Simonyan and Andrew Zisserman. Very deep convo-\nlutional networks for large-scale image recognition. arXiv\npreprint arXiv:1409.1556, 2014. 8, 14\n[59] Ondrej\nSkopek,\nOctavian-Eugen\nGanea,\nand\nGary\nB´ecigneul.\nMixed-curvature variational autoencoders.\nIn International Conference on Learning Representations,\n2019. 2\n10\n[60] Lei Tang and Huan Liu. Relational learning via latent social\ndimensions. In Proceedings of the 15th ACM SIGKDD In-\nternational Conference on Knowledge Discovery and Data\nmining, pages 817–826. ACM, 2009. 4, 12, 15\n[61] Michael Tschannen, Josip Djolonga, Paul K Rubenstein, Syl-\nvain Gelly, and Mario Lucic. On mutual information maxi-\nmization for representation learning. In International Con-\nference on Learning Representations, 2019. 16\n[62] Abraham Albert Ungar. A gyrovector space approach to hy-\nperbolic geometry. Synthesis Lectures on Mathematics and\nStatistics, 1(1):1–194, 2008. 3\n[63] Petar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova,\nAdriana Romero, Pietro Li`o, and Yoshua Bengio.\nGraph\nAttention Networks. International Conference on Learning\nRepresentations, 2018. 1, 3\n[64] Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua\nBengio,\nPierre-Antoine\nManzagol,\nand\nL´eon\nBottou.\nStacked denoising autoencoders: Learning useful represen-\ntations in a deep network with a local denoising criterion.\nJournal of Machine Learning Research, 11(12), 2010. 6, 13\n[65] Catherine Wah, Steve Branson, Peter Welinder, Pietro Per-\nona, and Serge Belongie. The caltech-ucsd birds-200-2011\ndataset. 2011. 1, 2\n[66] Chun Wang, Shirui Pan, Guodong Long, Xingquan Zhu, and\nJing Jiang. Mgae: Marginalized graph autoencoder for graph\nclustering. In Proceedings of the 2017 ACM on Conference\non Information and Knowledge Management, pages 889–\n898. ACM, 2017. 4, 5, 13, 15\n[67] Jianlong Wu, Keyu Long, Fei Wang, Chen Qian, Cheng Li,\nZhouchen Lin, and Hongbin Zha. Deep comprehensive cor-\nrelation mining for image clustering. In Proceedings of the\nIEEE International Conference on Computer Vision, pages\n8150–8159, 2019. 6, 13\n[68] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised\ndeep embedding for clustering analysis.\nIn International\nConference on Machine Learning, pages 478–487, 2016. 6,\n13\n[69] Sijie Yan, Yuanjun Xiong, and Dahua Lin. Spatial tempo-\nral graph convolutional networks for skeleton-based action\nrecognition. arXiv preprint arXiv:1801.07455, 2018. 1\n[70] Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, and Ed-\nward Chang. Network representation learning with rich text\ninformation. In Twenty-Fourth International Joint Confer-\nence on Artiﬁcial Intelligence, 2015. 4, 12\n[71] Jianwei Yang, Devi Parikh, and Dhruv Batra. Joint unsuper-\nvised learning of deep representations and image clusters.\nIn Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition, pages 5147–5156, 2016. 6, 13\n[72] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk\nChun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regular-\nization strategy to train strong classiﬁers with localizable fea-\ntures. In Proceedings of the IEEE/CVF International Con-\nference on Computer Vision, pages 6023–6032, 2019. 14\n[73] Matthew D Zeiler, Dilip Krishnan, Graham W Taylor, and\nRob Fergus.\nDeconvolutional networks.\nIn Proceedings\nof the IEEE Conference on Computer Vision and Pattern\nRecognition, pages 2528–2535. IEEE, 2010. 6, 13, 14\n[74] Lihi Zelnik-Manor and Pietro Perona. Self-tuning spectral\nclustering. In Advances in Neural Information Processing\nSystems, pages 1601–1608, 2005. 6, 13\n[75] Junbo Zhao, Michael Mathieu, Ross Goroshin, and Yann Le-\ncun.\nStacked what-where auto-encoders.\narXiv preprint\narXiv:1506.02351, 2015. 6, 13\n[76] Shuai Zheng, Zhenfeng Zhu, Xingxing Zhang, Zhizhe Liu,\nJian Cheng, and Yao Zhao.\nDistribution-induced bidirec-\ntional generative adversarial network for graph representa-\ntion learning. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pages 7224–\n7233, 2020. 4, 5, 13\n11\nSupplementary material for “Unsupervised Hyperbolic Representation Learning\nvia Message Passing Auto-Encoders”\nIn this supplemental material, we present the reviews of\nRiemannian geometry and hyperboloid model ﬁrstly. Then,\nwe explain the details of the datasets, compared methods,\nand experimental details. Finally, further experiments on\nnetwork datasets and further discussions are presented.\nA. Riemannian Geometry\nA.1. A Review of Riemannian Geometry\nA manifold M of n-dimension is a topological space\nthat each point x ∈M has a neighborhood that is home-\nomorphic to n-dimensional Euclidean space Rn. For each\npoint x ∈M, a real vector space TxM whose dimen-\nsionality is the same as M exists and is called a tangent\nspace. The tangent space TxM is the set of all the pos-\nsible directions and speeds of the curves on M across\nx ∈M. A Riemannian manifold is a tuple (M, g) that\nis possessing Riemannian metric gx : TxM × TxM →R\non the tangent space TxM at each point x ∈M such that\n⟨y, z⟩x = gx(y, z) = yT G(x)z, where G(x) is a matrix\nrepresentation of Riemannian metric [49]. The metric ten-\nsor provides geometric notions such as the length of curve,\nangle and volume. The length of curve γ : t 7→γ(t) ∈M\nis L(γ) =\nR 1\n0 ∥γ\n′(t)∥1/2\nγ(t) dt. The geodesic, the general-\nization of straight line on Euclidean space, is the constant\nspeed curves giving the shortest path between the pair of\npoints x, y ∈M: γ∗= arg minγ L(γ) where γ(0) = x,\nγ(1) = y and ∥γ\n′(t)∥γ(t) = 1. The global distance between\ntwo points x, y ∈M is deﬁned as dM(x, y) = infγ L(γ).\nFor a tangent vector v ∈TxM of x ∈M, there exists\na unique unit speed geodesic γ such that γ(0) = x and\nγ\n′(0) = v. Then, the corresponding exponential map is de-\nﬁned as expx(v) = γ(1). The inverse mapping of exponen-\ntial map, the logarithmic map, is deﬁned as logx : M →\nTxM. Refer the website of footnote for good introduction\nof hyperbolic geometry4.\nA.2. Hyperboloid Model\nThe hyperbolic space is a Riemannian manifold with\nconstant negative sectional curvature equipped with hyper-\nbolic geometry, and the hyperboloid model is one of the\nmultiple equivalent hyperbolic models. For x, y ∈Rn+1,\nthe Lorentz inner product ⟨·, ·⟩L is deﬁned as ⟨x, y⟩L =\n−x0y0 + Pn\ni=1 xiyi. The n-dimensional hyperboloid with\nconstant negative curvature K(K\n<\n0) is deﬁned as\n4http : / / hyperbolicdeeplearning . com / simple -\ngeometry-initiation/\n(Hn\nK, gHK\nx\n):\nHn\nK = {x ∈Rn+1 : ⟨x, x⟩L = 1/K, x0 > 0}.\n(13)\nThe metric tensor is gHK\nx\n= diag([−1, 1, . . . 1]), and the ori-\ngin of the hyperboloid model is o = (1/\np\n|K|, 0, . . . , 0) ∈\nRn+1. The distance between two points x, y ∈Hn\nK is de-\nﬁned as\ndHn\nK(x, y) =\n1\n√\n−K arcosh(K⟨x, y⟩L).\n(14)\nFor points x ∈Hn\nK, tangent vector v ∈TxHn\nK, and y ̸= 0,\nexpx : TxHn\nK →Hn\nK and logx : Hn\nK →TxHn\nK are deﬁned\nas\nexpK\nx (v) = cosh(s)x + sinh(s)v\ns,\n(15)\nlogK\nx (y) = arcosh(K⟨x, y⟩L)\np\nK2⟨x, y⟩2\nL −1\n(y −K⟨x, y⟩Lx),\n(16)\nwhere s =\n√\n−K∥v∥L and ∥x∥L =\np\n⟨x, x⟩L.\nB. Datasets\nB.1. Network Datasets\nPhylogenetic tree [22, 56] models the generic heritage.\nCS PhDs [13] represents the relationship between Ph.D.\ncandidates and their advisors in computer science ﬁelds.\nDiseases [18, 53] is a biological network expressing the\nrelationship between diseases. Cora [57], Citeseer [57],\nPubmed [57], and Wiki [70] are citation networks whose\nnodes are scientiﬁc papers or web pages and edges repre-\nsent citation relationships between any two papers or links\nbetween any two web pages. BlogCatalog [60] models a\nsocial network among bloggers in the online community.\nAttribute and label of a node represent the description of\neach blog and the interest of a blogger, respectively. Ama-\nzon Photo [39] is a part of Amazon co-purchase networks\nwhose nodes are goods and edges represent purchase corre-\nlations between any two goods. A node attribute indicates\nthe bag-of-words for goods’ reviews and its label denotes a\nproduct category.\nB.2. Image Datasets\nImageNet-10 [9] and ImageNet-Dogs [9] are subsets of\nthe ImageNet dataset [31]. ImageNet-10 consists of 13, 000\nimages from 10 randomly selected subjects. ImageNet-\nDogs are 19, 500 images from 15 randomly selected dog\n5http://image-net.org/index\n12\nDog\nHunting dog\nMaltese \ndog\nBlenheim \nspaniel\nNorwegian \nelkhound\nBasset\nGiant \nschnauzer\nBrittany \nspaniel\nClumber\nWelsh springer \nspaniel\nGolden \nretriever\nChow\nPug\nDoberman\nShetland \nsheepdog\nKelpie\nGroenendael\nToy spaniel\nToy dog\nEnglish toy \nspaniel\nHound\nTerrier\nSporting dog\nSchnauzer\nSpaniel\nRetriever\nSpringer \nSpaniel\nWorking dog\nShepherd dog\nWatch dog\nSpitz\nPinscher\nBelgian \nsheepdog\nAnimal\nChordate\nVertebrate\nMammal\nPlacental\nCarnivore\nCanine\nFigure 8: Class hierarchy of ImageNet-Dogs5.\nbreeds. The class hierarchy of ImageNet-Dogs is illustrated\nin Fig. 8. We have constructed a new dataset, ImageNet-\nBNCR, via randomly choosing 3 leaf classes per root. We\nchose three roots, Artifacts, Natural objects, and Animal.\nThus, there exist 9 leaf classes, and each leaf class con-\ntains 1, 300 images in ImageNet-BNCR dataset. For every\ndataset used for the image clustering task, we used only the\ntraining set without the validation set, and images were re-\nsized to 96 × 96 × 3.\nC. Compared Methods\nC.1. Node Clustering and Link Prediction\nWe compared HGCAE with seven state-of-the-art unsu-\npervised message passing models which mainly conduct in\nEuclidean space.\n• GAE [27], VGAE [27], ARGA [47], and ARVGA [47]\nare graph auto-encoders that reconstruct only the afﬁnity\nmatrix using a non-parametric decoder which is not learn-\nable.\n• MGAE [66] is a stacked one-layer graph auto-encoder\nthat reconstructs only the node attributes via a linear acti-\nvation function.\n• GALA [48] is a graph auto-encoder that reconstructs only\nthe node attributes through learnable parametric encoder\nand decoder.\n• DBGAN [76] is a distribution-induced bidirectional gen-\nerative adversarial network that estimates the structure-\naware prior distribution of the representations.\nGAE [27], VGAE [27], ARGA [47], ARVGA [47], and\nGALA [48] are constrained to have two-layer auto-encoder\nmodels, since they report that two-layer structures show the\nbest performances. In the case of MGAE [66] which is a\nstacked one-layer auto-encoder model, we have stacked the\nlayer up to three and reported the best performances. For\nDBGAN [76], we followed the number of layers in the lit-\nerature. For every compared method, we followed the hy-\nperparameters in the literature.\nC.2. Image Clustering\nExtensive baselines and state-of-the-art image cluster-\ning methods were compared. Several traditional methods\nincluding k-means clustering (Kmeans) [35], spectral clus-\ntering (SC) [74], agglomerative clustering (AC) [19], and\nnonnegative matrix factorization (NMF) [6] were also com-\npared. For the representation-based clustering methods,\nAE [3], CAE [37], SAE [43], DAE [64], DCGAN [50],\nDeCNN [73], SWWAE [75], and VAE [26] were adopted.\nBesides, the state-of-the-art image clustering methods in-\ncluding JULE [71], DEC [68], DAC [9], DDC [8], DCCM\n[67], and PICA [23] were employed. For every compared\nmethod, we followed the experimental details in the litera-\nture.\n13\nD. Experimental Details\nFor every experiment and analysis, HGCAE has two en-\ncoder layers and two decoder layers. The dimension of each\nlayer for HGCAE was set to one of {23, 24, ..., 211}. We op-\ntimized HGCAE using Adam [25] with learning rate 0.01.\nAs reported in [7], we observe that Euclidean optimization\n[25] is much more stable than Riemannian optimization [2].\nBecause of exponential and logarithmic maps, the param-\neters of our model can be optimized using Euclidean op-\ntimization. We experimented with HGCAE for two cases,\nﬁxing the curvature of all layers or learning the curvature of\neach layer, then we reported the best performances. In the\ncase of ﬁxing the curvature of all layers, the curvature K\nwas set to one of {−0.1, −0.5, −1, −2}. The regularization\nparameter λ of Eq. (12) in the manuscript was set to one\nof {10−6, 10−5, ..., 103}. The initial values of trainable pa-\nrameters β and γ in Eq. (9) in the manuscript were set to 0.\nWe searched the best hyperparameters which suited well to\neach dataset by random search. For visual datasets, we con-\nstruct the mutual k nearest neighbors graph, A, as follows:\nAij =\n(\n1\nif xi ∈NNk(xj) ∧xj ∈NNk(xi)\n0\notherwise,\n(17)\nwhere xi and NNk(xi) denote the feature and k Euclidean\nnearest neighbor set of the i-th image respectively. We set\nk = 20 and k = 10 for ImageNet-10 and ImageNet-Dogs,\nrespectively.\nD.1. Details of Node Clustering and Link Prediction\nFor the link prediction task, we divided the edges into\ntraining edges, validation edges, and test edges as 85%,\n5%, and 10%, then we used validation edges for the\nmodel convergence. During training for the link prediction\ntask, we only reconstructed training edges in LREC−A =\nEq(H|X,A)[log p( ˆA|H)]. For the node clustering task, every\nedge is reconstructed by the output of the encoder during\ntraining. The performance of node clustering was obtained\nby running k-means clustering [35] on the latent representa-\ntions (output of the encoder) in the tangent space of the last\nlayer of the encoder.\nD.2. Details of Image Clustering\nThe performance of HGCAE on the image clustering\ntask was obtained by running k-means clustering [35] on\nthe latent representations (output of the encoder) in the tan-\ngent space of the last layer of the encoder.\nD.3. Details of Convolutional Auto-Encoder\nWe extracted 1000-dimensional features by training a\nconvolutional auto-encoder (CAE) [37] on the ImageNet-10\n[9] and ImageNet-BNCR datasets on the experiment of Sec-\ntion 5.3 in the manuscript. We used the encoder part and de-\ncoder part as VGG-16 network [58] and ﬁve deconvolution\nlayers [73] respectively. We optimized CAE using Adam\n[25] with learning rate 0.0001 and obtained the feature after\n100 epochs.\nD.4. Details of Image Classiﬁcation\nWe obtained the latent representation of ImageNet-10 [9]\nand ImageNet-BNCR by training CAE on the experiments\nof Section 5.4 in the manuscript. For the image classiﬁca-\ntion task, we trained the VGG-11 [58] classiﬁer. We trained\nthe classiﬁer using stochastic gradient descent [4] and used\nthe learning rate scheduler as in [72]. When adding fur-\nther samples in every training epoch, high, middle, and low\nHDO samples were chosen by n% of the original data clos-\nest to the boundary, n% of the original data closest to the\nmedian of distance histogram, and n% of the original data\nclosest to the origin, respectively. We set n for ImageNet-10\nand ImageNet-BNCR to 30 and 50 respectively. The learn-\ning rates of ImageNet-10 and ImageNet-BCNR were set to\n0.01 and 0.0005 respectively. When training BaselineFL,\nwe tried {0.5, 1.0, 2.0} for γ in focal loss [32] and reported\nthe best performances. There has been recent research on\nmanipulating the gradient updates based on the prediction\ndifﬁculty, anchor loss (AL) [55], and we have tried to report\nthe classiﬁcation performance of AL as well as FL. How-\never, due to the several NaN issues of ofﬁcial AL imple-\nmentation6, we could not report the performance of AL.\nE. Further Experiments\nE.1. Effectiveness of The Proposed Components\nThrough link prediction experiments, we validated the\neffectiveness of two components: learning in the hyperbolic\nspaces and reconstructing both the graph structure and the\nnode attributes. The experiment was conducted on two ci-\ntation networks, Cora [57] and Citeseer [57], then the re-\nsults for link prediction task are presented in Table 6. The\nbaseline model is GAE [27], which conducts graph convo-\nlution in Euclidean space, does not use an attention mecha-\nnism, and reconstructs only the afﬁnity matrix A. In Abla-\ntion I, reconstructing both the node attribute XEuc and the\ngraph structure A (Eq. (12) in the manuscript) are added to\nthe baseline settings. In Ablation II, operating in hyperbolic\nspace with ﬁxed curvature K is added to Ablation I. In Ab-\nlation III, operating in hyperbolic space with ﬁxed curvature\nK and the geometry-aware attention mechanism (Eq. (9) in\nthe manuscript) are added to baseline settings. The results\nbetween Ablation I and Ablation II show that the message\npassing in the hyperbolic space is more effective than that\n6https://github.com/slryou41/AnchorLoss\n14\nTable 6: Ablation studies on link prediction task: The baseline model is GAE which conducts graph convolution in Euclidean\nspace, does not use an attention mechanism and reconstructs only the graph structure A.\nReconstruct\nGeometry\nin hyperbolic space\nin hyperbolic spaces\nCora\nCiteseer\nboth A and X\naware attention\nﬁxing K\nlearning K\nAUC\nAP\nAUC\nAP\nBaseline: GAE [27]\n×\n×\n×\n×\n91.0\n92.0\n89.5\n89.9\nAblation I\n√\n×\n×\n×\n92.7\n92.1\n94.0\n94.8\nAblation II\n√\n×\n√\n×\n94.6\n94.4\n95.9\n96.3\nAblation III\n×\n√\n√\n×\n94.5\n94.8\n96.1\n96.4\nProposed I: HGCAE\n√\n√\n√\n×\n95.4\n95.5\n96.7\n97.0\nProposed II: HGCAE\n√\n√\n×\n√\n95.6\n95.5\n96.5\n96.8\nTable 7: Clustering performances in low-dimensional space.\nPubmed\nBlogCatalog\nAmazon Photo\nACC\nNMI\nACC\nNMI\nACC\nNMI\nGAE [27]\n51.3\n7.7\n27.6\n11.4\n37.1\n27.3\nVGAE [27]\n40.6\n0.1\n23.3\n5.9\n36.3\n27.7\nARGA [47]\n40.0\n0.5\n29.8\n14.6\n41.0\n37.0\nARVGA [47]\n38.5\n0.1\n27.2\n9.7\n40.8\n27.8\nGALA [48]\n36.1\n0.4\n25.2\n7.1\n24.2\n5.8\nHGCAE\n68.1\n28.2\n74.1\n57.8\n76.3\n64.0\nin Euclidean space. Also, the performance gap between Ab-\nlation III and Proposed I shows that it is helpful to learn a\nrepresentation that reﬂects both the structure of the network\nand the attributes of each node in hyperbolic space. This\ncomponent is also valid in Euclidean space, as shown in the\ngap between Baseline and Ablation I. As shown in the gap\nbetween Proposed I and II, the ﬁxed K and the trainable K\nshow similar performance to each other for some datasets,\nbut training K gives an efﬁcient training scheme without\nmultiple learning for searching the best K.\nE.2. Learning in Low-Dimensional Space\nOne of the strengths of hyperbolic space compared to\nEuclidean space is that hyperbolic model can learn la-\ntent representation of data whose structure is hierarchi-\ncal without the need for infeasible high-dimensional space\n[14]. To show this point, we obtained the latent representa-\ntions of network datasets in the very low-dimensional latent\nspace for node clustering task. Every compared graph auto-\nencoder and HGCAE were constrained to have two layers\nwhose each dimension was 4 and 2 respectively. Note that\nthe performance of MGAE [66] cannot be reported since\nMGAE cannot manipulate the latent dimension. The ex-\nperiments were conducted on Pubmed [57], BlogCatalog\n[60], and Amazon Photo [39] datasets. The results are pre-\nsented in Table 7. Although the dimension of latent space is\nextremely low, HGCAE still signiﬁcantly outperforms the\nstate-of-the-art unsupervised message passing methods op-\nerating in Euclidean space. Notably, on BlogCatalog and\nAmazon Photo datasets, HGCAE achieves more than 30%\nhigher performances compared to Euclidean counterparts.\nGAE\nHGCAE-P\nHGCAE-H\nPubmed\nBlogCatalog\nCiteseer\nAmazon Photo\nFigure 9: 2-dimensional embeddings in Euclidean, Poincar´e\nball, and hyperboloid latent spaces on Pubmed, BlogCata-\nlog, Citeseer, and Amazon Photo datasets.\nThese results support that hyperbolic space is effective than\nEuclidean space even in the very low-dimensional latent\nspace.\nE.3. Visualization of The Network Datasets\nWe explored the latent representations of GAE [27] and\nour models on Pubmed [57], BlogCatalog [60], Citesser\n[57], and Amazon Photo [39] datasets by constraining the\nlatent space as a 2-dimensional hyperbolic or Euclidean\nspace. The result is given in Fig. 9. On the results of HG-\nCAE, most of the nodes are located on the boundary of hy-\nperbolic space and well-clustered with the nodes in the same\n15\nclass.\nE.4. Sensitivity of Hyperparameter Setting\nOne of the important hyperparameters of HGCAE is λ\nin Eq. (12) in the manuscript. If λ is required large (small)\nvalue, this means that the node attributes (subgraph struc-\ntures) are the more important factor of latent representation.\nSince node attributes and the graph structure are different\nfor each dataset, the optimal λ has different values for each\ndataset. In cases of BlogCatalog and Citeseer (Cora), we\nempirically found that small (large) λ value is optimal for\nboth link prediction and node clustering tasks.\nF. Further Discussions\nF.1. Connection to Contrastive Learning\nThe hyperbolic geometry can be extended to contrastive\nlearning [10]. A recent study [61] has uncovered the link\nbetween contrastive learning and deep metric learning. In\nthis respect, it is becoming more signiﬁcant to ﬁnd the in-\nformative (hard) negative samples, embeddings that are dif-\nﬁcult to distinguish from anchors, beyond uniform sam-\npling [52]. Our work empirically showed that Hyperbolic\nDistance from the Origin (HDO) is an effective criterion for\nselecting samples without supervision for better generaliza-\ntion. The concept of HDO could be extended to informative\nnegative sampling. Since the embeddings hard to discrimi-\nnate is equal to those that are hard to classify by the model,\nthe samples near the origin of hyperbolic space can be the\nimpactful negative samples to increase the ability of the un-\nsupervised contrastive learning.\nF.2. Failure Cases of Hyperbolic Embedding Spaces\nThe inductive bias of hyperbolic representation learn-\ning is assuming that there exist hierarchical relationships\nin the dataset. Thus if the structure of the graph model-\ning the relation between data points is close to a tree, the\nhyperbolic space, a continuous version of a tree, is a suit-\nable latent space. However, not all datasets’ latent structures\nhave the topological properties of the tree. For instance,\ndatasets obtained from omnidirectional sensors of drones\nand autonomous cars are indeed more suitable to latent hy-\nperspherical manifold rather than the hyperbolic manifold\n[11].\n16\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2021-03-30",
  "updated": "2021-03-30"
}