{
  "id": "http://arxiv.org/abs/2105.00830v1",
  "title": "Natural Language Generation Using Link Grammar for General Conversational Intelligence",
  "authors": [
    "Vignav Ramesh",
    "Anton Kolonin"
  ],
  "abstract": "Many current artificial general intelligence (AGI) and natural language\nprocessing (NLP) architectures do not possess general conversational\nintelligence--that is, they either do not deal with language or are unable to\nconvey knowledge in a form similar to the human language without manual,\nlabor-intensive methods such as template-based customization. In this paper, we\npropose a new technique to automatically generate grammatically valid sentences\nusing the Link Grammar database. This natural language generation method far\noutperforms current state-of-the-art baselines and may serve as the final\ncomponent in a proto-AGI question answering pipeline that understandably\nhandles natural language material.",
  "text": "Natural Language Generation Using Link Grammar for \nGeneral Conversational Intelligence \nVignav Ramesh1,2 and Anton Kolonin2,3,4 \n1 Saratoga High School, Saratoga CA 95070, USA \n2 SingularityNET Foundation, Amsterdam, Netherlands \n3 Aigents, Novosibirsk, Russian Federation \n4 Novosibirsk State University, Russian Federation \n{rvignav, akolonin}@gmail.com \nAbstract. Many current artificial general intelligence (AGI) and natural language \nprocessing (NLP) architectures do not possess general conversational intelli-\ngence—that is, they either do not deal with language or are unable to convey \nknowledge in a form similar to the human language without manual, labor-inten-\nsive methods such as template-based customization. In this paper, we propose a \nnew technique to automatically generate grammatically valid sentences using the \nLink Grammar database. This natural language generation method far outper-\nforms current state-of-the-art baselines and may serve as the final component in \na proto-AGI question answering pipeline that understandably handles natural lan-\nguage material. \nKeywords: Interpretable Artificial Intelligence, Formal Grammar, Natural Lan-\nguage Generation, Natural Language Processing. \n1 \nIntroduction \n1.1 \nArtificial General Intelligence and Natural Language Processing \nCurrently, the fields of AGI and NLP have little overlap, with few existing AGI archi-\ntectures capable of comprehending natural language and nearly all NLP systems \nfounded upon specialized, hardcoded rules and language-specific frameworks that are \nnot generalizable to the various complex domains of human language [1]. Furthermore, \nwhile some NLP and AGI frameworks do incorporate some form of natural language \nunderstanding, they are still unable to convey knowledge in a form similar to the human \nlanguage without manual, labor-intensive methods such as template-based customiza-\ntion. \n1.2 \nMotivations \nInterpretable Language Processing. Unlike explainable artificial intelligence (XAI), \nwhich refers to methods and techniques in the application of artificial intelligence (AI) \nsuch that the results generated by the AI model can be understood by humans, inter-\n2 \npretable AI (IAI) requires both the AI model itself as well as its results to be under-\nstandable. It contrasts with the concept of “black box” algorithms in machine learning \nwhere even developers cannot explain how the AI arrived at a specific decision. Inter-\npretable language processing (ILP) is an extension of the IAI concept to NLP; ILP is \nexpected to allow for acquisition of natural language, comprehension of textual com-\nmunications, and production of textual messages in a reasonable and transparent way \n[2]. Our natural language generation (NLG) architecture intends to serve as an ILP \nmethod that allows for the generation of grammatically valid sentences in an interpret-\nable manner. Our work not only provides explainable results but also provides an inter-\npretable model for sentence generation, since we rely on Link Grammar which is com-\nprehensible in itself. \nUnsupervised Language Learning. Current methods of grammar learning, such as \ndeep neural networks (DNNs), require extensive supervised training on large corpora. \nHowever, humans are capable of acquiring explainable and reasonable rules of building \nsentences from words based on grammatical rules and conversational patterns and \nclearly understand the grammatical and semantic categories of words. This raises the \nidea of unsupervised language learning (ULL), which enables acquisition of language \ngrammar from unlabeled text corpora programmatically in an unsupervised way. In a \nULL system, the learned knowledge is stored in a human-readable and reasonable rep-\nresentation [2]. Examples of ULL systems include the OpenCog AI platform’s cogni-\ntive pipeline that enables unsupervised grammar learning [3] and Glushchenko et al.’s \ngrammar induction technology that unsupervisedly learns grammar from only a single \ninput corpus [4]. \nThe ULL pipeline consists of five main components: a text pre-cleaner (which pre-\nprocesses corpus files with configurable cleanup and normalization options), a sense \npre-disambiguator (which performs word disambiguation and builds senses from to-\nkens), a text parser (which parses sentences into word tokens or senses), a grammar \nlearner (which learns word categories and rules from parses), and a tester that evaluates \nthe quality of the inferred grammar. The ultimate output of the ULL pipeline is a model \nof the human language; one such model is the Link Grammar dictionary itself, which \nserves as the knowledge base behind our NLG architecture [5]. \nQuestion Answering. Question answering is a computer science discipline within the \nfields of information retrieval and natural language processing concerned with building \nsystems that automatically answer questions posed by humans in a natural language. \nAn explainable question answering pipeline would consist of two main components: \nnatural language comprehension, and natural language generation. Natural language \ncomprehension involves first parsing the question (otherwise known as the input query) \nbased on a formal grammar such as Link Grammar, and then performing semantic in-\nterpretation (extracting the concept represented by the query and determining relation-\nships between individual parts of the parsed query obtained in the previous step). The \nnatural language generation component then involves semantic query execution (deter-\nmining the answer to the input question based on the semantic relationships extracted \nin the previous step) and the use of a formal grammar to construct grammatically valid \n3 \nsentences from the words associated with the semantic relationships derived during \nquery execution [2]. A diagram of the question answering pipeline is shown below. \n \nFig. 1. Question answering workflow \nOur current work is concerned with the final part of the question answering pipeline; \nwith Link Grammar serving as the requisite formal grammar, the proposed NLG archi-\ntecture automates sentence construction from the words derived in the penultimate part \nof the pipeline and thereby enables question answering with minimal to no human in-\nterference. \n1.3 \nLink Grammar \nLink Grammar is founded upon the idea that each word possesses a feature structure \nconsisting of a set of typed connectors and disjuncts associating those connectors. \n4 \nRules, which correspond to lexical entries or grammatical categories, describe a list of \nwords and a set of their defining disjuncts. Generation involves matching up connectors \nfrom one word with connectors from another, given the known set of disjuncts for both \nof them. \nA connector represents either the left or right half of a grammatical link of a given \ntype, and different types of connectors are denoted by letters or pairs of letters like S or \nSX. For instance, if a word A has the connector S+, this means that A can have an S \nlink to its right. If a word B has the connector S-, this means that B can have an S link \nto its left. In this case, if A occurs to the left of B in a sentence, then the two words can \nbe joined together with an S link [1]. The “Link Grammar dictionary,” then, is a data-\nbase that maps all common words of a given language to the connectors that define \nthem. \nDisjuncts are sets of connectors that constitute the legal use of a given word. For \ninstance, if word A has the expression {C-} & (X+ or Y+), where {} denotes optional-\nity, then A has the following four disjuncts: C- X+, X+, C- Y+, Y+. \nMacros are single symbols that define large connector expressions. For instance, let \nthe macro <macro> define the expression {C-} & (X+ or Y+) as above. Then, the ex-\npression <macro> or {W+ & Z-} is simply shorthand for ({C-} & (X+ or Y+)) or {W+ \n& Z-}. Macros are used throughout the Link Grammar dictionary to reduce redundancy \nof connector expressions and increase readability. \nIn Link Grammar notation, a sentence is a set of tokens (words, punctuation, and \nother syntactic structures) that may be linked by matching connectors between pairs of \ntokens. For instance, consider the sentence, “The cat caught a mouse.” The Link Gram-\nmar parse structure for this sentence is: \n \n \nFig. 2. Link Grammar parse of “The cat caught a mouse.” \n \nThe rules of Link Grammar impose additional constraints beyond the matching of \nconnectors, namely the planarity and connectivity metarules. Planarity means that links \ndo not cross, while connectivity means that the links and words of a sentence must form \na connected graph—all the words must be linked to the other words in the sentence via \nat least one path. \nOverall, the structure of grammatical knowledge as stored in Link Grammar appears \ninterpretable, human-readable, and maintainable, including the ability to add new rules \nand amend existing ones based on the intent of a human linguist maintaining the \nknowledge base or a programmatic language learning framework such as the ULL pipe-\nline discussed in Section 1.2 [3, 4]. Our proposed architecture utilizes the English Link \nGrammar dictionaries to perform natural language generation. \n \nLink Grammar Database. The Link Grammar database is comprised of dictionaries \nfor each of more than 10 languages. In this paper, we focus on the English database, \n5 \nwhich includes approximately 1,430 distinct rules that each correspond to word clus-\nters—groups of words with the same sets of grammar properties—and 86,863 word \nforms. Dictionaries may be represented as hierarchical trees of files, where a master \n“.dict” file maps all common words to their defining connector expressions and refer-\nences supporting files that contain additional word clusters or their corresponding rep-\nresentation in a relational database [2]. \nWhy Link Grammar? Besides Link Grammar, other grammar rule dictionaries and \nAPIs exist, such as spaCy1 and Universal Dependencies2 (UD). Solutions such as spaCy \nare programming language-specific APIs or packages; for instance, spaCy restricts its \ngrammar database to applications developed using Python. Moreover, unlike both \nspaCy and UD, which rely on or are structured as dependency grammars that require \nhead-dependent relationships (links must be directional), Link Grammar does not man-\ndate head-dependency. For example, consider the UD parse for the sentence “The dog \nwas chased by the cat.” below, which contains directional links: \n \n \nFig. 3. UD parse of “The dog was chased by the cat.” \n \nAs shown in Fig. 3., each link in the UD parse contains an arrow directed from the \nhead component to the dependent component of the link. Link Grammar makes this \ndirectionality optional and can thereby be applied to a greater variety of sentential forms \n[6, 7]. \nMore importantly, spaCy and similar libraries require grammar rules to be hardcoded \ninto the client architectures for which they are utilized while Link Grammar does not, \nallowing continual updates and enhancement to the Link Grammar database (likely in \nthe form of automated ULL input) without any client-side modifications. The human-\nreadable and editable nature of Link Grammar allows our grammar induction algorithm \nto better serve as an INLP method for the purposes of the NLG task. \n1.4 \nNatural Language Generation \nNatural language generation refers to the process of mapping some representation of \ndata or information (usually semantic and non-linguistic) to a linguistic (grammatically \nand morphologically valid) representation of that information. The task of generating \neven simple sentences demands a large body of knowledge (grammatical, syntactical, \nmorphological, phonological, etc.). One possible way to build this knowledge base is \nto develop an integrated representation of semantic and grammatical knowledge using \nan extended Link Grammar schema—however, while this may be a product of our fu-\nture work, our current NLG architecture is concerned only with generating sentences \nusing the basic Link Grammar database in its current form. \n \n1  https://spacy.io \n2  https://universaldependencies.org/introduction.html \n6 \nOur proposed architecture focuses on the surface realization component of NLG. \nSurface realization refers to a determination of how the underlying content of a text, in \nthe form of a list of words, should be mapped into a sequence of grammatically correct \nsentences [8]. Often, the same content can be expressed in various sentential forms; an \nNLG system must first, determine which of these sentential forms is most appropriate, \nand second, ensure that the resulting sentence is syntactically and morphologically cor-\nrect. \n1.5 \nPrior Work \nWhen considering small application domains with minimal variation, sentence genera-\ntion is relatively simple, and outputs can be specified using templates (Reiter et al., \n1995; McRoy et al., 2003). While templates allow for full control over the quality of \nthe output and avoid the generation of ungrammatical structures, manually constructing \nthem is a tedious and labor-intensive task. Most importantly, however, they do not scale \nwell to applications involving heavy linguistic variation [9]. \nThe KPML system (Bateman, 1997), based on Systemic-Functional Grammar (Hal-\nliday & Matthiessen, 2004), models surface realization as a traversal of a network in \nwhich the ideal route depends on both grammatical and semantic-pragmatic infor-\nmation. However, the high complexity and level of detail of these systems prevents \nthem from being used as “plug-and-play” or “off the shelf” architectures (e.g., Kasper, \n1989). A state-of-the-art example of these “plug-and-play” models is Dathathri et al.’s \nPlug and Play Language Model (PPLM), which combines a pretrained transformer-\nbased language model (LM) with attribute classifiers that allow for controllable text \ngeneration. The flexibility of these attribute classifier combinations that can be plugged \ninto the model (hence the name “plug-and-play”) allow for various manners of guiding \ntext generation and, in turn, a diverse range of NLG applications [10]. \nLian et. al. proposed a natural language generation system via satisfaction of the \nconstraints posed by inverse relations of hypergraph homomorphisms. To perform sur-\nface realization, the proposed OpenCog NLGen software uses the SegSim approach to \ntake an Atom set in need of linguistic expression and match its subsets against a data-\nstore of (sentence, link parse, RelEx relationship set, Atom set) tuples, produced via \napplying OpenCog’s natural language comprehension tools to a corpus of sentences. \nVia this matching, it determines which syntactic structures have been previously used \nto produce relevant Atom subsets. It then pieces together the syntactic structures found \nto correspond to its subsets, thereby forming overall syntactic structures corresponding \nto one or more sentences. The sentence is solved for as a constraint satisfaction problem \nfrom the Atom set semantics [1]. While SegSim processes words unproblematically for \nrelatively simple sentences, it becomes unreliable for sentences involving conjunctions \nor other complex syntactic forms. \nRatnaparkhi proposed three trainable systems for surface natural language genera-\ntion. The first two systems, called NLG1 and NLG2, require a corpus marked only with \ndomain-specific semantic attributes, while the last system, called NLG3, requires a cor-\npus marked with both semantic attributes and syntactic dependency information. All \nsystems attempt to produce a grammatical natural language phrase from a domain-spe-\ncific semantic representation. NLG1 serves a baseline system and uses phrase frequen-\ncies to generate a whole phrase in one step, while NLG2 and NLG3 use maximum \n7 \nentropy probability models to individually generate each word in the phrase. The sys-\ntems NLG2 and NLG3 learn to determine both the word choice and the word order of \nthe phrase [11]. Not only are Ratnaparkhi’s black box NLG systems restricted to certain \ndomain-specific grammar representations, but, as supervised models, they require la-\nbeled training data, thus straying from the goal of building an NLG system that satisfies \nthe concepts of ULL and ULP. \nWen et al. proposed a statistical language generator based on a semantically con-\ntrolled Long Short-term Memory (LSTM) structure. The LSTM generator learns from \nunaligned data by jointly optimizing sentence planning and surface realization using a \nsimple cross entropy training criterion, and language variation is achieved by sampling \nfrom output candidates [12]. However, like Ratnaparkhi’s work, the LSTM structure \ninherently requires large amounts of labeled training data and is a black box algorithm, \nand hence is neither unsupervised nor interpretable. \nFreitag and Roy proposed an NLG technique whereby, without any supervision and \nonly based on unlabeled text, denoising autoencoders are used to construct a sentence \nfrom structured data interpreted as a “corrupt representation” of the desired output sen-\ntence. Freitag and Roy’s model also extends to NLG for unstructured data in that their \ndenoising autoencoder can generalize to unstructured training samples to which noise \nhas previously been introduced [13]. \n2 \nMethodology \nOur NLG architecture consists of two main components: the Loader, and the Generator. \nThe Loader is simply a utility program used by the Generator to store Link Grammar \nin memory; it is not specific to our NLG architecture but rather a tool for loading Link \nGrammar that can be used by any application [2]. Fig. 4. displays the presented NLG \narchitecture, including the workflow of Loader and Generator. \n8 \n \nFig. 4. Overall NLG architecture involving a sentence parsing algorithm (the “Parser”) and \nquestion answering framework built upon the Generator, all relying on the same Link Grammar \ndictionary Loader infrastructure. \n2.1 \nLoader \nThe Loader is responsible for loading and storing the Link Grammar dictionary into \nmemory for future usage [2]. Namely, the Dictionary class stores a list of Word objects, \nwhere each word corresponds to a distinct Rule object; a Rule object may associate \nmultiple Word objects and contains a list of Disjunct objects that each contain a list of \nconnectors constituting the legal use of any of the words that correspond with the given \nrule. Currently, the Loader architecture only supports English and does not handle com-\nplex morphology structures such as those needed to support languages that require \nheavy morphology usage (one such language being Russian). \nThe core of the Loader is the makeDict() function, which converts an array of lines \n(obtained from the Link Grammar database) into an array of Dictionary objects con-\ntaining the rules for all common words and phrases that Link Grammar provides sup-\nport for. The basic framework of makeDict() is as follows: \n \n9 \n \nAlgorithm 1. makeDict() function \n \nAs shown in the above algorithm, makeDict() parses the lines of the Link Grammar \ndatabase to assign rules (within which all macros are expanded) to the words that they \ndefine. After splitting the contents of the Link Grammar database file, the Loader calls \nmakeDict() to obtain the Dictionaries that store the Link Grammar rules for use in the \nGenerator. \n2.2 \nGenerator \nAfter obtaining the loaded Dictionary objects from the Loader, the Generator deter-\nmines what sentences can be formed from a given list of words via valid Link Grammar \nrules. First, given a list of words, the Generator determines a subset of all orderings of \nthose words that satisfies initial checks of the planarity and connectivity metarules (for \nexample, one partial connectivity check that the Generator implements involves ensur-\ning that the first and last words are capable of forming links to the right and left, re-\nspectively). Then, for each ordering in the subset, the Generator determines if that or-\ndering is valid; specifically, it ensures that every pair of consecutive words (with certain \nexceptions as discussed below) can be connected via links part of the Dictionary ob-\njects. To do so, the Generator uses the connects() function, which returns a boolean \n10 \nvalue indicating whether its two parameters, the tokens left and right, can be linked \ntogether: \n \n \nAlgorithm 2. connects() function \n \nAs shown in the above algorithm, connects() first obtains the lists of rules leftList \nand rightList corresponding with left and right, and then checks if any Disjunct in any \nRule in leftList matches with any Disjunct in any Rule in rightList. \nHowever, connects() is not always applicable. For instance, when the determiner “a” \nis present in the phrase “is a human,” the links are not “is” → “a” and “a” → “human” \nbut rather “is” → “human” and “a” → “human” as shown in the Link Grammar parse \nbelow: \n \nFig. 5. Link Grammar parse of “is a human” \n \nHence, functions similar to connects() are implemented that deal with specific cases \ninvolving links not between consecutive words but rather from the far left or far right \nwords to each of the other words in a set of three or more consecutive words. \nA sample surface realization query, along with its result as generated by our NLG \narchitecture, is as follows: \nGENERATE([“mom”, “dad”, “company”, “wants”, “join”, “the”, “to”]) =  \n[“mom wants dad to join the company”, “dad wants mom to join the company”] \nAs seen here, the proposed architecture generates grammatically valid sentences, but \nsuccumbs to the grammatical ambiguity problem described in the following section. \n11 \n3 \nResults \nOur algorithm was tested on two distinct corpora in a total of three different tests. We \nfound that the accuracy of our results was affected primarily by the issue of grammatical \nambiguity, which refers to situations in which the same word may have different roles \nin a sentence (i.e. a noun can be either a subject or an object) or may represent different \nparts of speech (such as the word “saw” in its verb and noun forms). Subject-object \nambiguity, a specific case of grammatical ambiguity, refers to the potential interchange-\nability of the subject and object in a sentence. For instance, consider the sentence “The \ncat caught a mouse” as referenced in 1.3. Both “The cat caught a mouse” and “The \nmouse caught a cat” are grammatically valid sentences that can be constructed from the \nfive words “the,” “cat,”, “caught,” “a,” and “mouse;” the presence of these extra sen-\ntences that are grammatically valid yet contextually wrong skewed the accuracy of our \nalgorithm.  \nGrammatical disambiguation—a solution to the grammatical ambiguity problem—\nrefers to the process of determining which sentential form is most appropriate to repre-\nsent some non-linguistic content; for instance, the sentence “The cat caught a mouse” \nis likely more contextually valid than “The mouse caught a cat.” Semantic (word sense) \ndisambiguation refers to the process of determining which “sense” or meaning of a \nword is activated by the use of the word in a particular context; for instance, the word \n“saw”, when used in the sentence “Mom saw a bird,” will have a different sense—and \nthus different Link Grammar rules—than when it is used in the sentence “The lumber-\njack is holding a saw.” Implementing grammatical and semantic disambiguation will \nbe a product of our future work. \nOur algorithm was primarily tested on 92 sentences with words all part of Singular-\nityNET’s “small world” POC-English corpus.3 For this purpose, we have used a corre-\nsponding “small world” Link Grammar dictionary (automatically inferred from high \nquality Link Grammar parses created by SingularityNET’s ULL pipeline) containing \n42 total words and 5 total word clusters.4 We use the following metrics to evaluate our \nproposed architecture: \n \nArchitecture-Specific Metrics: \n• \nSingle correct generated sentence: the number of times the algorithm generates \na single candidate sentence that exactly matches the reference sentence \n• \nMultiple sentences with one correct: the number of times the algorithm gener-\nates multiple candidate sentences, one of which exactly matches the reference \nsentence \n• \nMultiple sentences with none correct: the number of times the algorithm gen-\nerates multiple candidate sentences, none of which exactly matches the refer-\nence sentence \n• \nNo generated sentences: the number of times the algorithm fails to generate a \ncandidate sentence \n \n3  http://langlearn.singularitynet.io/data/poc-english/poc_english.txt \n4  http://langlearn.singularitynet.io/test/nlp/poc-english_5C_2018-06-\n06_0004.4.0.dict.txt \n12 \n• \nToo many results: the number of times the algorithm generates over 25 candi-\ndate sentences \n• \nAccuracy: the proportion of results within the categories “Single correct gen-\nerated sentence” and “Multiple sentences with one correct” \n \nCanonical NLG Metrics: \n• \nAverage BLEU (Bigram) [14]: BLEU (Bilingual Evaluation Understudy) is \ncalculated by counting the number of matching n-grams in the candidate and \nreference sentences. It is represented as a float between 0 and 1 inclusive, \nwhere values closer to 1 denote more similar texts. Given the short sentence \nlength of SingularityNET’s “small world” corpus, we use the bigram variant \nof BLEU, meaning that n = 2 for the above explanation. \n• \nAverage Word2Vec Cosine Similarity [15]: Word2Vec Cosine Similarity is \ncalculated by first encoding each sentence as a vector, which is accomplished \nusing the RoBERTa sentence transformer [16], and then calculating the cosine \nof the angle, or angular distance, between the vectors. Like BLEU, Word2Vec \nCosine Similarity is represented as a float between 0 and 1 inclusive, where \nvalues closer to 1 denote more similar texts. \n• \nAverage WER [17]: WER (Word Error Rate) is a measure of the Levenshtein \ndistance, or edit distance, for two sentences; in other words, it is a function the \nminimum number of edits (insertions, deletions, or substitutions) required to \nchange the candidate sentence into the reference sentence. WER is calculated \nas (S + D + I)/N, where S is the number of necessary substitutions, D is the \nnumber of deletions, I is the number of insertions, and N is the total number \nof words. It takes on a minimum value of 0 (which means the sentences are \nidentical) and has no maximum value (an arbitrary number of words can be \ninserted into the sentence); values closer to 0 indicate greater similarity. \n• \nAverage TER [18]: TER (Translation Edit Rate) refers to the number of edits \nrequired to make a candidate sentence exactly match its reference sentence in \nfluency and semantics. It is calculated as E/R, where E is the minimum number \nof edits and R is the average length of the reference text. Like WER, its mini-\nmum is 0 but it has no maximum value, and TER scores closer to 0 denote \nmore similar texts. \n \nBy “average,” we mean that the given metric is calculated for each pair of candidate \nand reference sentences and then averaged over the entire corpus. \nTable 1. Results when tested on 92 sentences with words from SingularityNET’s “small world” \ncorpus using ULL-generated grammar. \nMetric \nResult \nArchitecture-Specific Metrics \nSingle correct generated sentence \nMultiple sentences with one correct \nMultiple sentences with none correct \nNo generated sentences \nToo many results \n \n62/92 \n30/92 \n0/92 \n0/92 \n0/92 \n13 \nAccuracy \n1.000 \n \n \nCanonical NLG Metrics \nAverage BLEU (Bigram) \nAverage Word2Vec Cosine Similarity \nAverage WER \nAverage TER \n \n1.000 \n0.988 \n0.246 \n0.082 \n \nWhen tested on the same 92 sentences while using the complete Link Grammar dic-\ntionary for English,5 the algorithm achieved the following results:  \nTable 2. Results when tested on 92 sentences with words from SingularityNET’s “small world” \ncorpus using complete Link Grammar. \n \nMetric \nResult \nArchitecture-Specific Metrics \nSingle correct generated sentence \nMultiple sentences with one correct \nMultiple sentences with none correct \nNo generated sentences \nToo many results \nAccuracy \n \n8/92 \n57/92 \n0/92 \n0/92 \n27/92 \n0.707 \n \n \nCanonical NLG Metrics \nAverage BLEU (Bigram) \nAverage Word2Vec Cosine Similarity \nAverage WER \nAverage TER \n \n0.999 \n0.900 \n3.713 \n0.395 \n \nThe decreased value of the “Single correct generated sentence” metric, increased \nvalue of the “Multiple sentences with one correct” metric, slightly decreased BLEU, \ndecreased Word2Vec Cosine Similarity, increased WER, and increased TER in the sec-\nond test as compared to first test are all direct results of the increased grammatical and \nsemantic ambiguity caused by using Link Grammar instead of SingularityNET’s “small \nworld” grammar. Since the “small world” grammar was created from the “small world” \ncorpus itself, each of the words in the corpus contains no other grammatical or semantic \ncontexts (and thus no other sets of grammar rules) besides those required to form the \n92 sentences that the algorithm was tested on. However, since the Link Grammar data-\nbase is much larger and contains many more “senses” for each word, there is a greater \nnumber of valid sentences that can be constructed from those words, thereby causing a \nmajority of reference sentences previously associated with a single candidate sentence \nin the first test to instead correspond with several candidate sentences in the second test. \n \n5  https://github.com/opencog/link-grammar/tree/master/data/en \n14 \nOur NLG architecture was also tested on 54 sentences part of Charles Keller’s pro-\nduction of Lucy Maud Montgomery’s “Anne’s House of Dreams” as found in the Gu-\ntenberg Children corpus,6 and performed as follows: \nTable 3. Results when tested “Anne’s House of Dreams” using complete Link Grammar. \nMetric \nResult \nArchitecture-Specific Metrics \nSingle correct generated sentence \nMultiple sentences with one correct \nMultiple sentences with none correct \nNo generated sentences \nAccuracy \n \n1/54 \n53/54 \n0/54 \n0/54 \n1.000 \n \n \nCanonical NLG Metrics \nAverage BLEU (Bigram) \nAverage Word2Vec Cosine Similarity \nAverage WER \nAverage TER \n \n0.652 \n0.746 \n5.976  \n1.738 \n \nHere, the decreased BLEU and Word2Vec Cosine Similarity as well as increased \nWER and TER are due to the increase in results satisfying the “Multiple sentences with \none correct” metric. Not only is the proportion of results in this category greater, but \nthe number of candidate sentences generated for each reference sentence is also much \ngreater due to longer average sentence length and the increased number of “senses” per \nword used in the Gutenberg Children corpus, resulting in lower average similarity \nscores and greater average error and edit rates. \nOur NLG architecture outperforms prior work. As a baseline, we implemented a \n(slightly modified) version of the state-of-the-art Transformer model proposed in [19] \nfor the task of sentence reconstruction from randomly shuffled sets of tokens, which \nexactly matches the surface realization task that our proposed NLG algorithm accom-\nplishes (note that the algorithms described in Section 1.5 did not contain publicly avail-\nable code or model schematics and thus could not be used as baselines). The imple-\nmented Transformer, which is built upon spaCy’s English grammar, differs from [19] \nin that it uses a learned positional encoding rather than a static one, label smoothing is \nnot utilized, and a standard Adam optimizer with a static learning rate is used instead \nof one with warm-up and cool-down steps (the reason for making these changes is that \nthe modified Transformer closely matches the majority of current Transformer variants, \nsuch as Bidirectional Encoder Representations from Transformers, or BERT) [20]. This \nbaseline implementation achieved the following results on the “small world” POC-\nEnglish corpus and the “Anne’s House of Dreams” excerpt of the Gutenberg Children \ncorpus: \n \n6  http://langlearn.singularitynet.io/data/cleaned/English/Gutenberg-\nChildrenBooks/capital/pg544.txt \n15 \nTable 4. Baseline results on the POC-English and Gutenberg Children corpora. \nCorpus / Metric \nResult \nPOC-English Corpus \nAverage BLEU (Bigram) \nAverage Word2Vec Cosine Similarity \nAverage WER \nAverage TER \n \n0.747 \n0.722 \n3.114 \n0.505 \n \n \nGutenberg Children Corpus \nAverage BLEU (Bigram) \nAverage Word2Vec Cosine Similarity \nAverage WER \nAverage TER \n \n0.325 \n0.401 \n11.622  \n1.988 \n \nOur NLG architecture, when using complete Link Grammar (and when using Sin-\ngularityNET’s ULL-generated grammar for the POC-English corpus), far outperformed \nthe baseline model in terms of BLEU, Word2Vec Cosine Similarity, and TER; it \nachieves a competitive WER score on the POC-English corpus when using complete \nLink Grammar and a far superior WER score  on the POC-English corpus when using \nthe ULL-generated grammar and on the Gutenberg Children corpus with complete Link \nGrammar. Overall, we find that our proposed architecture outperforms the Trans-\nformer—a ubiquitous state-of-the-art NLG model—and achieves stronger results \nacross the board. \n4 \nConclusion \nOur NLG architecture, when paired with the requisite task-specific NLP algorithms, \nmay be used in a variety of scenarios. It can primarily be applied to the question an-\nswering problem as discussed in 1.2.; one such application is the Aigents Social Media \nIntelligence Platform [21]. Currently, the Aigents framework relies on artificially de-\nsigned controlled language resembling oversimplified “pidgin” English; our proposed \nNLG algorithm can be integrated into the Aigents cognitive architecture to provide Ai-\ngents with full conversational intelligence [22]. In this scenario, natural language text \nwould be produced in a quality higher than that provided by Aigents’ current chatbots \nwhile also being explainable. \nAnother prominent subdomain of question answering in which our NLG architecture \ncan be utilized is that of virtual assistant AI technologies such as Alexa and Google \nHome. The proposed NLG system, if integrated into these technologies in conjunction \nwith the other parts of the question answering pipeline, would serve as an understand-\nable and unsupervised rather than black box NLP framework. \nOur further work will be dedicated to: 1) implementing grammatical and semantic \ndisambiguation based on the context of a sentence or body of text; and 2) extending the \nalgorithm’s generation capabilities to languages other than English (including those that \nrequire heavy morphology usage). \n16 \n5 \nCode Availability \nOur NLG architecture is open-source and available under the MIT License (a permis-\nsive, limited-restriction license) on GitHub at https://github.com/aigents/ai-\ngents-java-nlp. \n \nReferences \n1. \nR. Lian, et. al, “Syntax-Semantic Mapping for General Intelligence: Language Com-\nprehension as Hypergraph Homomorphism, Language Generation as Constraint Satis-\nfaction,” International Conference on Artificial General Intelligence, Springer, Berlin, \nHeidelberg, pp. 158-167, December 2012. \n2. \nV. Ramesh and A. Kolonin, “Interpretable Natural Language Segmentation Based on \nLink Grammar,” 2020 Science and Artificial Intelligence conference (S.A.I.ence), No-\nvosibirsk, Russia, 2020, pp. 25-32, doi: 10.1109/S.A.I.ence50533.2020.9303220. \n3. \nA. Glushchenko, et al., “Unsupervised Language Learning in OpenCog,” 11th Inter-\nnational Conference on Artificial General Intelligence, AGI 2018, Prague, Czech Re-\npublic, pp. 109–118, July 2018. \n4. \nA. Glushchenko, et al., “Programmatic Link Grammar Induction for Unsupervised \nLanguage Learning,” Artificial General Intelligence, Springer, Berlin, Heidelberg, pp. \n111-120, July 2019. \n5. \nD. Sleator and D. Temperley, “Parsing English with a Link Grammar,” in Proceedings \nof the Third International Workshop on Parsing Technologies. Association for Com-\nputational Linguistics, 1993, pp. 277–292. \n6. \nLink Grammar Bibliography, https://www.link.cs.cmu.edu/link/papers/index.html. \nLast accessed 18 April 2021. \n7. \nAn Introduction to the Link Grammar Parser, http://www.abisource.com/projects/link-\ngrammar/dict/introduction.html. Last accessed 18 April 2021. \n8. \nC. Mellish and R. Dale, “Evaluation in the context of natural language generation,” \nComputer Speech and Language, vol. 10, no. 2, pp. 349–373, October 1998. \n9. \nA. Gatt and E. Krahmer, “Survey of the State of the Art in Natural Language Genera-\ntion: Core tasks, applications and evaluation,” Journal of AI Research (JAIR), vol. 61, \npp. 75-170, March 2018. \n10. S. Dathathri, et al., “Plug and Play Language Models: A Simple Approach to Con-\ntrolled Text Generation.,” arXiv:1912.02164 [cs.CL], March 2020. \n11. A. Ratnaparkhi, “Trainable Methods for Surface Natural Language Generation,” arXiv \nComputing Research Repository (CoRR), pp. 194–201, June 2000. \n12. T. Wen, et al., “Semantically Conditioned LSTM-based Natural Language Generation \nfor Spoken Dialogue Systems,” in Proceedings of the 2015 Conference on Empirical \nMethods in Natural Language Processing. Association for Computational Linguistics, \npp. 1711–1721, August 2015. \n13. M. Freitag and S. Roy, “Unsupervised Natural Language Generation with Denoising \nAutoencoders,” arXiv:1804.07899 [cs.CL], August 2018. \n14. K. Papineni, et al., “Bleu: A Method for Automatic Evaluation of Machine Transla-\ntion,” in Proceedings of the 40th Annual Meeting of the Association for Computational \nLinguistics. Association for Computational Linguistics, pp. 311–318, 2002. \n15. P. Sitikhu, et al., “A Comparison of Semantic Similarity Methods for Maximum Hu-\nman Interpretbility,” arXiv:1910.09129 [cs.IR], October 2019. \n17 \n16. Y. Liu, et al., “RoBERTa: A Robustly Optimized BERT Pretraining Approach,” \narXiv:1907.11692 [cs.CL], July 2019. \n17. D. Klakow and J. Peters, “Testing the Correlation of Word Error Rate and Perplexity,” \nSpeech Communication, pp. 19–28, September 2002. \n18. M. Snover, et al., “A Study of Translation Edit Rate with Targeted Human Annota-\ntion,” in Proceedings of Association for Machine Translation in the Americas, pp. 223–\n231, 2006. \n19. A. Vaswani, et al., “Attention Is All You Need,” arXiv:1706.03762 [cs.CL], December \n2017. \n20. J. Devlin, et al., “BERT: Pre-Training of Deep Bidirectional Transformers for Lan-\nguage Understanding,” arXiv:1810.04805 [cs.CL], May 2019. \n21. A. Kolonin, “Personal Analytics for Societies and Businesses: With Aigents Online \nPlatform,” 2017 International Multi-Conference on Engineering, Computer and Infor-\nmation Sciences (SIBIRCON), Novosibirsk, pp. 272-275, September 2017. \n22. A. Kolonin, “Controlled Language and Baby Turing Test for General Conversational \nIntelligence,” arXiv:2005.09280 [cs.AI], May 2020. \n",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "published": "2021-04-19",
  "updated": "2021-04-19"
}