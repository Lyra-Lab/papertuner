{
  "id": "http://arxiv.org/abs/2105.07636v2",
  "title": "DOC3-Deep One Class Classification using Contradictions",
  "authors": [
    "Sauptik Dhar",
    "Bernardo Gonzalez Torres"
  ],
  "abstract": "This paper introduces the notion of learning from contradictions (a.k.a\nUniversum learning) for deep one class classification problems. We formalize\nthis notion for the widely adopted one class large-margin loss, and propose the\nDeep One Class Classification using Contradictions (DOC3) algorithm. We show\nthat learning from contradictions incurs lower generalization error by\ncomparing the Empirical Rademacher Complexity (ERC) of DOC3 against its\ntraditional inductive learning counterpart. Our empirical results demonstrate\nthe efficacy of DOC3 compared to popular baseline algorithms on several\nreal-life data sets.",
  "text": "DOC3 - Deep One Class Classiﬁcation using Contradictions\nSauptik Dhar 1 Bernardo Gonzalez Torres 2\nAbstract\nThis paper introduces the notion of learning\nfrom contradictions (a.k.a Universum learning)\nfor deep one class classiﬁcation problems. We\nformalize this notion for the widely adopted one\nclass large-margin loss (Sch¨olkopf et al., 2001),\nand propose the Deep One Class Classiﬁcation us-\ning Contradictions (DOC3) algorithm. We show\nthat learning from contradictions incurs lower\ngeneralization error by comparing the Empiri-\ncal Rademacher Complexity (ERC) of DOC3\nagainst its traditional inductive learning counter-\npart. Our empirical results demonstrate the ef-\nﬁcacy of DOC3 compared to popular baseline\nalgorithms on several real-life data sets.\n1. Introduction\nAnomaly Detection (AD) is one of the most widely re-\nsearched problem in the machine learning community\n(Chandola et al., 2009).\nIn its basic form, the task of\nAnomaly Detection (AD) involves discerning patterns in\ndata that do not conform to expected ‘normal’ behavior.\nThese non-conforming patterns are referred to as anomalies\nor outliers. Anomaly detection problems manifest in several\nforms in real-life like, defect detection in manufacturing\nlines, intrusion detection for cyber security, or pathology\ndetection for medical diagnosis etc. There are several mech-\nanisms to handle anomaly detection problems viz., paramet-\nric or non-parametric statistical modeling, spectral based,\nor classiﬁcation based modeling (Chandola et al., 2009).\nOf these, the classiﬁcation based approach has been widely\nadopted in literature (Scholkopf et al., 2002; Tax & Duin,\n2004; Tan et al., 2016; Cherkassky & Mulier, 2007). One\nspeciﬁc classiﬁcation based formulation which has gained\nhuge adoption is one class classiﬁcation (Scholkopf et al.,\n2002; Tax & Duin, 2004), where we design a parametric\nmodel to estimate the support of the ‘normal’ class distribu-\ntion. The estimated model is then used to detect ‘unseen’\n1Independent, Santa Clara, CA, USA 2Intuition Machines, Inc.,\nSan Francisco, CA, USA. Correspondence to: Sauptik Dhar <saup-\ntik.dhar@gmail.com>.\nCopyright 2021 by the author.\nabnormal samples.\nWith the recent success of deep learning based approaches\nfor different machine learning problems, there has been a\nsurge in research adopting deep learning for one class prob-\nlems (Ruff et al., 2021; Pang et al., 2020; Chalapathy &\nChawla, 2019). However, most of these works adopt an\ninductive learning setting. This makes the underlying model\nestimation data hungry, and perform poorly for applications\nwith limited training data availability, like medical diagnosis,\nindustrial defect detection, etc. The learning from contra-\ndictions paradigm (popularly known as Universum learning)\nhas shown to be particularly effective for problems with\nlimited training data availability (Vapnik, 2006; Sinz et al.,\n2008; Weston et al., 2006; Chen & Zhang, 2009; Cherkassky\net al., 2011; Shen et al., 2012; Dhar & Cherkassky, 2015;\nZhang & LeCun, 2017; Xiao et al., 2021). However, it has\nbeen mostly limited to binary or multi class problems. In\nthis paradigm, along with the labeled training data we are\nalso given a set of unlabeled contradictory (a.k.a universum)\nsamples. These universum samples belong to the same ap-\nplication domain as the training data, but are known not to\nbelong to any of the classes. The rationale behind this set-\nting comes from the fact that even though obtaining labels is\nvery difﬁcult, obtaining such additional unlabeled samples\nis relatively easier. These unlabeled universum samples act\nas contradictions and should not be explained by the esti-\nmated decision rule. Adopting this to one class problems is\nnot straight forward. A major conceptual problem is that,\none class model estimation represents unsupervised learn-\ning, where the notion of contradiction needs to be redeﬁned\nproperly. In this paper,\n1. Deﬁnition We introduce the notion of ‘Learning from\ncontradictions’ for one class problems (Deﬁnition 3.1).\n2. Formulation We analyze the popular one class hinge\nloss (Sch¨olkopf et al., 2001), and extend it under uni-\nversum settings to propose the Deep One Class Classi-\nﬁcation using contradictions DOC3 algorithm.\n3. Generalization Error We analyze the generalization\nperformance of one class formulations under inductive\nand universum settings using Rademacher complexity\nbased bounds, and show that learning under the uni-\nversum setting can provide improved generalization\ncompared to its inductive counterpart.\n4. Empirical Results Finally, we provide an exhaustive\narXiv:2105.07636v2  [cs.LG]  23 May 2022\nTitle Suppressed Due to Excessive Size\nset of empirical results in support of our formulation.\n2. One class learning under inductive settings\nFirst we introduce the widely adopted inductive learning\nsetting used for one class problems (Scholkopf et al., 2002;\nCherkassky & Mulier, 2007).\nDeﬁnition 2.1. (Inductive Setting)\nGiven i.i.d training\nsamples from a single class T = (xi, yi = +1)n\ni=1 ∼\nDn\nX|Y=+1, with x ∈X ⊆ℜd and y ∈Y = {−1, +1};\nestimate a hypothesis h∗: X →Y from an hypothesis class\nH which minimizes,\ninf\nh∈H EDT [1y̸=h(x)]\n(1)\nDT is the training distribution (consisting of both classes)\nDX|Y=+1 is class conditional distribution\n1(·) is the indicator function, and\nEDT (·) is the expectation under training distribution.\nNote that, the underlying data generation process assumes\na two class problem; of which the samples from only one\nclass is available during training. The overall goal is to\nestimate a model which minimizes the error on the future\ntest data, containing samples from both normal (y = +1)\nand abnormal classes (y = −1). Typical examples include,\nAI driven visual inspection of product defects in a man-\nufacturing line; where images or videos of non-defective\nproducts are available in abundance. The goal is to detect\n‘defective’ (abnormal / anomalous) products through visual\ninspection in manufacturing lines (Bergmann et al., 2019;\nWeimer et al., 2016). A popular loss function used in such\nsettings is the ν-SVM loss (Sch¨olkopf et al., 2001),\nmin\nw,ξ,ρ\n1\n2||w||2\n2 +\n1\nνn\nn\nX\ni=1\nξi −ρ\n(2)\ns.t.\nw⊤φ(xi) ≥ρ −ξi,\nξi ≥0;\n∀i = 1 . . . n\nwhere, ν ∈(0, 1] is a user-deﬁned parameter which con-\ntrols the margin errors P\ni ξi and the size of geometric\n1\n||w|| and functional ρ margins.\nφ(·) : X\n→G is a\nfeature map. Typical examples include an empirical ker-\nnel map (see Deﬁnition 2.15 (Scholkopf et al., 2002)) or\na map induced by a deep learning network (Goodfellow\net al., 2016).\nThe ﬁnal decision function is given as,\nh(x) =\n\u001a\n+1;\nif w⊤φ(xi) ≥ρ\n−1;\nelse\n.\nNote that, recent\nworks like (Ruff et al., 2018) extend a different loss func-\ntion which uses a ball to explain the support of the data\ndistribution following (Tax & Duin, 2004). As discussed in\n(Sch¨olkopf et al., 2001), most of the time these two formula-\ntions yield equivalent decision functions. For example, with\nkernel machines K(x, x′) = φ(x)⊤φ(x′) depending solely\non x−x′ (like RBF kernels), these two formulations are the\nsame. Hence, most of the improvements discussed in this\nwork translates to such alternate formulations. In this paper\nhowever, we solve the following one class Hinge Loss,\nmin\nw\n1\n2||w||2\n2 + C LT (w, {φ(xi)}n\ni=1)\n(3)\nLT (w, {φ(xi)}n\ni=1) =\nn\nX\ni=1\n[1 −w⊤φ(xi)]+ ; [x]+ = max(0, x)\nto estimate the the decision function f(x) = w⊤φ(xi) and\nuse the decision rule, h(x) =\n\u001a +1;\nif f(x) ≥1\n−1;\nelse\n. Here,\nthe user-deﬁned parameter C controls the trade-off between\nexplaining the training samples (through small margin error\nPn\ni=1 ξi), and the margin size (through ||w||2\n2), which in\nturn controls the generalization error. For deep learning\narchitectures we optimize using all the model parameters\nand equivalently regularize the entire matrix norm ||W||2\nF ,\nsee (Goyal et al., 2020; Ruff et al., 2018). Note that, we\nsolve one class Hinge loss (3) for the two main reasons,\n– First, it has the advantage that LT (w, φ({x}n\ni=1)) =\nPn\ni=1[1−wT φ(xi)]+ exhibits the same form as the tra-\nditional hinge loss used for binary classiﬁcation prob-\nlems (Vapnik, 2006) and can be easily solved using\nexisting software packages (Paszke et al., 2019; Abadi\net al., 2016; Pedregosa et al., 2011). Throughout the\npaper we refer (3) using underlying deep architectures\nas Deep One Class DOC (Hinge) formulation.\n– Second, solving (3) also provides the solution for (2).\nThis connection follows from Proposition 2.2.\nProposition 2.2. Connection between (2) and (3)\ni Any solution w of (3) also solves (2) with ν =\n1\nCnδ;\nwhere δ > 0 is a scalar that depends on the solution\nof (3). Further, this solution (ˆw, ρ) of (2) is given as\nˆw = wδ, ρ = δ.\nii The decision function obtained through solving (3) i.e.,\nw⊤φ(x) −1 = 0 coincides with the decision function\nˆw⊤φ(x) −ρ = 0 obtained by solving (2) using (i).\nAll proofs are provided in Appendix.\n3. One class learning using Contradictions\na.k.a Universum Learning\n3.1. Problem Formulation\nLearning from contradictions or Universum learning was\nintroduced in (Vapnik, 2006) for binary classiﬁcation prob-\nlems to incorporate a priori knowledge about admissible\ndata samples. For example, if the goal of learning is to\ndiscriminate between handwritten digits ‘5’ and ‘8’, one\ncan introduce additional knowledge in the form of other\nTitle Suppressed Due to Excessive Size\nFigure 1. Visual inspection of anomalous screws in a manufactur-\ning line (Bergmann et al., 2019). Images of the other products act\nas universum samples. Such images are neither normal - screw nor\nanomalous-screw images and act as contradictions.\nhandwritten letters ‘a’,‘b’,‘c’,‘d’,. . . ‘z’. These examples\nfrom the Universum contain certain information about the\nhandwritten styles of authors, but they cannot be assigned\nto any of the two classes (5 or 8). Further, these Universum\nsamples do not have the same distribution as labeled training\nsamples. In this work we introduce the notion of ‘Learning\nfrom Contradictions’ for one class problems. Similar to\ninductive setting (Deﬁnition 2.1) the goal here is also to\nminimize the generalization error on future test data contain-\ning both normal (y = +1) and abnormal (y = −1) samples.\nHere however, during training in addition to the samples\nfrom the normal class (xi, yi = +1)n\ni=1, we are also pro-\nvided with universum (contradictory) samples, which are\nknown not to belong to either of the (normal or abnormal)\nclasses of interest. A practical use-case can be of automated\nvisual inspection based anomaly detection in manufacturing\nlines. Here the target is to identify the defects in a speciﬁc\nproduct type (say ’screws’ in Fig. 1). For this case, the im-\nages from other product types in the manufacturing line act\nas universum samples. Note that, such universum samples\nbelong to the same application domain (i.e. visual inspec-\ntion data); but do not represent either of the classes normal\nscrews or anomalous screws. This setting is formalized as,\nDeﬁnition 3.1. (Learning from Contradictions a.k.a Uni-\nversum Setting) Given i.i.d training samples T = (xi, yi =\n+1)n\ni=1 ∼Dn\nX|Y=+1, with x ∈X\n⊆ℜd and y ∈\nY\n= {−1, +1} and additional m universum samples\nU = (x∗\ni′)m\ni′=1 ∼DU with x∗∈X ∗\nU ⊆ℜd, estimate\nh∗: X →Y from hypothesis class H which, in addition to\neq. (1), obtains maximum contradiction on universum sam-\nples i.e. maximizes the following probability for x∗∈X ∗\nU,\nsup\nh∈H\nPDU [h(x∗) /∈Y] = sup\nh∈H\nEDU [1{ T\ny∈Y\nh(x∗)̸=y}]\n(4)\nDU is the universum distribution,\nPDU (·) is probability under universum distribution,\nEDU (·) is the expectation under universum distribution, X ∗\nU\nis the domain of universum data.\nLearning using contradictions under Universum setting has\nthe dual goal of minimizing the generalization error in (1)\nwhile maximizing the contradiction on universum samples\n(4). The following proposition provides guidelines on how\nthis can be achieved for the one class hinge loss in (3).\nProposition 3.2. For the one class hinge loss in (3), maxi-\nmum contradiction on universum samples x∗∈X ∗\nU can be\nachieved when,\n|w⊤φ(x∗) −1| = 0\n(5)\nThat is, we need the universum samples to lie on the decision\nboundary. This motivates the following one class loss using\ncontradictions (under Universum settings) where we relax\nthe constraint in (5) by introducing a ∆−insensitive loss\nsimilar to (Weston et al., 2006; Dhar et al., 2019) and solve,\nmin\nw\n1\n2||w||2\n2 + C LT (w, φ({xi}n\ni=1))\n+ CU LU(w, φ({x∗\ni′}m\ni′=1))\n(6)\ns.t.\nLT (w, φ({x}n\ni=1)) =\nn\nX\ni=1\n[1 −w⊤φ(xi)]+\nLU(w, φ({x∗\ni′}m\ni′=1)) =\nm\nX\ni′=1\n[|1 −w⊤φ(x∗\ni′)| −∆]+\nHere, [x]+ = max(0, x). Further, the interplay between\nC, CU−controls the trade-off between explaining the train-\ning samples using LT vs. maximizing the contradiction on\nUniversum samples using LU. For CU = 0 or ∆→∞, (6)\ntransforms to (3). For deep learning models, we optimize\n(6) over all the model parameters and refer to it as Deep\nOne Class Classiﬁcation using Contradictions (DOC3).\n3.2. Analysis of Generalization Error bound\nNext we provide theoretical justiﬁcation in support of Uni-\nversum learning. We argue, learning under universum set-\ntings using DOC3 can provide improved generalization error\ncompared to its inductive counterpart DOC (Hinge). For\nthis, we ﬁrst derive a generic form of the generalization\nerror bound for one class learning using the Rademacher\ncomplexity capacity measure in Theorem 3.3.\nTheorem 3.3. (Generalization Error Bound) Let F be\nthe class of functions from which the decision function f(x)\nin eq. (3) and (6) are estimated. Let Rf,1 = {x : f(x) ≥1}\nbe the induced decision region. Then, with probability 1 −η\nwith η ∈[0, 1], over any independent draw of the random\nsample T = (xi, yi = +1)n\ni=1 ∼Dn\nT |Y=+1, for any κ > 0\nTitle Suppressed Due to Excessive Size\nwe have,\nPDT |Y=+1(x /∈Rf,1−κ) ≤\n1\nκn\nn\nX\ni=1\nξi + 2\nκ\nˆRn(F)\n+ 3\ns\nln 2\nη\n2n\n(7)\nwhere,\nξi = [1 −f(x)]+ ; Rf,θ = {x : f(x) ≥θ}\nˆRn(F) = Eσ[sup\nf∈F\n| 2\nn\nPn\ni=1 σif(xi)|\n\f\f\f(xi)n\ni=1]\nσ = independent uniform {±1}−valued random variables\na.k.a Rademacher variables.\nThe Theorem 3.3 is agnostic of model parameterization\nand holds for any popularly adopted kernel machine or\ndeep learning architectures. Similar to the Theorem 7 in\n(Sch¨olkopf et al., 2001), Theorem 3.3 gives a probabilistic\nguarantee that new points lie in a larger region Rf,1−κ.\nHere, we rather use the Empirical Rademacher Complexity\n(ERC) ˆRn(F) as the capacity measure of the hypothesis\nclass, instead of the covering number. Additionally, our\nbound does not contain a\n1\nκ2 term as in (Sch¨olkopf et al.,\n2001), and only has the scaling factor of 1\nκ. As seen from\nTheorem 3.3 above, it is preferable to use a hypothesis class\nF with smaller ERC ˆRn(F). Next we compare the ERC of\nthe hypothesis class induced by the formulations (3) vs. (6).\nTheorem 3.4. (Empirical Rademacher Complexity).\nFor the hypothesis class induced by the formulations,\n– Eq. (3) : Find = {f : x →w⊤φ(x)\n\f\f\f||w||2\n2 ≤Λ2}\n– Eq. (6) : Funiv = {f : x →w⊤φ(x)\n\f\f\f||w||2\n2 ≤\nΛ2; |w⊤φ(x∗) −1| ≤∆, ∀x∗∈X ∗\nU}\nThe following holds,\n(a) ˆRn(Find) ≥ˆRn(Funiv)\n(b) Further, for any ﬁxed mapping φ(·), ∀γ ≥0 we have,\n(i) ˆRn(Find) ≤2Λ\nn\ns\nnP\ni=1\n||zi||2; where z = φ(x)\n(ii) ˆRn(Funiv) ≤2Λ\nn\ns\nnP\ni=1\n||zi||2 min\nγ≥0 K(γ)\n\u0002\n1−Σ(γ)\n\u0003 1\n2\nwhere, K(γ) =\n\u0002\n1 + 2γm(∆2 + 1)\nΛ2\n\u0003 1\n2\n(8)\nΣ(γ) = γ\ntr(V Z⊤ZV ⊤)\n\u0002\ntr(Z⊤Z)\n\u0003 \u0002\ntr(I + γV V ⊤)\n\u0003\n(9)\nZ =\n\n\n(z1)T\n...\n(zn)T\n\nand V =\n\u0014\n1\n−1\n\u0015\n⊗\n\n\n(u1)T\n...\n(um)T\n\n\nu = φ(x∗);\nx∗∈X ∗\nU\n⊗= Kronecker Product,\ntr = Matrix Trace\nNote that, several recent works (Neyshabur et al., 2015;\nSokolic et al., 2016; Cortes et al., 2017) derive the ERC of\nthe function class induced by an underlying neural architec-\nture. In this analysis however, we ﬁx the feature map and\nanalyze how the loss function in (6) reduces the function\nclass capacity compared to (3). This simpliﬁes our analysis\nand focuses on the effect of the proposed new loss in (6)\nunder the universum setting. As seen from Theorem 3.4\n(a), the function class induced under the universum setting\n(using contradictions) exhibits lower ERC compared to that\nunder inductive settings. A more explicit characterization\nof the ERC is provided in part (b). Setting γ = 0 in (ii),\nwe achieve the same R.H.S as (i); hence the R.H.S in (ii)\nis always smaller than in (i). Further note that Σ(γ) in (9)\nhas the form of a correlation matrix between the training\nand universum samples in the feature space. In fact, we\nhave Σ(∞) = lim\nγ→∞Σ(γ) =\ntr(V Z⊤ZV ⊤)\ntr(Z⊤Z) tr(V V ⊤). This shows\nthat, for a ﬁxed number of universum samples m and ∆, the\neffect of the DOC3 algorithm is inﬂuenced by the correla-\ntion between training and universum samples in the feature\nspace. Loosely speaking, the DOC3 algorithm searches for\na solution where in addition to reducing the margin errors\nξi, also minimizes this correlation; and by doing so min-\nimizes the generalization error. Similar conclusions have\nbeen empirically derived for binary, multiclass problems in\n(Weston et al., 2006; Chapelle et al., 2008; Cherkassky et al.,\n2011; Dhar et al., 2019). Here, we provide the theoretical\nreasoning for one class problems. Further, we conﬁrm these\ntheoretical ﬁndings in our results (Section 5.2.3).\n3.3. Algorithm Implementation\nA limitation in solving (6) is handling the absolute term\nin LU. In this paper we adopt a similar approach used in\n(Weston et al., 2006; Dhar et al., 2019) and simplify this\nby re-writing LU as a sum of two hinge functions. To do\nthis, for every universum sample x∗\ni′ we create two artiﬁcial\nsamples, (x∗\ni′, y∗\ni′1 = 1), (x∗\ni′, y∗\ni′2 = −1) and re-write,\nLU =\nm\nX\ni′=1\n[|1 −w⊤φ(x∗\ni′)| −∆]+\n(10)\n=\nm\nX\ni′=1\n\u0010\n[ϵ1 −y∗\ni′1w⊤φ(x∗\ni′)]+ + [ϵ2 −y∗\ni′2w⊤φ(x∗\ni′)]+\n\u0011\nwhere, ϵ1 = 1 −∆and ϵ2 = −1 −∆. Now, the universum\nloss is the sum of two hinge functions with ϵ1, ϵ2−margins;\nand can be solved using standard deep learning libraries\n(Paszke et al., 2019; Abadi et al., 2016; Pedregosa et al.,\n2011).\n4. Existing Approaches and Related Works\nMost research in Anomaly Detection (AD) can be broadly\ncategorized as adopting either traditional (shallow) or the\nTitle Suppressed Due to Excessive Size\nmore modern deep learning based approaches. Traditional\napproaches generally adopt parametric or non-parametric\nstatistical modeling, spectral based, or classiﬁcation based\nmodeling (Chandola et al., 2009). Typical examples include,\nPCA based methods (Jolliffe, 2002; Hoffmann, 2007), prox-\nimity based methods (Knorr et al., 2000; Ramaswamy et al.,\n2000), tree-based methods like Isolation Forest (IF) (Liu\net al., 2008), or classiﬁcation based OC-SVM (Sch¨olkopf\net al., 2001), Support Vector Data Description (SVDD) (Tax\n& Duin, 2004) etc. These techniques provide good per-\nformance for optimally tuned feature map. However, for\ncomplex domains like vision or speech, where designing\noptimal feature maps is non trivial; such approaches per-\nform sub-optimally. A detailed survey on these approaches\nis available in (Chandola et al., 2009).\nIn contrast, for the modern deep learning based approaches,\nextracting the optimal feature map is imbibed in the learning\nprocess. Broadly there are three main sub-categories for\ndeep learning based AD. First, the Deep Auto Encoder and\nits variants like DCAE (Masci et al., 2011; Makhzani & Frey,\n2014) or ITAE (Huang et al., 2019a) etc. Here, the aim is to\nbuild an embedding where the normal samples are correctly\nreconstructed while the anomalous samples exhibit high\nreconstruction error. The second type of approach adopt\nGenerative Adversarial Network (GAN) - based techniques\nlike AnoGAN (Schlegl et al., 2017), GANomaly (Akcay\net al., 2018), EGBAD (Zenati et al., 2018), CBiGAN (Car-\nrara et al., 2020) etc. These approaches, typically focus on\ngenerating additional samples which follow similar distribu-\ntion as the training data. This is followed up by designing an\nanomaly score to discriminate between normal vs. anoma-\nlous samples. Finally, the third category consist of the more\nrecent one class classiﬁcation based approaches like, DOCC\n(Ruff et al., 2018), DROCC (Goyal et al., 2020) etc. These\napproaches adopt solving a one class loss function catered\nfor deep architectures. All these above approaches however\nadopt an unsupervised inductive learning setting. There is a\nnewer class of classiﬁcation based paradigm which adopts\nsemi or self supervised formulations. Typical examples in-\nclude, GOAD (Bergman & Hoshen, 2020), SSAD (Ruff\net al., 2019), ESAD (Huang et al., 2020) etc. However, such\napproaches use fundamentally different problem settings\n(like a multi class problem for GOAD); or have different\nassumptions on the additional data available.\nLearning with disjoint auxiliary (DA) data A recently\npopularized new learning setting assumes the availability\nof an additional auxiliary data which is disjoint from the\ntest set. The underlying assumption is that these auxiliary\nsamples may or may not follow the same distribution as the\ntest data and are disjoint from test set. This idea was ﬁrst in-\ntroduced in (Dhar, 2014) (see Section 4.3) and misconstrued\nas Universum learning. Note that, the notion of universum\nsamples was originally introduced to act as contradictions to\nthe concept classes in the test set (Vapnik, 2006). The above\nassumption does not adhere to this notion and violates the\ntrue essence of Universum learning. This setting has been\nrecently used to propose ‘outlier exposure’ in (Hendrycks\net al., 2018) and variants (Ruff et al., 2021), (Goyal et al.,\n2020). Our learning from contradiction setting is different\nfrom the above methods in the following aspects,\n• (Problem Setting) is different. While the above setting\nonly assumes disjoint auxiliary data from test set, Uni-\nversum follows a different assumption that the concept\nclasses of the universum data is different from both the\nnormal as well as anomalous samples. This assumption\nis quintessential for proving Prop. 3.2, which in turn pro-\nvides the optimality constraint on the decision function\n(in eq. (5)). Prop. 2 is not possible for DA setting.\n• (Formulation) The difference in problem setting is also\nclear from the formulations. For example, the formula-\ntions proposed under the disjoint auxiliary setting like,\n(Dhar, 2014), Outlier Exposure (OE) (Hendrycks et al.,\n2018) or DROCC-LF (Goyal et al., 2020) only uses the\nrelation between in-lier training data and the additional\nauxiliary data. No information on the relation between\nthe auxiliary data and the anomalous samples in test set\nis encoded in the loss function. In essence, such ap-\nproaches controls the complexity of hypotheses class by\nconstraining the space in which ‘normal’ samples can lie.\nIn contrast, Universum learning assumes different concept\nclasses for Universum vs. both normal and anomalous\n(test) samples. This information is encoded through the\nproof in Prop. 3.2. The Universum setting controls the\ncomplexity of hypotheses class by constraining the space\nin which both ‘normal’ or ‘anomalous’ samples can lie.\nIn short, Universum learning adopts a different learning\nparadigm (see Deﬁnition 3.1) compared to the ‘disjoint\nauxiliary data’ settings. Different from the existing ‘dis-\njoint auxiliary’ based loss functions in (Dhar, 2014), OE\n(Hendrycks et al., 2018), DROCC-LF (Goyal et al., 2020)\netc., the Universum samples (in (6)) implicitly contradicts\nthe unseen anomalous test samples. A pedagogical explana-\ntion of the differences between these settings with examples\nis provided in Appendix C.1.\n5. Empirical Results\n5.1. Standard Benchmark on CIFAR-10\n5.1.1. DATA SET AND EXPERIMENT SETUP\nFor our ﬁrst set of experiments we use the standard bench-\nmark using the CIFAR-10 (Ruff et al., 2018; Goyal et al.,\n2020). The data consists of 32x32 colour images of 10\nclasses with 6000 images per class. The classes are mu-\ntually exclusive. The underlying task involves one-vs-rest\nanomaly detection, where we build a one class classiﬁer\nTitle Suppressed Due to Excessive Size\nFigure 2. Random\nnoise\nUniversum (contradictions)\n.\nfor each class and evaluate it\non the test data for all the 10-\nclasses. Note that, this data\ndoes not have any naturally oc-\ncurring universum (contradic-\ntion) samples (following Def.\n3.1). So, we use synthetic uni-\nversum samples by randomly\ngenerating the pixel values as\n∼N(µ, σ), with µ = 0, σ = 1; where N is the normal\ndistribution (see Fig. 2). The idea of generating synthetic\nuniversum (contradiction) samples has been previously stud-\nied for binary (Weston et al., 2006; Cherkassky et al., 2011;\nSinz et al., 2008), multiclass (Zhang & LeCun, 2017; Dhar\net al., 2019) and regression (Dhar & Cherkassky, 2017)\nproblems. In this paper we use such a similar mechanism\nfor one class problems. Note that for the one-vs-rest AD\nproblem, the generated universum samples do not belong to\neither ‘+1’ (normal) or ‘-1’ (anomalous) class used during\ntesting (see Def. 3.1).The data is scaled in range [−1, +1].\nFor this set of experiments we adopt a LeNet like archi-\ntecture used in (Ruff et al., 2018; Goyal et al., 2020). The\ndetailed architecture speciﬁcs is provided in Appendix B.1.1.\nNote that, this paper focuses on the design and analysis of\nthe DOC3 loss ((6)). Here rather than adopting a state-of-the-\nart network architecture optimized for the speciﬁc dataset;\nwe adopt a systematic approach to isolate the effectiveness\nof the proposed loss by using a basic LeNet architecture\nsimilar to (Ruff et al., 2018; Goyal et al., 2020). This avoids\nsecondary generalization effects encoded in most advanced\narchitectures. To that end, the approaches in (Ruff et al.,\n2018; Goyal et al., 2020) and their OE extensions serve as\nthe main baselines. We run the experiments over 10 runs.\n5.1.2. RESULTS\nTable 1 provides the average ± standard deviation of the\nAUC under the ROC curve over 10 runs of the experiment.\nHere, we report the results of the best performing DOC\n(Hinge in (3)) model selected over the range of parameters\nλ = 1/2C = [1.0, 0.5] and that for DOC3 over the range\nof parameters λ = 1/2C = [0.1, 0.05], CU/C = [1.0, 0.5].\nThrough out the paper we ﬁx ∆= 0. A more detailed\ndiscussion on model selection and the selected model pa-\nrameters is provided in Appendix B.2. Moreover, for a more\nthorough comparison we also include the results of the DOC\nusing Hinge loss extended under the Disjoint Auxiliary (DA)\nor Outlier Exposure (OE) setting. Throughout the paper, as\nan exemplar for the DA/OE setting; we use the additional\nuniversum samples as belonging to the negative class fol-\nlowing (Goyal et al., 2020). In addition we also report the\nbenchmark results for both shallow and deep learning meth-\nods provided in (Ruff et al., 2018; Goyal et al., 2020). Note\nhowever, our results for the DROCC algorithm is different\nfrom that reported in (Goyal et al., 2020). Re-running the\ncodes provided in (Goyal et al., 2020) did not yield simi-\nlar results as reported in the paper (especially for ‘Ship’).\nMoreover, their current implementation normalizes the data\nusing mean, µ = (0.4914, 0.4822, 0.4465) and standard\ndeviation, σ = (0.247, 0.243, 0.261). These values are cal-\nculated using the data from all the classes; which is not avail-\nable during training of a single class. To avoid such inconsis-\ntencies we rather normalize using mean, µ = (0.5, 0.5, 0.5)\nand standard deviation, σ = (0.5, 0.5, 0.5). Such a scale\ndoes not need apriori information of the other class’s pixel\nvalues and scales the data in a range of [−1, +1]. Detailed\ndiscussions on reproducing the results of the recent deep\nlearning algorithms DOCC (Ruff et al., 2018) and DROCC\n(Goyal et al., 2020) is provided in Appendix C.2.\nAs seen from Table 1, DOC3 (using the noise universum),\nprovides signiﬁcant improvement ∼5−15% (and upto 30%\nfor ‘Bird’), over its inductive counterpart (DOC). In addition,\nthe DOC3 in most cases outperforms the DOC (DA/OE).\nThis illustrates the advantage of extending Anomaly Detec-\ntion problems following Def. 3.1 in accordance with the\nProp. 3.2. To further consolidate our approach we com-\npare the advanced adversarial based DROCC-LF method\n(Goyal et al., 2020) (under OE settings) vs. our extension of\nDROCC-LF under universum setting. The major difference\nis now the auxilliary data serves as universum samples and\nthe loss function follows (6) (see Appendix B.2.3 Algo. 1).\nAs seen from Table 1 the DROCC-LF (univ) signiﬁcantly\noutperforms the DROCC-LF (OE) method to upto - 30%\n(‘dog’) for some cases. Details on the experiment setup\nand the optimal model parameters are available in Appendix\nB.2.3 for reproducibilty. Additional results showing DOC3\nimproving the state-of-the-art for tabular data sets Abalone,\nArrhythmia, Thyroid used in (Goyal et al., 2020) is provided\nin Appendix C.3.\n5.2. Visual Inspection using MV-Tec AD data\nFor our next set of experiments we tackle the more realistic\nvisual inspection based anomaly detection problem in manu-\nfacturing lines. Lately with the recent advancements in deep\nlearning technologies, there has been an increased interest\ntowards automating manufacturing lines and adopting AI\ndriven solutions providing automated visual inspection of\nproduct defects (Bergmann et al., 2019; Huang & Pan, 2015).\nOne popular benchmark data set used for such problems is\nthe MV-Tec AD data set (Bergmann et al., 2019).\n5.2.1. DATA SET AND EXPERIMENT SETUP\nThe MV-Tec AD data set contains 5354 high-resolution\ncolor images of different industrial object and texture cat-\negories. For each categories it contains normal (no defect)\nimages used for training. The test data contains both nor-\nTitle Suppressed Due to Excessive Size\nTable 1. Average AUC (with standard deviation) for one-vs-rest anomaly detection on CIFAR-10.\n†Results reported in (Ruff et al.,\n2018).∗Result reported in (Goyal et al., 2020). ‡Our re-run of the algorithm in (Goyal et al., 2020).\nCIFAR-10\nAirplane\nAutomobile Bird\nCat\nDeer\nDog\nFrog\nHorse\nShip\nTruck\nOC-SVM†\n61.6±0.9\n63.8±0.6\n50.0±0.5\n55.9±1.3\n66.0±0.7\n62.4±0.8\n74.7±0.3\n62.6±0.6\n74.9±0.4\n75.9±0.3\nIF†\n60.1 ± 0.7\n50.8±0.6\n49.2±0.4\n55.1±0.4\n49.8±0.4\n58.5±0.4\n42.9±0.6\n55.1±0.7\n74.2±0.6\n58.9±0.7\nDCAE†\n59.1 ± 5.1\n57.4±2.9\n48.9±2.4\n58.4±1.2\n54.0±1.3\n62.2±1.8\n51.2±5.2\n58.6±2.9\n76.8±4.1\n67.3±3.0\nAnoGAN†\n67.1 ± 2.5\n54.7±3.4\n52.9±3.0\n54.5±1.9\n65.1±3.2\n60.3±2.6\n58.5±1.4\n62.5±0.8\n75.8±4.1\n66.5±2.8\nConAD 16∗\n77.2\n63.1\n63.1\n61.5\n63.3\n58.8\n69.1\n64\n75.5\n63.7\n1-NN∗\n69.02\n44.2\n68.27\n51.32\n76.71\n49.97\n72.44\n51.13\n69.09\n43.33\nDOCC (Soft-Bound)†\n61.7 ± 4.2\n64.8±1.4\n49.5±1.4\n56.0±1.1\n59.1±1.1\n62.1±2.4\n67.8±2.4\n65.2±1.0\n75.6±1.7\n71.0±1.1\nDOCC†\n61.7 ± 4.1\n65.9±2.1\n50.8±0.8\n59.1±1.4\n60.9±1.1\n65.7±2.5\n67.7±2.6\n67.3±0.9\n75.9±1.2\n73.1±1.2\nDROCC‡\n79.2 ± 1.9\n74.9 ± 2.6 68.3±1.5\n62.3 ± 2.7 70.3±2.7\n66.1±2.0\n68.1±2.2\n71.3±4.6\n62.3±10.3\n76.6±1.9\nDOC (Hinge eq. (3))\n76.8 ± 1.4\n62.6±2.8\n52.1±0.7\n60.4±0.7\n62.3±1.2\n61.9±1.9\n76.3±0.5\n59.8±1.3\n72.8±1.1\n74.9±2.0\nDOC (DA/OE)\n69.5 ± 14.5\n73.1±3.3\n67.3±0.3\n62.4 ± 2.5 71.1±2.1\n67.3 ± 7.4 78.6 ± 1.7 66.8±2.4\n70.3±1.9\n75.8±2.5\nDOC3 (univ)\n81.3 ± 0.5\n74.2 ± 1.3 69.0 ± 0.6 62.1 ± 0.4 74.0±1.6\n63.0±4.6\n77.7 ± 0.3 67.6±1.8\n81.1 ± 0.6 76.8 ± 2.0\nDROCC-LF(OE)\n91.9 ± 0.9\n70.5±2.4\n70.9±2.2\n63.1±2.2\n76.6±1.3\n65.7±1.4\n74.1±2.7\n70.6±3.6\n85.1±4.1\n84.6±2.4\nDROCC-LF(univ)\n96.8 ± 0.4\n88.2±5.3\n79.8±1.6\n62.7±5.3\n80.4±1.3\n84.9±4.1\n87.4±0.9\n75.0±1.4\n93.4±0.2\n86.5±0.8\nmal as well as anomalous (defective) product images. The\nanomalies manifest themselves in the form of over 70 differ-\nent types of defects such as scratches, dents, contamination,\nand various other structural changes. The goal in this paper\nis to build one class image-level classiﬁers for the texture\ncategories (see Table 2). We use the original data scale of\n[0,1]. Further, to simplify the problem we resize all the\nimages to 64 × 64 pixel. Note that, for the current analysis\nwe only use the texture classes containing RGB images.\nFor this problem we have naturally occurring universum\n(contradiction) samples in the form of the objects’ images\nor other texture types. That is, for the goal of building a one\nclass classiﬁer for ‘carpet’, all the ‘other textures’ (leather,\ntile, wood) or the ‘objects’ (bottle, cable, capsule, hazelnut,\nmetal nut, pill, transistor) available in the dataset, can serve\nas universum (contradiction) samples. This is inline with\nthe problem setting in Def. 3.1, where such samples are\nneither ‘normal’ nor ‘anomalous’ (defective) carpet samples.\nFor our experiments, we use three types of universum,\n• Noise: Similar to previous experiments we generate ran-\ndom noise as universum samples. Here, since the data is\nalready scaled in the range of [0,1], we generate 64 × 64\ndimension images where the pixel values are obtained\nfrom a uniform distribution ∼U(0, 1).\n• Objects: This type of universum contains all the images\nin the object categories with RGB pixels viz. bottle, cable,\ncapsule, hazelnut, metal nut, pill, transistor. Note that, we\ninclude both the normal as well as the defective samples\nfor these objects.\n• other Textures: Here we use the remaining texture im-\nages as universum. That is, if the goal is building a one\nclass classiﬁer for ‘carpet’ we use the images from the\nother ‘textures’ (leather, tile, wood) as universum. We\ninclude both the normal as well as the defective samples\nin the universum set.\nAs before, we adopt a LeNet like architecture (schematic\nTable 2. MVTec-AD Dataset\nTEXTURES\nTRAIN\nTEST\nNORMAL\nANOMALY\nCARPET\n280\n28\n89\nLEATHER\n245\n32\n92\nTILE\n230\n33\n84\nWOOD\n247\n19\n60\nrepresentation in Fig. 3, details in Appendix B.1.2). Note\nthat, there have been a few recent works proposing advanced\narchitectures to achieve state-of-the-art performance on this\ndata (Carrara et al., 2020; Huang et al., 2019b). However,\nthe main focus here is to isolate the effectiveness of DOC3,\nand hence we mainly compare against DOC and DOC(OE)\nbaselines using a simple LeNet network. Since our baselines\nDOC, DOC(OE) using LeNet have not been previously\nreported on this data; as sanity check we also add the results\nin (Massoli et al., 2020) for a good comparison with different\nclasses of algorithms. Also, we adopt a slight modiﬁcation\nto our loss function. Rather than using relu function [x]+\nin (3), and (6) for the training samples; we use a softplus\noperator. We see improved results using this modiﬁcation.\nNote that, softplus is a dominating surrogate loss over relu,\nand hence Theorem 3.3 still holds.\n5.2.2. PERFORMANCE COMPARISON RESULTS\nTable 3 provides the results over 10 runs of our experiments.\nWe provide the the average ± standard deviation of the AUC\nvalues for DOC, DOC (DA/OE) and DOC3 algorithm. In\naddition we also provide the best AUC obtained for each\nalgorithm over these 10 runs. Additional details on model\nselection and the optimal hyperparameters is provided in\nAppendix B.3. As seen in Table 3, the DOC3 algorithm pro-\nvides signiﬁcant improvement over DOC. Depending on the\ntype of universum typical improvements range upto > 50%.\nIn addition, DOC3 provides consistent improvements over\nTitle Suppressed Due to Excessive Size\nTable 3. AUC for MVTec-AD (Texture) data. † Results taken from (Massoli et al., 2020). Bold = best overall model. Underline = best\nuniversum or OE model.\nTEXTURES\nAE†\nL2\nGeoTrans†\nGANomaly†\nITAE†\nEGBAD†\nCBiGAN†\nDOC (3)\nDOC (OE)\n(noise)\nDOC (OE)\n(objects)\nDOC (OE)\n(textures)\nDOC3\n(noise)\nDOC3\n(objects)\nDOC3\n(textures)\nBest\nAvg. ± std\nBest\nAvg. ± std\nBest\nAvg. ± std\nBest\nAvg. ± std\nBest\nAvg. ± std\nBest\nAvg. ± std\nBest\nAvg. ± std\nCarpet\n64\n44\n70\n71\n52\n55\n81.1\n81.1 ± 0.0\n76.2\n56.5 ± 10.1\n89.6\n82.1 ± 4.2\n54.9\n49.2 ± 4.9\n95.7\n80.4 ± 8.4\n93.8\n87.5 ± 3.8\n81.1\n81.1 ± 0.0\nLeather\n80\n84\n84\n86\n55\n83\n63.1\n62.7 ± 0.3\n65.7\n64.8 ± 0.8\n95.5\n89.6 ± 5.1\n40.1\n39.8 ± 0.2\n88.1\n82.9 ± 4.5\n93.5\n83.1 ± 7.5\n63.1\n62.4 ± 0.5\nTile\n74\n42\n79\n74\n79\n91\n62.8\n62.3 ± 0.7\n65.9\n64.9 ± 0.7\n75.7\n74.0 ± 1.4\n67.7\n65.3 ± 0.9\n66.3\n64.7 ± 0.6\n77.0\n76.5 ± 0.5\n65.1\n64.4 ± 0.5\nWood\n97\n61\n83\n92\n91\n95\n41.1\n40.6 ± 0.1\n90.2\n82.8 ± 5.6\n77.2\n70.9 ± 6.7\n52.6\n50.5 ± 1.5\n93.1\n83.4 ± 7.0\n75.3\n69.0 ± 5.8\n49.4\n49 ± 0.4\nthe DOC (DA/OE) algorithm. In all, these results further\nconsolidate the utility of DOC3 under the universum setting\n(Def 3.1). Separately, Table 3 also provides the baseline\nresults available in (Massoli et al., 2020). Note that, these\nresults are obtained using advanced network architectures\nadopted for the MVTec data, and are not averaged over\nmultiple runs. Hence, we compare these results with the\nbest AUC obtained for DOC, DOC (DA/OE) and DOC3\nover 10 runs. As seen from Table 3, DOC3 improves upon\nthe ‘carpet’ and ‘leather’ results using the ‘objects’ univer-\nsum. Further, it achieves comparable performance for the\n‘Wood’ and ‘Tile’ texture using ‘Noise’ and ‘Obj.’ univer-\nsum respectively. Achieving improved performance over the\nbaseline algorithms, even using a basic LeNet architecture\nsheds a very positive note for the proposed DOC3 algorithm.\n5.2.3. UNDERSTANDING DOC3 PERFORMANCE USING\nTHEOREM (3.4)\nFor our ﬁnal set of experiments we try to understand the\nworking of the DOC3 algorithm in connection with the\ncorrelation Σ(∞) (in Theorem 3.4). Table 4 reports the cor-\nrelation values for the training and universum samples using\n‘RAW’ pixel, ‘DOC’ and DOC3 solution’s feature maps.\nFor the feature map we use the CNN features shown in Fig.\n3. Also, the DOC3 solutions represent the estimated model\nusing the training data (in column 1) and the respective uni-\nversum data (in column 2). As seen from the results, the\nDOC solution provides high correlation Σ(∞) between the\ntraining and universum samples. In essence, the DOC solu-\ntion sees the training and universum samples similarly. This\nis not desirable, as the universum samples follow a differ-\nent distribution than training samples. On the contrary, the\nDOC3 provides a solution where the correlation between the\ntraining and universum samples are signiﬁcantly reduced.\nThis is inline with the Theorem 3.4’s analysis (section 3.2),\nwhere we argued that the DOC3 searches for a solution with\nlow Σ(∞) between the training and universum samples (in\nFigure 3. Schematic representation of the Network used for\nMVTec-AD results in Table 3.\nTable 4. Average ± standard deviation of correlation Σ(∞) be-\ntween training and universum over 10 runs. Values scaled ×102\nTRAIN\nDATA\nUNIV.\nDATA\nRAW\nDOC\nFEAT. MAP\nDOC3\nFEAT. MAP\nCARPET\nNOISE\n73.8\n99.9 ± 0.0\n17.5 ± 3.8\nOBJ.\n73.8\n97.1 ± 0.1\n28.8 ± 3.4\nTEXT.\n92.4\n99.9 ± 0.0\n68.7 ± 0.0\nLEATHER\nNOISE\n70.1\n99.3 ± 0.1\n42.1 ± 1.9\nOBJ.\n70.7\n91.9 ± 0.3\n23.5 ± 4.3\nTEXT.\n93.6\n99.3 ± 0.1\n97.0 ± 1.7\nTILE\nNOISE\n71.2\n99.8 ± 0.0\n54.2 ± 1.0\nOBJ.\n71.5\n92.8 ± 0.8\n31.3 ± 8.8\nTEXT.\n89.9\n99.6 ± 0.0\n89.3 ± 2.2\nWOOD\nNOISE\n69.5\n99.8 ± 0.0\n39.8 ± 5.8\nOBJ.\n69.8\n93.5 ± 0.2\n41.9 ± 7.1\nTEXT.\n91.7\n99.7 ± 0.0\n64.4 ± 2.1\nfeature space). And by doing so ensures lower ERC and\nimproved generalization compared to DOC (conﬁrmed em-\npirically in Table 3). Another interesting point seen for\nthe ‘other texture’ universum type, with originally high raw\npixel correlation values (∼0.9) is that; using DOC3 pro-\nvides limited improvement. Such universum types are too\nsimilar to the training data, and act as ‘bad’ contradictions.\nTitle Suppressed Due to Excessive Size\n6. Conclusions\nThis paper introduces the notion of learning from contra-\ndictions for deep one class classiﬁcation and introduces the\nDOC3 algorithm. DOC3 is shown to provide improved gen-\neralization over DOC, its inductive counterpart, by deriving\nthe Empirical Rademacher Complexity (ERC). We empir-\nically show the effectiveness of the proposed formulation,\nand connect the results to our theoretical analysis. Finally,\nwe also discuss the limitations and the future research direc-\ntions (moved to Appendix D due to space constraints).\nReferences\nAbadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean,\nJ., Devin, M., Ghemawat, S., Irving, G., Isard, M., et al.\nTensorﬂow: A system for large-scale machine learning. In\n12th {USENIX} symposium on operating systems design\nand implementation ({OSDI} 16), pp. 265–283, 2016.\nAkcay, S., Atapour-Abarghouei, A., and Breckon, T. P.\nGanomaly: Semi-supervised anomaly detection via adver-\nsarial training. In Asian conference on computer vision,\npp. 622–637. Springer, 2018.\nBartlett, P. L. and Mendelson, S. Rademacher and gaussian\ncomplexities: Risk bounds and structural results. Journal\nof Machine Learning Research, 3(Nov):463–482, 2002.\nBergman, L. and Hoshen, Y.\nClassiﬁcation-based\nanomaly detection for general data.\narXiv preprint\narXiv:2005.02359, 2020.\nBergmann, P., Fauser, M., Sattlegger, D., and Steger, C.\nMvtec ad–a comprehensive real-world dataset for unsu-\npervised anomaly detection. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition,\npp. 9592–9600, 2019.\nBreunig, M. M., Kriegel, H.-P., Ng, R. T., and Sander, J. Lof:\nidentifying density-based local outliers. In Proceedings\nof the 2000 ACM SIGMOD international conference on\nManagement of data, pp. 93–104, 2000.\nCaron, M., Bojanowski, P., Joulin, A., and Douze, M. Deep\nclustering for unsupervised learning of visual features. In\nProceedings of the European Conference on Computer\nVision (ECCV), pp. 132–149, 2018.\nCarrara, F., Amato, G., Brombin, L., Falchi, F., and Gen-\nnaro, C. Combining gans and autoencoders for efﬁcient\nanomaly detection. arXiv preprint arXiv:2011.08102,\n2020.\nChalapathy, R. and Chawla, S. Deep learning for anomaly\ndetection: A survey. arXiv preprint arXiv:1901.03407,\n2019.\nChandola, V., Banerjee, A., and Kumar, V. Anomaly detec-\ntion: A survey. ACM computing surveys (CSUR), 41(3):\n1–58, 2009.\nChang, C.-C. and Lin, C.-J. Training v-support vector clas-\nsiﬁers: theory and algorithms. Neural computation, 13\n(9):2119–2147, 2001.\nChapelle, O., Agarwal, A., Sinz, F. H., and Sch¨olkopf, B.\nAn analysis of inference with the universum. In Advances\nin neural information processing systems, pp. 1369–1376,\n2008.\nChen, S. and Zhang, C. Selecting informative universum\nsample for semi-supervised learning. In IJCAI, pp. 1016–\n1021, 2009.\nCherkassky, V. and Mulier, F. M. Learning from data: con-\ncepts, theory, and methods. John Wiley & Sons, 2007.\nCherkassky, V., Dhar, S., and Dai, W. Practical conditions\nfor effectiveness of the universum learning. IEEE Trans-\nactions on Neural Networks, 22(8):1241–1255, 2011.\nCortes, C., Gonzalvo, X., Kuznetsov, V., Mohri, M., and\nYang, S. Adanet: Adaptive structural learning of artiﬁcial\nneural networks. In International conference on machine\nlearning, pp. 874–883. PMLR, 2017.\nDas, S., Islam, M. R., Jayakodi, N. K., and Doppa, J. R.\nActive anomaly detection via ensembles. arXiv preprint\narXiv:1809.06477, 2018.\nDhar, S. Analysis and extensions of universum learning.\n2014.\nDhar, S. and Cherkassky, V. Development and evaluation of\ncost-sensitive universum-svm. Cybernetics, IEEE Trans-\nactions on, 45(4):806–818, 2015.\nDhar, S. and Cherkassky, V. Universum learning for svm\nregression. In Neural Networks (IJCNN), 2017 Interna-\ntional Joint Conference on, pp. 3641–3648. IEEE, 2017.\nDhar, S., Cherkassky, V., and Shah, M. Multiclass learning\nfrom contradictions. In Advances in Neural Information\nProcessing Systems, pp. 8400–8410, 2019.\nGoodfellow, I., Bengio, Y., Courville, A., and Bengio, Y.\nDeep learning, volume 1. MIT press Cambridge, 2016.\nGoyal, S., Raghunathan, A., Jain, M., Simhadri, H. V., and\nJain, P. Drocc: Deep robust one-class classiﬁcation. In\nInternational Conference on Machine Learning, pp. 3711–\n3721. PMLR, 2020.\nHendrycks, D., Mazeika, M., and Dietterich, T.\nDeep\nanomaly detection with outlier exposure. arXiv preprint\narXiv:1812.04606, 2018.\nTitle Suppressed Due to Excessive Size\nHoffmann, H. Kernel pca for novelty detection. Pattern\nrecognition, 40(3):863–874, 2007.\nHuang, C., Cao, J., Ye, F., Li, M., Zhang, Y., and Lu,\nC. Inverse-transform autoencoder for anomaly detection.\narXiv preprint arXiv:1911.10676, 2019a.\nHuang, C., Ye, F., Cao, J., Li, M., Zhang, Y., and Lu, C.\nAttribute restoration framework for anomaly detection.\narXiv preprint arXiv:1911.10676, 2019b.\nHuang, C., Ye, F., Zhang, Y., Wang, Y.-F., and Tian, Q.\nEsad: End-to-end deep semi-supervised anomaly detec-\ntion. arXiv preprint arXiv:2012.04905, 2020.\nHuang, S.-H. and Pan, Y.-C. Automated visual inspection\nin the semiconductor industry: A survey. Computers in\nindustry, 66:1–10, 2015.\nJolliffe, I. Principal Component Analysis. Springer, 2002.\nKnorr, E. M., Ng, R. T., and Tucakov, V. Distance-based\noutliers: algorithms and applications. The VLDB Journal,\n8(3):237–253, 2000.\nLiu, F. T., Ting, K. M., and Zhou, Z.-H. Isolation forest. In\n2008 eighth ieee international conference on data mining,\npp. 413–422. IEEE, 2008.\nMakhzani, A. and Frey, B. Winner-take-all autoencoders.\narXiv preprint arXiv:1409.2752, 2014.\nMasci, J., Meier, U., Cires¸an, D., and Schmidhuber, J.\nStacked convolutional auto-encoders for hierarchical fea-\nture extraction. In International conference on artiﬁcial\nneural networks, pp. 52–59. Springer, 2011.\nMassoli, F. V., Falchi, F., Kantarci, A., Akti, S¸., Ekenel,\nH. K., and Amato, G. Mocca: Multi-layer one-class\nclassiﬁcation for anomaly detection.\narXiv preprint\narXiv:2012.12111, 2020.\nNeyshabur, B., Tomioka, R., and Srebro, N. Norm-based\ncapacity control in neural networks. In Conference on\nLearning Theory, pp. 1376–1401, 2015.\nPang, G., Shen, C., Cao, L., and Hengel, A. v. d. Deep\nlearning for anomaly detection: A review. arXiv preprint\narXiv:2007.02500, 2020.\nPaszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J.,\nChanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga,\nL., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Rai-\nson, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang,\nL., Bai, J., and Chintala, S. Pytorch: An imperative\nstyle, high-performance deep learning library. In Wal-\nlach, H., Larochelle, H., Beygelzimer, A., d Alch´e-Buc,\nF., Fox, E., and Garnett, R. (eds.), Advances in Neural In-\nformation Processing Systems 32, pp. 8026–8037. Curran\nAssociates, Inc., 2019.\nPatel, R. and Toda, M. Trace inequalities involving hermi-\ntian matrices. Linear algebra and its applications, 23:\n13–20, 1979.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V.,\nThirion, B., Grisel, O., Blondel, M., Prettenhofer, P.,\nWeiss, R., Dubourg, V., et al. Scikit-learn: Machine\nlearning in python. the Journal of machine Learning\nresearch, 12:2825–2830, 2011.\nRamaswamy, S., Rastogi, R., and Shim, K. Efﬁcient al-\ngorithms for mining outliers from large data sets. In\nProceedings of the 2000 ACM SIGMOD international\nconference on Management of data, pp. 427–438, 2000.\nRosenberg, D. S. and Bartlett, P. L. The rademacher com-\nplexity of co-regularized kernel classes. In Artiﬁcial In-\ntelligence and Statistics, pp. 396–403, 2007.\nRuff, L., Vandermeulen, R., Goernitz, N., Deecke, L., Sid-\ndiqui, S. A., Binder, A., M¨uller, E., and Kloft, M. Deep\none-class classiﬁcation. In International conference on\nmachine learning, pp. 4393–4402, 2018.\nRuff, L., Vandermeulen, R. A., G¨ornitz, N., Binder,\nA., M¨uller, E., M¨uller, K.-R., and Kloft, M.\nDeep\nsemi-supervised anomaly detection.\narXiv preprint\narXiv:1906.02694, 2019.\nRuff, L., Kauffmann, J. R., Vandermeulen, R. A., Montavon,\nG., Samek, W., Kloft, M., Dietterich, T. G., and M¨uller,\nK.-R. A unifying review of deep and shallow anomaly\ndetection. Proceedings of the IEEE, 2021.\nSchlegl, T., Seeb¨ock, P., Waldstein, S. M., Schmidt-Erfurth,\nU., and Langs, G. Unsupervised anomaly detection with\ngenerative adversarial networks to guide marker discov-\nery. In International conference on information process-\ning in medical imaging, pp. 146–157. Springer, 2017.\nSch¨olkopf, B., Williamson, R., Smola, A., Shawe-Taylor, J.,\nand Platt, J. Support vector method for novelty detection.\nIn Proceedings of the 12th International Conference on\nNeural Information Processing Systems, 1999.\nSch¨olkopf, B., Platt, J. C., Shawe-Taylor, J., Smola, A. J.,\nand Williamson, R. C. Estimating the support of a high-\ndimensional distribution.\nNeural computation, 13(7):\n1443–1471, 2001.\nScholkopf, B., Smola, A. J., Bach, F., et al. Learning with\nkernels: support vector machines, regularization, opti-\nmization, and beyond. MIT press, 2002.\nShawe-Taylor, J., Cristianini, N., et al. Kernel methods for\npattern analysis. Cambridge university press, 2004.\nTitle Suppressed Due to Excessive Size\nShen, C., Wang, P., Shen, F., and Wang, H. Uboost: Boost-\ning with the universum. Pattern Analysis and Machine In-\ntelligence, IEEE Transactions on, 34(4):825–832, 2012.\nSinz, F., Chapelle, O., Agarwal, A., and Sch¨olkopf, B. An\nanalysis of inference with the universum. In Advances\nin neural information processing systems 20, pp. 1369–\n1376, NY, USA, September 2008. Curran.\nSokolic, J., Giryes, R., Sapiro, G., and Rodrigues, M. R.\nLessons from the rademacher complexity for deep learn-\ning. 2016.\nTan, P.-N., Steinbach, M., and Kumar, V. Introduction to\ndata mining. Pearson Education India, 2016.\nTax, D. M. and Duin, R. P. Support vector data description.\nMachine learning, 54(1):45–66, 2004.\nVapnik, V. Estimation of Dependences Based on Empiri-\ncal Data (Information Science and Statistics). Springer,\nMarch 2006. ISBN 0387308652.\nWeimer, D., Scholz-Reiter, B., and Shpitalni, M. Design of\ndeep convolutional neural network architectures for auto-\nmated feature extraction in industrial inspection. CIRP\nAnnals, 65(1):417–420, 2016.\nWeston, J., Collobert, R., Sinz, F., Bottou, L., and Vapnik,\nV. Inference with the universum. In Proceedings of the\n23rd international conference on Machine learning, pp.\n1009–1016. ACM, 2006.\nXiao, Y., Feng, J., and Liu, B. A new transductive learning\nmethod with universum data. Applied Intelligence, pp.\n1–13, 2021.\nZenati, H., Foo, C. S., Lecouat, B., Manek, G., and Chan-\ndrasekhar, V. R. Efﬁcient gan-based anomaly detection.\narXiv preprint arXiv:1802.06222, 2018.\nZhang, X. and LeCun, Y. Universum prescription: Regu-\nlarization using unlabeled data. In AAAI, pp. 2907–2913,\n2017.\nZong, B., Song, Q., Min, M. R., Cheng, W., Lumezanu,\nC., Cho, D., and Chen, H. Deep autoencoding gaussian\nmixture model for unsupervised anomaly detection. In\nInternational Conference on Learning Representations,\n2018. URL https://openreview.net/forum?\nid=BJJLHbb0-.\nTitle Suppressed Due to Excessive Size\nA. Proofs\nA.1. Proof of Proposition 2.2\nPart i A slightly different version of this proposition is an-\nalyzed in Proposition 8.2 of (Scholkopf et al., 2002) and\n(Chang & Lin, 2001). Here, we provide a different version\nof the connection between the solutions of (3) and (2). This\nis achieved through analyzing the KKT systems of the for-\nmulations. We start with the formulation (3). Note that, (3)\nis the same as solving,\nmin\nw\n1\n2||w||2 + C\nn\nX\ni=1\nξi\n(11)\ns.t. w⊤φ(xi) ≥1 −ξi; ξi ≥0\nThe Lagrangian is given as,\nL(w, ξ, α, β) =\n1\n2||w||2 + C Pn\ni=1 ξi −Pn\ni=1 βiξi −\nPn\ni=1 αi[w⊤φ(xi) −1 + ξi]\nKKT System\n∇wL = 0 ⇒w =\nn\nX\ni=1\nαiφ(xi)\n(12)\n∇ξL = 0 ⇒C = αi + βi\n(13)\nComplimentary Slackness,\nαi[w⊤φ(xi) −1 + ξi] = 0\n(14)\nβiξi = 0\n(15)\nConstraints,\nw⊤φ(xi) ≥1 −ξi\n(16)\nξi ≥0\n(17)\nDeﬁne δ =\n1\nP\ni αi and re-write the equations (12) - (17)\nby scaling with δ > 0\nas, ˆw = wδ; ˆαi = αiδ; ˆβi =\nβiδ; ˆξi = ξiδ. (δ > 0; ∵∃i s.t. αi > 0 and ∀i, αi ≥0)\nThis gives, Transformed KKT System\nˆw =\nn\nX\ni=1\nˆαiφ(xi)\n(18)\nCδ = ˆαi + ˆβi\n(19)\nComplimentary Slackness,\nˆαi[ˆw⊤φ(xi) −δ + ˆξi] = 0\n(20)\nˆβi ˆξi = 0\n(21)\nConstraints,\nˆw⊤φ(xi) ≥δ −ˆξi;\nˆξi ≥0\n(22)\nNote that, the transformed KKT system (18) - (22) solves\n(2) with ν =\n1\nCnδ; ρ = δ (compare with the KKT of (2)).\nPart ii For the solution to (2) obtained from Proposition 2.2\n(i) the decision rule can be given as,\nˆw⊤φ(x) −ρ = 0 ⇒(wδ)⊤φ(x) −δ = 0\n⇒w⊤φ(x) −1 = 0\n(∵δ > 0)\nA.2. Proof of Proposition 3.2\nNote that for this proof we need to accommodate a case\nwhere a sample may not belong to either of the two classes\n{−1, +1}. For this we rather analyze a different decision\nrule than (3).\nDeﬁne,\ng(x) =\n\u001a +1;\nif w⊤φ(xi) > 1\n−1;\nif w⊤φ(xi) < 1\nThis gives,\ng(x) = +1 ⇒h(x) = +1 and g(x) = −1 ⇒h(x) = −1\n⇒PDU (h(x∗) = y) ≥PDU (g(x∗) = y) ∀y = {−1, +1}\nSince the events are mutually exclusive we have,\nEDU\n\n\n[\ny∈{−1,+1}\n1[h(x∗) = y]\n\n\n≥EDU\n\n\n[\ny∈{−1,+1}\n1[g(x∗) = y]\n\n\n⇒inf\nh EDU\n\n\n[\ny∈{−1,+1}\n1[h(x∗) = y]\n\n\n≥inf\ng EDU\n\n\n[\ny∈{−1,+1}\n1[g(x∗) = y]\n\n\n⇒1 −inf\nh EDU\n\n\n[\ny∈{−1,+1}\n1[h(x∗) = y]\n\n\n≤1 −inf\ng EDU\n\n\n[\ny∈{−1,+1}\n1[g(x∗) = y]\n\n\nTitle Suppressed Due to Excessive Size\n⇒sup\nh\nEDU\n\n\n\\\ny∈{−1,+1}\n1[h(x∗) ̸= y]\n\n(De-Morgan’s law)\n≤sup\ng\nEDU\n\n\n\\\ny∈{−1,+1}\n1[g(x∗) ̸= y]\n\n\n= sup\ng\nEDU (1[g(x∗) ̸= +1] ∧1[g(x∗) ̸= −1])\n= sup\ng\nEDU\n\u00001[w⊤φ(x) −1 ≯0] ∧1[w⊤φ(x) −1 ≮0]\n\u0001\nThe maximum can be achieved when w⊤φ(x) −1 = 0\nA.3. Proof of Theorem 3.3\nDeﬁne, Rf,θ = {x : f(x) ≥θ}. This gives,\nPDT |Y=+1{x /∈Rf,1−κ} = EDT |Y=+1[H(f(x), 1 −κ)]\n(23)\nwhere, H(x, θ) =\n\u001a 0;\nif x ≥θ\n1;\nelse\n. For the rest of the\nproof we drop the subscripts as it is clear from context.\nTo bound the R.H.S of (23) we follow a similar approach\nof bounding a dominating function see Theorem 4.17 in\n(Shawe-Taylor et al., 2004). Here we deﬁne,\nA(x) =\n\n\n\n0;\nif x > 1\n1−x\nκ ;\nif 1 −κ ≤x ≤1\n1;\nif x < 1 −κ\nNote that, A(x) is 1\nκ−Lipchitz. Further, H(f(x), 1 −\nκ) ≤A(f(x)). This gives, E[H(f(x), 1 −κ) −1] ≤\nE[A(f(x)) −1]. Hence with probability 1 −η, ∀f ∈F the\nfollowing holds (see Theorem 4.9 in (Shawe-Taylor et al.,\n2004)); where ˆE = the empirical estimate for the expecta-\ntion operator.\nE[H(f(x), 1 −κ) −1] ≤ˆE[A(f(x)) −1]\n+ ˆRn((A −1) ◦F) + 3\ns\nln 2\nη\n2n\nFrom Th. 4.15 (Shawe-Taylor et al., 2004)\n⇒E[H(f(x), 1 −κ)] ≤\nnP\ni=1\nξi\nκn\n2\nκ\nˆRn(F) + 3\ns\nln 2\nη\n2n\nwhere, ξi = [1 −f(xi)]+. Using (23), we get the ﬁnal form\nof Theorem (3.3).\nA.4. Proof of Theorem 3.4\nPart (a): It is clear that Funiv\n⊆Find.\nThis ensures\nˆRn(Funiv) ≤\nˆRn(Find) (following Theorem 4.15 (i) in\n(Shawe-Taylor et al., 2004).\nPart (b) - (i): This follows from standard analysis (see The-\norem 4.12 (Shawe-Taylor et al., 2004) or Lemma 22 in\n(Bartlett & Mendelson, 2002)).\nˆRn(Find) = Eσ[sup\nf∈F\n| 2\nn\nn\nX\ni=1\nσif(xi)|\n\f\f\f(xi)n\ni=1]\n= Eσ[\nsup\n||w||2≤Λ2| 2\nn\nn\nX\ni=1\nσif(xi)|\n\f\f\f(xi)n\ni=1]\n= Eσ\n\u0002\nsup\n||w||2≤Λ2| 2\nnw⊤\u0000n\nX\ni=1\nσiφ(xi)\n\u0001\n|\n\f\f\f(xi)n\ni=1\n\u0003\n≤Eσ\n\u0002\nsup\n||w||2≤Λ2\n2||w||\nn\n||\n\u0000n\nX\ni=1\nσiφ(xi)\n\u0001\n||\n\f\f\f(xi)n\ni=1\n\u0003\n≤2Λ\nn Eσ\n\u0002\n||\nn\nX\ni=1\nσiφ(xi)||\n\f\f\f(xi)n\ni=1\n\u0003\n≤2Λ\nn Eσ\n\u0002\n||\nn\nX\ni=1\nσiφ(xi)||2\f\f\f(xi)n\ni=1\n\u0003 1\n2\n(Jensen’s inequality)\n≤2Λ\nn Eσ\nh\nn\nX\ni,j=1\nσiσjφ(xi)φ(xj)\n\f\f(xi)n\ni=1\ni 1\n2\n= 2Λ\nn\nh\nn\nX\ni=1\n||φ(xi)||2i 1\n2\nPart (b) - (ii): Deﬁne\nWuniv = {w\n\f\f||w||2 ≤Λ2; |w⊤φ(x∗) −1| ≤∆; ∀x∗∈X ∗\nU}\n⊆{w\n\f\f ||w||2 ≤Λ2; |w⊤uj −1| ≤∆;\n∀uj = φ(x∗\nj) ; ∀x∗\nj ∈X ∗\nU; j = 1 . . . m}\n(24)\n∵the constraint on all x∗∈X ∗\nU ⇒constraint on m−sam-\nples. Now, let’s analyze the constraint |w⊤uj −1| ≤∆.\nThis implies, w⊤uj −1 ≤∆; 1 −w⊤uj ≤∆(simul-\ntaneously). However, only one of the constraint is active.\nHence, we re-write the constraint as, ∀j ;\n\u0014 w⊤uj\nw⊤(−uj)\n\u0015\n≤\n\u0014\n∆+ 1\n∆−1\n\u0015\n.\nNext deﬁne a mapping where we concatenate the reﬂected\nspace.\ni.e.\nψ : φ(x∗) →\n\u0014\nφ(x∗)⊤\n−φ(x∗)⊤\n\u0015\nand rewrite\nTitle Suppressed Due to Excessive Size\nV = ψ\n\u0010\n[φ(x∗\nj)]m\nj=1\n\u0011\n=\n\n\nφ(x∗\n1)⊤\nφ(x∗\n2)⊤\n...\nφ(x∗\nm)⊤\n−φ(x∗\n1)⊤\n−φ(x∗\n2)⊤\n...\n−φ(x∗\nm)⊤\n\n\n. This can be com-\npactly re-written as, V =\n\u0014 1\n−1\n\u0015\n⊗\n\n\n(u1)T\n...\n(um)T\n\n. This results\nto the overall constraint in (24) to be,\nWuniv ⊆{w\n\f\f||w||2 ≤Λ2 ; [V w]j ≤ϵj; j = 1 . . . 2m}\nwhere, ϵ =\n\n\n∆+ 1\n...\n∆+ 1\n\n\n\n\n\n\n\nm-times\n∆−1\n...\n∆−1\n\n\n\n\n\n\n\nm-times\n\n\n.\nIn essence for each constraint in (24) we create 2× the\nconstraints for both the original and reﬂected space to take\ncare of the absolute value.\nNow,\nWuniv ⊆{w\n\f\f||w||2 ≤Λ2; [V w]j ≤ϵj ∀j = 1 . . . 2m}\n⊆{w\n\f\f||w||2 ≤Λ2; (w⊤V ⊤V w) ≤2m[∆2 + 1]}\n(25)\nThe last line follows as the element-wise constraint is re-\nlaxed by || · ||2\n2 constraint.\nNext, from (25) and assuming a ﬁxed mapping φ(·), for the\ngiven training data Z =\n\n\n(z1)⊤\n...\n(zn)⊤\n\n=\n\n\nφ(x1)⊤\n...\nφ(xn)⊤\n\nwe have,\nˆR(Funiv)\n(a)\n= 2\nnEσ\n\u0002\nsup\nw∈Wuniv\nσ⊤(Zw)\n\u0003\n≤2\nnEσ\n\u0002\nsup\n||w||2 ≤Λ2\n(w⊤V ⊤V w) ≤2m[∆2 + 1]\nσ⊤(Zw)\n\u0003\n(from (25))\nHence ∀γ ≥0 and Γ = Λ2 + 2γm(∆2 + 1) we have,\n(b)\n≤2\nnEσ\n\u0002\nsup\n||w||2+γ(w⊤V ⊤V w)≤Γ\nσ⊤(Zw)\n\u0003\n= 2\nnEσ\n\u0002\nsup\nw⊤\u0000I+γV ⊤V\nΓ\n\u0001\nw≤1\nσ⊤(Zw)\n\u0003\n(26)\n(c)\n= 2\nnEσ\nh\n||\n\u0000I + γV ⊤V\nΓ\n\u0001−1\n2 Z⊤σ||\ni\n≤2\nn\nh\nEσ\n\u0002\n||\n\u0000I + γV ⊤V\nΓ\n\u0001−1\n2 Z⊤σ||\n\u00032i 1\n2 (Jensen’s inequality)\n(d)\n= 2\nn\nh\ntr\n\u0002\nZ\n\u0000I + γV ⊤V\nΓ\n\u0001−1Z⊤\u0003i 1\n2 (tr := Trace)\n= 2\nn\n\u0002\nΛ2 + 2γm(∆2 + 1)\n\u0003 1\n2 h\ntr\n\u0002\nZ\n\u0000I + γV ⊤V\n\u0001−1Z⊤\u0003i 1\n2\n(e)\n=\n\u0000 2\nn\n\u0001\n(Λ2 + 2γm(∆2 + 1))\n1\n2\nh\ntr(Z⊤Z)\n−γtr[ZV ⊤(I + γV V ⊤)−1V Z⊤]\ni 1\n2\n(∀γ ≥0)\n= 2Λ\nn\nv\nu\nu\nt||\nn\nX\ni=1\nφ(xi)||2\nh\u00001 + 2γm(∆2 + 1)\nΛ2\n\u0001\n\u0002\n1 −γtr[(I + γV V ⊤)−1(V Z⊤ZV ⊤)]\ntr(Z⊤Z)\n\u0003i 1\n2\n⇒ˆR(Funiv)\n(f)\n≤2Λ\nn\nv\nu\nu\nt||\nn\nX\ni=1\nφ(xi)||2\nh\u00001 + 2γm(∆2 + 1)\nΛ2\n\u0001\n\u0002\n1 −\nγtr(V Z⊤ZV ⊤)\ntr(I + γV V ⊤) tr(Z⊤Z)\n\u0003i 1\n2\nThe (in)-equalities follow,\n(a) from symmetry w ∈WUSV M ⇒−w ∈WUSV M.\nHence we drop the absolute term from deﬁnition. Also\nfor simplicity we drop the conditional term. This is\nclear from context.\n(b) since the conditions\n||w||2 ≤Λ2\n(w⊤V ⊤V w) ≤2m[∆2 + 1]\n⇒||w||2 + γ(w⊤V ⊤V w) ≤Γ\n∀γ ≥0.\n(c) stationary point of the constraint. A similar approach\nwas previously used in (Rosenberg & Bartlett, 2007).\n(d) since (Rademacher variables) are drawn uniformly over\nσ ∼{−1, +1}; we cancel the cross-terms σiσj under\nexpectation Eσ.\n(e) using Sherman-Morrison-Woodbury formula.\n(f) from the matrix inequality II in (Patel & Toda, 1979).\nTitle Suppressed Due to Excessive Size\nB. Reproducibility\nB.1. Network Architectures\nB.1.1. LENET ARCHITECTURE FOR CIFAR-10\nEXPERIMENTS\nFigure 4. Network used for CIFAR10 results in Table 1\n.\nFor CIFAR-10 we use the same architecture (Fig. 4) as used\nin (Goyal et al., 2020).\nB.1.2. LENET ARCHITECTURE FOR MVTEC\nEXPERIMENTS\nFigure 5. Network used for MVTec-AD results in Table 3\n.\nFor MVTec-AD there have been a few recent works propos-\ning advanced architectures to achieve state-of-the-art per-\nformance on this data (Carrara et al., 2020; Huang et al.,\n2019b). However, the main goal of our experiment is to illus-\ntrate the effectiveness of universum over inductive learning\nfor one class problems. Hence, we stick to a simple LeNet\narchitecture shown in Fig. 5.\nFinally, for both the above architectures we use bias = False\nfor convolution operations and set ϵ = 10−4, Afﬁne = False\nfor BatchNorm. Additionally, we use a leaky ReLU activa-\ntion after every max-pool operation.\nB.2. Model Parameters for Table 1\nB.2.1. DOC AND DOC3 MODEL PARAMETERS USED IN\nTABLE 1\nTable 5. Optimal Model Parameters for CIFAR10 results for DOC.\nCLASS\nλ\nSGD\n(LEARNING RATE)\nAIRPLANE\n0.5\n0.005\nAUTOMOBILE\n1.0\n0.001\nBIRD\n0.5\n0.005\nCAT\n1.0\n0.001\nDEER\n1.0\n0.001\nDOG\n0.5\n0.001\nFROG\n0.5\n0.001\nHORSE\n1.0\n0.001\nSHIP\n0.5\n0.001\nTRUCK\n0.001\n0.001\nTable 6. Optimal Model Parameters for CIFAR10 results for\nDOC3.\nCLASS\nλ\nSGD\n(LEARNING RATE)\nCU/C\nAIRPLANE\n0.1\n0.005\n0.5\nAUTOMOBILE\n0.05\n0.0005\n0.1\nBIRD\n0.05\n0.005\n0.5\nCAT\n0.1\n0.005\n1.0\nDEER\n0.1\n0.001\n1.0\nDOG\n0.05\n0.001\n1.0\nFROG\n0.1\n0.005\n0.5\nHORSE\n0.05\n0.0005\n1.0\nSHIP\n0.05\n0.005\n0.1\nTRUCK\n0.05\n0.0001\n0.05\nThere are several hyper-parameters to be tuned for DOC\nand DOC3. To simplify our analysis we ﬁx a few of these\nparameters following prior research.\n• Unlike previous works like (Ruff et al., 2018; Goyal\net al., 2020), we uniformly use an SGD optimizer with\nbatch size = 256. Although, training for each class\nrepresent a completely different problem, we adopt\nthis to maintain consistency and isolate out the effect\nof optimizers for DOC vs. DOC3 performances.\n• For DOC we ﬁx the total number of iterations for gradi-\nent updates to 300. Except for class ‘DOG’ and ‘Truck’\nwe use 400 and 50 respectively. For DOC3 we ﬁx it to\n350. This is in the same range as (Ruff et al., 2018),\nand hence incurs similar computation complexity as\nthe baseline DOCC and DROCC algorithms.\n• Finally for DOC3 we ﬁx ∆= 0.\nTitle Suppressed Due to Excessive Size\nWith the above hyper parameters ﬁxed our best selected re-\nmaining hyper parameters for DOC and DOC3 are provided\nin Table 5 and 6 respectively.\nB.2.2. DOC (DA/OE) MODEL PARAMETERS IN TABLE 1\nNext, we provide the optimal model parameters for the\nDOC (DA/OE) setting in Table 7. For the DOC (DA/OE)\nfollowing (Goyal et al., 2020) we introduce the universum\nsamples as negative class in a standard binary hinge loss.\nThe explicit form of this loss is also discussed in Appendix\nC.1.1 in eq. (27). Here we set C+ = C−= 1.\nTable 7. DOC (DA/OE) parameters CIFAR-10.\nCIFAR-10\n(CLASS)\nλ =\n1\n2C\nSGD\nLEARNING RATE\nAIRPLANE\n1.0\n5 × 10−3\nAUTOMOBILE\n0.01\n5 × 10−4\nBIRD\n0.5\n5 × 10−4\nCAT\n1.0\n10−4\nDEER\n1.0\n10−4\nDOG\n0.5\n10−3\nFROG\n0.5\n5 × 10−3\nHORSE\n0.01\n10−3\nSHIP\n1.0\n10−3\nTRUCK\n0.01\n10−4\nB.2.3. MODEL PARAMETERS AND EXPERIMENT SET UP\nFOR DROCC-LF UNDER OE VS. UNIVERSUM\nSETTING\nFor the DROCC-LF (OE) we use the same implementation\nas in (Goyal et al., 2020). For the DROCC-LF under univer-\nsum setting we replace the binary cross entropy loss used\nin (Goyal et al., 2020) with the universum loss in (6) (see\nAlgo 1). Here we use the same notations as also used in\n(Goyal et al., 2020). Further, as in Section 5.2.1 we replace\nthe relu operator [x]+ with the softplus operator for the loss\nfunctions.\nWe adopt the same LeNet architecture used in (Ruff et al.,\n2018; Goyal et al., 2020) (see Fig 4). Finally, we run the\nexperiments over 10 runs and report the best AUC over the\nrange of parameters recommended in (Goyal et al., 2020)\n(Section 5). That is learning rate = 10−4, radius (r) in range\nof\n√\nd = {8.0, 16.0, 32.0}. Here, for both the methods we\nuse Adam and ﬁx the number of ascent steps = 10 and batch\nsize = 256 and total epochs = 350. The remaining parame-\nters are set to default values. The ﬁnal optimal parameters\nselected for the different classes is provided in Table 8.\nTable 8. DROCC (OE) and DROCC (Univ) optimal (radius) pa-\nrameters used in Table 1\nCIFAR-10\n(CLASS)\nDROCC-LF\n(OE)\nDROCC-LF\n(UNIV)\nAIRPLANE\n8\n8\nAUTOMOBILE\n32\n8\nBIRD\n16\n8\nCAT\n16\n16\nDEER\n16\n16\nDOG\n16\n8\nFROG\n32\n32\nHORSE\n16\n32\nSHIP\n8\n8\nTRUCK\n8\n8\nAlgorithm 1 DROCC-LF (under Universum setting)\nInput: Training (normal) samples T = (xi, yi = +1)n\ni=1\nand Universum samples U = (x∗\ni′)m\ni′=1.\nParameters: Radius r, λ ≥0, µ ≥0, step-size η, number\nof gradient steps mg, number of initial training steps n0.\nInitial steps: For B = 1, . . . n0\nBatch of training (XT ) and universum (XU) samples\nθ = θ −∇\n\u0010\nP\nxi∈XB\nLT (f(xi)) +\nP\nx∗\ni′∈XU\nLU(f(x∗\ni′))\n\u0011\nDROCC steps: For B = n0, . . . n0 + N\nXT : Batch of normal training inputs (y = +1)\n∀x ∈XT : h ∼N(0, Id)\nAdversarial search: For i = 1, . . . mg\n1. LT (h) = LT (f(x + h), −1)\n2. h = h + η\n∇hLT (h)\n∥∇hLT (h)∥\n3. h = Projection given by Prop.1 in (Goyal et al., 2020)\nℓitr = λ∥w∥2 +\nP\nxi∈XB\nLT (f(xi)) +\nP\nx∗\ni′∈XU\nLU(f(x∗\ni′)) +\nµLT (f(x + h), −1)\nθ = θ −∇ℓitr\nCaveat(s): We found a few caveats while running the\nDROCC-LF experiments. One major caveat is that the\ngradient ascent steps are prone to instabilities. Note that\nthe DROCC-LF algorithm (Algo 2 in (Goyal et al., 2020))\nscales the perturbation direction (h) by the norm of the\ngradient vector. This results to severe gradient explosion.\nAppropriate measures to alleviate this issue has to be taken.\nAnother major caveat is that the additional gradient ascent\nupdates results to high computation complexity. For exam-\nple, for the experiments presented in this paper a typical\nDROCC-LF run (350 epoch) takes ∼104 secs compared\nto ∼103 sec without the adversarial updates. The system\nconﬁguration used here is,\n– CPU = AMD Ryzen 9 5950X 16 Core.\n– RAM = 32 GB.\nTitle Suppressed Due to Excessive Size\n– GPU = NVIDIA GeForce RTX 3080\n– CUDA = 11.4\nB.3. Model Parameters for Table 3\nTable 9. Optimal Model Parameters for MVTEC-AD results.\nMETHOD\nλ\nADAM\n(LEARNING RATE)\nCU/C\nLEATHER\nDOC\n0.01\n10−5\n-\nDOC3\nNOISE\n0.01\n10−5\n0.01\nOBJ.\n0.01\n10−5\n0.1\nTEXT.\n0.01\n10−6\n0.01\nWOOD\nDOC\n0.005\n10−4\n-\nDOC3\nNOISE\n0.005\n5 × 10−6\n1.0\nOBJ.\n0.005\n10−5\n1.0\nTEXT.\n0.05\n10−5\n0.1\nTILE\nDOC\n0.01\n10−5\n-\nDOC3\nNOISE\n0.1\n5 × 10−6\n0.1\nOBJ.\n0.005\n10−4\n2.0\nTEXT.\n0.1\n5 × 10−6\n0.1\nCARPET\nDOC\n1.0\n5 × 10−4\n-\nDOC3\nNOISE\n0.001\n10−5\n0.01\nOBJ.\n0.005\n5 × 10−5\n2.0\nTEXT.\n1.0\n10−3\n10−5\nHere we provide the optimal model parameters selected and\nused to reproduce the DOC and DOC3 results in Table 3 and\n4. For this set of experiments we use the Adam optimizer\nwith batch size = 100. Further, to simplify model selection\nwe ﬁx the total number of iterations to 1000, and ∆= 0.\nFinally we also provide the optimal hyperparameters for the\nDOC (DA/OE) algorithm in Table 10.\nB.4. Ablation Study Hyperparameters\nThe DOC3 algorithm mainly introduces two additional\nhyper-parameters CU and ∆compared to its inductive coun-\nterpart. The success of such an advanced technique depends\non careful tuning of the hyperparameters. In this section we\nperform an ablation study of the CU\nC and the ∆hyperparam-\neters. To simplify we present the results for the CIFAR10\ndata. Analysis using MVTec-AD data provides similar con-\nclusions.\nFigs 6 and 7 provides the average ± std. deviation of the\nAUC values over 10 experiment runs for varying CU\nC - ra-\ntios and ∆values respectively. The experiment follows\nthe same setting as in Section 5.2.1. Further all the other\nTable 10. DOC (DA/OE) model parameters for MVTEC results.\nNORMAL\nUNIV.\nANOMALY\nλ =\n1\n2C\nLEARNING RATE\nLEATHER\nNOISE\n0.001\n10−6\nOBJ.\n0.01\n10−5\nTEXT.\n0.0001\n10−5\nWOOD\nNOISE\n0.01\n10−5\nOBJ.\n0.01\n10−6\nTEXT.\n0.01\n10−6\nTILE\nNOISE\n0.005\n10−6\nOBJ.\n0.001\n10−4\nTEXT.\n0.1\n10−6\nCARPET\nNOISE\n0.001\n10−6\nOBJ.\n0.01\n10−5\nTEXT.\n0.005\n10−5\nmodel parameters are set to their optimal values reported in\nTable 9. As seen from the ﬁgures, the model performance\nsigniﬁcantly varies for different CU\nC -values (speciﬁcally\nfor automobile, deer, dog, frog etc.). On the contrary, the\nDOC3 model performance seems relatively stable for vary-\ning ∆values (see Fig 7). Such behavior is also seen for\nthe MVTec-AD dataset. In line with this analysis through-\nout the paper we ﬁx ∆= 0 and follow the current norm\nof reporting the best model’s results over a small subset\nof hyperparameters. But this is far from practical. This\nmotivates advanced mechanisms for optimal selection of\nthis hyper parameter, which is still an open research topic.\nFrom our prior experiments, we found CU/C in the range\nof [0.01, 1.0] provides reasonable performance in practice.\nC. Additional Experiments and Results\nC.1. Comparisons of Disjoint Auxiliary (or Outlier\nExposure) vs. Universum settings\nIn this section we highlight the differences between the\nuniversum vs. the ‘Disjoint Auxiliary data’ setting used\nin (Dhar, 2014) (see Section 4.3) and (Hendrycks et al.,\n2018; Goyal et al., 2020) etc. As discussed in the Section\n4 a major difference is the assumption that the universum\nsamples act as contradictions to the unseen anomalous class\n(see Deﬁnition (3.1)). Methods using the ‘Disjoint Auxil-\niary’ setting do not use this assumption and formulate a loss\nfunction which only contradicts the ‘normal’ class. Such\napproaches have also been called ‘Supervised OE’ in (Ruff\net al., 2021) or ‘Limited Negatives’ in (Goyal et al., 2020).\nIn this section we take a more pedagogical approach to\nhighlight the differences between Universum vs. ‘Disjoint\nAuxiliary’ setting. For simplicity we use a binary classiﬁer\nas an exemplar of this ‘Disjoint Auxiliary’ setting. That is,\nTitle Suppressed Due to Excessive Size\n(a) Airplane\n(b) Automobile\n(c) Bird\n(d) Cat\n(e) Deer\n(f) Dog\n(g) Frog\n(h) Horse\n(i) Ship\n(j) Truck\nFigure 6. Ablation study - AUC values for varying CU/C values.\n(a) Airplane\n(b) Automobile\n(c) Bird\n(d) Cat\n(e) Deer\n(f) Dog\n(g) Frog\n(h) Horse\n(i) Ship\n(j) Truck\nFigure 7. Ablation study - AUC values for varying ∆values.\nTitle Suppressed Due to Excessive Size\nwe build a binary classiﬁer with ‘+1’ (normal samples) and\n‘−1’ (contradiction a.k.a universum) samples. Note that,\nsuch an approach is philosophically inconsistent following\nDef. 3.1; where the universum samples are assumed to not\nfollow the same distribution as both the normal (‘+1’) and\nanomalous (‘-1’) class. Using the universum samples as\n(‘-1’) class violates the assumption that universum follows\na different distribution than the anomalous class. To further\nconﬁrm our theoretical analysis we provide a simple syn-\nthetic example in C.1.1. Empirical comparisons using the\nCIFAR-10 and MV-Tec AD datasets are already provided\nin the main text in Tables 1 and 3 respectively. We further\nconsolidate our claim by comparing the adversarial setting\nbased DROCC-LF (extended under OE setting) (Goyal et al.,\n2020) vs. DROCC-LF (extended under universum setting)\nin Table 1 (also discussed in section B.2.3)\nC.1.1. SYNTHETIC EXPERIMENT\nFigure 8. Decision boundaries for one class SVM vs. one class\nU-SVM vs. binary SVM. Typical parameters, one class SVM (C\n= 5), one class U-SVM (CU = 10−3, ∆= 0), binary SVM (C =\n10). TP = True Positive, TN = True Negatives.\nFor our synthetic example, we use synthetic data generated\nusing normal distribution N(µ, σ). For illustration we use,\n• Normal Class (+1) : µ = (1.0, 1.0), σ = (0.25, 1.0).\n• Anomaly Class (-1) : µ = (0.25, 1.0), σ = (0.25, 1.0).\n• Contradictions : µ = (0.75, 6.0), σ = (0.25, 1.0).\nAdditionally we use,\n• No. of Training samples (+1 class) = 10\n• No. of Test samples (+1, -1) class = 1000 per class.\n• No. of Universum samples = 1000.\nNote, that in the above synthetic example the discriminative\npower is mostly contained in the 1st dimension. Having\n‘good’ universum samples can incorporate this additional\ninformation by contradicting the 2nd dimension while esti-\nmating the decision rule. This is also seen from Fig. 8. Fig.\n8 provides the decision boundaries obtained under inductive\n(3) vs. universum settings (6) using only linear parame-\nterization. Under linear parameterization the formulations\nreduces to standard SVM formulations so we refer them as\none class SVM and one class U-SVM respectively. Finally,\nwe also provide the decision boundary using a binary SVM\n(Cherkassky & Mulier, 2007).\nmin\nw\n1\n2||w||2\n2 + C\nn\nX\ni=1\nh\nC+[1 −w⊤φ(xi)]+\n(27)\n+\nC−[1 + w⊤φ(xi)]+\ni\nwhere, [x]+ = max(0, x). For the binary SVM we use the\nuniversum as (-1) class, and adopt cost-sensitive formulation\nwith a cost ratio C+\nC−= #univ\n#train = 1000\n10 , to handle the class\nimbalance.\nAs seen from Fig. 8, using binary formulation in this univer-\nsum setting does not correctly capture information available\nthrough the contradiction samples. That is, discriminating\nbetween normal and contradiction samples does not provide\na good classiﬁer for normal vs. anomaly classiﬁcation. The\none class SVM although correctly classiﬁes the positive\nsamples (TP = 100%); does not perform good on future test\nsamples. Using the universum samples, we can incorporate\nthe additional information that the decision boundary should\nalign along the vertical axis to have maximal contradiction\n(following Prop. 3.2). And by doing so, it improves the test\nperformance over the one class SVM solution.\nC.2. Reproducing DOCC (Ruff et al., 2018) and\nDROCC (Goyal et al., 2020) Results\nC.2.1. DEEP ONE CLASS CLASSIFICATION (DOCC)\nRESULTS\nFor the DOCC results we see very similar results for our run\nexcept the ‘Frog’ and ‘Dog’ classes; where the difference\nare not too signiﬁcant. Hence, we report the results as\npresented in the paper.\nC.2.2. DEEP ROBUST ONE CLASS CLASSIFICATION\n(DROCC) RESULTS\nHere, we report the results of our run with two differ-\nent scaling.\nFor the ‘all-class’ scale we use the scale\nTitle Suppressed Due to Excessive Size\nTable 11. Reproducing DOCC results in (Ruff et al., 2018)\nDOCC (OUR RUN)\nCLASS\nRUFF ET AL.,\n2018 (RUFF ET AL., 2018)\nν = 0.1\nν = 0.01\nAIRPLANE\n61.7 ± 4.1\n61.0 ± 1.6\n61.1 ± 1.4\nAUTOMOBILE\n65.9 ± 2.1\n60.4 ± 1.7\n60.4 ± 1.7\nBIRD\n50.8 ± 0.8\n48.6 ± 0.6\n48.6 ± 0.6\nCAT\n59.1 ± 1.4\n57.7 ± 0.9\n57.8 ± 1.0\nDEER\n60.9 ± 1.1\n56.2 ± 0.7\n56.3 ± 0.8\nDOG\n65.7 ± 2.5\n63.4 ± 1.1\n63.5 ± 1.3\nFROG\n67.7 ± 2.6\n56.8 ± 1.8\n56.9 ± 2.0\nHORSE\n67.3 ± 0.9\n59.9 ± 1.9\n59.8 ± 1.9\nSHIP\n75.9 ± 1.2\n77.1 ± 1.0\n76.9 ± 1.0\nTRUCK\n73.1 ± 1.2\n66.9 ± 0.6\n66.9 ± 0.7\nTable 12. Reproducing DOCC (soft-boundary) results in (Ruff\net al., 2018)\nDOCC SOFT-BOUNDARY\n(OUR RUN)\nCLASS\nRUFF ET AL.,\n2018 (RUFF ET AL., 2018)\nν = 0.1\nν = 0.01\nAIRPLANE\n61.7 ± 4.1\n61.9 ± 1.6\n62.5 ± 1.9\nAUTOMOBILE\n65.9 ± 2.1\n61.6 ± 1.7\n62.6 ± 2.0\nBIRD\n50.8 ± 0.8\n48.0 ± 0.9\n45.9 ± 1.6\nCAT\n59.1 ± 1.4\n56.6 ± 1.3\n56.0 ± 1.8\nDEER\n60.9 ± 1.1\n56.2 ± 0.8\n56.1 ± 1.2\nDOG\n65.7 ± 2.5\n61.9 ± 0.9\n60.7 ± 1.7\nFROG\n67.7 ± 2.6\n59.8 ± 1.8\n61.0 ± 1.5\nHORSE\n67.3 ± 0.9\n61.5 ± 1.6\n61.3 ± 1.5\nSHIP\n75.9 ± 1.2\n77.7 ± 0.9\n76.7 ± 0.8\nTRUCK\n73.1 ± 1.2\n67.5 ± 0.9\n68.7 ± 1.4\nused in the original DROCC paper (Goyal et al., 2020)\ni.e. µ = (0.4914, 0.4822, 0.4465) and standard deviation,\nσ = (0.247, 0.243, 0.261). Note that, this scale is com-\nputed using the pixel values for all the classes. This in\ngeneral is not available during training a one class classiﬁer.\nAlternatively, ‘no-prior’ scale also reports the results using\na scale using µ = (0.5, 0.5, 0.5) and standard deviation,\nσ = (0.5, 0.5, 0.5). This scale does not need additional\ninformation from the other class’s pixel values. We do not\nsee a signiﬁcant difference using these different scales. Al-\nthough our re-runs show a signiﬁcant difference for the\n‘ship’ class between our results and the paper. We report the\nresults of our re-run using the ‘no-prior’ scale in Table 1.\nTable 13. Reproducing DROCC results in (Goyal et al., 2020)\nCLASS\nGOYAL ET AL.,\n2020 (GOYAL ET AL., 2020)\nDROCC\n(ALL-CLASS\nSCALE)\nDROCC\n(NO-PRIOR\nSCALE)\nAIRPLANE\n81.66 ± 0.22\n79.99 ± 1.65\n79.24 ± 1.95\nAUTOMOBILE\n76.73 ± 0.99\n74.61 ± 2.57\n74.92 ± 2.66\nBIRD\n66.66 ± 0.96\n69.56 ± 0.94\n68.29 ± 1.53\nCAT\n67.13 ± 1.51\n54.54 ± 3.71\n62.25 ± 2.67\nDEER\n73.62 ± 2.00\n65.85 ± 2.94\n70.34 ± 2.68\nDOG\n74.43 ± 1.95\n66.47 ± 3.16\n66.18 ± 2.09\nFROG\n74.42 ± 0.92\n70.64 ± 2.40\n68.16 ± 2.12\nHORSE\n71.39 ± 0.22\n70.18 ± 2.42\n71.33 ± 4.57\nSHIP\n80.01 ± 1.69\n63.58 ± 7.88\n62.39 ± 10.33\nTRUCK\n76.21 ± 0.67\n75.12 ± 1.92\n76.58 ± 1.94\nC.3. Additional Results on Tabular data from (Goyal\net al., 2020)\nIn this section we provide additional results on the tabular\ndata used in (Goyal et al., 2020). The data used involves\nstandard anomaly detection problem described next,\n• Abalone as used in (Das et al., 2018) : Here the task\nis to predict the age of abalone using several phys-\nical measurements like, rings, sex, length, diameter,\nheight, weight, etc. For this problem class 3 and 21\nare anomalies and class 8, 9 and 10 serve as normal\nsamples.\n• Arrhythmia as used in (Zong et al., 2018). Here the\ntask is to identify the arrhythmic samples using the\nECG features. We follow the same data set preparation\nas (Zong et al., 2018).\n• Thyroid as used in (Zong et al., 2018). The goal is to\npredict if a patient is hypothyroid based on his/her med-\nical history.We follow the same data set preparation as\n(Zong et al., 2018).\nFor all the above data we use the data set preparation codes\nprovided in (Goyal et al., 2020). This code provides the\ndata preprocessing and partitioning scheme as used in the\nprevious works.\nWe follow the same experiment setup and network archi-\ntecture as in (Goyal et al., 2020). Table 14 provides the\nresults of DOC3 over 10 random partition of the data set.\nIn each partition, we create training/test data as used in\n(Goyal et al., 2020). Note however, different from (Goyal\net al., 2020), we scale the data in the range of [−1, +1] uni-\nformly. In addition, here we generate uniform noise in range\n[−1, +1] and use that as universum/contradiction samples.\nAs seen from Table 14 the DOC3 outperforms all existing\napproaches (except DROCC) for the Thyroid data; and sig-\nniﬁcantly improves (> 5 - 15 %) upon the state-of-the-art\nresults for the Arrhythmia and Abalone data. The optimal\nmodel parameters used for the results is also provided in\nTable 15 for reproducibility.\nTable 14. F1-Score ± standard deviation for one-vs-all anomaly\ndetection on Thyroid, Arrhythmia, and Abalone datasets.\nF1-Score\nMethod\nThyroid\nArrhythmia\nAbalone\nOC-SVM (Sch¨olkopf et al., 1999)\n0.39 ± 0.01\n0.46 ± 0.00\n0.48 ± 0.00\nDCN(Caron et al., 2018)\n0.33 ± 0.03\n0.38 ± 0.03\n0.40 ± 0.01\nE2E-AE (Zong et al., 2018)\n0.13 ± 0.04\n0.45 ± 0.03\n0.33 ± 0.03\nLOF (Breunig et al., 2000)\n0.54 ± 0.01\n0.51 ± 0.01\n0.33 ± 0.01\nDAGMM (Zong et al., 2018)\n0.49 ± 0.04\n0.49 ± 0.03\n0.20 ± 0.03\nDeepSVDD (Ruff et al., 2018)\n0.73 ± 0.00\n0.54 ± 0.01\n0.62 ± 0.01\nGOAD (Bergman & Hoshen, 2020)\n0.72 ± 0.01\n0.51 ± 0.02\n0.61 ± 0.02\nDROCC (Goyal et al., 2020)\n0.78 ± 0.03\n0.69 ± 0.02\n0.68 ± 0.02\nDOC3 (ours)\n0.74 ± 0.01\n0.73 ± 0.01\n0.77 ± 0.01\nTitle Suppressed Due to Excessive Size\nTable 15. Optimal Model Parameters for the Tabular data sets.\nClass\nλ\nLearning\nRate\nCU/C\nEpoch\nBatch Size\nThyroid\n10−6\n10−3\n5.0\n500\n100\nArrhythmia\n0.01\n10−3\n0.001\n300\n100\nAbalone\n0.1\n10−3\n0.01\n300\n100\nD. Future Research\nBroadly there are two major future research directions,\nModel Selection This is a generic issue for any (unsuper-\nvised) one class based anomaly detection formulation, and\nis further complicated by the non-convex loss landscape\nfor deep learning problems. For DOC3 we simplify model\nselection by ﬁxing ∆= 0, and optimally tuning CU. How-\never, the success of DOC3 heavily depends on carefully\ntuning of its hyperparameters. In the absence of any valida-\ntion set containing both ‘normal’ and ‘anomalous’ samples,\nwe follow the current norm of reporting the best model’s\nresults over a small subset of hyperparameters. But this is\nfar from practical. We believe, our Theorem 3.3 provides a\ngood framework for bound based model selection. This in\nconjunction with Theorem 3.4 and the recent works on ERC\nfor deep architectures (Neyshabur et al., 2015; Sokolic et al.,\n2016), may provide better mechanisms for model selection\nand yield optimal models.\nSelecting ‘good’ universum samples The effectiveness of\nDOC3 also depends on the type of universum used. Our\nanalysis in section 5.2.3 provides some initial insights into\nthe workings of DOC3, and how to loosely identify ‘bad’\ncontradictions. Additional analysis, possibly inline with the\nHistogram of Projections (HOP) technique introduced in\n(Cherkassky et al., 2011; Dhar et al., 2019), is needed to\nimprove our understanding of ‘good’ universum samples.\nThis is an open research problem.\n",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CV",
    "stat.ML"
  ],
  "published": "2021-05-17",
  "updated": "2022-05-23"
}