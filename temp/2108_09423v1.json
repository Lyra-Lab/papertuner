{
  "id": "http://arxiv.org/abs/2108.09423v1",
  "title": "Adaptive unsupervised learning with enhanced feature representation for intra-tumor partitioning and survival prediction for glioblastoma",
  "authors": [
    "Yifan Li",
    "Chao Li",
    "Yiran Wei",
    "Stephen Price",
    "Carola-Bibiane Schönlieb",
    "Xi Chen"
  ],
  "abstract": "Glioblastoma is profoundly heterogeneous in regional microstructure and\nvasculature. Characterizing the spatial heterogeneity of glioblastoma could\nlead to more precise treatment. With unsupervised learning techniques,\nglioblastoma MRI-derived radiomic features have been widely utilized for tumor\nsub-region segmentation and survival prediction. However, the reliability of\nalgorithm outcomes is often challenged by both ambiguous intermediate process\nand instability introduced by the randomness of clustering algorithms,\nespecially for data from heterogeneous patients.\n  In this paper, we propose an adaptive unsupervised learning approach for\nefficient MRI intra-tumor partitioning and glioblastoma survival prediction. A\nnovel and problem-specific Feature-enhanced Auto-Encoder (FAE) is developed to\nenhance the representation of pairwise clinical modalities and therefore\nimprove clustering stability of unsupervised learning algorithms such as\nK-means. Moreover, the entire process is modelled by the Bayesian optimization\n(BO) technique with a custom loss function that the hyper-parameters can be\nadaptively optimized in a reasonably few steps. The results demonstrate that\nthe proposed approach can produce robust and clinically relevant MRI\nsub-regions and statistically significant survival predictions.",
  "text": "Adaptive unsupervised learning with enhanced\nfeature representation for intra-tumor\npartitioning and survival prediction for\nglioblastoma\nYifan Li1, Chao Li⋆2, Yiran Wei2, Stephen Price2, Carola-Bibiane Sch¨onlieb3,\nand Xi Chen1,4\n1 Department of Computer Science, University of Bath, Bath, UK.\n2 {Division of Neurosurgery, Department of Clinical Neurosciences,\n3 Department of Applied Mathematics and Theoretical Physics,\n4 Department of Physics}, University of Cambridge, Cambridge, UK.\nyl3548@bath.ac.uk, cl647@cam.ac.uk, yw500@cam.ac.uk, sjp58@cam.ac.uk,\ncbs31@cam.ac.uk, xc841@bath.ac.uk/xc253@mrao.cam.ac.uk\nAbstract. Glioblastoma is profoundly heterogeneous in regional mi-\ncrostructure and vasculature. Characterizing the spatial heterogeneity\nof glioblastoma could lead to more precise treatment. With unsuper-\nvised learning techniques, glioblastoma MRI-derived radiomic features\nhave been widely utilized for tumor sub-region segmentation and sur-\nvival prediction. However, the reliability of algorithm outcomes is often\nchallenged by both ambiguous intermediate process and instability in-\ntroduced by the randomness of clustering algorithms, especially for data\nfrom heterogeneous patients.\nIn this paper, we propose an adaptive unsupervised learning approach\nfor eﬃcient MRI intra-tumor partitioning and glioblastoma survival pre-\ndiction. A novel and problem-speciﬁc Feature-enhanced Auto-Encoder\n(FAE) is developed to enhance the representation of pairwise clinical\nmodalities and therefore improve clustering stability of unsupervised\nlearning algorithms such as K-means. Moreover, the entire process is\nmodelled by the Bayesian optimization (BO) technique with a custom\nloss function that the hyper-parameters can be adaptively optimized in\na reasonably few steps. The results demonstrate that the proposed ap-\nproach can produce robust and clinically relevant MRI sub-regions and\nstatistically signiﬁcant survival predictions.\nKeywords: Glioblastoma · MRI · auto-encoder · K-means clustering ·\nBayesian optimization · survival prediction\n1\nIntroduction\nGlioblastoma is one of the most aggressive adult brain tumors characterized\nby heterogeneous tissue microstructure and vasculature. Previous research has\n⋆Equal contribution.\narXiv:2108.09423v1  [cs.LG]  21 Aug 2021\n2\nYifan Li et al.\nshown that multiple sub-regions (also known as tumor habitats) co-exist within\nthe tumor, which gives rise to the disparities in tumor composition among pa-\ntients and may lead to diﬀerent patient treatment response [7,8]. Therefore, this\nintra-tumoral heterogeneity has signiﬁcantly challenged the precise treatment of\npatients. Clinicians desire a more accurate identiﬁcation of intra-tumoral inva-\nsive sub-regions for targeted therapy.\nMagnetic resonance imaging (MRI) is a non-invasive technique for tumor\ndiagnosis and monitoring. MRI radiomic features [17] provide quantitative in-\nformation for both tumor partition and survival prediction [5,6]. Mounting ev-\nidence supports the usefulness of the radiomic approach in tumor characteri-\nzation, evidenced by the Brain Tumor Image Segmentation (BraTS) challenge,\nwhich provides a large dataset of structural MRI sequences, i.e., T1-weighted,\nT2-weighted, post-contrast T1-weighted (T1C), and ﬂuid attenuation inversion\nrecovery (FLAIR). Although providing high tissue contrast, these weighted MRI\nsequences are limited by their non-speciﬁcity in reﬂecting tumor biology, where\nphysiological MRIs, e.g., perfusion MRI (pMRI) and diﬀusion MRI (dMRI),\ncould complement. Speciﬁcally, pMRI measures vascularity within the tumor,\nwhile dMRI estimates the brain tissue microstructure. Incorporating these com-\nplementary multi-modal MRI has emerged as a promising approach for more\naccurate tumor characterization and sub-region segmentation for clinical deci-\nsion support.\nUnsupervised learning methods have been widely leveraged to identify the\nintra-tumoral sub-regions based on multi-modal MRI [3,13,15,19,22,23]. Stan-\ndard unsupervised learning methods, e.g., K-means, require a pre-deﬁned class\nnumber, which lacks concrete determination criteria, aﬀecting the robustness of\nsub-region identiﬁcation. For instance, some researchers used pre-deﬁned class\nnumbers according to empirical experience before clustering [3,13]. Some other\nwork [11,23] introduced clustering metrics, e.g., the Calinski-Harabasz (CH) in-\ndex, which quantiﬁes the quality of clustering outcomes to estimate the ideal\nclass number. However, the CH index is sensitive to data scale [11, 23], limit-\ning its generalization ability across datasets. Some other clustering techniques,\ne.g., agglomerative clustering, do not require a pre-deﬁned class number and\ninstead require manual classiﬁcation. A sensitivity hyper-parameter, however, is\noften needed a priori. The clustering results can be unstable during iterations\nand across datasets. Due to the above limitations, the generalization ability of\nclustering methods has been a signiﬁcant challenge in clinical applications, par-\nticularly when dealing with heterogeneous clinical data.\nFurther, the relevance of clustering results is often assessed using patient sur-\nvival in clinical studies [1,4,9,13]. However, existing research seldom addressed\nthe potential inﬂuence of instability posed by the unsupervised clustering algo-\nrithms. Joint hyper-parameter optimization considering both clustering stability\nand survival relevance is desirable in tumor sub-region partitioning.\nIn this paper, we propose a variant of auto-encoder (AE), termed Feature-\nenhanced Auto-Encoder (FAE), to identify robust latent feature space con-\nstituted by the multiple input MRI modalities and thus alleviate the impact\nAdaptive learning with enhanced representation for glioblastoma\n3\nbrought by the heterogeneous clinical data. Additionally, we present a Bayesian\noptimization (BO) framework [18] to undertake the joint optimization task in\nconjunction with a tailored loss function, which ensures clinical relevance while\nboosting clustering stability. As a non-parametric optimization technique based\non Bayes’ Theorem and Gaussian Processes (GP) [16], BO learns the repre-\nsentation of the underlying data distribution that the most probable candidate\nof the hyper-parameters is generated for evaluation in each step. Here, BO is\nleveraged to identify the (sub)optimal hyper-parameter set with the potential to\neﬀectively identify robust and clinically relevant tumor sub-regions. The primary\ncontributions of this work include:\n– Developing a novel loss function that balances the stability of sub-region\nsegmentation and the performance of survival prediction.\n– Developing an FAE architecture in the context of glioblastoma studies to\nfurther enhance individual clinical relevance between input clinical features\nand improve the robustness of clustering algorithms.\n– Integrating a BO framework that enables automatic hyper-parameter search,\nwhich signiﬁcantly reduces the computational cost and provides robust and\nclinically relevant results.\nThe remainder of this paper is organized as follows. Section 2 describes the\noverall study design, the proposed framework, and techniques. Section 3 reports\nnumerical results, and Section 4 is the concluding remarks.\n2\nProblem formulation and methodology\nConsider an N patients multi-modal MRI dataset Ωwith M modalities deﬁned\nas {Xm}M\nm=1. Xm denotes the mth (pixel-wise) modality values over a collection\nof N patients. Xm = {xm,n}N\nn=1, where xm,n ∈RIm,n×1 and Im,n denotes total\npixel number of an individual MRI image for the mth modality of the nth patient.\nOur goal is to conduct sub-region segmentation on MRI images and perform\nclinically explainable survival analysis. Instead of running unsupervised learning\nalgorithms directly on Xm, we introduce an extra latent feature enhancement\nscheme (termed FAE) prior to the unsupervised learning step to further improve\nthe eﬃciency and robustness of clustering algorithms.\nAs shown in Figure 1(A), FAE aims to produce a set of latent features\n{Zm′}M\nm′=1 that represent the original data {Xm}M\nm=1. Unlike a standard AE\nthat takes all modalities as input, FAE ‘highlights’ pairwise common features\nand produces Z through a set of encoders (denoted as E) and decoders (de-\nnoted as D). The latent features are then used in unsupervised clustering to\nclassify tumor sub-region {Pn}N\nn=1 for all patients. As an intermediate step, we\ncan now produce spatial features {Fn}N\nn=1 from the segmented ﬁgures through\nradiomic spatial feature extraction methods such as gray level co-occurrence\nmatrix (GLCM) and Gray Level Run Length Matrix (GLRLM) [12].\n4\nYifan Li et al.\nFig. 1. A: Workﬂow of the proposed approach. The entire process is modelled under\na Bayesian optimization framework. B: Architecture of FAE. The light orange circle\nrepresents modality Xm overall patients and the blue circle is the latent feature Zm′.\nThe green dotted frame denotes the modality pair, and the green trapezoid represents\nfeature-enhanced encoder E and decoder D. The blue trapezoid indicates the fully\nconnected decoders Ds. C: Illustration of stability loss calculation. Circles in diﬀerent\ncolours represent individual patient MRI data, which are then randomly shuﬄed for\nK times to split into train/validation sets.\n2.1\nFeature-enhanced auto-encoder\nFAE is developed on Auto-encoder (AE), a type of artiﬁcial neural network used\nfor dimensionality reduction. A standard AE is a 3-layer symmetric network that\nhas the same inputs and outputs. As illustrated in Figure 1(B), FAE contains\nW feature-enhanced encoder layers {Ew}W\nw=1 to deal with {Gw}W\nw=1 pairs of\nmodalities, where W =\n\u0000M\n2\n\u0001\npairs of modalities (from combination) given M\ninputs. The wth encoder takes a pair of modalities from {Xm}M\nm=1 and encodes\nAdaptive learning with enhanced representation for glioblastoma\n5\nto a representation ew. The central hidden layer of FAE contains {Zm′}M\nm′=1\nnodes that represents M learnt abstract features. FAE also possesses a ‘mirrored’\narchitecture similar to AE, where W feature-enhanced decoder layers {Dw}W\nw=1\nare connected to the decoded representations {dw}W\nw=1.\nUnlike the standard symmetric AE, FAE has a ‘dual decoding’ architecture\nthat an extra fully-connected decoder layer Ds is added to the decoding half of\nthe networks to connect {dw}W\nw=1 directly to the outputs {X′m}M\nm=1. Decoder Ds\naims to pass all outputs information (and correlations) rather than the pairwise\ninformation from Gw in the back-propagation process. As a result, node weights\n{Zm′}M\nm′=1 are updated by gradients from both {Dw}W\nw=1 and Ds. In practice, Z\nand the encoders are iteratively amended by {Dw}W\nw=1 (i.e., reconstruction loss\nfrom pairwise AEs) and Ds (i.e., global reconstruction loss) in turns.\nFAE enhances the latent features in every pair of input modalities before\nreducing the dimensionality from W to M. For instance, ew is a unique rep-\nresentation that only depends on (and thus enhances the information of) the\ngiven input pair Gw. Under this dual decoding architecture, FAE takes advan-\ntage of highlighting the pairwise information in {Zm′}M\nm′=1 while retaining the\nglobal correlation information from Ds. Another advantage of FAE lies in its\nﬂexibility to the dimensionality of input features. The FAE presented in this\npaper always produces the same number of latent features as the input dimen-\nsion. The latent dimension might be further reduced manually depending on\ncomputational/clinical needs.\n2.2\nPatient-wise feature extraction and survival analysis\nWe implement Kaplan–Meier (KM) survival analysis [1, 13] on spatial features\nand sub-region counts {Fn}N\nn=1 to verify the relevance of clustering sub-regions.\nTo characterize the intratumoral co-existing sub-regions, we employed the com-\nmonly used texture features from the GLCM and GLRLM families, i.e., Long\nRun Emphasis (LRE), Relative mutual information (RMI), Joint Energy, Run\nVariance (RV) and Non-Uniformity. These features are formulated to reﬂect\nthe spatial heterogeneity of tumor sub-regions. For example, LRE indicates the\nprevalence of a large population of tumor sub-regions. The formulas and inter-\npretations of all these features are detailed in [20]. We next use the k-medoids\ntechnique to classify N patients into high- and low-risk subgroups based on\n{Fn}N\nn=1 and then perform KM analysis to analyze the survival signiﬁcance of\nthe subgroups to determine the Lp, as described in Section 2.4 and equation 2.\n2.3\nConstructing problem-speciﬁc losses\nStability loss We ﬁrst introduce a stability quantiﬁcation scheme to evaluate\nclustering stability using pairwise cluster distance [10,21], which will serve as part\nof the loss function in hyper-parameter optimization. Speciﬁcally, we employ a\nHamming distance method (see [21] for details) to quantify the gap between\nclustering models. We ﬁrst split the MRI training dataset Ωinto train and\nvalidation sets, denoted as Ωtrain and Ωval respectively. We then train two\n6\nYifan Li et al.\nclustering models C (based on Ωtrain) and C′ (based on Ωval). The stability\nloss aims to measure the performance of model C on the unseen validation set\nΩval. The distance d(·) (also termed as Ls) is deﬁned as:\nLs = d(C, C′) = min\nπ\n1\nIval\nX\nΩval\n1{π(C(Ωval)̸=C′(Ωval))},\n(1)\nwhere Ival denotes the total number of pixels over all MRI images in the vali-\ndation set Ωval. 1 represents the Dirac delta function [24] that returns 1 when\nthe inequality condition is satisﬁed and 0 otherwise, and function π(·) denotes\nthe repeated permutations of dataset Ωto guarantee the generalization of the\nstability measure [21].\nFigure 1 (C) shows the diagram for Ls calculation, where N patients are\nrandomly shuﬄed for K times to mitigate the eﬀect of randomness. K pairs of\nintermediate latent features {Ztrain,k, Zval,k}K\nk=1 are generated through FAE for\ntraining the clustering models C and C′. We then compute Ls over K repeated\ntrials. Ls is normalized to range [0, 1], and smaller values indicates more stable\nclusterings.\nSigniﬁcance loss We integrate prior knowledge from clinical survival analysis\nand develop a signiﬁcance loss Lp to quantify clinical relevance between the\nclustering outcomes and patient survival, as demonstrated in the below equation:\nLp =\n\n\n\n1\n1−τ log( τ\np) 0 < p ≤τ\n−logτ( τ\np)\nτ < p < 1\n(2)\nwhere p represents p-value (i.e., statistical signiﬁcance measure) of the log-rank\ntest in the survival analysis and τ is a predeﬁned threshold.\nThis follows the clinical practice that a lower p-value implies that the seg-\nmented tumor sub-regions can provide sensible diﬀerentiation for patient sur-\nvival. In particular, for p less than the threshold, the loss equation returns a\npositive reward. Otherwise, for p greater than or equal to τ, the segmented tu-\nmor sub-regions are considered undesirable and the penalty increases linearly\nwith p.\n2.4\nBayesian optimization\nHyper-parameters tuning is computational expensive and often requires expert\nknowledge, both of which raise practical diﬃculties in clinical applications. In\nthis paper, we consider two undetermined hyper-parameters: a quantile threshold\nγ ∈[0, 1] that distinguishes outlier data points from the majority and cluster\nnumber η for the pixel-wise clustering algorithm. We treat the entire process of\nFigure 1(A) as a black-box system, of which the input is the hyper-parameter set\nθ = [γ, η] and the output is a joint loss L deﬁned as:\nAdaptive learning with enhanced representation for glioblastoma\n7\nL = αLs + (1 −α)Lp\n(3)\nwhere α is a coeﬃcient that balances Ls and Lp and ranges between [0, 1].\nAlgorithm 1: Bayesian optimization for hyper-parameter tuning\n1 Initialization of GP surrogate f and the RBF kernel K(·)\n2 while not converged do\n3\nFit GP surrogate model f with {θj, Lj}J\nj=1\n4\nPropose a most probable candidate θj+1 through Equation (4)\n5\nRun Algorithm 2 with θj+1, and compute loss Lj+1\n6\nEstimate current optimal θj+2 of the constructed GP surrogate f ′\n7\nRun Algorithm 2 with θj+2, calculate the loss Lj+2\n8\nJ = J + 2\n9 end\n10 Obtain (sub)optimal θ∗upon convergence\nWe address the hyper-parameter tuning issue by modelling the black-box\nsystem under BO, a sequential optimization technique that aims to approximate\nthe search space contour of θ by constructing a Gaussian Process (GP) surrogate\nfunction in light of data. BO adopts an exploration-exploitation scheme to search\nfor the most probable θ candidate and therefore minimize the surrogate function\nmapping f : Θ →L in J optimization steps, where Θ and L denote input and\noutput spaces respectively. The GP surrogate is deﬁned as: f ∼GP(·|µ, Σ);\nwhere µ is the J × 1 mean function vector and Σ is a J × J co-variance matrix\ncomposed by the pre-deﬁned kernel function K(·) over the inputs {θj}J\nj=1. In\nthis paper, we adopt a standard radial basis function (RBF) kernel (see [2] for\nan overview of GP and the kernel functions).\nGiven training data ΩB = {θj, Lj}J\nj=1, BO introduces a so-called acquisi-\ntion function a(·) to propose the most probable candidate to be evaluated at\neach step. Amongst various types of acquisition functions [18], we employ an\nEI strategy that seeks new candidates to maximize expected improvement over\nthe current best sample. Speciﬁcally, suppose f ′ returns the best value so far, EI\nsearches for a new θ candidate that maximizes function g(θ) = max{0, f ′−f(θ)}.\nThe EI acquisition can thus be written as a function of θ:\naEI(θ) = E(g(θ)|ΩB) = (f ′ −µ)Φ(f ′|µ, Σ) + ΣN(f ′|µ, Σ)\n(4)\nwhere Φ(·) denotes CDF of the standard normal distribution. In practice, BO\nstep J increases over time and the optimal θ∗can be obtained if the predeﬁned\nconvergence criteria is satisﬁed. Pseudo-code of the entire process is shown in\nboth Algorithm 2 and Algorithm 1.\n8\nYifan Li et al.\nAlgorithm 2: Pseudo-code of the workﬂow as a component of BO\n// Initialization\n1 Prepare MRI data Ωwith N patients and M modalities, perform data\nﬁltering with quantile threshold γ\n// FAE training follows Figure 1(B)\n2 Compose W pairs of modalities GW\nw=1, where W =\n\u0000M\n2\n\u0001\n3 Train FAE on {Xm}M\nm=1 to generate latent features {Zm′}W\nm′=1\n// Stability loss calculation follows Figure 1(C)\n4 for k =1,2,...,K do\n5\nRandomly divide Ωinto train (Ωtrain) and validation (Ωval) sets\n6\nProduce latent pairs {Ztrain,k, Zval,k}K\nk=1\n// Pixel-wise clustering\n7\nObtain Ck and C′\nk through standard K-means with η clusters\n8\nCompute kth stability loss Ls,k by Eq (1)\n9 end\n10 Compute stability score Ls by averaging over {Ls,k}K\nk=1\n// Sub-region segmentation\n11 Obtain patient-wise sub-region segments {Pn}N\nn=1\n// Patient-wise feature extraction\n12 Extract {Fn}N\nn=1 for all N patients\n// Survival analysis\n13 Cluster patients into high/low risk subgroups based on {Fn}N\nn=1 using a\nstandard K-Medoids algorithm. Perform survival analysis and obtain p\n// BO loss calculation\n14 Compute clinical signiﬁcance score Lp by Eq (2)\n15 Compute joint loss L follows Eq (3)\n2.5\nExperiment details\nData from a total of N = 117 glioblastoma patients were collected and divided\ninto training set Ω= 82 and test set Ωtest = 35, where the test set was separated\nfor out-of-sample model evaluation. We collected both pMRI and dMRI data and\nco-registered them into T1C images, containing approximately 11 million pixels\nper modality over all patients. M = 3 input modalities were calculated, including\nrCBV (denoted as r) from pMRI, and isotropic/anisotropic components (denoted\nas p/q) of dMRI, thus X = {p, q, r}. Dataset Ωwas used for stability loss\ncalculation with Ωtrain = 57, Ωval = 25. Ls was evaluated over K = 10 trials\nfor all following experiments. The BO is initialized with J = 10 data points\nΩB, γ ∈[0, 1] and η is an integer ranges between 3 and 7. The models were\ndeveloped on Pytorch platform [14] under Python 3.8. Both encoder E and\ndecoder D employed a fully connected feed-forward NN with one hidden layer,\nwhere the hidden node number was set to 10. We adopted hyperbolic tangent\nas the activation function for all layers, mean squared error (MSE) as the loss\nfunction, and Adam as the optimiser.\nAdaptive learning with enhanced representation for glioblastoma\n9\n3\nResults and discussions\nWe ﬁrst present the clustering stability of the models incorporating FAE ar-\nchitecture, other AE variants against the baseline model and then compare the\nperformance of the proposed methodology under diﬀerent experimental settings.\nWe ﬁnally demonstrate the results of survival analysis and independent test.\n3.1\nEvaluation of FAE based clustering\nThe results comparing the models are detailed in Table 1. One sees that all three\nAE variants show better stability performance than that of the baseline model\nin the varying cluster numbers. Of note, our proposed FAE architecture, which\nincorporates both standard AE and ensemble AE, outperforms other models in\nmajority comparisons.\nTable 1. Stability performance of cluster algorithms under diﬀerent AE variants. Base-\nline represents the original model without AE. The standard AE represents a standard\n3-layer (with 1 hidden layer) feed-forward network and the ensemble AE is the FAE\nwithout dual decoder Ds. The hidden layer contains 10 nodes for all AE variants.\nClusters\n3\n4\n5\n6\nStability score\nBaseline\n0.761±0.026\n0.890±0.04\n0.744±0.027\n0.761±0.035\nStandard AE\n0.909±0.024\n0.896±0.063\n0.859±0.06\n0.836±0.061\nEnsemble AE\n0.972±0.013 0.921±0.028\n0.872±0.046\n0.881±0.046\nFAE\n0.909±0.048 0.923±0.029 0.911±0.038 0.891±0.048\nCalinski-Harabasz (CH) score\nBaseline (106)\n4.12±0.00003 5.16±0.00013 4.82±0.00003 4.73±0.00009\nStandard AE (106)\n5.94±0.63\n5.74±0.51\n5.50±0.41\n5.36±0.28\nEnsemble AE (106)\n10.43±0.67\n10.99±0.52\n10.98±0.89\n11.09±1.00\nFAE (106)\n13.85±4.45\n14.85±4.49\n15.09±4.19\n15.34±4.14\nAs expected, all AE variants enhance the clustering stability and quality,\nshown by the stability score and CH score. The latter of which is relatively sen-\nsitive to data scale but can provide reasonable evaluation for a ﬁxed dataset.\nIn our case, as the dimensions of the original input modalities and the latent\nfeatures remain identical (M = 3), the considerably improved stability of the\nmodels incorporating FAE architecture suggests the usefulness of the FAE in\nextracting robust features for the unsupervised clustering. Additionally, our ex-\nperiments show that the FAE demonstrates remarkably stable performance in the\nclustering when the training data is randomly selected, which further supports\nthe resilience of the FAE in extracting generalizable features for distance-based\nclustering algorithms.\n10\nYifan Li et al.\n(a) α = 0\n(b) α = 0.25\n(c) α = 0.5\n(d) α = 1\nFig. 2. Performance of the proposed approach with respect to BO step number (on\nx-axis). Each ﬁgure contains two y-axis: stability loss Ls (in blue) on the left y-axis,\nand both signiﬁcant loss Lp (in green) and joint loss (in orange) on the right y-axis. All\nlosses are normalized and the shadowed areas in diﬀerent colors indicate error-bars of\nthe corresponding curves. Figure (a) - (d) shows the performance with loss coeﬃcient\nα = 0, 0.25, 0.5 and 1, respectively.\n3.2\nAdaptive hyper-parameter tuning\nFigure 2 shows the performance of the proposed approach in 4 diﬀerent α values\nin terms of stability score (lower score value indicates better stability). 10 initial\ntraining steps and 20 follow-up BO steps are evaluated in the experiments, all\nthe results are averaged over 10 repeated trials. One sees signiﬁcant dispersion\nof initial points (dots in the left half of each ﬁgure) in all ﬁgures, indicating\nreasonable randomness of initial points in BO training. BO proposes a new\ncandidate θ per step after the initial training. One observes that the joint loss\nL (orange curves) converges and the proposed approach successfully estimates\n(sub)optimal θ∗in all α cases.\nFigure 2(a) shows α = 0 case, for which L = Lp according to Equation (3).\nIn other words, the algorithm aims to optimize signiﬁcance loss Lp (green curve)\nrather than stability loss Ls (blue curve). As a result, the orange and green\ncurves overlap with each other, and the stability scores are clearly lower than\nAdaptive learning with enhanced representation for glioblastoma\n11\nthat of Ls. A consistent trend can be observed across all four cases that the\nerror-bar areas of Ls (blue shadowed areas) shrink as the weight of Ls increases\nin the joint loss. Similar observations can be seen in Figure 2(d) where α = 1 and\nL = Ls, the error-bar area of Lp (green shadowed area) is considerably bigger\nthan those in the rest α cases. Note that Ls and L also overlap with each other\nand the mismatch in the ﬁgure is caused by the diﬀerences of left and right y-axis\nscale. When α = 0.5 (Figure 2(c)), clustering stability can quickly converge in a\nfew BO steps (around 6 steps in the orange curve), shows the advantage of the\nproposed BO integrated method in hyper-parameter optimization.\n3.3\nStatistical analysis and independent test\nUpon convergence of BO, we acquire well-trained FAE encoders to extract fea-\ntures from modalities, a well-trained clustering model for tumor sub-region seg-\nmentation and a population-level grouping model to divide patients into high-risk\nand low-risk subgroups. Subsequently, we apply these well-trained models to the\ntest set with 35 patients. The results of KM analysis are shown in Figure\n3,\nillustrating that the spatial features extracted from tumor sub-regions could lead\nto patient-level clustering that successfully separates patients into distinct sur-\nvival groups in both datasets (Train: p-value = 0.013 Test: p-value = 0.0034).\nFigure 4 shows two case examples from the high-risk and low-risk subgroups,\nrespectively, where diﬀerent colours indicate the partitioned sub-regions. Intu-\nitively, these sub-regions are in line with the prior knowledge of proliferating,\nnecrotic, and edema tumor areas, respectively.\n(a) Train set Ω= 82 patients\n(b) Test set Ωtest = 35 patients\nFig. 3. KM survival curves for the train and test datasets.\n4\nConclusions\nThe paper is an interdisciplinary work that helps clinical research to acquire ro-\nbust and eﬀective sub-regions of glioblastoma for clinical decision support. The\n12\nYifan Li et al.\n(a) low-risk (CE) (b) low-risk (NE) (c) high-risk (CE) (d) high-risk (NE)\nFig. 4. Two case examples from the high-risk (a & b) and lower-risk (c & d) group,\nrespectively. Diﬀerent colours denote the partitioned sub-regions. The two patients\nhave signiﬁcantly diﬀerent proportions of sub-regions with clinical relevance, which\ncould provide clinical decision support.\nproposed FAE architectures signiﬁcantly enhance the robustness of the cluster-\ning model and improve the quality of clustering results. Additionally, robust\nand reliable clustering solutions can be accomplished with minimal time invest-\nment by integrating the entire process inside a BO framework and presenting\na unique loss function for problem-speciﬁc multi-task optimization. Finally, the\nindependent validation of our methodology using a diﬀerent dataset strengthens\nits viability in clinical applications.\nAlthough we have conducted numerous repeating trials, it is inevitable to\neliminate the randomness for clustering algorithm experiments. In future work,\nwe could include more modalities and datasets to test the framework. To en-\nhance the clinical relevance, more clinical variables could be included into the\nBO framework for multi-task optimization. To summarise, the BO framework\ncombined with the suggested FAE and mixed loss represents a robust frame-\nwork for obtaining clustering results that are clinically relevant and generalizable\nacross datasets.\nReferences\n1. Beig, N., Bera, K., Prasanna, P., Antunes, J., Correa, R., Singh, S., Bamashmos,\nA.S., Ismail, M., Braman, N., Verma, R., et al.: Radiogenomic-Based survival risk\nstratiﬁcation of tumor habitat on Gd-T1w MRI is associated with biological pro-\ncesses in glioblastoma. Clinical Cancer Research 26(8), 1866–1876 (2020)\n2. Brochu, E., Cora, V.M., De Freitas, N.: A tutorial on Bayesian optimization of\nexpensive cost functions, with application to active user modeling and hierarchical\nreinforcement learning. arXiv preprint arXiv:1012.2599 (2010)\n3. Dextraze, K., Saha, A., Kim, D., Narang, S., Lehrer, M., Rao, A., Narang, S.,\nRao, D., Ahmed, S., Madhugiri, V., et al.: Spatial habitats from multiparamet-\nric mr imaging are associated with signaling pathway activities and survival in\nglioblastoma. Oncotarget 8(68), 112992 (2017)\n4. Leone, J., Zwenger, A.O., Leone, B.A., Vallejo, C.T., Leone, J.P.: Overall survival\nof men and women with breast cancer according to tumor subtype. American\njournal of clinical oncology 42(2), 215–220 (2019)\nAdaptive learning with enhanced representation for glioblastoma\n13\n5. Li, C., Wang, S., Liu, P., Torheim, T., Boonzaier, N.R., van Dijken, B.R., Sch¨onlieb,\nC.B., Markowetz, F., Price, S.J.: Decoding the interdependence of multiparametric\nmagnetic resonance imaging to reveal patient subgroups correlated with survivals.\nNeoplasia 21(5), 442–449 (2019)\n6. Li, C., Wang, S., Serra, A., Torheim, T., Yan, J.L., Boonzaier, N.R., Huang, Y.,\nMatys, T., McLean, M.A., Markowetz, F., et al.: Multi-parametric and multi-\nregional histogram analysis of mri: modality integration reveals imaging pheno-\ntypes of glioblastoma. European radiology 29(9), 4718–4729 (2019)\n7. Li, C., Wang, S., Yan, J.L., Piper, R.J., Liu, H., Torheim, T., Kim, H., Zou,\nJ., Boonzaier, N.R., Sinha, R., et al.: Intratumoral heterogeneity of glioblastoma\ninﬁltration revealed by joint histogram analysis of diﬀusion tensor imaging. Neu-\nrosurgery 85(4), 524–534 (2019)\n8. Li, C., Yan, J.L., Torheim, T., McLean, M.A., Boonzaier, N.R., Zou, J., Huang,\nY., Yuan, J., van Dijken, B.R., Matys, T., et al.: Low perfusion compartments in\nglioblastoma quantiﬁed by advanced magnetic resonance imaging and correlated\nwith patient survival. Radiotherapy and Oncology 134, 17–24 (2019)\n9. Mangla, R., Ginat, D.T., Kamalian, S., Milano, M.T., Korones, D.N., Walter,\nK.A., Ekholm, S.: Correlation between progression free survival and dynamic sus-\nceptibility contrast MRI perfusion in WHO grade III glioma subtypes. Journal of\nneuro-oncology 116(2), 325–331 (2014)\n10. Meil˘a, M.: Comparing clusterings by the variation of information. In: Learning\ntheory and kernel machines, pp. 173–187. Springer (2003)\n11. Meyer-B¨ase, A., Saalbach, A., Lange, O., Wism¨uller, A.: Unsupervised clustering\nof fMRI and MRI time series. Biomedical Signal Processing and Control 2(4),\n295–310 (2007)\n12. Mohanty, A.K., Beberta, S., Lenka, S.K.: Classifying benign and malignant mass\nusing glcm and glrlm based texture features from mammogram. International Jour-\nnal of Engineering Research and Applications 1(3), 687–693 (2011)\n13. Park, J.E., Kim, H.S., Kim, N., Park, S.Y., Kim, Y.H., Kim, J.H.: Spatiotempo-\nral Heterogeneity in Multiparametric Physiologic MRI Is Associated with Patient\nOutcomes in IDH-Wildtype Glioblastoma. Clinical Cancer Research 27(1), 237–\n245 (2021)\n14. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,\nT., Lin, Z., Gimelshein, N., Antiga, L., et al.: Pytorch: An imperative style, high-\nperformance deep learning library. Advances in neural information processing sys-\ntems 32, 8026–8037 (2019)\n15. Patel, E., Kushwaha, D.S.: Clustering cloud workloads: K-means vs gaussian mix-\nture model. Procedia Computer Science 171, 158–167 (2020)\n16. Rasmussen, C.E.: Gaussian processes in machine learning. In: Summer school on\nmachine learning. pp. 63–71. Springer (2003)\n17. Sala, E., Mema, E., Himoto, Y., Veeraraghavan, H., Brenton, J., Snyder, A.,\nWeigelt, B., Vargas, H.: Unravelling tumour heterogeneity using next-generation\nimaging: radiomics, radiogenomics, and habitat imaging. Clinical radiology 72(1),\n3–10 (2017)\n18. Snoek, J., Larochelle, H., Adams, R.P.: Practical Bayesian optimization of machine\nlearning algorithms. arXiv preprint arXiv:1206.2944 (2012)\n19. Syed, A.K., Whisenant, J.G., Barnes, S.L., Sorace, A.G., Yankeelov, T.E.: Mul-\ntiparametric analysis of longitudinal quantitative MRI data to identify distinct\ntumor habitats in preclinical models of breast cancer. Cancers 12(6), 1682 (2020)\n14\nYifan Li et al.\n20. Van Griethuysen, J.J., Fedorov, A., Parmar, C., Hosny, A., Aucoin, N., Narayan,\nV., Beets-Tan, R.G., Fillion-Robin, J.C., Pieper, S., Aerts, H.J.: Computational\nradiomics system to decode the radiographic phenotype. Cancer research 77(21),\ne104–e107 (2017)\n21. Von Luxburg, U.: Clustering stability: an overview. Foundations and Trends in\nMachine Learning 2(3), 235–274 (2010)\n22. Wu, J., Cui, Y., Sun, X., Cao, G., Li, B., Ikeda, D.M., Kurian, A.W., Li, R.: Unsu-\npervised clustering of quantitative image phenotypes reveals breast cancer subtypes\nwith distinct prognoses and molecular pathways. Clinical Cancer Research 23(13),\n3334–3342 (2017)\n23. Xia, W., Chen, Y., Zhang, R., Yan, Z., Zhou, X., Zhang, B., Gao, X.: Radio-\ngenomics of hepatocellular carcinoma: multiregion analysis-based identiﬁcation of\nprognostic imaging biomarkers by integrating gene data—a preliminary study.\nPhysics in Medicine & Biology 63(3), 035044 (2018)\n24. Zhang, L.: Dirac delta function of matrix argument. International Journal of The-\noretical Physics pp. 1–28 (2020)\n",
  "categories": [
    "cs.LG",
    "eess.SP"
  ],
  "published": "2021-08-21",
  "updated": "2021-08-21"
}