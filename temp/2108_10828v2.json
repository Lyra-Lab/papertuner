{
  "id": "http://arxiv.org/abs/2108.10828v2",
  "title": "Physics-Informed Deep Learning: A Promising Technique for System Reliability Assessment",
  "authors": [
    "Taotao Zhou",
    "Enrique Lopez Droguett",
    "Ali Mosleh"
  ],
  "abstract": "Considerable research has been devoted to deep learning-based predictive\nmodels for system prognostics and health management in the reliability and\nsafety community. However, there is limited study on the utilization of deep\nlearning for system reliability assessment. This paper aims to bridge this gap\nand explore this new interface between deep learning and system reliability\nassessment by exploiting the recent advances of physics-informed deep learning.\nParticularly, we present an approach to frame system reliability assessment in\nthe context of physics-informed deep learning and discuss the potential value\nof physics-informed generative adversarial networks for the uncertainty\nquantification and measurement data incorporation in system reliability\nassessment. The proposed approach is demonstrated by three numerical examples\ninvolving a dual-processor computing system. The results indicate the potential\nvalue of physics-informed deep learning to alleviate computational challenges\nand combine measurement data and mathematical models for system reliability\nassessment.",
  "text": "1 \n \nPhysics-Informed Deep Learning: A Promising Technique for System \nReliability Assessment \n \nTaotao Zhou1*, Enrique Lopez Droguett2,3, Ali Mosleh3 \n \n1 Center for Risk and Reliability, University of Maryland, College Park, USA \n2 Department of Civil and Environmental Engineering, University of California, Los Angeles, USA \n3The Garrick Institute for the Risk Sciences, University of California, Los Angeles, USA \n \nABSTRACT: \nConsiderable research has been devoted to deep learning-based predictive models for system \nprognostics and health management in the reliability and safety community. However, there is \nlimited study on the utilization of deep learning for system reliability assessment. This paper aims \nto bridge this gap and explore this new interface between deep learning and system reliability \nassessment by exploiting the recent advances of physics-informed deep learning. Particularly, we \npresent an approach to frame system reliability assessment in the context of physics-informed deep \nlearning and discuss the potential value of physics-informed generative adversarial networks for \nthe uncertainty quantification and measurement data incorporation in system reliability assessment. \nThe proposed approach is demonstrated by three numerical examples involving a dual-processor \ncomputing system. The results indicate the potential value of physics-informed deep learning to \nalleviate computational challenges and combine measurement data and mathematical models for \nsystem reliability assessment. \n \nKEYWORDS: physics-informed deep learning, reliability assessment, generative adversarial \nnetworks, uncertainty quantification. \n \n \n* Corresponding author. \nE-mail address: taotao.zhou@outlook.com (Taotao Zhou). \n2 \n \n1. INTRODUCTION \nDeep learning has been an emerging approach to handle multi-dimensional sensor data without \nrequiring many manual feature engineering efforts [1]. This draws increasing attention from the \nreliability and safety community to developing the deep learning-based predictive framework for \nprognostics and health management (PHM), which has been comprehensively documented in \nsome review articles [2, 3, 4]. From a reliability perspective, these studies address some particular \nchallenges encountered in the reliability context: (i) develop probabilistic deep learning models \nthat consider epistemic and aleatory uncertainties in support of the decision-making process [5, 6, \n7]; (ii) develop deep domain adaptation and generalization models that address the challenges of \nvarying working conditions; (iii) develop hybrid deep learning models that exploit both physics \nknowledge and data [8]; (iv) study the robustness of deep learning-based PHM models under \nadversarial attacks [9, 10]; (v) address the imbalanced dataset due to the scarcity of fault \nobservations [11]; (vi) integrate deep learning-based models into the conventional probabilistic \nrisk assessment (PRA) that incorporates the specific systems’ dynamic evolutions [12]. \n \nAll the above research mainly focuses on deep learning-based PHM using the sensor data that \ncaptures the system's health conditions. There is little literature available to explore the value of \ndeep learning in the system reliability assessment. Typically, the system reliability evolution is \nrepresented by mathematical models. For instance, partial differential equations describe the \nunderlying failure mechanisms [13, 14], Markov process characterizes the state transitions using \na set of ordinary differential equations [15]. These problems are usually difficult to solve \nanalytically, and hence numerical methods are commonly used, such as differential equation solver \nand Monte Carlo simulation. These numerical methods are computational expensive especially \nwhen uncertainty and sensitivity analysis is required for safety-critical applications. Moreover, \nthose methods cannot integrate the measurement data collected through inspection and \nmaintenance activities. \n \nRecent advances in scientific machine learning provide a new lens to solve the aforementioned \nproblems [16]. The physics-informed neural networks (PINNs) have been well-recognized since \nthe pioneering work of Raissi et al. [17]. The essential idea is to use neural networks as universal \napproximators of the desired solution and then constrain the training process by designing the loss \nfunction according to the domain-specific knowledge, such as the physics model described by \npartial differential equations. Most recent research focuses on enhancing PINNs by using different \ndeep learning architectures [18, 19, 20] with applications to biophysics, geophysics, and \nengineering sciences [21, 22, 23, 24, 25]. The interested readers can find a comprehensive review \nof the progress of physics-informed deep learning with diverse applications in Karniadakis et al. \n[26].  \n \n3 \n \n \nPhysics-informed deep learning is still in an early stage of development and needs to be well \nconfigured given the specific problem. One of the main concerns is to improve PINNs for \nuncertainty quantification to achieve a robust and reliable prediction. Most notably, physics-\ninformed generative adversarial networks (PIGANs) have been proposed and are still under \ndevelopment to probabilistically leverage observations and the underlying physics model in \nsolving both forward and inverse problems. The studies of PIGANs mainly use a similar \nframework and vary depending on two factors: integrate domain knowledge into either generator \nor discriminator [27]; adopt different types of GANs to improve their training stability [18, 19, 28, \n29, 30]. The choice of PIGANs would vary depending on the scale of specific problems and the \ncomputational resources available. It is worthwhile noting that the above research also shows great \nvalue to address the challenges of scarcity of measurements in system reliability assessment. \nParticularly, the following applications adopted the PIGANs proposed by Yang and Perdikaris \n[18], which integrates domain knowledge into the generator and follows the training scheme \ndeveloped by Li et al. [31]. \n \nThis paper presents a novel perspective of system reliability assessment by leveraging the advance \nof physics-informed deep learning. The main objective is to make a connection between deep \nlearning and system reliability assessment and to further demonstrate the important value of deep \nlearning to benefit system reliability assessment. Our contributions are twofold: \n1) We present an approach to frame system reliability assessment as a problem of deep learning. \nThe essential is to encode the system property into the network configuration and training \nbased on the mathematical model governing system reliability evolutions. Particularly, \napproximate the solution to reliability assessment with a neural network and induce another \nneural network to obtain the derivatives of system state probability by using automatic \ndifferentiate techniques. The outputs of the two neural networks are utilized to construct a \ncomposite loss function, and then gradient-based optimization algorithms are employed to \nlearn the solution to system reliability assessment. It is worthwhile noting that this provides a \ncontinuous solution to the system reliability assessment because of the universal approximation \ntheorem [32]. This enables one to assess system reliability at any given time instant.  \n2) To highlight the potential value of physics-informed deep learning, we discuss a PIGANs-\nbased approach for uncertainty quantitation and incorporating measurement data in system \nreliability assessment. The essential is to formulate a deep probabilistic setting by an \nadversarial game between the data constraints and the mathematical model describing system \nreliability evolution. This provides a new perspective on combining measurement data with \nthe underlying mathematical model. This is particularly valuable for the safety-critical sectors \nwith a small number of measurements, such as passive structures in nuclear power plants. \nMoreover, the proposed approach has superior efficiency to alleviate the computational \n4 \n \nchallenges in uncertainty quantification that is important for the reliability and safety \ncommunity. \n \nThe proposed approach is demonstrated using a dual-processor computing system with \nperformance degradation. Three examples are formulated and discussed to validate the proposed \napproach: (i) the system starts with a perfect condition and degrades over mission time, which is \nvalidated by comparison with the differential equation solver and the Monte Carlo simulation; (ii) \nthe system starts with either a perfect condition or a degraded state. The uncertainty is modeled by \nthe Bernoulli distribution, the epistemic uncertainty of which is modeled by the Beta distribution. \nThe results are validated by comparison with the Monte Carlo simulation; (iii) the system starts \nwith a perfect condition given synthetic measurement data available to reflect the system’s \ncondition during a service life span. This example is heuristically demonstrated by two simulated \nsystems with either better or worse performance as compared to the baseline case in the first \nexample. A heuristic demonstration is presented because measurement data cannot be properly \nincorporated using the current methods for system reliability assessment. Overall, the results \nvalidate the effectiveness of the proposed approach for system reliability assessment and show the \nsuperiority of the proposed approach in computational efficiency.  \n \nThis remaining paper is structured as follows. Section 2 summarizes the problem formulation and \nbackground of system reliability assessment. Section 3 presents the deep learning-based approach \nfor system reliability assessment. Section 4 demonstrates the proposed model using three \nnumerical examples involving a dual-processor computing system. Section 5 discusses the \nconclusions and future directions.  \n \n \n \n \n \n \n \n5 \n \n2. PROBLEM FORMULATION AND BACKGROUND \nConventionally, the component or system performance is modeled as a binary state that is either \nfully functioning or complete failure. However, this is often not the truth, especially, where an \nintermediate state always manifests between fully functioning and complete failure. Therefore, it \nis a natural fit to characterize the component or system states by a range of discrete levels, often \nknown as a multi-state model [33]. Typically, the multi-state model is mathematically described \nby a continuous-time Markov or semi-Markov process in reliability applications. We limit the \nscope of this paper to the continuous-time Markov process. \n \nSuppose a system performance is characterized by a finite number of states 𝑆 = {0, 1, … ,\n𝑗, … , 𝑀}. The system dynamics are reflected by the transitions across states at each time instant 𝑡, \nwhich is parameterized by the transition rate 𝜆!,#(𝑡) from state 𝑖 to state 𝑗. Note that the state \ntransitions are often time-dependent, due to performance deterioration and maintenance \ninterventions. Hence, denote the corresponding transition rate matrix 𝑄(𝑡) at a time instant 𝑡 as \nbelow, where 𝜆!(𝑡) = ∑\n𝜆!,$(𝑡)\n#∈&,#'!\n. \n \n𝑄(𝑡) =\n⎣\n⎢\n⎢\n⎢\n⎢\n⎡−𝜆((𝑡)\n𝜆(,)(𝑡)\n…\n𝜆(,#(𝑡)\n…\n𝜆(,*(𝑡)\n𝜆),((𝑡)\n−𝜆)(𝑡)\n…\n𝜆),#(𝑡)\n…\n𝜆),*(𝑡)\n…\n…\n…\n…\n…\n…\n𝜆#,((𝑡)\n𝜆#,)(𝑡)\n…\n−𝜆#(𝑡)\n…\n𝜆#,*(𝑡)\n…\n…\n…\n…\n…\n…\n𝜆+,((𝑡)\n𝜆+,)(𝑡)\n…\n𝜆+,#(𝑡)\n…\n−𝜆+(𝑡)⎦\n⎥\n⎥\n⎥\n⎥\n⎤\n \n(1) \n \nThe system state at each time instant 𝑡 is represented by a probability vector, that is 𝑝(𝑡) =\n{𝑝((𝑡), 𝑝)(𝑡), … , 𝑝#(𝑡), … , 𝑝+(𝑡)}, where 𝑝#(𝑡) is the probability that the system is in state 𝑗 at \ntime instant 𝑡, and ∑\n𝑝#(𝑡)\n+\n#,)\n= 1. The system state probability can be derived according to the \nforward Kolmogorov equations, which consists of a set of differential equations parameterized by \nthe transition rate matrix and state probability vector in Equation (2). Then the system reliability \ncan be determined by aggregating the state probability where the system is considered as \nfunctioning. \n \n𝑝′(𝑡) = 𝑝(𝑡)𝑄(𝑡) \n(2) \n𝑝(𝑡= 0) = 𝑠( \n(3) \n \nwhere 𝑝′(𝑡) is the derivative of 𝑝(𝑡) for system’s operational time 𝑡, and 𝑝(t = 0) represents the \nsystem state at time instant 0, referred to as the initial condition s(.  \n6 \n \n3. SYSTEM RELIABILITY ASSESSMENT USING DEEP LEARNING \nThis section discusses the deep learning-based approach for system reliability assessment in \ncontinuous time. Section 3.1 discusses the approach to frame a deep learning problem to assess \nsystem reliability. Section 3.2 discusses a PIGANs-based approach for uncertainty quantification \nand measurement data incorporation in system reliability assessment.   \n \n3.1. Frame System Reliability Assessment in Deep Learning Context \nThis section focuses on the connection between deep learning and system reliability assessment. \nThe essential objective is to learn a continuous latent function as the solution to system reliability \nconsidering the possible state transitions and the initial condition. In particular, a neural network \nis utilized to approximate 𝑝(𝑡) which acts as a prior on the unknown reliability solution. According \nto the universal approximation theorem, this leads to a continuous solution that enables one to \nassess the system reliability at any time instant up to mission time. As illustrated in Figure 1, the \nsystem property is encoded into the network configuration and training, which are discussed in the \nfollowing.  \n \n \nFigure 1. Frame system reliability assessment as a problem of deep learning. \n \nIn the network configuration, there are two neural networks with shared parameters that \napproximate the system state probability and obtain their derivative regarding the system’s \n7 \n \noperational time. In other words, the time dependency is encoded by the state probability and its \nderivative at any time instant. These two networks are configured as below: \n• Utilize a neural network 𝑁-(𝑡) as the surrogate for the reliability estimates 𝑝(𝑡), where \n𝑁-(𝑡) denotes a neural network parametrized by 𝜃 and the network input is global time 𝑡. \nThe number of neurons in the output layers needs to match the number of system states. \nThen using the SoftMax function as the activation function in the output layer would \nprovide the probability regarding each system state. This implicitly satisfies the constraints \nof probability value regarding each state in the range [0,1].  \n• Establish an induced neural network 𝑁-\n.(𝑡)  to obtain the derivative of system state \nprobability  𝑝′(𝑡). Particularly, 𝑁-\n.(𝑡) is an induced neural network based on 𝑁-(𝑡) using \nautomatic differentiation. \nThe network training process needs to be constrained to satisfy the system initial condition and \nsystem state transition model as reflected in Equations (2) and (3). Therefore, a composite loss \nfunction can be constructed in Equation (4), by combining two residual terms.   \n𝐿(𝜃) = (𝑁-(t = 0) −𝑠()/ + 𝜆C 1\n𝑁0\nD E𝑁-(𝑡!) ∙𝑄(𝑡!) −𝑑𝑁-(𝑡!)\n𝑑𝑡!\nH\n/\n1!\n!,)\nI \n(4) \nwhere the first term enforces the neural network in agreement with the system’s initial condition \nas given by Equation (3); the second term enforces training process consistent with the system \nstate transition as expressed in Equation (2) by penalizing at 𝑁0 collocation points; 𝜆 is a weighting \nfactor to balance those loss terms. This is then formulated as a minimization problem to train the \nneural networks via gradient-based optimization algorithms.  \nmin\n- 𝐿(𝜃) \n(5) \n \nThe optimal parameters would be learned to parameterize the solutions to system reliability \nassessment. Then one can assess the system state probability at any time instant in Equation (6), \nwhere 𝑝#(𝑡) denotes the 𝑗23 state probability at time 𝑡. As shown in Equation (7), the system \nreliability 𝑅(𝑡) can be obtained by summing the probability regarding a set of state indexes 𝑈, \nwhere the system works reliably. \n \n \n \n \n \n \n𝑝#(𝑡) ≈𝑁-(𝑡)[𝑗]   \n(6) \n𝑅(𝑡) ≈D\n𝑁-(𝑡)[𝑗]\n#∈4\n   \n(7) \n8 \n \n3.2. Physics-Informed Generative Adversarial Networks (GANs) For System Reliability \nAssessment \nThis section further discusses how deep learning can benefit system reliability assessment. \nParticularly, we discuss PIGANs based approach to integrate data constraints in system reliability \nassessment. The idea is to formulate a probabilistic setting to learn the probabilistic distributions \nof the system reliability that, in turn, results in a generative model capable to produce synthetic \ndata, which is consistent with data constraints and underlying mathematical model describing \nsystem reliability evolution. The data constraints would be imposed by measurement data observed \nthrough the system’s lifetime and the system’s initial condition. As displayed in Figure 2, the key \nis to encode both system property and data constraints into the network configuration and training, \nby formulating an adversarial game between a generator and a discriminator. Without loss of \ngenerality, the reasoning behind the network design and training is discussed based on standard \nGANs conditional on the system’s operational time 𝑡. \n \nFigure 2. A physics-informed generative adversarial network (GANs) based approach for system \nreliability assessment considering measurement data. \n9 \n \n \nThe generator 𝑁-\"(𝑡, 𝑍) is designed to produce fake datasets given random noise vector 𝑍 and \ntime 𝑡. 𝑍 is a collection of random latent variables with a multivariate Gaussian distribution and is \nemployed to construct probabilistic representations for the system state probability. The fake data \nneeds to approximately satisfy the underlying state transitions governed by Equation (2). This \ngenerator is designed in the same manner as Section 3.1, with an additional loss term to constrain \nthe learning process to be consistent with the measurement data. The real measurement data is \ndenoted by S𝑡#, 𝑦U𝑡#VW, where 𝑗= 1,2 … 𝑁5. The system’s initial condition can also be treated as \none type of measurement data. Then, we can combine it with the measurement data as [𝑡6,   𝑦(𝑡6)], \nwhere 𝑘= 0,1,2 … 𝑁5 and 𝑦(𝑡( = 0) = 𝑠(. The generator loss function is shown in Equation (8). \nThe first term fools the discriminator to mark the fake dataset as the real ones; the second term \nconstrains the generated fake data to be consistent with the measurement data; the third term \nimposes the constraints according to the domain knowledge.   \n𝐿7(𝜃7) =\n1\n𝑁5 + 1 D log ]1 −𝑁-# ^𝑡6, 𝑁-\"(𝑡6, 𝑧6)`a\n1$\n6,(\n+\n1\n𝑁5 + 1 D ^𝑦(𝑡6) −𝑁-\"(𝑡6, 𝑧6)`\n/\n1$\n6,(\n+ 𝜆C 1\n𝑁0\nD E𝑁-\"(𝑡!, 𝑧!) ∙𝑄(𝑡!) −𝑑𝑁-\"(𝑡!, 𝑧!)\n𝑑𝑡!\nH\n/\n1!\n!,)\nI \n(8) \n \nThe discriminator 𝑁-#(𝑡, 𝑢) is designed to distinguish between fake datasets produced by the \ngenerative model and real datasets collected from measurements. There is one neuron in the output \nlayer with the sigmoid activation function. This constrains the generator to produce a dataset \nmatching the real dataset. The discriminator loss function is shown in Equation (9). The first term \nis maximized to correctly classify the real measurement data, and the second term is maximized \nto correctly detect the fake dataset produced by the generator. \n𝐿8(𝜃8) =\n1\n𝑁5 + 1 D log ^𝑁-#U𝑡6, 𝑦(𝑡6)V`\n1$\n6,)\n+\n1\n𝑁5 + 1 D log ]1 −𝑁-# ^𝑡6, 𝑁-\"(𝑡6, 𝑧6)`a\n1$\n6,(\n \n(9) \n \nThus, the two competing loss functions are used: 𝐿7(𝜃7) and 𝐿8(𝜃8), for the generator and \ndiscriminator, respectively. Then, we derive an adversarial training rule for updating the unknown \n10 \n \nmodel parameters contained in the vectors 𝜃8, 𝜃7. This leads to an adversarial game for training \nthe PIGANs by alternating the optimization of the two objectives in Equations (10) and (11).  \nmax\n-# 𝐿8(𝜃8) \n(10) \nmin\n-\" 𝐿7(𝜃7) \n(11) \nUpon the PIGANs model is successfully trained, the generator 𝑁-\"(𝑡, 𝑧) can be utilized to simulate \nthe system reliability considering measurement data and uncertainty. Particularly, the system \nreliability assessment is accomplished by drawing 𝑁9 samples through stochastic forward passes \nof the generator. A point estimate of 𝑗23 state probability is determined by computing the mean of \nthe predictions regarding each sample in Equation (12). The uncertainty of 𝑗23 state probability is \ncharacterized by intervals with two-standard deviation in Equation (13).  \n \n \n \n𝜎#(𝑡) ≈f\n1\n𝑁9 −1 DS𝑁-\"(𝑡, 𝑧:)[𝑗] −𝑝;(𝑡)\ngggggggW\n/\n1%\n<,)\n \n(13) \n \nAssume the system works reliably in a set of state indexes 𝑈. It is straightforward to compute the \npoint estimate and uncertainty of system reliability by aggregating the state probability within the \nset U as follows: \n \n \n \n𝜎=(𝑡) ≈f\n1\n𝑁9 −1 D hD\n𝑁-\"(𝑡, 𝑧:)[𝑗]\n#∈4\n−𝑅(𝑡)\nggggggi\n/\n1%\n<,)\n \n(15) \n \nThe PIGANs-based approach has twofold advantages. First, the generator can be used as a \nsurrogate model for conventional Monte Carlo simulation. This would be more efficient for a \nhighly reliable system that is often computationally expensive and requires a large number of \nsamples in the conventional Monte Carlo simulation. Second, the proposed approach accounts for \nboth measurement data and the mathematical model, thus, in turn, the system reliability evolution \nsimulated by the generator is also informed by the measurement data. This offers a unique \nadvantage against the current methods that cannot consider measurement data. These two \nadvantages are experimentally demonstrated in the following numerical examples. \n𝑝;(𝑡)\nggggggg ≈1\n𝑁9\nD 𝑁-\"(𝑡, 𝑧:)[𝑗]\n1%\n:,)\n   \n(12) \n𝑅(𝑡)\ngggggg ≈1\n𝑁9\nD D\n𝑁-\"(𝑡, 𝑧:)[𝑗]\n#∈4\n1%\n:,)\n   \n(14) \n11 \n \n4. NUMERICAL EXAMPLES \nThis section demonstrates the deep learning approach for system reliability assessment using three \nnumerical examples involving a four-state system. Section 4.1 provides a brief description of \nproblem formulation. Section 4.2 discusses the results and the model performance assessment. The \nproposed approach was developed based on Python v3.6 [34], and TensorFlow v1.13 [35] using a \ndesktop with Intel Core i7-6700 CPU and 32 GB DDR4 RAM. The differential equation solver \nwas implemented using Matlab [36]. The Monte Carlo simulation was also implemented in Python \nv3.6 [34].  \n \n \nFigure 3. A state transition diagram to describe the performance deterioration of a dual-processor \ncomputing system. \n \n4.1. Problem Description \nConsider a safety model of a dual-processor computing system that degrades through 4 possible \nstates {0, 1, 2, 3} as taken from Rindos et al. [37]. Figure 3 shows the state transition diagram \ndescribing the possible transition across states. With the system state increasing from 0 to 3, the \nsystem continuously degrades until a safe or unsafe failure. The system is considered reliable in \nstates 0 and 1, so the system reliability can be calculated by summing the probability of these two \nstates. The definition of each state is presented below. \n• State 0: the system functions in full capacity with two processors. \n• State 1: the system works in a degraded mode given any of the two processors fails, which \ncan be successfully detected (i.e., probability 𝑐/). \n• State 2: the system is operated in a degraded state, and the other processor failure leads to \nsafe shutdown (i.e., probability 𝑐)). \n12 \n \n• State 3: the system fails unsafely due to two scenarios: any of the two processors fails but \nis not detected (i.e., probability 1 −𝑐/); the failure of the other processor leads the system \nto an unsafe state (i.e., probability 1 −𝑐)) when the system is operated in a degraded state. \nThe transition across states follows the Weibull distribution, and the transition rates are denoted \nby 𝜆(𝑡) = 𝜆(𝛼𝑡>?), where 𝑡 is the system’s operational time. This results in a Non-Homogenous \nContinuous-Time Markov system where the transition rates depend on the system's operational \ntime.  In this paper, we set the parameters as the same as Rindos et al. [37], that is 𝑐/  =  0.9, 𝑐)  =\n 0.9, 𝜆( = 0.01 and 𝛼= 2.0. The corresponding transition rate matrix is shown in Equation (16). \n \n𝑸(𝒕) = p\n−0.04 ∙𝑡\n0.036 ∙𝑡\n0\n0.004 ∙𝑡\n0\n−0.02 ∙𝑡\n0.018 ∙𝑡\n0.002 ∙𝑡\n0\n0\n0\n0\n0\n0\n0\n0\nu \n \n(16) \nTo demonstrate our proposed approach, three example problems are formulated with the detailed \nsetup below: \n1) Suppose the system starts with a perfect working condition (i.e., state 0) and degrades over a \nservice life span. The results are validated by a comparative study with the ordinary differential \nequation solver and the Monte Carlo simulation, respectively. \n2) Suppose the system starts with a perfect working condition (i.e., state 0) or degraded state (i.e., \nstate 1), which follows the Bernoulli distribution. This scenario is subject to large uncertainty \ndue to the cause of manufacturing defects and installation in the field. Hence, we use the Beta \ndistribution to model the epistemic uncertainty for the Bernoulli distribution. The results are \nvalidated by comparison with the Monte Carlo simulation.  \n3) The third example intends to demonstrate how the deep learning approach can incorporate the \nmeasurement data into the mathematical model describing the underlying state transitions. \nParticularly, we follow the same assumption that the system starts with a perfect working \ncondition; generate some synthetic measurement data by using the results in the first example \nas a baseline; heuristically validate the results by discussing the impacts of measurements on \nthe system behavior.  \n \n4.2. Results and Discussions \nThis section discusses the results of the three examples. For validation purposes, all the following \ndiscussions are based on the system reliability with a certain time step (i.e., 1-time unit) equally \nup to mission time 30.  \n13 \n \n \n4.2.1. Example 1 \nThe system reliability is assessed using the proposed approach in Section 3.1. The neural network \nconsists of 2 hidden layers, each of which has 50 neurons and uses the Tanh activation function. \nThere are four neurons in the output layer with the SoftMax activation function. The output of \neach neuron corresponds to the probability of each system state, respectively. There are 40 \ncollocation points, which are generated linearly spaced within the range [0, 30]. The network is \ntrained using the Adam optimization algorithm and the number of iterations is 2 × 10@. An \nexponential decaying learning rate is applied with the starting learning rate as 1 × 10?A, the decay \nrate as 0.9 and the decay step as 1000. The weighting factor 𝜆 is set equal to 1. On the other hand, \nbaseline results are obtained by using the differential equation solver particularly the Runge-Kutta \nmethod and the Monte Carlo simulation with 1 × 10B iterations. Figure 4 summarizes the mean \nvalue of each system state probability. The results of the proposed approach are close to the \nbaseline results, which indicates the good performance of our proposed approach.  \n \nFigure 4. The results of system state probability using the proposed approach, the differential \nequation solver, and the Monte Carlo simulation. \n \nTo further evaluate the consistency of the results between the proposed approach and the \ndifferential equation solver, we run the proposed approach for 60 replications considering the \n14 \n \nrandom effects through training and testing. The consistency between the results is measured using \nthe root mean square error (RMSE) in Equation (17), where 𝑝#\n∗(𝑡) is the probability of state 𝑗 at \ntime 𝑡 given by the differential equation solver, 𝑝#\n!(𝑡) is the state probability of state 𝑗 at time 𝑡 \nobtained in the 𝑖23 replication of the proposed approach, the total number of replications is 𝑁, \n𝑅𝑀𝑆𝐸#(𝑡) is the RMSE of 𝑗23 state probability between the proposed approach and differential \nsolver at time 𝑡. \n \n𝑅𝑀𝑆𝐸#(𝑡) = f1\n𝑁DS𝑝#\n!(𝑡) −𝑝#\n∗(𝑡)W\n/\n1\nD,)\n \n(17) \n \nThe distributions of 𝑅𝑀𝑆𝐸#(𝑡) up to mission time are summarized in Figure 5. The overall \nvariability of the RMSE is further illustrated by its value of 5% quantile, median, mean, and 95% \nquantile. The RMSE remains relatively small and indicates the effectiveness of our proposed \nmethod to achieve a satisfactory assessment of system reliability. \n \n \nFigure 5. The root mean square error (RMSE) of the results between the proposed approach and \nthe differential equation solver. \n \n15 \n \nThe proposed approach is also validated by comparison with the Monte Carlo simulation.  \nConsidering the random effects of both methods, we run the proposed approach and the Monte \nCarlo simulation for 60 replications, respectively. The predictive uncertainty at each time instant \nis characterized by the mean and standard deviation of the corresponding realizations. The \nprediction of 𝑗23 state probability at time 𝑡 is denoted: by mean 𝑝#(𝑡) and standard deviation 𝜎#(𝑡) \nusing the proposed approach; by mean 𝑝#\n.(𝑡) and standard deviation 𝜎#\n.(𝑡) using the Monte Carlo \nsimulation. Then evaluate the consistency of results between the proposed approach and the Monte \nCarlo simulation by measuring their absolute difference and composite standard deviation, as \nrepresented by ∆𝑝#(𝑡) and ∆𝜎#(𝑡) in Equations (18) and (19), representatively.  \n \n∆𝑝#(𝑡) = y𝑝#(𝑡) −𝑝#\n.(𝑡)y \n(18) \n \n∆𝜎#(𝑡) = z𝜎#(𝑡)/ + 𝜎#\n.(𝑡)/ \n(19) \n \nFigures 6 and 7 show the distribution of ∆𝑝#(𝑡) and ∆𝜎#(𝑡) up to mission time. The values of \nabsolute difference and composite standard deviation remain relatively small, which shows that \nthe performance of the proposed approach is as comparable as the Monte Carlo simulation. \nFurthermore, it is worthwhile noting that the proposed approach only takes 17.9 seconds for a \nreplicate, while a replicate of the Monte Carlo simulation takes 283.4 seconds. This shows the \nsuperiority of the proposed approach in terms of computational efficiency. \n \nFigure 6. The absolute difference of the results between the proposed approach and the Monte \nCarlo simulation.  \n16 \n \n \nFigure 7. The composite standard deviation of the results between the proposed approach and the \nMonte Carlo simulation.  \n \nSo far, we have demonstrated the performance of the proposed approach in assessing each system \nstate probability. Then, we can calculate the system reliability by summing the probability in states \n0 and 1. The results of system reliability are displayed in Figure 8 and show a good match for the \nresults using all three methods. Therefore, we can conclude the validity of the proposed approach \nto assess system reliability.  \n17 \n \n \nFigure 8. The results of system reliability using the proposed approach, the differential equation \nsolver, and the Monte Carlo simulation.  \n \n \n4.2.2. Example 2 \nThe proposed approach is of particular advantage for uncertainty quantification, which is important \nin reliability and safety applications. This example shows how the proposed approach can \npropagate and quantify the uncertainty of the system’s initial condition. Denote the probability \nvector of the system’s initial condition by [𝜌(, 1 −𝜌(, 0,0,0,0] , where 𝜌(  follows the Beta \ndistribution parameterized by two shape parameters, 𝛼=  5  and 𝛽= 1.5. To integrate such \nuncertainty in the proposed approach, 50 samples are generated accordingly and are treated as a \ntype of boundary condition, which needs to be satisfied by the neural network training process. In \nthe generator, the neural network consists of 4 hidden layers of 50 neurons with the Tanh activation \nfunctions. There are four units in the final layer with the SoftMax activation function. The number \nof collocation points is 40, which are linearly spaced values generated within the range [0, 30]. In \nthe discriminator, the neural network has 2 hidden layers of 50 neurons with the Tanh activation \nfunctions and 1 neuron in the output layer. An exponential decaying learning rate is applied with \nthe starting learning rate as 1 × 10?/ , the decay rate as 0.9 and the decay step as 1000. The number \nof iterations is 1 × 10B using the Adam optimization algorithm. The weighting factor 𝜆 is set equal \nto 1.  Once the model is well trained, the generator is used to generate 5 × 10A samples to estimate \nthe system state probability with uncertainty.  \n \n18 \n \nThe Monte Carlo simulation consists of 50 replications and each replication includes 1 × 10B \niterations. Note that each sample from the Monte Carlo simulation represents the actual state \nnumber, while the samples in the proposed approach represent the system state probability vector. \nNote that the Monte Carlo simulation is computationally expensive, which takes 300.6 seconds \nper replication and needs around 4 hours in total. However, the whole training and sampling \nprocess of the proposed approach takes only 625.9 seconds. This indicates the superior \ncomputational efficiency of the proposed approach that is 24 times more computationally efficient \nwhen compared with the Monte Carlo simulation.  \n \nFigures 9 and 10 display the predictions with uncertainty quantification for system state probability \nand system reliability, respectively. The results indicate the consistency between the proposed \napproach and the Monte Carlo simulation. Indeed, some deviations are observed in both the mean \nprediction and uncertainty bound for each state probability. Such deviation would be attributed to \nthe sources of uncertainty due to the Monte Carlo simulation and the neural network configuration. \nThis inconsistency would be further reduced by increasing the number of replications and \niterations for the Monte Carlo simulation, enhancing the network configuration and training \nprocess. Note that the difficulty of training GANs has been well recognized, and the training of \nPIGANs becomes even more challenging due to the integration of more complicated composite \ngenerator loss. This is still an open topic on improving the configuration of network architecture \nand training of PIGANs, which is discussed in Section 5 and will be considered in the authors’ \nfuture work.  \n \n \n19 \n \n \nFigure 9. The results of system state probability using the proposed approach and the Monte \nCarlo simulation considering the measurement data of the system’s initial condition. \n \nFigure 10. The results of system reliability using the proposed approach and the Monte Carlo \nsimulation considering the measurement data of system initial condition. \n20 \n \n \n \nFigure 11. A comparison of the distribution of state probability initially in states 0 and 1 using \nthe proposed approach. \n \nWe also present a comparison between the exact system’s initial condition and the corresponding \nprediction by the proposed approach. A shown in Figure 11, the proposed approach performs well \nto quantify the uncertainty of the system’s initial condition. Then, we follow the same process in \nSection 4.2.1 to evaluate the consistency of the results between the proposed approach and the \nMonte Carlo simulation. Figures 12 and 13 summarize the distribution of absolute difference and \ncomposite standard deviation between the proposed approach and the Monte Carlo simulation. As \ncan be observed, both the two measures remain relatively small. Hence, the proposed approach \nprovides a satisfactory result when compared with the Monte Carlo simulation.  \n \n \n21 \n \n \nFigure 12. The absolute difference of the results between the proposed approach and the Monte \nCarlo simulation considering the measurement data of system initial condition. \n \nFigure 13. The composite standard deviation of the results between the proposed approach and \nthe Monte Carlo simulation considering the measurement data of system initial condition. \n22 \n \n \n \n4.2.3. Example 3 \nThis example demonstrates the capability of the proposed approach to incorporate measurement \ndata observed during a service life span. Note that the state-of-the-art method cannot incorporate \nthis type of measurement data into system reliability assessment. Therefore, we heuristically \ndemonstrate the process using a system with either better or worse performance when compared \nto the system in the first example as a baseline case. Specifically, synthetic measurement data are \ngenerated at various inspection time instances to reflect the performance deviation (i.e., better, or \nworse) from the baseline system. We incorporate these synthetic measurement data into system \nreliability assessment based on the proposed approach in Section 3.2 which, in turn, results in an \nupdated evolution of system reliability up to mission time. Then one can heuristically evaluate the \ntrend of reliability evolution in the simulated system. If the trend of updated reliability evolution \nis consistent with the assumption used to generate such synthetics measurement data, the proposed \napproach can be considered as effective to incorporate the measurement data collected during a \nservice life span.  \n \nSuppose a simulated system is inspected at time 𝑡, and the corresponding measurement data is \n[𝑡, 𝑝2], where 𝑡 is the simulated system’s operational time, and 𝑝2 is the state probability vector \naccording to inspection and expert judgment. The same notation applies to the baseline case and \nthe baseline system state probability is denoted by [𝑡∗, 𝑝2∗\n∗]. Then, the synthetic measurement data \ncan be generated as equal to the state probability vector 𝑝2\n∗ of the baseline case at a time instant \n𝑡∗= 𝑡∓∆𝑡, which shifts the inspection time 𝑡 forward or backward. Particularly, a backward shift \nthat is 𝑡∗= 𝑡−∆𝑡 leads to a system with better performance; a forward shift that is 𝑡∗= 𝑡+ ∆𝑡 \nleads to a system with worse performance. \n \nTable 1: The synthetic measurement data generated to simulate a system with better or worse \nperformance \n \nInspection-\nTime 𝑡 \nTime-\nShifted ∆𝑡 \nSynthetic Measurement \nData \nSystem \nReliability \nA system with better \nperformance \n5 \n2 \n[8.35E-01, 1.42E-01, \n6.20E-03, 1.72E-02] \n0.977 \n10 \n2 \n[2.79E-01, 4.47E-01, \n1.81E-01, 9.23E-02] \n0.726 \n15 \n2 \n[3.43E-02, 2.71E-01, \n5.38E-01, 1.56E-01] \n0.3053 \n23 \n \nA system with worse \nperformance \n2 \n3 \n[8.35E-01, 1.42E-01, \n6.20E-03, 1.72E-02] \n0.977 \n5 \n2 \n[3.75E-01, 4.27E-01, \n1.22E-01, 7.60E-02] \n0.802 \n9 \n4 \n[3.43E-02, 2.71E-01, \n5.38E-01, 1.56E-01] \n0.3053 \n \nFor demonstration purposes, Table 1 shows the synthetic measurement data generated to simulate \ntwo systems with either better or worse performance. The measurement data is sequentially used \nto update the system reliability evolution. The network architecture is used as the same as that is \nused in Section 4.2.2. The Adam optimization algorithm is used for training with 2 × 10@ \niterations. The weighting factor 𝜆 is set equal to 1. An exponential decaying learning rate is applied \nwith the starting learning rate as 1 × 10?A, the decay rate as 0.9 and the decay step as 1000. Figures \n14 and 15 show the reliability evolution of the simulated system with worse and better performance, \nrespectively. The validity of results can be justified by the insights as below: \n• The model can generally capture the trend that the reliability of the simulated system is \nalmost always lower or larger than the baseline case as in Figures 14 and 15, respectively. \n• The uncertainty of the reliability evolution can be effectively quantified to consider the \nmeasurement data since the synthetic measurement data are bounded by the two-standard \ndeviation intervals of the updated system reliability. \n• With more inspection data available in both simulated systems, the distance between the \nsimulated system reliability curve and baseline system reliability curve becomes greater. \nThis indicates that more measurement data make the model more confident to conclude \nthat the simulated system is different from the baseline case.  \n \n24 \n \n \nFigure 14. Updated reliability evolution for a simulated system with worse performance as \ncompared to the baseline case. \n25 \n \n \nFigure 15. Updated reliability evolution for a simulated system with better performance as \ncompared to the baseline case. \n \n26 \n \n \n5. CONCLUSIONS AND FUTURE DIRECTIONS \nThis paper presented a novel perspective on system reliability assessment by leveraging the \nadvance of physics-informed deep learning. We discussed the approach to formulate system \nreliability assessment in the deep learning context by encoding the system property into the \nnetwork configuration and training which, in turn, led to a continuous solution to system reliability \nassessment that is parametrized by the neural network parameters. Those were accomplished based \non the universal approximation theorem and automatic differentiation techniques. Upon bridging \nthe gap between deep learning and system reliability assessment, we demonstrated the benefits of \nuncertainty quantification and measurement data incorporation using a PIGANs-based approach. \nThe proposed approach was validated by three numerical examples using a dual-processor \ncomputing system. The model performance was examined by comparison with the differential \nequation solver and the Monte Carlo simulation. The results demonstrated that the physics-\ninformed deep learning approach performs satisfactorily and has superior computational efficiency \nfor system reliability assessment. Note that the results presented in this paper would be further \nimproved by tuning the network configuration and training process. We hope that this paper can \nfacilitate a better understanding and future exploration of the deep learning application to system \nreliability assessment, as we believe it holds many potential advantages for deep learning-based \napproaches for the reliability and safety community. \n \nThe systematic configuration of a robust network architecture and training algorithm for physics-\ninformed deep learning is still an open and active research issue. Future work would be leveraging \nthe advance of deep learning, such as use Bayesian deep learning and deep ensemble learning to \nenhance the capability of uncertainty quantification in system reliability assessment; exploit meta-\nlearning and multi-task learning techniques to improve and facilitate the training process for \nsystem reliability assessment; develop new network configurations to address non-Markovian \nsystem reliability assessment; use physics-informed deep learning to discover new patterns of \nunderlying system reliability evolution; develop a systematic framework to integrate measurement \ndata and other mathematical models describing system reliability evolution. \n \n \n \n \n27 \n \nREFERENCES \n1. Goodfellow I., Bengio Y., and Courville A. \"Deep learning,\" Cumberland: MIT Press (2016).  \n2. Jia F., Lei Y., Lin J., Zhou X., and Lu N. \"Deep neural networks: A promising tool for fault \ncharacteristic mining and intelligent diagnosis of rotating machinery with massive data,\" \nMechanical Systems and Signal Processing, 72-73, pp.303-315 (2016).  \n3. Zhao R., Yan R., Chen Z., Mao K., Wang P., and Gao R. \"Deep learning and its applications \nto machine health monitoring,\" Mechanical Systems and Signal Processing, 115, pp.213-237 \n(2019).  \n4. Fink O., Wang Q., Svensen M., Dersin P., Lee W. J., and Ducoffe M. \"Potential, challenges \nand future directions for deep learning in prognostics and health management applications,\" \nEngineering Applications of Artificial Intelligence, 92, 103678 (2020). \n5. Kraus M. and Feuerriegel S. \"Forecasting remaining useful life: Interpretable deep learning \napproach via variational Bayesian inferences,\" Decision Support Systems, 125, 113100 (2019). \n6. Li G., Yang L., Lee C.G., Wang X., and Rong M. \"A Bayesian deep learning RUL framework \nintegrating epistemic and aleatoric uncertainties,\" IEEE Transactions on Industrial Electronics. \n(2020).  \n7. Caceres J., Gonzalez D., Zhou T., and Droguett E.L. \"A probabilistic Bayesian recurrent neural \nnetwork for remaining useful life prognostics considering epistemic and aleatory \nuncertainties,\" Structural Control and Health Monitoring, e2811 (2021). \n8. Wang J., Li Y., Zhao R., and Gao R. X. \"Physics guided neural network for machining tool \nwear prediction,\" Journal of Manufacturing Systems, 57, 298-310 (2020). \n9. Zhou X., Canady R., Li Y., and Gokhale A. \"Overcoming adversarial perturbations in data-\ndriven prognostics through semantic structural context-driven deep learning,\" In Annual \nConference of the PHM Society, Vol. 12, No. 1, pp. 11-11 (2020). \n10. Champneys M.D., Green A., Morales J., Silva M., and Mascarenas D. \"On the vulnerability of \ndata-driven structural health monitoring models to adversarial attack,\" Structural Health \nMonitoring, 20(4), 1476-1493 (2021). \n11. Wu J., Zhao Z., Sun C., Yan R., and Chen X. \"Learning from class-imbalanced data with a \nmodel-agnostic framework for machine intelligent diagnosis,\" Reliability Engineering & \nSystem Safety, 107934 (2021). \n12. Moradi R., Palazuelos A.R.T., Droguett E.L., and Groth K.M. \"Towards a framework for risk \nmonitoring of complex engineering systems with online operation data: A deep learning based \nsolution,\" Proceedings of the 30th European Safety and Reliability Conference and the 15th \nProbabilistic Safety Assessment and Management Conference, Venice, Italy, November 1-5 \n(2020). \n13. Ross S.M., \"Stochastic Processes,\" 2nd Edition, Wiley, 1995. \n14. Chapra S.C. and Canale R.P. \"Numerical methods for engineers (Vol. 1221),\" New York: \nMcgraw-hill (2011).  \n28 \n \n15. Lisnianski A., Frenkel I., and Karagrigoriou A. \"Recent advances in multi-state systems \nreliability: Theory and applications,\" Springer (2017). \n16. Rackauckas C., Ma Y., Martensen J., Warner C., Zubov K., Supekar R., Skinner D., Ramadhan \nA., and Edelman A. \"Universal differential equations for scientific machine learning,\" arXiv \npreprint arXiv:2001.04385 (2020). \n17. Raissi M., Perdikaris P., and Karniadakis G.E. \"Physics-informed neural networks: A deep \nlearning framework for solving forward and inverse problems involving nonlinear partial \ndifferential equations,\" Journal of Computational Physics, 378, 686-707 (2019). \n18. Yang Y. and Perdikaris P. \"Adversarial uncertainty quantification in physics-informed neural \nnetworks,\" Journal of Computational Physics, 394, 136-152 (2019). \n19. Yang L., Zhang D., and Karniadakis G.E. \"Physics-informed generative adversarial networks \nfor stochastic differential equations,\" SIAM Journal on Scientific Computing, 42(1), A292-\nA317 (2020). \n20. Yang L., Meng X., and Karniadakis G.E. \"B-PINNs: Bayesian physics-informed neural \nnetworks for forward and inverse PDE problems with noisy data,\" Journal of Computational \nPhysics, 425, 109913 (2021). \n21. Raissi M., Yazdani A., and Karniadakis G.E. \"Hidden fluid mechanics: Learning velocity and \npressure fields from flow visualizations,\" Science, 367(6481), 1026-1030 (2020). \n22. Singh R., Shah V., Pokuri B., Sarkar S., Ganapathysubramanian B., and Hegde C. \"Physics-\naware deep generative models for creating synthetic microstructures,\" arXiv preprint \narXiv:1811.09669 (2018). \n23. Zheng Q., Zeng L., and Karniadakis G.E. \"Physics-informed semantic inpainting: Application \nto geostatistical modeling,\" Journal of Computational Physics, 419, 109676 (2020). \n24. Yazdani A., Lu L., Raissi M., and Karniadakis G.E. \"Systems biology informed deep learning \nfor inferring parameters and hidden dynamics,\" PLoS Computational Biology, 16(11), \ne1007575 (2020). \n25. Cofre-Martel S., Droguett, E.L., and Modarres M. \"Remaining useful life estimation through \ndeep learning partial differential equation models: A framework for degradation dynamics \ninterpretation using latent variables.\" Shock and Vibration, 9937846 (2021). \n26. Karniadakis G.E., Kevrekidis I.G., Lu L., Perdikaris P., Wang S., and Yang L. \"Physics-\ninformed machine learning,\" Nature Reviews Physics, 1-19 (2021). \n27. Daw A., Maruf M., and Karpatne A. \"PID-GAN: A GAN framework based on a physics-\ninformed discriminator for uncertainty quantification with physics,\" arXiv preprint \narXiv:2106.02993 (2021). \n28. Warner J.E., Cuevas J., Bomarito G.F., Leser P.E., and Leser W.P. \"Inverse estimation of \nelastic modulus using physics-informed generative adversarial networks,\" arXiv preprint \narXiv:2006.05791 (2020). \n29. Jacquier P., Abdedou A., Delmas V., and Soulaïmani, A. \"Non-intrusive reduced-order \nmodeling using uncertainty-aware Deep Neural Networks and Proper Orthogonal \n29 \n \nDecomposition: Application to flood modeling,\" Journal of Computational Physics, 424, \n109854 (2021). \n30. Lütjens B., Leshchinskiy B., Requena-Mesa C., Chishtie F., Díaz-Rodríguez N., Boulais, O., \nSankaranarayanan A., Pina A., Gal Y., Raissi C., Lavin A., and Newman D. \"Physically-\nconsistent generative adversarial networks for coastal flood visualization,\" arXiv preprint \narXiv:2104.04785 (2021). \n31. Li C., Li J., Wang G., and Carin L. \"Learning to sample with adversarially learned likelihood-\nratio,\" (2018). \n32. Hornik K., Stinchcombe M., and White H. \"Multilayer feedforward networks are universal \napproximators,\" Neural networks, 2(5), 359-366 (1989). \n33. Rausand M., Barros A., and Hoyland, A. \"System reliability theory: Models, statistical \nmethods, and applications,\" 3rd Edition, John Wiley & Sons (2020). \n34. Van Rossum G. and Drake F.L. \"Python 3 reference manual,\" Scotts Valley, CA: CreateSpace \n(2009). \n35. Abadi M. Barham P., Chen J., Chen Z., Davis A., Dean J., Devin M., Ghemawat S., Irving G., \nIsard M., Kudlur M., Levenberg J., Monga R., Moore S., Murray D.G., Steiner B., Tucker P., \nVasudevan V., Warden P., Wicke M., Yu Y., and Zheng X. \"Tensorflow: A system for large-\nscale machine learning,\" Proceedings of the 12th USENIX Symposium on Operating Systems \nDesign and Implementation (OSDI ’16), Savannah, GA, USA, November 2–4 (2016) \n36. Shampine L.F., Gladwell I., and Thompson S. \"Solving ODEs with MATLAB,\" Cambridge \nUniversity Press, Cambridge U.K. (2003). \n37. Rindos A., Woolet S., Viniotis I., and Trivedi K. \"Exact methods for the transient analysis of \nnonhomogeneous continuous time Markov chains.\" In Computations with Markov chains, pp. \n121-133. Springer, Boston, MA (1995). \n \n",
  "categories": [
    "stat.ML",
    "cs.LG"
  ],
  "published": "2021-08-24",
  "updated": "2021-09-05"
}