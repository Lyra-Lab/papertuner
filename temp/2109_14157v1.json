{
  "id": "http://arxiv.org/abs/2109.14157v1",
  "title": "Hybrid Dynamic Contrast and Probability Distillation for Unsupervised Person Re-Id",
  "authors": [
    "De Cheng",
    "Jingyu Zhou",
    "Nannan Wang",
    "Xinbo Gao"
  ],
  "abstract": "Unsupervised person re-identification (Re-Id) has attracted increasing\nattention due to its practical application in the read-world video surveillance\nsystem. The traditional unsupervised Re-Id are mostly based on the method\nalternating between clustering and fine-tuning with the classification or\nmetric learning objectives on the grouped clusters. However, since person Re-Id\nis an open-set problem, the clustering based methods often leave out lots of\noutlier instances or group the instances into the wrong clusters, thus they can\nnot make full use of the training samples as a whole. To solve these problems,\nwe present the hybrid dynamic cluster contrast and probability distillation\nalgorithm. It formulates the unsupervised Re-Id problem into an unified\nlocal-to-global dynamic contrastive learning and self-supervised probability\ndistillation framework. Specifically, the proposed method can make the utmost\nof the self-supervised signals of all the clustered and un-clustered instances,\nfrom both the instances' self-contrastive level and the probability\ndistillation respective, in the memory-based non-parametric manner. Besides,\nthe proposed hybrid local-to-global contrastive learning can take full\nadvantage of the informative and valuable training examples for effective and\nrobust training. Extensive experiment results show that the proposed method\nachieves superior performances to state-of-the-art methods, under both the\npurely unsupervised and unsupervised domain adaptation experiment settings.",
  "text": "1\nHybrid Dynamic Contrast and Probability\nDistillation for Unsupervised Person Re-Id\nDe Cheng, Jingyu Zhou, Nannan Wang∗Member, IEEE, Xinbo Gao Senior Member, IEEE.\nAbstract—Unsupervised person re-identiﬁcation (Re-Id) has\nattracted increasing attention due to its practical application\nin the read-world video surveillance system. The traditional\nunsupervised Re-Id are mostly based on the method alternating\nbetween clustering and ﬁne-tuning with the classiﬁcation or\nmetric learning objectives on the grouped clusters. However, since\nperson Re-Id is an open-set problem, the clustering based meth-\nods often leave out lots of outlier instances or group the instances\ninto the wrong clusters, thus they can not make full use of the\ntraining samples as a whole. To solve these problems, we present\nthe hybrid dynamic cluster contrast and probability distillation\nalgorithm. It formulates the unsupervised Re-Id problem into\nan uniﬁed local-to-global dynamic contrastive learning and self-\nsupervised probability distillation framework. Speciﬁcally, the\nproposed method can make the utmost of the self-supervised\nsignals of all the clustered and un-clustered instances, from both\nthe instances’ self-contrastive level and the probability distillation\nrespective, in the memory-based non-parametric manner. Besides,\nthe proposed hybrid local-to-global contrastive learning can take\nfull advantage of the informative and valuable training examples\nfor effective and robust training. Extensive experiment results\nshow that the proposed method achieves superior performances\nto state-of-the-art methods, under both the purely unsupervised\nand unsupervised domain adaptation experiment settings.\nIndex Terms—Unsupervised, Person Re-Id, Dynamic Con-\ntrastive Learning, Probability Distillation.\nI. INTRODUCTION\nU\nNsupervised person Re-Id aims to train a deep model\ncapable of retrieving the person of interest from a large\namount of unlabeled person Re-Id datasets. This task attracts\nincreasing attention in the computer vision research ﬁeld in\nrecent years, due to the great demand in practical intelligent\nvideo surveillance and the expensive labeling cost with ever-\nincreasing surveillance data. Thus, developing efﬁcient and\nrobust unsupervised person Re-Id system is very appealing\nnot only in the academic area but also for the industrial ﬁeld.\nExisting unsupervised person Re-Id methods falls into the\nfollowing two categories: 1) the purely unsupervised learning\n(USL) person Re-Id; 2) the unsupervised domain adaptation\n(UDA) person Re-Id. The purely USL methods don’t use\nany labeled data for pre-training. They generally estimate the\npseudo labels for the completely unlabeled training sample,\nthen they gradually use the pseudo labels for classiﬁcation or\nmetric learning, the traditional method is named ”Clustering\nand Fine-tuning” [1]. The UDA methods usually adopt the\ntwo-stage training strategy, they ﬁrst pre-train a model on the\nsource labeled dataset, and then ﬁnetune the model on the\nunlabeled target datasets in an unsupervised manner. For the\nunsupervised ﬁne-tuning stage, many state-of-the-art methods\ndemonstrate the effectiveness of the pseudo-label-based USL\nmethods [2], [3], [4], [5], [6]. Besides, the UDA methods\nalways exploit the relationships between the source and target\ndatasets, and adapt the model trained on the source domain\nto capture the inter-sample relations in the target domain.\nGenerally the UDA methods are superior to that of the purely\nUSL for person Re-Id, since the UDA methods could improve\nthe performances on the target domain by transferring the\nlearned knowledge from the labeled source domain.\nIn this paper, we formulate the USL and UDA methods\ninto the same infrastructure. The proposed method can be\neasily extended from the purely USL to the UDA person Re-Id\ntask, with effective performance improvements and requiring\nno complex training process. Existing state-of-the-art USL\nmethods integrate pseudo-label-based algorithm to the hybrid\nmemory-based contrastive learning framework[4], and the\nrepresentative memory-based method ﬁrst extract all the image\nfeatures of the training data by the current feature extractor and\nstore them in the memory bank. Then, they use a clustering\nmethod, like DBSCAN [7] or K-means [8], to group the\nimage features and generate the pseudo labels, thus the cluster\nID is assigned to each image as its person identity. Finally,\nthe deep model is trained with the contrastive loss or some\nother identity classiﬁcation loss using the corresponding image\nfeatures contained in the memory bank. Such memory-based\nmethods have the following merits:1) The image features can\nbe updated gradually as a whole, then the clustering step can\nbe processed online and the estimated pseudo label of the\nimage could be gradually corrected in the training process; 2)\nThe memory-based methods can utilize large batch sizes of the\ntraining data in every training step. This could great beneﬁt\nthe contrastive learning, where the more sample pairs are used\nin each training batch, the better performance improvements\ncan be obtained, as larger batches are likely to contain more\ninformative examples. Thus, this memory-based method can\novercome the limitations of the GPU memory in the training\nprocess, then the deep model can be optimized globally in\neach training step.\nAlthough these memory-based contrastive learning methods\nhave achieved remarkable performance, there still contains a\nlarge gap between the purely USL and supervised methods.\nAfter detailed analysis of these methods, we consider that there\nexist the following two major limitations hindering the further\nperformance improvements for the purely USL person Re-Id:\n1) The traditional ”Clustering-Finetuning”-based methods [1]\ndidn’t explore the valuable training samples from different\nviewpoints or cameras with the same identity for person Re-\nId tasks. Since the unsupervised person Re-Id task is a little\ndifferent from the traditional unsupervised classiﬁcation task,\narXiv:2109.14157v1  [cs.CV]  29 Sep 2021\n2\nthe true cluster for the person Re-Id task always contains\nsamples from different viewpoints or different cameras, which\nare the most informative training examples but make the\nintra-class distances always larger than that of the inter-\nclass distances. Especially in the clustering process, this leads\nthe samples in each cluster only contains samples from the\nsame viewpoint or camera. Some methods may relax the\ncluster conditions, usually it could only get a small portion\nof samples in different viewpoints with the same identity, or\nsometimes get the incorrect samples. However, the sample\npairs in different viewpoints or cameras with the same identity\nare the most valuable training samples for the person Re-\nId task. 2) The traditional USL methods did not make full\nuse of the training samples, especially for lots of un-clustered\ninstances. Usually, the clustering method group the training\ndata into the conﬁdent clusters and some un-clustered outlier\ninstances. To ensure the reliability of the generated pseudo\nlabels, recent existing methods [9], [5], [2] simply discard the\nun-clustered outliers from being used for training, and just use\nthe clustered instances to generate pseudo labels for supervised\nlearning. However, the un-clustered outliers always contains\nmany hard training examples, which might actually be very\ndifﬁcult but valuable for the person Re-Id task. Just simply\nabandoning such training examples might critically hurt the\nrecognition performances.\nTo address the above mentioned problems, we propose\nthe hybrid dynamic contrastive and probability distillation\nframework for the purely USL and UDA person Re-Id. For\nthe instances in each cluster, we dynamically ﬁnd its corre-\nsponding hardest positive and negative pairs from the global\nmemory-bank level and the local mini-batch level. Mining\nhardest examples for each instance in the current training\nbatch from the global memory bank, can help us use the\nmost informative and valuable examples to optimize the deep\nmodel. However, such hardest examples may contain some\nincorrect training pairs, because the clustering results is usually\nnot accurate in some cases. In order to keep moderate model\nupdating, we also consider the local batch-level contrastive\nlearning. Since the instances in each mini-batch are randomly\nsampled from the whole training dataset, and the number of\nclusters is relatively very small, thus it could have relatively\nlow probability to select the incorrect negative/positive sample\npairs for the contrastive learning. By combining this local-\nto-global contrastive learning with dynamic hardest sample\nmining, the model optimization process could be very stable\nwhile effective and robust.\nSpecially, we also propose the instance-level self-contrastive\nand the probability distillation method, to make full use of the\nself-supervised signals of all the clustered and un-clustered\ninstances in the non-parametric manner. We consider the self-\nsupervisor signals from the following two perspectives: 1)\nWe treat the un-clustered outlier instances as independent\nclasses [4], and then maximize the distance between the simi-\nlarity of the instance with its corresponding strong augmented\ninstance, and the similarity of the instance with its nearest\nnegative examples in each clusters; 2) The proposed the prob-\nability distillation framework, relies on the assumption that\nthe model should output very similar probability predictions\nwhen fed perturbed augmentation of the same image. The\nfactor that contribute most to the success of the proposed\nalgorithm is that we have cast the unsupervised person Re-\nId task as the gradual semi-supervised learning. Given the\npreviously clustered instances stored in the memory bank, we\ncreatively obtain the probability distribution of each instance\non the clustered centroids, in a non-parametric manner. More\nspecially, on top of the ”Mean-Teacher”[10] framework, we\nuse the weak and stochastic data augmentation of the image as\nthe input of the teacher channel, and the strong augmentation\nof the same image as the input of the student channel. As the\nparameters of the teacher model is updated by the Exponential\nMoving Average(EMA) of the student model, this will provide\na more stable target and was empirically found to be very\neffective. Besides, after obtaining the probability distribution\nof each instance from the teacher model, we further trans-\nform the probability into the near ”one-hot” output by using\nthe sharpen technics [11]. Finally, the proposed probability\nregression technic is used between the probability output of\nthe student model and the sharpened probability of the teacher\nmodel. Thus, the proposed method can effectively utilize all\nthe self-supervised signals in the training dataset.\nOur contributions are summarized as three-fold:\n• Besides utilizing the clustering-based pseudo labels for\nUSL person Re-Id, the proposed method can make full\nuse of the self-supervised signals of all the clustered\nand un-clustered instances, from both the instances’ self-\ncontrastive level and the probability distillation perspec-\ntive in the memory-based non-parametric manner.\n• The proposed hybrid local-to-global contrastive learning\nwith dynamic sample mining, can take full advantages of\nthe informative and valuable training examples for person\nRe-Id task, which also makes the model optimization\nprocess very stable while effective and robust.\n• The proposed method signiﬁcantly outperforms most\nof state-of-the-art algorithms on multiple person Re-Id\ndatasets, under both the purely USL and UDA experiment\nsettings. Specially, our method outperforms the state-of-\nthe-art method [4] by 8.6%, 3.7%, 5.5%, 11.0% in terms\nof mAP on Market1501,Duke, MSMT17 and PersonX\ndatasets.\nII. RELATED WORKS\nIn this section, we review the most relevant works with ours\nin the following perspectives: 1)Deep unsupervised person\nRe-Id, which includes both the purely unsupervised person\nRe-Id and the unsupervised domain adaptation person Re-Id;\n2)The general unsupervised or self-supervised representation\nlearning; 3) Memory-based deep metric learning.\nDeep unsupervised person Re-Id methods can be sum-\nmarized into the purely USL person Re-Id and the UDA Re-\nId. Generally, the recent effective purely USL person Re-Id\nare clustering-based methods, which generate hard/soft pseudo\nlabels, and then ﬁnetune/train the deep models based on the\npseudo labels [1]. The pseudo labels can be obtained by\nclustering the sample features or measuring the similarities\namong the instances’ features. The representatives of such\n3\npseudo-label-based methods include [12], [2], [4], which have\ngot state-of-the-art performances at present. However, such\npseudo-label-based method highly depends on the precision\nof the estimated pseudo labels, since the noisy labels could\ndegrade the model performances. To improve the accuracy of\nthe estimated pseudo labels and mitigate the effects caused by\nthe incorrect labels, many improved pseudo-label estimation\nmethods were proposed, such as SSG[2] adopted human local\nfeatures to assign multi-scale pseudo labels, PAST [5] try\nto utilize multiple regularization to overcome this problem,\nand a lot of methods proposed some reliability evaluation\ncriteria to further modify the generated pseudo labels [3].\nBesides estimating the hard pseudo labels, some researchers\nproposed the soft-label and multi-label based USL methods\nfor person Re-Id. For instance, Yu etal [13] proposed the\nsoft-label based method by measuring the similarities between\nthe current person image with the reference clustered images,\nand Wang etal [14] transferred the USL person Re-Id into\nthe multi-label classiﬁcation problem, then it gradually found\nthe true labels with the help of some label estimation strategy\nand consistency regularization, to improve the precision of the\nestimated pseudo labels. Recently, some methods introduce\nmutual learning among two/three collaborative networks to\nmutually exploit the reﬁned soft pseudo labels of the peer\nnetworks as supervision [3]. The above mentioned two types\nof pseudo-label-based methods are widely used in both of the\npurely USL and UDA person Re-Id tasks. While for the UDA\nperson Re-Id, some domain translation-based methods are spe-\ncially proposed, because the source domain labeled data can\nbe used in this task. The representative work include the style-\nGAN [15] based translation methods from the source domain\nto the target domain images, which transform the images from\nthe source domain to match the image styles in the target\ndomain while keep the person identities appeared in the source\ndomain. These methods transfer the purely USL task to the\nsemi-supervised task, then the previously mentioned purely\nUSL methods can be fully used. Besides, some other methods\nexploits the valuable information across the source and target\ndomains, then explore some underlying relationships among\nthem and ﬁnally construct the joint learning framework by\nusing the training data in both the source and target domain.\nThe proposed method in this paper falls into the category of\npurely USL, but we have also extended the method to the UDA\ntask by fully exploits the useful training examples in the source\ndomain without consuming too much training resources. We\nhave considered the local and global label estimation quality\nto make the training procedure stable and efﬁcient.\nUnsupervised or Self-supervised Representation Learn-\ning aims to learn the feature representations from the to-\ntally unlabeled data. Besides the above mentioned clustering\npseudo-label-based methods, the unsupervised representation\nlearning have another two categories: the generative models\nand the self-supervised learning. In this paper, we just talk\nabout the relevant self-supervised learning methods. Early self-\nsupervised learning methods in computer vision were based on\nthe proxy tasks, such as the solving jigsaw puzzels [16], col-\norization and rotation prediction methods [17], [18]. Recently,\nsome contrastive learning based self training methods were\nproposed and achieved promising results, the representative\nmethods includes MoCo [19], SimCLR [20] and BYOL [21].\nThe idea behind such self-supervised learning methods is that\nthe same image in different views or augmented by different\nmethods should have consistent outputs when processed by the\nsame deep model. There also exist many other works aiming\nto improve previous self-supervised learning approaches from\ndifferent perspectives [19]. The most relevant work to ours in\nthe self-supervised learning research area is the MoCo [19],\nBYOL [21] and MeanTeacher [22], where the Moco method\nbuilds a dynamic dictionary based contrastive learning frame-\nwork with a moving averaged encoder, and it narrows the gap\nbetween the supervised and unsupervised learning in some\ndomains. The BYOL method further improves this method\nand achieved better results than previous work\n[23], [21]\nby optimizing a feature regression loss. Both of these two\nmethods borrow the ideas from the mean-teacher approach\nincluding the student-teacher framework and the EMA pa-\nrameter updating strategy. Our proposed method falls into\nthis category, but we are different with them. The proposed\nmethod ﬁst transform the unsupervised person Re-Id into the\nsemi-supervised problem, then we creatively transform the\ninstance feature into the class probability, and ﬁnally the\nprobability regression objective is used to further improve the\nperformances, instead of the instance feature itself. To some\nextent, such strategy can mimic the traditional combination of\nidentity loss and the contrastive loss, which have got superior\nperformances on the supervised person Re-Id task.\nThe memory dictionary based deep metric learning\nmethods present promising results on the unsupervised visual\nrepresentation tasks. Besides that, state-of-the-art unsupervised\nperson Re-Id methods also build memory dictionary for the\ncontrastive learning, and many strategies have been proposed\nto consistently update the memory dictionary which makes\nthe deep metric learning very effective. Especially for the\nUSL/UDA person Re-Id, Ge etal [4] proposed the self-paced\ncontrastive learning for UDA person Re-Id tasks. Zheng\netal [24] also proposed to exploit the sample uncertainty for\nUDA person Re-Id task while afﬁliating with the memory\nbased contrastive learning. These methods can leverage the\nmemory bank to measure the similarity between a sample and\nthe instances stored in the memory, which helps to mine hard\nnegative examples across batches and increase the contrastive\npower with more negatives, and ﬁnally better train the deep\nmodel. We introduce the local-to-global memory bank con-\ntrastive learning to jointly utilize the estimated pseudo labels\nand the self-supervised consistency regularization. We further\nvalidate the synergy between the pseudo label estimation and\nthe self-supervised probability regression module, where the\nprobability regression module can be interpreted as a form of\nknowledge distillation with pseudo labels or the approximately\nprojected labels.\nIII. METHOD\nTo tackle the challenges on the USL person Re-Id task, we\npropose the hybrid dynamic contrast and probability distilla-\ntion framework as shown in Figure 1. It mainly consists of\n4\nFig. 1. This is the proposed framework for unsupervised person Re-Id. It mainly consists of two modules: the hybrid dynamic contrastive learning and the\nprobability distillation component. For the memory-based hybrid dynamic contrastive learning, it ﬁrst uses the clustering method ”DBSCAN” to group the\nunlabeled instances into the clustered instances and the outlier instances, then we use the memory-based local-to-global contrastive learning objectives with\ndynamic hardest example mining strategy to optimize the deep model. The instance features stored in the memory bank is updated dynamically in the training\nprocess. For the probability distillation module, the training images with different data augmentation strategies are processed through the student and teacher\nnetwork, then we project the image features from the student and teacher network onto the pseudo class centers to get their class responses. Followed by the\nsharpen technics, we ﬁnally minimize the probability regression objective to make full use of the self-supervised signals of the training data.\nthe following two modules: 1) The self-supervised framework\nwith probability distillation;2) The hybrid dynamic local-\nto-global contrastive learning. The above two modules are\nboth optimized in the global memory bank. In Figure 1, it\ndemonstrates the pipeline of the proposed method. Specially,\nwe also use the Resnet50 [25] as the backbone network to\nextract the semantic features of the input image. Similar to [4],\nthe DBSCAN [7] clustering method is used to group the\ninstance features into several clusters and the remaining un-\nclustered individual instances, then we assign the cluster ID\nto each instance as its pseudo label. Note that there are two\nimportant hyper-parameters in the DBSCAN [7] algorithm,\none is the maximum distance α between the examples to be\nconsidered as the neighborhood of each other, and another\nis the minimum number of samples in a neighborhood for\nan instance to be considered as the center instance. In this\npaper, we experimentally set these two hyper-parameters as\n0.5 and 5 respectively according to SPCL method [4]. For the\nun-clustered instances, we just simply consider them as the\nindividual classes. When the pseudo labels are generated, the\ndynamic local-to-global contrastive learning is performed in\nthe training stage. During optimizing the contrastive learning\nobjectives, the dynamic hardest example mining strategy is\nperformed in the training batch level and the memory based\ncluster level. The instance features stored in the memory are\ndynamically updated using the mined hardest training example\nduring the training process. The local-to-global contrastive\nlearning process can help us not only utilize the most valu-\nable and informative training examples in the cluster level\namong the whole training dataset, but also make the model\noptimization process avoid training error ampliﬁcation caused\nby the noisy clusters, thus keep the training process very\nstable while effective and robust. Meanwhile, to make full\nuse of all the self-supervised signals of all the clustered and\nun-clustered instances, we propose the instance level self-\ncontrastive learning on the un-clustered individual training\nsamples and the probability distillation objectives on the whole\ntraining data, in the non-parametric manner. As shown in\nthe left side of Figure 1, each training image augmented\nwith different strategies is processed through the student and\nteacher networks, then we project the image features from\nthe student and teacher network onto the cluster centroids\nto get their class predictions, where the cluster centroids is\ndynamically computed by the instances’ features stored in the\nmemory bank. Followed by the probability sharpen technics,\nwe ﬁnally minimize the probability regression objectives.\nWe formulate the above cluster contrast and the probability\ndistillation modules into the uniﬁed learning framework.\nNoted that, the training scheme alternates between the\nfollowing two steps: 1) Grouping the un-labeled training\nexamples into clusters and un-clustered instances by using the\nDBSCAN method [7] with the instances stored in the memory\nbank; 2) optimizing the feature extractor with the proposed\nlocal-to-global contrastive learning and the self-supervised\nprobability distillation objectives, and dynamically update the\nhybrid memory bank with instance features extracted by the\nteacher network at the sametime.\nA. Hybrid Local-to-Global Cluster Contrast Learning\nAs we all know, the most valuable and informative training\nexamples for person Re-Id task, are the examples which are\n5\ncaptured from different cameras or views of the same identity.\nBut for the USL person Re-Id task, the primary grouped\nclusters usually contain examples mainly from one camera\nview, because the intra-class distance from different camera\nviews of the same identity is usually larger than that of the\ninter-class distance from the same camera view of different\nidentities, due to the illumination and resolution changes.\nThis is the main difference between the USL person Re-Id\nand the traditional unsupervised classiﬁcation task, where the\ntraditional unsupervised classiﬁcation tasks usually process\nthe training data which are uniformly distributed. Here, we\nintroduce the memory-based local-to-global cluster contrast\nmethod with hardest data mining strategy to overcome this\nchallenge in some respects. To make the description of the\nproposed method readable, we keep some similar deﬁnitions\nas described in [4], and demonstrate the algorithm from the\nfollowing two aspects1) the local-to-global cluster contrastive\nlearning; 2) The memory bank initialization and updating\nstrategy.\nGiven the training datasets X without any ground-truth\nlabel, we initially use the clustering method DBSCAN [7]\nto group the training data into clusters Xc and the un-\nclustered individual instances Xo. Then we assign the cluster\nID to each instance as the pseudo label, and here we just\nconsider the un-clustered instances as individual clusters. In\nthe proposed probability distillation framework, the parameters\nof the student network is optimized using these training\nexamples. Given the training sample xi, we deﬁne fθ(xi) as\nits feature representation vector, abbreviated as fi = fθ(xi),\nxi ∈Xo ∪Xc. The memory based global contrastive loss\nLGMemory can be deﬁned as the following Eq 1,\n−log\nexp < qi, f +)/τ >\nNc\nP\nk=1\nexp(< qi, fck∗> /τ) +\nNo\nP\nk=1\nexp(< qi, fk > /τ)\n,\n(1)\nwhere qi indicates the i −th query feature in current mini-\nbatch, f + indicates the positive class prototype corresponding\nto the i −th query feature qi, τ is the temperature hyper-\nparameter which is empirically set to 0.05 in our experiments,\n< ., . > denotes the inner product between two feature vectors\nto measure the similarity, Nc is the number of grouped clusters\nin current memory bank, No is the number of un-clustered\nindividual instances in current memory bank. If the current\nquery feature qi falls into the grouped clusters, f + is the\nhardest positive example for qi in its corresponding cluster,\nwhere the ”hardest positive” means the selected example is the\nfarthest to qi in the same cluster. Thus, fck∗, c ∈{1, ..., Nc}\ncontain one hardest positive example for the qi’s correspond-\ning cluster, and the rest Nc −1 hardest negative examples in\nthe corresponding negative clusters in the memory bank, where\nthe ”hardest negative” means the nearest negative example to\nthe query example qi in each cluster, and fk, k ∈{1, ..., No}\nis the un-clustered instance features in the memory bank. If\nqi falls into the un-clustered individual groups, we would set\nf + = fk as the outlier instance feature corresponding to qi in\nthe memory bank, and fck∗is the hardest negative examples\nin all the Nc clusters in the memory bank corresponding to\nqi. Thus, in this situation, the proposed method can make full\nuse of the self-supervised signals from the instance-level self-\ncontrastive learning. Please note that q represents the features\nin current mini-batch, and f represents the features stored in\nthe memory bank in Eq 1 and the following descriptions.\nAbove we have described the proposed memory-based\nglobal cluster contrastive loss. In order to keep the learning\nprocedure much more stable and moderate, we further pro-\npose the local batch contrastive loss LLBatch to facilitate the\nmemory-based global contrast loss as follows,\n−log\nexp< qi, q+\ni > /τ\nexp\n\u0000< qi, q+\ni > /τ\n\u0001\n+\nP\nqj∈B,yi̸=yj\nexp(< qi, qj > /τ),\n(2)\nwhere yi and yj denote the pseudo labels for the examples\nqi and qj in current mini-batch, B is the batch size. we\ncan clearly see that the local batch contrastive loss LLBatch\nis the traditional contrastive loss, where the hardest positive\nand negative training pairs are selected in current min-batch.\nThe memory-based global hardest contrast loss LGMemory\nexplores to utilize the most informative and valuable examples\nfrom the global memory bank to optimize the deep model, but\nsuch hardest examples usually contain some incorrect training\npairs since the unsupervised clustering results is not accurate in\nsome cases. In order to keep moderate model updating, we also\nconsider the local batch-level contrastive loss LLBatch, which\ncould have relatively low probability to select the incorrect\nnegative example pairs, since the number of clusters in each\nmini-batch is relatively small. Besides, leveraging the training\npairs in the current mini-batch can utilize the latest instance\nfeatures to update the deep model. Finally, the hybrid local-to-\nglobal contrastive loss with hardest data mining strategy LL2G\nconstitutes as follows,\nLL2G = LGMemory + LLBatch.\n(3)\nB. The memory bank and Its updating strategy\nWe store all the instances’ feature {f1, f2, ..., fN} in the\nmemory bank. Here N stands for the number of the whole\ntraining examples in the dataset. At the beginning, we use the\ndeep CNN model pre-trained on the ImageNet to extract the\ninstance features, then we use the DBSCAN [7] method to\ncluster the instances into several clusters as initialization. The\nclustering results would impact the learned representations.\nIf the clustering is perfect, merging the instances to its true\nclusters would no doubt improve the performance, which is\nthe upper bound or ideal conditions. However, in practice,\nthe unsupervised learning usually would merge some instances\ninto the wrong clusters inevitably, which could do harm to the\nﬁnal performance. For clustering-based unsupervised person\nRe-Id, the accuracy of clustering results would gradually im-\nproves as the model updates, thus better feature representations\ncan be learned ﬁnally. In the proposed algorithm, we ﬁrst\ngroup all training instances into the clusteres and the un-\nclustered individual instances, to obtain the pseudo labels of\nthe instances with the cluster ID. Following, we optimize the\n6\nproposed learning objectives with these pseudo labels for T\nepoch on the training dataset, here T = 2 in our experiments.\nAs the model parameters update, the instances’ features stored\nin the memory bank would also be updated in the training\nprocess. After every T epoch, we use the clustering method\n”DBSCAN” to generate the pseudo labels for all the training\ninstances in the memory bank.\nPlease note that, the instances’ features stored in the mem-\nory bank are updated at each training iteration dynamically,\ninstead of updating them totally using current model param-\neters every T epoch. Experiments shows that updating the\ninstances’ feature vectors dynamically is better than that of\nupdating them as a whole every several iterations. In order to\nmake the contrastive loss work well in the training process, we\nsample P person identities and a ﬁxed number of H instances\nfor each person identity using the obtained pseudo labels in\neach training batch. As a consequence, there are P × H\nquery instances in each mini batch [26]. The same as previous\ninstance-level feature memory methods [26], we also update\nall the P × H query instances’ features in the memory. The\ndifference is that we use the instance features extracted from\nthe teacher model in the framework to update the instance\nfeatures stored in the memory bank, as the teacher model\ngradually grows better than the student model in the training\nprocess. In each iteration, the P ×H extracted feature vectors\nin current mini-batch are utilized to update the corresponding\nfeature vectors stored in the memory bank as follows,\nfi ←mfi + (1 −m)qi,\n(4)\nwhere m ∈[0, 1] is the momentum coefﬁcient for updating\nthe instance features in the memory bank and is set to 0.3 in\nour experiments. qi is the instance feature vector in current\nmini-batch, and fi is the feature vector stored in the memory\nbank.\nC. Self-Supervised Probability Distillation\nApart from learning discriminative image features based on\nthe pseudo labels generated by the clustering methods, our\nmethod also considers the self-supervised signals through the\nproposed pseudo probability distillation framework, which can\nalso be regarded as a sort of knowledge distillation approach.\nThe proposed probability distillation framework is a learn-\ning paradigm which trains a student neural network fθs(·) and\na teacher network fθt(·). The teacher and student networks\nshare the same network architecture, but they are parameter-\nized by θs and θt respectively. Give each input image x, our\nnetwork takes two randomly augmented views x′ and x′′ as\nthe input for the student and teacher network, respectively.\nThese two augmented views are processed by the encoder\nnetwork fθ(·) and the class probability projection module,\nwhere the encoder network is formed by a backbone network\nResnet50 [25]. For the pseudo label based unsupervised learn-\ning, we ﬁrst group all the training instances into the clusters\nand un-clustered outliers. Then, we can obtain the cluster\ncentroid based on the grouped instances’ features. Thus we can\ncompute the probability distribution of each instance belonging\nto the corresponding cluster centers. Speciﬁcally, we compute\nFig. 2.\nThis is the proposed probability distillation framework. Two aug-\nmented views of one input image x are processed by the same network\narchitecture named ”Student-Network” and ”Teacher-Network” respectively,\nboth of which contains the backbone network (Resnet50) and the class\nprobability estimation module. Then the sharpen technic and stop-gradient\noperation are applied on the teacher network, where the parameter in the\nteacher network is updated by EMA method. The model use the L2 regression\nloss to maximize the similarity of the estimated probability between the\nstudent and teacher networks.\nthe cluster center with the mean feature vectors of each cluster\nset from {fi} in the memory bank, as illustrated in Eq 5,\nck =\n1\n|Mk|\nX\nfi∈Mk\nfi,\n(5)\nwhere Mk demotes the k-th cluster set that contain all the\nfeature vectors within the k-th cluster in current memory bank\nM, and | · | denotes the number of instances in the subset, fi\nis the feature vector stored in the memory bank. Please note\nthat only the grouped clusters are used to computer the cluster\ncenters.\nGiven each query image xi, both networks output their\ncorresponding feature representations qs\ni and qt\ni, then we\ncompute their probability distributions on the obtained cluster\ncenters. For the feature vector qs\ni, the corresponding probabil-\nity distribution Ps(xi) is illustrated in the following Eq 6,\nPs\nk(xi) =\nexp(< qs\ni, ck > /τs)\nPK\nk=1 exp(< qs\ni, ck > /τs)\n,\n(6)\nwhere k ∈1, ..., K, and K is the number of grouped clusters\nat present, please note that K is changing in the whole\ntraining procedure, because the unsupervised person ReId is\nan openset problem, we don’t know the true number of IDs\npreviously, and we cluster the whole instances every several\nepoches using the DBSCAN methods in the algorithm. Then\nfor the clustered instances, the obtained probability distribution\nPk(xi) could represent the probability that the instance xi\nbelongs to the k-th cluster. While for some instances in the\nrest un-clustered outlier subset, the probability distribution can\n7\nonly be considered as the feature projection on the obtained\ncluster centers, because some outliers maybe don’t belong to\nany of the previously obtained clusters. This is also one of\nthe major differences between the unsupervised classiﬁcation\nand the unsupervised open-set problems, such as person Re-\nId. In Eq 6, τs > 0 is the temperature parameter that controls\nthe sharpness of the output distribution. Similar formula holds\nfor the teacher network fθt(·), and we obtain Pt(xi) for the\ninstance feature vector qt\ni with temperature parameter τt.\nThe proposed self-supervised probability distillation module\nworks as a regularisation term between these two networks’\noutput probability distributions. Given a ﬁxed teacher network\nfθt(·), we learn to match these probability distributions by\nminimizing the Mean Square Loss LS in the self-supervised\nmanner, as illustrated in Eq. 7,\nLS = ||Ps(xi) −Pt(xi)||2\n2.\n(7)\nNote that in Eq 7, the probability distribution Pt(xi) from\nthe teacher network is ﬁxed. Minimizing the loss function LS\ncould directly optimize the parameters of the student network\nfθs(·), while the parameters in the teacher network fθt(·)\nis updated by Exponential Moving Average(EMA) methods\nbased on current parameters in the student network fθs(·).\nUnlike the traditional knowledge distillation, we don’t have\na predeﬁned high quality model as the ﬁxed teacher model,\nwe build it from the past iteration of the student network. The\nparameter update rule ”EMA” is θt ←λθt + (1 −λ)θs, and λ\nis a smoothing coefﬁcient hyper-parameter. In our algorithm,\nwe not only update the parameter θt in the teacher network\nfθt(·) with the parameter θs in the student network fθs(·), but\nalso the parameters µt and σt in the BatchNorm layer of the\nteacher network are updated using the EMA method with the\nparameters µs and σs in the BatchNorm layer of the student\nnetwork [22], µt ←λµt+(1−λ)µs and σt ←λσt+(1−λ)σs.\nD. The Final Objective Function\nConsidering the above descriptions, the ﬁnal objective func-\ntion in our algorithm consists of the pseudo label based local-\nto-global contrastive loss and the self-supervised probability\nregression, as denoted in Eq. 8,\nLtotal = LL2G + γLS,\n(8)\nwhere γ is the hyper-parameter to balance these two objectives.\nBy optimizing Eq. 8, the proposed algorithm can not only well\nutilize the estimated pseudo labels, but also can make full\nuse of the self-supervised signal from both the instances self-\ncontrastive level and the probability distillation perspectives\nin the memory-based non-parametric manner, to learn the\ndiscriminative image features for the unsupervised person Re-\nId task.\nIV. EXPERIMENTS\nA. Datasets and Evaluation Protocal\nWe evaluate the proposed method on four large-scale per-\nson re-Id benchmark datasets, namely: Martket1501 [27],\nDukeMTMC [28], MSMT17-v2 [15], and PersonX [29].\nAmong the four benchmark datasets, PersonX [29] is one\nsynthetic dataset, it contains the manually designed obstacles\nsuch as the random erasing, different resolution and lighting\nconditions. The rest three datasets are widely used real-world\nperson re-Id datasets. We also illustrate the statistics of the\nfour datasets used for training and evaluation in Table I.\nFollowing existing person Re-Id methods [27], we adopt the\nmean Average Precision (mAP) and the Cumulative Matching\nCharacteristic (CMC) as the evaluation metrics, where we\nreport Top-1, Top5 and Top-10 of the CMC metric in this\npaper. We don’t adopt any post-processing technics, such as\nre-ranking [30] or multi-query fusion methods [27] for the\nexperiment evaluation. In the experiment settings, besides the\ntraditional purely USL person Re-Id which doesn’t use any\nlabeled data in the whole training procedure, we also adopt\nthe UDA in the experiment to illustrate the effectiveness of\nthe proposed method. Speciﬁcally, we use these two real-world\ndatasets Market1501 and DukeMTMC to work as the source\nand target dataset alternatively, and ﬁnally report the matching\nperformance under this UDA experiment settings.\nB. Implementation Details\nThe backbone network we used to extract the image features\nis the Resnet50 [25], we remove the sub-modules after the\n“conv5 x” [25] and add the global average pooling (GAP)\nfollowed by the batch normalization and L2 normalization\nlayers, ﬁnally it will produce 2048-dimensional features for\neach image. The backbone network is initialized with the\nparameters pre-trained on ImageNet [31]. At the beginning,\nwe just use the model pre-trained on ImageNet to extract the\nfeatures of all the training examples for initialization, then the\nDBSCAN [7] method is used for clustering to generate the\npseudo labels on all the training datasets.\nIn the training stage, the input images are resized to\n256 × 128 on all the datasets, the batchsize is set to 256.\nFor each mini-batch, we randomly select 16 pseudo identities\nand each identity has 16 different images. For the two-\nstream probability distillation networks, we use different data\naugmentation strategies for each input branch, such as random\ncropping, horizontal ﬂipping and random easing. The param-\neters τ in Eq. 2 and Eq. 1 are all set to 0.6, and the parameter\nτs in Eq. 6 is set to 1.0 for the student model and 0.5 for\nthe teacher model. The parameter of the maximum neighbour\ndistance for DBSCAN [7] is set to 0.5. We adopt Adam as the\noptimizer with learning rate setting as 3.5e−4, and step-size is\n30 which means that the learning rate degrades 1/10 every 30\nepoches, and the weight decay is set to 5e −4, the parameter\nof momentum is 0.2. In the whole training stage, it runs 70\nepoches and we do clustering with DBSCAN to generate new\npseudo labels every two epoches. We did the experiments on\ntwo Tesla V100 GPU platform with 32G memory.\nC. Comparison with State-of-the-Arts on Purely USL Setting\nWe compared our method with State-of-the-art methods\nunder the purely USL setting on four commonly used datasets,\nMarket1501, Duke, MSMT17 and PersonX, respectively. As\nillustrated in Table II, Table III, Table IV and Table XI, it\n8\nTABLE I\nTHE STATISTICS OF THE FOUR DATASETS USED FOR TRAINING AND EVALUATIONS IN OUR PAPER.\nDataset\n♯train IDs\n♯train images\n♯test IDs\n♯query images\n♯cameras\n♯total images\nMarket-1501\n751\n12936\n750\n3368\n6\n32217\nMSMT-v2\n1041\n32621\n3060\n11659\n15\n126441\nDukeMTMC\n702\n16522\n702\n2228\n8\n36442\nPersonX\n410\n9840\n856\n5136\n6\n45792\nTABLE II\nCOMPARISON WITH STATE-OF-THE-ART METHODS ON MARKET1501\nDATASET UNDER PURELY USL EXPERIMENT SETTING.\nMethods\nReference\nmAp\nTop-1\nTop-5\nTop-10\nOIM [32]\nCVPR2017\n14.0\n38.0\n58.0\n66.3\nLOMO [33]\nCVPR2015\n8.0\n27.2\n41.6\n49.1\nBOW [27]\nICCV2015\n14.8\n35.8\n52.4\n60.3\nBUC [34]\nAAAI2019\n38.3\n66.2\n79.6\n84.5\nUGA [35]\nCVPR2019\n70.3\n87.2\n–\n–\nSoftSim [36]\nCVPR2020\n37.8\n71.7\n83.8\n87.4\nTSSL [37]\nAAAI2020\n43.3\n71.2\n–\n–\nMMCL [14]\nCVPR2020\n45.5\n80.3\n89.4\n92.3\nJVTC [38]\nECCV2020\n41.8\n72.9\n84.2\n88.7\nJVTC+[38]\nECCV2020\n47.5\n79.5\n89.2\n91.9\nHCT [39]\nCVPR2020\n56.4\n80.0\n91.6\n95.2\nCycAs [40]\nECCV2020\n64.8\n84.8\n–\n–\nMoCo [19]\nCVPR2020\n6.1\n12.8\n27.1\n35.7\nSPCL [4]\nNIPS2020\n73.1\n88.1\n95.1\n97.0\nJNTL [41]\nCVPR2021\n61.7\n83.9\n92.3\n–\nJGCL [42]\nCVPR2021\n66.8\n87.3\n93.5\n95.5\nIICS [41]\nCVPR2021\n72.9\n89.5\n95.2\n97.0\nOurs\n–\n81.7\n92.4\n97.4\n98.1\nClusterContrast [26]\nArXiv2021\n82.6\n93.0\n97.0\n98.1\nClusterContrast+Ours\n–\n84.5\n93.5\n97.6\n98.6\nshows that the proposed method outperforms all the latest\nunsupervised person Re-Id methods. Compared with the base-\nline method SPCL [4], the mAP of our proposed method\nsurpasses the SPCL [4] method by 8.6%, 5.2%, 5.5% and\n5.4% on Martket1501 [27], DukeMTMC [28], MSMT17-\nv2 [15], and PersonX [29] datasets respectively. Since the pro-\nposed method improves the current unsupervised person Re-Id\nperformance from different perspectives, we also formulate the\nlatest un-published state-of-the-art method “ClusterContrast”\ninto the probability distillation framework which named “Clus-\nterContrast+Ours” in Table II,III,IV,XI, and further improves\nthe mAP of the ”ClusterContrast” method [26] by 1.9%,\n0.7%, 2.0% and 4.7 on Martket1501 [27], DukeMTMC [28],\nMSMT17-v2 [15], and PersonX [29] datasets respectively.\nFinally, our proposed method obtains a new state-of-the-art\nperformances 84.5%, 73.5%, 24.6% and 89.5% mAP on all\nthe four datasets, which surpass all published results for un-\nsupervised person Re-Id tasks. Besides, the proposed method\ndoes not apply any extra parameters comparing with other\nstate-of-the-art methods SPCL [4] and ”ClusterContrast” [26].\nD. Comparison with State-of-the-Arts on UDA Setting\nWe also compare the proposed method with the state-of-\nthe-art UDA person Re-Id methods, which utilize the labeled\nsource domain datasets to assist the training on the unlabeled\ntarget datasets. Inspired by the state-of-the-art UDA person\nRe-Id method SPCL [4], we further extend our method on the\nUDA setting. As presented in SPCL [4], we also consider the\nsource domain class centroids from both the hybrid memory\nTABLE III\nCOMPARISON WITH STATE-OF-THE-ART METHODS ON DUKEMTMC\nDATASET UNDER PURELY USL EXPERIMENT SETTING.\nMethods\nReference\nmAp\nTop-1\nTop-5\nTop-10\nLOMO [33]\nCVPR2015\n4.8\n12.3\n21.3\n26.6\nBOW [27]\nICCV2015\n8.3\n17.1\n28.8\n34.9\nBUC [34]\nAAAI2019\n27.5\n47.4\n62.6\n68.4\nUGA [35]\nCVPR2019\n53.3\n75.0\n–\n–\nSoftSim [36]\nCVPR2020\n28.6\n52.5\n63.5\n68.9\nTSSL [37]\nAAAI2020\n38.5\n62.2\n–\n–\nMMCL [14]\nCVPR2020\n40.2\n65.2\n75.9\n80.0\nJVTC [38]\nECCV2020\n42.2\n67.6\n78.0\n81.6\nJVTC+[38]\nECCV2020\n50.7\n74.6\n82.9\n85.3\nHCT [39]\nCVPR2020\n50.7\n69.6\n83.4\n87.4\nCycAs [40]\nECCV2020\n60.1\n77.9\n–\n–\nSPCL [4]\nNIPS2020\n65.3\n81.2\n90.3\n92.2\nJNTL [41]\nCVPR2021\n53.8\n73.8\n84.2\n–\nJGCL [42]\nCVPR2021\n62.8\n82.9\n87.1\n88.5\nIICS [41]\nCVPR2021\n59.1\n76.9\n86.1\n89.8\nOurs\n–\n69.0\n82.9\n90.9\n93.0\nClusterContrast [26]\nArXiv2021\n72.8\n85.7\n92.0\n93.5\nClusterContrast+Ours\n–\n73.5\n85.4\n92.2\n94.5\nTABLE IV\nCOMPARISON WITH STATE-OF-THE-ART METHODS ON MSMT17 DATASET\nUNDER PURELY USL EXPERIMENT SETTING.(*) INDICATES THAT THE\nIMPLEMENTATION IS BASED ON THE AUTHORS’ CODE.\nMethods\nReference\nmAp\nTop-1\nTop-5\nTop-10\nTAUDL[43]\nECCV2018\n12.5\n28.4\n–\n–\nUGA [35]\nCVPR2019\n21.7\n49.5\n–\n–\nMoCo [19]\nCVPR2020\n1.6\n4.3\n–\n–\nMMCL [14]\nCVPR2020\n11.2\n35.4\n44.8\n49.8\nJVTC [38]\nECCV2020\n15.1\n39.0\n50.9\n56.8\nJVTC+[38]\nECCV2020\n17.3\n43.1\n53.8\n59.4\nSPCL [4]\nNIPS2020\n19.1\n42.3\n55.6\n61.2\nJNTL [41]\nCVPR2021\n15.5\n35.2\n48.3\n–\nJGCL [42]\nCVPR2021\n21.3\n45.7\n58.6\n64.5\nIICS [41]\nCVPR2021\n18.6\n45.7\n57.7\n62.8\nOurs\n–\n24.6\n50.2\n61.4\n65.7\nClusterContrast* [26]\nArXiv2021\n18.7\n40.5\n51.7\n56.9\nClusterContrast+Ours\n–\n20.7\n43.8\n55.1\n60.1\nbank and the the training objectives. Thus the main differences\nbetween our method and the SPCL [4] method under the UDA\nsetting are described as follows: 1)In the training objective,\nwe consider both the local batch contrastive the memory-\nbased global contrastive learning. Besides, we always mine\nthe hardest examples in each clustered group to represent the\ncluster for optimizing the objectives, without using the self-\npaced training strategy. While for the SPCL [4] method, it\noptimizes the objectives using the memory-based contrastive\nlearning with the class centroid representing the cluster in a\nself-paced manner; 2) The proposed method formulate the\nfeature learning in the probability distillation framework to\nutilize both the pseudo class labels and the self-supervised\nsignals. The main similarity is that: we also use the labeled\nsource domain dataset in the same manner as illustrated\n9\nTABLE V\nCOMPARISON WITH STATE-OF-THE-ART METHODS ON PERSONX DATASET\nUNDER PURELY USL EXPERIMENT SETTING.\nMethods\nReference\nmAp\nTop-1\nTop-5\nTop-10\nMMT [3]\nNIPS2019\n78.9\n90.6\n96.8\n98.2\nSPCL [4]\nNIPS2020\n73.1\n88.1\n95.1\n97.0\nOurs\n–\n84.1\n94.4\n98.7\n99.5\nClusterContrast [26]\nArXiv2021\n84.8\n94.5\n98.4\n99.2\nClusterContrast+Ours\n–\n89.5\n95.6\n98.7\n99.4\nTABLE VI\nCOMPARISON WITH STATE-OF-THE-ARTS ON MARKET1501 DATASET\nUNDER THE UDA EXPERIMENT SETTING.\nMethods\nReference\nSource\nmAp\nTop-1\nTop-5\nTop-10\nECN [44]\nCVPR2019\nDuke\n43.0\n75.1\n87.6\n91.6\nPDA [45]\nICCV2019\nDuke\n47.6\n75.2\n86.3\n90.2\nCR-GAN [46]\nICCV2019\nDuke\n54.0\n77.7\n89.7\n92.7\nSSG [2]\nICCV2019\nDuke\n58.3\n80.0\n90.0\n92.4\nCSCL [35]\nICCV2019\nDuke\n35.6\n64.7\n80.2\n85.6\nMEB-Net*[47]\nECCV2020\nDuke\n71.9\n87.5\n95.2\n96.8\nACT [48]\nAAAI2020\nDuke\n60.6\n80.5\n–\n–\nMMCL [14]\nCVPR2020\nDuke\n60.4\n84.4\n92.8\n95.0\nDG-Net++ [49]\nECCV2020\nDuke\n61.7\n82.1\n90.2\n92.7\nJVTC [38]\nECCV2020\nDuke\n61.1\n83.8\n93.0\n95.2\nJVTC+[38]\nECCV2020\nDuke\n67.2\n86.8\n95.2\n97.1\nENC+[50]\nTPAMI2020\nDuke\n63.8\n84.1\n92.8\n95.4\nCAIL [51]\nECCV2020\nDuke\n71.5\n88.1\n94.4\n96.2\nMMT [3]\nICLR2020\nDuke\n71.2\n87.7\n94.9\n96.9\nNRMT [52]\nECCV2020\nDuke\n71.7\n87.8\n94.6\n96.5\nSPCL [4]\nNIPS2020\nDuke\n76.7\n90.3\n96.2\n97.7\nJNTL [41]\nCVPR2021\nDuke\n76.5\n90.1\n–\n–\nJGCL [42]\nCVPR2021\nDuke\n75.4\n90.5\n96.2\n97.1\nOurs\n–\nDuke\n83.9\n93.6\n97.5\n98.3\nin SPCL [4] and formulate them in the uniﬁed contrastive\nlearning, which can make full use of all the source and target\ndomain datasets, especially that the source domain dataset are\nwell labeled.\nAs illustrated in Table VII and Table VI, we compare the\nproposed method with the state-of-the-art methods on two\ndomain adaptation tasks, including Duke 7→Market1501\nand Market1501 7→Duke. It clearly shows that our proposed\nmethod outperforms all the other UDA methods, and we\nachieve 7.2% and 2.1% improvements in terms of mAP on the\ncommon Duke 7→Market1501 and Market1501 7→Duke\ntasks over state-of-the-art method SPCL [4], respectively. This\ngreatly shows the robustness of the proposed method both on\nthe purely unsupervised and UDA feature learning.\nE. Ablation Studies\nThe proposed USL person Re-Id method contains two\nmain novel ingredients: 1)The local-to-global memory-based\ncontrastive learning with dynamic hardest example mining;\n2)the proposed probability distillation framework to capture\nthe self-supervised information. To reveal how each ingredient\ncontributes to the performance improvements, we perform ab-\nlation study and implement different variants of the methods,\nthen report the intermediate results of each component on\nMarket1501 and Duke datasets.\nAs illustrated in Table VIII, the ﬁrst line means that we use\nthe estimated centroids in the contrastive learning framework\nas presented in SPCL [4], but we implement this without using\nthe self-paced learning strategy. We can clearly see that our\nmemory based global centroid contrastive learning can obtain\n76.3% mAP on Market1501 dataset, which performs better\nTABLE VII\nCOMPARISON WITH STATE-OF-THE-ARTS ON DUKE DATASET UNDER THE\nUDA EXPERIMENT SETTING..\nMethods\nReference\nSource\nmAp\nTop-1\nTop-5\nTop-10\nECN [44]\nCVPR2019\nMarket\n40.4\n63.3\n75.8\n80.4\nPDA [45]\nICCV2019\nMarket\n45.1\n63.2\n77.0\n82.5\nCR-GAN [46]\nICCV2019\nMarket\n48.6\n68.9\n80.2\n84.7\nSSG [2]\nICCV2019\nMarket\n53.4\n73.0\n80.6\n83.2\nCSCL [35]\nICCV2019\nMarket\n30.5\n51.5\n66.7\n71.7\nMEB-Net*[47]\nECCV2020\nMarket\n63.5\n77.2\n87.9\n91.3\nACT [48]\nAAAI2020\nMarket\n54.5\n72.4\n–\n–\nMMCL [14]\nCVPR2020\nMarket\n51.4\n72.4\n82.9\n85.0\nDG-Net++ [49]\nECCV2020\nMarket\n63.8\n78.9\n87.8\n90.4\nJVTC [38]\nECCV2020\nMarket\n56.2\n75.0\n85.1\n88.2\nJVTC+[38]\nECCV2020\nMarket\n66.5\n80.4\n89.9\n92.2\nENC+[50]\nTPAMI2020\nMarket\n54.4\n74.0\n83.7\n87.4\nCAIL [51]\nECCV2020\nMarket\n65.2\n79.5\n88.3\n91.4\nMMT [3]\nICLR2020\nMarket\n65.1\n78.0\n88.8\n92.5\nNRMT [52]\nECCV2020\nMarket\n62.2\n77.8\n86.9\n89.5\nSPCL [4]\nNIPS2020\nMarket\n68.8\n82.9\n90.1\n92.5\nJNTL [41]\nCVPR2021\nMarket\n65.0\n79.5\n–\n–\nJGCL [42]\nCVPR2021\nMarket\n67.6\n81.9\n88.9\n90.6\nOurs\n–\nMarket\n70.9\n83.5\n90.8\n93.3\nthan the SPCL [4] method (72.6% mAP). The second line is\nthe proposed hybrid local-to-global cluster contrastive learn-\ning, we can clearly see that adding the local-batch contrastive\nlearning could further improve the performance by 2.8% and\n2.3% mAP on these two datasets respectively. The third line\nmeans that we propose to use the dynamic hardest example\nmining strategy to select one example in each group to replace\nthe centroid in the contrastive learning objective as shown in\nEq. 5, we can clearly see that such strategy can further improve\nthe performance by 1.7% and 3.5% mAP on these two datasets\nrespectively. The third line is to illustrate the effectiveness of\nthe proposed probability distillation framework on top of our\nbaseline method (line 1), we can clearly see that the probability\ndistillation framework could well capture the self-supervised\nsignals, which can improve the performances by 1.8% and\n2.7% mAP on Market1501 and Duke datasets respectively.\nThe last line is the results of our ﬁnal USL algorithm. By\ncomparing the last line with the third line, we can also see\nthat the probability distillation framework can further improve\nthe local-to-global cluster contrastive learning with dynamic\nhardest mining strategy by 0.9% and 1.3% mAP respectively.\nBesides, we also illustrate the effectiveness of all the com-\nponents in our proposed algorithm under the UDA setting on\nMarket1501 dataset, as shown in Table IX. The ﬁrst line in\nTable IX shows the performance of the SPCL [4] algorithm,\nand the second line means that we use the estimated centroids\nin the contrastive learning framework as proposed in SPCL [4],\nbut we implement this without using the self-paced learning\nstrategy. It clearly shows that our proposed baseline method\nsurpasses the SPCL method by 3.3% mAP. The third line\nLL2G is our proposed local-to-global memory based contrastive\nlearning with the hybrid hardest example mining strategy,\nwhich improves the baseline method for 2.5% mAP. The last\ntwo line illustrate the effectiveness of the proposed probability\ndistillation framework LS on top of the baseline method\nand the LL2G, the probability distillation module can further\nimprove their corresponding baseline method by 1.3% and\n1.4% mAP. Thus, we have illustrated the effectiveness of all\nthe components in the proposed method under both the USL\nand UDA experiment settings.\n10\nTABLE VIII\nABLATION STUDY ON THE MARKET1501 AND DUKE DATASETS UNDER THE PURELY UNSUPERVISED PERSON RE-ID TASK.\nCentroids-Based\nMemory Contrastive\nLocal-Batch\nContrastive\nDynamic Hardest\nexample Mining\nProbability\nDistillation\nMarket1501\nDuke\nmAP\nTop-1\nTop-5\nTop-10\nmAP\nTop-1\nTop-5\nTop-10\n\u0013\n\u0017\n\u0017\n\u0017\n76.3\n90.1\n96.1\n97.3\n61.9\n78.0\n87.1\n90.5\n\u0013\n\u0013\n\u0017\n\u0017\n79.1\n91.0\n96.4\n97.5\n64.2\n80.1\n88.2\n90.4\n\u0013\n\u0013\n\u0013\n\u0017\n80.8\n92.2\n96.8\n97.9\n67.7\n82.1\n90.1\n92.6\n\u0013\n\u0017\n\u0017\n\u0013\n78.1\n90.6\n96.5\n97.5\n64.8\n80.4\n88.2\n90.5\n\u0013\n\u0013\n\u0013\n\u0013\n81.7\n92.4\n97.4\n98.1\n69.0\n82.9\n90.9\n93.0\nTABLE IX\nABLATION STUDY ON THE MARKET1501 DATASETS UNDER THE UDA\nPERSON RE-ID TASK.\nMethods\nmAp\nTop-1\nTop-5\nTop-10\nSPCL[4]\n76.7\n90.3\n96.2\n97.7\nBaseline\n80.0\n91.5\n96.8\n97.9\nLL2G\n82.5\n92.9\n97.1\n98.1\nBaseline+LS\n81.3\n92.2\n96.8\n97.7\nLL2G + γLS\n83.9\n93.6\n97.5\n98.3\nTABLE X\nABLATION STUDY OF THE PROBABILITY DISTILLATION METHOD ON THE\nMARKET1501 DATASETS.\nMethods\nmAp\nTop-1\nTop-5\nTop-10\nLL2G\n80.8\n92.2\n96.8\n97.9\nLL2G+MeanTeacher-L2\n81.0\n92.4\n97.0\n98.1\nLL2G + λLS\n81.7\n92.4\n97.4\n98.1\nProbability Distillation is one of the main module in the\nproposed framework to capture the self-supervised signals.\nTo reveal some inner mechanism of the proposed distillation\nmethod, we thoroughly make detailed comparison with the\ntraditional Mean-Teacher framework [22] on the Market1501\ndataset under the purely USL setting. As illustrated in Ta-\nble X, the ﬁrst line is the baseline method LL2G without\nusing the probability distillation algorithm. The second line\n”LL2G+MeanTeacher-L2” is the traditional ”Mean-Teacher”\nmethod [22], where we have simply incorporated the pro-\nposed method LS into the ”Mean-Teacher” framework, and\nL 2 regression loss is used to minimize the output features\nbetween the teacher and student networks. By comparing\nthe results between LL2G and LL2G+MeanTeacher-L2, the\n”LL2G+MeanTeacher-L2” algorithm obtains comparable re-\nsults, and just improved the mAP by 0.2% on Market1501\ndataset. The third line is our proposed probability distillation\nmethod, where we have project all the image features onto the\nobtained cluster centroids and then get their corresponding\npseudo labels. Finally, by using the proposed probability\ndistillation method, we have further improved our baseline\nmethod LL2G by another 0.9% mAP, and we have got the new\nstate-of-the-art results on all the four commonly used large-\nscale person re-Id datasets, under the purely USL and UDA\nsettings.\nThe hyper-parameter λ in the ﬁnal objective function is\nused as a tradeoff between the local-to-global cluster con-\ntrastive learning LL2G and the probability distillation objective\nTABLE XI\nABLATION STUDY OF THE PARAMETER λ ON THE MARKET1501\nDATASETS.\nParameter λ\nmAp\nTop-1\nTop-5\nTop-10\n0\n80.8\n92.2\n96.8\n97.9\n0.1\n81.1\n92.2\n97.1\n98.1\n0.2\n81.7\n92.4\n97.4\n98.1\n0.3\n81.6\n92.5\n96.9\n98.1\n0.5\n80.9\n91.8\n96.9\n98.0\n1.0\n81.0\n92.4\n97.0\n98.1\n1.5\n79.9\n91.7\n96.6\n97.8\nLS. As illustrated in Table XI, we have made detailed analysis\nof the hyper-parameter λ by varying its value from 0.0 to\n1.5 on Market1501 dataset. We can clearly see that the\nproposed method obtains the best performances at λ = 0.2.\nBy comparing all the results under different values of λ, the\nﬁnal results don’t vibrate too much, which reveals that the\nproposed distillation framework is robust to such parameter\nand beneﬁts for network training.\nV. DISCUSSION ANF CONCLUSION\nIn this paper, we propose the hybrid dynamic local-to-global\ncluster contrastive and probability distillation framework for\nunsupervised person re-Id task. Our algorithm surpasses al-\nmost all state-of-the-art methods on the four commonly used\nlarge-scale person re-Id datasets, namely Martket1501 [27],\nDukeMTMC [28], MSMT17-v2 [15], and PersonX [29]. The\nproposed method formulates the unsupervised person Re-Id\nproblem into an uniﬁed local-to-global dynamic learning and\nself-supervised probability regression framework. It can not\nonly explore useful supervised information from the estimated\npseudo labels by cluster contrast learning, but also make\nfull use of the self-supervised signals of all the training\nimages from both the instances’ self-contrastive level and the\nprobability regression perspective, in the memory-based non-\nparametric manner. We believe that our proposed unsuper-\nvised learning framework can be further extended to other\nunsupervised or semi-supervised learning tasks, and we will\nmake much more detailed analysis and improvements of the\nproposed USL algorithm in the future.\nREFERENCES\n[1] H. Fan, L. Zheng, C. Yan, and Y. Yang, “Unsupervised person re-\nidentiﬁcation: Clustering and ﬁne-tuning,” ACM Transactions on Multi-\n11\nmedia Computing, Communications, and Applications (TOMM), vol. 14,\nno. 4, pp. 1–18, 2018.\n[2] Y. Fu, Y. Wei, G. Wang, Y. Zhou, H. Shi, and T. S. Huang, “Self-\nsimilarity grouping: A simple unsupervised cross domain adaptation\napproach for person re-identiﬁcation,” in Proceedings of the IEEE/CVF\nInternational Conference on Computer Vision, 2019, pp. 6112–6121.\n[3] Y. Ge, D. Chen, and H. Li, “Mutual mean-teaching: Pseudo label reﬁnery\nfor unsupervised domain adaptation on person re-identiﬁcation,” arXiv\npreprint arXiv:2001.01526, 2020.\n[4] Y. G. F. Zhu, D. Chen, and R. Z. H. Li, “Self-paced contrastive learning\nwith hybrid memory for domain adaptive object re-id,” pp. 11 309–\n11 321, 2020.\n[5] X. Zhang, J. Cao, C. Shen, and M. You, “Self-training with progressive\naugmentation for unsupervised cross-domain person re-identiﬁcation,”\nin Proceedings of the IEEE/CVF International Conference on Computer\nVision, 2019, pp. 8222–8231.\n[6] D. Cheng, Y. Gong, S. Zhou, J. Wang, and N. Zheng, “Person re-\nidentiﬁcation by multi-channel parts-based cnn with improved triplet\nloss function,” in Proceedings of the iEEE conference on computer vision\nand pattern recognition, 2016, pp. 1335–1344.\n[7] M. Ester, H.-P. Kriegel, J. Sander, X. Xu et al., “A density-based\nalgorithm for discovering clusters in large spatial databases with noise.”\nin kdd, vol. 96, no. 34, 1996, pp. 226–231.\n[8] T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. Piatko, R. Silverman,\nand A. Y. Wu, “An efﬁcient k-means clustering algorithm: Analysis and\nimplementation,” IEEE transactions on pattern analysis and machine\nintelligence, vol. 24, no. 7, pp. 881–892, 2002.\n[9] Y. Ge, F. Zhu, R. Zhao, and H. Li, “Structured domain adaptation\nwith online relation regularization for unsupervised person re-id,” arXiv\npreprint arXiv:2003.06650, 2020.\n[10] A. Tarvainen and H. Valpola, “Mean teachers are better role mod-\nels: Weight-averaged consistency targets improve semi-supervised deep\nlearning results,” arXiv preprint arXiv:1703.01780, 2017.\n[11] J. Li, R. Socher, and S. C. Hoi, “Dividemix: Learning with noisy labels\nas semi-supervised learning,” arXiv preprint arXiv:2002.07394, 2020.\n[12] L. Song, C. Wang, L. Zhang, B. Du, Q. Zhang, C. Huang, and X. Wang,\n“Unsupervised domain adaptive re-identiﬁcation: Theory and practice,”\nPattern Recognition, vol. 102, p. 107173, 2020.\n[13] H.-X. Yu, W.-S. Zheng, A. Wu, X. Guo, S. Gong, and J.-H. Lai,\n“Unsupervised person re-identiﬁcation by soft multilabel learning,” in\nProceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2019, pp. 2148–2157.\n[14] D. Wang and S. Zhang, “Unsupervised person re-identiﬁcation via multi-\nlabel classiﬁcation,” in Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, 2020, pp. 10 981–10 990.\n[15] L. Wei, S. Zhang, W. Gao, and Q. Tian, “Person transfer gan to bridge\ndomain gap for person re-identiﬁcation,” in Proceedings of the IEEE\nconference on computer vision and pattern recognition, 2018, pp. 79–\n88.\n[16] M. Noroozi and P. Favaro, “Unsupervised learning of visual representa-\ntions by solving jigsaw puzzles,” in European conference on computer\nvision.\nSpringer, 2016, pp. 69–84.\n[17] R. Zhang, P. Isola, and A. A. Efros, “Colorful image colorization,” in\nEuropean conference on computer vision. Springer, 2016, pp. 649–666.\n[18] C. Doersch, A. Gupta, and A. A. Efros, “Unsupervised visual repre-\nsentation learning by context prediction,” in Proceedings of the IEEE\ninternational conference on computer vision, 2015, pp. 1422–1430.\n[19] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, “Momentum contrast\nfor unsupervised visual representation learning,” in Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2020, pp. 9729–9738.\n[20] T. Chen, S. Kornblith, K. Swersky, M. Norouzi, and G. Hinton, “Big self-\nsupervised models are strong semi-supervised learners,” arXiv preprint\narXiv:2006.10029, 2020.\n[21] J.-B.\nGrill,\nF.\nStrub,\nF.\nAltch´e,\nC.\nTallec,\nP.\nH.\nRichemond,\nE. Buchatskaya, C. Doersch, B. A. Pires, Z. D. Guo, M. G. Azar et al.,\n“Bootstrap your own latent: A new approach to self-supervised learning,”\narXiv preprint arXiv:2006.07733, 2020.\n[22] Z. Cai, A. Ravichandran, S. Maji, C. Fowlkes, Z. Tu, and S. Soatto,\n“Exponential moving average normalization for self-supervised and\nsemi-supervised learning,” in Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, 2021, pp. 194–203.\n[23] X. Chen and K. He, “Exploring simple siamese representation learning,”\nin Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2021, pp. 15 750–15 758.\n[24] K. Zheng, C. Lan, W. Zeng, Z. Zhang, and Z.-J. Zha, “Exploiting sample\nuncertainty for domain adaptive person re-identiﬁcation,” arXiv preprint\narXiv:2012.08733, 2020.\n[25] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770–778.\n[26] Z. Dai, G. Wang, W. Yuan, S. Zhu, and P. Tan, “Cluster contrast for\nunsupervised person re-identiﬁcation,” arXiv preprint arXiv:2103.11568,\n2021.\n[27] L. Zheng, L. Shen, L. Tian, S. Wang, J. Wang, and Q. Tian, “Scalable\nperson re-identiﬁcation: A benchmark,” in Proceedings of the IEEE\ninternational conference on computer vision, 2015, pp. 1116–1124.\n[28] E. Ristani, F. Solera, R. Zou, R. Cucchiara, and C. Tomasi, “Performance\nmeasures and a data set for multi-target, multi-camera tracking,” in\nEuropean conference on computer vision.\nSpringer, 2016, pp. 17–35.\n[29] X. Sun and L. Zheng, “Dissecting person re-identiﬁcation from the\nviewpoint of viewpoint,” in Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, 2019, pp. 608–617.\n[30] Z. Zhong, L. Zheng, D. Cao, and S. Li, “Re-ranking person re-\nidentiﬁcation with k-reciprocal encoding,” in Proceedings of the IEEE\nconference on computer vision and pattern recognition, 2017, pp. 1318–\n1327.\n[31] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:\nA large-scale hierarchical image database,” in 2009 IEEE conference on\ncomputer vision and pattern recognition.\nIeee, 2009, pp. 248–255.\n[32] T. Xiao, S. Li, B. Wang, L. Lin, and X. Wang, “Joint detection and\nidentiﬁcation feature learning for person search,” in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, 2017,\npp. 3415–3424.\n[33] S. Liao, Y. Hu, X. Zhu, and S. Z. Li, “Person re-identiﬁcation by local\nmaximal occurrence representation and metric learning,” in Proceedings\nof the IEEE conference on computer vision and pattern recognition,\n2015, pp. 2197–2206.\n[34] Y. Lin, X. Dong, L. Zheng, Y. Yan, and Y. Yang, “A bottom-up clustering\napproach to unsupervised person re-identiﬁcation,” in Proceedings of the\nAAAI Conference on Artiﬁcial Intelligence, vol. 33, no. 01, 2019, pp.\n8738–8745.\n[35] J. Wu, Y. Yang, H. Liu, S. Liao, Z. Lei, and S. Z. Li, “Unsupervised\ngraph association for person re-identiﬁcation,” in Proceedings of the\nIEEE/CVF International Conference on Computer Vision, 2019, pp.\n8321–8330.\n[36] Y. Lin, L. Xie, Y. Wu, C. Yan, and Q. Tian, “Unsupervised person\nre-identiﬁcation via softened similarity learning,” in Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2020, pp. 3390–3399.\n[37] G. Wu, X. Zhu, and S. Gong, “Tracklet self-supervised learning for\nunsupervised person re-identiﬁcation,” in Proceedings of the AAAI\nConference on Artiﬁcial Intelligence, vol. 34, no. 07, 2020, pp. 12 362–\n12 369.\n[38] J. Li and S. Zhang, “Joint visual and temporal consistency for unsuper-\nvised domain adaptive person re-identiﬁcation,” in European Conference\non Computer Vision.\nSpringer, 2020, pp. 483–499.\n[39] K. Zeng, M. Ning, Y. Wang, and Y. Guo, “Hierarchical clustering with\nhard-batch triplet loss for person re-identiﬁcation,” in Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2020, pp. 13 657–13 665.\n[40] Z. Wang, J. Zhang, L. Zheng, Y. Liu, Y. Sun, Y. Li, and S. Wang,\n“Cycas: Self-supervised cycle association for learning re-identiﬁable\ndescriptions,” in Computer Vision–ECCV 2020: 16th European Con-\nference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XI 16.\nSpringer, 2020, pp. 72–88.\n[41] Z. L. Y. C. Y. L. S. L. N. S. Fengxiang Yang, Zhun Zhong, “Joint noise-\ntolerant learning and meta camera shift adaptation for unsupervised\nperson re-identiﬁcation,” in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition, 2021, pp. 4855–4864.\n[42] H. Chen, Y. Wang, B. Lagadec, A. Dantcheva, and F. Bremond,\n“Joint generative and contrastive learning for unsupervised person re-\nidentiﬁcation,” in Proceedings of the IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition, 2021, pp. 2004–2013.\n[43] M. Li, X. Zhu, and S. Gong, “Unsupervised person re-identiﬁcation\nby deep learning tracklet association,” in Proceedings of the European\nconference on computer vision (ECCV), 2018, pp. 737–753.\n[44] Z. Zhong, L. Zheng, Z. Luo, S. Li, and Y. Yang, “Invariance matters:\nExemplar memory for domain adaptive person re-identiﬁcation,” in\nProceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2019, pp. 598–607.\n12\n[45] Y.-J. Li, C.-S. Lin, Y.-B. Lin, and Y.-C. F. Wang, “Cross-dataset person\nre-identiﬁcation via unsupervised pose disentanglement and adaptation,”\nin Proceedings of the IEEE/CVF International Conference on Computer\nVision, 2019, pp. 7919–7929.\n[46] Y. Chen, X. Zhu, and S. Gong, “Instance-guided context rendering for\ncross-domain person re-identiﬁcation,” in Proceedings of the IEEE/CVF\nInternational Conference on Computer Vision, 2019, pp. 232–242.\n[47] Y. Zhai, Q. Ye, S. Lu, M. Jia, R. Ji, and Y. Tian, “Multiple expert\nbrainstorming for domain adaptive person re-identiﬁcation,” in Computer\nVision–ECCV 2020: 16th European Conference, Glasgow, UK, August\n23–28, 2020, Proceedings, Part VII 16.\nSpringer, 2020, pp. 594–611.\n[48] F. Yang, K. Li, Z. Zhong, Z. Luo, X. Sun, H. Cheng, X. Guo, F. Huang,\nR. Ji, and S. Li, “Asymmetric co-teaching for unsupervised cross-domain\nperson re-identiﬁcation,” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, vol. 34, no. 07, 2020, pp. 12 597–12 604.\n[49] Y. Zou, X. Yang, Z. Yu, B. V. Kumar, and J. Kautz, “Joint disentangling\nand adaptation for cross-domain person re-identiﬁcation,” in Computer\nVision–ECCV 2020: 16th European Conference, Glasgow, UK, August\n23–28, 2020, Proceedings, Part II 16.\nSpringer, 2020, pp. 87–104.\n[50] Z. Zhong, L. Zheng, Z. Luo, S. Li, and Y. Yang, “Learning to adapt\ninvariance in memory for person re-identiﬁcation,” IEEE transactions\non pattern analysis and machine intelligence, 2020.\n[51] C. Luo, C. Song, and Z. Zhang, “Generalizing person re-identiﬁcation\nby camera-aware invariance learning and cross-domain mixup,” in\nComputer Vision–ECCV 2020: 16th European Conference, Glasgow,\nUK, August 23–28, 2020, Proceedings, Part XV 16.\nSpringer, 2020,\npp. 224–241.\n[52] F. Zhao, S. Liao, G.-S. Xie, J. Zhao, K. Zhang, and L. Shao, “Un-\nsupervised domain adaptation with noise resistible mutual-training for\nperson re-identiﬁcation,” in European Conference on Computer Vision.\nSpringer, 2020, pp. 526–544.\n",
  "categories": [
    "cs.CV"
  ],
  "published": "2021-09-29",
  "updated": "2021-09-29"
}