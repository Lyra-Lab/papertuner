{
  "id": "http://arxiv.org/abs/2110.01894v2",
  "title": "Combining Physics and Deep Learning to learn Continuous-Time Dynamics Models",
  "authors": [
    "Michael Lutter",
    "Jan Peters"
  ],
  "abstract": "Deep learning has been widely used within learning algorithms for robotics.\nOne disadvantage of deep networks is that these networks are black-box\nrepresentations. Therefore, the learned approximations ignore the existing\nknowledge of physics or robotics. Especially for learning dynamics models,\nthese black-box models are not desirable as the underlying principles are well\nunderstood and the standard deep networks can learn dynamics that violate these\nprinciples. To learn dynamics models with deep networks that guarantee\nphysically plausible dynamics, we introduce physics-inspired deep networks that\ncombine first principles from physics with deep learning. We incorporate\nLagrangian mechanics within the model learning such that all approximated\nmodels adhere to the laws of physics and conserve energy. Deep Lagrangian\nNetworks (DeLaN) parametrize the system energy using two networks. The\nparameters are obtained by minimizing the squared residual of the\nEuler-Lagrange differential equation. Therefore, the resulting model does not\nrequire specific knowledge of the individual system, is interpretable, and can\nbe used as a forward, inverse, and energy model. Previously these properties\nwere only obtained when using system identification techniques that require\nknowledge of the kinematic structure. We apply DeLaN to learning dynamics\nmodels and apply these models to control simulated and physical rigid body\nsystems. The results show that the proposed approach obtains dynamics models\nthat can be applied to physical systems for real-time control. Compared to\nstandard deep networks, the physics-inspired models learn better models and\ncapture the underlying structure of the dynamics.",
  "text": "Combining Physics and Deep Learning to learn\nContinuous-Time Dynamics Models\nMichael Lutter1 and Jan Peters1\nAbstract\nDeep learning has been widely used within learning algorithms for robotics. One disadvantage of deep networks is that\nthese networks are black-box representations. Therefore, the learned approximations ignore the existing knowledge of\nphysics or robotics. Especially for learning dynamics models, these black-box models are not desirable as the underlying\nprinciples are well understood and the standard deep networks can learn dynamics that violate these principles. To learn\ndynamics models with deep networks that guarantee physically plausible dynamics, we introduce physics-inspired\ndeep networks that combine ﬁrst principles from physics with deep learning. We incorporate Lagrangian mechanics\nwithin the model learning such that all approximated models adhere to the laws of physics and conserve energy.\nDeep Lagrangian Networks (DeLaN) parametrize the system energy using two networks. The parameters are obtained\nby minimizing the squared residual of the Euler-Lagrange differential equation. Therefore, the resulting model does\nnot require speciﬁc knowledge of the individual system, is interpretable, and can be used as a forward, inverse, and\nenergy model. Previously these properties were only obtained when using system identiﬁcation techniques that require\nknowledge of the kinematic structure. We apply DeLaN to learning dynamics models and apply these models to control\nsimulated and physical rigid body systems. The results show that the proposed approach obtains dynamics models that\ncan be applied to physical systems for real-time control. Compared to standard deep networks, the physics-inspired\nmodels learn better models and capture the underlying structure of the dynamics.\n1\nIntroduction\nDuring the last ﬁve years, deep learning has shown the\npotential to fundamentally change the use of learning in\nrobotics. Currently, many robot learning approaches involve\na deep network as part of their algorithm. The network\neither represents a policy that selects the actions, a dynamics\nmodel that predicts the next state, or a state estimator that\nextracts the relevant features from unstructured observations.\nInitially, many of these approaches were only applicable\nto simulated environments due to the large amounts of\ndata required to train the networks. When using massive\nparallelized simulations, these methods achieved astonishing\nresults (Heess et al. 2017). By now, these learning algorithms\nhave been improved and start to be applied to real-world\nsystems (Akkaya et al. 2019; Haarnoja et al. 2018). On\nthe physical systems, the deep network approaches have\nnot bypassed classical robotics techniques yet, but have\nshown very promising results achieving comparable results\nas classical methods.\nWithin many proposed algorithms deep networks have\nreplaced analytic models and other function approximators\ndue to their simplicity, generic applicability, scalability,\nhigh\nmodel\ncapacity\nand\nwidespread\navailability\nof\nGPU’s enabling fast training and evaluation. The generic\napplicability of these black-box models combined with the\nhigh model capacity is a curse and blessing. On the one\nside, this combination enables the learning of arbitrary\nfunctions with high ﬁdelity. However, this combination is\nalso susceptible to overﬁt to the data without retrieving the\nunderlying structure. Furthermore, the black-box nature of\nstandard deep networks prevents including prior knowledge\nfrom ﬁrst-order principles. This limitation is especially\nproblematic for robotics as the overﬁtting to spurious data\ncan lead to unpredictable behaviors damaging the physical\nsystem. The problem is also made unnecessarily harder as\nall existing knowledge of robotics and mechanics is ignored.\nIn this article, we propose a new approach that combines\nexisting knowledge with deep networks. This combination\nenables to learn better representations for robotics and\nretains\nthe\nadvantages\nof\ndeep\nnetworks.\nTo\nlearn\nphysically plausible continuous-time dynamics models of\nrigid body systems, we combine Lagrangian mechanics with\ndeep networks. The proposed Deep Lagrangian Networks\n(DeLaN) use two deep networks to parameterize the\nkinetic and potential energy (Lutter et al. 2019). The\nnetwork parameters are learned by minimizing the squared\nresidual of the Euler-Lagrange differential equation. The\nresulting dynamics models are guaranteed to evolve as\na mechanical system and conserve the system energy.\nTherefore, these models achieve better long-term predictions\nand control performance than the standard black-box models.\nThe resulting physics-inspired models share many of the\ncharacteristics of analytic models without requiring speciﬁc\nknowledge about the individual system. For example, DeLaN\nmodels are interpretable and enable the computation of\nthe gravitational forces, the momentum, and the system\nenergy. Previously, computing this decomposition was\n1Intelligent Autonomous Systems Group at Technical University of\nDarmstadt, Germany\nCorresponding author:\nMichael Lutter, michael@robot-learning.de\narXiv:2110.01894v2  [cs.LG]  17 Mar 2023\n2\nonly possible using the analytic models with the system\nparameters. DeLaN also enables the computation of the\nforward and inverse models with the same parameters.\nThese characteristics are in stark contrast to standard black-\nbox models. Such black-box models only obtain either\nthe forward or the inverse model and cannot compute the\ndifferent physical quantities as these need to be learned\nunsupervised. Due to these advantages of physics-inspired\ndynamics models, many variants have been proposed\n(Greydanus et al. 2019; Gupta et al. 2019; Zhong et al. 2019;\nSaemundsson et al. 2020; Cranmer et al. 2020).\n1.1\nContribution\nThe contribution of this article is the presentation of a model\nlearning framework that combines the existing knowledge of\nmechanics with deep networks. To highlight the possibilities\nof this approach for learning dynamics model, we describe\nDeep Lagrangian Networks (DeLaN) (Lutter et al. 2019).\nThis model learning approach combines deep learning with\nLagrangian mechanics to learn a physically plausible model\nby minimizing the residual of the Euler-Lagrange ordinary\ndifferential equation. In contrast to our previous papers\n(Lutter et al. 2019; Lutter and Peters 2019), which mainly\nfocused on speciﬁc algorithmic ideas, this article\n(1) consolidates the existing literature on physics-inspired\nmodel learning which has been introduced since the initial\npresentation of DeLaN. We summarize the individual\ncontributions and merge the variants into a single big picture.\n(2) extends\nthe\nprevious\nexperimental\nevaluation\nand\nprovides in-depths comparisons of the different variants\nof physics-inspired networks. We evaluate the control\nperformance\nof\nthe\nlearned\nmodels\non\nthe\nphysical\nsystem using inverse dynamics control and energy control.\nIn addition, the performance is compared to system\nidentiﬁcation and black-box model learning.\n(3) provides\nan\nelaborate\ndiscussion\non\nthe\ncurrent\nshortcomings of physics-inspired networks and highlight\npossibilities to overcome these limitations.\n1.2\nOutline\nTo provide a self-contained overview about physics-inspired\ndeep networks for learning dynamics models, we brieﬂy\nsummarize the related work (Section 2), prior approaches\nfor learning dynamics models of rigid body systems\nas well as the basics of Lagrangian and Hamiltonian\nmechanics\n(Section\n3.2).\nSubsequently,\nwe\nintroduce\nphysics-inspired networks derived from Lagrangian and\nHamiltonian mechanics as well as the existing variants\n(Section 4). Section 5 presents the experimental results of\napplying these models to model-based control and compares\nthe performance to system identiﬁcation as well as deep\nnetwork dynamics models. Finally, Section 6 discusses the\nexperimental results, highlights the limitations of physics-\ninspired networks, and summarizes the contributions of this\narticle.\n2\nRelated Work\nIn the main part of this article, we focus on learning\ncontinuous-time dynamics models of mechanical systems.\nHowever, physics-inspired networks and continuous-time\ndeep networks have been utilized for different applications\nareas. In this section, we want to brieﬂy summarize the\nexisting work on both topics outside the domain of rigid body\nsystems and their differences.\n2.1\nPhysics-Inspired Deep Networks\nIncorporating knowledge of physics within deep networks\nhas been approached by introducing conservation laws\nor symmetries within the network architecture. Both\napproaches are tightly coupled due to Noether’s theorem\nshowing that symmetries induce conservation laws. In the\ncase of conservation laws, these laws can be incorporated\nby minimizing the residual of the corresponding differential\nequation to obtain the optimal network parameters. The\ncombination of deep learning and differential equations\nhas been well known for a long time and investigated in\nmore abstract forms (Lee and Kang 1990; Meade Jr and\nFernandez 1994; Lagaris et al. 1998, 2000). Using this\napproach, various authors proposed to use the Navier-Stokes\nequation (Raissi et al. 2017a; Chu et al. 2021), Schroedinger\nequation (Raissi et al. 2017b), Burgers Equation (Holl et al.\n2020), Hamilton’s equation (Greydanus et al. 2019; Zhong\net al. 2019; Chen et al. 2020; Toth et al. 2019) or the Euler-\nLagrange equation (Lutter et al. 2019; Qin 2020; Cranmer\net al. 2020; Gupta et al. 2019).\nSymmetries can be integrated within the network architec-\nture by selecting a non-linear transformation that is either\nequivariant, i.e., preserves the symmetry, or is invariant to\nspeciﬁc transformations of the input. Using this approach,\none can derive layers that are translational-, rotational-,\nscale- and gauge equivariant (Cohen and Welling 2016;\nBekkers 2019; Wang et al. 2020b; Cohen et al. 2019). These\narchitectures are frequently used for computer vision as\nimage classiﬁcation is translational and rotational invari-\nant (Cohen et al. 2019; Weiler and Cesa 2019; Lenc and\nVedaldi 2015). Up to now, only very few papers have applied\nthis approach to model physical phenomena (Wang et al.\n2020b; Anderson et al. 2019). A different approach to sym-\nmetries was proposed by Huh et al. (2020). To obtain time\ntranslation invariance, which is equivalent to conservation of\nenergy, this work optimized time-reversibility. Therefore, the\nsymmetry is not incorporated in the network architecture but\nthe optimization loss.\nBesides these generic approaches utilizing symmetries and\nconservation laws, various authors also proposed speciﬁc\narchitectures for individual problems. In this case, the\nknown spatial structure of the problem is embedded\nwithin the network architecture. For example, Wang et al.\n(2020a) proposed a network architecture for turbulent ﬂow\npredictions that incorporates multiple spatial and temporal\nscales. Sanchez-Gonzalez et al. (2018) used a graph network\nto encode the known kinematic structure and the local\ninteractions between two links within the network structure.\nSimilarly, Sch¨utt et al. (2017) incorporates the local structure\nof molecules within the network architecture.\nLutter and Peters\n3\n2.2\nContinuous-Time Models & Neural ODEs\nThe work on neural ordinary differential equation (ODE)\nby Chen et al. (2018) initiated a large surge of research\non continuous-time models. The original work on neural\nODE proposed a deep network with inﬁnite depth to improve\nclassiﬁcation and density estimation. While these algorithms\nwere not meant for modeling dynamical systems, the explicit\nintegration step within the neural ODE led to rediscover\ncontinuous-time models for dynamical systems. Since then,\nneural ode’s have been frequently mentioned as inspiration\nto learn continuous-time models (Saemundsson et al. 2020;\nHuh et al. 2020; Botev et al. 2021; Hochlehnert et al. 2021).\nFrequently the term neural ODE is used interchangeably for a\ncontinuous-time model with a deep network. In this work, we\nwill only use the term continuous-time model. One technical\ndifference between the original neural ODE and continuous-\ntime models is that the neural ODE uses a variable time step\nintegrator, most commonly the Dormand–Prince method.\nThe continuous-time models use a ﬁxed time step integrator.\nFor the ﬁxed time step integrator, different authors have used\nthe explicit Euler, the Runge Kutta method, or symplectic\nintegrators. For dynamics models, the ﬁxed time step is\nconvenient as the data is observed at a ﬁxed time step\ndetermined by the sampling rate of digital sensors.\n3\nPreliminaries\nWe want to introduce the standard model learning techniques\nfor dynamical systems and brieﬂy summarize the relevant\ntheory of Lagrangian and Hamiltonian Mechanics.\n3.1\nLearning Dynamics Models\nModels describing system dynamics, i.e. the coupling of\nthe system input u and system state x, are essential for\nmodel-based control approaches (Ioannou and Sun 1996)\nand model based planning. Depending on the approach, one\neither relies on the forward or inverse model. For example,\ninverse dynamics control (de Wit et al. 2012) uses the\ninverse model to compensate system dynamics, while model-\npredictive control (Camacho and Alba 2013) and optimal\ncontrol (Zhou et al. 1996) use the forward model to compute\nthe future states given an action sequence. For discrete time\nmodels, the forward model 𝑓maps from the system state x𝑡\nand input u𝑡to the next state x𝑡+1. The inverse model 𝑓−1\nmaps from system state and the next state to the system input.\nMathematically this is described by\n𝑓(x𝑡, u𝑡; θ) = x𝑡+1,\n𝑓−1(x𝑡, x𝑡+1; θ) = u𝑡,\n(1)\nwith the model parameters θ. In the continuous time setting\nthe next state x𝑡+1 is replaced with the change of the state ¤x,\ni.e.,\n𝑓(x𝑡, u𝑡; θ) = ¤x𝑡,\n𝑓−1(x𝑡, ¤x𝑡; θ) = u𝑡.\n(2)\nThe continuous-time system can be combined with an\nintegrator, e.g., explicit Euler, Runge-Kutta method, or\nsymplectic integrators, to predict the next state instead of the\nchange of the system state. Therefore, the continuous-time\nmodel is independent of the time discretization. Depending\non the chosen representation, the transfer function 𝑓and\nparameters θ are obtained using different approaches. In\nthe following, we will differentiate the different approaches,\n(1) model engineering, (2) data-driven system identiﬁcation,\nand (3) black-box model learning. In Section 4, we will\nextend these existing categories to physics-inspired models.\n3.1.1\nModel Engineering. The most classical approach\nis model engineering, which is predominantly used within\nthe industry. In this case, the transfer function 𝑓is the\nequations of motion and the model parameters are the\nphysical parameters of the robot consisting of the masses,\ncenter of gravity, length, and inertia. The equations of motion\nhave to be manually derived for each system. Frequently, one\nassumes perfect rigid bodies connected by ideal joints and\nuses Newtonian, Lagrangian or Hamiltonian mechanics and\nthe known structure of the systems to derive the equations.\nThe model parameters can be either inferred using the\nCAD software or measured by disassembling the individual\nsystem. The latter is more precise as it incorporates\nthe deviations due to the manufacturing process (Albu-\nSch¨affer 2002). Furthermore, the parameters are identical\nfor the forward and inverse model. Therefore, this approach\nyields the forward and inverse model simultaneously. To\nsummarize, this approach can yield very precise forward and\ninverse models for rigid body systems but is labor-intensive\nas the parameters need to be manually inferred.\n3.1.2\nData-Driven System Identiﬁcation. Similar to\nmodel engineering, data-driven system identiﬁcation uses\nthe analytic equations of motions as the transfer function.\nHowever, the model parameters are learned from observed\ndata rather than measured. Therefore, the equations of\nmotions need to be manually derived but the model\nparameters are learned. In 1985 four different groups showed\nconcurrently that the dynamics parameters can be obtained\nby linear regression using hand-designed features for rigid\nbody kinematic chains (Khosla and Kanade 1985; Mukerjee\nand Ballard 1985; Atkeson et al. 1986; Gautier 1986).\nThis approach is commonly referenced as the standard\nsystem identiﬁcation technique for robot manipulators by\nthe textbooks (Siciliano and Khatib 2016). However, this\napproach cannot guarantee physically plausible parameters\nas the dynamics parameters have additional constraints. For\nexample, this approach can yield negative masses, an inertia\nmatrix that is not positive deﬁnite, or violate the parallel\naxis theorem (Ting et al. 2006). The disadvantages of this\napproach are that one can only infer linear combinations\nof the dynamics parameters, cannot apply it to close-loop\nkinematics (Siciliano and Khatib 2016) and can only be\napplied inverse dynamics. The inverse dynamic formulation\nis problematic as the inverse dynamics do not necessarily\nhave a unique solution due to friction (Ratliff et al. 2016).\nTo overcome these shortcomings, Ting et al. (2006) proposed\na projection-based approach while many others (Traversaro\net al. 2016; Wensing et al. 2017; Ledezma and Haddadin\n2017; Sutanto et al. 2020; Lutter et al. 2020, 2021b; Geist and\nTrimpe 2021) used virtual parametrizations that guarantee\nphysical plausible parameters. For the latter, the optimization\ndoes not simplify to linear regression but can be solved using\ngradient descent. To summarize, this approach only requires\nthe equations of motions analytically and can learn the\ndynamical parameters from data. Therefore, this approach is\n4\nRequires:\nAssumption: \nModels:\n∧Forward Model\n∧Inverse Model\nBlack-box Model \nLearning\n$!\n̈&!\nRequires:\n§\nKinematic Chain\n§\nLink Dimension\nAssumption: \n§ Rigid Body Dynamics\nModels:\n∨Forward Model\n∨Inverse Model\n∨Energy Model\nSystem \nIdentification\n$!\n̈&!\nRequires:\nAssumption: \n§ Lagrangian Mechanics\nModels:\n∨Forward Model\n∨Inverse Model\n∨Energy Model\nPhysics-Inspired \nNetworks\n$!\n̈&!\nℒ\n'\n(\nRequires:\n§\nKinematic Chain\n§\nLink Dimension\n§\nLink Parameter\nAssumption: \n§ Rigid Body Dynamics\nModels:\n∨\nForward Model\n∨\nInverse Model\n∨\nEnergy Model\nModel \nEngineering\n$!\n̈&!\nFigure 1. The requirements and assumptions of the different approaches to obtain the dynamics model of mechanical systems.\nThe physics-inspired networks bridge the gap between classical system identiﬁcation and black-box model learning. While system\nidentiﬁcation requires knowledge of the kinematic chain, the physics-inspired networks do not require any knowledge of the speciﬁc\nsystem but obtain comparable characteristics as system identiﬁcation. Physics-inspired networks also guarantee\nenergy-conserving models and obtain the forward, inverse, and energy model simultaneously.\nnot as labor-intensive as model engineering but one needs to\nensure to collect ’good’ data for the learning.\n3.1.3\nBlack-Box Model Learning. While the previous\napproaches required knowledge about the individual kine-\nmatic chain to derive the equations of motion, the black-\nbox approaches do not require any knowledge of the system.\nThese approaches use any black-box function approxima-\ntor as a transfer function and optimize the model param-\neters to ﬁt the observed data. For example, the existing\nliterature used Local Linear Models (Schaal et al. 2002;\nHaruno et al. 2001), Gaussian Mixture Models (Calinon\net al. 2010; Khansari-Zadeh and Billard 2011), Gaussian\nProcesses (Kocijan et al. 2004; Nguyen-Tuong et al. 2009;\nNguyen-Tuong and Peters 2010; Romeres et al. 2019, 2016;\nCamoriano et al. 2016), Support Vector Machines (Choi et al.\n2007; Ferreira et al. 2007), feedforward- (Jansen 1994; Lenz\net al. 2015; Ledezma and Haddadin 2017; Sanchez-Gonzalez\net al. 2018) or recurrent neural networks (Rueckert et al.\n2017; Ha and Schmidhuber 2018; Hafner et al. 2019a,b)\nto learn the dynamics model. The black-box models obtain\neither the forward or inverse model and the learned model\nis only valid on the training data distribution. The previous\nmethods based on the analytic equations of motions obtained\nboth models simultaneously and generalize beyond the data\ndistribution as the learned physical parameters are globally\nvalid. However, the black-box models do not require assump-\ntions about the systems and can learn systems including\ncontacts. These previous approaches relied on assuming rigid\nbody dynamics and could only learn the system dynamics\nof articulated bodies using reduced coordinates without con-\ntacts. Therefore, black-box models can be more accurate\nfor real-world systems where the underlying assumption is\nnot valid but is limited to the training domain and rarely\nextrapolate.\n3.2\nLagrangian Mechanics\nOne approach to derive equations of motion is Lagrangian\nMechanics. In the following, we summarize this approach\nas we will use it in Section 4 to propose a physics-inspired\nnetwork for learning dynamics models. More speciﬁcally we\nuse the Euler-Lagrange formulation with non-conservative\nforces and generalized coordinates. For more information\nand the formulation using Cartesian coordinates please\nrefer to the textbooks (Greenwood 2006; de Wit et al.\n2012; Featherstone 2007). Generalized coordinates q are\ncoordinates that uniquely deﬁne the system conﬁguration\nwithout constraints. These coordinates are often called\nreduced coordinates. For articulated bodies, the system state\ncan be expressed as x = [q, ¤q]. The Lagrangian mechanic’s\nformalism deﬁnes the Lagrangian L as a function of\ngeneralized coordinates q describing the complete dynamics\nof a given system. The Lagrangian is not unique and every\nL which yields the correct equations of motion is valid. The\nLagrangian is generally chosen to be\nL(q, ¤q) = 𝑇(q, ¤q) −𝑉(q) = 1\n2 ¤q⊤H(q) ¤q −𝑉(q),\n(3)\nwith the kinetic energy 𝑇, the potential energy 𝑉and the mass\nmatrix H(q). The kinetic energy 𝑇is quadratic for any choice\nof generalized coordinates and any non-relativistic system.\nThe mass matrix is the symmetric and positive deﬁnite\n(de Wit et al. 2012). The positive deﬁniteness ensures that all\nnon-zero velocities lead to positive kinetic energy. Applying\nthe calculus of variations yields the Euler-Lagrange equation\nwith non-conservative forces described by\n𝑑\n𝑑𝑡\n𝜕L(q, ¤q)\n𝜕¤q\n−𝜕L(q, ¤q)\n𝜕q\n= τ,\n(4)\n𝜕2L(q, ¤q)\n𝜕2 ¤q\n¥q + 𝜕L(q, ¤q)\n𝜕q𝜕¤q\n¤q −𝜕L(q, ¤q)\n𝜕q\n= τ,\n(5)\nwhere τ are generalized forces frequently corresponding to\nthe system input u. Substituting L with the kinetic and\npotential energy into Equation (4) yields the second order\nODE described by\nH(q) ¥q + ¤H(q) ¤q −1\n2\n\u0012\n¤q⊤𝜕H(q)\n𝜕q\n¤q\n\u0013⊤\n|                              {z                              }\n= c(q, ¤q)\n+ 𝜕𝑉(q)\n𝜕q\n|  {z  }\n= g(q)\n= τ,\n(6)\nLutter and Peters\n5\nwhere c describes the forces generated by the Centripetal and\nCoriolis forces and g the gravitational forces (Featherstone\n2007). Most robotics textbooks abbreviate this equation as\nH(q) ¥q + c(q, ¤q) + g(q) = τ. Using this ODE, any multi-\nparticle mechanical system with holonomic constraints can\nbe described. Various authors used this ODE to manually\nderive the equations of motion for coupled pendulums\n(Greenwood 2006), robotic manipulators with ﬂexible joints\n(Book 1984; Spong 1987), parallel robots (Miller 1992;\nGeng et al. 1992; Liu et al. 1993) or legged robots (Hemami\nand Wyman 1979; Golliday and Hemami 1977).\n3.3\nHamiltonian Mechanics\nA different approach to deriving the equations of motions is\nHamiltonian mechanics. In this case, the system dynamics\nare described using the state x = [q, p] with generalized\nmomentum p instead of the generalized velocity ¤q and the\nHamiltonian H instead of the Lagrangian. The generalized\nmomentum can be expressed using the Lagrangian and\nis described by p = 𝜕L/𝜕¤q (Fitzpatrick 2008). Given the\nparametrization of the Lagrangian (Equation (3)), this\ndeﬁnition is equivalent to p = H(q) ¤q. The Hamiltonian\ndescribes the complete energy of the system and is deﬁned\nas\nH (q, p) = 𝑇(q, p) + 𝑉(q) = 1\n2p⊤H(q)−1p + 𝑉(q).\n(7)\nThe Hamiltonian can be computed by applying the Legendre\ntransformation to the Lagrangian which is described by\nH (q, ¤q) = ¤q⊤𝜕L(q, ¤q)\n𝜕¤q\n−L(q, ¤q).\n(8)\nUsing the generalized momentum p and the generalized\ncoordinate q, the Euler-Lagrange equation can be rewritten\nto yield Hamilton’s equations with control (Greenwood\n2006). Hamilton’s equations is described by\n¤q = 𝜕H (q, p)\n𝜕p\n,\n¤p = −𝜕H (q, p)\n𝜕q\n+ τ .\n(9)\nThe\nEuler-Lagrange\nequation\n(Equation\n(6))\ncan\nbe\neasily derived from Hamilton’s equation by substituting\nEquation (7) into Equation (9) and using the deﬁnition of\nthe generalized momentum, i.e.,\n¤p = −𝜕H (q, p)\n𝜕q\n+ τ,\n𝑑\n𝑑𝑡\nh\nH(q) ¤q\ni\n= 1\n2\n\u0012\np⊤H−1 𝜕H\n𝜕q H−1p\n\u0013⊤\n−𝜕𝑉\n𝜕q + τ,\nH ¥q + ¤H ¤q = 1\n2\n\u0012\n¤q⊤𝜕H\n𝜕q ¤q\n\u0013⊤\n−𝜕𝑉\n𝜕q + τ,\nH ¥q + ¤H ¤q −1\n2\n\u0012\n¤q⊤𝜕H\n𝜕q ¤q\n\u0013⊤\n+ 𝜕𝑉\n𝜕q = τ .\nMany\ntextbooks\nomit\nthe\ngeneralized\nforces\nwithin\nHamilton’s equation but adding these generalized forces is\nstraightforward as shown in the previous derivation.\n4\nPhysics-Inspired Deep Networks\nA different approach to black-box model learning is to\ncombine black-box models with physics to guarantee a\nphysically plausible dynamics model. One combination\nis to use deep networks to represent the system energy\nand use the resulting Lagrangian to derive the equations\nof motion using the Euler-Lagrange differential equation.\nThis approach was initially proposed by Lutter et al.\n(2019) with the presentation of Deep Lagrangian Networks\n(DeLaN). Since then, many papers exploring variations of\nthese approaches have been proposed including approaches\nthat use Hamiltonian mechanics instead of Lagrangian\nmechanics (Greydanus et al. 2019; Cranmer et al. 2020;\nGupta et al. 2019; Zhong et al. 2019; Sanchez-Gonzalez et al.\n2019; Saemundsson et al. 2020; Zhong et al. 2021, 2020;\nHochlehnert et al. 2021).\nAll of these models have in common, that the learned dynam-\nics models conserve energy when the non-conservative\nforces can be modeled properly and the generalized coordi-\nnates are observed. Therefore, the learned model is guaran-\nteed to adhere to one of the fundamental concepts of physics.\nThis property is beneﬁcial as it has been shown within\nprior research that naive deep network dynamics models\nfrequently increase or decrease the system energy even when\nthe energy should be conserved (Greydanus et al. 2019;\nZhong et al. 2019; Hochlehnert et al. 2021; Saemundsson\net al. 2020).\nIn the following, we present DeLaN (Section 4.1) and the\ncombination of Hamiltonian mechanics and deep networks\nin Section 4.2. Afterwards, Section 4.3 describes all the\nproposed extensions of DeLaN and Hamiltonian Neural\nNetworks (HNN). Therefore, this section provides the\nbig picture of existing physics-inspired deep networks for\nlearning dynamics models. The ﬂow charts of the variants\nare shown in Figure 2\n4.1\nDeep Lagrangian Networks (DeLaN)\nDeLaN is one instantiation of these physics-inspired deep\nnetworks. DeLaN parametrizes the mass matrix H and the\npotential energy 𝑉as two separate deep networks. Therefore,\nthe approximate Lagrangian L described by\nL(q, ¤q; ψ, φ) = 1\n2 ¤q⊤H(q; ψ) ¤q −𝑉(q; φ).\n(10)\nUsing this parametrization the forward and inverse model\ncan be derived. The forward model ¥q = 𝑓(q, ¤q, τ; ψ, φ) is\ndescribed by\n¥q =\n\u0014 𝜕2L(q, ¤q)\n𝜕2 ¤q\n\u0015−1\u0014\nτ −𝜕L(q, ¤q)\n𝜕q𝜕¤q\n¤q + 𝜕L(q, ¤q)\n𝜕q\n\u0015\n,\n=\nH−1\n\u0014\nτ −¤H ¤q + 1\n2\n\u0012\n¤q⊤𝜕H\n𝜕q ¤q\n\u0013⊤\n−𝜕𝑉\n𝜕q\n\u0015\n.\nThe inverse model τ = 𝑓−1(q, ¤q, ¥q; ψ, φ) is described by\nτ = 𝜕2L(q, ¤q)\n𝜕2 ¤q\n¥q + 𝜕L(q, ¤q)\n𝜕q𝜕¤q\n¤q −𝜕L(q, ¤q)\n𝜕q\n,\n= H ¥q + ¤H ¤q −1\n2\n\u0012\n¤q⊤𝜕H\n𝜕q ¤q\n\u0013⊤\n+ 𝜕𝑉\n𝜕q .\n(11)\nThe partial derivatives within the forward and inverse model\ncan be computed using automatic differentiation or symbolic\n6\n!\ṅ\"!# ̇\"\n\"\nKinetic Energy\n#\nPotential Energy\n!\n$\"ℒ\n$\" ̇\"\n#$\n& −$\"ℒ\n$\" $ ̇\" ̇\" + $ℒ\n$\"\n-\n\"!\ṅ\"!\n\"!\"#\ṅ\"!\"#\nℒ\nLagrangian\n!\n$\"ℒ\n$\" ̇\"\n#$\n& −$\"ℒ\n$\" $ ̇\" ̇\" + $ℒ\n$\"\n\"!\ṅ\"!\n\"!\"#\ṅ\"!\"#\n!\n\"!\ṅ\"!\n\"!\"#\ṅ\"!\"#\n!\ṅ\"!# ̇\"\n\"\nKinetic Energy\n#\nPotential Energy\n!\ṅ\" = $ℋ\n$+\ṅ+ = & −$ℋ\n$\"\n+\n\"! %!\n\"!\"# %!\"#\nℋ\nHamiltonian\n!\ṅ\" = $ℋ\n$+\ṅ+ = & −$ℋ\n$\"\n\"! %!\n\"!\"# %!\"#\nDeep Network\nDeep Lagrangian Networks\nHamiltonian Neural Networks\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 2. The ﬂowcharts of a continuous-time forward model using a deep network and the physics-inspired networks forward\nmodels. (a) Standard deep model learning approach, where a network is used to directly predict the change in position and velocity.\n(b-c) Deep Lagrangian Networks which use deep networks to predict the Lagrangian L of the dynamical system and compute the\nchange in position and velocity using the Euler-Lagrange differential equation. (b) shows the structured Lagrangian approach,\nwhere two networks predict the kinetic 𝑇and potential energy 𝑉and computes the Lagrangian is analytically using L = 𝑇−𝑉. (c)\nshows the black-box Lagrangian approach where a network directly predicts L. (d-e) Hamiltonian Neural networks which use deep\nnetworks to predict the Hamiltonian H and computes the change in position and impulse via Hamilton’s equation. Similar to the\nLagrangian variants, (d) shows the structured Hamiltonian and (e) the black-box Hamiltonian. The structured Hamiltonian computes\nthe Hamiltonian via H = 𝑇(q, ¤q) −𝑉(q), where the kinectic and potential energy is predicted using two networks. The black-box\nHamiltonian uses a single network to directly predict H.\ndifferentiation. See Lutter et al. (2019) for the symbolic\ndifferentiation of the mass matrix and the deep networks.\nThe system energy cannot be learned using supervised\nlearning as the system energy cannot be observed. Therefore,\nthe network weights of the kinetic and potential energy are\nlearned unsupervised using the temporal consequences of\nthe actions and system energy. One approach to learn the\nnetwork parameters is to minimize the residual of the Euler-\nLagrange differential equation. This optimization problem is\ndescribed by\nψ∗, φ∗= arg min\nψ,φ\n\r\r\r\r\n𝑑\n𝑑𝑡\n𝜕L\n𝜕¤q −𝜕L\n𝜕q𝑖\n−τ\n\r\r\r\r\n2\nW𝜏\n,\n(12)\nwith the Mahalanobis norm\n∥·∥W\nand the diagonal\ncovariance matrix of the generalized forces W𝜏. It is\nbeneﬁcial to normalize the loss using the covariance matrix\nbecause magnitude of the residual might vary between\ndifferent joints. This optimization can be solved using\nany gradient-based optimization technique. Minimizing the\nsquared residual is equivalent to ﬁtting the inverse model,\ni.e., ψ∗, φ∗= arg minψ,φ\n\r\rτ −𝑓−1(q, ¤q, ¥q; ψ, φ)\n\r\r2\nW𝜏. This\nloss can also be extended to include the forward prediction\nthat ﬁts the joint accelerations. The combined optimization\nproblem is described by\nψ∗, φ∗= arg min\nψ,φ\n\r\rτ −𝑓−1(q, ¤q, ¥q; ψ, φ)\n\r\r2\nW𝜏\n+ ∥¥q −𝑓(q, ¤q, τ; ψ, φ)∥2\nW ¥q ,\n(13)\nwith the diagonal covariance matrix of the generalized\nforces W𝜏and accelerations W ¥q. Furthermore, its beneﬁcial\nto add regularization in the form of weight decay as the\nLagrangian is not unique. The Euler-Lagrange equation is\ninvariant to linear transformation. Hence, the Lagrangian\nL′ = 𝛼𝐿+ 𝛽solves the Euler-Lagrange equation if 𝛼is non-\nzero and L is a valid Lagrangian. Therefore, adding weight\nregularization helps obtaining a unique solution.\n4.1.1\nPositive-Deﬁnite Mass Matrix. To obtain a phys-\nically plausible kinetic energy, the mass matrix has to be\npositive deﬁnite, i.e.,\nq⊤H(q) q > 0\n∀\nq ∈R𝑛\n0.\n(14)\nThis constraint ensures all non-zero velocities have positive\nkinetic energy for all joint conﬁgurations. We obtain a\npositive deﬁnite mass matrix by predicting the Cholesky\ndecomposition of the mass matrix with a small positive\noffset 𝜖on the diagonal instead of the mass matrix directly.\nTherefore, the mass matrix is described by\nH(q) = L(q)L(q)⊤+ 𝜖I,\n(15)\nLutter and Peters\n7\nwith lower triangular matrix L and identity matrix I. In\naddition, the diagonal needs to be positive as otherwise,\nthe mass matrix is only positive semi-deﬁnite. A positive\ndiagonal is ensured by adding a non-negative linearity to\nthe elements of the diagonal and the positive offset 𝜖.\nUsing this parametrization the mass matrix is ensured to\nbe positive deﬁnite for all joint conﬁgurations. However,\nthis parametrization is numerically not favorable because the\nrandom weights the diagonal is close to 𝜖for all inputs.\nThis small diagonal is problematic for the forward model\nas the small eigenvalues of the mass matrix lead to a large\nampliﬁcation of the control torques due to the matrix inverse.\nThe default diagonal can be shifted by adding the positive\nconstant 𝛼before the non-linearity. This shift is described by\nldiag = 𝜎(ldiag + 𝛼) + 𝜖,\nwith the vectorized diagonal ldiag and the softplus function 𝜎.\nIf 𝛼> 1, the mass matrix damps the applied torques when\nldiag ≈0. This transformation is not essential to obtain good\nresults but balances the forward and inverse losses.\n4.1.2\nAdvantages of DeLaN. In contrast to the black-\nbox model, this parametrization of the dynamics has three\nadvantages, (1) this approach yields a physically plausible\nmodel that conserves energy, (2) is interpretable, and (3) can\nbe used as forward, inverse, and energy model. The DeLaN\nmodel is guaranteed to evolve like a mechanical system and\nis passive (Spong 1987) as the forward dynamics are derived\nfrom the physics prior and the positive deﬁnite mass matrix\nfor all model parameters. If the system is uncontrolled, i.e.,\nτ = 0, the system energy is conserved as the change in\nenergy is described by\n¤H = ¤q⊤τ = 0. In contrast, black-\nbox models can generate additional energy without system\ninputs. It is important to note that the conservation of energy\nof DeLaN does not guarantee to prevent the divergence of\nthe model rollouts. The potential energy is not bounded and\ncan accelerate the system indeﬁnitely. Especially outside the\ntraining domain, the potential energy is random.\nThe model is interpretable as one can disambiguate between\nthe different forces, e.g., inertial-, centrifugal-, Coriolis,\nand gravitational force. This decomposition is beneﬁcial as\nsome model-based control approaches require the explicit\ncomputation of the mass matrix, the gravitational force, or\nthe system energy. Furthermore, the same model parameters\ncan be used for the forward, inverse, and energy model.\nTherefore, the forward and inverse model are consistent. In\ncontrast, black-box models need to learn separate parameters\nfor the inverse and forward model that might not be\nconsistent and cannot obtain the system energy as these\ncannot be observed.\n4.2\nHamiltonian Neural Networks (HNN)\nInstead of using Lagrangian Mechanics as model prior for\ndeep networks, Greydanus et al. (2019) proposed to use\nHamiltonian mechanics. In this case, the HNN parametrize\nthe Hamiltonian with two deep networks described by\nH (q, p; ψ, φ) = 1\n2p⊤H(q; ψ)−1 p −𝑉(q; φ).\n(16)\nIt is important to note that HNN predict the inverse of the\nmass matrix instead of the mass matrix as in DeLaN. Similar\nto DeLaN, the forward and inverse model can be derived. The\nforward model [ ¤q, ¤p] = 𝑓(q, p, τ; ψ, φ) is described by\n¤q =\n𝜕H (q, p)\n𝜕p\n= H−1p,\n¤p = −𝜕H (q, p)\n𝜕q\n+ τ = −1\n2\n\u0012\np⊤𝜕H−1\n𝜕q\np\n\u0013⊤\n−𝜕𝑉\n𝜕q + τ .\nThe inverse model τ = 𝑓−1(q, p, ¤p; ψ, φ) is described by\nτ = ¤p + 𝜕H (q, p)\n𝜕q\n,\n= ¤p −1\n2\n\u0012\np⊤H−1 𝜕H\n𝜕q H−1p\n\u0013⊤\n+ 𝜕𝑉\n𝜕q .\nThe network parameters of the kinetic and potential energy\ncan be obtained by minimizing the squared residual using the\nobserved data consisting of [q, p, ¤q, ¤p, τ]. This optimization\nis described by\nψ∗, φ∗= arg min\n𝜓,𝜙\n\r\r\r\r ¤p + 𝜕H (q, p)\n𝜕q\n−τ\n\r\r\r\r\n2\nW ¤p\n+\n\r\r\r\r ¤q −𝜕H (q, p)\n𝜕p\n\r\r\r\r\n2\nW ¤q\n,\n(17)\nwith the diagonal covariance matrix W ¤q and W ¤p of ¤q and ¤p.\nThe minimization can be solved using the standard gradient\nbased optimization toolkit and automatic differentiation.\n4.2.1\nDifferences to DeLaN. DeLaN and HNN share\nthe same advantages as both models are derived from\nthe same principle. Therefore, HNN conserve energy, are\ninterpretable, and provide a forward, inverse, and energy\nmodel. The main difference is that DeLaN uses position\nand velocity while HNN uses position and momentum.\nDepending on the observed quantities either model ﬁts\nbetter than the other. A minor difference is that minimizing\nthe residual of the Euler-Lagrange equation is identical to\nthe inverse model loss while minimizing the residual of\nHamilton’s equations is identical to the forward model loss.\nFrom a numerical perspective, the Hamiltonian mechanics\nprior is slightly beneﬁcial as the forward and inverse model\nonly relies on the inverse of the mass matrix. Therefore,\none does not need to numerically compute the inverse of the\npredicted matrix. Avoiding the explicit inversion makes the\nlearning and model rollout a bit more stable. The Lagrangian\nmechanics prior relies on the mass matrix as well on the\ninverse. Therefore, the inverse of the predicted matrix has\nto be computed numerically. When the eigenvalues of the\nmass matrix approach 𝜖and 𝜖≪1, the model rollout and the\noptimization of the forward model can become numerically\nsensitive. Therefore, it is important to choose 𝜖as large\nas possible for the corresponding system as this limits the\nampliﬁcation of the acceleration.\n4.3\nVariations of DeLaN & HNN\nSince the introduction of DeLaN (Lutter et al. 2019) and\nHNN (Greydanus et al. 2019), many other variants and\nextensions have been proposed within the literature. We\nprovide an overview of the existing work and highlight the\ndifferences.\n8\n4.3.1\nParametrization of L and H. In the previous\nsections, the Hamiltonian H and Lagrangian L were\nparameterized by two networks predicting the mass matrix,\nor its inverse, for the kinetic energy and the potential energy.\nInstead of predicting these two quantities separately, one can\nalso use a single feed-forward network for both quantities.\nThis factorization is described by\nL = ℎ(q, ¤q; ψ),\nH = ℎ(q, p; ψ),\nwith the standard feed-forward network ℎand the network\nparameters ψ. Within the literature, this approach was used\nby (Greydanus et al. 2019; Cranmer et al. 2020) while\nthe (Lutter et al. 2019; Gupta et al. 2020; Zhong et al.\n2019; Saemundsson et al. 2020; Finzi et al. 2020) used\nthe representation of kinetic and potential energy. In the\nfollowing we, will differentiate between both approaches by\nusing the term structured Lagrangian/Hamiltonian and black-\nbox Lagrangian/Hamiltonian. The structured approach,\nrepresent the mass matrix and potential energy explicitly\nwhile the black-box approach uses a single network to\nrepresent the Lagrangian or Hamiltonian. The differences in\nthe model architecture for both approaches are depicted in\nFigure 2.\nOne beneﬁt of using a black-box L and H is that\nthe quadratic parametrization of the kinetic energy does\nnot apply to relativistic systems. The disadvantages of a\nsingle network approach are that this parametrization is\ncomputationally more demanding as one needs to compute\nthe Hessian of the network. Evaluating the Hessian of a\ndeep network can be done using automatic differentiation,\nbut is expensive in terms of computation and memory. When\nusing the quadratic kinetic energy, computing the Hessian\nof the network is not needed. Furthermore, the Hessian may\nnot be invertible if only a single network is used. If the\nHessian is singular or nearly singular, the forward model\nusing the Lagrangian prior becomes unstable and diverges.\nFor structured Lagrangian, this problem does not occur as\nthe eigenvalues of the mass matrix are lower bounded.\nMost existing work uses standard feed-forward networks to\nmodel the system energy, the Hamiltonian or the Lagrangian\n(Lutter et al. 2019; Greydanus et al. 2019; Zhong et al. 2019;\nGupta et al. 2020; Saemundsson et al. 2020; Finzi et al.\n2020). Other variants have also applied the physics-inspired\nnetworks to graph neural networks (Sanchez-Gonzalez et al.\n2019; Cranmer et al. 2020; Botev et al. 2021). Such graph\nneural networks incorporate additional structure within the\nnetwork architecture when the system dynamics consist of\nmultiple identical particles without additional constraints.\nTherefore, these methods exhibit improved performance for\nmodeling N-body problems.\n4.3.2\nLoss Functions and Integrators. The loss func-\ntions of DeLaN (Equation (13)) and HNN (Equation (17))\nexpress the loss in terms including the acceleration, i.e.,\n¥q and ¤p. These quantities are commonly not observed for\nreal-world systems and are approximated using ﬁnite differ-\nences. The problem of this approximation is that the ﬁnite\ndifferences amplify the amplitude of high frequency noise\ncomponents. Therefore, one has to use low-pass ﬁlters to\nobtain good acceleration estimates. A different approach that\navoids approximating the accelerations is to only use the\nforward loss and reformulate the loss in terms of position\nand velocities. In this case, the loss is described by\nψ∗, φ∗= arg min\nψ,φ\n∥x𝑡+1 −ˆx𝑡+1(x𝑡, τ𝑡; ψ, φ) ∥2 ,\n(18)\nwith the predicted next state ˆx, the state x = [q, ¤q] in the\ncase of Lagrangian formulation and the state x = [q, p] in\nthe Hamiltonian formulation. The predicted next state can be\nobtained by solving the differential equation\n\u0014 ¤q\n¥q\n\u0015\n=\n\"\n¤q\n𝜕2L(q, ¤q)\n𝜕2 ¤q\n−1 h\nτ −𝜕L(q, ¤q)\n𝜕q𝜕¤q\n¤q + 𝜕L(q, ¤q)\n𝜕q\ni\n#\n,\n\u0014 ¤q\n¤p\n\u0015\n=\n\"\n𝜕H(q,p)\n𝜕p\n−𝜕H(q,p)\n𝜕q\n+ G(q) τ\n#\n,\nusing any numerical integration approach. In the case of\nthe explicit Euler integration this approach is identical to\nthe loss of Equation (13) and Equation (17). A common\nchoice to compute the next step is the Runge Kutta 4 (RK4)\nﬁxed time step integrator (Gupta et al. 2019; Greydanus\net al. 2019). This loss formulation also enables a multi-step\nloss which has been shown to improve the performance of\nmodel predictive control for deterministic models (Lutter\net al. 2021a)\nA\nmore\nelaborate\napproach\nhas\nbeen\nproposed\nby\nSaemundsson et al. (2020) that combines discrete mechanics\nwith variational integrators. This combination guarantees\nthat even the discrete-time system conserves momentum and\nenergy. The RK4 integration might leak or add energy due\nto the discrete-time approximation. The main disadvantage\nof the variational integrator networks is that this approach\nassumes a constant mass matrix. Therefore, the Coriolis\nand centrifugal force disappear (Equation (6)) and the\nacceleration only depends on the position. Within the\ndiscrete mechanics literature, extensions exist to apply the\nvariational integrator to multi-body systems with a non-\nconstant mass matrix. However, these extensions are non-\ntrivial and involve solving a root-ﬁnding problem within each\nintegration step (Lee et al. 2020).\n4.3.3\nFeature Transformation. The previous sections\nalways used generalized coordinates or momentum to\ndescribe the system dynamics. However, this formulation\ncan be problematic as these coordinates are unknown\nor unsuitable for function approximation. For example,\ncontinuous revolute joints without angular limits are\nproblematic for function approximation due to the wrapping\nof the angle at ±𝜋. This problem is commonly mitigated\nusing sine/cosine feature transformations. Such feature\ntransformation can be included in physics-inspired networks\nif the feature transforms mapping from the generalized\ncoordinates to the features z is known and differentiable.\nThe more general problem of only observing the features and\nunknown feature transformation and generalized coordinates\nis discussed in Section 6.1.2.\nLet 𝑔be the feature transform mapping generalized\ncoordinates to the features z = 𝑔(q). For continuous revolute\nLutter and Peters\n9\njoints the feature transform g(q) = [cos q0, sin q0] avoids the\nproblems associated with wrapping the angle. In this case the\nLagrangian is described by\nL(z, ¤q; ψ, φ) = 1\n2 ¤q⊤H(z; ψ) ¤q −𝑉(z; φ).\nIn this case, one can apply the chain rule to obtain the\ngradients w.r.t. the generalized coordinates, i.e.,\n𝜕L\n𝜕q = 𝜕g\n𝜕q\n⊤𝜕L\n𝜕z .\nThis approach is identical to adding an input layer to the\nneural network with the hand-crafted transformations. The\nfeature transformation was previously introduced by Zhong\net al. (2019). However, the authors only manually derived\nthe special case for continuous angle while this approach\ncan be easily generalized to arbitrary differentiable feature\ntransformations.\n4.3.4\nActuator\nModels\nand\nFriction. The physics-\ninspired networks cannot model friction directly as the\nlearned dynamics are conservative. Incorporating friction\nwithin this model learning approach in a non-black-box\nfashion is non-trivial because friction is an abstraction to\ncombine various physical effects. For robot arms in free\nspace, the friction of the motors dominates, for mechanical\nsystems dragging along a surface the friction at the surface\ndominates while for legged locomotion the friction between\nthe feet and ﬂoor dominates but also varies with time.\nTherefore, deﬁning a general case for all types of friction in\ncompliance with the Lagrangian and Hamiltonian Mechanics\nis challenging. Various approaches to incorporate friction\nmodels analytically can be found in (Lurie 2013; Wells\n1967).\nMost existing works on physics-inspired networks only focus\non friction caused by the actuators, which dominates for\nrobot arms (Lutter and Peters 2019; Gupta et al. 2019; Lutter\net al. 2020). In this case the friction can be expressed using\ngeneralized coordinates and is a non-conservative force.\nIncorporating other types of friction than actuator friction\nis non-trivial as these cannot be easily expressed using the\ngeneralized force. In this case, one requires the contact-\npoint and contact Jacobian to map the contact-force to the\ngeneralized force. For the actuator model, the generalized\nforce required for DeLaN and HNN is expressed using an\naddition function that modulates the system input and adds\nfriction. This function is described by τ = 𝑔(q, ¤q, u) with\nthe system input u. For the actuator model, one can either\nchoose a white-box approach that uses a analytic actuator\nand friction models (Lutter and Peters 2019) or a black-\nbox approach that uses a deep network (Gupta et al. 2019;\nZhong et al. 2019). For example, a white-box model can\nadd a friction torque τ 𝑓\nto motor torque u. Therefore,\nthe generalized force is described τ = u + τ 𝑓. Within the\nliterature many friction models have been proposed (Olsson\net al. 1998; Albu-Sch¨affer 2002; Bona and Indri 2005;\nWahrburg et al. 2018). These models assume that the motor\nfriction only depends on the joint velocity ¤q𝑖of the 𝑖th-joint\nand is independent of the other joints. Common choices for\nfriction are static, viscous, stiction described by\nCoulomb Friction\nτ 𝑓= −τ𝑐,\nViscous Friction\nτ 𝑓= −ρ ⊙¤q,\nStiction\nτ 𝑓= −𝜏𝑠⊙sign ( ¤q) ⊙exp \u0000 −¤q2/𝜈\u0001,\nwith the elementwise multiplication ⊙, the Coulomb friction\nconstant τ𝑐, the viscous friction constant ρ and the stiction\nconstants τ𝑠and 𝜈. These friction models can also be\ncombined to yield the Stribeck friction described by\nτ 𝑓= −\n\u0010\n𝜏𝑐+ 𝜏𝑠⊙exp\n\u0010\n−¤q2/𝜈\n\u0011\u0011\n⊙sign ( ¤q) −d ⊙¤q.\nIt is important to note that the system is not time-reversible\nwhen stiction is added to the dynamics as multiple motor-\ntorques can generate the same joint acceleration (Ratliff et al.\n2016).\nIn contrast to these white-box approaches, Gupta et al. (2019)\nand Zhong et al. (2019) proposed to add an black-box\nactuator model. For example, Gupta et al. (2019) proposed\nto use a black-box control matrix G(q) with viscous friction\nfor DeLaN. Therefore, the actuator model is described by\nτ = G(q, ¤q; θ) u −ρ ⊙¤q,\n(19)\nwith the positive friction coefﬁcients ρ. The control matrix\nG is predicted by an additional neural network. Similarly,\nZhong et al. (2020) proposed to use a state-dependent control\nmatrix G(q) and a positive deﬁnite dissipation matrix D(q)\nfor HNN. In this case the generalized force is described by\nτ = G(q) u −D(q)\n\" 𝜕H(q,p)\n𝜕q\n𝜕H(q,p)\n𝜕p\n#\n.\nBoth matrices are predicted using a deep network. The\nnetwork parameters of the actuator model are optimized\nusing gradient descent. These black-box actuator models can\nrepresent more complex actuator dynamics and even system\ndynamics violating the assumptions of Lagrangian and\nHamiltonian Mechanics. However, this actuator model can\nalso result that the potential and kinetic energy are ignored\nand only the black-box model dominates the predicted\ndynamics. To avoid that the actuator model predicts the\ncomplete system dynamics, it is beneﬁcial to add penalties\nto the magnitude of the actuator during the optimization.\nThe existing grey-box model learning literature (Lutter et al.\n2020; Hwangbo et al. 2019; Allevato et al. 2020) has shown\nthat these penalties improve the performance.\n5\nExperiments\nIn the experiments, we apply physics-inspired deep network\nmodels to learn the non-linear dynamics of simulated\nsystems and physical systems. Within the simulation\nexperiments,\nwe\nwant\nto\ntest\nwhether\nthe\ndifferent\nphysics-inspired networks learn the underlying structure\nand highlight the empirical differences of the existing\napproaches. On the physical systems, we compare the model-\nbased control performance of DeLaN with a structured\nLagrangian for the fully-actuated and under-actuated system\nto standard system identiﬁcation techniques and black-box\n10\n(a)\n(b)\n(c)\nFigure 3. The (a) Cartpole, (b)\nFuruta pendulum and (c) Barrett\nWAM used for the evaluation.\nThe Furuta pendulum and\ncartpole perform a swing-up\nusing the energy controller. The\nBarrett WAM executes a cosine\ntrajectory with a different\nfrequency per joint.\nmodel learning. We only use DeLaN for the physical systems\nas for these systems we do not observe the momentum.\nHence, only the Lagrangian physics prior is applicable.\nOne could treat the Hamiltonian prior as a latent space\nproblem with the momentum being the latent representation.\nHowever, this approach would effectively boil down to\nthe Lagrangian prior. Using these experiments, we want to\nanswer the following questions:\nQ1: Do physics-inspired networks learn the underlying\nrepresentation of the dynamical system?\nQ2: Do physics-inspired networks perform better than\ncontinuous-time black-box models?\nQ3: Can physics-inspired networks be applied to physical\nsystems where the physics prior does not hold?\n5.1\nExperimental Setup\nTo answer these questions, we apply the different variations\nof physics-inspired models to 4 different systems and\ncompare the performance to three baselines. Within the\nexperiments, we denote the physics-inspired networks that\nonly use a single network to represent the Lagrangian or\nHamiltonian as black-box DeLaN/HNN. When two separate\nnetworks are used to represent that mass-matrix and potential\nenergy, we refer to this approach as structured DeLaN/HNN.\nThe detailed differences between both approaches are\ndescribed in section 4.3.1. For each of the experiments the\ndynamics models are learned from a ﬁxed dataset and are\ntrained until convergence. All evaluations are performed on\na test dataset that is not contained within the training dataset.\nIn the following, we brieﬂy introduce the systems and\nbaselines. The code of Deep Lagrangian Networks (DeLaN)\nand Hamiltonian Neural Networks (HNN) is available at\nhttps://github.com/milutter/deep lagrangian networks.\n5.1.1\nPlants. Within the experiments, we apply the model\nlearning techniques to a simulated two-link pendulum, the\nBarrett WAM, the cartpole, and the Furuta pendulum. For all\nphysical systems, only the joint position is directly observed.\nThe velocities and accelerations are computed using ﬁnite\ndifferences and low-pass ﬁlters. These ﬁlters are applied\nofﬂine to use zero-phase shift ﬁlters that do not cause a\nphase shift within the observations. The hyperparameters of\nDeLaN for each system are described in Table 1.\nTwo-link Pendulum. The two-link pendulum has two\ncontinuous revolute joints, is fully actuated, and acts in the\nvertical x-z plane with gravity. The pendulum is simulated\nusing Bullet (Coumans and Bai 2016).\nCartpole. The physical cartpole (Figure 3a) is an under-\nactuated system manufactured by Quanser (2018). The\npendulum is passive and the cart is voltage controlled with up\nto 500Hz. The linear actuator consists of a plastic cogwheel\ndrive with high stiction.\nFuruta Pendulum. The physical Furuta pendulum (Fig-\nure 3b) is an under-actuated system manufactured by\nQuanser (2018). Instead of the linear actuator of the cartpole,\nthe Furuta pendulum has an actuated revolute joint and a\npassive pendulum. The revolute joint is voltage controlled\nwith up to 500Hz. The main challenge with this system\nis the small masses and length scale of the system. These\ncharacteristics yield a very sensitive control system.\nBarrett WAM. The Barrett WAM (Figure 3c) consists\nof four actuated degrees of freedom controlled via torque\ncontrol with 500Hz. The actuators are back-driveable and\nconsist of cable drives with low gear ratios enabling fast\naccelerations. The joint angles sensing is on the motor-\nside. Therefore, any deviation between the motor position\nand joint position due to the slack of the cables cannot be\nobserved. We only use the 4 degree of freedom version as\nTable 1. The hyperparameters of DeLaN used for the different dynamical systems. All physical system have a ﬁxed sampling time of 2.0ms. The\nnumber of training samples for the 2-DoF robot differs by dataset. See table 2 for more details about the different datasets.\n2-DoF Robot\nCartpole\nFuruta Pendulum\nBarrett WAM\nTotal DoF / Actuated DoF\n2 / 2\n2 / 1\n2 / 1\n4 / 4\nNumber of Training Samples\n2500 & 105\n105 / ≈200s\n105 / ≈200s\n105 / ≈200s\nNetwork Dimension\n[2 x 64]\n[2 x 256]\n[2 x 128]\n[2 x 128]\nActivation\nTanh\nSoftPlus\nSoftPlus\nSoftPlus\nBatch Size\n512\n1024\n1024\n1024\nLearning Rate\n10−4\n10−4\n10−4\n10−4\nWeight Decay\n10−5\n10−5\n10−5\n10−5\nOptimizer\nADAM\nADAM\nADAM\nADAM\nLutter and Peters\n11\ne\nv\nq\n0\n2\n4\nTorque [Nm]\nJoint 0\nTorque τ\ne\nv\nq\n−2\n0\nTorque [Nm]\nJoint 1\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\nError\n(a)\ne\nv\nq\n−2\n0\n2\nTorque [Nm]\nInertial Torque τ I = H(q)¨q\ne\nv\nq\n−2\n0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(b)\ne\nv\nq\n0.0\n0.5\nTorque [Nm]\nCoriolis Torque τ c = c(q, ˙q)\ne\nv\nq\n0.0\n0.5\n1.0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(c)\ne\nv\nq\n0\n1\n2\n3\nTorque [Nm]\nGravitational Torque τ c = ∂V (q)/∂q\ne\nv\nq\n−0.5\n0.0\n0.5\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 4. (a) The learned inverse model using the character dataset averaged over 10 seeds. The test character ’e’, ’v’, ’q’ are not\ncontained within the training set. The remaining columns show predicted force decomposition. (b) plots the inertial force H ¥q, (c) the\nCoriolis and Centrifugal forces 𝑐(q, ¤q) and (d) the gravitational force 𝑔(q). All physics-inspired networks learn a good inverse model\nthat obtains a lower MSE than the feed-forward network. The Lagrangian approaches learn a better force decomposition than the\nHamiltonian approach. This improved performance is especially visible for the inertial, centrifugal, and Coriolis torque.\nthe wrist and end-effector joints cannot be excited due to the\nlimited range of motion and acceleration.\n5.1.2\nBaselines. We use the analytic dynamics model,\nsystem identiﬁcation, and a feed-forward deep network as\nbaselines.\nAnalytic Model. The analytic model uses the equation of\nmotion derived using rigid body dynamics and the system\nparameters, i.e., masses, center of gravity, and inertias,\nprovided by the manufacturer. In addition to the rigid\nbody dynamics, these models are augmented with a viscous\nfriction model.\nSystem Identiﬁcation. This approach requires the knowl-\nedge of the analytic equations of motions and infers the\nsystem parameters from data. More speciﬁcally we use the\ntechnique described by Atkeson et al. (1986). This approach\nshowed that for rigid body kinematic trees the inverse\ndynamics model is a linear model described by\nτ = A(q, ¤q, ¥q) θ,\n(20)\nwith the with hand-crafted features A(·) derived from the\nkinematics and the system parameters θ. As the inverse\ndynamics are a linear model, the system parameters can be\nobtained using linear regression. We additionally penalize\ndeviations from the parameters nominal parameters provided\nby the manufacturer. In this case the optimal parameters\ninferred from data are obtained by\nθ∗= θ0 +\n\u0010\nA⊤A + 𝜆2I\n\u0011−1\nA⊤\u0010\nτ −Aθ0\n\u0011\n,\n(21)\nwith the nominal parameters θ0 and the regularization\nconstant 𝜆. The resulting system parameters might not be\nphysically plausible as the individual elements of θ have\nadditional constraints (Ting et al. 2006). For example the\nmasses have to be positive and the inertias have to adhere\nto the parallel axis theorem.\nFeed-Forward Network. The deep network baseline uses\ntwo separate networks, where one describes the forward\ndynamics and the other the inverse dynamics. This model\ndoes not necessarily generate coherent predictions as the\nparameters of the forward and inverse model are decoupled.\nTherefore, it is not guaranteed that 𝑓( 𝑓−1 (x)) = x holds.\nThe forward model is a continuous-time model and predicts\nthe joint acceleration\n¥q. Therefore, the deep network\nbaseline is independent of the sampling frequency and\nuses an explicit integrator as the physics-inspired network.\nThe network parameters are learned by minimizing the\nnormalized squared error of the forward and inverse model.\nThis optimization problem is solved by gradient descent\nusing ADAM. This baseline cannot be applied to the energy\nexperiments, as the system energy cannot be learned by a\nstandard deep network.\n5.2\nModel Prediction Experiments\nFor the simulated experiments, we want to evaluate whether\nthe physics-inspired networks can learn the underlying\nsystem dynamics and recover the structure with ideal\nobservations. Therefore, we want to observe the data ﬁt and\nas well as the long-term forward predictions. Furthermore,\nwe want to differentiate between two separate datasets,\n(1) a large data set with 100k samples spanning the state\ndomain uniformly and (2) a small dataset with only 2.5k\nsamples which consist of trajectories of drawing characters.\nFor the character test dataset, the test set contains different\ncharacters than the training set. This dataset only spans a\nsmall sub-domain of the state space. The character dataset\nwas initially introduced by Williams et al. (2008) and is\navailable in the UCI Machine Learning Repository (Dheeru\nand Karra Taniskidou 2017). For training, the datasets are\nsplit into a test and training set. The reported results are\nreported on the test set and averaged over 5 seeds.\n5.2.1\nInverse Model. The results of the inverse model\nare summarized in Table 2 and visualized in Figure 4. All\nmodels learn a good inverse model that ﬁts the test set.\nWhen comparing the performance across the large and small\ndatasets one cannot observe a difference in performance. All\nmodels perform comparably for the small and large datasets.\nOn average, the physics-inspired networks obtain a lower\nMSE than the black-box deep network. When comparing\n12\nTest 0\nTest 1\n−6\n−4\n−2\n0\nq0 [Rad]\nJoint 0\nGeneralized Position q\nTest 0\nTest 1\n−10\n0\n10\nq1 [Rad]\nJoint 1\nTest 0\nTest 1\n10−5\n10−2\n101\nPosition Error\nError\n(a)\nTest 0\nTest 1\n−5\n0\n5\n˙q0 [Rad/s]\nGeneralized Velocity ˙q\nTest 0\nTest 1\n−10\n0\n10\n˙q1 [Rad/s]\nTest 0\nTest 1\n10−5\n10−2\n101\nVelocity Error\n(b)\nTest 0\nTest 1\n−5.0\n−2.5\n0.0\n2.5\np0\nGeneralized Momentum p\nTest 0\nTest 1\n−2\n0\n2\np1\nTest 0\nTest 1\n10−5\n10−2\n101\nImpulse Error\n(c)\nTest 0\nTest 1\n−0.010\n−0.005\n0.000\n0.005\n0.010\nH\nNormalized Energy H\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 5. The model rollouts of (a) the position, (b) velocity and (c) momentum, and (d) energy of the forward models for two test\ntrajectories of the uniform dataset averaged over 10 seeds. The structured physics-inspired networks perform the best compared to\nthe standard feed-forward network and the black-box counterparts. Especially the rollout of the black-box Lagrangian commonly\ndiverges as the Hessian of the Lagrangian, which is required for computing the acceleration, becomes close to singular. This nearly\nsingular Hessian causes exploding velocities and consequently also divergence of the estimated momentum computed via H ¤q. In\nthe appendix we provide additional plots with only one model per ﬁgure to enable an in-depth comparison of the error-bounds.\nthe structured Lagrangian / Hamiltonian to the black-box\ncounterparts no clear difference is observable for the inverse\nmodel.\nWhen comparing the torque decomposition of the inertial,\ncentrifugal, Coriolis, and gravitational forces, all models\nlearn a good decomposition. For the unstructured models,\nthis decomposition can be evaluated by assuming the\nunderlying structure and evaluating the inverse model. For\nexample, the gravitational component by evaluating τ𝑔=\n𝑓−1(q, 0, 0). All models learn the underlying structure\nthat ﬁts the true decomposition. Even the black-box feed-\nforward network obtains a good decomposition despite\nhaving no structure. When comparing the MSE error in\nTable 2, the MSE for the physics-inspired networks is better\nthan the black-box feed-forward network. This difference\nis especially pronounced for the inertial and Coriolis\ntorque. The difference in the gravitational torque is not so\nlarge. When comparing the decomposition of the black-box\nLagrangian / Hamiltonian to the structured counterparts, the\nstructured approach outperforms the black-box approach on\nthe inertial and Coriolis torque.\n5.2.2\nForward Model. The results of the forward model\nare summarized in Table 2 and visualized in Figure 5. Also\nfor the forward model, the physics-inspired networks obtain\na better performance on the state error than the feed-forward\nnetwork. All models perform better on the small character\ndataset than on the large dataset as the state domain is much\nsmaller than the uniform domain of the large dataset. For\nthe large dataset, the black-box Lagrangian / Hamiltonian\napproaches are much worse compared to the structured\ncounterparts. This is especially visible for the black-box\nLagrangian. The average error and variance is so large\nbecause the mass matrix becomes nearly singular for some\nsamples. The nearly singular mass matrix ampliﬁes small\ndifferences yielding a very large error.\nTo compare the long-term predictions of the models, we\ncompare the valid prediction time (VPT) (Botev et al. 2021),\nwhich is deﬁned as the duration until the predicted rollout\nhas a larger error than a pre-deﬁned threshold. We deﬁne the\nthreshold of the MSE to be 1e−2, which corresponds to an\nangular error of ≈5 degrees. The long-term prediction of\nTable 2. The normalized mean squared error (nmse) and mean valid prediction time (VPT) as well as the corresponding\nconﬁdence interval averaged over 10 seeds. On average the structured Hamiltonian and Lagrangian approaches obtain better\nforward and inverse models than the black-box counterparts and the standard feed forward neural network. When observing the\ncorresponding phase space coordinates, the Hamiltonian and Lagrangian approaches perform comparable.\nInverse Model\nForward Model\nUniform Data - # Samples = 100, 000\nTorque - τ\nInertial Torque τI\nCoriolis Torque τc\nGravitational Torque τ𝑔\nState Error ¤x\nVPT [s]\nDeLaN\nStructured Lagrangian\n2.2e−7 ± 3.2e−6\n2.9e−9 ± 4.5e−8\n2.5e−8 ± 3.0e−7\n1.0e−8 ± 3.2e−8\n3.9e−5 ± 5.9e−4\n5.64s ± 1.78s\nDeLaN\nBlack-Box Lagrangian\n2.1e−4 ± 4.9e−3\n4.0e−9 ± 2.1e−8\n1.9e−5 ± 3.9e−4\n3.0e−8 ± 7.2e−8\n2.1e+1 ± 1.9e+3\n3.59s ± 2.18s\nHNN\nStructured Hamiltonian\n4.6e−7 ± 1.9e−6\n4.6e−9 ± 2.8e−8\n8.1e−8 ± 5.3e−7\n3.5e−8 ± 8.3e−8\n1.1e−4 ± 4.4e−4\n5.09s ± 1.91s\nHNN\nBlack-Box Hamiltonian\n3.3e−5 ± 5.5e−4\n9.9e−6 ± 6.0e−5\n3.3e−5 ± 3.1e−4\n5.9e−8 ± 1.4e−7\n2.0e−2 ± 3.1e−1\n3.80s ± 1.72s\nFF-NN\nFeed Forward Network\n5.8e−5 ± 1.0e−3\n2.3e−7 ± 1.5e−6\n9.9e−6 ± 1.4e−4\n2.9e−7 ± 7.4e−7\n6.1e−3 ± 1.1e−1\n2.52s ± 0.56s\nCharacter Data - # Samples = 2500\nDeLaN\nStructured Lagrangian\n7.7e−8 ± 2.1e−7\n2.0e−7 ± 1.7e−6\n1.1e−6 ± 5.2e−6\n2.0e−7 ± 1.0e−6\n3.5e−5 ± 1.1e−4\n2.32s ± 0.37s\nDeLaN\nBlack-Box Lagrangian\n9.9e−8 ± 4.4e−7\n9.4e−8 ± 4.7e−7\n1.7e−6 ± 1.2e−5\n1.3e−7 ± 1.1e−6\n4.3e−5 ± 1.7e−4\n2.76s ± 0.68s\nHNN\nStructured Hamiltonian\n1.8e−8 ± 5.5e−8\n1.5e−8 ± 9.1e−8\n5.5e−7 ± 1.9e−6\n2.5e−8 ± 7.0e−8\n1.5e−5 ± 3.6e−5\n2.90s ± 0.68s\nHNN\nBlack-Box Hamiltonian\n5.5e−8 ± 1.8e−7\n5.0e−5 ± 2.7e−4\n7.2e−4 ± 4.3e−3\n8.4e−8 ± 2.7e−7\n6.1e−5 ± 1.6e−4\n2.19s ± 0.62s\nFF-NN\nFeed Forward Network\n2.2e−6 ± 9.1e−6\n4.2e−6 ± 2.5e−5\n5.5e−5 ± 3.2e−4\n9.2e−7 ± 5.1e−6\n6.5e−4 ± 3.0e−3\n1.81s ± 0.49s\nLutter and Peters\n13\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10°3\n10°2\n10°1\n100\n101\n102\n103\nMSE\n(a)\nTest Data\nSL Barrett WAM - Cosine 0\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10°3\n10°2\n10°1\n100\n101\n102\n103\nMSE\n(b)\nTest Data\nSL Barrett WAM - Cosine 1\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10°3\n10°2\n10°1\n100\n101\n102\n103\nMSE\n(c)\nTest Data\nBarrett WAM - Cosine 0\n1\n1.25\n1.5\n1.75\n2\nVelocity Scale\n10°3\n10°2\n10°1\n100\n101\n102\n103\nMSE\n(d)\nTest Data\nBarrett WAM - Cosine 1\nSI\nDeLaN\nFF-NN\nRNE\nDeLaN\nDeep Network (FF-NN)\nSystem Identification\nAnalytic Model\nFigure 6. (a, b) The mean squared tracking error of the inverse dynamics control following cosine trajectories for the simulated\nBarrett WAM. (c, d) the mean squared tracking error on the physical Barrett WAM. The system identiﬁcation approach, feed-forward\nneural network, and DeLaN are trained ofﬂine using only the trajectories at a velocity scale of 1×. Afterward, the models are tested\non the same trajectories with increased velocities to evaluate the extrapolation to new velocities.\nthe physics-inspired networks is better than the prediction\ntime of the feed-forward network on both datasets (Table\n2). Furthermore, the structured variants of DeLaN and HNN\nperform better than the black-box approaches. The problem\nof the nearly singular mass matrix can be observed in\nFigure 5 for the black-box Lagrangian. For one test trajectory\nand some seeds, the near singular mass matrix lets the\ntrajectory diverge. For the structured HNN and DeLaN this\ndivergence is not observed. Furthermore, the momentum\nprediction of the black-box DeLaN variant shows the worse\naccuracy of the network Hessian corresponding to the mass\nmatrix. The predicted momentum of this approach has a\nmuch higher variance.\n5.2.3\nConclusion. The simulated experiments show that\nthe physics-inspired networks learn the underlying structure\nof the dynamical system. These models can accurately\npredict the force decomposition, momentum, and system\nenergy. Furthermore, the physics-inspired models can learn\nbetter forward and inverse models than a standard feed-\nforward deep network. The structured DeLaN and HNN\nperform better than the black-box counterparts. The forward\nand inverse model of the structured DeLaN and HNN do\nnot show any empirical differences when the corresponding\nphase space coordinates are observed.\n5.3\nModel-Based Control Experiments\nWith the experiments on the physical system, we want to\nevaluate the control performance of the learned models with\nnoisy real-world data. Evaluating the control performance\nrather than the MSE on static datasets is the more relevant\nperformance measure as the application of the models is\ncontrol. Furthermore, it has been shown that the MSE is\nnot a good substitute to predict the control performance of a\nlearned model and commonly overestimates the performance\n(Hobbs and Hepenstal 1989; Lambert et al. 2020; Lutter et al.\n2021a). To evaluate the model performance for control, we\napply the learned models to inverse dynamics control and\nenergy control. We only apply DeLaN with the structured\nLagrangian to the physical systems as the potentially singular\nmass matrix risks damaging the physical system. HNN do\nnot apply to the system as the momentum cannot be retrieved\nfrom the position observations while the velocity can be\nobtained using ﬁnite differences.\n5.3.1\nInverse Dynamics Control. Evaluating learned\nmodels by comparing the tracking error of a model-based\ncontrol law has been a well-established benchmark for\nevaluating the control performance of models (Nguyen-\nTuong et al. 2008, 2009). In this experiment, we use\ninverse dynamics control as a model-based control law.\nThis feedback controller augments the PD-control law with\nan additional feed-forward torque to compensate for the\nnon-linear dynamics of the system. Therefore, the inverse\ndynamics control obtains a better tracking error than the\nstandard PD control. The resulting control law is described\nby\nτ = K𝑝(qdes −q) + K𝐷( ¤qdes −¤q) + 𝑓−1(qdes, ¤qdes, ¥qdes),\nwith the position and derivative gains K𝑝and K𝑑. In\naddition, we test the generalization of the learned models\nby increasing the velocity of the test trajectories. One\nwould expect that DeLaN would generalize better to scaled\nvelocities as the predicted mass matrix and potential energy\nonly depend on the joint position and are independent of\nthe velocity. The training and testing sequences consist of\ncosine trajectories with different frequencies for each joint\nand include a little chirp to avoid learning the Fourier basis.\nThe test and train data differ in the frequency of each joint.\nThese trajectories are the standard approach to excite the\nsystem and cover a large state domain. The analytic model\nof the Barrett WAM is obtained from the JHU LCSR (2018).\nThe results for the simulated and physical Barrett WAM\nare summarized in Figure 6. In the simulation, DeLaN\nand the system identiﬁcation perform equally well on\nthe training velocity. When comparing generalization,\nthe system identiﬁcation approach generalizes better than\nDeLaN to higher velocities. This behavior is expected as\nsystem identiﬁcation obtains the global system parameter\nwhile DeLaN only learns a local approximation of the\nmass matrix and potential energy. In comparison to the\nfeed-forward deep network, DeLaN performs worse on the\ntraining velocity but generalizes better to higher velocities.\nTherefore, the deep network overﬁts to the training velocity.\nThe analytic model and the system identiﬁcation have a large\nperformance gap in simulation as we use the same analytic\nmodel for simulation and the physical system but the analytic\nmodel is optimized for the physical system.\n14\n(c) Simulated Furuta Pendulum\n°º\n°º/2\n0\n+º/2\n+º\nµ [rad]\n°15.0\n°10.0\n°5.0\n+0.0\n+5.0\n+10.0\n+15.0\n˙µ [rad/s]\n(a) Simulated Cartpole\nAnalytical Model\n°15.0\n°10.0\n°5.0\n+0.0\n+5.0\n+10.0\n+15.0\n˙µ [rad/s]\nSystem Identiﬁcation\n°3.0\n°2.0\n°1.0\n+0.0\n+1.0\n+2.0\n+3.0\nµ [rad]\n°15.0\n°10.0\n°5.0\n+0.0\n+5.0\n+10.0\n+15.0\n˙µ [rad/s]\nDeLaN\n(b) Physical Cartpole\n°3.0\n°2.0\n°1.0\n+0.0\n+1.0\n+2.0\n+3.0\nµ [rad]\n(d) Physical Furuta Pendulum\n°º\n°º/2\n0\n+º/2\n+º\nµ [rad]\nManufacturer / Ground Truth\nSystem Identiﬁcation\nDeLaN 4EC\nManufacturer / Ground Truth\nSystem Identiﬁcation\nDeLaN\nFigure 7. The position 𝜃and velocity ¤𝜃orbits recorded using energy control to swing up the cartpole and Furuta pendulum. The\nrows show the different models, i.e., the analytic model, the system identiﬁcation model, and the DeLaN model while the columns\nshow the different simulated and physical systems. The dashed orbit highlights the desired energy 𝐸∗. While the learned and the\nanalytic model can swing up the simulated system and physical Cartpole only the analytic model and DeLaN can swing up the\nphysical Furuta pendulum, while the energy controller using the System Identiﬁcation model cannot.\nOn the physical system, the feed-forward network performs\nthe best on the training domain but deteriorates when\nthe velocity is increased. DeLaN performs worse than the\ndeep network but better than the analytic model and the\nsystem identiﬁcation. The analytic model and the system\nidentiﬁcation model perform nearly identical. The system\nidentiﬁcation approach is only marginally better. Both\napproaches generalize better compared to DeLaN and the\ndeep network. This better generalization is expected as the\nsystem parameters are global while the other approaches\nuse local approximations. When increasing the velocity,\nDeLaN and deep network dynamics model degrade in\nperformance. In contrast to the simulation results, where\nDeLaN extrapolates better than the deep network, the black-\nbox deep network obtains the better generalization on the\nphysical system. The worse performance and generalization\nof DeLaN on this physical system can be explained by the\nassumption of rigid body dynamics. This assumption is not\nfulﬁlled due to the cable drives and the motor-side sensing.\nTherefore, DeLaN cannot model every phenomenon with\nhigh ﬁdelity. However, DeLaN learns a good approximation\nthat is better than the system identiﬁcation approach with the\nsame rigid body assumption.\n5.3.2\nEnergy Control Control. A different approach to\ntest the control performance of the learned models is to apply\nthe learned models to controlling under-actuated systems\nusing an energy controller. More speciﬁcally we apply an\nenergy controller to swing up the Furuta pendulum and the\ncartpole. This energy controller regulates the system energy\nrather than the position and velocities. The control law is\ndescribed by\nu = 𝑘𝐸\n\u0002\n𝐸(q, ¤q) −𝐸(qdes, ¤qdes)\n\u0003\nsign \u0000 ¤q1 cos(q1)\u0001 −𝑘𝑝q1,\nwith the energy gain 𝑘𝐸and position gain 𝑘𝑝. We use an\nadditional position controller to prevent the system from\nhitting the joint limits. The control gains are tuned w.r.t. to\nthe analytic model and ﬁxed for all models. This control\ntask is challenging as the control law relies on the system\nenergy, which cannot be learned supervised. Therefore, the\nfeed-forward network baseline cannot be applied to this\ntask. In contrast to the feed-forward network, the physics-\ninspired deep network models are the ﬁrst network models\nthat can be applied to this task as these models can infer the\nsystem energy. For the training dataset, we use the energy\ncontroller to swing-up the pendulum, stabilize the pendulum\nat the top and let the pendulum fall down after 2s. Once the\npendulum settles the process repeated until about 200s of\ndata is collected.\nThe results for the simulated and physical experiments\nare summarized in Figure 7. Videos of the physical\nexperiments are available at [Link]. Within the simulation,\nthe analytic model, the system identiﬁcation model, and\nDeLaN achieve the successful swing-up of the cartpole and\nFuruta pendulum. On the physical cartpole, all approaches\nachieve the swing-up despite the large stiction of the\nlinear actuator. For the physical Furuta pendulum, only the\nLutter and Peters\n15\nanalytic model and DeLaN achieve the swing-up. The system\nidentiﬁcation model does not. The system identiﬁcation\nmodel fails as the linear regression is very sensitive to the\nobservation noise and the small condition number of the\nfeatures A due to the small dimensions. Therefore, minor\nchanges in the observation can lead to vastly different system\nparameters. In this speciﬁc case, the system identiﬁcation\napproach underestimates the masses and hence, exerts too\nlittle action to swing up the pendulum and is stuck on the\nlimit cycle.\n5.3.3\nConclusion. The non-linear control experiments on\nthe physical systems show that DeLaN with a structured\nLagrangian can learn a good model despite the noisy\nobservations. The resulting model can be used for closed-\nloop feedback control in real-time for fully-actuated and\nunder-actuated systems. For both systems categories DeLaN\nachieves a good control performance. It is noteworthy that\nDeLaN is the ﬁrst model learning approach utilizing no prior\nknowledge of the equations of motion that can be applied\nto energy control. The previous black-box model learning\napproach could not be applied as the system energy can only\nbe learned unsupervised.\n6\nConclusion\nComing back to the initial questions of the experiments. The\nexperimental results have showed that\nQ1: physics-inspired networks can learn the underlying\nrepresentation of the dynamical system unsupervised. The\npredicted inertial, centrifugal, Coriolis and gravitational\nforces match the ground-truth (Fig 4). On the physical\nsystems the learned system energy can be used for energy\ncontrol. The swing-up of under-actuated Furuta pendulum\nand cartpole where successfully achieved.\nQ2: physics-inspired networks may learn better models\nthan continuous-time black-box models with feed-forward\nnetworks. Especially, in simulation the physics-inspired\nnetworks achieve lower mean squared error (Fig. 5), longer\nvalid prediction times (Table 2) and better generalization\n(Fig. 6). On the physical system, when the assumptions\nof the physics-inspired networks are violated, the results\nare not as clear. While DeLaN performs comparable to\nsystem identiﬁcation techniques, the deep network model\ncan represent physical phenomena that are not captured in\nthe physics prior and achieves a lower tracking error.\nQ3: physics-inspired networks can be applied to physical\nsystems. Even though the physical systems violate the\nphysics prior due to non-ideal torque sources and unmodeled\nphenomena such as cable drives, motor dynamics and\nbackslash, DeLaN was able to learn the system energy. For\nexample, the energy controller utilizing DeLaN was able to\nsolve the swing-up the Furuta pendulum and the cartpole,\nwhich has large backslash in the linear actuator.\nSimilar empirical results were also presented by (Greydanus\net al. 2019; Cranmer et al. 2020; Gupta et al. 2019,\n2020; Saemundsson et al. 2020; Zhong et al. 2019, 2020).\nWhen comparing the different physics prior, Hamiltonian\nand Lagrangian priors yield comparable models when\nthe corresponding phase space coordinates are observed,\ni.e., velocities for DeLaN and impulse for HNN. When\ncomparing structured DeLaN and HNN to the black-box\nDeLaN and HNN, we ﬁnd that the structured approaches\nachieve better dynamics models (Table 2). The black-box\nvariants struggle to obtain non-singular network Hessians\nfor all possible system states. For the structured approaches\nsingular Hessians can be prevented by parametrized the\nkinetic energy such that the eigenvalues of the Hessian are\nlower-bounded and do not become singular.\nDespite the advantages of the physics-inspired models\nto standard deep networks models, the physics-inspired\napproaches\nhave\ndrawbacks\nthat\nprevent\nthe\ngeneral\napplicability compared to feed-forward networks. In the\nfollowing, we discuss these limitations.\n6.1\nOpen Challenges\nPhysics-inspired deep networks have two main shortcom-\nings, which have not been solved yet. First of all, the\ncurrent approaches are only able to simulate articulated rigid-\nbodies without contact and second the current approaches\nrely on knowing and observing the generalized coordinates.\nTherefore, most of the existing work only showcased these\nnetworks for simple n-link pendulums (Zhong et al. 2021)\nand n-body problems (Sanchez-Gonzalez et al. 2019). For\nmost real-world robotic tasks these assumptions are not full-\nﬁlled. One frequently does not know or observe the system\nstate and most interesting robotic tasks include contacts. In\ncontrast to physics-inspired networks, black-box dynamics\nmodels work with any observations and contacts. These\nmodels have been extensively used for model predictive\ncontrol and are sufﬁcient for complex control tasks (Hafner\net al. 2019a,b; Lutter et al. 2021a). Therefore, these chal-\nlenges need to be addressed to enable the widespread use of\nphysics-inspired methods for robot control. In the following,\nwe highlight the challenges of both limitation and the initial\nstep towards applying these models to contact-rich tasks with\narbitrary observations.\n6.1.1\nContacts. Analytically,\ncontact\nforces\ncan\nbe\nincorporated by adding generalized contact forces to the\nEuler-Lagrange equation. In this case the differential\nequation is described by\n𝑑\n𝑑𝑡\n𝜕L(q, ¤q)\n𝜕¤q\n−𝜕L(q, ¤q)\n𝜕q\n= τ +\n∑︁\n𝑖∈Ω\nJ 𝑐\n𝑖(q)f 𝑐\n𝑖(q, ¤q)\n|                  {z                  }\nGeneralized Contact Force\n,\nwith the Cartesian contact forces f 𝑐, the contact Jacobian J 𝑐\nconnecting the Cartesian forces at the contact point to\nthe generalized coordinates and the set of all active\ncontacts Ω. To compute the generalized contact force,\nanalytic simulators ﬁrst use the known kinematics and\nmeshes to ﬁnd all contact points and there respective\nJacobians. Afterwards the contact force is computed by\nsolving the linear complementarity problem (LCP). A similar\napproach can also be used for Hamiltonian mechanics that\nuses contact impulses rather than forces. Within the physics-\ninspired deep network literature only Hochlehnert et al.\n(2021) and Zhong et al. (2021) have included contacts.\n16\nHowever, both existing works only consider special cases\nwith strong assumptions. For example, Hochlehnert et al.\n(2021) only considers elastic collisions of simple geometric\nshapes, i.e., circles. In this case, the contact forces can be\ncomputed and the contact Jacobian is the identity matrix.\nTherefore, one only needs to learn an indicator function 𝟙(q)\nbeing 1 if the contact is active and 0 otherwise. Furthermore,\nthe indicator function is learned supervised. Hence, the\ntraining data has to include whether the contact was active\nor not for each sample. The experiments only apply the\nproposed algorithm to a ball bouncing on a plane and the\nNewton cradle.\nA different approach was proposed by Zhong et al.\n(2021). This work augments the physics-inspired network\nwith a differentiable physics simulator to handle the\ncontacts. In this case, a collision detection algorithm\ndetermines all active contacts and the contact Jacobians.\nThe contact forces are computed by solving the LCP.\nIn this case, only the coefﬁcients of the contact model,\ne.g.,\nfriction\nand\nrestitution,\nare\nlearned\nfrom\ndata.\nTherefore, this approach is similar to the white-box friction\nmodels described in Section 4.3.4. This approach also\nimplicitly assumes that the meshes and kinematics are\nknown. Without the kinematics and meshes the collision\ndetection algorithms cannot compute the active contacts and\nJacobians. If these quantities of the system are known, the\nanalytic equations of motions can be computed and many\nphysical parameters can be approximated from the meshes.\nTherefore, these assumptions are identical to the required\nknowledge for system identiﬁcation using differentiable\nphysics simulators (Werling et al. 2021; Degrave et al.\n2019; Heiden et al. 2021). The advantage of physics-\ninspired networks compared to system identiﬁcation with\ndifferentiable simulators are unknown. The experiments only\napplied the proposed approach to bouncing disks and a multi-\nlink pendulum with a ground plane.\nTo summarize, no general way to add contacts to physics-\ninspired networks has been proposed and shown to work for\nmulti-contact physics with complex geometries. The naive\napproach to add a single network to model the generalized\ncontact forces is challenging as this reduces the physics-\ninspired model learning approaches to a black-box model\nlearning technique without proper regularization. Therefore,\nan important open challenge for physics-inspired networks\nfor robotics is to introduce a generic approach to include\nmultiple contacts.\n6.1.2\nGeneralized Coordinates. The second limiting\nassumption is the observation of the generalized coordi-\nnates q, ¤q or the generalized momentum p. For most robotic\nsystems that do not only involve a rigid body manipulator,\nthese coordinates are commonly not observed or known.\nOne usually only obtains observations derived from the\ngeneralized coordinates if the system is fully observed. In\nmany cases, the system is only partially observed and one\ncannot infer the system state from a single observation. For\nblack-box models this is not a problem as these models do\nnot require speciﬁc observations and have been shown to\nlearn good dynamics models for complex systems using only\nimages, e.g., Hafner et al. (2019a,b, 2020) and many others.\nTo overcome this limitation, existing work combined\nphysics-inspired networks with variational autoencoders\n(VAE) to learn a latent space the resembles the generalized\ncoordinates. In this case, the Lagrangian and Hamiltonian\ninspired networks are applied in the latent space. Using\nthis approach, the dynamics of single-link pendulums\nand N-body problems have been learned from artiﬁcial\nimages (Greydanus et al. 2019; Zhong et al. 2019; Toth\net al. 2019; Saemundsson et al. 2020; Allen-Blanchette\net al. 2020). However, these approaches have not been\ndemonstrated on more complex systems and realistic\nrendering of systems. Botev et al. (2021) also showed that\nthis approach does not necessarily obtain better results than\nusing a normal deep network continuous-time model within\nthe latent space. Therefore, it remains an important open\nchallenge to extend physics-inspired networks to arbitrary\nobservations. The main challenge is to learn a latent space\nthat resembles the generalized coordinates and the naive\napproach to use a VAE does not seem to be sufﬁcient.\n6.2\nSummary\nWe introduced physics-inspired networks that combine\nLagrangian and Hamiltonian mechanics with deep networks.\nThis combination obtains physically plausible dynamics\nmodels that guarantee to conserve energy. The resulting\nmodels are also interpretable and can be used as forward,\ninverse, or energy models using the same parameters.\nPreviously this was not possible with standard deep network\ndynamics models. Furthermore, we presented all the existing\nextensions of physics-inspired networks which include\ndifferent representations of the Hamiltonian and Lagrangian,\ndifferent loss functions as well as different actuation and\nfriction models. We elaborated on the shortcomings of\nthe current approaches as these techniques are limited\nto mechanical systems without contacts and require the\nobservation of generalized positions, velocity, momentum,\nand forces. Therefore, this summary provides the big picture\nof physics-inspired networks for learning continuous-time\ndynamics models of rigid body systems.\nWithin the experiments, we showed that Deep Lagrangian\nNetworks (DeLaN) and Hamiltonian Neural Networks\n(HNN) learn the underlying structure of the dynamical\nsystem for simulated and physical systems. When the\ncorresponding phase-space coordinates of each model\nare observed, both models perform nearly identical. On\naverage the structured Hamiltonian and Lagrangian perform\nbetter than their black-box counterparts. Especially for the\nLagrangian combination, the black-box approach can lead to\nhigh prediction errors due to inverting the Hessian of a deep\nnetwork. Furthermore, we show that these physics-inspired\ntechniques can be applied to the physical system despite\nthe observation noise. The resulting DeLaN models can be\nused for real-time control and achieve good performance\nfor inverse dynamics control as well as energy control.\nEspecially the latter is noteworthy, as DeLaN is the ﬁrst\nmodel learning technique that utilizes deep networks and can\nlearn the system energy. Previously this was only possible\nusing system identiﬁcation which requires knowledge of the\nkinematic structure to derive the equations of motion.\nLutter and Peters\n17\nAcknowledgments\nThis project has received funding from ABB and NVIDIA.\nFurthermore, we want to thank the open-source projects\nNumPy (Harris et al. 2020), PyTorch (Paszke et al. 2019)\nand JAX (Bradbury et al. 2018).\nReferences\nAkkaya I, Andrychowicz M, Chociej M, Litwin M, McGrew B,\nPetron A, Paino A, Plappert M, Powell G, Ribas R et al.\n(2019) Solving rubik’s cube with a robot hand. arXiv preprint\narXiv:1910.07113 .\nAlbu-Sch¨affer A (2002) Regelung von Robotern mit elastischen\nGelenken am Beispiel der DLR-Leichtbauarme. PhD Thesis,\nTechnische Universit¨at M¨unchen.\nAllen-Blanchette C, Veer S, Majumdar A and Leonard NE (2020)\nLagnetvip: A Lagrangian neural network for video prediction.\narXiv preprint arXiv:2010.12932 .\nAllevato A, Short ES, Pryor M and Thomaz A (2020) Tunenet: One-\nshot residual tuning for system identiﬁcation and sim-to-real\nrobot task transfer. In: Conference on Robot Learning (CoRL).\nAnderson B, Hy TS and Kondor R (2019) Cormorant: Covariant\nmolecular neural networks. Advances in neural information\nprocessing systems (NeuRIPS) .\nAtkeson CG, An CH and Hollerbach JM (1986) Estimation of\ninertial parameters of manipulator loads and links.\nThe\nInternational Journal of Robotics Research .\nBekkers EJ (2019) B-spline CNNs on Lie groups. International\nConference on Learning Representations (ICLR) .\nBona B and Indri M (2005) Friction compensation in robotics:\nan overview. In: IEEE Conference on Decision and Control\n(CDC).\nBook WJ (1984) Recursive lagrangian dynamics of ﬂexible\nmanipulator arms.\nThe International Journal of Robotics\nResearch .\nBotev A, Jaegle A, Wirnsberger P, Hennes D and Higgins I (2021)\nWhich priors matter? benchmarking models for learning latent\ndynamics. Neural Information Processing Systems Track on\nDatasets and Benchmarks .\nBradbury J, Frostig R, Hawkins P, Johnson MJ, Leary C, Maclaurin\nD, Necula G, Paszke A, VanderPlas J, Wanderman-Milne S\nand Zhang Q (2018) JAX: composable transformations of\nPython+NumPy programs. URL http://github.com/google/jax.\nCalinon S, D’halluin F, Sauser EL, Caldwell DG and Billard AG\n(2010) Learning and reproduction of gestures by imitation.\nIEEE Robotics & Automation Magazine .\nCamacho EF and Alba CB (2013) Model predictive control.\nSpringer Science & Business Media.\nCamoriano R, Traversaro S, Rosasco L, Metta G and Nori F (2016)\nIncremental semiparametric inverse dynamics learning.\nIn:\nInternational Conference on Robotics and Automation (ICRA).\nChen RT, Rubanova Y, Bettencourt J and Duvenaud D (2018)\nNeural ordinary differential equations.\nAdvances in neural\ninformation processing systems (NeuRIPS) .\nChen Z, Zhang J, Arjovsky M and Bottou L (2020) Symplectic\nrecurrent neural networks.\nInternational Conference on\nLearning Representations (ICLR) .\nChoi Y, Cheong SY and Schweighofer N (2007) Local online\nsupport vector regression for learning control. In: International\nSymposium on Computational Intelligence in Robotics and\nAutomation.\nChu M, Thuerey N, Seidel HP, Theobalt C and Zayer R (2021)\nLearning meaningful controls for ﬂuids.\nACM Transactions\non Graphics (TOG) .\nCohen T, Weiler M, Kicanaoglu B and Welling M (2019) Gauge\nequivariant convolutional networks and the icosahedral CNN.\nIn: International Conference on Machine Learning (ICML).\nCohen T and Welling M (2016) Group equivariant convolutional\nnetworks. In: International Conference on Machine Learning\n(ICML).\nCoumans E and Bai Y (2016) Pybullet, a python module for physics\nsimulation for games, robotics and machine learning.\nhttp:\n//pybullet.org.\nCranmer M, Greydanus S, Hoyer S, Battaglia P, Spergel D and\nHo S (2020) Lagrangian neural networks.\narXiv preprint\narXiv:2003.04630 .\nde Wit CC, Siciliano B and Bastin G (2012) Theory of robot control.\nSpringer Science & Business Media.\nDegrave J, Hermans M, Dambre J et al. (2019) A differentiable\nphysics engine for deep learning in robotics.\nFrontiers in\nneurorobotics .\nDheeru D and Karra Taniskidou E (2017) UCI machine learning\nrepository. URL http://archive.ics.uci.edu/ml.\nFeatherstone R (2007) Rigid Body Dynamics Algorithms. Springer-\nVerlag.\nFerreira JP, Crisostomo M, Coimbra AP and Ribeiro B (2007)\nSimulation control of a biped robot with support vector\nregression. In: IEEE International Symposium on Intelligent\nSignal Processing.\nFinzi\nM,\nWang\nKA\nand\nWilson\nAG\n(2020)\nSimplifying\nHamiltonian and Lagrangian neural networks via explicit\nconstraints.\nAdvances of Neural Information Processing\nSystems (NeuRIPS) .\nFitzpatrick R (2008) Newtonian dynamics.\nGautier M (1986) Identiﬁcation of robots dynamics.\nIFAC\nProceedings Volumes .\nGeist AR and Trimpe S (2021) Structured learning of rigid-\nbody dynamics: A survey and uniﬁed view from a robotics\nperspective. GAMM-Mitteilungen .\nGeng Z, Haynes LS, Lee JD and Carroll RL (1992) On the dynamic\nmodel and kinematic analysis of a class of stewart platforms.\nRobotics and autonomous systems .\nGolliday CL and Hemami H (1977) An approach to analyzing biped\nlocomotion dynamics and designing robot locomotion controls.\nIEEE Transactions on Automatic Control .\nGreenwood DT (2006) Advanced dynamics. Cambridge University\nPress.\nGreydanus S, Dzamba M and Yosinski J (2019) Hamiltonian neural\nnetworks.\nIn: Advances in Neural Information Processing\nSystems (NeuRIPS).\nGupta JK, Menda K, Manchester Z and Kochenderfer M (2020)\nStructured mechanical models for robot learning and control.\nIn: Learning for Dynamics and Control (L4DC).\nGupta JK, Menda K, Manchester Z and Kochenderfer MJ (2019)\nA general framework for structured learning of mechanical\nsystems. arXiv preprint arXiv:1902.08705 .\nHa D and Schmidhuber J (2018) World models.\narXiv preprint\narXiv:1803.10122 .\n18\nHaarnoja T, Zhou A, Abbeel P and Levine S (2018) Soft actor-critic:\nOff-policy maximum entropy deep reinforcement learning with\na stochastic actor. In: International Conference on Machine\nLearning (ICML).\nHafner D, Lillicrap T, Ba J and Norouzi M (2019a) Dream to con-\ntrol: Learning behaviors by latent imagination. International\nConference on Learning Representations (ICLR) .\nHafner D, Lillicrap T, Fischer I, Villegas R, Ha D, Lee H and\nDavidson J (2019b) Learning latent dynamics for planning\nfrom pixels. In: International Conference on Machine Learning\n(ICML).\nHafner D, Lillicrap T, Norouzi M and Ba J (2020) Mastering\natari with discrete world models. International Conference on\nLearning Representations (ICLR) .\nHarris CR, Millman KJ, van der Walt SJ, Gommers R, Virtanen P,\nCournapeau D, Wieser E, Taylor J, Berg S, Smith NJ, Kern R,\nPicus M, Hoyer S, van Kerkwijk MH, Brett M, Haldane A, del\nR´ıo JF, Wiebe M, Peterson P, G´erard-Marchant P, Sheppard K,\nReddy T, Weckesser W, Abbasi H, Gohlke C and Oliphant TE\n(2020) Array programming with NumPy. Nature .\nHaruno M, Wolpert DM and Kawato M (2001) Mosaic model for\nsensorimotor learning and control. Neural computation .\nHeess N, Sriram S, Lemmon J, Merel J, Wayne G, Tassa Y, Erez\nT, Wang Z, Eslami S, Riedmiller M et al. (2017) Emergence\nof locomotion behaviours in rich environments. arXiv preprint\narXiv:1707.02286 .\nHeiden\nE,\nMacklin\nM,\nNarang\nY,\nFox\nD,\nGarg\nA\nand\nRamos F (2021) Disect: Differentiable simulation engine for\nautonomous robotic cutting.\nRobotics: Science and Systems\n(RSS) .\nHemami H and Wyman B (1979) Modeling and control of\nconstrained dynamic systems with application to biped\nlocomotion in the frontal plane.\nIEEE Transactions on\nAutomatic Control (TAC) .\nHobbs BF and Hepenstal A (1989) Is optimization optimistically\nbiased? Water Resources Research .\nHochlehnert A, Terenin A, Sæmundsson S and Deisenroth M\n(2021) Learning contact dynamics using physically structured\nneural networks.\nIn: International Conference on Artiﬁcial\nIntelligence and Statistics (Aistats).\nHoll P, Koltun V and Thuerey N (2020) Learning to control\nPDEs with differentiable physics. International Conference on\nLearning Representations (ICLR) .\nHuh I, Yang E, Hwang SJ and Shin J (2020) Time-reversal\nsymmetric ode network.\nAdvances of Neural Information\nProcessing Systems (NeuRIPS) .\nHwangbo J, Lee J, Dosovitskiy A, Bellicoso D, Tsounis V, Koltun V\nand Hutter M (2019) Learning agile and dynamic motor skills\nfor legged robots. Science Robotics .\nIoannou PA and Sun J (1996) Robust adaptive control. Prentice-\nHall.\nJansen M (1994) Learning an accurate neural model of the\ndynamics of a typical industrial robot.\nIn: International\nConference on Artiﬁcial Neural Networks (ICANN).\nJHU LCSR JL (2018) Barrett model containing the 7-dof urdf. URL\nhttps://github.com/jhu-lcsr/barrett model.\nKhansari-Zadeh SM and Billard A (2011) Learning stable nonlinear\ndynamical systems with gaussian mixture models.\nIEEE\nTransactions on Robotics .\nKhosla PK and Kanade T (1985) Parameter identiﬁcation of robot\ndynamics. In: Conference on Decision and Control (CDC).\nKocijan J, Murray-Smith R, Rasmussen CE and Girard A (2004)\nGaussian process model based predictive control. In: American\nControl Conference (ACC).\nLagaris IE, Likas A and Fotiadis DI (1998) Artiﬁcial neural\nnetworks for solving ordinary and partial differential equations.\nIEEE Transactions on Neural Networks .\nLagaris IE, Likas AC and Papageorgiou DG (2000) Neural-\nnetwork methods for boundary value problems with irregular\nboundaries. IEEE Transactions on Neural Networks .\nLambert N, Amos B, Yadan O and Calandra R (2020) Objective\nmismatch in model-based reinforcement learning. Learning for\nDynamics and Control (L4DC) .\nLedezma FD and Haddadin S (2017) First-order-principles-based\nconstructive network topologies: An application to robot\ninverse dynamics. In: International Conference on Humanoid\nRobotics (Humanoids).\nLee H and Kang IS (1990) Neural algorithm for solving differential\nequations. Journal of Computational Physics .\nLee J, Liu CK, Park FC and Srinivasa SS (2020) A linear-time\nvariational integrator for multibody systems.\nAlgorithmic\nFoundations of Robotics XII. Springer .\nLenc K and Vedaldi A (2015) Understanding image representations\nby measuring their equivariance and equivalence.\nIn:\nConference on Computer Vision and Pattern Recognition.\nLenz I, Knepper RA and Saxena A (2015) Deepmpc: Learning\ndeep latent features for model predictive control. In: Robotics:\nScience and Systems (RSS).\nLiu K, Lewis F, Lebret G and Taylor D (1993) The singularities\nand dynamics of a stewart platform manipulator. Journal of\nIntelligent and Robotic Systems .\nLurie AI (2013) Analytical mechanics.\nSpringer Science &\nBusiness Media.\nLutter M, Hasenclever L, Byravan A, Dulac-Arnold G, Trochim\nP, Heess N, Merel J and Tassa Y (2021a) Learning\ndynamics models for model predictive agents. arXiv preprint\narXiv:2109.14311 .\nLutter M and Peters J (2019) Deep lagrangian networks for end-\nto-end learning of energy-based control for under-actuated\nsystems.\nIn: International Conference on Intelligent Robots\nand Systems (IROS).\nLutter M, Ritter C and Peters J (2019) Deep lagrangian networks:\nUsing physics as model prior for deep learning.\nIn:\nInternational Conference on Learning Representations (ICLR).\nLutter M, Silberbauer J, Watson J and Peters J (2020) A\ndifferentiable Newton-Euler algorithm for multi-body model\nlearning. arXiv preprint arXiv:2010.09802 .\nLutter\nM,\nSilberbauer\nJ,\nWatson\nJ and\nPeters\nJ\n(2021b)\nDifferentiable physics models for real-world ofﬂine model-\nbased reinforcement learning.\nInternational Conference on\nRobotics and Automation (ICRA) .\nMeade Jr AJ and Fernandez AA (1994) Solution of nonlinear\nordinary differential equations by feedforward neural networks.\nMathematical and Computer Modelling .\nMiller K (1992) The lagrange-based model of delta-4 robot\ndynamics. Robotersysteme .\nMukerjee A and Ballard D (1985) Self-calibration in robot\nmanipulators. In: International Conference on Robotics and\nLutter and Peters\n19\nAutomation (ICRA).\nNguyen-Tuong D and Peters J (2010) Using model knowledge for\nlearning inverse dynamics.\nIn: International Conference on\nRobotics and Automation (ICRA).\nNguyen-Tuong D, Seeger M and Peters J (2008) Computed torque\ncontrol with nonparametric regression models. In: American\nControl Conference (ACC).\nNguyen-Tuong D, Seeger M and Peters J (2009) Model learning\nwith local gaussian process regression. Advanced Robotics .\nOlsson H, ˚Astr¨om KJ, De Wit CC, G¨afvert M and Lischinsky P\n(1998) Friction models and friction compensation. European\nJournalf of Control .\nPaszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G,\nKilleen T, Lin Z, Gimelshein N, Antiga L, Desmaison A, Kopf\nA, Yang E, DeVito Z, Raison M, Tejani A, Chilamkurthy S,\nSteiner B, Fang L, Bai J and Chintala S (2019) PyTorch:\nAn imperative style, high-performance deep learning library.\nIn: Advances in Neural Information Processing Systems\n(NeuRIPS).\nQin H (2020) Machine learning and serving of discrete ﬁeld\ntheories. Scientiﬁc Reports .\nQuanser (2018) Quanser courseware and resources. https://www.\nquanser.com/solution/control-systems/.\nRaissi M, Perdikaris P and Karniadakis GE (2017a) Physics\ninformed deep learning (part i): Data-driven solutions of\nnonlinear partial differential equations.\narXiv preprint\narXiv:1711.10561 .\nRaissi M, Perdikaris P and Karniadakis GE (2017b) Physics\ninformed deep learning (part ii): data-driven discovery of\nnonlinear partial differential equations.\narXiv preprint\narXiv:1711.10566 .\nRatliff N, Meier F, Kappler D and Schaal S (2016) Doomed: Direct\nonline optimization of modeling errors in dynamics. Big data .\nRomeres D, Zorzi M, Camoriano R and Chiuso A (2016) Online\nsemi-parametric learning for inverse dynamics modeling. In:\nConference on Decision and Control (CDC).\nRomeres D, Zorzi M, Camoriano R, Traversaro S and Chiuso\nA (2019) Derivative-free online learning of inverse dynamics\nmodels. IEEE Transactions on Control Systems Technology .\nRueckert E, Nakatenus M, Tosatto S and Peters J (2017) Learning\ninverse dynamics models in o (n) time with lstm networks. In:\nInternational Conference on Humanoid Robotics (Humanoids).\nSaemundsson S, Terenin A, Hofmann K and Deisenroth M\n(2020) Variational integrator networks for physically structured\nembeddings.\nIn: International Conference on Artiﬁcial\nIntelligence and Statistics (Aistats).\nSanchez-Gonzalez A, Bapst V, Cranmer K and Battaglia P (2019)\nHamiltonian graph networks with ode integrators.\narXiv\npreprint arXiv:1909.12790 .\nSanchez-Gonzalez A, Heess N, Springenberg JT, Merel J,\nRiedmiller M, Hadsell R and Battaglia P (2018) Graph\nnetworks as learnable physics engines for inference and\ncontrol.\nInternational Conference on Machine Learning\n(ICML) .\nSchaal S, Atkeson CG and Vijayakumar S (2002) Scalable\ntechniques from nonparametric statistics for real time robot\nlearning. Applied Intelligence .\nSch¨utt KT, Arbabzadah F, Chmiela S, M¨uller KR and Tkatchenko\nA (2017) Quantum-chemical insights from deep tensor neural\nnetworks. Nature communications .\nSiciliano B and Khatib O (2016) Springer handbook of robotics.\nSpringer.\nSpong MW (1987) Modeling and control of elastic joint robots.\nJournal of dynamic systems, measurement, and control .\nSutanto G, Wang A, Lin Y, Mukadam M, Sukhatme G, Rai A and\nMeier F (2020) Encoding physical constraints in differentiable\nNewton-Euler Algorithm.\nLearning for Dynamics Control\n(L4DC) .\nTing JA, Mistry M, Peters J, Schaal S and Nakanishi J (2006)\nA bayesian approach to nonlinear parameter identiﬁcation for\nrigid body dynamics. In: Robotics: Science and Systems.\nToth P, Rezende DJ, Jaegle A, Racani`ere S, Botev A and Higgins\nI (2019) Hamiltonian generative networks.\nInternational\nConference on Learning Representations (ICLR) .\nTraversaro S, Brossette S, Escande A and Nori F (2016)\nIdentiﬁcation of fully physical consistent inertial parameters\nusing optimization on manifolds. In: International Conference\non Intelligent Robots and Systems (IROS).\nWahrburg A, B¨os J, Listmann KD, Dai F, Matthias B and Ding\nH (2018) Motor-current-based estimation of cartesian contact\nforces and torques for robotic manipulators and its application\nto force control. IEEE Transactions on Automation Science and\nEngineering .\nWang R, Kashinath K, Mustafa M, Albert A and Yu R (2020a)\nTowards physics-informed deep learning for turbulent ﬂow\nprediction.\nIn: International Conference on Knowledge\nDiscovery & Data Mining.\nWang R, Walters R and Yu R (2020b) Incorporating symmetry\ninto deep dynamics models for improved generalization.\nInternational Conference on Learning Representations .\nWeiler M and Cesa G (2019) General E(2)-equivariant steerable\nCNNs.\nAdvances in neural information processing systems\n(NeuRIPS) .\nWells DA (1967) Schaum’s outline of theory and problems of\nlagrangian dynamics. McGraw-Hill.\nWensing PM, Kim S and Slotine JJE (2017) Linear matrix\ninequalities\nfor\nphysically\nconsistent\ninertial\nparameter\nidentiﬁcation: A statistical perspective on the mass distribution.\nIEEE Robotics and Automation Letters (RAL) .\nWerling K, Omens D, Lee J, Exarchos I and Liu CK (2021) Fast\nand feature-complete differentiable physics for articulated rigid\nbodies with contact. Robotics: Science and Systems (RSS) .\nWilliams B, Toussaint M and Storkey AJ (2008) Modelling\nmotion primitives and their timing in biologically executed\nmovements. In: Advances in Neural Information Processing\nSystems (NeurIPS).\nZhong YD, Dey B and Chakraborty A (2019) Symplectic ode-net:\nLearning Hamiltonian dynamics with control.\nInternational\nConference on Learning Representations (ICLR) .\nZhong YD, Dey B and Chakraborty A (2020) Dissipative symoden:\nEncoding Hamiltonian dynamics with dissipation and control\ninto deep learning. arXiv preprint arXiv:2002.08860 .\nZhong YD, Dey B and Chakraborty A (2021) Extending Lagrangian\nand Hamiltonian neural networks with differentiable contact\nmodels. Advances of Neural Information Processing Systems\n(NeuRIPS) .\nZhou K, Doyle JC, Glover K et al. (1996) Robust and optimal\ncontrol. Prentice Hall.\n20\n7\nAppendix\n7.1\nExtended Experimental Results\nTo make the differences between the different learned models shown in Figure 4 and Figure 5 clearer, we provide a ﬁgure\nper model in the appendix. For more details about the ﬁgures please refer to the ﬁgures in the article and section 5.\ne\nv\nq\n0\n2\n4\nTorque [Nm]\nJoint 0\nTorque τ\ne\nv\nq\n−2\n0\nTorque [Nm]\nJoint 1\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\nError\n(a)\ne\nv\nq\n−2\n0\n2\nTorque [Nm]\nInertial Torque τ I = H(q)¨q\ne\nv\nq\n−2\n0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(b)\ne\nv\nq\n0.0\n0.5\nTorque [Nm]\nCoriolis Torque τ c = c(q, ˙q)\ne\nv\nq\n0.0\n0.5\n1.0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(c)\ne\nv\nq\n0\n1\n2\n3\nTorque [Nm]\nGravitational Torque τ c = ∂V (q)/∂q\ne\nv\nq\n−0.5\n0.0\n0.5\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 8. The learned inverse model of structured DeLaN using the character dataset averaged over 10 seeds. For more\ninformation see Fig. 4.\ne\nv\nq\n0\n2\n4\nTorque [Nm]\nJoint 0\nTorque τ\ne\nv\nq\n−2\n0\nTorque [Nm]\nJoint 1\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\nError\n(a)\ne\nv\nq\n−2\n0\n2\nTorque [Nm]\nInertial Torque τ I = H(q)¨q\ne\nv\nq\n−2\n0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(b)\ne\nv\nq\n0.0\n0.5\nTorque [Nm]\nCoriolis Torque τ c = c(q, ˙q)\ne\nv\nq\n0.0\n0.5\n1.0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(c)\ne\nv\nq\n0\n1\n2\n3\nTorque [Nm]\nGravitational Torque τ c = ∂V (q)/∂q\ne\nv\nq\n−0.5\n0.0\n0.5\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 9. The learned inverse model of black-box DeLaN using the character dataset averaged over 10 seeds. For more\ninformation see Fig. 4.\ne\nv\nq\n0\n2\n4\nTorque [Nm]\nJoint 0\nTorque τ\ne\nv\nq\n−2\n0\nTorque [Nm]\nJoint 1\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\nError\n(a)\ne\nv\nq\n−2\n0\n2\nTorque [Nm]\nInertial Torque τ I = H(q)¨q\ne\nv\nq\n−2\n0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(b)\ne\nv\nq\n0.0\n0.5\nTorque [Nm]\nCoriolis Torque τ c = c(q, ˙q)\ne\nv\nq\n0.0\n0.5\n1.0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(c)\ne\nv\nq\n0\n1\n2\n3\nTorque [Nm]\nGravitational Torque τ c = ∂V (q)/∂q\ne\nv\nq\n−0.5\n0.0\n0.5\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 10. The learned inverse model of structured HNN using the character dataset averaged over 10 seeds. For more\ninformation see Fig. 4.\nLutter and Peters\n21\ne\nv\nq\n0\n2\n4\nTorque [Nm]\nJoint 0\nTorque τ\ne\nv\nq\n−2\n0\nTorque [Nm]\nJoint 1\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\nError\n(a)\ne\nv\nq\n−2\n0\n2\nTorque [Nm]\nInertial Torque τ I = H(q)¨q\ne\nv\nq\n−2\n0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(b)\ne\nv\nq\n0.0\n0.5\nTorque [Nm]\nCoriolis Torque τ c = c(q, ˙q)\ne\nv\nq\n0.0\n0.5\n1.0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(c)\ne\nv\nq\n0\n1\n2\n3\nTorque [Nm]\nGravitational Torque τ c = ∂V (q)/∂q\ne\nv\nq\n−0.5\n0.0\n0.5\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 11. The learned inverse model of black-box HNN using the character dataset averaged over 10 seeds. For more\ninformation see Fig. 4.\ne\nv\nq\n0\n2\n4\nTorque [Nm]\nJoint 0\nTorque τ\ne\nv\nq\n−2\n0\nTorque [Nm]\nJoint 1\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\nError\n(a)\ne\nv\nq\n−2\n0\n2\nTorque [Nm]\nInertial Torque τ I = H(q)¨q\ne\nv\nq\n−2\n0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(b)\ne\nv\nq\n0.0\n0.5\nTorque [Nm]\nCoriolis Torque τ c = c(q, ˙q)\ne\nv\nq\n0.0\n0.5\n1.0\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(c)\ne\nv\nq\n0\n1\n2\n3\nTorque [Nm]\nGravitational Torque τ c = ∂V (q)/∂q\ne\nv\nq\n−0.5\n0.0\n0.5\nTorque [Nm]\ne\nv\nq\n10−12\n10−8\n10−4\n100\nNormalized MSE\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 12. The learned inverse model of the feed-forward network using the character dataset averaged over 10 seeds. For more\ninformation see Fig. 4.\nTest 0\nTest 1\n−6\n−4\n−2\n0\nq0 [Rad]\nJoint 0\nGeneralized Position q\nTest 0\nTest 1\n−10\n0\n10\nq1 [Rad]\nJoint 1\nTest 0\nTest 1\n10−5\n10−2\n101\nPosition Error\nError\n(a)\nTest 0\nTest 1\n−5\n0\n5\n˙q0 [Rad/s]\nGeneralized Velocity ˙q\nTest 0\nTest 1\n−10\n0\n10\n˙q1 [Rad/s]\nTest 0\nTest 1\n10−5\n10−2\n101\nVelocity Error\n(b)\nTest 0\nTest 1\n−5.0\n−2.5\n0.0\n2.5\np0\nGeneralized Momentum p\nTest 0\nTest 1\n−2\n0\n2\np1\nTest 0\nTest 1\n10−5\n10−2\n101\nImpulse Error\n(c)\nTest 0\nTest 1\n−0.010\n−0.005\n0.000\n0.005\n0.010\nH\nNormalized Energy H\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 13. The model rollouts of (a) the position, (b) velocity and (c) momentum, and (d) energy of the structured DeLaN model\ntrained on the uniform dataset averaged over 10 seeds. For more information see Fig. 5\n22\nTest 0\nTest 1\n−6\n−4\n−2\n0\nq0 [Rad]\nJoint 0\nGeneralized Position q\nTest 0\nTest 1\n−10\n0\n10\nq1 [Rad]\nJoint 1\nTest 0\nTest 1\n10−5\n10−2\n101\nPosition Error\nError\n(a)\nTest 0\nTest 1\n−5\n0\n5\n˙q0 [Rad/s]\nGeneralized Velocity ˙q\nTest 0\nTest 1\n−10\n0\n10\n˙q1 [Rad/s]\nTest 0\nTest 1\n10−5\n10−2\n101\nVelocity Error\n(b)\nTest 0\nTest 1\n−5.0\n−2.5\n0.0\n2.5\np0\nGeneralized Momentum p\nTest 0\nTest 1\n−2\n0\n2\np1\nTest 0\nTest 1\n10−5\n10−2\n101\nImpulse Error\n(c)\nTest 0\nTest 1\n−0.010\n−0.005\n0.000\n0.005\n0.010\nH\nNormalized Energy H\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 14. The model rollouts of (a) the position, (b) velocity and (c) momentum, and (d) energy of the black-box DeLaN model\ntrained on the uniform dataset averaged over 10 seeds. For more information see Fig. 5\nTest 0\nTest 1\n−6\n−4\n−2\n0\nq0 [Rad]\nJoint 0\nGeneralized Position q\nTest 0\nTest 1\n−10\n0\n10\nq1 [Rad]\nJoint 1\nTest 0\nTest 1\n10−5\n10−2\n101\nPosition Error\nError\n(a)\nTest 0\nTest 1\n−5\n0\n5\n˙q0 [Rad/s]\nGeneralized Velocity ˙q\nTest 0\nTest 1\n−10\n0\n10\n˙q1 [Rad/s]\nTest 0\nTest 1\n10−5\n10−2\n101\nVelocity Error\n(b)\nTest 0\nTest 1\n−5.0\n−2.5\n0.0\n2.5\np0\nGeneralized Momentum p\nTest 0\nTest 1\n−2\n0\n2\np1\nTest 0\nTest 1\n10−5\n10−2\n101\nImpulse Error\n(c)\nTest 0\nTest 1\n−0.010\n−0.005\n0.000\n0.005\n0.010\nH\nNormalized Energy H\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 15. The model rollouts of (a) the position, (b) velocity and (c) momentum, and (d) energy of the structured HNN model\ntrained on the uniform dataset averaged over 10 seeds. For more information see Fig. 5\nTest 0\nTest 1\n−6\n−4\n−2\n0\nq0 [Rad]\nJoint 0\nGeneralized Position q\nTest 0\nTest 1\n−10\n0\n10\nq1 [Rad]\nJoint 1\nTest 0\nTest 1\n10−5\n10−2\n101\nPosition Error\nError\n(a)\nTest 0\nTest 1\n−5\n0\n5\n˙q0 [Rad/s]\nGeneralized Velocity ˙q\nTest 0\nTest 1\n−10\n0\n10\n˙q1 [Rad/s]\nTest 0\nTest 1\n10−5\n10−2\n101\nVelocity Error\n(b)\nTest 0\nTest 1\n−5.0\n−2.5\n0.0\n2.5\np0\nGeneralized Momentum p\nTest 0\nTest 1\n−2\n0\n2\np1\nTest 0\nTest 1\n10−5\n10−2\n101\nImpulse Error\n(c)\nTest 0\nTest 1\n−0.010\n−0.005\n0.000\n0.005\n0.010\nH\nNormalized Energy H\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 16. The model rollouts of (a) the position, (b) velocity and (c) momentum, and (d) energy of the black-box HNN model\ntrained on the uniform dataset averaged over 10 seeds. For more information see Fig. 5\nLutter and Peters\n23\nTest 0\nTest 1\n−6\n−4\n−2\n0\nq0 [Rad]\nJoint 0\nGeneralized Position q\nTest 0\nTest 1\n−10\n0\n10\nq1 [Rad]\nJoint 1\nTest 0\nTest 1\n10−5\n10−2\n101\nPosition Error\nError\n(a)\nTest 0\nTest 1\n−5\n0\n5\n˙q0 [Rad/s]\nGeneralized Velocity ˙q\nTest 0\nTest 1\n−10\n0\n10\n˙q1 [Rad/s]\nTest 0\nTest 1\n10−5\n10−2\n101\nVelocity Error\n(b)\nTest 0\nTest 1\n−5.0\n−2.5\n0.0\n2.5\np0\nGeneralized Momentum p\nTest 0\nTest 1\n−2\n0\n2\np1\nTest 0\nTest 1\n10−5\n10−2\n101\nImpulse Error\n(c)\nTest 0\nTest 1\n−0.010\n−0.005\n0.000\n0.005\n0.010\nH\nNormalized Energy H\n(d)\nDeLaN - Structured Lagrangian\nDeLaN - Black-Box Lagrangian\nHNN - Structured Hamiltonian\nHNN - Black-Box Hamiltonian\nFeed-Forward Network\nGround Truth\nFigure 17. The model rollouts of (a) the position, (b) velocity and (c) momentum, and (d) energy of the feed-forward network model\ntrained on the uniform dataset averaged over 10 seeds. For more information see Fig. 5\n",
  "categories": [
    "cs.LG",
    "cs.RO"
  ],
  "published": "2021-10-05",
  "updated": "2023-03-17"
}