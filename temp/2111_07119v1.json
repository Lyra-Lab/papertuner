{
  "id": "http://arxiv.org/abs/2111.07119v1",
  "title": "Extracting and filtering paraphrases by bridging natural language inference and paraphrasing",
  "authors": [
    "Matej Klemen",
    "Marko Robnik-Šikonja"
  ],
  "abstract": "Paraphrasing is a useful natural language processing task that can contribute\nto more diverse generated or translated texts. Natural language inference (NLI)\nand paraphrasing share some similarities and can benefit from a joint approach.\nWe propose a novel methodology for the extraction of paraphrasing datasets from\nNLI datasets and cleaning existing paraphrasing datasets. Our approach is based\non bidirectional entailment; namely, if two sentences can be mutually entailed,\nthey are paraphrases. We evaluate our approach using several large pretrained\ntransformer language models in the monolingual and cross-lingual setting. The\nresults show high quality of extracted paraphrasing datasets and surprisingly\nhigh noise levels in two existing paraphrasing datasets.",
  "text": "EXTRACTING AND FILTERING PARAPHRASES BY BRIDGING\nNATURAL LANGUAGE INFERENCE AND PARAPHRASING\nMatej Klemen\nUniversity of Ljubljana\nFaculty of Computer and Information Science\nVeˇcna pot 113, 1000 Ljubljana, Slovenia\nmatej.klemen@fri.uni-lj.si\nMarko Robnik-Šikonja\nUniversity of Ljubljana\nFaculty of Computer and Information Science\nVeˇcna pot 113, 1000 Ljubljana, Slovenia\nmarko.robnik@fri.uni-lj.si\nNovember 16, 2021\nABSTRACT\nParaphrasing is a useful natural language processing task that can contribute to more diverse generated\nor translated texts. Natural language inference (NLI) and paraphrasing share some similarities and\ncan beneﬁt from a joint approach. We propose a novel methodology for the extraction of paraphrasing\ndatasets from NLI datasets and cleaning existing paraphrasing datasets. Our approach is based on\nbidirectional entailment; namely, if two sentences can be mutually entailed, they are paraphrases. We\nevaluate our approach using several large pretrained transformer language models in the monolingual\nand cross-lingual setting. The results show high quality of extracted paraphrasing datasets and\nsurprisingly high noise levels in two existing paraphrasing datasets.\nKeywords natural language processing · paraphrasing · natural language inference\n1\nIntroduction\nNatural language inference (NLI) and text paraphrasing are two useful and frequently applied tasks in natural language\nprocessing. In NLI, the task is to determine if a target sequence (hypothesis) entails the source sequence (premise),\ncontradicts it, or is neutral with respect to it. A paraphrase is a restatement of the meaning of a text or passage using\nother words. Both tasks are commonly used, either on their own or to support other tasks. For example, NLI can be used\nfor fact veriﬁcation, as demonstrated in the Fact Extraction and Veriﬁcation 2018 Shared Task [24], while paraphrasing\ncan be used to rephrase news headlines [29] or improve text expression in grammar tools.\nDespite mainly being researched separately, NLI and paraphrasing are similar and can beneﬁt from a joint approach.\nAs we show, the performance of paraphrasing can be improved by using additional resources available for NLI. For\nexample, paraphrase generation methods can generate more diverse paraphrases by being trained using paraphrases\nextracted from existing NLI datasets. In the situation where little or no resources are available to train a paraphrase\nidentiﬁcation model, a pretrained NLI model could be used as an alternative.\nAlthough large English datasets exist for both NLI and paraphrasing, paraphrasing datasets are often automatically\nderived from datasets containing similar texts but not necessarily paraphrases. For example, COCO captions dataset\n[4]) contains multiple captions of the same image, and Quora question pairs are composed of duplicate questions. We\naim to extend the pool of available paraphrasing resources using a framework whose primary use is the extraction of\nparaphrases from existing NLI datasets.\nIn the proposed framework, we treat paraphrases as sequence pairs where the hypothesis entails the premise and the\npremise entails the hypothesis, i.e. there is a bidirectional entailment. This connection has previously been mentioned\n[1], but its potential for paraphrase extraction and ﬁltering was not fully explored. We study the following two scenarios:\n1. Creation of a paraphrase dataset from an existing NLI dataset. We demonstrate this scenario in a mono-\nlingual and a cross-lingual setting, using Stanford NLI (SNLI) [2], Multi-genre NLI (MNLI) [27] and\narXiv:2111.07119v1  [cs.CL]  13 Nov 2021\nA PREPRINT - NOVEMBER 16, 2021\nCross-lingual NLI (XNLI) [5] datasets to produce new paraphrasing datasets. In the cross-lingual setting,\nwe compare extracted paraphrases with the so-called “translate-train” and “translate-test” methods, which\ntransform the cross-lingual into a multilingual problem by automatically translating the training or the test set.\n2. Cleaning of an existing paraphrasing dataset. By a slight modiﬁcation, we reuse the framework to ﬁlter\nfalse positive instances, i.e. instances which are labeled as paraphrases but are not actual paraphrases. The\nﬁltering uses the validation with the bidirectional entailment relation. We demonstrate this scenario on two\nEnglish paraphrase identiﬁcation datasets: Quora Question Pairs (QQP) and Microsoft Research Paraphrase\nCorpus (MRPC) [9].\nIn our approach, we compare several NLI classiﬁers with varying performance. To show the usability for different\nuse-cases that might have different expectations concerning the correctness of paraphrases, we present the results at\nmultiple certainty levels and show that precision and recall can be used to select the right setting. For example, when\nbuilding a model for rephrasing news, a more “conservative” paraphrase dataset might be preferable in order to avoid a\nmodel that would make up facts. To facilitate further research, we release the source code of our framework 1.\nThe paper is split into further four sections. In Section 2, we present a related work on paraphrasing and NLI. In\nSection 3, we present our methodology for creation and cleaning of new paraphrasing datasets. In Section 4, we evaluate\nthe newly proposed methods. Finally, in Section 5, we summarize the work and give directions for further work.\n2\nRelated work\nWe ﬁrst overview the related work that connects NLI with other tasks, followed by existing work on the construction of\nparaphrasing datasets.\n2.1\nConnections between NLI and other tasks\nSince the early days of research on textual entailment, various authors have used it to improve other tasks’ performance.\nFor example, Lloret et al. [19] use the textual entailment recognition to improve a summarization system. In order\nto generate preliminary summaries, they iterate through sentences and only keep those that did not entail any other\npreviously seen sentences. To improve an information retrieval system, Lin and Pantel [17] extract textual entailment\nrules from text by using similarities in dependency paths. Harabagiu and Hickl [13] integrate textual entailment into the\nopen-domain question answering task, observing improved performance when using it to ﬁlter answer candidates or\nas a ranking mechanism for passages. Similarly, Chen et al. [3] use textual entailment to verify that the answer to the\nquestion entails a given context. The entailment was also used to improve the evaluation procedure of other tasks. Padó\net al. [22] propose a metric for machine translation evaluation that incorporates bidirectional textual entailment as a way\nto measure meaning equivalence between a hypothesis and a reference summary. In our work, we use the bidirectional\ntextual entailment for three purposes. First, to create new paraphrasing datasets. Second, we show the feasibility of\nthe idea in the cross-lingual setting, and third, we show that the idea can be reused for ﬁltering existing paraphrasing\ndatasets.\nWith the introduction of large annotated datasets for many tasks, authors started to use them in transfer learning. For\nexample, White et al. [26] convert semantic proto-role labeling, paraphrasing and anaphora resolution datasets into a\nbinary textual entailment dataset to explore the extent to which an NLI model can capture speciﬁc aspects of semantics.\nTwo further examples of such datasets (QNLI and WNLI) are included in the GLUE benchmark (General Language\nUnderstanding Evaluation) [25]. QNLI is derived from the Stanford question answering dataset [23] that contains\nquestion-context pairs, where one of the sentences in the context contains the answer to the question. To produce QNLI,\neach pair is converted into multiple question-sentence pairs labeled as entailment if that sentence contains the answer to\nthe question and non-entailment otherwise. WNLI is derived from the Winograd schema challenge dataset [16] that\ncontains sentences involving an ambiguous pronoun and a list of possible referents of that pronoun. To produce WNLI,\nthe pronoun is replaced by each possible referent and labeled as entailment if that referent refers to the pronoun.\n2.2\nExisting paraphrasing datasets\nExisting paraphrasing datasets have been created (or repurposed) using a variety of data sources including image\ncaptions - COCO [4] and Multi30k [10]), duplicate questions - QQP and PAWS2 [33]), news data - MRPC [9]), tweets\n- Twitter News URL corpus [14] and Twitter Paraphrase corpus [30]), subtitles - Opusparcus [7]), and more general\n1https://github.com/matejklemen/paraphrase-nli\n2PAWS also contains instances from Wikipedia as an additional source.\n2\nA PREPRINT - NOVEMBER 16, 2021\nbilingual text - PPDB [11]). Although most resources are available for the English language, some datasets also exist\nfor other languages. Opusparcus uses multilingual subtitles to produce paraphrases in six different languages. PPDB\nwas created for English and Spanish, and PAWS-X [31] contains instances from PAWS translated into six different\nlanguages. The Multi30k dataset provides a translation of the image captions in Flickr30k [32] to German, to which\nthey add new (independent) German captions.\nWith our work, we expand the pool of paraphrasing resources by using a different, previously unused source – NLI data.\nBy learning the relations in NLI datasets and asserting the validity of bidirectional entailment for paraphrasing, we\nensure the equivalence of meanings. In some of the existing paraphrasing datasets, the meaning equivalence can be\npotentially problematic, e.g., in those that use image captions or duplicate questions. However, a slight modiﬁcation of\nour framework enables us to detect some of the inconsistencies in existing paraphrasing datasets.\nOur approach can be used in any language with an existing NLI dataset and NLI model of sufﬁcient quality. We\nverify this with cross-lingual experiments where we extract paraphrases for a few less-resourced languages using a\ncross-lingual transfer from the English NLI model.\n3\nTransfer between NLI and paraphrasing datasets\nIn this section, we describe the use of NLI for extracting paraphrases and paraphrase ﬁltering. In Section 3.1, we ﬁrst\ndescribe the methodology for extraction of paraphrases from an existing NLI dataset, while in Section 3.2, we describe\nhow an existing paraphrasing dataset can be cleaned. In Section 3.3, we discuss the training of NLI classiﬁers which are\nthe essential components of our methodology.\nentailment\nentailment\ncontradiction\nneutral\nentailment\nNLI dataset\ns1\ns2\nentailment\nentailment\nentailment\n?\n?\n?\nNLI \nMODEL\nentailment\nneutral\nentailment\nentailment\nentailment\nParaphrases\ns1\ns2\ns1\ns2\ns1\ns2\n1\n2\n3\n4\n5\ns1\ns2\nFigure 1: A schematic representation of our method for paraphrase extraction from an NLI dataset. In Step 1, we extract\nthe sequence pairs labeled as entailment from the NLI dataset. In Step 2, we reverse the order of these sequence pairs.\nThe labels for the reversed instances are unknown, so we use an NLI model to predict them (Steps 3 and 4). Once we\nobtain the new labels, we select the sequence pairs that are marked as entailment (Step 5). These make up the new\nparaphrasing dataset.\n3.1\nNLI for paraphrase extraction\nFigure 1 shows ﬁve steps of the proposed methodology for extraction of paraphrases from an existing NLI dataset. The\nmain idea of the methodology is that two sentences forming a paraphrase have to mutually entail each other in the\nlogical sense. The input to the methodology is a high quality (e.g., manually labeled) NLI dataset, where instances\nare pairs of sentences (s1, s2), i.e. (premise, hypothesis). In NLI datasets, there are typically three types of relations\nbetween the sentences s1 and s2, namely entailment, contradiction, or neutral.\nIn Step 1, we ﬁlter the input NLI dataset, keeping only the instances labeled as the entailment. In Step 2, we reverse the\norder of these sequences, placing each hypothesis in place of the premise and the premise in place of the hypothesis.\n3\nA PREPRINT - NOVEMBER 16, 2021\nWe obtain a new NLI dataset with unknown labels, so in Step 3, we use an existing NLI prediction model to predict\nthem. This can be any NLI model; for example, we can obtain it by training a machine learning classiﬁer on the original\nNLI dataset or some other NLI dataset.\nThe result (Step 4) are pairs of sentences, labeled as entailment, contradiction or neutral by the trained NLI model. We\nﬁlter the results (Step 5), keeping only the instances predicted to be entailment. For these instances, the bidirectional\ntextual entailment relation holds and, therefore, they constitute paraphrases. To form the ﬁnal paraphrasing dataset, we\nremove the labels, keeping only sentence pairs (s2, s1).\nThe instances which are not extracted are not paraphrases and could be used as negative instances in a paraphrase\ndetection or generating dataset. As our experiments show, the number of non-paraphrases is much larger than the\nnumber of paraphrases. They range from trivial to difﬁcult-to-detect non-paraphrases. In order to ﬁnd difﬁcult instances,\nStep 5 can be modiﬁed only to keep the instances predicted to be neutral. In our experiments, we only deal with the\nextraction of paraphrases and leave the detailed exploration of this scenario for further work.\n3.2\nNLI for paraphrase ﬁltering\nThe above method for paraphrase extraction can be reused for other tasks. We describe how it can be adapted to ﬁlter\nan existing paraphrase identiﬁcation dataset, where examples are labeled as paraphrases or non-paraphrases. Such\ndatasets may contain a certain amount of noisy annotations. For instance, in the QQP dataset, noisy instances are\npresent because a question and its duplicate question (a paraphrase) are usually, but not always, identical concepts. The\nauthors motivate duplicate question detection as ﬁnding questions with the same intent. For example, “How do I learn\nSQL?” and “Which is the best book for SQL?” would indicate the exact intent of obtaining more knowledge about\nSQL, but the meaning cannot be considered identical.\nTo use the framework for paraphrase ﬁltering, we make the following modiﬁcations. The input to our framework is\nnow a paraphrase identiﬁcation dataset, with the labels paraphrase and non-paraphrase. In Step 1, we ﬁlter the dataset\nby selecting instances labeled as a paraphrase (instead of entailment). We repeat the process of reversing the order of\nparaphrases (Step 2), now predicting if the reversed sequence pair is a paraphrase or non-paraphrase using an existing\nparaphrase identiﬁcation model (Step 3 and 4). In Step 5, we select the instances predicted to be non-paraphrases.\nThese instances are paraphrases in one direction but not in the other. Since a paraphrase is supposed to be symmetrical,\nthe output represents falsely labeled paraphrases removed in the ﬁnal cleaned dataset.\n3.3\nImplementation details\nSections 3.1 and 3.2 presents the description of the proposed method. Here, we provide implementation details. For all\nNLI models, we use the default sequence pair set up [8].\nIn our ﬁne-tuning procedure, we consider four types of models: BERT, multilingual BERT [8], RoBERTa (base and\nlarge variant) [18], and XLM-RoBERTa (XLM-R, base and large variant) [6]. We ﬁne-tune them on the datasets\ndescribed in Section 4.1, considering multilingual BERT and XLM-R in cross-lingual experiments and BERT and\nRoBERTa in monolingual experiments. In Section 4, we report results for only one of the two model types, selected\nbased on the validation set F1 score. We use the AdamW optimizer [20] with the learning rate 2 × 10−5. In one\ninstance, where the model did not converge (large XLM-R on XNLI), we decreased the learning rate to 5 × 10−6. We\ntry two settings of the maximum sequence length for each model: 95th and 99th percentile of sequence lengths in a\ntraining set. To prevent overﬁtting, we use early stopping based on the validation set F1 score using a tolerance of ﬁve\nrounds. We use the model implementations from the transformers package [28] and pretrained checkpoints from the\nHuggingFace Model Hub3.\n4\nEvaluation\nThe proposed methodology can create paraphrasing datasets from NLI datasets or improve the quality of existing\nparaphrasing datasets. We ﬁrst describe the NLI and paraphrasing datasets used as inputs to our methodology\n(Section 4.1), and the metrics we use to measure the performance of the models (Section 4.2). In Section 4.3 we evaluate\nthe creation of paraphrasing datasets, and in Section 4.4, we analyse the cleaning of existing paraphrasing datasets.\n3https://huggingface.co/models\n4\nA PREPRINT - NOVEMBER 16, 2021\n4.1\nInput NLI and paraphrasing datasets\nIn our experiments, we use three NLI datasets (SNLI, MNLI, and XNLI) and two paraphrase identiﬁcation datasets (QQP\nand MRPC). All instances in NLI datasets are annotated using a three-class annotation scheme where each sequence pair\nis labeled as entailment, neutral, or contradiction. The paraphrase identiﬁcation datasets are annotated using two labels:\nparaphrase or non-paraphrase. The NLI datasets are balanced in the distributions of the three labels. In contrast, the\nparaphrase identiﬁcation datasets are unbalanced, with MRPC containing approximately two-thirds of paraphrases and\nQQP approximately two-thirds of non-paraphrases. Unless described otherwise, we use the training:development:testing\nset splits determined by dataset authors.\nSNLI [2] is a NLI dataset containing 569 033 instances. The premises are image captions taken from the Flickr30k\ncorpus [32]. The hypotheses were produced by human contributors asked to write one caption that is deﬁnitely true\n(entailment), one that might be true (neutral) and one that is deﬁnitely not true (contradiction) given the premise. The\nsame meaning of labels is also used in MNLI and XNLI.\nMNLI [27] is an NLI dataset containing 412 349 instances that include written and spoken English across ten genres,\nas opposed to the single genre present in SNLI. The premises are obtained from ten sources of freely available text\nwhile obtaining hypotheses is the same as for SNLI. We use a slightly different dataset split from the one proposed by\nthe authors. The validation and test sets in the original version are split into two parts, one containing genres present in\nthe training set and the other containing genres not present in the training set. Models are usually evaluated separately\non the two parts, but we combine the two parts in our experiments. The test set labels are private, so we cannot use\nthem. Instead, we split the combined validation set randomly into two equal parts and use one half as the validation and\none half as the test set.\nXNLI [5] is a NLI dataset containing 112 500 instances divided evenly across 15 languages. In contrast to the previous\ntwo NLI datasets, XNLI only contains the validation and test set, while the training set is reused from MNLI. The\nsequence pairs were obtained using the same procedure as in MNLI and human translated into 15 languages. The\nauthors also provide a machine translation of the training set into 15 languages and a machine translation of the\nvalidation and test sets into English, which we use to train monolingual models showing upper bounds of performance.\nQQP4 is a paraphrase identiﬁcation dataset containing 404 279 instances. It contains potentially duplicate question\npairs posted on the Quora question-and-answer platform. The labels indicate whether a pair of questions could be\nconsidered a duplicate or not. We use the dataset version provided in the GLUE benchmark [25]. As the test set labels\nare private, we use a randomly selected 50% of the validation set as the test set instead.\nMRPC [9] is a paraphrase identiﬁcation dataset containing 5801 instances. Its construction consisted of an initial\ncandidate selection, noisy paraphrase detection using a machine learning model with handcrafted features, and human\nannotation of a subset of detected paraphrases. As there is no pre-determined validation set, we constructed it from\n1000 instances, randomly sampled from the training set.\n4.2\nEvaluation metrics\nTo assess the properties of our method, we use several metrics on the trained NLI models and also perform a human\nevaluation of a sample of the instances.\nFor the NLI models, we measure the (binary) precision (P) and recall (R) for the label entailment. These provide\nus with an estimate of how many and how correct paraphrases NLI models are able to extract: high precision\nindicates many correct paraphrases, and high recall indicates good coverage of paraphrases existing in the NLI\ndataset. P and R are deﬁned with Equation 1, where tp is the number of actual entailment instances that are\ncorrectly predicted by the model, fp the number of actual non-entailment instances that are incorrectly predicted\nby the model, and fn the number of actual entailment instances that are incorrectly predicted by the model.\nP =\ntp\ntp + fp\nR =\ntp\ntp + fn\n(1)\nUsing P and R, we rely on the NLI model performance as a reasonable proxy for paraphrase extraction. To validate\nthese numbers, we perform a small scale manual validation. We randomly sample 100 extracted paraphrases for each\nsetting and check its precision (to compute recall, we would have to check the entire NLI dataset). On XNLI, which\nconsists of 15 languages, we manually validated German and French results as experts in other languages were not\naccessible to us. In manual validation, we mark as paraphrases only those sequence pairs, for which both sequences\ncontain exactly the same meaning.\n4https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs\n5\nA PREPRINT - NOVEMBER 16, 2021\nFor the evaluation of paraphrase ﬁltering, we use the same metrics, but we take non-paraphrase as the positive label.\n4.3\nParaphrase extraction results\nUsing the methodology described in Section 3.1, we processed the three NLI datasets (SNLI, MNLI, and XNLI)\ndescribed in Section 4.1. We ﬁrst present the monolingual paraphrase extraction, followed by the cross-lingual\nexperiments.\n4.3.1\nMonolingual paraphrase extraction\nTable 1 presents the number of extracted paraphrases, precision and recall of the used NLI model, and a manual estimate\nof precision in two monolingual datasets, SNLI and MNLI. We show results for three decision boundaries: when the\nentailment class is the most likely of the three (argmax) and two stricter probability thresholds for the entailment class\n(0.75 and 0.90).\nTable 1: The number of extracted paraphrases (#), precision (P), recall (R) and manually estimated precision («P) in\nSNLI and MNLI using three different decision thresholds for the entailment label. Below each dataset name we show\nthe number of entailment instances in the dataset.\ndataset\ndecision\nroberta-base\nroberta-large\n(size)\nthreshold\n#\nP\nR\n«P\n#\nP\nR\n«P\nSNLI\n(183416)\nargmax\n17793\n0.902\n0.901\n0.670\n16300\n0.921\n0.906\n0.790\nT=0.75\n12067\n0.948\n0.825\n0.790\n10339\n0.961\n0.817\n0.900\nT=0.90\n8857\n0.972\n0.730\n0.850\n4539\n0.985\n0.547\n0.920\nMNLI\n(130899)\nargmax\n40948\n0.888\n0.865\n0.820\n43992\n0.909\n0.886\n0.860\nT=0.75\n30718\n0.945\n0.734\n0.930\n35789\n0.956\n0.799\n0.910\nT=0.90\n21905\n0.975\n0.576\n0.950\n27119\n0.976\n0.661\n0.950\nWe notice that the proposed approach extracts a signiﬁcant number of paraphrases in all tested modes. Below we\naddress several aspects of the obtained paraphrases.\nFirst, although SNLI contains a larger candidate pool of potential paraphrases than MNLI, there is a larger proportion\nof paraphrases present in MNLI. A likely reason for this is heuristics employed by the MNLI annotators to generate\nhypotheses quickly; some have previously been outlined for SNLI and MNLI by Gururangan et al. [12]. MNLI contains\nmultiple genres, for some of which the quickest way to create a hypothesis given a premise is to rephrase the premise.\nThis explanation is strengthened by the genre distribution of extracted paraphrases, with the most common genres being\ntelephone and ﬁction. Premises from these two genres are often parts of dialogues. It is difﬁcult for annotators to\nquickly ﬁnd a true hypothesis without it being a rephrased version of the premise.\nSecond, using a larger and more precise roberta-large model does not necessarily imply a higher amount of extracted\nparaphrases. For example, in MNLI, the large model extracts more paraphrases than the base model, but in SNLI, this is\nnot the case. When using the two stricter decision thresholds, we can see the reason: the larger model obtains higher\nprecision, but lower recall, which roughly corresponds to the decrease in the number of extracted paraphrases. On the\nother hand, the explanation for the argmax decision boundary is less clear. We checked the rate and type of errors the\ntwo models make and found that the base model more frequently incorrectly classiﬁes entailment as contradiction than\nthe large model (80 versus 38 errors). This could be an indication that the model has learned an erroneous pattern which\nleads to the model extracting more false positives. The manual validation conﬁrmed that the base model indeed extracts\nless correct paraphrases.\nUnsurprisingly, with more strict decision thresholds, we extract fewer paraphrases. Different thresholds represent\ntrade-offs between the precision and recall of the paraphrase extraction process. Higher thresholds lead to the extraction\nof paraphrases with higher conﬁdence. Thus, using higher thresholds, we decrease the likelihood of extracting false\nparaphrases and increase the chance that we miss some of the actual paraphrases. The results of the manual validation\nagree with this, although the improvement in precision becomes smaller as we use stricter decision thresholds. More\ncertain paraphrases are typically more conservative. Our additional analysis showed that the sequences in more\ncertain pairs are more similar in length (number of tokens) and have a smaller normalized edit distance [15] than the\nparaphrases extracted with the argmax decision boundary. Stricter decision boundaries might be preferred when we\nwant to minimize the false positives in paraphrases that could guide the downstream paraphrase generation model to\nmake up new information.\n6\nA PREPRINT - NOVEMBER 16, 2021\n4.3.2\nCross-lingual paraphrase extraction\nTable 2 shows the number of extracted paraphrases in the cross-lingual setting using the XNLI datasets in 15 languages.\nWe train and validate a single model on the English data and use this model on the validation and test sets in all 15\nlanguages. We report only the results obtained with the argmax decision boundary, i.e. we extract a paraphrase if\nentailment is the most probable class. The other two decision thresholds extract lower numbers of paraphrases in similar\nratios as shown in Table 1.\nTable 2: The number of extracted paraphrases (#), precision (P) and recall (R) for datasets in 15 different languages\npresent in XNLI for the argmax decision threshold. Each dataset contained 2500 entailment instances. We mark\nmachine translation (MT) settings where a language-speciﬁc model could not be found or set up with “/”. For German\nand French, we provide a human estimate of the precision («P).\nlng\nXLM-R base\nXLM-R large\nMT (train)\nMT (test)\n#\nP\nR\n#\nP\nR\n«P\n#\nP\nR\n#\nP\nR\nar\n405 0.768 0.587\n394 0.866 0.629\n/\n624 0.761 0.710\n331 0.900 0.562\nbg\n449 0.808 0.686\n439 0.882 0.735\n/\n452 0.799 0.722\n388 0.889 0.670\nde\n494 0.783 0.686\n465 0.872 0.740 0.780\n560 0.830 0.792\n399 0.880 0.660\nel\n488 0.777 0.667\n446 0.860 0.726\n/\n431 0.813 0.670\n382 0.895 0.655\nen\n488 0.831 0.795\n509 0.890 0.843\n/\n521 0.907 0.874\n521 0.907 0.874\nes\n462 0.804 0.723\n462 0.893 0.740\n/\n505 0.811 0.774\n393 0.896 0.705\nfr\n512 0.780 0.737\n460 0.881 0.741 0.810\n480 0.875 0.791\n386 0.884 0.692\nhi\n383 0.746 0.532\n383 0.841 0.607\n/\n620 0.575 0.644\n268 0.847 0.446\nru\n438 0.781 0.665\n411 0.882 0.663\n/\n465 0.784 0.703\n356 0.884 0.611\nsw\n407 0.657 0.580\n371 0.812 0.560\n/\n/\n/\n/\n242 0.841 0.380\nth\n381 0.815 0.544\n387 0.851 0.644\n/\n/\n/\n/\n302 0.867 0.499\ntr\n405 0.764 0.619\n367 0.865 0.662\n/\n466 0.793 0.724\n331 0.878 0.569\nur\n307 0.760 0.449\n358 0.823 0.531\n/\n/\n/\n/\n244 0.837 0.384\nvi\n374 0.785 0.649\n380 0.863 0.650\n/\n563 0.762 0.645\n278 0.866 0.531\nzh\n419 0.784 0.610\n407 0.854 0.640\n/\n597 0.778 0.736\n349 0.893 0.567\nThe results indicate that the proposed approach is effective even in the cross-lingual setting and produces valuable\nparaphrasing datasets. Below we analyze their properties.\nWhile the number of extracted paraphrases is fairly similar across most languages, the cross-lingual models do not\nperform equally well across all languages, as indicated by the precision and recall of these models. Differences between\nlanguages are present also for stricter decision thresholds. A further cause of errors is translations. While all datasets are\ntranslated from the same English originals, the translations are not necessarily direct and unambiguous. For example, “I\nhave a problem with a mole” can mean a problem due to skin growth or caused by an animal, and can get different\ntranslations due to the assumed meaning. To illustrate the variance of the extracted paraphrases in the cross-lingual\nsetting, we counted the overlapping paraphrases for the XLM-R-large model with the argmax threshold. Across all\n15 languages, there are a total of 898 unique paraphrases, of which 47 are common across all languages, and 330 are\ncommon across at least 10 languages.\nThe results of manual validation show that the paraphrases extracted using a cross-lingual approach are also of good\nquality. For the two settings we validated (German and French), we found that approximately 80% of the extracted\nparaphrases are correct.\nIn addition to cross-lingual approach, we tested two common translation baselines “translate-train” and “translate-test”\n[5]. The “translate-train” generally extracts more paraphrases than the cross-lingual models, while the reverse is true for\nthe “translate-test” approach. We hypothesize this is due to the noise introduced by machine translation. In “translate-\ntrain”, the training sequences are translated into the target language. The low quality of some translations causes that\nthe models learn noisy patterns and extract more paraphrases from the validation and test set. In “translate-test”, the\nsituation is reversed. The model learns from higher-quality English instances, while the machine-translated validation\nand test instances are less coherent and less likely classiﬁed as paraphrases. For example, the German sentence “Was\nsuper ist am Leben auf dem Land, ist dass man sich nicht über solche Dinge ärgern muss.” gets incorrectly translated\ninto “What’s great about life in the country is that you don’t have to tease about such things.” (instead of “be upset”),\nwhich decreases the entailment probability in this instance. Due to the sources of noise that are hard to account for, we\nwarn against the sole use of translation baselines in XNLI. The cross-lingual models present a strong alternative and\nmay be used alone or in an ensemble mode.\n7\nA PREPRINT - NOVEMBER 16, 2021\nTable 3: The number of ﬁltered paraphrases (#), precision (P), recall (R) and manually estimated precision («P) in\nQQP and MRPC datasets using three different decision thresholds for the non-paraphrase label. Below the dataset name\nwe show the number of paraphrase instances in the dataset.\ndataset\ndecision\nroberta-base\nroberta-large\n(size)\nthreshold\n#\nP\nR\n«P\n#\nP\nR\n«P\nQQP\n(149 263)\nargmax\n13471\n0.934\n0.834\n0.940\n13426\n0.937\n0.884\n0.910\nT=0.75\n4084\n0.978\n0.727\n0.940\n5865\n0.967\n0.821\n0.920\nT=0.90\n1285\n0.991\n0.622\n0.950\n2363\n0.985\n0.748\n0.960\nMRPC\n(3900)\nargmax\n230\n0.854\n0.718\n0.900\n213\n0.832\n0.796\n0.860\nT=0.75\n157\n0.882\n0.649\n0.920\n148\n0.859\n0.746\n0.950\nT=0.90\n83\n0.913\n0.542\n0.960\n100\n0.880\n0.670\n0.940\n4.4\nFiltering existing paraphrases\nUsing the methodology described in Section 3.2, we cleaned two existing paraphrasing datasets (QQP and MRPC)\ndescribed in Section 4.1. Table 3 shows the number of ﬁltered-out paraphrases from QQP and MRPC datasets and\na manual estimate of their precision. As in our paraphrase extraction experiments, we report the results using three\ndecision boundaries, but now the thresholds apply to probabilities of non-paraphrase labels.\nOur method removes a relatively high amount of false paraphrases for both datasets, considering both datasets are\nwell-known and popular paraphrase identiﬁcation datasets. This conﬁrms recent ﬁndings in other machine learning\nareas [21], where analyses have shown relatively high noise levels with possibly detrimental consequences.\nThe false paraphrases in QQP are often a consequence of using questions with the same intent but not necessarily\nidentical concepts, as mentioned in Section 3.2. In MRPC, the false paraphrases are due to relaxed annotation guidelines\nof what is to be considered a paraphrase. Dolan and Brockett [9] mention that their dataset intentionally contains\nsentence pairs that semantically differ to an extent, a choice made to increase the diversity of paraphrases. If a dataset\nuser does not agree with this loose approach or wishes to treat such instances differently, our method can automatically\nﬁnd at least some of them.\nSimilarly to Table 1, the results in Table 3 also show that a more strict decision boundary leads to less ﬁltered-out\nparaphrases. However, these are more likely to be false paraphrases.\nThe results of manual validation show that the ﬁltered-out paraphrases are, in most cases, actual non-paraphrases.\nThe ﬁltered-out paraphrases typically contain more than 90% of actual non-paraphrases. Qualitative analysis of the\nﬁltered-out instances shows that they are often similarly structured, with one of the sequences containing additional\ninformation that is not present in the other sequence, making the pair semantically non-equivalent. Among the\nerroneously ﬁltered-out paraphrases, we ﬁnd that some are ﬁltered due to too strict NLI models. For example, when\nprocessing the pair “What are CoCo bonds?” and “What is a coco bond?”, the model decides that the two sentences are\nnot paraphrases, likely because one is talking about bonds (plural) and the other is talking about a bond (singular). In a\nsemantic sense, this pair shall be declared a paraphrase.\n5\nConclusion\nWe have proposed a novel paraphrases extraction approach based on the similarity between NLI and paraphrasing.\nResults show that the proposed methodology can effectively extract paraphrases from NLI datasets both in the\nmonolingual and cross-lingual setting. Furthermore, the proposed ﬁltering demonstrates a surprisingly large amount of\nnoise in the existing paraphrasing datasets. In summary, the proposed method enables the reuse of NLI resources and\nprovides additional quality assurances for paraphrasing.\nIn further work, we plan to extend the analysis of extracted paraphrases and test their use in downstream tasks. For\nexample, different decision thresholds and different qualities of paraphrases might be helpful in different applications –\nto favour either logical equivalence or variability of sentences.\nAdditionally, there is a potential to leverage further connections between NLI and other tasks. For example, text\nsummarization instances could possibly be obtained from NLI datasets by extracting sequence pairs where entailment\nholds in one direction, while the instances are neutral in the other direction. Another more difﬁcult task would be to\nextract NLI instances from existing paraphrasing datasets, i.e. going in the reverse direction of the presented one.\n8\nA PREPRINT - NOVEMBER 16, 2021\nAcknowledgements\nFor the evaluation of French paraphrases we are grateful to Jožica Robnik-Šikonja. The work was partially supported\nby the Slovenian Research Agency (ARRS) through the core research programme P6-0411, projects J6-2581 and\nJ7-3159, as well as the young researcher grant. This paper is supported by European Union’s Horizon 2020 research\nand innovation programme under grant agreement No 825153, project EMBEDDIA (Cross-Lingual Embeddings for\nLess-Represented Languages in European News Media).\n9\nA PREPRINT - NOVEMBER 16, 2021\nReferences\n[1] Ion Androutsopoulos and Prodromos Malakasiotis. A survey of paraphrasing and textual entailment methods.\nJournal of Artiﬁcial Intelligence Research, 38(1):135–187, May 2010. ISSN 1076-9757.\n[2] Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large annotated corpus\nfor learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in\nNatural Language Processing, pages 632–642, Lisbon, Portugal, September 2015. Association for Computational\nLinguistics. doi: 10.18653/v1/D15-1075. URL https://www.aclweb.org/anthology/D15-1075.\n[3] Jifan Chen, Eunsol Choi, and Greg Durrett. Can NLI models verify QA systems’ predictions? In Findings\nof the Association for Computational Linguistics: EMNLP 2021, pages 3841–3854, Punta Cana, Dominican\nRepublic, November 2021. Association for Computational Linguistics. URL https://aclanthology.org/\n2021.findings-emnlp.324.\n[4] Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Dollar, and C. Lawrence\nZitnick. Microsoft COCO captions: Data collection and evaluation server, 2015.\n[5] Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman, Holger Schwenk, and Veselin\nStoyanov. XNLI: Evaluating cross-lingual sentence representations. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing, pages 2475–2485, Brussels, Belgium, October-November\n2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1269. URL https://www.aclweb.\norg/anthology/D18-1269.\n[6] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán,\nEdouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. Unsupervised cross-lingual representation\nlearning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,\npages 8440–8451, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.\n747. URL https://www.aclweb.org/anthology/2020.acl-main.747.\n[7] Mathias Creutz. Open subtitles paraphrase corpus for six languages. In Proceedings of the Eleventh International\nConference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan, May 2018. European\nLanguage Resources Association (ELRA). URL https://www.aclweb.org/anthology/L18-1218.\n[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional\ntransformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short\nPapers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi:\n10.18653/v1/N19-1423. URL https://www.aclweb.org/anthology/N19-1423.\n[9] William B. Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases. In\nProceedings of the Third International Workshop on Paraphrasing (IWP2005), 2005. URL https://www.\naclweb.org/anthology/I05-5002.\n[10] Desmond Elliott, Stella Frank, Khalil Sima’an, and Lucia Specia. Multi30K: Multilingual English-German image\ndescriptions. In Proceedings of the 5th Workshop on Vision and Language, pages 70–74, Berlin, Germany, August\n2016. Association for Computational Linguistics. doi: 10.18653/v1/W16-3210. URL https://www.aclweb.\norg/anthology/W16-3210.\n[11] Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. PPDB: The paraphrase database. In\nProceedings of the 2013 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages 758–764, Atlanta, Georgia, June 2013. Association for\nComputational Linguistics. URL https://www.aclweb.org/anthology/N13-1092.\n[12] Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman, and Noah A. Smith.\nAnnotation artifacts in natural language inference data. In Proceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2\n(Short Papers), pages 107–112, New Orleans, Louisiana, June 2018. Association for Computational Linguistics.\ndoi: 10.18653/v1/N18-2017. URL https://www.aclweb.org/anthology/N18-2017.\n[13] Sanda Harabagiu and Andrew Hickl. Methods for using textual entailment in open-domain question answering.\nIn Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of\nthe Association for Computational Linguistics, pages 905–912, Sydney, Australia, July 2006. Association for\nComputational Linguistics. doi: 10.3115/1220175.1220289. URL https://www.aclweb.org/anthology/\nP06-1114.\n[14] Wuwei Lan, Siyu Qiu, Hua He, and Wei Xu. A continuously growing dataset of sentential paraphrases. In\nProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1224–1234,\n10\nA PREPRINT - NOVEMBER 16, 2021\nCopenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1126.\nURL https://www.aclweb.org/anthology/D17-1126.\n[15] Vladimir Levenshtein. Binary Codes Capable of Correcting Deletions, Insertions and Reversals. Soviet Physics\nDoklady, 10:707, 1966.\n[16] Hector J. Levesque, Ernest Davis, and Leora Morgenstern. The Winograd schema challenge. In Proceedings of\nthe Thirteenth International Conference on Principles of Knowledge Representation and Reasoning, KR’12, page\n552–561. AAAI Press, 2012. ISBN 9781577355601.\n[17] Dekang Lin and Patrick Pantel. Dirt - discovery of inference rules from text. In Proceedings of the Seventh ACM\nSIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’01, page 323–328, 2001.\nISBN 158113391X. doi: 10.1145/502512.502559.\n[18] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pretraining approach. arXiv preprint\narXiv:1907.11692, 2019.\n[19] Elena Lloret, Óscar Ferrández, Rafael Muñoz, and Manuel Palomar. A text summarization approach under the\ninﬂuence of textual entailment. In Bernadette Sharp and Michael Zock, editors, Natural Language Processing and\nCognitive Science, Proceedings of the 5th International Workshop on Natural Language Processing and Cognitive\nScience, NLPCS 2008, pages 22–31. INSTICC Press, 2008.\n[20] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Conference on\nLearning Representations, 2019. URL https://openreview.net/forum?id=Bkg6RiCqY7.\n[21] Curtis G Northcutt, Anish Athalye, and Jonas Mueller. Pervasive label errors in test sets destabilize machine\nlearning benchmarks. arXiv preprint arXiv:2103.14749, 2021.\n[22] Sebastian Padó, Michel Galley, Dan Jurafsky, and Christopher D. Manning. Robust machine translation evaluation\nwith entailment features. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL\nand the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 297–305,\nSuntec, Singapore, August 2009. Association for Computational Linguistics. URL https://www.aclweb.org/\nanthology/P09-1034.\n[23] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions for machine\ncomprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language\nProcessing, pages 2383–2392, Austin, Texas, November 2016. Association for Computational Linguistics. doi:\n10.18653/v1/D16-1264. URL https://www.aclweb.org/anthology/D16-1264.\n[24] James Thorne, Andreas Vlachos, Oana Cocarascu, Christos Christodoulopoulos, and Arpit Mittal. The fact\nextraction and VERiﬁcation (FEVER) shared task. In Proceedings of the First Workshop on Fact Extraction and\nVERiﬁcation (FEVER), pages 1–9, Brussels, Belgium, November 2018. Association for Computational Linguistics.\ndoi: 10.18653/v1/W18-5501. URL https://www.aclweb.org/anthology/W18-5501.\n[25] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE: A multi-\ntask benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP\nWorkshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353–355, Brussels, Belgium,\nNovember 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5446. URL https://www.\naclweb.org/anthology/W18-5446.\n[26] Aaron Steven White, Pushpendre Rastogi, Kevin Duh, and Benjamin Van Durme. Inference is everything: Recast-\ning semantic resources into a uniﬁed evaluation framework. In Proceedings of the Eighth International Joint Confer-\nence on Natural Language Processing (Volume 1: Long Papers), pages 996–1005, Taipei, Taiwan, November 2017.\nAsian Federation of Natural Language Processing. URL https://www.aclweb.org/anthology/I17-1100.\n[27] Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sentence understand-\ning through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112–1122, New\nOrleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1101. URL\nhttps://www.aclweb.org/anthology/N18-1101.\n[28] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric\nCistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma,\nYacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,\nand Alexander Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020\nConference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45,\nOnline, October 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-demos.6. URL\nhttps://www.aclweb.org/anthology/2020.emnlp-demos.6.\n11\nA PREPRINT - NOVEMBER 16, 2021\n[29] Sander Wubben, Antal van den Bosch, and Emiel Krahmer. Paraphrasing headlines by machine translatio:\nSentential paraphrase acquisition and generation using Google News. In Computational Linguistics in the\nNetherlands 2010, pages 169–183. LOT, 2011.\n[30] Wei Xu, Alan Ritter, Chris Callison-Burch, William B. Dolan, and Yangfeng Ji. Extracting lexically divergent\nparaphrases from Twitter. Transactions of the Association for Computational Linguistics, 2:435–448, 2014. doi:\n10.1162/tacl_a_00194. URL https://www.aclweb.org/anthology/Q14-1034.\n[31] Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. PAWS-X: A cross-lingual adversarial dataset for\nparaphrase identiﬁcation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages\n3687–3692, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/\nD19-1382. URL https://www.aclweb.org/anthology/D19-1382.\n[32] Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier. From image descriptions to visual denotations:\nNew similarity metrics for semantic inference over event descriptions. Transactions of the Association for\nComputational Linguistics, 2:67–78, 2014. doi: 10.1162/tacl_a_00166. URL https://www.aclweb.org/\nanthology/Q14-1006.\n[33] Yuan Zhang, Jason Baldridge, and Luheng He. PAWS: Paraphrase adversaries from word scrambling. In\nProceedings of the 2019 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1298–1308, Minneapolis,\nMinnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1131. URL https:\n//www.aclweb.org/anthology/N19-1131.\n12\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2021-11-13",
  "updated": "2021-11-13"
}