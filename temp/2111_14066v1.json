{
  "id": "http://arxiv.org/abs/2111.14066v1",
  "title": "Natural Language and Spatial Rules",
  "authors": [
    "Alexandros Haridis",
    "Stella Rossikopoulou Pappa"
  ],
  "abstract": "We develop a system that formally represents spatial semantics concepts\nwithin natural language descriptions of spatial arrangements. The system builds\non a model of spatial semantics representation according to which words in a\nsentence are assigned spatial roles and the relations among these roles are\nrepresented with spatial relations. We combine our system with the shape\ngrammar formalism that uses shape rules to generate languages (sets) of\ntwo-dimensional shapes. Our proposed system consists of pairs of shape rules\nand verbal rules where the verbal rules describe in English the action of the\nassociated shape rule. We present various types of natural language\ndescriptions of shapes that are successfully parsed by our system and we\ndiscuss open questions and challenges we see at the interface of language and\nperception.",
  "text": "Natural Language and Spatial Rules $\nAlexandros Haridisa, Styliani Rossikopoulou Pappab\naPhD Student, Department of Architecture, MIT\nbGraduate Student, Master in Design Studies, Harvard Graduate School of Design\nAbstract\nWe develop a system that formally represents spatial semantics concepts within natural\nlanguage descriptions of shapes given in text. The system builds upon a model of spatial\nsemantics representation according to which words in a sentence are assigned spatial roles\nand the relations among these roles are represented with spatial relations. We combine our\nsystem with the shape grammar formalism that uses shape rules to generate arrangements\nof shapes. Our proposed system then consists of pairs of shape rules and verbal rules where\nverbal rules describe in natural language the action of a corresponding shape rule.\nWe\npresent various types of natural language descriptions of shapes that are successfully parsed\nby our system and we discuss open questions and challenges.\nKeywords:\nSpatial semantics, verbal description, shape rules\n1. Introduction\nNatural language is generally recognized as one of the important human faculties capable of\nexpressing spatial information and visual material [1, 2, 3, 4, 5, 6, 7]. Language provides\nverbal tools for the schematization of space and for describing the visual appearance or\nstructural characteristics of perceived objects [4, 8, 9, 7]. A number of questions arise in\nthis regard. Can natural language substitute for perceptual information? What are some\nof the situations where this may indeed happen? What are some of the cases where such a\ntask is impossible? In this project, we propose to investigate this interface between natural\nlanguage and perception of visual material and to evaluate whether, and to what extent,\nsensory and linguistic stimuli support the formation of equivalent spatial representations.\nThis present write up is organized in the following way. Section 1 continues with an\noverview of selected literature on research conducted from a variety of knowledge areas and\ndisciplines on the interface between natural language and perception of visual-spatial mate-\nrial. In Section 1.2, we describe our methodology by brieﬂy explaining the basic elements\n$Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science,\n6.863J/9.611J Natural Language Processing\nEmail addresses: charidis@mit.edu (Alexandros Haridis), spappa@gsd.harvard.edu (Styliani\nRossikopoulou Pappa)\nFinal-course checkin for 6.863 Final Project\nMay 16, 2018\narXiv:2111.14066v1  [cs.CL]  28 Nov 2021\nof our computational approach and we outline the intended contributions of our project.\nIn Section 2, we describe a model of spatial semantics representation that we have used to\nbuild our system. In section 3, we brieﬂy describe shape grammars and how shape rules\nare deﬁned and used to generate languages of shapes. In section 4, we give a motivating\nexample that illustrates how shape rules are combined with verbal rules to build natural\nlanguage descriptions of arrangements of shapes and their corresponding spatial semantic\nrepresentation. In section 5, we outline the formal spatial semantics representation based on\nthe lambda calculus method and show various examples that illustrate the capabilities of our\nsystem. In section 6, we discuss open questions, challenges and interesting observations we\nmade throughout the development of this project. Finally, we provide an Appendix section\nwith supporting material.\n1.1. Background\nThe study of verbal descriptions for spatial material, such as shapes, diagrams, pictures,\ndrawings, physical objects, physical spaces, and so on, can be divided into two broad di-\nrections: verbal descriptions that attempt to capture space (that is, physical space, an\nenvironment, a natural scene, and so on), and verbal descriptions that attempt to capture\nobject (that is, a physical-material object, an entity in a scene, objects in an environment,\nshapes in pictures, and so on). While in our project we exclusively focus on the second type\nof verbal descriptions, in this background section we cover both types because we judge\nthat it is important to have a good sense of what kind of work has been conducted at the\ninterface between natural language descriptions and perception of visual-spatial material.\nIn the literature of experimental psychology, we very commonly ﬁnd studies that examine\nlinguistic representations of physical environments.\nA classic example is the 1975 work\nof [10] who asked New Yorkers to answer the question, ”Could you tell me the lay-out of\nyour apartment?” The majority of the participants in their study gave verbal descriptions\nbased on imaginary tours through their apartment. In general, we may distinguish three\ncommon ways of experiencing a certain environment with the purpose of constructing a\nverbal description of it: walking through the environment or route description; standing in\none place in the environment or gaze tour description; viewing the environment ’from above’\nor survey perspective. This classiﬁcation is given in [4]. An important point worth raising\nis that physical environments (like an apartment) are multi-dimensional. Not only because\nthey are entities in a three-dimensional world but also because they can be characterized\nin terms of a variety of things, such as geometry, color, materials, light, etc. However, no\nmatter the environment picked, the linguistic representation of the environment has to be\ninherently one dimensional [4, 11, 12]. That is to say, if someone wants to construct a verbal\ndescription of a physical environment (and indeed of any physical object in general) then\none needs to linearize space into language or in other words one needs to lexicalize space\nin the terms of a one-dimensional representational system, namely, natural language. This\nimportant aspect of natural language holds a central place in our project where we attempt\nto build natural language descriptions of the appearance of shapes, of how a given shape or\narrangement of shapes ’looks’. In this respect, some of the questions that arise are, which\naspects of an object come ﬁrst in a linearized description of the object? Which aspects are\n2\nemphasized at the expense of ignoring others? Why is one description better than another?\nCan there even be an adequate description of the object?\nThe connections between formal models of computation of space, and ’space’ as it oc-\ncurs in language are themselves a matter of intense research activity. This is particularly\nevident in the computer science disciplines concerned with the investigation of an artiﬁcial\nintelligence capable of ’talking’ about space or about perceived objects within space. For\nexample, [7] develop an architectural design assistant with a broader focus to examine the\nrelationship between the conception, formalization, and the computational aspects of space\nas it occurs within systems of human assistance. Such systems are meant to know the prop-\nerties of physical space and are skilled in dealing with the spaces they ’know’ in such a way so\nthat they support humans, such as interior space designers, engineers, media designers, and\nso on [7]. The relationship between language and perception of visual-spatial material was\nof great interest already in the 1970s when the ﬁrst artiﬁcial intelligence programs started\nto emerge. For example, Winograd’s system [9] was a system that could understand ver-\nbal instructions in English about speciﬁc spatial tasks within a ’blocks-world’ setting, such\nas ”pick up a big red block” or ”what is the pyramid supported by?”. Winston’s system\n[13] was building and understanding descriptions of physical objects such as an ”arch” or\na ”house” and it used a form of spatial language where relations between objects where\nmodeled using notions, such as left-of, on-top-of, part-of, behind. Another early work was\nthe system of Boberg\n[14], which was an early attempt to build a machine ’envisioner’\nthat could understand verbal descriptions of spatial objects and draw the described objects.\nLike Winograd’s system, Boberg’s system was also situated within a ’block’s world’. In our\nproject, we focus not on a block’s world where objects have predeﬁned geometric and/or\nmaterial characteristics but we focus on shapes and arrangements of shapes whose visual\nappearance is ambiguous and no predeﬁned set of component parts exists. This interface\nbetween perception and natural language still holds an important role (and largely open)\nin artiﬁcial intelligence. This can be seen from many recent attempts to create artiﬁcial\nintelligence systems that can describe images as humans do. This task is mainly approached\nfrom an engineering standpoint and typical tasks involved in research are image captioning\nand annotation, question answering, and recognition and description of objects and rela-\ntionships among them. For example, two recent eﬀorts towards these ends are the Visual\nGenome dataset in [15], a large dataset that aims to connect language and vision by gather-\ning dense image annotations via crowdsourcing, and CLEVR [16], a dataset that is aimed at\nsupporting systems in elementary visual reasoning tasks with an emphasis on compositional\nreasoning (i.e. the ability to understand how a complex scene is composed out of simpler\nparts).\nThe importance of language in describing visual-spatial material has been recognized in\ndesign research in architecture and the visual arts. For example, the now classic (self)study\nof artist Paul Klee [17] shows very clearly that verbal descriptions are important for ped-\nagogical purposes, in particular, in how to teach someone to talk about the visual, spatial\ncharacteristics of a painting or of any type of aesthetic object. Language-enabled descrip-\ntions are pervasive in architectural design education and in particular in the studio culture as\nthe analytical study of [18] shows. In the more formal, computational approaches towards\n3\ndesign,\n[19] and\n[20] have shown how the shape of aesthetic objects, such as buildings,\npaintings, designs, can be computed with a shape grammar and how the spatial character-\nistics of these objects can be described using special forms of description grammars. In our\nproject we use the shape grammar formalism because it enables us to describe arrangements\nof shapes in a visual manner through shape rules (see section 2).\nOther relevant work to our project, is the research conducted on spatial semantics [21,\n22, 23] where the goal is to understand spatial expressions in natural language. Two of\nthe most common notions in terms of which spatial language is formalized is topology\nand orientation. There exist special forms of calculus systems that compute topological\nrelations between geometric objects called regions [24] and these relations are represented\nby prepositions in language.\nWork conducted towards this direction aims at developing\nsystems that can infer spatial relations between either abstract or real objects in scenes by\nreading a natural language description in text. The systems then are able to annotate the\ngiven sentences by inferring spatial prepositions, actors, trajectors, and other thematic roles.\nSome recent work conducted in this direction from which we take inspiration in this project\nare\n[22, 23, 25]. Special forms of natural language have been also developed in order to\ndescribe more speciﬁc spatial phenomena, such as for example how language may capture\nthe way spatial entities interact with respect to force [8], or how language may be used to\ndescribe movement [24].\n1.2. Project Summary and Intended Contributions\nIn this project, we develop i) a model of spatial semantics representation that interprets a\nsentence given in text according to basic spatial semantics concepts; ii) a methodology for\ncombining shape rules and verbal rules for the generation of speciﬁc languages of shapes as\nwell as the generation of corresponding verbal descriptions; and iii) an implementation of our\nmodel based on a rule-to-rule association of context-free rules and lambda calculus forms.\nWith this project, our goal is to highlight some of the limitations of language to capture\nvisual-spatial phenomena that a human ’eye’ would capture with no particular diﬃculty.\nTo show some of the challenges that one may face when approaching the task of capturing\nspatial semantics concepts from a given natural language description in text. Finally, to\ndemonstrate the elements of a system that successfully captures spatial roles and spatial\nrelations among them and associates them with a visual arrangement of shapes.\n2. Spatial Semantics Concepts\n2.1. Verbal description styles: constructive and ’from-above’\nGiven an arrangement of shapes, there are at least the following two verbal description\nstyles that one may follow to construct a natural language description of the arrangement:\nconstructive and ’from above’. A constructive description tells how the arrangement can be\nconstructed, i.e. drawn on a paper, in a step by step manner. A constructive description\nis diﬀerent from a ‘perspective′ or ‘from −above′ description according to which one de-\nscribes an arrangement in a static way, emphasizing certain perceived parts. From-above\n4\ndescriptions have a declarative nature; they are meant to tell how things are. Constructive\ndescriptions tell how things can be derived in a step by step manner.\nIn our project, we only consider speciﬁc classes of arrangements of shapes (see sections\n3 and 4).\nFor each arrangement of shapes, we have built an associated grammar that\nconsists of shape rules and corresponding verbal rules. These grammars provide, almost\nnaturally, a framework for generating constructive descriptions of arrangements of shapes.\nHowever, the two description styles, namely, constructive and from-above, can be easily\nconverted to one another. In particular, constructive descriptions can be characterized as\nverb phrases that always start with an action verb, such as ’add’, ’put’, or ’draw’. From-\nabove descriptions make use of ’is’ to declare a fact or assertion. Hence, one may convert\na from-above description to a constructive description by simply adding an action verb\nand removing all existential verbs like ’is’. To give an example, consider the from-above\ndescription,\n“the square is next to the rectangle.”\nThis sentence can be converted into a constructive description in a straightforward way, like\nso,\n“add the square next to the rectangle.”\nWe could likewise use the verbs ’draw’ or ’put’ (or similar ones). In our formal spatial seman-\ntics representation (section 5), we handle both description styles although their underlying\nstructures (and in particular, their event structures) do not diﬀer much as expected.\n2.2. Basic spatial semantics concepts\nSpatial semantics concepts are intermediaries between perception and natural language.\nThey provide cross-linguistic spatial concepts for specifying how entities in (two or three\ndimensional) space are arranged. We use spatial semantics concepts mainly as a general\nframework for organizing the spatial roles that the words in a verbal description sentence\nplay and how these spatial roles are related to one another within the sentence. The content\nof this subsection draws from a variety of sources, in particular [1, 21, 22, 23, 24, 26, 27]. In\nour system, we use the following basic spatial semantics concepts:\nTrajector: an entity whose location or motion is of relevance in the description. It can be\nan object, like a shape, a geometric attribute of the shape, such as an edge or a corner, or\nit can be itself an event. In psychology, the trajector is sometimes called the ’ﬁgure’ or the\n’referent’.\nLandmark: a reference entity in relation to which the location or the movement of the\ntrajector is speciﬁed. In psychology, the landmark is sometimes called the ’ground’ or the\n’relatum’.\n5\nFrame of reference: a linguistic concept that speciﬁes certain reference points or even a\ncoordinate system based on axes and angles. An object can be a frame of reference, such as\nthe landmark. In English, there are three lexicalized frames of reference: relative, absolute\nand intrinsic [27]. An absolute frame of reference, for example, can be the geolocation of an\nobject with respect to the north or south pole. In our project, we are interested in describing\nspatial arrangements and more speciﬁcally to specify a shape with respect to another shape\nor with respect to an attribute of a shape. Thus, we exclusively use a relative frames of\nreference. In our case, the frame of reference in each description sentence is implied by the\nspatial roles of the trajector and the landmark along with a directional system (see below).\nDirection: speciﬁes directional relations with respect to a frame of reference. Frames of\nreference in our description sentences are relative and are always implied by the spatial roles\nof the trajector and the landmark. We only use the following relative directions { left, right,\ntop,bottom }. It is of course assumed that by, for example, ’left edge’ we mean the edge of\nthe shape that is to the left with respect to a viewer that looks at the shape drawn on the\ntwo dimensional plane.\nSpatial locator: a non-projective, locative preposition that describes the spatial relation\nbetween the trajector and the landmark. It takes the following values { ’at,’ ’in,’ ’on’ }.\nThe meaning of a spatial locator is also represented in more detail by a topological relation,\nwhich we call ’region’ (see below).\nRegion: a concept that denotes a topological relation that deﬁnes how a trajector, or more\ngenerally some region of space, is related to a landmark. The values of a region may denote\nconcepts, such as contiguity, parthood, inclusion, overlap, and others. These values are\ndenoted more elaborately using the rules of the RCC8 regional calculus [26]. We use the\nfollowing three types of relations from RCC8:\nY\nX\nX  TPP Y\nX\nY\nX  EC Y\nY\nX\nX  NTPP Y\nEach regional relation above has a logical speciﬁcation. More speciﬁcally, according to [26],\na predicate Connect(x, y) evaluates to true if the objects x and y are connected in some way,\nin our case, if shapes x and y ’touch’; it evaluates to false when x and y are not connected in\nsome way, i.e. shapes x and y do not touch. Parthood relation is expressed in the following\nway. Part(x, y) evaluates to true if and only if for every z, Connect(z, x) implies Connect(z,\ny). Now we can deﬁne overlap. Overlap(x, y) evaluates to true if there exists a z, such that\nPart(z, x) evaluates to true and Part(z, y) evaluates also to true.\nThe relation of overlap can be easily expressed with shape arithmetic: two shapes overlap\nif they share some part. As a simple illustration, consider the following Figure:\n6\na\na • b\na • b\na • b\na + b\na + b\na + b\nb\nThe Figure shows two shapes, labelled a and b (mainly for ease of reference). In general, two\nshapes may be put together in many diﬀerent ways (in fact, inﬁnitely many). In the Figure\nwe only show two such ways. With shapes, the result of adding one shape onto the other can\nbe represented with the arithmetic operation of sum, that is, a + b. The Figure thus shows\nthree ways of adding shape b to a (or the converse), such that the two shapes overlap. Now,\nthe overlapping part is simply the multiplication of the two shapes, which computes the\ncommon part. Therefore, for all the above three cases, the predicate Overlap(a, b) would\nevaluate to true.\nUsing connect, parthood and overlap, we may deﬁne new regional relations. In particular,\nwe deﬁne the three relations EC, TPP, and NTPP (as shown in the previous Figure). EC(x,\ny) means that x is externally connected to y, if Connect(x, y) evaluates to true and Overlap(x,\ny) is not true. TPP(x, y) means that x is a tangential propert part of y, and NTPP(x, y)\nmeans that x is non-tangential propert part of y (we choose to omit their logical forms\nbecause they can be derived in a straightforward way, but the interested reader may refer to\n[26]). English spatial prepositions ’at’, ’in’, ’on’ can be mapped to regional relations. To do\nso, we follow [24]. The preposition ’at’, when used spatially denotes a trajector object that\ncoincides in some way with a landmark object, or that it tangentially overlaps some part of\nthe landmark object. Thus, ’at’ is mapped to {TPP, NTPP}. Using similar reasoning, the\npreposition ’on’ has a meaning of contiguity as well as it may function as a kind of support.\nFor example, ”the book is on the table”. Thus, ’on’ is mapped to {EC, TPP}. Similarly, the\npreposition ’in’ typically means that a trajector object is contained in a landmark object.\nOr it may denote enclosure. Thus, ’in’ is mapped to {EC, TPP, NTPP}. We should note at\nthis point that this mapping of spatial prepositions to regional relations is quite ambiguous\n(see [24] for relevant discussion). Nevertheless, we ﬁnd it useful to include this information\nin our system for purposes of completeness but also because it may have some further uses\nthat we shortly outline in the Discussion section.\nApart from the above spatial semantics concepts, we introduce two additional concepts that\nare speciﬁc to our project. When describing an arrangement of shapes, it is common to refer\nto attributes of shapes related to their geometry. For example, the sentence ”the right edge\nof shape1” makes explicit reference to the attribute ’edge’ of shape1, and more speciﬁcally,\namong the edges of shape1, it makes reference to the ’right’ edge. Other examples of shape\nattributes are ’midpoint’ and ’corner’. To handle sentences that make explicit reference to\n7\nshape attributes, we introduce the following semantic concepts:\nProperty of shape: this acts as an operator that applies to a shape object and extracts\ngeometric information about the shape. In our project, we use the following properties ‘edge’,\n‘midpoint’, ‘corner’. Properties can be combined with information about directionality to\ndistinguish, for example, between the four edges of a square.\nShape: a direct reference link to a shape entity in the given arrangement of shapes. This is\nnot a string or a structured representation, but the actual ‘picture’ of the referenced shape.\nWe denote referenced shapes in description sentences with angle brackets < ... >. When\nour grammar generates a sentence, the references to speciﬁc shapes from the arrangement\nare replaced with the actual pictures of the referent shapes (see section 4).\n3. Shape rules and verbal rules\n3.1. Shapes and shape rules\nA speciﬁc class of formal machines useful for generating arrangements of shapes are Shape\nGrammars (SG) [19]. A shape grammar is deﬁned with a set of shape rules. A shape rule\nhas the general form a →b, where a and b are not words (or symbols) but shapes. Shape\nrules generate arrangements of shapes that constitute a language. We give a few examples of\nlanguages of shapes for purposes of illustration. Consider the following pair of shape rules,\nr1 :\n(0,0)\n→\nr2 :\n(0,0)\n→\nThe label • is a registration mark that constraints the possible ways in which the shape\nrules may be applied. The ’red cross’ indicates a coordinate system relative to the shape (we\noften ignore this symbol, but it is always assumed). Before explaining further the underlying\nmechanisms, we show the language of shapes generated by the two shape rules above.\n,\n,\n,\n...\nA (shape) rule application works as follows. Let a →b be a rule and S an initial shape.\nFor a rule to be applicable to S, there must exist a transformation t that makes the shape\n8\nt(a) a subshape of S. The transformations that we deal with here are the Euclidean ones\naugmented with uniform scale. If a rule is applicable, then the new shape S’ is computed\nas follows: (S - t(a)) + t(b). We show the following step by step derivation (each rule\napplication starts in a diﬀerent row),\nr1 \ninitial shape \nሰ\nr1 \nሰ\nr1 \nሰ\nr1 \nሰ\nr1 \nሰ\nr2 \nሰ\nThe rule applications stop either when there is no other rule applicable or no label •. A more\nelaborate speciﬁcation of shape rules is the following, which indicates several properties of\nthe left and right hand shapes.\nr1 :\n(0,0)\n⟨ LHShape1L, trans1L, L1L ⟩\nwhere,\nLHShape1L    =  {l1, l2, l3, l4}\ntrans1L         =  T.M., coord. sys.\nL1L               =  set of labels, e.g. { • }\n⟨ RHShape1R, trans1R, L1R ⟩\nwhere,\nRHShape1R  =  LHShape1L  +  {l’1, l’2, l’3, l’4}\ntrans1R          =  T.M., coord. sys.\nL1R                =  set of labels, e.g. { • }\n→\nMore speciﬁcally, a labelled shape is a tuple ⟨shape, trans, L⟩, where shape is a list of\nlinear elements, trans is a coordinate system and a transformation matrix describing the\n9\ntranslation, rotation, and scale of the shape, and L is a list of labels associated with the\nshape; in this case, L simply consists of the label •. We show this more analytic speciﬁcation\nof shape rules in order to illustrate how one may go about implementing them. However,\nfrom now on we will only specify shape rules by showing only the left and right hand shapes\nand ignore the rest of the details.\nWe give two additional examples of shape rules and their associated languages of shapes.\nIn particular, the following shape rules,\nr1’ :\n→\nr2 :\n(0,0)\n→\ngenerate the language of shapes,\n,\n,\n,\n. . .\nand the next two shape rules,\nr3:\n→\nr4:\n→\ngenerate the language of shapes on the opposite page.\nThe chosen shape rules and their associated languages of shapes are characterized by a\ncertain visual simplicity. We have made this choice to simplify the cases we examine but\nalso because even with these simple arrangements of shapes the very task of describing them\nin natural language is a hard one. Thus, even with the chosen arrangements, we gain good\ninsights into some of the diﬃculties involved in connecting perception with natural language.\n3.2. Verbal rules\nIn this subsection we discuss the approach we take towards constructing natural language\ndescriptions for arrangements of shapes. Before we do so, however, it is important to em-\nphasize that when it comes to shapes, there exist several approaches that one can take to\n10\n,\n,\n,\n,\n.. .\nconstruct a description for the shapes. The most common description appears in Computer\nAided Design where shapes are always represented with certain primitives that have speciﬁc\ngeometric characteristics. For example, consider the following arrangement of shapes,\ncould be described as a set of three geometric primitives, two squares and one rectangle,\nwith speciﬁc sizes, i.e. {square1, square2, rectangle1}. The individual primitives could be\nfurther described with respect to their geometric characteristics, for example in the case\nof the rectangle {rectangle1, width = 1, length = 3}. Another possible way of describing\nshapes is by providing the sequence of rules that generate them, i.e., a procedural description.\nFor example, the following arrangements come with their respective procedural descriptions\n(rules r3 and r4 are given in subsection 3.1),\n,\n,\n,\n...\nr3 r4\nr3 r4 r3 r4 r3 r4 \n(r3 r4 )* r3\nr3 r4 r3 r4 r3 r4 r3\n11\nA geometric description and a procedural description are two common ways of describing\narrangements of shapes. However, none of the two is a natural language description. Fur-\nthermore, in the case of the procedural description, notice that the second arrangement and\nthe fourth arrangement have the same procedural description but their ’appearances’ are\ndiﬀerent. Our goal in this project is to instead construct natural language descriptions,\nparticularly in English, that capture semantically how an arrangement of shapes ’looks’; as\nif we were to describe the arrangement to a person on the phone.\nTo this end, we propose a system that works with both shape rules and, what we call,\nverbal rules. A shape rule shows visually how a shape is transformed to another shape by\nreplacement, addition, or subtraction. For example, rules r1, r1′, r3, r4 are additive rules;\nrule r2 is a replacing rule (these rules are shown in subsection 3.1). The right hand side of a\nshape rule always consists of a spatial relation between two shapes; it shows pictorially how\ntwo shapes are put together. A verbal rule describes in natural language the action of the\nshape rule. Consider the following pair {r1, v1}, where r1 is a shape rule and v1 is a verbal\nrule:\n <shape1>\nReference to:\nSHAPE    = \ne.g. <shape1>\nReference to:\nSHAPE    = \ne.g. <shape2>\nReference to:\nSHAPE    = \n“add <shape2> to <shape1>. \nthe upper left corner of <shape2> is \nat the midpoint of the right edge of \n<shape1> ”\nr1 :\nv1 :\n(0,0)\n→\n→\nA verbal rule has the general form v →w, where v and w are strings with references to\nspeciﬁc shapes taken from the corresponding shape rule. For example, < shape1 > and\n< shape2 > in the verbal rule v1 shown in the above ﬁgure are references to the squares in\nthe shape rule r1. The right hand side of a verbal rule always describes the spatial relation\nat the right hand side of its associated shape rule. The two are in correspondence.\nA shape rule and a verbal rule are applied in parallel. The shape rule generates the\narrangement of shapes visually, while the verbal rule describes the action of the shape rule,\nin eﬀect, describing the generated arrangement of shapes. Notice that in the above example\n12\nof a verbal rule, the right hand side consists of both a constructive (”add ... to...”) and a from-\nabove (”the... is...”) description. When a verbal rule is applied to create a natural language\ndescription of a shape or an arrangement of shapes, our system semantically interprets the\ngenerated description by following the basic spatial semantic concepts we outlined in section\n2. We describe the precise underlying mechanisms for how our system parses the natural\nlanguage description into spatial semantic concepts in section 5. Before we do so, however,\nwe motivate the reader with an example.\n4. A motivating example\nConsider once again the pair {r1, v1} shown in the previous section. Our system takes as an\ninput the natural language description generated by verbal rule v1. The system then assigns\nspatial roles to words using the spatial semantics concepts outlined in section 2. For the\ncase of the description generated by verbal rule v1, following is the semantic interpretation\nthat our system generates:\nunderlying semantic representation \ndescription sentence\n“[add (<shape2>,  <shape1>) ]ACTION . \n[ at [ upper_left [ corner (<shape2>)] ]TRAJECTOR, [ is ]EXIST,  \n[ midpoint [ right_edge_of <shape1> ] ]LANDMARK ]SPATIAL_LOCATOR . ”\n“add <shape2> to <shape1>. \nthe upper left corner of <shape2> is \nat the midpoint of the right edge of \n<shape1> .”\nThe system understands that the rule is ”additive” and that it adds < shape2 > to <\nshape1 >. The system then understands that at is the spatial locator that determines the\nspatial relation between the two shapes. Further, the system understands speciﬁc geometric\nattributes of < shape1 > and < shape2 > and assigns the corresponding spatial roles to the\ncorrect words. Once the various assignments of spatial roles are complete, the system has a\ncomplete semantic representation of the input description sentence.\nOne may wish to apply rules r1 and v1 multiple times, to obtain a derivation of ar-\nrangements of shapes and their associated verbal descriptions. In a derivation, the system\nreplaces the referenced links for < shape1 > and < shape2 > with the shapes that corre-\nspond to these references, and as a result, the generated descriptions consist of both words\nand pictures. The two-step derivation shown on the opposite page illustrates this idea. The\ngenerated descriptions work essentially like instructions; they explain in both a verbal and\na pictorial manner how the arrangement of shapes can be constructed, possibly by a human.\n5. Formal spatial semantics representation\n5.1. Semantic interpreter and internal representations\nOur system pairs context-free rules with lambda calculus procedures to generate a spatial\nsemantic interpretation of description sentences. We have a create a set of context-free rules\nthat generate descriptions of arrangements of shapes in natural language and we use lambda\n13\n“  add            to               . \nthe upper left corner of          is at the \nmidpoint of the right edge of               .”\n“  draw          .\nr1 \nv1 \nr1 \nሰ\nሰ\nv1 \nሰ\nሰ\n“  add            to               . \nthe upper left corner of          is at the \nmidpoint of the right edge of               .\nadd             to                   . \nthe upper left corner of           is at the midpoint \nof the right edge of                    .”\ncalculus compositionality to semantically interpret those sentences using the basic spatial\nconcepts we described in section 2. The complete list of rule-to-rule pairs (i.e. a context-free\nrule and its associated lambda calculus form) is given in the Appendix. In this section, we\nexplain the principal spatial semantic representations produced by our system using simple\ndescription sentences.\nThe system parses an input sentence using context-free rules and generates a parse\ntree; this parse tree is then passed to a semantic interpreter. The semantic interpreter is\nequipped with specialized lambda-calculus forms that we developed in order to speciﬁcally\nhandle spatial semantics concepts. The semantic interpreter traverses the parse tree in the\nlambda-calculus fashion and outputs, what we call, a spatial relation structure corresponding\nto a semantic interpretation of the spatial relations described in the sentence. The system\nmay also output an action structure; these are sentences that start with verbs which we\ndiscuss in more detail in the following pages. Both the spatial relation structure and the\naction structure follow certain templates (see below) with attribute-value pairs. They yield\na representation of the meaning conveyed in a given sentence regarding the spatial roles of\ndiﬀerent words and how these spatial roles are related with one another. We shall give a short\nexample to illustrate how our system generates a spatial semantic structure. Consider the\nfollowing from-above description sentence and its corresponding spatial semantic structure\ngenerated by our system,\n”shape1 is at shape2”\nSPATIAL_RELATION[’at’, \"SHAPE[’shape1’]\", ’ttp-nttp’,\n\"SHAPE[’shape2’]\", \"ACTION[’is’, ’present’]\"]\n14\nThe parse tree of this sentence is:\n(Start[]\n(S[]\n(NP[-pro, -wh] (SHAPE[] shape1))\n(VP[]\n(EXIST_VERB[] is)\n(PP[] (SP[] at) (NP[-pro, -wh] (SHAPE[] shape2))))))\nThe internal representation of the above spatial relation structure is based on the following\ntemplate:\nC(\"SPATIAL_RELATION\", relation=word, region=\"ttp-nttp\",\naction=action, trajector=trajector, landmark=landmark)\nIn essence, the spatial relation structure ”SPATIAL RELATION” plays the role of an\n”event” structure (as it is found in the standard lambda calculus approach to semantics).\nThe element that gives the principal meaning in a spatial relation structure is the preposition\n”at” (and respectively ”in” and ”on”). Spatial prepositions have the most complex lambda\ncalculus forms and they apply their meaning to the lambda forms of other elements in\na sentence. The spatial roles in the above structure are the trajector, the landmark, the\nspatial locator at, and the topological description region based on the regional calculus\ninterpretation of the spatial preposition at. Note that the existential verb is, in the above\nsentence, is not a spatial semantics concept. It is only a verb that denotes the existence\nof shape1 at shape2 (a sample trace of our system assigning spatial semantics role to the\nfrom-above description “shape1 is at shape2” can be found in the Appendix).\nSimilar to the spatial relation structure, we have an action structure ACTION. This\napplies to constructive sentences of the following form,\nadd shape1 to shape2\nACTION[’add’, \"SHAPE[’shape1’]\", \"SHAPE[’shape2’]\"]\nIn this case, the meaning of the sentence is determined by the action verb ”add” which\napplies its meaning to the other elements, namely, the trajector ”shape1” and the landmark\n”shape2”. Now consider the following more complex description sentence:\n“The upper left corner of shape2 is at the midpoint of the right edge of shape1.”\nSPATIAL_RELATION[’midpoint’, \"ACTION[’is’, ’present’]\",\n’ATTRIBUTE[\"ATTRIBUTE[’edge’]\", \"DIRECTION[’right’]\", \"SHAPE[’shape1’]\"]’,\n’ttp-nttp’, ’at’, ’DIRECTION[\"ATTRIBUTE[’corner’]\", ’upper’,\n\"DIRECTION[’left’]\", \"SHAPE[’shape2’]\"]’]\n15\nThis sentence contains some new spatial roles. Apart from the trajector, landmark, region,\nand spatial locator, there is the spatial concept of an attribute of a shape and the spatial\nconcept of a direction speciﬁc to the attribute. Here, again, the existential verb is is not\na spatial semantics concept. However, the two new spatial concepts, namely attribute and\ndirection, denote speciﬁc geometric properties of the two shapes, i.e. the trajector and the\nlandmark. attribute, as a spatial semantics concept, is a property of a shape, which in this\ncase is either an edge, a corner of a shape or a midpoint of an edge of a shape. direction\nstores the information about the directionality of the attributes of the shapes. For instance,\n”the right edge of shape1,” may be written in a functional form as right(edge(shape1)).\nGeometric attributes are made with a semantic category with the keyword ”ATTRIBUTE”\nand directions with a semantic category with the keyword ”DIRECTION”.\nA from-above description style can be converted to a constructive description style. For\nthe previous sentence, the constructive description is as follows,\n“Draw the upper left corner of shape2 at the midpoint of the right edge of shape1”\nIn general, our system accepts the following verbs that denote constructive descriptions: add,\ndraw, subtract, and replace; these actions correspond, in essence, to shape rules and some\nexamples are given in the next section. These action verbs are put at the start of every new\nsentence only. The words ”shape1” and ”shape2” are interpreted as lexical items that follow\na noun phrase NP, i.e. NP →SHAPE and SHAPE →shape1 | shape2 with a lambda\nprocedure corresponding to identity, and a semantic category with the keyword ”SHAPE”\nwhose value is determined with whatever shape happens to appear. The spatial prepositions\nin and on have the same spatial semantic structure as the preposition at. Note that we have\nomitted to include a special attribute-value pair for the spatial semantic concept frame of\nreference because in the examples we are interested in, shapes are always related with other\nshapes with respect to a relative frame of reference.\n5.2. Description sentences and interpretation: examples\nThe system, while limited in many respects, is able to semantically interpret a relatively\nlarge spectrum of spatial arrangements of shapes. We will now give a series of examples\nillustrating how descriptions of diﬀerent kinds of arrangements of shapes are interpreted by\nour system. This list is not exhaustive and is only meant to be indicative of the capabilities\nof the system.\nIn all examples, we show graphically a spatial relation between two shapes (that could\nbe used as the right hand side of a shape rule) and an equivalent verbal description of the\narrangement in natural language, either constructive, or from-above or combination of the\ntwo styles, along with its semantic interpretation. The existential verb ”be” [”is”] is used\nfor all the from-above descriptions and ’action’ verbs are used to structure the constructive\ndescriptions. The actions of the constructive descriptions can be additions, subtractions or\nreplacements. It is worth mentioning that the verbal descriptions are made of 24 lexical\nterms. These are: [”right”, ”left”, ”top”, ”bottom”, ”upper”, ”lower” ”edge”, ”corner”,\n”midpoint”, ”shape1”, ”shape2”, ”is”, ”draw”, ”add”, ”subtract”, ”replace”, ”at”, ”on”,\n”in”, ”to”, ”from”, ”with”, ”of”, ”the” ].\n16\nExample 1.\nadd <shape2> to <shape1>.\n<shape2> is in <shape1>.\nSPATIAL_RELATION['in', \"SHAPE['shape1']\",    \n       'ec-ttp-nttp', \"ACTION['is', 'present']\",\n       \"SHAPE['shape2']\"]\nwhere <shape1> and <shape2> are the following shapes:\n<shape1>\n<shape2>\nExample 2.\nadd <shape2> to <shape1>.\n<shape2> is on <shape1>.\nthe bottom edge of <shape2> is at the midpoint of the top edge of <shape1>.\nSPATIAL_RELATION['on', \"SHAPE['shape2']\",    \n       'ec-ttp', \"ACTION['is', 'present']\",   \n       \"SHAPE['shape1']\"]\nSPATIAL_RELATION[\"ACTION['is', 'present']\", \n       'ATTRIBUTE[\"ATTRIBUTE[\\'edge\\']\", \"DIRECTION[\\'top\\']\", \n       \\'midpoint\\', \"SHAPE[\\'shape1\\']\"]', 'ttp-nttp', 'at', \n           'DIRECTION[\"ATTRIBUTE[\\'edge\\']\", \\'bottom\\',  \n            \"SHAPE[\\'shape2\\']\"]']\nwhere <shape1> and <shape2> are the following shapes:\n<shape1>\n<shape2>\nExample 3.\nreplace <shape1> with <shape2>.\n17\nACTION['replace', \"SHAPE['shape1']\", \"SHAPE['shape2']\"]\nwhere <shape1> and <shape2> are the same as in example 2.\nExample 4.\nOne may also pursue consecutive arithmetic operations between shapes using verbal descrip-\ntions.\nadd <shape1> to <shape2>.\nthe midpoint of the right edge of <shape1> is at the midpoint of the left edge of <shape2>.\nSPATIAL_RELATION[\"ACTION['is', 'present']\", \n       'ATTRIBUTE[\"ATTRIBUTE[edge]\", \"DIRECTION['right']\", \n       'midpoint', \"SHAPE['shape1']\"]', 'ttp-nttp', 'at', \n       'DIRECTION[’left’, \"ATTRIBUTE['edge']\", \"SHAPE['shape2']\"]']\nwhere <shape1> and <shape2> are the following shapes:\n<shape1>\n<shape2>\nsubtract <shape2> from <shape1>.\nACTION['subtract', \"SHAPE['shape2']\", \"SHAPE['shape2']\"]\nwhere <shape1> and <shape2> are the following shapes:\n<shape1>\n<shape2>\nExample 5.\n18\nSPATIAL_RELATION[\"ACTION['is', 'present']\", 'ATTRIBUTE[\"ATTRIBUTE[\\'edge\\']\", \n    \"DIRECTION[\\'right\\']\", \\'midpoint\\', \"SHAPE[\\'shape1\\']\"]', 'ttp-nttp', \n    ‘at’, 'ATTRIBUTE[\"ATTRIBUTE[\\'edge\\']\", \"DIRECTION[\\'top\\']\", \\'midpoint\\', \n    \"SHAPE[\\'shape2\\']\"]']\nthe midpoint of the top edge of <shape2> is at the midpoint of the right edge of <shape1>\nwhere <shape1> and <shape2> are the same as in example 4 (ﬁrst part).\n6. Discussion\nOur system successfully performs semantic interpretation of a variety of spatial relations\nbetween shapes following the spatial semantics concepts we outlined in section 2. Beyond the\ncurrent capabilities of the system, there are a number of interesting questions and problems\narising, which we brieﬂy discuss in this section.\n1. The words <shape1> and <shape2> match to individual shapes (as is the case with all\nexamples in the previous subsection). However, <shape1> and <shape2> may also match\nwith any arrangement of shapes that becomes useful for interpreting the action of a shape\nrule in the course of a computation that proceeds with shape rules and verbal rules jointly\napplied.\nIn particular, during a derivation with shape rules, at each step, the shape that is being\n”matched” in a rule application matches under some transformation of the left shape of the\nshape rule that is being applied at that step. If a is this shape, t(a) is its transformed version\n(t can be an identity, a translation, a rotation, uniform scale or a composition of them). t(a)\nmatches some part of the current arrangement of shapes. If S is the current arrangement\nof shapes, when the rule is applied, t(a) is subtracted from S and a new shape is added,\nnamely, the right hand side of the shape rule t(b). Thus, at each step, we can always obtain\ntwo shapes for semantic interpretation as a consequence of a rule application: t(b) and S -\nt(b). The semantic interpreter binds <shape1> to S - t(b) and <shape2> to t(b) (or the\nconverse) but its ”oblivious” as to how exactly these shapes ’look’ spatially. To illustrate\nthis concept, imagine two ”snapshot” steps within a larger computation (opposite page),\nwhere in the ﬁrst snapshot, at step 1, the word <shape1> matches a single shape, whereas\nin the second snapshot, at some later step n, the word <shape1> matches the arrangement\nof shapes that has been created up until step n (i.e., shapes created in the previous n-1\nsteps).\nThis observation is useful because it supports the way we have implemented our spatial\nsemantics interpretation where spatial relations always consist of two participant members:\na trajector and a landmark. Thus, by virtue of the way shape rule applications work, the two\nspatial roles trajector and landmark will always correspond to some shape (or arrangement\nof shapes) pictorially.\n2. The fact that at each step of the computation we have two participating shapes t(b)\nand S - t(b), raises interesting questions with respect to the possible natural language\n19\n<shape1>\nstep = 1\n.\n.\n.\nstep = n\n<shape1>\n<shape2>\n<shape2>\ndescriptions that one may pursue. In particular, it would be interesting to explore how a\nverbal description at some step n can be modiﬁed with reference to past actions. That is to\nsay, it would be interesting to explore higher-level descriptions that recapitulate or even make\nuse past facts of a computational history to make a more reﬁned (and possibly shorter) verbal\ndescription. Consider the arrangement of shapes in the above Figure. One may describe\nthis arrangement not as a monotonically increasing sequence of repeated descriptions of the\nlike, “shape1 is added to shape2. the lower left corner of shape1 is at....”, but a more reﬁned\ndescription that backwards references a speciﬁc action meant to be repeated multiple times.\nFor example, one possible way to approach this could be to construct descriptions of the\nsort, “add shape2 at the midpoint of shape1, do this for any newly added shape”. The words\ndo this backwards reference a speciﬁc action described in the ﬁrst portion of the sentence\nthus rendering unnecessary its exact repetition. This approach would come closer to the\nlinguistic concept of “anaphora” but applied to arrangements of shapes.\n3. Apart from constructive and from-above descriptions, humans may describe spatial ob-\njects like shapes in many other ways. Figures of speech, such as analogies and similarities,\nand historical or disciplinary contexts are two other possible approaches that one may fol-\nlow to build verbal descriptions of spatial arrangements of shapes. For example, one may\ndescribe the following shapes,\n20\nwith a verbal description, such as ”It looks like a large cross with a smaller cross in the mid-\ndle” for the ﬁrst shape (left) and for the second shape (right), ”it is a parti used for buildings\nof classical architecture”; the former incorporates an analogy, the latter incorporates his-\ntorical and disciplinary knowledge. To represent the semantics of such sentences following\nlambda calculus compositionality approaches is an interesting future endeavor that would\nenhance the current system with description styles that are close to what humans would\n’talk’ about shapes and spatial arrangements of them.\n4. Another important issue to raise is about the inherent visual ambiguity of shapes. As\nan example, consider the following shape and its various ’emergent’ pieces highlighted with\ndarker outline.\nEven if one were to obtain a detailed, constructive description of the arrangement on the\nfar left, the actual generated descriptions would not be able to capture its various emergent\nparts; those emergent parts are not captured by the underlying representation. These parts,\nhowever, are easy to see with a human eye and they may contribute to how one understands\nthe meaning(s) of the arrangement.\n5. One possible extension of our system could be a Graphical User Interface that, having\nparsed a description sentence into its various spatial roles, it could replace the references\nto shapes, e.g. <shape1> and <shape2>, with their equivalent graphical depictions. The\nresult of this would be a description that combines natural language with pictures and\none motivating example of this was shown earlier in section 4. Moreover, such a graphical\ninterface could help a human disambiguate references to directionality or geometric attribute,\ne.g. the right edge of <shape1> or even more speciﬁcally the midpoint of the right edge of\n<shape1>.\n7. Acknowledgements\nThe lambda calculus interpreter that we used to build our spatial semantics system on\nwas taken from the course material of the class 6.863J/9.611J, Intro to Natural Language\nProcessing taught by Prof. Robert Berwick at the Massachusetts Institute of Technology\nin the Spring semester of 2018. We would like to thank Sagar Indurkhya for the useful\ndiscussions and helpful feedback.\n21\nAppendix\nContext-free Syntactic Rule\nCorresponding Semantic Rule\nStart →S\nlambda s: processSentence(s)\nS →NP VP\nlambda np, vp: vp(np)\nS →VACT NPP\nlambda vp, npp: npp(vp)\nS →ADD NP NPP1\nlambda vp, np1, np2: vp(np1, np2)\nS →DRAW NP NPP1\nlambda vp, np1, np2: vp(np1, np2)\nS →SUBTRACT NP NPP1\nlambda vp, np1, np2: vp(np1, np2)\nS →REPLACE NP NPP1\nlambda vp, np1, np2: vp(np1, np2)\nNP →SHAPE\nidentity\nNP →DET NP\nlambda det, np: np\nNPP →NP PP\nlambda np, pp: pp(np)\nNPP1 →To NP\nlambda t, np: np\nNPP1 →FROM NP\nlambda t, np: np\nNPP1 →WITH NP\nlambda t, np: np\nNP →PROP OF SHAPE\nlambda pr, of, s: pr(s)\nPROP →DIR ATTR\nlambda d, a: d(a)\nPROP →COMP DIR ATTR\nlambda c, d, a: c(d, a)\nPROP →ATTR OF DET DIR ATTR\nlambda atr1, o, t, d, atr2: atr1(d, atr2)\n”DIR”, [’right’, ’left’, ’top’, ’bottom’]\nlambda word: lambda attr: lambda shape:\nC(”DIRECTION”, shape=shape,\nattribute=attr, direction=word))\n”ATTR ”, [’edge’, ’corner’, ’midpoint’]\nlambda attribute: C(”ATTRIBUTE”,\nattribute=attribute)\n”DIR ”, [’right’, ’left’, ’top’, ’bottom’]\nlambda attribute: C(”DIRECTION”,\nattribute=attribute)\n”COMP”, [’top’, ’bottom’, ’upper’, ’lower’]\nlambda word: lambda direct, attr: lambda\nshape: C(”DIRECTION”, shape=shape,\nattribute=attr, direction=direct,\ncomparative=word))\n”ATTR”, [’edge’, ’corner’, ’midpoint’]\nlambda word: lambda direct, attr: lambda\nshape: C(”ATTRIBUTE”, select=word,\nshape=shape, attribute=attr,\ndirection=direct)\nVP →EXIST VERB PP\nlambda v, pp: pp(v)\nVACT →ACTION VERB\nidentity\n”EXIST VERB”, [’is’]\nlambda action: C(”ACTION”,\naction=action, tense=’present’)\n”ACTION VERB”, [’draw’, ’add’,\n’subtract’, ’replace’]\nlambda action: C(”ACTION”,\naction=action, tense=’present’\n22\nADD →’add’\nlambda word: lambda landmark, trajector:\nC(”ACTION”, action=word,\ntrajector=trajector, landmark=landmark)\nSUBTRACT →’subtract’\nlambda word: lambda landmark, trajector:\nC(”ACTION”, action=word,\ntrajector=trajector, landmark=landmark)\nDRAW →’draw’\nlambda word: lambda landmark, trajector:\nC(”ACTION”, action=word,\ntrajector=trajector, landmark=landmark)\nREPLACE →’replace’\nlambda word: lambda landmark, trajector:\nC(”ACTION”, action=word,\ntrajector=trajector, landmark=landmark)\nPP →IN NP\nlambda p, np: p(np)\n”SHAPE”, [’shape1’, ’shape2’]\nlambda shape: C(”SHAPE”,\nshape=shape)\nIN →’at’\nlambda word: lambda landmark: lambda\naction: lambda trajector:\nC(”SPATIAL RELATION”,\nrelation=word, region=”ttp-nttp”,\naction=action, trajector=trajector,\nlandmark=landmark)\nIN →’on’\nlambda word: lambda landmark: lambda\naction: lambda trajector:\nC(”SPATIAL RELATION”,\nrelation=word, region=”ec-ttp”,\naction=action, trajector=trajector,\nlandmark=landmark)\nIN →’in’\nlambda word: lambda landmark: lambda\naction: lambda trajector:\nC(”SPATIAL RELATION”,\nrelation=word, region=”ec-ttp-nttp”,\naction=action, trajector=trajector,\nlandmark=landmark)\nTo →’to’\nlambda word: lambda: None\nFROM →’from’\nlambda word: lambda: None\nWITH →’with’\nlambda word: lambda: None\nOF →’of’\nlambda word: lambda: None\nDET →’the’\nlambda word: lambda: None\nidentity\nlambda x: x\n23\nReferences\n[1] B. Landau, R. Jackendoﬀ, ”What” and ”Where” in spatial language and spatial cognition, Behavioral\nand Brain Sciences 16 (2) (1993) 217–238.\n[2] P. H. Winston, The strong story hypothesis and the directed perception hypothesis, in: AAAI Fall\nSymposium Series, Association for the Advancement of Artiﬁcial Intelligence, 2011, accessed on MIT\nDSpace.\n[3] R. Jackendoﬀ, Language as a source of evidence for theories of spatial representation, Perception 41\n(2012) 1128–1152.\n[4] T. Tenbrink, J. Wiener, C. Claramunt, Representing space in cognition: interrelations of behaviour,\nlanguage, and formal models, Oxford University Press, 2013.\n[5] L. G. Ungerleider, M. Mishkin, Two cortical visual systems, in: D. J. Ingle, M. A. Goodale, R. J. W.\nMansﬁeld (Eds.), Analysis of visual behavior, MIT Press, 1982, pp. 549–586.\n[6] B. Landau, Update on ”What” and ”Where” in spatial language: a new division of labor for spatial\nterms, Cognitive Science 41 (2) (2017) 321–350.\n[7] M. Bhatt, C. Schultz, C. Freksa, The ’space’ in spatial assistance systems: conception, formalization,\nand computation, in: T. Tenbrink, J. Wiener, C. Claramunt (Eds.), Representing space in cognition:\ninterrelations of behaviour, language, and formal models, Oxford University Press, 2013, Ch. 9, pp.\n171–214.\n[8] L. Talmy, Towards a Cognitive Semantics - Vol.1, MIT Press, 2000.\n[9] T. Winograd, Understanding natural language, Cognitive Psychology 3 (1972) 1–191.\n[10] C. Linde, W. Labov, Spatial networks as a site for the study of language and thought, Language 51\n(1975) 924–939.\n[11] B. Tversky, N. Franklin, H. A. Taylor, D. J. Bryant, Spatial mental models from descriptions, Journal\nof the American Society for Information Science 45 (9) (1994) 656–668.\n[12] C. Habel, H. Tappe, Processes of segmentation and linearization in described events, in: V. Stutterheim,\nR. Klabunde (Eds.), Representations and Processes in Language Production, Opladen: Westdeutcher\nVerlag, 1999, pp. 117–153.\n[13] P. H. Winston, Learning structural descriptions from examples, Ph.D. thesis, Department of Electrical\nEngineering and Computer Science, Massachusetts Institute of Technology (9 1970).\n[14] R. W. Boberg, Generating line drawings from abstract scene descriptions, Master’s thesis, Department\nof Electrical Engineering and Computer Science, Massachusetts Institute of Technology (2 1973).\n[15] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen, Y. Kalantidis, L.-J. Li, D. A.\nShamma, M. Bernstein, L. Fei-Fei, Visual genome: Connecting language and vision using crowdsourced\ndense image annotations, 2016, https://arxiv.org/abs/1602.07332.\n[16] J. Johnson, et al., CLEVR: A diagnostic dataset for compositional language and elementary visual\nreasoning, Tech. rep., arXiv:1612.06890v1 (12 2016).\n[17] P. Klee, Notebooks, Volume 1, The thinking eye, [German: Das bildnerische Denken], Lund Humphries,\nLondon, 2013.\n[18] D. A. Schon, The reﬂective practitioner: how professionals think in action, Basic Books, New York,\n1983.\n[19] G. Stiny, Shape: talking about seeing and doing, MIT Press, 2006.\n[20] G. Stiny, A note on the description of designs, Environment and Planning B: Planning and Design 8 (3)\n(1981) 257–267.\n[21] J. Zlatev, Spatial semantics, in: D. G. H. Cuyckens (Ed.), Handbook in Cognitive Linguistics, Oxford\nUniversity Press, 2010, Ch. 13, pp. 319–350.\n[22] P. Kordjamshidi, M. van Otterlo, M.-F. Moens, Spatial role labeling: towards extraction of spatial\nrelations from natural language, ACM - Trans. Speech Lang. Process 8 (4) (2011) 1–36.\n[23] P. Kordjamshidi, M. van Otterlo, M.-F. Moens, Learning to interpret spatial natural language in terms\nof qualitative spatial relations, in: T. Tenbrink, J. Wiener, C. Claramunt (Eds.), Representing space\nin cognition: interrelations of behaviour, language, and formal models, Oxford University Press, 2013,\nCh. 7, pp. 115–146.\n24\n[24] I. Mani, J. Pustejovsky, Interpreting Motion: grounded representations for spatial language, Oxford\nScholarship Online, 2012. doi:10.1093/acprof:oso/9780199601240.001.0001.\n[25] Spatialml: Annotation scheme for marking spatial expressions in natural language, Tech. Rep. 3.0.1,\nThe MITRE Corporation (6 2010).\n[26] A. G. C. D. A. Randell, Z. Cui, A spatial logic based on regions and connection, in: Proceedings of the\n3rd International Conference on the Principles of Knowledge Representation and Reasoning, KR’92,\n1992, pp. 165–176.\n[27] S. C. Levinson, Space in language and cognition: explorations in cognitive diversity, Cambridge Uni-\nversity Press, 2003.\n25\n",
  "categories": [
    "cs.CL",
    "I.2.7; I.2.4; J.6"
  ],
  "published": "2021-11-28",
  "updated": "2021-11-28"
}