{
  "id": "http://arxiv.org/abs/2112.11352v2",
  "title": "Unsupervised quark/gluon jet tagging with Poissonian Mixture Models",
  "authors": [
    "Ezequiel Alvarez",
    "Michael Spannowsky",
    "Manuel Szewc"
  ],
  "abstract": "The classification of jets induced by quarks or gluons is important for New\nPhysics searches at high-energy colliders. However, available taggers usually\nrely on modelling the data through Monte Carlo simulations, which could veil\nintractable theoretical and systematical uncertainties. To significantly reduce\nbiases, we propose an unsupervised learning algorithm that, given a sample of\njets, can learn the SoftDrop Poissonian rates for quark- and gluon-initiated\njets and their fractions. We extract the Maximum Likelihood Estimates for the\nmixture parameters and the posterior probability over them. We then construct a\nquark-gluon tagger and estimate its accuracy in actual data to be in the\n$0.65-0.7$ range, below supervised algorithms but nevertheless competitive. We\nalso show how relevant unsupervised metrics perform well, allowing for an\nunsupervised hyperparameter selection. Further, we find that this result is not\naffected by an angular smearing introduced to simulate detector effects for\ncentral jets. The presented unsupervised learning algorithm is simple; its\nresult is interpretable and depends on very few assumptions.",
  "text": "Unsupervised quark/gluon jet tagging with\nPoissonian Mixture Models\nE. Alvarez,a M. Spannowskyb,c and M. Szewca\naInternational Center for Advanced Studies (ICAS) and CONICET, UNSAM, Campus Miguelete,\n25 de Mayo y Francia, CP1650, San Martin, Buenos Aires, Argentina\nbInstitute for Particle Physics Phenomenology, Durham University, DH1 3LE, United Kingdom\ncDepartment of Physics, Durham University, DH1 3LE, United Kingdom\nE-mail: sequi@unsam.edu.ar, michael.spannowsky@durham.ac.uk,\nmszewc@unsam.edu.ar\nAbstract: The classiﬁcation of jets induced by quarks or gluons is important for New\nPhysics searches at high-energy colliders. However, available taggers usually rely on mod-\nelling the data through Monte Carlo simulations, which could veil intractable theoretical\nand systematical uncertainties. To signiﬁcantly reduce biases, we propose an unsupervised\nlearning algorithm that, given a sample of jets, can learn the SoftDrop Poissonian rates\nfor quark- and gluon-initiated jets and their fractions. We extract the Maximum Likeli-\nhood Estimates for the mixture parameters and the posterior probability over them. We\nthen construct a quark-gluon tagger and estimate its accuracy in actual data to be in the\n0.65 −0.7 range, below supervised algorithms but nevertheless competitive. We also show\nhow relevant unsupervised metrics perform well, allowing for an unsupervised hyperpa-\nrameter selection. Further, we ﬁnd that this result is not aﬀected by an angular smearing\nintroduced to simulate detector eﬀects for central jets. The presented unsupervised learning\nalgorithm is simple; its result is interpretable and depends on very few assumptions.\narXiv:2112.11352v2  [hep-ph]  28 Feb 2022\nContents\n1\nIntroduction\n1\n2\nMixture models for quark- and gluon-jets data\n2\n3\nResults\n6\n3.1\nModel performance at generator level\n6\n3.2\nDetector eﬀects\n8\n4\nBayesian analysis\n10\n5\nDiscussion and outlook\n11\n1\nIntroduction\nAs ongoing searches at the LHC have not succeeded in providing guidance on the nature of\nextensions of the Standard Model, unbiased event reconstruction and classiﬁcation methods\nfor new resonances and interactions have become increasingly important to ensure that the\ngathered data is exploited to its fullest extent [1, 2]. Unsupervised data-driven classiﬁcation\nframeworks, often used as anomaly-detection methods, are comprehensive in scope, as their\nsuccess does not hinge on how theoretically well-modelled signal or background processes\nare allowing for more signal-agnostic analyses [3–11].\nHere, we apply the unsupervised-learning paradigm to the discrimination of jets induced\nby quarks or gluons.\nThe so-called quark-gluon tagging of jets can be a very powerful\nmethod to separate signal from background processes.\nImportant examples include the\nsearch for dark matter at colliders, where the dark matter candidates are required to recoil\nagainst a single hard jet [12], the measurement of Higgs boson couplings in the weak-\nboson fusion process [13, 14] or the discovery of SUSY cascade decays involving squarks or\ngluinos [15]. Thus, a robust and reliable method to discriminate between quark and gluon\njets furthers the scientiﬁc success of the LHC programme in precision measurements and\nsearches for new physics. Consequently, several approaches have been proposed to exploit\nthe diﬀerences in the radiation proﬁles of quarks and gluons [16–21] and have been studied\nin data by ATLAS [22] and CMS [23].\nThe discrimination of quarks and gluons as incident particles for a jet poses a challeng-\ning task. Some of the best performing observables to classify quark/gluon jets are infrared\nand/or collinear (IRC) unsafe, e.g. the number of charged tracks of a jet. Thus, evaluating\nthe classiﬁcation performance of IRC unsafe observables from the ﬁrst principles is an inher-\nently diﬃcult task. Instead, SoftDrop [24] has been shown to achieve a high classiﬁcation\nperformance while maintaining IRC safety. Further, at leading-logarithmic accuracy, the\n– 1 –\nSoftDrop multiplicity nSD exhibits a Poisson-like scaling [25], allowing us to construct an\nentire data-driven unsupervised classiﬁer based on a mixture model. Although IRC safety is\nin principle not necessary to construct an unsupervised tagger, the fact that we are able to\nknow the leading-logarithmic behavior of the observable is what allows us to build a simple\nand interpretable probabilistic model. To build a tagger that discriminates between quark\nand gluon jets, we extract the Maximum Likelihood Estimate (MLE) and the posterior\ndistributions for the rate of the Poissonians and the mixing proportions of the respective\nclasses. We ﬁnd such a tagger to have a high accuracy (≈0.7) while remaining insensitive\nto detector eﬀects. In a second step, we augment this method by using Bayesian inference\nto obtain the full set of posterior distributions and correlations between the model parame-\nters, which allows to calculate the probability of a jet being a quark or gluon jet. The latter\nmethod results in a robust tagger with even higher accuracy. Thus, this approach opens a\nnovel avenue to analyse jet-rich ﬁnal states at the LHC, thereby increasing the sensitivity\nin searches for new physics.\nThe structure of the paper is as follows: In section 2 we present the datasets considered\nand describe the mixture model method for the discrimination of quark and gluon jets. In\nsection 3 we discuss the performance and uncertainties of the MLE algorithm, detailing the\nviability of this algorithm in the presence of detector eﬀects. We use Bayesian inference to\nobtain the full posterior probability density function in section 4. In section 5 we oﬀer a\nsummary and conclusions.\n2\nMixture models for quark- and gluon-jets data\nTo showcase and benchmark our model performance in a way comparable to other algo-\nrithms, we have considered two datasets available in the literature, both considered initially\nin Ref. [26]. These two datasets contain quark and gluon jets after hadronization, and corre-\nspond to a set [27] generated with Pythia [28] and a set [29] generated with Herwig [30, 31].\nThe reason for using datasets from diﬀerent generators is to verify that the algorithm is\nindependent of the generator and from any speciﬁc tuning. As detailed in the documenta-\ntion, the quark- and gluon-initiated jets are generated from qg →Z(→νν) + u/d/s and\nqq →Z(→νν) + g processes in pp collisions at √s = 14 TeV. After hadronization, the jets\nare clustered using the anti-kT algorithm with R = 0.4. For the sake of validation and com-\nparing supervised and unsupervised metrics, we use the parton level information to deﬁne\nwhether a jet is a true quark or a true gluon. This deﬁnition is known to be problematic and\nwe emphasize that our model does not depend on these unphysical labels and could instead\nprovide an operational deﬁnition of quark and gluon jets [32]. In addition, there is a very\nstrict selection cut and all the provided jets have transverse momentum pT ∈[500.0, 550.0]\nGeV and rapidity |y| < 1.7. We detail the impact of these cuts on the tagging observable in\nthe following paragraphs. Finally, the dataset is balanced with an equal number of quark\nand gluon jets.\nAs a tagging observable, we have considered the Iterative SoftDrop Multiplicity nSD\ndeﬁned in Ref. [25]. Once deﬁned the jet radius R used to cluster the constituents with the\nCambridge-Aachen algorithm [33], nSD has three hyperparameters zcut, β and θcut. The\n– 2 –\ndependence on these hyperparameters and the classiﬁcation performance on supervised\ntasks has been explored in Ref. [25]. In this work and in agreement with Ref. [25] we will\nconsider IRC safe parameter choices: zcut > 0, β < 0 and θcut = 0.\nThe choice of a well-known tagging observable allows us to perform unsupervised quark-\ngluon discrimination by considering interpretable mixture models [34–43], where we think\nof the measurement of N jets and their nSD, values as originating from underlying themes,\nwhich we would ideally match with quark and gluon jets. In a probabilistic modelling frame-\nwork, we want to obtain the underlying quark and gluon distributions from the observed\ndata X = {n(i)\nSD, i = 1, ..., N}, which has a likelihood function\np(X) =\nN\nY\ni=1\np(n(i)\nSD) =\nN\nY\ni=1\nX\nk={q,g}\nπk p(n(i)\nSD | k),\n(2.1)\nwhere k is the jet class or theme. The mixing fraction πk denotes the probability of sampling\na jet from theme k and p(n(i)\nSD | k) is the nSD probability mass functions conditioned on which\ntheme the jet belongs to. In principle, the number of themes is a hyperparameter of the\nmodel and could be optimized with some criteria (see e.g. Ref. [44] for a review on diﬀerent\nmethods to select the number of themes). In this work, we consider only two themes that\nwe identify with quark and gluon jets. This choice is based on physical grounds. As we\nwill detail in the following paragraphs, for a suﬃciently small pT range we only expect\ntwo themes. The ﬁnal ingredient to build the probabilistic model is the speciﬁcation of\np(n(i)\nSD | k). To model these probability mass functions, we make use of the fact that at\nleading logarithmic (LL) order nSD is Poisson distributed [25]:\np(X) =\nN\nY\ni=1\nX\nk={q,g}\nπk Poisson(n(i)\nSD; λk),\n(2.2)\nwhere λk is the Poisson rate for each theme, which ﬁxes the mean and variance of the\nnSD distribution. The departure of the Poisson hypothesis by NLL corrections and Non\nPerturbative eﬀects can then be seen by examining the variance to mean ratio for each class\nof jets. We see that deviations from the Poissonian behaviour are parameter-dependent,\nin agreement with previous results detailed in Ref. [25].\nFurthermore, we see that the\ndeviations are more substantial for quark jets than for gluon jets. This is enhanced by the\nfact that quark jets usually have smaller nSD values than gluon jets.\nThe behavior of nSD is also dependent on the kinematics of the jet. For the samples\nconsidered, the limited pT and |y| ranges ensure that all quark- and gluon-initiated jets\nfollow the same respective nSD distributions. In a more realistic implementation of this\nmodel where the pT of the jets populates a much wider range, the model implementation\nshould be modiﬁed to account for the variation of the nSD distribution with pT . A straight-\nforward strategy is to bin the pT distribution and infer the mixture model parameters in\neach bin, eﬀectively conditioning the Poisson rates and the mixture fractions on the pT of\nthe jets populating such region. The pT dependence also implies that the discriminating\npower of the mixture model will depend on the pT of the jet as is usually the case for most\nquark/gluon classiﬁcation methods.\n– 3 –\nThe likelihood in Eq. 2.2 describes how for a given value of the mixing fractions πq,g\nand the Poisson rates λq,g, each jet is sampled or generated. This is called a generative\nprocess and it is often useful to represent it as a plaque diagram [45]. The corresponding\nplaque diagram to Eq. 2.2 can be seen in Fig. 1.\nni\nSD\nzi\nπ\nλk\nN\nK\nFigure 1. Generative process for nSD due to a mixture of quark and gluon jets.\nIn the ﬁgure, we have introduced a hidden or latent class variable, the theme assign-\nment z, which dictates whether the generated jet is a quark or a gluon jet. This class\nassignment is necessary to think of the likelihood as a generative process and it is useful\nwhen performing inference and when building a probabilistic jet classiﬁer. Having deﬁned\nthe probabilistic model and the relevant parameters π and λ, ﬁnding the underlying themes\nbecomes synonymous with ﬁnding the posterior probabilities for π and λ. These poste-\nrior probabilities can then be used to build a quark/gluon classiﬁer. Instead of tackling\nthe Bayesian Inference problem head-on, one can ﬁrst obtain point estimates for π and\nλ. Because we consider a statistically signiﬁcant dataset and a straightforward model, at\nthis stage we consider the Maximum Likelihood Estimates (MLE) of π and λ instead of\nMaximum A Posterior (MAP) estimates. These estimates can be obtained easily through\nExpectation-Maximization (EM) or with Stochastic Variational Inference through dedi-\ncated software such as the Pyro package [46, 47]. We need to be careful when estimating\nthe point parameters as they can suﬀer from mode degeneracy and mode collapse. The\nformer occurs due to the permutation symmetry of the classes and can be ﬁxed by requir-\n– 4 –\ning that λq < λg as dictated by basic principles. The latter occurs when one theme is\nemptied of samples. Because we only consider two classes, collapse is avoided for for good\nhyperparameter choices because of the multimodality of the data distribution.\nWith the MLE point estimation of πMLE and λMLE, we can construct a probabilistic\njet classiﬁer by computing the assignment probabilities or responsibilities,\np(z = quark | nSD, πMLE, λMLE) =\nπMLE\nq\nPoisson(nSD, λMLE\nq\n)\nP\nk={q,g} πMLE\nk\nPoisson(nSD, λMLE\nk\n),\n(2.3)\nwith p(z = gluon) = 1 −p(z = quark). The classiﬁer is obtained by selecting a threshold\n0 ≤c ≤1.0 and labeling any jet with p(z = quark | nSD, πMLE, λMLE) ≥c as a quark\njet. This classiﬁer has a clear probabilistic justiﬁcation and it is interpretable, which is a\nconsiderable asset for an unsupervised task.\nFor validation, we compute the usual supervised metrics: the accuracy obtained by as-\nsigning classes using the probabilistic working point c = 0.5 chosen because we have a binary\nclassiﬁcation problem and a probabilistic algorithm, the mistag rate at 50% signal eﬃciency\nϵ−1\ng (ϵq = 50%) and the Area-Under-Curve (AUC). The accuracy is deﬁned as the number\nof fraction of well classiﬁed samples, ϵq,g are the fraction of well classiﬁed quark/gluon jets\nand the AUC is the integral of the Receiver Operating Characteristic (ROC) curve ϵq(ϵg)\nwith a higher AUC usually signaling a higher overall performance. However, because we are\ninterested in an unsupervised classiﬁer trained directly on data, we also deﬁne unsupervised\nmetrics. These metrics need to be correlated with the unseen accuracy so as to substitute\nit as a measure of performance in a fully data-driven implementation of the model. In an\nunsupervised metric we measure how consistent is the learned model with the measured\ndata. We investigate two metrics that encode such consistency:\ndH(p, q) =\n1\n√\n2\nv\nu\nu\nt\n∞\nX\nnSD=0\n(\np\np(nSD) −\np\nq(nSD))2\nKL(p||q) = −\n∞\nX\nnSD=0\np(nSD)Ln\n\u0012q(nSD)\np(nSD)\n\u0013\n,\n(2.4)\nwhere dH is the Hellinger distance [48] and KL is the Kullback-Leibler divergence between\nthe learned data density and the measured data density. The latter can be interpreted as\nthe amount of information needed to approximate samples that follow the distribution p\nwith samples generated by a model q. In this paper, p will be the measured data density\nobtained by the nSD frequencies and q will be the posterior predictive distribution q(nSD) =\nP\nk={q,g} πMLE\nk\nPoisson(nSD, λMLE\nk\n). Other metrics such as the Energy Mover’s Distance [49]\ncould also be applied. We emphasize that this takes advantage of the fact that we are\nlearning more than a classiﬁer, as we are modelling the data density itself and the underlying\nprocesses that generate it. If we can match the learned models to quark and gluon jets, it\nmeans we can understand the data beyond merely a good discriminator.\nIn section 3, we apply this model to the two quark and gluon datasets [27], [29] and\nobtain the diﬀerent MLE point parameters and derived metrics for other choices of SoftDrop\n– 5 –\nhyperparameters. We then go beyond the point estimate calculation by introducing priors\nfor π and λ and obtain the corresponding posterior through numerical Bayesian inference\nin section 4. These priors can encode our theoretical domain knowledge, such as the LL\nestimates of λq and λg and also regularize our model and thus avoid mode degeneracy and\nmode collapse.\n3\nResults\nHaving detailed the data and our model in section 2, we proceed to obtain point estimates\nfor the parameters of the mixture model. In subsection 3.1 we study the model performance\nat the generator level for the two generator choices available, and we include a brief study of\ndetector levels in subsection 3.2. All results are reported on a test set which was separated\nfrom the train set prior to the model training.\n3.1\nModel performance at generator level\nAs detailed in section 2, we model the nSD distribution as originating from a mixture of\ntwo Poissonians, which we aim to identify with gluon and quark jets (or, should we want to\nget rid of perturbative deﬁnitions, to operationally deﬁne gluon or quark enriched samples).\nFor each choice of hyperparameters, we obtain the Maximum Likelihood Estimates (MLE)\nof the rates of the Poissonians.\nλMLE\ng\nand λMLE\nq\n, and the mixing fraction between the\ntwo πMLE\ng\n. We deﬁne the gluon theme as the theme with the larger rate, as oriented by\nthe perturbative calculations.\nWe obtain the MLE of the parameters with the help of\nthe Pyro package [46, 47], which we have veriﬁed to coincide with the results obtained\nthrough Expectation-Maximization but provide us with a more ﬂexible framework that can\nincorporate additional features to the generative model and optimize the code appropriately.\nFor the sake of validation and understanding, we consider three supervised metrics: the\naccuracy using the probabilistic decision boundary p(g | nSD) = p(q | nSD), the inverse gluon\nmistag rate at 50% quark eﬃciency ϵ−1\ng (ϵq = 50%) and the AUC. Since we are dealing with\nan unsupervised algorithm, and as discussed above, we also apply the unsupervised metrics\ndeﬁned in section 2: the Hellinger distance [48] and the Kullback-Leibler divergence. These\nmetrics compare the measured nSD distribution (without any labels) to the learned total\ndistribution\np(nSD | data) = πMLE\ng\nPoisson(λMLE\ng\n) + (1.0 −πMLE\ng\n) Poisson(λMLE\nq\n).\n(3.1)\nWe show two examples of the results we obtain for diﬀerent SoftDrop hyperparameters in\nFig. 2. In the left column, we show the true underlying distributions and the two learned\nPoissonians, their respective means and Poissonian rates, and the supervised metrics. In the\nright column, we show the data distribution, the learned data distribution and the default\ndecision boundary, along with the unsupervised data-driven metrics. In the top row, we\nshow a good hyperparameter choice that leads to a data distribution that is well modelled\nby a mixture of Poissonians, and thus we obtain good supervised and unsupervised metrics.\nIn the bottom row, we show a bad hyperparameter choice leading to a data distribution that\n– 6 –\nis not well modelled by a mixture of Poissonians, and thus we obtain mostly bad supervised\nand unsupervised metrics, with the exception of the AUC score.\n0\n2\n4\n6\n8\n10\n12\n14\n16\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\nProbability Mass Function\nAcc. = 0.73, AUC = 0.8, ϵ−1\ng (ϵs = 0.5) = 5.84, πg = 0.56\nQuark Truth\nQuark Theme\nGluon Truth\nGluon Theme\n0\n2\n4\n6\n8\n10\n12\n14\n16\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14\ndH = 0.0464, KL = 0.0078\nDecision boundary\nData\nGenerative model\n0\n5\n10\n15\n20\nnSD\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150\n0.175\nProbability Mass Function\nAcc. = 0.51, AUC = 0.81, ϵ−1\ng (ϵs = 0.5) = 5.12, πg = 0.52\nQuark Truth\nQuark Theme\nGluon Truth\nGluon Theme\n0\n5\n10\n15\n20\nnSD\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14\ndH = 0.0823, KL = 0.0235\nDecision boundary\nData\nGenerative model\nPythia, zcut = 0.005, β = -1.0, θcut = 0.0, N = 100000 jets\npT ∈[500.0,550.0] GeV\nand |y| < 1.7\nPythia, zcut = 0.005, β = -0.5, θcut = 0.0, N = 100000 jets\npT ∈[500.0,550.0] GeV\nand |y| < 1.7\nFigure 2. SoftDrop multiplicity distributions for the learned quark and gluon jet themes and the\ncorrect ‘true’ answer based on the Pythia generated sample. The upper (lower) row corresponds to\na good (bad) choice of hyperparameters. This can be seen from the supervised side by the accuracy\nmetric and from the unsupervised side by the Hellinger and KL divergence metrics which measure\nthe consistency between the real data and pseudo-data sampled with the learned model parameters.\nOn the left plots, we show with vertical lines the diﬀerent Poisson rates while on the right plots\nwe show with a vertical line the threshold corresponding to p(z = quark | nSD) = 0.5. See text for\ndetails.\nThe supervised metrics show that the accuracy and the AUC do not necessarily favour\nthe same models. As shown in Fig. 2, two very diﬀerent cases can lead to high AUC, with\nthe accuracy being able to reﬂect more the true performance of the model. This is due to the\nfact that the AUC is a more global metric which takes into account every possible threshold\nin p(z = quark | nSD) including the default threshold used for computing the accuracy,\np(z = quark | nSD) = 0.5, and can be fooled by moving said threshold. Because the default\nthreshold is theoretically well-motivated, as it takes full advantage of the probabilistic\nmodelling to deﬁne a speciﬁc boundary between the two classes, it tends better to reﬂect the\ngoodness of the modelling than the AUC. As we use probabilistic models for an unsupervised\ntask, interpretability and consistency are important features to keep in mind. In that sense,\n– 7 –\nthe accuracy is more aligned with the unsupervised metrics, which cannot be fooled by\nmoving the decision threshold. The Hellinger distance and the KL divergence see whether\nthe generated dataset is consistent with the measured dataset, taking advantage of the\ngenerative procedure.\nAs a next step, we scan the hyperparameter values to study the algorithm performance\nand how unsupervised metrics can assist us in having a good (unseen) supervised metric.\nWe show the accuracy and the KL divergence for an array of hyperparameter values in\nFig. 3.\nWe observe that the accuracy and the KL divergence have a fair agreement in\nqualifying a good model for a given SoftDrop parameter choice. Although their respective\nmaximum and minimum do not match exactly, the regions of high accuracy coincide with\nthe regions of low KL divergence. Therefore, we can trust that the accuracy will be increased\nfor a reasonable parameter choice by inspecting the KL divergence and verifying that the\nobtained quark and gluon themes are suitable. As for the other metrics (not shown in\nthe plot), we ﬁnd that the Hellinger distance is consistent with the KL divergence and the\nmistag rate is consistent with the accuracy. The AUC presents the caveat discussed above\nand thus is less relevant for this study.\nFrom the above results, we see that, by choosing the accuracy as the relevant met-\nric, there is a signiﬁcant overlap of the good regions in hyperparameter space according\nto the unsupervised and supervised metrics. This indicates that classiﬁcation performance\ncoincides with generative performance, and therefore opens the door for exploring a fully\nunsupervised approach where the quark/gluon tagging is deﬁned by a relatively simple pa-\nrameter scan — yielding an unsupervised, interpretable and simple model for classiﬁcation.\nTo study the performance of the proposed unsupervised classiﬁer in some more detail,\nwe compute the ROC and the accuracy as a function of the threshold c to which the classes\nare deﬁned. We show in Fig. 4 both results for a good point in hyperparameter space.\nIn a real case scenario, one would only have access to the bottom panel in Fig. 3, and\nchoosing a point with small KL divergence would yield a tagger that for the threshold\np(z = quark) = 0.5 has an accuracy of roughly ∼0.65 −0.73 (Pythia) and 0.62 −0.70\n(Herwig).\n3.2\nDetector eﬀects\nTo study the sensitivity of our tagger to detector eﬀects, we used the procedure outlined\nin section 6 in Ref. [50] and smeared the η, φ distribution of each jet constituent.\nWe\nconsidered the same smearing as in Ref. [50], where they spread the η and φ values of a\nconstituent by sampling Gaussian noise with mean zero and standard deviation given by:\nσ0(pT ) =\n0.028\n1 + e(pT −25 GeV)/0.1 GeV ,\n(3.2)\nwhere pT is the pT of the constituent.\nWe consider diﬀerent smearing noise factors σ\nobtained by re-scaling σ0 by a global multiplicative factor. The results are shown in Figs. 5\nand 6. Although there is a diﬀerence in the MLE due to the change in the distributions, we\nﬁnd no signiﬁcant alteration in the supervised metrics, and hence in the model performance.\nIt seems that generator eﬀects as simulated are not challenging the model.\nThis may\n– 8 –\n0.05\n0.1\n0.01\n0.005\n0.001\nzcut\n0.68\n0.705\n0.502\n0.495\n0.514\n0.633\n0.638\n0.731\n0.507\n0.502\n0.611\n0.641\n0.689\n0.504\n0.496\n0.538\n0.558\n0.503\n0.679\n0.676\n0.511\n0.53\n0.553\n0.504\n0.564\nPythia\n0.622\n0.709\n0.501\n0.501\n0.511\n0.528\n0.589\n0.696\n0.499\n0.501\n0.503\n0.533\n0.642\n0.637\n0.501\n0.539\n0.567\n0.501\n0.634\n0.493\n0.512\n0.526\n0.558\n0.502\n0.62\nHerwig\n-0.5\n-0.1\n-2.0\n-1.0\n-1.5\nβ\n0.05\n0.1\n0.01\n0.005\n0.001\nzcut\n-5.47\n-5.11\n-3.32\n-2.51\n-2.27\n-3.75\n-5.65\n-4.85\n-3.75\n-2.77\n-4.1\n-4.44\n-4.9\n-4.4\n-3.19\n-3.89\n-4.09\n-4.02\n-6.55\n-3.71\n-3.77\n-4.21\n-4.61\n-4.45\n-3.99\n-0.5\n-0.1\n-2.0\n-1.0\n-1.5\nβ\n-7.39\n-5.28\n-3.61\n-2.67\n-2.54\n-5.39\n-5.69\n-5.49\n-3.51\n-2.81\n-4.08\n-5.81\n-6.57\n-4.13\n-3.07\n-4\n-3.98\n-4.61\n-7.48\n-3.34\n-4.12\n-4.41\n-4.45\n-4.92\n-3.64\nSupervised Accuracy with 11112 test jets\nUnsupervised Logarithm of KL divergence with 11112 test jets\nFigure 3. Comparison of supervised and unsupervised learning performance metrics for various\nhyperparameter choices using the same input data. The color code reﬂects the goodness of the\nmetrics by coloring in green high accuracies and low KL divergences and vice versa in red. We note\nthat the best hyperparameter choice is consistent with the results reported in Ref. [25]. Moreover,\nsince there is a fair agreement of the best regions in the upper (supervised) and lower (unsupervised)\npanels, this suggests that an unsupervised optimization in real data would select a region of good\naccuracy. Observe that right and left plots correspond not only to diﬀerent generators, but also to\nthe diﬀerent setup of the generator parameters.\nnot be surprising since the model only relies on the assumptions that the integer value\nnSD are composed of a mixture of approximately Poissonian distributions. In any case,\na more realistic detector simulation should be implemented to verify this analysis, which\nincludes modelling the energy response of various jet constituents, should be implemented.\nA diﬀerent and interesting extension is to extend the |y| range to include forward jets. For\nforward jets, the detector granularity changes and thus the nSD becomes more dependent\non |y|. It would then be necessary to introduce similar strategies as the ones detailed for\ndealing with a large pT range. Finally, we should mention that potential pile-up issues\nwould only have a minor eﬀect on the tagger, not only because nSD is a robust observable\nas it discards soft emission, but also because we are keeping a small radius (R = 0.4) in the\njet clustering algorithm.\n– 9 –\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nQuark eﬃciency ϵq\n0.0\n5.0\n10.0\n15.0\n20.0\n25.0\nGluon rejection factor 1/ϵg\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nThreshold\n0.5\n0.55\n0.6\n0.65\n0.7\nAccuracy\nPythia, zcut = 0.007, β = -1.0, θcut = 0.0, with 88888 train events and 11112 test events\nFigure 4. Left: ROC curve for a good hyperparameter choice (AUC=0.77). Right: Accuracy\nas a function of threshold for the same hyperparameter choice. We observe that the accuracy is\nconstant in regions and that it is maximum in the region that contains the default decision boundary\np(z = quark) = 0.5. The coarse behavior of the accuracy can be traced back to the probabilistic\nclassiﬁer dependence on the discrete nSD. A jet can have a discrete set of nSD and thus a discrete\nset of p(z = quark) values.\n0\n2\n4\n6\n8\n10\n12\nnSD\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150\n0.175\n0.200\nProbability Mass Function\nzcut = 0.007, β = -1.0, θcut = 0.0, N = 10000 jets\nσ/σ0 = 0.0\nσ/σ0 = 1.0\nσ/σ0 = 2.0\nσ/σ0 = 3.0\nFigure 5. Smeared nSD distributions obtained by applying the pT -dependent emulation of detector\neﬀects/response detailed in Eq. 3.2 and in Ref. [50] with diﬀerent scaling factors. A scaling factor of\n0 indicates no smearing while a scaling factor of 1 indicates the same smearing factor as in Ref. [50].\n4\nBayesian analysis\nAs a ﬁnal study for the model, we perform Bayesian inference to obtain the full posterior\nprobability density function over the parameters. Introducing uniform priors and perform-\ning numerical Bayesian inference, we obtain the posterior probabilities of π and λ. In order\nto achieve this goal, we employ the dedicated emcee package [51]. We show the result-\ning corner plot for a justiﬁed hyperparameter choice in Fig. 7. Because we have so many\njets and we consider uniform priors, the inference is likelihood dominated with a promi-\nnent posterior peak in the MLE. However, one should not lose sight of the fact that the\nposterior distribution includes more information than the MAP point estimates since we\n– 10 –\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nσ/σ0\n0\n1\n2\n3\n4\n5\n6\n7\n8\nλ\nMean Quark\nMean Gluon\nMLE Quark\nMLE Gluon\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nσ/σ0\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nAccuracy\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nAUC score\nzcut = 0.007, β = -1.0, θcut = 0.0, with 1112 test jets\nFigure 6. Model performance as a function of the angular smearing. In the left plot we show the\nobtained Maximum Likelihood Estimates for each Poisson rate and compare them with the means\nof the true underlying distributions. In the right plot we show the accuracy and the AUC as a\nfunction of the scaling factor.\ncan quantify the uncertainty of the π and λ estimation and their correlation. Suppose the\ngenerative model for the data is precise enough. In that case, this is a potentially useful\napplication as one could establish a distance between the data-driven posterior distribution\nand the diﬀerent Monte Carlo tunes one needs to consider to relate data with Standard\nModel predictions. In the speciﬁc case of the LL approximation for the nSD distribution\nas Poissonians, we ﬁnd by inspecting the MC labelled data that the agreement is not good\nenough to perform such a task (See Fig. 8). However, the approximation is good enough\nto distinguish the quark from the gluon nSD distributions, and therefore to create a good\nunsupervised classiﬁer.\nAnother feature of Bayesian computation is that we can compute the probability of a\ngiven measurement nSD belonging to class z integrated over the λg, λq and πg posterior\ndistribution. Using our Monte Carlo samples, we calculate\np(z | nSD, X) ≈1\nT\nT\nX\nt=1\np(z | nSD, π(t)\ng , λ(t)\ng , λ(t)\nq )\n(4.1)\nwhere X represents the training dataset and t is the posterior sample index. We show\nthis probability for both classes in Fig. 9. Although the MLE dominates the likelihood\nbecause of our uniform priors and the amount of data, this probability is a more solid\nestimate when we only care about classifying samples as it considers all possible values of\nthe underlying model parameters weighted by previous measurements through the posterior.\nThe performance of this tagger using the decision threshold of p(z = quark) = 0.5 yields\nan accuracy of 0.71.\n5\nDiscussion and outlook\nWe have proposed an unsupervised data-driven learning algorithm to classify jets induced\nby quarks or gluons. The key of the method is to approximate that each class (quark and\n– 11 –\nπg = 0.550+0.004\n−0.004\n4.12\n4.16\n4.20\n4.24\n4.28\nλg\nλg = 4.209+0.016\n−0.016\n0.53\n0.54\n0.55\n0.56\nπg\n1.08\n1.11\n1.14\n1.17\nλq\n4.12\n4.16\n4.20\n4.24\n4.28\nλg\n1.075\n1.100\n1.125\n1.150\n1.175\nλq\nλq = 1.124+0.012\n−0.012\nzcut = 0.007, β = -1.0, θcut = 0.0, N = 100000 jets, pT ∈[500.0,550.0] GeV and |y| < 1.7\nFigure 7. Corner plots for the model parameters πg, λq and λg. The diagonal plots are the 1D\nmarginalized posterior distributions for each parameter while the oﬀ-diagonal plots are the pairwise\n2D distributions marginalized over the third parameter. The πq distribution can be obtained by\nconsidering 1 −πg.\ngluon) has a Poissonian distribution with a diﬀerent rate for the jets’ Soft Drop observable,\nnSD. Therefore, the nSD distribution of a sample of an unknown mixture of quark and gluon\njets correspond to a mix of Poissonians. This observation, which is only for approximately\nconstant jet pT , allows to set up an unsupervised learning paradigm that can extract the\nMaximum Likelihood Estimate (MLE) and the posterior distributions for the rate of each\nPoissonian (λq and λg) and the fraction of each constituent in the sample (πq,g) and thus,\nwith this knowledge, one can create a tagger to discriminate quark and gluon induced\njets. This is all achieved without relying on any Monte Carlo generator, nor any previous\nknowledge other than the assumption that nSD is Poisson distributed for each class. We\nuse the basic principle knowledge that λg > λq to assign the tagging of the reconstructed\nthemes.\nIn the ﬁrst part of the work, we have deﬁned the generative process of the data ac-\ncording to the above hypothesis and obtained the MLE for the parameters using Stochastic\nVariational Inference and Expectation-Maximization techniques independently. We have\nthen designed a quark-gluon tagger and discussed a method to ﬁnd the best hyperparame-\n– 12 –\n0\n2\n4\n6\n8\n10\n12\n14\nnSD\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\nProbability Mass Function\nLn LMeans = -214531.0, Ln LMAP = -211884.0\nPoisson(µq)\nPoisson(λMAP\nq\n)\nPoisson(µq)\nPoisson(λMAP\ng\n)\nQuark Truth\nGluon Truth\npT ∈[500.0,550.0] GeV\nand |y| < 1.7\nFigure 8. nSD distribution comparison between pseudo-data generated through MC (solid) and\nPoissonians estimates using as rates the mean of the data (dashed) and the Maximum a Posteriori\nMAP from the Bayesian inference (dashed). We see that the Poissonian approximations are good\nenough to distinguish quark from gluon, but there are slight diﬀerences when comparing each\napproximation to its corresponding data.\n0\n2\n4\n6\n8\n10\n12\n14\nnSD\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\np(z|nSD, X)\nzcut = 0.007, β = -1.0, θcut = 0.0, N = 100000 jets\nz = Quark\nz = Gluon\npT ∈[500.0,550.0] GeV\nand |y| < 1.7\nFigure 9. Class assignment probabilities for each nSD possible value obtained after marginalizing\nover π and λ. Note that each nSD has its own probability mass function with two possible outcomes\nwith no constraint arising from summing over nSD.\nters choice for the SoftDrop algorithm that optimise the tagger accuracy. Since one cannot\nmeasure the accuracy in actual data because one does not have access to the labels, we\nhave shown that minimizing the KL divergence between the real data and generated data\nsampled with the generative model improves the tagger accuracy. We have veriﬁed that the\nprocedure works for diﬀerent Monte Carlo with diﬀerent tunes. One can expect that the\ndescribed unsupervised tagger can have an accuracy in the range ≈0.65 −0.70.\nWe have performed a simple detector eﬀect simulation by smearing the angular coor-\ndinate of each jet constituent, and we ﬁnd that the tagger accuracy remains approximately\nthe same.\nThis is not surprising since, despite the detector eﬀects, the nSD observable\nis still a counting observable that may vary its value but still be Poissonian distributed\n– 13 –\nwith shifted rates. Therefore the whole machinery of the unsupervised algorithm works\nessentially the same.\nIn a second part of the article, we have performed a Bayesian inference on the pa-\nrameters to extract the full posterior distribution and the correlation between the model\nparameters, namely λq, λg and πg.\nIn particular, we have found that the Maximum a\nPosterior (MAP) approximately coincides with the MLE of the parameters. Furthermore,\nwe have found that although the reconstructed Poissons for each class does not match the\nlabelled data within the posterior uncertainty, the classiﬁer still works quite good. The\nreason for this is that, although we can see a slight departure of the approximation of the\nnSD being Poissonian distributed, the two inferred Poissonians for quark and gluon still\nshow a more pronounced diﬀerence between them than its corresponding labelled data.\nWith the posterior obtained through Bayesian inference, we have designed a quark-\ngluon tagger based on computing the probability of a jet being induced by either quark or\ngluon using all the observed data. This is a more robust tagger since it sees the posterior\nand hence the correlation between the parameters rather than the point MLE. With this\ntagger, we obtain an accuracy of 0.71.\nThere are potential improvements and limitations on the proposed algorithm.\nFor\nexample, suppose one could have a model for the nSD that goes beyond the LL Poissonian\napproximation.\nIn that case, one could modify the likelihood and obtain the posterior\nfor the new likelihood parameters. Although we do not expect this to improve the tagger\naccuracy considerably, it could help tune a Monte Carlo using unsupervised learning. If\none could have a reliable posterior for speciﬁc signal distribution, then one could check\nwhether a Monte Carlo is compatible or not with it.\nObserve that, since Monte Carlo\ngenerators do not have a handle to set the value for each observable, having a prediction for\nsome observable and its uncertainty provides the necessary information to check whether\nthe Monte Carlo sampling is within the allowed regions deﬁned by the posterior. On other\naspects, we have performed simple modelling for the detector eﬀects, which apparently\nwould not aﬀect the tagger performance. Further investigation in this direction would be\nhelpful to ﬁnd the actual limitations of the algorithm.\nFinally, we should comment on the challenges that may arise when applying this algo-\nrithm in real data. A balanced quark/gluon dataset is far from guaranteed. However, we\nhave veriﬁed that the classiﬁcation and generative powers of the model are robust against\na change in the classes fractions up to a 80% in any class. There is also the possibility of\nsample contamination with, for example, charm- and bottom-quarks. If there is no need\nto disentangle charm- and bottom- from light-quarks, then no modiﬁcation is needed as\nnSD is mostly agnostic to quark ﬂavor for relatively ﬁxed jet kinematics. In particular, for\njets with pT ≫5 GeV c- and b-jets are as massless as light-jets and they have a similar\nnSD behavior. If b-tagging and c-tagging is needed, then the model should be extended\nby incorporating other observables which are sensitive to quark ﬂavor, like the number of\ndisplaced vertices in the jet, before searching for three themes instead of two.\nCurrent supervised algorithms to discriminate jets induced by quark or gluon have\na non-negligible dependence on Monte Carlo and their tunes, which may hide some in-\ntractable systematic uncertainties or biases. Therefore, we ﬁnd that proposing an unsuper-\n– 14 –\nvised paradigm for quark-gluon determination is an appealing road that should be transited.\nIn addition to being interpretable and straightforward, the presented algorithm yields an\naccuracy in the 0.65 −0.7 range, which is a good achievement for the small number of\nassumptions on which it relies.\nAcknowledgements\nMSz would like to thank the Jozef Stefan Institute for its warm hospitality during part of\nthis work. We thank Referees for relevant and useful suggestions which were included in\nthis revised version.\nReferences\n[1] G. Kasieczka et al., The LHC Olympics 2020: A Community Challenge for Anomaly\nDetection in High Energy Physics, arXiv:2101.08320.\n[2] T. Aarrestad et al., The Dark Machines Anomaly Score Challenge: Benchmark Data and\nModel Independent Event Classiﬁcation for the Large Hadron Collider, arXiv:2105.14027.\n[3] S. Choi, J. Lim, and H. Oh, Data-driven Estimation of Background Distribution through\nNeural Autoregressive Flows, arXiv:2008.03636.\n[4] S. Caron, L. Hendriks, and R. Verheyen, Rare and Diﬀerent: Anomaly Scores from a\ncombination of likelihood and out-of-distribution models to detect new physics at the LHC,\narXiv:2106.10164.\n[5] K. Dohi, Variational Autoencoders for Jet Simulation, arXiv:2009.04842.\n[6] R. T. d’Agnolo, G. Grosso, M. Pierini, A. Wulzer, and M. Zanetti, Learning New Physics\nfrom an Imperfect Machine, arXiv:2111.13633.\n[7] B. Nachman and D. Shih, Anomaly Detection with Density Estimation, arXiv:2001.04990.\n[8] A. Andreassen, B. Nachman, and D. Shih, Simulation Assisted Likelihood-free Anomaly\nDetection, arXiv:2001.05001.\n[9] J. Hajer, Y.-Y. Li, T. Liu, and H. Wang, Novelty detection meets collider physics, Physical\nReview D 101 (Apr, 2020).\n[10] T. S. Roy and A. H. Vijay, A robust anomaly ﬁnder based on autoencoders, 2020.\n[11] A. Andreassen, I. Feige, C. Frye, and M. D. Schwartz, JUNIPR: a Framework for\nUnsupervised Machine Learning in Particle Physics, Eur. Phys. J. C 79 (2019), no. 2 102,\n[arXiv:1804.09720].\n[12] CMS Collaboration, V. Khachatryan et al., Search for dark matter, extra dimensions, and\nunparticles in monojet events in proton–proton collisions at √s = 8 TeV, Eur. Phys. J. C 75\n(2015), no. 5 235, [arXiv:1408.3583].\n[13] Y. L. Dokshitzer, V. A. Khoze, and T. Sjostrand, Rapidity gaps in Higgs production, Phys.\nLett. B 274 (1992) 116–121.\n[14] D. L. Rainwater, D. Zeppenfeld, and K. Hagiwara, Searching for H →τ +τ −in weak boson\nfusion at the CERN LHC, Phys. Rev. D 59 (1998) 014037, [hep-ph/9808468].\n– 15 –\n[15] B. Bhattacherjee, S. Mukhopadhyay, M. M. Nojiri, Y. Sakaki, and B. R. Webber,\nQuark-gluon discrimination in the search for gluino pair production at the LHC, JHEP 01\n(2017) 044, [arXiv:1609.08781].\n[16] J. Gallicchio and M. D. Schwartz, Quark and Gluon Tagging at the LHC, Phys. Rev. Lett.\n107 (2011) 172001, [arXiv:1106.3076].\n[17] A. J. Larkoski, G. P. Salam, and J. Thaler, Energy Correlation Functions for Jet\nSubstructure, JHEP 06 (2013) 108, [arXiv:1305.0007].\n[18] A. J. Larkoski, J. Thaler, and W. J. Waalewijn, Gaining (Mutual) Information about\nQuark/Gluon Discrimination, JHEP 11 (2014) 129, [arXiv:1408.3122].\n[19] B. Bhattacherjee, S. Mukhopadhyay, M. M. Nojiri, Y. Sakaki, and B. R. Webber, Associated\njet and subjet rates in light-quark and gluon jet discrimination, JHEP 04 (2015) 131,\n[arXiv:1501.04794].\n[20] D. Ferreira de Lima, P. Petrov, D. Soper, and M. Spannowsky, Quark-Gluon tagging with\nShower Deconstruction: Unearthing dark matter and Higgs couplings, Phys. Rev. D 95\n(2017), no. 3 034001, [arXiv:1607.06031].\n[21] G. Kasieczka, N. Kiefer, T. Plehn, and J. M. Thompson, Quark-Gluon Tagging: Machine\nLearning vs Detector, SciPost Phys. 6 (2019), no. 6 069, [arXiv:1812.09223].\n[22] ATLAS Collaboration, G. Aad et al., Light-quark and gluon jet discrimination in pp\ncollisions at √s = 7 TeV with the ATLAS detector, Eur. Phys. J. C 74 (2014), no. 8 3023,\n[arXiv:1405.6583].\n[23] CMS Collaboration, Performance of quark/gluon discrimination in 8 TeV pp data, .\n[24] A. J. Larkoski, S. Marzani, G. Soyez, and J. Thaler, Soft Drop, JHEP 05 (2014) 146,\n[arXiv:1402.2657].\n[25] C. Frye, A. J. Larkoski, J. Thaler, and K. Zhou, Casimir Meets Poisson: Improved\nQuark/Gluon Discrimination with Counting Observables, JHEP 09 (2017) 083,\n[arXiv:1704.06266].\n[26] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Networks: Deep Sets for\nParticle Jets, JHEP 01 (2019) 121, [arXiv:1810.05165].\n[27] P. Komiske, E. Metodiev, and J. Thaler, Pythia8 quark and gluon jets for energy ﬂow,\nZenodo (2019).\n[28] T. Sjöstrand, S. Ask, J. R. Christiansen, R. Corke, N. Desai, P. Ilten, S. Mrenna, S. Prestel,\nC. O. Rasmussen, and P. Z. Skands, An introduction to PYTHIA 8.2, Comput. Phys.\nCommun. 191 (2015) 159–177, [arXiv:1410.3012].\n[29] A. Pathak, P. Komiske, E. Metodiev, and M. Schwartz, Herwig7.1 quark and gluon jets,\nZenodo (2019).\n[30] M. Bahr et al., Herwig++ Physics and Manual, Eur. Phys. J. C 58 (2008) 639–707,\n[arXiv:0803.0883].\n[31] J. Bellm et al., Herwig 7.0/Herwig++ 3.0 release note, Eur. Phys. J. C 76 (2016), no. 4 196,\n[arXiv:1512.01178].\n[32] P. T. Komiske, E. M. Metodiev, and J. Thaler, An operational deﬁnition of quark and gluon\njets, JHEP 11 (2018) 059, [arXiv:1809.01140].\n– 16 –\n[33] Y. L. Dokshitzer, G. D. Leder, S. Moretti, and B. R. Webber, Better jet clustering\nalgorithms, JHEP 08 (1997) 001, [hep-ph/9707323].\n[34] E. M. Metodiev, B. Nachman, and J. Thaler, Classiﬁcation without labels: Learning from\nmixed samples in high energy physics, JHEP 10 (2017) 174, [arXiv:1708.02949].\n[35] P. T. Komiske, E. M. Metodiev, B. Nachman, and M. D. Schwartz, Learning to classify from\nimpure samples with high-dimensional data, Phys. Rev. D98 (2018), no. 1 011502,\n[arXiv:1801.10158].\n[36] E. M. Metodiev and J. Thaler, Jet Topics: Disentangling Quarks and Gluons at Colliders,\nPhys. Rev. Lett. 120 (2018), no. 24 241602, [arXiv:1802.00008].\n[37] B. M. Dillon, D. A. Faroughy, and J. F. Kamenik, Uncovering latent jet substructure, Phys.\nRev. D100 (2019), no. 5 056002, [arXiv:1904.04200].\n[38] E. Alvarez, F. Lamagna, and M. Szewc, Topic Model for four-top at the LHC, JHEP 01\n(2020) 049, [arXiv:1911.09699]. [JHEP20,049(2020)].\n[39] B. M. Dillon, D. A. Faroughy, J. F. Kamenik, and M. Szewc, Learning the latent structure of\ncollider events, JHEP 10 (2020) 206, [arXiv:2005.12319].\n[40] E. Alvarez, B. M. Dillon, D. A. Faroughy, J. F. Kamenik, F. Lamagna, and M. Szewc,\nBayesian Probabilistic Modelling for Four-Tops at the LHC, arXiv:2107.00668.\n[41] G. Graziani, L. Anderlini, S. Mariani, E. Franzoso, L. Pappalardo, and P. di Nezza, A\nNeural-Network-deﬁned Gaussian Mixture Model for particle identiﬁcation applied to the\nLHCb ﬁxed-target programme, arXiv:2110.10259.\n[42] M. Štěpánek, J. Franc, and V. Kůs, Modiﬁcation of gaussian mixture models for data\nclassiﬁcation in high energy physics, Journal of Physics: Conference Series 574 (jan, 2015)\n012150.\n[43] B. M. Dillon, D. A. Faroughy, J. F. Kamenik, and M. Szewc, Learning Latent Jet Structure,\nSymmetry 13 (2021), no. 7 1167.\n[44] G. Celeux, S. Frühwirth-Schnatter, and C. Robert, Model Selection for Mixture\nModels-Perspectives and Strategies, in Handbook of Mixture Analysis. CRC Press, Dec., 2018.\n[45] C. M. Bishop, Pattern Recognition and Machine Learning. Springer Berlin Heidelberg,\nBerlin, Heidelberg, 2013.\n[46] E. Bingham, J. P. Chen, M. Jankowiak, F. Obermeyer, N. Pradhan, T. Karaletsos, R. Singh,\nP. Szerlip, P. Horsfall, and N. D. Goodman, Pyro: Deep Universal Probabilistic\nProgramming, Journal of Machine Learning Research (2018).\n[47] D. Phan, N. Pradhan, and M. Jankowiak, Composable eﬀects for ﬂexible and accelerated\nprobabilistic programming in numpyro, arXiv:1912.11554.\n[48] M. M. Deza and E. Deza, Encyclopedia of Distances, pp. 1–583. Springer Berlin Heidelberg,\nBerlin, Heidelberg, 2009.\n[49] P. T. Komiske, E. M. Metodiev, and J. Thaler, Metric Space of Collider Events, Phys. Rev.\nLett. 123 (2019), no. 4 041801, [arXiv:1902.02346].\n[50] A. Buckley, D. Kar, and K. Nordström, Fast simulation of detector eﬀects in Rivet, SciPost\nPhys. 8 (2020) 025, [arXiv:1910.01637].\n[51] D. Foreman-Mackey, D. W. Hogg, D. Lang, and J. Goodman, emcee: The mcmc hammer,\nPublications of the Astronomical Society of the Paciﬁc 125 (03, 2013) 306–312.\n– 17 –\n",
  "categories": [
    "hep-ph"
  ],
  "published": "2021-12-21",
  "updated": "2022-02-28"
}