{
  "id": "http://arxiv.org/abs/2202.01319v1",
  "title": "Deep Learning for Epidemiologists: An Introduction to Neural Networks",
  "authors": [
    "Stylianos Serghiou",
    "Kathryn Rough"
  ],
  "abstract": "Deep learning methods are increasingly being applied to problems in medicine\nand healthcare. However, few epidemiologists have received formal training in\nthese methods. To bridge this gap, this article introduces to the fundamentals\nof deep learning from an epidemiological perspective. Specifically, this\narticle reviews core concepts in machine learning (overfitting, regularization,\nhyperparameters), explains several fundamental deep learning architectures\n(convolutional neural networks, recurrent neural networks), and summarizes\ntraining, evaluation, and deployment of models. We aim to enable the reader to\nengage with and critically evaluate medical applications of deep learning,\nfacilitating a dialogue between computer scientists and epidemiologists that\nwill improve the safety and efficacy of applications of this technology.",
  "text": "Deep Learning for Epidemiologists: An\nIntroduction to Neural Networks\nStylianos Serghiou, Kathryn Rough\nFootnotes page\nAbbreviations\nAUPRC = area under the precision-recall curve; AUROC = area under the receiver\noperating characteristic; CNN = convolutional neural network; DL = deep learning; EHR =\nelectronic health record; FNN = feed-forward neural network; GRU = gated recurrent unit;\nLSTM = long short-term memory; ML = machine learning; ReLU = rectified linear unit; RGB\n= red green blue; RNN = recurrent neural network; SELU = Scaled Exponential Linear Unit\nCorresponding author\nStylianos Serghiou, MD, PhD Google Health, 1600 Amphitheatre Parkway, Mountain View,\nCA 94043, serghiou@google.com\n1\nAbstract\nDeep learning methods are increasingly being applied to problems in medicine and\nhealthcare. However, few epidemiologists have received formal training in these methods.\nTo bridge this gap, this article introduces to the fundamentals of deep learning from an\nepidemiological perspective. Specifically, this article reviews core concepts in machine\nlearning (overfitting, regularization, hyperparameters), explains several fundamental deep\nlearning architectures (convolutional neural networks, recurrent neural networks), and\nsummarizes training, evaluation, and deployment of models. We aim to enable the reader\nto engage with and critically evaluate medical applications of deep learning, facilitating a\ndialogue between computer scientists and epidemiologists that will improve the safety and\nefficacy of applications of this technology.\n2\nIn 1998, researchers used longitudinal data on seven carefully curated predictors from\n5,345 individuals to build the Framingham Risk Score for 10-year risk of coronary heart\ndisease (1). In the subsequent decades, it became one of the most well-known and\nfrequently utilized medical risk prediction models. Investigators prospectively collected\ndata from a 12-year cohort study and fit a Cox model to predictors identified using\ndecades of domain-specific knowledge. Though not typically regarded as such, the\nFramingham Risk Score and many other popular scores (2–4) are early applications of\nmachine learning in medicine (5).\nDeep learning is a subset of machine learning methods, recent advancements in which\nhave led to breakthroughs in tasks that are not easily handled by more traditional methods,\nincluding image recognition (6,7), language translation (8), text-to-speech generation (9),\nand text synthesis (10,11). While some deep learning techniques were originally proposed in\nthe 1980s, the increased availability of large datasets (12) and of better computing\nresources (13), have led to dramatic performance improvements in recent years.\nDeep learning techniques are increasingly being applied to tasks in the health and medical\ndomains (14), though few have reached the stage of clinical implementation (15). Studies\ndemonstrate that models can use optical coherence tomography images to classify need\nfor clinical referral on par with retinal specialists (16), use chest X-rays to diagnose\npneumonia on par with radiologists (17), and use electronic health records (EHR) to predict\nacute kidney injury two days in advance (18), among many other applications (19,20). These\nresults\nhave\nled\nto\nexcitement,\ndespite\nfew\nprospective\nevaluations\nand several\nmethodological concerns (21–24).\n3\nWith the abundance of research in this domain, it is important that epidemiologists and\nother health researchers are able to critically engage with and contribute to research using\ndeep learning. This review offers an accessible introduction to the basics of deep learning\nfrom an epidemiologic perspective. It covers fundamental principles of machine learning,\nan\nexplanation\nof\ncommon deep learning architectures, and summarizes training,\nevaluation, and deployment of models.\nMACHINE LEARNING FUNDAMENTALS\nIn the mid-80s, researchers at Massachusetts General Hospital developed a system that\nranked possible diagnoses based on up to 4,700 signs or symptoms. One of the first\nautomated\ndecision\nsupport\nsystems\nof\nits\nkind,\nDXplain\n(25,26)\nwas based on\nhuman-curated rules and information. For example, an expert specified chest pain and\nshortness of breath could be signs of myocardial infarction, pulmonary embolism, aortic\ndissection, or other conditions.\nDXplain is an ‘expert system’, a form of artificial intelligence (AI) outside the domain of\nmachine learning (Figure 1). ‘Artificial intelligence’ (27,28) was a phrase coined in the 1950s\nto encompass a broad collection of machine behavior and abilities traditionally attributed\nto intelligent beings, including image recognition, text summarization, and commonsense\nreasoning. The term ‘AI’ does not place constraints on the methods used to achieve these\ngoals. Early work in the field of AI, including DXplain, focused on creating decision systems\nthat followed hard-coded logical rules. In contrast, machine learning is a data-driven\napproach to AI that relies on “the ability to learn without being explicitly programmed” (a\n4\nquote often attributed to Arthur Samuel’s work in 1959 (29)). This review will not examine\nnon-machine learning approaches to AI.\nFigure 1. Terminology. Deep learning is a subfield of Machine Learning, which is a\nsubfield of Artificial Intelligence. This image was adapted from Goodfellow et al. (Chapter\n1, Page 9)\nMost machine learning algorithms can be classified as being supervised, unsupervised, or\nreinforcement learning approaches. In supervised learning, observations in the dataset\nneed ‘ground truth’ labels, and the algorithm learns to identify patterns in the data that are\nindicative of a certain label. Unsupervised approaches learn useful properties of the\ndataset, such as clustering (e.g., deriving ways of phenotyping sepsis (30)), without\nrequiring any labels. Reinforcement learning allows the use of trial and error to learn which\nactions generate the greatest rewards. Supervised learning algorithms tend to be used\nmost frequently, and are the focus of this article.\n5\nIn the supervised learning paradigm, each training example, or observation, in the dataset,\nhas two key components: its features (typically termed ‘variables’ or ‘predictors’ by\nepidemiologists) and its label (typically termed ‘outcomes’ by epidemiologists). Based on\ninternal parameters, the learning algorithm processes the features and produces an\noutput, which can be compared to the ground truth label. As the learning algorithm views\nmore training examples, it adjusts its parameters to minimize the difference between it’s\noutput and the ground-truth labels. These differences are quantified using a loss function,\nwhich is chosen based on the type of task the model is performing. The further the\nmodel’s output from ground-truth, the greater the loss. A perfect model would have a loss\nof zero. This may sound quite familiar; linear regression and logistic regression are both\nsupervised learning algorithms.\nIn addition to regression, numerous other machine learning algorithms fall outside the\nscope of deep learning, including support vector machines, naive-Bayes algorithms, and\ndecision trees (Bi and colleagues provided a thorough review of these methods in an\nearlier volume of AJE (31)). Terms used in the field of machine learning tend to vary from\nthose used in the medical literature. Table 1 contains common machine learning vocabulary\nand analogous epidemiologic terms as a reference for the reader.\nTable 1. Analogous epidemiologic terms for common machine learning vocabulary\nMachine learning term\nAnalogous epidemiology term or concept\nTraining example\nObservation, individual\nFeature\nPredictor, covariate, independent variable\nLabel\nOutcome, response variable\nNoisy labels\nOutcome with measurement error\nFeature engineering\nData pre-processing\nWeights\nModel coefficients\n6\nBias term\nModel intercept\nTraining\nModel fitting\nTraining set\nDerivation set\nBagging\nBootstrap model selection\nModel output\nPrediction\nSigmoid classifier\nLogistic regression\nSoftmax classifier\nMultinomial logistic regression\nL1 regularization\nLASSO regression\nL2 regularization\nRidge regression\nConfusion matrix\nContingency table, 2x2 table\nRecall\nSensitivity\nPrecision\nPositive predictive value\nDEEP LEARNING\nDeep learning is a collection of machine learning methods, where stacked processing\nlayers are used to create abstract representations of data, creating an artificial “neural\nnetwork” (32,33). These processing layers form an interconnected path from input features\n(e.g. age, smoking status, systolic blood pressure, etc.) to the model’s output (e.g. risk of\nheart disease). Initially inspired by mechanistic theories of brain physiology, each layer\nconsists of processing units called ‘neurons’ or ‘nodes’.\nNeural networks may be considered a more flexible approach to fitting a prediction model.\nPrediction modeling typically involves numerous pre-processing decisions: selecting a\nsubset of the available predictors using prior knowledge or a statistical procedure (e.g.\nstepwise regression), discretizing continuous predictors, introducing polynomials, or using\ninteraction terms. In deep learning, with enough data, pre-processing steps become\n7\nunnecessary because of the flexibility gained by multiple processing layers and nonlinear\ndata transformations, known as activation functions (32) (Figure 2).\nFigure 2. Traditional epidemiology vs. Deep Learning. The traditional process to data\nanalysis in epidemiology is one where the researcher will use a priori knowledge to\nengage in “feature discovery,” by selecting, transforming and modifying available data\ninto the most appropriate features for the task at hand. The researcher will then use a\nmethod of choice, such as logistic regression, to fit a model. Deep learning differs in that\nthe process of feature discovery can solely depend on the data at hand (i.e. it is\ndata-driven) and off-loaded to the neural network, rather than the researcher.\n8\nStructure\nThe building block of neural networks are neurons, each of which perform two fairly simple\noperations. First, the neuron calculates a weighted sum of the inputs; these weights are\nrandomly chosen at the start of model training and progressively revised to improve the\nperformance of the model (i.e., minimize loss) throughout the learning process. During the\nsecond step, the neuron applies a non-linear mathematical transformation, an activation\nfunction, to that weighted sum.\nWhile both of their operations are simple, neurons can be extremely powerful in aggregate.\nBy adding more layers (and more neurons per layer), it is possible to model highly complex\nfunctions, including non-linearities and interactions, without any further specification\n(Figure 3). The universal approximation theorem (34–36) demonstrates that a sufficiently\ndeep (i.e., many layers) or wide (i.e., many neurons) neural network can approximate any\ncontinuous mathematical function.\nA regression model can be expressed as a simple neural network. A network with an input\nlayer, an output layer, and no hidden layers (or, hidden layers of neurons applying linear\nactivation functions) will behave equivalently to linear regression.\n9\nFigure 3. Classification in increasingly non-linear data. In practice, discovering\nextremely complex high-dimensional functions is limited by finite amounts of data. Say\nwe are interested in fitting a model to classify each dot into the red group or the green\ngroup based on its location. Now consider a simple regression model with one parameter\nper predictor. Such a model would only perform well in a setting where the underlying\nfunction is itself roughly affine; it lacks the capacity to model more complicated\nfunctions. We could increase its capacity by using splines, polynomials, or interaction\nterms, but even with such approaches, performance in say the spiral panel would be\nterrible. In deep learning, such problems can be addressed by adding more layers,\nadding more neurons per layer, changing the learning rate and other modeling choices\ncollectively known as hyperparameters. You can test the impact of such choices in\nGoogle Playground, from which the data were adapted.\n10\nActivation functions\nAfter the weighted sum of the inputs is calculated by the neuron, an activation function\napplies\na\nmathematical\ntransformation.\nIn\ntheory,\nboth\nlinear\nand\nnon-linear\ntransformations may be used, but nonlinear functions are particularly useful because they\nincrease the network’s capacity to model nonlinearities in the data. In fact, it can be shown\nmathematically that multiple layers of linear transformations can be collapsed into a single\nlayer.\nThe rectified linear unit (ReLU) is a simple activation function used extensively in the\nmachine learning literature. If the input is positive, it outputs the value of the input. If the\noutput is negative or zero, it outputs zero.\nHyperparameters and training\n‘Hyperparameter’ is a term used to describe any modifiable or “tunable” modeling choice.\nIn regression, one could consider the use of higher order terms or interaction terms to be\nhyperparameters. In addition to increasing the complexity of the model structure, deep\nlearning also increases the number of hyperparameters: the number of layers, the number\nof neurons in layers, parameters for regularization, and batch size (i.e. how many examples\nare shown to the model before updating weights), among others. These hyperparameters\ndefine the structure of the neural network and dictate how it will be trained. Values of\nhyperparameters can have a large impact on model performance, and should be reported\nto enhance reproducibility.\nAmong the most important hyperparameters is the learning rate. Unlike regression, loss\nfunctions cannot be formulaically minimized in deep learning models. Instead, an iterative\n11\napproach known as gradient descent is commonly used. In simple terms, calculating the\ngradient tells us in which direction we should adjust parameter values. The magnitude of\nthe change made is partly determined by the learning rate hyperparameter. The learning\nrate is critical to the success of the gradient descent algorithm; too large a learning rate\ncan result in a failure to converge and too small will make the model train slowly and\ninefficiently.\nDEEP LEARNING ARCHITECTURES\nFully-connected Neural Networks\nFeed-forward neural networks (FNN) (also known as fully-connected neural networks,\nmulti-layer perceptrons, or dense neural networks) are the most fundamental type of deep\nlearning networks. They consist of one or more fully-connected layers (Figure 4). In a\nfully-connected layer, each neuron receives the output of all neurons from the previous\nlayer. Based on learned weights, neurons calculate a weighted average of these inputs,\napply an activation function, and  propagate their output to neurons in the next layer.\n12\nFigure 4. The basic architecture of Fully-connected Neural Networks (FNNs). This\nfigure demonstrates a FNN that predicts mortality on the basis of age (in years) and the\nbody mass index (BMI; in kg/m2). FNNs only consist of fully-connected layers. This figure\ndemonstrates three fully-connected layers, each of which consists of four neurons (in\nblue). Starting from the input layer (in gray), each neuron receives an input, takes a\nweighted average of that input using arrow-specific weights, applies an activation\nfunction (in orange; here we demonstrate ReLU: max(0, x)) and propagates the activated\nweighted average to each of the neurons of the next hidden layer. The depicted FNN is a\n4-layer neural network because it consists of 4 layers of learned parameters (3 hidden\nlayers, 1 output layer).\nExamples in health research\nAvati et al. (37) used the electronic health record (EHR) of 221,284 patients and 13,654\ndifferent features to predict all-cause mortality within the following year. To do so, they\n13\nsplit the available data into training, validation and test sets at a ratio of 8:1:1. They trained\nan FNN with 18 fully-connected layers of 512 neurons each. The neurons in these layers\nused an activation function closely-related to the ReLU, a scaled exponential linear unit\n(SELU). The output layer used a single neuron with a logistic activation function to output a\nprobability. Their model correctly identified 1 in 3 deaths at the pre-specified tolerance of 1\nin 10 false alarms.\nConvolutional neural networks\nConvolutional neural networks (CNNs) are a family of deep learning models particularly\nwell-suited to tasks involving images. However, they can also be used with other data types\n(e.g., medical records) (38,39). The networks have three core components: convolutional\nlayers, pooling layers and fully-connected layers. These layers can be rearranged into\ndifferent architectures of varying complexity.\nConvolutional layers\nGenerally speaking, there are several reasons why FNNs are poorly suited to process\nimages. They require an inefficiently large number of trainable parameters. Digital images\nare represented to machine learning models as grids of tens of thousands of pixels, each\nwith a numerical red, green and blue (RGB) value. If each RGB value is a feature and each\nneuron is fully connected, the exponential increase in weights from adding neurons or\nlayers quickly becomes an issue. Further inefficiencies arise because weights learned by\nneurons are not shared in FNNs; if the network learns to locate an object of interest in one\narea of the frame, it will need to re-learn the pattern if the object is shifted. Similarly, FNNs\n14\nlack an inherent structure to compare a given pixel with the pixels around it. Finally, an FNN\nis only capable of processing images of a fixed size.\nThese issues motivated the creation of convolutional layers (Figure 5). Conceptually,\nconvolutional layers recognize patterns across an image by maintaining a consistent but\nsmall number of weights. Each convolutional layer is a square (e.g., 1x1, 3x3, 5x5) of learned\nweights, known as the ‘filter’. The filter is first applied at the top left of an image, and the\nweight of the filter corresponds to a pixel. Each convolutional layer can have multiple\nfilters, the same way a fully-connected layer can have multiple neurons. A pixel’s value is\nmultiplied by the corresponding weight. The filter then moves to the right by a\npre-specified number of pixels or ‘stride,’ and repeats the process of multiplying pixel\nvalues by weights to create an image representation. Continuing this process across the\nwhole image is a ‘convolution.’ As with fully-connected layers, an activation function is\napplied to the output of the filter before being fed to the next layer.\nConvolutions\ncreate\n‘translation invariant’ representations, meaning their output is\nconsistent regardless of where in the picture the object may be. Often, they are\nconceptualized as ‘feature detectors’ because they are able to represent specific features\n- early layers detect basic features, such as edges and outlines of a face. Later layers\ndetect more complex features and shapes, such as the eyes or the mouth of a face.\n15\nFigure 5. The basic architecture of Convolutional Neural Networks (CNN). CNNs are\ncharacterized by their inclusion of convolutional and pooling layers. Each of these layers\nconsists of one or more filters of identical dimensions and of as many channels as their\ninput. The input in this figure consists of three channels, in reminiscence of the standard\nRGB channels of an image (but, the input does not need to be an image and does not\nneed to be constrained to 3 channels). Each channel of each filter is applied to the top\nleft corner of the input, each input is multiplied by its respective weight and all values are\nthen summed across channels, including the bias term. The filter is then moved by a\npredetermined stride (i.e. the number of squares by which the filter will move) to the\nright and down to cover the whole input. A padding of zeros is used so that the filter\nalways perfectly fits into the input. An activation function is then applied to each of the\ntotals, filter-specific outputs are stacked onto each other (such that the output of each\nfilter now represents a new channel) and the stacked output is propagated to the next\nlayer. A convolutional layer is almost always followed by a pooling layer (in this case and\nin most cases, max pooling), which is applied across the output of the convolutional layer\nin a similar fashion as described above. Note that no activation is applied after max\n16\npooling. Finally, it is common to finish off a CNN with one or more fully-connected layers,\nwhere each rectangle of the max pooling output represents a single feature input to the\nfully-connected layer. Image adapted from the CS231n course at Stanford University.\nPooling layers\nConvolutional layers are interlaced with pooling layers, which aggregate information across\nrectangular “neighborhoods” of an image. This reduces the size of its representation and\nhelps neural networks identify specific features (e.g. a mouth of a face), regardless of their\nlocation within the image; they play a critical role in the performance of CNNs (40).\nTypically, pooling layers will take the maximum value of the neighborhood (“max pooling”),\nbut they can also take the average (“average pooling”). Unlike most other types of layers\ndiscussed, no activation function is applied to the output of pooling layers, nor do they\ncontain any learned parameters.\nExamples in health research\nIn 2017, Esteva et al. published a paper evaluating the ability of a CNN to classify skin lesion\nphotographs into the risk of having each one of 2,032 different dermatologic diseases (41).\nAuthors\nfound\nthe\nmodel\nachieved\nperformance\non\npar\nwith\n21\nboard-certified\ndermatologists\nin\nprediction\nof\nkeratinocyte\ncarcinomas versus benign seborrheic\nkeratoses and malignant melanomas versus benign nevi.\nThe study used a previously-developed CNN architecture, Inception-v3 (42). The network\ncontained repeated convolution and pooling layers, and had been originally trained to\nclassify ImageNet, a non-medical dataset of over 14 million photographs from more than\n17\n21,000 categories (12,43). Esteva et al. leveraged this “pre-trained” model, and refitted the\nfinal fully-connected layers using the dermatology images and labels in their dataset.\nRepurposing pre-trained CNNs for medical tasks is a frequently-used strategy known as\n‘transfer learning’; otherwise, training performant CNN architectures from scratch can\nrequire enormous resources.\nRecurrent neural networks (RNNs)\nThere are many tasks where the ordering of model inputs matters, such as the sequence of\nwords in natural language processing or the sequence of notes in music recognition.\nRecurrent Neural Networks (RNNs) process data in a sequential fashion, achieving\nbetter-than-human ability in tasks such as speech recognition (44).\nRecurrent layer\nIn its simplest form, a recurrent layer is a fully-connected layer that feeds into itself;\noutputs at one timestep become inputs at the next timestep (Figure 6). Take for example\nthe phrase “the quick brown fox jumps over the lazy dog”. We first create a mathematical\nrepresentation for each word. A straightforward way of doing so is to create an indicator\nvector (i.e., a vector where the position corresponding to the specific word equals to 1 and\nall other positions to 0). However, the indicator method is inefficient; words can\nalternatively be represented as embeddings, where words that are similar are represented\nby vectors that are close to one another in vector space. Using embeddings tends to\nimprove model performance, and a number of these embeddings are open sourced and\nfreely available (10,45,46).\n18\nFigure 6. The basic architecture of Recurrent Neural Networks (RNN). RNNs are\ncharacterized by their inclusion of recurrent layers. Each recurrent layer takes a\nweighted average of input from the previous time point (known as the “hidden state”),\nadds it to a weighted average of the input from the current time point (known as the\n“embedding”), adds a bias term, applies an activation function (e.g. ReLU) and\npropagates the activated weighted average to the next time point. Image adapted from\nThamarasee Jeewandara’s article (2020) on Phys.org.\nA basic RNN unit consists of a single layer and an activation function, and it will process the\nsequence from left to right. The vector representing the first word, ‘the’ is propagated\nthrough the layer, and an activation function is applied. The output will be concatenated\n(i.e. bundled) with the vectorized representation of “quick”, passed through the same\n19\nnetwork, and the output will again be concatenated with the representation of the next\nword. This process continues as the model iterates through the entire sequence. Notice\nthat the RNN unit remains unchanged, we are simply looping through the inputs.\nPredictions or inferences can be made using outputs of the model at any stage (i.e., a\nprediction can be made after each item in the sequence or after the entire sequence has\nbeen processed).\nSimple RNN units often fail to retain key contextual information that occurred earlier in the\nsequence (47). Instead, many RNNs use other types of units, such as Gated Recurrent\nUnits (GRU) (48), or Long-Short Term Memory (LSTM) units (49). LSTMs have an additional\n‘memory’ state that allows storage of information from previous hidden states, in addition\nto the hidden state maintained by the simple RNN unit. At each subsequent time step along\nthe sequence, the LSTM takes two inputs: the hidden state from the previous time step\nand the values of the predictors at the current time step. Using these inputs, it determines\nwhat new information to retain, what old information to forget and what information to pass\nalong to the next time step as an output. This last value is the new hidden state at the\ncurrent time point and captures information that was seen recently, as well as several time\nsteps before.\nExamples in health research\nUse of RNN architectures has often led to higher performance than standard feedforward\nnetworks (14). Choi et al. used an RNN to predict the risk of being diagnosed with heart\nfailure in a matched case-control sample within the next 12 months (50). Embeddings were\nused to capture clinical events in the timeline of a patient (e.g. being diagnosed with\n20\npneumonia, having a chest X-Ray, or being prescribed amoxicillin). A GRU was used to\npropagate through each event in the sequence it was recorded. At the end of the\nsequence of clinical events, the model output a probability of heart failure.\nModern directions\nThere has been substantial work on alternative architectures for sequences that mitigate\nsome of the limitations of RNNs. RNNs cannot organically represent events occurring at\nvarying or irregular time intervals; recent work proposed RNNs that work on a continuum,\nrather than discrete event units (51).\nEven LSTMs and GRUs have limited capacity to\neffectively capture long-term dependencies; transformer models use a mechanism called\n‘attention’ (52) to simultaneously process all sequence elements, which has led to\nenormous improvements in performance (8,10).\nAlternative architectures\nCNNs and RNNs represent only a portion of deep learning architectures. Other models\ninclude deep generative models (53), Bayesian neural networks (54,55), graphical models\n(56), and general adversarial networks\n(57–59), though we are unable to describe these\narchitectures in detail in this review.\nMODEL FITTING\nDeep learning models can have substantial capacity. Given raw data and labels, the\nnetwork can “discover” intermediate representations that facilitate translation of a given\n21\ninput into the desired output, referred to as ‘end-to-end’ learning. Neural networks have\nthe ability to use, combine, and create intermediate representations of features through\nlearned weights. Figuring out which models are ‘optimal’ typically requires partitioning the\ndata,\nfitting\nmultiple\nmodels\nwith\ndifferent\nspecifications,\nand\nchoosing\nthe\nbest-performing model according to a metric of interest.\nTraining, validation, and test sets\nUsing the same data to fit a model and evaluate it will lead to an overoptimistic estimate of\nperformance in the target population. To prevent this, machine learning typically splits the\navailable data into three sets: the training, validation, and test sets (the training-validation\nsplit can be avoided if cross-validation is used). The split ratio can vary depending on total\ndataset size. The training set can be used to train a variety of models. Performance of\nthese models is compared by measuring their performance on the validation set.\nThe\n‘held-out’ test set should be used only once, to assess performance after the final model\nhas been selected.\nHyperparameter tuning\nThere is typically limited theoretical understanding of which modeling choices will work well\nfor a given machine learning task. Choosing hyperparameters often requires iterative\nexperimentation, a process known as tuning. Candidate values can be found through\nrandom search (values randomly selected independently of one another) or Bayesian\nhyperparameter optimization (60) (conditioning on the observed performance of previous\nhyperparameter combinations to inform which combination of hyperparameters should be\ntested next).\n22\nRegularization\nThe ultimate goal of fitting a model is to generalize well to a target population that has not\nyet been “seen” by the model. Models with sufficient capacity can ‘memorize’ training data\n- they fit to noise rather than signal - and become ‘overfit.’ In contrast, models with\ninadequate capacity will poorly model the underlying function; this is often referred to as\n‘underfitting’. Overfitting is diagnosed when a model performs very well in the training set,\nbut poorly in the validation set. Underfit models will perform poorly both in the training and\nvalidation sets.\nRegularization helps to minimize overfitting. There are several methods to regularize\nmodels; the most widely used is weight decay, which adds an extra term to the loss\nfunction to shrink small weights to 0 (known as L1 regularization) or to shrink all weights by\na small amount (known as L2 regularization). In addition to these methods, deep learning\nutilizes many other methods of regularization, such as adding random noise (61) to the\ninputs, dropout (62) and batch normalization (63)\nPerformance metrics\nA number of metrics can be used to quantify the performance of the model and\nappropriate performance metrics will depend on the task. For binary classification tasks,\ncommon metrics include recall (sensitivity in epidemiological literature), precision (positive\npredictive value in epidemiological literature), accuracy, area under the receiver operating\ncurve (AUROC), area under the precision-recall curve (AUPRC) and calibration.\nAUPRC is a particularly useful metric for measuring performance when there is a large\nimbalance in the prevalence of different outcome labels (64,65). It is a measure of average\n23\npositive predictive value, across all values of sensitivity and varies in value from the\nprevalence of the outcome in the sample (no predictive ability) to 1 (perfect predictive\nability).\nCalibration measures how well the expected risk corresponds to the observed risk and may\nbe assessed using a calibration curve, the Greenwood-Nam-D’agostino test (a modified\nversion of the Hosmer-Lemeshow chi-squared statistic) (66) or the Brier score.\nReporting\nmultiple\nmetrics\nwith\nconfidence\nintervals\nand\na\nclinically\nmeaningful\ninterpretation of the result is generally good practice. On their own, standard machine\nlearning metrics do not quantify potential benefits or harms to the patient.\nPractical challenges for real-world use of deep learning\nThe use of machine learning-enabled technologies in real-world clinical settings presents\nnumerous practical challenges (67).\nIn non-healthcare settings, model performance tends to degrade with time, and the\nperformance originally measured in the test set overestimates real-world performance.\nThis phenomenon is known as the “training-serving skew.” We can view this as a failure of\nthe model to generalize to the population it is currently being used in (a lack of external\nvalidity). This can have several root causes, including temporal shifts in the input features\n(e.g., changes in patient behavior, clinical or operational practices), or differences between\nthe population included in the training set versus actual users of the technology.\nContinuous\nperformance\nmonitoring\nis\nimportant\nfor\ndetection\nof\nperformance\n24\ndegradation, and deployed deep learning models are often retrained on fairly regular\nschedules to mitigate this issue.\nThe use of machine learning in clinical settings also has the potential to propagate or\nincrease existing disparities in healthcare. Ensuring fairness requires a holistic approach\n(68), including consideration of biases in formulation of the machine learning task, training\nset composition, labeling of observations, non-random missingness of data, and real-world\nuse of the models.\nCONCLUSION\nIn a 1970 commentary, physician William Shwartz mused, “indeed, it seems probable that in\nthe not too distant future the physician and the computer will engage in frequent dialogue,\nthe computer continuously taking note of history, physical findings, laboratory data, and\nthe like, alerting the physician to the most probable diagnoses and suggesting the\nappropriate, safest course of action.” (69) While this vision has certainly not been realized,\ndeep learning may enable tooling that facilitates parts of it. Deep learning presents real\nopportunities for improving the quality of care provided to patients, as well as numerous\nchallenges.\nWe hope this review has provided you with the foundation needed to engage with research\nthat\nuses\ndeep\nlearning,\neither\nas\na\ncollaborator,\nreviewer,\nor\ncritical\nreader.\nEpidemiologists have a critical role to play in the development of these technologies and in\nmeasuring their real-world impact and safety.\n25\nAcknowledgements\nAuthor affiliations\n1.\nGoogle LLC, Mountain View, California (Stylianos Serghiou)\n2. Meta-Research\nInnovation Center at Stanford, Stanford University School of\nMedicine, Stanford University, Stanford, California (Stylianos Serghiou)\n3. IQVIA (Kathryn Rough)\nAuthor contribution\nBoth authors contributed equally to this work.\nFinancial support\nThis work was supported by Google, LLC.\nPresentation at a meeting\nA version of this work was presented at the Society for Epidemiologic Research’s 2019\nMeeting.\n26\nConflicts of Interest\nStylianos Serghiou and Kathryn Rough were employed by Google, LLC at the time this\narticle was originally drafted. Kathryn Rough currently is employed by IQVIA.\n27\nReferences\n1.\nWilson PW, D’Agostino RB, Levy D, et al. Prediction of coronary heart disease using risk\nfactor categories. Circulation. 1998;97(18):1837–1847.\n2.\nKnaus WA, Wagner DP, Draper EA, et al. The APACHE III prognostic system. Risk\nprediction\nof\nhospital\nmortality\nfor\ncritically\nill\nhospitalized\nadults.\nChest.\n1991;100(6):1619–1636.\n3.\nLip GYH, Nieuwlaat R, Pisters R, et al. Refining clinical risk stratification for predicting\nstroke and thromboembolism in atrial fibrillation using a novel risk factor-based\napproach: the euro heart survey on atrial fibrillation. Chest. 2010;137(2):263–272.\n4.\nWells PS, Ginsberg JS, Anderson DR, et al. Use of a clinical model for safe\nmanagement of patients with suspected pulmonary embolism. Ann. Intern. Med.\n1998;129(12):997–1005.\n5.\nBeam AL, Kohane IS. Big Data and Machine Learning in Health Care. JAMA.\n2018;319(13):1317–1318.\n6.\nKrizhevsky A, Sutskever I, Hinton GE. ImageNet Classification with Deep Convolutional\nNeural Networks. In: Pereira F, Burges CJC, Bottou L, et al., eds. Advances in Neural\nInformation Processing Systems 25. Curran Associates, Inc.; 2012:1097–1105.\n7.\nHe K, Zhang X, Ren S, et al. Identity Mappings in Deep Residual Networks. In: Computer\nVision – ECCV 2016. Springer International Publishing; 2016:630–645.\n8.\nVaswani A, Shazeer N, Parmar N, et al. Attention is All you Need. In: Guyon I, Luxburg\nUV, Bengio S, et al., eds. Advances in Neural Information Processing Systems 30.\nCurran Associates, Inc.; 2017:5998–6008.\n9.\nvan den Oord A, Dieleman S, Zen H, et al. WaveNet: A Generative Model for Raw Audio.\n28\narXiv [cs.SD]. 2016;(http://arxiv.org/abs/1609.03499)\n10. Devlin J, Chang M-W, Lee K, et al. BERT: Pre-training of Deep Bidirectional\nTransformers\nfor\nLanguage\nUnderstanding.\narXiv\n[cs.CL].\n2018;(http://arxiv.org/abs/1810.04805)\n11.\nRadford A, Wu J, Child R, et al. Language Models are Unsupervised Multitask Learners.\n(https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/\nPAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask-%20Lear\nners.pdf)\n12.\nDeng J, Dong W, Socher R, et al. ImageNet: A large-scale hierarchical image database.\nIn: 2009 IEEE Conference on Computer Vision and Pattern Recognition. 2009:248–255.\n13.\nKrizhevsky A. One weird trick for parallelizing convolutional neural networks. arXiv\n[cs.NE]. 2014;(http://arxiv.org/abs/1404.5997)\n14. Xiao C, Choi E, Sun J. Opportunities and challenges in developing deep learning\nmodels using electronic health records data: a systematic review. Journal of the\nAmerican\nMedical\nInformatics\nAssociation.\n2018;25(10):1419–1428.\n(http://dx.doi.org/10.1093/jamia/ocy068)\n15.\nShah P, Kendall F, Khozin S, et al. Artificial intelligence and machine learning in clinical\ndevelopment: a translational perspective. NPJ Digit Med. 2019;2:69.\n16.\nDe Fauw J, Ledsam JR, Romera-Paredes B, et al. Clinically applicable deep learning for\ndiagnosis and referral in retinal disease. Nat. Med. 2018;24(9):1342–1350.\n17.\nRajpurkar P, Irvin J, Zhu K, et al. CheXNet: Radiologist-Level Pneumonia Detection on\nChest X-Rays with Deep Learning. arXiv [cs.CV]. 2017;(http://arxiv.org/abs/1711.05225)\n18.\nTomašev N, Glorot X, Rae JW, et al. A clinically applicable approach to continuous\nprediction of future acute kidney injury. Nature. 2019;572(7767):116–119.\n19.\nRavi D, Wong C, Deligianni F, et al. Deep Learning for Health Informatics. IEEE J Biomed\n29\nHealth Inform. 2017;21(1):4–21.\n20. Topol EJ. High-performance medicine: the convergence of human and artificial\nintelligence. Nat. Med. 2019;25(1):44–56.\n21.\nGoldstein BA, Navar AM, Pencina MJ, et al. Opportunities and challenges in developing\nrisk prediction models with electronic health records data: a systematic review. J. Am.\nMed. Inform. Assoc. 2017;24(1):198–208.\n22. Chen JH, Asch SM. Machine Learning and Prediction in Medicine - Beyond the Peak of\nInflated Expectations. N. Engl. J. Med. 2017;376(26):2507–2509.\n23. Emanuel EJ, Wachter RM. Artificial Intelligence in Health Care: Will the Value Match the\nHype? JAMA. 2019;321(23):2281–2282.\n24. Rajkomar A, Dean J, Kohane I. Machine Learning in Medicine. N. Engl. J. Med.\n2019;380(14):1347–1358.\n25. Octo Barnett G, Cimino JJ, Hupp JA, et al. DXplain: An Evolving Diagnostic\nDecision-Support System. JAMA. 1987;258(1):67–74.\n26. Miller RA. Medical diagnostic decision support systems--past, present, and future: a\nthreaded\nbibliography\nand\nbrief\ncommentary.\nJ.\nAm.\nMed.\nInform.\nAssoc.\n1994;1(1):8–27.\n27.\nMcCarthy J, Minsky ML, Shannon CE, et al. A Proposal for the Dartmouth Summer\nResearch Project on Artificial Intelligence. 1955 34 p.\n28. McCarthy J. Recursive functions of symbolic expressions and their computation by\nmachine,\nPart\nI.\nCommunications\nof\nthe\nACM.\n1960;3(4):184–195.\n(http://dx.doi.org/10.1145/367177.367199)\n29. Samuel AL. Some Studies in Machine Learning Using the Game of Checkers. IBM\nJournal\nof\nResearch\nand\nDevelopment.\n1959;3(3):210–229.\n30\n(http://dx.doi.org/10.1147/rd.33.0210)\n30. Seymour CW, Kennedy JN, Wang S, et al. Derivation, Validation, and Potential\nTreatment\nImplications\nof\nNovel\nClinical\nPhenotypes\nfor\nSepsis.\nJAMA.\n2019;321(20):2003–2017.\n31.\nBi Q, Goodman KE, Kaminsky J, et al. What is Machine Learning? A Primer for the\nEpidemiologist. Am. J. Epidemiol. 2019;188(12):2222–2239.\n32. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature. 2015;521(7553):436–444.\n33. Goodfellow I, Bengio Y, Courville A. Deep Learning. MIT Press; 2016 775 p.\n34. Cybenko G. Approximation by superpositions of a sigmoidal function. Math. Control\nSignals Systems. 1989;2(4):303–314.\n35. Leshno\nM,\nLin\nVY,\nPinkus\nA,\net\nal.\nMultilayer\nfeedforward\nnetworks\nwith a\nnonpolynomial activation function can approximate any function. Neural Netw.\n1993;6(6):861–867.\n36. Hanin B, Sellke M. Approximating Continuous Functions by ReLU Nets of Minimal\nWidth. arXiv [stat.ML]. 2017;(http://arxiv.org/abs/1710.11278)\n37. Avati A, Jung K, Harman S, et al. Improving palliative care with deep learning. BMC\nMed. Inform. Decis. Mak. 2018;18(Suppl 4):122.\n38. Razavian N, Marcus J, Sontag D. Multi-task Prediction of Disease Onsets from\nLongitudinal Laboratory Tests. Proceedings of Machine Learning Research [electronic\narticle]. 2016;56. (http://proceedings.mlr.press/v56/Razavian16.html)\n39. Yang Z, Huang Y, Jiang Y, et al. Clinical Assistant Diagnosis for Electronic Medical\nRecord Based on Convolutional Neural Network. Sci. Rep. 2018;8(1):6329.\n40. Boureau Y-L, Ponce J, LeCunn Y. A theoretical analysis of feature pooling in visual\nrecognition. In: Proceedings of the 27th International Conference on International\n31\nConference on Machine Learning. 2010:111–118.\n41.\nEsteva A, Kuprel B, Novoa RA, et al. Dermatologist-level classification of skin cancer\nwith deep neural networks. Nature. 2017;542(7639):115–118.\n42. Szegedy C, Vanhoucke V, Ioffe S, et al. Rethinking the Inception Architecture for\nComputer Vision. 2016 IEEE Conference on Computer Vision and Pattern Recognition\n(CVPR). 2016;(http://dx.doi.org/10.1109/cvpr.2016.308)\n43. Image\nClassification\non\nImageNet.\nPapers\nWith\nCode.\n2020;(https://paperswithcode.com/sota/image-classification-on-imagenet). (Accessed\n, 17 July, 2020)\n44. Shoham Y, Perrault R, Brynjolfsson E, et al. Artificial Intelligence Index. 2017.\n45. Mikolov T, Sutskever I, Chen K, et al. Distributed Representations of Words and Phrases\nand their Compositionality. In: Burges CJC, Bottou L, Welling M, et al., eds. Advances in\nNeural Information Processing Systems 26. Curran Associates, Inc.; 2013:3111–3119.\n46. Pennington J, Socher R, Manning C. GloVe: Global Vectors for Word Representation. In:\nProceedings of the 2014 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP). 2014:1532–1543.\n47. Bengio Y, Simard P, Frasconi P. Learning long-term dependencies with gradient\ndescent is difficult. IEEE Trans. Neural Netw. 1994;5(2):157–166.\n48. Cho K, van Merrienboer B, Gulcehre C, et al. Learning Phrase Representations using\nRNN Encoder–Decoder for Statistical Machine Translation. Proceedings of the 2014\nConference\non\nEmpirical\nMethods\nin\nNatural\nLanguage\nProcessing\n(EMNLP).\n2014;(http://dx.doi.org/10.3115/v1/d14-1179)\n49. Hochreiter\nS,\nSchmidhuber\nJ.\nLong\nshort-term\nmemory.\nNeural\nComput.\n1997;9(8):1735–1780.\n50. Choi E, Schuetz A, Stewart WF, et al. Using recurrent neural network models for early\n32\ndetection of heart failure onset. J. Am. Med. Inform. Assoc. 2017;24(2):361–370.\n51.\nRubanova Y, Chen RTQ, Duvenaud D. Latent odes for irregularly-sampled time series.\nIn: 33rd Conference on Neural Information Processing Systems (NeurIPS 2019). 2019\n52. Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align\nand translate. In: International Conference on Learning Representations (ICLR). 2015\n53. Oussidi\nA,\nElhassouny\nA.\nDeep\ngenerative\nmodels: Survey. 2018 International\nConference\non\nIntelligent\nSystems\nand\nComputer\nVision\n(ISCV).\n2018;(http://dx.doi.org/10.1109/isacv.2018.8354080)\n54. Bishop CM. Bayesian methods for neural networks. Aston University; 1995.\n55. Mullachery V, Khera A, Husain A. Bayesian Neural Networks. arXiv [electronic article].\n2018;(https://arxiv.org/abs/1801.07710)\n56. Johnson MJ, Duvenaud DK, Wiltschko A, et al. Composing graphical models with\nneural networks for structured representations and fast inference. In: Lee DD,\nSugiyama M, Luxburg UV, et al., eds. Advances in Neural Information Processing\nSystems 29. Curran Associates, Inc.; 2016:2946–2954.\n57. Senior AW, Evans R, Jumper J, et al. Improved protein structure prediction using\npotentials from deep learning. Nature. 2020;577(7792):706–710.\n58. Jordon J, Yoon J, van der Schaar M. PATE-GAN: Generating synthetic data with\ndifferential\nprivacy\nguarantees.\nIn:\nInternational\nConference\non\nLearning\nRepresentations. 2018\n59. Yahi A, Vanguri R, Elhadad N, et al. Generative Adversarial Networks for Electronic\nHealth Records: A Framework for Exploring and Evaluating Methods for Predicting\nDrug-Induced Laboratory Test Trajectories. In: Neural Information Processing Systems:\nMachine Learning for Health (NeurIPS ML4H). 2017\n60. Bergstra J, Yamins D, Cox DD. Making a science of model search: hyperparameter\n33\noptimization in hundreds of dimensions for vision architectures. In: Proceedings of the\n30th International Conference on International Conference on Machine Learning.\n2013:115–123.\n61.\nBishop CM. Training with Noise is Equivalent to Tikhonov Regularization. Neural\nComputation. 1995;7(1):108–116. (http://dx.doi.org/10.1162/neco.1995.7.1.108)\n62. Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: a simple way to prevent neural\nnetworks from overfitting. J. Mach. Learn. Res. 2014;15(1):1929–1958.\n63. Ioffe S, Szegedy C. Batch Normalization: Accelerating Deep Network Training by\nReducing Internal Covariate Shift. In: Proceedings of the 32nd International Conference\non\nInternational\nConference\non\nMachine\nLearning\n-\nVolume\n37.\nJMLR.org;\n2015:448–456.\n64. Davis J, Goadrich M. The relationship between Precision-Recall and ROC curves.\nProceedings of the 23rd international conference on Machine learning - ICML ’06.\n2006;(http://dx.doi.org/10.1145/1143844.1143874)\n65. Leisman DE. Rare Events in the ICU: An Emerging Challenge in Classification and\nPrediction. Crit. Care Med. 2018;46(3):418–424.\n66. D’Agostino RB, Nam B-H. Evaluation of the Performance of Survival Analysis Models:\nDiscrimination\nand\nCalibration\nMeasures.\nHandbook\nof\nStatistics.\n2003;1–25.\n(http://dx.doi.org/10.1016/s0169-7161(03)23001-7)\n67. Kelly CJ, Karthikesalingam A, Suleyman M, et al. Key challenges for delivering clinical\nimpact with artificial intelligence. BMC Med. 2019;17(1):195.\n68. Rajkomar A, Hardt M, Howell MD, et al. Ensuring Fairness in Machine Learning to\nAdvance Health Equity. Ann. Intern. Med. 2018;169(12):866–872.\n69. Schwartz WB. Medicine and the computer. The promise and problems of change. N.\nEngl. J. Med. 1970;283(23):1257–1264.\n34\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2022-02-02",
  "updated": "2022-02-02"
}