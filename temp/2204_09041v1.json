{
  "id": "http://arxiv.org/abs/2204.09041v1",
  "title": "Unsupervised detection of ash dieback disease (Hymenoscyphus fraxineus) using diffusion-based hyperspectral image clustering",
  "authors": [
    "Sam L. Polk",
    "Aland H. Y. Chan",
    "Kangning Cui",
    "Robert J. Plemmons",
    "David A. Coomes",
    "James M. Murphy"
  ],
  "abstract": "Ash dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is\ncausing the widespread death of ash trees across Europe. Remote sensing\nhyperspectral images encode rich structure that has been exploited for the\ndetection of dieback disease in ash trees using supervised machine learning\ntechniques. However, to understand the state of forest health at\nlandscape-scale, accurate unsupervised approaches are needed. This article\ninvestigates the use of the unsupervised Diffusion and VCA-Assisted Image\nSegmentation (D-VIS) clustering algorithm for the detection of ash dieback\ndisease in a forest site near Cambridge, United Kingdom. The unsupervised\nclustering presented in this work has high overlap with the supervised\nclassification of previous work on this scene (overall accuracy = 71%). Thus,\nunsupervised learning may be used for the remote detection of ash dieback\ndisease without the need for expert labeling.",
  "text": "Unsupervised detection of ash dieback disease (Hymenoscyphus\nfraxineus) using diﬀusion-based hyperspectral image clustering\nSam L. Polk1, Aland H. Y. Chan2, Kangning Cui3, Robert J. Plemmons4,\nDavid A. Coomes2, and James M. Murphy∗1\n1 Department of Mathematics, Tufts University\n2 Department of Plant Sciences, University of Cambridge\n3 Department of Mathematics, City University of Hong Kong\n4 Departments of Mathematics and Computer Science, Wake Forest University\nAbstract\nAsh dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is causing the widespread\ndeath of ash trees across Europe.\nRemote sensing hyperspectral images encode rich structure that\nhas been exploited for the detection of dieback disease in ash trees using supervised machine learning\ntechniques. However, to understand the state of forest health at landscape-scale, accurate unsupervised\napproaches are needed. This article investigates the use of the unsupervised Diﬀusion and VCA-Assisted\nImage Segmentation (D-VIS) clustering algorithm for the detection of ash dieback disease in a forest\nsite near Cambridge, United Kingdom. The unsupervised clustering presented in this work has high\noverlap with the supervised classiﬁcation of previous work on this scene (overall accuracy = 71%). Thus,\nunsupervised learning may be used for the remote detection of ash dieback disease without the need for\nexpert labeling.\nIndex Terms: Clustering, Diﬀusion, Forestry, Graphs, Hyperspectral Imagery, Unsupervised Machine\nLearning.\n1\nIntroduction\nAsh dieback disease, caused by the Hymenoscyphus fraxineus ascomycete, poses a major threat to the\nhealth of European forests and ash-dependent biota [11]. To aid epidemiologists and forest managers in the\nmodeling and mitigation of ash dieback disease, healthy and infected trees must be identiﬁed at landscape-\nscale [3]. Recent years have brought signiﬁcant advances in methods for passive remote sensing of forest\npathogens [19, 20]. For example, remote sensing hyperspectral images (HSIs) are high-dimensional images\nthat encode rich structure that can be exploited by machine learning algorithms for the detection of diseases\nin forests [3, 19, 20]. While HSIs may be used for disease detection, the large volume of HSI data generated\nover forests makes manual labeling (generally required for supervised learning) infeasible. Thus, unsupervised\nmachine learning algorithms are needed to produce accurate disease mappings of forests using HSIs.\nThis article implements the unsupervised Diﬀusion and VCA-Assisted Image Segmentation (D-VIS) on\nan HSI generated over a forest in Madingley Village, near Cambridge, United Kingdom [3]. D-VIS is closely\nrelated to Diﬀusion and Volume maximization-based Image Clustering (D-VIC), which has been shown to\nsuccessfully recover ground truth labels from benchmark HSIs [17]. We compare an unsupervised D-VIS\nclustering to a disease mapping generated by a supervised Random Forest (RF) [3]. High levels of overlap\nwere observed between unsupervised and supervised partitions, indicating that unsupervised learning—and\n∗Corresponding Author: JM.Murphy@Tufts.edu\nThis work was partially funded by the US National Science Foundation grants NSF-DMS 1924513, NSF-CCF 1934553, and\nNSF-DMS 1912737.\n1\narXiv:2204.09041v1  [cs.CV]  19 Apr 2022\nD-VIS, in particular—may be used to detect ash dieback disease in European forests even when no ground\ntruth labels are available.\nThe rest of this article is structured as follows. In Section 2, background material is provided on HSI\nsegmentation, diﬀusion geometry, spectral unmixing, and the D-VIS clustering algorithm.\nIn Section 3,\nthe Madingley HSI is described, and disease mappings obtained by D-VIS are presented. We conclude and\nsuggest directions for future work in Section 4.\n2\nBackground\n2.1\nHyperspectral Image Segmentation\nLet X = {xi}n\ni=1 ⊂RD be the set of HSI pixel spectra, where n and D indicate the number of pixels and\nbands, respectively. HSI segmentation algorithms partition an HSI into clusters of pixels {Xk}K\nk=1 [6, 7].\nIdeally, any two pixels in the same cluster will be similar, but two pixels from diﬀerent clusters will be\ndissimilar [7]. Supervised HSI segmentation algorithms rely on some fraction of the image’s ground truth\nlabels to obtain a partition of X. Conversely, unsupervised HSI segmentation algorithms (also called HSI\nclustering algorithms) require no ground truth labels to partition X [7].\n2.2\nDiﬀusion Geometry\nGraph-based HSI clustering algorithms treat each pixel as a node in an undirected graph [5]. The edges\nbetween pixels can be encoded in an adjacency matrix W ∈Rn×n, where Wij = 1 if xj is one of the N\nℓ2-nearest neighbors of xi and Wij = 0 otherwise. Deﬁne P = D−1W, where D ∈Rn×n is the diagonal\ndegree matrix deﬁned by Dii = Pn\nj=1 Wij. We identify P as the transition matrix for a Markov diﬀusion\nprocess on HSI pixels.\nAssuming P is irreducible and aperiodic, there is a unique π ∈R1×n satisfying\nπP = π [5].\nDiﬀusion distances enable the comparison of HSI pixels in the context of the diﬀusion process encoded\nin P [5, 10]. Deﬁne\nDt(xi, xj) =\nv\nu\nu\nu\nt\nn\nX\nk=1\n\u0010\u0000Pt\u0001\nik −\n\u0000Pt\u0001\njk\n\u00112\nπk\nto be the diﬀusion distance between xi and xj at time t ≥0 [5]. For datasets with highly coherent and\nwell-separated latent cluster structure, the maximum within-cluster diﬀusion distance is bounded away from\nthe minimum between-cluster diﬀusion distance across a large range of t [10, 14]. As such, diﬀusion distances\ncan be used to learn latent structure in HSIs.\n2.3\nSpectral Unmixing\nHSIs are usually generated at a relatively coarse spatial resolution (often with a spatial resolution as high\nas 10 m) [6].\nAs such, in many scenarios (e.g., disease mapping in forests), a single pixel may corre-\nspond to a spatial region containing multiple materials. If m is the number of materials present in the\nscene, the goal of a linear spectral unmixing algorithm is to ﬁnd two nonnegative matrices, A ∈Rn×m and\nU =\n(u1, u2, . . . , um)⊤∈Rm×D such that xi ≈Pm\nj=1 Aijuj for each xi ∈X [4, 15]. Ideally, the rows\nof U will encode the intrinsic spectral signatures associated with materials in the scene, while the rows of\nA encode the relative frequency that those materials appear in a given pixel. Information about material\nabundance can be summarized using pixel purity, deﬁned for each xi ∈X by\nη(xi) = max1≤j≤m Aij\nPm\nj=1 Aij\n.\nThe function η(x) will be nearly 1 if the spatial region corresponding to the pixel x contains predominantly\none material, and η(x) will be small for mixed pixels containing many materials [16, 17].\n2\nAlgorithm 1: Diﬀusion and VCA-Assisted Image Segmentation (D-VIS)\nInput: X (HSI), K (# clusters), N (# neighbors), σ0 (density scale), t (diﬀusion time)\nOutput: ˆC = {Xk}K\nk=1 (clustering)\n1 Calculate η(x) by implementing HySime [1] to estimate m and VCA [2, 15] to estimate U and A;\n2 Calculate ζ(x) using density p(x) (see Section 2.4);\n3 Label cluster modes ˆC(xmk) = k for 1 ≤k ≤K, where {xmk}K\nk=1 are the K maximizers of\nDt(x) = ζ(x)dt(x); dt(x) is as in Section 2.4;\n4 In order of non-increasing ζ(x), assign unlabeled points x ∈X the label ˆC(x) = ˆC(x∗), where\nx∗= argmin\ny∈X\nn\nDt(x, y)\n\f\f\f ζ(y) ≥ζ(x) and ˆC(y) > 0\no\n;\n2.4\nDiﬀusion and VCA-Assisted Image Segmentation\nIn its ﬁrst stage, D-VIS (Algorithm 1) locates K pixels that exemplify underlying structure in the HSI.\nTo locate these cluster modes, D-VIS ﬁrst calculates η(x) using HySime [1] to learn m and VCA [2, 15] to\nlearn A and U. This diﬀers slightly from D-VIC, which relies on Alternating Volume Maximization to learn\nU [4, 17]. Next, D-VIS calculates density:\np(x) =\nX\ny∈NN(x,N)\nexp\n\u0012\n−∥x −y∥2\n2\nσ2\n0\n\u0013\n,\nwhere NN(x, N) is the set of N ℓ2-nearest neighbors of x in X and σ0 > 0 is a density scale that controls\ninteractions between points. The functions p(x) and η(x) are combined into a single measure\nζ(x) = 2¯p(x)¯η(x)\n¯p(x) + ¯η(x),\nwhere ¯p(x) =\np(x)\nmaxy∈X p(y) and ¯η(x) =\nη(x)\nmaxy∈X η(y). As the harmonic mean of pixel purity and density, ζ(x)\nwill be large if and only if x is both modal (i.e., close to its N ℓ2-nearest neighbors) and representative of a\nsingle material in the scene (i.e., high-purity).\nCluster modes are identiﬁed in D-VIS as the maximizers of Dt(x) = ζ(x)dt(x), where\ndt(x) =\n\n\n\nmin\ny∈X {Dt(x, y)|ζ(y) ≥ζ(x)}\nx = argmin\ny∈X\nζ(y),\nmax\ny∈X Dt(x, y)\notherwise.\nThe function dt(x) outputs the diﬀusion distance at time t between x and its diﬀusion distance-nearest\nneighbor of higher ζ-value. Thus, Dt-maximizers are high-density, high-purity pixels that are far in diﬀusion\ndistance at time t from other high-density, high-purity pixels. As such, these K points are suitable exemplars\nfor the materials in the scene. Cluster modes are given unique labels, and each non-modal x ∈X is, in order\nof non-increasing ζ(x), given the label of its Dt-nearest neighbor of higher ζ-value that is already labeled.\n3\nUnsupervised Ash Dieback Detection\n3.1\nMadingley Hyperspectral Image\nThis article presents the implementation of D-VIS on hyperspectral data collected by a human-crewed aircraft\nover a 512m × 356m region of temperate deciduous forest near Madingley, on the outskirts of Cambridge,\nUnited Kingdom, in August 2018 [3].\nSpectral reﬂectance was recorded using a Norsk Elektro Optikk\nhyperspectral camera (Hyspex VNIR 1800) at a spectral resolution of 3.26 nm across wavelengths 410-1001\nnm and at a high spatial resolution of 0.32 m. Thus, reﬂectance at a total of D = 186 spectral bands\nwas recorded for 1816835 pixels in a scene with spatial dimensions of 1601 × 1113. QUick Atmospheric\nCorrection [6] was implemented to remove atmospheric eﬀects on pixel spectra, and spectral signatures were\nnormalized to prevent diﬀerences in illumination from corrupting classiﬁcation results [3].\n3\nFigure 1: Ground truth labels and PLSDA species mapping for the Madingley HSI [3]. Colors indicate\ndiﬀerent tree species. The class marked in yellow corresponds to ash trees.\n3.2\nSupervised Classiﬁcation of Ash Dieback Disease\nTo enable the detection of ash dieback disease in the Madingley scene, a Partial Least Squares Discriminant\nAnalysis (PLSDA) classiﬁer was trained to locate pixels corresponding to ash trees in the Madingley scene [3].\nGround truth labels were collected for 166 tree crowns in the Madingley region as well as 256 tree crowns\nfrom three other forest sites near Cambridge [3]. Manually delineated and labeled tree crowns from these\nfour forest sites were separated into training (70%) and testing (30%) sets. The resulting species mapping\nwas highly accurate, with an overall accuracy of 85.3% on the testing dataset [3]. The ground truth labels\nand PLSDA species mapping are visualized in Fig. 1.\nAsh dieback disease was identiﬁed using a supervised RF classiﬁer [3]. The RF was trained to detect\nthree disease classes—infected, severely infected, and healthy—among trees labeled ash in the PLSDA species\nmapping. Models were trained and tested using the average pixel spectra of tree crowns, where the testing\nset included 16 trees from each disease class. The resulting RF classiﬁer demonstrated strong recovery of\nash dieback disease in the Madingley scene, with an overall accuracy of 77.1% [3].\n3.3\nUnsupervised Classiﬁcation of Ash Dieback Disease\nThis section presents the results of unsupervised clustering of the Madingley HSI using the D-VIS clustering\nalgorithm. Because ash trees aﬀected by dieback often have a mosaic of healthy and dead branches, the pixels\ncorresponding to visibly infected trees at the original 0.32 m spatial resolution may resemble the pixels of\nhealthy trees [3]. Therefore, to provide a more holistic assessment of tree health (as opposed to that of the\nhealth of individual branches), the HSI was downsampled to a spatial resolution of 1.28 m using bicubic\ninterpolation [8] so that each pixel covered multiple branches.\nPixels corresponding to species other than ash in the PLSDA species mapping were discarded, leaving\nn = 72775 pixels across a 401×279 scene. D-VIS relied on a sparse K-nearest neighbors graph with N = 150\nedges per pixel, a density scale σ0 = 3.89 × 10−4, and t = 25. We set K = 2 so that classes corresponded to\nhealthy and dieback-infected trees. After cluster analysis, majority voting was implemented among pixels in\neach delineated tree crown, yielding an unsupervised tree crown-level disease mapping.\nFor validation, the unsupervised D-VIS clustering was compared against the supervised RF classiﬁcation\nof ash dieback disease obtained in prior work [3] after aligning labels using the Hungarian algorithm. The two\ndieback classes in the RF disease mapping (infected and severely infected) were combined, yielding a single\n“dieback” class. A matching matrix summarizing the overlap between the supervised RF and unsupervised\nD-VIS labelings is provided in Table 1, while disease mappings are visualized in Fig. 2. D-VIS and RF\ndisease mappings exhibited a high level of overlap, with D-VIS achieving an overall accuracy of 71.0% and\naverage accuracy of 71.3%. Thus, unsupervised clustering algorithms such as D-VIS may be used for the\ndetection of ash dieback disease using hyperspectral data, even when no ground truth labels are available.\n4\nFigure 2: Supervised RF [3] and unsupervised D-VIS disease mappings of the Madingley HSI. Signiﬁcant\noverlap exists between the two labelings, indicating that unsupervised methods such as D-VIS may be used\nfor ash dieback disease mapping when no ground truth labels are available.\n4\nConclusions\nWe conclude that the unsupervised D-VIS clustering algorithm can successfully identify ash dieback disease\nfrom remote sensing HSIs.\nFuture work includes implementing the pipeline developed in this article on\nadditional forest regions as further validation, as well as scaling up our approach to be implemented on\nlarger forests. Moreover, we expect the unsupervised learning procedure outlined in this article to be useful\nfor the remote detection of other damaging agents in forests and hope to consider this problem in future\nwork. Finally, the performance of D-VIS is likely to improve upon further modiﬁcation (e.g., modifying for\nactive learning [9, 12, 16] or adding spatial regularization [12, 13, 18]).\n5\nAcknowledgments\nWe acknowledge 2Excel Geo (in particular, Dr. Chloe Barnes) for collecting the high-resolution HSI used\nin this study. We thank the University of Cambridge for critical support and access to the Madingley ﬁeld\nsite. We thank the Wildlife Trust for Bedfordshire, Cambridgeshire & Nottinghamshire for allowing access\nto other woodland sites. Finally, we thank Dr. Carola-Bibiane Sch¨onlieb for operating the INTEGRAL\nresearch group during the Zoom meetings of which many discussions that motivated this work occurred.\nReferences\n[1] J. M. Bioucas-Dias and J. M. P. Nascimento, Hyperspectral subspace identiﬁcation, IEEE Trans\nGeosci Remote Sens, 46 (2008), pp. 2435–2445.\nHealthy\nDieback\nProducer’s Acc.\nHealthy\n27460\n12895\n68.0%\nDieback\n8238\n24182\n74.6 %\nUser’s Acc.\n76.9%\n65.2%\nTable 1: Matching matrix showing overlap between the unsupervised D-VIS and supervised RF ash dieback\nmappings [3]. Rows summarize how pixels labeled by the RF in a ﬁxed class were classiﬁed by D-VIS. “Acc.”\nindicates Accuracy.\n5\n[2] R. Bro and S. De Jong, A fast non-negativity-constrained least squares algorithm, J Chemom, 11\n(1997), pp. 393–401.\n[3] A. H. Y. Chan, C. Barnes, T. Swinfield, and D. A. Coomes, Monitoring ash dieback (Hy-\nmenoscyphus fraxineus) in British forests using hyperspectral remote sensing, Remote Sens Ecol Con-\nserv, 7 (2021), pp. 306–320.\n[4] T. Chan, W. Ma, A. Ambikapathi, and C. Chi, A simplex volume maximization framework for\nhyperspectral endmember extraction, IEEE Trans Geosci Remote Sens, 49 (2011), pp. 4177–4193.\n[5] R. R. Coifman and S. Lafon, Diﬀusion maps, Appl Comput Harm Anal, 21 (2006), pp. 5–30.\n[6] M. T. Eismann, Hyperspectral remote sensing, SPIE, 2012.\n[7] J. Friedman, T. Hastie, and R. Tibshirani, The elements of statistical learning, Springer, 2001.\n[8] R. Keys, Cubic convolution interpolation for digital image processing, IEEE Trans Signal Process, 29\n(1981), pp. 1153–1160.\n[9] M. Maggioni and J. M. Murphy, Learning by active nonlinear diﬀusion, Found Data Sci, 1 (2019),\np. 271.\n[10]\n, Learning by unsupervised nonlinear diﬀusion, J Mach Learn Res, 20 (2019), pp. 1–56.\n[11] L. V. McKinney et al., The ash dieback crisis: genetic variation in resistance can prove a long-term\nsolution, Plant Pathol, 63 (2014), pp. 485–499.\n[12] J. M. Murphy, Spatially regularized active diﬀusion learning for high-dimensional images, Pattern\nRecognit Lett, 135 (2020), pp. 213–220.\n[13] J. M. Murphy and M. Maggioni, Spectral–spatial diﬀusion geometry for hyperspectral image clus-\ntering, IEEE Geosci Remote Sens Lett, 17 (2019), pp. 1243–1247.\n[14] J. M. Murphy and S. L. Polk, A multiscale environment for learning by diﬀusion, Appl Comput\nHarm Anal, 57 (2022), pp. 58–100.\n[15] J. M. P. Nascimento and J. M. Bioucas-Dias, Vertex component analysis: A fast algorithm to\nunmix hyperspectral data, IEEE Trans Geosci Remote Sens, 43 (2005), pp. 898–910.\n[16] S. L. Polk, K. Cui, R. J. Plemmons, and J. M. Murphy, Active diﬀusion and VCA-assisted image\nsegmentation of hyperspectral images, arXiv preprint arXiv:2204.06298, (2022).\n[17]\n, Diﬀusion and volume maximization-based clustering of highly mixed hyperspectral images, arXiv\npreprint arXiv:2203.09992, (2022).\n[18] S. L. Polk and J. M. Murphy, Multiscale clustering of hyperspectral images through spectral-spatial\ndiﬀusion geometry, in Proc IEEE Geosci Remote Sens Symp, 2021, pp. 4688–4691.\n[19] C. Stone and C. Mohammed, Application of remote sensing technologies for assessing planted forests\ndamaged by insect pests and fungal pathogens: a review, Curr For Rep, 3 (2017), pp. 75–92.\n[20] L. T. Waser, M. K¨uchler, K. J¨utte, and T. Stampfer, Evaluating the potential of Worldview-2\ndata to classify tree species and diﬀerent levels of ash mortality, Remote Sens, 6 (2014), pp. 4515–4545.\n6\n",
  "categories": [
    "cs.CV",
    "cs.LG",
    "stat.AP"
  ],
  "published": "2022-04-19",
  "updated": "2022-04-19"
}