{
  "id": "http://arxiv.org/abs/2205.01069v1",
  "title": "Deep Learning: From Basics to Building Deep Neural Networks with Python",
  "authors": [
    "Milad Vazan"
  ],
  "abstract": "This book is intended for beginners who have no familiarity with deep\nlearning. Our only expectation from readers is that they already have the basic\nprogramming skills in Python.",
  "text": "به نام خدا \n \n \n \n \nیادگیری عمی  ق \n  از\nاصول اولیه  تا ساخت شبکه\nهای عصبی عمیق با پایتون \n \n \n \n \n \n \n \n \n \n \n \nتالیف و گردآوری:\n \nمیالد \n وزان \n \n \n \n \n \n \n \nMiaadpub.ir \n : تلفن انتشارات09125120067\n – \n02166017448\n- \n02166014797\n \n \n \n  :عنوان کتاب یادگیری  عمیق: از\nاصول اولیه  تا ساخت شبکه  های عصبی عمیق با  پایتون  \n \nتالیف و گردآوری :میالد  وزان \n ناشر: میعاد اندیشه \n  نوبت چاپ: اول-  \n1401\n \n  :شمارگان1000\n  \n نسخه \n  :قیمت \n1150000\n  \n ریال \n:شابک0\n–\n909\n–  \n231\n  –  \n622\n  - \n978\n \nهمه \n ی حقوق مادی و معنوی این اثر برای\nمولف \n .محفوظ است \nتکثیر و انتشار این اثر به هر صورت، از جمله بازنویسی، فتوکپی، ضبط الکترونیکی \n و ذخیره در سیستم های بازیابی و پخش، بدون دریافت مجوز کتبی و قبلی از \n.به هر شکلی ممنوع است \n این اثر تحت حمایت «قانون حمایت از حقوق مولفان، مصنفان و هنرمندان ایران» قرار دارد \nسرشناسه \n:\n \n وزان، میالد-۱۳۷۱ ،\n \nعنوان و نام پديدآور \n:\n یادگیری عمیق: از اصول اولیه تا ساخت شبکه های عصبی عمیق با پایتون/ تالیف و گردآوری\n .میالد وزان \n مشخصات نشر \n:\n \n  ، تهران: میعاد اندیشه.۱۴۰۱\n \n مشخصات ظاهری \n:\n \n.ص ۲۰۲\n .: مصور، جدول، نمودار \n شابک \n:\n \n9۷8-6۲۲-۲۳۱-9۰9-۰\n \n وضعیت فهرست نویسی:\n \n فیپا \n موضوع \n:\n \n یادگیری عمیق \nDeep Learning\n \n \n فراگیری ماشینی \nMachine learning\n  \n \n )کامپیوتر نویسی برنامه  زبان( پایتون  \n \nPython (Computer program language)\n \n \n ساختار داده ها--\n الگو  های ریاضی \nData structures (computer science) -- Mathematical models\n \n رده بندی کنگره \n:\n \nLB۱۰۶۰\n \n رده بندی دیویی \n:\n \n۱۵۲۳/۳۷۰\n \nشماره کتابشناسی ملی \n:\n \n8۷99۶۳۷\n \n اطالعات رکورد\n کتابشناسی \n:\n \n فیپا \n \nمولف\n \n \n \n \n نسخهpdf \n کتاب توسط مولف به صورت رایگان\nبه اشتراک گذاشته شده است  \n \n و\nهرگونه استفاده تجاری از ٱن پیگرد قانونی دارد .\n \n \n \nاست\nفاده از مطالب کتاب بدون ذکر من\nبع\n، غیراخالق .ی و غیرقانونی است \n \n \n \n \n \n \n \nد\nیگر کت اب\nها \nیری ادگ ی ی عم ق\n: اصول، مفاه\nی م ی و رو کردها یری ادگ ی ماش\nین \n و علم داده: مبان، مفاه\nی،م الگور\nی تم\nها و ابزارها\n \n \n دانلود رایگان \n دانلود را\nی گان \n \nپیش\nگفتار \n \n  یادگیری عمیق یک فناوری جدید قدرتمند است\nکه  محبوبیت آن روز به روز در حوزه  های مختلف\nدر حالِ افزایش است. از این  رو، بسیار مهم است که به یادگیری آن بپردازیم. این کتاب برای افراد\nمبتدی که هیچ آشنایی با یادگیری عمیق ندارند در نظر گرفته شده است تا خوانندگان را ب  ا یک\nدوره  یِ فوقِ سریع در یادگیری عمیق آماده کند. تنها انتظار ما از خوانندگان این است که از قبل\n مهارت های برنامه\nنویسی اولیه در زبان پایتون را داشته باش ن  .د \nاین راهنمایِ کوتاه،  \n  در نظر گرفته شده است تا شما را به عنوان یک مبتدی با درک درستی از\nموضوع، از جمله  تجربهِیِ عملی  \n ملموس در توسعه مدل\nها، مجهز کن  .د  اگر در حال حاضر باالتر\nاز سطح مبتد\nی هست\nدی ، این کتاب مناسب شما نیست !\n \n \n \n \n \n \n \n \n \n \n \n \nمیالد وزان \nکاشمر-\n بهار1401\n09370174459\nvazanmilad@gmail.com\n \nفهرست \n \n :فصل اول\nمقدمه\nای \n ی بر ادگ\nیری ی عم ق\n مقدمه \n12\n \nادگ ی\nیری  ی عم ق یچ\nست؟ \n12\n \nشی دا یپ ادگ ی یری  قی عم  ؟ \n13\n \nعلت محبوب\nتی ادگ ی\nری ی عم قی  ؟ \n \n14\n \nادگ ی\nیری  ی عم ق چگونه کار م ی\nکند؟ \n16\n \nبی معا \n و چالش\nی ها ادگ ی\nی یر عم قی \n17\n \nآی\nنده\nی ادگ ی\nی یر ی عم ق؟ \n21\n \n استدالل نماد\nین  (\nsymbolic reasoning\n )\n22\n \nکاربردها\nی ادگ ی یری  ی عم ق؟ \n23\n \nدست\nی اران مجاز ی \n23\n \nتجم\nیع \n اخبار و کشف اخبار تقلب \n23\n \nهوش عاطف ی \n24\n \n مراقبت\nی ها بهداشت ی \n24\n \nشناسا\nیی کالهبردار ی \n24\n \n خالصه فصل \n25\n \n آزمونک \n25\n \n مقدمه28\n \n ( دادهData\n )\n \n28\n \nداده\nی ها \n قابل خواندن توسط ماش\nنی در مقابل قابل خواندن توسط انسان29\n \nعبارت داده در فناور ی29\n \n انواع داده\nها \n30\n \nعدد\nی  (\nNumeric\n )ای یپ وسته  (\nContinuous\n )\n \n30\n \n رسته\nای  (\nCategorical\n )ای اسم ی  (\nNominal\n )\n31\n \n مجموعه داده \n31\n \nی رو\nکردها\nی ادگ ی یری  ماش\nی ن \n32\n \nادگ ی\nیری  \n بانظارت \n32\n \nطبقه\nبند\nی  (\nClassification\n )\n \n33\n \nرگرس\nی ون \n35\n \nای مزا و معا\nبی  ادگ ی\nیر ی \n بانظارت \n35\n \nادگ ی\nیری  \n بدون نظارت \n36\n \nخوشه\nبند\nی \n37\n \nکاهش ابعاد37\n \nسه ی مقا ادگ ی\nیر ی \n بانظارت با\nادگ ی یری \n بدون نظارت \n38\n \n چرا\nادگ ی یری \n بدون\nنظارت؟ \n38\n \nای مزا و معا\nبی  ادگ ی\nیر ی \n بدون نظارت \n40\n \nادگ ی\nیری تقو\nیت ی40\n \nانتخاب و ارز\nی اب ی \n مدل \n41\n \n تقس\nبند می\nی \n داده\nها \n43\n \nموازنه سوگ\nی یر و وار\nانس ی  (\nBias-Variance Trade-Off\n )\n \n44\n \nروش\nی ها اب ی ارز ی \n46\n \n :فصل دوم\nینشیپ ازها\n \nی مع\nارها\nی ی اب ی ارز  \n کارآ\nیی \n46\n \n ابزارها و کتابخانه\nی ها ی پا تون \n49\n \nنصب پا\nی تون \n49\n \nشروع کار با پا\nی تون \n49\n \n نصب کتابخانه\nها \n51\n \nJupyter  Notebook\n................................\n \n51\n \nColab\n \n53\n \n چارچوب\nی ها ادگ ی\nری ی عم ی ق55\n \nی پا تورچ  (\nPyTorch\n )\n \n56\n \nای مزا و معا\nی ب \n56\n \n ( تنسورفلوTensorFlow\n )\n \n56\n \nای مزا و معا\nی ب57\n \n ( کراسKeras\n )\n \n57\n \nای مزا و معا\nی ب \n58\n \n خالصه فصل \n58\n \n آزمونک \n59\n \n:فصل سوم \n شبکه\nی ها \n عصب\nی پی ش\nخور\n مقدمه \n62\n \n شبکه\nی ها عصب\nی  مصنوع ی (\nArtificial neural networks\n )\n \n62\n \n ( پرسپترونperceptron\n )\n \n63\n \nالگور\nتم ی ادگ ی یری \n پرسپترون \n67\n \nاده یپ\nی ساز پرسپترون در پا\nی تون \n69\n \nپرسپترون چند ال\nی ه \n (شبکه عصب\nی پی ش\nخور)\n \n74\n \nتابع فعال\nساز ی \n77\n \n چرا توابع فعال\nی ساز  یغ\nرخط\nی ضرور ی هستند؟ \n77\n \nژگ یو ی ها ی \n مطلوب\nی ک تابع فعال\nساز ی78\n \nمشکالت\nی \n که توابع فعال\nی ساز \n با آن مواجه هستند \n79\n \nتوابع فعال\nی ساز \n پرکاربرد \n80\n \nSigmoid\n \n80\n \ntanh\n83\n \nReLU\n \n84\n \nSoftmax\n \n86\n \nی به نه\nسازها و توابع ز\nی ( انLoss Function\n )\n \n87\n \nگراد\nی ان \n کاهش\nی (نزول گراد\nان ی )\n \n89\n \nاده یپ\nی ساز گراد\nی ان \n کاهش\nی \n در پا\nتون ی \n90\n \nگراد\nی ان \n کاهش\nی مبتن بر ی \n ( تکانهMomentum\n )\n \n94\n \nگراد\nی ان \n کاهش\nی تسر\nی ع\nشده \n ( نستروفNAG\n )\n \n96\n \nالگور\nی تم\nی ها گراد\nی ان \n کاهش\nی \n  درkeras\n \n96\n \nالگور\nی تم\nی ها بهن\nی ه\nی ساز  \n نرخ\nادگ ی\nیری تطب\nیق ی \n97\n \nAdagrad\n \n97\n \nAdaDelta\n \n98\n \nRMSprop\n99\n \nAdam\n \n100\n \nتابع ز\nی ان \n100\n \nتوابع ز\nان ی  \n ی برا رگرس\nی ون \n101\n \nتوابع ز\nان ی  \n ی برا \n طبقه\nبند ی \n102\n \nپس انتشار \n103\n \n وزن\nی ده یهی اول \n پارامترها \n104\n \n \n پارامترها \n106\n \nتعم\nیم \n و منظم\nساز ی \n106\n \n( توقف زودهنگامEarly stopping\n)\n \n108\n \nحذف تصادف\nی  (\nDropout\n )\n \n109\n \n نرمال\nی ساز \n دسته\nای (\nBatch Normalization\n )\n \n110\n \nاده یپ\nی ساز شبکه عصب\nی \n  درkeras\n \n111\n \n خالصه فصل \n124\n \n آزمونک \n124\n \nتمر\nی ن124\n \n :فصل چهارم\nشبکه\nی ها  عصب\nی کانولوشن\nی\n مقدمه \n126\n \n شبکه عصب\nی کانولوشن\nی  (\nCNN\n )\n \n126\n \n عملگر کانولوشن \n128\n \nلایه \n کانولوشن \n130\n \nلایه \n کانولوشن درkeras\n \n133\n \nلایه \n ادغام \n134\n \nطبقه\nبند\nی تصو\nیر  \n با شبکه کانولوشن\nی \n  درkeras\n \n135\n \n خالصه فصل \n148\n \n آزمونک \n148\n \n :فصل پنجم\nشبکه\nی ها عصب\nی بازگشت ی \n مقدمه \n150\n \n شبکه عصب\nی  بازگشت\nی یچ ست؟ \n150\n \nساختار شبکه عصب\nی  بازگشت ی \n152\n \nانواع معمار ی ها ی  \nRNN\n \n153\n \nدی تول \n  متن باRNN\n154\n \nLSTM\n162\n \nدی تول \n  متن باLSTM\n \n164\n \nطبقه\nبند\nی چندبرچسب\nی \n متن \n  باLSTM\n167\n \nتحل\nیل \n  احساسات باLSTM\n \n173\n \n خالصه فصل178\n \n آزمونک \n178\n \n :فصل ششم شبکه متخاصم مولد \n مقدمه \n180\n \nمدل مولد چ\nی\nست؟ \n180\n \nمدل\nی ها مولد و آ\nی\nنده هوش مصنوع\nی ؟ \n181\n \n ( شبکه متخاصم مولدGenerative     Adversarial    Network\n )\n \n182\n \nآموزش به ش\nوه ی تخاصم ی \n184\n \n  آموزشGAN\n \n186\n \nآموزش تما\nی زگر \n187\n \nآموزش مولد \n189\n \n هر دو در کنار هم \n189\n \nی تول\nد تصاو\nی\nر جد\nی  دMNIST\n  \n  باGAN\n \n190\n \nچالش\nی ها مرتبط با آموزش شبکه\nی ها \n متخاصم مولد197\n \n خالصه فصل197\n \n آزمونک \n198\n \n مراجع \n199\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n1 \n \n▪\n یادگیری عمیق چیست ؟ \n▪\n \n علت محبوبیت یادگیری عمیق \n▪\n \n تفاوت آن با یادگیری ماشین \n▪\n \n آینده ی یادگیری عمیق \n▪\n \n کاربردهای یادگیری عمیق \n \n \n اهداف  یادگیری:\n \nمقدمه\nای بر یادگیری عمیق \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 12 \n \n \n مقدمه \nیری ادگ ی  \n قی عم  یز\nرمجموعه\nای  \n  از یری ادگ ی  ماش\nنی  است که بر استفاده از شبکه\nی ها  \n عصب\nی  ی برا  \nحل مسائل پ ده یچی  تمرکز دارد. امروزه به لطف پ ی شرفت\nی ها  \n نرم\nافزار\nی  \n و سخت\nافزار\nی  \n  که به ما\n امکان جمع\nآور\nی  \n و پردازش مقاد\nری  ی اد یز  داده را م ی،دهد  محبوب تی  یب\nی شتر  دا یپ  کرده است  .\nچراکه  شبکه\nی ها  \n عصب\nی  \n قی عم  \n ی برا  عملکرد خوب\nی که ما از آن انتظار داریم  به مقاد\nری  ی اد یز  \n  داده\nو در نتیجه\nیِ آن به سخت  افزار قدرتمند برای پردازش این حجم بزرگ داده\nاز ین  \n .دارد \nیادگیری عمیق چیست؟ \nهوش مصنوع\nی  اساسا  \n هی شب ساز ی  \n انسان\nها و رفتارها\nی  \n ی ذهن  \n آن  ها توسط\nکی  برنامه را\nی یا انه  \nاست  که  م ی\nتواند کارها\nیی  را انجام دهند که معموالً به هوش انسان\nی   از ین  دارند. به عبارت ساده  ،تر\nیس ی ستم  که  م ی\nتواند  رفتار  انسان  را  تقل\nدی  کند.  ا\nین  \n  رفتارها  شامل  حل\nمسئله  ،ی ادگ ی یر  \n  و\n برنامه\nیزیر  است که از طر\nقی  تجز\nهی  و تحل\nلی  داده\nها و شناسا\nیی  الگ\nی وها  \n  درون آن به منظور\nتکرار آن رفتارها بدست م دیآی.   \nکد، فناور\nی  ،الگور\nتم ی  یا هر سیستمی  که بتواند مقوله فهم شناخت\nی  را تقل\nید  \n کند که در خود\nیا  \n در دستاوردها\nی  آن پد\nدار ی  م ی،شود  هوش مصنوع\nی  است. ا\nی ن  \n  شامل یری ادگ ی  ماش\nنی  نیز  \nم ی،شود  یی جا  که ماش\nها نی  یم\nتوانند  با تجربه ب\nی\nاموزند  \n و بدون دخالت انسان مهارت\nیی ها  \n  کسب\nکنند. از ا\nین\nرو، هوش مصنوع ی  \n سازنده\nی  یری ادگ ی  ماش\nین  \n  ،است. در واقع\nیری ادگ ی  ماش\nین  \nزی\nرمجموعه  اصل\nی  هوش مصنوع\nی  است و م\nی\nتواند  ماش\nها نی  \n  را قادر سازد تا با استفاده از\n روش\nی ها  آمار\nی،  تجرب ات ی  خود را با ک\nیفی تر ت  \n  تر قی دق و  کنند. ا\nنی  امر به را\nانه ی\nها  و ماش\nی ن ها \nامکان  م ی\nدهد  تا دستورات  را  بر  اساس داده  ها و\nیری ادگ ی  خود  اجرا کنند. ا\nنی  برنامه  ای ها \nالگور\nی تم\nها  به گونه\nیا  طراح\nی  شده  اند که بتوانند\nدر  طول زمان اطالعات ب\nی\nی شتر  \n  کسب کنند و با\nداده\nی ها  دی جد  \n بهتر شوند و تطب قی  دا یپ  \n.کنند  \nده یا  اصل\nی  \n  اختراع\nیری ادگ ی  ماش\nی ن  \n استدالل مبتن\nبر ی  نمونه است که فرآ\nند ی  \n  استدالل در مسئله  \nمورد نظر با مراجعه به نمونه\nی ها  مشابه قبل\nی  ممکن م ی\nشود . مثال\nی ها  ی قبل  که برا\nی  ای\nجاد  ی ظرف ت  \nاستفاده م\nی  شود، نمونه\nی ها  آموزش\nی  ده ی نام  شده  و فرآ\nند ی  انجام ا\nی ن  \n  کار\nیری ادگ ی  ده ی نام  م ی\nشود.  \nدر س\nی ستم\nی ها  ی را یا انه،  تجربه در قالب داده\nها وجود دارد و وظ\nفه ی  اصل\nی   یری ادگ ی  ماش\nین  \n  توسعه\nالگور\nی تم\nی ها  یری ادگ ی  است که از داده\nها مدل م ی\nسازد . با تغذ\nهی  داده\nی ها  تجرب\nی  \n به الگور\nی تم  \nیری ادگ ی  ماش\nی،ن  ما مدل\nی  ار  بدست م\nآور ی\nمی  که م\nی\nتواند  یبشیپ یی ها ین  را در مشاهدات جد\nید  \n.انجام دهد \n13 \n فصل\nاول: مقدمه ای بر یادگیری عمیق \n \nیری ادگ ی  \n قی عم  \n  نیز\nیز رمجموعه\nای  \n  از  هوش  مصنوعی  و\nری ادگ ی ی  ماش\nین  \n  است که  در  آن\nشبکه\nی ها  \n عصب\nی  مصنوع\nی،  الگور\nتم ی\nیی ها  \n  که از مغز انسان الهام گرفته\nشده\nاند\n، از مقاد\nری  ز اد ی ی  \n  داده  توانایی یادگیری  بدست  می\nآورند\n.  الگور\nتم ی  یری ادگ ی  \n قی عم  \n  مشابه  نحوه\nیری ادگ ی  \n  ما  از\n تجربه  ها و\nنمونه\nها  ،کی  کار را به طور مکرر انجام م ی دهد و هر بار کم\nی  آن را تغ\nر یی  یم  دهد تا\nجه ی نت  \n  .را بهبود بخشد\nبا انجام ا\nنی  کار، به را\nانه ی\nها  کمک م\nکند ی  تا و\nها ی ژگ ی  از داده\nی ها پ دا  \n کنند\nو با تغ\nیی\nرات  سازگار شوند. قرار گرفتن مکرر در معرض مجموعه داده\nها به ماش\nنی ها کمک\nم کند ی  \n تا تفاوت\nها و منطق  داده  ها را درک کنند و به\nکی  یریگ جه ی نت  \n  .قابل اعتماد برسند  در\nساده\nنی تر  \n  ،حالت\nیری ادگ ی  \n قی عم  را م\nی\nتوان راه\nی  ی برا  خودکارساز ی  تجز هی  و تحل\nیل  \n پیش\nگویانه  \n(\npredictive analytics\n)  \n.در نظر گرفت \n تعریف1.1\n یادگیری  \n عمیق \n،یادگیری عمیق  مجموعه یا  از الگور\nتم ی\nیی ها  است که \"از طر\nقی   ها هیل  ادی  رند یگیم\n\".  به عبارت د\nی ،گر \n  شامل\nیری ادگ ی  از طر قی   یی ها هیل  است که الگور\nتم ی  را قادر م\nی\nسازد  \n تا سلسله\nمراتب\nی  از مفاه\nمی  ده یچیپ   را\nاز مفاه\nمی ساده جاد ی تر ا \n .کند \nی برا  \n  درک  بهتر\nیری ادگ ی  \n ی عم،ق  کودک نوپا\nیی  \n را تصور کن\nدی  چیزی  \n  که  در حال  یاد  گرفتن آن\nاست  گربه  \n می\nباشد\n. کودک نوپا با اشاره به اش اء ی  \n  و گفتن کلمه\nگربه  اد ی  م رد یگی  \n  که  چه چیزی گربه  \nاست  \n  و  چه چیزی گربه\nست ین\n. والد\nنی  م ند ی گو ی  :\n\"\n  بله، آن\nگربه  است\"  ای  \"\n  نه، آن\nگربه  ست ین\"\n .\nهمان\nطور که کودک نوپا همچنان به اش\nاء ی  اشاره م\nی\nکند، ا\nز  یی ها ی ژگ یو  \n  که همه\nگربه\nها  \n دارند\nبی\nشتر  \n  و بیشتر آگاه م ی\n؛ شود  کار ی  که کودک نوپا بدون ا\nی که ن  بداند انجام م ی\nدهد.  \n  نیا به  \n  طریق\n  است که کی  انتزاع پ\nچی ده ی  \n)(مفهوم گربه  \n  را با ساختن سلسله مراتب ی  \n  که در آن هر سطح از انتزاع\nبا دانش\nی  که از ال\nهی  ی قبل  سلسله مراتب بدست آمده،  یا\nجاد  \n می  کند تا\nبرای\nش این  \n  ،انتزاع پیچیده\n  ساده و\nر\nوشن  \n.شود \nپیدایش یادگیری عمیق ؟ \n  از آغاز عصر رایانه\nها،  محققان در مورد هوش ماش\nی ین،  نظر\nی ه\nپرداز\nی  \n می\nکردند  \n  و رویای  داشتن\nی را انه\nی ها  هوشمند\nی  را در سر م\nی  پروراندند که بتوانند راه حل\nی ها  مسائل پ\nده یچی  ی را ب\nاموزند  \n  و\nدرک کنند\n. در دهه\nی ها  \n1950\n  \n  و60، اول\nی ن  شبکه\nهای  \n عصب\nی،  از جمله الگور\nتم ی  پرسپترون برا\nی  \nطبقه\nی بند  تصاو\nی،ر  دار ی پد  شدند. با ا\nنی  حال، ا نی  موارد اول\nهی  ار ی بس  \n  ساده بودند و  نتوانستند\n محبوبیت گسترده\nای داشته باشند. \nشبکه\nی ها  \n عصب\nی  \n  در دهه1980\n  زمان\nی  \n که محققان روش\nیی ها  را برا\nی  پس\nانتشار  \n  پارامترها به\n منظور ساخت و آموزش شبکه\nی ها  \n عصب\nی  \n  چند\nسطحی  توسعه دادند، دوباره ظهور کرد\nن .ند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 14 \n \n \nبا  یپ شرفت\nها در  \n  دهه2000\n ، تکن یی ها کی  پدیدار گشتند  تا امکان افزا\nشی  ی ها هیال  شبکه\nها ی  \n عصب\nی  را فراهم کنند. ا\nنی  شبکه ی ها  چندال\nهی  باعث شد که ا\nنی  حوزه از تحق قات ی  هوش مصنوع\nی  \n\" ادگ ی\nیری قی عم\"  \n نامگذار\nی  شود،  چراکه  الگور\nی تم\nها  داده\nها را در چند\nین  لایه  \n پردازش م ی\nکنند  \n  تا\nبه پاسخ برسند. \nدر  \n  سال2012، شبکه ها\nی  عصب\nی  \n قی عم  شروع به عملکرد\nی  بهتر از الگور\nی تم\nی ها  طبقه\nبند ی  \nی سنت،  از جمله الگور\nتم ی\nی ها  یری ادگ ی  ماش\nنی  کردند. ا\nنی  افزایش کارایی  تا حد ز\nی اد ی  لی بدل  \nافزا\nیش  \n عملکرد پردازنده\nی ها  را انه ی  (\nGPU\n  ) و\nحجم انبوه داده\nای  \n  است که اکنون در دسترس\nاست. د\nیجی ی تال  شدن سر\nی ع  منجر به تول\nدی  داده\nی ها  در مق اس ی  بزرگ شده است و ا\nین  \n داده  ها\nاکس\nی ژن ی  ی برا  \n  آموزش\nمدل\nهای  یری ادگ ی  \n قی عم  \n  .هستند  ،از آن زمان، هر سال\nیری ادگ ی  \n قی عم \n  همچنان  در حال\nبهتر شد\nن  و تبد لی  به بهتر\nنی  رویکرد  ی برا  حل مشکالت در بس\nی ار ی  \n از حوزه\nی ها  \n  .مختلف شده است \nاین  \nِانفجار\n محبوبیت و استفاده از  ادگ ی\nیری  قی عم  تا حد ز\nی اد ی  به لطف پ\nی شرفت  \nدر سخت\nافزار و مجموعه داده\nی ها  \n برچسب\nگذار\nی  شده عظ\nیم  \n است که به\nمدل\nی ها ادگ ی\nیری قی عم  \n اجازه م\nی\nدهد \n تا به سرعت در طول زمان بهبود\nی\nابند. \n علت محبوبیت یادگیری عمیق ؟ \n صنعت نرم\nافزار امروزه به سمت هوش ماش\nی نی  \n حرکت م کند ی  \n  و این\nیری ادگ ی  ماش\nنی  است  که  \nی راه  ی برا  \n هوشمندساز\nی  ماش\nی ن  ها\nبوجود آورده است  . به\nبیان  \n ساده  ،یری ادگ ی  ماش\nنی  مجموعه\nای  \nاز الگور\nتم ی\nیی ها  است که داده\nها را تجز\nهی  یم،کنند  از آن  اد ی ها  رند یگیم  و سپس آنچه ر ا  \n  ی که اد \n گرفته\nاند برا\nی  \n تصم\nیریگمی  هوشمندانه به کار م رند یگی.  نکته\nیا  که در مورد الگور\nی تم\nی ها  ری ادگ ی ی  \nماش\nنی  ی سنت  وجود دارد،  نیا  \n  است که\nآن  ها\nهر چقدر که پ\nده یچی  به نظر برسند، هم چنان شب\nیه \nماش\nین  \n  .هستند  ،به عبارت دیگر\nآن\nها  برای بدست آوردن یادگیری  \n  به\nکارشناسان  حوزه ن\nاز ی  دارند  .\nی برا  کارشناسان  هوش مصنوع  ،یا ی\nنجا  \n نقطه  ای است  که ی ادگ ی یر  \n قی عم  ی نو\nدبخش  \n می\nشود.  \nچراکه شبکه\nهای عصبی عمیق بدون نیاز به مداخله  ،ی انسانی\nیو ی ها ی ژگ  سطح باال را از داده ها\nبه صورت افزا\nی شی  \n (سلسله)مراتبی  اد ی  \n می\nگیرند\nنی . ا  امر ن\nاز ی  \n  به\nکارشناس\nان  \n  دامنه و استخراج\nها ی ژگ یو  به صورت دستی  را از ب نی  یم.برد  \n  انتخاب ویژگی برای یک مجموعه داده تاثیر بسیار\nزیادی در موفقیت یک مدل یادگیری ماشین دارد، حال آن که این استخراج ویژگی\nها به  صورت\nدستی فرآیندی زمان .بر و پیچیده خواهد بود \n امروزه عالوه بر شرکت ها و سازمان\nها، حت\nی  افرادِ به سمتِ جنبه\nی ها  فناور\nی،  \n  ی ادگ ی به ر ی  \n ی عم،ق  لی تما  دارند  و هم\nچنان تعداد ا\nین  \n شرکت  ها  و افراد  در استفاده از\nیری ادگ ی  \n قی عم  \n  روز به\nروز در حال افزا\nشی  هستند\n. برا\nی  درک ا\nنی  ی دل ،ل  دی با  به مزا\nیی ای  که م ی\nتوان  با استفاده از رو\nی کرد \n15 \n فصل\nاول: مقدمه ای بر یادگیری عمیق \n \nیری ادگ ی  \n قی عم  \n  .بدست آورد، نگاه کرد\nبه\nطور خالصه می\nتوان  ی مز های ت  یدی کل  \n  که هنگام استفاده\nاز ا\nنی  فناور\nی  \n  وجود دارد را\nبه  صورت زیر\nفهرس\nت  کرد: \n▪ عدم ن\nاز ی  به مهندس\nی  و ژگ ی ها ی:  \n  ی ادگ ی در یر  ماش\nی،ن  \n مهندس\nی  یو ی ژگ  کی  کار اساس ی  \nو مهم است. چراکه دقت را بهبود م\nی\nبخشد  و گاه\nی  اوقات ا\nنی  ند ی فرآ  یم\nتواند  \n  به\n  دانش دامنه در مورد\nکی  مساله خاص ن\nاز ی  \n  .داشته باشد\nیکی  از بزرگتر\nنی  ی مزا ا ی  \nاستفاده از رو\nی\nکرد  یری ادگ ی  \n ی عم،ق  توانا\nیی  آن در اجرا\nی  مهندس\nی   ی ژگ یو  \n به صورت\nخودکار است. در ا\nنی  ی رو،کرد   کی  الگور\nتم ی  داده ها را اسکن م کند ی  تا و\nژگ ی ها ی ی  \n مرتبط را شناسا\nیی  \n کند و سپس آن\nها را برا\nی  \n ارتقا\nی  ی سر تر ع  ی ادگ ی یر،  بدون ا\nنکه ی  \n به\nطور صر حی  به او گفته شود، ترک\nبی  م کند ی\nنی . ا  توانا\nیی  به دانشمندان دا\nده  کمک م\nی کند  \nتا مقدار قابل توجه\nی  \n در زمان صرفه\nیی جو  کرده و به دنبال آن نتا\nجی  بهتر\nی  را ن\nیز \n  .بدست آورند \n▪ حداکثر استفاده از داده\nی ها بدون ساختار :تحق\nقات ی  نشان م ی\nدهد  \n که درصد ز\nاد ی ی  \nاز داده\nی ها  کی  سازمان بدون ساختار هستند، ز\nرا ی  \n اکثر آن ها در قالب\nی ها  \n مختلف ی  \nهمانند تصو\nی،ر  \n متن و غ\nره ی  هستند. برا\nی  اکثر الگور\nتم ی\nی ها  یری ادگ ی  ماش\nی،ن  تجز\nیه  \n  و\nتحل\nلی  داده\nی ها  بدون ساختار دشوار است. از ا\nی ن،رو  یا\nنجاست  \n  یری ادگ ی که  \n ی عم ق  \nدی مف  م ی\nشود\n. چرا که م\nی\nتوان\nید  \n از قالب\nی ها  داده\nیا  مختلف برا\nی  آموزش الگور\nی تم\nی ها  \nیری ادگ ی  \n قی عم  \n استفاده کن\nدی  و همچنان ب\nنش ی\nی ها  \n  مرتبط با هدف آموزش را بدست\nآور\nید\n. برا\nی  مثال، م\nی\nتوان\nدی  از الگور\nتم ی\nی ها  یری ادگ ی  \n قی عم  برا ی  \n کشف روابط موجود\nنیب  تجز\nهی  و تحل\nلی  صنعت، گفتگو\nی  رسانه\nی ها  اجتماع\nی  و موارد د\nگر ی  ی برا  یبشیپ ن ی \nمت یق\nی ها  سهام آ\nنده ی  کی  \n سازمان استفاده کن\nید.\n \n▪ ارائه  نتا جی  با ک\nیفیت  \n:باال  \n انسان  ها گرسنه\nای  خسته م\nی\nشوند  و گاه\nی  \n اوقات اشتباه\nم ی\nکنند\n.  در  مقابل،  وقت\nی  صحبت  از  شبکه\nی ها  \n عصب\nی  یم،شود  نیا\nطور  ست ین .\nهنگام\nی  \n  کی که  \n  مدل یری ادگ ی  \n قی عم  بدرست\nی  \n آموزش داده شود، م\nی\nتواند  \n  هزاران کار\nمعمول\nی  و تکرار ی  \n  را در مدت زمان نسبتا کوتاه\nی تر  در مقا\nسه ی  \n با آن\nچه که برا ی  کی \nانسان الزم است، انجام دهد. عالوه بر ا\nی،ن  کیف یت  \n کار هرگز کاهش نم\nیی،ابد  \n  مگر\nنکه یا  داده\nی ها  آموزش\nی  ی حاو  داده\nی ها  ی خام  \n باشد که نشان دهنده مساله\nیا  ست ین  \n  که\nم ی\nخواه\nید  \n آن راحل کن\nید . \n▪ \n:یادگیری انتقالی  \n  یادگیری عمیق\nی دارا  نی چند  مدل از پ\nیش\nآموز\nده ی ش د  با وزن ها و\n سوگیری\nهای  ثابت است  \n  که\nبرخ\nی  از ا\nنی  الگور\nتم ی\nها  در پ\nیبشی ین  ار ی بس  ی عال  \n .هستند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 16 \n \n \n▪ \n دقت باال:ی نتایج  هنگام\nی  \n  یری ادگ ی که  \n قی عم  با حجم عظ ی یم  \n از داده آموزش داده\nم ی\nشود، م\nی\nتواند دقت خوب\nی  در مقا سه ی  با الگور\nی تم\nی ها  ی ادگ ی یر  ماش\nنی  ی سنت  \n  داشته\n .باشد \nبا  در نظر گرفتن مزا\nیای  فوق و استفاده ب\nی\nشتر  از رو\nی\nکرد  یری ادگ ی  \n ی عم ،ق  یم\nتوان  \nگفت که تاث ری  \n  قابل توجه\nیری ادگ ی  \n قی عم  در فناور\nها یِی  مختلفِ پ\nی\nشرفته  همانند ا\nی نترنت \nای اش در آ\nنده ی یهی بد \n .است\nی ادگ ی یر \n ی عم،ق راهِ دراز\nی را ط\nی \n کرده است و به سرعت در\nحال تبد\nیل  \n  شدن به\nیک  \n فن ی اور  ی ات یح  \n است که به\nطور پ\nی\nوسته  توسط مجموعه\nای  \n  از\n کسب\nوکارها، در صنا\nی ع  \n مختلف مورد استفاده قرار م رد یگی. \n  با این حال باید توجه داشت که\nادگ ی\nیری  قی عم  \n همچن\nی ن  \n ممکن است بهتر\nی ن  \n انتخاب بر اساس داده ،ها نباشد. به عنوان مثال، اگر مجموعه داده کوچک باشد\nگاه\nی  \n اوقات مدل\nی ها  ادگ ی\nیری  ماش\nیِن  خطِی  ساده\nتر ممکن است نتا جی  ی دق تر ق ی \nبه همراه داشته باشند. هرچند، برخ\nی  \n  از متخصصان\nادگ ی یری  ماش\nنی  استد\nالل \n می\nکنند  \n  که\nکی  شبکهِی  عصبِی  ی عمِق  \n آموزش\nده یدِی  \n مناسب، همچنان م\nی تواند  \nبا مقاد\nیِر کمِ داده، عملکرد خوب\nی \n.داشته باشد \n یادگیری عمیق چگونه کار می\nکند؟ \n مدل\nی ها  یری ادگ ی  \n قی عم  با تجز\nهی  و تحل\nیل  \n مداوم داده\nها و با کشف ساختارها\nی  ده یچیپ  \n در داده  ها\n  توانایی یری ادگ ی  \n بدست می\nآورند\n. فرآ\nند ی  ادگ ی یری  \n با ساخت مدل\nی ها  \n محاسبات\nی  به نام شبکه\nی ها  \n عصب\nی  که از ساختار مغز الهام گرفته شده، حاصل م\nی\nشود  .هسته اصل\nی  \n  این\nیری ادگ ی  به روش\nی  \nتکرار\nی در راستای آموزش ماش\nی ها ن ی برا دی تقل از هوش انسان\nی  ی متک \n .است\nیک \n شبکه عصب ی  \nمصنوع\nی  نیا  روش تکرار\nی  را از طر\nقی  نی چند  \n سطح سلسله مراتب\nی  انجام م ی\nدهد  \n  و در این\nساختار با رفتن به الیه\nهای سطح بعدی، قادر به حل مفاهیم پیچیده\nتری از مسئله می.شود  \n  سطوح\nهی اول  به ماش\nها نی  کمک م ی\nکنند  تا اطالعات ساده را ب\nی\nاموزند\n. با رفتن به هر سط\nح  \n ی جد ،د  \nماش\nی ها ن  اطالعات ب\nی\nی شتر  \n را جمع\nآور\nی  کرده و آن\nها را با آنچه در آخر\nین  \n سطح آموخته بوده اند\nبی ترک   م ی\nکنند\n. در پا\nان ی  ی فرآ،ند یس\nستم  کی  \n قطعه اطالعات نها یی  \n را جمع\nآور\nی  کند یم  \n  کی که  \nورود\nی  ی ترک یب  است. ا\nنی  اطالعات از چند\nنی  سلسله مراتب عبور م کند ی  \n و شب هی  به تِفکر  منطقِی  \nده یچیپ  \n  .است \nد یی ایب  \n  با کمک\nکی  مثال آن را ب ی\nشتر  تجز\nیه  \n می کن\n. دست\nار ی  ی صوت  \n  مانند الکسا ای  یریس  \n  را در\nنظر بگ\nیرید  \n تا بب\nی نید  \n  چگونه از\nیری ادگ ی  \n قی عم  ی برا  تجرب\nات ی  \n مکالمه طب\nیعی  استفاده م کند ی . در\nسطوح اول\nیه  \n شبکه عصب\nی،  زمان\nی  که دست\nار ی  ی صوت  با داده\nها تغذ\nهی  یم،شود  ی سع  م کند ی  \n  صداها\nو موارد د\nگر ی  را شناسا\nیی  کند. در سطوح باالتر، اطالعات مربوط به واژگان را م رد یگی    ی و\nافته\nها ی  \n17 \n فصل\nاول: مقدمه ای بر یادگیری عمیق \n \nسطوح قبل\nی  را به آن اضافه م کند ی\n. در سطوح بعد\nی،  \n اعالنات (فرمان\nها) را تجز\nهی  و تحل\nی ل  \nم کند ی  و تمام نتا\nجی  خود را ترک بی  م کند ی\n. برا\nی  باالتر\nین  \n سِطح  \n ساختارِ سلسله مراتب\nی،  دست\nار ی  \nی صوت  \n به اندازه کاف\nی  \n  آموخته است که بتواند\nکی  د الوگ ی  را تجز\nی ه  و تحل\nیل  \n  کند و بر اساس آن\nورود\nی،  \n.اقدام مربوط را ارائه دهد \n  ادگ ی در\nیری  ی عم،ق  ی از ین  به برنامه\nی نو سِی  ی صرِح  \n همه\nچیز  \n ندار\nمی . آن ها م\nی توانند  \nبه\nطور خودکار بازنما یی\nیی ها  را از داده\nیی ها  مانند تصاو\nی ،ر  ویدیو  یا  \n  متن، بدون\nمعرف\nی  قوان\nی ن  دست\nی اد ی  \n بگ رند ی\n. معمار\nها یِی  بس\nی ار  انعطاف\nری پذ  \n آن ها م\nی توانند  \nمستق\nما ی از داده\nی ها \n خام\nاد ی رند ی بگ و در صورت ارائه داده\nی ها یب\nشتر  م ی توانند \nعملکرد خود را افزا شی \n .دهند \nمعایب و چالش های یادگیری عمیق \n اگرچه اهم\nتی  ی و پ\nشرفت\nی ها  ی یری ادگ  \n قی عم  در حال افزا\nشی  است، اما چند جنبه منف\nی  یا  \n  چالش\nوجود دارد که برا\nی  \n  توسعه\nیک  \n  مدل\nیری ادگ ی  \n قی عم  دی با  \n با آن  .ها مقابله کرد\nبزرگتر\nنی  محدود\nی ت  \n مدل\nی ها  یری ادگ ی  \n قی عم  نیا  است که آن\nها از طر\nیق  \n  مشاهدات\nاد ی  م رند یگی\nنی . ا  \n بدان معن\nی  \n  است\nکه آنها فقط م ی\nدانند که در داده\nیی ها  که در آن آموزش داده\nاند چه چ\nیزی  وجود دارد  \n  و تنها در\nنگاشت بین ورودی و خروجی بسیار خوب هستند\n. به عبارت دیگر، آ\nن  از ها  زمینهِی  داده  هایی\nکه از آن  ها\nاستفاده می  کنند\nچیزی نمی\nدانند . در حقیقت، کلمه \"عمیق\" در یادگیری عمیق بیشتر\nاشاره به مرجع معماری فناوری و تعداد الیه های پنهان است که در ساختار آن قرار دارد نه درک\n.عمیقی از آنچه که در حال انجام آن است   \n مدل\nی ها  ری ادگ ی ی  \n قی عم  یکی  \n  از\nدادهِ  خوارترین  \n مدل\nی ها  داده در دن\nیای  یری ادگ ی  ماش\nین  \n  .هستند\nآن\nها به حجم عظ\nی می  \n از داده ها ن\nاز ی  \n  دارند تا به عملکرد مطلوب خود برسند و\nبه قدرتی  \n  که از\nآن\nها انتظار دار\nمی  به ما خدمت کنند. با ا\nنی  حال، داشتن ا\nین  \n مقدار داده هم\nشه ی  آس\nان  ست ین  .\nعالوه بر ا\nی،ن در حال\nی\nکه م\nی\nتوان\nمی  مقاد\nری  ی اد یز  \n  داده در مورد\nکی  موضوع داشته باش\nی،م  \n اغلب\n اوقات برچسب\nگذار\nی  \n نم ی،شود  بنابرا\nین  \n نم ی\nتوان\nمی  از آن برا\nی  \n آموزش هر نوع الگور\nتم ی  ی ادگ ی یر  \nبا نظارت استفاده کن\nمی.  به  ،طور خالصه اگر کاربر مقدار کم\nی  \n  داده داشته باشد  این مدل ها به\nروش\nی  \n قابل تعم\nمی  اد ی  \n رند یگی نم.  یری ادگ ی  \n قی عم  زمان\nی  م ی\nتواند  بهتر\nین  \n  عملکرد را داشته باشد\nکه حجم ز\nی اد ی  از داده\nی ها  با ک\nتیفی  در دسترس باشد. با افزا شی  داده\nی ها  \n موجود، عملکرد\nسی\nستم  ی ادگ ی یر  \n قی عم  زین  \n رشد م\nکند ی. \nزمان\nی  که  داده\nی ها  با ک\nتیفی  به س\nی\nستم  وارد نم ی\nشون،د   کی  یس\nستم  ادگ ی\nیری \nقی عم  م ی\nتواند اب \n شدت شکست.مواجه شود \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 18 \n \n \n  موضوع\nسوگ\nری ها ی  (\nbiases\n)  ین ز  کی  مشکل عمده برا\nی  مدل\nی ها  یری ادگ ی  \n قی عم  \n است. اگر\nکی  مدل بر رو\nی  داده\nیی ها  \n آموزش بب\nند ی  که دارا ی  یری سوگ  هستند، مدل آن سوگ\nری ها ی  \n را در\nیپ یبش ی ها ین  خود بازتول\nدی  م کند ی .\n \nاگرچه مدل\nی ها  ی ادگ ی یر  \n قی عم  \n ار ی بس  کارآمد هستند و م\nی\nتوانند  کی  راه\nحل مناسب برا\nی  یک  \nمشکل خاص پس از آموزش با داده\nها فرموله کنند، اما برا\nی کی مساله مشابه قادر به انجام ا\nین  \nکار ن\nی\nستند  از ی و ن  به آموزش مجدد دارند. برا\nی  نشان دادن ا\nین  \n  ،موضوع\nکی  الگور\nتم ی  ری ادگ ی ی  \n قی عم  را در نظر بگ\nیرید  \n  اد ی که  م رد یگی  اتوبوس\nی ها  \n مدرسه هم\nشه ی  \n  زرد هستند، اما ناگهان\n اتوبوس\nی ها  مدرسه آب\nی  م ی\nشوند\n. از ا\nنی،رو  دی با  \n  ،دوباره آموزش داده شود. برعکس\nی ک  \n کودک\nپنج ساله مشکل\nی  ی برا  تشخ\nصی  له ی وس  هی نقل  \n  به عنوان\nکی  اتوبوس مدرسه آب\nی  \n ندارد. عالوه بر\nیا،ن  اه آن  \n همچن\nنی  در موقع\nیی ها تی  که م مکن است کم\nی  متفاوت با مح\nیطی  \n  باشد که با آن\nتمر\nنی کرده\nاند، عملکرد موثر\nی ندارند. برا\nی \n  مثالDeepMind\n  گوگل س\nی ی ستم را برا\nی \n  شکست\n49\n  ی باز  آتار\nی  آموزش داد. با ا\nنی  حال، هر بار که س\nی\nستم  ی ک  ی باز  را شکست م ی،داد  دی با  برا ی \nشکست دادن باز\nی  بعد\nی  دوباره آموزش داده م\nشد ی\nنی . ا  ما را به محدود\nتی  ی گر ید  \n  ری ادگ ی در ی  \n قی عم  یم،رساند  ی ی عن  \n در حال\nی  \n که مدل ممکن است در نگاشت ورود\nها ی  به خروج\nها ی  \n فوق  العاده\nخوب باشد، اما ممکن است در درک زم\nنه ی  داده\nیی ها  که آنها مد\nیر یت  م ی\nکنند  \n.خوب نباشد \nالگو\nی  ادگ ی یری  \n  عمیق یا به\nطور کلی\nتر الگوریتمِهای یادگیری ماشین  ی فعل  \n  به صورت مجزا ی اد  \nم رد یگی\n: با توجه به مجموعه داده\nی ها  آموزش\nی،  الگور\nتم ی  یری ادگ ی  ماش\nنی  را رو\nی  \n مجموعه داده\nاجرا م\nکند ی \n کی تا مدل تول\nید \n کند \n چیه و تالش\nی ی برا حفظِ دانشِ آموخ\nته \n شده و استفاده از آن\n  ری ادگ ی درِی  نده یآ  \n انجام نم\nی\nدهد\n. اگرچه ا\nنی  الگوِی  ری ادگ یِی  مجزا بس\nار ی  موفق\nی زی آم ت  \n ،بوده است\nاما به تعداد ز\nی اد ی  نمونه آموزش\nی  از ین  دارد و فقط برا\nی  کارها\nیی  که به خوب\nی  فی تعر  \n شده و\nمحدود هستند مناسب است. با دردسترس قرار گرفتن مجموعه داده\nی ها  \n  بزرگتر و کاهش\nنه ی هز\nی ها محاسبات\nی، \n مدل\nیی ها که قادر به حل وظا\nفی بزرگتر هستند ن\nیز  \n  در دسترس شدند. با\nاین  \n  حال، آموزش\nکی  مدل هر بار که ن\nاز ی  \n  یری ادگ ی به  کی  کار جد دی  دارد\n، ممکن است غ\nری  ممکن\nباشد. چ\nراکه ممکن است داده\nها ی  ی قد م تر ی  در دسترس نباشند، داده\nی ها  دی جد  به دل\nیل  \n  مشکالت\nحفظ حر\nمی  خصوص\nی  نتوانند ذخ\nره ی  \n  شوند\nای  دفعات\nی  که س ی\nستم  دی با  \n در آن بروزرسان\nی  \n  ،شود\n ی نم\nتواند  \n  از آموزش\nکی  مدل جد\nدی  با تمام داده ها به اندازه کاف\nی  مکرر پشت\nی بان ی  \n.کند  ی وقت  \nشبکه\nی ها  \n عصب\nی  عمیق  وظا\nفی  یدی جد  \n  اد ی را   م یگی،رند  در صورت عدم استفاده از مع\nی\nارها ی  \nخاص، دانش جد\nدی  بر دانش قد\nی تر یم  اولو\nتی  داده م ی\nشود  و معموال باعث فراموش\nی  \n  دانش دوم\nم ی\nشود\nنی .  ا  \n  موضوع  معموال  به  عنوان\nفراموش\nی  فاجعه\nزی آم  \n(\ncatastrophic forgetting\n  )\nشناخته م ی\nشود  \n  (شکل1\n-\n1\n  را ببینید.)\n  \n فراموش\nی  \n فاجعه\nزی آم  زمان\nی  اتفاق م ی\nافتد  \n  کی که  \n  شبکه\n عصب\nی  \n آموزش\nید،ده  زمان\nی  که برا\nی  انجام وظا\nفی  دی جد  \n تطب\nقی  داده م\nی\nشود  قادر به حفظ توانا یی  \nخود برا\nی  انجام وظا\nیفی  که قبال آموخته است،  ست ین . \n19 \n فصل\nاول: مقدمه ای بر یادگیری عمیق \n \n \n  شکل1\n-\n1\n.  \n تصو\nیری  از فراموش\nی  فاجعه\nزی آم.  \nِدانش  آموخته شدهِی  ی قبل  \n  هنگام\nی یری ادگ  کالس\nها ی  \nدی جد ی که برا\nی ی مدت ده ید نشده ، فراموش م\nی شود (به صورت تدر\nجی ی محو م\nی .)شود \n مشکل دیگر شبکه های عصبی عمیق این است که آن  ها\nاغلب با فرض\nات ی  \n  جهان بسته آموزش\nداده م\nی،شوند  ی ی عن  \n فرض م ی\nشود  که توز\nی ع  داده\nی ها  آزما یشی  مشابه توز\nی ع  داده\nی ها  آموزش ی  \nاست. با ا\nنی  حال، هنگام\nی  \n که در کارها\nی  یای دن  واقع\nی  بکار گرفته م ن شو ی\nنی د، ا  \n  فرض درست\nست ین  و منجر به کاهش قابل توجه\nی  از  عملکر\nد  آن\nها م ی\nشود. هنگام\nی  که شبکه\nی ها  \n عصب\nی  \n قی عم  داده\nیی ها  را پردازش م ی\nکنند  \n که شب\nهی  ی توز ع  مشاهده شده در زمان آموزش ن\nی\nستند  \n  که  به\n  اصطالح\nخارج ازتوز عی  ده ی نام   (\nOut-of-distribution\n  )می\nشوند\n، اغلب پ\nیبشی ی ها ین  اشتباه\nی  \nانجام م ی\nدهند  نی و ا  \n کار را با اطم نان ی  شیب  از حد انجام م\nی دهند  \n  (شکل1\n-\n2  را بب\nی نید\n). در ا\nی ن \nموارد خروج\nی  \n  شبکه\nکی  تناظر مستق\nمی  با راه  ،حل مساله دارد\nی ی عن  احتمال برا\nی  \n  هر کالس. با\nنیا  حال، جمع نما\nیِش  بردارِ خروج\nی  \n مجبور است هم\nشه ی  \n  کی به  برسد. ا\nین  \n  بدان معناست که\nی وقت \n به شبکه\nکی  ورود\nی نشان داده م\nی\nشود که بخش\nی از توز\nی ع آموزش\nی ین،ست \n بازهم احتمال\n  را\nبه  نی تر کی نزد  \n کالس  یم\nدهد  تا جمع احتما  الت به\nکی  برسد. ا\nنی  ده ی پد  \n  منجر به مشکل\nشناخته شده\nی  شبکه\nی ها  \n عصب\nی   اد یز  مطمئن  (\noverconfident\n)  به محتوا\nیی  \n  شده است که هرگز\nی ند اند ده . \nاگرچه ا\nنی  افت عملکرد برا\nی  کاربردها\nی  ه\nمانند توص\nی ه\nگرهای  \n  محصول قابل قبول است، اما\n استفاده از چن\nین  سی\nستم\nیی ها  در حوزه\nی ها  ه\nمانند پزشک\nی  و ربات کی  خانگ\nی  خطرناک است،  \nچرا که  م ی\nتوانند  باعث بروز حوادث جد\nی  \n.شوند  کی  س ی\nستم  هوش مصنوع\nی  ا آل ده ی  دی با  \n  در\nصورت امکان به نمونه\nی ها خارج از توز\nی ع \n تعم\nمی دا یپ کند. بنابرا\nی،ن توانا\nیی  تشخ\nیِص \n  خارج از\nی توز ع ی برا بس ی ار ی \n از برنامه\nی ها کاربرد\nی ی دن یا واقع\nی ار ی بس  مهم است و ی برا \n تضم\nنی قابل ی ت  \n اطم\nنان ی  ی و ا ی من  یس\nستم\nی ها  ادگ ی یری  ماش\nنی  ضرور\nی  است. به عنوان مثال، در رانندگ\nی  \n  ،خودران\nما م ی\nخواه\nیم  سی\nستم  رانندگ\nی  \n زمان\nی  \n که صحنه\nی ها  یغ\nرعاد\nی  ای  اش ی یی ا  را که قبال ند\nده ی  \n  است و\n ی نم\nتواند  \n تصم\nمی  من یا  رد ی بگ  را تشخ\nیص  \n  دهد، هشدار\nبدهد  \n.و کنترل را به انسان واگذار کند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 20 \n \n \n \n  شکل1\n-\n2\n.  هنگام\nی  \n  کی که  نمونه\nی  ی جدِد  \n خارج از توز\nیِع  آموخته شده  ارائه شود، شبکه\nی ها  عصب\nی  \n عمیق  \nیک \n کالس را از توز\nی ع آموخته\nشده با اطم\nنان ی ی اد یز نیبشیپ ی یم .کنند \nدر نها\nی،ت  \n شناخته\nشده\nنی تر  نقطه ضعف شبکه\nی ها  \n عصب\nی  ی ماه ت  عدم شفافیت  \n  .آنهاست\nدر حالی\nکه، تصمیمات گرفته شده توسط مدل\nهای مبتنی بر قاعده  را می  توان توسط دستورات𝑖𝑓\n  \n  و𝑒𝑙𝑠𝑒\n \n  ردیابی کرد، در یادگیری عمیق چنین چیزی امکان پذیر نخواهد بود. این عدم شفافیت\n\" همان چیزی است که در یادگیری عمیق از آن به عنوان\nجعبه سیاه\n\" یاد می.شود   \n به عبارت ساده، شما نم\nدی دان ی \n چگونه و\nیا \n چرا شبکه عصب\nی شما خروج\nی خاص\nی \n  را بدست\nآورده است. به عنوان مثال، وقت\nی  تصو\nیری  \n  کی از  \n  گربه را به\nیک  \n شبکه عصب\nی  تغذ\nهی  م ی دی کن  \n و\n  آن را\nکی  ماش\nنی  یپ یبش ین  م ی،کند  درک ا\nنکه ی  چه چ\nیزی  باعث شده است که به ا\nین  پیشبی نی  \nبرسد بس\nار ی  سخت است. ا\nنی  سنار\nیو  \n در تصم\nی مات  تجار\nی  مهم خواهند بود. آ\nیا  می\nتوان\nید  \n تصور\n دی کن  که مد\nیر  \n  عامل\nیک  \n شرکت بزرگ تصم\nی یم  در مورد م\nون یلی\nها  دالر بگ\nرد ی  بدون ا\nی نکه  \n بفهمد\nچرا با\nدی  نیا  کار را انجام د\nهد؟  فقط به ا\nنی  ی دل ل  که \"را\nانه ی\nدی گو ی \" م  او با\nید  ای ن  \n  کار را انجام\nدهد؟ در مقا\nی،سه  \n الگور\nتم ی\nیی ها  \n مانند درخت تصم\nمی  ار ی بس  قابل تفس\nیر  \n.هستند \nالگوریتم  های یادگیری\nعمیق، الگوها و همبستگی\nها را از طریق داده  های تغذیه شده به آن پیدا\nمی کنند و گاهی تصمیماتی می\nگیرند که حتی برای مهندسانی که آن\nها را ایجاد کرده  اند، گیج\nکننده است. این امر زمانی که یادگیری عمیق کاری با اهمیت کم را انجام می  دهد، مشکلی را\n  .بوجود نخواهد آورد  اما وقتی تصمیم به سرنوشت یک متهم در دادگاه یا معالجه پزشکی بیمار\n باشد، بسیار سرنوشت\nساز خواهد بود. چرا که اشتباهات می\nتواند عواقب زیادی را به همراه داشته\n  .باشد  طبق گفته  گری  :مارکوس \n  \"مسئله شفافیت هنوز حل نشده است، کاربران هنگام استفاده از یادگیری عمیق\nبرای کار در حوزه-\n  های تشخیص پزشکی و تجارت مالی، دوست دارند درک کنند که چگونه یک سیستم مشخص یک\n \".تصمیم مشخصی را گرفته است \n21 \n فصل\nاول: مقدمه ای بر یادگیری عمیق \n \nی رو  \n  ،هم رفته، به گفته اندرو انگ\nیری ادگ ی  \n ی عم ق  ی راه  ی عال  ی برا  \n \"ساخت جامعه\nای  \n بر ی مبتن \nهوش مصنوع\nی\n\" است و غلبه بر ا نی  کاست ها ی  با کمک سا\nری  آور نف\nی،ها  راه درست برا ی  ی رس دن  \nنی به ا  \n.هدف است \nآینده ی یادگیری عمیق؟ \nیری ادگ ی  \n قی عم  در حال حاضر موثرتر\nنی  فناور\nی  هوش مصنوع\nی  ی برا  کاربردها\nی  \n  .متعدد است\nنی با ا \n حال، نظرات متفاوت\nی در مورد توانا یی\nهاِی  یری ادگ ی \n قی عم وجود دارد. در حال\nی که برخ ی  \n  محققان\nی ادگ ی یر  \n قی عم  بر ا\nین  \n باورند که همه مشکالت را م ی\nتوان  \n  یری ادگ ی با  \n قی عم  \n  ،حل کرد\nدانشمندا\nن  ی اد یز  وجود دارند که به نقص\nیی ها  \n  ی ادگ ی در یر  \n قی عم  اشاره م ی\nکنند .\n \nی گر  مارکوس  \n روانشناس پژوهشی  یکی  از پ\nی\nشگامان  \n  در\nحوزه  ِیری ادگ ی ی  \n قی عم!!\n!، روش\nها ی  \nیدی جد  را برا\nی  \n بهبود راه\nحل\nی ها  یری ادگ ی  \n قی عم  یپ\nشنهاد  م کند ی\nنی . ا  روش\nها شامل معرف ی  \n  استدالل\nیا  \nِدانش  ی قبل  \n  یری ادگ ی به  \n ی عم،ق  یری ادگ ی  خودنظارت\nی،  شبکه\nی ها  \n کپسول\nی  ی و غ ره  \n .هستند\nی گر  مارکوس، ت دیکا  م ی کند که تکن\nی ها کی  یری ادگ ی  \n ی عم،ق  دادهِ \n   خوار و\nشکننده هستند و توانا\nیی  \nآن  ها\nی برا  \n تعم\nیم  \n.محدود است   \n  ،یان لکان  دانشمند\nرایانه  \n می\nگوید\n: \"ه\nیچ  یک  \n از تکن\nی ها کی  هوش مصنوع\nی  که ما در اخت\nی ار  \nمی دار  \n ی نم\nتوان ن\nد از طر\nیق  \n  ساختار و\nای  از طر\nقی  یری ادگ ی،  بازنما یی\nیی ها  \n از جهان بسازد که به\nیزیچ  ی نزد ک  به آنچه در ح\nی\nوانات  \n و انسان\nها مشاهده م\nیک نیم  \n\"باشد.  از این\nرو  \n ی ها کی تکن  ی فعل  \nهوش مصنوع\nی  \n  مانند\nی ادگ ی یر  \n قی عم  هنوز هم قادر به ا\nی\nجاد  کی  هوش مصنوع\nی  عموم\nی  \n  که\nی دارا  هوش قابل مقا سه ی  با ح\nی\nوانات  ای  \n انسان اس\nت را ندارند\n. با ا\nی ن  \n  ،حال\nلکان  \n  معتقد است که\nهوش مصنوع\nی  م ی\nتواند  به سمت توسعه هوش عموم\nی  \n ی مبتن  \n  یری ادگ ی بر  \n قی عم  \n بدون  نظارت\nپی\nشرفت کند. یپ\nشرفت\nی که اخ\nرا ی از ین انسان به ارائه داده\nی ها برچسب\nدار دست\nی را که ماش\nها نی \n از\nآن  اد ی ها  م یگی،رند  برطرف م کند ی. \nی گر  \n  مارکوس  ِکه از مدافعان\nرو ی\nکرد  ی ترک یب  ی برا  ی ادگ ی یر  \n قی عم  \n  ،است\nیک  \n برنامهِی  \n  چهار\n مرحله\nای  \n  را\nبرای آینده  ی یادگیری عمیق\nپی\nشنهاد  یم:کند \n1\n. اتصال به دن\nیای  هوش مصنوع ی  کالس\nکی.  مارکوس رها\nیی  \n  از یری ادگ ی  \n قی عم  \n را\nپی\nشنهاد  \n ی نم\nکند، بلکه ادعا م\nکند ی  که ما با\nدی  از سا\nری  ی رو کردها ی  هوش مصنوع ی  \nمانند دانش قبل\nی،  استدالل و مدل\nی ها  شناختِی  \n ی غن  \n  همراه با\nیری ادگ ی  \n قی عم  ی برا  \nیی تغ\nرات  \n دگرگون کننده استفاده کن\nیم. \n2\n. ساخت چارچوب\nی ها  شناخت\nی  ی غن  و پا گاه ی\nی ها  \n اطالعاتِی  دانش در مق\nاس ی  بزرگ.  \nیس ستم\nی ها  یری ادگ ی  \n قی عم  به\nطور عمده  فقط با همبستگ\nی  بین  چ ی\nی زها  \n  خاص پر\n شده\nاند. بنابرا\nنی  به دانش ز\nی اد ی  از ین  \n.دارند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 22 \n \n \n3\n. ابزارها\nیی  ی برا  استدالل انتزاع\nی  ی برا  تعم\nمی  مؤثر.  ما با\nدی  بتوان\nمی  در مورد ا\nین  چی\nزها  \n استدالل کن\nمی . فرض کن\nدی  در مورد اش\nاء ی  یکیزیف  و موقع\nتی  آن  ها در جهان اطالعات\nمی دار  ،ی برا  \n  مثال\nکی  فنجان. فنجان حاو\nی  مداد است. سپس س\nی\nستم\nی ها  \n  یادگیری\nعمیق  دی با  \n  بتوانند متوجه  این موضوع\nشوند که اگر سوراخ\nی  در ته فنجان ا\nی\nجاد  \n ی کن،م  \nممکن است مدا\nدها  یب\nفتند\n. انسان ها هم\nشه ی  نیا  نوع استدالل را انجام م ی دهند، اما\nیس ستم\nی ها  \n یادگیری عمیق یا به طور کلی\nتر هوش مصنوعی  \n فعل ی،  نیا  \n  توانایی را\nندارند. \n4\n. مکان\nسم ی\nیی ها ی برا بازنما\nیی و القا\nی \n مدل\nی ها شناخت .ی \nادگ ی\nیری  قی عم  \n هنوز راه دراز\nی  در پ\nشی  دارد تا بتواند به ظرف\nی ها تی  همتا\nی ان \nانسان\nی \n خود دست\nابد ی . \n( استدالل نمادینsymbolic reasoning\n)\n \nی تار\nخچهِی  تحق قات ی  هوش مصنوع\nی  ی گاه  \n  اوقات به عنوان\nکی  کشمکش ب\nنی  دو رو\nی\nکرد  \nِمختلف  استدالل نماد\nین  \n  یری ادگ ی و  ماش\nنی  توص فی  م ی\nشود. در دهه اول، استدالل نماد\nین  \n  غالب\n  بود، اما\nیری ادگ ی  ماش\nین  \n  در دهه1990\n  \n  شروع به نفوذ کرد و با انقالب\nیری ادگ ی  \n ی عم،ق  یا ن  \n حوزه\nرا فرا گر\nفت.  با این حال، به نظر می،رسد  استدالل نماد\nنی  تنها مجموعهِی  ی گر ید  از روش  هاست\n  که ممکن است  به  گسترش\nو قدرتمند  ِتر کردن\nی ادگ ی یر  \n قی عم  \n.منجر شود \n  نیکو استروم\nیم  گو دی  :\n\"\n شبکه\nی ها  دگرگون( سازTransformer networks\n)  چیزی  \n  به نام توجه  \n(\nattention\n)  دارند. بنابرا\nنی  می\nتوان  کی  \n  بردار در شبکه  داشت و  شبکه\nمی\nتواند  یب\nشتر  از همهِی \nاطالعات د\nگر ی  به آن بردار بپرداز د.  از این\nرو  اگر پا\nگاه ی  دانش\nی  از اطالعات دار\nی،د  م ی\nتوان\nید  \n  آن را\nبا بردارها\nیی  که ن\nشان  دهنده حق\nقت ی  \n در آن پا\nگاه ی  \n دانش هستند، از قبل پر کن\nید  \n و سپس م ی\nتوان\nید  \nاز شبکه بخواه\nدی  که بسته به ورود\nی\n، به دانش درست توجه کند. به ا\nنی  بی ترت   م ی\nتوان\nدی  سع ی  \n دی کن  \nِدانش  \n  ساختار\nی افتهِی  جهان را با س\nی\nستم  یری ادگ ی  \n قی عم  ی ترک ب  \n دی کن. \nشبکه\nی ها  \n عصب\nی  گراف  زین  وجود دارند که م ی\nتوانند  \nِدانش  دربارهِی  \n  جهان را نشان دهند. شما\n گره\nها  \n  ی و ال\nیی ها  نیب  \n  این\nگره\nها دار\nدی  که روابط ب\nین  \n آن\nها را نشان می\nدهند  .بنابرا\nی،ن  ی برا  \n  ،مثال\nم ی\nتوان\nدی موجود\nیی ها تی را در گره\nها و سپس روابط ب\nی ن موجود\nها تی \n را\nنشان ده\nی . م دی\nتوان\nی م \nاز توجه در بخش\nی  \n  از\nگراف  دانش که برا\nی  نه ی زم  ای  وس\nال فعل\nی  \n مهم است استفاده کن\nیم. \nبه نظر می\nرسد  که   م ی  توان تمام دانش را در\nکی  گراف  \n  نشان\nداد  .\n  با این\nحال  ،نکته  ی مهم اسن\n  است که\nچگونه م\nی\nتوان آن را به روش\nی  \n  کارآمد و مناسب انجام\n؟ داد   \n\"هی\nنتون  یلیخ  وقت پ\nشی  نیا  ده یا  \n  را داشت. او آن را\nبردار فکر  (\nthought vector\n)  دی نام  .\nهر فکر\nی  که م\nی\nتوان\nدی  داشته باش\nی،د  می\nتوان\nیم  \n  ی با ک  بردار نما\nشی  می ده\n. دل\nلی  جالب بودن ا\nی ن \n23 \n فصل\nاول: مقدمه ای بر یادگیری عمیق \n \nاست که  ما م ی\nتوان\nمی  هر چ\nیزی  \n  را در\nگراف  نشان ده\nی،م  اما برا\nی  نکه یا  نیا  کار به خوب\nی  \n  هماهنگ\n  کی با  \n  مدل\nیری ادگ ی  \n قی عم  باشد، با\nدی  از طرف د\nگر ی  یزیچ  زین  داشته باش\nمی  که بتوان\nمی  هر چ\nیز ی \nرا با آن نشان ده\nمی  و اتفاقا  این همان  \n بردار  است\n. بنابرا\nین  \n ما م ی\nتوان\nیم  بین  این  \n  دو  یک نگاشت\nایجاد  \n می کن.\" \nر کا\nبردهای یادگیری عمیق؟ \n  امروزه\nیری ادگ ی  \n قی عم  به ابزاری قدرتمند و محبوب برای حل  مشکالت انسان\nی  در  هر حوزه\nا ی \n  .در حال استفاده است\nادگ ی یری  \n قی عم  ی برا  صدها مشکل، از ب\nیی نا ی  رایانه  \n تا پردازش زبان طب\nیعی ،  \nبکار گرفته شده است. در بس\nی ار ی  \n  ،از موارد  کارایی\nیری ادگ ی  \n قی عم  بهتر از کارها\nی  ی قبل  بود  ه\nاست  .ی ادگ ی یر  \n قی عم  \n به شدت در دانشگاه\nها برا\nی  \n مطالعهِی  \n  هوش و در صنعت در ساختن\nیس ستم\nی ها  هوشمند برا\nی  کمک به انسان د\nر  \n کارها\nی  مختلف استفاده م ی.شود  \n  در ادامه  \n این\nبخش،  نگاهی گذار  \n به بخشی از  کاربردهای  یری ادگ ی  \n قی عم  \n که مطمئناً شما را شگفت زده خواهد\nکرد  ،\n .خواهیم داشت  \n  البته باید گفت که\nبرنامه\nی ها  مختلف بس ار ی  ی اد یز  وجود دارد و ا\nی ن  ست یل  \nبه ه\nچی  وجه جامع ن\nست ی . \n  دستیاران مجازی \nمحبوب\nنی تر  \n  برنامه\nیری ادگ ی  \n قی عم  دست\nان ار ی  \n مجاز\nی  الکسا  ،یس یر  و دست\nار ی  \n  گوگل است. هر\nتعامل با ا\nنی  دست\nی\nارها  فرصت\nی  ی برا  آن\nها فراهم م\nی\nکند تا در مورد صدا و لهجه شما ب\nی شتر \nبی\nاموزند  و در نت\nجه ی  ی ک  تجربه ثانو\nهی  از تعامل انسان\nی  را برا ی  شما به ارمغان م\nی\nآورند. دست\nی\nاران  \nمجاز\nی  \n  یری ادگ ی از  \n قی عم  ی برا  دانستن ب\nی\nشتر  در مورد موضوعات خود استفاده م\nی کنند، از\nترج\nی\nحات  غذاخور\nی  \n شما گرفته تا مکان\nی ها  پربازد\nید  یا  \n موسیقی\nهای  مورد عالقه شما. آن  ی ها اد \nم رند یگی  که دستورات شما را با ارز\nی اب ی  \n زبان طب\nیعی  انسان برا\nی  اجرا\nی  آن .ها درک کنند \nیکی  گر ید  از قابل\nیی ها تی  \n  که  به\nدست\nی\nاران  مجاز\nی  \n ،اعطا شده است، ترجمه گفتار شما به متن\nی ادداشت\nبردار\nی  ی برا  شما و رزرو قرار مالقات است. دست\nاران ی  مجاز\nی  به معنا\nی  واقع\nی  \n  کلمه در\nخدمت  شما هستند،  \n چراکه  یم\nتوانند همهِی  کارها را از انجام وظا فی  تا پاسخگو\nیی  \n  خودکار به\n تماس\nی ها  خاص  \n  شما  گرفته\nتا هماهنگ\nی  وظا\nیف  بین  \n شما و اعضا\nی  تی\nمتان  \n.انجام دهند \n تجمیع اخبار و کشف اخبار تقلب \nاکنون راه\nی  ی برا  لتر یف  \n  کردن همه اخبار بد و زشت از\nگزیده\nی اخبار  \n شما وجود دارد. استفاده\n  گسترده از\nیری ادگ ی  \n قی عم  \n در جمع\nآور\nی  اخبار، تالش\nها را برا\nی  \n سفارش ی\nی ساز  \n اخبار طبق نظر\nخوانندگان تقو\nتی  م کند ی\n. اگرچه ا\nنی  ممکن است جد\nید  \n به نظر نرسد، سطوح جد\nی ی دتر  \n  از\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 24 \n \n \nی دگ یچیپ  ی برا  ت فی عر  شخص\nی ی ها ت  خواننده برا\nی  لتر یف  کردن اخبار بر اساس پارامترها ی  \nجغراف\nیی ای،  اجتماع\nی،  اقتصاد\nی  همراه با ترج\nی\nحات  ی فرد  خواننده انجام شده است. از سو\nی  \nید،گر  کشف اخبار کالهبردار\nی،  کی  دارا\nیی  مهم در دن\nیای  \n امروز\nی  است که در آن ا\nی\nنترنت  \n  به\nمنبع اصل\nی  همه اطالعات واقع\nی  \n  و\nی جعل  لی تبد  \n  .شده است \nتشخ\nیص  \n اخبار جعل\nی  بس ار ی  \n  سخت می،باشد  چراکه  ربات ها آن را به طور خودکار در کانال  ها\nتکرار م ی  .کنند\nیادگیری عمیق  \n  به توسعه\nطبقه\nبندهایی  \n کمک م کند ی  که م ی\nتوانند  اخبار جعل\nی  ی  ا\nمغرضانه را شناسا\nیی  کرده و آن  ها را از\nگزیده ی اخبار شما  حذف کند و در مورد نقض احتمال\nی  \nمی حر  خصوص\nی  \n .به شما هشدار دهند \n هوش عاطفی \nدر حال ی  که\nرایانه\nها  ممکن است نتوانند احساسات انسان\nی  \n  را تکرار کنند، به لطف\nیری ادگ ی  \n ی عم،ق  \nدرک بهتر\nی  از حاالت ما بدست م\nی\nآورند. الگوها\nیی  مانند تغ\nر یی  در لحن، اخم\nی ها  فی خف  ای  \nهق\nهق همگ\nی  سی\nگنال\nی ها  داده ارزشمند\nی  هستند که م ی\nتوانند به هوش مصنوع\nی  \n  کمک کنند  و\nت حاال  روح\nی  ما را تشخ\nصی  ده ن.د  \n از چن\nنی  برنامه\nیی ها  م ی\nتوان برا\nی  \n کمک به شرکت\nها برا\nی  \nارتباط دادن داده\nی ها  احساسات ب\nرای  غات ی تبل  \n  استفاده کرد\nای  حت ی  پزشکان را در مورد وضع\nیت  \nعاطف\nی  مار یب  \n .آگاه کرد \n مراقبت های بهداشتی \n پزشکان نم ی  توانند24\n  ساعت  شبانه روز را  در کنار ب\nی ماران  خود باشند، اما تنها چ\nیزی  \n  که همه\nما تقر\nبا ی  \n شه ی هم  همراه خود دار\nیم  \n تلفن\nمان ی ها  \n  است. به لطف\nیری ادگ ی  \n ی عم ،ق  ابزارها\nی  پزشک ی \nم ی\nتوانند  داده\nهاِی  عکس\nیی ها  که م\nمیریگی  و داده\nی ها  حرکت\nی  را برا\nی  تشخ\nصی  مشکالت سالمت ی  \nبالقوه بر\nی رس  کنند. نرم\nافزار ب\nنا ی یی  انه ی را  \nRobbie.AI\n  ی از ا ن  داده\nها برا\nی  ی اب ی رد  الگوها\nی  حرکت\nی  \nمار یب  ی برا  یبشیپ ین  \n سقوط و همچن\nنی  یی تغ\nرات  در وضع\nتی  روان\nی  کاربر استفاده م کند ی  .\n  یادگیری\n قی عم  \n همچن\nنی  ی برا  تشخ\nصی  سرطان پوست از طر\nقی  تصاو ری  \n.ثابت شده است \nیادگیری عمیق  \n همچن\nنی  در تحق\nقات ی  ی بال ین  ی برا  ی\nافتن  راه\nحل\nیی ها  ی برا  ی ها ی مار یب  یغ رقابل  \n درمان به\nشدت مورد استفاده قرار م یگی،رد  اما شک و ترد\nدی  پزشکان و فقدان مجموعه داده\nی ها  \n گسترده هنوز چالش\nیی ها  را برا\nی  \n  استفاده از\nی ادگ ی یر  \n قی عم  در پزشک\nی  ای\nجاد م کند ی. \n شناسایی کالهبرداری \nاز  آنجا\nیی  که  بانک\nها  به  د\nی تال یجی  کردن  فرآ\nند ی  \n تراکنش\nی ها  خود  ادامه  م\nده ی ن د،  احتمال\nکالهبردار ی ها ی  ی تال یجید  در حال افزا\nشی  است، بنابرا\nنی  ی برا  جلوگ یری  نی از ا  نوع کالهبردار\nی،  \n25 \n فصل\nاول: مقدمه ای بر یادگیری عمیق \n \nیری ادگ ی  \n قی عم  \n نقش مهم\nی  فا یا  م ی\nکند. تشخ\nصی  کالهبردار\nی  را م ی\nتوان به سرعت از طر\nیق  \n ی ها کی تکن  یری ادگ ی  \n قی عم  \n .انجام داد \nخالصه فصل \n▪ هوش مصنوعی یس ستم\nی \n است\nکه م ی\nتواند رفتار انسان را تقل\nدی کند.\n \n▪ در س\nی\nستم\nی ها را یا انه ی، تجربه در قالب داده ها وجود دارد .\n \n▪ الگور\nتم ی  ادگ ی\nیری  قی عم  \n  مشابه نحوه ادگ ی\nیری  \n ما از تجربه\nها و نمونه  ،ها کی  \n کار را به طور\nمکرر انجام م\nی\nدهد و هر بار کم ی آن را تغ\nر یی یم\nدهد تا نت\nجه ی \n .را بهبود بخشد \n▪ \n مدل\nی ها   ادگ ی\nیری  قی عم   یکی  از داده    خوارتر نی  مدل\nی ها  داده در دن\nیای   ادگ ی\nیری  ماش\nی ن \n.هستند \n▪ \n شناخته\nشده\nتر نی نقطه ضعف شبکه\nی ها عصب\nی تی ماه \n عدم شفاف\nیت \n .آنهاست \n آزمونک \n1\n. \n هوش مصنوعی، یادگیری ماشین و یادگیری عمیق .را تعریف کنید \n2\n. \n فراموشی فاجعه\nآمیز در شبکه\nهای عصبی چه زمانی اتفاق می\nافتد؟ \n3\n. مزیت مهم یادگیری عمیق در مقایسه با یادگیری ماشین در چیست؟ \n4\n. \n چند مورد از محدودیت و چالش.های یادگیری عمیق را شرح دهید \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n2 \n \n▪\n \n داده چیست؟ \n▪\n انواع داده ها \n▪\n \n آشنایی با رویکردهای متفاوت یادگیری ماشین \n▪\n \n مزایا و معایب هر یک از رویکردها \n▪\n ا نتخاب و ارزیابی مدل چیست؟ \n \n اهداف  یادگیری:\n \nپیش\nنیازها \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 28 \n \n \n مقدمه \nیری ادگ ی  \n قی عم  یز\nرمجموعه\nای  \n از روش  های\nیری ادگ ی  ماش\nنی  است\n. از ا\nنی،رو  مرور\nی  بر مفاه\nیم  \nیری ادگ ی  ماش\nنی  قبل از فراگ\nیری  یری ادگ ی  \n قی عم  دی مف  خواهد بود. ا نی  فصل جزئ\nات ی  مفاه\nی می  \n که\nی برا  \n  درک\nادگ ی یری  \n قی عم  مورد ن از ی  \n است را به گونه\nیا  ارائه م ی\nدهد  که پ\nی ینش از\nها  \n  حداقل شود\nو اطالعات کامل\nی  در مورد داده\nها، ابزارها\nی  مورد ن\nاز ی  و مبان\nی  یری ادگ ی  ماش\nنی  ارائه م ی\nدهد .\nبه\nطور کل\nی،  نیا  فصل به عنوان پا یاهی  ی برا  یری ادگ ی  کامل مطالب ارائه شده در ا\nین  \n.کتاب است \nداده  (\nData\n )   \n\" کلمه\nداده\n\" از کلمه الت\nین  \ndare\n  گرفته شده است که به معنا\nی  \"\n یزیچ  داده شده\n\" است\n؛  یک  \n  مشاهده\nای  کی  واقع\nیت  \n  در مورد\nیک  \n  .موضوع\nداده  ها اشکال و\nقالب\nهای  مختلف\nی  \n  دارند، اما\nبه\nطور کل\nی م ی\nتوان آن را نت\nجه ی آزما\nشی تصادف\nی تصور کرد\n؛ آزما شی ی که نت\nجه ی \n آن را نم\nی توان از\nقبل تع\nن یی  کرد، اما عملکرد آن هنوز در معرض تجز\nهی  و تحل\nلی  است. داده\nی ها  کی  آزما ی ش  \n تصادف\nی  \n  اغلب در\nیک  \n  جدول ای  صفحه گسترده ذخ\nره ی  م ی  .شود\nیک  \n قرارداد آمار\nی  این  \n  است که\nی متغ\nرها  را که اغلب و\nی ژگ ی\nها نام\nده ی  یم\nشود،  به عنوان ستون و موارد منفرد را به عنوان رد\nی ف  \n  نشان\nداده شوند  .\n \n تعریف1.2\n داده \nِداده ها به قطعات  زی متماِ اطالعات\nی  اطالق م\nی شود که معمولً به گونه ا ی  قالب\nی بند  ره ی و ذخ  یم  \n  شوند که با\nهدف خاص\nی  مطابقت داشته باشد. داده\nی ها م  توانند به اشکال مختلف وجود\nداشته باشند،  \n  به صورت\n  اعداد\nای  متن بر رو\nی  \n کاغذ، به صورت ب\nتی  ای ها  یبا یها ت  ره ی ذخ  ه شد  در حافظه الکترون\nیکی  یا  \n  به عنوان\nیقی حقا  \n  که در ذهن\nیک  \n  فرد\nوجود دارند نی . با ا  \n  ،حال\nدر  \n  علوم\nرایانه    ،داده ها معمولً به اطالعات\nی  \n  اشاره\nدارند که به صورت الکترون\nیکی  \n  منتقل\nای  ره ی ذخ  یم\nشوند    و\nبه شکل\nی  ترجمه شده اند که برا ی  جابجا\nیی  ی ا  \nپردازش کارآمد باش\nن .د \n \nی برا  آموزش الگور تم ی  ی ادگ\nیری  عمیق  \n ما به داده\nی ها  ی اد یز  ی برا  ورود\nی  ین از  \nمی دار . هر نقطه داده را م ی  توان\nیک  \n  نمونه\nیا  یک  \n مثال   زین  \n نام\nدی  . اگر مسئله  \nادگ ی\nیری  با\nنظارت داشته باش\nی،م  هر ورود\nی  \n  )(بردار\nی ک  خروج\nی  \n  (بردار) مرتبط\n خواهد داشت. م ی\nتوان\nی د  یا ن ها  \n را به عنوان م\nی تغ\nرها\nی  \n مستقل و وابسته ی مرتبط  \nدر نظر بگ\nیرید .\n \n \n29 \n فصل\nدوم: پیش نیازها \n \nداده های قابل خواندن توسط ماشین در مقابل قابل خواندن توسط انسان \nداده  کی ها  دارا\nیی  ضرور\nی  برا ی همهِی  \n سازمان\nها هستند و اساس بس\nی ار ی  از توسعه  \n برنامه\nها  \n را\nتشک\nیل  م ی\nدهند  \n  و  همچنین\nکاربرد الگور\nتم ی  به صحت داده\nها و صحت منبع بستگ\nی  دارد. نما\nی ش  \nداده\nها در قالب صح حی  بدون از ب\nنی  بردن مقدار اصل\nی،  بخش م ی هم  از س\nی\nستم  ری مد تی  \n  داده\n.است \nهمه داده\nها را م\nی\nتوان به عنوان قابل خواندن توسط ماش\nی،ن  \n  قابل خواندن توسط انسان\nیا  \n  هر\nدو دسته\nی بند  کرد. داده\nی ها  \n قابل خواندن توسط انسان از قالب\nی ها  \n زبان طب\nیعی  \n  (مانند\nکی  لی فا  \n ی متن  ی حاو  کدها\nی  \nASCII\n  یا  \n  سندPDF) استفاده م ی،کنند  در حال\nی  که داده\nی ها  \n  قابل خواندن\nتوسط  ماش\nین  \n از زبان\nی ها  \n رایانه\nای  \n با ساختار رسم\nی  ی برا  خواندن توسط س\nی\nستم\nها  ای  \n نرم\nافزارها ی  \nی را یا انه  استفاده م ی\nکنند\n. برخ\nی  از داده\nها هم توسط ماش\nی ن  ها و هم توسط انسان قابل خواندن\n  هستند، مانندCSV\n  ،\nHTML\n یا  \nJSON\n . \nقالب قابل خواندن توسط ماش\nی ن  ی برا  دستگاه\nها و ماش\nنی  ها\nطراح\nی  شده است. درک ا\nین \nقالب برا\nی  انسان پ\nده یچی  است  و همچنین  ابزارها\nی  تخصص\nی  ی برا  خواندن محتوا\nی  داده\nی ها  \nقابل خواندن توسط ماش\nنی  ضرور\nی  \n  .است\nداده\nی ها  \n  ارائه شده در قالب قابل خواندن توسط\nماش\nین  \n را م ی\nتوان به\nطور خودکار استخراج کرد و برا\nی  پردازش و تجز\nهی  و تحل\nیل  بی\nشتر  \n  بدون\n.دخالت انسان استفاده کرد \nداده\nی ها  قابل خواندن توسط انسان م ی\nتواند توسط انسان درک و تفس\nری  شود. تفس\nری  داده  ها\nبه تجه\nی زات  ای  دستگاه\nی ها  تخصص\nی  از ین  ندارد  .نیا  زبان دارا ی  کی  \n زبان طب\nیعی  \n است (به عنوان\n  ،مثال  ،فارسی\nانگل یسی،  \n فرانسو\nی  و غ\nره ی\n) و نما\nی  ش\nداده\nها بدون ساختار است.  نمونه\nای  \n  از\n قالب\nهای  \n  قابل خواندن توسط انسان\nیک  \n  سندPDF\n  \n  است. اگرچهPDF\n  کی  رسانه د\nیجی تال \nاست اما نما\nیش  \n داده\nی ها  آن ن\nی ی از  به ه\nچی  تجه\nزات ی  تخصص\nی  ی ا  یا انه ی را  ی برا  تفس\nیر  \n  .ندارد\nعالوه بر ا\nی،ن  \n  اطالعات موجود در سندPDF\n  معموالً برا\nی  انسان\nها در نظر گرفته شده است، ن\nه  \nماش\nی ن.ها \n عبارت داده در فناوری \nداده  ها  به\nجلودار  ی ار ی بس  از گفتگوها  ی اصلی\nدر مورد فناور\nی  لی تبد  شده\nاند. نوآور\nی ها ی  ی جد د \nبه\nطور دائم  بر رو\nی  داده\nها، نحوه استفاده و تجز\nهی  و تحل\nیل  \n آن\nها  \n تفسیر می\nشود\n. در نت\nی،جه  \n  زبان\nجی را  فناوری  شامل تعداد\nی  \n  از\nعبارات جد\nدی  ید و ق یم  \n :شده است \n• کالن داده  (\nBig data\n):  حجم عظ\nی یم  از داده\nی ها  \n ساختار\nی\nافته  و بدون  ساختار که  به\nسرعت تولید و از منابع مختلفی بدست آمده و سبب افزایش بینش و تصمیم\nگیری می شود \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 30 \n \n \n• تجزیه و تحلیل کالن داده  (\nBig data analytics\n):  ند ی فرآ  \n جمع\nآور\nی،  سازمانده\nی  \n  و\nبی ترک  \n مجموعه\nی ها  بزرگ داده برا\nی  \n  کشف الگوها\nای  ری سا  اطالعات مف\nید.\n \n• یکپارچگی داده ها  (\nData integrity\n):  اعتبار داده\nها که م\nی\nتواند به طرق مختلف\nی  \n  از جمله\nی خطا  انسان\nی   ای  خطاها\nی  انتقال به خطر ب\nفتد ی.\n \n• فراداده (\nMetadata\n): \n  اطالعات خالصه در مورد\nیک  \n.مجموعه داده \n• داده( ها خامRaw data\n:)\n  اطالعات\nی  \n که جمع\nآور\nی  شده\nاند،  \n اما قالب\nی بند  ای  تجز\nیه  \n و\nتحل\nیل  \n نشده.اند \n• داده\nهای ساختاریافته  (\nStructured data\n):  هر داده\nای  \n  که در کی  لد یف  \n  ثابت در\nی ک  \n  رکورد\nای   لی فا  قرار دارد، از جمله داده\nی ها  موجود در پا\nی گاه\nی ها  داده رابطه\nای  \n  و صفحات\n.گسترده  \n به عبارت ساده  ،تر\nداده\nی ها  ساخت ی ار\nافته  شامل انواع داده ی ها  به وضوح تعر فی  \nشده با الگوها\nیی  \n است که آن\nها را براحت\nی  قابل جستجو م کند ی.\n \n• داده\nهای بدون ساختار  (\nUnstructured data\n):  اطالعات\nی  \n  که در\nکی  گاه ی پا  \n  داده به\n  صورت\nفی رد  \n  و\nستون\nی  سنت ی  مانند داده\nی ها  ساخت\nی ار\nافته  ند ست ین.  \n ،به عبارت دیگر\nداده های بدون  ساختار شامل داده\nیی ها  است که معموال به راحت\nی  قابل جستجو ن\nی،ست  \n  از\n جمله فرمت\nیی ها  مانند صوت،  دئو یو  \n و پست\nی ها  رسانه\nی ها  اجتماع\nی.\n \n انواع داده\nها \nداده\nها در قالب\nها و انواع مختلف\nی  ند یآیم\n. درک خصوص\nات ی  هر و\nی ژگ ی  ای  \n،جنبه  اطالعات\nی  \n را در\nمورد ا\nی نکه  چه نوع عمل\nی ات ی  را م\nی\nتوان بر رو\nی  آن و\nی ژگ ی  انجام داد، ارائه م\nی ،دهد. به عنوان مثال\nدما در داده\nی ها  آب و هوا را م\nی  توان به صورت\nیکی  \n از فرمت\nی ها  ریز  ان یب  \n :کرد \n1\n. درجه سانتی\nگراد عددی (\n25\n درجه سانتی)گراد ، فارنهایت و یا در مقیاس کلوین \n2\n. \n برچسب گذاری  بر اساس هوای گرم، سرد و یا مالیم \n3\n. تعداد روزها\nی  کی سال ز ری صفر درجه سانت\nی\nگراد (\n20\n روز در سال ز ری \n )صفر \nهمهِی  نیا  ها ی ژگ یو  ی دما  کی  \n منطقه را نشان م ی،دهند  اما هر کدام دارا\nی  انواع داده\nای  \n متفاوت\nی  \n.هستند \n ( عددیNumeric\n( ) یا پیوستهContinuous\n ) \nدما\nیی  که بر حسب سانت\nی\nگراد  ای  فارنها\nتی  ان یب  م ی\nشود  عدد\nی  ی و پ\nوسته  است،  را یز  یم\nتوان  \n  آن\nرا با اعداد نشان داد و ب\nنی  ارقام ب\nتی نها ی  مقدار را گرفت. عدد صح\nحی  شکل خاص\nی  \n  از نوع داده\nعدد\nی  است که دارا\nی  اعشار در مقدار ن\nست ی  ی ا  به\nطور دق\nی ق\nتر دارا ی  مقاد ری  ب تی نها ی  نیب  اعد\nاد  \nمتوال\nی  ست ین\n. معموال تعداد چ\nی یز،  تعداد روزها\nی  \n با دما\nی  \n کم  تر از0\n  درجه سانت\nی،گراد  \n  تعداد\n31 \n فصل\nدوم: پیش نیازها \n \n  سفارشات، تعداد فرزندان\nکی  خانواده و غ\nره ی  را نشان م ی .دهند  اگر نقطه صفر تعر فی  \n  ،شود\nداده\nی ها  عدد\nی  \n  کی به  \n  نسبت\nای  نوع داده واقع\nی  لی تبد  م ی\nشوند. به عنوان مثال م ی  توان به دما در\nاس ی مق  \n ی کلو،ن  موجود\nی  حساب بانک\nی  \n.و درآمد اشاره کرد \nرسته( ایCategorical\n( ) یا اسمیNominal\n ) \nداده\nی ها  رسته\nای  یا  اسمی  به  عنوان  داده\nیی ها  فی تعر  م ی\nشوند  که  برا\nی  نام\nگذار\nی  ی ا  \n برچسب\nگذار\nی  ی متغ،رها  بدون ه\nیچ  \n مقدار کم\nی  استفاده م ی\nشوند\n. معموال ه\nچی  بی ترت  ی ذات  ی برا \nداده\nی ها  \n اسم\nی  وجود ندارد. به  عنوان مثال، رنگ\nکی  تلفن هوشمند را م\nی\nتوان  به عنوان نوع داده\n اسم\nی  در نظر گرف\nرا ی . ز ت  \n نم ی\nتوان\nیم  یک  \n رنگ را با رنگ\nی ها  گر ید  سه ی مقا  \n می کن\n. به عبارت د\nی،گر \n ی نم\nتوان  ان یب  کرد که \"قرمز\" بزرگتر از \"آب\nی\n\" است. به\nعنوان مثال\nی   ید،گر  \n  رنگ چشم\nی ک  ی متغ ر  \n اسم\nی  است که دارا\nی  چند دسته (آب\nی،  سبز، قهوه\nای\n) است و راه\nی  ی برا  \n مرتب\nی ساز   نیا  \n دسته ها\nاز باالتر\nنی  به کمتر\nین  \n .وجود ندارد \n مجموعه داده \nکی  مجموعه داده  ،مجموعه\nیا  از داده\nها است که معموالً به صورت جدول ارائه م\nی شود. هر\n ستون نشان  دهنده\nکی  ری متغ  خاص  \n)(ویژگی  است. هر رد\nیف  \n  مربوط به\nکی  عضو مع\nین  \n  از\nمجموعه داده مورد نظر است  و  مقاد\nیر  \n  را\nی برا  \n  کی هر  از متغ\nی\nرها  م ی  کند. هر مقدار به عنوان ی ک  \nداده شناخته م\nی .شود \n تعریف1.2\n مجموعه داده \nمجموعه داده\nها را اغلب م\nتوان ی  به عنوان مجموعه یا  از اش\nاءی  داده با و\nیها ی ژگ ی  ی\nکسان  \n  .در نظر گرفت\n نام\nیها  گر ید   ی برا  کی   یش  \n داده عبارتند از: رکورد، نقطه، بردار، الگو، رو\nی،داد  \n ،مورد، نمونه، مثال\n مشاهده\nای موجود\nیت . \n \n تعریف1.2\n ویژگی \nکی  ی ژگ یو،  \n  .مشخصه داده است ویژگی   را  می  توان  \n  به عنوان\nکی  ری متغ  توض یحی  \n  در نظر  \n  گرفت. این ویژگی\nممکن است عدد ی  باشد (ارتفاع درخت  3  متر  )ای  ممکن است توص\nفی ی  باشد (رنگ چشم آب\nی ). اغلب اگر\nتوص\nیفی \n باشد، برا\nی \n انجام دست\nورزی های ی اضیر  دیبا \n به آن\nکی برچسب عدد\nی بده\nید. \n \n  هر نقطه داده اغلب با\nکی  بردار و\nی ژگ ی  \n نشان داده م\nی\nشود، هر ورود\nی  \n  در بردار\n نشان دهنده\nکی  ی ژگ یو \n .است \n \n \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 32 \n \n \nرویکردهای یادگیری ماشین  \nدر زم\nنه ی  یری ادگ ی  ماش\nی،ن  \n  دو نوع\nرویکرد  اصل\nی  \n  :وجود دارد\nبانظارت  و بدون  نظارت. تفاوت\nاصل\nی  بین  این  \n دو نوع  رویکرد  یا ن  \n  است که\nیری ادگ ی  با  نظارت با استفاده از\nی ک  قت ی حق  \n  یادگیری\nرا بدست می  آورد\nای  به عبارت د ی،گر  ما از مقدار خروج ی  نمونه ی ها  خود ،  آگاه\nی  ی قبل  می دار .\nبنابرا\nی،ن  \n  هدف\nاز  یری ادگ ی  با  ،نظارت\nیری ادگ ی  تابع\nی  است که با در نظر گرفتن نمونه\nیا  از داده ها\nو خروج\nی ها ی  مورد نظر، به بهتر نی  وجه رابطه ب\nنی  ورود\nی  \n و خروج\nی  \n قابل مشاهده در داده  ها را\nتخمین  می\nزند  .یری ادگ ی  با\nنظارت معموالً در زم\nنه ی  طبقه\nی بند  انجام م\nی\nشود، زمان\nی  که م ی\nخواه\nی م  \nورود\nی  \n را به برچسب\nی ها  خروج ی  \n نگاشت کن\nمی ،  ای  رگرس\nی،ون  زمان ی  که م\nی\nخواه\nی م  ورود ی  \n را به\nکی  خروج\nی  پی\nوسته  \n.نگاشت کنیم \nاز سو\nی  ید،گر  \n  یری ادگ ی در  بدون\nنظارت، خروج\nی ها ی  \n برچسب\nگذار\nی  یا شده  \n  وجود ،ندارد\nبنابرا\nین  \n هدف آن استنباط ساختار طب\nیعی  موجود در مجموعه\nای  \n  از نقاط داده  و کشف الگوها\n  بدون هیچ راهنمایی.است  متداول\nنی تر  وظا فی  \n  ادگ ی در یری  \n بدون نظارت عبارتند از خوشه\nی بند \n  و\nکاهش ابعاد\n. در ا\nنی  موارد، ما م ی\nخواه\nمی  ساختار ذات\nی  داده\nی ها  \n  خود را بدون استفاده از\n برچسب\nی ها  \n  ارائه شده\nاد ی  میری بگ. \n  کی در  \n  مدل\nادگ ی\nیری  با\nنظارت، الگور\nتم ی  ی رو  کی  \n مجموعه داده برچسب\nگذار ی \n  شده\nاد ی  \n رد یگیم  و  دارای  کی  دی کل  \n  پاسخ\nاست  که الگور تم ی  \n می\nتواند  \n از آن برا ی  \n ی اب ی ارز  دقت  خود  در  داده\nی ها  آموزش\nی  \n  ،استفاده  کند.  در  مقابل\nیک  \n مدل\n بدون  ،نظارت  از داده\nی ها  \n  بدون برچسب\nاستفاده   یم\nکند  و  الگور\nتم ی  ی سع   م ی\nکند \nبا استخراج و\nژگ ی ها ی و الگوها به تنها\nیی  \n آن ها\nبه ساختار ذاتی داده.ها پی ببرد \n یادگیری بانظارت \nیری ادگ ی  با  نظارت\nیکی  از پرکاربردتر\nین  \n شاخه\nی ها  یری ادگ ی  ماش\nنی  است که از داده\nی ها  آموزش ی  \n برچسب\nگذار\nی  شده برا\nی  کمک به مدل\nها در پ\nیبشی ین  قی دق  استفاده م\nکند ی\n. داده\nی ها  آموزش\nی  \nدر ا\nی\nنجا  به\nعنوان سرپرست و معلم برا\nی  ماش\nی ها ن  عمل م\nی،کنند  از ا\nنی  رو به ا\nین  \n  نام\nاشاره  \nم ی\nشود  .یری ادگ ی  با نظارت مبتن\nی\nبر تول\nدی  خروج\nی  از تجرب\nات ی  گذشته (داده\nی ها  \n )برچسب دار\n  است. در\nیری ادگ ی  با  ،نظارت\nکی  ری متغ  ورود ی   (\n𝑥\n  ) با کمک\nیک  \n  تابع نگاشت که توسط\nی ک \n  مدل\nیادگیری ماشین  آموخته م ی\nشود، به متغ\nری  خروج\nی   (\n𝑦) نگاشت م ی.شود \n𝑦= 𝑓(𝑥) \nدر ا\nی\nنجا  مدل تابع\nی  ی را ا\nجاد  کند یم  که دو متغ\nری  را با هدف نها\nیی  بهم متصل م\nکند ی  \n  تا برچسب\nحی صح  داده\nی ها  ورود\nی  ی را پ بش ی ین  کند. \n33 \n فصل\nدوم: پیش نیازها \n \nیک  \n الگور\nی تم  ادگ ی\nیری  با\nنظارت هم ی\nشه  ی دارا  کی  متغ\nیر  \n  هدف\nای  جه ی نت   (ای  متغ\nی ر  \nوابسته) است که از مجموعه\nیا  از پ ی ینیبش  کننده\nی ها  ارائه شده (متغ\nی\nرها ی \nمستقل) شناسا یی   یم\nشود. الگور\nتم ی از ا\nنی  مجموعه متغ\nی\nرها ی برا   یا\nجاد  \n تابع ی  \n استفاده م ی\nکند که ورود ی\nها را به خروج ی ها ی  \n دلخواه نگاشت م\nی\nکند. ا\nین  \n ی فرآ ند  \nآموزش\nی \n تا زمان\nی \n که\nتکرار می\nشود که مدل به سطح باال\nیی \n از دقت دست\nابد ی. \n \n مجموعه داده برچسب\nگذاری شده  \n به ا\nنی  معن ی  \n  است که هر نمونه در مجموعه\nداده آموزش\nی  با پاسخ\nی  که الگور\nتم ی  دی با  به خود\nی  خود ارائه کند برچسب\nگذار ی \n می\nشود. بنابرا\nی،ن  \n مجموعه داده برچسب\nگذار\nی  \n شده از تصاو\nیر  \n گل به مدل\n دی گو یم  \n که کدام عکس  ها\nمربوط به  گل رز، گل بابونه و نرگس است. هنگا م ی  \n  کی که  تصو\nری  دی جد  بخ مدل  \n نشان داده م\nی شود، مدل آن را با نمونه\nی ها  آموزش ی \nی مقا\nسه  م ی\nکند تا برچسب صح\nحی را پ ی ینیبش \n .کند \nطبقه\nبندی (\nClassification\n ) \nطبقه\nی بند  \n  یک\nند ی فرآ   با  ،نظارت است\nیعنی  الگور\nتم ی  یادگیرنده  بر اساس داده\nی ها  آموزش\nی  \n  که از\nقبل برچسب خورده\nاند سع\nی  در یافتن یک ارتباط  نیب  داده ها و برچسب  ها\nدارد .\n \n در طبقه\nبندی  کالس  ها از قبل مشخص هستند و اغلب با عنوان هدف، برچسب\nای دسته \n نام\nده ی  یم\nشوند . \n \nداده\nی ها ی دارا  برچسب برا\nی  \n آموزش دسته بند استفاده م\nی\nشود \n تا بتواند بر رو ی  \nداده\nی ها  ورود\nی  دی جد  به خوب\nی  \n  عمل کند و بتواند کالس درست آن نمونه را\nپ ی ینیبش  کند. به عبارت د ی،گر  \n هدف ا\nین  \n  است که\nی ک  تقر\nبی  خوب برا\nی  \n𝑓(𝑥)\n \nدا یپ  شود تا بتواند برا\nی  \n داده\nی ها  ده ید\nنشده  در فرآ ند ی  آموزش پ ی ینیبش  \n  انجام\n دهد و بگو\nدی که نمونه جد\nی د \n به کدام\nیکی از کالس.ها تعلق دارد \n مسائل طبقه\nی بند را م\nی\nتوان از دو د\nی\nدگاه متفاوت تقس\nی ی بند م کرد.  از د\nی\nدگاه \n  تعداد برچسب\n  که  به  دو\nدسته  \n طبقه ی بند  تک\nبرچسب\nی  \n(\nsingle-label classification\n)\n  \n  و طبقه ی بند \n چند\nبرچسب\nی  (\nmulti-label classification\n) \n قابل تقسیم هستند و\nاز د\nی\nدگاه  \n تعداد کالس\nها \n  به\n  دو دسته  \n طبقه ی بند  دودو\nیی  \n(\nBinary Classification\n)  \n  و طبقه\nی بند  \n چند\nکالس\nی  \n(\nMulti-\nClass Classification\n)  تقس\nیم\nبندی  م دن شو ی.   \nطبقه\nبندی  دودو\nیی  \n  که در آن هر نمونه تنها به\nیکی  \n  از دو\nکالس  از پ ی ش  ی تعر ف\nشده  \n  اختصاص\nداده م\nی،شود  ساده\nنی تر  \n  نوع\nطبقه\nبندی  \n  .است\nطبقه\nبندی  دودو\nیی  با تعر\nیف \n کالس\nهای  یب\nشتر  \n  به\nطبقه\nبندی  چندکالسی  \n گسترش م ابد یی  .\n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 34 \n \n \n طبقه بندی تک برچسبی \nدر طبقه\nی بند  داده\nی ها  تک برچسب\nی،  هر نمونه تنها م\nی\nتواند  \n  کی با  برچسب ارتباط داشته باشد   و \nالگور\nتم ی  طبقه\nبندی  در مرحله آموزش برا\nی  هر نمونه جد\nید  \n  تنها\nکی  برچسب را پ\nی یبش ین  می\nکند  .\nبه طور کل\nی،  \n  مسائل\nطبقه\nبندی  تک برچسب\nی  را م ی\nتوان  به دو گروه اصل\nی  تقس\nیم  \n  کرد: مسائل\nدودو\nیی  \n  و\nچندکالسی.   \n طبقه بندی دودویی \nمساله دسته\nی بند  دودو\nیی  ساده\nنی تر  \n  حالت از مسائل طبقه\nبندی  \n است که در آن مجموعه کالس ها\nتنها به دو مورد محدود م\nی\nشود\n. در ا\nنی  ی زم،نه  ما ب\nی ن  کالس مثبت و کالس منف\nی  زی تما  \n  قائل\nم می شو ی  .کی  مثال ساده از مسائل دسته\nی بند  دودو\nیی  زمان\nی  \n  است که\nیک  \n زن به پزشک مراجعه\nم کند ی  تا از باردار بودن خود مطلع شود. نت\nی جه  آزما\nیش  \n  ممکن است مثبت\nای  ی منف  \n.باشد   \nبه\nطور  اساس\nی  \n طبقه\nبندی  دودو\nیی  نوع\nی  پ ی ینیبش  است  که  به  ا\nین  \n موضوع\n می\nپردازد \n که\nیک \n نمونه به کدام\nیک \n.از دو گروه کالس تعلق دارد \n طبقه بندی چند کالسی \nطبقه\nبندی  چند\nکالسی  ای  \n چندگانه  ،طبقه\nبندی  \n عناصر  به کالس\nی ها  \n  مختلف  است.  برخالف\nطبقه\nبندی  دودو\nیی  که محدود به تنها دو کالس است، محدود\nیتی  \n در تعداد کالس ها ندارد و\nم ی\nتواند  طبقه\nبندی  یب از ش  \n  ،دو کالس را انجام دهد. به عنوان مثال\nطبقه\nبندی  اخبار در دسته\nها ی  \n  ،مختلف طبقه\nبندی  کتاب\nها براساس موضوع و طبقه\nی بند  یح\nوانات  \n  مختلف در\nکی  تصو\nی ر  \nنمونه\nی ها  \n  از\nطبقه\nبندی  چندکالسی  هستند. \n طبقه بندی چندبرچسبی \n  در مسائل\nطبقه\nبندی  ی سنت،  \n  هر نمونه با\nکی  برچسب کالس مرتبط است. با ا\nنی  حال، در بس\nی ار ی  \nاز سنار\nی\nی وها  یای دن  واقع\nی،  کی  نمونه ممکن است با چند\nین  \n برچسب مرتبط باشد. به عنوان\n  مثال، در طبقه\nبندی  اخبار، بخش\nی  از اخبار مربوط به عرضه آ\nفون ی  دی جد  \n  توسط اپل، هم با\nبرچسب تجارت و هم با برچسب فناور\nی  مرتبط است. به عبا رت د\nی،گر  هر نمونه به جا\nی  \n تنها\nکی  برچسب، با مجموعه\nای  \n از برچسب  .ها مرتبط است\nیری ادگ ی  چند برچسب\nی  کی  نه ی زم  ری ادگ ی ی  \nماش\nین  \n  است که به یری ادگ ی  از داده\nی ها  چند برچسب\nی  اشاره دارد که در آن هر نمونه با چند\nی ن  \nبرچسب بالقوه مرتبط ا\nست.   \nطبقه\nی بند  چند برچسب\nی  یکی  از مسائل مهم در زم\nنه ی  \n پردازش زبان طب\nیعی،  \n به خصوص در\nطبقه\nبندی  متون است. عالوه بر ا\nی،ن  از آن در بس\nی ار ی  مسائل دن\nیای  واقع\nی  همانند، باز\nی اب ی  \n35 \n فصل\nدوم: پیش نیازها \n \nاطالعات، تشخ\nصی  ی مار یب  ی و ب\nوانفورمات\nکی  استفاده م ی\nشود\n. تفاوت طبقه\nی بند  چند برچسب ی \nبا طبقه\nی بند  چ\nندکالس\nی،  \n در تعداد برچسب\nیی ها  است که م ی\nتواند  \n  کی به  \n  نمونه اختصاص\nابد ی . \n طبقه\nبندی  چند\nبرچسب\nی  حالت تعم می  ی افته\nای  \n  از طبقه\nبندی  تک\nبرچسب\nی  \n  ،است\n چرا که در آن هر نمونه م ی\nتواند به جا\nی ی ک \n برچسب با مجموعه\nای \n از برچسب ها\n.در ارتباط باشد \nرگرسیون \nتفاوت اصل\nی  نیب  مدل\nی ها  رگرس\nون ی  و طبقه\nی بند  یا ن  است که الگور\nی تم\nی ها  رگرس\nون ی  ی برا  \nیپ یبش ین  مقاد\nیر  پی\nوسته  (نمرات آزمون) استفاده م ی،شوند  در حال ی  که الگور\nی تم\nی ها  طبقه\nی بند  \nمقاد\nری  گسسته (مذکر/مونث، درست/نادرست) را پ\nیشبی نی  می\nکنند  .رگرس\nون ی  ی\nک فرآ\nند ی  آمار ی  \nاست که رابطه معنادار\nی  نیب  ی متغ\nی رها  وابسته و مستقل پ\nدا ی  م ی.کند  \n  به عنوان\nکی  الگور\nی،تم  ی ک  \nعدد پ\nی\nوسته  را پ\nی یبش ین  یم  کند. به عنوان مثال، ممکن است از\nکی  الگور\nتم ی  رگرس\nون ی  برا ی  \nن یی تع  نمرهِی  \n آزمون دانش\nآموز\nان  \n بسته به تعداد ساعات مطالعه آن\nها در هفته است\nفاده  \n دی کن  . در\nنیا  طی شرا  ساعات مطالعه شده به متغ\nری  مستقل تبد\nیل   م ی\nشود و نمره نها\nیی  \n  آزمون دانشجو\nری متغ وابسته است. م ی\nتوان\nید \n ی خط از بهتر\nنی تناسب را از طر\nقی نقاط داده مختلف ترس\nیم \n دی کن  \nتا پ\nی یبش ی ها ین  مدل را هنگام معرف\nی  ورود\nی  دی جد  نشان ده\nدی . از هم\nی ن  خط م\nی\nتوان برا ی  \nیپ یبش ین  نمرات آزمون بر اساس عملکرد دانش\nآموز د\nگر ی  زین  \n .استفاده کرد \n،به عنوان یک مثال دیگر  \n فرض کن\nید  می\nخواه\nمی  یس ی ستم  داشته باش\nمی  که بتواند ق\nمت ی  کی \nخودرو\nی دست دوم را پ\nیبشی ن ی کند. ورود\nی،ها  ی ها ی ژگ یو \n  خودرو همانند برند، سال، مسافت\nپی\nموده  شده و اطالعات د\nی گر ی  که به اعتقاد ما بر ارزش خودرو تاث\nیر  می\nگذارد  و خروج\nی  یق مت \n  .خودرو است\nای  ناوبر\nی  کی  ربات متحر\nک  (اتوموب\nلی  خودران) را در نظر بگ\nد؛ یری  خروج ی \nیاهی زاو  است که در هر بار فرمان با\nدی  بچرخد تا بدون برخورد به موانع و انحراف از مس\nیر  \nپی\nی شرو  کند و ورود\nها ی  توسط حسگرها\nی  بررو\nی  اتوموب\nلی  همانند دورب\nنی  لم یف\nبردار\nی،  \nGPS\n  \n و\nره یغ  ارائه م\nی\nشوند. \n مزایا و معایب یادگیری بانظارت \nمزایا \n \n▪ ادگ ی یری  با نظارت فرآ\nند ی \n ساده ا\nی است که م\nدی توان ی آن را درک کن\nید. \n▪ \n پس از اتمام\nفرآیند آموزش، لزوم نی ست ی که داده\nیها آموزش\nی را در حافظه خود نگه دار\nید . \n▪ نتی\nجه  آن در مقابل روش\nیری ادگ ی \n بدون\nنظارت از دقت ب\nی شتر ی \n.برخوردار است \n▪ از آن\nجایی داده های برچسب ،دار وجود دارند\nدی توان یم براحتی مدل \n خود را تست و اشکال زدا\nیی دی کن . \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 36 \n \n \n معایب \n \n▪ ادگ ی یری  با نظارت از جنبه\nیها  مختلف محدود است به\nی طور  که نم\nی\nتواند برخ\nی  از وظا\nفی  ده یچیپ   در\nادگ ی یری نی ماش \n .را انجام دهد \n▪ اگر ورود\nی  بده\nمی  که از ه\nچی  کی  از کالس\nیها  داده آموزش\nی  \n نباشد، ممکن است خروج\nی،  یک  \n برچسب\nِکالس  \n.اشتباه باشد  به عنوان مثال، فرض کن\nید   یک  \n طبقه\nبند  تصو\nری  را با داده\nیها  \n گربه  \n و سگ  \n  آموزش\nداده دیا\n. سپس اگر تصو\nیر \n زرافه را بده\nی،د خروج\nی \n ممکن است گربه ای سگ باشد، که درست ن\nست ی. \n▪  ی برا آموزش به زمان محاسبات\nی ز ی ادی  ازین \n .دارد \n▪ جمع\nی آور \n و برچسب\nی گذار داده\nها پرهز\nنه ی و زمان .بر است \n یادگیری بدون نظارت \nیری ادگ ی  \n بدون\nنظارت  در یادگیری ماشین  \n زمان\nی  است که به ه\nچی  وجه دسته\nی بند  ای  برچسب گذار\nی  \nداده .ها وجود ندارد فه ی وظ نیا است که اطالعات گروه\nی بند نشده را بر اساس برخ\nی شباهت  ها\nو تفاوت\nها بدون ه\nیچ  \n  گونه،راهنمایی  \n.مرتب کند  به عبارت د\nی،گر  از ماش\nنی  انتظار م ی رود الگوها\nو ساختار پنهان در داده\nی ها  بدون برچسب را به تنها\nیی  دا یپ  \n کند. به هم\nنی  لی دل  \n است که به آن\n بدون\nنظارت م\nند ی گو ی.  \n  چراکه\nیه چ  راهنمایی  وجود ندارد که به ماش\nنی  اد ی  دهد چه چ\nیزی  \n  درست\nو چه چ\nیزی  نادرست  \n.است  \n  ،در این رویکرد\nماش\nنی  این را  \n ی نم\nداند به دنبال چه چ\nیز ی  \n  است، اما\nم ی\nتواند به\nطور مستقل داده\nها را مرتب کند و الگوها\nی  قانع کننده\nیا  دا یپ  \n.کند \nادگ ی\nیری  \n بدون نظارت، اطالعات مرتب نشده را بر اساس شباهت ها و تفاوت ها\nگروه\nبند\nی  می\nکند، حت\nی \n اگر ه\nیچ \n دسته\nای \n.ارائه نشده باشد \n \nیکی  از و\nژگ ی ی ها ی  مهم  نیا  مدل\nنی ها ا  است  ،\n در حال\nکه ی  \n مدل م\nی\nتواند  \n روش\nی ها \nمختلف\nی  را برا\nی  \n گروه\nبند\nی  یا \n سفارش داده\nی ها  شما پ\nی\nشنهاد  \n،دهد  نیا  \n  به شما\nبستگ\nی  دارد که تحق\nی\nقات  ب ی\nشتر\nی  بررو\nی   نیا  مدل\nها انجام ده\nدی  تا از چ\nزی  یدی مف  \n رونما\nیی دی کن . \n \nادگ ی\nیری  \n بدون\nنظارت  در  تحل\nلی  اکتشاف\nی  \n بس\nار ی  دی مف  است،  چراکه  \n یم  تواند\nبه\nطور خودکار ساختار  ذاتی  در داده\nها را شناسا\nیی  \n  کند. به عنوان مثال، اگر ی ک  \nتحل\nی\nلگر  ی سع   م ی\nکند  مصرف کنندگان را بخش\nبند\nی  کند، روش\nی ها  \n خوشه\nبند ی \n بدون\nنظارت نقطه شروع خوب\nی ی برا  تحل\nیل \n آن  .ها خواهد بود \n37 \n فصل\nدوم: پیش نیازها \n \nخوشه\nبندی \nخوش\nی بند ه  فرآیند  تخصیص  \n  نمونه\nداده\nها به تعداد مع\nی ین  از خوشه\nها است  \n  (شکل2\n-\n1\n)  \n به\nگونه\nای  \n  که نقاط داده متعلق به کی  خوشه دارا\nی  ژگ یو ی ها ی  \n  .مشابه باشند\nبه عبارت ساده،تر  \nخوشه\nها چ\nیزی  نی\nستند  جز گروه\nی بند  نقاط داده به گونه\nیا  که فاصله ب\nنی  نقاط داده درون خوشه ها\n.حداقل باشد  هدف تحل\nلی  خوشه\nیا  (در حالت ا آل ده ی  )\n ی\nافتن  خوشه\nیی ها  \n است که نمونه\nها ی  \n درون هر خوشه کامال شب\nی ه  گر ی کد ی  باشند، در حال\nی  که هر خوشه یا  \n  گر ی کد ی با  \n  کامال متفاوت\n .باشد \n \n شکل2\n-\n1\n. خوشه.بندی \n از آن\nیی جا  که خوشه\nبند\nی  توسط الگور\nتم ی  \n انجام م\nی،شود  نیا  \n احتمال وجود دارد\nکه بتوان\nدی  همبستگ ی ها ی  ناشناخته قبل ی  \n را در داده\nها کشف کن\nی د  \n که م ی تواند  \n  به شما در برخورد با\nکی چالش تجار\nی از د\nی\nدگاه دی جد \n.کمک کند \nکاهش ابعاد \nکاهش ابعاد به فرآ\nند ی  کاهش تعداد و\nها ی ژگ ی  در مجموعه داده\nها اشاره دارد، در حال\nی  \n  که تا آنجا\nکه ممکن است تغ\nیی\nرات  در مجموعه داده اصل\nی  \n  حفظ\nشود\n. فرآ\nند ی  کاهش ابعاد اساسا داده  ها را\nاز فضا\nی  یو ژگ ی ها ی  با ابعاد باال به فضا\nی  ژگ یو ی ها ی  \n با بعد کم\nتر تبد\nلی  م کند ی  ،. به طور همزمان\nمهم است که و\nی ها ی ژگ ی  \n ی معن  دار موجود در داده\nها در طول تبد\nلی  از ب\nین  \n .نروند \nکاهش ا عاد ی  کی  مرحله پ\nی ش\nپردازش  داده است. به ا\nین  \n معنا که قبل از آموزش\n مدل، کاهش ابعاد را انجام م\nمی ده ی. \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 38 \n \n \n مقایسه یادگیری بانظارت با یادگیری بدون نظارت \n فرض کن\nید  می\nخواه\nیم  \n  ی به ک  \n  کودک\nکی  زبان جد\nی،د  به عنوان مثال انگل\nیسی،  آموزش ده\nمی . اگر\nاین  \n  کار را طبق اصل\nادگ ی یری  \n با\nنظارت انجام ده\nی،م  \n به سادگ\nی   یک  \n  فرهنگ لغت با کلمات\nانگل\nیسی  و ترجمه به زبان مادر اش ی  ، به عنوان مثال\nفارسی،  به او م\nمی ده ی  . شروع\nی ادگ ی یر  برا ی  \nکودک نسبتاً آسان خواهد بود و احتماال با به خاطر سپردن ترجمه\nها م\nی\nتواند خ\nیلی  ی سر ع  پ ی شرفت  \nکند. با ا\nنی  حال، او در خواندن و درک متون به زبان انگل یسی  \n  ،مشکل خواهد داشت\nچراکه او  \nفقط ترجمه\nی ها  کلمات  فارسی-انگل\nیسی  و نه ساختار دستور\nی  جمالت انگل\nیسی  \n  ی را اد  \n  گرفته\nاست. \nطبق  \n  اصل\nیری ادگ ی  \n بدون\nنظارت، سنار\nوی  کامالً متفاوت به نظر م ی  .رسد\nبه\nعنوان مثال  \n  پنج\nکتاب انگل\nیسی  را ب\nه کودک تقد\nی م  م می کرد ی  \n  و\nیادگیری را به خودش بدست آورد\n. البته ا\nین  \n  کار\nار ی بس چیپ ی تر ده است!!\n به عنوان مثال، با کمک\"\n داده\nها\"، کودک م ی\nتواند تشخ\nیص \n  دهد که کلمه\n\"من\"  به طو ر  نسبتاً مکرر در متون وجود دارد و در بس\nی ار ی  از موارد در ابتدا\nی  کی  جمله ن\nیز  \n  آمده\nاست و از آن نت\nیریگ جه ی  کند. \nنیا  مثال تفاوت ب\nنی  یری ادگ ی   با\nنظارت و بدون\nنظارت را نشان م ی  .دهد\nیری ادگ ی  با  نظارت در\nی ار ی بس  \n از موارد الگور\nتم ی  ساده ی تر  است  .نی با ا  حال، مدل فقط زم\nنه ی\nیی ها  را م ی آموزد که به\nصراحت در مجموعه داده\nی ها  آموز\nیش  وجود دارند و به عنوان ورود\nی  به مدل داده شده\nاند. برا\nی  \nمثال، کودک\nی  که انگل\nی سی  \n  اد ی را  یگیم،رد  یم  \n  تواند کلمات اف\nرسی  را به خوب\nی  به انگل\nیسی  \n ترجمه\nکند، اما خواندن و درک متون انگل\nیسی  \n  اد ی را  نگرفته است. \nاز  ی سو  ید،گر  ی ادگ ی یر  \n بدون\nنظارت، با کار بس\nار ی  یچیپ ی تر ده  مواجه است، ز\nرا ی  با دی  \n  ساختارها\nرا به\nطور مستقل شناسا\nیی  \n  اد ی و  رد ی بگ\n. در نت\nجه ی  زمان و تالش تمر\nین  نیز  بی\nشتر  است. با ا\nین \nحال، مز\nیت  این  \n است که مدل آموزش\nید،ده  نه ی زم\nیی ها  ی را ن ز  تشخ\nیص  می\nدهد  \n که به صراحت\nآن\nها را فرانگرفته است\n. کودک\nی  که با کمک پنج رمان انگل\nیسی،  زبان انگل\nیسی  \n  را به خود آموزش\nداده است، احتماالً م ی\nتواند متون انگل\nیسی  \n  را بخواند، تک تک کلمات را به\nفارسی  \n  ترجمه کند\n و همچن\nی ن  گرامر انگل\nیسی  \n.را درک کند \n چرا یادگیری بدون نظارت؟ \nیری ادگ ی  بانظارت در به\nنه ی\nی ساز  عملکردِ وظا\nیفی  با مجموعه داده\nها یی  با برچسب\nی ها  \n  ،فراوان\nکارآ\nیی  ار ی بس  ی خوب  از خود نشان م ی\nدهد\n. به عنوان مثال، مجموعه دادهِی  ار ی بس  بزرگ\nی  \n  از\nتصاو\nیری  از اش\nیا  \n را در نظر بگ\nدیری  که هر تصو\nری  برچسب\nگذار\nی  \n شده است. اگر مجموعه داده\nبه ا\nندازه  ی کاف  بزرگ باشد، اگر آن را به اندازه کا\nیف  با استفاده از الگور\nی تم\nی ها  یری ادگ ی  ماش\nین  \n39 \n فصل\nدوم: پیش نیازها \n \nمناسب و با را\nیا انه ی  قدرتمند آموزش ده\nی،م  می\nتوان\nیم  یک  \n  مدل\nطبقه\nبند  تصو\nیِر  \n بر ی مبتن  یری ادگ ی  \nبانظارتِ بس\nار ی  خوب بساز\nیم  .\n \nهمان\nطور که الگور\nتم ی  بانظار\nت  بر رو\nی  داده ها آموزش م یبی،ند  یم\nتواند  \n  عملکرد خود را (از\nقی طر  تابع هز\nنه ی\n) با مقا سه ی  برچسب تصو\nیر  پ ی شبی نی\nشده  خود با برچسب تصو\nری  واقع\nی  \n  که در\nمجموعه داده دار\nی،م  اندازه\nیریگ  کند. الگور\nی،تم  به صورت صر\nحی  ی سع  م کند ی  نیا  تابع هز\nی نه  \n را\nبه حداقل برساند؛ به\nی طور  هک  خطا\nی  آن در تصاو\nیری  که قبال د\nده ی  \n  )نشده است (مجموعه آزمون\n تا حد امکان کم باشد. به هم\nی ن  لی دل  \n است که برچسب\nها بس\nار ی  قدرتمند هستند، آن ها با ارائه\nکی  ار ی مع  خطا به هدا\nتی  الگور\nتم ی  کمک م\nی\nکنند\n. الگور\nتم ی  از مع\nار ی  خطا برا\nی  \n بهبود عملکرد\nخود در طول زمان استفاده م کند ی . بدون چن\nین  \n برچسب\nیی ها،  الگور\nیتم  \n ی نم\nداند  \n که چقدر در\nطبقه\nبندی  درست تصاو\nیر  \n  موفق است\nای  نه\n. با ا\nنی  حال، گاه\nی  اوقات هز\nی نه ی  برچسب\nگذار ی  \nدست\nی  کی  مجموعه داده بس\nار ی  \n.باال است \nعالوه بر ا\nی،ن  به همان اندازه\nای  \n که مدل\nی ها  یری ادگ ی  \n بانظارت قدرتمند هستند، در تعم\nده می ِی \n دانشِ فراتر از موارد برچسب گذار\nی  یا شده  که رو\nی  آن\nها آموزش د اند ده ی  ین،ز  \n محدود هستند. از\nآن\nیی جا  که اکثر داده\nی ها  \n جهان بدون  برچسب هستند، با استفاده از\nیری ادگ ی  \n  ،بانظارت\nتوانا\nیی  \nهوش مصنوع\nی  ی برا  گسترش عملکرد خود به نمونه\nیی ها  \n که قبال د\nده ی  نشده .اند، محدود است\nبه عبارت د\nی،گر  یری ادگ ی  \n  بانظارت در حل مسائل\nهوش مصنوع\nی  محدود  (\nNarrow AI\n)  ی عال  \nاست، اما در حل مسائل از نوع هوش مصنوع\nی  ی قو،  چندان خوب ن\nست ی. \n،در مقابل  ی برا  مسائل\nی  \n  که الگوها ناشناخته هستند ای  به\nطور دائم در حال تغ\nر یی  \n  هستند ی ا  \nمجموعه  داده\nی ها  برچسب گذار\nی\nشده  ی کاف  ی برا  \n آن\nها  ندار\nی،م  یری ادگ ی  \n بدون\nنظارت  \n  واقعا\nم ی\nدرخشد  .یری ادگ ی  یغ\nرنظارت\nی،  به جا\nی  تی هدا  \n شدن توسط برچسب  ها، با\nری ادگ یِی  \n  ِساختار\nزی\nربنا\nیی داده\nیی ها که رو\nی آنها آموزش د\nده ی است، کار م\nکند ی .یری ادگ ی بدون\nنظارت نیا \n کار را\nبا تالش برا\nی بازنما\nیی از داده\nیی ها که رو\nی \n آن آموزش م ند یبی با مجموعه\nای \n  از پارامترها انجام\nم ی\nدهد\n. با انجام ا\nنی   ادگ ی\nیری  بازنما\nیی  (\nrepresentation learning\n)\n  ،یری ادگ ی  \n بدون\nنظارت  \nم ی\nتواند  الگوها\nی  متما\nیزی  را  در مجموعه داده  شناسا\nیی  \n  .کند \n تعریف1.2\n \n یادگیری بازنمایی \nادگ ی یری  بازنما\nیی   یز\nرمجموعه یا    یری ادگ ی از  نی ماش  است که هدف آن بدست آوردن و\nی ژگ یها ی  \n  خوب و\nدی مف  از داده\nها به  طور خودکار، بدون آن که\nکی  مهندس و ی ی ژگ  ری درگ  \n با مساله باشد. در ا\nنی  ی رو،کرد  نی ماش \nداده\nیها  خام را به عنوان ورود\nی  رد یگیم  و به\nطور خودکار بازنما یی\nیها  ورد م  ازین   ی برا  شناسا\nیی  ی ژگ یو   را\nکشف م\nکند ی  و سپس به طور خودکار و\nی ژگ یها ی  دی جد    ادی را  رد یگیم  و آن را اعمال م\nکند ی\n. به عبارت د\nی ،گر  \n  هدف\nادگ ی یری  \n بازنما\nیی   افتن ی  \n یلی تبد  است که داده\nیها  خام را به بازنما\nیی  \n که برا\nی  کی  فه ی وظ  ری ادگ ی ی  \nنی ماش  \n مناسب  تر است (به عنوان مثال\nطبقه\nبندی\n) نگاشت م کند ی\n. از آن جا که ا\nنی  روش م\nی\nتواند    به\n عنوان\nیری ادگ ی و ی ژگ یها ی \n معنادار تفس\nیر \n شود، به آن\nادگ ی یری ی ژگ یو  زین گفته م\nی\nشود . \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 40 \n \n \nدر مثال مجموعه داده تصو\nری  (ا نی  \n بار بدون  ،)برچسب\nیری ادگ ی  \n بدون\nنظارت  \n  ممکن است\nبتواند تصاو\nری را بر اساس شباهت آن ها به\nگر ی کد ی و تفاوت آن\nها با بق\nهی شناسا\nیی و گروه\nبند ی \nکند. به عنوان مثال، تمام تصاو\nیری  \n که شب\nی ه  صندل\nی  \n  هستند باهم و\nهمه  تصاو\nیری  \n که شب\nی ه  \n به گربه\nهستند با هم گروه\nی بند  یم\nشوند  . البته، خود\nیری ادگ ی  بدون نظارت  \n ی نم\nتوان\nد  نیا  گروه  ها را به\nعنوان  \"صندل\nی  \"\n ای  \"گربه\"  برچسب\nگذار\nی  کند.  با  ا\nنی  حال،  اکنون که  تصاو\nیر  \n  مشابه  با  هم\nگروه\nی بند  شده\nاند، انسان وظ\nفه ی  \n برچسب\nگذار\nی  ار ی بس  \n ساده\nی تر  ارد د\n. به\nی جا  برچسب\nگذار ی  \nیلیم ون\nها  تصو\nیر  \n با  دست،  انسان\nها  م\nی\nتوانند  به  صورت  دست\nی  همهِی  گروه\nی ها  \n مجزا  را\n برچسب\nگذار\nی  کنند و ا\nنی  برچسب\nها برا\nی  همه اعضا\nی  \n  هر گروه اعمال\nشوند. \n \nاز  نیا،رو  یری ادگ ی  بدون،نظارت  مسائل حل نشدن\nی  ی قبل  را قابل حل\nتر م\nکند ی  \n  و در\nی ِافتن  \nالگوهاِی  پنهان، هم در داده\nی ها  گذشتهِی  در دسترسِ برا\nی  آموزش و هم در داده\nهاِی  یآ ،نده  ار ی بس  \nچابک\nتر عمل م\nکند ی\n. حت\nی  \n  اگر\nیری ادگ ی  \n بدون\nنظارت  \n  در حل مسائل خاص (مسائل محدود\nهوش مص\nنوع\nی\n) مهارت کم\nی تر  \n  نسبت به\nیری ادگ ی  \n  بانظارت دارد، اما در مقابله با مشکالتِ بازتر\nاز نوع هوش مصنوع\nی  ی قو  \n و تعم\nمی  نیا  دانش بهتر است. مهم  تر  ،از آن\nیری ادگ ی  \n بدون\nنظارت  \nم ی\nتواند  ی ار ی بس  از مشکالت را یجی  \n را که دانشمندان داده هنگام ساخت راه حل\nی ها  ری ادگ ی ی  \nماش\nین  \n  با آن\nمواجه  م ی،شوند  \n.برطرف کند \n مزایا و معایب یادگیری بدون نظارت \nمزایا \n \n▪ می\nتواند آنچه که ذهن انسان نم ی\nتواند تصور کند را بب\nند ی. \n▪ \n بدست\nآوردن داده\nیها بدون برچسب نسبتاً ساده .تر است \n \n معایب \n \n▪ نه ی هز  ی شتر یب  دارد ز\nی را  ممکن است ن\nازی  به مداخله انسان\nی   ی برا  \n درک الگوها و ارتباط آنها با دانش حوزه\n.داشته باشد \n▪ \n  سودمندی و مفید بودن نتایج\nشه ی هم  \n  ،قابل تایید نیست یز را  چیه  \n  برچسب ی ا  اری مع  خروج\nی   ی برا   یی تا د  \nدی مف \n .بودن آن وجود ندارد \n▪ جی نتا اغلب دقت کم\nی تر \n.دارند \n یادگیری تقویتی \nیری ادگ ی  یتی تقو  ر شه ی  در روانشناس\nی  ی ادگ ی یر  یح\nوانات  دارد  \n  و  در مورد\nیری ادگ ی  رفتار به\nنه ی  \n در\nکی طی مح ی برا بدست آوردن حداکثر پاداش است. ا\nنی رفتار به\nنه ی از طر\nقی تعامل با مح\nی ط \n و\n41 \n فصل\nدوم: پیش نیازها \n \n  مشاهدات نحوه\nواکنش آن آموخته م ی\nشود  .\n  ی ادگ ی به\nرنده  (عامل) برا\nی  اقدامات صح حی  ی جا زه  \nداده می\nشود  و برا\nی  \n اعمال اشتباه\nتنبیه در نظر گرفته  \n می\nشود.  \nدر غ\nاب ی  ناظر  ،ی ادگ ی\nرنده  \n  به دنبال\nکی  خط\nی مش  \n موثر برا\nی  \n  حل کی  وظیفهِی  \n تصم\nیمگیر ی  \n است. چن\nنی  خط\nمشی  کته ید  یم\nکند که چگونه عامل با\nید  \n در هر حالت\nی  \n که ممکن است با آن مواجه\n شود رفتار کند تا با آزمون و خطا در تعامل با\nکی طی مح \n ی پو،ا \n کل پاداش مورد انتظار را بیشینه  \n.)کند (یا تنبیه را کمینه کند  \n  از\nآنجا\nیی  که م ی\nتواند اقدامات\nی  را که منجر به موفق\nتی  نها\nیی  \n  کی در  \nطی مح  دیده\nنشده  م ی\nشود  \n  بدون کمک\nناظر  یب،اموزد  یری ادگ ی  \n یتی تقو  کی  الگور\nتم ی  ار ی بس  \n  قدرتمند\n.است \nانتخاب و ارزیابی مدل \nانتخاب مدل در زم\nی نه  یری ادگ ی  ماش\nین  می\nتواند معان\nی  \n متفاوت\nی  داشته باشد  .ممکن است عالقه  مند\nبه انتخاب بهتر\nنی  ابر\nپارامترها  \n ی برا  کی  \n  روش یری ادگ ی  ماش\nنی  باش می  .ابر\nپارامترها،  \n پارامترها\nی  \n  روش\nادگ ی یری  \n هستند که با\nید  \n آن  ها را به صورت ینیشیپ  \n مشخص کن\nی،م   ی عن ی  \n قبل از برازش\nمدل . در مقابل، پارامترها\nی  مدل، پارام\nترها\nیی  هستند که در نت\nجه ی  برازش  یا\nجاد  م ی\nشوند  .\n به\n عنوان مثال، در\nیک \n  مدل\nشبکه عصبی، \n تعداد نورون های الیه پنهان و تعداد\nالیه\nهای پنهان  ی ک  \nابر\nپارامتر است که با\nدی  قبل از برازش مشخص شود، در حال\nی  \n  که وزن\nهای  مدل پارامترها\nی  \n  مدل\n  .هستند\nی\nافتن  ابر پارا\nمترها\nی  مناسب برا\nی  کی  مدل م ی\nتواند برا\nی  کارایی مدل  ار ی بس  \n  مهم\nاست. \n  ،در مواقع دیگر\nممکن است بخواه\nمی  بهتر\nین  \n  روش یری ادگ ی  را از مجموعه روش\nی ها   ی ادگ ی ر ی  \nماش\nین  \n (الگوریتم)ها  واجد شرا\nی ط  \n انتخاب کن\nیم .\n \n تعریف2.2\n \n( انتخاب مدلModel selection\n)\n \nانتخاب مدل تکن\nیکی   ی برا  انتخاب بهتر نی  مدل پس از ارز\nی ابی  تک تک مدل ها بر اساس مع\nی\nارها\nی  مورد ن\nازی \n.است \nقبل از پرداختن رو\nی\nکردها  ی برا  انتخاب مدل  کی  زیچ  گر ید  وجود دارد که با\nید  \n در مورد آن\n بحث کن\nمی  :ارز ی اب ی  مدل   (\nmodel evaluation\n). هدف ارز\nی ی اب  \n مدل تخم\nنی  ی خطا  \n تعم\nیم  \n  مدل\n  ،انتخاب شده است\nی ی عن  نکه یا  مدل انتخاب\nشده تا چه اندازه رو\nی  داده\nی ها  ده ید  \n نشده عمل\nم ی\nکند. بد\nیهی  \n  است که\nیک  \n  مدل یری ادگ ی  ماش\nنی  خوب، مدل\nی  است که نه تنها رو\nی  داده\nیی ها  \n  که\nدر طول آموزش د ده ی  شده  عملکرد خوب\nی  دارد (در غ\nیر  این  \n  ،صورت\nیک  \n  مدل\nادگ ی یری  ماش\nی ن  \nم ی\nتواند  به سادگ\nی  داده\nی ها  آموزش\nی  \n  را به خاطر بسپارد)، بلکه  باید\nی رو  داده\nی ها  ده ید  نشده  ن ی ز \nعملکرد خوب\nی  داشته باشد\n. بنابرا ی،ن  \n  قبل  از\nاستقرار  کی  \n مدل به تول\nی،د  دی با  نسبتاً مطمئن باش\nی م  \nکه عملکرد مدل در مواجهه با داده\nی ها  دی جد  \n کاهش نم\nابد یی . \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 42 \n \n \nاما چرا ما به تما\nزی  نیب  انتخاب مدل  \n  و\nارز ی اب ی  مدل  از ین  م؟ ی دار  \n لی دل  \n  آن بیش\nبرازش  \n  .است\nاگر خطا\nی  \n تعم\nمی  مدل انتخاب\nی  خود را بر رو\nی  همان داده\nیی ها  که برا\nی  \n  انتخاب مدل برنده\n استفاده کرده\nایم  \n)(با فرض اینکه انتخاب مدل براساس مجموعه آموزشی صورت گرفته باشد  \n تخم\nنی  ی بزن،م  کی  \n تخم\nین  \n خوش\nنانه یب  بدست خواه\nیم  \n آورد. چ\nرا؟  \n  !!پاسخ ساده است  مدل\nیری ادگ ی  ماش\nنی  توانسته است  به سادگ\nی  داده\nی ها  آموزش\nی  را به خاطر بسپارد\n. از این  رو ارزیابی\n  کارایی و\nجلوگ\nیری  \n از چن\nین  \n مسائل\nی،  ما به داده\nی ها  \n کامال مستقل برا\nی  \n تخم\nنی  ی خطا  \n تعم\nیم  یک \nمدل ن\nاز ی  می دار. \n استراتژ\nی  پی\nشنهاد\nی  ی برا  انتخاب مدل به مقدار داده\nی ها  موجود بستگ\nی  دارد. اگر داده\nها ی \nی اد یز  در دسترس باشد، ممکن است داده\nها را به چند بخش تقس\nیم  \n می کن  \n  که هر کدام هدف\nخاص\nی  را دنبال م\nی\nکنند\n. به عنوان مثال، برا\nی  تنظ\nی م  ابر،پارامتر  ممکن است داده ها را به سه\nمجموعه تقس\nیم  \n می کن  :آموزش  / اعتبارسنج\nی  / آزما شی\n. مجموعه آموزش\nی  ی برا  \n آموزش مدل\nی ها  \nمختلف به تعداد ترک\nی ها بی  \n  مختلف\nابر\nپارامترها\nی  مدل استفاده م\nی\nشود. سپس ا\nنی  مدل ها بر\nی رو  مجموعه اعتبارسنج\nی  ی اب ی ارز  یم\nشوند  و مدل\nی  که بهتر\nی ن  عملکرد را در ا\nی ن  \n مجموعه\nاعتبارسنج\nی  داشته باش\nد  به عنوان مدل برنده انتخاب م\nی\nشود  .سپس\n، مدل بر رو\nی  داده\nی ها  \nآموزش\nی  \n  به\nهمراه داده\nهای  اعتبارسنج\nی  \n  با استفاده از مجموعه\nابر\nپارامترها\nی  \n انتخاب\nی  بازآموز\nی  \nم ی\nشود  و عملکرد تعم\nمی  با استفاده از مجموعه آزمون برآورد م\nی\nشود\n. اگر ا\nنی  ی خطا  \n تعم\nی م \nمشابه خطا\nی  اعتبارسنج\nی  \n  ،باشد\nبر این  \n  باور\nهستیم که  مدل رو\nی  داده\nی ها  ده ید  \n نشده عملکرد\nی خوب  خواهد د .اشت \nآنچه ما به طور ضمن\nی  در طول بحث باال فرض کرده\nایم  ای ن  \n  است که\nداده  های  ،آموزش\nاعتبارسنج\nی  \n  و آزمون از\nکی  ی توز ع  نمونه\nبردار\nی  شده\nاند. اگر ا\nین\nطور  \n نباشد، همه تخم\nنی  ًها کامال\nاشتباه خواهند بود. به هم\nنی  ی دل ل  ضرور\nی  است که قبل از ساخت مدل اطم\nنان ی  \n  حاصل شود\nکه توز عی داده ها تحت تأث\nری  تقسیم\nبندی داده\nی ها شما قرار نم رد یگی.  \nاما چه م\nی\nشود اگر داده\nی ها  ک،م  تنها چ\nیزی  است که ما دار\nم؟ ی  چگونه انتخاب و ارز\nی اب ی  \n  مدل\nرا در ا\nنی  مورد انجام ده\nم؟ ی  \n  پاسخ این است\nی اب ی ارز  مدل تغ\nر یی  \n کند ی نم  چراکه  \n  ما هنوز به\nی ک \nمجموعه آزما یشی  از ین  می دار  که بر اساس آن بتوان\nیم  \n ی خطا  \n تعم\nمی  مدل نها\nیی  \n انتخاب  شده را\n تخم\nنی  می بزن\n. از ا\nین\nرو، داده  ،ها را به دو مجموعه\nکی  مجموعه آموزش\nی  \n  کی و  مجموعه آزما شی ی  \nتقس\nمی  م ی می کن\n. آنچه در مقا\nسه ی  با روش قبل\nی  ر یی تغ  یم  ،کند\nنحوه استفاده ما از مجموعه آموزش ی  \n.است  یکی از این تکنیک ها اعتبارسنجی متقابل است که در ادامه بخش به آن پرداخته خواهد\n.شد  به\nطور خالصه اما می  ،توان گفت\nاعتبارسنج\nی  \n متقابل تکن\nیکی  است که مجموعه آموزش\nی  \nاصل\nی  را به دو مجموعه داده آموزش\nی  و آزما\nی یش  (اعتبارسنج\nی\n) تقس\nمی  م کند ی. \n \n43 \n فصل\nدوم: پیش نیازها \n \nهنگام  برخورد  با  داده\nی ها  ی سر  زمان\nی  \n  که\nیک  مسئلهِی  یپ ینیبش  \n ،است\nمجموعه\nی ها  آموزش، اعتبارسنج\nی  و آزما شی  دی با  \n با تقس\nمی  داده ها در امتداد\nمحور زمان\nی  \n  .انتخاب شوند ی عن ی  \"می قد نی تر ی\"  \n داده\nها برا\nی  آموزش، جد\nی\nدتر  برا ی  \nاعتبارسنج\nی  و  جد\nی\nنی دتر  داده  برا\nی  آزما\nیش  \n استفاده  م\nی\nشود\n.  نمونه  گ\nیری \nتصادف\nی در ا\nین \n مورد معن\nی \n.ندارد \n تقسیم بندی داده\nها \nهر چند الگوریتم\nهای یادگیری ماشین با\nنظارت ابزار\nهای شگفت  انگیز و قدرتمند در\nپیش\nبینی و دسته\nبندی هستند، اما این سوال به\nوجود می\nآید که این پیش\nبینی  ها تا چه\nاندازه دقیق هستند  \n  و آیا راهی برای سنجش میزان کارایی مدل وجود دارد؟ از آنجایی که\nاین الگوریتم\nها دارای نمونه های برچسب خورده می\nباشند، این پرسش را می  توان با\nتقسیم نمونه.های آموزشی به چندین بخش، پاسخ داد  \nبا تقسیم\nبندی داده\nها ابتدا، آموزش را روی بخشی از د\nاده  ها انجام داده، سپس برای\n  سنجش میزان کارای مدل و قابلیت\nتعمیم\nدهی  آن از داده\nهای آزمایشی استفاده می  .کنیم\n تعمیم\nدهی نشان دهنده میزان عملکرد مدل، در برخورد با داده  هایی است، که تاکنون مدل\nآن\nها را در فرآیند آموزش مشاهده نکرده است. البته در طراحی مدل های ی  ادگیری ماشین\nدر بیشتر اوقات مجموعه داده\nهای مسئله مورد نظر را عالوه بر داده  های آموزشی و\nآزمایشی به بخش دیگری نیز تقسیم می\nکنیم، نحوهِی  این تقسیم\nبندی به  صورت زیر\nمی:باشد \n▪ \n  :مجموعه آموزشی به\nطور معمول بزرگ\nترین در بین این سه دسته داده\nها می  باشد\nو برای یاف\nتن پارامتر\nهای مدل مورد استفاده قرار می  گیرد. مجموعه داده آموزشی\nرابطه اساسی بین داده\nها و برچسب  های آن را به بهترین وجه ممکن توضیح\nمی  .دهد \n▪ \n  :مجموعه آزمایشی\nاندازه\nگیری عملکرد یک مدل را بر  اساس توانایی مدل در\nپیش بینی  داده  هایی که  در  فرآیند  یادگیری نقشی  نداشته  می  سنجند،  مجموعه\nآزمایشی همان داده  های دیده نشده در فرآیند یادگیری هستند. این مجموعه کارایی\nمدل نهایی را می سنجد. اگر مدلی عملکرد خوبی در مجموعه آموزشی داشته\n  باشد و همچنین متناسب با مجموعه آزمون باشد، یعنی برچسب درست را برای\nتعداد زیادی از داد\nه\nهای ورودی نادیده پیش\nبینی کند، حداقل بیش  برازش صورت\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 44 \n \n \n  گرفته است. الزم به ذکر است که مجموعه آزمون معموالً فقط یک بار به محض\n  مشخص  شدن کامل  پارامترها  و  ابرپارامترهای  مدل  برای  ارزیابی  عملکرد\nتعمیم\nدهی مدل استفاده می\nشود. با این حال، برای تقریب عملکرد پیش بینی  یک\nمدل در طول آموزش، از یک مجموعه اعتبار\nسنجی استفاده می.شود \n▪ \n:مجموعه اعتبارسنجی  در ارزیابی انواع مختلف مدل\nها و الگوریتم  ها برای مسئله\nمورد نظر از مجموعه اعتبارسنجی استفاده می\nشود. از این داده  ها برای تنظیم\nابرپارامتر ها و جلوگیری از بیش\nبرازش مدل استفاده \n .تا بهترین مدل انتخاب شود \n \nچیه قانون کل\nی در مورد نحوه تقس می داده .ها وجود ندارد\nبا این حال، \n مجموعه  \nاعتبارسنجی  دی با  به اندازه کاف\nی  \n  بزرگ باشد تا  بتوانیم\nتفاوت عملکرد\nی  \n  را که\n می\nخواه\nمی  بدست آوریم، اندازه\nیریگ می کن. \n \n \nمجموعه  اعتبارسنج\nی  \n ی برا  بدست  آوردن  مقاد\nی ر  ابرپارامترها\nی  \n ی به نه  \n(به\nی نه\nی ساز  \n ابرپارمترها) و کمک به انتخاب مدل استفاده م\nی\nشود  \n  و مجموعه\nآزمون  برا\nی  ی اب ی ارز  عملکرد  مدل  نها\nیی  \n در  نمونه\nی ها  ده ید  شده  در  فرآ\nی ند  \nادگ ی\nیری \n استفاده م\nی\nشود. \n  موازنه\nسوگیری و واریانس (\nBias-Variance Trade-Off\n ) \n  یری ادگ ی در  ماش\nی،ن  رابطهِی  نیب  ی دگ یچیپ  \n  ،مدل\nخطای آموزش و آزمون\n، نت\nجه یِی  دو و\nی ژگ ی  \nرقابت\nی  ی سوگ یر  و وار\nانس ی  \n  .است\nسوگیری  به خطا\nیی  اشاره دارد که هنگام تالش برا\nی  \n  استفاده\n  کی از  مدل ساده برا\nی  \n  کی حل  مشکل پ\nده یچی  یای دن  واقع\nی  \n معرف\nی  م ی\nشود  .به عبارت د\nی،گر  یا ن \nناتوان\nی  یک  \n  مدل\nیری ادگ ی  ماش\nنی ،  در به تصو\nری  دن ی کش  \n رابطه واقع\nی  در داده  ها است. به عنوان\nمثال، اگر بخواه\nی م  از رگرس\nون ی  ی خط  ی برا  \n تخم\nی ن  کی  رابطه غ\nی\nرخط\nی  \n استفاده کن\nی ،م  مدل با\nاس ی  \nباال\nیی  خواهد داشت. ا\nنی  نی به ا  لی دل  \n  است که\nکی  خط مستق\nیم  \n هرگز نم\nی  تواند به اندازه کاف\nی  \n انعطاف\nری پذ  \n  باشد تا\nکی  رابطه غ\nی خط ری  را به تصو\nیر  \n  .بکشد \n،در مقابل  انس ی وار  \n  تفاوت در\nبرازش  (\nfit\n)  نیب  مجموعه\nی ها  داده است. برا\nی  \n مثال، زمان ی  \n  کی که  مدل ب ی ش  برازش\nم ی،کند  انس ی وار  \n باال\nیی  دارد.  چراکه  \n ی خطا  یپ یبش ین  ی برا  \n  مجموعه\nآموزش\nی  و آزما یشی  بس ار ی  \n.متفاوت است \nبه طور کل\nی،  ما دوست دار\nمی  تا حد امکان سوگ\nیری  و وار\nانس ی  \n ی تر کم  داشته باش\nیم\n. با ا\nی ن  \nحال، ا\nنی  ی مع\nارها  \n اثرات متضاد\nی  دارند  \n و نم\nی\nتوان  یری سوگ  را بدون افزا\nشی  وار انس ی  \n  کاهش\n  داد. به منظور\nی\nافتن  تعادل به\nی نه  نیب  یری سوگ  و وار\nی،انس  نی چند  مدل را ارز\nی اب ی  م ی می کن  \n تا\nبهتر\nنی  پارامترها  را برا\nی  مدل پ\nدا ی  \n می کن\n. به عنوان مثال، گاه\nی  \n  اوقات\nیک  \n مجموعه داده را به دو\n45 \n فصل\nدوم: پیش نیازها \n \nبخش تقس\nمی  م ی یم کن\n: مجموعه آموزش\nی  و آزما\nی شی\n. هنگام ارز\nی ی اب  \n  نحوه عملکرد\nیک  \n  مدل ساخته\nشده بر رو\nی  \n مجموعه آموزش\nی،  هم در مجموعه آموزش\nی  و هم در مجموعه آزما\nی شی،  م ی\nخواه\nیم  \nی خطا  یپ یبش ین  تا حد امکان کم باشد. اگر مدل دارا\nی  ی خطا  یپ یبش ین  کم در مجموعه آموزش\nی  \nباشد، اما خطا\nی  یپ یبش ین  باال در مجموعه آزما یشی  داشته باشد، گفته م ی\nشود  که مدل دارا ی  \nانس ی وار  \n باال\nیی  است و در نت\nجه ی  داده  ها\nمنجر به بیش\nبرازش شده است.  \n به طور کل\nی،  \n مدل\nی ها  \nده یچیپ\nتر وار\nانس ی  باالتر\nی  دارند  .نیا  به ا\nنی  لی دل  \n  است که\nکی  مدل پ\nده یچی  م ی\nتواند  داده\nی ها  \nخاص\nی  را که با آن مطابقت دارد را با دقت ب\nی\nی شتر  دنبال کند. با ا\nنی  حال، از آنجا\nیی  \n  کی که  \n  مدل\nده یچیپ  داده\nها را با دقت ب\nی\nی شتر  دنبال م\nی\nکند، به احتمال ز\nاد ی  رابطه واقع\nی  را در داده\nی ها \nآموزش\nی  نشان م د ده ی  و در نت\nجه ی  یری سوگ  \n ی تر کم  دارد. از ا\nی ن رو، انتخاب مدل\nی  با سوگ\nیر ی  \n  نسبتا\nکم\nتر تنها با هز\nنه ی  انس ی وار  باالتر قابل دست\nی اب ی  است. \nاز سو\nی  ید،گر  اگر مدل دارا\nی  ی خطا  یپ یبش ین  باال در هر دو مجموعه آموزش\nی  و آزما شی ی  \nباشد، گفته م ی\nشود  \n که مدل دارا\nی  سوگیری  باال\nیی  است و در نت جه ی  داده\nها را ناد\nده ی  رد یگیم  .\nبه  ،طور خالصه اگر مدل مبتن ی  بر داده\nی ها  آموزش\nی  ار ی بس  ده یچیپ  باشد، خطا\nی  پیشبی نی  \n در\nداده\nی ها  آموزش\nی  کم خواهد بود. به عبارت د\nی،گر  \n  مدل معموال\nمنجر به بیش برازش می\nشود  \n  و در\nنتیجه  به خوب\nی  با داده\nی ها  آزما\nی یش  مطابقت ندارد و باعث خطا\nی  یبشیپ ین  باالتر برا\nی  مجمو عه \nآزما یشی  م ی\nشود  . هدف\nی\nافتن  \n راه\nحل به\nنه ی  است و ا\nنی  کی  موازنه  ب نی  یری سوگ  و وار\nانس ی  \n  .است \nراه\nی ها  مختل یف  ی برا  تنظ\nمی  یری سوگ  و  وار\nانس ی  وجود  دارد.  اکثر  الگور\nتم ی\nها  دارا\nی \nپارامترها\nیی  هستند  که  پ\nچی دگ ی ی  مدل  را  تنظ\nمی  م ی.کنند  نیا  فرآ ند ی  \n\"  اغلب  به  عنوان\nتنظ\nی م  \nابرپارمترها\n\" شناخته م\nی\nشود، که بخش\nی  \n ضرور\nی  از مرحله ارز\nی ی اب  \n.مدل است \nسوگیری  ناتوان\nی  یک  \n  مدل\nادگ ی\nیری  ماش\nنی  ی برا  \n بدست آوردن رابطه واقع\nی  ب ی ن  \nمتغ\nی\nرها\nی  داده است. ا\nنی  امر ناش\nی  از فرض\nات ی  اشتباه\nی  است که درون الگور\nی تم  \nادگ ی\nیری  \n.است  \n  مدل با\nسوگیری  باال توجه بس\nار ی  ی کم  به داده\nی ها  آموزش\nی  \n دارد\nو مدل را ب شی \n از حد ساده م\nی\nکند و هم ی\nشه منجر به خطا\nی باال یی \n  در آموزش و\nداده\nی ها \n آزمون م ی\nشود . \n \n انس ی وار  \n نشان م\nی  دهد که در صورت استفاده از داده ها\nی  آموزش\nی  \n  ،متفاوت\nبرآورد تابع هدف چقدر تغ\nر یی  یم  کند. به عبارت د\nی،گر  وار انس ی   ان یب   م ی\nکند  \n  که\nکی  متغ\nری  تصادف\nی  \n.چقدر با مقدار مورد انتظارش تفاوت دارد  \n مدل با وار\nی انس  \n باال توجه ز\nی اد ی  \n به داده\nی ها  آموزش\nی   م ی\nکند  \n و به داده\nیی ها  که قبال ند\nده ی  \n تعم ی م  \nنم دیایی\n.  در  نت\nی،جه  \n نی چن  مدل\nیی ها  ی رو  داده\nی ها  آموزش\nی  بس\nار ی  \n  خوب  عمل\n یم،کنند اما نرخ خطا\nی باال\nیی  در داده\nی ها آزما\nیشی \n .دارند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 46 \n \n \n روش های ارزیابی \nدر حال\nکه ی  \n  آموزش مدل\nکی  گام کل\nیدی  \n است، نحوه تعم\nی ده می  مدل بررو\nی  داده\nی ها  ده ید  \n نشده\nیا جنبه  به همان اندازه مهم است که با\nدی  پس از طراح\nی  \n  هر مدل\nیری ادگ ی  ماش\nین  \n  در نظر گرفته\nشود. با\nید این \n اطم\nنان ی حاصل شود که آ\nای مدل واقعا کارا است و م ی\nتوان به نتا\nجی پ ی یبش ی ها ین  \n  آن اعتماد کرد\nیا  خیر . \nکی  الگور\nتم ی  طبقه\nی بند  یم\nتواند  بررو\nی  کی  مجموعه داده خاص با مجموعه\nیا  منحصر به \nفرد از پارامترها آموزش داده شود که م\nی\nتواند \n مرز تصم\nیریگمی را متناسب با داده\nی ها ا\nجاد \n .کند\nجه ی نت آن الگور\nتم ی خاص نه تنها به پارامترها\nی ارائه شده برا\nی آموزش مدل بستگ\nی \n دارد، بلکه به  \nنوع داده\nی ها  آموزش\nی  ین ز  بستگ\nی  دارد. اگر داده\nی ها  آموزش\nی  ی حاو  انس ی وار  \n  کم\nای  داده  ها\nی\nکنواخت  باشد، ممکن است مدل منجر به ب\nی ش\nبرازش  گردد و  جی نتا  \n جانبدارانه\nای  \n  را نسبت به\nداده\nی ها  ده ید  نشده  ا\nی\nجاد  کند.  بنابرا\nی،ن  از  رو\nی\nکردها\nیی  همانند  اعتبارسنج\nی  متقابل  برا\nی  \nبه\nحداقل  رساندن ب ی ش\nبرازش  استفاده م ی\nشود\n. اعتبارسنج\nی  \n متقابل تکن\nیکی  \n  است که مجموعه\nآموزش\nی  اصل\nی  را به دو مجموعه داده آموزش\nی  و آزما\nیشی  \n (اعتبارسنج\nی\n) تقس\nمی  م کند ی\nی تر جی . را ن  \nروش اعتبارسنج\nی  متقابل، اعتبارسنج\nی  متقابل چند-\n بخش\nی  است که مجموعه داده اصل\nی  \n را به\nk بخش با ان\nدازه ی\nکسان تقس\nمی  کند یم .\nk یک \n  عدد مشخص شده توسط کاربر است که معموال\n5\n  یا  \n10\n  انتخاب م ی\nشود\n. در ا\nین  \n  روش هر بار\nی یک  از ز ری  مجموعه\nی ها  \nk\n  به  عنوان مجموعه\nاعتبارسنج\nی  (آزمون) مورد استفاده قرار م\nرد یگی  \n  وk-1\n  ریز  مجموعه\nی  گر ید  برا ی  تشک\nیل  یک \nمجموعه آموزش\nی  کنار هم ق\nرار   رند یگیم\n. برا\nی  بدست آوردن کارآ\nیی  \n  کل مدل، برآورد خطا در\n تمام آزما\nی ها ش  به\nطور م\nانگ ی\nنی  محاسبه م ی\nشود. \nدر تکن\nکی  اعتبارسنج\nی  متقابل چند-بخش\nی  \n  کی هر  \n از داده\nها دق\nقا ی  کی  \n  بار در\nی ک  \nمجموعه آزما یشی \n  قرار و\nیک  \n  بار در\nکی مجموعه آموزش\nی  \n قرار م\nرد یگی\nنی . ا \n  امر\nبه\nطور قابل توجه ی  ی با اس  \n و وار\nانس ی  \n را کاهش م ی،دهد  \n چراکه تضم\nنی   م ی کند \n هر نمونه\nیا  از مجموعه داده اصل\nی  این  \n  شانس را\nدارد  \n که در مجموعه آموزش ی  \nو آزما\nشی ی  ظاهر شود. اگر داده ها\nی  ورود\nی  محدود\nی  داشته باش\nی ،م  اعتبارسنج ی  \nمتقابل چند-بخش\nی از بهتر نی \n روش\nها  برا\nی ی ارز ی اب \n کارآ یی کی \n .مدل است \nمعیارهای ارزیابی \n کارآیی  \n  برای محاسبه معیارهای ارزیابی کارآیی یک مدل طبقه\nبندی  \n  نیاز به چهار ترکیب از کالس واقعی\nو کالس پیش بینی با عناوین، مثبت راستین، مثبت کاذب، منفی راستین و منفی کاذب داریم که\n می\nتوان آن\nها را در یک ماتریس درهم\nریختگ\nی  (\nConfusion Matrix\n)  \n  نشان داد (جدول5\n-\n1\n .)\n :جایی که \n47 \n فصل\nدوم: پیش نیازها \n \n• \n (مثبت راستین𝑻𝑷\n:)\n  \n\" به عنوان مثال، وقتی مقدار واقعی کالس\nبله  \" بود، مدل هم \"بله\" را\nپیش\nبینی کرد (یعنی پیش)بینی درست \n• مثبت کاذب(𝑭𝑷)\n  :\n  به عنوان مثال، یعنی زمانی که مقدار واقعی کالس \"نه\" بود، اما مدل\n\"بله \" را\nپیش\nبینی کرد (یعنی پیش )بینی اشتباه \n• منفی کاذب(𝑭𝑵)\n  :\n\" به عنوان مثال، زمانی که مقدار واقعی کالس\nبله  \" بود، اما مدل \"نه\" را\nپیش\nبینی کرد (یعنی پیش )بینی اشتباه \n• منفی راستین(𝑻𝑵)\n  :\n\" به عنوان مثال، یعنی زمانی که مقدار واقعی کالس\nنه  \" بود و مدل هم\n\"نه\n\" را پیش\nبینی کرد (یعنی پیش .)بینی درست \n جدول2\n-\n1\n. ماتریس درهم ریختگی \n کالس پیش\nبینی\nشده \n \n \n منفی \n مثبت \n \n \n منفی کاذب \n(FN)\n \nمثبت راستین \n(TP)\n \n مثبت \n کالس واقعی \nمنفی راستین \n(TN)\n \n منفی کاذب \n(FP)\n \n منفی \nی را نی تر ج  ی مع ار\nی که  از ماتر سی  درهم\nریختگ ی بدست می\nآید  دقت  (\naccuracy\n)  یا  \n  ،معکوس آن\nخطا\nی  پیشبینی (\nprediction error\n)  \n:است \nدقت=\n𝑇𝑃+ 𝑇𝑁\n𝑇𝑃+ 𝐹𝑁+ 𝐹𝑃+ 𝑇𝑁 \nبینی پیش  خطای= 1 −دقت \nدقت، نسبت تعداد پ\nی یبش ی ها ین  درست به تعداد کل نمونه\nی ها  ورود\nی  \n.است \nزمان\nی  که با\nدی  کی  مدل را ارز\nی اب ی  \n ی کن،م  در اغلب اوقات از نرخ خطا و دقت استفاده م\nی ی کن،م \nاما چ\nیزی  که عمدتا رو\nی  آن تمرکز م\nی  \n می کن  نیا  \n است که مدل ما چقدر قابل اعتماد است، چگونه\nی رو  کی  مجموعه داده متفاوت عمل م\nکند ی  (قابل\nیت  \n تعم\nمی ) و چقدر انعطاف\nیری پذ  \n  دارد. بدون\nشک دقت مع\nار ی  ار ی بس  \n مهم\nی  است که با\nید  \n  در نظر گرفته شود، اما هم\nشه ی  تصو\nری  کامل\nی  \n را از\nکارآ\nیی  \n مدل ارائه نم\nی\nدهد. \nی وقت  م م یی گو ی  مدل قابل اعتماد است، منظور ما ا\nنی  است که مدل از داده\nها به\nدرست\nی  \n و مطابق\n  خواسته\nیری ادگ ی  بدست آورده است. بنابرا\nی،ن  یبشیپ ی ها ین  انجام شده توسط آن به مقاد\nری  واقع ی  \nکی نزد  است. در برخ\nی  \n موارد، مدل ممکن است منجر به دقت بهتر\nی  \n شود، اما نم\nی\nتواند  داده\nها \nرا به\nدرست\nی  \n درک کند و بنابرا\nنی  زمان\nی  \n که داده\nها متفاوت هستند، عملکرد ضع\nی یف  دارد. ا\nین  \n  بدان\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 48 \n \n \n ی معن  است که مدل به اندازه کاف\nی  قابل اعتماد و قو\nی  ست ین  و از ا\nین  \n رو استفاده از آن را محدود\nم کند ی. \nبه  \n  عنوان مثال، ما980\n  سیب  \n  و20\n  پرتقال دار\nیم  \n  کی و  مدل دار می  که هر م\nی وه  \n را به عنوان\nکی  بیس  دسته\nی بند  کند یم . از ا\nرو نی  \n  دقت مدل98\n%\n=\n1000\n/\n980\n  است و بر اساس مع\nی ار  \n  دقت، ما کی  مدل بس\nار ی  قی دق  می دار\n. با ا\nنی  حال، اگر ما از ا\nنی  مدل برا\nی  یپ یبش ین  وه یم\nها  \n  در\nنده یآ  استف\nاده  \n ی کن،م  با شکست مواجه خواه\nمی  شد. چرا که ا\nنی  مدل تنها م ی\nتواند  کی  \n  کالس را\nیپ یبش ین  کند. \nافت ی در  تصو یری  کامل از مدل، به عنوان مثال ا\nنکه ی  چگونه داده\nها را درک م کند ی  \n و چگونه\nم ی\nتواند  یبشیپ ین  کند، به درک عم\nقی  ما از مدل کمک م\nکند ی  و به بهبود آن کمک م\nکند ی\n. بنابرا\nی،ن \n فرض کن\nدی  ی مدل  ی را ا\nجاد  \n کرده\nاید  \n  که دقت90\n %  را بدست م\nی ،آورد  از ا\nرو نی  چگونه م\nی\nخواه\nید \nآن را بهبود ببخش\nد؟ ی  ی برا  تصح حی  کی  اشتباه، ابتدا با\nدی  متوجه آن اشتباه شو\nیم\n. به  ،طور مشابه\nی برا  بهبود مدل ما با\nدی  به نحوه ِی  \n عملکرد مدل در سطح عم\nی ی تر ق  \n نگاه کن\nیم\n. با ا\nنی  حال، ا\nی ن  \nکار تنها با نگاه کردن به مع\nار ی  \n دقت بدست نم\nدیآی  و از ا\nرو نی  ی مع\nارها\nی  ی گر ید  زین  \n  در نظر گرفته\nم ی\nشود\n. مع\nی\nارها\nیی  \n  ،همانند\nصحت  (\nprecision\n)    ،فراخوان(یrecall\n)  \n  وF1\n  نمونه\nیی ها  ی از ا ن \nی مع ار\nها  \n.هستند \nفراخوان\nی،  به توانا\nیی  کی  مدل در پ\nیشبی نی  \n  موارد مثبت از کل موارد مثبت\nراستین  \n اشاره\nم کند ی\n. در حال\nکه ی  \n صحت، کسر ی  \n  از موارد مثبت\nراستین  را در ب\nنی  نمونه\nیی ها  \n  که به عنوان مثبت\nیپ یبش ین  شده\nاند، اندازه\nیریگ  کند یم  . صحت و\nفراخوان\nی  به تنها\nیی  ممکن است برا\nی  اب ی ارز ی  \n مدل من\nاسب  نباشد، بنابرا\nنی  از امت\nاز یF1\n  استفاده م ی\nشود  که هم صحت و هم فراخوان\nی  \n  را شامل\nم ی\nشود  و نشان م ی\nدهد  طبقه\nبند چقدر دق\nقی  است. هرچه امت\nاز ی  \nF1\n  بی\nشتر  باشد، کارآ\nیی  \n  مدل ما\n.بهتر است  نحوه یِ محاسبات این معیارها به :صورت زیر است \n \n فراخوانی=\n𝑇𝑃\n𝐹𝑁+ 𝑇𝑃 \nصحت=\n𝑇𝑃\n𝐹𝑃+ 𝑇𝑃 \nF1 = 2 ×\nصحت∗ فراخوانی\nصحت+  فراخوانی \n49 \n فصل\nدوم: پیش نیازها \n \nابزارها و کتابخانه\nهای پایتون \n نصب پایتون \nدر این بخش مراحل نصب پایتون را در سیستم عامل Windows \n معرفی می\nکنیم. از آن جایی که\n  هیچ محیط\nپایتون داخلی در سیستم عامل ویندوز وجود ندارد، باید به .طور مستقل نصب شود\n بسته نصب را می توان از وب سایت رسمی پایتون (www.Python.org) \n  بارگیری کرد. پس از\nباز کردن وب سایت رسمی، نوار ناوبری ر  ا  که دارای دکمه بارگیری  (\ndownload\n)  \n  است جستجو\nکنید.  وب  ،سایت پیوندی را به طور پیش فرض توصیه می  کند، چرا که می تواند سیستم عامل شما\n را شناسایی کرده و آخرین نسخه Python 3.x \n  را توصیه کند. پس از ورود به صفحه بارگیری\nنسخه مربوطه، مقدم ه ای اساسی در مورد محیطی که می خواهید بارگیری کنید وجود دارد. چندین\n نسخه مختلف عمدتا برا\nی سیستم عامل های مختلف طراحی شده  اند. بسته به32\n  \n  یا64\n  \n بیتی\nبودن سیستم، می توانید فایل\nهای مختلفی را برای بارگیری انتخاب کنید.  \n در صفحه جدیدی که\n باز می شود، می\nتوانیم نسخه  های دیگری را نیز پیدا کنیم، از جمله آخرین نسخه آزمایشی و نسخه\nمورد نیاز. اگر می\nخواهی  د نسخه64\n  \n  بیتی3.9.6\n  \n را نصب کنید، روی پیوند ارائه شده در صفحه\n.کنونی کلیک کنید \nپس از بارگ\nیری  ی پا،تون  \n نوبت به نصب آن م ی\nرسد\n. نصب بسته و ی\nندوز  ار ی بس  \n  .آسان است\nدرست مانند نصب سا ری  \n برنامه\nی ها  یو،ندوز  ما فقط با\nدی  نه ی گز  مناسب را انتخاب کرده و رو ی  \nدکمه \"بعد\nی\n\" کل\nیک  \n می کن  تا نصب کامل شود. هنگام\nی  که گز\nنه ی\nها  در هنگام نصب ظاهر م ی،شوند  \nی برا \n رفتن\nبه مرحله بعد\nی \n عجله نکن\nید\n. چرا که برا\nی راحت\nی در آ ی،نده دی با کی \n دکمه را انتخاب\n دی کن . پس از عالمت\nگذار\nی \n\" دکمهAdd Python 3.9.6 to PATH\n \"به متغ\nری طی مح ، م ی توان  \nدر آ\nنده ی  دستورات پا\nتون ی  را مستق\nما ی  و به\nراحت\nی  \n  در خط فرمانWindows\n  \n  اجرا کرد. پس از\n\" انتخابAdd Python 3.9.6 to PATH\n \"، نصب دلخواه را انتخاب کن\nدی  . البته امکان انتخاب\nمکان نصب ن\nزی وجود دارد، که به\nطور پ\nشی فرض در دا\nی\nرکتور\nی کاربر\nی در درا\nیو \nC\n \n  نصب شده\nاست. با ا\nنی  حال، بهتر است بدان\nدی  ی دا\nرکتور\nی  کاربر چ\nست ی  تا بتوان\nدی  در مواقع ضرور\nی \nی فا ی ها ل  \nPython.exe\n  نصب شده را پ\nدا ی  \n دی کن\n. دستورالعمل\nها را ادامه ده\nدی  تا پا\nتون ی  با موفق ی ت  \nدر س\nی\nستم  \n.نصب شود \nشروع کار با پایتون \nراه  اندازی پایتون به دو صورت امکان :پذیر است \n1\n)\n \n  با استفاده ازIDLE\n  \n  .خود پایتون اگر می خواهید پایتون را اجرا کنید، می  توانید روی دکمه\n \" \"شروع\" در دسکتاب ویندوز کلیک و در کادر \"جستجو\" عبارتIDLE\n  \" را تایپ کنید تا\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 50 \n \n \nبه \" طور سریع واردread-evaluate-print-loop\n \" شوید. پس از اجرای  برنامه، با تصویری\nهمانند زیر روبه\nرو می:شوید \n \n \n \nIDLE\n  \n  یک(\nIntegrated Development Environment\n  )\nIDE\n  \n  ساده خود پایتون است که یک\n ویرایشگر رابط گرافیکی را در اختیار کاربران قرار می دهد. عملکرد آن ساده به نظر می  رسد و\n  برای مبتدیان یادگیری زبان پایتون مناسب است. توسطIDLE\n  \n  یک محیطREPL\n  ارائه می  ،شود\nیعنی ورودی کاربر () را می خواند، ارزیابی و محاسبه می  ،)( کند\nسپس نتیجه را چاپ می )( کند\n و یک پیغام \"حلقه\" (منتظر ورودی بعدی) ظاهر می.شود \n2\n)\n \n  با استفاده ازWindows Prompt\n  .\n راه دیگر برای راه اندازی پایتون، اجرای برنامه  های\n \" پایتون از طریق خط فرمان ویندوز است. برای این کار کلیدهایWin+R\n  \" را فشار دهید\n  تا کادر اعالن باز\" ،شود و سپس در کادر باز شدهcmd\n  \" را وارد کنید. اگر در هنگام نصب\n  پایتون\"\nAdd Python 3.x to PATH\n  \"\n را عالمت زده باشید، پایتون نصب  شده به متغیر\n\" محیط ویندوز اضافه شده است. حال با وارد کردن کلمهpython\n\" \" پس از ظاهر شدن>>>\n  \"\n پایتون با موفقیت اجرا می\nشود و با تصو\nیری همانند زیر روبه رو می :شوید \n \n   \n \n  اعالن\"\n>>>\n\"  \n بیانگر این است که نصب با پایتون موفقیت آمیز بوده و پایتون شروع به  کار کرده\n.است \n \n51 \n فصل\nدوم: پیش نیازها \n \n نصب کتابخانه\nها \n برای مدیریت کتابخانه  های پایتون باید ازPip\n  \n  .استفاده کنیدPip\n  \n  یک ابزار ضروری است که به\n شما امکان می  دهد\nبسته\nهای مورد نیاز خود را بارگیری، بروزرسانی و حذف کنید. عالوه براین با\n استفاده از آن می توان وابستگی های مناسب و سازگاری بین نسخه.ها را بررسی کنید \n  نصب یک کتابخانه با استفاده ازPip\n  در خط فرمان ویندوز صورت می  گیرد. برای مثال فرض\nکنید می  خواهیم کتابخانهNumPy\n  \n  را نصب کنیم. مراحل زیر نحوه نصب این کتابخانه را نشان\n می :دهد \n▪ \n\" ابتدا کلیدهایWin+R\n  ،\" را فشار دهید تا کادر اعالن باز شود و سپس در کادر باز شده\n\"\ncmd\n  \" را وارد کنید. سپس دستور زیر را:در خط فرمان وارد کنید \n> pip install numpy \n \n▪ \n :برای اطمینان از نصب کتابخانه، از خط فرمان پایتون را اجرا کرده و دستور زیر را بنویسید \n>>> import numpy \n▪ اگر کتابخانه به\nدرستی نصب شده باشد پیغامی مشاهده نمی  شود. در صورتی کتابخانه در\n  رایانه شما نصب نشده:باشد با اجرای دستور فوق، این پیغام را مشاهده خواهید کرد \nTraceback (most recent call last): \n   File \"<stdin>\", line 1, in <module> \nImportError: No module named numpy \nJupyter  Notebook\n \nJupyter Notebook\n کی  ابزار فوق\nالعاده قدرتمند برا\nی  توسعه و ارائه پروژه\nی ها  یادگیری ماشین  \nبه\nصورت تعامل\nی  است که م ی\nتواند  عالوه  بر اجرا ی  کد، شامل متن، تصو\nی،ر  \n  صدا و\nیا  ویدی و \n  .باشد\nیک  \nNotebook، کد و خروج\nی  آن را با مصورساز\nی،  \nِمتن  روا\nیی،  معادالت ر اض ی\nی  و سا\nی ر  \n رسانه  ها در\nقالب  کی  سند واحد ترک\nبی  م کند ی  . به عبارت\nید،گر  کی  \nNotebook\n  ،یک  \n  سند واحد\nاست که در آن م\nی\nتوان\nید  \n کد را اجرا کن\nی،د  خروج\nی  را نما\nیش  \n دی ده  \n و همچن\nی ن  توض\nی،حات  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 52 \n \n \n فرمول ها، نمودارها را اضافه، تا کار خود را شفاف\nتر، قابل فهم\n، تکرارپذ\nیر  \n و قابل اشتراک\nگذار ی  \n دی کن  .\n \n  برای نصبJupyter Notebook\n  ، الزم است  پایتون را از قبل نصب کرده باشید. حتی اگر\n قصد داشته باشید از جوپیتر برای سایر زبان های برنامه  نویسی استفاده کنید، پایتون ستون اصلی\n.جوپیتر است  \n :برای نصب جوپیتر کافی است در خط فرمان ویندوز دستور زیر را بنویسید \n> pip install jupyter \n  برای اجرایJupyter \n \n:خط فرمان را باز کرده و دستور زیر را در آن بنویسید \n> jupyter notebook \nپس از اجرای دستور فوق، مرورگر وب پیش  فرض شما باJupyter \n  راه اندازی می  شود. هنگام\nراه اندازیJupyter Notebook\n \n  به دایرکتوری خط فرمان توجه فرمایید، چرا که این دایرکتوری به\nفهرست اصلی تبدیل می\nشود که بالفاصله در جوپیتر نوت\nبوک ظاهر می\nشود و تنها به پرونده ها\n و زیردایرکتوری  هایی موجود در آن دسترسی خواهید داشت. با اجرای دستورjupyter notebook\n  \n با صفحه\nای همانند زیر روبه\nرو می :شوید \n \n  با این حال، این صفحه هنوز یکnotebook\n \n  نیست و تنها میزکار جوپیتر است که برای مدیریت\nنوت\nبوک\nهای  جوپیتر  شما  طراحی  شده  است  و  آن  را  به\nعنوان  راه اندازی  برای  پیگردی \n(\nexploring\n)\n  ، ویرایش و ایجادnotebook\n  .های خود در نظر بگیریدnotebook\n  ها و میزکار\nجوپیتر مبتنی بر مرورگر است و جوپیتر یک سرور محلی پایتون راه اندازی می کند تا این برنامه  ها\n .را به مرورگر وب شما ارتباط دهد \n برای ایجاد یکnotebook\n  \n جدید به به دایرکتوری که قصد دارید اولینnotebook\n  \n  خود را در\n  ایجاد\" کنید بروید و بر روی دکمه کشوییNew\n \" که در قسمت باالی میزکار در سمت راست\n\" است کلیک کرده و گزینهPython 3\"را انتخاب کنید : \n \n \n53 \n فصل\nدوم: پیش نیازها \n \nپس از آن، اولین نوت\nبوک شما در یک برگه جدی( دnew tab\n  )\n همانند تصویر زیر باز می\nشود:\n \n \n  اگر به میزکارJupyter \n  \n  بازگردید، فایل جدیدUntitled.ipynb\n  \n  را مشاهده خواهید کرد و باید متن\n سبز رنگی را مشاهده کنید که به شما می\nگوید نوت .بوک شما در حال اجرا است \nدیایب  نحوه اجرا\nی  یک  \n  سلول را با\nکی  مثال کالس\nکی  آزما شی  \n می کن:  \nprint('Hello World!')\n  \n را\n  کی در  سلول تا\nیپ  \n دی کن  \n و بررو\nی  \n  دکمه  در نوار ابزار باال کل\nیک  \n دی کن  ای  دکمه\nها ی \nCtrl+Enter\n را فشار ده\nجه ی . نت دی آن به ا\nین  \n :صورت خواهد بود \n \nColab\n \nColaboratory\n  \n  یا به اختصارColab\n  \n  یک محصول تحقیقاتی گوگل (سرویس ابری) است که\nبه توسعه دهندگان اجازه می  دهد کدهای پایتون را از طریق\n  .مرورگر خود بنویسند و اجرا کنندGoogle Colab\n  \n  یک\nابزار عالی برای کارهای یادگیری عمیق است  \n  و به توسعه\n مدل  ها  با  استفاده  از  چندین  کتابخانه  مانندKeras\n ،\nPytorch\n  ،\nOpenCv\n  ،\nTensorflow\n  و غیره کمک می  .کندColab\n  یک نوت\nبوک مبتنی  بر\nJupyter\n  \n  است که نیازی به نصب ندارد و دارای نسخه رایگان عالی است که دسترسی رایگان\n  به منابع محاسباتیGoogle\n  \n  مانندGPU\n  \n  وTPU\n  را می.دهد \n چراColab\n ؟ \nColab\n  برای همه چیز ایده\nآل است، از بهبود مهارت  های کدنویسی پایتون گرفته تا کار با\n کتابخانه  های  یادگیری  عمیق،  مانندPyTorch\n  ،\nKeras\n  ،\nTensorFlow\n  \n  وOpenCV\n .\n می\nتوانید نوت\nبوک  ها را درColab\n  \n  ،ایجاد، بارگذاری، ذخیره و به اشتراک بگذاریدGoogle \nDrive\n خود را نصب کنید و ا\nز هر چیزی که در آن\nجا ذخیره کرده\nاید استفاده کنید، نوت\nبوک ها\n  را مستقیما ازGitHub\n  \n بارگذاری کنید، فایل  هایKaggle\n  \n را بارگذاری کنید، نوت\nبوک  های\n خود را باگیری کنید و تقریبا هر کار دیگری را که ممکن است بخواهید انجام دهید را انجام\n .دهید \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 54 \n \n \n از دیگر ویژگی  های عالیGoogle Colab، ویژگی همکار( یcollaboration\n)  \n  است. اگر\nبا چند برنامه نویس روی یک پروژه کار می\nکنید، استفاده از نوت  بوکGoogle Colab\n  \n عالی\n  است. درست همانند همکاری در یک سندGoogle Docs، می توانید با استفاده از یک\nنوت  بوکColab\n  با چندین برنامه\nنویس کدنویسی کنید. عالوه بر این، شما همچنین می توانید\nکارهای تکمیل شده خود را با توسعه  .دهندگان دیگر به اشتراک بگذارید \nبه طور خالصه می  توان دالیل مختلف استفاده ازColab\n را به:صورت زیر فهرست کرد \n• \n کتابخانه های از پیش  نصب\nشده \n• ذخیره\nشده در ا\nبر \n• همکاری \n• \n  استفاده ازGPU\n  \n  وTPU\n  رایگان \nبا این حال، دو سناریو وجود دارد که شما باید ازJupyter Notebook \n  \n  در ماشین خود استفاده\nکنید: \n1\n.\n اگر به حریم خصوصی اهمیت می\nدهید و می ،خواهید کد خود را مخفی نگه دارید\nاز Google Colab \n .دوری کنید \n2\n.\n \n اگر یک ماشین فوق العاده قدرتمن  د با دسترسی بهGPU\n  \n  وTPU\n \n.دارید \n راه اندازیGoogle Colab\n  \n \nفرآیند راه  اندازی Colab\n نسبتا آسان است و می تواند با مراحل زیر در هر نوع دستگاهی تکمیل\nشود: \n1\n.\n از صفحه Google Colab \n :دیدن کنید \nhttp://colab.research.google.com \n  بارگذاری تارنمای فوق شما را به صفحه\nخوش\nآمدگویی Google Colaboratory \n هدایت می\nکند \n2\n.\n \n( روی دکمه ورود به سیستمSign in\n:) در باال سمت راست کلیک کنید \n55 \n فصل\nدوم: پیش نیازها \n \n3\n.\n \n با حسابGMail\n \n خود وارد شوید. اگر حسابGMail\n \n :ندارید یکی بسازید \n \n4\n.\n \n  به محض تکمیل فرآیند ورود به سیستم، آماده استفاده ازGoogle Colab\n  \n.هستید \n5\n.\n \n  با کلیک بر رویFile> New notebook\n  \n به\nراحتی می توانید یک نوت  بوک\nColab\n \n.جدید در این صفحه ایجاد کنید \n \nچارچوب های یادگیری عمیق \n  توسعه\nیک  \n شبکه عصب\nی  \n قی عم  و آماده ی ساز  آن برا\nی  حل مشکالت  ،کی  کار بس\nار ی  \n  .دشوار است\n  چرا که نیاز است تاِقطعات  ار ی بس  ی اد یز  ی برا  ایجاد  و تنظ\nیِم  یک  \n ان ی جر  س ی\nستمات\nیک  \nِدر راستای  \nدست\nی اب ی به اهداف ی \n که با یری ادگ ی  \n قی عم \n،قصد داریم بدست آوریم کنار هم قرار گیرند .\n از این رو\nی برا  \n فعالِکردن  راه\nحل\nهاِی  \n آسان\nتر، سر\nی تر ع  \n  تر تیفیک و با  ی برا  آزما ی ها ش   و  تحق\nقات ی  ،\n  محققین\n،و یا دانشمندان داده نیاز به یک چارچوب دارند\nنی . ا چارچوب\nها  به محققان و توسعه  دهندگان\nکمک م\nکند ی  تا به جا\nی  سرما\nی ه\nگذارِی  یبِشتر  \nِوقت  خود بر رو\nی  ات ی عمل\nی ها  \n اساس\nی،  ی رو بر  \nوظا\nیفی  \n  که مهم\nتر  هستند تمرکز کنند. چارچوب ها و پلتفرم\nی ها  یری ادگ ی  \n ی عم،ق  انتزاع\nی  \n منصفانه\nبر رو\nی  وظا\nفی  ده یچیپ  با توابع ساده ارائه م\nی\nکنند  که م\nی\nتوانند  به عنوان ابزار\nی  ی برا  \n حل\n مشکالت بزرگ\nتر توسط محققان و توسعه .دهندگان استفاده شوند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 56 \n \n \n پای\nتورچ  (\nPyTorch\n ) \nPyTorch\n یک محیط کاری یادگیری ماشین مبتنی برTorch\n \n  است\nکه  برای  طراحی  شبکه  عصبی  ایده  .آل  استPyTorch\n  \n توسط\n آزمایشگاه تحقیقاتی هوش مصنوعی فیس  بوک توسعه یافته و در\n  ژانویه2016\n  \n  به عنوان یک کتابخانه رایگان و منبع  باز منتشر شد و عمدتا در بینایی رایانه، یادگیری\nعمیق و برنامه\nهای پردازش زبان طبیعی استفاده می\nشود و از توسعه نرم\nافزار مبتنی بر ابر پشتیبانی\n می\nکند. پیاده  سازی یک شبکه عصبی درPyTorch\n  \n نسبت به سایر محیط\nها ساده  تر و شهودی\nاست  . با پشتیبانی ازCPU\n  \n  وGPU، شبکه\nهای عصبی عمیق پیچیده را می  توان با مجموعه\nداده .های بزرگ آموزش داد \nمزایا و معایب \nمزایا \n \n▪ \n یادگیری آسان \n▪ \n انعطاف پذیر و سریع \n▪  ا شکال زدایی آسان \n \n معایب \n \n▪ \n عدم وجود ابزار مصورسازی \n مانندtensor board\n \nتنسورفلو  (\nTensorFlow\n ) \nTensorFlow\n  یکی  از  محبوب ترین  محیط  های\n  کاری  یادگیری  ماشین  و  یادگیری  عمیق  است که\n توسط توسعه دهندگان و محققان استفاده می .شود\nTensorFlow\n  \n  در ابتدا در سال2007\n  \n توسط تیم\nGoogle Brain\n راه\nاندازی شد و می  تواند بر روی\nCPU\n  \n و  تسریع\nکننده\nهای  تخصصی  هوش  مصنوعی،  از  جمله  \nGPU\n  \n  وTPU\n  \n  .اجرا  شود\nTensorFlow\n  \n  در لینوکس64\n  \n  ،بیتیmacOS، ویندوز و پلتفرم  های محاسباتی موبایل، از\n  جمله اندروید وiOS\n  \n در دسترس است. مدل  های آموزش دیده درTensorFlow\n  را می  توان\n  ،بر  روی  دسکتاپ،  مرورگرها  و  حتی  میکروکنترلرها  مستقر  کرد.  این  پشتیبانی گسترده\n57 \n فصل\nدوم: پیش نیازها \n \nTensorFlow\n  \n را منحصر به فرد و آماده تولید می  ،کند. چه در حال کار با مسائل بینایی رایانه\n پردازش زبان طبیعی یا مدل  ،های سری زمانی باشیدTensorFlow\n  \n  یک پلتفرم یادگیری ماشین\n بالغ و قوی با قابلیت.های زیاد است \nمزایا و معایب \nمزایا \n \n▪ ی پشت ی بان ی عال  از گراف\nهای محاسبات\nی،  \n هم برا\nی \n محاسبات و هم برا\nی مصورسازی \n▪ توان یم \nTensorFlow\n را بر رو\nی دسکتاپ، مرورگرها و حت\nی می\nکروکنترلرها \n.مستقر کرد \n \n معایب \n \n▪  منحن\nی یری ادگ ی  بیش دار به دل\nیل \nAPI\n یها \n سطح پا\nن یی \n)(یادگیری دشوار \n▪ درک برخی امی از پ\nیها \n خطا درTensorFlow\n می\nتواند اری بس \n.دشوار باشد \nکراس  (\nKeras\n ) \nKeras\n  یک رابط برنامه  نویسی است که\nدانشمندان داده را قادر می\nسازد به  راحتی\n به پلتفرم یادگیری\nعمیق \nTensorFlow\n \nدسترسی داشته باشند و از آن استفاده کنند. این یک رابط برنامه( نویسی برنامه کاربردیAPI\n  )\n و  محیط کاری  یادگیری  عمیق  منبع  باز  است که  در  پایتون  نوشته  شده  است که  برروی\nTensorFlow\n  اجرا می  .شود و اکنون در آن پلتفرم ادغام شده استKeras\n  \n قبال از چندین\nپشتگ( اهback end\n)  \n پشتیبانی می  کرد اما با شروع نسخه2.4.0\n  \n  در ژوئن2020\n  به  طور انحصاری\n  باTensorFlow\n  \n  .مرتبط  شده  استKeras\n  به  عنوان  یکAPI\n  \n  سطح  باال،  برای  انجام\n آزمایش\nهای آسان و سریع طراحی شده است که نسبت به سایر گزینه های یادگیری عمیق نیاز به\n کدنویسی کم\nتری دارد. هدف تسریع اجرای مدل\nهای یادگیری ماشین، به ویژه، شبکه های عصبی\nعمیق، از طریق یک فرآیند توسعه با \"سرعت تکرار باال\" است. مدل  هایKeras\n  می توانند بر\n  رویCPU\n  \n  یاGPU\n  اجرا شوند و در چندین پلتفرم از جمله مرورگرهای وب و دستگاه های\n  تلفن همراهAndroid\n  \n  وiOS\n  \n  .مستقر شوندKeras\n  \n  کندتر ازTensorFlow\n  \n  وPyTorch\n \n است اما معماری ساده\nای دارد و خواناتر، مختصرتر، کاربر پسند و قابل  .توسعه استKeras\n \nبیشتر ب\nرای مجموعه داده های کوچک مناسب است و به دلیل طراحی ساده و قابل درک آن برای\n مبتدیان توصیه می.شود \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 58 \n \n \nمزایا و معایب \nمزایا \n \n▪ \nAPI\n سطح بال عال ی \n▪ \n یادگیری آسان \n▪ \n تولید آسان مدل\nها \n▪ \n کاربرپسند \n▪ ی ازین به داشتن پ\nنه یشی ی قو  ی ادگ ی در یر قی عم ست ین. \n \n معایب \n \n▪ برای مجموعه داده ها\nی کوچک مناسب است \n▪ ی گاه \n اوقات درGPU\n \n .کند است \n \nاگر مبتد\nی  \n هست\nید  ی ا  \n مدل\nی ها  ساده\nیا  را برا\nی  \n مسئله امتحان م ی کن ی،د  \nKeras\n  \n بهتر\nنی نه ی گز  ی برا شما است. چراکه شروع با آن کار آسان  تر است، آنقدر آسان\nکه  برا\nی  \n  آموزش\nکی  شبکه  عصب\nی  \n قی عم  ی از ین  به  دانستن  چ\nیزی  \n  در  مورد\nادگ ی\nیری  قی عم  \n ندار\nید  !!\nPyTorch\n  اگرچه از ا\nنی  نظر ن\nیز  ن\nمره  خوب\nی  \n رد یگیم  \n (در\nی مقا\nسه \n با تنسورفلو خالص) اماKeras\n  \n .بهتر است \nخالصه فصل \n▪ داده  ها\nبه قطعات متما زی  \n اطالعات\nی  اطالق م دن شو ی  که معموال  به گونه\nای  \n قالب\nی بند  و ذخ\nره ی \nم ی\nشوند که با هدف خاص\nی \n.مطابقت داشته باشد \n▪ \n  هر نقطه داده اغلب با کی  بردار و ی ژگ ی  نشان داده م\nی،شود  هر ورود\nی  در بردار نشان  دهنده\n کی و ی ژگ ی \n.است \n▪ داده\nها را م\nی توان به عنوان قابل خواندن توسط ماش\nی،ن \n  قابل خواندن توسط انسان ی ا \n  هر دو\nدسته ی بند \n.کرد \n▪  ادگ ی\nیری  \n  بانظارت یکی  از  پرکاربردتر نی  \n شاخه\nی ها   ادگ ی\nیری  ماش\nنی  است که از داده\nها ی \nآموزش\nی \n برچسب\nگذار\nی \n شده برا\nی \n کمک به مدل ها در پ\nینیبشی قی دق استفاده م\nکند ی.\n \n▪ \n در طبقه ی بند  \n کالس\nها ا  ز قبل مشخص هستند و اغلب با عنوان هدف، برچسب ای  \n دسته  \nده ی نام یم\nشوند.\n \n59 \n فصل\nدوم: پیش نیازها \n \n▪ رگرس\nون ی   کی  فرآ ند ی  آمار\nی  است که رابطه معنادار\nی  نیب  متغ ی ی رها  \n وابسته و مستقل پ\nدا ی \nم کند ی \n و به عنوان کی \n الگور ی،تم   کی \n عدد پ\nی\nوسته \n ینیبشی را پ م کند ی .\n \n▪  ادگ ی\nیری  بدون  نظارت  در\nادگ ی\nیری  ماش\nنی  زمان\nی  است که  به  ه\nیچ  \n وجه  دسته\nی بند   ای \n برچسب\nگذار\nی داده.ها وجود ندارد \n آزمونک \n1\n. رویکردهای متفاوت یادگیری ماشین را نام ببرید ، تفاوت  ها، مزایا و معایب هر یک شرح\n دهید؟ \n2\n. منظور از تعمیم\nدهی در یادگیری ماشین چیست؟ \n3\n. تفاوت پارامتر و ابرپارامتر در چیست؟ \n4\n. \n چرا برای\nآموزش یک الگوریتم یادگیری ماشین، داده\nها تقسیم بندی می\nشوند؟ \n5\n. \n  آیا مدلی  که در مجموعه\nی آموزشی به دقت\nی برابر  \n98\n   دست یافته است ولی در مجموعه٪\n داده آزمون دقتی برابر79\n  ، دارد٪\n می\nتواند مدل قابل قبولی باشد یا خیر ؟.دلیل بیاورید \n6\n. \n  فرض کنید مدلی در یک مجموعه\nداده  \n  با دو کالس متفاوت و به شدت نامتوازن دقتی برابر\n99٪\n  بدست آورده است، آیا تنها با براساس معیار دقت می  توان گفت این مدل کارایی بسیار\n باالیی دارد؟ \n.علت را شرح دهید \n7\n. از مجموعه داده اعتبارسنجی به چه دلیل استفاده می شود؟ \n8\n. بیش\nبرازش به چه علت اتفاق می\nافتد؟ \n9\n. وار\nیانس باال و سوگیری باال چه چیزی را نشان می دهد؟ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n3 \n \n▪\n آشنایی با پرسپترون \n▪\n \n آشنایی با شبکه عصبی پیش خور \n▪\n \n بهینه سازها \n▪\n \n توابع زیان \n▪\n \n پیاده سازی شبکه عصبی درkeras\n \n:اهداف یادگیری \nشبکه\nهای عصبی پیش\nخور  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 62 \n \n \n مقدمه \nدر ا\nنی  فصل، به معرف\nی  \n ساختار\nشبکه\nی ها  \n عصب\nی  می\nپرداز\nی،م  نحوهِی  \n  عملکرد\nیک  \n نورون را به\nتفص\nلی  شرح م می ده ی  \n  و  سپس\nفرآیند  آموزش  در  شبکه های عصبی و مفاهیمی که در این زمینه\nوجود دارند را تشریح  خواهیم کرد.  نیا  مفاه\nمی  به عنوان پا\nیاهی  برای فصل  .های بعدی هستند \nشبکه\nهای عصبی مصنوعی (\nArtificial neural networks\n)\n \n شبکه\nی ها  عصب\nی  مصنوع\nی  \n  یا به  طور خالصهANN\n  دسته\nیا  از مدل\nی ها  ی ادگ ی یر  ماش\nین  \n هستند  \nکه به\nطور کل\nی  از مطالعات مربوط به س\nی\nستم  \n عصب\nی  مرکز\nی  \n پستانداران الهام گرفته شده\nاند . به\nعبارت دیگر، آن  کی ها  مدل محاسبات\nی  هستند  \n که نحوهِی  عملکرد سلول\nی ها  \n عصب\nی  \n  در مغز\nانسان را تقل\nدی   م ی.کند  \n  هر شبکه عصب\nی  مصنوع\nی  از چند\nنی  \"نورون  \"مرتبط  تشک\nیل  \n  شده است\n\" که در\nال ی ها ه\n\" سازمانده ی  \n شده اند. نورون\nی ها  هر یک از  یال ه،ها  یپ ام\nها  \n را به نورون\nی ها  یال ه  \nبعد\nی  م ی\nفرستند.   \nشبکه عصب\nی مصنوع\nی \n تالش\nی ی برا ی شب ه\nی ساز شبکه\nای \n از نورون\nیی ها \n  است که\nمغز انسان را تشک\nیل  \n م ی\nدهند  \n  تا\nرایانه  \n  بتواند توانایی  یادگیری بدست آورد  \n  و به\nیا وه یش انسان\nی  \n تصم\nیم \n رد ی بگ . \nیک  \n شبکه عصب\nی  مصنوع\nی  ی دارا  یک الیه ورودی، یک الیه خروجی و یک  ای  چند ال\nیه  \n پنهان  \n می\nباشد  که بهم متصل هستند. ال\nهی  اول از نورون\nی ها  ورود\nی  تشک\nلی  شده است. ا\nین  \n نورون  ها\nداده\nها را به ال\nی ها هی  \n تر قی عم  یم\nفرستند  ،. هر الیه بعد از الیه ورودی\nبه\nی جا  ورود\nی  خام، خروج ی  \n الیه قبلی را به عنوان ورودی دریافت می  ،کند. در نهایت\nآخر\nنی  هیال  خروج\nی  مدل  را تول\nدی  م ی.کند \nنمونه\nی ها  آموزش\nی  به\nطور مستق\nی م  مشخص م ی\nکنند  که برا\nی  هر ورود\nی  \n𝑥\n  چه خروج ی  دی با  \nدی تول  شود. ال\nهی  خروج\nی  ی سع  در محاسبه مقدار\nی  دارد که نزد\nکی  به خروج\nی  مشخص برا\nی  \nنمونه\nی ها  آموزش\nی  \n  .مشابه باشد،با این حال  رفتار ال\nی ها هی  داخلی  مستق\nما ی  تحت تاث\nری  نمونه\nها ی  \nآموزش\nی  ن ی\nستند  \n  و این\nالگور\nی\nتم آموزش\nی  است که  \n با تصم\nی ریگم ی ها ی  خود در جهت تول\nدی  خروج ی  \nمورد\nنظر، چگونگ\nی  \n  عملکرد این\nها هیال  را تع\nن یی  کند یم  .\n  ،در نتیجه\nعملکرد الیه های داخلی\n  براساس خروجی مطلوبی که تحت\nنمونه\nی ها  \n آموزش\nی  بدست آورده است، به  صورت واضح\nمشخص نیست و همانند یک جعبه سیاه عمل می\nکند  ،از این  رو\nبه  این الیه،ها  ال هی  پنهان  \n  گفته\nم ی\nشود. \n63 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nفه ی وظ  \n الیه\nهای  پنهان،  تبد لی  ورود\nی  \n به چ\nیزی  \n  است که\nالیه  خروج\nی  \n م ی  تواند از\n.آن استفاده کند  \n با افزا شی  تعداد ال\nی ی ها ه  \n  پنهان، به سمت\nیک  \n شبکه عم\nی ق  \n می رو یم  که توانا\nیی  حل مسائل پ\nتر ده یچی  \n را نسبت به همتا\nان ی  \n کم عمق خود دارا\n می\nباشد. \nدانشمندان علوم اعصاب شناخت\nی ،  از زمان\nی  \n  که دانشمندان\nرایانه  ی برا  نی اول  \n  بار اقدام به ساخت\n شبکه عصب\nی  مصنوع\nی  هی اول  کردند، اطالعات بس\nار ی  ی اد یز  \n در مورد مغز انسان آموخته  .اند\nیکی  \nاز چ\nی\nزها\nیی  \n که آن\nها آموختند ا\nی ن  \n است که بخش\nی ها  مختلف مغز مسئول پردازش جنبه\nها ی  \n  مختلف\nاطالعات  هستند و ا\nین  \n بخش ها به صورت سلسله مراتب\nی  \n مرتب شده\nاند. بنابرا\nی،ن  ورود ی \nوارد مغز م\nی شود و هر سطح از نورون\nی ها ب نش  را ارائه م\nی  دهد و سپس اطالعات به سطح باالتر\nبعد\nی  منتقل م ی\nشود. ا\nنی  قا ی دق  مکان\nی زم ی  \n  است کهANN\n  ها\nی سع  \n.در تکرار آن دارند \n شبکه\nی ها  عصب\nی  مصنوع\nی  \n به دل\nلی  تطب\nی ری پذ ق  \n بودن قابل توجه هستند، به ا ی ن \nمعن\nی  \n  که با\nادگ ی\nیری  \n  از داده،ها  \n خود را اصالح م ی\nکنند  و  \n در  اجراها\nی  بعد\nی  \n اطالعات\nبی\nشتر\nی کسب \n می\nکنند. \nی برا  نکه یا  شبکه\nی ها  \n عصب\nی  مصنوع\nی  \n  بتواند  توانایی  یادگیری  بدست\nآورند،  دی با  \n  حجم\nی عظ یم  \n  از\nداده\nها  را در اخت\nار ی  \n  داشته باشند که\nمجموعه آموزش\nی  ده ی نام  یم\nشود\n. هنگام\nی  \n  که\nم ی\nخواه\nدی  به شبکه\nها ی  \n عصب\nی  مصنوع\nی  بی\nاموز\nید  \n  که چگونه\nیک  \n  گربه را از سگ\nتشخیص دهد ،\nمجموعه آموزش\nی  هزاران تصو\nری  با برچسب سگ ارائه م\nکند ی  \n  تا شبکه شروع به\nیری ادگ ی  \n  .کند\nهنگام\nی  که با حجم قابل توجه\nی  از داده\nها آموزش داده شد، سع ی  م ی\nکند داده\nی ها  نده یآ  \n  را بر\nاساس آنچه که فکر م ی\nکند م ند یبی  (ای  م ی\nشنود، بسته به مجموعه داده  ها) در دسته\nهای  \n  مختلف\nطبقه\nی بند  کند. در طول دوره آموزش، خروج\nی  نی اش م  با توض ی\nحات  \n ارائه شده توسط انسان  \n (برچسب)ها  \n از آنچه با\nدی  مشاهده شود مقا\nسه ی م ی شود. اگر آن  ها ی\nکسان  \n  ،باشند  مدل به خوبی\nکارآیی خوبی دارد  .  اگر  نادرست  باشد،  از پس\nانتشا(  رbackpropagation\n)  ی برا  تنظ\nی م  \nیری ادگ ی  خود استفاده م\nکند ی. \nپرسپترون  (\nperceptron\n )\n \nنورون  عنصر اساس\nی  \n در هر شبکه عصب\nی  مصنوع\nی  \n.است  \n ساده ترین نوع مدل\nسازی یک ن\nور  ون\n  را\nپرسپترون  گویند که می  .تواند دارای تعداد زیادی ورودی تنها با یک خروجی باشد در شکل\n3-1\n  شما\nیی  \n  .از پرسپترون رسم شده است  پرسپترون از\nری ادگ ی ی  با\nنظارت برا\nی  \n طبقه\nی بند  ای  \nیپ یبش ین  خروج ی  استفاده  م\nی.کند  کی  پرسپترون  تک ال\nهی  با  ترس\nمی  کی  مرز  تصم\nیمگیری  \n(\ndecision boundary\n)  \n  با استفاده از\nکی  خط جداساز،  داده\nها را طبقه\nبندی می.کند \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 64 \n \n \n \n شکل3\n-\n1\n. \n پرسپترون \nد یی ایب  نگاه\nی  به نحوه عملکرد پرسپترون ب\nی\nنداز\nمی.  پرسپترون با گرفتن برخ\nی  ورود\nی ها ی  عدد ی  \n  همراه با آنچه به عنوان\nوزن( هاweights\n)  \n  و\nسوگیری  (\nbias\n)  شناخته م\nی\nشود، کار م\nی  کند. سپس\nنیا  ورود\nها ی  را با وزن\nی ها  مربوط ضرب م\nکند ی  (که به عنوان  مجموع وزن\nی  شناخته م ی\nشود  .)\nسپس ا\nین  \n حاصل\nضرب  همراه با سوگ\nیری  بهم اضافه م ی  .شوند تابع فعال\nی ساز  (\nActivation \nFunction\n  )مجموع وزن\nی  اس ی و با  را به عنوان ورود ی  رد یگیم  و خروج\nی  نها\nیی  را برم\nی.گرداند  \nجیگ  کننده بود!!!!... ب\nد یی ای  \n پرسپترون را تجزیه کنیم، تا نحوه\nیِ کار آن را بهترکنیم.  کی  پرسپترون  \n  (شکل3\n-\n1\n)  از چهار بخش  اصلی  تشک\nیل  \n  :شده است\nمقاد ری  ورود\nی،  وزن\nها و  با اس ی،  \n مجموع\nی وزن  \n  و\nتابع فعال\nی ساز.  \n فرض کن\nدی  کی  نورون و سه ورود\nی  \n𝑥1\n  ،\n𝑥2\n  ،\n𝑥3\n  می دار  که به ترت\nی ب  \nدر وزن\nی ها  \n𝑤1\n  ،\n𝑤2\n ،\n𝑤3\n  ضرب م ی\nشوند: \n \nده یا ساده است، با توجه به مقدار عدد\nی ورود\nی\nها و وزن\nها، تابع\nی  \n در داخل نورون وجود دارد\n  کی که  خروج\nی  دی تول  م ی  .کند حال\nسوال ا نی است که ا نی تابع چ ی\nست؟ این  \n  تابع\nاین\nگونه  \n عمل\n می:کند \n𝑦= 𝑥1𝑤1 + 𝑥2𝑤2 + 𝑥3𝑤3 \nاین \n تابع را\nمجموع وزن\nی م ی نامند، چراکه \n مجموع وزن\nها و ورود\nی .ها است تا این جا همه چیز\nخوب به نظر می\nرسد  ،\n ،با این حال  اگر بخواه\nی م  خروج\nی\nها در محدوده خاص\nی  قرار گ\nی،رند  \n  ًمثال\n65 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n0\n  \n  تا1\n  \n  !چه کاری باید کرد؟ ما م\nی\nتوان\nمی  نیا  کار را با استفاده از چ\nیزی  \n  به نام\nتابع فعال\nی ساز  \nانجام ده\nمی  .ی ک  تابع فعال\nی ساز،  تابع\nی  است که ورود\nی  داده شده (در ا\nین  \n  ،مورد  ورودی مجموع\nی وزن  \n  خواهد بود) را به\nیک  \n خروج\nی  مشخص،  بر اساس مجموعه\nا ی  از قوان\nنی  لی تبد  کند یم: \n \nاکنون تقر\nبا ی  \n همهِی  یچ\nزها\nیی  که برا\nی  ساختن پرسپترون ن\nاز ی  \n  است را\nدر اخت\nار ی  می دار\n. آخر\nی ن \nچیزی  \n  که\nسوگیری  \n  .است،سوگیری  کی  پارامتر اضاف\nی  \n در شبکه عصب\nی  است که برا\nی  تنظ\nی م \nخروج\nی  به همراه مجموع وزن\nی  ورود\nی ها ی  نورون استفاده م ی\nشود\n. عالوه بر ا\nی،ن  \n  مقدار سوگیری  \n  به\nاین  \n  امکان  م را ی  دهد تا تابع  فعال\nی ساز  \n  به راست\nای  چپ تغ\nر یی  \n  .پیدا کند\nکی  راه ساده  تر برا ی  \nدرک سوگ\nیری  از طر\nیق  \n  ثابت𝑐  کی  تابع خط\nی  است: \n𝑦 = 𝑚𝑥 +  𝑐 \nنیا به شما امکان م ی\nدهد خط را به پا\nن یی و باال ببر\nدی ی تا پ یبش ین را با داده ها بهتر تطب\nقی دی ده .\n  اگر ثابت𝑐\n  \n ( وجود نداشته باشد، خط از مبدأ0\n  ،\n0) عبور م\nی  کند و شما تطبیق  ی تر فی ضع  \nخواه\nید  \n  .داشت از این  ،رو\nی سوگ ها یر  اجازه م ی\nدهند  تا تغ\nیی\nرات  ب ی\nشتر  ی و ب\nی شتر  \n از وزن  اد ی ها  \nگرفته شوند. به\nطور خالصه\n، تغ یی\nرات  یب\nشتر  نی به ا  \n ی معن  است که سوگ\nری ی  ها\nبازنمایی  \n تر ی غن ی  \nاز فضا\nی  ورود\nی  را به وزن\nی ها  آموخته شده مدل اضافه م ی.کنند  \n  ،بنابراین\nمعادله نها\nیی  \n  نورون\n  به این صورت محاسبه می:شود \nخروجی = ∑( وزن∗ورودی) +   سوگیری \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 66 \n \n \nهمان طور که پیش\nتر بیان شد، از پرسپترون برای  \n طبقه\nی بند  \n دودویی  استفاده م ی  .شود  بیاید یک\n  پرسپترون ساده  را در نظر\nیری بگ م  \n و با یک مثال ساده نحوه  ی کار آن  را در طبقه بندی دودویی\nداده\nها  \n.بهتر درک کنیم  نی در ا  \n  پرسپترون\nدو  ورود\nی  \n𝑥1\n  \n  و𝑥2\n  می دار  که به ترت\nبی  با وزن ها\nی  \n𝑤1\n  \n و𝑤2\n  ضرب م ی\nشود  \n  و همچن\nین  \n ی دارا  کی  اس یاب  است: \n \nد یی ایب  \n همچن\nنی  کی  نمودار با دو دسته مختلف داده ا\nی\nجاد  \n می کن  \n  که با\nاشکال  دایره  \n  و مستطیل  \n نشان داده شده:اند \n \n فرض کن\nدی  هدف ما ا\nنی  بود که ا\nنی  داده ها را جدا کن\nمی  ی تا ب ن  دایره  \n  و\nمستطیل  زی تما  \n وجود داشته\n  .باشد\nکی  پرسپترون م ی  تواند\nی ک  \n مرز تصم\nمی  ی برا  کی  طبقه\nبند  دودویی  یا\nجاد  کند، جا\nیی  \n  که\n مرز تصم\nمی  مناطق\nی  از فضا رو\nی  کی  نمودار است که نقاط داده\nی ها  مختلف را از هم جدا م\nی .کند \nی برا  درک بهتر ا\nنی  موضوع، ب\nای د یی  \n  کمی\nبا تابع باز\nی  \n ی . م می کن\nتوان\nمی  بگو\nم یی : \n𝑤1  =  0.5 \n𝑤2  =  0.5 \n𝑏 =  0 \n  ،بر این اساس  تابع پرسپترون به :این صورت خواهد بود \n0.5𝑥1 +  0.5𝑥2  =  0 \n67 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n  و نمودار  آن  به :صورت زیر خواهد بود \n \n فرض کن\nید \n تابع فعال ی ساز، در ا نی \n ،مورد\nیک \n  تابع ا پله( یstep function\n) \n ساده است که0  ای  \n1\n  را خروج\nی  می\nدهد  . سپس تابع پرسپترون\nاشکال مستطیل  \n  را1\n  \n  و\nاشکال  دایره  را  با  \n0\n  \n  نشان\nم ی\nدهد\n. به عبارت د\nگر ی : \n{1,\n𝑖𝑓 0.5𝑥1 + 0.5𝑥2  ≥0\n0,\n𝑖𝑓 0.5𝑥1 + 0.5𝑥2 < 0 \nبنابرا\nی،ن  \n  تابع0.5𝑥1 +  0.5𝑥2 = 0\n  یک  \n مرز تصم\nیم  ای\nجاد  م ی  کند که\nاشکال مستطیل  \n و\n  دایره\nرا از هم جدا م\nی.کند   \n  الگوریتم یادگیری پرسپترون \nیادگیری  \n  پرسپترون\nکی  ات ی عمل  نسبتا ساده است. هدف ما بدست آوردن مجموعه\nیا  از وزن\nها ی  \n𝑤\n  است که به طور دق\nی ق  \n  هر نمونه را در مجموعه\nآموزشی  ما طبقه\nی بند  م ی  کند. به منظور آموزش\nپرسپترون، ما به طور مکرر شبکه را با داده\nی ها  آموزش\nی  خود چند\nنی  مرتبه  تغذ\nهی  یم می کن\n. هر با ر \nکه شبکه مجموعه کامل\nی  از  داده ی ها  آموزش\nی  ی را د،د  م یی گو یم  کی  دوره  (\nepoch\n)  \n .گذشته است\n دوره پارامتری است که توسط کاربر، قبل از آموزش تعیین می .شود \nشبه کد الگور\nتم ی  یادگیری  پرسپترون  \n  (الگوریتم1.3\n)  را م ی  توان\nبه صورت خالصه کرد: \n\" ادگ ی\nیری\n\" واقع\nی  \n  در مراحل(\n2\n  ).ب  و(\n2\n).ج  صورت م\nی  رد یگ  .ابتدا بردار و\nی ژگ ی  \n𝑥𝑗\n  \n را از شبکه\nعبور م\nی ده ی ،م  حاصل\nضرب داخلی  با وزن\nی ها  \n𝑤\n  \n  میریگیم را  \n و خروج\nی  \n𝑦𝑗\n  را بدست م\nآور ی\nیم .\nسپس،  نیا  \n  مقدار از تابع\nپله  عبور داده م\nی  شود که اگر𝑥> 0\n  \n  باشد1  و در غ\nی ر  این  \n  صورت0 \n برگردانده می .شود\nاکنون با دی \n بردار وزن خود را بروز کن\nمی تا در جهت\nی قدم بردار\nمی که نزد\nی تر ک  \nبه طبقه\nی بند  درست داده\nها  است. ا\nین  \n  عمل با\nبروز رسان\nی  بردار وزن توسط قانون دلتا  \n  در مرحله\n(\n2\n).ج    تیری مد  م ی.شود \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 68 \n \n \n  عبارت(𝑑𝑗−𝑦𝑗)\n  یی تع ن  یم\nکند که آ\nای  طبقه\nی بند  خروج\nی  \n  درست است\nی ا  نه. اگر طبقه\nبند ی \nدرست  باشد، ا\nنی  اختالف صفر خواهد بود. در غ\nیر  این  \n  صورت، تفاوت\nیا  \n  مثبت\nای  ی منف  \n خواهد\nبود و به ما جهت\nی  می\nدهد که وزن\nی ها  در آن بروز م\nی\nشوند (در نها\nتی  ما را به طبقه\nی بند  درست \nکی زد ن  یم  کند). سپس(𝑑𝑗−𝑦𝑗)\n   \n  را در𝑥𝑗\n  ضرب م\nی می کن  که  ما را به طبقه\nبند ی  درست  ی نزد ک  \nم ی  .کند  مقدار𝛼\n  \n  نرخ ادگ ی\nیری   (\nlearning rate\n )  ما است و م\nی زان  بزرگ\nی  ( ای  کوچک ی  )کی  \n گام  \nرا کنترل م ی  .کند\nار ی بس  مهم است که ا\nنی  مقدار بدرست\nی  تنظ\nمی  شود  .\n  هرچند  مقدار بزرگ𝛼\n  \n  باعث\nم ی\nشود که گام\nی  در جهت درست بردار\nمی ،  ی با ا ن  \n  ،حال\nمی  تواند\nبراحت\nی  \n ما را  از به ی\nنه محل\nی  \n  یا\nسراسری  \n  عبور.دهد  درمقابل ، مقدار کم\nی  \n𝛼\n  \n به ما اجازه م ی\nدهد  \n گام\nی ها  \n  کوچک را در جهت\nدرست بردار\nیم  \n و تضم\nنی  کند یم  \n  که از\nبهینه  محل\nی  یا سراسری  \n تجاوز نم\nی می کن\n. با ا\nنی  حال، ا\nی ن \n گام\nی ها  کوچک ممکن است زمان ز\nی اد ی  \n  طول بکشد تا\nیری ادگ ی  \n .ما همگرا شود  در نها\nی،ت  \n بردار\nوزن قبل\nی  \n  را در زمان𝑡\n  ،\n𝑤𝑗(𝑡)\n  اضافه م ی می کن  که فرآ\nند ی  گام برداشتن به سمت طبقه\nی بند  \n درست \nرا کامل م ی\nکند. اگر ا\nنی  روش آموزش\nی  \n را کم\nی  جیگ  کننده م یبی ین،د  نگران نباش\nید. \nند ی فرآ  یادگیری  \n پرسپترون تا زمان ی  که تمام نمونه\nی ها  آموزش\nی  بدرست\nی  طبقه\nی بند  \n  شوند\nیا  \n  به\nتعداد از پ\nشی  یی تع ن\nشده  \n  )(توسط کاربر دوره\nها برسد، اجازه داده م ی\nشود  تا  \n  ادامه\nابد ی  . اگر𝛼\n  \n  به\nاندازه کاف\nی  کوچک باشد و داده ی ها  آموزش\nی  به صورت خط\nی  قابل تفک\nیک  \n باشند، خاتمه تضم\nی ن \nم ی.شود  به عبارت دیگر، با داشتن فرضیات مناسب می  توان نشان داد یادگیری در پرسپترون با\nتکرار الگوریتم آن، به وزن های درست همگرا خواهد شد. یعنی یادگیری شبکه منجر به تخمین\nوزن هایی خواهد شد که شبکه را قادر می\nسازد تا مقادیر درست را در خروجی  \n.تولید کند \n الگوریتم1.3\n \n الگوریتم یادگیری پرسپترون \n1\n.\n بردار وزن  \n𝑤\n  خود را با مقاد\nری  تصادف\nی  کوچک مقدارده\nی  هی اول  \n دی کن. \n2\n.\n \n:تا زمانی که پرسپترون همگرا شود \nأ.\n یک  حلقه  بر\nی رو  هر  بردار  و\nی ژگ ی  \n𝑥𝑗\n  و  برچسب کالس  واقع\nی  \n𝑑𝑗\n  \n  در\nمجموعه آموزش\nی  دی بزن. \nب. \n𝑥 را بگ\nدیری و آن را از طر\nیق \n شبکه عبور ده\nدی و مقدار خروج ی \n  را محاسبه\n دی کن  :\n \n𝑦𝑗= 𝑓(𝑤(𝑡). 𝑥𝑗) \nج.\n \n وزن\nی ها  \n𝑤\n  را به\nروزرسان\nی  \n دی کن: \n𝑤: 𝑤𝑖(𝑡 + 1) = 𝑤𝑖(𝑡) + 𝛼(𝑑𝑗 −𝑦𝑗)𝑥𝑗,𝑖 \nحال پرسش اینجاست،  \n اگر داده\nی ها  ما به صورت خط\nی  قابل تفک\nیک  \n  نباشند\nای  انتخاب ضع فی ی  \n در𝛼\n داشته باش\nی،م چه اتفاق\nی  م ی\nافتد؟ آ\nای آموزش \n به صورت\nب نها ی تی \n  ادامه خواهد داشت؟ در\nنیا  مورد، خ\nیر.  \n  معموال  ما بعد از ا\nنکه ی  تعداد دوره\nی ها  ی مع ین  انجام شد، متوقف م می شو ی  ای  \n  اگر\n69 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nتعداد طبقه ی ها ید بن  اشتباه در تعداد ز\nی اد ی  از دوره\nها تغ\nر یی  نکرده باشد (که نشان م ی\nدهد  داده ها\nبه صورت خط\nی  قابل تفک\nیک  نی\nستند.)\n \nپیاده سازی\nپرسپترون  در پایتون   \nاکنون که الگور\nتم ی  پرسپترون را مطالعه کرد\nی،م  د یی ایب  الگور\nتم ی  آن  را در پا\nتون ی  یپ اده\nی ساز  \n می کن  \n(این پیاده سازی تنها برای این است که با عملکرد پرسپترون و روند آموزشی که در کتابخانه  ها\nوجود دارد آشنایی پیدا کنید. از این  رو اگر این موارد برای شما\nکمی مشکل به نظر می  ،رسد نگران\nنباشید،  چراکه  در ادامه تنها از کتابخانه  ها و چارچوب  ها استفاده می\nشود و نیاز  ی به کد زدن این\n)موارد نیست.  در ابتدا  کد ز\nیر  \n را وارد کن\nید: \n# import the necessary packages \nimport numpy as np \n \nclass Perceptron: \n  def __init__(self, N, alpha=0.1): \n    # initialize the weight matrix and store the learning rate \n    self.W = np.random.randn(N + 1) / np.sqrt(N) \n    self.alpha = alpha \n  خط5\n  \n  سازنده کالسPerceptron\n  ما را تعر فی  م ی  کند، که\nکی  پارامتر مورد ن\nی از  \n  و سپس ی ک  \nپارامتر اخت\nی ار ی  را م\nی  رد ی پذ : \n▪ \nN\n: تعداد  \n ستون  .ها در بردارهای ویژگی ورودی ما است \n▪ \nalpha\n  :\n  نرخ یری ادگ ی  ما برا\nی  الگور\nتم ی  پرسپترون  است\nنی . ا  مقدار را به\nطور پ\nشی  فرض\nی رو بر  \n0.1\n \n قرار م می ده ی . \n  در  خط7\n  ماتر\nیس  \n  وزن𝑊\n  با مقاد\nری  تصادف\nی  از توز\nی ع  نرمال  (گاوس\nی\n) با م\nانگ ی\nین  \n صفر و\nانس ی وار واحد نمونه\nبردار ی شده است. ماتر\nسی وزن دارا\nی \nN +1\n  ورود\nی است، کی ی ی برا \n هر\nیک  \n  ازN\n  ورود ی  در بردار و ی ژگ ی،  \n  به عالوه\nکی  ورود\nی  برا ی  سوگیری  .\nW\n  را بر ر\nشه ی  \n مربع تعداد\nورود\nها ی  تقس\nمی   م ی ی کن،م  \n کی تکن  یجی را  \n که برا\nی  مق ی اس\nی بند  \n ماتر سی  وزن که منجر به همگرا\nیی  \nی سر تر ع  یم\nشود. \nسپس\nد یی ای ، ب  \n  تابع\nپله  را تعر فی  \n می کن : \n  def step(self, x): \n    return 1 if x > 0 else 0 \nی برا  \n آموزش پرسپترون، تابع\nی  به نام fit \n فی تعر  م ی می کن.  اگر  تجربه قبل\nی  \n  یری ادگ ی با  ماش\nین  \n و\n  کتابخانهscikit-learn\n  داشته باشید،  دی دان یم  که نام\nگذار\nی  این  \n  تابع\nبرای آموزش با این نام \n:معمول است \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 70 \n \n \n  def fit(self, X, y, epochs=10): \n    X = np.c_[X, np.ones((X.shape[0]))] \n \nمتد  \nfit\n  \n  به دو پارامتر  الزامی  و به دنبال آن\nکی  پارامتر اخت\nی ار ی  از ین  دارد:  مقدار X داده\nها ی  \nآموزش\nی  \n  و ما  ی متغ ر y \n برچسب ی ها  کالس خروج\nی  \n  هدف ما\nهستند  (ی ی عن  آنچه شبکه ما با دی  \nیپ یبش ین  کند). در نها\nی،ت  \n پارامتر دوره را داریم که  تعداد دوره\nیی ها  که Perceptron \n  آموزش\n  خواهد\nیافت.  خط  \n،آخر کد  \n یری سوگ  را با درج ستون\nی  \n  ی از ک\nها در داده\nی ها  آموزش\nی  \n  اعمال\nم کند ی  که به ما امکان م\nی\nدهد با\nاس ی  \n  را به عنوان\nی ک  پارامتر قابل آموزش مستق\nما ی  \n  در داخل\nماتر سی  وزن در نظر بگ\nمیری.  حال\nد یی ای ، ب  روند آموزش واقع\nی  \n را مرور کن\nیم : \n    # loop over the desired number of epochs \n    for epoch in np.arange(0, epochs): \n      # loop over each individual data point \n      for (x, target) in zip(X, y): \n        # take the dot product between the input features \n        # and the weight matrix, then pass this value \n        # through the step function to obtain the prediction \n        p = self.step(np.dot(x, self.W)) \n        # only perform a weight update if our prediction \n        # does not match the target \n        if p != target: \n          # determine the error \n          error = p - target \n          # update the weight matrix \n          self.W += -self.alpha * error * x \n \n \nدر ابتدا از یک حلقه استفاده می کنیم و آن را به  \n  تعداد دوره\nاجرا می\nکنیم\n. برا\nی  \n هر دوره، همچن\nی ن \nبر رو\nی  \n  هر نقطه داده جداگانه𝑥\n  و برچسب کالس هدف خروج ی  \n  از حلقه استفاده می\nکنیم. \n  ،سپس حاصل  ضرب\nداخلی  یب ن  ی ها ی ژگ یو  ورود\nی  \n𝑥\n  و ماتر سی  \n  وزن𝑊\n  \n گرفته می  شود تا\nخروج\nی  \n  را از تابع\nپله  \n  عبور\nدهد  و  یپ یبش ین  توسط پرسپترون بدست آ\nدی.  تنها  \n در صورت ی  \nبروزرسان\nی  \n وزن را انجام م ی ده ی م  که پ\nی یبش ین  ما با هدف مطابقت نداشته باشد  .اگر ا\nی ن\nطور  \n  باشد، خطا را با محاسبه عالمت (مثبت\nای  ی منف\n) تع\nن یی  م ی می کن.  \nبروز رسان ی  ماتر\nی س  \n  وزن در خط\nآخر کد  انجام م ی\nشود، جا یی  \n  که ما\nیک  \n  گام به سمت\nطبقه\nی بند حی صح \n .برمیداریم\nدر ط\nی کی تعداد از دوره\nها، پرسپترون ما قادر است الگوها\nیی \n  را\nدر داده\nی ها  یز\nربنا\nیی  یب\nاموزد  و مقاد\nری  ماتر\nسی  ن وز  را طور\nی  ر یی تغ  دهد که نمونه\nها ی  ورود ی \nخود را بدرست\nی  طبقه\nی بند  \n می کن . \nآخر\nنی  تابع\nی  که با\nدی  فی تعر  \n ی کن،م  \npredict\n  است  و  همانطور که از نام آن پ\nی،داست  ی برا \nیپ یبش ین  برچسب\nی ها  کالس برا\nی  مجموعه داده\nی ها  ورود\nی استفاده م\nی\nشود: \n  def predict(self, X, addBias=True): \n    X = np.atleast_2d(X) \n    if addBias: \n71 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n      X = np.c_[X, np.ones((X.shape[0]))] \n    return self.step(np.dot(X, self.W)) \n \nمتد  \npredict\n  ما به مجموعه\nیا  از داده\nی ها  ورود ی  \nX\n  از ین  دارد که با دی  طبقه\nی بند  \n  .شوند همچنین\nکی  بررس\nی  \n  در  کد\nانجام م ی شود تا بب\nند ی  ایآ  کی  ستون با\nاس ی   دی با  \n  اضافه شود\nیا  خیر  .\n \n  اکنون کهPerceptron\n  خود را  پ\nاده ی ی ساز  کرده\nیا،م  د یی ایب  ی سع  \n می کن  \n آن را در مجموعه\nداده\nی ها  یتیب  (\nAND\n  ،\nOR\n \n وXOR\n  )\n اعمال کن\nیم \n ی و بب ین م  که چگونه کار م ی.کند \n  ابتدا در مجموعه دادهOR\n  \n آن را آزمایش می :کنیم. برای این کار کد زیر را وارد کنید \n# construct the OR dataset \nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) \ny = np.array([[0], [1], [1], [1]]) \n# define our perceptron and train it \nprint(\"[INFO] training perceptron...\") \np = Perceptron(X.shape[1], alpha=0.1) \np.fit(X, y, epochs=20) \n \n  در خطوط2\n  \n  و3\n  \n  مجموعه دادهOR\n  \n را تعریف می  .کنیم  خطوط6\n  \n  و7\n  \n  پرسپترون ما را با نرخ\nیری ادگ ی  \n𝛼 = 0.1\n  در  \n20\n  دوره آموزش م\nی .دهند \nبعد از آموزش  \nPerceptron\n  \n خود\n، باید آن  را رو\nی  \n داده\nها ارز\nی اب ی \n می کن  د یی ا تا ت  \n می کن  \n  که در واقع\n  تابعOR\n  \n  اد ی را  \n:گرفته است \n# now that our perceptron is trained we can evaluate it \nprint(\"[INFO] testing perceptron...\") \n# now that our network is trained, loop over the data points \nfor (x, target) in zip(X, y): \n  # make a prediction on the data point and display the result \n  pred = p.predict(x) \n  print(\"[INFO] data={}, ground-truth={}, pred={}\".format( \n    x, target[0], pred)) \n \n کد نهایی به :صورت زیر است \nimport numpy as np \nclass Perceptron: \n  def __init__(self, N, alpha=0.1): \n    self.W = np.random.randn(N + 1) / np.sqrt(N) \n    self.alpha = alpha \n \n  def step(self, x): \n    return 1 if x > 0 else 0 \n \n  def fit(self, X, y, epochs=10): \n    X = np.c_[X, np.ones((X.shape[0]))] \n    for epoch in np.arange(0, epochs): \n      for (x, target) in zip(X, y): \n        p = self.step(np.dot(x, self.W)) \n        if p != target: \n          error = p - target \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 72 \n \n \n          self.W += -self.alpha * error * x \n  def predict(self, X, addBias=True): \n    X = np.atleast_2d(X) \n    if addBias: \n      X = np.c_[X, np.ones((X.shape[0]))] \n    return self.step(np.dot(X, self.W)) \n \nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) \ny = np.array([[0], [1], [1], [1]]) \n# define our perceptron and train it \nprint(\"[INFO] training perceptron...\") \np = Perceptron(X.shape[1], alpha=0.1) \np.fit(X, y, epochs=20) \n \nprint(\"[INFO] testing perceptron...\") \n \nfor (x, target) in zip(X, y): \n  pred = p.predict(x) \n  print(\"[INFO] data={}, ground-truth={}, pred={}\".format( \n    x, target[0], pred)) \n \n \n  ،بعد از اجرای کد باال خروجی به صورت زیر نمایش داده می:شود \n[INFO] training perceptron... \n[INFO] testing perceptron... \n[INFO] data=[0 0], ground-truth=0, pred=0 \n[INFO] data=[0 1], ground-truth=1, pred=1 \n[INFO] data=[1 0], ground-truth=1, pred=1 \n[INFO] data=[1 1], ground-truth=1, pred=1 \n \nهمان طور که مشاهده می  شود، پرسپترون ما توانست عملیاتOR\n  \n.را یاد بگیرد  عملگر  \nOR\n  برا ی \n𝑥0 =  0\n  \n و𝑥1 =  0\n  \n  صفر است\nو  همه ترک\nبات ی  گر ید  کی  \n.هستند \nحاال ب\nد یی ای  \n  به  سراغ  تابعAND\n  می برو  ،کد ز\nیر  \n را وارد کن\nید : \nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) \ny = np.array([[0], [0], [0], [1]]) \n# define our perceptron and train it \nprint(\"[INFO] training perceptron...\") \np = Perceptron(X.shape[1], alpha=0.1) \np.fit(X, y, epochs=20) \n# now that our perceptron is trained we can evaluate it \nprint(\"[INFO] testing perceptron...\") \n# now that our network is trained, loop over the data points \nfor (x, target) in zip(X, y): \n  # make a prediction on the data point and display the result \n  # to our console \n  pred = p.predict(x) \n  print(\"[INFO] data={}, ground-truth={}, pred={}\".format( \n    x, target[0], pred)) \n \n  توجه کنید که\nدر ا\nی\nنجا  تنها خطوط کد\nی  که تغ\nر یی  \n کرده  اند، خطوط1\n  \n  و2\n  \n هستند که در آن\n مجموعه دادهAND\n  را به جا\nی  \n  مجموعه دادهOR\n  فی تعر  کرده.ایم   \n73 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nبعد از اجرا\nی  \n  کد\nپیشین\n، خروج\nی  به صورت ز\nری  شی نما  داده م\nی\nشود: \n[INFO] training perceptron... \n[INFO] testing perceptron... \n[INFO] data=[0 0], ground-truth=0, pred=0 \n[INFO] data=[0 1], ground-truth=0, pred=0 \n[INFO] data=[1 0], ground-truth=0, pred=0 \n[INFO] data=[1 1], ground-truth=1, pred=1 \n \n  مشاهده شد که  دوبارهPerceptron\n  ما توانست بدرست\nی  \n تابع  \nAND\n  \n.را مدل کند  عملگر  \nAND\n \nفقط زمان\nی  درست است که  هم  \n𝑥0 =  1\n  \n  و𝑥1 =  1\n  باشد و  ی برا  همه ترک\nی ی ها ب  گر ید  \nAND\n \n .صفر است \nدر نها\nی،ت  اجازه دهید تا  نگاه\nی  به تابع غ\nی\nرخط\nی  \nXOR\n  \n  با پرسپترون\nبی\nنداز\nمی  . کد زیر را وارد\n:کنید \nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) \ny = np.array([[0], [1], [1], [0]]) \n# define our perceptron and train it \nprint(\"[INFO] training perceptron...\") \np = Perceptron(X.shape[1], alpha=0.1) \np.fit(X, y, epochs=20) \n# now that our perceptron is trained we can evaluate it \nprint(\"[INFO] testing perceptron...\") \n# now that our network is trained, loop over the data points \nfor (x, target) in zip(X, y): \n  # make a prediction on the data point and display the result \n  pred = p.predict(x) \n  print(\"[INFO] data={}, ground-truth={}, pred={}\".format( \n    x, target[0], pred)) \n \n:با اجرای کد باال خروجی به صورت بدست آمد \n[INFO] training perceptron... \n[INFO] testing perceptron... \n[INFO] data=[0 0], ground-truth=0, pred=1 \n[INFO] data=[0 1], ground-truth=1, pred=1 \n[INFO] data=[1 0], ground-truth=1, pred=0 \n[INFO] data=[1 1], ground-truth=0, pred=0 \n \n  بیاید دوباره کد باال را اجرا کنیم. خروجی این بار به صورت زیر بدست :آمد \n[INFO] training perceptron... \n[INFO] testing perceptron... \n[INFO] data=[0 0], ground-truth=0, pred=0 \n[INFO] data=[0 1], ground-truth=1, pred=0 \n[INFO] data=[1 0], ground-truth=1, pred=0 \n[INFO] data=[1 1], ground-truth=0, pred=1 \n \nمهم ن\nست ی  \n چند بار ا\nنی  آزما\nیش  \n را با نرخ\nی ها  یری ادگ ی  \n  متفاوت\nای  روش\nهای  \n مقداردهی اولیه  \n متفاوت اجرا کن\nی،د  \n  چرا که هرگز نم\nی\nتوان\nید  \n  تابعXOR\n را با پرسپترون تک ال\nیه  \n مدل\nی ساز  \n دی کن. \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 74 \n \n \nدر عوض، آنچه ما ن\nاز ی  می دار\n، تعداد  ی ها هیال  یب\nشتر  با توابع فعال ی ساز  یغ\nرخط\nی  است. \nپرسپترون تنها  کی  \n طبقه\nبند خط\nی  است و هرگز نم ی\nتواند داده\nیی ها  \n  را که به\nصورت خط ی  قابل تفک\nیک  ن ی\nستند  \n را از یکدگیر  \n.جدا کند  \n  ،همچنین نیا  \n الگور\nی تم  \nفقط برا\nی \n مسائل طبقه\nبند ی دودیی \n استفاده م\nی.شود \n پرسپترون چند الیه (شبکه عصبی پیش)خور \nهمان\nطور که بیان شد، محدودیت  اصلی شبکه\nهای  عصبی  \n  پرسپترون، عدم  توانایی در طبقه  بندی\nداده\nها\nیی است که  \n جدایی  پذیر خطی  .نیستند استفاده از یک الیه پنهان در ساختار شبکه  ها\n گریزی است بر این محدودیت  ،. به عبارت دیگر  در\nراستای  حل این محدودیت،  می  توان از\nالیه پنهان بین الیه ورودی و خروجی استفاد\nه کرد. نمونه\nای از این شبکه  ها که اساس یادگیری\n  عمیق نیز  می\nباشد\n، شبکه  های پرسپترون چند\nالیه  (\nmultilayer perceptron\n  )\n  یا به اختصار\nMLP\n  هستند  که هم\nچنین از آن  ها با عنوان شبکه  های  عصبی\nپیش\nخور  (\nfeed forward \nneural network\n)  \n نام برده می.شود  این شبکه  ها از\nپرکابردترین\nها شبکه ها در یادگیری عمیق\n  به دلیل سازگاری آن با انواع مسائل\nهستند . چرا که برای ورودی آن هیچ محدودیتی وجود ندارد\nکه داده .ها تصویر، متن و یا ویدیو باشد \n \n شکل3\n-\n2\n. یک شبکه عصبی با دو الیه پنهان \n  کی در  \nMLP، داده\nها در جهت روبه\nجلو از ال\nهی  ورود\nی  به خروج\nی  ان ی جر  م ابند یی  .در ا\nی ن  \nنوع  از شبکه  ها با  رفتن از هر ال\nی ه  به ال\nهی  ید،گر  جمع وزن\nدار مجموعه ن\nور ون\nی ها  هیال  \n قبل محاسبه\n  و با اعمال\nکی  تابع فعال ساز غ\nی خط ری  به ال\nهی  گر ید  منتقل م\nی\nشوند\n. دل\nیل  \n نام\nگذار\nی  \n  آن به\n پیش\nخور  (\nFeed forward\n)  عدم وجود اتصال بازخورد\nی  است که از طر\nقی  آن خروج\nی ها ی  \nمدل دوباره به عنوان ورود\nی  خود مدل محسوب شوند  (مقاد\nری  فقط از ورود\nی  به ال\nی ها هی  \n پنهان\n  و سپس\nبه خروج\nی  می\nروند   و  ه چی  \n مقدار\nی  به ال\nی ها هی  ی قبل  \n بازگردانده نم\nی\nشود.  \n  ،در مقابل\nیک  \n75 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n  شبکه\nبازگشتی  اجازه م ی\nدهد  \n مقاد\nری  به عقب برگردانده شوند)\n  .به عبارت د\nی،گر  \n  ی در ک  \n شبکه\nیپ ش،خور  \n فعال\nساز ها ی  در شبکه،  \n شه ی هم  از طر\nقی  دنباله\nیا  از ال\nها هی  به جلو جر\nان ی  م ابند یی\nنی . ا  \n شبکه همچن\nین  یک  \n  شبکه\nکامالً متصل  (\nfully connected\n)  است ،  چراکه  \n  کی هر  از نورون\nها ی  \nشبکه به گونه\nیا بهم متصل شده\nاند که ورود\nها ی را از تمام نورون\nی ها هیال ی قبل افت یرد  م کند ی \nو فعال ی ساز  خروج\nی  \n خود را به تمام نورون\nی ها  هیال  بعد\nی  منتقل م\nکند ی.  \n  در شکل3\n-\n2  شما یی  \n  کی از  \n شبکه عصب\nی  \n  با2  هیال  \n  پنهان .قابل مشاهده است \nهنگام\nی  نی که ا  \n شبکه در حال پردازش مجموعه\nیا  از ورود\nی ها ی  خارج\nی  است، ورود ی  ها از\nقی طر  \n نورون\nی ها  حسگر در ال\nهی  ورود\nی  به شبکه ارائه م\nی\nشوند. ا\nنی  باعث م ی\nشود که نورون\nها ی  \nهیال بعد\nی سی\nگنال\nی ها \n فعال\nساز ی را در پاسخ به ا\nنی ورود\nی\nها تول دی کنند. و ا\nی ن فعال ساز ها ی  \nاز طر\nقی  شبکه جر\nان ی  ابند ییم  تا به ال\nی ه  خروج\nی  برسند  .فعال\nساز ی  نورون\nی ها  نیا  هیال ،  \n  پاسخ\nشبکه به ورود\nها ی   و  خروج\nی  نها\nیی  است. ال\nی ها هی  داخل\nی  شبکه که نه ال\nهی  ورود\nی  \n هستند و نه\nهیال  خروج\nی،  ال ی ها هی پنهان  نام ده ی  یم .شوند \nعمق  کی  \n شبکه عصب ی  برابر است با تعداد ال\nها هی ی  پنهان به اضافه ال\nهی  خروج\nی  است .\nبنابرا\nی،ن  \n  شبکه در شکل3\n-\n2  \n ی دارا  سه ال\nهی  است. تعداد ال\nی ها هی  مورد ن\nاز ی  ی برا  \n  در نظر گرفتن\n  عمق\nیک  \n  شبکه\nکی  سوال باز است. با ا\nین  \n  حال، ثابت\nشده است  \n  کی که  شبکه با سه ال\nهی  نور\nون \n(ی ی عن  دو ال\nیه  \n  پنهان و\nکی  هیال  خروج\n) م ی ی\nتواند هر تابع\nی  \n را به دقت دلخواه تقر\nبی  بزند  .\nبنابرا\nی،ن  در ا\nی\nنجا  \n حداقل تعداد ال\nی ها هی  پنهان الزم برا\nی  \n قی عم  \n  در نظر گرفتن\nیک  \n شبکه را به\nعنوان دو تعر\nفی  یم می کن . تحت ا\nنی  ی تعر،ف  شبکه در شکل  \n3\n-\n2\n  \n  به عنوان  کی  شبکه عم\nی ق \nتوص\nیف  م ی\nشود. با ا\nنی حال، ب\nی\nشتر شبکه\nی ها \n قی عم شیب از دو ال هی \n.پنهان دارند امروزه برخ\nی \nاز شبکه\nی ها  \n قی عم  ده  ای ها  ی حت  صدها ال\nیه  \n.دارند \n هر شبکه  عصب\nی   پی ش\nخور  \n از  ورود ها ی\n، تعداد دلخواه ال\nها هی  پنهان  و ال\nی های  \n که\nخروج\nها ی  \n را محاسبه م ی\nکند  \n به نام ال\nهی  خروج\nی   تشک\nیل  \n می\nشود\nنی . ا  \n ی رو کرد \nمبتن بر ی یال،ه یی جا  \n است که نام\nادگ ی\nیری قی عم  \n  ،از آن گرفته شده است، چراکه\n  عمق\nیک  \n شبکه  \n عصب\nی   پ ی ش،خور  \n تعداد  ال\nی یی ها ه  \n  را  که\nیک  \n شبکه  \n عصب ی  \nپ ی ش\nخور \n از آن تشک\nلی شده است را توص\nیف  م ی\nکند. \n \n نورون  ها  درMLP\n  با  الگور\nتم ی  ادگ ی\nیری  \n پس انتشار  آموزش  داده  م\nی\nشوند  .\nMLP\n  ها  به  عنوان تقر ی ب گر ها ی  \n(  جامعuniversal approximators\n)\n  \n عمل\n می\nکنند . به عبارت د\nی،گر  \n آن ها م\nی توانند  \n هر تابع پ\nی وسته\nیا  را تقر\nی ب  \n  بزنند و\n می\nتوانند مسائل\nی که به صورت خط\nی \n قابل تفک\nیک ن ی\nستند \n.را حل کنند \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 76 \n \n \nنشان داد\nه شده است  که شبکه\nها ِی  عصبِی   پ ی ش\nخور  \n  تنها با\nیک  لای هِی  \n  ،پنهان\n می\nتوانند ی برا تقر\nبی  هر تابع پ\nی\nوسته مورد استفاده قرار گ\nرند ی. \nمسائل مرتبط با طراحی و آموزش \n شبکه های عصبی \nهدف از فرآیند یادگیری در شبکه\nهای عصبی، یافتن مجموعه ای از مقادیر وزنی است که باعث\n می شود خروجی  شبکه عصبی تا حد امکان با مقادیر هدف واقعی مطابقت داشته باشد. مسائل\nمختلفی در طراحی و آموزش شبکه پرسپترون چندالیه وجود دارد: \n▪ انتخاب تعداد الیه\nهای پنهان برای استفاده در شبکه.\n \n▪ تصمیم\nگیری برای استفاده از چند نورون در هر الیه پنهان.    تعداد نورون\nها در ال\nیه\nی (ها  )\nپنهان  \n یکی از تصمیم\nگیری\nهای مهم در طراحی یک شبکه عصبی  \n  است. اگر  به  تعداد کافی  \n  نورون استفاده\nنشود\n، شبکه قادر به مدل\nی ساز  داده\nی ها  ده یچیپ  \n  نخواهد بود و\nتطابق  \nحاصل ضع فی  \n.خواهد بود  اگر تعداد ز\nی اد ی  \n  نورون استفاده شود، زمان آموزش ممکن\nاست ب\nشی  از حد طوالن\nی  \n  شود و بدتر از آن، شبکه ممکن است\nمنجر به بیش\nبرازش  شود .\nهنگام\nی که ب\nی ش برازش\nاتفاق م ی افتد، شبکه شروع به مدل\nی ساز نو زی تصادف\nی \n در داده ها\nم ی\nکند. نت\nی جه  نیا  است که م\nدل  به خوب\nی  با داده\nی ها  آموزش\nی  مطابقت د\nارد، اما به طور\nیفی ضع  به داده\nها ی  دی جد  ی و د ده  \n نشده تعم\nی م  ابد ییم\n. برا\nی  آزما شی  نیا  مورد با\nید  \n از\nاعتبارسنج\nی  \n .استفاده شود \n▪ یافتن یک راه حل بهینه سراسری که از کمینه\nهای محلی اجتناب کند.  کی  \n شبکه عصب\nی \nمعمول\nی  ممکن است صد\nها  وزن داشته باشد که مقاد\nیر  \n آن  ها  باید ی برا  دی تول  کی  \n  راه حل\nنه ی به  یپ دا  شود. اگر شبکه\nی ها  \n عصب\nی  مدل\nی ها  ی خط  (مانند رگرس\nون ی  ی خط)  باشند  ،\nی\nافتن  مجموعه به\nنه ی  وزن\nها کار سخت\nی  نیست\n. اما خروج\nی  یک  \n شبکه عصب\nی  \n به عنوان\nتابع\nی  از ورود ی\nها اغل\nب  ار ی بس  یغ\nرخط\nی  است. ا\nنی  امر فرآ\nند ی  ی به نه\nی ساز  \n  را  بسیار\nیچیپ ده  \nم ی\nکند. اگر خطا را به عنوان تابع\nی  از وزن\nها ترس\nیم  \n ی کن،د  \n  احتماال\nیک  \n  سطح ناهموار با\nکمینه\nهای  محل\nی  ی اد یز  مانند ز\nری  مشاهده خواه\nید  \n :کرد \n \nنیا  تصو\nری  ار ی بس  ساده شده است ز\nرا ی  \n  تنها مقدار  یک\nوزن را نشان م\nی دهد (در محور\nافق ی  .)\n \n▪ همگرایی به یک راه\nحل بهینه در یک دوره زمانی معقول.\n \n▪ اعتبارسنجی شبکه عصبی برای آزمایش بیش.برازش \n77 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n تابع فعال سازی \n تابع فعال\nی ساز  \n از اهم\nتی  اد یز ی  \n  در\nیادگیری عمیق  \n  برخوردار است. هدف توابع فعال سازی  \nافت ی در  عدد\nی  از ورود\nی  \n  و محاسبه\nکی  ی سر  ات ی عمل  اض یر\nی  است تا خروج\nی  بین  \n  بازه0  \n  تا1  \nیا  1\n-\n  \n  تا1  \n  را\nدی تول  کند. تابع فعال\nی ساز  در هر نورون مصنوع\nی  اگر  یس\nگنال\nی ها  در ی افت ی  \n  به  حد\nآستانه رس\nی ده  \n  ،باشند\nیس گنال\nی ها  خروج\nی  را برا\nی  سطح بعد\nی  \n  ارسال می.کنند  ان ی به ب  یلیخ  \n  ساده\n تابع فعال ساز تصم\nمی  م رد یگی  \n  کی که  نرون با\nید  \n  فعال شود\nیا  خیر  .\n \n  یری ادگ ی در  \n ی عم،ق  کی  \n شبکه عصب\nی  \n بدون تابع فعال\nی ساز  \n  فقط\nکی  مدل رگرس\nون ی  خط ی  \nساده  است!؟  چراکه  نیا  توابع در واقع محاسبات غ\nی\nرخط\nی  را در ورود\nی  یک  \n شبکه عصب ی  \n  انجام\nم ی\nدهند  \n  و آن را قادر به\nیری ادگ ی  و انجام وظا فی  چیپ تر ده ی  م ی\nکنند\n. بنابرا\nی،ن  \n  مطالعه انواع مختلف  \nو تجز\nهی  و تحل\nلی  ای مزا  و معا\nبی  هر تابع فعال ی ساز،  ی برا  \n انتخاب نوع مناسب تابع فعال ی ساز  \nکه بتواند غ\nی\nرخط\nی  \n  بودن و دقت را در\nیک  \n مدل شبکه عصب\nی  خاص ارائه دهد، بس\nار ی  \n ضرور\nی  \n.است  \n  ،همچنین\nبه دل\nیل  \n  مشکل\nمحو  گراد ان ی  (\nVanishing gradient\n)  \n که بعدا در مورد آن\nصحبت خواه\nمی  کرد، تنظ\nیم  \n تابع \n فعال\nی ساز  مناسب  برای شبکه  ار ی بس  \n.مهم است \n تابع فعال\nسازی مورد استفاده در شبکه  های\nعمیق\n، نمی  تواند از هر تابعی باشد، بلکه باید\nویژگی  .های خاصی را در خود به همراه داشته باشد\nیکی  از و\nی ها ی ژگ ی  \n  مهم\nکی  تابع فعال\nساز ی  \nنیا  است که با\nید  \n مشتق\nپذیر  باشد. شبکه از خطاها\nیی  که در ال\nهی  خروج\nی  محاسبه م ی  ،شود\nی اد \nم رد یگی  .ی ک  تابع فعال\nی ساز  مشتق\nپذیر  ی برا  انجام به\nنه ی\nی ساز  \n پس\nانتشار در حال\nی  \n  که  انتشار\nعقب\nگر( دpropagating backwards\n)  را  ی برا  محاسبه گراد ی ان ی ها  ا خط  \n با توجه به وزن  ها و\nسپس به\nنه ی\nی ساز  \n وزن\nها  با استفاده از گراد\nان ی  \n کاهشی انجام می\nدهد  (ای  \n هر تکن\nکی  نه ی به\nساز ی  \nی گر ید  ی برا  \n کاهش خطا)، مورد ن\nاز ی  \n .است \n نقش تابع فعال\nی ساز  استخراج خروج\nی  از مجموعه مقاد ری  ورود\nی  \n  است که به\nکی نورون (ای  کی هیال ) داده م\nی.شود \n چرا\nتوابع فعال\nسازی غیرخطی \n ضروری هستند؟ \nت ابع  \n فعال\nی ساز  کی  مرحله اضاف\nی  \n  را\nدر هر ال\nی ه  \n  در طول\nانتشار  \n  جلورو(\nforward propagation\n ) \nمعرف\nی  م ی\nکنند، اما محاسبه آن ارزش  ش  .را دارد\nفرض  \n دی کن  کی  \n شبکه عصب\nی  می دار  \n  که بدون توابع\n فعال\nی ساز  \n کار م ی  کند. در آن صورت، هر نورون تنها با استفاده از وزن\nها و با\nی اس،ها  کی  ی تبد ل  \nی خط  ی رو  ورود\nها ی  انجام م ی\nدهد  .از این\nرو  دیگر اهمیتی ندارد  که از  چند ال\nیه  \n پنهان در شبکه\n عصب\nی  \n  خود استفاده\nکنید  \n  چراکه\nهمه ال\nهی  ها به\nیک  \n  شکل\nرفتار  م ی  کنند\nبه این علت که  بی ترک  \n دو\nتابع خط\nی  \n  خود\nکی  تابع خط\nی  است  \n  و شبکه قدرتی بیشتر از یک رگرسیون خطی را نخواهد\n.داشت \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 78 \n \n \n فرض کن\nدی  کی  بردار ورود ی  x  \n  و\nسه  هیال  پنهان دار\nی د  که با ماتر\nی ی ها س  \n  وزن𝑊1\n  ،\n𝑊2\n  \n  و𝑊3\n \nنشان داده شده\nاند. بدون ه\nچی  تابع فعال\nی ساز،  \n شبکه عصب\nی  شما خروج\nی  \ny=x 𝑊1𝑊2𝑊3\n  \n را\n  دارد که برابر است باy=𝑥𝑊به طور\nی  \n  که𝑊= 𝑊1𝑊2𝑊3\n  \n  نیا و  یزیچ  ست ین  جز ضرب ماتر\nیس .  \nحال\n، با معرف\nی  یک  \n تابع  \n فعال ی ساز  ی خط ریغ  پس از هر تبد\nلی  ی خط،  گر ید  نیا  \n اتفاق نم ی\nافتد: \n𝑦= 𝑓1 (𝑊1𝑓2(𝑊2𝑓3(𝑊3𝑥))) \nاکنون هر ال هی   یم\nتواند بر رو ی  جی نتا  یال ه  یغ\nرخط ی  قبل ی  ا ی\nجاد  \n  شود که اساسا منجر به کی  تابع غ\nی\nرخط ی  \nده یچیپ یم\nشود. \nیک  \n تابع فعال\nی ساز  به شبکه عصب ی  مصنوع\nی  \n اضافه م ی شود تا به شبکه کمک\nکند الگوها\nی ده یچیپ \n در داده  ها را\nاد ی رد ی بگ. \nی ها ی ژگ یو \n مطلوب\nکی تابع فعال\nی ساز \nهم چنان که پیش  ،تر بیان گردید\nتابع فعال  سازی\nدر شبکه  های عصبی\nباید ویژگی  های خاصی را\n.در خود به همراه داشته باشد  ویژگی\nها\nی مطلوبی که یک تابع فعال\nسازی باید داشته باشد  \n  را\n می:توان به صورت زیر خالصه کرد \n▪ غیرخطی  (\nNonlinear\n  :)همان طور که پیش  ،تر بیان شد  اگر\nتابع فعال\nی ساز  ی خط  \n  ،باشد\nکی  پرسپترون با چند\nنی  هیال  پنهان را م ی\nتوان  براحت\nی  \n  کی به  پرسپترون تک ال\nیه  \n  فشرده\nکرد،  چراکه  بی ترک  ی خط  از بردار ورود\nی  را م\nی\nتوان  به سادگ\nی  \n  به عنوان\nکی  بی ترک  ی خط \nمنفرد از بردار ورود\nی  ان یب  کرد. در ا\nنی  صورت عمق شبکه تاث\nیری  \n  .نخواهد داشت\n بن\nابرا\nی،ن  غی\nرخط\nی  \n بودن در تابع فعال\nی ساز  زمان\nی  که  \n مرز تصم\nمی  تی ماه  یغ\nرخط\nی  \n  داشته\nباشد.، ضروری است  از آنجا\nیی  \n  کی که  \n شبکه عصب ی  مصنوع\nی  \n الگو\nها  ای  مرز را از داده ها\nاد ی  م یگی،رد  یغ\nرخط\nی  بودن در تابع فعال ی ساز  ضرور\nی  \n است تا شبکه عصب\nی  مصنوع\nی \nبتواند هر مرز خط\nی  یا  غی\nرخط\nی  را براحت\nی  اد ی  رد ی بگ . \n▪ صفر-مرکز  \n(\nZero-Centered\n  :)خروج\nی  تابع  فعال\nی ساز  \n دی با  صفر -مرکز  \n  باشد  تا\n گرادیان\nها  به جهت خاص\nی  ر یی تغ  \n .نکنند  زمان\nی  به تابع\nی   صفر-\n  مرکز\nگویند  \n که محدوده\nآن دارا\nی  مقاد\nری  مثبت و منف\nی  \n باشد. اگر تابع فعال\nی ساز  \n  شبکه صفر-\n  مرکز  ،نباشد ی هم شه  \n  مثبت\nیا  \n شه ی هم  ی منف  است. بنابرا\nی،ن  خروج\nی  یک  لایه  \n شه ی هم  به مقاد\nیر  \n  مثبت\nیا  \n منف ی  \nمنتقل م ی\nشود. در نت\nی،جه  بردا\nر  وزن ن\nاز ی  \n به بروز رسان\nی  یب ی شتر  \n دارد تا بدرست\nی  \n  آموزش\nداده شود. بنابرا\nی،ن  اگر تابع فعال\nی ساز  \n  در صفر-مرکز نباشد، تعداد دوره\nی ها  مورد ن\nاز ی \nی برا  آموزش شبکه افزا\nشی   م ابد یی . به هم\nنی  لی دل  است که و\nی ژگ ی  صفر-\n  ،مرکز مهم است\nاگرچه ضرور\nی  ست ین . \n79 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n▪ \n( هزینه محاسباتیComputational Expense\n  :)توابع فعال\nی ساز  بعد از هر ال\nیه  \n اعمال\nم ی\nشوند و با\nدی  یلیم ون\nها بار در شبکه\nی ها  \n قی عم  محاسبه شوند. بنابرا\nی،ن  محاسبه آن  ها\nدی با  از نظر محاسبات\nی  \n .ارزان باشد \n▪ \n مشتق( پذیرDifferentiable\n:)\n  شبکه\nی ها  \n عصب\nی  با استفاده از فرآ\nند ی  \n گرادیان کاهشی  \nآموزش داده م\nی،شوند  بنابرا\nنی  الزم است تابع فعال\nی ساز  با توجه به ورود ی  مشتق پذیر  \nباشد. ا\nنی  کی  از ین  ضرور\nی  ی برا  \n  عملکرد\nکی  تابع فعال ی ساز  \n.است \n▪ \n( پیوستهContinuous\n:)\n  یک  \n تابع نم\nی  تواند\nمشتق\nپذیر  شود مگر ا نکه ی  یپ\nوسته  \n.باشد \n▪ کران( دارBounded\n  :)داده\nی ها  ورود\nی  از طر\nقی  ی ک  ی سر  پرسپترون که هر کدام حاو\nی \nیک  \n تابع فعال\nی ساز  هستند، منتقل م ی\nشود. در نت\nی،جه  \n  اگر تابع در\nکی  کران  \n  محدود\nنباشد، مقدار خروج\nی  ممکن است منفجر  (\nexplode\n)  \n شود. برا\nی  کنترل ا\nین  \n ِانفجار  \nمقاد\nی،ر  تی ماه  \n کران\nدار  تابع فعال\nی ساز  مهم است اما ضرور\nی  ست ین. \nمشکالتی که ت\nوابع \n فعال ی ساز \n با آن مواجه هستند \n  مشکل  محو\nگراد ان ی  (\nVanishing Gradient problem\n)  \n  و مشکل\nنورون  \n( مردهdead neuron\n)  \nدو مشکل عمده\nیا  هستند که توابع فعال ی ساز  پرکاربرد با آن مواجه هستند: \n▪ مشکل  \n:محو  گرادیان  شبکه\nها ی  \n عصب\nی  \n  با  استفاده  از  گرادیان کاهشی  و  الگوریتم\n پس\nانتشار  آموزش داده م\nی\nشوند. هنگام استفاده از الگوریتم پس  انتشار، در فاز عقبگرد\nمحاسبه گرادیان کوچک و کوچک\nتر می\nشود. این اتفاق به این دلیل بوجود می  آید که\n  گرادیان کاهشی در هر تکرار مشتقات جزئی را با طی کردن از الیه پایانی به سمت الیه\nابتدایی با استفاده ا\nز قانون زنجیره\nای می\nیابد. در شبکه  ای با داشتن𝑛  \n  الیه پنهان، مشتقات\n  این𝑛\n  الیه در یک\nدیگر ضرب می  شود. حال اگر این مشتقات کوچک باشند، با رفتن به\nالیه  های اولیه به صورت نمایی کاهش پیدا و (یا در بدترین حالت صفر می  شوند و\n یادگیری شبکه متوقف می\nشود) همین امر  \n سبب پدیده  محو گرادیان\nمی  شود. از آنجایی\n که این گرادیان\nهای \n کوچک در تکرار الگوریتم بروزرسانی نمی شوند\nو این الیه های اولیه\nاغلب در شناخت داده\nها موثر هستند، منجر به عدم دقت کافی شبکه می\nشوند  \n  و این  \nهیال ها نم\nی\nتوانند به درست\nی  ی اد  بگ رند ی.  به عبارت د\nی،گر  گرادیان  آن\nها به دل\nیل  \n عمق شبکه\n و فعال\nی ساز  که مقدار را به صفر م\nی\nبرد، از ب\nنی  م ی  .روند\nاز این،رو  ما م ی\nخواه\nیم  \n تابع\n فعال\nی ساز  گراد ان ی  را به سمت صفر تغ\nر یی  \n.ندهد  \n  در مقابل  ،محو گرادیان\nانفجار گرادیان  \n(\nExploding Gradients\n.) وجود دارد  \n  اگر مقادیر گردایان\nها  بزرگ باشند  ،\n  منجر به بروز\nرسان ی ها ی  ار ی بس  \n بزرگ وزن  \n مدل شبکه عصب\nی  در طول آموزش م\nی.شوند  \n  با رشد نمایی\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 80 \n \n \nاز طریق انتقال به الیه  ،ها این گردایان  های بزرگ در نهایت\nسبب سرریز شده و وزن  ها\n  دیگر توانایی\nبروزرسانی  نخواهند داشت  و شبکه\nای ناپایدار\nی  را پدید می\nآور\nن.د \n▪ \n:نورون مرده  ی وقت  کی  \n تابع فعال\nی ساز  \n بخش بزرگ\nی  از ورود\nی  \n  را به صفر ای  با ی تقر  \n  صفر\nوادار م\nی،کند  آن نورون\nی ها  متناظر برا\nی  کمک به خروج ی  نها\nیی  یغ\nرفعال  (مرده)  \n  .هستند\nدر ح\nنی  بروز رسان\nی  \n وزن\nها\nنی ، ا  احتمال وجود دارد که وزن\nها به گونه\nای  \n  بروز شوند که\nمجموع وزن\nی  بخش بزرگ\nی  \n  از شبکه به  \n  .اجبار صفر شود\nکی  شبکه به سخت\nی  \n از چن\nی ن \nوضع\nیتی بهبود \n می\nیابد و بخش بزرگ\nی از ورود\nی \n نم ی\nتواند به شبکه کمک کند. ا\nین \n  منجر\n کی به مشکل م\nی\nشود ز\nرا ی ممکن است بخش بزرگ\nی از ورود ی در طول اجرا\nی \n شبکه به\nطور کامل غ\nی\nرفعال  شود. ا\nین  \n نورون\nیی ها  \n که به\nشدت غ\nی\nرفعال  م ی،شوند  \"ور ن ون\nی ها  \n مرده \"  \nده ی نام  م ی\nشوند  نی و ا  \n  مشکل به عنوان مشکل\nنورون مرده  ده ی نام  م ی\nشود.  به  ،طور خالصه\n نورون مرده در اصطالح شبکه عصب\nی  مصنوع\nی  به نورون\nی  \n گفته م ی\nشود که در ح\nین  \n  آموزش\n فعال نم شی.ود  نیا  امر باعث م\nی\nشود که نورون نتواند وزن خود را بروز کند ز\nرا ی  \n  مشتقات\n آن وزن\nی ها  مربوط بس\nار ی  \n  کوچک\nای  صفر خواهد بود. خطاها از طر\nیق  یک  \n  نورون مرده\nنیز  \n منتشر نم\nی،شوند  بنابرا\nنی  ی رو  گر ید  نورون\nی ها  شبکه تأث\nیر  م ی\nگذارند. \n توابع فعال\nی ساز پرکاربرد \nدر ا\nین  \n بخش به پرکاربردتر\nنی  توابع فعال ی ساز  ی ها ی ژگ ی و و  \n آن\nها م\nی\nپرداز\nیم . \nSigmoid\n \n تابع فعال\nساز  \n Sigmoid\n به صورت زیر تعریف می:شود \n𝜎(𝑥) =\n1\n1 + 𝑒−𝑥 \n  که در آن𝑥  ورود\nی  تابع فعال.ساز است  \n  حال\nبیایید  نیا  را در پا\nتون ی  کدنو یسی  \n می کن: \ndef sigmoid(x): \n  return 1/(1+np.exp(-x)) \n تابعSigmoid\n  پی\nوسته \n( و در محدوده0،1\n )کران\nدار \n و مشتق\nپذیر است \n اما صفر-مرکز نیست.  \nاین \n تابع هر مقدار( حقیقیreal\n ) را به عنوان ورود\nی رد یگیم و مقاد\nیری \n  را در محدوده0 \n تا1 \n  در\nخروج\nی  م ی.دهد  \n هرچه ورود\nی  بزرگتر باشد (مثبت ب\nی\nشتر\n)، مقدار خروج\nی  \n  به1.0\n  ی نزد کتر  \nخواهد شد، در حال\nی  که هرچه ورود\nی  کوچکتر (منف\nی\nتر) باشد، خروج\nی  \n  به0.0\n  کتر ی نزد  \n خواهد\nبود. \n  مشتق تابعSigmoid\n  \n،𝜎(𝑥)\n  \n  تابعSigmoid\n  \n𝜎(𝑥)\n \n ضرب در1 −𝜎(𝑥)\n است: \n𝜎́(𝑥) = 𝜎(𝑥). (1 −𝜎(𝑥)) \n81 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n که در پایتون می\nتوانیم آن را به\nصورت زیر  کدنو یسی  \n می کن: \ndef der_sigmoid(x): \n  return sigmoid(x) * (1- sigmoid(x)) \n  حال بیاید تابعSigmoid\n و مش\nت :ق آن را مصورسازی کنیم. برای این کار کد زیر را وارد کنید \nimport numpy as np \nimport matplotlib.pyplot as plt \n \n# Sigmoid Activation Function \ndef sigmoid(x): \n  return 1/(1+np.exp(-x)) \n \n# Derivative of Sigmoid \ndef der_sigmoid(x): \n  return sigmoid(x) * (1- sigmoid(x)) \n \n# Generating data to plot \nx_data = np.linspace(-10,10,100) \ny_data = sigmoid(x_data) \ndy_data = der_sigmoid(x_data) \n \n# Plotting \nplt.plot(x_data, y_data, x_data, dy_data) \nplt.title('Sigmoid Activation Function & Derivative') \nplt.legend(['sigmoid','der_sigmoid']) \nplt.grid() \nplt.show() \n \n \n  تابعSigmoid\n  از برخ\nی  اشکاالت عمده رنج م ی  برد. تابعSigmoid\n  \n( در محدوده0،1\n  )\nمحدود م\nی\nشود. از ا\nین  \n رو هم\nشه ی  کی  مقدار غ\nی منف ری  به عنوان خروج\nی  دی تول  یم\nکند. بنابرا\nین  \nیک  \n تابع فعال ی ساز  صفر-مرکز  ست ین  . تابعSigmoid\n  دامنه بزرگ\nی  از ورود\nی  \n  را به محدوده\nکوچک\nی  \n(\n0،1\n  )نگاشت  م ی\nکند. بنابرا\nی،ن  کی  ر یی تغ  بزرگ در مقدار ورود\nی  منجر به تغ\nر یی  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 82 \n \n \nکوچک در مقدار خروج\nی  م ی\nشود. ا\nنی  منجر به مقاد\nری  گراد\nان ی  کوچک ن\nیز  می\nشود. به دل ی ل \nمقاد\nری  کم گراد\nی،ان  \n  با مشکل\nمحو گرادیان  مواجه م ی.شود \n در کاربردها\nی  ی عمل،  \n تابع فعال  سازSigmoid\n  ی عل\nرغم  محبوب\nتی  آن در گذشته،  به دل\nیل  \n  دو\n مشکل مهم کم\nتر مورد استفاده قرار م\nرد یگی : \n1\n.\n \n.مشکل محو گرادیان دارد  \n  تابعSigmoid\n  \n  منجر به مشکل  محو گرادیان\nدر الگور\nتم ی  \n پس\nانتشار م ی\nشود. در ا\nنی  حالت ه\nیچ  سی\nی گنال  \n از طر\nیق  \n نورون ها منتقل نم\nی  شود و\nبنابرا\nنی  نورون  در مرحله آموزش چ\nیزی  اد ی  \n .نخواهد گرفت \n2\n.\n صفر-\n.مرکز  نیست  خروج\nی های  \n  تابعSigmoid\n  صفر-مرکز  نیستند.  از این  رو در\nالگور\nتم ی  \n پس\nانتشار، گراد\nی ان\nیی ها  یا\nجاد  م ی  شود که\nیا  \n  همه مثبت  ای و  همه منف\nی  \n هستند\n  که\nی برا  بروز رسان\nی  گراد ان ی  \n وزن\nها مناسب ن\nست ی . \nاز  تابع  فعال  سازSigmoid\n  به  طور  کل\nی  ی برا  \n مسائل  طبقه\nبند\nی  دودویی  \n  و\n طبقه\nبندی چندبرچسبی  در الیه خروجی  \n استفاده م\nی\nشود  \n  چراکه\nدی با  \n  احتمال را\nبه  عنوان  خروج\nی   یپ بش ینی  می کن\n.  از  آنجا\nیی  که  احتمال  هر  چ\nیزی  فقط  ب\nی ن \n محدوده0 \n و1 است ،\nSigmoid\n \n به دل\nلی دامنه آن انتخاب مناسب\nی \n .است \n \nمزایا \n \n▪ محدوده خروج\nی  \n  آن از0    تا1  \n  ،است\nاز این\nرو  یم تواند احتمالت را ا\nجاد ی  کند.   نیا  باعث م\nی  شود که\nSigmoid\n  ی برا نورون\nیها خروج\nی شبکه\nیها عصب\nی \n با هدف طبقه\nی بند دی مف باش .ند \n▪ در همه\nجا مشتق.پذیر است \n▪ \n .ماهیت آن غیرخطی است \n \n معایب \n \n▪  از مشکل اشباع  (\nsaturation problem\n)  رنج م ی  .کی برد  نورون در صورت\nی  \n  اشباع شده در نظر\nگرفته م ی  شود که به حداکثر\nای  حداقل مقدار خود برسد، به طور\nی  \n  که مشتق آن برابر با0  \n باشد. در ا\nی ن  \nصورت، وزن\nها بروز نم ی\nشوند \n که باعث\nادگ ی یری فی ضع  ی برا شبکه\nیها قی عم یم\nشود . \n▪  این  ی ک  \n  تابع صفر\nمرکز  ست ین . بنابرا ی،ن  انی گراد  \n تمام وزن\nیها  \n  متصل به\nیک  \n  نورون مثبت\nیا  \n منف ی  \nاست. در طول فرآ\nند ی بروزرسان\nی،  این  \n وزن ها تنها مجاز به حرکت در\nیک \n ،جهت\nی عن ی \n مثبت ای ی منف   در\nیک \n زمان هستند. ا\nنی امر به\nنه ی ی ساز \n تابع\nزیان \n را سخت\nتر م ی.کند \n▪ \n.هزینه محاسباتی زیادی دارد  \n  این  تابع\nکی  ی عمل ات  \n یی نما  انجام م ی\nدهد که در نت\nجه ی  \n  زمان محاسبات\nی شتر یب رد یگی را م . \n83 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \ntanh\n \n تابع فعال\nی ساز  \n تانژانت هذلولوی\nگون  \n  یاtanh\n،  ارتباط نزد\nیکی  با تابع فعال ی ساز  \nSigmoid\n  \n  دارد\nو شکل ر\nاض ی\nی  \n  آن:به صورت زیر است \n𝑓(𝑥) = tanh(𝑥) = sinh(𝑥)\ncosh(𝑥) = 𝑒𝑥−𝑒−𝑥\n𝑒𝑥+ 𝑒−𝑥= 2𝜎(2𝑥) −1. \nدر پا\nتون ی  \n می\nتوانیم آن را به  صورت زیر\nکدنو\nی سی  \n می کن: \ndef htan(x): \n  return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x)) \nهمان \n  طور که در معادله\nباال  مشاهده م\nی  ،شودtanh\n  به سادگ\nی  کی  نسخه مق\nی اس شده از فعال  ساز\nSigmoid\n  است  .نی با ا  \n،حال صفر-مرکز  است.  \n  از این،رو  برخ\nی  \n  از\nمشکالتی  \n را که فعال  ساز\nSigmoid\n  \n  دارد  را از خود نشان نم\nی\nدهد.  \n  این تابع\nیپ،وسته  مشتق\nپذیر  \n  و\nکران\nدار  در  محدوده\nا ی \n( از1،1\n-) است. بنابرا\nی،ن  ی منف،  مثبت و صفر را به عنوان خروج ی  دی تول  کند یم  \n  و\nورود\nی ها ی  \nدا ی شد  \n ی منف  \n  بهtanh\n  به خروج ی ها ی  ی منف  \n نگاشت م ی\nشوند\n. بنابرا\nین  \n تابع فعال ی ساز  \ntanh\n  \n  در\nصفر -مرکز  \n می\nباشد  \n  و\nمشکل  عدم  صفر -مرکز بودن  \n  تابعSigmoid\n را حل م\nکند ی. \n مشتق تابع  \n tanhبه صورت زیر محاسبه می:شود \n𝑓(𝑥) = 1 −𝑓(𝑥)2 \n که در پایتون می\nتوانیم آن را به\nصورت زیر  بنویسیم: \ndef der_htan(x): \n  return 1 - htan(x) * htan(x) \n  بیاید تابعtanh\n و مش\nت :ق آن را مصورسازی کنیم. برای این کار کد زیر را وارد کنید \nimport numpy as np \nimport matplotlib.pyplot as plt \n \n# Hyperbolic Tangent (htan) Activation Function \ndef htan(x): \n  return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x)) \n \n# htan derivative \ndef der_htan(x): \n  return 1 - htan(x) * htan(x) \n \n# Generating data for Graph \nx_data = np.linspace(-6,6,100) \ny_data = htan(x_data) \ndy_data = der_htan(x_data) \n \n# Graph \nplt.plot(x_data, y_data, x_data, dy_data) \nplt.title('htan Activation Function & Derivative') \nplt.legend(['htan','der_htan']) \nplt.grid() \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 84 \n \n \n \nمزایا \n \n▪ \n برخالفSigmoid\n ، کی تابع صفر-مرکز است تا به\nنه ی\nی ساز \n تابع\nزیان \n آسان.تر شود \n▪ خروج\nی نورون را در محدوده یا نیب 1\n-   و1 نرمال م ی.کند \n \n معایب \n \n▪  \n.از نظر محاسباتی گران است \n▪ \n مستعد \n محو گرادیان\nاست. \nReLU\n \nتوابع فعال ی ساز  \nsigmoid\n  \n  و tanh\n را نم\nی\nتوان  در شبکه\nیی ها  با ال\nی ها هی  اد یز  به دل\nیل  \n  مشکل\n  محو\nگراد\nان ی  استفاده کرد. تابع فعال ی ساز  \nReLU\n  \n  که\nمحبوب\nنی تر  \n تابع فعال\nی ساز  \n  ی ادگ ی در ر ی  \n قی عم  است (در ال\nهی  پنهان،)\n \n  بر مشکل  محو\nگراد ان ی  غلبه م کند ی  \n  و به\nشبکه  اجازه م\nی\nدهد  ی سر تر ع  \nاد ی  رد ی بگ  و عملکرد بهتر\nی  داشته باشد . تابع  \nReLU\n  \n  به صورت زیر تعریف می\nشود: \n𝑓(𝑥) = {0 𝑓𝑜𝑟 𝑥≤0\n𝑥 𝑓𝑜𝑟 𝑥> 0 \n که در پایتون می\nتوانیم آن را به\nصورت زیر  بنویسیم: \ndef ReLU(x): \n  data = [max(0,value) for value in x] \n  return np.array(data, dtype=float) \n \n85 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n مشتق تابع  \n ReLUبه صورت زیر محاسبه می:شود \n𝑓́(𝑥) = {0 𝑓𝑜𝑟 𝑥≤0\n1 𝑓𝑜𝑟 𝑥> 0 \nدر پا\nتون ی  \n می\nتوانیم آن را به  صورت زیر\nکدنو\nی سی  \n می کن: \ndef der_ReLU(x): \n  data = [1 if value>0 else 0 for value in x] \n  return np.array(data, dtype=float) \nبرای مصورسازی  \n  تابعReLU\n و مش\nت\nق آن کد ز ری  \n را وارد کن\nید : \nimport numpy as np \nimport matplotlib.pyplot as plt \n \n# Rectified Linear Unit (ReLU) \ndef ReLU(x): \n  data = [max(0,value) for value in x] \n  return np.array(data, dtype=float) \n \n# Derivative for ReLU \ndef der_ReLU(x): \n  data = [1 if value>0 else 0 for value in x] \n  return np.array(data, dtype=float) \n \n# Generating data for Graph \nx_data = np.linspace(-10,10,100) \ny_data = ReLU(x_data) \ndy_data = der_ReLU(x_data) \n \n# Graph \nplt.plot(x_data, y_data, x_data, dy_data) \nplt.title('ReLU Activation Function & Derivative') \nplt.legend(['ReLU','der_ReLU']) \nplt.grid() \nplt.show() \n \n \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 86 \n \n \n \nمزایا \n \n▪ زان ی به م ی ادیز \n همگرا\nیی انی گراد کاهشی تصادف\nی را در مقا\nسه ی \n با توابعSigmoid\n عی تسر م ی .کند \n▪ می.تواند با مشکل محو گرادیان مقابله کند \n▪ \n.تابع محاسباتی ارزانی است \n▪ \n پرکاربردتر\nنی تابع فعال ساز\nی \n .است \n▪ خیلی سریع همگرا می.شود \n \n معایب \n \n▪  صفر-\n .مرکز نیست \n▪ \n  .مشکل نورون مرده دارد سمت منف\nی  نمودار مقدار گراد\nانی  را صفر م\nی\nکند. به هم\nی ن  ی دل ،ل  \n در طول\nند ی فرآ  \n پس\nانتشار  ،  وزن  ها و سوگیری\nها   ی برا  ی برخ  نورون ها بروز نم ی\nشوند نی . ا  یم\nتواند نورون\nها ی \nمرده یا   جاد یا  کند که هرگز فعال نم ی.شوند  \n  ،به عبارت دیگر\nتمام مقاد\nری  ورود\nی  ی منف  \n بالفاصله صفر\nیم ،شوند\nاز این\nرو توانا\nیی \n مدل را برا\nی \n آموزش\nدرست از داده\nها کاهش م\nی.دهد \n \nهر زمان که \nReLU\n ورود\nی منفی را در\nافت ی د کن، خروج\nی صفر  یم .شود ،بنابراین\nاز طریق  \n پس\nانتشار چ\nیزی  اد ی  رد یگی نم  را ی (ز  نم ی\nتوان\nید  \n  در آن انتشار  عقبگرد\nانجام  دهد)\n  .\n  به\nعبارت  د\nی،گر  \n  اگر  مشتق\nصفر  باش،د  کل  فعال\nی ساز  \n  صفر\n یم شود، بنابرا\nنی چیه مشارکت\nی \n.از آن نورون در شبکه وجود ندارد \nSoftmax\n \n  از تابعsofmax\n  به عنوان خروج ی  در مسائل طبقه\nی بند  چند کالس\nی  ی برا  ی\nافتن  احتماالت برا\nی \n کالس\nی ها  مختلف استفاده م ی  شود (برخالفSigmoid\n  که برا\nی  طبقه\nی بند  دودویی  ترج\nیح  \nداده م\nی.)شود  \n  تابعSoftmax\n  احتماالت هر کالس هدف را بررو\nی  \n تمام کالس\nی ها  \n  هدف ممکن\nمحاسبه م ی\nکند (که به تع\nن یی  کالس هدف کمک م\nی  \n)کند : \n𝑆𝑜𝑓𝑡𝑚𝑎𝑥 (𝑧𝑖) =\n𝑒𝑧𝑖\n∑\n𝑒𝑧𝑘\n𝑘\n𝑘=1\n 𝑓𝑜𝑟 𝑗= 1, … , 𝑘 \nSoftmax\n  احتمال را برا\nی  ی ک  نقطه داده متعلق به هر کالس،  جداگانه برم ی گرداند. توجه داشته\nباش\nدی  که مجموع همه مقاد ری  1  \n.است \n در پایتون می\nتوانیم آن را به\nصورت زیر  کدنو\nی سی  \n می کن: \ndef softmax(x): \n    return np.exp(x) / np.sum(np.exp(x), axis=0) \n87 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nبرای مصورسازی  \n  تابعSoftmax\n  کد ز\nیر  \n را وارد کن\nید: \nimport numpy as np \nimport matplotlib.pyplot as plt \n \n# Softmax Activation Function \ndef softmax(x): \n    return np.exp(x) / np.sum(np.exp(x), axis=0) \n \n# Generating data to plot \nx_data = np.linspace(-10,10,100) \ny_data = softmax(x_data) \n \n# Plotting \nplt.plot(x_data, y_data) \nplt.title('Softmax Activation Function') \nplt.legend(['Softmax']) \nplt.grid() \nplt.show() \n \nی برا  مسائل  \n طبقه\nبندی  چندکالسه، ال\nهی  خروج\nی  \n  به اندازه کالس هدف نورون\nدارد  . به عنوان\n مثال، فرض کن\nید  \n  شما4  \n [ کالسA, B, C, D] دار\nدی.  از این\nرو  4  نورون در ال\nهی  خروج\nی  \n وجود\n خواهد  داشت.  فرض  کن\nید  \n  خروجی  تابعSoftmax\n  \n برای  یک  داده  برابر  با\n[\n0.26،0.14،0.41،0.19\n  ]شده است،  با د\nدن ی  مقدار احتمال م ی\nتوان گفت ورود\nی  \n  متعلق به\n  کالسC\n  \n .است \nبهینه سازها\nو توابع ز ان ی (\nLoss Function\n )\n \nنه ی به\nساز\nها  الگور\nی تم یی ها ی  هستند که برا\nی  کمینه\nکردن  تابع ز\nان ی/\n( هزینه  تابع\nزیان  ی خطا  نمونه ِی \nآموزش\nی  واحد است،  در حال ی  که\nتابع هز نه ی (\ncost function\n)  ی خطا  کل مجموعه داده آموزش ی  \nاست)  از طر\nقی  بروزرسان\nی  \n وزن\nی ها  شبکه استفاده م\nی\nشوند\n. الگور\nتم ی\nی ها  نه ی به\nی ساز  نقش بس\nی ار  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 88 \n \n \n مهم\nی  را در فرآ\nند ی  آموزش شبکه بر عهده داشته و تاث\nری  مستق\nی یم  بر  \n  زمان صرف شده آموزش\n.دارند  \n  ،به بیانی دیگر\nالگور\nتم ی\nی ها  نه ی به\nی ساز  \n  قلب\nادگ ی یری  عمیق  هستند که مسئول کار پ\nیچی ده  \n مدل\nی ها  یری ادگ ی  عمیق  ی برا  ی یری ادگ  از داده.ها هستند  \nی برا  نکه یا  \n بفهم\nی م  نه ی به\nی ساز  ست یچ\n؟  ابتدا با\nدی  هدف را شناسا\nیی  \n می کن  .هدف به و\nی ها ی ژگ ی  \nخاص\nی  از س\nی\nستم  به نام متغ\nری  بستگ\nی  \n  .دارد  هدف ما\nی\nافتن  مقاد\nری  ی متغ\nرها\nیی  \n  است که هدف را\nنه ی به یم.کند اغلب متغ\nی\nرها به نوع\nی مح\nدود \n.هستند \n م از\nنظر ر\nی ی اض، نه ی به\nی ساز \n ی ند ی فرآ \n  است\nی برا  \n  به\nبیشینه\nسازی(\nmaximizing\n)  ای  ی کم نه\nی ساز  (\nminimizing\n)  یک  \n  تابع هدف𝑓(𝑥)\n  \n  با\nجستجو\nی  ی متغ\nی رها  \n  مناسب𝑥\n  با توجه به محدود\nی ها تی  \n𝑐𝑖، که م\nی\nتواند  \n به صورت فشرده به\nصورت ز\nری  نوشته شود: \n𝑚𝑖𝑛𝑥𝜖𝑅𝑛𝑓(𝑥)𝑠𝑢𝑏𝑗𝑒𝑐𝑡 𝑡𝑜 {𝑐𝑖(𝑥) = 0,\n𝑖 𝜖 ℰ\n𝑐𝑖(𝑥) ≥0,\n𝑖 𝜖 ℐ  \n  که در آنℰ\n  \n  وℐ  به ترت\nبی  مجموعه یا  از شاخص\nها برا\nی  محدود\nی ی ها ت  برابر\nی  و نابرابر ی  \n.هستند  نیا  عبارت ر\nاض ی\nی  قطعا در نگاه اول دلهره آور است!!، شا\nدی  نی به ا  لی دل  که برا\nی  توص ی ف  \nی کل  نه ی به\nی ساز  است. اما نگران نباش\nی،د  \n  در ادامه مطالب\nهمه چ\nیز \n .مشخص خواهد شد \nنی چند  روش  مختلف  برا\nی  نه ی به\nی ساز  \n  در  یادگیری  عمیق ،وجود  دارد.  به  عنوان  مثال\nساده\nنی تر  الگور\nتم ی  نه ی به\nی ساز  \n  مورد استفاده در\nیادگیری عمیق،  گرادیان کاهشیGradient \nDescent\n  است  . گرادیان کاهشی کی  الگور\nتم ی  نه ی به\nی ساز  مرتبه اول تکرار\nی  است که  ی برا  ی افتن  \n)کمینه (بیشینه  محل\nی   کی  تابع مع\nنی  استفاده م ی\nشود  .نیا  \n بدان معن\nی  \n  است که هنگام انجام\nبروزرسان\nی  پارامترها فقط اول\nنی  مشتق را در نظر م\nرد یگی . در هر تکرار، ما پارامترها را در جهت\n  مخالف\nگرادیان  \n  تابع هدفJ(𝜃)\n  بروز م\nی می کن\n. اندازه گام\nی  که در هر تکر\nار  ی برا  دن ی رس  \n  به کمینه \nمحل\nی  برم می دار ی  \n  با نرخ\nیری ادگ ی  \n𝛼  ن یی تع  یم\nشود. بنابرا\nین  \n  جهت\nگرادیان  به سمت پا\nن یی  \n را دنبال\nم ی می کن  \n  تا کمینه  محل\nی  برس\nیم. \nروش  دیگر  \n بهینه\nسازی  وتن ین  است  \n  که با استفاده از مشتق مرتبه دوم با\nی\nافتن  ر ی شه\nی ها  ی ک  \nتابع در بهبود به\nنه ی\nی ساز  کمک م\nکند ی  .البته ا\nنی  روش در مقا\nسه ی  \n  با\nروش\nهای  گراد ان ی  کاهش\nی  \n  که\n بر ی مبتن  مشتق مرتبه اول هستند، پ\nی دگ یچی  محاسبات\nی  را به م\nزان ی  قابل توجه\nی  افزا شی  م ی\nدهد. \n از  هم\nنی  رو، گراد\nان ی  \n کاهش\nی  \n در  آموزش  شبکه\nی ها  \n عصب\nی  بی\nشتر  ترج حی  داده  م ی\nشود. \nالگور\nی تم\nی ها  \n متفاوت\nی  \n بر ی مبتن  گردا\nان ی  \n کاهش\nی  \n  .وجود دارند  در ادامه این بخش، پس تشریح کامل\nآن، به معرفی و بررسی سایر نسخه های این الگوریتم می.پردازیم \n تعریف1.3\n \n بهینه سازها \nدر\nفرآیند  \n آموزش شبکه\nیها  عصب\nی،  نه ی به\nساز\nها  به دنبال  مجموعه یا  \n  از پارامترها\nکه  \n وزن\nزی ها ن  ی نام ده  \nمی\nشوند\n، هستند \n تا مقدار\nزیان \n تابع\nزیان \n .تا حد امکان کوچک شود \n89 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n )گرادیان کاهشی (نزول گرادیان \nالگور\nتم ی  گراد\nان ی  کاهش\nی،  \n  یک\nروش به\nنه ی\nی ساز  \n بر ی مبتن  \n  تکرار\nاست  \n  که  تالش\nمی\nکند  با تغ\nیی ر \n وزن\nی ها  داخل\nی  \n شبکه عصب\nی،  مقدار تابع ز\nان ی  \n  را\nکمینه کند\n. در ا\nنی  روش،  وزن\nی ها  \n  شبکه\nبه\nصورت تدر\nیجی  بروز م\nی\nشوند  \n  و\nدر هر تکرار،  الگور\nتم ی  \n تالش م\nکند ی  با ترفند\nی  \n  مقدار تابع\nان یز  را تضع فی  کند. ا\nنی  عمل تا جا\nیی  که تکرار آن منجر به تغ\nیر یی  در تابع ز\nان ی  نشود،  \n  انجام\n می.شود  \n  سه\nروش کل\nی  ی برا  ی برا  استفاده از گراد\nان ی  کاهش\nی  وجود دار\nد  :گراد\nان ی  ش کاه ی  \n  با کی  نمونه  ،\nگراد ان ی  کاهش\nی  کامل  \n  و\nگراد ان ی  کاهش\nی  ر یز  \n دسته\nیا  .هنگام\nی  که بروزرسان\nی  \n  تنها با\nیک  \n نمونه\n  انجام  شود  به  آن  روش\nگراد ان ی  کاهش\nی  تصادف\nی  \n(\nStochastic gradient descent\n)  \n  گفته\nم ی\nشود .\n \nدر ا\nنی روش، با ورود هر نمونه به شبکه بروزرسان\nی اعمال و وزن\nی ها دی جد بدست م ند یآی  .\nنقطه ضعف ا\nنی  روش، گ\nیر  \n افتادن در کم\nنه ی  محل\nی  است. عالوه برا\nی،ن  نتا جی  \n ی دار ی ناپا  \n  را به\n .سبب پاسخ به هربار ورود نمونه به شبکه دارد \n  ،گرادیان کاهشی تصادفی\nزمان بروزرسان\nی  \n کاهش م ی\nدهد و مقدار  ی از افزونگ ی  \nمحاسبات\nی \n را حذف م ی\nکند که به طور قابل توجه\nی محاسبه را تسر عی  یم.کند \nدر روش گراد\nان ی  کاهش\nی  کامل، شبکه با تمام نمونه\nی ها  آموزش\nی  تغذ\nیه  می\nشود . شبکه پس از\nمحاسبه خطا برا\nی  تمام نمونه  کی ها  بار بروزرسان\nی  را انجام م\nی\nدهد\n. اگرچه ا\nی ن  \n  روش به مدل\n در فرار از کم\nنه ی  محل\nی  کمک کرده و همگرا\nیی  ی پا\nدارتر\nی  \n در مقا\nسه ی  با گراد ان ی  کاهش\nی  ی ک  \nنمونه\nای  \n  ارائه\nمی\nدهد، با ا\nنی  همه، زمان آموزش طوالن تر ی  \n  را\nدر  یپ  دارد. همچن\nنی  تغذ\nیه  \n  تمام\nنمونه\nی ها  آموزش\nی  به شبکه به\nلی دل  \n کمبود حافظه هم\nشه ی  \n امکان\nپذ ری  ست ین\n. در خال ب\nین  این  \n  دو\n روش  ،گراد ی ان  کاهش\nی  ر یز\nدسته\nای  (\nmini-batch gradient descent\n)  استفاده م ی\nشود\n. در ا\nی ن \nروش شبکه با گروه\nی  از نمونه\nها ی  آموزش\nی  تغذ\nیه  م ی\nشود  تا از مز\nتی  هر دو روش قبل\nی  \n  استفاده\n.کند  بروزرسان\nی  \n پارامتر\nها با استفاده از گروه\nی  از نمونه\nها مز\nیتی  \n  :مهم دارد\nبا استفاده از ا\nین \nروش مدل نسبت به نمونه\nها ی ی نو\nزدار مقاوم\nتر بوده و وار\nانس ی ی تر کم در بروز\nرسان\nی \n پارامتر  ها\n.دارد  نیا  عمل همگرا\nیی  دار ی پا ی تر  را ارائه م\nی\nدهد\n. با ا\nنی  همه، ا\nنی  روش\nاز ی ها ن  \n  به انتخاب نرخ\n ادگ ی\nیری  (\n𝛼\n)  \n دارند که انتخاب آن هم\nشه ی  آسان ن\nست ی\n. عالوه برا\nی،ن  \n  نرخ\nیری ادگ ی  ی\nکسان  \n  در\n تمام مراحل آموزش\nی و برا\nی \n همه پارامتر\nی ها \n مختلف نم ی\nتواند نه ی به \n .باشد اگر 𝛼  خ یلی \n  بزرگ\n  انتخاب شود، آموزش ممکن است نوسان کند، همگرا نشود\nی ا  \n از کم نه ی\nی ها  محل\nی  \n .مربوط بگذرد\n  در مقابل، اگر نرخ یری ادگ ی  خ یلی  کوچک انتخاب شود، به طور قابل توجه\nی  \n ند ی فرآ  همگرا\nیی  \n  را\nبه تاخ\nیر  می\nاندازد\n. از ا\nنی ،رو  کی  \n کی تکن  جی را  ی برا  دورزدن ا\nنی  مساله استفا\nده  \n  از\nنرخ واپاش ی  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 90 \n \n \n(\nrate decay\n  )ی ادگ ی یر  است. به عنوان مثال، با استفاده از واپاش ی  ی گام  م ی\nتوان  \n  نرخ\nری ادگ ی ی  \nرا هر چند دوره به م\nی زان ی  کاهش داد. ا\nنی  امر ا\nین  \n امکان را م ی\nدهد  تا م\nزان ی  ی ادگ ی یر  ز ی اد ی  \n  در\nابتدا\nی  \n  آموزش و نرخ\nیری ادگ ی  \n ی تر کم  در پا\nان ی  آموزش وجود داشته باشد. با ا\nنی  ح،ال  نیا  \n  روش\nواپاش\nی  ین،ز  به خود\nی  \n  خود\nکی  ابرپارامتر است و بسته به کاربرد با\nی د  با دقت طراح\nی  شود. \nهدف  نه ی به\nسازها\nی  \n  نرخ\nیری ادگ ی  \n تطب\nیقی،  \n  حل مشکل\nی\nافتن  \n  نرخ\nیری ادگ ی  \n  درست است. در\nنیا  روش  ها، نرخ\nیری ادگ ی  \n𝛼\n  کی  ری متغ  سراسر\nی  ین،ست  \n  ،اما در عوض هر پارامترِ قابل آموزش\n  ِنرخ\nیری ادگ ی  \n جداگانه\nیا  ی برا  خود دارد. در حال\nی  که ا\nی ن  روش\nها اغلب هنوز ن\nاز ی  به تنظ\nی م \nابرپارامتر د،ارند  بحث اصل\nی  نیا  است که آن\nها برا\nی  فیط  ی وس ی تر ع  از پ\nی\nکربند\nها ی  به خوب ی \nکار م ی\nکنند؛  اغلب زمان\nی  که تنها از ابرپارمترها\nی  یپ شِفرض  یپ شنهاد\nی  استفاده م ی\nکنند. \n پیاده سازی گرادیان کاهشی در پایتون \n همانطور که پیش\nتر بیان شد در بهینه  سازی ما قصد داشتیم یک تابع را𝑚𝑖𝑛\n  \n  کنیم. حال بیاید\nببینیم چگونه می\nتوان  \n  تابع𝑚𝑖𝑛\n  \n را حل کن\nم؟ ی  به لطف حساب د\nی\nفرانس لی  و انتگرال، ابزار\nی  \n به\nنام گراد ان ی  \n می دار\n. توپ\nی  را در باال\nی  \n تپه تصور کن\n. م دی می دان ی  که تپه در نقاط مختلف دارا\nی  \nیش ب های (گرادیان)ها  مختلف است. به دل\nیل  \n جاذبه، توپ به دنبال منحن\nی  تپه به سمت پا\nن یی  \nحرکت م ی  .کند  توپ\nبه کد\nام  سمت م ی\nرود؟ تندتر\nین  شیب\n. پس از مدت\nی،  \n  توپ به\nکمینه  محل ی \nم ی\nرسد که در آن زم\nنی  نسبت به اطراف خود  صاف  \n.باشد  نیا  تی ماه  گرادیان کاهشی  \n  .است\nم ی\nتوان\nمی  ری مس  صاف توپ را به مراحل کوچک تبد\nیل  \n می کن  . در مرحلهk\n-\n ام، دو کم\nتی  خواه\nی م \n  داشت: طول گام𝛼𝑘\n  \n و جهت𝑝𝑘. برا\nی  \n  مشاهده\nگردایان کاهشی  \n  در عمل، ابتدا چند کتابخانه را\nوارد م\nی می کن. \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom matplotlib.ticker import MaxNLocator \nfrom itertools import product \nی برا  \n  ،شروع\nیک  \n  تابع هدف ساده𝑓(𝑥) =  𝑥² − 2𝑥 − 3\n  را تعر\nفی  م ی می کن  \n  که𝑥\n  \n اعداد\nحقیقی  هستند\n. از آنجا\nیی  \n  که\nگرادیان کاهشی  از گراد\nان ی  استفاده م ی\nکند، گراد\nان ی  𝑓  زی را ن  فی تعر  \nم ی ی کن،م  که فقط مشتق  اول  \n𝑓  \n  ،است\nی ی عن \n∇𝑓(𝑥) = 2𝑥−2\n:\n \ndef func(x): \n    return x**2 - 2*x - 3 \n \ndef fprime(x): \n    return 2*x - 2 \nدر مرحله بعد، توابع پا\nتون ی را برا\nی رسم تابع هدف و مس\nری یری ادگ ی در طول فرآ\nند ی نه ی به\nی ساز  \nفی تعر   م ی می کن : \n91 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \ndef plotFunc(x0): \n    x = np.linspace(-5, 7, 100) \n    plt.plot(x, func(x)) \n    plt.plot(x0, func(x0), 'ko') \n    plt.xlabel('$x$') \n    plt.ylabel('$f(x)$') \n    plt.title('Objective Function') \n \ndef plotPath(xs, ys, x0): \n    plotFunc(x0) \n    plt.plot(xs, ys, linestyle='--', marker='o', color='#F12F79') \n    plt.plot(xs[-1], ys[-1], 'ko') \nاز نمودار ز\nی،ر  براحت\nی   م ی\nتوان\nیم  \n ی بب مین  \n  که𝑓\n  ی دارا  کمینه  \n  مقدار𝑥= 1 \n  \n  است  .\n فرض کن\nید  \n  از\n𝑥 = −4 \n  شروع م ی می کن  \n  (که با\nیک  \n  نقطه\nمشکی  \n در ز\nیر  \n  ،)نشان داده شده است می\nخواهیم  \n ببینیم  ای که آ  گرادیان کاهشی   م ی  تواند\nکمینه  محل\nی  \n𝑥 =  1\n  را تع\nن یی  کند  \n .یا خیر \nx0 = -4 \nplotFunc(x0) \n \nکی  الگور\nتم ی  گرادیان کاهشی  \n  ساده را به  این\nصورت تعر فی  \n می:کنیم  ی برا  \n  هر نقطه𝑥𝑘\n  در ابتدا\nی  \n  مرحله𝑘، طول گام  \n𝛼𝑘\n  را ثابت نگه م\nی  می دار  \n  و جهت𝑝𝑘\n  را منف\nی  مقدار گراد\nان ی  قرار م\nی  می ده .\n  با استفاده از فرمول  زیر این\nمراحل را انجام م می ده ی : \n𝑥𝑘+1 = 𝑥𝑘+ 𝛼𝑘𝑝𝑘 \nجایی که  \n گراد\nان ی  \n  باالتر از\nکی  مقدار تلورانس مع\nنی  است (در مورد ما  \n1 × 10−5\n  ) و تعداد\n  مراحل  یک\nمقدار مع\nین  \n  است (در مورد ما1000\n .)\n \ndef GradientDescentSimple(func, fprime, x0, alpha, tol=1e-5, max_iter=1000): \n    # initialize x, f(x), and -f'(x) \n    xk = x0 \n    fk = func(xk) \n    pk = -fprime(xk) \n    # initialize number of steps, save x and f(x) \n    num_iter = 0 \n    curve_x = [xk] \n    curve_y = [fk] \n    # take steps \n    while abs(pk) > tol and num_iter < max_iter: \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 92 \n \n \n        # calculate new x, f(x), and -f'(x) \n        xk = xk + alpha * pk \n        fk = func(xk) \n        pk = -fprime(xk) \n        # increase number of steps by 1, save new x and f(x) \n        num_iter += 1 \n        curve_x.append(xk) \n        curve_y.append(fk) \n    # print results \n    if num_iter == max_iter: \n        print('Gradient descent does not converge.') \n    else: \n        print('Solution found:\\n  y = {:.4f}\\n  x = {:.4f}'.format(fk, xk)) \n     \n    return curve_x, curve_y \nاز 𝑥 = −4 \n شروع م ی می کن   و  الگور\nتم ی  گراد\nان ی  کاهشی  را رو\nی 𝑓 با سنار\nی\nی وها  \n  مختلف اجرا\nمی  \n می کن: \n     𝛼ₖ =  0.1 \n     𝛼ₖ =  0.9 \n     𝛼ₖ =  1 ×  10−4 \n     𝛼ₖ =  1.01 \n  :سناریو اول𝛼ₖ =  0.1\n \nxs, ys = GradientDescentSimple(func, fprime, x0, alpha=0.1) \nplotPath(xs, ys, x0) \nSolution found: \n  y = -4.0000 \n  x = 1.0000 \n \n سناریو\nدوم  :\n𝛼ₖ =  0.9\n \nxs, ys = GradientDescentSimple(func, fprime, x0, alpha=0.9) \nplotPath(xs, ys, x0) \nSolution found: \n  y = -4.0000 \n  x = 1.0000 \n93 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n \n سناریو\nسوم  :\n𝛼ₖ =  1 ×  10−4\n \nxs, ys = GradientDescentSimple(func, fprime, x0, alpha=1e-4) \nplotPath(xs, ys, x0) \nGradient descent does not converge. \n \n \n سناریو\nچهارم  :\n𝛼ₖ =  0.1\n \nxs, ys = GradientDescentSimple(func, fprime, x0, alpha=1.01, max_iter=8) \nplotPath(xs, ys, x0) \nGradient descent does not converge. \n \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 94 \n \n \nچیزی  \n  که از مصورسازی  های باال در سناریوهای مختلف بدست\nآورد  یم، به صورت زیر خالصه\n می:شود \n    سنار\nی وی  \n  اول\nبراحتی  \n  همگرا\nشد\n. حت\nی  \n  اگر طول گام ثابت\nباشد  ، جهت به سمت صفر کاهش\nم ابد یی  و از ا\nین  \n رو منجر به همگرا\nیی  م ی\nشود. \n    سنار\nی یو  دوم ن\nزی  با وجود ا\nنکه ی  ری مس   یری ادگ ی  لی بدل  \n  طول گام بزرگ در اطراف راه حل در\nنوسان است، همگرا م\nی\nشود. \n    سنار\nی یو  سوم به سمت راه حل حرکت م ی\nکند. با ا\nنی  حال، طول گام بقدر\nی  \n  کوچک است که\nتعداد تکرارها به حداکثر م ی\nرسد و نمی\nتواند جواب را بیابد .\n ،در این مورد\nافزا\nیش max_iter \nمشکل را حل م کند ی. \n    سنار\nی یو  چهارم بدل\nلی  طول گام بزرگ متفاوت است. در ا\nی ،نجا  \n max_iter = 8 را تنظ\nیم  \nکرده\nایم  \n  تا\nمصورسازی  را بهتر  \n کن می .\n \nچیزی که می  توان فهمید این است که\nراه حل x = 1 را م ی\nتوان با گراد\nان ی  کاهشی  \n  با طول گام\nمناسب بدست آورد. \nدی شا  \n تعجب کن\nدی  که چرا از راه حل تحل\nیلی  قی دق  \n استفاده نم\nی می کن  : مشتق𝑓  را بگ\nیری،د  \n  سپس\n𝑥\n  را طور\nی  \n حل کن\nدی  که مشتق صفر شود. برا\nی  مثال قبل\nی،  \n متوجه م\nمی شو ی  \n  که𝑥ای  \n  که𝑓\n  \n  را به\nکمینه  می\nکند،  \n∇𝑓(𝑥) = 2𝑥−2\n  \n  را برآورده\nکند ،  ی ی عن  \n𝑥 =  1. بله، ا\nین  یک  \n  راه است. اما\nزمان\nی  \n  که با\nکی  مسئله  نه ی به ی ساز  مواجه م دی شو ی  \n  که در آن مشتق𝑓\n  \n  سخت است\nیا  \n  حل آن\nغی\nرممکن  \n  ،است\nدیگر این  \n ی تکن ک  توص\nیه\nشده  نمی\nشود. \n توجه داشته باشید که پیاده\nسازی ساده  یِ باال تنها برای درک بهتر نحوه کار گرادیان کاهشی\nهمراه با مصورسازی بوده است. در عمل نیازی به پیاده\nسازی نیست و چارچوب  های یادگیری\nعمیق، پ\nیاده\nسازی کارآمد این الگوریتم\nها را در خود جای داده .اند \n گرادیان کاهشی مبتنی بر ( تکانهMomentum\n )\n \nروش  گرادیان کاهشی استاندارد  \n  با استفاده از نرخ\nیری ادگ ی  \n𝛼\n  یک  \n  گام کوچک در جهت مخالف\nگراد\nان ی  برم ی\nدارد. ا\nنی  پارامتر در طول کل فرآ\nند ی  ادگ ی یری  ی دارا  کی  مقدار ثابت است  . معادله\nریاضی آن به صورت زیر  \n می :باشد \n𝜃𝑡+1 = 𝜃𝑡−𝛼. ∇𝑡(𝜃𝑡) \n که در آن𝜃𝑡\n  \n پارامترها/وزن\nی ها  \n  مدل در\nدوره 𝑡\n ،\n∇𝑡(𝜃𝑡)\n  گراد\nان ی  ی برا  \n هر وزن𝜃𝑡\n  \n در دوره𝑡 \n و\n𝛼\n  \n  نرخ\nیری ادگ ی  \n.است  گراد ان ی  \n  کاهشی\nاستاندارد، مستقل از مراحل قبل\nی،  \n  با اندازه گام ثابت در\nسراش\nی یب  حرکت م ی.کند  \n  اگر تابع هدف شما ه د مانن  کی  \n دره  طوالن\nی  با  نه ی به\nهای محلی   و \nدی\nوارها\nی  ش ی ب\nدار در دو طرف باشد  \n  (شکل3\n-\n3\n  \n)را ببینید\n، بروزرسان\nی  \n وزن\nها  ار ی بس  \n  کند\n95 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nخواهد بود  و  منجر به تعداد ز\nی اد ی  مرحله م ی\nشود  .ی برا  حل ا\nنی  موضوع، تکانه به الگور\nتم ی  \nگراد\nان ی  \n کاهش\nی  اضافه م ی\nشود\nده ی . ا  اصل\nی  \n تکانه، اضافه کردن حافظه کوتاه\nمدت به گراد\nان ی  \n کاهش\nی  است  ،. به عبارت دیگر\nبه جا\nی  استفاده از گراد\nان ی  مرحله فعل\nی  ی برا  تی هدا  \n  ،جستجو\nتکانه،  \n گرادیان\nهای  \n گام\nی ها  گذشته را ن\nزی  ی برا  ن یی تع  جهت انباشته م ی.کند  نیا  مکان سم ی  را م ی  توان\n  به\nصورت  ریز  اجرا کرد: \n𝜃𝑡+1 = 𝜃𝑡−𝑣𝑡 \n𝑣𝑡= 𝛾. 𝑣𝑡−1 −𝛼. ∇𝑡(𝜃𝑡) \nدر ا\nین  \n  ،معادالت𝛾  \n  عبارت\nتکانه  است که ت ریثا  گراد ی ان\nی ها  ی قبل  را بر بروزرسان\nی  ی فعل  یی تع ن  \nم ی\nکند. ا\nده ی  ی کل  نیا  است که ا\nنی  عبارت را تا حد امکان نزد\nیک  \n  به1\n  قرار ده\nمی  و برا\nی  \n نرخ\nیری ادگ ی  مقدار\nی  تا حد امکان باالتر انتخاب  کرده،  در حال\nی  که همگرا\nیی  دار ی پا  \n  را حفظ ک می مین . \n \n شکل3\n-\n3\n. \n مصورسازی تابعGriewank\n \n  تکانه با اضافه کردن تار\nی\nخچه  به معادله بروزرسان\nی  پارامتر بر اساس گراد\nی ان ی  \n  که در\nب\nروزرسان ی ها ی  ی قبل  \n با آن مواجه شده  است  ،تغ\nیی یر  در گراد\nان ی  \n کاهش ی  \nبوجود می آورد (به نوعی یک حافظه به آن اضافه می)کند  \n که به همگرا\nیی  ی سر ع تر  \n منجر م\nی\nشود . \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 96 \n \n \n گرادیان کاهشی تسریع\nشده نستروف  (\nNAG\n)   \nاس یق  ی توپ  \n  که از\nدره  غلت م\nزند ی  و از طر\nقی  تکانه  سرعت م\nیگی،رد   ی ژگ یو  ی خوب  ی برا  اده یپ\nساز ی  \nبه نظر م\nی\nرسد\n. با ا\nین  \n  ،حال\nکی  توپ وقت\nی  \n در دره باشد متوقف نم\nی\nشود،  یب\nشتر  \n  و بیشتر  خواهد\nچرخ\nدی  تا زمان\nی  که ه\nچی  سرعت\nی  ی باق  \n  .نماند\nاز طرفی، اگر در طرف دیگر  \n  دره\nیک  سرباال\nیی  \nوجود داشته باشد، ا\nنی  امر باع\nث م ی\nشود  توپ در نها\nیت  \n  به عقب برگردد، اما قبل از توقف توپ\n  در\nنقطه\nیِ کمینه  \n دره، نوسان\nها ی  متعدد\nی  خواهد داشت( . نستروف1983\n)،  یا ده یا  را برا ی  \nجلوگ\nیری  از باال رفتن ب\nشی  از حد توپ در سرباال\nیی  مطرح کرد. برا\nی  \n محاسبه اندازه گام در دوره\nی فعل،  گرادیان  را در مکان تق\nیر یب  که توپ با استفاده از تکانه استاندارد به پا\nان ی  م ی\nرسد،  \n  محاسبه\nم ی\nکند. سپس، از ا\nی ن گراد\nان ی ی برا یا\nجاد کی اصالح استفاده م\nی\nشود \n که\nبه و ژه ی  در موارد ی \n که\nشیب  \n سرباال\nیی  در محل تقر\nی بی  \n  ،وجود دارد\nمناسب  \n  .است این کار سبب می  شود تا  از اندازه\n گام\nی ها  یلیخ  بزرگ که به طرف د گر ی  دره م رود ی،  یری وگ جل  کند  .\n  نستروف\nاین  \n  روش را به\nصورت  \nریز  یپ اده\nی ساز  م ی:کند \n𝜃𝑡+1 = 𝜃𝑡−𝑣𝑡 \n𝑣𝑡= 𝛾. 𝑣𝑡−1 −𝛼. ∇𝑡(𝜃𝑡−𝛾. 𝑣𝑡−1) \n این روش\nگراد ان ی  کاهش\nی  تسر عی\nشده  نستروف  (\nNesterov Accelerated Gradient Descent\n)  \n  یا\n به اختصارNAG\n  \n نامیده می .شود\nنقطه ضعف ا\nین \n روش محاسبه∇𝑡(𝜃𝑡−𝛾. 𝑣𝑡−1)\n  \n  است که\nم ی\nتواند برا\nی  برخ\nی  از شبکه ها از نظر محاسبات\nی  \n زمان بر باشد. سوتسکور1  \n( و همکاران2013\n )\nپی\nشنهاد  م کی ن  ند که محاسبه𝑣𝑡\n  به روش ز\nیر  \n  اصالح\nشود: \n𝑣𝑡= 𝛾. 𝑚𝑡+ 𝛼. ∇𝑡(𝜃𝑡) \n𝑚𝑡= 𝛾. 𝑚𝑡−1 + 𝛼. ∇𝑡(𝜃𝑡) \nالگوریتم های گرادیان کاهشی درkeras\n \n  هنگام استفاده ازKeras\n  ،برای انتخاب بهینه  ،ساز\nم ی\nتوان  با نمونه\nی ساز  مستق\nیم  \n  کالسSGD\n  \n و\n  استفاده از آن در\nزمان  کامپا\nلی  مدل،  نه ی به  ساز( گرادیان کاهشی تصادفیSGD\n)  \n  را  سفارشی\n(\ncustomize\n)  \n :کرد \nfrom tensorflow.keras.optimizers import SGD \n... \nsgd = SGD(learning_rate=0.0001, momentum=0.8, nesterov=True) \nmodel.compile(optimizer=sgd, loss = ..., metrics= ...) \n \n1 Sutskever \n97 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n  کالسSGD\n  \n  پارامترlearning_rate\n  \n  (نرخ ری ادگ ی ی  با تنظ\nمی  پ ی فرض ش  ی رو  \n0.01\n )، تکانه  \n(momentum)، نستروف  \n(\nnesterov\n)  با یک مقدار بولین  \n  و یک  \n پارامتر واپاش\nی  (\ndecay\n )  \nاخت\nی ار ی  را  م رد ی پذ ی  .\n \n الگوریتم های بهنیه سازی نرخ یادگیری تطبیقی \n تمام نسخه\nی ها  گرادیان کاهشی که تاکنون معرفی شدند  ،ی برا  محاسبه بروزرسان\nی  \n  هر پارامتر\n  ،منفرد  از نرخ\nی ادگ ی یر  ی\nکسان\nی  استفاده م ی  .کنند\nاما نکته اینجاست که\n، اطالعات گراد\nان ی  \n  کی در  \nبروزرسان\nی  \n،منفرد  م ی\nتواند برا\nی   کی  پارامتر بس ار ی  \n مهم\nتر از  یک  پارامتر د\nگر ی  باش\nد  .\n از این  ،رو در\n نی چن یطی شرا \n پارامتر\nی با \n بروزرسانی\nهای مهم،تر دی با گام بزرگتر ی در جهت گراد\nان ی \n  بردارد تا\nپارامتر با بروزرسان\nی  \n کم\nتر مهم. به عبارت د\nگر ی ،  ی برا  سرعت بخش\nدن ی  به فرآ\nند ی  یری ادگ ی،  \n  هر\nپارامتر\nی  که با\nدی  بروز شود،  دی با  \n  نرخ\nیری ادگ ی  \n.خاص خود را در هر دوره داشته باشد \n  از\nاین\nرو، الگور\nتم ی\nی ها  متفاوت\nی  ی برا  حل ا\nین  \n مشکل در جهت تطب قی  \n  نرخ\nیری ادگ ی  \n در مراحل\nمختلف الگور\nتم ی ارائه شده است  تا همگرا\nیی ی سر تر ع شبکه را \n.بوجود آورند \n  در ادامه به بررسی\nبرخی از این الگوریتم ها می.پردازیم \nAdagrad\n \nی\nافتن  \n  نرخ\nیری ادگ ی  نه ی به  ی برا  کی  الگور\nتم ی  یری ادگ ی  عمیق  م ی\nتواند  کی  مشکل پ\nده یچی  باشد  .\n اگر نرخ\nی ادگ ی یر یلیخ باال تنظ\nمی شود، پارامتر ممکن اس\nت با نوسانات ز\nی اد ی \n  حرکت کند تا به\nسطح قابل قبول\nی  \n  از\nزیان  برسد. از طرف د\nی،گر  تنظ\nیم  \n  نرخ\nیری ادگ ی  ار ی بس  ن یی پا  منجر به پ\nی شرفت  \nار ی بس  \n .کند خواهد شد  \nAdagrad\n  \n  ،برای این منظور ارائه شد\nیی جا  که انتخاب دست\nی  نرخ\nی ها  \nیری ادگ ی  مختلف برا\nی  هر بعد از مسئله به دل\nلی  حجم ابعاد غ\nی\nرعمل\nی  است  .\nAdagrad\n  به  طور\n تطب\nیقی  \n  پارامتر نرخ\nیری ادگ ی  را برا\nی  هر بعد مق\nی اس\nبندی  می\nکند  \n تا اطم\nنان ی  حاصل شود که فرآ\nند ی  \nآموزش نه خ\nی یل  کند است و نه خ یلی  فرار و نادق\nیق\n. برا ی  انجام ا\nنی  کار، الگور\nی تم  \nAdaGrad\n  \n  به\nصورت پو\nای  دانش هندسه داده\nی ها  \n مشاهده\nشده در تکرارها\nی  گذشته را ترک\nبی  م کند ی\n. سپس ،  \nنیا  دانش را برا\nی  تنظ\nیم  \n  نرخ ادگ ی\nیری  تر ن یی پا  ی برا  و ژگ ی ی ها ی  \n متداول\nتر  \n  و\nنرخ\nی ها   ادگ ی\nیری \nبا\nالتر  ی برا  و ژگ ی ی ها ی  نسبتا نادر  اعمال م\nکند ی\n. در نت\nی ،جه  ی ها ی ژگ یو  نادر برجسته م\nی\nشوند  \n  و\nی ادگ ی\nرنده  را قادر م ی\nسازد  تا و\nی ی ها ی ژگ  نادر و در ع\nنی  حال بس\nار ی  پیش  گویانه\nرا شناسا\nیی  \n.کند \n  نیا در  \n  روش نرخ\nیری ادگ ی  جداگانه برا\nی  هر پارامتر مدل،  \n بر اساس تار\nی\nخچه  کامل گراد\nی ان\nی ها  \n  مجذور پارامتر محاسبه می\nشود\n. گراد\nان ی  \n  مجذور\nمشابه  اب  اهمیت  گراد\nان ی  \n است. آن\nها برا\nی  \n  هر\n  پارامتر\nحساب  م ی  شوند و نرخ\nیری ادگ ی  \n ی فعل  با تقس\nمی  گرادیان  ی فعل  بر مجذور گراد\nان ی  \n  به اضافه\nکی  مقدار کوچک  𝜀  (برا\nی  جلوگ\nیری  از تقس\nمی  بر صفر) محاسبه م ی\nشود. ا\nین  \n  ،بدان معناست که\nهر چه گراد\nی ان\nی ها  \n بدست\nآمده قبل\nی  بزرگ\nتر باشند، گراد\nی ان  ی فعل  \n اهم\nتی  ی تر کم  \n دارد و در نت\nجه ی \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 98 \n \n \n  نرخ\nیری ادگ ی  \n  و  بدین ترتیب\nاندازه گام در دوره فعل\nی  \n  .کوچکتر خواهد بود  معادله ریاضی این\nروش به :صورت زیر است \n𝜃𝑡+1 = 𝜃𝑡−𝛼. ∇𝑡(𝜃𝑡)\n√𝐺𝑡+ 𝜀\n \n𝐺𝑡= 𝐺𝑡−1 + ∇𝑡(𝜃𝑡)2 \nالگوریتم \nAdagrad\n \n درkeras\n \nبا  استفاده از  \n قطعه کد زیر می\nتوان از بهینه  سازAdagrad\n  در  \nKeras\n  \n :استفاده کرد \nfrom tensorflow.keras.optimizers import Adagrad \n... \nadagrad = Adagrad(learning_rate=0.0001, epsilon=1e-6) \nmodel.compile(optimizer=adagrad, loss = ..., metrics= ...) \n \nAdaDelta\n \nده یا  پشت  الگوریتم  \nAdagrad\n  خوب است، اما الگور\nتم ی  دارا ی  برخ\nی  \n  نقاط ضعف است. پس\nاز مدت\nی،  انباشت گراد\nی ان\nی ها  مربع به مقدار ز\nی اد ی  یم  رسد که نرخ\nیری ادگ ی  \n استفاده شده در\nبروزرسان ی\nها بس\nار ی  کم م ی\nشود و از ا\nنی  رو\nبا ی تقر  نمی  توان\nچیه  یپ شرفت\nی  ای\nجاد  \n.کرد  الگور\nتم ی  \nAdaDelta ، سع\nی  یم  کند به ا\nنی  مشکل رس\nی دگ ی  \n کند، به\nی طور  که پنجره گراد\nی ان\nی ها  \n  گذشته\nانباشته بجا\nی  گرفتن کل تار ی،خ  \n.به اندازه ثابت محدود شود  برای این  ،کار بجا\nی  \n جمع  \n  تمام\nگراد\nی ان\nی ها  مجذور از ابتدا\nی  \n آموزش، فرض کن\nدی  مجموع رو به زوال\nی  نی از ا  گراد\nان ی\nها  \n  را حفظ\nم ی می کن\n. ما م\nی\nتوان\nیم  این  \n  را به عنوان\nکی  ل ست ی  در حال اجرا از جد\nدتر ی نی  \n گرادیان\nها  ی برا  \n  هر\nوزن در نظر بگ\nمیری . هر بار که وزن\nها را بروزرسان\nی  یم ی کن،م  ان ید گرا  دی جد  را در انتها\nی  \n  فهرست\nقرار م می ده ی  و قد\nی نی تر یم  را از شروع حذف م ی می کن\n. برا\nی  ی\nافتن  مقدار\nی  که برا\nی  تقس\nمی  گراد\nان ی  \nدی جد  استفاده م ی ی کن،م  همه مقاد ری  موجود در ل\nست ی  را جمع م ی ی کن،م  \n اما ابتدا همه آن  ها را بر\nاساس موقع تی  آن\nها در ل\nست ی  \n  کی در  عدد ضرب م\nی . م می کن\nری قاد  ری اخ  \n  ی در ک  \n مقدار بزرگ\nضرب م\nی\nشوند، در حال\nی که قد\nی ی تر یم ن ها در\nکی مقدار بس\nار ی کوچک ضرب م\nی\nشوند. به ا\nین \nبی ترت  مجموع در حال اجرا ما به شدت توسط گراد\nی ان\nی ها  ری اخ  ن یی تع  م ی\nشود، اگرچه به م\nزان ی  \nی تر کم  \n تحت ت\nریثا  گراد\nی ان\nی ها  ی قد م ی\nتر است.  به  ،طور خالصه\nی برا  اده یپ\nی ساز کارآمد، بجا ی  \nره ی ذخ کردن گراد\nی ان\nی ها ی قبل مربوط، از م\nانگ ی\nنی رو به زوال نما\nیی از همه گراد\nی ان\nی ها \n  مجذور\n  گذشته استفاده می.شود \nنیا  الگور\nتم ی  به طور تطب\nیقی  زان یم  بروزرسان\nی  \n وزن  ها را در هر مرحله با استفاده از مجموع\nی وزن  هر مرحله تغ\nر یی  م ی\nدهد\n. از آنجا\nیی  \n  کهAdadelta\n  زان یم   یری ادگ ی  \n وزن  ها را به صورت\n99 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nجداگانه تنظ\nمی  یم،کند  هر وزن\nی  که برا\nی  ی مدت  در ش\nیب  \n تند قرار داشته باشد، سرعت خود را\nکاهش  م ی\nدهد  \n  تا  به صورت\nخارج نشود، اما زمان\nی  که آن وزن در قسمت صاف\nی تر  قرار م یگی،رد  \nم ی\nتواند  \n گام\nی ها  بزرگ\nی تر  \n.بردارد \nی جدا از ا\nی،ن  ی نو\nسندگان مقاله روش\nی را برا\nی حذف ن\nاز ی  \n به نرخ\nیری ادگ ی از الگور\nتم ی معرف\nی  \nم ی\nکنند. آن  ها\nخاطرنشان م ی\nکنند که واحدها\nی  \n  نرخ\nیری ادگ ی  نی انگ ی و م  زوال تمام گراد\nی ان\nی ها  \nمجذور گذشته با هم مطابقت ندارند. آن\nنی ها ا  مشکل را با جا نی گز ی  \n  کردن نرخ\nیری ادگ ی  \n با\nانگ یم\nین  \n  رو\nبه  زوال د\nی گر ی،  از پارامتر مربع بروزرسان\nی  \n∆𝜃𝑡\n2\n  حل م ی\nکنند. ا\nین  \n هی شب  \n  به اهمیت  \nیی تغ\nرات  ی قبل  پارامتر است. با تقس\nمی  شه یر  \n دوم آن بر جذر  \n اهمیت  گراد\nی ان\nی ها  ی قبل  ،به مقدار ی  \nم می رس ی  که کم و ب\nیش  \n  نسبت\nاهمیت  گراد\nی ان\nی ها  ی قبل  \n است که برا\nی  بروزرسان\nی  \n  پارامترها استفاده\n  ،شده است ای  به عبارت د\nگر ی  ثات ری  گراد\nی ان\nی ها  ی قبل  بر مقدار فعل ی  \n  پارامتر. نماد\nریاضی آن  \n  به\nشرح ز\nیر  \n :است \n𝜃𝑡+1 = 𝜃𝑡−∇𝑡(𝜃𝑡). √𝐸(∆𝜃𝑡\n2)𝑡+ 𝜀\n√𝐸(∇2)𝑡+ 𝜀\n \n𝐸(∆𝜃𝑡\n2)𝑡= 𝛾. 𝐸(∆𝜃2 )𝑡−1 + (1 −𝛾) ∆𝜃𝑡\n2 \n𝐸(∇2)𝑡= 𝛾. 𝐸(∇2)𝑡−1 + (1 −𝛾)∇𝑡(𝜃𝑡)2 \n الگوریتم \nAdadelta\n \n درkeras\n \nبا  استفاده از  \n قطعه کد زیر می\nتوان از بهینه  سازAdadelta\n در  \nKeras\n  \n:استفاده کرد \nfrom tensorflow.keras.optimizers import Adadelta \n... \nadadelta= Adadelta(learning_rate=0.0001, epsilon=1e-6) \nmodel.compile(optimizer= adadelta, loss = ..., metrics= ...) \n \nRMSprop\n \nالگور\nی ی تم  که بس\nار ی  \n هی شب  \n  بهAdadelta\n  است، اما از ر اض ی\nات ی  \n ی کم  متفاوت استفاده م ی  ،کند\nRMSprop\n  نام ده ی  نی . ا د شو یم  \n  نام از\nآن\nجایی  ناش\nی  م ی  شود که از\nکی  ات ی عمل  انگ یم\nین  \n مربعات\nشه یر  (\nroot mean-squared\n)،  \n  که اغلب به اختصارRMS\n  ده ی نام  م ی\nشود، برا\nی  ن یی تع  \n تطبیقی  \nکه به گراد\nی ان ها اضافه م ی( شود\nای منتشر م\nی شود) استفاده م ی.کند \n نماد\nریاضی آن به شرح ز ری  \n:است \n𝜃𝑡+1 = 𝜃𝑡−𝛼.\n∇𝑡(𝜃𝑡)\n√𝐸(∇2)𝑡+ 𝜀\n \n𝐸(∇2)𝑡= 𝛾. 𝐸(∇2)𝑡−1 + (1 −𝛾)∇𝑡(𝜃𝑡)2 \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 100 \n \n \n الگوریتم \nRMSprop\n \n درkeras\n \nبا  استفاده از  \n قطعه کد زیر می\nتوان از بهینه  سازRMSprop\n در  \nKeras\n  \n :استفاده کرد \nfrom tensorflow.keras.optimizers import RMSprop \n... \nrms_prop = RMSprop(learning_rate=0.0001, epsilon=1e-6) \nmodel.compile(optimizer= rms_prop, loss = ..., metrics= ...) \n \nAdam\n \nالگور\nتم ی  ی ها  ی قبل  ا ده ی  ره ی ذخ  ی ست یل  از گراد ان ی  ی ها  مجذور با هر وزن را به اشتراک م ی  .گذارند\nسپس،  با جمع کردن مقاد ری  موجود در ا\nنی  یل،ست  دی شا  پس از مق\nی اس\nگذار\nی  \n آن  ،کی ها  \n ی ضر ب  \nاس ی مق  یا\nجاد  م ی\nکنند. گراد\nان ی  \n در  هر  مرحلهِی  بروزرسان\nی  بر  ا نی  مجموع  تقس\nیم  م ی\nشود. \nAdagrad\n  هنگام ا\nی\nجاد  بی ضر  ی مق اس\nی بند  \n  به همه عناصر موجود در\nلیست  \n  وزن\nی\nکسان\nی  \nم ی،دهد  در حال\nی  که Adadelta و RMSprop عناصر قد\nی م تر ی  را کم اهم\nی ت  ی تلق  م ی\nکنند  \n و\nبنابرا\nنی  سهم کم\nی تر  \n  در\nکل  دارند.   \n مربع  کردن گراد\nان ی  قبل از قرار دادن آن در ل\nست ی  از نظر ر\nاض ی\nی  دی مف  است، اما وقت\nی  یک  \nعدد را مربع م\nی ی کن ،م  ی نت جه  \n هم شه ی  مثبت است. ا\nی ن  بدان معناست که ما مس\nیر  \n  مثبت\nای  منف ی  \nبودن آن گراد ان ی  در ل\nست ی  خود را از دست م می ده ی  که اطالعات مف\nیدی  است. بنابرا\nی،ن  برا ی  \nجلوگ\nیری  از  از دست دادن ا\nنی  اطالعات، م\nی\nتوان\nمی  ست یل  دوم\nی  از گراد\nی ان\nها  \n  را بدون مجذور\nکردن آنها نگه دار\nیم\n. سپس م\nی\nتوان\nمی  از هر دو ل\nست ی  ی برا  استخراج ضر\nبی  اس ی مق  \n  خود استفاده\n نی .  ا می کن  ی رو\nکرد  الگور\nی ی تم  \n است  به  نام  تخم\nین  \n لحظه  تطب یقی  \n(\nadaptive moment \nestimation\n)  یا  \n  به طور معمولAdam\n.   \n الگوریتم \nAdam\n \n درkeras\n \nبا  استفاده از  \n قطعه کد زیر می\nتوان از بهینه  سازAdam\n در  \nKeras\n  \n:استفاده کرد \nfrom tensorflow.keras.optimizers import Adam \n... \nadam= Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-6) \nmodel.compile(optimizer= adam, loss = ..., metrics= ...) \n \n تابع زیان \n  در مرحله  ِی آموزش شبکه\nی ها  \n عصب\nی  \n  کی از  امتیاز  (\nscore\n)  ی برا  نشان دادن وضع\nتی  فعل ی  \nاستفاده م ی شود. بر اساس\nاین امتیاز، پارامترها\nی وزن به\nنه ی جستجو م\nی .شوند ،به عبارت دیگر\nیک  \n شبکه عصب\nی  با استفاده از امت\nاز ی  به عنوان راهنما، پارامترها\nی  نه ی به  را جستجو م\nی  .کند  این\n101 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nاز ی امت  \n  از طریق یک تابع\nزیان \n)(تابع ضرر\n، براساس  \n اندازه\nیریگ  زان یم  خطا ب\nنی  مقاد\nیر  پی شبی نی  \nشده و واقع\nی  محاسبه می.شود  فرمول ساده  ِریز ی،  \n  تابع\nزیان  \n  را به عنوان\nکی  معادله نشان م ی\nدهد: \n𝐿𝑜𝑠𝑠= 𝑦−𝑦̂ \n  که در آن𝑦  \n و𝑦̂  به  ترتیب به  عنوان  مقدار  واقعی  و مقدار پ ی یبش ین\nشده  هستند. \n تعریف2.3\n \n تابع زیان \nیتی کم  است که به صورت دوره یا  در طول آموزش ارز\nی ابی  م شود ی  و  زان یم  یپ\nشرفت  ادگ ی یری    را\nبیان \nکند یم . \n \nکی شبکه عصب\nی از طر\nقی  کی ند ی فرآ \n ی به نه\nی ساز \n آموزش داده م\nی شود\nو \n از ی ک \n  تابع\nزیان  ی برا  \n محاسبه خطا ب نی  مقدار پ ی نیبش ی\nشده مدل و خروج ی  \n مورد انتظار  \n)(خروجی واقعی  \n استفاده م\nی\nکند. برا\nی  اهداف مختلف آموزش، فرآ\nی ند  \n ی به نه\nساز ی \n ممکن است تابع ز\nان ی  \n  را\nکمینه  ای  بیشینه  کند ، به ا\nین  \n ی عن م  که با\nید  \n راه حل\nمناسب\nی  \n مانند مجموعه\nای  \n از پارامترها را ارز\nاب ی ی  کند تا به ترت\nی ب  \n به کم\nنی تر  ی ا  \nباالتر\nین \n.نمره برسد \n با استفاده از تابع زیان می\nتوان  نحوهِی  \n مدل\nی ساز  الگور\nتم ی  را برروری  داده  ها .ارزیابی کرد  \n  انتخاب تابع زیان به نوع مساله بستگی دارد و  برای مسائل مختلف طبقه\nبندی  \n  و رگرسیون این\n  .تابع زیان متفاوت خواهد بود  در یک مساله\nطبقه\nبندی ، قصد داریم تا یک توزیع احتماالتی برای\n مجموعه کالس\nها پیش\nبینی کنیم. حال آن  که، در مسائل رگرسیون، قصد داریم یک مقدار خاص\nرا  \n .بیابیم \n توابع زیان برای رگرسیون \nهمچنان که پیش  ،تر بیان شد\nمدل\nی ها  رگرس\nون ی  با پ\nی یبش ین  ی ک  مقدار پ\nی\nوسته  به عنوان مثال\nمت یق  خودرو، پ\nیبشی ین  وام و غ\nره ی  \n  .سروکار دارند،در این بخش  پرکاربردترین  \n  توابع\nزیان  \n  مربوط\n  به\nرگرس\nون ی  فهرست شده.اند \nMean Square Error\n \n  از\nمعروف\nترین توابع زیان در رگرسیون می  باشد، و میانگین اختالف مربعات بین مقادیر واقعی\nو پیش بینی شده را توسط معادله زیر محاسبه می  :کند \n𝑀𝑆𝐸(𝑦, 𝑦̂) = 1\n𝑛∑(𝑦𝑖−𝑦̂𝑖)2\n𝑛\n𝑖=1\n \n  که در آن𝑛\n  تعداد نمونه.های آموزشی است \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 102 \n \n \nبا  استفاده از  \n قطعه کد زیر می  توان از تابع زیانMean Square Error\n در  \nKeras\n  \n:استفاده کرد \nfrom tensorflow import keras \n... \nloss_fn = keras.losses.MeanSquaredError() \nmodel.compile(loss=loss_fn, optimizer=..., metrics= ...) \n \nMean Absolute Error\n \n  این تابع میانگین\nاختالف قدرمطلق بین مقادیر واقعی و پیش  بینی شده را توسط معادله\nزیر محاسبه می :کند \n𝑀𝐴𝐸(𝑦, 𝑦̂) = 1\n𝑛∑|𝑦𝑖−𝑦̂𝑖|\n𝑛\n𝑖=1\n \nبا  استفاده از  \n قطعه کد زیر می  توان از تابع زیانMean Absolute Error\n در  \nKeras\n  \n :استفاده کرد \nfrom tensorflow import keras \n... \nloss_fn = keras.losses.MeanAbsoluteError() \nmodel.compile(loss=loss_fn, optimizer=..., metrics= ...) \n \n توابع زیان برای\nطبقه بندی \nدر ا\nنی  بخش توابع ز\nان ی  \n  مربوط به\nطبقه\nبندی  \n فهرست شده.اند \nCross Entropy\n \nنیا  تابع فاصله ب\nنی  دو توز\nی ع  احتمال را محاسبه م کند ی  و به صورت ز\nری  فی تعر  م ی\nشود: \n𝐶𝑟𝑜𝑠𝑠 𝐸𝑛𝑡𝑟𝑜𝑝𝑦(𝑦, 𝑦̂) = 1\n𝑛∑𝑦𝑖\n𝑛\n𝑖=1\nlog(𝑦̂) \nبا  استفاده از  \n قطعه کد زیر می  توان از تابع زیانCross Entropy\n در  \nKeras\n  \n :استفاده کرد \nfrom tensorflow import keras \n... \nloss_fn = keras.losses.CategoricalCrossentropy() \nmodel.compile(loss=loss_fn, optimizer=..., metrics= ...) \n \nBinary Cross Entropy\n \nی برا  طبقه\nبندهایی  دودو\nیی  \n  ازBinary Cross Entropy\n  استفاده م\nی\nشود  که به صورت ز\nی ر  \nفی تعر   م ی\nشود: \n𝐵𝑖𝑛𝑎𝑟𝑦 𝐶𝑟𝑜𝑠𝑠 𝐸𝑛𝑡𝑟𝑜𝑝𝑦(𝑦, 𝑦̂) = −1\n𝑛∑(𝑦𝑖\n𝑛\n𝑖=1\nlog(𝑦̂) + (1 −𝑦𝑖)(1 −log(𝑦̂))) \n103 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nبا  استفاده از  قطعه کد زیر می  توان از تابع زیانBinary Cross Entropy\n  در  \nKeras\n  \n :استفاده کرد \nfrom tensorflow import keras \n... \nloss_fn = keras.losses.binary_crossentropy \nmodel.compile(loss=loss_fn, optimizer=..., metrics= ...) \n \n پس انتشار \nیری ادگ ی  \n  کی در  \n شبکه عصب\nی  با چند\nنی  هیال  به\nطور کل\nی  \n هی شب  \n  نحوه\nیری ادگ ی  کی  پرسپترون است،  \n با تطب\nقی وزن\nها. با ا\nنی حال، ا\nنکه ی چگونه هر وزن با\nدی ر یی تغ \n کند کم\nی \n  دشوارتر است. در مورد\nکی  پرسپترون  ،\n ی برا  بدست آوردن خروج\nی  یک  \n  گره، تنها\nکی  ضرب داخلی  نیب  داده\nی ها  ورود ی  \nو وزن\nها مورد ن\nاز ی \n .است\nاز آنجا\nیی \n که در\nیک \nMLP\n نی چند هیال  وجود دارد، خروج ی کی \n گره\nدر آخر\nین  لایه  \n  با گرفتن\nضرب داخلی  \n وزن\nها و خروج\nی  \n گره\nها در ال\nهی  ی قبل  ن یی تع   م ی\nشود. ا\nین  \nمقاد\nری  ری اخ  \n  هر کدام به\nکی  روش محاسبه م ی\nشوند. ا\nین  \n بدان معن\nی  است که خطا\nی  \n  بدست آمده\nدر خروج\nی  یال ه  نها\nیی  یم  تواند ناش\nی  از وزن\nی ها  هیال  \n آخر و همچن نی  وزن\nی ها  هیال\n(های) قبلی \nباشد. بنابرا\nنی  سوال ا نی  است که  مسبب این  \n ی خطا  بدست آمد\nه  ،\n وزن\nهای کدام الیه است\n. گاه ی  \nاوقات به ا\nنی  مشک\nل  \n تخص صی  اعتبار  (\ncredit assignment\n)  زین  م ند ی گو ی\n. روش\nی  که م ی  تواند\nاین  \n  ،مشکل را حل کند\nپس\nانتشار \n.نام دارد \nالگور\nتم ی  \n پس انتشار احتماال اساس\nنی تر ی  \n  بلوک سازنده در کی  \n شبکه عصب\nی  \n است. پس  انتشار\nاساسا تدب\nری  هوشمندانه\nیا  ی برا  محاسبه مؤثر گراد\nان ی  \n در شبکه\nی ها  \n عصب\nی  چندال\nیه  \n  .است  این\nالگوریتم از قاعده زنجیره ای حساب دیفرانسیل استفاده می\nکند و گرادیان خطا را در مسیر  های\nمختلف از یک گره تا خروجی محاسبه می\nکند  و از دو فاز اصل\nی  \n  به نام فاز\nجل ورو (پیش)رو  \n  و\n  فاز( عقبگرد\nپس\nرو)  تشک\nیل  م ی\nشود  .\n  \n  ،در این الگوریتم  ِپس از هر گذر جلورو در  کی  \n ،شبکه\n پس انتشار\nیک  \n گذر عقبگرد\nانجام م ی\nدهد و در ع\nنی حال پارامترها ی مدل (وزن ها و با\nی اس\nها  )\nرا تنظ\nمی  کند یم.  \nالگور\nتم ی  \n پس انتشار اجازه م\nی\nدهد تا گراد\nان ی  کی  هیال  \n  را در\nیک  \n زمان به روش ی  \nکارآمد محاسبه کن\nی،د  از مقاد\nری  محاسبه شده مجدد استفاده کن\nید  \n و از آخر\nی ن \nلایه \n از طر\nقی قانون زنج\nی ای ره \n .عقبگرد کنید \nبه  طور خالصه و  کی در  سطح بس\nار ی  \n  ،باال\nبر اساس آن  ،چه تاکنون بیان شد\nیک  \n شبکه عصب\nی \nنیا  مراحل را در طول آموزش  نی چند  \n  مرتبه\nتکرار  و  اجرا م\nی کن  د (شکل3\n-\n4\n:)\n \n▪  کی فاز جلورو ی برا دی تول خروج\nی بر اساس پارامترها\nی ی فعل و داده\nی ها ورود\nی \n▪ محاسبه تابع زیان ی برا شکاف ب نی خروج ی ها ی ی فعل و خروج ی ها ی \n  هدف \n▪  کی فاز عقبگرد ی برا محاسبه گراد ان ی زیان نسبت به پارامترها \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 104 \n \n \n▪  کی  مرحله به ی نه\nی ساز  که از گراد ان ی\nها برا\nی  بروزرسان\nی  پارامترها استفاده م\nی  کند تا\nزیان ی برا تکرار بعد\nی \n کاهش ابد ی.\n \n \n شکل3\n-\n4\n. \n فرآیند آموزش یک شبکه عصبی \n وزن\nدهی \n اولیه\nی پارامترها \nکی  عنصر بس\nار ی  مهم  در طراحی شبکه\nهای عصبی  ،مقداردهی  هی اول  وزن\nها  \n.است  در شبکه\nها ی \n عصب\nی،  مقدارده\nی  هی اولِی  \n وزن\nها با\nدی  با دقت بس ی ار ی  انتخاب شود. برا\nی  مثال، اگر چند\nین  \n  نورون در\nیک  لایهِی  \n پنهان، وزن\nی ها  مشابه\nی  داشته باشند، گراد ی ان\nی ها  ی کسان\nی  را در\nی افت  \nخواهند کرد  . در نتیجه، هنگام\nتصح\nحی  گراد\nان ی  همه نورون  ها به\nیک  \n  شکل بهسازی می شوند. به\nعبارت دیگر، برای همه آن  ها\nجی نتا  ی\nکسان\nی  محاسبه م\nی\nشود  که منجر به هدر رفتن ظرف\nی ت مدل\nم ی\nشود.  بنابرا\nی،ن  \n شبکه معادل دنباله\nیا  از ال\nی ها هی  تک نورون\nی  \n.است \nاگر پ\nی\nکربند\nی  نها\nیی  را م\nی\nدانست\nمی  (یا حتی به طور تقریبی می)دانستیم،  یم\nتوانست\nیم  \n آن ها را\nی طور  تنظ\nیم  \n می کن  که براحت\nی  در چند تکرار به نقطه به\nنه ی  برسند.  اما، متأسفانه  ما  \n می دان ی نم  \n  که\nبهنیه محلی در  کجا قرار دارد. از ا\nین\nرو، راهبردها\nی  تجرب\nی  \n  با هدف  کمینه کردن  زمان آموزش\n  توسعه\nی\nافته  و آزم\nا یش  \n اند ه شد  .در حالت ا\nی ده،آل  انس ی وار\nی ها  فعال\nساز با\nدی  با ی تقر  \n  در سراسر\n شبکه و همچن\nنی  ی وار انس\nی ها \n وزن پس از هر مرحله\nپس\nانتشار ثابت باقی بمانند\nنی . ا \n  دو شرط\nبه منظور بهبود فرآ\nند ی  همگرا\nیی  و جلوگ\nیری  \n  از مشکالت  محو و انفجار\nگراد ان ی  اساس\nی  هستند . \nبه  طور معمول، وزنِهای  شبکه\nی ها  \n عصب\nی  ب\nا استفاده از ی\nک  \n ی توز ع  گاوس\nی  با م\nانگ ی\nین  \n  صفر و  \nیک  \n  انحراف\nمعیار  کوچک مقدارده\nی  هی اول  یم\nشوند  .نی با ا  \n  ،حال مشکلی که وجود دارد این  \n است که توز\nی ع  خروج\nی ها ی  کی  \nِنورون  به\nطور تصادف\nی  مقداردهی اولیه،شده  ی دارا  ی وار انس ی  \nاست که با تعداد ورود ی\nها افزا\nشی م ابد یی\n. برا\nی نرمال کردن وار انس ی خروج\nی \n هر نورون به1\n  ،\n ی کاف  \n  است از\nیک  \n ی توز ع  \n نرمال استاندارد استفاده کن\nدی  و وزن را بر اساس جذر گنجا\nشی  ورود  ی  \n𝑛𝑖𝑛، که تعداد ورود\nی ها ی  آن است، مق\nاس ی  \n دی کن: \n105 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n𝑤0~ 𝒩(0,1)\n√𝑛𝑖𝑛\n \nاین  \n  روش\nی مق اس\nی بند  وار انس ی  \n(\nvariance scaling\n)  ده ی نام  یم\nشود  و  م\nی  تواند عالوه  بر \nاستفاده از تعداد واحدها\nی  ورود\nی  (\nFan-In\n  ،)\n  براساس\nتعداد واحدها\nی  خروج\nی  (\nFan-Out\n  )ی ا  \nانگ یم\nین  \n آن\nها اعمال شود. ا\nنی  ده یا  ار ی بس  شهود\nی  است،  اگر تعداد اتصاالت ورود\nی  ای  خروج ی  \nاد یز  هستند ، وزن\nها با\nدی  کوچکتر باشند تا از خرو\nی ها یج  بزرگ جلوگ\nیری  \n.شود \nبا  استفاده از  قطعه کد زیر  \n  درKeras\n  می  توان ازvariance scaling\n \n :استفاده کرد \nfrom keras import initializers \ninitializer = initializers.VarianceScaling(scale=1.0, mode='fan_in', \ndistribution='normal') \nگلورت  و  بنج\nوی  تجز\nهی  و  تحل\nی یل  را  بررو\nی  گراد\nی ان\nی ها  \n پس\nانتشار  انجام  دادند  و ی ک  \nمقدارده\nی  هی اول  (معروف به مقدارده\nی  هی اول  \nXavier) را توص\nیه  \n:کردند \n𝑤0~√\n2\n𝑛𝑖𝑛+ 𝑛𝑜𝑢𝑡\n𝒩(0,1) \nیی جا  \n  که𝑛𝑜𝑢𝑡\n  \n  تعداد\nواحدها\nی  خروج\nی  را توص فی  م ی.کند  نیا  کی  نوع قو ی  تر  از روش\n  قبلی\nاست،  چراکه  هم اتصاالت ورود\nی  و هم اتصاالت خروج\nی  \n  (که به نوبه خود اتصاالت\nورود\nی  هستند) را در نظر م\nرد یگی\n. هدف ،  تالش برا\nی  برآوردن دو الزام ارائه شده قبل\nی  \n.است \nثابت شده است که مقدارده\nی  هی اول  \nXavier\n در بس\nی ار ی  از معمار\nی ها ی  \n قی عم ار ی بس  \n  موثر است\nو اغل\nب  انتخاب پ\nشی .فرض است \nبا  استفاده از  \n  قطعه کد زیر  درKeras\n  می  توان ازXavier\n \n:استفاده کرد \nfrom keras import initializers \ninitializer = initializers.GlorotNormal() \n \nهدف از مقدارده\nی  \n هی اول  \n وزن\nها\n، جلوگ\nیری  \n  از انفجار\nای  محو  خروج ی ها ی  فعال\nساز ها \nدر طول مس\nیر  \n  عبور از\nکی  شبکه عصب\nی  عم قی  \n  است. اگر\nیکی  از ا\nین  \n دو اتفاق\nیب،فتد  گراد\nی ان\nی ها  \n)خطا (زیان  ای  \n خیلی  \n  بزرگ\nیا  خی لی  \n کوچک خواهند بود که\nبه طور سودمند به عقب جر\nان ی   دا یپ  نم ی\nکنند.  ی حت  اگر اصال بتواند ا\nین  \n  کار را\nانجام دهد شبکه زمان ب\nی\nشتر\nی نیاز دارد تا همگرا شود . \n \n همه  ا\nین  \n روش\nها  اصول  مشترک\nی  \n دارند  و  در  بس\nی ار ی  \n از  موارد  قابل  تعو ی ض  \n هستند. همان  ،طور که قبال ذکر شدXavier\n   یکی  از قو نی تر ی  \n  هاست و در اکثر\nمسائل کارکرد خوبی دارد  .نی با ا  حال، فقط اعتبارسنج\nی  ب\nرروی  \n  مجموعه داده\nواقع\nی  م ی  تواند این را د یی تأ کند . \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 106 \n \n \nپارامتر ها \n در هر شبکه عصب\nی  \n،عمیق  \n  :دو نوع پارامتر مختلف وجود دارد کی  نوع پارامتر مدل و د\nگر ی ی  \nاَبَر\nپارامتر  (\nhyper parameter\n ). پارامترها\nی  مدل آن دسته از پارامترها\nیی  هستند که به  طور\n  خودکار توسط\nمدل  از داده\nی ها  آموزش\nی  شناسا\nیی  م ی  .شوند  ،در مقابل\nاَبَرپارامتر\nها  \n  آن دسته از\nپارامترها\nیی  ه\nستند که قابل تنظ\nمی هستند و با\nدی ی برا بدست آوردن بهتر\nنی عملکرد مدل تنظ\nیم  \n.شوند  \n  ،به عبارت دیگر\nاین  \n  پارامترها در طول آموزش\nآموخته نمی\nشوند،  اما در شروع فرآ\nی ند  \nیری ادگ ی  توسط کاربر تنظ\nمی  یم.شوند  اَبَرپارامتر  ها\nکل فرآ\nند ی  \n  یادگیری در شبکه عصب ی  \n را تحت\n تاثیر قرار می\nدهند\n. برخ\nی  از اَبَرپارامتر\nها  شامل تعداد ال\nی ها هی  \n پنهان است که ساختار شبکه را\nن یی تع  م ی  کند. نرخ\nی ادگ ی یر  کی  \n  اَبَرپارامتر\nدیگر است  که به درک نحوه آموزش شبکه کمک م ی  .کند\nانتخاب اَبَرپارامتر به\nنه ی  \n نقش مهم\nی  در کل فرآ\nند ی  آموزش شبکه  \n .دارد \n تعریف3.3\n \n ابرپارامتر \n ،ابرپارامترها\nآرگومان\nیها مدل هستند که مقدار آن\nها قبل از شروع فرآ\nند ی یری ادگ ی \n می تنظ یم\nشود . \n \nابرپارامترها \n  را می توان به\nعنوان داشبورد\nی  با کل\nی ها د  و شماره\nیی ها یریگ  \n  در نظر\nدیری بگ  \n که نحوه\nی  عملکرد الگور\nتم ی  \n را کنترل م ی\nکنند.  \n تنظ\nمی  ابرپارامترها ی  \n مختلف اغلب به مدل\nیی ها \n با عملکرد متفاوت منجر م ی\nشوند. \nتعمیم \n و منظم سازی \n هدف اصل\nی  از ساخت یک مدل یادگیری عمیق، یادگیری  کی  \n تابع  ای  \n  یک( وظیفهtask\n)  \n می  .باشد\n  برای\nدست\nی اب ی  \n،به این هدف  به شبکه داده های آموزشی را تغذیه می  کنیم. پس از  آموزش\nی ک \nشبکه\nی  \n عصب\nی  با گراد\nان ی  کاهش\nی  و پس\nانتشار  ،فرض م ی می کن  نی که ا  عملکرد خوب رو\nی  داده\nها ی \nده ید نشده باق\nی  م ی\nماند  (ی ی عن  داده\nیی ها  که در طول آموزش درگ ری  \n نشده)اند  .حال آن  ،که  لزوما\nاین بدان  \n ا معن  ست ین  که  \n مدل  قادر به پ\nیبشی ین  درست خروج ی  ی برا  داده\nی ها  ده ید\nنشده  \n  .هم باشد\nبنابرا\nی،ن  دو مجموعه اضاف\nی  از داده\nها برا\nی  به نه ی\nی ساز  معرف\nی  م ی،شوند  مجموعه اعتبارسنج\nی  \nو مجموعه آزما\nیشی\n. هر سه مجموعه داده از هم مستقل هستند، به طور\nی  که ه\nچی  نمونه\nای  \n در\nنیب  آن\nها مشترک ن\nست ی . \nمجموعه اعتبارسنجی در شبکه  های عصبی، معموال برای تنظیم دقیق ابرپارمترهای مدل مانند\n معماری شبکه یا نرخ یادگیری استفاده می  شود. مجموعه آزمون فقط برای ارزیابی نهایی در\nراستایِ بررسی عملکرد شبکه در داده\nهای دیده نشده استفاده می\nشود. اگر یک شبکه ی عصبی به\n  خوبی ت\nعمیم  نیابد  (تی قابل  انتقال دانش به داده\nی ها  یغ\nرقابل  \n مشاهده را تعم\nی م   \n)گویند ، یعنی\nزیانِ آموزشِ کم  تری نسبت به زیانِ آزمون داشته باشد، به این حالت\nبیش\nبرازش  گفته می .شود\n107 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n در حالی که سناریوی معکوس، زمانی که زیان آزمون نسبت به زیان آموزش بسیار کم  ،تر باشد\nکم\nبرازش  \n نامیده می  شود (شکل3\n-\n5\n  .)\n \n \n شکل3\n-\n5\n. رفتار تعم\nی ده می در منحن\nی ادگ ی\nیری با توجه به مع\nار ی دقت در داده\nی ها آموزش\nی \n و آزمون \nبیش\nبرازش پد\nی یا ده  است که در نها\nتی  همه شبکه\nی ها  \n عصب\nی  را تحت ت\nاثیر  \n قرار م ی .دهد\nنیا  به  دل\nی ل  نیا  واقع\nتی  است که  آن\nها  فقط  از  مجموعه  داده\nی ها  آموزش\nی  اد ی  م رند یگی:  \nریز مجموعه\nیا  از تمام داده\nی ها  ممکن.  که نیا  آن\nها در ا\nنی  ریز مجموعه چقدر خوب عمل\nم ی\nکنند،  ن یی تع  یم\nکند که وز ها ن ی  \n  آنها چقدر پاداش\nیا  مه ی جر  \n بشود\n. به عبارت د\nی،گر  ی حت  \n اگر\n  هدف ما دانش تعم\nمی  باشد\n، خود شبکه\nها برا\nی  دست\nی اب ی  به دقت باال در مجموعه داده\nی ها  خاص ی  \nطراح\nی \n شده\nاند. به ا\nنی ی ترت،ب \n آن\nها در نها\nیت \n با توجه به توانا\nیی انجام ا\nین  \n  کار، شروع به حفظ\nمجموعه داده\nی ها  خود خواهند  کرد. ا\nین   به\nخاطر سپردن باعث م\nی  شود شبکه\nمنجر به بیش\nبرازش  \nشود. شبکه\nیا  که ب\nیش\nبرازش را آغاز کرده است، و\nژگ ی ی ها ی  منحصربه\nفرد و جزئ\nات ی  \n خاص\nداده\nیا  را که به طور انحصار\nی  در مجموعه د\nاده\nی ها  آموزش\nی  افت ی  م ی،شود  \n  به خاطر\nمی\nسپارد  \n  آن و\nها  را به\nعنوان مفاه\nیِم  کلِی  مشترک در همهِی  ورود\nی ها ی  \n  داده مشابه  به\nاشتباه م\nرد یگی.  بنابرا\nین  \n نی چن  شبکه\nا ی  ی برا  تجز\nهی  و تحل\nلی  ورود\nی  ها\nدی جد  \n( و ناآشنا\nمجموعه داده آزما\nیشی)،  \n  زمان\nدشوارتر\nی  خواهد داشت. ا\nنی  به ا\nنی  لی دل  است که بخش\nی  \n  از\nصفات متمایزکنندهِی  شناسا یی  \nشده قبل\nی،  در داده\nی ها  دی جد  وجود ندار\nن\nد. عالوه بر ا\nی،ن  با افزا\nشی  دقت شبکه در طول آ ،موزش  \nشکاف ب\nنی ی خطا یا\nجاد شده در طول آموزش و خطا\nی دی تول شده در طول آزما\nشی زین افزا\nی ش  \nم ابد یی\n. با ا\nنی حال، گاه\nی اوقات هنگام تالش برا\nی حل وظا فی \n ار ی بس یچیپ،ده \n استفاده از\nیک  \nمدل پ\nده یچی  \n اجتناب\nناپذ\nری  است. افزودن ال\nی ی ها ه  یب\nشتر  ای  \n نورون\nها  یب،شتر  سطح ب\nی\nی شتر  \n  از\nاستخراج و\nی ژگ ی  را ممکن م\nی\nسازد  \n  یم که  تواند منجر به\nیک  \n  سطح باالتر از دقت تا\nیک  \n  نقطه\nخاص م ی .شود \nبه طور معمول، بیش\nبرازش و کم برازش در شبکه  های عصبی عمیق، مستقیما با ظرفیت مدل\nمرتبط ا\nست. به زبان ساده، ظرفیتِ مدلِ یک شبکه\nیِ عصبیِ عمیق، به طور مستقیم با تعداد\n پارامترهای داخل شبکه در ارتباط است. ظرفیت مدل تعیین می کند که یک شبکه عمیق تا چه\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 108 \n \n \nحد قادر به برازش با طیف گسترده ای از توابع است. اگر ظرفیت خیلی کم باشد، شبکه ممکن\nاست نتواند مجموعه  آموزشی را تطبیق دهد (کم برازش)، در حالی که ظرفیت مدل خیلی بزرگ\nممکن  است  منجر به  حفظ  نمونه\nهای  آموزشی (بیش  .برازش)  شود\nکم برازش  معموالً برای\nشبکه\nهای عصبی عمیق، مشکل چندانی ندارد. چراکه این مشکل را می  توان با استفاده از معماری\nشبکه\nیِ قوی  تر یا\nعمیق.تر با پارامترهای بیشتر برطرف کرد  \n با این حال، برای اینکه بتوان از\nشبکه\nهای عمیق برای داده های جدید و دیده نشده استفاده کرد، باید بیش  .برازش را کنترل کرد\n فرآیند کاهش اثر بیش  برازش یا جلوگیری از آن را\nمنظم\nساز( یregularization\n)  می  .گویند\nمنظم\nی ساز  روش\nی  ی برا  کنترل ب ی ش  برازش\nای  بهتر است بگو\nم یی  بهبود خطا\nی تعم\nیم  \n  .است \nمناسب بودن داده\nی ها  آموزش\nی  \n  را  نیز\nدی نبا  ده ی ناد  گرفت.  چراکه  موفق\nیت  \n در تعم\nمی  ای  حت ی  \nبرازش کاف\nی  در داده\nی ها  \n آموزش\nی  نی به ا  امر بستگ\nی  دارد. در غ\nیر  ا ین  \n  صورت، مدل ممکن است\nلی تما  داشته باشد که ب\nشی  از حد با و\nژگ ی ها یِی  \nِخاص  داده\nهاِی  آموزش\nی  سازگار شود. ا\nین  \n  امر از\nیک  \n  طرف\nبه  مقدار داده\nی ها  موجود برا\nی  آموزش بستگ\nی  \n  ،دارد\nچراکه  \n  ممکن است\nیک  \n مجموعه\nآموزش\nی  کوچک برا\nی  تشخ صی  الگوها و ساختارها\nی  ی کل  ی کاف  نباشد و از طرف د\nگر ی  به ک تیفی  \nداده\nی ها  آموزش\n؛ی  به و\nژه ی  \n  در مورد\nیری ادگ ی  باِنظارت در مورد  \nِصحت  \n برچسب\nهاِی  \n  هدف که از\nقبل توس\nط  \n  انسان\nای  ی حت  متخصصان انسان\nی  تنظ\nمی  شده است. عالوه برا\nی،ن  \n اطم\nنان ی  از ا\nنکه ی  \nی توز ع  ی ها ی ژگ ی و و  داده\nی ها  آموزش\nی  با داده\nی ها  \n  آزمون مطابقت دارد\nای  به طور کل\nی  با داده\nیی ها \nکه مدل آموخته\nشده برا ی  استفاده در آ\nی نده  برنامه\nیزیر  شده است مطابقت داشته باشد، ضرور ی  \n  .است \nتوقف زودهنگام (\nEarly stopping\n )\n \n در آموزش مدل\nی ها  بزرگ، معموال خطا\nی  آموزش و اعتبارسنج\nی  در طول زمان کاهش م یی،ابد  \n  اما در\nکی  نقطه ،  خطاِی  اعتبارسنج\nی  شروع به افزا\nشی  کند یم\n. در ا\nین  \n مرحله، مدل شروع به\nبیش\nبرازش  م کند ی  ژگ ی و و ی ها ی  \n خاص مجموعه آموزش\nی  \n  را اد ی   رد یگیم\n. برا\nی  توقف در ا\nی ن  \nمرحله از رو  ش توقف زودهنگام\nاستفاده م ی  .شود  ،این روش\nی مدل  که کم\nنی تر  ی خطا  اعتبارسنج\nی  \nرا دارد برم\nی  .گرداند\nبنابرا\nی،ن  \n  آموزش به\nکی  مجموعه اعتبارسنج\nی  ن از ی  دارد تا به صورت دوره\nا ی \nی خطا  اعتبارسنج\nی  را ارز\nی اب ی  \n .کند \n  ،در این روش\nآموزش پس از اول\nنی  افزا\nشی  ی خطا  اعتبارسنج\nی  \n متوقف نم\nی  .شود  ،بلکه شبکه\nتا رس\nدن ی  \n\" به آستانه\nتعداد دوره\nی ها  \n بدون پ\nی\nشرفت  \" آموزش\nبیشتری می\nبیند  .\n  ،سپس\nاز طر\nیق  \nی اب ی ارز  دوره\nی ها  بعد\nی،  \nِروند  خطاِی  اعتبارسنج\nی  را برا\nی  آموزش ب\nی\nشتر  افت ی در  م ی می کن . به\n  عنوان مثال، اگر10\n  بار متوال\nی  ی خطا  اعتبارسنج\nی  \n نسبت به بهتر\nنی  ی خطا  اعتبارسنج\nی  هی چ  \nپی\nشرفت\nی  نداشته باشد، آموزش متوقف م ی\nشود و مدل\nی  که بهتر\nنی  ی خطا  اعتبارسنج\nی  \n را دارد\nبرگردانده م ی.شود \n109 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n \n شکل3\n-\n6\n. \n توقف زودهنگام \n  ،توقف  زودهنگام  به  نظارت  عملکرد  مدل\nدر  \n  هر  دوره\nبراساس  \n  مجموعه\nاعتبارسنج ی  \n می\nپردازد  \n  و  خاتمه\nآموزش  \n را  مشروط  به  عملکرد  اعتبار\nسنج\nی \nمی.داند \nحذف تصادف\nی  (\nDropout\n )\n \n  ،حذف تصادفی\nکی  روش منظم\nی ساز  ی برا  شبکه\nی ها  \n عصب\nی  است. ا\nده ی  یدی کل  نیا  \n است که\n نورون\nها به\nصورت تصادف\nی در هر \n تکرار آموزش حذف\nشوند .\n اگر کی نورون \n حذف شود، همه\n گرادیان\nهای  وابسته صفر هستند و بنابرا\nین  \n وزن مربوط بروز نم ی  .شود  فرآیند اجرای  این  روش\nبه  این صورت است که در هر دوره  \n  تکرار  آموزش، با یک احتمال𝑝\n  \n هر نرون باقی و با احتمال\n(1 −𝑝)\n \n از شبکه حذف خواهد شد. این عمل باعث خواهد شد که در هر\nدوره \n تمام ویژگی ها\nیاد\nگرفته نشوند و با هر  بار ورود\nیک  داده ویژگی  های متفاوتی از آن برای\nطبقه\nبندی  استفاده  \n  .شود\n  در شکل3\n -\n4\n  \n  یک شبکه عصبی معمولی و یک شبکه عصبی همراه با حذف تصادفی قابل\n.مشاهده است \n \n شکل3\n-\n6\n. \n ( یک شبکه عصبی الف) قبل از حدف تصادفی و (ب) بعد از حذف تصادفی \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 110 \n \n \nمتداول  ترین تفسیر از اثر\nحذف تصادفی  نیا  \n است که به طور ضمن\nی  گروهی  (\nensemble\n)  \n از\n مدل ها را آموزش م ی.دهد \n چراکه در\nهر تکرار نسخه متفاوت\nی از مدل را ا\nی\nجاد م ی  کند و هر وزن\nبا مجموعه وزن\nی ها  ی گر ید  بروز م ی  .شود\nری ادگ یِی  گروهی  از چند\nنی  مدل،  کی  \n کی تکن  جی را  \n در\nیادگیری ماشین  ی برا  کاهش خطا\nی  \n تعم\nی م  نی با ا  یا ده  \n  است که\nی ک   پیشبی نی  \n  نادرست از\nیک  \n مدل\nواحد م\nی تواند توسط مدل\nی ها  گر ید  \n.جبران شود \nاز سو\nی  ید،گر  حذف تصادفی  \n ی را م\nتوان ا\nی ن\nگونه تفس\nیر  \n کرد که شبکه عصب\nی  \n  مجبوربه بازنمایی  \n اضاف\nی  از دانش بدست آمده از طر\nقی  یری ادگ ی  است.  چراکه  دانش خاص\nی  \n در مورد کالس  ای ها  \nورود\nی ها ی خاص لزوماً در برخ ی از تکرارها در دسترس ن\nی،ست به دلیل اینکه دانشی که در این\n نورون\nها برای این ورودی ها رمزگذاری شده است، در حال حاضر حذف شده.اند  از این رو، برای\nیک شبکه عصبی دشوار است  تا  ی رو بر  نمونه\nی ها  آموزش\nی  خاص،  \n بیش\nبرازش  \n  ،کند\nچراکه  \n برخی  \n نورون\nی ها  \n  خاص\nهمیشه  قابل دست\nی اب ی  ست ین.ند \nبا  استفاده از  \n  قطعه کد زیر  درKeras\n  می:توان به حذف تصادفی دسترسی پیدا کرد   \nfrom keras.layers import Dropout \nfrom keras.models import Sequential \n \nmodel = Sequential() \n... \nmodel.add(Dropout(0.5)) \nنرمال\nی ساز دسته\nای (\nBatch Normalization\n )\n \n  آموزش\nکی  شبکه،  \n وزن\nی ها  هر  ال\nهی  را  تغ\nر یی  یم\nدهد.  ا\nی ن  ر یی تغ  باعث  م\nی  شود که\nتوز\nی ع \n(\ndistribution\n)  ورود\nی  در طول بروزرسان\nی  یال ی ها ه  ی قبل  ر یی تغ  کند،  نیا  \n   اثر\nر یی تغ  ری متغ  داخل\nی   \n(\ninternal covariate shift\n  )نام ده ی  \n می\nشود  .این مشکل از آن جا ناشی می\nشود که پارامتر  ها در\nطول فرآیند آموزش مدام تغییر می کن ن د، این تغییرات به نوبه خود مقادیر توابع فعال  سازی را\nتغییر می\nدهد. تغییر مقادیر ورودی از الیه\nهای اولیه به الیه  های بعدی سبب همگرایی کندتر در\nطول فرآیند آموزش می\nشود، چرا که داده\nهای آموزشی الیه\nهای بع  .دی پایدار نیستند به  \n  عبارت\nدیگر\n، شبکه  های عمیق ترکیبی از چندین الیه با توابع مختلف بوده و هر الیه فقط یادگیری\nبازنمایی کلی از ابتدای آموزش را فرا نمی گیرد، بلکه باید با تغییر مداوم در توزیع  های ورودی با\nتوجه به الیه\nهای قبلی تسلط پیدا کند. حال آن  که\nبهینه\nساز بر این فرض ب\nروزرسانی  پارامتر  ها را\nانجام می\nدهد که در الیه\nهای دیگر تغییر نکنند و تمام الیه\nها را هم  زمان\nبروز  \n می  کند، این عمل\nسبب نتایج ناخواسته.ای هنگام ترکیب توابع مختلف خواهد شد  \n  در راستای\nمقابله با تغ\nر یی  \n ی توز ع  \n  در طول\nیری ادگ ی،  \n نرمال\nی ساز  \n دسته\nیا  معرفی شد  .\n  ،در این روش نرمال\nسازی  \n بر\nروی داده  های\n  ورودی یک الیه را به\nگونه\nای انجام می  .دهد، که دارای میانگین صفر و انحراف معیار یک شوند\n111 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n  با قرار دادن نرمال\nسازی  دسته\nای بین الیه  های پنهان و با ایجاد ویژگی واریانس مشترک، سبب\nکاهش تغییرات داخلی الیه\nهای شبکه می.شویم \nاز طر\nیق  \n اعمال نرمال\nی ساز  دسته\nای   می\nتوان   زان یم  \n نرخ  ادگ ی\nیری  را افزا شی  \n  داد و\nنیا  امر منجر به آموزش سر ی تر ع   یم\nشود\n. عالوه بر ا\nی،ن  دقت در مقا\nی\nسه  \n  با همان\n شبکه بدون نرمال\nی ساز دسته\nای \n در حال افزا\nیش  \n .است \nبا  استفاده از  \n  قطعه کد زیر  درKeras\n  می توان از نرمال سازی دسته:ای استفاده کرد   \nfrom keras.layers import BatchNormalization \nfrom keras.models import Sequential \n \nmodel = Sequential() \n... \nmodel.add(BatchNormalization()) \n پیاده\nسازی شبکه عصبی \n  درkeras\n \nنی در ا  بخش  نحوه پ\nاده ی\nی ساز  \n شبکه عصب ی  پیش\nخور  \n  درKeras\n  را خواه\nیم  \n  .آموخت برای اولین\n،مثال  \n شبکه عصب\nی  ی برا  یبشیپ ین  نکه یا  مت یق  خانه  ها باالتر\nای  یی پا تر ن  \n  از مقدار متوسط است  را\n می.سازیم \nمجموعه داده\nیا  که استفاده خواه\nمی  کرد از داده\nی ها1  مسابقه  \nKaggle\n  \n  برای\nپیشبی نی  \n  ارزش\nخانه ز\nلو ی اقتباس شده است. ما تعداد و\nی ها ی ژگ ی ورود\nی را کاهش داده\nمیا و کار را به پ\nیشبی ن ی \nنکه یا  یق مت  \n  خانه باالتر\nای  کم\nتر از مقدار متوسط  است  ر یی تغ  داده\nایم\n. برا\nی  \n دانلود2  م جموعه  \n داده\nاصالح شده از پ\nوند ی .ی که در پانویس قرار دارد استفاده کنید \n  قبل از\nکدنو یسی  برای ساخت هر مدل یادگیری ماشین\n، اول\nنی  کار ی  که با\nدی  انجام ده\nیم  ا ی ن  \nاست که داده\nی ها  \n خود را در قالب\nی  قرار ده\nیم  \n  که\nبرای الگوریتم مناسب باشد  .\n  ،برای این مثال\n کارهای زیر را انجام می:دهیم \n▪ \n  ابتدا\nی فا ل CSV \n  را می\nخوانیم  \n و آن\nها را به آرا\nهی  لی تبد  \n می\nکنیم\n. آرا\nیه\nها فرمت داده\nا ی  \nهستند که الگور\nتم ی  ما م ی\nتواند آن\nها را پردازش کند. \n▪ مجموعه داده خود را به و\nی ها ی ژگ ی  ورود\nی که آن را 𝑥 \n  و برچسب  که آن را 𝑦 م ی نام ی م  \nتقس\nیم  \n می\nکنیم. \n▪ داده\nها را نرمال\nی ساز  \n می .کنیم \n▪ مجموعه داده را به مجموعه آموزش\nی،  مجموعه اعتبارسنج\nی  \n  و مجموعه\nآزمون  تقس\nی م  \n می\nکنیم . \n \n1 https://www.kaggle.com/c/zillow-prize-1/data \n2 https://drive.google.com/file/d/1h6LPHNs4F_FnxwfdE_fCIsGeEh30tDBf/view?usp=sharing \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 112 \n \n \nد یی ایب  \n شروع کن\nمی  !ابتدا  کتابخانه  \npandas\n  \n  را وارد می،کنیم  کد ز\nیر  \n  را  در سلولnotebook\n  \n  خود\n  تایپ  کرده وAlt+Enter\n  \n  را:فشار دهید \nimport pandas as pd \nنیا  فقط به ا\nین  \n معن ا  \n\" است که اگر بخواهم به کد موجود در بستهpandas\n \" اشاره کنم، آن را با\n  نامpd\n  ارجاع خواهم داد. سپس با اجرا\nی  \n  کد\nزیر  لی فا  \nCSV\n  \n  خود را\nمی\nخوان\nیم: \ndf = pd.read_csv('housepricedata.csv') \nنیا  خط کد به ا\nین  \n ا معن  است که ما فا\nیل  \n'housepricedata.csv'\n  را م ی\nخوان\nمی  و آن را در متغ\nیر \ndf\n  ره ی ذخ  یم می کن  . اگر بخواهیم  \n بفهم\nیم  \n  درdf\n  چه چ\nزی ی  وجود دارد، کاف\nی  \n  استdf\n  \n  را در  سلول\nnotebook\n  تا پی  \n  کرده وAlt+Enter\n  \n  را:فشار دهید \ndf \nخروجی  شما با\nید  چیزی  \n هی شب  \n نی به ا  \n :باشد \n \nی ها ی ژگ یو  ورود\nی  ما  \n  در ده ستون اول  .هستند\nدر آخر\nین  \n  ،ستون)ویژگی (برچسب  را دار\nیم  \n  که\nم ی\nخواه\nیم پیشبی نی \n ی کن م :ایآ مت یق خانه باالتر از م\nانگ ی\nین \n است\nای ر؟ یخ (\n1 ی برا \n بله و0 ی برا \nریخ).  اکنون که د\nمیدی  داده\nها چگونه به نظر م\nرس ی ن،د  یم\nخواه\nمی  آن\nها را به آرا\nیی ها هی  لی تبد  \n ی کن م \nتا ماش\nین  \n آن\nها را  \n :پردازش کند \ndataset = df.values \nی برا  لی تبد  ید\nتافر\nیم  (\ndataframe\n)  خود به آرا\nی،ه  فقط مقاد\nیر  \ndf\n  \n  را (باdf.values) در متغ\nی ر  \ndataset\n  ره ی ذخ  یم می کن\n. برا ی  د دن ی  آنچه در داخل متغ\nیر  \"\ndataset\" وجود دارد، کاف\nی  \n است \ndataset\n   \n  را در\nسلول  \nnotebook\n  خود تا\nیپ  \n دی کن  \n و سلول را اجرا کن\nید  (\nAlt+Enter\n:)\n \ndataset \nهمان\nطور که م یبی ین،د  \n  اکنون همه در\nکی  هی آرا  ره ی ذخ  ن شو یم:د \narray([[ 8450,     7,     5, ...,     0,   548,     1], \n       [ 9600,     6,     8, ...,     1,   460,     1], \n       [11250,     7,     5, ...,     1,   608,     1], \n       ..., \n113 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n       [ 9042,     7,     9, ...,     2,   252,     1], \n       [ 9717,     5,     6, ...,     0,   240,     0], \n       [ 9937,     5,     6, ...,     0,   276,     0]]) \nا\nکنون مجموعه داده خود را به و ی ها ی ژگ ی  ورود\nی  (\nX) و و ی ژگ ی  که م\nی\nخواه\nیم  پیشبی ن ی  \n ی کن م \n(\nY) تقس\nمی  م ی می کن\n. برا\nی  انجام ا\nنی  تقس\nی،م  ما به سادگ\nی  \n10\n  ستون اول آرا\nهی  خود را به متغ\nیر ی \n  به نامX\n  و آخر\nنی  ستون آرا\nهی  خود را به متغ\nیری  \n  به نامY\n  اختصاص م می ده ی\n. کد انجام اول\nین  \nانتساب  نی به ا  \n:صورت است \nX = dataset[:,0:10] \nاین  \n ممکن است کم\nی  ی عج ب  به نظر برسد، اما اجازه ده\nدی  تا آن\nرا شرح  دهم که چه چ یزی  \n در\nداخل  \n[]\n  قرار دارد\n. همه چ\nی ز  قبل از کاما  (,)  به رد\nی ها فی  هی آرا  و همه چ زی  \n  بعد از کاما به\n ستون\nی ها هی آرا \n اشاره دارد. از آن\nیی جا که سطرها را از هم جدا نم\nی ی کن،م \":\" \n  را قبل از کاما قرار\nم می ده ی  .نیا  به ا\nین  \n ا معن  \n است که تمام سطرها\nی  مجموعه داده را بردار\nمی  و آن را در X \n  قرار\nی . م می ده\nخواه\nی م  \n10\n  \n ستون اول را استخراج کن\nی،م  بنابرا\nین  \"\n0:10\n\"  بعد از کاما به معنا\nی  \n  گرفتن\n ستون\nی ها  \n0\n  \n  تا9\n  و قرار دادن آن در X است  (\n  ستون10\n  \n  را شامل\nنمی\nشود ). ستون\nی ها  \n  ما از\n  شاخص0  شروع م ی\nشوند، بنابرا\nین  \n10\n  ستون اول ستون\nی ها  0  \n تا9  هستند. \nسپس  آخر\nنی  ستون آرا\nیه  \n  خود را بهY\n  اختصاص م\nمی ده ی : \nY = dataset[:,10] \nاکنون  مجموعه داده خود  را به  و\nی ها ی ژگ ی  ورود ی (X) و  برچسب،  \n  یعنی\nآنچه  م ی\nخواه\nیم \nپی شبی نی  \n می کن (Y) تقس\nمی  کرده\nایم\n. مرحله بعد\nی  پردازش ا\nین  \n است که اطم\nنان ی  \n حاصل کن\nیم  \n که\nاس ی مق  ژگ یو ی ها ی  ورود\nی  مشابه است. در حال حاضر، و\nژگ ی یی ها ی  مانند مساحت زم\nین  \n  به\nصورت  ر هزا،  ی امت از  ی برا  ک تیفی  ی کل  \n  از1  \n  تا10\n  ری متغ  است و تعداد شوم\nنه ی  \n  ها0\n  ،\n1  یا  2  \n  .است\nنیا  امر شروع اول\nی ه  \n شبکه عصب\nی  را دشوار م\nی\nکند که باعث ا\nی\nجاد  برخ\nی  مشکالت عمل\nی  یم.شود \nیکی  از راه\nی ها  ی مق اس\nی ساز  داده  ها استفاده از بسته scikit-learnاست.  ابتدا  آن  را  \n  وارد\nمی می کن : \nfrom sklearn import preprocessing \n  کد باال\nم دی گو ی  که من م ی  خواهم از کدpreprocessing\n  \n  در بستهsklearn\n  \n  ،استفاده کنم. سپس\nاز تابع\nی  به نام مق\nی اس\nکننده  \nmin-max\n  استفاده م ی می کن  که مجموعه داده  را به\nگونه\nیا  ی مق اس\nی بند  \nم کند ی  که همه و\nی ها ی ژگ ی  ورود\nی  بین  0 \n  و1  قرار بگ\nرند ی: \nmin_max_scaler = preprocessing.MinMaxScaler() \nX_scale = min_max_scaler.fit_transform(X) \nتوجه داشته باش\nید  \n  که ما0  \n  و1  را برا\nی  \n کمک به آموزش شبکه عصب\nی  خود انتخاب کرد\nمی  . اکنون\nمجموعه  داده\nی ها  ی مق اس\nشده  ما  در  آرا\nیه  \nX_scale\n  ره ی ذخ  م ی\nشود.  اگر  م ی\nخواه\nید  \n ی بب دین \nX_scale \n \n چه شکل\nی  است، به سادگ\nی  سلول  زیر  \n را اجرا کن\nی:د \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 114 \n \n \nX_scale  \n  ،بعد از اجرای کد باال  خروجی :زیر را خواهید دید \narray([[0.0334198 , 0.66666667, 0.5       , ..., 0.5       , 0.        , \n        0.3864598 ], \n       [0.03879502, 0.55555556, 0.875     , ..., 0.33333333, 0.33333333, \n        0.32440056], \n       [0.04650728, 0.66666667, 0.5       , ..., 0.33333333, 0.33333333, \n        0.42877292], \n       ..., \n       [0.03618687, 0.66666667, 1.        , ..., 0.58333333, 0.66666667, \n        0.17771509], \n       [0.03934189, 0.44444444, 0.625     , ..., 0.25      , 0.        , \n        0.16925247], \n       [0.04037019, 0.44444444, 0.625     , ..., 0.33333333, 0.        , \n        0.19464034]]) \nاکنون، به آخر\nنی  مرحله خود در پردازش داده\nها رس\nی یا ده،م  ی ی عن  تقس\nیم  \n  مجموعه داده به\nی ک \nمجموعه آموزش\nی،  کی  مجموعه اعتبارسنج\nی  \n  کی و  مجموعه آزم)ون (آزمایشی.  \n  برای این منظور\n  از کدscikit-learn\n  \n \" به نامtrain_test_split\" استفاده خواه\nیم  \n کرد، که همان  طور که از نام آن\nیپ،داست  \n  مجموعه داده ما را به کی  مجموعه آموزش\nی  \n  کی و  مجموعه آزما\nیشی  تقس\nمی  یم  .کند\nابتدا کد مورد ن\nاز ی  خود را وارد م\nی می کن : \nfrom sklearn.model_selection import train_test_split \n  سپس مجموعه داده خود را به صورت زیر تقسیم می:کنیم \nX_train, X_val_and_test, Y_train, Y_val_and_test = \ntrain_test_split(X_scale, Y, test_size=0.3) \n قطعه کد باال\nبه scikit-learn م دی گو ی که اندازه val_and_test ما \n30\n  از کل مجموعه داده%\nخواهد بود. کد،  داده\nی ها  تقس\nمی  شده را در چهار متغ\nری  اول در سمت چپ عالمت مساو\nی  ره ی ذخ  \nم کند ی.  \n،متأسفانه  نیا  تابع فقط به ما کمک م\nی\nکند مجموعه داده خود را به دو قسمت تقس\nی م  \n می کن\n. از آنجا\nیی  \n  که ما کی  مجموعه اعتبارسنج\nی  \n  و مجموعه\nآزمون  جداگانه م ی\nخواه\nی،م  می\nتوان\nی م  \nاز همان تابع برا\nی  انجام دوباره تقس\nیم  \n  درval_and_test\n  \n استفاده کن\nیم : \nX_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, \nY_val_and_test, test_size=0.5) \n  کد باال اندازهval_and_test\n  را به\nطور مساو\nی  به مجموعه اعتبارسنج\nی  \n  و مجموعه\nآزمون  \nتقس\nیم  م ی\nکند. به طور خالصه، ما اکنون در مجموع شش متغ\nری  ی برا  مجموعه داده\nی ها  \n خود\nمی دار  که از آن\nها استفاده خواه\nیم  \n:کرد \n▪ \nX_train \n \n▪ \nX_val \n \n▪ \nX_test \n \n▪ \nY_train \n \n▪ \nY_val \n \n▪ \nY_test \n \n115 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nاگر م ی\nخواه\nدی   ی بب ین د  که شکل آرا هی\nها برا\nی  \n  ی هر ک  از آن( ها چگونه است\nی ی عن  چه ابعاد\nی  \n ،)دارند\nبه سادگ\nی  کد زیر را  \n اجرا کن\nید: \nprint(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, \nY_val.shape, Y_test.shape) \n(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n \nهمان  طور که م یبی ین،د  مجموعه آموزش\nی  ی دارا  \n1022\n  \n نقطه داده است درحال\nی  \n  که مجموعه\nاعتبارسنج\nی  \n  و\nآزمون هر کدام  ی دارا  \n219\n  \n  نقطه داده\nهستند\n. متغ\nی\nی رها  \nX\n  دارا ی  \n10\n  ژگ یو ی \nورود\nی  هستند، در حال\nی  که متغ\nی\nی رها  \nY\n  \n  فقط\nکی  ی ژگ یو  ی برا  یپ یبش ین  \n .دارند \n  اکنون نوبت به\nساخت و آموزش اول\nین  \n شبکه عصب\nی  ما  \n  .رسیده است\nنی اول  \n ی کار  \n که با\nی د  \nانجام ده\nمی  نیا  است که معمار\nی  \n  را\nپیکره\nبندی  \n می کن . فرض کن\nید  \n شبکه عصب\nی  \n  با معماری به شکل\nزیر  م ی\nخواه\nیم : \n \nبه عبارت دیگر\nی ، م\nخواه\nیم  این \n لایه\nها را داشته باش\nیم: \n▪\n لایه  \n  پنهان1\n  :\n32\n  نورون  \n  با تابع\nفعال ی ساز  \n ReLU\n \n▪\n لایه  \n  پنهان2\n  :\n32\n  نورون  \n با تابع  فعال ی ساز  \n ReLU\n \n▪\n هیال  خروج\nی  :\n1  نورون  \n  با تابع\nفعال\nی ساز  \nSigmoid\n \nحال  دی با   نیا  \n معمار\nی  \n  را\nدر  \nKeras\n  توص\nی ف  \n می کن\n. ما از مدل  ترتیبی  (\nSequential\n  )\n  استفاده\nخواه\nمی  کرد، به ا\nین  \n معن ا  \n  که تنها  دی با  ی ها هیال  باال را به ترت\nبی  توص\nیف  \n می کن  .ابتدا، ب\nد یی ای  \n کد\n  الزم را ازKeras\n  \n وارد کن\nیم: \nfrom keras.models import Sequential \nfrom keras.layers import Dense \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 116 \n \n \nسپس، مشخص م ی می کن  که مدل ترت\nی یب  ما به ا\nین  \n:صورت است \nmodel = Sequential([ \n    Dense(32, activation='relu', input_shape=(10,)), \n    Dense(32, activation='relu'), \n    Dense(1, activation='sigmoid'), \n]) \nقا ی دق  مانند  \n  شکل قبلی\nکه معماری خود را\nترسیم کرده\nایم  ، قطعه کد باال  همین\nمعمار\nی  را تعر\nی ف  \nکرده است.  \n  قطعه\nکد باال را م ی\nتوان ا\nی\nنگونه  تفس\nری  کرد: \nmodel = Sequential([...]) \nاین  \n  دی گو یم کد  که ما مدل خود را در متغ\nی ر  \nmodel\n  ره ی ذخ  یم می کن  و آن را به صورت متوال\nی \nهی (ال  به ال\nیه\n) در ب\nنی  براکت\nها توص\nفی  م ی می کن. \nDense(32, activation='relu', input_shape=(10,))\n \n  در\nنی اول  هیال  ،ی ک  هیال  کامال متصل  \n  با32\n  نورون دار\nی ،م  \n  تابع فعال\nی ساز  \nReLU\n  \n و شکل \n(\nshape\n)  ورود\nی  \n10\n  است،  چراکه  \n  ما10\n  ی ژگ یو  ورود\nی  می دار\n. توجه داشته باش\nید  \n\" کهDense\n  \"\n  کی به  هیال  کامال  متصل اشاره دارد. \nDense(32, activation='relu'),\n \nهیال  دوم ما ن زی  ی ک  هیال  کامال متصل  \n  با32\n  نورون  \n و تابع  فعال ی ساز  \nReLU\n  \n است. توجه داشته\nباش\nدی  که ما مجبور ن\nمی ست ی  شکل ورود\nی  را توص\nیف  \n می کن،  چراکه  \nKeras\n  می\nتواند از خروج\nی  \nلایه  \n  اول ما  این را\nجه ی نت  ی بگ رد . \nDense(1, activation='sigmoid'),\n \nهیال  سوم  ما یا همان الیه خروجی  کی  هیال  کامال متصل  \n  با1  نورون  \n  و تابع\nفعال\nی ساز  \nsigmoid\n  \n.است  \n نی هم\nطور  \n  که دیدید توانستیم\nمعمار\nی  \n  مدل خود را به صورت کد.بنویسیم \nاکنون که معمار\nی  خود را مشخص کرده\nیا،م  دی با  بهتر\nنی  پارامترها  را برا\nی  آن پ\nدا ی  \n ی کن م . قبل\nاز شروع آموزش، با\nید  \n  مدل را توسط  موارد زیر\nپی\nکربند\nی  \n می کن: \n▪ به او بگو\nد یی از کدام الگور ی تم یم\nخواه\nدی ی برا انجام به\nی نه\nی ساز استفاده کن\nید .\n \n▪ به او بگو\nد یی \n از چه تابع\nزیانی استفاده کند .\n \n▪ به آن بگو\nد یی که چه مع\nی\nارها\nی د ی گر ی را م\nی\nخواه\nید \n جدا از\nتابع زیان ی اب ی رد کن.ید \nی برا  یپ\nکربند\nی  مدل با ا\nنی  تنظ\nی،مات  دی با  \n  تابعmodel.compile\n  را فراخوان\nی  \n ی کن،م  به این صورت: \nmodel.compile(optimizer='sgd', \n              loss='binary_crossentropy', \n              metrics=['accuracy']) \nتنظ\nمات ی  ریز  \n  را بعد ازmodel.compile\n  \n داخل براکت\nها قرار م ی می ده : \noptimizer='sgd',\n \n117 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n'\nsgd\n'  به گراد\nان ی  کاهشی  تصادف ی  اشاره دارد (در ا\nی،نجا  به گراد\nان ی  کاهشی  ریز دسته\nای  \n  اشاره\nدارد. \nloss='binary_crossentropy',\n \n  برای\nخروج\nیی ها ی  که مقاد\nیر  \n1\n  یا  \n0\n  را م\nیگی،رند  \n  از تابع زیان'binary_crossentropy'\n  \n(آنتروپ\nی  \n  متقاطع)دودویی  استفاده می.شود \nmetrics=['accuracy']\n \nدر نها\nی،ت  ما م ی\nخواه\nیم  \n  دقت را  نیز همراه با  تابع\nزیان  رد ی اب ی  \n می کن.  حاال وقت\nی  این  \n  سلول را\nاجرا کرد\nی،م  آماده آموزش هست\nیم ! \n  آموزش  شبکه درkeras\n  ار ی بس  ساده است و از ما م\nی  خواهد  تنها\nکی  خط کد بنو\nیسیم: \nhist = model.fit(X_train, Y_train, \n          batch_size=32, epochs=100, \n          validation_data=(X_val, Y_val)) \n  برای این کار از \" تابعfit\n  \"\n استفاده می\nکنیم  که  برازش پارامترها به داده  ها را انجام می\nدهد\nدی . با  \n مشخص کن\nمی  که رو\nی  چه داده یی ها  آموزش م می ده ی  که  توسط  \nX_train\n  \n  وY_train\n  \n  مشخص\n شده\nاند  . سپس، اندازه  ریزدسته (توسط پارامترbatch_size\n)  خود را مشخص م ی می کن  \n  و مدت\nزمان\nی  که م ی\nخواه\nمی  آن را آموزش ده\nیم  (\nepochs) مشخص م\nی می کن  . در\nی نها،ت  \n  ما مشخص\nم ی می کن  که داده\nی ها  اعتبارسنج\nی  ما چ\nست ی  تا مدل به ما بگو\nدی  در هر نقطه در مورد داده\nها ی \nاعتبارسنج\nی  \n  چگونه عمل\nمی\nشود\nنی . ا  \n  تابع\nکی  ی تار\nخچه  را تول\nید  می\nکند که آن را در متغ\nیر  \nhist\n \nره ی ذخ  یم می کن\n. زمان\nی  \n  که به\nمصورسازی  میدی رس  ،نی از ا  ری متغ  استفاد\nه  خواه\nیم  \n.کرد  \n  حاال، سلول\n را اجرا کن\nید  \n  و\nآموزش  \n آن را تماشا کن\nید  !\n  خروجی\nشما با\nدی  به شکل ز\nیر  \n :باشد \nEpoch 1/100 \n32/32 [==============================] - 0s 5ms/step - loss: 0.6990 - accuracy: 0.3542 - \nval_loss: 0.6974 - val_accuracy: 0.3699 \nEpoch 2/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4022 - \nval_loss: 0.6943 - val_accuracy: 0.4110 \nEpoch 3/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.4706 - \nval_loss: 0.6915 - val_accuracy: 0.4703 \nEpoch 4/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5499 - \nval_loss: 0.6889 - val_accuracy: 0.5616 \nEpoch 5/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6468 - \nval_loss: 0.6864 - val_accuracy: 0.6758 \nEpoch 6/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.7133 - \nval_loss: 0.6842 - val_accuracy: 0.7123 \nEpoch 7/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.7524 - \nval_loss: 0.6821 - val_accuracy: 0.7489 \nEpoch 8/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.7564 - \nval_loss: 0.6801 - val_accuracy: 0.7717 \nEpoch 9/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.7779 - \nval_loss: 0.6781 - val_accuracy: 0.8037 \nEpoch 10/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.8072 - \nval_loss: 0.6761 - val_accuracy: 0.8128 \nEpoch 11/100 \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 118 \n \n \n32/32 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.8317 - \nval_loss: 0.6740 - val_accuracy: 0.8219 \nEpoch 12/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.8239 - \nval_loss: 0.6717 - val_accuracy: 0.8265 \n. \n. \n. \n. \n. \n. \nEpoch 95/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8865 - \nval_loss: 0.3051 - val_accuracy: 0.9041 \nEpoch 96/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8816 - \nval_loss: 0.3043 - val_accuracy: 0.8995 \nEpoch 97/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8855 - \nval_loss: 0.3044 - val_accuracy: 0.9041 \nEpoch 98/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8865 - \nval_loss: 0.3030 - val_accuracy: 0.8995 \nEpoch 99/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8806 - \nval_loss: 0.3025 - val_accuracy: 0.8995 \nEpoch 100/100 \n32/32 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8816 - \nval_loss: 0.3017 - val_accuracy: 0.8995 \nاکنون م یبی دین  که مدل در حال آموزش است! با مشاهده اعداد، با\nدی  بتوان\nید  \n  کاهش\nزیان  \n  و\nافزا\nیش  \n دقت را در طول زمان مشاهده کن\nید\n. در ا\nنی  مرحله، م ی\nتوان\nید  \n  با\nابر\nپارامترها\nی  \n  مختلف\n شبکه عصب\nی  \n  را\nآزما\nیش  \n دی کن\n. سلول ها را دوباره اجرا کن\nید  \n تا بب ی دین  ی وقت  \n  که\nابر پارامترها\nی  خود \nرا تغ\nر یی داده\nیا،د  آموزش شما چگونه تغ\nر یی می .کند\nهنگام\nی  که از مدل نها\nیی خود راض\nی  ی بود،د  \nم ی\nتوان\nدی  آن را در مجموعه آزما یشی  ارز ی اب ی  \n دی کن\n. برا\nی  ی\nافتن  دقت در مجموعه آزما\nی شی  \n  ،خود\nنیا  قطعه کد را اجرا م\nی می کن: \nmodel.evaluate(X_test, Y_test)[1] \nلی دل  نکه یا  \n  ما شاخص1  \n را بعد از تابع model.evaluate می دار  نیا  \n  است که تابع\nزیان  \n  را به عنوان\nعنصر اول و دقت را به عنوان عنصر دوم برم\nی  .گرداند\nاز آن  جایی که\nی برا  \n  نمایش\nخروج\nی  \n دقت\nکاف ست ی ، از این طریق می\nتوان به آن دسترس\nی داشته باش\nدی. به لی دل \n تصادف\nی \n بودن\nنحوه تقس\nیم \nمجموعه داده\nها  \n و همچن\nنی  مقدارده\nی هی اول \n وزن\nها  ، هر بار کهnotebook\n \n خود را اجرا م ی ی کن،م \n اعداد و نمودار کم\nی  متفاوت خواهند بود. با ا\nنی  وجود، اگر از معمار\nی  \n  که در باال مشخص شده  \nی رو یپ  کرده باش\nی،د  دی با  دقت آزمون را ب\nین  \n80\n  \n  تا95\n  درصد در\nی افت  \n دی کن!  \n:همانند خروجی زیر \n7/7 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8584 \n0.8584474921226501 \n تبریک می\nگویم! شما توانستید  نی اول  \n شبکه عصب\nی  \n  خود را\nطراحی کرده  \n  و آن را آموزش .دهید \n در بخش  های قبلی در مورد \n بیش برازش و برخ\nی  \n ی تکن ی ها ک  منظم\nی ساز  صحبت کرد\nیم.  \n  حاال\n چگونه بفهم\nیم  \n  که مدل ما در حال حاضر بیش\nبرازش شده است؟  \n ی کار  \n  که می  ،توانیم انجام دهیم\nاین  \n  است که از\nزیان آموزشی  \n  و\nزیان  اعتبارسنجی  را بررو\nی  تعداد دوره\nی ها  ی سپر  شده ترس\nیم \n می کن\n. برا\nی  مصورسازی  \n این،ها  \n  از بستهmatplotlib\n  استفاده م ی می کن\n. طبق معمول، با\nدی  ی کد  \n  را\nکه م ی\nخواه\nیم  \n استفاده کن\nیم \n وارد کن\nیم : \nimport matplotlib.pyplot as plt \n119 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nسپس، م ی\nخواه\nمی  زیان  \n  آموزش و\nزیان  \n اعتبارسنج\nی  \n  را مصورسازی  \n می کن\n. برا\nی  انجام ا\nین  \n  ،کار\nاین  \n قطعه کد را اجرا کن\nید: \nplt.plot(hist.history['loss']) \nplt.plot(hist.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='upper right') \nplt.show() \n  ما\nهر خط از قطعه کد باال را توض\nحی  خواه\nیم  \n داد. دو خط اول م\nدی گو ی  که م ی\nخواه\nیم  \nloss\n  \n  و\nval_loss\n  را ترس\nیم  \n می کن\n. خط سوم عنوان ا\nنی  نمودار را مشخص م\nکند ی:  \nModel loss\n .  \n  خط\n چهارم و پنجم به ما م دی گو ی  \n  که محورy  \n  وx  به ترت\nبی  دی با  \n چه برچسب\nی  \n  داشته باشند. خط ششم\n  شامل کی  شرح  ی برا  \n  نمودار ما است و مکان\nشرح  در سمت راست باال خواهد بود  \n  و خط هفتم\n  بهjupyter notebook\n  م دی گو ی  که نمودار را نما\nیش  \n.دهد  خروجی  شما با\nید  چیزی  \n هی شب  نی به ا  \n :باشد \n \nما م ی\nتوان\nیم  \n نی هم  کار را برا\nی  ترس\nمی  دقت آموزش\nی  \n  و\nدقت  اعتبارسنج\nی  با کد ز\nری  انجام ده\nیم :\n \nplt.plot(hist.history['accuracy']) \nplt.plot(hist.history['val_accuracy']) \nplt.title('Model accuracy') \nplt.ylabel('Accuracy') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='lower right') \nplt.show() \nشما با\nدی  نمودار\nی  \n که کم\nی  \n هی شب  نی به ا  در خروجی دریافت کنید: \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 120 \n \n \n \nاز آنجا\nیی  که پ\nی شرفت\nی ها  مدل ما در مجموعه آموزش\nی  تا حدود\nی  با بهبود مجموعه اعتبارسنج\nی  \n مطابقت دارد، به نظر نم\nی\nرسد  \n  که\nبیش\nبرازش مشکل  بزرگ\nی  در مدل ما باشد  (با این حال می  توان\nآن را از طریق بهینه)سازی ابرپارمترها بهبود بخشید. \n به منظور معرف\nی \n منظم\nی ساز \n به شبکه عصب\nی خود، ب\nد یی ای \n ی با ک \n شبکه عصب\nی \n فرموله کن\nیم \n  که\nبه شدت در مجموعه آموزش\nی  مطابقت داشته باشد\n. ما ا\nین  \n  راmodel_2\n  م می نام ی. \nmodel_2 = Sequential([ \n    Dense(1000, activation='relu', input_shape=(10,)), \n    Dense(1000, activation='relu'), \n    Dense(1000, activation='relu'), \n    Dense(1000, activation='relu'), \n    Dense(1, activation='sigmoid'), \n]) \n \nmodel_2.compile(optimizer='adam', \n              loss='binary_crossentropy', \n              metrics=['accuracy']) \n               \nhist_2 = model_2.fit(X_train, Y_train, \n          batch_size=32, epochs=100, \n          validation_data=(X_val, Y_val)) \nدر ا\nی،نجا  \n  کی ما  مدل بس\nار ی  \n بزرگتر ساخته\nمیا  و از به\nنه ی  \n  سازAdam\n  استفاده م ی می کن  .\nAdam\n  \nیکی  از را\nی نی تر ج  نه ی به\nسازها\nیی  \n  است که\nدر معماری\nهای شبکه\nهای عصبی استفاده می\nشود،  \n به\nدلیل این\nکه  ی سر تر ع  \n  به\nزیان  کم\nتر م ی\nرسد\n. اگر ا\nین  کد  \n را اجرا کن\nمی  و نمودارها\nی  زیان  را برا ی  \nhist_2\n با استفاده از کد ز\nیر \n رسم کن\nمی (توجه داشته باش\nید \n که کد\nی\nکسان است با ا\nین \n  تفاوت که\nبه جا\nی  \nhist\n  \n  ازhist_2\n  \n استفاده م\nی می کن:)\n \nplt.plot(hist_2.history['loss']) \nplt.plot(hist_2.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \n121 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='upper right') \nplt.show() \n  کی ما  نمودار  به صورت  زیر  افت ی در  م ی می کن : \n \nاین  \n  نشانه بارز بیش\nبرازش  \n  .است\nزیان  آموزشی  \n  در حال کاهش است، اما\nزیان  اعتبار\nسنجی  ی بس ار  \n  باالتر از\nزیان  آموزشی  \n  و  در حال\nافزا\nشی  است  .\n  اگر دقت را با\nاستفاده از کد ز\nری  ترس\nیم  \n می کن : \nplt.plot(hist_2.history['accuracy']) \nplt.plot(hist_2.history['val_accuracy']) \nplt.title('Model accuracy') \nplt.ylabel('Accuracy') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='lower right') \nplt.show() \n همچن\nین  می\nتوان\nیم  \n تفاوت واضح\nی تر  نیب  \n  دقت\nآموزشی  و اعتبارسنج\nی  را   ی بب مین : \n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 122 \n \n \nاکنون، ب\nد یی ای  برخ\nی  \n از استراتژ ی ها ی  خود را برا\nی  \n  کاهش\nبیش برازش  \n امتحان کن\nمی  .در  بخش  های\nپیشین ما چندین روش را برای جلوگیری از بیش\nبرازش معرفی کردیم  .\n با این حال، در این بخش\nما تنها از  \n  حذف تصادفی استفاده می\nکنیم.  ابتدا، ب\nد یی ای  ی کد  را که برا\nی  حذف تصادفی  از ین  ی دار م  \n  را وارد کن\nیم : \nfrom keras.layers import Dropout \nسپس مدل سوم خود را به صورت ز\nری  مشخص م ی می کن: \nmodel_3 = Sequential([ \n    Dense(1000, activation='relu',  input_shape=(10,)), \n    Dropout(0.5), \n    Dense(1000, activation='relu'),  \n    Dropout(0.5), \n    Dense(1000, activation='relu'),  \n    Dropout(0.5), \n    Dense(1000, activation='relu'),  \n    Dropout(0.5), \n    Dense(1, activation='sigmoid'),  \n]) \nآیا  م ی\nتوان\nدی  تفاوت ب\nین  \n  مدل3  \n  و مدل2  را تشخ\nصی  د؟ ی ده  یک  تفاوت اصل\nی  \n :وجود دارد \nی برا  \n  اضافه کردنDropout\n  ،کی  هیال  دی جد  مانند ا\nنی  اضافه کرد\nیم: \nDropout(0.5),\n \nنیا نی به ا \n معن ی است که نورون\nی ها هیال ی قبل  در ح\nی ن آموزش \n0.5\n  \n احتمال\nحذف دارند. ب\nد یی ای \n آن را کامپا\nلی  کرده و با همان پارامترها\nی  \n  مدل2  \n خود اجرا کن\nی م . \nmodel_3.compile(optimizer='adam', \n              loss='binary_crossentropy', \n              metrics=['accuracy']) \n               \nhist_3 = model_3.fit(X_train, Y_train, \n          batch_size=32, epochs=100, \n          validation_data=(X_val, Y_val)) \nاکنون، ب\nد یی ای  نمودارها\nی  زیان  \n و دقت را رسم کن\nیم .\n \nplt.plot(hist_3.history['loss']) \nplt.plot(hist_3.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='upper right') \nplt.show() \nخروجی به شکل زیر دریافت خواهیم کرد : \n123 \n فصل\nسوم: شبکه\nهای عصبی پیش خور \n \n \nهمان طور که مشاهده می  ،شود\nزیان  اعتبار  سنجی نسبت مدل2\n   بی\nشتر  \n  با از\nزیان  آموزش  \n  ما\nمطابقت دارد  (با این حال این مدل همچنان مطلوب نیست  و مدل بیش برازش شده است)\n  .\nد یی ایب  دقت را با قطعه کد مشابه ترس\nیم  \n می کن : \nplt.plot(hist_3.history['accuracy']) \nplt.plot(hist_3.history['val_accuracy']) \nplt.title('Model accuracy') \nplt.ylabel('Accuracy') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='lower right') \nplt.show() \n  و :خروجی به صورت زیر دریافت خواهیم کرد \n \nدر مقا سه ی  \n  با مدل2، ما ب\nیش\nبرازش  را به م\nزان ی  قابل توجه\nی  کاهش داده\nایم\n! به ا\nی ن  بی ترت  \n  است\n که ما تکن\nی ی ها ک  منظم\nی ساز  را برا\nی  \n  کاهش بیش\nبرازش  \n  در مجموعه\nآموزشی  \n اعمال م ی ی کن م . \n می .توانید به عنوان تمرین، ابرپارمترها را تغییر داده و نتایج را مقایسه کنید \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 124 \n \n \nخالصه فصل \n \n▪ \n شبکه  های عصبی مصنوعی مدل محاسبات\nی  \n هستند که نحوه ی  \n عملکرد سلول\nی ها  عصب ی  \nدر مغز انسان را تقل\nدی م کند ی .\n \n▪ \n  هر\nشبکه عصب\nی  مصنوع\nی  دارا\nی   کی  ال هی  ورود\nی،   یک  لا یه  \n خروج\nی  \n  و کی   ای  چند ال هی  \n پنهان\nم ی\nباشد.\n \n▪ ساده\nتر نی  \n نوع مدل\nی ساز   کی  نورون را پرسپترون گو ند ی  \n که م ی\nتواند  دارا\nی  \n تعداد ز اد ی ی  \nورود\nی \n تنها با کی خروج\nی \n .باشد \n▪ محدود تی  اصل\nی  \n شبکه\nی ها  عصب\nی  پرسپترون، عدم توانا یی  \n در طبقه\nی بند  داده\nیی ها  \n  است\nکه جدا\nیی\nپذ ری ی خط ین\nستند .\n \n▪ هدف از فرآ ند ی   ادگ ی\nیری  \n در شبکه\nی ها  عصب\nی،   ی\nافتن  \n مجموعه\nیا  از مقاد ری  ی وزن  \n است که\nباعث م\nی\nشود  خروج\nی  شبکه عصب\nی  \n تا حد امکان با مقاد ری  هدف واقع\nی  \n مطابقت داشته\n.باشد \n▪ تابع فعال\nساز تصم\nمی رد یگیم \n  که کی نرون با دی \n فعال شود ای ریخ .\n \n آزمونک \n1\n.\n \n انتخاب نرخ یادگیری خیلی کوچک و یا خیلی\nبزرگ چه تاثیری در فرآیند یادگیری دارد؟ \n2\n.\n پدیده محو گرادیان را شرح دهید؟ \n3\n.\n \n ویژگی های مطلوب یک تابع فعال\nسازی چیست؟ \n4\n.\n \n در الیه خروجی مسائل طبقه بندی دودویی و چندکالسه از کدام تابع فعال سازی استفاده\n می شود؟ \n5\n.\n \n بهینه\nساز\nها چه نقشی \n در فرآیند یادگیری شبکه های عصبی\nدارند\n؟ \n تمرین \nیک شبکه عصبی با دو الیه پنهان  بسازید تا به  طبقه\nبندی مجموعه داده  \nIris\n  بپردازد.  نمودار  های دقت و\n زیان  .را برای مجموعه آموزشی و اعتبارسنجی در حین آموزش مصورسازی کنید \nراهنمایی بر\nای \n وارد کردن داده\nها \nfrom sklearn.datasets import load_iris \niris = load_iris() \nX = iris['data'] \ny = iris['target'] \n \nراهنمایی بر\nای \n مقیاس\nبندی داده ها \nscaler = StandardScaler() \nX_scaled = scaler.fit_transform(X) \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n4 \n \n▪\n شبکه کانولوشنی \n چیست؟ \n▪\n \n آشنایی با انواع الیه\nهای آن \n▪\n \n طبقه  بندی تصویر با شبکه عصبی کانولوشنی \n \n:اهداف یادگیری \nشبکه\nهای عصبی کانولوشنی \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 126 \n \n \n مقدمه \nنی در ا  \n فصل به معرف\nی  \n  مفاهیم\nشبکه\nی ها  \n  عصبی کانولوشن\nی   م ی\nپرداز\nنی . ا می  \n،مفاهیم  شامل اجزا ی  \nاصل\nی  \n  شبکه  هستند\nکه معمار\nی  \n  یک\nشبکه  \n  عصبی کانولوشن\nی  را تشک\nیل  م ی\nدهند  .شبکه\nها ی \n عصب\nی \n کانولوشن\nی ی برا داده\nی ها بدون ساختار \n همانند تصاویر عملکرد بسیار خوبی \n .دارند  پس\n  از آشنایی کامل با\nمعماری  \n شبکه  ،های عصبی کانولوشنی\nدر انتهای فصل  به پیاده  سازی  یک مثال\n  عملی با استفاده از شبکه عصبی کانولوشنی  درkeras\n  \n می.پردازیم \nشبکه \n( عصبی کانولوشنیCNN\n )\n \n  کی در  \n شبکه عصبی پیش\nخور  \n کامال متصل، تمام گره\nی ها  کی  یال ه  \n به تمام گره\nی ها  هیال  بعد\nی  \nمتصل م ی\nشوند. هر اتصال دارا\nی  \n  وزن𝑤𝑖,𝑗\n  است که با\nدی  توسط الگور\nتم ی  یری ادگ ی  \n .آموخته شود\n فرض کن\nدی  ورود\nی  \n  کی ما  تصو ری  \n64\n  پی\nکسل  \n  در64\n  پی\nکسل  در مق\nاس ی  خاکستر\nی  \n  است. از\nآنجا\nیی  که هر پ\nی\nکسل  خاکستر\nی  را م\nی  \n  توان با1  مقدار نشان داد، م\nم یی گو ی  \n  اندازه کانال1  \n  .است\n نی چن  تصو\nیری  را م\nی  توان با64 × 64 × 1 = 4096\n  نشان داد   (\n سطر×  ستون×  کانال)\n  . از\nنیا  رو، ال\nهی  ورود\nی  یک  \n شبکه پیش\nخور  \n که چن\nنی  تصو\nیری  را پردازش م ی\nکند دارا\nی  \n4096\n  \n  گره\n.است  فرض کنید  هیال  بعد\nی  \n500\n  \n.گره دارد  از آنجا\nیی  \n که تمام گره\nی ها  ی ها هیال  بعد\nی  کامال  \n  بهم\nمتصل هستند، ب\nنی  ورود ی  \n و اول\nین  لایه  \n  ،پنهان4096 × 500 = 2048000\n  وزن خواه\nی م \n .داشت حال آن ،که\nی برا مسائل پ یچی،ده ما معموال به چند\nین لایه \n پنهان در شبکه پیش\nخور \n  خود\nاز ین  ی دار،م  را یز  ی ک  شبکه پیش\nخور  ساده ممکن است نتواند مدل نگاشت ورود\nی\nها به خروج\nی ها\nرا در داده\nی ها  آموزش\nی  بی\nاموزد\n. داشتن چند\nنی  هیال  پنهان مشکل داشتن وزن\nی ها  اد یز  \n  در  شبکه\n پیش\nور خ  ما را تشد\nدی  م کند ی    و\nبا افزا\nشی  ابعاد فضا\nی  جستجو، فرآ\nند ی  یری ادگ ی  را دشوارتر م ی .کند\n همچن\nنی  باعث م ی\nشود آموزش،  زمان و منابع ب\nی\nی شتر  را صرف ک\nند  .عالوه برا\nی،ن  تعداد ز اد ی  \nپارامترها م\nلی  شبکه را به ب\nیش\nبرازش  افزا\nیش   م ی\nدهد\n. از ا\nنی،رو  به منظور پرداختن به ا\nین  \n  ،مسائل\nشبکه\nی ها  \n عصب\nی  \n کانولوشن\nی  \n(\nCNN)  به  عنوان  توسعهِی  ار ی بس  محبوب  شبکه\nی ها  \n عصب ی \nاستاندارد معرف\nی  شدند. شبکه\nی  \n عصب\nی  کانولوشنی  دسته\nیا  از شبکه\nهای  \n عصب\nی  پی ش\nخور  \n  هستند\nکه از ال\nی ها هی  چش یپ  ی برا  تجز\nهی  و تحل\nلی  ورود\nیی ها ی  با توپولوژ ها یِی  مشبک\nی،  همانند تصاو\nی ر  \nیدی و و\nوها  استفاده م\nی\nکنند\n. نام ا نی  شبکه\nها بر اساس تابع ر\nاض ی\nی  \n  به نام\nکانولوشن  \n  یا\nپیچش  \nاست که در ساختار خود به کار م ی\nبرند\n. به طور خالصه، شبکه\nی ها  \n کانولوشن\nی،  شبکه\nی ها  \n عصب ی  \nهستند که از کانولوشن به جا\nی  ضرب ماتر ی،س  \n  حداقل در\nیکی  از ال ی ها هی  خود استفاده م ی\nکنند . \n127 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nچیزی  \n که در مورد شبکه کانولوشن\nی  خاص است، نحوه ساختاربند\nی  اتصاالت ب\nنی  نورون ها\nو معمار\nی  هیال  پنهان منحصر به فرد\nی  است که از مکان\nسم ی  پردازش داده\nی ها  بصر\nی  \n  خودمان در\nداخل قشر ب\nیی نا ی  ما الهام گرفته شده است و برخالف شبکه\nی ها  \n عصب\nی  \n پیش\nخور،  هیال  ها در\nCNN\n \n  در3  بعد سازمانده\nی  \n .شده اند: عرض، ارتفاع و عمق \nیکی  از مهم\nنی تر  ژگ یو ی ها ی  شبکه کانولوش\nنی  \n  را  که باید\nبدون توجه به ا\nی نکه  چند ال\nیه  \n در\nمعماری آن  \n وجود دارد را به خاطر بسپار\nید\n، این است که  \n  کل  معماری یکCNN\n  \n  از دو بخش\nاصل\nی  تشک\nیل  \n :شده است \n▪ استخراج ویژگی  (\nFeature Extraction\n): در این الیه ، شبکه\nکی ی سر \n کانولوشن  \n(\nconvolution\n)  \n  و\nعملگر  ادغام   (\npooling\n)، انجام م ی  .دهد اگر بخواهیم تصویر یک\n  ،گربه را در تصویر شناسایی کنیم نیا  قسمت\nی  است که در آن و\nهای ی ژگ ی  خاص\nی  ه  مانند\n گوش، پنجه، رنگ خز گربه تشخ\nصی  داده م\nی.شود  به  ،طور خالصه\nفه ی وظ  این  \n،الیه \nتشخ\nصی  ژگ یو ی ها ی  مهم در پ\nی کسل\nی ها  تصو\nیر  \n  .است\nیال ی ها ه  تر کی نزد  به ورود\nی \nاد ی  رند یگیم  که و\nژگ ی ی ها ی  ساده مانند لبه\nها و گراد\nی ان\nی ها  رنگ را شناسا\nیی  \n کنند، در\nی حال  که ال\nی ی ها ه  \n تر قی عم  ی ها ی ژگ یو  ساده را با و\nژگ ی ی ها ی  ده یچیپ تر  بی ترک  م ی\nکنند. \n▪ \n طبقه:بندی  ی در ا،نجا  هیال  \n  کامال متصل به عنوان\nکی  طبقه  بند\nبعد از  مرحله\nی  \n  استخراج\nویژگی\nها عمل م\nی .کند\nاین الیه مشخص م کی ند ن که کدام و\nژگ ی ی یب\nنی شتر \n  ارتباط را با\nکی  کالس خاص دارد ، از این  رو\nکالس تصو\nری  را بر اساس و\nی ژگ ی ها ی  \n  استخراج شده\nدر مراحل قبل\nی  یپ یبش ین  کند یم.  معمار\nی  ی کل  \n  آن در شکل4\n-\n1  \n .قابل مشاهده است \n \n شکل4\n-\n1\n. \n شمایی کلی از ساختار یک شبکه\nکانولوشنی  \n \nشبکه\nی ها  \n عصب\nی  \n کانولوشن\nی  \n ی دارا  سه و\nی ژگ ی  متما\nزی  در مقایسه با سایر شبکه  های عصبی\nهستند: \n1\n.\n \n( میدان پذیرای محلیlocal receptive fields\n):  \n  هر نورون در کی  \nCNN\n  \n  مسئول\nی ک \nمنطقه تعر فی  شده از داده\nی ها  ورود\nی  است و ا\nنی  به نورون\nها امکان م ی\nدهد تا الگوها یی  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 128 \n \n \nمانند خطوط، لبه\nها و جزئ\nات ی  کوچک\nی  که تصو\nری  را م ی\nسازند، ب\nی\nاموزند\nنی . ا  ناح\nهی  فی تعر  \n  شده از فضا که\nیک  \n  نورون ای  واحد در داده\nی ها  ورود\nی  در معرض آن قرار م یگی،رد  یم دان  \nپذیرای  محل\nی  ده ی نام   م ی.شود  دان یم  پذیرا  با اندازه ف لتر ی  کی  هیال  \n  کی در  \n شبکه عصب\nی  \n کانولوشن\nی  فی تعر   م ی .شود \n2\n.\n اشتراک\nگذاری  پارامتر  (\nparameter sharing\n)  و اتصال(محلیLocal connectivity\n): \n هر الیه کانولوشنی شامل چندین فیلتر می  باشد\nنی و ا   کی  ابر\nپارامتر از پ\nیش  \n فی تعر \n  شده\n.است  \n  کی هر  از ا\nین  فی\nلترها  ی دارا  کی  عرض و ارتفاع تنظ\nیم  \n  شده است که مربوط به\nدان یم  پذیرای  محل\nی  یک  \n نورون  است.  ف\nی لترها\nیی  که  بر  رو\nی  داده\nی ها  ورود\nی  \n عمل\nم ی  ،کنند\nنقشه و ی ژگ ی  \n(\nfeature map\n)  \n  را  در خروجی الیه کانولوشنی\nای\nجاد  م ی .کنند \nاشتراک\nگذاری  پارامتر  به اشتراک\nگذار\nی  \n وزن ها توسط همه نورون  ها در\nکی  نقشه و\nی ژگ ی  \n.است  \n  ،از طرف دیگر\nاتصال محل\nی  مفهوم\nی  \n  است که هر\nنورون  فقط به ز\nیر\nمجموعه\nای  \n از\n نورون\nها  متصل است  ،\n  برخالف کی  \n شبکه عصب\nی  پیش\nخور  که در آن همه نورون  ها کامال\nبهم متصل هستند. \n این ویژگی ها به کاهش تعداد پارامترها در کل س\nی\nستم کمک م ی  کند و\nمحاسبات را کارآمدتر م ی.کند  \n3\n.\n زیرنمونه ( گیریsub-sampling\n)  \n( یا ادغامpooling\n):  \n زیرنمونه\nگیری یا ادغام  \n  اغلب\n بالفاصله پس از\nکی هیال کانولوشنی \n  درCNN\n  میآید\n. نقش آن پا\nن یی آوردن خروج\nی ی ک \nهیال  کانولوشنی  \n در امتداد ابعاد فضا\nیی  \n.ارتفاع و عرض است  عملکرد اصل\nی  ادغام،  \n  کاهش\nتعداد پارامترها\nیی  \n است که با\nید  \n  توسط شبکه\nاد ی گرفته شود\nنی . ا  \n،ویژگی  \n همچن\nین  \n  سبب\nکاهش  اثر  شیب برازش می  شود\nو در نت\nجه ی افزا\nشی  عملکرد و دقت کل\nی  \n  شبکه را به همراه\n.دارد \n شبکه\nهای  کانولوشنی،  نقش  مهم ی  \n را  در  تار\nی\nخچه  ادگ ی\nیری  ی عم ق  \n به همراه  \n داشته\nاند  .\n آن\nها  \n نمونه\nای  مهم و موفق در فهم ما از مطالعه مغز در کاربردها ی \nادگ ی\nیری  ماش\nنی  هستند. شبکه\nهای  عصب\nی  کانولوشنی  \n جزو اول\nین  \n شبکه های  \nعصب ی  بودند که در حل و انجام کابردها\nی  تجار\nی  \n مهم مورد استفاده قرار گرفته\nو حت\nی تا امروز در صدر برنامه\nهای کابرد\nی تجار\nی ادگ ی\nیری قی عم \n.قرار دارند \n \n شبکه\nها\nی کانولوشنی  \n  ی در\nافتن  الگوها\nی  تکرار\nی  و استخراج و\nژگ ی ی ها ی  محل ی  \n.قدرت بسیار زیادی دارند \n عملگر کانولوشن \nشبکه\nی ها  کانولوش\nنی  \n به دسته\nیا  از شبکه\nی ها  \n عصب\nی  تعلق دارند که تصو\nری  را به عنوان ورود ی  \nم یگی،رند  آن را در معرض ترک\nی ب ی  \n از وزن\nها و سوگ\nری ها ی  قرار م ی،دهند  ها ی ژگ یو  \n  را استخراج\n129 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nم ی\nکنند و نتا\nیج \n ب را\nدست م ی\nآورند\n. آن\nها تما\nلی به کاهش ابعاد تصو ری ورود\nی \n با استفاده از\nیک \nهسته  \n  دارند که\nاستخراج و ژگ ی ها ی  را در مقا\nسه ی  \n با شبکه عصب ی  \n پیش\nخور  آسان\nتر م ی  .کند  اساس\n  یک\nشبکه\nی  کانولو\nشنی  عملگر  \n  کانولوشن .است \nکانولوشن  دوبعدی  اساسا  کی  ات ی عمل  نسبتا ساده است.  \n  شما با\nکی  هسته شروع م ی ی کن،د \n  کی که  \n ماتر\nیس  \n کوچک از وزن\nها است. ا\nنی  هسته رو\nی  داده\nی ها  ورود\nی  دوبعد\nی   می\nلغزد، \n  ضرب\nدرایه\nای  را با بخش\nی  از ورود\nی  که در حال حاضر رو\nی  آن است انجام م ی\nدهد  \n و سپس\nجی نتا  ر را د   کی  یپ\nکسل  خروج\nی  خالصه م کند ی  \n  (شکل4\n-\n2\n).  هسته ا\nنی  ند ی فرآ  را برا\nی  هر مکان ی  \nکه رو\nی  آن م\nی\nلغزد تکرار م\nی  کند و\nکی  ماتر\nسی  دو بعد ی  از و ی ژگ ی\nها را به ماتر\nسی  دو بعد\nی \nگر ید  از و\nی ژگ ی\nها تبد\nلی  یم کند. و\nژگ ی ی ها ی  خروج\nی  \n اساساً، مجموع وزن\nدار و\nی ها ی ژگ ی  ورود\nی \nهستند که تقر\nبا ی  در همان م\nکان  پ ی\nکسل  خروج\nی  در ال\nهی  ورود\nی  \n.قرار دارند  \n \n شکل4\n-\n2\n. \n عملگر کانولوشن \nدر مثال باال، و\nی ها ی ژگ ی  ورود\nی  \n25\n=\n5\n×\n5، و و\nی ها ی ژگ ی  خروج\nی  \n9\n=\n3\n×\n3\n  است\n. اگر ا\nین \nکی هیال کامل متصل استاندارد بود، ماتر\nیِس ی وزن ب\nه تعداد \n  پارامتر225\n =\n9\n ×\n29\n خواه\nیم \n داشت\nکه هر و\nی ژگ ی  خروج\nی  مجموع وزن\nی  هر و\nی ژگ ی  ورود\nی  \n است. کانولوشن\nها به ما ا\nین  \n  امکان را\nم ی\nدهند که ا\nنی  لی تبد  \n  را تنها با9 پارامتر انجام ده\nیم.  \nری تأث  \n،کانولوشن  تأک\nدی  بر مرزها\nی  اشکال مختلف است. هسته\nی ها  ری متغ  را م\nی\nتوان  \n به منظور\nبرآوردن ن\nی\nازها\nی  قی دق  تنظ\nمی  کرد. با ا\nنی  حال، به جا\nی  تالش برا\nی  انجام آن به صورت دست\nی، \nیک  \n شبکه کانولوشن عم\nقی  نیا  وظا\nفی  را به فرآ\nند ی  یری ادگ ی  واگذار م\nکند ی  .\n \nکاربرد مواز\nی  \n هسته)های (فیلترهای  \n مختلف، همپوشان ی ها ی  یا ده یچیپ  \n را به همراه دارد که\nم ی\nتواند استخراج و\nیی ها ی ژگ ی را که واقعاً برا\nی طبقه\nی بند مهم هستند، ساده کند. تفاوت اصل ی  \nبین  یک  لایه  \n  کامال متصل و\nیک   لایه  \n کانولوشن، توانا\nیی  هیال  \n دوم برا\nی  \n  کار با\nیک  \n  هندسه موجود\n  است که\nتمام  عناصر مورد ن\nاز ی  ی برا  تشخ\nصی  کی  یش  از  کی  \n ش ی  گر ید  \n را رمزگذار\nی  م ی  .کند\nاین  \n عناصر را نم\nی توان فوراً تعم\nمی  داد  ،اما به پردازش بعد\nی  ی برا  \n  انجام\nکی  ا بهام\nزدا\nیی  از ین  \n  .دارد\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 130 \n \n \nبه عنوان مثال، چشم و ب\nی ین  با ی تقر  \n هی شب  هب\nهم هستند. چگونه م\nی\nتوان تصو ری  \n را بدرست\nی  تقس\nی م  \n  کرد؟ پاسخ با\nکی  تحل\nلی  مضاعف ارائه م ی\nشود : تفاوت\nی ها  ظر ی یف  وجود دارد که م ی\nتوان  \n آن  ها\nرا با ف\nی لترها\nی ری\nزدانه کشف کرد و م\nتر هم \n از همه، هندسه\nسراسری ای اش ،\n ی مبتن بر روابط درون\nی  \nاست که تقر\nبا ی  ثابت هستند. به عنوان مثال  ،\n چشم\nها و ب\nی ین  دی با  کی  مثلث متساو ی\nالساق\nین  \n  را\nتشک\nلی  دهند، ز\nرا ی  \n  تقارن صورت داللت بر فاصله\nی\nکسان  نیب  \n هر چشم و ب\nی ین  دارد. ا\nین  \n  یم را  توان\nاز قبل، مانند بس\nی ار ی  \n از تکن\nکی ی ها  \n  پردازش  تصویر  ،انجام داد\nیا  \n  به لطف قدرت\nادگ ی یری  \n ی عم ،ق \nم ی\nتوان آن را به فرآ\nند ی  آموزش واگذار کرد. از آنجا\nیی  که تابع هز نه ی  \n و کالس\nی ها  خروج\nی  \n  به\n طور ضمن\nی  \n تفاوت\nها را کنترل م\nی،کنند  کی  \n شبکه کانولوشن عم\nیق  می\nتواند  اد ی  رد ی بگ  که  برا ی  \nدن ی رس  \n  کی به  \n هدف خاص چه چ\nیزی  مهم است و در ع\nی ن  حال تمام جزئ\nات ی  ده ی فا یب  \n  را کنار\n.بگذارد \n الیه کانولوشن \nلایه  \n کانولوشن مهم\nنی تر  \n  بلوک سازنده\nیک  \nCNN\n  است. ا\nین  \n  الیه  شامل\nمجموعه\nای  \n  یف از\nلترها  \n  که\n همچن\nین  \n  به عنوان\nهسته( هاkernels\n)  ای  آشکارسازها\nی  و ی ژگ ی  (\nfeature detectors\n)  \n  شناخته\nم ی،شود  هستند  که در آن هر ف\nلتر ی  در تمام مناطق داده\nی ها  ورود\nی  اعمال م\nی  .شود  به عبارت\n  ،دیگر\nفه ی وظ  اصل\nی  هیال  کانولوشن\n، شناسا\nیی  یو ژگ ی ها ی  افت ی  شده در مناطق محل\nی  \n تصو\nی ر  \nورود\nی  است  که ا\nنی  یو ژگ ها ی  در کل مجموعه داده مشترک هستند. ا\nنی  شناسا\nیی  ژگ یو ها ی  \n  از\nقی طر \n اعمال\nیف لتر\nها منجر به تول دی نقشه و ی ژگ ی  م ی\nشود\n. ال\nهی کانولوشنی ،کی لتر یف  \n محل\nی \n  را بر\nی رو  تصو\nری  ورود\nی  \n اعم\nال  کند یم\nنی .  ا  امر  منجر  م\nی\nشود  طبقه\nی بند  بهتر\nی  در  پ\nی\nکسل\nی ها  \nهمسا\nی یاه  که همبستگ\nی  بی\nی شتر  نیب  آن ها وجود دارد در همان تصو\nیر  \n صورت پذ\nرد ی  . به عبارت\nید،گر  یپ کسل\nی ها  تصاو\nری  ورود ی  یم\nتوانند  \n  ی با گر یدک  همبستگ\nی  \n  ،داشته باشند. به عنوان مثال\nدر تصاو\nری صورت، ب\nی نی \n شه ی هم  نیب چشم\nها و دهان قرار دارد. و\nی قت لتر یف را به ز\nی\nرمجموعه\nای  \nاز تصو\nری  اعمال م\nی ی کن،م  برخ\nی  از و\nی ها ی ژگ ی  محل\nی  را استخراج م ی می کن  .از  نیا  یال ه  \n به عنوان\nهیال  استخراج و ی ژگ ی  زین  اد ی  یم\nشود\n. چراکه و\nی ها ی ژگ ی  تصو\nری  در ا\nنی  هیال  استخراج م ی\nشوند  .\n \nهر ال\nهی  کانولوشن  ی دارا  مجموعه خاص\nی  \n  از\nابرپارمترها  \n  است که هر\nکی  از آن ها تعداد\nارتباطات  و اندازهِی  خروجِی  \n نقشه\nهاِی  ی ژگ یو  را تع\nن یی  کند یم: \n• \n:اندازه هسته  اندازه\nی  هسته  یK\n  (گاه\nی  \n  اوقات\nاندازه ف\nلتر ی  ین ز  ده ی نام  یم  )شود\nیم دان \nپذیر  ا\nرا توص\nیف   م ی\nکند که برا\nی  \n همه مکان\nی ها  ورود\nی  اعمال م ی\nشود. افزا\nیش  ای ن  \n پارامتر به ال\nهی  کانولوشن  \n اجازه م\nی\nدهد تا اطالعات فضا\nیی  یب ی شتر  را در\nافت ی  \n  ،کند\nدر حال\nی  که  به\nطور هم زمان تعداد وزن\nی ها  شبکه را افزا\nشی  یم.دهد \n• \n تعداد هسته:  تعداد هسته\nها مستق\nما ی  با تعداد پارامترها\nی  \n  قابل\nیری ادگ ی  \n  و عمقD\n \nحجم خروج\nی  کی  هیال  پیچش  \n مطابقت دارد. همان  طور که هر هسته\nکی  نقشه و\nژگ ی ی  \n131 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nخروج\nی  جداگانه تول\nید  می\nکند، هسته\nی ها  \nD\n  کی  نقشهِی  ی ژگ یو  خروج\nی  \n  با عمقD\n \nرا تول\nدی  م ی .کنند \n• \n:گام پیچش را م\nی توان به عنوان جمع\nی وزن \n \"با \"لغزاندن\nکی هسته بر رو\nی یک \n حجم\nورود\nی  درک کرد. با ا\nین  \n  ،حال  نیازی نیست که  \"لغزش\" با\nیک \n  فاصله\nیک  پی\nکسل  \n  در\nکی  زمان اتفاق ب ی،فتد  یزیچ  که گام توص\nفی   م ی کند. گام𝑆  تعداد پ\nی کسل\nیی ها  \n  را که\nهست\nه  نیب  هر محاسبهِی  ژگ یوِی  خروج\nی  جابجا م ی\nشود را مشخص م\nی کند. گام\nی ها  \nبزرگ\nتر،  \n نقشه\nهاِی  ژگ یوِی  \n خروجِی  کوچکتر\nی  دی تول  یم،کنند  را یز  محاسبات  \n کم  تری\n انجام می.شود  نیا  \n  مفهوم در شکل  زیر نشان\nداده شده است: \n \n• \n الیه\nگذاری-صفر :به دل\nلی نحوه عملکرد عمل\nات ی پیچش ،\n هیال از\nگذاری-صفر برا ی   \n  کنترل\nکاهش  ابعاد پس از اعمال ف\nی\nلترها\nی  \n  بزرگتر از1\n*\n1\n  و جلوگ\nیری  \n  از گم شدن\n  اطالعات در حاشیه استفاده می\nشود. به عبارت دیگر، از الیه\nگذاری-\n  صفر  اغلب\n استفاده می\nشود تا  ابعاد فضا\nیی  ی ها هیال  ورود\nی  و خروج\nی  \n  ی را\nکسان  \n  نگه  .داشت  با\nاضافه کردن ورودِی  \n  صفر در اطراف\nحاشیه،  یم توان کوچک\nشدن ابعاد فضا\nیی  \n  هنگام\n  انجام\nپیچش را  دور زد. مقدار صفرها\nی  \n اضافه شده در هر طرف برا\nی  هر بعد فضا یی  \nکی  ابرپارمتر  \n اضاف\nی  \n𝑃\n  است. نمونه\nیا  از ال\nیه\nگذاری  \n  صفر در شکل  زیر نشان داده\nشده است:  \n \n• فراخ\nش(\nDilation\n):  فراخش  یا  ازهم\nگشودگی  \n𝑑\n  که  اخ\nرا ی  \n معرف\nی  شد\nه  است  ،\nابرپارمتر  ی گر ید  است که به ال\nهی  کانولوشن  اجازه م ی\nدهد تا م\nدان ی  پذیر\nای  م و ثرتر ی  \nنسبت به ورود\nی  داشته باشد،  در حال\nی  که اندازه هسته را ثابت نگه م ی\nدارد. ا\nنی  امر  \n با\nمعرف\nی  \n𝑑\n  فاصله ب\nنی  هر سلول از هسته بدست م دیآی  .کانولوشن  استاندارد، به سادگ ی  \n  از\nفراخش  \n0\n  استفاده م\nکند ی\n. از این\nرو  \n دارای  کی  هسته پ\nی وسته  است\n. با افزا\nی ش  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 132 \n \n \nفراخش  نیا  امکان برا\nی  کی  هیالِی  کانولوشن  وجود دارد که وسعت فضا\nیی  یب\nشتر ی  \nاز  ورود\nی  را  بگ\nرد ی  و  در  ع\nی ن  \n  حال\nمصرف  \n  حافظه  را  ثابت  نگه  دارد.  مفهوم\n کانولوشن\nهای  فراخش  که  گاه\nی  \n  اوقات\nکانولوشن\nهای  آترو(  سatrous \nconvolutions\n)  زین  ده ی نام  یم\nشود،  \n  با فراخش\nهای  \n  مختلف در شکل4\n-\n3  \n نشان داده\nشده است . \nبا توجه به اندازهِی  حجم ورود\nی  \n𝑊، اندازهِی  هستهِی  \n𝐾\n  ، گام𝑆\n  ،\n فراخش  \n𝑑\n  \n  و𝑃\n  الیه\nگذاری،  \nحجم خروج\nی  \n  حاصل\nبه صورت زیر محاسبه می:شود \n𝑊𝑜= ⌊𝑊+ 2𝑃−𝐾−(𝐾−1)(𝑑−1)\n𝑆\n⌋+ 1. \n \n شکل4\n-\n3\n. فراخش رو\nی  ورود\nی دو بعد\nی با اندازه\nی ها \n .مختلف \n استفاده از\nکانولوشن دارای سه مزیت مهم است\n. اوال، شبکه\nی ها  \n عصب\nی کانولوشنی \n معموال\nی دارا  ارتباط\nهای  خلو( تSparse interactions\n)  \n  .هستند\nشبکه های عصبی پیش\nخور  \n  از\nماتر یسی  از پارامترها استفاده م ی  کنند که\nارتباط  نیب  واحد ورود\nی  و خروج\nی  را توص\nفی  یم  .کند\nنیا  بدان معناست که هر واحد خروج\nی  با هر واحد ورود\nی  ارتباط  دارد. با ا\nنی  حال، شبکه\nها ی \n عصب\nی  کانولوشنی  ی دارا  ارتباط خلوت  هستند  \n  که\nبا کوچک\nتر کردن هسته از ورود\nی  \n بدست\nم یآید. \n ،به عنوان مثال\nی ک تصو\nیر می\nتواند یلیم ون\nها ای هزاران پ\nی\nکسل داشته باشد، اما در ح\nی ن \n پردازش آن با استفاده از هسته، م\nی\nتوان\nیم  \n اطالعات معن ی دار ی  که ده  ای ها  صدها پ\nی\nکسل  \n  هستند\n133 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \n را شناسا\nیی  \n نی . ا می کن  \n بدان معن\nی  است که ما با دی  پارامترها\nی  تر کم ی  را ذخ\nره ی  \n می کن  که نه تنها ن\nی از  \n به حافظه را کاهش م ی\nدهد، بلکه کارا\nیی  آمار\nی  مدل را ن\nزی  بهبود م ی\nبخشد. ثان\nی،ًا  \n شبکه\nی ها  \n عصب\nی  پیچشی  \n  از\nاشتراک\nگذار ی  پارا\nمتر  استفاده م ی\nکنند.  به ا\nین  \n ا معن  که آن\nها از پارامترها ی  \nمشابه برا\nی  نی چند  ت ابع  دوباره استفاده م ی\nکنند\n. اشتراک\nگذار\nی  پارامترها هم نی چن  باعث آخر\nین \nتی مز اصل\nی ی ی عن \n هم وردای( یEquivariance\n  )م ی .شود\nهم\nوردایی نی به ا \n ی معن \n  است که اگر\nورود\nی  جابجا شود، خروج\nی  نی ز  \n به همان صورت جابجا م ی\nشود. ا\nنی  ی ژگ یو  ی برا  \n  پردازش\nداده\nی ها  دوبعد ی  ضرور\nی  \n  ،است\nچراکه  \n  اگر\nکی  تصویر  ای  بخش\nی  \n از  کی  تصو\nری  به جا ی  ی گر ید  \nدر تصو\nری  منتقل شود، نما\nیش  ی\nکسان\nی  \n .خواهد داشت \n شبکه\nی ها  عصب\nی  پ ی ش\nخور  هر نورون ورود\nی  \n را به تمام نورون\nی ها  هیال  \n بعد ی  \n متصل م\nی\nکنند  که به ا\nنی  ند ی فرآ  \n اتصال کامل گفته م\nی\nشود\n. با ا\nنی  حال، ا\nی ن \nروش مستلزم محاسبه اضاف\nی  \n وزن ها است به\nطور\nی  \n  که بر سرعت آموزش\nمدل  تاث\nری  ی اد یز  \n می\nگذارد\n.  به  جا\nی  \n  ،اتخاذ  ارتباط  کاملCNN\n  \n از  اتصال  جزئ ی  \n استفاده م ی،کند  ی عن ی  \n هر نورون فقط به ناح\nی یاه  از ال\nی ه  ورود\nی  \n  متصل است که\n به عنوان م\nدان ی  \n ی را ی پذ  محل\nی   \n نورون پنهان شناخته م ی\nشود\n. بنابرا\nی،ن  یک  \nCNN\n \nپارامترها\nی  کم\nی تر  \n نسبت به شبکه\nی ها  عصب ی   یپ ش\nخور  \n دارد و در نت\nجه ی  \n  سرعت\nآموزش سر\nی ی تر ع زین \n دارد \n \nدر ال\nی ی ها ه  \n کانولوشن نقشه\nی ها  ی ژگ یو از داده\nی ها  ورود ی  \n  با استفاده از عملگر\n کانولوشن بدست م\nیآید . \n  الیه کانولوشن درkeras\n \nی برا  یا\nجاد  کی  هیال  \n  کانولوشن درKeras، ابتدا با دی  \n ماژول\nی ها  مورد ن\nاز ی  را به صورت ز\nیر  \n وارد\n دی کن: \nfrom keras.layers import Conv2D \nسپس م ی\nتوان\nدی  با استفاده از فرمت ز\nری  کی  هیال  کانولوشن ا\nی\nجاد  \n دی کن: \nConv2D  (filters, kernel_size, strides, padding, activation='relu', \ninput_shape) \nشما با\nید  \n آرگومان\nی ها  ریز  \n  را\nوارد  \n دی کن: \n▪ \nfilters\n : تعداد فیلترها \n▪ \nkernel_size\n  :عدد\nی  \n  که هم ارتفاع و هم عرض پنجره\nکانولوشن  را مشخص م ی.کند \n▪ \nstrides\n  :\n  گام\nکانولوشنی\n. اگر چ\nیزی  \n را مشخص نکن\nی،د  \n به صورت پیش\nفرض  ی رو  ی ک  \nتنظ\nمی  یم.شود \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 134 \n \n \n▪ \npadding\n  :\nvalid\n  \n  یاsame\n \n▪ \nactivation\n  :معموال از تابع فعال  سازrelu\n  \n استفاده می.شود \n  هنگام استفاده از\nهیال  کانولوش نی  خود به عنوان اول\nین  لایه  \n  در کی  مدل، با\nید  یک  \n  آرگومان\ninput_shape\n  اضاف\nی  \n  را ارائه\nوارد کنید\nنی . ا  کی  تاپل است که ارتفاع، عرض و عمق (به ترت\nیب  )\nورود\nی  را مشخص م ی.کند \nمطمئن شو\nید  \n  که آرگومانinput_shape\n  در صورت\nی  که ال\nهی  کانولوش\nنی  \n اول ی ن  \nلایه \n در شبکه شما ن\nی،ست \n .گنجانده نشده باشد \n الیه ادغام \nاز مزا\nیای  یال ی ها ه  کانولوشن ا\nنی  است که تعداد پارامترها\nی  مورد ن\nاز ی  را کاهش م ی  دهد، عملکرد\nرا بهبود م\nی\nبخشد و ب\nیش\nبرازش را کاهش م ی  دهد. پس از\nکی  عمل\nگر  کانولوشن، اغلب عمل\nی ات  \nی گر ید  انجام م ی\nشود:  ادغام  .هیال  ادغام به کاهش م\nزان ی  توان محاسبات\nی  مورد ن\nاز ی  ی برا  \n  پردازش\nداده\nها کمک م\nی\nکند و مسئول کاهش ابعاد است. با کمک کاهش ابعاد، م\nزان ی  \n  قدرت پردازش\nالزم برا\nی  \n  پردازش مجموعه داده\nکاهش پیدا می  .کند\nادغام را م\nی\nتوان به دو نوع تقس\nیم  \n  :کرد ادغام  \nحداکثری   (\nmaximum pooling\n)   و  ادغام م یانگین  (\naverage pooling\n)\n  .متدوال\nترین  \n  نوع\n،اداغام  ادغام  حداکثری  و  یا\nجاد  شبکه\nهای  (\n2\n×\n2\n  ) در هر\nبخش  \n  و انتخاب نورون با حداکثر\n مقدار فعال ی ساز  \n  در هر شبکه و\nکنار گذاشتن  هی بق  \n  .است\nیهی بد  \n است که چن\nی ن  ی ات ی عمل  \n75\n  از%\n نورون\nها را دور م\nی  اندازد و\nتنها  \n نورون\nیی ها  را که ب\nی\nنی شتر  نقش را ا\nفا ی  م ی\nکنند  ،حفظ م\nی.کند  \n  ،در مقابل  در  ،ادغام میانگین\nی انگ یمِن  \n  مقدار\nهسته  محاسبه م ی\nشود  \n  (شکل3\n-\n4\n). \n \n شکل4\n-\n4\n. ادغام حداکثری و ادغام میانگین \n \n135 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nی برا  هر ال\nیه  \nِادغام دو پارامتر\n اندازه  ِي\nسلول  \n  و\nگام،  مشابه  به پارامترها\nی  \n  گام و\nالیه\nگذاری  \n  در\nی ها هیال  کانولوشن  وجود دارد  . کی  \n  انتخاب معمول انتخاب اندازه سلول2  \n  و گام2  است.  \n  اگرچه\n  انتخاب اندازه سلول3\n  \n  و گام2\n  غی\nرمعمول  ست ین  .البته با\nید  \n  توجه داشت که اگر اندازه سلول\nیلیخ  بزرگ باشد، ممکن است ال\nهی  ادغام اطالعات ز\nی اد ی  را  دور ب\nی\nندازد  و مف\nید  \n.نباشد \n الزم به ذکر است که مانند نحوه استفاده از توابع فعال\nی ساز  \n مختلف، م\nی\nتوان ی م  \n  از\nعملگرهای  ادغام متفاوت ن\nزی  استفاده کن\nیم  .\n با این حال، استفاده از ادغام  \nحداکثر\nی  یکی  \n از را\nی نی تر ج  عملگرها  \n  است، اما\nادغام  \n انگ یم\nین  \n  هم ریغ  معمول\nنی\nست  ،. در عمل\nادغام حداکثری  \n اغلب بهتر عمل م ی  ،کند\nچراکه  مرتبط\nی تر ن \nساختارها را در تصو\nیر \n حفظ م\nی.کند \n \nتوجه داشته  باش\nدی  که ال\nی ها هی  ادغام  ه\nچی  پارامتر جد\nیدی  اضافه  نم\nی ،کنند\nچراکه  \n آن\nها به سادگ\nی  مقاد\nی ر  \n (مانند حداکثر) را بدون ن\nاز ی  \n  به وزن\nای   اس ی با  اضاف ی  \n استخراج م ی.کنند \nطبقه بندی تصویر با شبکه \n  کانولوشنی درkeras\n \nی برا  \n  انجام\nطبقه\nبندی  تصو\nی،ر  \n  ابتدا به\nکی  مجموعه داده و برچسب\nی ها  \n  موجود\nبرای هر  تصو\nیر  \nاز ین  می دار\n. خوشبختانه، مجبور ن\nمی ست ی  به صورت دست\nی  وب را برا\nی  تصاو\nیر  \n( اسکرپscrape\n)  \nکنیم  و خودمان آن\nها را برچسب\nگذار\nی  \n ی کن،م  چراکه \n چند مجموعه داده استاندارد وجود دارد که\nم ی\nتوان\nمی  از آن.ها استفاده کنیم  \n،برای این مثال  از مجموعه داده CIFAR-10 استفاده خواه\nی م \nکرد. جزئ\nات ی  مجموعه داده به شرح ز\nری  است: \n▪ \n ابعاد\nتصاو ری:  تصاو\nیر  \n  کوچک32\n \n×\n  \n32\n  پی\nکسل \n▪ \n برچسب:ها  \n10\n  \n  برچسب  :شامل\nهواپ\nی،ما  \n  ،خودرو، پرنده، گربه، گوزن، سگ، قورباغه\nاسب، کشت\nی  و کام\nی ون \n▪ \n :اندازه مجموعه داده  \n60000\n  تصو\nیر  \n  که  به50000\n  \n  داده\nی برا  \n  آموزش و10000\n  \n داده\nی برا  آزما شی  تقسیم شده.اند \nنی اول  ی کار  \n که با\nدی  انجام ده\nمی  نیا  است که مجموعه داده تصو\nی ر  \n  را\nوارد  کنیم\nنی . ا  \n کار را با\nKeras\n  انجام م ؛می ده ی  با اجرا\nی کد ز\nیر  \n  درjupyter notebook\n: \nfrom keras.datasets import cifar10 \n(x_train, y_train), (x_test, y_test) = cifar10.load_data() \nDownloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz \n170500096/170498071 [==============================] - 2s 0us/step \n170508288/170498071 [==============================] - 2s 0us/step \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 136 \n \n \nاکنون داده\nیی ها  از ی که ن  می دار  در آرا\nی ها هی  مربوط  \n (x_train, y_train)\n و (x_test, y_test) \n  \nره ی ذخ  شده\nاند\n. اجازه ده\nید  \n ی کم  \n   مجموعه داده را\nمورد بررسی قرار دهیم.  د یی ایب   بب ی ین م  \n شکل\nهی آراِی  ژگ یو ها یِی  ورود\nی  \n:ما چگونه است \nprint('x_train shape:', x_train.shape) \nx_train shape: (50000, 32, 32, 3) \nشکل آرا\nهی  به ما م\nدی گو ی  که  \nx_train\n  مجموعه داده شامل موارد ز ری  است: \n▪ \n50000\n \n عکس \n▪ \n  ارتفاع32\n  یپ کسل \n▪ \n  عرض32\n  پی\nکسل \n▪ \n3  پی\nکسل  در عمق (مرتبط با قرمز، سبز و آب\nی)\n \nد یی ایب   ی بب مین  شکل آرا\nیه  \n:برچسب چگونه است \nprint('y_train shape:', y_train.shape) \ny_train shape: (50000, 1) \nاین  \n بدان معن\nا  است که برا ی  \n  هر کی  \n  از50000\n  تصو\nیر  ی ک  \n .عدد (مرتبط با برچسب) وجود دارد \nاکنون، ب\nد یی ای  ی سع  \n می کن  نمونه\nای  \n  کی از  تصو\nری  و برچسب آن  \n را برا\nی  \n :فهم بهتر ببینیم \nprint(x_train[0]) \n [[[ 59  62  63] \n  [ 43  46  45] \n  [ 50  48  43] \n  ... \n  [158 132 108] \n  [152 125 102] \n  [148 124 103]] \n \n [[ 16  20  20] \n  [  0   0   0] \n  [ 18   8   0] \n  ... \n  [123  88  55] \n  [119  83  50] \n  [122  87  57]] \n \n [[ 25  24  21] \n  [ 16   7   0] \n  [ 49  27   8] \n  ... \n  [118  84  50] \n  [120  84  50] \n  [109  73  42]] \n \n ... \n \n [[208 170  96] \n  [201 153  34] \n  [198 161  26] \n  ... \n  [216 184 140] \n  [151 118  84] \n  [123  92  72]]] \nدر حال ی  که\nرایانه  \n تصو\nری  ی را ا\nنگونه  یبیم،ند  اما برا\nی  ما چندان مف دی  ست ین\n. بنابرا\nنی  یب د یی ا  نیا  \nتصو\nیر  \n  ازx_train[0]\n \n  را با استفاده از بستهmatplotlib\n  مصورسازی  \n می کن: \n137 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nimport matplotlib.pyplot as plt \nimg = plt.imshow(x_train[0]) \n \nplt.imshow\n  تابع\nی  است که مقاد\nیر  پی\nکسل  شماره\nگذار\nی  \n  شده را درx_train[0]\n  به تصو\nی ر  \nواقع\nی  نشان م ی.دهد  \n  تصویر نمایش داده شده در باال\nار ی بس  یپ کسل ی  است، ا\nنی  به  لی دل  \n  این  است\nکه اندازه تصو\nیر  \n32\n  \n×\n  \n32\n  پی\nکسل  است که بس\nار ی  \n  کوچک می.باشد  حال  د یی ایب  \n ببینیم  \n  که برچسب\nنیا  تصو\nری  در مجموعه داده ما چ ست ی : \nprint('The label is:', y_train[0]) \nThe label is: [6] \nم یبی نیم  \n\" که برچسب عدد6\" است. تبد\nلی  اعداد به برچسب بر اساس حروف الفبا\nی انگلیسی  \n  به\nصورت ز\nیر  \n :مرتب شده است \nبرچسب \n شماره \n هواپیما \n0\n \n خودرو \n1\n \n پرنده \n2\n \n گربه \n3\n \n گوزن \n4\n \nسگ \n5\n \nقورباغه \n6\n \n اسب \n7\n \nکشتی \n8\n \n کامیون \n9\n \nبنابرا\nی،ن  از جدول م\nیبی ن می  که تصو\nری  باال به عنوان تصو\nری  کی  قورباغه برچسب\nگذار\nی  \n  شده است\n  (برچسب6). ب\nد یی ای  نمونه د\nی گر ی  \n  کی از  تصو\nری  را با تغ\nر یی  \n  شاخص به1\n  (تصو\nیر  \n دوم در\nمجموعه داده ما) به جا\nی  0 (تصو\nیر  \n اول در مجموعه داده ما) مشاهده کن\nیم : \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 138 \n \n \nimg = plt.imshow(x_train[1]) \n \nبیایید  برچسب آن را ن\nزی  شی نما  می ده : \nprint('The label is:', y_train[1]) \nThe label is: [9] \n  با استفاده از جدول\nپیشین،  م مینیبی  نی که ا  تصو\nری  به عنوان کام\nون ی  \n برچسب\nگذار\nی  شده است. \nاکنون  که مجموعه داده خود را بررس\nی  \n کرده\nیا،م  دی با  \n آن را پردازش کن\nمی.  ی اول ن  مشاهده\nای  \n  که\nانجام م می ده ی  نیا  \n است که برچسب\nی ها  ما به عنوان شماره کالس خ\nیلی  دی مف  ین\nستند\nنی . ا  \n به\nنیا  لی دل  \n است که کالس  ها  نظم و ترتیبی\nندارند\n. برا\nی  روشن شدن ا\nنی  موضوع مثال\nی  م می زن ی  .\n اگر شبکه عصب\nی \n ما\nنتواند \n تصم\nی یم رد ی بگ ای که آ  تصو\nی ر یک \n :خودرو (برچسب1\n) است ی ا ی ک  \nون ی کام \n :(برچسب9)، چه اتفاق ی یم\nافتد. آ\nای دی با میانگین در نظر بگ\nیریم \n و آن را به عنوان\nی ک \nسگ پ\nی شبی نی  \n می کن \n  :(برچسب5\n  )؟  قطعا چنین چیزی\nچیه  معنا\nیی  دارد. \nدر فصل پیشین،  نی اول  \n شبکه عصب\nی  خود را برا\nی  یپ یبش ین  مت یق  \n خانه با Keras ساختیم،  \n ممکن است تعجب کن\nید  \n  که چرا\nتوانستیم  \n از برچسب\nی ها  [\n0\n[ ] و1\n ] در آنجا استفاده کن\nنی . ا می \nنی به ا  لی دل  است که فقط دو کالس وجود دارد و ما م\nی\nتوان\nمی  خروج\nی  شبکه  \n عصب\nی  \n را به عنوان\nکی  احتمال تفس\nیر  \n می کن  .ی ی عن  اگر خروج\nی  \n شبکه عصب\nی  \n0.6\n  باشد، به ا\nین  \n معن ی  \n است که معتقد\n  است با احتمال60\n  درصد باالتر از م\nانگ ی\nنی  مت یق  \n  .خانه است  ،با این حال\nاین  \n  در پیکربندی  \n  چند کالسه\nه\nمانند ا\nین  \n  مثال کار نم\nی\nکند، جا\nیی  که تصو ری  م ی  تواند به\nیکی  \n  از10\n  \n  کالس مختلف\nلق تع  داشته باشد. \nآنچه  ما واقعا م ی\nخواه\nیم  \n  احتمال هر\nیک  \n  از10\n  کالس مختلف است. برا\nی  \n  آن، ما به10\n \nنورون خروج\nی  \n در شبکه عصب\nی  خود ن\nاز ی  می دار\n. از آنجا\nیی  \n  که ما10\n  نورون خروج\nی  ی دار،م  \n برچسب\nی ها  ما  ن\nزی  دی با  با  آن  مطابقت  داشته  باشند.  برا\nی  انجام  ا\nین  \n  کار،  برچسب  را  به\nمجموعه\nای  \n  از10\n  عدد تبد\nلی  یم می کن  که هر عدد نشان م\nی\nدهد آ\nای  تصو\nیر  \n  متعلق به آن کالس\n  است\nیا  خیر\n. بنابرا\nین  \n  اگر\nی ک  تصو\nری  متعلق به کالس اول باشد، اول\nنی  عدد ا\nین  \n  مجموعه1\n  \n و\n139 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nتمام اعداد د\nی گر  در ا\nی ن  \n  مجموعه0\n  خواهند بود. به ا\nی ن  کدگذار\nی  \none-hot\n  م ند ی گو ی  \n و جدول\nلی تبد  \n  برای این مثال\nنی به ا  \n  صورت\nاست: \n کدگذار\nی \none-hot\n برچسب \n شماره \n[1000000000]\n \n هواپیما \n0\n \n[0100000000]\n \n خودرو \n1\n \n[0010000000]\n \n پرنده \n2\n \n[0001000000]\n \n گربه \n3\n \n[0000100000]\n \n گوزن \n4\n \n[0000010000]\n سگ \n5\n \n[0000001000]\n قورباغه \n6\n \n[0000000100]\n \n اسب \n7\n \n[0000000010]\n کشتی \n8\n \n[0000000001]\n \n کامیون \n9\n \nی برا  انجام ا\nنی  لی تبد  \n  ، دوباره ازKeras\n  استفاده م ی می کن: \nfrom keras.utils import np_utils \ny_train_one_hot = keras.utils.np_utils.to_categorical(y_train, 10) \ny_test_one_hot = keras.utils.np_utils.to_categorical(y_test, 10) \n  خطy_train_one_hot = keras.utils.np_utils.to_categorical(y_train, 10)\n  ی به ا ن  \n ی معن  است که آرا\nهی  هی اول  \n  را فقط با عددy_train\n  م یگیریم  \n  و آن را به\nکدگذاری  \none_hot\n  ،\ny_train_one_hot\n  لی تبد   م ی می کن  . عدد10\n  به عنوان پارامتر مورد ن\nاز ی  است ز\nرا ی  دی با  \n  به تابع\nبگو\nد یی  چند کال\nس  وجود دارد . \n حال، فرض کن\nید  م ی\nخواه\nمی  ی بب ین م  \n  که\nبرچسب تصو\nری  دوم  ما  (کام\nون ی  با  \n  :برچسب9\n  ) در  این\nکدگذاری  چگونه به نظر م\nی\nرسد: \nprint('The one hot label is:', y_train_one_hot[1]) \nThe one hot label is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \n اکنون که برچسب\nی ها  \n( خودy) را پردازش کرده\nیا،م  ممکن است بخواه\nمی  تصو\nیر  \n( خودx\n ) را\nنیز  \n پردازش کن\nمی . گام متداول\nی  که ما انجام م می ده ی  نیا  است که اجازه ده\nمی  مقاد\nیر  بین  0\n  \n  و1 \n باشد که به آموزش شبکه عصب\nی  ما کمک م ی\nکند. از آنجا\nیی  که مقاد ری  یپ\nکسل  ما از قبل مقاد ری ی  \nبین  0  \n  تا255\n  یگیم،رند  به سادگ ی  دی با  \n آن  ها را  بر255\n  تقس\nیم  \n می کن : \nx_train = x_train.astype('float32') \nx_test = x_test.astype('float32') \nx_train = x_train / 255 \nx_test = x_test / 255 \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 140 \n \n \nدر عمل، کار\nی  که ما انجام م می ده ی  نیا  \n \" است که نوع را بهfloat32\" تبد\nلی  م ی ی کن،م  \n  کی که  \n  نوع\nداده است که م ی\nتواند مقاد ری  را با اعشار ذخ\nره ی  \n  کند. سپس، هر سلول را بر255\n  تقس\nمی  م ی می کن .\nدر صورت تما\nی،ل  \n می  توانید\nبا اجرا\nی  سلول به مقاد\nری  ی آرا هِی  نی اول  تصو\nیر  \n آموزش\nی  \n نگاه کن\nید: \nx_train[0] \narray([[[0.23137255, 0.24313726, 0.24705882], \n        [0.16862746, 0.18039216, 0.1764706 ], \n        [0.19607843, 0.1882353 , 0.16862746], \n        ..., \n        [0.61960787, 0.5176471 , 0.42352942], \n        [0.59607846, 0.49019608, 0.4       ], \n        [0.5803922 , 0.4862745 , 0.40392157]], \n \n       [[0.0627451 , 0.07843138, 0.07843138], \n        [0.        , 0.        , 0.        ], \n        [0.07058824, 0.03137255, 0.        ], \n        ..., \n        [0.48235294, 0.34509805, 0.21568628], \n        [0.46666667, 0.3254902 , 0.19607843], \n        [0.47843137, 0.34117648, 0.22352941]], \n \n       [[0.09803922, 0.09411765, 0.08235294], \n        [0.0627451 , 0.02745098, 0.        ], \n        [0.19215687, 0.10588235, 0.03137255], \n        ..., \n        [0.4627451 , 0.32941177, 0.19607843], \n        [0.47058824, 0.32941177, 0.19607843], \n        [0.42745098, 0.28627452, 0.16470589]], \n \n       ..., \n \n       [[0.8156863 , 0.6666667 , 0.3764706 ], \n        [0.7882353 , 0.6       , 0.13333334], \n        [0.7764706 , 0.6313726 , 0.10196079], \n        ..., \n        [0.627451  , 0.52156866, 0.27450982], \n        [0.21960784, 0.12156863, 0.02745098], \n        [0.20784314, 0.13333334, 0.07843138]], \n \n       [[0.7058824 , 0.54509807, 0.3764706 ], \n        [0.6784314 , 0.48235294, 0.16470589], \n        [0.7294118 , 0.5647059 , 0.11764706], \n        ..., \n        [0.72156864, 0.5803922 , 0.36862746], \n        [0.38039216, 0.24313726, 0.13333334], \n        [0.3254902 , 0.20784314, 0.13333334]], \n \n       [[0.69411767, 0.5647059 , 0.45490196], \n        [0.65882355, 0.5058824 , 0.36862746], \n        [0.7019608 , 0.5568628 , 0.34117648], \n        ..., \n        [0.84705883, 0.72156864, 0.54901963], \n        [0.5921569 , 0.4627451 , 0.32941177], \n        [0.48235294, 0.36078432, 0.28235295]]], dtype=float32) \n  تا کنون ما فقط\nیک  \n  مجموعه\nآموزشی  \n  کی و  مجموعه آزما یشی  \n داریم  . برخالف\nمثال فصل پیش  ،\nمجموعه اعتبارسنج\nی  خود را از قبل تقس\nیم  \n ی نم می کن،  چراکه  انبر یم ی  ی برا  نیا  \n  کار وجود دارد که\nبعدا  معرف\nی  خواه\nیم  \n.کرد \n141 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \n  مشابه\nبا مثال  ی قبل\n، ابتدا با دی  معمار\nی  \n  مدلی خود\nرا تعر فی  \n می کن.  معمار\nی  \nCNN\n  که ما خواه\nی م \n  ساخت به\nشکل  ریز  \n :است \n \n و مقادیرِ پارامترهای معماری باال به صورت زیر خالصه شده:اند \n• \nConv Layer (32 Filter size 3×3) \n• \nConv Layer (32 Filter size 3×3) \n• \nMax Pool Layer (Filter size 2×2) \n• \nDropout Layer (Prob of dropout 0.25) \n• \nConv Layer (64 Filter size 3×3) \n• \nConv Layer (64 Filter size 3×3) \n• \nMax Pool Layer (Filter size 2×2)   \n• \nDropout Layer (Prob of dropout 0.25) \n• \nFC Layer (512 neurons) \n• \nDropout Layer (Prob of dropout 0.5) \n• \nFC Layer, Softmax (10 neurons) \nنیا  معماری دارای تعداد  هیال ی ها  ی اد یز  است (ب\nی\nشتر  از آنچه تاکنون د\nی میا ده )، اما همه از\nمفاه\nی می  \n ساخته شده\nاند که قبال  میا ده ید  .با این حال، ساخت  هر ال هی  \n  فقط با\nیک  \n  خط کد  انجام\n می\nشود  \n  و  جای!نگرانی نیست  \n  اد ی به  اور یب\nید  \n  که تابع  \nsoftmax\n  به سادگ\nی  خروج\nی  \n هیال  ی قبل  \n  را\nبه توز\nی ی ها ع  احتمال\nی  لی تبد  م ی\nکند، چ\nیزی  که ما برا\nی  مسئله  طبقه\nی بند  خود م\nی\nخواه\nیم .\n \nی برا  کدنو\nی یس  نیا  مورد، از مدل ترت\nی بی  \nKeras\n  استفاده خواه\nمی  کرد. با ا\nی ن  حال، از آنجا یی  \nکه ما ال\nی ها هی  ی اد یز  در مدل خود دار\nی،م  روش جد\nیدی  را برا\nی  \n ن یی تع  دنباله معرف\nی  یم ی کن م. ما\nکد را خط به خط مرور م\nی ی کن م  تا بتوان\nدی  قا ی دق  آنچه را که انجام م\nمی ده ی  \n دنبال کن\n. ا دی\nبتدا  \n بخشی  \nاز کدها\nی  مورد ن\nاز ی  خود را وارد م ی می کن : \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D \n  سپس، ما\nکی  مدل ترت\nی یب  ی خال  \n  را\nایجاد می\nکنیم: \nmodel = Sequential() \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 142 \n \n \n  ما هر بار\nکی  هیال  به ا\nنی  مدل خال\nی  اضافه م ی . ال می کن\nیه  \n  اول (اگر از\nشکل  \n  قبلی با یاد داشته\n باشید  )کی  هیال  کانولوشنی  با اندازه ف\nلتر ی  \n3×3\n  ، اندازه گام1  \n  و عمق32\n  \n  .است\nالیه\nگذاری  \"\nsame\n  \"\nو فعال\nساز  آن   \"\nrelu\n\"  است (ا\nین  \n  دو\nپیکربندی  ی برا  همه ال\nی ها هی  \nCNN\n  اعمال م\nی\nشود  ). با  این\nحال،  اجازه ده\nدی  نی اول  هیال  \n  خود را\nبا کد مشخص کن\nیم: \nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', \ninput_shape=(32,32,3))) \nی کار  نی که ا  \n  تکه کد\nانجام م ی\nدهد،  اضافه کردن ا\nنی  هیال  به مدل ترت\nی یب  ی خال  \n  ما با استفاده از\n تابع model.add() \n .است\nنی اول  عدد یعنی \n32\n \n به\nتعداد فیلترها اشاره دارد. جفت اعداد بعد\nی  \n(\n3،3) به عرض و اندازه ف\nلتر ی  \n اشاره دارد. سپس، فعال\nی ساز  \n را که 'relu' \n و \n الیه  گذاری را که\n'same'\n  است مشخص م ی می کن  .توجه  داشته باش\nدی  که ما گام را مشخص نکرد\nیم\n. دل\nلش ی  یا ن  \nاست که stride=1\n  کی  تنظ\nمی  یپ فرض ش  است و تا زمان\nی  که بخواه\nمی  نیا  تنظ\nمی  را تغ\nر یی \nنده\nی،م  ی از ین  به تع\nن یی  آن ندار\nمی  . اگر به خاطر\nداشته باشید،  \n ما همچن\nنی  دی با  اندازه ورود\nی  \n  را\nی برا  هیال  \n اول خود مشخص کن\nی . ال م\nی ها هی  بعد\nی  نیا  مشخصات را ندارند،  چراکه  م ی توانند\nاندازه ورود\nی  را از اندازه خروج ی  هیال  ی قبل  استنتاج کنند.  هیال  دوم ما در کد به ا\nین \n  شکل است\nی از ی (ن  به تع\nن یی  اندازه ورود\nی  ندار\nیم :)\n \nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same')) \nهیال  بعد\nی  کی  یال ه  ادغام حداکثری  \n  با اندازه\nادغام  2\n ×\n2  \n  و گام2  است. پ\nیش\nفرض برا\nی  \n  گام ادغام\nحداکثری  ، اندازه\nادغام  است، بنابرا\nنی  ی از ی ما ن  به تع\nن یی  \n گام ندار\nیم: \nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nدر نها\nی،ت  کی  هیال  حذف\nی  \n  با احتمال0.25\n،  اضافه م\nی می کن  تا از ب\nی ش  برازش\nجلوگ\nیری  \n یم کن: \nmodel.add(Dropout(0.25)) \n  .اکنون چهار الیه اول را با کد ایجاد کردیم\nچهار ال\nهی  بعد\nی  \n واقعا شب\nهی  بهم به نظر م\nی\nرسند: \nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(Dropout(0.25)) \nدر نها\nی،ت  ما با دی  هیال   متصل  کامل  خود  را  کدنو\nیسی  \n ی کن،م  که مشابه کار\nی  \n  است که در  مثال\n  .فصل پیش انجام دادیم\nنی با ا  حال، در ا\nنی  مرحله، نورون\nی ها  ما به\nی جا  کی  ی رد،ف  \n  در قالب\n مکعب  مانند قرار گرفته\nاند. برا\nی  نکه یا  نیا  \n قالب مکعب د مانن  نورون  ها را در\nکی  فی رد  قرار ده\nی ،م \nابتدا با\nید  \n آن را صاف کن\nنی . ا می  \n  کار را با افزودن\nیک  لایه  \nFlatten\n  انجام م می ده ی : \nmodel.add(Flatten()) \n  ،اکنون\nباید  کی  هیال  متصل کامل  با  \n512\n  \n  نورون  و\nفعال  سازrelu\n بسازیم : \n143 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nmodel.add(Dense(512, activation='relu')) \nسپس یک  حذف تصادفی دیگر با  \n  احتمال0.5\n  اضافه م\nی می کن : \nmodel.add(Dropout(0.5)) \n  و در آخر، ما\nکی  هیال  متصل کامل  \n  با10\n  نورون و فعال  سازsoftmax\n  می\nسازیم: \nmodel.add(Dense(10, activation='softmax')) \nساخت  معمار\nی  \n  ما\nاکنون  به پا ان ی  دی رس.  \n  ،حال\nی برا  مشاهده خالصه\nیا  از معمار ی  \n کامل، کد  \n زیر  \nرا اجرا م\nی می کن: \nmodel.summary() \nModel: \"sequential\" \n_________________________________________________________________ \nLayer (type)                Output Shape              Param # \n================================================================= \nconv2d (Conv2D)             (None, 32, 32, 32)        896 \n \nconv2d_1 (Conv2D)           (None, 32, 32, 32)        9248 \n \nmax_pooling2d (MaxPooling2D)  (None, 16, 16, 32)       0 \n \nmax_pooling2d_1 (MaxPooling2D)   (None, 8, 8, 32)         0 \n \n \ndropout (Dropout)           (None, 8, 8, 32)          0 \n \nflatten (Flatten)           (None, 2048)              0 \n \ndense (Dense)               (None, 512)               1049088 \n \ndropout_1 (Dropout)         (None, 512)               0 \n \ndense_1 (Dense)             (None, 10)                5130 \n \n================================================================= \nTotal params: 1,064,362 \nTrainable params: 1,064,362 \nNon-trainable params: 0 \n_________________________________________________________________ \n  ،سپس\nمدل را با تنظ\nمات ی  خود کامپا\nلی  م ی می کن: \nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy']) \n تابع\nزیانی که ما استفاده م ی می کن آنتروپ\nی \n متقاطع طبقه\nیا ده ی نام م ی\nشود .نه ی به ساز ما در ا\nی\nنجا \nadam\n است. در نها\nی،ت  ما م ی\nخواه\nمی  دقت مدل خود را رد\nی اب ی  \n می کن.  \nاکنون، زمان اجرا\nی  \n آموزش م\nدل  \n:است \nhist = model.fit(x_train, y_train_one_hot,  \n           batch_size=32, epochs=20,  \n           validation_split=0.2) \n  ما مدل خود را با\nاندازه  دستهِی  \n32\n  \n  و20\n  دوره آموزش م\nمی ده ی . با ا\nین  \n  ،حال  یک تفاوت در کد\nرا متوجه شدید\n؟  ما از تنظ\nیم  \nvalidation_split=0.2\n  به جا\nی  \nvalidation_data\n  استفاده م ی می کن .\nنی با ا  یم،انبر  ما ن\nی ی از  به تقس\nمی  مجموعه داده\nی ها  \n  خود به\nکی  مجموعه آموزشی  و مجموع\nه  \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 144 \n \n \nاعتبارسنج\nی  \n  در شروع.نداریم  \n در عوض، ما به سادگ\nی  مشخص م ی می کن  \n  که چه مقدار از مجموعه\n  داده ما به عنوان\nی ک  مجموعه اعتبارسنج\nی  استفاده م\nی\nشود. در ا\nی ن  \n  ،مورد20\n  از مجموعه داده%\n  ما به عنوان\nکی  مجموعه اعتبارسنج\nی  استفاده م ی شود. سلول را اجرا کن\nی د  و خواه\nید  دی د  \n که\n مدل شروع به آموزش م کند ی:\n \nEpoch 1/20 \n1250/1250 [==============================] - 27s 14ms/step - loss: 1.4824 - accuracy: 0.4623 - val_loss: 1.1698 - \nval_accuracy: 0.5885 \nEpoch 2/20 \n1250/1250 [==============================] - 17s 14ms/step - loss: 1.1323 - accuracy: 0.6000 - val_loss: 1.0689 - \nval_accuracy: 0.6276 \nEpoch 3/20 \n1250/1250 [==============================] - 17s 13ms/step - loss: 0.9810 - accuracy: 0.6534 - val_loss: 0.9494 - \nval_accuracy: 0.6725 \nEpoch 4/20 \n1250/1250 [==============================] - 17s 14ms/step - loss: 0.8859 - accuracy: 0.6900 - val_loss: 0.9151 - \nval_accuracy: 0.6828 \nEpoch 5/20 \n1250/1250 [==============================] - 18s 15ms/step - loss: 0.8015 - accuracy: 0.7171 - val_loss: 0.9117 - \nval_accuracy: 0.6802 \nEpoch 6/20 \n1250/1250 [==============================] - 18s 14ms/step - loss: 0.7203 - accuracy: 0.7469 - val_loss: 0.8959 - \nval_accuracy: 0.6874 \nEpoch 7/20 \n1250/1250 [==============================] - 17s 14ms/step - loss: 0.6486 - accuracy: 0.7709 - val_loss: 0.8811 - \nval_accuracy: 0.7066 \nEpoch 8/20 \n1250/1250 [==============================] - 17s 14ms/step - loss: 0.5960 - accuracy: 0.7902 - val_loss: 0.9053 - \nval_accuracy: 0.7055 \nEpoch 9/20 \n1250/1250 [==============================] - 17s 13ms/step - loss: 0.5312 - accuracy: 0.8129 - val_loss: 0.9100 - \nval_accuracy: 0.6982 \nEpoch 10/20 \n1250/1250 [==============================] - 18s 14ms/step - loss: 0.4887 - accuracy: 0.8262 - val_loss: 0.9183 - \nval_accuracy: 0.7077 \nEpoch 11/20 \n1250/1250 [==============================] - 18s 14ms/step - loss: 0.4483 - accuracy: 0.8415 - val_loss: 0.9454 - \nval_accuracy: 0.7083 \nEpoch 12/20 \n1250/1250 [==============================] - 17s 13ms/step - loss: 0.4195 - accuracy: 0.8514 - val_loss: 1.0072 - \nval_accuracy: 0.7062 \nEpoch 13/20 \n1250/1250 [==============================] - 18s 14ms/step - loss: 0.3889 - accuracy: 0.8625 - val_loss: 0.9655 - \nval_accuracy: 0.7089 \nEpoch 14/20 \n1250/1250 [==============================] - 18s 14ms/step - loss: 0.3591 - accuracy: 0.8764 - val_loss: 1.0041 - \nval_accuracy: 0.7042 \nEpoch 15/20 \n1250/1250 [==============================] - 17s 13ms/step - loss: 0.3372 - accuracy: 0.8814 - val_loss: 1.0220 - \nval_accuracy: 0.7133 \nEpoch 16/20 \n1250/1250 [==============================] - 18s 14ms/step - loss: 0.3242 - accuracy: 0.8868 - val_loss: 1.0927 - \nval_accuracy: 0.7041 \nEpoch 17/20 \n1250/1250 [==============================] - 23s 18ms/step - loss: 0.3053 - accuracy: 0.8925 - val_loss: 1.0579 - \nval_accuracy: 0.7046 \nEpoch 18/20 \n1250/1250 [==============================] - 18s 14ms/step - loss: 0.2917 - accuracy: 0.8990 - val_loss: 1.0833 - \nval_accuracy: 0.7061 \nEpoch 19/20 \n1250/1250 [==============================] - 17s 14ms/step - loss: 0.2825 - accuracy: 0.9014 - val_loss: 1.0957 - \nval_accuracy: 0.7165 \nEpoch 20/20 \n1250/1250 [==============================] - 17s 14ms/step - loss: 0.2700 - accuracy: 0.9064 - val_loss: 1.0855 - \nval_accuracy: 0.7131 \nپس از اتمام آموزش، م ی\nتوان\nمی  با استفاده از ا\nنی  ی کد  که در ساخت اول\nین  \n شبکه عصب\nی  \n خود\nیا ده ید،م  زیان آموزش و  اعتبارسنج\nی  را در طول تعداد دوره  ها\nمصورسازی  \n می کن: \nplt.plot(hist.history['loss']) \nplt.plot(hist.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='upper right') \nplt.show() \n145 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \n \n ما همچن\nین  می\nتوان\nیم  \n  دقت را\nمصورسازی  \n می کن: \nplt.plot(hist.history['loss']) \nplt.plot(hist.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Val'], loc='upper right') \nplt.show() \n \nهمان طور که مشاهده می\nشود، مدل دچار بیش  .برازش شده است\nدر ا\nین  \n  ،مرحله  به شما توصیه\n می\nکنم  که به عقب برگرد\nدی  و پارامترها\nی  مختلف مانند تغ\nر یی  معمار\nی  یا  \n  تغییر\nتعداد دوره  ها را\n امتحان کن\nید  \n تا بب\nی نی د  آیا  می\nتوان\nید \n  دقتval\n  بهتر\nی  افت ی در  \n دی کن\n. هنگام\nی  که از مدل خود راض\nی \nی بود،د  م ی\nتوان\nدی  آن را در مجموعه آزما\nی یش  ی ارز ی اب  \n دی کن: \nmodel.evaluate(x_test, y_test_one_hot)[1] \n313/313 [==============================] - 2s 5ms/step - loss: 1.1410 - accuracy: 0.6924 \n0.6923999786376953 \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 146 \n \n \nهمان طور که مشاهده می  شود، مدل کارایی چندانی ندارد. با این حال از حدس زدن تصادفی بهتر\nعمل می .کند \nدر  نیا  مرحله، ممکن است بخواه\nدی  مدل آموزش د\nده ی  خود را ذخ\nره ی  \n دی کن  \n (با فرض این  که\n یک مدل با کارایی خوب با تنظیم دقیق ابرپارمترها ساخته  .)اید\nمدل در قالب فا\nیل ی  \n  به نامHDF5\n  \n  (با پسوندh5) ذخ\nره ی  م ی\nشود. ما مدل خود را با ا\nنی  خط کد ذخ\nره ی م ی می کن : \nmodel.save('my_cifar10_model.h5') \nاگر م ی\nخواه\nدی  مدل ذخ\nره ی  شده خود را در آ\nنده ی  بارگ\nیری  \n ی کن،د  از ا نی  \n خط کد استفاده کن\nید: \nfrom keras.models import load_model \nmodel = load_model('my_cifar10_model.h5') \nبه،طور خالصه  ما اول\nین  \nCNN\n  خود را برا\nی  ای\nجاد  کی  طبقه\nبند تصو\nیر  \n ساخته\nایم\n. برا\nی  \n  انجام\nاین  \n  کار، ما از مدلKeras Sequential\n  ی برا  مشخص کردن معمار\nی  \n استفاده کرده\nایم  \n و آن را\nبر رو\nی  مجموعه داده\nای  \n که قبال پردازش کرده\nمیا  آموزش داده\nمیا . ما همچن\nین  \n  مدل خود\nرا  ی ذخ ره \nکرده\nمیا  تا بتوان\nیم  \n بعدا از آن برا\nی  انجام طبقه\nی بند  تصاو\nری  بدون ن\nاز ی  \n  به آموزش مجدد مدل\n استفاده کن\nیم. \n  اکنون که  یک\nمدل دار\nی،م  یب د یی ا  آن را رو\nی  تصاو ری  \n خودمان امتحان کن\nیم\n. برا\nی  انجام ا\nین  \n  ،کار\n  یک\nتصو\nی ر  \n  (بر اساس یکی از10\n  \n)کالس مجموعه داده  از اینترنت دانلود کرده و  \n  در همان  پوشه\nnotebook\n  خود قرار ده\nدی  .ما  از تصو\nری  گربه  زیر  \n استفاده می\nکنیم: \n \nلی فا  تصو\nیری  \n\" منcat.jpg\n  \" است. اکنون\nاین  لی فا  \nJPEG\n  را  به صورت آرا\nیاهی  از مقاد\nری  یپ کسل  \nم ی\nخوان\nیم : \nmy_image = plt.imread(\"cat.jpg\") \nنی اول ی کار که با\nدی انجام ده\nی م ا نی است که اندازه تصو\nری گربه خود را تغ\nر یی \n ی ده م تا بتوان\nی م \n آن\nرا در مدل خود قرار ده\nی م  (اندازه ورود\nی  3  \n×\n  \n32\n  \n×\n  \n32). به جا\nی  یا نکه  \n  خودمان\nکی  تابع تغ یی ر \nاندازه را کدنو\nیسی  \n ی کن،م  د یی ایب  \n  از\nبسته\nای  \n\" به نامscikit-image\n  \"استفاده کنیم  \n  که\nبه  \n  ما در انجام\nآن کمک م\nکند ی : \nfrom skimage.transform import resize \nmy_image_resized = resize(my_image, (32,32,3)) \n147 \n:فصل چهارم شبکه های عصبی کانولوشنی \n \nما م ی\nتوان\nمی  تصو\nری  ر یی تغ  اندازه  یافته  خود را به صورت ز\nری  مصورسازی  \n می کن: \nimg = plt.imshow(my_image_resized) \n \nتوجه داشته باش\nید  \n که اندازه تصو\nری  ر یی تغ  ی\nافته  ی دارا  مقاد\nری  یپ کسل\nی  است که قبال ب\nین  \n0\n  \n  و1 \nی مق اس\nی بند  شده است، بنابرا\nی ن  ی از ین  ست ین  مراحل پ ی ش\nپردازش\nی  را که قبال برا\nی  تصو\nی ر  \nآموزش\nی  خود انجام داد\nیم  \n اعمال کن\nمی  . اکنون، با استفاده از کدmodel.predict، م یبی مین  \n که\nی وقت  تصو\nیری  ا  ز گربه  داده م\nی،شود  \n مدل آموزش\nده ید  \n ما چه خروج\nی  \n:خواهد داشت \nimport numpy as np \nprobabilities = model.predict(np.array( [my_image_resized,] )) \nخروج\nی ها ی  کد باال،  خروج\nی  \n10\n  نورون مربوط به توز\nی ع  احتمال بر رو\nی  \n کالس  ها هستند. اگر\n سلول را اجرا کن\nمی:، خواهیم داشت \nprobabilities \narray([[2.6720341e-02, 3.1344647e-05, 1.5095539e-01, 3.8518414e-01, \n        3.3354717e-03, 3.2324010e-01, 5.1648129e-02, 5.7933435e-02, \n        9.2716294e-04, 2.4454062e-05]], dtype=float32) \nی برا  سهولت خواندن پ ی یبش ی ها ین  مدل، قطعه کد ز\nیر  \n را اجرا کن\nید: \nnumber_to_class = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', \n'horse', 'ship', 'truck'] \nindex = np.argsort(probabilities[0,:]) \nprint(\"Most \nlikely \nclass:\", \nnumber_to_class[index[9]], \n\"-- \nProbability:\", \nprobabilities[0,index[9]]) \nprint(\"Second most likely class:\", number_to_class[index[8]], \"-- Probability:\", \nprobabilities[0,index[8]]) \nprint(\"Third most likely class:\", number_to_class[index[7]], \"-- Probability:\", \nprobabilities[0,index[7]]) \nprint(\"Fourth most likely class:\", number_to_class[index[6]], \"-- Probability:\", \nprobabilities[0,index[6]]) \nprint(\"Fifth most likely class:\", number_to_class[index[5]], \"-- Probability:\", \nprobabilities[0,index[5]]) \nMost likely class: cat -- Probability: 0.31140402 \nSecond most likely class: horse -- Probability: 0.296455 \nThird most likely class: dog -- Probability: 0.1401798 \nFourth most likely class: truck -- Probability: 0.12088975 \nFifth most likely class: frog -- Probability: 0.078746535 \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 148 \n \n \nهمانطور که م\nیبی ین،د  مدل به\nطور دق\nیق  پی شبی نی  \n  کرده است که\nتصویر ورودی  در واقع تصو\nی ر \nیک  \n  .گربه است\nبا این حال\nنی ، ا  بهتر\nنی  ی مدل  ست ین  که ما دار\nمی  و دقت آن بس\nار ی  ن یی پا  \n  ،است\nبنابرا\nنی نباید انتظار ز\nی اد ی از آن نداشته باش\nنی . ا دی مثال، تنها اصول اساس\nی \nCNN\n ها را در\nی ک \nمجموعه داده بس\nار ی  اده س  \n  .پوشش داده است\nمی  توانید به عنوان تمرین، برای این مجموعه داده\n مدل .های دیگری را بسازید و نتایج را مقایسه کنید \nخالصه فصل \n \n▪ \n شبکه\nی ها  عصب\nی  \n،کانولوشنی  از کانولوشن به جا ی  ضرب ماتر ی،س  \n  حداقل در یکی  \n از\nال ی ی ها ه خود استفاده م\nی\nکنند .\n \n▪ شناسا\nیی و ژگ ی ها ی از طر قی اعمال ف\nی لتر\nها منجر به تول\nدی نقشه و ی ژگ ی م ی\nشود.\n \n▪ \n  از\nالیه کانولوشن  به عنوان ال هی  استخراج و ی ژگ ی  زین   اد ی  یم\nشود\n. چراکه و ی ژگ ی ها ی  تصو ی ر  \nدر ا نی ال هی استخراج م\nی\nشوند.\n \n آزمونک \n1\n.\n \n معماری کلی یک شبکه کانولوشنی از چه قسمت\nهای تشکیل شده است؟ \n2\n.\n \n سه ویژگی متمایز شبکه\nهای کانولوشنی را بیان کنید؟ \n3\n.\n الیه کانولوشن \n از چه بخش\nهایی تشکیل شده است ؟ \n4\n.\n مزایای استفاده از کانولوشن چیست؟ \n5\n.\n الیه ادغام در شبکه\nهای کانولوشنی چه نقشی دارند؟\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n5 \n \n▪\n \n شبکه عصبی بازگشتی چیست؟ \n▪\n \n آشنایی باLSTM\n \n▪\n \n تولید متن و طبقه بندی متن با این شبکه ها \n \n:اهداف یادگیری \nشبکه\nهای عصبی بازگشتی \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 150 \n \n \n مقدمه \nمعمار ی  شبکه\nهای  \n عصب\nی  که در فصل\nی ها  پیشین  مورد بحث قرار گرفت،ند  ورود\nی  \n  با اندازه ثابت\nرا در\nافت ی  م ی\nکنند  و خروج\nی  \n با اندازه ثابت ارائه م ی\nکنند\nنی . ا  \n  فصل\nبا  \n معرف\nی  شبکه\nی ها  \n عصب ی  \nبازگشت\nی  (\nRecurrent Neural Networks) یا به اختصار  \nRNN\n از ا نی  محدود\nیت  \n  دور\nمی\nشویم .\nRNNها به ما کمک م\nی\nکنند تا با توال یی ها ی  با طول متغ\nی ر  با تعر\nفی کی  ارتباط  بازگشت\nی  بررو ی  \nنیا  دنباله\nها  (\nsequences\n)  \n مقابله کن\nمی  .توانا\nیی  \n پردازش توال ی ها ی  دلخواه ورود\nی  باعث م\nی  شود\nRNNها برا\nی  کارها\nیی  مانند مدل ساز\nی  زبان  ،تشخ\nیص  \n  گفتار\nو یا غیره  \n  قابل استفاده\nباشند . در\nواقع، در تئور\nی،  \nRNNها را م ی\nتوان برا\nی  \n هر مشکل\nی  اعمال کرد، ز را ی  \n ثابت شده است که آن  ها\nComplete\n-\nTuring\n  \n هستند1ی . ا ن  \n بدان معن\nی  است که از نظر تئور\nی،  آن\nها م ی\nتوانند هر برنامه\nای  \n را شب\nهی ی ساز \n کنند که\nکی  کامپ\nوتر ی معمول\nی قادر به محاسبه آن ن\nست ی\n. به عنوان نمونه\nیا از ا\nی ن \n  ،موضوعGoogle DeepMind\n  ی مدل  \n  به نام\nماش\nی ها نی  تور نگ ی  عصب\nی  ی را پ\nشنهاد  \n  کرده است\nکه م ی  تواند\nنحوه  اجرا\nی  الگور\nتم ی\nی ها  \n ساده مانند مرتب ی ساز  ی را ب\nاموزد. \nشبکه عصبی بازگشتی چیست؟ \nدر فصل قبل، به  تشریح  معمار ی  شبکه\nی ها  \n عصب\nی  \n کانولوشن\nی  که پا\nهی  بس ی ار ی  از س ی\nستم\nها ی  \nیی نا یب  کامپ\nی وتر ی  یپ\nشرفته  را تشک لی  یم  ،دهند\nپرداختیم.  نی با ا  \n  حال، ما\nیای دن  \n  اطراف خود را تنها\nیی نا ی با ب  \n درک نم ی می کن\n. به عنوان مثال، صدا ن\nزی  نقش بس ار ی  \n مهم\nی  دارد. به طور مشخص  تر، ما\n انسان\nها عاشق برقرار\nی  ارتباط و ب\nان ی  افکار و ا\nده ی\nی ها  ده یچیپ  از طر\nقی  توال\nیی ها ی  نماد\nین  \n و\nبازنما یی\nی ها  انتزاع\nی  هست\nمی  .از این  ،رو\nمنطق\nی  \n است که ما م ی\nخواه\nمی  ماش\nی ن  ها\nبتوانند  \n  اطالعات\nمتوال\nی  را درک کنند .\n \nهنگامی که داده\nها به\nگونه\nای تنظیم شده باشند که هر قطعه به نوعی رابطه  ای با قطعاتی که قبل\nو بعد از آن ایجاد می\nشوند، داشته باشد از آن\nها به عنوان دنبال\nه  یاد می  .شود شبکه\nی ها  عصب\nی  \nبازگشت\nی  ای  مکرر\n، نوع\nی  شبکه\nی  \n عصب\nی  مصنوع\nی  هستند که برا\nی  تشخ\nصی  الگوها در داده\nها  ی\nدنباله\nای  ه\nمانند متن، ژنوم، دست\nخط، کلمات گفتار\nی،  داده\nی ها  ی سر  \n زمان، بازارها\nی  \n  سهام و\nره یغ طراح\nی \n شده\nاند. ا\nده یِی پشت ا\nنی شبکه\nی ها \n عصب\nی نیا است که به سلول\nها اجازه م ی\nدهند  \n از سلول\nی ها  ی قبل  \n  متصل به خود\nاد ی  رند ی بگ\n. م ی\nتوان  گفت که به نوع\nی،  این  \n سلول\nها دارا\nی  \n\"حافظه\" هستند. از ا\nنی،رو  دانشِ پ\nی تر ده یچی  را از داده\nی ها  ورود\nی  می\nسازند. \n \n \n1 Alex Graves and Greg Wayne and Ivo Danihelka (2014). \"Neural Turing Machines\". \n151 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \n مدل\nیی ها  \n که در فصل\nی ها  یشیپ ن  \n  ،مورد مطالعه قرار گرفتند\nکی   ی ژگ یو  \n  مشترک دارند. پس\n از تکم\nی ل  ند ی فرآ  آموزش، وزن\nها ثابت م ی\nشوند  و خروج\nی  فقط به نمونه ورود\nی  بستگ ی  \n .دارد\nواضح است که ا\nین  \n  رفتار مورد انتظار\nیک  \n طبقه\nبند است، اما سنار ی\nی وها  ی اد یز  \n  وجود دارد که\nدر آن پ\nیبشی ین  دی با  ی تار\nخچه  مقاد\nری  ورود\nی  را در نظر بگ\nرد ی\n. سر\nی  زمان\nی  کی  نمونه کالس\nیک  \nدر ا\nنی  خصوص است. ب\nد یی ای  \n فرض کن\nمی  که با\nدی  ی دما  هفته آ\nنده ی  یبشی را پ ین  \n می کن\n. اگر سع\nی  \n می کن  فقط آخر\nین  \n  مقدار𝑥(𝑡)\n  \n  شناخته شده و\nیک  \nMLP\n  آموزش د\nده ی  ی برا  یپ یبش ین  \n𝑥(𝑡+ 1)\n  \n استفاده کن\nی،م  \n ی نم\nتوان شرا\nطی  زمان\nی  \n مانند فصل، تار\nی\nخچه  \n فصل در طول سال\nها  \n و غیره  \n را در\nنظر گرفت. رگرس\nون ی  قادر خواهد بود خروج\nیی ها ی  \n  را که کم\nترین  م انگ ی\nنی  خطا را ا\nی\nجاد  م ی  کند\nمرتبط کند، اما در موقع\nی ی ها ت  واقع\nی،  این  \n ی کاف  ست ین\n. تنها راه معقول برا\nی  حل ا\nین  \n مشکل ا\nین  \n  است که\nکی  معمار\nی  دی جد  ی برا  نورون مصنوع\nی  فی تعر  \n می کن  \n  تا  یک  حافظه  برای آن فراهم کن\nیم .\nاین  \n  مفهوم در\nشکل  ریز  \n:نشان داده شده است \n \nاکنون نورون د\nگر ی  کی  واحد محاسبات\nی  پی ش\nخور  خالص ن\nست ی،  چراکه  اتصال بازخورد\nی  \n  آن را\nمجبور م کند ی  گذشته خود را به خاطر بسپارد و از آن برا\nی  یپ یبش ین مقاد\nیر  \n دی جد  \n.استفاده کند \nشبکه\nی ها  عصب\nی  بازگشت ی،  نواقصِ شبکه\nهاِی  عصبِی  پ شی\nخور  را برطرف م\nی\nکنند  . چرا\nکه  شبکه\nی ها  پ شی\nخور  تنها  م\nی\nتوانند  ورود\nی ها ی  با  اندازه  ثابت  را  بپذ\nرند ی  \n و  تنها\n خروج\nیی ها ی با اندازه ثابت تول\nدی  کنند و قادر به در نظر گرفتن ورود\nی ها ی ی قبل \n  با همان\nبی ترت  ن ی\nستند\n. با در نظر گرفتن ورود\nی ها ی  \n گذشته در توال\nی،ها  شبکه\nی  \n عصب\nی  بازگشت\nی  \nقادر به گرفتن وابستگ\nی ها ی  زمان\nی  هستند که شبکه\nی  \n عصب\nی  پ یش\nخور  قادر به آن  \nنی\nست . \n \nشبکه\nی ها  \n عصب\nی  بازگشت\nی ،  دنباله\nیا  را به عنوان ورود\nی  رند یگیم  و برا\nی  هر مرحله زمان ی  \nشبکه عصب\nی  را ارز\nاب ی ی  یم\nکنند\nنی . ا  شبکه\nها را م\nی\nتوان  \n  به عنوان\nکی  شبکه عصب ی  \n  در\nنظر گرفت که دارا\nی  ی ک  حلقه است که به آن اجازه م\nی\nدهد حالت را حفظ کند. هنگام ی  \nکه ارز\nی اب ی  یم،شود  ح\nلقه  \n از طر\nقی  مراحلِ زمانِی  کی  دنباله باز م\nی\nشود\nنی . ا  حلقه  ی ها ا  \nپی\nوندها\nی  مکرر دل یلی  هستند که ا\nنی  شبکه\nها را شبکه\nی ها  بازگشت ی  یم نامند\nی . ا\nنکه  \nیک  \n شبکه بازگشت\nی  شامل حلقه است به ا\nنی  معن\nی  است که خروج\nی  یک  \n  نورون در\nی ک \nنقطه زمان\nی  ممکن است در نقطه زمان\nی  د گر ی  \n به همان نورون بازگردانده شود. نت\nجه ی  \nنیا  امر ا\nنی  است که شبکه نسبت به فعال\nی ها ی ساز  گذشته (و بنابرا\nنی  ورود\nی ها ی \n گذشته که در ا\nنی فعال\nی ساز نقش داشته .اند) حافظه دارد \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 152 \n \n \nساختار شبکه عصبی بازگشتی \n فرض کن\nید  \n  کی در  \n شبکه عصب\nی ی سنت،  \n  همانطور که در\nشکل  ریز  نشان داده شده است: \n \n  تعداد\nی  ورود ی  \n𝑥𝑡\n  می دار  ،\n  که𝑡  \n  نشان دهنده\nی ک  گام زمان\nی  ای  کی  بی ترت  متوال\nی  است. ب\nد یی ای  \n فرض کن\nمی  ورود\nها یِی  𝑡  مختلف،  \n  مستقل از\nگر ی کد ی  باشند. خروج\nی  \n  شبکه در هر𝑡  را م ی  توان\n  به صورتℎ𝑡= 𝑓(𝑥𝑡)\n  نوشت. \n  درRNN\n  ،ها\nحلقه بازخورد،ی  \nِاطالعات  وضع\nیِت  ی فعل  را به حالت بعد\nی  منتقل م ی  ،کند\nهمان  طور که در نسخه\nبازشده  شبکه،  \n  در\nشکل  ریز  نشان داده شده است:   \n \nخروج\nی  \n  شبکهRNN\n  \n  در هر𝑡  را م\nی توان به صورتℎ𝑡= 𝑓(ℎ𝑡−1, 𝑥𝑡)\n  \n  .نوشت\nکار  مشابه  \n𝑓  \nی رو  هر عنصر دنباله انجام م ی\nشود و خروجِی  \nℎ𝑡\n  وابسته به خرو\nجِی  محاسبات قبل\nی  \n  .است  از\nاین  ،رو برخالف شبکه\nی ها  \n معمول\nی،  که حالت فقط به ورود\nی  ی جر ان  (و وزن شبکه) بستگ\nی  \n  ،دارد\nدر ا\nی\nنجا \nℎ𝑡\n تابع\nی از ورود\nی ی فعل \n و همچن\nنی وضع\nتی ی قبل \nℎ𝑡−1\n است. شما م\nی توان\nید \nℎ𝑡−1\n  \n  را به\nعنوان خالصه\nیا  از تمام ورود\nی ها ی  ی قبل  شبکه در نظر بگ\nیرید. \nبه لطف ا\nین  \n معمار\nی  زنج\nی ره\nوار  ای  \n،به عبارت دیگر  ای ره ی ذخ  اضاف\nی  \n)(حافظه  \n  از آنچه تاکنون\nمحاسبه شده است، موفق\nتی  یز ی اد  در بکارگ\nیری  \nRNN\n  در داده\nها ی  ی سر  زمان\nی  \n  و\nمتوالی  \n  حاصل\n .شده است \nRNNها نام خود را به ا\nنی  لی دل  یگیم رند  \n چراکه  تابع  مشابه\nی  را به\nطور مکرر رو\nی  ی ک  \nدنباله اعمال م\nی .کنند \n153 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \nRNN\n ی دارا  \n :سه مجموعه پارامتر (وزن) است \n▪\n \nU\n  ورود\nی \n𝑥𝑡\n  \n را به حالتℎ𝑡\n  لی تبد  م کند ی. \n▪\n \nW\n  حالت قبل\nی  \nℎ𝑡−1\n  را به حالت فعل\nی  \nℎ𝑡\n  لی تبد  کند یم. \n▪\n \nV\n  وضع\nتی  داخل\nی  \n  تازه محاسبه شدهℎ𝑡\n  را به خروج\nی \n𝑦  نگاشت م کند ی. \nU\n  ،\nV\n  \n  وW\n  لی تبد  ی خط  را رو ی  ورود\nها یِی  مربوط اعمال م\nی\nکنند. اساس نی تر ی  \n مورد چن\nی ن \nتبدیلی،  مجموع وزنی  است که ما م ی\nشناس\nیم\n. اکنون م ی\nتوان\nمی  وضع\nتی  داخل\nی  و خروج\nی  \n  شبکه\nرا به صورت ز\nری  فی تعر  \n می کن: \nℎ𝑡= 𝑓(ℎ𝑡−1 ∗𝑊+ 𝑥𝑡∗𝑈) \n𝑦𝑡= ℎ𝑡∗𝑉 \nدر ا\nی،نجا  f  تابع فعال \n ی ساز  ی خط ریغ  است. \nتوجه داشته باش\nید  \n  که در\nی ک  \nRNN، هر حالت به تمام محاسبات قبل\nی  از طر\nیق  این  \n رابطه\nتکرار\nی  \n  .وابسته است\nکی  مفهوم مهم ا\nین  \n  است کهRNN\n ها در طول زمان دارا\nی  \n  ،حافظه هستند\nرا یز  \n حالت\nی ها  \nℎ\n  ی حاو  اطالعات\nی  بر اساس مراحل قبل\nی  هستند. در تئور\nی،  \nRNNها م\nی  توانند\nاطالعات را برا\nی  \n  مدت زمان دلخواه خود به خاطر بسپارند، اما در عمل فقط\nمی  توانند به چند\n  مرحله به عقب نگاه\nکنند .\n \n  درRNN، هر حالت به تمام محاسبات قبل\nی  توسط معادله بازگشت\nی  \n  وابسته\nاست. پ\nی\nامد  مهم ا\nین  \n امر سبب ا\nی\nجاد  \n حافظه در طول زمان م\nی،شود  \n  چرا که\nحالت\nها مبتنی \n بر مراحل قبل\nی \n.هستند \n انواع معماری هایRNN\n \n  از آنجا کهRNNها به پردازش ورود\nی  اندازهِی  ثابت،  \n محدود نم\nی\nشوند،  معماری  های متفاوتی\nرا شامل می\nشوند: \n▪ \n:یک به یک  همان  طور که در شکل،مقابل  قابل مشاهده است  ، در این\nِمعماری یک واحد ورودی  \nRNN\n  \n  به یک واحد پنهان و یک واحد خروجی\n  نگاشت می\nشود\n. این معماری یک پردازش بدون متوالی همانند، شبکه  های\nعصبی پیش\nخور و شبکه  ی عصبی\nکانولوشنی  می\nباشد. نمونه  ای از این\n  پردازش طبقه\nبندی  تصاویر می.باشد \n \n▪ \n:یک به چند  همان  طور که در شکل\nزیر،  قابل مشاهده است  ، در این معماری یک واحد\n  ورودیRNN\n  \n به چند واحد پنهان و چند واحد خروجی نگاشت شده است. نمونه کابردی\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 154 \n \n \nاز این معماری شرح\nنویسی تصاویر می باشد. الیه ورودی یک تصویر را دریافت کرده و\n  آن را به چندین کلمه\nنگاشت می.کند \n \n \n▪ \n:چند به یک  همان  طور که در شکل ،مقابل  \nقابل  مشاهده  است  ، در  این  معماری چند\n  واحد ورودیRNN\n  \n  به چند واحد پنهان و\n  یک واحد خروجی نگاشت شده است. یک\n  نمونه کاربردی  از  این  معماری\nطبقه بندی  \nاحساسات  می باشد.  الیه  ورودی  چندین\nنشانه از کلمات یک جمله را د\nریافت  \n می\nکند \n  و  به  صورت  یک  احساس  مثبت  یا  منفی\n نگاشت می.کند \n \n▪ \n  :چند به چند\nهمان  طور که در شکل ،مقابل  \nقابل مشاهده است  ، در این معماری چند واحد\n  ورودیRNN\n  \n به چند واحد پنهان و چند واحد\n  خروجی نگاشت شده است. نمونه کاربردی از\n  این معماری ترجمه ماشینی است. الیه  ورودی\n چندین نشانه از کلمات زبان مبدا را دریافت  \nکرده  و آن\nها را به نشانه  هایی از کلمات به زبان\nهدف نگاشت م ی.کند \n \n  تولید متن باRNN\n \nRNNها معموال به عنوان مدل\nی ها  زبان  (\nlanguage models\n)  \n  در حوزه پردازش زبان طبیعی \n(\nnatural language processing\n )  استفاده م\nی\nشوند  .ما قصد دار\nمی  ی رو  کی  \n  زبان نسبتا جالب\n155 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \nی برا  \n مدل\nسازِی  دی تول  \n متن کار کن ی،م  یی جا  \n که مدل\nی ها  \nRNN\n  ی برا  یری ادگ ی  \n دنباله\nی ها  \n ی متن   کی  \nدامنه مشخص و سپس،  تول یِد  توالِی  \nِمتن  کامال جد دی  \n  و معقول در دامنه مورد نظر استفاده\nم ی\nشوندِ. مولد  \nِمتن  \n ی مبتن  \n  برRNN\n  می\nتواند  هر متن ورود\nی،  \n مانند رمان\nیی ها  مانند هر ی  ،پاتر\nشعرها\nیی  از شکسپ\nری  لم ی و ف\nنامه\nهاِی  لم یف\nی ها\nی همانند  \n  جنگ ستارگان\nرا بگیرد  ،\n  و\nاشعار شکسپ\nی ر  \nی و ف\nلمنامه\nی ها  یف لم  جنگ ستارگان را تول\nدی  کند. اگر مدل به خوب\nی  \n  آموزش داده شده باشد، متن\nمصنوع\nی  دی با  \n قابل قبول باشد و شب\nهی  به متن اصل\nی  خوانده شود. در ا\nین  \n  بخش از رمان\"\n  جنگ و\nصلح\"  از نو\nی\nسنده  روس\nی  لئو\nتولستو\nی  ب ه  عنوان مثال استفاده م\nی می کن  .\n  ،با این حال\nمی\nتوان\nید  \n از هر\nیک  \n از کتاب\nیاه  مورد عالقه خود برا\nی  ورود\nی ها ی  آموزش\nی  \n استفاده کن\nدی  . پروژه گوتنبرگ\n(\nwww.gutenberg.org\n  )کی  منبع عال\nی  ی برا  نیا  کار است، با ب\nیش  \n  از57000\n  کتاب عال\nی \nگان ی را  \n که حق چاپ آن\nها منقض ی  \n.شده است \nابتدا با\nدی  لی فا  \ntxt\n  جنگ و صلح را مستق\nما ی  از  \n :پیوند \nhttps://cs.stanford.edu/people/karpathy/char-rnn/warpeace_input.txt\n \n  دانلود\nمی می کن\n. از طرف د\nی،گر  یم\nتوان\nیم  \n آن را از پروژه گوتنبرگ \nhttps://www.gutenberg.org/ebooks/2600\n \n دانلود کن\nی،م  اما با\nدی  برخ\nی  از پاک\nساز ها ی  را انجام ده\nمی.  سپس فا\nلی  را م ی\nخوان\nی،م  \n متن را به\nحروف کوچک تبد\nلی  م ی می کن  \n  و با چاپ100\n  کاراکتر اول، نگاه\nی  گذرا به آن م\nی\nانداز\nیم: \ntraining_file = 'warpeace_input.txt' \nraw_text = open(training_file, 'r').read() \nraw_text = raw_text.lower() \nraw_text[:100] \n'ufeff\"well, prince, so genoa and lucca are now just family estates \nof thenbuonapartes. but i warn you, i' \nاکنون با\nدی  تعداد کاراکترها را بشمار\nیم: \nn_chars = len(raw_text) \nprint('Total characters: {}'.format(n_chars)) \nTotal characters: 3196213 \nسپس، م ی\nتوان\nمی  کاراکترهای  یکتا  و اندازه واژگان را بدست آور\nیم: \nchars = sorted(list(set(raw_text))) \nn_vocab = len(chars) \nprint('Total vocabulary (unique characters): {}'.format(n_vocab)) \nprint(chars) \nTotal vocabulary (unique characters): 57 \n['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', \n'1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', \n'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 156 \n \n \n'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \n'à', 'ä', 'é', 'ê', '\\ufeff'] \n  اکنون، ما\nکی  مجموعه داده آموزش\nی  \n خام دار\nمی  که از ب\nیش  \n  از3\n  م ون یلی  \n  کاراکتر و57\n  \n  کاراکتر\nیکتا  \n  تشکیل\nشده است. اما چگونه م ی\nتوان\nیم  \n  آن را به مدلRNN\n تغذ\nیه  \n م؟ ی کن  در معمار\nی  \n  چند به\nچند، مدل توال ها ی  را م رد یگی  و توال ها ی  را ه\nم\nزمان  دی تول  م کند ی . در مورد ما، م ی\nتوان\nیم  \n  مدل را\nبا دنباله\nی ها کاراکترها\nی با طول ثابت تغذ\nیه \n می کن\n. طول دنباله\nی ها  خروج\nی با توال ی ها ی ورود ی  \n  برابر است و\nکی  کاراکتر از دنباله\nی ها  ورود\nی  آن\nها جابه\nجا م\nی شود. فرض کن\nی د  \n طول دنباله را\nبرای  \n  کلمهlearning\n  ی رو  5  \n قرار م\nمی ده ی\n. اکنون م\nی\nتوان\nمی  با ورود\nی  \nlearn\n  و خروج\nیearni \n  ی ک  \nنمونه آموزش\nی  بساز\nیم\n. ما م ی\nتوان می  نیا  \n  عمل  را در شبکه\nبه صورت زیر تجسم  \n می کن: \n \n  ما فقط\nکی  نمونه آموزش\nی  ساخت می\n. در مورد کل مجموعه آموزش\nی ،  م ی\nتوان\nمی  داده\nی ها  \n  متن خام\nرا به دنباله\nیی ها  با طول مساو\nی،  \n  مثال100\n  تقس\nیم  \n می کن\n. هر دنباله از کاراکترها ورود\nی  یک  \n نمونه\nآموزش\nی  است. سپس، ما داده\nی ها  \n ی متن  خام را به همان روش تجز\nهی  و تحل\nلی  یم ی کن،م  اما ا\nین \nبار از کاراکتر دوم شروع م ی می کن  . هر\nکی  از توال\nی ها ی  \n بدست آمدهِی  خروج\nی،  کی  نمونه آموزش\nی  \nاست. برا\nی  \n  مثال، با توجه به متن خامdeep learning architectures \n  و  عدد  5  \n به عنوان طول\nتوال\nی،  م ی\nتوان\nمی  پنج نمونه آموزش\nی  \n  را به\nصورت  ریز  بساز\nیم : \nورودی \n خروجی \ndeep_ \neep_l \nlearn \nearni \ning_a \nng_ar \nrchit \nchite \nectur \ncture \n157 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \nدر ا\nی،نجا  \n _ نشانِگر  فضا\nی خالی  است  .\n \nاز آنجا\nیی  \n که مدل\nی ها  \n شبکه عصب\nی  فقط داده\nی ها  عدد\nی  را در\nافت ی  م ی،کنند  دنباله\nی ها \nورود\nی  و خروج\nی  کاراکترها با بردارهاِی  کدگذارِی  \none-hot\n  نشان داده م\nی\nشوند  . ما با نگاشت\n57\n  کاراکتر به شاخص ها\nی  0  \n  تا56\n  ،کی  دیکشنری  یا\nجاد  یم می کن: \nindex_to_char = dict((i, c) for i, c in enumerate(chars)) \nchar_to_index = dict((c, i) for i, c in enumerate(chars)) \nprint(char_to_index) \n  به عنوان مثال، کاراکتر𝑒  به بردار\nی  \n  با طول57\n  لی تبد  یم\nشود  \n که  در  \n  شاخص30\n  بردارش  \n  مقدار\n1\n  \n  قرار دارد\nو همه شاخص\nی ها  گر ید  \n  آن0\n  وجود دارد  (\n  نحوه  این کدگذاری را در فصل پیشین\nمشاهده کردی د). با آماده شدن جدول جستجو\nی  کاراکتر، م ی\nتوان\nمی  مجموعه داده آموزش\nی  \n  را به\nصورت ز\nری  بساز\nیم: \nimport numpy as np \nseq_length = 100 \nn_seq = int(n_chars / seq_length) \nبا تنظ\nمی  طول دنباله رو\nی  \n100\n  ،\n  ماn_seq\n  نمونهِی  \n آموزش\nی  خواه\nیم  \n  .داشت\nسپس\n، ورود\nی  \n و\nخروج\nی  آموزش\nی  را مقدارده\nی  هی اول  یم می کن: \nX = np.zeros((n_seq, seq_length, n_vocab)) \nY = np.zeros((n_seq, seq_length, n_vocab)) \nتوجه داشته باش\nید  \n  که طول دنباله از نظر شکل:اینگونه است  \n(تعداد نمونه، طول دنباله، ابعاد و ژگ ی )ی \n نی چن  ی فرم  مورد ن\nاز ی  است،  چراکه  ما قصد دار\nیم  \n  ازKeras\n  ی برا  \n  آموزش مدلRNN\n  \n  استفاده\n می کن.  \n  ،سپس  کی هر  از نمونه\nی ها  \nn_seq\n  \n  را\nایجاد  \n می دی کن: \nfor i in range(n_seq): \n \nx_sequence = raw_text[i * seq_length : (i + 1) * seq_length] \n \nx_sequence_ohe = np.zeros((seq_length, n_vocab)) \n \nfor j in range(seq_length): \n \n \nchar = x_sequence[j] \n \n \nindex = char_to_index[char] \n \n \nx_sequence_ohe[j][index] = 1. \n \nX[i] = x_sequence_ohe \n \ny_sequence = raw_text[i * seq_length + 1 : (i + 1) * seq_length + 1] \n \ny_sequence_ohe = np.zeros((seq_length, n_vocab)) \n \nfor j in range(seq_length): \n \n \nchar = y_sequence[j] \n \n \nindex = char_to_index[char] \n \n \ny_sequence_ohe[j][index] = 1. \n \nY[i] = y_sequence_ohe \nدر صورت تما\nی،ل  م ی\nتوان\nدی  با اجرا\nی  \n سلول\nهای زیر  شکل آرایه را  ببینید: \nX.shape \n(31962, 100, 57) \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 158 \n \n \nY.shape \n(31962, 100, 57) \n تا این  ،جا\nمجموعه داده آموزش\nی  را آماده کرد\nیم  \n  و اکنون زمان ساخت مدلRNN\n  \n  .است  ابتدا\n تمام ماژول\nی ها  \n الزم را وارد کن\nید: \nfrom keras.models import Sequential \nfrom keras.layers.core import Dense, Activation, Dropout \nfrom keras.layers.recurrent import SimpleRNN \nfrom keras.layers.wrappers import TimeDistributed \nfrom keras import optimizers \nfrom tensorflow import keras \n  ،اکنون\nابر\nپارامترها، از جمله اندازه دسته ، تعداد نورون\nها، تعداد الیه\nها، احتمال حذف تصادفی  \nو تعداد دوره  ها را مشخص\nمی\nکنیم: \nbatch_size = 100 \nn_layer = 2 \nhidden_units = 800 \nn_epoch = 300 \ndropout = 0.3 \n  ،سپس  شبکه را ایجاد می\nکنیم : \nmodel = Sequential() \nmodel.add(SimpleRNN(hidden_units, activation='relu', input_shape=(None, \nn_vocab), return_sequences=True)) \nmodel.add(Dropout(dropout)) \nfor i in range(n_layer - 1): \n    model.add(SimpleRNN(hidden_units, activation='relu', \nreturn_sequences=True)) \n    model.add(Dropout(dropout)) \nmodel.add(TimeDistributed(Dense(n_vocab))) \nmodel.add(Activation('softmax')) \nدر مورد مدل\nی  \n  که ساخته\nایم،  دی با  به چند نکته توجه داشت: \n▪ \nreturn_sequences=True\n  :خروج\nی  ی ها هیال  \n،بازگشتی  \n  کی به  دنباله تبد\nیل  م ی\nشود  \nو معمار\nی  \n چند به چند را ممکن م\nی،کند  \n همان\nطور که م ی\nخواست\nیم\n. در غ\nیر  این  \n  ،صورت\n  تبدیل به  چند به\nیک  می\nشود و آخر\nنی  عنصر به عنوان خروج\nی  \n .خواهد بود \n▪ \n:TimeDistributed\n  از آنجا\nیی  که خروج ی  ی ها هیال  بازگشتی  کی  \n دنباله است، در\nی حال  که  ال\nهی  بعد\nی  یک  هیال  متصل کامل  \n  است  و\nورود\nی  متوال\nی  \n رد یگی نم\n.  از  \nTimeDistributed\n  ی برا  دور زدن ا\nنی  مورد استفاده م ی\nشود. \nبرای  نه ی به  ساز، ماRMSprop\n  \n  را با نرخ\nیری ادگ ی  \n0.001\n  انتخاب م\nی می کن: \noptimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, \nepsilon=1e-08, decay=0.0) \n159 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \n  با اضافه\nکردن  زیان  \n آنتروپ\nی  متقاطع چندکالسه، ساخت مدل خود را به پا\nان ی  \n رساند\nیم  \n و در\n نهایت مدل را کامپایل می :کنیم \nmodel.compile(loss= \"categorical_crossentropy\", optimizer=optimizer) \nبا استفاده از کد ز\nیر  م ی\nتوان\nمی  نگاه\nی  به خالصه  ای از مدل\nبی\nنداز\nیم : \nmodel.summary() \n_________________________________________________________________ \n Layer (type)                Output Shape              Param #    \n================================================================= \n simple_rnn_4 (SimpleRNN)    (None, None, 800)         686400     \n                                                                  \n dropout_4 (Dropout)         (None, None, 800)         0          \n                                                                  \n simple_rnn_5 (SimpleRNN)    (None, None, 800)         1280800    \n                                                                  \n dropout_5 (Dropout)         (None, None, 800)         0          \n                                                                  \n time_distributed_2 (TimeDis  (None, None, 57)         45657      \n tributed)                                                        \n                                                                  \n activation_2 (Activation)   (None, None, 57)          0          \n                                                                  \n================================================================= \nTotal params: 2,012,857 \nTrainable params: 2,012,857 \nNon-trainable params: 0 \nشی ما ب  \n  از2\n  یلیم ون  پارام\nتر برا\nی  \n آموزش دار\nمیِ. اما قبل از شروع روند آموزش  طوالن\nی،  تمر\nی ن  \nی خوب  است که برخ\nی  \n  ازcallbackها  را برا\nی  یریگیپ  آمار و وضع ی ها تی  داخل\nی  \n  مدل در طول\nآموزش تنظ\nیم  \n می کن  . توابعcallback\n  شامل موارد ز ری  است: \n▪ نقطه  \n( ِوارسیcheckpoint\n)  \n،مدل  که مدل را بعد از هر دوره ذخ\nره ی  یم\nکند تا بتوان\nی م  \nآخر\nنی  مدل ذخ\nره ی  شده را بارگ\nیر ی  \n می کن  و در صورت توقف غ\nی،رمنتظره  \n  آموزش را از آنجا\nاز سر بگ\nیریم. \n▪ توقف  \n،زودهنگام  \n که زمان\nی  \n  که تابع  \n،زیان  گر ید  \n بهبود نم\nیی،ابد  آموزش  را متوقف م کند ی. \n▪ بررس\nی نتا جی ی تول د متن به.طور منظم  ما م\nی\nخواه\nمی   ی بب ین م  متن تول\nید  \n  شده چقدر معقول\n  است\nچرا که زیان  آموزش به اندازه کاف\nی  ملموس ن\nست ی . \nنیا  توابع به صورت ز\nری  فی تعر  ی ا  مقدارده\nی  هی اول  م ی:شوند \nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping \n \nfilepath=\"weights/weights_layer_%d_hidden_%d_epoch_{epoch:03d}_loss_{loss\n:.4f}.hdf5\" \n \ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, \nsave_best_only=True, mode='min') \n  نقاط\nوارسی  مدل،  \n  با شماره دوره وِزیان  آموزش\nی  در نام فا\nلی  ره ی ذخ  یم  شود. ما همچن\nین  \n  زیان\nاعتبارسنجی  را به\nطور هم\nزمان نظارت م ی می کن  تا ببینیم  که آ\nای  کاهش آن برا\nی  \n50\n  دوره متوال ی  \n متوقف م ی  شود\nیا  خیر: \nearly_stop = EarlyStopping(monitor='loss', min_delta=0, patience=50, \nverbose=1, mode='min') \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 160 \n \n \n  در مرحله بعد، ما  یکcallback\n  ی برا  نظارت\nبر ک\nتیفی  الزم داریم  . ابتدا\nکی  تابع کمک\nی \nم میسی نو ی  \n که متن\nی  با هر طول\nی  \n  را با توجه به مدلRNN\n  ما تول\nدی  یم:کند \ndef generate_text(model, gen_length, n_vocab, index_to_char): \n    \"\"\" \n    Generating text using the RNN model \n    @param model: current RNN model \n    @param gen_length: number of characters we want to generate \n    @param n_vocab: number of unique characters \n    @param index_to_char: index to character mapping \n    @return: \n    \"\"\" \n    # Start with a randomly picked character \n    index = np.random.randint(n_vocab) \n    y_char = [index_to_char[index]] \n    X = np.zeros((1, gen_length, n_vocab)) \n    for i in range(gen_length): \n        X[0, i, index] = 1. \n        indices = np.argmax(model.predict(X[:, max(0, i - 99):i + 1, :])[0], 1) \n        index = indices[-1] \n        y_char.append(index_to_char[index]) \n    return ('').join(y_char) \n ،این تابع با\nکارکتری که به طور تصادف\nی \n انتخاب شده شروع می\nکند . سپس مدل\nورود\nی \n ی هر ک  \n  از\nکارکترهای  \n باق ی\nمانده  \ngen_length-1\n  \n  را بر اساس\nکارکترهای  \n دی تول  \n شده قبل\nی  \n  که طول آنها تا\n100\n  است (طول دنباله) پ\nیبشی ین  کند یم.  اکنون م ی\nتوان\nیم  \n  کالسcallback\n  را تعر\nیف  \n می کن  \n  که\nمتن را برا\nی  \n  هرN\n  دوره تول\nدی  کند یم: \nclass ResultChecker(Callback): \n    def __init__(self, model, N, gen_length): \n        self.model = model \n        self.N = N \n        self.gen_length = gen_length \n \n    def on_epoch_end(self, epoch, logs={}): \n        if epoch % self.N == 0: \n            result = generate_text(self.model, self.gen_length, n_vocab, \nindex_to_char) \n            print('\\nMy War and Peace:\\n' + result) \nاکنون  که همه اجزا آماده هستند، آموزش مدل را شروع م ی می کن: \nmodel.fit(X, Y, batch_size=batch_size, verbose=1, epochs=n_epoch, \n                 callbacks=[ResultChecker(model, 10, 200), checkpoint, early_stop]) \nمولد  ی برا  \n  هر10\n  \n  دوره200\n  کاراکتر م سد ی نو ی\n. نتا جی  ریز  \n ی برا  دوره\nی ها  \n1\n  ،\n11\n  ،\n51\n  \n  و101\n \n می\nباشد: \nEpoch 1: \nEpoch 1/300\n \n8000/31962 [======>.......................] - ETA: 51s - loss: 2.8891\n \n31962/31962 [==============================] - 67s 2ms/step - loss: 2.1955\n \nMy War and Peace:\n \n5 the count of the stord and the stord and the stord and the stord and the\n  \nstord and the stord and the stord and the stord and the stord and the stord\n   \nand the stord and the stord and the stord\n  \nand the\n \n161 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \nEpoch 00001: loss improved from inf to 2.19552, saving model to\n  \nweights/weights_epoch_001_loss_2.19552.hdf5\n \nEpoch 11:\n \nEpoch 11/300\n \n100/31962 [..............................] - ETA: 1:26 - loss: 1.2321\n \n31962/31962 [==============================] - 66s 2ms/step - loss: 1.2493\n \nMy War and Peace:\n \n?\" said the countess was a strange the same time the countess was already \nbeen and said that he was so strange to the countess was already been and \nthe same time the countess was already been and said\n \nEpoch 00011: loss improved from 1.26144 to 1.24933, saving model to\n \nweights/weights_epoch_011_loss_1.2493.hdf5\n \nEpoch 51:\n \nEpoch 51/300\n \n31962/31962 [==============================] - 66s 2ms/step - loss: 1.1562\n \nMy War and Peace:\n \n!!CDP!E.agrave!! to see him and the same thing is the same thing to him and \nthe same thing the same thing is the same thing to him and the sam thing \nthe same thing is the same thing to him and the same thing the sam\n \nEpoch 00051: loss did not improve from 1.14279\n \nEpoch 101:\n \nEpoch 101/300\n \n31962/31962 [==============================] - 67s 2ms/step - loss: 1.1736\n \nMy War and Peace:\n \n= the same thing is to be a soldier in the same way to the soldiers and the \nsame thing is the same to me to see him and the same thing is the same to \nme to see him and the same thing is the same to me\n \nEpoch 00101: loss did not improve from 1.11891\n \nآموزش در اوا\nیل  \n  دوره203\n  متوقف م ی:شود \nEpoch 00203: loss did not improve from 1.10864 \nEpoch 00203: early stopping \n \n  ،مدل\nمتن ز\nیر  \n  را در دوره151\n  ا ی\nجاد  م ی:کند \nwhich was a strange and serious expression of his face and shouting and  said \nthat the countess was standing beside him.  \"what a battle is a strange and \nserious and strange and so that the  countess was \n  جنگ و صلح ما  تا حدودی\nخوب خوانده م\nی.شود  \n  با این حال، شاید برای شما سوال پیش آید\nکه  ایآ  یم\nتوان\nمی  با تغ\nر یی  \n  پارامترها  در این  مدلRNN\n  \n بهتر عمل کن\nم؟ ی  پاسخ آری است ، اما\n  .ارزشش  را  ندارد  چراکه  آموزش\nیک  \n  مدلRNN\n  ی برا  \n حل  مسائل\nی  که  ن\nی\nازمند  ادگ ی یری  \nوابستگ\nی ها ی  بلندمدت هستند،  کارایی خیلی عالی  ندارد  .معمار\nیی ها ی  \n  مانندLSTM\n  \n  وGRU\n \nبه\nر طو  خاص برا\nی  حل ا\nنی  مشکل طراح\nی  شده.اند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 162 \n \n \nLSTM\n \nدر تئور\nی،\nRNN ی ها  \n  ساده قادر به\nری ادگ یِی  وابستگ\nها یِی  بلند مدت هستند، اما در عمل، به دل\nی ل \n مشکل\nمحو گرادیان، \n آن ها خود را محدود به\nری ادگ یِی وابستگِی کوتاه مدت \n می.کنند \n  در راستای\nمقابله با این محدودیت، شبکه  \n( حافظه طوالنی کوتاه مدتLong short term memory\n)  \n  یا\n  به اختصارLSTM\n  \n  .ارائه شدLSTM\n  م ی\nتواند وابستگ\nی ها ی  بلندمدت را به دل\nی ِل  \n  ِوجود\nی ک \nِسلول  \n حافظهِی  \n  مخصوص،در ساختارش  \n  .انجام دهد \nده یا  یدی کل LSTM \n( سلول وضعیتcell state\n)  است که اطالعات م\nی تواند به صراحت\n  در آن نوشته\nای  حذف شود  .نیا  \n،سلول وضعیت  ی برا  \n زمان 𝑡 اب  عنوان 𝑐𝑡 \n  در شکل5\n -\n1  \n  نشان\nداده شده است. \n \n𝑓𝑡= 𝜎(𝑊𝑓ℎ𝑡−1 + 𝑈𝑓𝑥𝑡+ 𝑏𝑓) \n𝑖𝑡= 𝜎(𝑊𝑖ℎ𝑡−1 + 𝑈𝑖𝑥𝑡+ 𝑏𝑖) \n𝑎𝑡= tanh(𝑊𝑐ℎ𝑡−1 + 𝑈𝑐𝑥𝑡+ 𝑏𝑓) \n𝑜𝑡= 𝜎(𝑊𝑜ℎ𝑡−1 + 𝑈𝑜𝑥𝑡+ 𝑏𝑜) \n𝑐𝑡= 𝑓𝑡∗𝑐𝑡−1 + 𝑖𝑡∗𝑎𝑡 \nℎ𝑡= 𝑜𝑡∗tanh (𝑐𝑡) \n شکل5\n-\n1. \n ساختار یکLSTM\n \nسلول وضعیت  \nLSTM\n  تنها م\nی\nتواند توسط دروازه\nی ها  خاص تغ\nر یی  کند که راه\nی  برا ی  \n  انتقال\nاطالعات از طر\nیق  \n  .آن است\nیک  \nLSTM\n  معمول\nی  از سه دروازه تشک\nیل  \n  :شده است دروازه\nفراموش  (\n𝑓\n)\n  ،دروازه ورود\nی  (\n𝑖)  \n و\nدروازه خروج\nی (\n𝑜\n).  \n163 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \n  دروازه اول درLSTM\n  دروازه فرامو\nشی  است.  این دروازه  \n تصم\nمی  م رد یگی  ای که آ  \n ما م ی\nخواه\nی م \nسلول  \n وضعیت  \n را پاک کن\nیم  یا  خیر  .\n  ِتصمیم\nدروازه فراموش بر\nاساس  خروج\nی  قبل ی  \nℎ𝑡−1\n  \n و\nورود\nی  ی فعل  \n𝑥𝑡\n  \n  است. از\nیک  \n  تابعsigmoid\n ی برا  یا\nجاد  خروج\nی  با مقدار ب\nین  \n  صفر و\nکی  برا ی \n  کی هر  \n  از عناصر در سلول\nوضعیت  استفاده م\nی\nشود  .کی  \n  ضرب\nدرایه\nای  نیب  خروج ِی  دروازه ِی \n فراموش\nی  \n  و سلول\nوضعیت  انجام م ی\nشودِ. مقدار  کی  در خروج\nی  دروازهِی  \n فراموش\nی،  به معناِی  \n  حفظ کاملِ اطالعات عنصر در سلول\nوضعیت  است.  در مقابل، صفر به معنا\nی  \n  فراموش کردن\nکامل اطالعات در عنصر سلول حالت است. ا\nنی  نی به ا  \n ا معن  \n  است\nکه  \nLSTM\n  یم  تواند اطالعات\nریب  بط را  از\nبردار سلول  وضعیت \n  خود\nدور بی  .اندازد\nمعادله\nی  دروازهِی  فراموش\nی  به\nصورت ز\nی ر  \n:است \n𝑓𝑡= 𝜎(𝑊𝑓ℎ𝑡−1 + 𝑈𝑓𝑥𝑡+ 𝑏𝑓) \nدروازه بعد\nی  \n تصم\nمی  م رد یگی  که اطالعات جد\nدی  به سلول حافظه اضافه شود. ا\nین  \n  کار در دو\nبخش انجام م ی\nشود : تصم\nمی  دری بگ  که کدام مقاد ری  را بروزرسان\nی  \n کن د  \n  و  سپس ایجاد\nمقاد ی  ر  برای\nبروزرسانی است  .\n  ابتدا از  بردار𝑖𝑡\n  ی برا  انتخاب مقاد\nیری  \n از نامزدها\nی  دی جد  بالقوه برا\nی  \n  گنجاندن\nدر  سلول  وضعیت  استفاده م ی  شود. بردار\nنامزد  \n𝑎𝑡\n  نیز  \n ماتر\nیس  \n  وزن مخصوص به خود را دارد\nو از حالت پنهان قبل\nی  و ورود\nی\nها برا\nی  تشک\nلی  بردار\nی  \n  با ابعاد مشابه  سلول\nوضعیت  \n  استفاده\nم ی  .کند\nبرای ایجاد این بردار نامزد از ی\nک  \n  تابعtanh\n  \n  به عنوان\nکی  تابع غ\nی خط ری  استفاده م\nی .شود\nنیا  ند ی فرآ  \n  در معادالت:زیر نشان داده شده است \n𝑖𝑡= 𝜎(𝑊𝑖ℎ𝑡−1 + 𝑈𝑖𝑥𝑡+ 𝑏𝑖) \n𝑎𝑡= tanh(𝑊𝑐ℎ𝑡−1 + 𝑈𝑐𝑥𝑡+ 𝑏𝑓) \nدروازه\nی فراموش\nی و ورود\nی \n نحوهِی \n بروزرسان\nی \n سلول\nوضعیت  را در هر مرحله زمان\nی  \n  مشخص\nم ی\nکنند\n. بروزرسان\nی  \n  سلول\nوضعیت  \n  کی در  مرحله زمان\nی  از طر\nقی  معادله ز\nیر  \n انجام م ی\nشود: \n𝑐𝑡= 𝑓𝑡∗𝑐𝑡−1 + 𝑖𝑡∗𝑎𝑡 \nآخر\nین  \n دروازه تصم\nی م  رد یگیم  که خروج\nی  چه باشد  .خروج ی  نها\nیی  کی  \n  سلولLSTM\n،  \n  حالت\n  پنهانℎ𝑡\n  \n.است  دروازه ِی  خروج ی  \nℎ𝑡−1\n  و  \n𝑥𝑡\n  را به عنوان ورود\nی  می\nگیرد .  \n  ابتدا، از\nی ک  \n تابع\nsigmoid\n ی برا  محاسبه بردار با مقاد\nیر  بین  \n  صفر و\nکی  استفاده م ی\nشود  تا انتخابِ مقاد\nیِر  \n  ِسلول\nوضع\nیت  \n در مرحله زمان\nی  \n  را انجام دهد. سپس مقدار سلول\nوضعیت  \n  را به\nیک  لایه  \ntanh\n  م ی ده ی م \nتا در نها\nتی  مقدار آن را در خروج\nی  هیال  ی قبل  \nsigmoid\n  ضرب ک،رده  \n تا قسمت\nی ها  \n  مورد نظر در\nخروج\nی \n .به اشتراک گذاشته شوند\nخروج\nی  0 ی به ا ن \n ی معن است که بلوک سلول\nی چیه اطالعات ی  \nرا تول\nید  \n ی نم\nکند، در حال\nی  که خروج\nی  1  نی به ا  مع ان  است که حافظه  کامل بلوک سلول به خروج\nی  \nسلول منتقل م ی.شود  معادالت ز\nری  نیا  روند را نشان م ی\nدهند : \n𝑜𝑡= 𝜎(𝑊𝑜ℎ𝑡−1 + 𝑈𝑜𝑥𝑡+ 𝑏𝑜) \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 164 \n \n \nℎ𝑡= 𝑜𝑡∗tanh (𝑐𝑡) \n  حال چگونهLSTM\n \n از ما در برابر\nمحو گرادیان  محافظت م ی\nکند؟  توجه داشته باش\nید  \n  که اگر\nدروازه  \n  فراموش1  \n  باشد و\nدروازه  ورود\nی  0  \n  ،باشد\nوضعیت  \n سلول ع\nنا ی  \n  مرحله به مرحله رونوشت  \nم ی\nشود . تنها\nدروازه  فراموش  یم ی\nتواند  به طور کامل حافظه سلول را پاک کند. در نت\nی ،جه  \n حافظه\nم ی\nتواند  در مدت\nزمان طوالن\nی  بدون تغ\nر یی  ی باق  \n .بماند \nنحوه  ِی  بازشدنLSTM\n \n ،در طول زمان\nدر عمل در شکل ز\nیر  \n نشان\nداده شده\nاست: \n \n  در ابتدا مقدار4.2\n  به شبکه به عنوان ورود\nی  داده م\nی\nشود؛ دروازه ورود\nی  \n  به1  تنظ می  \n ،شده است\nبنابرا\nنی  مقدار کامل ذخ\nره ی  یم\nشود. سپس برا ی  \n  دو مرحله بعد، دروازه فراموش شده به1  تنظ ی م \nشده است. بنابرا\nنی  کل اطالعات در طول ا\nنی  مراحل نگهدار\nی  م ی\nشود و ه\nچی  اطالعات جد\nیدی  \nاضافه \n ی نم\nشود، چراکه دروازه\nی ها ورود ی \n  به0 تنظ\nی م شده\nاند\n. در نها\nی،ت دروازه خروج\nی \n  به1 \nتنظ\nمی  یم  شود و4.2\n  دی تول  یم\nشود و بدون تغ\nر یی  ی باق  م ی\nماند. \n  تولید متن باLSTM\n \n  درِمولد  \nِمتن  \n ی مبتن  برLSTM\n  ،\n  ،در مقایسه با مثال پیشین  طول دنباله را به160\n  کاراکتر افزا ی ش  \nم می ده ی\n. از این\nرو  مجموعه آموزشی  \nX\n  \n  وY\n  \n  را با  مقدار\nجد دی  \nSEQ_LENGTH = 160\n  بازساز ی  \n می :کنیم \nseq_length = 160 \nn_seq = int(n_chars / seq_length) \n \nX = np.zeros((n_seq, seq_length, n_vocab)) \nY = np.zeros((n_seq, seq_length, n_vocab)) \n \nfor i in range(n_seq): \n \nx_sequence = raw_text[i * seq_length : (i + 1) * seq_length] \n \nx_sequence_ohe = np.zeros((seq_length, n_vocab)) \n \nfor j in range(seq_length): \n \n \nchar = x_sequence[j] \n \n \nindex = char_to_index[char] \n \n \nx_sequence_ohe[j][index] = 1. \n \nX[i] = x_sequence_ohe \n \ny_sequence = raw_text[i * seq_length + 1 : (i + 1) * seq_length + 1] \n165 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \n \ny_sequence_ohe = np.zeros((seq_length, n_vocab)) \n \nfor j in range(seq_length): \n \n \nchar = y_sequence[j] \n \n \nindex = char_to_index[char] \n \n \ny_sequence_ohe[j][index] = 1. \n \nY[i] = y_sequence_ohe \nدر مقایسه  \n  با مدلRNN\n  قبلی،  \n  ما  از مدلی با\nدو ال\nیه  \n  بازگشتی\nی حاو  \n800\n  \n  نورون و حذف تصادفی\n  با احتمال0.4\n \n استفاده می :کنیم \nfrom keras.layers.recurrent import LSTM \nbatch_size = 100 \nn_layer = 2 \nhidden_units = 800 \nn_epoch= 300 \ndropout = 0.4 \nاکنون شبکه را ا\nی\nجاد  و کامپا\nلی  می:کنیم \nmodel = Sequential() \nmodel.add(LSTM(hidden_units, input_shape=(None, n_vocab), \nreturn_sequences=True)) \nmodel.add(Dropout(dropout)) \nfor i in range(n_layer - 1): \n    model.add(LSTM(hidden_units, return_sequences=True)) \n    model.add(Dropout(dropout)) \nmodel.add(TimeDistributed(Dense(n_vocab))) \nmodel.add(Activation('softmax')) \n  برای\nنه ی به،ساز  از  \nRMSprop\n  ، با نرخ\nیری ادگ ی  \n0.001\n  استفاده می :کنیم \noptimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, \nepsilon=1e-08, decay=0.0) \n \nmodel.compile(loss= \"categorical_crossentropy\", optimizer=optimizer) \nد یی ایب  \n  مدلLSTM\n را که به تازگ\nی  \n ساخته\nایم،  \n خالصه کن\nیم : \nmodel.summary() \n________________________________________________________________ \nLayer (type) Output Shape Param # \n================================================================= \nlstm_1 (LSTM) (None, None, 800) 2745600 \n_________________________________________________________________ \ndropout_1 (Dropout) (None, None, 800) 0 \n_________________________________________________________________ \nlstm_2 (LSTM) (None, None, 800) 5123200 \n_________________________________________________________________ \ndropout_2 (Dropout) (None, None, 800) 0 \n_________________________________________________________________ \ntime_distributed_1 (TimeDist (None, None, 57) 45657 \n_________________________________________________________________ \nactivation_1 (Activation) (None, None, 57) 0 \n================================================================= \nTotal params: 7,914,457 \nTrainable params: 7,914,457 \nNon-trainable params: 0 \n حدود8 ون یلیم پارامتر برا\nی \n آموزش وجود دارد\nکه با ی تقر چهار برابر ب\nی\nشتر \n  از مدلRNN\n  قبلی .\nد یی ایب  \n آموزش را شروع کن\nیم: \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 166 \n \n \nmodel.fit(X, Y, batch_size=batch_size, verbose=1, epochs=n_epoch, \n                 callbacks=[ResultChecker(model, 10, 200), checkpoint, early_stop]) \nمولد برا\nی \n هر10\n  \n دوره متن\nی \n با500\n کاراکتر م\nسد ی نو ی\n. نتا\nجی ریز ی برا دوره\nی ها \n151\n ،\n201\n \n و\n251\n  \n :است \nEpoch 151:\n \nEpoch \n151/300 \n19976/19976 [==============================] - 250s 12ms/step - loss: \n0.7300 \nMy War and Peace: \ning to the countess. \"i have nothing to do with him and i have nothing to \ndo with the general,\" said prince andrew. \n\"i am so sorry for the princess, i am so since he will not be able to say \nanything. i saw him long ago. i am so sincerely that i am not to blame for \nit. i am sure that something is so much talk about the emperor alexander's \npersonal attention.\"  \n\"why do you say that?\" and she recognized in his son's presence. \n\"well, and how is she?\" asked pierre. \n\"the prince is very good to make \n \nEpoch 00151: loss improved from 0.73175 to 0.73003, saving model to \nweights/weights_epoch_151_loss_0.7300.hdf5 \n \nEpoch 201:\n \nEpoch 201/300 \n19976/19976 [==============================] - 248s 12ms/step - loss: \n0.6794 \nMy War and Peace: \nwas all the same to him. he received a story proved that the count had not \nyet seen the countess and the other and asked to be able to start a tender \nman than the world. she was not a family affair and was at the same time as \nin the same way. a few minutes later the count had been at home with his \nsmile and said: \n\"i am so glad! well, what does that mean? you will see that you are always \nthe same.\" \n\"you know i have not come to the conclusion that i should like to \nsend my private result. the prin \n \nEpoch 00201: loss improved from 0.68000 to 0.67937, saving model to \nweights/weights_epoch_151_loss_0.6793.hdf5 \n \nEpoch 251:\n \nEpoch 251/300 \n19976/19976 [==============================] - 249s 12ms/step - loss: \n0.6369 \nMy War and Peace: \nnd the countess was sitting in a single look on \nher face. \n\"why should you be ashamed?\" \n\"why do you say that?\" said princess mary. \"why didn't you say a word of \nthis?\" said prince andrew with a smile. \n\"you would not like that for my sake, prince vasili's son, have you seen \nthe rest of the two?\" \n\"well, i am suffering,\" replied the princess with a sigh. \"well, what a \n167 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \ndelightful norse?\" he shouted. \nthe convoy and driving away the flames of the battalions of the first \nday of the orthodox russian \n \nEpoch 00251: loss improved from 0.63715 to 0.63689, saving model to \nweights/weights_epoch_251_loss_0.6368.hdf5 \nدر نها\nی،ت  \n  در دوره300\n  ،آموزش  \n  با\nزیان  \n0.6001\n  متوقف م ی.شود \nِمولد  متن به لطف معمار ی LSTM \n  قادر است  ِداستان\nجنگ و صلح واقع ی تر و جالب  تر\nسد ی بنو.  عالوه  بر ا\nی،ن  \nRNNی ها  \nLSTM\n  ی برا  دی تول  \n کاراکتر به متن محدود نم ی  شوند. آنها\nم ی\nتوانند از هر داده کاراکتر\nی،  \n  مانندHTML\n  ،\nLaTex\n \n  و غیره\nاد ی  \n رند ی بگ. \n طبقه\nبندی چندبرچسبی  متن \n  باLSTM\n \nدر ا\nنی  بخش قصد داریم تا  \n نحوهِی  یا\nجاد  کی  \nِمدل  \n طبقه  ِبند\nمتن،  با خروج\nی ها ی  \n  متعدد را  شرح\nدهیم  . ما\nبه  \n  توسعه\nکی  مدل طبقه\nبند متن خواه\nمی  پرداخت  \n  کی که  \n نظر متن\nی  را تحل\nلی  کرده  \n  و\nنی چند  برچسب مرتبط با نظر را پ\nیبشی ین  کند یم  .\n \n  مجموعه داده ،مورد استفاده برای آموزش\nشش برچسب خروج\nی  ی برا  \n  :هر نظر داردtoxic\n ،  \nsevere_toxic\n،  \nobscene\n  ،\nthreat\n،  \ninsult\n  \n  وidentity_hate\n  .کی  نظر م ی\nتواند به همه ا\nنی  دسته ها\nیا  زی\nرمجموعه\nیا  از ا\nنی  دسته  ها تعلق داشته باشد که آن را به\nکی  مسئله  طبقه\nی بند  \n چندبرچسب\nی \nلی تبد  م ی.کند  \n  این\nمجموعه داده را م\nی\nتوان\nدی  نی از ا  وب سایت1  \nKaggle\n  \n دانلود کن\nدی  .در این مثال  \nتنها  از فا\nیل  \"\ntrain.csv\n\"  استفاده خواه\nمی  کرد . \nابتدا  کتابخانه\nی ها  مورد  ن\nاز ی  را  وارد کرده  و  مجموعه  \n  داده  را\nبارگذار\nی  \n می می کن  .کد  ریز \n کتابخانه\nی ها  مورد ن\nاز ی  را وارد م\nی:کند \nfrom numpy import array \nfrom keras.preprocessing.text import one_hot \nfrom keras.preprocessing.sequence import pad_sequences \nfrom keras.models import Sequential \nfrom keras.layers.core import Activation, Dropout, Dense \nfrom keras.layers import Flatten, LSTM \nfrom keras.layers import GlobalMaxPooling1D \nfrom keras.models import Model \nfrom keras.layers.embeddings import Embedding \nfrom sklearn.model_selection import train_test_split \nfrom keras.preprocessing.text import Tokenizer \nfrom keras.layers import Input \nfrom keras.layers.merge import Concatenate \nimport pandas as pd \nimport numpy as np \nimport re \nimport matplotlib.pyplot as plt \nحال  مجموعه داده را بارگذار\nی  می می کن: \ntoxic_comments = pd.read_csv(\"train.csv\") \n \n1 https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 168 \n \n \nکد  ریز  شکل مجموعه داده را نما شی  م ی\nدهد : \nprint(toxic_comments.shape) \n(159571, 8) \nهمان طور که مشاهده می  ،شود  مجموعه داده شامل159571\n  \n  رکورد و8  \n.ستون است \nبا دستور زیر چند نمونه  \n  از\nداده\nها \n  را  خروجی مشاهده می\nکنید: \ntoxic_comments.head() \n \nid \ncomment_text \ntoxic severe_toxic obscene threat insult identity_hate \n0 0000997932d777bf \nExplanation\\nWhy the \nedits made under my \nusern... \n0 \n0 \n0 \n0 \n0 \n0 \n1 000103f0d9cfb60f \nD'aww! He matches this \nbackground colour I'm \ns... \n0 \n0 \n0 \n0 \n0 \n0 \n2 000113f07ec002fd \nHey man, I'm really not \ntrying to edit war. \nIt... \n0 \n0 \n0 \n0 \n0 \n0 \n3 0001b41b1c6bb37e \n\"\\nMore\\nI can't make \nany real suggestions on \n... \n0 \n0 \n0 \n0 \n0 \n0 \n4 0001d958c54c6e35 \nYou, sir, are my hero. \nAny chance you \nremember... \n0 \n0 \n0 \n0 \n0 \n0 \n،در مرحله بعد  تمام رکوردها\nیی  که در آن هر رد\nفی  ی حاو  مقدار ته\nی  ای  رشته خال\nی  است  را  \n  حذف می می کن . \nfilter = toxic_comments[\"comment_text\"] != \"\" \ntoxic_comments = toxic_comments[filter] \ntoxic_comments = toxic_comments.dropna() \n  ستونcomment_text\n  ی حاو  \n نظرات  متن\nی  است.  ب\nد یی ای  کی  \n  نظر\nرا  \n چاپ کن\nیم  \n  و  سپس\n برچسب\nی ها  \n نظرات را بب\nی ن یم : \nprint(toxic_comments[\"comment_text\"][168]) \nYou should be fired, you're a moronic wimp who is too lazy to do research. \nIt makes me sick that people like you exist in this world. \nحال با دستور زیر، نگاهی به  \n برچسب\nی ها  مرتبط با ا\nین  \n  نظر\nمی\nاندازیم: \nprint(\"Toxic:\" + str(toxic_comments[\"toxic\"][168])) \nprint(\"Severe_toxic:\" + str(toxic_comments[\"severe_toxic\"][168])) \nprint(\"Obscene:\" + str(toxic_comments[\"obscene\"][168])) \nprint(\"Threat:\" + str(toxic_comments[\"threat\"][168])) \nprint(\"Insult:\" + str(toxic_comments[\"insult\"][168])) \nprint(\"Identity_hate:\" + str(toxic_comments[\"identity_hate\"][168])) \nToxic:1 \nSevere_toxic:0 \nObscene:0 \nThreat:0 \nInsult:1 \nIdentity_hate:0 \nحال ب\nد یی ای  تعداد نظرات را برا\nی  هر  \n  برچسب\nمصورسازی  \n می کن : \ntoxic_comments_labels = toxic_comments[[\"toxic\", \"severe_toxic\", \"obscene\", \n\"threat\", \"insult\", \"identity_hate\"]] \nfig_size = plt.rcParams[\"figure.figsize\"] \nfig_size[0] = 10 \n169 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \nfig_size[1] = 8 \nplt.rcParams[\"figure.figsize\"] = fig_size \ntoxic_comments_labels.sum(axis=0).plot.bar() \n \nم شاهده می\nکنید  \n  که\" کالسtoxic\n\"  بی\nنی شتر  فراوان\nی  را دارد  .ما مجموعه داده  ِی\nخود را با موفق\nیت  \nتجز\nهی  و تحل\nلی  کرد.یم  \n  در\nادامه  مدل طبقه بند چندبرچسب\nی  را ب\nرای  نیا  مجموعه داده ا\nی جاد \nخواه\nیم  \n .کرد \nبه  ،طور کلی\nدو راه برا\nی  ای\nجاد  مدل\nی ها  طبقه بند چندبرچسب\nی  \n  وجود دارد: استفاده از  یک\nلایه \nخروج\nی  متصل کامل  و استفاده از چند\nنی  هیال  خروج\nی  متصل کامل.  در رو\nی کرد  اول، م\nی\nتوان\nی م \n کی از هیال متصل کامل با شش خروج\nی با ت ابع\nفعال\nاز س \nsigmoid\n  \n و\nتابع زیان آنتروپ\nی \n  متقاطع\nدودویی  \n استفاده کن\nیم\n. هر نورون در ال\nیه  \n،متصل کامل  خروجِی  ی یک  \n  از شش برچسب را نشان\nم ی  .دهد\nهمان طور که می  ،دانیم\nتابع فعال\nی ساز  \nsigmoid\n  مقدار\nی  بین  \n0\n  \n  و1\n  یا بر  \n هر نورون\nبرم ی\nگرداند. اگر مقدار خروج\nی  \n  هر نورون بزرگتر از0.5\n  باشد، فرض م\nی  شود که نظر متعلق به\nکالس\nی  \n.است که توسط آن نورون خاص نشان داده شده است  \nدر رو\nی\nکرد \n دوم می\nتوان کی هیال  خروج\nی \n متصل\nکامل ی برا هربرچسب ا\nی\nجاد کرد .\n  برای این\nمثال، باید  \n6\n  هیال  متصل کامل  در خروج\nی  \n  ایجاد کرد که\nهر ال\nیه  \n  تابعsigmoid\n  \n خود را خواهد\n.داشت   \n ما تنها از رویکرد اول برای این مجموعه داده استفاده می\nکنیم  و یک  \n مدل طبقه  بند متن چند\n برچسب\nی \n را با یک\nهیال خروج\nی ا ی\nجاد خواه\nیم \n .کرد ابتدا، یک تابع یا\nجاد \n می\nکنیم تا \n به\nپاکساز ی  \n  متن:بپردازد \ndef preprocess_text(sen): \n    # Remove punctuations and numbers \n    sentence = re.sub('[^a-zA-Z]', ' ', sen) \n    # Single character removal \n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence) \n    # Removing multiple spaces \n    sentence = re.sub(r'\\s+', ' ', sentence) \n    return sentence \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 170 \n \n \nمرحله بعد مجموعه ورود\nی  و خروج\nی  خود را ا\nی\nجاد  یم می کن\n. ورودِی  \n  نظر ستونcomment_text\n  \n  است.  ما  تمام  نظرات  را\nدر  متغ\nیر  \nX\n  ره ی ذخ  یم می کن\n.  برچسب  ای ها  خروج ی  ها  قبال  در\ntoxic_comments_labels\n  ی ذخ ره  شده\nاند. ما از آن مقاد\nری  ی برا  ره ی ذخِی  خروج\nی  در متغ\nیر  \ny \n  استفاده می\nکنیم  .کد  ریز  \n این کار را انجام می :دهد \nX = [] \nsentences = list(toxic_comments[\"comment_text\"]) \nfor sen in sentences: \n    X.append(preprocess_text(sen)) \ny = toxic_comments_labels.values \n در این مجموعه داده ی از ی ما ن به انجام کدگذار\nی \none-hot\n \n ندار\nمی، چراکه \n برچسب\nهاِی خروج\nی  \n  ما قبال  تبدیل\nبه بردارها\nی  \n کدگذار\nی  \none-hot\n  \n شده\nاند.  در  مرحله بعد، داده\nی ها  \n خود را به مجموعه\nداده  آموزش\nی  و آزم\nون  تقس\nمی  م ی می کن : \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \nrandom_state=42) \nدر ادامه نیاز به تبدیل ورودی خود به بردارهای عددی داریم. از این رو قبل از اینکه به ادامه این\n مثال بپردازیم بیاید\nتا \n در مورد\nجاساز کلمات (\nword embedding\n ) \n .بیشتر بدانیم الگور\nتم ی\nی ها \nیری ادگ ی  \n قی عم  قادر به درک داده\nی ها  \n ی متن  به\nصورت خام ن\nی،ستند  \n نی از ا  رو با\nدی  متن را به گونه\nای  \nلی تبد  \n کرد تا شبکه قادر به درک و پردازش آن\nها باشد. جاساز کلمات روش\nی  ی برا  بازنما یی  \nکلمات است که هدف آن نما ی ش  معنا\nیی  \n کلمات در قالب بردار\nیی ها  ی حق یق  \n،است  یی جا  \n  که\n کلمات با معن\nی  و زم\nنه ی  مشابه با بردارها\nی  مشابه نشان داده م ی\nشوند\nنی . ا  ب\nردارها\nی  عدد\nی  \n در\nمقا سه ی با رو\nی کردها\nی آمار\nی \n در پردازش زبان طب\nیعی ی برا لی تبد کلمات به اعداد، ابعاد کم\nی تر \nدارند. هم ی چن ،ن  نیا  بردارها\nی  عدد\nی  اگر به خوب\nی  آموزش د\nی ده  شده باشند، توانا\nیی  نیا  \n را دارند\nکه ارتباطات معنا\nیی و نحو ی یب ن \n .کلمات را نشان دهند جاساز\nکلمات، سنگ بنا\nی ی ار ی بس \n از\n کارها\nی  \n انجام گرفته در حوزه پردازش زبان طب\nیعی  \n  است که از\nادگ ی یری  \n قی عم  استفاده م ی\nکنند.  \n جاساز کلمات را برا\nی  متون م ی\nتوان  از دو رو\nی\nکرد  متفاوت بدست آورد. در رو\nی\nکرد  \n  اول، در\nنیح  آموزش شبکه هم\nزمان با کار اصل\nی  اد ی  گرفته م\nی\nشوند\n. در ا\nنی  روش، در ابتدا مقاد\nری  عدد ی \nی برا  بردارها به\nصورت تصادف\nی  دی تول  م ی\nشود  و سپس در ح\nنی  آموزش ا\nنی  مقاد\nری  از طر\nیق  \nنه ی به\nی ساز  مانند د\nگر ی  یال ی ها ه  شبکه بروزرسان\nی   م ی\nشوند\n. رو\nی\nکرد  دوم، از طر\nیق  \n  آموزش دادن\nبا الگور\nتم ی\nی ها  خاص\nی  همانند  \nfasttext\n  \n  وglove\n  بررو\nی  مجموعه  داده\nی ها  \n بزرگ متن\nی  \n و\n استفاده از وزن\nی ها  بدست آمده از ا\nنی  الگور\nتم ی\nها  \n.است \n  حال\nبیاید تا  ورود ی ها ی  \n ی متن  را به بردارها\nی  جاساز تبد\nیل  \n می کن: \ntokenizer = Tokenizer(num_words=5000) \ntokenizer.fit_on_texts(X_train) \nX_train = tokenizer.texts_to_sequences(X_train) \nX_test = tokenizer.texts_to_sequences(X_test) \nvocab_size = len(tokenizer.word_index) + 1 \nmaxlen = 200 \n171 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \nX_train = pad_sequences(X_train, padding='post', maxlen=maxlen) \nX_test = pad_sequences(X_test, padding='post', maxlen=maxlen) \nما از جاساز ی  \n  کلمهGloVe\n  ی برا  لی تبد  ورود\nی ها ی  متن به همتا\nان ی  عدد\nی  خود استفاده خواه\nی م \n.کرد  \n:برای بارگیری آن کد زیر را وارد کنید \n!wget http://nlp.stanford.edu/data/glove.6B.zip \n!unzip glove*.zip \nبرای استفاده از آن به صورت زیر عمل می :کنیم \nfrom numpy import array \nfrom numpy import asarray \nfrom numpy import zeros \n \nembeddings_dictionary = dict() \n \nglove_file = open('glove.6B.100d.txt', encoding=\"utf8\") \n \nfor line in glove_file: \n    records = line.split() \n    word = records[0] \n    vector_dimensions = asarray(records[1:], dtype='float32') \n    embeddings_dictionary[word] = vector_dimensions \nglove_file.close() \n \nembedding_matrix = zeros((vocab_size, 100)) \nfor word, index in tokenizer.word_index.items(): \n    embedding_vector = embeddings_dictionary.get(word) \n    if embedding_vector is not None: \n        embedding_matrix[index] = embedding_vector \n  سپس با کد زیر مدل خود را ایجاد\nمی\nکنیم\n. مدل ما دارا\nی  کی  هیال  ورود\nی،  کی  هیال  جاساز،  کی  \nلایه \nLSTM\n  \n با128\n \n نورون و\nکی هیال خروج\nی \n با6 نورون خواهد بود، چراکه \n ما6 \n  برچسب در\nخروج\nی  می دار. \ndeep_inputs = Input(shape=(maxlen,)) \nembedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], \ntrainable=False)(deep_inputs) \nLSTM_Layer_1 = LSTM(128)(embedding_layer) \ndense_layer_1 = Dense(6, activation='sigmoid')(LSTM_Layer_1) \nmodel = Model(inputs=deep_inputs, outputs=dense_layer_1) \n \nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc']) \nد یی ایب  \n خالصه مدل را چاپ کن\nیم: \nprint(model.summary()) \nModel: \"model\" \n_________________________________________________________________ \n Layer (type)                Output Shape              Param #    \n================================================================= \n input_1 (InputLayer)        [(None, 200)]             0          \n                                                                  \n embedding (Embedding)       (None, 200, 100)          14824300   \n                                                                  \n lstm (LSTM)                 (None, 128)               117248     \n                                                                  \n dense (Dense)               (None, 6)                 774        \n                                                                  \n================================================================= \nTotal params: 14,942,322 \nTrainable params: 118,022 \nNon-trainable params: 14,824,300 \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 172 \n \n \n می  توان با استفاده از کد\nریز  معمار\nی  \n شبکه عصب\nی  \n :خود را به تصویر کشید \nfrom keras.utils.vis_utils import plot_model \nplot_model(model, to_file='model_plot4a.png', show_shapes=True, \nshow_layer_names=True) \n \nاز شکل باال م\nیبی دین  که ال\nهی  خروج\nی  \n  فقط شامل1\n  یال ه  متصل کامل  \n  با6\n  \n نورون است. حال\nد یی ایب  مدل خود را آموزش ده\nیم: \nhistory = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, \nvalidation_split=0.2) \nEpoch 1/5 \n798/798 [==============================] - 20s 17ms/step - loss: 0.1193 - acc: 0.9684 - val_loss: \n0.0739 - val_acc: 0.9941 \nEpoch 2/5 \n798/798 [==============================] - 13s 17ms/step - loss: 0.0643 - acc: 0.9927 - val_loss: \n0.0599 - val_acc: 0.9943 \nEpoch 3/5 \n798/798 [==============================] - 13s 17ms/step - loss: 0.0572 - acc: 0.9938 - val_loss: \n0.0573 - val_acc: 0.9935 \nEpoch 4/5 \n798/798 [==============================] - 13s 17ms/step - loss: 0.0548 - acc: 0.9939 - val_loss: \n0.0566 - val_acc: 0.9943 \nEpoch 5/5 \n798/798 [==============================] - 14s 17ms/step - loss: 0.0523 - acc: 0.9940 - val_loss: \n0.0542 - val_acc: 0.9942 \nحال ب\nد یی ای  مدل خود را در مجموعه آزما\nیشی  \n ی اب ی ارز  \n می کن: \nscore = model.evaluate(X_test, y_test, verbose=1) \nprint(\"Test Score:\", score[0]) \nprint(\"Test Accuracy:\", score[1]) \n998/998 [==============================] - 6s 6ms/step - loss: 0.0529 - acc: 0.9938 \nTest Score: 0.05285229906439781 \nTest Accuracy: 0.9937959909439087 \n  مدل ما به دقت99\n  \n  درصد\nدر مجموعه آزمون دست یافته است  که بس\nار ی  عالی  است.  در  ی نها ،ت  \nمقاد\nی ر زیان و دقت را برا\nی  مجموعه\nی ها آموزش ی \n و آزما\nشی ی ترس\nی م م ی می کن \n تا بب\nی نیم آیا \n  مدل ما\n  منجر به\nبیش\nبرازش  شده است  ای  ریخ. \nimport matplotlib.pyplot as plt \n \nplt.plot(history.history['acc']) \nplt.plot(history.history['val_acc']) \n \n173 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \nplt.title('model accuracy') \nplt.ylabel('accuracy') \nplt.xlabel('epoch') \nplt.legend(['train','test'], loc='upper left') \nplt.show() \n \n \nplt.plot(history.history['loss']) \nplt.plot(history.history['val_loss']) \n \nplt.title('model loss') \nplt.ylabel('loss') \nplt.xlabel('epoch') \nplt.legend(['train','test'], loc='upper left') \nplt.show() \n \nهمچنان که در تصاویر باال مشاهده می،کنید  مدل  منجر به بیش  .برازش نشده است \n  تحلیل احساسات باLSTM\n \nبا افزا\nشی  ابزارها\nی  \n  وب2  و ظهور رسانه\nی ها  اجتماع\nی،  زندگ\nی  \n  امروز\nجوامع بشری  با آن پ\nی وند \n یقی عم  \n خورده است. هم\nنی  امر منجر به تول\nدی  حجم عظ\nی می  \n از داده\nها توسط کاربران ا\nین  \n رسانه  ها\n شده است. داده\nی ها  \n ی متن  یکی  \n از پرمصرف\nی تر ها ن  است که م ی\nتواند  ی برا  \n  بدست آوردن اطالعات\nمهم در موضوعات مختلف مورد استفاده قرار گ\nرد ی\n. رسانه\nی ها  اجتماع\nی  \n  در اشکال گوناگون\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 174 \n \n \nخود همانند انجمن\nها، وبالگ\nها، م\nی\nکروبالگ،ها  ی سا ی ها ت  نظرده\nی  و غ\nره ی  \n روزانه منجر به\nدی تول  حجم وس\nیعی  از داده\nها م\nی\nشوند . چن\nنی  داده\nیی ها  در قالب نظرات، نقد\nها، د\nی دگاه\nها  \n در\n مورد خدمات، شرکت ها، سازمان\nها، رو\nی،دادها  افراد، م\nسائل  و موضوعات م ی\nباشد  . نظرات\nارائه شده کاربران در شبکه\nی ها  اجتماع\nی  ار ی بس  مهم و کابرد\nی  \n  هستند. در\nیک  \n  ،فروشگاه برخط\nنظرات و د\nی دگاه\nی ها  \n  مختلف در مورد\nکی  محصول م ی\nتواند  سطح رضا\nی ت  فی و ک تی  مشتر\nی  \n  را\nمنعکس سازد که ا\nین  م ی\nتواند  راهنما\nی  ار ی بس  ی خوب  ی برا  \n ری سا  ی خر\nداران  \n باشد. طبقه\nی بند  \n و\nسازمانده\nی  نیا  حجم بس\nار ی  می عظ  \n  از نظرات در مورد\nکی  موضوع خاص به\nصورت دست\nی  \n  کار\nآسان\nی  ست ین . از هم\nنی ،رو  از ین  \n  به کی  یس\nستم  خودکار برا\nی  \n جمع آور\nی  \n  نظرات منجر به ظهور\nیک \nنه ی زم  تحق\nی ی قات  دی جد  \n  به نام\nتحل\nلی  احساسات  (\nsentiment analysis\n )  \n  .شد  ،تحلیل احساسات\nنه ی زم  \n مطالعات\nی  است که هدف اصل\nی  آن شناسا\nیی،  استخراج و طبقه\nی بند  \n  ،احساسات، نظرات\n نگرش\nها، افکار، قضاوت\nها، نقدها و د\nی دگاه\nها  نسبت به موجود\nتی،ها  \n سازمان\nها، رو\nداد ی\nها  \n و\nره یغ  بدون تعامل انسان\nی  در قالب دسته\nی ها  مثبت، منف\nی  \n  ای و  ی خنث م ی\nباشد. \nدو رو\nی\nکرد  متفاوت\nی  که محقق\nنی  ی برا  طبقه\nی بند  \n  احساسات در\nکی  متن استفاده م ی،کنند \nی رو\nکرد\nی ها  \n بر ی مبتن  \n واژگان و مبتن\nبر ی  یری ادگ ی  ماش\nین  م ی\nباشد  .ی رو\nکرد  ی گر ید  را هم م\nی توان  \nی ترک یب  از ا\nین  \n دو نظر گرفت. رو\nی\nکرد  \n بر ی مبتن  \n واژگان، متمرکز بر استخراج کلم\nات  ای  \n عبارات ی  \nاست که م ی\nتواند  ند ی فرآ  \n طبقه\nی بند  را در جهت\nگیری  \n معنا\nیی  خاص\nی  تی هدا  کند. هر واژه دارا\nی  \nبار معنا\nیی  \n خاص\nی  است که از طر قی  کی  فرهنگ واژه از کلمات با بار احساس\nی  مثبت و منف\nی  \n  که\nیپ تر ش  ی امت\nازبند\nی  \n شده\nاند، استخراج م ی\nشود\n. با جمع امت\nاز ی  \n بار احساس\nی  واژه\nها  یا  \n  شمارش\nتعداد واژه\nی ها  \n با بار مثبت و منف\nی،  \n قطب\nتی  ی کل  جمله بدست م\nیآید\n. رو\nی\nکرد  یری ادگ ی  ماش\nین  \n  را\nم ی\nتوان  در حالت\nی ها  مختلف\nی  ی برا  مساله تحل\nیل  \n  احساسات آموزش داد و بکار برد. در حالت\nیری ادگ ی  \n  بانظارت با\nکی  مجموعه داده آموزش\nی  که پ\nتر شی  برچسب خورده است مدل آموز\nش  \nم ند یبی  \n  تا قادر به یری ادگ ی  شود و بتواند در مواجهه با داده\nی ها  ده ید  \n نشده رفتار\nی  \n مشابه با داده\nی ها  \nآموزش د\nده ی  \n.از خود نشان دهد   \nطی \n سال\nی ها ی اخ،ر به طور گسترده\nیا توسط محقق\nین \n اثبات شده است که مدل\nی ها بازنما یی  \n بر ی مبتن یری ادگ ی \n قی عم  در مساله\nی ها مرتبط با طبقه\nی بند احساسات کارآ\nیی بهتر\nی دارند .\n اتخاذ\nی رو\nکرد\nی ها یری ادگ ی \n قی عم در تحل\nلی احساسات به دل\nلی توانا\nیی \n ار ی بس باال\nی \n مدل\nی ها ری ادگ ی ی  \n قی عم  \n  یری ادگ ی در  ژگ یو ها ی  به صورت خودکار است که م ی\nتواند  به دقت و عملکرد بهتر\nی  \n  دست\nابند ی.  در بس\nی ار ی  از زم\nنه ی\nی ها  \n پردازش زبان طب\nیعی،  \n  استفاده از\nی یری ادگ  \n قی عم  \n  سبب شده است\nجی نتا  از آنچه که در گذشته توسط روش\nی ها  یری ادگ ی  \n نیش ما  \n و روش\nی ها  آمار\nی  \n  مورد استفاده\nقرار م ی\nگرفته  است،  فراتر رود. \n  حال که با تحلیل احساسات آشنایی پیدا کردید، بیاید تا به کمک شبکهLSTM\n  \n یک مدل\nتحلیل  احساسات  در  حوزه ی  نقدهای  فیلم.های  سینمایی  بسازیم  ی برا  نیا  اده یپ\nی ساز،  \n  از\n175 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \n  مجموعه دادهIMDB\n  \n  استفاده\nمی\nکنیم  .\n  مزیت این مجموعه داده این است که از قبل با کتابخانه\nمجموعه داده\nی ها  \nKeras\n  همراه است. \n ابتدا مجموعه داده را از طریق کد زیر بارگیری می :کنیم \nfrom keras.datasets import imdb  \ntop_words = 5000  \n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words) \nکد باال هم  زمان با بارگیری5000\n  \n  ،کلمه برتر هر نقد مجموعه داده را به دو مجموعه آموزشی و\n آزمایشی تقسیم می.کند  \n:حال بیاید تا نگاهی به مجموعه داده بیاندازیم \nX_train \narray([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, \n25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, \n39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, \n4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, \n18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, \n16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, \n16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, \n400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, \n7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, \n4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]), \n       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, \n       ..., \n       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, \n11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, \n575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, \n257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, \n13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, \n40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, \n52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, \n23]), \n       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, \n16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, \n7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, \n5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, \n12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, \n2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, \n27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, \n6, 1739, 22, 4, 204, 131, 9])], \n      dtype=object) \nاگر به داده\nها ی باال \n نگاه کن\nدی متوجه م\nدی شو ی \n که\nداده ها\nقبال پردازش شد\nاند ه\n. همه ِی \n کلمات به\nاعداد صح\nیح \n نگاشت شده\nاند و اعداد صح\nیح \n نشان\nدهنده کلمات مرتب شده بر اساس فراوان\nی  \nآن  .ها هستند،به عنوان مثال  4  نشان دهنده چهارم\nین  \n  ،کلمه پرکاربرد5  \n پنجم\nی ن  \n کلمه پرکاربرد و\nره یغ  است.  عدد صح\nیح  \n1\n  ی برا  نشانگر شروع، عدد صح حی  \n2\n  ی برا  کی  \n  کلمه ناشناخته و0 \nی برا  \npadding\n  \n.رزرو شده است  اگر م ی\nخواه\nید  \n  خودتان به\nنقدها  نگاه\nی  بی\nنداز\nید  \n ی و بب ین د  \n  مردم\nچه نوشته\nاند، م\nی\nتوان\nدی  نیا  روند را ن\nیز  \n معکوس کن\nید : \nword_index = imdb.get_word_index() # get {word : index} \nindex_word = {v : k for k,v in word_index.items()} # get {index : word} \nindex = 1 \nprint(\" \".join([index_word[idx] for idx in x_train[index]])) \nprint(\"positve\" if y_train[index]==1 else \"negetive\") \nthe thought solid thought senator do making to is spot nomination assumed while he of \njack in where picked as getting on was did hands fact characters to always life \nthrillers not as me can't in at are br of sure your way of little it strongly random \nto view of love it so principles of guy it used producer of where it of here icon film \nof outside to don't all unique some like of direction it if out her imagination below \nkeep of queen he diverse to makes this stretch stefan of solid it thought begins br \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 176 \n \n \nsenator machinations budget worthwhile though ok brokedown awaiting for ever better \nwere lugia diverse for budget look kicked any to of making it out bosworth's follows \nfor effects show to show cast this family us scenes more it severe making senator to \nlevant's finds tv tend to of emerged these thing wants but fuher an beckinsale cult as \nit is video do you david see scenery it in few those are of ship for with of wild to \none is very work dark they don't do dvd with those them \nnegetive \nاز آنجا\nیی  \n  که،نقدها  \n ِاز نظر  طول بس\nار ی  متفاوت هستند، م\nی\nخواه\nیم  \n  هر\nنقد  \n  را به500\n  \n کلمه\nاول برش ده\nیم\n. ما با\nدی  نمونه\nی ها  \n ی متن  \n  با طول\nی\nکسان  داشته باش\nی م  تا بتوان\nمی  آن ها را به شبکه\n عصب\nی  \n خود وارد کن\nمی  . اگر\nنقدها  \n کوتاه  تر از500\n  کلمه باشند، آن\nها را با صفر اضافه م ی می کن .\nKeras\n  \n  برای این کار\nار ی بس  \n عالی  \n  ،است  چراکه\nمجموعه\nیا  از روال\nی ها  یپ ش  پردازش را ارائه\nم ی\nدهد که م\nی\nتواند ا\nنی  کار را براحت\nی  ی برا  ما انجام دهد: \nword_index = imdb.get_word_index() # get {word : index} \nindex_word = {v : k for k,v in word_index.items()} # get {index : word} \nindex = 1 \nprint(\" \".join([index_word[idx] for idx in x_train[index]])) \nprint(\"positve\" if y_train[index]==1 else \"negetive\") \nبرای درک بهتر بیاید یک نمونه از داده ها را به صورت تصادفی انتخاب کنیم و مشاهده کنیم که\n:کد باال چه کاری انجام داده است \nX_train[125] \narray([    0,     0,     0,     0,     0,     0,     0,     0,     0, \n           0,     0,     0,     0,     0,     0,     0,     0,     0, \n           0,     0,     0,     0,     0,     0,     0,     0,     0, \n           0,     0,     0,     0,     0,     0,     0,     0,     0, \n           0,     0,     0,     0,     0,     0,     0,     0,     0, \n           0,     0,     0,     0,     0,     0,     0,     0,     0, \n           0,     0,     0,     0,     0,     0,     0,     1,    11, \n           6,    58,    54,     4, 14537,     5,  6495,     4,  2351, \n        1630,    71, 13202,    23,    26, 20094, 40865,    34,    35, \n        9454,  1680,     8,  6681,   692,    39,    94,   205,  6177, \n         712,   121,     4, 18147,  7037,   406,  2657,     5,  2189, \n       61778,    26, 23906, 11420,     6,   708,    44,     4,  1110, \n         656,  4667,   206,    15,   230, 13781,    15,     7,     4, \n        4847,    36,    26, 54759,   238,   306,  2316,   190,    48, \n          25,   181,     8,    67,     6,    22,    44,    15,   353, \n        1659, 84675,  3048,     4,  9818,   305,    88, 11493,     9, \n          31,     7,     4,    91, 12789, 53410,  3106,   126,    93, \n          40,   670,  8759, 41931,     6,  6951,     4,   167,    47, \n         623,    23,     6,   875,    29,   186,   340,  4447,     7, \n           5, 44141,    27,  5485,    23,   220,   175,  2122,    10, \n          10,    27,  4847,    26,     6,  5261,  2631,   604,     7, \n        2118, 23310, 36011,  5350,    17,    48,    29,    71, 12129, \n          18,  1168, 38886, 33829,  1918, 31235,  3255,  9977, 31537, \n        9248,    40,    35,  1755,   362,    11,     4,  2370,  2222, \n          56,     7,     4, 23052,  2489,    39,   609, 82401, 48583, \n           6,  3440,   655,   707,  4198,  3801,    37,  4486,    33, \n         175,  2631,   114,   471,    17,    48,    36,   181,     8, \n          30,  1059,     4,  3408,  5963,  2396,     6,   117,   128, \n          21,    26,   131,  4218,    11, 20663,  3826, 14524,    10, \n          10,    12,     9,   614,     8,    97,     6,  1393,    22, \n          44,   995,    84, 21800,  5801,    21,    14,     9,     6, \n        4953,    22,    44,   995,    84,    93,    34,    84,    37, \n         104,   507, 11076,    37,    26,   662,   180,     8,     4, \n        5075,    11,   882,    71,    31,     8, 39022, 36011, 31537, \n           5, 48583,    19,  1240, 31800,  1806, 11521,     5,  7863, \n       28281,     4,   959,    62,   165,    30,     8,  2988,     4, \n177 \n فصل\nپنجم: شبکه\nهای عصبی بازگشتی \n \n        2772,  1500,     7,     4,    22,    24,  2358,    12,    10, \n          10, 22993,   238,    43,    28,   188,   245,    19,    27, \n         105,     5,   687,    48,    29,   562,    98,   615,    21, \n          27,  8500,     9,    38,  2797,     4,   548,   139,    62, \n        9343,     6, 14053,   707,   137,     4,  1205,     7,     4, \n        6556,     9,    53,  2797,    74,     4,  6556,   410,     5, \n          27,  5150,     8,    79,    27,   177,     8,  3126,    19, \n          33,   222,    49, 22895,     7, 14090,   406,  5424,    38, \n        4144,    15,    12,     9,   165,  2268,     8,   106,   318, \n         760,   215,    30,    93,   133,     7, 31537,    38,    55, \n          52,    11, 26149, 17310,  1080, 24192, 68007,    29,     9, \n        6248,    78,   133,    11,     6,   239,    15,     9,    38, \n         230,   120,     4,   350,    45,   145,   174,    10,    10, \n       22993,    47,    93,    49,   478,   108,    21,    25,    62, \n         115,   482,    12,    39,    14,  2342,   947,     6,  6950, \n           8,    27,   157,    62,   115,   181,     8,    67,   160, \n           7,    27,   108,   103,    14,    63,    62,    30,     6, \n          87,   902,  2152,  3572,     5,     6,   619,   437,     7, \n           6,  4616,   221,   819,    31,   323,    46,     7,   747, \n           5,   198,   112,    55,  3591], dtype=int32) \nهمانطور که در باال م یبی دین ، به دلیل اینکه این رکورد طولی کم  تر از500\n  \n  کلمه  داشته  ،است\n  تعدادی0  \n  جلوی آن قرار گرفته است تا این رکورد طولی برابر با500\n  \n.داشته باشد \nبه طرز تعجب\nآور\nی  کار  پیش\nپردازش  داده\nها ی ما به تمام رسید و  اکنون  یم\nتوان\nیم  \n شروع به\n ساخت مدل خود کن\nیم: \nfrom keras.models import Sequential \nfrom keras.layers import Embedding \nfrom keras.layers import LSTM, Dense   \nembedding_vector_length = 32  \nmodel = Sequential()  \nmodel.add(Embedding(top_words, embedding_vector_length, \ninput_length=max_review_length))  \nmodel.add(LSTM(100))  \nmodel.add(Dense(1, activation='sigmoid'))  \nmodel.compile(loss='binary_crossentropy',optimizer='adam', \nmetrics=['accuracy'])  \nprint(model.summary()) \nModel: \"sequential_2\" \n_________________________________________________________________ \n Layer (type)                Output Shape              Param #    \n================================================================= \n embedding (Embedding)       (None, 500, 32)           160000     \n                                                                  \n lstm (LSTM)                 (None, 100)               53200      \n                                                                  \n dense (Dense)               (None, 1)                 101        \n                                                                  \n================================================================= \nTotal params: 213,301 \nTrainable params: 213,301 \nNon-trainable params: 0 \n_________________________________________________________________ \nNone \nهمان طور که پیش  تر بیان شد، دو راه برای جاساز کلمات وجود دارد. در مثال قبلی ما از جاساز\nکلمات از پیش  آموزش دیده استفاده کردیم. در این مثال از الیهEmbedding\n  استفاده می .کنیم\nلایه  \nembedding\n کی  جاساز  کلمات  را  از  \n  مجموعه داده\nاد ی  رد یگیم  .\n \n اکنون نوبت به آموزش مدل می:رسد \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 178 \n \n \nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, \nbatch_size=32) \nEpoch 1/5 \n782/782 [==============================] - 82s 103ms/step - loss: 0.4681 - accuracy: \n0.7815 - val_loss: 0.3702 - val_accuracy: 0.8430 \nEpoch 2/5 \n782/782 [==============================] - 79s 101ms/step - loss: 0.3340 - accuracy: \n0.8618 - val_loss: 0.3984 - val_accuracy: 0.8299 \nEpoch 3/5 \n782/782 [==============================] - 80s 102ms/step - loss: 0.2669 - accuracy: \n0.8954 - val_loss: 0.3272 - val_accuracy: 0.8657 \nEpoch 4/5 \n782/782 [==============================] - 80s 102ms/step - loss: 0.2259 - accuracy: \n0.9117 - val_loss: 0.3122 - val_accuracy: 0.8713 \nEpoch 5/5 \n782/782 [==============================] - 79s 101ms/step - loss: 0.1912 - accuracy: \n0.9270 - val_loss: 0.3399 - val_accuracy: 0.8604 \n  ،پس از اتمام آموزش مدل :نوبت ارزیابی کارایی مدل است \nscores = model.evaluate(X_test, y_test, verbose=0)  \nprint(\"Accuracy: %.2f%%\" % (scores[1]*100)) \nAccuracy: 86.04% \nهمان طور که مشاهده می\nشود  مدل  در عین سادگی توانسته است  به دقت\nی  \n  حدود86\n  \n درصد دست\nبد ای  \n  که با توجه به\nمسئله  دشوار بس\nار ی  \n ی عال  \n  .است  با این حال، این مدلِبهترین مدل  \n  ممکن\nنیست. به عنوان تمرین، می  توانید با آزمایش برروی ابرپارمترهای مختلف  نتایج را مشاهده کنید\n.و یک مدل با کارایی باال بسازید  هم\nچنین، نمودار زیان و دقت را برای مدل ها رسم کنید و ببینید\n آیا مدل\nها منجر به بیش برازش شده\nاند یا خیر. در مورد مدل با\nال نظر شما در خصوص بیش  برازش\n چیست؟ \nخالصه فصل \n \n▪ \n شبکه\nی ها عصب\nی بازگشت\nی، \n نواقصِ شبکه\nها ی عصبِی  شیپ\nخور را برطرف م ی\nکنند.\n \n▪ \nRNNی ها \n ساده قادر به\nادگ ی\nری ی وابستگ\nها ی ی \n بلند مدت .نیستند \n▪ \nLSTM\n  می\nتواند  وابستگ\nی ها ی  بلندمدت را به دل\nیِل  \n  وجود کی  \n سلول حافظه ی  \n  مخصوص\n.در ساختارش، انجام دهد \n آزمونک \n یکLSTM\n چه تعداد دروازه دارد و نقش هر یک از آن\nها چیست؟ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n6 \n \n▪\n \n تفاوت مدل مولد با مدل تفکیک\nگر \n▪\n آشنایی با شبکه متخاصم مولد \n▪\n \n آموزش به شیوه تخاصمی \n▪\n \n تولید ارقام دست\nنویس با شبکه متخاصم مولد \n \n:اهداف یادگیری \nشبکه متخاصم \n مولد \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 180 \n \n \n مقدمه \nدر ا\nنی  فصل قصد دار\nمی  به معرف\nی  خانواده\nیا  از مدل\nی ها  مولد بر اساس برخ\nی  مفاه\nمی  تئور\nی  \nباز ی\nها بپرداز\nژگ ی . و میِی  اصل\nی  \n آن  کی ها  \n روش آموزش\nی  \nِمتخاصم است که با هدف  ادگ ی ریِی  ی تما ز  \nنیب  نمونه\nی ها  واقع\nی  و جعل\nی  توسط یک مولفه،  \n در همان زمان، مولفه\nی دیگری  نمونه هایی را  \nبی\nشتر  ی و ب شتر  \n ی شب ه  به نمونه\nها ی  آموزش\nی  دی تول  م ی.کند  \n  به صورت خالصه\nدر این شبکه\nها  ،کی ی \nدی تول  م کند ی  ،ی گر ید  نکته\nگیری   کند یم  \n  و در کنار هم و در\nکی  همکار\nی  کامل، نتا\nجی  بس ار ی  ی خوب  \nب\nدست م ی\nآورند. \nمدل مولد چیست؟ \nبه  طور کلی\nدو نوع مدل اصل\nی  \n  یری ادگ ی در  ماش\nنی  وجود دارد :  مدل مولد (\ngenerative model\n)  \n  و  مدل تفکیک(  گرdiscriminative model\n)\n  .یک  \n  مدل\nتفک\nگر کی،  \n همان  طور که  از  نامش\nیپ،داست  \n ی سع  م ی\nکند داده\nها  را  نیب  \n  دو\nیا  \n  چند  کالس تفکیک  کند  .به  ،طور کلی مدل\nی ها  \nتفک\nی گر ک  بر پ\nی شبی نی  \n کالس\nی ها  داده با توجه به و\nی ها ی ژگ ی  \n آن ها ت\nمرکز  م ی\nکنند  . برعکس، مدل\nمولد سع\nی \n نم کند ی ها ی ژگ یو \n را به کالس ها\nنگاشت \n ،کند\nبلکه ژگ یو یی ها ی را تول\nدی م کند ی که در  \nیک  \n  کالس خاص وجود دارد  .ی ک  راه آسان برا\nی  تشخ\nیص  یک  \n  مدل\nمولد  \n  کی از  مدل تفک\nگر کی  \nوجود دارد: \n▪\n مدل  تفک\nی گر ک  \n  ی به\nافتن  \n  مرزها ای  قوان\nی ین  ی برا  تفک\nکی  داده\nها عالقه\nمند است. \n▪\n مدل  مولد  \n بر مدل\nسازِی  \n ی توز ع  داده\nها تمرکز دارد . \n تعریف1.6\n مدل مولد \nکی مدل مولد نحوه تول\nید یک \n مجموعه داده را بر اساس\nکی مدل احتمال\nی توص\nفی یم.کند \n مدل\nی ها  مولد ابزار قدرتمند\nی  ی برا  بررس\nی  ی توز ع  داده  ای ها  \n تخم\nنی  چگال\nی  مجموعه\nی ها  \n داده\nهستند. مدل\nی ها  \n  مولد از ی ادگ ی یر  بدون\nنظارت پ\nی رو ی  م ی\nکنند که به  طور خودکار الگوها\nی ا  \nیب نظم\nی ها ی  داده\nی ها  مورد تجز هی  و تحل\nیل  \n را کشف م ی\nکند. ا\nنی  به تول\nدی  داده\nی ها  یدی جد  \n  که\nعمدت\nا  \n هی شب  مجموعه داده اصل\nی  است کمک م کند ی\n. به\nطور دق\nی،ق  \n هدف مدل\nی ها  مولد  ی ادگ ی رِی  \nی توزِع  واقعِی  داده\nها در  مجموعه آموزش\nی،  براِی  ی تولِد  \nِنقاط  دادهِی  دی جد  با برخ\nی  یی تغ\nرات  \n .است \n هدف اصل\nی  \n انواع مدل\nی ها  \n  مولد\nیری ادگ ی  ی توزِع  \n واقعِی  داده\nهاِی  مجموعه آموزش\nی  \n  است تا\nنقاط داده جد\nدی  با تغ\nیی\nی رات  ی تول د  شوند. اما ا\nنی  امکان برا\nی  مدل وجود ندارد که توز\nی ع  ی دق ق \nداده\nی ها  ما را ب\nی\nاموزد  و بنابرا\nنی  یعی توز  \n را مدل\nی ساز  م ی می کن  \n که مشابه توز\nی ع  داده\nی ها  یع واق  \n181 \n فصل\nششم: \n شبکه متخاصم مولد \n \nاست. برا\nی  نیا  کار، ما از دانش شبکه\nی ها  \n عصب\nی  ی برا  یری ادگ ی  تابع ی  استفاده م ی می کن  که م\nی تواند  \nی توز ع  مدل را به توز\nی ع  واقع\nی  تقر بی  \n.بزند \nمدل\nی ها  مولد  را  م\nی\nتوان  \n  به  عنوان\nکی  کالس  از  مدل\nها  تعر فی  کرد  که  هدف  آن  ها\nادگ ی\nیری  نحوهِی  تول دی  نمونه ی ها  یدی جد  است که به نظر م\nی\nرسد  \n  از همان مجموعه\nداده\nی ها  آموزش ی  \n  ،هستند. در طول مرحله آموزش\nیک  \n  مدل مولد در تالش است\nیک  \nمساله تخم\nنی  چگال\nی  \n را حل کند. در تخم\nنی  چگا\nیل،  مدل م\nی\nآموزد  \n  کی تا  تخم\nین  \n  تا حد\n امکان شب\nهی  به تابع چگال\nی  احتمال غ\nی\nرقابل  مشاهده بسازد. نکته مهم ا\nین  \n  ،است که\nمدل مولد با\nدی  بتواند نمونه ی ها  یدی جد  از توز\nعی  را تشک\nلی  دهد و نه فقط نمونه\nها ی \nموجود را رونوشت و ا\nی\nجاد \n .کند \n \nمدل\nی ها  مولد  ط\nی  \n  دهه  گذشته  در  خط  مقدم\nادگ ی یری  بدونِنظارت  \n قی عم  \n  قرار\nداشته اند. دل\nلی  نیا  امر ا\nنی  است که آن\nها روش\nی  بس\nار ی  کارآمد را برا\nی  تجز\nهی  و تحل\nیل  \n  و\nدرک داده\nی ها بدون برچسب ارائه م\nی دهند . \n مدل های مولد و آینده هوش مصنوعی ؟ \nسه دل\nلی  کلی  وجود دارد که چرا مدل\nهای  مولد را م ی\nتوان  ی کلِد  بازگشاِیی  \nِشکل  ار ی بس  یچیپ تر ده ی  \nاز هوش مصنوع\nی  در نظر گرفت  که فراتر از آن چ\nیزی  \n  است که مدل\nهای  \n تفکیک\nگر  یم\nتوان دن  \n  به\n  آن دست\nاب ی دن. \n▪ \n،اوال  \nِصرفا از نقطه نظر  تئوری  ما نبا\nدی  تنها به توانا\nیی  برتر در طبقه\nی بند  داده ها بسنده\n ی کن،م  بلکه با\nدی  به دنبال درک کامل\nی تر  از نحوه تول\nدی  داده\nها در وهله اول باش\nمی . بدون\nشک حل ا\nنی  مسئله بسیار  دشوارتر  \n در مقایسه روش\nهای تفکیک\nگر  است  .نی با ا  \n ،حال\nهمان\nطور که خواه\nمی  ید،د  ار ی بس ی  \n از تکن\nی ها کی  مشابه\nی  \n که باعث توسعه در مدل\nساز ی  \n تفکیک\nگر  شده\nاند  (ه  مانند\nیری ادگ ی  \n قی عم)،  یم\nتوانند  توسط مدل\nی ها  مولد  زین  \n  مورد\nاستفاده قرار گ رند ی. \n▪ \n،دوم  نیا  احتمال وجود دارد که مدل ی ساز  مولد براِی  ی هداِت  پ ی شرفت\nی ها  نده یآ  \n  در\nنه ی زم\nی ها  گر ید  یری ادگ ی  ماش\nی،ن   ه  مانند\nیری ادگ ی  \n یتی تقو،  \n مهم\nتر و تاث\nی\nرگذارتر  از هر چ\nیز \nی گر ید  باشد  .به عنوان مثال، م ی\nتوان\nیم  \n  یری ادگ ی از  ی تقو یت  ی برا  \n  آموزش\nکی  ربات برا ی  \n  راه رفتن در\nکی  نی زم  \n خاص استفاده کن\nیم\n. رو\nی\nکرد  ی کل،  \n  ساخت\nی ک  \n هی شب\nی ساز  را ا انه ی ی  \nاز زم\nنی  و سپس اجرا\nی  آزما\nشی ی ها  ی اد یز  \n است که در آن عامل استراتژ\nی ها ی  \n  مختلف\nرا امتحان م کند ی  ،. با گذشت زمان\nعامل  یم\nآموزد  \n که کدام استراتژ\nها ی  \n موفق\nتر از س\nایری ن  \nهستند و بنابرا\nنی  به تدر جی  بهبود م ابند یی  .کی  مشکل معمول\nی  با ا نی  ی رو\nکرد  نیا  \n  است\nکه ف\nکیزی  مح طی  اغلب بس ار ی  یپ ده یچ  است و با\nید  \n  در هر مرحله محاسبه شود تا اطالعات\nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 182 \n \n \nبه عامل برا\nی  \n تصم\nیمگیری  \nِدر مورد حرکت  بعدِی  خود،  بازگردانده شود. با ا\nین  \n حال، اگر\nعامل بتواند مح\nیط  \n خود را از طر\nیق  یک  \n مدل مولد شب\nی ه\nی ساز  کند، ن\nی از ی  به آزما ی ش  \n استراتژ\nی  \n در شب\nیه\nی ساز  \n رایانه\nای  ای  در دن\nیای  واقع\nی  نخواهد داشت، بلکه م\nی\nتواند  \n  در\nطی مح  ی ال یخ  خود ب\nی\nاموزد  .\n \n▪ در  ی نها،ت  اگر واقعا بخواه\nیم  \n بگو\nم یی  که ماش\nی ین  ساخته\nمیا  که شکل\nی  \n از هوش را بدست\nآورده است که با هوش انسان قابل مقا سه ی \n است، مدل\nی ساز مولد مطمئنا با\nدی بخش\nی \n  از\nراه  .حل باشد\nیکی  از بهتر\nنی  نمونه\nی ها  مدل مولد در دن\nیای  واقعی،  شخص\nی  است که ا\nی ن  \nکتاب را م\nی\nخواند. ل\nحظه\nیا به ا نی \n فکر کن\nدی که شما چه مدل م\nولد باورنکردن\nی هست\nید .\nم ی\nتوان\nدی  چشمان خود را ببند\nید  \n و تصور کن\nید  \n  که کی  لیف  \n از هر زاو\nهی  ممکن چه شکل ی  \nاست. شما م\nی\nتوان\nدی  تعدادِی  ان ی پا  متفاوت و قابل قبول برا\nی  برنامه تلو\nی ون یزی  \n  مورد عالقه\n خود تصور کن\nید  \n  و  همچنین شما م\nی\nتوان\nید  \n هفته خود را با کار از طر قی  نده یآ  \n در ذهن خود\n برنامه\nیزیر  کرده  \n و براساس آن اقدام کن\nید\n. نظر\nیه  \n عصب\nشناس\nی  فعلی  نشان م ی\nدهد  \n  که\nدرک ما از واقع\nیت  یک \n مدل\nتفکیک\nگر ار ی بس ده یچیپ ست ین که بر رو\nی ورود\nی ی حس \n  ما\nی برا  دی تول  یبشیپ یی ها ین  از آنچه تجربه م\nی ی کن م  عمل م\nی،کند  \n  بلکه در عوض\nیک  \n مدل\nمولد  \n  است که از  بدو\nتولد برا\nی  دی تول  \n هی شب\nی ساز  طی مح  اطرافمان که دق\nقا ی  نده ی با آ  \n تطب\nی ق \nم ی،کند  آموزش داده م\nی\nشود.   \n شبکه متخاصم مولد(\nGenerative     Adversarial    Network\n )\n \nبه نحوهِی  یری ادگ ی  \n خود فکر کن دی\n. شما چ\nیزی  را امتحان م ی دی کن  \n  و\nبازخورد در\nافت ی  م ی دی کن  .\n شما استراتژ\nی  خود را تنظ می  یم دی کن  و دوباره تالش م\nی دی کن . بازخورد ممکن است به شکل\n  انتقاد، درد\nای  سود باشد. ممکن است از قضاوت خودتان در مورد ا\nی نکه  \n چقدر خوب عمل\nکرده\nاید  \n ناش\nی  د شو  .\n  ،با این حال\nاغلب  \n  اوقات\nنی دتر ی مف   با\nزخورد، بازخورد\nی  \n  است که از طرف\nشخص د\nی گر ی   م یآی،د  چراکه  \n  فقط\nیک  \n  عدد\nای  احساس ن ی،ست  بلکه ارز\nی اب ی  \n هوشمندانه\nای  \n  است\nاز ا\nنکه ی  چقدر کار را به خوب\nی  انجام داده\nاید. \nهنگام\nی  \n  کی که  رایانه  ی برا  کی  کار آموزش داده م ی  شود، انسان معموال بازخورد را در قالب\n  تنظیم  پارامترها\nای  الگور\nی تم  ها\nارائه م ی\nدهد. وقت\nی  \n  کار\nساده\nای  \n  مانند\nیری ادگ ی  ضرب دو عدد  باشد ،\n این بازخورد آسان\nتر است\n. شما م\nی\nتوان\nدی  براحت\nی  و دق\nقا ی  هب  انه ی را  بگو\nد یی  \n که چگونه اشتباه کرده\n  .است حال آن\nکه با یک  کار پ\nچی ده ی\nتر، مانند ا ی\nجاد  \n تصو\nیری  \n  از\nگربه\n، ارائهِی  \n  بازخورد دشوارتر\nم ی\nشود. آ\nای تصو\nری تار است، آ\nیا  بی\nشتر \n هی شب کی سگ \n است ای \n اصال شب\nهی یزیچ است؟ م\nی توان  \nآمارها\nی  یچیپ یا ده  را پ\nاده ی\nساز ی  کرد، اما ثبت تمام جزئ\nی ات ی  \n  کی که  تصو\nری  را واقع\nی  \n  جلوه\nم ی،دهد  \n  .دشوار است\nیک  \n انسان م\nی تواند تخم\nین  \n  ،بزند\nچراکه  ما تجربه ز\nی اد ی  \n در ارز\nی اب ی  ورود ی  \n183 \n فصل\nششم: \n شبکه متخاصم مولد \n \nبصر\nی  ی دار،م  \n اما نسبتا کند هست\nمی  و ارز\nی ها ی اب ی  ما م\nی\nتواند بس\nار ی  \n ی ذهن  \n باشد. در عوض\nم ی\nتوان\nیم  یک  \n شبکه عصب\nی  را آموزش ده\nمی  تا وظ\nفه ی  زی تما  نیب  تصاو\nری  ی اقع و  و تول\nید  \n  شده را\nبی\nاموزد  ،. سپس می  توان  به\nمولد  تصو\nیر  \n (شبکه عصب\nی  ) و\nتمایزگر  فرصت داد تا  \n  گر ی کد ی از  ی اد  \nبگیرند و  \n  در طول زمان بهبود\nابند ی\nنی . ا  دو شبکه که ا\nنی  ی باز  را انجام م ی  ،دهند\nیک  \n شبکه\n.متخاصم مولد هستند \n شبکه\nی ها  \n متخاصم مولد  \n  یا به اختصارGAN\n،  \n دسته\nای  \n از تکن\nی ها کی  ی ادگ ی یر  ماش\nین  \n  هستند\nکه از دو مدل آموزش داده شده به\nطور هم\nزمان تشک\nیل  \n شده  :اند\nیکی  مولد  (\nGenerator\n  ) که\nی برا  دی تول  داده\nی ها  ی جعل  آموزش داده شده است و د\nی گر ی  تما زگر ی  (\nDiscriminator) که  \nآموزش د\nده ی  \n  است تا به\nتشخ\nصی  داده\nی ها  ی جعل  از نمونه\nی ها  واقع\nی  \n.بپردازد  کلمه مولد،  \n هدف\nی کل  مدل را نشان م ی  :دهد\nای\nجاد داده\nی ها  دی جد\n. داده\nیی ها  \n  کی که \nGAN\n اد ی  رد یگیم  دی تول  \n کند\nبه انتخاب مجموعه آموزش\nی  بستگ\nی  دارد. برا ی  مثال، اگر بخواه می  ی ک  \nGAN\n  تصاو\nیری  \n هی شب \nبه داو\nی نچ ی  را ترک\nبی  کند، از مجموعه داده آموزش\nی  آثار هنر\nی  ی نچ ی داو  اس\nتفاده  م ی می کن. \n  اصطالح\nتخاصم  (\nadversarial\n)  به رقابت\nی  پویا  و باز\nیِمانند  یب ن  دو مدل\nی  که چارچوب \nGAN \n را تشک\nیل  می\nدهند  اشاره دارد  :مولد  \n  و\nتمایزگر  .هدف \n مولد ا ی\nجاد  نمونه\nیی ها  \n  است که از\nداده\nی ها  واقع\nی  در مجموعه آموزش\nی  قابل تشخ\nیص  نی\nستند\n. در مثال ما، ا\nنی  به معنا\nی  ی تول د  \n نقاش\nی  یی ها  است که دق\nقا ی  \n هی شب  \n نقاش ی ها ی  ی نچ ی داو  هستند. هدف \n تمایزگر تشخ\nصی  نمونه\nی ها  \nی جعل  دی تول  شده توسط مولد از نمونه\nهاِی  \nِواقع\nی  حاصل از مجموعه داده\nهاِی  آموزش\nی  \n است. در\n  ،مثال ما،تمایزگر \n  نقش\nکی  متخصص هنر\nی  را باز\nی  می\nکند که اصالت نقاش یی ها ی  \n  را که تصور\nم ی\nشود متعلق به داو ی نچ ی  است، ارز\nی اب ی  م ی\nکند. ا\nین  \n دو شبکه به طور مداوم در تالش هستند تا\nگر ی کد ی  را فر\nبی  دهند: هر چه مولد در ا\nی\nجاد  داده\nهاِی  \n واقع بینانه  \n  ،بهتر باشد\nتمایزگر  دی با  \n  در\nتشخ\nصی  نمونه\nی ها  واقع\nی  از نمونه\nی ها  ی جعل  \n  بهتر\nعمل کند. \nدر  ی نها،ت  کلمه شبکهِها کالس  مدل\nی ها  ی ادگ ی رِی  ماش\nی ین  را نشان م ی\nدهد  که معموال برا ی \n  نشان دادن\nمولد  \n  و\nتمایزگر  استفاده م\nی\nشوند  :شبکه\nی ها  عصب\nی\n. بسته به پ\nی دگ یچی  اده یپ\nساز ی  \nGANی ، م\nتوانند از شبکه\nی ها  \n عصب\nی  پیش\nخور  ساده تا شبکه\nی ها  \n عصب\nی  \n کانولوشن\nی   ای  ی حت  \n  انواع\nتر ده یچیپ  ی از آن.ها باشند \nاض یر ات ی  یز\nیی ربنا  \nGANچی ها پ ده ی  هستند  .خوشبختانه، بس\nی ار ی  از ق\nی اس\nهاِی  ای دنِی  واقع\nی \nم ی  توانند درکGANها را آسان\nتر کنند. در مثال  قبلی در مورد  کی  \nِجاعل  ی هنر  \n  (مولد) صحبت\nمی کرد  که تالش م ی  کند\nکی  مت\nخصص  ی هنر  (تما\nزگر ی\n) را فر\nبی  دهد. هر چه نقاش\nی ها ی  جعل ی  \nکه جاعل م\nی\nسازد متقاعدکننده\nتر باشد، متخصص هنر ی  دی با  در تشخ\nیص  \n صحت آن ها بهتر\nعمل کند\nی . ا ن  امر در وضع\nتی  معکوس ن\nزی  صادق است: هر چه متخصص هنر\nی  در تشخ\nیص  \nواقع\nی  \n  بودن\nکی  نقاشِی  خاص بهتر باشد، جاعل با\nدی  ی برا  جلوگ\nری ی  از  گرفتار شدن،  \n  بهتر عمل\nکند. \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 184 \n \n \n  به عبارت\nدقیق\nترِ، هدف  \n،مولد  دی تول  نمونه\nیی ها  است که و\nها ی ژگ یِی  مجموعه داده آموزش ی  \nرا به تصو\nیر  می\nکشد، به\nی طور  که نمونه\nیی ها  که تول\nید  می\nکند از داده\nی ها  آموزش\nی  قابل تشخ\nیص  \nنی\nستند  .مولد  را م ی  توان به عنوان\nکی  مدل تشخ\nیص  شی  \n  در\nوضعیت معکوس  \n  .در نظر گرفت\nالگور\nی یاه تم  تشخ\nصی  ای اش  الگوها\nی  موجود در تصاو\nیر  \n  اد ی را  رند یگیم  تا محتوا\nی  کی  تصو\nیر  \nرا تشخ\nیص  \n  .دهند  ،در مقابل\nبه جا\nی  تشخ\nیص  \n  ،الگوها\nمولد  اد ی  م رد یگی  که اساسا آن ها را از\nابتدا ا\nی\nجاد  کند. در واقع، ورود ی  مولد  اغلب ب\nیش  \n  کی از  بردار اعداد تصادف\nی  ست ین.  \n  مولد از\nقی طر  \n بازخوردها\nیی  \n  که از تمایزگر  افت ی در  م ی  ،کند\nاد ی  م رد یگی  . هدف،تمایزگر  ن یی تع  نیا  \n  است\nای که آ  کی  \n نمونهِی  خاص واقع\nی  (برگرفته از مجموعه داده آموزش\nی  )ای  ی جعل  (ا ی\nجاد  \n  شده توسط\nمولد)  است\n. بر ا\nین  \n  اساس، هر بار که\nتمایزگر  \n بی فر  خورده  \n  کی و  تصو\nری  ی جعل  \n  را به عنوان\nواقع\nی  طبقه\nبندی  یم  ،کند،مولد   یم\nداند که کار\nی  را به خوب\nی  \n انجام داده است. برعکس، هر بار\n  که\nتمایزگر  به درست\nی  \n تصو\nری  دی تول  \n  شده توسط\nمولد  را به عنوان جعل\nی  رد م\nی  ،کند\nمولد  بازخورد ی  \nرا در\nافت ی  م ی\nکند که با\nدی  به بود  ابد ی.  تمایزگر  زین  به بهبود خود ادامه م\nی\nدهد  . مانند هر\nطبقه بند\nدیگری،  \n  از\nاختالف بین  یپ یبش شی ها ین  \n با برچسب\nی ها  واقع\nی  (واقع\nی  یا  \n ی جعل  )\n اد ی  م رد یگی .\nبنابرا\nی،ن  \n  همانطور که\nمولد  در تول\nدی  داده\nی ها  واقع\nی  بهتر م\nی  ،شود\nتمایزگر  در تشخ\nصی  داده\nی ها \nی جعل  از واقع\nی  بهتر  م ی\nشود و هر دو شبکه به طور هم\nزمان به پ\nی\nشرفت  خود ادامه م\nی .دهند \nدر شبکه\nی ها  متخاصم مولد، نو\nزی  به شبکه ِی  عصب ِی  مولد القا م\nی\nشود که نمونه\nی ها  \nجعل\nی  از طریق آن  یا\nجاد  یم\nشود\n. وظ فه ی  شبکه\nی  تمایزگر  شناسا\nیی  نمونه\nی ها  جعل\nی  \nتول\nید  \n  شده توسط شبکه\nمولد  است. ا\nنی  با بررس\nی  نمونه\nی ها  آموزش\nی  مشخص م\nی  شود\nتا بب ینی د  که نمونه تول\nی د  شده چقدر با نمونه\nی ها  \n واقع\nی  متفاوت است. ا\nنی  شبکه  ها\nمانند دو دشمن عمل م\nی\nکنند که سع\nی  \n  در رقابت با\nگر ی کد ی  \n دارند. در مراحل اول\nی ،ه  \n  شبکه\nتمایزگر  براحت ی  یم\nتواند نمونه\nی ها  جعل ی  \n تول\nید  \n  شده توسط\nمولد  را شناسا\nیی  \n  کند. سپس شبکهِمولد  ی رق ب،  سخت کار م\nی\nکند تا تفاوت نمونه\nی ها  یل جع  \n تول\nید  \n  شده\nاز داده\nها ی  \n واقع\nی  را کاهش دهد. آن\nها سع ی  یم\nکنند  نمونه\nیی ها  \n را نزد\nکی  به نمونه\nی ها  \nآموزش\nی  \n تول\nدی  کنند و ا\nنی  کار را برا\nی  شبکه ت\nمایزگر  ی کم  چالش برانگ\nزی  یم کند  .\n با این\n  ،حال  هنوز شبکه تمایزگر  تالش م\nی\nکند تا جعل ی  بودن داده ی ها  تول دی  شده را ب\nابد ی  . هر\nدو شبکه ب\nا  گر ی کد ی  رقابت م\nی\nکنند تا زمان\nی  \n  که شبکه\nتمایزگر  تشخ\nیص  ای\nنکه  \n  کدام\nکی  از نمونه\nی ها  \n تول\nی د  \n  شده توسط شبکه مولد  جعل ی  \n و کدام واقع\nی  \n  ،است\nبرایش  \n دشوار .شود \nآموز ش\nبه شیوه تخاص یم \n  مولد و\nتمایزگر  \n  کی در GAN به روش\nی  تخاصمی  آموزش م یبی،نند  ی ی عن  \n  کی در  \n چارچوب\nمجموع صفر  (\nzero-sum\n)  \n  گر ی کد ی با  به رقابت م\nی\nپردازند تا داده\nیی ها  \n هی شب  ی توز ع  داده\nی ها \n185 \n فصل\nششم: \n شبکه متخاصم مولد \n \nواقع\nی  دی تول  شود . هدف مولد در GAN دی تول  نمونه\nی ها  است که به\nنظر م ی\nرسد  از توز\nی ع  داده\nها ی  \nواقع\nی  م یآی،ند  ی حت  اگر جعل\nی  هستند  \n  و هدف،تمایزگر  تشخ\nیِص  ی جعل  ای  واقع\nی  بودن نمونه\nی ها  \nتولیدی  \n  .است \nِاز منظر  نه ی به\nی ساز،  \nِهدف  \n آموزشِی  مولد،  افزا\nشی  خطاها\nی  \n تمایزگر  است،. به عبارت دیگر \nهر چه تعداد اشتباهات ب\nی\nی شتر  \n  توسط\nتمایزگر  انجام شود، مولد عملکرد بهتر\nی  \n  دارد. هدف\nزگر ی تما  کاهش خطا\nی  \n  خود است. در هر تکرار، هر دو شبکه با استفاده از\nگردایان کاهشی  \n به  \n  سمت اهداف خود\nمی  .روند\nجالب ا\nی\nنجاست  که هر شبکه در تالش است تا شبکه د\nی گر ی  \n را\nشکست دهد.  مولد تالش م\nکند ی  تمایزگر  را فر\nبی  دهد، در حال\nی  \n  که\nتمایزگر  تالش م\nکند ی  ی فر ب  \nنخورد. در نها\nی،ت  داده\nی ها  تولیدی  (مانند تصاو\nی،ر  صدا، و\nی،دئو  ی ها ی سر  زمان ی  ) از مولد  \nم ی\nتواند پ\nنی تر ده یچی  تمایزگر  \n را فر\nبی  دهد. \nدر  عمل، مولد نمونه\nی ها  تصادف\nی  \n  را از\nکی  ی توز ع  از پ شی  \n ی تعر ف شده  با توز\nی ع   به\nعنوان ورود ی \nم رد یگی  و داده\nیی ها  را تول\nدی  م کند ی  که به نظر م\nی\nرسد  از توز\nی ع  هدف م ند یآی .\n \n  به\nعنوان مثال\nی از تولید یک تصویر  ،کی  \n  مدلGAN\n را م\nی  توان در\nشکل  ریز  \n:نشان داد \n \n شکل6\n-\n1\n. \n.ساختار کلی یک شبکه متخاصم مولد \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 186 \n \n \nمراحل ز\nیر  \n  توسطGAN\n  \n  انجام\nمی:شود \n1\n.\n \n  شبکه\nمولد نمونه\nی ها  تصادف\nی  را از توز\nی ع  گاوس\nی  م رد یگی  و تصاو\nیر  \n  را\nایجاد  م ی.کند \n2\n.\n نیا  تصاو\nری  دی تول  \n  شده سپس به شبکه\nتمایزگر  داده م\nی.شوند \n3\n.\n \n  شبکه\nتمایزگر  هم تصاو\nری  دی تول  شده و هم تصاو\nیری  را که از مجموعه داده واقع\nی  \n  گرفته\n شده\nاند را م\nرد یگی. \n4\n.\n تمایزگر  \n  احتماالت را\nدر  خروج\nی م ی .دهد \n5\n.\n \nِزیان  (\n  تابع\nنه ی هز  )\n،مولد  \nِبر اساس  آنتروپِی  \nِمتقاطع  تصاو یِر  \n ی جعل  \n  که توسط\nتمایزگر  \nمعتبر تلق\nی  م ی\nشود،  محاسبه م\nی.شود \n6\n.\n \nِزیان  (تابع هز\nنه ی\n) تما\nزگر ی  \nِبر اساس  آنتروپِی  \nِمتقاطع  تصاو\nیِر  ی جعل  که جعل\nی  تلق ی  \nم ی\nشوند، به اضافه آنتروپ\nی  متقاطع تصاو\nری  واقع\nی  \n که معتبر تلق ی  یم  شوند، محاسبه\nم ی.شود \n7\n.\n در  هر دوره، هر دو شبکه به ترت بی  ی برا  \n  به\nکمینه  کردن  زیان  خود به\nنه ی  می.شوند \n8\n.\n در نها\nیت \nِمولد به خوب ی آموزش\nده ید، تصاو\nری را به عنوان خروج ی  نها\nیی دی تول م ی  کند\nکه تصاو\nیِرِ ورودی  واقع\nی  را تقل ی د  یم.کند \nآموزش \nGAN\n \nهدف اصل\nی  نی ما ا  است که مولد تصاو\nری  (داده)های  واقع\nی  تول دی  \n  کند و چارچوبGAN\n  \nیا له ی وس  ی برا  نیا  هدف است. قبل از پرداختن به جزئ\nات ی  یب ،شتر  اجازه ده\nید  \n  به معرفی چند\nنماد بپردازیم : \n▪ \n  مولد را با𝐺(𝑧, 𝜃𝑔)\n  نشان م ی ده ی،م  یی جا  \n  که𝜃𝑔\n  وزن\nی ها  \n شبکه هستند و𝑧  \n بردار  نهفته\n(\nlatent vector\n)  است که به عنوان ورود\nی  مولد عمل م\nکند ی  . آن را به عنوان\nیک  \n  مقدار\nبذر  تصادف\nی  (\nrandom seed\n)  \n براِی  \nِشروع ی فرآِند  ی تولِد  \n تصو\nری  در نظر بگ\nیرید .\n𝑧  ی دارا \nی توز ع  احتمال  \n𝑝𝑧(𝑧)\n  است ک\nه  \n  ًمعموال\nنرمال  \n( تصادفیrandom normal\n)  یا   ی\nکنواخت \nتصادفی  (\nrandom uniform\n)  \n  .است\nمولد  نمونه\nی ها  ی جعل  𝑥  را با توز\nی ع  \n  احتمال𝑝𝑔(𝑥)\n  \nخروج\nی  می\nدهد. شما م\nی\nتوان\nید  \n𝑝𝑔(𝑥)\n  را به عنوان توز\nی ع  احتمال داده\nی ها  واقع\nی  \n  با توجه\nبه مولد در نظر بگ\nیرید. \n▪ زی تما  گر را با𝐷(𝑥, 𝜃𝑑)\n  نشان م\nمی ده ی  \n که𝜃𝑑\n  وزن شبکه است. داده\nی ها واقع\nی  با توز\nی ع \n𝑥~𝑝𝑑𝑎𝑡𝑎(𝑥)\n  ای  نمونه\nی ها  دی تول  \n شده𝑥~𝑝𝑔(𝑥)\n  را به عنوان ورود\nی  رد یگیم  .تمایزگر  \nکی  طبقه  بند\nدودویی  \n  است که\nبراساس اینکه  ایآ  تصو\nری  ورود\nی  \n واقع\nی  (خروج\nی  \n  شبکه1\n  )\nای  دی تول  شده (خروج\nی  \n  شبکه0\n)  است  ، مقدار1  \n  یا0  \n  را\nخروجی می.دهد \n▪ \n  در طول آموزش، توابع\nزیان  ت\nمایزگر  و مولد را به ترت\nیب  \n  با𝐽(𝐷)\n  \n و𝐽(𝐺)\n  نشان م می ده ی . \n187 \n فصل\nششم: \n شبکه متخاصم مولد \n \n  آموزشGAN\n  در مقا\nسه ی  \n  با آموزش\nکی  شبکه ِی  \n ِعصبیِ عمیق  معمول\nی  \n  ،متفاوت است چراکه \nما دو شبکه دار\nی . م می\nتوان\nمی  آن را به  عنوان\nکی  بازِی  مجموع -\nِصفر  کمینِبیش  متوال\nی  دو باز\nی کن  \n(مولد  \n  و\nتمایزگر\n) در نظر بگ\nیریم: \n1\n.\n \n( متوالیSequential\n :)\n  نی به ا  \n ی معن  که باز\nی\nکنان  به نوبت پشت سر هم قرار م یگی،رند  \n هی شب  به شطرنج (برخالف هم  ،زمان). ابتدا\nتمایزگر  ی سع  یم  کند𝐽(𝐷)\n  \n  را\nکمینه کند ، اما\nتنها با تنظ\nمی وزن\nهای  \n𝜃𝑑\n  می\nتواند ا\nین  \n  .کار را انجام دهد\nسپس  ،مولد ی سع  م ی  کند𝐽(𝐺)\n  \n  را به\nکمینه کند  ، اما\nفقط  یم تواند وزن\nی ها  ،\n𝜃𝑔\n  را تنظ\nی م  کند. ا\nنی  ند ی فرآ  نی چند  \n بار تکرار\nم ی.شود \n2\n.\n مجموع-\n( صفرZero-sum\n:)\n  نی به ا  \n ی معن  \n  که سود\nای  زیان  کی  باز کن ی  قا ی دق  \n  با سود\nای  زیان  کن ی باز  مقابل متعادل م\nی  .شود\nی عن ی  \n  مجموع ضرر مولد و\nتمایزگر  \n شه ی هم  0  \n :است \n𝐽(𝐺) = −𝐽(𝐷) \n3\n.\n \n کمین( بیشminimax\n:)\n  به ا\nین  \n ی معن  \n که استراتژ\nی  \n کن ی باز  \n  )اول (مولد  کمینه کردن  \n بیشینه ی  از ی امت  فی حر  (تمایزگر\n) است. وقت\nی  زگر ی تما  را آموزش م ی ده ی،م  در تشخ\nیص \nنمونه\nی ها  واقع\nی  و جعل\nی  بهتر م\nی\nشود  (کمینه کردن  \n𝐽(𝐷)). در مرحله بعد، زمان\nی  \n  که مولد  \nرا آموزش م ی ده ی،م  ی سع  م کند ی  \nِتا سطح  تمایزگر  \n که به تازگ\nی  \n  بهبود\nی\nافته  است ، باال برود  \n (ما𝐽(𝐺)\n  \n  را\nکمینه می\nکنیم،  \n  که معادل به\nبیشینه  کردن \n𝐽(𝐷)\n  است). ا\nین  \nِدو شبکه در حال  \nِرقابت  \n دائم\nی  هستند. ما باز\nی  \nminimax\n  را با موارد ز\nری  نشان م می ده ی  \n  که𝑉\n  تابع هز\nنه ی  \n:است \n𝒎𝒊𝒏𝑮𝒎𝒂𝒙𝑫𝑽(𝑮, 𝑫) \nد یی ایب  \n فرض کن\nمی  که پس از چند مرحله آموزش\nی،  \n  هر دو𝐽(𝐷)\n  \n  و𝐽(𝐺)\n  \n  در کمینه  محل\nی  \nخواهند بود. سپس، راهِحل  بازِی  کمین\nبیش،  تعادل نش  (\nNash equilibrium\n)  ده ی نام  \nم ی\nشود\n. تعادل نش زمان\nی  اتفاق م ی  افتد که\nیکی  از باز\nی\nگران  کنش خود را تغ\nر یی  \n ،ندهد\nصرف نظر از ا\nنکه ی  گر ی باز  گر ید  چه کار\nی  \n  انجام دهد. تعادل نش در\nیک  \n  چارچوبGAN\n  \nزمان\nی  اتفاق  م ی\nافتد  \n  که  مولد  آنقدر  خوب  شود که\nتمایزگر  گر ید  قادر  به  تشخ\nی ص  \nنمونه\nی ها  دی تول  شده و واقع\nی  \n.نباشد \nآموزش تمایزگر \nزگر ی تما  کی  طبقه\nبند  \n شبکه عصبی  است و م\nی\nتوان\nمی  آن را به روش معمول، با استفاده از گراد\nان ی  \nکاهشی  \n  و پس\nانتشار  آموزش ده\nیم\n. با ا\nنی  حال، مجموعه آموزش\nی  \n از بخش\nی ها  مساو\nی  نمونه\nی ها  \nواقع\nی  و تول\nدی  شده تشک\nلی  شده است. ب\nد یی ای   ی بب ین م  که چگونه م\nی\nتوان آن را در فرآ\nند ی  آ\nموزش  \n :گنجاند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 188 \n \n \n1\n.\n بسته به نمونه ورود\nی  (واقع\nی  ای  ی جعل\n)، دو مس\nری  می دار : \n▪ نمونه را از داد\nی ها ه  واقع\nی  \n𝑥~𝑝𝑑𝑎𝑡𝑎\n  انتخاب کرده و از آن برا\nی  دی تول \n𝐷𝑥\n  \n استفاده\n دی کن. \n▪ دی تول  نمونه جعل\nی  \n𝑥~𝑝𝑔. در ا\nی،نجا  \n  مولد و\nتمایزگر  \n  به عنوان\nیک  \n  شبکه واحد کار\nم ی  کنند. با\nی ک  بردار تصادف\nی 𝑧  شروع م\nی می کن  \n  که از آن\nی برا  دی تول  نمونه تول\nید  \n شده\n𝐺𝑧\n  استفاده م ی می کن\n. سپس، از آن به عنوان ورود\nی  تمایزگر  ی برا  تول دی  خروج\nی  نها یی  \n𝐷(𝐺(𝑧))\n  استفاده م ی می کن . \n2\n.\n \n  محاسبه تابع\nزیان  ، که\nمنعکس\nکننده\nی  دوگانگ\nی  داده\nی ها  آموزش\nی  است. \n3\n.\n گراد\nان ی  \n  خطا را پس\nانتشار داده شده  \n و وزن  ها بروز می\nشوند\n. اگرچه ا\nنی  دو شبکه با هم\nکار م ی کنند، وزن\nی ها  \n  مولد𝜃𝑔\n ، قفل خواهند شد و ما فقط وزن\nی ها  تمایزگر  \n𝜃𝑑\n  \n  را\nبروز م\nی نی . ا می کن  \n تضم\nنی  کند یم  \n  که ما عملکرد\nتمایزگر  را بهبود  یم\nبخش\nیم . \nی برا  \n  درک از\nزیان  تمایزگر،  د یی ایب  \n  فرمول\nزیان  آنتروپ\nی  \n  متقاطع را\nیادآوری کنیم : \n𝐶𝐸(𝑝, 𝑞) = −∑𝑝𝑖(𝑥)\n𝑛\n𝑖=1\nlog(𝑞𝑖(𝑥)) \nیی جا  \n  که𝑞𝑖(𝑥)\n  احتماِل  \n تخم\nیِن  خروجِی  \n  متعلق به کالس𝑖  \n  (از𝑛  \n  کالس) و𝑝𝑖(𝑥)\n  احتمال واقع\nی  \nاست. برا\nی  سادگ\nی،  فرض م ی می کن  که فرمول را رو\nی  کی  نمونه آموزش\nی  اعمال م ی می کن  . در مورد\nطبقه\nی بند  دودویی،  نیا  فرمول را م ی\nتوان به صورت ز\nیر  \n:ساده کرد \n𝐶𝐸(𝑝, 𝑞) = −(𝑝(𝑥) log 𝑞(𝑥) + (1 −𝑝(𝑥)) log(1 −𝑞(𝑥)) \nم ی\nتوان\nمی  فرمول  را برای  کی  ریزدسته  \n  از𝑚\n  نمونه گسترش ده\nیم: \n𝐶𝐸(𝑝, 𝑞) = −1\n𝑚∑(𝑝(𝑥𝑗) log 𝑞(𝑥𝑗) + (1 −𝑝(𝑥𝑗)) log(1 −𝑞(𝑥𝑗))\n𝑚\n𝑗=𝑖\n \nبا دانستن همهِی  نیا،ها  \n  حال\nد یی ایب  زیان  تمایزگر  را تعر فی  \n می کن: \n𝐽(𝐷) = −1\n2 𝔼𝑥~𝑝𝑑𝑎𝑡𝑎log(𝐷(𝑥)) −1\n2 𝔼𝑧log (1 −𝐷(𝐺(𝑧))) \nاگرچه پ\nده یچی  به نظر م\nی  ،رسد\nبا این حال  \n  فقط\nکی  زیان  آنتروپ ی  متقاطع برا\nی  کی  طبقه  بند\nدودویی  با برخ\nی  موارد  \n  خاصGAN\n  \n  .است \n189 \n فصل\nششم: \n شبکه متخاصم مولد \n \n آموزش مولد \n  ما\nمولد  \nِرا با بهترکردن  آن در فر\nبی  دادن متما\nزگر ی  آموزش خواه\nی م  داد. برا ی  انجام ا\nین  \n کار، به\nهر دو شبکه ن\nاز ی  ی دار،م  مشابه روش\nی  \n  که ما\nتمایزگر  را با نمونه\nی ها  ی جعل  \n آموزش م می ده ی : \n1\n.\n \n ما با\nکی بردار نهفته تصادف\nی 𝑧 شروع م\nی می کن و آن را از طر\nیق \n مولد و\nتمایزگر تغذ\nیه  \nم ی می کن  تا خروج\nی \n𝐷(𝐺(𝑧))\n  را تول\nید  \n می کن . \n2\n.\n \n  تابع،زیان  \n  همانِزیان  تمایزگر  است. با ا\nنی  حال، هدف ما در ا\nی\nنجا  بیشینه کردن  \n  آن\n  است، نه.کمینه کردن  چرا که  یم\nخواه\nیم  ت\nمایزگر  را فر\nبی  می ده. \n3\n.\n \n  در\nفاز  \n عقب\nگرد\n، وزن\nی ها  \n  تمایزگر𝜃𝑑\n  قفل هستند و فقط م\nی\nتوان\nیم  \n𝜃𝑔\n  را تنظ\nیم  \n ی کن م .\nنیا  به ما ا\nین  \n امکان را م ی\nدهد  به جا\nی  \n  بدتر کردن\nتمایزگر،  \n  با بهتر کردن مولد\nزیان  \nزی تما\nگر را بیشینه کنیم. \nدر ا\nنی مرحله ما فقط از داده\nی ها  دی تول \n شده استفاده م ی می کن\n. بخش\nی \n از تابع\nزیان که با داده\nی ها  \nواقع\nی  \n سروکار دارد هم\nشه ی  0  خواهد بود. بنابرا\nی،ن  می\nتوان\nمی  آن را به صورت ز\nیر  \n ساده کن\nیم: \n𝐽(𝐺) = 𝔼𝑧log (1 −𝐷(𝐺(𝑧))) \nدر  اوا\nی،ل  زمان\nی  \n  که\nمتمایزگر  براحت\nی  می\nتواند  نمونه\nی ها  واقع\nی  و جعل\nی  را  تشخ\nیص  \n  ،دهد\n(\n𝐷(𝐺(𝑧)) ≈0)، گراد\nان ی کی نزد به صفر خواهد بود. ا\nین \n امر منجر به\nیری ادگ ی \n ی کم از وزن  ها\nمی \n شود نیا که \n مشکل به عنوان\nگراد ان ی  کاهیده (\ndiminished gradient\n) شناخته م\nی\nشود .\n ما\nم ی\nتوان\nیم  این  \n  مشکل را با استفاده از\nیک  \n  تابع\nزیان  \n متفاوت حل کن\nی م: \n𝐽(𝐺) = −𝔼𝑧log (𝐷(𝐺(𝑧))) \nنیا  زیان  \n  هنوز\nکمینه می\nشود\n، زمان\nی  \n  که𝐷(𝐺(𝑧)) ≈1\n  و در ع\nنی  حال گراد\nان ی  \n  بزرگ است\n(زمان\nی  \n  که\nمولد  عملکرد ضع\nیفی  دارد). با ا\nنی  زیان\n، باز\nی  گر ید  \n مجموع\nصفر ن\nی،ست  اما ت\nاثی ر  \nی عمل  \n  بر چارچوبGAN\n \n.نخواهد داشت \nهر دو در کنار هم \nبا دانش جد\nی،دمان  م ی\nتوان\nیم  \n  هدف\nکمین\nبیشین  را به طور کامل تعر\nیف  \n می کن: \n𝑚𝑖𝑛𝐺𝑚𝑎𝑥𝐷𝑉(𝐺, 𝐷) = 1\n2 𝔼𝑥~𝑝𝑑𝑎𝑡𝑎log(𝐷(𝑥)) + 1\n2 𝔼𝑧log (1 −𝐷(𝐺(𝑧))) \n به طور خالصه، مولد سع\nی  م ی \n  کند هدف را\nکمینه کند\n، در حال\nی  \n  که\nتمایزگر  ی سع   م ی  کند آن را\nبیشینه کند\n. توجه داشته باش\nدی  ،در حال\nی  که\nتمایزگر  دی با  زیان  \n  خود را  کمینه\nکند  ، هدف\nکمین بیش \nی منف  زیان تمایزگر  است.  بنابرا\nنی  تمایزگر  با ی  د آن را.بیشینه کند \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 190 \n \n \nدی تول تصاو\nری دی جد \nMNIST\n \n باGAN\n   \nدر  ا\nنی  بخش  م ی\nخواه\nیم  \n به  اده یپ\nی ساز  کی  \n  شبکه  متخاصم  مولد  با  استفاده  ازKeras\n  و \ntensorflow\n بپردازیم.  ابتدا کدهای مورد نیاز را وارد می :کنیم \nfrom tensorflow.keras.datasets import mnist \nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout \nfrom tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D \nfrom tensorflow.keras.layers import LeakyReLU \nfrom tensorflow.keras.layers import UpSampling2D, Conv2D \nfrom tensorflow.keras.models import Sequential, Model \nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras import initializers \nimport matplotlib.pyplot as plt \nimport sys \nimport numpy as np \nimport tqdm \n  سپس، مجموعه دادهMNIST\n \n را بارگذاری و نرمال می :کنیم \n(X_train, _), (_, _) = mnist.load_data() \nX_train = (X_train.astype(np.float32) - 127.5)/127.5 \nهمانطور که احتماال متوجه شد\nی،د  ما ه\nچی  کی  از برچسب  ای ها  مجموعه داده آزما\nیشی  \n  را بر\n ی نم\nگردان\nیم\n. ما فقط از مجموعه داده آموزش\nی  استفاده م\nی می کن\n. برچسب\nها مورد ن\nاز ی  ین\nستند،  یز را \n تنها برچسب\nیی ها  که استفاده خواه\nیم  \n  کرد0\n  ی برا  ی جعل  \n  و1\n  ی برا  واقع\nی  است. ا\nنها ی  تصاو\nیر  \nی اقع و  هستند، بنابرا\nنی  به همه آن  کی ها  \n  برچسب1  \n  در\nتمایزگر  اختصاص داده م\nی.شود \n  ما از\nکی  پرسپترون چند ال\nی ه  استفاده خواه می  کرد و به آن تصو\nیری  \n  به عنوان\nیک  \n ِبردار  \n  مسطح\n  با اندازه784\n  ی ده یم ،م  بنابرا\nنی  داده\nی ها  آموزش\nی  را تغ\nر یی  شکل م می ده ی : \nX_train = X_train.reshape(60000, 784) \nاکنون با\nید  یک  \n  مولد و\nتمایزگر  بساز\nمی  . هدف\nمولد  افت ی در  کی  ورود\nی  ی نو\nزدار  و تول\nدی  تصو\nیر ی  \nمشابه مجموعه داده آموزش\nی  است. اندازه ورود\nی  \n نویز  توسط متغ\nیر  \nrandomDim\n  ن یی تع  م ی  .شود\nیم  توان\nدی  آن را به هر مقدار  ی\nمقدارده\nی  هی اول  \n دی کن  . معموال آن\nرا  \n ی رو  \n100\n  تنظ می  یم\nکنند. برا\nی \nاده یپ ی ساز،  \n  ما مقدار10\n  را امتحان کرد\nنی . ا می  ورود ی  \n  کی به  ال هی  \n  متراکم با256\n  \n نورون با\n فعال\nی ساز  \nLeakyReLU\n  وارد م\nی  شود. در مرحله بعد\nکی  یال ه  متصل کامل  گر ید  \n  با512\n  \n نورون\nپنهان اضافه م\nی ی کن،م  به دنبال آن ال\nیه  \n  سوم پنهان با1024\n  \n  نورون\nو  در نها\nتی  یال ه  خروج\nی  \n با\n784\n \n نورون را اضافه م ی ی . م می کن\nتوان\nید \n تعداد نورون\nها را در ال\nی ی ها ه پنهان تغ\nر یی دی ده \n ی و بب دین  \nعملکرد چگونه  تغ\nر یی  یم  .کند\nبا ا نی  حال،  تعداد  نورون\nها در  واحد  خروج\nی  با دی  \n با  تعداد\n پی\nکسل\nی ها  موجود در تصاو ری  آموزش\nی  \n.مطابقت داشته باشد  مولد مربوط به صورت ز\nیر  \n:است \n191 \n فصل\nششم: \n شبکه متخاصم مولد \n \nrandomDim = 10 \ngenerator = Sequential() \ngenerator.add(Dense(256, input_dim=randomDim))  \ngenerator.add(LeakyReLU(0.2)) \ngenerator.add(Dense(512)) \ngenerator.add(LeakyReLU(0.2)) \ngenerator.add(Dense(1024)) \ngenerator.add(LeakyReLU(0.2)) \ngenerator.add(Dense(784, activation='tanh')) \n  به طور مشابه، ما\nکی  گر زی تما  یا\nجاد  یم می کن\n. توجه داشته باش\nدی  که تما\nزگر ی  تصاو\nیر  \n  را از مجموعه\nآموزش\nی  ای تصاو ری دی تول \n شده توسط\nمولد م یگی،رد بنابرا\nنی اندازه ورود\nی \n آن784\n است. با ا\nی ن \nحال، خروج\nی  تشخ\nیص  \n  دهنده\nیک  بیت  \n  است و0\n  نشان  دهنده کی  تصو\nری  ی جعل  است (تول\nید  \n  شده توسط مولد  ) و1  نشان م ی\nدهد که تصو\nری  از مجموعه داده آموزش\nی  \n :است \ndiscriminator = Sequential() \ndiscriminator.add(Dense(1024, input_dim=784, \nkernel_initializer=initializers.RandomNormal(stddev=0.02))) \ndiscriminator.add(LeakyReLU(0.2)) \ndiscriminator.add(Dropout(0.3)) \ndiscriminator.add(Dense(512)) \ndiscriminator.add(LeakyReLU(0.2)) \ndiscriminator.add(Dropout(0.3)) \ndiscriminator.add(Dense(256)) \ndiscriminator.add(LeakyReLU(0.2)) \ndiscriminator.add(Dropout(0.3)) \ndiscriminator.add(Dense(1, activation='sigmoid')) \nسپس  ، مولد و\nتمایزگر  را با هم ترک\nبی  م ی می کن  \n  کی تا  \nGAN\n  تشک\nلی  می ده  . درGAN\n  ، با\nتنظ\nی م \n  آرگومانtrainable\n ی رو  \nFalse، مطمئن م\nمی شو ی  \n که وزن\nی ها  تمایزگر  ثابت م ی\nشوند: \n# Combined network \ndiscriminator.trainable = False \nganInput = Input(shape=(randomDim,)) \nx = generator(ganInput) \nganOutput = discriminator(x) \ngan = Model(inputs=ganInput, outputs=ganOutput) \nتدبیر  ی برا  آموزش ا\nنی  دو ا\nین  \n  است که ابتدا\nتمایزگر  را جداگانه آموزش م می ده ی  . از\nزیان  آنتروپ ی \n  متقاطع\nدودویی  ی برا  تمایزگر  استفاده م ی می کن  .\n،سپس  وزن\nی ها  تمایزگر  \n  راfreeze\n  یم می کن  \n و\nGAN\n ی ترک یب  را آموزش م نی . ا می ده ی  \n  منجر به آموزش\nمولد  م ی\nشود: \ndiscriminator.compile(loss='binary_crossentropy', optimizer=adam) \ngan.compile(loss='binary_crossentropy', optimizer=adam) \nحاال ب\nد یی ای  \n  آموزش را اجرا\nشروع کنیم\n. برا\nی  هر دوره ابتدا نمونه\nیا  از نو\nیز  \n تصادف\nی  م یگیری،م  \n  آن\n  را به\nمولد  می ده یم  \n  و\nمولد  کی  تصو\nری  ی جعل  دی تول  م کند ی\n. ما تصاو\nی ر  ی جعل  دی تول  شده و تصاو\nیر  \nآموزش\nی  واقع\nی  \n  را در\nیک  \n دسته با برچسب\nی ها  خاص خود ترک\nبی   یم می کن  و از آن\nها بر\nای  \n  آموزش\nتمایزگر  در دسته داده شده استفاده م\nی می کن: \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 192 \n \n \ndLosses = [] \ngLosses = [] \ndef train(epochs=1, batchSize=128): \n    batchCount = int(X_train.shape[0] / batchSize) \n    print ('Epochs:', epochs) \n    print ('Batch size:', batchSize) \n    print ('Batches per epoch:', batchCount) \n \n    for e in range(1, epochs+1): \n        print ('-'*15, 'Epoch %d' % e, '-'*15) \n        for _ in range(batchCount): \n            # Get a random set of input noise and images \n            noise = np.random.normal(0, 1, size=[batchSize, randomDim]) \n            imageBatch = X_train[np.random.randint(0, X_train.shape[0], \nsize=batchSize)] \n \n            # Generate fake MNIST images \n            generatedImages = generator.predict(noise) \n            # print np.shape(imageBatch), np.shape(generatedImages) \n            X = np.concatenate([imageBatch, generatedImages]) \n \n            # Labels for generated and real data \n            yDis = np.zeros(2*batchSize) \n            # One-sided label smoothing \n            yDis[:batchSize] = 0.9 \n \n            # Train discriminator \n            discriminator.trainable = True \n            dloss = discriminator.train_on_batch(X, yDis) \n  حاال در همان حلقهfor، ژنراتور را آموزش م می ده ی\n. ما م\nی  خواه می  تصاو\nری  دی تول  \n  شده توسط\n،مولد  \n  توسط،تمایزگر  واقع\nی  \n تشخ\nصی  داده شوند، بنابرا\nین  \n  کی از  \n بردار تصادف\nی  زی (نو  ) به عنوان\nورود\nی  \n  به\nمولد  استفاده م\nی نی . ا می کن  کی  تصو\nری  ی جعل  دی تول  م ی  کند و سپسGAN\n  را طو\nری \nآموزش م ی\nدهد که متما\nزی  کننده تصو\nری  را واقع\nی  درک کند (خروج\nی  1\n:)\n \n            # Train generator \n            noise = np.random.normal(0, 1, size=[batchSize, randomDim]) \n            yGen = np.ones(batchSize) \n            discriminator.trainable = False \n            gloss = gan.train_on_batch(noise, yGen) \nدر صورت تما\nی،ل  می\nتوان\nدی  زیان  مولد  \n  و\nتمایزگر  \n و همچن\nی ن  تصاو\nری  دی تول  \n شده را ذخ\nره ی  \n دی کن .\n  در مرحله بعد، ما\nزیان  را برا\nی  هر دوره ذخ\nره ی  یم می کن  \n  و پس از هر20\n  دوره تصاو\nری  ی تول د  \nم ی می کن : \n        # Store loss of most recent batch from this epoch \n        dLosses.append(dloss) \n        gLosses.append(gloss) \n \n        if e == 1 or e % 20 == 0: \n            saveGeneratedImages(e) \nی برا  ترسیم  زیان  و  تصاو\nری  دی تول  \n شده  ارقام  دست\nی نو،س  دو  تابع کمک\nی،\n  \nplotLoss\n  \n و\nsaveGeneratedImages\n تعر فی  م ی می کن\n. کد آن\nها به شرح ز\nیر  \n:است \n193 \n فصل\nششم: \n شبکه متخاصم مولد \n \n# Plot the loss from each batch \ndef plotLoss(epoch): \n    plt.figure(figsize=(10, 8)) \n    plt.plot(dLosses, label='Discriminitive loss') \n    plt.plot(gLosses, label='Generative loss') \n    plt.xlabel('Epoch') \n    plt.ylabel('Loss') \n    plt.legend() \n    plt.savefig('images/gan_loss_epoch_%d.png' % epoch) \n \n# Create a wall of generated MNIST images \ndef saveGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, \n10)): \n    noise = np.random.normal(0, 1, size=[examples, randomDim]) \n    generatedImages = generator.predict(noise) \n    generatedImages = generatedImages.reshape(examples, 28, 28) \n \n    plt.figure(figsize=figsize) \n    for i in range(generatedImages.shape[0]): \n        plt.subplot(dim[0], dim[1], i+1) \n        plt.imshow(generatedImages[i], interpolation='nearest', \ncmap='gray_r') \n        plt.axis('off') \n    plt.tight_layout() \n    plt.savefig('images/gan_generated_image_epoch_%d.png' % epoch) \n:حال بیاید تمام کدها را یکجا داشته باشیم \nfrom tensorflow.keras.datasets import mnist \nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, \nDropout \nfrom tensorflow.keras.layers import BatchNormalization, Activation, \nZeroPadding2D \nfrom tensorflow.keras.layers import LeakyReLU \nfrom tensorflow.keras.layers import UpSampling2D, Conv2D \nfrom tensorflow.keras.models import Sequential, Model \nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras import initializers \nimport matplotlib.pyplot as plt \nimport sys \nimport numpy as np \nimport tqdm \n \nrandomDim = 10  \n \n# Load MNIST data \n(X_train, _), (_, _) = mnist.load_data() \nX_train = (X_train.astype(np.float32) - 127.5)/127.5 \nX_train = X_train.reshape(60000, 784) \n \ngenerator = Sequential() \ngenerator.add(Dense(256, input_dim=randomDim)) #, \nkernel_initializer=initializers.RandomNormal(stddev=0.02))) \ngenerator.add(LeakyReLU(0.2)) \ngenerator.add(Dense(512)) \ngenerator.add(LeakyReLU(0.2)) \ngenerator.add(Dense(1024)) \ngenerator.add(LeakyReLU(0.2)) \ngenerator.add(Dense(784, activation='tanh')) \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 194 \n \n \nadam = Adam(learning_rate=0.0002, beta_1=0.5) \n \ndiscriminator = Sequential() \ndiscriminator.add(Dense(1024, input_dim=784, \nkernel_initializer=initializers.RandomNormal(stddev=0.02))) \ndiscriminator.add(LeakyReLU(0.2)) \ndiscriminator.add(Dropout(0.3)) \ndiscriminator.add(Dense(512)) \ndiscriminator.add(LeakyReLU(0.2)) \ndiscriminator.add(Dropout(0.3)) \ndiscriminator.add(Dense(256)) \ndiscriminator.add(LeakyReLU(0.2)) \ndiscriminator.add(Dropout(0.3)) \ndiscriminator.add(Dense(1, activation='sigmoid')) \ndiscriminator.compile(loss='binary_crossentropy', optimizer=adam) \n \n# Combined network \ndiscriminator.trainable = False \nganInput = Input(shape=(randomDim,)) \nx = generator(ganInput) \nganOutput = discriminator(x) \ngan = Model(inputs=ganInput, outputs=ganOutput) \ngan.compile(loss='binary_crossentropy', optimizer=adam) \n \ndLosses = [] \ngLosses = [] \n \n# Plot the loss from each batch \ndef plotLoss(epoch): \n    plt.figure(figsize=(10, 8)) \n    plt.plot(dLosses, label='Discriminitive loss') \n    plt.plot(gLosses, label='Generative loss') \n    plt.xlabel('Epoch') \n    plt.ylabel('Loss') \n    plt.legend() \n    plt.savefig('images/gan_loss_epoch_%d.png' % epoch) \n \n# Create a wall of generated MNIST images \ndef saveGeneratedImages(epoch, examples=100, dim=(10, 10), \nfigsize=(10, 10)): \n    noise = np.random.normal(0, 1, size=[examples, randomDim]) \n    generatedImages = generator.predict(noise) \n    generatedImages = generatedImages.reshape(examples, 28, 28) \n \n    plt.figure(figsize=figsize) \n    for i in range(generatedImages.shape[0]): \n        plt.subplot(dim[0], dim[1], i+1) \n        plt.imshow(generatedImages[i], interpolation='nearest', \ncmap='gray_r') \n        plt.axis('off') \n    plt.tight_layout() \n    plt.savefig('images/gan_generated_image_epoch_%d.png' % epoch) \n \ndef train(epochs=1, batchSize=128): \n    batchCount = int(X_train.shape[0] / batchSize) \n    print ('Epochs:', epochs) \n    print ('Batch size:', batchSize) \n195 \n فصل\nششم: \n شبکه متخاصم مولد \n \n    print ('Batches per epoch:', batchCount) \n \n    for e in range(1, epochs+1): \n        print ('-'*15, 'Epoch %d' % e, '-'*15) \n        for _ in range(batchCount): \n            # Get a random set of input noise and images \n            noise = np.random.normal(0, 1, size=[batchSize, \nrandomDim]) \n            imageBatch = X_train[np.random.randint(0, \nX_train.shape[0], size=batchSize)] \n \n            # Generate fake MNIST images \n            generatedImages = generator.predict(noise) \n            # print np.shape(imageBatch), np.shape(generatedImages) \n            X = np.concatenate([imageBatch, generatedImages]) \n \n            # Labels for generated and real data \n            yDis = np.zeros(2*batchSize) \n            # One-sided label smoothing \n            yDis[:batchSize] = 0.9 \n \n            # Train discriminator \n            discriminator.trainable = True \n            dloss = discriminator.train_on_batch(X, yDis) \n \n            # Train generator \n            noise = np.random.normal(0, 1, size=[batchSize, \nrandomDim]) \n            yGen = np.ones(batchSize) \n            discriminator.trainable = False \n            gloss = gan.train_on_batch(noise, yGen) \n \n        # Store loss of most recent batch from this epoch \n        dLosses.append(dloss) \n        gLosses.append(gloss) \n \n        if e == 1 or e % 20 == 0: \n            saveGeneratedImages(e) \n             \n \n    # Plot losses from every epoch \n    plotLoss(e) \n \n اکنون می  توانیمGAN\n \n :را آموزش دهیم \ntrain(200, 128) \nEpochs: 200 \nBatch size: 128 \nBatches per epoch: 468 \n--------------- Epoch 1 --------------- \n--------------- Epoch 2 --------------- \n--------------- Epoch 3 --------------- \n--------------- Epoch 4 --------------- \n--------------- Epoch 5 --------------- \n... \n--------------- Epoch 198 --------------- \n--------------- Epoch 199 --------------- \n--------------- Epoch 200 --------------- \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 196 \n \n \n  در\nشکل  ریز  م ی\nتوان\nدی  نمودار ز\nان ی  \n  مولد وِتمایزگر  \nGAN\n  \n  در حال\nیری ادگ ی  \n  را مشاهده کن\nید: \n \n ارقام دست\nسی نو  دی تول  \n  شده توسطGAN\n  ما  در دوره:های مختلف به صورت زیر هستند \nEpoch 20:\n \nEpoch 1:\n \nEpoch 200:\n \nEpoch 100:\n \n197 \n فصل\nششم: \n شبکه متخاصم مولد \n \nهمان  طور ک از شکل\nی ها ی قبل  یم\nتوان\nدی  ی بب دین، با افزا شی دوره ها، ارقام دست\nسی نو تول دی \n  شده\n  توسطGAN\n \n  بیشتر و بیشتر\nواقع\nی  می\nشوند . \n چالش\nهای مرتبط با آموز ش شبکه\nهای متخاصم مولد \n هنگام کار با GAN \n چالش\nی ها  ی اد یز  \n  وجود دارد. آموزش\nیک  \n شبکه عصب\nی  منفرد به دل\nیل  \n ِتعداد  \nِزیاد نه ی گز\nی ها ری درگ، م ی\nتواند \n :دشوار باشد\nمعمار\nی، \n توابع فعال\nی ساز، الگوریتم  نه ی به\nی ساز،  \n  نرخ ادگ ی\nیری  \n  و  نرخ\nحذف تصادفی. \n شبکه  ،های متخاصم مولد\nهمه ا\nنی  انتخاب  ها را دو برابر\nم ی\nکنند و پ\nی ها ی دگ یچی  یدی جد  \n  را  نیز\nاضافه م\nی  کنند. هم مولد و هم\nتمایزگر  \n ممکن است\n تدبیرهایی  را که قبال در آموزش خود استفاده کرده بودند،  فراموش کنند. ا\nنی  م ی  تواند منجر به\nگرفتار شدن دو شبکه در چرخهِی  ی پا دارِی  از راه\nحل ها شود که در طول زمان بهبود نم\nابد یی  .ی ک \nشبکه ممکن است بر شبکه د\nگر ی  \n ه غلب  کند، به\nیر طو  که ه چی  کی  گر ید  \n  نتوانند\nاد ی  رند ی بگ  .ای  \n  ممکن\nاست  مولد،  بس ی ار ی  از فضاِی  \n راهِحل  ممکن را کشف نکند  \n  و  فقط\nاز آن برا\nی  ی افتن  \n راه\nحل\nی ها  \n واقع\nنانه یب  استفاده م کند ی.  نیا  وضع\nیت  \n  به عنوان\nفروپاش\nی  حالت (\nmode collapse\n)  \n  شناخته\nم ی\nشود. \nفروپاش\nی  حالت زمان\nی  \n رخ می\nدهد  که مولد تنها ز\nی\nرمجموعه  کوچک\nی  \n از حالت\nهاِی  واقع\nی  \n  ممکن را\nاد ی  رد یگیم  . به عنوان مثال، اگر\nمسئله  ی تولِد  تصاو ری  گربه\nها  \n  ،باشد\nمولد  م ی  تواند\nاد ی  \nرد ی بگ  که فقط تصاو\nی ری  \n  از\nگربه\nهای مو کوتاه  و مشکی  را  تولید  \n  .کند\nمولد  \n تمام حالت\nی ها  گر ید  \n  که  شامل گربه\nهایی  \n با رنگ\nی ها  گر ید  است  را از دست م\nدی.هد \nراهبردها\nی  ی بس ی ار  ی برا  دگ ی رس ی  به ا\nنی  موضوع  \n،ارائه گردیده است  \n از جمله نرمال ساز ی  \nدسته\nای،  \n افزودن برچسب\nها به داده\nی ها  آموزش\nی  \n  .و غیره\nافزودن برچسب به داده\nها،  ی ی عن  تقس\nی م  \nآن ها به دسته\nها، تقر\nبا ی  \n هم شه ی  عملکردGAN \n  ها را\nبهبود م\nی\nبخشد. به جا\nی   ری ادگ ی ی  یا جاد  \nتصاو\nری از ح\nی\nوانات خانگ\nی به طور کلی، تول دی تصاو\nی ری \n  برای مثال\nاز گربه ها، سگ ،ها\nپرنده\nها  \nدی با  \n آسان\nتر با\nشد. \nخالصه فصل \n \n▪ به طور کل\nی دو نوع مدل اصل\nی \n در ادگ ی\nیری ماش\nنی وجود دارد: مدل مولد  و مدل تفک\nگر کی .\n \n▪ \n مدل\nی ها تفک\nی گر ک \n بر پ\nی شبینی \n کالس\nی ها داده با توجه به و ژگ ی ی ها ی آن\nها تمرکز م ی\nکنند.\n \n▪ مدل مولد سع\nی  \n نم کند ی  و ژگ ی ها ی  \n را به کالس\nها نگاشت کند، بلکه و ژگ ی یی ها ی  را تول\nی د  \nم کند ی  \n که در کی \n .کالس خاص وجود دارد \n▪ \n مدل\nی ها  \n  مولد  از ادگ ی\nیری  بدون نظارت  پ\nی رو ی  یم\nکنند  \n که  به  طور  خودکار  الگوها ی ا  \nبی\nنظم ی ها ی داده\nی ها مورد تجز\nهی و تحل\nلی را کشف م کند ی .\n \nیادگیری عمیق :از اصول اولیه \n تا ساخت شبکه های عصبی عمیق\nبا \n پایتون 198 \n \n \n▪ هدف اصل\nی \n انواع مدل\nی ها \n  مولد ادگ ی\nیری توز یِع واقعِی داده\nها ی مجموعه آموزش\nی است.\n \n آزمونک \n1\n.\n از منظر به\nی نه\nی ساز، هدف \n آموزش\nی مولد و تمایزگر چیست؟ \n2\n.\n \n تمایزگر با چه روشی آموزش می\nیابد؟ \n3\n.\n \n ورودی مولد چه چیزی است؟ \n4\n.\n \n فروپاشی حالت چیست؟ \n \n \nGoodfellow, I., Bengio, Y., and Courville, A. (2016). Deep Learning. MIT Press. \nGoodfellow, Ian J et al. (2013). “Challenges in representation learning: A report \non three machine learning contests”. In: International Conference on Neural \nInformation Processing. Springer \nSutskever, Ilya et al. (2013). On the importance of initialization and momentum \nin deep learning. In: ICML (3) 28.1139-1147, p. 5. \nSiegelmann, H.T. (1995). \"Computation Beyond the Turing Limit\". Science.  238 \n(28): 632–637.  \nAlex Graves and Greg Wayne and Ivo Danihelka (2014). \"Neural Turing  \nMachines\". \nValentino, Z., Gianmario, S., Daniel, S., & Peter, R. (2017). Python Deep \nLearning: Next Generation Techniques to Revolutionize Computer Vision, \nAI, Speech and Data Analysis. Birmingham, UK: Packt Publishing Ltd. \nAljundi, R. (2019). Continual learning in neural networks. arXiv preprint \narXiv:1910.02718. \nGupta, P., & Sehgal, N. K. (2021). Introduction to Machine Learning in the Cloud \nwith Python: Concepts and Practices. Springer Nature. \nAlpaydin, E. (2004). Introduction To Machine Learning. S.L.: Mit Press. \nBishop, Christopher M (2006). Pattern recognition and machine learning. \nspringer. \nReferences\nVazan, Milad, and Jafar Razmara. \"Jointly Modeling Aspect and Polarity for Aspect-based \nSentiment Analysis in Persian Reviews.\" arXiv preprint arXiv:2109.07680 (2021). \nhttps://doi.org/10.48550/arXiv.2109.07680\nVazan, Milad. \"Machine Learning and Data Science: Foundations, Concepts, Algorithms, and Tools.\"\narXiv preprint arXiv:2202.05163 (2022). https://doi.org/10.48550/arXiv.2202.05163\nVazan, Milad. \"Joint Learning for Aspect and Polarity Classification in Persian Reviews Using \nMulti-Task Deep Learning.\" arXiv preprint arXiv:2201.06313 (2022). \nhttps://doi.org/10.48550/arXiv.2201.06313\nVazan, Milad. \"A Novel Approach for Enhancing Sentiment Classification of Persian Reviews Using \nConvolutional Neural Network and Majority Voting Classifier.\"\n 200 \n \n \nBrudfors, M. (2020). Generative Models for Preprocessing of Hospital Brain \nScans (Doctoral dissertation, UCL (University College London)). \nCharte, F., Rivera, A. J., & Del Jesus, M. J. (2016). Multilabel classification: \nproblem analysis, metrics and techniques. Springer International Publishing. \nChen, Z., & Liu, B. (2018). Lifelong machine learning. Synthesis Lectures on \nArtificial Intelligence and Machine Learning, 12(3), 1-207. \nDulhare, U. N., Ahmad, K., & Ahmad, K. A. B. (Eds.). (2020). Machine Learning \nand Big Data: Concepts, Algorithms, Tools and Applications. John Wiley & \nSons. \nFriedemann Zenke, Ben Poole, and Surya Ganguli. (2017). Continual learning \nthrough synaptic intelligence. In International Conference on Machine \nLearning (ICML). \nGan, Z. (2018). Deep Generative Models for Vision and Language Intelligence \n(Doctoral dissertation, Duke University). \nJebara, T. (2012). Machine learning: discriminative and generative (Vol. 755). \nSpringer Science & Business Media. \nLesort, T. (2020). Continual Learning: Tackling Catastrophic Forgetting in Deep \nNeural Networks with Replay Processes. arXiv preprint arXiv:2007.00487 \nMarsland, S. (2015). Machine Learning : an algorithmic perspective. Boca Raton, \nFl: Crc Press. \nMitchell, T.M. (1997). Machine learning. New York: Mcgraw Hill. \nRhys, H. (2020). Machine Learning with R, the tidyverse, and mlr. Simon and \nSchuster. \nZhou Z. (2021). Machine Learning. Springer Nature Singapore Pte Ltd. \nWeidman, S. (2019). Deep Learning from Scratch: Building with Python from \nFirst Principles. O'Reilly Media. \nGulli, A., Kapoor, A., & Pal, S. (2019). Deep learning with TensorFlow 2 and \nKeras: regression, ConvNets, GANs, RNNs, NLP, and more with \nTensorFlow 2 and the Keras API. Packt Publishing Ltd. \nVasudevan, S. K., Pulari, S. R., & Vasudevan, S. (2022). Deep Learning: A \nComprehensive Guide. Chapman and Hall/CRC. \nZhang, A., Lipton, Z. C., Li, M., & Smola, A. J. (2021). Dive into deep learning. \narXiv preprint arXiv:2106.11342. \nEkman, M. (2021). Learning Deep Learning: Theory and Practice of Neural \nNetworks, Computer Vision, NLP, and Transformers Using TensorFlow. \nAddison-Wesley Professional. \nHuang, S. C., & Le, T. H. (2021). Principles and labs for deep learning. Elsevier. \nWilmott, P. (2019). Machine learning: an applied mathematics introduction. \nPanda Ohana Publishing. \n201 \n \n \nKelleher, J. D., Mac Namee, B., & D'arcy, A. (2020). Fundamentals of machine \nlearning for predictive data analytics: algorithms, worked examples, and case \nstudies. MIT press. \nDu, K. L., & Swamy, M. N. (2013). Neural networks and statistical learning. \nSpringer Science & Business Media. \nYe, J. C. (2022). Geometry of Deep Learning: A Signal Processing Perspective \n(Vol. 37). Springer Nature. \nHoward, J., & Gugger, S. (2020). Deep Learning for Coders with fastai and \nPyTorch. O'Reilly Media. \nStevens, E., Antiga, L., & Viehmann, T. (2020). Deep learning with PyTorch. \nManning Publications. \nSaitoh, K. (2021). Deep Learning from the Basics: Python and Deep Learning: \nTheory and Implementation. Packt Publishing Ltd. \nGhatak, A. (2019). Deep learning with R (Vol. 245). Singapore: Springer. \nCalin, O. (2020). Deep learning architectures. Springer International Publishing. \nSewak, M., Karim, M. R., & Pujari, P. (2018). Practical convolutional neural \nnetworks: implement advanced deep learning models using Python. Packt \nPublishing Ltd. \nLiu, Y. H., & Mehta, S. (2019). Hands-On Deep Learning Architectures with \nPython: Create deep neural networks to solve computational problems using \nTensorFlow and Keras. Packt Publishing Ltd. \nMa, Y., & Tang, J. (2021). Deep learning on graphs. Cambridge University Press. \nBuduma, N., & Locascio, N. (2017). Fundamentals of deep learning: Designing \nnext-generation machine intelligence algorithms. \" O'Reilly Media, Inc.\". \nRamsundar, B., & Zadeh, R. B. (2018). TensorFlow for deep learning: from linear \nregression to reinforcement learning. \" O'Reilly Media, Inc.\". \nHope, T., Resheff, Y. S., & Lieder, I. (2017). Learning tensorflow: A guide to \nbuilding deep learning systems. \" O'Reilly Media, Inc.\". \nOsinga, D. (2018). Deep learning cookbook: practical recipes to get started \nquickly. \" O'Reilly Media, Inc.\". \nTrask, A. W. (2019). Grokking deep learning. Simon and Schuster. \nWani, M. A., Bhat, F. A., Afzal, S., & Khan, A. I. (2020). Advances in deep \nlearning. Springer. \nBhardwaj, A., Di, W., & Wei, J. (2018). Deep Learning Essentials: Your hands-\non guide to the fundamentals of deep learning and neural network modeling. \nPackt Publishing Ltd. \nGulli, A., & Pal, S. (2017). Deep learning with Keras. Packt Publishing Ltd. \nAggarwal, C. C. (2018). Neural networks and deep learning. Springer, 10, 978-3. \nChollet, F. (2021). Deep learning with Python. Simon and Schuster. \n 202 \n \n \nFoster, D. (2019). Generative deep learning: teaching machines to paint, write, \ncompose, and play. O'Reilly Media. \nPatterson, J., & Gibson, A. (2017). Deep learning: A practitioner's approach. \" \nO'Reilly Media, Inc.\". \nGlassner, A. (2018). Deep learning: From basics to practice. Seattle, WA: The \nImaginary Institute. \nPointer, I. (2019). Programming PyTorch for Deep Learning: Creating and \nDeploying Deep Learning Applications. O'Reilly Media. \n \n \n \n",
  "categories": [
    "cs.LG"
  ],
  "published": "2022-04-22",
  "updated": "2022-04-22"
}