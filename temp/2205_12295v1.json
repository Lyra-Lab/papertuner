{
  "id": "http://arxiv.org/abs/2205.12295v1",
  "title": "lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for Efficient Unsupervised Continual Learning on Autonomous Agents",
  "authors": [
    "Rachmad Vidya Wicaksana Putra",
    "Muhammad Shafique"
  ],
  "abstract": "Recent advances have shown that SNN-based systems can efficiently perform\nunsupervised continual learning due to their bio-plausible learning rule, e.g.,\nSpike-Timing-Dependent Plasticity (STDP). Such learning capabilities are\nespecially beneficial for use cases like autonomous agents (e.g., robots and\nUAVs) that need to continuously adapt to dynamically changing\nscenarios/environments, where new data gathered directly from the environment\nmay have novel features that should be learned online. Current state-of-the-art\nworks employ high-precision weights (i.e., 32 bit) for both training and\ninference phases, which pose high memory and energy costs thereby hindering\nefficient embedded implementations of such systems for battery-driven mobile\nautonomous systems. On the other hand, precision reduction may jeopardize the\nquality of unsupervised continual learning due to information loss. Towards\nthis, we propose lpSpikeCon, a novel methodology to enable low-precision SNN\nprocessing for efficient unsupervised continual learning on\nresource-constrained autonomous agents/systems. Our lpSpikeCon methodology\nemploys the following key steps: (1) analyzing the impacts of training the SNN\nmodel under unsupervised continual learning settings with reduced weight\nprecision on the inference accuracy; (2) leveraging this study to identify SNN\nparameters that have a significant impact on the inference accuracy; and (3)\ndeveloping an algorithm for searching the respective SNN parameter values that\nimprove the quality of unsupervised continual learning. The experimental\nresults show that our lpSpikeCon can reduce weight memory of the SNN model by\n8x (i.e., by judiciously employing 4-bit weights) for performing online\ntraining with unsupervised continual learning and achieve no accuracy loss in\nthe inference phase, as compared to the baseline model with 32-bit weights\nacross different network sizes.",
  "text": "To appear at the 2022 International Joint Conference on Neural Networks (IJCNN),\nthe 2022 IEEE World Congress on Computational Intelligence (WCCI), July 2022, Padova, Italy.\nlpSpikeCon: Enabling Low-Precision Spiking Neural Network\nProcessing for Efﬁcient Unsupervised Continual Learning on\nAutonomous Agents\nRachmad Vidya Wicaksana Putra∗, Muhammad Shaﬁque†\n∗Institute of Computer Engineering, Technische Universit¨at Wien (TU Wien), Vienna, Austria\n†Division of Engineering, New York University Abu Dhabi (NYUAD), Abu Dhabi, United Arab Emirates\nEmail: rachmad.putra@tuwien.ac.at, muhammad.shaﬁque@nyu.edu\nAbstract—Recent advances have shown that Spiking Neural\nNetwork (SNN)-based systems can efﬁciently perform unsuper-\nvised continual learning due to their bio-plausible learning rule,\ne.g., Spike-Timing-Dependent Plasticity (STDP). Such learning\ncapabilities are especially beneﬁcial for use cases like autonomous\nagents (e.g., robots and UAVs) that need to continuously adapt\nto dynamically changing scenarios/environments, where new data\ngathered directly from the environment may have novel features\nthat should be learned online. Current state-of-the-art works\nemploy high-precision weights (i.e., 32 bit) for both training and\ninference phases, which pose high memory and energy costs\nthereby hindering efﬁcient embedded implementations of such\nsystems for battery-driven mobile autonomous systems. On the\nother hand, precision reduction may jeopardize the quality of\nunsupervised continual learning due to information loss. Towards\nthis, we propose lpSpikeCon, a novel methodology to enable\nlow-precision SNN processing for efﬁcient unsupervised continual\nlearning on resource-constrained autonomous agents/systems. Our\nlpSpikeCon methodology employs the following key steps: (1)\nanalyzing the impacts of training the SNN model under unsuper-\nvised continual learning settings with reduced weight precision\non the inference accuracy; (2) leveraging this study to identify\nSNN parameters that have a signiﬁcant impact on the inference\naccuracy; and (3) developing an algorithm for searching the\nrespective SNN parameter values that improve the quality of\nunsupervised continual learning. The experimental results show\nthat our lpSpikeCon can reduce weight memory of the SNN model\nby 8x (i.e., by judiciously employing 4-bit weights) for performing\nonline training with unsupervised continual learning and achieve\nno accuracy loss in the inference phase, as compared to the\nbaseline model with 32-bit weights across different network sizes.\nIndex Terms—Spiking neural networks, SNNs, unsupervised\nlearning, continual learning, memory efﬁciency, energy efﬁciency,\nautonomous agents, embedded systems.\nI. INTRODUCTION\nWith the advances of neuromorphic computing, SNN-based\nsystems have shown potential for having efﬁcient learning\ncapabilities due to their bio-plausible learning rules, like the\nSpike-Timing-Dependent Plasticity (STDP) [1]–[8]. However,\nthe knowledge learned from the ofﬂine training process may\nbecome obsolete over time and in unpredictable operational\nconditions, which leads to low accuracy at run time. This is\ncrucial when SNN systems are deployed in the dynamically\nchanging scenarios/environments, i.e., where new data collected\ndirectly from the operational environments have novel informa-\ntion/features that should be learned online [9] [10]; see Fig. 1.\nMoreover, this data is typically unlabeled and may not be pro-\nportionally distributed, thereby making it difﬁcult for the SNN\nsystems to learn different tasks/classes [11]. To address these\nissues, recent works have proposed strategies for enabling the\nunsupervised continual learning in SNNs [9]–[12], which are\nDynamically changing environments\nEnvironment-1\nEnvironment-2\nEnvironment-3\nAn SNN-based \nautonomous agent\n(e.g., drone)\nCurrent knowledge\nThe agent is moving across environments\nto learn\nto learn\nto learn\nFig. 1.\nThe SNN-based autonomous agent needs to perform training online\nusing unsupervised continual learning strategies to update the knowledge,\nthereby adapting to dynamically changing environments in an efﬁcient manner.\nbeneﬁcial for use cases like autonomous agents (e.g., robots and\nUAVs) that need to continuously adapt to dynamically changing\nenvironments [10]. However, autonomous agents typically have\ntight constraints (e.g., available memory), thereby requiring an\nefﬁcient embedded implementation of SNN systems.\nTargeted Problem: If and how can we efﬁciently implement\nSNN systems with unsupervised continual learning capabilities\non autonomous agents with tight memory constraints, while\nmaintaining the inference accuracy close to that of the baseline\nimplementation. An efﬁcient solution to this problem will\nenable highly memory- and power/energy-efﬁcient autonomous\nagents that are adaptive to unpredictable dynamic environments.\nA. The State-of-the-Art and Their Limitations\nThe research for unsupervised continual learning in SNN\nsystems is still at an early stage. Therefore, the state-of-the-art\nworks still focus on improving the quality of learning, while\nconsidering relatively simple datasets (e.g., MNIST) [9]–[12].\nThese works employ high-precision weights (i.e., 32 bits) for\nboth training and inference phases to achieve high accuracy,\nbut incur high memory and energy costs, thereby hindering\nthe implementation of such SNN systems for battery-powered\nautonomous agents. Towards this, quantization is a potential\ntechnique for efﬁciently reducing the memory footprint of\nSNNs, and hence the energy consumption [8] [13]. However,\nthe impacts of weight quantization on the accuracy of unsuper-\nvised continual learning in SNN systems have not been explored\nyet. To show the limitations of state-of-the-art and the targeted\nproblem, we perform an experimental case study in Section I-B.\nB. Case Study and Scientiﬁc Challenges\nFor the case study, we perform experiments that provide\ndynamic scenarios to the network by feeding consecutive tasks/\n1\narXiv:2205.12295v1  [cs.NE]  24 May 2022\n0\n20\n40\n60\n80\n100\nAfter\nTrain\n'0'\nAfter\nTrain\n'1'\nAfter\nTrain\n'2'\nAfter\nTrain\n'3'\nAfter\nTrain\n'4'\nAfter\nTrain\n'5'\nAfter\nTrain\n'6'\nAfter\nTrain\n'7'\nAfter\nTrain\n'8'\nAfter\nTrain\n'9'\nAccuracy [%]\nSequence of Task\nNo UCL (32b)\nBaseline UCL (32b)\nBaseline UCL (4b)\n(c)\nAccuracy degradation \nup to 19%\nAccuracy improvement up to 40%\n(a) \n0\n0.2\n0.4\n0.6\n0.8\n1\nNo UCL\n(32b)\nBaseline\nUCL (32b)\nBaseline\nUCL (4b)\nWeight Memory\n(Normalized to \nNo UCL)\n(b) \n8x \nsaving\nInhibition\nInput\nExcitatory layer\n…\nOutput\n…\nno \nsaving\nFig. 2. (a) The SNN architecture that supports unsupervised continual learning,\ni.e., a single-layer fully-connected network. (b) Weight memory of a 400-\nneuron network with different learning conditions: No Unsupervised Continual\nLearning (No UCL) with 32-bit weights; Baseline UCL with 32-bit weights,\nadapted from [10]; and Baseline UCL with 4-bit weights, using quantization.\n(c) Accuracy of a 400-neuron network with different learning conditions. In\nthis work, we consider the UCL algorithm from the work of [10].\nclasses using training samples, train the network accordingly,\nthen evaluate the trained network using the test samples for\ntasks/classes that have been fed so far. Following are the steps\nof experiments using the MNIST dataset.\n• First, we feed a stream of training samples for digit-0, and\ntrain the network accordingly. Then, we evaluate the trained\nnetwork using the test samples for digit-0.\n• Second, we repeat the above steps but for training digit-1,\nand testing digit-0 and digit-1.\n• The above steps are repeated but for training another digit,\nand testing the digits that have been learned so far, until all\n10 digits in MNIST are used for training and testing.\nOur experiments consider the network architecture shown in\nFig. 2(a) and different learning conditions: (1) No Unsupervised\nContinual Learning (No UCL); (2) Baseline UCL with 32-bit\nweights, adapted from [10]; and (3) Baseline UCL with 4-bit\nweights. Further details of the experimental setup are presented\nin Section IV. The experimental results are shown in Fig. 2(b)-\n(c), from which we make the following key observations.\n• The unsupervised continual learning improves the accuracy\nunder dynamic scenarios, due to its carefully crafted weight\npotentiation/depression strategy to learn new features, while\nretaining old yet important ones.\n• Reduction of weight precision can signiﬁcantly save the SNN\nweight memory, e.g., reducing precision from 32-bit to 4-bit\nweights enables 8x weight memory saving. However, it may\ndegrade the quality of unsupervised continual learning due\nto knowledge/information loss.\n• A network with 4-bit weights and continual learning may\nachieve higher accuracy than a network with 32-bit weights\nbut no continual learning, thereby showing the potential of\nmemory reduction for a network under dynamic scenarios.\nThese observations highlight the following key challenges to\ndevise an efﬁcient solution for the targeted problem.\n• Quantization should be performed judiciously to remove non-\nsigniﬁcant information in each weight, hence retaining most\nof the important information and maintaining the learning\nquality (i.e., high accuracy).\n• The solution should employ simple yet effective enhancements\nto compensate for the information loss due to weight quan-\ntization, thereby enabling energy-efﬁcient learning.\nC. Our Novel Contributions\nTo address the above challenges, we propose lpSpikeCon,\na novel methodology that enables low-precision Spiking neu-\nral network processing for efﬁcient unsupervised Continual\nlearning on autonomous agents/systems. To the best of our\nknowledge, this work is the ﬁrst effort that aims at reducing\nthe weight precision of SNNs, while maintaining the quality\nof unsupervised continual learning under dynamic scenarios.\nFollowing are the key steps of our lpSpikeCon methodology\n(see an overview in Fig. 3).\n• Analyzing the characteristics of SNN accuracy proﬁles of\neach given task under different quantization levels, when\nthe given SNN employs unsupervised continual learning.\n• Identifying the SNN parameters that have signiﬁcant\nimpact on the accuracy. It leverages the accuracy analysis\nto determine SNN parameters and their adjustment rules\nto get better neuronal dynamics for unsupervised continual\nlearning, and hence accuracy.\n• Devising an algorithm for determining parameter values\nthat effectively improve the learning quality. It leverages the\nparameter adjustment rules for guiding the algorithm to reﬁne\nthe parameter values for achieving high accuracy in dynamic\nscenarios/environments.\nKey Results: We evaluate our lpSpikeCon methodology\nusing a Python-based framework [14] on a multi-GPU machine.\nThe experimental results show that our lpSpikeCon improves\nthe quality of unsupervised continual learning for a quantized\nSNN through effective parameter adjustments, thereby achiev-\ning no accuracy loss in the inference while reducing the weight\nmemory (e.g., by 8x when the SNN employs 4-bit weights), as\ncompared to the non-quantized SNN (i.e., with 32-bit weights).\nDynamic \nScenarios / \nEnvironments\nQuantization \nLevels \nfor Weights\n…\n…\nBaseline Model\nEnhanced Model\n…\n…\nOur Novel Contributions\nlpSpikeCon Methodology (Section III)\nAnalyzing the characteristics of \nSNN accuracy (Section III-B)\nIdentifying SNN parameters that \nhave significant impact on accuracy \n(Section III-C)\nDevising an algorithm for determining \nSNN parameter values (Section III-D)\nFig. 3. The lpSpikeCon methodology, highlighting the novel components.\nII. BACKGROUND\nA. Spiking Neural Networks (SNNs)\nSNNs have the potential for energy-efﬁcient processing in\nboth the training and inference phases due to their highly\nbio-plausible computation model, i.e., spike-based information\nand computation [15]–[18]. Each SNN model is formed by\nseveral design components, i.e., network architecture, neuron\nand synapse models, spike coding, as well as learning rule [8].\nIn this work, we employ the network architecture/topology\nof Fig. 2(a), as it has been widely used for SNNs with\n2\nunsupervised continual learning capabilities [9]–[11]. This net-\nwork is trained so that each excitatory neuron can recognize\na speciﬁc task/class. For spike/information coding, several\ncoding schemes have been proposed in the literature, such as\ntemporal, rank-order, rate, phase, and burst coding [19]–[22].\nHere, we employ the rate coding to convert information into\nspike trains, since it can achieve high accuracy in unsupervised\nlearning settings [23]. For the neuron model, we employ the\nLeaky Integrate-and-Fire (LIF) model, as it incurs the lowest\ncomputational complexity while providing highly bio-plausible\nneuronal dynamics, as compared to other neuron models [24].\nThe neuronal dynamics of the LIF model are shown in Fig. 4,\nand explained in the following.\n• LIF neuron increases the membrane potential (Vmem) each\ntime there is an incoming spike, and otherwise, the Vmem\ndecreases exponentially with the rate of Vdecay.\n• If the Vmem reaches the membrane threshold potential (Vth),\nthe LIF neuron generates a spike, then the Vmem goes back\nto the reset potential (Vreset), and the neuron state enters the\nrefractory period (Tref).\n• To evenly distribute the spiking activity across all excitatory\nneurons (i.e., homeostasis), the membrane threshold potential\nis deﬁned as Vth = Vth + θ (so-called adaptive membrane\nthreshold potential) [25] with θ denotes the adaptation po-\ntential. The θ is added to Vth each time the neuron generates\na spike, and otherwise, Vth decreases with the rate of θdecay.\nMeanwhile, the synapse is modeled by the conductance and\nweight (w). The conductance is increased by w when there is\nlearning activity (i.e., weight potentiation). Depending upon the\nlearning rule, the w may be decreased with the rate of weight\ndecay (wdecay) if there is no learning activity (i.e., weight\ndepression). For the learning rule, we employ the pair-based\nSTDP learning, which is adapted from [10].\ntime\ntime\nVmem\nVreset\nVth\nincoming\nspikes\ntime\ngenerated\nspikes\nVth + θ\nrefractory period\nneuronal \ndynamics\nFig. 4. Overview of the neuronal dynamics of a LIF model.\nB. Quantization\nQuantization is a prominent technique to reduce the size of\nan SNN model (i.e., weight memory) that incurs a relatively low\noverhead, since it only needs to reduce the data precision [13].\nIt can be represented in a ﬁxed-point format (Qi.f), which\nconsists of 1 sign bit, i integer bits, f fractional bits, and\nfollows the 2’s complement format. Therefore, the Qi.f format\nhas a range of representable values of [−2i, 2i −2-f] with a\nprecision of ϵ = 2-f. In the quantization process, a rounding\nscheme is required, and we consider the simple and widely used\none, i.e., truncation [26] [27]. Truncation simply keeps f bits\nand removes the remaining bits from the fractional part. The\noutput of ﬁxed-point quantization for a given real number x\nwith conﬁguration Qi.f is deﬁned as T(x, Qi.f) = ⌊x⌋. To\nsimulate the unsupervised continual learning under quantized\nweights, we perform quantization during the training phase\nusing the simulated quantization approach [28]; see Fig. 5.\nSNN \nModel \n(FP32) \nTraining Phase\nQuantize \nSNN weights \n(Qi.f)\nQuantized SNN \nModel (Qi.f) \nTrained & \nQuantized SNN \nModel (Qi.f) \nAccuracy\nInference Phase\nTrain SNN model (Qi.f)\nTest SNN model \n(Qi.f)\nFig. 5. Overview of the quantization scheme.\nIII. THE LPSPIKECON METHODOLOGY\nA. Overview\nOur lpSpikeCon methodology employs the following key\nsteps (see an overview in Fig. 6).\n• Analyzing the SNN accuracy proﬁles (Section III-B) by\nperforming the following mechanisms.\n– Quantizing the weights of a given network.\n– Training the network with quantized weights using the\nunsupervised continual learning under dynamic scenarios.\n– Observing the accuracy proﬁles of each given task/class\nunder different quantization levels.\n• Identifying the SNN parameters and their adjustment\nrules for unsupervised continual learning (Section III-C)\nby performing the following mechanisms.\n– Leveraging the accuracy analysis to select SNN parameters\nthat have a signiﬁcant impact on accuracy.\n– Devising the adjustment rules for the selected parameters\nto derive better neural dynamics (e.g., membrane threshold\npotential) for unsupervised continual learning.\n• Devising an algorithm for reﬁning SNN parameter values\nfor unsupervised continual learning (Section III-D). It is\nperformed by leveraging the adjustment rules to gradually\nincrease/decrease parameter values that improve the learning\nquality under quantized weights.\nThe lpSpikeCon-enhanced SNN systems are then scheduled\nto update their ofﬂine-trained knowledge regularly at run time,\ne.g., based on the user-deﬁned duration of an inference mode.\nThe update is performed through online training using data\ngathered from the operational environments. After completing\nthe training mode, the systems are back to the inference mode.\nIn this manner, the SNN systems are expected to adapt better to\ndiverse operational environments than the ofﬂine-trained ones.\nB. Analyzing the SNN Accuracy Proﬁles\nTo devise a lightweight solution that enables efﬁcient unsu-\npervised continual learning for a quantized SNN, it is important\nto understand the characteristics of SNN accuracy for each\ngiven task/class under different quantization levels and dynamic\nscenarios. To do this, we perform the following steps.\n• We quantize the weights of a given SNN model using the\ntruncation approach, as described in Section II-B.\n• Then, we train the quantized model using unsupervised\ncontinual learning under dynamic scenarios. To do this, we\nfeed consecutive tasks/classes using training samples, train\nthe model accordingly, then evaluate the trained model using\nthe test samples for tasks/classes that have been fed so far;\nsee the overview in Alg. 1.\n3\nBaseline Model\n…\n…\nEnhanced Model\nAn autonomous \nagent/system \n(e.g., drone)\nEnvironment        \nAnalyzing the SNN accuracy profiles \n(Section III-B)\n…\n…\nDynamic Scenarios \n/ Environments\nQuantization\n0 0 1 1 0 1 0 1\n0 0 1 1 0 1 0 1\nAccuracy \nProfiles \nObservation\nTraining\nlpSpikeCon Methodology \n(Section III)\n0\n50\n100\n0 1 2 3 4 5 6 7 8 9\nIdentifying SNN parameters \nand their adjustment rules \n(Section III-C)\nParameter \nselection\nrules\nAdjustment \nrules\nTrained & Quantized \nSNN Model\nAdjustment \nRules\nAn algorithm for refining \nSNN parameter values \n(Section III-D)\nparams\nparams\n0\n50\n100\n0 1 2 3 4 5 6 7 8 9\nEvaluation on accuracy\nadjust params\nAlgorithm for exploring \nadjustment values\nQuantization Levels \nfor Weights\nFig. 6. The overview of our lpSpikeCon methodology, whose novel steps are shown in green boxes.\n• Afterwards, we observe the proﬁles of inference accuracy for\neach given task/class under different levels of weight quan-\ntization, to understand the sources of accuracy degradation\nand get insights on how to address it.\nAlgorithm 1 Training and testing under dynamic scenarios\nINPUT: (1) SNN model (modelin); (2) Dataset (D): dataset for class-i\n(D[i]), training set for class-i (D[i].train set), testing set for class-i\n(D[i].test set);\nOUTPUT: (1) Trained SNN model (modelout); (2) Accuracy (acc)\nBEGIN\nInitialization:\n1: modelout = modelin;\nProcess:\n2: task = class(D)\n3: for i ∈task do\n4:\nmodelout ←train(modelout, D[i].train set);\n5:\nfor k = 0 to i do\n6:\nacc[i, k] = test(modelout, D[k].test set);\n7:\nend for\n8: end for\n9: return modelout;\nEND\nThe experimental results are presented in Fig. 7, from which\nwe make the following key observations.\n• In general, reduced weight precision degrades the accuracy\nof unsupervised continual learning due to information loss.\nThe accuracy degradation is noticeable especially for tasks\nthat are learned at the later training sequence, as shown by\nlabels 1 , 2 , and 3 in Fig. 7.\n• Lower weight precision also leads to lower accuracy for more\ntasks. For instance, a model with 4-bit weights suffers from\nvery low accuracy (≤20%) on four tasks, i.e., digit-6, digit-\n7, digit-8, and digit-9 (see label 3 in Fig. 7), while a model\nwith 8-bit weights suffers from very low accuracy only on\ntask digit-9 (see label 1 in Fig. 7).\nThese observations lead to several insights for devising an\nefﬁcient solution for the targeted problem, as follows.\n• Reduced weight precision has a less memory capacity for\nstoring unique information from new tasks, thereby making\nthe quantized SNN model difﬁcult to recognize novel features\nfrom new tasks.\n• Different SNN models with different levels of weight preci-\nsion have different accuracy proﬁles. Therefore, such models\nrequire specialized settings for achieving high accuracy.\nThe above discussion indicates that, the potential solution is by\nemploying parameter adjustments that provide more available\nmemories for storing novel information from new tasks, while\nconsidering specialized settings for different levels of weight\nprecision. In this manner, costly additional components and/or\noperations can be avoided, which leads to efﬁcient learning.\nC. Identifying SNN Parameters and Their Adjustment Rules\nAnalysis in Section III-B suggests that the efﬁcient solution\nis by employing parameter adjustments for the given quan-\ntized SNN model. Therefore, it is important to identify SNN\nparameters that have a signiﬁcant impact on accuracy, and\ntheir effective adjustment rules for improving learning quality\nof the quantized model.\nSNN Parameters: To identify SNN parameters that should\nbe adjusted for better learning quality, we leverage the analysis\nfrom Section III-B. The analysis shows that the reduced weight\nprecision makes the model difﬁcult to learn tasks that appear\nat the later training sequence. This means that the weight bits\nare strongly associated with the previously learned tasks, and\nnot ﬂexible enough to change their context to another task.\nTo address this, we adjust the neuronal dynamics so that the\nsynaptic plasticity becomes more ﬂexible for learning new tasks,\nespecially when low weight precision is employed. To do this,\nwe adjust two parameters to change the ﬂexibility of neuronal\ndynamics for learning activity: adaptive membrane threshold\npotential (Vth) and weight decay rate (wdecay). This selection\nis based on the following reasons.\n• Vth determines how far Vmem should be increased to generate\na spike, which then triggers weight potentiation for learning.\nThe distance between Vth and Vmem is inversely proportional\nto the ﬂexibility for learning activity.\n• wdecay determines how fast each synaptic weight is depressed\nfor removing the learned information, and providing available\nmemory for storing novel information from new tasks.\nAdjustment Rules: To properly adjust the selected SNN\nparameters (i.e., Vth and wdecay) for achieving better learning\nquality of a quantized SNN model, we propose the following\nparameter adjustment rules.\n• In the non-quantized model, Vth is set with a value that\nprevents catastrophic forgetting1. Therefore, to make Vth\n1Catastrophic forgetting means that the system learns information from new\ndata, but quickly forgets the previously learned ones [29]–[31]\n4\nAfter\nTrain\n'0'\nAfter\nTrain\n'1'\nAfter\nTrain\n'2'\nAfter\nTrain\n'3'\nAfter\nTrain\n'4'\nAfter\nTrain\n'5'\nAfter\nTrain\n'6'\nAfter\nTrain\n'7'\nAfter\nTrain\n'8'\nAfter\nTrain\n'9'\nAvg Acc. / Training Task\nAcc. of Task Digit-0\nAcc. of Task Digit-1\nAcc. of Task Digit-2\nAcc. of Task Digit-3\nAcc. of Task Digit-4\nAcc. of Task Digit-5\nAcc. of Task Digit-6\nAcc. of Task Digit-7\nAcc. of Task Digit-8\nAcc. of Task Digit-9\nAfter\nTrain\n'0'\nAfter\nTrain\n'1'\nAfter\nTrain\n'2'\nAfter\nTrain\n'3'\nAfter\nTrain\n'4'\nAfter\nTrain\n'5'\nAfter\nTrain\n'6'\nAfter\nTrain\n'7'\nAfter\nTrain\n'8'\nAfter\nTrain\n'9'\n0\n20\n40\n60\n80\n100\nAfter\nTrain\n'0'\nAfter\nTrain\n'1'\nAfter\nTrain\n'2'\nAfter\nTrain\n'3'\nAfter\nTrain\n'4'\nAfter\nTrain\n'5'\nAfter\nTrain\n'6'\nAfter\nTrain\n'7'\nAfter\nTrain\n'8'\nAfter\nTrain\n'9'\nAccuracy [%]\n0\n20\n40\n60\n80\n100\nAfter\nTrain\n'0'\nAfter\nTrain\n'1'\nAfter\nTrain\n'2'\nAfter\nTrain\n'3'\nAfter\nTrain\n'4'\nAfter\nTrain\n'5'\nAfter\nTrain\n'6'\nAfter\nTrain\n'7'\nAfter\nTrain\n'8'\nAfter\nTrain\n'9'\nSequence of Task\n32-bit weights\n8-bit weights\n6-bit weights\n1\n2\n3\n4-bit weights\n12-bit weights\nSequence of Task\nA 400-neuron network\nMNIST dataset\nSequence of Task\nFig. 7. The accuracy proﬁles of a 400-neuron network on MNIST dataset under different levels of weight precision (i.e., 32, 12, 8, 6, and 4 bits) and dynamic\nscenarios. The colored line represents the accuracy for each task/class throughout the consecutive training phases from digit-0 to digit-9. The grey bar represents\nthe average accuracy after each training phase of a task/class.\n0\n20\n40\n60\n80\n100\nAfter\nTrain\n'0'\nAfter\nTrain\n'1'\nAfter\nTrain\n'2'\nAfter\nTrain\n'3'\nAfter\nTrain\n'4'\nAfter\nTrain\n'5'\nAfter\nTrain\n'6'\nAfter\nTrain\n'7'\nAfter\nTrain\n'8'\nAfter\nTrain\n'9'\n0\n20\n40\n60\n80\n100\nAfter\nTrain\n'0'\nAfter\nTrain\n'1'\nAfter\nTrain\n'2'\nAfter\nTrain\n'3'\nAfter\nTrain\n'4'\nAfter\nTrain\n'5'\nAfter\nTrain\n'6'\nAfter\nTrain\n'7'\nAfter\nTrain\n'8'\nAfter\nTrain\n'9'\nAvg Acc. / Training Task\nAcc. of Task Digit-0\nAcc. of Task Digit-1\nAcc. of Task Digit-2\nAcc. of Task Digit-3\nAcc. of Task Digit-4\nAcc. of Task Digit-5\nAcc. of Task Digit-6\nAcc. of Task Digit-7\nAcc. of Task Digit-8\nAcc. of Task Digit-9\nAccuracy [%]\nSequence of Task\nA 400-neuron \nnetwork\nMNIST dataset\n4\n4-bit weights + \nincreased wdecay\n(a)\n4-bit weights + \ndecreased Vth\n(b)\n5\nFig. 8. The accuracy proﬁles of a 400-neuron network with 4-bit weights on the\nMNIST dataset under dynamic scenarios and different parameter adjustments.\n(a) “Increased wdecay” by using baseline wdecay +0.09. (b) “Decreased Vth”\nby using Vth+ (baseline θ −0.2).\nmore suitable for the quantized model, its value should be\nless or equal (≤) than Vth of the non-quantized model. In\nthis manner, each neuron is expected to reach Vth faster and\nto generate spikes more frequently, which triggers learning\nactivity for any incoming tasks.\n• In the non-quantized model, wdecay is set with a value that\nprovides available memory for storing learned information\nfrom new tasks. Therefore, to make wdecay more suitable for\nthe quantized model, its value should be greater or equal (≥)\nthan wdecay of the non-quantized model. In this manner, each\nweight is expected to decay faster, hence providing available\nmemory for storing learned features from any incoming tasks.\nTo justify these rules, we perform an experimental case study\nto see the impact of our adjustment rules, i.e., “decreased Vth”\nand “increased wdecay”. Experimental results are provided in\nFig. 8. These results show that our adjustment rules improve the\nquality of unsupervised continual learning for both “decreased\nVth” and “increased wdecay” cases, since each case has less\nnumber of tasks with very low accuracy, i.e., ≤20% (see labels\n4 and 5 in Fig. 8), as compared to the model with 4-bit\nweights and baseline continual learning (see label 3 in Fig. 7).\nD. An Algorithm for Reﬁning SNN Parameter Values\nTo properly adjust the values of the selected SNN parameters,\na systematic mechanism is required. Toward this, we propose\nan algorithm that leverages our adjustment rules to reﬁne the\nselected SNN parameter values (Vth and wdecay) for achieving\nbetter learning quality, especially under dynamic scenarios.\nThis algorithm is developed based on the following ideas, and\nthe detailed steps are provided in Alg. 2.\n• The range of values for each selected SNN parameter (Vth\nor wdecay) should be deﬁned for guiding the design space\nexploration. The lower-bound value for Vth is V l\nth, while the\nupper-bound value for wdecay is wu\ndecay.\n• The accuracy for each task (acctask) should not be less or\nequal (≤) than the deﬁned value. Therefore, if we consider\nacclow as the borderline of low accuracy, then the acceptable\naccuracy for each task is deﬁned as follows.\nacctask > acclow\n(1)\n• The average accuracy of the lpSpikeCon-enhanced SNN\nmodel (acc∗\navg) should be within an acceptable accuracy loss.\nTherefore, if we consider accavg as the average accuracy of\nthe non-quantized SNN model with baseline unsupervised\ncontinual learning, and accloss as the acceptable accuracy\nloss, then the acc∗\navg is deﬁned as follows.\nacc∗\navg ≥(accavg −accloss)\n(2)\nIV. EVALUATION METHODOLOGY\nFig. 9 shows the experimental setup for evaluating lpSpike-\nCon methodology. We employ a Python-based framework [14]\nthat runs on a multi-GPU machine (i.e., Nvidia RTX 2080 Ti)\nand an Embedded-GPU machine (i.e., Nvidia Jetson Nano)\nto perform evaluations on different platforms with different\nmemory and compute capabilities. We employ a single-layer\nfully-connected network shown in Fig. 2(a) with different\nnetwork sizes (i.e., 200 and 400 neurons), since it has shown the\ncapabilities for performing unsupervised continual learning un-\nder resource- and power-constrained embedded platforms [10].\nWe consider MNIST dataset as workload, since it has been\nwidely used for evaluating unsupervised continual learning in\nthe SNN community [9]–[12]. For the baseline unsupervised\ncontinual learning, we consider the learning strategy from [10].\nThe evaluation is performed under both the non-dynamic and\ndynamic scenarios. Non-dynamic scenarios are provided by\nfeeding the network with training samples whose tasks/classes\n5\nAlgorithm 2 Adjustment steps for SNN parameter values\nINPUT: (1) SNN: baseline non-quantized model (modelin), weight decay rate\n(wdecay), upper-bound of wdecay (wu\ndecay); (2) Exploration variables:\ninvestigated/evaluated model (modeleval), increasing step for wdecay\n(step w), decreasing step for Vth (step Vth); (3) Functions: accuracy for\neach task (acctask), average accuracy of the given model (acc), acceptable\naccuracy loss (accloss);\nOUTPUT: Trained SNN model (modelout);\nBEGIN\nInitialization:\n1: modelout = modelin;\nProcess:\n2: for (p = wdecay; p ≤wu\ndecay; p = p + step w) do\n3:\nfor (q = Vth; q ≥V l\nth; q = q −step Vth) do\n4:\nmodeleval = modelin;\n5:\nupdate the values of selected SNN parameters;\n6:\nperform training and test on modeleval using Alg. 1\n7:\nif (acctask(modeleval) > acclow)\nand\n(acc(modeleval) ≥\n(acc(modelin) −accloss)) then\n8:\nif (acc(modeleval) ≥acc(modelout)) then\n9:\nmodelout = modeleval\n10:\nend if\n11:\nend if\n12:\nend for\n13: end for\n14: return modelout;\nEND\nare randomly distributed. It aims at simulating conventional\nofﬂine training where all training samples are already available.\nMeanwhile, dynamic scenarios are provided by feeding the net-\nwork with consecutive tasks/classes, where each task/class has\nthe same number of samples, and without re-feeding previous\ntasks/classes. It aims at simulating an extreme condition where\nthe deployed system receives training tasks in a consecutive\nmanner from the environment.\nSNN model (.pt)\nMemory (.txt)\nDataset\nNetwork\nconfiguration\nRun on GPU\nPython-based Framework\nUnsupervised \ncontinual \nlearning\nstrategy\nQuantization \nlevels\nTraining\nTesting\nMemory estimator\nSNN model\nSNN parameters controller\nAccuracy (.txt)\nScenario controller\n(dynamic & non-dynamic)\nlpSpikeCon Methodology\nTrained SNN\nSNN model generation\nFig. 9. The experimental setup for evaluating our lpSpikeCon methodology.\nV. RESULTS AND DISCUSSION\nA. Maintaining Accuracy under Quantized Weights\nDynamic Scenarios: We evaluate accuracy considering dif-\nferent network sizes (i.e., 200 and 400 neurons) and different\nweight precision levels (i.e., 32, 16, 14, 12, 8, 6, and 4 bits), and\nthe experimental results are provided in Fig. 10. These results\nshow that lower weight precision leads to lower accuracy for\nmore recognition tasks due to information loss. For instance, in\na 200-neuron network, 6-bit weights lead to very low accuracy\n(i.e., ≤20%) on one task (see label 1 ), while 4-bit weights\nlead to very low accuracy on four tasks (see label 2 ). Such\npatterns are also observed in a 400-neuron network, as shown\nby labels 5 and 6 .\nThe experimental results also show that our lpSpikeCon\nmethodology can improve the accuracy of the quantized SNNs,\nwhich can be observed in two aspects. First, the lpSpikeCon-\nenhanced SNNs do not suffer from very low accuracy (i.e.,\n≤20%) for recognizing any tasks/classes; see labels 3 and\n4 for a 200-neuron network, and labels 7 and 8 for a\n400-neuron network. Second, the lpSpikeCon-enhanced SNNs\nalso achieve no accuracy loss on average when compared to\nthe non-quantized SNNs with baseline unsupervised continual\nlearning, across different network sizes. For instance, in a\n200-neuron network, average accuracy for the 6-bit and 4-\nbit weights with lpSpikeCon is 65%, which is slightly higher\nthan the 32-bit weights with baseline learning (i.e., 62%); see\nlabels A and B . A similar pattern is also observed in a 400-\nneuron network, as the average accuracy for the 6-bit and 4-\nbit weights with lpSpikeCon are 68% and 67% respectively,\nwhich are slightly higher than the 32-bit weights with baseline\nlearning (i.e., 66%); see labels C and D . These accuracy\nimprovements are due to proper adjustments on the selected\nSNN parameters (i.e., Vth and wdecay). These adjustments\ntrigger the neuronal dynamics in the SNN system to quickly\nprovide available memory for learning new tasks through the\n“increased wdecay” approach, and trigger learning activity for\nany incoming tasks (including the new tasks) through the\n“decreased Vth” approach. From the results, we also observe\nthat in a certain case, an lpSpikeCon-enhanced model may\nhave lower average accuracy than the non-enhanced model\nunder the same weight precision. For instance, in the 200-\nneuron network with 8-bit weights, our lpSpikeCon-enhanced\nmodel achieves 63% accuracy (see label E ), while the non-\nenhanced one achieves 65% (see label F ). The reason is\nthat, the lpSpikeCon considers the borderline of low accuracy\n(acclow) as a constraint to determine the parameter adjustments\nand the output model. Therefore, since the non-enhanced model\nhas lower accuracy than the deﬁned acclow for one task, this\nmodel is not considered as the solution (see label 9 ).\nNon-Dynamic Scenarios: We evaluate accuracy considering\ndifferent network sizes (i.e., 200 and 400 neurons) and different\nweight precision levels (i.e., 32, 16, 14, 12, 8, 6, and 4 bits),\nand the experimental results are provided in Fig. 11. These\nresults show that, our lpSpikeCon-enhanced SNNs can achieve\ncomparable accuracy to the non-enhanced SNN counterparts\n(i.e., SNNs which employ baseline unsupervised continual\nlearning under the same weight precision). For instance, in\nthe 400-neuron network with 6-bit weights, our lpSpikeCon-\nenhanced SNN achieves 78% accuracy and the non-enhanced\none achieves 75% accuracy; while in the 4-bit weights case,\nthe lpSpikeCon-enhanced SNN achieves 71% accuracy and\nthe non-enhanced one achieves 77% accuracy, as highlighted\nby label G . The reason is that, our lpSpikeCon methodology\nperforms exploration for parameter adjustments within a range\nof values that is close to the baseline settings. In this manner,\nproper adjustment values can be found fast, and are expected\nto preserve good characteristics from the baseline settings\nof unsupervised continual learning, such as achieving high\naccuracy under non-dynamic scenarios.\nB. Weight Memory Savings for Efﬁcient SNN Systems\nFig. 12 shows the memory requirements of different SNN\nmodels under different levels of weight precision. These results\nshow that weight quantization in our lpSpikeCon methodology\ncan signiﬁcantly decrease the memory footprint, since fewer\nbits are required to represent all weight parameters of an SNN\n6\n0\n20\n40\n60\n80\n100\nAvg Acc. / Training Task\nAcc. of Task Digit-0\nAcc. of Task Digit-1\nAcc. of Task Digit-2\nAcc. of Task Digit-3\nAcc. of Task Digit-4\nAcc. of Task Digit-5\nAcc. of Task Digit-6\nAcc. of Task Digit-7\nAcc. of Task Digit-8\nAcc. of Task Digit-9\n0.00\n20.00\n40.00\n60.00\n80.00\n100.00\n0\n20\n40\n60\n80\n100\n0.00\n50.00\n100.00\n0\n20\n40\n60\n80\n100\nAvg Acc. / Training Task\nAcc. of Task Digit-0\nAcc. of Task Digit-1\nAcc. of Task Digit-2\nAcc. of Task Digit-3\nAcc. of Task Digit-4\nAcc. of Task Digit-5\nAcc. of Task Digit-6\nAcc. of Task Digit-7\nAcc. of Task Digit-8\nAcc. of Task Digit-9\n0\n20\n40\n60\n80\n100\nAccuracy [%]\nSequence of Task\n0\n20\n40\n60\n80\n100\n62%\n32-bit weights\n6-bit weights\n4-bit weights\nAccuracy [%]\n66%\n1\n5\n6\nB\n0\n20\n40\n60\n80\n100\n16-bit weights\n14-bit weights\n62%\n12-bit weights\n0\n20\n40\n60\n80\n100\n8-bit weights\n65%\n62%\n63%\n65%\n47%\n2\n0\n20\n40\n60\n80\n100\n64%\n16-bit weights + lpSpikeCon\n9\nE\n6-bit weights + lpSpikeCon\n65%\n12-bit weights + lpSpikeCon\n63%\n65%\n4-bit weights + lpSpikeCon\n14-bit weights + lpSpikeCon\n63%\n63%\n8-bit weights + lpSpikeCon\n32-bit weights\n0\n20\n40\n60\n80\n100\n16-bit weights\n66%\n14-bit weights\n66%\n66%\n12-bit weights\n0\n20\n40\n60\n80\n100\n8-bit weights\n68%\n66%\n6-bit weights\n4-bit weights\n0\n20\n40\n60\n80\n100\n66%\n16-bit weights + lpSpikeCon\n67%\n14-bit weights + lpSpikeCon\n53%\n3\n4\n12-bit weights + lpSpikeCon\n68%\nSequence of Task\n68%\n8-bit weights + lpSpikeCon\n68%\n6-bit weights + lpSpikeCon\n7\n(b) A 400-neuron network\n8\n67%\n4-bit weights + lpSpikeCon\n(a) A 200-neuron network\nA\nD\nC\nF\nSequence of Task\nFig. 10. The accuracy proﬁles of (a) a 200-neuron network, and (b) a 400-neuron network, under different levels of weight precision and dynamic scenarios.\nThe colored line represents the inference accuracy for each task/class throughout the consecutive training phases. The grey-colored bar represents the average\naccuracy after each training phase of a task/class. The pattern-coded bar represents the average accuracy for all evaluated tasks/classes.\n0\n20\n40\n60\n80\n100\n200\n400\nAccuracy [%]\nNetwork Size\nNon-enhanced SNN (32b)\nNon-enhanced SNN (6b)\nSpikeCon-enhanced SNN (6b)\nNon-enhanced SNN (4b)\nSpikeCon-enhanced SNN (4b)\nG\nFig. 11.\nThe accuracy of (a) a 200-neuron network, and (b) a 400-neuron\nnetwork, under different levels of weight precision and non-dynamic scenarios.\nHere, the non-enhanced SNN refers to the model that employs baseline\nunsupervised continual learning.\nmodel. For instance, a model with 8-bit weights reduces the\nweight memory by 4x (as shown by label H ), while a model\nwith 4-bit weights reduces the weight memory by 8x (as shown\nby label I ), as compared to the non-quantized model which\nemploys 32-bit weights. Reduced memory requirement is not\nonly leading to a smaller area in hardware implementation, but\nalso decreasing the number of (off-chip and on-chip) memory\naccesses. For instance, a non-quantized model requires a single\nDRAM-based off-chip memory access for obtaining a 32-\nbit weight, while a quantized model with 8-bit weight can\naccess four weights from a single 32-bit DRAM access [32]\n[33]. Memory access reduction is important to enable energy-\nefﬁcient SNN-based autonomous agents mainly for two rea-\nsons. First, memory accesses typically dominate the energy\nconsumption of SNN systems, i.e., about 50%-75% of total\nenergy consumption of an SNN accelerator [34]. Second, the\n7\nonline training with unsupervised continual learning requires\nfrequent memory accesses for updating the weight values at run\ntime. Therefore, memory access reduction can signiﬁcantly save\nthe overall system energy, which is especially beneﬁcial for\nmemory- and energy-constrained autonomous agents/systems.\n0\n1\n2\n3\n200\n400\nWeight Memory \n(Normalized to \n32-bit model)\nNetwork Size\n32\n16\n14\n12\n10\n8\n6\n4\nWeight bits\nsavings\nI\nH\nFig. 12. Weight memory requirements of SNN models with different sizes of\nnetwork (i.e., 200 and 400 excitatory neurons) and different weight precision,\nwhich are normalized to the non-quantized SNN model (i.e., 32-bit weights).\nThe above results and discussion highlight our lpSpikeCon\nmethodology provides several beneﬁts as compared to the\nstate-of-the-art works, including better learning quality under\ndynamic environments, smaller memory footprint, and higher\nenergy efﬁciency. Furthermore, our lpSpikeCon can be ex-\ntended further by incorporating network-speciﬁc parameters\nthat have signiﬁcant impacts on the accuracy. For instance, net-\nworks with multiple layers may have additional parameters that\nshould be considered for better adjustments towards adapting\nto new/unseen features.\nVI. CONCLUSION\nWe propose the lpSpikeCon methodology to enable low-\nprecision SNN processing for efﬁcient unsupervised continual\nlearning on autonomous agents, through three key steps: (1)\nanalysis of the SNN accuracy proﬁles, (2) identiﬁcation of SNN\nparameters and their adjustment rules, and (3) reﬁnements of\nparameter values for learning activity. As results, our lpSpike-\nCon signiﬁcantly reduces weight memory of an SNN model,\nwhile maintaining accuracy in both dynamic and non-dynamic\nscenarios, as compared to the non-quantized model. Therefore,\nour lpSpikeCon methodology may enable memory- and energy-\nefﬁcient autonomous agents/systems that are adaptive to diverse\noperational environments.\nACKNOWLEDGMENT\nThis work was partially supported by the NYUAD Center\nfor Artiﬁcial Intelligence and Robotics (CAIR), funded by Tam-\nkeen under the NYUAD Research Institute Award CG010. This\nwork was also partially supported by the project “eDLAuto: An\nAutomated Framework for Energy-Efﬁcient Embedded Deep\nLearning in Autonomous Systems”, funded by the NYUAD\nResearch Enhancement Fund (REF).\nREFERENCES\n[1] M. Pfeiffer and T. Pfeil, “Deep learning with spiking neurons: Opportu-\nnities and challenges,” Frontiers in Neuroscience, vol. 12, 2018.\n[2] A. Tavanaei et al., “Deep learning in spiking neural networks,” Neural\nNetworks, vol. 111, pp. 47–63, 2019.\n[3] M. Davies et al., “Loihi: A neuromorphic manycore processor with on-\nchip learning,” IEEE Micro, vol. 38, no. 1, pp. 82–99, January 2018.\n[4] H. Hazan et al., “Unsupervised learning with self-organizing spiking\nneural networks,” in Int. Joint Conf. on Neural Networks (IJCNN), 2018.\n[5] D. J. Saunders et al., “Stdp learning of image patches with convolutional\nspiking neural networks,” in Int. Joint Conf. on Neural Networks, 2018.\n[6] H. Hazan et al., “Lattice map spiking neural networks (lm-snns) for\nclustering and classifying image data,” Annals of Math. and AI, 2019.\n[7] D. J. Saunders et al., “Locally connected spiking neural networks for\nunsupervised feature learning,” Neural Networks, vol. 119, 2019.\n[8] R. V. W. Putra and M. Shaﬁque, “Fspinn: An optimization framework\nfor memory-and energy-efﬁcient spiking neural networks,” IEEE Trans.\non Computer-Aided Design of Integrated Circuits and Systems (TCAD),\nvol. 39, no. 11, pp. 3601–3613, 2020.\n[9] P. Panda et al., “Asp: Learning to forget with adaptive synaptic plasticity\nin spiking neural networks,” IEEE J. on Emerging and Selected Topics\nin Circuits and Systems (JETCAS), vol. 8, no. 1, pp. 51–64, March 2018.\n[10] R. V. W. Putra and M. Shaﬁque, “Spikedyn: A framework for energy-\nefﬁcient spiking neural networks with continual and unsupervised learn-\ning capabilities in dynamic environments,” in 2021 58th ACM/IEEE\nDesign Automation Conference (DAC), 2021, pp. 1057–1062.\n[11] J. M. Allred and K. Roy, “Unsupervised incremental stdp learning using\nforced ﬁring of dormant or idle neurons,” in Int. Joint Conf. on Neural\nNetworks (IJCNN), 2016, pp. 2492–2499.\n[12] J. M. Allred and K. Roy, “Controlled forgetting: Targeted stimulation and\ndopaminergic plasticity modulation for unsupervised lifelong learning in\nspiking neural networks,” Frontiers in Neuroscience, vol. 14, p. 7, 2020.\n[13] R. V. W. Putra and M. Shaﬁque, “Q-spinn: A framework for quantizing\nspiking neural networks,” in Int. Joint Conf. on Neural Networks (IJCNN),\n2021, pp. 1–8.\n[14] H. Hazan et al., “Bindsnet: A machine learning-oriented spiking neural\nnetworks library in python,” Frontiers in Neuroinformatics, 2018.\n[15] W. Maass, “Networks of spiking neurons: The third generation of neural\nnetwork models,” Neural Networks, vol. 10, no. 9, pp. 1659–1671, 1997.\n[16] R. V. W. Putra, M. A. Hanif, and M. Shaﬁque, “Respawn: Energy-\nefﬁcient fault-tolerance for spiking neural networks considering unreliable\nmemories,” in 2021 IEEE/ACM Int. Conf. on Computer Aided Design\n(ICCAD), 2021, pp. 1–9.\n[17] M. Shaﬁque et al., “Towards energy-efﬁcient and secure edge ai: A cross-\nlayer framework iccad special session paper,” in 2021 IEEE/ACM Int.\nConf. on Computer Aided Design (ICCAD), 2021, pp. 1–9.\n[18] R. V. W. Putra, M. A. Hanif, and M. Shaﬁque, “Sparkxd: A framework\nfor resilient and energy-efﬁcient spiking neural network inference using\napproximate dram,” in 2021 58th ACM/IEEE Design Automation Confer-\nence (DAC), 2021, pp. 379–384.\n[19] J. Gautrais and S. Thorpe, “Rate coding versus temporal order coding: a\ntheoretical approach,” Biosystems, vol. 48, no. 1, pp. 57–65, 1998.\n[20] C. Kayser et al., “Spike-phase coding boosts and stabilizes information\ncarried by spatial and temporal spike patterns,” Neuron, vol. 61, 2009.\n[21] S. Thorpe and J. Gautrais, “Rank order coding,” in Computational\nneuroscience.\nSpringer, 1998, pp. 113–118.\n[22] S. Park et al., “Fast and efﬁcient information transmission with burst\nspikes in deep spiking neural networks,” in 56th Annual Design Automa-\ntion Conference (DAC), 2019, p. 53.\n[23] R. V. W. Putra, M. A. Hanif, and M. Shaﬁque, “Softsnn: Low-cost fault\ntolerance for spiking neural network accelerators under soft errors,” arXiv\npreprint arXiv:2203.05523, 2022.\n[24] E. M. Izhikevich, “Which model to use for cortical spiking neurons?”\nIEEE Trans. on Neural Networks (TNN), vol. 15, no. 5, Sep. 2004.\n[25] P. Diehl and M. Cook, “Unsupervised learning of digit recognition using\nspike-timing-dependent plasticity,” Frontiers in Computational Neuro-\nscience, vol. 9, p. 99, 2015.\n[26] M. Hopkins et al., “Stochastic rounding and reduced-precision ﬁxed-point\narithmetic for solving neural ordinary differential equations,” Philosoph-\nical Transactions of the Royal Society A, vol. 378, 2020.\n[27] S. Gupta et al., “Deep learning with limited numerical precision,” in Int.\nConf. on Machine Learning (ICML), 2015, p. 1737–1746.\n[28] R. Krishnamoorthi, “Quantizing deep convolutional networks for efﬁcient\ninference: A whitepaper,” arXiv, vol. 1806.08342, 2018.\n[29] Z. Chen and B. Liu, “Lifelong machine learning,” Synthesis Lectures on\nArtiﬁcial Intelligence and Machine Learning, vol. 12, no. 3, 2018.\n[30] G. I. Parisi et al., “Continual lifelong learning with neural networks: A\nreview,” Neural Networks, vol. 113, pp. 54 – 71, 2019.\n[31] M. McCloskey and N. J. Cohen, “Catastrophic interference in connection-\nist networks: The sequential learning problem,” Psychology of Learning\nand Motivation, vol. 24, pp. 109 – 165, 1989.\n[32] R. V. W. Putra et al., “Drmap: A generic dram data mapping policy\nfor energy-efﬁcient processing of convolutional neural networks,” in 57th\nACM/IEEE Design Automation Conference (DAC), 2020, pp. 1–6.\n[33] R. V. W. Putra et al., “Romanet: Fine-grained reuse-driven off-chip\nmemory access management and data organization for deep neural\nnetwork accelerators,” IEEE Trans. on Very Large Scale Integration\n(VLSI) Systems, vol. 29, no. 4, pp. 702–715, 2021.\n[34] S. Krithivasan et al., “Dynamic spike bundling for energy-efﬁcient spiking\nneural networks,” in Int. Symp. on Low Power Electronics and Design\n(ISLPED), July 2019, pp. 1–6.\n8\n",
  "categories": [
    "cs.NE",
    "cs.AI",
    "cs.AR",
    "cs.LG"
  ],
  "published": "2022-05-24",
  "updated": "2022-05-24"
}