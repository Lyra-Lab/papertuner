{
  "id": "http://arxiv.org/abs/2206.08978v1",
  "title": "Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study of African-American English",
  "authors": [
    "Jamell Dacon"
  ],
  "abstract": "Currently, natural language processing (NLP) models proliferate language\ndiscrimination leading to potentially harmful societal impacts as a result of\nbiased outcomes. For example, part-of-speech taggers trained on Mainstream\nAmerican English (MAE) produce non-interpretable results when applied to\nAfrican American English (AAE) as a result of language features not seen during\ntraining. In this work, we incorporate a human-in-the-loop paradigm to gain a\nbetter understanding of AAE speakers' behavior and their language use, and\nhighlight the need for dialectal language inclusivity so that native AAE\nspeakers can extensively interact with NLP systems while reducing feelings of\ndisenfranchisement.",
  "text": "Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study\nof African-American English\nJamell Dacon\nMichigan State University\nEast Lansing, MI, USA\ndaconjam@msu.edu\nAbstract\nCurrently, natural language processing (NLP)\nmodels proliferate language discrimination\nleading to potentially harmful societal impacts\nas a result of biased outcomes.\nFor exam-\nple, part-of-speech taggers trained on Main-\nstream American English (MAE) produce non-\ninterpretable results when applied to African\nAmerican English (AAE) as a result of lan-\nguage features not seen during training.\nIn\nthis work, we incorporate a human-in-the-loop\nparadigm to gain a better understanding of\nAAE speakers’ behavior and their language\nuse, and highlight the need for dialectal lan-\nguage inclusivity so that native AAE speak-\ners can extensively interact with NLP systems\nwhile reducing feelings of disenfranchisement.\n1\nIntroduction\nOver the years, social media users have leveraged\nonline conversational platforms to perpetually ex-\npress themselves online. For example, African\nAmerican English (AAE)1, an English language\nvariety is often heavily used on Twitter (Field et al.,\n2021; Blodgett et al., 2020). This dialect contin-\nuum is neither spoken by all African Americans\nor individuals who identify as BIPOC (Black, In-\ndigenous, or People of Color), nor is it spoken only\nby African Americans or BIPOC individuals (Field\net al., 2021; Bland-Stewart, 2005). In some cases,\nAAE, a low-resource language (LRL) may be the\nﬁrst (or dominant) language, rather than the second\n(or non-dominant) language of an English speaker.\nSpeciﬁcally, AAE is a regional dialect con-\ntinuum that consists of a distinct set of lexical\n1A dialectal continuum previously known as Northern Ne-\ngro English, Black English Vernacular (BEV), Black English,\nAfrican American Vernacular English (AAVE), African Amer-\nican Language (AAL), Ebonics, and Non-standard English\n(Labov, 1975; Bailey et al., 1998; Green, 2002, 2014; Baugh,\n2008; Bland-Stewart, 2005; King, 2020). It is often referred to\nas African American Language (AAL) and African American\nEnglish (AAE). In this work, we use the denotation AAE.\nitems, some of which have distinct semantic mean-\nings, and may possess different syntactic struc-\ntures/patterns than in Mainstream American En-\nglish (MAE) (e.g., differentiating habitual be and\nnon-habitual be usage) (Stewart, 2014; Dorn, 2019;\nJones, 2015; Field et al., 2021; Bland-Stewart,\n2005; Baugh, 2008; Blodgett et al., 2020; Labov,\n1975). In particular, Green (2002) states that AAE\npossesses a morphologically invariant form of the\nverb that distinguishes between habitual action and\ncurrently occurring action, namely habitual be. For\nexample, “the habitual be” experiment2 by Univer-\nsity of Massachusetts Amherst’s Janice Jackson.\nHowever, AAE is perceived to be “bad english”\ndespite numerous studies by socio/raciolinguists\nand dialectologists in their attempts to quantify\nAAE as a legitimized language (Baugh, 2008; Field\net al., 2021; Bland-Stewart, 2005; Labov, 1975).\n“[T]he common misconception [is] that language\nuse has primarily to do with words and what they\nmean. It doesn’t. It has primarily to do with\npeople and what they mean.”\n– Clark and\nSchober (1992)\nRecently, online AAE has inﬂuenced the genera-\ntion of resources for AAE-like text for natural lan-\nguage (NLP) and corpus linguistic tasks e.g., part-\nof-speech (POS) tagging (Jørgensen et al., 2016;\nBlodgett et al., 2018), language generation (Groen-\nwold et al., 2020) and automatic speech recognition\n(Dorn, 2019; Tatman and Kasten, 2017). POS tag-\nging is a token-level text classiﬁcation task where\neach token is assigned a corresponding word cat-\negory label (see Table 1). It is an enabling tool\nfor NLP applications such as a syntactic parsing,\nnamed entity recognition, corpus linguistics, etc.\nIn this work, we incorporate a human-in-the-loop\nparadigm by directly involving affected (user) com-\nmunities to understand context and word ambigu-\n2https://www.umass.edu/synergy/fall98/\nebonics3.html\narXiv:2206.08978v1  [cs.CL]  3 Jun 2022\nMAE\nInput\nI have never done this before\nOutput\n(I, <PRP>), (have, <VBP>), (never, <RB>), (done, <VBN>), (that, <IN>), (before, <IN>)\nAAE\nInput\nI aint neva did dat befo\nOutput\n(I, <PRP>), (aint, < VBP >), (neva, < NN >), (did, <VBD>)(dat, < JJ >), (befo, < NN >)\nTable 1: An illustrative example of POS tagging of semantically equivalent sentences written in MAE and AAE.\nEach blue and red highlight corresponds to linguistics features of AAE lexical items, and their misclassiﬁed\nNLTK (inferred) tags, respectively.\nities in an attempt to study dialectal language in-\nclusivity in NLP language technologies that are\ngenerally designed for dominant language varieties.\nDacon and Liu (2021) state that,\n“NLP systems aim to [learn] from natural lan-\nguage data, and mitigating social biases become\na compelling matter not only for machine learn-\ning (ML) but for social justice as well.”\nTo address these issues, we aim to empirically\nstudy predictive bias (see Swinton (1981) for deﬁ-\nnition) i.e., if POS tagger models make predictions\ndependent on demographic language features, and\nattempt a dynamic approach in data-collection of\nnon-standard spellings and lexical items. To ex-\namine the behaviors of AAE speakers and their\nlanguage use, we ﬁrst collect variable (morphologi-\ncal and phonological) rules of AAE language fea-\ntures from literature (Labov, 1975; Bailey et al.,\n1998; Green, 2002; Bland-Stewart, 2005; Stew-\nart, 2014; Blodgett et al., 2016; Elazar and Gold-\nberg, 2018; Baugh, 2008; Green, 2014) (see Ap-\npendix C). Then, we employ 5 trained sociolinguist\nAmazon Mechanical Turk (AMT) annotators3 who\nidentify as bi-dialectal dominant AAE speakers to\naddress the issue of lexical, semantic and syntactic\nambiguity of tweets (see Appendix B for annota-\ntion guidelines). Next, we incorporate a human-in-\nthe-loop paradigm by recruiting 20 crowd-sourced\ndiglossic annotators to evaluate AAE language va-\nriety (see Table 2). Finally, we conclude by expand-\ning on the need for dialectal language inclusivity.\n2\nRelated Work\nPrevious works regarding AAE linguistic features\nhave analyzed tasks such as unsupervised do-\nmain adaptation for AAE-like language (Jørgensen\net al., 2016), detecting AAE syntax(Stewart, 2014),\nlanguage identiﬁcation (Blodgett and O’Connor,\n2017), voice recognition and transcription (Dorn,\n3A HIT approval rate ≥95% was used to select 5 bi-\ndialectal AMT annotators between the ages of 18 - 55, and\ncompleted > 10,000 HITs and located within the United\nStates.\n2019),\ndependency parsing (Blodgett et al.,\n2018), dialogue systems (Liu et al., 2020), hate\nspeech/toxic language detection and examining\nracial bias (Sap et al., 2019; Halevy et al., 2021;\nXia et al., 2020; Davidson and Bhattacharya, 2020;\nZhou et al., 2021; Mozafari et al., 2020; Xu et al.,\n2021; Koenecke et al., 2020), and language genera-\ntion (Groenwold et al., 2020). These central works\nare conclusive for highlighting systematic biases of\nnatural language processing (NLP) systems when\nemploying AAE in common downstream tasks.\nAlthough we mention popular works incorporat-\ning AAE, this dialectal continuum has been largely\nignored and underrepresented by the NLP commu-\nnity in comparison to MAE. Such lack of language\ndiversity cases constitutes technological inequality\nto minority groups, for example, by African Ameri-\ncans or BIPOC individuals, and may intensify feel-\nings of disenfranchisement due to monolingualism.\nWe refer to this pitfall as the inconvenient truth i.e.,\n“[I]f the systems show discriminatory behaviors\nin the interactions, the user experience will be\nadversely affected.”\n— Liu et al. (2020)\nTherefore, we deﬁne fairness as the model’s ability\nto correctly predict each tag while performing zero-\nshot transfer via dialectal language inclusivity.\nMoreover, these aforementioned works do not\ndiscuss nor reﬂect on the “role of the speech and\nlanguage technologies in sustaining language use”\n(Labov, 1975; Bird, 2020; Blodgett et al., 2020) as,\n“... models are expected to make predictions with\nthe semantic information rather than with the de-\nmographic group identity information” — Zhang\net al. (2020).\nInteractions with everyday items is increasingly me-\ndiated through language, yet systems have limited\nability to process less-represented dialects such as\nAAE. For example, a common AAE phrase, “I had\na long ass day” would receive a lower sentiment\npolarity score because of the word “ass”, a (noun)\nterm typically classiﬁed as offensive; however, in\nAAE, this term is often used as an emphatic, cumu-\nlative adjective and perceived as non-offensive.\nFigure 1: An illustration of inferred and manually-annotated AAE tag counts from k randomly sampled tweets.\nMotivation: We want to test our hypothesis that\ntraining each model on correctly tagged AAE lan-\nguage features will improve the model’s perfor-\nmance, interpretability, explainability, and usability\nto reduce predictive bias.\n3\nDataset and Annotation\n3.1\nDataset\nWe collect 3000 demographically-aligned African\nAmerican (AA) tweets possessing an average of 7\nwords per tweet from the publicly available Twit-\nterAAE corpus by Blodgett et al. (2016). Each\ntweet is accompanied by inferred geolocation topic\nmodel probabilities from Twitter + Census demo-\ngraphics and word likelihoods to calculate demo-\ngraphic dialect proportions. We aim to minimize\n(linguistic) discrimination by sampling tweets that\npossess over 99% conﬁdence to develop “fair” NLP\ntools that are originally designed for dominant lan-\nguage varieties by integrating non-standardized va-\nrieties. More information about the TwitterAAE\ndataset, including its statistical information, an-\nnotation process, and the link(s) to downloadable\nversions can be found in Appendix A.\n3.2\nPreprocessing\nAs it is common for most words on social me-\ndia to be plausibly semantically equivalent, we\ndenoise each tweet as tweets typically possess un-\nusual spelling patterns, repeated letter, emoticons\nand emojis4. We replace sequences of multiple\n4Emoticons are particular textual features made of punc-\ntuation such as exclamation marks, letters, and/or numbers\nrepeated letters with three repeated letters (e.g.,\nHmmmmmmmm →Hmmm), and remove all punc-\ntuation, “@” handles of users and emojis. Essen-\ntially, we aim to denoise each tweet only to capture\nnon-standard spellings and lexical items more efﬁ-\nciently.\n3.3\nAnnotation\nFirst, we employ off-the-shelf taggers such as\nspacy5 and TwitterNLP6; however, the Natural Lan-\nguage Toolkit (NLTK) (Loper and Bird, 2002) pro-\nvides a more ﬁne-grained Penn Treebank Tagset\n(PTB)7 along with evaluation metrics per tag such\nas F1 score.\nNext, we focus on aggregating\nthe appropriate tags by collecting and manually-\nannotating tags from AAE/slang-speciﬁc dictio-\nnaries to assist the AMT annotators, and later we\ncontrast these aggregated tags with inferred NLTK\nPTB inferred tags. In Figure 1, we display NLTK\ninferred and manually-annotated AAE tags from\nk = 300 randomly sampled tweets.\n• The Online Slang Dictionary (American,\nEnglish, and Urban slang)8 - created in 1996,\nthis is the oldest web dictionary of slang\nwords, neologisms, idioms, aphorisms, jar-\ngon, informal speech, and ﬁgurative usages.\nto create pictorial icons to display an emotion or sentiment\n(e.g., “;)” ⇒winking smile), while emojis are small text-like\npictographs of faces, objects, symbols, etc.\n5https://spacy.io\n6https://github.com/ianozsvald/\nark-tweet-nlp-python\n7https://www.guru99.com/\npos-tagging-chunking-nltk.html\n8http://onlineslangdictionary.com\nTags\nCategory\nAAE Example(s)\nMAE Equivalent(s)\nCC\nCoordinating Conjunction\ndoe/tho, n, bt\nthough, and, but\nDT\nDeterminer\nda, dis, dat\nthe, this, that\nEX\nExistential There\ndea\nthere\nIN\nPreposition/ Conjunction\nfa, cuz/cause, den\nfor, because, than\nJJ\nAdjective\nfoine, hawt\nﬁne, hot\nPRP\nPronoun\nu, dey, dem\nyou, they, them\nPRP$\nPersonal Pronoun\nha\nher\nRB\nAdverb\ntryna, ﬁnna, jus\ntrying to, ﬁxing to, just\nRBR\nAdverb, comparative\nmo, betta, hotta\nmore, better, hotter\nRP\nParticle\nbout, thru\nabout, through\nTO\nInﬁnite marker\nta\nto\nUH\nInterjection\nwassup, ion, ian\nwhat’s up, I don’t\nVBG\nVerb, gerund\nsleepin, gettin\nsleeping, getting\nVBZ\nVerb, 3rd-person present tense\niz\nis\nWDT\nWh-determiner\ndat, wat, wus, wen\nthat, what, what’s, when\nWRB\nWh-adverb\nhw\nhow\nTable 2: Accurately tagged (observed) AAE and English phonological and morphological linguistic feature(s)\naccompanied by their respective MAE equivalent(s).\nThis dictionary possesses more than 24,000\nreal deﬁnitions and tags for over 17,000 slang\nwords and phrases, 600 categories of mean-\ning, word use mapping and aids in addressing\nlexical ambiguity.\n• Word Type9 - an open source POS focused\ndictionary of words based on the Wiktionary10\nproject by Wikimedia11. Researchers have\nparsed Wiktionary and other sources, includ-\ning real deﬁnitions and categorical POS word\nuse cases necessary to address the issue of\nlexical, semantic and syntactic ambiguity.\n3.4\nHuman Evaluation\nAfter an initial training of the AMT annotators,\nwe task each annotator to annotate each tweet\nwith the appropriate POS tags. Then, as a cal-\nibration study we attempt to measure the inter-\nannotator agreement (IAA) using Krippendorff’s\nα.\nBy using NLTK’s (Loper and Bird, 2002)\nnltk.metrics.agreement, we calculate a Krippen-\ndorf’s α of 0.88. We did not observe notable dis-\ntinctions in annotator agreement across the indi-\nvidual tweets. We later randomly sampled 300\nannotated tweets and recruit 20 crowd-sourced an-\nnotators to evaluate AAE language variety. To re-\ncruit 20 diglossic annotators12, we created a volun-\nteer questionnaire with annotation guildlines, and\n9https://wordtype.org/\n10https://www.wiktionary.org\n11https://www.wikimedia.org\n12Note that we did not collect certain demographic infor-\nmation such as gender or race, only basic demographics such\nas age (18-55 years), state and country of residence.\nreleased it on LinkedIn. The full annotation guild-\nlines can be found in Appendix B. Each recruited\nannotator is tasked to judge sampled tweets and\nlist their MAE equivalents to examine contextual\ndifferences of simple, deterministic morphosyntac-\ntic substitutions of dialect-speciﬁc vocabulary in\nstandard English or MAE texts—a reverse study to\nhighlight several varieties of AAE (see Table 2).\n4\nMethodology\nIn this section, we describe our approach to per-\nform a preliminary study to validate the existence\nof predictive bias (Elazar and Goldberg, 2018; Shah\net al., 2020) in POS models. We ﬁrst introduce the\nPOS tagging, and then propose two ML sequence\nmodels.\n4.1\nPart-of-Speech (POS) Tagging\nWe consider POS tagging as it represents word\nsyntactic categories and serves as a pre-annotation\ntool for numerous downstream tasks, especially\nfor non-standardized English language varieties\nsuch as AAE (Zampieri et al., 2020). Common\ntags include prepositions, adjective, pronoun, noun,\nadverb, verb, interjection, etc., where multiple POS\ntags can be assigned to particular words due to\nsyntactic structural patterns. This can also lead to\nmisclassiﬁcation of non-standardized words that\ndo not exist in popular pre-trained NLP models.\n4.2\nModels\nWe propose to implement two well known sequence\nmodeling algorithms, namely a Bidirectional\nLong Short Term Memory (Bi-LSTM) network,\na deep neutral network (DNN) (Hochreiter and\nSchmidhuber, 1997; Graves and Schmidhuber,\n2005) that has been used for POS tagging (Ling\net al., 2015; Plank et al., 2016), and a Conditional\nRandom Field (CRF) (Lafferty et al.) typically\nused to identify entities or patterns in texts by\nexploiting previously learned word data.\nTaggers: First, we use NLTK (Loper and Bird,\n2002) for automatic tagging; then, we pre-deﬁne\na feature function for our CRF model where we\noptimized its L1 and L2 regularization parameters\nto 0.25 and 0.3, respectively. Later, we train our\nBi-LSTM network for 40 epochs with an Adam op-\ntimizer, and a learning rate of 0.001. Note that each\nmodel would be accompanied by error analysis for\na 70-30 split of the data with 5-fold cross-validation\nto obtain model classiﬁcation reports, for metrics\nsuch as precision, recall and F1-score.\n5\nOperationalization of AAE as an\nEnglish Language Variety\nAs (online) AAE can incorporate non-standardized\nspellings and lexical items, there is an active need\nfor a human-in-the-loop paradigm as humans pro-\nvide various forms of feedback in different stages\nof workﬂow. This can signiﬁcantly improve the\nmodel’s performance, interpretability, explainabil-\nity, and usability. Therefore, crowd-sourcing to\ndevelop language technologies that consider who\ncreated the data will lead to the inclusion of di-\nverse training data, and thus, decrease feelings\nof marginalization. For example, CORAAL13, is\nan online resource that features AAL text data,\nrecorded speech data, etc., into new and existing\nNLP technologies, AAE speakers can extensively\ninteract with current NLP language technologies.\nConsequently, to quantitatively and qualitatively\nensure fairness in NLP tools, artiﬁcial intelligence\n(AI) and NLP researchers need to go beyond evalu-\nation measures, word deﬁnitions and word order to\nassess AAE on a token-level to better understand\ncontext, culture and word ambiguities. We encour-\nage both AI and NLP practitioners to prioritize col-\nlecting a set of relevant labeled training data with\nseveral examples of informal phrases, expressions,\nidioms, and regional-speciﬁc varieties. Speciﬁcally,\nin models intended for broad use such as sentiment\nanalysis by partnering with low-resource and di-\n13https://oraal.uoregon.edu/coraal\nalectal communities to develop impactful speech\nand language technologies for dialect continua such\nas AAE to minimize further stigmatization of an\nalready stigmatized minority group.\n6\nConclusion\nThroughout this work, we highlight the need to\ndevelop language technologies for such varieties,\npushing back against potentially discriminatory\npractices (in many cases, discriminatory through\noversight more than malice). Our work calls for\nNLP researchers to consider both social and racial\nhierarchies sustained or intensiﬁed by current com-\nputational linguistic research. By shifting towards\na human-in-the-loop paradigm to conduct deep\nmulti-layered dialectal language analysis of AAE\nto counter-attack erasure and several forms of bi-\nases such as selection bias, label bias, model over-\nampliﬁcation, and semantic bias (see Shah et al.\n(2020) for deﬁnitions) in NLP.\nWe hope our dynamic approach can encourage\npractitioners, researchers and developers for AAE\ninclusive work, and that our contributions can pave\nthe way for normalizing the use of a human-in-the-\nloop paradigm both to obtain new data and create\nNLP tools to better comprehend underrepresented\ndialect continua and English language varieties. In\nthis way, NLP community can revolutionize the\nways in which humans and technology cooperate\nby considering certain demographic attributes such\nas culture, background, race and gender when de-\nveloping and deploying NLP models.\n7\nLimitations And Ethical\nConsiderations\nAll authors must warrant that increased model per-\nformance for non-standard varieties such as un-\nderrepresented dialects, non-standard spellings or\nlexical items in NLP systems can potentially en-\nable automated discrimination. In this work, we\nsolely attempt to highlight the need for dialectal\ninclusivity for the development of impactful speech\nand language technologies in the future, and do not\nintend for increased feelings of marginalization of\nan already stigmatized community.\n8\nAcknowledgements\nThe authors would like to thank Shaylnn L.A.\nCrum-Dacon, Serena Lotreck, Brianna Brown and\nKenia Segura Ab´a, Jyothi Kumar and Shin-Han\nShiu for their support and the anonymous review-\ners for their constructive comments.\nReferences\nGuy Bailey, John Baugh, Salikoko S. Mufwene, and\nJohn R. Rickford. 1998. African-American English:\nStructure, History and Use (1st ed.). Routledge.\nJohn Baugh. 2008.\nLinguistic discrimination.\nIn 1.\nHalbband, pages 709–714. De Gruyter Mouton.\nSteven Bird. 2020.\nDecolonising speech and lan-\nguage technology. In Proceedings of the 28th Inter-\nnational Conference on Computational Linguistics,\npages 3504–3519, Barcelona, Spain (Online). Inter-\nnational Committee on Computational Linguistics.\nLinda M. Bland-Stewart. 2005.\nDifference or\ndeﬁcit in speakers of african american english?\nhttps://leader.pubs.asha.org/doi/10.\n1044/leader.FTR1.10062005.6.\nSu Lin Blodgett, Solon Barocas, Hal Daum´e III, and\nHanna Wallach. 2020.\nLanguage (technology) is\npower: A critical survey of “bias” in NLP. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5454–\n5476, Online. Association for Computational Lin-\nguistics.\nSu Lin Blodgett, Lisa Green, and Brendan O’Connor.\n2016.\nDemographic dialectal variation in social\nmedia: A case study of African-American English.\nIn Proceedings of the 2016 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1119–1130, Austin, Texas. Association for Compu-\ntational Linguistics.\nSu Lin Blodgett and Brendan O’Connor. 2017. Racial\ndisparity in natural language processing: A case\nstudy of social media african-american english.\nCoRR, abs/1707.00061.\nSu Lin Blodgett, Johnny Wei, and Brendan O’Connor.\n2018.\nTwitter Universal Dependency parsing for\nAfrican-American and mainstream American En-\nglish. In Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1415–1425, Melbourne,\nAustralia. Association for Computational Linguis-\ntics.\nHerbert H. Clark and Michael F. Schober. 1992. Ask-\ning questions and inﬂuencing answers. In Russell\nSage Foundation.\nJamell Dacon and Haochen Liu. 2021.\nDoes gen-\nder matter in the news? detecting and examining\ngender bias in news articles.\nIn Companion Pro-\nceedings of the Web Conference 2021, WWW ’21,\npage 385–392, New York, NY, USA. Association for\nComputing Machinery.\nThomas Davidson and Debasmita Bhattacharya. 2020.\nExamining racial bias in an online abuse corpus with\nstructural topic modeling. CoRR, abs/2005.13041.\nRachel Dorn. 2019. Dialect-speciﬁc models for auto-\nmatic speech recognition of African American Ver-\nnacular English.\nIn Proceedings of the Student\nResearch Workshop Associated with RANLP 2019,\npages 16–20, Varna, Bulgaria. INCOMA Ltd.\nYanai Elazar and Yoav Goldberg. 2018. Adversarial\nremoval of demographic attributes from text data.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n11–21, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nAnjalie Field, Su Lin Blodgett, Zeerak Waseem, and\nYulia Tsvetkov. 2021. A survey of race, racism, and\nanti-racism in NLP. CoRR, abs/2106.11410.\nAlex Graves and J¨urgen Schmidhuber. 2005. Frame-\nwise phoneme classiﬁcation with bidirectional lstm\nand other neural network architectures. Neural Net-\nworks, 18(5):602–610. IJCNN 2005.\nJonathon Green. 2014. The vulgar tongue: Green’s his-\ntory of slang. Oxford University Press, New York,\nUSA.\nLisa J. Green. 2002. African American English: A Lin-\nguistic Introduction. Cambridge University Press.\nSophie Groenwold, Lily Ou, Aesha Parekh, Samhita\nHonnavalli,\nSharon\nLevy,\nDiba\nMirza,\nand\nWilliam Yang Wang. 2020.\nInvestigating African-\nAmerican Vernacular English in transformer-based\ntext generation. In Proceedings of the 2020 Confer-\nence on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 5877–5883, Online.\nAssociation for Computational Linguistics.\nMatan Halevy, Camille Harris, Amy Bruckman, Diyi\nYang, and Ayanna Howard. 2021. Mitigating racial\nbiases in toxic language detection with an equity-\nbased ensemble framework. New York, NY, USA.\nAssociation for Computing Machinery.\nSepp Hochreiter and J¨urgen Schmidhuber. 1997.\nLong\nshort-term\nmemory.\nNeural\nComput.,\n9(8):1735–1780.\nTaylor Jones. 2015. Toward a description of african\namerican vernacular english dialect regions using\n“black twitter”. American Speech, 90:403–440.\nAnna Jørgensen, Dirk Hovy, and Anders Søgaard. 2016.\nLearning a POS tagger for AAVE-like language. In\nProceedings of the 2016 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 1115–1120, San Diego, California. Associa-\ntion for Computational Linguistics.\nSharese King. 2020. From african american vernacu-\nlar english to african american language: Rethinking\nthe study of race and language in african americans’\nspeech.\nAnnual Review of Linguistics, 6(1):285–\n300.\nAllison Koenecke, Andrew Nam, Emily Lake, Joe\nNudell, Minnie Quartey, Zion Mengesha, Connor\nToups, John R. Rickford, Dan Jurafsky, and Sharad\nGoel. 2020. Racial disparities in automated speech\nrecognition. Proceedings of the National Academy\nof Sciences, 117(14):7684–7689.\nWilliam Labov. 1975. Ralph fasold, tense marking in\nblack english: a linguistic and social analysis. wash-\nington, d.c.: Center for applied linguistics, 1972. pp.\n254. Language in Society, 4(2):222–227.\nJohn Lafferty, Andrew McCallum, and Fernando CN\nPereira.\nConditional random ﬁelds: Probabilistic\nmodels for segmenting and labeling sequence data.\nWang Ling, Chris Dyer, Alan W Black, Isabel Tran-\ncoso, Ram´on Fermandez, Silvio Amir, Lu´ıs Marujo,\nand Tiago Lu´ıs. 2015.\nFinding function in form:\nCompositional character models for open vocabu-\nlary word representation. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1520–1530, Lisbon, Portu-\ngal. Association for Computational Linguistics.\nHaochen Liu, Jamell Dacon, Wenqi Fan, Hui Liu, Zitao\nLiu, and Jiliang Tang. 2020. Does gender matter?\ntowards fairness in dialogue systems. In Proceed-\nings of the 28th International Conference on Com-\nputational Linguistics, pages 4403–4416, Barcelona,\nSpain (Online). International Committee on Compu-\ntational Linguistics.\nEdward Loper and Steven Bird. 2002. NLTK: The nat-\nural language toolkit. In Proceedings of the ACL-02\nWorkshop on Effective Tools and Methodologies for\nTeaching Natural Language Processing and Com-\nputational Linguistics, pages 63–70, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nMarzieh Mozafari, Reza Farahbakhsh, and No¨el Crespi.\n2020.\nHate speech detection and racial bias miti-\ngation in social media based on bert model. PLOS\nONE, 15:1–26.\nBarbara Plank, Anders Søgaard, and Yoav Goldberg.\n2016. Multilingual part-of-speech tagging with bidi-\nrectional long short-term memory models and auxil-\niary loss. In Proceedings of the 54th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers), pages 412–418, Berlin,\nGermany. Association for Computational Linguis-\ntics.\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi,\nand Noah A. Smith. 2019. The risk of racial bias\nin hate speech detection.\nIn Proceedings of the\n57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 1668–1678, Florence,\nItaly. Association for Computational Linguistics.\nDeven Santosh Shah, H. Andrew Schwartz, and Dirk\nHovy. 2020. Predictive biases in natural language\nprocessing models: A conceptual framework and\noverview. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 5248–5264, Online. Association for Computa-\ntional Linguistics.\nIan Stewart. 2014. Now we stronger than ever: African-\nAmerican English syntax in Twitter.\nIn Proceed-\nings of the Student Research Workshop at the 14th\nConference of the European Chapter of the Asso-\nciation for Computational Linguistics, pages 31–\n37, Gothenburg, Sweden. Association for Computa-\ntional Linguistics.\nSpencer S. Swinton. 1981. Predictive bias in graduate\nadmissions tests. ETS Research Report Series, 1981.\nRachael Tatman and Conner Kasten. 2017. Effects of\nTalker Dialect, Gender & Race on Accuracy of Bing\nSpeech and YouTube Automatic Captions. In Proc.\nInterspeech 2017, pages 934–938.\nMengzhou Xia, Anjalie Field, and Yulia Tsvetkov.\n2020. Demoting racial bias in hate speech detection.\nIn Proceedings of the Eighth International Work-\nshop on Natural Language Processing for Social Me-\ndia, pages 7–14, Online. Association for Computa-\ntional Linguistics.\nAlbert Xu, Eshaan Pathak, Eric Wallace, Suchin Guru-\nrangan, Maarten Sap, and Dan Klein. 2021. Detoxi-\nfying language models risks marginalizing minority\nvoices. In Proceedings of the 2021 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 2390–2397, Online. Association for\nComputational Linguistics.\nMarcos Zampieri, Preslav Nakov, and Yves Scherrer.\n2020. Natural language processing for similar lan-\nguages, varieties, and dialects: A survey. Natural\nLanguage Engineering, 26(6):595–612.\nGuanhua Zhang, Bing Bai, Junqi Zhang, Kun Bai, Con-\nghui Zhu, and Tiejun Zhao. 2020. Demographics\nshould not be the reason of toxicity: Mitigating\ndiscrimination in text classiﬁcations with instance\nweighting. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4134–4145, Online. Association for Computa-\ntional Linguistics.\nXuhui Zhou, Maarten Sap, Swabha Swayamdipta,\nYejin Choi, and Noah Smith. 2021. Challenges in au-\ntomated debiasing for toxic language detection. In\nProceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume, pages 3143–3155, Online.\nAssociation for Computational Linguistics.\nA\nDataset Details\nOur collected dataset is demographically-aligned\non AAE in correspondence on the dialectal tweet\ncorpus by Blodgett et al. (2016).\nThe Twitter-\nAAE corpus is publicly available and can be down-\nloaded from link14. Blodgett et al. (2016) uses a\nmixed-membership demographic language model\nwhich calculates demographic dialect proportions\nfor a text accompanied by a race attribute—African\nAmerica, Hispanic, Other, and White in that order.\nThe race attribute is annotated by a jointly inferred\nprobabilistic topic model based on the geolocation\ninformation of each user and tweet. Given that\ngeolocation information (residence) is highly as-\nsociated with the race of a user, the model can\nmake accurate predictions. However, there a a low\nnumber messages that possess a posterior proba-\nbilities of NaN as these are messages that have no\nin-vocabulary words under the model.\nB\nAnnotator Annotation Guidelines\nYou will be given demographically-aligned African\nAmerican tweets, in which we refer to these tweets\nas sequences. As a dominant AAE speaker, who\nidentiﬁes as bi-dialectal, your task is to correctly\nidentify the context of each word in a given se-\nquence in hopes to address the issues of lexical,\nsemantic and syntactic ambiguity.\n1. Are you a dominant AAE speaker?\n2. If you responded “yes” above, are you bi-\ndialectal?\n3. If you responded “yes”, given a sequence,\nhave you ever said, seen or used any of these\nwords given the particular sequence?\n4. Given a sequence, what are the SAE equiva-\nlents to the identiﬁed non-SAE terms?\n5. For morphological and phonological (dialec-\ntal) purposes, are these particular words spelt\nhow would you say or use them?\n6. If you responded “no” above, can you pro-\nvide a different spelling along with its SAE\nequivalent?\n14http://slanglab.cs.umass.edu/\nTwitterAAE/\nB.1\nAnnotation Protocol\n1. What is the context of each word given the\nparticular sequence?\n2. Given NLTK’s Penn Treebank Tagset15, what\nis the most appropriate POS tag for each word\nin the given sequence?\nB.2\nHuman evaluation of POS tags Protocol\n1. Given the tagged sentence, are there any mis-\nclassiﬁed tags?\n2. If you responded “yes” above, can you pro-\nvide a different POS tag, and state why it is\ndifferent?\nC\nVariable Rules Examples\nIn this section we present a few examples of sim-\nple, deterministic phonological and morphological\nlanguage features or current variable rules which\nhighlight several regional varieties of AAE which\ntypically attain misclassiﬁed POS tags. Please note\nthat a more exhaustive list of these rules is still be-\ning constructed as this work is still ongoing. Below\nare a few variable cases (MAE →AAE), some of\nwhich may have been previously shown in Table 2:\n1. Consonant (‘t’) deletion (Adverb case) : e.g.\n“just” →“jus”; “must” →“mus”\n2. Contractive negative auxiliary verbs replace-\nment: “doesn’t” →“don’t”\n3. Contractive (’re) loss: e.g. “you’re” →“you”;\n“we’re” →“we”\n4. Copula deletion: Deletion of the verb “be”\nand its variants, namely “is” and “are” e.g.\n“He is on his way” →“He on his way”; “You\nare right” →“You right”\n5. Homophonic word replacement (Pronoun\ncase): e.g. “you’re” →“your”\n6. Indeﬁnite pronoun replacement: e.g. “anyone”\n→“anybody”;\n7. Interdental fricative loss (Coordinating Con-\njuction case): e.g. “this” →“dis”; ‘that’ →\n‘dat”; “the” →“da”\n15https://www.guru99.com/\npos-tagging-chunking-nltk.html\n8. Phrase reduction (present/ future tense) ⇒\nword (Adverb case): e.g. “what’s up” →“was-\nsup”; “ﬁxing to” →“ﬁnna”\n9. Present tense possession replacement: e.g.\n“John has two apples” →“John got two ap-\nples”; “The neighbors have a bigger pool” →\n“The neighbors got a bigger pool”\n10. Remote past “been” + completive (‘done’):\n“I’ve already done that” →“I been done that”\n11. Remote past “been” + completive (‘did’):\n“She already did that” →“She been did that”\n12. Remote past “been” + Present tense posses-\nsion replacement: “I already have food” →\n“I been had food”; “You already have those\nshoes” →“You been got those shoes”\n13. Term-fragment deletion: e.g. “brother” →\n“bro”; “sister” →“sis”; “your” →“ur”; “sup-\npose” →“pose”; “more” →“mo”\n14. Term-fragment replacement: “something” →\n“sumn”; “through” →“thru”; “for” →“fa”;\n“nothing” →“nun”\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2022-06-03",
  "updated": "2022-06-03"
}