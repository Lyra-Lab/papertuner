{
  "id": "http://arxiv.org/abs/2207.02727v2",
  "title": "An Unsupervised STDP-based Spiking Neural Network Inspired By Biologically Plausible Learning Rules and Connections",
  "authors": [
    "Yiting Dong",
    "Dongcheng Zhao",
    "Yang Li",
    "Yi Zeng"
  ],
  "abstract": "The backpropagation algorithm has promoted the rapid development of deep\nlearning, but it relies on a large amount of labeled data and still has a large\ngap with how humans learn. The human brain can quickly learn various conceptual\nknowledge in a self-organized and unsupervised manner, accomplished through\ncoordinating various learning rules and structures in the human brain.\nSpike-timing-dependent plasticity (STDP) is a general learning rule in the\nbrain, but spiking neural networks (SNNs) trained with STDP alone is\ninefficient and perform poorly. In this paper, taking inspiration from\nshort-term synaptic plasticity, we design an adaptive synaptic filter and\nintroduce the adaptive spiking threshold as the neuron plasticity to enrich the\nrepresentation ability of SNNs. We also introduce an adaptive lateral\ninhibitory connection to adjust the spikes balance dynamically to help the\nnetwork learn richer features. To speed up and stabilize the training of\nunsupervised spiking neural networks, we design a samples temporal batch STDP\n(STB-STDP), which updates weights based on multiple samples and moments. By\nintegrating the above three adaptive mechanisms and STB-STDP, our model greatly\naccelerates the training of unsupervised spiking neural networks and improves\nthe performance of unsupervised SNNs on complex tasks. Our model achieves the\ncurrent state-of-the-art performance of unsupervised STDP-based SNNs in the\nMNIST and FashionMNIST datasets. Further, we tested on the more complex CIFAR10\ndataset, and the results fully illustrate the superiority of our algorithm. Our\nmodel is also the first work to apply unsupervised STDP-based SNNs to CIFAR10.\nAt the same time, in the small-sample learning scenario, it will far exceed the\nsupervised ANN using the same structure.",
  "text": "An Unsupervised STDP-based Spiking Neural Network\nInspired By Biologically Plausible Learning\nRules and Connections\nYiting Donga,c, Dongcheng Zhaoc, Yang Lib,c, Yi Zenga,b,c,d,e\naSchool of Future Technology, University of Chinese Acadamy of Sciences\nbSchool of Artiﬁcial Intelligence, University of Chinese Academy of Sciences, Beijing\ncResearch Center for Brain-Inspired Intelligence, Institute of Automation,\nChinese Academy of Sciences (CAS), Beijing\ndCenter for Excellence in Brain Science and Intelligence Technology,\nChinese Academy of Sciences (CAS), Beijing\neNational Laboratory of Pattern Recognition, Institute of Automation,\nChinese Academy of Sciences (CAS), Beijing\nAbstract\nThe backpropagation algorithm has promoted the rapid development of\ndeep learning, but it relies on a large amount of labeled data and still has\na large gap with how humans learn. The human brain can quickly learn\nvarious conceptual knowledge in a self-organized and unsupervised manner,\naccomplished through coordinating various learning rules and structures in\nthe human brain. Spike-timing-dependent plasticity (STDP) is a general\nlearning rule in the brain, but spiking neural networks (SNNs) trained with\nSTDP alone is ineﬃcient and perform poorly. In this paper, taking inspiration\nfrom short-term synaptic plasticity, we design an adaptive synaptic ﬁlter and\nintroduce the adaptive spiking threshold as the neuron plasticity to enrich\nthe representation ability of SNNs. We also introduce an adaptive lateral\ninhibitory connection to adjust the spikes balance dynamically to help the\nnetwork learn richer features. To speed up and stabilize the training of\nunsupervised spiking neural networks, we design a samples temporal batch\nSTDP (STB-STDP), which updates weights based on multiple samples and\nmoments. By integrating the above three adaptive mechanisms and STB-\n⋆Yiting Dong, Dongcheng Zhao contributed equally to this work\nEmail address: yi.zeng@ia.ac.cn (Yi Zeng)\nPreprint submitted to Journal of Neural Networks\nApril 25, 2023\narXiv:2207.02727v2  [cs.NE]  22 Apr 2023\nSTDP, our model greatly accelerates the training of unsupervised spiking\nneural networks and improves the performance of unsupervised SNNs on\ncomplex tasks. Our model achieves the current state-of-the-art performance of\nunsupervised STDP-based SNNs in the MNIST and FashionMNIST datasets.\nFurther, we tested on the more complex CIFAR10 dataset, and the results\nfully illustrate the superiority of our algorithm. Our model is also the ﬁrst\nwork to apply unsupervised STDP-based SNNs to CIFAR10. At the same\ntime, in the small-sample learning scenario, it will far exceed the supervised\nANN using the same structure.\nKeywords:\nSpiking Neural Network, Unsupervised, Plasticity Learning Rule, Brain\nInspired Connection\n1. Introduction\nSimulating and designing a machine that thinks like a human is the\nultimate goal of artiﬁcial intelligence. The vast majority of deep learning\nmodels rely on backpropagation algorithms, which require a large amount\nof labeled data to adjust parameters. However, obtaining labeled data is\nexpensive. The backpropagation algorithm has a series of constraints, such\nas weight transport problem Lillicrap et al. (2016), and requires accurate\ngradient derivation, which is quite diﬀerent from the learning process in the\nhuman brain. The human brain learns rapidly by relying on unsupervised\nlocal learning rules. Meanwhile, the traditional artiﬁcial neurons are far from\nthe real spiking neurons which are rich in spatiotemporal dynamics Maass\n(1997). Spiking neurons receive input current and accumulate membrane\npotential, transmitting information through discrete spike sequences when\nthe membrane potential exceeds the threshold. The spiking neural networks\n(SNNs) are more biologically plausible and energy eﬃcient and have been\nwidely used in various ﬁelds Fang et al. (2021); Zhao et al. (2022, 2021).\nTraining an eﬃcient and robust spiking neural network is a critical problem\nmany researchers have been paying attention to. Due to the non-diﬀerentiable\ncharacteristics of the spiking neural network, it is challenging to directly use\nthe backpropagation algorithm for training, which signiﬁcantly restricts the\ndevelopment of the SNNs. Many researchers take inspiration from the learning\nprocess in the human brain and design some biologically plausible learning\nrules to train SNNs. The synaptic plasticity of neurons is the neurological\n2\nAdaptive Lateral \nInhibition Connection\nASF\nAdaptive \nSynaptic Filter\nAdaptive \nThreshold Balance\nConv\nPooling\nSpikeNorm\nFC\nVoting\nFigure 1: The backbone of our model, which introduces the adaptive synaptic ﬁlter, the\nadaptive threshold balance, and the adaptive lateral inhibitory connection to improve the\ninformation transmission and feature extraction of STDP-based SNNs.\nbasis of learning and memory in the brain Bi and Poo (1998). Spike Timing\nDependent Plasticity (STDP) is a common learning rule that exists in multiple\nareas of the brain and plays a vital role in the brain’s perception and learning\nprocess. STDP inﬂuences the strength of synapses through the temporal\nrelationship of pre- and postsynaptic spikes.\nSNNs trained based on STDP still perform poorly due to the local opti-\nmization rule without global guided error compared with the backpropagation\nalgorithm. This will lead to a lack of coordination and self-organization within\nand between layers of the model. Diﬀerent parameter settings can easily\nlead to disordered spikes, making it challenging to transfer useful informa-\ntion. The human brain is not regulated by a single learning ruleAbbott and\nRegehr (2004). The brain dynamically coordinates multiple learning rules\nand connections for rapid learning and inference. In mammals, short-term\nsynaptic plasticity (STP) is another essential learning rule. It lasts for a\nshort time and adaptively controls the activity of diﬀerent ﬁring frequencies\nto regulate the information transmission better in a diﬀerent layerZucker\nand Regehr (2002); Citri and Malenka (2008); Tauﬀer and Kumar (2021).\nInspired by this, this paper designs an adaptive synaptic ﬁlter to help amplify\nthe diﬀerence of the input current for better information transmission. Also,\nthe adaptive spiking threshold is designed as the neuron plasticity to reduce\nthe information loss during transmission. The adaptive lateral inhibition\n3\nconnection of diﬀerent input samples is introduced to the spiking neurons\nof the same layer, which improves the self-organization ability of the model\nand enables the network to learn more abundant representations. Also, this\npaper extends the original STDP with sample temporal batched processing,\nwhich signiﬁcantly accelerates the training process. To summarize, our key\ncontributions are:\n1. We propose the adaptive synaptic ﬁlter, adaptive lateral inhibitory\nconnection, and the adaptive threshold balance to assist the training\nof unsupervised STDP-based SNNs, which signiﬁcantly improves the\nrepresentation ability of SNNs, alleviates the problem of repetitive\nfeatures, and compensates for the input-output mismatch between\nlayers.\n2. We extend the original STDP by integrating multiple samples and\ndiﬀerent moments into a batch (STB-STDP), which signiﬁcantly speeds\nup and stabilizes the training process.\n3. Experimental results on MNIST and FashionMNIST show that our\nalgorithm achieves the state-of-the-art performance of unsupervised\nspiking neural networks. At the same time, the performance of SNNs\nin complex scenarios is improved, allowing unsupervised SNNs to show\nexcellent performance in CIFAR10 and small-sample training scenarios.\n2. Related Work\nThe training of spiking neural networks is currently divided into three cate-\ngories, conversion-based, backpropagation-based, and brain-inspired algorithm\nlearning rules based.\nBy exploring the relationship between the spike activation and the artiﬁcial\nactivation function, the real value of the artiﬁcial neural networks (ANNs) can\nbe approximated to the average ﬁring rates of SNNs. As a result, an alternative\nway is explored to add constraints on the weights of well-trained ANNs to\nconvert them to SNNs Diehl et al. (2015); Li et al. (2021); Han and Roy (2020).\nAlthough these converted methods make SNNs show excellent performance in\nmore complex network structures and tasks, it does not fundamentally solve\nthe training problems of SNNs. Other researchers introduce the surrogate\ngradient to make the backpropagation algorithm can be directed used in the\ntraining of SNN Lee et al. (2016); Wu et al. (2018, 2019); Shen et al. (2021).\nHowever, as said before, the backpropagation algorithm is implausible and\nfar from how the brain learns.\n4\nSince STDP is a ubiquitous learning rule in the brain, many researchers\ntrained spiking neural networks based on STDP. Querlioz et al. (2013) tried\na two-layer fully connected SNN using a simpliﬁed unsupervised approach\nof STDP. Diehl and Cook (2015) used an unsupervised STDP method with\ntwo layers of activation and inhibition. Notably, despite two layers, only one\nhas trainable parameters. Kheradpisheh et al. (2018) used hand-designed\nDoG ﬁlters for feature extraction, STDP to train convolutional layers, and\nSVM as the classiﬁer. The convolution kernels of each layer are designed\nindividually. Only the training in the intermediate convolutional layers is\nunsupervised. However, due to the local optimization property of STDP, it\ntends to perform poorly on deep networks, so many researchers have tried\nto introduce supervisory signals to guide STDP tuning based on the global\nfeedback connections Zhao et al. (2020), equilibrium propagation Zhang et al.\n(2018), backpropagation Liu et al. (2021), and the dopamine-modulated Hao\net al. (2020). Some methods combine STDP with backpropagation for hybrid\ntraining. Such as Liu et al. (2021) and Lee et al. (2018a), they both ﬁrst\nperformed STDP training to extract weights with better generalization. The\ntraining of supervised backpropagation is then performed to obtain better\nperformance.\nLateral inhibition is usually used to help neurons achieve mutual com-\npetition mechanism Heitzler and Simpson (1991); Amari (1977); Blakemore\net al. (1970). The lateral inhibition mechanism has been tried to be added to\nthe training of spiking neural networks. Diehl and Cook (2015) tried to use\na static lateral inhibition mechanism, so that the ﬁring neurons can inhibit\nother non-spiking neurons by reducing the membrane potential. Cheng et al.\n(2020) help the spiking neural network to have stronger noise-robustness by\nintroducing lateral inhibitory connections.\n3. Backgrounds\n3.1. Neuron Model\nThe leaky integral-and-ﬁre (LIF) neurons Dayan and Abbott (2005) are\nthe most commonly used computational model in the SNNs. LIF neurons\nreceive the pre-synaptic spikes as the input currents and accumulate them on\nthe decayed membrane potential. When the membrane potential reaches the\nthreshold, the neuron releases a spike with the membrane potential reset to\nthe resting potential ureset. Here we set ureset = 0. The details are shown in\n5\nEquation 1:\ns = 0\nτ du\ndt = −u + Ri,\nif u < uthresh\ns = 1\nu = 0,\nif u ≥uthresh\n(1)\nwhere u is the membrane potential. uthresh is the threshold for this neuron.\nτ is the time constant. i is the input current. We denote i = P\nj\nwijsj. s is\nthe spikes from pre-synaptic neuron. wij is the strength of synapses. R is\nresistance.\nIn order to facilitate the calculation, we convert the diﬀerential formula\ninto a discrete representation as shown in Equation 2, where C is capacitance,\nwhich we set equal to 1.\ns(t) = 0\nu(t) = (1 −1\nτ )u(t−1) + 1\nC i(t),\nif u(t) < u(t)\nthresh\ns(t) = 1\nu(t) = 0,\nif u(t) ≥u(t)\nthresh\n(2)\nwhere u(t) is the membrane potential at the time t. u(t)\nthresh is the threshold\nfor this neuron at the time t. i(t) is the input current at the time t.\n3.2. STDP Algorithm\nIn this paper, we improved the commonly used unilateral STDP. For\nconventional STDP, as seen in Equation 3, the modiﬁcation of weights is\ndetermined by the time interval of the pre- and post-synaptic spikes. The\nlarger the time gap, the less correlated the two spikes are and the less aﬀected\nthe synaptic weights.\n∆wj =\nN\nX\nf=1\nN\nX\nn=1\nW(tf\ni −tn\nj )\nW(∆t) = A+e\n−∆t\nτ+ −xoﬀset\nif ∆t > 0\n(3)\nwhere ∆wj is the modiﬁcation of the synapse j, W(∆t) is the STDP\nfunction. For unilateral STDP, focus only on the presynaptic spikes before the\nﬁring of the postsynaptic spikes, which makes the synapse strength continue\nto grow Lee et al. (2018a). So xoﬀset is to determine whether the modiﬁcation\nare potentiated or depressed.\n6\nFor the eﬃcient implementation, we take another form of STDP using\neligibility traces Lee et al. (2018a); Izhikevich (2007); Zenke et al. (2015). As\nshown in the Equation 4 , x(t)\ntrace accumulates presynaptic spikes and gradually\ndecays over time.\n∆wj = x(t)\ntrace −xoﬀset\nif xpostspike = 1\nxtrace\n(t) = λ+x(t−1)\ntrace + xprespike\n(4)\nWhen the neuron ﬁres at time t,xpostspike = 1 . When recieves a spike at time\nt, xprespike = 1. We denote λ+ = 1 −\n1\nτ+.\nIn experiments, we improve STDP and propose a sample-temporal batch\nSTDP (STB-STDP) algorithm. More details are in section 4.4.\n4. Proposed Algorithms\nTo be more explicit about the problem we focus on, we built a one-\nlayer convolutional spiking neural network and used the STDP algorithm,\ndescribed in Equation 4 , to train in MNIST dataset until convergence. This\nconvolutional layer consists of a 5x5 convolution kernel with 20 channels.\nAs shown in Figure 2(a), we show the synaptic weights of the convolutional\nlayers after training. It can be observed that a large number of repeated\nconvolution kernels appear. The same convolution kernel features are boxed in\nthe same color. Repeated convolution kernels will aﬀect the eﬀective feature\nrepresentation Glorot and Bengio (2010).\nOn the other hand, neurons from diﬀerent layers may also work in a\ndisordered way. Since the algorithm lacks a global guided signal, the neuron\ncan not judge whether it is a suitable ﬁring rate. Therefore This will cause\nthe adjacent next layer of neurons to receive too high or too low input current,\nwhich makes the last layer’s neurons ﬁre unstably. As shown in Figure 2(b),\nThe membrane potential will take longer to build up if the input current is\ntoo small, leading to delays in the transmission of information. When the\nﬁring frequency is signiﬁcant, the neuron ﬁres nearly all the time, which will\ndamage the eﬀective information representation. Diﬀerent parameter settings\ncan easily lead to disordered spikes, making it challenging to transfer useful\ninformation.\nTo alleviate the above problems, we propose three adaptive algorithms.\nTo address the problem of repetition of neuron features within a layer, we\n7\nI >> uthreshold\nlayer n\nlayer n+1\nt\nI << uthreshold\n(a)\n1       2        3       4       5\n(b)\nthe weights of convolution layer\ninput currents affect frequencies \n1\n2\n3\n4\nfiring frequency\nhigh\nlow \nFigure 2: (a) Features of the convolutional layers trained with only STDP, the same\nfeatures are marked with the same color. (b) SNNs trained only with STDP cannot\nproperly regulate the information transmitted by the spikes, which will lead to sparse or\nfrequent spikes.\npropose an Adaptive Lateral Inhibitory Connection (ALIC), diﬀerent from\nstatic lateral inhibition Diehl and Cook (2015), which provides a way to\ncoordinate neurons by automatically selecting those that need to be inhibited.\nNext, we use Adaptive Threshold Balance (ATB) to solve the mismatching of\ninput and output ranges between adjacent layers. In order to make the spikes\nﬁring more stable, we designed Adaptive Synaptic Filter (ASF) inspired by\nSTP. Finally, we propose STB-STDP, which combines spatial and temporal\ninformation into a single batch.\n4.1. Adaptive Lateral Inhibitory Connection\nWe introduce lateral inhibition to solve the problem of neurons in the\nsame layer tending to have the same weights. Interaction between neurons is\nenabled by lateral inhibition, which allows ﬁring neurons to dominate this\ninput by inhibiting the ﬁring of other neurons. The dominant neuron is more\nlikely to experience learning according to STDP, and sensitivity to its input\ngradually increases. Conversely, non-dominant neurons will not be sensitive to\nthis input. This prevents neurons from convergent towards the same weight.\nstatic lateral inhibition, however, is usually a constant set manually.\ninh(t)\nij = α\n(5)\nwhere inh(t)\nij denotes the inhibition received by the neuron i, j. α is a parame-\nter deﬁning the degree of inhibition. The same inhibiting degree is maintained\n8\nacross all neurons and inputs. As a part of the network, the lateral inhibitory\nconnections are static, with the same weights assigned to each neuron. How-\never, this is not reasonable. Evidence from neuroscience suggests that for\nbetter inhibition, it does not exert inhibition on all neurons, but on those with\nrelevant activity Linster et al. (2005); Kuﬄer (1953); Arevian et al. (2008).\nThus, we expect a dynamic structure of lateral inhibitory connections to\nproduce various structures for diﬀerent inputs. Such a dynamic structure\nwould help enhance coordination between neurons.\nTo this end, we introduce Adaptive Lateral Inhibitory Connection (ALIC),\nas shown in Figure 3 . We designed a dynamic structure of lateral inhibition.\nwe determine which neurons may ﬁre by setting a threshold and inhibit the\nmembrane potential for these neurons.\nAs shown in the Equation 6, we\nchoose the maximum input current as the reference. Inhibition depends on\nmaximum current for diﬀerent inputs. Threshold is set with ithresh = i(t)\nmax\n2\ninh(t)\nij = αinh ( max\nb,c,w,h i(t))(1 −ˆs(t)\nij )\n= αinh ( max\nb,c,w,h\nX\ni,j\nw(t)\nij ˆs(t)\nij )(1 −ˆs(t)\nij )\nif\ni(t)\nij > ithresh\n(6)\nwhere inh(t)\nij is the inhibition for the neuron at the position of i, j at the\ntime t. αinh is a coeﬃcient that adjusts the degree of inhibition. i(t) denotes\nthe input current, which obtained by synaptic weight wij and spikes ˆs(t)\nij .\nThe maximum is selected from all the neurons in batch, where b denotes\nbatch, c, w, h denotes the channel and size of output. (1 −s(t)\nij ) allows the\ninhibition to act only on neurons that are not ﬁring at this moment.\nWe\nadopt the winner-take-all strategy, randomly take out a ﬁring neuron, and set\nthe remaining spikes to 0, ˆs(t)\nij = wintakeall(s(t)\nij ). A more detailed analysis\nof section 5.3 shows that ALIC actually improves the performance of the\nnetwork.\n4.2. Adaptive Threshold Balance\nBy introducing an adaptive threshold method, we are able to eliminate the\nmismatch between input and output between layers. The input current varies\nfrom diﬀerent inputs, leading to spikes ﬁring variability.\nThe current may\nbe too small to reach the threshold, delaying the transmission of information\nand increasing the network delay. A large value may also be well above\n9\nthe threshold, increasing ﬁring frequency. The portion of current above the\nthreshold will be lost due to the reset of the membrane potential. Therefore, a\ndynamic threshold method is needed so that the threshold can be adaptively\nchanged according to the magnitude of the current. Due to neurons’ inherent\nplasticity, the adaptive threshold can reduce the loss during transmission and\nfacilitate the expression of more precise informationWilent and Contreras\n(2005); Huang et al. (2016). We introduce an adaptive threshold balancing\n(ATB) mechanism.\nThe convolutional and fully connected layers play diﬀerent roles in the\nnetwork. The convolutional layer extracts features, while the fully connected\nlayer exhibits feature selectivity sensitive to diﬀerent features. Therefore, we\nemploy variable threshold methods at layers. For convolutional layers, ATB\nset threshold positively related to the maximum input current, as shown in\nEquation 7. where u(t)\nthresh denotes the threshold of neuron at time t. βthresh\nis a parameter controlling the threshold scale. The maximum current is\nselected from the maximum input value of all neurons in the convolutional\nlayer. c, w, h represents the number of channels in the convolutional kernel\nand the size of the output, respectively. The input current of each neuron is\nobtained from the synaptic weights and the input spikes. ATB ensures that\nno information is lost due to excessive current. Meanwhile, it allows spikes to\nbe transmitted for a limited time.\nu(t)\nthresh = βthresh (max\nc,w,h i(t)) = βthresh (max\nc,w,h\nX\ni,j\nw(t)\nij ˆs(t)\nij )\n(7)\nFor fully connected layers, ATB improves the method in Diehl and Cook\n(2015). Where ut,j\nthresh denotes the threshold of the neuron j at time t. When\na neuron ﬁres a spike, we increase the threshold θt,j\nplus, making the next ﬁring\nmore diﬃcult. When θt,j\nplus reaches γ, all thresholds reduce the diﬀerence\nbetween maximum threshold and γ. As shown in Equation 8 . Where θinit\nis the initial value. θplus is the increment of ut,j\nthresh. αplus is a coeﬃcient\n10\ncontrolling the growth rate.\nut,j\nthresh = θinit + θt,j\nplus\nθt,j\nplus = θt−1,j\nplus + αplus\nX\nb,t\nˆs(t)\nj −θt,j\nbias\nθt,j\nbias =\n\n\n\n\n\nmax\nj\nut−1,j\nthresh −γ\nif\nmax\nj\nu(t−1)\nthresh > γ\n0\nif\nmax\nj\nu(t−1)\nthresh < γ\n(8)\nIn this manner, a dynamic balance is established, where each neuron is\nmeasured for relative sensitivity. When γ is reached, the whole shifts down-\nward. All thresholds are limited within a range. Thus, the diﬀerence between\nthe thresholds is indicative of the neuron’s sensitivity. Neurons with higher\nthresholds have lower sensitivity. This dynamic balance prevents a single\nneuron from dominating and ensures that each neuron has an opportunity to\nﬁre.\n4.3. Adaptive Synaptic Filter\nWith adaptive threshold balancing (ATB), the threshold is adjusted\nwithin the convolutional layers in order to match it to the current magnitude.\nHowever, current regulation for individual neurons will still assist the network\nin achieving a more stable performance.\nThe short-term plasticity (STP) of synapses aﬀects short-term information\nprocessing at synapses, as shown in Figure 3 (b). By increasing or decreasing\nthe signal transmission eﬃciency of synapses, it can provide ﬁlter functions\nfor the processing of information Scott et al. (2012); Rotman et al. (2011).\nInspired by this, we construct an adaptive synaptic ﬁlter (ASF) based on the\ninput current. Details are shown in the Equation 9.\nδasf (i(t)) = u(t)\nthresh\n1 + eσt\nwhere\nσt = −αasf\ni(t)\nu(t)\nthresh\n+ βasf\n(9)\nδasf is the function of ASF, where u(t)\nthresh denotes the threshold at time t.\ni(t) is the input current at time t. αasf and βasf are coeﬃcients and control\n11\nthe function of the ﬁlter. The ASF adjusts the current through a nonlinear\nfunction, making the current more likely to concentrate near the threshold\nor resting potential. Concentrating current towards the threshold will result\nin more competition for the neuron. More competition will help avoid the\ndominance of neurons. And the current approach to resting potential will\ndecrease the noise generated by low current strength neurons ﬁring. Since ASF\nis calculated according to the threshold, ASF must be performed concurrently\nwith ATB. We verify the eﬀectiveness of ASF in section 5.3.\nAdaptive \nSynaptic Filter\nAdaptive Threshold \nBalance\nASF\nSample 1\nSample 2\nSample 3\nSample 4\n(a) Adaptive Synaptic Filter (ASF) and \nAdpative Threshold Balance (ATB)\n(b) Short-tetrm Plasticity\n(c) Adaptive Lateral Inhibitory Connection (ALIC)\nspikes affect strength \nof the synapse\nS0\nS1\nS2\nFigure 3: (a) The adaptive synaptic ﬁlter helps to regulate the inputs, and (b) the adaptive\nthreshold balance helps to regulate the outputs.\n(c) The adaptive lateral inhibitory\nconnection helps to suppress the same state to avoid learning repeat features.\n4.4. STB-STDP\nA majority of STDP-based SNN algorithms are trained with one sample at\na time, with the weights being updated at every step of the training process.\nHowever, as with the backpropagation algorithm, combining a set of samples\ninto batches for training can reduce the convergence instability caused by\ndeviations in the distribution of each sample. Due to the batch processing of\n12\nthe samples, the convergence speed of the model is also signiﬁcantly increased.\nIn addition, SNNs exhibit multiple forward propagation processes in the\ntemporal dimension, in contrast to artiﬁcial neural networks. By aggregating\nmultiple time steps, the network can converge more smoothly instead of\nupdating at every step.\nFrom this, we propose a sample-temporal batches STDP algorithm (STB-\nSTDP). A weight update is done by integrating the information of samples\nand temporal information simultaneously. As the Equation 10 shows:\n∆wj =\nNbatch\nX\nn=0\nTbatch\nX\nt=0\n(xn,t\ntrace −xoﬀset)/(NbatchTbatch)\nif xpostspike = 1\nxn,t\ntrace = λ+xn,t−1\ntrace + xprespike\n(10)\nwhere Nbatchis the batchsize of the input, Tbatch is the batchsize of time step.\nWeights are normalized after updating, preventing them from diverging\nor shifting. As shown in Equation 11. Diﬀerent normalization methods are\nused for convolutional layers and fully connected layers. A−\nfc, A−\nconv is scale\nfactor to control normalization. Additionally, a spike normalization module\nis added between each layer to stabilize the inputs and outputs, which limits\nthe input range of the spike. This module captures spikes and outputs a ﬁring\nfrequency of up to one.\nfc : w(t)\nj\n= A−\nfc\nw(t)\nj\nmean(w(t)\nj )\nconv : w(t)\nij = A−\nconv\nw(t)\nij −mean(w(t)\nij )\nstd(w(t)\nij )\n(11)\n5. Experiments\nTo demonstrate the eﬀectiveness of our model, we conduct experiments\non the commonly used datasets, MNIST LeCun et al. (1998) and Fash-\nionMNIST Xiao et al. (2017), CIFAR10 Krizhevsky et al. (2009). All the\nexperiments are based on the structure consisting of a convolutional layer\nfollowed by a 2*2 max pooling layer, a spiking normalization layer, and a\nfully connected layer. Since our model is an unsupervised network, we adopt\nthe same voting strategy as in Diehl and Cook (2015) of the output of the\nﬁnal layer for category prediction. And the parameters of the network are\n13\ntrained layer-wisely. Where A−\nfc = 0.01, A−\nconv = 1,αinh = 1.625, θinit = 10,\nαsfa = 0.4, βsfa = 8, αplus = 0.001, λ = 0.99, βthresh = 1, xoﬀset = 0.3.\n5.1. Experimental Results\nMNIST is a digital handwriting recognition dataset widely used as a\nbenchmark for evaluating model performance in recognition and classiﬁcation\ntasks. The dataset contains a total of 60,000 training set samples and 10,000\ntest set samples. The size of each sample is 28*28 pixels. In the experiments,\nthe examples in MNIST were normalized using direct encoding and without\nany form of data augmentation and preprocessing. For the MNIST dataset,\nwe set the kernel size of the convolutional layer to 5 with 12 channels, and\n6400 neurons in the fully connected layer. Timestep is 300 in our experiments.\nTo verify the superiority of our model, we compare the results with other\nfamous STDP-based SNN models. Un-&Supervised denotes the former layer is\ntrained unsupervised, while the ﬁnal decision layer is trained with supervised\ninformation.\nAs shown in Table 1, Our model achieves 97.9% accuracy.\nCompared with Diehl and Cook (2015), which only uses the STDP, our\nmodel improves by nearly 3%. Our model has surpassed all the unsupervised\nSTDP-based SNNs and even some SNNs with supervised information.\nTable 1: The performance on MNIST dataset compared with other STDP-based SNNs.\nModel\nLearning Method\nType\nAccuracy\nQuerlioz et al. (2013)\nSTDP\nUnsupervised\n93.5%\nDiehl and Cook (2015)\nSTDP\nUnsupervised\n95.0%\nHao et al. (2020)\nSym-STDP + SVM\nUn-&Supervised\n96.7%\nDCSNN Mozafari et al. (2019)\nDoG + STDP + R-STDP\nUn-&Supervised\n97.2%\nFalez et al. (2019)\nDoG + STDP + SVM\nUn-&Supervised\n98.6%\nSDNN Kheradpisheh et al. (2018)\nDoG + STDP + SVM\nUn-&Supervised\n98.4%\nSpiCNNLee et al. (2018b)\nLoG+STDP\nUn-&Supervised\n91.1%\nTavanaei and Maida (2017)\nSTDP + SVM\nUn-&Supervised\n98.4%\nFerré et al. (2018)\nSTDP + BP\nUn-&Supervised\n98.5%\nSSTDPLiu et al. (2021)\nSTDP + BP\nSupervised\n98.1%\nVPSNN Zhang et al. (2018)\nEquilibrium Propagation + STDP\nSupervised\n98.5%\nCBSNN Shi et al. (2020)\nVPSNN + Curiosity\nSupervised\n98.6%\nBP-STDP Tavanaei and Maida (2019)\nSTDP-Based BP\nSupervised\n97.2%\nGLSNN Zhao et al. (2020)\nGlobal Feedback + STDP\nSupervised\n98.6%\nOurs\nASF + ATB + ALIC + STB-STDP\nUnsupervised\n97.9%\nFashionMNIST is more complex than MNIST within cloths and shoes as\nthe samples. Both the shape and the size of the data are the same as those\nobtained by MNIST. The kernel size for the convolutional layer is set at 3\nwith 64 channels, and 6400 neurons in the fully connected layer. The timestep\n14\nFigure 4: The accuracy curve of the model on cifar10. We conducted experiments with\n3200, 6400, and 10240 neurons in the fully connected layer. We visualize (a) the accuracy\ncurve for the training set and (b) the accuracy curve for the test set.\nis the same as that used in MNIST. As seen in Table 2, our model succeeded\nin achieving 87.0% accuracy and outperformed most STDP-based SNNs.\nAlthough the performance of GLSNN is higher than ours, it introduces global\nsupervised connections, while our network has no supervision information.\nTable 2: The performance on FashionMNIST dataset compared with other STDP-based\nSNNs.\nModel\nLearning Method\nType\nAccuracy\nFSpiNN Putra and Shaﬁque (2020)\nSTDP\nUnsupervised\n68.8%\nRastogi et al. (2021)\nA-STDP\nUnsupervised\n75.9%\nHao et al. (2020)\nSym-STDP\nSupervised\n85.3%\nVPSNN Zhang et al. (2018)\nEquilibrium Propagation + STDP\nSupervised\n83.0%\nCBSNN Shi et al. (2020)\nVPSNN + Curiosity\nSupervised\n85.7%\nGLSNN Zhao et al. (2020)\nGlobal Feedback + STDP\nSupervised\n89.1%\nOurs\nASF + ATB + ALIC + STB-STDP\nUnsupervised\n87.0%\n5.2. Result on CIFAR10\nOnly a few STDP-based SNN algorithms are capable of classifying the\nFashionMNIST dataset and achieving impressive results. As far as we know,\nfew unsupervised STDP-based models run experiments on more complex\ndatasets, such as CIFAR10. Trying to maintain high performance on more\ncomplex datasets will be our exploration direction. First, we used RGB data\nand the image size is 32x32. We use a 5x5 convolution kernel with 3 input\nchannels and 64 output channels in the convolutional layer. Meanwhile, 3200\n15\nneurons are used in the fully connected layer. After training, our model\nachieved 42.36% accuracy on the CIFAR10 dataset. We visualize the accuracy\ncurves of our model with 3200, 6400, and 10240 neurons in the fully connected\nlayer. The highest accuracy was obtained for the test set at the number of\nneurons of 3200.\n5.3. Discussion\nIn order to determine what causes misclassiﬁed samples, we visualized the\nclassiﬁcation confusion matrix of our model on the MNIST and FashionMNIST\ndatasets, respectively. As shown in the Figure 5. There is not much distinction\nbetween the categories on MNIST’s matrix. However, FashionMNIST’s matrix\nshowed lower accuracy on four categories of 0,2,4,6, corresponding to ’t-shirt’,\n’pullover’, ’coat’, and ’shirt’, respectively. There is a high degree of similarity\nbetween images in these four categories, which makes it more diﬃcult for the\nmodel to classify them accurately.\nkernels\nneurons\naccuracy\naccuracy\nneurons\nkernels\nEpoch\nTop1-Acc\nEpoch\nTop1-Acc\n(d)  Accuracy Curve of  MNIST\n(f)  Accuracy Curve of  FashionMNIST\n(c) Histogram of MNIST  \n(e) Histogram of FashionMNIST\n(a) MNIST Matrix\n(b) FashionMNIST Matrix  \nFigure 5: (a,b) The confusion matrix of our model in MNIST and FashionMNIST. (c,e)\nThe histograms of the performance of our model on MNIST and FahsionMNIST with the\ndiﬀerent numbers of convolutional kernels and voting neurons. (d,f) The test accuracy\ncurves of our model with and without the modules we design.\n16\nWe explore the impact of diﬀerent parameter settings on network per-\nformance. In convolutional layers, we changed the number of kernels, while\nin fully connected layers, we changed the number of neurons. As shown in\nFigure 5. The diﬀerent number of channels and the number of neurons in the\nfully connected layer are combined, respectively. The height of the histogram\nrepresents the ﬁnal accuracy of the model. There is a direct correlation\nbetween performance and the number of voting neurons set. Because more\nvoting neurons will provide more predictions, combining all predictions, the\nnetwork will produce more accurate results. However, this correlation does\nnot exist for the setting of the number of convolution kernels. The best\nperformance for MNIST is achieved when the number of kernels is set to 12.\nIn contrast, FashionMNIST requires more convolution kernels due to\nits complexity, and it works best when the number of kernels is set to 64.\nMore convolution kernels cannot extract more features, because repeated\nfeatures will appear in large numbers. In addition, the fully connected layer\nalso needs more connections due to the increased number of kernels because\nmore connections increase the complexity of the network and the diﬃculty of\nconvergence.\nTo fully illustrate the impact of each module of our model on the results,\nwe conduct ablation experiments on two datasets separately. We conducted\nexperiments with the settings \"w/o ASF\", \"w/o ASF and ALIC\", and \"w/o\nASF, ALIC, and ATB\", respectively. \"w/o\" denotes that we remove the\nrelevant module. We show the convergence curve of the model on the test\nset, as shown in Figure 5. All experiments included STB-STDP to ensure the\neﬃciency of the experiment. It would take a much longer time for the model\nto run without it. Adding each module can assist in improving the model’s\nlearning ability and its ability to achieve higher accuracy on the MNIST and\nFashionMNIST datasets.\nTo better illustrate the role of lateral inhibition, we added \"softmax\" for\ncomparison. \"softmax\" is a commonly used function that can serve as a lateral\ninhibition. For the experiments, we removed the lateral inhibition module\nand performed the experiments on the MNIST dataset with the same model\nstructure. The convolutional layer contains 12 5x5 convolutional kernels and\n6400 neurons in the fully connected layer. We have trained the model with\nthe same experimental setup. The model reached 28.26%. Then we added the\nsoftmax layer after the input currents in the convolutional layer and the fully\nconnected layer. Also, to ensure that the currents are of the same scale, we\nmultiplied by the maximum value of the current. After training, the model\n17\nobtained 78.16%. This shows that the softmax has a certain eﬀect. However,\nlateral inhibition can help the model to achieve the inhibition in a better way.\n5.4. Experiment for Small Samples\nTable 3: The performance of our model compared with ANN on MNIST dataset with\ndiﬀerent training samples.\nsamples\n200\n100\n50\n10\nANN\n79.77%\n71.40%\n68.72%\n47.12%\nOurs\n81.45%\n75.44%\n72.88%\n51.45%\n1.68%\n4.04%\n4.16%\n4.33%\nIn contrast to the backpropagation algorithm, our network trained with\nthe STDP unsupervised algorithm is more adaptable to diﬀerent number of\nsamples, especially in small-sample task, and shows superior performance\ncompared to supervised algorithms with the same structure. There are only\na very small number of samples in the whole train set in small-samples task,\nwhich diﬀers from few-shot learning. To this end, to illustrate the ability of\nour model to train on small samples tasks, a very small number of samples\nare randomly selected from the MNIST dataset. The number of samples\nper class ranges from 20 to 10 to 5, in the most extreme case, to 1. At the\nsame time, we also designed an artiﬁcial neural network model with the same\nstructure for comparison. The model consists of 5x5 convolutions with 12\nchannels, a maxpool layer, a fully connected layer of 6400 neurons, and a ﬁnal\nfully connected classiﬁer. The backpropagation algorithm is used to train this\nANN model.\nAs shown in the Table 3, our model has better performance than the\nANN model. As the number of training samples gradually decreases, the\nperformance gap between our model and ANN gradually increases. When\nthere is only 1 training sample per class, our model outperforms ANN by\n4.43%. It fully illustrates that our model requires only a small number of\nsamples to achieve high performance compared to artiﬁcial neural networks\nthat require a large amount of labeled training data.\n5.5. Visualization\nTo illustrate the feature extraction capability of our model, we visualize\nthe weights of diﬀerent layers. Figure 6 a and b shows the weight of the\nconvolutional layer on the MNIST and FashionMNIST dataset respectively.\n18\n(a) \n(d) \n(c) \n(b) \nFigure 6:\nVisualization of the weights of the model. (a) represents the convolutional layers\ntrained on MNIST. It contains 12 channels, and we visualize the weights of each kernel. (b)\nConvolutional layer trained on FashionMNIST. It contains 64 kernels. (c) Fully connected\nlayer on MNIST. We randomly selected 10 neurons from the corresponding categories. The\ncorresponding weights are visualized. Each of these rows shows one category, (d) Fully\nconnected layer on the FashionMNIST dataset. We visualized a portion of these weights,\nwhere each row represents the weight of neurons corresponding to a category.\n19\nThe convolutional kernels capture simple features such as edges, lines. With\nthe introduction of our adaptive lateral inhibitory connections, our network\ndoes not have a large number of repeated features. Figure 6 c and d show\nthe weight of the fully connected layer. According to the label assigned to\nthe neuron, we visualize the weight of ten categories, and each row represents\na category.\nIt can be seen that the fully connected layer automatically\ncombines the features of the convolutional layers to form higher-level semantic\nrepresentations. For MNIST, with the combination of simple features, the\ndiﬀerent numbers can be easily classiﬁed. While FashionMNIST is more\ncomplex, it is not easy to distinguish similar objects such as Shirts and T-\nShirt. In future work, we will consider introducing more biologically plausible\nrules to improve the performance of our model.\n6. Conclusion\nSpiking neural networks (SNNs) trained with STDP alone are ineﬃcient\nand hardly achieve a high performance of SNN. In this paper, we design\nan adaptive synaptic ﬁlter and introduce the adaptive threshold balance to\nenrich the representation ability of SNNs. We also introduce an adaptive\nlateral inhibitory connection to help the network learn richer features. We\ndesign a samples temporal batch STDP (STB-STDP), which updates weights\nbased on multiple samples and moments. By integrating the above three\nadaptive mechanisms and STB-STDP, we have achieved current state-of-\nthe-art performance for unsupervised STDP-trained SNNs on MNIST and\nFashionMNIST. Further, we tested on the more complex CIFAR10 dataset,\nand the results fully illustrate the superiority of our algorithm. Since we\nconsider more of the unsupervised learning rules, it does not obtain signiﬁcant\nimprovement when it is extended to deep networks. In future work, we intend\nto consider more learning methods of the human brain, such as dopamine-\nbased regulation of the reward mechanism. Also, We will introduce more\nbrain-like structures, such as global feedback connections.\nAcknowledgement\nThis study was supported by National Key Research and Development Pro-\ngram (Grant No.2020AAA0107800), the Strategic Priority Research Program\nof the Chinese Academy of Sciences (Grant No.XDB32070100).\n20\nReferences\nAbbott, L., Regehr, W.G., 2004. Synaptic computation. Nature 431, 796–803.\nAmari, S.i., 1977. Dynamics of pattern formation in lateral-inhibition type\nneural ﬁelds. Biological cybernetics 27, 77–87.\nArevian, A.C., Kapoor, V., Urban, N.N., 2008. Activity-dependent gating\nof lateral inhibition in the mouse olfactory bulb. Nature neuroscience 11,\n80–87.\nBi, G.q., Poo, M.m., 1998. Synaptic modiﬁcations in cultured hippocampal\nneurons: dependence on spike timing, synaptic strength, and postsynaptic\ncell type. Journal of neuroscience 18, 10464–10472.\nBlakemore, C., Carpenter, R.H., Georgeson, M.A., 1970. Lateral inhibition\nbetween orientation detectors in the human visual system. Nature 228,\n37–39.\nCheng, X., Hao, Y., Xu, J., Xu, B., 2020. Lisnn: Improving spiking neural\nnetworks with lateral interactions for robust object recognition., in: IJCAI,\npp. 1519–1525.\nCitri, A., Malenka, R.C., 2008. Synaptic plasticity: multiple forms, functions,\nand mechanisms. Neuropsychopharmacology 33, 18–41.\nDayan, P., Abbott, L.F., 2005. Theoretical neuroscience: computational and\nmathematical modeling of neural systems. MIT press.\nDiehl, P.U., Cook, M., 2015. Unsupervised learning of digit recognition using\nspike-timing-dependent plasticity. Frontiers in computational neuroscience\n9, 99.\nDiehl, P.U., Neil, D., Binas, J., Cook, M., Liu, S.C., Pfeiﬀer, M., 2015.\nFast-classifying, high-accuracy spiking deep networks through weight and\nthreshold balancing, in: 2015 International joint conference on neural\nnetworks (IJCNN), ieee. pp. 1–8.\nFalez, P., Tirilly, P., Bilasco, I.M., Devienne, P., Boulet, P., 2019. Multi-\nlayered spiking neural network with target timestamp threshold adaptation\nand stdp, in: 2019 International Joint Conference on Neural Networks\n(IJCNN), IEEE. pp. 1–8.\n21\nFang, H., Zeng, Y., Zhao, F., 2021. Brain inspired sequences production\nby spiking neural networks with reward-modulated stdp.\nFrontiers in\nComputational Neuroscience 15, 8.\nFerré, P., Mamalet, F., Thorpe, S.J., 2018. Unsupervised feature learning\nwith winner-takes-all based stdp. Frontiers in computational neuroscience\n12, 24.\nGlorot, X., Bengio, Y., 2010. Understanding the diﬃculty of training deep\nfeedforward neural networks, in: Proceedings of the thirteenth international\nconference on artiﬁcial intelligence and statistics, JMLR Workshop and\nConference Proceedings. pp. 249–256.\nHan, B., Roy, K., 2020. Deep spiking neural network: Energy eﬃciency\nthrough time based coding, in: European Conference on Computer Vision,\nSpringer. pp. 388–404.\nHao, Y., Huang, X., Dong, M., Xu, B., 2020.\nA biologically plausible\nsupervised learning method for spiking neural networks using the symmetric\nstdp rule. Neural Networks 121, 387–395.\nHeitzler, P., Simpson, P., 1991. The choice of cell fate in the epidermis of\ndrosophila. Cell 64, 1083–1092.\nHuang, C., Resnik, A., Celikel, T., Englitz, B., 2016. Adaptive spike threshold\nenables robust and temporally precise neuronal encoding. PLoS computa-\ntional biology 12, e1004984.\nIzhikevich, E.M., 2007. Solving the distal reward problem through linkage of\nstdp and dopamine signaling. Cerebral cortex 17, 2443–2452.\nKheradpisheh, S.R., Ganjtabesh, M., Thorpe, S.J., Masquelier, T., 2018. Stdp-\nbased spiking deep convolutional neural networks for object recognition.\nNeural Networks 99, 56–67.\nKrizhevsky, A., Hinton, G., et al., 2009. Learning multiple layers of features\nfrom tiny images .\nKuﬄer, S.W., 1953. Discharge patterns and functional organization of mam-\nmalian retina. Journal of neurophysiology 16, 37–68.\n22\nLeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P., 1998. Gradient-based learning\napplied to document recognition. Proceedings of the IEEE 86, 2278–2324.\nLee, C., Panda, P., Srinivasan, G., Roy, K., 2018a. Training deep spiking\nconvolutional neural networks with stdp-based unsupervised pre-training\nfollowed by supervised ﬁne-tuning. Frontiers in neuroscience 12, 435.\nLee, C., Srinivasan, G., Panda, P., Roy, K., 2018b. Deep spiking convolutional\nneural network trained with unsupervised spike-timing-dependent plasticity.\nIEEE Transactions on Cognitive and Developmental Systems 11, 384–394.\nLee, J.H., Delbruck, T., Pfeiﬀer, M., 2016. Training deep spiking neural\nnetworks using backpropagation. Frontiers in neuroscience 10, 508.\nLi, Y., Zeng, Y., Zhao, D., 2021. Bsnn: Towards faster and better conversion\nof artiﬁcial neural networks to spiking neural networks with bistable neurons.\narXiv preprint arXiv:2105.12917 .\nLillicrap, T.P., Cownden, D., Tweed, D.B., Akerman, C.J., 2016. Random\nsynaptic feedback weights support error backpropagation for deep learning.\nNature communications 7, 1–10.\nLinster, C., Sachse, S., Galizia, C.G., 2005. Computational modeling suggests\nthat response properties rather than spatial position determine connectivity\nbetween olfactory glomeruli. Journal of neurophysiology 93, 3410–3417.\nLiu, F., Zhao, W., Chen, Y., Wang, Z., Yang, T., Jiang, L., 2021. Sstdp:\nSupervised spike timing dependent plasticity for eﬃcient spiking neural\nnetwork training. Frontiers in Neuroscience 15.\nMaass, W., 1997. Networks of spiking neurons: the third generation of neural\nnetwork models. Neural networks 10, 1659–1671.\nMozafari, M., Ganjtabesh, M., Nowzari-Dalini, A., Thorpe, S.J., Masquelier,\nT., 2019. Bio-inspired digit recognition using reward-modulated spike-\ntiming-dependent plasticity in deep convolutional networks. Pattern recog-\nnition 94, 87–95.\nPutra, R.V.W., Shaﬁque, M., 2020. Fspinn: An optimization framework\nfor memory-eﬃcient and energy-eﬃcient spiking neural networks. IEEE\nTransactions on Computer-Aided Design of Integrated Circuits and Systems\n39, 3601–3613.\n23\nQuerlioz, D., Bichler, O., Dollfus, P., Gamrat, C., 2013. Immunity to device\nvariations in a spiking neural network with memristive nanodevices. IEEE\ntransactions on nanotechnology 12, 288–295.\nRastogi, M., Lu, S., Islam, N., Sengupta, A., 2021. On the self-repair role of\nastrocytes in stdp enabled unsupervised snns. Frontiers in Neuroscience 14,\n1351.\nRotman, Z., Deng, P.Y., Klyachko, V.A., 2011. Short-term plasticity optimizes\nsynaptic information transmission. Journal of Neuroscience 31, 14800–\n14809.\nScott, P., Cowan, A.I., Stricker, C., 2012. Quantifying impacts of short-term\nplasticity on neuronal information transfer. Physical Review E 85, 041921.\nShen, G., Zhao, D., Zeng, Y., 2021. Backpropagation with biologically plausi-\nble spatio-temporal adjustment for training deep spiking neural networks.\narXiv preprint arXiv:2110.08858 .\nShi, M., Zhang, T., Zeng, Y., 2020. A curiosity-based learning method for\nspiking neural networks. Frontiers in computational neuroscience 14, 7.\nTauﬀer, L., Kumar, A., 2021. Short-term synaptic plasticity makes neurons\nsensitive to the distribution of presynaptic population ﬁring rates. Eneuro\n8.\nTavanaei, A., Maida, A., 2019. Bp-stdp: Approximating backpropagation\nusing spike timing dependent plasticity. Neurocomputing 330, 39–47.\nTavanaei, A., Maida, A.S., 2017. Multi-layer unsupervised learning in a spiking\nconvolutional neural network, in: 2017 international joint conference on\nneural networks (IJCNN), IEEE. pp. 2023–2030.\nWilent, W.B., Contreras, D., 2005. Stimulus-dependent changes in spike\nthreshold enhance feature selectivity in rat barrel cortex neurons. Journal\nof Neuroscience 25, 2983–2991.\nWu, Y., Deng, L., Li, G., Zhu, J., Shi, L., 2018. Spatio-temporal backpropa-\ngation for training high-performance spiking neural networks. Frontiers in\nneuroscience 12, 331.\n24\nWu, Y., Deng, L., Li, G., Zhu, J., Xie, Y., Shi, L., 2019. Direct training\nfor spiking neural networks: Faster, larger, better, in: Proceedings of the\nAAAI Conference on Artiﬁcial Intelligence, pp. 1311–1318.\nXiao, H., Rasul, K., Vollgraf, R., 2017.\nFashion-mnist: a novel image\ndataset for benchmarking machine learning algorithms. arXiv preprint\narXiv:1708.07747 .\nZenke, F., Agnes, E.J., Gerstner, W., 2015.\nDiverse synaptic plasticity\nmechanisms orchestrated to form and retrieve memories in spiking neural\nnetworks. Nature communications 6, 6922.\nZhang, T., Zeng, Y., Zhao, D., Shi, M., 2018. A plasticity-centric approach\nto train the non-diﬀerential spiking neural networks, in: Proceedings of the\nAAAI Conference on Artiﬁcial Intelligence.\nZhao, D., Li, Y., Zeng, Y., Wang, J., Zhang, Q., 2021. Spiking capsnet: A\nspiking neural network with a biologically plausible routing rule between\ncapsules. arXiv preprint arXiv:2111.07785 .\nZhao, D., Zeng, Y., Zhang, T., Shi, M., Zhao, F., 2020. Glsnn: A multi-layer\nspiking neural network based on global feedback alignment and local stdp\nplasticity. Frontiers in Computational Neuroscience , 101.\nZhao, Z., Lu, E., Zhao, F., Zeng, Y., Zhao, Y., 2022. A brain-inspired theory\nof mind spiking neural network for reducing safety risks of other agents.\nFrontiers in Neuroscience , 446.\nZucker, R.S., Regehr, W.G., 2002. Short-term synaptic plasticity. Annual\nreview of physiology 64, 355–405.\n25\n",
  "categories": [
    "cs.NE"
  ],
  "published": "2022-07-06",
  "updated": "2023-04-22"
}