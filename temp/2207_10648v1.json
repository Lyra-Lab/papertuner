{
  "id": "http://arxiv.org/abs/2207.10648v1",
  "title": "A No-Code Low-Code Paradigm for Authoring Business Automations Using Natural Language",
  "authors": [
    "Michael Desmond",
    "Evelyn Duesterwald",
    "Vatche Isahagian",
    "Vinod Muthusamy"
  ],
  "abstract": "Most business process automation is still developed using traditional\nautomation technologies such as workflow engines. These systems provide domain\nspecific languages that require both business knowledge and programming skills\nto effectively use. As such, business users often lack adequate programming\nskills to fully leverage these code oriented environments. We propose a\nparadigm for the construction of business automations using natural language.\nThe approach applies a large language model to translate business rules and\nautomations described in natural language, into a domain specific language\ninterpretable by a business rule engine. We compare the performance of various\nlanguage model configurations, across various target domains, and explore the\nuse of constrained decoding to ensure syntactically correct generation of\noutput.",
  "text": "A No-Code Low-Code Paradigm for Authoring\nBusiness Automations Using Natural Language\nMichael Desmond, Evelyn Duesterwald, Vatche Isahagian, and\nVinod Muthusamy\nIBM Research AI, USA\n{mdesmond,duester}@us.ibm.com, vatchei@ibm.com, vmuthus@us.ibm.com\nAbstract. Most business process automation is still developed using\ntraditional automation technologies such as workﬂow engines. These sys-\ntems provide domain speciﬁc languages that require both business knowl-\nedge and programming skills to eﬀectively use. As such, business users\noften lack adequate programming skills to fully leverage these code ori-\nented environments. We propose a paradigm for the construction of busi-\nness automations using natural language. The approach applies a large\nlanguage model to translate business rules and automations described\nin natural language, into a domain speciﬁc language interpretable by a\nbusiness rule engine. We compare the performance of various language\nmodel conﬁgurations, across various target domains, and explore the use\nof constrained decoding to ensure syntactically correct generation of out-\nput.\n1\nIntroduction\nBusiness process automation (BPM) has emerged as a multi-billion dollar indus-\ntry [1] driven by the adoption of digital transformation and IT automation in the\nenterprise. Trends in automation are further accelerating due to changes in the\nnature of work as a result of the pandemic. Much of this automation has been\ndeveloped using traditional automation technologies, such as workﬂow engines\nand operational decision management services. Usually, these technologies come\nwith a custom automation language, such as BPMN [2] and DMN [3], that re-\nquire users to have adequate programming and infrastructure skills to develop,\ndebug and deploy. As enterprises continue to embrace automation, there is a\ngrowing need to enable business users (citizen developers) to build automations\nof their mundane business tasks. Citizen developers are experts in their ﬁelds,\nbut often lack adequate programming skills to code and debug automations using\nlanguages and tools designed for proﬁcient developers.\nMultiple low-code eﬀorts to ease the development burden for citizen develop-\ners have been proposed. Power Automate [12] provides a visual tool that enables\nusers to create automations. Robotic Process Automation (RPA) vendors such\nas UIPath, Automation Anywhere, and IBM RPA provide recorders that enable\nusers to record their actions and automate mundane tasks. While it is easier to\nbuild automations using these low code tools, they come with their own set of\narXiv:2207.10648v1  [cs.CL]  15 Jul 2022\n2\nDesmond, Duesterwald, Isahagian, Muthusamy\nAutomation \ntooling language\n(executable)\nConstrained \nnatural language\n(no ambiguity)\nTranspilation\nNatural language\n(expressive)\nLearned mapping\n(via NLP Foundation models)\nno-code\ndev\nlow-code\ndev\npro-code\ndev\n‘\nFig. 1: NL-based no-code/low-code solution for building automations.\nchallenges [9]. Furthermore, the generated RPAs are typically limited in execu-\ntion scope, and still require advanced development skills to modify and maintain.\nRecent advances in AI in domains such as AI planning [7], and Natural lan-\nguage Processing (NLP) [15] have enabled the construction of more advanced\nautomations. While such approaches have shown great promise for building so-\nphisticated ﬂows that go beyond simple mundane task automation, there has\nbeen less focus on using AI to lower the skill burden for citizen developers.\nWe believe that lowering the barrier of entry for business automation may\nprovide an even larger opportunity for AI. Speciﬁcally, we advocate the use of\nnatural language (NL) as an interface for ease of development and maintenance\nof business automations. If citizen developers can express their automation re-\nquirements using familiar NL, there is no skill hurdle to overcome. However,\nconstructing NL interfaces also poses unique challenges. NL is inherently am-\nbiguous making the mapping of user provided NL speciﬁcations to executable\nautomation code very challenging,\nIn this vision paper, we propose a paradigm for the construction of eﬀective\nno-code interfaces for authoring business automations using NL. Our approach\nleverages recent advances in NLP to oﬀer citizen developers an NL-based au-\nthoring experience while still providing eﬀective translation into non-ambiguous\nexecutable automation code.\n2\nProposed Paradigm\nOur paradigm for NL based automation is illustrated in Figure 1. As shown in\nthe ﬁgure, we connect an NL based no-code front end to a target automation\nlanguage backend via the introduction of an intermediate Constrained Natural\nLanguage (CNL). The CNL bridges the semantic gap between the citizen de-\nveloper’s NL input speciﬁcation and the low-level automation code. CNLs are\nnon-ambiguous domain speciﬁc programming languages (DSLs) but CNL do-\nmain keywords and abstractions bear more resemblance to NL. Due to their\nresemblance to NL, code written in a CNL tends to be easy to read and under-\nstand. However, learning to write code in a CNL is conceptually not any easier\nthan learning other DSLs. Thus, CNL code is generally not easy to write from\nAuthoring Business Automations Using Natural Language\n3\nFig. 2: NL, CNL and automation code example in Operational Decision Manager\n(ODM) [5]. The NL expression is hypothetical and not supported in ODM.\nscratch. Figure 2 provides an example illustrating the NL, CNL, and automation\ncode representation of the same business rule example.\nThe intermediate CNL provides several important advantages: First, it en-\nables the rapid construction of learned NL to CNL mappings based on emerging\ntechnology in language foundation models. Second, as an easy-to-read language,\nit provides a user-friendly interface for the citizen developer to review and vali-\ndate whether they achieved what they had in mind. Third, as a DSL, it facilitates\nthe construction of source-to-source transformation (transpilation) to the under-\nlying automation code using traditional compiler technology [8].\nOur approach provides a combined no-code/low-code authoring experience\nwhere citizen developers use NL to build automations that can be reviewed and\nvalidated at the CNL level before being transpiled to the underlying automation\ncode. Another advantage targets proﬁcient developers: they can use the NL front\nend to quickly bootstrap an initial automation that can further be edited and\nreﬁned at the automation code level.\nIn order to construct the NL front end, we need to the ability to quickly\nlearn a translation from the NL input to the corresponding representation in the\nCNL. We report on early experience with constructing these learned mappings\nusing emerging NLP foundation models with minimal training data [4]. Our\npreliminary results, summarized in Section 3 demonstrate both the feasibility\nand practicality of the proposed paradigm for building NL based interfaces for\nbusiness automation.\n3\nPreliminary Experiments\nWe evaluated the eﬃcacy of NL to CNL translation using generative language\nmodels, comparing a variety of language model (LM) conﬁgurations and the\nuse of constrained decoding [16], ﬁne-tuning vs. prompting [11], and varying\navailability of training data. We experimented with two distinct data sets: a\nbusiness rules dataset, based on the miniloan ruleset1, which included a set\nof CNL business rules with corresponding NL paraphrases; and the publicly\navailable overnight data set [17] containing cross-domain CNL style queries with\nNL paraphrases provided by MTurk workers.\n1 https://github.com/DecisionsDev/odm-for-dev-getting-started\n4\nDesmond, Duesterwald, Isahagian, Muthusamy\nThe task was to map NL statements into a corresponding CNL form. The\nmapping was learned either by ﬁne-tuning the model, or by prompting the\nmodel at inference time. We compared the following LM conﬁgurations: T5 [14],\nBART [10], as well as gpt-neo-125M, gpt-neo-1.3B, and gpt-neo-2.7B2 each cor-\nresponding to the GPT [6] architecture but with a larger parameter set. While T5\nand BART were ﬁne-tuned using training data, the gpt models were prompted\nat inference time with NL-CNL samples from the same training data. We im-\nplemented a prompt generation pipeline to generate a prompt based on the\nsimilarity of an input NL statement to existing NL statements in the training\ndata. Similar NL-CNL pairs are appended to the prompt until the context win-\ndow supported by the LM architecture is full, leaving suﬃcient room for the\ndesired output.\nIn some LM conﬁgurations we adopt constrained decoding techniques [16] to\nrestrict the generation process of the language models to adhere to a predeﬁned\ngrammar or language structure. We implemented constrained decoding using a\npreﬁx tree, constructed from tokenized examples of valid CNL statements. At\neach generation step the LM queries the preﬁx tree to select a valid next output\ntoken, thereby ensuring a syntactically correct CNL output.\nDue to the eﬀort involved in acquiring NL-CNL training examples we also\nevaluated with a reduced training set of only 100 samples. The primary metric\nwe report on is accuracy, which counts the number of exact matches generated by\nthe LM compared to reference CNL statements. Given the semantics of logical\nexpressions (and, or) which are contained in both data sets, exact matching may\nbe underestimating performance as operands can switch order without changing\nsemantics. However we believe accuracy, as a conservative measure, is still a\npractical metric. Additional metrics are reported in the appendix.\nExperimental Protocol: Each of the data sets were split into 70% training,\n24% test and 6% validation sets. A smaller training set containing 100 exam-\nples was also sampled from the initial training set to simulate a limited training\nenvironment. In the case of T5 and BART the training set was used to ﬁne-\ntune instances of these models for each of the data sets. Another version of T5\nand BART was also ﬁne-tuned using the smaller 100 sample training set. The\nLM conﬁgurations were then evaluated on the NL-to-CNL translation task using\ncommon test sets. Note that the prompted models were limited to generating\nprompts from the same training data used to train the ﬁne-tuned models. During\nconstrained decoding the preﬁx tree was constructed using all of the available\nCNL examples, from the train, test and validation sets combined. The predic-\ntions from each of the pipelines were then evaluated against the reference CNL\nstatements from the test set to produce results. All experiments were executed\nwith one v100 GPU. Decoding was performed using four beams.\nExperimental Results: Our results (summarized in Table 1) indicate that NL-\nto-CNL translation using large language models is a promising approach. On the\nbusiness rules dataset (miniloan), ﬁne-tuned ML conﬁgurations performed better\nthan prompted gpt conﬁgurations. This observation held even when comparing\n2 https://huggingface.co/EleutherAI/gpt-neo-2.7B\nAuthoring Business Automations Using Natural Language\n5\nﬁne-tuned LM conﬁgurations with limited training data to prompted LMs having\naccess to the entire training set.\nOverall T5 with constrained decoding performed best, followed closely by\nBART with constrained decoding. Constrained decoding provided slight perfor-\nmance improvements over ﬁne-tuned LM conﬁgurations with full training data,\nbut as the performance of the base LM deteriorated (with limited training data\nor prompted LM conﬁgurations), the support provided by constrained decoding\nbecame more noticable. This indicates that as the translation task becomes more\ndiﬃcult, the value of constrained decoding becomes more apparent.\nUsing limited training data (100 examples) diminished performance across\nall LM conﬁgurations, but the ﬁne-tuned LMs still performed well in this setting.\nThis is promising as it indicates that reliable translation can be achieved with a\nsmall amount of training data. Inference time became progressively slower with\nthe larger gpt LMs, taking 5 seconds per example with the largest parameter\nconﬁguration.\nDataset family\nminiloan\novernight\nDataset\nminiloan-full\nminiloan-100\nbasketball\nblocks\ncalendar\ncalendarplus\ngeo880\nhousing\npublications\nrecipes\nregex\nrestaurants\nsocialnetwork\nMetric INF\nACCURACY\nT5\n.23\n.98 .91\n.86 .50 .61 .45\n.74 .51 .63\n.72 .43 .56 .70\nT5/C.\n.29\n.99 .98\n.87 .50 .67 .63\n.75 .54 .64\n.72 .43 .58 .71\nBART\n.12\n.98 .91\n.85 .47 .65 .43\n.72 .54 .59\n.70 .73 .57 .71\nBART/C.\n.16\n.98 .97\n.85 .48 .65 .57\n.72 .55 .59\n.70 .74 .57 .72\nGPT125M\n.47\n.16 .12\n.34 .07 .15 .04\n.30 .09 .23\n.23 .09 .18 .22\nGPT125M/C. .50\n.49 .35\n.35 .11 .20 .09\n.38 .14 .28\n.28 .15 .21 .25\nGPT1.3B\n2.6\n.50 .25\n.53 .24 .33 .13\n.54 .29 .36\n.36 .30 .37 .34\nGPT1.3B/C.\n2.6\n.75 .54\n.54 .26 .34 .16\n.57 .32 .36\n.37 .33 .43 .35\nGPT2.7B\n4.9\n.43 .26\n.60 .28 .40 .10\n.54 .33 .40\n.43 .38 .41 .38\nGPT2.7B/C.\n5.0\n.76 .63\n.63 34 .46 .21\n.60 .37 .42\n.45 .44 .45 .41\nTable 1: Accuracy (exact match prediction) across language models and data\nsets. Each LM was run without and with constrained decoding (indicated with\n/C.). Miniloan-100 indicates the limited 100 examples training set was used.\nINF indicates inference time in seconds (only shown for miniloan-full). The best\nLM conﬁguration is highlighted.\n6\nDesmond, Duesterwald, Isahagian, Muthusamy\n4\nDiscussion\nThe experiments above oﬀer encouraging results for quickly building an NL no-\ncode interface for citizen developers to author automations. We discuss a few\nopen challenges to make this approach more practical.\nOne challenge is to design the CNL. Some automation tools [5] already have\na pre-deﬁned CNL but others will require a developer to deﬁne a grammar and\nontology for the CNL that ensures that the CNL is easy to read, and enables an\nunambiguous mapping to the target automation language. Compiler technologies\ncan then be used to generate the transpilation code [8].\nAnother related challenge is the creation of training examples needed for the\nNL-to-CNL translation. Our use of large pre-trained language models [4] reduces\nbut does not entirely eliminate the need for a training corpus. It is still an open\nquestion how large the training set needs to be. In our experiments we achieve\nstrong results with 100 training examples. We expected that further advances in\nfew-shot learning may help to further reduce the need for training [13].\nConstrained decoding using a preﬁx tree is well-suited to generate output ac-\ncording to a predeﬁned corpus of CNL examples, but does not account for user\ndeﬁned variables and literals. For example, in the CNL expression customer age\nis greater than 18 and customer credit score is more than 600, the val-\nues 18 and 600 may not appear in the CNL corpus and thus pose a problem\nduring constrained decoding. A context-aware algorithm might solve this prob-\nlem by extracting variables and literals from CNL inputs and replacing such\nvalues with special marker tokens during a pre-processing step. When such a\nmarker token is predicted during decoding, the LM can be presented with the\nselection of extracted context values in place of the marker. We leave this prob-\nlem of generalizing constrained decoding to future work.\nWe are currently also exploring a number of ways to generalize and extend\nour approach. For example the use of a CNL as an intermediate language in Fig-\nure 1 is primarily motivated by our use of pre-trained language models, which\nwork best when the target language is close to NL. In general, the intermediate\nlanguage can be any DSL, such as a YAML representation of a visual diagram,\nor DSLs based on Python. Such DSLs would require diﬀerent pre-trained models\nthan the ones we have experimented with. Conceptually, the only requirement\nis that the language is easy to understand, review and validate by the target\nuser. Another extension to our approach is to consider multi-modal interfaces.\nFor example, citizen developers may draw a sketch of their desired automa-\ntion, verbally describe a decision rule, markup a procedure document with edits,\ndemonstrate the steps of a workﬂow, or any combination of these modalities.\nThe most productive combination of input modalities may depend on both the\nend user as well as the business automation domain.\n5\nConclusions\nIn this paper we presented a paradigm for the construction of eﬀective and\neﬃcient NL interfaces to authoring business automations. Our paradigm provides\nAuthoring Business Automations Using Natural Language\n7\na combined no-code/low-code environment where users author automations in\nnatural language which then will be translated into a consumable CNL form\nthat can be reviewed and validated before being transpiled into automation\ncode of the underlying business platform. Early experimental results demonstrate\nthat our no-code/low-code paradigm provides a viable and practical approach to\nconstructing NL interfaces for automation, requiring only 100 training samples\nand oﬀ-the-shelf pre-trained language models. As such, our approach makes an\nimportant contribution towards a vision of enhanced productivity for business\nusers through the use of interfaces that most naturally model the way they reason\nabout their business domain and automation.\nReferences\n1. Gartner forecasts worldwide hyperautomation-enabling software market to reach\nnearly\n$600\nbillion\nby\n2022.\nhttps://www.gartner.com/en/newsroom/press-\nreleases/2021-04-28-gartner-forecasts-worldwide-hyperautomation-enabling-\nsoftware-market-to-reach-nearly-600-billion-by-2022 (2021)\n2. Aagesen, G., Krogstie, J.: Bpmn 2.0 for modeling business processes. In: Handbook\non Business Process Management 1, pp. 219–250. Springer (2015)\n3. Biard, T., Mauﬀ, A.L., Bigand, M., Bourey, J.P.: Separation of decision modeling\nfrom business process modeling using new “decision model and notation”(dmn)\nfor automating operational decision-making. In: Working Conference on Virtual\nEnterprises. pp. 489–496. Springer (2015)\n4. Bommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., von Arx, S.,\nBernstein, M.S., Bohg, J., Bosselut, A., Brunskill, E., et al.: On the opportunities\nand risks of foundation models. arXiv preprint arXiv:2108.07258 (2021)\n5. Boyer, J., Mili, H.: IBM Websphere ILOG JRules. In: Agile business rule develop-\nment, pp. 215–242. Springer (2011)\n6. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Nee-\nlakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are few-shot\nlearners. Advances in neural information processing systems 33, 1877–1901 (2020)\n7. Chakraborti, T., Agarwal, S., Khazaeni, Y., Rizk, Y., Isahagian, V.: D3ba: a tool for\noptimizing business processes using non-deterministic planning. In: International\nConference on Business Process Management. pp. 181–193. Springer (2020)\n8. Kulkarni, R., Chavan, A., Hardikar, A.: Transpiler and it’s advantages. Interna-\ntional Journal of Computer Science and Information Technologies 6(2) (2015)\n9. Leno, V., Polyvyanyy, A., Dumas, M., La Rosa, M., Maggi, F.M.: Robotic process\nmining: vision and challenges. Business & Information Systems Engineering (2021)\n10. Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O.,\nStoyanov, V., Zettlemoyer, L.: Bart: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and comprehension. arXiv preprint\narXiv:1910.13461 (2019)\n11. Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.: Pre-train, prompt, and\npredict: A systematic survey of prompting methods in natural language processing.\narXiv preprint arXiv:2107.13586 (2021)\n12. Pearson, M., Knight, B., Knight, D., Quintana, M.: Introduction to power auto-\nmate. In: Pro Microsoft Power Platform, pp. 73–78. Springer (2020)\n13. Perez, E., Kiela, D., Cho, K.: True few-shot learning with language models. Ad-\nvances in Neural Information Processing Systems 34 (2021)\n8\nDesmond, Duesterwald, Isahagian, Muthusamy\n14. Raﬀel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li,\nW., Liu, P.J.: Exploring the limits of transfer learning with a uniﬁed text-to-text\ntransformer. arXiv preprint arXiv:1910.10683 (2019)\n15. Rizk, Y., Isahagian, V., Boag, S., Khazaeni, Y., Unuvar, M., Muthusamy, V., Kha-\nlaf, R.: A conversational digital assistant for intelligent process automation. In:\nInternational Conference on Business Process Management. Springer (2020)\n16. Shin, R., Lin, C.H., Thomson, S., Chen, C., Roy, S., Platanios, E.A., Pauls, A.,\nKlein, D., Eisner, J., Van Durme, B.: Constrained language models yield few-shot\nsemantic parsers. arXiv preprint arXiv:2104.08768 (2021)\n17. Wang, Y., Berant, J., Liang, P.: Building a semantic parser overnight. In: Associ-\nation for Computational Linguistics. pp. 1332–1342 (2015)\nA\nAdditional Results\nLM\nBLEU RGL ACC BLEU100 RGL100 ACC100 INF\nT5\n.99\n.99\n.98\n.98\n.98\n.91\n.23\nT5/C.\n.98\n.99\n.99\n.98\n.99\n.98\n.29\nBART\n.99\n.99\n.98\n.98\n.98\n.91\n.12\nBART/C.\n.99\n.99\n.98\n.98\n.98\n.97\n.16\nGPT125M\n.41\n.64\n.16\n.33\n.62\n.12\n.47\nGPT125M/C. .63\n.77\n.49\n.48\n.69\n.35\n.50\nGPT1.3B\n.75\n.85\n.50\n.58\n.77\n.25\n2.6\nGPT1.3B/C. .90\n.92\n.75\n.73\n.83\n.54\n2.6\nGPT2.7B\n.74\n.84\n.43\n0.63\n.81\n.26\n4.9\nGPT2.7B/C. .91\n.93\n.76\n.83\n.89\n.63\n5.0\nTable 2: Full experimental result on a business rules (miniloan) dataset. The\nﬁrst column indicates the LM conﬁguration. Each LM was run with and with-\nout constrained decoding, indicated with /C. following the LM name. BLEU*,\nRGL* and ACC* columns indicate BLEU, ROUGEL and accuracy for the cor-\nresponding LM conﬁg. Columns with the 100 suﬃx indicate the same scores but\nwith a limited training set of 100 examples. INF indicates the inference time\n(seconds).\n",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "published": "2022-07-15",
  "updated": "2022-07-15"
}