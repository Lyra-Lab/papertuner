{
  "id": "http://arxiv.org/abs/2208.05720v1",
  "title": "A Model of Anaphoric Ambiguities using Sheaf Theoretic Quantum-like Contextuality and BERT",
  "authors": [
    "Kin Ian Lo",
    "Mehrnoosh Sadrzadeh",
    "Shane Mansfield"
  ],
  "abstract": "Ambiguities of natural language do not preclude us from using it and context\nhelps in getting ideas across. They, nonetheless, pose a key challenge to the\ndevelopment of competent machines to understand natural language and use it as\nhumans do. Contextuality is an unparalleled phenomenon in quantum mechanics,\nwhere different mathematical formalisms have been put forwards to understand\nand reason about it. In this paper, we construct a schema for anaphoric\nambiguities that exhibits quantum-like contextuality. We use a recently\ndeveloped criterion of sheaf-theoretic contextuality that is applicable to\nsignalling models. We then take advantage of the neural word embedding engine\nBERT to instantiate the schema to natural language examples and extract\nprobability distributions for the instances. As a result, plenty of\nsheaf-contextual examples were discovered in the natural language corpora BERT\nutilises. Our hope is that these examples will pave the way for future research\nand for finding ways to extend applications of quantum computing to natural\nlanguage processing.",
  "text": "M. Moortgat and G. Wijnholds: End-to-End Compositional\nModels of Vector-Based Semantics, 2022 (E2ECOMPVEC)\nEPTCS 366, 2022, pp. 23–34, doi:10.4204/EPTCS.366.5\n© K. I. Lo, M. Sadrzadeh & S. Mansﬁeld\nThis work is licensed under the\nCreative Commons Attribution License.\nA Model of Anaphoric Ambiguities using Sheaf Theoretic\nQuantum-like Contextuality and BERT\nKin Ian Lo\nMehrnoosh Sadrzadeh\nUniversity College London\nLondon, UK\n{kin.lo.20,m.sadrzadeh}@ucl.ac.uk\nShane Mansﬁeld\nQuandela\nParis, France\nshane.mansfield@quandela.com\nAmbiguities of natural language do not preclude us from using it and context helps in getting ideas\nacross. They, nonetheless, pose a key challenge to the development of competent machines to un-\nderstand natural language and use it as humans do. Contextuality is an unparalleled phenomenon in\nquantum mechanics, where different mathematical formalisms have been put forwards to understand\nand reason about it. In this paper, we construct a schema for anaphoric ambiguities that exhibits\nquantum-like contextuality. We use a recently developed criterion of sheaf-theoretic contextuality\nthat is applicable to signalling models. We then take advantage of the neural word embedding engine\nBERT to instantiate the schema to natural language examples and extract probability distributions for\nthe instances. As a result, plenty of sheaf-contextual examples were discovered in the natural lan-\nguage corpora BERT utilises. Our hope is that these examples will pave the way for future research\nand for ﬁnding ways to extend applications of quantum computing to natural language processing.\n1\nIntroduction\nContext plays a central role in determining meanings of words, as words that often occur in similar con-\ntexts have similar meanings. Conjured in the 1950’s by Firth [10] and Harris [11], this hypothesis led\nto the ﬁeld of Distributional semantics. Harris noticed that words such as ‘eye doctor’ and ‘optometrist’\noccur in the same contexts, e.g. in the neighbourhood of ‘eye’ and ‘glasses’. Firth’s infamous quote\nwas that you know a word by the company it keeps. The Distributional hypothesis has been formalised\nby vector semantics and implemented on large corpora of data. Originally, corpora of text were mined\nto build term-term co-occurrence matrices. Nowadays, contextualised deep neural network architectures\nsuch as BERT are used to train the vector statistics. Despite the daily successes of contextualised em-\nbeddings in Natural Language Processing tasks, they do not have an explicit notion of grammatical or\ndiscourse structure. The statistics learnt by engines such as BERT do indeed take some structure into ac-\ncount when training vector embeddings, but they certainly do not represent the grammatical or discourse\nstructures of a piece of text in a vector in the same as they do for words. Compositional distributional se-\nmantics [4, 6] is a ﬁeld of research introduced in an attempt to address this challenge. A line of research\nof this ﬁeld showed that by generalising the notion of vectors to tensors, one can embed both word and\ngrammar. Recent research, has showed how quantum computing devices such as the IBMQ’s quantum\ndevices can be used to learn these tensors as quantum states [14].\nThe links between natural language and quantum physics goes beyond the above. Discovery of sce-\nnarios such as EPR [9] and Bell [5], made quantum mechanics the ﬁrst science to formally deal with\nthe notion of contextuality. Scientists argued that quantum theory should be contextual in order to be\nsound and different mathematical formalisms were introduced to analyse this. Quantum-like contextu-\nality turned out to be, essentially, the failure of having a global explanation to local observations on a\nsystem and the presence of incompatible observables, in the sense that a simultaneous global observation\n24\nSheaves, BERT, and Anaphora\nof all observables are not possible, except in trivial systems. Over the last number of years it has been\nproved that it is this feature of quantum mechanics that is capable of lifting linear computation to uni-\nversal computation [3, 17, 15] and that contextuality is necessary for magic state distillation [12], a key\ncomponent in fault-tolerant quantum computing schemes. Roughly speaking, contextual systems hold\nadditional computational power which is absent in non-contextual systems. It is therefore a reasonable\nconjecture that quantum computers are better at dealing with contextual systems compared to classical\ncomputers. There exist a number of different frameworks for treating contextuality. The sheaf-theoretic\nframework of [2] is amongst the ones that connects the statistical data collected from quantum experi-\nments to the structures deﬁned by quantum mechanics. One of these laws is the no-signalling property,\nThe sheaf-theoretic framework can only formalise contextual scenarios that are no-signalling. However,\nthe examples we are aiming to study are highly unlikely to be non-signalling. We remedy this by using\na recent extension of them to realistic experiments [16], where the authors derive a new inequality to\ncheck the contextuality of systems of measurements with signalling data. In this setting, some degree of\nsignalling becomes possible. We use this inequality to check the contextuality of our examples.\nQuantum-like contextuality has been observed in other ﬁelds, e.g. in behavioural sciences [8] and\nnatural language [18, 19]. In [18, 19] Wang et al showed that pairs of ambiguous words can produce\ncontextual systems that resemble the Bell/CHSH quantum measurement scenario. In this paper, we\npropose a novel linguistic construction that exhibits the contextuality of Coreference ambiguities and\nexemplify it to anaphoric relations. We use BERT to instantiate the construction and extract probability\ndistributions for the instances. Checking the contextuality fraction for these instances showed that it is\npossible to discover examples of anaphoric ambiguity that exhibit quantum-like contextuality properties.\nIn fact, we were able to ﬁnd hundreds of examples after only working with a few pairs of nouns and\ntheir corresponding adjectives, verbs, and prepositional phrases. We hope ﬁnding contextual schema and\ninstances in natural language data help us devise new quantum algorithms that can handle ambiguities\nbetter than classical computers do in natural language processing tasks.\n2\nAmbiguities in Natural Language\nOne of the ambiguities of natural languages comes from the fact that words have different meanings. For\nexample, ‘bat’ has an animal meaning and a sport meaning, ‘plant’ can mean a living organism such as a\ntree or a shrub, or a manufacturing industrial unit, such as a power plant. Word Sense Disambiguation is\na long standing task and evaluation method in Natural Language Processing. Here the goal is to identify\nwhich meaning of a word is being used in a context. Another major ambiguity in natural language\ncomes from the Coreference Resolution task: the task of deciding which discourse entity is referring to\nwhich expression in a context. This is an important part of language engines such as dialogue systems or\nquestion answering. For instance, in an automatic MOT booking system, the NLP engine should know\nwhich car the user is referring to when they say ‘I have a Toyota RAV4 and a Toyota Aqua, it is the\nhybrid one for which I need an MOT today.’.\nDifferent Coreference Resolution algorithms focus on different classes of referring expressions. Pro-\nnouns are in the class of deﬁnite referents and refer to entities that are identiﬁable from the context,\nbecause they have been mentioned before (or after). In the discourse ‘Dawn called the AA. The car had\nbroken down and she had no choice’, the pronoun ‘she’ refers to the deﬁnite noun phrase ‘Dawn’ and\nis an instance of the linguistic phenomena anaphora. Despite presence of linguistics properties in the\nanaphoric relations, such as gender and number agreement and grammatical role and verb preferences,\nthese are ambiguities. In ‘Dawn texted Wendy. Her car had broken down.’, or ‘Dawn phoned Wendy.\nK. I. Lo, M. Sadrzadeh & S. Mansﬁeld\n25\nShe was upset and needed help.’, it is not clear whose car was broken or who was upset. Pronominal\ncoreference relations are many-to-many and the ambiguities arise from them taking complex forms. A\npronoun can refer to multiple referents and multiple pronouns can refer to the same referent. In the dis-\ncourse ‘There is a man carrying a boy. He is tired and worn out. He is snoring.’, the ﬁrst He can refer to\nboth man or boy, but the second He most certainly refers to boy.\nThe different choices that give rise to ambiguities, be it in the choice of the meaning of a word in a\nWord Sense Disambiguation task, or the choice of the potential referent of an expression in a Coreference\nResolution task, give rise to probability distributions. An ambiguous word can be treated as an observable\nwhich can have possible outcomes. In case of meaning ambiguities, these outcomes are possibilities\nover the semantic interpretations of the word. A probability distribution over the outcomes can then be\ndeﬁned using the frequency of occurrences of the possible interpretations in a corpus, e.g. the entire\nEnglish Wikipedia, or in plausibility judgements of human subjects. A single observable is not sufﬁcient\nto support contextuality, instead pairs of ambiguous words are needed. A pair of words is thought of as\na pair of compatible observables measured simultaneously.\nThe work of [18, 19] focused on meaning ambiguities. In this paper, we focus on coreference am-\nbiguities and model contextual features of ambiguities arising from anaphoric reference relations. An\nidentical approach can be taken if the relationship is cataphoric. We treat the pronouns as observables,\nof which the measurement outcomes are the possible referents of each pronoun. In what follows we de-\nscribe the mathematical setting we used, detail how to use it to model ambiguous anaphoric references,\nexplain how we found contextual examples, and present some of the contextual examples.\n3\nSheaf Theoretic Framework\nIn the sheaf-theoretic framework of contextuality [2], a measurement scenario is a tuple ⟨X ,M ,O⟩\nwith the data X , a set of observables, M , a measurement cover, and O, a set of measurement outcomes.\nAn observable in X is a quantity that can be measured to give one of the outcomes in O. A subset\nof simultaneously measurable observables of X is called a measurement context (or simply called a\ncontext). The measurement cover M is a collection of contexts which covers X , i.e. the union of all\ncontexts in M is X .\nFor every measurement context, we can perform a number of repeated simultaneously measurements\non the observables in the context. The gathered statistics can then be used to reconstruct an estimated\njoint probability distribution. Instead, one can also calculate the joint distribution exactly using an un-\nderlying theory of the concerned system, e.g. using Born’s rule in quantum mechanics for a quantum\nsystem.\nAn empirical model refers to a collection of such joint probability distribution for each context in\nthe measurement cover M . By deﬁnition, a subset of observables in X that are not all included in a\nmeasurement context in M cannot be measured simultaneously. Therefore, a joint distribution over the\nsaid observables cannot be empirically estimated. The empirical model of a system fully encapsulates\nwhat is to be known from the system with empirical measurements.\nContextuality comes from the failure of explaining an empirical model in a classically intuitive way:\nassuming that all measurements are just revealing deterministic pre-existing values, in other words, the\nmeasurement outcomes are already ﬁxed when the system was prepared. Thus the randomness comes\nentirely from the system preparation. That means that there is a global joint distribution over all the\nobservables in the scenario, which marginalises to every local joint distribution in the empirical model.\nGiven an empirical model, if such a global distribution does not exist, then we call such empirical model\n26\nSheaves, BERT, and Anaphora\n(0,0)\n(0,1)\n(1,0)\n(1,1)\n(a1,b1)\n1/2\n0\n0\n1/2\n(a1,b2)\n3/8\n1/8\n1/8\n3/8\n(a2,b1)\n3/8\n1/8\n1/8\n3/8\n(a2,b2)\n1/8\n3/8\n3/8\n1/8\n(0,0)\n(0,1)\n(1,0)\n(1,1)\n(a1,b1)\n1\n0\n0\n1\n(a1,b2)\n1\n1\n1\n1\n(a2,b1)\n1\n1\n1\n1\n(a2,b2)\n1\n1\n1\n1\nFigure 1: Empirical tables of measurement scenarios: Bell/CHSH (left), possibilistic Bell/CHSH (right)\ncontextual. Note that such global distribution exists only in theory as there are observables in X that\ncannot be measured simultaneously, unless in trivial scenarios.\nFor readers familiar with sheaf theory, the said criterion for contextuality can be formalised using the\nlanguage of sheaf. Consider the presheaf F which assigns each subset U ∈P(X ) the set of all possible\nprobability distributions on the observables in U. Each set inclusion U ⊆U′, interpreted as an arrow in\nthe category P(X ), is mapped to the marginalisation of distributions on U′ to distributions on U. For\na measurement cover M , an empirical model is just a family of compatible distributions {DC}C∈M. The\npresheaf F is a sheaf if the gluing property is satisﬁed:\nFix a cover M of X . For each family of compatible sections {DC}C∈M , there is a unique\nglobal distribution compatible with every distributions in {DC}C∈M .\nThus a contextual empirical model can only live on a measurement scenario for which the presheaf F is\nnot a sheaf, i.e. not satisfying the gluing property. To say that there is a contextual model that lives on a\nmeasurement scenario is to say that the presheaf F is not a sheaf on the scenario.\nAs an example, the Bell/CHSH scenario involves two experimenters, Alice and Bob, who share\nbetween them a two-qubit quantum state. Alice is allowed to measure her part of the state with one of two\nincompatible observables, a1 and a2, which gives either 0 or 1 as the outcome. Similarly Bob can choose\nto measure his part with observables b1 and b2. Therefore, the Bell/CHSH measurement scenario is fully\ndescribed with the following data: X = {a1,b1,a2,b2}, M = {{a1,b1},{a1,b2},{a2,b1},{a2,b2}}, and\nO = {0,1}. Notice that {a1,a2} and {b1,b2} are not in M as they cannot be measured simultaneously\ndue to their quantum mechanical incompatibility.\nSo far we have speciﬁed what measurements are allowed and what outcomes are possible. Suppose\nnow Alice and Bob repeat the experiment many times and have gathered sufﬁcient statistics to estimate\nthe joint probability distribution for each context in M . Their results can be summarised in a table\nreferred to as an empirical table, see Figure 1, where each row in the table represents a joint distribution\non the context shown in the leftmost column. For instance, the bottom right entry in the table (1/8)\nis the probability of both Alice and Bob getting 1 as their measurement outcomes when Alice chooses\nto measure a2 and Bob chooses to measure b2. Note that the empirical model of the system is entirely\ndescribed by the empirical table.\nOne can show that, using elementary linear algebra, there exists no global distribution over {a1,a2,b1,b2}\nthat marginalises to the 4 local distribution shown in the above empirical table. Therefore, the empirical\nmodel considered here is indeed contextual.\nInstead of probability, one can also consider possibility, i.e. whether an outcome is possible or not.\nIf we use Boolean values to represent possibility, 0 for impossible and 1 for possible, the passage from\nprobability to possibility is just a mapping of all zero probabilities to 0 and all non-zero probabilities\nto 1. This (irreversible) mapping is called a possibilistic collapse of the model. For the empirical table\nof the possibilistic version of Bell/CHSH see Figure 1. One can visualise a possibilistic model with a\nbundle diagram, see Figure 2:\nK. I. Lo, M. Sadrzadeh & S. Mansﬁeld\n27\n•\na1\n•b1\n• a2\n•\nb2\n•\n0\n•\n1\n•0\n•\n• 0\n• 1\n•\n•\n1\n•\na1\n•b1\n• a2\n•\nb2\n•\n0\n•\n1\n•0\n•\n• 0\n• 1\n•\n•\n1\n•\nx1\n•x2\n• x3\n•\n0\n•\n1\n•0\n•\n• 0\n• 1\nFigure 2: Bundle diagrams of possibilistic CHSH (left), PR box (middle), PR prism (right)\nThe base (i.e. the bottom part) of the bundle diagram represents the measurement cover M , where\neach vertex represents an observable in X . An edge is drawn between two observables if they can be\nsimultaneously measured, i.e. in the same measurement context. What sits on top of the base represents\nthe possible outcomes. For instance, the presence of the edge connecting the 0 vertex on top of a1 and\nthe 0 vertex on the observable b1 means that it is possible to get the joint outcome (0,0) when the context\n(a1,b1) is measured.\nA system is logically contextual if the inexistence of a global distribution can already be deduced\nby looking at the supports of the context-wise distributions – or equivalently if the Boolean distributions\nobtained by the possibilistic collapse of the model [2] is contextual. Such systems are said to be possi-\nbilistically contextual. Logical contextuality manifests on a bundle diagram as the failure of extending at\nleast one of the edges to a loop that wraps around the base once. For the possibilistic empirical model of\na PR box, see Figure 2. Note that none of the edges is extendable to a loop that wraps around the base\nonce. Given the possibilistic collapse of an empirical model, if none of the edges can be extendable to a\nloop that wraps around the base once, we say that the model is strongly contextual.1\nProposition 1 The minimal measurement scenario that admits contextuality has the data up to rela-\nbelling: X = {x1,x2,x3}, M = {{x1,x2},{x2,x3},{x1,x3}}, and O = {0,1}.\nThe proof of the above is routine, and so is that of the following:\nProposition 2 The only strongly contextual system, up to relabelling, for the minimal measurement sce-\nnario is where perfect correlation is observed on two of the contexts and perfect anti-correlation is\nobserved on the other one.\nWe call this scenario the PR prism as an analogy to the PR boxes. See Figure 2 for its bundle diagram.\nThe pairs of parallel edges over contexts {x2,x3} and {x3,x1} correspond to perfect correlation and the\npair of crossed edges over context {x1,x2} corresponds to the perfect anti-correlation.\n4\nContextual and Signalling Fractions\nThe contextual fraction (CF) [1] measures the degree of contextuality of a given non-signalling model.\nGiven an empirical model e, the CF of e is deﬁned as the minimum λ such that the following convex\n1Strictly speaking, this deﬁnition of strong contextuality only applies to cyclic scenarios where the base of the bundle\ndiagram forms a loop. Nonetheless, cyclic scenarios are the only scenarios considered in this paper.\n28\nSheaves, BERT, and Anaphora\ndecomposition of e works2:\ne = (1−λ)eNC +λeC,\n(1)\nwhere eNC is a non-contextual (and non-signalling) empirical model and eC is a model allowed to be\ncontextual. For non-signalling models, the criterion of contextuality is just\nCF > 0.\n(2)\nAs eNC is not allowed to be signalling, the CF of a signalling model must be greater than zero. Thus,\ninterpreting CF as a measure of contextuality for signalling models would lead to erroneous conclusions.\nHowever, most models, including the ones considered in this paper, are signalling.\nOne can try to deﬁne a signalling fraction (SF), in the same way CF is deﬁned, to quantify the degree\nof signalling. Given a model e, the SF of e is deﬁned as the minimum µ such that the following convex\ndecomposition of e works:\ne = (1−µ)eNS + µeS,\n(3)\nwhere eNS is a non-signalling empirical model and eS is a model allowed to be signalling.\nIn [16], the signalling fraction (SF) was used to quantify the amount of ﬁctitious contextuality con-\ntributing to the contextual fraction due to signalling in a signalling model. The authors derived a criterion\nof contextuality for signalling models that reads\nCF > 2|M |SF,\n(4)\nwhere |M | denotes the number of measurement contexts. Notice how criterion (4) reduces to the gener-\nalised criterion (2) when SF = 0.\nIn the general case, one would need to solve a linear program to calculate the CF or SF of a model.\nThe calculation is much simpler with models that share the same support as the PR prism. We call these\nmodel PR-like. Such models can always be written as the following empirical table upon relabelling:\n(0,0)\n(0,1)\n(1,0)\n(1,1)\n(x1,x2)\n(1+ε1)/2\n0\n0\n(1−ε1)/2\n(x2,x3)\n(1+ε2)/2\n0\n0\n(1−ε2)/2\n(x3,x1)\n0\n(1+ε3)/2\n(1−ε3)/2\n0\nwhere −1 ≤ε1,ε2,ε3 ≤1. Recall that the model eNC in the convex decomposition (1) is noncontextual\nand non-signalling. For a PR-like model to be non-signalling, one can check that a PR-like model is\nnon-signalling if and only if it is a PR box, i.e. ε1 = ε2 = ε3 = 0. However, the PR box is known to be\n(strongly) contextual. Thus, there does not exist a model eNC that is noncontextual and non-signalling\nfor a PR-like model. Therefore, the SF of PR-like model is always 1.\nThe calculation of SF for PR-like models is also simple. As eNS in the convex decomposition (3) can\nbe contextual but not signalling, eNS must be the PR box, the one with ε1 = ε2 = ε3 = 0. As we cannot\nhave negative probabilities in eS in the decomposition, the coefﬁcient (1−µ) can at most be double the\nsmallest non-zero value in the table, that is, min(1±εi). Thus we have\nSF = 1−min\ni=1,2,3(1±εi) = max\ni=1,2,3|εi|\nfor PR-like models. We will use this result to calculate the SF of the PR-like models we constructed in\nthe following section.\n2Here, we represent the empirical models as empirical tables. Addition and scalar multiplication are then interpreted as\nstandard matrix operations, where the empirical tables are treated as matrices.\nK. I. Lo, M. Sadrzadeh & S. Mansﬁeld\n29\nThere is an O1 and an O2.\n(1) It is X1 and the same one is X2.\n(2) It is X2 and the same one is X3.\n(3) It is X3 and the other one is X1.\nThere is an apple and an strawberry.\n(1) It is red and the same one is round.\n(2) It is round and the same one is sweet.\n(3) It is sweet and the other one is red.\nFigure 3: The PR prism schema and its adjective modiﬁer instance.\nThere is an apple and an strawberry.\n(1) It is on the table and the same one is in\na dish.\n(2) It is in a dish and the same one is in the\nfridge.\n(3) It is in the fridge and the other one is on\nthe table.\nThere is an apple and an strawberry.\n(1) It is being steamed and the same one is\nbeing cooked.\n(2) It is being cooked and the same one is\nbeing chilled.\n(3) It is being chilled and the other one is\nis being steamed.\nFigure 4: Examples of the PR prism schema with verbs (left) and preposition modiﬁers (right)\n5\nPossibilistic Examples\nThe construction used in a previous work on meaning ambiguities [18] was inspired by the Bell/CHSH\nscenario in quantum physics. However, the Bell/CHSH scenario is not minimal so we considered the\nminimal scenario with only 3 observables instead of 4. In our anaphoric setting, the set of possible\ninterpretations is dependent on the ambiguous anaphora, instead of a ﬁxed set of interpretations in the\ncase of meaning ambiguities. This poses a difﬁculty in obtaining probabilities through a corpus. So we\nﬁrst focus on possibility instead of probability. It is much easier to determine if it makes sense for a word\nto be the referent of an anaphora than to determine its likelihood. We constructed a schema (Figure 3)\nthat is modelled by the PR prism on the possibilistic level.\nIn the schema, O1 and O2 are two noun phrases as the candidate referents; X1,X2,X3 are three modi-\nﬁers commonly used to act on O1,O2. The Xi’s are the observables of the scenario.3 Statement (1) and (2)\nabove ensure that the modiﬁers Xi refer to the same referent, thus resulting in perfect correlation (parallel\nedges on the bundle diagram). Statement (3) ensures that the modiﬁers refer to different referents, thus\nresulting in perfect anti-correlation (crossing edges on the bundle diagram). The schema is constructed\nsuch that it is minimal and can immediately be modelled by the PR prism to ensure strong contextuality.\nFor other examples using the same pair of nouns but with instead verbs or prepositional modiﬁers, see\nFigure 4. Other types of modiﬁer are dealt with similarly.\n6\nProbabilistic Examples\nWe considered possibilistic models in the previous section. In this section, we propose a method for\ndeﬁning probability distributions for schemas such as the one considered in the previous sections.\n3The ambiguous anaphoric words in the schema are it and one. We acknowledge that it is controversial to treat the modiﬁers\nXi, instead of the ambiguous words, as observables. The construction of a more natural sounding schema is left for future\nresearch.\n30\nSheaves, BERT, and Anaphora\nWe form a probabilistic model through a contextualised language model such as BERT [7], which\npredicts a masked word (i.e. a blank space) in a sentence. Intuitively speaking, BERT uses the sentence\nas the context to generate a contextualised word embedding for the masked word, which is then measured\nfor similarity against every word in the vocabulary.\nFor example, given a sentence: The goal of life is [MASK]., BERT predicts the most likely word\nin the place of [MASK]. Moreover, BERT assigns a probability score to every word in the vocabulary.\nThe top 5 candidate words predicted by BERT and their probability scores are shown below.\nprobability scores\nlife\nsurvival\nlove\nfreedom\nsimplicity\n···\nProbability\n0.1093\n0.0394\n0.0329\n0.0300\n0.0249\n···\nWe choose to use BERT because it has been providing improved baselines for many NLP tasks. In\nthe following, we will demonstrate how we used BERT to deﬁne a probabilistic model for every schema\nconsidered in the previous section.\nConsider the apple-strawberry example of Section 5. To measure a context, we replace the pronoun\nIt in the sentence with The [MASK]. In practice, we feed the following 3 sentences separately to BERT:\nThere is an apple and an strawberry.\nThe [MASK] is red and the same one is round.\nThere is an apple and an strawberry.\nThe [MASK] is round and the same one is sweet.\nThere is an apple and an strawberry.\nThe [MASK] is sweet and the other one is red.\nBERT will then produce, probabilities Pi (apple) and Pi (strawberry) for the i-th sentence shown\nabove. As BERT gives a probability score to every word in the vocabulary which sum to one, it is almost\nimpossible that Pi (apple)+Pi (strawberry) = 1. We therefore normalise them by the following map4:\nPi (apple) 7→Pi (apple)/(Pi (apple)+Pi (strawberry))\nPi (strawberry) 7→Pi (strawberry)/(Pi (apple)+Pi (strawberry))\nWe will then use the normalised probabilities to construct a PR-like model with empirical table:\n(apple,apple)\n(apple,strawberry)\n(strawberry,apple)\n(strawberry,strawberry)\n(red,round)\nP1 (apple)\n0\n0\nP1 (strawberry)\n(round,sweet)\nP2 (apple)\n0\n0\nP2 (strawberry)\n(sweet,red)\n0\nP3 (apple)\nP3 (strawberry)\n0\nIt should be obvious how this procedure can be used on other examples of the schemas we consid-\nered in the last section. Notice that such an empirical model is non-signalling only if Pi (apple) =\nPi (strawberry) = 0.5 for all i. It is therefore very unlikely that the model is non-signalling. To deter-\nmine whether a signalling model is contextual, we use the inequality criterion of Equation (4). Recall\nthat the CF of a PR-like model is always 1. Also, all the examples we considered in this paper have 3\ncontexts, i.e. |M | = 3. Thus, to tell if such a model is contextual, we just need to check if SF < 1\n6.\nAs the criterion is actually quite strict, it is unlikely for any model constructed in this way to be\ncontextual. We therefore need to create plenty of examples and to be strategic in the way we construct\nthem. Equation (4) for PR-like models indicates that we need to make the probabilities as balanced as\npossible to make SF small. For that, we ﬁrst ﬁx two semantically similar nouns or noun phrases. Then, we\nask BERT to associate them with frequently used modifying adjectives, verbs and prepositional phrases.\nAs a result, we can ensure that the probabilities for the masked word given by BERT will be relatively\nbalanced and thus minimising signalling in the model. The examples that produce contextual empirical\nmodels are presented in the proceedings subsections.\n4The normalisation here is equivalent to limiting the vocabulary to just apple and strawberry when BERT computes the\nprobability scores.\nK. I. Lo, M. Sadrzadeh & S. Mansﬁeld\n31\n0\n1\n6\n2\n6\n3\n6\n4\n6\n5\n6\n1\n0\n200\n400\n600\n800\nSignalling fraction\ncontextual\nnon-contextual\nFigure 5: The distribution of signalling fractions of the models constructed with adjective modiﬁers.\n6.1\nAdjective Modiﬁers\nWe considered 11 pairs of similar noun phrases with between 3 and 18 candidate adjectives respectively.\nA model is constructed by picking a triple of adjective modiﬁers as the observables from the list of\nadjectives shown in the Appendix. This data generated 11,052 empirical models, of which 350 were\ncontextual. Out of the 11 noun pairs considered, (cat, dog), (girl, boy) and (man, woman) produced\nmodels that are contextual. See below for the empirical tables of 2 examples of the contextual models\nwe found.\n(1)\n(cat,cat)\n(cat,dog)\n(dog,cat)\n(dog,dog)\n(good,young)\n0.4941\n0\n0\n0.5059\n(young,small)\n0.4536\n0\n0\n0.5464\n(small,good)\n0\n0.5718\n0.4282\n0\n(2)\n(girl,girl)\n(girl,boy)\n(boy,girl)\n(boy,boy)\n(young,small)\n0.5711\n0\n0\n0.4289\n(small,little)\n0.5655\n0\n0\n0.4345\n(little,young)\n0\n0.5280\n0.4720\n0\nFigure 5 is a histogram of the distribution of signalling fractions of the models constructed using the\nadjective modiﬁers considered. One can see that the majority of the model constructed are non-contextual\nand that the distribution skews towards greater SF.\n6.2\nVerb Phrases\nWe considered 2 pairs of similar noun phrases with 8 and 9 candidate verbs respectively, see the table\nin Appendix for details. This data generated 1,680 empirical models, of which 84 were contextual.\nFor instance, the empirical table of the (apple, strawberry) - (sold, eaten, chilled) contextual model is\npresented below. The histogram of signalling fractions of the models constructed here is shown in the\nleft panel of Figure 6.\n(strawberry,strawberry)\n(strawberry,apple)\n(apple,strawberry)\n(apple,apple)\n(sold,eaten)\n0.4587\n0\n0\n0.5413\n(eaten,chilled)\n0.5621\n0\n0\n0.4379\n(chilled,sold)\n0\n0.4416\n0.5584\n0\n32\nSheaves, BERT, and Anaphora\n0\n1\n6\n2\n6\n3\n6\n4\n6\n5\n6\n1\n0\n50\n100\n150\nSignalling fraction\n0\n1\n6\n2\n6\n3\n6\n4\n6\n5\n6\n1\n0\n20\n40\nSignalling fraction\ncontextual\nnon-contextual\nFigure 6: The distributions of signalling fractions for verbs (left) and prepositions (right).\n6.3\nPrepositional Phrases\nWe considered 2 pairs of noun phrases with 3 and 6 prepositional phrases respectively, see the Appendix.\nThis data generated 252 empirical models, and we found two contextual models for each noun pair. For\nan example empirical see below; see the right panel of Figure 6 for the distribution of signalling fractions.\nHere strawberry is abbreviated as strawb. in the interest of space.\n(apple,apple)\n(apple,strawb.)\n(strawb.,apple)\n(strawb.,strawb.)\n(on the table,in the fridge)\n0.5591\n0\n0\n0.4409\n(in the fridge,in a dish)\n0.5640\n0\n0\n0.4360\n(in a dish,on the table)\n0\n0.4778\n0.5222\n0\n7\nConclusions and Future Work\nCoreference resolution is, amongst other Natural Language Processing tasks, facing the challenge of\nambiguities. Instances of this task require extra resources such as context and world knowledge. In this\npaper, we focused on anaphoric coreference relations and the role of context. We showed how realistic\ncontextual sheaf theoretic models of ambiguous data arising from quantum-inspired scenarios [16] can\nbe used to model these examples. We developed a schema that produces possibilistic contextual models\nanalogous to the PR Box. We mined probabilities for the instances of this schema using the BERT neural\nlanguage model. Our computations showed that it is possible to ﬁnd possibilistic as well as probabilistic\ncontextual examples in natural language data, with only a handful of noun phrases and their modiﬁers.\nFuture works include applying a similar methodology to coreference relations such as indeﬁnite and\ndeﬁnite noun phrases, quantiﬁer scope, and situations requiring world knowledge, e.g. the Winograd\nSchema Challenge [13].\nReferences\n[1] Samson Abramsky, Rui Soares Barbosa & Shane Mansﬁeld (2017): Contextual Fraction as a Measure of\nContextuality. Physical Review Letter 119, p. 050504, doi:10.1103/PhysRevLett.119.050504.\n[2] Samson Abramsky & Adam Brandenburger (2011): The sheaf-theoretic structure of non-locality and contex-\ntuality. New Journal of Physics 13(11), p. 113036, doi:10.1088/1367-2630/13/11/113036.\n[3] Janet Anders & Dan E. Browne (2009): Computational Power of Correlations. Physical Review Letter 102,\np. 050502, doi:10.1103/PhysRevLett.102.050502.\nK. I. Lo, M. Sadrzadeh & S. Mansﬁeld\n33\n[4] Marco Baroni, Raffaella Bernardi & Roberto Zamparelli (2014): Frege in Space: A Program for Composi-\ntional Distributional Semantics. 9, p. 241–346, doi:10.33011/lilt.v9i.1321.\n[5] John S. Bell (1964): On the Einstein Podolsky Rosen paradox. Physics Physique Fizika 1, pp. 195–200,\ndoi:10.1103/PhysicsPhysiqueFizika.1.195.\n[6] Bob Coecke, Mehrnoosh Sadrzadeh & Stephen Clark (2010): Mathematical Foundations for a Compositional\nDistributional Model of Meaning. doi:10.48550/arXiv.1003.4394.\n[7] Jacob Devlin, Ming-Wei Chang, Kenton Lee & Kristina Toutanova (2019): BERT: Pre-training of Deep\nBidirectional Transformers for Language Understanding. In: Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language Technologies,\nVolume 1 (Long and Short Papers), Minneapolis, Minnesota, pp. 4171–4186, doi:10.18653/v1/N19-1423.\n[8] Ehtibar N. Dzhafarov, Janne V. Kujala, Víctor H. Cervantes, Ru Zhang & Matt Jones (2016): On contextu-\nality in behavioural data. Philosophical Transactions of the Royal Society A: Mathematical, Physical and\nEngineering Sciences 374(2068), p. 20150234, doi:10.1098/rsta.2015.0234.\n[9] Albert Einstein, Boris Podolsky & Nathan Rosen (1935): Can Quantum-Mechanical Description of Physical\nReality Be Considered Complete? Phys. Rev. 47, pp. 777–780, doi:10.1103/PhysRev.47.777.\n[10] John R Firth (1957): A synopsis of linguistic theory, 1930-1955. Studies in linguistic analysis.\n[11] Zellig\nS.\nHarris\n(1954):\nDistributional\nStructure.\nWORD\n10(2-3),\npp.\n146–162,\ndoi:10.1080/00437956.1954.11659520.\n[12] M. Howard, J. Wallman, V. Veitch & J. Emerson (2014): Contextuality supplies the ’magic’ for quantum\ncomputation. Nature 510(7505), pp. 351–355, doi:10.1038/nature13460. arXiv:1401.4174.\n[13] Hector J. Levesque, Ernest Davis & Leora Morgenstern (2012): The Winograd Schema Challenge. In: Pro-\nceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reason-\ning, KR’12, AAAI Press, p. 552–561.\n[14] Robin Lorenz,\nAnna Pearson,\nKonstantinos Meichanetzidis,\nDimitri Kartsaklis & Bob Coecke\n(2021):\nQNLP in Practice:\nRunning Compositional Models of Meaning on a Quantum Computer,\ndoi:10.48550/arXiv.2102.12846.\n[15] S. Mansﬁeld & E. Kasheﬁ(2018): Quantum Advantage from Sequential-Transformation Contextuality. Phys-\nical Review Letters 121(23), pp. 1–8, doi:10.1103/PhysRevLett.121.230401. arXiv:1801.08150.\n[16] Damian Markham Pierre-Emmanuel Emariau, Shane Mansﬁeld (2022):\nCorrected Bell and Non-\nContextuality Inequalities for Realistic Experiments. in preparation.\n[17] R. Raussendorf (2013):\nContextuality in measurement-based quantum computation.\nPhysical Re-\nview A - Atomic, Molecular, and Optical Physics 88(2), pp. 1–7, doi:10.1103/PhysRevA.88.022322.\narXiv:0907.5449.\n[18] Daphne Wang, Mehrnoosh Sadrzadeh, Samson Abramsky & Victor Cervantes (2021): On the Quantum-\nlike Contextuality of Ambiguous Phrases. In: Proceedings of the 2021 Workshop on Semantic Spaces at the\nIntersection of NLP, Physics, and Cognitive Science (SemSpace), Association for Computational Linguistics,\nGroningen, The Netherlands, pp. 42–52.\n[19] Daphne Wang, Mehrnoosh Sadrzadeh, Samson Abramsky & Víctor H. Cervantes (2021): Analysing Ambigu-\nous Nouns and Verbs with Quantum Contextuality Tools. Journal of Cognitive Science 22(3), pp. 391–420,\ndoi:10.17791/jcs.2021.22.3.391.\n34\nSheaves, BERT, and Anaphora\n8\nAppendix\n8.1\nData for adjectives\nnoun pair\nadjective modiﬁers\nmodels\ncontextual models\ncat, dog\ncute, furry, lovely, friendly, sweet, big,\nsmall, house, young, large, wild, dead,\nthirsty, hungry, good, gray, black, little\n9792\n344\ngirl, boy\nlittle, beautiful, young, pretty, small,\nbaby, teenage\n420\n1\nman, woman\nyoung, dead, little, big, strange, beautiful,\ntall\n420\n5\nstrawberry, apple\nround, red, sweet, sour, rotten\n120\n0\ndaisy, marigold\nyellow, small, beautiful, everywhere\n48\n0\ndaisy, sunﬂower\nyellow, small, beautiful\n12\n0\nmoth, butterﬂy\nwinged, colorful, light, beautiful\n48\n0\ncucumber, courgette\ngreen, long, juicy, tasty\n48\n0\ndolphin, porpoise\ngrey, wet, slippery, slim\n48\n0\npotato, yam\norange, starchy, healthy, big\n48\n0\ncar, bus\nfast, sturdy, safe, heavy\n48\n0\n8.2\nData for verbs\nnoun pair\nverbs\nmodels\ncontextual models\nstrawberry, apple\nsold,\nbought,\nwashed,\neaten,\nrotten,\ncooked, chilled, steamed\n672\n9\ncat, dog\nfed,\nchased,\nwatched,\nheld,\nhunted,\ntouched, pet, bathed, cleaned\n1008\n75\n8.3\nData for prepositional phrases\nnoun pair\nprepositional phrase modiﬁers\nmodels\ncontextual models\napple, strawberry\non the table, in a dish, in the fridge\n12\n1\nboy, girl\nfrom the town, at the school, near the\nshop, on a bus, across the street, in the\ncity\n240\n1\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG",
    "cs.NE"
  ],
  "published": "2022-08-11",
  "updated": "2022-08-11"
}