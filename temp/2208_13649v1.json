{
  "id": "http://arxiv.org/abs/2208.13649v1",
  "title": "Large-scale photonic natural language processing",
  "authors": [
    "Carlo Michele Valensise",
    "Ivana Grecco",
    "Davide Pierangeli",
    "Claudio Conti"
  ],
  "abstract": "Modern machine learning applications require huge artificial networks\ndemanding in computational power and memory. Light-based platforms promise\nultra-fast and energy-efficient hardware, which may help in realizing\nnext-generation data processing devices. However, current photonic networks are\nlimited by the number of input-output nodes that can be processed in a single\nshot. This restricted network capacity prevents their application to relevant\nlarge-scale problems such as natural language processing. Here, we realize a\nphotonic processor with a capacity exceeding $1.5 \\times 10^{10}$ optical\nnodes, more than one order of magnitude larger than any previous\nimplementation, which enables photonic large-scale text encoding and\nclassification. By exploiting the full three-dimensional structure of the\noptical field propagating in free space, we overcome the interpolation\nthreshold and reach the over-parametrized region of machine learning, a\ncondition that allows high-performance natural language processing with a\nminimal fraction of training points. Our results provide a novel solution to\nscale-up light-driven computing and open the route to photonic language\nprocessing.",
  "text": "Large-scale photonic natural language\nprocessing\nCARLO MICHELE VALENSISE1, IVANA GRECCO2, DAVIDE\nPIERANGELI3,2,1,*, AND CLAUDIO CONTI2,3,1\n1 Enrico Fermi Research Center (CREF), 00184 Rome, Italy\n2 Physics Department, Sapienza University of Rome, 00185 Rome, Italy\n3 Institute for Complex Systems, National Research Council (ISC-CNR), 00185 Rome, Italy\n*davide.pierangeli@roma1.infn.it\nAbstract: Modern machine learning applications require huge artiï¬cial networks demanding in\ncomputational power and memory. Light-based platforms promise ultra-fast and energy-eï¬ƒcient\nhardware, which may help in realizing next-generation data processing devices. However, current\nphotonic networks are limited by the number of input-output nodes that can be processed in a\nsingle shot. This restricted network capacity prevents their application to relevant large-scale\nproblems such as natural language processing. Here, we realize a photonic processor with a\ncapacity exceeding 1.5 Ã— 1010 optical nodes, more than one order of magnitude larger than any\nprevious implementation, which enables photonic large-scale text encoding and classiï¬cation. By\nexploiting the full three-dimensional structure of the optical ï¬eld propagating in free space, we\novercome the interpolation threshold and reach the over-parametrized region of machine learning,\na condition that allows high-performance natural language processing with a minimal fraction of\ntraining points. Our results provide a novel solution to scale-up light-driven computing and open\nthe route to photonic language processing.\nÂ© 2022 Optical Society of America\n1.\nINTRODUCTION\nAdvanced artiï¬cial intelligence systems are becoming extremely demanding in terms of training\ntime and energy consumption [1, 2], since an ever-larger number of trainable parameters is\nrequired to exploit over-parametrization and achieve state-of-the-art performances [3,4]. In turn,\nlarge-scale, energy-eï¬ƒcient computational hardware is becoming a subject of intense interest.\nPhotonic neuromorphic computing systems [5â€“7] oï¬€er large throughput [8] and energetically\neï¬ƒcient [9] hardware accelerators, based on integrated silicon photonic circuits [10â€“14],\nengineered meta-materials [15], or 3D printed diï¬€ractive masks [16, 17]. Other light-based\ncomputing architectures leverage Reservoir Computing (RC) [18] and Extreme Learning Machine\n(ELM) [19] computational paradigms, in which the input data is mapped into a feature space\nthrough a ï¬xed set of random weights and training is performed only on the readout linear\nlayer. Optical reservoir computers [20â€“33] and Photonic Extreme Learning Machines (PELMs)\n[34,35,37,51] applies successfully to various learning tasks, ranging from time series prediction\n[38,39] to image classiï¬cation [40,41]. In spite of the remarkable performances achieved by\nthese architectures, their impact on large-scale problems is limited, mainly due to size constraints.\nHere, we demonstrate photonic machine learning at an ultra-large scale by mapping the optical\noutput layer in the full three-dimensional (3D) structure of the optical ï¬eld. This original approach\noï¬€ers inherent scalability to the optical device and eï¬€ortless access to the over-parametrized\nlearning region. The 3D-PELM that we implement is able to process simultaneously up to 250000\ntotal input-output nodes via spatial light modulation, featuring a total network capacity one order\nof magnitude larger than existing optical reservoir computers. Our large-scale photonic network\nallows us to optically implement a massive text classiï¬cation problem, the sentiment analysis\nof the Image Movie Database (IMDb) [44], and enable, for the ï¬rst time to our knowledge, the\narXiv:2208.13649v1  [cs.ET]  29 Aug 2022\n(A)\ntext\none-hot sparse\ntf-idf sparse\nHadamard\n(B)\noptical encoding\nplane 1\nplane 2\nplane 3\nSLM\nnetwork capacity ğ¶> 1010\nphotonic natural language processing\n(C)\n(D)\nrating\n# users > 106\npostive\nnegative\nFig. 1. Three-dimensional PELM for natural language processing. (A) The text\ndatabase entry is a paragraph of variable length.\nText pre-processing: a sparse\nrepresentation of the input paragraph is mapped into an Hadamard matrix with phase\nvalues in [0, ğœ‹]. (B) The mask is encoded into the optical wavefront by a phase-\nonly spatial light modulator (SLM). Free-space propagation of the optical ï¬eld maps\nthe input data into a 3D intensity distribution (speckle-like volume). (C) Sampling\nthe propagating laser beam in multiple far-ï¬eld planes enables the up-scaling of the\ncorresponding feature space. (D) Intensities picked from all the spatial modes form the\noutput layer H3D that undergoes training via ridge regression. By using three planes\n(ğ‘—= 3) we get a network capacity ğ¶> 1010. The inset example shows a binary text\nclassiï¬cation problem for large-scale rating.\nobservation of the double descent phenomenon [45â€“47] on a photonic computing device. We\ndemonstrate that, thanks to its huge number of optical output nodes, the 3D-PELM successfully\nclassiï¬es text by using only a limited number of training points, realizing energy-eï¬ƒcient\nlarge-scale text processing.\n2.\nRESULTS\nThree-dimensional PELM\nA PELM classiï¬es a dataset with ğ‘points X = [ğ‘‹1, ..., ğ‘‹ğ‘] by mapping the input sample\nğ‘‹ğ‘–âˆˆRğ¿into a high-dimensional feature space through a nonlinear transformation that is\nperformed by a photonic platform [34]. To perform the classiï¬cation, the output matrix H, which\ncontains the measured optical signals, is linearly combined with a set of ğ‘€trainable readout\nweights ğ›½(see Appendix A). In all previous PELM realizations [25,34,35,39,41], the intensities\nstored in H only contain information on the optical ï¬eld at a single spatial or temporal plane.\nHere, to scale up the optical network, we exploit the entire three-dimensional optical ï¬eld. Figure\n1(B) shows a schematic of our 3D-PELM: the photonic network uses as output nodes the full\n3D structure of the optical ï¬eld propagating in free space. The transformation of the input data\nsample into an optical intensity volume occurs through linear wave mixing by coherent free-space\npropagation and intensity detection. Speciï¬cally, the 3D optical mapping reads as\nH3D =\nâˆ‘ï¸\nğ‘—\nH ğ‘—,\n(1)\nH ğ‘—= ğºğ‘—(Mğ‘—expğ‘–(X + W)) ,\n(2)\nwhere M ğ‘—is the transfer matrix that models coherent light propagation to the ğ‘—th detection\nplane, e.g., the discretized diï¬€raction operator. The Mğ‘—have complex coeï¬ƒcients, and thus the\nphotonic scheme implements a complex-valued neural network [42,43]. In Eq. (2) the input\ndataset is encoded by phase modulation, while W is a pre-selected random matrix that embeds the\ninput signal and provides network biases. ğºğ‘—is the response function of the ğ‘—th detector to the\nimpinging light ï¬eld. In experiments, to collect uncorrelated output data H ğ‘—, we employ multiple\ncameras that simultaneously image the intensity in distinct far-ï¬eld planes (see Appendix B).\nThese intensity distributions are uncorrelated in order to acquire non-redundant information.\nTherefore, the speckle-like pattern detected by each camera (Fig. 1(C)) represents the optical\nprojection of the ğ‘‹ğ‘–input data on a distinct portion of the entire feature space.\nOptical encoding of natural language sentences\nThe NLP task we considered is the classiï¬cation of the IMDB dataset, constructed by Maas et\nal. [44]. To encode natural language on the optical setup, we need to develop an optics-speciï¬c\nrepresentation of the text data. Since text classiï¬cation tasks have remained elusive in photonic\nneuromorphic computing, we here introduce the problem. A similar issue is crucial also in digital\nNLP, where the text encoding problem consists in obtaining a numerical representation of the\ninput that is convenient for digital learning architectures [48]. Speciï¬cally, given a vocabulary,\ni.e., the set of all unique words in the corpus, a basic encoding method is the one-hot technique,\nin which each word corresponds to a boolean vector with vocabulary size ğ‘‰. Consequently,\nparagraph of diï¬€erent lengths can be represented by boolean vectors of size ğ‘‰, with the element\nğ‘¥ğ‘˜ğ‘–= 1 that indicates the presence of the ğ‘˜th vocabulary word in the paragraph ğ‘‹ğ‘–[Fig. 1(A)].\nAn input dataset with ğ‘samples, in which each database entry is a text paragraph [see Fig. 1(A)],\nthus becomes a ğ‘Ã— ğ‘‰matrix. The dimension of the single entry ğ‘‹ğ‘–to encode thus scales with\nthe number of words ğ‘‰in the vocabulary (104 âˆ’105). Photonic text processing hence necessitates\nan optical platform able of encoding huge input data. Given the large number of input modes\nğ¿supported by spatial light modulation, our 3D-PELM is the most convenient scheme for the\nscope.\nOptical encoding of natural language in the 3D-PELM requires using a SLM with a ï¬xed\nnumber of input modes for sentences with variable lengths. We can thus follow the one-hot\nmethod employed in digital NLP. We leverage an extension of one-hot encoding, the so-called\ntf-idf representation, and construct the input representation Xtï¬df. In information retrieval, the\ntf-idf(ğ‘–, ğ‘—) statistics reï¬‚ect how important is a word ğ‘˜to a document ğ‘—(frequency ğ‘›ğ‘˜ğ‘—) in a\ncollection of documents. It is deï¬ned as: tf-idf(ğ‘˜, ğ‘—) = ğ‘›ğ‘˜ğ‘—\nğ‘‰Â· log10\n\u0010\nğ‘\nğ‘†ğ‘˜\n\u0011\n, where ğ‘‰is the length\nof a paragraph, and ğ‘†ğ‘˜is the number of sentences containing the ğ‘˜th word. Within the tf-idf\nrepresentation, each paragraph becomes a sparse, real vector [see Fig. 1(A)] whose non-zero\nelements are the tf-idf values of the words composing it. To optically encode these sparse data,\nwe applied to Xtï¬df the Walsh-Hadamard transform (WHT) [49], which decomposes a discrete\nfunction in a superposition of Walsh functions. The transformed dataset XWHT is a dense matrix\n[Fig. 1(A)], which is displayed on the SLM as a phase mask within the [0,ğœ‹] range (X = XWHT\nin Eq. (2)). By exploiting the large number of available input pixels, we encode paragraphs with\na massive size ğ‘‰that contain hundreds of thousands of words.\n+ Ntest\nFig. 2. Photonic NLP. (A-B) Train and test accuracy of the 3D-PELM on the IMDb\ndataset as a function of the number of output channels. The shaded area corresponds\nto the over-parametrized region. The conï¬guration in (B) allows reaching very high\naccuracy in the over-parametrized region with a dataset limited to ğ‘train = 1186 training\npoints. In (A) the same accuracy is reached in the under-parametrized region with\nğ‘train = 12278. Black horizontal lines correspond to the maximum test accuracy\nachieved (0.77). (C) IMDb classiï¬cation accuracy by varying the number of features ğ‘€\nand training dataset size ğ‘train. The boundary between the under and over-parametrized\nregion (interpolation threshold), ğ‘train = ğ‘€, is characterized by a sharp accuracy drop\n(cyan contour line).\nObservation of the photonic double descent\nMachine learning models with a very large number of trainable parameters show unique features\nwith respect to smaller models, such as the double descent phenomenon. This eï¬€ect is a resonance\nin the neural network performance, ruled by the ratio between the number of trainable parameters\nğ‘€and the number of training points ğ‘train. In the under-parametrized regime (ğ‘€< ğ‘train), good\nperformances are obtained by balancing model bias and variance. As ğ‘€grows, models tend\nto overï¬t training data, and prediction performances get worse until the interpolation threshold\n(ğ‘€= ğ‘train) is reached, a point where the model optimally interpolates the training data and\nthe prediction error is maximum. Beyond this resonance, in the over-parametrized regime, the\nmodel keeps interpolating training points, but performances on the test set reach the global\noptimum [50].\nWe experimentally implement photonic NLP and investigate the double descent eï¬€ect on our\nlarge-scale 3D-PELM. Speciï¬cally, we analyze the classiï¬cation accuracy for the IMDb task\n(Appendix D) as a function of the features ğ‘€and training set size ğ‘train. In Figure 2(A) we\nreport the observation of the double descent. We observe a dip in test accuracy as the number of\nchannels ğ‘€reaches the number of training points ğ‘train. Beyond this resonance, also known as\nFig. 3. Performances at ultra-large scale. (A-C) Accuracy as a function of ğ‘€for\ndiï¬€erent input sizes ğ¿. In all cases, the 3D-PELM performance saturates in the\nover-parameterized region reaching a plateau. A linear ï¬t of the data preceding the\nplateau shows that the onset of the saturation is faster for datasets with a larger input\nspace. The corresponding angular coeï¬ƒcient ğ‘šis inset in each panel. (D) Test accuracy\nvarying the training set size, for ğ‘€= 0.8 Ã— 105 and ğ‘€= 1.2 Ã— 105.\ninterpolation threshold, we ï¬nd the over-parametrized region in which maximum accuracy on the\ntraining set is achieved. The behavior is obtained via training on ğ‘train â‰ƒ1.2 Ã— 104 examples and\nusing ï¬xed train/test split ratio of 0.67/0.33. In this case, the larger classiï¬cation accuracy is\nfound in the under-parametrized region (0.77). Conversely, in Figure 2(B), we consider a much\nsmaller number of training points, ğ‘train â‰ƒ103. Remarkably, we reach the same optimal accuracy\ndespite we are using only a fraction of the available training points. This observation reveals\na particularly favourable learning region of the 3D-PELM in which only a reduced number of\ntraining points is required to reach high-accuracy levels. In fact, from the operational standpoint,\nit is much more eï¬ƒcient to measure in parallel a large number of modes rather than sequentially\nprocessing many training examples. In Figure 2(C) we report the full dynamics of the double\ndescent phenomenon, by continuously varying both ğ‘€and ğ‘train. We observe the accuracy dip\nshifts with a constant velocity. This result shows the existence of an optimal learning region that\nis accessible on the 3D-PELM thanks to its large number of photonic nodes.\nNLP at ultra-large scale\nThe observed operational advantage of the over-parametrized region indicates that by further\nincreasing the number of output modes one can increase training eï¬€ectiveness and/or performances\n[3]. In our 3D-PELM we reached ğ‘€= 120000 readout channels that are independent from\neach other. We also considered larger input spaces, extending the vocabulary so as to include\nthe whole set of words in the corpus (ğ‘‰â‰ƒ217). Figure 3(A) shows that the test accuracy\nreaches a plateau as ğ‘€increases in the over-parametrized region. Saturation indicates that all the\nessential information encoded within the optical ï¬eld has been extracted through the available\nchannels. However, we observe a change in the performance as we employ more input features\nWorking principle\nM\nL\nC\nMachine learning task\nRef.\nTime-multiplexed cavity\n1400\n7129\n107\nRegression\n[39]\nAmplitude modulation\n16384\n2000\n108\nHuman action recognition\n[27]\nFrequency multiplexing\n200\n640\n105\nTime series recovery\n[41]\nOptical multiple scattering\n50000\n64\n106\nChaotic series prediction\n[38]\nAmplitude Fourier filtering\n1024\n43263\n107\nImage classification\n[30]\nMultimode Fiber\n240\n240\n105\nClassification, Regression\n[35]\nFree-space propagation\n6400\n784\n106\nClassification, Regression\n[34]\n3D optical field\n120000\n131044\n1010\nNatural Language\nProcessing\n3D-PELM\nTable 1. Maximum network capacity of current photonic neuromorphic computing\nhardware.\nğ¿, Fig. 3(B-C). To estimate the rate by which performance improves as more channels were\nused for training, we estimate the angular coeï¬ƒcient ğ‘šof the linear growth that precedes the\nplateau. Although the onset of saturation can be estimated using diverse criteria, and ğ‘švaries\ndepending on the measured range, its trend when increasing ğ¿remain unaltered. We note a\nrelevant enhancement of ğ‘šfor ğ¿= 362 Ã— 362, which indicates that PELMs featuring larger input\nspaces are able to reach optimal performances with a lower number of parameters. Figure 3(D)\nreports the accuracy as a function of the training-test split ratio (keeping ï¬xed ğ‘train = 6.7 Ã— 103)\nfor ğ‘€= 0.8 Ã— 105 and ğ‘€= 1.2 Ã— 105. Importantly, a limited number of examples (âˆ¼20%) is\nenough to reach maximum accuracy in the over-parametrized region.\nOptical network capacity\nTo establish a comparison among the various photonic neuromorphic computing devices, we\nintroduce the optical network capacity as a useful ingredient related to the over-parametrization\ncontext. We deï¬ne the capacity C of a generic optical neural network as the product between the\nnumber of input and output nodes that can be processed in a single iteration, C = ğ¿Ã— ğ‘€. This\nquantity gives direct information on the kind of large-scale problems that can be implemented\non the optical setup. It depends only the number of controllable nodes, which is the quantity\nthat is believed to play the main role in big data processing [3]. Speciï¬cally, ğ¿sets the size\nof the dataset that can be encoded, while ğ‘€reï¬‚ects the embedding capacity of the network,\nas larger dataset necessitate larger feature spaces to be learned. Moreover, C also furnishes an\nindication on how far is the over-parametrized regime for a given task. Useful over-parametrized\nconditions can be reached only if ğ¶â‰«ğ‘Ã— ğ¿. We remark that the capacity is not a measure\nof the processor accuracy. It is instead a useful quantity to compare the scalability of diï¬€erent\nphotonic computing devices.\nIn Tab. 1 we report the optical network capacity for various photonic processors that have been\nrecently demonstrated. We focus on photonic platforms that exploit RC and ELM paradigms, since\nthese devices are suitable for big data processing and may present the so-called photonic advantage\nat a large scale [51]. Our 3D-PELM has a record capacity C = 362 Ã— 362 Ã— 120000 â‰ƒ1.5 Ã— 1010,\nmore than one order of magnitude larger than any other optical processor. Moreover, while\nincreasing the capacity is challenging on many optical reservoir computers, our 3D-PELM can\nbe further scaled up by simply enlarging the measured volume of the optical ï¬eld.\n(A)\n3D-PELM\ndevice\n3D-PELM\nnumerics\n8-bit\nNtrain=6700\nNtrain= 1500\n(B)\nRP\nSVM\nCNN\nunder-parametrized\nover-parametrized\n(A)\n8-bit\n8-bit\n8-bit\nunder-parametrized\nover-parametrized\n0.75\n0.74\nFig. 4. Analysis of the IMDb accuracy. (A-B) The comparison report the accuracy\nfor the experimental device (3D-PELM device), the simulated device (3D-PELM\nnumerics), the random projection method with ridge regression (RP), the support\nvector machine (SVM) and a convolutional nueral network (CNN) in both the under-\nparameterized (ğ‘€= 1 Ã— 103) and over-parametrized (ğ‘€= 4 Ã— 104 ) regime, for (A)\nğ‘train = 6700, and (B) ğ‘train = 1500. 8-bit numerical results, when applicable, refer to\nthe over-parametrized regime.\nComparison with digital machine learning\nTo further validate the capability of our photonic setup for text processing, we compare the\naccuracy of our 3D-PELM with various general-purpose digital neural networks on the IMDb task.\nTo underline the overall impact of the over-parameterization on the performance, we consider two\nopposite parametrization regimes, respectively ğ‘€= 1 Ã— 103 and ğ‘€= 4 Ã— 104, and two distinct\ncondition for the dataset size, ğ‘train = 6700 [Fig. 4(A)] and ğ‘train = 1500 [Fig. 4(B)]. Since the\nlearning principle of the 3D-PELM is based on kernel methods (see Ref. [34]), we implement\na support vector machine (SVM) and a ridge regression based on nonlinear random projetions\n(RP) [25] as representative models of the kernel algorithms class. The input for the SVM and\nthe RP is the tï¬df-encoded dataset, but no signiï¬cant diï¬€erences are found using the Hadamard\ndataset. We also simulate the 3D-PELM, i.e., we evaluate our photonic scheme by using Eq. (2)\nto generate the output data. A convolutional neural network (CNN) with the same number of\ntrainable weights is used as an additional benchmark model. Details on the various digital models\nare reported in Appendix E. The results, for a split ratio ğ‘train/ğ‘test = 0.67/0.33, are shown\nin Figure 4. Overall, we observe that the photonic device performs sentiment analysis on the\nIMDb with an accuracy comparable with standard digital methods. The SVM sets the maximum\nexpected accuracy (0.86). The device over-parametrized accuracy (0.75 for ğ‘train = 6700) is\nmainly limited by the limited precision of the optical components and noise, and could be\nenhanced up to 0.83 (3D-PELM numerics) by using a 64-bit camera. In fact, when operating\nwith 8-bit precision, both the simulated 3D-PELM and the RP model achieves performances\nthat agree well with the experiments. Interestingly, Fig. 4(B) indicates that, for a limited set\nof training samples, the 3D-PELM surpasses the SVM and also the CNN. This points out an\nadditional advantage that the photonic setup achieves thanks to over-parametrization. Not only\nits accuracy is improved with respect the standard under-parametrized regime, but the device can\noperates eï¬€ectively in conditions where digital models are less accurate.\n3.\nDISCUSSION\nWe have reported the ï¬rst photonic implementation of natural language processing by performing\nsentiment analysis on the IMBd dataset. Our results demonstrate the feasibility of modern\nlarge-scale computing tasks in photonic hardware, and can be potentially improved both in terms\nof performance, via low-noise high-resolution cameras and more complex encoding/training\nalgorithms, and applications. Further developments include the implementation of advanced\ntasks such as multiclass sentiment analysis, which allows discriminating positive and negative\nsentences into diï¬€erent levels. Moreover, using diï¬€erent datasets such as the Stanford Sentiment\nTreebank (SST-5), we could train our 3D-PELM for providing ratings. On the other hand,\nour versatile optical setting may allow implementing alternative strategies for photonic NLP,\nthese including dimensionality reduction of the input data via optical random projection [52].\nAn optical scheme that preserves the sequential nature of language may be also conceived by\nintroducing recurrent mechanisms in our 3D-PELM. Another interesting direction is developing\nspeciï¬c encoding schemes for representing text in the optical domain. Viable approaches includes\nadapting bi-dimensional text representations such as Quick-Response (QR) codes. Furthermore,\nby following the concept of word embedding used in digital NLP [53], photonic hardware may be\nused to learn a purely optical word embedding, including semantics, word ordering, and syntax.\nIn conclusion, modern machine learning architectures rely on over-parametrization to reach\nthe global optimum of objective functions. However, as better performances are associated with\nlarger training sets, to reach an over-parametrized regime the number of adjustable parameters has\nto grow accordingly, requiring in turn longer training times and more energy consumption [54].\nThis trend is evident in NLP: the state-of-the-art NLP model, GPT-3 [55], features 175 billions\nof parameters, in line with the exponential growth in the number of parameters of latest NLP\nmodels [1], and requires a dedicated supercomputing hardware for training. On the other hand,\nachieving over-parametrization for large-scale problems is challenging in photonic computing.\nHere, we realize a novel photonic computing device that, thanks to its huge network capacity,\nnaturally operates in the over-parametrized region. The 3D-PELM is a very promising solution\nfor developing a fully-scalable photonic learning platform. Our photonic processor enables the\nï¬rst link between NLP and optical computing hardware, opening a new vibrant research stream\ntowards fast and energetically eï¬ƒcient artiï¬cial intelligence tools.\nAPPENDIX A: PELM framework\nIn ELMs a dataset with ğ‘data points X = [(ğ‘‹1, ğ‘¦1), . . . , (ğ‘‹ğ‘, ğ‘¦ğ‘)], with (ğ‘‹ğ‘–, ğ‘¦ğ‘–) âˆˆRğ¿Ã— R, is\nmapped into a higher-dimensional feature space through a nonlinear transformation ğ‘”(X), yielding\nthe hidden-layer output matrix H = [ğ‘”(ğ‘‹1), . . . , ğ‘”(ğ‘‹ğ‘)], with ğ‘”(ğ‘‹ğ‘–) âˆˆRğ‘€. A set of weights\nğ›½is learned via ridge regression such that the linear combination ËœY = Hğ›½well approximates\nthe true label vector Y = [ğ‘¦1, . . . , ğ‘¦ğ‘]. An explicit solution is ğ›½= (Hğ‘‡H + ğœ†I)âˆ’1 Hğ‘‡Y\nwhere ğœ†is the regularization parameter, I the identity. The use of ridge regression allows\nreducing at minimum the training costs, which is crucial in applications requiring fast and\nreconï¬gurable learning. In a free-space PELM, the nonlinear mapping of input data is realized\nby a combination of free-space optical propagation and intensity detection [34]. The speckle-like\npattern detected by a camera forms the nonlinear features of the input sample. The optical\nmapping reads as H = ğº[M expğ‘–(X + W)], where the input dataset X is phase-encoded via\nspatial light modulation. W is the embedding matrix, ğºthe detector response function, and M\nthe discrete Fourier transform that models propagation to the focal plane. For more details on the\nPELM architecture and its working principle see Ref. [34].\nAPPENDIX B: Experimental setup\nThe optical setup of the 3D-PELM is sketched in Figure 1(B). A CW laser beam (532 nm, 100\nmW) is expanded and collimated onto a phase-only SLM (Hamamatsu X13138, 1280 Ã— 1024\npixels, 60 Hz, 8 bits), that encodes data on the optical wavefront. The SLM operates in the\n[0, 2ğœ‹] interval with a linear response function. Both the input and the embedding signal are\nencoded within the [0, ğœ‹] range and superimposed. After free-space propagation through a lens\n( ğ‘“= 150mm), the far-ï¬eld three-dimensional intensity distribution is accessed simultaneously\nby three separated imaging systems and detected by three cameras (Basler Ace 2 Pro, 1920\nÃ— 1200 pixels, 12 bits). The speckle-like ï¬eld spatially decorrelates during propagation; the\ntransverse intensity is transformed in a random way from one plane to the other, provided that\nthese planes are at distances larger than the longitudinal ï¬eld correlation length. To carry out\nthe measurements, the propagating beam is divided by a series of beam splitters into separated\nimaging paths with diï¬€erent tunable optical paths. The far-ï¬eld planes are selected in order to\nsample three speckle-like distribution having a negligible mutual intensity correlation. This is\nconï¬rmed by intensity correlation measurements. Every additional plane contains additional\ninformation. In fact, keeping ï¬xed ğ‘€, we ï¬nd an improvement in the classiï¬cation accuracy\nwhen using three far-ï¬eld planes instead of a single intensity distribution. In this condition, each\ncamera maps a distinct portion of the high-dimensional feature space in which the input ï¬eld is\nprojected.\nThe measured set of speckle-like patterns is elaborated on a conventional computer. Speckle\ngrains typically extend over adjacent pixels [Fig. 1(C)]. To avoid spatial correlations within the\nsingle speckle pattern, pixels are grouped into square modes (channels) and the average intensity\non each channels forms the output signals.\nAPPENDIX C: 3D-PELM training\nTraining operates by loading the randomly-ordered input dataset on the SLM and measuring three\nspeckle-like intensity distributions for each input sample (paragraph). From the acquired signals\nwe randomly select ğ‘€of the available channels, and we use the corresponding ğ‘€intensity\nvalues to form the output dataset. This dataset is split randomly into a training and test dataset\nby using a split ratio ğ‘train/ğ‘test = 0.67/0.33, which is kept ï¬xed throughout the analysis. All\nthe classiï¬cation accuracies we obtained refer to this hyperparameter. The training dataset is\nthe output matrix H used for training (see Appendix A). Since our task corresponds to a binary\nclassiï¬cation problem, the target labels are ğ‘¦ğ‘–âˆˆ{0, 1}. According to the PELM framework,\ntraining by ridge regression consists in solving the equation for the ğ›½vector. This matrix inversion\nis performed using the ML Python Library Sci-kit learn. The regularization parameter ğœ†is varied\nin the [10âˆ’4, 102] range. As its value does not inï¬‚uence considerably the testing accuracy, we use\nğœ†= 10âˆ’4. Given a predicted output Ë†ğ‘¦ğ‘–, the predicted label is given by Ëœğ‘¦ğ‘–= Î˜( Ë†ğ‘¦ğ‘–âˆ’0.5), where Î˜\nis the Heaviside step function. Text classiï¬cation performances are evaluated via the accuracy\nÃ\nğ‘–[ğ‘¦ğ‘–= Ëœğ‘¦ğ‘–] /ğ‘, where [Â·] are the Iverson bracket deï¬ned as [ğ‘ƒ] = 1 if ğ‘ƒis true and 0 otherwise.\nAPPENDIX D: NLP task, text pre-processing and optical encoding\nWe consider the IMDb dataset [44], a widely used benchmark for polarity-based text classiï¬cation\n[56]. The dataset consists of 5 Ã— 104 movie reviews, each one forming the ğ‘–-th input data\nsample. Each review is made of a paragraph consisting of multiple sentences, and expresses\nan overall positive or negative sentiment (target variable). This sentiment analysis task hence\nconsists in a large-scale binary classiï¬cation. To implement the problem, the whole set of IMDb\nsentences is pre-processed by removing special characters (e.g. html), lowercasing, removing\nstop words and lemmatizing. The length of the resulting vector can be varied by neglecting\nwords that appears in the corpus with a frequency lower than a given threshold. To compute the\nWalsh-Hadamard transform and obtain a dense text representation, zero-padding is used to reach\na vector length ğ‘‘=\n\u0006\nlog2 ğ‘‰\n\u0007. For example, results in Fig. 2 refer to data with ğ‘‰= 104 that are\npadded to ğ¿= 214 = 16384 and reshaped as a 128 Ã— 128 square matrix, while the full vocabulary\n(ğ‘‰= 131044) requires zero-padding and paragraphs are arranged on 362 Ã— 362 input modes (Fig.\n3). After WHT computation, the values are normalized in the [0, ğœ‹] range and loaded on the\nSLM. Each element of the input XWHT is displayed onto a square block of SLM pixels. The\nembedding matrix W is a uniformly distributed random matrix for all the experiments. Its values\nğ‘¤ğ‘–ğ‘—are selected in [0, ğœ‹] before the training and kept ï¬xed for a given photonic computation.\nAPPENDIX E: Digital machine learning\nThe 3D-PELM is numerically simulated by following the optical mapping model in Eq. (1) (see\nalso Ref. [34]). Data encoding and training operates in the same way as the photonic device,\nand the output matrix is computed by using Eq. (2) with ğº(ğ‘§) = |ğ‘§|2 (quadratic nonlinearity).\nIn the RP model, data projection in the feature space is obtained by matrix multiplication with\na real-valued uniformly-distributed random matrix and using a quadratic activation function.\nTraining occurs by ridge regression. For simulating the 8-bit machines, the input data and\nthe output values forming the linear readout layer are properly discretized to values with 8-bit\nprecision. The SVM is a binary classiï¬er and thus it is especially suited for the IMDb task. We use\nthe Sci-kit learn built-in function on the tï¬d-processed dataset and the over-parametrized regime\nis evaluated by using ğ‘€= 103. The CNN is composed by four convolutional layer with nonlinear\nactivation and a fully connected layer. The CNN scheme is designed to have ğ‘€total nodes, and\nits accuracy does not depend signiï¬catively on the network details and hyperparameters.\nFunding. We acknowledge funding from the Italian Ministry of Education, University and\nResearch (PRIN PELM 20177PSCKT), Sapienza Research, and Enrico Fermi Research Center\n(CREF).\nAuthor Contributions. D.P. and C.C. conceived the research. C.M.V. proposed application\nto NLP. D.P. developed the 3D photonic network. I.G. and D.P. carried out experimental\nmeasurements. C.M.V. and I.G. performed data analysis. D.P and C.C. co-supervised the project.\nAll authors contributed to the manuscript.\nAcknowledgments. We thank I. MD Deen, V.H. Santos, and F. Farrelly for technical support\nin the laboratory.\nDisclosures. The authors declare no conï¬‚icts of interest.\nData availability. The data that support the results presented in this study are available from\nthe corresponding author upon reasonable request.\nCode availability. The codes developed within this research are available from the corre-\nsponding author upon reasonable request.\nReferences\n1.\nD. Narayanan et al., Eï¬ƒcient large-scale language model training on GPU clusters using megatron-LM,\narXiv:2104.04473 (2021).\n2.\nE. Strubell, A. Ganesh, and A. McCallum, Energy and policy considerations for modern deep learning research, Proc.\nAAAI Conf. on Artif. Intell. 34, 13693â€“13696 (2020).\n3.\nA. Chatelain, A. Djeghri, D. Hesslow, J. Launay, and I. Poli, Is the number of trainable parameters all that actually\nmatters?, arXiv:2109.11928 (2021).\n4.\nN.C. Thompson, K. Greenewald, K. Lee, and G.F. Manso, The computational limits of deep learning, arXiv:2007.05558\n(2020).\n5.\nG. Wetzstein, A. Ozcan, S. Gigan, S. Fan, D. Englund, M. SoljaÄiÄ‡, C. Denz, D.A.B. Miller and D. Psaltis, Inference\nin artiï¬cial intelligence with deep optics and photonics, Nature 588, 39-47 (2020).\n6.\nB.J. Shastri, A.N. Tait, T.F. de Lima, W.H.P. Pernice, H. Bhaskaran, C.D. Wright, and P.R. Prucnal, Photonics for\nartiï¬cial intelligence and neuromorphic computing, Nat. Photonics 15, 102â€“114 (2021).\n7.\nH. Zhou et al., Photonic matrix multiplication lights up photonic accelerator and beyond, Light Sci. Appl. 11, 1-21\n(2022).\n8.\nX. Xu, M. Tan, B. Corcoran, J. Wu, A. Boes, T.G. Nguyen, S.T. Chu, B.E. Little, D.G. Hicks, R. Morandotti, A.\nMitchell, and D.J. Moss, 11 TOPS photonic convolutional accelerator for optical neural networks, Nature 589, 44-51\n(2021).\n9.\nT. Wang, S.-Y. Ma, L.G. Wright, T. Onodera, B. Richard, and P.L. McMahon, An optical neural network using less\nthan 1 photon per multiplication, Nat. Commun. 13, 1-8 (2022).\n10. Y. Shen, N.C. Harris, S. Skirlo, M. Prabhu, T. Baehr-Jones, M. Hochberg, X. Sun, S. Zhao, H. Larochelle, D. Englund,\nand M. Soljacic, Deep learning with coherent nanophotonic circuits, Nat. Photon. 11, 441â€“446 (2017).\n11. A.N. Tait , T.F. de Lima, E. Zhou, A.X. Wu, M-A. Nahmias, B.J. Shastri, P.R. Prucnal, Neuromorphic photonic\nnetworks using silicon photonic weight banks, Sci. Rep. 7, 7430 (2017).\n12. J. Feldmann, N. Youngblood, C.D. Wright, H. Bhaskaran and W.H.P. Pernice, All-optical spiking neurosynaptic\nnetworks with self-learning capabilities, Nature 569, 208-214 (2019).\n13. F. Stelzer, A. RÃ¶hm, R. Vicente, I. Fischer, and S. Yanchuk, Deep neural networks using a single neuron: folded-in-time\narchitecture using feedback-modulated delay loops,Nat. Commun. 12 (2021).\n14. J. Feldmann, N. Youngblood, M. Karpov, H. Gehring, X. Li, M. Stappers, M. Le Gallo, X. Fu, A. Lukashchuk, A.S.\nRaja, J. Liu, C.D. Wright, A. Sebastian, T.J. Kippenberg, W.H.P. Pernice, and H. Bhaskaran, Parallel convolutional\nprocessing using an integrated photonic tensor core, Nature 589, 52-58 (2021).\n15. N. Mohammadi Estakhri, B. Edwards, and N. Engheta, Inverse-designed metastructures that solve equations, Science\n363, 1333 (2019).\n16. X. Lin, Y. Rivenson, N. T. Yardimci, M. Veli, Y. Luo, M. Jarrahi, and A. Ozcan, All-optical machine learning using\ndiï¬€ractive deep neural networks, Science 361, 1004â€“1008 (2018).\n17. T. Zhou, X. Lin, J. Wu, Y. Chen, H. Xie, Y. Li, J. Fan, H. Wu, L. Fang, and Q. Dai, Large-scale neuromorphic\noptoelectronic computing with a reconï¬gurable diï¬€ractive processing unit, Nat. Photonics 15, 367â€“373 (2021).\n18. D. Verstraeten, B. Schrauwen, M. Dâ€™Haene, and D. Stroobandt, An experimental uniï¬cation of reservoir computing\nmethods, Neural Networks 20, 391â€“403 (2007).\n19. G.B. Huang, H. Zhou, X. Ding, and R.Zhang, Extreme Learning Machine for Regression and Multiclass Classiï¬cation,\nIEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics) 42, 513-529 (2012).\n20. G. Van der Sande, D. Brunner, and M.C. Soriano, Advances in photonic reservoir computing, Nanophotonics 6,\n561â€“576 (2017).\n21. D. Brunner, M.C. Soriano, C. Mirasso, I. Fischer, Parallel photonic information processing at gigabyte per second\ndata rates using transient states, Nat. Commun. 4, 1364 (2013).\n22. Q. Vinckier, F. Duport, A. Smerieri, K. Vandoorne, P. Bienstman, M. Haelterman, and S. Massar, High-Performance\nPhotonic Reservoir Computer Based on a Coherently Driven Passive Cavity, Optica 2, 438 (2015).\n23. L. Larger, A. BaylÃ³n-Fuentes, R. Martinenghi, V.S. Udaltsov, Y.K. Chembo, and M. Jacquot, High-speed photonic\nreservoir computing using a time-delay based architecture: million words per second classiï¬cation, Phys. Rev. X 7,\n011015 (2017).\n24. D. Ballarini et al., Polaritonic neuromorphic computing outperforms linear classiï¬ers, Nano Lett.20, 3506â€“3512\n(2020).\n25. A. Saade, F. Caltagirone, I. Carron , L. Daudet, A. Dremeau, S. Gigan, F. Krzakala, Random projections through\nmultiple optical scattering: approximating kernels at the speed of light, IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP) 6215â€“6219 (2016).\n26. J. Bueno, S. Maktoobi, L. Froehly, I. Fischer, M. Jacquot, L. Larger, and D. Brunner, Reinforcement learning in a\nlarge-scale photonic recurrent neural network, Optica 5, 756â€“760 (2018).\n27. P. Antonik, N. Marsal, D. Brunner, and D. Rontani, Human action recognition with a large-scale brain-inspired\nphotonic computer, Nat. Mach. Intell. 1, 530â€“537 (2019).\n28. A. RÃ¶hm, L. Jaurigue, and K. LÃ¼dge, Reservoir Computing Using Laser Networks, IEEE J. Sel. Top. Quantum\nElectron. 26, 1 (2020).\n29. U. Paudel, M. Luengo-Kovac, J. Pilawa, T.J. Shaw, and G.C. Valley, Classiï¬cation of time-domain waveforms using a\nspeckle-based optical reservoir computer, Opt. Express 28, 1225 (2020).\n30. M. Miscuglio, Z. Hu, S. Li, J. George, R. Capanna, P.M. Bardet, P. Gupta, and V.J. Sorger, Massively Parallel\nAmplitude-Only Fourier Neural Network, Optica 7, 1812 (2020).\n31. S. Sunada and A. Uchida, Photonic neural ï¬eld on a silicon chip: large-scale, high-speed neuro-inspired computing\nand sensing, Optica 8, 1388 (2021).\n32. M. Borghi, S. Biasi, and L. Pavesi, Reservoir computing based on a silicon microring and time multiplexing for\nbinary and analog operations, Sci. Rep. 11, 15642 (2021).\n33. X. Porte, A. Skalli, N. Haghighi, S. Reitzenstein, J. A. Lott, and D. Brunner, A complete, parallel and autonomous\nphotonic neural network in a semiconductor multimode laser, J. Physics: Photonics 3, 024017 (2021).\n34. D. Pierangeli, G. Marcucci, and C. Conti, Photonic extreme learning machine by free-space optical propagation,\nPhotonics Res. 9, 1446 (2021).\n35. U. TeÄŸin, M. YÄ±ldÄ±rÄ±m, Ä°. OÄŸuz, C. Moser, and D. Psaltis, Scalable optical learning operator, Nat. Comput. Sci. 1,\n542â€“549 (2021).\n36. D. Pierangeli, G. Marcucci, and C. Conti, (2021, August). Neuromorphic computing device using optical shock\nwaves, In OSA Nonlinear Optics 2021 (pp. NTh1A-3), OSA Technical Digest (Optica Publishing Group, 2021).\n37. Z. Denis, I. Favero , and C. Ciuti, Photonic Kernel Machine Learning for Ultrafast Spectral Analysis, Phys. Rev.\nAppl.17, 034077 (2022).\n38. M. Rafayelyan, J. Dong, Y. Tan, F. Krzakala, and S. Gigan, Large-Scale Optical Reservoir Computing for\nSpatiotemporal Chaotic Systems Prediction, Phys. Rev. X 10, 041037 (2020).\n39. S. OrtÃ­n, M. C. Soriano, L. Pesquera, D. Brunner, D. San-MartÃ­n, I. Fischer, C. R. Mirasso, and J. M. GutiÃ©rrez, A\nuniï¬ed framework for reservoir computing and extreme learning machines based on a single time-delayed neuron,\nSci. Reports 5 (2015).\n40. R. Mirek, A. Opala, P. Comaron, M. Furman, M. KrÃ³l, K. Tyszka, B. SeredyÅ„ski, D. Ballarini, D. Sanvitto, T.C.H.\nLiew, W. Pacuski, J. Suï¬€czyÅ„ski, J. Szczytko, M. Matuszewski, and B. PiÄ™tka, Neuromorphic binarized polariton\nnetworks, Nano Lett. 21, 3715â€“3720 (2021).\n41. A. Lupo and S. Massar, Parallel extreme learning machines based on frequency multiplexing, Appl. Sci. 12, 214\n(2021).\n42. G. Marcucci, D. Pierangeli, and C. Conti, Theory of neuromorphic computing by waves: machine learning by rogue\nwaves, dispersive shocks, and solitons, Phys. Rev. Lett. 125, 093901 (2020).\n43. H. Zhang at al., An optical neural chip for implementing complex-valued neural network, Nat. Commun. 12,\n457 (2021).\n44. A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, and C. Potts, Learning word vectors for sentiment analysis,\nin Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language\nTechnologies, 142â€“150 (Association for Computational Linguistics, Portland, Oregon, USA, 2011).\n45. M. Belkin, D. Hsu, S. Ma, and S. Mandal, Reconciling modern machine-learning practice and the classical\nbiasâ€“variance trade-oï¬€, Proc. Natl. Acad. Sci. 116, 15849â€“15854 (2019).\n46. M. S. Advani, A. M. Saxe, and H. Sompolinsky, High-dimensional dynamics of generalization error in neural\nnetworks,Neural Networks 132, 428â€“446 (2020).\n47. S. Mei and A. Montanari, The generalization error of random features regression: Precise asymptotics and double\ndescent curve, arXiv:1908.05355 (2020).\n48. K. BabiÄ‡, S. MartinÄiÄ‡-IpÅ¡iÄ‡, and A. MeÅ¡troviÄ‡, Survey of neural text representation models, Information 11, 511\n(2020).\n49. A. Ashraï¬, Walshâ€“hadamard transforms: A review, in Advances in Imaging and Electron Physics, 1-55 (Elsevier,\n2017).\n50. M. Soltanolkotabi, A. Javanmard, and J. D. Lee, Theoretical insights into the optimization landscape of overparame-\nterized shallow neural networks, IEEE Transactions on Inf. Theory 65, 742â€“769 (2019).\n51. D. Pierangeli, M. Rafayelyan, C. Conti, and S. Gigan, Scalable Spin-Glass Optical Simulator, Phys. Rev. Appl. 15,\n034087 (2021).\n52. M.-A. Miri, Integrated random projection and dimensionality reduction by propagating light in photonic lattices, Opt.\nLett 46, 4936 (2021).\n53. T. Mikolov, K. Chen, G. Corrado, and J. Dean, Eï¬ƒcient estimation of word representations in vector space,\narXiv:1301.3781 (2013).\n54. A. Lacoste, A. Luccioni, V. Schmidt, and T. Dandres, Quantifying the carbon emissions of machine learning,\narXiv:1910.09700 (2019).\n55. T.B. Brown et al., Language Models are Few-Shot Learners, arXiv:2005.14165 (2020).\n56. A.U. Rehman et al., A hybrid CNN-LSTM model for improving accuracy of movie reviews sentiment analysis,\nMultimedia Tools and Applications 78, 26597 (2019).\n",
  "categories": [
    "cs.ET",
    "physics.optics"
  ],
  "published": "2022-08-29",
  "updated": "2022-08-29"
}