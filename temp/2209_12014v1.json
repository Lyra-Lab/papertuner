{
  "id": "http://arxiv.org/abs/2209.12014v1",
  "title": "Asset Pricing and Deep Learning",
  "authors": [
    "Chen Zhang"
  ],
  "abstract": "Traditional machine learning methods have been widely studied in financial\ninnovation. My study focuses on the application of deep learning methods on\nasset pricing. I investigate various deep learning methods for asset pricing,\nespecially for risk premia measurement. All models take the same set of\npredictive signals (firm characteristics, systematic risks and macroeconomics).\nI demonstrate high performance of all kinds of state-of-the-art (SOTA) deep\nlearning methods, and figure out that RNNs with memory mechanism and attention\nhave the best performance in terms of predictivity. Furthermore, I demonstrate\nlarge economic gains to investors using deep learning forecasts. The results of\nmy comparative experiments highlight the importance of domain knowledge and\nfinancial theory when designing deep learning models. I also show return\nprediction tasks bring new challenges to deep learning. The time varying\ndistribution causes distribution shift problem, which is essential for\nfinancial time series prediction. I demonstrate that deep learning methods can\nimprove asset risk premium measurement. Due to the booming deep learning\nstudies, they can constantly promote the study of underlying financial\nmechanisms behind asset pricing. I also propose a promising research method\nthat learning from data and figuring out the underlying economic mechanisms\nthrough explainable artificial intelligence (AI) methods. My findings not only\njustify the value of deep learning in blooming fintech development, but also\nhighlight their prospects and advantages over traditional machine learning\nmethods.",
  "text": "Asset Pricing and Deep Learning\nChen Zhang\nSenseTime Research, Shanghai, China\ndemi6d@gmail.com\nSeptember 27, 2022\nAbstract\nTraditional machine learning methods have been widely studied in ﬁnancial innovation. My study focuses on the\napplication of deep learning methods on asset pricing.\nI investigate various deep learning methods for asset pricing, especially for risk premia measurement. All models\ntake the same set of predictive signals (ﬁrm characteristics, systematic risks and macroeconomics). I demonstrate high\nperformance of all kinds of state-of-the-art (SOTA) deep learning methods, and ﬁgure out that RNNs with memory\nmechanism and attention have the best performance in terms of predictivity. Furthermore, I demonstrate large economic\ngains to investors using deep learning forecasts.\nThe results of my comparative experiments highlight the importance of domain knowledge and ﬁnancial theory\nwhen designing deep learning models. I also show return prediction tasks bring new challenges to deep learning. The\ntime varying distribution causes distribution shift problem, which is essential for ﬁnancial time series prediction.\nI demonstrate that deep learning methods can improve asset risk premium measurement. Due to the booming deep\nlearning studies, they can constantly promote the study of underlying ﬁnancial mechanisms behind asset pricing. I also\npropose a promising research method that learning from data and ﬁguring out the underlying economic mechanisms\nthrough explainable artiﬁcial intelligence (AI) methods. My ﬁndings not only justify the value of deep learning in\nblooming ﬁntech development, but also highlight their prospects and advantages over traditional machine learning\nmethods.\nKey words: Machine Learning, Deep Learning, Deep Neural Network, Big Data, Return Prediction, MLP, RNN,\nCNN, Transformer, Fintech\n1\nIntroduction\nIn this paper, I mainly build on the work of [Gu, Kelly, and Xiu(2020)], and perform a comparative analysis of various\nSOTA deep learning methods for asset pricing. I focus on asset risk premia measurement problems, which are essential\nin asset pricing.\nMy primary contributions are extending the study of traditional machine learning methods to the all kinds of SOTA\ndeep learning methods on ﬁnancial problems. And with the empirical comparative analysis, I gain several new ﬁndings\nin the interdisciplinary study of deep learning methods and asset pricing problems.\n1.1\nWhat is Deep Learning\nFormally, deep learning is a subﬁeld of machine learning, so it inherits all the theories of machine learning. Due to its\nhigh performance, wide range of applications and uniformed architectures (neural network), deep learning is commonly\nstudied as a separate ﬁeld from traditional machine learning methods such as logistic regression, SVM, tree based models,\netc. For clarity, I will use machine learning referring to traditional machine learning in this paper.\nConnectionism known as connectionist networks or artiﬁcial neural networks (NNs) is an approach to the study of\nhuman cognition that utilizes mathematical models. Deep learning is exactly the combination of machine learning and\nconnectionism. In recent years, deep learning methods as mainstream in machine learning studies is blooming and gain\nlarge success in AI literature.\nMachine learning is essentially learning a prediction function from input data to output, and deep learning is essentially\nlearning various data representation throughout such process. Data representation learning is also regarded as automatic\nfeature engineering which usually is manual in machine learning. Figure 1 show the contrast between machine learning\nand deep learning.\n1\narXiv:2209.12014v1  [q-fin.ST]  24 Sep 2022\nFigure 1: Deep Learning\nDeep Learning can automate the feature engineering process.\nDeep learning is good at ﬁnding high dimensional, nonlinear and deep relationships. Domain speciﬁed deep learning\nmodels such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are good at processing\nnon-structure data.\n1.2\nWhy Apply Deep Learning to Asset Pricing\nEmpirical asset pricing is essentially a dynamic prediction problem, and the input (predictive signals) and output (asset\nrisk premium) vary over time. Since there is a large amount of factors related to stock returns, the dimension of inputs\n(predictors) is usually high. The relationship between input information and output returns is also probably nonlinear.\nDeep learning has its special advantages over machine learning in asset pricing problems. Machine learning is hard\nto take advantage of the economic theory and introduce it into the model as prior knowledge. However, deep learning\ncan design speciﬁc NNs architecture suitable to diﬀerent scenarios. Therefore, it’s more ﬂexible and with more spaces\nfor improvement. For example, sequence models are proper kind of architectures for time series data and time varying\nprediction.\nDeep learning also called deep neural network, because they are loosely inspired by biological neuroscience.\nOne\nessential reason deep learning gain great success in the AI industry is that it takes advantage of the greatest art (brain\nmechanisms) of nature.\nWhat’s more, end to end type deep learning models can avoid tedious work of feature engineering in machine learning.\n1.3\nWhat Speciﬁc Deep Learning Methods Do I Study\nI select a set of typical deep learning methods which gain tremendous success in all ﬁelds of AI applications. They are\nrepresentative for all kinds of SOTA deep learning models.\nThis includes deep feedforward NNs such as DNNs, Residual DNNs (i.e., DNNs with skip connection), CNNs and\nresidual CNNs. This also includes sequential models such as RNNs, Long Short-Term Memory (LSTM), Gated Recurrent\nUnit (GRU) and RNNs with attention mechanisms. At last, I introduce the Transformer, whose NNs architecture is\nentirely based on attention mechanism, which has achieved better performance than all kinds of RNNs on various Natural\nLanguage Process (NLP) tasks.\n1.4\nMain Empirical Findings\nRefer to the work of [Gu, Kelly, and Xiu(2020)], I perform a large scale empirical analysis, investigating 30,000 individual\nstocks over 40 years from 1976 to 2016. Furthermore, I conduct my analysis with 2 kinds of time span samples, long time\nspan (40 years) and short time span (5 years). My predictor set include 81 characteristics for each stock, 6 macroeconomic\nproxies and 5 factors by [Fama and French(2015)] as proxies of systematic risks.\nI gain several new ﬁndings through my empirical analysis.\nAll SOTA deep learning methods have high performance in stock return prediction, and far outperform the traditional\nlinear prediction model. It demonstrates the great promise of deep learning method for asset pricing.\nRNNs with memory mechanism and Transformer have the best performance, and this means history data has predictive\npower for asset return. RNNs are good at merge past and present information together to make prediction. The memory\nmechanism attention and cell unit in RNNs both works well, and long term memory improves stock return prediction.\nCNNs have relative worse performance than other NN models, and transformer is not completely dominating all other\nRNNs. It shows the importance of domain knowledge and theory guided model design. There is no free lunch, and speciﬁc\nmodel design is essential for problems in diﬀerent scenarios.\nSkip connections with deep layers have only a little improvement, and middle or shallow networks still work well.\nIt shows the fundamental associations between market data and asset prices is not complex comparing with other deep\nlearning applications, and studies of economic mechanism behind asset pricing is promising.\nShort time span samples have better performance. This demonstrates the distribution of stock data varies over time,\nand the closer the information, the more predictive power. Therefore, distribution shift problem arises in stock returns\nprediction.\n2\n1.5\nWhat Deep Learning Cannot Do\nDeep learning is good at predicting excess return condition on market information.\nHowever, since the complete theory of deep learning models is still ongoing, the shortage of deep learning is just like\nmost machine learning methods that it’s hard to fully explain the mechanisms behind the model.\nDeep learning models are designed only with reference to, but not entirely based on, economic mechanisms. While\nin this respect, deep learning is still better than machine learning because I can take advantage of economic mechanisms\nwhen designing the NNs’ architecture. I can take the prior knowledge of ﬁnancial theory as induction bias of the model\nfor corresponding ﬁnancial problems. Also, some studies aim at mitigating this shortage in deep learning literature such\nas explainable AI.\n1.6\nLiterature\nMy work extends the literature on empirical asset pricing in several aspects.\nFirst, I extend the machine learning based empirical asset pricing, such as stock pricing and bond pricing studied\nby [Gu, Kelly, and Xiu(2020)], [Leippold, Wang, and Zhou(2021)] and [Bianchi, B¨uchner, and Tamoni(2021)]. While deep\nlearning methods talked in this paper are not limited to speciﬁc kind of asset return prediction.\nSecond, I extend machine learning based cross-section stock returns study such as factors dimension reduction by [Gu,\nKelly, and Xiu(2021)].\nThird, I extend the time series return prediction, what is surveyed by [Koijen and Van Nieuwerburgh(2011)] and\n[Rapach and Zhou(2013)].\nThere are many deep learning methods have appeared in the asset pricing literature. Some papers are about derivatives\npricing via NNs such as [Hutchinson, Lo, and Poggio(1994)] and [Yao, Li, and Tan(2000)].\n[Sirignano, Sadhwani, and Giesecke(2016)] use deep learning to measure mortgage risks, and\n[Heaton, Polson, and Witte(2016)] use deep learning for portfolio management.\nMy paper focus on studying various SOTA deep learning methods, and comparing their results on stock return\nprediction tasks. I conduct a deep fundamental analysis on the pattern and relationship lie behind the market data and\nstock returns.\n2\nMethodology\nIn this section, I give a brief description of all the deep learning methods in my analyzing list. Details of most basic deep\nlearning mechanisms are well illustrated by [Goodfellow, Bengio, and Courville(2016)].\nI use the same objective function for all models which is Mean-Square Error (MSE). I use learning algorithms sub-\nstantially based on gradient decent, which is the most common optimization algorithm for deep learning. In particular,\nI choose Adam, the enhanced gradient decent learning algorithm, as my basic optimizer, and make some additional im-\nprovements such as batch normalization and layer normalization on it. I mostly use Dropout as the regularization method\nin all of my deep learning models.\nI use the same asset pricing model as described by [Gu, Kelly, and Xiu(2020)], an additive prediction error model for\nexcess return.\nri,t+1 = yi,t+1 = Et(yi,t+1) + ϵi,t+1,\n(1)\nwhere\nEt(yi,t+1) = f(xi,t; θ⋆)\n(2)\n2.1\nObjective Function\nFor all of my deep learning models, I estimate the parameters through Max a Posterior Estimation (MAPE).\nI want to maximize the posterior probability of θ given the samples of X and Y .\ny = f(x; θ) + ϵ\n(3)\nE(y) = f(x; θ)\n(4)\nmy 2 assumptions are that the noise ϵ follows a normal distribution, and the prior distribution of parameters θ is uniform.\nθ⋆= arg max\nθ\nP(θ|Y , X)\n= arg max\nθ\nP(θ)P(Y |θ, X)\nP(Y |X)\n= arg max\nθ\nP(Y |θ, X)\n(5)\n3\nThen MAPE is the same as Maximum Likelihood Estimation (MLE) of θ given samples (X, Y ). Have the Gaussian noise\nassumption, and take the natural log of equation (5), MLE is equal to minimizing MSE. Therefore, my objective function\nfor the model is to minimize the MSE, so the loss function L(θ) of my deep learning models is deﬁned as MSE.\nL(θ) = ∥Y −f(X; θ)∥2\n=\n1\nN · T\nN\nX\ni=1\nT\nX\nt=1\n(ri,t+1 −f (xi,t; θ))2\n(6)\n2.2\nLearning Algorithm\nAdam introduced by [Kingma and Ba(2014)] is an algorithm for ﬁrst-order gradient-based optimization. Adam is an\nalgorithm putting Momentum and RMSprop mechanisms together.\nBatch Normalization and Layer Normalization are 2 kinds of data normalization method proposed respectively by [Ioﬀe\nand Szegedy(2015)] and [Ba, Kiros, and Hinton(2016)]. The idea of these mechanisms is normalizing the input and hidden\nunit data, so that diﬀerent data are at the same scale. They can ﬂatten the gradients during the gradient decent process.\nRegularization is used to improve the generalization ability of deep learning models. It makes the model eﬀectively\ngeneralize to out-of-sample data set instead of overﬁtting the training samples.\nIn each training batch, overﬁtting can be signiﬁcantly reduced by ignoring part of the feature detectors (leaving part\nof the hidden layer nodes with values of 0). This mechanism works in 2 aspects. First, it reduces the network connections\nand parameters, thus simplify the neural network. Second, it implicitly assembles various subnetworks to get the ﬁnal\nmodel of more generality.\nI divide the data set across the time by (80%, 10%, 10%), respectively as train set, validation set and test set. Train\nset is used to train the models, and estimate the parameters. Validation set is used to tune all the hyperparameters of\nthe models. It can prevent overﬁtting and ensure the best performance for out-of-sample data. Test set is only used to\ntest the ﬁnal out-of-sample performance of the models.\n2.3\nSimple Linear\nI take the traditional regression model, linear regression, as my baseline.\nf (xi,t; θ) = x′\ni,tθ\n(7)\nI also use the most common estimation method, ordinary least squares (OLS), to estimate the parameters.\nˆθOLS = (X′X)−1X′Y\n(8)\n2.4\nDeep Feedforward Networks\nThe idea of Deep Neural Networks (DNNs) is ﬁrst introduced by [Ivakhnenko(1971)]. The core idea of DNNs is repre-\nsentation learning. Each unit of one layer can be seen as a combination of previous layer’s units, so it’s essentially a\nmodularizing process.\nFrom mathematic perspective, DNNs is a sequence of transformations of vectors.\nEach transformation (layer) is\ncomposed of aﬃne transformation followed by a nonlinear function (i.e., activation function). Deep feedforward networks\nare often called Multilayer Perceptron (MLP). MLP with one hidden layer can approximate any function f(x). MLP is\nthe standard DNNs, and I will call it DNNs for simplicity in this paper. The special structure of DNNs also contains\nan implicit L2-norm Regularization eﬀect. Most DNN models are called feedforward, because the information ﬂow from\ninput to output in one-way direction without feedback. Models with feedback connections are called RNNs.\nDNNs are essentially approximating a function from x to y:\ny = f ⋆(x)\n(9)\nyi,t = f ⋆(xi,t)\n(10)\nyi,t = f (xi,t; θ⋆)\n(11)\nEvery layer in DNNs consists of two components, aﬃne transformation and activation function.\nz = W ′h + b\n(12)\nThe activation function used in my model is ReLU proposed by [Glorot, Bordes, and Bengio(2011)].\nReLU(z) = max{0, z}\n(13)\nThe total data transformation in each DNN layer is as follows:\nh<i+1> = ReLU(W <i+1>′h<i> + b<i+1>)\n(14)\n4\n2.4.1\nResidual DNNs\nInstead of approximating a function, each layer in Residual DNNs approximates the residual between input and output of\nthis layer. When I introduce the deep residual neural network framework, I explicitly let the layers ﬁt a residual function.\nf(x) := h(x) −x\n(15)\nOne implementation of residual networks is standard DNNs with a skip connection between each layer. Skip connection\nconnects layer i to layer i + 1 or higher layer is shown in Figure 2.\nFigure 2: Residual DNNs\nLayer of Residual DNNs approximates the residual between input and output.\nSkip connections make it easy for the gradient to ﬂow back during the backward propagation. Skip connections between\nlayers reduce the length of path from lower layer to the output, and thus mitigate the vanishing gradient problem.\n2.5\nConvolutional Networks\nCNNs have been demonstrated well performance in image recognition by [Krizhevsky, Sutskever, and Hinton(2012)]. In\ndeep learning literature, I regard the cross-correlation function as convolution, while formally cross-correlation stands for\nconvolution without ﬂip the kernel.\nS(i, j) = (I ∗K)(i, j) =\nX\nm\nX\nn\nI(i + m, j + n)K(m, n)\n(16)\nFigure 3 shows the convolution operation.\nFigure 3: Convolution\nThe convolution layer performs a convolution operation on inputs with the kernels.\nThe core idea of CNNs is that kernels in convolution layer stand for the receptive ﬁeld. Such architecture design\nhas two advantages. First is sparse connectivity, that neurons only have connections within receptive ﬁeld. Second is\nparameter sharing, each kernel has the same weights moving across all the inputs of the layer.\nAnother special layer type in CNNs is Pooling. It essentially is a summary statistic of each layer. There are diﬀerent\nkinds of pooling layers, such as max pooling and avg pooling. Max (or avg) pooling takes the maximum (or average)\nvalue in each receptive ﬁeld.\nS(i, j) = (I ∗K)(i, j) = max\nm,n {I(i, j), ..., I(i + m, j + n)}\n(17)\n5\nFigure 4 shows the pooling operation.\nFigure 4: Pooling\nMax pooling layer take the maximum value of inputs within the kernel range.\nOne complete layer in CNNs consists sequentially of convolution, activation and pooling layer, as shown in Figure 5.\nFigure 5: CNNs\nCNNs are usually composed with 3 kinds of layer: convolution, activation and pooling layer.\nResidual CNNs have the same idea as residual DNNs, that map the residual between layers by adding a skip connection.\nOne well-known realization is the RESNET presented by [He et al.(2016)He, Zhang, Ren, and Sun].\n2.6\nSequence Modeling\n2.6.1\nRecurrent Neural Networks\nRNNs introduced by [Rumelhart, Hinton, and Williams(1985)] are a family of neural networks designed for sequential\ndata. RNNs have a hidden state that keep the state information of each time step, which are suitable for time series data\nprediction. RNNs oﬀer a great way to deal with variable length of input sequence as shown in Figure 6.\nFigure 6: RNNs\nRNNs take the input sequence to update the hidden state, which is used to generate output in each step.\nRNNs share parameters across all time steps, that the input at any step combines with the hidden state through the\nsame mechanism (i.e., transition function f). Such structure is illustrated in Figure 7.\n6\nFigure 7: Fold Structure of RNNs\nFold graph of RNNs show the essence of the model that each step in RNNs share the same structure and parameters.\nh<t> = f\n\u0000h<t−1>, x<t>; θ\n\u0001\n(18)\nThe transition function f consists of two components: aﬃne transformation and activation function g1.\nh<t> = g1\n\u0000Wh<t−1> + Ux<t> + b1\n\u0001\n(19)\nThe output y is calculated from hidden state h.\ny<t> = g2\n\u0000V h<t> + b2\n\u0001\n(20)\nTheoretically, the hidden state will keep most of the predictive information for the output.\n2.6.2\nLSTM\nSince RNNs have the same transition function along whole sequence, the most common problems of RNNs are vanishing\nand exploding gradient.\nExploding gradient problem can be solved by gradient clipping, which is proposed by\n[Pascanu, Mikolov, and Bengio(2013)]. It clips the norm ∥g∥of the gradient g before parameters are updated.\nif ∥g∥> threshold,\ng ←g ⋆threshold\n∥g∥\n(21)\nVanishing gradient problem can be solved by adding extra memory in RNNs.\nRNNs with such mechanisms are\ncalled gated RNNs, including LSTM and GRU introduced respectively by [Hochreiter and Schmidhuber(1997)] and [Cho\net al.(2014)Cho, Van Merri¨enboer, Gulcehre, Bahdanau, Bougares, Schwenk, and Bengio]. Besides the hidden state, a cell\nunit is added into the network to keep the memory of history information along the sequence. Forget gate and update\ngate are used to control what information of the inputs is kept in memory. The LSTM architecture is shown in Figure 8.\nFigure 8: LSTM\nLSTM is an enhanced version of RNN with an additional cell unit to keep long term memory.\n7\nTherefore, LSTM networks learn long-term dependencies more easily than vanilla RNNs.\nThe gates are calculated from current input and pervious hidden sate.\nΓ = σ\n\u0000Wx<t> + Uh<t−1> + b\n\u0001\n(22)\nThey are used to control what to forget and what to update in the cell unit.\n˜c<t> = tanh\n\u0000Wc\n\u0002\nΓr ⋆a<t−1>, x<t>\u0003\n+ bc\n\u0001\n(23)\nc<t> = Γu ⋆˜c<t> + Γf ⋆c<t−1>\n(24)\nh<t> = Γo ⋆c<t>\n(25)\n2.6.3\nGRU\nGRU is essentially a simpliﬁed version of LSTM, which only use one gate to control both the forget and update operation.\nThe architecture is shown in Figure 9.\nFigure 9: GRU\nGRU is a simpliﬁed version of LSTM which combine the cell unit and hidden state together.\n˜c<t> = tanh\n\u0000Wc\n\u0002\nΓr ⋆a<t−1>, x<t>\u0003\n+ bc\n\u0001\n(26)\nc<t> = Γu ⋆˜c<t> + (1 −Γu) ⋆c<t−1>\n(27)\nGRU also merges the information of cell unit and hidden state into one state variable.\nh<t> = c<t>\n(28)\n2.6.4\nRNNs with Attention\nAttention mechanism introduced by [Bahdanau, Cho, and Bengio(2014)] is another method to solve vanishing gradient.\nThe core idea of attention is inspired by attention mechanism in neuroscience.\nFrom mathematic perspective, attention mechanism is essentially a weighted average of all pervious information. A\ncontext vector c is constructed by taking a weighted average of encoder’s outputs y<t> as shown in Figure 10.\n8\nFigure 10: RNNs with Attention\nAttention mechanism helps the networks to ”pay attention to” history information.\nIn RNNs, the information contained in the outputs are also equivalent to the corresponding hidden states. Therefore,\nthe networks will mainly ”pay attention to” these memory units with most predictive power.\nThe attention weights Wz are ﬁrst calculated from current input and pervious hidden sate.\nWz = WW\n\u0002\nx<t+1>, h<t>\u0003\n+ bw\n(29)\nThe context of attention values c is generated from all pervious outputs.\nz<t+1> = WzY\n(30)\nc = Wc\n\u0002\nz<t+1>, h<t>\u0003\n(31)\nThe decoder will take context c as the hidden layer h.\nh<t+1> = g1\n\u0000Wc + Ux<t+1> + b1\n\u0001\n(32)\n2.6.5\nTransformer\nThe transformer model introduced by\n[Vaswani et al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin] only emphasizes on the\nattention mechanism and gets rid of recurrent structures. Therefore, Transformer model is entirely based on attention,\nand it replaces the recurrent mechanism with multi-headed self-attention.\nThe model ﬁrst generates the key K, query Q and value V from the inputs.\nQ = WQX\n(33)\nK = WKX\n(34)\nV = WV X\n(35)\nAnd then calculate the self-attention through K, Q, V .\nZ = Attention(Q, K, V ) = softmax\n\u0012QKT\n√dk\n\u0013\nV\n(36)\nEach head represents a diﬀerent kind of attention in every layer.\nMultiHead(Q, K, V ) = Concat (head1, . . . , headh) WO\n(37)\nwhere\nheadi = Attention (WQ,iQ, WK,iK, WV,iV )\n(38)\nIn Transformer, each layer works as transformation of data, which is totally based on self-attention mechanism applied\non all inputs of this layer. This architecture is shown in Figure 11.\n9\nFigure 11: Transformer\nTransformer is based on self-attention, it uses multiple layers and multi-head attentions to explore the deep associations\nin sequential data.\n2.7\nPerformance Evaluation\nI use out-of-sample R2 to evaluate the performance of all my models. I use the same R2 metric as\n[Gu, Kelly, and Xiu(2020)] proposed and justiﬁed, whose denominator is the sum of squared returns without demeaning.\nR2\noos = 1 −\nP\n(i,t)∈T (ri,t+1 −bri,t+1)2\nP\n(i,t)∈T r2\ni,t+1\n(39)\nT represents for test data set, which is only used for the ﬁnal performance evaluation. Therefore, I focus on the out-of-\nsample performance during my whole analysis on all deep learning methods.\n3\nMonte Carlo Simulations\nI use a Monte Carlo simulation algorithm with similar parameters calibrated by [Gu, Kelly, and Xiu(2020)], For each\nMonte Carlo sample, I divide the whole time series into 3 consecutive subsamples of 80% for training, 10% for validation\nand 10% for testing, respectively.\nI estimate both linear and nonlinear model in the training sample, using Random Forest (RF), Gradient Boosted\nRegression Trees (GBRT), LightGBM (LGBM), Multilayer Perceptron (MLP), Multilayer Perceptron (MLP) + Residual\nConvolutional Neural Networks (CNNs), Recurrent Neural Network (RNN), Recurrent Neural Network (RNN) + Atten-\ntion, Gated Recurrent Unit (GRU) Long Short-Term Memory (LSTM) and Transformer. I choose tuning parameters for\neach method in the validation sample, and calculate the prediction errors in the testing sample. For benchmark, I also\ncompared OLS and oracle model.\n10\nTable 1: Comparison of Predictive R2s for Machine Learning Algorithms in Simulations\nModel\nLinear\nNonlinear\nR2(%)\nIS\nOOS\nIS\nOOS\nOLS\n4.23\n3.38\n3.32\n2.32\nRFR\n7.37\n1.45\n9.06\n3.91\nGBRT\n6.69\n4.19\n8.52\n5.64\nLGBMR\n6.02\n4.34\n8.53\n5.68\nMLP\n3.61\n2.69\n4.92\n3.27\nMLP+R\n3.88\n2.91\n5.51\n4.57\nCNN\n4.12\n3.29\n11.84\n2.10\nRNN\n3.66\n2.63\n3.78\n2.91\nRNN+A\n3.78\n2.67\n5.73\n4.32\nGRU\n4.34\n2.71\n6.04\n4.13\nLSTM\n3.68\n2.73\n4.35\n3.58\nTransformer\n3.44\n2.67\n5.86\n4.14\nOracle\n5.22\n7.23\n7.88\n7.71\nI report the average R2s both in-sample (IS) and out-of-sample (OOS) for each model and each method over 10 Monte\nCarlo repetitions in Table 1.\nFor linear model, OLS and advanced tree methods deliver the best out-of-sample R2. By contrast, for nonlinear model,\nthese methods clearly dominate OLS, because the latter cannot capture the nonlinearity in the model. NNs is better,\nbut is dominated by RF, and GBRT. I think that’s because traditional ML methods are good at simple nonlinear tasks,\nwhile NNs are specialized in more complicated cases. Especially, NNs are best performed methods in nonstructural and\ncomplicated scenarios. OLS is the worst in all settings, not surprisingly.\n11\n4\nAn Empirical Study of US Equities\n4.1\nData and Over-arching Model\nI take all CRSP ﬁrms listed on the NYSE, AMEX, or NASDAQ as my samples. I obtain their monthly equity returns\nfrom July 1976 to December 2016, and the total time span is 40 years. I construct my empirical samples with about\n28,000 stocks totally and 6,000 per month on average.\nI take the one-month Treasury bill rate from Kenneth R. French’ data library to proxy for the risk-free rate. Then, I\ncalculate the excess return by using stock return minus risk-free rate.\nI construct 81 stock-level characteristics based on the cross section of stock returns literature, that mainly follows the\nwork of [Green, Hand, and Zhang(2017)].\nI construct 5 factors proposed by [Fama and French(2015)] as proxies for systematic risk.\nI also construct 6 macroeconomic proxies according to the work of [Welch and Goyal(2008)], including dividend-price\nratio (dp), earnings-price ratio (ep), book-to-market ratio (bm), net equity expansion (ntis), Treasury-bill rate (tbl) and\nstock variance (svar).\nJust like the work of [Gu, Kelly, and Xiu(2020)] for machine learning, all my deep learning methods are designed to\napproximate the over-arching empirical model Et(ri,t+1) = f ⋆(xi,t), which is deﬁned in equation (2), and baseline set of\nstock-level covariates zi,t is deﬁned as\nzi,t = xt ⊗ci,t\n(40)\nThe theory foundation for this model, as mentioned by [Gu, Kelly, and Xiu(2020)], is the standard beta-pricing rep-\nresentation of the asset pricing conditional Euler equation.\nStock-level characteristics ci,t are used in analogy with\nrisk exposure function βi,t, systemic risk and macroeconomic proxies are used in analogy with risk premium λt. Let\nβi,t = θ1ci,t, λt = θ2xt,\nEt (ri,t+1) = β′\ni,tλt\n(41)\ng⋆(zi,t) = Et (ri,t+1)\n= β′\ni,tλt\n= c′\ni,tθ′\n1θ2xt\n= (xt ⊗ci,t)′ vec (θ′\n1θ2)\n=: z′\ni,tθ,\n(42)\nwhere\nθ = vec (θ′\n1θ2)\n(43)\nThe Deep learning model is more general, because the g⋆(zi,t) can be any function and the input zi,t can be any\ncombination of xt and ci,t. Therefore, the factor risk premium can have nonlinear relationship with macroeconomic and\nsystematic risk, λt = f1(xt). Also the risk exposure can have nonlinear relationship with ﬁrm characteristics, βi,t = f2(ci,t).\nI design 2 kinds of time span samples, and separate the data set as follows.\nFirst, long time span contains totally 40 years. 80% for train set (1976 - 2007); 10% for validation set (2008 - 2012);\n10% for test set (2013 - 2016).\nSecond, short time span contains totally 5 years. 80% for train set (2011.12 - 2016.06); 10% for validation set (2016.06\n- 2016.12); 10% for test set (2016.07 - 2016.12).\n4.2\nThe Cross Section of Individual Stocks\nSince the work of [Gu, Kelly, and Xiu(2020)] and [Leippold, Wang, and Zhou(2021)] have both conduct a comparative\nanalysis on various machine learning methods and identiﬁed basic DNNs as the best preforming model, I focus on SOTA\ndeep learning models and start with basic DNNs.\nI compare 8 deep learning models in total, including OLS, DNNs, residual DNNs, CNNs, residual CNNs, RNNs, RNNs\nwith attention, GRU, LSTM and Transformer. Table 2 presents the comparison of diﬀerent deep learning models in terms\nof their out-of-sample R2. I use both long time span (40 years) and short time span (5 years) samples as the data set.\n12\nTable 2: Monthly Out-of-sample Stock-level Prediction Performance (Percentage R2\nOOS)\nOLS\nRFR\nGBRT\nLGBMR\nMLP\nMLP\nCNN\nRNN\nRNN\nGRU\nLSTM\nTransformer\n+R\n+A\n20 Years\n-0.50\n1.05\n0.53\n0.63\n1.14\n1.25\n1.00\n1.06\n1.38\n1.44\n1.44\n1.34\nThe main results of my comparative analysis are as follows.\nFirst, Compare with traditional linear regression method, all SOTA deep learning methods have far better performance\nin stock return prediction.\nSecond, RNNs have better performance. This demonstrates that past information have predictive power on present\nreturn prediction, and the underlying correlation exists between today’s return and history data. The high performance\nalso justiﬁes that RNNs are good at merging past and present information together to make predictions. However, vanilla\nRNNs in long time span data set are not trainable due to the vanishing gradient problem.\nThird, the memory mechanisms of attention and cell unit in RNNs both work well. It highlight the value of long term\nmemory in stock return prediction.\nForth, GRU as a simplify version of LSTM, make the model much simpler and without loss of performance at the\nsame time. According to Occam’s Razor principle, GRU could be a excellent substitution of LSTM in empirical asset\npricing.\nFifth, CNNs have relative worse performance than other NNs. It’s due to the design of CNNs is focusing on the\nComputer Vision (CV) tasks instead of stock return prediction. What’s more, Transformer works always better than\nRNNs in most NLP tasks, while it is not the case in stock return prediction. These ﬁndings demonstrate that a good\ndesign is mainly based on the domain knowledge, and highlight the importance of prior knowledge and domain theory\nguided model design.\nLast, deeper NNs with skip connections have only a little improvement. This suggests that the NNs needn’t much\nthe depth, and instead middle or shallow networks can also work well. Therefore, I should not overestimate the depth\nand complexity of the fundamental associations between market data and stock returns, and could be more optimistic\nabout the future research of asset pricing theory. Learning from data and then to ﬁgure out the underlying economic\nmechanisms through explainable AI methods could be another promising research method, which can promote the study\nof asset pricing.\n13\nTable 3: Diebold-Mariano Tests of Out-of-Sample Prediction\nRFR\nGBRT\nLGBMR\nMLP\nMLP\nCNN\nRNN\nRNN\nGRU\nLSTM\nTransformer\n+R\n+A\nOLS\n20.64\n13.83\n17.4\n21.35\n23.83\n28.32\n22.08\n26.74\n26.86\n27.22\n25.9\nRFR\n-23.35\n-15.89\n-3.19\n1.49\n-7.33\n-5.84\n7.21\n8.54\n7.09\n4.3\nGBRT\n15.08\n12.61\n10.68\n1.75\n7.21\n22.08\n24.73\n19.24\n20.65\nLGBMR\n8.46\n7.14\n-1.92\n2.46\n16.93\n19.82\n16.57\n15.43\nMLP\n3.38\n-6.54\n-3.54\n10.37\n12.49\n13.13\n8.03\nMLP+R\n-11.29\n-7.04\n4.24\n4.26\n3.71\n1.29\nCNN\n4.66\n15.44\n15.33\n15.25\n13.01\nRNN\n15.89\n17.36\n15.55\n13.16\nRNN+A\n0.69\n0.35\n-6.7\nGRU\n-0.12\n-8.79\nLSTM\n-5.6\nTable 3 assesses the statistical signiﬁcance of thirteen models, what reports the pairwise Diebold-Mariano test statistics\nof thirteen models. Positive statistic indicate the column model outperforms the row model and bold numbers indicate\nsigniﬁcance at the 5% level. The results consist with pervious discussion, and RNN with memory units and attention\nmechanisms have best performance.\n4.3\nPortfolio Forecasts\nI conduct portfolios experiments according to machine learning forecasts by calculating one-month-ahead out-of-sample\nstock return predictions. I ﬁrst sort stocks into deciles based on prediction of all 13 models, and then reconstitute portfolios\neach month with a zero-net-investment portfolio long the highest decile and short the lowest one.\nTable 4 reports the performance of portfolios over the 5-year testing period. Column ”Pred”, ”Avg”, ”Std”, and\n”SR” represent the predicted monthly returns, and realized average monthly returns, standard deviations and Sharpe\nratios. All portfolios are equally weighted. The results are consistent with pervious deep learning forecast performance,\nexcept that OLS has a relative good performance comparing to its OOS R2. Realized returns almost consist with deep\nlearning forecasts, and RNN models with memory mechanisms still dominate linear models and traditional ML (tree-based)\napproaches.\n14\nTable 4: Performance of Machine Learning Portfolios\nOLS\nRFR\nGBRT\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nLow(L)\n-3.78\n0.3\n7.31\n0.14\n-3.38\n1.13\n7.58\n0.52\n-0.08\n1.11\n5.89\n0.65\n2\n-2.23\n0.41\n5.63\n0.25\n-2.38\n1.33\n6.75\n0.68\n0.05\n1.08\n5.72\n0.65\n3\n-1.7\n0.69\n5.26\n0.45\n-1.91\n1.5\n6.05\n0.86\n0.15\n1.36\n5.94\n0.79\n4\n-1.32\n0.74\n4.88\n0.52\n-1.47\n1.46\n5.82\n0.87\n0.22\n1.13\n5.93\n0.66\n5\n-1.02\n1.23\n4.66\n0.91\n-1.07\n0.98\n5.19\n0.65\n0.22\n0.84\n4.82\n0.6\n6\n-0.73\n1.2\n4.74\n0.88\n-0.72\n0.9\n4.79\n0.65\n0.22\n1.17\n4.84\n0.84\n7\n-0.44\n1.48\n4.85\n1.05\n-0.39\n1.33\n4.98\n0.93\n0.23\n0.81\n4.55\n0.62\n8\n-0.1\n1.58\n4.97\n1.1\n-0.04\n1.38\n4.86\n0.98\n0.29\n2.05\n5.95\n1.19\n9\n0.37\n2.4\n5.78\n1.44\n0.44\n1.48\n5.69\n0.9\n0.4\n1.7\n5.78\n1.02\nHigh(H)\n1.55\n4.54\n7.64\n2.06\n2.3\n3.06\n7.48\n1.42\n0.83\n3.31\n7.5\n1.53\nH-L\n5.32\n4.24\n4.43\n3.31\n5.68\n1.93\n7.25\n0.92\n0.91\n2.21\n4.14\n1.84\nLGBMR\nMLP\nMLP+R\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nLow(L)\n0.39\n1.26\n5.9\n0.74\n0.33\n0.2\n7.16\n0.1\n-0.62\n-0.04\n7.94\n-0.02\n2\n0.56\n1.08\n5.8\n0.64\n0.79\n0.34\n5.36\n0.22\n0.02\n0.15\n6.39\n0.08\n3\n0.62\n1.42\n6.02\n0.82\n1.04\n0.76\n6\n0.44\n0.3\n0.53\n5.57\n0.33\n4\n0.67\n1.31\n6.42\n0.71\n1.22\n0.62\n5.25\n0.41\n0.51\n0.79\n5.12\n0.53\n5\n0.67\n1.25\n5.58\n0.78\n1.39\n0.9\n4.92\n0.63\n0.71\n0.9\n4.86\n0.64\n6\n0.67\n1.1\n4.76\n0.8\n1.55\n1.33\n4.65\n0.99\n0.92\n1.19\n4.85\n0.85\n7\n0.68\n1.13\n4.84\n0.81\n1.7\n1.53\n5.14\n1.03\n1.15\n1.69\n4.79\n1.22\n8\n0.7\n1.98\n6.32\n1.08\n1.86\n1.77\n5.09\n1.2\n1.43\n1.78\n4.89\n1.26\n9\n0.75\n1.78\n5.72\n1.08\n2.03\n2.9\n5.83\n1.72\n1.85\n2.49\n5.24\n1.65\nHigh(H)\n1.01\n2.25\n5.66\n1.38\n2.4\n4.22\n7.34\n1.99\n2.96\n5.09\n7.9\n2.23\nH-L\n0.62\n0.99\n3.54\n0.97\n2.07\n4.02\n4.63\n3.01\n3.57\n5.12\n5.38\n3.3\nCNN\nRNN\nRNN+A\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nLow(L)\n-1.47\n-0.45\n7.16\n-0.22\n-0.61\n-0.07\n8.24\n-0.03\n-0.78\n0.02\n7.99\n0.01\n2\n-0.47\n0.18\n5.84\n0.11\n0.16\n-0.03\n6.17\n-0.02\n-0.06\n0.37\n6.23\n0.2\n3\n-0.11\n0.43\n5.5\n0.27\n0.5\n0.31\n5.66\n0.19\n0.31\n0.48\n5.59\n0.3\n4\n0.15\n0.79\n4.95\n0.55\n0.74\n0.4\n5\n0.28\n0.58\n0.42\n4.89\n0.3\n5\n0.38\n1.11\n4.99\n0.77\n0.94\n0.81\n4.62\n0.61\n0.8\n0.75\n4.58\n0.57\n6\n0.59\n1.26\n4.65\n0.94\n1.12\n1.4\n4.5\n1.08\n1\n1.22\n4.57\n0.92\n7\n0.82\n1.61\n4.79\n1.17\n1.31\n1.76\n4.37\n1.39\n1.22\n1.69\n4.38\n1.34\n8\n1.1\n2.1\n5.11\n1.42\n1.54\n2.09\n5.05\n1.43\n1.48\n2.05\n4.94\n1.44\n9\n1.47\n2.58\n5.6\n1.59\n1.86\n2.88\n5.67\n1.76\n1.86\n2.72\n6.09\n1.55\nHigh(H)\n2.48\n4.95\n7.79\n2.2\n2.6\n5\n8.09\n2.14\n2.76\n4.83\n8.12\n2.06\nH-L\n3.95\n5.41\n5.09\n3.68\n3.21\n5.07\n4.34\n4.05\n3.54\n4.8\n5.06\n3.29\nGRU\nLSTM\nTransformer\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nPred\nAvg\nStd\nSR\nLow(L)\n-1.04\n-0.23\n7.87\n-0.1\n-0.63\n-0.26\n7.88\n-0.11\n-0.55\n-0.07\n7.88\n-0.03\n2\n-0.24\n0.2\n6.76\n0.1\n0.11\n0.06\n6.08\n0.03\n0.12\n0.05\n5.89\n0.03\n3\n0.23\n0.44\n5.51\n0.28\n0.49\n0.41\n5.41\n0.27\n0.45\n0.35\n5.63\n0.22\n4\n0.56\n0.57\n5.07\n0.39\n0.75\n0.46\n5\n0.32\n0.7\n0.68\n4.99\n0.47\n5\n0.81\n0.93\n4.83\n0.67\n0.95\n0.72\n4.71\n0.53\n0.9\n1.2\n4.75\n0.88\n6\n1.03\n1.15\n4.45\n0.89\n1.14\n1.41\n4.64\n1.06\n1.09\n1.58\n4.65\n1.18\n7\n1.25\n1.69\n4.5\n1.3\n1.33\n1.69\n4.61\n1.27\n1.28\n1.84\n4.75\n1.34\n8\n1.54\n2.05\n4.89\n1.45\n1.58\n2.21\n5.09\n1.51\n1.49\n1.97\n4.9\n1.39\n9\n1.95\n2.73\n5.5\n1.72\n1.95\n2.8\n5.98\n1.62\n1.78\n2.71\n5.67\n1.66\nHigh(H)\n2.86\n5.03\n8.26\n2.11\n2.88\n5.05\n8.49\n2.06\n2.32\n4.25\n7.83\n1.88\nH-L\n3.9\n5.26\n4.63\n3.94\n3.51\n5.31\n5.22\n3.53\n2.87\n4.32\n4.24\n3.53\nFigure 12 reports cumulative log returns for long and short sides of portfolios sorted on models’ forecasts. Bold black\nbaseline is cumulative market excess return. The solid and dash lines represent long (top decile) and short (bottom decile)\npositions. Finally, RNN with memory mechanisms and Residual MLP dominate all other models in both directions.\n15\nFigure 12: Cumulative Return of Machine Learning Portfolios\n5\nConclusion\nI conduct a comprehensive comparative analysis of various deep learning methods on empirical asset pricing, and identify\nthat RNNs with memory mechanism and Transformer have the best performance in terms of predictivity. Furthermore,\nI demonstrate large economic gains to investors using deep learning forecasts.\nMy comparisons of various NNs’ performance on stock return prediction demonstrate the importance of domain\nknowledge and ﬁnancial theory when designing deep learning models. This ﬁnding inspires a promising research direction\non empirical asset pricing via deep learning in future work . My ﬁndings show prediction in asset pricing brings new\nchallenges to deep learning, that the samples violate IID assumption accepted by most deep learning applications. The\ndistribution shift problem caused by time varying distribution and the low signal-to-noise ratio problem of ﬁnancial data\nare the two urgent problems need solving in stock return prediction models. The ﬁnding that well performed networks are\nnot always deep gives a promising direction for future study of asset pricing theory. Learning from data and ﬁguring out\nthe insights of asset pricing theory behind deep learning models through explainable AI theory is a promising research\nmethod.\nThe success of deep learning methods for stock return prediction brings great prospects for innovative economic models,\nand highlights the value of deep learning in empirical understanding of asset prices. What’s more, it also suggests that\nall the follow-up achievements in the booming deep learning studies (e.g., explainable AI theory, innovative architectures,\nmechanisms and models, etc.) can constantly promote the study of asset pricing. The better measurement with deep\nlearning methods can improve the risk premia prediction, and promote and simplify the study of underlying economic\nmechanisms behind asset pricing.\nOverall, my ﬁndings not only justify the role of deep learning methods in the booming ﬁnancial innovation, but also\nhighlight their prospects and advantages over traditional machine learning methods.\nReferences\n[Ba, Kiros, and Hinton(2016)] Ba, J. L., J. R. Kiros, and G. E. Hinton. 2016.\nLayer normalization.\narXiv preprint\narXiv:1607.06450 .\n16\n[Bahdanau, Cho, and Bengio(2014)] Bahdanau, D., K. Cho, and Y. Bengio. 2014. Neural machine translation by jointly\nlearning to align and translate. arXiv preprint arXiv:1409.0473 .\n[Bianchi, B¨uchner, and Tamoni(2021)] Bianchi, D., M. B¨uchner, and A. Tamoni. 2021. Bond risk premiums with machine\nlearning. The Review of Financial Studies 34:1046–89.\n[Cho et al.(2014)Cho, Van Merri¨enboer, Gulcehre, Bahdanau, Bougares, Schwenk, and Bengio] Cho,\nK.,\nB. Van Merri¨enboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. 2014.\nLearning\nphrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078\n.\n[Fama and French(2015)] Fama, E. F., and K. R. French. 2015. A ﬁve-factor asset pricing model. Journal of ﬁnancial\neconomics 116:1–22.\n[Glorot, Bordes, and Bengio(2011)] Glorot, X., A. Bordes, and Y. Bengio. 2011. Deep sparse rectiﬁer neural networks. In\nProceedings of the fourteenth international conference on artiﬁcial intelligence and statistics, 315–23. JMLR Workshop\nand Conference Proceedings.\n[Goodfellow, Bengio, and Courville(2016)] Goodfellow, I., Y. Bengio, and A. Courville. 2016. Deep learning. MIT press.\n[Green, Hand, and Zhang(2017)] Green, J., J. R. Hand, and X. F. Zhang. 2017. The characteristics that provide inde-\npendent information about average us monthly stock returns. The Review of Financial Studies 30:4389–436.\n[Gu, Kelly, and Xiu(2020)] Gu, S., B. Kelly, and D. Xiu. 2020. Empirical asset pricing via machine learning. The Review\nof Financial Studies 33:2223–73.\n[Gu, Kelly, and Xiu(2021)] ———. 2021. Autoencoder asset pricing models. Journal of Econometrics 222:429–50.\n[He et al.(2016)He, Zhang, Ren, and Sun] He, K., X. Zhang, S. Ren, and J. Sun. 2016. Deep residual learning for image\nrecognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770–8.\n[Heaton, Polson, and Witte(2016)] Heaton, J., N. G. Polson, and J. H. Witte. 2016. Deep learning in ﬁnance. arXiv\npreprint arXiv:1602.06561 .\n[Hochreiter and Schmidhuber(1997)] Hochreiter, S., and J. Schmidhuber. 1997. Long short-term memory. Neural com-\nputation 9:1735–80.\n[Hutchinson, Lo, and Poggio(1994)] Hutchinson, J. M., A. W. Lo, and T. Poggio. 1994. A nonparametric approach to\npricing and hedging derivative securities via learning networks. The journal of Finance 49:851–89.\n[Ioﬀe and Szegedy(2015)] Ioﬀe, S., and C. Szegedy. 2015. Batch normalization: Accelerating deep network training by\nreducing internal covariate shift. In International conference on machine learning, 448–56. PMLR.\n[Ivakhnenko(1971)] Ivakhnenko, A. G. 1971. Polynomial theory of complex systems. IEEE transactions on Systems, Man,\nand Cybernetics 364–78.\n[Kingma and Ba(2014)] Kingma, D. P., and J. Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980 .\n[Koijen and Van Nieuwerburgh(2011)] Koijen, R. S., and S. Van Nieuwerburgh. 2011. Predictability of returns and cash\nﬂows. Annu. Rev. Financ. Econ. 3:467–91.\n[Krizhevsky, Sutskever, and Hinton(2012)] Krizhevsky, A., I. Sutskever, and G. E. Hinton. 2012. Imagenet classiﬁcation\nwith deep convolutional neural networks. Advances in neural information processing systems 25:1097–105.\n[Leippold, Wang, and Zhou(2021)] Leippold, M., Q. Wang, and W. Zhou. 2021. Machine learning in the chinese stock\nmarket. Journal of Financial Economics ISSN 0304-405X. doi:https://doi.org/10.1016/j.jﬁneco.2021.08.017.\n[Pascanu, Mikolov, and Bengio(2013)] Pascanu, R., T. Mikolov, and Y. Bengio. 2013. On the diﬃculty of training recur-\nrent neural networks. In International conference on machine learning, 1310–8. PMLR.\n[Rapach and Zhou(2013)] Rapach, D., and G. Zhou. 2013. Forecasting stock returns. In Handbook of economic forecasting,\nvol. 2, 328–83. Elsevier.\n[Rumelhart, Hinton, and Williams(1985)] Rumelhart, D. E., G. E. Hinton, and R. J. Williams. 1985. Learning internal\nrepresentations by error propagation. Working Paper, California Univ San Diego La Jolla Inst for Cognitive Science.\n17\n[Sirignano, Sadhwani, and Giesecke(2016)] Sirignano, J., A. Sadhwani, and K. Giesecke. 2016. Deep learning for mortgage\nrisk. arXiv preprint arXiv:1607.02470 .\n[Vaswani et al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin] Vaswani,\nA.,\nN. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,  L. Kaiser, and I. Polosukhin. 2017.\nAttention\nis all you need. In Advances in neural information processing systems, 5998–6008.\n[Welch and Goyal(2008)] Welch, I., and A. Goyal. 2008. A comprehensive look at the empirical performance of equity\npremium prediction. The Review of Financial Studies 21:1455–508.\n[Yao, Li, and Tan(2000)] Yao, J., Y. Li, and C. L. Tan. 2000. Option price forecasting using neural networks. Omega\n28:455–66.\n18\n",
  "categories": [
    "q-fin.ST",
    "cs.LG",
    "q-fin.PR"
  ],
  "published": "2022-09-24",
  "updated": "2022-09-24"
}