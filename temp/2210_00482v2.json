{
  "id": "http://arxiv.org/abs/2210.00482v2",
  "title": "Compositional Generalization in Unsupervised Compositional Representation Learning: A Study on Disentanglement and Emergent Language",
  "authors": [
    "Zhenlin Xu",
    "Marc Niethammer",
    "Colin Raffel"
  ],
  "abstract": "Deep learning models struggle with compositional generalization, i.e. the\nability to recognize or generate novel combinations of observed elementary\nconcepts. In hopes of enabling compositional generalization, various\nunsupervised learning algorithms have been proposed with inductive biases that\naim to induce compositional structure in learned representations (e.g.\ndisentangled representation and emergent language learning). In this work, we\nevaluate these unsupervised learning algorithms in terms of how well they\nenable compositional generalization. Specifically, our evaluation protocol\nfocuses on whether or not it is easy to train a simple model on top of the\nlearned representation that generalizes to new combinations of compositional\nfactors. We systematically study three unsupervised representation learning\nalgorithms - $\\beta$-VAE, $\\beta$-TCVAE, and emergent language (EL)\nautoencoders - on two datasets that allow directly testing compositional\ngeneralization. We find that directly using the bottleneck representation with\nsimple models and few labels may lead to worse generalization than using\nrepresentations from layers before or after the learned representation itself.\nIn addition, we find that the previously proposed metrics for evaluating the\nlevels of compositionality are not correlated with actual compositional\ngeneralization in our framework. Surprisingly, we find that increasing pressure\nto produce a disentangled representation produces representations with worse\ngeneralization, while representations from EL models show strong compositional\ngeneralization. Taken together, our results shed new light on the compositional\ngeneralization behavior of different unsupervised learning algorithms with a\nnew setting to rigorously test this behavior, and suggest the potential\nbenefits of delevoping EL learning algorithms for more generalizable\nrepresentations.",
  "text": "Compositional Generalization in Unsupervised\nCompositional Representation Learning:\nA Study on Disentanglement and Emergent Language\nZhenlin Xu\nMarc Niethammer\nColin Raffel\nDepartment of Computer Science\nUniversity of North Carolina at Chapel Hill\n{zhenlinx, mn, craffel}@cs.unc.edu\nAbstract\nDeep learning models struggle with compositional generalization, i.e. the ability\nto recognize or generate novel combinations of observed elementary concepts. In\nhopes of enabling compositional generalization, various unsupervised learning algo-\nrithms have been proposed with inductive biases that aim to induce compositional\nstructure in learned representations (e.g. disentangled representation and emergent\nlanguage learning). In this work, we evaluate these unsupervised learning algo-\nrithms in terms of how well they enable compositional generalization. Speciﬁcally,\nour evaluation protocol focuses on whether or not it is easy to train a simple model\non top of the learned representation that generalizes to new combinations of compo-\nsitional factors. We systematically study three unsupervised representation learning\nalgorithms – β-VAE, β-TCVAE, and emergent language (EL) autoencoders – on\ntwo datasets that allow directly testing compositional generalization. We ﬁnd that\ndirectly using the bottleneck representation with simple models and few labels may\nlead to worse generalization than using representations from layers before or after\nthe learned representation itself. In addition, we ﬁnd that the previously proposed\nmetrics for evaluating the levels of compositionality are not correlated with the\nactual compositional generalization in our framework. Surprisingly, we ﬁnd that\nincreasing pressure to produce a disentangled representation (e.g. increasing β\nin the β-VAE) produces representations with worse generalization, while repre-\nsentations from EL models show strong compositional generalization. Motivated\nby this observation, we further investigate the advantages of using EL to induce\ncompositional structure in unsupervised representation learning, ﬁnding that it\nshows consistently stronger generalization than disentanglement models, especially\nwhen using less unlabeled data for unsupervised learning and fewer labels for\ndownstream tasks. Taken together, our results shed new light onto the composi-\ntional generalization behavior of different unsupervised learning algorithms with a\nnew setting to rigorously test this behavior, and suggest the potential beneﬁts of\ndeveloping EL learning algorithms for more generalizable representations.\n1\nIntroduction\nA human’s ability to recognize or generate novel combinations of seen elementary concepts, also\nknown as compositional generalization, is desirable for building general artiﬁcial ingelligence (AI)\nsystems [22, 16, 3]. The Recognition-By-Components theory by Biederman [3] inﬂuenced the\nearly development of computer vision models that are inherently compositional, e.g., hierarchical\nfeatures [13, 14] and part-based models [37, 38]. However, modern deep learning systems still\nstruggle with this key capability of human intelligence [33]. A few works studied speciﬁc spatial and\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\narXiv:2210.00482v2  [cs.LG]  5 Oct 2022\nobject-wise compositionality [42, 30] or more general compositionality in the space of pre-deﬁned\nattributes [45, 39] or the semantics of human language descriptions [49, 44].\nHumans often express complex meaning in a compositional manner: we combine elementary rep-\nresentations to describe observations. For example, an object with simple geometry is described\nby separate and independent properties such as color (red, blue, ...), position (left, right, close, far\naway,...), and shape (circle, triangle, ...). Therefore, compositional representations are thought as\nhelpful or even essential to achieve compositional generalization [22, 15, 3, 28]. However, consider-\ning that there are exponentially many possible combinations of a given set of elementary concepts, we\nneed to deal with this combinatorial explosion for real-world visual observations. It is unrealistic to an-\nnotate enough data to learn the ﬁne-grained compositionality. Therefore, unsupervised compositional\nrepresentation learning is appealing because it does not require comprehensive labeling. However,\nunsupervised representation learning heavily relies on the design of an effective inductive bias (e.g.\non the representation formulation) to induce the emergence of compositional representations.\nA widely explored representation formulation with explicit compositionality is disentanglement.\nThe most common formulation of disentanglement is that the generative factors of observations\nshould be encoded into different factors of low-dimensional representations, and a change of a\nsingle factor in an observation leads to a change in a single factor of the representation. State-\nof-the-art unsupervised disentanglement models [20, 24, 27, 7, 34] are largely built on top of\nvariational generative models [25]. To measure the level of disentanglement, various quantitative\nmetrics have been proposed that are deﬁned based on the statistical relations between the learned\nrepresentations and ground truth factors with an emphasis on the separation of factors. A summary of\ndisentanglement metrics and methods is provided in [31]. Another representation learning approach\nwith an inductive bias towards compositionality is emergent language learning. Natural language\nallows us to describe novel composite concepts by combining expressions of their elementary concepts\naccording to grammar. Therefore, linguists have been interested in studying the compositionality\nof discrete codes evolving during multi-agent communication when agents learn to complete a task\ncooperatively [9, 29, 19, 40]. Compositionality metrics with language structure assumptions, e.g.\ntopographic similarity [4], were used to evaluate the learned language. However, for the above two\ntypes of methods, relatively few studies [36, 41, 6, 1] have directly evaluated how well the learned\nrepresentations generalize to novel combinations on downstream tasks, which is the main motivation\nfor compositional representation learning in the ﬁrst place.\nIn this work, we study the compositional generalization performance of representations learned\nfrom unsupervised learning algorithms with two types of inductive biases for compositionality:\ndisentanglement and emergent languages (EL). Instead of measuring the compositionality and\ndisentanglement metrics deﬁned based on various assumptions, we directly measure the generalization\nperformance on novel input combinations with a two-stage protocol. Speciﬁcally, with a dataset\ndivided into train and test sets ensuring that the test set contains novel combinations of concepts that\nnever appear in the train set, we ﬁrst learn an unsupervised representation model from unlabeled\nimages in the train set. With very few labeled samples from the train set and the frozen unsupervised\nrepresentation model, we train simple (e.g. linear) models on top of learned representations to predict\nthe ground truth value for each generative factor of the dataset and evaluate these simple models\non the test set. These choices are aligned with common practices in recent deep representation\nlearning works, for example, self-supervised representation learning [10] and semi-supervised\nlearning with generative models [26]. Different from previous studies (e.g. [6, 36]) that measure\nunsupervised learning performance (e.g. image reconstruction), we evaluate the performance on\ndownstream tasks. We also emphasize how easily we can obtain downstream task models with the\nlearned representation, e.g. when using very few labels and simple linear models. These designs\nhighlight the generalization performance of the unsupervised learning stage, different from a setup\nthat uses many more or even all labeled samples of the train set in the downstream task learning stage\n[10, 41] or performs unsupervised learning on the entire dataset [31]. More importantly, we study\nnot only the compositional generalization of intermediate representations at the model bottleneck,\ne.g. where the disentangled latent variables are formulated, but also the representations from layers\nbefore or after it.\nWith the above evaluation protocol for compositional generalization, we explore selected unsupervised\nlearning algorithms by varying (1) the hyperparameters of each algorithm that may control the levels\nof compositionality; (2) image datasets and the amount of data for both unsupervised and supervised\nlearning stages; and (3) design choices of EL learning. First, we ﬁnd that, compared to the low-\n2\nFigure 1: Architectures of disentanglement models (left) and emergent language models (right).\ndimensional latent variables from the model bottleneck, representations from the layers before or\nafter the model bottleneck enable better compositional generalization. Second, we ﬁnd that attaining\nhigher scores on previously proposed compositionality/disentanglement metrics does not always\ncorrelate with better generalization performance. Finally, the representations learned from EL models\nshow stronger generalization performance than disentanglement models. These ﬁndings reveal the\ndivergence between the efforts to achieve better compositionality / disentanglement metric scores and\nthe initial motivation to obtain better generalization performance. To our best knowledge, this is the\nﬁrst study to compare representations in disentanglement models and emergent language learning\nthrough the lens of compositional generalization with a uniﬁed evaluation setup. We also discuss\nthe advantage of the emergent language representation format versus disentanglement and connect it\nwith recent related research in representation learning.\n2\nUnsupervised Learning with Compositional Representation Inductive Bias\nIn this section, we introduce more details on unsupervised learning algorithms with two different\ncompositionality-seeking inductive biases on the representation formulation: disentangled representa-\ntions in Section 2.1 and emergent languages in Section 2.2.\n2.1\nLearning Disentangled Representations\nThe concept of disentanglement assumes that high-dimensional observations of the real world x\ncan be represented by low-dimensional latent variables z, where each dimension of z encodes\nindependent factors of variations in x. For unsupervised disentanglement learning algorithms, we\nselect the popular β-VAE and β-TCVAE methods which both modify the evidence lower bound\n(ELBO) objective in the variational autoencoder (VAE).\nβ-VAE use a hyperparameter β for the Kullback-Leibler (KL) regularization term of the vanilla VAE\nloss to control the bandwidth of the VAE bottleneck:\nEp(x)[Eqφ(z|x)[log pθ(x|z)] −βKL(qφ(z|x)||p(z))] ,\n(1)\nwhere p(z) is the assumed prior distribution of the latent variables and its conditional distribution\nqφ(z|x) is parameterized by a neural network (encoder) whose parameters are φ and the posterior\npθ(x|z) is parameterized by a decoder whose parameters are θ. β = 1 corresponds to the VAE loss.\nβ-TCVAE further decomposes the KL term in Eq. (1) into mutual information, total correlation, and\ndimension-wise KL terms, and penalizes the total correlation with the hyperparameter β:\nEq(z|x)p(x)[log pθ(x|z)] −αIq(x; z) −βKL(qφ(z)||\nY\nj\nqφ(zj)) −γ\nX\nj\nKL(q(zj)||p(zj)) , (2)\nwhere Iq(x; z), KL(qφ(z)|| Q\nj qφ(zj)) and P\nj KL(q(zj)||p(zj)) are the mutual information term,\ntotal correlation term and the dimension-wise KL term respectively. The proposed β-TCVAE uses\nα = γ = 1 and tunes β only.\n2.2\nLearning Emergent Language\nAn alternative compositional representation learning method is emergent language (EL) learning,\nwhich aims to learn a representation that mimics the properties of natural language. The emergent\nlanguage consists of sequences of discrete symbols from a vocabulary. Since the model combines\ndiscrete symbols in the vocabulary to represent complex semantics in observations, one expects that\n3\nmeaningful compositionality might naturally emerge in communication between multiple agents\nusing the emergent language to solve tasks. We consider the typical speaker-listener model (two-\nagent communication) for EL learning, as shown in Fig. 1. We apply EL learning to the image\nreconstruction task to be consistent with the reconstruction objective used by variational auto-encoder-\nbased models. Note that in our setting the terminology “speaker-listener” is equivalent to the more\ncommon “encoder-decoder” terminology. The task is as follows.\n1. The speaker receives an input x and encodes it as a message m = {m1, m2, ...}, a sequence\nof discrete symbols from the vocabulary V = {c1, c2, cnV } of size nV . The maximum\nlength of m is nmsg.\n2. The listener model receives the message m and the outputs ˆx, aiming to accurately recon-\nstruct the encoder input x.\nIn this work, we use a speaker and a listener that are both hybrids of a convolutional neural network\nand an LSTM recurrent neural network. The ﬂattened convolutional embedding of the input image,\nEncConv(x), is used as the initial cell state of an LSTM encoding module (EncLSTM). EncLSTM\ngenerates a discrete distribution q(mt|x) over V at each time step t autoregressively (with the\nembedding of the discrete token sampled in the previous step t −1 as input):\nq(mt|x) = EncLSTM(mt−1|EncConv(x), emb(m1), .., emb(mt−2)) ,\n(3)\nwhere emb(·) is the learnable layer that projects a discrete token into a high-dimensional embedding.\nWe use the Gumbel-Softmax [23, 32] to sample from the discrete distribution q(mt|x) and the\n“straight-through” (ST) gradient estimator [2] for quantization (from soft-distribution to one-hot\nvector). This allow us to estimate the gradients from the discrete sampling process.\nmt = ST(GumbelSoftmax(q(mt|x))) .\n(4)\nTo allow the message to be of variable length, which better mimics natural language, we set one token\nin V to be the end-of-sequence (EOS) token that indicates the message end.\nWhen the listener decodes the message m, it ﬁrst maps each discrete symbol into an embedding\nbased on a learnable embedding layer and uses a decoding LSTM layer (DecLSTM) to process the\nsequence of embeddings recurrently.\nEmbt(m) = DecLSTM(emb(mt)|emb(m1), emb(m2), .., emb(mt−1)) .\n(5)\nWe use the output of DecLSTM at the ending step T as the embedding of the message to be the input\nof a convolutional decoder for image reconstruction:\nEmb(m) = EmbT (m), where T = min(nmsg, argmin\ni\n{mi == EOS, i ∈{1..N}}) .\n(6)\nFinally, the convolutional decoder (DecConv) reconstructs the input by:\nˆx = DecConv(Emb(m)) .\n(7)\n3\nExperimental Design\n3.1\nDatasets\nWe are interested in whether representations can generalize to novel combinations of seen concepts.\nTherefore, we need datasets that provide ground-truth labels of elementary concepts for (1) creating\ntrain/test splits and (2) downstream task evaluation. We consider datasets with ngen independent\ngenerative factors F = {f1, ..., fngen} where the space of factor fi is Si. For example, if f1 is color,\nthen S1 could be {yellow, red, blue, ...}. The data space D is deﬁned by the Cartesian product of\nthe spaces of each factor, and therefore the cardinality of the dataset is |D| = Qngen\ni\n|Si|.\nIn our study, we used two public image datasets studied in the disentanglement literature: dSprites [35]\nand MPI3D [17]. The dSprites dataset contains images of 2D shapes generated from 5 factors F =\n{shape, scale, rotation, x and y position}. To avoid label ambiguity due to the rotational symmetry\nof the square and ellipse shapes, we limit the range of orientations to be within [0, π/2). Then the\ncardinality of each factor’s space is {3, 6, 10, 32, 32} respectively, which makes |D| = 183, 320.\nMPI3D is a set of 3D datasets synthesized or recorded in a controlled environment with an object held\n4\nby a robotic arm. In our evaluation, the challenging real-world version (MPI3D-Real) is used. It has 7\nfactors F = {object-color(6), object-shape(6), object-size(2), camera-height(3), background-color(3),\nhorizontal-axis(40), vertical-axis(40)} with the corresponding cardinalities of the space in parentheses,\nleading to a total of 1,036,800 images.\n3.2\nCompositional Generalization Evaluation Protocol\nOur evaluation protocol emphasizes the compositional generalization that models can achieve on\ndownstream tasks. Our objective is to measure how easily an unsupervised representation learning\nmethod can produce compositional generalization using a simple model on top of the learned\nrepresentation. (1) Data splits. We ﬁrst split a dataset into train/test sets randomly while ensuring\nthat all samples in the test-set are novel combinations of elementary factors seen in the train-set. (2)\nUnsupervised representation learning. We learn unsupervised representations from the unlabeled\nimages of the train-set of size Ntrain with a selected algorithm. (3) Learning for downstream tasks.\nThen, we freeze the learned representation model and use the Nlabel labeled samples from the train\nset (Nlabel << Ntrain), to train a simple classiﬁer / regressor to predict the ground truth value for\neach factor fi of the dataset. (4) Testing generalization performance. Lastly, we test the performance\nof the downstream task models on novel combinations of seen values of elementary factors.\nReadout model. We argue that it is important to use simple read-out models and a limited number\nof labeled training samples to evaluate downstream tasks. Otherwise, the performance gain from the\ndownstream task learning stage is mixed with that of the unsupervised learning stage. For example, if\nthe unsupervised representation model is an identity mapping, we can still get great performance with\na powerful read-out model and enough labeled samples. In our main article, we use linear models for\ndownstream tasks. However, perfectly disentangled but linearly inseparable representations may still\nshow poor performance with a linear readout model. Through sanity checking experiments (discussed\nin Appendix B), the linear readout model can still generalize well on nonlinear oracle representations\npossibly due to the limited value range of attributes in our datasets. In addition, extra results using a\nnon-linear readout model (Gradient Boosting Trees) are in Appendix C and the main observations\nare consistent. The linear models we use to predict the values of the generative factors are ridge\nregression, using the R2 score as the evaluation metric, and logistic regression, using classiﬁcation\naccuracy as the evaluation metric. Since the R2 score can be negative while R2 = 0 indicates random\nguessing, we clip all negative R2 scores to zero.\nRepresentation Mode. In unsupervised disentanglement learning, low-dimensional latent variables\nwith explicit disentanglement regularization are used as the representation for downstream tasks, e.g.\nthe mean values of Gaussian distributions of the latent variables in the VAE. If the disentangled latent\nvariables each represent a single ground truth factor, only a simple mapping between factors and the\ncorresponding variables must be learned to achieve good performance. However, it is questionable if\nthe learned latent variables disentangle in the assumed structure and therefore improve generalization.\nOn the other hand, the simple linear models in our evaluation protocol may not be capable to process\nthe latent variables (discrete messages) in emergent language (EL) learning because we would not\nexpect discrete sequential latent variables to be easily linearly separable. Therefore, we also evaluate\nthe intermediate features of the layers before or after the model bottleneck. Speciﬁcally, in addition\nto the latent variables (zlatent), we also use the features immediately after the convolutional encoder\n(zpost) or before the convolutional decoder (zpre) as representations of images, shown in Fig. 1. We\nevaluate the use of zpost and zpre in both disentanglement and emergent language models.\n3.3\nImplementation details.\nData Splits For the main experiments, we use a 1:9 train/test split. The train set size (10%) is smaller\nthan what common machine learning setups and previous studies have used [36, 41]. However,\nconsidering the number of possible combinations increases exponentially for real data with an\nincreased number of generative factors, using fewer training samples even at the unsupervised\nlearning stage can help to obtain more meaningful conclusions for real-world scenarios.\nModel architectures. Fig. 1 shows the architectures for disentanglement and emergent language\nlearning models. The encoder and decoder in disentanglement learning models are symmetric\narchitectures with a convolutional network and a multi-layer perceptron (MLP) similar to the design\nin [5]. We scale up the size of the model by doubling the width of all layers, which improves the\n5\nperformance of all models. Since our emergent language learning model uses the same autoencoding\ntask as disentanglement learning, it also uses a symmetric encoder-decoder architecture. Instead of\nMLPs, the EL model uses LSTM modules to encode and decode latent variables. The sizes of the\nMLP module in the disentanglement models and the LSTM module in the EL models are matched\nfor a fair comparison. We use a Bernoulli decoder for the autoencoding task, which uses pixel values\nnormalized to [0, 1] as probabilities.\nHyperparameters. We follow previous studies [31, 36] for disentanglement models to set our\nhyperparameters. We set the number of disentangled latent variables, |zlatent|, and the maximum\nlength of the emergent latent message, nmsg, to 10, unless speciﬁcally mentioned. For the pre-training\nstage, we use batch size 64 and train the model for 500,000 steps for dSprites and 1,000,000 steps\nfor MPI3D-Real using the Adam optimizer with learning rate 0.0001. For each speciﬁc model, we\ncollect results from three different runs with different random seeds.\nFigure 2: Generalization performance (accuracy for classiﬁcation tasks and R2 score for regression\ntasks) of three representation models: β-VAE, β-TCVAE, and emergent language on dSprites.\n4\nKey Studies and Results\n4.1\nCompositional latent variables may not be the best representations for downstream\ntasks\nWe ﬁrst study the generalization behaviors of different representation modes. For each unsupervised\nlearning algorithm, we vary the hyperparameters that were designed to control the compositionality\nof representations. For β-VAE and β-TCVAE, we simply vary β. For emergent language models, we\nuse the communication bandwidth, deﬁned as the number of bits in the message and calculated by\nlog2(nnmsg\nV\n), nmsg ∈{8, 10, 12} and nV ∈{128, 256, 512}. Fig. 2 shows the results for accuracy\nand R2-score vs. β and the number of bits when Nlabel = 500 for the dSprites dataset. We highlight\nthe following observations:\nEmergent language learning As expected, linear models do not work well on zlatent for EL models.\nzpost and zpre are more suitable. zpost consistently outperforms zpre, which reveals that the emergent\nlanguage bottleneck induces compositional latent structures useful for downstream tasks after being\nprocessed by the DecLSTM module.\nDisentanglement learning Surprisingly, mismatched with the goal of disentanglement, zlatent in\nβ-VAE and β-TCVAE is not the optimal choice for downstream tasks. For β -VAE and β -TCVAE,\nincreasing β to decrease the bandwidth of the bottleneck (which was thought of as the source of\ndisentanglement [5]) reduces generalization performance. When β is larger, zpre works best. For\nmost cases, the representation of β = 0 is best. When β = 0, the regression task seems to favor zpre\nwhile zpost performs better for classiﬁcation tasks.\nImplications. Both disentangled representation learning and emergent language learning try to\ninduce compositionality through the inductive bias on the representation’s compositional structure.\nThe zlatent representation itself does not perform well as its structure may be too complex to be\nprocessed by simple linear models. But if zlatent can generalize well, its decoded version zpost will\nperform well. In EL models, zpost consistently performs better than zpre, which demonstrates the\n6\nFigure 3: Compositionality metrics vs generalization performance in the dSprites dataset. The\ndisentanglement metrics (SAP, IRS, DCI, MIG) of the β-VAE (dots) and β-TCVAE (crosses) models\nare not postively correlated with generalization performance in all the three representation modes.\nThe compositionality metric for emergent language (EL), topographical similarity (TopSim), shows\nno strong correlation with generalization performance.\nimproved generalization with the language-like bottleneck. However, disentanglement models may\nlearn useless disentangled representations since increasing the penalty on either the KL-term of the\nELBO or the total correlation consistently lead to worse generalization performance. To further\nconﬁrm this conclusion, we also measure the disentanglement metrics on the learned β-VAE and\nβ-TCVAE models in the next section.\n4.2\nCompositionality Metrics May Not Represent Generalization Performance\nFigure 4: Generalization performance vs Nlabel.\nThree representation modes of β-VAE with β=0,\nβ-TCVAE with β=0, and emergent language\n(EL) with nV =256 are evaluated.\nFigure 5:\nGeneralization performance (with\nNlabel = 500) of β-VAE with β=0, and Emer-\ngent language (EL) with nV =256 on MPI3D-\nReal when using (5%) and (10%) unlabeled data.\nWe further evaluate existing compositionality metrics on learned representations. For β-VAE, β-\nTCVAE with various β, we measure four common disetanglement metrics: Separated Attribute\nPredictability (SAP) Score [27], Interventional Robustness Score (IRS) [43], Disentanglement-\nCompleteness-Informativeness (DCI) [11], and Mutual Information Gap (MIG) [7] based on the\nimplementation in disentanglement-lib [31]. The large-scale studies used by Locatello et al. 2019\n[31] broadly measured these metrics on a few datasets. For emergent language learning models, we\nvary the number of bits in the discrete messages and measure topographical similarity, a common\ncompositionality metric for emergent languages that uses the (Spearman) correlation ρSpearman\nbetween the pairwise distances of the inputs and the distances of the corresponding representations.\nWe compute the cosine distance for input attributes and the editing distance for messages. Since we\nhave the train/test data split for the unsupervised learning stage, we evaluate these metrics on both\nsplits. The metrics on these two splits are similar, and we only show the ones for the train split.\nWe ﬁnd that both β-VAE and β-TCVAE show positive correlations between β and the disentanglement\nmetric scores, stronger in dSprites and weaker in MPI3D-Real where the highest scores usually occur\nfor moderate β values. However, neither of the two datasets show the same pattern as in Fig. 2 where\ngeneralization performance is negatively correlated with β. Therefore, for β-VAE and β-TCVAE,\nmodels with higher disentanglement scores do not achieve a better generalization performance.\nFig. 3 conﬁrms the noncorrelation or even negative correlation between compositionality metrics\nand generalization performance on the dSprites dataset. The topographical similarity of emergent\nlanguage models does not show a strong correlation, e.g. ρSpearman < 0.5 with compositional\n7\ngeneralization for both dSprites and MPI3D-Real datasets. The observations are consistent with some\nprevious studies on emergent language [6] and disentanglement [31].\nImplications. Existing compositionality/disentanglement metrics do not measure the generalization\nperformance of learned representations. However, we should be careful about interpreting the results\nas compositionality in representation learning does not necessarily help compositional generalization.\nAs these metrics were deﬁned more or less based on compositional annotations by humans, they\ncan only measure particular types of compositionality. However, the compositionality exhibited\nin representation learning, especially with unsupervised algorithms, may not match with human\ndeﬁnitions, e.g., a language where editing distance is a poor measure of similarity, and therefore\ncannot be captured by those metrics. Since designing generic compositionality is challenging or\nmaybe even impossible, one should directly evaluate the compositional generalization if it is the\nultimate goal.\n4.3\nRepresentations Learned by Emergent Language Models Generalize Better\nIn Fig 2, we observed some clues that “post” representations of EL models generalize consistently\nwell on both tasks. In this section, we take a closer look at the generalization performance of\nrepresentations learned by EL by comparing them with disentanglement models.\nVarying the number of labeled samples for downstream learning. We evaluate the performance\nof downstream models trained with different numbers of labeled samples Nlabel ∈{100, 500, 1000}.\nWe compare three models: β-VAE and β-TCVAE with β = 0 (since β = 0 consistently performs\nbest, as shown in Fig. 2) and the EL model with nV = 256. Fig. 4 shows the results for dSprites.\nWhen Nlabel is low, e.g. Nlabel = 100 and 500 for dSprites, zpost of EL consistently beats all other\nmodels in all representation modes for both classiﬁcation (accuracy metric) and regression (R2 score\nmetric). More importantly, even when Nlabel is large, 0-VAE/0-TCVAE/AE models do not have a\nconsistent representation mode that shows similar performance as zpost of the EL models: their zpost\nis worse at regression and zpre is worse at classiﬁcation.\nUsing less unlabeled data for unsupervised learning. Furthermore, we reduced the train-split\nratio to 5% to test unsupervised learning algorithms with less unlabeled data. We compared the\nperformance of the 0 -VAE and EL models on MPI3D-Real in Fig. 5. With 5% unlabeled training data,\nthe post representation of EL models outperforms the pre/post 0-VAE model at both classﬁcation\nor regression tasks and all Nlabel with an even larger margin. In other words, the generalization\nperformance of representations of 0-VAE models degrades faster with reduced unlabeled data.\nImplications. Representations learned by emergent language models generalize well even with\nlimited unlabeled data for unsupervised learning and labeled samples for downstream learning.\n4.4\nAblations on Emergent Language Models\nFigure 6: (Left) Ablation study of Emergent Language (EL) with nV = 256 and Nlabel = 500\nin MPI3D-Real using ﬁxed-length messages (EL-ﬁx) and greedy sampling (EL-ﬁx-det). (Right)\nGeneralization performance of EL models with zpost and Nlabel = 500 on the MPI3D-Real dataset,\nfor different bandwidths by varying message sizes nmsg ∈{8, 10, 12} and vocabulary sizes nV ∈\n{128, 256, 512}. Three nmsg are plotted as segments of different line styles with increasing nV /bits.\nSince EL models showed superior compositional generalization performance over disentanglement\nmodels, we conduct ablation studies on important hyperparameters and design choices of EL models\non the MPI3D-real dataset. We ﬁrst study the impact of bandwidth controlled by either length of the\nmessages or the size of dictionary. We can see that increasing the bandwidth generally improves\ncompositional generalization. In some cases, for similar bandwidth, shorter sequences/a larger\nvocabulary is favored, e.g. 5128 vs. 12810. Since the MPI3D-Real dataset only has 6 + 6 + 2 + 3 +\n8\n3 + 40 + 40 = 100 distinct values for all generative factors, a simple choice of language can express\nthe values of factors in a ﬁxed order using nmsg = 7 and nV = 100. Apparently this behavior is not\nlearned by the current design of EL models, possibly because of optimization issues due to poor\ngradient estimation for discretization, regardless of the good generalization performance. However,\nEL models can learn their own language with additional redundancies that require more bandwidth.\nWe also ablate the two characteristics of the EL models we have considered thus far: allowing\nvariable-length messages and using stochastic sampling. We can turn an EL model into one with\nﬁxed-length messages by always generating nmsg tokens (EL-ﬁx) and additionally with deterministic\nmessages by using greedy sampling (EL-ﬁx-det). We can see that as we remove these two designs,\nthe generalization performance is worse, especially after making the model deterministic. Notably,\nthe EL model with ﬁxed-length messages and using deterministic sampling (EL-ﬁx-det) is very close\nto the popular discrete representation learning model VQ-VAE [46] that uses a shared vocabulary\nover spatial locations of the feature map. Therefore, our study may indicate that the use of discrete\nlatent variables of variable length and stochastic sampling can enable unsupervised learning models\nto learn better representations for downstream tasks. We also found that while the EL model allows\nvariable-length codes, at convergence it still almost always uses the maximum message length on\nboth the training and testing set. This is not surprising given that the reconstruction task drives the\ndiscrete message to be longer so that more information can pass through the discrete bottleneck.\n5\nLimitations of Our Study\nOur goal is to provide a comprehensive study of learning algorithms, including their hyperparameters.\nHowever, our study is limited on the variety of other design choices to restrict the experimental\ncomplexity. While we studied both synthetic and realistic image datasets, both these datasets are\nrelatively simple with the same small number of generative factors and each of the factor follows\na uniform distribution. For learning algorithms, we focus on studying the inductive bias on the\nrepresentation format while ﬁxing the model architecture design which can impact the results.\nMoreover, we did not study hyperparameters beyond those related to the latent representations.\nSpeciﬁcally, we did not study how the type and conﬁgurations of the optimizer and the batch size\nwould change the results; instead, we followed common setups in previous studies.\n6\nRelated Work\nCompositional generalization was shown in previous work on disentangled representation learning\n[12, 21] to generate images of novel combinations of concepts. Zhao et al. [50] systematically\nevaluated generative models in a few compositional generalization tasks without exploring whether\ndisentanglement is correlated with generalization performance. Recently, Montero et al. [36] studied\nthe compositional generalization along with the interpolation and extrapolation generalization of\ntwo VAE-based disentanglement models. Similar to [50], the performance is evaluated on the\nunsupervised learning task, e.g. image reconstruction/generation. However, we directly evaluate\nthe compositional generalization. Different from [36] that manually selects the train-test splits with\nvarious difﬁculty, we use random splits which is earlier for studying different split ratios.\nThe comprehensive study on the unsupervised learning of disentangled representation by Locatello\net al. [31] included an evaluation on downstream tasks. However, they train unsupervised models\non the whole dataset and therefore are not able to evaluate the generalization as we do. [10]\nevaluated the downstream out-of-distribution (OOD) generalization that includes the interpolation\nand extrapolation generalization of unsupervised and weakly supervised disentanglement models,\nwhile we focus on compositional generalization. A very recent work [41] included compositional\ngeneralization behaviors of unsupervised and weakly supervised disentanglement models in their\nbroad study on generalization. Unlike our evaluation that trains simple downstream models with a\nsmall amount of labeled samples, they use all labels in the train set to learn MLP models. Furthermore,\nnone of these works evaluated the representations beyond the latent variables at the bottleneck layer\nas we did.\nIn emerging language (EL) learning, Chaabouni et al. [6] found that regardless of the degree of\ncompositionality measured by topographic similarity, EL can generalize to novel combinations of\nconcepts when the input space is rich enough. Andreas [1] proposed a new compositionality metric,\n9\ntree reconstruction error (TRE), measuring how well a representation model can be approximated\nby a compositional operator and learnable primitive representations. While claimed as a general\ncompositionality metric with learnable compositional operator, some pre-commitment to a restricted\ncomposition function is essentially inevitable. Similar to [6], [1] also studied the relationship between\nTRE and generalization. While they work on simple attribute data and evaluate on the tasks for\nemergent language learning, we used image data and are motivated by learning useful representations\nfor downstream tasks. Furthermore, unlike all previous work, we studied the compositional general-\nization of representations from both disentanglement and emergent language models with a uniﬁed\nsetup.\n7\nConclusions and Discussions\nWe proposed a protocol to evaluate the compositional generalization of unsupervised representation\nlearning models that have a built-in inductive bias for compositionality: disentanglement models\nand emergent language (EL) learning. Our evaluation emphasizes using a small number of labeled\nsamples to train simple models for downstream tasks. The interesting ﬁnding that latent variables\nat the bottleneck do not work as well as “pre\" and “post\" representations reminds us to be careful\nwhen concluding that a model performs poorly when its latent representation does not perform\nwell. For disentanglement models, we observe that generalization performance is not well correlated\nwith existing disentanglement metrics. This ﬁnding demonstrates the gap between pursuing better\ndisentanglement metrics and more generalizable representations in previous studies. Similarly,\nthe existing compositionality metrics for EL, e.g. topographical similarity, cannot represent the\ngeneralization of learned representations. However, under the same setup, EL models which were not\ninitially proposed for unsupervised representation learning induce representations with surprisingly\nstrong compositional generalization and are robust to the change of dataset and hyperparameters.\nWe focus on unsupervised learning algorithms that are speciﬁcally designed for compositional\nrepresentation to answer whether they lead to better generalization (which was an assumption made\nby a great deal of prior work). A broader evaluation on other representation learning approaches e.g.\nself-supervised learning [8, 18] would be interesting for future work. We hope that our study draws\nmore attention to the study of compositional generalization and emergent language models as a way of\nlearning representations. Interesting future directions include working on more challenging datasets,\ne.g. images of multiple objects; testing on other downstream tasks, e.g. visual question answering;\ntesting different model architectures, e.g. Transformers [47]; and developing better pre-training tasks\nbeyond auto-encoding. Recent work showing that emergent language (zlatent) can be used as a\ncorpus to pre-train a language model [48] also suggests that emergent language may be a better visual\nrepresentation choice in vision-language models.\nAcknowledgement\nWe thank Nikhil Kandpal for giving feedback on the draft of the paper. Zhenlin Xu is supported by\nthe Royster Society of Fellows Dissertation Completion Fellowship during this work.\nReferences\n[1] ANDREAS, Jacob:\nMeasuring Compositionality in Representation Learning. In: Interna-\ntional Conference on Learning Representations, URL https://openreview.net/forum?\nid=HJz05o0qK7, 2019\n[2] BENGIO, Yoshua ; LÉONARD, Nicholas ; COURVILLE, Aaron: Estimating or propagating gradi-\nents through stochastic neurons for conditional computation. In: arXiv preprint arXiv:1308.3432\n(2013)\n[3] BIEDERMAN, Irving: Recognition-by-components: a theory of human image understanding.\nIn: Psychological review 94 (1987), Nr. 2, S. 115\n[4] BRIGHTON, Henry ; KIRBY, Simon: Understanding linguistic evolution by visualizing the\nemergence of topographic mappings. In: Artiﬁcial life 12 (2006), Nr. 2, S. 229–242\n10\n[5] BURGESS, Christopher P. ; HIGGINS, Irina ; PAL, Arka ; MATTHEY, Loic ; WATTERS, Nick ;\nDESJARDINS, Guillaume ; LERCHNER, Alexander: Understanding disentangling in β-VAE. In:\narXiv preprint arXiv:1804.03599 (2018)\n[6] CHAABOUNI, Rahma ; KHARITONOV, Eugene ; BOUCHACOURT, Diane ; DUPOUX, Em-\nmanuel ; BARONI, Marco: Compositionality and Generalization In Emergent Languages. In:\nJURAFSKY, Dan (Hrsg.) ; CHAI, Joyce (Hrsg.) ; SCHLUTER, Natalie (Hrsg.) ; TETREAULT,\nJoel R. (Hrsg.): Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, ACL 2020, Online, July 5-10, 2020, Association for Computational Linguistics,\n2020, S. 4427–4442. – URL https://doi.org/10.18653/v1/2020.acl-main.407\n[7] CHEN, Ricky T. Q. ; LI, Xuechen ; GROSSE, Roger B. ; DUVENAUD, David K.: Isolating\nSources of Disentanglement in Variational Autoencoders. In: BENGIO, S. (Hrsg.) ; WALLACH,\nH. (Hrsg.) ; LAROCHELLE, H. (Hrsg.) ; GRAUMAN, K. (Hrsg.) ; CESA-BIANCHI, N. (Hrsg.) ;\nGARNETT, R. (Hrsg.): Advances in Neural Information Processing Systems Bd. 31, Curran\nAssociates, Inc., 2018, S. 2610–2620. – URL https://proceedings.neurips.cc/paper/\n2018/file/1ee3dfcd8a0645a25a35977997223d22-Paper.pdf\n[8] CHEN, Ting ; KORNBLITH, Simon ; NOROUZI, Mohammad ; HINTON, Geoffrey: A simple\nframework for contrastive learning of visual representations. In: International conference on\nmachine learning PMLR (Veranst.), 2020, S. 1597–1607\n[9] CHRUPAŁA, Grzegorz ; KÁDÁR, Ákos ; ALISHAHI, Afra: Learning language through pictures.\nIn: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics\nand the 7th International Joint Conference on Natural Language Processing (Volume 2: Short\nPapers), 2015, S. 112–118\n[10] DITTADI, Andrea ; TRÄUBLE, Frederik ; LOCATELLO, Francesco ; WUTHRICH, Manuel ;\nAGRAWAL, Vaibhav ; WINTHER, Ole ; BAUER, Stefan ; SCHÖLKOPF, Bernhard: On the\nTransfer of Disentangled Representations in Realistic Settings. In: International Conference\non Learning Representations, URL https://openreview.net/forum?id=8VXvj1QNRl1,\n2021\n[11] EASTWOOD, Cian ; WILLIAMS, Christopher K. I.: A framework for the quantitative evaluation\nof disentangled representations. In: International Conference on Learning Representations,\nURL https://openreview.net/forum?id=By-7dz-AZ, 2018\n[12] ESMAEILI, Babak ; WU, Hao ; JAIN, Sarthak ; BOZKURT, Alican ; SIDDHARTH,\nNarayanaswamy ; PAIGE, Brooks ; BROOKS, Dana H. ; DY, Jennifer ; MEENT, Jan-Willem:\nStructured disentangled representations. In: The 22nd International Conference on Artiﬁcial\nIntelligence and Statistics PMLR (Veranst.), 2019, S. 2525–2534\n[13] FELZENSZWALB, Pedro F. ; GIRSHICK, Ross B. ; MCALLESTER, David ; RAMANAN, Deva:\nObject detection with discriminatively trained part-based models. In: IEEE transactions on\npattern analysis and machine intelligence 32 (2009), Nr. 9, S. 1627–1645\n[14] FIDLER, Sanja ; LEONARDIS, Ales: Towards scalable representations of object categories:\nLearning a hierarchy of parts. In: 2007 IEEE Conference on Computer Vision and Pattern\nRecognition IEEE (Veranst.), 2007, S. 1–8\n[15] FODOR, Jerry A.: The language of thought. Bd. 5. Harvard university press, 1975\n[16] FODOR, Jerry A. ; PYLYSHYN, Zenon W.: Connectionism and cognitive architecture: A critical\nanalysis. In: Cognition 28 (1988), Nr. 1-2, S. 3–71\n[17] GONDAL, Muhammad W. ; WUTHRICH, Manuel ; MILADINOVIC, Djordje ; LOCATELLO,\nFrancesco ; BREIDT, Martin ; VOLCHKOV, Valentin ; AKPO, Joel ; BACHEM, Olivier ;\nSCHÖLKOPF, Bernhard ; BAUER, Stefan:\nOn the Transfer of Inductive Bias from Simu-\nlation to the Real World: a New Disentanglement Dataset.\nIn: WALLACH, H. (Hrsg.) ;\nLAROCHELLE, H. (Hrsg.) ; BEYGELZIMER, A. (Hrsg.) ; ALCHÉ-BUC, F. d'(Hrsg.) ; FOX, E.\n(Hrsg.) ; GARNETT, R. (Hrsg.): Advances in Neural Information Processing Systems Bd. 32,\nCurran Associates, Inc., 2019. – URL https://proceedings.neurips.cc/paper/2019/\nfile/d97d404b6119214e4a7018391195240a-Paper.pdf\n11\n[18] GRILL, Jean-Bastien ; STRUB, Florian ; ALTCHÉ, Florent ; TALLEC, Corentin ; RICHEMOND,\nPierre ; BUCHATSKAYA, Elena ; DOERSCH, Carl ; AVILA PIRES, Bernardo ; GUO, Zhaohan ;\nGHESHLAGHI AZAR, Mohammad u. a.: Bootstrap your own latent-a new approach to self-\nsupervised learning.\nIn: Advances in neural information processing systems\n33 (2020),\nS. 21271–21284\n[19] HAVRYLOV, Serhii ; TITOV, Ivan: Emergence of language with multi-agent games: Learning\nto communicate with sequences of symbols. In: Advances in neural information processing\nsystems, 2017, S. 2149–2159\n[20] HIGGINS, Irina ; MATTHEY, Loic ; PAL, Arka ; BURGESS, Christopher ; GLOROT, Xavier ;\nBOTVINICK, Matthew ; MOHAMED, Shakir ; LERCHNER, Alexander: β-VAE: Learning basic\nvisual concepts with a constrained variational framework. In: International Conference on\nLearning Representations, 2017\n[21] HIGGINS, Irina ; SONNERAT, Nicolas ; MATTHEY, Loic ; PAL, Arka ; BURGESS, Christo-\npher P. ; BOŠNJAK, Matko ; SHANAHAN, Murray ; BOTVINICK, Matthew ; HASSABIS, Demis ;\nLERCHNER, Alexander: SCAN: Learning Hierarchical Compositional Visual Concepts. In:\nInternational Conference on Learning Representations, 2018\n[22] HOFFMAN, Donald D. ; RICHARDS, Whitman A.: Parts of recognition. In: Cognition 18\n(1984), Nr. 1-3, S. 65–96\n[23] JANG, Eric ; GU, Shixiang ; POOLE, Ben: Categorical reparameterization with gumbel-softmax.\nIn: International Conference on Learning Representations, URL https://openreview.net/\nforum?id=rkE3y85ee, 2017\n[24] KIM, Hyunjik ; MNIH, Andriy: Disentangling by factorising. In: International Conference on\nMachine Learning PMLR (Veranst.), 2018, S. 2649–2658\n[25] KINGMA, Diederik P. ; WELLING, Max: Auto-encoding variational bayes. In: arXiv preprint\narXiv:1312.6114 (2013)\n[26] KINGMA, Durk P. ; MOHAMED, Shakir ; JIMENEZ REZENDE, Danilo ; WELLING, Max:\nSemi-supervised learning with deep generative models. In: Advances in neural information\nprocessing systems 27 (2014)\n[27] KUMAR, Abhishek ; SATTIGERI, Prasanna ; BALAKRISHNAN, Avinash: VARIATIONAL\nINFERENCE OF DISENTANGLED LATENT CONCEPTS FROM UNLABELED OB-\nSERVATIONS. In: International Conference on Learning Representations, URL https:\n//openreview.net/forum?id=H1kG7GZAW, 2018\n[28] LAKE, Brenden M. ; ULLMAN, Tomer D. ; TENENBAUM, Joshua B. ; GERSHMAN, Samuel J.:\nBuilding machines that learn and think like people. In: Behavioral and brain sciences 40 (2017)\n[29] LAZARIDOU, Angeliki ; PHAM, Nghia T. ; BARONI, Marco:\nTowards multi-agent\ncommunication-based language learning. In: arXiv preprint arXiv:1605.07133 (2016)\n[30] LIN, Zhixuan ; WU, Yi-Fu ; PERI, Skand V. ; SUN, Weihao ; SINGH, Gautam ; DENG, Fei ;\nJIANG, Jindong ; AHN, Sungjin: SPACE: Unsupervised Object-Oriented Scene Represen-\ntation via Spatial Attention and Decomposition. In: International Conference on Learning\nRepresentations, URL https://openreview.net/forum?id=rkl03ySYDH, 2020\n[31] LOCATELLO, Francesco ; BAUER, Stefan ; LUCIC, Mario ; RAETSCH, Gunnar ; GELLY,\nSylvain ; SCHÖLKOPF, Bernhard ; BACHEM, Olivier: Challenging Common Assumptions in\nthe Unsupervised Learning of Disentangled Representations. In: International Conference on\nMachine Learning, 2019, S. 4114–4124\n[32] MADDISON, Chris J. ; MNIH, Andriy ; TEH, Yee W.:\nThe concrete distribution: A con-\ntinuous relaxation of discrete random variables. In: International Conference on Learning\nRepresentations, URL https://openreview.net/forum?id=S1jE5L5gl, 2017\n[33] MARCUS, Gary: Deep learning: A critical appraisal. In: arXiv preprint arXiv:1801.00631\n(2018)\n12\n[34] MATHIEU, Emile ; RAINFORTH, Tom ; SIDDHARTH, Nana ; TEH, Yee W.: Disentangling\ndisentanglement in variational autoencoders. In: International Conference on Machine Learning\nPMLR (Veranst.), 2019, S. 4402–4412\n[35] MATTHEY, Loic ; HIGGINS, Irina ; HASSABIS, Demis ; LERCHNER, Alexander: dSprites:\nDisentanglement testing Sprites dataset. https://github.com/deepmind/dsprites-dataset/. 2017\n[36] MONTERO, Milton L. ; LUDWIG, Casimir J. ; COSTA, Rui P. ; MALHOTRA, Gaurav ; BOW-\nERS, Jeffrey: The role of Disentanglement in Generalisation. In: International Conference\non Learning Representations, URL https://openreview.net/forum?id=qbH974jKUVy,\n2021\n[37] OTT, Patrick ; EVERINGHAM, Mark: Shared parts for deformable part-based models. In: CVPR\n2011 IEEE (Veranst.), 2011, S. 1513–1520\n[38] PANDEY, Megha ; LAZEBNIK, Svetlana: Scene recognition and weakly supervised object\nlocalization with deformable part-based models. In: 2011 International Conference on Computer\nVision IEEE (Veranst.), 2011, S. 1307–1314\n[39] PURUSHWALKAM, Senthil ;\nNICKEL, Maximilian ;\nGUPTA, Abhinav ;\nRANZATO,\nMarc’Aurelio: Task-driven modular networks for zero-shot compositional learning. In: Pro-\nceedings of the IEEE/CVF International Conference on Computer Vision, 2019, S. 3593–3602\n[40] REN, Yi ; GUO, Shangmin ; LABEAU, Matthieu ; COHEN, Shay B. ; KIRBY, Simon: Composi-\ntional languages emerge in a neural iterated learning model. In: International Conference on\nLearning Representations, URL https://openreview.net/forum?id=HkePNpVKPB, 2020\n[41] SCHOTT, Lukas ; KÜGELGEN, Julius V. ; TRÄUBLE, Frederik ; GEHLER, Peter V. ; RUS-\nSELL, Chris ; BETHGE, Matthias ; SCHÖLKOPF, Bernhard ; LOCATELLO, Francesco ; BREN-\nDEL, Wieland: Visual Representation Learning Does Not Generalize Strongly Within the\nSame Domain. In: International Conference on Learning Representations, URL https:\n//openreview.net/forum?id=9RUHPlladgh, 2022\n[42] STONE, Austin ; WANG, Huayan ; STARK, Michael ; LIU, Yi ; SCOTT PHOENIX, D ; GEORGE,\nDileep:\nTeaching compositionality to cnns. In: Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition, 2017, S. 5058–5067\n[43] SUTER, Raphael ; MILADINOVIC, Djordje ; SCHÖLKOPF, Bernhard ; BAUER, Stefan: Robustly\ndisentangled causal mechanisms: Validating deep representations for interventional robustness.\nIn: International Conference on Machine Learning PMLR (Veranst.), 2019, S. 6056–6065\n[44] THRUSH, Tristan ; JIANG, Ryan ; BARTOLO, Max ; SINGH, Amanpreet ; WILLIAMS, Adina ;\nKIELA, Douwe ; ROSS, Candace: Winoground: Probing Vision and Language Models for\nVisio-Linguistic Compositionality. In: arXiv preprint arXiv:2204.03162 (2022)\n[45] TOKMAKOV, Pavel ; WANG, Yu-Xiong ; HEBERT, Martial: Learning compositional repre-\nsentations for few-shot recognition. In: Proceedings of the IEEE International Conference on\nComputer Vision, 2019, S. 6372–6381\n[46] VAN DEN OORD, Aaron ; VINYALS, Oriol u. a.: Neural discrete representation learning. In:\nAdvances in neural information processing systems 30 (2017)\n[47] VASWANI, Ashish ; SHAZEER, Noam ; PARMAR, Niki ; USZKOREIT, Jakob ; JONES, Llion ;\nGOMEZ, Aidan N. ; KAISER, Łukasz ; POLOSUKHIN, Illia: Attention is all you need. In:\nAdvances in neural information processing systems (2017)\n[48] YAO, Shunyu ; YU, Mo ; ZHANG, Yang ; NARASIMHAN, Karthik R. ; TENENBAUM, Joshua B. ;\nGAN, Chuang: Linking Emergent and Natural Languages via Corpus Transfer. In: Interna-\ntional Conference on Learning Representations, URL https://openreview.net/forum?\nid=49A1Y6tRhaq, 2022\n[49] YUN, Tian ; BHALLA, Usha ; PAVLICK, Ellie ; SUN, Chen: Do Vision-Language Pretrained\nModels Learn Primitive Concepts? In: arXiv preprint arXiv:2203.17271 (2022)\n13\n[50] ZHAO, Shengjia ; REN, Hongyu ; YUAN, Arianna ; SONG, Jiaming ; GOODMAN, Noah ;\nERMON, Stefano: Bias and generalization in deep generative models: An empirical study. In:\nAdvances in Neural Information Processing Systems 31 (2018)\nChecklist\n1. For all authors...\n(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s\ncontributions and scope? [Yes]\n(b) Did you describe the limitations of your work? [Yes] See Appendix.\n(c) Did you discuss any potential negative societal impacts of your work? [No]\n(d) Have you read the ethics review guidelines and ensured that your paper conforms to\nthem? [Yes]\n2. If you are including theoretical results...\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\n(b) Did you include complete proofs of all theoretical results? [N/A]\n3. If you ran experiments...\n(a) Did you include the code, data, and instructions needed to reproduce the main experi-\nmental results (either in the supplemental material or as a URL)? [Yes]\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\nwere chosen)? [Yes] See Section 3.3\n(c) Did you report error bars (e.g., with respect to the random seed after running experi-\nments multiple times)? [Yes]\n(d) Did you include the total amount of compute and the type of resources used (e.g., type\nof GPUs, internal cluster, or cloud provider)? [Yes] See Appendix.\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\n(a) If your work uses existing assets, did you cite the creators? [Yes]\n(b) Did you mention the license of the assets? [Yes] See Appendix.\n(c) Did you include any new assets either in the supplemental material or as a URL? [N/A]\n(d) Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? [N/A]\n(e) Did you discuss whether the data you are using/curating contains personally identiﬁable\ninformation or offensive content? [N/A]\n5. If you used crowdsourcing or conducted research with human subjects...\n(a) Did you include the full text of instructions given to participants and screenshots, if\napplicable? [N/A]\n(b) Did you describe any potential participant risks, with links to Institutional Review\nBoard (IRB) approvals, if applicable? [N/A]\n(c) Did you include the estimated hourly wage paid to participants and the total amount\nspent on participant compensation? [N/A]\n14\nA\nMore Implementation Details\nModel architectures.\nIn our experiments, disentanglement models and emergent language (EL)\nmodels use the same architectures for the convolutional encoder and decoder. Disentanglement\nmodels use an MLP to encode the convolutional features into the disentangled latent variables and\nanother MLP to decode them, while EL models use two LSTMs to encode and decode the discrete\nmessages. Table 1 provides architecture details for all these modules.\nTable 1: The encoder module architectures which are the symmetric reﬂection of the decoder layers.\nEncConv\nEncMLP\nEncLSTM\n4x4 Conv, 64 ReLU, stride 2\nFC 512, ReLU\nLSTM 512\n4x4 Conv, 128 ReLU, stride 2\nFC 1024, ReLU\n4x4 Conv, 128 ReLU, stride 2\nFC 1024, ReLU\nLinear nmsg\n4x4 Conv, 128 ReLU, stride 2\nFC 512, ReLU\nFlatten layer\nLinear |zlatent|\nReadout Models.\nWe use the implementations in scikit-learn1 (version 0.22) for the readout\nmodels of our downstream evaluation. The speciﬁc linear or gradient boosting tree (GBT) models for\nclassiﬁcation or regression tasks are conﬁgured as speciﬁed in Table 2.\nTable 2: The implementation details of the readout models.\nScikit-learn function\nConﬁguration\nLinear\nlinear_model.LogisticRegressionCV\ndefault\nlinear_model.RidgeCV\nalphas=[0, 0.01, 0.1, 1.0, 10]\nGBT\nensemble.GradientBoostingClassiﬁer\ndefault\nensemble.GradientBoostingRegressor\ndefault\nComputational Cost.\nWe use an Nvidia RTX A6000 to benchmark the computational cost. For\nunsupervised representation learning, training a β-VAE or a β-TCVAE model takes about 3 hours\nand 10 hours for dSprites and MPI3D-real respectively, and an EL model with nmsg = 10 takes\nabout 11 and 15 hours respectively for dSprites and MPI3D-real .\nDataset License.\nThe two datasets used in our experiments, dSprites2 and MPI3D3, are publicly\navailable under an Apache License and the Creative Commons Public License respectively.\nReproducibility.\nOur code is publicly available.4.\nB\nSanity Check Experiments with Oracle Representations\nWe test the oracle representations using the ground truth value of all attributes or the squared value\nof each attribute (which would not be perfectly linearly ﬁttable). On the dSprites dataset, we use\n500 samples to train linear or GBT readout models for classiﬁcation and regressions tasks. Their\ngeneralization performance is given in Table 3. It is expected that the attribute values can generalize\nperfectly with either linear or GBT readout models. However, linear readout models can still ﬁt\nthe non-linear attributes2 well. We think this may be due to the limited value range of attributes of\nour datasets. This experiment shows that if the learned representation is disentangled into attributes\n(as is often the goal), the linear head should not be a major issue to constrain the generalization\nperformance.\n1https://scikit-learn.org/\n2https://github.com/deepmind/dsprites-dataset\n3https://github.com/rr-learning/disentanglement_dataset\n4https://github.com/wildphoton/Compositional-Generalization\n15\nTable 3: Sanity check with oracle linear and non-linear representations. The accuracy/R2-score are\nreported for classﬁﬁcation and regression tasks respectively.\nRepresentations\nLinear\nGBT\nattributes\n100% /100%\n100% / 100%\nattributes2\n94.7% / 100%\n100% / 100%\nC\nDetailed Experimental Results\nIn the main article, we only present representative results to support our key ﬁndings. In this section,\nwe provide detailed results for different algorithms and datasets with additional gradient-boosting-tree\n(GBT) read-out models that are able to model non-linear mappings.\nCompositional latent variables may not be the best representations for downstream tasks.\nFig. 7 compares pre, latent, and post representation modes for three different learning models\n(β-VAE, β-TCVAE, and emergent language (EL)) using different read-out models. For emergent\nlanguage (EL) models, when using GBT instead of linear models for downstream tasks, zlatent perfor-\nmance improves, but still underperforms zpre and zpost. For disentanglement models, increasing the\nregularization (β) still decreases performance when using GBT read-out models. However, when\nβ = 0, the regression task no longer favors zpre and zpost performs well for both the regression and\nclassiﬁcation tasks.\nCompositionality Metrics May Not Represent Generalization Performance.\nFig. 8 shows the\ndisentanglement/compositionality metrics vs generalization performance on the dSprites and MPI3D-\nReal datasets using linear and GBT read-out models. Consistently to our results in the main article,\nwe do not observe strong correlations between these metrics and generalization performance. Figs. 9\nand 10 show quantitative measures of ranking correlation. We see that for disentanglement models,\nall metrics show no or negative correlations with generalization performance except for a weak\ncorrelation between the DCI score and generalization on the MPI3D-Real dataset. For EL models,\npost representations show stronger, although still weak, correlations than pre representations.\nRepresentations Learned by Emergent Language Models Generalize Better.\nFig. 11 compares\nEL models with β-VAE and β-TCVAE with β = 0. We see that zpre of EL using linear read-out\nmodels gives the best performance overall especially when Nlabel is small. While applying GBT\nread-out models improves the performance of zpost/zpre over the 0-VAE and 0-TCVAE models and\nzpre from the EL models in regression tasks, GBT read-out reduces performance in other cases,\nespecially for classiﬁcation tasks. The reason may be that GBT models need more labeled samples\nthan linear models for training to work well. When we reduce the train-split ratio in Fig. 12, the\nEL model learns more generalizable representations than the 0-VAE and 0-TCVAE models which\ndegrade faster with reduced unlabeled data.\nAblations on Emergent Language Models.\nFrom the ablation study of EL models in Figs. 14\nand 13, we observe consistent patterns: using a shorter sequence with a larger vocabulary size works\nbetter; using greedy sampling signiﬁcantly reduces the performance of EL models.\nA closer look of generalization.\nOur evaluation protocol includes two training stages: unsuper-\nvised pre-training of a representation model and supervised training of a read-out model with a small\namount of labeled data. To better understand the generalization results, we further evaluate perfor-\nmance on the whole unsupervised training data (US-train) that is only visible to the representation\nmodel, and the supervised training data (S-train) that is part of the pre-training data and were seen\nby both the representation model and the readout model. The results on the held-out test set (Test)\nunseen by both training stages are given as a reference. In Table 4, we show results of evaluating the\npre/latent/post representations of EL and β-VAE(beta=0) with linear or GBT readout models on the\ndSprites dataset. The classiﬁcation accuracy or regression R2 score is given in each entry.\n16\n• On all representation models/modes and read-out models, the performance of Unsup-train\nand test is very close. This tells us that an example seen by the unusupervised pretraining\nstage does not necessarily have good performance in a downstream task in our setting.\n• In the S-train set, linear readout models under-ﬁt the latent representations of both VAE\nand EL models. Bad performance is expected for EL-latent representations since a linear\nreadout model is not a good choice for language-like messages as discussed in the paper.\nCombined with sanity-checking experiment B, it indicates that VAE models do not produce\nrepresentations that disentangle attributes.\n• GBT readout models ﬁt EL-latent and VAE-latent well on S-train but generalize poorly\nto US-train and Test. This further indicates that latent representations perform worse in\nproviding good generalization when compared to pre/post representations.\nTable 4: Performance on three subsets of dSprites data. Pre/latent/post representations of EL and\nβ-VAE(beta=0) are evaluated with linear and GBT readout models. The classiﬁcation accuracy /\nregression R2 score is given in each entry.\nData + Readout\nVAE-Pre\nVAE-Latent\nVAE-Post\nEL-Pre\nEL-Latent\nEL-Post\nS-train + Linear\n99.93/94.48\n73.27/64.83\n100/95.99\n100/92.55\n46.13/13.35\n100/99.39\nUS-train + Linear\n84.83/84.15\n70.89/63.13\n98.74/71.29\n91.02/84.7\n39.11/9.92\n99.99/98.04\nTest + Linear\n84.3/83.9\n70.98/63.1\n97.88/73.98\n90.56/84.6\n38.8/9.5\n99.94/97.85\nS-train + GBT\n100/96.44\n99.33/93.64\n100/98.81\n100/95.86\n96.93/83.63\n100/99.83\nUS-train + GBT\n77.67/79.44\n76.8/77.57\n97.73/88.34\n81.58/81.02\n56.19/58.53\n99.53/95.83\nTest + GBT\n76.76/78.95\n76.09/77.26\n96.83/87.82\n80.86/90.56\n54.84/57.36\n99.52/95.68\n17\n(a) Results on dSprites with linear read-out models.\n(b) Results on dSprites with GBT read-out models.\n(c) Results on MPI3D-Real with linear read-out models.\n(d) Results on MPI3D-Real with GBT read-out models\nFigure 7: Generalization performance (accuracy for classiﬁcation and R2 score for regression) with\nNlabel = 500 of three representation models: β-VAE, β-TCVAE, and emergent language (EL)\nvarying hyper-parameters (β or bandwidth), datasets (dSprites and MPI3D-Real) and read-out model\n(linear and GPT).\n18\n(a) Results on dSprites with linear read-out models.\n(b) Results on dSprites with GBT read-out models.\n(c) Results on MPI3D-Real with linear read-out models.\n(d) Results on MPI3D-Real with GBT read-out models\nFigure 8: Compositionality metrics vs generalization performance on dSprites and MPI3D-Real\ndatasets, and linear and GPT read-out models. The disentanglement metrics (SAP, IRS, DCI, MIG)\nof the β-VAE (dots) and β-TCVAE (crosses) models are not positively correlated with generalization\nperformance in all the three representation modes. The compositionality metric for emergent language\n(EL), topographical similarity (TopSim), shows no strong correlation with generalization performance.\n19\nFigure 9: Ranking correlation between disentanglement scores (SAP, IRS, DCI, MIG) and the\ngeneralization performance of three representation modes (pre, latent, post) using linear (the ﬁrst row)\nand GBT (the second row) read-out models on dSprites (the left column) and MPI3D-Real (the right\ncolumn) datasets. Except for the DCI metric, which shows weak correlations with generalization\nperformance on MPI3D-Real, all other metrics show no or even negative correlations.\nFigure 10: Ranking correlation between topographical similarity (TopSim) and the generalization\nperformance of three representation modes (pre, latent, post) using linear (the left column) and GBT\n(the right column) read-out models on dSprites (the second row) and MPI3D-Real (the ﬁrst row)\ndatasets. The correlations between TopSim and generalization are stronger on post representations\nthan on the pre representations.\n20\n(a) Results on dSprites dataset.\n(b) Results on MPI3D-Real dataset.\nFigure 11: Generalization performance of two representation modes (pre, post) of β-VAE with β=0,\nβ-TCVAE with β=0, and emergent language (EL) with nV =512 when evaluated with linear (LN)\nand gradient boosting tree (GBT) read-out models.\n21\nFigure 12: Generalization performance of pre and post representations of β-VAE with β=0 (0-β-\nVAE) and β-TCVAE with β=0 (0-β-TCVAE), and post representations of emergent language (EL)\nwith nV =512 when evaluated with linear (LN) and gradient boosting tree (GBT) read-out models on\nMPI3D-Real when using (5%) and (10%) unlabeled data.\n22\n(a) Results using linear read-out models.\n(b) Results using GBT read-out models.\nFigure 13:\nAblation study of Emergent Language (EL) models with zpost and Nlabel\n=\n100/500/1000 on MPI3D-Real dataset evaluated with linear (a) and gradient boosting tree (b)\nread-out models, for different bandwidths by varying message sizes nmsg ∈{8, 10, 12} and vocab-\nulary sizes nV ∈{128, 256, 512}. The three nmsg results are plotted as segments of different line\nstyles with increasing nV /bits.\n23\n(a) Results using linear read-out models.\n(b) Results using GBT read-out models.\nFigure 14: Ablation study of Emergent Language (EL) with nV = 512 and Nlabel = 100/500/1000\nfor MPI3D-Real when using ﬁxed-length messages (EL-ﬁx) and greedy sampling (EL-ﬁx-det).\n24\n",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CV"
  ],
  "published": "2022-10-02",
  "updated": "2022-10-05"
}