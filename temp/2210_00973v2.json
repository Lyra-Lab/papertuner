{
  "id": "http://arxiv.org/abs/2210.00973v2",
  "title": "NCVX: A General-Purpose Optimization Solver for Constrained Machine and Deep Learning",
  "authors": [
    "Buyun Liang",
    "Tim Mitchell",
    "Ju Sun"
  ],
  "abstract": "Imposing explicit constraints is relatively new but increasingly pressing in\ndeep learning, stimulated by, e.g., trustworthy AI that performs robust\noptimization over complicated perturbation sets and scientific applications\nthat need to respect physical laws and constraints. However, it can be hard to\nreliably solve constrained deep learning problems without optimization\nexpertise. The existing deep learning frameworks do not admit constraints.\nGeneral-purpose optimization packages can handle constraints but do not perform\nauto-differentiation and have trouble dealing with nonsmoothness. In this\npaper, we introduce a new software package called NCVX, whose initial release\ncontains the solver PyGRANSO, a PyTorch-enabled general-purpose optimization\npackage for constrained machine/deep learning problems, the first of its kind.\nNCVX inherits auto-differentiation, GPU acceleration, and tensor variables from\nPyTorch, and is built on freely available and widely used open-source\nframeworks. NCVX is available at https://ncvx.org, with detailed documentation\nand numerous examples from machine/deep learning and other fields.",
  "text": "arXiv:2210.00973v2  [cs.LG]  14 Nov 2022\nOPT2022: 14th Annual Workshop on Optimization for Machine Learning\nNCVX: A General-Purpose Optimization Solver for\nConstrained Machine and Deep Learning\nBuyun Liang1\nLIANG664@UMN.EDU\nTim Mitchell2\nTMITCHELL@QC.CUNY.EDU\nJu Sun1\nJUSUN@UMN.EDU\n1Computer Science & Engineering, University of Minnesota, Minneapolis, USA\n2Queens College, City University of New York, New York City, USA\nAbstract\nImposing explicit constraints is relatively new but increasingly pressing in deep learning, stimu-\nlated by, e.g., trustworthy AI that performs robust optimization over complicated perturbation sets\nand scientiﬁc applications that need to respect physical laws and constraints. However, it can be\nhard to reliably solve constrained deep learning problems without optimization expertise. The ex-\nisting deep learning frameworks do not admit constraints. General-purpose optimization packages\ncan handle constraints but do not perform auto-differentiation and have trouble dealing with nons-\nmoothness. In this paper, we introduce a new software package called NCVX, whose initial release\ncontains the solver PyGRANSO, a PyTorch-enabled general-purpose optimization package for con-\nstrained machine/deep learning problems, the ﬁrst of its kind. NCVX inherits auto-differentiation,\nGPU acceleration, and tensor variables from PyTorch, and is built on freely available and widely\nused open-source frameworks. NCVX is available at https://ncvx.org, with detailed docu-\nmentation and numerous examples from machine/deep learning and other ﬁelds.\n1. Introduction\nMathematical optimization is an indispensable modeling and computational tool for all science\nand engineering ﬁelds, especially for machine/deep learning.\nTo date, researchers have devel-\noped numerous foolproof techniques, user-friendly solvers, and modeling languages for convex\n(CVX) problems, such as SDPT3 [66], Gurobi [28], Cplex [14], TFOCS [5], CVX(PY) [22, 27],\nAMPL [24], YALMIP [46]. These developments have substantially lowered the barrier of CVX\noptimization for non-experts. However, practical problems, especially from machine/deep learning,\nare often nonconvex (NCVX), and possibly also constrained (CSTR) and nonsmooth (NSMT).\nThere are methods and packages handling NCVX problems in restricted settings: PyTorch [56]\nand TensorFlow [1] can solve large-scale NCVX, NSMT problems without constraints. CSTR prob-\nlems can be heuristically turned into penalty forms and solved as unconstrained, but this may not\nproduce feasible solutions for the original problems. When the constraints are simple, structured\nmethods such as projected (sub)gradient and Frank-Wolfe [61] can be used. When the constraints\nare differentiable manifolds, one can consider manifold optimization methods and packages, e.g.,\n(Py)manopt [6, 67], Geomstats [53], McTorch [51], and Geoopt [39]. For general CSTR prob-\nlems, KNITRO [58] and IPOPT [74] implement interior-point methods, while ensmallen [18] and\nGENO [42] rely on augmented Lagrangian methods. However, moving beyond smooth (SMT) con-\nstraints, both of these families of methods, at best, handle only special types of NSMT constraints.\n© B. Liang1, T. Mitchell2 & J. Sun1.\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\nFinally, packages specialized for machine learning, e.g., scikit-learn [57], MLib [52] and Weka [72],\noften use problem-speciﬁc solvers that cannot be easily extended to new formulations.\n2. The GRANSO and NCVX packages\nGRANSO1 is among the ﬁrst optimization packages that can handle general NCVX, NSMT, CSTR\nproblems [19]:\nmin\nx∈Rn f(x), s.t. ci(x) ≤0, ∀i ∈I; ci(x) = 0, ∀i ∈E.\n(1)\nHere, the objective f and constraint functions ci’s are only required to be almost everywhere con-\ntinuously differentiable. GRANSO is based on quasi-Newton updating with sequential quadratic\nprogramming (BFGS-SQP) and has the following advantages: (1) uniﬁed treatment of NCVX\nproblems: no need to distinguish CVX vs NCVX and SMT vs NSMT problems, similar to typical\nnonlinear programming packages; (2) reliable step-size rule: specialized methods for NSMT prob-\nlems, such as subgradient and proximal methods, often entail tricky step-size tuning and require\nthe expertise to recognize the structures [61], while GRANSO chooses step sizes adaptively via a\ngold-standard line search; (3) principled stopping criterion: GRANSO stops its iteration by check-\ning a theory-grounded stationarity condition for NMST problems, whereas specialized methods are\nusually stopped when reaching ad-hoc iteration caps.\nHowever, GRANSO users must derive gradients analytically2 and then provide code for these\ncomputations, a process which is often error-prone in machine learning and impractical for deep\nlearning. Furthermore, as part of the MATLAB software ecosystem, GRANSO is generally not com-\npatible with popular machine/deep learning frameworks—mostly in Python and R—and users’ own\nexisting toolchains. To overcome these issues and facilitate both high performance and ease of use\nin machine/deep learning, we introduce a new software package called NCVX, whose initial release\ncontains the solver PyGRANSO, a PyTorch-port of GRANSO with several new and key features: (1)\nauto-differentiation of all gradients, a critical feature to make PyGRANSO user-friendly; (2) support\nfor both CPU and GPU computations for improved hardware acceleration and massive parallelism;\n(3) support for general tensor variables including vectors and matrices, as opposed to the single vec-\ntor of concatenated optimization variables that GRANSO uses; (4) integrated support for OSQP [62]\nand other QP solvers for respectively computing search directions and the stationarity measure on\neach iteration. OSQP generally outperforms commercial QP solvers in terms of scalability and\nspeed. All of these enhancements are crucial for solving large-scale machine/deep learning prob-\nlems. NCVX, licensed under the AGPL V3, is built entirely on freely available and widely used\nopen-source frameworks; see https://ncvx.org for documentation and examples.\n3. Usage examples: dictionary learning and neural perceptual attack\nIn order to make NCVX friendly to non-experts, we strive to keep the user input minimal. The user is\nonly required to specify the optimization variables (names and dimensions of variables) and deﬁne\nthe objective and constraint functions. Here, we brieﬂy demonstrate the usage of PyGRANSO solver\non a couple of machine/deep learning problems.\n1. http://www.timmitchell.com/software/GRANSO/\n2. GRANSO is implemented in MATLAB and does not support auto-differentiation, although recent versions of MAT-\nLAB have included primitive auto-differentiation functionalities.\n2\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\nOrthogonal dictionary learning (ODL, [3])\nOne hopes to ﬁnd a “transformation” q ∈Rn to\nsparsify a data matrix Y ∈Rn×m:\nmin\nq∈Rn f(q) .= 1/m · ∥q⊺Y ∥1,\ns.t. ∥q∥2 = 1,\n(2)\nwhere the constraint ∥q∥2 = 1 is to avoid the trivial solution q = 0. Eq. (2) is NCVX, NSMT,\nand CSTR: nonsmoothness comes from the objective, and nonconvexity comes from the constraint.\nDemos 1 & 2 show the implementations of ODL in GRANSO and PyGRANSO, respectively. Note\nthat the analytical gradients of the objective and constraint functions are not required in PyGRANSO.\nfunction[f,fg,ci,cig,ce,ceg]=fn(q)\nf = 1/m*norm(q’*Y, 1);%obj\nfg = 1/m*Y*sign(Y’*q);%obj grad\nci = [];cig = [];%no ineq constr\nce = q’*q - 1; % eq constr\nceg = 2*q; % eq constr grad\nend\nsoln = granso(n,fn);\nDemo 1: GRANSO for ODL\ndef fn(X_struct):\nq = X_struct.q\nf = 1/m*norm(q.T@Y, p=1) # obj\nce = pygransoStruct()\nce.c1 = q.T@q - 1 # eq constr\nreturn [f,None,ce]\nvar_in = {\"q\": [n,1]}# def variable\nsoln = pygranso(var_in, fn)\nDemo 2: PyGRANSO for ODL\nNeural perceptual attack (NPA, [41])\nThe CSTR deep learning problem, NPA, is shown below:\nmax\nex\nL (f (ex) , y) , s.t. d (x, ex) = ∥φ (x) −φ (ex)∥2 ≤ǫ.\n(3)\nHere, x is an input image, and the goal is to ﬁnd its perturbed version ex that is perceptually similar\nto x (encoded by the constraint) but can fool the classiﬁer f (encoded by the objective). The loss\nL (·, ·) is the margin loss used in Laidlaw et al. [41]. Both f in the objective and φ in the constraint\nare deep neural networks with ReLU activations, making both the objective and constraint functions\nNSMT and NCVX. The d (x, ex) distance is called the Learned Perceptual Image Patch Similarity\n(LPIPS) [41, 76]. Demo 3 is the PyGRANSO example for solving Eq. (3). Note that the codes\nfor data loading, model speciﬁcation, loss function, and LPIPS distance are not included here. It\nis almost impossible to derive analytical subgradients for Eq. (3), and thus the auto-differentiation\nfeature in PyGRANSO is necessary for solving it.\ndef comb_fn(X_struct):\nadv_inputs = X_struct.x_tilde\nf = MarginLoss(model(adv_inputs),labels) # obj\nci = pygransoStruct()\nci.c1 = lpips_dists(adv_inputs) - 0.5 # ineq constr. bound eps=0.5\nreturn [f,ci,None] # No eq constr\nvar_in = {\"x_tilde\": list(inputs.shape)} # define variable\nsoln = pygranso(var_in,comb_fn)\nDemo 3: PyGRANSO for NPA\n3\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\n4. Constrained deep learning applications\nIn this section, we highlight 4 families of constrained deep learning problems with highly non-\ntrivial, often nonsmooth, constraints. These constraints cannot be easily built into the underlying\nneural networks. PyGRANSO can directly solve these problems, and detailed codes and tutorials\nare available on https://ncvx.org/examples.\n4.1. Robustness of deep learning models\nIn visual recognition, deep neural networks (DNNs) are not robust against perturbations—either ad-\nversarially constructed or naturally occurring—that are easily discounted by human perception [26,\n33]. To formalize robustness, one popular way is the adversarial loss deﬁned as [49]\nmax\nx′ ℓ\n\u0000y, fθ(x′)\n\u0001\ns. t. x′ ∈∆(x) = {x′ ∈[0, 1]n : d\n\u0000x, x′\u0001\n≤ǫ},\n(4)\nwhere fθ is the DNN model, and ∆(x) is the set of allowable perturbations with a radius ǫ mea-\nsured with respect to the metric d. Early works assume that ∆(x) is the ℓp norm ball intersected\nwith the natural image box, i.e., {x′ ∈[0, 1]n : ∥x −x′∥p ≤ǫ}, where p = 1, 2, ∞are pop-\nular choices [26, 49]. To capture visually realistic perturbations, recent work has also modeled\nnontrivial transformations [33] that use non-ℓp metrics. For empirical robustness evaluation (RE),\nsolving Eq. (4) leads to the worst perturbations that could fool fθ.\nAn alternative formalism of robustness is the robustness radius (or minimum distortion radius),\ndeﬁned as the minimal level of perturbation that can cause fθ to change its predicted class:\nmin\nx′∈[0,1]n d\n\u0000x, x′\u0001\ns. t. max\ni̸=y f i\nθ(x′) ≥f y\nθ(x′),\n(5)\nwhere the superscript for fθ indexes its elements, i.e., the output logits. Solving Eq. (5) produces not\nonly a minimally distorted perturbation x′ but also a robustness radius, making it another popular\nchoice for RE [15, 16]. For small and restricted fθ and selected d, Eq. (5) can be solved exactly\nby mixed integer programming [7, 38, 65]. For general fθ and selected d, lower bounds of the\nrobustness radius can be computed [48, 70, 71, 75]. But in general, Eq. (5) is heuristically solved\nvia gradient-based methods or iterative linearization [8, 15, 30, 54, 59, 60, 64].\nEqs. (4) and (5) are difﬁcult constrained problems, especially when d is sophisticated—necessary\nfor modeling realistic perturbations [23, 33, 34, 40, 73]. Popular exisiting solvers for them rely on\nexplicit projections onto simple sets, and they will not work when d is a non-ℓp metric. Also, pre-\nvious work has shown that the quality of the solution using these handcrafted methods is sensitive\nto key hyperparameters: e.g., step-size schedule and iteration budget [9, 16]. With PyGRANSO, we\ncan reliably solve Eqs. (4) and (5) with general d’s with minimal hyperparameter tuning [45]; see\nhttps://arxiv.org/pdf/2210.00621 for more details.\n4.2. Neural structural optimization\nDesigning physical structures such as bridges, optical devices and airplanes often boils down to\nstructural optimization, a fundamental family of problems in physical science and engineering [10,\n11, 13, 35]. A primitive version of structural optimization takes the form3:\nmin\nx,u u⊺K(x)u\ns. t. K(x)u = f, V (x) ≤v0, x ∈{0, 1}d ,\n(6)\n3. This form is also called topology optimization.\n4\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\nwhere x ∈Rd is the vectorized binary design variable that indicates where the material should be\nput to form the structure, u ∈Rn is the displacement vector, K is the global stiffness matrix, and\nf is the vector of external force. For the constraints, K(x)u = f encodes the physical laws (e.g.,\nHooke’s law) and is often called the equilibrium constraint, and V (x) = v0 limits the amount of\nmaterial to be used.\nRecent work [35] has introduced the deep image prior (DIP) [68] idea into Eq. (6): x is reparametrized\nas x = gθ(β), where gθ is a deep neural network parametrized by θ, and β is a ﬁxed random input.\nDIP has shown great promise for solving difﬁcult visual inverse problems (see, e.g., discussions\nin [44, 69, 78]), and can implicitly promote spatial continuity of the design—which is not explicitly\nmodeled in Eq. (6)4. Also, the overparametrization in DIP tends to ease the global optimization.\nRelaxing the integer constraint x ∈{0, 1}d into a box constraint x ∈[0, 1]d as is typically done in\nstructural optimization, we arrive at\nmin\nθ,u u⊺K(gθ(β))u\ns. t. K(gθ(β))u = f, V (gθ(β)) ≤v0, gθ(β) ∈[0, 1]d.\n(7)\nIn order to solve Eq. (7), recent work [35] transforms Eq. (7) into an unconstrained problem, which\nincludes 1) eliminating u from the physical constraint by solving the linear system K(gθ(β))u =\nf; 2) enforcing the couple of constraints V (gθ(β)) ≤v0 and gθ(β) ∈[0, 1]d via reparametrization,\nbinary search, and implicit differentiation. By contrast, using PyGRANSO we can directly solve\nEq. (7) without any of the problem-speciﬁc tricks. For realistic design problems, x needs to be\ndiscrete-valued (it can have more than 2 discrete values in multi-material design), and the constraint\nK(gθ(β))u = f becomes nonlinear—K becomes a nonlinear operator acting on u due to the\ngoverning PDEs [10, 11]. PyGRANSO can easily handle these general cases also, whereas the\ntricks used in [35] cannot be generalized.\n4.3. Orthogonal recurrent neural networks (RNNs)\nThe exploding and vanishing gradient issues are common in RNNs, and they could occur whenever\nthe recurrent kernel does not have unit eigenvalues [2, 4, 29, 32, 43], i.e., the associated weight\nmatrix is not orthogonal. Recent work proposes imposing orthogonality constraint on the weight\nmatrix directly [31, 43]:\nmin\nθ L (fθ(x), y)\ns. t. W ⊺\nhh(θ)Whh(θ) = I, det Whh(θ) = 1,\n(8)\nwhere fθ is the RNN parameterized by θ, and Whh is the recurrent kernel of the RNN (i.e., a\nsubvector of θ). Since the constraints deﬁne the famous special orthogonal group which is a smooth\nmanifold, manifold optimization methods can be developed to solve Eq. (8) [31, 43]. But these\nmethods entail heavy mathematics from differential geometry, and hence is impractical for non-\nexperts to implement and build on (there could be additional constraints in real applications). Again,\nPyGRANSO is able to directly handle the nonlinear constraints, whether the user recognizes or not\nthat the constraint forms the special orthogonal group.\n4. The state-of-the-art methods for structural optimization use smoothing ﬁlters during iteration heuristically to encour-\nage spatial continuity; see, e.g., [11].\n5\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\n4.4. Knowledge-aware machine learning (KAML)\nKAML concerns learning that incorporates prior knowledge, e.g., physical laws as constraints. As\nan example, it can take the general form of minimizing a loss subject to PDE constraints [21, 50]:\nmin\nu(x) L(u(x))\ns. t.\n(\nf\n\u0010\nx; ∂u\n∂x1 , . . . , ∂u\n∂xd;\n∂2u\n∂x1∂x1 , . . . ,\n∂2u\n∂x1∂xd ; . . .\n\u0011\n= 0,\n∀x ∈Ω\nB (u, x) = 0,\n∀x ∈∂Ω\n.\n(9)\nHere, Ωand ∂Ωdenote the domain and its boundary respectively, and the loss L depends on the\nfunctional variable u(x) over the domain Ω. The constraints are PDEs, with boundary and/or initial\nconditions B (·) = 0. If the loss is a constant, this reduces to solving the PDE problem about u(x).\nIn supervised learning scenarios, the loss could take the form of 1/N · PN\ni=1 ℓ(yi, u(xi)), where\n{(xi, yi)} is the training set and u is the predictor to be learned from the training set.\nTo solve Eq. (9), one can parametrize u(x) as a neural network, i.e., u(x; θ). This is nat-\nural in modern supervised learning, and is called physics-informed neural networks (PINNs) in\nthe numerical PDE community [12, 17, 21, 36, 47, 55]. In numerical PDEs, classical methods use\nﬁnite-difference approximations for all the partial derivatives, whereas the PINN idea directly works\nwith continuous functions that allow partial derivatives to be computed via auto-differentiation.\nThis “mesh-free” nature of PINNs holds the promise for high-precision solutions even for high-\ndimensional PDEs.\nThe state-of-the-art methods for solving the DNN-parametrized version of Eq. (9) use penalty\nmethods, Lagrangian methods, and augmented Lagrangian methods [17, 21, 47, 50], which often\ninvolve delicate tuning of multiple hyperparameters and could lead to infeasible solutions. By\ncontrast, PyGRANSOstops iterations by rigorous check of constraint violation and stationarity.\n5. Roadmap\nAlthough NCVX, with the PyGRANSO solver, already has many powerful features, we plan to further\nimprove it by adding several major components: (1) symmetric rank one (SR1): SR1, another\nmajor type of quasi-Newton methods, allows less stringent step-size search and tends to help escape\nfrom saddle points faster by taking advantage of negative curvature directions [20]; (2) stochastic\nalgorithms: in machine learning, computing with large-scale datasets often involves ﬁnite sums\nwith huge number of terms, calling for stochastic algorithms for reduced per-iteration cost and better\nscalability [63]; (3) conic programming (CP): semideﬁnite programming and second-order cone\nprogramming, special cases of CP, are abundant in machine learning, e.g., kernel machines [77]; (4)\nminimax optimization (MMO): MMO is an emerging modeling technique in machine learning,\ne.g., generative adversarial networks (GANs) [25] and multi-agent reinforcement learning [37].\nReferences\n[1] Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S.\nCorrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp,\nGeoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh\nLevenberg, Dandelion Man´e, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster,\nJonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay\nVasudevan, Fernanda Vi´egas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu,\n6\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\nand Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015.\nURL https://www.tensorflow.org/. Software available from tensorﬂow.org.\n[2] Martin Arjovsky, Amar Shah, and Yoshua Bengio. Unitary evolution recurrent neural networks. In\nInternational conference on machine learning, pages 1120–1128. PMLR, 2016.\n[3] Yu Bai, Qijia Jiang, and Ju Sun. Subgradient descent learns orthogonal dictionaries. arXiv preprint\narXiv:1810.10702, October 2018.\n[4] Nitin Bansal, Xiaohan Chen, and Zhangyang Wang. Can we gain more from orthogonality regulariza-\ntions in training deep networks? Advances in Neural Information Processing Systems, 31, 2018.\n[5] Stephen R. Becker, Emmanuel J. Cand`es, and Michael C. Grant. Templates for convex cone problems\nwith applications to sparse signal recovery. Mathematical programming computation, 3(3):165, 2011.\n[6] Nicolas Boumal, Bamdev Mishra, Pierre-Antoine Absil, and Rodolphe Sepulchre. Manopt, a Matlab\ntoolbox for optimization on manifolds. Journal of Machine Learning Research, 15(42):1455–1459,\n2014.\n[7] Rudy Bunel, P Mudigonda, Ilker Turkaslan, P Torr, Jingyue Lu, and Pushmeet Kohli. Branch and\nbound for piecewise linear neural network veriﬁcation. Journal of Machine Learning Research, 21\n(2020), 2020.\n[8] Nicholas Carlini and David Wagner.\nTowards evaluating the robustness of neural networks.\narXiv:1608.04644, August 2016.\n[9] Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas Rauber, Dimitris Tsipras,\nIan Goodfellow, Aleksander Madry, and Alexey Kurakin.\nOn evaluating adversarial robustness.\narXiv:1902.06705, February 2019.\n[10] Aaditya Chandrasekhar and Krishnan Suresh. Tounn: topology optimization using neural networks.\nStructural and Multidisciplinary Optimization, 63(3):1135–1149, 2021.\n[11] Aaditya Chandrasekhar, Saketh Sridhara, and Krishnan Suresh. Auto: a framework for automatic dif-\nferentiation in topology optimization. Structural and Multidisciplinary Optimization, 64(6):4355–4365,\n2021.\n[12] Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John M Gregoire, and Carla P Gomes. Deep\nreasoning networks: Thinking fast and slow. arXiv preprint arXiv:1906.00855, 2019.\n[13] Peter W. Christensen and Anders Klarbring. An Introduction to Structural Optimization. Springer\nNetherlands, 2008. doi: 10.1007/978-1-4020-8666-3.\n[14] IBM ILOG Cplex. V12. 1: User’s manual for CPLEX. International Business Machines Corporation,\n46(53):157, 2009.\n[15] Francesco Croce and Matthias Hein. Minimally distorted adversarial examples with a fast adaptive\nboundary attack. In International Conference on Machine Learning, pages 2196–2205. PMLR, 2020.\n[16] Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble\nof diverse parameter-free attacks. In International conference on machine learning, pages 2206–2216.\nPMLR, 2020.\n[17] Salvatore Cuomo, Vincenzo Schiano Di Cola, Fabio Giampaolo, Gianluigi Rozza, Maizar Raissi, and\nFrancesco Piccialli. Scientiﬁc machine learning through physics-informed neural networks: Where we\nare and what’s next. arXiv preprint arXiv:2201.05624, 2022.\n[18] Ryan R. Curtin, Marcus Edel, Rahul Ganesh Prabhu, Suryoday Basak, Zhihao Lou, and Conrad Sander-\nson. The ensmallen library for ﬂexible numerical optimization. Journal of Machine Learning Research,\n22(166):1–6, 2021.\n[19] Frank E Curtis, Tim Mitchell, and Michael L Overton. A BFGS-SQP method for nonsmooth, non-\nconvex, constrained optimization and its evaluation using relative minimization proﬁles. Optimization\nMethods and Software, 32(1):148–181, 2017.\n[20] Yann N. Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, and Yoshua\nBengio. Identifying and attacking the saddle point problem in high-dimensional non-convex optimiza-\ntion. In Proceedings of the 27th International Conference on Neural Information Processing Systems -\nVolume 2, NIPS’14, page 2933–2941, Cambridge, MA, USA, 2014. MIT Press.\n7\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\n[21] Alp Dener, Marco Andres Miller, Randy Michael Churchill, Todd Munson, and Choong-Seock Chang.\nTraining neural networks under physical constraints using a stochastic augmented lagrangian approach.\narXiv preprint arXiv:2009.07330, 2020.\n[22] Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex\noptimization. Journal of Machine Learning Research, 17(83):1–5, 2016.\n[23] Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry.\nEx-\nploring the landscape of spatial robustness.\nIn Kamalika Chaudhuri and Ruslan Salakhutdinov,\neditors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of\nProceedings of Machine Learning Research, pages 1802–1811. PMLR, 09–15 Jun 2019.\nURL\nhttps://proceedings.mlr.press/v97/engstrom19a.html.\n[24] David M. Gay. The AMPL modeling language: An aid to formulating and solving optimization prob-\nlems. In Mehiddin Al-Baali, Lucio Grandinetti, and Anton Purnama, editors, Numerical analysis and\noptimization, pages 95–116. Springer International Publishing, Cham, 2015. ISBN 978-3-319-17689-5.\n[25] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 63(11):\n139–144, 2020.\n[26] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial\nexamples. CoRR, abs/1412.6572, 2015.\n[27] Michael Grant, Stephen Boyd, and Yinyu Ye. CVX: Matlab software for disciplined convex program-\nming. http://cvxr.com/cvx, 2008.\n[28] Gurobi\nOptimization,\nLLC.\nGurobi\nOptimizer\nReference\nManual,\n2021.\nURL\nhttps://www.gurobi.com.\n[29] Mehrtash Harandi and Basura Fernando. Generalized backpropagation,\\’{E} tude de cas: Orthogonal-\nity. arXiv preprint arXiv:1611.05927, 2016.\n[30] Matthias Hein and Maksym Andriushchenko. Formal guarantees on the robustness of a classiﬁer against\nadversarial manipulation. arXiv:1705.08475, May 2017.\n[31] Kyle Helfrich, Devin Willmott, and Qiang Ye. Orthogonal recurrent neural networks with scaled cayley\ntransform. In International Conference on Machine Learning, pages 1969–1978. PMLR, 2018.\n[32] Mikael Henaff, Arthur Szlam, and Yann LeCun. Recurrent orthogonal networks and long-memory\ntasks. In International Conference on Machine Learning, pages 2034–2042. PMLR, 2016.\n[33] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corrup-\ntions and perturbations. arXiv preprint arXiv:1903.12261, 2019.\n[34] Hossein Hosseini and Radha Poovendran. Semantic adversarial examples. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition Workshops, pages 1614–1619, 2018.\n[35] Stephan Hoyer, Jascha Sohl-Dickstein, and Sam Greydanus. Neural reparameterization improves struc-\ntural optimization. arXiv preprint arXiv:1909.04240, 2019.\n[36] Dou Huang, Haoran Zhang, Xuan Song, and Ryosuke Shibasaki. Differentiable projection for con-\nstrained deep learning. arXiv preprint arXiv:2111.10785, 2021.\n[37] Chi Jin, Praneeth Netrapalli, and Michael Jordan. What is local optimality in nonconvex-nonconcave\nminimax optimization? In Hal Daum´e III and Aarti Singh, editors, Proceedings of the 37th International\nConference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages\n4880–4889. PMLR, 13–18 Jul 2020.\n[38] Guy Katz, Clark Barrett, David Dill, Kyle Julian, and Mykel Kochenderfer. Reluplex: An efﬁcient smt\nsolver for verifying deep neural networks. arXiv:1702.01135, February 2017.\n[39] Max Kochurov, Rasul Karimov, and Serge Kozlukov. Geoopt: Riemannian optimization in PyTorch.\narXiv preprint arXiv:2005.02819, May 2020.\n[40] Cassidy Laidlaw and Soheil Feizi. Functional adversarial attacks. Advances in neural information\nprocessing systems, 32, 2019.\n[41] Cassidy Laidlaw, Sahil Singla, and Soheil Feizi. Perceptual adversarial robustness: Defense against\nunseen threat models. arXiv preprint arXiv:2006.12655, June 2020.\n8\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\n[42] S¨oren Laue, Matthias Mitterreiter, and Joachim Giesen. GENO – GENeric Optimization for classical\nmachine learning. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc, E. Fox, and R. Gar-\nnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.,\n2019.\n[43] Mario Lezcano-Casado and David Martınez-Rubio. Cheap orthogonal constraints in neural networks:\nA simple parametrization of the orthogonal and unitary group. In International Conference on Machine\nLearning, pages 3794–3803. PMLR, 2019.\n[44] Taihui Li, Zhong Zhuang, Hengyue Liang, Le Peng, Hengkang Wang, and Ju Sun. Self-validation:\nEarly stopping for single-instance deep generative priors. arXiv:2110.12271, October 2021.\n[45] Hengyue Liang, Buyun Liang, Ying Cui, Tim Mitchell, and Ju Sun. Optimization for robustness evalu-\nation beyond ℓp metrics. arXiv preprint arXiv:2210.00621, 2022.\n[46] Johan Lofberg. YALMIP : a toolbox for modeling and optimization in MATLAB. In 2004 IEEE\nInternational Conference on Robotics and Automation (IEEE Cat. No.04CH37508), pages 284–289.\nIEEE, 2004. doi: 10.1109/cacsd.2004.1393890.\n[47] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. Deepxde: A deep learning library for\nsolving differential equations. SIAM Review, 63(1):208–228, 2021.\n[48] Zhaoyang Lyu, Ching-Yun Ko, Zhifeng Kong, Ngai Wong, Dahua Lin, and Luca Daniel. Fastened\ncrown: Tightened neural network robustness certiﬁcates. In Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, volume 34, pages 5037–5044, 2020.\n[49] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. To-\nwards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083, 2017.\n[50] Levi McClenny and Ulisses Braga-Neto. Self-adaptive physics-informed neural networks using a soft\nattention mechanism. arXiv preprint arXiv:2009.04544, 2020.\n[51] Mayank Meghwanshi, Pratik Jawanpuria, Anoop Kunchukuttan, Hiroyuki Kasai, and Bamdev Mishra.\nMcTorch, a manifold optimization library for deep learning. arXiv preprint arXiv:1810.01811, October\n2018.\n[52] Xiangrui Meng, Joseph Bradley, Burak Yavuz, Evan Sparks, Shivaram Venkataraman, Davies Liu,\nJeremy Freeman, DB Tsai, Manish Amde, Sean Owen, Doris Xin, Reynold Xin, Michael J. Franklin,\nReza Zadeh, Matei Zaharia, and Ameet Talwalkar. MLlib: Machine learning in Apache Spark. Journal\nof Machine Learning Research, 17(34):1–7, 2016.\n[53] Nina Miolane, Nicolas Guigui, Alice Le Brigant, Johan Mathe, Benjamin Hou, Yann Thanwerdas,\nStefan Heyder, Olivier Peltre, Niklas Koep, Hadi Zaatiti, Hatem Hajri, Yann Cabanes, Thomas Gerald,\nPaul Chauchat, Christian Shewmake, Daniel Brooks, Bernhard Kainz, Claire Donnat, Susan Holmes,\nand Xavier Pennec. Geomstats: A Python package for Riemannian geometry in machine learning.\nJournal of Machine Learning Research, 21(223):1–9, 2020.\n[54] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.\nDeepfool: a simple and\naccurate method to fool deep neural networks. arXiv:1511.04599., November 2015.\n[55] Yatin Nandwani, Abhishek Pathak, and Parag Singla. A primal dual formulation for deep learning with\nconstraints. Advances in Neural Information Processing Systems, 32, 2019.\n[56] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance deep learning li-\nbrary. Advances in neural information processing systems, 32:8026–8037, 2019.\n[57] Fabian Pedregosa, Ga¨el Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier\nGrisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre\nPassos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and ´Edouard Duchesnay. Scikit-learn:\nMachine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.\n[58] Gianni Pillo and Massimo Roma. Large-Scale Nonlinear Optimization, volume 83 of Nonconvex Opti-\nmization and Its Applications. Springer Science & Business Media, Boston, MA, 2006.\n9\nA GENERAL-PURPOSE OPTIMIZATION SOLVER FOR CONSTRAINED MACHINE AND DEEP LEARNING\n[59] Maura Pintor, Fabio Roli, Wieland Brendel, and Battista Biggio. Fast minimum-norm adversarial at-\ntacks through adaptive norm constraints. Advances in Neural Information Processing Systems, 34,\n2021.\n[60] J´erˆome Rony, Luiz G Hafemann, Luiz S Oliveira, Ismail Ben Ayed, Robert Sabourin, and Eric Granger.\nDecoupling direction and norm for efﬁcient gradient-based l2 adversarial attacks and defenses.\nIn\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4322–\n4330, 2019.\n[61] Suvrit Sra, Sebastian Nowozin, and Stephen J. Wright. Optimization for Machine Learning. The MIT\nPress, Cambridge, MA, 2012.\n[62] Bartolomeo Stellato, Goran Banjac, Paul Goulart, Alberto Bemporad, and Stephen Boyd. OSQP: an\noperator splitting solver for quadratic programs. Mathematical Programming Computation, 12(4):637–\n672, 2020. doi: 10.1007/s12532-020-00179-2.\n[63] Ruoyu Sun. Optimization for deep learning: theory and algorithms. arXiv preprint arXiv:1912.08957,\nDecember 2019.\n[64] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,\nand Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.\n[65] Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed\ninteger programming. arXiv:1711.07356, November 2017.\n[66] Kim-Chuan Toh, Michael J. Todd, and Reha H. T¨ut¨unc¨u. SDPT3—a Matlab software package for\nsemideﬁnite programming, Version 1.3. Optimization Methods and Software, 11(1-4):545–581, 1999.\n[67] James Townsend, Niklas Koep, and Sebastian Weichwald. Pymanopt: A Python toolbox for optimiza-\ntion on manifolds using automatic differentiation. Journal of Machine Learning Research, 17(137):1–5,\n2016.\n[68] Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Deep image prior. In Proceedings of the IEEE\nconference on computer vision and pattern recognition, pages 9446–9454, 2018.\n[69] Hengkang Wang, Taihui Li, Zhong Zhuang, Tiancong Chen, Hengyue Liang, and Ju Sun. Early stopping\nfor deep image prior. arXiv:2112.06074, December 2021.\n[70] Lily Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning, and\nInderjit Dhillon. Towards fast computation of certiﬁed robustness for relu networks. In International\nConference on Machine Learning, pages 5276–5285. PMLR, 2018.\n[71] Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, Dong Su, Yupeng Gao, Cho-Jui Hsieh, and\nLuca Daniel. Evaluating the robustness of neural networks: An extreme value theory approach. arXiv\npreprint arXiv:1801.10578, 2018.\n[72] Ian H. Witten, Eibe Frank, and Mark A. Hall. Data Mining: Practical Machine Learning Tools and\nTechniques. Morgan Kaufmann, Burlington, MA, third edition, 2011.\n[73] Eric Wong, Frank R. Schmidt, and J. Zico Kolter.\nWasserstein adversarial examples via projected\nsinkhorn iterations. arXiv:1902.07906, February 2019.\n[74] Andreas W¨achter and Lorenz T. Biegler. On the implementation of an interior-point ﬁlter line-search\nalgorithm for large-scale nonlinear programming. Mathematical Programming, 106(1):25–57, 2006.\ndoi: 10.1007/s10107-004-0559-y.\n[75] Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efﬁcient neural network\nrobustness certiﬁcation with general activation functions. Advances in neural information processing\nsystems, 31, 2018.\n[76] Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, and Oliver Wang. The unreasonable\neffectiveness of deep features as a perceptual metric. In 2018 IEEE/CVF Conference on Computer\nVision and Pattern Recognition, pages 586–595, 2018.\n[77] Richard Y. Zhang, C´edric Josz, and Somayeh Sojoudi. Conic optimization for control, energy systems,\nand machine learning: Applications and algorithms. Annual Reviews in Control, 47:323–340, 2019.\n[78] Zhong Zhuang, Taihui Li, Hengkang Wang, and Ju Sun. Blind image deblurring with unknown kernel\nsize and substantial noise. arXiv:2208.09483, August 2022.\n10\n",
  "categories": [
    "cs.LG",
    "cs.CV",
    "cs.MS",
    "eess.SP",
    "math.OC"
  ],
  "published": "2022-10-03",
  "updated": "2022-11-14"
}