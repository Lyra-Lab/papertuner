{
  "id": "http://arxiv.org/abs/2210.11250v1",
  "title": "Structure-based drug design with geometric deep learning",
  "authors": [
    "Clemens Isert",
    "Kenneth Atz",
    "Gisbert Schneider"
  ],
  "abstract": "Structure-based drug design uses three-dimensional geometric information of\nmacromolecules, such as proteins or nucleic acids, to identify suitable\nligands. Geometric deep learning, an emerging concept of neural-network-based\nmachine learning, has been applied to macromolecular structures. This review\nprovides an overview of the recent applications of geometric deep learning in\nbioorganic and medicinal chemistry, highlighting its potential for\nstructure-based drug discovery and design. Emphasis is placed on molecular\nproperty prediction, ligand binding site and pose prediction, and\nstructure-based de novo molecular design. The current challenges and\nopportunities are highlighted, and a forecast of the future of geometric deep\nlearning for drug discovery is presented.",
  "text": "Structure-based drug design with geometric deep learning\nClemens Isert1,†, Kenneth Atz1,† & Gisbert Schneider1,2,∗\n1ETH Zurich, Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093 Zurich, Switzerland.\n2ETH Singapore SEC Ltd, 1 CREATE Way, #06-01 CREATE Tower, Singapore, Singapore.\n† These authors contributed equally to this work.\n∗To whom correspondence should be addressed.\nE-mail: gisbert@ethz.ch\nAbstract\nStructure-based drug design uses three-dimensional geometric information of macromolecules, such as proteins\nor nucleic acids, to identify suitable ligands. Geometric deep learning, an emerging concept of neural-network-\nbased machine learning, has been applied to macromolecular structures. This review provides an overview\nof the recent applications of geometric deep learning in bioorganic and medicinal chemistry, highlighting its\npotential for structure-based drug discovery and design. Emphasis is placed on molecular property prediction,\nligand binding site and pose prediction, and structure-based de novo molecular design. The current challenges\nand opportunities are highlighted, and a forecast of the future of geometric deep learning for drug discovery\nis presented.\n1\nIntroduction\nStructure-based drug design is based on methods\nthat leverage three-dimensional (3D) structures of\nmacromolecular targets, such as proteins and nucleic\nacids, for decision-making in medicinal chemistry.1,2\nStructure-based modeling is well established through-\nout the drug discovery process, aiming to rationalize\nnon-covalent interactions between ligands and their\ntarget macromolecule(s).3 The questions addressed\nwith structure-based approaches include molecular\nproperty prediction, ligand binding site recognition,\nbinding pose estimation, as well as de novo design.4–7\nFor such tasks, detailed knowledge of the 3D struc-\nture of the investigated macromolecular surfaces and\nligand-receptor interfaces is essential.\nRecently, an\nemerging concept of neural-network-based \"artiﬁcial\nintelligence\", geometric deep learning, has been intro-\nduced to solve numerous problems in the molecular\nsciences, including structure-based drug discovery and\ndesign.8\nGeometric deep learning is based on a neural net-\nwork architecture that can incorporate and process\nsymmetry information.9 Eﬀective learning on three-di-\nmensional (3D) graphs has become one of the primary\nfunctions of molecular geometric deep learning.10–14\nSuch methods, which were initially limited to small\nmolecules, are now increasingly applied to macro-\nmolecules for structure-based drug design.15,16\nThis review provides a concise overview of geomet-\nric deep-learning methods for structure-based drug de-\nsign and seeks to forecasts future developments in the\nﬁeld. We focus on methods that use 3D macromolec-\nular structure representations developed for rational\ndrug design, emphasizing the most recent develop-\nments in both predictive and generative deep-learning\nmethods for structure-based molecular modeling. The\nmost relevant representations of 3D protein structures\nand the essential symmetry operations for geometric\nlearning are discussed (Figure 1). Then, the most re-\ncent developments in the ﬁeld are addressed (Figure 3),\nnamely, (i) molecular property prediction (e.g., binding\naﬃnity, protein function, and pose scoring, Section 2),\n(ii) binding site and interface prediction (e.g., small\nmolecule binding sites and protein-protein interfaces, ,\nSection 3), (iii) binding pose generation and molecular\ndocking (e.g., ligand-protein and protein-protein bind-\ning, Section 4), and (iv) the structure-based de novo\ndesign of small-molecule ligands (Section 5).\n1.1\nMolecular representation\nThe representation of the macromolecular structure de-\npends on the machine learning task and the chosen ar-\nchitecture. The three most prevalent macromolecular\nrepresentations described in the recent literature are\ngrids, surfaces, and graphs (Figure 1). These three rep-\nresentations have unique geometries and symmetries:9\n• 3D grids are deﬁned by a Euclidean data struc-\nture consisting of voxels in 3D space. This Eu-\nclidean geometry features the individual voxels\nof the grid with a ﬁxed neighborhood geometry,\ni.e. (i) each voxel has an identical neighborhood\nstructure (deﬁned by the number of neighbours\nand distances) and is indistinguishable from all\nother voxels from a purely structural perspective,\nand (ii) the voxels have a ﬁxed order that is de-\nﬁned by the spatial dimensions of the grid.\n• 3D surfaces consist of polygons (faces) that de-\nscribe the 3D arrangement of the mesh coordi-\nnates (\"mesh space\"). The polygons can be dis-\ntinguished according to their chemical features\nand geometric features deﬁned by the local ge-\nometry of the mesh.\n• 3D graphs are deﬁned by a non-Euclidean data\nstructure consisting of nodes (represented by the\nindividual atoms) and their edges, which are de-\nﬁned by the neighboring nodes, e.g., through a\n1\narXiv:2210.11250v1  [physics.chem-ph]  19 Oct 2022\nC\nB\nA\nVoxel-based features\nMesh-based features\nNode-based features\n3D Graph\n3D Surface\n3D Grid\nFigure 1: Overview of 3D representations of macromolecular structures used for geometric deep learning, il-\nlustrated for the human MDM2 protein (PDB-ID 4JRG17). Ligand DF-1 was docked into the active site of\nMDM2. The highest-ranking docking pose is shown. DF-1 was automatically generated using a novel geometric\ndeep-learning method (see Section 9 for details). The white and orange squares illustrate the feature vectors\ncorresponding to the diﬀerent representations. (A) 3D grid. (B) 3D surface. (C) 3D graph. For visual clarity,\nonly covalent edges are shown.\ncertain distance cutoﬀor k-nearest neighbor as-\nsignment. The non-Euclidean geometry of graphs\noriginates from a non-consistent neighborhood\nstructure of the individual nodes, i.e.\neach\nnode can have a diﬀerent number of neighbors\nwith edges deﬁned by diﬀerent spatial distances.\nThere is no general ordering of nodes and edges.\n1.2\nSymmetry\nIncorporating symmetry into the deep learning ar-\nchitecture to suit the input molecular representation\nand targeted property enables eﬀective learning.18 The\nmost relevant symmetry groups of molecular systems\ninclude the Euclidean group E(3), the special Eu-\nclidean group SE(3), and the permutation group (Fig-\nure 2).8 Both E(3) and SE(3) cover transformations\nin a 3D coordinate system, including rotations and\ntranslations, but only E(3) covers reﬂections. There-\nfore, SE(3) becomes relevant when a neural network\naims to learn diﬀerent outputs for chiral inputs. Both\nsymmetry groups are essential for learning in 3D. The\npermutation group is primarily related to the inﬂuence\nof node (i.e. atom) numbering on neural network per-\nformance and is often incorporated via permutation-\ninvariant pooling operators (e.g. sum, weighted-sum,\nmax or mean). Concerning these three basic symmetry\ngroups (E(3), SE(3) and permutation), the individual\nneural network layers F can transform the input X in\nan equivariant, invariant, or non-equivariant manner\nw.r.t the diﬀerent symmetry properties.8,9\n• Equivariance.\nF(X) is equivariant to a trans-\nformation T if the transformation of input X\ncommutes with the transformation of F(X) via a\ntransformation T ′ of the same symmetry group:\nF(T (X)) = T ′(F(X)).\nAn example would be\nan E(3)-equivariant neural network that has ac-\ncess to the coordinate system (e.g., edge features\nthat include relative coordinates) and predicts\nthe dipole vector which rotates together with the\ninput molecule.\n• Invariance. Invariance is a special case of equiv-\nariance, where F(X) is invariant to T if T ′ is the\ntrivial group action: F(T (X)) = T ′(F(X)) =\nF(X). An example would be an E(3)-invariant\nneural network which has no access to the coor-\ndinate system, (e.g., edge features that only in-\nclude pairwise distances) and predicts the same\nformation energy irrespective of how the input\nmolecule is rotated, translated, or mirrored.\n• Non-equivariance.\nF(X) is neither equivariant\nnor invariant to T when the transformation of\nthe input X does not commute with the trans-\nformation of F(X): F(T (X)) ̸= T ′(F(X)). An\nexample would be an E(3)-non-equivariant neural\nnetwork that has access to the coordinate system\n(e.g., explicit spatial properties such as voxels in\na 3D grid) for which the output does change, but\nnot deterministically, w.r.t to the alignment of\nthe molecule. In such cases approximate invari-\nance or equivariance can be learned through data\naugmentation.\n2\nSymmetry groups\nSymmetry transformations\nE(3)\nSE(3)\nPermutation\nInput\nEquivariance\nOutput changes deterministically \nwith input\nTranslation\nRotation\nTranslation\n1\n2\n3\n3\n1\n2\nAtom/node numbering\nRotation\nReflection\nInvariance\nOutput does not change with \ninput\n4.73\n4.73\nNon-equivariance\nOutput changes non-deterministically\nwith input\n4.73\nor\n?\nOutput\nFigure 2: Symmetry groups and transformations relevant for structure-based drug design. Symmetry transfor-\nmations (lower panel) are shown exemplary as a rotation of a protein structure (gray) used as the input to a\ndeep-learning model. The resulting eﬀect on the output (orange) is shown both for the prediction of a vector\n(arrow) or a scalar (value: 4.73).\nNeural-network-based\napproaches\nfeaturing\nequivariance19, invariance20, and non-equivariance21\n(approximate invariance) to the E(3) or SE(3) symme-\ntry groups are discussed below.\n2\nMolecular property prediction\nThis section discusses approaches that aim to predict\na scalar quantity based on a macromolecular structure\n(potentially including a ligand), e.g., ligand-binding\naﬃnity prediction or docking pose scoring (see Fig-\nure 3, ﬁrst row).\n2.1\nGrid-based methods\nSeveral\napproaches\nrepresent\nthe\nmacromolecular\nstructure on a 3D grid and employ convolutional neu-\nral networks (CNNs) to predict the property of inter-\nest. KDEEP estimates absolute binding aﬃnities by\nrepresenting the protein-ligand complex as a 3D grid\nin which each voxel is featurized with channels encod-\ning a set of pharmacological properties separately for\nprotein and ligand.\nOwing to the lack of rotational\ninvariance of 3D-CNNs, 90° rotations of the input at\ntraining time were used for data augmentation.21 Ex-\ntending the approach of classical 3D-CNNs, 3D steer-\nable CNNs can provide SE(3)-equivariant convolutions\non grid-like data and have been used for the prediction\nof amino acid preference for the atomic environment\nand of the protein structural class. SE(3)-equivariance\nis achieved by using a linear combination of steerable\nkernels.19\n2.2\nSurface-based methods\nHoloProt, an approach for binding aﬃnity and pro-\ntein function prediction, encodes proteins across diﬀer-\nent length-scales by combining sequence-, surface-, and\nstructure-based graph representations. A surface-level\ngraph uses nodes on the triangulated protein surface\nannotated with physicochemical and geometric fea-\ntures, whereas a structure-level graph based on amino\nacid residue nodes captures the 3D structure. A multi-\nlevel message-passing network aggregates the informa-\ntion from surface-and structure-based representations,\nand combines it with the ligand graph to ﬁnally output\nthe desired quantity (for binding aﬃnity prediction).22\n2.3\nGraph-based methods\nVarious methods use 3D graphs to capture the struc-\nture of a macromolecule and combine it with ligand\ninformation, either via separate ligand encoding or a\nmacromolecule-ligand co-complex. By using 3D graphs\ninstead of directly operating on the Cartesian atom\ncoordinates, these approaches are often invariant to\ntranslation and rotation of the input structure.\nThe construction of 3D graphs diﬀers among the\nvarious graph-based approaches. They either use an\nencoding of the node distances (atom-atom distance\nor residue-residue distance) as edge features, or diﬀer-\nent edge types (e.g., intra-and intermolecular edges to\ndiﬀerentiate between ligand and protein subgraphs),\nor construct edges in the molecular graph if the node\ndistance falls below a pre-deﬁned threshold.\nThese\nmethods for graph construction are not mutually ex-\nclusive, and combinations between them exist.\nAs an example for directly using node distances,\nSIGN predicts protein-ligand binding aﬃnities by us-\ning iterative interaction layers with either angle or\ndistance awareness, to incorporate knowledge of spa-\ntial orientation during the message-passing steps.23\nAnother E(3)-invariant architecture, the 3D message-\npassing neural network DelFTa24, trained on a data\nset of quantum-mechanical reference calculations25,\nuses Fourier-encoded atom distances to predict Wiberg\n3\n3D Grid\nProperty prediction\nSection 2\nBinding site/\ninterface prediction\nSection 3\nBinding pose \ngeneration/\nmolecular docking\nSection 4\nDe novo design\nSection 5\n3D Surface\n3D Graph\nOther\nPIGNet (Moon et al.26)\nGraph-CNN (Torng et al.31)\n3D structure-embedded graphs (Lim et al.27)\nDiffDock\n(Corso\net al.46)\nScanNet \n(Tubiana et al.42)\nMaSIF \n(Gainza et al.37)\ndMaSIF (Sver-\nrisson et al.38)\n3D steerable CNNs \n(Weiler et al.19)\n3D-graph-SBDD (Luo et al.62)\nLigDream (Skalic et al.61)\nDiffSBDD (Anonymous66)\nDiffLinker (Igashov et al.68)\nDeepLigBuilder (Li et al.63)\nTargetDiff (Anonymous67)\nDeepSite (Jiménez et al.35)\nPIP-GCN (Fout et al.40)\nRNet (Möller et al.36)\nPINet (Dai et al.39)\nGeometricTransformer (Morehead et al.41)\nInteractionGraphNet (Jiang et al.30)\nKDEEP (Jiménez et al.21)\nHoloProt (Somnath et al.22)\nPLIG (Moesser et al.32)\nPaxNet (Zhang et al.28)\nPotentialNet (Feinberg et al.29)\nIEConv (Hermosilla et al.33)\nDelFTa (Atz et al.24)\nSIGN (Li et al.23)\nPAUL (Eismann et al.34)\nEquiDock\n(Ganea \net al.15)\nEquiBind\n(Stärk\net al.43)\ndMaSIF docking (Sverrisson et al.44)\nDeepDock (Méndez-Lucio et al.45)\nRepresentation\nTask\nSpookyNet/GEMS \n(Unke et al.10,16)\nFigure 3: Overview of geometric deep-learning methods for structure-based drug design discussed in this review.\nMethods are placed according to the task (rows) and macromolecular representation (columns).\nbond orders of macromolecular molecules.24 Based on\nthe E(3)-equivariant 3D message-passing neural net-\nwork architecture SpookyNet10, GEMS trains a ma-\nchine learning force ﬁeld on molecular fragments to\nobtain close-to-DFT accuracy for protein structures.\nBy incorporating long-range interactions learned from\ntop-down generated fragments, greater-than-expected\nﬂexibility of protein structures was discovered.16\nBy combining direct distance encoding and dif-\nferent edge types, PIGNet26 aims to predict binding\naﬃnities. To this end, PIGNet uses physics-informed\npairwise interactions modeled with a gate-augmented\ngraph attention network26 In another approach, Lim\net al.27 classiﬁed ligands as either active or inactive\nagainst a given target by treating covalent and non-\ncovalent interactions separately, while using distances\nfor the description of non-covalent interactions.\nBy\nsubtracting the graph features obtained from the pro-\ntein and ligand separately from those of the respective\ncomplex, the relevance of intermolecular interactions\ncan be perceived by the network.27 Tackling the bind-\ning aﬃnity prediction problem, PaxNet diﬀerentiates\nbetween local and non-local interactions with separate\n(but connected) message-passing schemes for each type\nof interaction. By using angle information only for lo-\ncal interactions and focusing on distances for non-local\ninteractions, the computational cost of geometric deep\nlearning operations can be minimized.28\nExamples of using diﬀerent edge types include\nPotentialNet29 and InteractionGraphNet30 for bind-\ning aﬃnity prediction, diﬀerentiating between covalent\nand non-covalent, respectively intra-and intermolecu-\nlar graph convolutions.\nIn another approach, Torng\net al.31 used an unsupervised graph-autoencoder to\ngenerate representative binding pocket representations\nfollowed by protein-level graph convolutions based on\na Euclidean distance cutoﬀfor active/inactive classiﬁ-\ncation of a protein-ligand pair.31\nDeparting from the direct use of the protein struc-\nture in the 3D graph, the recently introduced \"Protein-\nLigand Interaction Graphs\" (PLIGs) incorporate infor-\nmation about the protein environment directly into the\nnode features of the ligand graph, thereby reducing the\nsize and complexity of the resulting graph structure.32\n2.4\nOther methods\nIn addition to grids, surfaces, and graphs, various types\nof data have been used to model macromolecular struc-\ntures.\nFor example, Hermosilla et al.33 approached\nthe problem of protein fold and reaction classiﬁca-\ntion as a learning problem on 3D point clouds, in-\ntroducing an E(3)-invariant convolution operator that\nconsiders extrinsic (Euclidean) and intrinsic distances\n4\n(covalent-only or covalent and non-covalent bond hop\ndistance).33 A network architecture called PAUL pre-\ndicts the root-mean-square-deviation of protein struc-\nture from an experimental structure directly from the\n3D coordinates of atoms by using SE(3)-equivariant\nconvolution ﬁlters.34\n3\nBinding site/interface prediction\nThis section discusses approaches that aim to predict\nthe parts of a macromolecular structure that can act\nas a binding site for small, drug-like ligands, or as an\ninteraction interface for other macromolecules (see Fig-\nure 3, second row). Binding pose-generating methods\nthat implicitly identify binding sites are discussed in\nSection 4.\n3.1\nGrid-based methods\nDeepSite is an early approach that represents a protein\nusing a regular 3D grid with voxels characterized by\npharmacophoric features of nearby atom types. Using\na sliding subgrid approach, the network outputs the\nprobability that this sub-grid is close to a druggable\nbinding site.35 RNet extended this approach to pre-\ndicting ligand-binding sites of ribonucleic acid (RNA)\nstructures.36\n3.2\nSurface-based methods\nMaSIF37 (molecular surface interaction ﬁngerprinting)\nand its diﬀerentiable analogue dMaSIF38 use macro-\nmolecular surface representations for binding site pre-\ndiction, and can also classify, e.g., pocket function. The\nsurface-based approach describes individual points on\nthe protein surface in geodesic space, such that dis-\ntances between points correspond to the length of the\npath between them along the surface, rather than to\nthe Euclidean distance. In a three-step approach, the\nsurface is decomposed into individual patches. Points\nwithin each patch are featurized with geometric and\nchemical properties. Geodesic convolutions transform\nthese features into a numerical vector for downstream\ntasks.\nThe ﬁrst two steps required expensive pre-\ncomputation in the original implementation37, whereas\ndMaSIF is end-to-end diﬀerentiable and operates di-\nrectly on atom types and coordinates.38 Another ap-\nproach, PINet, uses a physics-inspired geometric deep\nlearning network to identify interface regions between\ntwo interacting proteins by learning the complemen-\ntarity of surface shape and physicochemical properties.\nOwing to the lack of rotational invariance in this net-\nwork architecture, data augmentation using random ro-\ntations of the input structures is required.39\n3.3\nGraph-based methods\nNetworks operating on 3D graph representations of\nmolecular structures have been widely applied to bind-\ning sites and interface prediction. Examples of such ap-\nproaches are rototranslational-invariant methods that\nuse edge features (including distances and angles) to in-\nfuse the model with geometric understanding, followed\nby the prediction of pairwise residue-level interaction\npotential using either spatial graph convolutions40 or a\ngraph transformer41.\n3.4\nOther approaches\nScanNet uses an E(3)-invariant geometric deep learn-\ning model by applying structure-based linear Gaussian\nkernel ﬁlters to predict protein-protein and protein-an-\ntibody binding sites.42\n4\nBinding pose generation/molecular\ndocking\nThis section focuses on methods for docking pose gener-\nation, i.e., the generation of a suitable binding confor-\nmation between for either a small-molecule ligand and\nits macromolecular receptor, or between two macro-\nmolecular structures (see Figure 3, third row).\n4.1\nGraph-based and hybrid methods\nEquiDock uses an SE(3)-equivariant message passing\nneural network combined with optimal transport to\npredict the binding pose between two protein molecules\nin a rigid-body, blind-docking fashion (which also en-\ntails detecting a suitable binding site). The network\npredicts a rotation matrix and a translation vector to\nmove one protein structure into the binding pose while\nkeeping the second protein ﬁxed, guaranteeing that the\nresulting docking pose is invariant to the initial ori-\nentation and positioning of both binding partners.15\nEquiBind extends this approach to the docking of ﬂex-\nible small-molecule ligand molecules to protein struc-\ntures, incorporating changes in the torsion angles of\nrotatable bonds starting from a randomly generated\nconformer.43 Building on dMaSIF38, another approach\nfor rigid-body docking of protein complexes combines\nSE(3)-equivariant graph neural networks with surface\nﬁngerprints for atomic point clouds to estimate the\nsurface shape complementarity of the two binding\npartners.44 In contrast to EquiDock15, this approach\ngenerates and ranks multiple binding poses for each\nprotein-protein pair.44 DeepDock constitutes a geo-\nmetric deep-learning approach for predicting small-\nmolecule binding poses by representing the binding site\nsurface as a polygon mesh and the ligand as a molec-\nular graph, and predicting a probability distribution\nover pairwise node distances between the ligand and\nprotein.45 DiﬀDock uses a diﬀusion-based generative\nmodel for molecular docking. The approach generates a\ntuneable number of ligand poses in a two-step process:\nFirst, a scoring model uses a reverse diﬀusion process\nthat transforms random initial ligand poses into pre-\ndicted poses by translation, rotation, and torsion angle\nchanges. Second, a conﬁdence model predicts a binary\nlabel indicating whether a generated ligand pose is be-\nlow the 2 Å root-mean-square-distance threshold com-\nmonly used to evaluate binding pose accuracy. While\n5\n1D protein representation\nEncoding\nDecoding\nN\nO\nN\nN\nN\nCl\nCC1=CC(N2C(C3=C([C@@H]2\nC4=CC=C(Cl)C=C4)N(C5CCCC5)\nC(CC(N(C)C)C)=N3)=O)=CC=C1\nFigure 4: Structure-based de novo design with machine learning. A protein, or only its ligand-binding site, is\nprocessed using an encoder neural network, which transforms the protein representation into a 1D latent space.\nThis latent space can then be transformed into SMILES-strings by a decoder neural network such as a chemical\nlanguage model. The illustrated molecule DF-1 was designed using a novel, yet unpublished geometric deep-\nlearning method to target MDM2 (cf. Section 9). The active binding site is colored on the protein surface. The\n1D protein representation corresponds to the feature vector of the latent space.\nthe scoring model employs a residue-level 3D graph of\nthe protein, the conﬁdence model uses a full-atomistic\n3D graph. The translation and rotation outputs of the\nscoring model are SE(3)-equivariant, whereas the tor-\nsion angle outputs and conﬁdence model predictions\nare SE(3)-invariant. The approach substantially out-\nperformed existing classical and deep learning-based\napproaches on a common docking benchmark.46\n5\nDe novo design\nDe novo design methods aim to generate new molecular\nstructures with desired biological and physical prop-\nerties from scratch (see Figure 3, fourth row).47 The\nconcept of deriving features from a protein binding site\ntailored for the use in automated de novo design dates\nback more than thirty years.48 Early structure-based\nde novo design approaches used to generate desired\nmolecular structures iteratively by using either single\natoms or fragments.49 Prominent algorithms included\n(i) linking50 (i.e.\nplacing building blocks at key in-\nteraction sites of the receptor and linking them), (ii)\ngrowing51 (i.e.\nstarting with a single building block\nat one of the key interaction sites of the receptor and\ngrowing to a complete ligand), and (iii) lattice-based\ndesign52 (i.e. starting from an atomic lattice in the re-\nceptor binding site consisting of sp3 carbon atoms and\nreplacing them until a complete ligand is formed).\n5.1\nChemical language models\nMore recently, deep learning has been used for de novo\nmolecular design and has found various applications\nin medicinal chemistry and chemical biology.53 Cur-\nrently, the most prevalent and successful deep learn-\ning models for de novo drug design, so called chemical\nlanguage models (CLMs), learn on string-based molec-\nular representations (e.g., SMILES strings).54 Ligand-\nbased de novo design with CLMs has led to the suc-\ncessful generation of molecules with desired physico-\nchemical and biological properties.55–58 In this context,\ndata augmentation based on non-canonical SMILES\nstring enumeration59 and bidirectional learning60 has\nbeen shown to considerably improve the quality of the\nchemical language learned by CLMs.\nSuch ligand-\nbased deep generative methods have been extended\nto structure-based approaches that incorporate explicit\ninformation of the targeted protein (Figure 4). Con-\nvolutional neural networks using 3D-grid-based repre-\nsentation of the binding site of the protein as input\nhave been proposed to learn a latent space that is then\ndecoded to sequences (i.e.\nSMILES-string) using a\nCLM.61\n5.2\nGraph-based methods\nMethods have been proposed that generate 3D struc-\ntures of potential ligand molecules directly from the 3D\nstructure of the macromolecular binding site. Ligands\nare constructed within the binding site in the form of\na 3D graph.62,63 These models sample atoms sequen-\ntially from a learned distribution and have been shown\nto be applicable to a variety of molecular properties.64\nRecent work has introduced E(3)-equivariant diﬀusion\nmodels that enable the generation of molecules as 3D\ngraphs by learning to denoise a normally distributed\nset of points.65 This process has been extended to\nmolecule generation from scratch within the binding\nsite of macromolecules, as implemented in DiﬀSBDD66\nand TargetDiﬀ67. DiﬀLinker generates suitable linkers\nthat connect fragments placed in the binding pocket68.\nAlthough these 3D graph-based de novo design models\ncan construct a large fraction of novel molecules, their\npractical applications remain to be explored.\n6\n6\nOutlook\nBased on the success of these pioneering applica-\ntions, we expect future work to extend equivariant\nneural networks and physics-inspired approaches to\nstructure-based drug design.\nPrevious studies have\nindicated that incorporating certain aspects of physics\nand symmetry into a model tends to increase the\naccuracy, generalizability, and interpretability of the\npredictions.26,69,70 We further expect that geometric\ndeep learning research for structure-based drug de-\nsign will follow trends in the pharmaceutical industry.\nThese trends include a growing interest in protein-\nprotein interaction inhibitors71, induced proximity ap-\nproaches such as molecular glues72 and proteolysis\ntargeting chimeras (PROTACs)73, as well as RNA-\ntargeting therapeutics74.\nNovel applications in the ﬁeld of structure-based\nbinding aﬃnity prediction will have to address the\npoints of criticism directed toward existing methods.\nRecent work has shown that many deep learning ar-\nchitectures trained on the PDBbind75 data set merely\nmemorize the training data rather than learning a\nmeaningful mapping between protein-ligand structure\nand binding aﬃnity, contributing to poor generaliza-\ntion performance in some cases. The use of protein-\nligand complexes for model development often leads to\nsimilar performance compared to the use of ligand-only\nor protein-only descriptors.76 Future work in this area\nwill likely beneﬁt from suitable benchmarking data\nsets77,78, and guidelines for building such data sets\nhave been proposed.79 A promising example for such\na data set is the recently released collection of binding\naﬃnities and X-ray co-crystal structures of PDE10A\ninhibitors.80 Included train-test splits mirroring diﬀer-\nent real-world lead optimization scenarios can be used\nto assess generalization performance.\n3D-aware models, such as normalizing ﬂow-based\napproaches, may appear at the forefront of future gen-\nerative modeling studies.65 To comprehensively eval-\nuate the utility of emerging new models in a real-\nworld drug design context, experimental validation of\nthe proposed molecular structures is paramount. Since\nnot all computational groups working in this ﬁeld will\nhave the expertise, equipment, or desire to perform the\nrequired synthesis and experimental testing, collabora-\ntions with experimentalists will be highly valuable.\n7\nAcknowledgements\nThis work was ﬁnancially supported by the Swiss Na-\ntional Science Foundation (grant no. 205321_182176).\nC.I. acknowledges support from the Scholarship Fund\nof the Swiss Chemical Industry.\n8\nCompeting interest\nG.S. declares a potential ﬁnancial conﬂict of interest as\nco-founder of inSili.com LLC, Zurich, and in his role as\na scientiﬁc consultant to the pharmaceutical industry.\n9\nStructure-based de novo design of\nDF-1\nThe ligand DF-1 displayed in Figures 1 and 4 was de-\nsigned using a new geometric deep-learning method to\ntarget MDM2 (K. Atz, G. Schneider, unpublished).\nDF-1 was docked into the active binding site of the\nhuman MDM2 protein (PDB-ID 4JRG) using GOLD\nsoftware81.\nThe highest ranking docking pose is\nshown in Figure 1.\nDF-1 has an Euclidean dis-\ntance of 0.48 (using ECFP482) to the closest molecule\n(ChEMBL3653229) in the ChEMBL database83 (Ver-\nsion 29), and atomic- and graph-scaﬀolds that are not\npresent in this database.\nReferences\n1.\nGubernator, K., Böhm, H.-J., Mannhold, R., Ku-\nbinyi, H. & Timmerman, H. Structure-based lig-\nand design (Wiley Online Library, 1998).\n2.\nAnderson, A. C. The process of structure-based\ndrug design. Chem. Biol. 10, 787–797 (2003).\n3.\nBissantz, C., Kuhn, B. & Stahl, M. A medicinal\nchemist’s guide to molecular interactions. J. Med.\nChem. 53, 5061–5084 (2010).\n4.\nBleicher, K. H., Böhm, H.-J., Müller, K. & Ala-\nnine, A. I. Hit and lead generation: beyond high-\nthroughput screening. Nat. Rev. Drug Discov. 2,\n369–378 (2003).\n5.\nŚledź, P. & Caﬂisch, A. Protein structure-based\ndrug design: from docking to molecular dynam-\nics. Curr. Opin. Struct. Biol. 48, 93–102 (2018).\n6.\nAtz, K., Guba, W., Grether, U. & Schneider, G.\nin Endocannabinoid Signaling 477–493 (Springer,\n2022).\n7.\nSadybekov, A. A. et al. Synthon-based ligand dis-\ncovery in virtual libraries of over 11 billion com-\npounds. Nature 601, 452–459 (2022).\n8.\nAtz, K., Grisoni, F. & Schneider, G. Geometric\ndeep learning on molecular representations. Nat.\nMach. Intell. 3, 1023–1032 (2021).\n9.\nBronstein, M. M., Bruna, J., Cohen, T. &\nVeličković, P. Geometric deep learning: Grids,\ngroups, graphs, geodesics, and gauges. arXiv\npreprint arXiv:2104.13478 (2021).\n* This work provides an introduction to the\nterminology of geometric deep learning as a\nuniﬁcation of machine learning for diﬀerent\ndata structures and neural network archi-\ntectures from the perspective of symmetry\nand invariance.\n7\n10.\nUnke, O. T. et al. SpookyNet: Learning force\nﬁelds with electronic degrees of freedom and non-\nlocal eﬀects. Nat. Commun. 12, 7273 (2021).\n11.\nUnke, O. et al. SE(3)-equivariant prediction of\nmolecular wavefunctions and electronic densities.\nAdvances in Neural Information Processing Sys-\ntems (NeurIPS) 34, 14434–14447 (2021).\n12.\nSatorras, V. G., Hoogeboom, E. & Welling, M.\nE(n) equivariant graph neural networks. Interna-\ntional Conference on Machine Learning (ICML)\n38, 9323–9332 (2021).\n13.\nChristensen, A. S. et al. OrbNet Denali: A ma-\nchine learning potential for biological and organic\nchemistry with semi-empirical cost and DFT ac-\ncuracy. J. Chem. Phys. 155, 204103 (2021).\n* OrbNet Denali introduces a message-\npassing mechanism for graph neural net-\nworks that uses symmetry-adapted atomic\norbital features from a low-cost QM calcu-\nlation as input features.\n14.\nNippa, D. F. et al. Enabling late-stage drug di-\nversiﬁcation by high-throughput experimentation\nwith geometric deep learning. ChemRxiv preprint\n10.26434/chemrxiv-2022-gkxm6 (2022).\n15.\nGanea,\nO.-E.\net\nal.\nIndependent\nSE\n(3)-\nEquivariant Models for End-to-End Rigid Pro-\ntein Docking. International Conference on Learn-\ning Representations (ICML) 38 (2021).\n16.\nUnke, O. T. et al. Accurate Machine Learned\nQuantum-Mechanical Force Fields for Biomolecu-\nlar Simulations. arXiv preprint arXiv:2205.08306\n(2022).\n** GEMS introduces an approach to ex-\ntend machine-learning force ﬁelds to large\nmacromolecular structures by training on\nmolecular fragments. Using a physically\nmotivated\narchitecture,\nselected\nprotein\ndynamics and protein-protein interactions\nare modelled at close to ab initio accuracy.\n17.\nDing, Q. et al. Discovery of RG7388, a potent and\nselective p53–MDM2 inhibitor in clinical develop-\nment. J. Med. Chem. 56, 5979–5983 (2013).\n18.\nBronstein, M. M., Bruna, J., LeCun, Y., Szlam,\nA. & Vandergheynst, P. Geometric deep learning:\ngoing beyond Euclidean data. IEEE Signal Pro-\ncess. Mag. 34, 18–42 (2017).\n19.\nWeiler, M., Geiger, M., Welling, M., Boomsma,\nW. & Cohen, T. S. 3D steerable CNNs: Learn-\ning rotationally equivariant features in volumetric\ndata. Advances in Neural Information Processing\nSystems (NeurIPS) 31 (2018).\n20.\nSchütt, K. T., Sauceda, H. E., Kindermans, P.-J.,\nTkatchenko, A. & Müller, K.-R. SchNet – a deep\nlearning architecture for molecules and materials.\nJ. Chem. Phys. 148, 241722 (2018).\n21.\nJiménez, J., Skalic, M., Martinez-Rosell, G. &\nDe Fabritiis, G. KDEEP: protein–ligand absolute\nbinding aﬃnity prediction via 3D-convolutional\nneural networks. J. Chem. Inf. Model. 58, 287–\n296 (2018).\n22.\nSomnath, V. R., Bunne, C. & Krause, A. Multi-\nscale representation learning on proteins. Ad-\nvances in Neural Information Processing Systems\n(NeurIPS) 34, 25244–25255 (2021).\n* HoloProt combines diﬀerent molecular\nrepresentations to aggregate information\nfrom multiple length scales and predicts\nbinding aﬃnity and protein function.\n23.\nLi, S. et al. Structure-aware interactive graph neu-\nral networks for the prediction of protein-ligand\nbinding aﬃnity. Proceedings of the 27th ACM\nSIGKDD Conference on Knowledge Discovery &\nData Mining, 975–985 (2021).\n24.\nAtz, K., Isert, C., Böcker, M. N., Jiménez-Luna, J.\n& Schneider, G. ∆-Quantum machine-learning for\nmedicinal chemistry. Phys. Chem. Chem. Phys.\n24, 10775–10783 (2022).\n25.\nIsert, C., Atz, K., Jiménez-Luna, J. & Schnei-\nder, G. QMugs, quantum mechanical properties\nof drug-like molecules. Sci. Data 9, 273 (2022).\n26.\nMoon, S., Zhung, W., Yang, S., Lim, J. & Kim,\nW. Y. PIGNet: a physics-informed deep learning\nmodel toward generalized drug–target interaction\npredictions. Chem. Sci. 13, 3661–3673 (2022).\n27.\nLim, J. et al. Predicting drug–target interac-\ntion using a novel graph neural network with\n3D structure-embedded graph representation. J.\nChem. Inf. Model. 59, 3981–3988 (2019).\n28.\nZhang, S., Liu, Y. & Xie, L. Eﬃcient and Accurate\nPhysics-aware Multiplex Graph Neural Networks\nfor 3D Small Molecules and Macromolecule Com-\nplexes. arXiv preprint arXiv:2206.02789 (2022).\n29.\nFeinberg, E. N. et al. PotentialNet for molecular\nproperty prediction. ACS Cent. Sci. 4, 1520–1530\n(2018).\n30.\nJiang, D. et al. InteractionGraphNet: A novel\nand eﬃcient deep graph representation learning\nframework for accurate protein–ligand interac-\ntion predictions. J. Med. Chem. 64, 18209–18232\n(2021).\n31.\nTorng, W. & Altman, R. B. Graph convolutional\nneural networks for predicting drug-target in-\nteractions. J. Chem. Inf. Model. 59, 4131–4149\n(2019).\n32.\nMoesser,\nM.\nA.\net\nal.\nProtein-Ligand\nIn-\nteraction\nGraphs:\nLearning\nfrom\nLigand-\nShaped\n3D\nInteraction\nGraphs\nto\nImprove\nBinding\nAﬃnity Prediction.\nbioRxiv preprint\nbioRxiv:2022.03.04.483012 (2022).\n33.\nHermosilla, P. et al. Intrinsic-extrinsic convolu-\ntion and pooling for learning on 3D protein struc-\ntures. arXiv preprint arXiv:2007.06252 (2020).\n8\n34.\nEismann,\nS.\net\nal.\nHierarchical,\nrotation-\nequivariant neural networks to select structural\nmodels of protein complexes. Proteins: Struct.,\nFunct., Bioinf. 89, 493–501 (2021).\n35.\nJiménez, J., Doerr, S., Martínez-Rosell, G., Rose,\nA. S. & De Fabritiis, G. DeepSite: protein-binding\nsite predictor using 3D-convolutional neural net-\nworks. Bioinformatics 33, 3036–3042 (2017).\n36.\nMöller, L., Guerci, L., Isert, C., Atz, K. & Schnei-\nder, G. Translating from proteins to ribonucleic\nacids for ligand-binding site detection. Mol. In-\nform. 41, 2200059 (2022).\n37.\nGainza, P. et al. Deciphering interaction ﬁnger-\nprints from protein molecular surfaces using geo-\nmetric deep learning. Nat. Methods 17, 184–192\n(2020).\n* The MaSIF approach uses geodesic con-\nvolutions on the protein surface to trans-\nlate chemical and geometric surface fea-\ntures into a numerical vector for down-\nstream applications, such as pocket classi-\nﬁcation or binding site prediction.\n38.\nSverrisson, F., Feydy, J., Correia, B. E. & Bron-\nstein, M. M. Fast end-to-end learning on protein\nsurfaces. Proc. IEEE Comput. Soc. Conf. Com-\nput. Vis. Pattern Recognit., 15272–15281 (2021).\n39.\nDai, B. & Bailey-Kellogg, C. Protein interac-\ntion interface region prediction by geometric deep\nlearning. Bioinformatics 37, 2580–2588 (2021).\n40.\nFout, A., Byrd, J., Shariat, B. & Ben-Hur, A.\nProtein interface prediction using graph convolu-\ntional networks. Advances in Neural Information\nProcessing Systems (NeurIPS) 30 (2017).\n41.\nMorehead, A., Chen, C. & Cheng, J. Geometric\nTransformers for Protein Interface Contact Pre-\ndiction. arXiv preprint arXiv:2110.02423 (2021).\n42.\nTubiana, J., Schneidman-Duhovny, D. & Wolfson,\nH. J. ScanNet: An interpretable geometric deep\nlearning model for structure-based protein bind-\ning site prediction. Nat. Methods 19, 1–10 (2022).\n43.\nStärk, H., Ganea, O., Pattanaik, L., Barzilay, R.\n& Jaakkola, T. EquiBind: Geometric deep learn-\ning for drug binding structure prediction. Interna-\ntional Conference on Machine Learning (ICML)\n39, 20503–20521 (2022).\n44.\nSverrisson, F., Feydy, J., Southern, J., Bronstein,\nM. M. & Correia, B. Physics-informed deep neu-\nral network for rigid-body protein docking. In-\nternational Conference on Learning Representa-\ntions (ICLR) Machine Learning for Drug Discov-\nery 10, 1–13 (2022).\n45.\nMéndez-Lucio, O., Ahmad, M., del Rio-Chanona,\nE. A. & Wegner, J. K. A geometric deep learn-\ning approach to predict binding conformations of\nbioactive molecules. Nat. Mach. Intell. 3, 1033–\n1039 (2021).\n46.\nCorso, G., Stärk, H., Jing, B., Barzilay, R. &\nJaakkola, T. DiﬀDock: Diﬀusion Steps, Twists,\nand Turns for Molecular Docking. arXiv preprint\narXiv:2210.01776 (2022).\n** DiﬀDock frames molecular docking as\na generative task and uses diﬀusion-based\ngenerative models to obtain ligand poses\nand conﬁdence estimates. It shows substan-\ntially improved performance over existing\nstate-of-the-art docking methods on a com-\nmonly used benchmark while achieving rel-\natively quick run times.\n47.\nSchneider, G. & Fechner, U. Computer-based de\nnovo design of drug-like molecules. Nat. Rev.\nDrug Discovery 4, 649–663 (2005).\n48.\nDanziger, D. & Dean, P. Automated site-directed\ndrug design: a general algorithm for knowledge ac-\nquisition about hydrogen-bonding regions at pro-\ntein surfaces. Proc. Royal Soc. B . 236, 101–113\n(1989).\n49.\nSchneider, G., Lee, M.-L., Stahl, M. & Schnei-\nder, P. De novo design of molecular architectures\nby evolutionary assembly of drug-derived building\nblocks. J. Comput. Aided Mol. Des. 14, 487–494\n(2000).\n50.\nBöhm, H.-J. The computer program LUDI: a new\nmethod for the de novo design of enzyme in-\nhibitors. J. Comput. Aided Mol. Des. 6, 61–78\n(1992).\n51.\nRotstein, S. H. & Murcko, M. A. GroupBuild: a\nfragment-based method for de novo drug design.\nJ. Med. Chem. 36, 1700–1710 (1993).\n52.\nLewis, R. A. et al. Automated site-directed drug\ndesign using molecular lattices. J. Mol. Graph.\n10, 66–78 (1992).\n53.\nSchneider, P. & Schneider, G. De novo design at\nthe edge of chaos: Miniperspective. J. Med. Chem.\n59, 4077–4086 (2016).\n54.\nSegler, M. H., Kogej, T., Tyrchan, C. & Waller,\nM. P. Generating focused molecule libraries for\ndrug discovery with recurrent neural networks.\nACS Cent. Sci. 4, 120–131 (2018).\n55.\nMerk, D., Friedrich, L., Grisoni, F. & Schneider,\nG. De novo design of bioactive small molecules by\nartiﬁcial intelligence. Mol. Inform. 37, 1700153\n(2018).\n56.\nMerk, D., Grisoni, F., Friedrich, L. & Schneider,\nG. Tuning artiﬁcial intelligence on the de novo de-\nsign of natural-product-inspired retinoid X recep-\ntor modulators. Commun. Chem. 1, 1–9 (2018).\n57.\nGrisoni, F. et al. Combining generative artiﬁcial\nintelligence and on-chip synthesis for de novo drug\ndesign. Sci. Adv. 7, eabg3338 (2021).\n58.\nYuan, W. et al. Chemical Space Mimicry for\nDrug Discovery. J. Chem. Inf. Model. 57, 875–\n882 (2017).\n9\n59.\nArús-Pous, J. et al. Randomized SMILES strings\nimprove the quality of molecular generative mod-\nels. J. Cheminformatics 11, 1–13 (2019).\n60.\nGrisoni, F., Moret, M., Lingwood, R. & Schneider,\nG. Bidirectional molecule generation with recur-\nrent neural networks. J. Chem. Inf. Model. 60,\n1175–1183 (2020).\n61.\nSkalic, M., Jiménez, J., Sabbadin, D. & De Fab-\nritiis, G. Shape-based generative modeling for de\nnovo drug design. J. Chem. Inf. Model. 59, 1205–\n1214 (2019).\n62.\nLuo, S., Guan, J., Ma, J. & Peng, J. A 3D gener-\native model for structure-based drug design. Ad-\nvances in Neural Information Processing Systems\n(NeurIPS) 34, 6229–6239 (2021).\n63.\nLi, Y., Pei, J. & Lai, L. Structure-based de novo\ndrug design using 3D deep generative models.\nChem. Sci. 12, 13664–13675 (2021).\n64.\nGebauer, N. W., Gastegger, M., Hessmann, S. S.,\nMüller, K.-R. & Schütt, K. T. Inverse design of 3D\nmolecular structures with conditional generative\nneural networks. Nat. Commun. 13, 973 (2022).\n65.\nHoogeboom, E., Satorras, V. G., Vignac, C. &\nWelling, M. Equivariant diﬀusion for molecule\ngeneration in 3D. International Conference on\nMachine Learning (ICML) 39, 8867–8887 (2022).\n66.\nAnonymous.\nStructure-based\nDrug\nDe-\nsign\nwith\nEquivariant\nDiﬀusion\nModels.\nhttps://openreview.net/forum?id=uKmuzIuVl8z.\nunder review, 1–13 (2023).\n* DiﬀSBDD introduces a generative diﬀu-\nsion model that designs molecules directly\nin the 3D environment of the active bind-\ning site of a protein by denoising normally\ndistributed sets of points.\n67.\nAnonymous. 3D Equivariant Diﬀusion for Target-\nAware Molecule Generation and Aﬃnity Pre-\ndiction. https://openreview.net/forum?id= kJqX-\nEPXMsE0. under review, 1–13 (2023).\n68.\nIgashov, I. et al. Equivariant 3D-Conditional Dif-\nfusion Models for Molecular Linker Design. arXiv\npreprint arXiv:2210.05274 (2022).\n69.\nBatatia, I., Kovács, D. P., Simm, G. N., Ortner, C.\n& Csányi, G. Mace: Higher order equivariant mes-\nsage passing neural networks for fast and accu-\nrate force ﬁelds. arXiv preprint arXiv:2206.07697\n(2022).\n70.\nBatzner, S. et al. E(3)-equivariant graph neu-\nral networks for data-eﬃcient and accurate in-\nteratomic potentials. Nat. Commun. 13, 2453\n(2022).\n71.\nCheng, S.-S., Yang, G.-J., Wang, W., Leung,\nC.-H. & Ma, D.-L. The design and development\nof covalent protein-protein interaction inhibitors\nfor cancer treatment. J. Hematol. Oncol. 13, 1–14\n(2020).\n72.\nSchreiber, S. L. The rise of molecular glues. Cell\n184, 3–9 (2021).\n73.\nLi, K. & Crews, C. M. PROTACs: past, present\nand future. Chem. Soc. Rev. 51, 5214–5236\n(2022).\n74.\nSalton, M. & Misteli, T. Small molecule modu-\nlators of pre-mRNA splicing in cancer therapy.\nTrends Mol. Med. 22, 28–37 (2016).\n75.\nWang, R., Fang, X., Lu, Y. & Wang, S. The\nPDBbind database: Collection of binding aﬃni-\nties for protein- ligand complexes with known\nthree-dimensional structures. J. Med. Chem. 47,\n2977–2980 (2004).\n76.\nVolkov, M. et al. On the Frustration to Predict\nBinding Aﬃnities from Protein–Ligand Struc-\ntures with Deep Neural Networks. J. Med. Chem.\n65, 7946–7958 (2022).\n77.\nParks, C. D. et al. D3R grand challenge 4: blind\nprediction of protein–ligand poses, aﬃnity rank-\nings, and relative binding free energies. J. Com-\nput. Aided Mol. Des. 34, 99–119 (2020).\n78.\nGaieb, Z. et al. D3R Grand Challenge 2: blind\nprediction of protein–ligand poses, aﬃnity rank-\nings, and relative binding free energies. J. Com-\nput. Aided Mol. Des. 32, 1–20 (2018).\n79.\nHahn, D. F. et al. Best practices for construct-\ning, preparing, and evaluating protein-ligand\nbinding\naﬃnity\nbenchmarks.\narXiv\npreprint\narXiv:2105.06222 (2021).\n80.\nTosstorﬀ, A. et al. A high quality, industrial data\nset for binding aﬃnity prediction: performance\ncomparison in diﬀerent early drug discovery sce-\nnarios. J. Comput. Aided Mol. Des., 1–13 (2022).\n81.\nVerdonk, M. L., Cole, J. C., Hartshorn, M. J.,\nMurray, C. W. & Taylor, R. D. Improved protein–\nligand docking using GOLD. Proteins: Struct.,\nFunct., Bioinf. 52, 609–623 (2003).\n82.\nRogers, D. & Hahn, M. Extended-connectivity\nﬁngerprints. J. Chem. Inf. Model. 50, 742–754\n(2010).\n83.\nMendez, D. et al. ChEMBL: Towards direct de-\nposition of bioassay data. Nucleic Acids Res. 47,\nD930–D940 (2019).\n10\n",
  "categories": [
    "physics.chem-ph",
    "cs.LG"
  ],
  "published": "2022-10-19",
  "updated": "2022-10-19"
}