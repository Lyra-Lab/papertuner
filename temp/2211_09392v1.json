{
  "id": "http://arxiv.org/abs/2211.09392v1",
  "title": "Data Dimension Reduction makes ML Algorithms efficient",
  "authors": [
    "Wisal Khan",
    "Muhammad Turab",
    "Waqas Ahmad",
    "Syed Hasnat Ahmad",
    "Kelash Kumar",
    "Bin Luo"
  ],
  "abstract": "Data dimension reduction (DDR) is all about mapping data from high dimensions\nto low dimensions, various techniques of DDR are being used for image dimension\nreduction like Random Projections, Principal Component Analysis (PCA), the\nVariance approach, LSA-Transform, the Combined and Direct approaches, and the\nNew Random Approach. Auto-encoders (AE) are used to learn end-to-end mapping.\nIn this paper, we demonstrate that pre-processing not only speeds up the\nalgorithms but also improves accuracy in both supervised and unsupervised\nlearning. In pre-processing of DDR, first PCA based DDR is used for supervised\nlearning, then we explore AE based DDR for unsupervised learning. In PCA based\nDDR, we first compare supervised learning algorithms accuracy and time before\nand after applying PCA. Similarly, in AE based DDR, we compare unsupervised\nlearning algorithm accuracy and time before and after AE representation\nlearning. Supervised learning algorithms including support-vector machines\n(SVM), Decision Tree with GINI index, Decision Tree with entropy and Stochastic\nGradient Descent classifier (SGDC) and unsupervised learning algorithm\nincluding K-means clustering, are used for classification purpose. We used two\ndatasets MNIST and FashionMNIST Our experiment shows that there is massive\nimprovement in accuracy and time reduction after pre-processing in both\nsupervised and unsupervised learning.",
  "text": "Data Dimension Reduction makes ML Algorithms\nefﬁcient\n1st Wisal Khan\nSchool of Computer and Technology\nAnhui University, Hefei 230039\nPeoples Republic of China\nwisal.khan@cecos.edu.pk\n2nd Muhammad Turab\nDept: Computer Systems Engineering\nMehran Uni. of Enginerring & Technology\nHyderabad, Pakistan\nturabbajeer202@gmail.com\n3rd Waqas Ahmad\nSchool of Computer and Technology\nAnhui University, Hefei 230039\nPeoples Republic of China\nwaqasasad007@yahoo.com\n4th Syed Hasnat Ahmad\nSchool of Aeronautics\nNorthwestern Polytechnical University,\nXi’an, Shaanxi,710129, P. R of China\nHasnat92@hotmail.com\n5th Kelash Kumar\nDepartment Electrical Engineering\nMehran Uni. of Enginerring & Technology\nHyderabad, Pakistan\nkelash.nijar17@gmail.com\n6th Bin Luo\nSchool of Computer and Technology\nAnhui University, Hefei 230039\nPeoples Republic of China\nluobin@ahu.edu.cn\nAbstract—Data dimension reduction (DDR) is all about map-\nping data from high dimensions to low dimensions, various\ntechniques of DDR are being used for image dimension re-\nduction like Random Projections, Principal Component Analysis\n(PCA), the Variance approach, LSA-Transform, the Combined\nand Direct approaches, and the New Random Approach. Auto-\nencoders (AE) are used to learn end-to-end mapping. In this\npaper, we demonstrate that pre-processing not only speeds up\nthe algorithms but also improves accuracy in both supervised\nand unsupervised learning. In pre-processing of DDR, ﬁrst PCA\nbased DDR is used for supervised learning, then we explore AE\nbased DDR for unsupervised learning. In PCA based DDR, we\nﬁrst compare supervised learning algorithms accuracy and time\nbefore and after applying PCA. Similarly, in AE based DDR,\nwe compare unsupervised learning algorithm accuracy and time\nbefore and after AE representation learning. Supervised learning\nalgorithms including support-vector machines (SVM), Decision\nTree with GINI index, Decision Tree with entropy and Stochastic\nGradient Descent classiﬁer (SGDC) and unsupervised learning al-\ngorithm including K-means clustering, are used for classiﬁcation\npurpose. We used two datasets MNIST and FashionMNIST Our\nexperiment shows that there is massive improvement in accuracy\nand time reduction after pre-processing in both supervised and\nunsupervised learning.\nIndex Terms—Dimension Reduction, Supervised Learning,\nUnsupervised Learning, Principal Component Analysis, autoen-\ncoder, clustering.\nI. INTRODUCTION\nMachine learning (ML) algorithms are successful in range\nof domain tasks such as image classiﬁcation [16], [20], [21],\n[23], audio classiﬁcation [5], [22], [35], [46] and data dimen-\nsion reduction [25], [27] and many more [19]. Among them,\nDDR reduces [25], [27] the high dimension representation\ninto low level representation for data processing step. In the\ncurrent era, image classiﬁcation is the core task and improving\naccuracy and time are the key factors in image classiﬁcation.\nThe higher image dimension, the more time machine learning\nalgorithms require to process and at the same time, it is very\ndifﬁcult for the algorithms to classify due to higher dimension.\nTo cater these issues, we found that data dimension reduction\n(DDR) can solve these issues. For the purposes, we use AE\nand PCA for data dimension reduction and show their effect.\nA. Auto-Encoders (AE)\nConvolutional Neural Network (CNN) is one of the estab-\nlished deep learning techniques and brought certain advantages\nin feature extraction of high level semantics in the ﬁeld of\nimage detection, segmentation and classiﬁcation. Considering\nimage feature extraction many researchers have been proposed\nsmall optimized convolutional neural networks [11], [18], [44].\nThe purpose of the Auto-Encoders (AE) is to copy their\ninput to their output along with many constraints. The AEs\n[42] are neural networks. The main task of AE is the input\ncompression to gain the latent space representation. And then\nthis representation is used to build the desired output. The\ntwo main components of this kind of network are: Encoder\nand Decoder. The job of the AEs is not only to map the\ninput to the output but also to learn latent space representation.\nThe two main practical applications of AEs are data denoising\nand dimensionality reduction for data visualization. AEs are\ncategorized into 4 different types to achieve various properties\nwhen input is passed via encoder and decoder to construct a\nnew presentation. The types are Vanilla, Multilayer, Convo-\nlutional, and Regularized AEs. The representation of image\ninput is described in ﬁgure 1.\nB. Principal Component Analysis (PCA)\nPrincipal Component Analysis (PCA) is another technique\nto reduce image dimensions [14], [33]. PCA is based on\nmathematical functions. Single value decomposition method\nis used by the PCA [47] to extract the essential features of\na linear system. In many ﬁelds PCA is being widely applied\nsuch as digital signal processing, image recognition as well\nas classiﬁcation problems to discard noisy data [15], [26],\narXiv:2211.09392v1  [cs.CV]  17 Nov 2022\n[37], [43], [48]. PCA technique is applied to medical data\nto compress digital images according to the study of [41].\nLabeling data is tedious, time-consuming and expensive\ntask. In order to limit these problem, we explore DDR for un-\nsupervised learning that would cluster similar type of objects.\nBut we know, applying clustering directly on images is useless\nand waste of time. Our main contribution is, we pre-processed\ndata using state-of-the-art (SOTA) encoder-decoder models to\nget better representation for making accurate and efﬁcient\nprediction. We also compare with other SOTA techniques such\nas PCA. So our main focus on pre-processing of data and how\nit helps in speeding up algorithm and improving accuracy for\nclustering similar type of objects. And further it can be used\nfor auto labeling the data. The following is the contribution of\nour proposed work:\n• We demonstrate how pre-processing helps in improving\nspeed and accuracy in both supervised and unsupervised\nlearning.\n• We show the effect of DDR for supervised and unsuper-\nvised learning accuracy and time duration improvement.\n• We put our analysis on why accuracy and speed improved\nand clustering for auto labelling the data.\nThe rest of the paper is organized as follows.Section II de-\nscribes related work, section III explain methodology, section\nIV deﬁnes the experimental setup, section V discusses results\nevaluations and ﬁnally section VI concludes the whole work.\nFig. 1. Auto-encoder (Encoder-Decoder) architecture. Image taken from [45]\nII. RELATED WORK\nRetrieving the image, the non-linearity can be learned by\nmultiple layers of CNN to extract and characterize features.\nThe article [18] investigated that by observing the advance-\nment in the CNN regarding image segmentation, classiﬁcation\nand detection we can use for image retrieval the deep learning\napproach. They [18] achieved good result on ImageNet. For\nimage retrieval, they learn similarity using different networks\nacross different images in dataset, query image features are\ncalculated and the ﬁnal results are visualized [10]. The study\n[52] proposed the CNNH (Convolutional Neural Network\nHashing) for learning more robust features. CNNH ﬁrst de-\ncomposed the similarity matrix by using the similarity between\nthe training images. The training image binary coding is then\nobtained via similarity matrix. The obtained binary coding\nis then used by the CNN. Considering image retrieval paper\n[49] performed characteristics learning techniques on images\nby using CNN. DSRH (Deep Semantic Ranking Hashing) is\ninvestigated by article [54]. According to DSRH, the image\nretrieval job is to transform into solving the problem of image\nrelevancy ranking. Image learning feature representation is\nachieved via deep convolutional neural network (CNN) in\nDSRH. The obtained learning features of an image are then\nmapped to a hash code. The study [24] investigated a technique\nfor simultaneous feature learning and hash coding via deep\nconvolutional neural network. According to their proposed\nmethod [24] the image features are divided into individual\nencoding module into many chunks. In the hash code each\nchunk is responsible for learning one bit. In the paper [29] the\nimage pair supervision information has been utilized. The deep\nneural network has been constrained via a proposed regular\nterm. Therefore, the neural network output is close to the\nbinary code. In computer vision, according to the literature,\nthe CBIR is one of the hot areas of the last decade. The\nstudies [11], [18], [44] describes that for feature extraction\nfrom image search based on deep learning used classical\nclassiﬁcation models. The performance has been improving of\nthese classiﬁcation networks but too large models. Besides the\nlarge models the extracted feature dimension is also too high.\nTherefor for image search applications it is still insufﬁcient. In\nCNN the latter two layers are good for image search feature\nretrieval as investigated by [49]. According to the research the\nauthors of [17] are the founders of depth Auto-Encoder for\nimage retrieval. They [17] searched in CIFAR10 dataset and\ngained some good outcomes by using Boltzmann machine to\nencode and decode. The image features are compressed to\n254 bits. Extracting features via neural networks the article\n[2] and several other researchers used PCAs. IBM-supervised\nKL divergence is introduced by the author of [30] and is\nused for extracting the features. Approximate nearest neighbor\napproach is used instead of linear search to speed up the\nimage retrieval [28]. In the regarding of computer vision\nsimilarity, many proposed methods are investigated by the\nresearchers such as approaches based on hashing [9], [31],\n[34], [50], [53]. Hamming distance is used by the hashed-\nbased approaches to calculate the similarity. The authors of\n[39] investigated a hybrid model for CBIR. By considering\nextracting the corresponding image features, the authors [39]\nused convolutional neural network and depth Auto-Encoder.\nAccording to the literature the following compression coding\ntechniques and well established used in JPEG [12], [38], [40],\n[51] standard are Fast Fourier Transform (FFT), Discrete Co-\nsine Transform (DCT), Artiﬁcial Neural Network, and Discrete\nWavelet Transform (DWT). The PCA technique is explained\nby the study [3], [41] in detail. The article [39] explains the\ndigital image reduction process via PCA and used following\nequations.\nF(x, y) =\n\n\nf(0, 0)\n· · ·\nf(0, m −1)\n...\n...\n...\nf(n −1, 0)\n· · ·\nf(n −1, m −1)\n\n\n(1)\nIn equation 1, F(x,y) denoting the required colors while x,\ny represents the pixels coordinates of the image. Equation 2\nis about image normalization.\nFnormalized (x, y) =\n\n\nf(0, 0)\n· · ·\nf(0, m −1)\n...\n...\n...\nf(n −1, 0)\n· · ·\nf(n −1, m −1)\n\n−[ ¯f(0, 0)\n. . .\n¯f(0, m −1)]\n(2)\nEquation 3 is representing the Covariance Matrix of image\ndata.\nCov(X, Y ) = Fnormalized (x, y) ∗Fnormalized (x, y)T\nm −1\n(3)\nThe Covariance Matrix Eigenvectors and Eigenvalues are\ngiven in equation 4 while equation 5 representing the image\ntransformation data into New Basis.\nAAT = Cov(X, Y ) = UD2U T\n(4)\nFtransformed (x, y) = U T Fnormalized (x, y)\n(5)\nIn equation 4 and equation 5, U, U T and D2 are matrices.\nColumn vectors of U represent eigen vector while diagonal\nentr(ies) of D2 represent eigen values.\nIII. METHODOLOGY\nWe have divided method into two sections one with super-\nvised learning and other with unsupervised learning. We will\nshow comparison results within the experiments section.\nA. Supervised\nIn this part, we used ﬁrst PCA algorithm to reduce the\ndimension of data (images) and then applied some machine\nlearning algorithms [32], and showed how pre-processing\nspeedup algorithm and with comparable accuracy as shown\nin experiments section. For this supervised learning to learn\nfaster, we ﬁrst projected the data into low dimension using\nPCA.\nAfter applying PCA, we used below machine learning\nalgorithm to check accuracy and time before and after PCA\napplying.\n• SVM (with and without PCA)\n• Decision Tree with GINI index (with and without PCA)\n• Decision Tree with entropy (with and without PCA)\n• Stochastic Gradient Descent classiﬁer (with and without\nPCA)\n• Gaussian Naive Bayes (with and without PCA)\n1) SVM: Support Vector Machine (SVM) is a classiﬁer that\nis used for binary or multi classiﬁcation problem [36]. Tech-\nnically, provided labels with data, it learns the parameter and\ncalculate the optimal hyperplane. In SVM, kernel plays very\nimportant role. For linear kernel the equation for prediction\nfor a new input as follows:\nF(x) = w∗x + b\n(6)\nEquation 6 used in SVM, where we learn w and b from\ntraining data, once these are learnt they can be used for testing.\nThe polynomial kernel can be written as\nK(x, xi) = 1 + sum(x ∗xi)d\n(7)\nand exponential as\nK(x, xi) = exp(−gamma ∗sum((x −xi2))\n(8)\n.\n2) Decision Tree with GINI index: Decision tree is classi-\nﬁcation algorithm used for classiﬁcation and regression both.\nThey are very popular because trees often mimic the human\nlevel thinking so easy to interpret the data. In Classiﬁcation\nwith using the Classiﬁcation and Regression Trees (CART)\nalgorithm, mostly GINI index is used. Gini impurity is a\nmeasurement of how often a randomly chosen element from\nthe set would be incorrectly labeled if it was randomly labeled\naccording to the distribution of labels in the subset [4].\n3) Decision Tree with Entropy: Decision tree is built as\ntop-down from root node and composed of partitioning the\ndata into subsets that has further many instances with same\nvalue that we call as homogeneous. Entropy means disorder,\nand it measures the homogeneity of sample. If the sample\nis completely homogeneous, then entropy is zero and if the\nsample is equally divided then it has entropy of one [13].\n4) Stochastic Gradient Descent Classiﬁer: The stochastic\ngradient method is a gradient decent method used to classify\nthe data point and highly depends on rate of the convergence.\nIt differs from traditional gradient in a way; its elements\nare interpreted separately. It approximate the gradient while\nusing only one data point and results in saving a lot of time,\nand really more helpful while working with huge dataset.\nProcedure is described below.\n• Shufﬂe dataset randomly\n• Cycle on all elements of the sample\n• Cycle on all weights\n• Adjust the current weight in accordance with the private\nderivative of the cost function.\nIt is really critical to get to know that in contrast to\ntraditional method of gradient descent, this algorithm at every\nstep may not endeavor to minimize the cost function, but as\na result of speciﬁed steps number, the general direction will\ntend to this minimum [1].\n5) Gaussian Naive Bayes: First let’s know Na¨ıve Bayes, it\nis classiﬁer based on probability, it calculates the probability\nof each example or sample be part of certain label or category,\nbased on prior knowledge [8].\nB. Unsupervised\nIn unsupervised learning [6], we used ﬁrst reduced image di-\nmension by training encoder decoder and then apply k-means\nclustering to know improved accuracy. Below is architecture\nof encoder decoder architecture.\nFig. 2. Encode decoder architecture. Image is taken from [7]\nFrom above ﬁgure 2, we ﬁrst pass train image twice, one\ntime as an image to be processed and secondly as a label to\nbe learnt. We want to ensure that encoder and decoder learnt\ncompressed representation properly or not. Once it is trained,\nthen we compress all train images and then apply k-means\nclustering. We showed accuracy and duration of clustering\nafter and before image compression. Figure 1 and ﬁgure 2\nrepresent white box and black box architecture, respectively. .\nIV. EXPERIMENT\nFor our experiment, we used two datasets, MNIST and\nFASHION-MNIST. For each dataset, we applied both super-\nvised and unsupervised learning. First we will explain the\nsupervised learning, in which we ﬁrst reduced dimension (used\n25 components) of image using PCA then applied ﬁve super-\nvised learning algorithms. In this experiment, we will show\naccuracy and time before and after PCA. For unsupervised\nlearning, ﬁrst we trained the encoder decoder to learn image\nin compressed form, then applied k-means clustering. In this\nexperiment, we will show accuracy and time before and after\ncompressed form images. At the end we will show, how much\nunsupervised learning is close to supervised learning in the\nterm of accuracy.\nV. RESULTS EVALUATIONS\nA. Supervised learning experiment result\nIn this experiment, we used MNIST and FASHION-MNIST\ndatasets and their results are shown in tables I & II respec-\ntively. Note: — means, it was unable to ﬁnd decision boundary\nand it took too much time to train.\nAs you can see that how much time is reduced in some\ncases, it is reduced to nine times plus relatively. Regarding,\naccuracy, PCA reduction outperforms before PCA cases. For\nbetter understanding, we visualised the result before and after\ndimension reduction, for MNIST and FashionMNIST datasets\nfor time and accuracy as shown in ﬁgures 3, 4 V-A and 5.\nFigure 5 shows major time difference before and after PCA.\nIt can be easy for PCA to learn better representation and\nadditionaly, it can also be dependent on model as different\nmodel is showing different gap before and after PCA. From\nthis experiment, we conclude that pre-processing not help in\nimproving time but also accuracy.\nFig. 3. Supervised learning accuracy results for MNIST dataset\nFig. 4. Supervised learning time results for MNIST dataset\nB. Unsupervised learning experiment\nIn this experiment, we ﬁrst apply k-means clustering di-\nrectly on images and we get lower accuracy. To improve the\naccuracy, we trained the encoder to encode an image in low\ndimension and then apply k-means clustering. Here we refer\nNormalize mutual information score as accuracy. Encoder is\nnot helpful in accuracy improving but it also time efﬁcient as\nshown in below tables III & IV for MNIST and FASHION-\nMNIST dataset respectively.\nAccuracy\nTime\nAlgorithms\nBefore PCA\nAfter PCA\nBefore PCA\nAfter PCA\nDecision Tree GINI index\n85.44%\n81.59%\n18.649s\n2.152s\nDecision Tree Entropy\n88.05%\n84.1%\n27.447s\n8.664s\nStochastic Gradient Descent classiﬁer\n85.44%\n85.22%\n5.491s\n0.321s\nGaussian Naive Bayes\n55.58%\n86.38%\n0.585s\n0.041s\nSVM\n—\n96.77%\n—\n163.970s\nTABLE I\nSUPERVISED LEARNING FOR MNIST DATASET\nAccuracy\nTime\nAlgorithm\nBefore PCA\nAfter PCA\nBefore PCA\nAfter PCA\nDecision Tree GINI index\n80.44%\n76.06%\n32.101s\n3.233s\nDecision Tree Entropy\n81.58%\n78.39%\n39.973s\n11.347s\nStochastic Gradient Descent classiﬁer\n82.28%\n78.06%\n5.385s\n0.380s\nGaussian Naive Bayes\n58.56%\n75.07%\n0.842s\n0.115s\nSVM\n–\n84.79%\n—\n162.740s\nTABLE II\nSUPERVISED LEARNING FOR FASHION-MNIST DATASET\nAccuracy\nTime\nAlgorithm\nBefore Encoder\nAfter Encoder\nBefore Encoder\nAfter Encoder\nK-means\n49.81%\n75.37%\n205.714s\n7.5889\nTABLE III\nUNSUPERVISED LEARNING FOR MNIST DATASET\nAccuracy\nTime\nAlgorithm\nBefore Encoder\nAfter Encoder\nBefore Encoder\nAfter Encoder\nK-means\n51.4%\n58.56%\n224.386s\n8.597s\nTABLE IV\nUNSUPERVISED LEARNING FOR FASHION-MNIST DATASET\nFig. 5. Supervised learning time results for Fashion-MNIST dataset\nFrom this experiment, we have shown that pre-processing\nnot helps in supervised learning, but also in unsupervised\nlearning. As above both table showed, not only time reduced\nbut also accuracy improved a lot. It is improved because of\nlow dimension of data representation, that low dimension data\nbecome easy for k-means algorithm to learn and make cluster\neasily. For cluster evaluation we used normalized mutual\ninformation score.\nC. Supervised and unsupervised learning comparison\nOne common thing is preprocessing helped in both learning\na lot. We will discuss accuracies and durations of both\nlearning after preprocessing. In supervised learning, accuracy\nis improved a little bit and in some cases it is reduced a\nlittle bit too. But in clustering, it is improved in both cases\na lot. Because for clustering it becomes easy to learn data\nin low dimension, so clustering accuracy is much closer to\nthe supervised learning algorithms. Regarding duration, it has\nimproved a lot in both learning after preprocessing.\nAnalysis:Why dimension helpful? This is because of pre-\nprocessing, DDR reduced the dimensions and it becomes easy\nfor algorithms to classiﬁer and at the same time, it takes a\nvery less time, that is why algorithm learns faster and more\naccurate.\nVI. CONCLUSION\nIn this paper, we demonstrated that the data dimension\nreduction helps to improve accuracy and time of ML algo-\nrithms. To do so, we explored two different technique of data\ndimension reduction for supervised and unsupervised learning\nusing two different datasets namely, MNIST and Fashion-\nMNIST. DDR has shown massive improvement in term of\ntime and accuracy. Furthermore, we discussed result behind\nefﬁciency of these algorithm due to DDR. Our future work is\nto explore these techniques for data other than gray.\nREFERENCES\n[1] Hakob Avjyan. SGD stochastic gradient descent, 2018.\n[2] Artem Babenko, Anton Slesarev, Alexandr Chigorin, and Victor Lem-\npitsky. Neural codes for image retrieval. In European conference on\ncomputer vision, pages 584–599. Springer, 2014.\n[3] Bing-Kun Bao, Guangcan Liu, Changsheng Xu, and Shuicheng Yan.\nInductive robust principal component analysis. IEEE transactions on\nimage processing, 21(8):3794–3800, 2012.\n[4] Learn by Marketing. Gini index, 2017.\n[5] Aisha Chandio, Yao Shen, Malika Bendechache, Irum Inayat, and\nTeerath Kumar. Audd: audio urdu digits dataset for automatic audio\nurdu digit recognition. Applied Sciences, 11(19):8842, 2021.\n[6] Chengwei. How to do Unsupervised Clustering with Keras, 2018.\n[7] Francois Chollet. Building Autoencoders in Keras, 2016.\n[8] Sara Iris Garcia. Easy and quick explanation: naive bayes algorithm,\n2018.\n[9] Aristides Gionis, Piotr Indyk, Rajeev Motwani, et al. Similarity search\nin high dimensions via hashing. In Vldb, volume 99, pages 518–529,\n1999.\n[10] Davar Giveki, Ashkan Shakarami, Hadis Tarrah, and Mohammad Ali\nSoltanshahi. A new method for image classiﬁcation and image retrieval\nusing convolutional neural networks. Concurrency and Computation:\nPractice and Experience, 34(1):e6533, 2022.\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\nDeep\nresidual learning for image recognition. In Proceedings of the IEEE\nconference on computer vision and pattern recognition, pages 770–778,\n2016.\n[12] Abir Jaafar Hussain, Dhiya Al-Jumeily, Naeem Radi, and Paulo Lisboa.\nHybrid neural network predictive-wavelet image compression system.\nNeurocomputing, 151:975–984, 2015.\n[13] Rishabh Jain. Decision Trees it begin here, 2017.\n[14] Ian T Jolliffe. Principal component analysis for special types of data.\nSpringer, 2002.\n[15] Patrik Kamencay, Tibor Trnovszky, Miroslav Benco, Robert Hudec,\nPeter Sykora, and Andrej Satnik.\nAccurate wild animal recognition\nusing pca, lda and lbph. In 2016 ELEKTRO, pages 62–67. IEEE, 2016.\n[16] Wisal Khan, Kislay Raj, Teerath Kumar, Arunabha M Roy, and Bin\nLuo. Introducing urdu digits dataset with demonstration of an efﬁcient\nand robust noisy decoder-based pseudo example generator. Symmetry,\n14(10):1976, 2022.\n[17] Alex Krizhevsky and Geoffrey E Hinton. Using very deep autoencoders\nfor content-based image retrieval. In ESANN, volume 1, page 2. Citeseer,\n2011.\n[18] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.\nImagenet\nclassiﬁcation with deep convolutional neural networks.\nAdvances in\nneural information processing systems, 25, 2012.\n[19] Teerath Kumar, Rob Brennan, and Malika Bendechache. Stride random\nerasing augmentation.\n[20] Teerath Kumar, Jinbae Park, Muhammad Salman Ali, AFM Uddin, and\nSung-Ho Bae.\nClass speciﬁc autoencoders enhance sample diversity.\nJournal of Broadcast Engineering, 26(7):844–854, 2021.\n[21] Teerath Kumar, Jinbae Park, Muhammad Salman Ali, AFM Shahab\nUddin, Jong Hwan Ko, and Sung-Ho Bae. Binary-classiﬁers-enabled\nﬁlters for semi-supervised learning. IEEE Access, 9:167663–167673,\n2021.\n[22] Teerath Kumar, Jinbae Park, and Sung-Ho Bae.\nIntra-class random\nerasing (icre) augmentation for audio classiﬁcation. In Proceedings Of\nThe Korean Society Of Broadcast Engineers Conference, pages 244–247.\nThe Korean Institute of Broadcast and Media Engineers, 2020.\n[23] Teerath Kumar, Muhammad Turab, Shahnawaz Talpur, Rob Brennan,\nand Malika Bendechache. Forged character detection datasets: Passports,\ndriving licences and visa stickers.\n[24] Hanjiang Lai, Yan Pan, Ye Liu, and Shuicheng Yan.\nSimultaneous\nfeature learning and hash coding with deep neural networks.\nIn\nProceedings of the IEEE conference on computer vision and pattern\nrecognition, pages 3270–3278, 2015.\n[25] Chulhee Lee and David A Landgrebe.\nAnalyzing high-dimensional\nmultispectral data.\nIEEE Transactions on Geoscience and Remote\nSensing, 31(4):792–800, 1993.\n[26] Hailin Li. Accurate and efﬁcient classiﬁcation based on common princi-\npal components analysis for multivariate time series. Neurocomputing,\n171:744–753, 2016.\n[27] Wei Li, Saurabh Prasad, James E Fowler, and Lori Mann Bruce.\nLocality-preserving dimensionality reduction and classiﬁcation for hy-\nperspectral image analysis.\nIEEE Transactions on Geoscience and\nRemote Sensing, 50(4):1185–1198, 2011.\n[28] Kevin Lin, Huei-Fang Yang, Jen-Hao Hsiao, and Chu-Song Chen. Deep\nlearning of binary hash codes for fast image retrieval. In Proceedings\nof the IEEE conference on computer vision and pattern recognition\nworkshops, pages 27–35, 2015.\n[29] Haomiao Liu, Ruiping Wang, Shiguang Shan, and Xilin Chen. Deep\nsupervised hashing for fast image retrieval. In Proceedings of the IEEE\nconference on computer vision and pattern recognition, pages 2064–\n2072, 2016.\n[30] Wei Liu. Hashing by deep learning. IBM TJ Watson Research Center.\n[31] Wei Liu, Jun Wang, Rongrong Ji, Yu-Gang Jiang, and Shih-Fu Chang.\nSupervised hashing with kernels. In 2012 IEEE conference on computer\nvision and pattern recognition, pages 2074–2081. IEEE, 2012.\n[32] MCU. Dimension reduction.\n[33] Bruce Moore.\nPrincipal component analysis in linear systems: Con-\ntrollability, observability, and model reduction. IEEE transactions on\nautomatic control, 26(1):17–32, 1981.\n[34] Mohammad Norouzi and David J Fleet.\nMinimal loss hashing for\ncompact binary codes. In ICML, 2011.\n[35] Jinbae Park, Teerath Kumar, and Sung-Ho Bae.\nSearch for optimal\ndata augmentation policy for environmental sound classiﬁcation with\ndeep neural networks. Journal of Broadcast Engineering, 25(6):854–\n860, 2020.\n[36] Savan Patel. Chapter 2:svm (support vector machine) — theory, 2017.\n[37] Robertas Petrolis and Algimantas Krisciukaitis. Multi stage principal\ncomponent analysis based method for detection of fetal heart beats in\nabdominal ecgs.\nIn Computing in Cardiology 2013, pages 301–304.\nIEEE, 2013.\n[38] KMM Prabhu, K Sridhar, Massimo Mischi, and Halandur Nagaraja\nBharath. 3-d warped discrete cosine transform for mri image compres-\nsion. Biomedical signal processing and control, 8(1):50–58, 2013.\n[39] Jingkun Qin, E Haihong, Meina Song, and Zhijun Ren. Image retrieval\nbased on a hybrid model of deep convolutional encoder. In 2018 IEEE\nInternational Conference of Intelligent Robotic and Control Engineering\n(IRCE), pages 257–262. IEEE, 2018.\n[40] Jonathan Quijas and Olac Fuentes. Removing jpeg blocking artifacts\nusing machine learning.\nIn 2014 Southwest Symposium on Image\nAnalysis and Interpretation, pages 77–80. IEEE, 2014.\n[41] Rafael do Esp´ırito Santo. Principal component analysis applied to digital\nimage compression. Einstein (S˜ao Paulo), 10:135–139, 2012.\n[42] Towards Data Science. Build a simple Image Retrieval System with an\nAutoencoder, 2018.\n[43] Huawang Shi. Application of principal component analysis to general\ncontracting risk assessment. In 2009 ISECS International Colloquium\non Computing, Communication, Control, and Management, volume 3,\npages 53–56. IEEE, 2009.\n[44] Karen Simonyan and Andrew Zisserman.\nVery deep convolu-\ntional networks for large-scale image recognition.\narXiv preprint\narXiv:1409.1556, 2014.\n[45] Hossen Teimoorinia, Sara Shishehchi, Ahnaf Tazwar, Ping Lin, Finn\nArchinuk, Stephen DJ Gwyn, and JJ Kavelaars. An astronomical image\ncontent-based recommendation system using combined deep learning\nmodels in a fully unsupervised mode.\nThe Astronomical Journal,\n161(5):227, 2021.\n[46] Muhammad Turab, Teerath Kumar, Malika Bendechache, and Takfarinas\nSaber. Investigating multi-feature selection and ensembling for audio\nclassiﬁcation. arXiv preprint arXiv:2206.07511, 2022.\n[47] Jengnan Tzeng.\nSplit-and-combine singular value decomposition for\nlarge-scale matrix. Journal of Applied Mathematics, 2013, 2013.\n[48] Georgios Tzimiropoulos, Stefanos Zafeiriou, and Maja Pantic. Principal\ncomponent analysis of image gradient orientations for face recognition.\nIn 2011 IEEE International Conference on Automatic Face & Gesture\nRecognition (FG), pages 553–558. IEEE, 2011.\n[49] Ji Wan, Dayong Wang, Steven Chu Hong Hoi, Pengcheng Wu, Jianke\nZhu, Yongdong Zhang, and Jintao Li. Deep learning for content-based\nimage retrieval: A comprehensive study. In Proceedings of the 22nd\nACM international conference on Multimedia, pages 157–166, 2014.\n[50] Yair Weiss, Antonio Torralba, and Rob Fergus.\nSpectral hashing.\nAdvances in neural information processing systems, 21, 2008.\n[51] Ming-Sheng Wu. Genetic algorithm based on discrete wavelet transfor-\nmation for fractal image compression. Journal of Visual Communication\nand Image Representation, 25(8):1835–1841, 2014.\n[52] Rongkai Xia, Yan Pan, Hanjiang Lai, Cong Liu, and Shuicheng Yan.\nSupervised hashing for image retrieval via image representation learning.\nIn Twenty-eighth AAAI conference on artiﬁcial intelligence, 2014.\n[53] Matthew D Zeiler and Rob Fergus. Stochastic pooling for regularization\nof deep convolutional neural networks. arXiv preprint arXiv:1301.3557,\n2013.\n[54] Fang Zhao, Yongzhen Huang, Liang Wang, and Tieniu Tan.\nDeep\nsemantic ranking based hashing for multi-label image retrieval.\nIn\nProceedings of the IEEE conference on computer vision and pattern\nrecognition, pages 1556–1564, 2015.\n",
  "categories": [
    "cs.CV",
    "cs.AI",
    "cs.LG"
  ],
  "published": "2022-11-17",
  "updated": "2022-11-17"
}