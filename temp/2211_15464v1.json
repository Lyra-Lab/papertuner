{
  "id": "http://arxiv.org/abs/2211.15464v1",
  "title": "Considerations for meaningful sign language machine translation based on glosses",
  "authors": [
    "Mathias Müller",
    "Zifan Jiang",
    "Amit Moryossef",
    "Annette Rios",
    "Sarah Ebling"
  ],
  "abstract": "Automatic sign language processing is gaining popularity in Natural Language\nProcessing (NLP) research (Yin et al., 2021). In machine translation (MT) in\nparticular, sign language translation based on glosses is a prominent approach.\nIn this paper, we review recent works on neural gloss translation. We find that\nlimitations of glosses in general and limitations of specific datasets are not\ndiscussed in a transparent manner and that there is no common standard for\nevaluation.\n  To address these issues, we put forward concrete recommendations for future\nresearch on gloss translation. Our suggestions advocate awareness of the\ninherent limitations of gloss-based approaches, realistic datasets, stronger\nbaselines and convincing evaluation.",
  "text": "Considerations for meaningful sign language machine translation based\non glosses\nMathias Müller1, Zifan Jiang1, Amit Moryossef1,2,3, Annette Rios1 and Sarah Ebling1\n1 Department of Computational Linguistics, University of Zurich, Switzerland\n2 ETH Zurich, Switzerland, 3 Bar-Ilan University, Tel Aviv, Israel\n{mmueller,jiang,rios,ebling}@cl.uzh.ch, amitmoryossef@gmail.com\nAbstract\nAutomatic sign language processing is gain-\ning popularity in Natural Language Processing\n(NLP) research (Yin et al., 2021). In machine\ntranslation (MT) in particular, sign language\ntranslation based on glosses is a prominent ap-\nproach. In this paper, we review recent works\non neural gloss translation. We ﬁnd that limi-\ntations of glosses in general and limitations of\nspeciﬁc datasets are not discussed in a transpar-\nent manner and that there is no common stan-\ndard for evaluation.\nTo address these issues, we put forward con-\ncrete recommendations for future research on\ngloss translation.\nOur suggestions advocate\nawareness of the inherent limitations of gloss-\nbased approaches, realistic datasets, stronger\nbaselines and convincing evaluation.\n1\nIntroduction\nAutomatic sign language processing is becom-\ning more popular in Natural Language Processing\n(NLP) research (Yin et al., 2021). In machine trans-\nlation (MT) in particular, many recent publications\nhave proposed sign language translation based on\nglosses. Glosses provide semantic labels for in-\ndividual signs. They typically consist of the base\nform of a word in the surrounding spoken language\nwritten in capital letters (see Table 1). Even though\nglosses are not a complete representation of signs\n(see e.g. Pizzuto et al. 2006), they are often adopted\nin MT because, by virtue of being textual, they ﬁt\nseamlessly into existing MT pipelines and existing\nmethods seemingly require the least modiﬁcation.\nIn this paper, we review recent works on neu-\nral gloss translation. We ﬁnd that limitations of\ngloss-based approaches in general and limitations\nof speciﬁc datasets are not transparently discussed\nas inherent shortcomings. Furthermore, among\ngloss translation papers there is no common stan-\ndard for evaluation, especially regarding the exact\nmethod to compute BLEU scores.\nGlosses (DSGS)\nKINDER FREUEN WARUM FERIEN NÄHER-KOMMEN\nTranslation (DE)\nDie Kinder freuen sich, weil die Ferien näher\nrücken.\nGlosses (EN)\n(‘CHILDREN REJOICE WHY HOLIDAYS APPROACHING’)\nTranslation (EN)\n(‘The children are happy because the holidays\nare approaching.’)\nTable\n1:\nExample\nfor\nsign\nlanguage\nglosses.\nDSGS=Swiss German Sign Language, DE=German,\nEN=English. English translations are provided for con-\nvenience. Example is adapted from a lexicon of the\nthree sign languages of Switzerland, where a sign lan-\nguage video of this sentence is available (https://\nsignsuisse.sgb-fss.ch/de/lexikon/g/ferien/).\nExperiments in sign language translation should\nbe informed by sign language expertise and should\nbe performed according to the best practices al-\nready established in the MT community.\nTo alleviate these problems going forward, we\nmake practical recommendations for future re-\nsearch on gloss translation.\nOur paper makes the following contributions:\n• We provide a review of recent works on gloss\ntranslation (§2).\n• We outline recommendations for future work\nwhich promote awareness of the inherent lim-\nitations of gloss-based approaches, realistic\ndatasets, stronger baselines and convincing\nevaluation (§3).\n2\nRelated work\nFor a general overview of sign language process-\ning in the context of NLP see Yin et al. (2021);\nMoryossef and Goldberg (2021) and De Coster\net al. (2022) for a comprehensive survey of sign\nlanguage machine translation (including, but not\nlimited to, gloss-based approaches).\narXiv:2211.15464v1  [cs.CL]  28 Nov 2022\nL\ndatasets\ntranslation directions\ncode\nevaluation metrics\nBLEU tool\nP\nO\nDGS→DE\nDE→DGS\nO\nB 1-3\nB-4\nR\nO\nCamgöz et al. (2018)\n-\n\u0014\n-\n\u0014\n-\n-\n\u0014\n\u0014\n\u0014\n\u0014\n-\nTensorﬂow\nStoll et al. (2018)\n-\n\u0014\n-\n-\n\u0014\n-\n-\n\u0014\n\u0014\n\u0014\n-\n(unclear)\nCamgöz et al. (2020b)\n\u0014\n\u0014\n-\n\u0014\n-\n-\n\u0014\n\u0014\n\u0014\n-\nWER\n(unclear)\nCamgöz et al. (2020a)\n\u0014\n\u0014\n-\n\u0014\n-\n-\n-\n-\n\u0014\n\u0014\n-\n(unclear)\nYin and Read (2020)\n\u0014\n\u0014\nASLG-PC12\n\u0014\n-\nASL→EN\n\u0014\n\u0014\n\u0014\n\u0014\nMETEOR\nNLTK\nSaunders et al. (2020)\n\u0014\n\u0014\n-\n-\n\u0014\n-\n\u0014\n\u0014\n\u0014\n\u0014\n-\n(unclear)\nStoll et al. (2020)\n\u0014\n\u0014\n-\n-\n\u0014\n-\n-\n\u0014\n\u0014\n\u0014\nWER\n(unclear)\nOrbay and Akarun (2020)\n-\n\u0014\n-\n\u0014\n-\n-\n-\n\u0014\n\u0014\n\u0014\n-\n(unclear)\nMoryossef et al. (2021)\n-\n\u0014\nNCSLGR\n\u0014\n-\nASL→EN\n(\u0014)\n-\n\u0014\n-\nCOMET\nSacreBLEU\nZhang and Duh (2021)\n-\n\u0014\n-\n\u0014\n\u0014\n-\n-\n-\n\u0014\n-\n-\n(unclear)\nEgea Gómez et al. (2021)\n-\n\u0014\n-\n-\n\u0014\n-\n\u0014\n-\n\u0014\n\u0014\nMETEOR, TER\nSacreBLEU\nSaunders et al. (2022)\n-\n\u0014\nDGS Corpus\n-\n\u0014\n-\n-\n-\n\u0014\n\u0014\n-\n(unclear)\nAngelova et al. (2022)\n\u0014\n\u0014\nDGS Corpus\n\u0014\n-\n-\n\u0014\n-\n\u0014\n-\n-\nSacreBLEU\nWalsh et al. (2022)\n-\n\u0014\nDGS Corpus\n-\n\u0014\n-\n-\n\u0014\n\u0014\n\u0014\n-\n(unclear)\nTable 2: Review of recent works on gloss translation. L=whether a paper discusses limitations of gloss approaches,\nP=RWTH-PHOENIX-Weather 2014T introduced by Camgöz et al. (2018), O=other, (\u0014)=exact shell commands are\nlisted in the appendix of the paper, B=BLEU, R=ROUGE, B1-4=four variants of BLEU, varying the maximum\nngram order from 1 to 4, SacreBLEU=version 1.4.14, COMET=wmt-large-da-estimator-1719, DGS=German Sign\nLanguage, DE=German, ASL=American Sign Language, EN=English. In the code column, checkmark symbols\n(\u0014) are clickable links.\nWe conduct a more narrow literature review of\n14 recent publications on gloss translation. We re-\nport characteristics such as the datasets used, trans-\nlation directions, and evaluation details (Table 2).\n2.1\nAwareness of limitations of gloss\napproach\nWe ﬁnd that 8 out of 14 reviewed works do not\ninclude an adequate discussion of the limitations\nof gloss approaches, inadvertently overstating the\npotential usefulness of their experiments.\nIn the context of sign languages, glosses are\nunique identiﬁers for individual signs. However, a\nlinear sequence of glosses is not an adequate rep-\nresentation of a signed utterance, where different\nchannels (manual and non-manual) are engaged si-\nmultaneously. Linguistically relevant cues such as\nnon-manual movement or use of three-dimensional\nspace may be missing (Yin et al., 2021).\nThe gloss transcription conventions of different\ncorpora vary greatly, as does the level of detail (see\nKopf et al. (2022) for an overview of differences\nand commonalities between corpora). Therefore,\nglosses in different corpora or across languages\nare not comparable. Gloss transcription is an enor-\nmously laborious process done by expert linguists.\nBesides, glosses are a linguistic tool, not a writ-\ning system established in Deaf 1 communities.\n1It is a widely recognized convention to use the uppercased\nSign language users generally do not read or write\nglosses in their everyday lives.\nTaken together, this means that gloss translation\nsuffers from an inherent and irrecoverable informa-\ntion loss, that creating an abundance of translations\ntranscribed as glosses is unrealistic, and that gloss\ntranslation systems are not immediately useful to\nend users.\n2.2\nChoice of dataset\nAll reviewed works use the RWTH-PHOENIX\nWeather\n2014T\n(hereafter\nabbreviated\nas\nPHOENIX) dataset (Forster et al., 2014; Camgöz\net al., 2018) while other datasets are used far less\nfrequently. Besides, we note a distinct paucity of\nlanguages and translation directions: 12 out of 14\nworks are concerned only with translation between\nGerman Sign Language (DGS) and German (DE),\nthe language pair of the PHOENIX dataset.\nWhile PHOENIX was a breakthrough when it\nwas published, it is of limited use for current re-\nsearch. The dataset is small (8k sentence pairs)\nand contains only weather reports, covering a very\nnarrow linguistic domain. It is important to discuss\nthe exact nature of glosses, how the corpus was\nword Deaf for describing members of a sign language commu-\nnity and, in contrast, to use the lowercased word deaf when\ndescribing the audiological state of a hearing loss (Morgan and\nWoll, 2002). More recent works (Napier and Leeson, 2016;\nKusters et al., 2017) propose to use deaf in both situations.\ncreated and how it is distributed.\nGlossing\nPHOENIX\nis\nbased\non\nGerman\nweather reports interpreted into DGS and broad-\ncast on the TV station Phoenix. The broadcast\nvideos served as input for the DGS side of the par-\nallel corpus. Compared to the glossing conventions\nof other well-known corpora, PHOENIX glosses\nare simplistic and capture mostly manual features\n(with mouthings as the only non-manual activity\ncovered), which is not sufﬁcient to represent mean-\ning (§2.1).\nLive interpretation and translationese effects\nThe fact that PHOENIX data comes from inter-\npretation in a live setting has two implications:\nFirstly, since information was conveyed at high\nspeed, the sign language interpreters omitted pieces\nof information from time to time. This leads to\nan information mismatch between some German\nsentences and their DGS counterparts. Secondly,\ndue to the high speed of transmission, the (hear-\ning) interpreters sometimes followed the grammar\nof German more closely than that of DGS. As a\nconsequence, some translations are more similar\nto Signed German (Lautsprachbegleitendes Gebär-\nden) than DGS.\nPreprocessing of spoken language\nThe Ger-\nman side of the PHOENIX corpus is available only\nalready tokenized, lowercased and with punctua-\ntion symbols removed. From an MT perspective\nthis is unexpected since corpora are usually dis-\ntributed without such preprocessing.\nPHOENIX is popular because it is freely avail-\nable and is a benchmark with clearly deﬁned data\nsplits introduced by Camgöz et al. (2018). Sign lan-\nguage machine translation as a ﬁeld is experiencing\na shortage of free and open datasets and, with the\nexception of PHOENIX, there are no agreed-upon\ndata splits.\nEssentially, from a scientiﬁc point of view\nachieving higher gloss translation quality on the\nPHOENIX dataset is near meaningless. The ap-\nparent overuse of PHOENIX is reminiscent of the\noveruse of MNIST (LeCun et al., 2010) in machine\nlearning, or the overuse of the WMT 14 English-\nGerman benchmark in the MT community, popu-\nlarized by Vaswani et al. (2017).\n2.3\nEvaluation\nAs evaluation metrics, all works use some variant\nof BLEU (Papineni et al., 2002), and ten out of\n14 use some variant of ROUGE (Lin, 2004). All\nbut four papers do not contain enough information\nabout how exactly BLEU was computed. Different\nBLEU implementations, settings (e.g. ngram or-\nders, tokenization schemes) and versions are used.\nNon-standard metrics\nROUGE is a metric com-\nmon in automatic summarization but not in MT,\nand was never correlated with human judgement\nin a large study. In eight out of 14 papers, BLEU\nis used with a non-standard maximum ngram or-\nder, producing variants such as BLEU-1, BLEU-2,\netc. Similar to ROUGE, these variants of BLEU\nhave never been validated as metrics of translation\nquality, and their use is scientiﬁcally unmotivated.\nTokenization\nBLEU requires tokenized machine\ntranslations and references. Modern tools there-\nfore apply a tokenization procedure internally and\nimplicitly (independently of the MT system’s pre-\nprocessing). Computing BLEU with tokenization\non glosses leads to seemingly better scores but is\nmisleading since tokenization creates many trivial\nmatches. For instance, in corpora that make use\nof the character $ in glosses (e.g. the DGS Cor-\npus (Konrad et al., 2022)), $ is split off as a single\ncharacter, inﬂating the ngram sub-scores. For an\nillustration see Table 3 (and Appendix A for a com-\nplete code listing) where we demonstrate that using\nor omitting tokenization leads to a difference of 15\nBLEU.\nSpurious gains\nDifferent implementations of\nBLEU or different tokenizations lead to differences\nin BLEU bigger than what many papers describe as\nan “improvement” over previous work (Post, 2018).\nIncorrectly attributing such improvements to, for in-\nstance, changes to the model architecture amounts\nto a “failure to identify the sources of empirical\ngains” (Lipton and Steinhardt, 2019). In a similar\nvein, we observe that papers on gloss translation\ntend to copy scores from previous papers without\nknowing whether the evaluation procedures are in\nfact the same. This constitutes a general trend in\nrecent MT literature (Marie et al., 2021).\nIn summary, some previous works on gloss trans-\nlation have used 1) automatic metrics that are not\nsuitable for MT or 2) well-established MT met-\nrics in ways that are not recommended. BLEU\nwith standard settings and tools is inappropriate for\ngloss outputs.\nThe recommended way to compute BLEU on\ngloss output is to use the tool SacreBLEU (Post,\nReference\nVIEL1A FAMILIE1* JUNG1 FAMILIE1 GERN1* IN1* HAMBURG1* STADT2*\nWOHNUNG2B* FAMILIE1\nHypothesis\nVIEL1B JUNG1 LEBEN1 GERN1* HAMBURG1* STADT2* $INDEX1\nBLEU with tokenization\n25.61\nBLEU without tokenization\n10.18\nTable 3: Impact of applying or disabling internal tokenization (mtv13a) when computing BLEU on gloss outputs.\nExample taken from the Public DGS Corpus (Hanke et al., 2020).\n2018) and to disable internal tokenization. Never-\ntheless, even with these precautions, it is important\nto note that BLEU was never validated empirically\nas an evaluation metric for gloss output. Some as-\npects of BLEU may not be adequate for a sequence\nof glosses, such as its emphasis on whitespaces to\nmark the boundaries of meaningful units that are\nthe basis of the ﬁnal score.\nOther string-based metrics such as CHRF\n(Popovi´c, 2016) may be viable alternatives for gloss\nevaluation. CHRF is a character-based metric and\nits correlation with human judgement is at least as\ngood as BLEU’s (Kocmi et al., 2021).\n2.4\nFurther observations\nMore informally (beyond what we show in Table 2),\nwe observe that most papers do not process glosses\nin any corpus-speciﬁc way, that particular modeling\nand training decisions may not be ideal for low-\nresource gloss translation and that document-level\nsystems may be crucial.\nPreprocessing glosses\nGlosses are created for\nlinguistic purposes (§2.1), not necessarily with ma-\nchine translation in mind. Particular gloss parts\nare not relevant for translation and, if kept, make\nthe problem harder unnecessarily. For instance, a\ncorpus transcription and annotation scheme might\nprescribe that meaning-equivalent, minor form vari-\nants of signs2 are transcribed as different glosses.\nAn example of meaning-equivalent form variants\nin some sign languages is a ﬂat handshape with\nthe thumb adducted (aligned with the remaining\nﬁngers) or spread. Reading or producing such\nmeaning-equivalent variants may not be relevant\nfor an MT system and makes the learning problem\nharder.\nSince the particular nature of glosses is spe-\nciﬁc to every corpus, it is necessary to preprocess\nglosses in a corpus-speciﬁc way. We illustrate\ncorpus-speciﬁc gloss processing in Appendix B,\n2In spoken language linguistics, these occurrences are\ncalled allophonic variants. We refrain from using the term\nhere, as sign languages do not consist of sounds (phones).\nusing the Public DGS Corpus (Hanke et al., 2020)\nas an example.\nModeling and training decisions\nGloss transla-\ntion experiments are certainly low-resource scenar-\nios and therefore, best practices for optimizing MT\nsystems on low-resource datasets apply (Sennrich\nand Zhang, 2019). For example, dropout rates or\nlabel smoothing should be set accordingly, and the\nvocabulary of subwords of a subword model should\nbe generally small (Ding et al., 2019).\nGloss translation models are often compared to\nother approaches as baselines, it is therefore prob-\nlematic if those gloss baselines are weak and unop-\ntimized (Denkowski and Neubig, 2017).\nLimitations of sentence-level systems\nAll sur-\nveyed works propose sentence-level systems, as\nopposed to larger-context models. For sign lan-\nguage MT speciﬁcally, sentence-level approaches\nhave inherent limitations.\nSigned languages exhibit frequent referencing\n(or “indexing”) behaviour similar to anaphora in\nspoken languages. But while in spoken languages\nambiguities arising from anaphora can often be re-\nsolved with sentence-level context, that is not the\ncase for signed languages. After a subject was in-\ntroduced with a sign once it is often unacceptable\nto use the sign again in a later utterance of the\ndiscourse, instead the subject is referred to with\nan index (see e.g. Engberg-Pedersen, 1993). Be-\nsides, sign languages are generally not gendered\n(which for spoken languages helps disambiguate\nby narrowing down possible antecedents).\nDocument-level benchmarks (e.g. Bawden et al.,\n2018; Müller et al., 2018) show that for spoken\nlanguages, document-level context is not crucial\nsince sentence-level baseline systems have rela-\ntively high performance. For signed languages,\ndiscourse context may be indispensable.\nWe are not aware of any existing discourse-level\ntranslation system for sign languages but we be-\nlieve they could be investigated in the future.\n3\nRecommendations for gloss translation\nBased on our review of recent works on gloss trans-\nlation, we make the following recommendations\nfor future research:\n• Demonstrate awareness of limitations of gloss\napproaches (§2.1), and explicitly discuss them\nin the paper.\n• Focus on datasets beyond PHOENIX. Openly\ndiscuss the limited size and linguistic domain\nof PHOENIX (§2.2).\n• Use metrics that are well-established in MT.\nCompute BLEU with SacreBLEU, report met-\nric signatures and disable internal tokenization\nfor gloss outputs. Do not compare to scores\nproduced with a different or unknown evalua-\ntion procedure (§2.3).\n• Given that glossing is corpus-speciﬁc (§2.1),\nprocess glosses in a corpus-speciﬁc way, in-\nformed by the respective transcription conven-\ntions (§2.4).\n• Optimize gloss translation baselines with\nmethods shown to be effective for low-\nresource MT (§2.4).\nWe also believe publishing reproducible code\nmakes works on gloss translation more valuable.\n4\nConclusion\nIn this paper we have shown that some recent works\non gloss translation lack awareness of the inherent\nlimitations of glosses and common datasets, as well\nas a standardized evaluation method (§2). In order\nto make future research on gloss translation more\nmeaningful, we make practical recommendations\n(§3).\nWe urge researchers to spell out limitations\nof gloss translation approaches, e.g. in the now\nmandatory limitation sections of *ACL papers, and\nto strengthen their ﬁndings by implementing exist-\ning best practices in MT.\nFinally, we also caution that researchers should\nconsider whether gloss translation is worthwhile,\nand if time and effort would be better spent on basic\nlinguistic tools (such as segmentation, alignment or\ncoreference resolution), creating training corpora\nor translation methods that do not rely on glosses.\nData licensing\nThe license of the Public DGS Corpus3 (which we\nuse only as examples in Table 3 and Appendix B)\ndoes not allow any computational research except\nif express permission is given by the University of\nHamburg.\nAcknowledgements\nThis work was funded by the EU Horizon 2020\nproject EASIER (grant agreement no. 101016982)\nand the Swiss Innovation Agency (Innosuisse) ﬂag-\nship IICT (PFFS-21-47).\nWe thank the DGS Corpus team at the Univer-\nsity of Hamburg for helpful discussions on gloss\npreprocessing.\nReferences\nGalina Angelova, Eleftherios Avramidis, and Sebas-\ntian Möller. 2022.\nUsing neural machine transla-\ntion methods for sign language translation. In Pro-\nceedings of the 60th Annual Meeting of the Asso-\nciation for Computational Linguistics: Student Re-\nsearch Workshop, pages 273–284, Dublin, Ireland.\nAssociation for Computational Linguistics.\nRachel Bawden, Rico Sennrich, Alexandra Birch, and\nBarry Haddow. 2018. Evaluating discourse phenom-\nena in neural machine translation. In Proceedings of\nthe 2018 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long Pa-\npers), pages 1304–1313, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\nNecati Cihan Camgöz, Simon Hadﬁeld, Oscar Koller,\nHermann Ney, and Richard Bowden. 2018.\nNeu-\nral sign language translation.\nIn 2018 IEEE/CVF\nConference on Computer Vision and Pattern Recog-\nnition, pages 7784–7793.\nNecati Cihan Camgöz, Oscar Koller, Simon Hadﬁeld,\nand Richard Bowden. 2020a. Multi-channel trans-\nformers for multi-articulatory sign language transla-\ntion. In Computer Vision – ECCV 2020 Workshops:\nGlasgow, UK, August 23–28, 2020, Proceedings,\nPart IV, page 301–319, Berlin, Heidelberg. Springer-\nVerlag.\nNecati Cihan Camgöz, Oscar Koller, Simon Hadﬁeld,\nand Richard Bowden. 2020b. Sign language trans-\nformers: Joint end-to-end sign language recognition\nand translation. In IEEE Conference on Computer\nVision and Pattern Recognition (CVPR).\n3https://www.sign-lang.uni-hamburg.de/\nmeinedgs/ling/license_en.html\nMathieu\nDe\nCoster,\nDimitar\nShterionov,\nMieke\nVan Herreweghe, and Joni Dambre. 2022.\nMa-\nchine translation from signed to spoken languages:\nState of the art and challenges.\narXiv preprint\narXiv:2202.03086.\nMichael\nDenkowski\nand\nGraham\nNeubig.\n2017.\nStronger baselines for trustable results in neural ma-\nchine translation. In Proceedings of the First Work-\nshop on Neural Machine Translation, pages 18–27,\nVancouver. Association for Computational Linguis-\ntics.\nShuoyang Ding, Adithya Renduchintala, and Kevin\nDuh. 2019. A call for prudent choice of subword\nmerge operations in neural machine translation. In\nProceedings of Machine Translation Summit XVII:\nResearch Track, pages 204–213, Dublin, Ireland. Eu-\nropean Association for Machine Translation.\nSantiago Egea Gómez, Euan McGill, and Horacio Sag-\ngion. 2021.\nSyntax-aware transformers for neu-\nral machine translation: The case of text to sign\ngloss translation. In Proceedings of the 14th Work-\nshop on Building and Using Comparable Corpora\n(BUCC 2021), pages 18–27, Online (Virtual Mode).\nINCOMA Ltd.\nElisabeth Engberg-Pedersen. 1993. Space in Danish\nSign Language: The Semantics and Morphosyntax\nof the Use of Space in a Visual Language. SIGNUM-\nPress.\nJens Forster, Christoph Schmidt, Oscar Koller, Mar-\ntin Bellgardt, and Hermann Ney. 2014. Extensions\nof the sign language recognition and translation cor-\npus RWTH-PHOENIX-weather. In Proceedings of\nthe Ninth International Conference on Language Re-\nsources and Evaluation (LREC’14), pages 1911–\n1916, Reykjavik, Iceland. European Language Re-\nsources Association (ELRA).\nThomas Hanke, Marc Schulder, Reiner Konrad, and\nElena Jahn. 2020. Extending the Public DGS Cor-\npus in size and depth.\nIn Proceedings of the\nLREC2020 9th Workshop on the Representation and\nProcessing of Sign Languages: Sign Language Re-\nsources in the Service of the Language Commu-\nnity, Technological Challenges and Application Per-\nspectives, pages 75–82, Marseille, France. European\nLanguage Resources Association (ELRA).\nTom Kocmi, Christian Federmann, Roman Grund-\nkiewicz, Marcin Junczys-Dowmunt, Hitokazu Mat-\nsushita, and Arul Menezes. 2021. To ship or not to\nship: An extensive evaluation of automatic metrics\nfor machine translation. In Proceedings of the Sixth\nConference on Machine Translation, pages 478–494,\nOnline. Association for Computational Linguistics.\nReiner Konrad, Thomas Hanke, Gabriele Langer, Su-\nsanne König, Lutz König, Rie Nishio, and Anja Re-\ngen. 2022. Public DGS Corpus: Annotation Conven-\ntions / Öffentliches DGS-Korpus: Annotationskon-\nventionen.\nMaria Kopf, Marc Schulder, Thomas Hanke, and Sam\nBigeard. 2022. Speciﬁcation for the harmonization\nof sign language annotations.\nAnnelies Maria Jozef Kusters, Dai O’Brien, and\nMaartje De Meulder. 2017.\nInnovations in Deaf\nStudies: Critically Mapping the Field. In Annelies\nKusters, Maartje De Meulder, and Dai O’Brien, ed-\nitors, Innovations in Deaf Studies, pages 1–53. Ox-\nford University Press, United Kingdom.\nYann LeCun, Corinna Cortes, and CJ Burges. 2010.\nMnist handwritten digit database.\nATT Labs [On-\nline]. Available: http://yann.lecun.com/exdb/mnist,\n2.\nChin-Yew Lin. 2004.\nROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out, pages 74–81, Barcelona, Spain.\nAssociation for Computational Linguistics.\nZachary C. Lipton and Jacob Steinhardt. 2019. Trou-\nbling trends in machine learning scholarship: Some\nml papers suffer from ﬂaws that could mislead\nthe public and stymie future research.\nQueue,\n17(1):45–77.\nBenjamin Marie, Atsushi Fujita, and Raphael Rubino.\n2021. Scientiﬁc credibility of machine translation\nresearch: A meta-evaluation of 769 papers. In Pro-\nceedings of the 59th Annual Meeting of the Associa-\ntion for Computational Linguistics and the 11th In-\nternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers), pages 7297–\n7306, Online. Association for Computational Lin-\nguistics.\nGary Morgan and Bencie Woll. 2002.\nThe develop-\nment of complex sentences in British Sign Language.\nIn Gary Morgan and Bencie Woll, editors, Direc-\ntions in Sign Language Acquisition: Trends in Lan-\nguage Acquisition Research, pages 255–276. John\nBenjamins, Amsterdam, Netherlands.\nAmit\nMoryossef\nand\nYoav\nGoldberg.\n2021.\nSign\nLanguage\nProcessing.\nhttps:\n//sign-language-processing.github.io/.\nAmit Moryossef, Kayo Yin, Graham Neubig, and Yoav\nGoldberg. 2021.\nData augmentation for sign lan-\nguage gloss translation. In Proceedings of the 1st In-\nternational Workshop on Automatic Translation for\nSigned and Spoken Languages (AT4SSL), pages 1–\n11, Virtual. Association for Machine Translation in\nthe Americas.\nMathias Müller, Annette Rios, Elena Voita, and Rico\nSennrich. 2018. A large-scale test set for the eval-\nuation of context-aware pronoun translation in neu-\nral machine translation. In Proceedings of the Third\nConference on Machine Translation: Research Pa-\npers, pages 61–72, Brussels, Belgium. Association\nfor Computational Linguistics.\nJemina Napier and Lorraine Leeson. 2016. Sign Lan-\nguage in Action. Palgrave Macmillan, London.\nAlptekin Orbay and Lale Akarun. 2020. Neural sign\nlanguage translation by learning tokenization.\nIn\n2020 15th IEEE International Conference on Au-\ntomatic Face and Gesture Recognition (FG 2020),\npages 222–228.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation.\nIn Proceedings of\nthe 40th Annual Meeting of the Association for Com-\nputational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nElena Antinoro Pizzuto, Paolo Rossini, and Tommaso\nRusso. 2006. Representing signed languages in writ-\nten form: Questions that need to be posed.\nIn\nProceedings of the LREC2006 2nd Workshop on\nthe Representation and Processing of Sign Lan-\nguages: Lexicographic Matters and Didactic Sce-\nnarios, pages 1–6, Genoa, Italy. European Language\nResources Association (ELRA).\nMaja Popovi´c. 2016. chrF deconstructed: beta param-\neters and n-gram weights.\nIn Proceedings of the\nFirst Conference on Machine Translation: Volume\n2, Shared Task Papers, pages 499–504, Berlin, Ger-\nmany. Association for Computational Linguistics.\nMatt Post. 2018. A call for clarity in reporting BLEU\nscores. In Proceedings of the Third Conference on\nMachine Translation: Research Papers, pages 186–\n191, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nBen Saunders, Necati Cihan Camgöz, and Richard\nBowden. 2020. Progressive Transformers for End-\nto-End Sign Language Production. In Proceedings\nof the European Conference on Computer Vision\n(ECCV).\nBen Saunders, Necati Cihan Camgöz, and Richard\nBowden. 2022.\nSigning at Scale:\nLearning to\nCo-Articulate Signs for Large-Scale Photo-Realistic\nSign Language Production. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern\nRecognition (CVPR).\nRico Sennrich and Biao Zhang. 2019. Revisiting low-\nresource neural machine translation: A case study.\nIn Proceedings of the 57th Annual Meeting of the As-\nsociation for Computational Linguistics, pages 211–\n221, Florence, Italy. Association for Computational\nLinguistics.\nStephanie Stoll, Necati Cihan Camgöz, Simon Had-\nﬁeld, and Richard Bowden. 2018.\nSign language\nproduction using neural machine translation and gen-\nerative adversarial networks.\nIn Proceedings of\nthe 29th British Machine Vision Conference (BMVC\n2018). British Machine Vision Association.\nStephanie Stoll, Necati Cihan Camgöz, Simon Had-\nﬁeld, and Richard Bowden. 2020.\nText2sign: to-\nwards sign language production using neural ma-\nchine translation and generative adversarial net-\nworks.\nInternational Journal of Computer Vision,\n128(4):891–908.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is All\nyou Need. In Advances in Neural Information Pro-\ncessing Systems 30, pages 5998–6008.\nHarry Walsh, Ben Saunders, and Richard Bowden.\n2022. Changing the representation: Examining lan-\nguage representation for neural sign language pro-\nduction.\nIn Proceedings of the 7th International\nWorkshop on Sign Language Translation and Avatar\nTechnology: The Junction of the Visual and the Tex-\ntual: Challenges and Perspectives, pages 117–124,\nMarseille, France. European Language Resources\nAssociation.\nKayo Yin, Amit Moryossef, Julie Hochgesang, Yoav\nGoldberg, and Malihe Alikhani. 2021.\nIncluding\nsigned languages in natural language processing.\nIn Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the\n11th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers), pages\n7347–7360, Online. Association for Computational\nLinguistics.\nKayo Yin and Jesse Read. 2020. Better sign language\ntranslation with STMC-transformer.\nIn Proceed-\nings of the 28th International Conference on Com-\nputational Linguistics, pages 5975–5989, Barcelona,\nSpain (Online). International Committee on Compu-\ntational Linguistics.\nXuan Zhang and Kevin Duh. 2021. Approaching sign\nlanguage gloss translation as a low-resource ma-\nchine translation task. In Proceedings of the 1st In-\nternational Workshop on Automatic Translation for\nSigned and Spoken Languages (AT4SSL), pages 60–\n70, Virtual. Association for Machine Translation in\nthe Americas.\nA\nImpact of internal tokenization when computing BLEU on gloss sequences\n1\n2\n# ! pip install sacrebleu==2.2.0\n3\n4\n>>> from sacrebleu.metrics import BLEU\n5\n6\n# English translation: Many young families like living in the city of Hamburg.\n7\n# German translation: Viele junge Familien leben gerne in Hamburg in der Stadt.\n8\n9\n>>> ref = \"VIEL1A FAMILIE1* JUNG1 FAMILIE1 GERN1* IN1* HAMBURG1* STADT2* WOHNUNG2B* FAMILIE1\"\n10\n11\n>>> hyp = \"VIEL1B JUNG1 LEBEN1 GERN1* HAMBURG1* STADT2* $INDEX1\"\n12\n13\n# computing BLEU on gloss output with tokenization (not recommended):\n14\n15\n>>> bleu = BLEU() # default: BLEU(tokenize=\"13a\")\n16\n>>> bleu.corpus_score([hyp], [[ref]])\n17\nBLEU = 25.61 63.6/50.0/33.3/25.0 (BP = 0.635 ratio = 0.688 hyp_len = 11 ref_len = 16)\n18\n19\n# computing BLEU on gloss output without tokenization (recommended):\n20\n21\n>>> bleu = BLEU(tokenize=\"none\")\n22\n>>> bleu.corpus_score([hyp], [[ref]])\n23\nBLEU = 10.18 57.1/16.7/10.0/6.2 (BP = 0.651 ratio = 0.700 hyp_len = 7 ref_len = 10)\n24\nListing 1: Impact of enabling or disabling internal tokenization (mtv13a) when computing BLEU on gloss outputs.\nB\nExample for corpus-speciﬁc gloss preprocessing\nFor this example we recommend to download and process release 3.0 of the corpus. To DGS glosses\nwe suggest to apply the following modiﬁcations derived from the DGS Corpus transcription conventions\n(Konrad et al., 2022):\n• Removing entirely two speciﬁc gloss types that cannot possibly help the translation: $GEST-OFF and\n$$EXTRA-LING-MAN.\n• Removing ad-hoc deviations from citation forms, marked by *. Example: ANDERS1* →ANDERS1.\n• Removing the distinction between type glosses and subtype glosses, marked by ˆ. Example:\nWISSEN2Bˆ →WISSEN2B.\n• Collapsing phonological variations of the same type that are meaning-equivalent. Such variants are\nmarked with uppercase letter sufﬁxes. Example: WISSEN2B →WISSEN2.\n• Deliberately keep numerals ($NUM), list glosses ($LIST) and ﬁnger alphabet ($ALPHA) intact, except\nfor removing handshape variants.\nSee Table 4 for examples for this preprocessing step. Overall these simpliﬁcations should reduce the\nnumber of observed forms while not affecting the machine translation task. For other purposes such as\nlinguistic analysis our preprocessing would of course be detrimental.\nbefore\n$INDEX1 ENDE1ˆ ANDERS1* SEHEN1 MÜNCHEN1B* BEREICH1A*\nafter\n$INDEX1 ENDE1 ANDERS1 SEHEN1 MÜNCHEN1 BEREICH1\nbefore\nICH1\nETWAS-PLANEN-UND-UMSETZEN1\nSELBST1A*\nKLAPPT1*\n$GEST-OFFˆ\nBIS-JETZT1\nGEWOHNHEIT1* $GEST-OFFˆ*\nafter\nICH1 ETWAS-PLANEN-UND-UMSETZEN1 SELBST1 KLAPPT1 BIS-JETZT1 GEWOHNHEIT1\nTable 4: Examples for preprocessing of DGS glosses.\nWhile this preprocessing method provides a good baseline, it can certainly be reﬁned further. For\ninstance, the treatment of two-handed signs could be improved. If a gloss occurs simultaneously on\nboth hands, we either keep both glosses or remove one occurrence. In both cases, information about the\nsimultaneity of signs is lost during preprocessing and preserving it could potentially improve translation.\n",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "published": "2022-11-28",
  "updated": "2022-11-28"
}