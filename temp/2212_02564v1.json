{
  "id": "http://arxiv.org/abs/2212.02564v1",
  "title": "INCLUSIFY: A benchmark and a model for gender-inclusive German",
  "authors": [
    "David Pomerenke"
  ],
  "abstract": "Gender-inclusive language is important for achieving gender equality in\nlanguages with gender inflections, such as German. While stirring some\ncontroversy, it is increasingly adopted by companies and political\ninstitutions. A handful of tools have been developed to help people use\ngender-inclusive language by identifying instances of the generic masculine and\nproviding suggestions for more inclusive reformulations. In this report, we\ndefine the underlying tasks in terms of natural language processing, and\npresent a dataset and measures for benchmarking them. We also present a model\nthat implements these tasks, by combining an inclusive language database with\nan elaborate sequence of processing steps via standard pre-trained models. Our\nmodel achieves a recall of 0.89 and a precision of 0.82 in our benchmark for\nidentifying exclusive language; and one of its top five suggestions is chosen\nin real-world texts in 44% of cases. We sketch how the area could be further\nadvanced by training end-to-end models and using large language models; and we\nurge the community to include more gender-inclusive texts in their training\ndata in order to not present an obstacle to the adoption of gender-inclusive\nlanguage. Through these efforts, we hope to contribute to restoring justice in\nlanguage and, to a small extent, in reality.",
  "text": "INCLUSIFY\nA benchmark and a model\nfor gender-inclusive German\nDavid Pomerenke\nMaastricht University / Tech4Germany\ndavidpomerenke@mailbox.org\nSupervisor: Jan Niehues\nJune 5, 2022\nAbstract\nGender-inclusive language is important for achieving gender equality in languages with gender\ninﬂections, such as German. While stirring some controversy, it is increasingly adopted by companies\nand political institutions. A handful of tools have been developed to help people use gender-inclusive\nlanguage by identifying instances of the generic masculine and providing suggestions for more inclusive\nreformulations. In this report, we deﬁne the underlying tasks in terms of natural language processing,\nand present a dataset and measures for benchmarking them. We also present a model that implements\nthese tasks, by combining an inclusive language database with an elaborate sequence of processing\nsteps via standard pre-trained models. Our model achieves a recall of 0.89 and a precision of 0.82 in our\nbenchmark for identifying exclusive language; and one of its top ﬁve suggestions is chosen in real-world\ntexts in 44% of cases. We sketch how the area could be further advanced by training end-to-end models\nand using large language models; and we urge the community to include more gender-inclusive texts\nin their training data in order to not present an obstacle to the adoption of gender-inclusive language.\nThrough these efforts, we hope to contribute to restoring justice in language and, to a small extent, in\nreality.\n1\narXiv:2212.02564v1  [cs.CL]  5 Dec 2022\nContents\nPreface\n3\n1\nIntroduction\n4\n1.1\nGender and language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.2\nVariations of gender-inclusive language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.3\nBeyond gender-inclusion\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.4\nTechnology for inclusive language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2\nA new benchmark\n9\n2.1\nInclusive language as a task for NLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.2\nData acquisition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.3\nData annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.4\nA benchmark for detecting exclusive words . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.5\nA benchmark for suggesting inclusive alternatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3\nA new model\n15\n3.1\nHigh-level overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2\nInclusive language database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3\nProcessing and matching\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.4\nGrammatical assimilation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.5\nPreﬁx removal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.6\nStyle application\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4\nEvaluation\n21\n4.1\nPerformance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.2\nAblation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.3\nDiscussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n5\nFuture work\n24\n5.1\nBenchmarking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n5.2\nImproving the model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n5.3\nTraining end-to-end models\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n5.4\nPrompting large language models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n5.5\nNo red ink\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\nBibliography\n27\nA Metrics for scoring text suggestions\n29\nB Dimensions of diversity in language\n30\n2\nPreface\nThis report concludes the project \"Diversity-sensitive language\" that has been conducted in 2021 by\na team of Tech4Germany fellows in cooperation with employees of the German Federal Institute for\nMaterials Research. The employees came with the problem that they found it highly desirable, but often\ndifﬁcult, to draft texts in gender-inclusive and moreover diversity-sensitive language. During 3 months,\na team of one product manager, one product designer, and two engineers has explored the problem\nfrom a user-centric perspective and developed a prototype to solve it. One of the engineers has focused\non the frontend aspects, which were quite complex, as we have created both an add-in for Microsoft\nWord and a standalone website. The other engineer has dealt with the backend, which is mostly the\nchallenge of the processing of the text to produce some meaningful suggestions to be displayed in the\nfrontend. The result is the INCLUSIFY prototype, which has been deployed in the institute. The team\nhas created a documentation of the process of the creation of the prototype, which can be found at\nhttps://tech.4germany.org/project/diversitaetssensible-sprache-bam/. The prototype is\nnow publicly hosted under the rebrand DIVERSIFIX at https://diversifix.org.\nThis report focuses on the technical aspects behind the development of the backend, and also goes\nbeyond them by presenting a benchmark for evaluating the underlying tasks, as well as further technical\ndevelopments that are not included in the public prototype, especially the grammatical adjustment.\nWhile the design choices for the model are justiﬁed at the beginning of section 3, in retrospect the\napproach appears over-engineered and further improvements are complicated to integrate. Therefore we\nat least give an outlook on alternative approaches in section 5, and we hope that the presented benchmark\nwill also be helpful for the further pursuit of these alternatives.\nThe code accompanying this report is published at https://gitlab.com/davidpomerenke/gender-\ninclusive-german. Parts of the data are also published at https://huggingface.co/diversifix.\n3\n1\nIntroduction\n1.1\nGender and language\nMuch of our perception, thought, and expression happens by the means of language, thus it seems\nnatural that the structure of the language has a profound impact on our lives. Language is shared in a\nsocial community, and so the structures of the community – including forms of discrimination, such as\ngender discrimination – may be interrelated with the structure of the shared language.1\nFigure 1: Relations between different terms from biology, sociology and linguistics. Biological sex is loosely correlated\nwith social gender, but does not determine it. Social gender determines the gender inﬂection, for example a\nfemale teacher is referred to as \"Lehrerin\". Gender inﬂection in turn determines grammatical gender; \"Lehrerin\"\nis grammatically female, as seen when used with an article: \"die Lehrerin\". For words that do not have a gender\ninﬂection, the grammatical gender is more or less arbitrary in German.\nMany languages feature the concept of grammatical gender, and usually grammatical gender is\nsomehow related to the social gender of persons. In German there are three grammatical genders:\nfeminine, masculine, neuter. The grammatical gender of nouns in general is almost completely arbitrary,\nand language learners have to do lots of rote learning. Only for nouns which refer to persons there is some\nregularity: For most of these nouns, there are two gender inﬂections, a female one and a male one. For all\nwords with a gender inﬂection, the grammatical gender is identical to the assumed social gender. While\nthe diverse gender is ofﬁcially recognized in the German-speaking countries, it is not clearly associated\nwith any of the grammatical genders and does not have its own gender inﬂection.\nTraditional grammar textbooks (German and otherwise) deﬁne the principle of the generic masculine:\nWhenever the social gender is not established, or when a group consists of individuals of various genders,\nthe masculine gender may be used. This has the beneﬁt that phrases such as \"der Lehrer oder die\nLehrerin\" / \"die Lehrerinnen und Lehrer\", can be shortened to \"der Lehrer\" / \"die Lehrer\". As a corollary\nof the generic masculine, the usage of male gender inﬂections is always ambiguous and whether the\ngender of a person or group is (purely) male, mixed, or unknown, can only be established by context, if\nat all. A body of psycholinguistic experiments demonstrates that language users tend to think of male\npersons when the generic masculine is used, as opposed to when both male and female inﬂections are\nused (for an overview, see [1, ch. 2.2]).\nWith the availability of these results and an increased urge for gender equality, it becomes desirable\nto dispose of the principle of the generic masculine. In this vein, German-speaking feminism has\ntraditionally demanded that in place of the generic masculine both the male and female inﬂections\nshould be used.\n(Alternative approaches exist as well: The concept of gender inﬂection could be abolished, thus\ncompletely separating grammatical from social gender. This could be implemented, e. g., by abolishing\nthose gender inﬂections which are derived – in practice, these would overwelmingly be the female\ninﬂections. This approach is pursued in many English-speaking communities and has been practiced\n1Cf. the Sapir-Whorf hypothesis.\n4\nto some extent in the GDR [2]. The position is also present in the current German debate 2. Less\npopular approaches are the (temporary) introduction of a generic feminine, which would suffer from\nthe same problems as the generic masculine but discriminate against a currently privileged group; or\nthe introduction of a speciﬁc masculine, a technically sound solution, which has only been proposed\nsatirically [3].)\nIn this report, we will use the term gender-inclusive language, or brief, inclusive language, to refer to\nlanguage that represents female, male, and (only sometimes) diverse persons in an equal manner, be it by\nusing both gender inﬂections or by avoiding nouns with gender inﬂections. Common alternative terms\nare gender-neutral language, gender-sensitive language, or gender-equitable language. We use the term\n[gender-]exclusive language to refer to language that uses the generic masculine.\n1.2\nVariations of gender-inclusive language\nFigure 2: Hierarchy of different possibilities to form inclusive alternatives to a gender-exclusive term. The categories\nare partially inspired by [1, ch. 2.4].\nThere are many options for transforming an exclusive phrase into an inclusive phrase; see Figure 2.\nThe most straightforward way is to use pair notation, that is, mentioning both the female and the male\ninﬂection. The conjunction between the two depends on the semantical context: For plural nouns, \"und\"\n(\"and\") is appropriate in afﬁrmative contexts (\"Die Schülerinnen und Schüler kommen (nicht) zu spät.\")\nwhile \"oder\" (\"or\") is appropriate in negative contexts (\"Keine Schülerinnen oder Schüler kommen zu\nspät.\"). For singular nouns, the opposite is the case (\"Die Schülerin oder der Schüler kommt zu spät.\",\n\"Keine Schülerin und kein Schüler kommen zu spät.\"). Instead of \"oder\", \"bzw.\" may be used.\nSometimes, a generic plural word has to be resolved into gender inﬂections in singular: \"Die Bären\"\n(multiple bears) may be resolved to \"die Bärinnen und Bären\" (multiple female bears and multiple\nmale bears), \"die Bärinnen und der Bär\" (multiple females, one male), \"die Bären und die Bärin\" (one\nfemale, multiple males) or \"die Bärin und der Bär\" (one female, one male). The necessary information\n2https://www.youtube.com/watch?v=aZaBzeVbLnQ\n5\nFigure 3: Evolution of the prevalence of the various styles of gender-inclusive language in the head_0 part of the\nGerman Colossal Clean Crawled Corpus (cf . subsection 2.2). The colon : style is not found within the corpus. The\nneutral word style has been detected by counting the occurrence of 111 selected words of which we believe that they\nwould only occur in the context of gender-inclusive language (see subsection 2.2 for details); the real share of the\nneutral word style can thus be assumed to be larger. In October 2016, there is an unexplained anomaly with regard to\nthe hyphened slash /- style (e. g., \"Schüler/-innen\").\nfor choosing between these options may not be present in the context; but in the majority of cases, the\nmultiple-females-multiple-males option is the correct one.\nSince the pair notation is rather lenghty, merged abbreviations are often used. In the merged abbrevi-\nations, the female and male words are merged into a single word. This is often easy because the female\ninﬂections are derived from the male inﬂections and do contain them. Various special characters as\nwell as the internal I are used to distinguish the merged word (e. g., \"SchülerInnen\") from the female\ninﬂection (\"Schülerinnen\"). These gender characters are pronounced as a glottal stop, similar to the small\npause between the parts of a compound word. The gender characters – especially the gender gap _ and\nthe gender star * – serve as a reminder for the presence of the diverse gender. Other popular gender\ncharacters are the colon :, and the slash / or the hyphened slash /-.\nAs a potential grammatical criterion for the mergeability of two inﬂections, the omission trial has\nbeen proposed: From \"Kanzler:in\", both the female \"Kanzlerin\" and the male \"Kanzler\" can be derived\nby omitting letters. But from \"Beamt*in\", only the female \"Beamtin\" can be derived, and not the male\n\"Beamter\"; and \"Ärzt_in\" includes the female \"Ärztin\" but not the male \"Arzt\". But the rule is not\nuniversally acknowledged, and \"Beamt*in\" and \"Ärzt_in\" are often found.\nThe merging of female and male words may be complicated by inﬂecting their syntactic dependencies\nand coreferences: One could try to transform \"Wir suchen einen talentierten Professor, der Meister seines\nFaches ist.\" into the inclusive sentence \"Wir suchen eine*n talentierte*n Professor*in, der/die Meister*in\nseines/ihres Faches ist.\" – such sentences can be found occasionally, but are hardly legible. In such a\ncase, the pair notation is more appropriate: \"Wir suchen eine talentierte Professorin, die Meisterin ihres\nFaches ist, bzw. einen Professor, der Meister seines Faches ist.\"\nSince the deﬁnite article is identical for female and male inﬂections in the plural and the indeﬁnite\narticle is omitted in the plural, plural nouns are generally more likely to be suitable for merging than\nsingular nouns.\nThe choice of which of the gender characters and the internal I is to be used, and whether these\nabbreviations are to be used at all, is subject to controversy. Companies as well as governmental agencies\noften have style guides where a certain style is enforced for ofﬁcial writing. For example, as of 2021 the\nFederal Institute for Materials Science recommends the gender star, the Federal Ministry of Family Affairs,\nSenior Citizens, Women and Youth recommends not to use any special characters and the Bavarian State\nMinistry for Digital Matters uses the dot as a gender character. Figure 3 demonstrates the usage of the\nvarious styles on the German-speaking internet.\n6\n1.3\nBeyond gender-inclusion\nGender-inclusive language as we have deﬁned it in subsection 1.1 is only one aspect of a more broadly\nconceived gender-equitable language. [4] and [5] propose hierarchies of gender bias, where our gender-\ninclusive language corresponds to the subcategory explicit marking of sex, which is once found in the\ncategory structural bias [4], and once in the category exclusionary bias [5].\nOne other category of gender bias is gender bias in job advertisements. We mention this category\nbecause it has not only found extensive treatment in both English and German research communities3,\nbut has also led to the development of technological solutions,4 similar to the tasks discussed in this\nreport.\nDiversity-sensitive language or inclusive language (in a more general sense than in this report) views\ngender as just one dimension of diversity, among many. The nonproﬁt Charta der Vielfalt characterizes\nthe seven core diversity dimensions age, ethnic origin and nationality, sex and gender identity, physical\nand mental abilities, religion and worldview, sexual orientation, and social background.5 Language\nguidelines demonstrate how all of these dimensions are relevant for language [6, 7], and Appendix B gives\nan exemplary overview. In this report we follow the mainstream in focusing merely on the dimension of\ngender. Research and action in the other dimensions is similarly important and probably yields higher\nmarginal beneﬁts.\n1.4\nTechnology for inclusive language\nTo our knowledge there is no published research in the area of technological solutions to gender-inclusive\nlanguage in our sense; but there are a variety of existing software tools.\nIn the previous section we have mentioned tools for diversity-sensitive English and for addressing\ngender bias in job advertisements in English and German. In this section, we give an overview over the\ntechnology for gender-inclusive German (see Figure 4):\nScribbr provides a commercial \"gender check\"6 for PDF documents. The user uploads a PDF and\nenters a view where exclusive words – as well as incorrect inclusive words – are highlighted within the PDF.\nClicking on a highlight reveals an explanation, such as the omission trial mentioned above, and several\nsuggestions for inclusive alternatives. By selecting a \"gender style\", the user can choose among multiple\nsets of suggestions. The suggestions are given in singular and plural. Since PDFs are mostly static, there is\nno way of applying the suggestions, this has to be done manually. Thus, the process resembles that one\nof a student handing in an assignment and a teacher grading it with feedback.\nGender app7 provides a commercial add-in for Microsoft Word, which is free for personal use. Word\nadd-ins reside in a side-panel with limited interaction with the document. Exclusive words are therefore\nnot highlighted but listed in the side panel, along with inclusive suggestions. There is a setting for\nswitching the \"gender style\". On clicking on a suggestion, the word is highlighted in the document and\nreplaced by the suggestion. Since the grammar is not adapted at the same time, a prompt reminds the\nuser to check for necessary adjustments themselves. Gender app also offers a website check and an\nexperimental \"translation\" tool. In the translation tool, exclusive texts are transformed into grammatically\n3See\nhttps://www.msl.mgt.tum.de/rm/third-party-funded-projects/projekt-fuehrmint/gender-decoder/\nliteratur/ for a literature list.\n4For German: https://genderdecoder.wi.tum.de/. For English: http://gender-decoder.katmatfield.com/, https:\n//github.com/gender-bias/gender-bias, https://github.com/slowe/genderbias.\n5https://www.charta-der-vielfalt.de/\n6https://www.scribbr.de/gendern/genderpruefung/\n7https://genderapp.org/\n7\nFigure 4: Screenshots of tools for gender-inclusive German.\ncorrect inclusive texts without any user interaction. On the gender app website, users can look up, suggest,\nand vote on pairs of exclusive and inclusive phrases.\nFairlanguage has developed a prototypical browser extension8, where exclusive words in HTML forms\nare highlighted. Clicking on them reveals inclusive suggestions, usually in abbreviated pair notation. By\nselecting one of them, they are replaced in the text, without adjustment of the grammar.\nGenderly9 is a project in progress to apply supervised machine learning on a manually annotated\ncorpus of real-world texts to the problem of gender-inclusive language. By this approach, the team hopes\nto adequately capture and replicate the style of people who use inclusive language, rather than giving\nrigid rule-based advice. At the time of writing, their prototypical webapp can highlight exclusive words in\na given text. Notably, it can often differentiate between cases where the masculine is speciﬁc and therefore\nnot highlighted, and cases where it is generic and therefore highlighted. The model is expected to be\nopen-sourced later in 2022.\nThere is also a browser extension for \"correcting gendered language\"10 for those who are tired of\ninclusive language. It aims to replace inclusive words with more concise and legible words in the generic\nmasculine by applying heuristic rules.\nFor English, an outstanding software library for diversity-sensitive language across all dimensions is\nretext-equality. 11 12 Thanks to the simplicity of inﬂecting nouns in English, the tool pursues a purely\nlist-based approach, where the input text is checked against a ﬁxed lists of words in both singular and\nplural. Another available tool for English is the browser extension gender-neutralize13, which replaces\nstatic text on websites.\n8https://chrome.google.com/webstore/detail/fairlanguage-prototype/epmpidfdcpaeijfpkapmidinbbogleaa\n9https://gendern.jetzt/\n10https://github.com/brilliance-richter-huh/gendersprache-korrigieren\n11https://github.com/retextjs/retext-equality\n12With respect to English, the term gendered language is negatively connoted from the angle of gender equality (e. g., in [8]). With\nrespect to German, it is positively connoted because it refers to language where two or three genders are included, as opposed to\nthe commonly used generic masculine.\n13https://github.com/amity/gender-neutralize\n8\n2\nA new benchmark\nFor evaluating the usefulness of our system, as well as of other systems, we design a general benchmark\nfor tasks related to gender-inclusive language in German. To our knowledge, this is the ﬁrst benchmark\nfor this domain.\n2.1\nInclusive language as a task for NLP\nAfter studying the existing systems and our own system for inclusive language, we have come to the\ndistinction between two different tasks. Either task may be provided separately, or they may be combined\n(as is the case of our system).\n• The task of ﬂagging exclusive words, in order to inform the user that these should be replaced. This\nis a sequence labeling task: Each word of the input text is ﬂagged as either acceptable or as exclusive.\nThe exclusive words are then usually highlighted, and the user must think of good alternatives on\ntheir own.\n• The task of giving good suggestions for inclusive alternatives. There are multiple levels of difﬁ-\nculty for this task. At an easy level, we can view it as a dictionary lookup, where one exclusive word\nyields one or multiple inclusive words. At a more difﬁcult and more useful level, we can view it as\na sequence-to-sequence task: An input text in exclusive language is translated to an output text in\ninclusive language. This goes beyond word replacement in that the replaced words have to be ﬁtted\ngrammatically, and that other words in the sentence may need to be adjusted.\n2.2\nData acquisition\nOur benchmark should consist of data which represents a realistic use case and which is unbiased. If we\ncreated the data by hand, used the data underlying our system, or even used our system to synthesize the\ndata, bias would be inevitable. It is unlikely that there exist any parallel texts in the wild where there is\nboth a version with exclusive words and a version with inclusive words.14 A potential source of parallel\ntexts that are synthetic but of very high quality are examples from publications on inclusive language.\nFor example, [1] includes many parallel examples, but is subject to copyright. We therefore pursue the\napproach of collecting texts that are formulated in inclusive language, and creating parallel versions of\nthese texts ourselves. Thereby, the input texts may be slightly biased, but the more important target texts\nare completely realistic.\nGC415, the German equivalent to the English Colossal Clean Crawled Corpus, has an appropriate\ncontent and license for our purposes. It contains more than 1 TB of crawled German websites from\n2015 to 2020. Internet texts fulﬁl our criterion of being a realistic use case, and the size of the corpus\nensures that we ﬁnd enough inclusive texts. The corpus comes in a head part of \"high quality texts (e. g.,\nnewspapers and government websites)\", and a middle part of \"more colloquial language\", according to\nthe corpus description. Since the main use case for inclusive language technology is indeed governments,\nnewspapers, and similar cultural institutions, we select the head; and among the seven parts of the head\ndata, we focus on the ﬁrst one, which already contains more than enough data.\nInside the corpus, we want to identify inclusive texts of any style. Detecting the use of gender\ncharacters and of pair notation is straightforward by using elaborate regexes and, in the case of pair\n14This is in contrast to simple language, where Wikipedia and some other websites do provide more or less parallel texts.\n15https://german-nlp-group.github.io/projects/gc4-corpus.html\n9\nnotation, some additional handcoded heuristic.16 Detecting the neutral style is harder, since there is no\nunique rule for identifying these words.\nOne class of words that is used in the neutral style is the class of participles in the present active,\nusually ending with \"-ende(n)\". Some of these words (\"Vorsitzende\", ...) are also very common beyond\ntheir use for gender-inclusive purposes; therefore ﬁltering just by the mentioned postﬁx is not a robust\noption. But other words from this class (\"Studierende\", ...) have an obvious noun (\"Studenten\", ...) that\nis almost always used when inclusive language is not speciﬁcally desired; therefore these participles\ndo only very rarely occur outside inclusive texts. We collect a list of all present-active participles sorted\nby frequency from a part of the corpus and manually remove words, such that we keep a list of 111\nwords of which we believe that they would only occur in decidedly inclusive texts.17 There are only two\ngender-inclusive variations of these words (\"-ende\" and \"-enden\"), so it is easy to pattern match on this\nword list. Now that we have a criterion for the neutral style as well, we deﬁne that any text from the corpus\nis an inclusive text iff it includes at least two words of any given style (neutral, pair notation, gender\nsymbol, internal I). According to this deﬁnition, we extract all inclusive texts from the corpus and sort\nthem by their total number of inclusive word matches.\n2.3\nData annotation\nFigure 5: Screenshot of the minimal annotation interface. The annotator has conﬁrmed the sentence, and can now\nedit a copy of the sentence where inclusive words should be turned into exclusive words. Preliminary edits and labels\nhave been added automatically. In this case, the automatic edit and label for the second match are not fully correct,\nand the annotator needs to change them.\nOur assumption is that texts of all styles of inclusive language do also include words in the neutral style,\nsince this style is congruent with the other styles and is often deemed the most elegant choice. Moreover,\nfor many words there may not exist inclusive alternatives in the neutral styles, but there are almost always\nalternatives in the other styles; so it is likely that even an author who decidedly prefers the neutral style\nwill have to sidestep to one of the other style now and then. If however there are large amounts of text\nthat are written exclusively in the neutral style, then they may not be represented proportionally in our\nbenchmark data.\nFor the purpose of annotation, we create a minimalistic HTML/JavaScript interface, into which we\nload the inclusive samples. The annotator has three options for each sentence:\n• Discarding the sentence. For example, because it is not a sentence; or because it includes exclu-\nsive language (remember, these sentences are our target sentences and should include inclusive\nlanguage); or because grammatical errors affect the inclusive words.\n• Keeping the sentence. For sentences that do not have inclusive words. This will add the sentence to\nthe benchmark data set, both as an input sentence and as a target sentence, and with no labels.\n• Creating an exclusive version and corresponding labels. For sentences that have words which,\nby subjective judgment, could be regarded as inclusive words of any style. This will copy the\n16See data/benchmark/matches.py of our code.\n17See data/gc4/neutral-words.txt in our code.\n10\nsentence to an input ﬁeld where it can be edited. There, the annotator will replace inclusive\nwords with exclusive words; in so far as suitable exclusive words to replace the inclusive words\ndo unambiguously exist. The annotator will also adapt the grammar as necessary such that the\nexclusive sentence is grammatically coherent. Lastly, they will also ﬂag the exclusive words. In clear\ncases such as gender characters, the annotator is assisted by automatic suggestions. Their edited\nsentence will be added to the benchmark data as an input sentence, and the original inclusive\nsentence will be added as a corresponding target sentence, and the ﬂagged words will be added as\nlabels to the input sentence.\nUsing this interface, we process randomly sampled sentences (1 per document, to avoid bias and\ncopyright issues) from the 900 most dense documents, resulting in 400 annotated sentences. We only\nhave a single annotator – us –, but we believe that this is an acceptable limitation, because the reverse\nnature of the annotation process reduces the controversy of the annotation decisions.\n2.4\nA benchmark for detecting exclusive words\nInputs with\nlabels\nTargets\nMachen Sie bei uns Ihre Ausbildung\nzum\nFleischereifachverkäufer\noder\nFleischer .\nMachen Sie bei uns Ihre Ausbildung\nzum/zur Fleischereifachverkäufer*in oder\nFleischer*in.\nFür\ndie\nUnterstützung\nder\nQualität-\nskontrolle\nvon\nBatterien\nund\nPro-\nduktionsprozessen suchen wir einen\nQualitätsfachmann\nFür die Unterstützung der Qualitätskon-\ntrolle von Batterien und Produktion-\nsprozessen suchen wir eine/n Qualitäts-\nfachmann/frau\nDieser Text wurde automatisch generiert\nund stammt nicht vom Unternehmen\nselbst.\nDieser Text wurde automatisch generiert\nund stammt nicht vom Unternehmen\nselbst.\nBericht der\nRechnungsprüfer\nBericht der Rechnungsprüfer*innen\nUnsere\ngroße\nShowtanzgruppe\nfür\nTänzer\nab 16 Jahre\nUnsere große Showtanzgruppe für Tänzer\nund Tänzerinnen ab 16 Jahre\nFigure 6: Example items from the benchmark. The labels on the left are for the ﬁrst task: the detection of inclusive\nwords. The target sentences on the right side are for the second task: the suggestion of inclusive alternatives.\nEvaluating the detection of exclusive words is straightforward: For each word of each sentence, one\ncan compare the label which one’s system assigns with the label which the benchmark assigns, and\ncalculate recall, precision, and F1 score. Calculating the accuracy is not a good idea because only a very\nsmall share of overall words is labeled as exclusive.\nThe benchmark also includes input sentences without any inclusive words to the proportion with\nwhich they occur in the most densely inclusive texts. The calculated measures therefore give a realistic\nimpression of the performance of the system on real-world texts.\nBecause of the sorting, the benchmark data may be biased towards texts with lots of potential for\ninclusive language (for example, texts with lots of generic personal descriptions, such as job advertise-\nments); but this kind of texts is also the most urgent and most likely application domain for an inclusive\nlanguage system.\n11\n2.5\nA benchmark for suggesting inclusive alternatives\nWe have framed the task of giving good suggestions for inclusive alternatives to sentences with exclusive\nwords as a sequence-to-sequence task above. As a such it is similar to (among other tasks) machine\ntranslation, and indeed we could say that the task is a \"translation\" from exclusive to inclusive language\n(or a style transfer from an exclusive style to an inclusive style). Machine translation is often evaluated\nusing the BLEU algorithm based on n-gram overlaps. We believe that BLEU is not a suitable evaluation\nmethod for our task: Unlike in a real translation scenario, most words in the sentence stay the same, and\nwhile grammatical adjustments do matter, the correct \"translation\" of the exclusive word matters much\nmore than any correct grammatical adjustment. Moreover, we notice two key differences for our task as\nopposed to machine translation:\n1. The number of acceptable potential target sentences for a given input sentence is small. There\nis a choice between a small ﬁxed number of styles (cf. subsection 1.2), and for the neutral style there\nmay be a handful of suitable alternative words that could be chosen. Once replacement words are\nchosen, there is often just one way of correctly adjusting the grammar of the other words. In some\ncases, a major change of the structure of the sentence, such as putting it into passive voice, can be\nan elegant solution; but such solutions are hardly in the benchmark data due to the conservative\nannotation procedure.\nWhile in translation there may be hundreds or many more correct translations for a given input\nsentence, there are typically something like ﬁve and rarely more than 20 correct inclusive versions\nof an exclusive sentence. (This assumes that the sentence contains just one exclusive word. We will\ndiscuss other cases later.)\n2. Systems often display multiple suggestions and let the user choose. Machine translation systems\nlike Google Translate or DeepL, which are targeted towards consumers, take an input text and auto-\nmatically produce a complete output text. That is not the case for inclusive language technology.\nGender App, Fairlanguage and Scribbr style themselves not as translation systems but as grammar\ncorrection systems,18 and all of them offer multiple inclusive suggestions for each exclusive word.\nAnd they have a good reason for this: Inclusive language is like correct grammar. – It is desirable\nthat the user sees their mistakes, sees accompanying explanations, and sees how they can do better\nin the future. The primary goal is the education of the user (and the assistance given to them), not\nthe transformation of the text.19 Showing multiple replacement options to the user supports this\neducative goal.\nIn summary of these two points, inclusive language systems are often expected to produce a small\nnumber n of options, and there often only exists a similarly small number m of acceptable inclusive\nversions for any original, exclusive sentence.\nTaking these together, we postulate that the ideal system should be able to produce all m possible\ninclusive sentences. As a consequence, we can require that it must also produce the one speciﬁc inclusive\nsentence which is given as a target in our benchmark data.\nThe situation is analogous for spelling and grammar correction. For example, [9] specify: \"Given that\nour user is probably able to detect the correct suggestion among a small set of suggestions, we count as a\n18Gender App does have a translation tool, but has not included it into their main application.\n19During our project with the federal administration, some interviewees did indeed desire an end-to-end text transformation tool.\nOther interviewees, and in the end our team, preferred a more educative tool.\n12\ncorrect suggestion the case when the correct one is present among the set of suggestions (in case there\nare several), but not necessarily in the ﬁrst position.\"\nA system could trivially fulﬁl this requirement by producing an inﬁnity of sentences; or it would at\nleast have a good chance of fulﬁlling it by producing an unrealistically high amount of suggestions, of\nwhich only one would need to be correct. To approach this issue, we postulate that the system should\ngenerate a ranked list of suggestions for target sentences. The higher the system ranks the target sentence\nthat is given in our benchmark, the better should be its score. If the actual target sentence is not in the list\nat all, the score should be 0. If the actual target sentence is the ﬁrst sentence in the list, the score should\nbe 1.\n[10], in the context of spell checkers, propose three increasingly hard levels of evaluation for the task\nof spelling correction: First, \"how often is the correct CC [correction candidate] among the set of CCs?\"\nThis is identical to the suggestion by [9] mentioned above. Second, \"how often is the correct CC among\nthe n-best ranked CCs?\" Third, \"how often is the correct CC among the ﬁrst-best ranked CCs?\"\nWe consider these three levels to be useful metrics for reporting also for the task of suggesting\ninclusive alternatives. But they are not strictly sensitive to improvements of the ranking (a) within the\nbest n ranks and (b) beyond the best n ranks. Such sensitivity is useful, especially when monitoring small\nimprovements of a single system over time. Therefore, we propose that additional metrics should be\nconsidered which fulﬁl at least one of (a) or (b).\nWe discuss three such metrics in Appendix A. There we conclude that the logistic function s(r) =\n1 −\n1\n(1+e−r )100 (visualized in Figure 14) is especially suitable for assigning a score s(r) to a given rank r\n(with adjustments if the score is calculated for a suggestion that includes multiple locations of inclusive\nalternatives). We call this metric the suggestion score.\nAn interesting question for the formalization of the benchmark task is what role the different styles of\ninclusive language should play. Should the system be able to ﬁgure out the appropriate style on its own?\nProbably not, because it can hardly more than guess whether to use, for example, a star or an underscore\nas a gender symbol. Should the system then be given the exact information about which style to use as\npart of the input? This is a better solution, but, as we believe, still too simple.\nFigure 2 has coloured circles that indicate which styles are determined by the choice of the user, and\nwhich ones may be used next to each other. We try to capture this with the following formalization, which\nwe believe not to be perfect but to in a good balance between simplicity and accurateness: As part of\nthe benchmark task, the tested system is given the information whether the author makes any use of\nthe abbreviated pair notation style. This is determined by the occurrence or non-occurrence of gender\ncharacters (including the internal I) in the document from which the input sentence is sampled. The\nrationale behind this is that the neutral style and the pair notation style may always be used, but whether\na symbol-based style is used is a strictly applicable decision by the author. The different abbreviated pair\nnotation styles are taken care of by normalizing the target sentences such that all gender characters are\nconverted to a single consistent character (we have chosen the gender star).\nThe scores for the individual examples are then aggregated by using the mean, since we do not see a\nspecial reason to use another aggregation method.\nIn summary, the suggestion task is evaluated by calculating the three measures proposed by [10] and\nmentioned above, and either of the three continuous functions proposed above. The former measures\nare especially interpretable, and the latter measures are especially suitable for monitoring the progress\nwithin a single project.\n13\nEntries\n400\nEntry schema\n– Exclusive sentence string\n– Exclusive phrases list of strings\n– Inclusive sentence string\n– Gender characters allowed boolean\n– Metadata: URL, crawl date, GC4 ID\nEntries with gender characters allowed\n272\nEntries with gender characters used\n119\nExclusive phrases\n305\nExclusive phrases per entry\nµ = 0.76,σ = 0.60\nEntries by # exclusive phrases\n0 exclusive phrases\n169\n1 exclusive phrase\n166\n2 exclusive phrases\n57\n3 exclusive phrases\n7\n4 exclusive phrases\n1\nInclusive phrases by style\nFull pair notation\n97\nAbbreviated pair notation\n133\nNeutral (participles)\n35\nNeutral (other)\n40\nData source\nGC4 (web crawl) + annotation\nCrawl date\n2017-2020\nToxic/offensive language\nno\nFormat\nJSON\nLicense\nCC0 1.0\nFigure 7: Benchmark data summary. The ﬁeld Gender characters allowed speciﬁes whether any gender characters\nare used within the whole text from which the inclusive sentence was sampled. Gender characters used speciﬁes\nwhether the inclusive sentence actually makes use of such characters. GC4 served as the basis of the data and can be\nfound at https://german-nlp-group.github.io/projects/gc4-corpus.html.\n14\n3\nA new model\nWe see two viable approaches to the inclusive language tasks described in the previous section: First, a\nknowledge-based approach involving a database of exclusive and inclusive language, and second, the\ntraining of an end-to-end model. Here, we present a model for the knowledge-based approach. Ideas for\nfuture work relating to the end-to-end approach are discussed in subsection 5.3.\nThis approach has the beneﬁts of reliability, explainability and ﬂexibility. It is reliable because it\nonly ever displays suggestions from the knowledge base, at worst with grammatical errors, but never\nwith inappropriate suggestions. It is explainable because every suggestion can be traced back to a rule\nin the knowledge base. Moreover, the rules can be annotated with explanations that are shown to the\nuser, serving the educative purpose of the software. Flexibility enables the user, the administrator, or the\ncommunity to edit and extend the rule set. This is important because inclusive language is in constant\nﬂux, and because the intention is not only to replicate the style of already existing inclusive texts, but also\nto introduce new ideas and revise old ones.\n3.1\nHigh-level overview\nFigure 8: The model.\n15\nFigure 8 gives a graphical overview over the relatively complicated model.\nThere are two inputs: An input text, which may be a longer text containing many sentences; and\nstylistic preferences, where there is a choice between the neutral style (using only words without gender\ninﬂection), pair notation, and abbreviated pair notation with either the internal I or any custom character\n(such as the star * or the gap _).\nThe output is a list of suggestion items. Each suggestion item contains the exclusive phrase that\nshould be highlighted and its start and end position within the text, and a list of alternative formulations.\nIn the alternative formulations, the whole sentence is given, with the exclusive phrase replaced by an\ninclusive phrase, and all other words grammatically adjusted.\nThe core of the model is an inclusive language database. It contains exclusive phrases in dictionary\nform, associated with corresponding inclusive phrases, and with suitable explanation texts (the expla-\nnation texts are not implemented). The exclusive phrases are then preprocessed by tokenization and\nlemmatization to allow for easy matching.\nAn incoming text is ﬁrst stripped off the special characters that are used for abbreviated pair notation,\nto aid later steps in the pipeline. The characters are remembered and added back at the end of the\npipeline. The text is then segmented into sentences and cached: Sentences that have been processed\nbefore are not processed again; this matters because the model has to be re-run every time that the input\ntext changes.\nEach sentence is tokenized, lemmatized, and its dependencies are parsed. Then, it is established\nwhether the lemmas and their structure match any of the exclusive phrases from the database. If this is the\ncase, the grammar of the inclusive phrase is adapted to the grammar of the sentence, and the grammar\nof the sentence is adapted to the grammar of the inclusive phrase, by using morphological analysis\nand inﬂection. Compound words are integrated into this process by ﬁrst removing and remembering\npreﬁxes, and adding them back later. Lastly, the inclusive phrase is integrated into the sentence minus\nthe exclusive phrase, and eventual explanations are drawn from the database.\n3.2\nInclusive language database\nThe database can be queried for an exclusive phrase, and returns a set of pairs of inclusive alternatives\nand explanations.\nWe keep the inner structure of the database very simple; but there is potential for more complex\nschemas that account for synsets and categories of explanations. In our implementation we neglect\nthe aspect of explanations and always deliver the same explanation about the generic masculine. We\nuse denormalized CSV tables where each row contains one exclusive phrase and one inclusive phrase.\nThe tables are sorted by the ﬁrst column, so all the entries for a particular exclusive phrase are grouped\ntogether. In a standard entry, a masculine phrase is associated with a neutral phrase. For pair notation,\nwe only store the female inﬂection, since the male inﬂection is already given qua the exclusive phrase;\nwe use an additional column to mark these rows where only the female inﬂection is given. We do not\nstore phrases in abbreviated pair notation, but derive it from the pair notation. Another column is used\nto mark entries that are only applicable when the inclusive phrase is in the plural, such as \"Kollegium\"\n[the collective of the colleagues] as a replacement for \"Lehrer\" (\"teachers\").\n16\nFor ﬁlling our database with data, we rely on two datasets, which we process in the following ways:20.\n1. Geschickt gendern - das Genderwörterbuch21 provides a list with pairs of exclusive words and\ninclusive alternatives. The list is regularly updated. The inclusive alternatives are all gender-neutral.\nThe data is not machine-readable. We have transformed the data into a machine-readable format\nand simpliﬁed it, especially by removing redundant singular/plural data: For example, where there\nis a singular entry \"arbeitgebende Organisation\" and a plural entry \"Arbeitgebende\", we only keep\nthe singular. During the inﬂection of the inclusive phrase, we remove the words \"Personen\" and\n\"Organisationen\" if they are preceded by a participle, and nominalize the participle by capitalizing\nit. This allows us to remove the vast majority of plural entries, leaving ∼3500 entries, including\n∼3000 noun phrases.\n2. Deutsches Referenzkorpus (DeReKo)22 is the largest traditional corpus for German, mostly in-\ncluding newspaper articles. The texts themselves are protected by copyright, but mining them is\nallowed. We have searched for words that include any of the special characters that are commonly\nused for the abbreviated pair notation. Splitting the words at the position of the symbol gives the\nmale and female inﬂections of the word in many cases; in some cases, manual adjustments have to\nbe made. We have manually ﬁltered and corrected the list, leaving us with ∼3800 words with both\nmale and female inﬂection.\nWe have further identiﬁed the following relevant datasets, but have not integrated them into our\ndatabase:\n3. The Gendering word catalog Vienna23 provides ∼2300 pairs of exclusive and inclusive words\nfrom a government context. There are some erroneous entries, and the schema is not completely\nconsistent. Most of the inclusive alternatives are in double notation or in the internal-I style. Since\nwe have another source for these (see below), we have abstained from integrating this source.\n4. OpenThesaurus24 is a database of synsets and the hierarchy among them. We have extracted\n∼3500 nouns of the male grammatical gender which are (recursively) subordinate to the synsets of\n\"Person\", \"Mensch\", \"Beruf\". Our hope was to ﬁnd useful gender-neutral alternatives in the synsets\nof these words. This was only the case for a minority of words, so we abandoned this venture.\n5. Wiktionary25 provides links between many words for male and female persons. This is a potential\nhigh-quality source still to be leveraged.\n6. GC426 is a large corpus for German that is scraped from the internet. It could be mined similarly as\nwe have done with DeReKo. Since we have already used GC4 for the benchmark (see section 2), we\nhave not used it for our database.\nNoteworthy datasets for English are the data underlying retext-equality (see subsection 1.4), and a\nsoon-to-be-released dataset described in [11].\n20Data processing scripts for the various sources are listed in doc/data.md\n21https://geschicktgendern.de/\n22https://www.ids-mannheim.de/en/digspra/corpus-linguistics/projects/corpus-development/\n23https://www.data.gv.at/katalog/dataset/15d6ede8-f128-4fcd-aa3a-4479e828f477\n24https://www.openthesaurus.de/about/download\n25https://de.wiktionary.org/wiki/Wiktionary:Download\n26https://german-nlp-group.github.io/projects/gc4-corpus.html\n17\n3.3\nProcessing and matching\nModels: For sentence segmentation we make use of the Sentencizer of the Spacy library27, which works\nwith simple punctuation-based rules. Tokenization is approached by using the rule-based tokenizer\nfor German that is included in Spacy’s de_core_news_sm pipeline. For dependency parsing Spacy’s pre-\ntrained transformer model de_dep_news_trf is employed; this is a German BERT model28 ﬁne-tuned\nfor part-of-speech tagging and dependency parsing on the commercial TIGER corpus29. Lastly, for\nlemmatization we choose a hybrid model of two frequency dictionaries and a BiLSTM-encoder with\nattention from the Stanza library [12, 13], which is trained on Universal Dependencies datasets and in this\ncase speciﬁcally on the Hamburg Dependency Treebank30. We integrate Stanza via a wrapper library31\nand augment the output from the Spacy model with the lemmas of the Stanza model.32\nPre- and post-processing: We have observed that the pre-trained models that we use for sentence\nsegmentation, tokenization, and lemmatization (see below) are easily confused by the occurrence of\nspecial characters in the abbreviated pair notation. Perhaps the data sets for pretraining did not include\nmany inclusive texts. Future work could investigate this thesis, and if it holds true, the community may\nwish to include more inclusive texts in their pretraining data sets. For our purposes, one solution would\nbe to ﬁne-tune the models on inclusive texts. Instead, we perform a preprocessing step where these\nsymbols are removed when they occur inside an abbreviated pair notation. The abbreviated pair notation\nthen collapses to the female inﬂection, which the models can correctly deal with. The symbols and their\npositions are stored and added back to the text attributes of the output tokens of the models.\nMatching: We process both the input text and the exclusive phrases from the database with tokeniza-\ntion, lemmatization, and dependency parsing. For the input text, we remove preﬁxes in an intermediate\nstep; see subsection 3.5. We check whether all the lemmas from an exclusive phrase in our database\nare present in a sentence and whether the dependency relations between the tokens are identical in the\nsentence and the database. If this is the case, there is a match.\nFor creating the inclusive alternatives, we retrieve those inclusive phrases from the database that are\nassociated with the phrase that was involved in the match. We want to replace the exclusive phrase with\nthe inclusive phrase to create an inclusive sentence. Simple text replacement is not sufﬁcient in many\ncases, because it would render the sentence grammatically incoherent. Instead, we need to adjust to each\nother the inclusive phrase and the sentence shell into which it should be embedded.\nNote: We talk of inclusive and exclusive phrases because they may consist of two or more words\n(\"studierende Person\", \"Mensch mit Behinderungen\"). Most exclusive and exclusive phrases are however\njust a single word, and usually a noun.\n3.4\nGrammatical assimilation\nThe challenge in this step is to adjust those words that were originally dependent on the exclusive phrase\nsuch that they are afterwards dependent on the inclusive phrase; and to adjust the inclusive phrase to\nthe context into which it is embedded. We conduct part-of-speech tagging and morphological analysis\non both parts with Spacy. In the overwhelming majority of cases, the root word is a noun (less than 500\nphrases of the more than 7000 phrases in the database described in subsection 3.2 have roots of another\n27https://spacy.io/\n28https://huggingface.co/bert-base-german-cased\n29https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/tiger/\n30https://github.com/UniversalDependencies/UD_German-HDT/tree/master\n31https://github.com/explosion/spacy-stanza\n32We deviate from using Spacy here because lemmatization is the only case where it is signiﬁcantly outperformed by Stanza, cf.\nhttps://explosion.ai/blog/ud-benchmarks-v3-2.\n18\nword class), so we focus on this case. We refer to the root words of the replaced exclusive phrase and of\nthe new inclusive phrase as exclusive root and inclusive root, respectively.\nThe case of the inclusive root is adjusted to the case of the exclusive root. The number of the inclusive\nroot usually is adjusted to the number of the exclusive root. Only in some cases – those are marked in a\nspecial column in the database – a plural word is replaced by a singular word (e. g., the plural \"Polizisten\"\nby the singular \"Polizei\"). The grammatical gender of the inclusive root remains untouched (the case of\npair notation will be discussed later).\nNext, the dependent words of both the surrounding sentence and the inclusive phrase are inﬂected\nto match the new morphology of the inclusive root. Verbs to which the root is a subject are adjusted in\nnumber. Attributively dependent articles, adjectives and pronouns are adjusted in case, number, and\ngender. In the case of relative sentences, recursive adjustments should be made; this is not implemented.\nMoreover, coreferences should be adjusted, which is not implemented either.\nFor all these inﬂections, we make use of the morphological dictionary Morphy [14].33\nFigure 9 gives an example of the process and allows to capture the essence of the complicated process\njust described: Of the three morphological variables that determine noun-like words (case, number,\nand gender), case ﬂows in one direction, and number and gender ﬂow in the other direction. After the\nassimilation, all the involved words share the same case, number, and gender. Similar rules could be\nimplemented for verbs and adjectives, but since there are not many phrases with verbs and adjectives in\nthe database, we have not implemented this.\nFigure 9: Example for grammatical assimilation. (1) The exclusive sentence (left) with the exclusive phrase (blue),\nand an inclusive alternative phrase (orange, right). (2) Articles, adjectives and pronouns that depend on the exclusive\nphrase are assimilated by number and grammatical gender to the root of the exclusive phrase. The root of the\ninclusive phrase and articles, adjectives and pronouns that depend on the exclusive phrase are assimilated by case to\nthe root of the exclusive phrase. (3) Exclusive sentence and inclusive phrase are integrated into each other, forming\nan inclusive sentence.\n3.5\nPreﬁx removal\nTwo considerations support the case for ignoring preﬁxes during the core processing steps:\n1. When we try to match words from the text with exclusive words, we want compound nouns to\ntrigger a match in the same manner that their compounds do: If \"Lehrer\" triggers the suggestion\n\"Lehrer_in\", then \"Sportlehrer\" should trigger \"Sportlehrer_in\". Similarly, one could demand that\n\"Lehrerzimmer\" should trigger \"Lehrer_innenzimmer\"; but such adjustments (where a different\ncompound than the last one is adjusted) are considered less legible and less urgent [1, ch. 2.5], so\nwe do not implement them and focus on the former case.\n2. The inﬂection method is dictionary-based (see the previous section), and many compound words\nare not in the dictionary. Removing preﬁxes allows us to inﬂect a wider range of words.\n33We use a version that is extracted from the LanguageTool software. See http://www.danielnaber.de/morphologie/\n19\nFor these reasons, we remove preﬁxes before the lemmatization step, and add them back after the\neventual inﬂection step. We adjust the capitalization both when removing and adding back the preﬁx.\nFor ﬁnding preﬁxes, we use the compound-split library (originally known as CharSplit) [15, ch. A.3]. For a\ngiven German word, it delivers multiple possible word splits associated with a score. We only use the ﬁrst\nresult if it has a score of s > s0. For the optimization of s0, see subsection 4.2.\n3.6\nStyle application\nThe style (neutral / pair notation / internal I / custom character) is applied at two points. First, for ﬁltering\nthe inclusive phrases from the database; and second (not applicable to the neutral style) for creating an\ninclusive phrase from the female and male inﬂections.\nAs described in subsection 3.2, the database returns entries of two categories for an exclusive phrase:\nneutral words, and female inﬂections for deriving the pair notation forms. If the style is neutral, then only\nentries of the ﬁrst category are retrieved; otherwise, entries of both categories are retrieved. The neutral\nwords do not require further processing and just run through the pipeline as described above.\nFor the other styles, the database entries are processed as follows: For the internal I and custom\ncharacter styles, the female inﬂection of the word is inﬂected as described above; afterwards, the word is\nmodiﬁed with regexes and the special character is inserted or the I is capitalized. For the unabbreviated\npair notation, the female inﬂection is morphologically adjusted as described above, then combined with\nthe male inﬂection (that is, the root of the exclusive phrase). If the exclusive word has a dependent article\nor adjective, they are inﬂected to be female and prepended to the inclusive word. More complex cases\nsuch as described in subsection 1.2 are not covered. The female and male inﬂections are combined with\n\"oder\" in the singular, and with \"und\" in the plural, negations are not taken care of.\n20\n4\nEvaluation\n4.1\nPerformance\nThe performance is calculated using the two benchmark tasks – labeling exclusive phrases, and providing\nsuggestions for inclusive alternatives – from the benchmark described in section 2; results are in Table 1.\nFor the suggestion task we calculate the standard measures (Is the target sentence literally identical to one\nof the suggestions?), and also the same measures on lemmas (Is the set of lemmas of the target sentence\nidentical to the set of lemmas of one of the suggestions?). Moreover, we measure the time which the system\nneeds to process input texts of various lengths; see Figure 10.\nLabeling\nRecall\n.888\nPrecision\n.818\nF1\n.852\nSuggestions\nlemmas\nwords\nCorrect in candidates\n.610\n.537\nCorrect in 5 best candidates\n.497\n.441\nCorrect in 1 best candidates\n.051\n.051\nSuggestion score\n.559\n.492\nTable 1: Benchmark values for the model.\nFigure 10: Processing duration with respect to text size. Measured on 10 batches of random samples from German\nWikipedia. Wikipedia standardly uses the generic masculine.\n4.2\nAblation\nfull\n–pair not.\n–neut. not.\n–inﬂect.\n–pref. rem.\nRecall\n.888\n.820\n.867\n–\n.837\nPrecision\n.818\n.834\n.844\n–\n.842\nCorrect in 5 best candidates\n.441\n.006\n.528\n.114\n.465\nSuggestion score\n.492\n.006\n.436\n.075\n.307\nTable 2: Ablation results. Metrics for the full model; with omitted data for (both full and abbreviated) pair notation;\nwith omitted data for gender-neutral suggestions; without grammatical inﬂection step; and without removing preﬁxes\nbefore matching. (–) signiﬁes that the values are equal to those from the full model.\nFor an ablation study, we perform the same evaluation as in subsection 4.1 but while disabling various\ncomponents of the pipeline and of the inclusive language database; a subset of metrics is reported for\nfour components in Table 2.\n21\nFigure 11: Impact of s0 on the labeling task.\nThe inclusive language database consists of two kinds of entries, stemming from two different datasets\n(cf. subsection 3.2): Entries with male and female phrases to form the (full or abbreviated) pair notation,\nand entries with neutral phrases. Leaving out either dataset leads to a small decrease in recall and a small\nincrease in precision for the labeling task. Performance in the suggestion task drops to almost zero when\nleaving out data for the pair notation, while it stays the same or even improves when leaving out the data\nfor neutral alternatives.\nThe inﬂection step does not impact the labeling task, but it considerably improves the quality of the\nsuggestions on both measures. Preﬁx removal has a small positive effect on recall but a negative effect on\nprecision and an unclear effect on the quality of suggestions.\nThe preﬁx removal step is further characterized by the parameter s0, which determines how conﬁdent\nthe system needs be when it tries to automatically detect preﬁxes. We analyze the impact of s0 on recall,\nprecision and F1 score in Figure 11. An optimal F1 score is achieved for s0 = 0.8; this score is also used for\nthe performance anlaysis in subsection 4.1.\n4.3\nDiscussion\nAs for the labeling task, recall and precision are at a level that is acceptable for production use. The\nprecision of the model is necessarily limited because it cannot distinguish between generic and speciﬁc\nmasculines. We would have expected to achieve a higher recall, because we have mined all pair notations\nfrom a large corpus, and because we use a large database of neutral words that should conveniently cover\nthe more frequent exclusive words.\nAs for the suggestion task, roughly half of the suggestion sets contain the correct sentence (54%), and\nif it is contained, it is mostly also in the ﬁrst 5 suggestions (44%). Surprisingly it is almost never the top\nsuggestion, which may hint at an implementation bug. The current system does not have a mechanism\nfor ranking its suggestions; with such a mechanism it may well be possible to increase the top-5 and\ntop-1 scores to come closer to the 54% of the correct in candidates score. But the main challenge is the\nimprovement of this very score. For the lemma-based measures, the values are 8%points, 6%points\nand 0%points higher than for the respective word-based measures. This indicates that there are few\nproblems regarding the inﬂection of the words, even though not all theoretically necessary features are\nimplemented. The problem seems to be rather with the suggested words. Overall, these scores are not\ngreat: In 56% of cases, the user needs to scan through the suggestions only to realize that none of them is\nwhat they desire, and then make the adjustment manually.\nAs expected, the time complexity is linear with respect to the length of the input text (see Figure 10).\nAn original design for the frontend was to trigger the check again after every replacement that the user\nselects. In such an interactive environment, delays should not be longer than roughly 1.5 s, and even better\n22\nmuch shorter. This would allow for texts up to ∼700 characters – roughly one or two paragraphs –, which\nmakes the mentioned approach unattractive; some logic with regard to the effects of the replacement\nshould be implemented in the frontend independently from the backend processes.\nIf the system is designed in a way such that the check is only triggered once, then the delay is very\nacceptable, even for longer texts such as a thesis or book.\nThe ablation anlysis shows that (a) both the dataset for pair notation and the dataset for neutral\nalternatives are sufﬁcient on their own to detect most of the exclusive phrases (respectively 98% and 92%\nof the recall that they achieve in combination) with high precision; but (b) the pair notation dataset is\nresponsible for more or less all of the performance with respect to the inclusive suggestions made. This\nis in part due to the prevalence of pair notation and neutral words in the inclusive language database\n(Figure 7): Pair notation (full and abbreviated) makes up for 230 out of 305 inclusive phrases (75%), while\nthe remaining quarter is in one of the neutral styles; and it is unclear whether this is representative of the\nprevalences (see the last paragraph of subsection 2.2 for methodological discussion). Another reason for\nthe performance difference between the datasets may be that the pair notation dataset has been extracted\nfrom a large corpus with a method (matching special symbols and paired gendered words) that arguably\nhas a very high recall – while for the neutral words such a fully-automated approach is impossible and\nthe dataset is completely human-curated.\nThe ablation analysis conﬁrms that the inﬂection component has a signiﬁcant impact on the perfor-\nmance of the suggestions. Since the suggestion scores on words are not far behind those on lemmas, we\nalso know that it could not perform much better. In conclusion, the inﬂection, although not implemented\nto be comprehensive, works relatively well.\nThe s0 parameter for controlling the preﬁx removal allows us to trade precision for recall: Setting\ns0 = 1 effectively disables the component, with recall at 0.837, precision at 0.840 and F1 at 0.838. The F1\nscore is maximally increased at s0 = 0.8 by some rather small 1.4%points. Arguably, precision is more\nimportant than recall in the area of exclusive language detection; under that assumption the preﬁx\nremoval as is should be disabled. Preﬁx removal in general is still an attractive enhancement in our\njudgment, and we speculate that future work will be able to detect preﬁxes with a better tradeoff between\nrecall and precision.\n23\n5\nFuture work\n5.1\nBenchmarking\nFuture work with regard to the benchmark data (section 2) is to actually use it for benchmarking the\nexisting tools (subsection 1.4). The newly proposed measures in subsection 2.5 are hard to interpret in\nabsolute terms, but should be suitable for making comparisons between different tools (as well as the\nevolution of a single tool over time).\n5.2\nImproving the model\nThe model developed in this project is already relatively complicated, but not yet perfect. The following\nareas still deserve exploration:\n• Improving the grammatical adjustment mechanism. The grammatical adjustment currently\nworks well with standalone nouns and nouns that are accompanied by an article. More complicated\nconstructs, such as involving adjectives and adverbs or even relative sentences, are ignored. Phrases\nwhere the root word is a verb or adjective are not supported. This could be extended using similar\napproaches as for nouns.\n• Coreference resolution. The current model takes care of adjusting (some) syntactically dependent\nwords, but not of adjusting semantically dependent or coreferential words. It is open to which\nextent this would be desirable or how it should be conceptualized: A system that automatically\nchanges coreferences in other sentences when the user accepts a suggestion in one sentence may\nor may not be acceptable from a user experience perspective. Coreference resolution could also\nhelp with detecting speciﬁc masculines in some cases.\n• Detecting speciﬁc vs generic masculine. Our model labels all masculine occurrences and gives\nsuggestions for them. But some of the masculines are justiﬁed because they actually refer to\nexclusively male persons. The distinction is challenging because it often hinges on implicit context:\nAre all citizens allowed to vote or only male ones?\n• Automatic ranking. The system often gives multiple suggestions, but their order is currently\nirrelevant. An n-gram language model trained on inclusive texts could be used to score the ﬂuency\nof the different suggestions.\n• Discovery of neutral alternatives. The database could be enriched by automatically ﬁnding further\ngender-neutral words. Such discovery could help cure the poor performance of our dataset for\nneutral words (see subsection 4.3). Embeddings are known to encode male/female relationships,\nand it could be investigated whether there is also a relationship between male words and neutral\nalternatives, or multiple categories (cf. subsection 1.2) of such relationships.\n24\n5.3\nTraining end-to-end models\nAn alternative to the complicated pipeline presented here is the training or ﬁne-tuning of an end-to-end\nmodel (see the start of section 3 for a comparison). For the tasks (labeling and providing alternative\nsentences) one could train separate models. In both cases, such a model would require a large amount of\ntraining data. In section 2 we have used a semi-automatic approach for creating evaluation data from\ninclusive texts. The challenge is to completely automate this approach.\nFigure 12: Draft for a pipeline for training an end-to-end model for inclusive language.\nThe ﬁrst problem is the detection of inclusive words. As discussed in subsection 2.2 the detection\nof (abbreviated) pair notation is straightforward, but neutral words are harder to detect. An important\nsubclass of neutral words are participles. We have created a list of participles that we believe would only\noccur in inclusive contexts (see subsection 2.2). One could use this list for detecting a subset of participles,\nremove all other occurrences of participles from the training data to avoid potentially wrong examples,\nand hope that the model generalizes correctly.\nFrom the detected inclusive words, candidates for exclusive words could be generated by using a\ndatabase such as ours, and/or heuristic rules, which, for example, transform \"Arbeitende\" into \"Arbeiter\"\n(correct) and \"Studierende\" into \"Studierer\" (incorrect). An n-gram language model could be used to\nrank these candidates by ﬂuency. Grammatical adjustment could simply be omitted, hoping that the\npre-trained model does not mind too much about broken input sentences, as long as the target sentences\nare of high quality. Otherwise, a tool or model for grammar correction could be used.\nGiven the complexity of the model presented in this report, the approach of the end-to-end model is\ndeﬁnitely worth exploring.\n5.4\nPrompting large language models\nAnother alternative approach is to explore the suitability of large language models for the inclusive\nlanguage tasks. Simple experiments with OpenAI’s commercial GPT3-DaVinci model show that the model\nunderstands prompts such as \"Use gender-inclusive language.\" in both English and German. Examples\ncan help to make it reproduce the different inclusive language styles. In our experiment with the prompt\nfrom Figure 13 and a similar prompt for labeling, GPT3 achieves a recall of 0.76 with a precision of 0.5\n(F1=0.605). One of the top 5 suggestions that it provides is actually used 25% of the time in the benchmark\ndata, which corresponds to a (logistic) score of 0.249. Examples for errors are that the model often uses\nonly the female inﬂection rather than an inclusive form; and sometimes it uses lots of gender characters\nsuch that the result is hard to read. In conclusion, GPT3 as is is not reliable for gender-inclusive language\ntasks; but perhaps with more elaborate prompts and examples, it may become more reliable, even\n25\nFigure 13: The GPT3 DaVinci model (commercial, with 175 billion parameters), performing roughly the same task\nwith a 6-line prompt for which we have needed more than 1200 lines of code and lots of structured data. Here, it\ndoes well for the ﬁrst replacement, even ﬁnding an appropriate alternative participle, but wrongly turns the second\nphrase into the feminine rather than a gender-inclusive variant. Depending on the prompt and on randomness, it\nis sometimes perfect and sometimes stupid. GPT-J-6B (open source, with 6 billion parameters) does not produce\nuseful results for the same prompt.\nwithout ﬁne-tuning as in subsection 5.3. Next to the technical aspects, the practical aspects of using large\nlanguage models need to be considered: Particularly, these models are too large for local deployment in\nmost scenarios, and using a cloud service comes with increased costs as well as concerns for privacy and\nsecurity.\n5.5\nNo red ink\nThe deployment of inclusive language tools and the adoption of inclusive language in general is hindered\nby the red ink problem: Many spell and grammar checkers, commercial or open source, ﬂag the use of\ngender characters as spelling mistakes. For example, Microsoft Word accepts the gender star, but ﬂags\nthe gender gap and other symbols; an inclusive language tool that runs as an add-in in Word therefore\nsuffers from some limitations. Furthermore, when texts from standalone software are copied into word\nprocessors or browser forms, users are punished with red ink for their efforts towards inclusivity.\nAn oft-repeated argument against gender-inclusive language is that it is exclusive towards the visually\nimpaired because the gender characters are mispronounced by screen readers [16]. This is partially true\n[17], and it is urgently necessary that software producers change this behaviour.\nModern tools for grammar checking and text-to-speech production rely on language models as their\nbasis, so it is also important that these models are trained on data that includes inclusive language and\ngender characters.\nIn subsection 3.3, we explain that we needed to build a wrapper around Spacy for removing gender\ncharacters during processing. This adjustment is necessary solely because we also have inclusive text as\nan input, not because we want to produce it. Many other applications have gender-inclusive language as\nan input as well, and natural language processing tools that can process it by default would be a major\nadvancement.\n26\nBibliography\nOn gender-inclusive German\n[1]\nGabriele Diewald and Anja Steinhauer. Handbuch Geschlechtergerechte Sprache: Wie Sie Angemessen\nUnd Verständlich Gendern. Bibliographisches Institut GmbH, 2020.\n[2]\nChristine Olderdissen. \"Ich bin Ingenieur\", sagte sie. genderleicht.de. Sept. 29, 2020. URL: https://\nwww.genderleicht.de/30-jahre-wiedervereinigung-feministisches-sprachverstaendnis-\nversus-maennlich-gepraegte-sprache/ (visited on 03/25/2022).\n[3]\nGleichberechtigung: Männer Fordern Eigene Geschlechtsendung. Der Postillon. URL: https://www.\nder-postillon.com/2017/11/gleichberechtigung-er.html (visited on 03/25/2022).\n[4]\nYasmeen Hitti et al. “Proposed Taxonomy for Gender Bias in Text; A Filtering Methodology for the\nGender Generalization Subtype”. In: Proceedings of the First Workshop on Gender Bias in Natural\nLanguage Processing. Proceedings of the First Workshop on Gender Bias in Natural Language\nProcessing. Florence, Italy: Association for Computational Linguistics, 2019, pp. 8–17. DOI: 10.\n18653/v1/W19- 3802. URL: https://www.aclweb.org/anthology/W19-3802 (visited on\n03/26/2022).\n[5]\nJad Doughman et al. “Gender Bias in Text: Origin, Taxonomy, and Implications”. In: GEBNLP (2021).\nDOI: 10.18653/v1/2021.gebnlp-1.5.\n[6]\nIrmtraud Voglmayr. Leitfaden Für Einen Nicht-Diskriminierenden Sprachgebrauch. In Bezug Auf\nJunge Und Alte Menschen, Menschen Mit Behinderung, Frauen / Männer, Schwule / Lesben / Transgen-\nder, Migrant/Innen Und Menschen Mit Einer Anderen Religiösen Zugehörigkeit. Wien: Bundesminis-\nterium für Wirtschaft und Arbeit, 2008. URL: https://static.uni-graz.at/fileadmin/Akgl/\n4_Fuer_MitarbeiterInnen/leitfaden-nichtdiskriminierende-sprache_BMWA.pdf (vis-\nited on 03/26/2022).\n[7]\nMarlies Klamt. Handlungsempfehlungen Für Eine Diversitätssensible Mediensprache. Frankfurt am\nMain: Gleichstellungsbüro Goethe-Universität, 2016. URL: https://www.uni-frankfurt.de/\n66760835/Diversitaetssensible-Mediensprache.pdf (visited on 03/26/2022).\n[8]\nR. Bigler and C. Leaper. “Gendered Language”. In: (2015). DOI: 10.1177/2372732215600452.\n[11]\nJad Doughman and Wael Khreich. “Gender Bias in Text: Labeled Datasets and Lexicons”. In: ArXiv\n(2022).\n[16]\nGendern. URL: https://www.dbsv.org/gendern.html (visited on 03/30/2022).\n[17]\nbarrierefreies.design. Wie barrierefrei ist das Gendern? (mit Audio-Beispielen). barrierefreies.design.\nURL: https://barrierefreies.design/blog/wie- barrierefrei- ist- das- gendern\n(visited on 03/30/2022).\n27\nOn natural language processing\n[9]\nMarianne Starlander and Andrei Popescu-Belis. “Corpus-Based Evaluation of a French Spelling and\nGrammar Checker”. In: Proceedings of the Third International Conference on Language Resources\nand Evaluation (LREC’02). LREC 2002. Las Palmas, Canary Islands - Spain: European Language\nResources Association (ELRA), May 2002. URL: http://www.lrec-conf.org/proceedings/\nlrec2002/pdf/55.pdf (visited on 03/25/2022).\n[10]\nMartin Reynaert. “All, and Only, the Errors: More Complete and Consistent Spelling and OCR-Error\nCorrection Evaluation”. In: Proceedings of the Sixth International Conference on Language Resources\nand Evaluation (LREC’08). LREC 2008. Marrakech, Morocco: European Language Resources As-\nsociation (ELRA), May 2008. URL: http://www.lrec-conf.org/proceedings/lrec2008/pdf/\n477_paper.pdf (visited on 03/25/2022).\n[12]\nPeng Qi et al. “Stanza: A Python Natural Language Processing Toolkit for Many Human Languages”.\nApr. 23, 2020. arXiv: 2003.07082 [cs]. URL: http://arxiv.org/abs/2003.07082 (visited on\n03/27/2022).\n[13]\nPeng Qi et al. “Universal Dependency Parsing from Scratch”. In: Proceedings of The. Proceedings\nof The. Brussels, Belgium: Association for Computational Linguistics, 2018, pp. 160–170. DOI:\n10.18653/v1/K18- 2016. URL: http://aclweb.org/anthology/K18- 2016 (visited on\n05/21/2022).\n[14]\nWolfgang Lezius. “Morphy-German Morphology, Part-of-Speech Tagging and Applications”. In:\nProceedings of the 9th EURALEX International Congress. University of Stuttgart Stuttgart, 2000,\npp. 619–623.\n[15]\nDon Tuggener. “Incremental Coreference Resolution for German”. PhD thesis. University of Zurich,\n2016.\n28\nA\nMetrics for scoring text suggestions\nHere we discuss our choice of a metric for scoring inclusive suggestions. This is relevant in the context\nof benchmarking inclusive suggestions, as discussed in subsection 2.5. The inclusive language system\nreturns a ranked list of inclusive suggestions for each exclusive phrase in the text. Through the benchmark,\nwe know the inclusive alternative that the author has chosen and can check whether or not it is among\nthe suggestions by the system and what its position in the ranked list is. Now we want to convert this rank\ninto a more useful metric.\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n0\n0.5\n1\nproportional (n = 5)\nexponential (k = −0.6)\nlogistic (B = 1;v = 0.01)\nFigure 14: Candidate functions for assigning a suggestion score s(r) to a rank r. Parameters are chosen by hand to\nroughly suit the assumption that 5 items can be displayed. For an interactive version with adjustable parameters, see\nhttps://www.desmos.com/calculator/z9mq8xiqmz.\nThere are many functions that we could use to map the rank which a system assigns to the target\nsentence onto a score. Let r ∈{0,1,...} be the rank of the correct target sentence, and 0 ≤s(r) ≤1 its score\nqua our benchmark. Then, among other functions worth considering, we ﬁnd the following three families\nof functions especially attractive as a choice for s (see Figure 14):\n1. s(r) = max(0,1 −r\nn ): This expresses the intuition that n suggestions can be displayed. If the\nsentence is not within the ﬁrst n items of the ranked list, then it is \"not present\" in the visual list\nof suggestions, thus receives a score 0. Sentences that are ranked higher within the ﬁrst n items\nreceive a proportionally higher score. A good choice for n might be somewhere around 5, and n\ncould be varied according to the application scenario.\n2. s(r) = (1+r)−k: This expresses the intuition that any improvement in the rank – also beyond the\ncutoff of visually displayed options – should result in an improved score. Good choices of k may be\nbetween 0 < k ≤1.\n3. s(r) = 1−\n1\n(1+e−Br )1/v , that is, a specialization of the generalized logistic function, where B and v can\nbe modulated to adjust the slope and position of the steepest decline: This roughly captures the\ncombined intuitions underlying the two functions above.\nWe choose the third function as our suggestion score function because it ﬁts the intuitions best.\nSpeciﬁcally, we propose to use B = 1 and v = 0.01 such that the steepest part of the function (the smooth\nthreshold) is around r ≈5 = n.\nWe have not yet taken into account that a sentence may include multiple exclusive words, each of\nwhich may have multiple inclusive alternatives. We assume that the system will offer to the user a choice\nfor each occurrence of an exclusive word. Thus, if at most n options are displayed for selection for each of\np exclusive occurrences, the user has an overall choice between np options. From another perspective, it\nis naturally harder for the system to pick the right sentence when multiple replacements have to take\nplace; and this should be compensated for. To accommodate for this, we replace our ranks r with adjusted\nranks r ′ = ppr, and calculate s(r ′) rather than s(r).\n29\nB\nDimensions of diversity in language\n30\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2022-12-05",
  "updated": "2022-12-05"
}