{
  "id": "http://arxiv.org/abs/2212.08482v2",
  "title": "Implementation of general formal translators",
  "authors": [
    "Iosif Iulian Petrila"
  ],
  "abstract": "The general translator formalism and computing specific implementations are\nproposed. The implementation of specific elements necessary to process the\nsource and destination information within the translators are presented. Some\ncommon directives or instructions, such as classes and procedures, were unified\nand generalized in order to allow general translations implementations. In\norder to cover general cases, two levels of processing are required, related to\nthe source and destination information appropriate transformations, with the\nrelated control and processing instructions. The proposed general translator\nelements are useful for processing natural or artificial information described\nthrough any types of languages or systems.",
  "text": "1 \n \nImplementation of general formal translators \n \nIosif Iulian Petrila \n \nFaculty of Automatic Control and Computer Engineering, Gheorghe Asachi Technical University of Iasi, Str. Dimitrie \nMangeron, Nr. 27, 700050, Iasi, Romania \n \nThe general translator formalism and computing specific implementations are proposed. The implementation of specific elements \nnecessary to process the source and destination information within the translators are presented. Some common directives or \ninstructions, such as classes and procedures, were unified and generalized in order to allow general translations implementations. In \norder to cover general cases, two levels of processing are required, related to the source and destination information appropriate \ntransformations, with the related control and processing instructions. The proposed general translator elements are useful for \nprocessing natural or artificial information described through any types of languages or systems. \n \nKeywords: formal translators, formal languages, general compilers, programming instruments, languages completeness, \ncomputational methods, information processing \n \nIntroduction \n \nOne of our basic needs or of any other distinct \nsocial natural beings is to communicate in order to \nexchange and correlate information, the similar needs \nalso exist within artificial systems under all the aspects \nin which the information is represented, transported, \nmodeled, processed, coded, encrypted etc [1-4]. \nHowever, one of the most important challenges is to \nachieve the translation of information from one mode of \nrepresentation to another, in a general way, which is still \nan open question in many fields as: linguistics, \ninformation \nscience, \ncomputer \nscience, \ncomputer \nengineering etc. \nThe way in which the information can be \naccessed and used is through a language, which in a \ngeneral sense is nothing else than a set of rules \n(conventions, operations, laws, phenomena etc.) and \nsome related symbols (numerical, graphical, audio, \nobjects, particles etc.) used to represent its components. \nFrom this perspective, the languages are the instruments \nthat facilitate the description and the management of \ninformation related to any system [5-7]. \nDifferent perspectives of the same information \ncan be highlighted by different languages, as well as \ncertain \ninformation \ntransformations \ncan \nalso \nbe \ndescribed through a language. The connections between \nthese descriptions offered by different languages are \nmade by the translators. Nowadays, in order to be \neffective and relevant, any type of translator must be \nimplemented through a computer system. More than \nthat, a general computerized translator must be based on \nand also to generalize the best performing translator \nwithin computing systems, which is the compiler. The \ncompiler, \nas \nthe \nfundamental \ntranslator \nwithin \ncomputing systems, must itself first to be abstracted and \ngeneralized in order to allow the augmentation and \nflexibilisation of the usual programming languages and \n                                                 \n* E-mail address: IosifIulianPetrila@gmail.com \nto facilitate the approach and management of any \nlanguages and translations categories, specific to \ncomputing systems (such as compilation/decompilation, \nencryption/decryption, \ncompression/decompression, \nobfuscation/lisibilization etc.) or to natural systems [8-\n17]. \nA versatile translation framework must allow a \nunitary management of existing languages (natural or \nartificial) but also must be able to cover the present and \nthe future implementation challenges related to all \ncategories of systems such as: quantum, neural, smart, \nsocial, linguistic, algorithmic, chemical etc [18-26]. \n \nGeneral Translators \n \nA general translator must able to convert any \nsources of information descriptive through a language in \nany other type of description or representation. \nEffectively, \ndirectly \nor \nindirectly/implicitly, \nthe \ntranslation process must involve at least two steps of \nprocessing, one focused on source and other on \ndestination. For example, in the case of the web client-\nserver information transfer, at least one level of \nprocessing exists in the server (source) area (back-end) \nand at least one in the client (destination) area (front-\nend). In the case of compilation, one level is involved at \nthe input processing stage (high-level user facile \ndescriptions) and another (as compilation directive, \nmake file operations etc.) in the output formatting stage \n(low-level machine format representation). The same \ntwo levels must be also involved in the case of natural \nlanguages in the translation from one language to \nanother or even internally in the formation of \nrepresentations or perceptions of some information. \nFrom this perspective, a general translator must provide \nhierarchically-organized environments and tools in order \nto analyze and manage various source information \ndescribed through arbitrary languages and transformed \nin a different informational structure or language \ndescription. The computer implementable requirement of \n2 \n \nsuch translators must involve and to generalize the \nconcept of compiler, this being the fundamental \ntranslator used in computing systems. From this \nperspective, a formal general translator T can be defined \nby \nT = S, D, I, ,  \nwith S – source language alphabet, D – destination \nlanguage alphabet, I internal or intermediate alphabet (I \n S, I  D),  – source language rules,  – destination \nlanguage rules. Some internal transformations or rules  \n(which would operate with elements from I) can also be \nincluded in the definition (corresponding to middle end \nprocessing) but these are in fact manageable through  \nand/or . The T translator can also be detailed with the \nelements specific to Turing machines formalism [3] with \n(tape, states etc.) as a two interconnected Turing \nmachines. \nFrom \nimplementation \nperspective, \nthe \nsolution of a reliable general translator is given by \nhighlighting the two distinct levels of processing \ncorresponding to at least two languages associated with \nthe source and destination information. Also at each \nlevel is necessary two types of explicit control \ninstructions (decision sublevels), similar to some explicit \nor implicit control instructions used in some common \ncompilers one at high-level (for preprocessing, syntax \noperations \netc.) \nand \none \nat \nlow-level \n(for \ncompile/assembly/linking/optimization/formatting/postp\nrocessing operations). A diagram with the general stages \nand operations specific to the general translations can be \nseen in Figure 1.  \n \n \n \nFigure 1. Translation of source to destination \n \nEach processing level works as the usual language \nprocessing with typical directives, instructions etc. At \nsource level is performed a decomposition of the source \ninformation described by the source language (which \ncover  rules) where the most relevant keys are prefixed \nby # (#if, #elif, #else, #endif, #while, \n#endw, #repeat, #until, #break, #error, \n#print etc.). At destination level is performed a \ncomposition of the information according to the related \ndestination language instructions (incorporated in  \nrules), where the most relevant keys are prefixed by @ \n(@if, @elif, @else, @endif, @while, @endw, \n@repeat, @until, @break, @error, @print etc.). \nAt both levels, can be used relational and equivalence \nexpressions/operations (< – less than, > – greater than, \n<= – less than or equal to, >= – greater than or equal to, \n= – equal to, != or <> – not equal to), logical \nexpressions/operations (|| – or, && – and, ! – not), \nbitwise expressions/operations (& – and, | – or, ^ – xor, \n~ – complement, << – left shift, >> – right shift) and \narithmetic expressions/operations (+ – addition, - – \nsubtraction, * – multiplication, / – division, % – \nmodulo/remainder) etc. \n \nSource Language Processing \n \nThe source information described through the \nsource language is processed first within the first level of \nprocessing (depending on the relative human factor \nperspective in relation to the source or destination, in \nsome translators this level of processing it can be found \nunder different names such as high-level, user-level, \nmachine-level, front-end, back-end etc.) designated to \nimplement and manage the lexical and syntactic rules of \ndemand source language and also to convert the \ninformation in a unitary internal form for processing and \nconversion to the destination information. For example, \nin the case of compilers, source language processing \ncorresponds \nto \nthe \nhigh-level/user-level/front-end \nprocessing, in the case of decompilers corresponds to the \nlow-level/machine-level processing, while in the case of \nthe server-browser system translator it corresponds to the \nserver-level/back-end processing and so on. At this level, \nthe information must be decomposed into components \nthrough general but also language specific directives and \ninstructions. \nThe decision instructions are considerate as line \nprefixed directive, similar to (macro) instructions used in \nlanguages such as C/C++ [8]. For instance, the typical \nif-else instruction can be used as: \n \n#if condtition1 \n... \n#elif condtition2 \n... \n#else \n... \n#endif \n \nThe \ncondtition1, \ncondtition2 \nhave \na \nlogical/conditional structure with the usual operators and \nmeanings. The simple while loops can be used as: \n  \n#while condtition \n3 \n \n... \n[#break [levels]] \n... \n#endw \n \nwhere #break directive may be optionally followed by \nthe levels (to breaks) as a number of loops blocks to \nbreak (0 - do nothing or can be assumed as continue, 1 - \nbreak current block, 2 - break also parent block etc.). In \nsome situations is useful the repeat-until loop \ninstruction eventually times limited, which can be used \nas: \n \n#repeat [times] \n... \n[#break [levels]] \n... \n#until [condition] \n \nwhere times is the maxim repeated loops if \ncondition remains false or is absent. \nIf something goes wrong during the source \ninformation processing, the translation may be stopped \nby using  \n  \n#error message \n \nwith a message to be displayed. Also, at this level of \nprocessing, the non error messages can be displayed with \na similar instruction: \n \n#print message \n \nIdentifying the specific syntactic components of \na language, with the related semantics, is one of the most \ncomplex operations within translators. These operations \nare carried out through the general class implemented \nas a hyperclass or hyperfunction which unites in a single \nconcept the syntax parser, (class/object) structures, \nprocedures, classes, hygienic macro functions, syntactic \nclosures etc. and allowing their definition but also the \nmanagement of their invocations. This generalized \nclass is defined by \n \nclass name [fargs [.. vargs]] \n{ \n  ... \n}[name1 [... , nameN]] \n \nwith fargs fixed arguments, vargs variable/repetitive \narguments (with .. as separator operator of fixed \narguments from variable/repetitive ones) and name1 .. \nnameN some alias names of the current defined name \nclass. Each argument can be delimitated by one or \nmore symbol operators (+, *, | .. even comma , etc.), in \nthis way, this class generalizes the concept of lambda \ncalculus by using multiple arguments with any type of \nseparators to a syntactic general lambda calculus in \nwhich the call arguments can be separated by any type of \noperator, allowing the specific management of a general \nsyntactic parser. The class instruction can handle any \noperation declared by using prefix, postfix or infix \nnotation. \nA \nclass \ncan \nbe \nmultiple \nrewritten/overriding/redefined later, with the same or \ndifferent types of arguments and separators, without \nwarning because the global context may be different and \nuseful to be handled in each situation etc. For instance, if \nwe define first \n \nclass Sum x + y {S1(x, y)} \n \nand later \n \nclass Sum x + y {S2(x, y)} \n \nthe last defined class is used first when Sum class is \ncalled (the result will be S2(x, y)) if the specific \nglobal context is the same. To keep simple and natural \nthe implementation of various operations, a class can \nbe also overdefine / overload / overwrite. Also, a class \ncan be called or invoked as a usual procedure or \nfunction. When a class with a given name is calling, is \nverify first if the calling arguments are match from last \nto first defined class. In contrast to the usual \napproaches of functional languages (and not only) in \nwhich the verification of corresponding arguments in \nmultiple definitions is made from the first definition to \nthe last, the present classes will be verified in the reverse \norder of their definition, from the last definition to the \nfirst. The main argument is that the novelty appears later \nand must be present also after the previous definitions. \nIn this respect, the more general classes should be placed \nafter the less general ones etc. In this way, the problem \nof upgrading of a library is solved by including first the \nusual code and later adding new characteristics etc. Also, \nthe operations priorities definition and management are \nsimply solved by this order definition rule, in this \nrespect, a syntax S class with different arguments \nwhich must be defined in an order that is correlated with \nthe priority of the involved operators \n \nclass S X1{...} \n... \nclass S Xn{...} \n \nwhere X1 .. Xn are argument-expression (may contain \nsymbol operators). When is used S class \n \nS Expression \n \n4 \n \nit is verify each S class from last to first defined and is \nused \nonly \nthe \nclass \nwith \nargument \nwhich \nExpression is match. An example of an algebraic \nclass which parses simply addition and multiplication \nexpression can be defined as: \n \nclass E x {... x ...} \nclass E x * y {... E(x) * E(y) ...} \nclass E x + y {... E(x) + E(y) ...} \n \nIn this case, when E class is used with an expression \nwhich contain both operations ‘+’ and ‘*’, as in \n \nE a * b + c \n \nfor instance, the additive operation is identified and \nprocessed first through the last definition of the class \nE (x is a * b and y is c according to last E class) \nand second the multiplicative operation, according to \noperations relative priority/precedence which imposed \nthe order/succession of E classes definitions. \nIn some situations is need to parse multiple \narguments in a specific order. For instance, simple \ninteger addition operation of multiply arguments is \nuseful to be implemented by adding each argument into \nan accumulator register etc. For the operations reducible \nto binary operation, the associative property can be \nimplemented as left-associative operation x * y * z \n= (x * y) * z or as right-associative operation x * \ny * z = x * (y * z). An example of \nimplementation of a left-associative operation is: \n \nclass E x {... x ...} \nclass E x * y {... E(x)*E(y) ...} \nclass E x * y * z \n{... E(x*y)*E(z) ...} \n \nA right-associative operation is obtained by replacing the \nlast class with \n \nclass E x \n* \ny \n* \nz \n{... E(x)*E(y*z) ...} \n \nThe class instruction can be used to define \nvarious types of information like: simple or structured \ndata, procedures, objects etc. For instance, one can \ndefine simple Long data as: \n \nclass Long L \n{ \n  L dd ? \n} \n \nwhere, in this case, Long it was defined as double-word \nthrough dd. A structured data, like a 2D point for \ninstance, can be defined as: \n \nclass Point P \n{ \n  Long P.x \n  Long P.y \n} \n \nwhere, inside of Point class body, each field it was \ndefined as Long. One may mention that P argument \n(which will in fact be the next variable names defined by \nPoint) is substituted inside a body class on all \noperand in doted (in this case) or other operation. In the \nsame way can be used class instruction to define any \ndata type according with demand programming or \nnatural language. For example, object classes used in \nobject-oriented \nlanguages \n(with \nencapsulation, \ninheritance, polymorphism and abstraction features), can \nbe easily defined as: \n \nclass Parent P \n{ \n  ... \n  Long P.a \n  ... \n} \n \nclass Child C \n{ \n  Parent C \n  ... \n  Point C.p \n  ... \n} \n \nChild V \n \nwhere, \nfor \nV \nChild \nclass \nvariable, \nthe \ncharacteristic of its parent Parent are inherited and \naccessible as V.a etc. One may observe that the \ninheritances (simple or even multiple) are specified in \nthe body of the class where there is more freedom and \nflexibility to operate with them and not outside as in the \ncase of the usual programming languages. \n \nTo cover even the most complex information \n(such as template structures etc.) it allowed defining a \nclass inside to another class as: \n \nclass c a \n{ \n  ... \n  class a ... {...} \n  ... \n5 \n \n  class b ... {...} \n  ... \n} \n \nwhere a class is defined according with called \nargument of c class and b class may contain only \ninside references to the calling argument a. For instance, \nif we want to implement typical C #define \npreprocessor directive macro definition, the following \ndefinitions can be used \n \nclass #define a b {a := b} \n \nclass #define a(x) b {class a(x){b}} \n \nwhere, first are solved functional replacements (if any) \nand second the symbol substitution. In the case of \nfunctional replacement a(x), x can contain one \nargument or more and no additional definition is \nrequired. In a similar way can be implemented the \nspecific elements of lambda calculus or any other \nprocessing element. \n \nAlong with the syntactic analysis facility, the \nclass instruction generalizes and incorporates the \nusual \nprogramming \nlanguages \nmacro \nfunctions, \nstructures, classes, procedures with nested and closure \ncharacteristics etc. With this flexible class instruction, \nnear to control instructions, it can be handled the syntax \nof even the most complex programming or natural \nlanguage or different type of data or information. In \nrelation to the way in which the analysis of source \nlanguage syntax is performed, the present approach is: \nimplicit, dynamic, contextual and implementable. At this \nlevel, after splitting the source information into \ncomponents, a series of operations may be necessary to \nidentify information semantics, these classes can be also \nused for this purpose, regardless of the type of method \nused in this sense as neural etc. \nBecause at source level processing it converts \nthe \nsource \ninformation \ninto \ninternal \nabstract \nrepresentation or partial destination information, the next \ndestination level operations will allow the organization \nof information in accordance with the specific rules of \nthe destination language similar to the operations of \nusual compilers in the sage of output formatting \noperations (assembly, linking, optimization etc.). \n \nDestination Language Processing \n \nAt destination level processing/stage, the \ninformation/code is transformed into the desired output \nformat \naccording \nto \ndestination \nlanguage \nand \ninformation system characteristics, similar to processor \nand operating system type and generally corresponds to \nthe middle-end and back-end usual compiler operations. \nThe explicit existence of control instructions within this \nlevel is essential because the formatting of the output \ncannot be done by simple operations, for these \noperations the usual compilers are used some extra \nlanguages or directives in a implicitly and non-\ntransparently \nway, \nsuch \ninstructions \nare \nused \nincoherently within the usual compilers, often through \nsome scripts and directives less correlated with the \ncompiled language etc. In addition, a series of \noptimization operations are required, which require the \nuse of decision and control instructions. This second \ncategory of transformations is often implicitly included \nin the linking routines in the case of programming \nlanguages information processing (such as C/C++ for \nwhich both the source and destination languages are \nclear etc.). In the general case, for the translation of \ninformation described from any language to any other \nlanguage, these translations must be explicitly described \nby instructions that facilitate optimization operations \nspecific to the target language. In this respect, similar to \nhigh-level processing, with equivalent definitions and \nmeanings, \nthe \ndestination \nlanguage \ninformation \nprocessing (low-level languages in the case of compiling \ninformation described by the programming languages) \nmust use similar control instructions: @if-@elif-\n@else-@endif, \n@while-@break-@endw, \n@repeat-@break-@until \netc. \nThe \ncontrol \ninstructions are also very useful for destination \ninformation processes (to perform code optimization, \nmanaging multiple processing steps etc.) but in an \nexplicit way. For instance, if some procedures are not \nused (called) during translation/compilation, then one \nmay add a conditional translation/compilation like: \n \n@if [Pn] \n  ... \n  Pn: \n  ... \n@endif  \n \nwhich include implementation of the procedure only if \nthe entry point in procedure Pn (calling name or label) is \nused elsewhere, useful to eliminate the code/body of \nunused/uncalled procedures etc. In some languages, \nthese types of instructions can be replaced by operations \nexternal to the language performed by the compilers, or \nthey can even be replaced by some preprocessing \ninstructions [8]. \nIn case of possible errors that may occur during \nthis level processing stage, the execution of the translator \nmay be stopped by using: \n \n@error message \n \nwith a message to be displayed. The non error \nmessages can be displayed also at this level of \nprocessing with  \n6 \n \n \n@print message \n \nOne may mention that, in the case of using both \n#print and @print instructions, the next two \nmessages will be displayed in reverse order because at \nthe first processing level/stage #print will be managed \nand @print at the next level/stage. \n  \n@print \"Output Processing ...\" \n#print \"Input Processing ...\" \n \nAn important process in relation to this stage is \nto write on to destination various types of information \nand values on different bytes size representation: \n \ndX v1 [[,] v2 ...] \n \nas the usual low-level specific data instructions, where X \ncan be b for byte, w for word (two bytes), d for double \nword (four bytes), p for three words (six bytes), q for \nquad words (eight bytes) etc. If we want to reserve for \ninstance only upper case chars one may use \n \nI = 'A' \n@while I <= 'Z' \n  db I \n  I = I + 1 \n@endw \n \nwhere in the output will be write in this case ABCD..Z. \nIn the same way it can be write in the output repeated or \nreserved multiple data units through \n \nrX N [[,] V] \n \nwhere X has the same meaning as in the above \ndefinition, N is the number of allocation units and V (if \npresent) is the values to fill each unit. \nThe connection between source information or \nsource \nlanguage \nelements \nand \nthe \ndestination \ncorrespondents is performed through combining source \ndirectives or instructions with destination ones. For \nexample, in the simplest case of translation from \nassembly language to machine language, “No Operation \nPerformed” - nop instruction can have the following \nsimply implementation for Intel (x86) system \n \nclass nop {db 0x90} \n \nor one of the following implementations for the \nARM/RISCV systems \n \nclass nop {dd 0}//andeq r0, r0, r0 \nclass nop {dd 0xE1A00000}//mov r0, r0 \nclass nop {dd 0x13}//addi x0, x0, 0 \n \nIn the same way can be implemented and managed the \ninstructions related to any languages for translating any \ntypes of language elements such as: literals, operations, \nexpressions, phrases etc. The present implementation \napproaches can be used to implement any type of \ntranslator and also can provide clues for completing \nsome source or destination languages with elements that \nallow \nthem to be \nflexible, versatile, optimally \nimplementable etc [8]. \n \nConclusions \n \nThe general formalism related to the description \nand implementation of general translators has been \nproposed. The formal descriptions of the translators were \ncorrelated with computer implementative elements by \ngeneralizing some computational concepts and systems \nin order to facilitate the translation of any source \ninformation, described according to the source language \nrules, into destination information structured according \nto other language rules. \nThe most difficult problem related to the \ntranslation of some arbitrary languages through general \nparsing rules by splitting source information into its \nbasic components was solved by generalizing and \njoining \nthe \nconcepts \nof \nfunction/procedure \nand \nobject/class into a hyperclass with the role of \nhyperfunction that accepts arguments with any type of \nseparator, separators that can be source language \noperators/delimiters/punctuators, \nin \nthis \nway \nthe \nsyntactic components source splitting issue being \nresolved. \nThe proposed general translator system is based \non compiler generalization through incorporating and \ndetailing source and destination language operations by \nusing two levels of processing related to the source and \ndestination information specific transformations, with \nthe related control and processing instructions. The two \nlevels of processing are proposed in order to cover the \ngeneral translations cases, but for certain translation, it is \npossible that some instructions from a certain level to not \nbe explicit necessary as is in the case of some usual \ncompilers where they are used implicitly or as auxiliary \nor external operations. \nThe presented characteristics of the general \ntranslators allow procession of information within the \ncomputing systems of any type of natural language or \nprogramming/script \nlanguage \nfacilitating \nimplementations through any operating systems or \nprocessors. Some of the presented elements may \ncontribute to optimization of some usual translators such \nas compilers and related languages as well as for more \nrelevant translations of natural languages descriptions. \n \n7 \n \nReferences \n \n[1] N. Chomsky, Three models for the description of \nlanguage, IRE Transactions on Information Theory \n2, 113-124 (1956). \n[2] C. E. Shannon, A Mathematical Theory of \nCommunication, Bell System Technical Journal 27, \n379-656 (1948). \n[3] A. M. Turing, On computable numbers, with an \napplication \nto \nthe \nEntscheidungsproblem, \nProceedings of the London Mathematical Society \n42, 230-265 (1936). \n[4] J. von Neumann, First Draft of a Report on the \nEDVAC (Electronic Discrete Variable Automatic \nComputer), Moore School of Electrical Engineering, \nUniversity of Pennsylvania (1945). \n[5] D. M. Ritchie, The Development of the C Language, \nACM 28, 201-208 (1993). \n[6] T. X. Sun, X. Y. Liu, X. P. Qiu, X. J. Huang, \nParadigm shift in natural language processing, \nMachine Intelligence Research 19, 169-183 (2022). \n[7] D. Khurana, A. Koli, K. Khatter, S. Singh, Natural \nlanguage processing: State of the art, current trends \nand challenges, Multimedia Tools and Applications, \n1-32 (2022). \n[8] I. I. Petrila, @C – augmented version of C \nprogramming language, arXiv:2212.11245 (2022). \n[9] M. Maronese, L. Moro, L. Rocutto, E. Prati, \nQuantum \ncompiling, \nQuantum \nComputing \nEnvironments, 39-74 (2022). \n[10] M. De Coster, D. Shterionov, M. Van Herreweghe, \nJ. Dambre, Machine Translation from Signed to \nSpoken Languages: State of the Art and Challenges, \narXiv:2202.03086 (2022). \n[11] K. Georgiou, Z. Chamski, A. A. Garcia, D. May, K. \nEder, Lost in translation: Exposing hidden compiler \noptimization opportunities, The Computer Journal \n65, 718-735 (2022). \n[12] B. Haddow, R. Bawden, A. V. M. Barone, J. Helcl, \nA. \nBirch, \nSurvey \nof \nlow-resource \nmachine \ntranslation, Computational Linguistics 48, 673-732 \n(2022). \n[13] Ö. Özerk, C. Elgezen, A. C. Mert, E. Öztürk, E. \nSavaş, \nEfficient \nnumber \ntheoretic \ntransform \nimplementation \non \nGPU \nfor \nhomomorphic \nencryption, The Journal of Supercomputing 78, \n2840-2872 (2022). \n[14] X. Tang, Z. Zhang, W. Xu, M. T. Kandemir, R. \nMelhem, J. Yang, Enhancing Address Translations \nin \nThroughput \nProcessors \nvia \nCompression, \nProceedings of the ACM International Conference \non \nParallel \nArchitectures \nand \nCompilation \nTechniques 20, 191-204 (2020). \n[15] F. Tang, D. Huang, F. Wang, Z. Chen, Universal \nSignature Translators, International Journal of \nNetwork Security 23, 1058-1064 (2021). \n[16] Y. Hao, Q. Li, C. Fan, F. Wang, Data storage based \non DNA, Small Structures 2, 2000046 (2021). \n[17] M. Li, Y. Liu, X. Liu, Q. Sun, X. You, H. Yang, Z. \nLuan, L. Gan, G. Yang, D. Qian, The deep learning \ncompiler: \nA \ncomprehensive \nsurvey, \nIEEE \nTransactions on Parallel and Distributed Systems \n32, 708-727 (2020). \n[18] R. P. Feynman, Quantum mechanical computers, \nFoundations of Physics 16, 507-531 (1986). \n[19] R. A. Frost, Realization of Natural-Language \nInterfaces Using Lazy Functional Programming, \nACM Computing Surveys 38, 11-es (2006). \n[20] J. M. Shine, M. Breakspear, P. T. Bell, K. A. \nEhgoetz Martens, R. Shine, O. Koyejo, O. Sporns, \nR. A. Poldrack, Human cognition involves the \ndynamic \nintegration \nof \nneural \nactivity \nand \nneuromodulatory systems, Nature Neuroscience 22, \n289-296 (2019). \n[21] D. Agarwal, Y. Baba, P. Sachdeva, T. Tandon, T. \nVetterli, A. Alghunaim, Accurate and Scalable \nMatching of Translators to Displaced Persons for \nOvercoming Language Barriers, arXiv:2012.02595 \n(2020). \n[22] W. Merrill, Formal language theory meets modern \nNLP, arXiv:2102.10094 (2021). \n[23] P. Lu, R. Gong, S. Jiang, L. Qiu, S. Huang, X. \nLiang, S. C. Zhu, Inter-gps: Interpretable geometry \nproblem solving with formal language and symbolic \nreasoning, arXiv:2105.04165 (2021). \n[24] Y. Hao, D. Angluin, R. Frank, Formal language \nrecognition \nby \nhard \nattention \ntransformers: \nPerspectives from circuit complexity, Transactions \nof the Association for Computational Linguistics 10, \n800-810 (2022). \n[25] S. Longo, Generative grammars for branched \nmolecular structures, Chemical Physics Letters 809, \n140151 (2022). \n[26] T. Æ. Mogensen, Programming Language Design \nand Implementation, Springer Nature, 2022. \n \n",
  "categories": [
    "cs.CL",
    "cs.FL",
    "cs.PL",
    "cs.SC"
  ],
  "published": "2022-12-16",
  "updated": "2022-12-22"
}