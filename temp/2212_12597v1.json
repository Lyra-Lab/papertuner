{
  "id": "http://arxiv.org/abs/2212.12597v1",
  "title": "Deep Causal Learning for Robotic Intelligence",
  "authors": [
    "Yangming Li"
  ],
  "abstract": "This invited review discusses causal learning in the context of robotic\nintelligence. The paper introduced the psychological findings on causal\nlearning in human cognition, then it introduced the traditional statistical\nsolutions on causal discovery and causal inference. The paper reviewed recent\ndeep causal learning algorithms with a focus on their architectures and the\nbenefits of using deep nets and discussed the gap between deep causal learning\nand the needs of robotic intelligence.",
  "text": "Deep Causal Learning for Robotic Intelligence \nYangming Li \n \n \n \nAbstract \nThis invited review discusses causal learning in the context of robotic intelligence. The paper introduced the psychological \nfindings on causal learning in human cognition, then it introduced the traditional statistical solutions on causal discovery and \ncausal inference. The paper reviewed recent deep causal learning algorithms with a focus on their architectures and the \nbenefits of using deep nets and discussed the gap between deep causal learning and the needs of robotic intelligence. \n \nIndex Terms \nDeep Causal Learning, Robotic Perception, Complementary Perception, Robotics, Causal Learning, Deep Learning \n \nI. INTRODUCTION \nIntelligent Robots infer knowledge about the world from sensor perception, estimate status, model the world, and plan \nand execute tasks. Although intelligent robots have achieved remarkable progress in the past two decades, it is still \nchallenging to improve the reliability of intelligent robots in the real world. The challenges roots in both the wide variance \nof environments and robotic tasks and the uncertainties of the world, sensor observation, the models and the status, and \nthe execution of tasks. \nState of art robotic systems achieve intelligence from two types of methods. One method is to transplant knowledge, \nincluding proven theory, established models, and coded rules, to robots. This type of achieved intelligence has predictable \nperformance, is explainable, but lacks adaptiveness, their complexity grows exponentially with respect to the complexity \nof tasks. The other method is to learn knowledge from observations. This type of achieved intelligence is the opposite of \nthe previous type, as it is salable but difficult to explain. \nHuman beings, or even animals, learn the world effortlessly from an early age and build up prior knowledge quickly to \nmake causal decisions in daily life. Let’s use the perception of an object’s physical properties as an example. Even infants \ndemonstrate their instinctual behavior of inspecting a new toy with their hands and eyes in tandem for learning the toy’s \nproperties[1]. Robots, in comparison, still have problems understanding and operating the most commonly used objects in \ndaily life. As clear as causality is critical from low-level visual perception to high-level decision-making, state of art robots \nrarely establish the causal relationship and utilize the relationship to improve intelligence. But there are examples that \n“causal” relationships improve robotic intelligence. For example, Simultaneous Localization and Mapping (SLAM) explicitly \nutilizes the fact that causal relationships of robot movements causally changing observations and use a Bayesian network \nto improve mapping and localization simultaneously[2]. \nCausal learning consists of the causal discovery and causal inference. Classical causal learning methods. Causal discovery \nlearns cause-effect relationships, and causal inference estimates how much the changes in factors impact other factors. \nTraditional causal learning algorithms mainly use statistical theories and tools. With the development of deep learning \ntechnology, there are trends that use deep learning to improve causal learning with high-dimensional data and big data \nand trends that use causal learning to improve deep learning model expandability, extrapolation capability, and explainability. \nAlthough these emerging techniques are not developed and tested on intelligent robots yet, they do have great potential \nto improve robotic intelligence and expand the applicability of intelligent robots. This paper incompletely but systematically \nreviews causal cognition, causal learning, and deep causal learning, and discusses the need for deep causal learning in \nrobotic intelligence. The rest of the paper is organized as follows: Section 2 briefly introduces causal cognition from the \npsychological perspective, section 3 presents the statistical causal discovery and causal inference, section 4 discusses \ndeep causal learning for robotic intelligence, and the last section concludes the paper. \n \nII. CAUSAL COGNITION AND INTELLIGENCE \nRegardless of the debut on cognition mechanism, modern physiological studies generally support that human subjects \ncognize causal regularities is more sophisticated than that of any other animal on the planet[3]. Causal cognition has major \ndifferences with associative learning, as it can improve inferences from nonobvious and hidden causal relationships[4]. \nLearning causal relations is critical to human beings [4, 5], as it confers an important advantage for survival[6, 7]. \nRoCAL, Rochester Institute of Technology, Rochester, NY, USA, 14623 \nIt is clear that to achieve or avoid an outcome, one may want to predict with what probability an effect will occur given \nthat a certain cause of the effect occurs. It remains mysterious as to how the input noncausal empirical observations \nof cues and outcomes yield output values. Studies have shown that causal cognition emerges early in development[6]. \nResearchers are amazed by how children learn so much about the world so quickly and effortlessly[8, 9]. Studies have \ndemonstrated that infants, as young as 4.5 months, register particular aspects of physical causality[5, 10–12], toddlers \nrecognize various causal relations in the psychological domain, especially about others’ desires and intentions[13, 14], and \npreschoolers understand that biological and psychological events can rely on nonobvious, hidden causal relations [15, 16]. \nAdults use substantive prior knowledge about everyday physics and psychology to make new causal judgments[17]. \n \nIII. CAUSAL LEARNING \nAs presented in the previous section, causal learning is associated with human intelligence and is widely studied. Traditional \ncausal learning uses statistical methods to discover knowledge from data and perform causal inference. These methods \nare widely used in the field of medical science, economics, epidemiology, etc, but rarely used in the domain of intelligent \nrobotics[18, 19]. \n \nA. Causal Discovery \nCausal discovery learns the causal structure that represents the causality between observations X, treatments t, and \noutcomes y. \nTraditional causal discovery relies on statistically verifying potential causal relationships or estimating functional equations \nto establish causal structures. Generally, there are four types of representative algorithms for traditional causal discovery: \nthe constraint-based algorithms and the score-based algorithms, which rely on statistical verification, the functional causal \nmodel-based algorithms, which rely on functional estimation, and the hybrid algorithms, which fuse multiple algorithms[18]. \n1) constraint-based algorithms: Constraint-based algorithms analyze conditional independence in observation data to \nidentify causal relationships. This family of algorithms often uses statistical testing algorithms to determine the conditional \nindependence of two variables, given their neighbor nodes, then further determine the direction of the causality. \nMathematically, we can use three variables X, Y , and Z to explain Constraint-based algorithms. The causal relationship \nis verified by conditional independence, for example, X ⊥ Y | Z, which is equivalent to zero conditional information \nI[X; Y | Z] = 0. This is defined as Faithfulness in causal learning, as explained in Definition 3.1. If the three variables are \ndiscrete, χ2 and G2 can verify the conditional independence based on the contingency table of X, Y , and Z. If the three \nvariables are linear and multivariate Gaussian, we can verify the conditional indecency by test if the partial correlation is \nzero. For other circumstances, it often needs extra assumptions to ensure the verification is computationally tractable. \nDefinition 3.1: (Faithfulness). Conditional independence between a pair of variables, xi ⊥ xj|x− for xi /= xj, x− ⊆ X\\{xi, xj}, \ncan be estimated from a dataset X iff x− d-separates xi and xj in the causal graph G = (V, E). \nThe conditional independence is symmetric, and additional tests are required to determine the orientations of edges. \nWhen X ⊥ Y | Z, there are three possible graphical structures, including two chains (X ← Z ← Y and X → Z → Y ) \nand a fork X ← Z → Y . The determination of which structures are induced based on the adjacency among variables, \nthe background knowledge, etc. When X ⊥/ ⊥ Y | Z it is a collision structure (X → Z ← Y ). \nConstraint-based algorithms used assumptions to improve efficiency and effectiveness for causal discovery from data. \nFor example, the Peter-Clark algorithm assumes i.i.d. sampling and no latent confounders, which prunes edges between \nvariables by testing conditional independence based on observations data, and determines and propagates the orients to \nform the directed acyclic graph (DAG)[20]. The inductive causation algorithm assumes stable distributions (Definition 3.2), \ntests conditional independence to find the associative relationship between variables, finds collision structures, determines \norients based on variable’s adjacency, and propagates directions[21]. \nDefinition 3.2: (Stable Distribution). a distribution is stable if a linear combination of two independent random variables with this \ndistribution has the same distribution, up to location and scale parameters. \nOther constraint-based algorithms aim to relax the assumptions and extend the causal discovery to other families of \ndistributions [22–24], causal discovery from data with unobserved confounders [18, 25]. \n2) score based algorithms: Score-based algorithms learn causal graphs by maximizing the goodness-of-fit test scores of \nthe causal graph G given observation data X[20]. Because these algorithms replaced the conditional independence tests \nwith the goodness-of-fit tests, they relax the assumption of faithfulness (Definition 3.1) but often increase computational \ncomplexity. This is because the scoring criterion S(X, G) enumerates and scores the possible graphs under parameter \nadjustments. For example, the popular Bayesian Information Criterion adopts the score function S(X, G) = log P (X|θˆ, G)− \nJ/2 log(n) to find the graph that maximizes the likelihood of observing the data, while the number of parameters and the \nsample size is regularized, where θˆ is the Maximum Likelihood Estimation of the parameters and J and n denote the \nnumber of variables and the number of instances, respectively[26]. \nIt is not tractable to score all possible causal graphs given observation data because it is NP-hard[27] and NP-complete [28]. \nIn practice, score-based algorithms use heuristics to find a local optimum[29, 30]. For example, the Greedy Equivalence \nSearch algorithm uses Bayesian Dirichlet equivalence score SBD: \nJ \nqj \nrj \nS \n(X, G) = log IT \n0.001(rj −1)qj IT  \nΓ(10/qj) \n IT Γ(10/ri/qi + Njkl) , \n(1) \nDB \nj=1 \n \nk=1 Γ(10/qj + Njk)  \nl=1 \nΓ(10/ri/qi) \nto score a graph G, where rj and qj signify the numbers of configurations of variable xj and the numbers of configurations \nof parent set Pa(xj), respectively, Γ(·) denotes the Gamma function, and Njkl denotes the number of records of xj = k \nand Pa(xj) are in the k-th configuration. \nWidely used score-based algorithms optimize the searching and the scoring process based on the assumptions such as \nlinear-Gaussian models[31], discrete data [32], and sparsity [33]. There are also works on relaxing the assumptions for \ncausal discovery from nonlinear and arbitrarily distributed data [34]. Compared with constraint-based algorithms, score- \nbased algorithms can compare the output models in the space searched for model selection. \n3) Functional Causal Models based algorithms: Functional Causal Models based algorithms represent the causal rela- \ntionship with functional equations (Define 3.3). \nDefinition 3.3: (Functional Equation). a functional equation represents a direct causal relation as y = fθ(X, n), where X is the \nvariables that directly impact the outcome y, n is noise with n ⊥ X, and fθ is the general form of a function. \nCausal discovery with functional equations can be expressed as sorting causal orders (which variables depend on which) \nfrom observation data. We use Linear Non-Gaussian Acyclic Model to explain the process with a simple linear case \nx = Ax + µ, where x denotes the variable vector, A denotes the adjacency matrix, and µ denotes the noise independent \nof x. With this representation, the causal discovery is the equivalent of estimating a strictly lower triangle matrix A that \ndetermines the unique causal order k(xi), ∀xi ∈ mathbfx, which can be performed in the form of Matrix permutation as \ndescribed in [35]. \nFunctional Causal Models based algorithms have demonstrated effectiveness in producing unique causal graphs. For \nexample, the post-nonlinear causal model learns the causal relationship that can be represented by a post-nonlinear \ntransformation on a nonlinear effect of the cause variables and additive noises[36]. This algorithm can be further improved \nwith independent component analysis [37] and relaxed by warped Gaussian process with the noise modeled by the mixture \nof Gaussian distributions[38]. Compared to the constraint-based algorithms and the score-based algorithms, Functional \nCausal Models based algorithms are able to distinguish between different DAGs from the same equivalent class. \n4) hybrid algorithms: Hybrid algorithms combine multiple algorithms to overcome problems that exist in constraint-based \nalgorithms or score-based algorithms. For example, [39] uses the Max-Min Parents and Children algorithm (constrained- \nbased) to learn the skeleton of the causal graph and uses Bayesian scoring hill-climbing search (score-based) to determine \nthe orients of edges. [40] uses the conditional independence test to learn the skeleton of the causal graph and use a \nmetric to search good network structures. \n \nB. Causal Inference \nCausal inference is the process of estimating the changes of outcomes y given treatments t. Before we discuss causal \ninference algorithms, let’s define the metrics (Definition 3.4) for measuring causal inference. ATE, ATT, CATE, and ITE \nmeasure the treatment effects at the population, treated group, a subgroup of a given feature x, and individual levels, \nrespectively. \nDefinition 3.4: (Treatment Effect). \n• Average Treatment Effect (ATE): ATE = E[Y (w = 1) − Y (w = 0)]. \n• Average Treatment Effect on Treated Group (ATT): ATT = E[Y (w = 1) | w = 1] − E[Y (w = 0) | w = 1]. \n• Conditional Average Treatment Effect (CATE): CATE = E[Y (w = 1) | X = x] − E[Y (w = 0)|X = x]. \n• Individual Treatment Effect (ITE): ITEi = Yi(w = 1) − Yi(w = 0). \nCausal inference estimates the treatment effects for specific groups. However, the different distributions of groups and \nthe existence of confounders make the task very challenging. According to the methodological differences, existing \nclassical algorithms for addressing these problems can be grouped into Re-weighting based algorithms, stratification- \nbased algorithms, batching-based algorithms, and tree-based algorithms. \ni=1 \ni \ni=1 \nj \nPotential \nconfounder (x) \nTreatment (T) \nOutput (y) \n \nPropensity score \nbased model \n1) Re-weighting based algorithms: Re-weighting-based algorithms assign appropriate weights to the samples to create \npseudo populations or re-weight the covariates to mitigate the differences in the distributions between the treated groups \nand the control groups. These algorithms are designed to address the selection bias between the treated groups and the \ncontrol groups. \nBoth samples and covariate re-weighting are used to address the selection bias. The inverse propensity weighting algorithm \nis one of the pioneering works on re-weighting samples. This algorithm uses the Propensity Scores (Definition 3.5) to find \nthe appropriate weights for samples as r = T/e(x) + (1 − T )/(1 − e(x)), where T is the treatment. \nDefinition 3.5: (Propensity Score). Propensity Score e(x) is the conditional probability of assignment to a particular treatment \ngiven a vector of observed covariates e(x) = Pr(T = 1|X = x). \nWith the re-weighting, the ATE is defined as: ATˆ E = 1/NT \n'[',  NT TiY F /eˆ(x) − 1/NC \n'[',  NC (1 − Ti)Y F /(1 − eˆ(x)). This \nmethod is sufficient to remove bias, however, heavily relies on the correctness of propensity scores[41]. Along the lines of \npropensity score-based sample re-weighting, the Doubly Robust Estimator combines the propensity score weighting with \nthe outcome regression to remain unbiased as long as the propensity score or outcome regression is correct(Fig. 1)[41], \nthe overlap weights algorithm down-weighting the units in the tails of the propensity score distribution to emphasizes the \ntarget population with the most overlap in observed characteristics to overcome the extreme propensity score problem \n[42]. \n \nFig. 1: Doubly Robust Estimator. \n \nThe covariate re-weight algorithms learn sample weights from data through regression. To re-weight covariate, [43] uses \na maximum entropy re-weighting scheme to calibrate sample weights to match the moments of the treated group and the \ncontrol group and minimizes information loss by keeping weights close to the base weights. \nThere are also algorithms that balance distributions with both covariate and sample re-weighting. Covariate balancing \npropensity score estimates the propensity score by solving: E[Wix˜i/e(xi; β) + (1 − Wi)x˜i/(1 − e(xi; β))] to measure the \nprobability of being treated and covariate balancing score and improves the empirical performance of propensity score \nmatching[44]. Data-Driven Variable Decomposition (D2VD) balances distribution by automatically decomposing observed \nvariables confounders, adjusted variables, and irrelevant variables[45], Differentiated Confounder Balancing (DCB) selects \nand differentiates confounders, and re-weighting both the sample and the confounders to balance distributions [46]. \n2) Stratification based algorithms: Stratification-based algorithms split observation into subgroups, which are similar under \ncertain measurements. With subgroups that have balanced distributions, ATE is estimated as τˆstrat = \n'[',  j = 1J q(j)Y¯t(j) − Y¯c(j). \nFor example, if a model can predict the strata in which subjects always stay in the study regardless of which treatment \nthey were assigned, then the data from this strata is free of selection biases[47, 48]. The stratification can be performed \non samples on the basis of the propensity score to improve the estimation robustness, as explained in the marginal \nmean weighting through stratification algorithm [49]. The stratification algorithms can also be combined with propensity \nscore-based algorithms as a prepossessing of data to remove imbalances of pre-intervention characteristics [50]. \n3) Matching based algorithms: Matching-based algorithms use specific distance measurements to match samples in \nthe treatment group with ones in the control group to estimate the counterfactuals and reduce the estimation bias of \nconfounders. Matching-based algorithms require the definition of distance metrics and the selection of matching algorithms. \nEuclidean distances and Mahalanobis distances are commonly used as distance metrics in the original data space, while \ntransformations, such as propensity score-based transformation, and observed outcome information are commonly used in \nthe transformed feature space [19, 51]. For matching algorithms, Nearest Neighbor, Caliper, Stratification, and Kernel-based \nmethods are all widely adopted[18]. It is worth noticing that matching-based algorithms can be used in data selection, as \nwell as experimental design and performance. The latter uses matching to identify subjects whose outcomes should be \ncollected [52, 53], which potentially reduces costs and difficulty in collecting effective data. \n4) Tree-based methods: A tree structure naturally divides data into disjoint subgroups. While the subgroups have similar \ne(x), the estimation of the treatment effect is unbiased. Bayesian Additive Regression Trees (BART), a Bayesian “sum-of- \ntrees” model, is a flexible approach to fitting a variety of regression models while avoiding strong parametric assumptions. \nWith BART, the treatment y is the sum of subgroups as y = g(x; T1, θ1) + · · · + g(x; Tn, θn) + σ, where σ is Gaussian \n6 \n \n \nWhite noise[54]. Similarly, the Classification And Regression Trees (CART) algorithm also splits data into classes that \nbelong to the response variable. Being different from BART, CART recursively partitions the data space and fits a simple \nprediction model for each partition[55]. Causal Forests ensemble multiple causal trees to achieve a smooth estimation \nof CATE. Causal Forests are based on Breiman’s random forest algorithm and maximize the difference across splits in \nthe relationship between an outcome variable and a treatment variable for revealing how treatment effects vary across \nsamples[56]. \n \n \n \nA. Deep Causal Learning \nIV. DEEP CAUSAL LEARNING FOR ROBOTIC PERCEPTION \nDeep learning (DL) successfully attracted researchers from all fields as DL demonstrated the power and the simplicity \nof learning from data[57]. The majority of existing DL algorithms use specialized architecture to establish end-to-end \nrelationships from observation data, for example, Convolutional Neural Networks (CNN) for data with spatial locality, \nRecurrent Neural Networks (RNN) for data with sequential or temporal structure, Transformers for data with context \ninformation, Autoencoders for data need compressed representation, Generative Adversarial Networks for data need \ndomain adaption[58–62]. Despite the remarkable success DL achieved, some challenges remain in DL, such as model \nexpandability, extrapolation capability, and explainability. Causal Learning (CL), on the other hand, discovers knowledge, \nexplains prediction, and has extendable structures, but struggles with high dimensional data and scalability problems. It is \nencouraging to compliment DL with CL and vers versa. Actually, recent studies make great progress and demonstrated \nCausal Deep Learning has advantages as they can use prior knowledge to disentangle modeling problems and reduce \ndata needs[63–65], have superior performance on extrapolating unseen data [66, 67], modularize learning problems, \nincrementally learn from multiple studies[68–70], and demonstrate its potential as a solution to artificial general intelli- \ngence [71–73]. \nBelow, we introduce some of the representative works in plain language, with a focus on the network architecture and \nthe benefits of using the architecture. Because the algorithms we reviewed share many common characteristics, such as \nmost of them use two or more neural networks, most of the representation learning involves CNN, etc., we categorize the \nalgorithms into the following categories to maximize the uniqueness among the categories. \n1) Using DL for learning representation: Balancing Neural Networks and Balancing Linear Regression is one of the \npioneer works that use deep neural networks to solve the problem of causal learning from high dimensional data[74]. \nThese algorithms learn a representation g : X → Rd through deep neural networks or feature re-weighting and selection, \nthen based on the features g(X) learn the causal effect h : Rd × T → R. These models learn balanced representations \nthat have similar distributions among the treated and untreated groups and demonstrated effectiveness in cases that have \none treatment. \nSimilarity preserved Individual Treatment Effect (SITE) uses two networks to preserve local similarity and balances data \ndistributions simultaneously[75]. The first network is a representation network, which maps the original pre-treatment \ncovariate space X into a latent space Z. The second network is a prediction network, which predicts the outcomes based \non the latent variable Z. The algorithm uses Position-Dependent Deep Metric and Middle Point Distance Minimization to \nenforce two special properties on the latent space Z, including the balanced distribution and preserved similarity. Adaptively \nsimilarity-preserved representation learning method for Causal Effect estimation (ACE) preserves similarity in represen- \ntation learning in an adaptive way for extracting fine-grained similarity information from the original feature space and \nminimizes the distance between different treatment groups as well as the similarity loss during the representation learning \nprocedure[76]. ACE applied Balancing and Adaptive Similarity preserving (BAS) regularization to the representation space. \nThe BAS regularization consists of distribution distance minimization and adaptive pairwise similarity preserving, therefore, \ndecreasing the ITE estimation error. \n[77] presented a theory and an algorithmic framework for learning to predict outcomes of interventions under shifts in \ndesign—changes in both intervention policy and feature domain. This framework combines representation learning and \nsample re-weighting to balance source and target designs, emphasizing information from the source sample relevant to \nthe target. As the result, this framework relaxes the strong assumption of having a well-specified model or knowing the \npolicy that gave rise to the observed data. \n2) End-to-end deep causal inference: [78] Treatment-Agnostic Representation Networks (TARNET) proposed to estimate \nITE based on the Rubin potential outcomes framework under the assumption of strong ignorability. This algorithm uses \nIntegral Probability Metrics to measure distances between distributions and derives explicit bounds for the Wasserstein \nand Maximum Mean Discrepancy (MMD) distances. Therefore, this algorithm is an end-to-end regularized minimization \nprocedure that fits the balanced representation of the data and a hypothesis for the outcome. Based on this work, [79] \nproposed a context-aware importance sampling re-weighing scheme to estimate ITEs, which addresses the distributional \nshift between the source (outcome of the administered treatment, appearing in the observed training data) and target \n7 \n \ni \ni \n \n \np(X|z) \n \n \np(y|t = 0, z) \n \n \np(y|t = 1, z) \n \n \n \n \n(a) Model Net. \n(b) Inference Net. \nFig. 2: Causal Effect Variational Autoencoder[82]. \n \n \n(outcome of the alternative treatment) that exists due to selection bias. Perfect Matching augments samples within \na minibatch with their propensity-matched nearest neighbors to improve inference performance in settings with many \ntreatments[80]. Perfect Matching is compatible with other architectures, such as the TARNET architecture, and extends \nthese architectures to any number of available treatments. Perfect Matching also uses the nearest neighbor approximation \nof Precision in the Estimation of Heterogenous Effect with multiple treatments to select models without requiring access \nto counterfactual outcomes. \n[81] models the inference of individualized causal effects of a treatment as a multitask learning problem. The algorithm \nuses a propensity network and a potential outcomes network to estimate ITE (Definition 3.4). The propensity network is a \nstandard feed-forward network and is trained separately to estimate the propensity score e(xi) (Definition 3.5) from (xi, ti). \nThrough assigning “simple models” to subjects with very high or very low propensity scores (e(xi) close to 0 or 1), and \n“complex models” to subjects with balanced propensity scores (e(xi) close to 0.5), it alleviates the selection bias problem. \nThe potential outcomes network is a multitask network that models the potential outcomes E[Y (1)|xi and E[Y (0)|xi as \ntwo separate but related learning tasks, therefore, the treatment assignments and the subjects’ characteristics are fully \nutilized. \n3) Autoencoder based algorithms: Causal Effect Variational Autoencoder (CEVAE) uses Variational Autoencoders (VAE) \nstructures to estimate individual treatment effects[82]. The algorithm uses an inference network (Fig. 2b) and a model \nnetwork (Fig. 2a) to simultaneously estimate the unknown latent space summarizing the confounders and the causal effect, \nbased on latent variable modeling. Because the algorithm uses the two networks to utilize both the causal inference with \nproxy variables and latent variable modeling, its performance is competitive with the state-of-the-art on benchmark datasets \nand has improved robustness on the problems with hidden confounders. \nThe Deep-Treat algorithm uses two networks for constructive effective treatment policies by addressing the problems of \nthe observed data being biased and counterfactual information being unavailable[83]. The first network is a bias-removing \nauto-encoder, which allows the explicit trade-off between bias reduction and information loss. The second network is a \nfeedforward network, which constructs effective treatment policies on the transformed data. \nTask Embedding based Causal Effect Variational Autoencoder (TECE-VAE) scales CEVAE with task embedding for \nestimating individual treatment effect using observational data for the applications that have multiple treatments[84]. TECE- \nVAE also adopts the Encoder-Decoder architecture. The encoder network takes input X to generate distribution for z. The \ndecoder network uses z to reconstruct features X, treatments t, and outcomes y. TECE-VAE uses information across \ntreatments and is robust to unobserved treatments. \nThe Conditional Treatment-Adversarial learning based Matching method (CTAM) uses treatment-adversarial learning to \neffectively filter out the nearly instrumental variables for processing textual covariates[85]. CTAM learns the representations \nof all covariates, which contain text variables, with the treatment-adversarial learning, then performs the nearest neighbor \nmatching among the learned representations to estimate the treatment effects. The conditional treatment adversarial \ntraining procedure in CTAM filters out the information related to nearly instrumental variables in the representation space, \ntherefore, the treatment discriminator, the representation learner, and the outcome predictor work together in the adversarial \nlearning way to predict the treatment effect estimation with text covariates. To be more specific, the treatment discriminator \nis trained to predict the treatment label, while the representation learner works with the outcome predictor for fooling the \ntreatment discriminator. \nReducing Selection Bias-net (RSB-net) proposed to use two networks to address the selection bias problem[86]. The first \n \n \n \n \n \n \n \n \n8 \n \n \nnet is an auto-encoder that learns the representation. This auto-encoder uses a Pearson Correlation Coefficient (PCC) \nbased on regularized loss and explicitly differentiates the bias variables with the confounders that affect treatments and \noutcomes and the variables that affect outcomes alone. Therefore, the confounders and the variables affecting outcomes \nare fed into the second network, which uses the branching structure network to predict outcomes. \nVariational Sample Reweighting (VSR) algorithm uses a variational autoencoder to remove the confounding bias in the \napplications with bundle treatments [87]. VSR simultaneously learns the encoder and the decoder by maximizing the \nevidence lower bound. \n4) Generative Adversarial Nets-based algorithms: Generative Adversarial Nets for inference of Individualized Treatment Ef- \nfects (GANITE), as suggested by the name, inferring ITE based on the Generative Adversarial Nets (GANs) framework[88]. \nThe algorithm uses a counterfactual generate, G, to generate potential outcome vector y˜ based on features X, treatments \nt, and factual outcome yf . Then the generated proxies are passed to an ITE generator that generates potential outcome yˆ \nbased on feature X. As the Generative Adversarial Nets[62], GANITE uses a discriminator for G, DG, and a discriminator \nfor I, DI to boost the training performance for the generators. DG maps pairs (X, y¯) to vectors in [0, 1]k with the i−th \ncomponent to representing the probability that the i−th component of y˜ is the factual outcome. Similarly, DI maps a pair \nx, y∗ to [0, 1] representing the probability of y∗ being from the data D˜ .  \nCausal Effect Generative Adversarial Network (CEGAN) utilizes an adversarially learned bidirectional model along with a \ndenoising auto-encoder to address the confounding bias caused by the existence of unmeasurable latent confounders[89]. \nCEGAN has two networks, a prediction network (consisting of a generator, a prediction decoder, an inference net, and \na discriminator), and a reconstruction network (a denoising autoencoder, whose encoder is used as the generator in the \nprediction network). \nSyncTwin proposed to construct a synthetic twin that closely matches the target in representation to exploit the longitudinal \nobservation of covariates and outcomes[90]. SyncTwin uses the sequence-to-sequence architecture with an attentive \nencoder and an LSTM decoder to learn the representation of temporal covariates, then it constructs a synthetic twin to \nmatch the target in representations for controlling estimation bias. The reliability of the estimated treatment effect can be \nassessed by comparing the observed and synthetic pre-treatment outcomes. \nGenerative Adversarial De-confounding (GAD) algorithm estimates outcomes of continuous treatments by eliminating the \nassociations between covariates and treatments[91]. GAD first randomly shuffles the value of covariate X into X′ in order \nto ensure X′ ⊥ T , where T is the treatments. Second, GAD re-weighting samples in X so the distribution of X is identical \nto X′. GAD then eliminated the confounding bias induced by the dependency between T and X. \nAdversarial Balancing-based representation learning for Causal Effect Inference (ABCEI) uses adversarial learning to \nbalance the distributions of covariates in the latent representation space to estimate the Conditional Average Treatment \nEffect (CATE)[92]. ABCET uses an encoder that is constrained by a mutual information estimator to minimize the information \nloss between representations and input covariates to preserve highly predictive information for causal effect inference. The \ngenerated representations are used for discriminator training, mutual information estimation, and prediction estimation. \n5) Recurrent Neural Networks-based algorithms: Recurrent Marginal Structural Network (RMSM) uses recurrent neural \nnetworks to forecast a subject’s response to a series of planned treatments[93]. RMSM uses the encoder-decoder \narchitecture. The encoder learns representations for the subject’s current state by using a standard LSTM to predict \none-step-ahead outcome (Ytˆ+2) given observations of covariates and actual treatments. The decoder forecast treatment \nresponses on the basis of planned future actions by using another LSTM to propagate the encoder representation forwards \nin time. \nCounterfactual Recurrent Network (CRN) uses recurrent neural network-based encoder-decoder to estimate treatment \neffects over time [94]. The encoder uses domain adversarial training to build balancing representations of the patient \nhistory for maximizing the loss of the treatment classifier and minimizing the loss of the outcome predictor. The decoder \nupdates the outcome predictor to predict counterfactual outcomes of a sequence of future treatments. \nTime Series Deconfounder recurrent neural network architecture with multitask-output for leveraging the assignment of \nmultiple treatments over time and enabling the estimation of treatment effects in the presence of multi-cause hidden \nconfounders[95]. The algorithm takes advantage of the patterns in the multiple treatment assignments over time to infer \nlatent variables that can be used as substitutes for the hidden confounders. It first builds a factor model over time and \ninfers latent variables that render the assigned treatments conditionally independent; then, it performs causal inference \nusing these latent variables that act as substitutes for the multi-cause unobserved confounders. \n6) Transformer-based algorithms: CETransformer uses transformer-based representation learning to address the problems \nof selection bias and unavailable counterfactual[96]. CETransformer contains three modules, including a self-supervised \nTransformer for representation learning which learns the balanced representation, a Discriminator network for adversarial \n9 \n \n \nlearning to progressively shrink the difference between treated and control groups in the representation space, and outcome \nprediction that uses the learned representations to estimate all potential outcome representations. \n7) Multiple-branch networks and subspaces: Dose Response Network (DRNet) uses neural networks to estimate individual \ndose-response curves for any number of treatments with continuous dosage parameters[97]. DRNet consists of shared \nbase layers, k intermediary treatment layers, and k ∗ E heads for the multiple treatment setting, where k denotes the \nnumber of treatments and E defines the dosage resolution. The shared base layers are trained on all samples, the \ntreatment layers are only trained on samples from their respective treatment category, and a head layer is only trained \non samples that fall within its respective dosage stratum. \nDisentangled Representations for CounterFactual Regression (DR-CFR) proposed to disentangle the learning problem by \nexplicitly identifying three categories of features, including the ones that only determine treatments, the ones that only \ndetermine outcomes, and the confounders that impact both treatments and outcomes[98]. Three representation learning \nnetworks are trained to identify each of the three categories of factors, and the identified factors are fed into two regression \nnetworks for identifying two types of treatments and two logistic networks to model the corresponding behavior policy. \nDecomposed Representations for CounterFactual Regression (DeR-CFR) proposed to disentangle the learning problem \nby explicitly dividing covariants into instrumental factors, confounding factors, and adjustment factors [99]. DeR-CFR has \nthree decomposed representation networks for learning the three categories of latent factors, respectively, has three \ndecomposition and balancing regularizers for confounder identification and balancing of the three categories of latent \nfactors, and has two regression networks for potential outcome prediction. \nNeural Counterfactual Relation Estimation (NCoRE) explicitly models cross-treatment interactions for learning counter- \nfactual representations in the combination treatment setting[100]. NCoRE uses a novel branched conditional neural \nrepresentation and consists of a variable number of shared base layers with k intermediary treatment layers which are \nthen merged to obtain a predicted outcome. The shared base layers are trained on all samples and serve to model cross- \ntreatment interactions, and the treatment layers are only trained on samples from their respective treatment category and \nserve to model per-treatment interactions. \nSingle-cause Perturbation (SCP) uses a two-step procedure to estimate the multi-cause treatment effect[101]. The first \nstep augments the observational dataset with the estimated potential outcomes under single-cause interventions. the \nsecond step performs covariate adjustment on the augmented dataset to obtain the estimator. \n[102] presented three end-to-end learning strategies to exploit structural similarities of an individual’s potential outcomes \nunder different treatments to obtain better estimates of CATE in finite samples. The three strategies regularize the difference \nbetween potential outcome functions, reparametrize the estimators, and automatically learn which information to share \nbetween potential outcome functions. \nDeep Orthogonal Networks for Unconfounded Treatments(DONUT) proposes a regularizer that accommodates uncon- \nfoundedness as an orthogonality constraint for estimating ATE[103]. The orthogonality constraint is defined as < Y (t) − \nf (X, t) >, T − E[T | X = x]), where < ˙, >˙  is the inner product. \nSubspace learning-based Counterfactual Inference (SCI) proposed to learn in a common subspace, a control subspace, \nand a treated subspace to improve the performance of estimating causal effect at the individual level[104]. SCI learns the \ncontrol subspace to investigate the treatment-specific information for improving the control outcome inference, learns the \ntreated subspace to retain the treated-specific information for improving the estimation of treated outcomes, and learns \ncommon subspace to share information between the control and treated subspaces for extracting the cross-treatment \ninformation and reducing the selection bias. \n8) Combining DL with statistical regulators and kernels: Varying Coefficient neural Network (VCNet) proposed a neural \nnetwork and a targeted regularization to estimate the average dose-response curve for continuous treatment and to \nimprove finite sample performance[105]. \n[106] proposed the Dragonnet to exploit the sufficiency of the propensity score for estimation adjustment, and proposed the \ntargeted regularization to induce a bias towards models. The Dragonnet uses a three-headed architecture to provide an \nend-to-end procedure for predicting propensity score and conditional outcome from covariates and treatment information. \nThe targeted regularization introduces a new parameter and a new regularization term to achieve stable finite-sample \nbehavior and strong asymptotic guarantees on estimation. \nDeep Kernel Learning for Individualized Treatment Effects (DKLITE2) proposed a deep kernel regression algorithm and \nposterior regularization framework to avoid learning domain-invariant representations of inputs[107]. DKLITE2 works in a \nfeature space constructed by a kernel function to exploit the correlation between inputs and uses a neural network to \nencode the information content of input variables. \n10 \n \nVision \nSensors \nAI \nMaterials \nRobotics \nControl \nMechanics \nCommni \n-cation \nElectronics \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFig. 3: Intelligent robots observe to learn, plan for interaction, and revise to improve. \n \nFig. 4: Robotics is multidisciplinary. \n \n \nFrom the above introduction, it is clear that DL architectures are widely used in CL for reducing dimensionality, processing \ntemporal data, balancing distributions, and removing confounding bias and selection bias. Among the architectures, \nautoencoder and GAN are particularly popular. From the application perspective, most of the above works focus on \nestimating ITE, and the works on estimating ATE and CATE do exist. \n \nB. Robotic Intelligence \nIntelligent robots observe and interact with the environment. They use various sensors to achieve information[1], use \nmodels to represent the world and estimate their status[108], plan motions[109], execute the planning and correct the \nexecution to achieve the tasks[110], under environmental uncertainties, sensory noises, modeling uncertainties, and \nexecution errors(Fig. 3)[111]. \nRobotics is multidisciplinary and widely involves technology from various fields (Fig. 4). This fact causes the fact that \nexisting intelligent robot research mainly focuses on specific robotic technology[112, 113]. To improve the application of \nintelligent robots, we need not only the improvement on a specific technology, such as AI, also the integration of robotic \ntechniques and the adoption of domain knowledge, which is essential to the real-world applications[114–116]. However, \ndomain knowledge is even out of the robotics field and state of the art deep learning alone can not bridge the gap because \nof the scarcity of data, etc [117–119]. We will use three examples, a low-level visual tracking example, a middle-level motion \nplanning, and a high-level task planning to illustrate why we believe that deep causal learning has the potential to bridge \nthe gap. \nVisual tracking is an important problem in robotics and is widely studied in computer vision, AI, and the robotics field \n(Table I). Particularly for visual tracking in endoscopic surgeries, there are a large number of results that can address \nchallenges of illumination changes, occlusions, lens blur, drastic scene changes, deformation, etc.[120–123]. However, \nvisual tracking remains challenging in endoscopic surgeries because all these adverse factors exist simultaneously and \ndeteriorate tracking performance. Meanwhile, these adverse factors, along with the variance of pathology and anatomy, \nmake the need for training data grow beyond our capacity. Therefore, we believe that deep causal learning is needed to \ndisentangle the problems for robots. \nWorld \nPlanning (robot/arms movement) \nAction (move and interact) \nModels (robots and the world) \nSensors (See, hear, touch...) \nShape \nStiffness \nHardness \n11 \n \n \n \n \n \nFig. 5: Visual tracking in endoscopic surgery. \n \n \nsparse \nsemidense \nfull-dense \nobject \n \n \n \nTABLE I: Visual tracking algorithms for addressing various challenges. \n \n \nMotion planning is widely studied in robotics [157, 158]. However, in real-world applications, intelligent robots not only \nneed to know where they move to and how to move there but also need to know if there are other application-specific \nrequirements. For example, it is well-studied that movement patterns impact surgical outcomes (Fig. 6)[114, 116], but \nit is not trivial to plan motions for a robot for various treatment procedures[110, 111, 159, 160]. Therefore, we believe \nthat deep causal learning, which naturally uses graphical structures to represent knowledge, can effectively incorporate \ndomain knowledge with robotic techniques. \nTask-level planning involves multiple decision-making and is specific to applications. For example, robotic surgery, as one \nof the most successful real-world applications of robotic technology, is still fully teleoperated, despite literature found that \nmany surgical accidents were caused by wrong operations of surgical robots[161–163]. While we do believe there are \nlegal and regulatory barriers that prevent the adoption of autonomous technology, we argue that the main problem is \nthat we lack the technology to handle environmental and task variance. For example, robots have problems dynamically \nadapting to changes and determining the completeness of surgery[164]. \n \nV. CONCLUSION \nRecently Deep Causal Learning has demonstrated its capability of using prior knowledge to disentangle modeling problems \nand reduce data needs, improve performance on extrapolating unseen data, modularize learning problems, and incre- \nmentally learn from multiple studies. Inspired by these new findings, this work incompletely, but systematically discusses \ncausal cognition, statistical causal learning, deep causal learning, and the need for deep causal learning in intelligent \nrobots, and argues that deep causal learning is the new frontier for intelligent robot research. \n \nREFERENCES \n[1] E. Smith, R. Calandra, A. Romero, G. Gkioxari, D. Meger, J. Malik, and M. Drozdzal, “3d shape reconstruction from \nvision and touch,” Advances in Neural Information Processing Systems, vol. 33, pp. 14193–14206, 2020. \n[2] S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics (Intelligent Robotics and Autonomous Agents). The MIT \nPress, September 2005. \n[3] D. C. Penn and D. J. Povinelli, “Causal cognition in human and nonhuman animals: A comparative, critical,” Annu. \nRev. Psychol, vol. 58, pp. 97–118, 2007. \n[4] D. Kuhn, “The development of causal reasoning,” Wiley Interdisciplinary Reviews: Cognitive Science, vol. 3, no. 3, \npp. 327–335, 2012. \n[5] E. S. Spelke, K. Breinlinger, J. Macomber, and K. Jacobson, “Origins of knowledge.,” Psychological review, vol. 99, \nno. 4, p. 605, 1992. \n[6] A. Bender and S. Beller, “The cultural fabric of human causal cognition,” Perspectives on Psychological Science, \nvol. 14, no. 6, pp. 922–940, 2019. \n[7] C. H. Legare, D. M. Sobel, and M. Callanan, “Causal learning is collaborative: Examining explanation and exploration \nin social contexts,” Psychonomic bulletin & review, vol. 24, no. 5, pp. 1548–1554, 2017. \nIllumination \nLens \nScene depth \nOcclusion \nFluid \nDeformation \nStatic \nDynamic \nLow \ntexture \nImage \nquality \nIllumi- \nnation \nReco- \nvery \nMo- \nDefor- \ntion \nmation \nScene \ndepth \n[124, 125] \n[126–129] \n[130, 131] \n[132] \n[131, 133] \n[134, 135] \n[136] \n[137, 138] \n[139] \n[140] \n[137] \n[141] \n[142–144] \n[145–148] \n[149, 150] \n[151–153] \n[147] \n[154, 155] \n[147, 156] \n12 \n \n \n \nFig. 6: Experts(in green) and novices (in red) show significant differences in hand movements. \n \n \n[8] D. M. Sobel and C. H. Legare, “Causal learning in children,” Wiley Interdisciplinary Reviews: Cognitive Science, \nvol. 5, no. 4, pp. 413–427, 2014. \n[9] A. Gopnik, C. Glymour, D. M. Sobel, L. E. Schulz, T. Kushnir, and D. Danks, “A theory of causal learning in children: \ncausal maps and bayes nets.,” Psychological review, vol. 111, no. 1, p. 3, 2004. \n[10] A. M. Leslie and S. Keeble, “Do six-month-old infants perceive causality?,” Cognition, vol. 25, no. 3, pp. 265–288, \n1987. \n[11] A. Needham and R. Baillargeon, “Intuitions about support in 4.5-month-old infants,” Cognition, vol. 47, no. 2, pp. 121– \n148, 1993. \n[12] S. J. Hespos and R. Baillargeon, “Reasoning about containment events in very young infants,” Cognition, vol. 78, \nno. 3, pp. 207–245, 2001. \n[13] H. M. Wellman, The child’s theory of mind. The MIT Press, 1992. \n[14] E. B. Bonawitz, D. Ferranti, R. Saxe, A. Gopnik, A. N. Meltzoff, J. Woodward, and L. E. Schulz, “Just do it? \ninvestigating the gap between prediction and action in toddlers’ causal inferences,” Cognition, vol. 115, no. 1, \npp. 104–117, 2010. \n[15] S. A. Gelman and H. M. Wellman, “Insides and essences: Early understandings of the non-obvious,” Cognition, \nvol. 38, no. 3, pp. 213–244, 1991. \n[16] J. Tooby, A. M. Leslie, D. Sperber, A. Caramazza, A. E. Hillis, E. C. Leek, M. Miozzo, and L. Cosmides, Mapping \nthe mind: Domain specificity in cognition and culture. Cambridge University Press, 1994. \n[17] W.-k. Ahn, S. A. Gelman, J. A. Amsterlaw, J. Hohenstein, and C. W. Kalish, “Causal status effect in children’s \ncategorization,” Cognition, vol. 76, no. 2, pp. B35–B43, 2000. \n[18] R. Guo, L. Cheng, J. Li, P. R. Hahn, and H. Liu, “A survey of learning causality with data: Problems and methods,” \nACM Computing Surveys (CSUR), vol. 53, no. 4, pp. 1–37, 2020. \n[19] L. Yao, Z. Chu, S. Li, Y. Li, J. Gao, and A. Zhang, “A survey on causal inference,” ACM Transactions on Knowledge \nDiscovery from Data (TKDD), vol. 15, no. 5, pp. 1–46, 2021. \n13 \n \n \n[20] P. Spirtes, C. N. Glymour, R. Scheines, and D. Heckerman, Causation, prediction, and search. MIT press, 2000. \n[21] J. Pearl, Causality. Cambridge university press, 2009. \n[22] J. D. Ramsey, “A scalable conditional independence test for nonlinear, non-gaussian data,” arXiv preprint \narXiv:1401.5031, 2014. \n[23] C. Glymour, K. Zhang, and P. Spirtes, “Review of causal discovery methods based on graphical models,” Frontiers \nin genetics, vol. 10, p. 524, 2019. \n[24] D. Sejdinovic, B. Sriperumbudur, A. Gretton, and K. Fukumizu, “Equivalence of distance-based and rkhs-based \nstatistics in hypothesis testing,” The annals of statistics, pp. 2263–2291, 2013. \n[25] P. L. Spirtes, C. Meek, and T. S. Richardson, “Causal inference in the presence of latent variables and selection \nbias,” arXiv preprint arXiv:1302.4983, 2013. \n[26] G. Schwarz, “Estimating the dimension of a model,” The annals of statistics, pp. 461–464, 1978. \n[27] D. M. Chickering, “Learning bayesian networks is np-complete,” in Learning from data, pp. 121–130, Springer, 1996. \n[28] D. M. Chickering, “Learning bayesian networks is np-complete,” in Learning from data, pp. 121–130, Springer, 1996. \n[29] D. M. Chickering, “Optimal structure identification with greedy search,” Journal of machine learning research, vol. 3, \nno. Nov, pp. 507–554, 2002. \n[30] J. Ramsey, M. Glymour, R. Sanchez-Romero, and C. Glymour, “A million variables and more: the fast greedy \nequivalence search algorithm for learning high-dimensional graphical causal models, with an application to functional \nmagnetic resonance images,” International journal of data science and analytics, vol. 3, no. 2, pp. 121–129, 2017. \n[31] K. Fukumizu, A. Gretton, X. Sun, and B. Schölkopf, “Kernel measures of conditional dependence,” Advances in \nneural information processing systems, vol. 20, 2007. \n[32] D. Heckerman, D. Geiger, and D. M. Chickering, “Learning bayesian networks: The combination of knowledge and \nstatistical data,” Machine learning, vol. 20, no. 3, pp. 197–243, 1995. \n[33] X. Zheng, C. Dan, B. Aragam, P. Ravikumar, and E. Xing, “Learning sparse nonparametric dags,” in International \nConference on Artificial Intelligence and Statistics, pp. 3414–3425, PMLR, 2020. \n[34] B. Huang, K. Zhang, Y. Lin, B. Schölkopf, and C. Glymour, “Generalized score functions for causal discovery,” in \nProceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 1551– \n1560, 2018. \n[35] S. Shimizu, P. O. Hoyer, A. Hyvärinen, A. Kerminen, and M. Jordan, “A linear non-gaussian acyclic model for causal \ndiscovery.,” Journal of Machine Learning Research, vol. 7, no. 10, 2006. \n[36] K. Zhang and A. Hyvarinen, “On the identifiability of the post-nonlinear causal model,” arXiv preprint arXiv:1205.2599, \n2012. \n[37] A. Taleb and C. Jutten, “Source separation in post-nonlinear mixtures,” IEEE Transactions on signal Processing, \nvol. 47, no. 10, pp. 2807–2820, 1999. \n[38] K. Zhang, Z. Wang, J. Zhang, and B. Schölkopf, “On estimation of functional causal models: general results and \napplication to the post-nonlinear causal model,” ACM Transactions on Intelligent Systems and Technology (TIST), \nvol. 7, no. 2, pp. 1–22, 2015. \n[39] I. Tsamardinos, L. E. Brown, and C. F. Aliferis, “The max-min hill-climbing bayesian network structure learning \nalgorithm,” Machine learning, vol. 65, no. 1, pp. 31–78, 2006. \n[40] M. L. Wong, S. Y. Lee, and K. S. Leung, “A hybrid approach to discover bayesian networks from databases using \nevolutionary programming,” in 2002 IEEE International Conference on Data Mining, 2002. Proceedings., pp. 498–505, \nIEEE, 2002. \n[41] J. M. Robins, A. Rotnitzky, and L. P. Zhao, “Estimation of regression coefficients when some regressors are not \nalways observed,” Journal of the American statistical Association, vol. 89, no. 427, pp. 846–866, 1994. \n[42] F. Li, L. E. Thomas, and F. Li, “Addressing extreme propensity scores via the overlap weights,” American journal of \nepidemiology, vol. 188, no. 1, pp. 250–257, 2019. \n14 \n \n \n[43] J. Hainmueller, “Entropy balancing for causal effects: A multivariate reweighting method to produce balanced samples \nin observational studies,” Political analysis, vol. 20, no. 1, pp. 25–46, 2012. \n[44] K. Imai and M. Ratkovic, “Covariate balancing propensity score,” Journal of the Royal Statistical Society: Series B \n(Statistical Methodology), vol. 76, no. 1, pp. 243–263, 2014. \n[45] K. Kuang, P. Cui, B. Li, M. Jiang, S. Yang, and F. Wang, “Treatment effect estimation with data-driven variable \ndecomposition,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 31, 2017. \n[46] K. Kuang, P. Cui, B. Li, M. Jiang, and S. Yang, “Estimating treatment effect in the wild via differentiated confounder \nbalancing,” in Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data \nmining, pp. 265–274, 2017. \n[47] C. E. Frangakis and D. B. Rubin, “Principal stratification in causal inference,” Biometrics, vol. 58, no. 1, pp. 21–29, \n2002. \n[48] H. Jin and D. B. Rubin, “Principal stratification for causal inference with extended partial compliance,” Journal of the \nAmerican Statistical Association, vol. 103, no. 481, pp. 101–111, 2008. \n[49] G. Hong, “Marginal mean weighting through stratification: Adjustment for selection bias in multilevel data,” Journal \nof Educational and Behavioral Statistics, vol. 35, no. 5, pp. 499–531, 2010. \n[50] A. Linden, “Combining propensity score-based stratification and weighting to improve causal inference in the \nevaluation of health care interventions,” Journal of evaluation in clinical practice, vol. 20, no. 6, pp. 1065–1071, \n2014. \n[51] E. A. Stuart, “Matching methods for causal inference: A review and a look forward,” Statistical science: a review \njournal of the Institute of Mathematical Statistics, vol. 25, no. 1, p. 1, 2010. \n[52] J. M. Reinisch, S. A. Sanders, E. L. Mortensen, and D. B. Rubin, “In utero exposure to phenobarbital and intelligence \ndeficits in adult men,” Jama, vol. 274, no. 19, pp. 1518–1525, 1995. \n[53] L. L. Kupper, J. M. Karon, D. G. Kleinbaum, H. Morgenstern, and D. K. Lewis, “Matching in epidemiologic studies: \nvalidity and efficiency considerations,” Biometrics, pp. 271–291, 1981. \n[54] H. A. Chipman, E. I. George, and R. E. McCulloch, “Bart: Bayesian additive regression trees,” The Annals of Applied \nStatistics, vol. 4, no. 1, pp. 266–298, 2010. \n[55] W.-Y. Loh, “Classification and regression trees,” Wiley interdisciplinary reviews: data mining and knowledge discovery, \nvol. 1, no. 1, pp. 14–23, 2011. \n[56] S. Wager and S. Athey, “Estimation and inference of heterogeneous treatment effects using random forests,” Journal \nof the American Statistical Association, vol. 113, no. 523, pp. 1228–1242, 2018. \n[57] I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, Deep learning, vol. 1. MIT press Cambridge, 2016. \n[58] Y. LeCun, Y. Bengio, et al., “Convolutional networks for images, speech, and time series,” The handbook of brain \ntheory and neural networks, vol. 3361, no. 10, p. 1995, 1995. \n[59] A. Graves, “Long short-term memory,” Supervised sequence labelling with recurrent neural networks, pp. 37–45, \n2012. \n[60] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is \nall you need,” Advances in neural information processing systems, vol. 30, 2017. \n[61] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” arXiv preprint arXiv:1312.6114, 2013. \n[62] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative \nadversarial networks,” Communications of the ACM, vol. 63, no. 11, pp. 139–144, 2020. \n[63] M. Yang, F. Liu, Z. Chen, X. Shen, J. Hao, and J. Wang, “Causalvae: Structured causal disentanglement in variational \nautoencoder,” arXiv preprint arXiv:2004.08697, 2020. \n[64] G. Parascandolo, N. Kilbertus, M. Rojas-Carulla, and B. Schölkopf, “Learning independent causal mechanisms,” in \nInternational Conference on Machine Learning, pp. 4036–4044, PMLR, 2018. \n[65] Y. Bengio, T. Deleu, N. Rahaman, R. Ke, S. Lachapelle, O. Bilaniuk, A. Goyal, and C. Pal, “A meta-transfer objective \nfor learning to disentangle causal mechanisms,” arXiv preprint arXiv:1901.10912, 2019. \n15 \n \n \n[66] Á. P. Martínez and J. V. Marca, “Explaining visual models by causal attribution,” in 2019 IEEE/CVF International \nConference on Computer Vision Workshop (ICCVW), pp. 4167–4175, IEEE, 2019. \n[67] N. Pawlowski, D. C. Castro, and B. Glocker, “Deep structural causal models for tractable counterfactual inference,” \narXiv preprint arXiv:2006.06485, 2020. \n[68] S. Singla, B. Pollack, J. Chen, and K. Batmanghelich, “Explanation by progressive exaggeration,” arXiv preprint \narXiv:1911.00483, 2019. \n[69] D. Kaushik, E. Hovy, and Z. C. Lipton, “Learning the difference that makes a difference with counterfactually- \naugmented data,” arXiv preprint arXiv:1909.12434, 2019. \n[70] N. Pawlowski, D. Coelho de Castro, and B. Glocker, “Deep structural causal models for tractable counterfactual \ninference,” Advances in Neural Information Processing Systems, vol. 33, pp. 857–869, 2020. \n[71] L. Yao, Z. Chu, S. Li, Y. Li, J. Gao, and A. Zhang, “A survey on causal inference,” ACM Transactions on Knowledge \nDiscovery from Data (TKDD), vol. 15, no. 5, pp. 1–46, 2021. \n[72] R. Guo, L. Cheng, J. Li, P. R. Hahn, and H. Liu, “A survey of learning causality with data: Problems and methods,” \nACM Computing Surveys (CSUR), vol. 53, no. 4, pp. 1–37, 2020. \n[73] J. Pearl, Causality. Cambridge university press, 2009. \n[74] F. Johansson, U. Shalit, and D. Sontag, “Learning representations for counterfactual inference,” in International \nconference on machine learning, pp. 3020–3029, PMLR, 2016. \n[75] L. Yao, S. Li, Y. Li, M. Huai, J. Gao, and A. Zhang, “Representation learning for treatment effect estimation from \nobservational data,” Advances in Neural Information Processing Systems, vol. 31, 2018. \n[76] L. Yao, S. Li, Y. Li, M. Huai, J. Gao, and A. Zhang, “Ace: Adaptively similarity-preserved representation learning for \nindividual treatment effect estimation,” in 2019 IEEE International Conference on Data Mining (ICDM), pp. 1432– \n1437, IEEE, 2019. \n[77] F. D. Johansson, N. Kallus, U. Shalit, and D. Sontag, “Learning weighted representations for generalization across \ndesigns,” arXiv preprint arXiv:1802.08598, 2018. \n[78] U. Shalit, F. D. Johansson, and D. Sontag, “Estimating individual treatment effect: generalization bounds and \nalgorithms,” in International Conference on Machine Learning, pp. 3076–3085, PMLR, 2017. \n[79] N. Hassanpour and R. Greiner, “Counterfactual regression with importance sampling weights.,” in IJCAI, pp. 5880– \n5887, 2019. \n[80] P. Schwab, L. Linhardt, and W. Karlen, “Perfect match: A simple method for learning representations for counterfactual \ninference with neural networks,” arXiv preprint arXiv:1810.00656, 2018. \n[81] A. M. Alaa, M. Weisz, and M. Van Der Schaar, “Deep counterfactual networks with propensity-dropout,” arXiv preprint \narXiv:1706.05966, 2017. \n[82] C. Louizos, U. Shalit, J. M. Mooij, D. Sontag, R. Zemel, and M. Welling, “Causal effect inference with deep latent- \nvariable models,” Advances in neural information processing systems, vol. 30, 2017. \n[83] O. Atan, J. Jordon, and M. Van der Schaar, “Deep-treat: Learning optimal personalized treatments from observational \ndata using neural networks,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 32, 2018. \n[84] S. K. Saini, S. Dhamnani, A. A. Ibrahim, and P. Chavan, “Multiple treatment effect estimation using deep generative \nmodel with task embedding,” in The World Wide Web Conference, pp. 1601–1611, 2019. \n[85] L. Yao, S. Li, Y. Li, H. Xue, J. Gao, and A. Zhang, “On the estimation of treatment effect with text covariates,” in \nInternational Joint Conference on Artificial Intelligence, 2019. \n[86] Z. Zhang, Q. Lan, L. Ding, Y. Wang, N. Hassanpour, and R. Greiner, “Reducing selection bias in counterfactual \nreasoning for individual treatment effects estimation,” arXiv preprint arXiv:1912.09040, 2019. \n[87] H. Zou, P. Cui, B. Li, Z. Shen, J. Ma, H. Yang, and Y. He, “Counterfactual prediction for bundle treatment,” Advances \nin Neural Information Processing Systems, vol. 33, pp. 19705–19715, 2020. \n[88] J. Yoon, J. Jordon, and M. Van Der Schaar, “Ganite: Estimation of individualized treatment effects using generative \nadversarial nets,” in International Conference on Learning Representations, 2018. \n16 \n \n \n[89] C. Lee, N. Mastronarde, and M. van der Schaar, “Estimation of individual treatment effect in latent confounder \nmodels via adversarial learning,” arXiv preprint arXiv:1811.08943, 2018. \n[90] Z. Qian, Y. Zhang, I. Bica, A. Wood, and M. van der Schaar, “Synctwin: Treatment effect estimation with longitudinal \noutcomes,” Advances in Neural Information Processing Systems, vol. 34, pp. 3178–3190, 2021. \n[91] K. Kuang, Y. Li, B. Li, P. Cui, H. Yang, J. Tao, and F. Wu, “Continuous treatment effect estimation via generative \nadversarial de-confounding,” Data Mining and Knowledge Discovery, vol. 35, no. 6, pp. 2467–2497, 2021. \n[92] X. Du, L. Sun, W. Duivesteijn, A. Nikolaev, and M. Pechenizkiy, “Adversarial balancing-based representation learning \nfor causal effect inference with observational data,” Data Mining and Knowledge Discovery, vol. 35, no. 4, pp. 1713– \n1738, 2021. \n[93] B. Lim, “Forecasting treatment responses over time using recurrent marginal structural networks,” advances in neural \ninformation processing systems, vol. 31, 2018. \n[94] I. Bica, A. M. Alaa, J. Jordon, and M. van der Schaar, “Estimating counterfactual treatment outcomes over time \nthrough adversarially balanced representations,” arXiv preprint arXiv:2002.04083, 2020. \n[95] I. Bica, A. Alaa, and M. Van Der Schaar, “Time series deconfounder: Estimating treatment effects over time in the \npresence of hidden confounders,” in International Conference on Machine Learning, pp. 884–895, PMLR, 2020. \n[96] Z. Guo, S. Zheng, Z. Liu, K. Yan, and Z. Zhu, “Cetransformer: Casual effect estimation via transformer based \nrepresentation learning,” in Chinese Conference on Pattern Recognition and Computer Vision (PRCV), pp. 524– \n535, Springer, 2021. \n[97] P. Schwab, L. Linhardt, S. Bauer, J. M. Buhmann, and W. Karlen, “Learning counterfactual representations for \nestimating individual dose-response curves,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, \npp. 5612–5619, 2020. \n[98] N. Hassanpour and R. Greiner, “Learning disentangled representations for counterfactual regression,” in International \nConference on Learning Representations, 2019. \n[99] A. Wu, K. Kuang, J. Yuan, B. Li, R. Wu, Q. Zhu, Y. Zhuang, and F. Wu, “Learning decomposed representation for \ncounterfactual inference,” arXiv preprint arXiv:2006.07040, 2020. \n[100] S. Parbhoo, S. Bauer, and P. Schwab, “Ncore: Neural counterfactual representation learning for combinations of \ntreatments,” arXiv preprint arXiv:2103.11175, 2021. \n[101] Z. Qian, A. Curth, and M. van der Schaar, “Estimating multi-cause treatment effects via single-cause perturbation,” \nAdvances in Neural Information Processing Systems, vol. 34, pp. 23754–23767, 2021. \n[102] A. Curth and M. van der Schaar, “On inductive biases for heterogeneous treatment effect estimation,” Advances in \nNeural Information Processing Systems, vol. 34, pp. 15883–15894, 2021. \n[103] T. Hatt and S. Feuerriegel, “Estimating average treatment effects via orthogonal regularization,” in Proceedings of \nthe 30th ACM International Conference on Information & Knowledge Management, pp. 680–689, 2021. \n[104] L. Yao, Y. Li, S. Li, M. Huai, J. Gao, and A. Zhang, “Sci: Subspace learning based counterfactual inference for \nindividual treatment effect estimation,” in Proceedings of the 30th ACM International Conference on Information & \nKnowledge Management, pp. 3583–3587, 2021. \n[105] L. Nie, M. Ye, Q. Liu, and D. Nicolae, “Vcnet and functional targeted regularization for learning causal effects of \ncontinuous treatments,” arXiv preprint arXiv:2103.07861, 2021. \n[106] C. Shi, D. Blei, and V. Veitch, “Adapting neural networks for the estimation of treatment effects,” Advances in neural \ninformation processing systems, vol. 32, 2019. \n[107] Y. Zhang, A. Bellot, and M. Schaar, “Learning overlapping representations for the estimation of individualized \ntreatment effects,” in International Conference on Artificial Intelligence and Statistics, pp. 1005–1014, PMLR, 2020. \n[108] M. Miyasaka, M. Haghighipanah, Y. Li, J. Matheson, A. Lewis, and B. Hannaford, “Modeling cable-driven robot with \nhysteresis and cable–pulley network friction,” IEEE/ASME Transactions on Mechatronics, vol. 25, no. 2, pp. 1095– \n1104, 2020. \n[109] Y. Qi, L. Jin, H. Li, Y. Li, and M. Liu, “Discrete computational neural dynamics models for solving time-dependent \nsylvester equations with applications to robotics and mimo systems,” IEEE Transactions on Industrial Informatics, \n2020. \n17 \n \n \n[110] Y. Li and B. Hannaford, “Soft-obstacle avoidance for redundant manipulators with recurrent neural network,” in \nIntelligent Robots and Systems (IROS), 2018 IEEE/RSJ International Conference on, pp. 1–6, IEEE, 2018. \n[111] Y. Li and B. Hannaford, “Gaussian process regression for sensorless grip force estimation of cable-driven elongated \nsurgical instruments,” IEEE Robotics and Automation Letters, vol. 2, no. 3, pp. 1312–1319, 2017. \n[112] Y. Li, S. Li, and B. Hannaford, “A novel recurrent neural network control scheme for improving redundant manipulator \nmotion planning completeness,” in Robotics and Automation (ICRA), 2018 IEEE International Conference on, p. 1 6, \nIEEE, 2018. \n[113] Y. Li, S. Li, M. Miyasaka, A. Lewis, and B. Hannaford, “Improving control precision and motion adaptiveness for \nsurgical robot with recurrent neural network,” in Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International \nConference on, pp. 1–6, IEEE, 2017. \n[114] R. A. Harbison, A. M. Berens, Y. Li, R. A. Bly, B. Hannaford, and K. S. Moe, “Region-specific objective signatures \nof endoscopic surgical instrument motion: A cadaveric exploratory analysis,” Journal of Neurological Surgery Part \nB: Skull Base, vol. 78, no. 01, pp. 099–104, 2017. \n[115] R. C. Saxena, S. Friedman, R. A. Bly, J. Otjen, A. M. Alessio, Y. Li, B. Hannaford, M. Whipple, and K. S. Moe, \n“Comparison of micro–computed tomography and clinical computed tomography protocols for visualization of nasal \ncartilage before surgical planning for rhinoplasty,” JAMA facial plastic surgery, 2019. \n[116] Y. Li, R. A. Bly, R. A. Harbison, I. M. Humphreys, M. E. Whipple, B. Hannaford, and K. S. Moe, “Anatomical region \nsegmentation for objective surgical skill assessment with operating room motion data,” Journal of Neurological \nSurgery Part B: Skull Base, vol. 369, no. 15, pp. 1434–1442, 2017. \n[117] Y. Li, R. A. Harbison, R. A. Bly, I. M. Humphreys, B. Hannaford, and K. Moe, “Atlas based anatomical region \nsegmentation for minimally invasive skull base surgery objective motion analysis,” in Journal of Neurological Surgery \nPart B: Skull Base, vol. 78, p. A146, Georg Thieme Verlag KG, 2017. \n[118] Y. Li, R. Bly, M. Whipple, I. Humphreys, B. Hannaford, and K. Moe, “Use endoscope and instrument and pathway \nrelative motion as metric for automated objective surgical skill assessment in skull base and sinus surgery,” in \nJournal of Neurological Surgery Part B: Skull Base, vol. 79, p. A194, Georg Thieme Verlag KG, 2018. \n[119] Y. Li, R. Bly, I. Humphreys, M. Whipple, B. Hannaford, and K. Moe, “Surgical motion based automatic objective \nsurgical completeness assessment in endoscopic skull base and sinus surgery,” in Journal of Neurological Surgery \nPart B: Skull Base, vol. 79, p. P193, Georg Thieme Verlag KG, 2018. \n[120] F. Qin, S. Lin, Y. Li, R. A. Bly, K. S. Moe, and B. Hannaford, “Towards better surgical instrument segmentation in \nendoscopic vision: multi-angle feature aggregation and contour supervision,” IEEE Robotics and Automation Letters, \nvol. 5, no. 4, pp. 6639–6646, 2020. \n[121] F. Qin, Y. Li, Y.-H. Su, D. Xu, and B. Hannaford, “Surgical instrument segmentation for endoscopic vision with data \nfusion of cnn prediction and kinematic pose,” in 2019 International Conference on Robotics and Automation (ICRA), \npp. 9821–9827, IEEE, 2019. \n[122] S. Lin, F. Qin, Y. Li, R. A. Bly, K. S. Moe, and B. Hannaford, “Lc-gan: Image-to-image translation based on generative \nadversarial network for endoscopic images,” in 2020 IEEE/RSJ International Conference on Intelligent Robots and \nSystems (IROS), pp. 2914–2920, 2020. \n[123] D. Recasens, J. Lamarca, J. M. Fácil, J. Montiel, and J. Civera, “Endo-depth-and-motion: Reconstruction and tracking \nin endoscopic videos using depth networks and photometric constraints,” IEEE Robotics and Automation Letters, \nvol. 6, no. 4, pp. 7225–7232, 2021. \n[124] A. J. Davison, I. D. Reid, N. D. Molton, and O. Stasse, “Monoslam: Real-time single camera slam,” IEEE transactions \non pattern analysis and machine intelligence, vol. 29, no. 6, pp. 1052–1067, 2007. \n[125] R. Mur-Artal, J. Montiel, and J. D. Tardós, “Orb-slam: a versatile and accurate monocular slam system,” IEEE \nTransactions on Robotics, vol. 31, no. 5, pp. 1147–1163, 2015. \n[126] M. R. U. Saputra, A. Markham, and N. Trigoni, “Visual slam and structure from motion in dynamic environments: A \nsurvey,” ACM Computing Surveys (CSUR), vol. 51, no. 2, pp. 1–36, 2018. \n[127] C. Yu, Z. Liu, X.-J. Liu, F. Xie, Y. Yang, Q. Wei, and Q. Fei, “Ds-slam: A semantic visual slam towards dynamic \nenvironments,” in 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1168– \n1174, IEEE, 2018. \n18 \n \n \n[128] M. J. Milford and G. F. Wyeth, “Seqslam: Visual route-based navigation for sunny summer days and stormy winter \nnights,” in 2012 IEEE international conference on robotics and automation, pp. 1643–1649, IEEE, 2012. \n[129] E. Pepperell, P. Corke, and M. Milford, “Routed roads: Probabilistic vision-based place recognition for changing \nconditions, split streets and varied viewpoints,” The International Journal of Robotics Research, vol. 35, no. 9, \npp. 1057–1179, 2016. \n[130] S. Yang, Y. Song, M. Kaess, and S. Scherer, “Pop-up slam: Semantic monocular plane slam for low-texture \nenvironments,” in 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1222– \n1229, IEEE, 2016. \n[131] R. Gomez-Ojeda et al., “Robust visual slam in challenging environments with low-texture and dynamic illumination,” \n2020. \n[132] H. S. Lee, J. Kwon, and K. M. Lee, “Simultaneous localization, mapping and deblurring,” in 2011 International \nConference on Computer Vision, pp. 1203–1210, IEEE, 2011. \n[133] T. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison, and S. Leutenegger, “Elasticfusion: Real-time dense slam \nand light source estimation,” The International Journal of Robotics Research, vol. 35, no. 14, pp. 1697–1716, 2016. \n[134] B. Williams, G. Klein, and I. Reid, “Real-time slam relocalisation,” in 2007 IEEE 11th international conference on \ncomputer vision, pp. 1–8, IEEE, 2007. \n[135] M. Hsiao and M. Kaess, “Mh-isam2: Multi-hypothesis isam using bayes tree and hypo-tree,” in 2019 International \nConference on Robotics and Automation (ICRA), pp. 1274–1280, IEEE, 2019. \n[136] F. Vasconcelos, E. Mazomenos, J. Kelly, and D. Stoyanov, “Rcm-slam: Visual localisation and mapping under remote \ncentre of motion constraints,” in 2019 International conference on robotics and automation (ICRA), pp. 9278–9284, \nIEEE, 2019. \n[137] R. Mur-Artal and J. D. Tardós, “Probabilistic semi-dense mapping from highly accurate feature-based monocular \nslam.,” in Robotics: Science and Systems, vol. 2015, Rome, 2015. \n[138] Y. Wu, Y. Zhang, D. Zhu, Y. Feng, S. Coleman, and D. Kerr, “Eao-slam: Monocular semi-dense object slam based on \nensemble data association,” in 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), \npp. 4966–4973, IEEE, 2020. \n[139] S. Wen, Y. Zhao, X. Liu, F. Sun, H. Lu, and Z. Wang, “Hybrid semi-dense 3d semantic-topological mapping from \nstereo visual-inertial odometry slam with loop closure detection,” IEEE Transactions on Vehicular Technology, vol. 69, \nno. 12, pp. 16057–16066, 2020. \n[140] N. Mahmoud, A. Hostettler, T. Collins, L. Soler, C. Doignon, and J. Montiel, “Slam based quasi dense reconstruction \nfor minimally invasive surgery scenes,” arXiv preprint arXiv:1705.09107, 2017. \n[141] R. Newcombe, Dense visual SLAM. PhD thesis, Imperial College London, 2012. \n[142] F. Wimbauer, N. Yang, L. von Stumberg, N. Zeller, and D. Cremers, “Monorec: Semi-supervised dense reconstruction \nin dynamic environments from a single moving camera,” in Proceedings of the IEEE/CVF Conference on Computer \nVision and Pattern Recognition, pp. 6112–6122, 2021. \n[143] M. Fehr, F. Furrer, I. Dryanovski, J. Sturm, I. Gilitschenski, R. Siegwart, and C. Cadena, “Tsdf-based change detection \nfor consistent long-term dense reconstruction and dynamic object discovery,” in 2017 IEEE International Conference \non Robotics and automation (ICRA), pp. 5237–5244, IEEE, 2017. \n[144] I. A. Bârsan, P. Liu, M. Pollefeys, and A. Geiger, “Robust dense mapping for large-scale dynamic environments,” in \n2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 7510–7517, IEEE, 2018. \n[145] M. Visentini-Scarzanella, T. Sugiura, T. Kaneko, and S. Koto, “Deep monocular 3d reconstruction for assisted \nnavigation in bronchoscopy,” International journal of computer assisted radiology and surgery, vol. 12, no. 7, \npp. 1089–1099, 2017. \n[146] K. Tateno, F. Tombari, I. Laina, and N. Navab, “Cnn-slam: Real-time dense monocular slam with learned depth \nprediction,” in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 6243–6252, \n2017. \n19 \n \n \n[147] R. Ma, R. Wang, S. Pizer, J. Rosenman, S. K. McGill, and J.-M. Frahm, “Real-time 3d reconstruction of colonoscopic \nsurfaces for determining missing regions,” in International Conference on Medical Image Computing and Computer- \nAssisted Intervention, pp. 573–582, Springer, 2019. \n[148] K. L. Lurie, R. Angst, D. V. Zlatev, J. C. Liao, and A. K. E. Bowden, “3d reconstruction of cystoscopy videos for \ncomprehensive bladder records,” Biomedical optics express, vol. 8, no. 4, pp. 2106–2123, 2017. \n[149] H. Seok Lee and K. Mu Lee, “Dense 3d reconstruction from severely blurred images using a single moving camera,” \nin Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 273–280, 2013. \n[150] R. J. Chen, T. L. Bobrow, T. Athey, F. Mahmood, and N. J. Durr, “Slam endoscopy enhanced by adversarial depth \nprediction,” arXiv preprint arXiv:1907.00283, 2019. \n[151] N. Mahmoud, I. Cirauqui, A. Hostettler, C. Doignon, L. Soler, J. Marescaux, and J. Montiel, “Orbslam-based \nendoscope tracking and 3d reconstruction,” in International workshop on computer-assisted and robotic endoscopy, \npp. 72–83, Springer, 2016. \n[152] T. D. Soper, M. P. Porter, and E. J. Seibel, “Surface mosaics of the bladder reconstructed from endoscopic video \nfor automated surveillance,” IEEE Transactions on Biomedical Engineering, vol. 59, no. 6, pp. 1670–1680, 2012. \n[153] T. Okatani and K. Deguchi, “Shape reconstruction from an endoscope image by shape from shading technique for \na point light source at the projection center,” Computer vision and image understanding, vol. 66, no. 2, pp. 119–131, \n1997. \n[154] J. Lamarca, S. Parashar, A. Bartoli, and J. Montiel, “Defslam: Tracking and mapping of deforming scenes from \nmonocular sequences,” IEEE Transactions on robotics, vol. 37, no. 1, pp. 291–303, 2020. \n[155] M. Turan, Y. Almalioglu, H. Araujo, E. Konukoglu, and M. Sitti, “A non-rigid map fusion-based direct slam method for \nendoscopic capsule robots,” International journal of intelligent robotics and applications, vol. 1, no. 4, pp. 399–409, \n2017. \n[156] Q. Péntek, S. Hein, A. Miernik, and A. Reiterer, “Image-based 3d surface approximation of the bladder using \nstructure-from-motion for enhanced cystoscopy based on phantom data,” Biomedical Engineering/Biomedizinische \nTechnik, vol. 63, no. 4, pp. 461–466, 2018. \n[157] S. M. LaValle and J. J. Kuffner Jr, “Randomized kinodynamic planning,” The International Journal of Robotics \nResearch, vol. 20, no. 5, pp. 378–400, 2001. \n[158] Y. Li, S. Li, and B. Hannaford, “A model based recurrent neural network with randomness for efficient control with \napplications,” IEEE Transactions on Industrial Informatics, 2018. \n[159] Y. Li, B. Hannaford, I. Humphreys, K. S. Moe, and R. A. Bly, “Learning surgical motion pattern from small data in \nendoscopic sinus and skull base surgeries,” in Robotics and Automation (ICRA), 2021 IEEE International Conference \non, pp. 1–6, IEEE, 2021. \n[160] L. Jin, S. Li, X. Luo, Y. Li, and B. Qin, “Neural dynamics for cooperative control of redundant robot manipulators,” \nIEEE Transactions on Industrial Informatics, vol. 14, no. 9, pp. 3812–3821, 2018. \n[161] H. Alemzadeh, J. Raman, N. Leveson, Z. Kalbarczyk, and R. K. Iyer, “Adverse events in robotic surgery: a \nretrospective study of 14 years of fda data,” PloS one, vol. 11, no. 4, p. e0151470, 2016. \n[162] Y.-H. Su, A. Munawar, A. Deguet, A. Lewis, K. Lindgren, Y. Li, R. H. Taylor, G. S. Fischer, B. Hannaford, and \nP. Kazanzides, “Collaborative robotics toolkit (crtk):open software framework forsurgical robotics research,” in IEEE \nRobotic Computing IRC 2020, pp. 1–8, IEEE, 2020. \n[163] Y. Li, B. Hannaford, and J. Rosen, “The raven open surgical robotic platforms: A review and prospect,” Acta \nPolytechnica Hungarica, vol. 16, no. 8, 2019. \n[164] R. H. Taylor, A. Menciassi, G. Fichtinger, P. Fiorini, and P. Dario, “Medical robotics and computer-integrated surgery,” \nin Springer handbook of robotics, pp. 1657–1684, Springer, 2016. \n",
  "categories": [
    "cs.RO"
  ],
  "published": "2022-12-23",
  "updated": "2022-12-23"
}