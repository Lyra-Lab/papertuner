{
  "id": "http://arxiv.org/abs/2302.03284v3",
  "title": "Unsupervised Deep Learning for IoT Time Series",
  "authors": [
    "Ya Liu",
    "Yingjie Zhou",
    "Kai Yang",
    "Xin Wang"
  ],
  "abstract": "IoT time series analysis has found numerous applications in a wide variety of\nareas, ranging from health informatics to network security. Nevertheless, the\ncomplex spatial temporal dynamics and high dimensionality of IoT time series\nmake the analysis increasingly challenging. In recent years, the powerful\nfeature extraction and representation learning capabilities of deep learning\n(DL) have provided an effective means for IoT time series analysis. However,\nfew existing surveys on time series have systematically discussed unsupervised\nDL-based methods. To fill this void, we investigate unsupervised deep learning\nfor IoT time series, i.e., unsupervised anomaly detection and clustering, under\na unified framework. We also discuss the application scenarios, public\ndatasets, existing challenges, and future research directions in this area.",
  "text": "THE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n1\nUnsupervised Deep Learning for IoT Time Series\nYa Liu, Yingjie Zhou, Kai Yang, and Xin Wang\nAbstract—IoT time series analysis has found numerous appli-\ncations in a wide variety of areas, ranging from health informatics\nto network security. Nevertheless, the complex spatial temporal\ndynamics and high dimensionality of IoT time series make the\nanalysis increasingly challenging. In recent years, the powerful\nfeature extraction and representation learning capabilities of deep\nlearning (DL) have provided an effective means for IoT time\nseries analysis. However, few existing surveys on time series have\nsystematically discussed unsupervised DL-based methods. To ﬁll\nthis void, we investigate unsupervised deep learning for IoT time\nseries, i.e., unsupervised anomaly detection and clustering, under\na uniﬁed framework. We also discuss the application scenarios,\npublic datasets, existing challenges, and future research directions\nin this area.\nIndex Terms—IoT, time series, unsupervised deep learning,\nanomaly detection, clustering.\nI. INTRODUCTION\nW\nITH the development of the ﬁfth generation (5G)\nnetwork, the Internet of Things (IoT) has become\nubiquitous in our daily life. 5G enables connections with\nextraordinary speed, expanded bandwidth, and low latency,\nserving billions of mobile users and IoT devices [1]. It is\nestimated that the global economic impact of IoT will reach\n$11.1 trillion per year by 2025 [2]. Nowadays, IoT sensors\ncontinue to generate large amounts of time series data, which\ncontain meaningful knowledge of the monitored system. Ana-\nlyzing these time series data can help operators understand the\nunderlying causes of systemic patterns over time and provide\na better user experience with lower operating costs. Thus,\ntime series analysis, e.g., anomaly detection and clustering,\nhas been in great demand in many ﬁelds, from energy and\nﬁnance to healthcare and IT Operations.\nTraditional time series analysis methods have achieved fa-\nvorable performance with hand-crafted features and sufﬁcient\nexpert knowledge. However, compared with non-IoT time se-\nries, IoT time series exhibit some unique characteristics which\nrender traditional time series analysis methods not directly\napplicable. First, IoT time series can be of massive amount and\nhigh-dimensional as 5G and beyond communication systems\nallow monitoring of hundreds or even millions of IoT devices\nsimultaneously, which entails scalability as a key challenge\nfor IoT time series analysis [3]. In addition, as opposed to\nnon-IoT time series data with only temporal correlations,\nIoT time series exhibit not only temporal correlations but\nYa\nLiu\nand\nKai\nYang\nare\nwith\nthe\nDepartment\nof\nComputer\nScience and Technology, Tongji University, Shanghai, China (e-mail:\nyaliu@tongji.edu.cn, kaiyang@tongji.edu.cn). Yingjie Zhou is with College\nof Computer Science, Sichuan university, Chengdu, Sichuan, China (e-mail:\nyjzhou09@gmail.com; yjzhou@scu.edu.cn). Xin Wang is with School of\nInformation Science and Engineering, Fudan University, Shanghai, China (e-\nmail: xwang11@fudan.edu.cn).\nalso complicated spatial correlations. That is because IoT\ndevices are usually geographically close to each other [4]. For\nexample, in smart transportation, multiple sensors installed on\nvehicles are exploited to record vehicle’s real-time information\nsuch as speed and position [5]. Then control center plans\nconvenient routes for users based on sensor time series to avoid\ntrafﬁc congestion.\nSecond, the spatial temporal dynamics of IoT time series\ncan be extremely complex. IoT time series may exhibit various\npatterns over different spatial and temporal scales. Here are\nsome examples: 1) IoT trafﬁc time series triggered by events of\nprogrammed machine activities or human interventions exhibit\nboth long-term and short-term temporal dependencies [6].\nSpeciﬁcally, frequent programmed machine activities, such as\nperiodic updates, are almost periodic and constitute short-\nterm dependencies. In contrast, human interventions, such as\nviewing surveillance videos, are bursty and occur much less\nfrequently. In this scenario, IoT dynamics are unpredictable\nbecause they are intertwined with or even partially determined\nby human behavior [7]. 2) Some IoT time series data may\nbe non-stationary due to the inﬂuence of the complex envi-\nronment [8], such as concept drift [9] and seasonality [10].\nIntuitively, non-stationarity means that the statistical properties\nof the process generating the IoT time series change over time.\n3) The sources of IoT time series data may be heterogeneous\nin the form of protocols, device data format, communication\ncapabilities of the devices, technologies, and hardware [11].\nThe heterogeneity of data sources can further lead to the\nheterogeneity of data characteristics, that is, time series gen-\nerated by different IoT devices/services may exhibit different\nbehaviors. 4) The low-cost, resource-constrained IoT sensors\nand the relatively uncontrollable environments in which they\nare deployed lead to more noise in IoT time series than data\ncollected from typical hosts. Noise included in IoT time series\nmay be caused by minor variations in the sensitivity of the\ndetector, unrelated events occurring within the vicinity of the\nsensor, or transmission-based errors in the data management\nsystem [12].\nNowadays, deep learning (DL) has been considered effec-\ntive in the time series analysis [13]–[15]. The development of\nDL has enabled researchers to solve complex problems in an\nend-to-end fashion to avoid manual feature extraction [16]. In\ngeneral, DL methods are categorized into supervised, semi-\nsupervised, and unsupervised methods based on the labels\navailable in the dataset. Since labeling large amounts of\ndata requires human resources that most organizations cannot\nafford, unsupervised DL methods have been used in a wide\nrange of applications in IoT scenarios [17], [18].\narXiv:2302.03284v3  [cs.LG]  21 Feb 2023\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n2\nA. Existing Surveys\nSeveral researchers have conducted surveys on time series\nmodeling and mining. This section summarizes the existing\nsurveys in the literature and compares them with our work,\nas Table I shows. To the best of our knowledge, most of the\nexisting surveys on time series analysis do not focus specif-\nically on IoT systems. Furthermore, existing surveys have\nnot systematically summarized the application of unsupervised\nDL in time series. In contrast, they only investigate speciﬁc\nmachine learning (ML) tasks, such as anomaly detection [12],\n[19]–[23], classiﬁcation [24], [25], clustering [26]–[31] and\nprediction [32], [33]. This article focuses on IoT time series\nand systematically discusses the advantages and applications\nof unsupervised DL methods. The most signiﬁcant difference\nbetween this article and existing surveys is that we bring\nunsupervised anomaly detection and clustering into a uniﬁed\nperspective and provide a general unsupervised DL-based\ntime series analysis framework for IoT. Studying unsupervised\nanomaly detection and clustering under this uniﬁed framework\nhelps to make works in these two ﬁelds learn from each\nother, reveal the relationship between DL’s capabilities and\nstructures, and then improve the ability of DL methods to\nanalyze IoT time series.\nThis paper focuses on unsupervised deep learning for time\nseries analysis with emphasis on anomaly detection and clus-\ntering. Other unsupervised time series modeling approaches\nbased on statistical methods other than DL methods, such as\nhidden Markov model [35] and functional principal component\nanalysis [36], are less relevant to our topic and not included\nin the article. Our unique survey perspective is also supported\nby the relevance of unsupervised anomaly detection and clus-\ntering in the following aspects, as shown in Fig. 1. First,\nresulting from the prohibitive cost for accessing ground-truth\nlabels of anomalies, anomaly detection methods in practice\nare predominately carried out in an unsupervised manner\n[37]. Clustering is also a typical unsupervised method [38].\nThat is to say, they both have to mine data patterns without\nsupervision, so it is particularly important to make full use\nof the information in the data. Second, unsupervised anomaly\ndetection and clustering both rely on the similarity measure-\nment of samples when mining data patterns. Speciﬁcally,\nanomaly detection methods identify anomalies by measuring\nthe similarity between the features of unknown samples and\nthose of normal samples. The clustering, on the other hand,\naims to organize samples with similar features into the same\ngroup. The above analysis shows that unsupervised anomaly\ndetection and clustering are closely related in the underlying\nprinciple. In fact, there have been some works using clustering\nto ﬁnd anomalies in unlabeled data [39], [40]. Typically, they\ncluster the data samples ﬁrst, and then assign anomaly score by\nusing the distance between the samples and the cluster centers\n[41].\nThis article investigates unsupervised anomaly detection\nand clustering in a unifying view to provide a general frame-\nwork for unsupervised DL-based time series analysis in the\ncontext of IoT. We then organize and discuss current works\nalong this framework, focusing on the structures and capa-\nClassification\nPrediction/\nForecasting\nUnsupervised\nanomaly detection\nClustering\nDL-based time series analysis\nUnsupervised Learning\n•\nUse the information in unlabeled \ndatasets to mine data patterns.\n•\nPay attention to the similarity \nmeasurement between samples.\n•\nClosely related in the underlying \nprinciple.\nFig. 1. The relevance between unsupervised anomaly detection and clustering.\nbilities of DL models. In addition, we also discuss emerging\napplication scenarios, public datasets, challenges, and potential\ndirections for IoT time series analysis to enhance the breadth\nof this survey.\nB. Scope and Organization\nThe scope of this review is as follows: First we discuss the\nmotivation for using DL techniques in light of the requirements\nof IoT time series analysis. Then we investigate two different\ntasks, anomaly detection and clustering, in a uniﬁed manner\nto summarize the general ﬂow of analyzing time series using\nDL techniques. After that, we introduce the current state-of-\nthe-art DL techniques and discuss their role in each stage of\nthe time series analysis ﬂow. In addition, we also list emerging\napplications and public datasets for IoT time series. Finally,\nwe discuss existing research challenges and future directions.\nTo the best of our knowledge, this paper is the ﬁrst survey of\nunsupervised DL methods for IoT time series.\nArticle Organization: The remainder of this article is\norganized as follows. Section II ﬁrst introduces the concept\nof time series analysis, which mainly focuses on time series\nanomaly detection and clustering. After that, we discuss the\nchallenges of IoT time series analysis and the motivation\nof using DL. Section III introduces a uniﬁed framework of\nunsupervised DL-based IoT time series analysis, which mainly\nconsists of three subsections. The ﬁrst subsection is about\ndata pre-processing of IoT time series data. The rest parts\nare feature extraction and pattern identiﬁcation based on DL\nmethods.\nA detailed review of DL methods related to time series\nanalysis is provided in Section IV. General purpose DL models\nand techniques are surveyed ﬁrst. Then state-of-the-art DL-\nbased methods for time series feature extraction, anomaly\ndetection, and clustering are classiﬁed and surveyed in detail.\nSection V summarizes the applications and datasets of IoT\ntime series analysis. Section VI discusses challenges and future\nresearch directions. Finally, we summarize our work in Section\nVII.\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n3\nTABLE I\nSUMMARY OF THE RELATED SURVEYS\nYear\nRef.\nContribution\nScope\nIoT\nDL\nAnomaly\nDetection\nClustering\n2014\n[20]\nOverview of outlier detection techniques for various forms of temporal data.\n\u0013\n2017\n[21]\nReview of graph theory-based anomaly detection in time series social networks data.\n\u0013\n2019\n[12]\nSurvey of current methods and future challenges of applying anomaly detection\ntechniques to IoT data.\n\u0013\n\u0013\n\u0013\n2020\n[22]\nResearch of statistical, ML and DL methods for univariate time series anomaly detection.\n\u0013\n\u0013\n2021\n[19]\nReview of DL-based anomaly detection methods for time series data.\n\u0013\n\u0013\n2021\n[23]\nReview of unsupervised outlier detection techniques in the context of time series.\n\u0013\n\u0013\n2005\n[26]\nSurvey of the algorithms, criteria and applications of time series clustering.\n\u0013\n2011\n[27]\nReview of panel time series data clustering based on ﬁnite mixture models.\n\u0013\n2014\n[28]\nSurvey of various subsequence time series clustering approaches.\n\u0013\n2015\n[29]\nExposition of four main components of time series clustering.\n\u0013\n2019\n[34]\nReview of clustering or classiﬁcation used in visual analytics for time series data.\n\u0013\n\u0013\n2020\n[30]\nResearch on the benchmark of time series clustering.\n\u0013\n\u0013\n2021\n[31]\nReview of deep time series clustering (DTSC) with a case study in the context of\nmovement behavior clustering.\n\u0013\n\u0013\nOurs\nSurvey of unsupervised deep learning methods for IoT time series analysis. Unsupervised\nanomaly detection and clustering are investigated under a uniﬁed framework.\n\u0013\n\u0013\n\u0013\n\u0013\nII. MOTIVATION FOR USING DL IN IOT TIME SERIES\nANALYSIS\nThis section discusses the motivation for using DL in IoT\ntime series analysis. We ﬁrst introduce time series analysis,\nfocusing mainly on anomaly detection and clustering. Then\nwe touch upon the challenges of analyzing IoT time series.\nFinally, we establish the motivation for using DL.\nA. Time Series Analysis\nA time series is a set of observations xt, each one being\nrecorded at a speciﬁed time instance t [42]. Compared with\nother types of data, time series data contain complex temporal\ndependencies and are often high-dimensional, making them\nchallenging to model and analyze [43]. Time series analysis\nmainly includes classiﬁcation, forecasting/prediction, anomaly\ndetection, and clustering. We focus on unsupervised time series\nanomaly detection and clustering in this article.\n1) Time Series Anomaly Detection: An anomaly is deﬁned\nas an observation that deviates signiﬁcantly from the majority\nof data [44]. It usually has actionable pieces of information\nwhich could be meaningful [45]. The basic interpretation of\nanomaly detection is to identify patterns that do not conform\nto the expected behaviors of the system [46]. In the context\nof IoT, a general deﬁnition of an anomaly is “a measurable\nconsequence of an unexpected change in the state of a system\nthat is outside of its local or global norm” [12]. Anomalies in\nthe IoT system may come from cyber-attacks, system failures,\nnoise, etc. For example, a sudden increase in the temperature\nof a room in a factory can signal that there is a ﬁre. Anomaly\ndetection, therefore, is the ﬁrst step to secure IoT systems and\nhas become an important research area [47]–[49].\nFollowing the literature, there are two ways to categorize\nanomalies in time series. First, time series anomalies can\nbe divided into point anomalies, subsequence anomalies, and\nsequence anomalies depending on the granularity [20], [23].\n• Point Anomalies. Point anomalies are data points that\nshow signiﬁcant deviations from other points in the time\nseries (global point anomalies) or from their neighboring\npoints in a particular frame (local point anomalies). Such\npoint anomalies may be caused by noise, sensor failures,\nor short-term outages in the system.\n• Subsequence Anomalies. A subsequence is a set of con-\nsecutive observations within a time series. Subsequence\nanomalies are subsequences that deviate from the ex-\npected patterns. However, if viewed separately, individual\npoints of the subsequences may all be within the expected\nrange.\n• Sequence Anomalies. When the input data is multivari-\nable, a univariate time series whose behavior is signif-\nicantly different from others is deemed as a sequence\nanomaly.\nSecond, from a behavior perspective, time series anomalies\ncan be divided into point anomalies, contextual anomalies, and\ncollective anomalies [12], [19].\n• Point Anomalies. Here, point anomalies refer to observa-\ntions or sequences that abruptly deviate from the normal\nstate of the entire dataset.\n• Contextual Anomalies. Contextual anomalies are obser-\nvations or sequences which not deviate from the normal\nrange in a global perspective but are out of the expected\npattern when considering the given context.\n• Collective Anomalies. Sets of observations showing dis-\ntinct patterns relative to the rest of the data are considered\ncollective anomalies.\nAnomaly detection is typically categorized into three as-\npects according to the input type: supervised, unsupervised,\nand semi-supervised. Among them, the essence of a supervised\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n4\nanomaly detection problem is a classiﬁcation problem that\ndistinguishes abnormality from normality. In practice, the\nscarcity of abnormal events limits supervised methods. Semi-\nsupervised anomaly detection learns a model of the normal\nclass and anomalies can be detected afterwards by deviating\nfrom that model [50]. Unsupervised anomaly detection gains\nno access to labels and identiﬁes the shared patterns among\nthe data instances to uncover the anomalies.\n2) Time Series Clustering: Clustering is one of the most\ncommonly used unsupervised learning algorithms. Time series\nclustering has been widely used in economics, medicine,\nengineering, and other ﬁelds. The goal of clustering is to orga-\nnize objects into homogeneous groups where the intra-group\nsimilarities are maximized, and the inter-group similarities are\nminimized [51]. Traditional clustering methods are generally\ndivided into ﬁve categories [52]: partitioning, hierarchical,\ndensity-based, grid-based, and model-based methods.\nHowever, due to the characteristics of time series data, it\nis difﬁcult for traditional clustering methods to achieve good\nperformance on raw time series. There are two main strategies\nto adapt traditional clustering methods to time series data [26].\nThe ﬁrst strategy is to choose a speciﬁc distance met-\nric for time series data, such as Euclidean distance, Ma-\nhalanobis distance, dynamic time warping (DTW) distance,\nand Kullback–Liebler distance [26]. Among these methods,\nEuclidean distance is the most widely used metric. But it\nis not suitable for multivariable IoT time series due to its\nill-deﬁned concept of proximity on high-dimensional settings\n[53]. Kullback–Liebler distance can effectively describe the\nsimilarity between different distributions, and it regards time\nseries as probability distributions. However, Euclidean distance\nand Kullback–Liebler distance require that the lengths of all\ntime series must be equal, which is not applicable in many\nreal IoT situations. Mahalanobis distance is a measure of\nthe distance between a variable and a distribution which is\ncalculated by a mean and the covariance matrix. This metric\nhas advantages in modeling multivariate time series as it\ntakes into account the correlations of different variables [54].\nBesides, Mahalanobis distance is robust to missing values [55],\nwhich are common in IoT time series. DTW is a mapping of\npoints between a pair of time series designed to minimize\nthe pairwise Euclidean distance. DTW tries to warp the time\nof the two time series to ﬁnd the closest possible match [56].\nTherefore, DTW is effective at ﬁnding similar time series with\ntime shifts. Such shifts can be observed in IoT time series data\ndue to physical misplacement or other erroneous acts.\nThe second strategy is to extract features from time series\nand subsequently cluster the time series based on the extracted\nfeatures. This article mainly focuses on the second strategy in\nthe context of DL.\nB. Challenges of IoT Time Series Analysis\nThe term Internet of Things (IoT) generally refers to\nscenarios where network connectivity and computing capa-\nbility extend to sensors and everyday items, allowing these\ndevices to generate and exchange data with minimal human\nintervention [57]. Examples of IoT machines and systems\ncould be manufacturing, wearable devices, or smart cities.\nThese IoT devices continuously generate a large number of\nmulti-dimensional time series and store critical information\n[58]. Examining these collected data is of great signiﬁcance\nfor system security and resource optimization. For exam-\nple, detecting suspicious events from time series can reduce\nthreats and avoid unseen issues that cause downtime in the\napplications, allowing administrators to minimize losses [45].\nBesides, clustering daily electricity time series can mine the\ncorrelation information between different buildings in an area,\nwhich provides a basis for optimizing the electricity price\nsetting and power facility conﬁguration [59].\nHowever, the complicated spatial temporal dynamics, high\ndimensionality, and large volume of IoT time series inevitably\nentail challenges for data analysis based on traditional ma-\nchine learning methods. First, traditional machine learning\nalgorithms fail to capture the spatial and temporal correlations\nsimultaneously [60]. Most traditional algorithms only focus\non the temporal correlations of IoT time series, with no or\nlimited addressing of the spatial impact among IoT devices.\nSecond, scalability is a key challenge for IoT time series\nanalysis. Dealing with the complex spatial temporal dynamics\nof high-dimensional, large-amount IoT time series exceeds the\ncapabilities of traditional methods, which rely on expensive,\ntime consuming-manual feature extraction and prior expert\nknowledge. In addition to computational efﬁciency, scalability\nis also about lower communication overhead (e.g., how often\na device needs to communicate with other machines), as well\nas reduced information needed (e.g., what type of information\na device needs before making decisions) [61].\nC. Deep Learning for IoT Time Series Analysis\nMachine Learning (ML) is intended to allow a system to\nlearn from the past or the present and to use the knowledge\nto make future predictions or decisions [62]. Deep learn-\ning (DL) is a subﬁeld of ML which enables computational\nmodels composed of multiple processing layers to learn data\nrepresentations. The multiple levels of features in DL are\nautomatically discovered and composed together to produce\nthe outputs. Compared with ML, the main advantage of DL is\nthe automatic feature extraction that avoids the tedious labor\nof generating feature representations manually. DL has gained\ngreat recognition in many areas such as computer vision,\nnatural language processing, and bioinformatics. Nowadays,\nacademia and industry apply DL to wider applications, such\nas IoT scenarios. IoT networks produce a large amount of data,\nand therefore, traditional data collection, storage, and process-\ning techniques may not work at this scale [63]. However, these\ndata are required by DL approaches to bring intelligence to\nthe systems.\nApplying DL methods to IoT time series analysis has\nthe following advantages. First, DL methods achieve higher\npower and ﬂexibility when dealing with massive and high-\ndimensional IoT time series due to their ability to process\nlarge amounts of data in parallel. Second, DL has powerful\nautomatic feature extraction capabilities. Theoretically, DL\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n5\nmodels can approximate any complex non-linear functions\nand can ﬁt any curves as long as they have enough layers\nand neurons [64]. With the multi-layer structure of neural\nnetworks, the complex spatial temporal dynamics in IoT time\nseries data can be learned automatically and effectively.\nHowever, using DL techniques in IoT time series analysis\nbrings additional challenges. First, it is challenging to label\nlarge amounts of data. Generally, sufﬁcient labeled data is\na prerequisite for training accurate deep learning models.\nHowever, it is infeasible to label the continuously generated,\nmassive IoT time series accurately. Second, IoT devices with\nlimited storage and computing resources cannot support deep\nlearning models with a large number of parameters [65].\nComplex models for hosts in traditional networks may fail\non IoT devices. On the other hand, complicated calculations\ncould generate a high computation overhead and lead to a rapid\ndecrease in the lifetime of IoT devices. Other challenges stem\nfrom the understanding of DL models. For example, most deep\nneural networks operate as black boxes and offer little inter-\npretability [66]. Besides, different ML tasks require different\ncapabilities of DL models, making it difﬁcult to select the\nappropriate model that best adapts to a given problem. In this\narticle, we systematically review unsupervised DL methods\nfor IoT time series. Particularly, we investigate unsupervised\nanomaly detection and clustering under a uniﬁed framework\nto provide insights into the structures and capabilities of DL\nmodels.\nIII. THE UNIFIED FRAMEWORK OF DL-BASED TIME\nSERIES ANALYSIS\nTime series analysis is of great importance for IoT system\nmanagement. In this section, we investigate anomaly detection\nand clustering to summarize the general process of analyzing\nIoT time series using DL techniques, as shown in Fig. 2. With-\nout loss of generality, this process can be abstractly divided\ninto two core stages, namely feature extraction and pattern\nidentiﬁcation. The aim of feature extraction is essentially the\nsame for different time series analysis tasks. That is, selecting\nan appropriate DL model according to the characteristic of\ninput data so that the learned representations can describe\nthe state of the monitored system as accurately as possible.\nBut the second stage, pattern identiﬁcation, varies from task\nto task and requires carefully designed objective functions.\nFor example, anomaly detection aims to identify whether the\nfeatures of an unknown sequence are similar to those of\nnormal sequences. The clustering, on the other hand, aims to\norganize sequences with similar features into the same group.\nSpeciﬁcally, based on the characteristics of IoT time series\ndata, we introduce some special designs when modeling and\nprocessing IoT time series data in III-A. Then we discuss\nthe other two important steps of IoT time series analysis,\nfeature extraction, and pattern recognition in III-B and III-C,\nrespectively.\nA. Data Preprocessing for IoT time series\nAs mentioned earlier, the challenges of IoT time series\nanalysis mainly arise from the complex spatial temporal dy-\nnamics of the massive and high dimensional data. For multi-\nvariate time series, there are mainly ﬁve modeling strategies\n[19]: 1) using raw data as input directly; 2) extracting the main\nfeatures via dimensional reduction; 3) using a 2D matrix to\ncapture the relationships among individual variables directly;\n4) constructing a graph to deﬁne an explicit topological\nstructure and learn the causal relationship among individual\nvariables; 5) deﬁning correlations by speciﬁc distribution such\nas multivariate Gaussian distribution.\nThere have also been designs for dealing with non-\nstationarity, heterogeneity, and noise of IoT time series. For\nnon-stationary time series, researchers can convert them into\nstationary time series through methods such as detrending to\nreduce their damage to DL models.\nThe heterogeneity in IoT data sources limits learning\ntechniques from realizing optimal performance. There have\nbeen studies regarding multimodal source fusion and het-\nerogeneous data processing for IoT. Time series encoding\nis one of the techniques to mitigate the effect of IoT time\nseries heterogeneity. [67] encoded the time series data from\ndifferent smartphone inertial sensors into three-channel image\nrepresentation (i.e., RGB) to improve the accuracy of heteroge-\nneous human activity recognition. Besides, some studies have\nshown that certain types of neural networks are robust to data\nheterogeneity. For example, in smart device localization, RSS\nvalues vary at the same location for different smart devices\nbecause of the difference in the receiver antenna, receiving\ncircuit, frequency bands, and other factors. To cope with this\nproblem caused by data heterogeneity, [68] found that using\nthe Residual Neural Network can reduce the localization error.\nUsing low-quality noisy IoT data as input can lead to\nincorrect analysis results. Therefore, denoising is a key prepro-\ncessing step for IoT time series analysis. Denoising methods\nfor time series mainly include 1) mathematical transforma-\ntions [69], such as Fourier and wavelet transforms; 2) deep-\nlearning-based supervised denoising [70], such as Denoising\nAutoencoder (DAE).\nIt is also worth noting that in some cases where the\nquantity or quality of IoT data is insufﬁcient, data augmen-\ntation [71] can be applied to facilitate the training of DL\nmodels. Generally, data augmentation increases the amount\nof data by adding synthetic data or slightly modiﬁed copies of\nexisting data. Looking at time series data, basic approaches to\ndata augmentation include time domain methods, frequency\ndomain methods, and time-frequency domain methods [72].\nSix commonly used augmentation methods for ECG series\n[73], a kind of IoT time series, are introduced in Fig. 3: speed\nvariation, rotation, time warping, missing value simulation,\nadding noise in time-domain, and adding noise in frequency\ndomain.\n• Speed Variation. Resample the time series to simulate\ndifferent heart rates. The deceleration and the acceleration\nof ECG time series are shown in Fig. 3(a) and Fig. 3(b),\nrespectively.\n• Rotation. Time series data often contains synchronization\nerrors, or the timestamps are not perfectly aligned. Rotat-\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n6\nSimilar with\nnormal\nrepresentations?\nAnomaly detection\nIoT\ntime series\nLatent\nrepresentations\nPattern \nidentification\nData \npreprocessing\nNormal\nrepresentations\nNormal\ntime series\nUnknown\ntime series\nUnknown representations\nNormal\nAbnormal\nYes\nNo\nTwo categories \nof time series\nRepresentations\n…\nRepresentations in the \nsame cluster are similar\nto each other\nDeep learning-based\nfeature extractor\nCluster 2\nCluster 1\n…\nClustering\nDeep learning-based\nfeature extractor\nFeature \nextraction\nFig. 2. A uniﬁed deep learning framework for unsupervised IoT time series analysis.\ning the time series can simulate synchronization errors.\nThe right rotation and the left rotation of ECG time series\nare shown in Fig. 3(c) and Fig. 3(d).\n• Time Warping. This method can be used to simulate the\nimmediate increase or decrease of heart rate. Remove r%\npoints at random from the time series, and then add r%\npoints at random. A case of r=10 is shown in Fig. 3(e).\n• Missing Value Simulation. Randomly set the value of a\nsubsequence to 0 to simulate the missing values caused by\nequipment failure. A case with 10% missing data points\nis shown in Fig. 3(f).\n• Time Domain Noise. Add noise to the time series in the\ntime domain. A time series with Gaussian noise is shown\nin Fig. 3(g).\n• Frequency Domain Noise. In low signal-to-noise ratio\n(SNR) conditions, adding noise directly in the time do-\nmain may destroy data characteristics. In contrast, adding\nnoise in the frequency domain is a better choice. A\ntime series that contains Gaussian noise in the frequency\ndomain is shown in Fig. 3(h).\nB. Feature Extraction\nConversion of given input data into set of features are\nknown as Feature Extraction [74]. Features learned from\nthe initial dataset are expected to be descriptive and non-\nredundant, simplifying subsequent analysis. Unlike traditional\nhandcrafted feature extraction, DL can automatically learn\ntime series features through complex nonlinear transforma-\ntions.\nFormally, a feature extractor f(·) can encode a univariate\ntime series X = {xt}t∈T into a latent vector Z or encode\na multivariate time series X = {xt}t∈T into a latent matrix\nZ. Using Z or Z for downstream tasks can reduce the cost\nof feature analysis and improve the accuracy and efﬁciency\nof models. We discuss how to select an effective feature\nextraction model according to the characteristics of the input\ntime series in subsection IV-B.\nC. Pattern Identiﬁcation\nWell-known time series analysis tasks include anomaly\ndetection, clustering, classiﬁcation, and forecasting. Each task\nidentiﬁes a particular data pattern from the learned represen-\ntations. For example, a semi-supervised anomaly detection\nmodel learns the pattern of normal data. Then test samples that\ndeviate from the normal pattern will be deemed as anomalies.\nAs for clustering, the DL model explores different patterns in\na dataset so that samples conforming to the same pattern will\nbe grouped into the same cluster.\nIn the pattern identiﬁcation phase, some works apply\ntraditional algorithms such as anomaly detection algorithms\n(Isolation Forest [75], one-class SVM [76], etc.) or cluster-\ning algorithms (K-Medoids, K-Means, etc.) to the previously\nlearned representations. However, in this case, the feature\nextraction and the pattern identiﬁcation are two independent\nstages, leading to suboptimal performance. A better strategy\nis to analyze problems end-to-end using DL models, that is,\nto automatically learn data features and calculate the results.\nNext, we will categorize and comment on DL-based anomaly\ndetection and clustering methods.\nIV. MODELS BASED ON DEEP LEARNING\nIn this section, we ﬁrst introduce several commonly used\nDL models and techniques. Then we review and categorize\ncurrent DL-based methods for time series feature extraction,\nanomaly detection, and clustering.\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n7\n(a) Deceleration\n(b) Acceleration\n(c) Right Rotation\n(d) Left Rotation\n(e) Time Warping\n(f) Missing Value Simulation\n(g) Time Domain Noise\n(h) Frequency Domain Noise\nFig. 3. Visualization of several data augmentation methods for ECG series.\nThe blue lines represent the original time series. The red lines represent the\naugmented time series. (a) Deceleration rate = 0.1. (b) Acceleration rate = 0.1.\n(c) Shift two steps to the right. (d) Shift two steps to the left. (e) Time warping\nrate = 0.1. (f) Missing rate = 0.1. (g) Add white Gauss noise (µ = 0, σ =\n0.05) in the time domain. (h) Add white Gauss noise (µ = 0, σ = 0.5) in\nthe frequency domain.\nA. Deep Learning Models and Techniques\nThe most basic model of artiﬁcial neural network (ANN)\nis multi-layer perceptron (MLP), which is a fully connected\nfeed-forward neural network [77]. Many types of neural net-\nworks have been proposed in the past decade. This subsection\nintroduces DL models commonly used for time series analysis.\n1) Convolutional Neural Network (CNN): CNN is suitable\nfor processing data with a grid-like structure [71]. It is a feed-\nforward neural network composed of three types of layers:\nconvolutional layers, pooling layers, and fully connected lay-\ners. The convolutional layer is the core building block of CNN.\nIt involves the multiplication of the input with a set of weights\ncalled a ﬁlter or a kernel. In the convolutional layers, the\nprevious layer’s output will be used as the input of the next\nlayer.\n2) Recurrent Neural Network (RNN): RNNs are dominant\nin research areas involving sequential data. The typical archi-\ntecture of RNN is a cyclic connection that enables the RNN\nto update the current state based on past states and current\ninput data [78]. However, gradients of conventional RNNs\nmay tend to disappear or explode during the propagation,\nwhich makes them difﬁcult to learn long-term dependencies.\nLong Short-Term Memory (LSTM) [79] and Gated Recurrent\nUnits (GRUs) [80] are proposed to resolve this issue. They\nuse internal mechanisms called gates to regulate the ﬂow of\ninformation.\nThere have been some attempts to combine RNNs and\nCNNs. Convolutional LSTM (ConvLSTM) [81] replaces the\nfully-connected layers in LSTM with convolutional layers\nto capture the spatio-temporal correlation. The Quasi-RNN\nmodel [82] alternates convolutional layers and simple recurrent\nlayers to allow parallel processing. The Dilated RNN [83] uses\ndilated recurrent skip connections to reduce model parameters\nand improve training efﬁciency. Bai et al. [84] proposed a gen-\neral architecture of convolution-recurrent models named Time\nConvolutional Network (TCN). They used causal convolution\nto ﬁt sequential data and extended convolution and residual\nmodules to memorize past states.\n3) Graph Neural Networks (GNN): GNNs [85] emerge\nas new approaches for modeling graph-structured data. There\nare usually complex topological relationships between sensors\nin IoT scenarios, so the whole system can be seen as a graph\nstructure where nodes represent sensors and edges describe the\nrelationships among nodes [86], [87]. GNNs have proved to\nbe effective for large-scale multi-relational data modeling [88],\nmaking them promising for modeling high-dimensional time\nseries. Up till now, GNNs can be categorized into Recurrent\nGNNs, Convolutional GNNs, Graph Autoencoders, and Spatial\nTemporal GNNs [89].\n4) Autoencoder (AE): Autoencoders are primarily de-\nsigned to encode an input into a latent representation and\nthen reconstruct it [90]. Generally, the dimension of the\nencoded representation is smaller than the input dimension.\nThe simplest form of an autoencoder is a feedforward, non-\nrecurrent neural network that employs an input layer and an\noutput layer connected by one or more hidden layers.\n5) Generative Adversarial Network (GAN): GANs are\nmachine learning frameworks consisting of two neural net-\nworks that compete with each other: one (the generator G) is\ntrained to generate fake data, and the other (the discriminator\nD) is trained to discern the fake data from the real one. G\ngenerates better data during training, while D becomes more\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n8\nClustering\nReconstruction-based\nDiscrimination-based\nPrediction-based\nAnomaly detection\nDeep representation learning-based\nJoint representation learning-based\nLabel prediction-based\nDeep learning\nmodels and techniques\nCNN\nRNN\nAE\nGAN\nAttention mechanism\nTransfer learning\nSelf-supervised learning\nFeature extraction \nDirect feature extraction\nGenerative model-based\nfeature extraction\nGNN\nTransformer\nHybrid\nFig. 4. Taxonomies of unsupervised DL methods for time series anomaly detection and clustering.\nskilled at discerning fake data. GANs can implicitly model the\nhigh-dimensional distribution of data [91].\n6) Transformer: Transformer [92] is an architecture that\nleverages the attention mechanism to process sequence data.\nUnlike RNNs, which rely on an inherently sequential nature,\nTransformer allows the model to access any part of the history\nregardless of distance, making it signiﬁcantly more paralleliz-\nable and potentially more suitable for capturing long-term\ndependencies. Canonical Transformer follows an encoder-\ndecoder structure using stacked self-attention and point-wise,\nfully connected layers. Li et al. [93] improved the canonical\nTransformer to make it more ideal for time series modeling.\nPrecisely, they used convolutional self-attention to utilize local\ncontext and proposed LogSparse self-attention to break the\nmemory bottleneck.\nNext we introduce techniques that can facilitate DL-based\ntime series analysis, such as attention mechanism, transfer\nlearning, and self-supervised learning.\n1) Attention Mechanism: The attention mechanism [92]\nis a component of the neural network architecture responsible\nfor capturing the correlations between different parts of data.\nIt helps the model automatically identify the crucial parts\nof the input data and assign them large weights. Attention\nmechanism has been widely used in many ﬁelds, such as\nmachine translation, speech recognition, and image caption. In\nthe ﬁeld of time series modeling, it is assumed that previous\ntime steps have different correlations with the current state.\nThus, models with attention mechanisms can adaptively select\nappropriate previous time steps and aggregate the information\nto form a reﬁned output [94]–[96].\n2) Transfer Learning (TL): It is challenging to train a\nreliable DL model through the traditional supervised learning\nparadigm with insufﬁcient labeled data. To cope with this\nproblem, TL utilizes labeled data from different but related\ntasks to facilitate the learning of the target task. In other\nwords, the knowledge learned from a related task is trans-\nferred to the target task [97]. Generally, the target model\nis ﬁrst pre-trained on an auxiliary dataset and then ﬁne-\ntuned on target data. Wen et al. [98] used TL to improve\ntheir time series anomaly detection model’s generalization\ncapabilities for unknown anomalies. They synthesized a pre-\ntraining dataset with short-term, medium-term, and long-term\nanomalies. These anomalies can be considered components\nof other complex anomalies, so the information learned from\nthe synthetic dataset would beneﬁt general anomaly detection\ntasks.\n3) Self-Supervised Learning (SSL): Another commonly\nused strategy to deal with the lack of labeled data is SSL.\nAs a branch of unsupervised learning, SSL leverages input\ndata itself as supervision [99]. The general process of SSL\nconsists of two steps. The ﬁrst step is to train a pretext task\non a large amount of unlabeled data. Then the second step is\nto ﬁne-tune the pre-trained model according to the target task.\nMa et al. [15] used SSL to improve representation learning.\nFirst, they generated a fake sample for each unlabeled time\nseries by shufﬂing partial timestamps. Then, the classiﬁcation\nof true and fake samples was used as an auxiliary task.\nB. Models for Feature Extraction\nA direct strategy of time series feature extraction is to\ninput time series into a feed-forward neural network and take\nthe output as representations. The most basic neural networks\nare MLPs. But MLPs ignore the temporal dependencies of\ntime series. Researchers have applied various more complex\nneural networks to feature extraction of time series.\nRNNs can capture complex temporal dependencies be-\ntween different time steps through a cyclic connection. An\nRNN trained on normal data can learn the normal behavior\nof a dynamic system [100], [101]. However, it is difﬁcult\nfor conventional RNNs to learn long-term dependencies due\nto the vanishing gradient. By utilizing the mechanism of\ngates, LSTMs perform better at modeling long sequences,\nbut the multiplying parameters of LSTMs increase the risk\nof overﬁtting. GRUs are more suitable for small-scale data\nbecause they can achieve similar performance as LSTMs with\nsimpler structures and fewer parameters. Also noteworthy, the\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n9\nTABLE II\nSUMMARY OF TIME SERIES FEATURE EXTRACTION METHODS BASED ON DL MODELS.\nCategory\nMajor Model\nRelated Works\nDirect Feature Extraction\nRNN\n[95] (Bi-direction GRU), [100] (LSTM), [101] (LSTM),\n[102] (Bi-direction GRU), [103] (LSTM), [104] (GRU)\nCNN\n[94], [96], [105]\nRNN + CNN\n[106]\nGNN\n[107] (GAT), [86] (Graph convolution), [108] (GAT)\nGenerative Model-Based\nFeature Extraction\nAutoencoder\n[15] (Bi-direction dilated recurrent autoencoder), [94] (Convolutional autoencoder),\n[95] (Bi-direction recurrent autoencoder), [96] (Convolutional autoencoder),\n[109] (Bi-direction DAE), [110] (SAE), [111] (SAE), [112] (VAE),\n[113] (Convolutional autoencoder), [114] (Convolutional autoencoder), [115] (Convolutional autoencoder),\n[116] (Convolutional autoencoder and recurrent autoencoder), [117] (Time convolutional autoencoder)\nGAN\n[118] (Recurrent GAN), [119] (GAN)\nstate of an RNN is usually passed from the front to back.\nBut in some cases, modeling time series simultaneously from\nforward and reverse can utilize more context information and\npromote representation learning. For example, Trosten et al.\n[102] used a bidirectional GRU to learn representations of\nmultivariable time series.\nCNNs can extract patterns of high-dimensional data with\ncomplex structures [120]. Zhang et al. [94] and Carrasco et al.\n[96] used CNN to extract representations of the sequences of\nsystem feature maps. Ren et al. [105] transformed time series\ninto saliency maps by the Spectral Residual (SR) algorithm\nand then analyzed the maps with CNNs.\nLiu et al. [106] used a hybrid model of LSTM and CNN\nto capture the long-term and short-term dependencies in the\nnetwork trafﬁc sequence. First, they built an LSTM model\non the network trafﬁc to capture long-term dependencies.\nThen a CNN is applied to the hidden states of the LSTM to\nextract the local spatial information. The ﬁnal representations\nlearned by the hybrid model fully encapsulate the sequence\ncharacteristics.\nWhen analyzing multivariate time series, the most straight-\nforward strategy is to treat each dimension as an independent\nunivariate time series. For example, Hundman et al. [103]\nconstructed an LSTM-based predictor for each univariate time\nseries when modeling multivariate aerospace remote sensing\ndata. However, treating each dimension separately has the\nfollowing disadvantages. First, it is labor-intensive to train\nand maintain an separate model for each dimension. Besides,\nthe dependencies among multiple dimensions are ignored.\nMethods such as multivariate Gaussian distributions [121] and\ntwo-dimensional matrices [19] can model these dependencies\nexplicitly.\nAnother promising approach to deal with multivariate time\nseries is GNN. Deng et al. [107] encoded the asymmetric rela-\ntionships between pairs of sensors as directed edges in a graph.\nIn the case without prior information, the graph’s adjacency\nmatrix is obtained by similarity measurement and embedded\nby a Graph Attention Network (GAT). Chen et al. [86] devised\na directed graph structure learning policy to automatically\ndiscover the adjacency matrix. Then graph convolution layers\nintegrated with different level dilated convolution layers are\nEncoder\nDecoder\nLatent\nrepresentation\nInput\ntime series\nReconstruction\nOutput\nReconstructionerror\nFig. 5. Feature extraction based on autoencoders.\nutilized to capture hierarchical temporal context. Zhao et\nal. [108] modeled the inter-feature correlations and temporal\ndependencies of multivariate time series with two GATs in\nparallel, followed by a GRU network to capture long-term\ndependencies.\nGenerative Model-Based Methods: In addition to the above\nworks, some researchers consider using generative models to\nachieve better representation capabilities. Generative models\nassume that the available data is generated by some unknown\ndistribution and try to estimate this distribution. Commonly\nused generative models include autoencoders and GANs.\nAutoencoders learn the distribution of the input data by\nminimizing the reconstruction loss that measures the distance\nbetween the output of the decoder and the input data. As\nshown in Fig. 5, the output of the encoder can be regarded\nas a meaningful representation that retains important patterns\nof the input data. The simplest autoencoder consists of three\nlayers: an input layer, a hidden layer, and an output layer.\nFurther, a stacked autoencoder (SAE) [122] contains multiple\nhidden layers, where the output of the front hidden layer is\nused as the input of the next hidden layer. Each layer produces\na more abstract representation than the one before because\nthe representation is obtained by composing more operations\n[123]. Doyup Lee [110] used an SAE with three hidden\nlayers to detect anomalies in a database management system.\nTavakoli et al. [111] used an SAE to cluster ﬁnancial data.\nThe number of hidden layers and hidden units is determined\nby the dataset.\nHowever, traditional autoencoders are trained only to min-\nimize the reconstruction errors, which may lead the model to\ncopy the input without learning helpful information. Denoising\nautoencoders (DAEs) are proposed to solve this problem. A\nDAE takes noisy data as input but is forced to reconstruct the\nclean version of the input [96], [109]. Another kind of well-\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n10\nknown autoencoders, Variational autoencoders (VAEs) [124],\nattempt to model the underlying probability distribution of\ndata. The latent space of a VAE is forced to obtain a speciﬁed\ndistribution so that a random vector sampled from the latent\ndistribution can generate meaningful content similar to the real\ndata. The latent constraint also improves the generalization\nability of VAEs. Lin et al. [112] used VAEs to learn robust\nlocal features of time series windows.\nAutoencoders can be constructed based on different neural\nnetworks. RNNs can enhance the sequence modeling capabil-\nity of autoencoders. Ienco and Interdonato [95] proposed a\nbidirectional GRU-based autoencoder to capture the complex\ntemporal dependencies among multivariable time series. Ma\net al. [15] proposed an autoencoder based on bidirectional\nextended RNNs [125]. Compared with traditional RNNs,\nextended RNNs contain the multi-resolution extended skip\nconnection that can reduce parameters, improve training ef-\nﬁciency, and maintain multi-level dependencies.\nCNNs can enhance the ability of autoencoders to extract\ncomplex features. The encoder of a convolutional autoencoder\n(CAE) contains convolutional layers, and the decoder contains\ndeconvolution layers. Biradar et al. [113] used CAEs to extract\nfeatures of trafﬁc videos in their anomaly detection framework.\nRichard et al. [114] used CAEs to learn meaningful represen-\ntations of electric power consumption time series. However,\nthese CNN-based works ignore the temporal dependencies of\ntime series data.\n[94] and [96] proposed spatio-temporal autoencoders to\ndeal with multivariable time series in Cyber-Physical-Systems\n(CPSs). They used 2D-CAEs to encode the correlations be-\ntween different sensors and then used ConvLSTMs to capture\nthe dynamic patterns of the system. Kalinicheva et al. [115]\nextracted features of the satellite image time series (SITS) with\na 3D-CAE, in which the 3D ﬁlter could preserve the temporal\ndependencies between data. Compared with the ConvLSTM\nstructure that combines 2D convolution and RNNs, the 3D\nconvolution has a lower computational overhead when mod-\neling sequence data.\nMeng et al. [117] captured features of Cyber-Physical-\nSocial Systems (CPSS) time series with a time convolutional\nnetwork-based automatic encoder (TCN–AE). It’s composed\nof causal convolution, dilated convolution, a residual module,\nand an FCN. TCN’s parallelism and low memory overhead\nenable TCN-AE to be applied in large and complex systems in\ncloud-fog-edge computing. Bhatnagar et al. [116] considered\ndifferent temporal resolutions when learning representations of\nhuman activities of varying time spans in videos. They used a\nset of CAEs to learn frame-level representations with varying\nintervals. Then multiple LSTM autoencoders are constructed\non the output of CAEs to obtain the ﬁnal representations.\nBesides autoencoder, another commonly used generative\nmodel is Generative Adversarial Network (GAN). [126] has\nproven that a trained GAN can model the distribution of\nhigh-dimensional time series data well. Bashar et al. [119]\nlearned the distribution of given time series through adversarial\ntraining as Fig. 6. They simultaneously trained an LSTM-\nbased generator G that generates fake time series data and\nNoise in\nlatent space\nGenerator\nG\nBackpropagation\nDiscriminator\nD\nFake time series\nReal time series\nIs 𝑫correct?\nFig. 6. Feature extraction based on GANs.\nan LSTM-based discriminator D to distinguish between the\ngenerated and real data. Li et al. [118] used LSTM-based\nGAN to learn the representations of multivariate time series\nin CPS systems. The proposed GAN framework processes\ntime series from multiple sensors simultaneously to capture\nthe latent interactions among the sensors. By being able to\ngenerate realistic data, the generator G will have captured the\nhidden distributions of the training sequences.\nC. Models for Anomaly Detection\nAccording\nto\nthe\ndetection\nprinciples,\nexisting\nDL-\nbased time series anomaly detection methods can be di-\nvided into three categories: reconstruction-based methods,\ndiscrimination-based methods, and prediction-based methods.\n1) Reconstruction-Based Methods: Reconstruction mod-\nels refer to those neural networks with a bidirectional mapping\nbetween data space and latent space, such as autoencoders.\nThe encoder maps the input data into a latent space, and\nthe decoder maps the latent vector back to the data space. A\nreconstruction model trained on normal samples could learn\nthe manifold of normal data. Therefore, a normal sample in\nthe test set will be reconstructed well, but anomalous samples\nwill not since the model has not seen anomalies during the\ntraining phase. In other words, it is reasonable to suspect that\na sample of low reconstruction quality is abnormal.\nThe most direct criterion of the reconstruction quality is\nthe reconstruction error, which is the distance between the\nreconstructed data and the input data [110], as Fig. 5 shows.\nZhang et al. [94] used multi-scale reconstruction errors of\nmultivariable time series to diagnose anomalies in complex\nsystems. They constructed multi-scale matrices of system\nstates and built convolutional encoders to embed the temporal\ndependencies between various sensors into low-dimensional\nrepresentations. Then a convolutional decoder is used to recon-\nstruct the learned representations. The obtained residual matrix\ncan be applied to anomaly detection, root cause analysis [132],\nand anomaly degree interpretation.\nZhou et al. [129] pointed out that reconstruction can be\nviewed as a process of projecting a test sample on the training\ndata manifold. They combined the reconstruction error of an\nautoencoder with the latent representation and reconstruction\nresidual vector to form a new representation for anomaly\ndetection. For a test sample, these three factors correspond\nto its projection on the training data manifold, its direction\nto its projection, and its distance to its projection. Therefore,\nthe new representation can characterize how a test sample\ndeviates from the normal pattern, and anomaly detectors based\non the new representations can have better generalization\nperformance on unseen data.\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n11\nTABLE III\nSUMMARY OF DL-BASED TIME SERIES ANOMALY DETECTION METHODS.\nWork\nCategory\nDescription\n[94]\nReconstruction-based\nReconstruction errors of multi-scale and multivariable time series are used to detect and diagnose anomalies in\ncomplex systems.\n[109]\nReconstruction-based\nA VAE is used to reconstruct the distribution parameters of the input data. The reconstruction probability is used\nas the anomaly score.\n[110]\nReconstruction-based\nReconstruction errors of an autoencoder are used as the anomaly score.\n[119]\nReconstruction-based\nReconstruction errors of a GAN’s generator are used as the anomaly score.\n[127]\nReconstruction-based\nReconstruction errors of an LTSM-based autoencoder are used as the anomaly score.\n[128]\nReconstruction-based\nA weighted sum of the reconstruction errors of two adversarially-trained autoencoders is used as the anomaly score.\n[129]\nReconstruction-based\nIt learns representations more meaningful for anomaly detection through the process of reconstruction.\n[118]\nDiscrimination-based\nThe discrimination results and reconstruction residuals of GAN are combined as a novel anomaly score.\n[86]\nPrediction-based\nCombine the graph structure with Transformer to model multivariable time series.\n[100]\nPrediction-based\nAn LSTM Mixture Density Network is used to learn the mixture distribution representing the probability density\nof input data.\n[101]\nPrediction-based\nAn LSTM is used to predict the mean and variance of the input time series. Then the likelihood is used as the\nanomaly score.\n[103]\nPrediction-based\nThe prediction errors are smoothed by EWMA to reduce false positives.\n[107]\nPrediction-based\nUse GAT to predict values of multiple correlated sensors.\n[112]\nPrediction-based\nA VAE is used to form the local features, and an LSTM is used to estimate the long-term correlation.\n[130]\nPrediction-based\nAn attention mechanism-based CNN is used to extract features. Then an LSTM is used to calculate the probability\nof anomaly.\n[131]\nPrediction-based\nThe correlation among multivariate time series is presented by ARX models. Then an LSTM is used to predict the\nabnormal labels of the residual sequence.\n[108]\nHybrid\nOptimize a reconstruction-based model and a prediction-based model jointly.\nAnother criterion of the reconstruction quality is recon-\nstruction probability. Pereira et al. [109] utilized a VAE to\nreconstruct the input data distribution parameters (the mean\nµx and the variance bx), and the reconstruction probability\nis considered the abnormal score. First, they constructed an\nencoder to obtain posterior parameters (µz, Σz) of an input\nsequence. Then they sampled L instances from the latent\ndistribution of the VAE and reconstructed their parameters\n(µlx, blx). Finally, they computed reconstruction probability,\nthe average log-likelihood of the input data, as the anomaly\nscore.\nIn addition to autoencoders, another model commonly\nused for reconstruction-based anomaly detection is GAN. The\ngenerator network of a GAN can generate realistic (fake) time\nseries from the latent space. However, GANs do not directly\noffer the mapping from the data space to the latent space.\nBashar et al. [119] proposed an iterative search algorithm\nto ﬁnd corresponding latent representations of the input time\nseries. Thus, the entire GAN-based framework in [119] can\nreconstruct time series and detect anomalies.\nTo combine the advantages of autoencoders and GANs,\nAudiber et al. [128] performed adversarial training on two\nautoencoders. On the one hand, the encoder-decoder structure\nimproves the stability of the adversarial training. On the other\nhand, the adversarial training allows the model to amplify the\nreconstruction error of inputs that contain anomalies. Both\nautoencoders learn to reconstruct a normal sample in the\nﬁrst training stage. Then they compete against each other:\nAE2 is trained to distinguish the real data from the data\ngenerated by AE1, and AE1 is trained to fool AE2. Finally,\nthe anomaly score is a weighted sum of the two autoencoders’\nReconstruction\nloss\nNoise in\nlatent space\nGenerator\nG\nDiscriminator\nD\nFake time series\nReal time series\nIs 𝑫correct?\nBackpropagation\nDiscrimination\nloss\nNovel anomaly score\nFig. 7. A combination of reconstruction loss and discrimination loss.\nreconstruction errors.\n2) Discrimination-Based Methods:\nThe core idea of\ndiscrimination-based anomaly detection is to establish a dis-\ncriminator model that directly predicts anomaly scores or\nanomaly labels of the input time series. For example, a GAN\npresents a discriminator D that learns to distinguish between\nfake (abnormal) data and true (normal) data. Li et al. [118]\nproposed a GAN-based time series anomaly detection frame-\nwork named MAD-GAN as Fig. 7. This framework predicts a\nnovel anomaly score that combines the discrimination results\nof the discriminator D and the reconstruction residuals of the\ngenerator G.\nThe reconstruction-based and the discrimination-based\nanomaly detection can efﬁciently detect subsequence anoma-\nlies or sequence anomalies. The following subsection will\nintroduce the prediction-based time series anomaly detection\nmethods, which are more suitable for predicting whether an\nobservation in a time step is abnormal based on contextual\ninformation.\n3) Prediction-Based\nMethods:\nGenerally,\nprediction-\nbased anomaly detection methods work as follows. A pre-\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n12\ndiction model trained on normal samples predicts the values\nor conditional probabilities of future time steps based on\nthe previous observations. Data points that deviate from the\nprediction will be deemed as anomalies.\nIn general, the difference between the incoming value\nand the predicted value can be used as the anomaly score\nfor each timestamp. The most commonly used model for se-\nquence prediction is RNN, which can learn complex temporal\ndependencies between previous and current time steps. Lin\net al. [112] proposed a hybrid model capable of identifying\nanomalies that span over multiple time scales. Their model\nuses a VAE to form robust local features in short windows and\nan LSTM to estimate long-term correlations in the sequence\non top of features inferred from the VAE.\nHundman et al. [103] pointed out that the abrupt change of\ntime series is often not perfectly predicted, resulting in sharp\nspikes in the residual error sequence even when the change\nis normal. To reduce the false positives of anomaly detection\ncaused by the false alarm spikes, they smoothed the residual\nerror sequence of LSTM by an exponential weighted average\n(EWMA) algorithm.\nFor multivariable time series, Deng et al. [107] consider\nsequences from multiple sensors as nodes of a graph and\ninter-sensor correlations as edges. They forecast future values\nof each sensor based on a graph attention function over its\nneighbors. Then they calculated anomaly scores, or prediction\nerrors, for each sensor and each time tick to ﬁgure out anomaly\nstates of the whole system. Chen et al. [86] also regarded\nIoT sensors as nodes of a directed graph structure. They\nused an efﬁcient multi-branch Transformer to make a single-\nstep time series forecasting and return an anomaly score for\neach testing timestamp. Combining the graph structure with\nthe Transformer enables the model to simultaneously capture\ninter-variable correlations and temporal dependencies of high-\ndimensional time series.\nSome anomaly detection methods make predictions on\nprobability distributions of the input data rather than values.\nThese methods deﬁne anomalies as observations drawn from a\nsigniﬁcantly divergent unknown distribution. Inoue et al. [101]\nconstructed an LSTM to predict the mean and variance of the\ninput time series and used the likelihood of the series as the\nanomaly score. Liu et al. [130] also adopted a similar predic-\ntion principle, but they extracted more ﬁne-grained features of\nthe time series by an attention mechanism-based CNN.\nWalton et al. [100] utilized mixture models to predict more\ncomplex distributions. They used a K component Gaussian\nmixture model to approximate the probability density of the\ndigital radio transmissions time series in a dynamic environ-\nment. Given a historical sequence, they proposed an LSTM\nMixture Density Network (MDN) to estimate the parameters\nof the Gaussian mixture model, and the likelihood of each test\nsequence is considered the anomaly score.\nBesides, some works directly predict anomaly labels of\nthe test samples. Dou et al. [131] focused on collective\ncontextual anomalies (CCA) that break the complex relations\namong multivariable time series in a complex IT system.\nThey modeled the system with an invariant graph, in which\neach node represents a univariable time series, and each\nedge represents a correlation between two nodes. They built\nautoregressive with exogenous terms (ARX) models to capture\neach edge’s invariance. Then, an LSTM is used to predict the\nanomaly labels of the residual sequences obtained from the\nARX models.\n4) Hybrid Methods: Different anomaly detection methods\ncan complement each other. Zhao et al. [108] jointly optimized\na reconstruction-based model and a prediction-based model to\nobtain better time series representations for anomaly detec-\ntion. Precisely, they summed the loss functions of a single-\ntimestamp prediction and the complete sequence reconstruc-\ntion. The anomaly score for each timestamp is calculated based\non the prediction value and reconstruction probability output\nby the hybrid model.\nD. Models for Clustering\nDL-based time series clustering methods can be mainly di-\nvided into three categories: deep representation learning-based\nclustering, joint representation learning-based clustering, and\nlabel prediction-based clustering.\n1) Deep Representation Learning-Based Clustering: Ap-\npropriate time series representation is essential for the efﬁ-\nciency and accuracy of clustering [134]. If two time series\nare similar in data space, their representations should also be\nsimilar in latent space. Thus, researchers can apply traditional\nclustering algorithms to the latent representations extracted by\nDL models. When clustering on low-dimensional representa-\ntions, the algorithm causes fewer memory requirements and\nless computational overhead of distance measurements.\nRichard [114] learned time series representations with a\nconvolutional autoencoder to accelerate the subsequent clus-\ntering. A convolutional autoencoder is trained to reconstruct\nthe input time series. Then a clustering algorithm is applied\non top of the learned representations in the latent space of\nthe autoencoder. The clustering algorithm they chose was K-\nMedoids, which is simple and robust to outliers.\nKalinicheva et al. [115] used a hierarchical clustering al-\ngorithm (HCA) [135] to cluster the representations of satellite\nimage time series (SITS), which are extracted by a multi-view\n3D convolutional autoencoder. The HCA does not demand a\nresearched number of clusters. Besides, Bhatnagar et al. [116]\nused the K-Means algorithm to cluster videos and discover\nmeaningful actions. The video features are extracted in two\nsteps. First, they used an array of convolutional autoencoders\nto learn the frame-level representations. Then multiple LSTM\nautoencoders are used to capture temporal information.\n2) Joint Representation Learning-Based Clustering: Al-\nthough the deep representation learning-based clustering meth-\nods beneﬁt from the feature extraction capability of DL mod-\nels, they do not guarantee that the learned representations have\na good clustering structure. An effective strategy to solve this\nproblem is jointly learning the representations and clustering.\nMa et al. [15] proposed a deep cluster representation\n(DTCR) framework to obtain time series representations that\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n13\nTABLE IV\nSUMMARY OF DL-BASED TIME SERIES CLUSTERING METHODS.\nWork\nCategory\nDescription\n[114]\nDeep representation learning-based\nRepresentations learned by a convolutional autoencoder are clustered by K-Medoids.\n[115]\nDeep representation learning-based\nRepresentations learned by a multi-view 3D convolutional autoencoder are clustered by the\nhierarchical clustering algorithm (HCA).\n[116]\nDeep representation learning-based\nRepresentations learned by an array of convolutional autoencoders and LSTM autoencoders are\nclustered by K-Means.\n[15]\nJoint representation learning-based\nThe temporal reconstruction and K-means objective are integrated into the seq2seq model to obtain\ncluster-speciﬁc temporal representations.\n[95]\nJoint representation learning-based\nA GRU-based autoencoder is used to obtain initial representations of time series, which are stretched\ntowards clustering centroids by K-Means.\n[133]\nJoint representation learning-based\nA framework is proposed to simultaneously implement video clustering, representational learning,\nand action segmentation. The clustering process provides supervisory cues for other tasks.\n[102]\nLabel prediction-based\nA recurrent network is presented to predict soft clustering labels of the input time series.\n[111]\nLabel prediction-based\nThe clustering is transformed into a task of label prediction.\nEncoder\nDecoder\nReal latent\nrepresentation\nReal input\nReconstruction\nloss\nFake input\nFake latent\nrepresentation\nK-means loss\nClassification\nloss\nFig. 8. A joint representation learning-based clustering framework.\nmaintain temporal dynamics, multi-scale features, and good\nclustering properties. As shown in Fig. 8, they used an autoen-\ncoder based on bidirectionally expanded RNN to reconstruct\nthe input data. Most importantly, a K-Means objective is\nintegrated into the latent space to guide the representation\nlearning.\nSimilarly, Ienco and Interdonato [95] used the K-Means al-\ngorithm to stretch the learned representation manifold towards\nclustering centroids. They obtained the initial representations\nwith a GRU-based autoencoder that consists of two encoders\nin reverse directions. Then the initial representations are opti-\nmized cyclically: 1) during each training epoch, the K-Means\nalgorithm is executed over the current representations; 2) then\nthe distance between the representations and the clustering\ncentroids is added into the loss function. Their hybrid algo-\nrithm can handle multivariate time series of variable lengths,\nbut the number of clusters must be speciﬁed in advance.\nFurther, Tzirakis et al. [133] proposed a framework that\nsimultaneously implements video clustering, representation\nlearning, and action segmentation. The framework is divided\ninto three parts: 1) clustering the time series data (this process\nprovides supervisory cues for the proposed framework); 2)\nlearning deep representations in an end-to-end manner with\nCNNs; 3) identifying the temporal boundaries of the segments.\nThese three parts are optimized iteratively during the training\nphase.\n3) Label Prediction-Based Clustering: There have been\nsome attempts to transform clustering into a label prediction\nproblem based on DL. Trosten et al. [102] proposed a recurrent\nnetwork to predict soft clustering labels for the input time\nseries. They ﬁrst used a two-layer bidirectional GRU to obtain\nrepresentations for all time series. Then they predicted soft\nclustering labels for the representations by a fully connected\noutput layer with a softmax activation function. Finally, they\ndeﬁned a divergence-based loss function to discover the un-\nderlying clustering structure. This loss function consists of\nthree terms corresponding with three critical characteristics\nof clustering: 1) cluster separability and compactness; 2)\ncluster orthogonality in the observation space; 3) closeness\nof cluster memberships to a simplex corner. This model can\nhandle multivariate time series of variable lengths and does\nnot require distance measurement in the data space.\nTavakoli et al. [111] used an autoencoder to predict pseudo\nlabels for data, which are assigned based on the initial clus-\ntering results. The neuron in the output layer represents the\nprobabilistic value of the clustering label, and the clustering\naccuracy can be measured by the mean square error (MSE) of\nthe prediction results.\nSummary: This section systematically reviews DL-based\ntime series anomaly detection and clustering. First, we intro-\nduced DL models and techniques commonly used in time se-\nries analysis. Then, we discussed DL-based feature extraction.\nThe related works are summarized in Table II. Finally, we\ncategorized and reviewed the DL-based approaches for time\nseries anomaly detection and clustering. The involved works\nare listed in Table III and Table IV.\nV. APPLICATIONS\nWith the development of IoT, anomaly detection and clus-\ntering have been used widely to explore complex data patterns\nand provide recommendations to system administrators. This\nsection ﬁrst introduces the emerging applications of IoT time\nseries anomaly detection and clustering. Then some well-\nknown time series datasets are summarized.\nA. Applications of IoT Time Series Analysis\n1) Smart Healthcare: Smart healthcare is a health service\nsystem that uses technology such as IoT to access informa-\ntion dynamically and then actively manages and responds\nto medical ecosystem needs in an intelligent manner [136].\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n14\nThe application of smart healthcare contains smart hospitals,\nassisting diagnosis and treatment, health management, etc. IoT\ntime series analysis has been widely used in smart healthcare.\nFor example, the recent advent of low-cost IoT-based health\nsensors can produce an enormous amount of time series\ndata for continuous monitoring of various physiological and\npsychological parameters of a human body [137].\n[138] proposed an IoT-edge-enabled anomaly detection\nmethod to work on the pulse sensor-driven real-life analog\nhealth time series data. It can analyze IoT-based sensor-\noriginated health data at the edge devices quickly and automat-\nically. [139] aimed to overcome the drawbacks of centralized\nanomaly detection models in the Internet of Medical Things\n(IoMT). They proposed a Federated Learning (FL) based\nanomaly detection model which utilizes edge cloudlets to run\nmodels locally without sharing patients’ data. The models\nanalyzed time series from a set of devices, such as motion\nsensor, smart thermometer, smart oximeter, and smart ECG.\n[140] proposed an unsupervised anomaly detection method for\nhealthcare time series data to cope with the issue that labels\nare often difﬁcult to obtain in applications like healthcare.\n[141] presented a particle swarm optimization-based clus-\ntering technique for the effective selection of cluster heads\namong diverse IoT devices. Appropriate cluster head selec-\ntion can reduce the amount of energy spent on transmitting\ndata from IoT devices to a cloud server. [142] clustered the\nsensory data collected through wearable devices to obtain a\nsummarized version of the original data and surmount the\ndata overload and processing latency in real-time remote\nmonitoring.\n2) The Industrial Internet of Things (IIoT): The IIoT is\ncomprised of sensor driven computing, data analytics and\nintelligent machine applications to provide scalability, efﬁ-\nciency and interoperability which directly promotes automa-\ntion in critical infrastructure and improve enterprise produc-\ntivity [143]. Artiﬁcial Intelligence for IT Operations (AIOps)\nis closely related to the management of IIoT. Data from\nsensors and equipment in factories is collected and analyzed.\nFor example, the shop ﬂoor is tracked and monitored by\nsensors in real-time, and predictive analytics is used to identify,\npredict, and prevent. AIOps empowers engineers to efﬁciently\nbuild services in IIoT that are easy to maintain and help\nto achieve higher service quality and customer satisfaction,\nincrease engineering productivity, and reduce costs [144].\nIn IIoT systems, data anomalies inevitably appear due to\nthe scale, computation, and storage complexities. In addition,\nthe networked sensors make IIoT systems more vulnerable to\nattacks on the control elements, network, or physical envi-\nronment. Therefore, timely detection of anomalies in sensor\nreadings helps to ensure maximum uptime for machines.\n[145] monitored different sensor data of engines, such as fuel\nusage, engine load, and oil pressure, to detect potential engine\nfailures. Giannoni et al. [146] developed an anomaly detection\nframework for a wastewater plant where IoT sensors are\ndeployed to manage chemical and particulate concentrations\nin storage tanks. This framework triggers reactive measures\nautomatically to identify the abnormal state of tanks. Aoudi\net al. [147] detected subtle structural changes in multivariate\nmonitored signals to prevent cyber-attacks on cyber-physical\nsystems. In addition, [148] pointed out that it is beneﬁcial to\nconsider the gradual aging of the IIoT’s physical dimension\nwhen detecting anomalies.\nClustering methods can capture underlying states of in-\ndustrial time series and identify unexpected events. Sun et\nal. [149] used a graph-based clustering algorithm to detect\nbotnets in IoT networks based on the assumption that a group\nof similar nodes in a graph might represent a botnet. Javier et\nal. [150] utilized the cluster assignment robustness to detect\nconcept drift in a monitoring system. The concept drifts alert\nthat the monitored process is changing over time, probably\ndue to degradation or other abnormal behaviors.\n3) Smart Buildings/Smart Cities: Smart buildings and\nsmart cities use IoT devices to monitor various entities of citi-\nzens, devices, buildings, and streets. The collected data is then\nprocessed to monitor and manage trafﬁc and transportation\nsystems, air quality, human behavior, cyber-attacks, etc.\nAnomaly detection methods have been applied to detect\ntrafﬁc congestion and incidents. These methods can improve\ncity mobility by regulating vehicular trafﬁc or advising users\nto modify their path to avoid trafﬁc jams [151], [152]. The\nsystem in [113] automatically detects anomalous events in\ntrafﬁc videos, which can be applied to trafﬁc rules violation\ndetection and suspicious movements analysis. [153] detected\nvarious anomalous road surface conditions, such as potholes,\nmanholes, transverse cracks, decelerating strips, and railroad\ncrossings.\nEnvironmental pollution management has gradually be-\ncome a critical issue in smart cities as the population density\ncontinues to grow. Jain et al. [154] analyzed time series of\nthe air pollution monitoring system to detect unhealthy or\nanomalous locations. The framework in [155] can detect po-\ntential regional emission sources and identify malfunctioning\ndevices. The government has referred to their analysis results\nwhen formulating environmental policies. Clustering methods\ncan also explore valuable information for environmental mon-\nitoring. [156] identiﬁed the major air pollutants of seventy-\nfour Chinese cities based on clustering. [157] identiﬁed the\npattern of air pollution sources using chemometric analysis\nthrough hierarchical clustering. [158] clustered air quality time\nseries sampled at different sites to identify similar patterns and\nreduce redundant information.\nThe vehicle-to-everything (V2X) [159] is an important\napplication of IoT technologies in the transportation industry\nand a key component of smart cities. Attacks on vehicles can\nlead to the leakage of personal information or even trafﬁc\naccidents [160]. Therefore, time series anomaly detection and\nclustering have been widely used in the security of V2X.\n[161] proposed an LSTM-based time series anomaly detection\nframework for the message ﬂows of the in-vehicle CAN\nnetwork. [162] applied reinforcement learning (RL) approach\nto detect misbehaving vehicles by exploiting real-time position\nand speed patterns. [163] proposed a distributed anomaly de-\ntection system framework on autonomous vehicle data. [164]\npresented a stable clustering algorithm for V2X networks to\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n15\nprovide trafﬁc information accurately and instantaneously for\ntrafﬁc control.\nAnother application of IoT time series anomaly detection\nand clustering is human behavior analysis. Anomaly detection\nhelps detect health problems or risky behaviors of people.\nThe smart assisted-living systems for elderly care proposed\nin [165] can effectively detect anomalous behaviors in human\ndaily life. For example, when a monitored individual is found\nto be on the ﬂoor for an extended period, this behavior\nmay suggest a fall or collapse. The framework in [166]\nused causal association rules mining to extract anomalous\nbehaviors. For instance, when one is using the phone despite\nbeing in the kitchen but the stove is on, there may be a risk\nof FireElectricity.\nClustering can discover semantically meaningful actions\npresent in videos, promoting the convenience and safety of\nsmart buildings and smart cities. [133] proposed a graph-\ndegree linkage clustering algorithm for human motion seg-\nmentation. The algorithm can analyze whether the monitored\nobject is performing a particular activity. In [116], a robust\nﬁrst-person action clustering approach is proposed to auto-\nmatically analyze lifelogging videos generated by wearable\ncameras.\nFinally, as more intelligent appliances have been connected\nto the Internet, these vulnerable IoT devices have become the\ntargets of cyberattacks. [167]–[169] studied how to identify\nanomalous activities and attacks in smart buildings.\n4) Smart Energy: The real-time monitoring and control\nof smart grids (SGs) are critical to enhancing power utilities’\nreliability and operational efﬁciency. The massive number\nof time series generated by smart meters (SMs) provides\nopportunities for better monitoring of power utilities.\nAnomalous behaviors in smart grids include transmission\nline outages, unusual power consumption, momentary and\nsustained outages. Anomaly detection methods for SGs can\nbe divided into four main categories [170]: 1) consumption\nanalysis; 2) malicious and security attacks detection; 3) fault\nlocation; and 4) outage detection. In [170], operators mon-\nitored power usage to enhance the situational awareness of\nutility operators so that they could identify faults in the local\ndistribution network in real-time before customers’ feedback.\nPasserini et al. [171] proposed a framework that enables\nthe autonomous detection and location of network anomalies\nin distribution grids. The framework mainly includes two\nalgorithms. The ﬁrst algorithm is used to detect and track the\nevolution of faults over time. The second algorithm uses the\nknowledge of the network topology to localize the detected\nanomaly by analyzing the sensed trace in the time domain. As\nSMs are likely to be exposed to multiple cyber-attacks, [172]\nevaluated consumers’ energy utilization behavior to identify\npotential energy frauds and faulty meters.\nThe clustering analysis also has great potential in energy\nefﬁciency programs. [173] clustered accounts based on their\nusage proﬁles to ﬁnd accounts with similar energy usage\ntendencies. [114] clustered electricity consumption time series\nof different clients to distinguish different types of users\n(such as residential clients, SMEs, and secondary homes). This\nprocess is conducive to the reﬁned management of the energy\ngrids.\nB. IoT Time Series Datasets\nVarious IoT time series datasets have been proposed in\nrecent years. This subsection introduces some IoT time series\ndatasets commonly used in anomaly detection and clustering,\nas summarized in Table V.\nSecure Water Treatment Dataset (SWaT) [174] and Water\nDistribution Dataset (WADI) [175] are two commonly used\nIoT time series datasets for anomaly detection. SWaT is\na testbed for cyber-security research built at the Singapore\nUniversity of Technology. The dataset contains 51 variables\n(sensor readings and actuator status) for 11 consecutive days:\n7 days collected under normal operations and 4 days collected\nwith attack scenarios, during which 36 simulated attacks were\ncarried out. The WADI dataset is collected from the WADI\ntestbed by measuring 103 variables for 16 days. The ﬁrst 14\ndays are under normal operations, and the last 2 days are under\nattack scenarios.\nThe Wearable Stress and Affect Detection (WESAD)\ndataset [176] records physiological and motion data of ﬁf-\nteen subjects measured through two IoMT devices, namely\nRespiBAN and Empatica E4, for two hours. The data includes\nthe following sensor modalities: blood volume pulse, electro-\ncardiogram, electrodermal activity, electromyogram, respira-\ntion, body temperature, and three-axis acceleration.\nThe BoT-IoT dataset [177] is an IoT botnet dataset col-\nlected from a simulated IoT environment. The testbed applied\nﬁve IoT scenarios: a weather station, a smart fridge, motion-\nactivated lights, a remotely activated garage door, and a smart\nthermostat. The BoT-IoT dataset contains over seventy-two\nmillion incorporated legitimate and simulated IoT network\ntrafﬁc, along with various attacks, such as DDoS, DoS, service\nscan, keylogging, and data exﬁltration.\nThe IoTID20 dataset [178] is an IoT botnet dataset gen-\nerated from a testbed of a smart home environment which\nconsists of smart home device SKT NGU and EZVIZ Wi-\nFi camera. Other devices connected to the smart home router\ninclude laptops, tablets, and smartphones. The SKT NGU and\nEZVIZ Wi-Fi camera are IoT victim devices, and all other\ndevices in the testbed are the attacking devices. Eight types\nof attacks were conducted, such as Syn ﬂooding, host brute\nforce, and ARP spooﬁng. The ﬁnal version of the IoTID20\ndataset consists of eighty-three network features and three\nlabel features.\nThe MQTTset dataset [179] is an IoT dataset focused\non MQTT communications and the associated IoT threats. It\nis composed of IoT devices of different natures to simulate\na smart home/ofﬁce/building environment. Eight sensors lo-\ncated into two separated rooms record temperature, humidity,\nmotion, CO-Gas, door opening/closure, fan status, smoke,\nand light. MQTTset includes both legitimate and malicious\ntrafﬁc over a week. Each sensor is conﬁgured to trigger\ncommunication at a speciﬁc time to simulate a real behavior\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n16\nTABLE V\nSUMMARY OF IOT TIME SERIES DATASETS.\nName\nYear\nRef.\nDescription\nSWaT\n2015\n[174]\nA water treatment time series datasets with simulated attack scenarios. It monitors 51 sensors for 11\nconsecutive days.\nWADI\n2016\n[175]\nA water treatment time series datasets with simulated attack scenarios. It monitors 103 sensors for 16\nconsecutive days.\nWESAD\n2018\nred [176]\nA multivariate time series dataset of wearable stress and affect detection. It can be used in smart\nhealthcare.\nBoT-IoT\n2019\n[177]\nAn IoT botnet dataset that incorporates legitimate and simulated IoT network trafﬁc, along with various\ntypes of attacks.\nIoTID20\n2020\n[178]\nAn IoT anomalous activity detection dataset generated through home-connected smart devices. It\nincludes eight attack types.\nMQTTset\n2020\n[179]\nAn IoT dataset focused on MQTT communications and the associated IoT threats.\nMedBIoT\n2020\n[180]\nAn IoT botnet detection dataset collected from eighty-three real and emulated IoT devices.\nIoT-23\n2020\n[181]\nA labeled dataset with malicious and benign IoT network trafﬁc over 2018 to 2019 from twenty-three\ndifferent scenarios.\nMQTT-IoT-IDS2020\n2021\n[182]\nA dataset collected from MQTT-IoT sensors. The network consists of twelve MQTT sensors and\ncontains four types of attacks.\nTON IoT\n2021\n[183]\nDatasets that include heterogeneous telemetry data of IoT/IIoT services, as well as the operating systems\nlogs and network trafﬁc of IoT network.\nX-IIoTID\n2021\n[184]\nAn IIoT intrusion dataset with the behaviors of new IIoT connectivity protocols, activities of recent\ndevices, diverse attack types and scenarios, and various attack protocols.\nIoTHealth\n2021\n[185]\nA synthetic IoT time series dataset for smart healthcare. Five human physiological parameters are\nconsidered. It can be used for multivarite or univarite anomaly detection.\nCIC IoT dataset 2022\n2022\n[186]\nA dataset for IoT identiﬁcation/proﬁling and intrusion detection. The network contains sixty IoT devices.\nDifferent stages, scenarios and attacks are analyzed.\nEdge-IIoT\n2022\n[187]\nA comprehensive realistic cyber security dataset of IoT and IIoT applications for centralized and\nfederated learning. Five threats are included.\nof a home automation. The malicious trafﬁc was generated by\nlaunching attacks against the MQTT broker.\nThe MedBIoT dataset [180] is an IoT botnet detection\ndataset collected from real and emulated IoT devices in a\nmedium-sized network (i.e., eighty-three devices). Three ac-\ntual botnet malware, Mirai, BashLite, and Torii, were deployed\nin the network, and the dataset is focused on the early stages\nof botnet deployment (spreading and C&C communication).\nMedBIoT is split according to the trafﬁc source (i.e., normal\nor malware trafﬁc) allowing to easily label the data and extract\nfeatures from the raw pcap ﬁles.\nThe IoT-23 dataset [181] consists of twenty-three captures\n(called scenarios) of different IoT network trafﬁc ranging from\n2018 to 2019. Both malicious network trafﬁc and benign\nIoT trafﬁc are included. Speciﬁcally, the malicious trafﬁc\nis obtained from twenty malware captures executed in a\nRaspberry Pi, and the benign network trafﬁc was obtained\nfrom three different real IoT devices: a smart LED lamp, a\nhome intelligent personal assistant, and a smart doorlock.\nThe MQTT-IoT-IDS2020 dataset [182] is an Intrusion\nDetection Systems (IDS) dataset based on Message Queu-\ning Telemetry Transport (MQTT) communication protocol.\nThe network consists of twelve MQTT sensors, a broker,\na machine to simulate camera feed, and an attacker. The\ndataset consists of ﬁve recorded scenarios: normal operation\nand four attack scenarios. During normal operation, all sensors\nsend randomized messages with different lengths to simulate\ndifferent usage scenarios. The attacker performs four types of\nattacks: aggressive scan, UDP scan, Sparta SSH brute-force,\nand MQTT brute-force attack.\nThe\nTON-IoT\ndatasets\n[183]\ninclude\nheterogeneous\ntelemetry data of IoT/IIoT services, as well as the operating\nsystems logs and network trafﬁc of IoT network, which were\ncollected from a realistic representation of a medium-scale\nnetwork. In the testbed of TON IoT, two smartphones and a\nsmart TV were logged in network trafﬁc, and seven IoT and\nIIoT sensors (e.g., weather, temperature, and Modbus sensors)\nwere used to capture their telemetry data. The network dataset\nof Ton IoT includes nine types of attacks, such as scanning,\nDoS, DDoS, and ransomware.\nThe X-IIoTID dataset [184] is the ﬁrst-of-its-kind IIoT\nintrusion dataset that includes the behaviors of new IIoT\nconnectivity protocols, activities of recent devices, diverse\nattack types and scenarios, and various attack protocols. The\nauthor distilled a generic attack life-cycle framework for IIoT\nattacks and generated different attacks in each stage. X-IIoTID\ncontains 421,417 normal records, 399,417 malicious records,\nand ﬁfty-nine features collected from network trafﬁc, device\nresources, and device/alert logs.\nThe IoTHealth dataset [185] can be used for performing\nmultivariate or column-wise univariate anomaly detections.\nThe IoT-based synthetic data considers ﬁve human physio-\nlogical parameters such as skin conductance (C) in micro\nSiemens, body temperature (T) in Fahrenheit, blood pressure\nlow (BL), blood pressure high (BH), and root mean square\nof successive difference (RMSSD) of heart rate variability\n(HRV) in milliseconds. Each of the variable columns include\nanomalies.\nThe CIC IoT dataset 2022 [186] is a state-of-the-art dataset\nfor intelligent identiﬁcation and intrusion detection of sixty\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n17\ndifferent IoT devices with different protocols such as IEEE\n802.11, Zigbee-based, and Z-Wave. The data contains different\nstages of each device and different scenarios of the simulated\nnetwork activity of a smart home. Besides, two different\nattacks were performed to capture the attack network trafﬁc.\nThe Edge-IIoT dataset [187] is a comprehensive, realistic\ncyber security dataset of IoT and IIoT applications for cen-\ntralized and federated learning. The IoT data were generated\nfrom more than ten types of IoT devices, such as low-\ncost digital sensors for sensing temperature and humidity,\nultrasonic sensors, and water level detection sensors. The\ndata features were extracted from different sources, including\nalerts, system resources, logs, and network trafﬁc. Besides,\nﬁve threats related to IoT and IIoT connectivity protocols were\nanalyzed, including DoS/DDoS attacks, information gathering,\nman in the middle attacks, injection attacks, and malware\nattacks.\nVI. FUTURE CHALLENGES AND DIRECTIONS\nIn this section, we discuss the challenges faced by, and\nfuture research opportunities in applying DL in IoT time series\nanalysis.\n1) Insufﬁcient Labels: Since the scale and complexity\nof IoT systems continue to grow, labeling large amounts of\ntime series requires human resources that most organizations\ncannot afford. Therefore, it is unpractical to train DL models\nin a supervised manner. Developing accurate and robust un-\nsupervised models is a promising direction. In addition, data\naugmentation, transfer learning, and meta-learning [188] are\nalso effective ways to deal with the insufﬁciency or imbalance\nof training data.\n2) Real-Time Performance: Time series analysis is usually\napplied in short-term decisions of scenarios such as IIoT, smart\ncities, and smart energy. Most traditional DL models have\nlimited applications in these time-sensitive tasks because of\ntheir high computational complexity. For example, suppose\nan anomaly detector in an IIoT system takes a long time\nto process an observation. In that case, the system may\nhave suffered a severe fault before the operator received the\nalarm. To improve the real-time performance of DL models,\nresearchers can develop lightweight models and algorithms to\nreduce computational complexity. Besides, the compression\nand acceleration methods of DL models [189] are also worthy\nof attention.\n3) Interpretability: Generally, interpretability refers to the\nextent of human’s ability to understand and reason a model\n[190]. Although DL methods have achieved great success in\nmany ﬁelds, their extremely complicated structures make it\ndifﬁcult to understand the innerworkings. Therefore, the lack\nof interpretability has become one of the primary obstacles\nof DL methods, especially deep neural networks (DNNs), in\ntheir wide acceptance in mission-critical applications such as\nIIoT. At present, the interpretability of neural networks can\nbe classiﬁed into Post-hoc interpretability analysis and ad-hoc\ninterpretable modeling [190]. In the future, combining DL with\nhuman knowledge or neuroscience may promote interpretable\nresearch on DL.\n4) Distributed System: A large amount of time series data\nis generated in a distributed way, such as the observation\nvalues from different IoT devices in a factory. However, many\nDL models require high computational power that signiﬁcantly\noutweighs the capacity of resource- and energy-constrained\nIoT devices, making it difﬁcult to run DL models directly on\nIoT devices. One common way to solve this problem is to\ntransmit data from IoT devices to a data center, which brings\na high additional transmission delay. Edge intelligence is a\nnew technology to achieve low-latency data processing for IoT\ndevices. It moves cloud computing capabilities in data centers\ncloser to the distributed intelligent devices [191].\n5) Irregular Time Series:\nVarious sequence modeling\ntechniques have been applied in time series analysis, and\nresearchers constantly develop novel algorithms. However,\nDL models for time series in unconventional forms, such\nas irregular time series, are relatively unexplored. Irregular\ndata and the resulting missing values severely compromise\ntraditional DL methods. Jiao et al. [192] utilized Automatic\nMachine Learning (AutoML) to search the optimal neural\nnetwork structures for irregular time series. In future research,\nmore DL models adapted to irregular time series should be\ndeveloped and gated recurrent neural networks have been\nfound to be a promising direction [193].\n6) Privacy: IoT devices typically record sensitive infor-\nmation in factories, businesses, homes, and other environ-\nments. Privacy breaches may result in severe economic losses\nand physical threats. Therefore, privacy-protected DL methods\nare urgently needed in practice. For example, Yang et al.\n[194] assumed that the controller company has no direct\naccess to users’ consumption requirements during the energy\nscheduling, which preserves the consumption data privacy.\nThe federated learning (FL) technology [195] is a promising\nprivacy-preserving machine learning paradigm, in which mul-\ntiple clients (such as mobile devices) train models collabora-\ntively under a central server (such as a service provider). Other\nprivacy-preserving mechanisms such as differential privacy are\nalso effective in practice [196].\nVII. CONCLUSION\nIn the 5G era, IoT networks and mobile applications\ngenerate ever-increasing amount of time series data. In the\npast decade, DL has shown great potential in automatically\nextracting data features and tackling complex problems in an\nend-to-end fashion. In this article, we systematically review\nDL-based unsupervised anomaly detection and clustering un-\nder a uniﬁed framework. We hope our work can offer insights\ninto the structures and capabilities of DL models and promote\nthe applications of DL in IoT time series analysis.\nREFERENCES\n[1] K. Yang, N. Prasad, and X. Wang, “An auction approach to resource\nallocation in uplink OFDMA systems,” IEEE Transactions on Signal\nProcessing, vol. 57, no. 11, pp. 4482–4496, 2009.\n[2] J. Manyika, M. Chui, P. Bisson, J. Woetzel, R. Dobbs, J. Bughin, and\nD. Aharon, “The Internet of Things: Mapping the value beyond the\nhype,” 2015.\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n18\n[3] J. A. Stankovic, “Research directions for the internet of things,” IEEE\ninternet of things journal, vol. 1, no. 1, pp. 3–9, 2014.\n[4] I. P. S. Mary and L. Arockiam, “Imputing the missing data in IoT based\non the spatial and temporal correlation,” in 2017 IEEE International\nConference on Current Trends in Advanced Computing (ICCTAC).\nIEEE, 2017, pp. 1–4.\n[5] C. Wang, Z. Zhao, L. Gong, L. Zhu, Z. Liu, and X. Cheng, “A\ndistributed anomaly detection system for in-vehicle network using\nHTM,” IEEE Access, vol. 6, pp. 9091–9098, 2018.\n[6] H. Tahaei, F. Aﬁﬁ, A. Asemi, F. Zaki, and N. B. Anuar, “The rise of\ntrafﬁc classiﬁcation in IoT networks: A survey,” Journal of Network\nand Computer Applications, vol. 154, p. 102538, 2020.\n[7] L. Duan, L. Huang, C. Langbort, A. Pozdnukhov, J. Walrand, and\nL. Zhang, “Human-in-the-loop mobile networks: A survey of recent\nadvancements,” IEEE Journal on Selected Areas in Communications,\nvol. 35, no. 4, pp. 813–831, 2017.\n[8] M. Zhang, X. Li, and L. Wang, “An adaptive outlier detection and\nprocessing approach towards time series sensor data,” IEEE Access,\nvol. 7, pp. 175 192–175 212, 2019.\n[9] J. Gama, I. ˇZliobait˙e, A. Bifet, M. Pechenizkiy, and A. Bouchachia, “A\nsurvey on concept drift adaptation,” ACM computing surveys (CSUR),\nvol. 46, no. 4, pp. 1–37, 2014.\n[10] Q. Wen, J. Gao, X. Song, L. Sun, H. Xu, and S. Zhu, “RobustSTL: A\nrobust seasonal-trend decomposition algorithm for long time series,” in\nProceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 33,\nno. 01, 2019, pp. 5409–5416.\n[11] D. C. Y. Vargas and C. E. P. Salvador, “Smart IoT gateway for hetero-\ngeneous devices interoperability,” IEEE Latin America Transactions,\nvol. 14, no. 8, pp. 3900–3906, 2016.\n[12] A. Cook, G. Mısırlı, and Z. Fan, “Anomaly detection for IoT time-\nseries data: A survey,” IEEE Internet of Things Journal, 2019.\n[13] A. Javaid, Q. Niyaz, W. Sun, and M. Alam, “A Deep Learning\nApproach for Network Intrusion Detection System,” in EAI Endorsed\nTrans. Security Safety, 2016.\n[14] H.-K. Peng and R. Marculescu, “Multi-Scale Compositionality: Iden-\ntifying the Compositional Structures of Social Dynamics Using Deep\nLearning,” PLoS ONE, vol. 10, 2015.\n[15] Q. Ma, J. Zheng, S. Li, and G. Cottrell, “Learning Representations for\nTime Series Clustering,” in NeurIPS, 2019.\n[16] J. C. B. Gamboa, “Deep learning for time-series analysis,” arXiv\npreprint arXiv:1701.01887, 2017.\n[17] Y. Bengio, A. C. Courville, and P. Vincent, “Unsupervised feature\nlearning and deep learning: A review and new perspectives,” CoRR,\nabs/1206.5538, vol. 1, p. 2012, 2012.\n[18] S. N˜omm and H. Bahs¸i, “Unsupervised anomaly based botnet detection\nin IoT networks,” in 2018 17th IEEE international conference on\nmachine learning and applications (ICMLA).\nIEEE, 2018, pp. 1048–\n1053.\n[19] K. Choi, J. Yi, C. Park, and S. Yoon, “Deep Learning for Anomaly\nDetection in Time-Series Data: Review, Analysis, and Guidelines,”\nIEEE Access, 2021.\n[20] M. Gupta, J. Gao, C. Aggarwal, and J. Han, “Outlier Detection for\nTemporal Data: A Survey,” IEEE Transactions on Knowledge and Data\nEngineering, vol. 26, pp. 2250–2267, 2014.\n[21] M. R. Islam, R. Islam, and A. R. M. Kamal, “Time Series Anomaly\nDetection in Online Social Network: Challenges & Solutions,” in 1st\nInternational Conference on Machine Learning and Data Engineering:\niCMLDE 2017, 2017, pp. 21–28.\n[22] M. Braei and S. Wagner, “Anomaly Detection in Univariate Time-\nseries: A Survey on the State-of-the-Art,” ArXiv, vol. abs/2004.00433,\n2020.\n[23] A. Bl´azquez-Garc´ıa, A. Conde, U. Mori, and J. A. Lozano, “A Review\non outlier/Anomaly Detection in Time Series Data,” ACM Computing\nSurveys (CSUR), vol. 54, no. 3, pp. 1–33, 2021.\n[24] G. A. Susto, A. Cenedese, and M. Terzi, “Time-series classiﬁcation\nmethods: Review and applications to power systems data,” Big data\napplication in power systems, pp. 179–220, 2018.\n[25] H. Ismail Fawaz, G. Forestier, J. Weber, L. Idoumghar, and P.-A.\nMuller, “Deep learning for time series classiﬁcation: a review,” Data\nmining and knowledge discovery, vol. 33, no. 4, pp. 917–963, 2019.\n[26] T. W. Liao, “Clustering of time series data–a survey,” Pattern Recognit.,\nvol. 38, pp. 1857–1874, 2005.\n[27] S. Fr¨uhwirth-Schnatter, “Panel data analysis: a survey on model-\nbased clustering of time series,” Advances in Data Analysis and\nClassiﬁcation, vol. 5, pp. 251–280, 2011.\n[28] S. Zolhavarieh, S. Aghabozorgi, and Y. W. Teh, “A Review of Sub-\nsequence Time Series Clustering,” The Scientiﬁc World Journal, vol.\n2014, 2014.\n[29] S. Aghabozorgi, A. S. Shirkhorshidi, and T. Y. Wah, “Time-series\nclustering–A decade review,” Inf. Syst., vol. 53, pp. 16–38, 2015.\n[30] A. Javed, B. S. Lee, and D. M. Rizzo, “A Benchmark Study on Time\nSeries Clustering,” ArXiv, vol. abs/2004.09546, 2020.\n[31] A. Alqahtani, M. Ali, X. Xie, and M. W. Jones, “Deep Time-Series\nClustering: A Review,” Electronics, vol. 10, no. 23, p. 3001, 2021.\n[32] Z. Han, J. Zhao, H. Leung, K. F. Ma, and W. Wang, “A review of\ndeep learning models for time series prediction,” IEEE Sensors Journal,\nvol. 21, no. 6, pp. 7833–7848, 2019.\n[33] B. Lim and S. Zohren, “Time-series forecasting with deep learning: a\nsurvey,” Philosophical Transactions of the Royal Society A, vol. 379,\nno. 2194, p. 20200209, 2021.\n[34] M. Ali, A. Alqahtani, M. W. Jones, and X. Xie, “Clustering and\nClassiﬁcation for Time Series Data in Visual Analytics: A Survey,”\nIEEE Access, vol. 7, pp. 181 314–181 338, 2019.\n[35] S. R. Eddy, “Hidden markov models,” Current opinion in structural\nbiology, vol. 6, no. 3, pp. 361–365, 1996.\n[36] H. L. Shang, “A survey of functional principal component analysis,”\nAStA Advances in Statistical Analysis, vol. 98, no. 2, pp. 121–142,\n2014.\n[37] L. Ruff, J. R. Kauffmann, R. A. Vandermeulen, G. Montavon,\nW. Samek, M. Kloft, T. G. Dietterich, and K.-R. M¨uller, “A unifying\nreview of deep and shallow anomaly detection,” Proceedings of the\nIEEE, 2021.\n[38] A. E. Ezugwu, A. M. Ikotun, O. O. Oyelade, L. Abualigah, J. O.\nAgushaka, C. I. Eke, and A. A. Akinyelu, “A comprehensive survey\nof clustering algorithms: State-of-the-art machine learning applications,\ntaxonomy, challenges, and future research prospects,” Engineering\nApplications of Artiﬁcial Intelligence, vol. 110, p. 104743, 2022.\n[39] X. Wang, “Two-phase outlier detection in multivariate time series,” in\n2011 Eighth International Conference on Fuzzy Systems and Knowl-\nedge Discovery (FSKD), vol. 3.\nIEEE, 2011, pp. 1555–1559.\n[40] G. Pu, L. Wang, J. Shen, and F. Dong, “A hybrid unsupervised\nclustering-based anomaly detection method,” Tsinghua Science and\nTechnology, vol. 26, no. 2, pp. 146–153, 2020.\n[41] C. C. Aggarwal, “An introduction to outlier analysis,” in Outlier\nanalysis.\nSpringer, 2017, pp. 1–34.\n[42] P. J. Brockwell and R. A. Davis, Time series: theory and methods.\nSpringer Science & Business Media, 2009.\n[43] M. L¨angkvist, L. Karlsson, and A. Loutﬁ, “A review of unsupervised\nfeature learning and deep learning for time-series modeling,” Pattern\nRecognition Letters, vol. 42, pp. 11–24, 2014.\n[44] D. Hawkins, “Identiﬁcation of Outliers,” in Monographs on Applied\nProbability and Statistics, 1980.\n[45] R. Al-amri, R. K. Murugesan, M. Man, A. F. Abdulateef, M. A. Al-\nSharaﬁ, and A. A. Alkahtani, “A review of machine learning and\ndeep learning techniques for anomaly detection in iot data,” Applied\nSciences, vol. 11, no. 12, p. 5320, 2021.\n[46] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A\nsurvey,” ACM Comput. Surv., vol. 41, pp. 15:1–15:58, 2009.\n[47] M. Xie, J. Hu, S. Guo, and A. Y. Zomaya, “Distributed segment-based\nanomaly detection with Kullback–Leibler divergence in wireless sensor\nnetworks,” IEEE Transactions on Information Forensics and Security,\nvol. 12, no. 1, pp. 101–110, 2016.\n[48] A. Armon, L. Faivishevsky, and G. Wallach, “Change and Anomaly\nDetection Framework for Internet of Things Data Streams.”\n[49] K. Yang, J. Ren, Y. Zhu, and W. Zhang, “Active learning for wireless\niot intrusion detection,” IEEE Wireless Communications, vol. 25, no. 6,\npp. 19–25, 2018.\n[50] M. Goldstein and S. Uchida, “A comparative evaluation of unsupervised\nanomaly detection algorithms for multivariate data,” PloS one, vol. 11,\nno. 4, p. e0152173, 2016.\n[51] M.-S. Chen, J. Han, and P. S. Yu, “Data mining: an overview from\na database perspective,” IEEE Transactions on Knowledge and data\nEngineering, vol. 8, no. 6, pp. 866–883, 1996.\n[52] J. Han, M. Kamber, and J. Pei, “Data mining concepts and techniques\nthird edition,” The Morgan Kaufmann Series in Data Management\nSystems, vol. 5, no. 4, pp. 83–124, 2011.\n[53] S. Maldonado, J. L´opez, and C. Vairetti, “An alternative SMOTE\noversampling strategy for high-dimensional datasets,” Applied Soft\nComputing, vol. 76, pp. 380–389, 2019.\n[54] J. Mei, M. Liu, Y.-F. Wang, and H. Gao, “Learning a mahalanobis\ndistance-based dynamic time warping measure for multivariate time\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n19\nseries classiﬁcation,” IEEE transactions on Cybernetics, vol. 46, no. 6,\npp. 1363–1374, 2015.\n[55] D. Sitaram, A. Dalwani, A. Narang, M. Das, and P. Auradkar, “A\nmeasure of similarity of time series containing missing data using\nthe mahalanobis distance,” in 2015 second international conference\non advances in computing and communication engineering.\nIEEE,\n2015, pp. 622–627.\n[56] S. Kang, J. Moon, and S.-W. Jun, “Fpga-accelerated time series mining\non low-power iot devices,” in 2020 IEEE 31st International Conference\non Application-speciﬁc Systems, Architectures and Processors (ASAP).\nIEEE, 2020, pp. 33–36.\n[57] K. Rose, S. Eldridge, and L. Chapin, “The internet of things: An\noverview,” The internet society (ISOC), vol. 80, pp. 1–50, 2015.\n[58] M. A. Al-Garadi, A. Mohamed, A. K. Al-Ali, X. Du, I. Ali, and\nM. Guizani, “A survey of machine and deep learning methods for\ninternet of things (IoT) security,” IEEE Communications Surveys &\nTutorials, vol. 22, no. 3, pp. 1646–1685, 2020.\n[59] H. Li, Z. Zhang, X. Wang, M. Zhou, and S. Li, “Electricity consump-\ntion behaviour analysis based on time sequence clustering,” in Journal\nof Physics: Conference Series, vol. 1168, no. 3. IOP Publishing, 2019,\np. 032011.\n[60] F. Dai, P. Huang, X. Xu, L. Qi, and M. R. Khosravi, “Spatio-temporal\ndeep learning framework for trafﬁc speed forecasting in IoT,” IEEE\nInternet of Things Magazine, vol. 3, no. 4, pp. 66–69, 2020.\n[61] T. Chen, S. Barbarossa, X. Wang, G. B. Giannakis, and Z.-L. Zhang,\n“Learning and management for internet of things: Accounting for\nadaptivity and scalability,” Proceedings of the IEEE, vol. 107, no. 4,\npp. 778–796, 2019.\n[62] R. A. A. Habeeb, F. Nasaruddin, A. Gani, I. A. T. Hashem, E. Ahmed,\nand M. Imran, “Real-time big data processing for anomaly detection:\nA survey,” International Journal of Information Management, vol. 45,\npp. 289–307, 2019.\n[63] F. Hussain, R. Hussain, S. A. Hassan, and E. Hossain, “Machine\nlearning in IoT security: Current solutions and future challenges,” IEEE\nCommunications Surveys & Tutorials, vol. 22, no. 3, pp. 1686–1721,\n2020.\n[64] S. Wang, J. Cao, and P. Yu, “Deep learning for spatio-temporal\ndata mining: A survey,” IEEE transactions on knowledge and data\nengineering, 2020.\n[65] M. Mohammadi, A. Al-Fuqaha, S. Sorour, and M. Guizani, “Deep\nlearning for IoT big data and streaming analytics: A survey,” IEEE\nCommunications Surveys & Tutorials, vol. 20, no. 4, pp. 2923–2960,\n2018.\n[66] S. Chakraborty, R. Tomsett, R. Raghavendra, D. Harborne, M. Alzantot,\nF. Cerutti, M. Srivastava, A. Preece, S. Julier, R. M. Rao et al.,\n“Interpretability of deep learning models: A survey of results,” in\n2017 IEEE smartworld, ubiquitous intelligence & computing, advanced\n& trusted computed, scalable computing & communications, cloud\n& big data computing, Internet of people and smart city innovation\n(smartworld/SCALCOM/UIC/ATC/CBDcom/IOP/SCI).\nIEEE, 2017,\npp. 1–6.\n[67] M. Abdel-Basset, H. Hawash, V. Chang, R. K. Chakrabortty, and\nM. Ryan, “Deep learning for heterogeneous human activity recognition\nin complex iot applications,” IEEE Internet of Things Journal, 2020.\n[68] A. Pandey, P. Tiwary, S. Kumar, and S. K. Das, “Residual neural\nnetworks for heterogeneous smart device localization in iot networks,”\nin 2020 29th International Conference on Computer Communications\nand Networks (ICCCN).\nIEEE, 2020, pp. 1–9.\n[69] R. M. Alrumaih and M. A. Al-Fawzan, “Time series forecasting using\nwavelet denoising an application to saudi stock index,” Journal of King\nSaud University-Engineering Sciences, vol. 14, no. 2, pp. 221–233,\n2002.\n[70] G. Frusque and O. Fink, “Robust Time Series Denoising with Learnable\nWavelet Packet Transform,” arXiv preprint arXiv:2206.06126, 2022.\n[71] I. Goodfellow, Y. Bengio, and A. C. Courville, “Deep Learning,”\nNature, vol. 521, pp. 436–444, 2015.\n[72] Q. Wen, L. Sun, X. Song, J. Gao, X. Wang, and H. Xu, “Time\nSeries Data Augmentation for Deep Learning: A Survey,” ArXiv, vol.\nabs/2002.12478, 2020.\n[73] H. Dau, A. J. Bagnall, K. Kamgar, C.-C. M. Yeh, Y. Zhu, S. Gharghabi,\nC. Ratanamahatana, and E. J. Keogh, “The UCR time series archive,”\nIEEE/CAA Journal of Automatica Sinica, vol. 6, pp. 1293–1305, 2019.\n[74] S. Dara and P. Tumma, “Feature extraction by using deep learning:\nA survey,” in 2018 Second International Conference on Electronics,\nCommunication and Aerospace Technology (ICECA).\nIEEE, 2018,\npp. 1795–1801.\n[75] F. T. Liu, K. M. Ting, and Z.-H. Zhou, “Isolation forest,” in 2008\neighth ieee international conference on data mining.\nIEEE, 2008, pp.\n413–422.\n[76] K.-L. Li, H.-K. Huang, S.-F. Tian, and W. Xu, “Improving one-class\nSVM for anomaly detection,” in Proceedings of the 2003 international\nconference on machine learning and cybernetics (IEEE Cat. No.\n03EX693), vol. 5.\nIEEE, 2003, pp. 3077–3081.\n[77] E. Haselsteiner and G. Pfurtscheller, “Using time-dependent neural\nnetworks for EEG classiﬁcation,” IEEE transactions on rehabilitation\nengineering : a publication of the IEEE Engineering in Medicine and\nBiology Society, vol. 8 4, pp. 457–63, 2000.\n[78] Y. Yu, X. Si, C. Hu, and J. Zhang, “A review of recurrent neural\nnetworks: LSTM cells and network architectures,” Neural computation,\nvol. 31, no. 7, pp. 1235–1270, 2019.\n[79] S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” Neural\nComputation, vol. 9, pp. 1735–1780, 1997.\n[80] J. Chung, C¸ aglar G¨ulc¸ehre, K. Cho, and Y. Bengio, “Empirical Eval-\nuation of Gated Recurrent Neural Networks on Sequence Modeling,”\nArXiv, vol. abs/1412.3555, 2014.\n[81] X. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-c.\nWoo, “Convolutional LSTM network: A machine learning approach\nfor precipitation nowcasting,” arXiv preprint arXiv:1506.04214, 2015.\n[82] J. Bradbury, S. Merity, C. Xiong, and R. Socher, “Quasi-recurrent\nneural networks,” arXiv preprint arXiv:1611.01576, 2016.\n[83] S. Chang, Y. Zhang, W. Han, M. Yu, X. Guo, W. Tan, X. Cui, M. Wit-\nbrock, M. Hasegawa-Johnson, and T. S. Huang, “Dilated recurrent\nneural networks,” arXiv preprint arXiv:1710.02224, 2017.\n[84] S. Bai, J. Z. Kolter, and V. Koltun, “An Empirical Evaluation of Generic\nConvolutional and Recurrent Networks for Sequence Modeling,” ArXiv,\nvol. abs/1803.01271, 2018.\n[85] M. Gori, G. Monfardini, and F. Scarselli, “A new model for learning\nin graph domains,” in Proceedings. 2005 IEEE International Joint\nConference on Neural Networks, 2005., vol. 2.\nIEEE, 2005, pp. 729–\n734.\n[86] Z. Chen, D. Chen, X. Zhang, Z. Yuan, and X. Cheng, “Learning\ngraph structures with transformer for multivariate time series anomaly\ndetection in IoT,” IEEE Internet of Things Journal, 2021.\n[87] Z. Wu, S. Pan, G. Long, J. Jiang, X. Chang, and C. Zhang, “Con-\nnecting the dots: Multivariate time series forecasting with graph neural\nnetworks,” in Proceedings of the 26th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining, 2020, pp. 753–\n763.\n[88] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. Van Den Berg, I. Titov,\nand M. Welling, “Modeling relational data with graph convolutional\nnetworks,” in European semantic web conference.\nSpringer, 2018, pp.\n593–607.\n[89] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, “A\ncomprehensive survey on graph neural networks,” IEEE transactions\non neural networks and learning systems, vol. 32, no. 1, pp. 4–24,\n2020.\n[90] D. Bank, N. Koenigstein, and R. Giryes, “Autoencoders,” arXiv preprint\narXiv:2003.05991, 2020.\n[91] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, B. Sengupta,\nand A. A. Bharath, “Generative adversarial networks: An overview,”\nIEEE Signal Processing Magazine, vol. 35, no. 1, pp. 53–65, 2018.\n[92] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in\nAdvances in neural information processing systems, 2017, pp. 5998–\n6008.\n[93] S. Li, X. Jin, Y. Xuan, X. Zhou, W. Chen, Y.-X. Wang, and X. Yan,\n“Enhancing the locality and breaking the memory bottleneck of trans-\nformer on time series forecasting,” Advances in Neural Information\nProcessing Systems, vol. 32, pp. 5243–5253, 2019.\n[94] C. Zhang, D. Song, Y. Chen, X. Feng, C. Lumezanu, W. Cheng, J. Ni,\nB. Zong, H. Chen, and N. V. Chawla, “A Deep Neural Network for\nUnsupervised Anomaly Detection and Diagnosis in Multivariate Time\nSeries Data,” in AAAI, 2019.\n[95] D. Ienco and R. Interdonato, “Deep Multivariate Time Series Em-\nbedding Clustering via Attentive-Gated Autoencoder,” Advances in\nKnowledge Discovery and Data Mining, vol. 12084, pp. 318 – 329,\n2020.\n[96] M. A. M. Carrasco and C. Wu, “An Unsupervised Framework for\nAnomaly Detection in a Water Treatment System,” 2019 18th IEEE\nInternational Conference On Machine Learning And Applications\n(ICMLA), pp. 1298–1305, 2019.\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n20\n[97] L. Torrey and J. Shavlik, “Transfer learning,” in Handbook of research\non machine learning applications and trends: algorithms, methods, and\ntechniques.\nIGI global, 2010, pp. 242–264.\n[98] T. Wen and R. Keyes, “Time Series Anomaly Detection Using\nConvolutional Neural Networks and Transfer Learning,” ArXiv, vol.\nabs/1905.13628, 2019.\n[99] X. Liu, F. Zhang, Z. Hou, Z. Wang, L. Mian, J. Zhang, and J. Tang,\n“Self-supervised Learning: Generative or Contrastive,” ArXiv, vol.\nabs/2006.08218, 2020.\n[100] M. Walton, M. Ayache, L. Straatemeier, D. Gebhardt, and B. Migliori,\n“Unsupervised Anomaly Detection for Digital Radio Frequency Trans-\nmissions,” 2017 16th IEEE International Conference on Machine\nLearning and Applications (ICMLA), pp. 826–832, 2017.\n[101] J. Inoue, Y. Yamagata, Y. Chen, C. M. Poskitt, and J. Sun, “Anomaly\nDetection for a Water Treatment System Using Unsupervised Machine\nLearning,” 2017 IEEE International Conference on Data Mining Work-\nshops (ICDMW), pp. 1058–1065, 2017.\n[102] D. J. Trosten, A. S. Strauman, M. Kampffmeyer, and R. Jenssen, “Re-\ncurrent Deep Divergence-based Clustering for Simultaneous Feature\nLearning and Clustering of Variable Length Time Series,” ICASSP 2019\n- 2019 IEEE International Conference on Acoustics, Speech and Signal\nProcessing (ICASSP), pp. 3257–3261, 2019.\n[103] K.\nHundman,\nV.\nConstantinou,\nC.\nLaporte,\nI.\nColwell,\nand\nT. S¨oderstr¨om, “Detecting Spacecraft Anomalies Using LSTMs and\nNonparametric Dynamic Thresholding,” Proceedings of the 24th ACM\nSIGKDD International Conference on Knowledge Discovery & Data\nMining, 2018.\n[104] Y. Su, Y. Zhao, C. Niu, R. Liu, W. Sun, and D. Pei, “Robust Anomaly\nDetection for Multivariate Time Series through Stochastic Recurrent\nNeural Network,” Proceedings of the 25th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining, 2019.\n[105] H. Ren, B. Xu, Y. Wang, C. Yi, C. Huang, X. Kou, T. Xing, M. Yang,\nJ. Tong, and Q. Zhang, “Time-Series Anomaly Detection Service\nat Microsoft,” Proceedings of the 25th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining, 2019.\n[106] J. Liu, X. Song, Y. Zhou, X. Peng, Y. Zhang, P. Liu, and\nD. Wu, “Deep Anomaly Detection in Packet Payload,” arXiv preprint\narXiv:1912.02549, 2019.\n[107] A. Deng and B. Hooi, “Graph neural network-based anomaly detection\nin multivariate time series,” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, vol. 35, no. 5, 2021, pp. 4027–4035.\n[108] H. Zhao, Y. Wang, J. Duan, C. Huang, D. Cao, Y. Tong, B. Xu, J. Bai,\nJ. Tong, and Q. Zhang, “Multivariate time-series anomaly detection via\ngraph attention network,” in 2020 IEEE International Conference on\nData Mining (ICDM).\nIEEE, 2020, pp. 841–850.\n[109] J. Pereira and M. Silveira, “Unsupervised Anomaly Detection in\nEnergy Time Series Data Using Variational Recurrent Autoencoders\nwith Attention,” 2018 17th IEEE International Conference on Machine\nLearning and Applications (ICMLA), pp. 1275–1282, 2018.\n[110] D. Lee, “Anomaly Detection in Multivariate Non-stationary Time\nSeries for Automatic DBMS Diagnosis,” 2017 16th IEEE International\nConference on Machine Learning and Applications (ICMLA), pp. 412–\n419, 2017.\n[111] N. Tavakoli, S. Siami-Namini, M. A. Khanghah, F. M. Soltani, and\nA. S. Namin, “Clustering Time Series Data through Autoencoder-based\nDeep Learning Models,” ArXiv, vol. abs/2004.07296, 2020.\n[112] S. Lin, R. Clark, R. Birke, S. Sch¨onborn, N. Trigoni, and S. Roberts,\n“Anomaly Detection for Time Series Using VAE-LSTM Hybrid\nModel,” ICASSP 2020 - 2020 IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP), pp. 4322–4326,\n2020.\n[113] K. M. Biradar, A. Gupta, M. Mandal, and S. K. Vipparthi, “Challenges\nin Time-Stamp Aware Anomaly Detection in Trafﬁc Videos,” in CVPR\nWorkshops, 2019.\n[114] G. Richard, B. Grossin, G. Germaine, G. H´ebrail, and A. de Moliner,\n“Autoencoder-based time series clustering with energy applications,”\nArXiv, vol. abs/2002.03624, 2020.\n[115] E. Kalinicheva, J. Sublime, and M. Trocan, “Unsupervised Satellite\nImage Time Series Clustering Using Object-Based Approaches and 3D\nConvolutional Autoencoder,” Remote. Sens., vol. 12, p. 1816, 2020.\n[116] B. L. Bhatnagar, S. Singh, C. Arora, and C. Jawahar, “Unsupervised\nLearning of Deep Feature Representation for Clustering Egocentric\nActions,” in IJCAI, 2017.\n[117] C. Meng, X. S. Jiang, X. M. Wei, and T. Wei, “A Time Convolutional\nNetwork Based Outlier Detection for Multidimensional Time Series\nin Cyber-Physical-Social Systems,” IEEE Access, vol. 8, pp. 74 933–\n74 942, 2020.\n[118] D. Li, D. Chen, L. Shi, B. Jin, J. Goh, and S. Ng, “MAD-GAN:\nMultivariate Anomaly Detection for Time Series Data with Generative\nAdversarial Networks,” in ICANN, 2019.\n[119] M. A. Bashar and R. Nayak, “TAnoGAN: Time Series Anomaly\nDetection\nwith\nGenerative\nAdversarial\nNetworks,”\nArXiv,\nvol.\nabs/2008.09567, 2020.\n[120] O. Gorokhov, M. Petrovskiy, and I. Mashechkin, “Convolutional Neural\nNetworks for Unsupervised Anomaly Detection in Text Data,” in\nIDEAL, 2017.\n[121] N. Ding, H. Ma, H. Gao, Y. Ma, and G. Tan, “Real-time anomaly\ndetection based on long short-Term memory and Gaussian Mixture\nModel,” Computers & Electrical Engineering, vol. 79, p. 106458, 2019.\n[122] Y. Chen, Z. Lin, X. Zhao, G. Wang, and Y. Gu, “Deep learning-based\nclassiﬁcation of hyperspectral data,” IEEE Journal of Selected topics\nin applied earth observations and remote sensing, vol. 7, no. 6, pp.\n2094–2107, 2014.\n[123] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, “Extracting\nand composing robust features with denoising autoencoders,” in Pro-\nceedings of the 25th international conference on Machine learning,\n2008, pp. 1096–1103.\n[124] D. P. Kingma and M. Welling, “Auto-Encoding Variational Bayes,”\nCoRR, vol. abs/1312.6114, 2014.\n[125] S. Chang, Y. Zhang, W. Han, M. Yu, X. Guo, W. Tan, X. Cui,\nM. Witbrock, M. Hasegawa-Johnson, and T. Huang, “Dilated Recurrent\nNeural Networks,” ArXiv, vol. abs/1710.02224, 2017.\n[126] C. Esteban, S. L. Hyland, and G. R¨atsch, “Real-valued (medical)\ntime series generation with recurrent conditional gans,” arXiv preprint\narXiv:1706.02633, 2017.\n[127] P. Malhotra, A. Ramakrishnan, G. Anand, L. Vig, P. Agarwal, and\nG. Shroff, “LSTM-based Encoder-Decoder for Multi-sensor Anomaly\nDetection,” ArXiv, vol. abs/1607.00148, 2016.\n[128] J. Audibert, P. Michiardi, F. Guyard, S. Marti, and M. A. Zuluaga,\n“USAD: UnSupervised Anomaly Detection on Multivariate Time Se-\nries,” Proceedings of the 26th ACM SIGKDD International Conference\non Knowledge Discovery & Data Mining, 2020.\n[129] Y. Zhou, X. Song, Y. Zhang, F. Liu, C. Zhu, and L. Liu, “Feature En-\ncoding with AutoEncoders for Weakly-supervised Anomaly Detection,”\narXiv preprint arXiv:2105.10500, 2021.\n[130] Y. Liu, S. Garg, J. Nie, Y. Zhang, Z. Xiong, J. Kang, and M. Hossain,\n“Deep Anomaly Detection for Time-series Data in Industrial IoT: A\nCommunication-Efﬁcient On-device Federated Learning Approach,”\nArXiv, vol. abs/2007.09712, 2020.\n[131] S. Dou, K. Yang, and H. V. Poor, “PC2A: Predicting Collective\nContextual Anomalies via LSTM With Deep Generative Model,” IEEE\nInternet of Things Journal, vol. 6, no. 6, pp. 9645–9655, 2019.\n[132] K. Yang, R. Liu, Y. Sun, J. Yang, and X. Chen, “Deep network\nanalyzer (dna): A big data analytics platform for cellular networks,”\nIEEE Internet of Things Journal, vol. 4, no. 6, pp. 2019–2027, 2017.\n[133] P. Tzirakis, M. A. Nicolaou, B. Schuller, and S. Zafeiriou, “Time-series\nClustering with Jointly Learning Deep Representations, Clusters and\nTemporal Boundaries,” 2019 14th IEEE International Conference on\nAutomatic Face & Gesture Recognition (FG 2019), pp. 1–5, 2019.\n[134] C. Ratanamahatana, E. Keogh, A. J. Bagnall, and S. Lonardi, “A novel\nbit level time series representation with implication of similarity search\nand clustering,” in Paciﬁc-Asia conference on knowledge discovery and\ndata mining.\nSpringer, 2005, pp. 771–777.\n[135] J. Ward, “Hierarchical Grouping to Optimize an Objective Function,”\n1963.\n[136] S. Tian, W. Yang, J. M. Le Grange, P. Wang, W. Huang, and Z. Ye,\n“Smart healthcare: making medical care more intelligent,” Global\nHealth Journal, vol. 3, no. 3, pp. 62–65, 2019.\n[137] Y. Cheng, Y. Xu, H. Zhong, and Y. Liu, “Leveraging semisupervised\nhierarchical stacking temporal convolutional network for anomaly\ndetection in IoT communication,” IEEE Internet of Things Journal,\nvol. 8, no. 1, pp. 144–155, 2020.\n[138] P. P. Ray and D. Dash, “IoT-edge anomaly detection for covariate\nshifted and point time series health data,” Journal of King Saud\nUniversity-Computer and Information Sciences, 2021.\n[139] D. Gupta, O. Kayode, S. Bhatt, M. Gupta, and A. S. Tosun, “Hierar-\nchical federated learning based anomaly detection using digital twins\nfor smart healthcare,” in 2021 IEEE 7th International Conference on\nCollaboration and Internet Computing (CIC). IEEE, 2021, pp. 16–25.\n[140] J. Pereira and M. Silveira, “Learning representations from healthcare\ntime series data for unsupervised anomaly detection,” in 2019 IEEE\ninternational conference on big data and smart computing (BigComp).\nIEEE, 2019, pp. 1–7.\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n21\n[141] R. Bharathi, T. Abirami, S. Dhanasekaran, D. Gupta, A. Khanna,\nM. Elhoseny, and K. Shankar, “Energy efﬁcient clustering with dis-\nease diagnosis model for IoT based sustainable healthcare systems,”\nSustainable Computing: Informatics and Systems, vol. 28, p. 100453,\n2020.\n[142] D. Gupta, M. Bhatia, and A. Kumar, “Resolving data overload and\nlatency issues in multivariate time-series IoMT data for mental health\nmonitoring,” IEEE Sensors Journal, vol. 21, no. 22, pp. 25 421–25 428,\n2021.\n[143] A. Hassanzadeh, S. Modi, and S. Mulchandani, “Towards effective\nsecurity control assignment in the Industrial Internet of Things,” in\n2015 IEEE 2nd World Forum on Internet of Things (WF-IoT).\nIEEE,\n2015, pp. 795–800.\n[144] Y. Dang, Q. Lin, and P. Huang, “Aiops: real-world challenges and re-\nsearch innovations,” in 2019 IEEE/ACM 41st International Conference\non Software Engineering: Companion Proceedings (ICSE-Companion).\nIEEE, 2019, pp. 4–5.\n[145] G. Shah and A. Tiwari, “Anomaly detection in iiot: A case study using\nmachine learning,” in Proceedings of the ACM India Joint International\nConference on Data Science and Management of Data, 2018, pp. 295–\n300.\n[146] F. Giannoni, M. Mancini, and F. Marinelli, “Anomaly detection models\nfor IoT time series data,” arXiv preprint arXiv:1812.00890, 2018.\n[147] W. Aoudi and M. Almgren, “A scalable speciﬁcation-agnostic multi-\nsensor anomaly detection system for IIoT environments,” International\nJournal of Critical Infrastructure Protection, vol. 30, p. 100377, 2020.\n[148] B. Genge, P. Haller, and C. En˘achescu, “Anomaly detection in aging\nindustrial internet of things,” IEEE Access, vol. 7, pp. 74 217–74 230,\n2019.\n[149] P. Sun, J. Li, M. Z. A. Bhuiyan, L. Wang, and B. Li, “Modeling\nand clustering attacker activities in IoT through machine learning\ntechniques,” Information Sciences, vol. 479, pp. 456–471, 2019.\n[150] J. Diaz-Rozo, C. Bielza, and P. Larra˜naga, “Clustering of data streams\nwith dynamic gaussian mixture models: an IoT application in industrial\nprocesses,” IEEE Internet of Things Journal, vol. 5, no. 5, pp. 3533–\n3547, 2018.\n[151] X. Kong, X. Song, F. Xia, H. Guo, J. Wang, and A. Tolba, “LoTAD:\nLong-term trafﬁc anomaly detection based on crowdsourced bus tra-\njectory data,” World Wide Web, vol. 21, no. 3, pp. 825–847, 2018.\n[152] E. D’Andrea and F. Marcelloni, “Detection of trafﬁc congestion and\nincidents from GPS trace analysis,” Expert Systems with Applications,\nvol. 73, pp. 43–56, 2017.\n[153] A. S. El-Wakeel, J. Li, M. T. Rahman, A. Noureldin, and H. S.\nHassanein, “Monitoring road surface anomalies towards dynamic road\nmapping for future smart cities,” in 2017 IEEE global conference on\nsignal and information processing (GlobalSIP). IEEE, 2017, pp. 828–\n832.\n[154] R. Jain and H. Shah, “An anomaly detection in smart cities modeled as\nwireless sensor network,” in 2016 International Conference on Signal\nand Information Processing (IConSIP).\nIEEE, 2016, pp. 1–5.\n[155] L.-J. Chen, Y.-H. Ho, H.-H. Hsieh, S.-T. Huang, H.-C. Lee, and\nS. Mahajan, “ADF: An anomaly detection framework for large-scale\nPM2. 5 sensing systems,” IEEE Internet of Things Journal, vol. 5,\nno. 2, pp. 559–570, 2017.\n[156] J. Zhang, L.-y. Zhang, M. Du, W. Zhang, X. Huang, Y.-q. Zhang, Y.-y.\nYang, J.-m. Zhang, S.-h. Deng, F. Shen et al., “Indentifying the major\nair pollutants base on factor and cluster analysis, a case study in 74\nChinese cities,” Atmospheric Environment, vol. 144, pp. 37–46, 2016.\n[157] A. K. Hua, “Applied chemometric approach in identiﬁcation sources of\nair quality pattern in Selangor, Malaysia,” Sains Malaysiana, vol. 47,\nno. 3, pp. 471–479, 2018.\n[158] P. D’Urso, L. De Giovanni, and R. Massari, “Time series clustering\nby a robust autoregressive metric with application to air pollution,”\nChemometrics and Intelligent Laboratory Systems, vol. 141, pp. 107–\n124, 2015.\n[159] A. Ghosal and M. Conti, “Security issues and challenges in V2X: A\nsurvey,” Computer Networks, vol. 169, p. 107093, 2020.\n[160] K. J. Ahmed and M. J. Lee, “Secure resource allocation for LTE-based\nV2X service,” IEEE Transactions on Vehicular Technology, vol. 67,\nno. 12, pp. 11 324–11 331, 2018.\n[161] H. Qin, M. Yan, and H. Ji, “Application of Controller Area Network\n(CAN) bus anomaly detection based on time series prediction,” Vehic-\nular Communications, vol. 27, p. 100291, 2021.\n[162] R. Sedar, C. Kalalas, F. V´azquez-Gallego, and J. Alonso-Zarate, “Re-\ninforcement learning-based misbehaviour detection in V2X scenarios,”\nin 2021 IEEE International Mediterranean Conference on Communi-\ncations and Networking (MeditCom).\nIEEE, 2021, pp. 109–111.\n[163] N. Negi, O. Jelassi, H. Chaouchi, and S. Clemenc¸on, “Distributed\nonline Data Anomaly Detection for connected vehicles,” in 2020\nInternational Conference on Artiﬁcial Intelligence in Information and\nCommunication (ICAIIC).\nIEEE, 2020, pp. 494–500.\n[164] W. Liu, G. Qin, Y. He, and F. Jiang, “Distributed cooperative re-\ninforcement learning-based trafﬁc signal control that integrates V2X\nnetworks’ dynamic clustering,” IEEE transactions on vehicular tech-\nnology, vol. 66, no. 10, pp. 8667–8681, 2017.\n[165] C. Zhu, W. Sheng, and M. Liu, “Wearable sensor-based behavioral\nanomaly detection in smart assisted living systems,” IEEE Transactions\non automation science and engineering, vol. 12, no. 4, pp. 1225–1234,\n2015.\n[166] S. Hela, B. Amel, and R. Badran, “Early anomaly detection in smart\nhome: A causal association rule-based approach,” Artiﬁcial intelligence\nin medicine, vol. 91, pp. 57–71, 2018.\n[167] M. Yamauchi, Y. Ohsita, M. Murata, K. Ueda, and Y. Kato, “Anomaly\ndetection in smart home operation from user behaviors and home\nconditions,” IEEE Transactions on Consumer Electronics, vol. 66,\nno. 2, pp. 183–192, 2020.\n[168] S. Ramapatruni, S. N. Narayanan, S. Mittal, A. Joshi, and K. Joshi,\n“Anomaly detection models for smart home security,” in 2019 IEEE\n5th Intl Conference on Big Data Security on Cloud (BigDataSecurity),\nIEEE Intl Conference on High Performance and Smart Comput-\ning,(HPSC) and IEEE Intl Conference on Intelligent Data and Security\n(IDS).\nIEEE, 2019, pp. 19–24.\n[169] M. Yamauchi, Y. Ohsita, M. Murata, K. Ueda, and Y. Kato, “Anomaly\ndetection for smart home based on user behavior,” in 2019 IEEE\nInternational Conference on Consumer Electronics (ICCE).\nIEEE,\n2019, pp. 1–6.\n[170] R. Moghaddass and J. Wang, “A hierarchical framework for smart\ngrid anomaly detection using large-scale smart meter data,” IEEE\nTransactions on Smart Grid, vol. 9, no. 6, pp. 5820–5830, 2017.\n[171] F. Passerini and A. M. Tonello, “Smart grid monitoring using power\nline modems: Anomaly detection and localization,” IEEE Transactions\non Smart Grid, vol. 10, no. 6, pp. 6178–6186, 2019.\n[172] S.-C. Yip, W.-N. Tan, C. Tan, M.-T. Gan, and K. Wong, “An anomaly\ndetection framework for identifying energy theft and defective meters\nin smart grids,” International Journal of Electrical Power & Energy\nSystems, vol. 101, pp. 189–203, 2018.\n[173] A. Lavin and D. Klabjan, “Clustering time-series energy data from\nsmart meters,” Energy efﬁciency, vol. 8, no. 4, pp. 681–689, 2015.\n[174] J. Goh, S. Adepu, K. N. Junejo, and A. Mathur, “A Dataset to\nSupport Research in the Design of Secure Water Treatment Systems,”\nin CRITIS, 2016.\n[175] Water\nDistribution.\n[Online].\nAvailable:\nhttps://itrust.sutd.edu.sg/\ntestbeds/water-distribution-wadi/\n[176] P. Schmidt, A. Reiss, R. Duerichen, C. Marberger, and K. Van Laer-\nhoven, “Introducing wesad, a multimodal dataset for wearable stress\nand affect detection,” in Proceedings of the 20th ACM international\nconference on multimodal interaction, 2018, pp. 400–408.\n[177] N. Koroniotis, N. Moustafa, E. Sitnikova, and B. Turnbull, “Towards\nthe development of realistic botnet dataset in the internet of things\nfor network forensic analytics: Bot-iot dataset,” Future Generation\nComputer Systems, vol. 100, pp. 779–796, 2019.\n[178] I. Ullah and Q. H. Mahmoud, “A scheme for generating a dataset for\nanomalous activity detection in iot networks,” in Canadian Conference\non Artiﬁcial Intelligence.\nSpringer, 2020, pp. 508–520.\n[179] I. Vaccari, G. Chiola, M. Aiello, M. Mongelli, and E. Cambiaso,\n“Mqttset, a new dataset for machine learning techniques on mqtt,”\nSensors, vol. 20, no. 22, p. 6578, 2020.\n[180] A. Guerra-Manzanares, J. Medina-Galindo, H. Bahsi, and S. N˜omm,\n“MedBIoT: Generation of an IoT Botnet Dataset in a Medium-sized\nIoT Network.” in ICISSP, 2020, pp. 207–218.\n[181] A. Parmisano, S. Garcia, and M. Erquiaga, “A labeled dataset with\nmalicious and benign iot network trafﬁc,” Stratosphere Laboratory:\nPraha, Czech Republic, 2020.\n[182] H. Hindy, E. Bayne, M. Bures, R. Atkinson, C. Tachtatzis, and\nX. Bellekens, “Machine learning based IoT intrusion detection system:\nAn MQTT case study (MQTT-IoT-IDS2020 dataset),” in International\nNetworking Conference.\nSpringer, 2021, pp. 73–84.\n[183] N. Moustafa, “A new distributed architecture for evaluating AI-based\nsecurity systems at the edge: Network TON IoT datasets,” Sustainable\nCities and Society, vol. 72, p. 102994, 2021.\n[184] M. Al-Hawawreh, E. Sitnikova, and N. Aboutorab, “X-IIoTID: A\nconnectivity-agnostic and device-agnostic intrusion data set for indus-\ntrial Internet of Things,” IEEE Internet of Things Journal, vol. 9, no. 5,\npp. 3962–3977, 2021.\nTHE MANUSCRIPT HAS BEEN ACCEPTED BY IEEE INTERNET OF THINGS JOURNAL. DOI: 10.1109/JIOT.2023.3243391\n22\n[185] The\nIoTHealthDataSet.\n[Online].\nAvailable:\nhttps://github.com/\nParthaPRay/IoTHealthDataSet\n[186] S. Dadkhah, H. Mahdikhani, P. K. Danso, A. Zohourian, K. A. Truong,\nand A. A. Ghorbani, “Towards the development of a realistic multi-\ndimensional IoT proﬁling dataset,” in 2022 19th Annual International\nConference on Privacy, Security & Trust (PST). IEEE, 2022, pp. 1–11.\n[187] M. A. Ferrag, O. Friha, D. Hamouda, L. Maglaras, and H. Janicke,\n“Edge-IIoTset: A new comprehensive realistic cyber security dataset\nof IoT and IIoT applications for centralized and federated learning,”\nIEEE Access, vol. 10, pp. 40 281–40 306, 2022.\n[188] T.\nHospedales,\nA.\nAntoniou,\nP.\nMicaelli,\nand\nA.\nStorkey,\n“Meta-learning\nin\nneural\nnetworks:\nA\nsurvey,”\narXiv\npreprint\narXiv:2004.05439, 2020.\n[189] T. Choudhary, V. Mishra, A. Goswami, and J. Sarangapani, “A com-\nprehensive survey on model compression and acceleration,” Artiﬁcial\nIntelligence Review, vol. 53, no. 7, pp. 5113–5155, 2020.\n[190] F.-L. Fan, J. Xiong, M. Li, and G. Wang, “On interpretability of\nartiﬁcial neural networks: A survey,” IEEE Transactions on Radiation\nand Plasma Medical Sciences, 2021.\n[191] Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, and J. Zhang, “Edge\nintelligence: Paving the last mile of artiﬁcial intelligence with edge\ncomputing,” Proceedings of the IEEE, vol. 107, no. 8, pp. 1738–1762,\n2019.\n[192] Y. Jiao, K. Yang, S. Dou, P. Luo, S. Liu, and D. Song, “TimeAutoML:\nAutonomous Representation Learning for Multivariate Irregularly Sam-\npled Time Series,” arXiv preprint arXiv:2010.01596, 2020.\n[193] P. B. Weerakody, K. W. Wong, G. Wang, and W. Ela, “A review\nof irregular time series data handling with gated recurrent neural\nnetworks,” Neurocomputing, vol. 441, pp. 161–178, 2021.\n[194] K. Yang, L. Jiang, S. H. Low, and S. Liu, “Privacy-Preserving Energy\nScheduling for Smart Grid With Renewables,” IEEE Access, vol. 8, pp.\n132 320–132 329, 2020.\n[195] J. Koneˇcn`y, H. B. McMahan, F. X. Yu, P. Richt´arik, A. T. Suresh, and\nD. Bacon, “Federated learning: Strategies for improving communica-\ntion efﬁciency,” arXiv preprint arXiv:1610.05492, 2016.\n[196] F. Mireshghallah, M. Taram, P. Vepakomma, A. Singh, R. Raskar, and\nH. Esmaeilzadeh, “Privacy in deep learning: A survey,” arXiv preprint\narXiv:2004.12254, 2020.\nYa Liu was born in Shanxi, China in 1997. She\nreceived the B.S degree from Beijing Jiaotong Uni-\nversity, Beijing, China, in 2019. She is currently pur-\nsuing the Ph.D. degree in computer science from the\nDepartment of Computer Science, Tongji University,\nShanghai, China.\nHer current research interests include anomaly\ndetection, network security, and distributed learning.\nYingjie Zhou (M’14) received his Ph.D. degree\nin the School of Communication and Information\nEngineering from University of Electronic Science\nand Technology of China (UESTC), China, in 2013.\nHe is currently an associate professor in the College\nof Computer Science at Sichuan University (SCU),\nChina. He was a visiting scholar in the Department\nof Electrical Engineering at Columbia University,\nNew York. His current research interests include\nnetwork management, behavioral data analysis, and\nresource allocation. He has served as Program Vice-\nChair of IEEE HPCC, Local Arrangement Chair of IEEE BMSB, and TPC\nmember for many major IEEE conferences, such as GLOBLECOM, ICC,\nITSC, MSN and VTC. He received the Best Paper Awards at IEEE HPCC\nand IEEE MMSP in 2022.\nKai Yang (SM’18) received the B.Eng. degree\nfrom Southeast University, Nanjing, China, the M.S.\ndegree from the National University of Singapore,\nSingapore, and the Ph.D. degree from Columbia\nUniversity, New York, NY, USA.\nHe is a Distinguished Professor with Tongji Uni-\nversity, Shanghai, China. He was a Technical Staff\nMember with Bell Laboratories, Murray Hill, NJ,\nUSA. He has also been an Adjunct Faculty Member\nwith Columbia University since 2011. He holds over\n20 patents and has been published extensively in\nleading IEEE journals and conferences. His current research interests include\nbig data analytics, machine learning, wireless communications, and signal\nprocessing.\nXin Wang (SM’09-F’23) received the B.Sc. and\nM.Sc.degrees from Fudan University, Shanghai,\nChina, in 1997 and 2000, respectively, and the Ph.D.\ndegree from Auburn University, Auburn, AL, USA,\nin 2004, all in electrical engineering.\nFrom September 2004 to August 2006, he was\na Postdoctoral Research Associate with the De-\npartment of Electrical and Computer Engineering,\nUniversity of Minnesota, Minneapolis. In August\n2006, he joined the Department of Electrical En-\ngineering, Florida Atlantic University, Boca Raton,\nFL, USA, as an Assistant Professor, then was promoted to a tenured As-\nsociate Professor in 2010. He is currently a Distinguished Professor and\nthe Chair of the Department of Communication Science and Engineering,\nFudan University, China. His research interests include stochastic network\noptimization, energy-efﬁcient communications, cross-layer design, and signal\nprocessing for communications. He is a Senior Area Editor for the IEEE\nTransactions on Signal Processing and an Editor for the IEEE Transactions\non Wireless Communications, and in the past served as an Associate Editor\nfor the IEEE Transactions on Signal Processing, as an Editor for the IEEE\nTransactions on Vehicular Technology, and as an Associate Editor for the\nIEEE Signal Processing Letters. He is a member of the Signal Processing\nfor Communications and Networking Technical Committee of IEEE Signal\nProcessing Society, and a Distinguished Speaker of the IEEE Vehicular\nTechnology Society.\n",
  "categories": [
    "cs.LG",
    "eess.SP",
    "A.1; I.2"
  ],
  "published": "2023-02-07",
  "updated": "2023-02-21"
}