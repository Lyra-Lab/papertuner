{
  "id": "http://arxiv.org/abs/2302.09731v1",
  "title": "CMVAE: Causal Meta VAE for Unsupervised Meta-Learning",
  "authors": [
    "Guodong Qi",
    "Huimin Yu"
  ],
  "abstract": "Unsupervised meta-learning aims to learn the meta knowledge from unlabeled\ndata and rapidly adapt to novel tasks. However, existing approaches may be\nmisled by the context-bias (e.g. background) from the training data. In this\npaper, we abstract the unsupervised meta-learning problem into a Structural\nCausal Model (SCM) and point out that such bias arises due to hidden\nconfounders. To eliminate the confounders, we define the priors are\n\\textit{conditionally} independent, learn the relationships between priors and\nintervene on them with casual factorization. Furthermore, we propose Causal\nMeta VAE (CMVAE) that encodes the priors into latent codes in the causal space\nand learns their relationships simultaneously to achieve the downstream\nfew-shot image classification task. Results on toy datasets and three benchmark\ndatasets demonstrate that our method can remove the context-bias and it\noutperforms other state-of-the-art unsupervised meta-learning algorithms\nbecause of bias-removal. Code is available at\n\\url{https://github.com/GuodongQi/CMVAE}",
  "text": "CMVAE: Causal Meta VAE for Unsupervised Meta-Learning\nGuodong Qi 1,2, Huimin Yu 1,2,3,4\n1College of Information Science and Electronic Engineering, Zhejiang University\n2ZJU-League Research & Development Center\n3State Key Lab of CAD&CG, Zhejiang University\n4Zhejiang Provincial Key Laboratory of Information Processing, Communication and Networking\n{guodong qi, yhm2005}@zju.edu.cn\nAbstract\nUnsupervised meta-learning aims to learn the meta knowl-\nedge from unlabeled data and rapidly adapt to novel tasks.\nHowever, existing approaches may be misled by the context-\nbias (e.g. background) from the training data. In this pa-\nper, we abstract the unsupervised meta-learning problem into\na Structural Causal Model (SCM) and point out that such\nbias arises due to hidden confounders. To eliminate the con-\nfounders, we deﬁne the priors are conditionally independent,\nlearn the relationships between priors and intervene on them\nwith casual factorization. Furthermore, we propose Causal\nMeta VAE (CMVAE) that encodes the priors into latent codes\nin the causal space and learns their relationships simulta-\nneously to achieve the downstream few-shot image classi-\nﬁcation task. Results on toy datasets and three benchmark\ndatasets demonstrate that our method can remove the context-\nbias and it outperforms other state-of-the-art unsupervised\nmeta-learning algorithms because of bias-removal. Code is\navailable at https://github.com/GuodongQi/CMVAE.\n1\nIntroduction\nRegular meta-learning algorithms such as (Finn, Abbeel,\nand Levine 2017; Snell, Swersky, and Zemel 2017) aim to\nlearn the meta knowledge to adapt to novel tasks quickly.\nHowever, it requires various supervised tasks on large la-\nbeled datasets during the meta-training phase. Recently, re-\nsearchers take great interest in unsupervised meta-learning\n(Hsu, Levine, and Finn 2019; Khodadadeh et al. 2021).\nDifferent from regular meta-learning, unsupervised meta-\nlearning contains unsupervised meta-training and super-\nvised meta-test. It aims to learn a learning procedure with\nunlabeled datasets in the meta-training and solve novel su-\npervised human-crafted tasks in the meta-test.\nPrevious methods focus on the pseudo-label generation of\nthe task. However, they may ignore the bias. Figure 1a illus-\ntrates a binary-classiﬁcation toy example where the back-\nground prior is one of bias. In the training images, the\n“birds” are always together with the “sky” and the “air-\nplanes” always park on the ground. As a result, the model\nwill take the “sky” as a part of the “bird”, and mistakenly\nrecognize the “airplane” test image as a “bird”. It is essential\nto remove the effect of background prior i.e., context-bias.\nCopyright © 2023, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nTraining images\nTest images\nSky √   Wing √ Sky √  Wing × \nSky ×  Wing √ Sky ×  Wing √ \nSky √  Wing √ \nSky ×  Wing ×\n(a)\nD1\nD2\nDd\nX\nY\n...\n(b)\nFigure 1: (a) Illustration of context-bias. (b) SCM of unsu-\npervised meta-learning. The dashed line means that the rela-\ntionship (DAG) need to be learned.\nHowever, discerning the context-bias is challenging, be-\ncause the priors may not be independent. For example, in the\ntask of Figure 1a, the “wing” and the “sky” prior is not inde-\npendent statistically1. When the “sky” prior is removed, the\n“wing” prior will be changed, and then the prediction will\nbe affected. In this case, the model will not know whether\nthe “sky” or “wing” prior is the context-bias.\nTo address the problems, we analyze, discern and re-\nmove the context-bias from a causal perspective via three\ntheories, i.e., Structural Causal Model (SCM) (Glymour,\nPearl, and Jewell 2016), Common Cause Principle (CCP)\n(Sch¨olkopf et al. 2021) and Independent Causal Mechanism\n(ICM) (Sch¨olkopf et al. 2012). Among them, SCM describes\nthe relevant concepts and how they interact with each other.\nCCP reveals that if two observables are statistically depen-\ndent, then there exists a variable such that they are indepen-\ndent conditioned on the variable. ICM states that the con-\nditional distribution of each prior given its causes does not\ninﬂuence the others. In other words, SCM explains how the\nbias affects predictions. CCP makes it reasonable to assume\nthe priors are conditionally independent. For example, in\nFigure 1a there exists a “ﬂying” prior, which causally af-\nfects “sky” and “wing” and makes them independent when\nconditioned on the prior. ICM allows us to remove one\nprior (e.g., p(sky|ﬂying)) will not affect another prior (e.g.,\np(wing|ﬂying)).\nSpecially, we build the SCM in Figure 1b. The bias\n1P(wing, sky) = 1/4, P(wing) = 3/4, P(sky) = 1/2, we\nhave P(wing, sky) ̸= P(wing)P(sky), so they are dependent.\narXiv:2302.09731v1  [cs.LG]  20 Feb 2023\nemerges because the priors are confounders that cause spu-\nrious correlations from the inputs to predictions. To achieve\nbias-removal, we deﬁne the relationships between priors\nbased on CCP, obtain the structure with a learnable directed\nacyclic graph (DAG), causally factorize the joint distribution\nof priors based on ICM, and then perform causal interven-\ntion (Glymour, Pearl, and Jewell 2016) in sequence.\nFurthermore, we design the Causal Meta VAE (CMVAE),\nwhich learns the priors and the causal factorization simul-\ntaneously. Particularly, we propose the causal intervention\nformula with the SCM. It leads us to learn the conditionally\nindependent latent codes (priors) as well as the DAG (causal\nfactorization). To make the correspondence between the la-\ntent codes and priors, we adopt the VAE-based framework\n(Kingma and Welling 2014) since VAE has been shown\nto achieve some useful disentangling performance (Higgins\net al. 2016). The “DAG-ness” can be quantiﬁed by a regu-\nlarizer (Zheng et al. 2018). Besides, we introduce the Causal\nLatent Space (CaLS) and show its addability, which makes\nit feasible to represent the class-concept codes while keep-\ning the DAG. We also extend one baseline (Lee et al. 2021)\ninto our CMVAE to achieve the downstream few-shot clas-\nsiﬁcation with the unsupervised meta-learning settings. The\ncontributions of this paper are as follows:\n• We point out the context-bias and the dependent priors\nin unsupervised meta-learning. We propose to learn the\nrelationship among the priors with a learnable DAG and\nmake the priors causally independent and factorize.\n• We design the intervention formula, introduce the CaLS,\nand propose CMVAE to learn the factors and the factor-\nization for the downstream classiﬁcation simultaneously.\n• Extensive experiments on two toy datasets and three\nwidely used benchmark datasets demonstrate that CM-\nVAE outperforms other state-of-the-art unsupervised\nmeta-learning algorithms. Furthermore, we show that\nCMVAE can be intervened to generate counterfactual\nsamples with some meaningful explanation.\n2\nRelated Work\nUnsupervised Meta-Learning aims to learn the meta-\nknowledge with unlabeled training data. CACTU (Hsu,\nLevine, and Finn 2019) and UMTRA (Khodadadeh, B¨ol¨oni,\nand Shah 2019) try to create synthetic labels. GMVAE (Lee\net al. 2021) introduces a Mixture of Gaussian priors by per-\nforming Expectation-Maximization (EM). However, none of\nthem notices the bias in the few-shot tasks.\nCausal Inference helps machines understand how and why\ncauses inﬂuence their effects (Glymour, Pearl, and Jewell\n2016). Recently, the connection between causality and ma-\nchine learning (Magliacane et al. 2018; Bengio et al. 2020;\nKyono, Zhang, and van der Schaar 2020) or computer vi-\nsion (Lopez-Paz et al. 2017; Yang et al. 2021b; Wang et al.\n2020) have gained increasing interest. Recently, IFSL (Yue\net al. 2020) introduces the causality into few-shot learning\nproblem with an SCM. However, CMVAE differs since it\nexplicitly learns and utilizes the causal factorization.\nDAG Learning is to estimate the structure of variables.\nThere are three types of methods, the discrete optimization\n(Scanagatta et al. 2016; Viinikka et al. 2020), the continuous\noptimization (Zheng et al. 2018, 2020) and the sampling-\nbased methods (Charpentier, Kibler, and G¨unnemann 2022).\nCMVAE incorporates recent continuous optimization meth-\nods to learn the DAG of the context-priors.\n3\nProposed Formulation\n3.1\nProblem Statement\nGiven an unlabeled dataset U in the meta-training stage, we\naim to learn the knowledge which can be adapted to novel\ntasks in the meta-test stage. Each task T is drawn from a\nfew-shot labeled dataset D. The U and D are drawn from the\nsame distribution but a different set of classes. Specially, a\nK-way S-shot classiﬁcation task T consists of support data\nS = {(xs, ys)}KS\ns=0 with K classes of S few labeled samples\nand query data Q = {xq}Q\nq=0 with Q unlabeled samples.\nOur goal is to predict the labels of Q given S.\n3.2\nCausal Insight\nUnsupervised meta-learning methods are confused by the\ncontext-bias. To analyze how the bias arises, we formulate\nthe problem into SCM in Figure 1b. In the SCM, 1) D →X\nmeans that the priors D determine where the object appears\nin an image, e.g., the context-priors in training images of\nFigure 1a put the bird object in the sky. 2) D →Y denotes\nthat the priors D affect the predictions Y , e.g., the wing and\nsky priors lead to the bird prediction. 3) D1, · · · , Dd are de-\npendent statistically, e.g., the “sky”, “wing” and prior are\nnot independent but causally dependent. Their causal rela-\ntionships need to be determined (dashed lines). 4) X →Y\nis the regular classiﬁcation process.\nFrom the SCM, we observe that context-priors D con-\nfound the effect that input X has on prediction Y , which\nleads to the bias. Thus, it is critical to eliminate the con-\nfounding effects, we then apply causal intervention with the\ndo-operator (Glymour, Pearl, and Jewell 2016) as follows\n(Details in Supp. 3.1),\nP(y|do(x)) =\nX\nd1,··· ,dd\nP(y|x, D1 = d1, · · · ,\nDd = dd)P(D1 = d1, · · · , Dd = dd)\n(1)\nwhere di ranges over all values that variables Di can take.\nEquation 1 informs that intervening on x calls for the joint\ndistribution of D. Note that D1, · · · , Dd may be dependent\nstatistically (i.e., P(D) ̸= Πd\ni=1P(Di)). Inspired by CCP\n(Sch¨olkopf et al. 2021), we assume the common causes are\nones of priors. Then ﬁnding the common causes suggests\ndiscovering the causal relationships among the priors. The\ncausal relationships can be represented by a DAG (dashed\nlines). For example in Figure 1a, the ﬂying prior is the com-\nmon cause of sky and wing priors, the DAG is “sky ←ﬂying\n→wing”, and the latter two are independent when condi-\ntioned on the ﬂying. Furthermore, based on ICM (Sch¨olkopf\net al. 2021), the joint distribution P(D) can be factorized\ninto,\nP(D) =\nd\nY\ni=1\nP(Di| PA(i))\n(2)\nD1\nD2\nD3\nD4\n\n\nD1\nD2\nD3\nD4\n\n\nT\n=\n\n\nD1\nD2\nD3\nD4\n\n\nT \n\n0\n0.9\n0.5\n0\n0\n0\n1.4\n2.2\n0\n0\n0\n0\n0\n0\n0\n0\n\n+\n\n\nϵ1\nϵ2\nϵ3\nϵ4\n\n\nT\nFigure 2: An SEM. [Left]: DAG with 4 nodes. [Right]: A\nlinear equation for Gaussian SEM with noise ϵ ∼N(0, I).\nwhere PA(i) denotes the parents of Di, which can be ob-\ntained from the DAG.\nTo discover the DAG, we utilize Gaussian Structural\nEquation Model (SEM) (Pearl et al. 2000). Figure 6b shows\na linear-Gaussian SEM. Formally, given the variables D,\nthere exist functions hi and hj : Rd →R such that\nDi = hi(D) + Ui,\nDj = hj(D) + Uj\n(3)\nwhere Ui and Uj are independent Gaussian noises, and hi\nand hj are regarded as structural functions. The relationship\nbetween hi and PA() is that hi(d1, · · · , dd) does not depend\non dk if Dk /∈PA(i).\nThe DAG can be learned by maximum likelihood estima-\ntion E[Di|hi(D)] and E[Dj|hj(D)] over D. Its “DAGness”\ncan be enforced using a trace exponential regularizer such as\nNoTears penalization (Zheng et al. 2018). Insufﬁcient penal-\nization weight may not ensure the “DAGness” and weaken\nthe effect of bias-removal, but default weight works for most\nscenarios. If the causal graph is Non-DAG graph, a solu-\ntion is to learn such mixed graphs with score-based methods\n(Bernstein et al. 2020). It is compatible with our method.\n3.3\nAdjustment Formulation\nThis section offer an adjustment formulation for Equation 1.\nSpecially, given the DAG function h = {hi}d\ni=1, the distri-\nbution P(D) is approximated by P(D1 = d1, · · · , Dd =\ndd) ≈P(D = d|h(D = d)), where d = [d1| · · · |dd] ∈\nR1×d. Also, given the input data x, we assume its latent\ncodes z ∈R1×d via VAE (Kingma and Welling 2014).\nSince VAE has been shown to achieve some useful disen-\ntangling (Higgins et al. 2016), we perform the dimensional-\nwise product to make each latent code represents one prior,\ni.e., z ←z ⊗d. Then we have P(D = d|h(D = d)) =\nP(Z = z|h(Z = z)). Finally, the adjustment formulation\nyields,\np(y|do(x)) = Ep(z|x)\n| {z }\nSampling\nEp(z|h(z))\n|\n{z\n}\nAdjusting\np(y|z)\n(4)\nEquation 4 reveals that the causal intervention can be ac-\ncomplished by the sampling term p(z|x) and the adjusting\nterm p(z|h(z)) with the DAG function h. Note that the ad-\njusting term is short for two steps: 1) Draw e ∼p(e|z); 2)\nMake z −e ∼N(0, I), which is a constraint that forces h\nto follow the DAG in z. Thus, we call it adjusting.\nWhile variables z and function h may be non-identiﬁable\ndue to non-conditional additionally observed variables (e.g.,\nDAG label) (Khemakhem et al. 2020), we can choose suit-\nable inductive biases to recover a certain structure in the real\nworld (Locatello et al. 2019; Tr¨auble et al. 2021). Besides,\nthe formulation is also sufﬁcient for classiﬁcation based on\nthe two causal principles. Empirical results in Section 5.4\nalso reveal some meaningful explanation.\nThough (Yang et al. 2021a; Kim et al. 2021) have stud-\nied learning causality with VAE, their generative process is\n“noises →causal codes →images”and needs additional ob-\nservations to learn the distributution of codes, which is im-\npractical and limited. While our generative is “noise →im-\nages” and make “noise = causal codes”. It is as ﬂexible as\nvanilla VAE. Compared to Deconfounder (Wang and Blei\n2019), our causal structure on the latent confounders is de-\nﬁned and to be learned by DAG learning methods.\n3.4\nCausal Latent Space\nTo achieve the downstream task such as clustering and clas-\nsiﬁcation, we introduce the causal latent space (CaLS) and\nstudy the computation of weighted sum in this space. Partic-\nularly, we assume the distribution of the causally indepen-\ndent codes z ∈R1×d is Gaussian 2\nz ∼N(h(z), I)\n(5)\nWe refer to the latent codes in CaLS as causal codes, and the\ncausal codes follow the same DAG. Then, the weighted sum\nlatent codes can be obtained by the following proposition.\nProposition 1. Assume there are n causal codes Z ∈Rn×d\nshared same h that represents the DAG, an assignment w ∈\nRn×1 satisfying wT 1 = 1 and the weighted sum z = wT Z.\nThen\nz ∼N(h(z), wT wI)\n(6)\nwhenever h is linear or non-linear function. Proof is avail-\nable in Supp. 3.2.\nProposition 1 shows that whatever the function h, the\ncausal relationships of z by weighted sum over z will re-\nmain unchanged as h can express the DAG structure.\n4\nCausal Meta VAE\nTo demonstrate the effectiveness of pipeline, we extent the\nbaseline (Lee et al. 2021) into our CMVAE. It includes the\nCausal Mixture of Gaussian (CMoG), unsupervised meta-\ntraining and meta-test methods with novel causal Expecta-\ntion Maximization. The following notation subscript is used:\nz[i] ∈R1×d for i-th observation of Z, and zj ∈Rn×1 for\nj-th dimension of Z. Figure 3 shows the graphical model of\nCMVAE.\n4.1\nCausal Mixture of Gaussians\nThe Causal Mixture of Gaussians (CMoG) is an extension\nof MoG distribution in the CaLS based on proposition 1,\nc ∼Cat(π),\nz|c ∼N(µ[k], σ2\n[k]I),\nµ[k] ∼N(h(µ[k]), s2\nkI)\n(7)\nwhere π is K dimensional weights, (µ[k], σ2\n[k]) are mean\nand diagonal covariance of the k-th mixture modality, and\n2Actually we assume the error term ϵ = z −h(z) is Gaussian\nand ignore this error to focus on z and the corresponding space.\nσ2I\nπ\nπ\nc\nz\nz\nh\nh\nh\nx\nx\nμ\nμ\ne\ne\n(a)\nys\nπ\nμ\nh\nxs\nxq\nz\nσ2I\n(b)\nFigure 3: Graphical model of CMVAE. (a) Unsupervised\nmeta-training. CMoG prior ψt = {π, µ}. [Left] Variational\nposterior qφ(z|x, Tt), qφ(e|z, x). ψt is learned by causal-\nEM. [Right] Generative model pθ(x|z, e), p(z|e). (b)Meta-\ntest by semi-supervised causal-EM.\nthe scalar s2\nk is a scaling parameter. Here we take the diago-\nnal covariance σ2\n[k]I instead of Σk since the relationships\nbetween dimensions can be mined by learning the DAG.\nFrom another perspective, Eq. 7 can be seen as a regular-\nization to make the modality causally independent. we refer\nto it as causal modality.\n4.2\nUnsupervised Meta-training\nWe now describe unsupervised meta-training in causal la-\ntent space based on VAE (Kingma and Welling 2014). Given\na meta-training task Tt = {xi ∈U}M\ni=1, the goals are to\noptimize the variational lower bound of the data marginal\nlikelihood of task Tt using an variational posterior. Specif-\nically, for the unsupervised meta-learning where labels are\nunknown, we deﬁne the variational posterior qφ(z|x, Tt)\nand the task-speciﬁc CMoG priors pψ∗\nt (z). For learning\nthe causal structure, let e be sampled from the causal la-\ntent space, where function h is applied to z, i.e., e|z ∼\nN(h(z), I). For posterior network, we use a factorization\nqφ(e, z|x, Tt) = qφ(e|z, x, Tt)qφ(z|x, Tt), sampling z given\nx ∈Tt ﬁrst, then conditionally sampling e based on these\nvalues. It leads to the evidence lower bound (ELBO) (De-\ntails in Supp. 3.3),\nEqφ(z|x,Tt)[Eqφ(e|z,x)[log pθ(x|z, e) −log qφ(e|z, x)\np(e|z)\n]\n+ log pψ∗\nt (z) −log qφ(z|x, Tt)] (8)\nwhere x ∈Tt. The ELBO can be approximated by Monte\nCarlo estimation. We then describe these variational posteri-\nors and priors in detail.\nVariational Posterior. The task-conditioned variational\nposterior qφ(z|x, Tt) is to encode the dependency into the\nlatent space between data in current task. Following (Lee\net al. 2021), we take task Tt as inputs and denote,\nH = TE(F(x)), x ∈Tt,\nµ = WµH + bµ,\nσ2 = exp(Wσ2H + bσ2), qφ(z|x, Tt) = N(z|µ, σ2) (9)\nwhere\nTE(·)\nis\nmulti-head\nself-attention\nmechanism\n(Vaswani et al. 2017), F is a convolutional neural network\n(or an identity function). To learn the causal structure, we\nAlgorithm 1: Unsupervised Causal Meta-training\nInput: An unlabeled dataset U, causal-EM steps step.\nInitialized parameterized qφ, pθ.\nwhile not converged do\nGenerate unlabeled task Tt = {xu|xu ∈U}\nDraw z ∼qφ(z|x, Tt), e ∼qφ(e|z, x) in Eq. 9, 10\nCompute ψ∗\nt in Eq. 14 with step causal-EM\nCompute loss L in Eq. 16 and update φ, θ, h\nend while\napply the function h to the latent space and then sample e\nfrom the obtained causal latent space,\nqφ(e|z, x) = N(e|h(z), I),\nz ∼qφ(z|x, Tt)\n(10)\nCausally Conditional Prior. Ideally if the DAG h repre-\nsents the true causal structure, the conditional prior p(e|z)\ncan be obtained by replacing the unknown h,\np(e|z) = N(0, I) + h(z) = N(e|z, 2I)\n(11)\nTask-speciﬁc Prior. The task-speciﬁc causal multi-modal\nprior is modeled via CMoG and formally factorized as:\npψt(z) =\nK\nX\nc=0\npψt(z|c)pψt(c),\npψt(c) = Cat(c|π),\npψt(z|c) = N(z|µ[k], σ2\n[k]I)N(µ[k]|h(µ[k]), s2\nkI)\n(12)\nwhere the task-speciﬁc parameters ψt is deﬁned as ψt =\n{π, µ[k], σ2\n[k]I, s2\nk}. Maximizing ELBO in Eq. 8 results in\nlocally maximizing the following maximum causal posterior\n(MCP) problem:\nψ∗\nt = argmax\nψt\nX\nlog p(ψt|z)\n(13)\nWithout losing the DAG structure, the derived EM equations\nin closed forms are referred to as causal-EM (Derivations in\nSupp. 3.4),\nE: ωik =\nαkN(z[i]|µ[k], I)N(µ[k]|h(µ[k]), γ2I)\nP\nk αkN(z[i]|µ[k], I)N(µ[k]|h(µ[k]), γ2I)\nM: µ[k] =\nPM\ni=1 ωikz[i](I + ϵ(γ−1I)ϵT (γ−1I))−1\nPM\ni=1 ωik\n(14)\nwhere ϵ(z) = z −h(z) and αk =\nPM\ni=1 ωik\nPK\nk=1\nPM\ni=1 ωik . It can\nalso be simpliﬁed using the inverse covariance matrix and\nwe want to show that the term ϵ(γ−1I) allows that j′ propa-\ngates its information to j if j′ ∈PA(j), then intervenes and\nreﬁnes µ[k]. Following the assumption of VAE, the covari-\nance of Gaussian distribution is set to I. We also observe that\nsetting s2\nk to a ﬁxed hyper-parameter γ2 results in better con-\nvergence. The αk is initialized as\n1\nK , and µ[k] is initialized\nas: µ[k] =\nPK\ni z[i](I+ϵ(γ−1I)ϵT (γ−1I))−1\nK\nwhere {z[i]}K\ni=1 are\nrandomly selected. By performing a few causal-EM steps it-\neratively, the MCP converges and task-speciﬁc parameters\nψ∗\nt is obtained.\n(a)\n(b)\n(c)\n(d)\nFigure 4: Visualization on Omniglot. (a, b) The samples and\ngenerated samples for each mode at supervised meta-test\nstep of CMVAE. Each row stands for each modality ob-\ntained by EM. (c, d) Counterfactual samples by intervention\non causes and effects, respectively. The larger the change,\nthe better the intervention, the more we can show that our\nmethod has learned the causes and effects.\n4.3\nTraining Objective\nDAG Loss. DAG loss is to ensure the “DAGness”. We\nconsider two types. 1) Linear SEM, h(z) = zA, where\nA ∈Rd×d. 2) Nonlinear SEM, we model it with a multi-\nlayer perceptron (MLP), hi(z) = σ(σ(σ(zW1\ni ) · · · )Wl\ni),\nand deﬁne [A]mi = ∥m th-row(W1\ni )∥2 where ∥· ∥2 is ℓ2\nnorm. Then the DAG loss (Zheng et al. 2018) is\nRD(A) = (tr(exp(A ◦A)) −d)2\n(15)\nObjective. After getting the task-speciﬁc parameters ψ∗\nt , we\nuse gradient descent-based method w.r.t. the variational pa-\nrameter φ, the generative parameter θ and the parameters of\nfunction h and minimize the following objective,\nL = −ELBO + λ1RD(A) + λ2∥A∥1\n(16)\nwhere λ1, λ2 are hyper parameters which control the “DAG-\nness”, and ∥· ∥1 is ℓ1 norm.\nAlgorithm 1 shows the steps of the unsupervised meta-\ntraining stage. The outputs of unsupervised meta-training\nstage consists of variational parameter φ, the generative pa-\nrameter θ and the parameters of function h. Similar to the\nregular meta-training stage, these outputs are also model ini-\ntialization as it is a bi-level optimization (Liu et al. 2022b;\nVicol et al. 2022). The inner optimization is to maximize\nELBO over task-speciﬁc ψ in Equation 8. In th outer loop,\nour method is to minimize the loss with regard to task-\nagnostic parameters φ, θ and h in Equation 16.\n4.4\nSupervised Meta-test\nWith CMoG priors, each causal modality can be seen as a\npseudo-class concept. To adapt the causal modality to few-\nshot classiﬁcation, we use both support set and query set\nand draw causal latent codes from the variational posterior\nqφ. During the meta-test given a task T = {(S, Q)|S =\n{xs, ys}S\ns=1, Q = {xq}Q\nq=1}, the goal is to compute the\nconditional probability p(yq|xq, T ) w.r.t. variational poste-\nrior qφ, the causal multi-modal prior parameter ψ∗and the\nbackdoor adjustment in Equation 4:\np(yq|xq, T ) = Eqφ(zq|xq,T )p(zq|h(zq))[pψ∗(yq|zq)]\n(17)\nEq. 17 can also be computed by Bayes rule and Monte Carlo\nsampling. Then the predicted label is\nˆyq = argmax\nk\np(yq = k|zq, T )\n(18)\n1\n5\n21\n51\n58\n10\n2\n11\n33\n34\n39\n44\n59\n(a)\n51\n58\n2\n44\n5\n11\n33\n39\n(b)\n51\n58\n2\n44\n5\n11\n33\n39\nIntervention\n(c)\nFigure 5: (a) DAG on Omniglot by the learned A. Each node\nrepresents each dimension of z. Other nodes are not shown\nbecause they are independent and have no cause-to-effect\nrelationship (b) Part of DAG to show the causes and effects.\nThe gray nodes represent the causes. (c) Intervention on one\ncause, e.g., z44, will change the effects e.g., z5 while will\nnot change other causes, e.g., z11. Best viewed in color.\nTo obtain the optimal prior parameters ψ∗in current meta-\ntest task T and make the causal modality as label, we de-\nvelop a semi-supervised causal-EM algorithm. In particular,\nwe sample the causal code z ∼qφ(z|x, T ) ﬁrst and then get\nthe causal multi-modalities with steps as follows,\nE: ωqk =\nN(z[q]|µ[k], σ2\n[k])N(µ[k]|h(µ[k]), γ2I)\nP\nk N(z[q]|µ[k], σ2\n[k])N(µ[k]|h(µ[k]), γ2I)\nM:\n˜µ[k] =\nX\ns\n˜ωskz[s] +\nX\nq\n˜ωqkz[q]\nµ[k] = ˜µ[k](I + ϵ(γ−1σ[k])ϵT (γ−1σ[k]))−1\n(19)\nσ2\n[k] =\nX\ns\n˜ωsk(z[s] −µ[k])2 +\nX\nq\n˜ωqk(z[q] −µ[k])2\nwhere ˜ωsk =\n1ys=k\nP\ns 1ys=k+P\nq ωqk , ˜ωqk =\nωqk\nP\ns 1ys=k+P\nq ωqk\nand 1 is the indicator function. We keep the mixture prob-\nability ﬁxed to\n1\nK due to the uniformly distributed labels\nand use diagonal covariance σ2\n[k] instead of I to obtain\nmore accurate results. The µ[k] is initialized as: µ[k] =\nP\ns 1ys=kz[s](I+ϵ(γ−1I)ϵT (γ−1I))−1\nP\ns 1ys=k\nFinally, we can get the\nsolution of MCP and ψ∗by a few steps iteratively similar\nto the meta-training.\n5\nExperiment\nIn this section we show the empirical performance of our\nmethod on few-shot classiﬁcation tasks.\n5.1\nExperiment Settings\nDataset. One biased toy dataset and three natural datasets\nare used to test our algorithm. 1) Toy dataset. It is a 2-\nway biased dataset with a synthetic ”bird” and ”plane” im-\nage. (Details in Supp. 5.1.) 2) Omniglot. Omniglot con-\nsists of 1,623 different characters and 20 images per char-\nacter. Each image is 28 × 28 gray-scale. We take 1200, 100,\n323 classes for training, validation and test, respectively. 3)\nminiImageNet. It is a subset of ImageNet (Russakovsky\net al. 2015) and consists of 100 classes, 600 images per class\nTable 1: Results (way, shot) in Omniglot and miniImageNet. The ACAI/DC (RO/N) mean ACAI clustering (Random Out-of-\nclass samples) on Omniglot and DeepCluster (Noise) on miniImageNet.\nOmniglot (way, shot)\nminiImageNet (way, shot)\nMethod\nClustering\n(5,1)\n(5,5)\n(20,1)\n(20,5)\n(5,1)\n(5,5)\n(5,20)\n(5,50)\nTraining from Scratch\nN/A\n52.50\n74.78\n24.91\n47.62\n27.59\n38.48\n51.53\n59.63\nCACTUs-MAML\nBiGAN\n58.18\n78.66\n35.56\n58.62\n36.24\n51.28\n61.33\n66.91\nCACTUs-ProtoNets\nBiGAN\n54.74\n71.69\n33.40\n50.62\n36.62\n50.16\n59.56\n63.27\nCACTUs-MAML\nACAI/DC\n68.84\n87.78\n48.09\n73.36\n39.90\n53.97\n63.84\n69.64\nCACTUs-ProtoNets\nACAI/DC\n68.12\n83.58\n47.75\n66.27\n39.18\n53.36\n61.54\n63.55\nUMTRA\nN/A\n83.80\n95.43\n74.25\n92.12\n39.93\n50.73\n61.11\n67.15\nLASIUM-MAML-RO/N\nN/A\n83.26\n95.29\n-\n-\n40.19\n54.56\n65.17\n69.13\nLASIUMs-ProtoNets-RO/N\nN/A\n80.12\n91.10\n-\n-\n40.05\n52.53\n59.45\n61.43\nMeta-GMVAE\nN/A\n94.92\n97.09\n82.21\n90.61\n42.82\n55.73\n63.14\n68.26\nIFSL†\nN/A\n94.22\n97.01\n82.21\n90.65\n42.90\n56.01\n63.24\n68.90\nCMVAE (ours)\nN/A\n95.11\n97.14\n82.58\n90.79\n44.27\n58.95\n66.25\n70.54\nMAML (Supervised)\nN/A\n94.46\n98.83\n84.60\n96.29\n46.81\n62.13\n71.03\n75.54\nProtoNets (Supervised)\nN/A\n98.35\n99.58\n95.31\n98.81\n46.56\n62.29\n70.05\n72.04\nwith size 84 × 84. we take 64 classes for training, 16 for val-\nidation and 20 for test, respectively. 4) CelebA. CelebA con-\nsists of 202,599 face images with 10,177 number of identi-\nties. It has been used in the 5-way few-shot recognition task.\nEvaluation metrics. During meta-test, we use the classes\nin the test set to generate 1000 tasks and compute the mean\naccuracy and 95% conﬁdence interval on these tasks.\nImplementation Details. We adopt the high-level feature\nreconstruction objective for toy dataset, mini-ImageNet and\nCelebA dataset. The backbone, variational posterior network\nqφ(z|x, Tt) and the high-level feature extractor (i.e., Sim-\nCLR (Chen et al. 2020)) are same as (Lee et al. 2021) for fair\ncomparisons (i.e., 4-layer CNN for Omniglot and 5-layer\nCNN for others). For the generative network pθ(x|z, e), we\nconcatenate z and e in the last dimension, and it outputs\nthe parameter of Bernoulli distribution for Omniglot and\nthe mean of Gaussian distribution for miniImageNet and\nCelebA. The causal function h is deﬁned as described in\nsection 3.4. There are no other parameters in qφ(e|z, x). The\nnumber of iterations for causal-EM steps of all experiment is\n10. The hyper-parameters γ, λ1 and λ2 are chosen based on\nthe validation class accuracy. We train all models for 60,000\niterations using Adam (Kingma and Ba 2015).\n5.2\nBaselines\nWe compare the following unsupervised meta-learning base-\nlines with our approach. CACTUs (Hsu, Levine, and Finn\n2019) extract features by ACAI (Berthelot* et al. 2019), Bi-\nGAN (Jeff Donahue 2017), and Deep- Cluster (Caron et al.\n2018) and then train MAML or ProtoNets. UMTRA (Kho-\ndadadeh, B¨ol¨oni, and Shah 2019) generates training tasks\nby random sampling and augmentation for unsupervised\nmeta-training. Meta-GMVAE (Lee et al. 2021) learns a\nset-level latent representation by EM algorithm. LASIUMs\n(Khodadadeh et al. 2021) creates synthetic training data by\nadding Noise, Random Out-of-class samples, and then train\nMAML or ProtoNets. IFSL (Yue et al. 2020) is a supervised\nmethod. We reimplement it by using backdoor adjustments\nin Meta-GMVAE. Furthermore, we compare the classic su-\nTable 2: Accuracy results on CelebA with 5-way, S-shot\nidentity recognition. All the values are from (Khodadadeh\net al. 2021), except for ours and † that we reproduce.\nAlgorithm\nS = 1\nS = 5\nTraining from scratch\n34.69\n56.50\nCACTUs\n41.42\n62.71\nUMTRA\n39.30\n60.44\nLASIUM-RO-GAN-MAML\n43.88\n66.98\nLASIUM-RO-VAE-MAML\n41.25\n58.22\nLASIUM-RO-GAN-ProtoNets\n44.39\n60.83\nLASIUM-RO-VAE-ProtoNets\n43.22\n61.12\nMeta-GMVAE†\n58.05\n71.95\nIFSL†\n57.98\n72.09\nCMVAE (Ours)\n61.04\n74.18\nMAML (Supervised)\n85.46\n94.98\nProtoNets (Supervised)\n84.17\n90.84\npervised methods MAML (Finn, Abbeel, and Levine 2017),\nProtoNets (Snell, Swersky, and Zemel 2017) to indicate the\ngap between the supervised and unsupervised methods.\n5.3\nResults\nToy dataset. The 2-way 4-shot classiﬁcation results in the\ntoy dataset are 78.51 ± 0.36 for Meta-GMVAE and 93.08\n± 0.32 for our CMVAE. Since Meta-GMVAE does not take\ninto account the context-bias, its performance is not impres-\nsive. While our CMVAE notices the existence of context-\nbias, the about 15% improvement on the biased toy dataset\ndemonstrates that it offers the ability to alleviate the context-\nbias. Natural dataset. Table 1 reports the results of few-shot\nimage classiﬁcation for Omniglot and miniImageNet bench-\nmarks. Table 2 shows the results of 5-way few-shot identity\nrecognition on CelebA. We can observe that our method out-\nperforms state-of-the-art methods, except for the UMTRA\non the 20-shot 5-shot classiﬁcation in Omniglot. Our CM-\nVAE even outperforms 5-way 1-shot classiﬁcation super-\nvised MAML in Omniglot. It is noticed that, for challenging\ndataset e.g., miniImageNet, our method outperforms Meta-\nTable 3: Results of 5-way 1-shot classiﬁcation on Omniglot,\nminiImageNet and CelebA with different settings. We show\nthe impact of choosing hyper parameters on test accuracies.\nIn the Default, the causal function is non-linear, λ1 = 1,\nλ2 = 10−4, and γ = 1.\nOmniglot\nminiImageNet\nCelebA\nDefault\n95.11 ± 0.47\n43.91 ± 0.74\n59.93 ± 0.95\nLinear\n89.26 ± 0.56\n42.68 ± 0.72\n51.28 ± 0.91\nλ1 = 10−1\n94.46 ± 0.49\n43.06 ± 0.75\n59.84 ± 0.95\nλ1 = 105\n94.42 ± 0.48\n42.11 ± 0.74\n59.72 ± 0.88\nλ1 = 1010\n91.28 ± 0.61\n41.27 ± 0.70\n50.92 ± 0.92\nλ2 = 10−2\n94.91 ± 0.50\n42.88 ± 0.75\n59.29 ± 0.93\nλ2 = 10−3\n94.95 ± 0.48\n43.05 ± 0.75\n59.27 ± 0.94\nλ2 = 10−5\n93.58 ± 0.49\n42.66 ± 0.72\n59.59 ± 0.95\nγ2 = s2\nk\n90.34 ± 0.65\n42.55 ± 0.75\n54.25 ± 0.97\nγ2 = 0.5\n94.76 ± 0.48\n43.48 ± 0.74\n60.25 ± 0.94\nγ2 = 0.9\n92.40 ± 0.57\n43.46 ± 0.74\n61.04 ± 0.94\nγ2 = 5\n92.52 ± 0.54\n44.27 ± 0.76\n59.04 ± 0.92\nγ2 = 10\n58.29 ± 1.07\n44.11 ± 0.75\n59.04 ± 0.95\nGMVAE by more than about 2.5% average. This shows that\n1) Our meta-learning network can capture the causal multi-\nmodal distribution. 2) The causality is a more reliable in the\nnatural images. 3) With causally independent codes and the\nadjustment for intervention, the confounding effect of meta-\nknowledge are removed.\nVisualization. To better understand how CMVAE learns\nin the supervised meta-test stage, we visualize the real in-\nstances and ones generated by pθ(x|z, e) in Figure 4a, 4b,\nwhere each row represents each modality. We can observe\nthat 1) The distinction between real samples and generated\nsamples reveals how well our generative ability for network\np(x|z, h) from output distribution. 2) Our CMVAE can cap-\nture the similar visual structure in each modality and make\nit as a class-concept in the meta-test stage.\n5.4\nAblation Study\nCounterfactual samples. To further demonstrate the effec-\ntiveness of the causality learned by CMVAE, we plot the\nDAG structure after obtaining A based on h in Figure 5.\nThe nodes are a collection of dimensions of latent codes i.e.,\nV = {z0, · · · , z63}, and the edges represent cause-to-effect.\nNote that all the nodes are codes with semantics of interest.\nWe can discover that z1, · · · , z59 are the causes.\nFigure 5c shows the intervention propagation. Because in-\ntervening causes will change the effects while intervening\neffects will not change the causes, the image will change\nmore massively when intervening causes. Although we do\nnot know which parts of the image these causes are respon-\nsible for generating, they are the most relevant to image gen-\neration. To this end, we generate counterfactual samples by\nintervening the causes and the effects, respectively, with the\nsame amount (e.g., 7 causes or 7 effects) and intervention\nvalue (e.g., ﬁxed to 0). Figure 4c, 4d show the visual results.\nComparing them, we conclude as follows: 1) Intervention on\nthe causes from the DAG results in larger changes. Since the\nintervention can propagate from causes to effects, the DAG\nlearned by our CMVAE is reliable. 2) The causes are the\nTable 4: Time (s) cost over 10000 20-way tasks on Omniglot\nduring the meta-test stage. Inverse: Matrix inversion.\nEM\nInverse\nCausal EM\n1-shot\n129.59\n139.45 (+7.6%)\n145.31 (+12.1%)\n5-shot\n143.36\n150.52 (+5.0%)\n156.46 (+9.1%)\nmost relevant to the images though we do not know what\nthey means in complex real-world scenes.\nDAG type. We compare the performance of CMVAE with\nregard to the DAG type, i.e., when the DAG function h is\nlinear or non-linear. The results are shown in the Rows 1-\n2 of Table 3. We can observe that performances get worse\nwhen the function h is linear, which is in line with the com-\nmon sense that the cause-to-effect is not a simple linear but\na complex non-linear relation in the natural images.\nInﬂuence of λ1, λ2. The hyper parameters λ1, λ2 control the\n“DAGness”. The larger λ1 and λ2, the more strongly causal\nrelations are enforced. Rows 3-8 of Table 3 show that the\nsetting when λ1 = 1, λ2 = 10−4 outperforms other settings.\nThis is because in the real-world images, factors with seman-\ntics are unknown and uncountable. The weak constraints can\navoid overﬁtting the causal relations.\nEffects of γ. The value of hype parameter γ controls the in-\nﬂuence of causal regularization on modalities. We tuned this\nparameter using the validation classes with the following\nvalues: [s2\nk, 0.5, 0.9, 1.0, 5, 10] where s2\nk = P\ni(\nwik\nP\ni wik )2\nfor the meta-training and s2\nk = P\ns(\n˜ωsk\nP\ns ˜ωsk+P\nq ˜ωqk )2 +\nP\nq(\n˜ωqk\nP\ns ˜ωsk+P\nq ˜ωqk )2 for the meta-test based on the causal\nEM algorithm, and select the best γ corresponding to the\nbest average 5-way 1-shot accuracy over meta-validation\ndata for inference over the meta-test data. The last 5 rows of\nTable 3 shows the test class accuracies with respect to differ-\nent values of γ. Though γ2 = 1, γ2 = 5, γ2 = 0.9 provide\nthe best results for Omniglot, miniImageNet and CelebA,\nwhich shows that the causal regularization needs to satisfy\nfor different datasets, the default value already outperforms\nSOTA and it is user-friendly in practice.\nTime complexity. Compared with the original EM, the in-\nference of causal-EM comes with more time cost, as matrix\noperations (i.e., inversion) have cubic time complexity. Ta-\nble 4 reports that causal-EM costs about 10% more time,\nwhich is acceptable compared to the better accuracy.\n6\nConclusion\nThe context-bias arises when the priors cause spurious cor-\nrections between inputs and predictions in unsupervised\nmeta-learning. In this work, we offer an adjustment formu-\nlation that performs intervention on inputs to achieve bias-\nremoval. We also develop CMVAE that carries out classiﬁ-\ncation in causal latent space. Extensive experiments demon-\nstrate that our approach has a better generalization ability\nacross different tasks and datasets. CMVAE is also ﬂexible\nfor the extension to supervised learning. The limitation is\nthat CMVAE may lack identiﬁability without any additional\nobservation. We leave these questions for future work.\nReferences\nBengio, Y.; Deleu, T.; Rahaman, N.; Ke, N. R.; Lachapelle,\nS.; Bilaniuk, O.; Goyal, A.; and Pal, C. J. 2020.\nA\nMeta-Transfer Objective for Learning to Disentangle Causal\nMechanisms. In 8th International Conference on Learning\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia, April\n26-30, 2020. OpenReview.net.\nBernstein, D.; Saeed, B.; Squires, C.; and Uhler, C. 2020.\nOrdering-Based Causal Structure Learning in the Presence\nof Latent Variables.\nIn Chiappa, S.; and Calandra, R.,\neds., Proceedings of the Twenty Third International Con-\nference on Artiﬁcial Intelligence and Statistics, volume 108\nof Proceedings of Machine Learning Research, 4098–4108.\nPMLR.\nBerthelot*, D.; Raffel*, C.; Roy, A.; and Goodfellow, I.\n2019. Understanding and Improving Interpolation in Au-\ntoencoders via an Adversarial Regularizer. In International\nConference on Learning Representations.\nCaron, M.; Bojanowski, P.; Joulin, A.; and Douze, M. 2018.\nDeep clustering for unsupervised learning of visual features.\nIn Proceedings of the European Conference on Computer\nVision (ECCV), 132–149.\nCharpentier, B.; Kibler, S.; and G¨unnemann, S. 2022. Dif-\nferentiable DAG Sampling. In International Conference on\nLearning Representations.\nChen, T.; Kornblith, S.; Norouzi, M.; and Hinton, G. 2020.\nA simple framework for contrastive learning of visual repre-\nsentations. In International conference on machine learning,\n1597–1607. PMLR.\nFinn, C.; Abbeel, P.; and Levine, S. 2017. Model-Agnostic\nMeta-Learning for Fast Adaptation of Deep Networks. In\nPrecup, D.; and Teh, Y. W., eds., Proceedings of the 34th In-\nternational Conference on Machine Learning, ICML 2017,\nSydney, NSW, Australia, 6-11 August 2017, volume 70 of\nProceedings of Machine Learning Research, 1126–1135.\nPMLR.\nGangloff, H.; Courbot, J.-B.; Monfrini, E.; and Collet, C.\n2021.\nUnsupervised Image Segmentation with Spatial\nTriplet Markov Trees. In ICASSP 2021 - 2021 IEEE Inter-\nnational Conference on Acoustics, Speech and Signal Pro-\ncessing (ICASSP), 1790–1794.\nGlymour, M.; Pearl, J.; and Jewell, N. P. 2016. Causal in-\nference in statistics: A primer. John Wiley & Sons.\nHiggins, I.; Matthey, L.; Pal, A.; Burgess, C.; Glorot, X.;\nBotvinick, M.; Mohamed, S.; and Lerchner, A. 2016. beta-\nvae: Learning basic visual concepts with a constrained vari-\national framework. In International Conference on Learning\nRepresentations.\nHsu, K.; Levine, S.; and Finn, C. 2019. Unsupervised Learn-\ning via Meta-Learning.\nIn International Conference on\nLearning Representations.\nJeff Donahue, T. D., Philipp Kr¨ahenb¨uhl. 2017. Adversarial\nFeature Learning. In International Conference on Learning\nRepresentations.\nKhemakhem, I.; Kingma, D.; Monti, R.; and Hyvarinen, A.\n2020. Variational autoencoders and nonlinear ica: A uni-\nfying framework. In International Conference on Artiﬁcial\nIntelligence and Statistics, 2207–2217. PMLR.\nKhodadadeh, S.; B¨ol¨oni, L.; and Shah, M. 2019. Unsuper-\nvised Meta-Learning for Few-Shot Image Classiﬁcation. In\nWallach, H. M.; Larochelle, H.; Beygelzimer, A.; d’Alch´e-\nBuc, F.; Fox, E. B.; and Garnett, R., eds., NeurIPS 2019,\n10132–10142.\nKhodadadeh, S.; Zehtabian, S.; Vahidian, S.; Wang, W.;\nLin, B.; and Boloni, L. 2021. Unsupervised Meta-Learning\nthrough Latent-Space Interpolation in Generative Models.\nIn International Conference on Learning Representations.\nKim, H.; Shin, S.; Jang, J.; Song, K.; Joo, W.; Kang, W.; and\nMoon, I.-C. 2021. Counterfactual Fairness with Disentan-\ngled Causal Effect Variational Autoencoder. Proceedings of\nthe AAAI Conference on Artiﬁcial Intelligence, 35(9): 8128–\n8136.\nKingma, D. P.; and Ba, J. 2015.\nAdam: A Method for\nStochastic Optimization. In Bengio, Y.; and LeCun, Y., eds.,\n3rd International Conference on Learning Representations,\nICLR 2015, San Diego, CA, USA, May 7-9, 2015, Confer-\nence Track Proceedings.\nKingma, D. P.; and Welling, M. 2014. Auto-Encoding Vari-\national Bayes. In 2nd International Conference on Learning\nRepresentations, ICLR 2014, Banff, AB, Canada, April 14-\n16, 2014, Conference Track Proceedings.\nKyono, T.; Zhang, Y.; and van der Schaar, M. 2020. CAS-\nTLE: Regularization via Auxiliary Causal Graph Discovery.\nIn Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.; and\nLin, H., eds., Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Information Pro-\ncessing Systems 2020, NeurIPS 2020, December 6-12, 2020,\nvirtual.\nLee, D. B.; Min, D.; Lee, S.; and Hwang, S. J. 2021. Meta-\nGMVAE: Mixture of Gaussian VAE for Unsupervised Meta-\nLearning. In International Conference on Learning Repre-\nsentations.\nLiu, N.; Li, S.; Du, Y.; Torralba, A.; and Tenenbaum, J. B.\n2022a. Compositional Visual Generation with Composable\nDiffusion Models. arXiv preprint arXiv:2206.01714.\nLiu, R.; Gao, J.; Zhang, J.; Meng, D.; and Lin, Z. 2022b.\nInvestigating Bi-Level Optimization for Learning and Vision\nFrom a Uniﬁed Perspective: A Survey and Beyond. IEEE\nTransactions on Pattern Analysis and Machine Intelligence,\n44(12): 10045–10067.\nLocatello, F.; Bauer, S.; Lucic, M.; Raetsch, G.; Gelly, S.;\nSch¨olkopf, B.; and Bachem, O. 2019.\nChallenging com-\nmon assumptions in the unsupervised learning of disentan-\ngled representations.\nIn international conference on ma-\nchine learning, 4114–4124. PMLR.\nLopez-Paz, D.; Nishihara, R.; Chintala, S.; Sch¨olkopf, B.;\nand Bottou, L. 2017. Discovering Causal Signals in Images.\nIn 2017 IEEE Conference on Computer Vision and Pattern\nRecognition, CVPR 2017, Honolulu, HI, USA, July 21-26,\n2017, 58–66. IEEE Computer Society.\nMagliacane, S.; Van Ommen, T.; Claassen, T.; Bongers, S.;\nVersteeg, P.; and Mooij, J. M. 2018. Domain adaptation by\nusing causal inference to predict invariant conditional distri-\nbutions. Advances in neural information processing systems,\n31.\nPearl, J.; et al. 2000. CAUSALITY: Models, Reasoning and\nInference. Cambridge, UK: CambridgeUniversityPress, 19.\nReichenbach, H. 1956. The direction of time, volume 65.\nUniv of California Press.\nRussakovsky, O.; Deng, J.; Su, H.; Krause, J.; Satheesh, S.;\nMa, S.; Huang, Z.; Karpathy, A.; Khosla, A.; Bernstein, M.;\net al. 2015. Imagenet large scale visual recognition chal-\nlenge.\nInternational journal of computer vision, 115(3):\n211–252.\nScanagatta, M.; Corani, G.; De Campos, C. P.; and Zaffalon,\nM. 2016. Learning treewidth-bounded Bayesian networks\nwith thousands of variables. Advances in neural information\nprocessing systems, 29.\nSch¨olkopf, B.; Locatello, F.; Bauer, S.; Ke, N. R.; Kalch-\nbrenner, N.; Goyal, A.; and Bengio, Y. 2021. Toward Causal\nRepresentation Learning. Proceedings of the IEEE, 109(5):\n612–634.\nSch¨olkopf, B.; Janzing, D.; Peters, J.; Sgouritsa, E.; Zhang,\nK.; and Mooij, J. M. 2012. On causal and anticausal learn-\ning. In ICML.\nSnell, J.; Swersky, K.; and Zemel, R. S. 2017. Prototyp-\nical Networks for Few-shot Learning.\nIn Guyon, I.; von\nLuxburg, U.; Bengio, S.; Wallach, H. M.; Fergus, R.; Vish-\nwanathan, S. V. N.; and Garnett, R., eds., Advances in Neu-\nral Information Processing Systems 30: Annual Conference\non Neural Information Processing Systems 2017, December\n4-9, 2017, Long Beach, CA, USA, 4077–4087.\nTr¨auble, F.; Creager, E.; Kilbertus, N.; Locatello, F.; Dit-\ntadi, A.; Goyal, A.; Sch¨olkopf, B.; and Bauer, S. 2021.\nOn Disentangled Representations Learned from Correlated\nData. In Meila, M.; and Zhang, T., eds., Proceedings of the\n38th International Conference on Machine Learning, vol-\nume 139 of Proceedings of Machine Learning Research,\n10401–10412. PMLR.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At-\ntention is all you need. In Advances in neural information\nprocessing systems, 5998–6008.\nVicol, P.; Lorraine, J. P.; Pedregosa, F.; Duvenaud, D.; and\nGrosse, R. B. 2022. On Implicit Bias in Overparameterized\nBilevel Optimization. In Chaudhuri, K.; Jegelka, S.; Song,\nL.; Szepesvari, C.; Niu, G.; and Sabato, S., eds., Proceedings\nof the 39th International Conference on Machine Learning,\nvolume 162 of Proceedings of Machine Learning Research,\n22234–22259. PMLR.\nViinikka, J.; Hyttinen, A.; Pensar, J.; and Koivisto, M.\n2020. Towards scalable bayesian learning of causal dags.\nAdvances in Neural Information Processing Systems, 33:\n6584–6594.\nWang, T.; Huang, J.; Zhang, H.; and Sun, Q. 2020.\nVi-\nsual Commonsense R-CNN. In 2020 IEEE/CVF Conference\non Computer Vision and Pattern Recognition, CVPR 2020,\nSeattle, WA, USA, June 13-19, 2020, 10757–10767. Com-\nputer Vision Foundation / IEEE.\nWang, Y.; and Blei, D. M. 2019. The blessings of multi-\nple causes. Journal of the American Statistical Association,\n114(528): 1574–1596.\nYang, M.; Liu, F.; Chen, Z.; Shen, X.; Hao, J.; and Wang,\nJ. 2021a.\nCausalVAE: disentangled representation learn-\ning via neural structural causal models. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 9593–9602.\nYang, X.; Zhang, H.; Qi, G.; and Cai, J. 2021b.\nCausal\nattention for vision-language tasks. In Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 9847–9857.\nYu, P.; Xie, S.; Ma, X.; Zhu, Y.; Wu, Y. N.; and Zhu, S.-C.\n2021. Unsupervised Foreground Extraction via Deep Region\nCompetition. In Beygelzimer, A.; Dauphin, Y.; Liang, P.;\nand Vaughan, J. W., eds., Advances in Neural Information\nProcessing Systems.\nYue, Z.; Zhang, H.; Sun, Q.; and Hua, X.-S. 2020. Interven-\ntional Few-Shot Learning. In Larochelle, H.; Ranzato, M.;\nHadsell, R.; Balcan, M. F.; and Lin, H., eds., Advances in\nNeural Information Processing Systems, volume 33, 2734–\n2746. Curran Associates, Inc.\nZheng, X.; Aragam, B.; Ravikumar, P.; and Xing, E. P.\n2018. DAGs with NO TEARS: Continuous Optimization\nfor Structure Learning. In Proceedings of the 32nd Inter-\nnational Conference on Neural Information Processing Sys-\ntems, NIPS’18, 9492–9503. Red Hook, NY, USA: Curran\nAssociates Inc.\nZheng, X.; Dan, C.; Aragam, B.; Ravikumar, P.; and Xing, E.\n2020. Learning sparse nonparametric dags. In International\nConference on Artiﬁcial Intelligence and Statistics, 3414–\n3425. PMLR.\nAppendix\nA\nImpacts\nA.1\nImpacts of Unsupervised Meta-Learning\nThough unsupervised meta-learning may not attract much\nattention now, we argue that it is a promising direction. Su-\npervised meta-learning requires a large labeled dataset dur-\ning the meta-training phase, which is a limitation in practice.\nHowever, unsupervised meta-learning learns to learn with\neasily obtainable unlabeled datasets in meta-training and\nonly requires few labeled data in meta-test, which is “actu-\nall” few-shot learning. Furthermore, in more simple datasets\n(i.e., Omniglot) 5-way 1-shot task, our work even outper-\nforms supervised MAML. And in more complex datasets\n(i.e., miniImageNet) 5-way 1-shot task, our work is 2.6%\nlower than MAML, where the gap is not too large.\nA.2\nPotential Societal Impacts\nBrieﬂy, Our method using the latent variables could be used\nto alter certain image semantic aspects, and then create fake\nimages with the intent to deceive the system and spread mis-\ninformation. Additionally, for causal inference practitioners\nmay over-rely on the claim with few assumptions, becom-\ning less rigorous when considering necessary assumptions\nsuch as identiﬁability. On the other hand, it could have a\nclear positive social impact, if CMVAE or other unsuper-\nvised meta-learning methods become usable and prevalent\nin application areas such as epidemiology where collect-\ning labeled data is very expensive. CMVAE may also mo-\ntivate researchers to investigate causal inference, which is a\npromising area for machine learning.\nB\nBasic Causal Properties\nCommon\nCause\nPrinciple.\n(Reichenbach\n1956;\nSch¨olkopf et al. 2021) If two observables X and Y are\nstatistically dependent, then there exists a variable Z that\ncausally inﬂuences both and explains all the dependence in\nthe sense of making them independent when conditioned on\nZ.\nIndependent Causal Mechanism Principle.\n(Sch¨olkopf\net al. 2021) The causal generative process of a system’s vari-\nables is composed of autonomous modules that do not in-\nform or inﬂuence each other. In the probabilistic case, this\nmeans that the conditional distribution of each variable given\nits causes (i.e., its mechanism) does not inform or inﬂuence\nthe other mechanisms.\nSCM.\nTo describe the relevant concepts and how they in-\nteract with each other, we abstract the problem into an SCM\nin Figure 6a. In the SCM, D →X means that the priors D\ndetermine where the object appears in an image XX, e.g.,\nin the main paper, the context priors in training images of\nFigure 1 put the bird object in the sky. D →Y denotes\nthat the priors D affect the predictions Y , e.g. the wing and\nsky priors lead to the bird prediction. X →Y is the regular\nclassiﬁcation process. From the SCM, we observe that D are\nconfounders and cause spurious correlation from X to Y .\nSEM.\nThe causal relationships between the variables D\ncan be estimated via SEM, represented by a weighted DAG.\nFigure 6b shows a linear-Gaussian SEM. In this paper, one\nof the goal is to estimated the weighted DAG.\nThe function hi(u1, ..., ud) does not depend on uk if\nDk /∈PA(i). hi can show the dependence among vari-\nables. For example, given a 4-node DAG where the nodes are\nD = {D1, D2, D3, D4} and the edges are {D1 →D2 ←\nD3, D4}, we have PA(2) = {D1, D3}. Since D2 is not de-\npended on {D2, D4}, the function h2 should be constant for\nall u2, u4 ∈R where D2 = u2, D4 = u4. In other words,\nif a learned h2 satisﬁes the above property, the dependence\nand parents of D2 will be known. Ditto for other hi, and the\nDAG will be known.\nC\nTheoretical Analysis\nC.1\nDerivation for Bias Removal\nWe offer a theoretical analysis based on the SCM in Fig-\nure 2. Before the derivation, we ﬁrst formally introduce two\nconcepts.\nDeﬁnition 1 (Block (Glymour, Pearl, and Jewell 2016))\nA set D of nodes is said to block a path p if either 1) p\ncontains at least one arrow-emitting node that is in D, or 2)\np contains at least one collision node that is outside D and\nhas no descendant in D.\nDeﬁnition 2 (Admissible sets (Pearl et al. 2000)) A set D\nis admissible (or ”sufﬁcient”) for adjustment if two condi-\ntions hold: 1). No element of D is a descendant of X. 2).\nThe elements of D ”block” all ”back-door” paths from X to\nY , namely all paths that end with an arrow pointing to X.\nIn the SCM, there exists ”back-door” paths P: X ←\nD1 →Y, ..., X ←Dd →Y that carry spurious associa-\ntions from X to Y . Blocking the paths P ensures that the\nmeasured association between X and Y is purely causative.\nMeanwhile, the set D = {D1, ..., Dd} is an admissible set\nand sufﬁcient for adjustment.\nWe consider the binary problem for convenience. For-\nmally, the average risk difference in stratum {u1, ..., ud} of\nD is:X\nu1,...,ud\n(P(Y = 1|X = 1, D1 = u1, ..., Dd = ud)\n−P(Y = 1|X = 0, D1 = u1, ..., Dd = ud))·\nP(D1 = u1, ..., Dd = ud)\n(20)\nThe risk difference focuses on effect of X. It is considered\none estimate of the true causal relationship without bias. One\nthe other hand, based on the adjustment formula, the causal\neffect is\nP(Y = 1|do(X = 1)) −P(Y = 1|do(X = 0))\n(21)\nWe then derive to prove that the above two equations are\nequivalent. Firstly, according to the the law of total proba-\nbility, we have:\nP(Y = 1|do(X = 1)) =\nX\nu1,...,ud\nP(Y = 1|do(X = 1), D1 = u1, ..., Dd = ud)·\nP(D1 = u1, ..., Dd = ud|do(X = 1))\n(22)\nD1\nD2\nDd\nX\nY\n...\n(a) SCM\nD1\nD2\nD3\nD4\n\n\nD1\nD2\nD3\nD4\n\n\nT\n=\n\n\nD1\nD2\nD3\nD4\n\n\nT \n\n0\n0.9\n0.5\n0\n0\n0\n1.4\n2.2\n0\n0\n0\n0\n0\n0\n0\n0\n\n+\n\n\nϵ1\nϵ2\nϵ3\nϵ4\n\n\nT\n(b) A linear SEM with 4 nodes\nFigure 6: (a) The Structural Causal Model (SCM). Causalities need to be learned (dashed lines) (b) A Structural Equation Model\n(SEM). [Left]: DAG with 4 nodes. [Right]: A linear equation for Gaussian SEM with noise ϵ ∼N(0, I).\n: Samples \n: Correlations\n: LatentCodes\n: Causal Relations\nCausal\n(a) Common Latent Space\n(b) Causal Latent Space\nFigure 7: CMVAE projects the latent codes (left) into the\nCausal space (right) and performs causal-EM algorithm to\nget the causal multi-modal prior. During training, the com-\nmon latent space gradually turns into the causal latent space\nwith the novel loss function.\n1\n5\n21\n51\n58\n10\n2\n11\n33\n34\n39\n44\n59\nFigure 8: DAG on Omniglot by the learned A. Each node\nrepresents each dimension of z. Other nodes are not shown\nbecause they are independent and have no cause-to-effect\nrelationship\nAlgorithm 2: Causal Meta-test\nInput: A meta test task T , causal-EM steps step.\nDraw z ∼qφ(z|x, T ) in Eq. 9\nInitialize µ[k]\nCompute ψ∗in Eq. 19 with step causal-EM iteratively\nCompute p(yq|xq, T ) in Eq. 17\nOutput: Query predictions ˆyq computed by Eq. 18\nSince D1, ..., Dd block all backdoor paths P, the only\nconnection from X to Y is causal relation. Then, we can\nremove the do() operator in the factor for Y in the ﬁrst part\nand get:\nP(Y = 1|do(X = 1), D1 = u1, ..., Dd = ud)\n= P(Y = 1|X = 1, D1 = u1, ..., Dd = ud)\n(23)\nFuthermore, there is no path from X to D1, ..Dd since we\nintervene on X. Then we can remove the do(X = 1) in the\nsecond part:\nP(D1 = u1, ..., Dd = ud|do(X = 1))\n= P(D1 = u1, ..., Dd = ud)\n(24)\nCombining them, we have:\nP(Y = 1|do(X = 1)) =\nX\nu1,...,ud\nP(Y = 1|X = 1, D1 = u1, ..., Dd = ud)·\nP(D1 = u1, ..., Dd = ud)\n(25)\nSimilarity,\nP(Y = 1|do(X = 0)) =\nX\nu1,...,ud\nP(Y = 1|X = 0, D1 = u1, ..., Dd = ud)·\nP(D1 = u1, ..., Dd = ud)\n(26)\nThen P(Y = 1|do(X = 1)) −P(Y = 1|do(X = 0)\nequals the average risk difference.\nIn general, for multi-classiﬁcation, given the admissible\nset, all factors on the right hand side of the equation are es-\ntimable from the observed data, the causal effect can like-\nwise be estimated from such data without bias.\nTable 5: Set-level variational posterior network qφ(z|x, Tt) used for Omniglot dataset.\nOutput Size\nLayers\n1 × 28 × 28\nInput Images\n64 × 14 × 14\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n64 × 7 × 7\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n64 × 4 × 4\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n64 × 2 × 2\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n256\nFlatten\n256\nTransformerEncoder(dmodel = 256, dff = 256, h = 4, ELU, LayerNorm = False)\n256\nTransformerEncoder(dmodel = 256, dff = 256, h = 4, ELU, LayerNorm = False)\n64 × 2\nLinear(256, 64 × 2)\nTable 6: Generative Network pθ(x|z, e) for Omniglot\ndataset.\nOutput Size\nLayers\n64 × 2\nLatent code\n256\nLinear(64,256), ELU\n256\nLinear(256,256), ELU\n256\nLinear(256,256), ELU\n64 × 2 × 2\nUnﬂatten\n64 × 4 × 4\ndeconv2d(4 × 4, stride 2, padding 1),\nBatchNorm2D, ReLU\n64 × 7 × 7\ndeconv2d(3 × 3, stride 2, padding 1),\nBatchNorm2D, ReLU\n64 × 14 × 14\ndeconv2d(4 × 4, stride 2, padding 1),\nBatchNorm2D, ReLU\n1 × 28 × 28\ndeconv2d(4 × 4, stride 2, padding 1),\nSigmoid\nC.2\nProof of Proposition 3.1\nAssume z[i] ∈R1×d and wi ∈R is the ith element of Z and\nw. Then, we have\nz =\nX\n(wiz[i]) ∼N(\nX\nwih(z[i]),\nX\nwi\n2I)\n(27)\nTaking ﬁrst-order Taylor approximation h(z) = h(0) +\nzh′(0) + R1(z), where R1(z) = z2 h′′(ξ)\n2\n. h′(0) is an\namendatory approximation of the DAG matrix, and R1(z)\naffects the edge weights only, then\nX\nwih(z[i]i)\n=\nX\n[wih(0) + wiz[i]h′(0) + wiR1(z[i])]\n= h(0) + (\nX\nwiz[i])h′(0) + R1(\nX\nwiz[i])\n+\nX\nwiR1(z[i]) −R1(\nX\nwiz[i])\n= h(\nX\nwiz[i]) +\nX\nwiR1(z[i]) −R1(\nX\nwiz[i]) (28)\nCompared the last two terms:\nlim\nz[i]→0\nP wiR1(z[i])\nR1(P wiz[i]) = lim\nz[i]→0\nP wiz[i]2h′′(ξ)\n(P wiz[i])2h′′(ξ′)\n=\nP wih′′(ξ)\n(P wi)2h′′(ξ′) = h′′(ξ)\nh′′(ξ′)\n(29)\nwhere some ξj ∈(0, mini (z[i]j)), ξ′\nj ∈(0, P\ni wiz[i]j).\nCombined with Eq. 27-29, we have\nz ∼N(h(z) + ( h′′(ξ)\nh′′(ξ′) −I)R1(z), wT wI)\n∼N(h(z), wT wI) + ( h′′(ξ)\nh′′(ξ′) −I)R1(z)\n(30)\nBecause ( h′′(ξ)\nh′′(ξ′) −I)R1(z) only changes the causal edge\nweights, it can be ignored and the DAG structure remains\nunchanged whenever h is linear or non-linear function:\nC.3\nDetails of Equation 8\nIn this section, we describe the Equation 8 in detail. Given a\ntask Tt, we assume there exists task dependent causal multi-\nmodalities ψ∗\nt , and we want maximize the marginal log-\nlikehood of Tt:\nlog pθ(Tt) =\nX\nlog pθ(x)\n=\nX\nlog\nZZ\npθ(x|z, e)pψ∗\nt (z)p(e|z)qφ(e, z|x, Tt)\nqφ(e, z|x, Tt)dedz\n=\nX\nlog\nZZ\npθ(x|z, e)pψ∗\nt (z)p(e|z)qφ(z|x, Tt)qφ(e|z, x)\nqφ(z|x, Tt)qφ(e|z, x)dedz\n=\nX\nlog\nZ\npθ(x|z, e)p(e|z)qφ(e|z, x)\nqφ(e|z, x)de\nZ\npψ∗\nt (z)qφ(z|x, Tt)\nqφ(z|x, Tt)dz\n≥\nX\nEqφ(z|x,Tt)[Eqφ(e|z,x)[log pθ(x|z, e) −log qφ(e|z, x)\np(e|z)\n]\n+ log pψ∗\nt (z) −log qφ(z|x, Tt)]\n=\nX\nELBO,\nz ∼qφ(z|x, Tt),\ne|z ∼qφ(e|z, x)\n(31)\nTable 7: Set-level variational posterior network qφ(z|x, Tt) used for miniImageNet and CelebA.\nOutput Size\nLayers\n256\nFlatten\n256\nTransformerEncoder(dmodel = 256, dff = 256, h = 4, ELU, LayerNorm = False)\n256\nTransformerEncoder(dmodel = 256, dff = 256, h = 4, ELU, LayerNorm = False)\n64 × 2\nLinear(256, 64 × 2)\nTable 8: Feature Extractor for SimCLR on miniImageNet and CelebA.\nOutput Size\nLayers\n3 × 84 × 84\nInput Images\n64 × 42 × 42\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n64 × 21 × 21\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n64 × 10 × 10\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n64 × 5 × 5\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n64 × 2 × 2\nconv2d(3 × 3, stride 1, padding 1), BatchNorm2D, ReLU, Maxpool(2 × 2, stride 2)\n256\nFlatten\nTable 9: Generative Network pθ(x|z, e) for miniImageNet\nand CelebA.\nOutput Size\nLayers\n64 × 2\nLatent code\n512\nLinear(64, 512), ELU\n512\nLinear(512, 512), ELU\n256\nLinear(512, 256), ELU\nTable 10: Results (way, shot) with 95% conﬁdence interval\non the Omniglot.\nOmniglot (way, shot)\n(5,1)\n(5,5)\nCMVAE\n95.11 ± 0.47\n97.14 ± 0.20\nOmniglot (way, shot)\n(20,1)\n(20,5)\nCMVAE\n82.58 ± 0.41\n90.97 ± 0.18\nC.4\nDerivations of Causal-EM\nThe MCP can be rewritten as:\nX\ni\nlog pψt(z[i]) =\nX\ni\nlog\nX\nk\npψt(z|c)pψt(c)\n=\nX\ni\nlog\nX\nk\np(c = k)N(z|µ[k], σ2\n[k]I)N(µ[k]|h(µ[k]), s2\nkI)\n=\nX\ni\nlog\nX\nk\np(c = k|z[i], µ[k], σ2\n[k]I, s2\nkI)·\np(c = k)N(z|µ[k], σ2\n[k]I)N(µ[k]|h(µ[k]), s2\nkI)\np(c = k|z[i], µ[k], σ2\n[k]I)\n≥\nX\ni\nX\nk\nωik log\nαkN(z|µ[k], σ2\n[k]I)N(µ[k]|h(µ[k]), s2\nkI)\nωik\n= Q(ψt, ψ′\nt)\n(32)\nTable 11: Results (way, shot) with 95% conﬁdence interval\non the miniImageNet and CelebA.\nminiImageNe (way, shot)\n(5,1)\n(5,5)\nCMVAE\n44.27 ± 0.76\n58.95 ± 0.71\nminiImageNe (way, shot)\n(5, 20)\n(5, 50)\nCMVAE\n66.25 ± 0.51\n70.54 ± 0.44\nCelebA (way, shot)\n(5,1)\n(5,5)\nCMVAE\n61.04 ± 0.94\n74.18 ± 0.67\nwhere ψ′\nt is values of the previous iteration, αk = p(c =\nk) and s2\nk = P\ni(\nwik\nP\ni wik )2. Here we ﬁx the parameters of h\nduring the whole progress.\nE-step: According to Bayes’ theorem, ωik is:\nωik = p(c = k|z[i], µ[k], σ2\n[k]I, s2\nkI)\n=\nαkp(z[i]|µ[k], σ2\n[k]I, s2\nkI)\nP\nk αkp(z[i]|µ[k], σ2\n[k]I, s2\nkI)\n=\nαkN(z[i]|µ[k], I)N(µ[k]|h(µ[k]), s2\nkI)\nP\nk αkN(z[i]|µ[k], I)N(µ[k]|h(µ[k]), s2\nkI)\n(33)\nThen we have\nQ(ψt, ψ′\nt)\n=\nX\ni\nX\nk\nωik(log αk −log ωik\n−log\nq\n2πσ2\n[k] −(z[i] −µ[k])(z[i] −µ[k])T\n2σ2\n[k]\n−log\nq\n2πs2\nk −(µ[k] −h(µ[k]))(µ[k] −h(µ[k])T\n2s2\nk\n)\n(34)\nM-step: The derivations of αk and σ[k] is the same with\ncommon M-step, since the additional term does not contain\n(a) Intervention on z1, z59\n(b) Intervention on z7, z30\n(c) Intervention on z5, z58\n(d) Intervention on z23, z41\n(e) Intervention on z1, z59\n(f) Intervention on z7, z30\n(g) Intervention on z5, z58\n(h) Intervention on z23, z41\nFigure 9: Counterfactual samples generated. In the top row, the intervened value is 0. In the bottom row, the intervened value is\n1. (a, e) The dimensions are two causes. (c, g) The dimensions are two effects. (b, d, f, h) The dimensions are selected randomly.\nthese parameters.\nαk =\nPM\ni=1 ωik\nPK\nk=1\nPM\ni=1 ωik\n(35)\nσ[k] =\nPM\ni=1 ωik(z[i] −µ[k])2\nPM\ni=1 ωik\n(36)\nFor µ[k], we take ﬁrst-order Taylor approximation h(z) ≈\nh(0)+zh′(0). h′(0) is an amendatory approximation of the\nDAG matrix, and others affects the edge weights only. We\nassume the errors can be eliminated with neural networks.\nDenote ϵ(·):\nϵ(z) = z −h(z) ≈ϵ(0) + z(I −h′(0))\n(37)\nand b = ϵ(0), C = I −h′(0), then we have ϵ(z) = b+zC.\n∂Q\n∂µ[k]\n=\nX\ni\nωik(zi −µ[k]\nσ2\n[k]\n−µ[k]CCT −CbT\ns2\nk\n) = 0\n⇒\nµ[k] =\nP\ni z[i](I + CCT (s−1\nk σ[k]I)2)−1\nP\ni ωik\n−bCT (s−1\nk σ[k]I)2\n(38)\nReplace b, C back with ϵ(),\nCCT (s−1\nk σ[k]I)2 = (s−1\nk σ[k]IC)(s−1\nk σ[k]IC)T\n≈(ϵ(s−1\nk σ[k]I) −ϵ(0[d×d]))(ϵ(s−1\nk σ[k]I) −ϵ(0[d×d]))T\n(39)\nbCT (s−1\nk σ[k]I)2 = s−2\nk σ2\n[k]bCT ≈ϵ(s−2\nk σ2\n[k]ϵ(0)) −ϵ(0)\n(40)\nThen we can get the approximated closed solution:\nµ[k] =\nP\ni z[i](I + (ϵ(s−1\nk σ[k]I) −ϵ(0[d×d]))(ϵ(s−1\nk σ[k]I) −ϵ(0[d×d]))T )−1\nP\ni ωik\n−ϵ(s−2\nk σ2\n[k]ϵ(0)) + ϵ(0)\n(41)\nBoth in the unsupervised meta-learning and meta-test, we\nassume ϵ(0) = 0 to reduce the complexity of calculation\nbecause the errors can be ignored iteratively if Efj(z) = 0.\nThen Eq 41 can be reduced as:\nµ[k] =\nP\ni z[i](I + ϵ(s−1\nk σ[k]I)ϵT (s−1\nk σ[k]I))−1\nP\ni ωik\n(42)\nD\nImplementation details\nD.1\nHigh level of CMVAE\nWe show high level of CMVAE as Figure 7. CMVAE\nprojects the latent codes (left) into the Causal space (right)\nand performs causal-EM algorithm to get the causal multi-\nmodal prior. During training, the common latent space grad-\nually turns into the causal latent space. The Algorithm 2\nshows the meta-test stage.\nD.2\nOmniglot\nFollowing Meta-GMVAE (Lee et al. 2021), we train all mod-\nels for 60,000 iterations using Adam (Kingma and Ba 2015)\n(a)\n(b)\n(c)\n(d)\nFigure 10: (a)(b) Toy samples generated by ”A bird is ﬂying in the sky”. (c)(d) Toy samples generated by ”A bird is standing\non the ground”.\nTable 12: Results with 95% conﬁdence interval on the miniImageNet and CelebA.\nMethod\nAT\nLinear\nNonlinear\nVanilla-EM\nCausal-EM\nminiImageNet\nCelebA\nBaseline\n✓\n42.81 ± 0.70\n58.05 ± 0.90\n✓\n✓\n✓\n42.68 ± 0.72\n51.28 ± 0.91\n✓\n✓\n✓\n43.48 ± 0.74\n60.03 ± 0.95\nOurs\n✓\n✓\n✓\n44.27 ± 0.76\n61.04 ± 0.94\nwith learning rate 1e-3. For the 5-way experiments (i.e., K\n= 5), we set the mini-batch size, the number of datapoints,\nand Monte Carlo sample size as 4, 200, and 32, respectively.\nFor the 20-way experiments (i.e., K = 20), we set them as 4,\n300, and 32. We set the number of causal EM iterations as\n10.\nNetwork architecture. The set-level variational posterior\nnetwork qφ(z|x, Tt) and generative Network pθ(x|z, e) are\nsummarized as Table 5, 6, respectively.\n95% Conﬁdence interval. We provide the standard er-\nrors of our model’s performance at 95% conﬁdence interval\nover 1000 episodes on the Omniglot dataset in Table 10.\nD.3\nminiImageNet and CelebA\nSince the high-level features for miniImageNet and CelebA\nare extracted by SimCLR, the settings are also same. We\ntrain all models using Adam (Kingma and Ba 2015) with\nlearning rate 1e-4. For the 5/20-way experiments (i.e., K = 5\nor 20), we set the mini-batch size, the number of datapoints,\nand Monte Carlo sample size as 16, 5, and 256, respectively.\nWe set the number of causal EM iterations as 10.\nNetwork architecture. The SimCLR, set-level varia-\ntional posterior network qφ(z|x, Tt) and generative Network\npθ(x|z, e) are summarized as Table 8, 7, 9, respectively.\n95% Conﬁdence interval. We provide the standard er-\nrors of our model’s performance at 95% conﬁdence interval\nover 1000 episodes on the miniImageNet and CelebA dataset\nin Table 11.\nE\nAdditional Study\nDAG and Counterfactual Samples. we show the full\nDAG in Figure 8. From Figure 8, we discover that\nTable 13: Results with 95% conﬁdence interval on the biased\ntoy examples.\nMethod\n2-way 5-shot\nMeta-GMVAE\n78.51 ± 0.36\nOurs\n93.08 ± 0.32\nz1, z11, z33, z34, z39, z44, z59 are the causes. More counter-\nfactual samples are shown in Figure 9. In the top row, the in-\ntervened value is 0. In the bottom row, the intervened value\nis 1.\nResults of Each Component. Table 12 reports the results\nof the ablation study on each component on 5-way 1-shot\nclassiﬁcation on miniImageNet and CelebA. ’Baseline’ de-\nnotes that we do not consider the causality and do not ap-\nply the adjusting term. ’AT’ denotes that we apply the ad-\njusting term. ’Linear’ denotes that we assume the causal-\nity relationship between context priors is linear. ’Nonlinear’\ndenotes that we assume the causality relationship between\ncontext priors is nonlinear. ’Vanilla-EM’ denotes that we\ncalculate the modalities with traditional EM. ’Causal-EM’\ndenotes that we calculate the modalities with causal-EM.\nWe observe that: (1) It is in line with common sense that\nthe cause-to-effect is not a simple linear but a complex non-\nlinear relationship in the natural images. (2) With nonlinear\nassumptions, the adjusting term address the context bias. (3)\nCausal-EM is the solution for maximum causal posterior and\ncan remove the context bias better.\nE.1\nToy Examples\nIn this section, we perform two types of toy examples.\nIntuitively-labeled Toy Example. This toy example is to\n(a)\n(b)\n(c)\n(d)\nFigure 11: (a) A toy sample generated by ”A bird in the sky”. (b) A toy sample generated by ”A bird is on the ground” (c) A\ntoy sample generated by ”A plane in the sky”. (d) A toy sample generated by ”A plane is on the ground”\nTable 14: Results with 95% conﬁdence interval on the\nminiImageNet and CelebA.\nMethod\nminiImageNet\nCelebA\nDRC\n43.14 ± 0.73\n59.67 ± 0.91\nSTMT\n41.97 ± 0.65\n58.92 ± 0.90\nOurs\n44.27 ± 0.76\n61.04 ± 0.94\nfurther show the learned DAG with an unsupervised manner\nis meaningful. We build a synthetic bird image dataset. Each\nimage contains 3 concepts (wing, ﬂying, sky). Intuitively,\nthe relationship-label Ag is ”wing ←ﬂying →sky”. Figure\n10 shows some samples. Specially, 1K images with 84 × 84\nsize are generated by the Composable Diffusion Models (Liu\net al. 2022a) with the text input ”A bird is ﬂying in the sky”\nand ”A bird is standing on the ground”. During unsupervised\ntraining, we set the dimension to 3 and the number of clus-\nters to 1. During test, we calculate the relationship A from\nthe learned DAG, and compute the Structural Hamming dis-\ntance (SHD). We ran 100 random experiments. For the total\n2 edges, the average of SHD is 0.7 in the linear DAG setting,\nand 0.4 with the nonlinear DAG setting, respectively. (lower\nis better).\nBiased Toy Example. Here we provide a 2-way biased\ntoy example. We build a synthetic image dataset with two\nclass ”bird” and ”plane”. Specially, 2k images (1K for train-\ning and 1K for test) are generated by the Composable Diffu-\nsion Models (Liu et al. 2022a) with the text input ”A bird in\nthe sky”, ”A bird is on the ground”, ”A plane in the sky” and\n”A plane is on the ground”. Figure 11 shows some samples.\nAs Figure 1 shows, in the tasks, the support sets are biased\nand the query sets are drawn uniformly at random. During\ntest, the number of clusters is set to 2 and the number of\nquery data is 15. The results are as shown in Table 13. We\ncan observe that our can alleviate the bias with about 15%\nimprovement.\nE.2\nCompared with Other Methods\nFor background removal approaches, DRC (Yu et al. 2021)\nis probabilistic foreground-background modeling by recon-\nciling energy-based prior in a fully unsupervised manner.\nFor probabilistic graphical models (PGMs), STMT (Gan-\ngloff et al. 2021) enriches the dependencies between the ran-\ndom variables to better take into account the spatial context\nof an image in an unsupervised manner. To apply DRC and\nSTMT in unsupervised meta-learning, we train them in the\nunlabeled train set to remove the background and extract the\nforeground and then use standard Meta-GMVAE to perform\nclassiﬁcation. The results of 5-way 1-shot classiﬁcation are\nas shown in Table 14. Our method performs best. The rea-\nson may be (1) DRC and STMT do not consider the depen-\ndence among priors. (2) Meta-GMVAE highly depends on\nthe qualities of DRC and STMT.\n",
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "published": "2023-02-20",
  "updated": "2023-02-20"
}