{
  "id": "http://arxiv.org/abs/2304.07689v3",
  "title": "Learning Empirical Bregman Divergence for Uncertain Distance Representation",
  "authors": [
    "Zhiyuan Li",
    "Ziru Liu",
    "Anna Zou",
    "Anca L. Ralescu"
  ],
  "abstract": "Deep metric learning techniques have been used for visual representation in\nvarious supervised and unsupervised learning tasks through learning embeddings\nof samples with deep networks. However, classic approaches, which employ a\nfixed distance metric as a similarity function between two embeddings, may lead\nto suboptimal performance for capturing the complex data distribution. The\nBregman divergence generalizes measures of various distance metrics and arises\nthroughout many fields of deep metric learning. In this paper, we first show\nhow deep metric learning loss can arise from the Bregman divergence. We then\nintroduce a novel method for learning empirical Bregman divergence directly\nfrom data based on parameterizing the convex function underlying the Bregman\ndivergence with a deep learning setting. We further experimentally show that\nour approach performs effectively on five popular public datasets compared to\nother SOTA deep metric learning methods, particularly for pattern recognition\nproblems.",
  "text": "Learning Empirical Bregman Divergence for\nUncertain Distance Representation\nZhiyuan Li‚àó, Student Member, IEEE, Ziru Liu‚Ä†, Anna Zou‚Ä°, Anca L. Ralescu‚àó, Senior Member, IEEE\n‚àóDepartment of Computer Science, University of Cincinnati\n‚Ä†School of Data Science, City University of Hong Kong\n‚Ä°Directorate for Social, Behavioral and Economic Sciences, National Science Foundation\nAbstract‚ÄîDeep metric learning techniques have been used\nfor visual representation in various supervised and unsupervised\nlearning tasks through learning embeddings of samples with deep\nnetworks. However, classic approaches, which employ a Ô¨Åxed\ndistance metric as a similarity function between two embeddings,\nmay lead to suboptimal performance for capturing the complex\ndata distribution. The Bregman divergence generalizes measures\nof various distance metrics and arises throughout many Ô¨Åelds\nof deep metric learning. In this paper, we Ô¨Årst show how deep\nmetric learning loss can arise from the Bregman divergence. We\nthen introduce a novel method for learning empirical Bregman\ndivergence directly from data based on parameterizing the convex\nfunction underlying the Bregman divergence with a deep learning\nsetting. We further experimentally show that our approach\nperforms effectively on Ô¨Åve popular public datasets compared\nto other SOTA deep metric learning methods, particularly for\npattern recognition problems.\nIndex Terms‚ÄîBregman divergence, distance representation,\ndeep metric learning, visual representation\nI. INTRODUCTION\nDeep metric learning formulates a task-speciÔ¨Åc problem for\nlearning the distance metrics among samples. The learned\ndistance can then be applied to object detection, matching,\nranking, and other machine learning tasks [1]‚Äì[3]. Despite\nthe success and advances of deep metric learning techniques\nacross many applications, selecting the optimal distance met-\nric, or even a general distance metric remains an uncertain task.\nYet the chosen distance metric of the learning loss function\ncan be a key factor in deciding the performance of deep\nlearning models by learning the feature representations within\nthe geometric or probabilistic space [4]. In contrast to previous\nworks, instead of selecting the uncertain distance metric, our\ngoal is to learn a generalized distance metric for deep learning\nclassiÔ¨Åcation using the Bregman divergence [5].\nClassic methods of deep metric learning [6]‚Äì[8] aim to learn\na robust feature representation by training a deep encoder\nover the input space to maximize the distance between similar\nsamples (positive pairs) and minimize the distance between\ndissimilar ones (negative pairs). For example, the Siamese\nCopyright (c) 2023 IEEE. Personal use of this material is permitted.\nPermission from IEEE must be obtained for all other uses, in any current or\nfuture media, including reprinting/republishing this material for advertising or\npromotional purposes, creating new collective works, for resale or redistribu-\ntion to servers or lists, or reuse of any copyrighted component of this work\nin other works.\nContact authors: li3z3@mail.uc.edu (Zhiyuan Li); ralescal@ucmail.uc.edu\n(Anca Ralescu).\nnetwork [6] uses the Euclidean distance to calculate the\ndistance metric between two feature embeddings and employs\na Softmax function to convert the computed distance into a\nprobability to present the similarity score. The Triplet network\n[7], an extended version of the Siamese network, takes a triplet\ninput (anchor, negative and positive) to the deep encoder and\naims to group together anchor and positive samples and push\naway anchor and negative samples. SupCon [8], a supervised\ncontrastive learning approach, utilizes cosine similarity as a\ndistance metric in the loss function for learning the discrim-\ninative features among samples for classiÔ¨Åcation. Contrastive\nlearning methods, such as SupCon [8], Invariant [9], etc., use a\nsimilar idea to deep metric learning but with a self-supervision\napproach. These works can be summarized in two steps: 1)\ntrain an embedding function (neural network) fŒ∏(¬∑) to learn\nthe similarity features among samples with the same labels,\n2) Ô¨Åne-tune the pre-trained embedding function ÀÜfŒ∏(¬∑) for a\nsupervised classiÔ¨Åcation task. Although these methods have\nachieved excellent results in deep learning classiÔ¨Åcation, the\ndistance metrics are manually selected, which may lead to a\nsub-optimal performance during training.\nMore recently, integrating deep metric learning and statisti-\ncal divergence has achieved popularity in the metric learning\narea. One of the most famous statistical divergences, the\nBregman divergence, is generated by a strictly convex and\ncontinuously differentiable function œÜ deÔ¨Åned on a closed\nconvex set [5]. Depending on the selected underlying con-\nvex function, speciÔ¨Åc distance metrics, such as Euclidean or\ncosine similarity, can be generated. For example, the Bregman\ndivergence can be chosen as the well-known Kullback-Leibler\n(KL)-divergence to measure the probabilistic distance between\ntwo inputs where comparison is needed for the distributions.\nHowever, the learning objective still remains uncertain since\nthe standard family of the Bregman divergences may not fully\ncapture the patterns of samples. In deep divergence learning,\nemploying the Bregman divergence as a deep learning setting\ncaptures the nonlinear relationship for learning more gener-\nalizable distance metrics among samples [10]. For example,\nSiahkamari et al. [11] used arbitrary Bregman divergence to\nlearn the underlying divergence function through a piecewise\nlinear approximation approach. Cilingir et al. [10] proposed\ndeep Bregman divergences by formulating the metric learning\ntask into a particular case of symmetric divergences. However,\nthese works use a linear max-afÔ¨Åne function to parameterize\narXiv:2304.07689v3  [cs.CV]  15 May 2023\nœÜ while the nonlinear properties are ignored, and the gradient\nof the learning loss may vanish during the training.\nThis paper introduces a framework to learn the functional\narbitrary Bregman divergence for distance representation with\ndeep metric and contrastive learning styles, which can be\napplied to foundational visual representation tasks. We Ô¨Årst\ninvestigate the relationship between deÔ¨Åned metric learning\nloss and the Bregman divergence. In this setting, we show\nthat for any probability-based similarity measurements us-\ning the Softmax function, their metric learning loss can be\nseen to arise from the Bregman divergence. These included\ndeep metric learning models, i.e., Siamese network, Triplet\nnetwork, supervised contrastive learning, and a typical con-\ntrastive learning model, such as SupCon [8]. We then turn our\nattention to learning a Bregman divergence directly through\nthe deep learning approach. In contrast to previous works on\npre-Ô¨Åxed distance metrics, e.g., the Euclidean distance and\ncosine similarity, the learned Bregman divergence represents\na generalizable solution to effectively capture the similarity\ninformation between samples for various deep metric learning\ntasks. To achieve this, we used the generalized nonlinear mod-\nels (GNMs) to smoothly parameterize the strictly convex and\ncontinuously differentiable function œÜ. Then, a standard deep\nlearning setting is performed to learn the Bregman divergence\nusing the gradient-descent-based algorithm. To evaluate the\nperformance of our proposed approach, we employed two\npublic datasets to show the empirical results that highlight the\neffectiveness of our proposed method. In particular, we showed\nthat learning a Bregman divergence directly through the deep\nlearning setting offers classiÔ¨Åcation performance gains over\nlearning a Ô¨Åxed distance metric. We also showed that the\nlearned distance metrics could capture more complex data\ndistribution than other state-of-the-art (SOTA) methods.\nOur main contributions of this work are summarized as\nfollows: (1) We consider the implicit relationship between\ndeep metric learning and the Bregman divergence by proving\nthat for any deÔ¨Åned metric learning loss, the general distance\nmetric form can arise from the Bregman divergence. (2) We\npresent a novel framework to learn the uncertain Bregman\ndivergence in a deep learning setting. Instead of Ô¨Åxing the\ndistance metric function during training, we employ the GNMs\nto parameterize the generating function œÜ in the Bregman\ndivergence. Our approach, strictly convex and smoothness,\napproximates œÜ arbitrarily well. (3) With theoretical analysis\nand extensive experiments, our approach demonstrates the\neffectiveness of learned empirical distance representation over\nother SOTA methods in deep metric and contrastive learning\nsettings.\nII. RELATED WORK\nIn this section, we Ô¨Årst provide a brief overview of deep\nmetric learning and then discuss the related works of the\nBregman divergence learning.\nDeep Metric Learning: With the popularity of deep learn-\ning techniques, researchers have started to perform metric\nlearning tasks in a deep learning setting [12]. Similar to classic\nmetric learning methods, deep metric learning focuses on\nlearning the similarity relationship among samples using deep\nfeatures (e.g., feature embeddings). In this setting, suppose\nfŒ∏(¬∑) is a function that embeds the sample x into a feature\nembedding fŒ∏(x), a gradient-descent-based optimization al-\ngorithm is employed to iteratively learn the nonlinear distance\nmetric among embedded features fŒ∏(x) and fŒ∏(y). Several\nwell-deÔ¨Åned loss functions, such as contrastive loss [13],\ntriplet loss [7], NCE loss [14], and SupCon loss [8], have been\nproposed to learn discriminative features for classiÔ¨Åcation.\nHowever, all of these loss functions use a Ô¨Åxed distance,\neither Euclidean distance ‚à•fŒ∏(x) ‚àífŒ∏(y)‚à•2 or dot product\nfŒ∏(x)T fŒ∏(y).\nBregman Divergence Learning: Another approach that\ngoes beyond linear metric learning is the Bregman divergence\nlearning framework. The common idea is to generalize the\nlearning distance metric into an arbitrary Bregman diver-\ngence [15]. Here, beyond the linear metric, in the Bregman\ndivergence, more general asymmetric divergence, such as\nthe KL-divergence, Itakura-Satio divergence, and others, are\nalso considered as the nonlinear distance metric, resulting in\nmore robust performance than linear methods. Learning the\nfunctional Bregman divergence is being explored to extend the\nstandard Bregman divergence into a more generalizable form.\nInstead of taking two vectors as input in functional Bregman\ndivergence, here, we compute the divergence between two\nfunctions or probability distributions [16]. The existing works\nof learning functional Bregman divergence can be divided into\ntwo directions: (1) integrate contrastive learning, and Bregman\ndivergence [17], [18], (2) parameterize the generating function\nœÜ of the Bregman divergence using the max-afÔ¨Åne represen-\ntations approach [10], [11]. However, these works have the\nfollowing shortcomings: (1) the implicit connection between\ncontrastive loss and the Bregman divergence is ignored, (2) the\npiecewise linear approximation does not yield the continuously\ndifferentiable (smoothness) property. In our approach, not only\ndo we study the inner connection between contrastive loss and\nthe Bregman divergence but also directly learn the generation\nfunction œÜ directly using a set of smooth GNMs approach.\nIII. LEARNING BREGMAN DIVERGENCE\nIn this section, we Ô¨Årst formally introduce some deÔ¨Ånitions\nand background that will be used throughout the rest of the\npaper. We then turn out attention to learning the Bregman\ndivergences for a deep metric learning task, the main contri-\nbution of our work.\nA. Preliminaries\nBregman Divergence. The Bregman divergence [5] rep-\nresents a general distance metric between two data inputs.\nLet œÜ be a strictly convex and continuously differentiable\nfunction deÔ¨Åned on a closed convex set ‚Ñ¶‚ààRd. The Bregman\ndivergence between two inputs x and y are deÔ¨Åned as\ndœÜ(x, y) = œÜ(x) ‚àíœÜ(y) ‚àí(x ‚àíy)T ‚àáœÜ(y)\n(1)\nwhere ‚àáœÜ(y) is the Ô¨Årst-order derivative of œÜ(y). Examples\nof several well-known distance metrics such as Euclidean\ndistance, KL-divergence, and Itakura-Satio divergence can be\nparameterized to the Bregman divergence form of Eq (1). In\nthis paper, we consider the extended version of the Bregman\ndivergence via functional Bregman divergences.\nFunctional Bregman Divergence. Similar to classic Breg-\nman divergences, a functional Bregman divergence [16] mea-\nsures the distance between two functions (e.g., probability\ndistributions). Given two functions p and q, and a strictly\nconvex function œÜ, the corresponding functional Bregman\ndivergence is deÔ¨Åned by\ndœÜ(p, q) = œÜ(p) ‚àíœÜ(q) ‚àí\nZ\n[p(x) ‚àíq(x)] Œ¥œÜ(q)(x)dx\n(2)\nwhere Œ¥œÜ(q) represents the functional derivative of œÜ at q.\nSame as the classic Bregman divergence, the functional Breg-\nman divergences hold the same properties, such as convexity,\nnon-negativity, linearity, and others.\nConvexity. The Bregman divergence, œÜ is restricted to be\nstrictly convex, which constrains the parameterization of the\nBregman divergence when choosing a œÜ. In this paper, we\nlearn the arbitrary Bregman divergence directly through a deep\nlearning approach and consider learning an optimal œÜ. To\napproach this, we recall the deÔ¨Ånition of strict convexity:\nDeÔ¨Ånition 1. A function f : Rn ‚ÜíR is strictly convex if\nf(Œªx + (1 ‚àíŒª)y) < Œªf(x) + (1 ‚àíŒª)f(y)\n(3)\nwhere ‚àÄx, y, x Ã∏= y, ‚àÄŒª ‚àà(0, 1).\nB. Bregman Divergence View of Deep Metric Learning\nLet D = {xi, yi}N\ni=1 denote the training data, where xi is\nthe sample, and its corresponding label yi, S(i) ‚ààD denotes\nthe set of indices for positive pair samples, i.e., S(i) : {j ‚àà\nŒõ|yi = yj, i Ã∏= j}. Similarly, K(i) ‚ààD : {j ‚ààŒõ|yi Ã∏=\nyj, i Ã∏= j} denotes the indices set for negative pair samples.\nThe probability to recognize xi, xs, s ‚ààS(i) as yi can be\nformulated as\np(yi|xi, xs) =\nexp(zT\ni zs)\nP\nj‚ààŒõ,jÃ∏=i exp(zT\ni zj)\n(4)\nwhere zi, zj ‚ààRd denotes the (i, j)th embeddings extracted\nfrom an encoding function fŒ∏(), such that, zi = fŒ∏(xi). Like-\nwise, the probability of xi, xk, k ‚ààK(i) is being recognized\nas yi can be formulated as\np(yi|xi, xk) =\nexp(zT\ni zk)\nP\nj‚ààŒõ,jÃ∏=i exp(zT\ni zj)\n(5)\nTo learn a representative distance metric, which groups posi-\ntive pairs and pushes away the negative pairs, we need to max-\nimize p(yi|xi, xs) and minimize p(yi|xi, xk), simultaneously.\nThus, the objective function leads to a maximum likelihood\nestimation, which is\n‚Ñìi =\nY\ns‚ààS(i)\nY\nk‚ààK(i)\np(yi|xi, xs) [1 ‚àíp(yi|xi, xk)]\n(6)\nThereby, learning loss is the negative-log-likelihood of ‚Ñìi over\nall the data points indexed by Œõ, which simpliÔ¨Åes ‚Ñìi to\nL = ‚àí\nX\ni‚ààŒõ\n‚à•K(i)‚à•\nX\ns‚ààS(i)\nlog p(yi|xi, xs)\n‚àí\nX\ni‚ààŒõ\n‚à•S(i)‚à•\nX\nk‚ààK(i)\nlog [1 ‚àíp(yi|xi, xk)]\n(7)\nwhere ‚à•S(i)‚à•and ‚à•K(i)‚à•are the sizes of their corresponding\nset.\nProposition 1. For any probability-based distance metric\nbetween two inputs, i.e., d(x, y), with the Softmax function,\nthere exists a general distance form of d(x, y), which arises\nfrom the Bregman divergence.\nProof. Here, we prove the Proposition 1 starting from the\nabove Eq(7). For ‚àílog p(yi|xi, xs), based on the Ô¨Årst-order\nTaylor approximation, we have\n‚àílog p(yi|xi, xs) = log\nP\nj‚ààŒõ,jÃ∏=i exp(zT\ni zj)\nexp(zT\ni zs)\n= log\nÔ£´\nÔ£≠1 +\nX\njÃ∏=i,s\nexp\n\u0002\nzT\ni zj ‚àízT\ni zs\n\u0003\nÔ£∂\nÔ£∏\n‚âà\nX\njÃ∏=i,s\nexp\n\u0000zT\ni zj ‚àízT\ni zs\n\u0001\n‚âà1 +\nX\njÃ∏=i,s\nzT\ni zj ‚àízT\ni zs\n(8)\nNotice that, zT\ni zj = 1‚àí1\n2‚à•zi ‚àízj‚à•2 if ‚à•z‚à•= 1. With œÜ(x) =\n‚à•x‚à•2, the general distance of log p(yi|xi, xs) arises from the\nfunctional Bregman divergence is\nlog p(yi|xi, xs) ‚âà\nX\niÃ∏=s\ndœÜ (fŒ∏(xi), fŒ∏(xs)) ‚àí\nX\njÃ∏=i\ndœÜ (fŒ∏(xi), fŒ∏(xj))\n= Œò (fŒ∏(xi), fŒ∏(xs), fŒ∏(xj))\n(9)\nNext, we turn our attention to p(yi|xi, xk) of Eq (5). Follow-\ning the same approach of Eq (8), the log of p(yi|xi, xk) can\nbe expressed as\nlog p(yi|xi, xk) ‚âà\nX\niÃ∏=k\ndœÜ (fŒ∏(xi), fŒ∏(xk)) ‚àí\nX\njÃ∏=i\ndœÜ (fŒ∏(xi), fŒ∏(xj))\n= Œò (fŒ∏(xi), fŒ∏(xk), fŒ∏(xj))\n(10)\nThus, we formulate the learning loss L of Eq (7) as the Breg-\nman divergences approximation without any scale parameters:\nLdiv ‚âà‚àí\nX\ni‚ààŒõ\n‚à•K(i)‚à•\nX\ns‚ààS(i)\nŒò (fŒ∏(xi), fŒ∏(xs), fŒ∏(xj))\n+\nX\ni‚ààŒõ\n‚à•S(i)‚à•\nX\nk‚ààK(i)\nŒò (fŒ∏(xi), fŒ∏(xk), fŒ∏(xj))\n(11)\nThis yields the initial idea of divergence learning that\nmaximizes\nthe\nfunctional\nBregman\ndivergence\namong\na positive pair Œò (fŒ∏(xi), fŒ∏(xs), fŒ∏(xj)) and minimizes\nŒò (fŒ∏(xi), fŒ∏(xk), fŒ∏(xj)), the functional Bregman divergence\namong a negative pair.\nInput Data \nFeature Extractor\nCat\nDog\nClassification\nDivergence Learning\nCross-Entropy \nLoss ‚ÑíùíÑùíÜ\nDivergence \nLoss ‚ÑíùíÖùíäùíó\n‚ÑíùíÑùíÜ+ ùùÄ‚ÑíùíÖùíäùíó\nSoftmax\nPull\nPush\n0.8\n1\n1\n1\n0\n0\nùíö\n‡∑ùùíö\n0.9\n0.9\n0.2\n0.1\nFC\nFC\n‚Ä¶\nGNMs layer\n‚Ä¶\n1\n2\nm\nSoftplus(ùëß1\nùëëùõΩ1 + ùëè1)\nSoftplus(ùëß2\nùëëùõΩ2 + ùëè2)\nSoftplus(ùëßùëö\nùëëùõΩùëö+ ùëèùëö)\n‚Ä¶\nSplit m-Softplus regressions\nGNMs Layer\nùíõùëë\nùíõùëë\nùëß1\nùëë+1\nùëß2\nùëë+1\nùëßùëö\nùëë+1\n‚Ä¶\nFig. 1.\nThe overview of our proposed framework. We use a pre-trained ResNet18 as the encoder and learn joint tasks of supervised classiÔ¨Åcation and\nBregman divergence learning. We employed a group of generalized nonlinear models (GNMs) with the Softplus function to represent œÜ. The learned distance\nrepresentation will be further used in image classiÔ¨Åcation tasks using a kNN classiÔ¨Åer. (Top branch applies cross-entropy loss for classiÔ¨Åcation while bottom\nbranch applies divergence loss for distance learning.)\nC. Deep Bregman Divergence Learning With GNMs\nParameterization. We consider learning a functional Breg-\nman divergence dœÜ with the deep learning setting. Suppose zd\nis the dth layer output embedding vector, and zd+1 is the target\nembedding, which will be the input for functional Bregman\ndivergence dœÜ. To directly learn dœÜ, one thing that needs to\nbe considered is the convexity property of œÜ. We employ a\nset of generalized nonlinear models to estimate each value of\nzd+1. In this case, all zd+1\ni\n‚ààzd+1 are independent to each\nother. Let Œ≤, b denote the weights and biases, respectively, the\nith expectation value of the zd+1 is\nE(zd+1\ni\n|zd\ni ) = Œ±(zd\ni Œ≤i + bi)\n(12)\nwhere Œ≤i ‚ààŒ≤, bi ‚ààb, and Œ± is a convex link function. Note\nthat our learning loss is a functional Bregman divergence, in\nwhich Œ¥œÜ(q)(x) involves the second derivatives. Similar to\n[18], we employ a Softplus as the parametric link function.\nLemma 1. The Softplus function Œ±(x) = log(1+exp(wx)) is\nstrictly monotonically increasing, strictly convex, and smooth.\nProof. Obviously, the Ô¨Årst and second derivative of Œ±(x) is\nalways positive such that\nd\ndxlog (1 + exp(wx)) = (1 + exp(‚àíwx))‚àí1 ‚àà(0, 1)\nd2\ndx2 log (1 + exp(wx)) =\nw exp(wx)\n(1 + exp(wx))2 ‚àà(0, 1)\n(13)\nThus, Œ±(x) is strictly monotonically increasing, strictly con-\nvex, and smooth.\nProposition 2. The expectation E(zd+1|zd) for (d + 1)th\nlayer of the embedding outputs is also strictly monotonically\nincreasing, strictly convex, and smooth.\nProof. Let Œª ‚àà(0, 1), Œ± : Rd ‚ÜíR denotes a Softplus\nfunction, and g : Rn ‚ÜíRd denotes an afÔ¨Åne function, such\nthat g(z) = zŒ≤ + b. Suppose z1, z2 ‚ààz, we have\ng(Œªz1 + (1 ‚àíŒª)z2) = Œªg(z1) + (1 ‚àíŒª)g(z2)\n(14)\nBy DeÔ¨Ånition 1 and Lemma 1, E = Œ± ‚ó¶g is as:\nE(Œªz1 + (1 ‚àíŒª)z2) = ŒªŒ± (g(z1) + (1 ‚àíŒª)g(z2))\n< ŒªŒ± ‚ó¶g(z1) + (1 ‚àíŒª)Œ± ‚ó¶g(z2)\n= ŒªE(z1) + (1 ‚àíŒª)E(z2)\n(15)\nwhich means that E a strictly convex function. We know\nthat E(z) = log (1 + exp(zŒ≤ + b)), and\n‚àÇ\n‚àÇzE(z), ‚àÇ2\n‚àÇz2 E(z),\nwhich are always positive. Thus, E is strictly monotonically\nincreasing and smooth.\nLearning Algorithm. With the above foundations, we pro-\npose a training algorithm to learn the arbitrary functional Breg-\nman divergence dœÜ for classiÔ¨Åcation in Figure 1. Our approach\nis two-fold: (1) a metric learning task for learning dœÜ among\nsamples from an input batch, (2) a classiÔ¨Åcation task for learn-\ning the label information. SpeciÔ¨Åcally, we directly employ the\ndeÔ¨Åned divergence loss Ldiv in Eq (11) as distance metrics and\ntrain it with a cross-entropy loss Lce jointly. In this case, the\nlearned distance metrics capture more patterns than any pre-\nÔ¨Åxed distance metrics, leading to higher predictive power for\nclassiÔ¨Åcation. Let D = (xi, yi)N\ni=1 denote the training dataset\nwith labels y, a positive pairs set Ds = (xi, xs)N\ni=1, yi = ys,\nnegative pairs set Dk = (xi, xk)N\ni=1, yi Ã∏= yk, a arbitrary\ndeep encoder fŒ∏, where the pseudo-code is summarized in\nAlgorithm 1.\nIV. DATA AND EXPERIMENTS\nA. Dataset\nWe employed Ô¨Åve datasets for image recognition, namely\niChallenge-PM [19], iChallenge-AMD [20], Caltech-UCSD\nBirds (CUB200 dataset) [21], Animal FaceHQ (AFHQ) [22]\nAlgorithm 1 Deep Bregman Divergence Learning for Clas-\nsiÔ¨Åcation Via Joint Training\nRequire: D, Ds, Dk, Ldiv, fŒ∏, and Lce.\nf d\nŒ∏ ‚Üêa dth layer of fŒ∏ for feature extraction\nfor each (xi, xj, yi) ‚ààD, (xi, xs) ‚ààDs, (xixk) ‚ààDk do\nzd\ni , zd\nj , zd\ns, zd\nk ‚Üêf d\nŒ∏ (xi), f d\nŒ∏ (xj), f d\nŒ∏ (xs), f d\nŒ∏ (xk)\nCompute œÜ(zd\ni ), œÜ(zd\nj ), œÜ(zs\ni ), œÜ(zk\nj )\n‚ñ∑Eq (12)\ndœÜ1, dœÜ2, dœÜ3 ‚ÜêdœÜ(zd\ni , zd\nj ), dœÜ(zd\ni , zd\ns), dœÜ(zd\ni , zd\nk)\n‚Ñìdiv ‚ÜêLdiv(dœÜ1, dœÜ2, dœÜ3)\n‚ñ∑Eq (11)\n‚Ñìce ‚ÜêLce(xi, yi)\n‚ñ∑cross-entropy loss\nL‚àó‚Üê‚Ñìce + Œ≥‚Ñìdiv\n‚ñ∑joint training\nL‚àó.backward()\n‚ñ∑perform backpropagation\nend for\nreturn ÀÜfŒ∏\n‚ñ∑the pre-trained fŒ∏\nand Oxford-III Pet [23]. The dataset consists of 1,200 anno-\ntated retinal fundus images from 2 classes, 1,200 color fundus\nimages with 400 ones released with annotations from 2 classes,\n11,788 bird images from 200 classes, 16,130 animal images\nfrom 3 classes, and 7,349 from 2 classes, respectively. To\nprovide the advantage of our approach in small-size samples,\nwe randomly selected 300 and 1000 images from the AFHQ\nand the Oxford-III pet with an equal ratio of each class,\nrespectively,\nB. Implementation Details\nAs shown in Figure 1, our approach is built on a network\nbackbone, i.e., pre-trained ResNet18 [24], with the same\nsetting in our previous study [25], [26] for feature extraction.\nWith the output of ResNet18, f, is then connected to a Multi-\nLayer Perceptron (MLP) layer, followed by batch normaliza-\ntion and a RectiÔ¨Åed Linear Unit (ReLU) activation function.\nThe output of this process is reduced feature dimension to 128,\ndenoted as z. For the classiÔ¨Åcation branch, z is connected\nto a Softmax and cross-entropy loss Lce with labels. For\nthe divergence learning task, z is input to a L2 norm layer,\nresulting in ‚à•z‚à•= 1, and sequentially followed by a GNMs\nlayer fused with k-Softplus regression outputs. Furthermore, a\ndivergence metric loss Ldiv is employed to learn the arbitrary\nBregman divergence. To test the learned Bregman divergence,\nwe applied the kNN classiÔ¨Åer based on z, in which we set\nk = 50 empirically. We randomly resized each image within\na range of 0.3 to 1.0 for each batch size. The batch size was\nset to 32, and the model optimization was performed using\nthe Adam optimizer. We set the learning rate and weight\ndecay to 0.0001 and trained the whole framework for 2000\nepochs. To evaluate the model, we used accuracy and the Area\nUnder the Receiver Operating Characteristic (ROC) curve\n(AUC). Following standard practice, we used 10-fold cross-\nvalidation to evaluate each competing method. In addition, we\nconducted a non-parametric Wilcoxon test with a signiÔ¨Åcance\nlevel of 0.05 for all statistical inferences using R-studio. The\nframework was implemented using python 3.8, Scikit-Learn\n0.24.1, Pytorch 1.9.1, and Cuda 11.1 on a NVIDIA GeForce\nGTX 1660 SUPER GPU.\nC. Competing State-of-The-Art Methods\nWe compared our approach with other SOTA methods\nacross the deep metric learning and contrastive learning, in-\ncluding Siamese network [6], Triplet network [7], N-pair [27],\nSupCon [8], GHM [25], PDBL [11], and DeepDiv [10] using\ntheir released code on GitHub. A supervised learning baseline\nwas also included by modifying the last fully connected layer\nof ResNet18 to match the number of classes with a cross-\nentropy loss for classiÔ¨Åcation. To ensure fairness, all methods\nwere trained with the same feature extractor (e.g., ResNet18)\nwith consistent hyperparameters, learning rate, batch size, and\noptimizer. We Ô¨Åxed the classiÔ¨Åcation branch and replaced the\ndivergence learning branch. To show the effectiveness of Breg-\nman divergence, we replaced the similarity functions (cosine\nsimilarity, Euclidean distance) with the Bregman divergence\nin the SOTA methods to perform metrics comparison.\n1) Quantitative Results: To demonstrate the promise of the\nproposed method, we performed image classiÔ¨Åcation tasks\non Ô¨Åve datasets and compared the prediction performance\nof our approach with other SOTA methods. The results are\nshown in Table I. Our approach signiÔ¨Åcantly outperforms\nthe other SOTA methods with higher overall accuracy and\nAUC. The results of the iChallenge-PM dataset indicate that\nall methods can achieve over 95% accuracy and AUC, demon-\nstrating the feasibility of identifying pathological myopia from\ncolor fundus images. However, the performance drops for all\nmethods on the iChallenge-AMD dataset due to insufÔ¨Åcient\nannotated samples. For the CUB200 dataset, even though the\ndataset contains a large number of samples, the classiÔ¨Åcation\nperformance achieved similar results as the iChallenge-AMD\ndataset since the bird patterns are harder to detect, making\nthe classiÔ¨Åcation task more difÔ¨Åcult challenging. Our approach\noutperforms other SOTA methods, showing the effectiveness\nof learned Bregman divergence for image recognition tasks.\n2) Model Generalizability: To prove the generalizability of\nour proposed method, we Ô¨Årst compared our approach with\nother SOTA methods on the AFHQ dataset and saved each pre-\ntrained model. Since AFHQ and Oxford-III Pet contain cat and\ndog classes, we employed Oxford-III Pet as an independent\nexternal dataset and evaluated model generalizability using\nthe pre-trained models. The results are shown in the last\ntwo columns of Table I. Our approach achieved overall\nclassiÔ¨Åcation performance with more precise accuracy and\nAUC on internal validations using the AFHQ dataset and\nexternal validation using the Oxford-III Pet dataset. In this\nway, we presented the generalization capabilities of learned\nempirical Bregman divergence of our proposed method for\nimage classiÔ¨Åcation.\nD. Ablation Study\n1) Impact of Divergence Learning Loss: Our learning ob-\njective is a linear combination of two loss functions, i.e., Lce\nand Ldiv. Here, we analyzed the importance of the divergence\nloss Ldiv by training our approach with different Œ≥ using the\niChallenge-AMD dataset, in which Œ≥ indicates a weighting\nfactor of Ldiv. The results are demonstrated in Figure 3.\nTABLE I\nCOMPETING FOR SOTA DEEP METRIC LEARNING AND CONTRASTIVE LEARNING METHODS ON FIVE SELECTED DATASETS (UNIT: %). RESNET18 IS\nEMPLOYED AS A NETWORK ENCODER FOR FEATURE EXTRACTION\niChallenge-PM\niChallenge-AMD\nCUB200\nAFHQ\nOxford-III Pet\nSOTAs\nAccuracy\nAUC\nAccuracy\nAUC\nAccuracy\nAUC\nAccuracy\nAUC\nAccuracy\nAUC\nBaseline [24]\n95.45\n96.01\n84.14\n76.51\n71.02\n69.14\n76.42\n75.54\n77.50\n78.24\nSiamese [6]\n95.12\n97.21\n78.14\n69.45\n77.14\n73.45\n80.25\n82.64\n85.12\n84.54\nTriplet [7]\n95.12\n97.21\n80.18\n70.28\n80.14\n75.65\n83.36\n84.45\n85.50\n84.47\nN-pair [27]\n96.45\n94.38\n85.12\n74.54\n82.14\n79.45\n78.98\n81.25\n81.65\n80.22\nSupCon [8]\n98.22\n98.06\n85.64\n73.24\n81.45\n78.46\n82.87\n79.69\n86.20\n82.84\nGHM [25]\n95.24\n95.36\n82.47\n72.58\n79.45\n77.41\n81.54\n79.65\n82.41\n83.10\nPDBL [11]\n98.57\n98.42\n85.04\n78.69\n80.47\n80.14\n84.12\n84.74\n85.50\n85.10\nDeepDiv [10]\n97.25\n98.05\n86.51\n73.65\n83.47\n80.87\n82.05\n81.25\n81.10\n78.65\nOurs\n99.12\n98.14\n87.45\n80.17\n82.53\n82.49\n85.45\n86.03\n88.20\n89.35\nFig. 2. Training model on the iChallenge-AMD using different Œ≥ of L‚àóin\nAlgorithm 1. We achieved the best accuracy and AUC when Œ≥ = 1.0.\nWe found that when Œ≥ = 0.0, the network is equivalent to\na supervised baseline method with 84.14% on accuracy and\n76.51% on AUC. As Œ≥ increases, the performance improves\nand reaches the best performance when Œ≥ = 1.0. This shows\nthat the classiÔ¨Åcation and divergence learning branches con-\ntribute equally to diagnosing age-related macular degeneration\n(AMD).\n2) Quality Representations: To verify the effectiveness of\nthe learned feature representation of our approach, we use t-\nSNE to represent the last fully connected layer after CNN.\nAs shown in Figure 3, we compared our approach with other\nSOTA metric learning and divergence learning methods on the\n1000 testing AFHQ dataset. It is observed that our approach\ndemonstrates a more precise decision boundary between the\ntwo classes. These results further show that learning the\nempirical Bregman divergence provides a better solution to\ncapture the discriminative patterns.\n3) Feature Visualization: We compared our approach to\nTriplet Network [7] and Deep Divergence Learning [10] by\nshowing the feature attention maps of the last ResNet18 block\n(Figure 4). We randomly selected seven input images from\nAFHQ, Oxford-III pet, and CUB200 datasets. We applied\nGrad-CAM [28] to localize the discriminative patterns by\npointwise multiplying the attention map with backpropagation\ncorresponding to image classiÔ¨Åcation. This visualization sug-\ngests the attention to various image patterns in each model for\nOurs\nDeepDiv\nTriplet\nSupCon\nFig. 3.\nt-SNE visualization of learned embeddings from ResNet18 on the\nAFHQ dataset. Our approach precisely captures the decision boundary for\nseparating two classes.\nclassiÔ¨Åcation. Compared to other SOTA methods, our approach\nlearns the empirical Bregman divergence that can help the\nnetwork focus on the correction positions of images in terms of\nlearning a more robust feature representation for classiÔ¨Åcation.\n4) Metrics Comparison: This section shows the advantage\nof learned Bregman divergence for capturing complex sim-\nilarity using synthetic examples where existing approaches\nwould fail. Assuming the relationship between two embedding\npresents a complex distribution, i.e., a random nonlinear\ncorrelation. We split the synthetic dataset into a supporting\nset and a query set, in which we train a Siamese network\nusing the supporting set and apply the pre-trained network\nto match the query set. Figure 5 shows each sample input\nGround \nTruth\nTriplet \nNetwork\nDeepDiv\nOurs\nFig. 4. Feature visualization with different SOTA methods on three datasets (AFHQ, Oxford-III pet, and CUB200) using GradCAM. The more discriminative\npatterns of images indicate the high attention scores of the heatmap. Our approach captures more patterns than other methods, resulting in better classiÔ¨Åcation\nperformance.\n(pixel) is highlighted if it matches the query input. We com-\npared empirical Bregman divergence with other Ô¨Åxed distance\nfunctions in this setting, including cosine similarity and KL-\ndivergence. As we can see, the learned Bregman divergence\ncaptures the best representation of nonlinear similarity among\ntwo embeddings. At the same time, other distances are not\ndiscriminative enough to capture the basic patterns under this\ncomplex distribution.\n5) Effects of the Number of m-Softplus Regressions: Our\nproposed method contains m-Softplus regression of the GNM\nlayer for parameterizing the convex function œÜ of the Bregman\ndivergence. Here, we study the effects of different m on\nclassiÔ¨Åcation performance. To assess it, we train our model\nwith different m and then compare the performance on the\ndatasets of the iChallenge-AMD, CUB200, and AFHQ. The\nresults are shown in Figure 6. We can see that performance\nfor all datasets increases until m = 150, then drops. We also\nobserved a similar phenomenon in [17].\nV. DISCUSSION AND FUTURE WORK\nLearning a representative distance is vital in visual represen-\ntation for enhancing machine vision and pattern recognition.\nThe learned distance representation can be further applied to\nvarious downstream tasks, including classiÔ¨Åcation, clustering,\nand object detection. With the advances in deep learning\ntechniques, deep metric learning has been widely used in the\nvisual representation, and machine intelligence community [1],\n[2], [29]. Besides promising evidence from previous studies\n[6]‚Äì[8], classic deep metric learning employed Ô¨Åxed distance\nmetrics as the similarity function during the training, resulting\nin ignoring natural data distribution. Across probability theory\nand information science, the Bregman divergence uses a\nGround Truth\nCosine Similarity\nJS-Divergence\nOurs\nFig. 5.\nThe synthetic example showing learned Bregman divergence can\ncapture more complex distribution on a matching. Each color pixel indicates\nthe correct matched case from the supporting and query sets.\nstrictly convex function to represent a general distance metric,\nwhich provides a potential solution to address the challenge\nof arbitrary distance selection. This work Ô¨Årst proves the\nequivalent relationship between a general metric learning loss\nand the Bregman divergence. We then present a novel approach\nto learn the empirical Bregman divergence by parameterizing\nFig. 6. The importance of increasing Softplus regressions (m) on accuracy\n(%): We train our model with different m on the iChallenge-AMD, CUB200,\nand AFHQ datasets. The performance reaches best when m = 150, then\ndrops down because of over-parameterization.\na convex function between two feature embeddings in a deep\nmetric learning style. Unlike previous works, our approach\ndirectly learns an optimal distance representation from data,\nshowing practical advances for complex sample distributions.\nCompared to other SOTA methods, our approach consistently\nachieves promising results on Ô¨Åve public datasets, which\nshows the supervisor of the learned distance representation. In\naddition to performance evaluation with other SOTA methods,\nextensive ablation studies are provided to further prove our\napproach‚Äôs effectiveness.\nAlthough our approach outperforms other SOTA methods,\nit still comes with limitations. First, we only study learning\na Bregman divergence in a supervised manner, which relies\non a more signiÔ¨Åcant number of annotated training samples\nand requires expensive human effort. Secondly, our approach\nemploys a GNM layer, which may be computationally costly if\nm is large. In the future, we will investigate learning empirical\nBregman divergence in an unsupervised or self-supervised\nlearning style and study a more efÔ¨Åcient alternative approach.\nVI. ACKNOWLEDGEMENT\nProfessor Anca Ralescu would like to thank Professor\nShun‚Äôichi Amari who Ô¨Årst mentioned the Bregman divergence\nto her.\nREFERENCES\n[1] O. Mees, N. Abdo, M. Mazuran, and W. Burgard, ‚ÄúMetric learning\nfor generalizing spatial relations to new objects,‚Äù in 2017 IEEE/RSJ\nInternational Conference on Intelligent Robots and Systems (IROS).\nIEEE, 2017, pp. 3175‚Äì3182.\n[2] B. J. Meyer and T. Drummond, ‚ÄúThe importance of metric learning\nfor robotic vision: Open set recognition and active learning,‚Äù in 2019\nInternational Conference on Robotics and Automation (ICRA).\nIEEE,\n2019, pp. 2924‚Äì2931.\n[3] M. Rezayati, G. Zanni, Y. Zaoshi, D. Scaramuzza, and H. W. van de\nVenn, ‚ÄúImproving safety in physical human-robot collaboration via\ndeep metric learning,‚Äù in 2022 IEEE 27th International Conference on\nEmerging Technologies and Factory Automation (ETFA).\nIEEE, 2022,\npp. 1‚Äì8.\n[4] A. Bellet, A. Habrard, and M. Sebban, Metric learning.\nMorgan &\nClaypool Publishers, 2015.\n[5] L. M. Bregman, ‚ÄúThe relaxation method of Ô¨Ånding the common point\nof convex sets and its application to the solution of problems in convex\nprogramming,‚Äù USSR computational mathematics and mathematical\nphysics, vol. 7, no. 3, pp. 200‚Äì217, 1967.\n[6] G. Koch, R. Zemel, R. Salakhutdinov et al., ‚ÄúSiamese neural networks\nfor one-shot image recognition,‚Äù in ICML deep learning workshop,\nvol. 2.\nLille, 2015, p. 0.\n[7] E. Hoffer and N. Ailon, ‚ÄúDeep metric learning using triplet network,‚Äù\nin International workshop on similarity-based pattern recognition.\nSpringer, 2015, pp. 84‚Äì92.\n[8] P. Khosla et al., ‚ÄúSupervised contrastive learning,‚Äù Advances in Neural\nInformation Processing Systems, vol. 33, pp. 18 661‚Äì18 673, 2020.\n[9] M. Ye, X. Zhang, P. C. Yuen, and S.-F. Chang, ‚ÄúUnsupervised em-\nbedding learning via invariant and spreading instance feature,‚Äù in Pro-\nceedings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 2019, pp. 6210‚Äì6219.\n[10] H. K. Cilingir, R. Manzelli, and B. Kulis, ‚ÄúDeep divergence learning,‚Äù\nin International Conference on Machine Learning.\nPMLR, 2020, pp.\n2027‚Äì2037.\n[11] A. Siahkamari, X. Xia, V. Saligrama, D. CastaÀún¬¥on, and B. Kulis,\n‚ÄúLearning to approximate a bregman divergence,‚Äù Advances in Neural\nInformation Processing Systems, vol. 33, pp. 3603‚Äì3612, 2020.\n[12] M. Kaya and H. S¬∏. Bilge, ‚ÄúDeep metric learning: A survey,‚Äù Symmetry,\nvol. 11, no. 9, p. 1066, 2019.\n[13] S. Chopra, R. Hadsell, and Y. LeCun, ‚ÄúLearning a similarity metric\ndiscriminatively, with application to face veriÔ¨Åcation,‚Äù in 2005 IEEE\nComputer Society Conference on Computer Vision and Pattern Recog-\nnition (CVPR‚Äô05), vol. 1.\nIEEE, 2005, pp. 539‚Äì546.\n[14] M. Gutmann and A. Hyv¬®arinen, ‚ÄúNoise-contrastive estimation: A new\nestimation principle for unnormalized statistical models,‚Äù in Proceedings\nof the thirteenth international conference on artiÔ¨Åcial intelligence and\nstatistics.\nJMLR Workshop and Conference Proceedings, 2010, pp.\n297‚Äì304.\n[15] A. Banerjee, S. Merugu, I. S. Dhillon, J. Ghosh, and J. Lafferty,\n‚ÄúClustering with bregman divergences.‚Äù Journal of machine learning\nresearch, vol. 6, no. 10, 2005.\n[16] B. A. Frigyik, S. Srivastava, and M. R. Gupta, ‚ÄúFunctional bregman\ndivergence and bayesian estimation of distributions,‚Äù IEEE Transactions\non Information Theory, vol. 54, no. 11, pp. 5130‚Äì5139, 2008.\n[17] M. Rezaei, F. Soleymani, B. Bischl, and S. Azizi, ‚ÄúDeep bregman\ndivergence for contrastive learning of visual representations,‚Äù arXiv\npreprint arXiv:2109.07455, 2021.\n[18] F. Lu, E. Raff, and F. Ferraro, ‚ÄúNeural bregman divergences for distance\nlearning,‚Äù arXiv preprint arXiv:2206.04763, 2022.\n[19] H. Fu et al., ‚ÄúPalm: Pathologic myopia challenge,‚Äù IEEE Dataport, 2019.\n[20] H. Fang et al., ‚ÄúAdam challenge: Detecting age-related macular degen-\neration from fundus images,‚Äù IEEE Transactions on Medical Imaging,\n2022.\n[21] P. Welinder et al., ‚ÄúCaltech-ucsd birds 200,‚Äù California Institute of\nTechnology, 2010.\n[22] Y. Choi, Y. Uh, J. Yoo, and J.-W. Ha, ‚ÄúStargan v2: Diverse image\nsynthesis for multiple domains,‚Äù in Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition, 2020, pp. 8188‚Äì\n8197.\n[23] O. M. Parkhi, A. Vedaldi, A. Zisserman, and C. Jawahar, ‚ÄúCats and\ndogs,‚Äù in 2012 IEEE conference on computer vision and pattern recog-\nnition.\nIEEE, 2012, pp. 3498‚Äì3505.\n[24] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDeep residual learning for image\nrecognition,‚Äù in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770‚Äì778.\n[25] Z. Li and A. Ralescu, ‚ÄúLearning generalized hybrid proximity represen-\ntation for image recognition,‚Äù arXiv preprint arXiv:2301.13459, 2023.\n[26] Z. Li, H. Li, A. L. Ralescu, J. R. Dillman, N. A. Parikh, and L. He, ‚ÄúA\nnovel collaborative self-supervised learning method for radiomic data,‚Äù\narXiv preprint arXiv:2302.09807, 2023.\n[27] K. Sohn, ‚ÄúImproved deep metric learning with multi-class n-pair loss\nobjective,‚Äù Advances in neural information processing systems, vol. 29,\n2016.\n[28] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and\nD. Batra, ‚ÄúGrad-cam: Visual explanations from deep networks via\ngradient-based localization,‚Äù in Proceedings of the IEEE international\nconference on computer vision, 2017, pp. 618‚Äì626.\n[29] Z. Li and J. Tang, ‚ÄúWeakly supervised deep metric learning for\ncommunity-contributed image retrieval,‚Äù IEEE Transactions on Multi-\nmedia, vol. 17, no. 11, pp. 1989‚Äì1999, 2015.\n",
  "categories": [
    "cs.CV",
    "cs.AI",
    "cs.IT",
    "cs.LG",
    "math.IT",
    "stat.ML"
  ],
  "published": "2023-04-16",
  "updated": "2023-05-15"
}