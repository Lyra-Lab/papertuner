{
  "id": "http://arxiv.org/abs/2304.07689v3",
  "title": "Learning Empirical Bregman Divergence for Uncertain Distance Representation",
  "authors": [
    "Zhiyuan Li",
    "Ziru Liu",
    "Anna Zou",
    "Anca L. Ralescu"
  ],
  "abstract": "Deep metric learning techniques have been used for visual representation in\nvarious supervised and unsupervised learning tasks through learning embeddings\nof samples with deep networks. However, classic approaches, which employ a\nfixed distance metric as a similarity function between two embeddings, may lead\nto suboptimal performance for capturing the complex data distribution. The\nBregman divergence generalizes measures of various distance metrics and arises\nthroughout many fields of deep metric learning. In this paper, we first show\nhow deep metric learning loss can arise from the Bregman divergence. We then\nintroduce a novel method for learning empirical Bregman divergence directly\nfrom data based on parameterizing the convex function underlying the Bregman\ndivergence with a deep learning setting. We further experimentally show that\nour approach performs effectively on five popular public datasets compared to\nother SOTA deep metric learning methods, particularly for pattern recognition\nproblems.",
  "text": "Learning Empirical Bregman Divergence for\nUncertain Distance Representation\nZhiyuan Li∗, Student Member, IEEE, Ziru Liu†, Anna Zou‡, Anca L. Ralescu∗, Senior Member, IEEE\n∗Department of Computer Science, University of Cincinnati\n†School of Data Science, City University of Hong Kong\n‡Directorate for Social, Behavioral and Economic Sciences, National Science Foundation\nAbstract—Deep metric learning techniques have been used\nfor visual representation in various supervised and unsupervised\nlearning tasks through learning embeddings of samples with deep\nnetworks. However, classic approaches, which employ a ﬁxed\ndistance metric as a similarity function between two embeddings,\nmay lead to suboptimal performance for capturing the complex\ndata distribution. The Bregman divergence generalizes measures\nof various distance metrics and arises throughout many ﬁelds\nof deep metric learning. In this paper, we ﬁrst show how deep\nmetric learning loss can arise from the Bregman divergence. We\nthen introduce a novel method for learning empirical Bregman\ndivergence directly from data based on parameterizing the convex\nfunction underlying the Bregman divergence with a deep learning\nsetting. We further experimentally show that our approach\nperforms effectively on ﬁve popular public datasets compared\nto other SOTA deep metric learning methods, particularly for\npattern recognition problems.\nIndex Terms—Bregman divergence, distance representation,\ndeep metric learning, visual representation\nI. INTRODUCTION\nDeep metric learning formulates a task-speciﬁc problem for\nlearning the distance metrics among samples. The learned\ndistance can then be applied to object detection, matching,\nranking, and other machine learning tasks [1]–[3]. Despite\nthe success and advances of deep metric learning techniques\nacross many applications, selecting the optimal distance met-\nric, or even a general distance metric remains an uncertain task.\nYet the chosen distance metric of the learning loss function\ncan be a key factor in deciding the performance of deep\nlearning models by learning the feature representations within\nthe geometric or probabilistic space [4]. In contrast to previous\nworks, instead of selecting the uncertain distance metric, our\ngoal is to learn a generalized distance metric for deep learning\nclassiﬁcation using the Bregman divergence [5].\nClassic methods of deep metric learning [6]–[8] aim to learn\na robust feature representation by training a deep encoder\nover the input space to maximize the distance between similar\nsamples (positive pairs) and minimize the distance between\ndissimilar ones (negative pairs). For example, the Siamese\nCopyright (c) 2023 IEEE. Personal use of this material is permitted.\nPermission from IEEE must be obtained for all other uses, in any current or\nfuture media, including reprinting/republishing this material for advertising or\npromotional purposes, creating new collective works, for resale or redistribu-\ntion to servers or lists, or reuse of any copyrighted component of this work\nin other works.\nContact authors: li3z3@mail.uc.edu (Zhiyuan Li); ralescal@ucmail.uc.edu\n(Anca Ralescu).\nnetwork [6] uses the Euclidean distance to calculate the\ndistance metric between two feature embeddings and employs\na Softmax function to convert the computed distance into a\nprobability to present the similarity score. The Triplet network\n[7], an extended version of the Siamese network, takes a triplet\ninput (anchor, negative and positive) to the deep encoder and\naims to group together anchor and positive samples and push\naway anchor and negative samples. SupCon [8], a supervised\ncontrastive learning approach, utilizes cosine similarity as a\ndistance metric in the loss function for learning the discrim-\ninative features among samples for classiﬁcation. Contrastive\nlearning methods, such as SupCon [8], Invariant [9], etc., use a\nsimilar idea to deep metric learning but with a self-supervision\napproach. These works can be summarized in two steps: 1)\ntrain an embedding function (neural network) fθ(·) to learn\nthe similarity features among samples with the same labels,\n2) ﬁne-tune the pre-trained embedding function ˆfθ(·) for a\nsupervised classiﬁcation task. Although these methods have\nachieved excellent results in deep learning classiﬁcation, the\ndistance metrics are manually selected, which may lead to a\nsub-optimal performance during training.\nMore recently, integrating deep metric learning and statisti-\ncal divergence has achieved popularity in the metric learning\narea. One of the most famous statistical divergences, the\nBregman divergence, is generated by a strictly convex and\ncontinuously differentiable function φ deﬁned on a closed\nconvex set [5]. Depending on the selected underlying con-\nvex function, speciﬁc distance metrics, such as Euclidean or\ncosine similarity, can be generated. For example, the Bregman\ndivergence can be chosen as the well-known Kullback-Leibler\n(KL)-divergence to measure the probabilistic distance between\ntwo inputs where comparison is needed for the distributions.\nHowever, the learning objective still remains uncertain since\nthe standard family of the Bregman divergences may not fully\ncapture the patterns of samples. In deep divergence learning,\nemploying the Bregman divergence as a deep learning setting\ncaptures the nonlinear relationship for learning more gener-\nalizable distance metrics among samples [10]. For example,\nSiahkamari et al. [11] used arbitrary Bregman divergence to\nlearn the underlying divergence function through a piecewise\nlinear approximation approach. Cilingir et al. [10] proposed\ndeep Bregman divergences by formulating the metric learning\ntask into a particular case of symmetric divergences. However,\nthese works use a linear max-afﬁne function to parameterize\narXiv:2304.07689v3  [cs.CV]  15 May 2023\nφ while the nonlinear properties are ignored, and the gradient\nof the learning loss may vanish during the training.\nThis paper introduces a framework to learn the functional\narbitrary Bregman divergence for distance representation with\ndeep metric and contrastive learning styles, which can be\napplied to foundational visual representation tasks. We ﬁrst\ninvestigate the relationship between deﬁned metric learning\nloss and the Bregman divergence. In this setting, we show\nthat for any probability-based similarity measurements us-\ning the Softmax function, their metric learning loss can be\nseen to arise from the Bregman divergence. These included\ndeep metric learning models, i.e., Siamese network, Triplet\nnetwork, supervised contrastive learning, and a typical con-\ntrastive learning model, such as SupCon [8]. We then turn our\nattention to learning a Bregman divergence directly through\nthe deep learning approach. In contrast to previous works on\npre-ﬁxed distance metrics, e.g., the Euclidean distance and\ncosine similarity, the learned Bregman divergence represents\na generalizable solution to effectively capture the similarity\ninformation between samples for various deep metric learning\ntasks. To achieve this, we used the generalized nonlinear mod-\nels (GNMs) to smoothly parameterize the strictly convex and\ncontinuously differentiable function φ. Then, a standard deep\nlearning setting is performed to learn the Bregman divergence\nusing the gradient-descent-based algorithm. To evaluate the\nperformance of our proposed approach, we employed two\npublic datasets to show the empirical results that highlight the\neffectiveness of our proposed method. In particular, we showed\nthat learning a Bregman divergence directly through the deep\nlearning setting offers classiﬁcation performance gains over\nlearning a ﬁxed distance metric. We also showed that the\nlearned distance metrics could capture more complex data\ndistribution than other state-of-the-art (SOTA) methods.\nOur main contributions of this work are summarized as\nfollows: (1) We consider the implicit relationship between\ndeep metric learning and the Bregman divergence by proving\nthat for any deﬁned metric learning loss, the general distance\nmetric form can arise from the Bregman divergence. (2) We\npresent a novel framework to learn the uncertain Bregman\ndivergence in a deep learning setting. Instead of ﬁxing the\ndistance metric function during training, we employ the GNMs\nto parameterize the generating function φ in the Bregman\ndivergence. Our approach, strictly convex and smoothness,\napproximates φ arbitrarily well. (3) With theoretical analysis\nand extensive experiments, our approach demonstrates the\neffectiveness of learned empirical distance representation over\nother SOTA methods in deep metric and contrastive learning\nsettings.\nII. RELATED WORK\nIn this section, we ﬁrst provide a brief overview of deep\nmetric learning and then discuss the related works of the\nBregman divergence learning.\nDeep Metric Learning: With the popularity of deep learn-\ning techniques, researchers have started to perform metric\nlearning tasks in a deep learning setting [12]. Similar to classic\nmetric learning methods, deep metric learning focuses on\nlearning the similarity relationship among samples using deep\nfeatures (e.g., feature embeddings). In this setting, suppose\nfθ(·) is a function that embeds the sample x into a feature\nembedding fθ(x), a gradient-descent-based optimization al-\ngorithm is employed to iteratively learn the nonlinear distance\nmetric among embedded features fθ(x) and fθ(y). Several\nwell-deﬁned loss functions, such as contrastive loss [13],\ntriplet loss [7], NCE loss [14], and SupCon loss [8], have been\nproposed to learn discriminative features for classiﬁcation.\nHowever, all of these loss functions use a ﬁxed distance,\neither Euclidean distance ∥fθ(x) −fθ(y)∥2 or dot product\nfθ(x)T fθ(y).\nBregman Divergence Learning: Another approach that\ngoes beyond linear metric learning is the Bregman divergence\nlearning framework. The common idea is to generalize the\nlearning distance metric into an arbitrary Bregman diver-\ngence [15]. Here, beyond the linear metric, in the Bregman\ndivergence, more general asymmetric divergence, such as\nthe KL-divergence, Itakura-Satio divergence, and others, are\nalso considered as the nonlinear distance metric, resulting in\nmore robust performance than linear methods. Learning the\nfunctional Bregman divergence is being explored to extend the\nstandard Bregman divergence into a more generalizable form.\nInstead of taking two vectors as input in functional Bregman\ndivergence, here, we compute the divergence between two\nfunctions or probability distributions [16]. The existing works\nof learning functional Bregman divergence can be divided into\ntwo directions: (1) integrate contrastive learning, and Bregman\ndivergence [17], [18], (2) parameterize the generating function\nφ of the Bregman divergence using the max-afﬁne represen-\ntations approach [10], [11]. However, these works have the\nfollowing shortcomings: (1) the implicit connection between\ncontrastive loss and the Bregman divergence is ignored, (2) the\npiecewise linear approximation does not yield the continuously\ndifferentiable (smoothness) property. In our approach, not only\ndo we study the inner connection between contrastive loss and\nthe Bregman divergence but also directly learn the generation\nfunction φ directly using a set of smooth GNMs approach.\nIII. LEARNING BREGMAN DIVERGENCE\nIn this section, we ﬁrst formally introduce some deﬁnitions\nand background that will be used throughout the rest of the\npaper. We then turn out attention to learning the Bregman\ndivergences for a deep metric learning task, the main contri-\nbution of our work.\nA. Preliminaries\nBregman Divergence. The Bregman divergence [5] rep-\nresents a general distance metric between two data inputs.\nLet φ be a strictly convex and continuously differentiable\nfunction deﬁned on a closed convex set Ω∈Rd. The Bregman\ndivergence between two inputs x and y are deﬁned as\ndφ(x, y) = φ(x) −φ(y) −(x −y)T ∇φ(y)\n(1)\nwhere ∇φ(y) is the ﬁrst-order derivative of φ(y). Examples\nof several well-known distance metrics such as Euclidean\ndistance, KL-divergence, and Itakura-Satio divergence can be\nparameterized to the Bregman divergence form of Eq (1). In\nthis paper, we consider the extended version of the Bregman\ndivergence via functional Bregman divergences.\nFunctional Bregman Divergence. Similar to classic Breg-\nman divergences, a functional Bregman divergence [16] mea-\nsures the distance between two functions (e.g., probability\ndistributions). Given two functions p and q, and a strictly\nconvex function φ, the corresponding functional Bregman\ndivergence is deﬁned by\ndφ(p, q) = φ(p) −φ(q) −\nZ\n[p(x) −q(x)] δφ(q)(x)dx\n(2)\nwhere δφ(q) represents the functional derivative of φ at q.\nSame as the classic Bregman divergence, the functional Breg-\nman divergences hold the same properties, such as convexity,\nnon-negativity, linearity, and others.\nConvexity. The Bregman divergence, φ is restricted to be\nstrictly convex, which constrains the parameterization of the\nBregman divergence when choosing a φ. In this paper, we\nlearn the arbitrary Bregman divergence directly through a deep\nlearning approach and consider learning an optimal φ. To\napproach this, we recall the deﬁnition of strict convexity:\nDeﬁnition 1. A function f : Rn →R is strictly convex if\nf(λx + (1 −λ)y) < λf(x) + (1 −λ)f(y)\n(3)\nwhere ∀x, y, x ̸= y, ∀λ ∈(0, 1).\nB. Bregman Divergence View of Deep Metric Learning\nLet D = {xi, yi}N\ni=1 denote the training data, where xi is\nthe sample, and its corresponding label yi, S(i) ∈D denotes\nthe set of indices for positive pair samples, i.e., S(i) : {j ∈\nΛ|yi = yj, i ̸= j}. Similarly, K(i) ∈D : {j ∈Λ|yi ̸=\nyj, i ̸= j} denotes the indices set for negative pair samples.\nThe probability to recognize xi, xs, s ∈S(i) as yi can be\nformulated as\np(yi|xi, xs) =\nexp(zT\ni zs)\nP\nj∈Λ,j̸=i exp(zT\ni zj)\n(4)\nwhere zi, zj ∈Rd denotes the (i, j)th embeddings extracted\nfrom an encoding function fθ(), such that, zi = fθ(xi). Like-\nwise, the probability of xi, xk, k ∈K(i) is being recognized\nas yi can be formulated as\np(yi|xi, xk) =\nexp(zT\ni zk)\nP\nj∈Λ,j̸=i exp(zT\ni zj)\n(5)\nTo learn a representative distance metric, which groups posi-\ntive pairs and pushes away the negative pairs, we need to max-\nimize p(yi|xi, xs) and minimize p(yi|xi, xk), simultaneously.\nThus, the objective function leads to a maximum likelihood\nestimation, which is\nℓi =\nY\ns∈S(i)\nY\nk∈K(i)\np(yi|xi, xs) [1 −p(yi|xi, xk)]\n(6)\nThereby, learning loss is the negative-log-likelihood of ℓi over\nall the data points indexed by Λ, which simpliﬁes ℓi to\nL = −\nX\ni∈Λ\n∥K(i)∥\nX\ns∈S(i)\nlog p(yi|xi, xs)\n−\nX\ni∈Λ\n∥S(i)∥\nX\nk∈K(i)\nlog [1 −p(yi|xi, xk)]\n(7)\nwhere ∥S(i)∥and ∥K(i)∥are the sizes of their corresponding\nset.\nProposition 1. For any probability-based distance metric\nbetween two inputs, i.e., d(x, y), with the Softmax function,\nthere exists a general distance form of d(x, y), which arises\nfrom the Bregman divergence.\nProof. Here, we prove the Proposition 1 starting from the\nabove Eq(7). For −log p(yi|xi, xs), based on the ﬁrst-order\nTaylor approximation, we have\n−log p(yi|xi, xs) = log\nP\nj∈Λ,j̸=i exp(zT\ni zj)\nexp(zT\ni zs)\n= log\n\n1 +\nX\nj̸=i,s\nexp\n\u0002\nzT\ni zj −zT\ni zs\n\u0003\n\n\n≈\nX\nj̸=i,s\nexp\n\u0000zT\ni zj −zT\ni zs\n\u0001\n≈1 +\nX\nj̸=i,s\nzT\ni zj −zT\ni zs\n(8)\nNotice that, zT\ni zj = 1−1\n2∥zi −zj∥2 if ∥z∥= 1. With φ(x) =\n∥x∥2, the general distance of log p(yi|xi, xs) arises from the\nfunctional Bregman divergence is\nlog p(yi|xi, xs) ≈\nX\ni̸=s\ndφ (fθ(xi), fθ(xs)) −\nX\nj̸=i\ndφ (fθ(xi), fθ(xj))\n= Θ (fθ(xi), fθ(xs), fθ(xj))\n(9)\nNext, we turn our attention to p(yi|xi, xk) of Eq (5). Follow-\ning the same approach of Eq (8), the log of p(yi|xi, xk) can\nbe expressed as\nlog p(yi|xi, xk) ≈\nX\ni̸=k\ndφ (fθ(xi), fθ(xk)) −\nX\nj̸=i\ndφ (fθ(xi), fθ(xj))\n= Θ (fθ(xi), fθ(xk), fθ(xj))\n(10)\nThus, we formulate the learning loss L of Eq (7) as the Breg-\nman divergences approximation without any scale parameters:\nLdiv ≈−\nX\ni∈Λ\n∥K(i)∥\nX\ns∈S(i)\nΘ (fθ(xi), fθ(xs), fθ(xj))\n+\nX\ni∈Λ\n∥S(i)∥\nX\nk∈K(i)\nΘ (fθ(xi), fθ(xk), fθ(xj))\n(11)\nThis yields the initial idea of divergence learning that\nmaximizes\nthe\nfunctional\nBregman\ndivergence\namong\na positive pair Θ (fθ(xi), fθ(xs), fθ(xj)) and minimizes\nΘ (fθ(xi), fθ(xk), fθ(xj)), the functional Bregman divergence\namong a negative pair.\nInput Data \nFeature Extractor\nCat\nDog\nClassification\nDivergence Learning\nCross-Entropy \nLoss ℒ𝒄𝒆\nDivergence \nLoss ℒ𝒅𝒊𝒗\nℒ𝒄𝒆+ 𝝀ℒ𝒅𝒊𝒗\nSoftmax\nPull\nPush\n0.8\n1\n1\n1\n0\n0\n𝒚\nෝ𝒚\n0.9\n0.9\n0.2\n0.1\nFC\nFC\n…\nGNMs layer\n…\n1\n2\nm\nSoftplus(𝑧1\n𝑑𝛽1 + 𝑏1)\nSoftplus(𝑧2\n𝑑𝛽2 + 𝑏2)\nSoftplus(𝑧𝑚\n𝑑𝛽𝑚+ 𝑏𝑚)\n…\nSplit m-Softplus regressions\nGNMs Layer\n𝒛𝑑\n𝒛𝑑\n𝑧1\n𝑑+1\n𝑧2\n𝑑+1\n𝑧𝑚\n𝑑+1\n…\nFig. 1.\nThe overview of our proposed framework. We use a pre-trained ResNet18 as the encoder and learn joint tasks of supervised classiﬁcation and\nBregman divergence learning. We employed a group of generalized nonlinear models (GNMs) with the Softplus function to represent φ. The learned distance\nrepresentation will be further used in image classiﬁcation tasks using a kNN classiﬁer. (Top branch applies cross-entropy loss for classiﬁcation while bottom\nbranch applies divergence loss for distance learning.)\nC. Deep Bregman Divergence Learning With GNMs\nParameterization. We consider learning a functional Breg-\nman divergence dφ with the deep learning setting. Suppose zd\nis the dth layer output embedding vector, and zd+1 is the target\nembedding, which will be the input for functional Bregman\ndivergence dφ. To directly learn dφ, one thing that needs to\nbe considered is the convexity property of φ. We employ a\nset of generalized nonlinear models to estimate each value of\nzd+1. In this case, all zd+1\ni\n∈zd+1 are independent to each\nother. Let β, b denote the weights and biases, respectively, the\nith expectation value of the zd+1 is\nE(zd+1\ni\n|zd\ni ) = α(zd\ni βi + bi)\n(12)\nwhere βi ∈β, bi ∈b, and α is a convex link function. Note\nthat our learning loss is a functional Bregman divergence, in\nwhich δφ(q)(x) involves the second derivatives. Similar to\n[18], we employ a Softplus as the parametric link function.\nLemma 1. The Softplus function α(x) = log(1+exp(wx)) is\nstrictly monotonically increasing, strictly convex, and smooth.\nProof. Obviously, the ﬁrst and second derivative of α(x) is\nalways positive such that\nd\ndxlog (1 + exp(wx)) = (1 + exp(−wx))−1 ∈(0, 1)\nd2\ndx2 log (1 + exp(wx)) =\nw exp(wx)\n(1 + exp(wx))2 ∈(0, 1)\n(13)\nThus, α(x) is strictly monotonically increasing, strictly con-\nvex, and smooth.\nProposition 2. The expectation E(zd+1|zd) for (d + 1)th\nlayer of the embedding outputs is also strictly monotonically\nincreasing, strictly convex, and smooth.\nProof. Let λ ∈(0, 1), α : Rd →R denotes a Softplus\nfunction, and g : Rn →Rd denotes an afﬁne function, such\nthat g(z) = zβ + b. Suppose z1, z2 ∈z, we have\ng(λz1 + (1 −λ)z2) = λg(z1) + (1 −λ)g(z2)\n(14)\nBy Deﬁnition 1 and Lemma 1, E = α ◦g is as:\nE(λz1 + (1 −λ)z2) = λα (g(z1) + (1 −λ)g(z2))\n< λα ◦g(z1) + (1 −λ)α ◦g(z2)\n= λE(z1) + (1 −λ)E(z2)\n(15)\nwhich means that E a strictly convex function. We know\nthat E(z) = log (1 + exp(zβ + b)), and\n∂\n∂zE(z), ∂2\n∂z2 E(z),\nwhich are always positive. Thus, E is strictly monotonically\nincreasing and smooth.\nLearning Algorithm. With the above foundations, we pro-\npose a training algorithm to learn the arbitrary functional Breg-\nman divergence dφ for classiﬁcation in Figure 1. Our approach\nis two-fold: (1) a metric learning task for learning dφ among\nsamples from an input batch, (2) a classiﬁcation task for learn-\ning the label information. Speciﬁcally, we directly employ the\ndeﬁned divergence loss Ldiv in Eq (11) as distance metrics and\ntrain it with a cross-entropy loss Lce jointly. In this case, the\nlearned distance metrics capture more patterns than any pre-\nﬁxed distance metrics, leading to higher predictive power for\nclassiﬁcation. Let D = (xi, yi)N\ni=1 denote the training dataset\nwith labels y, a positive pairs set Ds = (xi, xs)N\ni=1, yi = ys,\nnegative pairs set Dk = (xi, xk)N\ni=1, yi ̸= yk, a arbitrary\ndeep encoder fθ, where the pseudo-code is summarized in\nAlgorithm 1.\nIV. DATA AND EXPERIMENTS\nA. Dataset\nWe employed ﬁve datasets for image recognition, namely\niChallenge-PM [19], iChallenge-AMD [20], Caltech-UCSD\nBirds (CUB200 dataset) [21], Animal FaceHQ (AFHQ) [22]\nAlgorithm 1 Deep Bregman Divergence Learning for Clas-\nsiﬁcation Via Joint Training\nRequire: D, Ds, Dk, Ldiv, fθ, and Lce.\nf d\nθ ←a dth layer of fθ for feature extraction\nfor each (xi, xj, yi) ∈D, (xi, xs) ∈Ds, (xixk) ∈Dk do\nzd\ni , zd\nj , zd\ns, zd\nk ←f d\nθ (xi), f d\nθ (xj), f d\nθ (xs), f d\nθ (xk)\nCompute φ(zd\ni ), φ(zd\nj ), φ(zs\ni ), φ(zk\nj )\n▷Eq (12)\ndφ1, dφ2, dφ3 ←dφ(zd\ni , zd\nj ), dφ(zd\ni , zd\ns), dφ(zd\ni , zd\nk)\nℓdiv ←Ldiv(dφ1, dφ2, dφ3)\n▷Eq (11)\nℓce ←Lce(xi, yi)\n▷cross-entropy loss\nL∗←ℓce + γℓdiv\n▷joint training\nL∗.backward()\n▷perform backpropagation\nend for\nreturn ˆfθ\n▷the pre-trained fθ\nand Oxford-III Pet [23]. The dataset consists of 1,200 anno-\ntated retinal fundus images from 2 classes, 1,200 color fundus\nimages with 400 ones released with annotations from 2 classes,\n11,788 bird images from 200 classes, 16,130 animal images\nfrom 3 classes, and 7,349 from 2 classes, respectively. To\nprovide the advantage of our approach in small-size samples,\nwe randomly selected 300 and 1000 images from the AFHQ\nand the Oxford-III pet with an equal ratio of each class,\nrespectively,\nB. Implementation Details\nAs shown in Figure 1, our approach is built on a network\nbackbone, i.e., pre-trained ResNet18 [24], with the same\nsetting in our previous study [25], [26] for feature extraction.\nWith the output of ResNet18, f, is then connected to a Multi-\nLayer Perceptron (MLP) layer, followed by batch normaliza-\ntion and a Rectiﬁed Linear Unit (ReLU) activation function.\nThe output of this process is reduced feature dimension to 128,\ndenoted as z. For the classiﬁcation branch, z is connected\nto a Softmax and cross-entropy loss Lce with labels. For\nthe divergence learning task, z is input to a L2 norm layer,\nresulting in ∥z∥= 1, and sequentially followed by a GNMs\nlayer fused with k-Softplus regression outputs. Furthermore, a\ndivergence metric loss Ldiv is employed to learn the arbitrary\nBregman divergence. To test the learned Bregman divergence,\nwe applied the kNN classiﬁer based on z, in which we set\nk = 50 empirically. We randomly resized each image within\na range of 0.3 to 1.0 for each batch size. The batch size was\nset to 32, and the model optimization was performed using\nthe Adam optimizer. We set the learning rate and weight\ndecay to 0.0001 and trained the whole framework for 2000\nepochs. To evaluate the model, we used accuracy and the Area\nUnder the Receiver Operating Characteristic (ROC) curve\n(AUC). Following standard practice, we used 10-fold cross-\nvalidation to evaluate each competing method. In addition, we\nconducted a non-parametric Wilcoxon test with a signiﬁcance\nlevel of 0.05 for all statistical inferences using R-studio. The\nframework was implemented using python 3.8, Scikit-Learn\n0.24.1, Pytorch 1.9.1, and Cuda 11.1 on a NVIDIA GeForce\nGTX 1660 SUPER GPU.\nC. Competing State-of-The-Art Methods\nWe compared our approach with other SOTA methods\nacross the deep metric learning and contrastive learning, in-\ncluding Siamese network [6], Triplet network [7], N-pair [27],\nSupCon [8], GHM [25], PDBL [11], and DeepDiv [10] using\ntheir released code on GitHub. A supervised learning baseline\nwas also included by modifying the last fully connected layer\nof ResNet18 to match the number of classes with a cross-\nentropy loss for classiﬁcation. To ensure fairness, all methods\nwere trained with the same feature extractor (e.g., ResNet18)\nwith consistent hyperparameters, learning rate, batch size, and\noptimizer. We ﬁxed the classiﬁcation branch and replaced the\ndivergence learning branch. To show the effectiveness of Breg-\nman divergence, we replaced the similarity functions (cosine\nsimilarity, Euclidean distance) with the Bregman divergence\nin the SOTA methods to perform metrics comparison.\n1) Quantitative Results: To demonstrate the promise of the\nproposed method, we performed image classiﬁcation tasks\non ﬁve datasets and compared the prediction performance\nof our approach with other SOTA methods. The results are\nshown in Table I. Our approach signiﬁcantly outperforms\nthe other SOTA methods with higher overall accuracy and\nAUC. The results of the iChallenge-PM dataset indicate that\nall methods can achieve over 95% accuracy and AUC, demon-\nstrating the feasibility of identifying pathological myopia from\ncolor fundus images. However, the performance drops for all\nmethods on the iChallenge-AMD dataset due to insufﬁcient\nannotated samples. For the CUB200 dataset, even though the\ndataset contains a large number of samples, the classiﬁcation\nperformance achieved similar results as the iChallenge-AMD\ndataset since the bird patterns are harder to detect, making\nthe classiﬁcation task more difﬁcult challenging. Our approach\noutperforms other SOTA methods, showing the effectiveness\nof learned Bregman divergence for image recognition tasks.\n2) Model Generalizability: To prove the generalizability of\nour proposed method, we ﬁrst compared our approach with\nother SOTA methods on the AFHQ dataset and saved each pre-\ntrained model. Since AFHQ and Oxford-III Pet contain cat and\ndog classes, we employed Oxford-III Pet as an independent\nexternal dataset and evaluated model generalizability using\nthe pre-trained models. The results are shown in the last\ntwo columns of Table I. Our approach achieved overall\nclassiﬁcation performance with more precise accuracy and\nAUC on internal validations using the AFHQ dataset and\nexternal validation using the Oxford-III Pet dataset. In this\nway, we presented the generalization capabilities of learned\nempirical Bregman divergence of our proposed method for\nimage classiﬁcation.\nD. Ablation Study\n1) Impact of Divergence Learning Loss: Our learning ob-\njective is a linear combination of two loss functions, i.e., Lce\nand Ldiv. Here, we analyzed the importance of the divergence\nloss Ldiv by training our approach with different γ using the\niChallenge-AMD dataset, in which γ indicates a weighting\nfactor of Ldiv. The results are demonstrated in Figure 3.\nTABLE I\nCOMPETING FOR SOTA DEEP METRIC LEARNING AND CONTRASTIVE LEARNING METHODS ON FIVE SELECTED DATASETS (UNIT: %). RESNET18 IS\nEMPLOYED AS A NETWORK ENCODER FOR FEATURE EXTRACTION\niChallenge-PM\niChallenge-AMD\nCUB200\nAFHQ\nOxford-III Pet\nSOTAs\nAccuracy\nAUC\nAccuracy\nAUC\nAccuracy\nAUC\nAccuracy\nAUC\nAccuracy\nAUC\nBaseline [24]\n95.45\n96.01\n84.14\n76.51\n71.02\n69.14\n76.42\n75.54\n77.50\n78.24\nSiamese [6]\n95.12\n97.21\n78.14\n69.45\n77.14\n73.45\n80.25\n82.64\n85.12\n84.54\nTriplet [7]\n95.12\n97.21\n80.18\n70.28\n80.14\n75.65\n83.36\n84.45\n85.50\n84.47\nN-pair [27]\n96.45\n94.38\n85.12\n74.54\n82.14\n79.45\n78.98\n81.25\n81.65\n80.22\nSupCon [8]\n98.22\n98.06\n85.64\n73.24\n81.45\n78.46\n82.87\n79.69\n86.20\n82.84\nGHM [25]\n95.24\n95.36\n82.47\n72.58\n79.45\n77.41\n81.54\n79.65\n82.41\n83.10\nPDBL [11]\n98.57\n98.42\n85.04\n78.69\n80.47\n80.14\n84.12\n84.74\n85.50\n85.10\nDeepDiv [10]\n97.25\n98.05\n86.51\n73.65\n83.47\n80.87\n82.05\n81.25\n81.10\n78.65\nOurs\n99.12\n98.14\n87.45\n80.17\n82.53\n82.49\n85.45\n86.03\n88.20\n89.35\nFig. 2. Training model on the iChallenge-AMD using different γ of L∗in\nAlgorithm 1. We achieved the best accuracy and AUC when γ = 1.0.\nWe found that when γ = 0.0, the network is equivalent to\na supervised baseline method with 84.14% on accuracy and\n76.51% on AUC. As γ increases, the performance improves\nand reaches the best performance when γ = 1.0. This shows\nthat the classiﬁcation and divergence learning branches con-\ntribute equally to diagnosing age-related macular degeneration\n(AMD).\n2) Quality Representations: To verify the effectiveness of\nthe learned feature representation of our approach, we use t-\nSNE to represent the last fully connected layer after CNN.\nAs shown in Figure 3, we compared our approach with other\nSOTA metric learning and divergence learning methods on the\n1000 testing AFHQ dataset. It is observed that our approach\ndemonstrates a more precise decision boundary between the\ntwo classes. These results further show that learning the\nempirical Bregman divergence provides a better solution to\ncapture the discriminative patterns.\n3) Feature Visualization: We compared our approach to\nTriplet Network [7] and Deep Divergence Learning [10] by\nshowing the feature attention maps of the last ResNet18 block\n(Figure 4). We randomly selected seven input images from\nAFHQ, Oxford-III pet, and CUB200 datasets. We applied\nGrad-CAM [28] to localize the discriminative patterns by\npointwise multiplying the attention map with backpropagation\ncorresponding to image classiﬁcation. This visualization sug-\ngests the attention to various image patterns in each model for\nOurs\nDeepDiv\nTriplet\nSupCon\nFig. 3.\nt-SNE visualization of learned embeddings from ResNet18 on the\nAFHQ dataset. Our approach precisely captures the decision boundary for\nseparating two classes.\nclassiﬁcation. Compared to other SOTA methods, our approach\nlearns the empirical Bregman divergence that can help the\nnetwork focus on the correction positions of images in terms of\nlearning a more robust feature representation for classiﬁcation.\n4) Metrics Comparison: This section shows the advantage\nof learned Bregman divergence for capturing complex sim-\nilarity using synthetic examples where existing approaches\nwould fail. Assuming the relationship between two embedding\npresents a complex distribution, i.e., a random nonlinear\ncorrelation. We split the synthetic dataset into a supporting\nset and a query set, in which we train a Siamese network\nusing the supporting set and apply the pre-trained network\nto match the query set. Figure 5 shows each sample input\nGround \nTruth\nTriplet \nNetwork\nDeepDiv\nOurs\nFig. 4. Feature visualization with different SOTA methods on three datasets (AFHQ, Oxford-III pet, and CUB200) using GradCAM. The more discriminative\npatterns of images indicate the high attention scores of the heatmap. Our approach captures more patterns than other methods, resulting in better classiﬁcation\nperformance.\n(pixel) is highlighted if it matches the query input. We com-\npared empirical Bregman divergence with other ﬁxed distance\nfunctions in this setting, including cosine similarity and KL-\ndivergence. As we can see, the learned Bregman divergence\ncaptures the best representation of nonlinear similarity among\ntwo embeddings. At the same time, other distances are not\ndiscriminative enough to capture the basic patterns under this\ncomplex distribution.\n5) Effects of the Number of m-Softplus Regressions: Our\nproposed method contains m-Softplus regression of the GNM\nlayer for parameterizing the convex function φ of the Bregman\ndivergence. Here, we study the effects of different m on\nclassiﬁcation performance. To assess it, we train our model\nwith different m and then compare the performance on the\ndatasets of the iChallenge-AMD, CUB200, and AFHQ. The\nresults are shown in Figure 6. We can see that performance\nfor all datasets increases until m = 150, then drops. We also\nobserved a similar phenomenon in [17].\nV. DISCUSSION AND FUTURE WORK\nLearning a representative distance is vital in visual represen-\ntation for enhancing machine vision and pattern recognition.\nThe learned distance representation can be further applied to\nvarious downstream tasks, including classiﬁcation, clustering,\nand object detection. With the advances in deep learning\ntechniques, deep metric learning has been widely used in the\nvisual representation, and machine intelligence community [1],\n[2], [29]. Besides promising evidence from previous studies\n[6]–[8], classic deep metric learning employed ﬁxed distance\nmetrics as the similarity function during the training, resulting\nin ignoring natural data distribution. Across probability theory\nand information science, the Bregman divergence uses a\nGround Truth\nCosine Similarity\nJS-Divergence\nOurs\nFig. 5.\nThe synthetic example showing learned Bregman divergence can\ncapture more complex distribution on a matching. Each color pixel indicates\nthe correct matched case from the supporting and query sets.\nstrictly convex function to represent a general distance metric,\nwhich provides a potential solution to address the challenge\nof arbitrary distance selection. This work ﬁrst proves the\nequivalent relationship between a general metric learning loss\nand the Bregman divergence. We then present a novel approach\nto learn the empirical Bregman divergence by parameterizing\nFig. 6. The importance of increasing Softplus regressions (m) on accuracy\n(%): We train our model with different m on the iChallenge-AMD, CUB200,\nand AFHQ datasets. The performance reaches best when m = 150, then\ndrops down because of over-parameterization.\na convex function between two feature embeddings in a deep\nmetric learning style. Unlike previous works, our approach\ndirectly learns an optimal distance representation from data,\nshowing practical advances for complex sample distributions.\nCompared to other SOTA methods, our approach consistently\nachieves promising results on ﬁve public datasets, which\nshows the supervisor of the learned distance representation. In\naddition to performance evaluation with other SOTA methods,\nextensive ablation studies are provided to further prove our\napproach’s effectiveness.\nAlthough our approach outperforms other SOTA methods,\nit still comes with limitations. First, we only study learning\na Bregman divergence in a supervised manner, which relies\non a more signiﬁcant number of annotated training samples\nand requires expensive human effort. Secondly, our approach\nemploys a GNM layer, which may be computationally costly if\nm is large. In the future, we will investigate learning empirical\nBregman divergence in an unsupervised or self-supervised\nlearning style and study a more efﬁcient alternative approach.\nVI. ACKNOWLEDGEMENT\nProfessor Anca Ralescu would like to thank Professor\nShun’ichi Amari who ﬁrst mentioned the Bregman divergence\nto her.\nREFERENCES\n[1] O. Mees, N. Abdo, M. Mazuran, and W. Burgard, “Metric learning\nfor generalizing spatial relations to new objects,” in 2017 IEEE/RSJ\nInternational Conference on Intelligent Robots and Systems (IROS).\nIEEE, 2017, pp. 3175–3182.\n[2] B. J. Meyer and T. Drummond, “The importance of metric learning\nfor robotic vision: Open set recognition and active learning,” in 2019\nInternational Conference on Robotics and Automation (ICRA).\nIEEE,\n2019, pp. 2924–2931.\n[3] M. Rezayati, G. Zanni, Y. Zaoshi, D. Scaramuzza, and H. W. van de\nVenn, “Improving safety in physical human-robot collaboration via\ndeep metric learning,” in 2022 IEEE 27th International Conference on\nEmerging Technologies and Factory Automation (ETFA).\nIEEE, 2022,\npp. 1–8.\n[4] A. Bellet, A. Habrard, and M. Sebban, Metric learning.\nMorgan &\nClaypool Publishers, 2015.\n[5] L. M. Bregman, “The relaxation method of ﬁnding the common point\nof convex sets and its application to the solution of problems in convex\nprogramming,” USSR computational mathematics and mathematical\nphysics, vol. 7, no. 3, pp. 200–217, 1967.\n[6] G. Koch, R. Zemel, R. Salakhutdinov et al., “Siamese neural networks\nfor one-shot image recognition,” in ICML deep learning workshop,\nvol. 2.\nLille, 2015, p. 0.\n[7] E. Hoffer and N. Ailon, “Deep metric learning using triplet network,”\nin International workshop on similarity-based pattern recognition.\nSpringer, 2015, pp. 84–92.\n[8] P. Khosla et al., “Supervised contrastive learning,” Advances in Neural\nInformation Processing Systems, vol. 33, pp. 18 661–18 673, 2020.\n[9] M. Ye, X. Zhang, P. C. Yuen, and S.-F. Chang, “Unsupervised em-\nbedding learning via invariant and spreading instance feature,” in Pro-\nceedings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 2019, pp. 6210–6219.\n[10] H. K. Cilingir, R. Manzelli, and B. Kulis, “Deep divergence learning,”\nin International Conference on Machine Learning.\nPMLR, 2020, pp.\n2027–2037.\n[11] A. Siahkamari, X. Xia, V. Saligrama, D. Casta˜n´on, and B. Kulis,\n“Learning to approximate a bregman divergence,” Advances in Neural\nInformation Processing Systems, vol. 33, pp. 3603–3612, 2020.\n[12] M. Kaya and H. S¸. Bilge, “Deep metric learning: A survey,” Symmetry,\nvol. 11, no. 9, p. 1066, 2019.\n[13] S. Chopra, R. Hadsell, and Y. LeCun, “Learning a similarity metric\ndiscriminatively, with application to face veriﬁcation,” in 2005 IEEE\nComputer Society Conference on Computer Vision and Pattern Recog-\nnition (CVPR’05), vol. 1.\nIEEE, 2005, pp. 539–546.\n[14] M. Gutmann and A. Hyv¨arinen, “Noise-contrastive estimation: A new\nestimation principle for unnormalized statistical models,” in Proceedings\nof the thirteenth international conference on artiﬁcial intelligence and\nstatistics.\nJMLR Workshop and Conference Proceedings, 2010, pp.\n297–304.\n[15] A. Banerjee, S. Merugu, I. S. Dhillon, J. Ghosh, and J. Lafferty,\n“Clustering with bregman divergences.” Journal of machine learning\nresearch, vol. 6, no. 10, 2005.\n[16] B. A. Frigyik, S. Srivastava, and M. R. Gupta, “Functional bregman\ndivergence and bayesian estimation of distributions,” IEEE Transactions\non Information Theory, vol. 54, no. 11, pp. 5130–5139, 2008.\n[17] M. Rezaei, F. Soleymani, B. Bischl, and S. Azizi, “Deep bregman\ndivergence for contrastive learning of visual representations,” arXiv\npreprint arXiv:2109.07455, 2021.\n[18] F. Lu, E. Raff, and F. Ferraro, “Neural bregman divergences for distance\nlearning,” arXiv preprint arXiv:2206.04763, 2022.\n[19] H. Fu et al., “Palm: Pathologic myopia challenge,” IEEE Dataport, 2019.\n[20] H. Fang et al., “Adam challenge: Detecting age-related macular degen-\neration from fundus images,” IEEE Transactions on Medical Imaging,\n2022.\n[21] P. Welinder et al., “Caltech-ucsd birds 200,” California Institute of\nTechnology, 2010.\n[22] Y. Choi, Y. Uh, J. Yoo, and J.-W. Ha, “Stargan v2: Diverse image\nsynthesis for multiple domains,” in Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition, 2020, pp. 8188–\n8197.\n[23] O. M. Parkhi, A. Vedaldi, A. Zisserman, and C. Jawahar, “Cats and\ndogs,” in 2012 IEEE conference on computer vision and pattern recog-\nnition.\nIEEE, 2012, pp. 3498–3505.\n[24] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770–778.\n[25] Z. Li and A. Ralescu, “Learning generalized hybrid proximity represen-\ntation for image recognition,” arXiv preprint arXiv:2301.13459, 2023.\n[26] Z. Li, H. Li, A. L. Ralescu, J. R. Dillman, N. A. Parikh, and L. He, “A\nnovel collaborative self-supervised learning method for radiomic data,”\narXiv preprint arXiv:2302.09807, 2023.\n[27] K. Sohn, “Improved deep metric learning with multi-class n-pair loss\nobjective,” Advances in neural information processing systems, vol. 29,\n2016.\n[28] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and\nD. Batra, “Grad-cam: Visual explanations from deep networks via\ngradient-based localization,” in Proceedings of the IEEE international\nconference on computer vision, 2017, pp. 618–626.\n[29] Z. Li and J. Tang, “Weakly supervised deep metric learning for\ncommunity-contributed image retrieval,” IEEE Transactions on Multi-\nmedia, vol. 17, no. 11, pp. 1989–1999, 2015.\n",
  "categories": [
    "cs.CV",
    "cs.AI",
    "cs.IT",
    "cs.LG",
    "math.IT",
    "stat.ML"
  ],
  "published": "2023-04-16",
  "updated": "2023-05-15"
}