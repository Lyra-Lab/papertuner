{
  "id": "http://arxiv.org/abs/2304.14670v2",
  "title": "Prompt Engineering for Healthcare: Methodologies and Applications",
  "authors": [
    "Jiaqi Wang",
    "Enze Shi",
    "Sigang Yu",
    "Zihao Wu",
    "Chong Ma",
    "Haixing Dai",
    "Qiushi Yang",
    "Yanqing Kang",
    "Jinru Wu",
    "Huawen Hu",
    "Chenxi Yue",
    "Haiyang Zhang",
    "Yiheng Liu",
    "Yi Pan",
    "Zhengliang Liu",
    "Lichao Sun",
    "Xiang Li",
    "Bao Ge",
    "Xi Jiang",
    "Dajiang Zhu",
    "Yixuan Yuan",
    "Dinggang Shen",
    "Tianming Liu",
    "Shu Zhang"
  ],
  "abstract": "Prompt engineering is a critical technique in the field of natural language\nprocessing that involves designing and optimizing the prompts used to input\ninformation into models, aiming to enhance their performance on specific tasks.\nWith the recent advancements in large language models, prompt engineering has\nshown significant superiority across various domains and has become\nincreasingly important in the healthcare domain. However, there is a lack of\ncomprehensive reviews specifically focusing on prompt engineering in the\nmedical field. This review will introduce the latest advances in prompt\nengineering in the field of natural language processing for the medical field.\nFirst, we will provide the development of prompt engineering and emphasize its\nsignificant contributions to healthcare natural language processing\napplications such as question-answering systems, text summarization, and\nmachine translation. With the continuous improvement of general large language\nmodels, the importance of prompt engineering in the healthcare domain is\nbecoming increasingly prominent. The aim of this article is to provide useful\nresources and bridges for healthcare natural language processing researchers to\nbetter explore the application of prompt engineering in this field. We hope\nthat this review can provide new ideas and inspire for research and application\nin medical natural language processing.",
  "text": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n1\nPrompt Engineering for Healthcare: Methodologies\nand Applications\nJiaqi Wang∗, Enze Shi∗, Sigang Yu, Zihao Wu, Chong Ma, Haixing Dai, Qiushi Yang, Yanqing Kang, Jinru Wu,\nHuawen Hu, Chenxi Yue, Haiyang Zhang, Yiheng Liu, Yi Pan, Zhengliang Liu, Lichao Sun,\nXiang Li, Bao Ge, Xi Jiang, Dajiang Zhu, Yixuan Yuan, Dinggang Shen, Tianming Liu, and Shu Zhang\nAbstract—Prompt engineering is a critical technique in the\nfield of natural language processing that involves designing and\noptimizing the prompts used to input information into models,\naiming to enhance their performance on specific tasks. With the\nrecent advancements in large language models, prompt engineer-\ning has shown significant superiority across various domains and\nhas become increasingly important in the healthcare domain.\nHowever, there is a lack of comprehensive reviews specifically\nfocusing on prompt engineering in the medical field. This review\nwill introduce the latest advances in prompt engineering in\nthe field of natural language processing for the medical field.\nFirst, we will provide the development of prompt engineering\nand emphasize its significant contributions to healthcare natural\nlanguage processing applications such as question-answering\nsystems, text summarization, and machine translation. With the\ncontinuous improvement of general large language models, the\nimportance of prompt engineering in the healthcare domain\nis becoming increasingly prominent. The aim of this article is\nto provide useful resources and bridges for healthcare natural\n∗Co-first author\nCorresponding author: Shu Zhang\nJiaqi\nWang,\nEnze\nShi,\nSigang\nYu,\nYanqing\nKang,\nJinru\nWu,\nHuawen\nHu,\nChenxi\nYue,\nHaiyang\nZhang,\nShu\nZhang\nare\nwith\nthe School of Computer Science, Northwestern Polytechnical Univer-\nsity,\nXi’an\n710072,\nChina.\nChong\nMa\nis\nwith\nthe\nSchool\nof\nAu-\ntomation, Northwestern Polytechnical University, Xi’an 710072, China.\n(e-mail:\n{jiaqi.wang,\nezshi,\nsgyu,\nyanqing.kang,\njinru.wu,\nhuawenhu,\nchenxi.yue,\nhaiyang.zhang}@mail.nwpu.edu.cn;\nshu.zhang@nwpu.edu.cn;\nmc-npu@mail.nwpu.edu.cn).\nZihao Wu, Haixing Dai, Zhengliang Liu, and Tianming Liu are with the\nSchool of Computing, The University of Georgia, Athens 30602, USA. (e-\nmail: {zihao.wu1, haixing.dai, zl18864, tliu}@uga.edu).\nLichao Sun is with the Department of Computer Science and Engineering,\nLehigh University, PA 18015, USA. (e-mail: lis221@lehigh.edu).\nXiang Li is with the Department of Radiology, Massachusetts Gen-\neral Hospital and Harvard Medical School, Boston 02115, USA. (e-mail:\nXLI60@mgh.harvard.edu).\nDajiang Zhu is with the Department of Computer Science and Engineering,\nThe University of Texas at Arlington, Arlington 76019, USA. (e-mail:\ndajiang.zhu@uta.edu).\nDinggang Shen is with the School of Biomedical Engineering, Shang-\nhaiTech University, Shanghai 201210, China; Shanghai United Imaging Intel-\nligence Co., Ltd., Shanghai 200230, China; Shanghai Clinical Research and\nTrial Center, Shanghai, 201210, China. (e-mail: Dinggang.Shen@gmail.com).\nQiushi Yang is with the Department of Electronic Engineering, City\nUniversity of Hong Kong, Hong Kong 999077, China. Yixuan Yuan is\nwith the Department of Electronic Engineering, Chinese University of Hong\nKong, Hong Kong 999077, China. (e-mail: qsyang2-c@my.cityu.edu.hk;\nyxyuan@ee.cuhk.edu.hk).\nYiheng Liu and Bao Ge are with the School of Physics and Informa-\ntion Technology, Shaanxi Normal University, Xi’an 710119 China. (e-mail:\n{liuyiheng,bob ge}@snnu.edu.cn)\nYi Pan is with the School of Glasgow College, University of Electronic\nScience and Technology of China, Chengdu 611731, China. Xi Jiang is\nwith the School of Life Science and Technology, University of Elec-\ntronic Science and Technology of China, Chengdu 611731, China. (e-mail:\ndwaynepan5277@gmail.com; xijiang@uestc.edu.cn)\nlanguage processing researchers to better explore the application\nof prompt engineering in this field. We hope that this review can\nprovide new ideas and inspire for research and application in\nmedical natural language processing.\nIndex Terms—Prompt engineering, Healthcare, Natural lan-\nguage processing, Medical application\nI. INTRODUCTION\nPrompt engineering has emerged as a cutting-edge approach\nin the field of natural language processing (NLP), providing\na more efficient and cost-effective means of using large\nlanguage models (LLM). This innovative paradigm is rooted\nin the development of LLMs, which have transformed our\nunderstanding of natural language [1], [2].\nThe history of language models can be traced back to the\n1950s, but it is until the introduction of the BERT and GPT\nmodels in 2018 that LLMs became the mainstream [3]. These\nmodels utilize complex algorithms and massive amounts of\ntraining data to understand natural language in ways that are\npreviously unimaginable. Their ability to learn patterns and\nstructures in language has proven invaluable in a wide range of\nlanguage-related tasks [4], [5]. However, fine-tuning these pre-\ntrained models can be a costly and time-consuming process,\nrequiring significant amounts of annotated data and computing\nresources. To address this challenge, researchers have turned\nto prompts as a means of guiding model learning [2], [6],\n[7]. Prompt learning is a novel paradigm in NLP that enables\nlanguage models to perform few or even zero-shot learning,\nadapting to new scenarios with minimal labeled data [1], [2],\n[8]. This approach is rooted in language modeling, directly\nmodeling the probability of text. The key to prompt engineer-\ning is designing prompts for downstream tasks, which guide\nthe pre-trained model to perform the desired task [9].\nPrompt learning can be broken down into five key steps [1].\nFirst, researchers must choose an appropriate pre-training\nmodel. Next, they must design prompts for downstream tasks,\nwhich can be tailored to the specific requirements of each\ntask, and this step is called the prompt engineering process.\nThe third step involves designing responses based on the\ntask at hand, allowing the model to produce the desired\noutput. The fourth step is to expand the paradigm to further\nimprove results or adaptability methods. Finally, researchers\nmust design training strategies that enable the model to learn\nefficiently and effectively. Prompt engineering is thus a critical\nstep in the prompt-based approach, which involves designing\neffective prompts to guide the pre-trained language model in\narXiv:2304.14670v2  [cs.AI]  23 Mar 2024\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n2\ndownstream tasks. While prompt engineering plays a crucial\nrole in the success of the overall approach, studies have\nshown that the design of prompts can significantly impact\nthe performance of the model on downstream tasks. A well-\ndesigned prompt should provide clear guidance to the model\nand facilitate effective task completion. Moreover, optimizing\nprompt parameters is also an important aspect of prompt\nengineering, as it can lead to improved model performance.\nThe subsequent steps in prompt-based methods, such as\ndesigning answers, expanding the paradigm, and adjusting\ntraining strategies, require task-specific prompt design and\noptimization.\nOverall, prompt engineering is a promising new approach in\nNLP that has the potential to revolutionize the field. Its focus\non using prompts to guide model learning provides a more\ncost-effective and efficient means of training large language\nmodels, making it an increasingly important area of research\nin the years to come [10].\nA. Scope and Focus of the Review\nIn recent years, the healthcare industry has received in-\ncreasing attention as it is closely related to each individual.\nHowever, there is still a significant gap between the shortage\nof medical resources and people’s needs [11], [12]. NLP\ntechnology can handle massive amounts of data from various\nmedical literature and medical records, thus helping doctors\nand patients better understand and manage diseases, which\nis of great significance in improving medical standards and\nproviding better health security [13].\nFig. 1.\nA wordcloud is employed to illustrate the research hotspots, focal\npoints, and directions in prompt engineering for NLP in the medical domain,\nwhich reflects the key vocabulary and highlights the significant themes of this\nliterature review.\nHowever, traditional machine learning and deep learning\nmethods cannot solve NLP tasks in the medical field very\nwell [3]. The complex and diverse professional terminology in\nthe medical field, the wide range of professional knowledge,\nand ethical issues related to patient privacy have all become\ndifficult problems in the development of the healthcare indus-\ntry [14]. The emergence of LLMs and prompt-based methods\nprovides a new solution for NLP tasks in the medical field.\nAs depicted in Figure 1, the wordcloud illustrates the research\nhotspots and focal points in NLP for the medical domain,\nhighlighting the significant themes of this literature review in\nthis field. Through the powerful contextual learning ability of\nLLMs, useful information can be effectively obtained from\na large number of medical literature and cases. By designing\nspecific prompts, domain-specific knowledge and task-specific\ninformation can be introduced into the pre-trained model,\nresulting in better performance and gaining more extensive\nattention [15].\nIn the research of prompt engineering, designing appro-\npriate prompts is an important issue. Currently, researchers\nare exploring various types of prompts, including manual\nprompts [14]–[19] and automated prompts [6], [20]–[22], as\nwell as various methods of prompt construction to help solve\ntasks in the medical field.\nB. Literature Search Process\nThe importance of NLP tasks in the medical field cannot be\noverstated. With the increasing volume of medical data, there\nis a growing need for effective NLP techniques to improve\nthe quality and efficiency of medical services. In this regard,\nprompt engineering has emerged as a promising approach\nto guiding model generation by providing targeted prompt\ninformation.\nTo investigate the application of prompt engineering in the\nmedical field, we conduct a comprehensive review of literature\nfrom 2019 to 2023 by searching for keywords “prompt” and\n“medical NLP” on arxiv. As shown in Figure 2, a total of 333\npapers related to the prompt are identified, and ChatGPT is\nused to screen the abstracts for their relevance to the medical\nfield, resulting in the selection of 140 relevant papers for\nfurther review. The dynamic graph in the following link1\nshows the daily publication rate of related papers.\nThese papers mainly focus on the design and application of\nprompt engineering in NLP tasks in the medical field, with the\ngoal of providing suitable prompt design methods for different\nmedical tasks. Specifically, the studies explore how to choose\nand design prompt elements, how to use prompts to guide\na model generation of text that meets medical requirements,\nand how to evaluate the impact of different prompt designs on\nmodel performance.\nC. Outline of the Review\nThis review article provides an in-depth overview of Prompt\nEngineering, a rapidly growing field of research focusing on\nenhancing medical applications through the development of\neffective prompts. As illustrated in Figure 3, we present the\noverview of this review article with each section organized as\nfollows:\nThe introduction of the article discusses the background and\nsignificance of Prompt Engineering and outlines the scope and\nfocus of the review. It describes the literature search process\nfollowed and provides an outline of the article.\nSection II presents the basics of Prompt Engineering, in-\ncluding common LLMs, and the elements and components of\nprompts.\nSection III discusses the different types of prompts available\nin the literature, with a focus on manual prompts such as\n1https://braininspiredai.github.io/prompt trend in medical\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n3\nFig. 2. The graphical representation is utilized to depict the number of research papers on prompt engineering for NLP in the medical domain, published from\n2019 to April 6, 2023, revealing the trend and growth of this field over time. The graph showcases three different plots: daily submitted count, cumulative\ndaily submitted count, and annual submitted count.\nFig. 3. The overview of this literature review provides a comprehensive and systematic summary of the current state of research on prompt engineering for\nNLP in the medical domain.\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n4\nzero-shot and few-shot prompting. The section uses medical\nliterature to highlight specific details. Automated prompts, in-\ncluding discrete and continuous prompting, are also discussed,\nand the section compares manual and automated prompting\ntechniques.\nIn Section IV, the various applications of prompts in med-\nical fields are covered in detail. These applications include\nclassification, generation, detection, augmentation, question\nanswering, and inference tasks, and the section provides the\nlatest medical examples to illustrate the practical use of\nprompts.\nSection V outlines the challenges and future directions\nof prompt engineering in medical applications. The section\nhighlights the current research directions in the field and\nprovides insight into the opportunities for future research.\nFinally, Section VI concludes the review by summarizing\nthe key findings and contributions of the article. The section\nalso discusses the limitations of the review and provides\nrecommendations for future research in the field of prompt\nengineering in medical applications.\nOverall, the review provides insights into the latest devel-\nopments in prompt engineering for medical NLP tasks and\nhighlights the importance of prompt engineering in improving\nthe accuracy and effectiveness of medical services. It also\nunderscores the need for continued research to explore the\npotential of prompt engineering in the medical field and to\nidentify effective strategies for its implementation. Ultimately,\nprompt engineering has the potential to transform the way\nmedical services are delivered and to enhance the quality of\ncare for patients.\nII. BASIC KNOWLEDGE\nIn prompt engineering, LLMs are of great importance as\nthey enable the design of appropriate prompts for specific tasks\nand can generate high-quality results even with limited training\ndata [16]. This section will delve into the latest advances in\nlarge models and provide a framework for prompt design.\nA. Large Language Models\nIn this section, we have explored the prevalent LLMs in\nprompt engineering within the medical field, which are trained\non large amounts of text data and are capable of generating\nhigh-quality, contextually relevant, and coherent text in various\nNLP tasks. Among them, prompt-based techniques provide\nresearchers with rich natural language patterns and structures\nand have become an important tool in prompt engineering.\nPrompt engineering is achieved through the design of\nprompts, which enables the model to generate diversified\ntext based on different contextual environments and can be\noptimized and customized for different tasks and application\nscenarios [23]. In the medical field, the application of these\nmodels has provided significant help and inspiration for med-\nical research and clinical practice.\nBERT (Bidirectional Encoder Representations from Trans-\nformers) [24] is a pre-trained model developed by the Google\nteam in 2018 that has bidirectional encoder representations\nusing the transformer architecture. Its purpose is to pre-train\nbidirectional representations by jointly adjusting the context in\nall layers, and by overcoming the limitations of previous unidi-\nrectional language models through a masked language model.\nIn addition, BERT introduces the next sentence prediction task,\nwhich can be used in conjunction with a masked language\nmodel to pre-train text pair representations [25]. The training\nobjective of BERT is highly meaningful, as it demonstrates the\nimportance of bidirectional pre-training for language represen-\ntations. Compared to previous unidirectional language models,\nBERT’s pre-training can better capture semantic information\nin the context [24].\nBERT is the first fine-tuning based representation model,\nwhich has surpassed many task-specific architectures in 11\nNLP tasks, setting new performance records [24]. This\nachievement demonstrates the enormous potential of pre-\ntrained models in NLP tasks, and provides important refer-\nences for the development of subsequent NLP models.\nThe Text-to-Text Transfer Transformer (T5) [4] is an LLM\ndeveloped by Google in 2019. The fundamental idea behind\nT5 is to treat every NLP task as a “text-to-text” problem.\nThe training objective of T5 is to develop it into a universal\nknowledge representation model, enabling the model to better\nunderstand and process text. T5 has achieved state-of-the-art\nresults in multiple NLP tasks, such as text classification, ma-\nchine translation, text summarization, and question answering,\namong others. In these tasks, the text is taken as input, and\nnew text is generated as output to solve specific problems. The\nadvantage of this approach is that by treating all NLP tasks as\n“text-to-text” problems, the T5 model can learn how to map\ninput text to output text, thereby enhancing its understanding\nand processing of text.\nChatGPT is a series of generative pre-trained transformer\nmodels developed by the OpenAI team. GPT-1 [26], which\nis released in June 2018, is trained on a large-scale text\ncorpus with the aim of generating coherent and natural text.\nSubsequently, GPT-2 [27] is released in February 2019, which\nis built on the foundation of GPT-1 with a larger model size\nand more training data, achieving outstanding performance on\na variety of NLP tasks. In June 2020, GPT-3 [28] is introduced,\nutilizing an even larger model size and more extensive training\ndata than GPT-2, resulting in further improvements in model\nperformance. GPT-3.5 then further optimizes the efficiency and\nperformance of GPT-3.\nTo enhance the performance of the model, the OpenAI team\nuses supervised and reinforcement learning to fine-tune GPT-\n3.5, with human intervention playing a key role in enhancing\nmachine learning capabilities [29], [30]. The optimization of\ntraining methods and increased training data has led to GPT-4\nbeing able to generate text that is similar to that produced by\nhumans, representing a significant breakthrough in the field of\nartificial intelligence.\nIn the future, LLMs will continue to evolve and improve,\nand we can expect their applications in the medical field to\nbring more value and contributions to human health.\nB. Elements and Formats of Prompts\nPrompts are usually classified into two forms: cloze\nprompts [16], [31] and prefix prompts [6], [22]. Cloze prompts\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n5\nFig. 4. This study distinguishes between two types of prompts, namely cloze\nprompts (illustrated in a) and prefix prompts (illustrated in b), where slot [x]\nrepresents the input text and slot [z] represents the answer text.\nrefer to a slot that needs to be filled in the middle of the\ntemplate text. For example, in sentiment analysis, when X\n= “I love this movie,” the template may take the form of “\n[X]. Overall, it was a [Z] movie.” Then, the new sentence\nX’ becomes “I love this movie. Overall it was a [Z] movie.”\nThis is an example of cloze prompts as shown in Figure 4(a).\nPrefix prompts, on the other hand, refer to the input text being\nentirely situated before the generated answer text Z. As shown\nin Figure 4(b), “English: [X] Chinese:[Z]”.\nPrompt engineering refers to the process of creating a\nprompt function that guides a model to perform effectively in\ndownstream tasks. This process typically involves two steps.\nFirst, a template is applied, which is a text string that contains\ntwo slots: an input slot [X] for the input text x and an answer\nslot [Z] for the intermediately generated answer text z that will\nlater be mapped into the final output y. Then, the input slot\n[X] is filled with the input text x [1].\nIt is important to note that in prompt engineering, prompts\nare not only in the form of natural language but can also be\ngenerated continuous vector embeddings [22]. This part will\nbe discussed in detail in section three. By utilizing prompt\nengineering techniques, model performance and efficiency\ncan be significantly improved, providing better support and\nassistance for downstream tasks.\nIII. TYPES OF PROMPTS\nIn the realm of scientific research, prompts play a crucial\nrole in guiding large models to produce accurate outputs. As\nshown in Figure 5 Prompts are broadly categorized into two\ntypes: manual prompts and automated prompts [1]. Manual\nprompts are meticulously crafted by human experts to provide\nexplicit instructions to the model on what type of data to focus\non and how to approach the task at hand. These prompts are\nparticularly effective when the input data is well-defined and\nthe output must conform to a specific structure or format.\nHowever, manual prompts have certain limitations that can-\nnot be overlooked. Creating effective manual prompts requires\nsignificant expertise and time, and even minor changes to the\nprompts can have a great impact on model predictions [14]–\n[19]. This is especially true for complex tasks where providing\nclear and effective prompts is a challenging endeavor. To\naddress these limitations, researchers have developed various\nautomated methods to design prompts.\nFig. 5. Prompt engineering can be broadly categorized into two types: man-\nual prompts and automated prompts. Manual prompts encompass zero-shot\nprompting and few-shot prompting, both of which rely on human expertise\nfor their manual configuration. On the other hand, automated prompts consist\nof discrete prompting and continuous prompting, which involve the design\nof a series of automatic algorithms. Discrete prompts are typically human\ninterpretable, whereas continuous prompting usually employs learning tokens\nthat are interpretable by computers.\nAutomated prompts have gained popularity due to their\nefficiency and adaptability. These prompts are generated using\nvarious algorithms and techniques, eliminating the need for\nhuman intervention [6], [20]–[22]. Discrete prompts and con-\ntinuous prompts are two common types of automated prompts.\nDiscrete prompts rely on predefined categories to generate\nresponses, while continuous prompts consider the current con-\nversation context to produce accurate outputs [1], [32]–[35].\nAdditionally, there are static prompts and dynamic prompts\nthat vary in their consideration of historical context [36], [37].\nA. Manual Prompts\nManual prompts can be used to guide models towards\nproducing the desired results for specific tasks. These prompts\nare often created based on human expertise, and are commonly\nused in LLMs to improve their performance on downstream\ntasks. For instance, the LAMA dataset introduced hand-crafted\ncloze prompts to explore the knowledge of large models [16].\nSimilarly, prefix prompts can be manually created to facilitate\ncommon sense reasoning tasks. In Chat-oriented models like\nChatGPT, zero-shot prompting is used to guide the models to-\nwards producing ideal results for downstream tasks. Addition-\nally, it is common to include prompt examples that match the\nlevel of task complexity, to further guide models in producing\naccurate outputs. In this section, we mainly discuss the few-\nshot prompting that is manually created through instruction\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n6\nwith examples selected by human experience, rather than being\nautomatically selected. As AI technology rapidly advances,\nautomated few-shot prompting techniques that select examples\nautomatically are also emerging, which will be discussed in\nsection 3.2.\n1) Zero-shot Prompting:\nThe superior performance of\nLLMs in a wide range of NLP tasks has garnered signifi-\ncant attention due to their remarkable ability to learn from\ncontext, making them an attractive tool for various research\nproblems. This emerging capability is often enhanced through\nprompt engineering to improve the performance of LLMs in\ndownstream tasks. Consequently, researchers have proposed\nvarious methods for designing prompts to guide the models’\napplications in different research questions [38].\nRecently, the development of LLMs such as GPT-3 and\nChatGPT has made the use of prompt-based methods in-\ncreasingly popular for various downstream tasks. Zero-shot\nprompting, in particular, has shown great promise, where\nproviding a well-designed prompt alone without corresponding\nexamples can lead to outstanding results. Some studies have\nsuggested that leveraging the powerful performance of GPT\ncan help us complete downstream tasks such as extraction\nand recognition, and even outperform some full-shot models\non certain datasets [17]. In the medical field, the impressive\nachievements of using LLMs to exploit their strong contextual\ncapabilities have also been observed. For instance, DeID-\nGPT proposes the use of high-quality prompts to preserve\nprivacy and summarize key information in medical data on\nChatGPT and GPT-4, achieving better results compared to\nseveral baseline methods. The study provides a foundation\nfor future research on applying medical data to LLMs [14].\nChatAug proposes a prompt-based medical data augmentation\nmethod on ChatGPT, which outperforms other popular meth-\nods. The study highlights the importance of domain knowledge\nin generating correct augmented data and suggests a fine-\ntuning approach for future research [15]. Recent work has\ninvestigated the feasibility of using manual prompts to guide\ndownstream tasks on ChatGPT and has shown that Chat-\nGPT’s performance on translation tasks can be significantly\nimproved with clear and accurate prompts [18]. Similarly,\nresearch on ChatGPT’s zero-shot prompting has also yielded\nsimilar conclusions [19]. The study presents HealthPrompt, a\nprompt-based clinical NLP framework that explores different\ntypes of prompt templates, including prefix prompts and\ncloze prompts, to improve zero-shot learning performance on\nclinical text classification tasks without requiring additional\ntraining data [32]. These findings highlight the potential of\nChatGPT to enhance models’ performances on NLP tasks with\neffective prompt design, providing valuable insights for future\nresearch in this area.\nOverall, the success of prompt-based methods has shown\ntheir great potential for further advancements, and their sig-\nnificance is likely to continue to grow in the future.\n2) Few-shot Prompting: While zero-shot prompting has\nshown impressive performance in many tasks, it still has\nsome limitations. First, it heavily relies on the performance\nof pre-trained models. Secondly, due to the flexibility of zero-\nshot prompting, its outputs may not always be accurate. In\nsuch cases, providing a small number of prompt examples\nas guidance for the model to achieve better performance has\nbecome a useful approach. Few-shot prompting can serve as\nclear and explicit prompt inputs to guide the model towards\ndesired outputs. For instance, research has been conducted\nto measure the baseline performance of GPT-4 on medical\nmultiple-choice questions (MCQs) using only a few prompt\nsamples, without the need for complex methods such as chain-\nof-thoug [39].\nThese prompt methods rely on the contextual emergence\nability of LLMs, which has demonstrated impressive perfor-\nmance on ChatGPT/GPT-4 [40]. The manual prompt-based\napproach has shown typical few-shot prompting capabilities\nin the medical text translation, text augmentation, generation,\nsummarization, and other tasks, with significant improvements\nover baseline models on public datasets [19], [41].\nB. Automated Prompts\nThe effectiveness of human-designed prompts depends on\nthe prompt designer’s expertise in selecting relevant informa-\ntion and constructing prompts in a way that is understandable\nto the model. Human prompts are particularly effective for\ntasks with well-defined input data and structured output re-\nquirements. However, designing effective human prompts re-\nquires a significant amount of time and domain-specific knowl-\nedge, making their usage in more complex tasks challenging.\nTherefore, researchers are exploring automated prompt design\nmethods to address these challenges and improve the efficiency\nand adaptability of prompt-based approaches.\n1) Discrete Prompting: Discrete prompts refer to automati-\ncally searching for templates in a discrete space, typically cor-\nresponding to natural language phrases, to provide the model\nwith guidance for generating the desired output. This approach\ncan help us design prompts more easily and improve the\nefficiency and adaptability of the model [1]. Common discrete\nprompt construction methods include prompt mining, prompt\nparaphrasing, prompt generation, and prompt scoring [42].\nPrompt mining is a method of automatically discovering\ntemplates or prompts by scraping a large text corpus for\nfrequent middle words or dependency paths between a set\nof input-output pairs. These prompts can be used for various\nnatural language processing tasks such as language modeling,\ntext classification, and question answering. The research pro-\nposes a method for prompt-based learning that automatically\nidentifies and adds prompt phrases to a prompt template for\nfine-grained detection of Alzheimer’s disease. The method\nenhances detection accuracy through the use of additional\nprompts [43].\nPrompt paraphrasing involves generating a set of candidate\nprompts from an existing seed prompt using methods such as\nround-trip translation or phrase replacement, and selecting the\none that achieves the highest training accuracy for a target task.\nThis approach can be optimized using a neural prompt rewriter\nand can be done on an individual input basis. For instance, the\narticle proposes a simple yet effective prompt method based\non paraphrasing to assist pre-trained models in learning rare\nbiomedical vocabulary, resulting in improved performance in\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n7\nbiomedical applications [44]–[46]. The STREAM framework\nleverages prompt-based language models to generate task-\nspecific logical rules for named entity tagging, reducing the\nneed for human labor. By utilizing existing prompt templates\nand continuously teaching the language model, STREAM\nachieves higher accuracy and efficiency in the tagging pro-\ncess [47].\nPrompt generation is the task of generating prompts us-\ning natural language generation models. The study proposes\nMEDIMP, a framework that generates medical prompts us-\ning automatic textual data augmentations from LLMs, and\ndemonstrates its superiority in producing high-quality prompts\nfor medical applications [33]. The paper proposes a method\nthat utilizes prompts filled with bounding box annotations to\ngenerate descriptions containing extensive hints and context\nfor instance recognition and localization. The knowledge from\nlanguage is then distilled into the detection model via maxi-\nmizing cross-modal mutual information in both image and ob-\nject levels [34]. This approach involves training prompts from\nexisting data and using these prompts to generate new data.\nThis newly generated data can then be used to define additional\nprompts, ultimately providing downstream tasks with more\nhigh-quality feature representations [35]. The study introduces\na prompt construction module that leverages medical language\ntemplates to enable pre-trained language models to extract\ncontextual information from tabular electronic health records\nand generate more comprehensive cell embeddings, which can\nbe used by a pre-trained sentence encoder to generate sentence\nembeddings as cell representations [48].\nPrompt scoring involves using language models to score\nfilled prompts for a given task and selecting the one with\nthe highest probability. This can result in a custom template\nfor each individual input, as in the case of knowledge-\nbased completion. For instance, ImpressionGPT has proposed\ndynamic prompts, which select the top-k examples with the\nhighest similarity for each input. Based on the probability and\nthreshold of the k-selected examples, the prompt for each input\nis determined. This approach, which utilizes few-shot learning,\nhas shown better performance than some full-shot learning\nmethods [49].\nThe utilization of various prompt types can greatly benefit\nlanguage models in their performance of a diverse range of\ntasks, such as natural language understanding, text generation,\nmachine translation, and question-answering. Each type of\nprompts, whether generated through prompt mining, prompt\nparaphrasing, prompt generation, or prompt scoring can be\nused independently or in combination to optimize the per-\nformance of the language model for a particular task. This\nunderscores the significance of prompt-based approaches in\nadvancing the capabilities of NLP systems.\n2) Continuous Prompting: In recent years, the development\nof LLMs has made prompt-based methods increasingly pop-\nular in various downstream tasks. In this context, continuous\nprompting (e.g., soft prompting) has emerged as a new type of\nprompts and has gained widespread attention from researchers.\nUnlike discrete prompts, continuous prompts can be operated\nin the embedding space and are no longer limited to text-\nreadable types. Additionally, continuous prompts can optimize\nparameters through tuning on training data for downstream\ntasks, which relaxes the constraints on prompts and improves\nthe efficiency of LLMs in task execution. Meanwhile, contin-\nuous prompting has been shown to be an effective alternative\nto standard model fine-tuning in cases where the data is highly\nimbalanced [50]. Discrete prompts are composed of discrete\nwords or phrases, typically in human-interpretable natural\nlanguage, to guide the model in performing downstream tasks.\nOn the other hand, continuous prompts directly prompt the\nmodel in the embedding space, without constraints on natural\nlanguage, and allow the prompts to have their own parameters\nthat can be fine-tuned using training data.\nIn the medical field, the advantages of continuous prompting\nhave been further demonstrated. Liang et al. use continuous\nprompts to introduce prompting into the model architecture as\nthe only trainable parameter to guide model output, proposing\nPromptFuse and BlindPrompt as methods for aligning different\nmodalities in a modular and parameter-efficient manner. These\nmethods require only a few trainable parameters and perform\ncomparably to several mutil-modal fusion methods in low-\nresource scenarios. The high modularity property of prompting\nallows for the flexible addition of modalities at low cost, as\nit avoids the need to fine-tune large pre-trained models [36].\nPrefixMol is a generative model that utilizes a learnable\nprompt token as prefix embedding to guide the model to\ngenerate an output that meets the desired criteria. This prompt\ntoken encodes a set of learnable features and contextual infor-\nmation about the targeted pocket’s circumstances and various\nproperties. This approach offers significant advantages over\ntraditional generative models as it allows for more precise and\nefficient control over the output [37]. Wang et al. propose an\nadaptive PromptNet for glioma grading that utilizes only non-\nenhanced MRI data and receives constraints from features of\ncontrast-enhanced MR data during training through a designed\nprompt loss. In the paper, enhanced features are used as\nprompts to guide the feature extraction of PromptNet, with an\nadaptive strategy designed to dynamically weight the prompt\nloss in a sample-based manner, thus achieving competitive\nglioma grading performance on NE-MRI data [51]. CPP\nutilizes task-specific prompts optimized with a contrastive\nprototypical loss to avoid semantic drift and prototype interfer-\nence, using prompts as learnable tokens to train task-specific\ninformation for each task. It also introduces a multi-centroid\nprototype strategy to improve prototype representativeness.\nCPP outperforms existing methods under a light memory\nbudget and improves class separation [52].\nOverall, continuous prompting is a powerful tool for im-\nproving the performance of automated systems. It helps these\nsystems to learn and adapt more quickly, and to perform more\naccurately in a wide range of applications. This technique can\nbe used in combination with other types of prompts, such\nas manual prompts and discrete prompts, to create a more\ncomprehensive and effective learning environment, which is\nalso used in multi-modal tasks such as image and speech\nrecognition to improve the accuracy and speed of the systems.\nAdditionally, continuous prompts can be tailored to the specific\nneeds of the task, which makes it highly adaptable and\nversatile.\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n8\nC. Comparison of Manual and Automated Prompts\nManual prompts refer to human-crafted prompts, while\nautomated prompts are generated by algorithms or automated\nmethods. The primary difference between manual and auto-\nmated prompts is the level of human involvement in the prompt\nconstruction process. Manual prompts are carefully designed\nby human experts, while automated prompts are generated us-\ning various search algorithms or other automated methods. The\nadvantage of manual prompts is that they are typically well-\ndesigned and can capture important aspects of the downstream\ntask. However, the manual prompt design process can be time-\nconsuming and costly. On the other hand, automated prompts\nare generated more quickly and can potentially capture more\ntask-specific information than manually crafted prompts. How-\never, the effectiveness of automated prompts heavily depends\non the quality of the search algorithms and the representation\npower of the language models.\nIn summary, both manual prompts and automated prompts\nhave their advantages and disadvantages. Manual prompts pro-\nvide greater control over the output, while automated prompts\nare more efficient and adaptable. Ultimately, the choice of\nthe prompt will depend on the specific task and available\nresources.\nIV. APPLICATIONS OF PROMPTS\nPrompt engineering enables language models to achieve\na wide range of AI tasks in the medical field with high\nperformance. With customized medical prompts, models can\naccomplish complex healthcare problems that are previously\ndifficult without huge medical datasets and resources. In the\nmedical field, the applications of prompt engineering include:\n• Classification [19], [32], [43], [50], [53]–[57]: Medical\nprompts elicit predicted diagnoses, categories or tags\nfrom models. For example, “The patient’s CT scan results\nshow: [tumor type]” can steer a model to generate “thy-\nmoma”, etc. Classification prompts provide context for\nmodel predictions in the medical domain. They are useful\nfor condition classification, diagnosis classification, etc.\n• Generation [18], [38], [58]–[63]: Open-ended medical\nprompts give models freedom to generate creative sam-\nples like case reports, draft research papers, and so on,\nfrom their knowledge. For instance, “Here is a possible\ncase report:” can lead to an original case report. Gen-\neration prompts allow unconstrained production of new\nmedical data samples. They are applicable for creative\nmedical tasks like clinical case modeling and medical\narticle writing.\n• Detection [14], [64], [65]: Medical prompts frame object\nor anomaly detection contexts and ask models to report\nentities detected. For example, “Detect any abnormal\nfindings you observe in the attached CT images”. Detec-\ntion prompts imply what medical models need to identify.\nThey are relevant for locating and classifying diseases,\nanatomical anomalies or other irregularities in medical\nimages, videos, and documents.\n• Augmentation [15], [33], [41], [66]: Medical prompts\nprovide additional context to augment data for training\nlanguage models. For example, we can input samples\nof all classes into language models like ChatGPT and\nprompt the model to generate samples that preserve\nsemantic consistency with existing labelled data. The\ngenerated data, together with original samples, are used\nto train classifier models. Augmentation prompts add\ndetails to expand medical datasets. They are useful for\nboosting model performance on certain medical tasks by\nsynthesizing more data context.\n• Question Answering [40], [67]–[73]: Medical prompts\npose questions for models to comprehend and accurately\nrespond to based on medical knowledge. For example,\n“What year was radiocontrast invented?” prompts the\nmodel to search its medical knowledge base and answer\n“1923”. Question answering prompts assess if medical\nmodels understand questions and can generate correct\nresponses by finding relevant medical information or\nfacts.\n• Inference [44], [74], [75]: Medical prompts present sce-\nnarios and have models explain their clinical reasoning or\ndiagnostic process. For example, “Here are two medical\nvariables: A = [some values], B = [some values]. Explain\nhow A affects B and why.” The model must logically\nrelate A and B based on medical knowledge. Reasoning\nprompts require coherent medical explanations and infer-\nence generation. They aim to test clinical logic, causality\nreasoning, and argumentation abilities of medical models.\nIn summary, prompt engineering provides a framework of\nadapting and improving language models for diverse medical\napplications. Prompt design is the key to unlocking model\ncapabilities for different medical problems.\nA. Classification Task\nPrompt engineering techniques show great promise for\nmedical classification tasks when annotated data is scarce.\nSome studies apply prompt-based learning with pre-trained\nlanguage models for clinical and mental health classification.\nAs shown in Table I.\n1) Medical image analysis: GPT4MIA utilizes the Gener-\native Pre-trained Transformer (GPT) as a plug-and-play infer-\nence model for medical image analysis (MIA) classification\ntasks [53]. The authors theoretically justify using GPT-3, a\nlarge pre-trained language model, for MIA. They develop\nprompt engineering techniques like improved prompt structure\ndesign, sample selection, and prompt ordering to enhance\nGPT4MIA’s efficiency and effectiveness in detecting predic-\ntion errors and improving accuracy for image classification.\nGPT4MIA, working with established vision models, shows\nstrong performance on these tasks.\n2) Clinical text classification: HealthPrompt proposes a\nnovel prompt-based clinical NLP framework that applies\nprompt engineering to pre-trained language models for classi-\nfying clinical texts without training data [32]. Deep learning\nmodels need large annotated datasets, but these are lacking for\nclinical NLP. HealthPrompt addresses this by using prompt-\nbased learning to tune pre-trained language models for new\ntasks by defining prompt templates instead of fine-tuning the\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n9\nTABLE I\nAPPLICATIONS OF PROMPT ENGINEERING IN CLASSIFICATION TASKS\nReference\nTask\nPrompt type\nDataset\nHighlight\nYang et al. [76]\nMulti-label classification\nDiscrete\nUS Veterans Health Administration\nCorporate Data Warehouse\nautoregressive model\nWang et al. [51]\nAuxiliary glioma diganosis\nContinuous\nBraTS\nPromptNet\nKolluru et al. [77]\nText classification and genera-\ntion\nDiscrete\nPRONCI\nMTGEN and UNIGEN model\nNiu et al. [78]\nLung cancer diagnosis\nContinuous\nNLST, LUNA16, LUNG-PET-CT-\nDx2\nCLIP and BioGPT\nSivarajkumar\net\nal. [32]\nClinical text classification\nDiscrete\nMIMIC-III\nDefining a prompt template\nYang et al. [79]\nFew-shot dialogue state track-\ning\nDiscrete\nMultiWOZ 2.0 and 2.1\nSOLOIST as base model\nMin et al. [80]\nFew-shot text classification\nManual\nSST-2, SST-5, MR, CR, Ama-\nzon, Yelp, TREC, AGNews, Ya-\nhoo, DBPedia and Subj\nAkrout [54]\nData augmentation, Skin con-\ndition classification\nManual\nLAION datasets\nA Clip-based text encoder, U-net\nbased latent space generator and\nVAE based image decoder\nZhu et al. [55]\nKidney stone classification\nCollect 1496 kidney stone images\nfrom 5 different videos.\nLamichhane [19]\nMental health classification\nManual\nStress Detection Dataset, Depres-\nsion Detection Dataset, Suicidality\nDetection Dataset\nChatGPT (GPT-3.5)\nDeyoung et al. [81]\nDisease inference\nDiscrete\nThe Evidence Inference dataset\nfine-tuned BERT\nElfrink [50]\nEarly prediction of lung cancer\nContinuous\nData from patients of General Prac-\ntitioners.\nTransformer-based pretrained lan-\nguage models\nWang et al. [43]\nAlzheimer’s disease diagnosis\nDiscrete\nADReSS20 Challenge dataset\nBERT and RoBERTa\nLin et al. [57]\nMultiple instance learning\nContinuous\nCamelyon16. TCGA-NSCLC\nChen et al. [56]\nMedical\nvision-and-language\npre-training\nContinuous\nROCO, MedICaT, MIMIC-CXR\nTaylor et al. [82]\nClinically meaningful decision\nMIMIC-III\nYao et al. [83]\nDistinguishing Disease Symp-\ntoms\nManual\nBioLAMA\nKeicher et al. [84]\nDiagnosis of disease;\nContinuous\nMIMIC-CXR-JPG v2.0.0\nCLIP\nDiao et al. [85]\nMolecular property prediction\nContinuous\nBBBP,\nBACE,\nClinTox,\nTox21,\nSIDER, HIV, MUV, and ToxCast.\nPrompting function\nRao et al. [86]\nDense prediction\nDiscrete\nADE20K\nLanguage-guided fine-tuning with\ncontextaware prompting\nYao et al. [87]\nPrompt probing\nManual\nLMC-EHRs\nOn BERT, RoBERTa, BioBERT,\nClinicalBERT, 3 kinds of BioLMs,\nand 3 kinds of BlueBERTs.\nZhang et al. [53]\nMedical image classification,\nTransductive inference\nManual\nRetinaMNIST, FractureMNIST3D\ndatasets\nGPT4MIA\nYang et al. [35]\nDrug synergy classification\nDiscrete\nBLIAM\nSung et al. [88]\nPredict/retrieve\nbiomedical\nknowledge\nManual\nCTD, UMLS, Wikidata\nBioLAMA\nmodels. An analysis of HealthPrompt using six pre-trained\nlanguage models in a no-data setting shows that prompts\neffectively capture the context in clinical texts and achieve\ngood performance without training data.\n3) Mental health classification: ChatGPT, an LLM-based\nmodel, demonstrates strong zero-shot performance in classi-\nfying social media posts for three mental health tasks: stress\ndetection, depression detection, and suicidality detection [19].\nLLMs show promise for NLP mental health applications but\nneed data, which ChatGPT addresses using prompt-based\nlearning. ChatGPT outperforms the baseline model, indicating\nthe potential of language models for mental health classifica-\ntion, especially when data is limited.\nB. Generation Task\n1) Medical image generation: Chambon et al. demonstrate\nhow selective fine-tuning and meaningful evaluation enable\nthe Stable Diffusion generative model to generate medical\nimages from clinical prompts [58]. By customizing Stable\nDiffusion for the medical domain through focusing fine-tuning\nand assessing performance with clinically tailored metrics, the\nauthors translate domain knowledge into model capabilities\nfor sensitive generation where data is scarce. Their methods\nand results highlight the promise of prompt engineering to\nimpart specialized expertise to models for nuanced generation\nto address real-world challenges. However, fully realizing this\npotential will require continued progress in techniques for\nmodel adaptation and domain-specific evaluation.\n2) Medical text generation: NapSS presents a “summarize-\nthen-simplify” strategy to coherently simplify medical text\n[59]. NapSS generates summaries and narrative prompts to\nrespectively train a model to extract key content and guide a\ngenerator to clarify it while preserving the flow of the text.\nEvaluated on medical text, NapSS improves on baselines in\nlexical, semantic, and human metrics. This highlights how\nmulti-stage prompt engineering achieves nuanced, domain-\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n10\nTABLE II\nAPPLICATIONS OF PROMPT ENGINEERING IN GENERATION TASKS\nreference\ntask\nprompt type\ndataset\nhighlight\nWang et al. [60]\nMedical text generation\nManual\nMIMIC-CXR\nChatGPT\nChambon et al. [58]\nGenerate medical images\nDiscrete\nCheXpert, MIMIC-CXR\nStable Diffusion model\nYang et al. [89]\nMedical text generation\nDiscrete\nMR, IMDB, SNLI\nBiLSTM and BERT\nLu et al. [59]\nAutomated text simplification\nDiscrete\nCochrane paragraph-level medical\ntext simplification dataset\nBERT\nLehman et al. [61]\nMedical question generating\nDiSCQ, MIMIC-III\nZuccon et al. [72]\nMedical text generation\nManual\nTREC 2021 and 2022\nChatGPT\nHertz et al. [90]\nImages generation\nManual\nPrompt-to prompt editing frame-\nwork\nLiu et al. [91]\nDiscrete\nACE,ERE\nAbaho et al. [38]\nHealth outcome generation\nDiscrete\nEBM-NLP, EBM-COMET\nPosition-attention mechanism\nGao et al. [37]\nGenerating molecules\nContinuous\nCrossDocked\nPrefixMol\nNori et al. [73]\nMedical text generation\nManual\nUSMLE Sample Exam, USMLE\nSelf Assessments, MedQA, Pub-\nMedQA, MedMCQA, MMLU\nGPT-4\nKasai et al. [70]\nMedical text generation\nManual\nIGAKUQA dataset\nChatGPT, GPT-3, and GPT-4\nHolmes et al. [40]\nMedical text generation\nManual\n100-question multiple-choice\nOn\nChatGPT\n(GPT-3.5),\nChat-\nGPT (GPT-4), Bard (LaMDA), and\nBLOOMZ\nChuang et al. [92]\nClinical note generation\nContinuous\nMIMIC-CXR\nWang et al. [93]\nQuestion generation\nSQuADv1, HotpotQA\nDu et al. [94]\nNatural language generation\nDiscrete\nDSTC8\nJang et al. [71]\nMedical note generation\nManual\nKorean National Licensing Exami-\nnation\nChatGPT3.5 and ChatGPT4\nChen et al. [56]\nGeneration\nContinuous\nROCO MedICaT MIMIC-CXR\nVision-Language Pre-trained mode\nLyu et al. [18]\nClinical note generation\nManual\nAtrium Health Wake Forest Baptist\nclinical database.\nChatGPT; GPT-4\nYan et al. [95]\nEntity clustering and entity set\nexpansion\nDiscrete\neCoNLL2003, BC5CDR, WNUT\n2017, WIKI\nCLIP\nLe et al. [96]\nText generation\nDiscrete\nCHEMU-REF\nGPT-J-6B\nPeng et al. [97]\nClinical concept extraction and\nrelation extraction\nManual\nThe 2018 National NLP Clinical\nChallenges and the 2022 n2c2 chal-\nlenges\nrelevant generation requiring sophisticated evaluation.\n3) Medical report translation: Lyu et al. examine the LLM\nChatGPT’s performance in translating radiology reports into\nplain language for education [18]. Evaluated by radiologists,\nChatGPT shows promise but some inconsistency improve-\nments with better prompts. ChatGPT generates both general\nand specific recommendations based on reports. Compared\nto GPT-4, which is a newer model, ChatGPT’s performance\nis significantly outperformed, indicating LLMs’ potential for\nclinical use but requiring advanced models and prompts for\noptimized performance.\nFurther research and applications of prompt engineering in\ngeneration tasks are shown in Table II.\nC. Detection Task\n1) Medical image detection: Qin et. al show how prompt\nengineering enables vision-language models (VLM) pretrained\non natural images to transfer knowledge to medical images\n[64]. Manual prompts containing expert medical knowledge\nimprove VLM performance on medical detection tasks with\nno medical training data. Automatic prompts inject image\ndetails, further enhancing performance. Proposed approaches\noutperform default prompts on 13 medical datasets. Fine-tuned\nmodels beat supervised baselines, demonstrating VLMs can\nlearn from limited medical data by transferring knowledge\nfrom natural images. This work establishes prompt engineering\nas a key to applying VLMs in medicine and paves the way\nfor developing VLMs tailored to healthcare applications.\n2) Medical text detection: DeID-GPT is the first framework\nto de-identify text-free medical data using GPT-4’s state-of-\nthe-art NLP capabilities, which achieves the highest accuracy\nin removing private information while preserving its original\nmeaning [14]. It requires no changes for different data types\nthanks to GPT-4’s scale and in-context learning. DeID-GPT\nuses prompts to generate optimal de-identification results with\nlittle human input, showing the potential of ChatGPT and\nGPT-4 for automated medical text processing. It contributes a\nnovel and highly effective approach to the important problem -\nenabling the use of medical text data while protecting patient\nprivacy. DeID-GPT establishes GPT-4 and similar LLMs as\na means to overcome grand challenges in healthcare through\nprompt engineering and natural language understanding.\nFurther research and applications of prompt engineering in\ndetection tasks are detailed in Table III.\nD. Augmentation Task\n1) Text data augmentation: Dai et. al propose a new text\ndata augmentation method called ChatAug [15]. ChatAug uses\nthe ChatGPT language model to rephrase sentences in the\ntraining data into multiple conceptually similar but seman-\ntically different samples, enlarging the sample corpus. They\napply ChatAug to few-shot learning text classification in the\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n11\nTABLE III\nAPPLICATIONS OF PROMPT ENGINEERING IN DETECTION TASKS\nreference\ntask\nprompt type\ndataset\nhighlight\nLiu et al. [14]\nPrivacy protection task\nManual\nThe i2b2/UTHealth Challenge\nChatGPT and GPT-4\nFeng et al. [34]\nMultimodal knowledge learn-\ning\nDiscrete\nMS-COCO,\nOpenImages\nChallenge 2019\nMultimodal knowledge learning\nZhou et al. [98]\nEvent argument extraction\nDiscrete\nACE2005, RAMS, WiKiEvents\nYao et al. [99]\nEviction status classification\nDiscrete\nHER notes\nRuan et al. [48]\nMedical intervention duration\nestimation\nDiscrete\nPASA Dataset, MIMIC-III\nLanguage-enhanced\ntransformer-\nbased framework\nQin et al. [64]\nMedical image analysis\nDiscrete\nISIC 2016, DFUC 2020, CVC-300,\nCVC-ClinicDB,\nCVC-ColonDB,\nKvasir, ETIS, BCCD, CPM-17,\nTBX11k, Luna16, ADNI, TN3k\nXing et al. [100]\nObject detection\nDiscrete\nEuroSAT,\nCaltech101,\nOxfordFlowers,\nFood101,\nFGVCAircraft, DTD, OxfordPets,\nStanfordCars,\nImageNet1K,\nSun397, and UCF101\nDual-modality\nPrompt\nTuning\n(DPT) paradigm\nDing et al. [101]\nMulti Label Recognition\nContinuous\nMS-COCO,\nPASCAL\nVOC,\nNUSWIDE\nCLIP\nLin et al. [57]\nMultiple instance learning\nContinuous\nCamelyon16, TCGA-NSCLC\nTABLE IV\nAPPLICATIONS OF PROMPT ENGINEERING IN AUGMENTATION TASKS\nReference\nTask\nPrompt type\nDataset\nHighlight\nDai et al. [15]\nMedical text augmentation\nManual\nPubMed20k Dataset\nChatGPT\nMilecki et al. [33]\nMedical text augmentation\nDiscrete\nDCE MRI, ID-RCB\nChatGPT\nLo et al. [102]\nMispronunciation detection\nDiscrete\nMAS\nYuan et al. [41]\nPrivacy-Aware Data Augmen-\ntation\nManual\nClinical Trial Data, Patient EHR\nData\nLLM-based patient-trial matching\nLi et al. [66]\nImage augmentation\nManual\nCIFAR-10, CIFAR-100, Caltech10,\nStanford Cars, Flowers102, Ox-\nfordPets,DTD\nYang et al. [103]\nFew-shot semantic parsing\nDiscrete\nGeoQuery and EcommerceQuery\ndatasets\nFilling in sequential prompts with\nLMs\nmedical domain and show improved performance over state-\nof-the-art data augmentation methods in terms of both testing\naccuracy and distribution of the generated samples.\n2) Transform clinical data into prompts: Milecki et. al\npropose a new mutil-modal learning model called MEDIMP -\nMedical Images and Prompts [33]. MEDIMP translates clinical\nbiomedical data into text prompts which as input of LLMs\nto produce augmented data. Contrastive learning and image-\ntext pairs are then used to learn meaningful representations\nof medical images, i.e., renal transplant DCE MRI images.\nMEDIMP generates prompts using predefined sentence tem-\nplates and ChatGPT, aiming to learn useful representations for\nprognosis of patient status 2-4 years after transplant.\nFurther research and applications of prompt engineering in\naugmentation tasks are shown in Table IV.\nE. Question Answering Task\n1) Medical text-based QA: Singhal et. al present medical\nQA datasets, MultiMedQA and HealthSearchQA, and propose\na framework for evaluating clinical LLMs along dimensions\nlike factuality, precision, harm and bias [67]. To adapt LLMs\nlike PaLM and FlanPaLM for the medical domain, the authors\napply prompt engineering techniques like instruction prompt\ntuning, a parameter-efficient prompting approach for aligning\nLLMs to specialized domains using a few examples. The re-\nsulting model, Med-PaLM, shows encouraging improvements\nbut still lags clinicians. This work highlights the importance\nof medical QA datasets and human-centered evaluation in\ncreating beneficial clinical language models. By systematically\nevaluating tuned language models, the authors reveal gaps in\ncomprehending medical knowledge and reasoning that must\nbe addressed to develop models for healthcare.\n2) Medical image-based QA: The open-ended medical vi-\nsual QA work treats the task as a generative process. Sonsbeek\net. al develop a network to map visual features to tokens\nthat, alone with the question, directly prompt a PLM [68].\nExploring PLM fine-tuning strategies, their approach generates\nopen-ended responses that outperform others on medical QA\nbenchmarks like Slake, OVQA and PathVQA. This enables a\nPLM to understand medical images for open-ended medical\nvisual QA tasks where answers are not constrained to a\npredefined set. The work points to promising directions for\nopen-domain medical visual question answering using prompt-\nbased generative models.\n3) Medical video-based QA: Visual-Prompt Text Span Lo-\ncalization (VPTSL) proposes a novel approach to the temporal\nanswering grounding in video (TAGV) task by formulating it\nas predicting the span of timestamped subtitles that matches\nthe visual answer [69]. To bridge the semantic gap between\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n12\nTABLE V\nAPPLICATIONS OF PROMPT ENGINEERING IN QA TASKS\nReference\nTask\nPrompt type\nDataset\nHighlight\nLiu et al. [104]\nVisual question answering\nDiscrete\nGQA\nLiang et al. [36]\nVisual question answering\nContinuous\nprompt\nVQAv2\nPromptFuse and BlindPrompt\nKasai et al. [70]\nAnswering medical questions\nManual\nIGAKUQA dataset\nChatGPT, GPT-3, and GPT-4\nHolmes et al. [40]\nAnswering medical questions\nManual\n100-question multiple-choice\nChatGPT\n(GPT-3.5),\nChatGPT\n(GPT-4),\nBard\n(LaMDA),\nand\nBLOOMZ\nLiu et al. [105]\nQuestion Answer\nDiscrete\nMIT\nMovie,\nMIT\nRestaurant,\nCoNLL03\nJang et al. [71]\nAnswering medical questions\nDiscrete\nKorean National Licensing Exami-\nnation\nChatGPT3.5, ChatGPT4\nLi et al. [69]\nMedical Instructional Video\nContinuous\nMedVidQA\nLee et al. [63]\nAnswering medical questions\nManual\nDiabetes EHR dataset\nClinical Decision Transformer\ntextual questions and visual answers, VPTSL introduces visual\nprompts—highlight features obtained from video-text high-\nlighting using the question. These visual prompts are fed\ninto the PLM along with the subtitles and question. A text\nspan predictor then models these visual and textual prompts\nto predict the subtitle span. VPTSL outperforms the state-of-\nthe-art on MedVidQA by a large margin (28.36% in mIOU),\nshowing the effectiveness of visual prompts and the text span\npredictor for medical video QA. This work enables PLMs to\nground temporal answers in instructional videos by prompting\nthem with contextual visual information.\nFurther research and applications of prompt engineering in\nquestion answering tasks are detailed in Table V.\nF. Inference Task\n1) Natural language inference in radiology: Wu et. al\nevaluate ChatGPT and GPT-4 on a radiology natural language\ninference task [74]. They implement zero-shot and few-shot\nprompts in the models. The zero-shot prompt provides only\ntask instructions and sentence-question pairs, requiring the\nmodels to determine entailment with no labeled examples. The\nfew-shot prompt incorporates 10 labeled sentence-question\nexamples to provide in-context learning before the evalua-\ntion pair. By designing these prompts with varying levels\nof contextual information, the authors show that ChatGPT\nand GPT-4 can achieve over 50% accuracy on the radiology\ntask without requiring large amounts of training data. GPT-\n4 outperforms ChatGPT, indicating its greater capability. The\nresults demonstrate the feasibility of building generic models\nthat can perform well across different domains.\n2) Causal reasoning about medical variables: Long et. al\nexamine whether GPT-3 can accurately predict the presence\nor absence of edges between variables in causal graphs based\non medical context [75]. They evaluate GPT-3 using differ-\nent prompts (e.g. declarative v.s. interrogative) and linking\nverbs (e.g. “causes” v.s. “correlates with”). They find GPT-\n3’s performance varies based on these factors, indicating its\nsensitivity to user input. With well-designed prompts using\n“causes”, GPT-3 achieves over 50% accuracy on the tested\ngraphs. Further, the authors select 3 causal graphs of different\ncomplexities from the medical literature. For each graph, they\ngenerate 2000 randomly permuted sentence pairs from the\ngraph. GPT-3 predicts whether a causal edge exists between\neach pair. Its accuracy is the highest (70%-85%) on the sim-\nplest graph. Though performance decreases for the complex\ngraphs, it remains well above the 50% random baselines,\ndemonstrating GPT-3’s potential for reasoning about medical\nvariables.\nFurther research and applications of prompt engineering in\ninference tasks are shown in Table VI.\nTABLE VI\nAPPLICATIONS OF PROMPT ENGINEERING IN INFERENCE TASKS\nReference\nTask\nPrompt type\nDataset\nHighlight\nWang et al. [44]\nBiomedical natural language\ninference\nDiscrete\nMedNLI, MedSTS\nLong et al. [75]\nBuilding causal graphs\nManual\nGPT-3\nLi´evin et al. [106]\nMedical natural language in-\nference\nManual\nUSMLE, MedMCQA, PubMedQA\nGPT-3.5\nKim et al. [107]\nNatural language interaction\nDiscrete\nExtractive and multiple-choice QA\nGPT-3\nLi et al. [108]\nArithmetic Reasoning, Com-\nmonsense Reasoning, Induc-\ntive Reasoning\nDiscrete\nGSM8K\nAsDiv,\nMultiArith,\nSVAMP,\nSingleEq,\nCommon-\nsenseQA, StrategyQA, CLUTRR\nDavinci,\ntext-davinci-002\nand\ncodedavinci-002\nGao et al. [109]\nMathematical problems, Sym-\nbolic reasoning, Algorithmic\nproblems\nDiscrete\nGSM8K,\nSVAMP,\nASDIV,\nMAWPS, BIG-Bench Hard\nProgramAided Language models\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n13\nG. A Recap of Prompt Engineering for Classification, Gener-\nation, Detection, Augmentation, QA, and Inference\nThese studies highlight the potential of using prompt en-\ngineering for pre-trained language models to advance clinical\nNLP and a range of medical AI applications, especially when\nannotated data is scarce. Prompt-based learning tunes models\nfor new tasks by defining task templates instead of fine-\ntuning, helping models achieve strong performance in zero-\nshot learning scenarios where they generalize to new classes\nwithout examples. Large pre-trained language models provide\nan ideal initialization for prompt engineering across medical\ndomains and tasks when combined with effective prompt\ndesign.\nThough more work is needed, these papers demonstrate the\npromise of prompt engineering and LLMs for medical AI with\nlimited data. Prompt-based learning could help address lacks\nof annotated data and advance applications like classification,\ngeneration, detection, enhancement, question answering, and\nreasoning by unlocking models’ capabilities through tailored\nprompts. Strong zero-shot performance suggests prompt engi-\nneering may reduce data needs for medical AI versus tradi-\ntional supervised learning.\nV. CHALLENGES AND FUTURE DIRECTIONS\nThis chapter discusses the challenges, current research di-\nrections, and future opportunities and development directions\nof prompt-based methods.\nFirstly, the challenges in prompt engineering are addressed,\nincluding the data scarcity [110] in the medical NLP domain,\nthe interpretability of models, and inherent issues in prompt\nengineering.\nSecondly, the current research directions are introduced,\nwhich include prompt generation [1], [111], prompt opti-\nmization [49], mutil-modal data processing [60], and deep\nreinforcement learning [112]. These research directions aim\nto improve the effectiveness and applicability of prompt-based\nmethods, further promoting the development of the NLP field.\nLastly, the opportunities and future development directions\nof Prompt-based methods are explored, such as the devel-\nopment of multitask and mutil-modal processing and the\nexpansion of innovative Prompt design and intelligent Prompt\ngeneration [2], [49]. These opportunities and development\ndirections provide a broad space and prospects for the future\ndevelopment of Prompt-based methods.\nA. Challenges in Prompt Engineering\nWhen it comes to NLP tasks in the medical field, prompt\nengineering faces several challenges. First, medical data is\nusually limited and specialized, making it difficult to cover\nall domain knowledge and thus restricting the model’s gener-\nalization ability [14], [60]. Secondly, the medical field is rich\nin terminology and domain knowledge, but often complex,\nwhich requires effective integration of this knowledge into\nprompts [12]. Additionally, different medical tasks require\ndifferent prompt designs, which requires balancing the com-\nplexity and interpretability of prompts while also utilizing\nexisting medical domain knowledge to guide the model to\ngenerate high-quality predictions [67]. Finally, the prompt\ndesign also needs to consider how to avoid introducing any\nhuman bias or erroneous information to ensure the fairness\nand accuracy of the model [113].\nIt should be noted that NLP tasks in the medical field are\nhighly challenging as they involve a large amount of domain\nknowledge and specialized terminology, which may not be\neasily understood or processed by general NLP models [114].\nTherefore, the importance of prompt engineering in the medi-\ncal field is self-evident. These challenges include, but are not\nlimited to:\nData scarcity: In the medical field, many tasks require the\nuse of specific medical data, which is often very scarce and\ndifficult to obtain [14], [83]. Moreover, the special nature\nof medical data involves ethical issues, which poses a great\nchallenge to prompt engineering. The lack of sufficient data\nmakes it difficult to design accurate and effective prompts.\nData uncertainty: The medical field involves numerous\ndomain knowledge and terminology, which may have different\ninterpretations and usage in different texts, leading to increased\nuncertainty in prompt design [72], [83].\nModel interpretability: In the medical field, model inter-\npretability is particularly important. As it involves human\nhealth and life, the model’s prediction results need to be\nreasonably explained and justified. Therefore, in the medical\nfield, prompt design not only considers the accuracy of the\nmodel but also its interpretability [14].\nAdditionally, prompt engineering in the medical field faces\ncommon challenges in other fields, such as prompt engineer-\ning’s self-consistency issues [115], prompt leakage [116], and\nadversarial issues [117], among others. These challenges in\nmedical tasks are more severe than in other fields. Future\nresearch needs to fully consider these challenges and propose\ncorresponding solutions.\nIn summary, prompt engineering in the medical field is\ncritical to the success of NLP tasks, but it also faces various\nchallenges, such as data scarcity [118], [119] and uncertainty\n[120], model interpretability [121], [122], self-consistency\n[123], and adversarial issues [124]. Addressing these chal-\nlenges requires innovative solutions and a comprehensive\nunderstanding of the medical domain knowledge and its related\nterminology.\nB. Current Research Directions\nAs the development and application of artificial general\nintelligence (AGI) models continue to advance, researchers in\nthe medical field have also begun to apply them to various\nmedical tasks. Currently, the research direction of prompt\nengineering in the medical field is very diverse, covering\ndifferent types of prompt designs [60], multi-modal data\nprocessing [57], and deep reinforcement learning [125], among\nother aspects.\nIn terms of prompt design methods, it is necessary to con-\nsider the specific characteristics of the task and data features\nto make appropriate choices. These include simple manually\ndesigned template-style prompts, prompts based on knowledge\ngraphs [126], prompts generated based on natural language\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n14\n[127], and prompts that can be embedded as trainable parame-\nters in the model for automatic generation [78]. In multi-modal\ndata processing, integrating text and image data requires the\ndesign of appropriate prompts to guide the model to handle and\nanalyze different types of data, thereby improving the model’s\nperformance and interpretability [128]. Additionally, deep re-\ninforcement [129] learning can continuously optimize prompt\ndesign through autonomous learning, further improving the\nperformance of the model.\nIn summary, the current research direction of prompt en-\ngineering in the medical field is diverse, and researchers\ncan choose appropriate methods and techniques based on the\nrequirements of the task and data characteristics to improve\nthe performance and interpretability of the model.\nC. Opportunities and Future Directions\nIn the field of medicine, prompt engineering presents a\nwide range of opportunities and future directions for appli-\ncation. The development of LLMs such as ChatGPT and\nGPT-4 provides tremendous potential for prompt engineering\nin the medical field [130]. As an essential part of prompt-\nbased technology, prompt engineering can assist large models\nin understanding and processing medical data more accu-\nrately [131], from manual prompts to automated prompts,\nimproving the automation and intelligence of prompts [132].\nApplying automated algorithms to prompt engineering, uti-\nlizing data-driven methods to generate more intelligent and\nefficient prompts, can enhance the efficiency and accuracy of\nNLP tasks in the medical field [133]. With the emergence\nof mutil-modal information in the medical field, combining\nmultiple modalities such as text, images, and speech can\nbetter address practical problems in the medical domain [134].\nAdditionally, conducting multi-task research by integrating\nmultiple medical research tasks can provide better services\nfor clinical healthcare [135], [136]. In conclusion, prompt\nengineering is a promising area for medical NLP research,\nand future studies should focus on developing more intelligent\nand automated prompt engineering methods and exploring the\ncombination of multiple modalities and tasks.\nVI. CONCLUSION\nIn this section, we will provide a summary of the review\nand discuss its limitations and contributions.\nA. Summary of the Review\nOverall, this review article provides a comprehensive\noverview of the different prompt engineering methods and\nchallenges in the context of NLP tasks in the medical field.\nWe have presented different prompt design methods, including\nmanual and automated, discrete and continuous, and provided\nexamples to illustrate their practical applications in medical\nsettings. Additionally, we have discussed the different prompt\nengineering methods used for various medical tasks, such\nas classification, generation, detection, argumentation, recon-\nstruction, question answering, prediction, and inference tasks.\nOne key finding of this review is that prompt engineering is\na promising approach to improving the performance of NLP\ntasks in the medical field. By carefully designing prompts\nthat are tailored to specific tasks and domains, researchers can\nachieve significant improvements in accuracy and efficiency.\nHowever, there are also several challenges and limitations\nto prompt engineering that need to be addressed in future\nresearch. Moreover, the effectiveness of prompts may depend\non the specific characteristics of the task and the domain,\nwhich can vary widely across different medical applications.\nB. Limitations of the Review\nDespite the comprehensive literature search process and the\ninclusion of 333 relevant studies, it is possible that some rele-\nvant research in the field of medical NLP prompt engineering\nmay have been missed. Therefore, the scope of this review may\nnot be entirely exhaustive, and there could be other important\nstudies that are not covered.\nAdditionally, although the article covers a range of medical\ntasks and the prompt engineering methods employed in each of\nthem, there may be other tasks or research methodologies that\nare not explored. Future research in this field should, therefore,\ncontinue to investigate the potential of prompt engineering in\nother areas of medical NLP and explore additional methods\nthat may not have been considered in this review.\nC. Conclusion and Contributions\nThis review article makes a significant contribution to the\nfield by providing a comprehensive and systematic overview\nof prompt engineering methods for NLP tasks in the medical\ndomain. By covering a wide range of methods from manual to\nautomated, and from discrete to continuous, the article serves\nas a valuable reference and guide for researchers in the medical\nNLP field to help them choose and design prompts that can\nimprove model performance and efficiency. Additionally, the\narticle discusses the unique challenges posed by medical NLP\ntasks and explores the future research directions for prompt\nengineering in this field. Overall, this review article is a\nvaluable resource for medical NLP researchers and provides\ninsightful guidance for future research in this rapidly growing\nfield.\nD. Recommendations for Future Research\nIn summary, the future of NLP in the medical field looks\npromising, with more advanced techniques such as prompt\nengineering and multi-modal integration being explored. We\ncan expect to see more research in applying state-of-the-art\nmodels like ChatGPT and GPT-4 to medical NLP tasks, as well\nas developing more efficient and accurate prompt engineering\nmethods [137]. Furthermore, there is a need to explore other\nareas of NLP in medical filed [74], such as text-based medical\nimage analysis and building medical knowledge graphs.\nAs the field continues to evolve, the development of large\nmodels such as GPT-4 will further advance NLP research.\nHowever, this will also require innovation and breakthroughs\nin both hardware and software to accommodate the higher\ncomputing and resource demands.\nOverall, future work in this field will require a compre-\nhensive and precise approach that incorporates multi-modal\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n15\ninformation and large model technology to advance medical\nNLP research and applications. With the potential for cross-\ndisciplinary collaboration between medical professionals and\nNLP researchers, the possibilities for improving healthcare\nthrough NLP are vast.\nVII. ACKNOWLEDGMENT\nThis work was supported by Faculty Construction Project\nunder Grants No. 22SH0201178, 23SH0201228; Founda-\ntional Research in Specialized Disciplines under Grant No.\nG2023WD0146; National Natural Science Foundation of\nChina under Grants No. 62276050; National Natural Sci-\nence Foundation of China under Grants No. 62001410; Na-\ntional Natural Science Foundation of China under Grants No.\n61976131.\nREFERENCES\n[1] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-train,\nprompt, and predict: A systematic survey of prompting methods in\nnatural language processing,” ACM Computing Surveys, vol. 55, no. 9,\npp. 1–35, 2023.\n[2] J. White, Q. Fu, S. Hays, M. Sandborn, C. Olea, H. Gilbert, A. El-\nnashar, J. Spencer-Smith, and D. C. Schmidt, “A prompt pattern\ncatalog to enhance prompt engineering with chatgpt,” arXiv preprint\narXiv:2302.11382, 2023.\n[3] M. Hu, S. Pan, Y. Li, and X. Yang, “Advancing medical imaging with\nlanguage models: A journey from n-grams to chatgpt,” arXiv preprint\narXiv:2304.04920, 2023.\n[4] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,\nY. Zhou, W. Li, and P. J. Liu, “Exploring the limits of transfer learn-\ning with a unified text-to-text transformer,” The Journal of Machine\nLearning Research, vol. 21, no. 1, pp. 5485–5551, 2020.\n[5] X. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, “Pre-trained\nmodels for natural language processing: A survey,” Science China\nTechnological Sciences, vol. 63, no. 10, pp. 1872–1897, 2020.\n[6] B. Lester, R. Al-Rfou, and N. Constant, “The power of scale for\nparameter-efficient prompt tuning,” arXiv preprint arXiv:2104.08691,\n2021.\n[7] J. Kopaˇc, M. Bahor, and M. Sokovi´c, “Optimal machining parameters\nfor achieving the desired surface roughness in fine turning of cold pre-\nformed steel workpieces,” International Journal of Machine Tools and\nManufacture, vol. 42, no. 6, pp. 707–716, 2002.\n[8] N. Ding, S. Hu, W. Zhao, Y. Chen, Z. Liu, H. Zheng, and M. Sun,\n“Openprompt: An open-source framework for prompt-learning,” in\nProceedings of the 60th Annual Meeting of the Association for Com-\nputational Linguistics: System Demonstrations, 2022, pp. 105–113.\n[9] V. Liu and L. B. Chilton, “Design guidelines for prompt engineering\ntext-to-image generative models,” in Proceedings of the 2022 CHI\nConference on Human Factors in Computing Systems, 2022, pp. 1–\n23.\n[10] T. Sorensen, J. Robinson, C. Rytting, A. Shaw, K. Rogers, A. Delorey,\nM. Khalil, N. Fulda, and D. Wingate, “An information-theoretic ap-\nproach to prompt engineering without ground truth labels,” in Proceed-\nings of the 60th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), 2022, pp. 819–862.\n[11] G. Rong, A. Mendez, E. B. Assi, B. Zhao, and M. Sawan, “Artificial\nintelligence in healthcare: review and prediction case studies,” Engi-\nneering, vol. 6, no. 3, pp. 291–301, 2020.\n[12] L. Zhou and G. Hripcsak, “Temporal reasoning with medical data—a\nreview with emphasis on medical natural language processing,” Journal\nof biomedical informatics, vol. 40, no. 2, pp. 183–202, 2007.\n[13] R. Baud, A.-M. Rassinoux, and J.-R. Scherrer, “Natural language\nprocessing and semantical representation of medical texts,” Methods\nof information in medicine, vol. 31, no. 02, pp. 117–125, 1992.\n[14] Z. Liu, X. Yu, L. Zhang, Z. Wu, C. Cao, H. Dai, L. Zhao,\nW. Liu, D. Shen, Q. Li et al., “Deid-gpt: Zero-shot medical text de-\nidentification by gpt-4,” arXiv preprint arXiv:2303.11032, 2023.\n[15] H. Dai, Z. Liu, W. Liao, X. Huang, Z. Wu, L. Zhao, W. Liu, N. Liu,\nS. Li, D. Zhu et al., “Chataug: Leveraging chatgpt for text data\naugmentation,” arXiv preprint arXiv:2302.13007, 2023.\n[16] F. Petroni, T. Rockt¨aschel, S. Riedel, P. Lewis, A. Bakhtin, Y. Wu, and\nA. Miller, “Language models as knowledge bases?” in Proceedings\nof the 2019 Conference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP), 2019, pp. 2463–2473.\n[17] X. Wei, X. Cui, N. Cheng, X. Wang, X. Zhang, S. Huang, P. Xie,\nJ. Xu, Y. Chen, M. Zhang et al., “Zero-shot information extraction via\nchatting with chatgpt,” arXiv preprint arXiv:2302.10205, 2023.\n[18] Q. Lyu, J. Tan, M. E. Zapadka, J. Ponnatapuram, C. Niu, G. Wang, and\nC. T. Whitlow, “Translating radiology reports into plain language using\nchatgpt and gpt-4 with prompt learning: Promising results, limitations,\nand potential,” arXiv preprint arXiv:2303.09038, 2023.\n[19] B. Lamichhane, “Evaluation of chatgpt for nlp-based mental health\napplications,” arXiv preprint arXiv:2303.15727, 2023.\n[20] E. Wallace, S. Feng, N. Kandpal, M. Gardner, and S. Singh, “Universal\nadversarial triggers for attacking and analyzing nlp,” in Proceedings\nof the 2019 Conference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP), 2019.\n[21] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh,\n“Autoprompt: Eliciting knowledge from language models with auto-\nmatically generated prompts,” in Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing (EMNLP),\n2020, pp. 4222–4235.\n[22] X. L. Li and P. Liang, “Prefix-tuning: Optimizing continuous prompts\nfor generation,” in Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the 11th International\nJoint Conference on Natural Language Processing (Volume 1: Long\nPapers), 2021, pp. 4582–4597.\n[23] K. Zhou, J. Yang, C. C. Loy, and Z. Liu, “Learning to prompt for\nvision-language models,” International Journal of Computer Vision,\nvol. 130, no. 9, pp. 2337–2348, 2022.\n[24] J. D. M.-W. C. Kenton and L. K. Toutanova, “Bert: Pre-training of deep\nbidirectional transformers for language understanding,” in Proceedings\nof NAACL-HLT, 2019, pp. 4171–4186.\n[25] K. He, X. Chen, S. Xie, Y. Li, P. Doll´ar, and R. Girshick, “Masked\nautoencoders are scalable vision learners,” in Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2022, pp. 16 000–16 009.\n[26] P. J. Liu, M. Saleh, E. Pot, B. Goodrich, R. Sepassi, L. Kaiser, and\nN. Shazeer, “Generating wikipedia by summarizing long sequences,”\nin International Conference on Learning Representations, 2018.\n[27] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al.,\n“Language models are unsupervised multitask learners,” OpenAI blog,\nvol. 1, no. 8, p. 9, 2019.\n[28] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., “Language mod-\nels are few-shot learners,” Advances in neural information processing\nsystems, vol. 33, pp. 1877–1901, 2020.\n[29] A. Najar and M. Chetouani, “Reinforcement learning with human\nadvice: a survey,” Frontiers in Robotics and AI, vol. 8, p. 584075,\n2021.\n[30] W. B. Knox and P. Stone, “Interactively shaping agents via human\nreinforcement: The tamer framework,” in Proceedings of the fifth\ninternational conference on Knowledge capture, 2009, pp. 9–16.\n[31] L. Cui, Y. Wu, J. Liu, S. Yang, and Y. Zhang, “Template-based\nnamed entity recognition using bart,” in Findings of the Association\nfor Computational Linguistics: ACL-IJCNLP 2021, 2021, pp. 1835–\n1845.\n[32] S. Sivarajkumar and Y. Wang, “Healthprompt: A zero-shot learning\nparadigm for clinical natural language processing,” arXiv preprint\narXiv:2203.05061, 2022.\n[33] L. Milecki, V. Kalogeiton, S. Bodard, D. Anglicheau, J.-M. Correas,\nM.-O. Timsit, and M. Vakalopoulou, “Medimp: Medical images and\nprompts for renal transplant representation learning,” in MIDL 2023,\n2023.\n[34] W. Feng, X. Bu, C. Zhang, and X. Li, “Beyond bounding box:\nMultimodal knowledge learning for object detection,” arXiv preprint\narXiv:2205.04072, 2022.\n[35] C. Yang, A. Woicik, H. Poon, and S. Wang, “Bliam: Literature-\nbased data synthesis for synergistic drug combination prediction,” arXiv\npreprint arXiv:2302.06860, 2023.\n[36] S. Liang, M. Zhao, and H. Sch¨utze, “Modular and parameter-efficient\nmultimodal fusion with prompting,” arXiv preprint arXiv:2203.08055,\n2022.\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n16\n[37] Z. Gao, Y. Hu, C. Tan, and S. Z. Li, “Prefixmol: Target-and\nchemistry-aware molecule design via prefix embedding,” arXiv preprint\narXiv:2302.07120, 2023.\n[38] M. Abaho, D. Bollegala, P. Williamson, and S. Dodd, “Position-based\nprompting for health outcome generation,” in Proc. of The 21st BioNLP\nworkshop associated with the ACL SIGBIOMED special interest group,\n2022.\n[39] V. D. Lai, N. T. Ngo, A. P. B. Veyseh, H. Man, F. Dernoncourt, T. Bui,\nand T. H. Nguyen, “Chatgpt beyond english: Towards a comprehensive\nevaluation of large language models in multilingual learning,” arXiv\npreprint arXiv:2304.05613, 2023.\n[40] J. Holmes, Z. Liu, L. Zhang, Y. Ding, T. T. Sio, L. A. McGee, J. B.\nAshman, X. Li, T. Liu, J. Shen et al., “Evaluating large language\nmodels on a highly-specialized topic, radiation oncology physics,”\narXiv preprint arXiv:2304.01938, 2023.\n[41] J. Yuan, R. Tang, X. Jiang, and X. Hu, “Llm for patient-trial match-\ning: Privacy-aware data augmentation towards better performance and\ngeneralizability,” arXiv preprint arXiv:2303.16756, 2023.\n[42] Y. Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan, and\nJ. Ba, “Large language models are human-level prompt engineers,”\narXiv preprint arXiv:2211.01910, 2022.\n[43] Y. Wang, J. Deng, T. Wang, B. Zheng, S. Hu, X. Liu, and H. Meng,\n“Exploiting prompt learning with pre-trained language models for\nalzheimer’s disease detection,” arXiv preprint arXiv:2210.16539, 2022.\n[44] H. Wang, C. Liu, N. Xi, S. Zhao, M. Ju, S. Zhang, Z. Zhang, Y. Zheng,\nB. Qin, and T. Liu, “Prompt combines paraphrase: Teaching pre-trained\nmodels to understand rare biomedical words,” in Proceedings of the\n29th International Conference on Computational Linguistics, 2022, pp.\n1422–1431.\n[45] A. Romanov and C. Shivade, “Lessons from natural language inference\nin the clinical domain,” in Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing, 2018, pp. 1586–\n1596.\n[46] T. Gao, A. Fisch, and D. Chen, “Making pre-trained language models\nbetter few-shot learners,” in Joint Conference of the 59th Annual\nMeeting of the Association for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language Processing, ACL-\nIJCNLP 2021.\nAssociation for Computational Linguistics (ACL),\n2021, pp. 3816–3830.\n[47] T. Chen, L. Liu, X. Jia, B. Cui, H. Tang, and S. Tang, “Distilling task-\nspecific logical rules from large pre-trained models,” arXiv preprint\narXiv:2210.02768, 2022.\n[48] Y. Ruan, X. Lan, D. J. Tan, H. R. Abdullah, and M. Feng, “Medical\nintervention duration estimation using language-enhanced transformer\nencoder with medical prompts,” arXiv preprint arXiv:2303.17408,\n2023.\n[49] C. Ma, Z. Wu, J. Wang, S. Xu, Y. Wei, Z. Liu, L. Guo, X. Cai,\nS. Zhang, T. Zhang et al., “Impressiongpt: An iterative optimizing\nframework for radiology report summarization with chatgpt,” arXiv\npreprint arXiv:2304.08448, 2023.\n[50] A. Elfrink, I. Vagliano, A. Abu-Hanna, and I. Calixto, “Soft-prompt\ntuning to predict lung cancer using primary care free-text dutch medical\nnotes,” arXiv preprint arXiv:2303.15846, 2023.\n[51] Y. Wang, W. Huang, C. Li, X. Zheng, Y. Lin, and S. Wang, “Adaptive\npromptnet for auxiliary glioma diagnosis without contrast-enhanced\nmri,” arXiv preprint arXiv:2211.07966, 2022.\n[52] Z. Li, L. Zhao, Z. Zhang, H. Zhang, D. Liu, T. Liu, and D. N. Metaxas,\n“Steering prototype with prompt-tuning for rehearsal-free continual\nlearning,” arXiv preprint arXiv:2303.09447, 2023.\n[53] Y. Zhang and D. Z. Chen, “Gpt4mia: Utilizing geneative pre-trained\ntransformer (gpt-3) as a plug-and-play transductive model for medical\nimage analysis,” arXiv preprint arXiv:2302.08722, 2023.\n[54] M. Akrout, B. Gyepesi, P. Holl´o, A. Po´or, B. Kincs˝o, S. Solis,\nK. Cirone, J. Kawahara, D. Slade, L. Abid et al., “Diffusion-\nbased data augmentation for skin disease classification: Impact across\noriginal medical datasets to fully synthetic images,” arXiv preprint\narXiv:2301.04802, 2023.\n[55] W. Zhu, R. Zhou, Y. Yuan, C. Timothy, R. Jain, and J. Luo, “Segprompt:\nUsing segmentation map as a better prompt to finetune deep models for\nkidney stone classification,” arXiv preprint arXiv:2303.08303, 2023.\n[56] Z. Chen, S. Diao, B. Wang, G. Li, and X. Wan, “Towards unifying\nmedical vision-and-language pre-training via soft prompts,” arXiv\npreprint arXiv:2302.08958, 2023.\n[57] Y. Lin, Z. Zhao, Z. ZHU, L. Wang, K.-T. Cheng, and H. Chen,\n“Exploring visual prompts for whole slide image classification with\nmultiple instance learning,” arXiv preprint arXiv:2303.13122, 2023.\n[58] P. Chambon, C. Bluethgen, C. P. Langlotz, and A. Chaudhari, “Adapt-\ning pretrained vision-language foundational models to medical imaging\ndomains,” arXiv preprint arXiv:2210.04133, 2022.\n[59] J. Lu, J. Li, B. C. Wallace, Y. He, and G. Pergola, “Napss: Paragraph-\nlevel medical text simplification via narrative prompting and sentence-\nmatching summarization,” arXiv preprint arXiv:2302.05574, 2023.\n[60] S. Wang, Z. Zhao, X. Ouyang, Q. Wang, and D. Shen, “Chatcad:\nInteractive computer-aided diagnosis on medical image using large\nlanguage models,” arXiv preprint arXiv:2302.07257, 2023.\n[61] E. Lehman, V. Lialin, K. Y. Legaspi, A. J. R. Sy, P. T. S. Pile, N. R. I.\nAlberto, R. R. R. Ragasa, C. V. M. Puyat, I. R. I. Alberto, P. G. I.\nAlfonso et al., “Learning to ask like a physician,” arXiv preprint\narXiv:2206.02696, 2022.\n[62] T. Weber, M. Ingrisch, B. Bischl, and D. R¨ugamer, “Cascaded latent\ndiffusion models for high-resolution chest x-ray synthesis,” arXiv\npreprint arXiv:2303.11224, 2023.\n[63] S. Lee, D. Y. Lee, S. Im, N. H. Kim, and S.-M. Park, “Clinical\ndecision transformer: Intended treatment recommendation through goal\nprompting,” arXiv preprint arXiv:2302.00612, 2023.\n[64] Z. Qin, H. Yi, Q. Lao, and K. Li, “Medical image understanding\nwith pretrained vision language models: A comprehensive study,” arXiv\npreprint arXiv:2209.15517, 2022.\n[65] Y. Ye, Y. Xie, J. Zhang, Z. Chen, and Y. Xia, “Uniseg: A prompt-\ndriven universal segmentation model as well as a strong representation\nlearner,” arXiv preprint arXiv:2304.03493, 2023.\n[66] B. Li, X. Wang, X. Xu, Y. Hou, Y. Feng, F. Wang, and W. Che,\n“Semantic-guided image augmentation with pre-trained models,” arXiv\npreprint arXiv:2302.02070, 2023.\n[67] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung,\nN. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl et al., “Large language\nmodels encode clinical knowledge,” arXiv preprint arXiv:2212.13138,\n2022.\n[68] T. van Sonsbeek, M. M. Derakhshani, I. Najdenkoska, C. G. Snoek, and\nM. Worring, “Open-ended medical visual question answering through\nprefix tuning of language models,” arXiv preprint arXiv:2303.05977,\n2023.\n[69] B. Li, Y. Weng, B. Sun, and S. Li, “Towards visual-prompt temporal\nanswering grounding in medical instructional video,” arXiv preprint\narXiv:2203.06667, 2022.\n[70] J. Kasai, Y. Kasai, K. Sakaguchi, Y. Yamada, and D. Radev, “Evaluating\ngpt-4 and chatgpt on japanese medical licensing examinations,” arXiv\npreprint arXiv:2303.18027, 2023.\n[71] D. Jang and C.-E. Kim, “Exploring the potential of large language\nmodels in traditional korean medicine: A foundation model approach to\nculturally-adapted healthcare,” arXiv preprint arXiv:2303.17807, 2023.\n[72] G. Zuccon and B. Koopman, “Dr chatgpt, tell me what i want to hear:\nHow prompt knowledge impacts health answer correctness,” arXiv\npreprint arXiv:2302.13793, 2023.\n[73] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz,\n“Capabilities of gpt-4 on medical challenge problems,” arXiv preprint\narXiv:2303.13375, 2023.\n[74] Z. Wu, L. Zhang, C. Cao, X. Yu, H. Dai, C. Ma, Z. Liu, L. Zhao, G. Li,\nW. Liu et al., “Exploring the trade-offs: Unified large language models\nvs local fine-tuned models for highly-specific radiology nli task,” arXiv\npreprint arXiv:2304.09138, 2023.\n[75] S. Long, T. Schuster, A. Pich´e, S. Research et al., “Can large language\nmodels build causal graphs?” arXiv preprint arXiv:2303.05279, 2023.\n[76] Z. Yang, S. Kwon, Z. Yao, and H. Yu, “Multi-label few-shot icd coding\nas autoregressive generation with prompt,” in Proceedings of the AAAI\nConference on Artificial Intelligence, vol. 37, no. 4, 2023, pp. 5366–\n5374.\n[77] K. Kolluru, G. Stanovsky et al., ““covid vaccine is against covid but\noxford vaccine is made at oxford!” semantic interpretation of proper\nnoun compounds,” in Proceedings of the 2022 Conference on Empirical\nMethods in Natural Language Processing, 2022, pp. 10 407–10 420.\n[78] C. Niu and G. Wang, “Ct multi-task learning with a large image-text\n(lit) model,” bioRxiv, pp. 2023–04, 2023.\n[79] Y. Yang, W. Lei, P. Huang, J. Cao, J. Li, and T.-S. Chua, “A dual\nprompt learning framework for few-shot dialogue state tracking,” in\nProceedings of the ACM Web Conference 2023, 2023, pp. 1468–1477.\n[80] S. Min, M. Lewis, H. Hajishirzi, and L. Zettlemoyer, “Noisy channel\nlanguage model prompting for few-shot text classification,” arXiv\npreprint arXiv:2108.04106, 2021.\n[81] J. DeYoung, E. Lehman, B. Nye, I. Marshall, and B. C. Wallace,\n“Evidence inference 2.0: More data, better models,” in Proceedings of\nthe 19th SIGBioMed Workshop on Biomedical Language Processing,\n2020, pp. 123–132.\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n17\n[82] N. Taylor, Y. Zhang, D. Joyce, A. Nevado-Holgado, and A. Kormilitzin,\n“Clinical prompt learning with frozen language models,” arXiv preprint\narXiv:2205.05535, 2022.\n[83] Z. Yao, Y. Cao, Z. Yang, V. Deshpande, and H. Yu, “Extracting\nbiomedical factual knowledge using pretrained language model and\nelectronic health record context,” arXiv preprint arXiv:2209.07859,\n2022.\n[84] M. Keicher, K. Mullakaeva, T. Czempiel, K. Mach, A. Khakzar, and\nN. Navab, “Few-shot structured radiology report generation using\nnatural language prompts,” arXiv preprint arXiv:2203.15723, 2022.\n[85] C. Diao, K. Zhou, X. Huang, and X. Hu, “Molcpt: Molecule continuous\nprompt tuning to generalize molecular representation learning,” arXiv\npreprint arXiv:2212.10614, 2022.\n[86] Y. Rao, W. Zhao, G. Chen, Y. Tang, Z. Zhu, G. Huang, J. Zhou,\nand J. Lu, “Denseclip: Language-guided dense prediction with context-\naware prompting,” in 2022 IEEE/CVF Conference on Computer Vision\nand Pattern Recognition (CVPR).\nIEEE, 2022, pp. 18 061–18 070.\n[87] Z. Yao, Y. Cao, Z. Yang, and H. Yu, “Context variance evaluation of\npretrained language models for prompt-based biomedical knowledge\nprobing,” AMIA Summits on Translational Science Proceedings, vol.\n2023, p. 592, 2023.\n[88] M. Sung, J. Lee, S. Yi, M. Jeon, S. Kim, and J. Kang, “Can language\nmodels be biomedical knowledge bases?” in Proceedings of the 2021\nConference on Empirical Methods in Natural Language Processing,\n2021, pp. 4723–4734.\n[89] Y. Yang, P. Huang, J. Cao, J. Li, Y. Lin, J. S. Dong, F. Ma, and J. Zhang,\n“A prompting-based approach for adversarial example generation and\nrobustness enhancement,” arXiv preprint arXiv:2203.10714, 2022.\n[90] A. Hertz, R. Mokady, J. Tenenbaum, K. Aberman, Y. Pritch, and\nD. Cohen-or, “Prompt-to-prompt image editing with cross-attention\ncontrol,” in The Eleventh International Conference on Learning Rep-\nresentations, 2022.\n[91] X. Liu, H.-Y. Huang, G. Shi, and B. Wang, “Dynamic prefix-tuning\nfor generative template-based event extraction,” in Proceedings of the\n60th Annual Meeting of the Association for Computational Linguistics\n(Volume 1: Long Papers), 2022, pp. 5216–5228.\n[92] Y.-N. Chuang, R. Tang, X. Jiang, and X. Hu, “Spec: A soft prompt-\nbased calibration on mitigating performance variability in clinical notes\nsummarization,” arXiv preprint arXiv:2303.13035, 2023.\n[93] X. Wang, B. Liu, S. Tang, and L. Wu, “Qrelscore: Better evaluating\ngenerated questions with deeper understanding of context-aware rele-\nvance,” in Proceedings of the 2022 Conference on Empirical Methods\nin Natural Language Processing, 2022, pp. 562–581.\n[94] Y. Du, S. Oraby, V. Perera, M. Shen, A. Narayan-Chen, T. Chung,\nA. Venkatesh, and D. Hakkani-Tur, “Schema-guided natural language\ngeneration,” in Proceedings of the 13th International Conference on\nNatural Language Generation, 2020, pp. 283–295.\n[95] A. Yan, J. Li, W. Zhu, Y. Lu, W. Y. Wang, and J. McAuley, “Clip\nalso understands text: Prompting clip for phrase understanding,” arXiv\npreprint arXiv:2210.05836, 2022.\n[96] N. T. Le, F. Bai, and A. Ritter, “Few-shot anaphora resolution in\nscientific protocols via mixtures of in-context experts,” in Findings of\nthe Association for Computational Linguistics: EMNLP 2022, 2022,\npp. 2693–2706.\n[97] C. Peng, X. Yang, Z. Yu, J. Bian, W. R. Hogan, and Y. Wu, “Clinical\nconcept and relation extraction using prompt-based machine reading\ncomprehension,” Journal of the American Medical Informatics Associ-\nation: JAMIA, p. ocad107.\n[98] J. Zhou, Q. Zhang, Q. Chen, L. He, and X.-J. Huang, “A multi-format\ntransfer learning model for event argument extraction via variational\ninformation bottleneck,” in Proceedings of the 29th International\nConference on Computational Linguistics, 2022, pp. 1990–2000.\n[99] Z. Yao, J. Tsai, W. Liu, D. A. Levy, E. Druhl, J. I. Reisman, and\nH. Yu, “Automated identification of eviction status from electronic\nhealth record notes,” Journal of the American Medical Informatics\nAssociation, p. ocad081, 2023.\n[100] Y. Xing, Q. Wu, D. Cheng, S. Zhang, G. Liang, P. Wang, and Y. Zhang,\n“Dual modality prompt tuning for vision-language pre-trained model,”\nIEEE Transactions on Multimedia, 2023.\n[101] Z. Ding, A. Wang, H. Chen, Q. Zhang, P. Liu, Y. Bao, W. Yan, and\nJ. Han, “Exploring structured semantic prior for multi label recognition\nwith incomplete labels,” in Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, 2023, pp. 3398–3407.\n[102] T.-H. Lo, S.-Y. Weng, H.-J. Chang, and B. Chen, “An effective end-to-\nend modeling approach for mispronunciation detection,” arXiv preprint\narXiv:2005.08440, 2020.\n[103] J. Yang, H. Jiang, Q. Yin, D. Zhang, B. Yin, and D. Yang, “Seqzero:\nFew-shot compositional semantic parsing with sequential prompts and\nzero-shot models,” arXiv preprint arXiv:2205.07381, 2022.\n[104] Y. Liu, W. Wei, D. Peng, and F. Zhu, “Declaration-based prompt tuning\nfor visual question answering,” arXiv preprint arXiv:2205.02456, 2022.\n[105] A. T. Liu, W. Xiao, H. Zhu, D. Zhang, S.-W. Li, and A. Arnold,\n“Qaner: Prompting question answering models for few-shot named\nentity recognition,” arXiv preprint arXiv:2203.01543, 2022.\n[106] V. Li´evin, C. E. Hother, and O. Winther, “Can large language models\nreason about medical questions?” arXiv preprint arXiv:2207.08143,\n2022.\n[107] Y.-H. Kim, S. Kim, M. Chang, and S.-W. Lee, “Leveraging pre-trained\nlanguage models to streamline natural language interaction for self-\ntracking,” arXiv preprint arXiv:2205.15503, 2022.\n[108] Y. Li, Z. Lin, S. Zhang, Q. Fu, B. Chen, J.-G. Lou, and W. Chen,\n“On the advance of making language models better reasoners,” arXiv\npreprint arXiv:2206.02336, 2022.\n[109] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan,\nand G. Neubig, “Pal: Program-aided language models,” arXiv preprint\narXiv:2211.10435, 2022.\n[110] A. Azaria, A. Ekblaw, T. Vieira, and A. Lippman, “Medrec: Using\nblockchain for medical data access and permission management,” in\n2016 2nd international conference on open and big data (OBD). IEEE,\n2016, pp. 25–30.\n[111] Y. He, S. Zheng, Y. Tay, J. Gupta, Y. Du, V. Aribandi, Z. Zhao,\nY. Li, Z. Chen, D. Metzler et al., “Hyperprompt: Prompt-based task-\nconditioning of transformers,” in International Conference on Machine\nLearning.\nPMLR, 2022, pp. 8678–8690.\n[112] V. Franc¸ois-Lavet, P. Henderson, R. Islam, M. G. Bellemare, J. Pineau\net al., “An introduction to deep reinforcement learning,” Foundations\nand Trends® in Machine Learning, vol. 11, no. 3-4, pp. 219–354, 2018.\n[113] E. Crothers, N. Japkowicz, and H. Viktor, “Machine generated text: A\ncomprehensive survey of threat models and detection methods,” arXiv\npreprint arXiv:2210.07321, 2022.\n[114] Z. Chen, Q. Zhou, Y. Shen, Y. Hong, H. Zhang, and C. Gan, “See, think,\nconfirm: Interactive prompting between vision and language models for\nknowledge-based visual reasoning,” arXiv preprint arXiv:2301.05226,\n2023.\n[115] P. Wang, H. Gao, X. Guo, C. Xiao, F. Qi, and Z. Yan, “An experimental\ninvestigation of text-based captcha attacks and their robustness,” ACM\nComputing Surveys, vol. 55, no. 9, pp. 1–38, 2023.\n[116] F. Perez and I. Ribeiro, “Ignore previous prompt: Attack techniques\nfor language models,” in NeurIPS ML Safety Workshop, 2022.\n[117] K. McGuffie and A. Newhouse, “The radicalization risks of gpt-3 and\nadvanced neural language models,” arXiv preprint arXiv:2009.06807,\n2020.\n[118] P. Rajpurkar, E. Chen, O. Banerjee, and E. J. Topol, “Ai in health and\nmedicine,” Nature medicine, vol. 28, no. 1, pp. 31–38, 2022.\n[119] X. Liu, J. Zhao, J. Li, B. Cao, and Z. Lv, “Federated neural architecture\nsearch for medical data security,” IEEE transactions on industrial\ninformatics, vol. 18, no. 8, pp. 5628–5636, 2022.\n[120] K. Wang, B. Zhan, C. Zu, X. Wu, J. Zhou, L. Zhou, and Y. Wang,\n“Semi-supervised medical image segmentation via a tripled-uncertainty\nguided mean teacher model with contrastive learning,” Medical Image\nAnalysis, vol. 79, p. 102447, 2022.\n[121] A. M. Barragan-Montero, A. Bibal, M. Huet, C. Draguet, G. Valdes,\nD. Nguyen, S. Willems, L. Vandewinckele, M. Holmstrom, F. Lofman\net al., “Towards a safe and efficient clinical implementation of machine\nlearning in radiation oncology by exploring model interpretability,\nexplainability and data-model dependency,” Physics in Medicine &\nBiology, 2022.\n[122] X. Li, H. Xiong, X. Li, X. Wu, X. Zhang, J. Liu, J. Bian, and\nD. Dou, “Interpretable deep learning: Interpretation, interpretability,\ntrustworthiness, and beyond,” Knowledge and Information Systems,\nvol. 64, no. 12, pp. 3197–3234, 2022.\n[123] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou, “Self-\nconsistency improves chain of thought reasoning in language models,”\narXiv preprint arXiv:2203.11171, 2022.\n[124] R. U. Rasool, H. F. Ahmad, W. Rafique, A. Qayyum, and J. Qadir,\n“Security and privacy of internet of medical things: A contemporary\nreview in the age of surveillance, botnets, and adversarial ml,” Journal\nof Network and Computer Applications, p. 103332, 2022.\n[125] T. Zhong, Y. Wei, L. Yang, Z. Wu, Z. Liu, X. Wei, W. Li, J. Yao,\nC. Ma, X. Li, D. Zhu, X. Jiang, J.-F. Han, D. Shen, T. Liu, and\nT. Zhang, “Chatabl: Abductive learning via natural language interaction\nwith chatgpt,” arXiv preprint arXiv:2304.11107, 2023.\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n18\n[126] B. R. Andrus, Y. Nasiri, S. Cui, B. Cullen, and N. Fulda, “Enhanced\nstory comprehension for large language models through dynamic\ndocument-based knowledge graphs,” in Proceedings of the AAAI Con-\nference on Artificial Intelligence, vol. 36, 2022, pp. 10 436–10 444.\n[127] A. Gilson, C. W. Safranek, T. Huang, V. Socrates, L. Chi, R. A. Taylor,\nD. Chartash et al., “How does chatgpt perform on the united states\nmedical licensing examination? the implications of large language mod-\nels for medical education and knowledge assessment,” JMIR Medical\nEducation, vol. 9, no. 1, p. e45312, 2023.\n[128] F. Behrad and M. S. Abadeh, “An overview of deep learning methods\nfor multimodal medical data mining,” Expert Systems with Applica-\ntions, p. 117006, 2022.\n[129] B. Jacob, A. Kaushik, P. Velavan, and M. Sharma, “Autonomous\ndrones for medical assistance using reinforcement learning,” Advances\nin Augmented Reality and Virtual Reality, pp. 133–156, 2022.\n[130] Y. Liu, T. Han, S. Ma, J. Zhang, Y. Yang, J. Tian, H. He, A. Li,\nM. He, Z. Liu et al., “Summary of chatgpt/gpt-4 research and per-\nspective towards the future of large language models,” arXiv preprint\narXiv:2304.01852, 2023.\n[131] J. S. Chen and S. L. Baxter, “Applications of natural language pro-\ncessing in ophthalmology: present and future,” Frontiers in Medicine,\nvol. 9, 2022.\n[132] M.\nThakur,\nS.\nDhanalakshmi,\nH.\nKuresan,\nR.\nSenthil,\nR. Narayanamoorthi, and K. W. Lai, “Automated restricted boltzmann\nmachine classifier for early diagnosis of parkinson’s disease using\ndigitized spiral drawings,” Journal of Ambient Intelligence and\nHumanized Computing, vol. 14, no. 1, pp. 175–189, 2023.\n[133] E. A. Martin, A. G. D’Souza, S. Lee, C. Doktorchik, C. A. Eastwood,\nand H. Quan, “Hypertension identification using inpatient clinical notes\nfrom electronic medical records: an explainable, data-driven algorithm\nstudy,” Canadian Medical Association Open Access Journal, vol. 11,\nno. 1, pp. E131–E139, 2023.\n[134] M. A. Azam, K. B. Khan, S. Salahuddin, E. Rehman, S. A. Khan, M. A.\nKhan, S. Kadry, and A. H. Gandomi, “A review on multimodal medical\nimage fusion: Compendious analysis of medical modalities, multimodal\ndatabases, fusion techniques and quality metrics,” Computers in biology\nand medicine, vol. 144, p. 105253, 2022.\n[135] R. Chengoden, N. Victor, T. Huynh-The, G. Yenduri, R. H. Jhaveri,\nM. Alazab, S. Bhattacharya, P. Hegde, P. K. R. Maddikunta, and\nT. R. Gadekallu, “Metaverse for healthcare: A survey on potential\napplications, challenges and future directions,” IEEE Access, 2023.\n[136] Q. D. Buchlak, N. Esmaili, C. Bennett, and F. Farrokhi, “Natural\nlanguage processing applications in the clinical neurosciences: A\nmachine learning augmented systematic review,” Machine Learning in\nClinical Neuroscience: Foundations and Applications, pp. 277–289,\n2022.\n[137] B. Kutela, K. Msechu, S. Das, and E. Kidando, “Chatgpt’s scientific\nwritings: A case study on traffic safety,” Available at SSRN 4329120,\n2023.\n",
  "categories": [
    "cs.AI"
  ],
  "published": "2023-04-28",
  "updated": "2024-03-23"
}