{
  "id": "http://arxiv.org/abs/2305.07637v3",
  "title": "Text2Cohort: Facilitating Intuitive Access to Biomedical Data with Natural Language Cohort Discovery",
  "authors": [
    "Pranav Kulkarni",
    "Adway Kanhere",
    "Paul H. Yi",
    "Vishwa S. Parekh"
  ],
  "abstract": "The Imaging Data Commons (IDC) is a cloud-based database that provides\nresearchers with open access to cancer imaging data, with the goal of\nfacilitating collaboration. However, cohort discovery within the IDC database\nhas a significant technical learning curve. Recently, large language models\n(LLM) have demonstrated exceptional utility for natural language processing\ntasks. We developed Text2Cohort, a LLM-powered toolkit to facilitate\nuser-friendly natural language cohort discovery in the IDC. Our method\ntranslates user input into IDC queries using grounding techniques and returns\nthe query's response. We evaluate Text2Cohort on 50 natural language inputs,\nfrom information extraction to cohort discovery. Our toolkit successfully\ngenerated responses with an 88% accuracy and 0.94 F1 score. We demonstrate that\nText2Cohort can enable researchers to discover and curate cohorts on IDC with\nhigh levels of accuracy using natural language in a more intuitive and\nuser-friendly way.",
  "text": "TEXT2COHORT: FACILITATING INTUITIVE ACCESS TO BIOMEDICAL DATA WITH\nNATURAL LANGUAGE COHORT DISCOVERY\nPranav Kulkarni, Adway Kanhere, Paul H. Yi, Vishwa S. Parekh\nUniversity of Maryland Medical Intelligent Imaging (UM2ii) Center,\nUniversity of Maryland School of Medicine, Baltimore, MD 21201\nABSTRACT\nThe Imaging Data Commons (IDC) is a cloud-based database\nthat provides researchers with open access to cancer imag-\ning data, with the goal of facilitating collaboration. However,\ncohort discovery within the IDC database has a significant\ntechnical learning curve. Recently, large language models\n(LLM) have demonstrated exceptional utility for natural lan-\nguage processing tasks. We developed Text2Cohort, a LLM-\npowered toolkit to facilitate user-friendly natural language co-\nhort discovery in the IDC. Our method translates user input\ninto IDC queries using grounding techniques and returns the\nquery’s response. We evaluate Text2Cohort on 50 natural lan-\nguage inputs, from information extraction to cohort discovery.\nOur toolkit successfully generated responses with an 88% ac-\ncuracy and 0.94 F1 score. We demonstrate that Text2Cohort\ncan enable researchers to discover and curate cohorts on IDC\nwith high levels of accuracy using natural language in a more\nintuitive and user-friendly way.\nIndex Terms— Natural Language, Cohort Discovery,\nImaging Data Commons, Large Language Model, Prompt\nEngineering\n1. INTRODUCTION\nThe National Cancer Institute’s Imaging Data Commons\n(IDC) is a cloud-based data commons that provides re-\nsearchers with open access to large-scale cancer imaging\ndatasets and tools for analysis, with the goal of facilitating\nthe sharing of imaging data and promoting collaboration in\nthe field of medical imaging research [1, 2, 3]. The IDC is\nhosted on the Google Cloud Platform (GCP) with the DICOM\nmetadata across all IDC collections indexed in the form of a\nBigQuery relational database to enable powerful queries and\ncohort discovery for any IDC user. However, curating cohorts\nby querying the BigQuery database requires extensive knowl-\nedge of the data schema, knowledge of Structured Query\nLanguage (SQL), and a sandbox environment with Python to\naccess, curate, and download the imaging data on IDC. This\nis a major bottleneck for users without extensive knowledge\nCorresponding author: vparekh@som.umaryland.edu\nFig. 1. The Text2Cohort toolkit on an example natural lan-\nguage user input. Text2Cohort first transforms the user input\ninto a query, uses the generated query to query the BigQuery\ndatabase, and returns the response back to the user.\nof the data schema or technical skills to effectively query\nthese datasets and curate multi-collection cohorts.\nRecently, large language models (LLMs) with billions of\nparameters pre-trained on enormous corpus’ of text data, such\nas news articles, books, and web pages on the entire internet\nare revolutionizing the field of natural language processing\nwith exceptional ability to understand and respond to natural\nlanguage queries [4, 5, 6]. At their core, LLMs learn to iden-\ntify patterns and relationships between words and phrases in\nthe text and develop an understanding of the structure and\ngrammar of language. LLM models like GPT-3.5 have pre-\nviously demonstrated exceptional capabilities in generating\nSQL queries from natural language input in zero- and few-\nshot scenarios [7, 8, 9, 10, 11]. However, LLMs occasionally\nhallucinate generating incorrect queries with syntactical or se-\nmantic errors, requiring expert understanding to identify and\ncorrect these errors [7]. These errors could significantly limit\nthe translational capability of LLMs for use by non-experts.\nFurthermore, executing the generated SQL queries would still\nneed a sandbox environment with Python to access the data\nand retrieve query’s response.\nTo that end, we developed Text2Cohort, an end-to-end\nnatural language cohort-discovery toolkit that would enable\nresearchers to interact with and discover cohorts from mul-\ntiple collections on IDC simultaneously in a more intuitive\nand user-friendly way, thus eliminating the learning curve as-\narXiv:2305.07637v3  [cs.LG]  25 Nov 2023\nFig. 2. Illustration of the Text2Cohort toolkit.\nsociated with writing SQL queries or understanding the IDC\ndatabase schema (Fig. 1). Text2Cohort uses self-supervised\nautocorrection to iteratively identify and correct hallucina-\ntions in the generated SQL queries and return the query’s cor-\nrect response to the user. We evaluated our framework on 50\nnatural language queries ranging from information extraction\nto cohort curation with varying levels of complexity to evalu-\nate for hallucination correction and response generation.\n2. MATERIALS AND METHODS\n2.1. Text2Cohort\nThe Text2Cohort toolkit is built using GPT-3.5 and consists\nof four major components: (1) prompt engineering, (2) Big-\nQuery generation, (3) BigQuery autocorrection, and (4) co-\nhort extraction, as illustrated in Fig. 2.\n2.1.1. Prompt Engineering\nWhile GPT-3.5 provides a sophisticated interface for nat-\nural language processing, it is crucial ground the model\nvia prompt engineering to provide contextual information,\nfocus the model’s responses for the task at hand, and mini-\nmize hallucinations. In other words, this enables a zero-shot\nfine-tuning of the model’s capabilities for the given task. In\nText2Cohort, we utilize prompt engineering to prime GPT-3.5\nfor query generation as follows:\n1. Query from the public BigQuery database, which contains\nDICOM metadata for all collections hosted by the IDC.\n2. Queries should be as specific as possible without provid-\ning explanations behind responses to reduce time taken to\ngenerate queries.\n3. Queries must be generated enclosed within fixed delim-\niters to simplify query extraction.\n4. Queries should utilize regular expressions in queries to\nprevent exact matches, thus resulting in a more general-\nizable query structure.\n2.1.2. BigQuery Generation\nOnce GPT-3.5 is primed for query generation, the user can en-\nter a free-text query such as ”How many male brain MRI im-\nages are hosted on IDC?” or ”I want all images in the NSCLC\nRadiomics collection”.\nThis input is fed to the model for\ninterpretation and query generation. The resultant query is\nextracted from the response and queried to IDC’s BigQuery\ndatabase using the GCloud SDK’s BigQuery client.\n2.1.3. BigQuery Autocorrection\nIn many cases, GPT-3.5 generates an incorrect query contain-\ning errors that can be classified under two groups: (1) syn-\ntax errors and (2) semantic errors. Syntax errors can occur\nFig. 3. Illustration of the autocorrection pipeline for an ex-\nample user input. The example demonstrates how the auto-\ncorrection pipeline recursively autoengineers the prompt to\nguide the LLM towards using the keyword SeriesDescription\nto filter different MRI sequences.\nTable 1. An example of Text2Cohort’s generated queries and responses on five natural language user inputs.\ndue a typo or an incorrectly labeled field, while semantic er-\nrors can occur due to an incorrect interpretation of the input\ntext. Text2Cohort implements an autocorrect pipeline to ad-\ndress both errors. As shown in Fig. 3, the autocorrection\npipeline ingests the associated error message when the gen-\nerated query is incorrect and passes back to GPT-3.5 to in-\nterpret the error and attempt to fix it. Text2Cohort’s auto-\ncorrect pipeline is implemented recursively to attempt query\nautocorrection until the query is executed successfully. How-\never, there are a few limitations to our autocorrection pipeline:\n(1) In some cases, semantic errors may not be corrected if the\nunderlying query is executed successfully, thus resulting in an\nincorrect response, and (2) we limit autocorrection to at most\n10 attempts to prevent token usage from exceeding OpenAI’s\nAPI token limit.\n2.1.4. Cohort Extraction\nThe cohort extraction component of the Text2Cohort toolkit\nuses the generated and autocorrected query to query the Big-\nQuery database and extract the resultant table as a Pandas\ndataframe in Python.\n2.2. Experiments\nTo initiate our study, we curated a dataset of n = 50 natural\nlanguage user inputs to evaluate Text2Cohort, with queries\nranging from information extraction to cohort discovery,\nlike ”How many male and female patients are present in the\nNSCLC Radiomics dataset?” and ”Please curate a dataset\nof all male brain MRI patients hosted on IDC”. The toolkit\nwas evaluated on these natural language user inputs and the\nresultant queries and responses were expert-verified by con-\nsensus between two computer scientists as either correct or\nincorrect; disagreements were adjudicated by a third com-\nputer scientist. The efficacy of the natural language toolkit\nwas consequently measured by its accuracy and F1 scores\nacross all user inputs. For user inputs that generated incorrect\nqueries and responses, the query was corrected by an expert\nand the Levenshtein distance between the corrected query\nand the incorrect query was calculated. In short, the Leven-\nshtein distance measures the minimum number of character\nmodifications to change one string into another\n3. RESULTS\nOur results indicate that on all 50 curated natural language\nuser inputs, across information extraction and cohort discov-\nery tasks, Text2Cohort demonstrates excellent performance\nwith an accuracy of 88% and F1 score of 0.94 in generating\ncorrect responses to the user inputs. The performance of the\ntoolkit on an example set of information extraction and cohort\ndiscovery queries is illustrated in Table 1. In other words, the\ntoolkit generated correct queries and responses to 44 out of 50\nuser inputs (88%) but failed to do so for six user inputs (12%),\nas shown in Table 2. Out of these six incorrect responses, one\n(17%) resulted in a query that exceeded the maximum number\nof autocorrection attempts, while five (83%) failed due to se-\nmantic errors within the generated queries. Furthermore, out\nof the five responses containing semantic errors, three (60%)\nfailed due to the generated query using an incorrect field for\nthe task. These six incorrect queries were manually corrected\nby an expert with 12.83 ± 5.81 character-edits determined\nby the Levenshtein distance between the corrected and incor-\nrect queries (Table 2). In short, our results demonstrate that\ndespite failing to correct 10% of all queries due to semantic\nerrors, Text2Cohort has the ability to generate queries with\ncorrect structure and autocorrect syntax errors within them\nwith a 98% success rate.\n4. DISCUSSION\nText2Cohort yields excellent results in translating natural lan-\nguage user input into powerful database queries, and subse-\nquently into responses, through prompt engineering and auto-\nTable 2. Natural language user inputs to which Text2Cohort generated incorrect responses. Expert corrected queries are\nprovided. Errors highlighted in red and corrections highlighted in blue.\ncorrection. Furthermore, it demonstrates the utility of LLMs\nto facilitate natural language information extraction and co-\nhort discovery by enabling a more intiutive and user-friendly\ninterface to the IDC and other similar databases. Further-\nmore, it eliminates the need for a technical understanding of\ndatabases and the underlying data schema. In other words,\nour work demonstrates that not only does Text2Cohort revo-\nlutionize how researchers can discover cohorts, interact with,\nand access imaging data hosted on the IDC, it also democra-\ntizes access to the IDC.\nHowever, the utility of the Text2Cohort toolkit is lim-\nited due to a few bottlenecks. Firstly, Text2Cohort requires\nan understanding of the entire data schema to reach its full\npotential.\nIn our study, we observed that all incorrect re-\nsponses were due to the lack of an understanding of the data\nschema (e.g., incorrectly interpreting collections as studies).\nWhile it is evident that LLM can encode facts, they are prone\nto fabricating facts without appropriate supervision [12].\nText2Cohort’s autocorrection pipeline functions as weak su-\npervision by allowing the model to interpret and correct any\nerrors generated while querying.\nHowever, autocorrection\nis limited in its utility when handling semantic errors. For\nexample, a query containing semantic errors may success-\nfully execute, bypass autocorrection, and return an incorrect\nresponse. Despite being held back by a limited knowledge of\nthe data schema, our results indicate that Text2Cohort always\ngenerates queries with correct structure and any queries with\nsyntax or semantic errors can be corrected by an expert with\nminimal character-edits.\nRecently, the paradigm of in-context learning has enabled\nzero-shot fine-tuning of LLMs using contextual information\nas a method for supervision [13, 14, 15, 10, 16]. For exam-\nple, the open source package Llamaindex implements data\nconnectors to pass various data sources as context to a GPT\nmodel [17].\nFor future work, we intend to explore these\nin-context learning techniques to address these limitations\nin Text2Cohort, while comparing with other state-of-the-art\nlanguage models.\nFurthermore, we intend to release our\ndataset of natural language user inputs for others in the re-\nsearch community to also experiment with other techniques\nand languages models.\n5. COMPLIANCE WITH ETHICAL STANDARDS\nThis research study was conducted retrospectively using\nhuman subject data made available open access by the Na-\ntional Cancer Institute’s Imaging Data Commons (https:\n//portal.imaging.datacommons.cancer.gov/\nexplore). Ethical approval was not required as confirmed\nby the license attached with the open access data.\n6. ACKNOWLEDGMENTS\nNo funding was received for conducting this study. The au-\nthors have no relevant financial or non-financial interests to\ndisclose.\n7. REFERENCES\n[1] Andrey Fedorov, William JR Longabaugh, David Pot,\nDavid A Clunie, Steve Pieper, Hugo JWL Aerts, Andr´e\nHomeyer, Rob Lewis, Afshin Akbarzadeh, Dennis Bon-\ntempi, et al.,\n“Nci imaging data commons,”\nCancer\nresearch, vol. 81, no. 16, pp. 4188, 2021.\n[2] Robert L Grossman, Allison Heath, Mark Murphy,\nMaria Patterson, and Walt Wells, “A case for data com-\nmons: toward data science as a service,” Computing in\nscience & engineering, vol. 18, no. 5, pp. 10–20, 2016.\n[3] Peng Jiang, Sanju Sinha, Kenneth Aldape, Sridhar Han-\nnenhalli, Cenk Sahinalp, and Eytan Ruppin, “Big data in\nbasic and translational cancer research,” Nature Reviews\nCancer, vol. 22, no. 11, pp. 625–639, 2022.\n[4] Salman Khan, Muzammal Naseer, Munawar Hayat,\nSyed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak\nShah, “Transformers in vision: A survey,” ACM com-\nputing surveys (CSUR), vol. 54, no. 10s, pp. 1–41, 2022.\n[5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al., “Language models are few-shot learners,”\nAdvances in neural information processing systems, vol.\n33, pp. 1877–1901, 2020.\n[6] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\nHiroaki Hayashi, and Graham Neubig,\n“Pre-train,\nprompt, and predict: A systematic survey of prompting\nmethods in natural language processing,” ACM Com-\nputing Surveys, vol. 55, no. 9, pp. 1–35, 2023.\n[7] Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao,\nDonovan Ong, Bin Chen, and Jian Su, “Battle of the\nlarge language models: Dolly vs llama vs vicuna vs gua-\nnaco vs bard vs chatgpt–a text-to-sql parsing compari-\nson,” arXiv preprint arXiv:2310.10190, 2023.\n[8] Nitarshan Rajkumar, Raymond Li, and Dzmitry Bah-\ndanau, “Evaluating the text-to-sql capabilities of large\nlanguage models,”\narXiv preprint arXiv:2204.00498,\n2022.\n[9] Ayush Kumar, Parth Nagarkar, Prabhav Nalhe, and San-\njeev Vijayakumar, “Deep learning driven natural lan-\nguages text to sql query conversion: A survey,” arXiv\npreprint arXiv:2208.04415, 2022.\n[10] Zhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei\nHu, Yumao Lu, Zicheng Liu, and Lijuan Wang, “An\nempirical study of gpt-3 for few-shot knowledge-based\nvqa,” Proceedings of the AAAI Conference on Artificial\nIntelligence, vol. 36, no. 3, pp. 3081–3089, 2022.\n[11] Xuemei Dong, Chao Zhang, Yuhang Ge, Yuren Mao,\nYunjun Gao, Jinshu Lin, Dongfang Lou, et al.,\n“C3:\nZero-shot text-to-sql with chatgpt,”\narXiv preprint\narXiv:2307.07306, 2023.\n[12] Jonathan H Choi, Kristin E Hickman, Amy Monahan,\nand Daniel Schwarcz,\n“Chatgpt goes to law school,”\nAvailable at SSRN, 2023.\n[13] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim\nRockt¨aschel, Yuxiang Wu, Alexander H Miller, and Se-\nbastian Riedel, “How context affects language models’\nfactual predictions,” arXiv preprint arXiv:2005.04611,\n2020.\n[14] Alexander Rau,\nStephan Rau,\nAnna Fink,\nHien\nTran, Caroline Wilpert, Johanna Nattenmueller, Jakob\nNeubauer, Fabian Bamberg, Marco Reisert, and Max-\nimilian F Russe,\n“A context-based chatbot surpasses\ntrained radiologists and generic chatgpt in following the\nacr appropriateness guidelines,” medRxiv, pp. 2023–04,\n2023.\n[15] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan\nScales, David Dohan, Ed Chi, Nathanael Sch¨arli, and\nDenny Zhou,\n“Large language models can be eas-\nily distracted by irrelevant context,”\narXiv preprint\narXiv:2302.00093, 2023.\n[16] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer, “Rethinking the role of demonstrations: What\nmakes in-context learning work?,”\narXiv preprint\narXiv:2202.12837, 2022.\n[17] Jerry Liu, “LlamaIndex,” 11 2022.\n",
  "categories": [
    "cs.LG",
    "cs.CL",
    "cs.HC",
    "cs.IR"
  ],
  "published": "2023-05-12",
  "updated": "2023-11-25"
}