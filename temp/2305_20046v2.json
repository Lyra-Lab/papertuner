{
  "id": "http://arxiv.org/abs/2305.20046v2",
  "title": "Assessing Language Disorders using Artificial Intelligence: a Paradigm Shift",
  "authors": [
    "Charalambos Themistocleous",
    "Kyrana Tsapkini",
    "Dimitrios Kokkinakis"
  ],
  "abstract": "Speech, language, and communication deficits are present in most\nneurodegenerative syndromes. They enable the early detection, diagnosis,\ntreatment planning, and monitoring of neurocognitive disease progression as\npart of traditional neurological assessment. Nevertheless, standard speech and\nlanguage evaluation is time-consuming and resource-intensive for clinicians. We\nargue that using machine learning methodologies, natural language processing,\nand modern artificial intelligence (AI) for Language Assessment is an\nimprovement over conventional manual assessment. Using these methodologies,\nComputational Language Assessment (CLA) accomplishes three goals: (i) provides\na neuro-cognitive evaluation of speech, language, and communication in elderly\nand high-risk individuals for dementia; (ii) facilitates the diagnosis,\nprognosis, and therapy efficacy in at-risk and language-impaired populations;\nand (iii) allows easier extensibility to assess patients from a wide range of\nlanguages. By employing AI models, CLA may inform neurocognitive theory on the\nrelationship between language symptoms and their neural bases. Finally, it\nsignals a paradigm shift by significantly advancing our ability to optimize the\nprevention and treatment of elderly individuals with communication disorders,\nallowing them to age gracefully with social engagement.",
  "text": "1 \n \n \n \n \n \n \n \nAssessing Language Disorders using Artificial Intelligence: a Paradigm Shift \nCharalambos Themistocleous1, Kyrana Tsapkini2, Dimitrios Kokkinakis3 \n1Department of Special Needs Education, University of Oslo, Oslo Norway \n2Department of Neurology, Johns Hopkins University, Baltimore, MD, USA \n3Department of Swedish, University of Gothenburg, Gothenburg, Sweden \n \n \n \n \n \nAuthor Note \nData collection and preliminary analysis were sponsored by the University of Oslo, Department \nof Special Needs Education. We have no conflicts of interest to disclose. \nCorrespondence concerning this article should be addressed to Charalambos K. Themistocleous, \nDepartment of Special Needs Education, Helga Engs hus 4.etg Sem Sælands vei 7 0371 OSLO. \nEmail: charalampos.themistokleous@isp.uio.no  \n \n \n2 \n \nAbstract \nSpeech, language, and communication deficits are present in most neurodegenerative syndromes. \nThey enable the early detection, diagnosis, treatment planning, and monitoring of neurocognitive \ndisease progression as part of traditional neurological assessment. Nevertheless, standard speech \nand language evaluation is time-consuming and resource-intensive for clinicians. We argue that \nusing machine learning methodologies, natural language processing, and modern artificial \nintelligence (AI) for Language Assessment is an improvement over conventional manual \nassessment. Using these methodologies, Computational Language Assessment (CLA) \naccomplishes three goals: (i) provides a neuro-cognitive evaluation of speech, language, and \ncommunication in elderly and high-risk individuals for dementia; (ii) facilitates the diagnosis, \nprognosis, and therapy efficacy in at-risk and language-impaired populations; and (iii) allows \neasier extensibility to assess patients from a wide range of languages. By employing AI models, \nCLA may inform neurocognitive theory on the relationship between language symptoms and their \nneural bases. Finally, it signals a paradigm shift by significantly advancing our ability to optimize \nthe prevention and treatment of elderly individuals with communication disorders, allowing them \nto age gracefully with social engagement. \nKeywords: AI language assessment, automated diagnosis, prognosis, therapy efficacy, \nacquired language disorders \n \n \n \n3 \n \nAssessing Language Disorders using Artificial Intelligence: A Paradigm Shift \n1 \nIntroduction \nLanguage impairments are evidenced in patients with Mild Cognitive Impairment (MCI), Primary \nProgressive Aphasia (PPA), Alzheimer's (AD), and Parkinson's Disease (PD). Patients with AD \nare characterized by a progressive deterioration in cognitive domains such as memory, executive \nfunctions, and language, which become more severe as the disease progresses. However, language \nimpairments can appear before the clinical manifestation of AD and are already evidenced in \npatients with Mild Cognitive Impairment (MCI), both in the amnestic and non-amnestic variants \n(Petersen et al., 1999). Therefore, detecting language impairments early in MCI is critical to \nprovide treatments that can prevent symptom progression. Speech, language, and communication \nsymptoms vary in patients with neurodegenerative disorders as this may depend on the affected \nbrain areas, especially in the left hemisphere. Symptom variation is especially evidenced in \npatients with Primary Progressive Aphasia (PPA), a progressive neurological condition primarily \naffecting speech and language (Gorno-Tempini et al., 2011; Mesulam, 1982, 2001). Specifically, \npatients with inferior frontal damage are characterized by agrammatism and speech apraxia as their \nprimary symptoms and are subtyped in the nonfluent/agrammatic PPA variant. Patients with \ntemporal lobe damage are characterized by semantic impairments, such as naming impairments, \nand are subtyped in the semantic variant PPA (svPPA). Finally, patients with temporal and parietal \nlobe damage are characterized by phonological errors, repetition, and naming deficits and are \nsubtyped in the logopenic variant PPA. \nAssessing language function early can inform clinical decisions concerning remediation \nand compensation of language functioning, the effects and progress of atrophy on language, \ncondition prognosis, and diagnosis (Strauss et al., 2006). The speech and language assessment \naims to determine the language functioning in patients with speech and language impairments and \nidentify deterioration of language functioning (Georgia Angelopoulou et al., 2018; Battista et al., \n2017; Beales et al., 2018; Fraser, Lundholm Fors, & Kokkinakis, 2019; Matias-Guiu et al., 2022; \nThilakaratne et al., 2022; Thomas et al., 2018). Also, it can provide an account of language \n(re)learning due to therapy, as learning is required for proper recovery and compensation \n(Krakauer, 2006). \nBased on recent findings from Computational Language Assessment (CLA) studies, a \ncollective term we use to refer to both AI and Computational Assessment tools, we argue that CLA \nis a superior approach to manual language assessment as it can detect dementia symptoms early, \nmonitor disease progression and evaluate treatment efficacy by offering a quick, easy, and \nquantifiable assessment of speech, language, and communication functioning (Themistocleous, \n2023). They can become easily accessible to patients as apps on their phones or through dedicated \nwebsites, allowing direct access to neurocognitive assessments to patients and clinicians. In \naddition, it can provide access to populations without access to a clinic for assessment, such as \npatients with mobility impairments and disadvantaged socioeconomic and language backgrounds. \nSpecifically, CLA implemented in a computational application can assist i. teleconsultation \ninforming healthcare professionals on patients in remote locations about symptom progression; ii. \n4 \n \ntelehomecare, supporting clinicians and doctors that overview and provide patient care; iii. \ntelemonitoring by providing evaluation data over time, and as such, it can work together with other \nmonitoring devices, such as devices monitoring heart rate and blood pressure to provide a holistic \npicture of patients' condition; and iv. teletherapy, delivering speech-language pathology, \naudiology, and other therapy services at a distance (Dial et al., 2019). Furthermore, such applications \ncan assist clinicians in assessing and scoring discourse from patients fast and with accuracy, \nallowing them to focus on things that matter, such as having more time to treat patients. \nIn the following, we discuss (i) the main complications of using manual diagnostic batteries \nfor language assessment in dementia diagnosis (ii) discuss applications of CLA, i.e., studies of \ncomputation and automation for language assessment. (iii) Finally, we discuss the underlying \ntechnologies and provide the main branches of CLA. \n2 \nComplications of using manual diagnostic batteries \nOver the past 50 years, standardized neurocognitive examination tests and neurolinguistic \nbatteries, such as the Boston Naming Test (BNT; Kaplan et al., 2001), Western Aphasia Battery-\nRevised (WAB-R Kertesz (2006)), Boston Diagnostic Aphasia Examination (BDAE; Goodglass \n& Kaplan, 1983), Psycholinguistic Assessment of Language Processing in Aphasia, (PALPA; Kay \net al., 1992) have been serving as the primary tools for screening patients with speech, language, \nand communication deficits. They focus on expressive language, such as naming, word finding, \nfluency, grammar, and receptive language. Language tests complement other tests for perceptual \nmotor function (e.g., visual perception and visuomotor skills), executive functioning (e.g., \nplanning, organizing, decision making, and working memory), learning and memory (e.g., \nimmediate memory, short-term memory, long-term memory), attention (processing speech and \nsustained, divided, and selective attention) (Lezak, 1995). \nManual language assessments have been helpful as a language assessment tool (Lezak, 1995). \nHowever, manual testing focuses on assessing narrow language domains, such as word and \nsentence repetition, fluency, and naming, but not language production and comprehension in \ncommunicative settings. Nevertheless, symptoms manifest in communication, such as the ability \nof an individual to recall known names of familiar persons or places to that specific individual, \nfinding words, planning the speech in the conversation, and uttering a coherent and cohesive \nspeech. The communicative aspects of language provide ecologically valid measures that better \nportray the language deficits of individuals (Cunningham & Haley, 2020; Hansen et al., 2022; Holt \net al., 2017; Kong et al., 2018; Mueller et al., 2018; Salis & DeDe, 2022; Stark et al., 2022). \nTherefore, manual standardized assessments do not comprehensively represent speech, language, \nand communication functioning and cannot inform early dementia detection, diagnosis, prognosis, \nand disease progression monitoring.  \nManual language assessments are that they are less sensitive to patients' idiosyncratic \ndeficits and conditions (Beltrami et al., 2018; Drummond et al., 2015; Drummond et al., 2019). \nPatients may perform poorly on tests for reasons unrelated to the pathology, such as fatigue, lack \nof sleep, education, and socialization opportunities. Furthermore, manual methods vary in \naccuracy among studies (Beach et al., 2012). For example, Beach et al. (2012) the sensitivity of \n5 \n \nneuropathologic examination ranged from 70.9% to 87.3%, and the specificity ranged from 44.3% \nto 70.8%. That allows the comparison of outcomes produced from sessions conducted at different \ntime points or from other clinicians.  \nSimilarly, global cognition screening tools, such as the Mini-Mental State Exam (MMSE), \nvary in sensitivity and specificity (Folstein et al., 1975). MMSE contains twelve questions \nmeasuring language, memory, attention, and orientation in time and space. It is scored out of thirty \n(30) and takes approximately five to ten minutes to administer but may last longer in patients with \ncognitive impairment. For MCI, MMSE provides a cut-off of 27/28 with a sensitivity of around \n76% and a specificity close to 75%  (Damian et al., 2011). However, its sensitivity is poor for \nright-lateralized focal brain lesions and executive and visuospatial impairments (Strauss et al., \n2006). \nPatients may also use dialectal variations, such as African American Vernacular English \n(AAVE), without enough data and standard assessments (Barnes, 2022; Labov, 1977). Also, \nmanual language assessment is usually conducted late as patients must visit a neurology clinic for \nmanual testing when the symptoms have progressed substantially and are evident to patients and \nothers (Strauss et al., 2006). However, early detection and precision in diagnosing a \nneurodegenerative disorder are critical to inform therapy and family planning. Also, manual \nlanguage assessments are difficult to administer, as they can be done only by trained personnel, \nand they are time-consuming and stressful to patients, all of which impede repeated language \nscreening and monitoring of disease progression. The grammatical analysis performed by a human \ndepends on their training, skills, knowledge of grammar, time constraints, tiredness, and other \nfactors that result in different scores depending on the person who conducts the analysis and the \nspecific conditions. \nFinally, a critical disadvantage of manual standardized batteries and tests is that they are \nlimited to language communities with the resources to produce them. Moreover, it requires \nsubstantial expertise to be adapted to other language varieties with care for keeping on the \npsychometric properties. Consequently, the lack of manual evaluations discriminates the patients \nfrom smaller language varieties. \n3 \nComputational Language Assessment  \nThe shortcomings of manual standardized assessments can be addressed by employing \nComputational Language Assessment (CLA). This language assessment approach uses artificial \nintelligence, including machine learning, natural language processing, statistical modeling, and \nsignal processing, to assess speech, language, and communication functioning. As such, we argue \nthat CLA-based evaluation of patients has several advantages over manual approaches. First, CLA \nmodels are continuously improving and evolving through learning and retraining on data, thus \nbecoming better at detecting language biomarkers of dementia. In contrast, the detection rate of \nlanguage impairment cannot improve over time in language batteries, as there is no straightforward \napproach to updating manual batteries and tests. \nAlso, CLA can offer objective measures of language functioning that do not depend on \nexaminers, expertise, the theoretical paradigms they adhere to, time constraints, and other factors \n6 \n \nand limitations, such as fatigue, lack of sleep, and use of a dialect such as AAVE. CLA  can detect \nspeech patterns and characteristics that are not visible to listeners by accessing gradient features \nwith physical meaning (e.g., fundamental frequency and vowel formants) that correspond to \nknown physical events (e.g., the vibration of the vocal folds and modification of oral cavity from \nthe active articulator) and continuous measures that cannot easily be matched to a physical \nmeaning, such as i-vectors and spectral moments (Dehak et al., 2011; DeMarco & Cox, 2013; \nGlembek et al., 2011; Hautamäki et al., 2013; Jiang et al., 2014; Lee et al., 2014; Scheffer et al., \n2011; Themistocleous, 2014, 2016a, 2016b, 2017a, 2017b, 2017c; Themistocleous et al., 2022; \nThemistocleous et al., 2016b). This is critical as it can identify patterns clinicians cannot evaluate \nwithout computational tools and distinguish characteristics not identifiable from a multifactorial \nanalysis of speech and language. \nIn contrast to manual assessments that focus on a single task at a time conducted in an \nartificial environment (cf. a picture description task, naming tasks, verbal, and semantic fluency \ntasks), CLA provides ecological speech, language, and communication measures by incorporating \nreal-world information from conversation and discourse. The latter can reveal a significant effect \nof aphasia due to dementia (Stark et al., 2022; Stark Brielle et al., 2020). Discourse and \nconversation have been known to reflect the early effects of dementia, which suggests that \ndiscourse and conversation can provide early biomarkers of dementia.  \nWritten language can also be analyzed using CLA. This analysis has been instrumental in \nproviding early biomarkers of dementia (Toledo et al., 2014). For example, researchers analyzed \ndiscourse micro-structure and macro-structure (e.g., planning, text coherence, and cohesion) in a \nlongitudinal computational study of autobiographies from Catholic sisters of the School Sisters of \nNotre Dame congregation (Danner et al., 2001) from the Nun Study of Aging and Alzheimer's \nDisease. They showed that lexical, syntactic measures and idea density could predict dementia \nover time. This project provided linguistic, social, physiological, and anatomical markers (the nuns \nhad donated their brains for posthumous study) of dementia. Other researchers identified the \ndecline in lexical and syntactic production in the works of British novelists Iris Murdoch and \nAgatha Christie (Le et al., 2011) and U.S. President Ronald Reagan (Berisha et al., 2014; Berisha \net al., 2015) and argued that they predict language function deterioration due to dementia. For \nexample, a comparative discourse analysis of talks produced by U.S. President Ronald Reagan, \nwho was diagnosed with Alzheimer's disease in 1994, and President George Herbert Walker Bush, \nwho had no known diagnosis of Alzheimer's disease, showed a significant reduction in the number \nof unique words for President Ronald Reagan over time and increase in conversational fillers and \nnon-specific nouns over time. \nCLA  machine learning models can assess discourse productions automatically and provide \nscores of language functioning concerning (i) discourse microstructure (e.g., phonetics, \nphonology, morphology, syntax, semantics) and (ii) macrostructure (e.g., discourse planning, \ncohesion, and coherence (56)) (Beaugrande & Dressler, 1981; Grice, 1975). Therefore, these \nmeasures can be employed to assess the linguistic competence of patients (Chomsky, 1965), \nnamely their knowledge of language grammar (e.g., phonetics, phonology, morphology, syntax, \n7 \n \nand semantics) and their communicative competence (Hymes, 1996; Murray et al., 2007), namely, \nhow individuals use language in the appropriate social context, follow social norms, and connect \nwith other individuals and settings.  \nComputational methods can facilitate the analysis of discourse micro- (e.g., sentence-level \ngrammatical domains) and macrostructure (e.g., textual domains, topics, cohesion, and coherence). \nCLA can provide valuable information about an individual's speech, language, and communication \nfunctioning from a short discourse sample. \n1. The acoustic and phonological analysis of speech production (e.g., speech articulation and \nprosody) evaluates the ability of individuals to perceive and produce speech sounds and \nprosody and determines the phonological representation of sounds. Speech impairments \ncommonly exist in patients with apraxia of speech, aprosodia, and phonological \nimpairments. \n2. The morphological analysis informs about the ability of individuals to form words and \nselect the grammatical information associated with word structure, such as verb tense and \naspect and case in nouns and adjectives. \n3. The syntactic analysis provides information about syntactic processing, informing about \nsyntactic comprehension and production impairments. For example, language deficits in \nrecalling names or actions can be measured by calculating parts of speech, such as verbs \nand nouns (Themistocleous, Webster, et al., 2020).  \n4. The semantic analysis determines the appropriate use of word and sentence meanings and \ncoherence of speech productions linked to semantic understanding and production \nimpairments, such as naming impairments. \n5. Pragmatics and theory of mind are linked to the ability of individuals to infer the state of \nmind of others in the conversation and express and understand communicative functions \nsuch as politeness, humor, and irony, which can become impaired in patients with \ndementia. \n6. Conversation, such as the ability of an individual to exchange conversational turns. CLA  \nprovides measures of social cognition by quantifying talk-in-interaction as a measure of \nindividuals' capacity to follow the turn-taking dynamics and social conventions in \nconversations (Sacks et al., 1974; Schegloff, 1998; Schegloff et al., 1977). This involves \nthe ability of individuals to follow the social norms of turn-taking interactions, such as \nproviding cues (e.g., prosodic and syntactic cues) for turn-transitions and turn \ncontinuations, and knowing how to deal with adjacency pairs, e.g., question-answer pair, \ngreeting-greeting pair, complaint-acceptance/denial, and invitation-acceptance/denial \n(Aijmer & Stenström, 2005; Akynova et al., 2014). Such ecological measures were \npreviously only feasible in the clinic, as discourse and conversation analysis are laborious, \nrequiring many hours of manual work conducted by an expert individual, usually a linguist. \nFurthermore, the manual analysis of discourse needs more consensus (Stark et al., 2022; \nStark Brielle et al., 2020).  \n \n8 \n \n7. Emotions are linked to the ability of individuals to express and perceive emotions in \nconversation and impairments related to emotions, such as apathy and depression. For \nexample, emotional expressions or words also manifest specific relationships to speech and \nlanguage pathology, and prosodic cues, such as low fundamental frequency and reduced \npitch accent variation, can indicate apathy and depression in speech production \n(Stockbridge et al., 2021; Wright et al., 2018).   \n \n \nThese suggest that CLA is an improved approach over manual neurolinguistic assessment \napproaches and has the potential to revolutionize neurolinguistic assessment. Next, we discuss \nmethodological approaches that aim to offer objective and accurate language assessments that are \nculturally and linguistically sensitive, thereby reducing potential biases and improving diagnostic \naccuracy. \n4 \nComponents of CLA: Assessment and Monitoring \nCLA combines different theoretical and methodological approaches to provide an optimal model \nfor assessing language, which includes Machine Learning models, Natural Language Processing, \nand acoustic analysis of speech productions. These components can be employed to understand \nthe characteristics of speech, language, and communication and to provide specific applications of \nthe assessment for diagnosis, prognosis, and treatment efficacy evaluation.  \n \n \nFigure 1  Computational Language Assessment Methodologies and Applications for Evaluating \nPatients' Speech, Language, and Communication Functioning. The methods include machine \nlearning, speech processing, natural language processing, and statistical modeling. Additional \n9 \n \nmeasures (e.g., imaging, biomarkers, sociolinguistic properties) can be included during machine \nlearning modeling for CLA applications. \n \n4.1 \nMachine Learning Models  \nMachine learning is a diverse field that encompasses a wide range of models, including Support \nVector Machines (SVM), Decision Trees (DT), Random Forests (RF), Principal Components \nAnalysis (PCA), and k-means, to name just a few. However, in recent years, Deep Neural \nNetworks (DNNs) have emerged as an extraordinarily successful approach to solving complex \nproblems. They are widely applied in various areas, including self-driving cars and robotics. \nResearch on neural networks from its early beginnings aimed to model cognitive representation, \nincluding language (e.g., McCulloch & Pitts, 1943; Rosenblatt, 1958; Turing, 1936; Turing, 1950). \nMcCulloch and Pitts (1943) simple neural network could compute logical operations. However, \nlearning was made possible a decade later by networks proposed by Rosenblatt (1958) and Hebb \n(1949) and through the formulation of backpropagation, which enabled learning in multi-layered \nnetworks in the late 1980s (Rumelhart et al., 1985; Rumelhart et al., 1988; Rumelhart et al., 1986). \nThe current deep neural network approaches, the availability of data, and improved hardware \nenable more complex high-performance learning (Hassabis et al., 2017; Lecun et al., 2015; \nSchmidhuber, 2015). Deep neural networks are currently employed for different machine learning \ntasks, such as supervised, unsupervised, and reinforcement learning (see Figure 2 and Table 1).  \nFinally, an essential aspect of learning in models, which is often underemphasized, is that \nit is constantly evolving; thus, machine learning models are always in a state of continuous \ndevelopment, which allows CLA models to improve over time with the addition of more data, \nbetter data, and the development of algorithms and methods, which is often counterintuitive to \nclinicians and researchers that have been using either the same tools (e.g., the same manual \nneurocognitive batteries and tests) or approaches, such as statistical models for hypothesis testing, \nwhere the models are approached in general as static evaluations of several data in a particular \npoint in time.  \n \n10 \n \n \nFigure 2. Supervised learning aims to teach how the features correspond to the label so that the \nmodel can predict unknown data. Unsupervised learning is a method where the model identifies \nstructure in the input data. Semi-unsupervised learning may involve a combination of unsupervised \nand supervised learning. Reinforcement learning is a method of learning incrementally by \nadjusting the model. Learned behavior is accompanied by positive feedback or reward, whereas \nbehavior to be avoided is accompanied by negative feedback. \n \nTable 1 Machine Learning Approaches. \nTerm \nDefinition \nSupervised Learning \nSupervised learning is a learning method where the input variables- a \nset of features- and the output variable- the label that describes the \nfeatures- are provided simultaneously. Supervising training aims to \nteach how the input features correspond to the label clinicians or other \nexperts provided. After training the model, it is evaluated on how well \nit can predict unknown data. \nUnsupervised \nLearning \nUnsupervised learning is a method where the model identifies \nstructure in the input data without any provided features. Semi-\nunsupervised learning may involve a combination of unsupervised \nand supervised learning. \nReinforcement \nLearning \nReinforcement learning is a method of learning incrementally by \nadjusting the network. Learned behavior is accompanied by positive \nfeedback or reward, whereas behavior to be avoided is accompanied \nby negative feedback. Positive and negative feedback depending on \n11 \n \nthe application; for example, a network that learns to play a game, \npositive feedback is earning points and negative feedback is losing \npoints. \n \nDeep neural network approaches are currently applied successfully in several language-\nrelated tasks for analyzing text, audio, and video (Baroni et al., 2017; Lazaridou et al., 2016). For \nexample, recurrent neural networks, such as long short-term memory units, simple feedforward \nneural networks, and convolutional neural networks (Bengio et al., 2012; Lecun et al., 2015; \nSchmidhuber, 2015) have been employed to elicit information from texts and for the linguistic \nanalysis of large language corpora. Also, neural networks capture semantic relationships—word \nembeddings—by identifying relationships between words (Le & Mikolov, 2014; Mikolov et al., \n2013; Pennington et al., 2014; Sutskever et al., 2014; Turian et al., 2010).  \nTo address the different tasks and applications, such as classification tasks, text generation, \nautomatic translation, and text summarization, the neural networks are combined in complex DNN \narchitectures, such as those listed in Table 2. \n \nTable 2 Main Neural Network Architectures.  \nTerm \nDefinition \nFeedforward neural network \nA network architecture with linear connections between the \nunits that make up the network. \nRecurrent Neural Networks \nand Long short-term \nmemory \nA type of recurrent neural network architecture that has been \napplied extensively in speech and text as they can model \ntemporal relations between events. A disadvantage of these \nnetworks is that they are slow. \nConvolutional neural \nnetwork \nA neural network that is inspired by the visual cortex and \nemploys filters to identify significant patterns. It has been used \nextensively in image recognition. \nGenerative Models \nA generative model, unlike a discriminative model, is a model \nthat generates both observed and target values for a \nphenomenon, given several hidden parameters. \nTransformers \nTransformers are like recurrent neural networks (RNNs) and \nlong short-term memory (LSTM) networks in that they map \nsequences of words but differ in how they handle long-range \ndependencies and context. RNNs and LSTMs process \nsequences sequentially, which makes them slow and prone to \nforgetting or ignoring distant information. On the other hand, \ntransformers use self-attention mechanisms to process the entire \nsequence in parallel, allowing them to capture long-range \ndependencies and context more effectively. \n12 \n \nLarge Language Models \nLarge language models (LLMs) are based on transformers but \nare trained on massive amounts of text data using unsupervised \nlearning. This enables them to learn complex patterns and \ngenerate realistic and coherent text. Some examples of LLM.s \nare BERT, developed by Google, and GPT-3, developed by \nOpenAI. \n \n4.2 \nNatural Language Processing \nNatural Language Processing (NLP) methods, in combination with Deep Neural Networks, are \nprofoundly transforming the analysis of the human language (Asgari et al., 2017; Calzà et al., \n2021; Fraser, Lundholm Fors, Eckerström, et al., 2019; Themistocleous, Eckerström, et al., 2018; \nTóth et al., 2018). NLP involves techniques for analyzing, studying, processing, and developing \nhuman language applications. Thus, CLA employs NLP to provide fast, efficient, and reliable \nquantification of speech, language, and communication in combination with machine learning and \nspeech analysis. Using these techniques, studying grammar becomes feasible for long texts, with \naccuracy, ease, and improved transparency, which is impossible when different humans perform \nthe analysis.  \n \n4.2.1 Lexical and Morphophonological Analysis \nThe potential of deep neural networks has been known since the 1980s. However, the acceleration \nof the field in the past three years is unparalleled, making deep neural networks the leading \nparadigm in machine learning for language analysis. Lexical and morphophonological features \ncharacterize the speech of patients with speech and language impairment and healthy controls. By \nanswering this question, we seek to provide a phonological (Vitevitch & Storkel, 2013) (e.g., \nmeasures of prosody and vowel quality) (Themistocleous, Eckerström, et al., 2020b), \nmorphological, lexical, syntactic, and semantic biomarkers that distinguish patients from healthy \ncontrols. Researchers can employ NLP methods (e.g., tokenization, tagging, and syntactic parsing) \nand machine learning to elicit novel grammatical measures and evaluate existing ones from the \nautomated transcriptions of speech productions and writings. Researchers can analyze the texts for \ngrammatical measures and evaluate the role of related measures, e.g.,  \n• \nUtterance length \n• \nPhonemes-to-word ratio: e.g., Do speakers prefer long or short words?  \n• \nContent words: e.g., Nouns, verbs, adjectives, and adverbs.  \n• \nFunction Words: e.g., Conjunctions, e.g., and, or, and, but Prepositions, e.g., de, in, pre \nand of; Determines, the and a/an; Pronouns such as he/she/it. \n• \nPart of Speech Ratio: e.g., content to function word ratio (Fraser et al., 2014; Saffran et al., \n1989; Themistocleous, Ficek, et al., 2021; Themistocleous, Webster, et al., 2020) and  \nnouns to vowels ratio. \n• \nMorphological and semantic information about the gender (e.g., male, female, neuter), \nperson (first, second, third), number (e.g., singular, plural), and time (e.g., present, past). \n13 \n \n \n4.2.2 Syntactic Analysis \nAlso, NLP analysis can provide automatic syntactic features to characterize patients with speech \nand language impairment and healthy controls, for example: \n• the calculation of probability estimates of syntactic constituents (e.g., noun phrases and \nverb phrases),  \n• syntactic complexity (e.g., dependency depth),  \n• syntactic roles \n• the ratio of coordinated, subordinated, and reduced sentences,  \n• the number of active and passive sentences,  \n• counts of dependencies (e.g., average dependencies per sentence) \nThese are calculated using automated syntactic parsers for English and other languages can \nidentify the syntactic role of textual constituents using automated syntactic analysis. Common \nparsing approaches are dependency parsing, which finds syntactic relations using a dependency \ngrammar and constituent parsing that follows a constituency grammar and constituent parsing. \nBoth are two common approaches to analyzing the grammatical structure of a sentence in natural \nlanguage processing (Jurafsky & Martin, 2009). \nDependency parsing involves identifying the grammatical relationships between words in \na sentence. It aims to identify the dependency relationships between words, where each word is \nlinked to its \"head\" word in the sentence. For example, in the sentence \"John loves Mary,\" the \nword \"loves\" depends on the subject \"John\" and the object \"Mary.\" Dependency parsing typically \nproduces a tree-like structure known as a dependency tree, which shows the relationships between \nthe words in the sentence (Jurafsky & Martin, 2009). \nConstituent parsing involves identifying the syntactic structure of a sentence by dividing it \ninto smaller sub-phrases or constituents (Jurafsky & Martin, 2009). Constituent parsing typically \nproduces a tree-like structure known as a parse tree, which shows the hierarchical structure of the \nsentence. For example, in the sentence \"The cat chased the mouse,\" the parse tree would show that \n\"the cat\" is the subject, \"chased\" is the verb, and \"the mouse\" is the object. Constituent parsing is \nused to identify the grammatical role of each word in a sentence and to determine the meaning of \nthe sentence. \n \n4.2.3 Semantic Analysis \nAutomatic semantic measures analysis aims to determine which computational semantic features \ncharacterize the speech of individuals with speech and language impairment. CLA employs \nsemantic analysis to provide quantified measures of semantic relationships, such as antonyms, \nsynonyms, semantic roles (e.g., agent, recipient, goal, and result), and entity characteristics (e.g., \nperson, location, and company) (Bengio & Heigold, 2014; Fraser, Lundholm Fors, & Kokkinakis, \n2019; Lappin & ebrary Inc., 1981; Pennington et al., 2014; Sutskever et al., 2014). \nOver the years, several methods have been employed to identify semantic relationships \nfrom texts, such as post-processing parsed texts and using regular expressions to annotate \n14 \n \nlocations, such as an address or a phone number. However, more recent semantic models rely on \nextensive textual corpora to establish semantic relationships often as part of deep neural network \narchitectures, such as recurrent neural networks and pre-trained neural network architectures, like \nBidirectional Encoder Representations from Transformer networks (BERT) (Devlin et al., 2018; \nVaswani et al., 2017), and more recently GPT4 (Bengio & Heigold, 2014; Fraser, Lundholm Fors, \n& Kokkinakis, 2019; Lappin & ebrary Inc., 1981; Pennington et al., 2014; Sutskever et al., 2014). \nWord and sentence embeddings from large language models, such as GPT, can explain semantic \nrelationships, provide semantic distances between words, and have the potential to explain neural \nactivation patterns (Hosseini et al., 2022). The embeddings are calculated using large corpora of \ntexts, and the underlying idea of these models is that words that regularly appear in similar contexts \nare closer semantically. Language models, such as chatGPT, are an exciting area of research; \nevaluating the performance of the models is not straightforward, and metrics from these models \ndo not correspond to human cognitive representations, so using them to elicit semantic measures \nthat correspond to human semantic understanding is not straightforward. For example, human and \ncomputational semantic representations are formed differently concerning multimodal sensory \ninformation and social interaction  (Bengio & Heigold, 2014; Pennington et al., 2014).  \nWord and sentence embeddings and large language models, such as GPT, can be employed \nto compare semantic productions in patients and healthy controls to measure distance scores \nbetween patients' productions and model predictions. For example, word embedding can indicate \nwhether patients produce semantically related or unrelated words in word-finding deficits, like \nnaming.   \nName Entity Recognition (N.E.R.) is a process of information extraction that can be used \nto determine how semantic relationships are presented linguistically (Jurafsky & Martin, 2009). \nFor example, Napoleon [Person] was the king of France [Place]. N.E.R. can be helpful in patients \nwith aphasia to reveal semantic impairment concerning semantic domains such as people and \nplaces. \n \n4.2.4 Discourse Macrostructure \nCLA can elicit information about cohesion and coherence, such as the following: \n• \nIdea density is a standardized measure of the number of ideas expressed in the number of \nwords or sentences (Danner et al., 2001); and measures of rhetorical structure (e.g., \nElaboration, Attribution, and Joint) (Abdalla et al., 2018). Farias et al. (2012) employed \nidea density, a computational measure, to measure cognitive decline in the Nun Study, a \nlongitudinal study of cognitive decline.  \n• \nTopics can be elicited using topic classification machine learning models, e.g., the number \nand type of discourse markers, the number of topics, and conversational measures such as \nbackground elements ('um' and 'hm'). \n• \nLexical richness is an informative measure of lexical impairments that measures, for \nexample, if speakers repeat the exact words or can access a variety of words from the \nlexicon (e.g., type-token ratio (TTR), Herdan's C (Herdan, 1955), Maas's TTR, Mean \n15 \n \nsegmental TTR, Moving-Average Type–Token Ratio (MATTR) (Covington & McFall, \n2010), word variation index, counts on function words, hapax legomena (i.e., words that \nappear once in the corpus), and n-grams, which are sequences of n (2, 3, or more) words \nthat occur in a text and can be employed to identify the speaker characteristics in a text. \n• \nSentiment analysis, lexical and semantic analysis quantify subjective information from \ntexts to analyze the emotional tone and can provide insights into the attitudes, such as the \nspeaker's stance, and positive or negative emotions associated with pathology. \n \nAnother significant development is the ability to combine language and video. This is an active \narea of research. Visual and textual alignment techniques (Arandjelovic & Zisserman, 2017; Aytar \net al., 2016; Harwath et al., 2016; Ioffe & Szegedy, 2015; Owens et al., 2015) enable researchers \nto align events in videos to texts (Karpathy & Fei-Fei, 2015). These can allow novel approaches \nto discourse assessment by aligning this to the environment. An example was provided by Pusiol \net al. (2014), who modeled the joint attention of a child and a caregiver toward an object or \nlocation. They analyzed video and texts to identify the signals of joined attention using an \nunsupervised extraction technique of joined attention episodes from video, which \"could give hints \nregarding robust cues that children might use in addition to, or even instead of, gaze.\" Their study \nassumed that joined attention is part of the overall language interaction and a necessary part of \nlanguage learning. \n \n4.3 \nAcoustic Analysis \nAcoustic Analysis can provide automatic measures of the acoustic characteristics, namely \nsegmental (vowels and consonants), prosodic (e.g., intonation, pauses, segmental lengthening), \nand voice quality production that can serve as diagnostic biomarkers. Speech analysis provides the \ntools to distinguish identity characteristics of speech production in individuals, which include \ninformation about their gender, dialect, emotional situation, physiological condition, cognitive and \nlinguistic functioning (Anastasi et al., 2017a, 2017b; G. Angelopoulou et al., 2018; Aristodemou \net al., 2015; Bernardy & Themistocleous, 2017; Themistocleous, 2014, 2016a, 2016b, 2017a, \n2017b, 2017c, 2017d, 2019; Themistocleous, Eckerström, et al., 2020a, 2020b; Themistocleous et \nal., 2019; Themistocleous, Fyndanis, et al., 2021; Themistocleous et al., 2022; Themistocleous & \nKokkinakis, 2019; Themistocleous & Logotheti, 2016; Themistocleous et al., 2016a, 2016b; \nThemistocleous, Webster, et al., 2021). \nAs speech articulation gets impaired by neurodegeneration, for example, in patients with \napraxia of speech, speech analysis can provide diagnostic biomarkers of dementia and distinguish \npatients with language communication disorders from healthy individuals. These can include \nprosodic and segmental measures (e.g., fundamental frequency and vowel formants), pause \nduration (Lopez-de-Ipina et al., 2018; López-de-Ipiña et al., 2015), the number of pauses and filled \npauses (e.g., um and hm), and phonological measures (sound deletions, insertions, transpositions), \nvariations in the quality of speech sounds (e.g., vowels and consonants), intonation errors, voice \n16 \n \nquality impairments (Themistocleous, Eckerström, et al., 2018; Themistocleous, Ficek, et al., \n2021). \n• \nVowel formants: the first five formant frequencies (F1...F5). \n• \nFormant dynamics: measurements of F1...F5 formant frequencies in steps of 5 from the \nonset of the vowel (time = 1) to the offset of the vowel (time 100): i.e., 1, 5, 10 . . . 100  \n• \nVowel Duration: the duration of vowels.  \n• \nPause duration (Mack et al. 2015) \n• \nIntonation: Fundamental frequency (F0) and related measures, such as the mean F0. \n• \nSpeech rate and fluency.  \n• \nVoice Quality: Harmonic and spectral amplitudes measures of voice quality  \nAlso, measures without physical meaning can characterize patients and healthy controls, such as \ni-vectors and spectral moments (Dehak et al., 2011; DeMarco & Cox, 2013; Glembek et al., 2011; \nHautamäki et al., 2013; Jiang et al., 2014; Lee et al., 2014; Scheffer et al., 2011; Themistocleous, \n2014, 2016a, 2016b, 2017a, 2017b, 2017c; Themistocleous et al., 2022; Themistocleous et al., \n2016b). \nThe acoustic analysis of speech productions provides explanatory measures that enable the \nidentification of the speech profile of an individual, identifying the speaker's identity and revealing \ninformation about that person's dialect, emotional state, and physiological condition (Foulkes et \nal., 2010; Preston & Niedzielski, 2010; Thomas, 2013). For example, we and others have shown \nthat acoustic analysis of vowel formants, namely the peak frequencies in vowel spectra, identify \nthe vowel and its properties, such as whether a vowel is front or back, low or high, and can assess \nminute differences between populations and the accents or dialect of the speaker (Themistocleous, \n2017a, 2017c). Also, acoustic analysis can identify the dialects of speakers from the fricative \n(Themistocleous, 2017b; Themistocleous et al., 2016b), sonorant (Themistocleous, 2019; \nThemistocleous et al., 2022), and stop consonants (Themistocleous, 2016a). These differences are \nvital in revealing differences between patients with articulatory impairments (e.g., patients with \nnfvPPA/apraxia of speech) (Georgiou & Themistocleous, 2020; Themistocleous, 2017a, 2017d).  \nFor example, Themistocleous, Eckerström, et al. (2020b) employed signal processing \ntechniques and showed that patients with MCI differ significantly from healthy controls \nconcerning voice quality measures (i.e., the amplitude of the first harmonic and the amplitude of \nthe third formant (H1-A3); cepstral peak prominence (a measure of dysphonia); the center of \ngravity indicating the voice's Mean Energy Concentration, and Shimmer (dB) (i.e., the variability \nof the amplitude from peak-to-peak (local maxima); and articulation rate/averaged speaking time. \nAlso, using acoustic measurements, we could determine the effectiveness of tDCS treatment vs. \nsham on patients with P.P.A. speech productions (Themistocleous, Webster, et al., 2021). A \nsubsequent study showed that Swedish patients with MCI differ significantly from healthy controls \nin prosody, voice quality, and fluency (Themistocleous, Eckerström, et al., 2020b). Acoustic \nanalysis of speech production can determine the speech profile of individuals with dementia and \nprovide early acoustic markers that can predict their pathology (Themistocleous, 2016a, 2017a, \n2017d; Themistocleous, Eckerström, et al., 2020b; Themistocleous et al., 2022; Themistocleous, \n17 \n \nKokkinakis, et al., 2018). These studies using acoustic analysis also demonstrated that a detailed \ncharacterization of the speech profile of individuals with dementia is pressing as it can provide \nessential and largely unexplored information for assessing speech impairments (e.g., in vowels and \nconsonants, voice quality, speech fluency, rhythm, and prosody).  \nAcoustic analysis has been employed to analyze several types of speech production tasks, such \nas diadochokinetic evaluation (DDK) of speech productions, which involves the rapid repetitions \nof syllables, such as /pa/-/ta/-/ka/, word repetition tasks, and connected speech productions. \nResearchers have employed various measures such as the Mel frequency cepstral \ncoefficients (MFCCs), measures of the fundamental frequency, such as the mean squared error \n(M.S.E.) measured relative to the regression curve, and the regression coefficient of the F0 contour \nwithin a frame, the mean value of F0, minimum and the maximum of F0, its value in the onset and \noffset, its temporal variation (jitter), its variation in amplitude (shimmer), and others (Moro-\nVelazquez et al., 2019; Orozco-Arroyave et al., 2016). For example, Tsanas et al. (2009) employed \nacoustic dysphonia measures. The Recurrence Period Density Entropy (RPDE), Detrended \nFluctuation Analysis (D.F.A.), and Pitch Period Entropy (P.P.E.) have been proposed for the \nfeasibility of identifying patients with P.D. as telemonitoring markers (Tsanas et al., 2009) and for \nclassifying these patients from healthy controls (Tsanas et al., 2012).  \n \n5 \nUsing CLA for informing diagnosis, prognosis, and treatment efficacy \nCLA integrates well with the existing neurocognitive assessment and has the potential to support \ndiagnosis and provide biomarkers and scores in cross-sectional and longitudinal studies, including \nmonitoring a patient's language functioning over time, assessing treatment efficacy, and improving \nexisting neurocognitive evaluations. These studies are discussed in this section.  \n5.1 \n(Differential) Diagnosis and Prognosis \nDuring life, the biopsy is the best determiner of dementia (along with postmortem histologic \nexamination). Nevertheless, a biopsy is rarely employed for early dementia diagnosis because of \nits high-risk ratio. Thus, our a need for diagnostic markers and biomarkers for diagnosis. Recent \nstudies have employed speech acoustics to identify individuals with dementia from healthy \ncontrols and provide classification models for diagnosis or subtyping (König et al., 2018; Meilan \net al., 2018; Themistocleous, Eckerström, et al., 2018; Themistocleous & Kokkinakis, 2019; Tóth \net al., 2018). These studies employed measures from (i) segments (i.e., vowels and consonants); \n(ii) prosody; and (iii) voice quality and speech fluency and showed that they could provide reliable \ndiagnostic markers. In addition, other studies have employed lexical and morphosyntactic to \ndistinguish speakers with speech and language pathology and other conditions (see Figure 2). \nTensorFlow (2015), Keras (2015), and PyTorch (2016) sparked an era of enthusiasm about \nneural networks and their potential in neurology and neuroscience. Among the first studies to \nutilize these tools for CLA was Themistocleous, Eckerström, et al. (2018), who developed deep \nneural network models that classify individuals with MCI from Healthy Controls. First, they \nrecorded patients and healthy individuals during the cookie-theft picture description task. \nSubsequently, the recordings were automatically transcribed and segmented. Next, they measured \n18 \n \npauses, vowel duration, and vowel formants (i.e., the frequencies that distinguish one vowel from \nanother). Their model classified individuals with MCI and healthy controls with high classification \naccuracy (M = 83%) from just one minute of conversation. In addition, their model contributed to \nthe early diagnosis of cognitive decline and showed that acoustic markers facilitate the \nidentification of patients with MCI.  \nOther studies demonstrated that lexical, morphosyntactic, and textual features provide \nlanguage biomarkers and distinguish patients with early-onset dementia from healthy controls. \nLanguage markers can also be employed for differential diagnosis determined within a group of \npatients. For example, Fraser et al. (2014) observe that differential diagnosis is hard to identify \nusing standardized tests, especially in the initial stages of the condition. In contrast, connected \nspeech has the potential to differentiate subtypes of patients. In their study, they employed natural \nlanguage processing to elicit textual measures. More specifically, they studied the number of \nwords. They provided measures of syntactic complexity estimated using the Stanford parser. One \nis the Yngve depth, which quantifies left-branching vs. right-branching phrases calculated from a \nsyntactic tree (Yngve, 1960) and measurements of Parts of Speech (P.O.S.), such as the number \nof nouns, verbs, and prepositions. These measures distinguished individuals with semantic \ndementia (S.D.), progressive nonfluent aphasia (PNFA), and healthy controls. They developed \nthree models: the Naïve Bayes, logistic regression, and Support Vector Machines. \n \nThemistocleous, Ficek, et al. (2021) used CLA to provide a classification that follows the \nconsensus criteria for PPA classification proposed by Gorno-Tempini et al. (2011). They employed \nacoustic, such as the fundamental frequency, pause duration, and morphosyntactic features, and \ntrained Random Forests, Support Vector Machines, and Decision Trees. The latter, a feedforward \nneural network, outperformed the other machine learning models and expert clinicians' \nclassifications with 80% classification accuracy. Their study showed that 90% of patients with \nnfvPPA and 95% with lvPPA were identified correctly. Others have developed Naïve Bayes \nmodels for dementia diagnosis (Garrard et al., 2014). Naïve Bayes, often with textual features \ngeneration (e.g., bag-of-words), were employed to develop good classification models for versatile \napplications, such as authorship identification and spam detection. \n \n5.2 \nCross-sectional and longitudinal assessments of language functioning \nIn clinical practice, manual scoring of language performance is extraordinarily time-consuming \nand challenging and requires substantial expertise. CLA provides a fast, objective, and quantified \nscore of speech and language performance and reduces trivial tasks, enabling clinicians to focus \non patients rather than trivial tasks. CLA has been employed to assess speech fluency, prosody, \nmorphosyntax, lexical, and semantic aspects in patients' speech. \n \nIn a recent study, researchers scored speech fluency and prosody and showed that these \nspeech features differed significantly between individuals with Mild Cognitive Impairment and \nHealthy Controls. For example, Themistocleous, Eckerström, et al. (2020b) employed signal \nprocessing to study patients' voice quality and speech fluency, showing that voice quality in \npatients with MCI differed significantly from H.C. Namely, the amplitude of the first harmonic \n19 \n \nand the amplitude of the third formant (H1-A3); cepstral peak prominence (a measure of \ndysphonia); the center of gravity indicating the voice's Mean Energy Concentration, and Shimmer \n(dB) (i.e., the variability of the amplitude from peak-to-peak (local maxima); and articulation \nrate/averaged speaking time1. \nThe evaluation of spelling is a complex, challenging, and time-consuming process. It relies \non comparing letter-to-letter words spelled by the patients to the target words. Therefore, \nThemistocleous, Neophytou, et al. (2020) developed a spelling distance algorithm that \nautomatically compares the inversions, insertions, deletions, and transpositions required to make \nthe target word and the response the same (Neophytou et al., 2018; Themistocleous, Neophytou, \net al., 2020).  \nNLP, signal processing, and machine learning can provide automated measures of language \nthat function as language biomarkers of dementia. These involve transcribing a speech and \nanalyzing transcripts using NLP to provide automated part-of-speech (POS) tagging and syntactic \nparsing. For example, Themistocleous, Webster, et al. (2020) analyzed connected speech \nproductions from 52 individuals with PPA using a morphological tagger. They showed differences \nin POS production in patients with nfvPPA, lvPPA, and svPPA. This NLP algorithm automatically \nprovides the part of speech category for all words individuals produce (Bird et al., 2009). From \nthe tagged corpus, they measured both content words (e.g., nouns, verbs, adjectives, adverbs) and \nfunction words (conjunctions, e.g., and, or, and but; prepositions, e.g., in, and of; determiners, e.g., \nthe a/an, both; pronouns, e.g., he/she/it and wh-pronouns, e.g., what, who, whom; modal verbs, \ne.g., can, should, will; possessive ending (' s), adverbial particles, e.g., about, off, up; infinitival \nto, as in to do). Themistocleous, Webster, et al. (2020) showed that the POS patterns of individuals \nwith PPA were both expected and unexpected. It showed that individuals with nfvPPA produced \nmore content words than function words (see top left for the content words and top right for the \nfunction words). Individuals with nfvPPA made fewer grammatical words than individuals with \nlvPPA and svPPA. These studies provide proof of the feasibility that computational tools can be \nemployed to study speech and language. They can form the basis for developing assessment tools \nfor scoring patients' language. By developing novel NLP language models in patients with \ndementia, researchers analyze language productions from patients with dementia and provide \nquantified scores of speech, language, and communication symptoms.  \n \n5.3 \nAssessment of Treatment Efficacy \nCLA applications can implement automated scoring during tasks to provide online feedback about \ncorrect or incorrect responses, motivating the patient to try again and self-correct. Thus, these \napplications can offer treatment and evaluation in any environment. In addition, CLA can support \nand monitor treatment for patients living in distant areas without access to memory clinics or \nhaving mobility issues. Currently, CLA methods provide objective and replicable scores of \n \n1 Articulation rate is the number of syllables divided by overall duration excluding pauses and silences whereas \naverage speaking time is a measure of the number of syllables divided by the overall duration including pauses and \nsilences). \n20 \n \nlanguage performance that take place post hoc after treatment on the recording files, the text \ntranscriptions, and the records that the clinician employed during the neuropsychological or \nneurocognitive evaluation. \nUsing acoustic analysis, Themistocleous, Webster, et al. (2021) provide an example of \nevaluations between treatments/time points. To evaluate the effects of transcranial direct current \nstimulation (tDCS), a non-invasive brain stimulation, on speech fluency in patients with nonfluent \nPrimary Progressive Aphasia (nfvPPA) and apraxia of speech (AOS.) as their primary symptom \n(nfvPPA/AOS), Themistocleous et al. 2021, extracted acoustic measures from vowels and \nconsonants from speech signals. tDCS improves functional connectivity by modulating neuronal \nexcitability by hyperpolarizing or depolarizing the resting membrane potential of neural cells. In \nother words, neurostimulation modifies the functional connectivity and the gamma-aminobutyric \nacid (GABA) concentrations. Themistocleous, Webster, et al. (2021) showed that tDCS with \nlanguage therapy enables patients to speak faster, reflected in vowels and consonants' duration. \nSound duration provides an objective measure of fluency, which measures articulatory \nperformance and shows that tDCS combined with language therapy can improve patients' language \nperformance. \n \n5.4 \nImprovement of existing neurocognitive tools \nThe accuracy of traditional screening tools can also be improved through CLA. Fraser et al. (2018) \naugmented an ML model for classification by adding automatically extracted linguistic \ninformation from a narrative speech task to MMSE scores to increase MMSE's reliability and \nevaluation outcomes. As a result, the ML model improved by adding just four linguistic features \nfrom POS. In addition, the AUC score (measuring a trade-off between sensitivity and specificity) \nimproved from 0.68 to 0.87 in logistic regression classification; a similar increase of accuracy was \nfound by adding prosodic and fluency measures (Themistocleous, Eckerström, et al., 2020a) \nemployed only acoustic measures from speech fluency and prosody. These studies show that \nmodels can corroborate existing tools, especially ones that assess linguistic and non-linguistic \ncognitive domains. The findings show that CLA can complement clinical evaluation and allow for \na timely and continuous assessment of patients. Also, it reduces evaluation time and patient stress \nthrough automation and enables time allocation for therapy and rehabilitation. \nCLA can also help automate the scoring of neurocognitive assessment tools, such as written \nlanguage evaluations. That has the advantage of providing quantified measures of spelling \naccuracy. For example, a method for comparing written speech productions concerning target \nwords was developed by Themistocleous, Neophytou, et al. (2020), who employed a modified \nLevenshtein distance to measure the spelling performance of patients in words and pseudowords. \nThe Levensthein distance is a measure used in NLP for applications that need to compare two \nstrings of letters. This algorithm was also applied to pseudo-words by converting pseudo-words to \nthe International Phonetic Alphabet (IPA) and comparing phonemes of the target and response \nword with the Levenshtein distance. The advantage of this method is that it allows an efficient \n21 \n \nevaluation of spelling performance and improves the accuracy and speed of traditional manual \nscoring methods. \n6 \nConclusions \nComputational Language Assessment offers an unprecedented possibility to analyze quickly and \nefficiently large amounts of data and thus support diagnosis, prognosis, disease progression, and \ntreatment efficacy. Measures are estimated automatically using signal processing, natural language \nprocessing, statistical and probabilistic models, and machine learning models. Data are analyzed \nwith CLA, e.g., texts, sound recordings, or neurocognitive tasks. Below, we summarize the \nsignificance of CLA methods in language research in neurodegenerative disorders. \n1. Reproducibility and standardization of measurement, terminology, and evaluation. \nStandardization promotes the precision of measures across studies, patients, and time points. \nFor example, a trained ML model, such as Random Forests, Neural Networks, or applications \nlike morphosyntactic taggers and parsers, can be reproduced given the same code, data, and \ntraining process. CLA provides relatively consistent outcomes for the same input compared to \nhumans, who can differ in their analysis depending on their expertise, the theoretical paradigms \nthey adhere to, the available time, and other factors and limitations that are challenging to \npredict (Stark et al., 2022; Stark Brielle et al., 2020). Similarly, the acoustic analysis provides \nmeasures of speech production that objectively and precisely define the quality of speech \nsounds (e.g., vowels and consonants) and grants an unbiased estimation of speech performance \n(Themistocleous et al., 2022; Themistocleous, Webster, et al., 2021). CLA evaluation metrics \nare standardized measures based on shared principles for distinct models, such as supervised \nclassification, unsupervised classification, binary or multifactorial classification, balanced or \nunbalanced designs, and reinforcement learning. Also, each machine learning model requires \nconventional reporting about the architecture and other hyperparameters machine learning \nmodels, such as artificial neural networks (e.g., feedforward neural networks, recurrent neural \nnetworks, and convolutional neural networks), support vector machines, decision trees, and \nrandom forests. \n2. Open-access research. Publications that provide CLA methods and outputs are freely \ndistributed online, and the code is available for replication and review. This research \nphilosophy promotes good scientific practices ensuring improvement of research techniques \nand methods of science. Researchers can read code, spot bugs, and trace the thinking process \nthat underlies the development of the model. Also, CLA applications commonly rely on free \nand open-source languages, such as Python, R, and Julia, which allows the evaluation of their \nsource code. These are stored repositories like GitHub, GitLab, and the Open Science \nFramework (OSF).  \n3. Objective disease and treatment monitoring and increase of our scientific understanding of \ndisease. The automatic measurements provide quantified results of acoustic and linguistic \nproduction and perception and do not rely on the subjective and challenging to quantify \nperception by humans.  \n \n22 \n \nChallenges and future directions \nSince CLA is a developing field, research must solve extraordinary problems. It is essential to \ndetermine the selection of data (number of data, the type of data, whether the data are labeled or \nunlabeled) and the definition of model architectures (e.g., machine learning models). Although no \nsingle model can address all aspects of language production, perception, and representation, we \nmust determine the best models for the task. Moreover, as scaling increases and multimodality is \nintroduced into the model, the capabilities of these models in domains other than language \nincrease. These models are well suited for CLA application. They enable multimodal information \n(e.g., language, MRI, EEG, EcOG, neurocognitive tests, and social factors) and interaction with \nother cognitive domains such as memory and attention (Diogo et al., 2022; Hosseini et al., 2022). \nFor example, CLA methods easily quantify and address several critical issues, i.e., the effects of \nbrain atrophy on language performance, and provide indications about brain atrophy from \nlanguage measures. In particular, typical functional and structural magnetic resonance imaging \n(MRI), anatomical connectivity and functional connectivity measures (Sporns, 2011), and \nelectrophysiological measures, such as EcOG and EEG, can be correlated with automated \nmeasures of language functioning to provide biomarkers of dementia and facilitate diagnosis and \nprognosis (Wilson et al., 2010). Thus, computational CLA models can be employed in interfaces \nsuch as brain-to-speech, allowing individuals to speak through neuroprosthesis (Bhaya-Grossman \n& Chang, 2022; Metzger et al., 2022). Therefore, studies may require interfaces with other \ndomains, such as MRI imaging or neurophysiological measures.  \nTo conclude, CLA can provide a neuro-cognitive evaluation of speech, language, and \ncommunication in the elderly and individuals at elevated risk for dementia; they can facilitate the \ndevelopment of computational models for diagnosing, prognosis, and evaluating progression and \ntreatment efficacy in at-risk and language-impaired populations and allow easier extensibility to \nassess patients from a wide range of languages. In addition, CLA-based AI models can inform \ntheory on the relationship between language symptoms and their neural bases and significantly \nadvance our ability to optimize the prevention and treatment of elderly individuals with \ncommunication disorders, allowing them to age gracefully with social engagement. Ultimately, \nCLA methods for neurocognitive assessments can facilitate a move towards a more inclusive, \nequitable, and democratic approach to science, where everyone has access to high-quality \nassessments and care regardless of their background, financial status, and identity. \n \nCompeting Interests: The authors have no competing interests or other interests that might be \nperceived to influence the results and discussion reported in this paper. The author has received no \nfunding for this project from other organization. \n \nReferences \nAbdalla, M., Rudzicz, F., & Hirst, G. (2018). Rhetorical structure and Alzheimer’s disease. \nAphasiology, 32(1), 41-60. https://doi.org/10.1080/02687038.2017.1355439  \n23 \n \nAijmer, K., & Stenström, A. B. (2005). Approaches to spoken interaction. Journal of Pragmatics, \n37(11 SPEC. ISS.), 1743-1751. https://doi.org/10.1016/j.pragma.2005.04.006  \nAkynova, D., Zharkynbekova, S., Agmanova, A., Kakzhanova, S., & Kuzar, Z. (2014). \nConversational aspect of code-switching: Using repair in EFL classrooms. Journal of \nLanguage \nand \nLiterature, \n5(3), \n210-218. \nhttp://www.scopus.com/inward/record.url?eid=2-s2.0-\n84914115219&partnerID=40&md5=8dff91588907f5dd9dfd776716b06ce5  \nAnastasi, E., Logotheti, A., Panayiotou, S., Serafim, M., & Themistocleous, C. (2017a, 2017). A \nsociophonetic study of Standard Modern Greek and Cypriot Greek Stop Consonants.  \nAnastasi, E., Logotheti, A., Panayiotou, S., Serafim, M., & Themistocleous, C. (2017b). A \nsociophonetic study of Standard Modern Greek and Cypriot Greek Stop Consonants. 12th \nInternational Conference on Greek Linguistics (ICGL12 ) 16 -- 19 September 2015.,  \nAngelopoulou, G., Kasselimis, D., Makrydakis, G., Varkanitsa, M., Roussos, P., Goutsos, D., \nEvdokimidis, I., & Potagas, C. (2018). Silent pauses in aphasia. Neuropsychologia, 114, \n41-49. https://doi.org/10.1016/j.neuropsychologia.2018.04.006  \nAngelopoulou, G., Kiran, S., Kasselimis, D., Varkanitsa, M., Meier, E., Pan, Y., Tsolakopoulos, \nD., Themistocleous, C., Vassilopoulou, S., & Korompoki, E. (2018). Unsuccessrul word \nretrieval in stroke patients with aphasia< bold>-</bold> cross-linguistic evidence from \nconnected speech European Stroke Conference - ESC, Athens, Greece.  \nArandjelovic, R., & Zisserman, A. (2017). Look, Listen and Learn. CoRR, abs/1705.08168. \nhttp://arxiv.org/abs/1705.08168  \nAristodemou, A., Savva, A., & Themistocleous, C. (2015). The Acoustics of Cypriot Greek \nFricatives. 6th International Conference of Experimental Linguistics. ExLing 2015. 26-27 \nJune 2015., Athens. \nAsgari, M., Kaye, J., & Dodge, H. (2017). Predicting mild cognitive impairment from spontaneous \nspoken utterances. Alzheimer's & dementia (New York, N. Y.), 3(2), 219-228. \nhttps://doi.org/10.1016/j.trci.2017.01.006  \nAytar, Y., Vondrick, C., & Torralba, A. (2016). SoundNet: Learning Sound Representations from \nUnlabeled Video. CoRR, abs/1610.09001. http://arxiv.org/abs/1610.09001  \nBarnes, L. L. (2022). Alzheimer disease in African American individuals: increased incidence or \nnot enough data? Nat Rev Neurol, 18(1), 56-62. https://doi.org/10.1038/s41582-021-\n00589-3  \nBaroni, M., Joulin, A., Jabri, A., Kruszewski, G., Lazaridou, A., Simonic, K., & Mikolov, T. \n(2017). CommAI: Evaluating the first steps towards a useful general AI. CoRR, \nabs/1701.08954. http://arxiv.org/abs/1701.08954  \nBattista, P., Miozzo, A., Piccininni, M., Catricalà, E., Capozzo, R., Tortelli, R., Padovani, A., \nCappa, S. F., & Logroscino, G. (2017). Primary progressive aphasia: a review of \nneuropsychological tests for the assessment of speech and language disorders. \nAphasiology, 31(12), 1359--1378.  \n24 \n \nBeach, T. G., Monsell, S. E., Phillips, L. E., & Kukull, W. (2012). Accuracy of the Clinical \nDiagnosis of Alzheimer Disease at National Institute on Aging Alzheimer Disease Centers, \n2005–2010. Journal of Neuropathology & Experimental Neurology, 71(4), 266-273. \nhttps://doi.org/10.1097/nen.0b013e31824b211b  \nBeales, A., Whitworth, A., & Cartwright, J. (2018). A review of lexical retrieval intervention in \nprimary progressive aphasia and Alzheimer's disease: mechanisms of change, \ngeneralisation, \nand \ncognition. \nAphasiology, \n32(11), \n1360-1387. \nhttps://doi.org/10.1080/02687038.2018.1491192  \nBeaugrande, R. D., & Dressler, W. U. (1981). Introduction to text linguistics. Longman.  \nBeltrami, D., Gagliardi, G., Rossini Favretti, R., Ghidoni, E., Tamburini, F., & Calza, L. (2018). \nSpeech Analysis by Natural Language Processing Techniques: A Possible Tool for Very \nEarly \nDetection \nof \nCognitive \nDecline? \nFront \nAging \nNeurosci, \n10, \n369. \nhttps://doi.org/10.3389/fnagi.2018.00369  \nBengio, S., & Heigold, G. (2014). Word embeddings for speech recognition. Proceedings of the \nAnnual Conference of the International Speech Communication Association, \nINTERSPEECH,  \nBengio, Y., Courville, A. C., & Vincent, P. (2012). Unsupervised Feature Learning and Deep \nLearning: \nA \nReview \nand \nNew \nPerspectives. \nCoRR, \nabs/1206.5538. \nhttp://arxiv.org/abs/1206.5538  \nBerisha, V., Sandoval, S., Utianski, R., Liss, J., & Spanias, A. (2014). Characterizing the \ndistribution of the quadrilateral vowel space area. Journal of the Acoustical Society of \nAmerica, \n135(1), \n421-427. \nhttp://www.scopus.com/inward/record.url?eid=2-s2.0-\n84893298346&partnerID=40&md5=a889c0ad473c9e3900166a8c7cce939f \nhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC3985878/pdf/JASMAN-000135-000421_1.pdf  \nBerisha, V., Wang, S., LaCross, A., & Liss, J. (2015). Tracking discourse complexity preceding \nAlzheimer's disease diagnosis: a case study comparing the press conferences of Presidents \nRonald Reagan and George Herbert Walker Bush. J Alzheimers Dis, 45(3), 959-963. \nhttps://doi.org/10.3233/JAD-142763  \nBernardy, J.-P., & Themistocleous, C. (2017). Modelling prosodic structure using Artificial Neural \nNetworks. Experimental Linguistics 2017.  \nBhaya-Grossman, I., & Chang, E. F. (2022). Speech Computations of the Human Superior \nTemporal Gyrus. Annu Rev Psychol, 73, 79-102. https://doi.org/10.1146/annurev-psych-\n022321-035256  \nBird, S., Klein, E., & Loper, E. (2009). Natural language processing with Python: analyzing text \nwith the natural language toolkit. O'Reilly Media, Inc.  \nCalzà, L., Gagliardi, G., Rossini Favretti, R., & Tamburini, F. (2021). Linguistic features and \nautomatic classifiers for identifying mild cognitive impairment and dementia. Computer \nSpeech & Language, 65. https://doi.org/10.1016/j.csl.2020.101113  \nChomsky, N. (1965). Aspects of the theory of syntax. M.I.T. Press.  \n25 \n \nCovington, M. A., & McFall, J. D. (2010). Cutting the Gordian Knot: The Moving-Average Type–\nToken Ratio (MATTR). Journal of Quantitative Linguistics, 17(2), 94-100. \nhttps://doi.org/10.1080/09296171003643098  \nCunningham, K. T., & Haley, K. L. (2020). Measuring Lexical Diversity for Discourse Analysis \nin Aphasia: Moving-Average Type-Token Ratio and Word Information Measure. J Speech \nLang Hear Res, 63(3), 710-721. https://doi.org/10.1044/2019_JSLHR-19-00226  \nDamian, A. M., Jacobson, S. A., Hentz, J. G., Belden, C. M., Shill, H. A., Sabbagh, M. N., \nCaviness, J. N., & Adler, C. H. (2011). The montreal cognitive assessment and the mini-\nmental state examination as screening instruments for cognitive impairment: Item analyses \nand threshold scores. Dementia and Geriatric Cognitive Disorders, 31(2), 126-131. \nhttps://www.scopus.com/inward/record.uri?eid=2-s2.0-\n79251537166&doi=10.1159%2f000323867&partnerID=40&md5=21c2f30479a56d2419\nadded781542640  \nDanner, D. D., Snowdon, D. A., & Friesen, W. V. (2001). Positive emotions in early life and \nlongevity: Findings from the nun study. Journal of Personality and Social Psychology, \n80(5), 804-813. https://doi.org/10.1037/0022-3514.80.5.804  \nDehak, N., Torres-Carrasquillo, P. A., Reynolds, D., & Dehak, R. (2011). Language recognition \nvia Ivectors and dimensionality reduction.12th Annual Conference of the International \nSpeech Communication Association, INTERSPEECH 2011 Florence. \nDeMarco, A., & Cox, S. J. (2013). Native accent classification via I-vectors and speaker \ncompensation fusion. Proceedings of the Annual Conference of the International Speech \nCommunication Association, INTERSPEECH,  \nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional \ntransformers for language understanding. arXiv preprint arXiv:1810.04805.  \nDial, H. R., Hinshelwood, H. A., Grasso, S. M., Hubbard, H. I., Gorno-Tempini, M. L., & Henry, \nM. L. (2019). Investigating the utility of teletherapy in individuals with primary \nprogressive aphasia. Clin Interv Aging, 14, 453-471. https://doi.org/10.2147/CIA.S178878  \nDiogo, V. S., Ferreira, H. A., Prata, D., & Alzheimer's Disease Neuroimaging, I. (2022). Early \ndiagnosis of Alzheimer's disease using machine learning: a multi-diagnostic, generalizable \napproach. Alzheimers Res Ther, 14(1), 107. https://doi.org/10.1186/s13195-022-01047-y  \nDrummond, C., Coutinho, G., Fonseca, R. P., Assuncao, N., Teldeschi, A., de Oliveira-Souza, R., \nMoll, J., Tovar-Moll, F., & Mattos, P. (2015). Deficits in narrative discourse elicited by \nvisual stimuli are already present in patients with mild cognitive impairment. Front Aging \nNeurosci, 7, 96. https://doi.org/10.3389/fnagi.2015.00096  \nDrummond, C., Coutinho, G., Monteiro, M. C., Assuncao, N., Teldeschi, A., de Souza, A. S., \nOliveira, N., Bramati, I., Sudo, F. K., Vanderboght, B., Brandao, C. O., Fonseca, R., de \nOliveira-Souza, R., Moll, J., Mattos, P., & Tovar-Moll, F. (2019). Narrative impairment, \nwhite matter damage and CSF biomarkers in the Alzheimer’s disease spectrum. Aging \n(Albany NY), 11(20), 9188–9208. https://doi.org/10.18632/aging.102391  \n26 \n \nFarias, S. T., Chand, V., Bonnici, L., Baynes, K., Harvey, D., Mungas, D., Simon, C., & Reed, B. \n(2012). Idea density measured in late life predicts subsequent cognitive trajectories: \nimplications for the measurement of cognitive reserve. The journals of gerontology. Series \nB, \nPsychological \nsciences \nand \nsocial \nsciences, \n67(6), \n677-686. \nhttps://doi.org/10.1093/geronb/gbr162  \nFolstein, M. F., Folstein, S. E., & McHugh, P. R. (1975). “Mini-mental state”: A practical method \nfor grading the cognitive state of patients for the clinician. Journal of Psychiatric Research, \n12(null), 189-198. https://doi.org/10.1016/0022-3956(75)90026-6  \nFoulkes, P., Scobbie, J., & Watt, D. (2010). Sociophonetics. In W. Hardcastle, J. Laver, & F. \nGibbon (Eds.), The Handbook of Phonetic Sciences (2 ed., pp. 703-754). Wiley-Blackwell.  \nFraser, K. C., Lundholm Fors, K., Eckerström, M., Öhman, F., & Kokkinakis, D. (2019). \nPredicting MCI Status From Multimodal Language Data Using Cascaded Classifiers \n[Original \nResearch]. \nFrontiers \nin \nAging \nNeuroscience, \n11(205). \nhttps://doi.org/10.3389/fnagi.2019.00205  \nFraser, K. C., Lundholm Fors, K., Eckerström, M., Themistocleous, C., & Kokkinakis, D. (2018). \nImproving the Sensitivity and Specificity of MCI Screening with Linguistic Information. \nProceedings of the LREC 2018 Workshop “Resources and ProcessIng of linguistic, para-\nlinguistic and extra-linguistic Data from people with various forms of cognitive/psychiatric \nimpairments (RaPID-2)”(2015), 19-26. http://demo.spraakdata.gu.se/svedk/pbl/rapid-2-\nfinal.pdf%0Ahttp://lrec-conf.org/workshops/lrec2018/W31/pdf/3_W31.pdf  \nFraser, K. C., Lundholm Fors, K., & Kokkinakis, D. (2019). Multilingual word embeddings for \nthe assessment of narrative speech in mild cognitive impairment. Computer Speech & \nLanguage, 53, 121-139. https://doi.org/https://doi.org/10.1016/j.csl.2018.07.005  \nFraser, K. C., Meltzer, J. A., Graham, N. L., Leonard, C., Hirst, G., Black, S. E., & Rochon, E. \n(2014). Automated classification of primary progressive aphasia subtypes from narrative \nspeech transcripts. Cortex, 55, 43-60. https://doi.org/10.1016/j.cortex.2012.12.006  \nGarrard, P., Rentoumi, V., Gesierich, B., Miller, B., & Gorno-Tempini, M. L. (2014). Machine \nlearning approaches to diagnosis and laterality effects in semantic dementia discourse. \nCortex, 55(1), 122-129. https://doi.org/10.1016/j.cortex.2013.05.008  \nGeorgiou, G. P., & Themistocleous, C. (2020). Vowel learning in diglossic settings: Evidence \nfrom Arabic-Greek learners. International Journal of Bilingualism, 1367006920945396. \nhttps://doi.org/10.1177/1367006920945396  \nGlembek, O., Burget, L., Brümmer, N., Plchot, O., & Matějka, P. (2011). Discriminatively trained \ni-vector extractor for speaker verification.12th Annual Conference of the International \nSpeech Communication Association, INTERSPEECH 2011 Florence. \nGoodglass, H., & Kaplan, E. (1983). Boston diagnostic aphasia examination (BDAE). Lea & \nFebiger.  \nGorno-Tempini, M. L., Hillis, A. E., Weintraub, S., Kertesz, A., Mendez, M., Cappa, S. F., Ogar, \nJ. M., Rohrer, J. D., Black, S., Boeve, B. F., Manes, F., Dronkers, N. F., Vandenberghe, \nR., Rascovsky, K., Patterson, K., Miller, B. L., Knopman, D. S., Hodges, J. R., Mesulam, \n27 \n \nM. M., & Grossman, M. (2011). Classification of primary progressive aphasia and its \nvariants. Neurology, 76(11), 1006-1014. https://doi.org/10.1212/WNL.0b013e31821103e6  \nGrice, H. P. (1975). Logic and Conversation. In P. Cole & J. L. Morgan (Eds.), Syntax And \nSemantics. Speech Acts (Vol. 3, pp. 41-58). Academic Press.  \nHansen, T. E. A., Praestegaard, J., Tjornhoj-Thomsen, T., Andresen, M., & Norgaard, B. (2022). \nDementia-Friendliness in Danish and International Contexts: A Critical Discourse \nAnalysis. Gerontologist, 62(1), 130-141. https://doi.org/10.1093/geront/gnab056  \nHarwath, D., Torralba, A., & Glass, J. R. (2016). Unsupervised Learning of Spoken Language \nwith Visual Context. NIPS 2016.  \nHassabis, D., Kumaran, D., Summerfield, C., & Botvinick, M. (2017). Neuroscience-Inspired \nArtificial \nIntelligence. \nNeuron, \n95(2), \n245--258. \nhttps://doi.org/10.1016/j.neuron.2017.06.011 \nsee \nalso \nthe \npost \nin: \nhttps://deepmind.com/blog/ai-and-neuroscience-virtuous-circle/  \nHautamäki, V., Cheng, Y. C., Rajan, P., & Lee, C. H. (2013). Minimax i-vector extractor for short \nduration speaker verification. Proceedings of the Annual Conference of the International \nSpeech Communication Association, INTERSPEECH,  \nHebb, D. O. (1949). The organization of behavior: A neuropsychological theory. John Wiley & \nSons Inc.  \nHerdan, G. (1955). A new derivation and interpretation of Yule's ‘Characteristic’K. Zeitschrift für \nangewandte \nMathematik \nund \nPhysik \nZAMP, \n6(4), \n332-339. \nhttps://doi.org/10.1007/BF01587632  \nHolt, C. M., Yuen, I., & Demuth, K. (2017). Discourse Strategies and the Production of Prosody \nby Prelingually Deaf Adolescent Cochlear Implant Users. Ear and Hearing, 38(2), e101-\ne108. https://doi.org/10.1097/AUD.0000000000000362  \nHosseini, E. A., Schrimpf, M., Zhang, Y., Bowman, S., Zaslavsky, N., & Fedorenko, E. (2022). \nArtificial neural network language models align neurally and behaviorally with humans \neven \nafter \na \ndevelopmentally \nrealistic \namount \nof \ntraining. \nbioRxiv, \n2022.2010.2004.510681. https://doi.org/10.1101/2022.10.04.510681  \nHymes, D. H. (1996). Ethnography, Linguistics, Narrative Inequality Toward An Understanding \nOf voice Critical Perspectives on Literacy and Education. Routledge.  \nIoffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by \nReducing \nInternal \nCovariate \nShift. \nCoRR, \nabs/1502.03167. \nhttp://arxiv.org/abs/1502.03167  \nJiang, B., Song, Y., Wei, S., McLoughlin, I., & Dai, L. R. (2014). Task-aware deep bottleneck \nfeatures for spoken language identification. Proceedings of the Annual Conference of the \nInternational Speech Communication Association, INTERSPEECH,  \nJurafsky, D., & Martin, J. H. (2009). Speech and language processing: An introduction to natural \nlanguage processing, computational linguistics, and speech recognition (2 ed.). Pearson \nPrentice Hall.  \nKaplan, E., Goodglass, H., & Weintraub, S. (2001). Boston Naming Test. Pro-ed.  \n28 \n \nKarpathy, A., & Fei-Fei, L. (2015). Deep Visual-Semantic Alignments for Generating Image \nDescriptions. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),  \nKay, J., Lesser, R., & Coltheart, R. M. (1992). PALPA. Psycholinguistic Assessments of Language \nProcessing in Aphasia. Psychology Press.  \nKertesz, A. (2006). Western aphasia battery-revised (WAB-R). Pearson.  \nKong, A. P.-H., Linnik, A., Law, S.-P., & Shum, W. W.-M. (2018). Measuring discourse \ncoherence in anomic aphasia using Rhetorical Structure Theory. International Journal of \nSpeech-Language \nPathology, \n20(4), \n406-421. \nhttps://doi.org/10.1080/17549507.2017.1293158  \nKönig, A., Satt, A., Sorin, A., & others. (2018). Automatic speech analysis for the assessment of \npatients with predementia and Alzheimer's disease. Alzheimer's & Dementia: Diagnosis, \nAssessment \n& \nDisease \nMonitoring, \n1(1), \n112-124. \nhttp://dx.doi.org/10.1016/j.dadm.2014.11.012  \nKrakauer, J. W. (2006). Motor learning: its relevance to stroke recovery and neurorehabilitation. \nCurrent Opinion in Neurology, 19, 84-90.  \nLabov, W. (1977). Language in the inner city : studies in the black English vernacular. Blackwell.  \nLappin, S., & ebrary Inc. (1981). Sorts, ontology, and metaphor the semantics of sortal structure. \nWalter de Gruyter,. http://site.ebrary.com/lib/princeton/Doc?id=10599631  \nLazaridou, A., Peysakhovich, A., & Baroni, M. (2016). Multi-Agent Cooperation and the \nEmergence of (Natural) Language. https://arxiv.org/abs/1612.07182  \nLe, Q. V., & Mikolov, T. (2014). Distributed Representations of Sentences and Documents  \nhttp://jmlr.org/proceedings/papers/v32/le14.html \nLe, X., Lancashire, I., Hirst, G., & Jokel, R. (2011). Longitudinal detection of dementia through \nlexical and syntactic changes in writing: a case study of three British novelists. Literary \nand Linguistic Computing, 26(4), 435-461. https://doi.org/10.1093/llc/fqr013  \nLecun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444. \nhttps://doi.org/10.1038/nature14539  \nLee, H. S., Tsao, Y., Wang, H. M., & Jeng, S. K. (2014). Clustering-based I-vector formulation \nfor speaker recognition. Proceedings of the Annual Conference of the International Speech \nCommunication Association, INTERSPEECH,  \nLezak, M. D. (1995). Neuropsychological assessment (Vol. null).  \nLopez-de-Ipina, K., Martinez-de-Lizarduy, U., Calvo, P. M., Mekyska, J., Beitia, B., Barroso, N., \nEstanga, A., Tainta, M., & Ecay-Torres, M. (2018). Advances on Automatic Speech \nAnalysis for Early Detection of Alzheimer Disease: A Non-linear Multi-task Approach. \nCurrent \nAlzheimer \nResearch, \n15(2), \n139-148. \nhttps://www.ingentaconnect.com/content/ben/car/2018/00000015/00000002/art00007  \nLópez-de-Ipiña, K., Solé-Casals, J., Eguiraun, H., Alonso, J. B., Travieso, C. M., Ezeiza, A., \nBarroso, N., Ecay-Torres, M., Martinez-Lage, P., & Beitia, B. (2015). Feature selection for \nspontaneous speech analysis to aid in Alzheimer's disease diagnosis: A fractal dimension \n29 \n \napproach. \nComputer \nSpeech \n& \nLanguage, \n30(1), \n43-60. \nhttps://doi.org/http://dx.doi.org/10.1016/j.csl.2014.08.002  \nMatias-Guiu, J. A., Suarez-Coalla, P., Yus, M., Pytel, V., Hernandez-Lorenzo, L., Delgado-\nAlonso, C., Delgado-Alvarez, A., Gomez-Ruiz, N., Polidura, C., Cabrera-Martin, M. N., \nMatias-Guiu, J., & Cuetos, F. (2022). Identification of the main components of \nspontaneous speech in primary progressive aphasia and their neural underpinnings using \nmultimodal \nMRI \nand \nFDG-PET \nimaging. \nCortex, \n146, \n141-160. \nhttps://doi.org/10.1016/j.cortex.2021.10.010  \nMcCulloch, W. S., & Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. \nThe \nbulletin \nof \nmathematical \nbiophysics, \n5(4), \n115--133. \nhttps://doi.org/10.1007/BF02478259  \nMeilan, J. J. G., Martinez-Sanchez, F., Carro, J., Carcavilla, N., & Ivanova, O. (2018). Voice \nMarkers of Lexical Access in Mild Cognitive Impairment and Alzheimer's Disease. \nCurrent \nAlzheimer \nResearch, \n15(2), \n111-119. \nhttps://www.ingentaconnect.com/content/ben/car/2018/00000015/00000002/art00004  \nMesulam, M. M. (1982). Slowly progressive aphasia without generalized dementia. Annals of \nNeurology, \n11(6), \n592--598. \nhttps://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ana.410110607?download=true  \nMesulam, M. M. (2001). Primary progressive aphasia. Annals of Neurology, 49(4), 425-432. \nhttps://www.ncbi.nlm.nih.gov/pubmed/11310619 \nhttps://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ana.91?download=true  \nMetzger, S. L., Liu, J. R., Moses, D. A., Dougherty, M. E., Seaton, M. P., Littlejohn, K. T., \nChartier, J., Anumanchipalli, G. K., Tu-Chan, A., Ganguly, K., & Chang, E. F. (2022). \nGeneralizable spelling using a speech neuroprosthesis in an individual with severe limb \nand vocal paralysis. Nat Commun, 13(1), 6510. https://doi.org/10.1038/s41467-022-\n33611-3  \nMikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word \nRepresentations in Vector Space. CoRR, abs/1301.3781. http://arxiv.org/abs/1301.3781  \nMoro-Velazquez, L., Gomez-Garcia, J. A., Godino-Llorente, J. I., Grandas-Perez, F., Shattuck-\nHufnagel, S., Yague-Jimenez, V., & Dehak, N. (2019). Phonetic relevance and phonemic \ngrouping of speech in the automatic detection of Parkinson's Disease. Sci Rep, 9(1), 19066. \nhttps://doi.org/10.1038/s41598-019-55271-y  \nMueller, K. D., Hermann, B., Mecollari, J., & Turkstra, L. S. (2018). Connected speech and \nlanguage in mild cognitive impairment and Alzheimer's disease: A review of picture \ndescription \ntasks. \nJ \nClin \nExp \nNeuropsychol, \n40(9), \n917-939. \nhttps://doi.org/10.1080/13803395.2018.1446513  \nMurray, L., Timberlake, A., & Eberle, R. (2007). Treatment of Underlying Forms in a discourse \ncontext. Aphasiology, 21(2), 139-163. https://doi.org/10.1080/02687030601026530  \nNeophytou, K., Themistocleous, C., Wiley, R., Tsapkini, K., & Rapp, B. (2018). Understanding \nand classifying the different variants of Primary Progressive Aphasia based on spelling \n30 \n \nperformance. \nFrontiers \nin \nHuman \nNeuroscience, \n12. \nhttps://doi.org/10.3389/conf.fnhum.2018.228.00001  \nOrozco-Arroyave, J. R., Honig, F., Arias-Londono, J. D., Vargas-Bonilla, J. F., Daqrouq, K., \nSkodda, S., Rusz, J., & Noth, E. (2016). Automatic detection of Parkinson's disease in \nrunning speech spoken in three different languages. J Acoust Soc Am, 139(1), 481-500. \nhttps://doi.org/10.1121/1.4939739  \nOwens, A., Isola, P., McDermott, J. H., Torralba, A., Adelson, E. H., & Freeman, W. T. (2015). \nVisually Indicated Sounds. CoRR, abs/1512.08512. http://arxiv.org/abs/1512.08512  \nPennington, J., Socher, R., & Manning, C. D. (2014). Glove: Global vectors for word \nrepresentation. In EMNLP,  \nPetersen, R. C., Smith, G. E., Waring, S. C., Ivnik, R. J., Tangalos, E. G., & Kokmen, E. (1999). \nMild cognitive impairment: clinical characterization and outcome. Archives of Neurology, \n56(3), 303-308.  \nPreston, D. R., & Niedzielski, N. A. (2010). A reader in sociophonetics. De Gruyter Mouton.  \nPusiol, G., Soriano, L., Frank, M. C., & Fei-Fei, L. (2014). Discovering the Signatures of Joint \nAttention in Child-Caregiver Interaction. Proceedings of the Cognitive Science Society, \n36(36). http://www.escholarship.org/uc/item/8z45f7cw  \nRosenblatt, F. (1958). The Perceptron: A Probabilistic Model for Information Storage and \nOrganization in The Brain. Psychological Review, 65--386.  \nRumelhart, D. E., Hinton, G. E., & Williams, R. J. (1985). Learning internal representations by \nerror propagation.  \nRumelhart, D. E., Hinton, G. E., Williams, R. J., & others. (1988). Learning representations by \nback-propagating errors. Cognitive modeling, 5(3), 1.  \nRumelhart, D. E., McClelland, J. L., Group, P. D. P. R., & others. (1986). Parallel distributed \nprocessing: Explorations in the microstructures of cognition. Volume 1: Foundations. The \nMIT Press.  \nSacks, H., Schegloff, E. A., & Jefferson, G. (1974). A Simplest Systematics for the Organization \nof Turn-Taking for Conversation. Language, 50, 696-735.  \nSaffran, E. M., Berndt, R. S., & Schwartz, M. F. (1989). The quantitative analysis of agrammatic \nproduction: \nProcedure \nand \ndata. \nBrain \nand \nLanguage, \n37(3), \n440-479. \nhttps://doi.org/https://doi.org/10.1016/0093-934X(89)90030-8  \nSalis, C., & DeDe, G. (2022). Sentence Production in a Discourse Context in Latent Aphasia: A \nReal-Time Study. American Journal of Speech-Language Pathology, 31(3), 1284-1296. \nhttps://doi.org/10.1044/2022_AJSLP-21-00232  \nScheffer, N., Lei, Y., & Ferrer, L. (2011). Factor Analysis back ends for MLLR transforms in \nspeaker recognition.12th Annual Conference of the International Speech Communication \nAssociation, INTERSPEECH 2011 Florence. \nSchegloff, E. A. (1998). Reflections on Studying Prosody in Talk-in-Interaction. Language and \nSpeech, \n41(3-4), \n235-263. \nhttp://www.scopus.com/inward/record.url?eid=2-s2.0-\n0038499827&partnerID=40&md5=1f64319f85f0ab7c8d504c1891f5ddfd  \n31 \n \nSchegloff, E. A., Jefferson, G., & Sacks, H. (1977). The preference for self-correction in the \norganization of repair in conversation. Language, 53(2), 361-382.  \nSchmidhuber, J. (2015). Deep learning in neural networks: An overview. Neural Networks, 61, \n85-117. http://www.sciencedirect.com/science/article/pii/S0893608014002135  \nSporns, O. (2011). Networks of the brain. MIT Press.  \nStark, B. C., Bryant, L., Themistocleous, C., den Ouden, D.-B., & Roberts, A. C. (2022). Best \npractice guidelines for reporting spoken discourse in aphasia and neurogenic \ncommunication \ndisorders. \nAphasiology, \n1-24. \nhttps://doi.org/10.1080/02687038.2022.2039372  \nStark Brielle, C., Dutta, M., Murray Laura, L., Bryant, L., Fromm, D., MacWhinney, B., Ramage \nAmy, E., Roberts, A., den Ouden Dirk, B., Brock, K., McKinney-Bock, K., Paek Eun, J., \nHarmon Tyson, G., Yoon Si, O., Themistocleous, C., Yoo, H., Aveni, K., Gutierrez, S., & \nSharma, S. (2020). Standardizing Assessment of Spoken Discourse in Aphasia: A Working \nGroup \nWith \nDeliverables. \nAm \nJ \nSpeech \nLang \nPathol, \n1-12. \nhttps://doi.org/10.1044/2020_AJSLP-19-00093  \nStockbridge, M. D., Sheppard, S. M., Keator, L. M., Murray, L. L., Lehman Blake, M., Right \nHemisphere Disorders working group, E.-B. C. R. C. A. o. N. C. D., & Sciences. (2021). \nAprosodia Subsequent to Right Hemisphere Brain Damage: A Systematic Review and \nMeta-Analysis. \nJ \nInt \nNeuropsychol \nSoc, \n1-27. \nhttps://doi.org/10.1017/S1355617721000825  \nStrauss, E., Sherman, E. M. S., Spreen, O., & Spreen, O. (2006). A compendium of \nneuropsychological tests : administration, norms, and commentary (3rd ed.). Oxford \nUniversity \nPress. \nTable \nof \ncontents \nhttp://www.loc.gov/catdir/toc/ecip0516/2005020769.html \nPublisher description http://www.loc.gov/catdir/enhancements/fy0635/2005020769-d.html  \nSutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to Sequence Learning with Neural \nNetworks. CoRR, abs/1409.3215. http://arxiv.org/abs/1409.3215  \nThemistocleous, C. (2014). Edge-Tone Effects and Prosodic Domain Effects on Final \nLengthening. Linguistic Variation, 14(1), 129–160.  \nThemistocleous, C. (2016a). The bursts of stops can convey dialectal information. The Journal of \nthe \nAcoustical \nSociety \nof \nAmerica, \n140(4), \nEL334-EL339. \nhttps://doi.org/doi:http://dx.doi.org/10.1121/1.4964818  \nThemistocleous, C. (2016b). Seeking an Anchorage. Stability and Variability in Tonal Alignment \nof Rising Prenuclear Pitch Accents in Cypriot Greek. Language and Speech, 59(4), 433-\n461. https://doi.org/ doi: 10.1177/0023830915614602  \nThemistocleous, C. (2017a). Dialect classification using vowel acoustic parameters. Speech \nCommunication, 92, 13-22. https://doi.org/https://doi.org/10.1016/j.specom.2017.05.003  \nThemistocleous, C. (2017b). Effects of two linguistically proximal varieties on the spectral and \ncoarticulatory properties of fricatives: Evidence from Athenian Greek and Cypriot Greek. \nFrontiers in Psychology, 8(NOV). https://doi.org/10.3389/fpsyg.2017.01945  \n32 \n \nThemistocleous, C. (2017c). Modern Greek vowels and the nature of acoustic gradience. \nPhonetica, 74(3), 157-172.  \nThemistocleous, C. (2017d). The Nature of Phonetic Gradience across a Dialect Continuum: \nEvidence from Modern Greek Vowels [Journal Article]. Phonetica, 74(3), 157-172. \nhttps://doi.org/10.1159/000450554)  \nThemistocleous, C. (2019). Dialect Classification From a Single Sonorant Sound Using Deep \nNeural \nNetworks. \nFrontiers \nin \nCommunication, \n4, \n1-12. \nhttps://doi.org/10.3389/fcomm.2019.00064  \nThemistocleous, C. (2023). Computational Language Assessment: Open Brain AI. arXiv, \n2306.06693, 1-17. https://doi.org/10.48550/arXiv.2306.06693  \nThemistocleous, C., Eckerström, M., & Kokkinakis, D. (2018). Identification of Mild Cognitive \nImpairment From Speech in Swedish Using Deep Sequential Neural Networks \n[10.3389/fneur.2018.00975]. \nFrontiers \nin \nNeurology, \n9, \n975. \nhttps://doi.org/10.3389/fneur.2018.00975  \nThemistocleous, C., Eckerström, M., & Kokkinakis, D. (2020a). Automated speech analysis \nenables MCI diagnosis. ExLing 2020, 201.  \nThemistocleous, C., Eckerström, M., & Kokkinakis, D. (2020b). Voice quality and speech fluency \ndistinguish individuals with Mild Cognitive Impairment from Healthy Controls. PLoS One, \n15(7), e0236009. https://doi.org/10.1371/journal.pone.0236009  \nThemistocleous, C., Ficek, B., Webster, K., den Ouden, D.-B., Hillis, A. E., & Tsapkini, K. (2021). \nAutomatic Subtyping of Individuals with Primary Progressive Aphasia. Journal of \nAlzheimer's Disease, 79, 1185-1194. https://doi.org/10.3233/JAD-201101  \nThemistocleous, C., Ficek, B., Webster, K. T., Wendt, H., Hillis, A. E., Den Ouden, D. B., & \nTsapkini, K. (2019). Acoustic markers of PPA variants using machine learning \n[10.3389/conf.fnhum.2018.228.00092]. Human Neuroscience Archive.  \nThemistocleous, C., Fyndanis, V., & Tsapkini, K. (2021). Sonorant spectra and coarticulation \ndistinguish speakers with different dialects.  \nThemistocleous, C., Fyndanis, V., & Tsapkini, K. (2022). Sonorant spectra and coarticulation \ndistinguish \nspeakers \nwith \ndifferent \ndialects. \nSpeech \nCommunication, \n1-14. \nhttps://doi.org/https://doi.org/10.1016/j.specom.2022.06.002  \nThemistocleous, C., & Kokkinakis, D. (2019). Speech and Mild Cognitive Impairment detection \nProceedings of the 9th Tutorial & Research Workshop on Experimental Linguistics \n(ExLing2019),   \nThemistocleous, C., Kokkinakis, D., Marie, E., Kathleen, F., & Kristina Lundholm, F. (2018). \nEffects of Cognitive Impairment on vowel duration. Proceedings of the 9th Tutorial & \nResearch Workshop on Experimental Linguistics (ExLing 2018) 28-30 Paris, France, 113-\n116.  \nThemistocleous, C., & Logotheti, A. (2016). Standard Modern Greek and Cypriot Greek vowels: \na sociophonetic study [Conference Proceedings]. 6th International Conference on Modern \nGreek Dialects and Linguistic Theory (MGDLT6), September 25-28, 2014,   \n33 \n \nThemistocleous, C., Neophytou, K., Rapp, B., & Tsapkini, K. (2020). A tool for automatic scoring \nof spelling performance. Journal of Speech, Language, and Hearing Research, 63, 4179-\n4192. https://doi.org/https://doi.org/10.1044/2020_JSLHR-20-00177  \nThemistocleous, C., Savva, A., & Aristodemou, A. (2016a, 2016). Effects of stress on fricatives: \nEvidence from {S}tandard {M}odern {G}reek.  \nThemistocleous, C., Savva, A., & Aristodemou, A. (2016b). Effects of stress on fricatives: \nEvidence from Standard Modern Greek. Interspeech 2016, San Francisco, September 8-\n12. \nThemistocleous, C., Webster, K., Afthinos, A., & Tsapkini, K. (2020). Part of Speech Production \nin Patients With Primary Progressive Aphasia: An Analysis Based on Natural Language \nProcessing. \nAmerican \nJournal \nof \nSpeech-Language \nPathology, \n1-15. \nhttps://doi.org/10.1044/2020_AJSLP-19-00114  \nThemistocleous, C., Webster, K., & Tsapkini, K. (2021). Effects of tDCS on Sound Duration in \nPatients with Apraxia of Speech in Primary Progressive Aphasia. Brain Sciences, 11(3). \nhttps://doi.org/10.3390/brainsci11030335  \nThilakaratne, R., Loftus, A. M., & Cocks, N. (2022). Assessing and treating conversations with \npartners in Parkinson's disease: A scoping review of the evidence. Int J Speech Lang \nPathol, 24(4), 427-436. https://doi.org/10.1080/17549507.2021.1978545  \nThomas, E. (2013). Sociophonetics. In J. K. Chambers & N. Schilling (Eds.), The Handbook of \nLanguage Variation and Change (2 ed., pp. 108-127). Blackwell Publishing.  \nThomas, P., Billon, R., & Hazif-Thomas, C. (2018). Narrative analysis in Alzheimer's disease. \nPsychology \nin \nRussia-State \nof \nthe \nArt, \n11(3), \n145-151. \nhttps://doi.org/10.11621/pir.2018.0310  \nToledo, C. M., Cunha, A., Scarton, C., & Aluísio, S. (2014). Automatic classification of written \ndescriptions by healthy adults: An overview of the application of natural language \nprocessing and machine learning techniques to clinical discourse analysis. Dementia & \nNeuropsychologia, 8(3), 227--235.  \nTóth, L., Hoffmann, I., Gosztolya, G., Vincze, V., Szatloczki, G., Banreti, Z., Pakaski, M., & \nKalman, J. (2018). A speech recognition-based solution for the automatic detection of mild \ncognitive impairment from spontaneous speech. Current Alzheimer Research, 15(2), 130-\n138. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5815089/pdf/CAR-15-130.pdf  \nTsanas, A., Little, M., McSharry, P., & Ramig, L. (2009). Accurate telemonitoring of Parkinson’s \ndisease \nprogression \nby \nnon-invasive \nspeech \ntests. \nNature \nPrecedings. \nhttps://doi.org/10.1038/npre.2009.3920.1  \nTsanas, A., Little, M. A., McSharry, P. E., Spielman, J., & Ramig, L. O. (2012). Novel Speech \nSignal Processing Algorithms for High-Accuracy Classification of Parkinson's Disease. \nIEEE Transactions on Biomedical Engineering, 59(5), 1264--1271.  \nTurian, J., Ratinov, L., & Bengio, Y. (2010). Word Representations: A Simple and General Method \nfor Semi-supervised Learning. Proceedings of the 48th Annual Meeting of the Association \nfor Computational Linguistics,  \n34 \n \nTuring, A. M. (1936). On Computable Numbers, with an Application to the \nEntscheidungsproblem. Proceedings of the London Mathematical Society, 2(42), 230--265.  \nTuring, A. M. (1950). I. Computing Machinery and Intelligence. Mind, LIX(236), 433--460. + \nhttp://dx.doi.org/10.1093/mind/LIX.236.433  \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & \nPolosukhin, I. (2017). Attention is all you need. Advances in neural information processing \nsystems, 30.  \nVitevitch, M. S., & Storkel, H. L. (2013). Examining the Acquisition of Phonological Word Forms \nwith \nComputational \nExperiments. \nLanguage \nand \nSpeech, \n56(4), \n493-527. \nhttp://www.scopus.com/inward/record.url?eid=2-s2.0-\n84888370927&partnerID=40&md5=3d1b4df61f13df02e93d78895e7c0025  \nWilson, S. M., Henry, M. L., Besbris, M., Ogar, J. M., Dronkers, N. F., Jarrold, W., Miller, B. L., \n& Gorno-Tempini, M. L. (2010). Connected speech production in three variants of primary \nprogressive aphasia. Brain, 133(Pt 7), 2069-2088. https://doi.org/10.1093/brain/awq129  \nWright, A., Saxena, S., Sheppard, S. M., & Hillis, A. E. (2018). Selective impairments in \ncomponents of affective prosody in neurologically impaired individuals. Brain and \nCognition, \n124, \n29--36. \nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6487306/pdf/nihms-1024763.pdf  \nYngve, V. H. (1960). A model and an hypothesis for language structure. Proceedings of the \nAmerican philosophical society, 104(5), 444-466.  \n \n",
  "categories": [
    "cs.CL"
  ],
  "published": "2023-05-31",
  "updated": "2023-12-06"
}