{
  "id": "http://arxiv.org/abs/2306.09441v1",
  "title": "Unsupervised Anomaly Detection via Nonlinear Manifold Learning",
  "authors": [
    "Amin Yousefpour",
    "Mehdi Shishehbor",
    "Zahra Zanjani Foumani",
    "Ramin Bostanabad"
  ],
  "abstract": "Anomalies are samples that significantly deviate from the rest of the data\nand their detection plays a major role in building machine learning models that\ncan be reliably used in applications such as data-driven design and novelty\ndetection. The majority of existing anomaly detection methods either are\nexclusively developed for (semi) supervised settings, or provide poor\nperformance in unsupervised applications where there is no training data with\nlabeled anomalous samples. To bridge this research gap, we introduce a robust,\nefficient, and interpretable methodology based on nonlinear manifold learning\nto detect anomalies in unsupervised settings. The essence of our approach is to\nlearn a low-dimensional and interpretable latent representation (aka manifold)\nfor all the data points such that normal samples are automatically clustered\ntogether and hence can be easily and robustly identified. We learn this\nlow-dimensional manifold by designing a learning algorithm that leverages\neither a latent map Gaussian process (LMGP) or a deep autoencoder (AE). Our\nLMGP-based approach, in particular, provides a probabilistic perspective on the\nlearning task and is ideal for high-dimensional applications with scarce data.\nWe demonstrate the superior performance of our approach over existing\ntechnologies via multiple analytic examples and real-world datasets.",
  "text": "Unsupervised Anomaly Detection via Nonlinear Manifold Learning\nAmin Yousefpour1, Mehdi Shishehbor1, Zahra Zanjani Foumani1, and Ramin Bostanabad *1\n1Department of Mechanical and Aerospace Engineering, University of California, Irvine\nAbstract\nAnomalies are samples that significantly deviate from the rest of the data and their detection plays a major\nrole in building machine learning models that can be reliably used in applications such as data-driven design\nand novelty detection. The majority of existing anomaly detection methods either are exclusively developed\nfor (semi) supervised settings, or provide poor performance in unsupervised applications where there is no\ntraining data with labeled anomalous samples. To bridge this research gap, we introduce a robust, efficient,\nand interpretable methodology based on nonlinear manifold learning to detect anomalies in unsupervised\nsettings. The essence of our approach is to learn a low-dimensional and interpretable latent representation\n(aka manifold) for all the data points such that normal samples are automatically clustered together and\nhence can be easily and robustly identified. We learn this low-dimensional manifold by designing a learning\nalgorithm that leverages either a latent map Gaussian process (LMGP) or a deep autoencoder (AE). Our\nLMGP-based approach, in particular, provides a probabilistic perspective on the learning task and is ideal for\nhigh-dimensional applications with scarce data. We demonstrate the superior performance of our approach\nover existing technologies via multiple analytic examples and real-world datasets.\nKeywords: Anomaly detection, manifold learning, novelty detection, Gaussian process, uncertainty quan-\ntification, autoencoder.\n1\nIntroduction\nAnomalies, i.e., observations that deviate significantly from the majority of instances, ubiquitously exist\nin real-world datasets. These samples can dramatically affect the performance of machine learning (ML)\nmodels [1] and arise for a multitude of reasons such as errors in the data generation/recording mechanism\nor existence of uncharacterized features [2]. For instance, factors such as faulty equipment, environmental\nconditions, or changes in the manufacturing process [3] can lead to anomalous samples in industrial ap-\nplications. Failure to detect these anomalies results in inaccurate predictions and decreased reliability in\ndata-driven design applications [4]. In this paper, we introduce a robust, efficient, and interpretable method-\nology based on nonlinear manifold learning to detect anomalies in unsupervised settings where anomaly\nrate (ar) is unknown and there is no training data with labeled anomalous samples1.\nAs a learning task, anomaly detection may be supervised, semi-supervised, or unsupervised [5‚Äì7]. Su-\npervised anomaly detection involves training a model on a labeled dataset where the normal and anomalous\n*Corresponding Author: Raminb@uci.edu\nGitlab repository: https://\n1Our approach can naturally handle supervised and semi-supervised cases.\n1\narXiv:2306.09441v1  [stat.ML]  15 Jun 2023\nsamples are known and labeled as such. In this case, the model learns to distinguish between normal and\nanomalous samples based on the features and patterns present in the training data and after training it is used\nto detect anomalies in unseen data [8, 9]. Semi-supervised techniques require training a model on a dataset\nthat consists of only normal samples and the trained model is then used to detect anomalous samples in\nunseen data [10‚Äì13]. Unsupervised anomaly detection involves training a model on a dataset that includes\nnormal and anomalous samples, with the goal of identifying samples that are unusual or do not conform to\nthe expected pattern. In unsupervised anomaly detection, there is no pre-existing information that indicates\nwhich instances are considered normal. Moreover, the dataset is not divided into distinct training and testing\nphases as in supervised and semi-supervised settings [14‚Äì16].\nAs reviewed in Section 2, many different anomaly detection techniques have been recently developed in\nthe literature [17‚Äì20]. However, these methods mostly require human supervision and their performance is\nvery sensitive to ar (i.e., the number of anomalous samples in the data) [21]. This sensitivity is due to the\nfact that anomalies are rare events and their underlying distribution (which differs from the rest of the data)\nshould be characterized based on very few samples. The performance of existing techniques is also very\nsensitive to the data dimensionality and their accuracy decreases as in high dimensions [22].\nTo address these challenges, in this paper we develop a robust anomaly detection technique based on\nnonlinear manifold learning . Our approach leverages spatial random processes to, while offering a proba-\nbilistic perspective, learn a low-dimensional and visualizable manifold where anomalies are encoded with\npoints that are distant from the rest of the data, see Figure 1. Our approach offers several major advantages\ncompared to existing unsupervised anomaly detection methods. Firstly, it is non-parametric and does not\nrequire any parameter tuning. Secondly, it does not require any labeled examples or additional information\nsuch as the ar. Lastly, it is well-suited for industrial applications that involve high-dimensional datasets with\na limited number of samples.\nThe rest of our paper is organized as follows. We review the major works on unsupervised anomaly\ndetection in Section 2. Then, we introduce our approach in Section 3 and test its performance against state-\nof-the-art techniques in Section 4. We conclude the paper with some final remarks and potential future\ndirections in Section 5.\nLMGP Covariance\nStructure \nMaximum a Posteriori\nùëø, ùíî\nùíö\nBackpropagated Error\nùëø\nDataset\n‡∑ùùíö\nEmbedding\nEmbedded Data\nNormal Data\nAnomalous Data\nk-mean Clustering \nFigure 1 Anomaly detection via manifold learning: We use latent map Gaussian processes (LMGPs) to nonlinearly learn an\nembedding for each sample (this process relies on augmenting the features with the categorical variable s which has as many\nunique levels as there are samples). We then use k-mean algorithm to cluster the learnt embedding into two sets where the samples\nin the larger set correspond to the normal data.\n2\n2\nRelated Works\nIn this section, we examine the key advancements and limitations of existing unsupervised anomaly detec-\ntion methods which we classify into four main categories: neighbor-based, statistical-based, neural network\n(NN)-based, and hybrid methods that combine multiple techniques.\n2.1\nNeighbor-based Methods\nNeighbor-based anomaly detection methods utilize spatial information to differentiate between normal and\nanomalous data points. They compare a sample to its neighboring points and flag it as anomalous if it devi-\nates significantly from its neighbors. Some neighbor-based methods consider the distance to the majority of\ndata (i.e., they are distance-based) while other leverage the density of data surrounding a specific point (i.e.,\nthey are density-based [23]).\nAnomaly detection techniques require two components: an anomaly score and a threshold for detection.\nThe anomaly score of a sample is a numerical value that indicates that sample‚Äôs level of abnormality or\ndeviation from expected behavior. The threshold is essentially a reference point for classifying data points\nas either normal or anomalous based on their respective anomaly scores. That is, by comparing the individual\nscores to the threshold, data points can be appropriately flagged as normal or anomalous. In distance-based\nanomaly detection methods, the criteria used for determining the anomaly score and threshold typically\ninclude the distance between a data point and its closest cluster center or the number of clusters surrounding\nthe data point within a fixed distance [24‚Äì26]. Similarly, in density-based methods such as the local outlier\nfactor algorithm [23], the local density of a data point is compared to the local densities of its neighbors and\nthe samples that exhibit a significantly lower density than their neighbors are flagged as anomalous.\nRecently, distance-based methods are improved by leveraging low-rank and sparse matrix decomposition-\ndistance [27] or Mahalanobis-distance-based classification [28] for both supervised and unsupervised\nanomaly detection. Another recent method is isolation forest which is a distance-based anomaly detec-\ntion technique [29]. Isolation forest is based on random forests and aims to find samples that are distant\nfrom the majority of the data. Isolation forest splits the data space using binary trees and assigns higher\nanomaly scores to data points that require fewer divisions to be isolated [30, 31].\nThe power of neighbor-based algorithms lies in their unsupervised structure, i.e., they do not need a\ntraining dataset whose samples are labeled as either normal or anomalous. However, they are limited by\ntheir quadratic computational costs and potential inaccuracies when dealing with high-dimensional data.\nAlternative approaches or the integration of multiple methods are necessary to overcome the limitations\nassociated with high-dimensional data. We elaborate more on this point in Section 2.4.\n2.2\nStatistical Methods\nStatistical methods build probabilistic models on the data and leverage likelihood ratios to detect anomalies.\nThat is, these methods presume an underlying probability distribution for the data and flag a sample as abnor-\nmal if its likelihood falls below a specified threshold [32, 33]. Determining this threshold is a difficult task\nin most applications. Moreover, these methods often leverage Gaussian processes (GPs) for constructing the\nlikelihood which, while effective in semi-supervised settings [32, 34], face some challenges in unsupervised\nsettings as determining the appropriate anomaly rates and thresholds are not straightforward. An example\neffort for addressing these issues is establishing the decision threshold based on the desired quantile of the\napproximating cumulative distribution function (CDF) [35]. For the most part, however, these extensions do\n3\nnot scale well to high dimensions.\n2.3\nNeural Network-based Methods\nDeep learning (DL) is increasingly used for fault and anomaly detection [36, 37]. Among the various DL\nmodels, autoencoders (AEs) have a particularly long history in industrial [38] as well as medical [39, 40]\napplications where typically convolutional auto-encoders [41] and variational auto-encoders [42] are used\nfor anomaly detection. However, these methods are primarily trained to extract useful features from normal\ndata and hence are best suited for supervised and semi-supervised anomaly detection scenarios. For instance,\nin [43] an anomaly detection approach via convolutional AEs is proposed for a gas turbine operation. While\nthis method is claimed to be unsupervised, its training phase relies on normal data which contradicts the\ndefinition of unsupervised anomaly learning. This issue is commonly seen in many works that leverage DL\nfor anomaly detection.\n2.4\nHybrid Methods\nRelying solely on a single algorithm may not produce satisfactory outcomes and hence hybrid methods\nuse an ensemble of techniques to more accurately identify anomalies [44‚Äì46]. Hybrid methods choose the\nensemble members based on the application at hand and aim to leverage the strengths of each technique in\nhandling particular anomaly detection cases. These approaches are particularly useful when dealing with\nhigh-dimensional data. Some of these methods involve two separate steps [47] while others integrate the\nsteps into a joint process [48, 49]. For instance, k-means clustering is employed in [47] to detect anomalies\nby grouping the normalization encoded values learnt via a deep AE. This work, however, does not leverage\nthe reconstructions error (which is naturally provided by the AE) for anomaly detection which reduces its\nrobustness. As part of our work, we extend this approach by redesigning the AE architecture based on our\nmanifold learning technique (see Section 3.1). Our extension achieves higher robustness and accuracy levels\nand we leverage it in our comparative studies in Section 4.\nIn [49], DAGMM is proposed which utilizes a deep AE to generate a low-dimensional representation for\neach data point by minimizing the reconstruction error. This representation along with the reconstruction\nerror are then fed into a Gaussian Mixture Model (GMM) to detect anomalies. An estimation network is\nthen used to facilitate the parameter learning of the mixture model. The DAGMM jointly optimizes the\nparameters of the deep AE and the mixture model‚Äôs estimation network in an end-to-end fashion. However,\nthis technique has some limitations that hinder its application in unsupervised anomaly detection. First,\nit requires knowledge of ar. Second, it either needs to be trained on a dataset with a few anomalies or\ntrained on a dataset containing only normal data which is contrary to the concept of unsupervised anomaly\ndetection.\n3\nProposed Approach\nOur anomaly detection approach has two primary stages. First, we use a nonlinear manifold learning algo-\nrithm to map all the data points into a low-dimensional and visualizable space that preserves the underlying\nstructure of the data while separating normal samples from the anomalous ones. This manifold assigns a\nlatent point to each sample and aims to learn patterns and dependencies that are typically too difficult to\ndiscern in the original feature space (due to high dimensionality or complexity). After the manifold is built,\nwe apply a clustering algorithm to it to group the encoded latent points into clusters based on their positions\n4\nin the manifold, i.e., our similarity metric is automatically learnt since it is the distances between the latent\npoints. This clustering enables us to distinguish between anomalous and normal samples and identify poten-\ntial outliers that deviate significantly from the expected behavior. In particular, we always cluster the latent\npoints into two groups and label the larger group as normal. Our clustering and labeling decisions are based\non the facts that (1) a sample is either normal or anomalous, and (2) anomalies are, by nature, rare events\nand hence the data should contain far more normal data than anomalies.\nIn our approach we leverage the fact that the normal data are all generated via the same underlying\nsource while anomalous samples either are generated by different sources, or are normal samples that are\ncorrupted during the data collection/recording process. Besides making this distinction on the distributional\ncharacteristics, we make no assumptions about the underlying nature of distributions (e.g., anomalies can be\ngenerated by multiple distinct sources, see Section 4 for an example). In essence, our manifold is expected\nto solve the following inverse problem: distinguish between the sources of normal and anomalous data given\na set of unlabeled samples where all the normal points are generated by a single source. We propose to build\nthese manifolds via either latent map Gaussian processes (LMGPs, which are our preferred approach) or\nAEs whose architecture are inspired via LMGPs.\nIn what follows, we first introduce LMGPs and then deep AEs for manifold learning. Then, in Section 3.3\nwe provide a detailed explanation of how we use k-means clustering to identify anomalous points on the\nlearned manifolds. Lastly, we delineate the advantages of our proposed approaches over existing techniques\nin the literature.\n3.1\nNonlinear manifold learning with Latent Map Gaussian Processes\nGPs are widely used metamodels that assume the training data is generated from a multivariate normal\ndistribution with parametric mean and covariance functions. These assumptions enable the use of closed-\nform formulas based on the conditional distributions to predict unseen events. Conventional GPs do not\naccommodate categorical or qualitative features as these variables are not equipped with a distance measure.\nLMGPs are extensions of GPs that address this limitation [50] by automatically learning an appropriate\ndistance metric for categorical variables. In this paper, we use this learning ability of LMGPs to distinguish\nbetween normal and anomalous samples. To this end, we augment the input space with the qualitative\nfeature s whose number of unique levels (i.e., distinct categories) matches with the number of samples, i.e.,\ns = {‚Ä≤1‚Ä≤, ¬∑ ¬∑ ¬∑ ,‚Ä≤ n‚Ä≤} where n is the dataset size. After this augmentation, we train an LMGP as described\nbelow and then use the manifold that it learns for s in Section 3.3 for anomaly detection.\nWe presume the general case where the original dataset has dx numerical and dt categorical inputs which\nare denoted via x = [x1, . . . , xdx]T and t = [t1, . . . , tdt]T , respectively. With the addition of s, the mixed\ninput space is given by u = [x1, ..., xdx, t1, ..., tdt, s]T . Given the n training pairs (ui, yi) where y is the\nresponse, LMGP assumes that the following relation holds:\ny(u) = Œ≤ + Œæ(u)\n(1)\nwhere Œ≤ is an unknown constant and Œæ(u) is a zero-mean GP with the covariance function or kernel of:\ncov\n\u0000Œæ(u), Œæ\n\u0000u‚Ä≤\u0001\u0001\n= c\n\u0000u, u‚Ä≤\u0001\n= œÉ2r\n\u0000u, u‚Ä≤\u0001\n(2)\nwhere œÉ2 indicates the variance of the process and r(., .) is the parametric correlation function. Evaluation\nof r(., .) in Equation (2) requires the conversion of all categorical variables (i.e., t and s) to some numerical\n5\nfeatures which are embedded in one or multiple manifolds2. Here, we consider two separate quantitative\nmanifolds where the first one encodes t (i.e., each unique combination of t is encoded with a single point in\nthis manifold) while the other one encodes s (i.e., each data point or level of s is mapped to a single point in\nthe this manifold). We make this decision to increase the interpretability and accuracy of our approach since\nvisualizing and clustering the latent points corresponding to the levels of s is much easier and more robust\nin a 2D space which does not encode t.\nFor an LMGP with two manifolds, we propose the following Gaussian correlation function that is tailored\nfor anomaly detection:\nr(\nÔ£Æ\nÔ£∞\nx\nt\ns\nÔ£π\nÔ£ª,\nÔ£Æ\nÔ£∞\nx‚Ä≤\nt‚Ä≤\ns‚Ä≤\nÔ£π\nÔ£ª) = exp{‚àí\ndx\nX\ni=1\n10œâi(xi ‚àíx‚Ä≤\ni)2 ‚àí\ndz\nX\ni=1\n(zi(t) ‚àízi(t‚Ä≤))2 ‚àí\ndh\nX\ni=1\n(hi(s) ‚àíhi(s‚Ä≤))2}\n(3)\nwhere œâ = [œâ1, . . . , œâdx]T are the scale parameters associated with the numerical features x, z is a dz\ndimensional vector that encodes t, and h is a dh dimensional vector that encodes s. To learn the variables in\nthe z‚àísapce, LMGP first assigns a unique numerical vector (i.e., a prior representation) to each combination\nof categorical variables and then maps these vectors to the z‚àíspace (where the posteriors reside) via a\nparametric function (a similar process is done to learn the latent variables in the h‚àíspace). Here, we use\ngrouped one-hot encoding for designing the prior vectors and leverage a linear transformation to map them\ninto the respective manifolds. That is:\nz(t) = Œ∂1(t)Az,\n(4a)\nh(s) = Œ∂2(s)Ah\n(4b)\nwhere the rectangular matrix Az maps Œ∂1(t) to z(t) which are, respectively, the prior and posterior nu-\nmerical representations of t. Similarly, Ah maps Œ∂2(s) to h(s) which denote, respectively, the prior and\nposterior representations of s.\nThe hyperparameters of an LMGP include Œ≤, Az, Ah, œâ, and œÉ2 which we collectively denote via Œò and\njointly estimate them via maximum a posteriori (MAP):\nbŒò = argmax\nŒò\n|2œÄœÉ2R|‚àí1\n2 √ó exp\n\u001a‚àí1\n2 (y ‚àí1Œ≤)T (œÉ2R)‚àí1(y ‚àí1Œ≤)\n\u001b\n√ó P(¬∑)\n(5)\nor equivalently:\nbŒò = argmin\nŒò\nn\n2 log\n\u0000œÉ2\u0001\n+ 1\n2 log(|R|) +\n1\n2œÉ2 (y ‚àí1Œ≤)T R‚àí1(y ‚àí1Œ≤) + log(P(¬∑))\n(6)\nwhere log(¬∑) and | ¬∑ | stand for the natural logarithm and the determinant operator, respectively. Also,\ny = [y1, . . . , yn]T denotes the n √ó 1 vector of outputs in the training data, R is the n √ó n correlation\nmatrix with the (i, j)th element Rij = r(ui, uj) for i, j = 1, . . . , n. Also, 1 is the n √ó 1 vector of 1\nand P(¬∑) indicates the prior on the hyperparameters. Herein, we follow [51] and place independent priors\non the hyperparameters in which œÉ ‚àºLognormal(0, 3), while œâ, Œ≤, Az and Ah follow normal priors as\nœâ ‚àºN(‚àí3, 3), Œ≤ ‚àºN(0, 1), Az ‚àºN(0, 3) and Ah ‚àºN(0, 3).\n2Regardless of the number of manifolds, we always use two dimensional manifolds which have large learning capacity while being\nvery easy to interpret and visualize.\n6\nThe objective function in Eq. 6 can be effectively and quickly minimized via gradient-based optimization\ntechniques [52, 53]. The formulations mentioned above can be adapted to handle datasets with noise by\nintroducing a nugget or jitter parameter, Œ¥ [54]. As a result, R is replaced by RŒ¥ = R + Œ¥In√ón, where In√ón\nis a n √ó n identity matrix.\nWe now elaborate on our rationale for identifying anomalies based on the latent points that encode the\nlevels of the categorical variable s: Factors that render a sample anomalous are potentially many. Moreover,\nthese factors are typically of different nature and we may not even know all of them (i.e., unknown sources\ncause anomalies). Consider a manufacturing process where the performance metrics of the built sample\ncan be affected via human errors, random variations in the raw materials, faulty measurements, or process\nvariations. Since it is extremely difficult to characterize all these factors for all the samples and then use them\nfor detecting anomalies, we assign a unique feature to each sample. This features must be categorical since\na numerical one (that is directly assigned by the analyst) induces incorrect relations among the samples. To\nlearn the relation between the levels of this categorical feature (or, equivalently, learn the relation among the\nsamples), we build an LMGP model as described above. In particular, LMGP maps the levels of s to points\nin the h‚àíspace such that they optimize Equation (6).\nThe optimization in Equation (6) requires normal points to be encoded via close-by points which are all\ndistant from anomalies (note that latent points that encode anomalies can be distant from one another in\nthe h‚àíspace depending on whether they are affected by the same factors). We explain this requirement\nvia Equation (3) for the case where x ‚âàx‚Ä≤, t ‚âàt‚Ä≤, and y ‚âày‚Ä≤ where the first two conditions imply\nr(u, u‚Ä≤) = exp(‚àíPdh\ni=1(hi(s) ‚àíhi(s‚Ä≤))2). That is, for two samples that are very close in the input space\nand have similar response values, the correlation function is maximized (and hence the optimization problem\nin Equation (6) is minimized) if those two points are encoded with close-by points in the h‚àíspace, i.e.,\n‚à•h(s) ‚àíh(s‚Ä≤)‚à•2 << 1.\n3.2\nNonlinear Manifold learning with Autoencoders\nThe second method that we develop for manifold learning is based on AEs which are widely used for\nanomaly detection. Most existing approaches that employ AEs for anomaly detection assume that the trained\nAE cannot accurately reconstruct anomalies as the underlying distribution that the AE learns does not cap-\nture the anomalies well. While this scenario might be the case for some anomalous samples, there are cases\nwhere we observe anomalies with relatively small reconstruction errors. To showcase such cases, we con-\nsider the following two cases: (1) if the anomalies are generated by distributions that are easy to learn, the\nAE can effectively characterize them and achieve low reconstruction errors even for anomalies, and (2) if\nnormal samples are noisy or display complex structures, the AE may achieve relatively large reconstruction\nerrors even for these samples which makes it difficult to distinguish them from the anomalies. Therefore,\nrelying solely on the reconstruction errors achieved by an AE does not provide robust performance for\nanomaly detection.\nTo address this robustness issue, in addition to using the reconstruction errors, one can leverage the learnt\nmanifold of an AE which is expected to encode anomalies far from the normal samples. As reviewed in\nSection 2.4, the DAGMM method [49] leverages this idea but has two major shortcomings (see Section 2.4\nfor details). To address these limitations in the context of regression (i.e., when the data has inputs and\noutputs), we draw inspiration from LMGPs. In particular, we argue that jointly using the total reconstruction\nerror and the encoded positions in the manifold for anomaly detection via AEs can result into identifiability\nissues since the latter is learnt by minimizing the former while training the AE. Hence, we propose to use the\nlatent points and part of the reconstruction error that characterizes the error on reproducing the responses.\n7\nHidden Layer \nHidden Layer \nùë¶‚àí‡∑úùë¶= ‚Ñé2\n‚Ñé1\nùë•1\nùë•2\nùë•ùëëùë•\n‚ãÆ\n‡∑úùë•1\n‡∑úùë•2\n‡∑úùë•ùëëùë•\n‚ãÆ\n‡∑úùë¶\nùë¶\nk-mean Clustering \nEmbedded Data\nNormal Data\nAnomalous Data\nEmbedding\nFigure 2 Anomaly detection with autoencoders: We feed the input and output of the data to the deep AE which aims to reconstruct\neach sample while passing it through the one-dimensional h‚àíspace. We then use the encoded value for each sample (i.e., h1) along\nwith the corresponding reconstruction error (i.e., h2 = |by ‚àíy|) to generate a 2D manifold. Finally, we use the k-means clustering\nalgorithm to group similar data points and identify anomalies.\nOur AE has the typical architecture that consists of the encoder f(¬∑) and the decoder g(¬∑). f(¬∑) takes\nthe inputs and response of the ith sample and maps this data point to the low-dimensional h‚àíspace. The\nencoded value of ith sample is hi\n1 = f([xi, yi]) which is then fed into g(¬∑) to reconstruct the ith sample:\n[bxi, byi] = g\n\u0000hi\n1\n\u0001\n= g\n\u0000f\n\u0000[xi, yi]\n\u0001\u0001\n(7)\nwhere bxi and byi are the reconstructed counterparts of xi and yi, respectively. We train our AE by minimizing\nthe total reconstruction error on both the inputs and output. That is:\nl = 1\nn\nn\nX\ni=1\n\u0012\r\r\rxi ‚àíbxi\r\r\r\n2\n2 + (yi ‚àíbyi)2\n\u0013\n(8)\nwhere ‚à•¬∑‚à•denotes Euclidean norm operator and n denotes the total number of samples in the dataset3. The\nloss function in Equation (8) is the typical mean squared error (MSE) that is used in training AEs.\nOnce the AE is trained, we create a secondary manifold whose axes are h1 (which is the bottleneck of\nthe AE and encodes the samples) and hi\n2 = |byi ‚àíyi| which measures the error of AE in reproducing the\nresponse values. We then use this secondary manifold for anomaly detection, see Figure 2.\n3.3\nManifold-based Clustering for Anomaly Detection\nWith either LMGP or AE, we map each sample to a point in the h‚àíspace where similar data (i.e., samples\nthat have the same underlying generative distribution) are expected to be close-by and distant from the\nanomalies. Since anomalies are rare, we expect the majority of the samples to be encoded with points that\nare close to the origin of the manifold (i.e., ‚à•hi‚à•2 << 1 for the ith sample) since we are using MAP and\notherwise the loss function of the LMGP is not optimally minimized. We test this expectation in Section 4\nwhere we show that LMGP consistently outperforms AE in this regard.\nRegardless of where the samples are encoded in the h‚àíspace, we cluster them into two groups (as we\nknow the data points are either normal or not) and label the samples that belong to the larger cluster as\n3If the dataset has categorical inputs (t) one-hot encoding should be used before feeding data to the AE.\n8\nnormal (since anomalies are rare events). To this end, we employ the k-mean clustering algorithm which\ngroups the points via an iterative scheme where it first assigns each data point to the cluster whose centroid\nin the h‚àíspace is closest to that data point. It then updates the cluster centroids to be the mean of all the\npoints assigned to that cluster. This assignment-update process is repeated until the centroids no longer\nchange or a maximum number of iterations is reached. In our anomaly detection framework, the input to\nthe algorithm is the distance of each point to the center of the learned manifold and the number of clusters\nk = 2 while the output is a labeled manifold where each point is assigned to one of the clusters, see Figure 1\nand Figure 2. With LMGP, we first augment the input space with the qualitative feature s whose number of\nunique levels (i.e., distinct categories) matches with the number of samples. After LMGP is fit, we feed the\nmanifold that it learns for s to the k-means clustering algorithm to identify the anomalies. With AE, we first\ntrain it to minimize the total reconstruction error in Equation (8). Then, we build the secondary manifold\n(based on h1 and part of the reconstruction error which is h2 = |by ‚àíy|) and use it for clustering. Note that\nin AE-based approche the scale of these two components of the manifold can vary. Therefore, we utilize\ntheir normalized values to construct the manifold.\n3.4\nComparison to Existing Techniques\nOur anomaly detection method is a hybrid one in essence since we first learn a low-dimensional representa-\ntion of the data and then apply a clustering algorithm to it. The major difference between our approach and\nthe existing technologies, is its first stage. Our LMGP-based technique is unique since it uses an extension\nof GPs for manifold learning in the context of anomaly detection. The proposed technique offers several\nadvantages compared to other methods. Firstly, due to the non-parametric nature of GP, the proposed tech-\nnique does not require any parameter tuning, which is a significant challenge in deep AE-based methods.\nSecondly, our method does not require any labeled examples or additional information such as ar which\nare typically needed in other unsupervised approaches. Thirdly, our proposed technique is well-suited for\nindustrial applications that involve high-dimensional datasets with a limited number of samples. Fourthly,\nour LMGP-based anomaly detection has a significant advantage over other anomaly detection methods as it\nautomatically handles mixed input spaces (that have both categorical and numerical features) which ubiqui-\ntously arise in design applications such as material composition optimization.\nInspired by our LMGP-based anomaly detection method, we introduce the AE-based approach for\nanomaly detection which works based on nonlinear manifold learning. Our AE-based method tackles two\ncritical challenges encountered by most existing AE-based techniques in the literature. Firstly, it does not re-\nquire knowledge of ar which is often unknown in realistic applications. Secondly, it operates in a completely\nunsupervised manner as it does not involve a training phase with only normal data.\n4\nExperiments\nIn this section, we test the performance of our approach against isolation forest and DAGMM which are two\npopular anomaly detection methods. We consider three analytic and two real-world examples in Section 4.1\nand Section 4.2, respectively. In each experiment, we repeat the simulation 20 times to assess the robustness\nand consistency of the results.\nWe follow two mechanisms for generating anomalous samples. In the first one we generate anomalous\nsamples via one or multiple functions which are different than the function that generates the normal data.\nThis mechanism aims to model scenarios where systematic or malicious errors corrupt the data. In the\n9\nsecond mechanism we select a random subset of the data and corrupt the outputs via the following equation:\nya(x) = (1 + a) √ó yn(x)\n(9)\nwhere ya and yn indicate anomalous and normal outputs, respectively. Also, parameter a represents the\nanomaly bound and is randomly selected for each sample from a uniform distribution on interval [1, 2]. This\nmechanism serves to assess the effectiveness of our methods in scenarios such as temporary measurement\nerrors and fluctuating environmental conditions.\nIn the current study, the anomalous and normal samples are categorized as the positive and negative\nclasses, respectively. Throughout this section, we use F1-score and G-mean metrics to evaluate the perfor-\nmance (see Appendix B for definitions). We also provide the performance of all approaches in terms of\nprecision in Appendix C. These metrics quantify the accuracy of each method in correctly classifying both\nnormal and anomalous samples.\n4.1\nAnalytic Datasets\nWe conduct three experiments where the data are generated by the analytic functions detailed in Appendix A.\nThe dimensionality of the output/response space is one in all of these cases while the input space is either\n10 or 8 dimensional. For each analytic example we generate a total of 500 samples and control the number\nof anomalous samples via ar. To assess the sensitivity of each approach to the number of abnormal data,\nwe consider the four anomaly rates of [0.05, 0.1, 0.2, 0.3] (e.g., 0.05 means that 0.05 √ó 500 of the samples\nare turned into anomalous data via either mechanism one or two). To challenge all the anomaly detection\nmethods, we add noise to all the 500 data points where the noise variance is defined based on the range of\neach function (see Appendix A for details).\n4.1.1\nMultiple Anomalous Data Sources\nWe use variations of the Wing model [55] that estimate the weight of a light aircraft wing (see Appendix A\nfor the functional forms). Specifically, we utilize three different sources modeled via Equation (A-1) through\nEquation (A-3) where Source 1 generates normal data while the other two sources generate anomalous\nsamples. The total number of samples is 500 and for each value of ar we equally sample from sources 2 and\n3 (e.g., ar = 0.1 corresponds to a case where 450, 25, and 25 samples are generated via sources 1, 2, and 3,\nrespectively).\nFigure 3 depicts the results of the LMGP-based, AE-based, DAGMM, and isolation forest methods in this\nexample as ar increases from 0.05 to 0.30. As the trends indicate, our LMGP-based approach consistently\noutperforms other approaches and is followed by our AE-based anomaly detection method. We attribute\nthe superior performance of LMGP to its probabilistic nature and the fact that its learnt manifold effectively\nseparates the anomalies from the rest of the data by optimizing Equation (6). Such a separation makes\nclustering easier as well. However, our AE approach builds its manifold based on (part of) the reconstruction\nerror and the encoding (see Figure 2) which are sensitive to variations and noise in small datasets and\nrelatively high dimensions.\nWe observe in Figure 3 that as ar increases the F1 score of all the approaches increases except for LMGP.\nThis exception is due to the fact that the total number of samples is always fixed to 500 and increasing\nar means that the dataset has increasingly more anomalous samples (and less normal data) which forces\nLMGP to learn a more complex distribution that can explain the behavior of both normal and anomalous\n10\nLMGP\nAutoencoder\nDAGMM\nIsolation Forest \nFigure 3 Effect of anomaly rate on the performance of different approaches: In all cases, our approach that is based on either\nLMGP or AE outperforms DAGMM and isolation forest which require the knowledge of ar. As ar increases, the F1‚àíscore of\nall approaches increases except for LMGP (see the main text for the reasons behind this trend). Additionally, all methods achieve\nsimilar results across the 20 repetitions as hence the error bars are pretty narrow.\ndata (as opposed to only learning the underlying distribution of the normal samples). For a similar reason,\nthe G-mean score of our LMGP-based approach decreases as ar increases.\nIn the case of DAGMM (which directly uses ar as one of its parameters), it cannot detect anomalies\nat low ar since (i) it has access to insufficient information on anomalies, and (ii) our datasets are noisy.\nSpecifically, at ar = 0.05 the model tends to randomly label approximately 5 percent of the data (mostly\nnormal ones) as anomalies and the true positive rate is observed to be close to zero. The findings from [49]\nsupport our observation and demonstrate that the performance of DAGMM substantially decreases as the\nanomaly rate decreases (see the Thyroid example discussed in [49]).\nIn the case of the isolation forest our results indicates that it divides the dataset into two classes with\napproximately the same size regardless of the ar value. That is, as the number of anomalies increases\nthe true positive rate (correctly identified anomalies) and false negative rate (incorrectly classified normal\nsamples) both increase while decreasing the true negative rate and the false positive rate (normal samples\nfalsely identified as anomalies). Consequently, the G-mean value (which provides an overall performance\nmeasure) does not change because the increase in true positives is offset by the decrease in true negatives.\nHowever, these adjustments lead to an improvement in the F1 score as its numerator grows more rapidly than\nits denominator (note that, as shown in Appendix B, the true positive rate is the only term in the numerator\nand directly affects the F1 score while in the denominator there are three terms where two of them cancel\neach other out (the increase in false negative and decrease in false positive counterbalance each other).\nIn the case of our AE-based method, a similar situation happens where its F1 score improves as more\nanomalous data are provided to it. That is, the model has access to more information on anomalies and\nhence can build a manifold that betters distinguishes between the normal and anomalous data. However, as\nar increases, the information on normal data decreases (which prevents the AE from effectively encoding\nnormal samples into its manifold) and hence its G-mean drops.\nWe note that the performance drop of LMGP (in terms of either F1 or G-mean) is expected since it\noperates under the assumption that anomalies are rare events. In our studies, the high anomaly rates in\nFigure 3 are meant to test the sensitivity of different approaches to this assumption in extreme cases which\nrarely happen in realistic applications.\n11\nTo gain more insights into the performance of our approaches, we examine their learnt manifolds. The\nlearned manifolds for this example with three different anomaly rates are presented in Figure 4 for one of the\nSource 1\nSource 2\nSource 3\nNormal\nAnomalous\n(a)\n(c)\n(b)\n(d)\n(f)\n(e)\nLMGP, ùëéùëü=0.30\nLMGP, ùëéùëü=0.20\nLMGP, ùëéùëü=0.05\nAE, ùëéùëü=0.05\nAE, ùëéùëü=0.20\nAE, ùëéùëü=0.30\nFigure 4 Learned manifold in Wing example with multiple anomalous data sources: We illustrate the learned manifolds using\nour two different techniques (LMGP and deep AE) and for three different anomaly rates. The shape assigned to each point on the\nlearned manifold indicates the result of our anomaly detection process (circles and triangles represent samples identified as normal\nand anomalous, respectively). The colors reflect the ground truth information (not used in our approach) where green, orange, and\nred correspond to samples from Source 1, Source 2, and Source 3, respectively. Comparing the two plots in each row we observe\nthat the manifold of LMGP is more interpretable and also results into a more accurate identification of normal and anomalous\nsamples. By increasing ar, the performance of LMGP drops while that of the AE increases.\n12\nrandomly selected repetitions. In these plots the shape assigned to each latent point represents the result of\nour anomaly detection process (circles represent normal samples while triangles flag anomalous data). Ad-\nditionally, the points on the learned manifold are color-coded based on the ground truth information where\ngreen, orange, and red correspond to samples from Source 1, Source 2, and Source 3, respectively (note that\nthe ground truth is not used by either of our approaches). This combination of shape and color enables easy\ninterpretation of both the detected anomalies and the ground truth information within the manifolds.\nAs depicted in Figure 4, both approaches aim to distinguish between normal and anomalous points. How-\never, the spread of the latent points are quite different: while LMGP mostly places the normal data in a circle\ncentered at the origin (which means that both latent variables are equally important for classification via k-\nmeans clustering), AE maps them to a relatively stretched area and primarily relies on h2 for classification.\nWhile our use of h2 dramatically improves the performance of DAGMM (see Section 3.2 and Figure 3), it\nis still not as effective as LMGP.\nIt is important to note that a portion of the misclassification errors associated with our methods is attributed\nto the k-mean algorithm rather than LMGP or AE. For instance, in Figure 4 (a), there is an instance where a\nnormal sample is misclassified (see the green triangle close to the origin). While LMGP effectively encodes\nthis point close to the other normal samples, the k-mean algorithm misclassifies it as an anomaly due to its\nrelatively greater distance from the center of the manifold compared to the other normal points.\nLastly, we note that the latent space of neither of our approaches is robustly able to distinguish between\nthe different anomaly sources. That is, we cannot specify the number of different mechanisms that result\ninto anomalous behavior. However, this behavior is expected to some extent since our approaches are not\ndesigned to identify the number of different mechanisms that result into abnormal behavior.\n4.1.2\nWing Model with One Anomaly Source\nIn this example, we generate 500 samples from Source 1 of the Wing model in Equation (A-1) and then\ncorrupt a subset of this dataset following Equation (9) and for various values of ar. The comparison results\nare summarized in Figure 5 which clearly illustrates the consistent superiority of our LMGP-based technique\nLMGP\nAutoencoder\nDAGMM\nIsolation Forest \nFigure 5 Anomaly detection results in the Wing model with one anomaly source: The results clearly indicate that our LMGP-\nbased and deep AE-based methods outperform isolation forest and DAGMM. See the main text for the rationale behind the trends\nin both F1 score and G-mean plots.\n13\nover all other methods especially in correctly identifying the anomalies (see the F1 score plot). The overall\ntrends in this figure are quite similar to those in Figure 3 but there are two notable differences in the case\nof our LMGP-based approach. Firstly, both F1 and G-mean scores slightly improve as ar is increased\nfrom 0.05 to 0.10 but they both drop as ar exceeds 0.10. Secondly, when ar = 0.05 the variation of F1\nscore in LMGP‚Äôs results is significantly higher compared to the previous example which indicates that the\nperformance is more sensitive across the 20 repetitions in this example.\nWe attribute these changes in LMGP‚Äôs results to the stochastic nature of the anomalies. When ar is\nset to 0.05 the model has only 25 anomalous samples. In the previous example (Section 4.1.1), these\nanomalies are highly correlated and come from specific sources. In contrast, the anomalies in this example\nare produced via a stochastic process with low correlation which produces a more diverse distribution of\nanomalies throughout the dataset. Consequently, LMGP cannot accurately identify that the underlying\ndistribution of these anomalies is different than the rest of the data which, in turn, challenges the clustering\nstage as LMGP‚Äôs manifold does not very accurately distinguish normal and anomalous samples. As ar\nis increased to 0.10 and more anomalous samples are included in the data, LMGP can better learn the\nunderlying mechanism that generates the anomalies and thus both F1 and G-mean scores increase and the\nvariations across the repetitions decrease. However, this positive trend is reversed as ar exceeds 0.10 since\nLMGP either cannot learn the normal data as well as the case where ar = 0.05 (recall that the total number\nof samples is fixed so a higher ar means fewer normal data) or learns a more complex underlying distribution\nthat aims to jointly model both normal and anomalous samples.\nThe learned manifolds are visually represented in Figure 6 for the case of ar = 0.20. This figure demon-\nstrates the effectiveness of both LMGP-based and AE-based anomaly detection methods in encoding anoma-\nlous samples sufficiently far from the normal data in their respective manifolds. This distinction is particu-\nlarly noticeable in LMGP‚Äôs manifold where most of the normal data are clustered around the origin while\nanomalies are scattered around that cluster. While these manifolds (especially that of LMGP) are quite ef-\nfective in separating normal and abnormal samples, k-means clustering incorrectly classifies some of them.\nFor instance, in the manifold of LMGP in Figure 6 there is a clear gap between the orange circles (i.e.,\nfalse negatives or anomalies which are incorrectly classified as normal) and the green circles (i.e., true nega-\ntives). That is, k-means clustering is expected to label the former as anomalies (i.e., we expect to see orange\ntriangles instead of orange circles) but fails to do so.\n4.1.3\nBorehole Model\nIn this example, we employ the Borehole function [56] in Appendix A to generate samples and use Equa-\ntion (9) to corrupt some of these samples. Figure 7 demonstrates the anomaly detection results for various\nvalues of ar in which LMGP consistently outperforms all other methods and is followed by our AE-based\napproach. For the most part, the trends in this figure are quite similar to those in Figure 5 where the F1\nscore of isolation forest and DAGMM increase as ar increases, the performance of our LMGP-based ap-\nproach slightly fluctuates and has a maximum at ar = 0.1, or the consistency of our AE- and LMGP-based\napproaches across the 20 repetitions increases as ar increases.\nHowever, despite the fact that the anomalies in the current and previous example are generated by the\nsame mechanism in Equation (9), notable differences can be observed in the results. In particular, while our\nLMGP- and AE-based approaches consistently outperform isolation forest and DAGMM in this example,\ntheir performance is dropped compared to the Wing model in Section 4.1.2. We attribute this performance\ndrop to the fact that the input-output relation in the 8D Borehole model is more complex than that in the\n10D Wing model which makes it difficult for our LMGP and AE to effectively encode samples into their\nmanifolds such that normal and anomalous data are separated. To validate this assertion, we compare the\n14\nTrue Negative\nTrue Positive\nFalse Positive\nFalse Negative\n(a) Learned Manifold Via LMGP\n(b) Learned Manifold Via Autoencoder\nLMGP, ùëéùëü=0.20\nAE, ùëéùëü=0.20\nFigure 6 Learned manifold in the Wing model with one anomaly source: Both approaches aim to cluster anomalous and normal\nsamples in different clusters. In an ideal scenario, normal and anomalous samples should be denoted -via green circles and orange\ntriangles, respectively. However, both methods fail to achieve this ideal scenario (recall that colors denote ground truth while the\nshapes indicate the results of our anomaly detection methods). In the case of LMGP, this error is mostly due to k-means clustering\n(see the main text for explanations) but in the case of AE it is due to both the manifold learning mechanism and k-means clustering.\nreconstruction errors (in terms of relative root mean square error or RRMSE) of two AEs that are fitted\nexclusively to the normal samples in the Borehole and Wing examples. The RRMSEs in the Borehole and\nWing examples are, respectively, 0.274 and 0.1666 which indicate that it is more difficult to learn the input-\noutput relation in the Borehole model (in other words, more normal samples are needed in the Borehole\nexample to match the scores achieved in the Wing example).\nLMGP\nAutoencoder\nDAGMM\nIsolation Forest \nFigure 7 Anomaly detection results in the Borehole model: Both LMPG and AE show superior performance. The performance\nof DAGMM improves as ar increases since it leverages anomaly rate information. Also, increasing ar improves the F1 value of\nisolation forest algorithm. This trend is because isolation forest classifies the dataset into two classes of approximately the same\nsize regardless of the anomaly rate. As ar increases, the proportion of anomalies in the dataset grows which improves F1 score as\nthe number of false positives decreases. However, the G-mean of isolation forest negligibly changes due to the trade-off between\ntrue positive and true negative rates.\n15\nTo gain more insights into the performance drop compared to the previous exmaple, we visualize the\nlearnt manifolds of LMGP and AE in Figure 8. Compared to Figure 6, the distinction between the normal\nand anomalous samples is not as clear (especially in the case of AE). That is, in this example, the errors\ncan be attributed to both k-means clustering and the manifold learning algorithm. To show the latter source\nof error in LMGP, we see in Figure 8 that some anomalies are incorrectly encoded close to the origin (see\nthe orange circles close to or in the cluster of green circles) or some normal samples are encoded far from\nthe origin (see the green triangle that is close to the bottom right corner of the plot). In both of these cases,\nk-means clustering incorrectly classifies the samples. These two error sources increase in our AE-based\napproach primarily because it is unable to learn an effective decision boundary that separates the normal\nfrom anomalous data.\nTrue Negative\nTrue Positive\nFalse Positive\nFalse Negative\n(a) Learned Manifold Via LMGP\n(b) Learned Manifold Via Autoencoder\nLMGP, ùëéùëü=0.20\nAE, ùëéùëü=0.20\nFigure 8 Learned manifold in the Borehole model: Both LMGP and AE aim to differentiate between the majority of normal and\nanomalous samples. Upon clustering, the LMGP-based approach exhibits superior performance with fewer false positives and false\nnegatives. Neither of the manifolds in this example are as effective as those in Figure 6 in differentiating the normal and anomalous\ndata.\n4.2\nReal-world Dataset\nIn this section, we study the performance of our anomaly detection techniques on two applications where\nthe input space has categorical features and is higher dimensional compared to the examples in Section 4.1.\nAdditionally, we do not explicitly know the input-output relation in these examples.\n4.2.1\nHybrid Organic‚Äìinorganic Perovskite (HOIPs)\nHOIPs are a class of materials with unique optoelectronic properties. These materials consist of a combina-\ntion of organic and inorganic components and have shown promise for applications in solar cells and other\nelectronic devices due to their low-cost fabrication and high efficiency. Ongoing research aims to improve\ntheir stability, scalability, and environmental impact [57]. The dataset used here is generated via three dis-\ntinct sources that simulate the band gap property of HOIPs as a function of composition based on the density\nfunctional theory (DFT). These compositions are characterized via three categorical variables that have 10,\n3, and 16 levels (i.e., there are 480 unique compositions in total). The major differences between the datasets\ngenerated by the three sources are their fidelity (or accuracy) and size. Specifically, dataset generated by\n16\nSource 1 is the most accurate among the three and contains 480 samples while the datasets generated by\nSource 2 and Source 3 contain 179 and 240 samples, respectively, and have lower levels of accuracy com-\npared to Source 1. Following the procedure in Section 4.1.1, we consider the samples generated by Source 1\nas normal data and those from sources 2 and 3 as anomalies. The composite dataset employed in this study\nhas a total of 500 data points and is constructed by randomly selecting normal samples from Source 1 while\nequally sampling anomalous instances from sources 2 and 3. The ratio between normal and anomalous\ndata is controlled via ar. The numerical outcomes obtained from the different methods are summarized in\nFigure 9. The trends observed in isolation forest, DAGMM, and LMGP are quite close to those observed in\nSection 4.1, e.g., our LMGP-based approach consistently outperforms other methods and its performance\nslightly fluctuates as ar increases. Our AE-based method, however, exhibits a large variance in the F1 score\n(and Precision presented in Appendix C) when ar = 0.05. We explain this behavior as follows. The three\ndatasets (and hence the combined one) are quite noisy (we do not know the noise variance) as the simula-\ntions are inherently stochastic. When the anomaly rate is low there are only a few anomalous points in the\ncombined dataset and hence detecting them is sensitive to repetition as the amount of noise and correlation\ncan change substantially in the small data sampled from either Source 2 or Source 3. Consequently, our\nAE-based method cannot learn the underlying distribution of the normal data well and as a result flags some\nnormal points as anomalous (false positive) when the anomaly rate is low. As opposed to the F1 score, the\nG-mean value obtained by our AE-based approach is quite insensitive to the variations across the repetitions\nsince both true positive and true negative rates are consistently high (note that with small ar the true negative\nrate remains considerably high even at high false positive rates).\nLMGP\nAutoencoder\nDAGMM\nIsolation Forest \nFigure 9 Anomaly detection results in HOIP Example: The plots depict the results of anomaly detection techniques applied to\nthe HOIP dataset. The large variations in F1 score of AE at ar = 0.05 are due to noise in the dataset. AE struggles to capture the\nunderlying distribution when there is a low anomaly rate and a high level of noise. LMGP, on the other hand, is more robust due to\nits modified correlation function, allowing it to handle noise and perform well.\nIn contrast to AE, LMGP is much less sensitive to noise due to its probabilistic nature and using the so-\ncalled nugget parameter that is embedded in LMGP‚Äôs kernel and directly models the noise process. Due to\nthese features and LMGP‚Äôs unique mechanism for handling categorical variables, it learnt manifold better\nseparates normal and abnormal data, see Figure 10. In the LMGP‚Äôs manifold most normal data are encoded\nclose to the origin while in the AE‚Äôs manifold these samples are encoded at the bottom part of the manifold,\ni.e., mostly h2 is responsible for separating the normal and anomalous data.\nIn Figure 10 we observe that both manifolds exhibit a slight distinction between anomalous points from\n17\nSource 2 and Source 3 where samples of Source 3 are encoded closer to samples of Source 1. This trend\nindicates that the generative distribution behind Source 1 is closer to Source 3 that Source 2. Similar to\nprevious examples, we also observe that part of the overall error is due to k-means clustering while the\nother part is due to the manifold learning. For instance, in LMGP‚Äôs manifold some of the normal data are\nincorrectly encoded far from the origin (e.g., the green triangle towards the right edge of the plot).\n(a) Learned Manifold Via LMGP\n(b) Learned Manifold Via Autoencoder\nSource 1\nSource 2\nSource 3\nNormal\nAnomalous\nLMGP, ùëéùëü=0.20\nAE, ùëéùëü=0.20\nFigure 10 Learned manifolds in the HOIP example: LMGP encodes the data from each source in distinct locations in the\nmanifold. Specifically, the samples from Source 1 are clustered close to the origin while the data points from Source 2 are located\nsignificantly far away from the rest of the points on the manifold. The majority of the data points from Source 3 are positioned\ncloser to those of Source 1 indicating that Source 1 exhibits more similarities with Source 3. This behavior is also observed to some\nextent in the manifold of AE.\n4.2.2\nHigh-pressure Die-casting (HPDC)\nHPDC is a widely used process for producing aluminum alloy near-net-shaped components. The process\ninvolves a machine that holds a steel die where the casting is formed and an injection system that delivers\nmetal at high speed and holds the solidifying metal under pressure [58]. The HPDC dataset studied here\nhas 1495 samples where each one represents a production scenario characterized with 79 variables (see [59]\nfor more details). Here, we use all 1495 samples and apply Equation (9) to render some of the samples\nanomalous.\nThe numerical results obtained from each method are summarized in Figure 11. The overall trends in\nthis example are to some extent similar to those in the previous sections: our LMGP-based approach con-\nsistently outperforms other methods, the variability of our approaches at ar = 0.05 are relatively large due\nto noise and small-data issues, and the performance of DAGMM improves as ar increases. Unlike previous\nexamples, however, the performance of isolation forest does not change as ar increases. This behavior is\ndue to the fact that isolation forest is a neighbor-based method which suffers from curse of dimensionality,\ni.e., its isolation technique fails to distinguish between normal and anomalous data. This failure is due to\nthe fact that in high dimensions and with small data the number of divisions (that this method uses to isolate\nanomalies) is also small for normal data. Hence, it only identifies a few samples as anomalies and, in turn,\nits true positive rate is close to zero regardless of the value of ar.\nFigure 12 illustrates the learned manifolds where in the case of LMGP normal samples are mostly placed\n18\nLMGP\nAutoencoder\nDAGMM\nIsolation Forest \nFigure 11 Anomaly detection results in the HPDC example: Although the data is high dimensional, our LMGP-based approach\nproduces quite accurate results while DAGMM and especially isolation forest perform poorly in distinguishing between normal and\nanomalous samples.\nTrue Negative\nTrue Positive\nFalse Positive\nFalse Negative\n(a) Learned Manifold Via LMGP\n(b) Learned Manifold Via Autoencoder\nLMGP, ùëéùëü=0.20\nAE, ùëéùëü=0.20\nFigure 12 Learned manifold in HPDC example: LMGP scatters anomalous samples across various positions without forming\ndistinct clusters which suggests that the anomalies in this example have a random nature. In contrast, the AE-based technique\nsolely relied on the utilization of h2 to cluster anomalous and normal points and it does not provide any further insights into the\ncharacteristics or nature of the anomalous samples.\nclose to the origin while anomalous ones are spread out around them without forming distinct clusters. This\ndistribution is a result of the random nature of the anomalous samples and is expected. In contrast, the\nAE-based method lacks the ability to uncover the inherent randomness in anomalies and primarily relies on\nthe reconstruction error (h2) to detect anomalous samples.\n19\n5\nConclusion\nWe introduce an unsupervised anomaly detection technique based on nonlinear manifold learning. Our\napproach has two primary stages. First, using either LMGP or AE, we embed all data points in a low-\ndimensional and visualizable latnet space that preserves the underlying structure of the data while sepa-\nrating normal samples from the anomalous ones. Then, we use the k-mean clustering algorithm to group\nthe encoded points into clusters based on their positions on the manifold. Unlike most existing methods,\nour approach operates entirely in an unsupervised manner and does not require any information about the\nanomaly rate. We compare our method against two of the state-of-the-art techniques on three analytic and\ntwo real-world datasets with different levels of complexity and dimensionality. The results demonstrate\nthat our LMGP-based approach consistently outperforms other techniques and is followed by our AE-based\nmethod.\nA particularly useful feature of our LMGP is its pre-defined framework that does not require any param-\neter tuning which makes it easier to implement. Moreover, our results indicate that the learned manifold\nby LMGP not only distinguishes between anomalous and normal samples, but also has the potential to pro-\nvide insights into the characteristics of anomalies (e.g., the number of different mechanisms that generate\nanomalous data, see Figure 10 for an example). Furthermore, our LMGP-based method demonstrates a\nremarkable robustness against noise as it has a probabilistic nature and directly models the noise process\nwithin its kernel.\nIn the present study we set k = 2 in the k-means clustering regardless of the obtained manifold. De-\nveloping an automated approach to dynamically adjust the value of k based on the characteristics of the\nlearned manifold has the potential to improve the results. Furthermore, in our current approach, two steps\nare performed sequentially. However, we anticipate that the effectiveness of our LMGP- and AE-based ap-\nproaches can be further enhanced by integrating and performing these steps jointly. We aim to investigate\nthese directions in our future works.\nAcknowledgments\nWe appreciate the support from the Office of the Naval Research (award number N000142312485),\nEarly Career Faculty grant from NASA‚Äôs Space Technology Research Grants Program (award number\n80NSSC21K1809), and the UC National Laboratory Fees Research Program of the University of California\n(Grant Number L22CR4520).\nAppendices\nA\nFunctional Form of the Analytic Models\nSource 1, 2, and 3 for wing function studied in section 4.1 are respectively given by:\ny(x) = 0.36s0.758\nw\nw0.0035\nfw\n(\nA\ncos2(Œõ))0.6q0.006 √ó Œª0.04( 100tc\ncos(Œõ))‚àí0.3(NzWdg)0.49 + swwp + œµ\n(A-1)\ny(x) = 0.36s0.8\nw w0.0035\nfw\n(\nA\ncos2(Œõ))0.6q0.006 √ó Œª0.04( 100tc\ncos(Œõ))‚àí0.3(NzWdg)0.49 + wp + œµ\n(A-2)\n20\ny(x) = 0.36s0.9\nw w0.0035\nfw\n(\nA\ncos2(Œõ))0.6q0.006 √ó Œª0.04( 100tc\ncos(Œõ))‚àí0.3(NzWdg)0.49 + œµ\n(A-3)\nwhere y(x) represents the response and the input vector is x = [sw, wfw, A, Œõ, q, Œª, tc, Nz, Wdg, wp]T .\nAlso, œµ ‚àºN(0, 52) represents the noise with zero mean and standard deviation of 5. The noise variance is\ndefined based on the range of each function. For more information on these models and their accuracy with\nrespect to Source 1 we refer the reader to [60].\nThe analytic Borehole function studied in section 4.1 is given by:\ny(x) =\n2œÄTu(Hu ‚àíHl)\nln( r\nrw )(1 +\n2LTu\nln( r\nrw )r2wkw + Tu\nTl ) + œµ\n(A-4)\nwhere the input vector is x = [Tu, Hu, Hl, r, rw, L, kw, Tl]T . Also, œµ ‚àºN(0, 3.402) represents the noise\nwith zero mean and standard deviation of 3.40.\nB\nMetrics\nWe choose three metrics in our evaluations, namely F1-Score, Precision, and G-mean. The formulas of\nF1-Score and precision are given by:\nF1 ‚àíscore =\nTP\nTP + 0.5(FP + FN)\n(B-5)\nPrecision =\nTP\nTP + FP\n(B-6)\nwhere TN and TP denote the number of True Negatives and True Positives, respectively. Also, FN and FP\nindicate the number of False Negatives and False Positives, respectively. In addition, G-mean is defined as:\nG ‚àímean =\nr\nTP\nTP + FN √ó\nTN\nTN + FP\n(B-7)\nC\nPrecision\nHere we present precision results across all examples. By applying various anomaly detection techniques to\nall examples, the precision results are visually represented in Figure 13. Our LMGP- and AE-based methods\noutperform all other techniques tested.\n21\n(a)\n(c)\n(b)\n(d)\n(e)\nLMGP\nAutoencoder\nDAGMM\nIsolation Forest \nFigure 13 Precision results in all examples: The plots illustrate the precision results obtained by applying various anomaly\ndetection techniques to all examples. Both LMG-based and AE-based methods outperform all other techniques while the LMG-\nbased method proposed in this study achieves the highest rank among all techniques.\n22\nReferences\n[1]\nFrancis Ysidro Edgeworth. ‚ÄúXli. on discordant observations‚Äù. In: The london, edinburgh, and dublin\nphilosophical magazine and journal of science 23.143 (1887), pp. 364‚Äì375.\n[2]\nVarun Chandola, Arindam Banerjee, and Vipin Kumar. ‚ÄúAnomaly detection: A survey‚Äù. In: ACM\ncomputing surveys (CSUR) 41.3 (2009), pp. 1‚Äì58.\n[3]\nMohammad Sadegh Sadeghi Garmaroodi, Faezeh Farivar, Mohammad Sayad Haghighi, Mahdi Ali-\nyari Shoorehdeli, and Alireza Jolfaei. ‚ÄúDetection of anomalies in industrial iot systems by data min-\ning: Study of christ osmotron water purification system‚Äù. In: IEEE Internet of Things Journal 8.13\n(2020), pp. 10280‚Äì10287.\n[4]\nÀöAsmund F Skomedal, Bj√∏rn L Aarseth, Halvard Haug, Josefine Selj, and Erik S Marstein. ‚ÄúHow much\npower is lost in a hot-spot? A case study quantifying the effect of thermal anomalies in two utility\nscale PV power plants‚Äù. In: Solar Energy 211 (2020), pp. 1255‚Äì1262.\n[5]\nKishan G Mehrotra, Chilukuri K Mohan, and HuaMing Huang. Anomaly detection principles and\nalgorithms. Vol. 1. Springer, 2017.\n[6]\nKeith Noto, Carla Brodley, and Donna Slonim. ‚ÄúFRaC: a feature-modeling approach for semi-\nsupervised and unsupervised anomaly detection‚Äù. In: Data mining and knowledge discovery 25\n(2012), pp. 109‚Äì133.\n[7]\nXuan Xia, Xizhou Pan, Nan Li, Xing He, Lin Ma, Xiaoguang Zhang, and Ning Ding. ‚ÄúGAN-based\nanomaly detection: a review‚Äù. In: Neurocomputing (2022).\n[8]\nNico G¬®ornitz, Marius Kloft, Konrad Rieck, and Ulf Brefeld. ‚ÄúToward supervised anomaly detection‚Äù.\nIn: Journal of Artificial Intelligence Research 46 (2013), pp. 235‚Äì262.\n[9]\nGuansong Pang, Anton van den Hengel, Chunhua Shen, and Longbing Cao. ‚ÄúToward deep supervised\nanomaly detection: Reinforcement learning from partially labeled anomaly data‚Äù. In: Proceedings of\nthe 27th ACM SIGKDD conference on knowledge discovery & data mining. 2021, pp. 1298‚Äì1308.\n[10]\nLukas Ruff, Robert A Vandermeulen, Nico G¬®ornitz, Alexander Binder, Emmanuel M¬®uller, Klaus-\nRobert M¬®uller, and Marius Kloft. ‚ÄúDeep semi-supervised anomaly detection‚Äù. In: arXiv preprint\narXiv:1906.02694 (2019).\n[11]\nMiryam Elizabeth Villa-P¬¥erez, Miguel A Alvarez-Carmona, Octavio Loyola-Gonzalez, Miguel\nAngel Medina-P¬¥erez, Juan Carlos Velazco-Rossell, and Kim-Kwang Raymond Choo. ‚ÄúSemi-\nsupervised anomaly detection algorithms: A comparative summary and future research directions‚Äù.\nIn: Knowledge-Based Systems 218 (2021), p. 106878.\n[12]\nJie Liu, Kechen Song, Mingzheng Feng, Yunhui Yan, Zhibiao Tu, and Liu Zhu. ‚ÄúSemi-supervised\nanomaly detection with dual prototypes autoencoder for industrial surface inspection‚Äù. In: Optics and\nLasers in Engineering 136 (2021), p. 106324.\n[13]\nFabrizio De Vita, Dario Bruneo, and Sajal K Das. ‚ÄúA Semi-Supervised Bayesian Anomaly Detection\nTechnique for Diagnosing Faults in Industrial IoT Systems‚Äù. In: 2021 IEEE International Conference\non Smart Computing (SMARTCOMP). IEEE. 2021, pp. 31‚Äì38.\n[14]\nTingting Chen, Xueping Liu, Bizhong Xia, Wei Wang, and Yongzhi Lai. ‚ÄúUnsupervised anomaly\ndetection of industrial robots using sliding-window convolutional variational autoencoder‚Äù. In: IEEE\nAccess 8 (2020), pp. 47072‚Äì47081.\n[15]\nYajie Cui, Zhaoxiang Liu, and Shiguo Lian. ‚ÄúA survey on unsupervised industrial anomaly detection\nalgorithms‚Äù. In: arXiv preprint arXiv:2204.11161 (2022).\n23\n[16]\nKatherine Fraser, Samuel Homiller, Rashmish K Mishra, Bryan Ostdiek, and Matthew D Schwartz.\n‚ÄúChallenges for unsupervised anomaly detection in particle physics‚Äù. In: Journal of High Energy\nPhysics 2022.3 (2022), pp. 1‚Äì31.\n[17]\nUsman Ahmad Usmani, Ari Happonen, and Junzo Watada. ‚ÄúA Review of Unsupervised Machine\nLearning Frameworks for Anomaly Detection in Industrial Applications‚Äù. In: Intelligent Computing:\nProceedings of the 2022 Computing Conference, Volume 2. Springer. 2022, pp. 158‚Äì189.\n[18]\nJie Yang, Yong Shi, and Zhiquan Qi. ‚ÄúLearning deep feature correspondence for unsupervised\nanomaly detection and segmentation‚Äù. In: Pattern Recognition 132 (2022), p. 108874.\n[19]\nHamzeh Alimohammadi and Shengnan Nancy Chen. ‚ÄúPerformance evaluation of outlier detection\ntechniques in production timeseries: A systematic review and meta-analysis‚Äù. In: Expert Systems\nwith Applications 191 (2022), p. 116371.\n[20]\nTolga Ergen and Suleyman Serdar Kozat. ‚ÄúUnsupervised anomaly detection with LSTM neural net-\nworks‚Äù. In: IEEE transactions on neural networks and learning systems 31.8 (2019), pp. 3127‚Äì3141.\n[21]\nJinan Fan, Qianru Zhang, Jialei Zhu, Meng Zhang, Zhou Yang, and Hanxiang Cao. ‚ÄúRobust deep auto-\nencoding Gaussian process regression for unsupervised anomaly detection‚Äù. In: Neurocomputing 376\n(2020), pp. 180‚Äì190.\n[22]\nPriyanga Dilini Talagala, Rob J Hyndman, and Kate Smith-Miles. ‚ÄúAnomaly detection in high-\ndimensional data‚Äù. In: Journal of Computational and Graphical Statistics 30.2 (2021), pp. 360‚Äì374.\n[23]\nMarkus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and J¬®org Sander. ‚ÄúLOF: identifying density-\nbased local outliers‚Äù. In: Proceedings of the 2000 ACM SIGMOD international conference on Man-\nagement of data. 2000, pp. 93‚Äì104.\n[24]\nGuo Pu, Lijuan Wang, Jun Shen, and Fang Dong. ‚ÄúA hybrid unsupervised clustering-based anomaly\ndetection method‚Äù. In: Tsinghua Science and Technology 26.2 (2020), pp. 146‚Äì153.\n[25]\nYu Gao, Tianshe Yang, Minqiang Xu, and Nan Xing. ‚ÄúAn unsupervised anomaly detection approach\nfor spacecraft based on normal behavior clustering‚Äù. In: 2012 Fifth International Conference on In-\ntelligent Computation Technology and Automation. IEEE. 2012, pp. 478‚Äì481.\n[26]\nIwan Syarif, Adam Prugel-Bennett, and Gary Wills. ‚ÄúUnsupervised clustering approach for network\nanomaly detection‚Äù. In: International conference on networked digital technologies. Springer. 2012,\npp. 135‚Äì145.\n[27]\nYuxiang Zhang, Bo Du, Liangpei Zhang, and Shugen Wang. ‚ÄúA low-rank and sparse matrix\ndecomposition-based Mahalanobis distance method for hyperspectral anomaly detection‚Äù. In: IEEE\nTransactions on Geoscience and Remote Sensing 54.3 (2015), pp. 1376‚Äì1389.\n[28]\nB¬¥alint Magyar, Ambrus Kenyeres, S¬¥andor T¬¥oth, Istv¬¥an Hajdu, and Roland Horv¬¥ath. ‚ÄúSpatial outlier\ndetection on discrete GNSS velocity fields using robust Mahalanobis-distance-based unsupervised\nclassification‚Äù. In: GPS Solutions 26.4 (2022), p. 145.\n[29]\nSahand Hariri, Matias Carrasco Kind, and Robert J Brunner. ‚ÄúExtended isolation forest‚Äù. In: IEEE\nTransactions on Knowledge and Data Engineering 33.4 (2019), pp. 1479‚Äì1489.\n[30]\nXiangyu Song, Sunil Aryal, Kai Ming Ting, Zhen Liu, and Bin He. ‚ÄúSpectral‚Äìspatial anomaly detec-\ntion of hyperspectral data based on improved isolation forest‚Äù. In: IEEE Transactions on Geoscience\nand Remote Sensing 60 (2021), pp. 1‚Äì16.\n[31]\nPawe≈Ç Karczmarek, Adam Kiersztyn, Witold Pedrycz, and Dariusz Czerwi¬¥nski. ‚ÄúFuzzy c-means-\nbased isolation forest‚Äù. In: Applied Soft Computing 106 (2021), p. 107354.\n24\n[32]\nBiao Wang and Zhizhong Mao. ‚ÄúOutlier detection based on Gaussian process with application to\nindustrial processes‚Äù. In: Applied Soft Computing 76 (2019), pp. 505‚Äì516.\n[33]\nYalda Rajabzadeh, Amir Hossein Rezaie, and Hamidreza Amindavar. ‚ÄúA dynamic modeling ap-\nproach for anomaly detection using stochastic differential equations‚Äù. In: Digital Signal Processing\n54 (2016), pp. 1‚Äì11.\n[34]\nFengmao Lv, Tao Liang, Jiayi Zhao, Zhongliu Zhuo, Jinzhao Wu, and Guowu Yang. ‚ÄúLatent Gaus-\nsian process for anomaly detection in categorical data‚Äù. In: Knowledge-Based Systems 220 (2021),\np. 106896.\n[35]\nGuang Yu, Zhiping Cai, Siqi Wang, Haiwen Chen, Fang Liu, and Anfeng Liu. ‚ÄúUnsupervised online\nanomaly detection with parameter adaptation for KPI abrupt changes‚Äù. In: IEEE Transactions on\nNetwork and Service Management 17.3 (2019), pp. 1294‚Äì1308.\n[36]\nGuansong Pang, Chunhua Shen, Longbing Cao, and Anton Van Den Hengel. ‚ÄúDeep learning for\nanomaly detection: A review‚Äù. In: ACM computing surveys (CSUR) 54.2 (2021), pp. 1‚Äì38.\n[37]\nRaghavendra Chalapathy and Sanjay Chawla. ‚ÄúDeep learning for anomaly detection: A survey‚Äù. In:\narXiv preprint arXiv:1901.03407 (2019).\n[38]\nXian Tao, Xinyi Gong, Xin Zhang, Shaohua Yan, and Chandranath Adak. ‚ÄúDeep learning for unsuper-\nvised anomaly localization in industrial images: A survey‚Äù. In: IEEE Transactions on Instrumentation\nand Measurement (2022).\n[39]\nTharindu Fernando, Harshala Gammulle, Simon Denman, Sridha Sridharan, and Clinton Fookes.\n‚ÄúDeep learning for medical anomaly detection‚Äìa survey‚Äù. In: ACM Computing Surveys (CSUR) 54.7\n(2021), pp. 1‚Äì37.\n[40]\nChristoph Baur, Stefan Denner, Benedikt Wiestler, Nassir Navab, and Shadi Albarqouni. ‚ÄúAutoen-\ncoders for unsupervised anomaly segmentation in brain MR images: a comparative study‚Äù. In: Medi-\ncal Image Analysis 69 (2021), p. 101952.\n[41]\nXing Hu, Jing Lian, Dawei Zhang, Xiumin Gao, Linhua Jiang, and Wenmin Chen. ‚ÄúVideo anomaly\ndetection based on 3D convolutional auto-encoder‚Äù. In: Signal, Image and Video Processing 16.7\n(2022), pp. 1885‚Äì1893.\n[42]\nDiederik P Kingma and Max Welling. ‚ÄúAuto-encoding variational bayes‚Äù. In: arXiv preprint\narXiv:1312.6114 (2013).\n[43]\nGeunbae Lee, Myungkyo Jung, Myoungwoo Song, and Jaegul Choo. ‚ÄúUnsupervised anomaly de-\ntection of the gas turbine operation via convolutional auto-encoder‚Äù. In: 2020 IEEE International\nConference on Prognostics and Health Management (ICPHM). IEEE. 2020, pp. 1‚Äì6.\n[44]\nShikha Agrawal and Jitendra Agrawal. ‚ÄúSurvey on anomaly detection using data mining techniques‚Äù.\nIn: Procedia Computer Science 60 (2015), pp. 708‚Äì713.\n[45]\nXin Zhang, Pingping Wei, and Qingling Wang. ‚ÄúA hybrid anomaly detection method for high dimen-\nsional data‚Äù. In: PeerJ Computer Science 9 (2023), e1199.\n[46]\nShen Yan, Haidong Shao, Yiming Xiao, Bin Liu, and Jiafu Wan. ‚ÄúHybrid robust convolutional au-\ntoencoder for unsupervised anomaly detection of machine tools under noises‚Äù. In: Robotics and\nComputer-Integrated Manufacturing 79 (2023), p. 102441.\n[47]\nCaglar Aytekin, Xingyang Ni, Francesco Cricri, and Emre Aksu. ‚ÄúClustering and unsupervised\nanomaly detection with l 2 normalized deep auto-encoder representations‚Äù. In: 2018 International\nJoint Conference on Neural Networks (IJCNN). IEEE. 2018, pp. 1‚Äì6.\n25\n[48]\nZahra Ghafoori and Christopher Leckie. ‚ÄúDeep multi-sphere support vector data description‚Äù. In:\nProceedings of the 2020 SIAM International Conference on Data Mining. SIAM. 2020, pp. 109‚Äì117.\n[49]\nBo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng\nChen. ‚ÄúDeep autoencoding gaussian mixture model for unsupervised anomaly detection‚Äù. In: Inter-\nnational conference on learning representations. 2018.\n[50]\nNicholas Oune and Ramin Bostanabad. ‚ÄúLatent map Gaussian processes for mixed variable meta-\nmodeling‚Äù. In: Computer Methods in Applied Mechanics and Engineering 387 (2021), p. 114128.\n[51]\nhttps://gpytorch.ai/.\n[52]\nR. Bostanabad, T. Kearney, S. Y. Tao, D. W. Apley, and W. Chen. ‚ÄúLeveraging the nugget param-\neter for efficient Gaussian process modeling‚Äù. In: International Journal for Numerical Methods in\nEngineering 114.5 (2018), pp. 501‚Äì516. ISSN: 0029-5981. DOI: 10 . 1002 / nme . 5751. URL:\n%3CGo%20to%20ISI%3E://WOS:000428998100002.\n[53]\nSiyu Tao, Kohei Shintani, Ramin Bostanabad, Yu-Chin Chan, Guang Yang, Herb Meingast, and Wei\nChen. ‚ÄúEnhanced Gaussian Process Metamodeling and Collaborative Optimization for Vehicle Sus-\npension Design Optimization‚Äù. In: ASME 2017 International Design Engineering Technical Confer-\nences and Computers and Information in Engineering Conference. Vol. 2B. American Society of\nMechanical Engineers.\n[54]\nRamin Bostanabad, Tucker Kearney, Siyu Tao, Daniel W Apley, and Wei Chen. ‚ÄúLeveraging the\nnugget parameter for efficient Gaussian process modeling‚Äù. In: International journal for numerical\nmethods in engineering 114.5 (2018), pp. 501‚Äì516.\n[55]\nHyejung Moon. ‚ÄúDesign and analysis of computer experiments for screening input variables‚Äù. PhD\nthesis. The Ohio State University, 2010.\n[56]\nMax D Morris, Toby J Mitchell, and Donald Ylvisaker. ‚ÄúBayesian design and analysis of computer\nexperiments: use of derivatives in surface prediction‚Äù. In: Technometrics 35.3 (1993), pp. 243‚Äì255.\n[57]\nDavid A Egger, Andrew M Rappe, and Leeor Kronik. ‚ÄúHybrid organic‚Äìinorganic perovskites on the\nmove‚Äù. In: Accounts of chemical research 49.3 (2016), pp. 573‚Äì581.\n[58]\nRoger Lumley. Fundamentals of aluminium metallurgy: production, processing and applications.\nElsevier, 2010.\n[59]\nAdam Kopper, Rasika Karkare, Randy C Paffenroth, and Diran Apelian. ‚ÄúModel selection and eval-\nuation for machine learning: deep learning in materials processing‚Äù. In: Integrating Materials and\nManufacturing Innovation 9 (2020), pp. 287‚Äì300.\n[60]\nJonathan Tammer Eweis-Labolle, Nicholas Oune, and Ramin Bostanabad. ‚ÄúData Fusion With Latent\nMap Gaussian Processes‚Äù. In: Journal of Mechanical Design 144.9 (2022), p. 091703.\n26\n",
  "categories": [
    "stat.ML",
    "cs.LG"
  ],
  "published": "2023-06-15",
  "updated": "2023-06-15"
}