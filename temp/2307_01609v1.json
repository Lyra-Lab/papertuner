{
  "id": "http://arxiv.org/abs/2307.01609v1",
  "title": "A Language Model for Grammatical Error Correction in L2 Russian",
  "authors": [
    "Nikita Remnev",
    "Sergei Obiedkov",
    "Ekaterina Rakhilina",
    "Ivan Smirnov",
    "Anastasia Vyrenkova"
  ],
  "abstract": "Grammatical error correction is one of the fundamental tasks in Natural\nLanguage Processing. For the Russian language, most of the spellcheckers\navailable correct typos and other simple errors with high accuracy, but often\nfail when faced with non-native (L2) writing, since the latter contains errors\nthat are not typical for native speakers. In this paper, we propose a pipeline\ninvolving a language model intended for correcting errors in L2 Russian\nwriting. The language model proposed is trained on untagged texts of the\nNewspaper subcorpus of the Russian National Corpus, and the quality of the\nmodel is validated against the RULEC-GEC corpus.",
  "text": "arXiv:2307.01609v1  [cs.CL]  4 Jul 2023\nA Language Model for Grammatical Error\nCorrection in L2 Russian\nNikita Remnev[0000−0002−1816−3823], Sergei Obiedkov[0000−0003−1497−4001],\nEkaterina Rakhilina[0000−0002−7126−0905], Ivan Smirnov[0000−0001−8361−0282],\nand Anastasia Vyrenkova[0000−0003−1707−7525]\nHSE University, 11 Pokrovsky Bulvar, Moscow, Russia\nremnev.nikita@gmail.com, sergei.obj@gmail.com, erakhilina@hse.ru,\nsmirnof.van@gmail.com, avyrenkova@hse.ru\nAbstract. Grammatical error correction is one of the fundamental tasks\nin Natural Language Processing. For the Russian language, most of the\nspellcheckers available correct typos and other simple errors with high\naccuracy, but often fail when faced with non-native (L2) writing, since\nthe latter contains errors that are not typical for native speakers. In this\npaper, we propose a pipeline involving a language model intended for\ncorrecting errors in L2 Russian writing. The language model proposed\nis trained on untagged texts of the Newspaper subcorpus of the Russian\nNational Corpus, and the quality of the model is validated against the\nRULEC-GEC corpus.\nKeywords: NLP · RULEC-GEC · Grammatical Error Correction · Lan-\nguage Model · L2\n1\nIntroduction\nGrammatical error correction (GEC) is one of the fundamental tasks in Natural\nLanguage Processing (NLP). Errors of diﬀerent types challenge GEC systems at\ndiﬀerent levels. Most current systems are suﬃciently good in dealing with typos,\nwhich can usually be corrected by considering the words that are closest to the\nerroneous word in terms of edit distance [1,2]. A language model can help choose\nthe right word among several options at the same distance. More complex cases\ninclude words with several typos, agreement and lexical choice errors, and other\ntypes of errors. To address such cases, it is possible to apply manually designed\nrules [3] or use machine learning methods, in particular, approaches based on\nclassiﬁcation [4] or machine translation [5], which require a large amount of data\n(most often, tagged) for training.\nOne of the best spellcheckers available for the Russian language is Yan-\ndex.Speller.1 This tool is capable of detecting and correcting errors in Russian,\nUkrainian, and English texts by using the CatBoost machine-learning library.2\n1 https://yandex.ru/dev/speller/\n2 https://catboost.ai\n2\nN. Remnev et al.\nOne of the advantages of Yandex.Speller is that it can handle words that are still\nmissing from dictionaries. To correct punctuation errors speciﬁc models focused\non punctuation marks are trained. Incorrect word choices and errors involving\nmultiple words are the most diﬃcult error types. Such errors are not only hard\nto correct, but they are also hard to detect. This happens because the individual\nitems making up such expressions are written correctly; so checking for their\nexistence in the dictionary does not help. Resorting to higher-order N-grams\ncould help, but would require a critically large amount of training data.\nIn this paper, we focus on texts by two types of non-native (L2) speakers of\nRussian. The ﬁrst type is people who study Russian as a foreign language. Within\nthis group, certain words and rules used in the native language are frequently\ntransferred into the target language. The second type is constituted by so-called\nheritage speakers, i.e., people who inherited Russian from their parents, but the\ndominant language in their environment is not Russian. For heritage speakers,\ntypical are cases of unusual word creation and combination of two languages.\nGenerally, L2 texts contain signiﬁcantly more errors than texts by native speak-\ners. Often, several words in a row can be misspelled, which makes it diﬃcult to\nuse context for error correction. Fully distorted words become even harder to\nrecognize, since they come together with word formation patterns transferred\nfrom another language; lexical choice errors are also much more common than\nin native writing.\nThis paper is structured as follows. In Section 2, we overview existing ap-\nproaches to grammatical error correction. Section 3 describes the data we use\nfor constructing our spellchecker and for testing it. In Section 4, we describe the\nvarious steps of our approach and evaluate them experimentally. We conclude\nin Section 5.\n2\nRelated Work\nSeveral approaches to GEC are commonly used. We will now describe these\napproaches in some detail.\n2.1\nRule-based approach\nThe classic approach to GEC consists in designing rules for speciﬁc error types\n[6,7]. The ﬁrst rule systems were based on pattern matching substitution. Even-\ntually, they included part-of-speech markup and information obtained from syn-\ntactic trees [3]. The main advantage of a rule-based system is that it can be\nimplemented without requiring a large amount of data and complex algorithms.\nThe drawback is that it is not possible to systematize rules that would cover all\ntypes of errors, especially for languages with rich morphology systems such as\nRussian. Therefore, the use of the rule-based approach has signiﬁcant limitations\nin practice, but it can successfully complement more complex models.\nA Language Model for Grammatical Error Correction in L2 Russian\n3\n2.2\nClassiﬁer-based approach\nAs the amount of annotated data has recently grown, there are now several\napproaches that use machine learning to train classiﬁers for correcting particular\ntypes of mistakes [8,9]. For each type of error, a list of corrections is made, which\nare considered as a set of class labels. Linguistic features for the classiﬁer may\ninclude part-of-speech tags, syntactic relationships, etc. Thus, the GEC task is\nsolved as a multi-class classiﬁcation problem in which the model selects the most\nappropriate candidate from the list. The classiﬁer corrects one word for a speciﬁc\ncategory of errors, which ignores the dependencies between words in a sentence.\nIn addition, the classiﬁer assumes that adjacent words in a context contain no\ngrammatical errors. However, this is not the case in texts written by non-native\nauthors. Thus, a system that can handle only one type of errors is restricted in\nuse.\nOver time, several methods have been developed to correct multiple errors\nin one sentence. One of the most commonly used approaches consists in training\nand combining multiple classiﬁers, one for each error type. In [10], an ensemble\nof rule-based models and classiﬁers was proposed for constructing multiple cor-\nrection systems. However, this approach works only if errors are independent of\none another.\nSeveral approaches have been proposed to solve the error interaction prob-\nlem. Dahlmeier [11] developed a beam search decoder to correct interdependent\nerrors. This approach outperformed the ensemble of individual rule-based clas-\nsiﬁers and models. The classiﬁcation paradigm is used for Russian in [4], where\nclassiﬁers were developed for several common grammatical errors: preposition,\nnoun case, verb aspect, and verb agreement. The experiments were conducted\nwith training on non-native speakers’ data, as well as on native speakers’ data\nusing so-called minimal supervision. The classiﬁers performed better in terms\nof the F-measure than the machine translation approach to which they were\ncompared.\n2.3\nApproach based on machine translation\nThe current availability of a large amount of data for some languages makes it\npossible to design high-quality language models. In correcting grammatical errors\nusing language models, the main idea is that sentences assigned low probabil-\nity by the model are more likely to contain grammatical errors than sequences\nassigned a high probability.\nThe ﬁrst works showing a successful use of language models trained on large\namounts of data are [12,13,14]). Most of the GEC systems presented at the\nCoNLL 2013 [15] and CoNLL 2014 [16] were either based on language models\nor included them as components. Although, with the development of neural\nmachine translation, approaches based solely on language models have become\nless popular, they continue to be an integral part of grammatical error correction\nmodules [17]. Alikaniotis [18] propose to replace the N-gram language model\nwith several implementations of modern language models of the Transformer\n4\nN. Remnev et al.\narchitecture [19]. They evaluated their eﬀectiveness in GEC tasks and concluded\nthat advanced language models produce results comparable to those produced\nby classiﬁer-based approaches.\nIn this work, we explore the potential of a language model-based approach\nin grammatical error correction for Russian.\n2.4\nApproach based on language modeling\nThe current availability of a large amount of data for some languages makes it\npossible to design high-quality language models. In correcting grammatical errors\nusing language models, the main idea is that sentences assigned low probabil-\nity by the model are more likely to contain grammatical errors than sequences\nassigned a high probability.\nThe ﬁrst works showing a successful use of language models trained on large\namounts of data are [12,13,14]. Most of the GEC systems presented at the CoNLL\n2013 [15] and CoNLL 2014 [16] were either based on language models or included\nthem as components. Although, with the development of neural machine transla-\ntion, approaches based solely on language models have become less popular, they\ncontinue to be an integral part of grammatical error correction modules [17]. [18]\npropose to replace the N-gram language model with several implementations of\nmodern language models of the Transformer architecture [19]. They evaluated\ntheir eﬀectiveness in GEC tasks and concluded that advanced language models\nproduce results comparable to those produced by classiﬁer-based approaches.\nIn this work, we explore the potential of a language model-based approach\nin grammatical error correction for Russian.\n3\nData\nWe use the Newspaper Corpus, which is part of the Russian National Corpus\n(RNC) [21], to build our language model. The corpus contains articles from\nmajor Russian media including Izvestia, Komsomolskaya Pravda, Novy Region,\nRBC, RIA Novosti, Sovetsky Sport, and Trud collected from 2000 to 2011. The\ncorpus features a diverse vocabulary and consists of a suﬃciently large number\nof grammatically correct texts.\nTo evaluate the performance of our system, we use the test sample of the\nRULEC-GEC corpus, which has become a benchmark for the GEC problem for\nthe Russian language [4]. This corpus contains annotated data from the Russian\nLearner Corpus of Academic Writing (RULEC) [22]. RULEC consists of essays\nand papers written in the United States by university students learning Russian\nas a foreign language and heritage speakers (those who grew up in the United\nStates but had exposure to Russian at home).\nIn total, the RULEC-GEC corpus includes 12480 sentences containing about\n206000 words. The data was manually tagged by two annotators, who identiﬁed\n13 categories of errors.\nA Language Model for Grammatical Error Correction in L2 Russian\n5\nIn total, the RULEC-GEC corpus includes 12480 sentences containing about\n206000 words. The data was manually tagged by two annotators, who identiﬁed\n13 categories of errors. The markup in the RULEC-GEC corpus is similar to the\none used for GEC in English [16], which allows using the MaxMatch Scorer [23] to\nevaluate the results. This tool measures the performance of a system by checking\nhow the set ei of suggested corrections for the ith sentence of the test set meets\nthe gold standard correction set gi for the same sentence. Precision P, recall R,\nand the F-measure Fβ are deﬁned as usual:\nP =\nPn\ni=1 |ei\nT gi|\nPn\ni=1 |ei|\n(1)\nR =\nPn\ni=1 |ei\nT gi|\nPn\ni=1 |gi|\n(2)\nFβ = (1 + β2)\nPR\nβ2P + R\n(3)\nThe MaxMatch scorer was the main scoring system for the CoNLL 2013\nand CoNLL 2014 shared tasks on grammatical error correction [15,16]. The F1\nmeasure was the main performance metric at CoNLL 2013 and the F0.5 measure\nwas the main one at CoNLL 2014. In this work, we will also use F0.5 measure as\nthe main performance metric.\nIt is worth noting that the texts in RULEC-GEC were written mostly by\nauthors with a relatively high proﬁciency level in Russian. This is conﬁrmed by\nthe number of errors found in the texts contained in the corpus: it is much lower\nthan in English corpora (Table 1). Some of the techniques we propose here may\nnot be particularly suitable for correcting errors in such texts. They are more\nrelevant for texts produced by speakers with a lower level of Russian, examples\nof which can be found in the Russian Learner Corpus (RLC) [24]. RLC includes\nthe data of the RULEC-GEC corpus, as well as texts of native speakers of 27\nlanguages with diﬀerent levels of proﬁciency in Russian. Some of the examples\nconsidered in this paper are taken from this corpus.\nTable 1. Error distribution in several corpora [4]\nCorpus\nError rate\nRussian (RULEC-GEC)\n6.3%\nEnglish (FCE)\n17.7%\nEnglish (CoNLL-test)\n10.8–13.6%\nEnglish (CoNLL-train)\n6.6%\nEnglish (JFLEG)\n18.5–25.5%\n6\nN. Remnev et al.\n4\nLanguage Model for Error Correction\nIn this section, we describe our approach to error correction using a language\nmodel built from (predominantly) correct texts of the Newspaper Corpus. Our\napproach is iterative, and we correct each sentence independently from others.\nBeing responsible for certain error types, each stage of the algorithm starts and\nterminates with a number of partially corrected versions of the same sentence.\nIf several corrections of an error are possible, the number of versions main-\ntained by the algorithm can grow after one iteration. This happens, in particu-\nlar, when several adjacent words are misspelled, which makes it hard to choose\none among several corrections based on the context. To prevent an exponential\ngrowth of versions to be maintained, we keep only a constant number (ﬁve, in the\nexperiments reported below) of most promising ones after each iteration. These\nare sentences that are most likely from the point of view of the language model.\nWe use a three-gram language model with Kneser-Key smoothing trained on the\nNewspaper Corpus with KenLM [25] to estimate the sentence probability.\nWe preprocess the Newspaper Corpus to build a dictionary that registers\nthe number of occurrences of each unigram and bigram and use the Symspell\nalgorithm3 to search the dictionary for words at a certain edit distance from the\nword to be corrected. In the following subsections, we describe the stages of our\nalgorithm in detail.\n4.1\nCorrection of orthographic errors\nThe ﬁrst stage of our pipeline consists in correcting words that contain spelling\nerrors. A sentence is divided into tokens, and each token is then searched in the\ndictionary. If the search does not return any results, the token is regarded as\nerroneous. For each such token, we compose a list of possible corrections based\non the Damerau–Levenshtein distance and then select the most promising ones\nusing the language model.\nIn L2 texts, we often encounter sequences of adjacent erroneous words. We\nstart correcting such sequences from the rightmost word and then proceed from\nright to left. Although the edit distance between the incorrect and correct\nspellings of a word in L2 texts can be quite large, using a very large distance\nwhen searching for candidates can be prohibitive: not only it is computationally\ndemanding, it may hopelessly complicate the selection of the right candidate\namong a potentially huge number of completely irrelevant ones. We found em-\npirically that limiting the maximum distance by two (and by one for words of\nlength at most four) at this stage yields the best results.\nThis however means that, for particularly distorted words, candidate lists\nobtained with edit distance are often empty. To address this problem, we resort\nto phonetic word representations yielded by the Soundex algorithm [26]. We build\nan additional dictionary where a phonetic representation is associated with a list\nof dictionary words that share this representation. As an example, “пирикрасут”\n3 https://github.com/wolfgarbe/SymSpell\nA Language Model for Grammatical Error Correction in L2 Russian\n7\nis an incorrect spelling of “перекрасят” (‘will recolor’), the edit distance between\nthe two variants being equal to three. The phonetic representation of “пирикра-\nсут”, “1090390604”, is shared by eight dictionary words including “перекрасят”.\nAgain, we use the Symspell algorithm to ﬁnd not only words with the same\nphonetic representation as the erroneous word, but also words with phonetic\nrepresentations at a small edit distance, in this case, at distance at most one.\nAmong these words, we ﬁrst select those at a minimum edit distance from the\nerroneous word, and, from these, we then choose the variants that maximize the\nsentence probability.\nThe experimental results are presented in Table 2. Line 1 shows the re-\nsults for Yandex.Speller open-access spell checker discussed in Section 1 on the\nRULEC-GEC data. Line 8 reports the results of the language-model approach\ndiscussed in this section. Line 15 corresponds to the results obtained by using\nYandex.Speller ﬁrst and then applying our approach to its output. Lines 22–\n27 contain the results obtained on the same data using other methods known\nfrom the literature. The other lines correspond to various improvements to be\ndiscussed in the following sections.\nOn its own, our approach performs worse than Yandex.Speller, especially in\nterms of recall. However, when used as a postprocessing step, it increases the\nrecall, albeit at the cost of some decrease in precision, showing a higher value of\nthe F0.5 measure. Next, we describe several additions to our model that make it\npossible to further increase both precision and recall.\n4.2\nManually designed rules\nAfter correcting spelling errors, we apply two simple rules:\n1. Add a comma before the conjunctions “а” and “что” (but only if the previous\nword is not “потому”, “не”, or “ни”), as well as before forms of “который”\n(‘which’).\n2. When choosing between the preposition “о” (‘about’) and its form “об”, use\n“о” when the following word starts with a consonant or a iotiﬁed vowel (“e”,\n“ё”, “ю”, “я”) and “об” when followed by any other vowel.\nAlthough these rules admit exceptions, their application results in improved\nmetrics on the learner corpus, see Table 2, lines 2–3, 9–10, and 16–17. This\nsuggests that contexts presenting counterexamples to these rules rarely occur in\nL2 writing.\nNote that the ﬁrst rule concerns punctuation. Although, in general, we do\nnot aim at correcting punctuation errors, accurate punctuation can help correct\nother errors at later stages, and this is why we choose to apply this simple rule.\n4.3\nPrepositions correction with RuBERT\nIncorrect use of prepositions is one of the most common errors made by non-\nnative speakers. We have already discussed the incorrect usage of the prepositions\n8\nN. Remnev et al.\n“о” and “об” in the previous section. Another problematic case for non-native\nspeakers concerns the prepositions “в” and “во” / ‘in’ (“*во природе” instead of\n“в природе” / ‘in nature’), as well as “с” and “со” / ‘with’ (“*с своим” instead\nof “со своим” / ‘with one’s own’). There are also more complex cases in which a\ncompletely incorrect preposition is used; for example, “на” (‘on’) is often confused\nwith “в” (‘in’) and vice versa (‘*в рынке” / ‘in the market’ instead of “на рынке”\n/ ‘on the market’).\nTo ﬁx such errors, we apply an approach based on the neural network model\nRuBERT (Bidirectional Encoder Representations from Transforms (BERT) [27]\nfor the Russian language. To do this, we use a pretrained RuBERT for the\nMasked Language Modeling problem. The principle behind this operation is\nas follows: one token from the sentence is replaced with a masked token <\nMASK >, then the model tries to predict which token is most likely to oc-\ncur in place of the mask.\nTo correct mistakes with prepositions, we mask all prepositions in the sen-\ntence and take the most probable option suggested by the RuBERT model. We\ndetermine whether a word is a preposition or not by using a POS-tagging solu-\ntion from DeepPavlov.4 The sentence probability is calculated before and after\nthe replacement, and, if changing the preposition suﬃciently increases the prob-\nability, we accept the replacement. Since diﬀerent prepositions can ﬁt in place\nof the mask, it is important to set a high threshold, so as to avoid unnecessary\nchanges in the sentence. The results obtained after this operation are presented\nin Table 2, lines 4, 11, and 18.\nThe results show that a small number of errors get corrected. The corrections\napplied mainly concern the errors mentioned above, i.e., those in the use of the\nprepositions “в” and “во”, as well as “с” and “со”. As a result of setting a high\nthreshold, the total number of corrected errors at this stage is small, but a lower\nthreshold would have led to a decrease in the F0.5 measure due to the replacement\nof correct prepositions.\n4.4\nCorrection of agreement and control errors\nAnother type of errors is related to agreement and control. These errors are\ntypical for non-native speakers, but they also occur among native speakers, al-\nthough not so often. Agreement errors include subject–verb and adjective–noun\nagreement in gender and number. Control errors concern noun case selection\ndepending on the governing preposition, verb, or adverb. There are other types\nof agreement and control errors, but, in this paper, we only consider these types\nas the most common in the RULEC-GEC corpus.\nThe POS-tagging solution from DeepPavlov mentioned in Section 4.3 is also\nused for agreement and control errors. Speciﬁcally, this solution is used to de-\ntermine not only the part of speech of a word, but also the gender and number\nfor verbs and the case, gender, and number for nouns.\n4 https://deeppavlov.ai/\nA Language Model for Grammatical Error Correction in L2 Russian\n9\nTo detect such errors, we extract what can be called grammatical two- and\nthree-grams from the Newspaper Corpus. For each sentence of the corpus, we\ncarry out POS tagging, build a parse tree, and extract all possible chains of two\nand three words one of which is a noun. We keep the root word and replace\nthe dependent words with corresponding grammatical tags. For example, the\nsentence\nВ этих местах мало перспектив.\nyields the following chains: в местах мало, этих местах мало, мало перспек-\nтив. The latter chain gets transformed into\nмало obl | NOUN | Animacy=Inan | Case=Gen | Gender=Fem | Number=Plur\nWhen correcting errors in a sentence, we extract such two- and three-element\nchains from it and match them against chains extracted from the Newspaper\nCorpus. If some chain is not found, this is an indication of a possible error. In\nthis case, we generate potential corrections by varying the case, number, and\ngender for nouns in the chain. If a resulting chain is found among the chains\nextracted from the Newspaper Corpus, we substitute it for the original chain in\nthe sentence and recalculate the sentence probability. We then choose the that\nmaximizes the increase in probability. The error correction results for each of\nthe agreement and control error types discussed above are presented in Table 2,\nlines 5, 12, and 19. Here again, we observe an increase in F0.5, as well in both\nprecision and recall.\nExamining the results demonstrated by the other approaches as shown in\nlines 22–27 of Table 2, we see that, in terms of F0.5, our results are second to the\nmachine-translation model from [5] with ﬁne-tuning, which, unlike our model,\nneeds a large amount of labeled data for training. Our model demonstrates a\nsigniﬁcantly lower recall, but its precision is slightly better than that of a ﬁne-\ntuned model and much better than that of the model without ﬁne-tuning.\n5\nConclusion and Future Work\nIn this paper, we study the usage of a language model built from correct texts for\ngrammatical error correction in L2 writing. We use this model in isolation and\nfor postprocessing of the results obtained with the help of another spellchecker\n(Yandex.Speller, in our case). We combine it with phonetic algorithms, manually\ndesigned rules, and dedicated procedures for speciﬁc error types, in paricular,\nthose for prepositions, coordination and control errors. On RULEC-GEC corpus,\nwe obtain 64.79% precision, 17.08% recall, and 41.41% F0.5, which is better than\nthe results reported in the literature except achieved by machine-translation\nmodels with ﬁne-tuning [5].\nUsing our language model in a postprocessing step following the application\nof Yandex.Speller results in increased recall, but at the cost of decreased preci-\nsion. The decrease is not big though: the value of the F0.5 measure, which favors\n10\nN. Remnev et al.\nTable 2. Results on the RULEC-GEC test sample. The best values for the precision,\nrecall, and F0.5 are in bold and the second-best values are in italics.\nModel\nPrecision\nRecall\nF0.5\n1\nYandex.Speller\n66.17%\n12.66%\n35.86%\n2\n+ Comma rules\n66.76%\n13.53%\n37.37%\n3\n+ Preposition rule\n67.00%\n13.84%\n37.89%\n4\n+ Preposition RuBERT\n67.23%\n14.22%\n38.51%\n5\n+ Agreement and control errors\n67.43%\n14.66%\n39.03%\n8\nLanguage Model\n65.89%\n10.16%\n31.43%\n9\n+ Comma rules\n66.78%\n11.07%\n33.29%\n10\n+ Preposition rule\n67.15%\n11.38%\n33.90%\n11\n+ Preposition RuBERT\n67.35%\n11.75%\n34.61%\n12\n+ Agreement and control errors\n67.65%\n12.25%\n35.35%\n15\nYandex.Speller + Language Model\n63.51%\n15.12%\n38.73%\n16\n+ Comma rules\n64.11%\n15.99%\n40.03%\n17\n+ Preposition rule\n64.40%\n16.30%\n40.49%\n18\n+ Preposition RuBERT\n64.64%\n16.68%\n41.03%\n19\n+ Agreement and control errors\n64.79%\n17.08%\n41.41%\n22\nA. Rozovskaya, 2019 [4]\n38.00%\n7.50%\n21.00%\n23\nR. Grundkiewicz, 2019 [28]\n33.30%\n29.40% 32.47%\n24\nR. Grundkiewicz, 2019 [28] with ﬁne-tuning\n36.30%\n28.70%\n34.46%\n25\nJ. Naplava, 2019 [5]\n47.76%\n26.08%\n40.96%\n26\nJ. Naplava, 2019 [5] with ﬁne-tuning\n63.26%\n27.50% 50.20%\n27\nY. Takahashi, 2020 [29]\n48.60%\n16.80%\n35.20%\nprecision over recall, is still higher with the language model than without it. Note\nthat we obtain this improvement using a very simple language model; replacing\nit by a more advanced version (with better smoothing, etc.) could help avoid\ndecrease in precision and result in an even more signiﬁcant overall improvement.\nOur pipeline can also be extended with additional manually designed rules and\nprocedures for speciﬁc error types.\nThere is room for improvement in how candidates for correcting erroneous\nwords are generated. Currently, candidate generation is based on edit distance\nand phonetic representations. In L2 writing, derivational and lexical choice errors\nare very common. Candidate generation for those could be handled by dedicated\nmodules based on morphological and semantic considerations.\nAs future work, we also intend to incorporate into our pipeline an auxiliary\npart-of-speech language model that would be used together with the main lan-\nguage model to estimate the probability of sentences resulting from substituting\nvarious candidates for erroneous words.\nIt remains to see whether our approach can be tweaked to the point that\nit outperforms state-of-the-art models based on machine translation. It would\nalso be interesting to see if adding our method as a postprocessing step to these\nmodels can improve their performance, as it does for Yandex.Speller.\nA Language Model for Grammatical Error Correction in L2 Russian\n11\nReferences\n1. Vladimir I. Levenshtein. 1966. Binary codes capable of correcting deletions, inser-\ntions, and reversals. Soviet Physics Doklady, 10(8):707–710.\n2. Fred J. Damerau. 1964. A technique for computer detection and correction of\nspelling errors. Commun. ACM, 7(3):171–176.\n3. Grigori Sidorov, Anubhav Gupta, Martin Tozer, Dolors Catala, Angels Catena, and\nSandrine Fuentes. 2013. Rule-based system for automatic grammar correction using\nsyntactic n-grams for English language learning (L2). In Proceedings of the Seven-\nteenth Conference on Computational Natural Language Learning: Shared Task, pp.\n96–101, Soﬁa, Bulgaria. Association for Computational Linguistics.\n4. Alla Rozovskaya and Dan Roth. 2019. Grammar error correction in morphologically\nrich languages: The case of Russian.Transactions of the Association for Computa-\ntional Linguistics, 7:1–17.\n5. Jakub N´aplava and Milan Straka. 2019. Grammatical error correction in low-\nresource scenarios. In Proceedings of the 5th Workshop on Noisy User-generated\nText (W-NUT 2019), pp. 346–356,Hong Kong, China. Association for Computa-\ntional Linguistics.\n6. G. E. Heidorn, K. Jensen, L. A. Miller, R. J. Byrd, and M. S. Chodorow. 1982. The\nepistle text-critiquing system. IBM Systems Journal, 21(3):305–326.\n7. Flora Ram´ırez Bustamante and Fernando S´anchez Le´on. 1996. GramCheck: A gram-\nmar and stylechecker. In COLING 1996 vol. 1: The 16th International Conference\non Computational Linguistics.\n8. Na-Rae Han, Martin Chodorow, and Claudia Leacock. 2004. Detecting errors in\nEnglish article usage with a maximum entropy classiﬁer trained on a large, di-\nverse corpus. In Proceedings of the Fourth International Conference on Language\nResources and Evaluation (LREC’04), Lisbon, Portugal. European Language Re-\nsources Association (ELRA).\n9. Alla Rozovskaya and Dan Roth. 2011.Algorithm selection and model adaptation for\nESL correction tasks. In Proceedings of the 49th Annual Meeting of the Association\nfor Computational Linguistics: Human Language Technologies, pp. 924–933, Port-\nland, Oregon, USA. Association for Computational Linguistics.\n10. Alla Rozovskaya, Kai-Wei Chang, Mark Sammons, and Dan Roth. 2013. The\nUniversity of Illinois system in the CoNLL-2013 shared task. In Proceedings of\nthe Seventeenth Conference on Computational Natural Language Learning: Shared\nTask,pp. 13–19, Soﬁa, Bulgaria. Association for Computational Linguistics.\n11. Daniel Dahlmeier and Hwee Tou Ng. 2012b. Better evaluation for grammatical\nerror correction. In Proceedings of the 2012 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Tech-\nnologies, pp. 568–572, Montr´eal, Canada. Association for Computational Linguis-\ntics.\n12. Michael Gamon, Jianfeng Gao, Chris Brockett, Alexandre Klementiev, William\nB. Dolan, Dmitriy Belenko, and Lucy Vanderwende. 2008. Using contextualspeller\ntechniques and language modeling for ESL error correction. In Proceedings of the\nThird Inter-national Joint Conference on Natural Language Processing: vol.-I.\n13. Matthieu Hermet, Alain D´esilets, and Stan Szpakowicz. 2008.Using the web as\na linguistic re-source to automatically correct lexico-syntactic errors. In Proceed-\nings of the Sixth International Conference on Language Resources and Evalua-\ntion (LREC’08), Marrakech, Morocco. European Language Resources Association\n(ELRA).\n12\nN. Remnev et al.\n14. Xing Yi, Jianfeng Gao, and William B. Dolan. 2008. A web-based English proof-\ning system for English as a second language users. In Proceedings of the Third\nInternational Joint Conference on Natural Language Processing: vol.-II.\n15. Hwee Tou Ng, Siew Mei Wu, Yuanbin Wu, Christian Hadiwinoto, and Joel\nTetreault. 2013. The CoNLL-2013 shared task on grammatical error correction.In\nProceedings of the Seventeenth Conference on Computational Natural Language\nLearning: Shared Task, pp. 1–12, Soﬁa, Bulgaria. Association for Computational\nLinguistics.\n16. Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, ChristianHadiwinoto, Raymond Hendy\nSusanto, and Christopher Bryant. 2014. The CoNLL-2014 shared task on grammati-\ncal error correction. In Proceedings of the Eighteenth Conference on Computational\nNatural Language Learning: Shared Task, pp. 1–14, Baltimore, Maryland. Associa-\ntion for Computational Linguistics.\n17. Marcin Junczys-Dowmunt and Roman Grundkiewicz. 2016. Phrase-based machine\ntranslation is state-of-the-art for automatic grammatical error correction. In Pro-\nceedings of the 2016 Conference on Empirical Methods in Natural Language Pro-\ncessing, pp. 1546–1556, Austin, Texas. Association for Computational Linguistics.\n18. Dimitris Alikaniotis and Vipul Raheja. 2019. The unreasonable eﬀectiveness of\ntransformer language models in grammatical error correction.In Proceedings of the\nFourteenth Workshop on Innovative Use of NLP for Building Educational Applica-\ntions, pp. 127–133, Florence, Italy. Association for Computational Linguistics.\n19. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, and\nI. Polosukhin. 2017. Grammatical error correction using hybrid systemsand type\nﬁltering. In Advances in neural information processing systems, pp. 5998–6008.\n20. R. Grundkiewicz and M. Junczys-Dowmunt. 2014. The wiked error corpus: A cor-\npus of corrective wikipedia edits and its application to grammatical er-ror correction.\nIn International Conference on Natural Language Processing, pp. 478–490. Springer.\n21. Ju. Apresjan, I. Boguslavsky, B. Iomdin, L. Iomdin, A. Sannikov, and Sizov V.\n2006. A syntactically and semantically tagged corpus of russian: State of the art\nand prospects. In Proceedings of LREC, pp. 1378–1381, Genova, Italy.\n22. Anna A. Alsuﬁeva, Olesya V. Kisselev, and Sandra G.Freels. 2012. Results 2012:\nUsing ﬂagship data to develop a Russian learner corpus of academic writing. Russian\nLanguage Journal, 62:79–105.\n23. Daniel Dahlmeier and Hwee Tou Ng. 2012a. A beam-search decoder for gram-\nmatical error correction. In Proceedings of the 2012 Joint Conference on Empirical\nMethods in Natural Language Processing and Computational Natural Language\nLearning, pp. 568–578, Jeju Island, Korea. Association for Computational Linguis-\ntics.\n24. E.V. Rakhilina, A.S. Vyrenkova, E. Mustakimova,I. Smirnov, and A. Ladygina.\n2016. Building a learner corpus for russian. In Proceedings of the joint workshop on\nNLP for Computer Assisted Language Learning and NLP for Language Acquisition\nat SLTC, pp. 1–10.\n25. Kenneth Heaﬁeld, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013\nScalable modiﬁed Kneser-Ney language model estimation. In Proceedings of ACL.\n26. Hema Raghavan and James Allan. 2004. Using soundex codes for indexing names\nin ASR documents. In Proceedings of the Workshop on Inter-disciplinary Ap-\nproaches to Speech Indexing and Retrieval at HLT-NAACL 2004, pp. 22–27,\nBoston,Massachusetts, USA. Association for Computational Linguistics.\n27. Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. BERT:\nPre-training of deep bidirectional transformers for language under-standing. In Pro-\nA Language Model for Grammatical Error Correction in L2 Russian\n13\nceedings of the 2019 Conference of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Language Technologies, vol. 1, pp.\n4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.\n28. Roman Grundkiewicz and Marcin Junczys-Dowmunt. 2019. Minimally-augmented\ngrammatical error correction. In Proceedings of the 5th Workshop on Noisy User-\ngenerated Text (W-NUT 2019), pp. 357–363, Hong Kong, China. Association for\nComputational Linguistics.\n29. Yujin Takahashi, Satoru Katsumata, and Mamoru Komachi. 2020. Grammatical\nerror correction using pseudo learner corpus considering learner’s error tendency.\nIn Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics: Student Research Workshop, pp. 27–32, Online. Association for Com-\nputational Linguistics.\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2023-07-04",
  "updated": "2023-07-04"
}