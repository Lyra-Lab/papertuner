{
  "id": "http://arxiv.org/abs/2307.10652v5",
  "title": "Exploring the Landscape of Natural Language Processing Research",
  "authors": [
    "Tim Schopf",
    "Karim Arabi",
    "Florian Matthes"
  ],
  "abstract": "As an efficient approach to understand, generate, and process natural\nlanguage texts, research in natural language processing (NLP) has exhibited a\nrapid spread and wide adoption in recent years. Given the increasing research\nwork in this area, several NLP-related approaches have been surveyed in the\nresearch community. However, a comprehensive study that categorizes established\ntopics, identifies trends, and outlines areas for future research remains\nabsent. Contributing to closing this gap, we have systematically classified and\nanalyzed research papers in the ACL Anthology. As a result, we present a\nstructured overview of the research landscape, provide a taxonomy of fields of\nstudy in NLP, analyze recent developments in NLP, summarize our findings, and\nhighlight directions for future work.",
  "text": "Exploring the Landscape of Natural Language Processing Research\nTim Schopf, Karim Arabi, and Florian Matthes\nTechnical University of Munich, Department of Computer Science, Germany\n{tim.schopf,karim.arabi,matthes}@tum.de\nAbstract\nAs an efficient approach to understand, gen-\nerate, and process natural language texts, re-\nsearch in natural language processing (NLP)\nhas exhibited a rapid spread and wide adop-\ntion in recent years. Given the increasing re-\nsearch work in this area, several NLP-related\napproaches have been surveyed in the research\ncommunity. However, a comprehensive study\nthat categorizes established topics, identifies\ntrends, and outlines areas for future research\nremains absent. Contributing to closing this\ngap, we have systematically classified and an-\nalyzed research papers in the ACL Anthology.\nAs a result, we present a structured overview\nof the research landscape, provide a taxonomy\nof fields of study in NLP, analyze recent devel-\nopments in NLP, summarize our findings, and\nhighlight directions for future work. 1\n1\nIntroduction\nNatural language is a fundamental aspect of hu-\nman communication and inherent to human utter-\nances and information sharing. Accordingly, most\nhuman-generated digital data are composed in nat-\nural language. Given the ever-increasing amount\nand importance of digital data, it is not surprising\nthat computational linguists have started develop-\ning ideas on enabling machines to understand, gen-\nerate, and process natural language since the 1950s\n(Hutchins, 1999).\nMore recently, the introduction of the trans-\nformer model (Vaswani et al., 2017) and pretrained\nlanguage models (Radford and Narasimhan, 2018;\nDevlin et al., 2019) have sparked increasing inter-\nest in natural language processing (NLP). Submis-\nsions on various NLP topics and applications are\nbeing published in a growing number of journals\nand conferences, such as TACL, ACL, and EMNLP,\n1Code available: https://github.com/sebischair/Exploring-\nNLP-Research\nas well as in several smaller workshops that focus\non specific areas. Thereby, the ACL Anthology2 as\na repository for publications from many major NLP\njournals, conferences, and workshops emerges as\nan important tool for researchers. As of January\n2023, it provides access to over 80,000 articles\npublished since 1952. Figure 1 shows the distribu-\ntion of publications in the ACL Anthology over the\n50-year observation period.\n1960\n1970\n1980\n1990\n2000\n2010\n2020\nYear\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\nNumber of Papers\nFigure 1: Distribution of the number of papers per year\nin the ACL Anthology from 1952 to 2022.\nAccompanying the increase in publications,\nthere has also been a growth in the number of differ-\nent fields of study (FoS) that have been researched\nwithin the NLP domain. FoS are academic dis-\nciplines and concepts that usually consist of (but\nare not limited to) tasks or techniques (Shen et al.,\n2018). Given the rapid developments in NLP re-\nsearch, obtaining an overview of the domain and\nmaintaining it is difficult. As such, collecting in-\nsights, consolidating existing results, and present-\ning a structured overview of the field is important.\nHowever, to the best of our knowledge, no stud-\n2https://aclanthology.org\narXiv:2307.10652v5  [cs.CL]  24 Sep 2023\nNatural Language Processing\nSemantic\nText\nProcessing\nSentiment\nAnalysis\nSyntactic\nText\nProcessing\nLinguistics &\nCognitive NLP\nResponsible &\nTrustworthy NLP\nReasoning\nMultilinguality\nInformation\nRetrieval\nInformation\nExtraction &\nText Mining\nText\nGeneration \nMultimodality\nDialogue Systems &\nConversational Agents\nNatural\nLanguage\nInterfaces\nQuestion Answering\nDiscourse &\nPragmatics\nKnowledge\nRepresentation\nText Complexity\nSemantic Search\nRepresentation\nLearning\nWord Sense\nDisambiguation\nSemantic Parsing\nLanguage Models\nSemantic Similarity\nStructured Data \nin NLP\nVisual Data in NLP\nSpeech & Audio\nin NLP\nOpinion Mining\nStylistic Analysis\nIntent Recognition\nEmotion Analysis\nAspect-based\nSentiment Analysis\nPolarity Analysis\nTagging\nMorphology\nChunking\nPhonology\nTypology\nSyntactic Parsing\nText Error Correction\nText Segmentation\nPhonetics\nLinguistic Theories\nCognitive Modeling\nPsycholinguistics\nEthical NLP\nLow-Resource NLP\nRobustness in NLP\nGreen &\nSustainable NLP\nExplainability & \nInterpretability in NLP\nTextual Inference\nCommonsense\nReasoning\nKnowledge Graph\nReasoning\nMachine Reading\nComprehension\nFact & Claim\nVerification\nArgument Mining\nCross-Lingual Transfer\nMachine Translation\nCode-Switching\nTypology\nIndexing\nDocument Retrieval\nSemantic Search\nText Classification\nPassage Retrieval\nCoreference\nResolution\nText Clustering\nNamed Entity\nRecognition\nEvent Extraction\nOpen Information\nExtraction\nTerm Extraction\nText Classification\nTopic Modeling\nSummarization\nData-to-Text\nGeneration\nSummarization\nQuestion Generation\nDialogue Response\nGeneration\nCaptioning\nParaphrassing\nNumerical Reasoning\nProgramming\nLanguages in NLP\nText Normalization\nRelation Extraction\nMachine Translation\nSpeech Recognition\nText Style Transfer\nCode Generation\nFigure 2: Taxonomy of fields of study in NLP. Appendix A.1 includes more detailed descriptions of the fields of\nstudy.\nies exist yet that offer an overview of the entire\nlandscape of NLP research. To bridge this gap, we\nperformed a comprehensive study to analyze all\nresearch performed in this area by classifying es-\ntablished topics, identifying trends, and outlining\nareas for future research. Our three main contribu-\ntions are as follows:\n• We provide an extensive taxonomy of FoS in\nNLP research shown in Figure 2.\n• We systematically classify research papers in-\ncluded in the ACL Anthology and report find-\nings on the development of FoS in NLP.\n• We identify trends in NLP research and high-\nlight directions for future work.\nOur study highlights the development and cur-\nrent state of NLP research. Although we cannot\nfully cover all relevant work on this topic, we aim\nto provide a representative overview that can serve\nas a starting point for both NLP scholars and prac-\ntitioners. In addition, our analysis can assist the\nresearch community in bridging existing gaps and\nexploring various FoS in NLP.\n2\nRelated Work\nRelated literature that considers various different\nFoS in NLP is relatively scarce. Most studies fo-\ncus only on a particular FoS or sub-field of NLP\nresearch.\nFor example, related studies focus on knowledge\ngraphs in NLP (Schneider et al., 2022), explain-\nability in NLP (Danilevsky et al., 2020), ethics\nand biases in NLP (ˇSuster et al., 2017; Blodgett\net al., 2020), question answering (Liu et al., 2022b),\nor knowledge representations in language models\n(Safavi and Koutra, 2021).\nStudies that analyze NLP research based on the\nentire ACL Anthology focus on citation analyses\n(Mohammad, 2020a; Rungta et al., 2022) or vi-\nsualizations of venues, authors, and n-grams and\nkeywords extracted from publications (Mohammad,\n2020b; Parmar et al., 2020).\nAnderson et al. (2012) apply topic modeling to\nidentify different epochs in the ACL’s history.\nVarious books categorize different FoS in NLP,\nfocusing on detailed explanations for each of these\ncategories (Allen, 1995; Manning and Sch¨utze,\n1999; Jurafsky and Martin, 2009; Eisenstein, 2019;\nTunstall et al., 2022).\n3\nResearch Questions\nThe goal of our study is an extensive analysis of re-\nsearch performed in NLP by classifying established\ntopics, identifying trends, and outlining areas for\nfuture research. These objectives are reflected in\nour research questions (RQs) presented as follows:\nRQ1:\nWhat are the different FoS investigated in\nNLP research?\nAlthough most FoS in NLP are well-known and\ndefined, there currently exists no commonly used\ntaxonomy or categorization scheme that attempts\nto collect and structure these FoS in a consistent\nand understandable format. Therefore, getting an\noverview of the entire field of NLP research is dif-\nficult, especially for students and early career re-\nsearchers. While there are lists of NLP topics in\nconferences and textbooks, they tend to vary con-\nsiderably and are often either too broad or too spe-\ncialized. To classify and analyze developments in\nNLP, we need a taxonomy that encompasses a wide\nrange of different FoS in NLP. Although this tax-\nonomy may not include all possible NLP concepts,\nit needs to cover a wide range of the most popu-\nlar FoS, whereby missing FoS may be considered\nas subtopics of the included FoS. This taxonomy\nserves as an overarching classification scheme in\nwhich NLP publications can be classified accord-\ning to at least one of the included FoS, even if they\ndo not directly address one of the FoS, but only\nsubtopics thereof.\nRQ2:\nHow to classify research publications ac-\ncording to the identified FoS in NLP?\nClassifying publications according to the iden-\ntified FoS in NLP is very tedious and time-\nconsuming. Especially with a large number of FoS\nand publications, a manual approach is very costly.\nTherefore, we need an approach that can automati-\ncally classify publications according to the different\nFoS in NLP.\nRQ3:\nWhat are the characteristics and develop-\nments over time of the research literature in NLP?\nTo understand past developments in NLP re-\nsearch, we examine the evolution of popular FoS\nover time. This will allow a better understanding of\ncurrent developments and help contextualize them.\nRQ4:\nWhat are the current trends and directions\nof future work in NLP research?\nAnalyzing the classified research publications\nallows us to identify current research trends and\ngaps and predict possible future developments in\nNLP research.\n4\nClassification & Analysis\nIn this section, we report the approaches and re-\nsults of the data classification and analysis. It is\nstructured according to the formulated RQs.\n4.1\nTaxonomy of FoS in NLP research (RQ1)\nTo develop the taxonomy of FoS in NLP shown in\nFigure 2, we first examined the submission topics\nof recent years as listed on the websites of major\nNLP conferences such as ACL, EMNLP, COLING,\nor IJCNLP. In addition, we reviewed the topics of\nworkshops included in the ACL Anthology to de-\nrive further FoS. In order to include smaller topics\nthat are not necessarily mentioned on conference\nor workshop websites, we manually reviewed all\npapers from the recently published EMNLP 2022\nProceedings, extracted their FoS, and annotated all\n828 papers accordingly. This provided us with an\ninitial set of FoS, which we used to create the first\nversion of the NLP taxonomy.\nBased on our initial taxonomy, we conducted\nsemi-structured expert interviews with NLP re-\nsearchers to evaluate and adjust the taxonomy. In\nthe interviews, we placed particular emphasis on\nthe evaluation of the mapping of lower-level FoS\nto their higher-level FoS and the correctness and\ncompleteness of FoS in the NLP domain. In total,\nwe conducted more than 20 one-on-one interviews\nwith different domain experts. After conducting the\ninterviews, we noticed that experts demonstrated\na high degree of agreement on certain aspects of\nevaluation, while opinions were highly divergent\non other aspects. While we easily implemented\nchanges resulting from high expert agreement, we\nacted as the final authority in deciding whether to\nimplement a particular change for aspects with low\nexpert agreement. For example, one of the aspects\nwith the highest agreement was that certain lower-\nlevel FoS must be assigned not only to one but also\nto multiple higher-level FoS.\nBased on the interview results, we subsequently\nadjusted the annotations of the 828 EMNLP 2022\npapers and developed the final NLP-taxonomy, as\nshown in Figure 2.\n4.2\nField of Study Classification (RQ2)\nWe trained a weakly supervised classifier to clas-\nsify ACL Anthology papers according to the NLP\ntaxonomy. To obtain a training dataset, we first\ndefined keywords for each FoS included in the\nfinal taxonomy to perform a database search for\nrelevant articles. Based on the keywords, we cre-\nated search strings to query the Scopus and arXiv\ndatabases. The search string was applied to titles\nand author keywords, if available. While we lim-\nited the Scopus search results to the NLP domain\nwith additional restrictive keywords such as ”NLP”,\n”natural language processing”, or ”computational\nlinguistics”, we limited the search in arXiv to the\ncs.CL domain. We subsequently merged dupli-\ncate articles to create a multi-label dataset and re-\nmoved articles included in the EMNLP 2022 pro-\nceedings, as this dataset is used as test set. Finally,\nwe applied a fuzzy string matching heuristic and\nadded missing classes based on the previously de-\nfined FoS keywords that appear twice or more in\nthe article titles or abstracts. The final training\ndataset consists of 178,521 articles annotated on\naverage with 3.65 different FoS. On average, each\nclass includes 7936.50 articles, while the most fre-\nquent class is represented by 63728 articles and\nField of Study\n# Papers\nRepresentative Papers\nField of Study\n# Papers\nRepresentative Papers\nMachine Translation\n12,922\nLiu et al. (2020),\nGoyal et al. (2022)\nVisual Data in NLP\n2,401\nTan and Bansal (2019),\nXu et al. (2021)\nLanguage Models\n11,005\nDevlin et al. (2019),\nOuyang et al. (2022)\nEthical NLP\n2,322\nBlodgett et al. (2020),\nPerez et al. (2022)\nRepresentation Learning\n6,370\nReimers and Gurevych (2019),\nGao et al. (2021b)\nQuestion Answering\n2,208\nKarpukhin et al. (2020),\nLiu et al. (2022b))\nText Classification\n6,117\nWei and Zou (2019),\nHu et al. (2022)\nTagging\n1,968\nMalmi et al. (2019),\nWei et al. (2020)\nLow-Resource NLP\n5,863\nGao et al. (2021a),\nLiu et al. (2022a)\nSummarization\n1,856\nLiu and Lapata (2019),\nHe et al. (2022)\nDialogue Systems &\nConversational Agents\n4,678\nZhang et al. (2020),\nRoller et al. (2021)\nGreen & Sustainable NLP\n1,780\nStrubell et al. (2019),\nBen Zaken et al. (2022)\nSyntactic Parsing\n4,028\nZhou and Zhao (2019),\nGlavaˇs and Vuli´c (2021)\nCross-Lingual Transfer\n1,749\nConneau et al. (2020),\nFeng et al. (2022)\nSpeech & Audio in NLP\n3,915\nBaevski et al. (2022),\nWang et al. (2020)\nMorphology\n1,749\nMcCarthy et al. (2020),\nGoldman et al. (2022)\nKnowledge Representation 2,967\nSchneider et al. (2022),\nSafavi and Koutra (2021)\nExplainability &\nInterpretability in NLP\n1,671\nDanilevsky et al. (2020),\nPruthi et al. (2022)\nStructured Data in NLP\n2,803\nHerzig et al. (2020),\nYin et al. (2020)\nRobustness in NLP\n1,621\nHendrycks et al. (2020),\nMeade et al. (2022)\nTable 1: Overview of the most popular FoS in NLP literature. Representative papers consist of either highly cited\nstudies or comprehensive surveys on the respective FoS.\nthe least frequent class by 141 articles. We split\nthis unevenly distributed dataset into three differ-\nent random 90/10 training/validation sets and used\nthe human-annotated EMNLP 2022 articles as the\ntest dataset. For multi-label classification, we fine-\ntuned and evaluated different base models. Train-\ning and evaluation details are shown in Appendix\nA.2. We found that SPECTER 2.0 performed best\non validation and test data, with average F1 scores\nof 96.06 and 93.21, respectively, on multiple train-\ning runs. Therefore, we selected SPECTER 2.0\nas our final classification model, which we subse-\nquently trained on the combined training, valida-\ntion, and test data.\nUsing the final model, we classified all papers\nincluded in the ACL Anthology from 1952 to 2022.\nTo obtain our final dataset for analysis, we removed\nthe articles that were not truly research articles,\nsuch as prefaces; articles that were not written in\nEnglish; and articles where the classifier was uncer-\ntain and simply predicted every class possible. This\nfinal classified dataset includes a total of 74,279 re-\nsearch papers. Table 1 shows the final classification\nresults with respect to the number of publications\nfor each of the most popular FoS.\n4.3\nCharacteristics and Developments of the\nResearch Landscape (RQ3)\nConsidering the literature on NLP, we start our\nanalysis with the number of studies as an indica-\ntor of research interest. The distribution of pub-\nlications over the 50-year observation period is\nshown in Figure 1. While the first publications\nappeared in 1952, the number of annual publica-\ntions grew slowly until 2000. Accordingly, be-\ntween 2000 and 2017, the number of publications\nroughly quadrupled, whereas in the subsequent five\nyears, it doubled again. We therefore observe a\nnear-exponential growth in the number of NLP\nstudies, indicating increasing attention from the\nresearch community.\nExamining Table 1 and Figure 3, the most popu-\nlar FoS in the NLP literature and their recent devel-\nopment over time are revealed. While the majority\nof studies in NLP are related to machine translation\nor language models, the developments of both FoS\nare different. Machine translation is a thoroughly\nresearched field that has been established for a long\ntime and has experienced a modest growth rate over\nthe last 20 years. Language models have also been\nresearched for a long time. However, the number\nof publications on this topic has only experienced\nsignificant growth since 2018. Similar differences\ncan be observed when looking at the other popular\nFoS. Representation learning and text classifica-\ntion, while generally widely researched, are par-\ntially stagnant in their growth. In contrast, dialogue\nsystems & conversational agents and particularly\nlow-resource NLP continue to exhibit high growth\nrates in the number of studies. Based on the de-\nvelopment of the average number of studies on the\nremaining FoS in Figure 3, we observe a slightly\npositive growth overall. However, the majority of\nFoS are significantly less researched than the most\n2002\n2004\n2006\n2008\n2010\n2012\n2014\n2016\n2018\n2020\n2022\nYear\nAverage of Others\nDialogue Systems &\nConversational Agents\nLow-Resource NLP\nText Classification\nRepresentation Learning\nLanguage Models\nMachine Translation\nField of Study\n41\n41\n49\n42\n51\n44\n52\n52\n59\n52\n63\n60\n66\n62\n75\n69\n85\n92\n122\n129\n151\n68\n83\n109\n70\n109\n113\n109\n119\n159\n89\n153\n119\n134\n98\n166\n155\n280\n340\n479\n511\n691\n31\n32\n47\n29\n72\n69\n106\n143\n159\n140\n160\n160\n188\n163\n199\n202\n341\n528\n775\n921\n1333\n69\n74\n100\n79\n109\n92\n130\n167\n194\n143\n200\n253\n261\n279\n416\n323\n449\n479\n653\n621\n717\n18\n21\n41\n24\n36\n24\n48\n35\n70\n62\n68\n118\n169\n302\n470\n501\n651\n790\n865\n814\n860\n17\n40\n36\n41\n61\n74\n76\n83\n77\n83\n120\n123\n130\n133\n293\n338\n618\n1029\n1908\n2392\n3109\n193\n224\n265\n297\n323\n345\n401\n467\n560\n501\n639\n523\n653\n548\n595\n429\n575\n627\n885\n829\n844\nFigure 3: Distribution of number of papers by most popular FoS from 2002 to 2022.\npopular FoS. We conclude that the distribution of\nresearch across FoS is extremely unbalanced and\nthat the development of NLP research is largely\nshaped by advances in a few highly popular FoS.\n4.4\nResearch Trends and Directions for\nFuture Work (RQ4)\nFigure 4 shows the growth-share matrix of FoS in\nNLP research inspired by Henderson (1970). We\nuse it to examine current research trends and pos-\nsible future research directions by analyzing the\ngrowth rates and total number of papers related to\nthe various FoS in NLP between 2018 and 2022.\nThe upper right section of the matrix consists of\nFoS that exhibit a high growth rate and simulta-\nneously a large number of papers overall. Given\nthe growing popularity of FoS in this section, we\ncategorize them as trending stars. The lower right\nsection contains FoS that are very popular but ex-\nhibit a low growth rate. Usually, these are FoS that\nare essential for NLP research but already relatively\nmature. Hence, we categorize them as foundational\nFoS. The upper left section of the matrix contains\nFoS that exhibit a high growth rate but only very\nfew papers overall. Since the progress of these FoS\nis rather promising, but the small number of overall\npapers renders it difficult to predict their further de-\nvelopments, we categorize them as rising question\nmarks. The FoS in the lower left of the matrix are\ncategorized as niche FoS owing to their low total\nnumber of papers and their low growth rates.\nFigure 4 shows that language models are cur-\nrently receiving the most attention, which is also\nconsistent with the observations from Table 1 and\nFigure 3. Based on the latest developments in\nthis area, this trend is likely to continue and ac-\ncelerate in the near future.\nText classification,\nmachine translation, and representation learning\nrank among the most popular FoS but only show\nmarginal growth. In the long term, they may be re-\nplaced by faster-growing fields as the most popular\nFoS.\nIn general, FoS related to syntactic text process-\ning exhibit negligible growth and low popularity\noverall. Conversely, FoS concerned with responsi-\nble & trustworthy NLP, such as green & sustain-\nable NLP, low-resource NLP, and ethical NLP tend\nto exhibit a high growth rate and also high popu-\nlarity overall. This trend can also be observed in\nthe case of structured data in NLP, visual data in\nNLP, and speech & audio in NLP, all of which\nare concerned with multimodality. In addition, nat-\nural language interfaces involving dialogue sys-\ntems & conversational agents, and question answer-\ning are becoming increasingly important in the re-\nsearch community. We conclude that in addition to\nlanguage models, responsible & trustworthy NLP,\nmultimodality, and natural language interfaces are\nlikely to characterize the NLP research landscape\nin the near future.\nFurther notable developments can be observed\nin the area of reasoning, specifically with respect to\nknowledge graph reasoning and numerical reason-\ning and in various FoS related to text generation.\nAlthough these FoS are currently still relatively\nsmall, they apparently attract more and more inter-\nest from the research community and show a clear\npositive tendency toward growth.\nFigure 5 shows the innovation life cycle of the\nmost popular FoS in NLP adapted from the dif-\nfusion of innovations theory (Rogers, 1962) and\ninspired by Huber (2005). The central assumption\nTotal Number of Papers\nGrowth Rate of Number of Papers\nPassage Retrieval\nNumerical Reasoning\nText Style Transfer\nKnowledge Graph Reasoning\nGreen & Sustainable NLP\nLanguage Models\nIntent Recognition\nDialogue Response Generation\nLow-Resource NLP\nEthical NLP\nPsycholinguistics\nCode Generation\nEvent Extraction\nSummarization\nRobustness in NLP\nStructured Data in NLP\nOpinion Mining\nCommonsense Reasoning\nNamed Entity Recognition\nQuestion Answering\nCross-Lingual Transfer\nFact & Claim Verification\nExplainability & Interpretability in NLP\nVisual Data in NLP\nDialogue Systems & Conversational Agents\nProgramming Languages in NLP\nQuestion Generation\nSpeech & Audio in NLP\nSpeech Recognition\nKnowledge Representation\nRelation Extraction\nDocument Retrieval\nData-to-Text Generation\nSemantic Search\nAspect-based Sentiment Analysis\nParaphrasing\nText Complexity\nCognitive Modeling\nIndexing\nText Segmentation\nTypology\nText Clustering\nTerm Extraction\nPhonetics\nCaptioning\nText Classification\nLinguistic Theories\nText Error Correction\nTextual Inference\nStylistic Analysis\nTopic Modeling\nSemantic Similarity\nMachine Translation\nArgument Mining\nDiscourse & Pragmatics\nSemantic Parsing\nOpen Information Extraction\nRepresentation Learning\nMachine Reading Comprehension\nCoreference Resolution\nCode-Switching\nWord Sense Disambiguation\nEmotion Analysis\nTagging\nMorphology\nPhonology\nChunking\nSyntactic Parsing\nText Normalization\nPolarity Analysis\nRising Question Marks\nTrending Stars\nNiche Fields of Study\nFoundational Fields of Study\nLow\nHigh\nLow\nHigh\nMultimodality\nNatural Language Interfaces\nSemantic Text Processing\nSentiment Analysis\nSyntactic Text Processing\nLinguistics & Cognitive NLP\nResponsible & Trustworthy NLP\nReasoning\nMultilinguality\nInformation Retrieval\nInformation Extraction & Text Mining\nText Generation\nFigure 4: Growth-share matrix of FoS in NLP. The growth rates and total number of works for each FoS are\ncalculated from the start of 2018 to the end of 2022. To obtain a more uniform distribution of the data, we apply the\nYeo-Johnson transformation (Yeo and Johnson, 2000).\nof the innovation life cycle theory is that for each\ninnovation (or in this case FoS), the number of pub-\nlished research per year is normally distributed over\ntime, while the total number of published research\nreaches saturation according to a sigmoid curve.\nAppendix A.3 shows how the positions of FoS on\nthe innovation life cycle curve are determined.\nFrom Figure 5, we observe that FoS related to\nsyntactic text processing are already relatively ma-\nture and approaching the end of the innovation life\ncycle. Particularly, syntactic parsing is getting near\nthe end of its life cycle, with only late modifica-\ntions being researched. While Table 1 shows that\nmachine translation, representation learning, and\ntext classification are very popular overall, Figure\n5 reveals that they have passed the inflection point\nof the innovation life cycle curve and their develop-\nment is currently slowing down. They are adopted\nby most researchers but show stagnant or negative\ngrowth, as also indicated in Figure 4. However,\nmost of FoS have not yet reached the inflection\npoint and are still experiencing increasing growth\nrates, while research on these FoS is accelerating.\nEspecially FoS related to responsible & trustwor-\nthy NLP, multimodality, and natural language inter-\nfaces are just beginning their innovation life cycle,\nsuggesting that research in these areas will likely\naccelerate in the following years. This is also in\nline with the observations from Figure 4, where\nmost of the FoS related to these areas are catego-\nrized as trending stars. Further, we observe that\nlanguage models have passed the first two stages\nof innovation and are currently in their prime un-\nfolding phase. They are adopted by a large number\nof researchers and research on them is still acceler-\nating. Comparing this to Figure 4, where language\nmodels are among the most trending FoS, we con-\nclude that this trend is likely to continue in the near\nfuture and is unlikely to slow down anytime soon.\n5\nDiscussion\nThe observations of our comprehensive study re-\nveal several insights that we can situate to re-\nlated work. Since the first publications in 1952,\nresearchers have paid increasing attention to the\nfield of NLP, particularly after the introduction\nof Word2Vec (Mikolov et al., 2013) and accel-\nerated by BERT (Devlin et al., 2019). This ob-\nserved growth in research interest is in line with\nthe study of Mohammad (2020b). Historically,\nmachine translation was one of the first research\nfields in NLP (Jones, 1994), which continues to\nbe popular and steadily growing nowadays. How-\never, recent advances in language model training\nhave sparked increasing research efforts in this\nfield, as shown in Figure 3. Since scaling up lan-\nInflection point\nLate modifications\nIncremental change\n or additions\nIncremental change\n or additions\nNew innovation path\nInvention\nOrganized \n development\nLatency/Emergence\nPrime unfolding\nAccelerating\nMaturation\nSlowing down\nRetention or decline\nNiche saturation\nDegree of Structuration\n and Diffusion\nTime\nSyntactic Parsing\nMorphology\nMachine Translation\nTagging\nRepresentation Learning\nText Classification\nDialogue Systems & Conversational Agents\nSpeech & Audio in NLP\nLanguage Models\nKnowledge Representation\nLow-Resource NLP\nVisual Data in NLP\nStructured Data in NLP\nQuestion Answering\nExplainability & Interpretability in NLP\nCross-Lingual Transfer\nEthical NLP\nSummarization\nRobustness in NLP\nGreen & Sustainable NLP\nMultimodality\nNatural Language Interfaces\nSemantic Text Processing\nSentiment Analysis\nSyntactic Text Processing\nLinguistics & Cognitive NLP\nResponsible & Trustworthy NLP\nReasoning\nMultilinguality\nInformation Retrieval\nInformation Extraction & Text Mining\nText Generation\nFigure 5: Innovation life cycle of the most popular FoS in NLP. FoS on the left side of the curve are at the beginning\nof their life cycle. They have just been invented or are in an early phase, where innovation on FoS accelerates by a\nrising number of studies. After passing the inflection point, the FoS move towards the end of their innovation life\ncycle, where research on FoS is retained or declines and only late modifications are added to the FoS.\nguage models significantly enhance performance\non downstream tasks (Brown et al., 2020; Kaplan\net al., 2020; Wei et al., 2022a; Hoffmann et al.,\n2022), researchers continue to introduce increas-\ningly larger language models (Han et al., 2021).\nHowever, training and using these large language\nmodels involves significant challenges, including\ncomputational costs (Narayanan et al., 2021), envi-\nronmental issues (Strubell et al., 2019), and ethical\nconsiderations (Perez et al., 2022). As a result, a\nrecent increase in research efforts has been noted to\nrender language models and NLP more responsible\n& trustworthy in general, as shown in Figure 4 and\nFigure 5. Additionally, recent advances aim to train\nlarge-scale multimodal language models capable\nof understanding and generating natural language\ntext and performing all types of downstream tasks\nwhile interacting with humans through natural lan-\nguage input prompts (OpenAI, 2023). From our\nobservations in Figure 4 and Figure 5, we again\nfind support for this trend in NLP literature for mul-\ntimodality, text generation, and natural language\ninterfaces.\nAlthough language models have achieved re-\nmarkable success on various NLP tasks, their in-\nability to reason is often seen as a limitation that\ncannot be overcome by increasing the model size\nalone (Rae et al., 2022; Wei et al., 2022b; Wang\net al., 2023). Although reasoning capabilities are a\ncrucial prerequisite for the reliability of language\nmodels, this field is still relatively less researched\nand receives negligible attention. While Figure 4\nexhibits high growth rates for knowledge graph\nreasoning and numerical reasoning in particular,\nresearch related to reasoning is still rather under-\nrepresented compared to the more popular FoS.\n6\nConclusion\nRecent years have witnessed an increasing promi-\nnence of NLP research. To summarize recent devel-\nopments and provide an overview of this research\narea, we defined a taxonomy of FoS in NLP and\nanalyzed recent research developments.\nOur findings show that a large number of FoS\nhave been studied, including trending fields such\nas multimodality, responsible & trustworthy NLP,\nand natural language interfaces. While recent devel-\nopments are largely a result of recent advances in\nlanguage models, we have noted a lack of research\npertaining to teaching these language models to rea-\nson and thereby afford more reliable predictions.\n7\nLimitations\nConstructing the taxonomy highly depends on the\npersonal decisions of the authors, which can bias\nthe final result. The taxonomy may not cover all\npossible FoS and offers potential for discussions, as\ndomain experts have inherently different opinions.\nAs a countermeasure, we aligned the opinions of\nmultiple domain experts and designed the taxon-\nomy at a higher level, allowing non-included FoS\nto be considered as possible subtopics of existing\nones.\nFor this study, we limited our analysis to papers\npublished in the ACL Anthology, which typically\nfeature research presented at major international\nconferences and are written in English. However,\nresearch communities that publish their work in\nregional venues exist, often in languages other than\nEnglish. In addition, NLP research is also pre-\nsented at other prominent global conferences such\nas AAAI, NeurIPS, ICLR, or ICML. Therefore, the\nfindings we report in this study pertain specifically\nto NLP research presented at major international\nconferences and journals in English.\nFurthermore, the accuracy of the classification\nresults poses another threat to the validity of our\nstudy. Data extraction bias and classification model\nerrors may negatively affect the results. To mitigate\nthis risk, the authors regularly discussed the used\nclassification schemes and conducted a thorough\nevaluation of the performance of the classification\nmodel.\nAcknowledgments\nWe would like to thank Phillip Schneider, Stephen\nMeisenbacher, Mahdi Dhaini, Juraj Vladika, Oliver\nWardas, Anum Afzal, Wessel Poelman, and Alexan-\nder Blatzheim of sebis for helpful discussions and\nvaluable feedback.\nReferences\nHadeel Al-Negheimish, Pranava Madhyastha, and\nAlessandra Russo. 2021. Numerical reasoning in ma-\nchine reading comprehension tasks: are we there yet?\nIn Proceedings of the 2021 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n9643–9649, Online and Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nJames Allen. 1995. Natural Language Understanding.\nBenjamin Cummings.\nAshton Anderson, Dan Jurafsky, and Daniel A. Mc-\nFarland. 2012. Towards a computational history of\nthe ACL: 1980-2008. In Proceedings of the ACL-\n2012 Special Workshop on Rediscovering 50 Years of\nDiscoveries, pages 13–21, Jeju Island, Korea. Asso-\nciation for Computational Linguistics.\nAlexei Baevski, Wei-Ning Hsu, Alexis Conneau, and\nMichael Auli. 2022. Unsupervised speech recogni-\ntion.\nK. Balamurugan. 2018. Introduction to psycholinguis-\ntics—a review. In Studies in Linguistics and Litera-\nture.\nAlejandro Barredo Arrieta, Natalia D´ıaz-Rodr´ıguez,\nJavier Del Ser, Adrien Bennetot, Siham Tabik, Al-\nberto Barbado, Salvador Garcia, Sergio Gil-Lopez,\nDaniel Molina, Richard Benjamins, Raja Chatila, and\nFrancisco Herrera. 2020. Explainable artificial intel-\nligence (xai): Concepts, taxonomies, opportunities\nand challenges toward responsible ai. Information\nFusion, 58:82–115.\nIz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciB-\nERT: A pretrained language model for scientific text.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 3615–\n3620, Hong Kong, China. Association for Computa-\ntional Linguistics.\nElad Ben Zaken, Yoav Goldberg, and Shauli Ravfogel.\n2022. BitFit: Simple parameter-efficient fine-tuning\nfor transformer-based masked language-models. In\nProceedings of the 60th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 2:\nShort Papers), pages 1–9, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nYoshua Bengio, R´ejean Ducharme, and Pascal Vincent.\n2000. A neural probabilistic language model. In\nAdvances in Neural Information Processing Systems,\nvolume 13. MIT Press.\nI. A. Bessmertny, A.V. Platonov, E.A. Poleschuk, and\nMa Pengyu. 2016. Syntactic text analysis without a\ndictionary. In 2016 IEEE 10th International Confer-\nence on Application of Information and Communica-\ntion Technologies (AICT), pages 1–3.\nSu Lin Blodgett, Solon Barocas, Hal Daum´e III, and\nHanna Wallach. 2020.\nLanguage (technology) is\npower: A critical survey of “bias” in NLP. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5454–\n5476, Online. Association for Computational Lin-\nguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners.\nIn Ad-\nvances in Neural Information Processing Systems,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nArman Cohan, Sergey Feldman, Iz Beltagy, Doug\nDowney, and Daniel Weld. 2020.\nSPECTER:\nDocument-level\nrepresentation\nlearning\nusing\ncitation-informed transformers.\nIn Proceedings\nof the 58th Annual Meeting of the Association\nfor Computational Linguistics, pages 2270–2282,\nOnline. Association for Computational Linguistics.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm´an, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nEwa Dabrowska and Dagmar Divjak, editors. 2015.\nHandbook of Cognitive Linguistics. De Gruyter Mou-\nton, Berlin, M¨unchen, Boston.\nMarina Danilevsky, Kun Qian, Ranit Aharonov, Yan-\nnis Katsis, Ban Kawas, and Prithviraj Sen. 2020. A\nsurvey of the state of explainable AI for natural lan-\nguage processing. In Proceedings of the 1st Confer-\nence of the Asia-Pacific Chapter of the Association\nfor Computational Linguistics and the 10th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing, pages 447–459, Suzhou, China. Association\nfor Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nAnuj Diwan, Rakesh Vaideeswaran, Sanket Shah,\nAnkita Singh, Srinivasa Raghavan, Shreya Khare,\nVinit Unni, Saurabh Vyas, Akash Rajpuria, Chiran-\njeevi Yarra, Ashish Mittal, Prasanta Kumar Ghosh,\nPreethi Jyothi, Kalika Bali, Vivek Seshadri, Sunayana\nSitaram, Samarth Bharadwaj, Jai Nanavati, Raoul\nNanavati, and Karthik Sankaranarayanan. 2021.\nMUCS 2021: Multilingual and Code-Switching ASR\nChallenges for Low Resource Indian Languages. In\nProc. Interspeech 2021, pages 2446–2450.\nJacob Eisenstein. 2019. Introduction to natural lan-\nguage processing. MIT press.\nWafaa S. El-Kassas, Cherif R. Salama, Ahmed A. Rafea,\nand Hoda K. Mohamed. 2021. Automatic text sum-\nmarization: A comprehensive survey. Expert Sys-\ntems with Applications, 165:113679.\nFangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Ari-\nvazhagan, and Wei Wang. 2022. Language-agnostic\nBERT sentence embedding. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n878–891, Dublin, Ireland. Association for Computa-\ntional Linguistics.\nZhiyi Fu, Wangchunshu Zhou, Jingjing Xu, Hao Zhou,\nand Lei Li. 2022. Contextual representation learning\nbeyond masked language modeling. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 2701–2714, Dublin, Ireland. Association for\nComputational Linguistics.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021a.\nMaking pre-trained language models better few-shot\nlearners. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 3816–3830, Online. Association for Computa-\ntional Linguistics.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021b.\nSimCSE: Simple contrastive learning of sentence em-\nbeddings. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 6894–6910, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics.\nMuskan Garg, Seema Wazarkar, Muskaan Singh, and\nOndˇrej Bojar. 2022. Multimodality for NLP-centered\napplications: Resources, advances and frontiers. In\nProceedings of the Thirteenth Language Resources\nand Evaluation Conference, pages 6837–6847, Mar-\nseille, France. European Language Resources Asso-\nciation.\nGoran Glavaˇs and Ivan Vuli´c. 2021. Is supervised syn-\ntactic parsing beneficial for language understanding\ntasks? an empirical investigation. In Proceedings\nof the 16th Conference of the European Chapter of\nthe Association for Computational Linguistics: Main\nVolume, pages 3090–3104, Online. Association for\nComputational Linguistics.\nOmer Goldman, David Guriel, and Reut Tsarfaty. 2022.\n(un)solving morphological inflection: Lemma over-\nlap artificially inflates models’ performance. In Pro-\nceedings of the 60th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 2: Short\nPapers), pages 864–870, Dublin, Ireland. Association\nfor Computational Linguistics.\nNaman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-\nJen Chen, Guillaume Wenzek, Da Ju, Sanjana Kr-\nishnan, Marc’Aurelio Ranzato, Francisco Guzm´an,\nand Angela Fan. 2022. The Flores-101 evaluation\nbenchmark for low-resource and multilingual ma-\nchine translation. Transactions of the Association for\nComputational Linguistics, 10:522–538.\nMaarten R. Grootendorst. 2022. Bertopic: Neural topic\nmodeling with a class-based tf-idf procedure. ArXiv,\nabs/2203.05794.\nXu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao\nLiu, Yuqi Huo, Jiezhong Qiu, Yuan Yao, Ao Zhang,\nLiang Zhang, Wentao Han, Minlie Huang, Qin Jin,\nYanyan Lan, Yang Liu, Zhiyuan Liu, Zhiwu Lu,\nXipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong Wen,\nJinhui Yuan, Wayne Xin Zhao, and Jun Zhu. 2021.\nPre-trained models: Past, present and future.\nAI\nOpen, 2:225–250.\nHossein Hassani, Christina Beneki, Stephan Unger,\nMaedeh Taj Mazinani,\nand Mohammad Reza\nYeganegi. 2020. Text mining in big data analytics.\nBig Data and Cognitive Computing, 4(1).\nJunxian He, Wojciech Kryscinski, Bryan McCann,\nNazneen Rajani, and Caiming Xiong. 2022. CTRL-\nsum: Towards generic controllable text summariza-\ntion. In Proceedings of the 2022 Conference on Em-\npirical Methods in Natural Language Processing,\npages 5879–5915, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nBruce Henderson. 1970. The product portfolio.\nDan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam\nDziedzic, Rishabh Krishnan, and Dawn Song. 2020.\nPretrained transformers improve out-of-distribution\nrobustness. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 2744–2751, Online. Association for Computa-\ntional Linguistics.\nJonathan Herzig, Pawel Krzysztof Nowak, Thomas\nM¨uller, Francesco Piccinno, and Julian Eisenschlos.\n2020. TaPas: Weakly supervised table parsing via\npre-training. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4320–4333, Online. Association for Computa-\ntional Linguistics.\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch,\nElena Buchatskaya, Trevor Cai, Eliza Rutherford,\nDiego de las Casas, Lisa Anne Hendricks, Johannes\nWelbl, Aidan Clark, Tom Hennigan, Eric Noland,\nKatherine Millican, George van den Driessche, Bog-\ndan Damoc, Aurelia Guy, Simon Osindero, Karen\nSimonyan, Erich Elsen, Oriol Vinyals, Jack William\nRae, and Laurent Sifre. 2022. An empirical analysis\nof compute-optimal large language model training.\nIn Advances in Neural Information Processing Sys-\ntems.\nShengding Hu, Ning Ding, Huadong Wang, Zhiyuan\nLiu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong\nSun. 2022. Knowledgeable prompt-tuning: Incor-\nporating knowledge into prompt verbalizer for text\nclassification. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 2225–2240,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nJoseph Huber. 2005. Key environmental innovations.\nJohn Hutchins. 1999.\nRetrospect and prospect in\ncomputer-based translation. In Proceedings of Ma-\nchine Translation Summit VII, pages 30–36, Singa-\npore, Singapore.\nKaren Sparck Jones. 1994. Natural language processing:\na historical review. Current issues in computational\nlinguistics: in honour of Don Walker, pages 3–16.\nDaniel Jurafsky and James H. Martin. 2009. Speech\nand language processing, 2. ed., [pearson interna-\ntional edition] edition. Prentice Hall series in artifi-\ncial intelligence. Prentice Hall, Pearson Education\nInternational, London [u.a.].\nMihir Kale and Abhinav Rastogi. 2020. Text-to-text\npre-training for data-to-text tasks. In Proceedings of\nthe 13th International Conference on Natural Lan-\nguage Generation, pages 97–102, Dublin, Ireland.\nAssociation for Computational Linguistics.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B.\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeffrey Wu, and Dario Amodei. 2020.\nScaling laws for neural language models. CoRR,\nabs/2001.08361.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nLewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\nWen-tau Yih. 2020. Dense passage retrieval for open-\ndomain question answering. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 6769–6781,\nOnline. Association for Computational Linguistics.\nJohn Lawrence and Chris Reed. 2019. Argument min-\ning: A survey. Computational Linguistics, 45(4):765–\n818.\nElena Leitner, Georg Rehm, and Julian Moreno-\nSchneider. 2020. A dataset of German legal doc-\numents for named entity recognition. In Proceedings\nof the Twelfth Language Resources and Evaluation\nConference, pages 4478–4485, Marseille, France. Eu-\nropean Language Resources Association.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022a. What\nmakes good in-context examples for GPT-3?\nIn\nProceedings of Deep Learning Inside Out (DeeLIO\n2022): The 3rd Workshop on Knowledge Extrac-\ntion and Integration for Deep Learning Architectures,\npages 100–114, Dublin, Ireland and Online. Associa-\ntion for Computational Linguistics.\nLinqing Liu, Patrick Lewis, Sebastian Riedel, and Pon-\ntus Stenetorp. 2022b. Challenges in generalization in\nopen domain question answering. In Findings of the\nAssociation for Computational Linguistics: NAACL\n2022, pages 2014–2029, Seattle, United States. Asso-\nciation for Computational Linguistics.\nYang Liu and Mirella Lapata. 2019. Text summariza-\ntion with pretrained encoders. In Proceedings of\nthe 2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 3730–3740, Hong Kong,\nChina. Association for Computational Linguistics.\nYinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey\nEdunov, Marjan Ghazvininejad, Mike Lewis, and\nLuke Zettlemoyer. 2020. Multilingual denoising pre-\ntraining for neural machine translation.\nTransac-\ntions of the Association for Computational Linguis-\ntics, 8:726–742.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In International Confer-\nence on Learning Representations.\nBill MacCartney and Christopher D. Manning. 2007.\nNatural logic for textual inference. In Proceedings of\nthe ACL-PASCAL Workshop on Textual Entailment\nand Paraphrasing, pages 193–200, Prague. Associa-\ntion for Computational Linguistics.\nEric Malmi, Sebastian Krause, Sascha Rothe, Daniil\nMirylenka, and Aliaksei Severyn. 2019. Encode, tag,\nrealize: High-precision text editing. In Proceedings\nof the 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 5054–5065, Hong Kong,\nChina. Association for Computational Linguistics.\nChristopher D. Manning, Prabhakar Raghavan, and Hin-\nrich Sch¨utze. 2008. Introduction to Information Re-\ntrieval. Cambridge University Press.\nChristopher D. Manning and Hinrich Sch¨utze. 1999.\nFoundations of Statistical Natural Language Process-\ning. MIT Press, Cambridge, MA, USA.\nArya D. McCarthy, Christo Kirov, Matteo Grella,\nAmrit Nidhi, Patrick Xia, Kyle Gorman, Ekate-\nrina Vylomova, Sabrina J. Mielke, Garrett Nico-\nlai, Miikka Silfverberg, Timofey Arkhangelskiy, Na-\ntaly Krizhanovsky, Andrew Krizhanovsky, Elena\nKlyachko, Alexey Sorokin, John Mansfield, Valts\nErnˇstreits, Yuval Pinter, Cassandra L. Jacobs, Ryan\nCotterell, Mans Hulden, and David Yarowsky. 2020.\nUniMorph 3.0: Universal Morphology. In Proceed-\nings of the Twelfth Language Resources and Evalua-\ntion Conference, pages 3922–3931, Marseille, France.\nEuropean Language Resources Association.\nNicholas Meade, Elinor Poole-Dayan, and Siva Reddy.\n2022. An empirical survey of the effectiveness of\ndebiasing techniques for pre-trained language models.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 1878–1898, Dublin, Ireland.\nAssociation for Computational Linguistics.\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey\nDean. 2013. Efficient estimation of word representa-\ntions in vector space.\nSaif M. Mohammad. 2020a. Examining citations of nat-\nural language processing literature. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 5199–5209, On-\nline. Association for Computational Linguistics.\nSaif M. Mohammad. 2020b. NLP scholar: An interac-\ntive visual explorer for natural language processing\nliterature. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics:\nSystem Demonstrations, pages 232–255, Online. As-\nsociation for Computational Linguistics.\nDeepak Narayanan, Mohammad Shoeybi, Jared Casper,\nPatrick LeGresley, Mostofa Patwary, Vijay Kor-\nthikanti, Dmitri Vainbrand, Prethvi Kashinkunti,\nJulie Bernauer, Bryan Catanzaro, Amar Phanishayee,\nand Matei Zaharia. 2021. Efficient large-scale lan-\nguage model training on GPU clusters.\nCoRR,\nabs/2104.04473.\nTong Niu, Semih Yavuz, Yingbo Zhou, Nitish Shirish\nKeskar, Huan Wang, and Caiming Xiong. 2021. Un-\nsupervised paraphrasing with pretrained language\nmodels. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 5136–5150, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nOpenAI. 2023. Gpt-4 technical report.\nMalte Ostendorff, Nils Rethmeier, Isabelle Augenstein,\nBela Gipp, and Georg Rehm. 2022. Neighborhood\ncontrastive learning for scientific document represen-\ntations with citation embeddings. In Proceedings\nof the 2022 Conference on Empirical Methods in\nNatural Language Processing, pages 11670–11688,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul F Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback. In Advances in Neural Information\nProcessing Systems, volume 35, pages 27730–27744.\nCurran Associates, Inc.\nMonarch Parmar, Naman Jain, Pranjali Jain, P. Jayakr-\nishna Sahit, Soham Pachpande, Shruti Singh, and\nMayank Singh. 2020. Nlpexplorer: Exploring the\nuniverse of nlp papers. In Advances in Information\nRetrieval, pages 476–480, Cham. Springer Interna-\ntional Publishing.\nEthan Perez, Saffron Huang, Francis Song, Trevor Cai,\nRoman Ring, John Aslanides, Amelia Glaese, Nat\nMcAleese, and Geoffrey Irving. 2022. Red teaming\nlanguage models with language models. In Proceed-\nings of the 2022 Conference on Empirical Methods\nin Natural Language Processing, pages 3419–3448,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nEdoardo Maria Ponti, Goran Glavaˇs, Olga Majewska,\nQianchu Liu, Ivan Vuli´c, and Anna Korhonen. 2020.\nXCOPA: A multilingual dataset for causal common-\nsense reasoning. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 2362–2376, Online. As-\nsociation for Computational Linguistics.\nDanish Pruthi, Rachit Bansal, Bhuwan Dhingra, Livio\nBaldini Soares, Michael Collins, Zachary C. Lipton,\nGraham Neubig, and William W. Cohen. 2022. Eval-\nuating explanations: How much do explanations from\nthe teacher aid students? Transactions of the Associ-\nation for Computational Linguistics, 10:359–375.\nAlec Radford and Karthik Narasimhan. 2018.\nIm-\nproving language understanding by generative pre-\ntraining.\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, Eliza Rutherford, Tom Hennigan, Ja-\ncob Menick, Albin Cassirer, Richard Powell, George\nvan den Driessche, Lisa Anne Hendricks, Mari-\nbeth Rauh, Po-Sen Huang, Amelia Glaese, Jo-\nhannes Welbl, Sumanth Dathathri, Saffron Huang,\nJonathan Uesato, John Mellor, Irina Higgins, Anto-\nnia Creswell, Nat McAleese, Amy Wu, Erich Elsen,\nSiddhant Jayakumar, Elena Buchatskaya, David Bud-\nden, Esme Sutherland, Karen Simonyan, Michela Pa-\nganini, Laurent Sifre, Lena Martens, Xiang Lorraine\nLi, Adhiguna Kuncoro, Aida Nematzadeh, Elena\nGribovskaya, Domenic Donato, Angeliki Lazaridou,\nArthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-\npoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sot-\ntiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong,\nDaniel Toyama, Cyprien de Masson d’Autume, Yujia\nLi, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin,\nAidan Clark, Diego de Las Casas, Aurelia Guy,\nChris Jones, James Bradbury, Matthew Johnson,\nBlake Hechtman, Laura Weidinger, Iason Gabriel,\nWilliam Isaac, Ed Lockhart, Simon Osindero, Laura\nRimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub,\nJeff Stanway, Lorrayne Bennett, Demis Hassabis, Ko-\nray Kavukcuoglu, and Geoffrey Irving. 2022. Scaling\nlanguage models: Methods, analysis & insights from\ntraining gopher.\nNils Reimers and Iryna Gurevych. 2019.\nSentence-\nBERT: Sentence embeddings using Siamese BERT-\nnetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n3982–3992, Hong Kong, China. Association for Com-\nputational Linguistics.\nAyla Rigouts Terryn, Veronique Hoste, Patrick Drouin,\nand Els Lefever. 2020. TermEval 2020: Shared task\non automatic term extraction using the annotated cor-\npora for term extraction research (ACTER) dataset.\nIn Proceedings of the 6th International Workshop on\nComputational Terminology, pages 85–94, Marseille,\nFrance. European Language Resources Association.\nE.M. Rogers. 1962. Diffusion of Innovations. Free\nPress of Glencoe.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju,\nMary Williamson, Yinhan Liu, Jing Xu, Myle Ott,\nEric Michael Smith, Y-Lan Boureau, and Jason We-\nston. 2021. Recipes for building an open-domain\nchatbot. In Proceedings of the 16th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics: Main Volume, pages 300–325,\nOnline. Association for Computational Linguistics.\nMukund Rungta, Janvijay Singh, Saif M. Mohammad,\nand Diyi Yang. 2022. Geographic citation gaps in\nNLP research. In Proceedings of the 2022 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing, pages 1371–1383, Abu Dhabi, United Arab\nEmirates. Association for Computational Linguistics.\nTara Safavi and Danai Koutra. 2021. Relational World\nKnowledge Representation in Contextual Language\nModels: A Review.\nIn Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1053–1067, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nPhillip Schneider, Tim Schopf, Juraj Vladika, Mikhail\nGalkin, Elena Simperl, and Florian Matthes. 2022.\nA decade of knowledge graphs in natural language\nprocessing: A survey. In Proceedings of the 2nd\nConference of the Asia-Pacific Chapter of the Asso-\nciation for Computational Linguistics and the 12th\nInternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers), pages 601–614,\nOnline only. Association for Computational Linguis-\ntics.\nTim Schopf, Daniel Braun, and Florian Matthes. 2021.\nLbl2vec: An embedding-based approach for unsu-\npervised document retrieval on predefined topics. In\nProceedings of the 17th International Conference on\nWeb Information Systems and Technologies - WE-\nBIST, pages 124–132. INSTICC, SciTePress.\nTim Schopf, Daniel Braun, and Florian Matthes. 2023a.\nEvaluating unsupervised text classification: Zero-\nshot and similarity-based approaches. In Proceed-\nings of the 2022 6th International Conference on\nNatural Language Processing and Information Re-\ntrieval, NLPIR ’22, page 6–15, New York, NY, USA.\nAssociation for Computing Machinery.\nTim Schopf, Daniel Braun, and Florian Matthes. 2023b.\nSemantic label representations with lbl2vec:\nA\nsimilarity-based approach for unsupervised text clas-\nsification. In Web Information Systems and Tech-\nnologies, pages 59–73, Cham. Springer International\nPublishing.\nTim Schopf, Emanuel Gerber, Malte Ostendorff, and\nFlorian Matthes. 2023c. Aspectcse: Sentence em-\nbeddings for aspect-based semantic textual similarity\nusing contrastive learning and structured knowledge.\nTim Schopf, Simon Klimek, and Florian Matthes. 2022.\nPatternrank: Leveraging pretrained language models\nand part of speech for unsupervised keyphrase extrac-\ntion. In Proceedings of the 14th International Joint\nConference on Knowledge Discovery, Knowledge En-\ngineering and Knowledge Management (IC3K 2022)\n- KDIR, pages 243–248. INSTICC, SciTePress.\nTim Schopf, Dennis Schneider, and Florian Matthes.\n2023d. Efficient domain adaptation of sentence em-\nbeddings using adapters.\nZhihong Shen, Hao Ma, and Kuansan Wang. 2018.\nA web-scale system for scientific knowledge explo-\nration. In Proceedings of ACL 2018, System Demon-\nstrations, pages 87–92, Melbourne, Australia. Asso-\nciation for Computational Linguistics.\nAmanpreet Singh, Mike D’Arcy, Arman Cohan, Doug\nDowney, and Sergey Feldman. 2022.\nScirepeval:\nA multi-format benchmark for scientific document\nrepresentations. ArXiv, abs/2211.13308.\nLinfeng Song, Zhiguo Wang, Wael Hamza, Yue Zhang,\nand Daniel Gildea. 2018.\nLeveraging context in-\nformation for natural question generation. In Pro-\nceedings of the 2018 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Vol-\nume 2 (Short Papers), pages 569–574, New Orleans,\nLouisiana. Association for Computational Linguis-\ntics.\nNikita Soni, Matthew Matero, Niranjan Balasubrama-\nnian, and H. Andrew Schwartz. 2022. Human lan-\nguage modeling. In Findings of the Association for\nComputational Linguistics: ACL 2022, pages 622–\n636, Dublin, Ireland. Association for Computational\nLinguistics.\nEmma Strubell, Ananya Ganesh, and Andrew McCal-\nlum. 2019. Energy and policy considerations for\ndeep learning in NLP. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 3645–3650, Florence, Italy. Asso-\nciation for Computational Linguistics.\nRon Sun. 2020. Cognitive modeling.\nSimon ˇSuster, St´ephan Tulkens, and Walter Daelemans.\n2017. A short review of ethical challenges in clinical\nnatural language processing. In Proceedings of the\nFirst ACL Workshop on Ethics in Natural Language\nProcessing, pages 80–87, Valencia, Spain. Associa-\ntion for Computational Linguistics.\nHao Tan and Mohit Bansal. 2019. LXMERT: Learning\ncross-modality encoder representations from trans-\nformers. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n5100–5111, Hong Kong, China. Association for Com-\nputational Linguistics.\nL. Tunstall, L. von Werra, and T. Wolf. 2022. Natural\nLanguage Processing with Transformers. O’Reilly\nMedia.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, volume 30. Curran Associates, Inc.\nHenrik Voigt, Monique Meuschke, Kai Lawonn, and\nSina Zarrieß. 2021. Challenges in designing natu-\nral language interfaces for complex visual models.\nIn Proceedings of the First Workshop on Bridging\nHuman–Computer Interaction and Natural Language\nProcessing, pages 66–73, Online. Association for\nComputational Linguistics.\nChanghan Wang, Yun Tang, Xutai Ma, Anne Wu,\nDmytro Okhonko, and Juan Pino. 2020.\nFairseq\nS2T: Fast speech-to-text modeling with fairseq. In\nProceedings of the 1st Conference of the Asia-Pacific\nChapter of the Association for Computational Lin-\nguistics and the 10th International Joint Conference\non Natural Language Processing: System Demon-\nstrations, pages 33–39, Suzhou, China. Association\nfor Computational Linguistics.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le,\nEd H. Chi, Sharan Narang, Aakanksha Chowdhery,\nand Denny Zhou. 2023. Self-consistency improves\nchain of thought reasoning in language models. In\nThe Eleventh International Conference on Learning\nRepresentations.\nMayur Wankhade, Annavarapu Chandra Sekhara Rao,\nand Chaitanya Kulkarni. 2022. A survey on senti-\nment analysis methods, applications, and challenges.\nArtificial Intelligence Review, 55(7):5731–5780.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, Ed H.\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy\nLiang, Jeff Dean, and William Fedus. 2022a. Emer-\ngent abilities of large language models. Transactions\non Machine Learning Research. Survey Certifica-\ntion.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,\nand Denny Zhou. 2022b. Chain of thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems.\nJason Wei and Kai Zou. 2019. EDA: Easy data augmen-\ntation techniques for boosting performance on text\nclassification tasks. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 6382–6388, Hong Kong, China. As-\nsociation for Computational Linguistics.\nZhepei Wei, Jianlin Su, Yue Wang, Yuan Tian, and\nYi Chang. 2020. A novel cascade binary tagging\nframework for relational triple extraction. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 1476–\n1488, Online. Association for Computational Linguis-\ntics.\nJustin C. Wise and Rose A. Sevcik. 2017. Language.\nIn Reference Module in Neuroscience and Biobehav-\nioral Psychology. Elsevier.\nYang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu\nWei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha\nZhang, Wanxiang Che, Min Zhang, and Lidong Zhou.\n2021. LayoutLMv2: Multi-modal pre-training for\nvisually-rich document understanding. In Proceed-\nings of the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 2579–2591, Online.\nAssociation for Computational Linguistics.\nWei Xue and Tao Li. 2018. Aspect based sentiment\nanalysis with gated convolutional networks. In Pro-\nceedings of the 56th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 2514–2523, Melbourne, Australia. As-\nsociation for Computational Linguistics.\nAlexander Yates, Michele Banko, Matthew Broadhead,\nMichael Cafarella, Oren Etzioni, and Stephen Soder-\nland. 2007. TextRunner: Open information extrac-\ntion on the web.\nIn Proceedings of Human Lan-\nguage Technologies: The Annual Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics (NAACL-HLT), pages 25–26,\nRochester, New York, USA. Association for Compu-\ntational Linguistics.\nIn-Kwon Yeo and Richard A. Johnson. 2000. A new\nfamily of power transformations to improve normal-\nity or symmetry. Biometrika, 87(4):954–959.\nKayo Yin, Kenneth DeHaan, and Malihe Alikhani. 2021.\nSigned coreference resolution. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 4950–4961, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nPengcheng Yin, Graham Neubig, Wen-tau Yih, and Se-\nbastian Riedel. 2020. TaBERT: Pretraining for joint\nunderstanding of textual and tabular data. In Proceed-\nings of the 58th Annual Meeting of the Association\nfor Computational Linguistics, pages 8413–8426, On-\nline. Association for Computational Linguistics.\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\nLiu, and Bill Dolan. 2020. DIALOGPT : Large-scale\ngenerative pre-training for conversational response\ngeneration. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics:\nSystem Demonstrations, pages 270–278, Online. As-\nsociation for Computational Linguistics.\nZhuosheng Zhang, Junjie Yang, and Hai Zhao. 2021.\nRetrospective reader for machine reading compre-\nhension. Proceedings of the AAAI Conference on\nArtificial Intelligence, 35(16):14506–14514.\nJunru Zhou and Hai Zhao. 2019. Head-Driven Phrase\nStructure Grammar parsing on Penn Treebank. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 2396–\n2408, Florence, Italy. Association for Computational\nLinguistics.\nA\nAppendix\nA.1\nFields of Study Descriptions\nIn the following, we explain the fields of study\nconcepts included in the NLP taxonomy in Figure\n2.\nA.1.1\nMultimodality\nMultimodality refers to the capability of a system\nor method to process input of different types or\n“modalities” (Garg et al., 2022). We distinguish\nbetween systems that can process text in natural\nlanguage along with visual data, speech & au-\ndio, programming languages, or structured data\nsuch as tables or graphs.\nA.1.2\nNatural Language Interfaces\nNatural language interfaces can process data based\non natural language queries (Voigt et al., 2021),\nusually implemented as question answering or\ndialogue & conversational systems.\nA.1.3\nSemantic Text Processing\nThis high-level FoS includes all types of concepts\nthat attempt to derive meaning from natural lan-\nguage and enable machines to interpret textual data\nsemantically. One of the most powerful FoS in this\nregard are language models that attempt to learn\nthe joint probability function of sequences of words\n(Bengio et al., 2000). Recent advances in language\nmodel training have enabled these models to suc-\ncessfully perform various downstream NLP tasks\n(Soni et al., 2022). In representation learning,\nsemantic text representations are usually learned in\nthe form of embeddings (Fu et al., 2022; Schopf\net al., 2023d,c), which can be used to compare the\nsemantic similarity of texts in semantic search\nsettings (Reimers and Gurevych, 2019). Addition-\nally, knowledge representations, e.g., in the form\nof knowledge graphs, can be incorporated to im-\nprove various NLP tasks (Schneider et al., 2022).\nA.1.4\nSentiment Analysis\nSentiment analysis attempts to identify and extract\nsubjective information from texts (Wankhade et al.,\n2022). Usually, studies focus on extracting opin-\nions, emotions, or polarity from texts. More re-\ncently, aspect-based sentiment analysis emerged\nas a way to provide more detailed information than\ngeneral sentiment analysis, as it aims to predict the\nsentiment polarities of given aspects or entities in\ntext (Xue and Li, 2018).\nA.1.5\nSyntactic Text Processing\nThis high-level FoS aims at analyzing the grammat-\nical syntax and vocabulary of texts (Bessmertny\net al., 2016). Representative tasks in this context\nare syntactic parsing of word dependencies in\nsentences, tagging of words to their respective\npart-of-speech, segmentation of texts into coher-\nent sections, or correction of erroneous texts with\nrespect to grammar and spelling.\nA.1.6\nLinguistics & Cognitive NLP\nLinguistics & Cognitive NLP deals with natural lan-\nguage based on the assumptions that our linguistic\nabilities are firmly rooted in our cognitive abilities,\nthat meaning is essentially conceptualization, and\nthat grammar is shaped by usage (Dabrowska and\nDivjak, 2015). Many different linguistic theories\nare present that generally argue that language acqui-\nsition is governed by universal grammatical rules\nthat are common to all typically developing hu-\nmans (Wise and Sevcik, 2017). Psycholinguistics\nattempts to model how a human brain acquires and\nproduces language, processes it, comprehends it,\nand provides feedback (Balamurugan, 2018). Cog-\nnitive modeling is concerned with modeling and\nsimulating human cognitive processes in various\nforms, particularly in a computational or mathemat-\nical form (Sun, 2020).\nA.1.7\nResponsible & Trustworthy NLP\nResponsible & trustworthy NLP is concerned with\nimplementing methods that focus on fairness, ex-\nplainability, accountability, and ethical aspects at\nits core (Barredo Arrieta et al., 2020). Green &\nsustainable NLP is mainly focused on efficient ap-\nproaches for text processing, while low-resource\nNLP aims to perform NLP tasks when data is\nscarce. Additionally, robustness in NLP attempts\nto develop models that are insensitive to biases,\nresistant to data perturbations, and reliable for out-\nof-distribution predictions.\nA.1.8\nReasoning\nReasoning enables machines to draw logical con-\nclusions and derive new knowledge based on the in-\nformation available to them, using techniques such\nas deduction and induction. Argument mining\nautomatically identifies and extracts the structure\nof inference and reasoning expressed as arguments\npresented in natural language texts (Lawrence and\nReed, 2019). Textual inference, usually modeled\nas entailment problem, automatically determines\nwhether a natural-language hypothesis can be in-\nferred from a given premise (MacCartney and Man-\nning, 2007). Commonsense reasoning bridges\npremises and hypotheses using world knowledge\nthat is not explicitly provided in the text (Ponti\net al., 2020), while numerical reasoning performs\narithmetic operations (Al-Negheimish et al., 2021).\nMachine reading comprehension aims to teach\nmachines to determine the correct answers to ques-\ntions based on a given passage (Zhang et al., 2021).\nA.1.9\nMultilinguality\nMultilinguality tackles all types of NLP tasks that\ninvolve more than one natural language and is con-\nventionally studied in machine translation. Addi-\ntionally, code-switching freely interchanges multi-\nple languages within a single sentence or between\nsentences (Diwan et al., 2021), while cross-lingual\ntransfer techniques use data and models available\nfor one language to solve NLP tasks in another\nlanguage.\nA.1.10\nInformation Retrieval\nInformation retrieval is concerned with finding\ntexts that satisfy an information need from within\nlarge collections (Manning et al., 2008). Typically,\nthis involves retrieving documents or passages.\nA.1.11\nInformation Extraction & Text Mining\nThis FoS focuses on extracting structured knowl-\nedge from unstructured text and enables the analy-\nsis and identification of patterns or correlations\nin data (Hassani et al., 2020).\nText classifica-\ntion automatically categorizes texts into predefined\nclasses Schopf et al. (2021, 2023a,b), while topic\nmodeling aims to discover latent topics in docu-\nment collections (Grootendorst, 2022), often using\ntext clustering techniques that organize semanti-\ncally similar texts into the same clusters. Summa-\nrization produces summaries of texts that include\nthe key points of the input in less space and to\nkeep repetition to a minimum (El-Kassas et al.,\n2021). Additionally, the information extraction\n& text mining FoS also includes named entity\nrecognition, which deals with the identification\nand categorization of named entities (Leitner et al.,\n2020), coreference resolution that aims to iden-\ntify all references to the same entity in discourse\n(Yin et al., 2021), term extraction that aims to ex-\ntract relevant terms such as keywords or keyphrases\n(Rigouts Terryn et al., 2020; Schopf et al., 2022),\nrelation extraction that aims to extract relations\nbetween entities, and open information extraction\nthat facilitates the domain-independent discovery\nof relational tuples (Yates et al., 2007).\nA.1.12\nText Generation\nThe objective of text generation approaches is to\ngenerate texts that are both comprehensible to hu-\nmans and indistinguishable from text authored by\nhumans. Accordingly, the input usually consists\nof text, such as in paraphrasing that renders the\ntext input in a different surface form while pre-\nserving the semantics (Niu et al., 2021), question\ngeneration that aims to generate a fluid and rele-\nvant question given a passage and a target answer\n(Song et al., 2018), or dialogue-response gener-\nation which aims to generate natural-looking text\nrelevant to the prompt (Zhang et al., 2020). In\nmany cases, however, the text is generated as a re-\nsult of input from other modalities, such as in the\ncase of data-to-text generation that generates text\nbased on structured data such as tables or graphs\n(Kale and Rastogi, 2020), captioning of images\nor videos, or speech recognition that transcribes a\nspeech waveform into text (Baevski et al., 2022).\nDataset →\nValidation\nTest\nModel ↓\nP\nR\nF1\nP\nR\nF1\nBERT\n96.57±0.14\n95.43±0.16\n96.00±0.03\n89.77±0.20\n93.58±0.07\n91.64±0.10\nRoBERTa\n95.77±0.19\n95.19±0.16\n95.48±0.17\n87.46±2.75\n93.29±0.10\n90.27±1.42\nSciBERT\n96.44±0.17\n95.65±0.14\n96.05±0.10\n90.18±3.17\n94.05±0.06\n92.06±1.65\nSPECTER 2.0\n96.44±0.11\n95.69±0.14\n96.06±0.08\n92.46±2.58\n93.99±0.22\n93.21±1.39\nSciNCL\n96.39±0.11\n95.71±0.09\n96.05±0.04\n89.97±1.85\n93.74±0.18\n91.81±0.93\nTable 2: Evaluation results for classifying papers according to the NLP taxonomy on three runs over different\nrandom train/validation splits. Since the distribution of classes is very unbalanced, we report micro scores.\nA.2\nEvaluating Fields of Study Classification\nModels\nFor multi-label classification, BERT (Devlin et al.,\n2019), RoBERTa (Liu et al., 2019), SciBERT (Belt-\nagy et al., 2019), SPECTER 2.0 (Cohan et al., 2020;\nSingh et al., 2022), and SciNCL (Ostendorff et al.,\n2022) models were fine-tuned in their base versions\non the three different training datasets and evalu-\nated on their respective validation and test datasets.\nWe trained all models for three epochs, using a\nbatch size of 8, a learning rate of 5e −5, and the\nAdamW optimizer (Loshchilov and Hutter, 2019).\nThe evaluation results are shown in Table 2.\nA.3\nCalculating the Positions of Fields of\nStudy on the Innovation Life Cycle Curve\nWe consider the following aspects which influence\nthe position of a FoS on the innovation life cycle\ncurve:\n• A high growth rate in the number of publica-\ntions indicates that FoS are at the beginning\nof their life cycle, while a stagnant or nega-\ntive growth rate indicates a tendency toward\nmaturation.\n• If the number of recently published papers ac-\ncounts for a significant percentage of the total\nnumber of papers published on a certain FoS\nover time, this indicates the new development\nof a FoS.\n• A high percentage of recent publications on\na certain FoS compared to the total number\nof recent publications on all FoS indicates\nthe maturity of a FoS and its adoption by the\nmajority of researchers.\nAccordingly, we define the position of a set of\nFoS F = {f1, .., fm} on the x-axis of the innova-\ntion life cycle curve as:\nxfi = log\n\u0012\n1\ngt−n,t(fi)·\n1\nht−n,t(fi)·kt−n,t(fi)\n\u0013\n(1)\nwhere t is a specific year, gt−n,t(fi) is the growth\nrate of the number of publications for a particular\nFoS, normalized between 1e−10 and 1, ht−n,t(fi)\nis the percentage of the number of papers for a\nparticular FoS in a chosen time period compared to\nthe total number of papers for the same FoS over\nthe entire observed time period, and kt−n,t(fi) is\nthe percentage of the number of publications for\na specific FoS in a chosen time period compared\nto all publications in the same time period across\nall FoS. We choose a five-year time period with\nt = 2022 and n = 5, while the entire observed\ntime period ranges from 1952 to 2022. Finally, to\nmap the FoS to the innovation life cycle curve, we\nnormalize X = {xf1, .., xfm} between lower and\nupper bounds of −5 and 5 as X′ = {x′\nf1, .., x′\nfm}\nand calculate their position on the y-axis of the\ninnovation life cycle curve as:\nyfi =\n1\n1 + e−x′\nfi\n.\n(2)\n",
  "categories": [
    "cs.CL",
    "I.2.7"
  ],
  "published": "2023-07-20",
  "updated": "2023-09-24"
}