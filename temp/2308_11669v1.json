{
  "id": "http://arxiv.org/abs/2308.11669v1",
  "title": "Class Label-aware Graph Anomaly Detection",
  "authors": [
    "Junghoon Kim",
    "Yeonjun In",
    "Kanghoon Yoon",
    "Junmo Lee",
    "Chanyoung Park"
  ],
  "abstract": "Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a\nnode is anomalous or not. One common observation we made from previous\nunsupervised methods is that they not only assume the absence of such anomaly\nlabels, but also the absence of class labels (the class a node belongs to used\nin a general node classification task). In this work, we study the utility of\nclass labels for unsupervised GAD; in particular, how they enhance the\ndetection of structural anomalies. To this end, we propose a Class Label-aware\nGraph Anomaly Detection framework (CLAD) that utilizes a limited amount of\nlabeled nodes to enhance the performance of unsupervised GAD. Extensive\nexperiments on ten datasets demonstrate the superior performance of CLAD in\ncomparison to existing unsupervised GAD methods, even in the absence of\nground-truth class label information. The source code for CLAD is available at\n\\url{https://github.com/jhkim611/CLAD}.",
  "text": "Class Label-aware Graph Anomaly Detection\nJunghoon Kim\nKAIST GSDS\nDaejeon, Republic of Korea\njhkim611@kaist.ac.kr\nYeonjun In\nKAIST ISysE\nDaejeon, Republic of Korea\nyeonjun.in@kaist.ac.kr\nKanghoon Yoon\nKAIST ISysE\nDaejeon, Republic of Korea\nykhoon08@kaist.ac.kr\nJunmo Lee\nKAIST ISysE\nDaejeon, Republic of Korea\nbubblego0217@kaist.ac.kr\nChanyoung Park∗\nKAIST ISysE & AI\nDaejeon, Republic of Korea\ncy.park@kaist.ac.kr\nABSTRACT\nUnsupervised GAD methods assume the lack of anomaly labels, i.e.,\nwhether a node is anomalous or not. One common observation we\nmade from previous unsupervised methods is that they not only\nassume the absence of such anomaly labels, but also the absence of\nclass labels (the class a node belongs to used in a general node clas-\nsification task). In this work, we study the utility of class labels for\nunsupervised GAD; in particular, how they enhance the detection\nof structural anomalies. To this end, we propose a Class Label-aware\nGraph Anomaly Detection framework (CLAD) that utilizes a limited\namount of labeled nodes to enhance the performance of unsuper-\nvised GAD. Extensive experiments on ten datasets demonstrate\nthe superior performance of CLAD in comparison to existing un-\nsupervised GAD methods, even in the absence of ground-truth\nclass label information. The source code for CLAD is available at\nhttps://github.com/jhkim611/CLAD.\nCCS CONCEPTS\n• Computing methodologies →Artificial intelligence.\nKEYWORDS\nAnomaly Detection, Attributed Graphs, Graph Neural Networks\nACM Reference Format:\nJunghoon Kim, Yeonjun In, Kanghoon Yoon, Junmo Lee, and Chanyoung\nPark. 2023. Class Label-aware Graph Anomaly Detection. In Proceedings\nof the 32nd ACM International Conference on Information and Knowledge\nManagement (CIKM ’23), October 21–25, 2023, Birmingham, United Kingdom.\nACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3583780.3615249\n1\nINTRODUCTION\nAnomalies in real-world graphs can manifest as frauds in telecom-\nmunications networks [1, 21], fake reviews in user rating sys-\ntems [17], or illicit transactions in financial networks [20]. Many\n∗Corresponding author\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nCIKM ’23, October 21–25, 2023, Birmingham, United Kingdom\n© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0124-5/23/10...$15.00\nhttps://doi.org/10.1145/3583780.3615249\nnode type\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\nShannon entropy\nStructural anomaly vs. Benign\nano: 75\nben: 3177\n(a)\nnode type\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\nDOMINANT-based detection\nano (correct): 21\nano (incorrect): 54\nben (correct): 3082\nben (incorrect): 95\n(b)\nnode type\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\nEntropy-based detection\nthreshold = 1.4\nano (correct): 71\nano (incorrect): 4\nben (correct): 3175\nben (incorrect): 2\n(c)\nFigure 1: (a) Average Shannon entropy of the neighbor-\nhood class distribution of structural anomalies/benign nodes.\n(b) GAD result of DOMINANT [3]. (c) GAD result of an\nentropy-based method, where the red horizontal line indi-\ncates the threshold (In (b) and (c), green/blue boxes indicate\ncorrectly/incorrectly classified structural anomalies, and yel-\nlow/purple boxes indicate correctly/incorrectly classified be-\nnign nodes. The number of nodes in each group is shown).\nGraph Anomaly Detection (GAD) studies employ Graph Neural\nNetworks (GNNs) due to their superior performance on various\ndownstream tasks [8, 9, 19, 22]. A line of research for GAD adopts a\nsupervised learning setting - where nodes are labeled as anomalous\nor benign - and solves a binary classification problem to detect\nanomalies [2, 4, 12, 13]. However, obtaining ground-truth anomaly\nlabels is not an easy task. For many real-world cases, only a small\nfraction of anomalous samples are annotated as such [11], which\nmakes the utilization of supervised methods in such scenarios com-\nparatively cumbersome.\nOn the other hand, unsupervised GAD methods assume the ab-\nsence of such labels, which is a more realistic scenario. Previous\nstudies [3, 14] categorize a node’s malicious behaviors into struc-\ntural anomalies - nodes that exhibit abnormal connections with\nother nodes - and attribute anomalies - nodes whose attributes sig-\nnificantly differ from those of their neighbors. Recent works [3, 15]\nhave employed GNN-based autoencoders to assign anomaly scores\nto individual nodes based on reconstruction errors. Specifically,\none GNN is trained to capture the structural information of nodes,\nwhile the other is trained to capture attribute information. The\nanomaly score for each node is computed as a weighted sum of the\nreconstruction errors from both GNNs, which do not require any\nanomaly label information.\nOne common observation we made from previous unsupervised\nmethods is that they not only assume the absence of anomaly labels\n(whether node is anomalous used in an anomaly detection task),\nbut also the absence of class labels (the class a node belongs to used\nin a general node classification task). However, since a structural\narXiv:2308.11669v1  [cs.LG]  22 Aug 2023\nCIKM ’23, October 21–25, 2023, Birmingham, United Kingdom\nKim et al.\nanomaly tends to exhibit abnormal behaviors in its vicinity (i.e.,\nneighbors) in terms of class distribution, we find that the class la-\nbel information of nodes is indeed beneficial for the GAD task. In\nFig. 1a, we show the average Shannon entropy of the neighborhood\nclass distribution for both structural anomalies and benign nodes in\nCiteseer dataset. We clearly observe that the vast majority of benign\nnodes have a lower entropy compared with that of structural anom-\nalies, indicating that structural anomalies tend to have neighboring\nnodes with a higher variety of classes. Based on this observation, in\nFig. 1c, we used the entropy value as a threshold (red line) to distin-\nguish between structural anomalies and benign nodes. Surprisingly,\nwe greatly outperformed the anomaly detection performance of an\nexisting unsupervised GAD method, DOMINANT [3], shown in\nFig. 1b, i.e., we reduced the number of anomalies that are incorrectly\nclassified as benign (54→4), and decreased the number of benign\nnodes that are incorrectly classified as anomalous (95→2) as well.\nInspired by our observations in Fig. 1, we focus on the utility\nof class labels for unsupervised GAD. More specifically, we study\nhow the class label information of nodes enhances the detection\nof structural anomalies in particular. In fact, the experiments in\nFig. 1 are conducted assuming that the node labels are known for\nall nodes, which explains the superior performance of a simple\nentropy-based anomaly detection approach as shown in Fig. 1c.\nHowever, since only a small fraction of nodes in real-world graphs\nare typically labeled, it becomes crucial to effectively utilize the\nlimited amount of labeled nodes available.\nTo this end, we propose a Class Label-aware Graph Anomaly\nDetection framework (CLAD) that utilizes a limited amount of la-\nbeled nodes to enhance the performance of unsupervised GAD.\nMore precisely, the main component of CLAD is the structural\nanomaly quantifier that uses the output of a GNN-based node clas-\nsifier to compute the discrepancy (i.e., Jenson-Shannon Divergence\n(JSD)) between the predicted class distribution of a node and the\naverage of its neighboring nodes.\nHowever, we discovered that the JSD value computed between a\nnode and its neighboring nodes is highly dependent on the degree\nof the node. In other words, introducing an additional neighbor\nto a low-degree node would significantly impact the JSD value,\nwhereas adding such a neighbor to a high-degree node would re-\nsult in a negligible change. Hence, we propose a modified JSD, i.e.,\nJSD+, to take into account the node degree information. Moreover,\nattribute anomalies are identified through an attribute anomaly\nquantifier, which is designed to compute the discrepancy between\nthe attributes of a node and its neighboring nodes. In the end, we\ncombine the anomaly scores obtained from the structural/attribute\nanomaly quantifiers to obtain the final anomaly score of each node.\nThrough extensive experiments, we demonstrate that CLAD\noutperforms existing unsupervised GAD methods, even when the\nratio of known labels is extremely small. Moreover, even in an\nextreme case where no class labels are available at all, pseudo-labels\nconstructed from simple attribute-based clustering techniques are\nenough for CLAD to successfully distinguish anomalies from benign\nnodes. This show that the framework is suitable for application\neven in scenarios where obtaining class labels is difficult. To the\nbest of our knowledge, this is the first work to consider class labels\nof nodes for unsupervised GAD.\nStructural Anomaly\nQuantifier\n \n \n \n \n \n \n \n \n\n\n\n\n\n\n\n\n \n \n \n \n: known/unknown class labels\n: attribute vectors\nInput Graph\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nGNN for node classification\nAttribute Anomaly\nQuantifier\nED\nJSD+\nFinal\nAnomaly Detector\n: 0.98\n: 0.92\n: 0.90\n: 0.36\n: 0.32\n: 0.17\n: 0.11\n: 0.03\nFigure 2: Overall framework of CLAD\n2\nPROBLEM STATEMENT\nDefinition. Let G = (V, E, A, X) denote an undirected attributed\ngraph, where V is the set of N nodes, E is the set of edges between\nthese nodes and X ∈RN ×F contains the node attributes. A ∈\nRN ×N is the adjacency matrix, in which Aij = 1 indicates vi and vj\nare linked and Aij = 0 otherwise. F is the number of node attributes\nand xi = X[i, :] ∈RF indicates the attribute vector of node vi.\nProblem. Given an attributed graph G = (V, E, A, X), our goal is\nto detect the nodes whose characteristics significantly deviate from\nthe majority of other nodes in terms of structure and attributes.\nMore specifically, we aim to give a numeric score yi ∈[0, 1] for\neach node vi such that a node with high yi is deemed anomalous.\nNote that as an unsupervised method we do not have access to\nnodes’ anomaly labels, but we do have information on a portion of\nnodes’ class labels, where C denotes the number of classes.\n3\nMETHOD\nFig. 2 illustrates the overall architecture of CLAD. First, a GNN for\nnode classification is trained in a semi-supervised manner using the\nknown class labels. Here, ground-truth class labels are used when\navailable; when not, pseudo-labels obtained from simple clustering\nalgorithms on the node attributes can be used. We then devise two\nmodules to measure the structural and attribute anomality of a node.\nThe final anomaly score for each node is calculated as a weighted\nsum of the scores from both modules.\n3.1\nStructural Anomaly Quantifier\nJensen-Shannon Divergence (JSD) [10] is a metric that measures\nthe divergence of a set of probabilities, which is defined as:\n𝐽𝑆𝐷(i) = H ©­\n«\n1\n|N(i) |\n∑︁\nj∈N(i)\npjª®\n¬\n−\n1\n|N(i) |\n∑︁\nj∈N(i)\nH (pj)\n(1)\nwhere pj ∈R𝐶is the output softmax probabilities of a GNN for\nnode vj. Regarding pj as a probability mass function over possible\nclass labels, H (pj) = −Í\nc pjc · 𝑙𝑜𝑔(pjc) is the Shannon entropy\nof pj, where pjc is the probability of node vj belonging to class\nc ∈[1, 2, ...,𝐶]. N (i) is the set of 1-hop neighboring nodes of a node\nvi including the node itself, i.e., vi. In short, 𝐽𝑆𝐷(i) is increased\nwhen the discrepancy in the class distribution of node vi and its\nneighboring nodes N (𝑖) becomes greater. From Fig. 1, we can expect\nthe JSD values of structural anomalies to be higher than those of\nbenign nodes. Moreover, the first plot of Fig. 3c shows a fairly clear\ndistinction in the 𝑙𝑜𝑔(𝐽𝑆𝐷) value between structural anomalies (in\ngreen) and benign nodes (in red), indicating that JSD can indeed be\nused as a metric for detecting structural anomalies.\nClass Label-aware Graph Anomaly Detection\nCIKM ’23, October 21–25, 2023, Birmingham, United Kingdom\n2\n3\n4\n5\n6\n7\n8\n9\nnode degree\n0.8\n1.0\n1.2\n1.4\n1.6\n1.8\n2.0\n2.2\n2.4\nlog(score)\nmean diff. (JSD)\nmean diff. (JSD2)\n(a)\nJSD\nJSD2\nJSD+\nmetric type\n0.6\n0.7\n0.8\n0.9\n1.0\nAUC score\nstruc. ano. (all) vs benign (all)\nstruc. ano. (high degree) vs benign (high degree)\nstruc. ano. (high degree) vs benign (low degree)\nstruc. ano. (low degree) vs benign (high degree)\nstruc. ano. (low degree) vs benign (low degree)\n(b)\n(c)\nED\n0\n2\n4\n6\n8\n10\nscore\nattribute anomalies\nbenign nodes\n(d)\nFigure 3: (a) Mean difference of JSD and JSD2 scores between\nstructural anomalies and benign nodes over node degrees.\n(b) ROC-AUC scores for JSD, JSD2 and JSD+ distinguishing\nnodes of different node degree groups. (c) Swarm plots of JSD,\nJSD2 and JSD+ scores for structural anomalies and benign\nnodes. (d) Swarm plot of ED scores for attribute anomalies\nand benign nodes. Citeseer dataset is used.\nAddressing node degree-bias issue in JSD. However, naively\nutilizing JSD in its base form has one major drawback. That is, when\nneighboring nodes are added/deleted, the JSD value of a relatively\nlow-degree structural anomaly would be largely affected, while a\nhigh-degree structural anomaly would see a negligible change. This\nwould make it difficult to differentiate high-degree structural anom-\nalies and benign nodes, potentially hindering the effectiveness of\nJSD. To alleviate this node degree-bias issue, we consider the node\ndegree in a way that maintains an appropriate difference in the\nvalues, which can be achieved by simply multiplying the node de-\ngree with the JSD value: 𝐽𝑆𝐷2(i) = 𝐽𝑆𝐷(i) · 𝑙𝑜𝑔(degreei). In Fig. 3a\nwe can see our intuition in action - for JSD the difference between\nstructural anomalies and benign nodes sharply declines with an\nincrease in the node degree, while for JSD2 anomalies maintain this\ndifference. Moreover, Fig. 3c shows that JSD2 better distinguishes\nstructural anomalies from benign nodes.\nYet, while JSD2 alleviates the problem of difference between scores,\nit runs into a new issue regarding the actual value of scores. Specifi-\ncally, by multiplying the node degree with the JSD value, we are at\nrisk of obtaining an extremely large value for high-degree nodes\nregardless of their anomality, which is not desired. Consequently,\nJSD2 can potentially predict benign nodes to be anomalous if their\nnode degree is high, and vice versa for low-degree structural anom-\nalies. This is evident in Fig. 3b, where we observe that JSD2 strug-\ngles more in distinguishing low-degree structural anomalies from\nhigh-degree benign nodes (as depicted by the red line).\nThis issue can be handled by using a value that doesn’t become\ntoo large for high-degree benign nodes. Based on our observation\nin Fig. 1, we can expect that a benign node’s neighboring nodes\nare likely to share the same class label as the benign node itself,\nwhile the opposite holds for structural anomalies. Thus, defining the\nnumber of neighboring nodes whose predicted class is the same as\nnode 𝑣𝑖as 𝛾i = Í\nj∈N(i) (arg max𝑐pi == arg max𝑐pj) (note that for\nobtaining𝛾i, 𝑣𝑖∉N (i)), the value (degreei−𝛾i) will tend to be small\nfor benign nodes and large for structural anomalies. Utilizing this\nvalue we devise a new metric: 𝐽𝑆𝐷+(i) = 𝐽𝑆𝐷(i) ·𝑙𝑜𝑔(degreei −𝛾i).\nJSD+ addresses the aforementioned problem by giving less weight\nto the node degree of benign nodes. In Figs. 3b and 3c, we observe\nTable 1: Statistics of the datasets used for experiments\nDataset\nN\n|E|\nF\n# Anomalies\n# Labeled nodes\nClass labels given?\nCora\n2708\n5803\n1433\n150\n812 (30%)\n⃝\nCiteseer\n3327\n5077\n3703\n150\n998 (30%)\nAmazon Computers\n13752\n245861\n767\n750\n4125 (30%)\nAmazon Photo\n7650\n119081\n745\n450\n2295 (30%)\nogbn-arxiv\n169343\n1249671\n128\n7500\n50802 (30%)\nAutomotive\n28922\n106650\n300\n3173\n-\n×\nPatio, Lawn and Garden\n30982\n124740\n300\n3173\nOffice Products\n47138\n487848\n300\n3226\nYelp\n45954\n3846979\n32\n6677\n-\n×\nElliptic\n46564\n73248\n93\n4545\nthat JSD+ improves significantly over JSD and JSD2, especially in\ndiscriminating low-degree structural anomalies from high-degree\nbenign nodes. Thus, our structural anomaly quantifier uses JSD+ to\nrepresent the structural anomality of each node.\n3.2\nAttribute Anomaly Quantifier\nTo detect attribute anomalies, we compute the discrepancy of a\nnode’s attributes compared to its neighboring nodes’ attributes.\nWe first define the divergence between two nodes vi and vj as\n𝑑𝑖𝑠𝑡(𝑖, 𝑗) = ∥xi −xj∥2 i.e., the Euclidean distance. Then, the discrep-\nancy metric used for our attribute anomaly quantifier is defined as:\n𝐸𝐷(i) =\n1\n|N(i) |\nÍ\nj∈N(i) 𝑑𝑖𝑠𝑡(𝑖, 𝑗), where N (i) is the set of 1-hop\nneighboring nodes of a node vi, and we take the mean over the dis-\ntances so that the number of neighbors does not affect the score. We\nexpect the ED values to be high for attribute anomalies as their at-\ntributes would significantly differ from those of their neighbors. In\nFig. 3d, we observe that the ED values clearly distinguish attribute\nanomalies from benign nodes.\nFinal Anomaly Detector. We compute the final anomaly score for\nnode vi as a weighted sum of its structural and attribute anomaly\nscores [3, 5, 15]: yi = 𝛼· 𝑠𝑡𝑟𝑢𝑐𝑖+ (1 −𝛼) · 𝑎𝑡𝑡𝑟𝑖, where struci and\nattri are the JSD+ and ED values obtained from the previous two\nmodules scaled to be in range [0, 1], respectively, and 𝛼∈[0, 1] is\na hyperparameter that balances the two scores. After ranking the\nfinal anomaly score for each node in descending order, we consider\nthe nodes with high rank as anomalous.\n4\nEXPERIMENTS\nDatasets. We conduct extensive experiments on ten widely used\ndatasets, which can be divided into three categories. (1) Synthetic1:\nWe use five benchmark datasets [6, 16, 18] in which anomalies\nare added following a previous well-known anomaly injection\nscheme [3] (i.e., Cora, Citeseer, Amazon Computers, Amazon Photo,\nand ogbn-arxiv). (2) Synthetic2: We create three datasets in which\nnodes are users in Amazon, edges denote the co-review relation-\nship between the users, and node attributes are the pre-trained\nembeddings of the reviews written by each user. We assume that\nan anomalous user writes fake reviews to random items, and this\nleads to anomalous links in our generated datasets (i.e., Automotive,\nPatio,Lawn and Garden, and Office Products). Synthetic2 datasets’\nanomalies follow a more realistic scenario than that of Synthetic1\ndatasets. (3) Real-world: We use two datasets [17, 20] that contain\nreal-world anomalies (i.e., Yelp and Elliptic). Data statistics are sum-\nmarized in Table 1. Note that ground-truth class labels are only\npresent for Synthetic1 datasets.\nBaselines. We compare CLAD with the following methods: DOM-\nINANT [3], CoLA [14], ANEMONE [7], AnomalyDAE [5] and\nComGA [15]. We additionally include variants of DOMINANT and\nCOLA, i.e., DOMINANT2 and CoLA2, by adding a cross-entropy\nCIKM ’23, October 21–25, 2023, Birmingham, United Kingdom\nKim et al.\nTable 2: AUC score (%) of CLAD and baselines on all datasets. The computation time(s) is included in parantheses.\nCora\nCiteseer\nAmz. Com.\nAmz. Pho.\nogbn-arxiv\nAutomotive\nPL&G\nOffice Products\nYelp\nElliptic\nDOMINANT\n89.6 (9.5)\n87.4 (24.4)\n63.4 (106.4)\n64.3 (35.1)\n77.9 (6651.7)\n72.4 (350.9)\n82.7 (407.2)\n33.6 (904.5)\n48.9 (740.4)\n16.0 (790.2)\nCoLA\n89.9 (628.3)\n89.7 (667.5)\n68.5 (2513.3)\n69.1 (1402.9)\n80.3 (28704.6)\n85.5 (4268.8)\n86.0 (5131.4)\n81.3 (7158.4)\n43.6 (9314.6)\n18.5 (6259.1)\nANEMONE\n91.0 (256.4)\n91.9 (542.2)\n65.1 (2321.8)\n65.9 (1184.7)\n80.2 (24026.5)\n60.9 4919.3)\n66.9 (5094.6)\n67.0 (7968.0)\n41.8 (9503.1)\n23.4 (6018.7)\nAnomalyDAE\n84.5 (10.1)\n82.6 (27.2)\n67.1 (116.8)\n67.6 (33.2)\n72.1 (7023.9)\n77.5 (344.6)\n74.1 (421.1)\n76.4 (1046.5)\n36.1 (767.0)\n14.7 (819.6)\nComGA\n92.2 (11.2)\n90.9 (26.7)\n69.7 (127.6)\n70.1 (36.7)\n81.0 (7203.5)\n73.4 (367.0)\n77.1 (448.6)\n82.5 (943.8)\n49.5 (786.3)\n17.1 (847.9)\nDOMINANT2\n89.1 (17.4)\n85.4 (17.6)\n63.1 (32.7)\n63.9 (20.9)\n77.5 (1543.8)\n71.1 (55.8)\n78.6 (59.9)\n34.7 (146.7)\n49.2 (190.3)\n15.9 (175.8)\nCoLA2\n76.9 (467.2)\n76.8 (933.7)\n60.6 (3511.2)\n59.8 (2238.0)\n75.3 (40171.4)\n75.3 (6515.2)\n66.2 (6528.6)\n66.4 (10432.3)\n39.7 (12148.8)\n18.7 (8041.0)\nCLAD (ours)\n94.9 (3.5)\n97.3 (3.7)\n75.6 (28.1)\n79.0 (14.8)\n84.6 (1322.1)\n91.6 (47.2)\n89.8 (53.6)\n88.1 (139.5)\n56.3 (173.6)\n49.4 (50.2)\nTable 3: AUC score (%) of CLAD and baselines on three\ndatasets. We report the results for detecting structural (s.)\nand attribute (a.) anomalies separately.\nDOMINANT\nCoLA\nANEMONE\nAnomalyDAE\nComGA\nDOMINANT2\nCoLA2\nCLAD (ours)\ns.\na.\ns.\na.\ns.\na.\ns.\na.\ns.\na.\ns.\na.\ns.\na.\ns.\na.\nCiteseer\n77.0\n95.8\n93.2\n80.9\n96.4\n87.5\n88.2\n81.5\n94.3\n82.6\n73.9\n95.2\n87.2\n65.2\n99.3\n97.7\nAmz. Com.\n69.8\n55.9\n79.2\n54.6\n73.0\n50.2\n78.8\n52.0\n80.3\n51.5\n69.9\n55.6\n68.1\n50.2\n93.1\n64.9\nAmz. Pho.\n69.4\n58.3\n78.1\n57.9\n72.5\n54.4\n76.9\n58.1\n79.4\n56.0\n69.0\n58.0\n65.3\n51.7\n96.5\n68.7\nTable 4: AUC score (%) of CLAD on three datasets while re-\nducing the ratio/number of known class labels.\n30%\n10%\n5%\n1%\n10\n1\nCiteseer\n97.3\n96.6\n96.4\n94.1\n90.2\n86.4\nAmz. Com.\n75.6\n74.9\n74.9\n74.6\n71.9\n58.8\nAmz. Pho.\n79.0\n78.9\n78.8\n78.8\n70.7\n57.3\nloss for the node classification task to their respective objective\nfunctions. For all baselines, we use the official codes published by\nthe authors, including the hyperparameter settings.\nImplementation Details. We use a two-layer GCN [9] as the\nbackbone GNN. For Synthetic1 datasets, we randomly sample 30% of\nthe ground-truth class labels. For Synthetic2 and Real-world datasets\nthat do not contain ground-truth class label information, we assign\na pseudo-label to each node via K-means clustering with 5 clusters\nbased on the node attributes. We then disregard all class label\ninformation except for the 50 nodes closest to each cluster centroid,\ni.e., we only have knowledge on 250 class labels, 50 per class. For\nall datasets the backbone GNN classifier is trained on 95% of these\nknown class labels and validated on the remaining 5%. We find the\nbest performing 𝛼from [0.0, 0.1, 0.2, ...0.9, 1.0]. The average value\nof five independent runs is reported for all results. We adopt the\nROC-AUC metric to evaluate the performance of anomaly detection.\n4.1\nPerformance Analysis\nGeneral Performance. Table 2 shows that CLAD outperforms all\nbaselines on Synthetic1 datasets, proving the effectiveness of our\nmethod in detecting anomalies present in graph data. This is further\nsupported by Table 3, which reports the detection performance in\nterms of structural and attribute anomalies separately. These results\ndemonstrate the effectiveness of our proposed metrics. By compar-\ning with DOMINANT2 and CoLA2, we can observe that naively\nusing the class label information falls short of improving the detec-\ntion performance, further proving the soundness of our proposed\nmethod. As a further appeal, we emphasize that CLAD achieves\nsuperior performance even while consuming much less computa-\ntional time(GCN training and calculating scores) than baselines,\nwhich is especially beneficial for massive datasets like ogbn-arxiv.\nThis shows the practicality of CLAD in the real-world.\nReducing the ratio/number of known class labels. We further\nreport the performance of CLAD for cases in which only a few nodes\nare labeled with class information. Table 4 shows that reducing\nCiteseer\nAmz. Com.\nAmz. Pho\nAutomotive\nOffice Products\ndataset\n70\n75\n80\n85\n90\n95\n100\nAUC score (%)\nCLAD\nCLAD-JSD2\nCLAD-JSD\n(a)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nalpha\n50\n60\n70\n80\n90\n100\nAUC score (%)\nCiteseer\nAmz. Com.\nAmz. Pho\nAutomotive\nOffice Products\n(b)\nFigure 4: (a) AUC scores (%) for CLAD and its two variants.\n(b) Effect of parameter 𝛼on CLAD’s detection performance.\nthe ratio down to 1% only incrementally hinders the performance.\nEven with access to only a handful (e.g., 10) of class labels, CLAD\nproduces results comparable to that of baselines.\nLack of class labels. As previously mentioned, experiments on\nSynthetic2 and Real-world datasets are conducted under the assump-\ntion that class labels are not available. In Table 2, we observe that\nCLAD still outperforms all baselines even with pseudo-labels ob-\ntained based on node attributes. Note that CLAD shows significant\nperformance gain especially in Real-world datasets. We argue that\nthese results demonstrate the practicality of CLAD in real-world\nscenarios where the class label information may be missing.\nAblation Study. We compare the results of CLAD with two vari-\nants that replace 𝐽𝑆𝐷+ with 𝐽𝑆𝐷and 𝐽𝑆𝐷2, respectively. Fig. 4a\nshows that the original CLAD model outperforms both CLAD-JSD2\nand CLAD-JSD. Since the output of the attribute anomaly quanti-\nfier does not change, the performance differences only stem from\nthe choice of the metric in the structural anomaly quantifier. This\ndemonstrates the superiority of 𝐽𝑆𝐷+ over 𝐽𝑆𝐷and 𝐽𝑆𝐷2.\nHyperparameter Sensitivity. We investigate the sensitivity of\nparameter 𝛼. In Fig. 4b, we observe that 𝛼should be set to a value\nbetween 0 and 1, indicating that jointly taking into account both\nperspectives of anomalies is important for achieving high detection\nperformance. Moreover, an optimal 𝛼differs across datasets.\n5\nCONCLUSION\nIn this paper, we propose a Class Label-aware Graph Anomaly\nDetection framework (CLAD) that utilizes a limited amount of\nlabeled nodes to enhance the performance of unsupervised GAD.\nSpecifically, based on our empirical analysis that the vast majority of\nbenign nodes have a much lower entropy of the neighborhood class\ndistribution compared with that of structural anomalies, we devise\na metric, called 𝐽𝑆𝐷+, that effectively and efficiently distinguishes\nstructural anomalies from benign nodes. Extensive experimental\nresults demonstrate that CLAD outperforms existing unsupervised\nGAD methods, even in the absence of ground-truth class label\ninformation - indicating CLAD’s versatility in real-world scenarios.\nAcknowledgement. No.2022-0-00077 and No.2021R1C1C1009081.\nClass Label-aware Graph Anomaly Detection\nCIKM ’23, October 21–25, 2023, Birmingham, United Kingdom\nREFERENCES\n[1] Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly\ndetection and description: a survey. Data mining and knowledge discovery 29\n(2015), 626–688.\n[2] Ziwei Chai, Siqi You, Yang Yang, Shiliang Pu, Jiarong Xu, Haoyang Cai, and\nWeihao Jiang. 2022. Can Abnormality be Detected by Graph Neural Networks?.\nIn Proceedings of the Twenty-Ninth International Joint Conference on Artificial\nIntelligence (IJCAI), Vienna, Austria. 23–29.\n[3] Kaize Ding, Jundong Li, Rohit Bhanushali, and Huan Liu. 2019. Deep anomaly\ndetection on attributed networks. In Proceedings of the 2019 SIAM International\nConference on Data Mining. SIAM, 594–602.\n[4] Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S Yu. 2020.\nEnhancing graph neural network-based fraud detectors against camouflaged\nfraudsters. In Proceedings of the 29th ACM International Conference on Information\n& Knowledge Management. 315–324.\n[5] Haoyi Fan, Fengbin Zhang, and Zuoyong Li. 2020. Anomalydae: Dual autoen-\ncoder for anomaly detection on attributed networks. In ICASSP 2020-2020 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE,\n5685–5689.\n[6] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu,\nMichele Catasta, and Jure Leskovec. 2020. Open graph benchmark: Datasets for\nmachine learning on graphs. Advances in neural information processing systems\n33 (2020), 22118–22133.\n[7] Ming Jin, Yixin Liu, Yu Zheng, Lianhua Chi, Yuan-Fang Li, and Shirui Pan. 2021.\nAnemone: Graph anomaly detection with multi-scale contrastive learning. In\nProceedings of the 30th ACM International Conference on Information & Knowledge\nManagement. 3122–3126.\n[8] Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang.\n2020. Graph structure learning for robust graph neural networks. In Proceedings\nof the 26th ACM SIGKDD international conference on knowledge discovery & data\nmining. 66–74.\n[9] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph\nconvolutional networks. arXiv preprint arXiv:1609.02907 (2016).\n[10] Jianhua Lin. 1991. Divergence measures based on the Shannon entropy. IEEE\nTransactions on Information theory 37, 1 (1991), 145–151.\n[11] Fanzhen Liu, Zhao Li, Baokun Wang, Jia Wu, Jian Yang, Jiaming Huang, Yiqing\nZhang, Weiqiang Wang, Shan Xue, Surya Nepal, et al. 2022. eRiskCom: an e-\ncommerce risky community detection platform. The VLDB Journal 31, 5 (2022),\n1085–1101.\n[12] Fanzhen Liu, Xiaoxiao Ma, Jia Wu, Jian Yang, Shan Xue, Amin Beheshti, Chuan\nZhou, Hao Peng, Quan Z Sheng, and Charu C Aggarwal. 2022. DAGAD: Data\nAugmentation for Graph Anomaly Detection. arXiv preprint arXiv:2210.09766\n(2022).\n[13] Yang Liu, Xiang Ao, Zidi Qin, Jianfeng Chi, Jinghua Feng, Hao Yang, and Qing\nHe. 2021. Pick and choose: a GNN-based imbalanced learning approach for fraud\ndetection. In Proceedings of the Web Conference 2021. 3168–3177.\n[14] Yixin Liu, Zhao Li, Shirui Pan, Chen Gong, Chuan Zhou, and George Karypis.\n2021. Anomaly detection on attributed networks via contrastive self-supervised\nlearning. IEEE transactions on neural networks and learning systems 33, 6 (2021),\n2378–2392.\n[15] Xuexiong Luo, Jia Wu, Amin Beheshti, Jian Yang, Xiankun Zhang, Yuan Wang,\nand Shan Xue. 2022. Comga: Community-aware attributed graph anomaly detec-\ntion. In Proceedings of the Fifteenth ACM International Conference on Web Search\nand Data Mining. 657–665.\n[16] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel.\n2015. Image-based recommendations on styles and substitutes. In Proceedings\nof the 38th international ACM SIGIR conference on research and development in\ninformation retrieval. 43–52.\n[17] Shebuti Rayana and Leman Akoglu. 2015. Collective opinion spam detection:\nBridging review networks and metadata. In Proceedings of the 21th acm sigkdd\ninternational conference on knowledge discovery and data mining. 985–994.\n[18] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and\nTina Eliassi-Rad. 2008. Collective classification in network data. AI magazine 29,\n3 (2008), 93–93.\n[19] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro\nLio, and Yoshua Bengio. 2017.\nGraph attention networks.\narXiv preprint\narXiv:1710.10903 (2017).\n[20] Mark Weber, Giacomo Domeniconi, Jie Chen, Daniel Karl I Weidele, Claudio\nBellei, Tom Robinson, and Charles E Leiserson. 2019. Anti-money laundering in\nbitcoin: Experimenting with graph convolutional networks for financial forensics.\narXiv preprint arXiv:1908.02591 (2019).\n[21] Yang Yang, Yuhong Xu, Yizhou Sun, Yuxiao Dong, Fei Wu, and Yueting Zhuang.\n2019. Mining fraudsters and fraudulent strategies in large-scale mobile social\nnetworks. IEEE Transactions on Knowledge and Data Engineering 33, 1 (2019),\n169–179.\n[22] Dingyuan Zhu, Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2019. Robust graph\nconvolutional networks against adversarial attacks. In Proceedings of the 25th\nACM SIGKDD international conference on knowledge discovery & data mining.\n1399–1407.\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2023-08-22",
  "updated": "2023-08-22"
}