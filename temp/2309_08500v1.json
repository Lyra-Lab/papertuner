{
  "id": "http://arxiv.org/abs/2309.08500v1",
  "title": "Deep-learning-powered data analysis in plankton ecology",
  "authors": [
    "Harshith Bachimanchi",
    "Matthew I. M. Pinder",
    "Chloé Robert",
    "Pierre De Wit",
    "Jonathan Havenhand",
    "Alexandra Kinnby",
    "Daniel Midtvedt",
    "Erik Selander",
    "Giovanni Volpe"
  ],
  "abstract": "The implementation of deep learning algorithms has brought new perspectives\nto plankton ecology. Emerging as an alternative approach to established\nmethods, deep learning offers objective schemes to investigate plankton\norganisms in diverse environments. We provide an overview of\ndeep-learning-based methods including detection and classification of phyto-\nand zooplankton images, foraging and swimming behaviour analysis, and finally\necological modelling. Deep learning has the potential to speed up the analysis\nand reduce the human experimental bias, thus enabling data acquisition at\nrelevant temporal and spatial scales with improved reproducibility. We also\ndiscuss shortcomings and show how deep learning architectures have evolved to\nmitigate imprecise readouts. Finally, we suggest opportunities where deep\nlearning is particularly likely to catalyze plankton research. The examples are\naccompanied by detailed tutorials and code samples that allow readers to apply\nthe methods described in this review to their own data.",
  "text": "Deep-learning-powered data analysis in plankton ecology\nHarshith Bachimanchi,1, ∗Matthew I. M. Pinder,2, ∗Chlo´e Robert,2, ∗Pierre De Wit,2 Jonathan\nHavenhand,2 Alexandra Kinnby,2 Daniel Midtvedt,1 Erik Selander,3 and Giovanni Volpe1\n1Department of Physics, University of Gothenburg, Sweden\n2Department of Marine Sciences, University of Gothenburg, Sweden\n3Department of Biology, Lund University, Sweden\n(Dated: September 18, 2023)\nThe implementation of deep learning algorithms has brought new perspectives to plankton ecology.\nEmerging as an alternative approach to established methods, deep learning offers objective schemes\nto investigate plankton organisms in diverse environments. We provide an overview of deep-learning-\nbased methods including detection and classification of phyto- and zooplankton images, foraging and\nswimming behaviour analysis, and finally ecological modelling. Deep learning has the potential to\nspeed up the analysis and reduce the human experimental bias, thus enabling data acquisition at\nrelevant temporal and spatial scales with improved reproducibility. We also discuss shortcomings\nand show how deep learning architectures have evolved to mitigate imprecise readouts. Finally, we\nsuggest opportunities where deep learning is particularly likely to catalyze plankton research. The\nexamples are accompanied by detailed tutorials and code samples that allow readers to apply the\nmethods described in this review to their own data [1].\nI.\nINTRODUCTION\nThe monitoring of marine organisms’ composition and\nabundance plays a pivotal role in evaluating environmen-\ntal conditions and gaining insights into ecological pro-\ncesses and interactions [2]. One group of particular inter-\nest is marine plankton, a collection of organisms defined\nby their inability to swim against the oceanic currents\n[3]. Plankton encompasses diverse organisms, from uni-\ncellular bacteria and protozoans to eumetazoans such as\nsmall crustaceans and gelatinous life forms. Given their\ndiverse size (ranging from micrometre to metre scales),\nrapid turnover, and displacement with ocean currents,\nthese organisms are challenging to study at appropriate\ntemporal and spatial scales. While studies of microplank-\nton have historically been performed using microscopy\nand chemical methods, such as pigment analysis and iso-\ntope labelling [4, 5], advances in such methods, alongside\nnew developments in molecular biology such as genetic\nbarcoding, have increased the taxonomic resolution in\nplankton monitoring and revealed a previously hidden\ndiversity in many groups. However, most methods are\nstill too time-consuming and labour-intensive to resolve\nthe plankton community at relevant spatial and tempo-\nral scales. Recent advances in machine learning, such as\ndeep-learning-based methods, hold promise to improve\nthis situation. In particular, automatic classification of\norganisms from in situ imaging systems allows high res-\nolution in both time and space [6]. Moreover, develop-\nments in deep learning microscopy provide single cell res-\nolution in food web interactions, such as microzooplank-\nton grazing and behaviour, which have previously been\nhard to obtain [7]. In this current state review, we aim\n∗Equal authorship. Names are listed in alphabetical order by the\nlast names.\nto delve into the application of deep learning methods\nin plankton studies, with a particular focus on utilising\nimage data. Our objective is to shed light on the poten-\ntial of these methods as tools for researchers in the field\nof plankton ecology, especially for those who may not be\nfamiliar with deep learning techniques.\nPlankton play a pivotal role in the Earth’s ecosystem\nand especially in its carbon cycle.\nPhytoplankton, for\nexample, produce nearly half of the oxygen on Earth,\nperforming around 40% of the world’s annual carbon fix-\nation (30-50 petagrams) [8]. Together with zooplankton\nas primary consumers, these form the base of most ma-\nrine food webs.\nCertain species of plankton can also\npose hazards to human health, such as harmful algal\nbloom-forming taxa (e.g., toxin-producing diatoms and\ndinoflagellates [9]). In ecological terms, the composition\nand abundance of certain species is used to determine\necological status [2, 10], or to obtain insights into past\nconditions (e.g., using shifts in diatom composition from\nsediment cores to make inferences about the climate in\nthe past few millennia [11]).\nTo accomplish these goals, it is important to have re-\nliable methods to identify, track, and quantify plankton\nspecies or groups. Unfortunately, this is complicated by\nthe extraordinary diversity among plankton taxa.\nFor\nexample, just one class of phytoplankton — the diatoms\n— contains an estimated number of species in the tens\nof thousands [12], many of which are highly similar in\nappearance and require microscopic analysis by expert\ntaxonomists to differentiate. Molecular methods such as\nmetabarcoding and environmental DNA (eDNA) drasti-\ncally improves the taxonomic resolution and has revealed\na previously overlooked diversity in plankton communi-\nties [13, 14].\nDeep learning has become increasingly popular in\nplankton studies.\nThis particular subset of machine\nlearning harnesses neural networks to acquire knowledge\nand enhance performance in specific tasks through itera-\narXiv:2309.08500v1  [physics.bio-ph]  15 Sep 2023\n2\nBox 1. Glossary of deep learning terms as used in this review\nBack-propagation algorithm: A training algorithm for neural networks that adjusts weights based on error\ngradients.\nBounding box: A rectangular box defined by latitude and longitude coordinates that enclose the object(s) of interest\nin an image.\nClass: A category or label assigned to data points.\nCycleGAN: A type of generative adversarial network designed to create realistic-looking images without paired\ninput-output examples.\nData augmentation: A technique to enhance the size and variety of a training dataset by applying transformations\nto the existing data to improve model generalization.\nDeep learning: A subfield of machine learning that models data using multiple layers of interconnected nodes. It is\ninspired by the structure and function of the biological brain.\nFeed-forward network: A neural network with connections that do not form cycles.\nF1 score: A metric combining precision and recall, defined as 2 ∗Precision∗Recall\nPrecision+Recall.\nGNN (Graph Neural Network): Neural networks designed to operate on graphs, mathematical structures\ncomposed of nodes (vertices) and edges.\nHuman-in-the-loop: An iterative process where a human provides feedback on a system’s outputs, aiding in\nimproving its performance.\nLayers: Sets of interconnected nodes or units in a neural network. Data is processed through each layer, undergoing\ntransformations before moving to subsequent layers or producing an output.\nLong short-term memory (LSTM): A type of recurrent neural network (RNN) architecture that is designed to\nrecognize patterns over time intervals and has memory cells to store information for longer periods.\nMultilayer perceptron (MLP): A type of feed-forward neural network with multiple layers of nodes.\nOverfitting: A modeling error that occurs when a machine learning model performs well on the training data but\npoorly on new, unseen data.\nPrecision: The ratio of correctly predicted positive observations to the total predicted positives, defined as\nTP\nTP+FP.\nR-CNN (Regional Convolutional Neural Network): A model used for object detection that scans an image in\nregions and uses CNNs to classify each region.\nRecall: The ratio of correctly predicted positive observations to all the observations in actual class, defined as\nTP\nTP+FN.\nReinforcement learning: A learning paradigm where agents learn by interacting with an environment, receiving\nfeedback through rewards or penalties based on their actions.\nSpecificity: The ratio of correctly predicted negative observations to all the observations in actual negative class,\ndefined as\nTN\nTN+FP.\nTest data: A subset of data used to evaluate the performance of a trained model, ensuring it works effectively on new,\nunseen examples.\nTraining dataset: A set of data used to train and adjust the weights of a model.\nTransfer learning: A technique wherein a pre-trained model on a large dataset is adapted for a different but related\ntask, often involving fine-tuning on a smaller, task-specific dataset.\nValidation dataset: A subset of data used to tune hyperparameters and prevent overfitting during the training\nprocess.\nYOLO (You Only Look Once): A real-time object detection system that divides images into a grid and predicts\nbounding boxes and class probabilities simultaneously.\ntive learning from experience [15]. Deep learning meth-\nods have been applied to many fields, such as natural\nlanguage processing [16] and computer vision [17]. While\nan in-depth explanation of these networks is outside the\nscope of this paper, we will provide an overview of how\nthese networks function, and recommend other reviews\non the subject (such as those by LeCun et al. [15] and\nAlzubaidi et al. [18]) to those readers interested in the\nfiner details of deep learning.\nAs its name implies, a neural network’s design is in-\nspired by the brain, with an interconnected network of\nneurons. The network to be trained is fed a set of input\ndata (training data), most often labelled (e.g., a selection\nof plankton images identified by a taxonomist).\nFrom\nthese training data, the network learns to recognise cer-\ntain features, and to associate these features or combi-\nnations thereof with given classifications. The network’s\nability to recognise these features (and by extension, to\nclassify the images) is then tested on a subset of the input\ndataset that the model has never seen before (validation\ndata) to assess the model’s performance. Adjustments\nare made to the internal parameters of the network to\nminimise the error (i.e., the difference between the true\nresults and the network predictions), and the process is\nrepeated multiple times. Finally, the model is tested on\nanother unseen subset of the input dataset (test data) to\nprovide the final statistics for the model’s performance.\nFor tasks such as plankton classification and detection,\nthe performance of the models can be evaluated using\nmetrics such as: precision, i.e., the proportion of positive\nresults identified that are truly positive; recall or sensi-\ntivity, i.e., the proportion of truly positive results that\nthe model recognises as positive; F1 score, i.e., the har-\nmonic mean of precision and recall; and specificity, i.e.,\n3\nFigure 1.\nWorkflow of a deep learning analysis applied to plankton studies. a Different sampling strategies for in situ and ex\nsitu data. Plankton can be cultivated in the laboratory or collected from the field. Remote-sensing data can also be collected\nvia drones or satellites. b Images and data are obtained using microscopic analyses or satellite imaging. c Data is processed\nusing a deep learning network. d The output of a deep learning analysis can be used for a wide range of applications.\nthe proportion of truly negative results that the model\nrecognises as negative.\nWith this review, we aim to provide an overview of\nthe key techniques used in deep learning, through the\nlens of their application in studies of plankton detection\nand classification (section II), plankton foraging and mi-\ngration (section III), and plankton biomass estimation\n(section IV) (Fig. 1). We aim to demystify deep learn-\ning and inspire its use in future plankton projects. As\nmany field-specific terms are used throughout this re-\nview, we define important concepts in Box 1 (terms de-\nfined this way are italicised in the text at first use).\nWe also show example schematics for some of the deep\nlearning architectures (Figs. 2 and 3). In addition, we\nprovide Jupyter notebooks containing example code for\nthree of the deep-learning-based tasks covered in this ar-\nticle: plankton segmentation and classification, plankton\ndetection, and plankton trajectory linking. The neces-\nsary code and plankton video data can be found in our\nGitHub repository [1]. We encourage the readers to go\nthrough the tutorials and apply the techniques to their\nown plankton microscopy data.\nII.\nPLANKTON DETECTION AND\nCLASSIFICATION\nGiven the importance of plankton in the ecosystem,\nit is vital to be able to accurately detect and classify\nthem. Such tasks are non-trivial, as images of plankton\nmay contain non-plankton particles, as well as multiple\nspecies of plankton that may have variable and some-\ntimes largely overlapping morphologies.\nMuch of this\nwork is traditionally performed manually, which consti-\ntutes a major bottleneck in analysis pipelines. Therefore,\nemerging technologies such as metabarcoding [19] (the se-\nquencing of taxon-specific DNA to identify which species\nare present) and deep learning methods present attrac-\ntive alternatives, either individually or as complements\nto one another (as noted by Høye et al. for the field of\nentomology [20]). A major advantage of deep-learning-\nbased approaches in this context is the potential for a\nmore automated analysis after the initial setup. While\ninitial labelling of training images and training of the\nmodel may take some time, later analyses of plankton\nimages do not require the repeated laboratory steps of,\nfor example, a barcoding-based method.\nThe presence of numerous plankton species, numbering\nin the thousands, underscores a significant factor to con-\nsider when employing deep learning methods. One such\nconsideration is the necessity for a substantial training\ndataset that encompasses a wide range of categories, of-\nten referred to as classes in the context of machine learn-\ning. These would correspond to taxonomic classifications\n(e.g., species) in a plankton study. Several curated plank-\nton image datasets are available, which can be used for\nthis purpose.\nFor example, the Woods Hole Oceano-\ngraphic Institution Plankton dataset (WHOI-Plankton)\ncontains over 3.4 million annotated plankton images be-\nlonging to 103 classes [21].\nIn terms of more taxon-\nspecific datasets, the Endless Forams dataset contains\nover 34,000 images of foraminifera classified to species\nlevel [22].\nPlankton detection. In order to classify plankton,\nthey must first be detected in images or videos. These\ncan be obtained, for example, from a microscope in a lab\ncontext, or from imaging planktons moored in position\nor deployed on remotely operated vehicles such as the\nzooplankton-sensing autonomous glider Zooglider [23], or\nmore integrated analysis and acquisition systems such\nas ZooScan [24] and the Underwater Vision Profiler\n4\n6 (UVP6) [25].\nThough most of these systems work\nfavourably well, accurate plankton detection and clas-\nsification can still be complicated by the issues such as\nmotion blur in the acquired imagery data, or the presence\nof non-plankton objects such as aggregates and debris.\nTherefore, sophisticated methods are required to detect\ntrue instances of plankton while rejecting non-plankton\nobjects, which can be achieved through deep learning\n(Fig. 2).\n(A summary of the studies in the following\nparagraphs are available in Table 3).\nTwo common approaches for object detection using\ndeep learning are models of either the R-CNN (Re-\ngional Convolutional Neural Network) or YOLO (You\nOnly Look Once) family. The R-CNN family of models\n(e.g., R-CNN, Fast R-CNN, Faster R-CNN, etc.) per-\nform object detection and classification in a two-step\nprocess [27].\nIn the RCNN workflow, initially, regions\nof interest (ROIs) are generated, involving the cropping\nof individual plankton, followed by the merging of simi-\nlar regions; subsequently, these resultant region propos-\nals undergo classification. The initial implementations of\nR-CNNs required processing of around 2,000 region pro-\nposals per image. However, this was a substantial time\nbottleneck. The more recent implementations are faster\nbecause this process has been significantly sped up; this\nimproved performance means that Faster R-CNN can be\nused for real-time applications [28]. On the other hand,\nin YOLO models (e.g., YOLO, YOLOv2, YOLOv3, etc.),\nthe detection and classification are performed across the\nwhole image in a single step instead (hence the acronym),\nrather than first generating region proposals as in R-\nCNN, which further speeds up the process [29].\nPedraza et al. [30] applied both R-CNN and YOLO\nto microscopy images of ten diatom species in order to\ncompare the two methods. YOLO produced better re-\nsults in this instance, with an average pixelwise recall of\n0.84, versus an average of 0.68 for R-CNN. In an intuitive\nsense, recall indicates the ability of a model to find all rel-\nevant detections. The issues noted by Pedraza et al. [30]\nregarding R-CNN were, objects being missed (i.e., false\nnegatives), and bounding boxes being much larger than\nobjects (i.e., false positives). The latter also relates to\nthe problem of multiple objects that are close together\nor overlapping being counted as a single object, which is\nproblematic for obtaining accurate numbers.\nIssues similar to those noted by Pedraza et al. [30] were\nalso noted in a study by Kakehi et al. [31], where the au-\nthors used a different object detection model (ResNeXt-\n101(32 x 8d), part of Detectron2 [32]) to detect and iden-\ntify Pacific oyster larvae in images taken from plankton\nnet samples.\nThe training dataset for this study was\ngenerated using a human-in-the-loop method, where an\nexpert labelled a part of the dataset, which was then\nused by the object detection model to label further im-\nages (which were then expertly verified). The authors\nidentified problems in the model whereby it could not\neasily distinguish larvae with obscured outlines, or that\noverlapped with other objects. Two possible solutions to\nthe identification problem were proposed: either apply-\ning a deep learning method to improve the image quality,\nor training on a larger dataset that includes more images\nof larvae with obscured outlines or overlaps.\nThe issue of object overlap has been addressed by Ruiz-\nSantaquiteria et al. [33], who applied a Mask R-CNN ap-\nproach to images of ten species of diatoms. Mask R-CNN\nis a development of Faster R-CNN that adds instance\nsegmentation (i.e., it identifies individual instances of ob-\njects within regions of interest) [34]. The authors com-\npared the Mask R-CNN to a SegNet [35], which instead\nperforms semantic segmentation (pixels are assigned to a\ngiven class, but instances of the same class are not sepa-\nrated). While SegNet was better on average at detecting\ntrue positives (i.e., higher average recall of 0.95, versus\n0.86 for Mask R-CNN), Mask R-CNN performed much\nbetter in terms of fewer false positives (i.e., higher aver-\nage specificity of 0.91, versus 0.60 for SegNet), and was\nbetter able to separate individual diatoms.\nImage quality in general is a major consideration for\ncomputer vision problems.\nShi et al. [36] trained a\nYOLOv2 model on digital holographic images of zoo-\nplankton, of varying sharpness, and noted that a training\ndataset composed of images with at least an intermediate\nsharpness assessment index (i.e., at least 0.6 on a 0-to-1\nscale) produced a much better result — training images\nwith sharpness in the 0.5 to 0.6 interval gave a precision\nof 0.85 and a recall of 0.70, whereas the 0.6 to 0.7 interval\ngave a precision of 0.94 and a recall of 0.89.\nFor the purposes of real-world applications of plankton\ndetection, such as real-time monitoring using a remotely\noperated vehicle, speed of detection is an important con-\nsideration. Li et al. [37] applied variants of YOLOv3, as\nwell as Faster R-CNN, to the WHOI-Plankton dataset\nto perform identification and classification [21]. Detec-\ntion times for YOLOv3 models were two orders of mag-\nnitude faster (8 to 51 ms) than the Faster R-CNN (814 to\n893 ms), which makes the YOLOv3 models more suitable\nfor real-time applications in this context. The authors\nintegrated a DenseNet structure into the YOLOv3-dense\nmodel.\nDenseNet is a structure in which all layers of\nthe network are connected to one another, such that as\nmuch information as possible is passed through the net-\nwork [38]. Given the small visible differences that can\nexist between various plankton taxa, this is particularly\nimportant.\nAs the field of deep learning continues to evolve, other\nmore recent methods are being applied to the field of\nplankton detection, an example of which is shown in\nFig. 2a-f.\nIn this example, simulated training images\nbearing similar features to the plankton being studied\nare generated (Fig. 2a). These images are used to train\na U-Net model (Fig. 2b), which outputs segmentation\nmasks corresponding to the positions of the given species\n(Fig. 2c). This trained model is then applied to true ex-\nperimental images (Fig. 2d), and corresponding species-\nspecific segmentation masks (Fig. 2e) are used for cell\ncounting in the experimental image (Fig. 2f).\nSuch\n5\nFigure 2.\nDeep learning methods for cell counting, segmentation and classification. a-f Example of a supervised\nmethod to detect, classify, and count plankton species Noctiluca scintillans and Dunaliella tertiolecta: a Synthetic training\nimages are generated by simulating plankton-like objects that carry similar spatial features to the original organisms. b A\nU-Net model is trained to perform an image-to-image translation task to output c two segmentation masks that correspond\nto the species N. scinitillans (left) and D. tertiolecta (right). d The pre-trained U-Net model is tested on experimental images\nto generate e the specific segmentation masks of N. scintillans\n(left) and D. tertiolecta (right). f The segmentation masks\nare then analysed to predict the number of cells (cell counting) for each species in the experimental image. g-i Example of\na self-supervised method to detect and count plankton. g The experimental image of N. scintillans is analysed h through a\nself-supervised object detection model, LodeSTAR [26], to automatically detect the objects without any labelled training data.\ni By controlling the spatial resolution of the input image, object centroids are controlled in the cell detection step. Figures g-i\nare adapted from Ref.[26], with some of the authors of this work being part of the cited reference.\na workflow is employed in the digital microscopy deep\nlearning framework DeepTrack 2.0 [39, 40]. We demon-\nstrate this task using a U-Net architecture, providing\ntraining data and analysis code in the associated GitHub\nrepository [1].\nWith emerging methods, it is also becoming possible\nto detect objects using only a single, unlabelled image\nto train a deep learning model. Such is the case with\nLodeSTAR [26], a recently developed method shown to\naccurately detect multiple instances of the dinoflagellate\nNoctiluca scintillans, after training on a single image, as\ndemonstrated in Fig. 2g-i. This is achieved by exploiting\nan object’s symmetry to train a neural network. In this\nexample, a pair of N. scintillans cells (Fig. 2g) are de-\ntected by training the LodeSTAR model (Fig. 2h) on a\ntraining image of a single cell (Fig. 2i, inset). Depending\non the resolution of the training image, LodeSTAR could\ndetect either a specific feature of the cells (e.g., the ten-\ntacle attachment point in Fig. 2i, left panel) or the entire\ncells (Fig. 2i, right panel). We provide detailed tutorials\n6\n7\non how to use the LodeSTAR model for detecting plank-\nton from microscopy videos in our GitHub repository [1].\nPlankton classification. After detection follows the\nmore complex task of classifying the individual plankton\nto a taxonomic group. Several convolutional neural net-\nworks have been applied to plankton classification prob-\nlems over the last decade [41]. Summaries of the studies\nwe mention in this section are given in Table 1.\nEven when using relatively large training datasets, ad-\nditional data may still be needed to train an effective\nmodel.\nThis can be achieved through data augmenta-\ntion, i.e., the generation of additional training images\nderived from the original training data.\nIf a training\ndataset is too small, it can result in overfitting, whereby\nthe model interprets noise in the data as a true signal,\nresulting in a model that has learned to work well with\nthe training dataset, but that fails to generalise to new,\nunseen data. In such cases, data augmentation is used to\nproduce more, transformed images, thus bolstering the\ntraining dataset.\nThis augmentation can be achieved\nthrough, for example, various transformations of the ex-\nisting images, such as rotation, cropping, or re-scaling, or\nthrough the addition of noise [41–43]. In their paper on\nthe ZooplanktoNet model, Dai et al. [42] compared the\nclassification accuracy of several popular deep learning\nmodels on a zooplankton dataset, with and without data\naugmentation. The accuracy increased by an average of\n9.7% when data augmentation was applied (albeit qua-\ndrupling the training time). Likewise, Correa et al. [43]\nnoted a 17.5% increase in accuracy after application of\ndata augmentation to a 19-class microalgal dataset.\nRegardless of the size of the dataset, there are likely\nto be classes that are underrepresented, e.g., rare taxa\nthat are detected less often, but whose accurate identifi-\ncation may be vital. For example, this can be the case\nin the identification of invasive species during the early\nstages of invasion. However, rare taxa can have a sub-\nstantial impact on a model’s performance. For example,\nLuo et al. [44] performed a classification of 75,000 images\ncollected using the In Situ Ichthyoplankton Imaging Sys-\ntem (ISIIS) [45]. While the average precision achieved\nwas 0.84, exclusion of the twelve rarest taxa from consid-\neration boosted the average precision to 0.907.\nAs noted by Li et al. [37], data augmentation is often\napplied to the whole training dataset, meaning that if\nthere is a class imbalance, the data augmentation will\nnot address this. To augment the training data for rare\ntaxa specifically, the authors used a Cycle Generative\nAdversarial Network (CycleGAN) model [46]. A Cycle-\nGAN is made up of two pairs of components — two gen-\nerators that generate realistic-looking images, and two\ndiscriminators, whose purpose is to differentiate between\nreal and generated images. With each iteration, the gen-\nerators become better at creating realistic-looking im-\nages, while the discriminators become better at detecting\nthem. Ultimately, the goal is to generate realistic-looking\nimages that look convincingly similar to the originals.\nIn Li et al., two taxa were randomly selected as “rare\ntaxa”, and a lower number of true images of these taxa\nwere included in the training dataset (around one-fifth\nthe number of images included for non-rare taxa). The\nCycleGAN model was then used to generate images of\nthese two taxa so that the total number of training im-\nages was comparable to those of the non-rare taxa. The\nresult was that the average precision for the two rare\ntaxa augmented with the CycleGAN model increased by\n1.93% (from 0.91 to 0.93) and 6% (from 0.92 to 0.98), for\nthe randomly-selected classes “Pennate” and “Prorocen-\ntrum”, respectively, compared to when these taxa were\nnot augmented.\nThe issue of class imbalance in plankton datasets has\nalso been addressed using the technique of transfer learn-\ning. This involves training a model on one dataset (often\nan unrelated, general dataset, which allows the model\nto learn broader patterns in image data), and then fine-\ntuning parts of the model by retraining with data from\nthe problem of interest. This can also help address the\nissue of long training times for new models. In a study\non the WHOI-Plankton dataset, Lee et al. [47] initially\ntrained a model on class-normalised data (i.e., any class\nwith more than 5,000 images was randomly subsampled\ndown to 5,000), then fine-tuned on the entire dataset\nto ensure that population data (the frequency of each\nclass) were not lost.\nThis method improved the accu-\nracy of the smaller classes while retaining the accuracy\nof the five most abundant (which composed over 90% of\nthe training and test data in the full dataset). Trans-\nfer learning has also been applied to plankton studies\nwhere class imbalance was not the main focus. The Ima-\ngeNet dataset [48] (containing over 14 million images as\nof March 2023) has been used in multiple transfer learn-\ning studies (e.g., Refs. [21], [49], [50]), resulting in greater\naccuracy than training on the plankton dataset alone. In\nthe case of Orenstein and Beijbom’s study on multiple\nplankton datasets [49], the accuracy increase was around\n10%.\nIn addition to performance improvement via the afore-\nmentioned strategies, improved performance has also\nbeen achieved in plankton classification through the in-\nclusion of context metadata (i.e., additional data about\nthe sample beyond just the image itself). Ellen et al. [51]\nincorporated into their model combinations of three dif-\nferent categories of metadata: Geometric (i.e., containing\nmeasurements from the original image before adjustment\nto be fed into the network), geotemporal (e.g., longitude,\nlatitude, and season), and hydrographic (e.g., chlorophyll\na (Chl a) fluorescence and salinity). With a baseline ac-\ncuracy of up to around 0.89 (depending on the dataset),\naddition of all three categories of metadata gave an ac-\ncuracy gain of around 1.5%, up to 0.91. With further\nimprovements to the network, a final classification accu-\nracy of 0.93 was achieved. Of the three categories listed\nabove, it was noted that geotemporal and hydrographic\nmetadata were the most informative, with addition of ge-\nometric metadata alone having minimal impact on pre-\ndiction accuracy.\n8\nDetection and classification of plankton are challenging\ntasks, but with the continued developments in the field\nof deep learning, as illustrated by the above examples,\nwe believe that such methods will continue to speed up\nand automate these processes.\nIII.\nPLANKTON FORAGING AND\nMIGRATION\nMotility is a fundamental characteristic of living organ-\nisms, enabling their interaction with the surrounding en-\nvironment [5]. The internal cellular processes that govern\nan organism’s motion have evolved to perform specific\nmajor tasks such as reproduction, foraging, migration,\ndefence, and communication.\nFor instance, terrestrial\norganisms such as zebras follow waves of freshly grown\nvegetation after winter months for active grazing. Simi-\nlarly, planktonic organisms often perform diurnal vertical\nmigration where organisms move to deeper levels of the\nocean during the day to avoid predators, and come back\nto the uppermost layers during the night in search of food\nand mating opportunities. More prominently, zooplank-\nton shelter in deeper, darker strata during the daytime\nto avoid visual predators, while flagellated phytoplankton\nsometimes do the opposite, collecting nutrients at depth\nduring the night and surfacing to harvest light during the\nday [52]. The behaviours associated with foraging and\nmigration are easy to observe in larger animals, such as\nterrestrial ungulates and larger aquatic organisms, which\ncan be followed by acoustic methods [53]. In contrast, the\nbehaviours of microscopic plankton are mainly inferred\nthrough video-microscopy-based methods. However, ex-\nperiments with these smaller organisms are performed\nunder simulated conditions due to limitations in micro-\nscopic system design [54], although the high-quality video\nimaging data still allows for successful extraction of indi-\nvidual cell information. In the previous section, we dis-\ncussed deep-learning-based image analysis methods for\ndetection and identification of plankton cells from mi-\ncroscopy videos. This section will explore how the posi-\ntions of the detected plankton in multiple frames can be\nlinked to determine swimming trajectories, and how we\ncan extract the statistical properties of such trajectories.\nFurthermore, we will discuss how reinforcement learning\ncan be used to model plankton swimming behaviours in\nvarious simulated systems.\nDeep-learning-based trajectory analysis.\nThe\nstudy of microplankton motility is essential to under-\nstand how swimming patterns mediate foraging be-\nhaviours, and which optimisation strategies can be used\nto improve prey encounter rates while avoiding preda-\ntors [55].\nIn this view, different mathematical models\nhave been developed to categorise the motions of various\norganisms. A microscopic particle whose motion is solely\ngoverned by the thermal collisions with neighbouring liq-\nuid molecules performs Brownian motion, the simplest\nform of random motion. Non-motile viruses and bacte-\nria (when suspended in liquid) belong to this category.\nMathematically, the motion of a microscopic organism is\ncharacterised by the space explored by the organism over\ntime. This can be be inferred by measuring the relation-\nship between the mean square displacement (MSD) of the\nparticle with time (t), which grows linearly (MSD ∝t) for\nparticles and organisms following Brownian motion [56].\nThe proportionality factor which links the MSD and t is\nknow as the diffusion coefficient (D) of the particle tra-\njectory (MSD = 2Dt). However, a majority of organisms\nare known to have an active motion mechanism, which re-\nsults in a non-linear relationship between MSD and time\n(MSD ∝tα). This phenomenon is generally referred to\nas “anomalous diffusion”. Due to a widespread occur-\nrence of anomalous diffusion in the behaviour of various\norganisms, a theoretical framework has been developed\nto further characterise their motions based on the spatial\nand temporal correlations of trajectories. This has led to\nthe development of several mathematical models, such\nas L´evy walks, fractional Brownian motion, continuous\ntime random walk and scaled-Brownian motion. Various\nmethods to determine (anomalous) diffusion properties\nhave been recently evaluated within the “Anomalous Dif-\nfusion Challenge”, concluding that deep-learning-based\nmethods outperform more classical approaches [56].\nHeterotrophic dinoflagellates, such as Oxyrrhis ma-\nrina, perform helical L´evy walks to optimise random\nsearching in environments with low prey densities [57].\nAt a larger scale, millimeter-sized organisms, such as\ncopepods, diffuse by multi-fractal random walks to op-\ntimise foraging [58].\nThe majority of studies employ conventional object-\nassociation approaches, such as the Hungarian algorithm\nand Kalman filtering, to identify moving particles across\nconsecutive frames of a video. These methods establish\nlinks between particles based on their proximity to pre-\nvious positions, and more advanced algorithms also take\ninto account the direction and speed from the previous\ntimestep to improve linking, e.g., when particles over-\nlap [59–61]. Although these techniques work well in many\nexperimental cases, they still require manual input of pa-\nrameters, can be error-prone (for instance when the cells\nare dense and motion is unpredictable), and are limited in\ntheir ability to accurately analyse large amounts of data.\nMore importantly, these traditional methods often strug-\ngle to measure accurate cell trajectories during scenarios\nsuch as cell division (parent cell dividing into daughter\ncells) and feeding events (predator cells consuming prey\ncells), as the number of cells in close proximity changes\nduring these events.\nIn recent years, deep-learning-based methods hold\npromise for analysing and modelling plankton trajec-\ntories.\nAlthough deep-learning-based trajectory analy-\nsis methods have not been extensively used in plankton\nstudies yet, they have the potential to provide a new\nperspective on the behaviour of these organisms.\nWe\nhighlight some of the possibilities below, and show an\nexample application (Fig. 3a-c) in our GitHub reposi-\n9\nFigure 4.\nQuantitative analysis of plankton behaviours. a-c Plankton trajectory analysis. a Snapshots of plankton\nspecies Oxyrrhis marina taken with a bright-field microscope at 10× magnification are analysed to extract the plankton\ntrajectories.\nb Techniques for trajectory linking.\nStandard approaches (top) include the Hungarian algorithm and linear\nsum assignment.\nDeep learning approaches (bottom) include recurrent neural networks (RNNs), long short-term memory\nnetworks (LSTMs) (left), and graph neural networks (GNNs) (right). c Reconstructed plankton trajectories. d-f Plankton\nbiomass estimation. The biomass of plankton cells can be estimated by imaging them under quantitative phase microscopy\nmethods such as holography [7] d Plankton species O. marina (orange) and D. tertiolecta (blue) are tracked under a holographic\nmicroscope. e Image crops of size 64 px × 64 px along the trajectories of respective species are analysed through a deep learning\nmodel called WAC-Net [7]. f Dry mass values (in picograms) of an exemplar of O. marina (orange) and one of D. tertiolecta\n(blue) over time. Figures d-f are adapted from Ref. [7], with some of the authors of this work being part of the cited reference.\ntory [1].\nA class of deep sequence modelling methods\nsuch as recurrent neural networks (RNNs), long short-\nterm memory (LSTMs), and transformers, are useful in\nanalysing sequential data [62–65]. Transformers, which\nare built on the attention mechanism in deep learning\n(explained in more detail in the next paragraph), can\neffectively learn and infer associations between different\ntime points in a trajectory by focusing on the most rel-\nevant information at each step of the computation [66].\nThis technique has been applied to various domains, such\nas computer vision, natural language processing, speech\nrecognition, and self-supervised image classification, with\ngroundbreaking results [67–69]. In deep sequence-based\nmodels as mentioned here, trajectories are considered as\na sequence of time points, and the associations between\nthe time points are learned during training.\nMore re-\ncently, advanced geometric deep learning models such as\ngraph neural networks (GNNs) are proving to be useful in\nextracting valuable information from the trajectories, in-\ncluding hidden patterns and behaviours [70, 71]. GNNs\nare a type of deep learning model designed to operate\non graphs, which can capture both spatial and temporal\ndependencies between graph nodes. In the case of tra-\njectories, each linked trajectory can be represented as a\ngraph, where each point along the trajectory represents a\nnode, and a connection between relevant nodes is called\n10\nan edge. As a starting point, the GNN is provided with\na complete graph, where all the positions of the objects\n(plankton) in all the frames of the video are considered\nas nodes, and all the possible edges within a likelihood\nradius connect these nodes. The likelihood radius is re-\nlated to the range each particle can cover within two\nframes of a video.\nThe GNN then learns to correctly\nclassify edges that complete a single plankton trajectory,\neffectively treating the problem as an edge classification\ntask. The advantage of GNNs is that, as a deep learning\nmethod, the network can be trained with species-specific\ntrajectories to capture complex patterns of movement\nthat are difficult to capture using traditional methods.\nLately, attention-based fingerprinting GNNs, which\ncombine the strengths of transformers (as mentioned\nabove) and GNNs, have shown great promise in a wide\nrange of applications [65]. These models can be used not\nonly for trajectory linking, but also for quantifying the\nmotion parameters of individual trajectories without the\nneed for explicit trajectory linking. This attention-based\ntechnique can encode and predict biological events such\nas cell division, cell merging, and feeding events. In most\napplications, the ultimate aim of trajectory linking is to\nunderstand the underlying behaviours of trajectories. By\ntreating the task as a node regression problem, this tech-\nnique can predict the diffusion coefficient of a trajectory\nwithout the need for linking. Moreover, by treating the\ntask as a graph-level classification problem, attention-\nbased GNNs can predict the underlying diffusion model\nitself (such as fractional Brownian motion or continuous-\ntime random walk). This method could prove useful in\nmany plankton applications, including understanding op-\ntimal swimming characteristics in predator-prey regimes\nand identification of changes in the diffusion model over\ntime.\nDeep-learning-based search optimisation. Apart\nfrom trajectory analysis, deep learning has also been\nused for search optimisation in plankton ecology.\nRe-\ninforcement learning is a type of machine learning where\nan agent (e.g., a fictive plankton) learns how to in-\nteract with an environment to achieve a specific goal\nthrough trial and error, receiving rewards or punishments\nalong the way.\nStudies in this direction have adapted\ndeep reinforcement-learning-based algorithms to investi-\ngate how plankton search for food and optimise their\nsearch strategies, or navigate their swimming under dif-\nferent environmental conditions such as turbulent flows\n[72–77].\nFor instance, many plankton species migrate vertically\nin the turbulent ocean, using a mechanism called gyro-\ntaxis to swim efficiently with or against gravity. While\nsome plankton rely on passive mechanisms for gyrotac-\ntic stability, they are often sensitive to turbulence, which\ncan upset their alignment. To address this, Qiu et al.\n[72] have suggested an active mechanism for gyrotac-\ntic stability, that they attempt to simulate using rein-\nforcement learning.\nThe proposed mechanism involves\na model plankton that swims at a constant speed and\nactively steers in response to hydrodynamic signals en-\ncountered in simulations of a turbulent flow. By sensing\nits settling velocity and steering in response to hydrody-\nnamic signals, the swimmer can maintain accurate align-\nment upwards, allowing for efficient upward migration in\nturbulent flows. This finding has provided some initial\ninsights on the role of active mechanisms used by plank-\nton to maintain stability in a turbulent ocean.\nAlthough these studies provide valuable insights into\nthe foraging behaviour of planktonic organisms, it is im-\nportant to note that they are based on simplified, ide-\nalised environments that do not fully represent the com-\nplex oceanic conditions. Thus, future studies should fo-\ncus on incorporating more realistic natural factors (e.g.,\nflow regimes, predator-prey interactions) into the models\nto obtain a more accurate representation of the ecological\ndynamics of planktonic organisms.\nIV.\nQUANTITATIVE ANALYSIS OF\nPLANKTON BIOMASS\nPhytoplankton blooms result from the rapid accumula-\ntion of plankton biomass in a restricted water body. They\ncan positively impact the ecosystem, as planktivorous or-\nganisms benefit from a high density of prey. However,\nlarge plankton blooms can be rather harmful to their en-\nvironment, as they limit the amount of light reaching the\nseafloor and often cause oxygen depletion where they die\nand decompose. Furthermore, harmful algal blooms can\nproduce toxins, impacting human health and aquacul-\nture [9, 78, 79]. As predicted global changes will affect\nthe intensity and frequency of plankton blooms, being\nable to automatically analyse their biomass is a valuable\ntool for assessing, monitoring and evaluating the effect of\nphytoplankton biomass on the ecosystem.\nThe biomass of plankton has previously been estimated\nusing mathematical models.\nNutrient-Phytoplankton-\nZooplankton (N-P-Z) models have commonly been used\nto model plankton dynamics [80]. These models use the\ninteractions among predator, prey, and nutrient availabil-\nity to simulate the dynamics in the ecosystem. Such a\nmodel was used by Frost\n[81], who combined chemical\n(e.g., concentration of Chl a), biological (e.g., photosyn-\nthetic rate) and physical (e.g., layer depth, incident solar\nradiation) parameters to simulate the increase in phyto-\nplankton biomass in the Pacific Ocean. N-P-Z models re-\nmain valuable tools for plankton biomass simulations [80]\nbut are limited by the relevance of the parameters chosen\nfor the modelling.\nDeep-learning-based approaches have been developed\nover the past decades to estimate plankton biomass in\nthe context of climate and ecosystem modelling, and to\nmonitor harmful algal blooms. Some of these approaches,\nall using neural network algorithms, will be highlighted\nin the present section, with the goal of giving an overview\nof possible applications of deep learning for quantifying\nplankton biomass.\n11\nDeep learning can be used in plankton biomass analysis\nto find correlations between biological events and envi-\nronmental parameters. Aoki et al. [82] analysed the long-\nterm changes in zooplankton biomass off the northeast-\nern coast of Japan, incorporating 39 years of zooplank-\nton data collected by vertical hauls and environmen-\ntal data gathered by the Japan Meteorological Agency.\nThey trained several dense neural networks (i.e., multi-\nlayer perceptrons) with different numbers of layers with\nvariable number of nodes per layer, and compared their\nperformance. A traditional back-propagation algorithm\nas discussed before is used to train the networks. The\nmost efficient model to generalise the data was a sim-\nple one-hidden-layer model with few hidden units. The\nlong-term variation in zooplankton biomass could be pre-\ndicted by generating mapping functions between environ-\nmental variables and zooplankton biomass. Nevertheless,\nthe range of their training dataset did not fit their data\nproperly; hence, they highlighted the importance of the\nrange of the training dataset when performing such anal-\nyses.\nA similar approach was undertaken by Woodd-\nWalker et al. [83], who collected plankton samples and\nrecorded environmental and seasonal parameters (lati-\ntude, temperature, salinity, density, total incoming radi-\nation, Chl a, and diel time) along a transect in the At-\nlantic. They used environmental parameters to estimate\nsurface plankton biomass using linear regression and a\ntwo-layer feed-forward network. As in Aoki et al. [82],\nthe network was able to predict the changes in biomass,\nbut the range of the training dataset limited the accu-\nracy of biomass estimates. The optimal neural network\nshowed an average prediction over the test dataset with\na determination coefficient r2 of 0.47, lower than the r2\nobtained with the training dataset (0.77).\nOther learning algorithms have also been used in the\ncontext of ecosystem modelling. To analyse the impacts\nof similar environmental conditions on the biomass of\nvarious phytoplankton groups, Pan et al. [84] used a\nmulti-layer feedforward network to explore the effects of\nglacial meltwater on phytoplankton communities. They\nfound that different environmental variables were respon-\nsible for the changes in the abundance of different tax-\nonomic groups. Chlorophyll a concentrations of flagel-\nlates, prasinophytes and diatoms were best predicted by\nH2O deep-learning models, with respective r2 values of\n0.91, 0.9 and 0.89. H2O models are multi-layer feedfor-\nward artificial neural networks trained with stochastic\ngradient descent (SGD) using back-propagation. Cryp-\ntophyte Chl a concentration was best predicted by a\ngradient boosting model (r2 0.97).\nThese models per-\nmitted the identification of the most important variables\nfor phytoplankton abundance, such as temperature for\ncryptophytes and flagellates, and nitrate availability for\ndiatoms and prasinophytes.\nIn the study by Pan et al. [84], in situ data collection\nwas feasible. However, this may not always be the case,\nso that remote imaging techniques are often favoured to\nstudy plankton biomass. For example, Chase et al. [85]\nassessed the reliability of satellite imaging to accurately\nquantify diatom biomass in the western North Atlantic\nusing a two-layer feedforward network to find a relation-\nship between Chl a, environmental information (salin-\nity and temperature) and concentration of diatom-bound\ncarbon. Their methodology seems promising for climate\nmodelling, but it remains preliminary, as the average un-\ncertainty of the diatom carbon estimated using the neural\nnetwork was relatively high (65%).\nBesides satellite imaging, aerial imaging from drones\ncan provide valuable data to monitor planktonic activ-\nity. This tool can be used as the foundation of ecosystem\nmodelling studies based on deep learning techniques. Pyo\net al. [86] developed a one-dimensional convolutional neu-\nral network, capable of quantitatively and qualitatively\nassessing algal blooms when applied to hyperspectral im-\nages captured by drones.\nThe network predicted the\ntrends of Chl a, phycocyanin, lutein, fucoxanthin, and\nzeaxanthin with respective r2 values of 0.87, 0.71, 0.76,\n0.78, and 0.74, in comparison to observed data.\nThe\nmethod remains to be perfected, as image borders have\ndistorted information which might bias the interpretation\nof the signal. Still, ex situ data collected using drone or\nsatellite imaging is a promising tool for studying the com-\nposition of algal blooms. Such data can even inform on\nthe vertical distribution of phytoplankton. For example,\nSammartino et al. [87] used an error back-propagation\nneural network (BPN) trained using Chl a profiles, geo-\ngraphical data, depth and temperature obtained from in\nsitu data and satellite observations to study the vertical\nprofile of Chl a. The prediction performance of the BPN\nwas assessed using observed data. For both in situ and\nsatellite datasets, the BPN had a fairly good predicting\nperformance with respective r2 values of 0.69 and 0.63. In\nconjunction with spatial scales, deep learning approaches\ncan also estimate plankton biomass at temporal scales.\nMartinez et al. [88] found that a multi-layer perceptron\n(MLP, a neural network with dense layers) performed\nbetter than a support vector regression (SVR) approach\nto reconstruct the long-term phytoplankton variability by\nestimating surface Chl a (r2 > 0.6 vs. r2 < 0.5). Even\nthough this deep learning algorithm underestimated the\namount of Chl a, this model is still considered a promis-\ning tool for monitoring phytoplankton activity.\nAs phytoplankton blooms often occur at a large scale,\nphotographing these events has been a favoured method\nto grasp their extent. With the improvement of the relia-\nbility and availability of imaging technologies, the image\ncapture of phytoplankton blooms has become easier, and\nneural networks have become the preferred tool to anal-\nyse such datasets. More complex networks were recently\nused to quantify the plankton biomass to predict harmful\nalgal blooms. For example, Liu et al. [89] used a com-\nbination of a long short-term memory network (LSTM)\nand time-frequency wavelength analysis (WA), a model\nnamed WLSTM, to estimate algal blooms. This model\nperformed better than other neural networks and LSTM\nalone for predicting biomass variations at different time\n12\nscales. This was particularly noticeable for longer time\nscales. At the daily and monthly scale, the hybrid net-\nwork predicted the data with respective r2 values of 0.878\nand 0.814, while the performance of the other methods\nwas lower, with r2 < 0.63. The hybrid WLSTM model\nwas even able to predict extreme algal bloom events.\nAnother LSTM was used to identify the most reli-\nable Chl a proxy for predicting changes in algal biomass.\nWenxiang et al. [90] found that the change rate and the\nrelative change rate of Chl a were more accurate outputs\nfor predicting the changes in biomass than the absolute\nconcentration of Chl a, especially in winter and spring.\nIndeed, the correlation coefficient indicating the relation-\nship between the forecasted and the observed concentra-\ntion of Chl a exceeds 0.84 for all-year-round predictions\nwhen using the change rate and the relative change rate\nof Chl a, while it dropped below 0.6 when using the ab-\nsolute concentration of Chl in winter and spring. This\ninformation can help direct future studies aimed at pre-\ndicting algal blooms.\nAt a much smaller scale, deep learning algorithms can\nalso be used to estimate the dry mass of individual plank-\nton cells. Bachimanchi et al. [7] used a combination of a\nregression U-Net (RU-Net) and a weighted-average con-\nvolutional neural network (WAC-Net) to analyse holo-\ngrams of plankton.\nThe RU-Net is a modified convo-\nlutional neural network, that segments the image into\nseveral heatmaps.\nThis output can be processed by\nthe WAC-Net to predict the dry mass and radius. The\ndry mass estimations obtained by WAC-Net and by the\n“volume-to-carbon” method for several species zooplank-\nton and phytoplankton have a correlation coefficient of\n0.988. Thanks to this network combination, it becomes\nfeasible to follow the growth of a single cell, something\nthat is impossible with classical methods (Fig. 3d-f).\nThrough these examples, we can see that deep learning\nhas revolutionised the field of plankton biomass estima-\ntion. Even though these networks have different levels of\ncomplexity, they have eased the study of plankton at var-\nious temporal and spatial scales, thanks to non-invasive\nimaging techniques, providing endless opportunities to\nmodel climate and ecosystems, and monitor harmful al-\ngal blooms.\nV.\nOPPORTUNITIES\nIn the following section, we explore the most recent ad-\nvancements in deep learning in light of their their poten-\ntial applications in the field of plankton ecology. These\ndevelopments offer new opportunities to overcome chal-\nlenges and pave the way for innovative solutions.\nOne of the biggest hurdles in many deep-learning ap-\nplications is the acquisition of labelled data. However,\nrecent advances in unsupervised and self-supervised deep\nlearning algorithms have shown promise in addressing\nthis problem. For instance, CycleGANs, which are part\nof the generative adversarial network family, can, in ad-\ndition to their use in generating new data, be utilised for\nsegmentation tasks in plankton images even when there\nis a limited amount of manually annotated data. Since\nsynthetically-generated masks with similar morphologies\ncan be used as ground truth data for real plankton im-\nages, CycleGANs can be trained on unpaired images and\nground truth data to produce accurate segmentations.\nMoreover, microscopy imaging data of plankton can\nbe synthetically generated through either GANs or by\nsimulating plankton-like objects.\nThis method allows\nfor ground-truth data to be known beforehand and con-\ntrolled, which can help overcome the challenges associ-\nated with manual annotation of data. As an example,\nthe segmentations of plankton species shown in Fig. 2\nwere obtained by a U-Net model trained on simulated\nplankton data. This approach also offers cell classifica-\ntion based on morphological properties, in addition to\nsegmentation.\nSelf-supervised deep learning algorithms, such as vision\ntransformers (ViTs), have also demonstrated promising\nresults in object segmentation and detection tasks. Un-\nlike supervised algorithms, which rely on labelled exam-\nples, self-supervised algorithms use transformed versions\nof input images themselves as labels. DINO (distillation\nwith no labels), a self-supervised vision transformer be-\nlonging to the ViT family, was able to accurately segment\nobjects from images without any labelled data. Given the\ndiverse morphologies of plankton, self-supervised vision\ntransformers can be used for segmentation and classifi-\ncation of complex taxa.\nIn conclusion, the field of AI-driven microscopy is ad-\nvancing quickly, offering new opportunities for identify-\ning, segmenting, and tracking individual plankton organ-\nisms. These developments are expected to revolutionise\nour understanding of the lower aquatic food web, provid-\ning insights that were previously unattainable. With the\nhelp of modern microscopy methods and deep learning\nalgorithms, it will soon be possible to observe large num-\nbers of organisms at high spatial and temporal resolu-\ntions, enabling us to better understand their interactions\nand ecology. These breakthroughs are poised to catalyse\nfurther progress in plankton ecology in the years to come.\nVI.\nGUIDELINES FOR USING DEEP\nLEARNING IN PLANKTON ECOLOGY\nTo ensure the effective use of deep learning in plank-\nton ecology research, we propose the following specific\nguidelines, on top om more general guidelines that can\nbe found for example in Ref. [91]:\n1. Model selection and development: During ex-\nperimental design, it is important to choose an ap-\npropriate model for the task being performed. For\nexample:\n• Regression models: where a value or quan-\ntity needs to be predicted from the given data\n13\n(e.g., dry mass prediction in section III).\n• Classification models: where the given data\n(e.g., images of planktons) need to be classi-\nfied into a particular class (such as species).\n• Generative models: when the data is insuffi-\ncient, and additional data is needed to train\nmodels.\n• Image-to-image\ntransformation\nmodels:\nwhere an image from one modality is con-\nverted to a different modality for easier\nanalysis (e.g., a microscopy image to a binary\nmap (segmentation map) for classification\nand detection purposes (see Fig. 2)).\nIn the GitHub repository accompanying this ar-\nticle, we provide an example model using Deep-\nTrack 2.0. Other open-source models are also read-\nily available, and we believe the studies mentioned\nin this article will help direct readers towards mod-\nels suitable for addressing their own research ques-\ntions.\n2. Data Preparation and Annotation: Once the\ntask and appropriate model have been defined, one\nneeds to prepare the input data in the right way.\nFor instance, for classification tasks, high quality\nplankton image data, classified by an expert tax-\nonomist, is required.\nFor regression tasks, such\nas predicting the physical parameters of a plank-\nton (size, aspect ratios, dry mass, etc.), ground\ntruth data can be obtained by standard methods\nas a representative set. Additionally, for segmen-\ntation tasks, simulating plankton images (as shown\nin Fig. 2) has its own advantages, as ground truth\nmasks are already known.\n3. Training and Validation: Once the data and the\nmodel are prepared, the next step is to train the\nmodel to maximise its accuracy and minimise its\nerror rate. The data obtained in the previous step\nmust be divided into training, validation, and test\ndata, each representative of the dataset as a whole.\nThe training is the step where the algorithm learns\nfrom the data. During training, the performance\nof the model should be evaluated regularly using\nmetrics like those described earlier in this review.\nIf required, data augmentation can be applied to\nimprove the model’s capacity to generalise across\nvariations in the plankton’s appearance. The vali-\ndation dataset is used to evaluate the performance\nof the model. The model does not learn from the\nvalidation dataset, but the results are used to tune\nthe model parameters. Lastly, the test dataset is\nused to get the final evaluation of the model’s per-\nformance.\n4. Interpretation and Validation of Results:\nOnce the trained model has been applied to the\ndata, it is important to interpret the data in the\ncontext of plankton ecology.\nUnderstanding how\nthe model makes its decisions, and assessing any\nuncertainties, is vital. At least part of the model’s\npredictions should also be compared to results ob-\ntained from traditional methods, to ensure the ac-\ncuracy and reliability of the model. For example,\nmanual identification of species by taxonomists in\nthe classifications tasks, and estimation of biomass\nby elemental analysis methods for the biomass es-\ntimation tasks.\n5. Reproducibility and Open Science: Given the\nongoing reproducibility crisis across scientific fields\n[92], we strongly recommend the sharing of analysis\ncode, models, and datasets used in studies, along\nwith detailed documentation on their use.\nPlat-\nforms such as GitHub can be used for this purpose,\nand sharing data in this way facilitates collabora-\ntion and scientific progress.\nBy adhering to these guidelines, researchers can en-\nsure the effective and responsible use of deep learning in\nplankton ecology, leading to robust and insightful out-\ncomes in the field. The guidelines highlight the impor-\ntance of proper data preparation, model selection, train-\ning and validation, result interpretation, and promoting\nreproducibility and open science.\n[1] H.\nBachimanchi,\nE.\nSelander,\nand\nG.\nVolpe,\nDeep-learning-in-plankton-\necology,\nhttps://github.com/softmatterlab/\nDeep-learning-in-plankton-ecology/ (2023).\n[2] M.-F. Racault, T. Platt, S. Sathyendranath, E. A˘girba¸s,\nV. Martinez Vicente, and R. Brewin, Plankton indica-\ntors and ocean observing systems: support to the ma-\nrine ecosystem state assessment, Journal of Plankton Re-\nsearch 36, 621 (2014).\n[3] V. Hensen, Kapitel 1: ¨Uber die Bestimmung des Plank-\nton’s oder des im Meere treibenden Materials an Pflanzen\nund Thieren, Jahresbericht der Commission zur Wis-\nsenschaftlichen Untersuchung der Deutschen Meere in\nKiel : f¨ur die Jahre ... 12-16, 1 (1887).\n[4] C. Butterwick, S. I. Heaney, and J. F. Talling, A com-\nparison of eight methods for estimating the biomass and\ngrowth of planktonic algae, British Phycological Journal\n17, 69 (1982).\n[5] T. Kiørboe, A mechanistic approach to plankton ecology,\nASLO Web Lectures 1, 1 (2009).\n[6] E. C. Orenstein, D. Ratelle, C. Brise˜no-Avena, M. L.\nCarter, P. J. Franks, J. S. Jaffe, and P. L. Roberts, The\nscripps plankton camera system: A framework and plat-\nform for in situ microscopy, Limnology and Oceanogra-\n14\nphy: Methods 18, 681 (2020).\n[7] H. Bachimanchi, B. Midtvedt, D. Midtvedt, E. Selander,\nand G. Volpe, Microplankton life histories revealed by\nholographic microscopy and deep learning, eLife 11,\ne79760 (2022).\n[8] P. G. Falkowski, The role of phytoplankton photosynthe-\nsis in global biogeochemical cycles, Photosynthesis Re-\nsearch 39, 235 (1994).\n[9] S. S. Bates, K. A. Hubbard, N. Lundholm, M. Montre-\nsor, and C. P. Leaw, Pseudo-nitzschia, Nitzschia, and do-\nmoic acid: New research since 2011, Harmful Algae 79,\n3 (2018).\n[10] HELCOM,\nGuidelines\nfor\nmonitoring\nof\nphy-\ntoplankton\nspecies\ncomposition,\nabundance\nand\nbiomass\n(2021),\nhttps://helcom.fi/wp-\ncontent/uploads/2020/01/HELCOM-Guidelines-for-\nmonitoring-of-phytoplankton-species-composition-\nabundance-and-biomass.pdf (2021).\n[11] A. W. Mackay, V. J. Jones, and R. W. Battarbee, Global\nchange in the holocene (2003).\n[12] S.\nMalviya,\nE.\nScalco,\nS.\nAudic,\nF.\nVincent,\nA. Veluchamy, J. Poulain, P. Wincker, D. Iudicone,\nC. de Vargas, L. Bittner, et al., Insights into global di-\natom distribution and diversity in the world’s ocean, Pro-\nceedings of the National Academy of Sciences 113, E1516\n(2016).\n[13] A. Bucklin, P. K. Lindeque, N. Rodriguez-Ezpeleta,\nA. Albaina, and M. Lehtiniemi, Metabarcoding of marine\nzooplankton: prospects, progress and pitfalls, Journal of\nPlankton Research 38, 393 (2016).\n[14] K. M. Ruppert, R. J. Kline, and M. S. Rahman, Past,\npresent, and future perspectives of environmental DNA\n(eDNA) metabarcoding: A systematic review in meth-\nods, monitoring, and applications of global eDNA, Global\nEcology and Conservation 17, e00547 (2019).\n[15] Y. LeCun, Y. Bengio, and G. Hinton, Deep learning, Na-\nture 521, 436 (2015).\n[16] T. Young, D. Hazarika, S. Poria, and E. Cambria, Re-\ncent Trends in Deep Learning Based Natural Language\nProcessing [Review Article], IEEE Computational Intel-\nligence Magazine 13, 55 (2018).\n[17] J. Chai, H. Zeng, A. Li, and E. W. T. Ngai, Deep learning\nin computer vision: A critical review of emerging tech-\nniques and application scenarios, Machine Learning with\nApplications 6, 100134 (2021).\n[18] L. Alzubaidi, J. Zhang, A. J. Humaidi, A. Al-Dujaili,\nY. Duan, O. Al-Shamma, J. Santamar´ıa, M. A. Fadhel,\nM. Al-Amidie, and L. Farhan, Review of deep learning:\nconcepts, CNN architectures, challenges, applications,\nfuture directions, Journal of Big Data 8, 53 (2021).\n[19] D. Abad, A. Albaina, M. Aguirre, A. Laza-Mart´ınez,\nI. Uriarte, A. Iriarte, F. Villate, and A. Estonba, Is\nmetabarcoding suitable for estuarine plankton monitor-\ning? A comparative study with microscopy, Marine Bi-\nology 163, 149 (2016).\n[20] T. T. Høye, J. ¨Arje, K. Bjerge, O. L. Hansen, A. Iosi-\nfidis, F. Leese, H. M. Mann, K. Meissner, C. Melvad,\nand J. Raitoharju, Deep learning and computer vision\nwill transform entomology, Proceedings of the National\nAcademy of Sciences 118, e2002545117 (2021).\n[21] E. C. Orenstein, O. Beijbom, E. E. Peacock, and H. M.\nSosik, Whoi-plankton-a large scale fine grained visual\nrecognition benchmark dataset for plankton classifica-\ntion, arXiv preprint arXiv:1510.00745 abs/1510.00745,\n10.48550/arXiv.1510.00745 (2015), 1510.00745.\n[22] A. Y. Hsiang, A. Brombacher, M. C. Rillo, M. J.\nMleneck-Vautravers, S. Conn, S. Lordsmith, A. Jentzen,\nM. J. Henehan, B. Metcalfe, I. S. Fenton, B. S. Wade,\nL. Fox,\nJ. Meilland,\nC. V. Davis,\nU. Baranowski,\nJ. Groeneveld, K. M. Edgar, A. Movellan, T. Aze, H. J.\nDowsett, C. G. Miller, N. Rios, and P. M. Hull, End-\nless Forams: >34,000 Modern Planktonic Foraminiferal\nImages for Taxonomic Training and Automated Species\nRecognition Using Convolutional Neural Networks, Pale-\noceanography and Paleoclimatology 34, 1157 (2019).\n[23] M. D. Ohman, R. E. Davis, J. T. Sherman, K. R. Grind-\nley, B. M. Whitmore, C. F. Nickels, and J. S. Ellen,\nZooglider: An autonomous vehicle for optical and acous-\ntic sensing of zooplankton, Limnology and Oceanogra-\nphy: Methods 17, 69 (2019).\n[24] G. Gorsky, M. D. Ohman, M. Picheral, S. Gasparini,\nL. Stemmann, J.-B. Romagnan, A. Cawood, S. Pesant,\nC. Garc´ıa-Comas, and F. Prejger, Digital zooplankton\nimage analysis using the zooscan integrated system, Jour-\nnal of plankton research 32, 285 (2010).\n[25] M. Picheral, C. Catalano, D. Brousseau, H. Claustre,\nL. Coppola, E. Leymarie, J. Coindat, F. Dias, S. Fevre,\nL. Guidi, et al., The underwater vision profiler 6: an\nimaging sensor of particle size spectra and plankton,\nfor autonomous and cabled platforms, Limnology and\nOceanography: Methods 20, 115 (2022).\n[26] B. Midtvedt, J. Pineda, F. Sk¨arberg, E. Ols´en, H. Bachi-\nmanchi, E. Wes´en, E. K. Esbj¨orner, E. Selander, F. H¨o¨ok,\nD. Midtvedt, and G. Volpe, Single-shot self-supervised\nobject detection in microscopy, Nature Communications\n13, 7492 (2022), number: 1 Publisher: Nature Publishing\nGroup.\n[27] R. Girshick, J. Donahue, T. Darrell, and J. Malik, Rich\nfeature hierarchies for accurate object detection and se-\nmantic segmentation, arXiv 10.48550/ARXIV.1311.2524\n(2013).\n[28] S. Ren, K. He, R. Girshick, and J. Sun, Faster r-cnn:\nTowards real-time object detection with region proposal\nnetworks, Advances in neural information processing sys-\ntems 28 (2015).\n[29] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, You\nonly look once: Unified, real-time object detection, in\nProceedings of the IEEE conference on computer vision\nand pattern recognition (2016) pp. 779–788.\n[30] A. Pedraza, G. Bueno, O. Deniz, J. Ruiz-Santaquiteria,\nC. Sanchez, S. Blanco, M. Borrego-Ramos, A. Olenici,\nand G. Cristobal, Lights and pitfalls of convolutional neu-\nral networks for diatom identification, in Proc.SPIE, Vol.\n10679 (2018).\n[31] S. Kakehi, T. Sekiuchi, H. Ito, S. Ueno, Y. Takeuchi,\nK. Suzuki, and M. Togawa, Identification and counting\nof Pacific oyster Crassostrea gigas larvae by object detec-\ntion using deep learning, Aquacultural Engineering 95,\n102197 (2021).\n[32] Y. Wu, A. Kirillov, F. Massa, W.-Y. Lo, and R. Girshick,\nDetectron2,\nhttps://github.com/facebookresearch/\ndetectron2 (2019).\n[33] J. Ruiz-Santaquiteria, G. Bueno, O. Deniz, N. Vallez,\nand G. Cristobal, Semantic versus instance segmentation\nin microscopic algae detection, Engineering Applications\nof Artificial Intelligence 87, 103271 (2020).\n[34] K. He, G. Gkioxari, P. Doll´ar, and R. Girshick, Mask r-\n15\ncnn, in Proceedings of the IEEE international conference\non computer vision (2017) pp. 2961–2969.\n[35] V. Badrinarayanan, A. Kendall, and R. Cipolla, Segnet:\nA deep convolutional encoder-decoder architecture for\nimage segmentation (2017).\n[36] Z. Shi, K. Wang, L. Cao, Y. Ren, Y. Han, and S. Ma,\nStudy on holographic image recognition technology of\nzooplankton, DEStech Trans. Comput. Sci. Eng , 580\n(2019).\n[37] Y. Li, J. Guo, X. Guo, Z. Hu, and Y. Tian, Plankton\ndetection with adversarial learning and a densely con-\nnected deep learning model for class imbalanced distri-\nbution, Journal of Marine Science and Engineering 9,\n10.3390/jmse9060636 (2021).\n[38] G. Huang, Z. Liu, L. van der Maaten, and K. Q.\nWeinberger, Densely Connected Convolutional Networks\n(2016).\n[39] S. Helgadottir, A. Argun, and G. Volpe, Digital video\nmicroscopy enhanced by deep learning, Optica 6, 506\n(2019).\n[40] B. Midtvedt, S. Helgadottir, A. Argun, J. Pineda,\nD. Midtvedt, and G. Volpe, Quantitative digital mi-\ncroscopy with deep learning, Applied Physics Reviews\n8, 011310 (2021), https://pubs.aip.org/aip/apr/article-\npdf/doi/10.1063/5.0034891/14577703/011310 1 online.pdf.\n[41] Y. Kuang, Deep neural network for deep sea plank-\nton classification, Tech. Rep. (Technical Report 2015.\nAvailable online: https://pdfs. semanticscholar. org . . . ,\n2015).\n[42] J. Dai, R. Wang, H. Zheng, G. Ji, and X. Qiao, Zoo-\nplanktoNet: Deep convolutional network for zooplankton\nclassification, in OCEANS 2016 - Shanghai (IEEE, 2016)\npp. 1–6.\n[43] I. Correa, P. Drews, S. Botelho, M. S. d. Souza, and V. M.\nTavano, Deep Learning for Microalgae Classification, in\n2017 16th IEEE International Conference on Machine\nLearning and Applications (ICMLA) (IEEE, 2017) pp.\n20–25.\n[44] J. Y. Luo, J.-O. Irisson, B. Graham, C. Guigand,\nA. Sarafraz, C. Mader, and R. K. Cowen, Automated\nplankton image analysis using convolutional neural net-\nworks, Limnology and Oceanography: Methods 16, 814\n(2018).\n[45] R. K. Cowen and C. M. Guigand, In situ ichthyoplankton\nimaging system (ISIIS): system design and preliminary\nresults, Limnology and Oceanography: Methods 6, 126\n(2008).\n[46] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, Unpaired\nimage-to-image translation using cycle-consistent adver-\nsarial networks (2020), arXiv:1703.10593 [cs.CV].\n[47] H. Lee, M. Park, and J. Kim, Plankton classification on\nimbalanced large scale database via convolutional neu-\nral networks with transfer learning, in 2016 IEEE inter-\nnational conference on image processing (ICIP) (IEEE,\n2016) pp. 3713–3717.\n[48] J. Deng, W. Dong, R. Socher, L.-J. Li, Kai Li, and Li Fei-\nFei, ImageNet: A large-scale hierarchical image database,\nin 2009 IEEE Conference on Computer Vision and Pat-\ntern Recognition (2009) pp. 248–255.\n[49] E. C. Orenstein and O. Beijbom, Transfer learning and\ndeep feature extraction for planktonic image data sets, in\n2017 IEEE Winter Conference on Applications of Com-\nputer Vision (WACV) (IEEE, 2017) pp. 1082–1088.\n[50] L. MacNeil, S. Missan, J. Luo, T. Trappenberg, and\nJ. LaRoche, Plankton classification with high-throughput\nsubmersible holographic microscopy and transfer learn-\ning, BMC Ecology and Evolution 21, 123 (2021).\n[51] J. S. Ellen, C. A. Graff, and M. D. Ohman, Improv-\ning plankton image classification using context metadata,\nLimnology and Oceanography: Methods 17, 439 (2019).\n[52] J. Pinti, S. H. J´onasd´ottir, N. R. Record, and A. W.\nVisser, The global contribution of seasonally migrating\ncopepods to the biological carbon pump, Limnology and\nOceanography 68, 1147 (2023).\n[53] K. Bandara, Ø. Varpe, L. Wijewardene, V. Tverberg,\nand K. Eiane, Two hundred years of zooplankton vertical\nmigration research, Biological Reviews 96, 1547 (2021).\n[54] D. Krishnamurthy, H. Li, F. Benoit du Rey, P. Cam-\nbournac, A. G. Larson, E. Li, and M. Prakash, Scale-free\nvertical tracking microscopy, Nature Methods 17, 1040\n(2020), number: 10 Publisher: Nature Publishing Group.\n[55] A. W. Visser and T. Kiørboe, Plankton motility patterns\nand encounter rates, Oecologia 148, 538 (2006).\n[56] G. Mu˜noz-Gil, G. Volpe, M. A. Garcia-March, E. Aghion,\nA. Argun, C. B. Hong, T. Bland, S. Bo, J. A. Conejero,\nN. Firbas, et al., Objective comparison of methods to\ndecode anomalous diffusion, Nature communications 12,\n6253 (2021).\n[57] F. Bartumeus, F. Peters, S. Pueyo, C. Marras´e, and\nJ. Catalan, Helical L´evy walks:\nAdjusting searching\nstatistics to resource availability in microzooplankton,\nProceedings of the National Academy of Sciences 100,\n12771 (2003).\n[58] F. G. Schmitt and L. Seuront, Multifractal random walk\nin copepod behavior, Physica A: Statistical Mechanics\nand its Applications 301, 375 (2001).\n[59] N. Chenouard, I. Smal, F. de Chaumont, M. Maˇska,\nI. F. Sbalzarini, Y. Gong, J. Cardinale, C. Carthel,\nS. Coraluppi, M. Winter, A. R. Cohen, W. J. Godinez,\nK. Rohr, Y. Kalaidzidis, L. Liang, J. Duncan, H. Shen,\nY. Xu, K. E. G. Magnusson, J. Jald´en, H. M. Blau,\nP. Paul-Gilloteaux, P. Roudot, C. Kervrann, F. Waharte,\nJ.-Y. Tinevez, S. L. Shorte, J. Willemse, K. Celler, G. P.\nvan Wezel, H.-W. Dan, Y.-S. Tsai, C. O. de Sol´orzano, J.-\nC. Olivo-Marin, and E. Meijering, Objective comparison\nof particle tracking methods, Nature Methods 11, 281\n(2014), number: 3 Publisher: Nature Publishing Group.\n[60] V. Ulman, M. Maˇska, K. E. Magnusson, O. Ronneberger,\nC. Haubold, N. Harder, P. Matula, P. Matula, D. Svo-\nboda, M. Radojevic, et al., An objective comparison\nof cell-tracking algorithms, Nature methods 14, 1141\n(2017).\n[61] W. J. Godinez and K. Rohr, Tracking multiple particles\nin fluorescence time-lapse microscopy images via proba-\nbilistic data association, IEEE transactions on medical\nimaging 34, 415 (2015).\n[62] R. Spilger, A. Imle, J.-Y. Lee, B. M¨uller, O. T. Fack-\nler, R. Bartenschlager, and K. Rohr, A Recurrent Neural\nNetwork for Particle Tracking in Microscopy Images Us-\ning Future Information, Track Hypotheses, and Multiple\nDetections, IEEE Transactions on Image Processing 29,\n3681 (2020).\n[63] R. Spilger, J.-Y. Lee, V. O. Chagin, L. Schermelleh, M. C.\nCardoso, R. Bartenschlager, and K. Rohr, Deep proba-\nbilistic tracking of particles in fluorescence microscopy\nimages, Medical Image Analysis 72, 102128 (2021).\n[64] Y. Yao, I. Smal, I. Grigoriev, A. Akhmanova, and E. Mei-\njering, Deep-learning method for data association in par-\n16\nticle tracking, Bioinformatics (Oxford, England) 36, 4935\n(2020).\n[65] J. Pineda,\nB. Midtvedt,\nH. Bachimanchi,\nS. No´e,\nD. Midtvedt, G. Volpe, and C. Manzo, Geometric deep\nlearning reveals the spatiotemporal features of micro-\nscopic motion, Nature Machine Intelligence 5, 71 (2023),\nnumber: 1 Publisher: Nature Publishing Group.\n[66] C. Ying, T. Cai, S. Luo, S. Zheng, G. Ke, D. He, Y. Shen,\nand T.-Y. Liu, Do Transformers Really Perform Bad for\nGraph Representation? (2021), arXiv:2106.05234 [cs].\n[67] A. Vaswani,\nN. Shazeer,\nN. Parmar,\nJ. Uszkoreit,\nL. Jones, A. N. Gomez,  L. Kaiser, and I. Polosukhin, At-\ntention is all you need, Advances in neural information\nprocessing systems 30 (2017).\n[68] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn,\nX. Zhai, T. Unterthiner, M. Dehghani, M. Minderer,\nG. Heigold, S. Gelly, et al., An image is worth 16x16\nwords: Transformers for image recognition at scale, arXiv\npreprint arXiv:2010.11929 (2020).\n[69] M. Caron, H. Touvron, I. Misra, H. J´egou, J. Mairal,\nP. Bojanowski, and A. Joulin, Emerging properties in\nself-supervised vision transformers, in Proceedings of the\nIEEE/CVF international conference on computer vision\n(2021) pp. 9650–9660.\n[70] J. Lee, M. Jeong, and B. C. Ko, Graph Convolution Neu-\nral Network-Based Data Association for Online Multi-\nObject Tracking, IEEE Access 9, 114535 (2021), confer-\nence Name: IEEE Access.\n[71] T. N. Kipf and M. Welling, Semi-Supervised Classi-\nfication with Graph Convolutional Networks (2017),\narXiv:1609.02907 [cs, stat].\n[72] J. Qiu,\nN. Mousavi,\nL. Zhao, and K. Gustavsson,\nActive\ngyrotactic\nstability\nof\nmicroswimmers\nusing\nhydromechanical signals, Physical Review Fluids 7,\n10.1103/PhysRevFluids.7.014311 (2022).\n[73] K. Gustavsson,\nL. Biferale,\nA. Celani, and S. Co-\nlabrese, Finding efficient swimming strategies in a three-\ndimensional chaotic flow by reinforcement learning, The\nEuropean Physical Journal E 40, 110 (2017).\n[74] S. Colabrese, K. Gustavsson, A. Celani, and L. Biferale,\nFlow Navigation by Smart Microswimmers via Reinforce-\nment Learning, Physical Review Letters 118, 158004\n(2017), publisher: American Physical Society.\n[75] P. Gunnarson, I. Mandralis, G. Novati, P. Koumoutsakos,\nand J. O. Dabiri, Learning efficient navigation in vorti-\ncal flow fields, Nature Communications 12, 7143 (2021),\nnumber: 1 Publisher: Nature Publishing Group.\n[76] J. K. Alageshan, A. K. Verma, J. Bec, and R. Pandit, Ma-\nchine learning strategies for path-planning microswim-\nmers in turbulent flows, Physical Review E 101, 043110\n(2020), publisher: American Physical Society.\n[77] J. Qiu, N. Mousavi, K. Gustavsson, C. Xu, B. Mehlig,\nand L. Zhao, Navigation of micro-swimmers in steady\nflow:\nthe importance of symmetries, Journal of Fluid\nMechanics 932, A10 (2022), publisher: Cambridge Uni-\nversity Press.\n[78] P. A. D´ıaz, G. ´Alvarez, D. Varela, I. P´erez-Santos,\nM. D´ıaz, C. Molinet, M. Seguel, A. Aguilera-Belmonte,\nL. Guzm´an, E. Uribe, et al., Impacts of harmful algal\nblooms on the aquaculture industry:\nChile as a case\nstudy, Perspect. Phycol 6, 39 (2019).\n[79] M. Lenzen, M. Li, and S. A. Murray, Impacts of harm-\nful algal blooms on marine aquaculture in a low-carbon\nfuture, Harmful Algae 110, 102143 (2021).\n[80] P. J. Franks, Npz models of plankton dynamics: their\nconstruction, coupling to physics, and application, Jour-\nnal of Oceanography 58, 379 (2002).\n[81] B. Frost, Grazing control of phytoplankton stock in the\nopen subarctic pacific ocean: a model assessing the role\nof mesozooplankton, particularly the large calanoid cope-\npods neocalanus spp., Marine ecology progress series.\nOldendorf 39, 49 (1987).\n[82] I. Aoki, T. Komatsu, and K. Hwang, Prediction of re-\nsponse of zooplankton biomass to climatic and oceanic\nchanges, Ecological Modelling 120, 261–270 (1999).\n[83] R. S. Woodd-Walker, K. S. Kingston, and C. P. Galli-\nenne, Using neural networks to predict surface zooplank-\nton biomass along a 50°n to 50°s transect of the atlantic,\nJournal of plankton research 23, 875 (2001).\n[84] B. J. Pan, M. Vernet, L. Manck, K. Forsch, L. Ek-\nern, M. Mascioni, K. A. Barbeau, G. O. Almandoz, and\nA. J. Orona, Environmental drivers of phytoplankton\ntaxonomic composition in an antarctic fjord, Progress in\nOceanography 183, 102295 (2020).\n[85] A. Chase, E. Boss, N. Ha¨entjens, E. Culhane, C. Roesler,\nand\nL.\nKarp-Boss,\nPlankton\nimagery\ndata\ninform\nsatellite-based estimates of diatom carbon, Geophysical\nResearch Letters 49, e2022GL098076 (2022).\n[86] J. Pyo, S. M. Hong, J. Jang, S. Park, J. Park, J. H. Noh,\nand K. H. Cho, Drone-borne sensing of major and ac-\ncessory pigments in algae using deep learning modeling,\nGIScience & Remote Sensing 59, 310–332 (2022).\n[87] M. Sammartino, S. Marullo, R. Santoleri, and M. Scardi,\nModelling the vertical distribution of phytoplankton\nbiomass in the mediterranean sea from satellite data:\nA neural network approach, Remote Sensing 10, 1666\n(2018).\n[88] E. Martinez, A. Brini, T. Gorgues, L. Drumetz, J. Rous-\nsillon,\nP. Tandeo,\nG. Maze, and R. Fablet, Neu-\nral network approaches to reconstruct phytoplankton\ntime-series in the global ocean, Remote Sensing 12,\n10.3390/rs12244156 (2020).\n[89] M. Liu, J. He, Y. Huang, T. Tang, J. Hu, and X. Xiao,\nAlgal bloom forecasting with time-frequency analysis:\nA hybrid deep learning approach, Water Research 219,\n118591 (2022).\n[90] D. Wenxiang, Z. Caiyun, S. Shaoping, and L. Xueding,\nOptimization of deep learning model for coastal chloro-\nphyll a dynamic forecast, Ecological Modelling 467,\n109913 (2022).\n[91] F. Cichos, K. Gustavsson, B. Mehlig, and G. Volpe, Ma-\nchine learning for active matter, Nature Machine Intelli-\ngence 2, 94 (2020).\n[92] M. Baker, 1,500 scientists lift the lid on reproducibility,\nNature 533, 452 (2016).\nCompeting interests\nThe authors declare no competing interests.\nData and code availability\nAll the relevant source code and the data are made\npublicly available at the GitHub repository [1]\nAuthor contributions\nHB, MIM, CR conceptualised the work, conducted liter-\nature research, and wrote the manuscript. HB developed\n17\nthe code examples and established the GitHub reposi-\ntory. HB, CR and ES analysed the data, and generated\nthe figures. PDW, JH, AK, DM, ES and GV provided\nfeedback on the manuscript. ES and GV provided project\noversight, and supervised the project.\n",
  "categories": [
    "physics.bio-ph",
    "cond-mat.soft",
    "cs.LG",
    "q-bio.QM"
  ],
  "published": "2023-09-15",
  "updated": "2023-09-15"
}