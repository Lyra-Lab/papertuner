{
  "id": "http://arxiv.org/abs/2309.15421v1",
  "title": "Deep Learning in Deterministic Computational Mechanics",
  "authors": [
    "Leon Herrmann",
    "Stefan Kollmannsberger"
  ],
  "abstract": "The rapid growth of deep learning research, including within the field of\ncomputational mechanics, has resulted in an extensive and diverse body of\nliterature. To help researchers identify key concepts and promising\nmethodologies within this field, we provide an overview of deep learning in\ndeterministic computational mechanics. Five main categories are identified and\nexplored: simulation substitution, simulation enhancement, discretizations as\nneural networks, generative approaches, and deep reinforcement learning. This\nreview focuses on deep learning methods rather than applications for\ncomputational mechanics, thereby enabling researchers to explore this field\nmore effectively. As such, the review is not necessarily aimed at researchers\nwith extensive knowledge of deep learning -- instead, the primary audience is\nresearchers at the verge of entering this field or those who attempt to gain an\noverview of deep learning in computational mechanics. The discussed concepts\nare, therefore, explained as simple as possible.",
  "text": "Deep Learning in Deterministic Computational\nMechanics\nLeon Herrmann∗1 and Stefan Kollmannsberger1\n1Chair of Computational Modeling and Simulation, Technical University of Munich, School of Engineering and\nDesign, Arcisstrae 21, Munich, 80 333, Germany\nAbstract\nThe rapid growth of deep learning research, including within the field of computational mechanics,\nhas resulted in an extensive and diverse body of literature. To help researchers identify key concepts\nand promising methodologies within this field, we provide an overview of deep learning in deter-\nministic computational mechanics. Five main categories are identified and explored: simulation\nsubstitution, simulation enhancement, discretizations as neural networks, generative approaches,\nand deep reinforcement learning. This review focuses on deep learning methods rather than ap-\nplications for computational mechanics, thereby enabling researchers to explore this field more\neffectively. As such, the review is not necessarily aimed at researchers with extensive knowledge of\ndeep learning — instead, the primary audience is researchers at the verge of entering this field or\nthose who attempt to gain an overview of deep learning in computational mechanics. The discussed\nconcepts are, therefore, explained as simple as possible.\nKeywords: Deep learning; Computational mechanics, Neural networks; Surrogate model; Physics-\ninformed; Generative\nContents\n1. Introduction\n3\n1.1. Motivation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.2. Taxonomy of Deep Learning Techniques in Computational Mechanics\n. . . . . . . .\n3\n1.3. Deep Learning\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n2. Simulation Substitution\n5\n2.1. Data-Driven Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.1.1.\nSpace-Time Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.1.1.\nFully-Connected Neural Networks . . . . . . . . . . . . . . . . . . .\n6\n2.1.1.2.\nImage-To-Image Mapping . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.1.3.\nModel Order Reduction Encoding . . . . . . . . . . . . . . . . . . .\n7\n2.1.1.4.\nNeural Operators\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.1.1.5.\nNeural Network Approximation Power . . . . . . . . . . . . . . . . .\n8\n2.1.1.6.\nActive Learning & Transfer Learning\n. . . . . . . . . . . . . . . . .\n9\n2.1.2.\nTime-Stepping Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.2.1.\nRecurrent Neural Networks . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.2.2.\nDynamic Mode Decomposition . . . . . . . . . . . . . . . . . . . . .\n10\n2.2. Physics-Informed Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.2.1.\nSpace-Time Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.2.1.1.\nDifferential Equation Solving With Neural Networks . . . . . . . . .\n11\n∗leon.herrmann@tum.de, Corresponding author\nPreprint submitted to Computational Mechanics.\nSeptember 28, 2023\narXiv:2309.15421v1  [cs.LG]  27 Sep 2023\n2.2.1.2.\nInverse Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.2.2.\nTime-Stepping Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.2.2.1.\nPhysics-Informed Neural Networks . . . . . . . . . . . . . . . . . . .\n17\n2.2.2.2.\nInverse Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n2.2.3.\nEnforcement Of Physics By Construction\n. . . . . . . . . . . . . . . . . . . .\n20\n3. Simulation Enhancement\n20\n3.1. Pre-processing\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.1.1.\nData Preparation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.1.2.\nInitialization\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.1.3.\nMeshing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.2. Physical Modeling\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.2.1.\nModel Substitution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.2.2.\nIdentification Of Model Parameters . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.2.3.\nModel Identification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.3. Numerical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.3.1.\nAlgorithm Enhancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.3.2.\nMultiscale Methods\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.3.3.\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4. Post-Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4. Discretizations As Neural Networks\n27\n4.1. Finite Element Method\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n4.2. Finite Difference Method\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n4.3. Material Discretizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n4.4. Neural Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n5. Generative Approaches\n31\n5.1. Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n5.2. Generative Adversarial Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n5.3. Diffusion Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n5.4. Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.4.1.\nData Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.4.2.\nGenerative Design & Design Optimization . . . . . . . . . . . . . . . . . . . .\n33\n5.4.3.\nConditional Generation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n5.4.4.\nAnomaly Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6. Deep Reinforcement Learning\n35\n6.1. Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n6.1.1.\nExtensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n7. Conclusion\n36\nA. Deep Reinforcement Learning\n38\nA.1. Deep Policy Networks\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\nA.2. Deep Q-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\nReferences\n40\n2\n1. Introduction\n1.1. Motivation\nIn recent years, access to enormous quantities of data combined with rapid advances in machine\nlearning has yielded outstanding results in computer vision, recommendation systems, medical di-\nagnosis, and financial forecasting [1]. Nonetheless, the impact of learning algorithms reaches far\nbeyond and has already found its way into many scientific disciplines [2].\nThe rapid interest in machine learning in general and within computational mechanics is well\ndocumented in the scientific literature. By considering the number of publications treating “Ar-\ntificial Intelligence”, “Machine Learning”, “Deep Learning”, and “Neural Networks”, the interest\ncan be quantified. Figure 1a shows the trend in all journals of Elsevier and Springer since 1999,\nwhile Figure 1b depicts the trend within the computational mechanics community by consider-\ning representative journals1 at Elsevier and Springer. The trends before 2017 differ slightly, with\na steady growth in general but only limited interest within computational mechanics. However,\naround 2017, both curves show a shift in trend, namely a vast increase in publications highlight-\ning the interest and potential prospects of artificial intelligence and its subtopics for a variety of\napplications.\n(a) Publications in all fields.\n(b) Publications within Computational Mechanics.\nFigure 1: Number of publications concerning artificial intelligence and some of its subtopics since\n1999. Illustration inspired by [3].\n1.2. Taxonomy of Deep Learning Techniques in Computational Mechanics\nDue to the rapid growth [4] in deep learning research, as also seen in Figure 1a, we provide an\noverview of the various deep learning methodologies in deterministic computational mechanics.\nNumerous review articles on deep learning for specific applications have already emerged (see [5,\n6] for topology optimization, [7] for full waveform inversion, [8–12] for fluid mechanics, [13] for\ncontinuum mechanics, [14] for material mechanics, [15] for constitutive modeling, [16] for generative\ndesign, [17] for material design, and [18] for aeronautics)2. The aim of this work is, however, to\nfocus on the general methods rather than applications, where similar methods are often applied\nto different problems. This has the potential to bridge gaps between scientific communities by\nhighlighting similarities between methods and thereby establishing clarity on the state-of-the-art.\nWe propose the following taxonomy in order to discuss the deep learning methods in a structured\nmanner:\n1The considered journals are Computer Methods in Applied Mechanics and Engineering, Computers & Mathematics\nwith Applications, Computers & Structures, Computational Mechanics, Engineering with Computers, Journal of\nComputational Physics.\n2For introductory textbooks, see [19–22, 3].\n3\n• simulation substitution (Section 2)\n– data-driven modeling (Section 2.1)\n– physics-informed learning (Section 2.2)\n• simulation enhancement (Section 3)\n• discretizations as neural networks (Section 4)\n• generative approaches (Section 5)\n• deep reinforcement learning (Section 6)\nSimulation substitution replaces the entire simulation with a surrogate model, which in this\nwork are neural networks (NNs). The model can be trained with supervised learning, which purely\nrelies on labeled data and therefore is referred to as data-driven modeling. The generalization\nerrors of these models can be reduced by physics-informed learning. Here, physics constraints\nare imposed on the learnable space such that only physically admissible solutions are learned.\nSimulation enhancement instead only replaces components of the simulation chain, while\nthe remaining parts are still handled by classical methods. Approaches within this category are\nstrongly linked to their respective applications and will, therefore, be presented in the context of\ntheir specific use cases. Both data-driven and physics-informed approaches will be discussed.\nTreating discretizations as neural networks is achieved by constructing a discretization from\nthe basic building blocks of NNs, i.e., linear transformations and non-linear activation functions.\nThereby, techniques within deep learning frameworks – such as automatic differentiation, gradient-\nbased optimization, and efficient GPU-based parallelization – can be leveraged to improve classical\nsimulation techniques.\nGenerative approaches deal with creating new content based on a data set. The goal is not,\nhowever, to recreate the data, but to generate statistically similar data. This is useful in diversify-\ning the design space or enhancing a data set to train surrogate models.\nFinally, in deep reinforcement learning, an agent learns how to interact with an environment\nin order to maximize rewards provided by the environment. In the case of deep reinforcement learn-\ning, the agent is modeled with NNs. In the context of computational mechanics, the environment\nis modeled by the governing physical equations. Reinforcement learning provides an alternative to\ngradient-based optimization, which is useful when gradient information is not available.\n1.3. Deep Learning\nBefore continuing with the topics specific to computational mechanics, NNs3 and the notation used\nthroughout this work are briefly introduced. In essence, NNs are function approximators that are\ncapable of approximating any continuous function [26]. The NN parametrized by the parameters θ\nlearns a function ˆy = fNN(x; θ), which approximates the relation y = f(x). The NN is constructed\nwith nested linear transformations in combination with non-linear activation functions σ.\nThe\nquality of prediction is determined by a cost function C(ˆy), which is to be minimized. Its gradients\n∇θC with respect to the parameters θ are used within a gradient-based optimization [23, 27, 28]\nto update the parameters θ and thereby improve the prediction ˆy. Supervised learning relies on\nlabeled data xM, yM to establish a cost function, while unsupervised learning does not rely on\nlabeled data. The parameters defining the user-defined training algorithm and NN architecture are\nreferred to as hyperparameters.\n3see [23] for an in-depth treatment and PyTorch [24] or TensorFlow [25] for deep learning libraries\n4\nNotational Remark 1 Although x and y may denote vector-valued quantities, we do not use\nbold-faced notation for them.\nInstead, this is reserved for all N degrees of freedom within a\nproblem, i.e., x = {xi}N\ni=1, y = {yi}N\ni=1. This can, for instance, be in the form of a domain Ω\nsampled with N grid points or systems composed of N degrees of freedom. Note however, that\nmatrices will still be denoted with capital letters in bold face.\nNotational Remark 2 A multitude of NN architectures will be discussed throughout this work,\nfor which we introduce abbreviations and subscripts. Most prominent are fully-connected NNs\nFFNN (FC-NNs) [29, 23], convolutional NNs fCNN (CNNs) [30–32], recurrent NNs fRNN (RNNs) [33–\n35], and graph NNs fGNN (GNNs) [36–38]4. If the network architecture is independent of the\nmethod, the network is denoted as fNN.\n2. Simulation Substitution\nIn the field of computational mechanics, numerical procedures are developed to solve or find partial\ndifferential equations (PDEs). A generic PDE can be written as\nN[u; λ] = 0,\non Ω× T ,\n(1)\nwhere a non-linear operator N acts on a solution u(x, t) of a PDE as well as the coefficients λ(x, t)\nof the PDE in the spatio-temporal domain Ω×T . In the forward problem, the solution u(x, t) is to\nbe computed, while the inverse problem considers either the non-linear operator N or coefficients\nλ(x, t) as unknowns.\nA further distinction is made between methods treating the temporal dimension t as a continuum,\nas in space-time approaches [42] (Sections 2.1.1 and 2.2.1)5, or in discrete sequential time steps, as\nin time-stepping procedures (Sections 2.1.2 and 2.2.2). For simplicity, but without loss of generality,\ntime-stepping procedures will be presented on PDEs with a first order derivative with respect to\ntime:\n∂u\n∂t = N[u; λ],\non Ω× T .\n(2)\nAnother task in computational mechanics is the forward modeling and identification of systems of\nordinary differential equations (ODEs). For this, we will consider systems of the following form:\ndx(t)\ndt\n= f(x(t)).\n(3)\nHere, x(t) are the time-dependent degrees of freedom and f is the right-hand side defining the\nsystem of equations.6 Both the forward problem of computing x(t) and the inverse problem of\nidentifying f will be discussed in the following.\n2.1. Data-Driven Modeling\nData-driven modeling relies entirely on labeled data xM, yM. The NN learns the mapping between\nxM and yM with ˆyi = fNN(xi; θ). Thereby an interpolation to yet unseen datapoints is established.\nA data-driven loss LD, such as the mean squared error, for example, can be used as cost function\nC.\nC = LD =\n1\n2ND\nND\nX\ni=1\n||ˆyi −yM\ni ||2\n2\n(4)\n4Another architecture worth mentioning, as it has recently been applied for regression [39, 40] are spiking NNs [41]\nspecialized to run on neuromorphic hardware and thereby reduce memory and energy consumption. These are\nhowever not treated in this work.\n5Static problems without time-dependence can only be treated by the space-time approaches.\n6Note that a spatial discretization of the PDE Equation (2) can also be written as a system of ODEs.\n5\n2.1.1. Space-Time Approaches\nTo declutter the notation, but without loss of generality, the temporal dimension t is dropped in\nthis section, as it is possible to treat it like any other spatial dimension x in the scope of these\nmethods. The goal of the upcoming methods is to either learn a forward operator ˆu = F[λ; x], an\ninverse operator for the coefficients ˆλ = I[u; x], or an inverse operator for the non-linear operator\nˆ\nN = O[u; λ; x].7 The methods will be explained using the forward operator, but they apply analo-\ngously to the inverse operators. Only the inputs and outputs differ.\nThe solution prediction ˆui at coordinate xi or ˆui on the entire domain Ωis made based on a set\nof inverse coefficients λi. The cost function C is formulated analogously to Equation (4):\nC = LD =\n1\n2ND\nND\nX\ni=1\n||ˆui −uM\ni ||2\n2\nor\nC = LD =\n1\n2ND\nND\nX\ni=1\n||ˆui −uM\ni ||2\n2.\n(5)\n2.1.1.1. Fully-Connected Neural Networks\nThe simplest procedure is to approximate the operator F with a FC-NN FFNN.\nˆu(x) = FFNN(λ; x; θ)\n(6)\nExample applications are flow classification [43, 44], fluid flow in turbomachinery [45], dynamic\nbeam displacements from previous measurements [46], wall velocity predictions in turbulence [47],\nheat transfer [48], prediction of source terms in turbulence models [49], full waveform inversion [50–\n52], and topology optimization based on moving morphable bars [53]. The approach is however\nlimited to simple problems, as an abundance of data is required. Therefore, several improvements\nhave been proposed.\n2.1.1.2. Image-To-Image Mapping\nOne downside of the application of fully-connected NNs to problems in computational mechanics is\nthat they often need to learn spatial relationships with respect to x from scratch. CNNs inherently\naccount for these spatial relationships due to their kernel-based structure. Therefore, image-to-\nimage mappings using CNNs have been proposed, where an image, i.e., a uniform grid (see Figure 2)\nof the coefficients λ, is used as input.\nˆu = FCNN(λ; θ)\n(7)\nThis results in a prediction of the solution ˆu throughout the entire image, i.e., the domain.\nFinite Element Mesh\nNodes as Pixels\nFigure 2: Representation of nodes of a Cartesian grid as pixels in an image. Adapted from [54].\nApplications include pressure and velocity predictions around airfoils [55–58], stress predictions\nfrom geometries and boundary conditions [59, 60], steady flow predictions [61], detection of manu-\nfacturing features [62, 63], full waveform inversion [64–75], and topology optimization [76–85]. An\nimportant choice in the design of the learning algorithm is the encoding of the input data. In the\ncase of geometries and boundary conditions, binary representations are the most straightforward\napproach. These are however challenging for CNNs, as discussed in [61]. Signed distance func-\ntions [61] or simulations on coarse grids provide superior alternatives. For inverse problems, an\n7Note that u might only be partially known on the domain Ωfor inverse problems.\n6\ninitial forward simulation of an initial guess of the inverse field can be used to encode the desired\nboundary conditions [80, 83–85]. Another possibility for CNNs is a decomposition of the domain.\nThe mapping can be performed on the full domain [86], smaller subdomains [87], or even individual\npixels [88]. In the latter two cases, interfaces require special treatment.\n2.1.1.3. Model Order Reduction Encoding\nThe disadvantage of CNN mappings is being constrained to uniform grids on rectangular domains.\nThis can be circumvented by using GNNs, such as in [89–91], or point cloud-based NNs [92, 93],\nsuch as in [94]. To further aid the learning, the NN can be applied to a lower-dimensional space\nthat is able to capture the data. For complex problems, mappings e to low-dimensional spaces\n(also referred to as latent space or latent vector) h can be identified with model order reduction\ntechniques. Thus, in the case of simulation substitution, a low-dimensional encoding hλ = e(λ)\nof λ is identified. This is provided as input to a NN to predict the solution field hu in a reduced\nlatent space. The full solution field u is obtained in a decoding d = e−1 step. The prediction is\ngiven as\nˆu = d(ˆh\nu) = d\n\u0000FNN(hλ; θ)\n\u0001\n= d\n\u0010\nFNN\n\u0000e(λ); θ\n\u0001\u0011\n.\n(8)\nThe dimensional reduction can, e.g., be performed with principal components analysis [95, 96],\nas proposed in [97], proper orthogonal decomposition [98], or reduced manifold learning [99]. These\ntechniques have been applied to learning aortic wall stresses [100], arterial wall stresses [101], flow\nvelocities in viscoplastic flow [102], and the inverse problem of identifying unpressurized geometries\nfrom pressurized geometries [103]. Currently, the most impressive results in data-driven surrogate\nmodeling are achieved with model order reduction encodings combined with NNs [104, 105], which\ncan be combined with most other methodologies presented in this work.\nAnother dimensionality reduction technique are autoencoders [106], where e and d are modeled by\nNNs8. These are treated in detail in Section 5.1 and enable non-linear encodings. An early investi-\ngation is presented in [107], where proper orthogonal decomposition is related to NNs. Application\nareas are the prediction of designs of acoustic scatterers from the reduced latent space [108], or\nmappings from dynamic responses of bridges to damage [109]. Furthermore, it has to be stated that\nmany of the image-to-image mapping techniques rely on NN architectures inspired by autoencoders,\nsuch as U-nets [110, 111].\n2.1.1.4. Neural Operators\nThe most recent trend in surrogate modeling with NNs are neural operators [112], which map\nbetween function spaces instead of functions. Neural operators rely on the extension of the universal\napproximation theorem [26] to non-linear operators [113]. The two most prominent neural operators\nare DeepONets9 [114] and Fourier neural operators [115].\nDeepONet\nIn DeepONets [114], illustrated in Figure 3, the task of predicting the operator ˆu(λ; x) is split up\ninto two sub-tasks:\n• the prediction of NP basis functions ˆt(x) (TrunkNet),\n• the prediction of the corresponding NP problem-specific coefficients ˆb(λ) (BranchNet).\nThe basis is predicted by the TrunkNet with parameters θT via an evaluation at coordinates x.\nThe coefficients are estimated from the coefficients λ using the BranchNet parametrized by θB\n8Note that the autoencoder is modified, as it does not perform an identity mapping.\nNonetheless, the idea of\nmapping to a reduced latent state is exploited.\n9Originally proposed in [113] with shallow NNs.\n7\nand, thus, specific to the problem being solved. Taking the dot product over the evaluated basis\nand the coefficients yields the solution prediction ˆu(λ; x).\nˆt(x) = F T\nFNN(x; θT )\n(9)\nˆb(λ) = F B\nFNN(λ; θB)\n(10)\nˆu(x) = ˆb(λ) · ˆt(x)\n(11)\nλ\nBranchNet(θ)\nˆb\nx\nTrunkNet(θ)\nˆt\nˆu(λ; x) = PNP\ni=1 ˆbiˆti\nFigure 3: DeepONet, operator learning via prediction of the basis functions ˆt and the corresponding\ncoefficients ˆb [114].\nApplications can be found in [116–128].\nDeepONets have also been extended with physics-\ninformed loss functions [129–131].\nFourier Neural Operators\nFourier neural operators [115] predict the solution ˆu on a uniform grid x from the spatially varying\ncoefficients λ = λ(x). As the aim is to learn a mapping between functions, sampled on the entire\ndomain, non-local mappings can be performed at each layer [132]. For example, mappings such\nas integral kernels [133, 134], Laplace transformations [135], and Fourier transforms [115] can be\nemployed. These transformations enhance the non-local expressivity of the NN [132], where Fourier\ntransforms are particularly favorable due to the computational efficiency achievable through fast\nFourier transforms.\nThe Fourier neural operator, as illustrated in Figure 4, consists of Fourier layers, where linear\ntransformations K are performed after Fourier transforms F along the spatial dimensions x. Sub-\nsequently, an inverse Fourier transform F−1 is applied, which is added to the output of a linear\ntransformation W performed outside the Fourier space. Thus, the Fourier transform can be skipped\nby the NN. The final step is an activation function σ. The manipulations within a Fourier layer to\npredict the next activation on the uniform grid a(j+1)(x) can be written as\na(j+1)(x) = σ\n\u0012\nW a(j)(x) + b + (F−1h\nKF\n\u0002\na(j)(x)\n\u0003i\u0013\n,\n(12)\nwhere b is the bias. Both the linear transformations K, W and the bias b are learnable and thereby\npart of the parameters θ. Multiple Fourier layers can be employed, typically used in combination\nwith an encoding network PNN and a decoding network QNN.\nApplications can be found in [136–146]. An extension relying on the attention mechanisms of\ntransformers [147] is presented in [148]. Analogously to DeepONets, Fourier neural operators have\nbeen combined with physics-informed loss functions [149].\n2.1.1.5. Neural Network Approximation Power\nDespite the advancements in NN architectures10, NN surrogates struggle to learn solutions of gen-\neral PDEs. Typically, successes have only been achieved for parametrized PDEs with relatively\nsmall parameter spaces – or in cases where accuracy, reliability, or generalization were disregarded.\nIt has, however, been shown – both for simple architectures such as FC-NNs [150, 151] as well as\n10including architectures specifically designed to solve PDEs\n8\nλ\nFNO(θ)\nˆu\nFC-NN\nPNN\nFourier\nLayer\nFourier\nLayer\n. . .\nFC-NN\nQNN\nF\nLinear Transform K\nLinear Transform W\nF−1\n+\nσ\nFigure 4: Fourier neural operator, operator learning in the Fourier space [115].\nfor advanced architectures such as DeepONets [152] – that NNs possess an excellent theoretical\napproximation power which can capture solutions of various PDEs. Currently, there are two obsta-\ncles that impede the identification of sufficiently good optima with these desirable NN parameter\nspaces [150]:\n• training data: generalization error,\n• training algorithm: optimization error.\nA lack of sufficient training data leads to poor generalization. This might be alleviated through\nfaster data generation using, e.g., faster and specialized classical methods [153], or improved sam-\npling strategies, i.e., finding the minimum number of required datapoints distributed in a specific\nmanner to train the surrogate. Additionally, current training algorithms only converge to local op-\ntima. Research into improved optimization algorithms, such as current trends in computing better\ninitial weights [154] and thereby better local optima, attempts to reduce the optimization error.\nAt the same time, training times are reduced drastically increasing the competitiveness.\n2.1.1.6. Active Learning & Transfer Learning\nFinally, an important machine learning technique independent of the NN architecture is active\nlearning [155]. Instead of precomputing a labeled data set, data is only provided when the pre-\ndiction quality of the NN is insufficient. Furthermore, the data is not chosen arbitrarily, but only\nin the vicinity of the failed prediction. In computational mechanics, the prediction of the NN can\nbe assessed with an error indicator. For an insufficient result, the results of a classical simulation\nare used to retrain the NN. Over time, the NN estimates improve in the respective domain of\napplication. Due to the error indicator and the classical simulations, the predictions are reliable.\nExamples for active learning in computational mechanics can be found in [156–158].\nAnother technique, transfer learning [159, 160], aims at accelerating the NN training. Here, the\nNN is first trained on a similar task. Subsequently, it is applied to the task of interest – where\nit converges faster than an untrained NN. Applications in computational mechanics can be found\nin [73, 161].\n2.1.2. Time-Stepping Procedures\nFor the time-stepping procedures, we will consider Equations (2) and (3) in the following.\n2.1.2.1. Recurrent Neural Networks\nThe simplest approach to modeling time series data is by using FC-NNs to predict the next time\n9\nstep ti+1 from the current time step ti:\nˆu(x, ti+1) = FFNN\n\u0000x, ti; u(x, ti); θ\n\u0001\n.\n(13)\nHowever, this approach lacks the ability to capture the temporal dependencies between different\ntime steps, as each input is treated independently and without considering more than just the\nprevious time step. Incorporating the sequential nature of the data can be achieved directly with\nRNNs. RNNs maintain a hidden state which captures information from the previous time steps,\nto be used for the next time step prediction. By unrolling the RNN, the entire time-history can be\npredicted.\n{ˆu(x, t2), ˆu(x, t3), . . . , ˆu(x, tN)} = FRNN(x; u(x, t1); θ)\n(14)\nShortcomings of RNNs, such as their tendency to struggle with learning long-term dependencies\ndue to the problem of vanishing or exploding gradients, have been addressed by more sophisticated\narchitectures such as long short-time memory networks (LSTM) [34], gated recurrent unit networks\n(GRU) [162], and transformers [147]. The concept of recurrent units has also been combined with\nother architectures, as demonstrated for CNNs [163] and GNNs [164–167, 89, 90, 168].\nFurther applications of RNNs are full waveform inversion [169–171], high-dimensional chaotic\nsystems [172], fluid flow [173, 3], fracture propagation [91], sensor signals in non-linear dynamic\nsystems [174, 175], and settlement field predictions induced by tunneling [176], which was extended\nto damage prediction in affected structures [177, 178]. RNNs are often combined with reduced order\nmodel encodings [179], where the dynamics are predicted on the reduced latent space, as demon-\nstrated in [180–186]. Further variations employ classical time-stepping schemes on the reduced\nlatent space obtained by autoencoders [187, 188].\n2.1.2.2. Dynamic Mode Decomposition\nAnother approach that was formulated for system dynamics, i.e., Equation (3) is dynamic mode\ndecomposition (DMD) [189, 190]. The aim of DMD is to identify a linear operator A that re-\nlates two successive snapshot matrices with n time steps X = [x(t1), x(t2), . . . , x(tn)]T , X′ =\n[x(t2), x(t3), . . . , x(tn+1)]T :\nX′ ≈AX.\n(15)\nTo solve this, the problem is reframed as a regression task. The operator A is approximated by\nminimizing the Frobenius norm of the difference between X′ and AX. This minimization can be\nperformed using the Moore-Penrose pseudoinverse X† (see, e.g., [191]):\nA = arg min\nA\n||X′ −AX||F = X′X†.\n(16)\nOnce the operator is identified, it can be used to propagate the dynamics forward in time, approx-\nimating the next state x(ti+1) using the current state x(ti):\nx(ti+1) ≈Ax(ti).\n(17)\nThis framework, is however, only valid for linear dynamics. DMD can be extended to handle non-\nlinear systems through the application of Koopman operator theory [192]. According to Koopman\noperator theory, it is possible to represent a non-linear system as a linear one by using an infinite-\ndimensional Koopman operator K that acts on a transformed state e(x(ti)):\ng(x(ti+1)) = K[e(x(ti))].\n(18)\nIn theory, the Koopman operator K is an infinite-dimensional linear transformation. In practice,\nhowever, finite-dimensional approximations are employed. This approach is, for example utilized\nin the extended DMD [193], where the regression from Equation (16) is performed on a higher-\ndimensional state h(ti) = e(x(ti)) relying on a dictionary of orthonormal basis functions ψ(x).\nAlternatively, the dictionary can be learned using NNs, i.e., ˆ\nψ(x) = ψNN(x; θ), as demonstrated\n10\nin [194, 195]. The NN is trained by minimizing the mismatch between predicted state ψ(ˆx(ti+1)) =\nA ˆ\nψ(x(ti)) (Equation (17)) and the true state in the dictionary space. Orthogonality is not required\nand therefore not enforced.\nC =\n1\n2N\nN\nX\ni=1\n|| ˆ\nψ(x(ti+1)) −A ˆ\nψ(x(ti))||2\n2\n(19)\nWhen the dictionary is learned, the state predictions can be reconstructed using the Koopman\nmode decomposition, as explained in detail in [194].\nAlternatively, the mapping to the augmented state can be performed with autoencoders, which\nat the same time allows for a direct map back to the original space [196–199]. Thus, an encoder\nlearns a reduced latent space ˆh(x) = eNN(x; θe) and a decoder learns the inverse mapping ˆx(h) =\ndNN(h; θd). The networks are trained using three losses: the autoencoder reconstruction loss LA,\nthe linear dynamics loss LR, and the future state prediction loss LF.\nLA =\n1\n2(n + 1)\nn+1\nX\ni=1\n||x(ti) −dNN(eNN(x(ti); θe); θd)||2\n2\n(20)\nLR = 1\n2n\nn\nX\ni=1\n||eNN(x(ti+1); θe) −AeNN(x(ti); θe)||2\n2\n(21)\nLF = 1\n2n\nn\nX\ni=1\n||x(ti+1) −dNN(AeNN(x(ti); θe); θd)||2\n2\n(22)\nC = κALA + κRLR + κFLF\n(23)\nThe cost function C is composed of a weighted sum of the loss terms LA, LR, LF and weighting\nterms κA, κR, κF. Furthermore, [198] allows A to vary depending on the state. This is achieved by\npredicting the eigenvalues of A with an auxiliary network and constructing the matrix from these.\n2.2. Physics-Informed Learning\nIn supervised learning, as discussed in Section 2.1, the quality of prediction strongly depends on\nthe amount of training data. Acquiring data in computational mechanics may be expensive. To\nreduce the amount of required data, constraints enforcing the physics have been proposed. Two\nmain approaches exist. The physics can be enforced by modifying the cost function through a\npenalty term punishing unphysical predictions, thus acting as a regularizer. Possible modifications\nare discussed in the upcoming section. Alternatively, the physics can be enforced by construction,\ni.e., by reducing the learnable space to a physically meaningful space. This approach is highly\nspecific to its application and will therefore mainly be explored in Section 3. A brief coverage is\nprovided in Section 2.2.3.\n2.2.1. Space-Time Approaches\nOnce again and without loss of generality, the temporal dimension t is dropped to declutter the\nnotation. However, in contrast to Section 2.1.1, the following methods are not equally applicable\nto forward and inverse problems. Thus, the prediction of the solution ˆu, the PDE coefficients ˆλ,\nand the non-linear operator N are treated separately.\n2.2.1.1. Differential Equation Solving With Neural Networks\nThe concept of solving PDEs11 was first proposed in the 1990s [200–202], but was recently popu-\nlarized by the so-called physics-informed neural networks (PINNs) [203] (see [204–206] for recent\n11Typically, a single solution to a PDE is obtained. If the PDE is parametrized, multiple solutions can be obtained.\n11\nreview articles and SciANN [207], SimNet [208], DeepXDE [209] for libraries).\nTo illustrate the idea and variations of PINNs, we will consider the differential equation of a\nstatic elastic bar\nd\ndx\n\u0012\nEAdu\ndx\n\u0013\n+ p = 0,\nx ∈Ω.\n(24)\nHere, the non-linear operator N is given by the left-hand side of the equation, the solution u(x) is\nthe axial displacement, and the spatially varying coefficients λ(x) are given by the cross-sectional\nproperties EA(x) and the distributed load p(x). Additionally, boundary conditions are specified,\nwhich can be in terms of Dirichlet (on ΓD) or Neumann boundary conditions (on ΓN):\nu(x) = g(x),\nx ∈ΓD,\n(25)\nEA(x)du(x)\ndx\n= f(x),\nx ∈ΓN.\n(26)\nPhysics-Informed Neural Networks\nPINNs [203] approximate either the solution u(x), the coefficients λ(x), or both with FC-NNs.\nˆu(x) = FFNN(x; θu)\n(27)\nˆλ(x) = IFNN(x; θλ)\n(28)\nInstead of training the network with labeled data as in Equation (5), the residual of the PDE is\nconsidered. The residual is evaluated at a set of NN points, called collocation points. Taking the\nmean squared error over the residual evaluations yields the PDE loss\nLN =\n1\n2NN\nNN\nX\ni\n||N[u(xi); λ(xi)]||2\n2 =\n1\n2NN\nNN\nX\ni\n\u0012 d\ndx\n\u0012\nEA(xi)du(xi)\ndx\n\u0013\n+ p(xi)\n\u00132\n.\n(29)\nThe gradients of the possible predictions, i.e., u, EA, and p with respect to x, are obtained with\nautomatic differentiation [210] through the NN approximation. Similarly, the boundary conditions\nare enforced at the NBD + NBN boundary points.\nLB =\n1\n2NND\nNBD\nX\ni\n(u(xi) −g)2 +\n1\n2NBN\nNBN\nX\ni\n\u0012\nEA(xi)du(xi)\ndx\n−f\n\u00132\n(30)\nThe cost function is composed of the PDE loss LN , boundary loss LB, and possibly a data-driven\nloss LD\nC = LN + LB + LD.\n(31)\nBoth the deep least-squares method [211] and the deep Galerkin method [212] are closely related.\nInstead of focusing on the residuals at individual collocation points as in PINNs, these methods\nconsider the L2-norm of the residuals integrated over the domain Ω.\nVariational Physics-Informed Neural Networks\nComputing high-order derivatives for the non-linear operator N is expensive. Therefore, variational\nPINNs [213, 214] consider the weak form of the PDE, which lowers the order of differentiation. In\nthe case of the bar equation, the weak PDE loss is given by\nLV =\nZ\nΩ\ndw(x)\ndx\nEA(x)du(x)\ndx dΩ−\nZ\nΓN\nw(x)EA(x)du(x)\ndx dΓN −\nZ\nΩ\nw(x)p(x)dΩ= 0, ∀w(x).\n(32)\nIn [213], trigonometric and polynomial test functions w(x) are used. The cost function is obtained\nby replacing the PDE loss LN with the weak PDE loss LV in Equation (31).\nNote that the\nNeumann boundary conditions are now not included in the boundary loss LB, as they are already\nincorporated in the weak form in Equation (32). The integrals are evaluated through numerical\nintegration methods, such as Gaussian quadrature, Monte Carlo integration methods [215, 216],\nor sparse grid quadratures [217]. Severe inaccuracies can be introduced through the numerical\nintegration of the NN output – for which remedies have been proposed in [218].\n12\nWeak Adversarial Networks\nInstead of specifying the test functions w(x), weak adversarial networks [219] employ a second NN\nas test function\nˆw(x) = WFNN(x; θw).\n(33)\nThe test function is learned through a minimax optimization\nmin\nθu max\nθw C,\n(34)\nwhere the test function w(x) continually challenges the solution u(x).\nDeep Energy Method & Deep Ritz Method\nBy minimizing the potential energy Π = Πi + Πe instead, the need for test functions is overcome\nby the deep energy method [220] and the deep Ritz method [221]. This results in the following loss\nterm\nLE = Πi + Πe = 1\n2\nZ\nΩ\nEA(x)\n\u0012du(x)\ndx\n\u00132\ndΩ−\nZ\nΓ\nu(x)EA(x)du(x)\ndx dΓ −\nZ\nΩ\nu(x)p(x)dΩ.\n(35)\nNote that the inverse problem generally cannot be solved using the minimization of the potential\nenergy. Consider, for instance, the potential energy of the bar equation in Equation (35), which is\nnot well-posed in the inverse setting. Here, EA(x) going towards −∞in the domain Ωand going\ntowards ∞at ΓN minimizes the potential energy LE.\nExtensions\nA multitude of extensions to the PINN methodology exist. For in-depth reviews, see [204–206].\nLearning Multiple Solutions\nCurrently, PINNs are mainly employed to learn a single solution. As the training effort exceeds the\nsolving effort of classical solvers, the viability of PINNs is questionable [222]. However, PINNs can\nalso be employed to learn multiple solutions. This is achieved by providing the parametrization\nof the PDE, i.e., λ as an additional input to the network, as discussed in Section 2. This enables\na cheap prediction stage without retraining for new solutions12. One possible example for this\nis [223], where different geometries are captured in terms of point clouds and processed with point\ncloud-based NNs [92].\nBoundary Conditions\nThe enforcement of the boundary conditions through a penalty term LB in Equation (30) leads to\nan unbalanced optimization, due to the competing loss terms LN , LB, LD in Equation (31)13. One\nremedy is to modify the NN output FFNN by multiplication of a function, such that the Dirichlet\nboundary conditions are satisfied a priori, i.e., LB = 0, as demonstrated in [224, 20].\nˆu(x) = G(x) + D(x)FFNN(x; θu)\n(36)\nHere, G(x) is a smooth interpolation of the boundary conditions, and D(x) is a signed distance\nfunction that is zero at the boundary. For Neumann boundary conditions, [225] propose to predict\nu and its derivatives ∂u/∂x with separate networks, such that the Neumann boundary conditions\ncan be enforced strongly by modifying the derivative network. This requires an additional con-\nstraint, ensuring that the derivative predictions match the derivative of u. For complex domains,\n12Importantly, the training would be without training data and would only require a definition of the parametrized\nPDE. Currently, this is only possible for simple PDEs with small parameter spaces.\n13Consider, for instance, a training procedure in which the PDE loss LN is first minimal, such that the PDE is\nfulfilled. Without fulfilment of the boundary conditions, the solution is not unique. However, the NN struggles to\nmodify the current boundary values without violating the PDE loss and thereby increasing the total cost function\nC. The NN is thus stuck in a bad local minimum. Similar scenarios can be formulated for a too rapid minimization\nof the other loss terms.\n13\nG(x) and D(x) cannot be found analytically. Therefore, [224] use NNs to learn G(x) and D(x)\nin a supervised manner by prescribing either the boundary values or zero at the boundary and\nrestricting the values within the domain to be non-zero. Similarly [226] proposed using radial basis\nfunction networks for G(x), where D(x) = 1 is assumed. The radial basis function networks are\ndetermined by solving a linear system of equations constructed with the boundary conditions. On\nuniform grids, strong enforcement can be achieved through specialized CNN kernels [185] with\nconstant padding terms for Dirichlet boundary conditions and ghost cells for Neumann boundary\nconditions. Constrained backward propagation [227] has also been proposed to guarantee the en-\nforcement of boundary conditions [228, 229].\nAnother possibility is to introduce weighting terms κN , κB, κD for each loss term. These are either\nhyperparameters, or they are learned during the optimization with attention mechanisms [230–\n232]. This is achieved by performing a minimax optimization with respect to all weighting terms\nκ = {κN , κB, κD}\nmin\nθ max\nκ\nC.\n(37)\nExpanding on this idea, each collocation point used for the loss terms can be considered an individ-\nual equality constraint [233, 234]. Therefore, a weighting term κNi is allocated for each collocation\npoint xi, as illustrated for the PDE loss LN from Equation (29)\nLN =\n1\n2NN\nNN\nX\ni\nκN,i||N[u(xi); λ(xi)]||2\n2.\n(38)\nThis has the added advantage that greater emphasis is assigned on more important collocation\npoints, i.e., points which lead to larger residuals. This approach is strongly related to the ap-\nproaches relying on the augmented Lagrangian method [235] and competitive PINNs [236], where\nan additional NN models the penalty weights κ(x) = KFNN(x; θκ). This is similar to weak adver-\nsarial networks, but instead formulated using the strong form.\nAnsatz\nAnother prominent topic is the question of which ansatz to choose. The type of ansatz is, for\nexample, determined by different NN architectures (see [237] for a comparison) or combinations\nwith classical ansatz formulations. Instead of using FC-NNs, some authors [238, 163] employ CNNs\nto exploit the spatial structure of the data. Irregular geometries can be handled by embedding the\nstructure in a rectangular domain using binary encodings [239] or signed distance functions [61, 240].\nAnother option are coordinate transformations into rectangular grids [241]. The CNN requires a\nfull-grid discretization, meaning that the coordinates x are analytically independent of the predic-\ntion ˆu = FCNN. Thus, the gradients of u are not obtained with automatic differentiation, but\nwith numerical differentiation, i.e., finite differences. Alternatively, the output of the CNN can\nrepresent coefficients of an interpolation, as proposed under the name spline-PINNs [242] using\nHermite splines. This again allows for an automatic differentiation. This is similarly applied for\nirregular geometries in [243], where GNNs are used in combination with a piecewise polynomial\nbasis. Using a classical basis has the added advantage that Dirichlet boundary conditions can be\nsatisfied exactly. A further variation is the approximation of the coefficients of classical bases with\nFC-NNs. This is shown with B-splines in [244] in the sense of isogeometric analysis [245]. This was\nsimilarly done for piecewise polynomials in [246]. However, instead of simply minimizing the PDE\nresidual from Equation (29) directly, the finite element discretization [247, 248] is exploited. The\nloss LF can thus be formulated in terms of the non-linear stiffness matrix K, the force vector F ,\nand the degrees of freedom uh.\nLF = ||K(uh)uh −F ||2\n2\n(39)\nIn the forward problem, uh is approximated by a FC-NN, whereas for the inverse problem a FC-NN\npredicts K. Similarly, [249, 250] map a NN onto a finite element space by using the NN evaluations\nat nodal coordinates as the corresponding basis function coefficents. This also allows a straight-\nforward strong enforcement of Dirichlet boundary conditions, as demonstrated in [54] with CNNs.\n14\nThe nodes are represented as pixels (see Figure 2).\nPrior information on the solution can be incorporated through a feature layer [251]. If, for ex-\nample, it is known that the solution is composed of trigonometric functions, a feature layer with\ntrigonometric functions can be applied after the input layer. Thus, known features are given to the\nNN directly to aid the learning. Without known features, the task can also be modified to improve\nlearning. Inspired by adaptivity from finite elements, refinements are progressively learned by ad-\nditional layers of the NN [252] (see Figure 5). Thus, a coarse solution u1 is learned to begin with,\nthen refined to u2 by an additional layer, which again is refined to u3 until the deepest refinement\nlevel is reached.\nu1\nu2\n1\nu1\n1\nu2\nu3\n2\nu2\n2\nu1\n2\nu3\nu5\n2\nu4\n2\nu3\n2\nu2\n2\nu1\n2\nRefinement\nλ\nu1\n1\nu2\n1\nu1\n3\nu2\n3\nu3\n3\nu4\n3\nu5\n3\nu1\n2\nu2\n2\nu3\n2\nIncreasing Depth\nFigure 5: Refinement expressed with NNs in terms of NN depth. Thick black lines indicate non-\nlearnable connections and gray lines indicate learnable connections. Each added layer is\ncomposed of a projection from the coarser level and a correction obtained through the\nlearnable connection.\nDomain Decomposition\nTo improve the scalability of PINNs to more complex problems, several domain decomposition\nmethods have been proposed. One approach are hp-variational PINNs [214], where the domain is\ndecomposed into patches. Piecewise polynomial test functions are defined on each patch separately,\nwhile the solution is approximated by a globally acting NN. This enables a separate numerical in-\ntegration of each patch, improving its accuracy.\nIn an alternative formulation, one NN can be used per subdomain. This was proposed as conser-\nvative PINNs [253], where conservation laws are enforced at the interface to ensure continuity. Here,\nthe discrepancies between both solution and flux were penalized at the interface in a least squares\nmanner. The advantages of this approach are twofold: Firstly, parallelization is possible [254] and,\nsecondly, adaptivitiy can be introduced. Shallower networks can be employed for smooth solutions\nand deeper networks for more complex solutions. The approach was generalized for any PDE in\nthe context of extended PINNs [255]. Here, the interface condition is formulated in terms of the\ndifference in both the residual and the solution.\nAcceleration Methods\nAnalogously to supervised learning, as discussed in Section 2.1, transfer learning can be applied\nto PINNs [256] as, e.g., demonstrated in phase-field fracture [257] or topology optimization [258].\nThese are very suitable problems since crack and displacement fields evolve with mostly local\nchanges in phase-field fracture. For topology optimization, only minor updates are expected be-\ntween each optimization iteration [258].\nThe poor performance of PINNs in their original form can also be improved with better sampling\n15\nstrategies. In importance sampling [259, 260], the collocation point density is proportional to the\nvalue of the cost function. Alternatively, residual-based adaptive refinement [209] adds collocation\npoints in the vicinity of areas with a higher cost function.\nAnother essential topic for NNs is normalization of the inputs, outputs, and loss terms [261, 262].\nFor time-dependent problems, it is possible to use time-dependent normalization [263] to ensure\nthat the solution is always in the same range regardless of the time step.\nFurthermore, the cost function can be enhanced by including the derivative of the residual [264]\nas well. The derivative should also be minimized, as both the residual and its derivative should be\nzero at the correct solution. However, a general problem in the cost function formulation persists.\nThe cost function should correspond to the norm of the error, which is not necessarily the case.\nThis means that a reduction in the cost does not necessarily yield an improvement in quality of\nsolution. The error norm can be expressed in terms of the H−1-norm, which, according to [265],\ncan efficiently be computed on rectangular domains with Fourier transforms. Thus, the H−1-norm\ncan directly be used as cost function and minimized.\nAnother aspect is numerical differentiation, which is advantageous for the residual of the PDE [266],\nas automatic differentiation may be erroneous due to spurious oscillations between collocation\npoints. Thus, numerical differentiation enforces regularity, which was exploited in [266] by cou-\npling automatic differentiation and numerical differentiation to retain the advantages of automatic\ndifferentiation.\nFurther specialized modifications to NN architectures have been proposed. Adaptive activation\nfunctions [267] have shown acceleration in convergence.\nExtreme learning machines [268, 269]\nremove the need for iterations altogether. All layers are randomly initialized in extreme learning\nmachines, and only the last layer is learnable. Without a non-linear activation function, the param-\neters are found with a least-squares regression. This was demonstrated for PINNs in [270]. Instead\nof only learning the last layer, the problem can be split into a non-linear and a linear regression\nproblem, which are solved separately [271], such that the full expressivity of NNs is retained.\nApplications To Forward Problems\nPINNs have been applied to various PDEs (see [204–206] for an overview). Forward problems can,\nfor example, be found in solid mechanics [261, 272, 273], fluid mechanics [274–281], and thermome-\nchanics [282, 283]. Currently, PINNs do not outperform classical solvers such as the finite element\nmethod [284, 222] in terms of speed for a given accuracy of engineering relevance. In the author’s\nexperience and judgement, this is especially the case for forward problems even if the extensions\nmentioned above are employed. Often, the mentioned gains compared to classical forward solvers\ndisregard the training effort and only report evaluation times.\nIncorporating large parts of the solution in the form of measurements with the data-driven loss\nLD improves the performance of PINNs, which thereby can become a viable method in some cases.\nYet, [285] states that data-driven methods outperform PINNs. Thus PINNs should not be regarded\nas a replacement for data-driven methods, but rather as a regularization technique for data-driven\nmethods to reduce the generalization error.\nApplications To Inverse Problems\nHowever, PINNs are in particular useful for inverse problems with full domain knowledge, i.e., the\nsolution is available throughout the entire domain. This has, for example, been shown for the\nidentification of material properties [286–288, 262, 289]. In contrast, for inverse problems with\nonly partial knowledge, the applicability of PINNs is limited [290], as both forward and inverse\nsolution have to be learned simultaneously. Most applications therefore limit themselves to simpler\n16\ninversions such as size and shape optimization. Examples are published, e.g., in [291, 272, 292–\n296]. Exceptions that deal with the identification of entire fields can be found in full waveform\ninversion [297], topology optimization [298], elasticity, and the heat equation [299].\n2.2.1.2. Inverse Problems\nPINNs are capable of discovering governing equations by either learning the operator N or the\ncoefficients λ. The resulting operator is, however, not always interpretable, and in the case of iden-\ntification of the coefficients, the underlying PDE is assumed. To discover interpretable operators,\none can apply sparse regression approaches [300]. Here, potential differential operators are assumed\nas an input to the non-linear operator\nˆ\nN\n\u0014\nx, u, ∂u\n∂x, ∂2u\n∂x2 , . . .\n\u0015\n= 0.\n(40)\nSubsequently, a NN learns the corresponding coefficients using observed solutions inserted into Equa-\ntion (40). The evaluation of the differential operators is achieved through automatic differentiation\nby first interpolating the solution with a NN. Sparsity is ensured with a L1-regularization.\nA more sophisticated and complete framework is AI-Feynman [301]. Sequentially, dimensional\nanalysis, polynomial regression, and brute force search algorithms are applied to identify funda-\nmental laws in the data. If unsuccessful, a NN interpolates the data, which can thereby be queried\nfor symmetry and separability. The identification of symmetries leads to a reduction in variables,\ni.e., a reduction of the input space. In the case of separability, the problem is decomposed into\ntwo subproblems. The reduced problems or subproblems are iteratively fed through the framework\nuntil an equation is identified. AI-Feynman has been successfully applied to 100 equations from\nthe Feynman lectures [302].\n2.2.2. Time-Stepping Procedures\nAgain Equation (2) and Equation (3) will be considered for the time-stepping procedures.\n2.2.2.1. Physics-Informed Neural Networks\nIn the spirit of domain decomposition, parareal PINNs [303] split up the temporal domain in sub-\ndomains [ti < ti+1]. A rough estimate of the solution u is provided by a conjugate gradient solver\non a simplified form of the PDE starting from t0. PINNs are then independently applied in each\nsubdomain to correct the estimate. Subsequently, the conjugate gradient solver is applied again,\nstarting from t1. This process is repeated until all time steps have been traversed. A closely related\napproach can be found in [304], where a PINN is retrained on successive time segments. It is\nhowever ensured that previous time steps are kept fulfilled through a data-driven loss term for time\nsegments that were already learned.\nAnother approach are the discrete-time PINNs [203], which consider the temporal dimension in a\ndiscrete manner. The differential equation from Equation (2) is discretized with the Runge-Kutta\nmethod with q stages [305]:\nun+ci = un + ∆t\nq\nX\nj=1\naijN[un+cj],\ni = 1, . . . , q,\n(41)\nun+1 = un + ∆t\nq\nX\nj=1\nbjN[un+cj],\n(42)\nwhere\nun+cj(x) = u(tn + cj∆t, x),\nj = 1, . . . , q.\n(43)\nA NN FNN predicts all stages i = 1, . . . , q from an input x:\nˆu = [ˆun+c1(x), . . . , ˆun+cq(x), ˆun+1(x)] = FNN(x; θ).\n(44)\n17\nThe cost is then constructed by rearranging Equations (41) and (42).\nˆun = ˆun\ni = ˆun+ci −∆t\nq\nX\nj=1\naijN[ˆun+cj],\ni = 1, . . . , q,\n(45)\nˆun = ˆun\nq+1 = ˆun+1 −∆t\nq\nX\nj=1\nbjN[ˆun+cj].\n(46)\nThe q + 1 predictions ˆun\ni , ˆun\nq+1 of ˆun have to match the initial conditions uMn, where the mean\nsquared error is used as a loss function to learn all stages ˆu. The approach has been applied to\nfluid mechanics [306, 307].\n2.2.2.2. Inverse Problems\nAs for inverse problems in the space-time approaches (Paragraph 2.2.1.2), the non-linear operator N\ncan be learned. For temporal problems, this corresponds to the right-hand side of Equation (2) for\nPDEs and to Equation (3) for systems of ODEs. The predicted right-hand side can then be used to\npredict time series using a classical time-stepping scheme, as proposed in [308]. More sophisticated\nmethods leaning on similar principles are presented in the following. Specifically, we will discuss\nPDE-Net for discovering PDEs, SINDy for discovering systems of ODEs in an interpretable sense,\nand an approach relying on multistep methods for systems of ODEs. The multistep approach leads\nto a non-interpretable, but more expressive approximation of the right-hand side.\nPDE-Net\nPDE-Net [309, 310] is designed to learn both the system dynamics u(x, t) and the underlying\ndifferential equation it follows. Given a problem of the form of Equation (2), the right-hand side\ncan be approximated as a function of coordinates and gradients of the solution.\nˆ\nN\n\u0014\nx, u, ∂u\n∂x, ∂2u\n∂x2 , . . .\n\u0015\n(47)\nThe operator ˆ\nN is approximated by NNs. The first step involves estimating spatial derivatives\nusing learnable convolutional filters. The filters are designed to adjust their order of approximation\nbased on the fit to the underlying measurements uM, while the type of gradient is predefined14.\nThus, the NN learns how to best approximate spatial derivatives specific to the underlying data.\nSubsequently, the inputs of ˆ\nN are combined with point-wise CNNs [311] in [309] or a symbolic\nnetwork in [310]. Both yield an interpretable operator from which the analytical expression can be\nextracted. In order to construct a loss function, Equations (2) and (47) are discretized using the\nforward Euler method:\nu(x, tn+1) = u(x, tn) + ∆t ˆ\nN\n\u0014\nx, u, ∂u\n∂x, ∂2u\n∂x2 , . . .\n\u0015\n.\n(48)\nThis temporal discretization is applied iteratively, and the discrepancy between the derived function\nand the measured data uM(x, tn) serves as the loss function.\nSINDy\nSparse identification of non-linear dynamic systems (SINDy) [312] deals with the discovery of\ndynamic systems of the form of Equation (3).\nThe task is posed as a sparse regression prob-\nlem. Snapshot matrices of the state X = [x(t1), x(t2), . . . , x(tn)] and its time derivative\n˙X =\n[ ˙x(t1), ˙x(t2), . . . , ˙x(tn)] are related to one another via candidate functions Θ(X) evaluated at X\nusing unknown coefficients Ξ:\n˙X = Θ(X)Ξ.\n(49)\n14This is enforced through constraints using moment matrices of the convolutional filters.\n18\nThe coefficients Ξ are determined through sparse regression, such as sequential thresholded least\nsquares or LASSO regression. By including partial derivatives, SINDy has been extended to the\ndiscovery of PDEs [313, 314].\nThe expressivity of SINDy can further be increased by a coordinate transformation into a rep-\nresentation allowing for a simpler representation of the system dynamics. This can be achieved\nwith an autoencoder (consisting of an encoder eNN(x; θe) and a decoder dNN(h; θd), as proposed\nin [315], where the dynamics are learned on the reduced latent space h using SINDy. A simul-\ntaneous optimization of the NN parameters θe, θd and SINDy parameters Ξ is conducted with\ngradient descent. The cost is defined in terms of the autoencoder reconstruction loss LA and the\nresidual of Equation (49) at both the reduced latent space LR and the original space LF 15. A\nL1-regularization for Ξ promotes sparsity.\nLA = 1\n2n\nn\nX\ni=1\n||x(ti) −dNN\n\u0000eNN(x(ti); θe); θd\u0001\n||2\n2\n(50)\nLR = 1\n2n\nn\nX\ni=1\n||\n\u0010\n∇xeNN\n\u0000x(ti); θe\u0001\u0011\n· ˙x(ti)\n|\n{z\n}\n˙h\n−Θ\n\u0010\neNN\n\u0000x(ti); θe\u0001\u0011\nΞ||2\n2\n(51)\nLF = 1\n2n\nn\nX\ni=1\n|| ˙x(ti) −∇hdNN\n\u0000eNN(x(ti); θe)\n|\n{z\n}\nh\n; θd\u0001\n· Θ\n\u0010\neNN(x(ti); θe)\n\u0011\nΞ\n|\n{z\n}\n˙h\n||2\n2\n(52)\nC = κALA + κRLR + κFLF\n(53)\nAs in Equation (23), a weighted cost function with weights κA, κR, κF is employed. The reduced\nlatent space can be exploited for forward simulations of the identified system. By solving the system\nwith classical time-stepping schemes in the reduced latent space, the solution is obtained in the\nfull space through the decoder, as outlined in [316]. Thus, a reduced order model of a previously\nunknown system is identified. The downside is, that the model is no longer interpretable in the full\nspace.\nMultistep Methods\nAnother approach to learning the system dynamics from Equation (3) is to approximate the right-\nhand side directly with a NN ˆ\nf(xi) = ONN(xi; θ), xi = x(ti). A residual can be formulated by\nconsidering linear multistep methods [305], a residual can be formulated. In general, these methods\ntake the form:\nM\nX\nm=0\n[αmxn−m + ∆tβmf(xn−m)] = 0,\n(54)\nwhere M, α0, α1, β0, β1 are parameters specific to a multistep scheme. The scheme can be reformu-\nlated with a cost function, given as:\nC =\n1\nN −M + 1\nN\nX\nn=M\n||ˆyn||2\n2\n(55)\nˆyn =\nM\nX\nm=0\n[αmxn−m + ∆tβm ˆ\nf(xn−m)]\n(56)\nThe idea of the method is strongly linked to the discrete-time PINN presented in Paragraph 2.2.2.1,\nwhere a reformulation of the Runge-Kutta method yields the cost function needed to learn the\nforward solution.\n15The encoder and decoder are derived with respect to their inputs to estimate the derivatives ˙x, ˙h using the chain\nrule.\n19\n2.2.3. Enforcement Of Physics By Construction\nUp to this point, this review only considered the case where physics are enforced indirectly through\npenalty terms of the PDE residual. The only exception, and the first example of enforcing physics\nby construction, was the strong enforcement of boundary conditions [224, 20, 185] by modifying the\noutputs of the NN – which led to a fulfillment of the boundary conditions independent of the NN\nparameters. For PDEs, this can be achieved by manipulating the output, such that the solution\nautomatically obeys fundamental physical laws. Examples for this are, e.g., given in [317], where\nstream functions are predicted and subsequently differentiated to ensure conservation of mass, the\nincorporation of symmetries [318], or invariances [319] by using integrity bases [320]. Dynami-\ncal systems have been treated by learning the Lagrangian or Hamiltonian with correspondingly\nLagrangian NNs [321–323] and Hamiltonian NNs [324]. The quantities of interest are obtained\nthrough the differentiable NN and compared to labeled data. Indirectly learning the quantities of\ninterest through the Lagrangian or Hamiltonian guarantees the conservation of energy. Enforcing\nthe physics by construction is also referred to as physics-constrained learning, as the learnable\nspace is constrained. More examples hereof are provided in the context of simulation enhancement\nin Section 3.2.\n3. Simulation Enhancement\nThe category of simulation enhancement deals with any deep learning technique that interacts\ndirectly with and, thus, improves a component of a classical simulation. This is the most diverse\ncategory and will therefore be subdivided into the individual steps of a classical simulation pipeline:\n• pre-processing\n• physical modeling\n• numerical methods\n• post-processing\nBoth data-driven and physics-informed approaches will be discussed in the following.\n3.1. Pre-processing\nThe discussed pre-processing methods are trained in a supervised manner relying on the techniques\npresented in Section 2.1 and on labeled data.\n3.1.1. Data Preparation\nData preparation includes tasks, such as geometry extraction. For instance the detection of cracks\nfrom images by means of segmentation [325–327] can subsequently be used in simulations to assess\nthe impact of the identified cracks. Also, CNNs have been used to prepare voxel data obtained from\ncomputed tomography scans, see [328], where scanning artifacts are removed. Similarly NNs can\nbe employed to enhance measurement data. This was, for example, demonstrated in [329], where\nthe NN acts as a denoiser for magnetic signals in the scope of non-destructive testing. Similarly,\nlow-frequency extrapolation for full waveform inversion has been performed using NNs [330–332].\n3.1.2. Initialization\nInstead of preparing the data, the simulation can be accelerated by an initialization. This can,\nfor example, be achieved through initial guesses by NNs, providing a better starting point for\nclassical iterative solvers [333]16. A tighter integration is achieved by using a pre-trained [256] NN\nansatz whose parameters are subsequently tweaked by the classical solver, as demonstrated for full\nwaveform inversion in [161].\n16Here, the initial guess is incorporated through a regularization term.\n20\n3.1.3. Meshing\nFinally, many simulation techniques rely on meshes. This can be achieved indirectly with NNs,\nby prediction of mesh density functions [334–338] incorporating either expert knowledge of where\nsmall elements are needed, or relying on error estimations. Subsequently, a classical mesh generator\nis employed. However, NNs (specifically let-it-grow NNs [339]) have also been proposed directly as\nmesh generators [340, 341].\n3.2. Physical Modeling\nPhysical models that capture physical phenomena accurately are a core component of mechanics.\nDeep learning offers three main approaches for physical models. Firstly, a NN is used as the phys-\nical model directly (model substitution). Secondly, an underlying model may be assumed where a\nNN determines its coefficients (identification of model parameters). Lastly, the entire model can\nbe identified by a NN (model identification). In the first approach, the NN is integrated within the\nsimulation pipeline, while the latter two rely on incorporation of the identified models in a classical\nsense.\nFor illustration purposes, the approaches are mostly explained on the example of constitutive\nmodels. Here, the task is to relate the strain ε to a stress σ, i.e., find a function σ = f(ε). This\ncan, for example, be used within a finite element framework to determine the element stiffness, as\nelaborated in [342].\n3.2.1. Model Substitution\nIn model substitution, a NN fNN replaces the model, yielding the prediction ˆσ = fNN(ε; θ). The\nquality of the model is assessed with a data-driven cost function (Equation (4)) using labeled data\nσM, εM. The approach is applied to a variety of problems, where the key difference lies in the\ndefinition of input and output quantities. The same deep learning techniques from data-driven\nsimulation substitution (Section 2.1) can be employed.\nApplications include predictions of stress from strain [342, 343], flow stresses from temperatures,\nstrain rates and strains [344, 345], yield functions [346], crack opening responses from stresses [347],\ncontact stiffness from penetration and contact pressure [348], point of contact from position of neigh-\nboring nodes of finite elements [349], or control points of NURBS surfaces [350]. Source terms of\nsimplified equations or coarser discretizations have also been learned for turbulence [49, 351, 352]\nand the wave equation [353]. Here, the reference – a high-fidelity model – is to be captured in the\nbest possible way by the source term.\nVariations also predict the quantity of interest indirectly. For example, strain energy densities\nψ are predicted by NNs from deformation tensors F, and subsequently derived using automatic\ndifferentiation to obtain stresses [354, 355]. The approach can also be extended to incorporate\nuncertainty quantification [356]. By extending the input space with microstructural information,\nan in-built homogenization is added to the constitutive model [357–359]. Thus, the macroscale\nsimulation considers the microstructure at the integration points in the sense of FE2 [360, 361],\nbut without an additional finite element computation. Incorporation of microstructures requires a\nlarge amount of realistic training data, which can be obtained through generative approaches as\ndiscussed in Section 5. Active learning can reduce the required number of simulations on these\ngeometries [158].\nA specialized NN architecture is employed by [362], where a NN first estimates invariants I of\nthe deformation tensor F and thereupon predicts the strain energy density, thus mimicking the\nclassical constitutive modeling approach. Another network extension is the use of RNNs to learn\nhistory-dependent models. This was shown in [357, 358, 363, 364] for the prediction of the stress\nincrement from the strain-stress history, the strain energy from the strain energy history [365], and\n21\ncrack patterns based on prior cracks and crystalline orientations [366, 367].\nThe learned models do not, however, necessarily obey fundamental physical laws. Attempts to\nincorporate physics as constraints using penalty terms have been made in [368–370]. Still, physical\nconsistency is not guaranteed. Instead, NN architectures can be chosen such that they satisfy phys-\nical requirements by construction. In constitutive modeling, objectivity can be enforced by using\nonly deformation invariants as input [371], and polyconvexity can be enforced through the archi-\ntecture, such as input-convex NNs [372–375] and neural ordinary differential equations [371, 376].\nIt was demonstrated that ensuring fundamental physical aspects such as invariants combined with\npolyconvexivity delivers a much better behavior for unseen data, especially if the model is used in\nextrapolation.\nInput-convex NNs [377] enforce the convexity with specialized activation functions such as log-\nsum-exponential, or softplus functions in combination with constraints on the NN weights to ensure\nthat they are positive, while neural ordinary differential equations [378] (discussed in Section 4)\napproximate the strain energy density derivatives and ensure non-negative values. Alternatively,\na mapping from the NN to a convex function can be defined [379] ensuring a convex function for\nany NN output. Related are also thermodynamics-based NNs [380, 381], e.g., applied to complex\nmicrostructures in [382], which by construction obey fundamental thermodynamic laws. Training\nof these methods can be performed in a supervised manner, relying on strain-stress data, or un-\nsupervised. In the unsupervised setting, the constitutive model is incorporated in a finite element\nsolver, yielding a displacement field for a specific boundary value problem. The computed field,\ntogether with measurement data, yields a residual that is referred to as the modified constitutive\nrelation error (mCRE) [383–385], which is minimized to improve the constitutive relation [386, 387].\nInstead of formulating the mismatch in terms of displacements, [388, 389] formulate it in terms\nof boundary forces. For an in-depth overview of constitutive model substitution in deep learning,\nsee [15].\n3.2.2. Identification Of Model Parameters\nIdentification of model parameters is achieved by assuming an underlying model and training a NN\nto predict its parameters for a given input. In the constitutive model example, one might assume a\nlinear elastic model expressed in terms of a constitutive tensor c, such that σ = cε. The constitutive\ntensor can be predicted from the material distribution defined in terms of a heterogeneous elasticity\nmodulus E defined throughout the domain\nˆc = fNN(E; θ).\n(57)\nTypical applications are homogenization, where effective properties are predicted from the ge-\nometry and material distribution. Examples are CNN-based homogenizations on computed to-\nmography scans [390, 391], predictions of in-vivo constitutive parameters of aortic walls from its\ngeometry [392], predictions of elastoplastic properties [393] from instrumented indentation results\nrelying on a multi-fidelity approach [394], prediction of stress intensity factors from the geometry in\nmicrofabricated microcantilevers [395], estimation of effective bone properties from the boundary\nconditions and applied stresses within a finite element, and incorporating meso-scale information\nby training a NN on representative volume elements [396].\n3.2.3. Model Identification\nNN models as a replacement of classical approaches are not interpretable, while only identifying\nmodel parameters of known models restricts the models capacity. This gap can be bridged by the\nidentification of models in terms of parsimonious mathematical expressions.\nThe typical procedure is to pose the problem in terms of candidate functions and to identify\nthe most relevant terms. The methodology was inspired by SINDy [312] and introduced in the\nframework for efficient unsupervised constitutive law identification and discovery (EUCLID) [397].\n22\nThe approach is unsupervised, as the stress-strain data is only indirectly available through the\ndisplacement field and corresponding reaction forces. The NI invariants Ii of the deformation tensor\nF are inserted into a candidate library Q({Ii}NI\ni=1) containing the candidate functions. Together\nwith the corresponding weights θ, the strain density ψ is determined:\nψ({Ii}NI\ni=1) = QT ({Ii}NI\ni=1)θ.\n(58)\nThrough derivation of the strain density ψ using automatic differentiation, the stresses σ are\ndetermined. The problem is then cast into the weak form with which the linear momentum balance\nis enforced. The weak form is then minimized with respect to θ using a fixed-point iteration scheme\n(inspired by [398]), where a Lp-regularization is used to promote sparsity in θ. Despite its young age,\nthe approach has already been applied to plasticity [399], viscoelasticity [400], combinations [401],\nand has been extended to incorporate uncertainties through a Bayesian model [402]. Furthermore,\nthe approach has been extended with an ensemble of input-convex NNs [389], yielding a more\naccurate, but less interpretable model.\nA similar effort was recently carried out by [403, 404], where NNs are designed to retain inter-\npretability. This is achieved through sparse connections in combination with specialized activation\nfunctions representing candidate functions, such that they are able to capture classical forms of\nconstitutive terms. Through the sparse connections in the network and the specialized activation\nfunctions, the NN’s weights become physical parameters, yielding an interpretable model. This is\nbest understood by consulting Figure 6, where the strain energy density is expressed as\nˆψ = θ1\n0eθ0\n0I1 + θ1\n1 ln(θ0\n1I1) + θ1\n2eθ0\n2I2\n1 + θ1\n2 ln(θ0\n2I2\n1) + θ1\n3eθ0\n3I2 + θ1\n4 ln(θ0\n4I2) + θ1\n5eθ0\n5I2\n2 + θ1\n6 ln(θ0\n6I2\n2). (59)\nDifferentiating the predicted strain energy density ˆψ with respect to the invariants Ii yields the\nconstitutive model, relating stress and strain.\nF\nI1\nI2\n(·)1\n(·)2\n(·)1\n(·)2\ne(·)\nln(·)\ne(·)\nln(·)\ne(·)\nln(·)\ne(·)\nln(·)\nψ\nθ0\nθ1\nFigure 6: Automated model discovery through a sparsely connected NN with specialized activation\nfunctions acting as candidate functions. The thick black connections are not learnable,\nwhile the gray ones represent linearly weighted connections. Figure adapted and simplified\nfrom [403].\n3.3. Numerical Methods\nThis subsection describes efforts in which NNs are used to replace or enhance classical numerical\nschemes to solve PDEs.\n23\n3.3.1. Algorithm Enhancement\nClassical algorithms can be enhanced by NNs, by learning corrections to commonly arising nu-\nmerical errors, or by estimating tunable parameters within the algorithm. Corrections have, for\nexample, been used for numerical quadrature [405] in the context of finite elements. Therein, NNs\nare used to predict adjustments to quadrature weights and positions from the nodal positions to\nimprove the accuracy for distorted elements. Similarly, NNs have been applied as correction for\nstrain-displacement matrices for distorted elements [406]. NNs have also been employed to provide\nimproved gradient estimates. Specifically, [407] modify the gradient computation to match a fine\nscale simulation on a coarse grid:\n∂nu\n∂xn ≈\nX\ni\nα(n)\ni\nui.\n(60)\nThe coefficients αi are predicted by NNs from the current coarse solution. Special constraints are\nimposed on αi to guarantee accurate derivatives. Another application are specialized strain map-\npings for damage mechanics embedded within individual finite elements learned by PINNs [408].\nIt has even been suggested to partially replace solvers. For example, [409] replace either the fluid\nor structural solver by a surrogate model for fluid-structure interaction problems.\nLearning tunable parameters was demonstrated for the estimation of the largest possible time\nstep using a RNN acting at the latent vector of an autoencoder [410]. Also, optimal test functions\nfor finite elements were learned to improve stability [411].\n3.3.2. Multiscale Methods\nMultiscale methods have been proposed to efficiently integrate and resolve systems acting on mul-\ntiple scales. One approach are the learned constitutive models from Section 3.2 that incorporate\nthe microstructure. This is essentially achieved through a homogenization at the mesoscale used\nwithin a macroscale simulation.\nA related approach is element substructuring [412, 413], where superelements mimic the behav-\nior of a conglomerate of classic basic finite elements. In [414], the superelements are enhanced by\nNNs, which draw on the boundary displacements to predict the displacements and stresses within\nthe element as well as the reaction forces at the boundary.\nThrough assembly of the reaction\nforces in the global finite element system, an equilibrium is reached with a Newton-Raphson solver.\nSimilarly, the approach in [415] learns the internal forces from the coarse degrees of freedom of\nthe superelements. These approaches are particularly valuable, as they can seamlessly incorporate\nhistory-dependent behavior using RNNs.\nFinally, multiscale analysis can also be performed by first solving a coarse global model with\na subsequent local analysis. This is referred to as zooming methods. In [416], a NN learns the\nglobal model and thereby predicts the boundary conditions for the local model. In a similar sense,\nDeepONets have been applied for the local analysis [417], whereas the global analysis is performed\nwith a finite element solver. Both are conducted in an alternating fashion until convergence is\nreached.\n3.3.3. Optimization\nOptimization is a fundamental task within computational mechanics and therefore addressed sepa-\nrately. It is not only used to find optimal structures, but also to solve inverse problems. Generally,\nthe task can be formulated as minimizing a cost function C with respect to parameters λ. In\ncomputational mechanics, λ is typically fed to a forward simulation u = F(λ), yielding a solution\nu inserted into the cost function C. If the gradients ∇λC are available, gradient-based optimiza-\ntion is the state-of-the-art [418], where the gradients are used to update λ. In order to access the\ngradients, the forward simulation F has to be differentiable. This requirement is, for example,\nutilized within the branch of deep learning called differentiable physics [19]. Incorporating gradient\n24\ninformation from the numerical solver into the NN improves learning, feedback, and generaliza-\ntion. An overview and introduction to differentiable physics is provided in [19], with applications\nin [197, 407, 378, 419–421]17.\nThe iterative gradient-based optimization procedure is illustrated in Figure 7. For an in-depth\ntreatment of NNs in optimization, see the recent review [5].\nλ\nF(λ)\nu\nC(u)\n∇λC\nFigure 7: Gradient-based optimization.\nInserting a learned forward operator F, as those discussed in Section 2.1, into an optimization\nproblem provides two advantages [422–426]. Firstly, a faster forward operator results in faster op-\ntimization iterations. Secondly, the gradient computation is simplified, as automatic differentiation\nthrough the forward operator F is straightforward in contrast to the adjoint state method [427, 428].\nNote however, that for time-stepping procedures, the computational cost might be greater for auto-\nmatic differentiation, as shown in [290]. Applications include full waveform inversion [290], topology\noptimization [429–431], and control problems [47, 45, 419].\nSimilarly, an operator replacing the sensitivity computation can be learned [432–434, 431].\nThis can be achieved in a supervised manner with precomputed sensitivities to reduce the cost\nC [433, 431], or by intending to maximize the improvement of the cost function after the gradient\nupdate [432, 434]. In [432, 434], an evolutionary algorithm was employed for the general case that\nthe sensitivites are not readily available. Training can adaptively be reintroduced during the opti-\nmization phase, if the cost C does not decrease [431], improving the NN for the specific problem\nit is handling. Taking this idea to the extreme, the NN is trained on the initial gradient updates\nof a specific optimization. Later, solely the NN delivers the sensitivities [435] with supervised up-\ndates every n updates to improve accuracy, where n is a hyperparameter. The ideas of learning a\nforward operator and a sensitivity operator are combined in [430], where it is pointed out that the\nsensitivity from automatic differentiation through the learned forward operator can be inaccurate,\ndespite an accurate forward operator18. Therefore, an additional loss term is added to the cost\nfunction, enforcing the correctness of the sensitivity through labels obtained with the adjoint state\nmethod. Alternatively, the sensitivity computation can be enhanced by correcting the sensitivity\ncomputation performed on a coarse grid, as proposed in [436] and related to the multiscale tech-\nniques discussed in Section 3.3.2. Here, the adjoint field used for the sensitivity computation is\nreduced by both a proper orthogonal decomposition, and a coarser discretization. Subsequently, a\nNN corrects the coarse estimate through a super-resolution NN [437]. Similarly, [431, 438] maps\nthe forward solution on a coarse grid to the design variable sensitivity on a fine grid. A similar\napplication is a correction term within a fixed-point iterator, as outlined in [439].\nRelated to the sensitivity predictions are approaches that directly predict an updated state. The\ngoal is to decrease the total number of iterations. In practice, a combination of predictions and\nclassical gradient-based updates is performed [86, 88, 87, 440]. The main variations between the\nmethods in the literature are the inputs and how far the forecasting is performed. In [86], the\nupdate is obtained from the current state and gradient, while [88] predicts the final state from the\nhistory of initial updates. The history is also considered in [87], but the prediction is performed on\nsubpatches which are then stitched together.\n17Applications of differentiable physics vary widely and are addressed throughout this work.\n18Although automatic differentiation in principle has a high accuracy, oscillations between the sampled points may\nlead to spurious gradients with regard to the sampled points [218].\n25\nAnother option of introducing NNs to the optimization loop is to use NNs as an ansatz of λ, see\ne.g. [441, 442, 419, 443–449, 290]. In the context of inverse problems [441, 442, 419, 443–445, 290],\nthe NN acts as regularizer on a spatially varying inverse quantity λ(x) = INN(x; θ), providing\nboth smoother and sharper solutions. For topology optimization with a NN parametrization of the\ndensity function [446–449], no regularizing effect was observed. It was however possible to obtain a\ngreater design diversity through different initializations of the NN. Extensions using specialized NN\narchitectures for implicit representations [450–455] have been presented in the context of topology\noptimization in [456]. Furthermore, [443, 447, 290] showed how to conduct the gradient computation\nwithout automatic differentiation through the solver F. The gradient computation is split up via\nthe chain rule:\n∇θC = ∇λC · ∇θλ.\n(61)\nThe first gradient ∇λC is computed with the adjoint state method, such that the solver can be\ntreated as a black box. The second gradient ∇θλ is obtained through automatic differentiation.\nAn additional advantage of the NN ansatz is that, if applied to multiple solutions with a problem\nspecific input, the NN is trained. Thus, after sufficient inversions, the NN can be used as predictor,\nas presented in [457]. The training can also be performed in combination with labeled data, yielding\na semi-supervised approach, as demonstrated in [458, 161].\n3.4. Post-Processing\nPost-processing concerns the modification and interpretation of the computed solution. One mo-\ntivation is to reduce the numerical error of the computed solution.\nThis can for example be\nachieved with super-resolution techniques relying on specialized CNN architectures from computer\nvision [459, 460]. Coarse to fine mappings can be obtained in a supervised manner using matching\ncoarse and fine simulations as labeled data, as presented for turbulent flows [461, 437] and topology\noptimization [462–464]. The mapping is typically performed from coarse to fine solution fields, but\nmappings from a posteriori errors have been proposed as well [465]. Further specialized extensions\nto the cost function have been suggested in the context of de-homogenization [466].\nThe methods can analogously be applied to temporal data where the solution is refined at each\ntime step, – as, e.g., presented with RNNs as corrector of reduced order models [467]. However,\ncoarse discretizations in dynamical models lead to an error accumulation, that increases with the\nnumber of time steps. Thus, a simple coarse-to-fine post-processing at each time step is not suffi-\ncient. To this end, [420, 421] apply a correction at each time step before the coarse solver predicts\nthe next time step. As the correction is propagated through the solver, the sensitivities of the\nsolver must be computed to perform the backward propagation. Therefore, a differentiable solver\n(i.e., differentiable physics) has to be employed. This significantly outperforms the purely super-\nvised approach, where the entire coarse trajectory is applied without corrections in between. The\nnumber of steps performed is a hyperparameter, which increases the accuracy but comes with a\nhigher computational effort. This concept is referred to as solver-in-the-loop.\nFurther variations perform the coarse-to-fine mapping in a patch-based manner, where the in-\nterfaces require a special treatment [468]. Another approach uses a NN to map the coarse solution\nto the closest fine solution stored in a database [469]. The mapping is performed on patches of the\ndomain.\nOther post-processing tasks include feature extraction. After a topology optimization, NNs have\nbeen used to extract basic shapes to be used in a subsequent shape optimization [470, 471]. Another\naspect that can be ensured through post-processing is manufacturability.\nLastly, adaptive mesh refinement falls under the category of post-processing as well. Closely\nrelated to the meshing approaches discussed in Section 3.1.3, NNs have been proposed as error\nindicators [472, 337] that are trained in a supervised manner. The error estimators can subsequently\nbe employed to adapt the mesh based on the error.\n26\n4. Discretizations As Neural Networks\nNNs are composed of linear transformations and non-linear functions, which are basic building\nblocks of most PDE discretizations. Thus, the motivation to utilize NNs to construct discretizations\nof PDEs herefore are twofold. Firstly, deep learning techniques can hereby be exploited within\nclassical discretization frameworks. Secondly, novel NN architectures arise, which are more tailored\ntowards many physical problems in computational mechanics but also find their use cases outside\nof that field.\n4.1. Finite Element Method\nOne method are finite element NNs [473, 474] (see [475–480] for applications), for which we consider\nthe system of equations from a finite element discretization with the stiffness matrix Kij, degrees\nof freedom uj, and the body load bi:\nN\nX\nj=1\nKijuj −bi = 0, i = 1, 2, . . . , N.\n(62)\nAssuming constant material properties along an element and uniform elements, a pre-integration\nof the local stiffness matrix ke\nij = αewe\nij can be performed, as, e.g., shown in [481]. The goal is to\npull out the material coefficients of the integration, leading to the following assembly of the global\nstiffness matrix:\nKij =\nM\nX\ne=1\nαeW e\nij with W e\nij =\n(\nwe\nij if i, j ∈e\n0 else\n.\n(63)\nInserting the assembly into the system of equations from equation (62) yields\nN\nX\nj=1\n M\nX\ne=1\nαeW e\nij\n!\nuj −bi = 0, i = 1, 2, . . . , N.\n(64)\nThe nested summation has a similar structure of a FC-NN, a(l)\ni\n= σ(z(l)\ni ) = σ(PN (l)\nj=1 a(l−1)\nj\n+ b(l)\ni )\nwithout activation and bias (see Figure 8):\na(2)\ni\n=\nN (2)\nX\nj=1\nW (1)\nij a(1)\nj\n=\nN (2)\nX\nj=1\nW (1)\nij (\nN (1)\nX\nk=1\nW (0)\njk a(0)\nk ).\n(65)\nThus, the stiffness matrix Kij is the hidden layer. In a forward problem, W e\nij are non-learnable\nweights, while uj contains a mixture of learnable weights and non-learnable weights coming from the\nimposed Dirichlet boundary conditions. A loss can be formulated in terms of body load mismatch,\nas 1\n2\nPN\ni=1(ˆbi −bi)2. In the inverse setting, αe becomes learnable – instead of uj, which is then\nfixed. For partial domain knowledge in the inverse case, uj becomes partially learnable.\nαe\nKij\nbi\nW e\nij\nuj\nFigure 8: Finite element NNs, prediction of forces bi from material coefficients αe via assembly of\nglobal stiffness matrix Kij, and evaluations of equations with the displacements uj [474].\nA different approach are the hierarchical deep-learning NNs (HiDeNNs) [482] with extensions\nin [483–488]. Here, shape functions are treated as NNs constructed from basic building blocks.\nConsider, for example, the one-dimensional linear shape functions\nN1(x) = x −xe\n2\nxe\n1 −xe\n2\n(66)\nN2(x) = x −xe\n1\nxe\n2 −xe\n1\n,\n(67)\n27\nwhich can be represented as a NN, as shown in Figure 9, where the weights depend on the nodal\npositions xe\n1, xe\n2. The interpolated displacement field ue, which is valid in the element domain Ωe,\nis obtained by multiplication with the nodal displacements ue\n1, ue\n2, treated as shared NN weights.\nue = Ne\n1(x)ue\n1 + Ne\n2(x)ue\n2\n(68)\nThey are shared, as the nodal displacements ue\n1, ue\n2 are also used for the neighboring elements\nue−1, ue+1. Finally the displacement over the entire domain u is obtained by superposition of all\nelemental displacement fields ue, which are first multiplied by a step function defined as 1 inside\nthe corresponding element domain Ωe and 0 outside.\nA forward problem is solved with a minimization of the variational loss function, as presented\nin Section 3.2 with the nodal values ue\ni as learnable weights. According to [482], this is equivalent to\niterative solution procedures in finite elements. The additional advantage is a seamless integration\nof r-refinement, i.e., the shift of nodal positions to optimal positions by making the nodal positions\nxe\ni learnable. Special care has to be taken to avoid element inversion, which is handled by an\nadditional term in the loss function. Inverse problems can similarly be solved by using learnable\ninput parameters, as presented for topology optimization [488].\nThe method has been combined with reduced order modeling techniques [484]. Furthermore, the\nshape functions have been extended with convolutions [486, 487]. Specifically, a second weighting\nfield W(x) is introduced to enhance the finite element space uc(x) through convolutions:\nuc(x) = ue(x) ∗W(x).\n(69)\nThis introduces a smoothing effect over the elements and can efficiently be implemented using CNNs\nand, thereby, obtain a more favorable data-structure to exploit the full parallelization capabilities\nof GPUs [487].\nThe enhanced space has been incorporated in the HiDeNN framework.\nWhile\nan independent confirmation is still missing, the authors promise a speedup of several orders of\nmagnitude compared to traditional finite element solvers [488].\nx\nue−1\nue, Ωe\nue+1\nue\n1, xe\n1\nue\n2, xe\n2\n(a) One-dimensional linear elements with two nodes each.\nx\nx −xe\n2\nNe\n1(x) = x−xe\n2\nxe\n1−xe\n2\nx −xe\n1\nNe\n2(x) = x−xe\n1\nxe\n2−xe\n1\nue\nue−1\nue+1\nu\n1\n1\nb = −xe\n2\nb = −xe\n1\n1\nxe\n1−xe\n2\n1\nxe\n2−xe\n1\nue\n1\nue\n2\nrestrict\nto Ωe\n(b) HiDeNN.\nFigure 9: HiDeNN with one-dimensional linear elements [482].\nAnother approach related to finite elements was presented as FEA-net [489, 490]. Here, the\nmatrix-vector multiplication of the global stiffness matrix K and solution vector u including the\nassembly of the global stiffness matrix is replaced by a convolution. In other words, the computation\nof the force vector f is used to compute the residual r.\nr = f −K · u\n(70)\n28\nAssuming a uniform mesh with homogeneous material properties, the mesh is defined by the seg-\nment illustrated in Figure 10. The degree of freedom uj only interacts with the stiffness contribu-\ntions K1\ni , K2\ni , K1\ni+1, K2\ni+1 of its neighboring elements i and i + 1. Therefore, the force component\nfj acting on node j can be expressed by a convolution:\nfj = [K1\ni , K2\ni + K1\ni+1, K2\ni+1] ∗[Uj−1, Uj, Uj+1]\n(71)\nThis can analogously be applied to all degrees of freedoms, with the same convolution filter W =\n[K1, K1 + K2, K2], assuming the same stiffness contributions for each element.\nK · u = W ∗U\n(72)\nThe convolution can then be exploited in iterative schemes which minimize the residual r from Equa-\ntion (70). This saves the effort of constructing and storing the global stiffness matrix. By construct-\ning the filter W as a function of the material properties of the adjacent elements, heterogeneities\ncan be taken into account [490].\nIf the same iterative solver is employed, FEA-Net is able to\noutperform classical finite elements for non-linear problems on uniform grids.\nuj−1\nuj\nuj+1\nelement i\nelement i + 1. . .\n. . .\nK1\ni\nK2\ni\nelement i\nFigure 10: Segment of one-dimensional finite element mesh with degrees of freedom (left). Local\nelement definition with stiffness contributions (right).\n4.2. Finite Difference Method\nSimilar ideas have been proposed for finite differences [491], as employed in [290], for example, where\nconvolutional kernels are used as an implementation of stencils exploiting the efficient NN libraries\nwith GPU capabilities.\nHere, the learnable parameters can be the finite difference stencil for\ninverse problems or the output for forward problems. This has, for example, been presented in the\ncontext of full waveform inversion, which is modeled as a RNN [492, 493]. The stencils are written as\nconvolutional filters and repeatedly applied to the current state and the corresponding inputs. These\nare the wave field, the material distribution, and the source. The problem can then be regarded as\na RNN. However, it is computationally expensive to perform automatic differentiation throughout\nthe time steps for full waveform inversion, thereby obtaining the sensitivities with respect to γ –\nboth regarding memory and wall clock computational time. A remedy is to combine automatic\ndifferentiation with the adjoint state method as in [447, 443, 290] and discussed in Section 3.3.3.\nTaking this idea one step further, the discretized wave equation can be regarded as an analog\nRNN [494] where the weights are the material distribution. Here, a binary material is learned in\na trainable region between source and probing location. The input x(t) is encoded as a signal and\nemitted as source, which is measured at the probing locations yi(t) as output. By integrating the\noutputs, a classification of the input can be performed.\n4.3. Material Discretizations\nDeep material networks [495, 496] construct a NN from a material distribution.\nAn output is\nconstructed from basic building blocks, inspired by analytical homogenization techniques. Given\ntwo materials defined in terms of their compliance tensors c1, c2, and volume fractions f1, f2, an\nanalytical effective compliance tensor ¯c is computed. The effective tensor is subsequently rotated\nwith a rotation tensor R, defined in terms of the three rotation angles α, β, γ, yielding a rotated\neffective tensor ¯cr.\nThus, the building block takes as input two compliance tensors c1, c2 and\noutputs a rotated effective compliance tensor ¯cr, where f1, f2, α, β, γ are the learnable parameters\n(see Figure 12). By connecting these building blocks, a large network can be created. The network\nis applied to homogenization tasks of RVEs [495, 496], where the material of the phases is varied\nduring evaluation.\n29\ny3 =\nR\nt u1(t)dt\ny2 =\nR\nt u2(t)dt\ny1 =\nR\nt u3(t)dt\nx(t)\nInput as\nSignal\nProbe Locations\nTrainable Region\nSource Location\nIntegrated Signals\nas Output\nFigure 11: Analog RNN.\nf1\nf2\nHomogenization\n¯c\nRotation\nR(α, β, γ)\n¯cr\nc1\nc2\nFigure 12: A single building block of the deep material network [495].\n4.4. Neural Differential Equations\nIn a more general setting, neural ordinary differential equations [378] consider the forward Euler\ndiscretization of ordinary differential equations. Specifically, RNNs are viewed as Euler discretiza-\ntions of continuous transformations [497–499]. Consider the iterative update rule of the hidden\nstates yt+1 = y(t + ∆t) of a RNN.\nyt+1 = yt + f(yt; θ)\n(73)\nHere, f is the evaluation of one recurrent unit in the RNN. In the limit of the time step size\nlim ∆t →0, the dynamics of the hidden units yt can be parametrized by an ordinary differential\nequation\ndy(t)\ndt\n= f(y(t), t; θ)\n(74)\nThe input to the network is the initial condition y(0), and the output is the solution y(T) at time\nT. The output of the NN, y(T), is obtained by solving Equation (74) with a differential equa-\ntion solver. The sensitivity computation for the weight update is obtained using the adjoint state\nmethod [500, 428], as backpropagating through each time step of the solver leads to a high memory\ncost. This also makes it possible to treat the solver as a black box. Similar extensions to PDEs [498]\nhave been proposed by considering recurrent CNNs with residual connections, where the CNNs act\nas spatial gradients.\nSimilarly, [501] establish a connection between deep residual RNNs and iterative solvers. Residual\nconnections in NNs allow information to bypass NN layers. Consider the estimation of the next\nstate of a PDE with a classical solver ut+1 = u(t + ∆t) = F[u(t)]. The residual rt+1 = r(t + ∆t) is\ndetermined in terms of the ground truth uM\nt+1:\nrt+1 = uM\nt+1 −ut+1.\n(75)\nAn iterative correction scheme is formulated with a NN. The iterations are indicated with the\nsuperindex (k).\nu(k+1)\nt+1\n= u(k)\nt+1 + fNN(r(k+1)\nt+1\n; θ)\n(76)\nr(k+1)\nt+1\n= uM\nt+1 −u(k)\nt+1\n(77)\n30\nNote that the residual connection, i.e., u(k)\nt+1 as directly used in the prediction of u(k+1)\nt+1 , allows\ninformation to pass past the recurrent unit fNN. A related approach can be found in [502], where\nan autoencoder iteratively acts on a solution until convergence. In the first iteration, a random\ninitial solution is used as input.\n5. Generative Approaches\nGenerative approaches (see [16] for an in-depth review in the field of design and [503] for a hands-on\ntextbook) aim to model the underlying probability distribution of a data set to generate new data\nthat resembles the training data. Three main methodologies exist:\n• autoencoders,\n• generative adversarial networks (GANs),\n• diffusion models.\nCurrently, there are two prominent areas of application in computational mechanics. One area of\nfocus is microstructure generation (Section 5.4.1), which aims to produce a sufficient quantity of\nrealistic training data for surrogate models, as described in Section 2.1. The second key application\narea is generative design (Section 5.4.2), which relies on algorithms to efficiently explore the design\nspace within the constraints established by the designer.\n5.1. Autoencoders\nAutoencoders facilitate data generation by mapping high-dimensional training data {xi}N\ni=1 to a\nlower-dimensional latent space {hi}N\ni=1 which can be sampled efficiently. Specifically, an encoder\nˆh = ENN(x; θe) transforms an input sample x to a reduced latent vector ˆh. A corresponding\ndecoder ˆx = DNN(ˆh; θd) reconstructs the original sample x from this latent vector ˆh. As mentioned\nin Paragraph 2.1.1.3, the encoder can serve as a tool for dimensionality reduction, whereas the\ndecoder, within the scope of generative approaches, operates as a generator. By emulating the\nprobability distribution of the latent space {ˆhi}N\ni=1, variational autoencoders [504, 505] are able to\ngenerate new data that resembles the training data.\n5.2. Generative Adversarial Networks\nGANs [506] emulate data distributions by setting up a two-player adversarial game between two\nNNs:\n• the generator GNN,\n• the discriminator DNN.\nThe generator creates predictions ˆy = GNN(ξ; θG) from random noise ξ, while the discriminator\nattempts to distinguish between these generated predictions ˆy from real data yM. The discrimi-\nnator assigns a probability score ˆp = DNN(y; θD) which evaluates the likelihood of a datapoint y\nbeing real or generated. The quality of both the generator and the discriminator can be expressed\nvia the following cost function:\nC =\n1\nND\nND\nX\ni=1\nlog\nh\nDNN(yi; θD)\ni\n+\n1\nNG\nNG\nX\ni=1\nlog\nh\n1 −DNN\n\u0000GNN(ξi; θG); θD\n\u0001i\n.\n(78)\nHere, ND real samples and NG generated samples are used for training. The goal for the generator\nis to minimize the cost function, implying that the discriminator fails to distinguish between real\nand generated samples. However, the discriminator strives to maximize the cost. Therefore, this\nis formulated as a minimax optimization problem\nmin\nθG max\nθD C.\n(79)\n31\nConvergence is ideally reached at the Nash equilibrium [507], where the discriminator always out-\nputs a probability of 1/2, signifying its inability to distinguish between real and generated samples.\nHowever, GANs can be challenging to train. Problems like mode collapse [508] can arise. Here, the\ngenerator learns only a few modes from the training data. In the extreme case, only a single sample\nfrom the training data is learned, yielding a low discriminator score, yet an undesirable outcome.\nTo combat mode collapse, design diversity can be either promoted in the learning algorithm or the\ncost [508, 509]. Another challenge lies in balancing the training of the two NNs. If the discrimina-\ntor learns too quickly and manages to distinguish all generated samples, the gradient of the cost\nfunction (Equation (78)) with respect to the weights becomes zero, halting further progress. A\npossible remedy is to use the Wasserstein distance in the cost function [510].\nAdditionally, GANs can be modified to include inputs that control the generated data. This can\nbe achieved in a supervised manner with conditional GANs [511]. The conditional GAN does not\njust receive random noise, but also an additional input. This supplementary input is considered by\nthe discriminator, which assesses whether the input-output pair are real or generated. An unsu-\npervised alternative are InfoGANs [512], which disentangle the input information, i.e., the random\ninput ξ, defining the generated data. This is achieved by introducing an additional parameter c, a\nlatent code to the generator GNN(ξ, c; θG). To ensure that the parameter is used by the NN, the\ncost (Equation (78)) is extended by a mutual information term [513] I(c, GNN(x, c; θG)) ensuring\nthat the generated data varies meaningfully based on the input latent code c.\nIn comparison to variational autoencoders, GANs typically generate higher quality data. How-\never, the advantage of autoencoders lies in their ability to construct a well-structured latent space,\nwhere proper sampling leads to smooth interpolations in the generated space. In other words, small\nchanges in the latent space correspond to small changes in the generated space – a characteristic\nnot inherent to GANs.\nTo achieve smooth interpolations, autoencoders can be combined with\nGANs [514], where the autoencoder acts as generator in the GAN framework, employing both an\nautoencoder loss and a GAN loss.\n5.3. Diffusion Models\nDiffusion models enhanced by NNs [515–517] convert random noise x into a sample resembling the\ntraining data through a series of transformations. Given a data set {y0\ni }N\ni=1 that corresponds to the\ndistribution q(x0), a forward noising process q(xt|xt−1) is introduced. This process adds Gaussian\nnoise to xt−1 at each time step t −1. The process is applied iteratively\nq(x0, x1, . . . , xT ) = q(x0)\nT\nY\nt=1\nq(xt|xt−1).\n(80)\nAfter a sufficient number of iterations T, the resulting distribution approximates a Gaussian distri-\nbution. Consequently, a random sample from a Gaussian distribution xT can be denoised with the\nreverse denoising process q(xt−1|xt), resulting in a sample x0 that matches the original distribution\nq(x0). The reverse denoising process is, however, unknown and therefore modeled as a Gaussian\ndistribution, where the mean and covariance are learned by a NN. With the learned denoising\nprocess, data can be generated by denoising samples drawn from a Gaussian distribution. Note\nthe similarity to autoencoders. Instead of learning a mapping to a hidden random state hi, the\nencoding is prescribed as the iterative application of Gaussian noise [503].\nA related approach are normalizing flows [518] (see [519] for an introduction and extensive re-\nview). Here, a basic probability distribution is transformed through a series of invertible transfor-\nmations, i.e., flows. The goal is to model distributions of interest. The individual transformations\ncan be modeled by NNs.\nA normalization is required, such that each intermediate probability\ndistribution integrates to one.\n32\n5.4. Applications\n5.4.1. Data Generation\nThe most straightforward application of variational autoencoders and GANs in computational me-\nchanics is the generation of new data, based on existing examples. This has been demonstrated\nin [520–524] for microstructures in [68] for velocity models used in full waveform inversion, and\nin [525] for optimized structures using GANs. Variational autoencoders have also been used to\nmodel the crossover operation in evolutionary algorithms to create new designs from parent de-\nsigns [526]. Applications of diffusion models for microstructure generation can be found in [527–529].\nMicrostructures pose a unique challenge due to their inherent three-dimensional nature, while\noften only two-dimensional reference images are available.\nThis has led to the development of\nspecialized architectures that are capable of creating three-dimensional structures from representa-\ntive two-dimensional slices [530–532]. The approach typically involves treating three-dimensional\nvoxel data as a sequence of two-dimensional slices of pixels. Sequences of images are predicted\nfrom individual slices, ultimately forming a three-dimensional microstructure. In [533], a RNN is\napplied to a two-dimensional reference image, yielding an additional dimension, and consequently\ncreating a three-dimensional structure. The RNN is applied at the latent vector inside an encoder\ndecoder architecture, such that the inputs and outputs of the RNN have a relatively small size.\nSimilarly, [534, 535] apply a transformer [147] to the latent vector. An alternative formulation\nusing variational autoencoder GANs is presented in [536] to reconstruct three-dimensional voxel\nmodels of porous media from two-dimensional images.\nThe generated data sets can subsequently be leveraged to train surrogate models, as demonstrated\nin [525, 537–539] where CNNs were used to verify the physical properties of designs, and in the\nstudy by [540] on the homogenization of microstructures with CNNs. Similarly, [541, 68] generate\nrealistic material distributions, such as velocity distributions, to train an inverse operator for full\nwaveform inversion.\n5.4.2. Generative Design & Design Optimization\nWithin generative design, the generator can also be considered as a reparametrization of the de-\nsign space that reduces the number of design variables.\nWith autoencoders, the latent vector\nserves as the design parameter [542, 543], which is then optimized19. In the context of GANs, the\noptimization task is aimed at the random input ξ provided to the generator. This approach is\ndemonstrated in various studies, such as ship hull design parameterized by NURBS surfaces [545],\nairfoil shapes expressed with B´ezier curves [546, 547], structural optimization [548], and full wave-\nform inversion [549]. For optimization, variational autoencoder GANs are particularly important,\nas the GAN ensures high quality designs, while the autoencoder ensures well-behaving gradients.\nThis was shown for microstructure optimization in [550].\nAn important requirement for generative design is design diversity. Achieving this involves en-\nsuring that the entire design space is spanned by the generated data. For this, the cost function\ncan be extended, as presented in [551], using determinantal point processes [552] or in [545] with a\nspace-filling term [553].\nOther strategies are specifically focused on promoting design diversity. This involves identifying\nnovel designs via a novelty score [554]. The novelty within these designs is segmented and used to\nmodify the GAN using methods outlined in [555]. An alternative approach proposed by [556] quan-\ntifies creativity and maximizes it. This is achieved by performing a classification in pre-determined\ncategories by the discriminator. If the classification is unsuccessful, the design must lie outside\n19It is worth noting, that to ensure designs that are physically meaningful, a style transfer technique can be imple-\nmented [544]. Here, the training data is perceived as a style, and the Gram matrices’ difference, characterizing\nthe distribution of visual patterns or textures in the generated designs, is minimized.\n33\nthe categories and is therefore deemed creative. Thus the generator then seeks to minimize the\nclassification accuracy.\nHowever, some applications necessitate a resemblance to prior designs due to factors such as\naesthetics [557] or manufacturability [558]. In [557], a pixel-wise L1-distance to previous designs\nis included in the loss20. A complete workflow with generative design enforcing resemblance of\nprevious designs and surrogate model training for the quantification of mechanical properties is\ndescribed in [559]. Another option is the use of style transfer techniques [544], which in [560] is\nincorporated into a conventional topology optimization scheme [561] as a constraint in the loss.\nThese are tools with the purpose of incorporating vague constraints based on previous designs for\ntopology optimization.\nGANs can also be applied to inverse problems, as presented in [562] for full waveform inversion.\nThe generator predicts the material distribution, which is used in a differentiable simulation pro-\nviding the forward solution in the form of a seismogram. The discriminator attempts to distinguish\nbetween the seismogram indirectly coming from the generator and the measured seismograms. The\nunderlying material distribution is determined through gradient descent.\n5.4.3. Conditional Generation\nAs stated earlier, GANs can take specific inputs to dictate the output’s nature. The key difference\nto data-driven surrogate models from Section 2.1 is that GANs provide a tool to generate multiple\noutputs given the same conditional input. They are thus applicable to problems with multiple\nsolutions, such as design optimization or data generation.\nExamples of conditional generation are rendered cars from car sketches [563], hierarchical shape\ngeneration [564], where the child shape considers its parent shape and topology optimization with\npredictions of optimal structures from initial fields, e.g., strain energy, of the unoptimized struc-\nture [565, 566]. Physical properties can also be used as input. The properties are computed by\na differentiable solver after generation and are incorporated in the loss. This was, e.g., presented\nin [567] for airplane shapes, and in [568] for inverse homogenization. For full waveform inversion,\n[569] trains a conditional GAN with seismograms as input to predict the corresponding velocity\ndistributions. A similar effort is made by [570] with CycleGANs [571] to circumvent the need for\npaired data. Here, one generator generates a seismogram ˆy = Gy(x) and another a correspond-\ning velocity distribution ˆx = Gx(y). The predictions are judged by two separate discriminators.\nAdditionally, a cycle-consistency loss ensures that a prediction from a prediction, i.e., Gy(ˆx) or\nGx(ˆy), matches the initial input x or y. This cycle-consistency loss ensures, that the learned trans-\nformations preserve the essential features and structures of the original seismograms or velocity\ndistributions when they are transformed from seismogram to velocity distribution and back again.\nLastly, coarse-to-fine mappings as previously discussed in Section 3.4, can also be learned by\nGANs. This was, for example, demonstrated in topology optimization, where a conditional GAN\nrefines coarse designs obtained from classical optimizations [572, 565] or CNN predictions [77].\nFor temporal problems, such as fluid flows, the temporal coherence between time steps poses an\nadditional challenge. Temporal coherence can be ensured by a second discriminator, which receives\nthree consecutive frames of either the generator or the real data and decides if they are real or\ngenerated. The method is referred to as tempoGAN [573].\n5.4.4. Anomaly Detection\nFinally, a last application of generative models is anomaly detection, see [574] for a review. This\nis particularly valuable for non-destructive testing, where flawed specimens can be identified in\nterms of anomalies. The approach relies on generative models and attempts to reconstruct the\n20Similarly, this loss can be used to filter out designs that are too similar.\n34\ngeometry. At first, the generative model is trained on structures without flaws. During evaluation,\nthe structures to be tested are then fed through the NN. In case of an autoencoder, as in [575], it\nis fed through the encoder and decoder. For a GAN, as discussed, e.g., in [576–578], the input of\nthe generator is optimized to fit the output as well as possible. The mismatch in reconstruction\nthen provides a spatially dependent measure of where an anomaly, i.e., defect is located.\nAnother approach is to use the discriminator directly, as presented in [579]. If a flawed specimen\nis given to the discriminator, it will be categorized as fake, as it was not part of the undamaged\nstructures during training. The discriminator can also be used to check if the domain of application\nof a surrogate model is valid.\nTrained on the same training data as the surrogate model, the\ndiscriminator estimates the dissimilarity between the data to be tested and the training data. For\nlarge discrepancies, the discriminator detects that the surrogate model becomes invalid.21\n6. Deep Reinforcement Learning\nIn reinforcement learning, an agent interacts with an environment through a sequence of actions at,\nwhich is illustrated in Figure 13. Upon executing an action at, the agent receives an updated state\nst+1 and reward rt+1 from the environment. The agent’s objective is to maximize the cumulative\nreward RΣ.\nThe environment can be treated as a black box.\nThis presents an advantage in\ncomputational mechanics when differentiable physics are not feasible. Reinforcement learning has\nachieved impressive results such as human-level performance in games like Atari [580], Go [581],\nand StarCraft II [582]. Further, reinforcement learning has been successfully been demonstrated\nin robotics [583]. An example hereof is learning complex maneuvers for autonomous helicopter\nflight [584–586].\nA comprehensive review of reinforcement learning exceeds the scope of this work, since it repre-\nsents a major branch of machine learning. An introduction is, e.g., given in [8, 21], and an in-depth\ntextbook is [587]. However, at the intersection of these domains lies deep reinforcement learning,\nwhich employs NNs to model the agent’s actions. In Appendix A, we present the main concepts\nof deep reinforcement learning and delve into two prominent methodologies: deep policy networks\n(Appendix A.1) and deep Q-learning (Appendix A.2) in view of applications in computational me-\nchanics.\nAgent\nEnvironment\naction at\nstate st\nreward rt\nFigure 13: Reinforcement learning in which an agent interacts with an environment with actions\nat, states st, and rewards rt. Figure adapted from [587].\n6.1. Applications\nDeep reinforcement learning is mainly used for inverse problems (see [8] for a review within fluid\nmechanics), where the PDE solver is treated as a black box, and assumed to not be differentiable.\nThe most prominent application are control problems. One example is discovering swimming\nstrategies for fish – with the goal of efficiently minimizing the distance to a leader fish [588, 589].\nThe environment is given by the Navier Stokes equation. Another example is balancing rigid bodies\n21Note however, that the discriminator does not guarantee an accurate assessment of the validity of the surrogate\nmodel.\n35\nwith fluid jets while using as little force as possible [590]. Similarly, [591] control jets in order to\nreduce the drag around a cylinder. Reducing the drag around a cylinder is also achieved by control-\nling small rotating cylinders in the wake of the flow [592]. A more complex example is controlling\nunmanned aerial vehicles [593]. The control schemes are learned by interacting with simulations\nand, subsequently, applied in experiments.\nFurther applications in connection with inverse problems are learning filters to perturb flows in\norder to match target flows [594]. Also, constitutive laws can be identified. The individual arith-\nmetic manipulations within a constitutive law can be represented as graphs. An agent constructs\nthe graph in order to best match simulation and measurement [595], which yields an interpretable\nlaw.\nTopology optimization has also been tackled by reinforcement learning. Specifically, the ability\nto predict only binary states (material or no material) is desirable – instead of intermediate states,\nas in solid isotropic material with penalization [596, 597]. This has been shown with binary truss\nstructures, modeled with graphs in order to minimize the total structural volume under stress\nconstraints. In [598], an agent removes trusses from existing structures, and trusses are added\nin [599]. Similarly, [600] removes finite elements in solid structures to modify the topology. In-\nstead, [601] pursues design diversity. Here a NN surrogate model predicts near optimal structures\nfrom reference designs. The agent then learns to generate reference designs as input, such that the\ncorresponding optimal structures are as diverse as possible.\nAlso, high-dimensional PDEs have been solved with reinforcement learning [602, 603]. This is\nachieved by recasting the PDE into stochastic control problems, thereby solving these with rein-\nforcement learning.\nFinally, adaptive mesh refinement algorithms have been learned by reinforcement learning [604].\nAn agent decides whether an element is to be refined based on the current state, i.e., the mesh and\nsolution. The reward is subsequently defined in terms of the error reduction, which is computed\nwith a ground truth solution. The trained agent can thus be applied to adaptive mesh refinement\nto previously unseen simulations.\n6.1.1. Extensions\nEach interaction with the environment requires solving the differential equation, which, due to\nthe many interactions, makes reinforcement learning expensive. The learning can be accelerated\nthrough some basic modifications. The learning can be perfectly parallelized by using multiple\nenvironments simultaneously [605], or by using multiple agents within the same environment [606].\nAnother idea is to construct a surrogate model of the environment and thereby exploit model-based\napproaches [607–610]. The general procedure consists of three steps:\n• model learning: learn surrogate of environment,\n• behavior learning: learn policy or value function,\n• environment interaction: apply learned policy and collect data.\nMost approaches construct the surrogate with data-driven modeling (Section 2.1), but physics-\ninformed approaches have been proposed as well [607, 609] (Section 3.2).\n7. Conclusion\nIn order to structure the state-of-the-art, an overview of the most prominent deep learning methods\nemployed in computational mechanics was presented. Six main categories were identified: simu-\nlation substitution, simulation enhancement, discretizations as NNs, generative approaches, and\n36\ndeep reinforcement learning.\nDespite the variety and abundance of the literature, few approaches are competitive in compari-\nson to classical methods. With only few exceptions, current research is still in its early stages, with\na focus on showcasing possibilities without focusing too much attention on accuracy and efficiency.\nFuture research must, nevertheless, shift its focus to incorporate more in-depth investigations into\nthe performance of the developed methods – including thorough and meaningful comparisons to\nclassical methods. This is in agreement with the recent review article on deep learning in topology\noptimization [5], where critical and fair assessments are requested. This includes the determination\nof generalization capabilities, greater transparency by including, e.g., worst case performances to\nillustrate reliability, and computation times without disregard of the training time.\nIn line with this, and to the best of our knowledge, we provide a final overview outlining the\npotentials and limitations of the discussed methods.\n• Simulation substitution has potential for surrogate modeling of parameterized models that\nneed to be evaluated many times. This is however, currently only realizable for small pa-\nrameter spaces, due to the amount of data required. Complex problems can still be solved\nif they are first reduced to a low-dimensional space through model order reduction tech-\nniques. Physics-informed learning further reduces the amount of required data and improves\nthe generalization capabilities. However, enforcing physics through penalty terms increases\nthe computational effort, where the solutions still do not necessarily satisfy the correspond-\ning physical laws. Instead, enforcing physics by construction, which guarantees the enforced\nphysics, seems more favorable.\n• Simulation enhancement is currently one of the most useful approaches. It is in particular\nbeneficial for tasks where classical methods show difficulties. An excellent example for this is\nthe formulation of constitutive laws, which are inherently phenomenological and thereby well-\nsuited to be identified from data using tools such as deep learning. In addition, simulation\nenhancement, makes it possible to draw on insights gained from classical methods developed\nsince the inception of computational mechanics. Furthermore, it is currently more realistic\nto learn smaller components of the simulation chain with NNs rather than the entire model.\nThese components should ideally be expensive and have limited requirements regarding the\naccuracy. Lastly, it is also easier to assess whether a method enhanced by deep learning\noutperforms the classical method, as direct and fair comparisons are readily possible.\n• An important research direction is to employ discretizations as NNs, as this offers the potential\nto discover NNs tailored to computational mechanics tasks, such as CNNs for computer vision\nand RNNs and transformers for natural language processing. Their main benefit comes from\nexploiting the computational benefits of tools and hardware that were created for the wider\ncommunity of deep learning – such as NN libraries and GPUs.\n• Generative approaches have been shown to be highly versatile in applications of computational\nmechanics since the accuracy of a specific instance under investigation is less of a concern\nhere.\nThey have been used for realistic data generation to train other machine learning\nmodels, incorporate vague constraints based on data within optimization frameworks, and\ndetect anomalies.\n• Deep reinforcement learning has already shown encouraging results – for example in control-\nling unmanned vehicles in complex physics environments. It is mainly applicable for problems\nwhere efficient differentiable physics solvers are unavailable, which is why it is popular in con-\ntrol problems for turbulence. In the presence of differentiable solvers, gradient-based methods\nare however still the state-of-the-art [418] and thus preferred.\n37\nAcknowledgements\nThe authors gratefully acknowledge the funding through the joint research project Geothermal-\nAlliance Bavaria (GAB) by the Bavarian State Ministry of Science and the Arts (StMWK) as well\nas the Georg Nemetschek Institut (GNI) under the project DeepMonitor.\nDeclarations\nConflict of interest No potential conflict of interest was reported by the authors.\nA. Deep Reinforcement Learning\nIn reinforcement learning, the environment is commonly modeled as a Markov Decision Process\n(MDP). This mathematical model is defined by a set of all possible states S, actions A, and asso-\nciated rewards R. Furthermore, the probability of getting to the next state st+1 from the previous\nst with action at is given by P(st+1|st, at). Thus, the environment is not necessarily deterministic.\nOne key aspect of a Markov Decision Process is the Markov property, stating that future states\ndepend solely on the current state and action, and not the history of states and actions.\nThe goal of a reinforcement learning algorithm is to determine a policy π(s, a) which dictates\nthe next action at in order to maximize the cumulative reward RΣ. The cumulative reward RΣ is\ndiscounted by a discount factor γt in order to give more importance to immediate rewards.\nRΣ =\n∞\nX\nt=0\nγtrt\n(81)\nThe quality of a policy π(s, a) can be assessed by a state-value function Vπ(s), defined as the\nexpected future reward given the current state s and following the policy π. Similarly, an action-\nvalue function Qπ(s) determines the expected future reward given the current state s and action a\nand then following the policy π. The expected value along a policy π is denoted as Eπ.\nVπ(s) = Eπ\n\u0002\nRΣ(t)|s\n\u0003\n(82)\nQπ(s, a) = Eπ\n\u0002\nRΣ(t)|s, a\n\u0003\n(83)\n(84)\nThe optimal value and quality function correspondingly follow the optimal policy:\nV (s) = max\nπ\nVπ(s),\n(85)\nQ(s, a) = max\nπ\nQπ(s).\n(86)\nThe approaches can be subdivided into model-based and model-free. Model-based methods in-\ncorporate a model of the environment. In the most general sense, a probabilistic environment,\nthis entitles the probability distribution of the next state P(st+1|st, at) and of the next reward\nR(rt+1|st+1, st, at). The model of the environment can be cheaply sampled to improve the policy\nπ with model-free reinforcement learning techniques [611–614] discussed in the sequel (Appen-\ndices A.1 and A.2). However, if the model is differentiable, the gradient of the reward can directly\nbe used to update the policy [615–620]. This is identical to the optimization through differentiable\nphysics solvers discussed in Section 3.3.3. Model-free reinforcement learning techniques can be used\nto enhance the optimization.\nA further distinction is made between policy-based [621–625] and value-based [626–628] ap-\nproaches. Policy-based methods, such as deep policy networks [21] (Appendix A.1), directly opti-\nmize the policy. By contrast, value-based methods, such as deep Q-learning [628] (Appendix A.2)\n38\nlearn the value function from which the optimal policy is selected. Actor-critic methods, such as\nproximal policy optimization [629] combine the ideas with an actor that performs a policy and a\ncritic that judges its quality. Both can be modeled by NNs.\nA.1. Deep Policy Networks\nIn deep policy networks, the policy, i.e., the mapping of states to actions, is modeled by a NN\nˆa = π(s; θ). The quality of the NN is assessed by the expected cumulative reward RΣ, formulated\nin terms of the action-value function Q(s, a).\nC = RΣ = E\n\u0002\nQ(s, a)\n\u0003\n(87)\nIts gradient (see [21, 622, 624] for a derivation), given as:\n∇θRΣ = E\n\u0002\nQ(s, a)∇θ log\n\u0000π(s, a; θ)\n\u0001\u0003\n(88)\ncan be applied within a gradient ascent scheme to learn the optimal policy.\nA.2. Deep Q-Learning\nDeep Q-learning identifies the optimal action-value function Q(s, a) from which the optimal policy\nis extracted. Q-Learning relies on the Bellman optimality criterion [630, 631]. By separating the\nreward r0 at the first step, the recursion formula of the optimal state-value function, i.e., the\nBellman optimality criterion, can be established:\nV (s) = max\nπ\nEπ\nh ∞\nX\nt=0\nγtrt|s0 = s\ni\n(89)\n= max\nπ\nEπ\nh\nr0 +\n∞\nX\nt=1\nγtrt|s1 = s′i\n(90)\n= max\nπ\nEπ\n\u0002\nr0 + γV (s′)\n\u0003\n.\n(91)\nHere, s′ represents the next state after s. This can be done analogously for the action-value function.\nQ(s, a) = max\nπ\nEπ\n\u0002\nr0 + γQ(s′, a′)\n\u0003\n(92)\nThe recursion enables an update formula, referred to as temporal difference (TD) learning [632, 633].\nSpecifically, the current estimate Q(m) at state st is compared to the more accurate estimate at the\nnext state st+1 using the obtained reward rt, referred to as the TD target estimate. The difference\nis the TD error, which in combination with a learning rate α is used to update the function Q(m):\nQ(m+1)(st, at) = Q(m)(st, at) + α\nTD error\nz\n}|\n{\n\u0000rt + γ max\na\nQ(st+1, a)\n|\n{z\n}\nTD target estimate\n−Q(m)(st, at)\n|\n{z\n}\nmodel prediction\n\u0001\n.\n(93)\nHere, the TD target estimate only looks one step ahead – and is therefore referred to as TD(0).\nThe generalization is called TD(N). In the limit N →∞, the method is equivalent to Monte Carlo\nlearning, where all steps are performed and a true target is obtained.\nDeep Q-learning introduces a NN for the action-value function Q(s, a; θ). Its quality is assessed\nwith a loss composed of the mean squared error of the TD error.\nC = E\nh1\n2\n\u0000rt + γ max\na\nQ(st+1, a; θ) −Q(st, at; θ)\n\u00012i\n(94)\nLastly, the optimal policy π(s) maximizing the action-value function Q(s, a; θ) is extracted:\nπ(s) = arg max\na\nQ(s, a; θ)\n(95)\n39\nReferences\n[1] Y. S. Abu-Mostafa, M. Magdon-Ismail, and H.-T. Lin, Learning From Data. S.l.: AMLBook, 2012.\n[2] J. Adie, Y. Juntao, X. Zhang, and S. See, “Deep Learning for Computational Science and Engineering,” 2018.\n[3] G. Yagawa and A. Oishi, Computational mechanics with deep learning: an introduction. Cham, Switzerland:\nSpringer, 2023.\n[4] D. Zhang, N. Maslej, E. Brynjolfsson, J. Etchemendy, T. Lyons, J. Manyika, H. Ngo, J. C. Niebles, M. Sel-\nlitto, E. Sakhaee, Y. Shoham, J. Clark, and R. Perrault, “The AI Index 2022 Annual Report,” May 2022.\narXiv:2205.03468 [cs].\n[5] R. V. Woldseth, N. Aage, J. A. Brentzen, and O. Sigmund, “On the use of artificial neural networks in topology\noptimisation,” Structural and Multidisciplinary Optimization, vol. 65, p. 294, Oct. 2022.\n[6] S. Shin, D. Shin, and N. Kang, “Topology optimization via machine learning and deep learning: a review,”\nJournal of Computational Design and Engineering, vol. 10, pp. 1736–1766, July 2023.\n[7] A. Adler, M. Araya-Polo, and T. Poggio, “Deep Learning for Seismic Inverse Problems: Toward the Acceleration\nof Geophysical Analysis Workflows,” IEEE Signal Processing Magazine, vol. 38, pp. 89–119, Mar. 2021.\n[8] P. Garnier, J. Viquerat, J. Rabault, A. Larcher, A. Kuhnle, and E. Hachem, “A review on Deep Reinforcement\nLearning for Fluid Mechanics,” arXiv:1908.04127 [physics], Aug. 2019. arXiv: 1908.04127.\n[9] K. Duraisamy, G. Iaccarino, and H. Xiao, “Turbulence Modeling in the Age of Data,” Annual Review of Fluid\nMechanics, vol. 51, pp. 357–377, Jan. 2019.\n[10] S. Brunton, B. Noack, and P. Koumoutsakos, “Machine Learning for Fluid Mechanics,” Annual Review of Fluid\nMechanics, vol. 52, pp. 477–508, Jan. 2020. arXiv: 1905.11075.\n[11] S. Cai, Z. Mao, Z. Wang, M. Yin, and G. E. Karniadakis, “Physics-informed neural networks (PINNs) for fluid\nmechanics: a review,” Acta Mechanica Sinica, vol. 37, pp. 1727–1738, Dec. 2021.\n[12] G. Calzolari and W. Liu, “Deep learning to replace, improve, or aid CFD analysis in built environment appli-\ncations: A review,” Building and Environment, vol. 206, p. 108315, Dec. 2021.\n[13] F. E. Bock, R. C. Aydin, C. J. Cyron, N. Huber, S. R. Kalidindi, and B. Klusemann, “A Review of the\nApplication of Machine Learning and Data Mining Approaches in Continuum Materials Mechanics,” Frontiers\nin Materials, vol. 6, p. 110, May 2019.\n[14] D. Bishara, Y. Xie, W. K. Liu, and S. Li, “A State-of-the-Art Review on Machine Learning-Based Multi-\nscale Modeling, Simulation, Homogenization and Design of Materials,” Archives of Computational Methods in\nEngineering, vol. 30, pp. 191–222, Jan. 2023.\n[15] M. Rosenkranz, K. A. Kalina, J. Brummund, and M. Kstner, “A comparative study on different neural network\narchitectures to model inelasticity,” International Journal for Numerical Methods in Engineering, p. nme.7319,\nJuly 2023.\n[16] L. Regenwetter, A. H. Nobari, and F. Ahmed, “Deep Generative Models in Engineering Design: A Review,”\narXiv:2110.10863 [cs, stat], Feb. 2022. arXiv: 2110.10863.\n[17] S. M. Moosavi, K. M. Jablonka, and B. Smit, “The Role of Machine Learning in the Understanding and Design\nof Materials,” Journal of the American Chemical Society, vol. 142, pp. 20273–20287, Dec. 2020.\n[18] W. E. Faller and S. J. Schreck, “Neural networks: Applications and opportunities in aeronautics,” Progress in\nAerospace Sciences, vol. 32, pp. 433–456, Oct. 1996.\n[19] N. Thuerey, P. Holl, M. Mueller, P. Schnell, F. Trost, and K. Um, Physics-based Deep Learning. WWW, 2021.\n[20] S. Kollmannsberger, D. D’Angella, M. Jokeit, and L. Herrmann, Deep Learning in Computational Mechanics:\nAn Introductory Course, vol. 977 of Studies in Computational Intelligence.\nCham: Springer International\nPublishing, 2021.\n[21] S. L. Brunton and J. N. Kutz, Data-driven science and engineering: machine learning, dynamical systems, and\ncontrol. Cambridge, United Kingdom, New York, NY: Cambridge University Press, 2022.\n[22] A. Karpatne, R. Kannan, and V. Kumar, eds., Knowledge Guided Machine Learning: Accelerating Discovery\nusing Scientific Knowledge and Data. New York: Chapman and Hall/CRC, Aug. 2022.\n[23] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press, 2016.\n[24] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga,\nA. Desmaison, A. Kpf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai,\nand S. Chintala, “PyTorch: An Imperative Style, High-Performance Deep Learning Library,” arXiv:1912.01703\n[cs, stat], Dec. 2019. arXiv: 1912.01703.\n[25] Martn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado,\nAndy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving,\nMichael Isard, Y. Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Man,\nRajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya\nSutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vigas, Oriol Vinyals,\nPete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng, “TensorFlow: Large-Scale\nMachine Learning on Heterogeneous Systems,” 2015.\n[26] K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward networks are universal approximators,”\nNeural Networks, vol. 2, pp. 359–366, Jan. 1989.\n[27] D. P. Kingma and J. Ba, “Adam: A Method for Stochastic Optimization,” arXiv:1412.6980 [cs], Jan. 2017.\narXiv: 1412.6980.\n[28] J. Nocedal and S. J. Wright, Numerical optimization. Springer series in operations research, New York: Springer,\n2nd ed ed., 2006. OCLC: ocm68629100.\n[29] F. Rosenblatt, “The perceptron: a probabilistic model for information storage and organization in the brain,”\nPsychological Review, vol. 65, pp. 386–408, Nov. 1958.\n40\n[30] Y. LeCun, B. Boser, J. Denker, D. Henderson, R. Howard, W. Hubbard, and L. Jackel, “Handwritten Digit\nRecognition with a Back-Propagation Network,” in Advances in Neural Information Processing Systems, vol. 2,\nMorgan-Kaufmann, 1989.\n[31] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel, “Back-\npropagation Applied to Handwritten Zip Code Recognition,” Neural Computation, vol. 1, pp. 541–551, Dec.\n1989.\n[32] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,”\nProceedings of the IEEE, vol. 86, pp. 2278–2324, Nov. 1998. Conference Name: Proceedings of the IEEE.\n[33] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning representations by back-propagating errors,”\nNature, vol. 323, pp. 533–536, Oct. 1986.\n[34] S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” Neural Computation, vol. 9, pp. 1735–1780,\nNov. 1997.\n[35] K. Cho, B. van Merrinboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio, “Learning\nPhrase Representations using RNN EncoderDecoder for Statistical Machine Translation,” in Proceedings of the\n2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), (Doha, Qatar), pp. 1724–\n1734, Association for Computational Linguistics, Oct. 2014.\n[36] T. N. Kipf and M. Welling, “Semi-Supervised Classification with Graph Convolutional Networks,” Feb. 2017.\narXiv:1609.02907 [cs, stat].\n[37] F. Monti, O. Shchur, A. Bojchevski, O. Litany, S. Gnnemann, and M. M. Bronstein, “Dual-Primal Graph\nConvolutional Networks,” June 2018. arXiv:1806.00770 [cs, stat].\n[38] P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski, A. Tacchetti,\nD. Raposo, A. Santoro, R. Faulkner, C. Gulcehre, F. Song, A. Ballard, J. Gilmer, G. Dahl, A. Vaswani,\nK. Allen, C. Nash, V. Langston, C. Dyer, N. Heess, D. Wierstra, P. Kohli, M. Botvinick, O. Vinyals, Y. Li, and\nR. Pascanu, “Relational inductive biases, deep learning, and graph networks,” Oct. 2018. arXiv:1806.01261 [cs,\nstat].\n[39] A. Henkes, J. K. Eshraghian, and H. Wessels, “Spiking neural networks for nonlinear regression,” Oct. 2022.\narXiv:2210.03515 [cs].\n[40] S. B. Tandale and M. Stoffel, “Spiking recurrent neural networks for neuromorphic computing in nonlinear\nstructural mechanics,” Computer Methods in Applied Mechanics and Engineering, vol. 412, p. 116095, July\n2023.\n[41] W. Gerstner and W. M. Kistler, Spiking Neuron Models: Single Neurons, Populations, Plasticity. Cambridge\nUniversity Press, 1 ed., Aug. 2002.\n[42] T. J. R. Hughes and G. M. Hulbert, “Space-time finite element methods for elastodynamics: Formulations and\nerror estimates,” Computer Methods in Applied Mechanics and Engineering, vol. 66, pp. 339–363, Feb. 1988.\n[43] M. Alsalman, B. Colvert, and E. Kanso, “Training bioinspired sensors to classify flows,” Bioinspiration &\nBiomimetics, vol. 14, p. 016009, Nov. 2018.\n[44] B. Colvert, M. Alsalman, and E. Kanso, “Classifying vortex wakes using neural networks,” Bioinspiration &\nBiomimetics, vol. 13, p. 025003, Feb. 2018.\n[45] S. Pierret and R. A. Van Den Braembussche, “Turbomachinery Blade Design Using a NavierStokes Solver and\nArtificial Neural Network,” Journal of Turbomachinery, vol. 121, pp. 326–332, Apr. 1999.\n[46] P. Vurtur Badarinath, M. Chierichetti, and F. Davoudi Kakhki, “A Machine Learning Approach as a Surrogate\nfor a Finite Element Analysis: Status of Research and Application to One Dimensional Systems,” Sensors,\nvol. 21, p. 1654, Jan. 2021.\n[47] C. Lee, J. Kim, D. Babcock, and R. Goodman, “Application of neural networks to turbulence control for drag\nreduction,” Physics of Fluids, vol. 9, pp. 1740–1747, June 1997.\n[48] K. Jambunathan, S. L. Hartle, S. Ashforth-Frost, and V. N. Fontama, “Evaluating convective heat transfer\ncoefficients using neural networks,” International Journal of Heat and Mass Transfer, vol. 39, pp. 2329–2332,\nJuly 1996.\n[49] B. D. Tracey, K. Duraisamy, and J. J. Alonso, “A Machine Learning Strategy to Assist Turbulence Model Devel-\nopment,” in 53rd AIAA Aerospace Sciences Meeting, (Kissimmee, Florida), American Institute of Aeronautics\nand Astronautics, Jan. 2015.\n[50] P. Ramuhalli, L. Udpa, and S. Udpa, “Electromagnetic NDE signal inversion by function-approximation neural\nnetworks,” IEEE Transactions on Magnetics, vol. 38, pp. 3633–3642, Nov. 2002.\n[51] M. Araya-Polo, J. Jennings, A. Adler, and T. Dahlke, “Deep-learning tomography,” The Leading Edge, vol. 37,\npp. 58–66, Jan. 2018.\n[52] Y. Kim and N. Nakata, “Geophysical inversion versus machine learning in inverse problems,” The Leading\nEdge, vol. 37, pp. 894–901, Dec. 2018.\n[53] V.-N. Hoang, N.-L. Nguyen, D. Q. Tran, Q.-V. Vu, and H. Nguyen-Xuan, “Data-driven geometry-based topol-\nogy optimization,” Structural and Multidisciplinary Optimization, vol. 65, p. 69, Jan. 2022.\n[54] X. Zhang and K. Garikipati, “Label-free learning of elliptic partial differential equation solvers with generaliz-\nability across boundary value problems,” Computer Methods in Applied Mechanics and Engineering, p. 116214,\nJuly 2023.\n[55] N. Thuerey, K. Weienow, L. Prantl, and X. Hu, “Deep Learning Methods for Reynolds-Averaged NavierStokes\nSimulations of Airfoil Flows,” AIAA Journal, vol. 58, pp. 25–36, Jan. 2020.\n[56] L.-W. Chen, B. A. Cakal, X. Hu, and N. Thuerey, “Numerical investigation of minimum drag profiles in laminar\nflow using deep learning surrogates,” Journal of Fluid Mechanics, vol. 919, p. A34, July 2021.\n[57] X. Chen, X. Zhao, Z. Gong, J. Zhang, W. Zhou, X. Chen, and W. Yao, “A deep neural network surrogate\nmodeling benchmark for temperature field prediction of heat source layout,” Science China Physics, Mechanics\n& Astronomy, vol. 64, p. 1, Sept. 2021.\n41\n[58] L.-W. Chen and N. Thuerey, “Towards high-accuracy deep learning inference of compressible flows over aero-\nfoils,” Computers & Fluids, vol. 250, p. 105707, Jan. 2023.\n[59] A. Khadilkar, J. Wang, and R. Rai, “Deep learningbased stress prediction for bottom-up SLA 3D printing\nprocess,” The International Journal of Advanced Manufacturing Technology, vol. 102, pp. 2555–2569, June\n2019.\n[60] Z. Nie, H. Jiang, and L. B. Kara, “Stress Field Prediction in Cantilevered Structures Using Convolutional\nNeural Networks,” Journal of Computing and Information Science in Engineering, vol. 20, p. 011002, Feb.\n2020.\n[61] X. Guo, W. Li, and F. Iorio, “Convolutional Neural Networks for Steady Flow Approximation,” in Proceedings\nof the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, (San Francisco\nCalifornia USA), pp. 481–490, ACM, Aug. 2016.\n[62] Z. Zhang, P. Jaiswal, and R. Rai, “FeatureNet: Machining feature recognition based on 3D Convolution Neural\nNetwork,” Computer-Aided Design, vol. 101, pp. 12–22, Aug. 2018.\n[63] G. Williams, N. A. Meisel, T. W. Simpson, and C. McComb, “Design Repository Effectiveness for 3D Convo-\nlutional Neural Networks: Application to Additive Manufacturing,” Journal of Mechanical Design, vol. 141,\np. 111701, Nov. 2019.\n[64] Y. Wu, Y. Lin, and Z. Zhou, “Inversionet: Accurate and efficient seismic-waveform inversion with convolutional\nneural networks,” in SEG Technical Program Expanded Abstracts 2018, (Anaheim, California), pp. 2096–2100,\nSociety of Exploration Geophysicists, Aug. 2018.\n[65] W. Wang, F. Yang, and J. Ma, “Velocity model building with a modified fully convolutional network,” in SEG\nTechnical Program Expanded Abstracts 2018, (Anaheim, California), pp. 2086–2090, Society of Exploration\nGeophysicists, Aug. 2018.\n[66] F. Yang and J. Ma, “Deep-learning inversion: A next-generation seismic velocity model building method,”\nGEOPHYSICS, vol. 84, pp. R583–R599, July 2019.\n[67] Y. Zheng, Q. Zhang, A. Yusifov, and Y. Shi, “Applications of supervised deep learning for seismic interpretation\nand inversion,” The Leading Edge, vol. 38, pp. 526–533, July 2019.\n[68] M. Araya-Polo, S. Farris, and M. Florez, “Deep learning-driven velocity model building workflow,” The Leading\nEdge, vol. 38, pp. 872a1–872a9, Nov. 2019.\n[69] V. Das, A. Pollack, U. Wollner, and T. Mukerji, “Convolutional neural network for seismic impedance inver-\nsion,” GEOPHYSICS, vol. 84, pp. R869–R880, Nov. 2019.\n[70] W. Wang and J. Ma, “Velocity model building in a crosswell acquisition geometry with image-trained artificial\nneural networks,” GEOPHYSICS, vol. 85, pp. U31–U46, Mar. 2020.\n[71] S. Li, B. Liu, Y. Ren, Y. Chen, S. Yang, Y. Wang, and P. Jiang, “Deep-Learning Inversion of Seismic Data,”\nIEEE Transactions on Geoscience and Remote Sensing, vol. 58, pp. 2135–2149, Mar. 2020.\n[72] B. Wu, D. Meng, L. Wang, N. Liu, and Y. Wang, “Seismic Impedance Inversion Using Fully Convolutional\nResidual Network and Transfer Learning,” IEEE Geoscience and Remote Sensing Letters, vol. 17, pp. 2140–\n2144, Dec. 2020.\n[73] M. J. Park and M. D. Sacchi, “Automatic velocity analysis using convolutional neural network and transfer\nlearning,” GEOPHYSICS, vol. 85, pp. V33–V43, Jan. 2020.\n[74] J. Ye and N. Toyama, “Automatic defect detection for ultrasonic wave propagation imaging method using\nspatio-temporal convolution neural networks,” Structural Health Monitoring, vol. 21, pp. 2750–2767, Nov.\n2022.\n[75] J. Rao, F. Yang, H. Mo, S. Kollmannsberger, and E. Rank, “Quantitative reconstruction of defects in multi-\nlayered bonded composites using fully convolutional network-based ultrasonic inversion,” Journal of Sound and\nVibration, vol. 542, p. 117418, Jan. 2023.\n[76] Q. Lin, J. Hong, Z. Liu, B. Li, and J. Wang, “Investigation into the topology optimization for conductive heat\ntransfer based on deep learning approach,” International Communications in Heat and Mass Transfer, vol. 97,\npp. 103–109, Oct. 2018.\n[77] Y. Yu, T. Hur, J. Jung, and I. G. Jang, “Deep learning for determining a near-optimal topological design\nwithout any iteration,” Structural and Multidisciplinary Optimization, vol. 59, pp. 787–799, Mar. 2019.\n[78] D. W. Abueidda, S. Koric, and N. A. Sobh, “Topology optimization of 2D structures with nonlinearities using\ndeep learning,” Computers & Structures, vol. 237, p. 106283, Sept. 2020.\n[79] K. Nakamura and Y. Suzuki, “Deep learning-based topological optimization for representing a user-specified\ndesign area,” Apr. 2020.\n[80] Y. Zhang, B. Peng, X. Zhou, C. Xiang, and D. Wang, “A deep Convolutional Neural Network for topology\noptimization with strong generalization ability,” Mar. 2020. arXiv:1901.07761 [cs, stat].\n[81] S. Zheng, Z. He, and H. Liu, “Generating three-dimensional structural topologies via a U-Net convolutional\nneural network,” Thin-Walled Structures, vol. 159, p. 107263, Feb. 2021.\n[82] S. Zheng, H. Fan, Z. Zhang, Z. Tian, and K. Jia, “Accurate and real-time structural topology prediction driven\nby deep learning under moving morphable component-based framework,” Applied Mathematical Modelling,\nvol. 97, pp. 522–535, Sept. 2021.\n[83] D. Wang, C. Xiang, Y. Pan, A. Chen, X. Zhou, and Y. Zhang, “A deep convolutional neural network for\ntopology optimization with perceptible generalization ability,” Engineering Optimization, vol. 54, pp. 973–988,\nJune 2022.\n[84] J. Yan, Q. Zhang, Q. Xu, Z. Fan, H. Li, W. Sun, and G. Wang, “Deep learning driven real time topology\noptimisation based on initial stress learning,” Advanced Engineering Informatics, vol. 51, p. 101472, Jan. 2022.\n[85] J. Seo and R. K. Kapania, “Topology optimization with advanced CNN using mapped physics-based data,”\nStructural and Multidisciplinary Optimization, vol. 66, p. 21, Jan. 2023.\n[86] I. Sosnovik and I. Oseledets, “Neural networks for topology optimization,” Russian Journal of Numerical\n42\nAnalysis and Mathematical Modelling, vol. 34, pp. 215–223, Aug. 2019.\n[87] Y. Joo, Y. Yu, and I. G. Jang, “Unit Module-Based Convergence Acceleration for Topology Optimization Using\nthe Spatiotemporal Deep Neural Network,” IEEE Access, vol. 9, pp. 149766–149779, 2021.\n[88] N. A. Kallioras, G. Kazakis, and N. D. Lagaros, “Accelerated topology optimization by means of deep learning,”\nStructural and Multidisciplinary Optimization, vol. 62, pp. 1185–1212, Sept. 2020.\n[89] A. Sanchez-Gonzalez, J. Godwin, T. Pfaff, R. Ying, J. Leskovec, and P. W. Battaglia, “Learning to Simulate\nComplex Physics with Graph Networks,” arXiv:2002.09405 [physics, stat], Sept. 2020. arXiv: 2002.09405.\n[90] T. Pfaff, M. Fortunato, A. Sanchez-Gonzalez, and P. W. Battaglia, “Learning Mesh-Based Simulation with\nGraph Networks,” arXiv:2010.03409 [cs], June 2021. arXiv: 2010.03409.\n[91] R. Perera, D. Guzzetti, and V. Agrawal, “Graph neural networks for simulating crack coalescence and prop-\nagation in brittle materials,” Computer Methods in Applied Mechanics and Engineering, vol. 395, p. 115021,\nMay 2022.\n[92] C. R. Qi, H. Su, K. Mo, and L. J. Guibas, “PointNet: Deep Learning on Point Sets for 3D Classification and\nSegmentation,” Apr. 2017.\n[93] T. Groueix, M. Fisher, V. G. Kim, B. C. Russell, and M. Aubry, “AtlasNet: A Papier-M\\ˆach\\’e Approach to\nLearning 3D Surface Generation,” July 2018. arXiv:1802.05384 [cs].\n[94] J. D. Cunningham, T. W. Simpson, and C. S. Tucker, “An Investigation of Surrogate Models for Efficient\nPerformance-Based Decoding of 3D Point Clouds,” Journal of Mechanical Design, vol. 141, p. 121401, Dec.\n2019.\n[95] I. T. Jolliffe, Principal component analysis. Springer series in statistics, New York: Springer, 2nd ed ed., 2002.\n[96] T. Heimann and H.-P. Meinzer, “Statistical shape models for 3D medical image segmentation: A review,”\nMedical Image Analysis, vol. 13, pp. 543–563, Aug. 2009.\n[97] K. Bhattacharya, B. Hosseini, N. B. Kovachki, and A. M. Stuart, “Model Reduction And Neural Networks For\nParametric PDEs,” The SMAI Journal of computational mathematics, vol. 7, pp. 121–157, 2021.\n[98] G. Berkooz, P. Holmes, and J. L. Lumley, “The Proper Orthogonal Decomposition in the Analysis of Turbulent\nFlows,” Annual Review of Fluid Mechanics, vol. 25, pp. 539–575, Jan. 1993.\n[99] D. Muoz, O. Allix, F. Chinesta, J. J. Rdenas, and E. Nadal, “Manifold learning for coherent design interpolation\nbased on geometrical and topological descriptors,” Computer Methods in Applied Mechanics and Engineering,\nvol. 405, p. 115859, Feb. 2023.\n[100] L. Liang, M. Liu, C. Martin, and W. Sun, “A deep learning approach to estimate stress distribution: a fast\nand accurate surrogate of finite-element analysis,” Journal of The Royal Society Interface, vol. 15, p. 20170844,\nJan. 2018.\n[101] A. Madani, A. Bakhaty, J. Kim, Y. Mubarak, and M. R. K. Mofrad, “Bridging Finite Element and Machine\nLearning Modeling: Stress Prediction of Arterial Walls in Atherosclerosis,” Journal of Biomechanical Engi-\nneering, vol. 141, p. 084502, Aug. 2019.\n[102] E. Muravleva, I. Oseledets, and D. Koroteev, “Application of machine learning to viscoplastic flow modeling,”\nPhysics of Fluids, vol. 30, p. 103102, Oct. 2018.\n[103] L. Liang, M. Liu, C. Martin, and W. Sun, “A machine learning approach as a surrogate of finite element\nanalysis-based inverse method to estimate the zero-pressure geometry of human thoracic aorta,” International\nJournal for Numerical Methods in Biomedical Engineering, vol. 34, p. e3103, Aug. 2018.\n[104] K. Derouiche, S. Garois, V. Champaney, M. Daoud, K. Traidi, and F. Chinesta, “Data-Driven Modeling for\nMultiphysics Parametrized Problems-Application to Induction Hardening Process,” Metals, vol. 11, p. 738,\nApr. 2021.\n[105] Q. Hernndez, A. Badas, F. Chinesta, and E. Cueto, “Thermodynamics-informed neural networks for physically\nrealistic mixed reality,” Computer Methods in Applied Mechanics and Engineering, vol. 407, p. 115912, Mar.\n2023.\n[106] G. E. Hinton and R. R. Salakhutdinov, “Reducing the Dimensionality of Data with Neural Networks,” Science,\nvol. 313, pp. 504–507, July 2006.\n[107] M. Milano and P. Koumoutsakos, “Neural Network Modeling for Near Wall Turbulent Flow,” Journal of\nComputational Physics, vol. 182, pp. 1–26, Oct. 2002.\n[108] S. Nair, T. F. Walsh, G. Pickrell, and F. Semperlotti, “GRIDS-Net: Inverse shape design and identification\nof scatterers via geometric regularization and physics-embedded deep learning,” Computer Methods in Applied\nMechanics and Engineering, vol. 414, p. 116167, Sept. 2023.\n[109] A. Fernandez-Navamuel, D. Zamora-Snchez, . J. Omella, D. Pardo, D. Garcia-Sanchez, and F. Magalhes,\n“Supervised Deep Learning with Finite Element simulations for damage identification in bridges,” Engineering\nStructures, vol. 257, p. 114016, Apr. 2022.\n[110] O. Ronneberger, P. Fischer, and T. Brox, “U-Net: Convolutional Networks for Biomedical Image Segmenta-\ntion,” in Medical Image Computing and Computer-Assisted Intervention MICCAI 2015 (N. Navab, J. Horneg-\nger, W. M. Wells, and A. F. Frangi, eds.), Lecture Notes in Computer Science, (Cham), pp. 234–241, Springer\nInternational Publishing, 2015.\n[111] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, and J. Liang, “UNet++: A Nested U-Net Architecture for Medical\nImage Segmentation,” July 2018. arXiv:1807.10165 [cs, eess, stat].\n[112] L. Lu, X. Meng, S. Cai, Z. Mao, S. Goswami, Z. Zhang, and G. E. Karniadakis, “A comprehensive and fair\ncomparison of two neural operators (with practical extensions) based on FAIR data,” Computer Methods in\nApplied Mechanics and Engineering, vol. 393, p. 114778, Apr. 2022.\n[113] T. Chen and H. Chen, “Universal approximation to nonlinear operators by neural networks with arbitrary\nactivation functions and its application to dynamical systems,” IEEE Transactions on Neural Networks, vol. 6,\npp. 911–917, July 1995.\n[114] L. Lu, P. Jin, G. Pang, Z. Zhang, and G. E. Karniadakis, “Learning nonlinear operators via DeepONet based\n43\non the universal approximation theorem of operators,” Nature Machine Intelligence, vol. 3, pp. 218–229, Mar.\n2021.\n[115] Z.-Y. Li, N. B. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, and A. Anandkumar, “Fourier\nneural operator for parametric partial differential equations,” ArXiv, vol. abs/2010.08895, 2021.\n[116] C. Lin, M. Maxey, Z. Li, and G. E. Karniadakis, “A seamless multiscale operator neural network for inferring\nbubble dynamics,” Journal of Fluid Mechanics, vol. 929, p. A18, Dec. 2021.\n[117] Z. Mao, L. Lu, O. Marxen, T. A. Zaki, and G. E. Karniadakis, “DeepM&Mnet for hypersonics: Predicting the\ncoupled flow and finite-rate chemistry behind a normal shock using neural-network approximation of operators,”\nJournal of Computational Physics, vol. 447, p. 110698, Dec. 2021.\n[118] P. C. Di Leoni, L. Lu, C. Meneveau, G. Karniadakis, and T. A. Zaki, “DeepONet prediction of linear instability\nwaves in high-speed boundary layers,” May 2021. arXiv:2105.08697 [physics].\n[119] S. Cai, Z. Wang, L. Lu, T. A. Zaki, and G. E. Karniadakis, “DeepM&Mnet: Inferring the electroconvection\nmultiphysics fields based on operator approximation by neural networks,” Journal of Computational Physics,\nvol. 436, p. 110296, July 2021.\n[120] C. Lin, Z. Li, L. Lu, S. Cai, M. Maxey, and G. E. Karniadakis, “Operator learning for predicting multiscale\nbubble growth dynamics,” The Journal of Chemical Physics, vol. 154, p. 104118, Mar. 2021. arXiv:2012.12816\n[physics].\n[121] M. Yin, E. Ban, B. V. Rego, E. Zhang, C. Cavinato, J. D. Humphrey, and G. Em Karniadakis, “Simulating\nprogressive intramural damage leading to aortic dissection using DeepONet: an operatorregression neural\nnetwork,” Journal of The Royal Society Interface, vol. 19, p. 20210670, Feb. 2022.\n[122] J. D. Osorio, Z. Wang, G. Karniadakis, S. Cai, C. Chryssostomidis, M. Panwar, and R. Hovsapian, “Forecasting\nsolar-thermal systems performance under transient operation using a data-driven machine learning approach\nbased on the deep operator network architecture,” Energy Conversion and Management, vol. 252, p. 115063,\nJan. 2022.\n[123] S. Goswami, D. S. Li, B. V. Rego, M. Latorre, J. D. Humphrey, and G. E. Karniadakis, “Neural operator\nlearning of heterogeneous mechanobiological insults contributing to aortic aneurysms,” Journal of The Royal\nSociety Interface, vol. 19, p. 20220410, Aug. 2022.\n[124] S. Koric, A. Viswantah, D. W. Abueidda, N. A. Sobh, and K. Khan, “Deep learning operator network for\nplastic deformation with variable loads and material properties,” Engineering with Computers, May 2023.\n[125] P. Clark Di Leoni, L. Lu, C. Meneveau, G. E. Karniadakis, and T. A. Zaki, “Neural operator prediction of\nlinear instability waves in high-speed boundary layers,” Journal of Computational Physics, vol. 474, p. 111793,\nFeb. 2023.\n[126] S. Koric and D. W. Abueidda, “Data-driven and physics-informed deep learning operators for solution of heat\nconduction equation with parametric heat source,” International Journal of Heat and Mass Transfer, vol. 203,\np. 123809, Apr. 2023.\n[127] C. Liu, Q. He, A. Zhao, T. Wu, Z. Song, B. Liu, and C. Feng, “Operator Learning for Predicting Mechanical\nResponse of Hierarchical Composites with Applications of Inverse Design,” International Journal of Applied\nMechanics, vol. 15, p. 2350028, May 2023.\n[128] S. E. Ahmed and P. Stinis, “A multifidelity deep operator network approach to closure for multiscale systems,”\nComputer Methods in Applied Mechanics and Engineering, vol. 414, p. 116161, Sept. 2023.\n[129] S. Wang, H. Wang, and P. Perdikaris, “Learning the solution operator of parametric partial differential equations\nwith physics-informed DeepONets,” Science Advances, vol. 7, p. eabi8605, Oct. 2021.\n[130] S. Goswami, M. Yin, Y. Yu, and G. E. Karniadakis, “A physics-informed variational DeepONet for predicting\ncrack path in quasi-brittle materials,” Computer Methods in Applied Mechanics and Engineering, vol. 391,\np. 114587, Mar. 2022.\n[131] S. Goswami, A. Bora, Y. Yu, and G. E. Karniadakis, “Physics-Informed Deep Neural Operator Networks,”\nJuly 2022. arXiv:2207.05748 [cs, math].\n[132] N. Kovachki, S. Lanthaler, and S. Mishra, “On universal approximation and error bounds for Fourier neural\noperators,” The Journal of Machine Learning Research, vol. 22, pp. 290:13237–290:13312, Jan. 2021.\n[133] Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, and A. Anandkumar, “Neural\nOperator: Graph Kernel Network for Partial Differential Equations,” Mar. 2020. arXiv:2003.03485 [cs, math,\nstat].\n[134] Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, and A. Anandkumar, “Multipole\ngraph neural operator for parametric partial differential equations,” in Proceedings of the 34th International\nConference on Neural Information Processing Systems, NIPS’20, (Red Hook, NY, USA), pp. 6755–6766, Curran\nAssociates Inc., Dec. 2020.\n[135] Q. Cao, S. Goswami, and G. E. Karniadakis, “LNO: Laplace Neural Operator for Solving Differential Equa-\ntions,” May 2023. arXiv:2303.10528 [cs].\n[136] C. Zhu, H. Ye, and B. Zhan, “Fast Solver of 2D Maxwells Equations Based on Fourier Neural Operator,” in\n2021 Photonics & Electromagnetics Research Symposium (PIERS), (Hangzhou, China), pp. 1635–1643, IEEE,\nNov. 2021.\n[137] C. Song and Y. Wang, “High-frequency wavefield extrapolation using the Fourier neural operator,” Journal of\nGeophysics and Engineering, vol. 19, pp. 269–282, Apr. 2022.\n[138] W. Wei and L.-Y. Fu, “Small-data-driven fast seismic simulations for complex media using physics-informed\nFourier neural operators,” GEOPHYSICS, vol. 87, pp. T435–T446, Nov. 2022.\n[139] M. M. Rashid, T. Pittie, S. Chakraborty, and N. A. Krishnan, “Learning the stress-strain fields in digital\ncomposites using Fourier neural operator,” iScience, vol. 25, p. 105452, Nov. 2022.\n[140] K. Zhang, Y. Zuo, H. Zhao, X. Ma, J. Gu, J. Wang, Y. Yang, C. Yao, and J. Yao, “Fourier Neural Operator for\nSolving Subsurface Oil/Water Two-Phase Flow Partial Differential Equation,” SPE Journal, vol. 27, pp. 1815–\n44\n1830, June 2022.\n[141] B. Yan, B. Chen, D. Robert Harp, W. Jia, and R. J. Pawar, “A robust deep learning workflow to predict\nmultiphase flow behavior during geological C O 2 sequestration injection and Post-Injection periods,” Journal\nof Hydrology, vol. 607, p. 127542, Apr. 2022.\n[142] G. Wen, Z. Li, K. Azizzadenesheli, A. Anandkumar, and S. M. Benson, “U-FNOAn enhanced Fourier neural\noperator-based deep-learning model for multiphase flow,” Advances in Water Resources, vol. 163, p. 104180,\nMay 2022.\n[143] W. Peng, Z. Yuan, and J. Wang, “Attention-enhanced neural network models for turbulence simulation,”\nPhysics of Fluids, vol. 34, p. 025111, Feb. 2022.\n[144] H. You, Q. Zhang, C. J. Ross, C.-H. Lee, and Y. Yu, “Learning deep Implicit Fourier Neural Operators\n(IFNOs) with applications to heterogeneous material modeling,” Computer Methods in Applied Mechanics and\nEngineering, vol. 398, p. 115296, Aug. 2022.\n[145] T. Kuang, J. Liu, Z. Yin, H. Jing, Y. Lan, Z. Lan, and H. Pan, “Fast and Robust Prediction of Multiphase\nFlow in Complex Fractured Reservoir Using a Fourier Neural Operator,” Energies, vol. 16, p. 3765, Apr. 2023.\n[146] P. A. Costa Rocha, S. J. Johnston, V. Oliveira Santos, A. A. Aliabadi, J. V. G. Th, and B. Gharabaghi, “Deep\nNeural Network Modeling for CFD Simulations: Benchmarking the Fourier Neural Operator on the Lid-Driven\nCavity Case,” Applied Sciences, vol. 13, p. 3165, Mar. 2023.\n[147] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin,\n“Attention is All you Need,” in Advances in Neural Information Processing Systems, vol. 30, Curran Associates,\nInc., 2017.\n[148] S. Cao, “Choose a Transformer: Fourier or Galerkin,” Nov. 2021. arXiv:2105.14995 [cs, math].\n[149] Z. Li, H. Zheng, N. Kovachki, D. Jin, H. Chen, B. Liu, K. Azizzadenesheli, and A. Anandkumar, “Physics-\nInformed Neural Operator for Learning Partial Differential Equations,” Apr. 2023. arXiv:2111.03794 [cs, math].\n[150] C. Marcati, J. A. A. Opschoor, P. C. Petersen, and C. Schwab, “Exponential ReLU Neural Network Ap-\nproximation Rates for Point and Edge Singularities,” Foundations of Computational Mathematics, vol. 23,\npp. 1043–1127, June 2023.\n[151] L. Gonon and C. Schwab, “Deep ReLU neural networks overcome the curse of dimensionality for partial\nintegrodifferential equations,” Analysis and Applications, vol. 21, pp. 1–47, Jan. 2023.\n[152] C. Marcati and C. Schwab, “Exponential Convergence of Deep Operator Networks for Elliptic Partial Differ-\nential Equations,” SIAM Journal on Numerical Analysis, vol. 61, pp. 1513–1545, June 2023.\n[153] J. .-A. lvarez Aramberri, V. D. Darrigrand, F. C. Caro, and D. P. Pardo, “Generation of Massive Databases for\nDeep Learning Inversion: A Goal-Oriented hp-Adaptive Strategy,” XI International Conference on Adaptive\nModeling and Simulation (ADMOS 2023), vol. Applications of Goal-Oriented Error Estimation and Adaptivity,\nMay 2023.\n[154] E. L. Bolager, I. Burak, C. Datar, Q. Sun, and F. Dietrich, “Sampling weights of deep neural networks,” June\n2023. arXiv:2306.16830 [cs, math].\n[155] D. Cohn, Z. Ghahramani, and M. Jordan, “Active Learning with Statistical Models,” in Advances in Neural\nInformation Processing Systems, vol. 7, MIT Press, 1994.\n[156] X. Liu, C. E. Athanasiou, N. P. Padture, B. W. Sheldon, and H. Gao, “Knowledge extraction and transfer in\ndata-driven fracture mechanics,” Proceedings of the National Academy of Sciences, vol. 118, p. e2104765118,\nJune 2021.\n[157] B. Haasdonk, H. Kleikamp, M. Ohlberger, F. Schindler, and T. Wenzel, “A New Certified Hierarchical and\nAdaptive RB-ML-ROM Surrogate Model for Parametrized PDEs,” SIAM Journal on Scientific Computing,\nvol. 45, pp. A1039–A1065, June 2023.\n[158] K. A. Kalina, L. Linden, J. Brummund, and M. Kstner, “FE$${}ˆ\\textrm{ANN}$$: an efficient data-driven\nmultiscale approach based on physics-constrained neural networks and automated data mining,” Computational\nMechanics, vol. 71, pp. 827–851, May 2023.\n[159] S. J. Pan and Q. Yang, “A Survey on Transfer Learning,” IEEE Transactions on Knowledge and Data Engi-\nneering, vol. 22, pp. 1345–1359, Oct. 2010.\n[160] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are features in deep neural networks?,”\nin Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2,\nNIPS’14, (Cambridge, MA, USA), pp. 3320–3328, MIT Press, Dec. 2014.\n[161] S. Kollmannsberger, D. Singh, and L. Herrmann, “Transfer Learning Enhanced Full Waveform Inversion,” Feb.\n2023. arXiv:2302.11259 [physics].\n[162] A. A. Ballakur and A. Arya, “Empirical Evaluation of Gated Recurrent Neural Network Architectures in\nAviation Delay Prediction,” in 2020 5th International Conference on Computing, Communication and Security\n(ICCCS), pp. 1–7, Oct. 2020.\n[163] N. Geneva and N. Zabaras, “Modeling the Dynamics of PDE Systems with Physics-Constrained Deep Auto-\nRegressive Networks,” Journal of Computational Physics, vol. 403, p. 109056, Feb. 2020. arXiv: 1906.05747.\n[164] M. B. Chang, T. Ullman, A. Torralba, and J. B. Tenenbaum, “A Compositional Object-Based Approach to\nLearning Physical Dynamics,” Mar. 2017.\n[165] D. Mrowca, C. Zhuang, E. Wang, N. Haber, L. Fei-Fei, J. B. Tenenbaum, and D. L. K. Yamins, “Flexible\nNeural Representation for Physics Prediction,” Oct. 2018.\n[166] A. Sanchez-Gonzalez, N. Heess, J. T. Springenberg, J. Merel, M. Riedmiller, R. Hadsell, and P. Battaglia,\n“Graph networks as learnable physics engines for inference and control,” June 2018.\n[167] Y. Li, J. Wu, J.-Y. Zhu, J. B. Tenenbaum, A. Torralba, and R. Tedrake, “Propagation Networks for Model-\nBased Control Under Partial Observation,” Apr. 2019.\n[168] M. Lino, C. Cantwell, A. A. Bharath, and S. Fotiadis, “Simulating Continuum Mechanics with Multi-Scale\nGraph Neural Networks,” June 2021.\n45\n[169] M. Alfarraj and G. AlRegib, “Petrophysical-property estimation from seismic data using recurrent neural\nnetworks,” in SEG Technical Program Expanded Abstracts 2018, (Anaheim, California), pp. 2141–2146, Society\nof Exploration Geophysicists, Aug. 2018.\n[170] A. Adler, M. Araya-Polo, and T. Poggio, “Deep Recurrent Architectures for Seismic Tomography,” in 81st\nEAGE Conference and Exhibition 2019, pp. 1–5, 2019.\n[171] G. Fabien-Ouellet and R. Sarkar, “Seismic velocity estimation: A deep recurrent neural-network approach,”\nGEOPHYSICS, vol. 85, pp. U21–U29, Jan. 2020.\n[172] P. R. Vlachas, W. Byeon, Z. Y. Wan, T. P. Sapsis, and P. Koumoutsakos, “Data-driven forecasting of high-\ndimensional chaotic systems with long short-term memory networks,” Proceedings of the Royal Society A:\nMathematical, Physical and Engineering Sciences, vol. 474, p. 20170844, May 2018.\n[173] W. Hou, D. Darakananda, and J. Eldredge, “Machine Learning Based Detection of Flow Disturbances Using\nSurface Pressure Measurements,” in AIAA Scitech 2019 Forum, (San Diego, California), American Institute of\nAeronautics and Astronautics, Jan. 2019.\n[174] L. Heindel, P. Hantschke, and M. Kstner, “A Virtual Sensing approach for approximating nonlinear dynamical\nsystems using LSTM networks,” PAMM, vol. 21, p. e202100119, Dec. 2021.\n[175] L. Heindel, P. Hantschke, and M. Kstner, “A data-driven approach for approximating non-linear dynamic\nsystems using LSTM networks,” Procedia Structural Integrity, vol. 38, pp. 159–167, Jan. 2022.\n[176] S. Freitag, B. T. Cao, J. Nini, and G. Meschke, “Recurrent neural networks and proper orthogonal decomposi-\ntion with interval data for real-time predictions of mechanised tunnelling processes,” Computers & Structures,\nvol. 207, pp. 258–273, Sept. 2018.\n[177] B. T. Cao, M. Obel, S. Freitag, P. Mark, and G. Meschke, “Artificial neural network surrogate modelling for\nreal-time predictions and control of building damage during mechanised tunnelling,” Advances in Engineering\nSoftware, vol. 149, p. 102869, Nov. 2020.\n[178] B. T. Cao, M. Obel, S. Freitag, L. Heuner, G. Meschke, and P. Mark, “Real-Time Risk Assessment of Tunneling-\nInduced Building Damage Considering Polymorphic Uncertainty,” ASCE-ASME Journal of Risk and Uncer-\ntainty in Engineering Systems, Part A: Civil Engineering, vol. 8, p. 04021069, Mar. 2022.\n[179] A. Gruber, M. Gunzburger, L. Ju, and Z. Wang, “A comparison of neural network architectures for data-driven\nreduced-order modeling,” Computer Methods in Applied Mechanics and Engineering, vol. 393, p. 114764, Apr.\n2022.\n[180] F. J. Gonzalez and M. Balajewicz, “Deep convolutional recurrent autoencoders for learning low-dimensional\nfeature dynamics of fluid systems,” Aug. 2018. arXiv:1808.01346 [physics].\n[181] D. Holden, B. C. Duong, S. Datta, and D. Nowrouzezahrai, “Subspace neural physics: fast data-driven interac-\ntive simulation,” in Proceedings of the 18th annual ACM SIGGRAPH/Eurographics Symposium on Computer\nAnimation, SCA ’19, (New York, NY, USA), pp. 1–12, Association for Computing Machinery, July 2019.\n[182] S. Fresca, A. Manzoni, L. Ded, and A. Quarteroni, “Deep learning-based reduced order models in cardiac\nelectrophysiology,” PLOS ONE, vol. 15, p. e0239416, Oct. 2020.\n[183] S. Fresca, L. Dede, and A. Manzoni, “A Comprehensive Deep Learning-Based Approach to Reduced Order\nModeling of Nonlinear Time-Dependent Parametrized PDEs,” Journal of Scientific Computing, vol. 87, p. 61,\nApr. 2021.\n[184] S. Fresca and A. Manzoni, “POD-DL-ROM: Enhancing deep learning-based reduced order models for nonlin-\near parametrized PDEs by proper orthogonal decomposition,” Computer Methods in Applied Mechanics and\nEngineering, vol. 388, p. 114181, Jan. 2022.\n[185] P. Ren, C. Rao, Y. Liu, J.-X. Wang, and H. Sun, “PhyCRNet: Physics-informed convolutional-recurrent\nnetwork for solving spatiotemporal PDEs,” Computer Methods in Applied Mechanics and Engineering, vol. 389,\np. 114399, Feb. 2022.\n[186] C. Hu, S. Martin, and R. Dingreville, “Accelerating phase-field predictions via recurrent neural networks learn-\ning the microstructure evolution in latent space,” Computer Methods in Applied Mechanics and Engineering,\nvol. 397, p. 115128, July 2022.\n[187] K. Lee and K. T. Carlberg, “Model reduction of dynamical systems on nonlinear manifolds using deep convo-\nlutional autoencoders,” Journal of Computational Physics, vol. 404, p. 108973, Mar. 2020.\n[188] S. Shen, Y. Yin, T. Shao, H. Wang, C. Jiang, L. Lan, and K. Zhou, “High-order Differentiable Autoencoder\nfor Nonlinear Model Reduction,” Feb. 2021. arXiv:2102.11026 [cs].\n[189] P. J. Schmid, “Dynamic mode decomposition of numerical and experimental data,” Journal of Fluid Mechanics,\nvol. 656, pp. 5–28, Aug. 2010.\n[190] J. H. Tu, C. W. Rowley, D. M. Luchtenburg, S. L. Brunton, and J. N. Kutz, “On Dynamic Mode Decomposition:\nTheory and Applications,” Nov. 2013. arXiv:1312.0041 [physics].\n[191] S. L. Brunton and J. N. Kutz, “Data Driven Science & Engineering,” p. 572, 2017.\n[192] B. O. Koopman, “Hamiltonian Systems and Transformation in Hilbert Space,” Proceedings of the National\nAcademy of Sciences, vol. 17, pp. 315–318, May 1931.\n[193] M. O. Williams, I. G. Kevrekidis, and C. W. Rowley, “A DataDriven Approximation of the Koopman Operator:\nExtending Dynamic Mode Decomposition,” Journal of Nonlinear Science, vol. 25, pp. 1307–1346, Dec. 2015.\n[194] Q. Li, F. Dietrich, E. M. Bollt, and I. G. Kevrekidis, “Extended dynamic mode decomposition with dictionary\nlearning: A data-driven adaptive spectral decomposition of the Koopman operator,” Chaos: An Interdisci-\nplinary Journal of Nonlinear Science, vol. 27, p. 103111, Oct. 2017.\n[195] E. Yeung, S. Kundu, and N. Hodas, “Learning Deep Neural Network Representations for Koopman Operators\nof Nonlinear Dynamical Systems,” in 2019 American Control Conference (ACC), pp. 4832–4839, July 2019.\nISSN: 2378-5861.\n[196] N. Takeishi, Y. Kawahara, and T. Yairi, “Learning Koopman invariant subspaces for dynamic mode decomposi-\ntion,” in Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS’17,\n46\n(Red Hook, NY, USA), pp. 1130–1140, Curran Associates Inc., Dec. 2017.\n[197] J. Morton, F. D. Witherden, A. Jameson, and M. J. Kochenderfer, “Deep dynamical modeling and control of\nunsteady fluid flows,” in Proceedings of the 32nd International Conference on Neural Information Processing\nSystems, NIPS’18, (Red Hook, NY, USA), pp. 9278–9288, Curran Associates Inc., Dec. 2018.\n[198] B. Lusch, J. N. Kutz, and S. L. Brunton, “Deep learning for universal linear embeddings of nonlinear dynamics,”\nNature Communications, vol. 9, p. 4950, Nov. 2018.\n[199] S. E. Otto and C. W. Rowley, “Linearly Recurrent Autoencoder Networks for Learning Dynamics,” SIAM\nJournal on Applied Dynamical Systems, vol. 18, pp. 558–593, Jan. 2019.\n[200] D. C. Psichogios and L. H. Ungar, “A hybrid neural network-first principles approach to process modeling,”\nAIChE Journal, vol. 38, pp. 1499–1511, Oct. 1992.\n[201] M. W. M. G. Dissanayake and N. Phan-Thien, “Neural-network-based approximations for solving partial dif-\nferential equations,” Communications in Numerical Methods in Engineering, vol. 10, pp. 195–201, Mar. 1994.\n[202] I. Lagaris, A. Likas, and D. Fotiadis, “Artificial neural networks for solving ordinary and partial differential\nequations,” IEEE Transactions on Neural Networks, vol. 9, pp. 987–1000, Sept. 1998.\n[203] M. Raissi, “Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Dierential Equations,” 2018.\n[204] G. E. Karniadakis, I. G. Kevrekidis, L. Lu, P. Perdikaris, S. Wang, and L. Yang, “Physics-informed machine\nlearning,” Nature Reviews Physics, vol. 3, pp. 422–440, June 2021.\n[205] S. Cuomo, V. S. di Cola, F. Giampaolo, G. Rozza, M. Raissi, and F. Piccialli, “Scientific Machine Learning\nthrough Physics-Informed Neural Networks: Where we are and What’s next,” arXiv:2201.05624 [physics], Jan.\n2022. arXiv: 2201.05624.\n[206] Z. Hao, S. Liu, Y. Zhang, C. Ying, Y. Feng, H. Su, and J. Zhu, “Physics-Informed Machine Learning: A Survey\non Problems, Methods and Applications,” Nov. 2022.\n[207] E. Haghighat and R. Juanes, “SciANN: A Keras/TensorFlow wrapper for scientific computations and physics-\ninformed deep learning using artificial neural networks,” Computer Methods in Applied Mechanics and Engi-\nneering, vol. 373, p. 113552, Jan. 2021.\n[208] O. Hennigh, S. Narasimhan, M. A. Nabian, A. Subramaniam, K. Tangsali, Z. Fang, M. Rietmann, W. Byeon,\nand S. Choudhry, “NVIDIA SimNet: An AI-Accelerated Multi-Physics Simulation Framework,” in Computa-\ntional Science ICCS 2021 (M. Paszynski, D. Kranzlmller, V. V. Krzhizhanovskaya, J. J. Dongarra, and P. M.\nSloot, eds.), Lecture Notes in Computer Science, (Cham), pp. 447–461, Springer International Publishing, 2021.\n[209] L. Lu, X. Meng, Z. Mao, and G. E. Karniadakis, “DeepXDE: A Deep Learning Library for Solving Differential\nEquations,” SIAM Review, vol. 63, pp. 208–228, Jan. 2021.\n[210] A. G. Baydin, B. A. Pearlmutter, A. A. Radul, and J. M. Siskind, “Automatic Dierentiation in Machine\nLearning: a Survey,” Journal of Machine Learning Research, p. 43, 2018.\n[211] Z. Cai, J. Chen, M. Liu, and X. Liu, “Deep least-squares methods: An unsupervised learning-based numerical\nmethod for solving elliptic PDEs,” Journal of Computational Physics, vol. 420, p. 109707, Nov. 2020.\n[212] J. Sirignano and K. Spiliopoulos, “DGM: A deep learning algorithm for solving partial differential equations,”\nJournal of Computational Physics, vol. 375, pp. 1339–1364, Dec. 2018. arXiv: 1708.07469.\n[213] E. Kharazmi, Z. Zhang, and G. E. Karniadakis, “Variational Physics-Informed Neural Networks For Solving\nPartial Differential Equations,” arXiv:1912.00873 [physics, stat], Nov. 2019. arXiv: 1912.00873.\n[214] E. Kharazmi, Z. Zhang, and G. E. M. Karniadakis, “hp-VPINNs: Variational physics-informed neural networks\nwith domain decomposition,” Computer Methods in Applied Mechanics and Engineering, vol. 374, p. 113547,\nFeb. 2021.\n[215] W. J. Morokoff and R. E. Caflisch, “Quasi-Monte Carlo Integration,” Journal of Computational Physics,\nvol. 122, pp. 218–230, Dec. 1995.\n[216] “14 - Monte carlo integration I: Basic concepts,” in Physically Based Rendering (M. Pharr and G. Humphreys,\neds.), pp. 631–660, Burlington: Morgan Kaufmann, Jan. 2004.\n[217] E. Novak and K. Ritter, “High dimensional integration of smooth functions over cubes,” Numerische Mathe-\nmatik, vol. 75, pp. 79–97, Nov. 1996.\n[218] J. A. Rivera, J. M. Taylor, A. J. Omella, and D. Pardo, “On quadrature rules for solving Partial Differen-\ntial Equations using Neural Networks,” Computer Methods in Applied Mechanics and Engineering, vol. 393,\np. 114710, Apr. 2022.\n[219] Y. Zang, G. Bao, X. Ye, and H. Zhou, “Weak adversarial networks for high-dimensional partial differential\nequations,” Journal of Computational Physics, vol. 411, p. 109409, June 2020.\n[220] V. M. Nguyen-Thanh, X. Zhuang, and T. Rabczuk, “A deep energy method for finite deformation hyperelas-\nticity,” European Journal of Mechanics - A/Solids, p. 103874, Oct. 2019.\n[221] W. E and B. Yu, “The Deep Ritz Method: A Deep Learning-Based Numerical Algorithm for Solving Variational\nProblems,” Communications in Mathematics and Statistics, vol. 6, pp. 1–12, Mar. 2018.\n[222] T. G. Grossmann, U. J. Komorowska, J. Latz, and C.-B. Schnlieb, “Can Physics-Informed Neural Networks\nbeat the Finite Element Method?,” Feb. 2023.\n[223] A. Kashefi and T. Mukerji, “Physics-informed PointNet: A deep learning solver for steady-state incompressible\nflows and thermal fields on multiple sets of irregular geometries,” Journal of Computational Physics, vol. 468,\np. 111510, Nov. 2022.\n[224] J. Berg and K. Nystrm, “A unified deep artificial neural network approach to partial differential equations in\ncomplex geometries,” Neurocomputing, vol. 317, pp. 28–41, Nov. 2018. arXiv: 1711.06464.\n[225] A. Henkes, H. Wessels, and R. Mahnken, “Physics informed neural networks for continuum micromechanics,”\nComputer Methods in Applied Mechanics and Engineering, vol. 393, p. 114790, Apr. 2022.\n[226] I. Lagaris, A. Likas, and D. Papageorgiou, “Neural-network methods for boundary value problems with irregular\nboundaries,” IEEE Transactions on Neural Networks, vol. 11, pp. 1041–1049, Sept. 2000.\n47\n[227] S. Ferrari and M. Jensenius, “A Constrained Optimization Approach to Preserving Prior Knowledge During\nIncremental Training,” IEEE Transactions on Neural Networks, vol. 19, pp. 996–1009, June 2008.\n[228] K. Rudd, G. D. Muro, and S. Ferrari, “A Constrained Backpropagation Approach for the Adaptive Solution\nof Partial Differential Equations,” IEEE Transactions on Neural Networks and Learning Systems, vol. 25,\npp. 571–584, Mar. 2014.\n[229] K. Rudd and S. Ferrari, “A constrained integration (CINT) approach to solving partial differential equations\nusing artificial neural networks,” Neurocomputing, vol. 155, pp. 277–285, May 2015.\n[230] F. Wang, M. Jiang, C. Qian, S. Yang, C. Li, H. Zhang, X. Wang, and X. Tang, “Residual Attention Network\nfor Image Classification,” in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),\npp. 6450–6458, July 2017. ISSN: 1063-6919.\n[231] S. Zhang, J. Yang, and B. Schiele, “Occluded Pedestrian Detection Through Guided Attention in CNNs,” in\n2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6995–7003, June 2018. ISSN:\n2575-7075.\n[232] J. Magiera, D. Ray, J. S. Hesthaven, and C. Rohde, “Constraint-aware neural networks for Riemann problems,”\nJournal of Computational Physics, vol. 409, p. 109345, May 2020.\n[233] Y. Nandwani, A. Pathak, Mausam, and P. Singla, “A Primal Dual Formulation For Deep Learning With\nConstraints,” in Advances in Neural Information Processing Systems, vol. 32, Curran Associates, Inc., 2019.\n[234] L. McClenny and U. Braga-Neto, “Self-Adaptive Physics-Informed Neural Networks using a Soft Attention\nMechanism,” Apr. 2022. arXiv:2009.04544 [cs, stat].\n[235] L. Lu, R. Pestourie, W. Yao, Z. Wang, F. Verdugo, and S. G. Johnson, “Physics-Informed Neural Networks\nwith Hard Constraints for Inverse Design,” SIAM Journal on Scientific Computing, vol. 43, pp. B1105–B1132,\nJan. 2021.\n[236] Q. Zeng, Y. Kothari, S. H. Bryngelson, and F. Schfer, “Competitive Physics Informed Networks,” Oct. 2022.\narXiv:2204.11144 [cs, math].\n[237] P. Moser, W. Fenz, S. Thumfart, I. Ganitzer, and M. Giretzlehner, “Modeling of 3D Blood Flows with Physics-\nInformed Neural Networks: Comparison of Network Architectures,” Fluids, vol. 8, p. 46, Jan. 2023.\n[238] Y. Zhu, N. Zabaras, P.-S. Koutsourelakis, and P. Perdikaris, “Physics-Constrained Deep Learning for High-\ndimensional Surrogate Modeling and Uncertainty Quantification without Labeled Data,” Journal of Computa-\ntional Physics, vol. 394, pp. 56–81, Oct. 2019. arXiv: 1901.06314.\n[239] J. Han, J. Tao, and C. Wang, “FlowNet: A Deep Learning Framework for Clustering and Selection of Stream-\nlines and Stream Surfaces,” IEEE Transactions on Visualization and Computer Graphics, vol. 26, pp. 1732–\n1744, Apr. 2020.\n[240] S. Bhatnagar, Y. Afshar, S. Pan, K. Duraisamy, and S. Kaushik, “Prediction of aerodynamic flow fields using\nconvolutional neural networks,” Computational Mechanics, vol. 64, pp. 525–545, Aug. 2019.\n[241] H. Gao, L. Sun, and J.-X. Wang, “PhyGeoNet: Physics-informed geometry-adaptive convolutional neural\nnetworks for solving parameterized steady-state PDEs on irregular domain,” Journal of Computational Physics,\nvol. 428, p. 110079, Mar. 2021.\n[242] N. Wandel, M. Weinmann, M. Neidlin, and R. Klein, “Spline-PINN: Approaching PDEs without Data using\nFast, Physics-Informed Hermite-Spline CNNs,” Mar. 2022. arXiv:2109.07143 [physics].\n[243] H. Gao, M. J. Zahr, and J.-X. Wang, “Physics-informed graph neural Galerkin networks: A unified frame-\nwork for solving PDE-governed forward and inverse problems,” Computer Methods in Applied Mechanics and\nEngineering, vol. 390, p. 114502, Feb. 2022.\n[244] M. Mller, D. Toshniwal, and F. Van Ruiten, “Physics-Informed Machine Learning Embedded into Isogeometric\nAnalysis,” Mathematics: Key enabling technology for scientific machine learning, 2021.\n[245] T. J. R. Hughes, J. A. Cottrell, and Y. Bazilevs, “Isogeometric analysis: CAD, finite elements, NURBS,\nexact geometry and mesh refinement,” Computer Methods in Applied Mechanics and Engineering, vol. 194,\npp. 4135–4195, Oct. 2005.\n[246] R. E. Meethal, B. Obst, M. Khalil, A. Ghantasala, A. Kodakkal, K.-U. Bletzinger, and R. Wchner, “Finite\nElement Method-enhanced Neural Network for Forward and Inverse Problems,” May 2022. arXiv:2205.08321\n[cs, math].\n[247] T. J. R. Hughes, The finite element method: linear static and dynamic finite element analysis. Mineola, NY:\nDover Publications, 2000.\n[248] K.-J. Bathe, Finite element procedures.\nEnglewood Cliffs, N.J: Prentice-Hall, 2nd ed ed., 2014.\nOCLC:\nocn930843107.\n[249] S. Berrone, C. Canuto, and M. Pintore, “Variational Physics Informed Neural Networks: the Role of Quadra-\ntures and Test Functions,” Journal of Scientific Computing, vol. 92, p. 100, Aug. 2022.\n[250] S. Badia, W. Li, and A. F. Martn, “Finite element interpolated neural networks for solving forward and inverse\nproblems,” June 2023. arXiv:2306.06304 [cs, math].\n[251] A. Yazdani, L. Lu, M. Raissi, and G. E. Karniadakis, “Systems biology informed deep learning for inferring\nparameters and hidden dynamics,” PLOS Computational Biology, vol. 16, p. e1007575, Nov. 2020.\n[252] C. Uriarte, D. Pardo, and A. J. Omella, “A Finite Element based Deep Learning solver for parametric PDEs,”\nComputer Methods in Applied Mechanics and Engineering, vol. 391, p. 114562, Mar. 2022.\n[253] A. D. Jagtap, E. Kharazmi, and G. E. Karniadakis, “Conservative physics-informed neural networks on discrete\ndomains for conservation laws: Applications to forward and inverse problems,” Computer Methods in Applied\nMechanics and Engineering, vol. 365, p. 113028, June 2020.\n[254] K. Shukla, A. D. Jagtap, and G. E. Karniadakis, “Parallel physics-informed neural networks via domain\ndecomposition,” Journal of Computational Physics, vol. 447, p. 110683, Dec. 2021.\n[255] A. D. J. . G. E. Karniadakis, “Extended Physics-Informed Neural Networks (XPINNs): A Generalized Space-\nTime Domain Decomposition Based Deep Learning Framework for Nonlinear Partial Differential Equations,”\n48\nCommunications in Computational Physics, vol. 28, pp. 2002–2041, June 2020.\n[256] X. Chen, C. Gong, Q. Wan, L. Deng, Y. Wan, Y. Liu, B. Chen, and J. Liu, “Transfer learning for deep neural\nnetwork-based partial differential equations solving,” Advances in Aerodynamics, vol. 3, p. 36, Dec. 2021.\n[257] S. Goswami, C. Anitescu, S. Chakraborty, and T. Rabczuk, “Transfer learning enhanced physics informed neural\nnetwork for phase-field modeling of fracture,” arXiv:1907.02531 [cs, stat], July 2019. arXiv: 1907.02531.\n[258] J. He, C. Chadha, S. Kushwaha, S. Koric, D. Abueidda, and I. Jasiuk, “Deep energy method in topology\noptimization applications,” Acta Mechanica, vol. 234, pp. 1365–1379, Apr. 2023.\n[259] M. A. Nabian, R. J. Gladstone, and H. Meidani, “Efficient training of physicsinformed neural networks via\nimportance sampling,” Computer-Aided Civil and Infrastructure Engineering, vol. 36, pp. 962–977, Aug. 2021.\n[260] J. M. Hanna, J. V. Aguado, S. Comas-Cardona, R. Askri, and D. Borzacchiello, “Residual-based adaptivity\nfor two-phase flow simulation in porous media using Physics-informed Neural Networks,” Computer Methods\nin Applied Mechanics and Engineering, vol. 396, p. 115100, June 2022.\n[261] S. Kollmannsberger, D. DAngella, M. Jokeit, and L. Herrmann, “Physics-Informed Neural Networks,” in Deep\nLearning in Computational Mechanics, vol. 977, pp. 55–84, Cham: Springer International Publishing, 2021.\nSeries Title: Studies in Computational Intelligence.\n[262] D. Anton and H. Wessels, “Identification of Material Parameters from Full-Field Displacement Data Using\nPhysics-Informed Neural Networks,” 2021.\n[263] Y. Zong, Q. He, and A. M. Tartakovsky, “Improved training of physics-informed neural networks for parabolic\ndifferential equations with sharply perturbed initial conditions,” Computer Methods in Applied Mechanics and\nEngineering, vol. 414, p. 116125, Sept. 2023.\n[264] J. Yu, L. Lu, X. Meng, and G. E. Karniadakis, “Gradient-enhanced physics-informed neural networks for\nforward and inverse PDE problems,” Computer Methods in Applied Mechanics and Engineering, vol. 393,\np. 114823, Apr. 2022.\n[265] J. M. Taylor, D. Pardo, and I. Muga, “A Deep Fourier Residual method for solving PDEs using Neural\nNetworks,” Computer Methods in Applied Mechanics and Engineering, vol. 405, p. 115850, Feb. 2023.\n[266] P.-H. Chiu, J. C. Wong, C. Ooi, M. H. Dao, and Y.-S. Ong, “CAN-PINN: A fast physics-informed neural network\nbased on coupled-automaticnumerical differentiation method,” Computer Methods in Applied Mechanics and\nEngineering, vol. 395, p. 114909, May 2022.\n[267] A. D. Jagtap and G. E. Karniadakis, “Adaptive activation functions accelerate convergence in deep and\nphysics-informed neural networks,” Journal of Computational Physics, vol. 404, p. 109136, Mar. 2020. arXiv:\n1906.01170.\n[268] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew, “Extreme learning machine: Theory and applications,” Neurocom-\nputing, vol. 70, pp. 489–501, Dec. 2006.\n[269] G.-B. Huang, D. H. Wang, and Y. Lan, “Extreme learning machines: a survey,” International Journal of\nMachine Learning and Cybernetics, vol. 2, pp. 107–122, June 2011.\n[270] S. Dong and Z. Li, “Local extreme learning machines and domain decomposition for solving linear and nonlinear\npartial differential equations,” Computer Methods in Applied Mechanics and Engineering, vol. 387, p. 114129,\nDec. 2021.\n[271] S. Dong and J. Yang, “Numerical approximation of partial differential equations by a variable projection method\nwith artificial neural networks,” Computer Methods in Applied Mechanics and Engineering, vol. 398, p. 115284,\nAug. 2022.\n[272] E. Haghighat, M. Raissi, A. Moure, H. Gomez, and R. Juanes, “A physics-informed deep learning frame-\nwork for inversion and surrogate modeling in solid mechanics,” Computer Methods in Applied Mechanics and\nEngineering, vol. 379, p. 113741, June 2021.\n[273] J. Bai, H. Jeong, C. P. Batuwatta-Gamage, S. Xiao, Q. Wang, C. M. Rathnayaka, L. Alzubaidi, G.-R. Liu,\nand Y. Gu, “An Introduction to Programming Physics-Informed Neural Network-Based Computational Solid\nMechanics,” International Journal of Computational Methods, p. 2350013, May 2023.\n[274] G. Kissas, Y. Yang, E. Hwuang, W. R. Witschey, J. A. Detre, and P. Perdikaris, “Machine learning in cardio-\nvascular flows modeling: Predicting arterial blood pressure from non-invasive 4D flow MRI data using physics-\ninformed neural networks,” Computer Methods in Applied Mechanics and Engineering, vol. 358, p. 112623, Jan.\n2020.\n[275] M. Raissi, A. Yazdani, and G. E. Karniadakis, “Hidden fluid mechanics: Learning velocity and pressure fields\nfrom flow visualizations,” Science, vol. 367, pp. 1026–1030, Feb. 2020.\n[276] L. Sun, H. Gao, S. Pan, and J.-X. Wang, “Surrogate modeling for fluid flows based on physics-constrained\ndeep learning without simulation data,” Computer Methods in Applied Mechanics and Engineering, vol. 361,\np. 112732, Apr. 2020.\n[277] X. Jin, S. Cai, H. Li, and G. E. Karniadakis, “NSFnets (Navier-Stokes flow nets): Physics-informed neural net-\nworks for the incompressible Navier-Stokes equations,” Journal of Computational Physics, vol. 426, p. 109951,\nFeb. 2021.\n[278] S. Cai, Z. Wang, F. Fuest, Y. J. Jeon, C. Gray, and G. E. Karniadakis, “Flow over an espresso cup: inferring\n3-D velocity and pressure fields from tomographic background oriented Schlieren via physics-informed neural\nnetworks,” Journal of Fluid Mechanics, vol. 915, p. A102, May 2021.\n[279] C. G. Fraces and H. Tchelepi, “Physics Informed Deep Learning for Flow and Transport in Porous Media,”\nOnePetro, Oct. 2021.\n[280] W. Zhang, D. S. Li, T. Bui-Thanh, and M. S. Sacks, “Simulation of the 3D hyperelastic behavior of ventricular\nmyocardium using a finite-element based neural-network approach,” Computer Methods in Applied Mechanics\nand Engineering, vol. 394, p. 114871, May 2022.\n[281] J. C. H. Wang and J.-P. Hickey, “FluxNet: A physics-informed learning-based Riemann solver for transcritical\nflows with non-ideal thermodynamics,” Computer Methods in Applied Mechanics and Engineering, vol. 411,\n49\np. 116070, June 2023.\n[282] S. Amini Niaki, E. Haghighat, T. Campbell, A. Poursartip, and R. Vaziri, “Physics-informed neural network\nfor modelling the thermochemical curing process of composite-tool systems during manufacture,” Computer\nMethods in Applied Mechanics and Engineering, vol. 384, p. 113959, Oct. 2021.\n[283] Q. Zhu, Z. Liu, and J. Yan, “Machine learning for metal additive manufacturing: predicting temperature\nand melt pool fluid dynamics using physics-informed neural networks,” Computational Mechanics, vol. 67,\npp. 619–635, Feb. 2021.\n[284] S. Markidis, “The Old and the New:\nCan Physics-Informed Deep-Learning Replace Traditional Linear\nSolvers?,” Frontiers in Big Data, vol. 4, 2021.\n[285] L. Li, Y. Li, Q. Du, T. Liu, and Y. Xie, “ReF-nets: Physics-informed neural network for Reynolds equation of\ngas bearing,” Computer Methods in Applied Mechanics and Engineering, vol. 391, p. 114524, Mar. 2022.\n[286] Y. Chen, L. Lu, G. E. Karniadakis, and L. D. Negro, “Physics-informed neural networks for inverse problems\nin nano-optics and metamaterials,” Optics Express, vol. 28, p. 11618, Apr. 2020.\n[287] R. Zhang, Y. Liu, and H. Sun, “Physics-Informed Multi-LSTM Networks for Metamodeling of Nonlinear\nStructures,” Computer Methods in Applied Mechanics and Engineering, vol. 369, p. 113226, Sept. 2020. arXiv:\n2002.10253.\n[288] K. Shukla, P. C. Di Leoni, J. Blackshire, D. Sparkman, and G. E. Karniadakis, “Physics-Informed Neural\nNetwork for Ultrasound Nondestructive Quantification of Surface Breaking Cracks,” Journal of Nondestructive\nEvaluation, vol. 39, p. 61, Aug. 2020.\n[289] D. Anton and H. Wessels, “Physics-Informed Neural Networks for Material Model Calibration from Full-Field\nDisplacement Data,” Dec. 2022.\n[290] L. Herrmann, T. Brchner, F. Dietrich, and S. Kollmannsberger, “On the use of neural networks for full waveform\ninversion,” Computer Methods in Applied Mechanics and Engineering, vol. 415, p. 116278, Oct. 2023.\n[291] C. J. G. Rojas, M. L. Bitterncourt, and J. L. Boldrini, “Parameter identification for a damage model using a\nphysics informed neural network,” June 2021.\n[292] W. Li and K.-M. Lee, “Physics informed neural network for parameter identification and boundary force estima-\ntion of compliant and biomechanical systems,” International Journal of Intelligent Robotics and Applications,\nvol. 5, pp. 313–325, Sept. 2021.\n[293] E. Zhang, M. Dao, G. E. Karniadakis, and S. Suresh, “Analyses of internal structures and defects in materials\nusing physics-informed neural networks,” Science Advances, vol. 8, p. eabk0644, Feb. 2022.\n[294] I. Depina, S. Jain, S. Mar Valsson, and H. Gotovac, “Application of physics-informed neural networks to inverse\nproblems in unsaturated groundwater flow,” Georisk: Assessment and Management of Risk for Engineered\nSystems and Geohazards, vol. 16, pp. 21–36, Jan. 2022.\n[295] C. Xu, B. T. Cao, Y. Yuan, and G. Meschke, “Transfer learning based physics-informed neural networks for\nsolving inverse problems in engineering structures under different loading scenarios,” Computer Methods in\nApplied Mechanics and Engineering, vol. 405, p. 115852, Feb. 2023.\n[296] Y. Sun, U. Sengupta, and M. Juniper, “Physics-informed deep learning for simultaneous surrogate model-\ning and PDE-constrained optimization of an airfoil geometry,” Computer Methods in Applied Mechanics and\nEngineering, vol. 411, p. 116042, June 2023.\n[297] M. RashtBehesht, C. Huber, K. Shukla, and G. E. Karniadakis, “PhysicsInformed Neural Networks (PINNs)\nfor Wave Propagation and Full Waveform Inversions,” Journal of Geophysical Research: Solid Earth, vol. 127,\nMay 2022.\n[298] J. Zehnder, Y. Li, S. Coros, and B. Thomaszewski, “NTopo: Mesh-free Topology Optimization using Implicit\nNeural Representations,” Nov. 2021.\n[299] D. Di Lorenzo, V. Champaney, J. Y. Marzin, C. Farhat, and F. Chinesta, “Physics informed and data-based\naugmented learning in structural health diagnosis,” Computer Methods in Applied Mechanics and Engineering,\nvol. 414, p. 116186, Sept. 2023.\n[300] J. Berg and K. Nystrm, “Data-driven discovery of PDEs in complex datasets,” Journal of Computational\nPhysics, vol. 384, pp. 239–252, May 2019.\n[301] S.-M. Udrescu and M. Tegmark, “AI Feynman: A physics-inspired method for symbolic regression,” Science\nAdvances, vol. 6, p. eaay2631, Apr. 2020.\n[302] R. P. Feynman, R. B. Leighton, and M. L. Sands, The Feynman lectures on physics. New York: Basic Books,\nnew millennium ed ed., 2011. OCLC: ocn671704374.\n[303] X. Meng, Z. Li, D. Zhang, and G. E. Karniadakis, “PPINN: Parareal physics-informed neural network for\ntime-dependent PDEs,” Computer Methods in Applied Mechanics and Engineering, vol. 370, p. 113250, Oct.\n2020.\n[304] R. Mattey and S. Ghosh, “A novel sequential method to train physics informed neural networks for Allen Cahn\nand Cahn Hilliard equations,” Computer Methods in Applied Mechanics and Engineering, vol. 390, p. 114474,\nFeb. 2022.\n[305] A. Iserles, A First Course in the Numerical Analysis of Differential Equations. Cambridge University Press,\nNov. 2008. Google-Books-ID: 3acgAwAAQBAJ.\n[306] H. Wessels, C. Weienfels, and P. Wriggers, “The neural particle method\nAn updated Lagrangian physics\ninformed neural network for computational fluid dynamics,” Computer Methods in Applied Mechanics and\nEngineering, vol. 368, p. 113127, Aug. 2020.\n[307] J. Bai, Y. Zhou, Y. Ma, H. Jeong, H. Zhan, C. Rathnayaka, E. Sauret, and Y. Gu, “A general Neural Particle\nMethod for hydrodynamics modeling,” Computer Methods in Applied Mechanics and Engineering, vol. 393,\np. 114740, Apr. 2022.\n[308] R. Gonzlez-Garca, R. Rico-Martnez, and I. G. Kevrekidis, “Identification of distributed parameter systems: A\nneural net based approach,” Computers & Chemical Engineering, vol. 22, pp. S965–S968, Mar. 1998.\n50\n[309] Z. Long, Y. Lu, X. Ma, and B. Dong, “PDE-Net: Learning PDEs from Data,” arXiv:1710.09668 [cs, math,\nstat], Jan. 2018. arXiv: 1710.09668.\n[310] Z. Long, Y. Lu, and B. Dong, “PDE-Net 2.0: Learning PDEs from data with a numeric-symbolic hybrid deep\nnetwork,” Journal of Computational Physics, vol. 399, p. 108925, Dec. 2019.\n[311] B.-S. Hua,\nM.-K. Tran,\nand S.-K. Yeung,\n“Pointwise Convolutional Neural Networks,”\nMar. 2018.\narXiv:1712.05245 [cs].\n[312] S. L. Brunton, J. L. Proctor, and J. N. Kutz, “Discovering governing equations from data by sparse identification\nof nonlinear dynamical systems,” Proceedings of the National Academy of Sciences, vol. 113, pp. 3932–3937,\nApr. 2016.\n[313] S. H. Rudy, S. L. Brunton, J. L. Proctor, and J. N. Kutz, “Data-driven discovery of partial differential equa-\ntions,” Science Advances, vol. 3, p. e1602614, Apr. 2017.\n[314] H. Schaeffer, “Learning partial differential equations via data discovery and sparse optimization,” Proceedings\nof the Royal Society A: Mathematical, Physical and Engineering Sciences, vol. 473, p. 20160446, Jan. 2017.\n[315] K. Champion, B. Lusch, J. N. Kutz, and S. L. Brunton, “Data-driven discovery of coordinates and governing\nequations,” Proceedings of the National Academy of Sciences, vol. 116, pp. 22445–22451, Nov. 2019.\n[316] P. Conti, G. Gobat, S. Fresca, A. Manzoni, and A. Frangi, “Reduced order modeling of parametrized systems\nthrough autoencoders and SINDy approach: continuation of periodic solutions,” Computer Methods in Applied\nMechanics and Engineering, vol. 411, p. 116072, June 2023.\n[317] B. Kim, V. C. Azevedo, N. Thuerey, T. Kim, M. Gross, and B. Solenthaler, “Deep Fluids: A Generative\nNetwork for Parameterized Fluid Simulations,” Computer Graphics Forum, vol. 38, pp. 59–70, May 2019.\n[318] J. Ling, R. Jones, and J. Templeton, “Machine learning strategies for systems with invariance properties,”\nJournal of Computational Physics, vol. 318, pp. 22–35, Aug. 2016.\n[319] J. Ling, A. Kurzawski, and J. Templeton, “Reynolds averaged turbulence modelling using deep neural networks\nwith embedded invariance,” Journal of Fluid Mechanics, vol. 807, pp. 155–166, Nov. 2016.\n[320] G. F. Smith, “On isotropic integrity bases,” Archive for Rational Mechanics and Analysis, vol. 18, pp. 282–292,\nJan. 1965.\n[321] M. Lutter, K. Listmann, and J. Peters, “Deep Lagrangian Networks for end-to-end learning of energy-based\ncontrol for under-actuated systems,” in 2019 IEEE/RSJ International Conference on Intelligent Robots and\nSystems (IROS), pp. 7718–7725, Nov. 2019. ISSN: 2153-0866.\n[322] M. Lutter, C. Ritter, and J. Peters, “Deep Lagrangian Networks: Using Physics as Model Prior for Deep\nLearning,” July 2019. arXiv:1907.04490 [cs, eess, stat].\n[323] M. Cranmer, S. Greydanus, S. Hoyer, P. Battaglia, D. Spergel, and S. Ho, “Lagrangian Neural Networks,” July\n2020. arXiv:2003.04630 [physics, stat].\n[324] S. Greydanus, M. Dzamba, and J. Yosinski, “Hamiltonian Neural Networks,” Sept. 2019. arXiv:1906.01563\n[cs].\n[325] L. Zhang, F. Yang, Y. Daniel Zhang, and Y. J. Zhu, “Road crack detection using deep convolutional neural\nnetwork,” in 2016 IEEE International Conference on Image Processing (ICIP), pp. 3708–3712, Sept. 2016.\n[326] F.-C. Chen and M. R. Jahanshahi, “NB-CNN: Deep Learning-Based Crack Detection Using Convolutional\nNeural Network and Nave Bayes Data Fusion,” IEEE Transactions on Industrial Electronics, vol. 65, pp. 4392–\n4400, May 2018.\n[327] B. E. Jaeger, S. Schmid, C. U. Grosse, A. Ggelein, and F. Elischberger, “Infrared Thermal Imaging-Based\nTurbine Blade Crack Classification Using Deep Learning,” Journal of Nondestructive Evaluation, vol. 41, p. 74,\nOct. 2022.\n[328] N. Korshunova, J. Jomo, G. Lk, D. Reznik, P. Balzs, and S. Kollmannsberger, “Image-based material charac-\nterization of complex microarchitectured additively manufactured structures,” Computers & Mathematics with\nApplications, vol. 80, pp. 2462–2480, Dec. 2020.\n[329] C. Hall Barbosa, A. Bruno, M. Vellasco, M. Pacheco, J. Wikswo, and A. Ewing, “Automation of SQUlD\nnondestructive evaluation of steel plates by neural networks,” IEEE Transactions on Applied Superconductivity,\nvol. 9, pp. 3475–3478, June 1999.\n[330] O. Ovcharenko, V. Kazei, M. Kalita, D. Peter, and T. Alkhalifah, “Deep learning for low-frequency extrapola-\ntion from multioffset seismic data,” GEOPHYSICS, vol. 84, pp. R989–R1001, Nov. 2019.\n[331] H. Sun and L. Demanet, “Extrapolated full waveform inversion with deep learning,” GEOPHYSICS, vol. 85,\npp. R275–R288, May 2020.\n[332] H. Sun and L. Demanet, “Deep Learning for Low-Frequency Extrapolation of Multicomponent Data in Elastic\nFWI,” IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 1–11, 2022.\n[333] W. Lewis and D. Vigh, “Deep learning prior models from seismic images for full-waveform inversion,” in\nSEG Technical Program Expanded Abstracts 2017, (Houston, Texas), pp. 1512–1517, Society of Exploration\nGeophysicists, Aug. 2017.\n[334] D. Dyck, D. Lowther, and S. McFee, “Determining an approximate finite element mesh density using neural\nnetwork techniques,” IEEE Transactions on Magnetics, vol. 28, pp. 1767–1770, Mar. 1992.\n[335] R. Chedid and N. Najjar, “Automatic finite-element mesh generation using artificial neural networks-Part I:\nPrediction of mesh density,” IEEE Transactions on Magnetics, vol. 32, pp. 5173–5178, Sept. 1996.\n[336] D. G. Triantafyllidis and D. P. Labridis, “An automatic mesh generator for handling small features in open\nboundary power transmission line problems using artificial neural networks,” Communications in Numerical\nMethods in Engineering, vol. 16, pp. 177–190, Mar. 2000.\n[337] Z. Zhang, Y. Wang, P. K. Jimack, and H. Wang, “MeshingNet: A New Mesh Generation Method Based on\nDeep Learning,” in Computational Science\nICCS 2020 (V. V. Krzhizhanovskaya, G. Zvodszky, M. H. Lees,\nJ. J. Dongarra, P. M. A. Sloot, S. Brissos, and J. Teixeira, eds.), vol. 12139, pp. 186–198, Cham: Springer\nInternational Publishing, 2020. Series Title: Lecture Notes in Computer Science.\n51\n[338] C. Lock, O. Hassan, R. Sevilla, and J. Jones, “Meshing using neural networks for improving the efficiency of\ncomputer modelling,” Engineering with Computers, Apr. 2023.\n[339] B. Fritzke, “Growing cell structuresA self-organizing network for unsupervised and supervised learning,” Neural\nNetworks, vol. 7, pp. 1441–1460, Jan. 1994.\n[340] S. Alfonzetti, S. Coco, S. Cavalieri, and M. Malgeri, “Automatic mesh generation by the let-it-grow neural\nnetwork,” IEEE Transactions on Magnetics, vol. 32, pp. 1349–1352, May 1996.\n[341] D. Triantafyllidis and D. Labridis, “A finite-element mesh generator based on growing neural networks,” IEEE\nTransactions on Neural Networks, vol. 13, pp. 1482–1496, Nov. 2002.\n[342] M. Lefik and B. A. Schrefler, “Artificial neural network as an incremental non-linear constitutive model for a\nfinite element code,” Computer Methods in Applied Mechanics and Engineering, vol. 192, pp. 3265–3283, July\n2003.\n[343] D. P. Jang, P. Fazily, and J. W. Yoon, “Machine learning-based constitutive model for J2- plasticity,” Inter-\nnational Journal of Plasticity, vol. 138, p. 102919, Mar. 2021.\n[344] Y. C. Lin, J. Zhang, and J. Zhong, “Application of neural networks to predict the elevated temperature flow\nbehavior of a low alloy steel,” Computational Materials Science, vol. 43, pp. 752–758, Oct. 2008.\n[345] H.-Y. Li, J.-D. Hu, D.-D. Wei, X.-F. Wang, and Y.-H. Li, “Artificial neural network and constitutive equations\nto predict the hot deformation behavior of modified 2.25Cr1Mo steel,” Materials & Design, vol. 42, pp. 192–197,\nDec. 2012.\n[346] D. Liu, H. Yang, K. I. Elkhodary, S. Tang, W. K. Liu, and X. Guo, “Mechanistically informed data-driven\nmodeling of cyclic plasticity via artificial neural networks,” Computer Methods in Applied Mechanics and\nEngineering, vol. 393, p. 114766, Apr. 2022.\n[347] J. F. Unger and C. Knke, “Neural networks as material models within a multiscale approach,” Computers &\nStructures, vol. 87, pp. 1177–1186, Oct. 2009.\n[348] G. Hattori and A. L. Serpa, “Contact stiffness estimation in ANSYS using simplified models and artificial\nneural networks,” Finite Elements in Analysis and Design, vol. 97, pp. 43–53, May 2015.\n[349] A. Oishi and S. Yoshimura, “A New Local Contact Search Method Using a Multi-Layer Neural Network,”\nComputer Modeling in Engineering & Sciences, vol. 21, no. 2, pp. 93–104, 1970.\n[350] A. Oishi and G. Yagawa, “A surface-to-surface contact search method enhanced by deep learning,” Computa-\ntional Mechanics, vol. 65, pp. 1125–1147, Apr. 2020.\n[351] A. P. Singh, S. Medida, and K. Duraisamy, “Machine-Learning-Augmented Predictive Modeling of Turbulent\nSeparated Flows over Airfoils,” AIAA Journal, vol. 55, pp. 2215–2227, July 2017.\n[352] R. Maulik, O. San, A. Rasheed, and P. Vedula, “Subgrid modelling for two-dimensional turbulence using neural\nnetworks,” Journal of Fluid Mechanics, vol. 858, pp. 122–144, Jan. 2019.\n[353] A. Fabra, J. Baiges, and R. Codina, “Finite element approximation of wave problems with correcting terms\nbased on training artificial neural networks with fine solutions,” Computer Methods in Applied Mechanics and\nEngineering, vol. 399, p. 115280, Sept. 2022.\n[354] B. A. Le, J. Yvonnet, and Q. He, “Computational homogenization of nonlinear elastic materials using neural\nnetworks,” International Journal for Numerical Methods in Engineering, vol. 104, pp. 1061–1084, Dec. 2015.\n[355] X. Lu, D. G. Giovanis, J. Yvonnet, V. Papadopoulos, F. Detrez, and J. Bai, “A data-driven computa-\ntional homogenization method based on neural networks for the nonlinear anisotropic electrical response of\ngraphene/polymer nanocomposites,” Computational Mechanics, vol. 64, pp. 307–321, Aug. 2019.\n[356] D. Z. Huang, K. Xu, C. Farhat, and E. Darve, “Learning constitutive relations from indirect observations using\ndeep neural networks,” Journal of Computational Physics, vol. 416, p. 109491, Sept. 2020.\n[357] K. Wang and W. Sun, “A multiscale multi-permeability poroplasticity model linked by recursive homogeniza-\ntions and deep learning,” Computer Methods in Applied Mechanics and Engineering, vol. 334, pp. 337–380,\nJune 2018.\n[358] B. Li and X. Zhuang, “Multiscale computation on feedforward neural network and recurrent neural network,”\nFrontiers of Structural and Civil Engineering, vol. 14, pp. 1285–1298, Dec. 2020.\n[359] N. N. Vlassis, R. Ma, and W. Sun, “Geometric deep learning for computational mechanics Part I: anisotropic\nhyperelasticity,” Computer Methods in Applied Mechanics and Engineering, vol. 371, p. 113299, Nov. 2020.\n[360] I. Frankenreiter, D. Rosato, and C. Miehe, “Hybrid Micro-Macro-Modeling of Evolving Anisotropies and Length\nScales in Finite Plasticity of Polycrystals: Hybrid Micro-Macro-Modeling of Evolving Anisotropies and Length\nScales in Finite Plasticity of Polycrystals,” PAMM, vol. 11, pp. 515–518, Dec. 2011.\n[361] J. Fish, Practical multiscaling. Chichester, West Sussex, United Kingdom: John Wiley & Sons Inc, 2013.\n[362] K. Linka, M. Hillgrtner, K. P. Abdolazizi, R. C. Aydin, M. Itskov, and C. J. Cyron, “Constitutive artificial\nneural networks: A fast and general approach to predictive data-driven constitutive modeling by deep learning,”\nJournal of Computational Physics, vol. 429, p. 110010, Mar. 2021.\n[363] M. Mozaffar, R. Bostanabad, W. Chen, K. Ehmann, J. Cao, and M. A. Bessa, “Deep learning predicts path-\ndependent plasticity,” Proceedings of the National Academy of Sciences, vol. 116, pp. 26414–26420, Dec. 2019.\n[364] L. Wu and L. Noels, “Recurrent Neural Networks (RNNs) with dimensionality reduction and break down in\ncomputational mechanics; application to multi-scale localization step,” Computer Methods in Applied Mechanics\nand Engineering, vol. 390, p. 114476, Feb. 2022.\n[365] D. W. Abueidda, S. Koric, N. A. Sobh, and H. Sehitoglu, “Deep learning for plasticity and thermo-\nviscoplasticity,” International Journal of Plasticity, vol. 136, p. 102852, Jan. 2021.\n[366] Y.-C. Hsu, C.-H. Yu, and M. J. Buehler, “Using Deep Learning to Predict Fracture Patterns in Crystalline\nSolids,” Matter, vol. 3, pp. 197–211, July 2020.\n[367] A. J. Lew, C.-H. Yu, Y.-C. Hsu, and M. J. Buehler, “Deep learning model to predict fracture mechanisms of\ngraphene,” npj 2D Materials and Applications, vol. 5, pp. 1–8, Apr. 2021.\n52\n[368] M. Liu, L. Liang, and W. Sun, “A generic physics-informed neural network-based constitutive model for soft\nbiological tissues,” Computer Methods in Applied Mechanics and Engineering, vol. 372, p. 113402, Dec. 2020.\n[369] P. Weber, J. Geiger, and W. Wagner, “Constrained neural network training and its application to hyperelastic\nmaterial modeling,” Computational Mechanics, vol. 68, pp. 1179–1204, Nov. 2021.\n[370] Y. Leng, V. Tac, S. Calve, and A. B. Tepole, “Predicting the Mechanical Properties of Biopolymer Gels Using\nNeural Networks Trained on Discrete Fiber Network Data,” Computer Methods in Applied Mechanics and\nEngineering, vol. 387, p. 114160, Dec. 2021. arXiv:2101.11712 [cs, q-bio].\n[371] V. Tac, F. Sahli Costabal, and A. B. Tepole, “Data-driven tissue mechanics with polyconvex neural ordinary\ndifferential equations,” Computer Methods in Applied Mechanics and Engineering, vol. 398, p. 115248, Aug.\n2022.\n[372] L. Linden, D. K. Klein, K. A. Kalina, J. Brummund, O. Weeger, and M. Kstner, “Neural networks meet\nhyperelasticity: A guide to enforcing physics,” Feb. 2023. arXiv:2302.02403 [cs].\n[373] D. K. Klein, R. Ortigosa, J. Martnez-Frutos, and O. Weeger, “Finite electro-elasticity with physics-augmented\nneural networks,” Computer Methods in Applied Mechanics and Engineering, vol. 400, p. 115501, Oct. 2022.\n[374] D. K. Klein, M. Fernndez, R. J. Martin, P. Neff, and O. Weeger, “Polyconvex anisotropic hyperelasticity with\nneural networks,” Journal of the Mechanics and Physics of Solids, vol. 159, p. 104703, Feb. 2022.\n[375] F. As’ad and C. Farhat, “A Mechanics-Informed Neural Network Framework for Data-Driven Nonlinear Vis-\ncoelasticity,” in AIAA SCITECH 2023 Forum, (National Harbor, MD & Online), American Institute of Aero-\nnautics and Astronautics, Jan. 2023.\n[376] V. Ta, M. K. Rausch, F. Sahli Costabal, and A. B. Tepole, “Data-driven anisotropic finite viscoelasticity using\nneural ordinary differential equations,” Computer Methods in Applied Mechanics and Engineering, vol. 411,\np. 116046, June 2023.\n[377] B. Amos, L. Xu, and J. Z. Kolter, “Input Convex Neural Networks,” in Proceedings of the 34th International\nConference on Machine Learning, pp. 146–155, PMLR, July 2017.\n[378] R. T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. Duvenaud, “Neural Ordinary Differential Equations,”\narXiv:1806.07366 [cs, stat], Dec. 2019. arXiv: 1806.07366.\n[379] P. Chen and J. Guilleminot, “Polyconvex neural networks for hyperelastic constitutive models: A rectification\napproach,” Mechanics Research Communications, vol. 125, p. 103993, Oct. 2022.\n[380] F. Masi, I. Stefanou, P. Vannucci, and V. Maffi-Berthier, “Thermodynamics-based Artificial Neural Networks\nfor constitutive modeling,” Journal of the Mechanics and Physics of Solids, vol. 147, p. 104277, Feb. 2021.\n[381] F. Masi, I. Stefanou, P. Vannucci, and V. Maffi-Berthier, “Material Modeling via Thermodynamics-Based Ar-\ntificial Neural Networks,” in Geometric Structures of Statistical Physics, Information Geometry, and Learning\n(F. Barbaresco and F. Nielsen, eds.), Springer Proceedings in Mathematics & Statistics, (Cham), pp. 308–329,\nSpringer International Publishing, 2021.\n[382] F. Masi and I. Stefanou, “Multiscale modeling of inelastic materials with Thermodynamics-based Artificial\nNeural Networks (TANN),” Computer Methods in Applied Mechanics and Engineering, vol. 398, p. 115190,\nAug. 2022.\n[383] P. Ladeveze, D. Nedjar, and M. Reynier, “Updating of finite element models using vibration tests,” AIAA\nJournal, vol. 32, pp. 1485–1491, July 1994.\n[384] B. Marchand, L. Chamoin, and C. Rey, “Parameter identification and model updating in the context of non-\nlinear mechanical behaviors using a unified formulation of the modified Constitutive Relation Error concept,”\nComputer Methods in Applied Mechanics and Engineering, vol. 345, pp. 1094–1113, Mar. 2019.\n[385] H. N. Nguyen, L. Chamoin, and C. Ha Minh, “mCRE-based parameter identification from full-field measure-\nments: Consistent framework, integrated version, and extension to nonlinear material behaviors,” Computer\nMethods in Applied Mechanics and Engineering, vol. 400, p. 115461, Oct. 2022.\n[386] A. Benady, E. Baranger, and L. Chamoin, “NN-mCRE: a modified Constitutive Relation Error framework for\nunsupervised learning of nonlinear state laws with physics-augmented Neural Networks,” 2023.\n[387] A. B. Benady, L. C. Chamoin, and E. B. Baranger, “A modified Constitutive Relation Error (mCRE) frame-\nwork to learn nonlinear constitutive models from strain measurements with thermodynamics-consistent Neural\nNetworks,” XI International Conference on Adaptive Modeling and Simulation (ADMOS 2023), vol. Advanced\nTechniques for Data Assimilation, Inverse Analysis, and Data-based Enrichment of Simulation Models, May\n2023.\n[388] X. Li, C. C. Roth, and D. Mohr, “Machine-learning based temperature- and rate-dependent plasticity model:\nApplication to analysis of fracture experiments on DP steel,” International Journal of Plasticity, vol. 118,\npp. 320–344, July 2019.\n[389] P. Thakolkaran, A. Joshi, Y. Zheng, M. Flaschel, L. De Lorenzis, and S. Kumar, “NN-EUCLID: Deep-learning\nhyperelasticity without stress data,” Journal of the Mechanics and Physics of Solids, vol. 169, p. 105076, Dec.\n2022.\n[390] X. Li, Z. Liu, S. Cui, C. Luo, C. Li, and Z. Zhuang, “Predicting the effective mechanical property of hetero-\ngeneous materials by image based modeling and deep learning,” Computer Methods in Applied Mechanics and\nEngineering, vol. 347, pp. 735–753, Apr. 2019.\n[391] A. Henkes, I. Caylak, and R. Mahnken, “A deep learning driven pseudospectral PCE based FFT homogenization\nalgorithm for complex microstructures,” Computer Methods in Applied Mechanics and Engineering, vol. 385,\np. 114070, Nov. 2021.\n[392] M. Liu, L. Liang, and W. Sun, “Estimation of in vivo constitutive parameters of the aortic wall using a\nmachine learning approach,” Computer Methods in Applied Mechanics and Engineering, vol. 347, pp. 201–217,\nApr. 2019.\n[393] L. Lu, M. Dao, P. Kumar, U. Ramamurty, G. E. Karniadakis, and S. Suresh, “Extraction of mechanical\nproperties of materials through deep learning from instrumented indentation,” Proceedings of the National\nAcademy of Sciences, vol. 117, pp. 7052–7062, Mar. 2020.\n53\n[394] X. Meng and G. E. Karniadakis, “A composite neural network that learns from multi-fidelity data: Application\nto function approximation and inverse PDE problems,” Journal of Computational Physics, vol. 401, p. 109020,\nJan. 2020.\n[395] X. Liu, C. E. Athanasiou, N. P. Padture, B. W. Sheldon, and H. Gao, “A machine learning approach to fracture\nmechanics problems,” Acta Materialia, vol. 190, pp. 105–112, May 2020.\n[396] R. Hambli, H. Katerchi, and C.-L. Benhamou, “Multiscale methodology for bone remodelling simulation us-\ning coupled finite element and neural network computation,” Biomechanics and Modeling in Mechanobiology,\nvol. 10, pp. 133–145, Feb. 2011.\n[397] M. Flaschel, S. Kumar, and L. De Lorenzis, “Unsupervised discovery of interpretable hyperelastic constitutive\nlaws,” Computer Methods in Applied Mechanics and Engineering, vol. 381, p. 113852, Aug. 2021.\n[398] R. Tibshirani, “Regression Shrinkage and Selection via the Lasso,” Journal of the Royal Statistical Society.\nSeries B (Methodological), vol. 58, no. 1, pp. 267–288, 1996.\n[399] M. Flaschel, S. Kumar, and L. De Lorenzis, “Discovering plasticity models without stress data,” npj Compu-\ntational Materials, vol. 8, p. 91, Apr. 2022. arXiv:2202.04916 [cs].\n[400] E. Marino, M. Flaschel, S. Kumar, and L. De Lorenzis, “Automated identification of linear viscoelastic consti-\ntutive laws with EUCLID,” Mechanics of Materials, vol. 181, p. 104643, June 2023.\n[401] M. Flaschel, S. Kumar, and L. De Lorenzis, “Automated discovery of generalized standard material models\nwith EUCLID,” Computer Methods in Applied Mechanics and Engineering, vol. 405, p. 115867, Feb. 2023.\n[402] A. Joshi, P. Thakolkaran, Y. Zheng, M. Escande, M. Flaschel, L. De Lorenzis, and S. Kumar, “Bayesian-\nEUCLID: Discovering hyperelastic material laws with uncertainties,” Computer Methods in Applied Mechanics\nand Engineering, vol. 398, p. 115225, Aug. 2022.\n[403] K. Linka, S. R. St. Pierre, and E. Kuhl, “Automated model discovery for human brain using Constitutive\nArtificial Neural Networks,” Acta Biomaterialia, vol. 160, pp. 134–151, Apr. 2023.\n[404] K. Linka and E. Kuhl, “A new family of Constitutive Artificial Neural Networks towards automated model\ndiscovery,” Computer Methods in Applied Mechanics and Engineering, vol. 403, p. 115731, Jan. 2023.\n[405] A. Oishi and G. Yagawa, “Computational mechanics enhanced by deep learning,” Computer Methods in Applied\nMechanics and Engineering, vol. 327, pp. 327–351, Dec. 2017.\n[406] J. Jung, K. Yoon, and P.-S. Lee, “Deep learned finite elements,” Computer Methods in Applied Mechanics and\nEngineering, vol. 372, p. 113401, Dec. 2020.\n[407] Y. Bar-Sinai, S. Hoyer, J. Hickey, and M. P. Brenner, “Learning data-driven discretizations for partial differ-\nential equations,” Proceedings of the National Academy of Sciences, vol. 116, pp. 15344–15349, July 2019.\n[408] P. Pantidis and M. E. Mobasher, “Integrated Finite Element Neural Network (I-FENN) for non-local continuum\ndamage mechanics,” Computer Methods in Applied Mechanics and Engineering, vol. 404, p. 115766, Feb. 2023.\n[409] D. A. Arcones, R. E. Meethal, B. Obst, and R. Wchner, “Neural Network-Based Surrogate Models Applied to\nFluid-Structure Interaction Problems,” WCCM-APCOM 2022, vol. 1700 Data Science, Machine Learning and\nArtificial Intelligence, July 2022.\n[410] C. Han, P. Zhang, D. Bluestein, G. Cong, and Y. Deng, “Artificial intelligence for accelerating time integrations\nin multiscale modeling,” Journal of Computational Physics, vol. 427, p. 110053, Feb. 2021.\n[411] T. Sualec, M. Dobija, A. Paszyska, I. Muga, M. o, and M. Paszyski, “Automatic stabilization of finite-element\nsimulations using neural networks and hierarchical matrices,” Computer Methods in Applied Mechanics and\nEngineering, vol. 411, p. 116073, June 2023.\n[412] F. Casadei, J. J. Rimoli, and M. Ruzzene, “A geometric multiscale finite element method for the dynamic\nanalysis of heterogeneous solids,” Computer Methods in Applied Mechanics and Engineering, vol. 263, pp. 56–\n70, Aug. 2013.\n[413] O. Oztoprak, A. Paolini, P. D’Acunto, E. Rank, and S. Kollmannsberger, “Two-scale analysis and design of\nspaceframes with complex additive manufactured nodes,” 2023.\n[414] A. Koeppe, F. Bamer, and B. Markert, “An intelligent nonlinear meta element for elastoplastic continua: deep\nlearning using a new Time-distributed Residual U-Net architecture,” Computer Methods in Applied Mechanics\nand Engineering, vol. 366, p. 113088, July 2020.\n[415] G. Capuano and J. J. Rimoli, “Smart finite elements: A novel machine learning application,” Computer Methods\nin Applied Mechanics and Engineering, vol. 345, pp. 363–381, Mar. 2019.\n[416] T. Yamaguchi and H. Okuda, “Zooming method for FEA using a neural network,” Computers & Structures,\nvol. 247, p. 106480, Apr. 2021.\n[417] M. Yin, E. Zhang, Y. Yu, and G. E. Karniadakis, “Interfacing finite elements with deep neural operators for\nfast multiscale modeling of mechanics problems,” Computer Methods in Applied Mechanics and Engineering,\nvol. 402, p. 115027, Dec. 2022.\n[418] O. Sigmund, “On the usefulness of non-gradient approaches in topology optimization,” Structural and Multi-\ndisciplinary Optimization, vol. 43, pp. 589–596, May 2011.\n[419] P. Holl, V. Koltun, and N. Thuerey, “Learning to Control PDEs with Differentiable Physics,” Jan. 2020.\narXiv:2001.07457 [physics, stat].\n[420] K. Um, R. Brand, Y. R. Fei, P. Holl, and N. Thuerey, “Solver-in-the-loop: learning from differentiable physics to\ninteract with iterative PDE-solvers,” in Proceedings of the 34th International Conference on Neural Information\nProcessing Systems, NIPS’20, (Red Hook, NY, USA), pp. 6111–6122, Curran Associates Inc., Dec. 2020.\n[421] K. Um, R. Brand, Yun, Fei, P. Holl, and N. Thuerey, “Solver-in-the-Loop: Learning from Differentiable Physics\nto Interact with Iterative PDE-Solvers,” Jan. 2021. arXiv:2007.00016 [physics].\n[422] C. Jensen, R. Reed, R. Marks, M. El-Sharkawi, J.-B. Jung, R. Miyamoto, G. Anderson, and C. Eggen, “Inversion\nof feedforward neural networks: algorithms and applications,” Proceedings of the IEEE, vol. 87, pp. 1536–1549,\nSept. 1999.\n54\n[423] C.-H. Yu, Z. Qin, and M. J. Buehler, “Artificial intelligence design algorithm for nanocomposites optimized for\nshear crack resistance,” Nano Futures, vol. 3, p. 035001, Aug. 2019.\n[424] C. Chen and G. X. Gu, “Generative Deep Neural Networks for Inverse Materials Design Using Backpropagation\nand Active Learning,” Advanced Science, vol. 7, p. 1902607, Mar. 2020.\n[425] D. N. Tanyu, J. Ning, T. Freudenberg, N. Heilenktter, A. Rademacher, U. Iben, and P. Maass, “Deep Learning\nMethods for Partial Differential Equations and Related Parameter Identification Problems,” Dec. 2022.\n[426] T. I. Zohdi, “A machine-learning digital-twin for rapid large-scale solar-thermal energy system design,” Com-\nputer Methods in Applied Mechanics and Engineering, vol. 412, p. 115991, July 2023.\n[427] R.-E. Plessix, “A review of the adjoint-state method for computing the gradient of a functional with geophysical\napplications,” Geophysical Journal International, vol. 167, pp. 495–503, Nov. 2006.\n[428] D. Givoli, “A tutorial on the adjoint method for inverse problems,” Computer Methods in Applied Mechanics\nand Engineering, vol. 380, p. 113810, July 2021.\n[429] V. Keshavarzzadeh, R. M. Kirby, and A. Narayan, “Robust topology optimization with low rank approximation\nusing artificial neural networks,” Computational Mechanics, vol. 68, pp. 1297–1323, Dec. 2021.\n[430] C. Qian and W. Ye, “Accelerating gradient-based topology optimization design with dual-model artificial neural\nnetworks,” Structural and Multidisciplinary Optimization, vol. 63, pp. 1687–1707, Apr. 2021.\n[431] H. Chi, Y. Zhang, T. L. E. Tang, L. Mirabella, L. Dalloro, L. Song, and G. H. Paulino, “Universal ma-\nchine learning for topology optimization,” Computer Methods in Applied Mechanics and Engineering, vol. 375,\np. 112739, Mar. 2021.\n[432] N. Aulig and M. Olhofer, “Evolutionary generation of neural network update signals for the topology opti-\nmization of structures,” in Proceedings of the 15th annual conference companion on Genetic and evolutionary\ncomputation, GECCO ’13 Companion, (New York, NY, USA), pp. 213–214, Association for Computing Ma-\nchinery, July 2013.\n[433] N. Aulig and M. Olhofer, “Topology Optimization by predicting sensitivities based on local state features,”\n2014.\n[434] N. Aulig and M. Olhofer, “Neuro-evolutionary Topology Optimization with Adaptive Improvement Threshold,”\nin Applications of Evolutionary Computation (A. M. Mora and G. Squillero, eds.), Lecture Notes in Computer\nScience, (Cham), pp. 655–666, Springer International Publishing, 2015.\n[435] Y. Zhang, H. Chi, B. Chen, T. L. E. Tang, L. Mirabella, L. Song, and G. H. Paulino, “Speeding up Computa-\ntional Morphogenesis with Online Neural Synthetic Gradients,” Apr. 2021.\n[436] T. H. Hunter, S. H. Hulsoff, and A. S. Sitaram, “SuperAdjoint: Super-Resolution Neural Networks in Adjoint-\nbased Output Error Estimation,” XI International Conference on Adaptive Modeling and Simulation (ADMOS\n2023), vol. Recent Developments in Methods and Applications for Mesh Adaptation, May 2023.\n[437] K. Fukami, K. Fukagata, and K. Taira, “Machine-learning-based spatio-temporal super resolution reconstruc-\ntion of turbulent flows,” Journal of Fluid Mechanics, vol. 909, p. A9, Feb. 2021.\n[438] F. V. Senhora, H. Chi, Y. Zhang, L. Mirabella, T. L. E. Tang, and G. H. Paulino, “Machine learning for\ntopology optimization: Physics-based learning through an independent training strategy,” Computer Methods\nin Applied Mechanics and Engineering, vol. 398, p. 115116, Aug. 2022.\n[439] J.-T. Hsieh, S. Zhao, S. Eismann, L. Mirabella, and S. Ermon, “Learning Neural PDE Solvers with Convergence\nGuarantees,” June 2019. arXiv:1906.01200 [cs, stat].\n[440] H.-L. Ye, J.-C. Li, B.-S. Yuan, N. Wei, and Y.-K. Sui, “Acceleration Design for Continuum Topology Opti-\nmization by Using Pix2pix Neural Network,” International Journal of Applied Mechanics, vol. 13, p. 2150042,\nMay 2021.\n[441] S. Hoyer, J. Sohl-Dickstein, and S. Greydanus, “Neural reparameterization improves structural optimization,”\nSept. 2019.\n[442] K. Xu and E. Darve, “The Neural Network Approach to Inverse Problems in Differential Equations,” Jan.\n2019.\n[443] J. Berg and K. Nystrm, “Neural networks as smooth priors for inverse problems for PDEs,” Journal of Com-\nputational Mathematics and Data Science, vol. 1, p. 100008, Sept. 2021.\n[444] L. Chen and M.-H. H. Shen, “A New Topology Optimization Approach by Physics-Informed Deep Learning\nProcess,” Advances in Science, Technology and Engineering Systems Journal, vol. 6, pp. 233–240, July 2021.\n[445] A. Halle, L. F. Campanile, and A. Hasse, “An Artificial IntelligenceAssisted Design Method for Topology\nOptimization without Pre-Optimized Training Data,” Applied Sciences, vol. 11, p. 9041, Jan. 2021.\n[446] H. Deng and A. C. To, “Topology optimization based on deep representation learning (DRL) for compliance\nand stress-constrained design,” Computational Mechanics, vol. 66, pp. 449–469, Aug. 2020.\n[447] A. Chandrasekhar and K. Suresh, “TOuNN: Topology Optimization using Neural Networks,” Structural and\nMultidisciplinary Optimization, vol. 63, pp. 1135–1149, Mar. 2021.\n[448] A. Chandrasekhar and K. Suresh, “Length Scale Control in Topology Optimization using Fourier Enhanced\nNeural Networks,” Sept. 2021.\n[449] A. Chandrasekhar and K. Suresh, “Multi-Material Topology Optimization Using Neural Networks,” Computer-\nAided Design, vol. 136, p. 103017, July 2021.\n[450] J. J. Park, P. Florence, J. Straub, R. Newcombe, and S. Lovegrove, “DeepSDF: Learning Continuous Signed\nDistance Functions for Shape Representation,” in 2019 IEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition (CVPR), pp. 165–174, June 2019. ISSN: 2575-7075.\n[451] M. Michalkiewicz, J. K. Pontes, D. Jack, M. Baktashmotlagh, and A. Eriksson, “Implicit Surface Represen-\ntations As Layers in Neural Networks,” in 2019 IEEE/CVF International Conference on Computer Vision\n(ICCV), pp. 4742–4751, Oct. 2019. ISSN: 2380-7504.\n[452] A. Gropp, L. Yariv, N. Haim, M. Atzmon, and Y. Lipman, “Implicit geometric regularization for learning\n55\nshapes,” in Proceedings of the 37th International Conference on Machine Learning, vol. 119 of ICML’20,\npp. 3789–3799, JMLR.org, July 2020.\n[453] V. Sitzmann, J. N. P. Martel, A. W. Bergman, D. B. Lindell, and G. Wetzstein, “Implicit Neural Representations\nwith Periodic Activation Functions,” arXiv:2006.09661 [cs, eess], June 2020. arXiv: 2006.09661.\n[454] Z. Huang, S. Bai, and J. Z. Kolter, “(\\textbackslash textrm\\lbrace Implicit\\rbrace )ˆ2: Implicit Layers for\nImplicit Representations,” in Advances in Neural Information Processing Systems, vol. 34, pp. 9639–9650,\nCurran Associates, Inc., 2021.\n[455] H. Deng and A. C. To, “A Parametric Level Set Method for Topology Optimization based on Deep Neural\nNetwork (DNN),” Jan. 2021.\n[456] Z. Zhang, Y. Li, W. Zhou, X. Chen, W. Yao, and Y. Zhao, “TONR: An exploration for a novel way combin-\ning neural network with topology optimization,” Computer Methods in Applied Mechanics and Engineering,\nvol. 386, p. 114083, Dec. 2021.\n[457] R. Biswas, M. K. Sen, V. Das, and T. Mukerji, “Prestack and poststack inversion using a physics-guided\nconvolutional neural network,” Interpretation, vol. 7, pp. SE161–SE174, Aug. 2019.\n[458] M. Alfarraj and G. AlRegib, “Semi-supervised learning for acoustic impedance inversion,” in SEG Technical\nProgram Expanded Abstracts 2019, (San Antonio, Texas), pp. 2298–2302, Society of Exploration Geophysicists,\nAug. 2019.\n[459] C. Dong, C. C. Loy, K. He, and X. Tang, “Learning a Deep Convolutional Network for Image Super-Resolution,”\nin Computer Vision ECCV 2014 (D. Fleet, T. Pajdla, B. Schiele, and T. Tuytelaars, eds.), Lecture Notes in\nComputer Science, (Cham), pp. 184–199, Springer International Publishing, 2014.\n[460] C. Dong, C. C. Loy, K. He, and X. Tang, “Image Super-Resolution Using Deep Convolutional Networks,” July\n2015. arXiv:1501.00092 [cs].\n[461] K. Fukami, K. Fukagata, and K. Taira, “Super-resolution reconstruction of turbulent flows with machine\nlearning,” Journal of Fluid Mechanics, vol. 870, pp. 106–120, July 2019.\n[462] N. Napier, S.-A. Sriraman, H. T. Tran, and K. A. James, “An Artificial Neural Network Approach for Gener-\nating High-Resolution Designs From Low-Resolution Input in Topology Optimization,” Journal of Mechanical\nDesign, vol. 142, p. 011402, Jan. 2020.\n[463] C. Wang, S. Yao, Z. Wang, and J. Hu, “Deep super-resolution neural network for structural topology optimiza-\ntion,” Engineering Optimization, vol. 53, pp. 2108–2121, Dec. 2021.\n[464] L. Xue, J. Liu, G. Wen, and H. Wang, “Efficient, high-resolution topology optimization method based on\nconvolutional neural networks,” Frontiers of Mechanical Engineering, vol. 16, pp. 80–96, Mar. 2021.\n[465] A. Oishi and G. Yagawa, “Finite Elements Using Neural Networks and a Posteriori Error,” Archives of Com-\nputational Methods in Engineering, vol. 28, pp. 3433–3456, Aug. 2021.\n[466] M. O. Elingaard, N. Aage, J. A. Brentzen, and O. Sigmund, “De-homogenization using convolutional neural\nnetworks,” Computer Methods in Applied Mechanics and Engineering, vol. 388, p. 114197, Jan. 2022.\n[467] Z. Y. Wan, P. Vlachas, P. Koumoutsakos, and T. Sapsis, “Data-assisted reduced-order modeling of extreme\nevents in complex dynamical systems,” PLOS ONE, vol. 13, p. e0197704, May 2018.\n[468] S. Sato, Y. Dobashi, T. Kim, and T. Nishita, “Example-based turbulence style transfer,” ACM Transactions\non Graphics, vol. 37, pp. 84:1–84:9, July 2018.\n[469] M. Chu and N. Thuerey, “Data-driven synthesis of smoke flows with CNN-based feature descriptors,” ACM\nTransactions on Graphics, vol. 36, pp. 69:1–69:14, July 2017.\n[470] A. Yildiz, N. ztrk, N. Kaya, and F. ztrk, “Integrated optimal topology design and shape optimization using\nneural networks,” Structural and Multidisciplinary Optimization, vol. 25, pp. 251–260, Oct. 2003.\n[471] C.-Y. Lin and S.-H. Lin, “Artificial neural network based hole image interpretation techniques for inte-\ngrated topology and shape optimization,” Computer Methods in Applied Mechanics and Engineering, vol. 194,\npp. 3817–3837, Sept. 2005.\n[472] G. Chen and K. Fidkowski, “Output-Based Error Estimation and Mesh Adaptation Using Convolutional Neural\nNetworks: Application to a Scalar Advection-Diffusion Problem,” in AIAA Scitech 2020 Forum, (Orlando, FL),\nAmerican Institute of Aeronautics and Astronautics, Jan. 2020.\n[473] J. Takeuchi and Y. Kosugi, “Neural network representation of finite element method,” Neural Networks, vol. 7,\npp. 389–395, Jan. 1994.\n[474] P. Ramuhalli, L. Udpa, and S. Udpa, “Finite-element neural networks for solving differential equations,” IEEE\nTransactions on Neural Networks, vol. 16, pp. 1381–1392, Nov. 2005.\n[475] R. Sikora, J. Sikora, E. Cardelli, and T. Chady, “Artificial neural network application for material evaluation\nby electromagnetic methods,” in IJCNN’99. International Joint Conference on Neural Networks. Proceedings\n(Cat. No.99CH36339), vol. 6, pp. 4027–4032 vol.6, July 1999.\n[476] G. Xu, G. Littlefair, R. Penson, and R. Callan, “Application of FE-based neural networks to dynamic problems,”\nin ICONIP’99. ANZIIS’99 & ANNES’99 & ACNN’99. 6th International Conference on Neural Information\nProcessing. Proceedings (Cat. No.99EX378), vol. 3, pp. 1039–1044 vol.3, Nov. 1999.\n[477] F. Guo, P. Zhang, F. Wang, X. Ma, and G. Qiu, “Finite element analysis based Hopfield neural network model\nfor solving nonlinear electromagnetic field problems,” in IJCNN’99. International Joint Conference on Neural\nNetworks. Proceedings (Cat. No.99CH36339), vol. 6, pp. 4399–4403 vol.6, July 1999.\n[478] H. Lee and I. S. Kang, “Neural algorithm for solving differential equations,” Journal of Computational Physics,\nvol. 91, pp. 110–131, Nov. 1990.\n[479] J. Kalkkuhl, K. Hunt, and H. Fritz, “FEM-based neural-network approach to nonlinear modeling with applica-\ntion to longitudinal vehicle dynamics control,” IEEE Transactions on Neural Networks, vol. 10, pp. 885–897,\nJuly 1999.\n[480] C. Xu, C. Wang, F. Ji, and X. Yuan, “Finite-Element Neural Network-Based Solving 3-D Differential Equations\nin MFL,” IEEE Transactions on Magnetics, vol. 48, pp. 4747–4756, Dec. 2012.\n56\n[481] Z. Yang, M. Ruess, S. Kollmannsberger, A. Dster, and E. Rank, “An efficient integration technique for the\nvoxel-based finite cell method: Efficient Integration Technique For Finite Cells,” International Journal for\nNumerical Methods in Engineering, vol. 91, pp. 457–471, Aug. 2012.\n[482] L. Zhang, L. Cheng, H. Li, J. Gao, C. Yu, R. Domel, Y. Yang, S. Tang, and W. K. Liu, “Hierarchical deep-\nlearning neural networks: finite elements and beyond,” Computational Mechanics, vol. 67, pp. 207–230, Jan.\n2021.\n[483] S. Saha, Z. Gan, L. Cheng, J. Gao, O. L. Kafka, X. Xie, H. Li, M. Tajdari, H. A. Kim, and W. K. Liu, “Hier-\narchical Deep Learning Neural Network (HiDeNN): An artificial intelligence (AI) framework for computational\nscience and engineering,” Computer Methods in Applied Mechanics and Engineering, vol. 373, p. 113452, Jan.\n2021.\n[484] L. Zhang, Y. Lu, S. Tang, and W. K. Liu, “HiDeNN-TD: Reduced-order hierarchical deep learning neural\nnetworks,” Computer Methods in Applied Mechanics and Engineering, vol. 389, p. 114414, Feb. 2022.\n[485] Y. Liu, C. Park, Y. Lu, S. Mojumder, W. K. Liu, and D. Qian, “HiDeNN-FEM: a seamless machine learning\napproach to nonlinear finite element analysis,” Computational Mechanics, vol. 72, pp. 173–194, July 2023.\n[486] Y. Lu, H. Li, L. Zhang, C. Park, S. Mojumder, S. Knapik, Z. Sang, S. Tang, D. W. Apley, G. J. Wagner,\nand W. K. Liu, “Convolution Hierarchical Deep-learning Neural Networks (C-HiDeNN): finite elements, iso-\ngeometric analysis, tensor decomposition, and beyond,” Computational Mechanics, vol. 72, pp. 333–362, Aug.\n2023.\n[487] C. Park, Y. Lu, S. Saha, T. Xue, J. Guo, S. Mojumder, D. W. Apley, G. J. Wagner, and W. K. Liu, “Convolution\nhierarchical deep-learning neural network (C-HiDeNN) with graphics processing unit (GPU) acceleration,”\nComputational Mechanics, vol. 72, pp. 383–409, Aug. 2023.\n[488] H. Li, S. Knapik, Y. Li, C. Park, J. Guo, S. Mojumder, Y. Lu, W. Chen, D. W. Apley, and W. K. Liu,\n“Convolution Hierarchical Deep-Learning Neural Network Tensor Decomposition (C-HiDeNN-TD) for high-\nresolution topology optimization,” Computational Mechanics, vol. 72, pp. 363–382, Aug. 2023.\n[489] H. Yao, Y. Ren, and Y. Liu, “FEA-Net: A Deep Convolutional Neural Network With PhysicsPrior For Efficient\nData Driven PDE Learning,” in AIAA Scitech 2019 Forum, (San Diego, California), American Institute of\nAeronautics and Astronautics, Jan. 2019.\n[490] H. Yao, Y. Gao, and Y. Liu, “FEA-Net: A physics-guided data-driven model for efficient mechanical response\nprediction,” Computer Methods in Applied Mechanics and Engineering, vol. 363, p. 112892, May 2020.\n[491] R. Mishra and P. Hall, “NFDTD concept,” IEEE Transactions on Neural Networks, vol. 16, pp. 484–490, Mar.\n2005.\n[492] A. Richardson, “Seismic Full-Waveform Inversion Using Deep Learning Tools and Techniques,” Jan. 2018.\n[493] J. Sun, Z. Niu, K. A. Innanen, J. Li, and D. O. Trad, “A theory-guided deep-learning formulation and opti-\nmization of seismic waveform inversion,” GEOPHYSICS, vol. 85, pp. R87–R99, Mar. 2020.\n[494] T. W. Hughes, I. A. D. Williamson, M. Minkov, and S. Fan, “Wave physics as an analog recurrent neural\nnetwork,” Science Advances, vol. 5, p. eaay6946, Dec. 2019.\n[495] Z. Liu, C. T. Wu, and M. Koishi, “A deep material network for multiscale topology learning and accelerated\nnonlinear modeling of heterogeneous materials,” Computer Methods in Applied Mechanics and Engineering,\nvol. 345, pp. 1138–1168, Mar. 2019.\n[496] Z. Liu and C. T. Wu, “Exploring the 3D architectures of deep material network in data-driven multiscale\nmechanics,” Journal of the Mechanics and Physics of Solids, vol. 127, pp. 20–46, June 2019.\n[497] E. Haber and L. Ruthotto, “Stable Architectures for Deep Neural Networks,” Inverse Problems, vol. 34,\np. 014004, Jan. 2018. arXiv:1705.03341 [cs, math].\n[498] L. Ruthotto and E. Haber, “Deep Neural Networks Motivated by Partial Differential Equations,” Dec. 2018.\narXiv:1804.04272 [cs, math, stat].\n[499] Y. Lu, A. Zhong, Q. Li, and B. Dong, “Beyond Finite Layer Neural Networks: Bridging Deep Architectures\nand Numerical Differential Equations,” Mar. 2020. arXiv:1710.10121 [cs, stat].\n[500] L. S. Pontriagin, L. W. Neustadt, and L. S. Pontriagin, The mathematical theory of optimal processes. No. v.\n1 in Classics of Soviet mathematics, New York: Gordon and Breach Science Publishers, english ed ed., 1986.\n[501] Y. Yu, H. Yao, and Y. Liu, “Physics-based Learning for Aircraft Dynamics Simulation,” Annual Conference of\nthe PHM Society, vol. 10, Sept. 2018.\n[502] R. Ranade, C. Hill, and J. Pathak, “DiscretizationNet: A machine-learning based solver for NavierStokes equa-\ntions using finite volume discretization,” Computer Methods in Applied Mechanics and Engineering, vol. 378,\np. 113722, May 2021.\n[503] D. Foster, Generative deep learning: teaching machines to paint, write, compose, and play. Sebastopol, CA:\nO’Reilly Media, Incorporated, second edition ed., 2023. OCLC: 1378390519.\n[504] D. J. Rezende, S. Mohamed, and D. Wierstra, “Stochastic Backpropagation and Approximate Inference in\nDeep Generative Models,” May 2014. arXiv:1401.4082 [cs, stat].\n[505] D. P. Kingma and M. Welling, “Auto-Encoding Variational Bayes,” Dec. 2022. arXiv:1312.6114 [cs, stat].\n[506] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Ben-\ngio, “Generative Adversarial Nets,” in Advances in Neural Information Processing Systems, vol. 27, Curran\nAssociates, Inc., 2014.\n[507] J. F. Nash, “Equilibrium points in n -person games,” Proceedings of the National Academy of Sciences, vol. 36,\npp. 48–49, Jan. 1950.\n[508] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, X. Chen, and X. Chen, “Improved Techniques\nfor Training GANs,” in Advances in Neural Information Processing Systems, vol. 29, Curran Associates, Inc.,\n2016.\n[509] A. Srivastava, L. Valkov, C. Russell, M. U. Gutmann, and C. Sutton, “VEEGAN: reducing mode collapse\nin GANs using implicit variational learning,” in Proceedings of the 31st International Conference on Neural\n57\nInformation Processing Systems, NIPS’17, (Red Hook, NY, USA), pp. 3310–3320, Curran Associates Inc., Dec.\n2017.\n[510] M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein GAN,” Dec. 2017. arXiv:1701.07875 [cs, stat].\n[511] M. Mirza and S. Osindero, “Conditional Generative Adversarial Nets,” Nov. 2014. arXiv:1411.1784 [cs, stat].\n[512] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel, “InfoGAN: interpretable represen-\ntation learning by information maximizing generative adversarial nets,” in Proceedings of the 30th International\nConference on Neural Information Processing Systems, NIPS’16, (Red Hook, NY, USA), pp. 2180–2188, Curran\nAssociates Inc., Dec. 2016.\n[513] J. S. Bridle, A. J. R. Heading, and D. J. C. MacKay, “Unsupervised classifiers, mutual information and ’phan-\ntom targets’,” in Proceedings of the 4th International Conference on Neural Information Processing Systems,\nNIPS’91, (San Francisco, CA, USA), pp. 1096–1101, Morgan Kaufmann Publishers Inc., Dec. 1991.\n[514] A. B. L. Larsen, S. K. Snderby, H. Larochelle, and O. Winther, “Autoencoding beyond pixels using a learned\nsimilarity metric,” in Proceedings of the 33rd International Conference on International Conference on Machine\nLearning - Volume 48, ICML’16, (New York, NY, USA), pp. 1558–1566, JMLR.org, June 2016.\n[515] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli, “Deep Unsupervised Learning using Nonequi-\nlibrium Thermodynamics,” in Proceedings of the 32nd International Conference on Machine Learning, pp. 2256–\n2265, PMLR, June 2015.\n[516] J. Ho, A. Jain, and P. Abbeel, “Denoising Diffusion Probabilistic Models,” in Advances in Neural Information\nProcessing Systems, vol. 33, pp. 6840–6851, Curran Associates, Inc., 2020.\n[517] A. Nichol and P. Dhariwal, “Improved Denoising Diffusion Probabilistic Models,” Feb. 2021. arXiv:2102.09672\n[cs, stat].\n[518] D. Rezende and S. Mohamed, “Variational Inference with Normalizing Flows,” in Proceedings of the 32nd\nInternational Conference on Machine Learning, pp. 1530–1538, PMLR, June 2015.\n[519] I. Kobyzev, S. J. D. Prince, and M. A. Brubaker, “Normalizing Flows: An Introduction and Review of Current\nMethods,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 43, pp. 3964–3979, Nov.\n2021. arXiv:1908.09257 [cs, stat].\n[520] L. Mosser, O. Dubrule, and M. J. Blunt, “Reconstruction of three-dimensional porous media using generative\nadversarial neural networks,” Physical Review E, vol. 96, p. 043309, Oct. 2017.\n[521] J. Feng, X. He, Q. Teng, C. Ren, H. Chen, and Y. Li, “Reconstruction of porous media from extremely limited\ninformation using conditional generative adversarial networks,” Physical Review E, vol. 100, p. 033308, Sept.\n2019.\n[522] R. Shams, M. Masihi, R. B. Boozarjomehry, and M. J. Blunt, “Coupled generative adversarial and auto-encoder\nneural networks to reconstruct three-dimensional multi-scale porous media,” Journal of Petroleum Science and\nEngineering, vol. 186, p. 106794, Mar. 2020.\n[523] P. Xia, H. Bai, and T. Zhang, “Multi-scale reconstruction of porous media based on progressively growing\ngenerative adversarial networks,” Stochastic Environmental Research and Risk Assessment, vol. 36, pp. 3685–\n3705, Nov. 2022.\n[524] A. Henkes and H. Wessels, “Three-dimensional microstructure generation using generative adversarial neural\nnetworks in the context of continuum micromechanics,” Computer Methods in Applied Mechanics and Engi-\nneering, vol. 400, p. 115497, Oct. 2022.\n[525] S. Rawat and M. H. H. Shen, “A novel topology design approach using an integrated deep learning network\narchitecture,” Jan. 2019.\n[526] K. Yaji, S. Yamasaki, and K. Fujita, “Data-driven multifidelity topology design using a deep generative model:\nApplication to forced convection heat transfer problems,” Computer Methods in Applied Mechanics and Engi-\nneering, vol. 388, p. 114284, Jan. 2022.\n[527] K.-H. Lee and G. J. Yun, “Microstructure reconstruction using diffusion-based generative models,” Jan. 2023.\narXiv:2211.10949 [cond-mat, physics:physics].\n[528] C. Dreth, P. Seibert, D. Rcker, S. Handford, M. Kstner, and M. Gude, “Conditional diffusion-based microstruc-\nture reconstruction,” Materials Today Communications, vol. 35, p. 105608, June 2023.\n[529] N. N. Vlassis and W. Sun, “Denoising diffusion algorithm for inverse design of microstructures with fine-tuned\nnonlinear material properties,” Computer Methods in Applied Mechanics and Engineering, vol. 413, p. 116126,\nAug. 2023.\n[530] J. Feng, Q. Teng, B. Li, X. He, H. Chen, and Y. Li, “An end-to-end three-dimensional reconstruction framework\nof porous media from a single two-dimensional image based on deep learning,” Computer Methods in Applied\nMechanics and Engineering, vol. 368, p. 113043, Aug. 2020.\n[531] S. Kench and S. J. Cooper, “Generating three-dimensional structures from a two-dimensional slice with gener-\native adversarial network-based dimensionality expansion,” Nature Machine Intelligence, vol. 3, pp. 299–305,\nApr. 2021.\n[532] Y. Li, P. Jian, and G. Han, “Cascaded Progressive Generative Adversarial Networks for Reconstructing Three-\nDimensional Grayscale Core Images From a Single Two-Dimensional Image,” Frontiers in Physics, vol. 10,\n2022.\n[533] F. Zhang, X. He, Q. Teng, X. Wu, and X. Dong, “3D-PMRNN: Reconstructing three-dimensional porous media\nfrom the two-dimensional image with recurrent neural network,” Journal of Petroleum Science and Engineering,\nvol. 208, p. 109652, Jan. 2022.\n[534] Q. Zheng and D. Zhang, “RockGPT: reconstructing three-dimensional digital rocks from single two-dimensional\nslice with deep learning,” Computational Geosciences, vol. 26, pp. 677–696, June 2022.\n[535] J. Phan, L. Ruspini, G. Kiss, and F. Lindseth, “Size-invariant 3D generation from a single 2D rock image,”\nJournal of Petroleum Science and Engineering, vol. 215, p. 110648, Aug. 2022.\n[536] F. Zhang, Q. Teng, H. Chen, X. He, and X. Dong, “Slice-to-voxel stochastic reconstructions on porous media\n58\nwith hybrid deep generative model,” Computational Materials Science, vol. 186, p. 110018, Jan. 2021.\n[537] S. Rawat and M. H. Shen, “Application of Adversarial Networks for 3D Structural Topology Optimization,”\npp. 2019–01–0829, Apr. 2019.\n[538] S. Rawat and M.-H. H. Shen, “A Novel Topology Optimization Approach using Conditional Deep Learning,”\nJan. 2019.\n[539] M.-H. H. Shen and L. Chen, “A New CGAN Technique for Constrained Topology Design Optimization,” Apr.\n2019.\n[540] H. Wessels, C. Bhm, F. Aldakheel, M. Hpgen, M. Haist, L. Lohaus, and P. Wriggers, “Computational Ho-\nmogenization Using Convolutional Neural Networks,” in Current Trends and Open Problems in Computational\nMechanics (F. Aldakheel, B. Hudobivnik, M. Soleimani, H. Wessels, C. Weienfels, and M. Marino, eds.),\npp. 569–579, Cham: Springer International Publishing, 2022.\n[541] L. Mosser, O. Dubrule, and M. J. Blunt, “Stochastic Seismic Waveform Inversion Using Generative Adversarial\nNetworks as a Geological Prior,” Mathematical Geosciences, vol. 52, pp. 53–79, Jan. 2020.\n[542] T. Guo, D. J. Lohan, R. Cang, M. Y. Ren, and J. T. Allison, “An Indirect Design Representation for Topology\nOptimization Using Variational Autoencoder and Style Transfer,” in 2018 AIAA/ASCE/AHS/ASC Structures,\nStructural Dynamics, and Materials Conference, AIAA SciTech Forum, American Institute of Aeronautics and\nAstronautics, Jan. 2018.\n[543] P. S. Vulimiri, H. Deng, F. Dugast, X. Zhang, and A. C. To, “Integrating Geometric Data into Topology\nOptimization via Neural Style Transfer,” Materials, vol. 14, p. 4551, Jan. 2021.\n[544] L. Gatys, A. Ecker, and M. Bethge, “A Neural Algorithm of Artistic Style,” Journal of Vision, vol. 16, p. 326,\nSept. 2016.\n[545] S. Khan, K. Goucher-Lambert, K. Kostas, and P. Kaklis, “ShipHullGAN: A generic parametric modeller for\nship hull design using deep convolutional generative model,” Computer Methods in Applied Mechanics and\nEngineering, vol. 411, p. 116051, June 2023.\n[546] Q. Chen, J. Wang, P. Pope, W. (Wayne) Chen, and M. Fuge, “Inverse Design of Two-Dimensional Airfoils\nUsing Conditional Generative Models and Surrogate Log-Likelihoods,” Journal of Mechanical Design, vol. 144,\np. 021712, Feb. 2022.\n[547] W. Chen and M. Fuge, “B\\’ezierGAN: Automatic Generation of Smooth Curves from Interpretable Low-\nDimensional Parameters,” Jan. 2021. arXiv:1808.08871 [cs, stat].\n[548] W. Chen and F. Ahmed, “MO-PaDGAN: Reparameterizing Engineering Designs for augmented multi-objective\noptimization,” Applied Soft Computing, vol. 113, p. 107909, Dec. 2021.\n[549] A. Richardson, “Generative Adversarial Networks for Model Order Reduction in Seismic Full-Waveform Inver-\nsion,” June 2018. arXiv:1806.00828 [physics].\n[550] Y. Zhang, P. Seibert, A. Otto, A. Raloff, M. Ambati, and M. Kstner, “DA-VEGAN: Differentiably Augmenting\nVAE-GAN for microstructure reconstruction from extremely small data sets,” Feb. 2023. arXiv:2303.03403 [cs].\n[551] W. Chen and F. Ahmed, “PaDGAN: Learning to Generate High-Quality Novel Designs,” Journal of Mechanical\nDesign, vol. 143, p. 031703, Mar. 2021.\n[552] A. Kulesza and B. Taskar, “Determinantal point processes for machine learning,” Foundations and Trends in\nMachine Learning, vol. 5, no. 2-3, pp. 123–286, 2012. arXiv:1207.6083 [cs, stat].\n[553] S. J. Bates, J. Sienz, and D. S. Langley, “Formulation of the AudzeEglais Uniform Latin Hypercube design of\nexperiments,” Advances in Engineering Software, vol. 34, pp. 493–506, Aug. 2003.\n[554] A. Heyrani Nobari, M. F. Rashad, and F. Ahmed, “CreativeGAN: Editing Generative Adversarial Networks\nfor Creative Design Synthesis,” in Volume 3A: 47th Design Automation Conference (DAC), (Virtual, Online),\np. V03AT03A002, American Society of Mechanical Engineers, Aug. 2021.\n[555] D. Bau, S. Liu, T. Wang, J.-Y. Zhu, and A. Torralba, “Rewriting a Deep Generative Model,” July 2020.\narXiv:2007.15646 [cs].\n[556] A. Elgammal, B. Liu, M. Elhoseiny, and M. Mazzone, “CAN: Creative Adversarial Networks, Generating ”Art”\nby Learning About Styles and Deviating from Style Norms,” June 2017. arXiv:1706.07068 [cs].\n[557] S. Oh, Y. Jung, S. Kim, I. Lee, and N. Kang, “Deep Generative Design: Integration of Topology Optimization\nand Generative Models,” Journal of Mechanical Design, vol. 141, p. 111405, Nov. 2019.\n[558] M. Greminger, “Generative Adversarial Networks With Synthetic Training Data for Enforcing Manufacturing\nConstraints on Topology Optimization,” in Volume 11A: 46th Design Automation Conference (DAC), (Virtual,\nOnline), p. V11AT11A005, American Society of Mechanical Engineers, Aug. 2020.\n[559] S. Yoo, S. Lee, S. Kim, K. H. Hwang, J. H. Park, and N. Kang, “Integrating deep learning into CAD/CAE sys-\ntem: generative design and evaluation of 3D conceptual wheel,” Structural and Multidisciplinary Optimization,\nvol. 64, pp. 2725–2747, Oct. 2021.\n[560] W. Zhang, Y. Wang, Z. Du, C. Liu, S.-K. Youn, and X. Guo, “Machine-learning assisted topology optimization\nfor architectural design with artistic flavor,” Computer Methods in Applied Mechanics and Engineering, vol. 413,\np. 116041, Aug. 2023.\n[561] M. P. Bendse and O. Sigmund, Topology optimization: theory, methods, and applications. Berlin ; New York:\nSpringer, 2003.\n[562] F. Yang and J. Ma, “FWIGAN: FullWaveform Inversion via a PhysicsInformed Generative Adversarial Net-\nwork,” Journal of Geophysical Research: Solid Earth, vol. 128, p. e2022JB025493, Apr. 2023.\n[563] S. Radhakrishnan, V. Bharadwaj, V. Manjunath, and R. Srinath, “Creative Intelligence\nAutomating Car\nDesign Studio with Generative Adversarial Networks (GAN),” in Machine Learning and Knowledge Extraction\n(A. Holzinger, P. Kieseberg, A. M. Tjoa, and E. Weippl, eds.), Lecture Notes in Computer Science, (Cham),\npp. 160–175, Springer International Publishing, 2018.\n[564] W. Chen and M. Fuge, “Synthesizing Designs With Interpart Dependencies Using Hierarchical Generative\nAdversarial Networks,” Journal of Mechanical Design, vol. 141, p. 111403, Nov. 2019.\n59\n[565] Z. Nie, T. Lin, H. Jiang, and L. B. Kara, “TopologyGAN: Topology Optimization Using Generative Adversarial\nNetworks Based on Physical Fields Over the Initial Domain,” Mar. 2020.\n[566] N. Hertlein, P. R. Buskohl, A. Gillman, K. Vemaganti, and S. Anand, “Generative adversarial network for\nearly-stage design flexibility in topology optimization for additive manufacturing,” Journal of Manufacturing\nSystems, vol. 59, pp. 675–685, Apr. 2021.\n[567] A. Heyrani Nobari, W. W. Chen, and F. Ahmed, “RANGE-GAN: Design Synthesis Under Constraints Using\nConditional Generative Adversarial Networks,” Journal of Mechanical Design, pp. 1–16, Sept. 2021.\n[568] J. Wang, W. W. Chen, D. Da, M. Fuge, and R. Rai, “IH-GAN: A conditional generative model for implicit\nsurface-based inverse design of cellular structures,” Computer Methods in Applied Mechanics and Engineering,\nvol. 396, p. 115060, June 2022.\n[569] L. Duque, G. Gutirrez, C. Arias, A. Rger, and H. Jaramillo, “Automated Velocity Estimation by Deep Learning\nBased Seismic-to-Velocity Mapping,” vol. 2019, pp. 1–5, European Association of Geoscientists & Engineers,\nJune 2019.\n[570] Y.-Q. Wang, Q. Wang, W.-K. Lu, Q. Ge, and X.-F. Yan, “Seismic impedance inversion based on cycle-consistent\ngenerative adversarial network,” Petroleum Science, vol. 19, pp. 147–161, Feb. 2022.\n[571] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, “Unpaired Image-to-Image Translation using Cycle-Consistent\nAdversarial Networks,” Aug. 2020. arXiv:1703.10593 [cs].\n[572] B. Li, C. Huang, X. Li, S. Zheng, and J. Hong, “Non-iterative structural topology optimization using deep\nlearning,” Computer-Aided Design, vol. 115, pp. 172–180, Oct. 2019.\n[573] Y. Xie, E. Franz, M. Chu, and N. Thuerey, “tempoGAN: a temporally coherent, volumetric GAN for super-\nresolution fluid flow,” ACM Transactions on Graphics, vol. 37, pp. 95:1–95:15, July 2018.\n[574] G. Pang, C. Shen, L. Cao, and A. V. D. Hengel, “Deep Learning for Anomaly Detection: A Review,” ACM\nComputing Surveys, vol. 54, pp. 1–38, Mar. 2022.\n[575] S. Hawkins, H. He, G. Williams, and R. Baxter, “Outlier Detection Using Replicator Neural Networks,” in\nData Warehousing and Knowledge Discovery (Y. Kambayashi, W. Winiwarter, and M. Arikawa, eds.), Lecture\nNotes in Computer Science, (Berlin, Heidelberg), pp. 170–180, Springer, 2002.\n[576] T. Schlegl, P. Seebck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs, “Unsupervised Anomaly Detection\nwith Generative Adversarial Networks to Guide Marker Discovery,” in Information Processing in Medical\nImaging (M. Niethammer, M. Styner, S. Aylward, H. Zhu, I. Oguz, P.-T. Yap, and D. Shen, eds.), Lecture\nNotes in Computer Science, (Cham), pp. 146–157, Springer International Publishing, 2017.\n[577] H. Zenati, C. S. Foo, B. Lecouat, G. Manek, and V. R. Chandrasekhar, “Efficient GAN-Based Anomaly\nDetection,” May 2019. arXiv:1802.06222 [cs, stat].\n[578] T. Schlegl, P. Seebck, S. M. Waldstein, G. Langs, and U. Schmidt-Erfurth, “f-AnoGAN: Fast unsupervised\nanomaly detection with generative adversarial networks,” Medical Image Analysis, vol. 54, pp. 30–44, May\n2019.\n[579] A. Henkes, L. Herrmann, H. Wessels, and S. Kollmannsberger, “GAN enables Microstructure Monitoring for\nAdditive Manufacturing of Complex Structures,” in preparation, 2023.\n[580] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K.\nFidjeland, G. Ostrovski, S. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra,\nS. Legg, and D. Hassabis, “Human-level control through deep reinforcement learning,” Nature, vol. 518, pp. 529–\n533, Feb. 2015.\n[581] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai,\nA. Bolton, Y. Chen, T. Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, and D. Hassabis, “Mastering\nthe game of Go without human knowledge,” Nature, vol. 550, pp. 354–359, Oct. 2017.\n[582] O. Vinyals, I. Babuschkin, W. M. Czarnecki, M. Mathieu, A. Dudzik, J. Chung, D. H. Choi, R. Powell,\nT. Ewalds, P. Georgiev, J. Oh, D. Horgan, M. Kroiss, I. Danihelka, A. Huang, L. Sifre, T. Cai, J. P. Agapiou,\nM. Jaderberg, A. S. Vezhnevets, R. Leblond, T. Pohlen, V. Dalibard, D. Budden, Y. Sulsky, J. Molloy, T. L.\nPaine, C. Gulcehre, Z. Wang, T. Pfaff, Y. Wu, R. Ring, D. Yogatama, D. Wnsch, K. McKinney, O. Smith,\nT. Schaul, T. Lillicrap, K. Kavukcuoglu, D. Hassabis, C. Apps, and D. Silver, “Grandmaster level in StarCraft\nII using multi-agent reinforcement learning,” Nature, vol. 575, pp. 350–354, Nov. 2019.\n[583] J. Kober, J. A. Bagnell, and J. Peters, “Reinforcement learning in robotics: A survey,” The International\nJournal of Robotics Research, vol. 32, pp. 1238–1274, Sept. 2013.\n[584] H. Kim, M. Jordan, S. Sastry, and A. Ng, “Autonomous Helicopter Flight via Reinforcement Learning,” in\nAdvances in Neural Information Processing Systems, vol. 16, MIT Press, 2003.\n[585] P. Abbeel, A. Coates, M. Quigley, and A. Ng, “An Application of Reinforcement Learning to Aerobatic Heli-\ncopter Flight,” in Advances in Neural Information Processing Systems, vol. 19, MIT Press, 2006.\n[586] P. Abbeel, A. Coates, and A. Y. Ng, “Autonomous Helicopter Aerobatics through Apprenticeship Learning,”\nThe International Journal of Robotics Research, vol. 29, pp. 1608–1639, Nov. 2010.\n[587] R. S. Sutton and A. G. Barto, Reinforcement learning: an introduction. Adaptive computation and machine\nlearning series, Cambridge, Massachusetts: The MIT Press, second edition ed., 2018.\n[588] G. Novati, S. Verma, D. Alexeev, D. Rossinelli, W. M. van Rees, and P. Koumoutsakos, “Synchronised Swim-\nming of Two Fish,” Bioinspiration & Biomimetics, vol. 12, p. 036001, Mar. 2017. arXiv:1610.04248 [physics].\n[589] S. Verma, G. Novati, and P. Koumoutsakos, “Efficient collective swimming by harnessing vortices through deep\nreinforcement learning,” Proceedings of the National Academy of Sciences, vol. 115, pp. 5849–5854, June 2018.\n[590] P. Ma, Y. Tian, Z. Pan, B. Ren, and D. Manocha, “Fluid directed rigid body control using deep reinforcement\nlearning,” ACM Transactions on Graphics, vol. 37, pp. 96:1–96:11, July 2018.\n[591] J. Rabault, M. Kuchta, A. Jensen, U. Rglade, and N. Cerardi, “Artificial neural networks trained through deep\nreinforcement learning discover control strategies for active flow control,” Journal of Fluid Mechanics, vol. 865,\npp. 281–302, Apr. 2019.\n60\n[592] D. Fan, L. Yang, Z. Wang, M. S. Triantafyllou, and G. E. Karniadakis, “Reinforcement learning for bluff body\nactive flow control in experiments and simulations,” Proceedings of the National Academy of Sciences, vol. 117,\npp. 26091–26098, Oct. 2020.\n[593] J. Xu, T. Du, M. Foshey, B. Li, B. Zhu, A. Schulz, and W. Matusik, “Learning to fly: computational controller\ndesign for hybrid UAVs with reinforcement learning,” ACM Transactions on Graphics, vol. 38, pp. 42:1–42:12,\nJuly 2019.\n[594] X. Y. Lee, A. Balu, D. Stoecklein, B. Ganapathysubramanian, and S. Sarkar, “Flow Shape Design for Microflu-\nidic Devices Using Deep Reinforcement Learning,” Nov. 2018. arXiv:1811.12444 [cs, stat].\n[595] K. Wang and W. Sun, “Meta-modeling game for deriving theory-consistent, microstructure-based traction-\nseparation laws via deep reinforcement learning,” Computer Methods in Applied Mechanics and Engineering,\nvol. 346, pp. 216–241, Apr. 2019.\n[596] M. P. Bendse, “Optimal shape design as a material distribution problem,” Structural optimization, vol. 1,\npp. 193–202, Dec. 1989.\n[597] M. P. Bendse and O. Sigmund, Topology Optimization. Berlin, Heidelberg: Springer, 2004.\n[598] K. Hayashi and M. Ohsaki, “Reinforcement Learning and Graph Embedding for Binary Truss Topology Opti-\nmization Under Stress and Displacement Constraints,” Frontiers in Built Environment, vol. 6, 2020.\n[599] S. Zhu, M. Ohsaki, K. Hayashi, and X. Guo, “Machine-specified ground structures for topology optimization of\nbinary trusses using graph embedding policy network,” Advances in Engineering Software, vol. 159, p. 103032,\nSept. 2021.\n[600] H. Sun and L. Ma, “Generative Design by Using Exploration Approaches of Reinforcement Learning in Density-\nBased Structural Topology Optimization,” Designs, vol. 4, p. 10, June 2020.\n[601] S. Jang, S. Yoo, and N. Kang, “Generative Design by Reinforcement Learning: Enhancing the Diversity of\nTopology Optimization Designs,” Computer-Aided Design, vol. 146, p. 103225, May 2022.\n[602] J. Han, A. Jentzen, and W. E, “Solving high-dimensional partial differential equations using deep learning,”\nProceedings of the National Academy of Sciences, vol. 115, pp. 8505–8510, Aug. 2018.\n[603] W. E and B. Yu, “The Deep Ritz method: A deep learning-based numerical algorithm for solving variational\nproblems,” arXiv:1710.00211 [cs, stat], Sept. 2017. arXiv: 1710.00211.\n[604] J. Yang, T. Dzanic, B. Petersen, J. Kudo, K. Mittal, V. Tomov, J.-S. Camier, T. Zhao, H. Zha, T. Kolev,\nR. Anderson, and D. Faissol, “Reinforcement Learning for Adaptive Mesh Refinement,” in Proceedings of The\n26th International Conference on Artificial Intelligence and Statistics, pp. 5997–6014, PMLR, Apr. 2023.\n[605] J. Rabault and A. Kuhnle, “Accelerating Deep Reinforcement Learning strategies of Flow Control through a\nmulti-environment approach,” Physics of Fluids, vol. 31, p. 094105, Sept. 2019. arXiv:1906.10382 [physics].\n[606] G. Novati, H. L. de Laroussilhe, and P. Koumoutsakos, “Automating Turbulence Modeling by Multi-Agent\nReinforcement Learning,” arXiv:2005.09023 [physics], Oct. 2020. arXiv: 2005.09023.\n[607] X.-Y. Liu and J.-X. Wang, “Physics-informed Dyna-style model-based deep reinforcement learning for dy-\nnamic control,” Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences, vol. 477,\np. 20210618, Nov. 2021.\n[608] H. Shi, Y. Zhou, K. Wu, S. Chen, B. Ran, and Q. Nie, “Physics-informed deep reinforcement learning-based\nintegrated two-dimensional car-following control strategy for connected automated vehicles,” Knowledge-Based\nSystems, vol. 269, p. 110485, June 2023.\n[609] A. Ramesh and B. Ravindran,\n“Physics-Informed Model-Based Reinforcement Learning,”\nMay 2023.\narXiv:2212.02179 [cs].\n[610] C. Rodwell and P. Tallapragada, “Physics-informed reinforcement learning for motion control of a fish-like\nswimming robot,” Scientific Reports, vol. 13, p. 10754, July 2023.\n[611] R. S. Sutton, “Dyna, an integrated architecture for learning, planning, and reacting,” ACM SIGART Bulletin,\nvol. 2, pp. 160–163, July 1991.\n[612] M. Janner, J. Fu, M. Zhang, and S. Levine, “When to trust your model: model-based policy optimization,”\nin Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1122,\npp. 12519–12530, Red Hook, NY, USA: Curran Associates Inc., Dec. 2019.\n[613] L. Kaiser, M. Babaeizadeh, P. Milos, B. Osinski, R. H. Campbell, K. Czechowski, D. Erhan, C. Finn, P. Koza-\nkowski, S. Levine, A. Mohiuddin, R. Sepassi, G. Tucker, and H. Michalewski, “Model-Based Reinforcement\nLearning for Atari,” Feb. 2020. arXiv:1903.00374 [cs, stat].\n[614] Y. Luo, H. Xu, Y. Li, Y. Tian, T. Darrell, and T. Ma, “Algorithmic Framework for Model-based Deep Rein-\nforcement Learning with Theoretical Guarantees,” Feb. 2021. arXiv:1807.03858 [cs, stat].\n[615] M. P. Deisenroth and C. E. Rasmussen, “PILCO: a model-based and data-efficient approach to policy search,” in\nProceedings of the 28th International Conference on International Conference on Machine Learning, ICML’11,\n(Madison, WI, USA), pp. 465–472, Omnipress, June 2011.\n[616] S. Levine and P. Abbeel, “Learning Neural Network Policies with Guided Policy Search under Unknown Dy-\nnamics,” in Advances in Neural Information Processing Systems, vol. 27, Curran Associates, Inc., 2014.\n[617] N. Heess, G. Wayne, D. Silver, T. Lillicrap, T. Erez, and Y. Tassa, “Learning Continuous Control Policies by\nStochastic Value Gradients,” in Advances in Neural Information Processing Systems, vol. 28, Curran Associates,\nInc., 2015.\n[618] I. Clavera, V. Fu, and P. Abbeel, “Model-Augmented Actor-Critic: Backpropagating through Paths,” May\n2020. arXiv:2005.08068 [cs, stat].\n[619] D. Hafner, T. Lillicrap, J. Ba, and M. Norouzi, “Dream to Control: Learning Behaviors by Latent Imagination,”\nMar. 2020. arXiv:1912.01603 [cs].\n[620] D. Hafner, T. Lillicrap, M. Norouzi, and J. Ba, “Mastering Atari with Discrete World Models,” Feb. 2022.\narXiv:2010.02193 [cs, stat].\n61\n[621] R. J. Williams, “Simple statistical gradient-following algorithms for connectionist reinforcement learning,”\nMachine Learning, vol. 8, pp. 229–256, May 1992.\n[622] R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour, “Policy Gradient Methods for Reinforcement Learning\nwith Function Approximation,” in Advances in Neural Information Processing Systems, vol. 12, MIT Press,\n1999.\n[623] S. M. Kakade, “A Natural Policy Gradient,” in Advances in Neural Information Processing Systems, vol. 14,\nMIT Press, 2001.\n[624] D. Silver, G. Lever, N. Heess, T. Degris, D. Wierstra, and M. Riedmiller, “Deterministic Policy Gradient\nAlgorithms,” in Proceedings of the 31st International Conference on Machine Learning, pp. 387–395, PMLR,\nJan. 2014.\n[625] J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz, “Trust Region Policy Optimization,” in Proceed-\nings of the 32nd International Conference on Machine Learning, pp. 1889–1897, PMLR, June 2015.\n[626] C. J. C. H. Watkins and P. Dayan, “Q-learning,” Machine Learning, vol. 8, pp. 279–292, May 1992.\n[627] H. v. Hasselt, A. Guez, and D. Silver, “Deep reinforcement learning with double Q-Learning,” in Proceedings of\nthe Thirtieth AAAI Conference on Artificial Intelligence, AAAI’16, (Phoenix, Arizona), pp. 2094–2100, AAAI\nPress, Feb. 2016.\n[628] Z. Wang, T. Schaul, M. Hessel, H. Van Hasselt, M. Lanctot, and N. De Freitas, “Dueling network architectures\nfor deep reinforcement learning,” in Proceedings of the 33rd International Conference on International Con-\nference on Machine Learning - Volume 48, ICML’16, (New York, NY, USA), pp. 1995–2003, JMLR.org, June\n2016.\n[629] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, “Proximal Policy Optimization Algorithms,”\nAug. 2017. arXiv:1707.06347 [cs].\n[630] R. Bellman, “A Markovian Decision Process,” Journal of Mathematics and Mechanics, vol. 6, no. 5, pp. 679–684,\n1957.\n[631] I. C. Dolcetta and H. Ishii, “Approximate solutions of the bellman equation of deterministic control theory,”\nApplied Mathematics & Optimization, vol. 11, pp. 161–181, Feb. 1984.\n[632] R. S. Sutton, “Learning to predict by the methods of temporal differences,” Machine Learning, vol. 3, pp. 9–44,\nAug. 1988.\n[633] S. J. Bradtke and A. G. Barto, “Linear Least-Squares algorithms for temporal difference learning,” Machine\nLearning, vol. 22, pp. 33–57, Mar. 1996.\n62\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2023-09-27",
  "updated": "2023-09-27"
}