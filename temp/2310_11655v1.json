{
  "id": "http://arxiv.org/abs/2310.11655v1",
  "title": "Field-testing items using artificial intelligence: Natural language processing with transformers",
  "authors": [
    "Hotaka Maeda"
  ],
  "abstract": "Five thousand variations of the RoBERTa model, an artificially intelligent\n\"transformer\" that can understand text language, completed an English literacy\nexam with 29 multiple-choice questions. Data were used to calculate the\npsychometric properties of the items, which showed some degree of agreement to\nthose obtained from human examinee data.",
  "text": "Field-testing items using artificial intelligence: Natural language processing with transformers \nHotaka Maeda, PhD, Smarter Balanced \nhotaka.maeda@smarterbalanced.org  \n \nAbstract  \nFive thousand variations of the RoBERTa model, an artificially intelligent ‚Äútransformer‚Äù \nthat can understand text language, completed an English literacy exam with 29 multiple-choice \nquestions. Data were used to calculate the psychometric properties of the items, which showed \nsome degree of agreement to those obtained from human examinee data.  \n \nIntroduction \n \nField-testing is costly and time-consuming (Jiao & Lissitz, 2020). There has been a \nvariety of efforts to limit the need for extensive field-testing of new items (e.g., Glas & van der \nLinden, 2003). Some have turned to natural language processing (NLP) to approximate item \ndifficulty and discrimination from the item text (Benedetto et al., 2020; Laverghetta et al., 2021; \nLuger, 2016). NLP is a branch of artificial intelligence (AI) concerned with providing computers \nan understanding of text and language. Currently, the field of NLP is led by the state-of-the-art \nclass of deep learning model architecture called the transformer (Vaswani et al., 2017). The core \nof transformers is the multiheaded attention mechanism, which create the meaning of each word \nefficiently by identifying its contextual relationship with the other words. For example, \ntransformers are able to distinguish the difference in the meaning of ‚Äúcheck‚Äù in the phrases \n‚Äúwrite a check‚Äù and ‚Äúcheck the engine‚Äù. Transformers also excel at understanding the meaning \nof relatively long text.  \nOne recently introduced transformers is RoBERTa (Yinhan et al., 2019), which is based \non the BERT model (Devlin et al., 2018) and has been pre-trained using 160GB of English text. \nRoBERTa is able to answer both open-ended and multiple-choice questions (MCQ) by selecting \nphrases that have the highest probability of matching the context. There have not been attempts \nto use transformers to generate human-like item response data for use in psychometric analyses. \nIn this proof-of-concept study, RoBERTa with varying levels of intelligence was created by \nmanipulating its vocabulary, and used to generate item response data for English MCQ items in \nan attempt to estimate their item parameters. These RoBERTa-based item parameters were \ncompared with those from human data.  \nMethod \nRoBERTa \nThe 1.4GB RoBERTa-large model (Liu et al., 2019) fine-tuned using the RACE dataset \n(Lai et al., 2017) was used. RACE is a publicly available English reading comprehension dataset \nwith 27,933 passages and 97,867 four-option MCQ items, which is a design similar to the items \nincluded in the current study. RoBERTa answered 85.2% of the RACE items correctly.  \nRoBERTa holds a vocabulary of 50,265 tokens (i.e., words, sub-words, or punctuation), \neach with 1,024 numerical weights called ‚Äúword embeddings‚Äù that define its latent meaning \n(Turian et al., 2010). In each iteration of this study, a random proportion ùëà·à∫0,1·àª of the 50,265 \ntokens was randomly selected, then their weights were set to zero. This manipulation effectively \nforces RoBERTa to ‚Äúforget‚Äù the meanings of some words. This was a simple, computationally \nfast, and effective way to create less intelligent variations of RoBERTa.  \nItem selection \n \nThird-grade English literacy four-option MCQ were used in the study. Items regarding \ngrammar, bolded words, underlined words, fill-in-the-blank, images, or audio were removed. \nItems with more than 512 tokens were removed, as RoBERTa can process only 512 tokens \nsimultaneously. There were 34 items that qualified, 5 of which RoBERTa answered incorrectly \n(85% correct) and were removed. Therefore, 29 items were included in the study (see Figure 1). \nData collection \nThe 2-parameter logistic model (2PL) parameters for the 29 items were previously \nestimated using human 3rd grade student data in the United States (N=814 to 5,283 per item), \nwith ability ùúÉ~ùëÅ·à∫0,1·àª. N=5,000 variations of RoBERTa completed the 29-item exam using the \ntransformers 4.18.0 and PyTorch 1.12.1 libraries in Python. RoBERTa provided the probability \nthat each response option may be correct. Based on these probabilities, a response was randomly \nselected for each item.  \nParameter estimation \nRoBERTa‚Äôs item responses were used to estimate the 2PL model with a 1.7 scaling factor \nusing the mirt package in R (Chalmers, 2012). Mean and SD of ùúÉ were freely estimated. To place \nhuman and RoBERTa parameters on the same scale, item parameters were estimated one item at \na time, with all others fixed (i.e., anchored) to the human-based values. RoBERTa‚Äôs ability \nestimates were obtained using both human (ùúÉ‡∑†‡ØÅ) and RoBERTa (ùúÉ‡∑†‡Øã) item parameters, with \nmaximum a-posteriori with a weak prior  ùúÉ~ùëÅ·à∫0,100·àª. Human and RoBERTa statistics were \ncompared using mean bias (RoBERTa minus human), root-mean-squared-error (RMSE), and \nSpearman correlation. \nResult \n \nRoBERTa‚Äôs mean score was .47 (SD=0.23, Cronbach‚Äôs Œ±=.87). A high negative \ncorrelation (r=-.86) between ùúÉ‡∑†‡Øã and the proportion of word embedding weights set to zero \nshowed that the RoBERTa‚Äôs intelligence was manipulated effectively (see Figure 2). Positive \ncorrelations were found between the corresponding human and RoBERTa-based item statistics \n(r=.39 to .47; see Table 1 and Figure 3). Ability estimates ùúÉ‡∑†‡ØÅ and ùúÉ‡∑†‡Øã were similar (bias=0.03, \nRMSE=0.22, r=.99), showing little practical difference of using human and RoBERTa-based \nitem parameters on test scores (see Figure 4).  \nDiscussion  \nThis preliminary study demonstrated the potential of approximating the item parameters \nof new items using transformer NLP models. To the author‚Äôs knowledge, this was also the first \nstudy to purposely and randomly downgrade the AI‚Äôs intelligence in an attempt to generate \nhuman-like item responses. There was some agreement between humans and RoBERTa about \nwhich items were difficult or discriminate well. However, there were still considerable \ndisagreements, which may be explained partly that human intelligence is not as simple as a \nrandom proportion of known vocabulary. A more complex manipulation of the AI‚Äôs intelligence \nmay be necessary to mimic the diverse knowledge levels and patterns of the target human \npopulation.  \nPotentially, using AI can bypass or reduce the need to administer field-test items to real \nhumans, which could save resources for testing organizations and reduce the stress on examinees \nto complete more items. Unlike human examinees, AI could take thousands of items in a large \nitem pool without fatigue or exposure, which may be replicated until ability and item parameter \nestimation error are near zero.  \nLimitations included the lack of access to individual human data, and RoBERTa‚Äôs \nincompatibility for answering some items. In the future, transformers could be fine-tuned using \noperational items similarly designed to the field-test items. Ethics of using AI for field-testing \nmust also be considered, such as how to incorporate differential item functioning analysis in the \nprocess.  \n \n \n \nReferences \nBenedetto, L., Cappelli, A., Turrin, R., & Cremonesi, P. (2020, March). R2DE: a NLP approach \nto estimating IRT parameters of newly generated questions. In Proceedings of the Tenth \nInternational Conference on Learning Analytics & Knowledge (pp. 412-421). \nChalmers, R. P. (2012). mirt: A multidimensional item response theory package for the R \nenvironment. Journal of statistical Software, 48, 1-29. \nDevlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep \nbidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. \nGlas, C. A. W., & van der Linden, W. J. (2003). Computerized adaptive testing with item \ncloning. Applied Psychological Measurement, 27, 247‚Äì 261. \nJiao, H., & Lissitz, R. W. (Eds.). (2020). Application of Artificial Intelligence to Assessment. \nCharlotte, NC: Information Age Publishing. \nLai, G., Xie, Q., Liu, H., Yang, Y., & Hovy, E. (2017). Race: Large-scale reading \ncomprehension dataset from examinations. arXiv preprint arXiv:1704.04683. \nLaverghetta Jr, A., Nighojkar, A., Mirzakhalov, J., & Licato, J. (2021). Can Transformer \nLanguage Models Predict Psychometric Properties?. arXiv preprint arXiv:2106.06849. \nLiu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). Roberta: A \nrobustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692. \nLuger, S. K. K. (2016). Algorithms for assessing the quality and difficulty of multiple choice \nexam questions. Retrieved from https://core.ac.uk/download/429732098.pdf  \nTurian, J., Ratinov, L., & Bengio, Y. (2010). Word representations: a simple and general method \nfor semi-supervised learning. In Proceedings of the 48th annual meeting of the association for \ncomputational linguistics (pp. 384-394). \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, ≈Å. & \nPolosukhin, I. (2017). Attention is all you need. Advances in Neural Information Processing \nSystems (pp. 5998-6008). \n \n \n \nFigure 1. An example 3rd grade English literacy item from the study that RoBERTa answered \ncorrectly (Item #10 on Figure 2) \n \n \n \n \nFigure 2. RoBERTa‚Äôs mean test score by proportions of original vocabulary retained \n \nFigure 3. 2PL item response functions estimated from human and RoBERTa‚Äôs data (29 items, \nsorted by item difficulty) \n \nFigure 4. RoBERTa‚Äôs estimated theta based on item parameters estimated from human and \nRoBERTa data \n \nTable 1.  \n  \nStatistic \nRoBERTa \nability \n2PL \ndiscrimination \n2PL \ndifficultya \nProportion \ncorrectb \nItem-total \ncorrelationb \nHuman data \n \n \n \n \n \n \n \nMean \n-0.32 \n0.66 \n0.05 \n.52 \n.50 \n \nSD \n1.08 \n0.26 \n0.83 \n.13 \n.17 \n \nMedian \n-0.53 \n0.65 \n-0.12 \n.52 \n.55 \n \nMin \n-3.66 \n0.19 \n-0.97 \n.32 \n.16 \n \nMax \n8.62 \n1.2 \n2.14 \n.76 \n.73 \nRoBERTa data  \n \n \n \n \n \n \nMean \n-0.29 \n0.7 \n0.6 \n.45 \n.47 \n \nSD \n1.12 \n0.36 \n4.25 \n.08 \n.10 \n \nMedian \n-0.55 \n0.64 \n-0.27 \n.45 \n.47 \n \nMin \n-6.36 \n0.02 \n-0.83 \n.27 \n.20 \n \nMax \n8.15 \n1.68 \n22.55 \n.65 \n.61 \nComparison \n \n \n \n \n \nBias \n0.03 \n0.04 \n0.55 \n \n \n \nRMSE \n0.22 \n0.33 \n4.21 \n \n \n  \nSpearman Correlation \n.99 \n.39 \n.45 \n.47 \n.47 \nNote. 2PL = 2-parameter logistic model; RMSE = root-mean-squared-error; Statistics calculated from human and \nRoBERTa‚Äôs response data and their comparisons are shown. The 2PL model parameters for humans and RoBERTa \nhave been placed on the same scale. RoBERTa‚Äôs ability was calculated using human and RoBERTa item \nparameters. \naWith an outlier removed (item 22 on Figure 3), bias improved to -0.22, and RMSE to 0.73.   \nbBias and RMSE are not shown as they would be misleading comparisons \n \n \n \n",
  "categories": [
    "cs.CL"
  ],
  "published": "2023-10-18",
  "updated": "2023-10-18"
}