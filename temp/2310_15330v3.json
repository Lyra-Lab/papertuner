{
  "id": "http://arxiv.org/abs/2310.15330v3",
  "title": "Towards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms",
  "authors": [
    "Ye Tian",
    "Haolei Weng",
    "Yang Feng"
  ],
  "abstract": "While supervised federated learning approaches have enjoyed significant\nsuccess, the domain of unsupervised federated learning remains relatively\nunderexplored. Several federated EM algorithms have gained popularity in\npractice, however, their theoretical foundations are often lacking. In this\npaper, we first introduce a federated gradient EM algorithm (FedGrEM) designed\nfor the unsupervised learning of mixture models, which supplements the existing\nfederated EM algorithms by considering task heterogeneity and potential\nadversarial attacks. We present a comprehensive finite-sample theory that holds\nfor general mixture models, then apply this general theory on specific\nstatistical models to characterize the explicit estimation error of model\nparameters and mixture proportions. Our theory elucidates when and how FedGrEM\noutperforms local single-task learning with insights extending to existing\nfederated EM algorithms. This bridges the gap between their practical success\nand theoretical understanding. Our numerical results validate our theory, and\ndemonstrate FedGrEM's superiority over existing unsupervised federated learning\nbenchmarks.",
  "text": "Towards the Theory of Unsupervised Federated Learning: Non-asymptotic\nAnalysis of Federated EM Algorithms\nYe Tian 1 Haolei Weng 2 Yang Feng 3\nAbstract\nWhile supervised federated learning approaches\nhave enjoyed significant success, the domain\nof unsupervised federated learning remains rel-\natively underexplored. Several federated EM al-\ngorithms have gained popularity in practice, how-\never, their theoretical foundations are often lack-\ning.\nIn this paper, we first introduce a feder-\nated gradient EM algorithm (FedGrEM) designed\nfor the unsupervised learning of mixture models,\nwhich supplements the existing federated EM al-\ngorithms by considering task heterogeneity and\npotential adversarial attacks. We present a com-\nprehensive finite-sample theory that holds for gen-\neral mixture models, then apply this general the-\nory on specific statistical models to characterize\nthe explicit estimation error of model parameters\nand mixture proportions. Our theory elucidates\nwhen and how FedGrEM outperforms local single-\ntask learning with insights extending to existing\nfederated EM algorithms. This bridges the gap\nbetween their practical success and theoretical\nunderstanding. Our numerical results validate\nour theory, and demonstrate FedGrEM’s superior-\nity over existing unsupervised federated learning\nbenchmarks.\n1. Introduction\nFederated learning (FDL) is a machine learning paradigm\nthat allows the training of statistical models by leveraging\ndata from various local tasks, while ensuring the data re-\nmains decentralized to protect privacy (Li et al., 2020a).\nIntroduced a few years ago, notably by Google (Koneˇcn`y\n1Department of Statistics, Columbia University, New York,\nUSA 2Department of Statistics and Probability, Michigan State\nUniversity, East Lansing, USA 3Department of Biostatistics,\nSchool of Global Public Health, New York University, New York,\nUSA. Correspondence to: Yang Feng <yang.feng@nyu.edu>.\nProceedings of the 41 st International Conference on Machine\nLearning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by\nthe author(s).\net al., 2016; McMahan et al., 2017), FDL has witnessed\nremarkable success in a diverse range of applications, in-\ncluding smartphones (Hard et al., 2018), healthcare (An-\ntunes et al., 2022), and the internet of things (Nguyen et al.,\n2021). However, it is important to note that a large por-\ntion of current FDL research is centered around supervised\nlearning problems. In this paper, we delve into the realm of\nunsupervised FDL, a scenario in which each task involves a\nmixture of distributions.\nBefore proceeding further, we summarize the mathemati-\ncal notations used in this paper here. P and E denote the\nprobability and expectation, respectively. For two positive\nsequences {an} and {bn}, an ≪bn or an = O(bn) means\nan/bn →0, an ≲bn or an = O(bn) means an/bn ≤C <\n∞, and an ≍bn means an/bn, bn/an ≤C < ∞. e\nO(bn) is\nthe same as an = O(bn) up to logarithmic factors. For a ran-\ndom variable xn and a positive sequence an, xn = OP(an)\nmeans that for any ϵ > 0, there exists M > 0 such that\nsupn P(|xn/an| > M) ≤ϵ. e\nOP(an) has a similar meaning\nup to logarithmic factors in an. For a vector x ∈Rd, ∥x∥2\nrepresents its Euclidean norm. For two numbers a and b,\na∨b = max{a, b} and a∧b = min{a, b}. For any positive\ninteger K, 1 : K and [K] stand for the set {1, 2, . . . , K}.\nAnd for any set S, |S| denotes its cardinality and Sc denotes\nits complement. “w.p.” stands for “with probability”. The\nabsolute constants c and C may vary from line to line.\n2. Federated Learning on Mixture of\nDistributions\n2.1. Problem Setting\nConsider K tasks, where for the k-th task, we observe data\n{x(k)\ni\n}n\ni=1 ⊆Rd 1. There exists an unknown subset S ⊆\n[K], such that each observation in task k ∈S comes from a\nmixture model with R components (R ≥2):\nx(k)\ni\ni.i.d.\n∼\nR\nX\nr=1\nw(k)∗\nr\n· p(k)\nr ( · ; θ(k)∗\nr\n),\n(1)\n1For simplicity, we assume all tasks share the same sample size\nn. We can easily extend our analysis to the case of heterogeneous\ntask sample sizes with similar theoretical results.\n1\narXiv:2310.15330v3  [stat.ML]  14 Jun 2024\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nwhere the mixture proportion {w(k)∗\nr\n}R\nr=1 ⊆(0, 1) with\nPR\nr=1 w(k)∗\nr\n= 1 and p(k)\nr ( · ; θ(k)∗\nr\n) is a Radon-Nikodym\ndensity w.r.t. a base measure σ. θ(k)∗\nr\n∈Rd 2 are the pa-\nrameters that index the distribution p(k)\nr . This is equivalent\nto\nz(k)\ni\ni.i.d.\n∼\nR\nX\nr=1\nw(k)∗\nr\n·δr,\nx(k)\ni\n|z(k)\ni\n= r\ni.i.d.\n∼p(k)\nr ( · ; θ(k)∗\nr\n),\n(2)\nfor k ∈S, where z(k)\ni\nis the unobserved latent cluster label\nand δr is the point mass at r. Here S is the index of simi-\nlar tasks (unknown), where the parameters {θ(k)∗\nr\n}k∈S of\ndifferent tasks are “similar” to each other, in the sense that\nmin\nθ∈Rd max\nk∈S ∥θ(k)∗\nr\n−θ∥2 ≤h,\n∀r ∈[R],\nwhere h is an unknown parameter controlling the task sim-\nilarity level. A small h implies that the tasks are more\nsimilar. The data from tasks in set Sc = [K]\\S can be\narbitrarily distributed, i.e., {x(k)\ni\n}i∈[n],k∈Sc follow an arbi-\ntrary joint distribution QSc, and we denote the proportion\nϵ := |Sc|/K ∈[0, 1). Note that h, K, R and d can change\nwith single-task sample size n.\nThere are two different interpretations of this setting.\nThe first one is from the perspective of adversarial at-\ntacks/contaminations, where there is an adversarial attacker\nwho can arbitrarily contaminate the data of tasks in an index\nset Sc. The index set Sc and the distribution QSc are picked\nby the attacker after we pick the estimator (hence Sc and\nQSc are unknown to us). A similar setting can be found in\nQiao (2018), Konstantinov & Lampert (2019), Konstantinov\net al. (2020), and Tian et al. (2023).\nAlternatively, aside from adversarial attacks, we can in-\nterpret the presence of contaminated data sets as a result\nof outlier tasks. In the era of big data, certain collected\ndata sets may exhibit distributions significantly different\nfrom others, particularly when dealing with numerous tasks\n(Zhang & Yang, 2021). These data sets within Sc can be\nviewed as outlier tasks. In practice, detecting outlier tasks\nis challenging.\nIn the rest of this paper, we may take the views of “adver-\nsarial attacks” and “outlier tasks” interchangeably.\nNote that in our unsupervised learning setting, similar to\nMarfoq et al. (2021) and Wu et al. (2023), we avoid as-\nsuming that the mixture proportions {w(k)∗\nr\n}k∈S are similar\nacross tasks, which offers more flexibility in practice.\nThe goal is to develop an algorithm to estimate the\nmixture proportions {w(k)∗\nr\n}k∈S,r∈[R] and the parameters\n2For simplicity, we assume parameters and observations are of\nthe same dimension, but our results can be generalized to the case\nwhere the two dimensions are different.\n{θ(k)∗\nr\n}k∈S,r∈[R] simultaneously, which satisfies the follow-\ning five desired properties:\n(i) Adaptability to unknown similarity level h: The algo-\nrithm should utilize the data from different sources in\nan “optimal” way. When h is small, the output estima-\ntor should achieve a better convergence rate than the\nlocal estimator (or single-task estimator of each task).\nWhen h is large, the output estimator should perform\nno worse than the local estimator.\n(ii) Robustness against the adversarial attack on a small\nfraction of sources: The output estimator should main-\ntain a good performance when the contaminated pro-\nportion ϵ is small.\n(iii) Privacy for local data: The algorithm should avoid\ntransferring raw data out of each task.\n(iv) Computation efficiency on local servers: The local\ncomputational cost should be low.\n(v) Communication efficiency between local and global\nservers: The communicational cost should be low.\n2.2. Related Works\nFederated learning (FDL): While there exists an exten-\nsive body of literature on FDL, the majority of it centers\naround the supervised learning paradigm. Notable frame-\nworks within supervised FDL include COCOA (Jaggi et al.,\n2014), MOCHA (Smith et al., 2017), and FedAvg (McMa-\nhan et al., 2017). To accommodate varying task character-\nistics, FedProx was introduced by Li et al. (2020b). See\nYang et al. (2019) and Li et al. (2020a) for a comprehen-\nsive overview of supervised FDL. In contrast to supervised\nFDL, much less attention has been given to unsupervised\nFDL with mixture models. Marfoq et al. (2021) examined a\nsimilar FDL problem presented in this paper and introduced\na federated EM algorithm without exploring the estimation\nerror of the parameter estimators. Dieuleveut et al. (2021)\nalso proposed a federated EM algorithm that supports com-\nmunication compression and partial participation. Wu et al.\n(2023) adapted the EM algorithm to the scenario where pre-\ndictors are from Gaussian Mixture Models (GMMs) and the\nregression models can encompass general mixture models.\nNotably, none of these papers provided finite-sample results\nfor their EM algorithm (which is the key to interpreting\ntheir practical successes) nor discussed the adversarial at-\ntacks and outlier tasks. Our work complements this line\nof research by explicitly accommodating outlier tasks, pro-\nviding comprehensive finite-sample results, and applying\nthe developed theory to illustrative model examples. Our\ntheory illustrates when and how the aforementioned feder-\nated EM algorithms (Dieuleveut et al., 2021; Marfoq et al.,\n2\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n2021; Wu et al., 2023) outperform local single-task learn-\ning. Note that there exist works on clustered FDL, wherein\ntasks are organized into several groups with tasks within\neach group being identical (task-level mixture) (Ghosh et al.,\n2020; Kong et al., 2020; Su et al., 2022). This setting differs\nfrom ours, where each task’s data originates from a mixture\nmodel at the sample level.\nMulti-task learning (MTL) and transfer learning (TL):\nProblems related to federated learning but permitting raw\ndata sharing across tasks include multi-task learning and\ntransfer learning. Analogous to federated learning, a sub-\nstantial proportion of research in MTL and TL centers on\nsupervised learning. In unsupervised MTL and TL, there\nhave been diverse approaches, including the kernel k-means\nclustering (Gu et al., 2011), the spectral method (Yang et al.,\n2014), and the penalized optimization (Dai et al., 2008;\nZhang & Zhang, 2011; Zhang et al., 2015; 2018). Specific\nmixture models such as Gaussian Mixture Models (GMMs)\nhave also been explored (Wang et al., 2021; Tian et al.,\n2022). Discussions on outlier tasks, adversarial attacks, and\nnegative transfer in MTL and TL have emerged in various\nmodel settings, for example, Qiao (2018); Konstantinov &\nLampert (2019); Hanneke & Kpotufe (2020); Konstantinov\net al. (2020); Li et al. (2021); Duan & Wang (2022); Tian\net al. (2023).\nEM algorithm: The EM algorithm was formalized by\nDempster et al. (1977), and there have been intensive studies\non the local convergence of the likelihood and the estimator\nto some stationary point (Wu, 1983; Redner & Walker, 1984;\nMeng & Rubin, 1994; McLachlan & Krishnan, 2007). More\nrecently, Xu et al. (2016) established the global convergence\nof EM algorithm on binary GMMs. Additionally, Balakr-\nishnan et al. (2017), Yan et al. (2017), Cai et al. (2019),\nKwon & Caramanis (2020a), Kwon & Caramanis (2020b),\nand Zhao et al. (2020) provided finite-sample convergence\nresults for EM and its variants under certain initialization\nconditions.\n2.3. A Federated Gradient EM: FedGrEM\nBefore delving into our main algorithm, we first introduce\nsome key notations and definitions. The posterior, i.e. the\nprobability of z(k) = r conditioned on the observation x(k),\ngiven that (x(k), z(k)) is from the mixture model (2) with\nparameters w(k) = {w(k)\nr }R\nr=1 and θ(k) = {θ(k)\nr }R\nr=1, is\ndefined as\nP(z(k) = r|x(k); w(k), θ(k))\n=\nw(k)\nr\n× p(k)\nr (x(k); θ(k)\nr )\nPR\nr=1 w(k)\nr\n× p(k)\nr (x(k); θ(k)\nr )\n.\nBased on this posterior, we define\nQ(k)(θ|w′, θ′) = E\n\"\nR\nX\nr=1\nP(z(k) = r|x(k); w′, θ′)\n× log p(k)\nr (x(k); θr)\n#\n,\nwhere θ = {θr}R\nr=1, w′ = {w′\nr}R\nr=1, and θ′ = {θ′\nr}R\nr=1.\nBy Jensen’s inequality, it can be shown that Q(k)(θ|w′, θ′)\nis a lower bound of the complete population-level log-\nlikelihood E log\n\u0002 PR\nr=1 wrp(k)\nr (x(k); θr)\n\u0003\n. The latter one\nis difficult to manage as the summation is within the loga-\nrithm. The EM algorithm endeavors to maximize the sur-\nrogate Q(k)(θ|w′, θ′) by iteratively alternating with the\nE-step and M-step. Gradient EM does a one-step gradi-\nent ascent in M-step instead of finding the exact optimizer,\nwhich can speed up the computation. In practice, we work\non a sample-based variant of Q(k)(θ|w′, θ′) as\nbQ(k)\u0000θ|w′, θ′\u0001\n= 1\nn\nn\nX\ni=1\nR\nX\nr=1\nP(z(k) = r|x(k)\ni\n; w′, θ′) × log p(k)\nr (x(k)\ni\n; θr).\nNow, we are ready to introduce our core algorithm Fed-\nGrEM in Algorithm 1. It executes the E-step and M-step\nlocally on each task, pooling the estimators of {θ(k)∗\nr\n}K\nk=1\nobtained in M-step by penalizing the ℓ2-distance between\neach estimator and a common center. This approach mir-\nrors the penalization strategy used in other MTL and TL\nliterature, such as Evgeniou & Pontil (2004); Li & Bilmes\n(2007); Lounici et al. (2011); Solnon et al. (2012); Jalali et al.\n(2013); Kuzborskij & Orabona (2013; 2017); Denevi et al.\n(2018); T Dinh et al. (2020); Li et al. (2021); Tian & Feng\n(2023); He et al. (2024); Lin & Reimherr (2024a;b). After\nseveral iterations of local and central updates, FedGrEM\nyields the final estimators. Figure 1 provides an intuitive\nillustration of the workflow of FedGrEM.\nWhile the core idea of FedGrEM is akin to FedEM in Mar-\nfoq et al. (2021) and FedGMM in Wu et al. (2023), two\ncrucial distinctions set them apart. First, we employ gra-\ndient EM, while FedEM and FedGMM use the full EM.\nSecond, the central update of FedGrEM can adapt to the het-\nerogeneity of θ(k)∗\nr\n’s across tasks and remain robust when\na small proportion of tasks is contaminated, which are not\npresent in FedEM or FedGMM. On the other hand, by set-\nting λ[t] = +∞, FedGrEM can be viewed as a simplified\ngradient version of FedEM and FedGMM, therefore our non-\nasymptotic theory in Section 3 can illustrate the empirical\nsuccess achieved by FedEM and FedGMM.\nFedGrEM is computationally efficient on local servers as it\ncomputes the gradient instead of explicitly solving the maxi-\nmizer of bQ(k). It is also communicationally efficient because\n3\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nAlgorithm 1 FedGrEM: A Federated Gradient EM Algorithm\nInput: Initializations { b\nw(k)[0]}k∈[K] and {bθ(k)[0]}k∈[K] ( b\nw(k)[0] = { bw(k)[0]\nr\n}R\nr=1, bθ(k)[0] = {bθ(k)[0]\nr\n}R\nr=1), data\n{x(k)\ni\n}i∈[n],k∈[K], iteration number T, penalty parameters {λ[t]}T\nt=1, step sizes {η(k)\nr }k∈[K],r∈[R]\nfor t = 1 to T do\nLocal update: For task k = 1 : K:\n•\nE-step: bQ(k)(θ| b\nw(k)[t−1], bθ(k)[t−1]) := 1\nn\nPn\ni=1\nPR\nr=1 P(z(k) = r|x(k)\ni\n; b\nw(k)[t−1], bθ(k)[t−1]) log p(k)\nr (x(k)\ni\n; θr)\n•\nM-step:\n⋄bw(k)[t]\nr\n= 1\nn\nPn\ni=1 P(z(k) = r|x(k)\ni\n; b\nw(k)[t−1], bθ(k)[t−1])\n⋄eθ(k)[t]\nr\n= bθ(k)[t−1]\nr\n+ η(k)\nr\n·\n∂\n∂θr bQ(k)(θ| b\nw(k)[t−1], bθ(k)[t−1])|θ=bθ(k)[t−1]\nCentral update: {bθ(k)[t]\nr\n}K\nk=1, θ\n[t]\nr =\narg min\n{ν(k)}K\nk=1⊆Rd,ν∈Rd\nn PK\nk=1\n\u0000 n\n2 ∥ν(k) −eθ(k)[t]\nr\n∥2\n2 +√nλ[t] ·∥ν(k) −ν∥2\n\u0001o\n, define\nb\nw(k)[t] = { bw(k)[t]\nr\n}R\nr=1, bθ(k)[t] = {bθ(k)[t]\nr\n}R\nr=1\nend for\nOutput: Final estimators { bw(k)[T ]\nr\n}k∈[K],r∈[R] and {bθ(k)[T ]\nr\n}k∈[K],r∈[R]\nFigure 1. An illustration of Algorithm 1 (the iteration round t).\nit only necessitates the exchange of parameter estimators\nbetween local and central servers. Therefore, FedGrEM ful-\nfills all five of the desired properties we outlined in Section\n2.1.\n2.4. Our Contributions\nFirstly, we introduced FedGrEM, a federated EM algorithm\nthat exhibits robustness against a small number of adversar-\nially contaminated tasks while maintaining computational\nand communication efficiency. FedGrEM supplements the\nexisting federated EM algorithms in literature (Dieuleveut\net al., 2021; Marfoq et al., 2021; Wu et al., 2023) by consid-\nering the heterogeneity across tasks and adversarial contam-\ninations.\nSecond, we provided an extensive non-asymptotic theory\nfor FedGrEM on general mixture models. We characterized\nthe estimation error of w(k)∗\nr\nand θ(k)∗\nr\nfor non-outlier tasks\nby five main components:\n• Iterative error, which vanishes as the number of itera-\ntions goes to infinity;\n• Aggregation rate, which depends on the combined sam-\nple sizes of non-outlier tasks;\n• Cost of heterogeneous mixture proportions;\n• Cost of task heterogeneity;\n• Cost of outlier tasks.\nThis analysis revealed that when the tasks exhibit sufficient\nsimilarity and the proportion of outlier tasks is sufficiently\nsmall, the estimation error of FedGrEM surpasses the rate\nachieved by typical single-task algorithms such as the local\nsingle-task EM. Since the setting of existing federated EM\npapers can be seen as a special case (no model heterogeneity\nand contaminations) of the scenario we study, our theory\nhelps illustrate the empirical success of existing federated\nEM algorithms (Dieuleveut et al., 2021; Marfoq et al., 2021;\nWu et al., 2023) and offers new theoretical insights for\nunsupervised federated learning.\nThirdly, we addressed the often overlooked issue of cluster\nlabel permutation in federated EMs. While label permuta-\ntion is not a concern for single-task EM, most federated EM\nalgorithms require all non-outlier tasks to share the same\npermutation as they take an average over the parameter esti-\nmators for the same cluster in the M-step. Failure to align\nthe label permutations across non-outlier tasks can lead to\nthe failure of federated EM algorithms. Due to space limit,\nwe leave this part to Section C of the appendix.\n4\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n3. Theory\nIn this section, we introduce a generic non-asymptotic upper\nbound for the estimation error of FedGrEM and apply this\ntheory to two statistical examples: Gaussian Mixture Mod-\nels (GMMs) and Mixture of Regressions (MoRs). Our the-\noretical findings offer a clear interpretation, shedding light\non the conditions under which existing federated EM algo-\nrithms, including FedGrEM, can outperform local single-\ntask learning. To streamline the presentation, we provide\nsimplified versions of most theoretical results here, with\nformal details available in Section A of the appendix.\n3.1. Generic Analysis\nFor simplicity, denote q(k)(θ) = Q(k)(θ|w(k)∗, θ(k)∗). We\nfirst state a few assumptions that are necessary for our results\non general mixture models.\nAssumption 3.1 (Concavity and smoothness, a simplified\nversion of Assumption A.1). For all k ∈S, there exist non-\nnegative constants {µ(k)\nr }R\nr=1 and {L(k)\nr }R\nr=1 such that for\nall θ = {θr}R\nr=1, θ′ = {θ′\nr}R\nr=1:\n(i) (Strong\nconcavity)\nq(k)(θ′)\n−\nq(k)(θ)\n−\n∂\n∂θq(k)(θ)T (θ′ −θ) ≤−PR\nr=1\nµ(k)\nr\n2 ∥θ′\nr −θr∥2\n2;\n(ii) (Smoothness) q(k)(θ′) −q(k)(θ) −\n∂\n∂θq(k)(θ)T (θ′ −\nθ) ≥−PR\nr=1\nL(k)\nr\n2 ∥θ′\nr −θr∥2\n2.\nRemark 3.2. The same conditions are imposed by Balakr-\nishnan et al. (2017) in the single-task setting. The strong\nconcavity is usually assumed to obtain the parametric con-\nvergence rate, and the smoothness is imposed for gradient\ndescent to converge at a geometric rate.\nAssumption 3.3 (Contraction and convergence, a simplified\nversion of Assumptions A.3 and A.5). There exist a constant\nκ ∈(0, 1), and rate functions Rw(n), Rθ(n), such that for\nany k ∈S, such that for all w′ = {w′\nr}R\nr=1 and θ′ =\n{θ′\nr}R\nr=1 close to {w(k)∗\nr\n}R\nr=1 and {w(k)∗\nr\n}R\nr=1:\n(i) (Contraction)\n(a)\n\f\fE\n\u0002\nP(z(k) = r|x(k); w′, θ′)\n\u0003\n−w(k)∗\nr\n\f\f ≤κ ·\nPR\nr=1\n\u0000|w′\nr −w(k)∗\nr\n| + ∥θ′\nr −θ(k)∗\nr\n∥2\n\u0001\n;\n(b)\n\r\r ∂\n∂θr q(k)(θ)|θ=θ′ −\n∂\n∂θr Q(k)(θ|w′, θ′)|θ=θ′\r\r\n2\n≤κ · PR\nr=1\n\u0000|w′\nr −w(k)∗\nr\n| + ∥θ′\nr −θ(k)∗\nr\n∥2\n\u0001\n(ii) (Uniform convergence) w.p. 1 −O(1),\n(a)\n\f\f 1\nn\nPn\ni=1 P(z(k) = r|x(k)\ni\n; w′, θ′)−E\n\u0002\nP(z(k) =\nr|x(k); w′, θ′)\n\u0003\f\f ≤Rw(n);\n(b)\n\r\r ∂\n∂θr bQ(k)(θ|w′, θ′)|θ=θ′ −\n∂\n∂θr Q(k)(θ|w′, θ′)\n|θ=θ′\r\r\n2 ≤Rθ(n);\n(c)\n\r\r 1\n|S|\nP\nk∈S\n\u0002 ∂\n∂θr bQ(k)(θ|w′, θ′)|θ=θ′ −\n∂\n∂θr Q(k)\n(θ|w′, θ′)|θ=θ′\u0003\r\r\n2 ≤Rθ(nK).\nNote that Rw(n) and Rθ(n) also depend on other parame-\nters such as d and R, which we suppress in the notation for\nthe ease of presentation.\nRemark 3.4. Note that by definition w(k)∗\nr\n= E[P(z(k) =\nr|x(k); w(k)∗, θ(k)∗)]. Therefore, condition (i) describes\nthe behavior of E\n\u0002\nP(z(k)\n=\nr|x(k); w′, θ′)\n\u0003\nand\n∂\n∂θr Q(k)(θ|w′, θ′), and condition (ii) is a uniform conver-\ngence assumption on the same quantities, when w′ and θ′\nare close to the true values w(k)∗and θ(k)∗. Condition (i)\nhas been used by Balakrishnan et al. (2017) in the single-task\nsetting. Condition (ii).(b) and condition (ii).(c) are uniform\nconvergence assumptions on the gradient around the true\nparameter values, which are often needed when analyzing\nthe EM without data splitting (Yan et al., 2017; Cai et al.,\n2019). Condition (ii).(c) is a generalization of (ii).(b) when\naggregating the data from multiple tasks. As we will see\nin later examples, we usually have Rw(n) = e\nO(R2p\n1/n)\nand Rθ(n) = e\nO(R2p\nd/n), and Rθ(n) is typically the\nestimation error of local single-task methods.\nAssumption 3.5 (Good initialization and step size, a sim-\nplified version of Assumption A.7). | bw(k)[0]\nr\n−w(k)∗\nr\n| ∨\n∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 ≤C, η(k)\nr\n≤1/L(k)\nr , for all k ∈S and\nr ∈[R], where C > 0 is a constant whose explicit form can\nbe found in the appendix.\nWe set the penalty parameters in Algorithm 1 by induction\nas\nλ[0] = C1\n√n,\nλ[t] = κ′ · λ[t−1] + C2\n√n[Rw(n) + Rθ(n)],\nwhere t ≥1 and the explicit forms of κ′ ∈(0, 1), C1, C2\ncan be found in the appendix.\nNext, we present our primary result for the estimation error\nof FedGrEM in Theorem 3.6.\nTheorem 3.6 (Main result, a simplified version of Theorem A.8). Suppose Assumptions 3.1, 3.3, and 3.5 hold. Then for\nany contaminated set Sc with ϵ = |Sc|/K < 1/3 and any contamination distribution QSc, w.p. 1 −O(1), for all T ≥1,\nFedGrEM satisfies\nmax\nk∈S,r∈[R]\n\u0000| bw(k)[T ]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n≲\nκT\n0\n|{z}\niterative error\n+ Rθ(nK)\n|\n{z\n}\naggregation rate\n+\nRw(n)\n| {z }\ncost of heterogeneous mixture proportions\n3. Theory\nIn this section, we introduce a generic non-asymptotic upper\nbound for the estimation error of FedGrEM and apply this\ntheory to two statistical examples: Gaussian Mixture Mod-\n5\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n+ min\n\b\nh, Rw(n) + Rθ(n)\n\t\n|\n{z\n}\ncost of task heterogeneity\n+ ϵ\n\u0002\nRw(n) + Rθ(n)\n\u0003\n|\n{z\n}\ncost of outlier tasks\n,\n(3)\nwhere κ0 ∈(0, 1).\nThe upper bound of convergence rate in Theorem 3.6 com-\nprises multiple terms, each with a clear interpretation. The\nfirst term corresponds to the geometric iterative error which\nvanishes as T →+∞, and the second term accounts for the\naggregation error which arises from combining all the data.\nThe third to fifth terms represent the cost of heterogeneous\nmixing proportions, task heterogeneity, and outlier tasks,\nrespectively.\nAs we will observe in later specific examples, Rθ(nK)\nscales as R2p\nd/(nK) which depends on the total sam-\nple size nK of all K tasks, Rθ(n) = e\nO(R2p\nd/n), and\nRw(n) = e\nO(R2p\n1/n). Note that Rθ(n) typically repre-\nsents the estimation error of local single-task algorithms.\nComparing (3) with Rθ(n) = e\nO(R2p\nd/n), we can see\nthat when both h and ϵ are small — indicating sufficient\nsimilarity shared across tasks and few contaminated tasks\n— FedGrEM can achieve a better estimation error than the\nlocal single-task methods. When h = ϵ = 0, implying\nthat all tasks share the same parameters, we revert to the\nsetting of Dieuleveut et al. (2021), Marfoq et al. (2021),\nand Wu et al. (2023). In this context, our finite-sample\nupper bound demonstrates that federated EM can indeed\noutperform the local single-task methods, aligning with the\nempirical success of federated EM algorithms observed in\nthese works.\nIn subsequent sections, we will substitute specific rate ex-\npressions for each term in concrete examples, by showing\nthat Rw = e\nO(R2p\n1/n) and Rθ(n) = e\nO(R2p\nd/n).\n3.2. Proof Sketch of Theorem 3.6\nWe briefly describe the proof of Theorem 3.6 here. The\nproof follows an iterative fashion, where we show a connec-\ntion between the estimation error rates in two consecutive\niteration rounds and then iterate the analysis to obtain the fi-\nnal result. More specifically, by utilizing the contraction and\nuniform convergence conditions assumed in Assumption\n3.3, if we define the estimation error of round t as Er(t) =\nmaxk∈S,r∈[R]\n\u0000| bw(k)[t]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[t]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n, we\ncan prove that with high probability,\nEr(t) ≤κ0Er(t −1) + other terms,\nwhere other terms include the sum of the last four terms on\nthe RHS of (3), and κ0 ∈(0, 1).\nWe want to highlight that the proof is much harder and\nmore complicated than the proofs in standard EM theory.\nThe reason is that the mixture proportions {w(k)∗\nr\n}R\nr=1 can\nbe heterogenous across tasks, where we can still benefit\nfrom federated learning because the similarity between\nd-dimensional parameters {θ(k)∗\nr\n}R\nr=1 is more important\nthan the heterogeneity of 1-dimensional scalers {w(k)∗\nr\n}R\nr=1.\nHowever, in standard EM theory (Balakrishnan et al., 2017;\nYan et al., 2017; Cai et al., 2019), the estimation errors of\n{w(k)∗\nr\n}R\nr=1 and {θ(k)∗\nr\n}R\nr=1 are entangled and it is challeng-\ning to separate them by the existing theory. We creatively\nused a localization technique to address the issue by adap-\ntively shrinking the radius of the ball within which uniform\nconvergence in Assumption 3.3 must hold. This adaptive ra-\ndius shrinking trick during iterations finally leads to a “fast\nrate”, effectively replacing Rθ(n) (“the slow rate”) with a\nmuch smaller Rw(n) for the term “cost of heterogeneous\nmixing proportions” in (3). The intuition is visually inter-\npreted in Figure 2, and more details can be found in the full\nproof of Theorem 3.6 in the appendix.\nFigure 2. Schematic of the geometric convergence and the local-\nization trick, where we shrink the radius of uniform convergence\nball from r∗\n1 to r∗\n0 after the first iteration.\n3.3. Example 1: Gaussian Mixture Models (GMMs)\nIn this section, we examine Gaussian Mixture Models\n(GMMs) as an example of (1). Each observation is from a\nmixture of R Gaussian distributions (R ≥2):\nx(k)\ni\ni.i.d.\n∼\nR\nX\nr=1\nw(k)∗\nr\n· N(θ(k)∗\nr\n, Id×d).\n(4)\nHence in (1), p(k)\nr ( · ; θ(k)∗\nr\n) represents the Lebesgue den-\nsity of Gaussian distribution N(θ(k)∗\nr\n, Id×d). We define\n6\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n∆:= mink∈S minr̸=r′ ∥θ(k)∗\nr\n−θ(k)∗\nr′\n∥2, which character-\nizes the signal-to-noise ratio of GMMs among S. We im-\npose the following assumption.\nAssumption 3.7. Suppose the following conditions hold:\n(i) (Bounded parameters) w(k)∗\nr\n≳1/R, ∥θ(k)∗\nr\n∥2 ≤C\nfor all k ∈S and r ∈[R], where C is a constant;\n(ii) (Good\ninitialization)\nmaxk∈S,r∈[R] | bw(k)[0]\nr\n−\nw(k)∗\nr\n| ≲1\nR, maxk∈S,r∈[R] ∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 ≲∆;\n(iii) (Large signal strength) ∆≳log(R);\n(iv) (Sample size) n ≳R4[d + log(RK)]∆−2;\n(v) (Step size) 1 −η(k)\nr w(k)∗\nr\n< c, and 0 < η(k)\nr\n≤\n1/w(k)∗\nr\nfor all k ∈S and r ∈[R], where c > 0\nis a small constant.\nProposition 3.8. Under Assumption 3.7, GMMs defined in\n(4) satisfies Assumptions 3.1, 3.3, and 3.5 with\nµ(k)\nr\n= L(k)\nr\n= w(k)∗\nr\n,\nκ ≍R2 exp{−C∆2},\nRw(n) = e\nO\n\u0012\nR2\nr\n1\nn\n\u0013\n,\nRθ(n) = e\nO\n\u0012\nR2\nr\nd\nn\n\u0013\n,\nwhere C > 0 is some constant.\nBy plugging the rates in Propositions 3.8 into Theorem 3.6,\nwe obtain the following estimation error for GMMs.\nCorollary 3.9. Under Assumption 3.7, for the GMMs de-\nfined in (4), for any contaminated set Sc with ϵ = |Sc|/K ≤\n1/3 and contaminated distribution QSc, w.p. 1 −O(1), for\nall T ≥1, FedGrEM satisfies\nmax\nk∈S,r∈[R]\n\u0000| bw(k)[T ]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n= e\nO\n \nκT\n0 + R2\nr\nd\nnK + R2\nr\n1\nn + min\n\u001a\nh, R2\nr\nd\nn\n\u001b\n+ ϵR2\nr\nd\nn\n!\n.\nwhere κ0 ∈(0, 1) is a constant.\nOur theoretical analysis is also applicable to local single-\ntask EM and gradient EM, enabling us to establish an upper\nbound of estimation error e\nOP\n\u0010\nR2\nq\nd\nn\n\u0011\non S. Consequently,\nwhen d →∞(diverging dimension), K →∞(many sim-\nilar tasks), h ≪R2\nq\nd\nn (sufficient similarity), and ϵ →0\n(small proportion of outlier tasks), FedGrEM exhibits a bet-\nter estimation error rate than single-task EM and gradient\nEM (up to logarithmic factors). Notably, FedGrEM always\nachieves an error rate at least as good as the single-task rate\ne\nOP\n\u0010\nR2\nq\nd\nn\n\u0011\n.\n3.4. Example 2: Mixture of Regressions (MoRs)\nAs a second example, we consider a mixture of linear re-\ngressions (MoRs), where each observation comes from a\nmixture of R linear regression models (R ≥2):\nz(k)\ni\ni.i.d.\n∼\nR\nX\nr=1\nw(k)∗\nr\n· δr,\nGiven z(k)\ni\n= r :\ny(k)\ni\n= (ex(k)\ni\n)T θ(k)∗\nr\n+ ϵ(k)\ni\n,\n(5)\nϵ(k)\ni\ni.i.d.\n∼N(0, 1),\nex(k)\ni\ni.i.d.\n∼N(0d, Id×d),\nϵ(k)\ni\n⊥⊥ex(k)\ni\n.\nHence in (1) and (2), x(k)\ni\nis the pair (ex(k)\ni\n, y(k)\ni\n) and\np(k)\nr ( · ; θ(k)∗\nr\n) is the Lebesgue density of joint distribution\nof (ex(k)\ni\n, y(k)\ni\n). We impose the following assumption set.\nAssumption 3.10. Suppose the same conditions in Assump-\ntion 3.7 hold by replacing (iii) with:\n(iii) (Large signal strength) ∆≳R3 + R2(log ∆)3/2.\nProposition 3.11. Under Assumption 3.10, the MoRs de-\nfined in (5) satisfies Assumptions 3.1, 3.3, and 3.5 with\nµ(k)\nr\n= w(k)∗\nr\n−CR\n√log ∆\n∆\n, L(k)\nr\n= w(k)∗\nr\n+ CR\n√log ∆\n∆\n,\nκ = e\nO\n\u0012\nR2\n∆\n\u0013\n, Rw(n) = e\nO\n\u0012\nR2q\n1\nn\n\u0013\n, Rθ(n) = e\nO\n\u0012\nR2\nq\nd\nn\n\u0013\n,\nwhere C > 0 is some constant.\nBy plugging the rates in Propositions 3.11 into Theorem 3.6,\nwe have the following estimation error for MoRs.\nCorollary 3.12. Under Assumption 3.10, for the MoRs de-\nfined in (5), for any contaminated set Sc with ϵ = |Sc|/K ≤\n1/3 and contaminated distribution QSc, with probability\n1 −O(1), for all T ≥1, FedGrEM satisfies\nmax\nk∈S,r∈[R]\n\u0000| bw(k)[T ]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n= e\nO\n \nκT\n0 + R2\nq\nd\nnK + R2q\n1\nn + min\n\u001a\nh, R2\nq\nd\nn\n\u001b\n+ ϵR2\nq\nd\nn\n!\n.\nwhere κ0 ∈(0, 1) is a constant.\nWe can similarly discuss when the rate of FedGrEM is better\nthan the estimation error of the local single-task algorithms\nfor GMMs, which we do not repeat here.\n4. Numerical Results\n4.1. Simulations\nIn this subsection, we present simulation results to empir-\nically validate our theoretical insights. We consider two\n7\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nGMMs\n−2.50\n−2.25\n−2.00\n0.00\n4.49\n8.98\n13.47\n17.96\n22.45\n26.94\n31.43\n35.92\n(h SNR) × 100 % \nmax. log(est.error) of w in S\n0.0\n0.5\n1.0\n1.5\n2.0\n0.00\n4.49\n8.98\n13.47\n17.96\n22.45\n26.94\n31.43\n35.92\n(h SNR) × 100 % \nmax. log(est.error) of θ in S\nMORs\n−2.2\n−2.1\n−2.0\n−1.9\n−1.8\n0.00\n4.49\n8.98\n13.47\n17.96\n22.45\n26.94\n31.43\n35.92\n(h SNR) × 100 % \nmax. log(est.error) of w in S\n1.4\n1.6\n1.8\n2.0\n2.2\n0.00\n4.49\n8.98\n13.47\n17.96\n22.45\n26.94\n31.43\n35.92\n(h SNR) × 100 % \nmax. log(est.error) of θ in S\nmethod\nLocal−EM\nLocal−GrEM\nFedEM\nTGMM (in GMMs)/FedGMM (in MoRs)\nPooled−EM\nPooled−GrEM\nFedGrEM\nFigure 3. The average estimation errors of different methods in 100 replications of the GMM and MoR simulations (in loge scale). The\nleft two figures show the estimation error maxk∈S maxr∈[R] log(| bw(k)[T ]\nr\n−w(k)∗\nr\n|) and the right two figures show the estimation error\nmaxk∈S maxr∈[R] log(∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2). x-axis represents the ratio between model heterogeneity h and SNR (signal-to-noise ratio),\nwhere the definition of SNR is in Section B.1 of the appendix.\nexamples in the last section: Gaussian Mixture Models\n(GMMs) and Mixture of Regressions (MoRs). For both ex-\namples, we set the number of tasks K = 10, the number of\nclusters R = 5, the sample size of each task n = 150 (per-\ncluster sample size is around 30), the dimension p = 10, and\nintroduce one outlier task (ϵ = 0.1). The simulations are\nconducted over 100 repetitions, and we generate w(k)∗in\ndependently from Dirichlet(5, 5, 5, 5, 5). Details regarding\nthe values of θ(k)∗’s and the generation mechanism of the\noutlier task can be found in Section B of the appendix. We\nvary the value of h from 0 to 2 with an increment of 0.25,\ncalculating the average mean estimation error of w(k)∗’s and\nθ(k)∗’s in S = 1 : 9 for different approaches.\nThe considered methods include several unsupervised feder-\nated learning or multi-task learning benchmarks: Local-EM\n(single-task EM), Local-GrEM (single-task gradient EM),\nFedEM (Marfoq et al., 2021), TGMM (Wang et al., 2021),\nFedGMM (Wu et al., 2023), Pooled-EM (EM on pooled\ndata), Pooled-GrEM (gradient EM on pooled data), and\nFedGrEM (ours).\nThe results are presented in Figure 3. In the GMM simula-\ntion, the estimation errors of w(k)∗’s for different methods\nare similar, except for EM methods on the pooled data. Fed-\nGrEM, FedEM, TGMM, and FedGMM outperform the oth-\ners in estimating θ(k)∗’s with FedGrEM surpassing the other\nthree due to its robustness to outlier tasks. As h increases,\nthe performance of FedEM and TGMM degrades, becoming\ninferior to EM and GrEM. Conversely, FedGrEM’s perfor-\nmance becomes comparable to EM and GrEM as h/SNR ap-\nproaches 35.92%, highlighting its adaptability to unknown\nh. Similar trends are observed in the MoR simulation. These\nnumerical results align with our theoretical analyses and con-\nfirm FedGrEM’s advantage in handling unknown similarity\nlevels h and a few outlier tasks.\n4.2. Real-data Studies\nWe also conduct experiments on three real datasets:\n8\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nϵ/Method\nLocal-EM\nLocal-GrEM\nFedEM\nFedGrEM\nTGMM\nPooled-EM\nPooled-GrEM\n0%\n13.30 (1.17)\n13.20 (1.77)\n15.75 (2.09)\n9.62 (1.03)\n25.14 (2.72)\n26.84 (5.54)\n34.88 (11.70)\n6.8%\n12.88 (1.11)\n12.96 (1.70)\n15.87 (2.20)\n9.31 (1.10)\n25.00 (3.16)\n26.60 (5.80)\n34.61 (11.92)\n13.6%\n12.62 (1.26)\n12.99 (1.99)\n17.56 (2.44)\n9.04 (1.06)\n25.68 (2.85)\n26.79 (5.53)\n35.61 (12.52)\n20.5%\n12.94 (1.37)\n13.31 (1.93)\n18.52 (2.38)\n9.39 (1.25)\n26.14 (3.08)\n27.05 (5.46)\n37.94 (13.65)\nTable 1. Average mis-clustering error rates (standard deviations) in percentages for Pen-Based Recognition of Handwritten Digits dataset\nϵ/Method\nLocal-EM\nLocal-GrEM\nFedEM\nFedGrEM\nTGMM\nPooled-EM\nPooled-GrEM\n0%\n12.47 (1.19)\n12.06 (0.95)\n9.97 (2.09)\n10.63 (2.72)\n12.18 (4.08)\n12.84 (2.92)\n10.67 (2.41)\n8%\n12.30 (1.10)\n11.98 (0.88)\n11.97 (2.80)\n10.64 (1.98)\n13.66 (4.13)\n15.07 (5.25)\n14.16 (4.23)\n16%\n12.47 (1.19)\n12.06 (0.93)\n14.46 (2.95)\n10.96 (1.96)\n14.47 (4.24)\n16.16 (5.46)\n14.97 (4.36)\n24%\n12.43 (1.11)\n12.10 (0.89)\n21.67 (4.33)\n10.97 (1.59)\n15.70 (5.01)\n15.50 (5.09)\n14.35 (3.96)\nTable 2. Average mis-clustering error rates (standard deviations) in percentages for MNIST dataset\nϵ/Method\nLocal-EM\nLocal-GrEM\nFedEM\nFedGrEM\nTGMM\nPooled-EM\nPooled-GrEM\n0%\n36.40 (0.67)\n35.66 (0.64)\n36.06 (1.42)\n34.44 (1.98)\n36.14 (2.89)\n36.31 (1.25)\n35.72 (1.07)\n8%\n36.40 (0.72)\n35.69 (0.65)\n36.82 (1.15)\n33.27 (1.96)\n36.71 (3.32)\n39.75 (1.41)\n39.71 (1.54)\n16%\n36.34 (0.66)\n35.65 (0.70)\n36.80 (1.28)\n33.29 (1.86)\n37.50 (3.16)\n39.65 (1.50)\n39.34 (1.91)\n24%\n36.31 (0.69)\n35.61 (0.73)\n37.93 (1.81)\n33.35 (1.69)\n38.20 (3.28)\n39.51 (1.24)\n39.44 (1.57)\nTable 3. Average mis-clustering error rates (standard deviations) in percentages for Fashion-MNIST dataset\n• Pen-Based Recognition of Handwritten Digits 3: This\ndataset collects 0-9 digits written by 44 writers on the\ntablet with 16 features related to each digit such as the\npressure level at certain coordinates. The ID of the\nwriter for each handwritten digit is provided. Hence, it\nis a federated multi-task learning dataset in nature by\nviewing each writer as a client.\n• MNIST 4: 70000 grayscale images of 28×28 pixels for\nthe handwritten digits 0-9 from different writers. There\nis no information about the writers, hence we manu-\nally created a federated learning dataset by randomly\nassigning each image to one of 100 clients.\n• Fashion-MNIST\n5:\n70000\nof\nZalando’s\narticle\ngrayscale images in 28 × 28 pixels, each associated\nwith a label from 10 classes. We manually created a\nfederated learning dataset by randomly assigning each\nimage to one of 100 clients.\nIn each replication, 80% data for each task is used as train-\ning data, and the remaining 20% is used as test data to\ncalculate the mis-clustering error. We also contaminate dif-\nferent proportions (ϵ) of tasks to showcase the robustness\n3https://archive.ics.uci.edu/dataset/81/\npen+based+recognition+of+handwritten+digits\n4https://www.kaggle.com/datasets/hojjatk/\nmnist-dataset\n5https://www.kaggle.com/datasets/\nzalando-research/fashionmnist\nof FedGrEM against adversarial attacks. We run different\nbenchmark methods with GMMs (without the knowledge of\nthe true labels) for 200 replications and compare their per-\nformances in terms of mis-clustering error rates, as shown in\nTables 1-3, where FedGrEM performs the best in most set-\ntings. More details about the datasets, pre-processing steps,\nand results can be found in Section B.2 of the appendix.\n5. Discussions\nIn this work, we introduced a federated gradient EM al-\ngorithm (FedGrEM) to enhance the existing federated EM\nmethods, by considering the task heterogeneity and adversar-\nial attacks. We studied the non-asymptotic theory on general\nmixture models, and applied the theory to GMMs and MoRs\nto obtain the explicit estimation error of the model parame-\nters and mixture proportions. Our theory helps illustrate the\nempirical success of existing federated EM algorithms in lit-\nerature and offers new theoretical insights on unsupervised\nfederated learning. The proposed FedGrEM was shown to\nbe adaptive to unknown task similarity, robust against the\nadversarial attack on a small proportion of tasks, protective\nfor the local data, computationally and communicationally\nefficient. It serves as a valuable supplement to existing\nfederated EM algorithms.\nSome additional discussions on the limitations and future\nextensions are available in Section D of the appendix.\n9\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nAcknowledgements\nAll the experiments were conducted on Ginsburg HPC clus-\nter of Columbia University. Haolei Weng was partially\nsupported by NSF-DMS 2210505. Yang Feng was partially\nsupported by NSF Grant DMS-2324489 and NIH Grant\n1R21AG074205-01.\nImpact Statement\nThis paper aims to study the non-asymptotic theory un-\nderlying the federated EM algorithms, accounting for task\nheterogeneity and adversarial contaminations. It seeks to\nillustrate when and how federated learning can improve lo-\ncal performance and offers novel insights into unsupervised\nfederated learning, a field with potential societal impacts,\nparticularly in data privacy and security. While this study\nprimarily advances Machine Learning, we acknowledge\nits indirect implications on ethical considerations in data\nhandling and algorithm deployment. We believe our find-\nings will contribute to the development of more secure and\nethically-aware federated learning algorithms.\nReferences\nAbbe, E., Fan, J., Wang, K., and Zhong, Y. Entrywise eigen-\nvector analysis of random matrices with low expected\nrank. Annals of statistics, 48(3):1452, 2020.\nAntunes, R. S., Andr´e da Costa, C., K¨uderle, A., Yari, I. A.,\nand Eskofier, B. Federated learning for healthcare: Sys-\ntematic review and architecture proposal. ACM Transac-\ntions on Intelligent Systems and Technology (TIST), 13\n(4):1–23, 2022.\nBalakrishnan, S., Wainwright, M. J., and Yu, B. Statistical\nguarantees for the em algorithm: From population to\nsample-based analysis. The Annals of Statistics, 45(1):\n77–120, 2017.\nCai, T. T., Ma, J., and Zhang, L. Chime: Clustering of high-\ndimensional gaussian mixtures with em algorithm and its\noptimality. The Annals of Statistics, 47(3):1234–1267,\n2019.\nDai, W., Yang, Q., Xue, G.-R., and Yu, Y. Self-taught cluster-\ning. In Proceedings of the 25th international conference\non Machine learning, pp. 200–207, 2008.\nDempster, A. P., Laird, N. M., and Rubin, D. B. Maxi-\nmum likelihood from incomplete data via the em algo-\nrithm. Journal of the Royal Statistical Society: Series B\n(Methodological), 39(1):1–22, 1977.\nDenevi, G., Ciliberto, C., Stamos, D., and Pontil, M. Learn-\ning to learn around a common mean. Advances in neural\ninformation processing systems, 31, 2018.\nDieuleveut, A., Fort, G., Moulines, E., and Robin, G.\nFederated-em with heterogeneity mitigation and variance\nreduction. Advances in Neural Information Processing\nSystems, 34:29553–29566, 2021.\nDuan, Y. and Wang, K. Adaptive and robust multi-task\nlearning. arXiv preprint arXiv:2202.05250, 2022.\nEvgeniou, T. and Pontil, M. Regularized multi–task learning.\nIn Proceedings of the tenth ACM SIGKDD international\nconference on Knowledge discovery and data mining, pp.\n109–117, 2004.\nGhosh, A., Chung, J., Yin, D., and Ramchandran, K. An\nefficient framework for clustered federated learning. Ad-\nvances in Neural Information Processing Systems, 33:\n19586–19597, 2020.\nGu, Q., Li, Z., and Han, J. Learning a kernel for multi-task\nclustering. In Proceedings of the AAAI Conference on\nArtificial Intelligence, volume 25, pp. 368–373, 2011.\nGuminov, S., Dvurechensky, P., Tupitsa, N., and Gasnikov,\nA. On a combination of alternating minimization and\nnesterov’s momentum. In International conference on\nmachine learning, pp. 3886–3898. PMLR, 2021.\nHanneke, S. and Kpotufe, S. On the value of target data\nin transfer learning. arXiv preprint arXiv:2002.04747,\n2020.\nHard, A., Rao, K., Mathews, R., Ramaswamy, S., Beaufays,\nF., Augenstein, S., Eichner, H., Kiddon, C., and Ramage,\nD. Federated learning for mobile keyboard prediction.\narXiv preprint arXiv:1811.03604, 2018.\nHe, Z., Sun, Y., and Li, R. Transfusion: Covariate-shift\nrobust transfer learning for high-dimensional regression.\nIn International Conference on Artificial Intelligence and\nStatistics, pp. 703–711. PMLR, 2024.\nHinton, G. E. and Roweis, S. Stochastic neighbor embed-\nding. Advances in neural information processing systems,\n15, 2002.\nJaggi, M., Smith, V., Tak´ac, M., Terhorst, J., Krishnan, S.,\nHofmann, T., and Jordan, M. I. Communication-efficient\ndistributed dual coordinate ascent. Advances in neural\ninformation processing systems, 27, 2014.\nJalali, A., Ravikumar, P., and Sanghavi, S. A dirty model\nfor multiple sparse regression. IEEE Transactions on\nInformation Theory, 59(12):7947–7968, 2013.\nKoneˇcn`y, J., McMahan, H. B., Ramage, D., and Richt´arik, P.\nFederated optimization: Distributed machine learning for\non-device intelligence. arXiv preprint arXiv:1610.02527,\n2016.\n10\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nKong, W., Somani, R., Song, Z., Kakade, S., and Oh, S.\nMeta-learning for mixed linear regression. In Interna-\ntional Conference on Machine Learning, pp. 5394–5404.\nPMLR, 2020.\nKonstantinov, N. and Lampert, C. Robust learning from un-\ntrusted sources. In International conference on machine\nlearning, pp. 3488–3498. PMLR, 2019.\nKonstantinov, N., Frantar, E., Alistarh, D., and Lampert,\nC. On the sample complexity of adversarial multi-source\npac learning. In International Conference on Machine\nLearning, pp. 5416–5425. PMLR, 2020.\nKuzborskij, I. and Orabona, F. Stability and hypothesis\ntransfer learning. In International Conference on Ma-\nchine Learning, pp. 942–950. PMLR, 2013.\nKuzborskij, I. and Orabona, F. Fast rates by transferring\nfrom auxiliary hypotheses. Machine Learning, 106:171–\n195, 2017.\nKwon, J. and Caramanis, C. The em algorithm gives sample-\noptimality for learning mixtures of well-separated gaus-\nsians. In Conference on Learning Theory, pp. 2425–2487.\nPMLR, 2020a.\nKwon, J. and Caramanis, C. Em converges for a mixture\nof many linear regressions. In International Conference\non Artificial Intelligence and Statistics, pp. 1727–1736.\nPMLR, 2020b.\nLan, G. First-order and stochastic optimization methods for\nmachine learning, volume 1. Springer, 2020.\nLi, Q., Zhu, Z., and Tang, G. Alternating minimizations\nconverge to second-order optimal solutions. In Interna-\ntional Conference on Machine Learning, pp. 3935–3943.\nPMLR, 2019.\nLi, S., Cai, T. T., and Li, H. Transfer learning for high-\ndimensional linear regression: Prediction, estimation and\nminimax optimality.\nJournal of the Royal Statistical\nSociety: Series B (Statistical Methodology), pp. 1–25,\n2021.\nLi, T., Sahu, A. K., Talwalkar, A., and Smith, V. Feder-\nated learning: Challenges, methods, and future directions.\nIEEE signal processing magazine, 37(3):50–60, 2020a.\nLi, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A.,\nand Smith, V. Federated optimization in heterogeneous\nnetworks. Proceedings of Machine learning and systems,\n2:429–450, 2020b.\nLi, X. and Bilmes, J. A bayesian divergence prior for clas-\nsiffier adaptation. In Artificial Intelligence and Statistics,\npp. 275–282. PMLR, 2007.\nLin, H. and Reimherr, M. On hypothesis transfer learning\nof functional linear models. stat, 1050:22, 2024a.\nLin, H. and Reimherr, M. Smoothness adaptive hypothe-\nsis transfer learning. arXiv preprint arXiv:2402.14966,\n2024b.\nLounici, K., Pontil, M., van de Geer, S., and Tsybakov, A. B.\nOracle inequalities and optimal inference under group\nsparsity. The Annals of Statistics, pp. 2164–2204, 2011.\nMarfoq, O., Neglia, G., Bellet, A., Kameni, L., and Vidal,\nR. Federated multi-task learning under a mixture of dis-\ntributions. Advances in Neural Information Processing\nSystems, 34:15434–15447, 2021.\nMaurer, A. A vector-contraction inequality for rademacher\ncomplexities. In Algorithmic Learning Theory: 27th\nInternational Conference, ALT 2016, Bari, Italy, October\n19-21, 2016, Proceedings 27, pp. 3–17. Springer, 2016.\nMaurer, A. and Pontil, M. Concentration inequalities un-\nder sub-gaussian and sub-exponential conditions. Ad-\nvances in Neural Information Processing Systems, 34:\n7588–7597, 2021.\nMcLachlan, G. J. and Krishnan, T. The EM algorithm and\nextensions. John Wiley & Sons, 2007.\nMcMahan, B., Moore, E., Ramage, D., Hampson, S., and\ny Arcas, B. A. Communication-efficient learning of deep\nnetworks from decentralized data. In Artificial intelli-\ngence and statistics, pp. 1273–1282. PMLR, 2017.\nMeng, X.-L. and Rubin, D. B. On the global and componen-\ntwise rates of convergence of the em algorithm. Linear\nAlgebra and its Applications, 199:413–425, 1994.\nNguyen, D. C., Ding, M., Pathirana, P. N., Seneviratne, A.,\nLi, J., and Poor, H. V. Federated learning for internet of\nthings: A comprehensive survey. IEEE Communications\nSurveys & Tutorials, 23(3):1622–1658, 2021.\nPolson, N., Scott, J. G., and Willard, B. T. Proximal al-\ngorithms in statistics and machine learning. Statistical\nscience, 30(4):559–581, 2015.\nQiao, M.\nDo outliers ruin collaboration?\nIn Interna-\ntional Conference on Machine Learning, pp. 4180–4187.\nPMLR, 2018.\nRedner, R. A. and Walker, H. F. Mixture densities, maxi-\nmum likelihood and the em algorithm. SIAM review, 26\n(2):195–239, 1984.\nRohe, K., Chatterjee, S., and Yu, B. Spectral clustering and\nthe high-dimensional stochastic blockmodel. The Annals\nof Statistics, 39(4):596, 2011.\n11\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nSmith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A. S.\nFederated multi-task learning. Advances in neural infor-\nmation processing systems, 30, 2017.\nSolnon, M., Arlot, S., and Bach, F. Multi-task regression us-\ning minimal penalties. The Journal of Machine Learning\nResearch, 13(1):2773–2812, 2012.\nSu, L., Xu, J., and Yang, P. Global convergence of feder-\nated learning for mixed regression. Advances in Neural\nInformation Processing Systems, 35:29889–29902, 2022.\nT Dinh, C., Tran, N., and Nguyen, J. Personalized federated\nlearning with moreau envelopes. Advances in Neural\nInformation Processing Systems, 33:21394–21405, 2020.\nTang, M. and Priebe, C. E. Limit theorems for eigenvec-\ntors of the normalized laplacian for random graphs. The\nAnnals of Statistics, 46(5):2360–2415, 2018.\nTian, Y. and Feng, Y.\nTransfer learning under high-\ndimensional generalized linear models. Journal of the\nAmerican Statistical Association, 118(544):2684–2697,\n2023.\nTian, Y., Weng, H., and Feng, Y. Unsupervised multi-task\nand transfer learning on gaussian mixture models. arXiv\npreprint arXiv:2209.15224, 2022.\nTian, Y., Gu, Y., and Feng, Y. Learning from similar linear\nrepresentations: Adaptivity, minimaxity, and robustness.\narXiv preprint arXiv:2303.17765, 2023.\nTupitsa, N., Dvurechensky, P., Gasnikov, A., and Guminov,\nS. Alternating minimization methods for strongly convex\noptimization. Journal of Inverse and Ill-posed Problems,\n29(5):721–739, 2021.\nVan der Maaten, L. and Hinton, G. Visualizing data using\nt-sne. Journal of machine learning research, 9(11), 2008.\nVarshney, P., Thakurta, A., and Jain, P. (nearly) optimal\nprivate linear regression for sub-gaussian data via adap-\ntive clipping. In Conference on Learning Theory, pp.\n1126–1166. PMLR, 2022.\nWainwright, M. J.\nHigh-dimensional statistics: A non-\nasymptotic viewpoint, volume 48. Cambridge University\nPress, 2019.\nWang, R., Zhou, J., Jiang, H., Han, S., Wang, L., Wang, D.,\nand Chen, Y. A general transfer learning-based gaussian\nmixture model for clustering. International Journal of\nFuzzy Systems, 23(3):776–793, 2021.\nWu, C. J. On the convergence properties of the em algorithm.\nThe Annals of statistics, pp. 95–103, 1983.\nWu, Y., Zhang, S., Yu, W., Liu, Y., Gu, Q., Zhou, D.,\nChen, H., and Cheng, W. Personalized federated learn-\ning under mixture of distributions.\narXiv preprint\narXiv:2305.01068, 2023.\nXu, J., Hsu, D. J., and Maleki, A. Global analysis of ex-\npectation maximization for mixtures of two gaussians.\nAdvances in Neural Information Processing Systems, 29,\n2016.\nYan, B., Yin, M., and Sarkar, P. Convergence of gradient\nem on multi-component mixture of gaussians. Advances\nin Neural Information Processing Systems, 30, 2017.\nYang, Q., Liu, Y., Chen, T., and Tong, Y. Federated machine\nlearning: Concept and applications. ACM Transactions\non Intelligent Systems and Technology (TIST), 10(2):1–19,\n2019.\nYang, Y., Ma, Z., Yang, Y., Nie, F., and Shen, H. T. Mul-\ntitask spectral clustering by exploring intertask correla-\ntion. IEEE transactions on cybernetics, 45(5):1083–1094,\n2014.\nZhang, J. and Zhang, C. Multitask bregman clustering.\nNeurocomputing, 74(10):1720–1734, 2011.\nZhang, X., Zhang, X., and Liu, H. Smart multitask bregman\nclustering and multitask kernel clustering. ACM Transac-\ntions on Knowledge Discovery from Data (TKDD), 10(1):\n1–29, 2015.\nZhang, X., Zhang, X., Liu, H., and Luo, J. Multi-task\nclustering with model relation learning. In Proceedings\nof the 27th International Joint Conference on Artificial\nIntelligence, pp. 3132–3140, 2018.\nZhang, Y. and Yang, Q. A survey on multi-task learning.\nIEEE Transactions on Knowledge and Data Engineering,\n2021.\nZhao, R., Li, Y., and Sun, Y. Statistical convergence of the\nem algorithm on gaussian mixture models. Electronic\nJournal of Statistics, 14:632–660, 2020.\n12\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nAppendix\nThis appendix collects the additional theoretical and numerical details as well as all the technical proofs of the theory. We\npresent the formal theoretical results in Section A which correspond to the simplified versions in Section 3 of the main text.\nSection B contains more details of the numerical studies presented in Section 4 of the main text. Section C discusses the\nlabel permutation issue we mentioned in Section 2.4. Section D includes additional discussions on limitations and potential\nextensions of the current work in the future. All the technical proofs are summarized in Section E.\nWe recall our mathematical notations here. P and E denote the probability and expectation, respectively. P and E denote the\nprobability and expectation, respectively. For two positive sequences {an} and {bn}, an ≪bn means an/bn →0, an ≲bn\nor an = O(bn) means an/bn ≤C < ∞, and an ≍bn means an/bn, bn/an ≤C < ∞. For a random variable xn and a\npositive sequence an, xn = Op(an) means that for any ϵ > 0, there exists M > 0 such that supn P(|xn/an| > M) ≤ϵ.\ne\nOp(an) has a similar meaning up to logarithmic factors in an. For a vector x ∈Rd, ∥x∥2 represents its Euclidean norm.\nFor two numbers a and b, a ∨b = max{a, b} and a ∧b = min{a, b}. For any positive integer K, 1 : K and [K] stand for\nthe set {1, 2, . . . , K}. Denote Bξ(θ) as an Euclidean ball centered at θ with radius ξ > 0. And for any set S, |S| denotes\nits cardinality and Sc denotes its complement. “w.p.” stands for “with probability”. “WLOG” stands for “Without loss of\ngenerality”. The absolute constants c and C may vary from line to line.\nA. Formal Theoretical Results\nDenote ¯η = maxk∈S,r∈[R] η(k)\nr\nas the maximum step size used in the local M-step on tasks in S. For simplicity, denote\nq(k)(θ) = Q(k)(θ|w(k)∗, θ(k)∗). We first state a few assumptions which are necessary for our result on general mixture\nmodels.\nAssumption A.1. For any k ∈S, there exist non-negative sets {µ(k)\nr }r∈[R], {L(k)\nr }r∈[R], and a positive constant r∗\n1 such\nthat for all θ = {θr}R\nr=1, θ′ = {θ′\nr}R\nr=1 with θr, θ′\nr ∈Br∗\n1(θ(k)∗\nr\n):\n(i) (Strong concavity) q(k)(θ′) −q(k)(θ) −\n∂\n∂θq(k)(θ)T (θ′ −θ) ≤−PR\nr=1\nµ(k)\nr\n2 ∥θ′\nr −θr∥2\n2;\n(ii) (Smoothness) q(k)(θ′) −q(k)(θ) −\n∂\n∂θq(k)(θ)T (θ′ −θ) ≥−PR\nr=1\nL(k)\nr\n2 ∥θ′\nr −θr∥2\n2.\nRemark A.2. The same conditions are imposed by Balakrishnan et al. (2017) in the single-task setting. The strong concavity\nis usually assumed to obtain the parametric convergence rate, and the smoothness is imposed for gradient descent to converge\nat a geometric rate.\nAssumption A.3. There exist positive constants r∗\nw, r∗\n2, and κ ∈(0, 1), and a function W, such that for any k ∈S:\n(i) For all w′ = {w′\nr}R\nr=1 and θ′ = {θ′\nr}R\nr=1 with w′\nr ∈Br∗w(w(k)∗\nr\n) and θ′\nr ∈Br∗\n2(θ(k)∗\nr\n), we have\n\f\fE\n\u0002\nP(z(k) =\nr|x(k); w′, θ′)\n\u0003\n−w(k)∗\nr\n\f\f ≤κ · PR\nr=1\n\u0000|w′\nr −w(k)∗\nr\n| + ∥θ′\nr −θ(k)∗\nr\n∥2\n\u0001\n;\n(ii) w.p. at least 1 −δ, for all w′ = {w′\nr}R\nr=1, ξ > 0, and θ′ = {θ′\nr}R\nr=1 with w′\nr ∈Br∗w(w(k)∗\nr\n) and θ′\nr ∈Bξ(θ(k)∗\nr\n), we\nhave\n\f\f 1\nn\nPn\ni=1 P(z(k) = r|x(k)\ni\n; w′, θ′) −E\n\u0002\nP(z(k) = r|x(k); w′, θ′)\n\u0003\f\f ≤W(n, δ, ξ).\nRemark A.4. Note that by definition w(k)∗\nr\n= E[P(z(k) = r|x(k); w(k)∗, θ(k)∗)]. Therefore, condition (i) describes the be-\nhavior of E\n\u0002\nP(z(k) = r|x(k); w′, θ′)\n\u0003\n, and condition (ii) is a uniform convergence assumption on P(z(k) = r|x(k)\ni\n; w′, θ′),\nwhen w′ and θ′ are close to the true values w(k)∗and θ(k)∗.\nAssumption A.5. With the same constants r∗\nw and r∗\n2 in Assumption A.3, there exists a constant γ ∈(0, 1) and functions\nE1, E2 such that for any k ∈S:\n(i) For all w′ = {w′\nr}R\nr=1 and θ′ = {θ′\nr}R\nr=1 with w′\nr ∈Br∗w(w(k)∗\nr\n) and θ′\nr ∈Br∗\n2(θ(k)∗\nr\n), we have\n\r\r ∂\n∂θr q(k)(θ)|θ=θ′ −\n∂\n∂θr Q(k)(θ|w′, θ′)|θ=θ′\r\r ≤γ · PR\nr=1\n\u0000|w′\nr −w(k)∗\nr\n| + ∥θ′\nr −θ(k)∗\nr\n∥2\n\u0001\n;\n(ii) w.p. at least 1 −δ, for all w′ = {w′\nr}R\nr=1 and θ′ = {θ′\nr}R\nr=1 with w′\nr ∈Br∗w(w(k)∗\nr\n) and θ′\nr ∈Br∗\n2(θ(k)∗\nr\n), we have\n\r\r ∂\n∂θr bQ(k)(θ|w′, θ′)|θ=θ′ −\n∂\n∂θr Q(k)(θ|w′, θ′)|θ=θ′\n\r\r\n2 ≤E1(n, δ);\n13\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n(iii) w.p. at least 1−δ, for ξ > 0 and all w(k)′ = {w(k)′\nr\n}R\nr=1, θ′ = {θ′\nr}R\nr=1, and {η(k)\nr }k∈S,r∈[R] with w(k)′\nr\n∈Br∗w(w(k)∗\nr\n)\nand θ′\nr\n∈Br∗\n2(θ(k)∗\nr\n), we have\n\r\r 1\n|S|\nP\nk∈S η(k)\nr\n·\n\u0002 ∂\n∂θr bQ(k)(θ|w′, θ′)|θ=θ′ −\n∂\n∂θr Q(k)(θ|w′, θ′)|θ=θ′\u0003\r\r\n2\n≤\n¯ηE2(n, |S|, δ).\nRemark A.6. Conditions (i) and (ii) have been used by Balakrishnan et al. (2017) in the single-task setting, while condition\n(iii) is a generalization of (ii) when aggregating the data from multiple tasks. Similar to condition (ii) in Assumption A.3,\ncondition (ii) and condition (iii) are uniform convergence assumptions on the gradient around the true parameter values,\nwhich are often needed when analyzing the EM without data splitting (Yan et al., 2017; Cai et al., 2019).\nAssumption A.7. Denote r∗\nθ = r∗\n1 ∧r∗\n2 and ˜κ0 = 119\n\u0010q\n1 −minr,k∈S(µ(k)\nr η(k)\nr ) + ¯ηγR + κR\n\u0011\n. Suppose\nmax\nk∈S,r∈[R] | bw(k)[0]\nr\n−w(k)∗\nr\n| ≤r∗\nw,\nmax\nk∈S,r∈[R] ∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 ≤r∗\nθ.\nIn addition, ˜κ0, κ, r∗\nw, r∗\nθ, and functions W, E1, and E2 defined in Assumptions A.1-A.5 satisfy\n(i) ˜κ0 ≤\nr∗\nθ\n18(r∗w+r∗\nθ), κR ≤\n9\n1199 ·\nr∗\nw\nr∗w+r∗\nθ ;\n(ii) ¯η · E1\n\u0010\nn,\nδ\n3RK\n\u0011\n≤\nh\n(1−˜κ0/119)(1−˜κ0)\n4320\nr∗\nθ\ni\n∧\n\u0010\n1\n3r∗\nw\n\u0011\n;\n(iii) W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n≤(1−˜κ0/119)(1−˜κ0)\n2160\nr∗\nθ;\n(iv) ¯η · E2\n\u0010\nn, |S|,\nδ\n3R\n\u0011\n≤1−˜κ0/119\n20\nr∗\nθ;\n(v) η(k)\nr\n≤1/L(k)\nr\nfor all k ∈S and r ∈[R].\nWe set the penalty parameters in Algorithm 1 by induction as\nλ[0] = 15\n119\n√n(r∗\nw + r∗\nθ),\nλ[t] = ˜κ0λ[t−1] + 15√n\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n,\nTheorem A.8. Suppose Assumptions A.1-A.7 hold. Then for any contaminated set Sc with ϵ = |Sc|/K < 1/3 and any\ncontaminated distribution QSc, with probability at least 1 −δ, for all T ≥1, FedGrEM satisfies\nmax\nk∈S,r∈[R]\n\u0000| bw(k)[T ]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n≤20T ˜κT −1\n0\n× (r∗\nw ∨r∗\nθ)\n|\n{z\n}\niterative error\n+\n1\n1 −˜κ0/119 ¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n|\n{z\n}\naggregation rate\n+\n1\n1 −˜κ0/119W\n\u0010\nn,\nδ\n3RK , r∗\nθ,T\n\u0011\n|\n{z\n}\ncost of heterogeneous mixing proportions\n+\n18\n1 −˜κ0/119 min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n|\n{z\n}\ncost of task heterogeneity\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n|\n{z\n}\ncost of outlier tasks\n,\nwhere r∗\nθ,T is defined in an iterative fashion by\nAt =\n\u0014\n9˜κ0\n\u0012 ˜κ0\n119\n\u0013t−1\n+ 118\n119(t −1)˜κt−1\n0\n\u0015\n(r∗\nw + r∗\nθ) +\n1\n1 −˜κ0/119 ¯ηE2\n\u0012\nn, |S|, δ\n3R\n\u0013\n+\n18\n1 −˜κ0/119 min\n\u001a\n3h,\n6\n1 −˜κ0\n\u0014\nW\n\u0012\nn,\nδ\n3RK , r∗\nθ\n\u0013\n+ 2¯ηE1\n\u0012\nn, δ\n3R\n\u0013\u0015\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ\n\u0014\nW\n\u0012\nn,\nδ\n3RK , r∗\nθ\n\u0013\n+ 2¯ηE1\n\u0012\nn, δ\n3R\n\u0013\u0015\n;\n14\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nAt +\n18\n1 −˜κ0/119W\n\u0012\nn,\nδ\n3RK , r∗\nθ,t\n\u0013\n= r∗\nθ,t+1,\nfor t ≥1 with r∗\nθ,1 := r∗\nθ.\nBefore jumping into two specific examples, we want to point out that the term r∗\nθ,T is introduced to address a specific\nchallenge in the analysis of gradient EM mentioned in Section 3.2. In the classical EM theory, the estimates of similar\n{θ(k)∗\nr\n}k∈S and heterogeneous {w(k)∗\nr\n}k∈S are entangled in the iterations, which will make the heterogeneous scalars\n{w(k)∗\nr\n}k∈S contribute a large dimension-dependent error W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\nto the estimation and finally lead to a “slow rate”\nof convergence for {θ(k)∗\nr\n}k∈S,r∈[R]. To mitigate this issue, we reduced the radius of the ball within which uniform conver-\ngence must hold during iterations. This localization trick finally leads to a “fast rate”, effectively replacing W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\nin the slow rate with the current W\n\u0010\nn,\nδ\n3RK , r∗\nθ,T\n\u0011\n, where r∗\nθ,T ≪r∗\nθ. The intuition has been visually interpreted in Figure\n2, and more details can be found in the proof of Theorem 3.6.\nA.1. Example 1: Gaussian Mixture Models (GMMs)\nAssumption A.9. Suppose the following conditions hold:\n(i) (Bounded parameters) w(k)∗\nr\n≥cw/R, ∥θ(k)∗\nr\n∥2 ≤M with some cw ∈(0, 1] for all k ∈S and r ∈[R] and\nM ≥C > 0, where C is a constant;\n(ii) (Good initialization) maxk∈S,r∈[R] | bw(k)[0]\nr\n−w(k)∗\nr\n| ≤Cb cw\nR , maxk∈S,r∈[R] ∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 ≤Cb∆, with Cb a\nsmall constant;\n(iii) (Large signal strength) ∆≳log(MRc−1\nw );\n(iv) (Sample size) n ≳[R2M 6d + R2 log2(Rc−1\nw )M 2 + M 2 log(RK/δ)]C−2\nb ∆−2¯η2;\n(v) (Step size) 1 −\nmin\nk∈S,r∈[R](η(k)\nr w(k)∗\nr\n) < a small constant c, and 0 < η(k)\nr\n≤1/w(k)∗\nr\nfor all k ∈S and r ∈[R].\nRemark A.10. Note that we allow cw, M, Cb, ∆, T, R, K, and d to change with sample size n.\nProposition A.11. Under Assumption A.9, GMMs defined in (4) satisfies Assumptions A.1-A.7 with\nµ(k)\nr\n= L(k)\nr\n= w(k)∗\nr\n,\nr∗\n1 = +∞, r∗\nw = Cb\ncw\nR , r∗\n2 = Cb∆,\nκ ≍c−2\nw R2 exp{−C∆2}, γ ≍M 2c−2\nw R2 exp{−C∆2},\nW(n, δ, ξ)≍RMξ\nr\nd\nn + [RM 2 + R log(Rc−1\nw )]\nr\n1\nn +\nr\nlog(1/δ)\nn\n,\nE1(n, δ) ≍RM 3\nr\nd\nn + RM log(Rc−1\nw )\nr\n1\nn + M\nr\nlog(1/δ)\nn\n,\nE2(n, |S|, δ) ≍RM 3\ns\nd\nn|S| + [RM 3 + RM log(Rc−1\nw )]\nr\n1\nn\n+ M\ns\nlog(1/δ)\nn|S|\n,\nwhere C > 0 is some constant.\nBy plugging the rates in Propositions 3.8 into Theorem 3.6, we obtain the following result for GMMs.\nCorollary A.12. Set η(k)\nr\n= (1 + Cb)−1( bw(k)[0]\nr\n)−1. Under Assumption 3.7, for the GMMs defined in (4), for any\ncontaminated set Sc with ϵ = |Sc|/K ≤1/3 and contaminated distribution QSc, with probability at least 1 −δ, for all\n15\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nT ≥1, FedGrEM satisfies\nmax\nk∈S,r∈[R]\n\u0000| bw(k)[T ]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n≲T 2κT −1\n0\nM + R2c−1\nw M 3\ns\nd\nn|S|\n+ Rc−1\nw M\nr\nlog(RK/δ)\nn\n+ R2c−1\nw M[M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ min\n\u001a\nh, R2c−1\nw M 3\nr\nd\nn\n\u001b\n+ ϵR2c−1\nw M 3\nr\nd\nn,\nwhere κ0 = 119\nq\n2Cb\n1+Cb + CM 2c−2\nw R3 exp{−C′∆2} + Cc−2\nw R3 exp{−C′∆2} + ˜κ′\n0 ∈(0, 1), and ˜κ′\n0 satisfies 1 > ˜κ′\n0 >\nCMR\nq\nd\nn for some C > 0..\nRemark A.13. If M and cw are bounded, when T ≳log n, we will have\nmax\nk∈S,r∈[R]\n\u0000| bw(k)[T ]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n= e\nOP\n\u0012\nR2\ns\nd\nn|S| + R2\nr\n1\nn + min\n\u001a\nh, R2\nr\nd\nn\n\u001b\n+ ϵR2\nr\nd\nn\n\u0013\n.\nNext, we want to illustrate the choice of step size η(k)\nr . In Corollary A.12, we set η(k)\nr\n= (1 + Cb)−1( bw(k)[0]\nr\n)−1, then under\nAssumption A.9, it can be shown that Assumptions A.7.(i) and A.7.(v) hold,\nq\n1 −mink∈S,r∈[R](η(k)\nr µ(k)\nr ) ≤\nq\n2Cb\n1+Cb , and\nwe can replace ¯η with CRc−1\nw for some constant C in Assumptions A.7.(ii) and A.7.(v).\nSecond, we have the following upper bound for r∗\nθ,T , which can be plugged into Theorem A.8 with the rates in Proposition\nA.11 to obtain the upper bound of estimation error in Corollary A.12.\nProposition A.14. Under Assumption A.9, for the GMMs defined in (4), we have\nr∗\nθ,T ≲T 2κT −1\n0\nM + ¯ηRM 3\ns\nd\nn|S| + [(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn + [(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn,\nwhere κ0 = 119\nq\n2Cb\n1+Cb +CM 2c−2\nw R3 exp{−C′∆2}+Cc−2\nw R3 exp{−C′∆2}+˜κ′\n0, and ˜κ′\n0 satisfies 1 > ˜κ′\n0 > CMR\nq\nd\nn\nfor some C > 0.\nA.2. Example 2: Mixture of Regressions (MoRs)\nAssumption A.15. Suppose the same conditions in Assumption A.9 hold by replacing (iii) with:\n(iii) (Strong signal strength) ∆≳R3c−1\nw + R2c−1\nw (log ∆)3/2;\nSimilar to our previous comments in Remark A.10 for GMMs, we also allow cw, M, Cb, ∆, T, R, K, and d to change with\nsample size n in MoRs.\nProposition A.16. Under Assumption A.15, the MoRs defined in (5) satisfies Assumptions A.1-A.7 with r∗\n1, r∗\n2, W(n, δ, ξ),\nE1(n, δ), E2(n, |S|, δ) the same as in Proposition A.11, and\nµ(k)\nr\n= w(k)∗\nr\n−CR\n√log ∆\n∆\n,\n16\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nL(k)\nr\n= w(k)∗\nr\n+ CR\n√log ∆\n∆\n,\nκ ≍c−1\nw R\n√log ∆\n∆\n+ c−1\nw RCb + R2c−1\nw\n1\n∆,\nγ ≍c−1\nw R(log ∆)3/2\n∆\n+ c−1\nw RCb + R2c−1\nw\n1\n∆,\nwhere C > 0 is some constant.\nCorollary A.17. Set η(k)\nr\n= (1 + Cb)−1( bw(k)[0]\nr\n)−1. Under Assumption A.15, for the MoRs defined in (5), for any\ncontaminated set Sc with ϵ = |Sc|/K ≤1/3 and contaminated distribution QSc, with probability at least 1 −δ, for all\nT ≥1, FedGrEM satisfies\nmax\nk∈S,r∈[R]\n\u0000| bw(k)[T ]\nr\n−w(k)∗\nr\n| ∨∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2\n\u0001\n≲T 2κT −1\n0\nM + R2c−1\nw M 3\ns\nd\nn|S|\n+ Rc−1\nw M\nr\nlog(RK/δ)\nn\n+ R2c−1\nw M[M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ min\n\u001a\nh, R2c−1\nw M 3\nr\nd\nn\n\u001b\n+ ϵR2c−1\nw M 3\nr\nd\nn,\nwhere κ0 = 119\nq\n3Cb\n1+2Cb + CR3c−2\nw\n(log ∆)3/2\n∆\n+ CR3c−2\nw Cb + CR4c−2\nw\n1\n∆+ ˜κ′\n0 ∈(0, 1), and ˜κ′\n0 satisfies 1 > ˜κ′\n0 >\nCMR\nq\nd\nn for some C > 0.\nRemark A.18. If M and cw are bounded, when T ≳log n, we will have the same rate for MoRs as in Remark A.13. We can\nalso compare the rate of FedGrEM and the local single-task rates as in GMMs, which we do not repeat here.\nIn Corollary A.17, we set η(k)\nr\n= (1+2Cb)−1( bw(k)[0]\nr\n)−1 and let Cb ≳Rc−1\nw\n√log ∆\n∆\n, then under Assumption A.15, it can be\nshown that Assumptions A.7.(i) and (v) hold,\nq\n1 −mink∈S,r∈[R](η(k)\nr µ(k)\nr ) ≤\nq\n3Cb\n1+2Cb + C\n√log ∆\n∆\n, and we can replace ¯η\nwith CRc−1\nw for some constant C in Assumptions A.7.(ii) and A.7.(iv).\nIn addition, we have the following upper bound for r∗\nθ,T , which can be plugged into Theorem A.8 with the rates in\nProposition A.16 to obtain the upper bound of estimation error in Corollary A.17.\nProposition A.19. Under Assumption A.15, for the MoRs defined in (5), we have\nr∗\nθ,T ≲T 2κT −1\n0\nM + ¯ηRM 3\ns\nd\nn|S| + [(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn + [(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn,\nwhere κ0 = 119\nq\n3Cb\n1+2Cb + CR3c−2\nw\n(log ∆)3/2\n∆\n+ CR3c−2\nw Cb + CR4c−2\nw\n1\n∆+ ˜κ′\n0, and ˜κ′\n0 satisfies 1 > ˜κ′\n0 > CMR\nq\nd\nn for\nsome C > 0.\nB. Additional Details of Numerical Results\nIn this section, we provide more details of the numerical studies in Section 4. All experiments are implemented in R, where\nEM is executed using the mclust package for GMMs and the mixreg package for MoRs. GrEM, FedEM (Marfoq et al.,\n2021), TGMM (Wang et al., 2021), FedGMM (Wu et al., 2023), and FedGrEM are initialized with the estimates from local\nEM. As the empirical results in Wang et al. (2021) suggested, we set the tuning parameter λ = 0.4 in TGMM, which controls\nhow much information to borrow from the other tasks. TGMM was originally designed for transfer learning in Wang et al.\n(2021) and we ran it on each task with all the other tasks as sources. For FedGMM, we set the number of mixtures M1 = 3.\n17\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nB.1. Additional Details of Simulations\nIn both examples, we generate centers ¯θr of parameters {θ(k)∗\nr\n}k∈S as\n¯θ1 = (1, 0, 3, −1, 1, −1, 0, 1, 1, −1)T ,\n¯θ2 = (0, 1, −1, −3, 2, −1, 2, −1, 1, −)T ,\n¯θ3 = (−3, −1, 2, −1, 2, −1, 1, −3, −1, −2)T ,\n¯θ4 = (1, −2, 0, −1, −2, 2, 1, 3, 1, −1)T ,\n¯θ5 = (3, 1, 2, −1, −2, 1, 2, −1, −1, 2)T .\nAnd we generate the parameter θ(k)∗\nr\nby\nθ(k)∗\nr\n= ¯θr + h ×\nz(k)\nr\n∥z(k)\nr ∥2\n,\nr ∈[R],\nwhere zr ∼N(0p, Ip×p) and they are independent for different k and r. In the GMM simulation, the observations of the\noutlier task are generated i.i.d. from N(2 · 1p, 3Ip×p). In the MoR simulation, all x(k)\ni\n’s are generated from N(0p, Ip×p),\nand the responses {y(k)\ni\n}n\ni=1 of the outlier task are generated i.i.d. from the regression model y(k)\ni\n= (x(k)\ni\n)T θ(k)∗\nr\n+ ϵ(k)\ni\nwith θ(k)∗\nr\n= 3 · 1p and ϵ(k)\ni\n∼N(0, 1). In Figure 3, the SNR is defined to be mink∈S maxr̸=r′∈[R] ∥θ(k)∗\nr\n−θ(k)∗\nr′\n∥2.\nIn FedGrEM, we set the number of iterations T = 1000, and the penalty parameters λ[t] are updated in iterations as follows:\nλ[0] = 1,\nλ[t] = κ0λ[t−1] + C\np\np + log K,\nwhere κ = 0.1 and C = 2.\nThe optimization in the central update is solved by an alternating optimization procedure. We first reparameterize the\nproblem by ν(k) = ¯ν + ∆(k), and we solve\narg min\n{∆(k)}K\nk=1⊆Rd,ν∈Rd\n\u001a K\nX\nk=1\n\u0010n\n2 ∥¯ν + ∆(k) −eθ(k)[t]\nr\n∥2\n2 + √nλ[t] · ∥∆(k)∥2\n\u0011\u001b\n,\n(6)\nand assign bθ(k)[t]\nr\n= ¯ν + ∆(k). We solve (6) by the alternating optimization as follows:\n(i) Set ∆(k) = 0 for all k ∈[K];\n(ii) Fix {∆(k)}K\nk=1, and update ¯ν = 1\nK\nPK\nk=1(eθ(k)[t]\nr\n−∆(k));\n(iii) Fix ¯ν, and update ∆(k) as\n∆(k) = arg min\n∆\nnn\n2 ∥¯ν + ∆−eθ(k)[t]\nr\n∥2\n2 + √nλ[t] · ∥∆∥2\no\n=\n\n\n\n\u0012\n1 −\nλ[t]/√n\n∥eθ(k)[t]\nr\n−¯ν∥2\n\u0013\n(eθ(k)[t]\nr\n−¯ν),\nif ∥eθ(k)[t]\nr\n−¯ν∥2 ≥λ[t]\n√n,\n0,\nelse.\nWe iterate (ii) and (iii) for a few times until convergence.\nWe also run our simulation example with different Cη values ranging from 0.55 to 1.35. The results are summarized in the\nfollowing Tables 4 and 5. It can be seen that the estimation error of mixture proportions w(k)∗\nr\n’s is quite stable with the\nchoice of Cη, and the estimation error of parameters θ(k)∗\nr\nfirst decreases then becomes stable when Cη changes from 0.55 to\n1.35. In fact, according to our observation in the experiments, if we continue increasing the Cη, the algorithm would fail to\nconverge and output useless estimates. Overall the performance is robust to the choice of Cη within this range [0.55, 1.35],\nand we can further tune it in practice, although the theoretically-guided choice already leads to a decent performance.\n18\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nCη / h\nh = 0\nh = 0.25\nh = 0.5\nh = 0.75\nh = 1\nh = 1.25\nh = 1.5\n0.55\n0.072 (0.017)\n0.071 (0.015)\n0.068 (0.015)\n0.071 (0.016)\n0.072 (0.017)\n0.071 (0.017)\n0.071 (0.016)\n0.65\n0.072 (0.017)\n0.071 (0.015)\n0.068 (0.015)\n0.071 (0.016)\n0.072 (0.017)\n0.071 (0.017)\n0.071 (0.016)\n0.75\n0.072 (0.017)\n0.071 (0.018)\n0.068 (0.015)\n0.071 (0.016)\n0.072 (0.017)\n0.071 (0.019)\n0.071 (0.015)\n0.85\n0.072 (0.017)\n0.071 (0.015)\n0.068 (0.015)\n0.071 (0.016)\n0.072 (0.019)\n0.071 (0.018)\n0.071 (0.015)\n0.95\n0.072 (0.017)\n0.071 (0.016)\n0.068 (0.015)\n0.071 (0.016)\n0.072 (0.02)\n0.071 (0.018)\n0.071 (0.015)\n1.05\n0.072 (0.017)\n0.071 (0.016)\n0.068 (0.015)\n0.071 (0.016)\n0.071 (0.017)\n0.071 (0.017)\n0.071 (0.015)\n1.15\n0.072 (0.017)\n0.071 (0.016)\n0.069 (0.017)\n0.071 (0.016)\n0.071 (0.017)\n0.071 (0.017)\n0.071 (0.016)\n1.25\n0.072 (0.017)\n0.071 (0.016)\n0.068 (0.015)\n0.071 (0.017)\n0.071 (0.017)\n0.072 (0.019)\n0.071 (0.017)\n1.35\n0.073 (0.021)\n0.071 (0.016)\n0.069 (0.017)\n0.071 (0.016)\n0.071 (0.017)\n0.072 (0.018)\n0.071 (0.016)\nTable 4. Average of the maximum estimation error of {w(k)∗\nr\n}k∈S,r (standard deviations) in loge scale in the GMM simulation, with\ndifferent constants Cη in learning rate η(k)\nr\n= Cη/ ˆw(k)[0]\nr\nand heterogeneity parameter h.\nCη/ h\nh = 0\nh = 0.25\nh = 0.5\nh = 0.75\nh = 1\nh = 1.25\nh = 1.5\nh = 1.75\n0.55\n1.36 (0.62)\n1.47 (0.63)\n1.62 (0.63)\n1.71 (0.56)\n1.89 (0.70)\n2.07 (0.72)\n2.23 (0.84)\n2.44 (0.99)\n0.65\n1.28 (0.59)\n1.38 (0.61)\n1.52 (0.62)\n1.62 (0.56)\n1.79 (0.71)\n1.99 (0.75)\n2.14 (0.90)\n2.33 (0.99)\n0.75\n1.22 (0.55)\n1.34 (0.63)\n1.44 (0.59)\n1.54 (0.55)\n1.71 (0.69)\n1.93 (0.78)\n2.02 (0.81)\n2.25 (1.01)\n0.85\n1.17 (0.51)\n1.30 (0.68)\n1.38 (0.57)\n1.49 (0.54)\n1.66 (0.68)\n1.88 (0.77)\n1.95 (0.79)\n2.22 (1.05)\n0.95\n1.13 (0.47)\n1.30 (0.80)\n1.34 (0.56)\n1.45 (0.52)\n1.60 (0.61)\n1.82 (0.74)\n1.90 (0.77)\n2.14 (1.05)\n1.05\n1.12 (0.44)\n1.27 (0.75)\n1.30 (0.51)\n1.42 (0.48)\n1.54 (0.52)\n1.79 (0.73)\n1.85 (0.74)\n2.07 (0.97)\n1.15\n1.10 (0.41)\n1.25 (0.77)\n1.32 (0.66)\n1.39 (0.46)\n1.52 (0.50)\n1.79 (0.79)\n1.82 (0.72)\n2.04 (0.98)\n1.25\n1.09 (0.38)\n1.23 (0.76)\n1.34 (0.71)\n1.40 (0.59)\n1.50 (0.48)\n1.78 (0.81)\n1.81 (0.75)\n1.99 (0.96)\n1.35\n1.21 (1.42)\n1.24 (0.81)\n1.31 (0.57)\n1.36 (0.41)\n1.49 (0.48)\n1.81 (0.91)\n1.79 (0.74)\n1.99 (1.00)\nTable 5. Average of the maximum estimation error of {θ(k)∗\nr\n}k∈S,r (standard deviations) in loge scale in the GMM simulation, with\ndifferent constants Cη in learning rate η(k)\nr\n= Cη/ ˆw(k)[0]\nr\nand heterogeneity parameter h.\nB.2. Additional Details of Real Studies\nDue to the high dimensionality of the MNIST and Fashion-MNIST datasets, we first applied tSNE (Hinton & Roweis, 2002;\nVan der Maaten & Hinton, 2008) to reduce the dimension to 10 then performed all methods on the transformed datasets. In\neach replication, 80% data for each task is used as training data and the remaining 20% is used as test data to calculate the\nmis-clustering error. We also contaminate different proportions of tasks to showcase the robustness of FedGrEM against\nadversarial attacks.\nWe record the average computational time for each method and the results are summarized below. The experiments were\nconducted with Dual Intel Xeon Gold 6226R processors (2.9 GHz) and a single core. The results are summarized in Tables\n6, 7, and 8. From the performance and computational time, we can see that FedGrEM can be adapted to a federated learning\nenvironment with hundreds of nodes, even without parallel computing. By parallelizing the local update steps in each\niteration, we can further speed things up.\nThe reason why gradient EM-based methods are slower than full EM-based methods is that the M-step of full EM has an\nexplicit expression and does not require calculating the matrix inverse since all covariances are identities. Full EM-based\nmethods do not apply to the problems with non-explicit M-steps and would be more time-consuming than gradient EM-based\nmethods if the explicit M-step expression is very complicated.\nC. Label Permutation\nDenote the family of permutation functions on [R] as PR.\n19\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nϵ / Method\nLocal-EM\nLocal-GrEM\nFedEM\nFedGrEM\nTGMM\nPooled-EM\nPooled-GrEM\n0%\n26.01 (1.22)\n36.55 (1.58)\n29.86 (1.48)\n47.07 (2.38)\n86.79 (3.69)\n18.85 (2.10)\n30.24 (2.97)\n6.8%\n25.92 (1.04)\n36.19 (1.41)\n29.74 (1.27)\n46.76 (1.92)\n85.07 (3.57)\n18.28 (1.66)\n29.71 (2.23)\n13.6%\n25.94 (1.46)\n36.07 (1.46)\n29.78 (1.54)\n46.90 (2.31)\n84.85 (3.73)\n17.81 (1.47)\n29.39 (2.00)\n20.5%\n25.62 (1.05)\n35.80 (1.48)\n29.49 (1.21)\n46.49 (2.12)\n83.84 (3.65)\n17.36 (1.35)\n28.56 (2.14)\nTable 6. Average computational time (standard deviations) in seconds for Pen-Based Recognition of Handwritten Digits dataset.\nϵ / Method\nLocal-EM\nLocal-GrEM\nFedEM\nFedGrEM\nTGMM\nPooled-EM\nPooled-GrEM\n0%\n83.99 (4.07)\n113.81 (6.59)\n93.00 (4.85)\n134.69 (6.41)\n299.56 (19.18)\n94.87 (12.26)\n166.12 (27.84)\n8%\n80.63 (3.92)\n110.90 (5.31)\n89.36 (4.57)\n132.49 (6.63)\n291.81 (17.09)\n93.51 (13.56)\n159.38 (28.76)\n16%\n80.06 (4.08)\n110.27 (5.51)\n88.52 (4.82)\n133.32 (7.12)\n290.71 (17.95)\n89.39 (14.91)\n151.79 (27.51)\n24%\n79.32 (3.82)\n109.31 (5.20)\n90.16 (4.55)\n133.74 (6.47)\n287.80 (15.12)\n86.54 (15.00)\n145.39 (25.01)\nTable 7. Average computational time (standard deviations) in seconds for MNIST dataset.\nϵ / Method\nLocal-EM\nLocal-GrEM\nFedEM\nFedGrEM\nTGMM\nPooled-EM\nPooled-GrEM\n0%\n83.89 (3.58)\n113.21 (4.94)\n92.82 (4.10)\n134.92 (5.98)\n297.01 (13.73)\n96.46 (14.15)\n169.07 (32.25)\n8%\n81.15 (3.54)\n111.78 (4.89)\n89.41 (4.08)\n133.29 (6.01)\n293.78 (14.59)\n94.52 (15.28)\n162.50 (30.77)\n16%\n80.70 (3.56)\n111.28 (4.78)\n89.80 (4.16)\n134.38 (6.17)\n293.31 (15.13)\n90.28 (15.88)\n154.20 (29.21)\n24%\n80.39 (3.46)\n110.75 (4.59)\n90.91 (4.17)\n135.52 (5.95)\n292.91 (13.93)\n87.20 (15.59)\n147.38 (27.98)\nTable 8. Average computational time (standard deviations) in seconds for Fashion-MNIST dataset.\nC.1. Label Permutation in Initialization\nOne challenge that hinders the practical application of FedGrEM (and other federated EM algorithms) and our theoretical\nframework relates to the initialization condition outlined in Assumption 3.5 (more rigorously, Assumption A.7). As is\ncommon in many unsupervised learning problems, the parameters are estimated up to a label permutation. Our results\nstill hold if the initialization condition holds up to a permutation, i.e. there exists a permutation π ∈PR such that\nmax\nk∈S,r∈[R] | bw(k)[0]\nπ(r) −w(k)∗\nr\n| ≤r∗\nw,\nmax\nk∈S,r∈[R] ∥bθ(k)[0]\nπ(r) −θ(k)∗\nr\n∥2 ≤r∗\nθ, however, it necessitates the presence of a shared\npermutation π ∈PR among the tasks in S. However, in all clustering methods typically employed for initialization in\nindividual tasks, the estimations are inherently invariant to permutations, and different tasks may yield distinct permutations.\nTo the best of our knowledge, there has been limited discussion in the existing literature on unsupervised FDL regarding this\nissue, with the exception of Tian et al. (2022). We generalized the solutions proposed in Tian et al. (2022) to address the\npermutation issue in initialization. By ensuring that different tasks in S share the same permutation, we make FedGrEM and\nour accompanying theory applicable in practice.\nC.2. Alignment Algorithms\nWe define the following score function of the permutations π = {πk}K\nk=1 ∈(PR)⊗K:\nscore(π, K) =\nR\nX\nr=1\nX\nk̸=k′∈[K]\n∥bθ(k)[0]\nπk(r) −bθ(k)[0]\nπk′(r)∥2.\nIntuitively, the score is smaller if the permutations π = {πk}K\nk=1 ∈(PR)⊗K are more aligned, serving as the basis for\nadjusting the permutations of each task. We also define the best permutation for task k ∈S as\nπ∗\nk = arg min\nπk∈PR\nR\nX\nr=1\n∥bθ(k)[0]\nπk(r) −θ(k)∗\nr\n∥2.\n20\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nNext, we introduce an exhaustive search algorithm for permutation alignment, which seeks the permutations minimizing the\nscore.\nPermutation Alignment Algorithm 1 (Exhaustive search): Let bπ = arg min\nπ∈(PR)⊗K score(π, K).\nUnder the assumption detailed below, we demonstrate that the output permutations in tasks of S from the exhaustive search\nalgorithm are well-aligned.\nAssumption C.1. The following conditions hold:\n(i) ∆> 2+2ϵ\n1−ϵ h + 4+4ϵ\n1−ϵ maxk∈S minπk∈PR maxr∈[R] ∥bθ(k)[0]\nπk(r) −θ(k)∗\nr\n∥2;\n(ii) ϵ < 1/2.\nTheorem C.2. Under Assumption C.1, for Alignment Algorithm 1 (Exhaustive search), there exists a permutation ι ∈PR\nsuch that bπk = ι ◦π∗\nk for all k ∈S.\nThe computational cost of the exhaustive search algorithm is O((R!)K · K2R) as it explores all the possible permutations\non [R] for all K tasks and takes O(K2R) time to calculate the score for each permutation. We introduce the following\nstepwise search algorithm which can reduce the computational cost to O(R!K · K2R).\nPermutation Alignment Algorithm 2 (Stepwise search): For k = 1 : K, with {bπk′}k−1\nk′=1 fixed, set bπk = arg min\nπk∈PR\nscore({bπk′}k−1\nk′=1 ∪πk, k). Finally, let bπ = {bπk}K\nk=1.\nUnder the following assumption, we show that the output permutations in tasks of S from the stepwise search algorithm are\nwell-aligned.\nAssumption C.3. Suppose there are no outlier tasks in the first K0 tasks and\n(i) ∆> 2 K0+Kϵ\nK0−Kϵh + 6 K0+Kϵ\nK0−Kϵ maxk∈S minπk∈PR maxr∈[R] ∥bθ(k)[0]\nπk(r) −θ(k)∗\nr\n∥2;\n(ii) K0 > Kϵ;\n(iii) ϵ < 1/2.\nTheorem C.4. Under Assumption C.3, there exists a permutation ι ∈PR such that bπk = ι ◦π∗\nk for all k ∈S.\nThe limitation of the stepwise search algorithm is that it requires the first K0 tasks to be non-outlier tasks. One potential\nsolution is running the algorithm multiple times with a random shuffling of tasks and then picking the permutations based\non recurring patterns observed across multiple experiment runs. We leave a full investigation of this random algorithm for\nfuture study.\nD. Additional Discussions\nWe want to comment a bit more about our FedGrEM algorithm.\n• When mixture proportions {w(k)∗\nr\n}K\nk=1 are also similar across tasks, we can apply the same aggregation by regularization\nin the central update to further improve the performance of FedGrEM. The same analysis tools can be applied to obtain\nstronger results.\n• When there exist various computational capabilities across different tasks, we can replace the current local gradient\ndescent with full local data by local stochastic gradient descent (SGD) with small batches of local data. This would\ndecrease the computational cost for each task. Moreover, instead of including all users in each iteration round, we can\nrandomly sample a few users in each round to update their local estimates and run the central update with only these\nactive users. These two approaches could further decrease the computational cost. And the size of SGD batches and\nthe proportion of active users in each round could depend on the computational and communicational budget for each\nuser, which could differ from user to user.\n21\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n• The current communicational cost for FedGrEM or FedEM (Marfoq et al., 2021) is already low because they only pass\nthe gradients across tasks in each iteration. The sampling of active users could help further decrease the communication\ncost.\n• Our current analysis and the method FedGrEM can be extended to a fully decentralized version with the same idea used\nby Algorithm 4 in (Marfoq et al., 2021). In each iteration, instead of sending all local estimates to the central server,\neach node can send their local estimates only to their neighbors (the nodes that are closest to them in the geometric\nsense or the communication cost sense) and perform the aggregation locally with the estimates received from the\nneighbors. We can use the current theoretical framework to analyze the estimation error of this fully decentralized\nalgorithm and derive similar results.\n• We can consider other types of attacks and contaminations. For example, instead of the corruption of the entire dataset\nfrom some users, we can assume partial observations are contaminated. In this case, we can create a robust version\nof local estimates by using truncated gradients, similar to the gradient clipping used in differential privacy (Varshney\net al., 2022). Aggregating these robust local estimates in the central update can make the whole procedure robust to\nboth observation-level and user-level attacks.\n• We assume that the central update can be exactly solved and we use alternating optimization to solve it in practice. We\ndid not directly analyze the alternating optimization itself because the EM procedure is already very complicated to\nstudy due to its iterative nature. We believe that this is an important question. One nice characteristic about our central\nupdate in FedGrEM (Algorithm 1) is that it is a convex problem. There exist convergence results about alternating\noptimization, such as (Li et al., 2019; Guminov et al., 2021; Tupitsa et al., 2021), which can be helpful. We can also\nconsider other optimization methods such as proximal gradient descent (Polson et al., 2015). We will work on this\nproblem in the future.\nWe also want to point out the possibility of generalizing our theory and method to high-dimensional or non-i.i.d. data.\n• For i.i.d. high-dimensional data, which is very common in healthcare and biomedical studies, we can add an additional\nregularization term (e.g., ℓ1-penalty) for the global estimator ¯ν in the central update of FedGrEM (Algorithm 1).\nAnother solution is to truncate the current local estimator (one-step gradient descent) by a coordinate-wise soft-\nthresholding function and keep the central update as it is. The challenges of analyzing such a problem are mainly\naligned with the challenges in other high-dimensional problems. For example, the strong concavity would fail for\nthe empirical surrogate risk function bQ(k). Instead, as one of the standard techniques used in the high-dimensional\nanalysis, we need to first prove that the estimators belong to a small subset (usually a cone in Rd), and within this\nsubset, the so-called restricted strong convexity or concavity (RSC) holds. In the context of federated EM algorithms,\nthe analysis would be more complicated due to the nature of the iterative procedure. Some analysis has been done for\nthe single-task EM in (Cai et al., 2019), and some techniques therein might be helpful.\n• For non-i.i.d. data, for example, the data of social networks, we can first apply some embedding methods to transform\nthe original data into a standard unsupervised learning problem. For instance, for adjacency or Laplacian matrices\nin social networks, we can compute its spectral embedding and use the embedding as the input for the federated EM\nalgorithms. The challenge here is that the embedded data is not independent. But in many situations, the dependence\nwithin the embedded data can be shown to be somewhat weak, which is sufficient to derive some theoretical guarantees\n(Rohe et al., 2011; Tang & Priebe, 2018; Abbe et al., 2020).\nE. Proofs\nE.1. Proof of Theorem A.8\nLet us first fix an S ⊆[K] and introduce the following key lemma.\nLemma E.1. (Duan & Wang, 2022) The following results hold:\n(i) If λ[t] ≥5√n maxk∈S ∥eθ(k)[t]\nr\n−θ(k)∗\nr\n∥2\n1−2ϵ\n, then\nmax\nk∈S ∥bθ(k)[t]\nr\n−θ(k)∗\nr\n∥2 ≤1\n|S|\n\r\r\r\r\r\nX\nk∈S\n(eθ(k)[t]\nr\n−θ(k)∗\nr\n)\n\r\r\r\r\r\n2\n+\n6\n1 −2ϵ min\nn\n3h, 2λ[t]\n5√n\no\n+ 2λ[t]\n√n ϵ.\n22\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n(ii) If we further have λ[t] ≥15√n\n1−2ϵ h, then\nmax\nk∈S ∥bθ(k)[t]\nr\n−θ(k)∗\nr\n∥2 ≤1\n|S|\n\r\r\r\r\r\nX\nk∈S\n(eθ(k)[t]\nr\n−θ(k)∗\nr\n)\n\r\r\r\r\r\n2\n+ 2h + 2λ[t]\n√n ϵ.\nDefine a random event V which is the intersection of the following three events:\n• The event in Assumption A.3.(ii) holds for all k ∈S with failure probability\nδ\n3RK ;\n• The event in Assumption A.3.(ii) holds for all k ∈S with failure probability\nδ\n3RK ;\n• The event in Assumption A.5.(iii) holds with failure probability δ\n3.\nThen by the union bound, P(V) ≥1 −δ. In the following analysis, we condition on V. Hence all arguments hold with\nprobability at least 1 −δ.\n(I) Part 1: Iteration round t = 1.\nBy Lemma E.1, when λ[t] ≥5√n\n1−2ϵ maxk∈S maxr∈[R] ∥eθ(k)[1]\nr\n−θ(k)∗\nr\n∥2:\nmax\nk∈S ∥bθ(k)[1]\nr\n−θ(k)∗\nr\n∥2 ≤1\n|S|\n\r\r\r\r\r\nX\nk∈S\n(eθ(k)[1]\nr\n−θ(k)∗\nr\n)\n\r\r\r\r\r\n2\n+\n6\n1 −2ϵ min\nn\n3h, 2λ[1]\n5√n\no\n+ 2λ[1]\n√n ϵ.\nNote that\n1\n|S|\n\r\r\r\r\r\nX\nk∈S\n(eθ(k)[1]\nr\n−θ(k)∗\nr\n)\n\r\r\r\r\r\n2\n≤1\n|S|\n\r\r\r\r\r\nX\nk∈S\n\u0014\nbθ(k)[0]\nr\n−θ(k)∗\nr\n+ η(k)\nr\n∂\n∂θr\nQ(k)(bθ(k)[0]| bw(k)[0], bθ(k)[0])\n\u0015\r\r\r\r\r\n2\n|\n{z\n}\n[1]\n+ 1\n|S|\n\r\r\r\r\r\nX\nk∈S\nη(k)\nr\n\u0014 ∂\n∂θr\nQ(k)(bθ(k)[0]| bw(k)[0], bθ(k)[0]) −\n∂\n∂θr\nbQ(k)(bθ(k)[0]| bw(k)[0], bθ(k)[0])\n\u0015\r\r\r\r\r\n2\n|\n{z\n}\n[2]\n.\nFor [1], we have\n[1] ≤1\n|S|\n\r\r\r\r\r\nX\nk∈S\n\u0014\nbθ(k)[0]\nr\n−θ(k)∗\nr\n+ η(k)\nr\n∂\n∂θr\nq(k)(bθ(k)[0])\n\u0015\r\r\r\r\r\n2\n+ 1\n|S|\n\r\r\r\r\r\nX\nk∈S\nη(k)\nr\n\u0014 ∂\n∂θr\nQ(k)(bθ(k)[0]| bw(k)[0], bθ(k)[0]) −\n∂\n∂θr\nq(k)(bθ(k)[0])\n\u0015\r\r\r\r\r\n2\n≤1\n|S|\nX\nk∈S\nq\n1 −η(k)\nr µ(k)\nr ∥bθ(k)[0] −θ(k)∗\nr\n∥2 + 1\n|S|\nX\nk∈S\nγ ·\nR\nX\nr=1\nη(k)\nr (| bw(k)[0]\nr\n−w(k)∗\nr\n| + ∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2)\n≤\n\u0012r\n1 −\nmin\nk∈S,r∈[R](η(k)\nr µ(k)\nr ) + γ¯ηR\n\u0013\nmax\nk∈S max\nr∈[R] ∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 + γ¯ηR · max\nk∈S max\nr∈[R] | bw(k)[0]\nr\n−w(k)∗\nr\n|,\nwhere the first part of the second inequality comes from the classical result of gradient descent (e.g., see Theorem 3.4 in Lan\n(2020)).\nSimilarly, we can show that\nmax\nk∈S ∥eθ(k)[1]\nr\n−θ(k)∗\nr\n∥2 ≤κ0G[0] + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n.\n23\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nTherefore λ[1] = eκ0λ[0] + 15√n[W(n,\nδ\n3RK , r∗\nθ) + 2¯ηE1(n,\nδ\n3RK )] =\n15\n119eκ0\n√n(r∗\nw + r∗\nθ) + 15√n[W(n,\nδ\n3RK , r∗\nθ) +\n2¯ηE1(n,\nδ\n3RK )] ≥5√n\n1−2ϵ maxk∈S ∥eθ(k)[1]\nr\n−θ(k)∗\nr\n∥2 indeed holds, where eκ0 = 119\nhq\n1 −mink∈S,r∈[R](η(k)\nr µ(k)\nr )+γ¯ηR+\nκR\ni\n.\nFor [2], we have\n[2] ≤¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n.\nCombine the bounds of [1] and [2]:\nmax\nk∈S max\nr∈[R] ∥bθ(k)[1]\nr\n−θ(k)∗\nr\n∥2 ≤\n\u0012r\n1 −\nmin\nk∈S,r∈[R](η(k)\nr µ(k)\nr ) + γ¯ηR\n\u0013\nmax\nk∈S max\nr∈[R](∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 + | bw(k)[0]\nr\n−w(k)∗\nr\n|)\n+\n6\n1 −2ϵ min\nn\n3h, 2λ[1]\n5√n\no\n+ 2λ[1]\n√n ϵ + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n.\nOn the other hand,\nmax\nk∈S max\nr∈[R] | bw(k)[0]\nr\n−w(k)∗\nr\n| ≤max\nk∈S max\nr∈[R]\n\f\f\f\f\f\n1\nn\nn\nX\ni=1\nP(z(k) = r|x(k)\ni\n, bw(k)[0], bθ(k)[0]) −E\n\u0002\nP(z(k) = r|x(k)\ni\n, bw(k)[0], bθ(k)[0])\n\u0003\n\f\f\f\f\f\n+ max\nk∈S max\nr∈[R]\n\f\f\fE\n\u0002\nP(z(k) = r|x(k)\ni\n, bw(k)[0], bθ(k)[0])\n\u0003\n−w(k)∗\nr\n\f\f\f\n≤W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ κ max\nk∈S\nR\nX\nr=1\n(∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 + | bw(k)[0]\nr\n−w(k)∗\nr\n|)\n≤W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ κR max\nk∈S max\nr∈[R](∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 + | bw(k)[0]\nr\n−w(k)∗\nr\n|).\n(7)\nAs a result,\nmax\nk∈S max\nr∈[R](∥bθ(k)[1]\nr\n−θ(k)∗\nr\n∥2 + | bw(k)[1]\nr\n−w(k)∗\nr\n|)\n≤\n\u0012r\n1 −\nmin\nk∈S,r∈[R](η(k)\nr µ(k)\nr ) + γ¯ηR + κR\n\u0013\nmax\nk∈S max\nr∈[R](∥bθ(k)[0]\nr\n−θ(k)∗\nr\n∥2 + | bw(k)[0]\nr\n−w(k)∗\nr\n|)\n+\n6\n1 −2ϵ min\nn\n3h, 2λ[1]\n5√n\no\n+ 2λ[1]\n√n ϵ + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n.\nDenote G[t] = maxk∈S maxr∈[R](∥bθ(k)[t]\nr\n−θ(k)∗\nr\n∥2 +| bw(k)[t]\nr\n−w(k)∗\nr\n|) and κ0 =\nq\n1 −mink∈S,r∈[R](η(k)\nr µ(k)\nr )+γ¯ηR+\nκR. Then\nG[1] ≤κ0G[0] +\n6\n1 −2ϵ min\nn\n3h, 2λ[1]\n5√n\no\n+ 2λ[1]\n√n ϵ + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n≤κ0G[0] +\n\u0014\n12\n5(1 −2ϵ) + 2ϵ\n\u0015λ[1]\n√n + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n≤κ0G[0] + 118\n15 · λ[1]\n√n + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n.\n(II) Part 2: Iteration round t ≥2.\nRepeating the analysis in (I), we can see that when λ[t]\n≥\n15√nκ0G[t−1] + 15√n¯ηE1(n,\nδ\n3RK )\n≥\n15√n\n\u0010q\n1 −mink∈S,r∈[R](η(k)\nr µ(k)\nr ) + γ¯ηR\n\u0011\nG[t−1] + 15√n¯ηE1(n,\nδ\n3RK ),\nG[t] ≤κ0G[t−1] + 118\n15 · λ[t]\n√n + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n24\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≤119\n15 · λ[t]\n√n + ¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n.\n(8)\nRecall our setting of {λ[t]}T\nt=1:\nλ[0] = 15\n119\n√n(r∗\nw + r∗\nθ),\nλ[t] = ˜κ0λ[t−1] + 15√n\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n.\nHence λ[t] ≥15√nκ0G[t−1] + 15√n¯ηE1(n,\nδ\n3RK ) indeed holds and\nλ[t] = (eκ0)tλ[0] + 1 −(eκ0)t\n1 −eκ0\n15√n\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n,\n(9)\nwhich together with (8) implies\nG[t] ≤(eκ0)t(r∗\nw + r∗\nθ) +\n\u0012 119\n1 −eκ0\n+ 1\n\u0013h\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n≤r∗\nθ,\n(10)\nwhen t ≥1. The last inequality holds due to Assumption A.7. Similar to (7), we have\nmax\nk∈S max\nr∈[R] | bw(k)[t]\nr\n−w(k)∗\nr\n| ≤W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ κR · G[t−1]\n≤W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 119\n15 (eκ0)t−1κR(r∗\nw + r∗\nθ)\n+ κR\n\u0012 119\n1 −eκ0\n+ 1\n\u0013h\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n≤r∗\nw,\nwhere the last inequality is due to Assumption A.7.\n(III) Part 3: The case when h ≤1\n3[W\n\u0000n,\nδ\n3RK , r∗\nθ\n\u0001\n+ 2¯ηE1\n\u0000n,\nδ\n3RK\n\u0001\u0003\n.\nIn this case, we have λ[t] ≥15√n\n\u0002\nW\n\u0000n,\nδ\n3RK , r∗\nθ\n\u0001\n+ 2¯ηE1\n\u0000n,\nδ\n3RK\n\u0001\u0003\n≥15√n\n1−2ϵ h for t ≥1. Then by Lemma E.1.(ii),\nbθ(k)[t]’s are equal for k ∈S when t ≥1. Thus\nG[1] ≤119\n15 ˜κ0λ[0] +\n\u0012 119\n1 −eκ0\n+ 1\n\u0013h\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n,\nmax\nk∈S max\nr∈[R] ∥bθ(k)[t]\nr\n−θ(k)∗\nr\n∥2 ≤\n\u0012r\n1 −\nmin\nk∈S,r∈[R](η(k)\nr µ(k)\nr ) + γ¯ηR\n\u0013\nG[t−1] + ¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+\n6\n1 −2ϵ min\nn\n3h, 2λ[t]\n5√n\no\n+ 2λ[t]\n√n ϵ,\nmax\nk∈S max\nr∈[R] | bw(k)[t]\nr\n−w(k)∗\nr\n| ≤W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ κRG[t−1],\nwhich implies that\nG[t] ≤κ0G[t−1] + ¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+\n6\n1 −2ϵ min\nn\n3h, 2λ[t]\n5√n\no\n+ 2λ[t]\n√n ϵ + W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n,\nwhen t ≥2. By induction,\nG[t] ≤κt−1\n0\nG[1] + 1 −κt−1\n0\n1 −κ0\n¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+\n6\n1 −2ϵ\nt\nX\nt′=2\nκt−t′\n0\n· min\nn\n3h, 2λ[t′]\n5√n\no\n|\n{z\n}\n[3]\n+ 2ϵ\n√n\nt\nX\nt′=2\nκt−t′\n0\n· λ[t′]\n|\n{z\n}\n[4]\n25\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n.\nBy (9),\n[3] ≤min\n\u001a\n31 −κt−1\n0\n1 −κ0\nh, 2\n5(t −1)(˜κ0)t · λ[0]\n√n +\n6\n1 −˜κ0\n· 1 −κt−1\n0\n1 −κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n,\n[4] ≤(t −1)(˜κ0)tλ[0] +\n15\n1 −˜κ0\n· 1 −κt−1\n0\n1 −κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i√n.\nTherefore,\nG[t] ≤(˜κ0/119)t−1G[1] +\n1\n1 −κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ ¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011i\n+\n18\n1 −˜κ0/119 · min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ ·\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n+\n\u00102\n3 + 2\n5 · 18\n\u0011\n· (t −1)(˜κ0)t λ[0]\n√n\n≤119\n15 ˜κ0(˜κ0/119)t−1\n\u001aλ[0]\n√n +\n\u0010 119\n1 −˜κ0\n+ 1\n\u0011h\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n+\n1\n1 −κ0\nh\n¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011i\n+\n18\n1 −˜κ0/119 · min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ ·\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n+ 118\n15 · (t −1)(˜κ0)t λ[0]\n√n\n≤˜κ0(˜κ0/119)t−1(r∗\nw + r∗\nθ) +\n\u0014119\n15 ˜κ0(˜κ0/119)t−1 + 118\n119(t −1)(˜κ0)t\n\u0015\n(r∗\nw + r∗\nθ)\n+\n1\n1 −κ0\nh\n¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011i\n+\n18\n1 −˜κ0/119 · min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ ·\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n.\nNote that ˜κ0(˜κ0/119)t−1 + 119\n15 ˜κ0(˜κ0/119)t−1 + 118\n119(t−1)(˜κ0)t ≤9˜κ0(˜κ0/119)t−1 + 118\n119(t−1)(˜κ0)t ≤10t(˜κ0)t, hence\nG[t] ≤20t(˜κ0)t−1(r∗\nw ∨r∗\nθ) +\n\u0014119\n15 ˜κ0(˜κ0/119)t−1 + 118\n119(t −1)(˜κ0)t\n\u0015\n(r∗\nw + r∗\nθ)\n+\n1\n1 −κ0\nh\n¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011i\n+\n18\n1 −˜κ0/119 · min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ ·\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n.\n(11)\nBy Assumption 4, we obtain maxk∈S maxr∈[R] ∥bθ(k)[t]\nr\n−θ(k)∗\nr\n∥2 ≤G[t] ≤r∗\nθ.\nNext, let us shrink the contraction radius to obtain the desired rate. Recall that\nAt =\n\u0014\n9˜κ0\n\u0010 ˜κ0\n119\n\u0011t−1\n+ 118\n119(t −1)˜κt−1\n0\n\u0015\n(r∗\nw + r∗\nθ) +\n1\n1 −˜κ0/119 ¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n26\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n+\n18\n1 −˜κ0/119 min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn, δ\n3R\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ\n\u0014\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn, δ\n3R\n\u0011\u0015\n,\nand\nAt +\n18\n1 −˜κ0/119W\n\u0010\nn,\nδ\n3RK , r∗\nθ,t\n\u0011\n= r∗\nθ,t+1,\nwith r∗\nθ,1 := r∗\nθ. Then we repeat the previous analysis in part (III) for t = 1 : T, then we will get the same rate as in (11) but\nreplace r∗\nθ with r∗\nθ,T in the term\n1\n1−κ0\n\u0002\n¯ηE2(n, |S|,\nδ\n3R) + W(n,\nδ\n3RK , r∗\nθ)\n\u0003\n.\n(IV) Part 4: Combining this rate (which holds when h ≤1\n3[W(n,\nδ\n3RK , r∗\nθ) + 2¯ηE1(n,\nδ\n3RK )]) with (10) (which holds for\nany h ≥0 but is only used when h > 1\n3[W(n,\nδ\n3RK , r∗\nθ) + 2¯ηE1(n,\nδ\n3RK )]) completes our proof.\nE.2. Proof of Proposition A.11\nWe first introduce two useful lemmas.\nLemma E.2 (Theorem 3 in Maurer & Pontil (2021)). Let f : X n →R and X = (X1, . . . , Xn) be a vector of independent\nrandom variables with values in a space X. Then for any t > 0 we have\nP(f(X) −Ef(X) > t) ≤exp\n\n\n−\nt2\n32e\n\r\r\r\nPn\ni=1 ∥fi(X)∥2\nψ2\n\r\r\r\n∞\n\n\n,\nwhere fi(X) as a random function of x is defined to be (fi(X))(x)\n:=\nf(x1, . . . , xi−1, Xi, xi+1, . . . , Xn) −\nEXi[f(x1, . . . , xi−1, Xi, xi+1, . . . , Xn)], the sub-Gaussian norm ∥Z∥ψ2 := supd≥1{∥Z∥d/\n√\nd}, and ∥Z∥d = (E|Z|d)1/d.\nLemma E.3 (Vectorized contraction of Rademacher complexity, Corollary 1 in Maurer (2016)). Suppose {ϵir}i∈[n],r∈[R]\nand {ϵi}n\ni=1 are independent Rademacher variables. Let F be a class of functions f : Rd →S ⊆RR and h : S →R is\nL-Lipschitz under ℓ2-norm, i.e., |h(y) −h(y′)| ≤L∥y −y′∥2, where y = (y1, . . . , yR)T , y′ = (y′\n1, . . . , y′\nR)T ∈S. Then\nE sup\nf∈F\nn\nX\ni=1\nϵih(f(xi)) ≤\n√\n2LE sup\nf∈F\nn\nX\ni=1\nR\nX\nr=1\nϵirfr(xi),\nwhere fr(xi) is the r-th component of f(xi) ∈S ⊆RR.\nDefine the posterior\nγ(r)\nθ(k),w(k)(x(k)) =\nw(k)\nr\nexp{(x(k))T (θ(k)\nr\n−θ(k)\n1 ) −1\n2(∥θ(k)\nr ∥2\n2 −∥θ(k)\n1 ∥2\n2)}\nw(k)\n1\n+ PR\nr=2 w(k)\nr\nexp{(x(k))T (θ(k)\nr\n−θ(k)\n1 ) −1\n2(∥θ(k)\nr ∥2\n2 −∥θ(k)\n1 ∥2\n2)}\n= P(z(k) = r|x(k); θ(k), w(k)), r ∈[R],\nwhere w(k) = {w(k)}K\nk=1 and θ(k) = {θ(k)\nr }K\nk=1.\nBy definition, q(k)(θ) = Q(k)(θ|θ(k)∗, w(k)∗) = −1\n2E\n\u0002 PR\nr=1 γ(r)\nθ(k)∗,w(k)∗(x(k))∥x(k)−θ∥2\n2\n\u0003\n, hence µ(k)\nr\n= L(k)\nr\n= w(k)∗\nr\nwith r∗\n1 = +∞. And\nbQ(k)(θ|θ′, w′) = −1\n2nk\nn\nX\ni=1\nR\nX\nr=1\nγ(r)\nθ′,w′(x(k)\ni\n)∥x(k)\ni\n−θ∥2\n2,\n∂\n∂θr\nQ(k)(θ|θ′, w′) = −Ex(k)\n\u0002\nγ(r)\nθ′,w′(x(k))(θ −x(k))\n\u0003\n,\n∂\n∂θr\nbQ(k)(θ|θ′, w′) = −1\nnk\nn\nX\ni=1\nγ(r)\nθ′,w′(x(k)\ni\n)(θ −x(k)\ni\n).\n27\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nFrom the proof of Theorem 1 in Tian et al. (2022), we have κ ≍c−2\nw R2 exp{−C∆2}, γ ≍M 2c−2\nw R2 exp{−C∆2} with\nr2 = Cb∆. Consider r∗\nθ = r∗\n1 ∧r∗\n2 = Cb∆≤M. In the remaining proof of Proposition 1, we will derive the expressions of\nW, E1 and E2. Let\nV =\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nP(z(k) = r|x(k)\ni\n; w, θ) −Ex(k)\n\u0002\nP(z(k) = r|x(k); w, θ)\n\u0003\f\f\f\f\n=\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n) −E\n\u0002\nγ(r)\nθ,w(x(k))\n\u0003\f\f\f\f.\nBy bounded difference inequality (Corollary 2.21 in Wainwright (2019)), w.p. at least 1 −δ,\nV ≤EV +\nr\nlog(1/δ)\nn\n.\nAnd by classical symmetrization arguments (e.g., see Proposition 4.11 in Wainwright (2019)),\nEV ≤2\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\ni\nγ(k)\nθ,w(x(k)\ni\n)\n\f\f\f\f.\nLet g(k)\nir = (θr −θ1)T x(k)\ni\n−1\n2(∥θr∥2\n2 −∥θ1∥2\n2) + log wr −log w1, φ(x) =\nexp{xr}\n1+PR\nr=2 exp{xr}, where φ is 1-Lipschitz (w.r.t.\nℓ2-norm) and γ(r)\nθ,w(x) = φ({g(k)\nir }R\nr=2). Then by Lemma E.3,\n2\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\ni\nγ(k)\nθ,w(x(k)\ni\n)\n\f\f\f\f\n≲1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nR\nX\nr=2\nϵ(k)\nir g(k)\nir\n\f\f\f\f\n≲1\nn\nR\nX\nr=2\nEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir g(k)\nir\n\f\f\f\f\n≲\nR\nX\nr=2\n(\n1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θr −θ1)T x(k)\ni\n\f\f\f\f + 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (∥θr∥2\n2 −∥θ1∥2\n2)\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (log wr −log w1)\n\f\f\f\f\n)\n≲\nR\nX\nr=2\n(\n1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θr −θ(k)∗\nr\n)T x(k)\ni\n\f\f\f\f + 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θ1 −θ(k)∗\n1\n)T x(k)\ni\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θ(k)∗\nr\n−θ(k)∗\n1\n)T x(k)\ni\n\f\f\f\f + 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θr + θ1)T (θr −θ1)\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (log wr −log w1)\n\f\f\f\f\n)\n28\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≲RMξ\nr\nd\nn + [RM 2 + R log(Rc−1\nw )]\nr\n1\nn,\nwhich implies\nV ≲RMξ\nr\nd\nn + [RM 2 + R log(Rc−1\nw )]\nr\n1\nn +\nr\nlog(1/δ)\nn\n≍W(n, δ, ξ).\nw.p. at least 1 −δ.\nNext, let\nU =\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\r\r\r\r\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)x(k)\ni\n−E\n\u0002\nγ(r)\nθ,w(x(k))x(k)\u0003\r\r\r\r\n2\n=\nsup\n∥u∥2≤1\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T u −E\n\u0002\nγ(r)\nθ,w(x(k))(x(k))T u\n\u0003\f\f\f\f\n≤2 max\nj=1:N\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T uj −E\n\u0002\nγ(r)\nθ,w(x(k))(x(k))T uj\n\u0003\f\f\f\f\n|\n{z\n}\nUj\n,\nwhere {uj}N\nj=1 is a 1/2-cover of the unit ball B(0, 1) in Rd w.r.t. ℓ2-norm, with N ≤5d (by Example 5.8 in (Wain-\nwright, 2019)). We first bound Uj −EUj as follows. Fix x(k)\n1 , . . . , x(k)\ni−1, x(k)\ni+1, . . . , x(k)\nn\nand define s(k)\nir (x(k)\ni\n) =\nVj −E[Vj|x(k)\n1 , . . . , x(k)\ni−1, x(k)\ni+1, . . . , x(k)\nn ]. Then\n|s(k)\nir (x(k)\ni\n)| ≤1\nn\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\fγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T uj\n\f\f\f\n|\n{z\n}\nW1\n+ 2\nnE\n\f\f\f\f\f\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\nγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T uj\n\f\f\f\f\f\n|\n{z\n}\nW2\n,\nwhere [E(W1 + W2)d]1/d ≤(EW d\n1 )1/d + (EW d\n2 )1/d, and (EW d\n1 )1/d, (EW d\n2 )1/d ≤CM\n√\nd/n with some constantC > 0.\nThen by Lemma E.2,\nP(Uj −EUj ≥t) ≲exp\n\u001a\n−Cnt2\nM 2\n\u001b\n.\nBy a similar procedure used in deriving W(n, δ, ξ), we can show that\nEUj ≲RM 2r∗\nθ\nr\nd\nn + [RM 3 + RM log(Rc−1\nw )]\nr\n1\nn.\nAs a consequence,\nP\n\u0012\nUj ≥CRM 2r∗\nθ\nr\nd\nn + C[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + t\n\u0013\n≲exp\n\u001a\n−Cnt2\nM 2\n\u001b\n.\nTherefore\nP\n\u0012\nmax\nj=1:N Uj ≥CRM 2r∗\nθ\nr\nd\nn + C[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + t\n\u0013\n≲N exp\n\u001a\n−Cnt2\nM 2\n\u001b\n,\nwhich implies that\nU ≲(RM 2r∗\nθ + M)\nr\nd\nn + [RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + M\nr\nlog(1/δ)\nn\n,\n29\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nw.p. at least 1 −δ. On the other hand, by W(n, δ, r∗\nθ), we have\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\r\r\r\r\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)θ−E\n\u0002\nγ(r)\nθ,w(x(k))θ\n\u0003\r\r\r\r\n2\n≲\n\u0014\nRMξ\nr\nd\nn +[RM 2+R log(Rc−1\nw )]\nr\n1\nn +\nr\nlog(1/δ)\nn\n\u0015\n·M,\nhence\nE1(n, δ) ≍(RM 2r∗\nθ + M)\nr\nd\nn + [RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + M\nr\nlog(1/δ)\nn\n≍RM 3\nr\nd\nn + [RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + M\nr\nlog(1/δ)\nn\n,\nwhere the last inequality is due to r∗\nθ = r∗\n1 ∧r∗\n2 = Cb∆≤M.\nLet\nZ =\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n0<≤η(k)\nr\n≤¯η\n1\nn|S|\n\r\r\r\r\r\nX\nk∈S\nη(k)\nr\n·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n)x(k)\ni\n−E[γ(k)\nθ,w(x(k))x(k)]\n\u0001\n\r\r\r\r\r\n2\n=\nsup\n∥u∥2≤1\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n0<≤η(k)\nr\n≤¯η\n1\nn|S|\n\f\f\f\f\f\nX\nk∈S\nη(k)\nr\n·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T u −E[γ(k)\nθ,w(x(k))(x(k))T u]\n\u0001\n\f\f\f\f\f\n≤\nsup\nj′\n1,...,j′\nk=1:N ′ sup\nj=1:N\n2\nn|S|\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\f\nX\nk∈S\nηj′\nk ·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T uj −E[γ(k)\nθ,w(x(k))(x(k))T uj]\n\u0001\n\f\f\f\f\f\n|\n{z\n}\nZ(j,j′\n1,...,j′\nk)\n,\nwhere {uj}N\nj=1 is a 1/2-cover of the unit ball B(0, 1) in Rd w.r.t. ℓ2-norm with N ≤5d and {ηj′}N′\nj′=1 is a 1/2-cover of\n[0, 1] with N ′ ≤2. We first bound Z(j, j′\n1, . . . , j′\nk) −EZ(j, j′\n1, . . . , j′\nk) as follows. Fix x(k)\n1 , . . . , x(k)\ni−1, x(k)\ni+1, . . . , x(k)\nn\nand\ndefine v(k)\nir (x(k)\ni\n) = Z(j, j′\n1, . . . , j′\nk) −E[Z(j, j′\n1, . . . , j′\nk)|{x(k)\ni\n}k∈S,i∈[n]\\{x(k)\ni\n}]. Then\n|v(k)\nir (x(k)\ni\n)| ≤ηjk\nn|S|\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\fγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T uj\n\f\f\f\n|\n{z\n}\nW1\n+ 2ηjk\nn|S|E\n\f\f\f\f\f\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\nγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T uj\n\f\f\f\f\f\n|\n{z\n}\nW2\n.\nVia the same procedure used to bound Uj, it can be shown that\nP(Z(j, j′\n1, . . . , j′\nk) −EZ(j, j′\n1, . . . , j′\nk) ≥t) ≲exp\n\u001a\n−Cn|S|t2\nM 2¯η2\n\u001b\n,\nEZ(j, j′\n1, . . . , j′\nk) ≲¯ηRM 2r∗\nθ\ns\nd\nn|S| + ¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn,\nleading to\nP\n\u0012\nZ(j, j′\n1, . . . , j′\nk) ≥¯ηRM 2r∗\nθ\ns\nd\nn|S| + ¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + t\n\u0013\n≲exp\n\u001a\n−Cn|S|t2\nM 2¯η2\n\u001b\n.\nTherefore\nP\n\u0012\nmax\nj′\n1,...,j′\nk=1:N′ max\nj=1:N Z(j, j′\n1, . . . , j′\nk) ≥C¯ηRM 2r∗\nθ\ns\nd\nn|S| + C¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + t\n\u0013\n30\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≲N(N ′)K exp\n\u001a\n−Cn|S|t2\nM 2¯η2\n\u001b\n,\nwhich implies that\nZ ≤\nmax\nj′\n1,...,j′\nk=1:N′ max\nj=1:N Z(j, j′\n1, . . . , j′\nk) ≲¯η(RM 2r∗\nθ+M)\ns\nd\nn|S| +¯η[RM 3+RM log(Rc−1\nw )]\nr\n1\nn +¯ηM\ns\nlog(1/δ)\nn|S|\n,\nw.p. at least 1 −δ. Similarly,\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n0<≤η(k)\nr\n≤¯η\n1\nn|S|\n\r\r\r\r\r\nX\nk∈S\nη(k)\nr\n·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n)θr −E[γ(k)\nθ,w(x(k))θr]\n\u0001\n\r\r\r\r\r\n2\n≲¯η(RM 2r∗\nθ + M)\ns\nd\nn|S| + ¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + ¯ηM\ns\nlog(1/δ)\nn|S|\n,\nw.p. at least 1 −δ. Considering that r∗\nθ = r∗\n1 ∧r∗\n2 = Cb∆≤M, we have\nE2(n, |S|, δ) ≍RM 3\ns\nd\nn|S| + [RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + M\ns\nlog(1/δ)\nn|S|\n.\nE.3. Proof of Proposition A.14\nRecall that\nAt =\n\u0014\n9˜κ0\n\u0010 ˜κ0\n119\n\u0011t−1\n+ 118\n119(t −1)˜κt−1\n0\n\u0015\n(r∗\nw + r∗\nθ) +\n1\n1 −˜κ0/119 ¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+\n18\n1 −˜κ0/119 min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn, δ\n3R\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ\n\u0014\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn, δ\n3R\n\u0011\u0015\n,\nand\nAt +\n18\n1 −˜κ0/119W\n\u0010\nn,\nδ\n3RK , r∗\nθ,t\n\u0011\n= r∗\nθ,t+1,\nfor t ≥1 with r∗\nθ,1 := r∗\nθ.\nBy Assumption A.9.(iv), there exists ˜κ′\n0 ∈(0, 1) such that CRM\np p\nn ≤˜κ′\n0 with a large C. Hence by plugging in the\nexplicit rates obtained in Proposition A.11,\nr∗\nθ,t+1 ≤˜κ′\n0r∗\nθ,t + Ct(˜κ0)t−1(r∗\nw ∨r∗\nθ) + C¯ηRM 3\ns\nd\nn|S| + C[(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn\n+ C[(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ C min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn,\nimplying that\nr∗\nθ,T ≲(˜κ′\n0)T −1r∗\nθ + T 2(˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + ¯ηRM 3\ns\nd\nn|S| + [(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn\n+ [(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn\n31\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≲T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + ¯ηRM 3\ns\nd\nn|S| + [(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn\n+ [(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn\n≲T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + R2M 3c−1\nw\ns\nd\nn|S| + R2Mc−1\nw [M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ MRc−1\nw\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, R2M 3c−1\nw\nr\nd\nn\n\u001b\n+ ϵRM 3c−1\nw\nr\nd\nn,\nwhere κ0 = 119\nq\n2Cb\n1+Cb +CM 2c−2\nw R3 exp{−C′∆2}+Cc−2\nw R3 exp{−C′∆2}+˜κ′\n0, and ˜κ′\n0 satisfies 1 > ˜κ′\n0 > CMR\nq\nd\nn\nfor some C > 0.\nE.4. Proof of Corollary A.12\nBy the rate of W(n,\nδ\n3RK , r∗\nθ,T ) in Proposition A.11 and the upper bound of r∗\nθ,T in Proposition A.14,\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ,T\n\u0011\n≍RMr∗\nθ,T\nr\nd\nn + [RM 2 + R log(Rc−1\nw )]\nr\n1\nn +\nr\nlog(RK/δ)\nn\n≲T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + R2M 3c−1\nw\ns\nd\nn|S| + R2Mc−1\nw [M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ MRc−1\nw\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, R2M 3c−1\nw\nr\nd\nn\n\u001b\n+ ϵRM 3c−1\nw\nr\nd\nn.\nApplying Theorem A.8, we have\nmax\nk∈S max\nr∈[R](∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2 + | bw(k)[T ]\nr\n−w(k)∗\nr\n|)\n≤20T(˜κ0)T −1(r∗\nw ∨r∗\nθ) +\n\u0014119\n15 ˜κ0(˜κ0/119)T −1 + 118\n119(T −1)(˜κ0)T\n\u0015\n(r∗\nw + r∗\nθ)\n+\n1\n1 −κ0\nh\n¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ,J\n\u0011i\n+\n18\n1 −˜κ0/119 · min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ ·\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n≤T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + R2M 3c−1\nw\ns\nd\nn|S| + R2Mc−1\nw [M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ MRc−1\nw\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, R2M 3c−1\nw\nr\nd\nn\n\u001b\n+ ϵRM 3c−1\nw\nr\nd\nn.\n(12)\nNote that conditioned on the event V defined in the proof of Theorem A.8,\nη(k)\nr\n= (1 + Cb)−1( bw(k)[0]\nr\n)−1 ≲Rc−1\nw ,\nfor all k ∈S and r ∈[R]. Plugging it in equation (12) implies the desired upper bound in Corollary A.12.\nE.5. Proof of Proposition A.16\nSince this proof is very long, we divide it into several parts.\n(I) Part 1: Deriving the expressions of µ(k)\nr\nand L(k)\nr .\n32\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nFirst, note that\nq(k)(θ) = Q(k)(θ|θ(k)∗, w(k)∗) = −1\n2E\n\"\nR\nX\nr=1\nγ(r)\nθ(k)∗,w(k)∗(x(k), y(k))(y(k) −(x(k))T θr)2\n#\n.\nand\nbQ(k)(θ|θ′, w′) = −1\n2n\nn\nX\ni=1\nR\nX\nr=1\nγ(r)\nθ′,w′(x(k)\ni\n)(y(k)\ni\n−(x(k)\ni\n)T θr)2,\n∂\n∂θr\nQ(k)(θ|θ′, w′) = −Ex(k)\n\u0002\nγ(r)\nθ′,w′(x(k), y(k))x(k)((x(k))T θr −y(k))\n\u0003\n,\n∂\n∂θr\nbQ(k)(θ|θ′, w′) = −1\nn\nn\nX\ni=1\nγ(r)\nθ′,w′(x(k)\ni\n, y(k)\ni\n)x(k)\ni\n((x(k)\ni\n)T θr −y(k)\ni\n),\n∇2\nθq(k)(θ) = diag\n\u0010n\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T ioR\nr=1\n\u0011\n.\nWe have the following lemma.\nLemma E.4. Under Assumption A.15:\n(i) λmax\n\u0000E\n\u0002\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T \u0003\u0001\n≤w(k)∗\nr\n+ C\n√log ∆\n∆\n:= L(k)\nr ;\n(ii) λmin\n\u0000E\n\u0002\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T \u0003\u0001\n≥w(k)∗\nr\n−CR\n√log ∆\n∆\n:= µ(k)\nr .\nNow let us prove the lemma.\n(i) Note that\nγ(r)\nw(k)∗,θ(k)∗(x(k), y(k)) =\nw(k)∗\nr\nexp{y(k)(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n) −1\n2[((x(k))T θ(k)∗\nr\n)2 −((x(k))T θ(k)∗\n1\n)2]}\nw(k)∗\n1\n+ PR\nr=2 w(k)∗\nr\nexp{y(k)(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n) −1\n2[((x(k))T θ(k)∗\nr\n)2 −((x(k))T θ(k)∗\n1\n)2]}\n,\nwhere\ny(k)(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n) −1\n2[((x(k))T θ(k)∗\nr\n)2 −((x(k))T θ(k)∗\n1\n)2]\n= [y(k) −(x(k))T θ(k)∗\n1\n] · (x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n) + [(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n)]\n\u0014\n(x(k))T θ(k)∗\n1\n−1\n2((x(k))T θ(k)∗\nr\n+ (x(k))T θ(k)∗\n1\n)\n\u0015\n= [y(k) −(x(k))T θ(k)∗\n1\n] · (x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n) −1\n2[(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n)]2.\nConditioned on the event {z(k) = 1}, we have [y(k) −(x(k))T θ(k)∗\n1\n] · (x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n) ∼N(0, [(x(k))T (θ(k)∗\nr\n−\nθ(k)∗\n1\n)]2). Define events\nV1 =\n\b\n|[y(k) −(x(k))T θ(k)∗\n1\n] · (x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n)| ≤τ1|(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n)|\n\t\n,\nV2 =\n\b\n|(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n)| ≥τ2∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2\n\t\n,\nthen by the tail bounds for Gaussian variables and the boundedness of Gaussian density, we have P(Vc\n1) ≲exp{−Cτ 2\n1 },\nP(Vc\n2) ≲τ2. Therefore,\nλmax\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T \f\f\fz(k) = 1\ni\u0011\n33\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≲\nsup\n∥u∥2=1\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))((x(k))T u)2\f\f\fz(k) = 1\ni\nP(V1 ∩V2)\n|\n{z\n}\n[1]\n+\nsup\n∥u∥2=1\nq\nE[((x(k))T u)4|z(k) = 1]\nq\nP(Vc\n1)\n|\n{z\n}\n[2]\n+\nsup\n∥u∥2=1\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))((x(k))T u)21(Vc\n2)\n\f\f\fz(k) = 1\ni\n|\n{z\n}\n[3]\n,\nwhere\n[1] ≲w(k)∗\nr\nw(k)∗\n1\n· E\n\u0014\nexp\nn\nτ1|(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n)| −1\n2|(x(k))T (θ(k)∗\nr\n−θ(k)∗\n1\n)|2\f\f\fz(k) = 1, V1 ∩V2\no\u0015\n≲w(k)∗\nr\nw(k)∗\n1\n· exp\nn\nτ1τ2∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2 −1\n2τ 2\n2 ∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2\n2\no\n,\n[2] ≲exp{−Cτ 2\n1 },\n[3] ≲\nsup\n∥u∥2=1\nE[((x(k))T u)2|V2] · P(V2) ≲P(V2) ≲τ2, .\n(13)\nThe second inequality in (13) holds due to Lemma A.1 in Kwon & Caramanis (2020b). Let τ1 = c\nq\nlog ∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2,\nτ2 = 3C\nq\nlog ∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2\n∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2\nwith some constant c > 0. Note that ∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2 ≤τ1/τ2 = ∥θ(k)∗\nr\n−θ(k)∗\n1\n∥2/3. Then\nλmax\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T \f\f\fz(k) = 1\ni\u0011\n≤[1] + [2] + [3] ≲w(k)∗\nr\nw(k)∗\n1\n1\n∆+\n√log ∆\n∆\n.\nSimilarly, the same bound holds for λmax(E[γ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T |z(k) = r′]) with all r′ ̸= r. In addition, we\ncan rewrite γ(r)\nw(k)∗,θ(k)∗(x(k), y(k)) as\nγ(r)\nw(k)∗,θ(k)∗(x(k), y(k)) =\nw(k)∗\nr\nw(k)∗\nr\n+ P\nr′̸=r w(k)∗\nr′\nexp{y(k)(x(k))T (θ(k)∗\nr′\n−θ(k)∗\n1\n) −1\n2[((x(k))T θ(k)∗\nr′\n)2 −((x(k))T θ(k)∗\n1\n)2]}\n≤1,\nwhich implies that\nλmax\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T \f\f\fz(k) = r\ni\u0011\n≤1.\nHence by the convexity of maximum eigenvalues,\nλmax\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T i\u0011\n≤\nR\nX\nr′=1\nw(k)∗\nr′\n· λmax\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T \f\f\fz(k) = r′i\u0011\n≤w(k)∗\nr\n\u0010\n1 + C\n∆\n\u0011\n+ C\n√log ∆\n∆\n≤w(k)∗\nr\n+ C′\n√log ∆\n∆\n.\n(ii) We have\nλmin\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T i\u0011\n≥w(k)∗\nr\nλmin\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T \f\f\fz(k) = r\ni\u0011\n≥w(k)∗\nr\nλmin\n\u0000E\n\u0002\nx(k)(x(k))T \f\fz(k) = r\n\u0003\u0001\n34\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n−w(k)∗\nr\nλmin\n\u0010\nE\nh\n(1 −γ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k)))x(k)(x(k))T \f\f\fz(k) = r\ni\u0011\n.\nSimilar to (i), it is straightforward to show that\nλmax\n \nE\n\"\nw(k)∗\nr′\nexp{y(k)(x(k))T (θ(k)∗\nr′\n−θ(k)∗\n1\n) −1\n2[((x(k))T θ(k)∗\nr′\n)2 −((x(k))T θ(k)∗\n1\n)2]}\nw(k)∗\nr\n+ P\nr′̸=r w(k)∗\nr′\nexp{y(k)(x(k))T (θ(k)∗\nr′\n−θ(k)∗\n1\n) −1\n2[((x(k))T θ(k)∗\nr′\n)2 −((x(k))T θ(k)∗\n1\n)2]}\nx(k)(x(k))T\n\f\f\f\f\fz(k) = r\n#!\n≲w(k)∗\nr′\nw(k)∗\nr\n1\n∆+\n√log ∆\n∆\n,\nfor any r′ ̸= r. Hence\nλmin\n\u0010\nE\nh\nγ(r)\nθ(k)∗\nr\n,w(k)∗\nr\n(x(k), y(k))x(k)(x(k))T i\u0011\n≥w(k)∗\nr\n−C\nX\nr′̸=r\n\u0012\nw(k)∗\nr′\n1\n∆+ w(k)∗\nr\n√log ∆\n∆\n\u0013\n≥w(k)∗\nr\n−CR\n√log ∆\n∆\n,\nwhich completes the proof of Lemma E.4.\n(II) Part 2: Deriving the rate of κ in Assumption 2.(i).\nSince Assumption A.3 is assumed to hold for all k ∈[K], in this part, for notation simplicity, we drop the task index k in\nthe superscript and write w(k) = {w(k)\nr }R\nr=1, θ(k) = {θ(k)\nr }R\nr=1, w(k)∗= {w(k)∗\nr\n}R\nr=1, θ(k)∗= {θ(k)∗\nr\n}R\nr=1, x(k), and y(k)\nsimply as w = {wr}R\nr=1, θ = {θr}R\nr=1, w∗= {w∗\nr}R\nr=1, θ(k) = {θ∗\nr}R\nr=1, x, and y.\nBy Taylor expansion:\nE\n\u0002\nγ(r)\nθ,w(x, y)−γ(r)\nθ∗,w∗(x, y)\n\u0003\n=\nR\nX\nr′=1\nE\n\"\n∂γ(r)\nθ,w(x, y)\n∂wr′\n\f\f\f\f\nwr′= e\nwr′\n(wr′−w∗\nr′)\n#\n+\nR\nX\nr′=1\nE\n\"\u0012∂γ(r)\nθ,w(x, y)\n∂θr′\n\f\f\f\f\nθr′=eθr′\n\u0013T\n(θr′−θ∗\nr′)\n#\n,\nwhere ewr′ is at the line segment between wr′ and w∗\nr, and eθr′ is at the line segment between θr′ and θ∗\nr. And\n∂γ(r)\nθ,w(x, y)\n∂wr′\n=\n\n\n\nexp{yxT (θr−θ1)−1\n2 [(xT θr)2−(xT θ1)2]}(w1+P\nr′̸=r wr′ exp{yxT (θr′−θ1)−1\n2 [(xT θr′)2−(xT θ1)2]})\n(w1+PR\nr′=1 wr′ exp{yxT (θr′−θ1)−1\n2 [(xT θr′)2−(xT θ1)2]})2\n,\nr′ = r;\n−wr exp{yxT (θr−θ1)−1\n2 [(xT θr)2−(xT θ1)2]}·exp{yxT (θr′−θ1)−1\n2 [(xT θr′)2−(xT θ1)2]}\n(w1+PR\nr′=1 wr′ exp{yxT (θr′−θ1)−1\n2 [(xT θr′)2−(xT θ1)2]})2\n,\nr′ ̸= r.\nWe want to upper bound E\nh ∂γ(r)\nθ,w(x,y)\n∂wr\n\f\f\fz = ˜r\ni\nfor all ˜r. Since in the expression of E\nh ∂γ(r)\nθ,w(x,y)\n∂wr\n\f\f\fz = ˜r\ni\n, {wr′}r′̸=r and\n{θr′}r′̸=r are symmetric, i.e., any class can be the reference class. WLOG, we only show how to bound E\nh ∂γ(r)\nθ,w(x,y)\n∂wr\n\f\f\fz = 1\ni\nand the same arguments can be used to bound E\nh ∂γ(r)\nθ,w(x,y)\n∂wr\n\f\f\fz = ˜r\ni\nfor er ̸= 1.\nDenote (∗) = y(1)xT (θr −θ1) −1\n2[(xT θr)2 −(xT θ1)2], ez = (y(1) −xT θ∗\n1) · xT (θr −θ1)|x ∼N(0, [xT (θr −θ1)]2),\nwhere y(1) d= (y|z = 1). Then\n(∗) = ez + (xT θ∗\n1) · xT (θr −θ1) −1\n2xT (θr + θ1) · xT (θr −θ1),\nwhere\n(xT θ∗\n1) · xT (θr −θ1) −1\n2xT (θr + θ1) · xT (θr −θ1)\n=\n\u0002\nxT (θ∗\nr −θ∗\n1) + xT (θ∗\n1 −θ1 + θr −θ∗\nr)\n\u0003\u0014\n−1\n2xT (θ∗\nr −θ∗\n1) + −1\n2xT (θ∗\n1 −θ1) + 1\n2xT (θ∗\nr −θr)\n\u0015\n= −1\n2[xT (θ∗\nr −θ∗\n1)]2 + 1\n2{xT [(θ∗\n1 −θ1) + (θ∗\nr −θr)]}2.\n35\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nDefine events\nV1 =\n\u001a\n|xT (θ∗\n1 −θ1)| ∨|xT (θ∗\nr −θr)| ≤1\n4|xT (θ∗\nr −θ∗\n1)|\n\u001b\n,\nV2 = {|ez| ≤τ1|xT (θr −θ1)|},\nV3 = {|xT (θ∗\nr −θ∗\n1)| > τ2|θ∗\nr −θ∗\n1|}.\nWe know that\nP(Vc\n1) ≤P\n\u0012\n|xT (θ∗\n1 −θ1)| ∨|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≤P\n\u0012\n|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n+ P\n\u0012\n|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≤4\n\u0012∥θ∗\n1 −θ1∥2\n∥θ∗r −θ∗\n1∥2\n+ ∥θ∗\nr −θr∥2\n∥θ∗r −θ∗\n1∥2\n\u0013\n≤8Cb,\nwhere we applied Lemma A.1 in Kwon & Caramanis (2020b) to get the second last inequality. And\nP(Vc\n2) ≤C exp{−C′τ 2\n1 },\nP(Vc\n3) ≤Cτ2.\nGiven V1 ∩V2 ∩V3, we have\n−1\n2[xT (θ∗\nr −θ∗\n1)]2 + 1\n2{xT [(θ∗\n1 −θ1) + (θ∗\nr −θr)]}2 ≤−3\n8[xT (θ∗\nr −θ∗\n1)]2,\nleading to\nez ≤τ1|xT (θr −θ1)| ≤τ1(|xT (θ∗\nr −θ∗\n1)| + |xT (θr −θ∗\nr)| + |xT (θ1 −θ∗\n1)|) ≤τ1 · 3\n2|xT (θ∗\nr −θ∗\n1)|.\nHence\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f ≤\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n\f\f\f\fz = 1, V1 ∩V2 ∩V3\n\u0015\nP(V1 ∩V2 ∩V3)\n\f\f\f\f\f + R\ncw\n[P(Vc\n1) + P(Vc\n2) + P(Vc\n3)]\n≤R\ncw\nexp\n\u001a3\n2τ1|xT (θ∗\nr −θ∗\n1)| −3\n8[xT (θ∗\nr −θ∗\n1)]2\n\u001b\n+ C R\ncw\n\u0000Cb + exp{−C′τ 2\n1 } + τ2\n\u0001\n≤R\ncw\nexp\n\u001a3\n2τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ 2\n2 ∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n+ C R\ncw\n\u0000Cb + exp{−C′τ 2\n1 } + τ2\n\u0001\n,\nwhere the last inequality requires |xT (θ∗\nr −θ∗\n1)| ≥τ2∥θ∗\nr −θ∗\n1∥2 ≥2τ1. Let τ1 = c\np\nlog ∥θ∗r −θ∗\n1∥2 and τ2 =\n10c\n√\nlog ∥θ∗\nr −θ∗\n1∥2\n∥θ∗r −θ∗\n1∥2\nwith some constant c > 0, then\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f ≲R\ncw\n\u0012\nCb +\np\nlog ∥θ∗r −θ∗\n1∥2\n∥θ∗r −θ∗\n1∥2\n\u0013\n≲R\ncw\n\u0012\nCb +\n√log ∆\n∆\n\u0013\n.\nSimilarly,\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr′\n\f\f\f\fz = er\n\u0015\f\f\f\f\f ≲R\ncw\n\u0012\nCb +\n√log ∆\n∆\n\u0013\n,\nfor any r, r′, and er. Therefore,\nR\nX\nr′=1\nE\n\"\n∂γ(r)\nθ,w(x, y)\n∂wr′\n\f\f\f\f\nwr′= e\nwr′\n(wr′ −w∗\nr′)\n#\n≤C R\ncw\n\u0012\nCb +\n√log ∆\n∆\n\u0013\nR\nX\nr=1\n|wr −w∗\nr|.\n36\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nOn the other hand,\n∂γ(r)\nw,θ(x, y)\n∂θr′\n=\n(\nγ(r)\nw,θ(x, y)x(y −xT θr) −\n\u0000γ(r)\nw,θ(x, y)\n\u00012x(y −xT θr),\nr′ = r;\n−γ(r)\nw,θ(x, y)γ(r′)\nw,θ(x, y)x(y −xT θr′),\nr′ ̸= r,\n(14)\nwhere\nγ(r)\nw,θ(x, y) =\nwr exp{yxT (θr −θ1) −1\n2[(xT θr)2 −(xT θ1)2]}\nw1 + PR\nr′=2 wr′ exp{yxT (θr′ −θ1) −1\n2[(xT θr′)2 −(xT θ1)2]}\n,\nWe will show how to upper bound E[γ(r)\nw,θ(x, y)(y −xT θr) · xT (θr −θ′\nr)], and the same arguments can be used to bound\nE[(γ(r)\nw,θ(x, y))2(y −xT θr) · xT (θr −θ′\nr)]. Then we will have an upper bound for E\nh\u0000 ∂γ(r)\nθ,w(x,y)\n∂θr\n\f\f\nθr=eθr\n\u0001T (θr −θ′\nr)\ni\n,\nand the analysis is the same for E\nh\u0000 ∂γ(r)\nθ,w(x,y)\n∂θr′\n\f\f\nθr′=eθr′\n\u0001T (θr′ −θ∗\nr′)\ni\nwith r′ ̸= r.\nLet us start from E[γ(r)\nw,θ(x, y)(y −xT θr) · xT (θr −θ′\nr)|z = 1]. Consider y(1) d= (y|z = 1) and\ny(1) −xT θr = (y(1) −xT θ∗\n1) + xT (θ∗\n1 −θ∗\nr) + xT (θ∗\nr −θr).\nDefine events\nV1 =\n\u001a\n|xT (θ∗\n1 −θ1)| ∨|xT (θ∗\nr −θr)| ≤1\n4|xT (θ∗\nr −θ∗\n1)|\n\u001b\n,\nV2 = {|y(1) −xT θ∗\n1| ≤τ1},\nV3 = {|xT (θ∗\nr −θ∗\n1)| > τ2|θ∗\nr −θ∗\n1|}.\nWe know that\nP(Vc\n1) ≤P\n\u0012\n|xT (θ∗\n1 −θ1)| ∨|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≤P\n\u0012\n|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n+ P\n\u0012\n|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≤4\n\u0012∥θ∗\n1 −θ1∥2\n∥θ∗r −θ∗\n1∥2\n+ ∥θ∗\nr −θr∥2\n∥θ∗r −θ∗\n1∥2\n\u0013\n≤8Cb,\nwhere we applied Lemma A.1 in Kwon & Caramanis (2020b) to get the second last inequality. And\nP(Vc\n2) ≤C exp{−C′τ 2\n1 },\nP(Vc\n3) ≤Cτ2.\nNote that\nE\n\u0002\nγ(r)\nw,θ(x, y)(y −xT θr) · xT (θr −θ′\nr)|z = 1\n\u0003\n≤E\n\u0002\nγ(r)\nw,θ(x, y)(y −xT θr) · xT (θr −θ′\nr)|z = 1, V1 ∩V2 ∩V3\n\u0003\nP(V1 ∩V2 ∩V3)\n|\n{z\n}\n[1]\n+ E\n\u0002\nxT (θr −θ′\nr)(y(1) −xT θr)1(Vc\n1 ∪Vc\n2 ∪Vc\n3)\n\u0003\n|\n{z\n}\n[2]\n.\n(a) Case 1: maxr ∥θr −θ∗\nr∥2 ≤1.\nNote that for term [2], by Lemma A.1 in Kwon & Caramanis (2020b),\nE\n\u0002\nxT (θr −θ′\nr)(y(1) −xT θ∗\n1)1(Vc\n1)\n\u0003\n37\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≤E\n\u0014\nxT (θr −θ′\nr)(y(1) −xT θ∗\n1)1(Vc\n1)\n\f\f\f\f|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0015\nP\n\u0012\n|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n+ E\n\u0014\nxT (θr −θ′\nr)(y(1) −xT θ∗\n1)1(Vc\n1)\n\f\f\f\f|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0015\nP\n\u0012\n|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≤\ns\nE\n\u0014\n(xT (θr −θ′r))2\n\f\f\f\f|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗r −θ∗\n1)|\n\u0015\n·\nq\nE(y(1) −xT θ∗\n1)2\n· P\n\u0012\n|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n+\ns\nE\n\u0014\n(xT (θr −θ′r))2\n\f\f\f\f|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗r −θ∗\n1)|\n\u0015\n·\nq\nE(y(1) −xT θ∗\n1)2\n· P\n\u0012\n|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≲Cb∥θr −θ′\nr∥2.\nAnd by Cauchy-Schwarz inequality,\nE\n\u0002\nxT (θr −θ′\nr)(y(1) −xT θ∗\n1)1(Vc\n2)\n\u0003\n≤\nq\nE\n\u0002\n(xT (θr −θ′r))2(y(1) −xT θ∗\n1)2\u0003q\nP(Vc\n2) ≲∥θr −θ′\nr∥2 · exp{−Cτ 2\n1 },\nE\n\u0002\nxT (θr −θ′\nr)(y(1) −xT θ∗\n1)1(Vc\n3)\n\u0003\n≤\nq\nE\n\u0002\n(xT (θr −θ′r))2\u0003\n· P(Vc\n2)\nq\nE\n\u0002\n(y(1) −xT θ∗\n1)2\u0003\n· P(Vc\n2) ≲∥θr −θ′\nr∥2 · τ2.\nCombine them together:\nE\n\u0002\nxT (θr −θ′\nr)(y(1) −xT θ∗\n1)1(Vc\n1 ∪Vc\n2 ∪Vc\n3)\n\u0003\n≲(Cb + exp{−Cτ 2\n1 } + τ2)∥θr −θ′\nr∥2.\nFurthermore,\nE\n\u0002\nxT (θr −θ′\nr) · xT (θ∗\n1 −θ∗\nr)1(Vc\n1)\n\u0003\n≤\nq\nE\n\u0002\n(xT (θr −θ′r))2|Vc\n1\n\u0003\n· P(Vc\n1) ·\nq\nE\n\u0002\n(xT (θ∗\n1 −θ∗r))2|Vc\n1\n\u0003\n· P(Vc\n1)\n≲∥θr −θ′\nr∥2 · Cb ·\nq\nE\n\u0002\n|xT (θ∗\n1 −θ1)|2 ∨|xT (θ∗r −θr)|2|Vc\n1\n\u0003\n≲Cb∥θr −θ′\nr∥2,\nand\nE\n\u0002\nxT (θr −θ′\nr) · xT (θ∗\n1 −θ∗\nr)1(Vc\n2)\n\u0003\n≲exp{−Cτ 2\n1 } · ∥θ∗\n1 −θ∗\nr∥2 · ∥θr −θ′\nr∥2,\nE\n\u0002\nxT (θr −θ′\nr) · xT (θ∗\n1 −θ∗\nr)1(Vc\n3)\n\u0003\n≲\nq\nE\n\u0002\n(xT (θr −θ′r))2|Vc\n3\n\u0003\n· P(Vc\n3) ·\nq\nE\n\u0002\n(xT (θ∗\n1 −θ∗r))2|Vc\n3\n\u0003\n· P(Vc\n3)\n≲τ 2\n2 ∥θr −θ′\nr∥2 · ∥θ∗\n1 −θ∗\nr∥2.\nTherefore\nE\n\u0002\nxT (θr −θ′\nr) · xT (θ∗\n1 −θ∗\nr)1(Vc\n1 ∪Vc\n2 ∪Vc\n3)\n\u0003\n≲(Cb + exp{−Cτ 2\n1 } + τ 2\n2 ∥θ∗\n1 −θ∗\nr∥2)∥θr −θ′\nr∥2.\nSimilarly,\nE\n\u0002\nxT (θr −θ′\nr) · xT (θ∗\nr −θr)1(Vc\n1 ∪Vc\n2 ∪Vc\n3)\n\u0003\n≲(Cb + exp{−Cτ 2\n1 } + τ 2\n2 ∥θ∗\nr −θr∥2)∥θr −θ′\nr∥2\n≲(Cb + exp{−Cτ 2\n1 } + τ 2\n2 )∥θr −θ′\nr∥2.\nTherefore we have\n[2] ≲(Cb + exp{−Cτ 2\n1 } + τ2 + τ 2\n2 ∥θ∗\n1 −θ∗\nr∥2)∥θr −θ′\nr∥2.\nFor [1], given V1 ∩V2 ∩V3, we know that\n−1\n2[xT (θ∗\nr −θ∗\n1)]2 + 1\n2{xT [(θ∗\n1 −θ1) + (θ∗\nr −θr)]}2 ≤−3\n8[xT (θ∗\nr −θ∗\n1)]2,\n38\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nleading to (y(1) −xT θ∗\n1) + xT (θ∗\n1 −θ∗\nr)\n(y(1)−xT θ∗\n1)·xT (θr−θ1) ≤τ1|xT (θr−θ1)| ≤τ1(|xT (θ∗\nr −θ∗\n1)|+|xT (θr−θ∗\nr)|+|xT (θ1−θ∗\n1)|) ≤τ1· 3\n2|xT (θ∗\nr −θ∗\n1)|.\nSimilar to the previous analysis, we can show that\n[1] ≲R\ncw\nexp\n\u001a3\n2τ1|xT (θ∗\nr −θ∗\n1)| −3\n8|xT (θ∗\nr −θ∗\n1)|2\n\u001b\n(τ1 + 1) · ∥θr −θ′\nr∥2\n≲R\ncw\nexp\n\u001a3\n2τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ 2\n2 ∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n(τ1 + 1) · ∥θr −θ′\nr∥2.\nThis implies that\nE\n\u0002\nγ(r)\nw,θ(x, y)(y −xT θr) · xT (θr −θ′\nr)|z = 1\n\u0003\n≤[1] + [2]\n≲\n\"\nR\ncw\nexp\n\u001a3\n2τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ 2\n2 ∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n(τ1 + 1) + Cb + exp{−Cτ 2\n1 } + τ2 + τ 2\n2 ∥θ∗\n1 −θ∗\nr∥2\n#\n· ∥θr −θ′\nr∥2.\n(15)\nLet τ1 = c\np\nlog ∥θ∗r −θ∗\n1∥2 and τ2 = 10c\n√\nlog ∥θ∗r −θ∗\n1∥2\n∥θ∗r −θ∗\n1∥2\nwith some constant c > 0. Then\nRHS of (15) ≲\n\u0012 R\ncw\n1\n∆\np\nlog ∆+ R\ncw\nCb\n\u0013\n∥θr −θ′\nr∥2.\nSimilarly, we can show that E\n\u0002\nγ(r)\nw,θ(x, y)(y −xT θr) · xT (θr −θ′\nr)|z = r′\u0003\nhas the same upper bound. Therefore\nE\n\u0002\nγ(r)\nw,θ(x, y)(y −xT θr) · xT (θr −θ′\nr)\n\u0003\n≲\n\u0012 R\ncw\n1\n∆\np\nlog ∆+ R\ncw\nCb\n\u0013\n∥θr −θ′\nr∥2.\nSimilarly, following the same arguments, it can be shown that\nE\n\u0002\n(γ(r)\nw,θ(x, y))2(y −xT θr) · xT (θr −θ′\nr)\n\u0003\n≲\n\u0012 R\ncw\n1\n∆\np\nlog ∆+ R\ncw\nCb\n\u0013\n∥θr −θ′\nr∥2.\nHence by (14),\n\f\f\f\f\fE\n\u0014\u0012∂γ(r)\nθ,w(x, y)\n∂θr\n\f\f\nθr=eθr\n\u0013T\n(θr −θ∗\nr)\n\u0015\f\f\f\f\f ≲\n\u0012 R\ncw\n1\n∆\np\nlog ∆+ R\ncw\nCb\n\u0013\n∥θr −θ′\nr∥2.\n(b) Case 2: maxr ∥θr −θ∗\nr∥2 > 1.\nSuppose r0 ∈[R] satisfies ∥θr0 −θ∗\nr0∥2 > 1. For r′ ̸= r, we have\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\f\fz = r′\u0003\f\f ≤\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)\n\f\fz = r′\u0003\f\f +\n\f\fE\n\u0002\nγ(r)\nw∗,θ∗(x, y)\n\f\fz = r′\u0003\f\f.\nWLOG, let us consider the case r′ = 1 ̸= r, and the other cases can be similarly discussed. We have\nE\n\u0002\nγ(r)\nw,θ(x, y)\n\f\fz = 1\n\u0003\n= E\n\"\nwr exp{yxT (θr −θ1) −1\n2[(xT θr)2 −(xT θ1)2]}\nw1 + PR\nr′=2 wr′ exp{yxT (θr′ −θ1) −1\n2[(xT θr′)2 −(xT θ1)2]}\n#\n.\nRecall that\nV1 =\n\u001a\n|xT (θ∗\n1 −θ1)| ∨|xT (θ∗\nr −θr)| ≤1\n4|xT (θ∗\nr −θ∗\n1)|\n\u001b\n,\n39\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nV2 = {|y(1) −xT θ∗\n1| ≤τ1},\nV3 = {|xT (θ∗\nr −θ∗\n1)| > τ2|θ∗\nr −θ∗\n1|}.\nand\nP(Vc\n1) ≤8Cb,\nP(Vc\n2) ≤C exp{−C′τ 2\n1 },\nP(Vc\n3) ≤Cτ2.\nSimilar to the previous analysis,\ny(1)xT (θr−θ1)−1\n2[(xT θr)2−(xT θ1)2] = (y(1)−xT θ∗\n1)xT (θr−θ1)+(xT θ∗\n1)·xT (θr−θ1)−1\n2xT (θr+θ1)·xT (θr−θ1).\nConditioned on V1 ∩V2 ∩V3,\n(xT θ∗\n1) · xT (θr −θ1) −1\n2xT (θr + θ1) · xT (θr −θ1)\n=\n\u0002\nxT (θ∗\nr −θ∗\n1) + xT (θ∗\n1 −θ1 + θr −θ∗\nr)\n\u0003\u0014\n−1\n2xT (θ∗\nr −θ∗\n1) + −1\n2xT (θ∗\n1 −θ1) + 1\n2xT (θ∗\nr −θr)\n\u0015\n= −1\n2[xT (θ∗\nr −θ∗\n1)]2 + 1\n2{xT [(θ∗\n1 −θ1) + (θ∗\nr −θr)]}2\n≤−3\n8[xT (θ∗\nr −θ∗\n1)]2,\nand\n|(y(1) −xT θ∗\n1)xT (θr −θ1)| ≤1\n4τ1|xT (θ∗\nr −θ∗\n1)|,\nhence\nE\n\u0002\nγ(r)\nw,θ(x, y)\n\f\fz = 1, V1 ∩V2 ∩V3\n\u0003\n≤wr\nw1\nE\n\u0014\nexp\n\u001a1\n4τ1|xT (θ∗\nr −θ∗\n1)| −3\n8|xT (θ∗\nr −θ∗\n1)|2\n\u001b\u0015\n≲R\ncw\nexp\n\u001a1\n4τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ2∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n.\nTherefore,\nE\n\u0002\nγ(r)\nw,θ(x, y)\n\f\fz = 1\n\u0003\n≲R\ncw\nexp\n\u001a1\n4τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ2∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n+ P(Vc\n1) + P(Vc\n2) + P(Vc\n3)\n≲R\ncw\nexp\n\u001a1\n4τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ2∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n+ Cb + exp{−Cτ 2\n1 } + τ2.\nLet τ1 = c\np\nlog ∥θ∗r −θ∗\n1∥2 and τ2 = 10c\n√\nlog ∥θ∗r −θ∗\n1∥2\n∥θ∗r −θ∗\n1∥2\nwith some constant c > 0. Then\nE\n\u0002\nγ(r)\nw,θ(x, y)\n\f\fz = 1\n\u0003\n≲R\ncw\n1\n∆+ Cb + 1\n∆+\n√log ∆\n∆\n≲R\ncw\n1\n∆+ Cb +\n√log ∆\n∆\n.\nSimilarly, we can show the same bound for E[γ(r)\nw∗,θ∗(x, y)|z = 1]. Then\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\f\fz = 1\n\u0003\f\f ≲R\ncw\n1\n∆+ Cb +\n√log ∆\n∆\n,\nand the same bound holds for\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\f\fz = r′\u0003\f\f for any r′ ̸= r. On the other hand,\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\f\fz = r\n\u0003\f\f ≤\nX\nr′̸=r\n\f\fE\n\u0002\nγ(r′)\nw,θ(x, y) −γ(r′)\nw∗,θ∗(x, y)\n\f\fz = r\n\u0003\f\f ≲R2\ncw\n1\n∆+ RCb + R\n√log ∆\n∆\n.\nTherefore,\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0003\f\f ≤\nR\nX\nr′=1\nw∗\nr′\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\f\fz = r′\u0003\f\f\n40\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≲R2\ncw\n1\n∆+ RCb + R\n√log ∆\n∆\n≲\n\u0012R2\ncw\n1\n∆+ RCb + R\n√log ∆\n∆\n\u0013\n· ∥θr0 −θ∗\nr0∥2,\nwhere the last inequality comes from the fact that ∥θr0 −θ∗\nr0∥2 > 1.\nCombining two cases entails Assumption A.3.(i) with κ ≍R\ncw\n√log ∆\n∆\n+ R\ncw Cb + R2\ncw\n1\n∆.\n(III) Part 3: Deriving the rate of γ in Assumption A.5.(i).\nSimilar to Part 2, for notation simplicity, we drop the task index k in the superscript and write w(k) = {w(k)\nr }R\nr=1,\nθ(k) = {θ(k)\nr }R\nr=1, w(k)∗= {w(k)∗\nr\n}R\nr=1, θ(k)∗= {θ(k)∗\nr\n}R\nr=1, x(k), y(k), Q(k), and q(k) simply as w(k) = {w(k)\nr }R\nr=1,\nθ = {θr}R\nr=1, w = {w∗\nr}R\nr=1, θ(k) = {θ∗\nr}R\nr=1, x, y, Q, and q.\nNote that ∂Q(k)\n∂θr (θ|w′, θ′) = −E[γ(r)\nw′,θ′(x, y)x(xT θr −y)], which implies that\n\r\r\r\r\n∂Q\n∂θr\n(θ|w, θ) −∂q\n∂θr\n(θ)\n\r\r\r\r\n2\n=\n\r\r\r\rE\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\nx(xT θr −y)\n\u0003\r\r\r\r\n2\n(a) Case 1: maxr ∥θr −θ∗\nr∥2 ≤1.\nWLOG, let us consider E\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\nx(xT θr −y)\n\f\fz = 1\n\u0003\nwith r ̸= 1. For any u ∈Sd−1,\n\f\fE\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\nxT u · (xT θr −y)\n\f\fz = 1\n\u0003\f\f\n≤\n\f\fE\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\nxT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f\n|\n{z\n}\n[1]\n+\n\f\fE\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\nxT u · xT (θr −θ∗\nr)\n\f\fz = 1\n\u0003\f\f\n|\n{z\n}\n[2]\n+\n\f\fE\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\nxT u · (y −xT θ∗\n1)\n\f\fz = 1\n\u0003\f\f\n|\n{z\n}\n[3]\n.\n(16)\nFirst,\n[1] ≤\nR\nX\nr′=1\n\f\f\f\fE\n\u0014∂γ(r)(x, y)\n∂wr′\n(wr′ −w∗\nr′)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\n+\nR\nX\nr′=1\n\f\f\f\fE\n\u0014\u0012∂γ(r)(x, y)\n∂θr′\n\u0013T\n(θr′ −θ∗\nr′)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f.\n(17)\nRecall that\n∂γ(r)(x, y)\n∂wr\n=\nexp{yxT (θr −θ1) −1\n2[(xT θr)2 −(xT θ1)2]}(w1 + P\nr′̸=r wr′ exp{yxT (θr′ −θ1) −1\n2[(xT θr′)2 −(xT θ1)2]})\n(w1 + PR\nr′=1 wr′ exp{yxT (θr′ −θ1) −1\n2[(xT θr′)2 −(xT θ1)2]})2\n.\nDenote (∗) = y(1)xT (θr −θ1) −1\n2[(xT θr)2 −(xT θ1)2], ez = (y(1) −xT θ∗\n1) · xT (θr −θ1)|x ∼N(0, [xT (θr −θ1)]2),\nwhere y(1) d= (y|z = 1). Then\n(∗) = ez + (xT θ∗\n1) · xT (θr −θ1) −1\n2xT (θr + θ1) · xT (θr −θ1),\n41\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nwhere\n(xT θ∗\n1) · xT (θr −θ1) −1\n2xT (θr + θ1) · xT (θr −θ1)\n=\n\u0002\nxT (θ∗\nr −θ∗\n1) + xT (θ∗\n1 −θ1 + θr −θ∗\nr)\n\u0003\u0014\n−1\n2xT (θ∗\nr −θ∗\n1) + −1\n2xT (θ∗\n1 −θ1) + 1\n2xT (θ∗\nr −θr)\n\u0015\n= −1\n2[xT (θ∗\nr −θ∗\n1)]2 + 1\n2{xT [(θ∗\n1 −θ1) + (θ∗\nr −θr)]}2.\nDefine events\nV1 =\n\u001a\n|xT (θ∗\n1 −θ1)| ∨|xT (θ∗\nr −θr)| ≤1\n4|xT (θ∗\nr −θ∗\n1)|\n\u001b\n,\nV2 = {|ez| ≤τ1|xT (θr −θ1)|},\nV3 = {|xT (θ∗\nr −θ∗\n1)| > τ2|θ∗\nr −θ∗\n1|}.\nWe know that\nP(Vc\n1) ≤P\n\u0012\n|xT (θ∗\n1 −θ1)| ∨|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≤P\n\u0012\n|xT (θ∗\n1 −θ1)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n+ P\n\u0012\n|xT (θ∗\nr −θr)| > 1\n4|xT (θ∗\nr −θ∗\n1)|\n\u0013\n≤4\n\u0012∥θ∗\n1 −θ1∥2\n∥θ∗r −θ∗\n1∥2\n+ ∥θ∗\nr −θr∥2\n∥θ∗r −θ∗\n1∥2\n\u0013\n≤8Cb,\nwhere we applied Lemma A.1 in Kwon & Caramanis (2020b) to get the second last inequality. And\nP(Vc\n2) ≤C exp{−C′τ 2\n1 },\nP(Vc\n3) ≤Cτ2.\nGiven V1 ∩V2 ∩V3, we have\n−1\n2[xT (θ∗\nr −θ∗\n1)]2 + 1\n2{xT [(θ∗\n1 −θ1) + (θ∗\nr −θr)]}2 ≤−3\n8[xT (θ∗\nr −θ∗\n1)]2,\nleading to\nez ≤τ1|xT (θr −θ1)| ≤τ1(|xT (θ∗\nr −θ∗\n1)| + |xT (θr −θ∗\nr)| + |xT (θ1 −θ∗\n1)|) ≤τ1 · 3\n2|xT (θ∗\nr −θ∗\n1)|.\nHence\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f\n≤\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1, V1 ∩V2 ∩V3\n\u0015\nP(V1 ∩V2 ∩V3)\n\f\f\f\f\f\n+\n3\nX\nj=1\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1) · 1(Vc\nj )\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f.\nNote that\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1, V1 ∩V2 ∩V3\n\u0015\f\f\f\f\f\n≲R\ncw\nexp\n\u001a3\n2τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ 2\n2 ∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n· ∥θ∗\nr −θ∗\n1∥2 · |wr −w∗\nr|.\n42\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nAlso,\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1) · 1(Vc\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f\n≤R\ncw\nq\nE[(xT u)2|Vc\n1]P(Vc\n1)\nq\nE[(xT (θ∗r −θ∗\n1))2|Vc\n1]P(Vc\n1) · |wr −w∗\nr|\n≲R\ncw\nq\nE[(xT (θr −θ∗r))2|Vc\n1] + E[(xT (θ1 −θ∗\n1))2|Vc\n1] · P(Vc\n1) · |wr −w∗\nr|\n≲R\ncw\nCb|wr −w∗\nr|.\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1) · 1(Vc\n2)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f ≲exp{−Cτ 2\n1 } · ∥θ∗\nr −θ∗\n1∥2 · |wr −w∗\nr|.\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1) · 1(Vc\n3)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f\n≤R\ncw\nq\nE[(xT u)2|Vc\n3]P(Vc\n3)\nq\nE[(xT (θ∗r −θ∗\n1))2|Vc\n3]P(Vc\n3) · |wr −w∗\nr|\n≲R\ncw\nτ 2\n2 · ∥θ∗\nr −θ∗\n1∥2 · |wr −w∗\nr|.\nLet τ1 = c\np\nlog ∥θ∗r −θ∗\n1∥2 and τ2 = 10c\n√\nlog ∥θ∗r −θ∗\n1∥2\n∥θ∗r −θ∗\n1∥2\nwith some constant c > 0, then\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr\n(wr −w∗\nr)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f ≲\n\u0012 R\ncw\n1\n∆+ R\ncw\nCb + 1\n∆+ R\nCw\nlog ∆\n∆\n\u0013\n· |wr −w∗\nr|\n≲\n\u0012 R\ncw\nCb + R\nCw\nlog ∆\n∆\n\u0013\n· |wr −w∗\nr|.\nSimilarly, we can show that\n\f\f\f\f\fE\n\u0014∂γ(r)\nθ,w(x, y)\n∂wr′\n(wr′ −w∗\nr′)xT u · xT (θ∗\nr′ −θ∗\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\f ≲\n\u0012 R\ncw\nCb + R\nCw\nlog ∆\n∆\n\u0013\n· |wr′ −w∗\nr′|,\nfor r′ ̸= r.\nOn the other hand, recall that\n∂γ(r)\nw,θ(x, y)\n∂θr\n= γ(r)\nw,θ(x, y)x(y −xT θr) −\n\u0000γ(r)\nw,θ(x, y)\n\u00012x(y −xT θr),\nwhere\nγ(r)\nw,θ(x, y) =\nwr exp{yxT (θr −θ1) −1\n2[(xT θr)2 −(xT θ1)2]}\nw1 + PR\nr′=2 wr′ exp{yxT (θr′ −θ1) −1\n2[(xT θr′)2 −(xT θ1)2]}\n.\nWe have\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · (y(1) −xT θr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f\n≤\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · (y(1) −xT θ∗\n1) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f\n+\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · xT (θ∗\n1 −θ∗\nr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f\n+\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · xT (θ∗\nr −θr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f.\n43\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nSimilar to the previous analysis,\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · (y(1) −xT θ∗\n1) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f\n≤\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · (y(1) −xT θ∗\n1) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1, V1 ∩V2 ∩V3\n\u0003\f\f\n+\n3\nX\nj=1\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · (y(1) −xT θ∗\n1) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1, Vc\nj\n\u0003\f\f · P(Vc\nj )\n≲R\ncw\nexp\n\u001a3\n2τ1τ2∥θ∗\nr −θ∗\n1∥2 −3\n8τ2∥θ∗\nr −θ∗\n1∥2\n2\n\u001b\n∥θ∗\nr −θ∗\n1∥2 · ∥θr −θ∗\nr∥2\n+ R\ncw\nCb + exp{−Cτ 2\n1 } · ∥θ∗\nr −θ∗\n1∥2 · ∥θr −θ∗\nr∥2 + R\ncw\nτ 2\n2 ∥θ∗\nr −θ∗\n1∥2 · ∥θr −θ∗\nr∥2.\nLet τ1 = c\np\nlog ∥θ∗r −θ∗\n1∥2 and τ2 = 10c\n√\nlog ∥θ∗r −θ∗\n1∥2\n∥θ∗r −θ∗\n1∥2\nwith some constant c > 0, then\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · (y(1) −xT θ∗\n1) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f ≲\n\u0012 R\ncw\nlog ∆\n∆\n+ R\ncw\nCb\n\u0013\n· ∥θr −θ∗\nr∥2.\nSimilarly,\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · xT (θ∗\n1 −θ∗\nr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f ≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n· ∥θr −θ∗\nr∥2,\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · xT (θ∗\nr −θr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f ≲\n\u0012 R\ncw\nlog ∆\n∆\n+ R\ncw\nCb\n\u0013\n· ∥θr −θ∗\nr∥2.\nHence,\n\f\fE\n\u0002\nγ(r)\nw,θ(x, y)xT (θr −θ∗\nr) · (y(1) −xT θr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f ≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n· ∥θr −θ∗\nr∥2.\nSimilarly,\n\f\fE\n\u0002\n(γ(r)\nw,θ(x, y))2xT (θr −θ∗\nr) · (y(1) −xT θr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0003\f\f ≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n· ∥θr −θ∗\nr∥2.\nTherefore,\n\f\f\f\fE\n\u0014\u0012∂γ(r)\nw,θ(x, y)\n∂θr\n\u0013T\n(θr −θ∗\nr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0015\f\f\f\f ≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n· ∥θr −θ∗\nr∥2.\nSimilarly,\n\f\f\f\fE\n\u0014\u0012∂γ(r)\nw,θ(x, y)\n∂θr′\n\u0013T\n(θr −θ∗\nr) · xT u · xT (θ∗\nr −θ∗\n1)\n\f\fz = 1\n\u0015\f\f\f\f ≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n· ∥θr −θ∗\nr∥2,\nfor r′ ̸= r. Recall (16) and (17),\n[1] ≤\nR\nX\nr′=1\n\f\f\f\fE\n\u0014∂γ(r)(x, y)\n∂wr′\n(wr′ −w∗\nr′)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\n+\nR\nX\nr′=1\n\f\f\f\fE\n\u0014\u0012∂γ(r)(x, y)\n∂θr′\n\u0013T\n(θr′ −θ∗\nr′)xT u · xT (θ∗\nr −θ∗\n1)\n\f\f\f\fz = 1\n\u0015\f\f\f\f\n≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n·\nR\nX\nr′=1\n(|wr′ −w∗\nr′| + ∥θr′ −θ∗\nr′∥2).\n44\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nSimilarly, the same bound holds for terms [2] and [3] in (16) as well, therefore\n\f\fE\n\u0002\u0000γ(r)\nw,θ(x, y)−γ(r)\nw∗,θ∗(x, y)\n\u0001\nxT u·(xT θr−y)\n\f\fz = 1\n\u0003\f\f ≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n·\nR\nX\nr′=1\n(|wr′ −w∗\nr′|+∥θr′ −θ∗\nr′∥2).\nWith similar arguments, we have\n\f\fE\n\u0002\u0000γ(r)\nw,θ(x, y)−γ(r)\nw∗,θ∗(x, y)\n\u0001\nxT u·(xT θr−y)\n\f\fz = ˜r\n\u0003\f\f ≲\n\u0014 R\ncw\n(log ∆)3/2\n∆\n+ R\ncw\nCb\n\u0015\n·\nR\nX\nr′=1\n(|wr′ −w∗\nr′|+∥θr′ −θ∗\nr′∥2),\nfor ˜r ̸= 1. Therefore,\n\r\r\r\r\n∂Q\n∂θr\n(θ|w, θ) −∂q\n∂θr\n(θ)\n\r\r\r\r\n2\n=\n\r\r\r\rE\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\nx(xT θr −y)\n\u0003\r\r\r\r\n2\n=\nsup\n∥u∥2≤1\nR\nX\nr′=1\nE\n\u0002\u0000γ(r)\nw,θ(x, y) −γ(r)\nw∗,θ∗(x, y)\n\u0001\n(xT u)(xT θr −y)\n\f\fz = r′\u0003\n· P(z = r′)\n≤\n\u0014\nC R\ncw\n(log ∆)3/2\n∆\n+ C R\ncw\nCb\n\u0015\n·\nR\nX\nr′=1\n(|wr′ −w∗\nr′| + ∥θr′ −θ∗\nr′∥2).\n(b) Case 2: maxr ∥θr −θ∗\nr∥2 > 1.\nSimilar to case 2 of Part 2, it can be shown that\n\r\r\r\r\n∂Q\n∂θr\n(θ|w, θ) −∂q\n∂θr\n(θ)\n\r\r\r\r\n2\n≤\n\u0014\nC R2\ncw\n+ C R\ncw\n(log ∆)3/2\n∆\n+ C R\ncw\nCb\n\u0015\n·\nR\nX\nr′=1\n(|wr′ −w∗\nr′| + ∥θr′ −θ∗\nr′∥2).\nTherefore γ ≍R2\ncw + R\ncw\n(log ∆)3/2\n∆\n+ R\ncw Cb in Assumption A.5.(i).\n(IV) Part 4: Deriving the rate of W in Assumption A.3.(ii). Let\nV =\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nP(z(k) = r|x(k)\ni\n, y(k)\ni\n; w, θ) −Ex(k)\n\u0002\nP(z(k) = r|x(k), y(k); w, θ)\n\u0003\f\f\f\f\n=\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n, y(k)\ni\n) −E\n\u0002\nγ(r)\nθ,w(x(k), y(k))\n\u0003\f\f\f\f.\nBy bounded difference inequality (Corollary 2.21 in Wainwright (2019)), w.p. at least 1 −δ,\nV ≤EV +\nr\nlog(1/δ)\nn\n.\nAnd by classical symmetrization arguments (e.g., see Proposition 4.11 in Wainwright (2019)),\nEV ≤2\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\ni\nγ(k)\nθ,w(x(k)\ni\n, y(k)\ni\n)\n\f\f\f\f.\nLet g(k)\nir = (θr −θ1)T x(k)\ni\n· y(k)\ni\n−1\n2[((x(k)\ni\n)T θr)2 −((x(k)\ni\n)T θ1)2] + log wr −log w1, φ(x) =\nexp{xr}\n1+PR\nr=2 exp{xr}, where\nφ is 1-Lipschitz (w.r.t. ℓ2-norm) and γ(r)\nθ,w(x, y) = φ({g(k)\nir }R\nr=2). Then by Lemma E.3,\n2\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\ni\nγ(k)\nθ,w(x(k)\ni\n, y(k)\ni\n))\n\f\f\f\f\n45\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≲1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nR\nX\nr=2\nϵ(k)\nir g(k)\nir\n\f\f\f\f\n≲1\nn\nR\nX\nr=2\nEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir g(k)\nir\n\f\f\f\f\n≲\nR\nX\nr=2\n(\n1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θr −θ1)T x(k)\ni\n· y(k)\ni\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir [((x(k)\ni\n)T θr)2 −((x(k)\ni\n)T θ1)2]\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (log wr −log w1)\n\f\f\f\f\n)\n≲\nR\nX\nr=2\n(\n1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θr −θ(k)∗\nr\n)T x(k)\ni\n· y(k)\ni\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θ1 −θ(k)∗\n1\n)T x(k)\ni\n· y(k)\ni\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θ(k)∗\nr\n−θ(k)∗\n1\n)T x(k)\ni\n· y(k)\ni\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θr + θ1)T x(k)\ni\n· (θr −θ1)T x(k)\ni\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤ξ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (log wr −log w1)\n\f\f\f\f\n)\n≲RMξ\nr\nd\nn + [RM 2 + R log(Rc−1\nw )]\nr\n1\nn,\nwhich implies\nV ≲RMξ\nr\nd\nn + [RM 2 + R log(Rc−1\nw )]\nr\n1\nn +\nr\nlog(1/δ)\nn\n≍W(n, δ, ξ).\nw.p. at least 1 −δ.\n(V) Part 5: Deriving the rate of E1 in Assumption A.5.(ii).\nWe first introduce the following useful lemma.\nLemma E.5 (Theorem 4 in Maurer & Pontil (2021)). Let f : X n →R and X = (X1, . . . , Xn) be a vector of independent\nrandom variables with values in a space X. Then for any t > 0 we have\nP(f(X) −Ef(X) > t) ≤exp\n\n\n−\nt2\n4e2\n\r\r\rPn\ni=1 ∥fi(X)∥2\nψ1\n\r\r\r\n∞+ 2e maxi ∥∥fi(X)∥ψ1∥∞t\n\n\n,\nwhere fi(X) as a random function of x is defined to be (fi(X))(x)\n:=\nf(x1, . . . , xi−1, Xi, xi+1, . . . , Xn) −\nEXi[f(x1, . . . , xi−1, Xi, xi+1, . . . , Xn)], the sub-Gaussian norm ∥Z∥ψ1 := supd≥1{∥Z∥d/d}, and ∥Z∥d = (E|Z|d)1/d.\n46\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nLet\nU =\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\r\r\r\r\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)x(k)\ni\ny(k)\ni\n−E\n\u0002\nγ(r)\nθ,w(x(k))x(k)y(k)\u0003\r\r\r\r\n2\n=\nsup\n∥u∥2≤1\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T u · y(k)\ni\n−E\n\u0002\nγ(r)\nθ,w(x(k))(x(k))T u · y(k)\u0003\f\f\f\f\n≤2 max\nj=1:N\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)(x(k)\ni\n)T uj · y(k)\ni\n−E\n\u0002\nγ(r)\nθ,w(x(k))(x(k))T uj · y(k)\ni\n\u0003\f\f\f\f\n|\n{z\n}\nUj\n,\nwhere {uj}N\nj=1 is a 1/2-cover of the unit ball B(0, 1) in Rd w.r.t. ℓ2-norm, with N ≤5d (by Example 5.8 in Wainwright\n(2019)). We first bound Uj −EUj as below. Fix (x(k)\n1 , y(k)\ni\n), . . . , (x(k)\ni−1, y(k)\ni−1), (x(k)\ni+1, y(k)\ni+1), . . . , (x(k)\nn , y(k)\nn ) and define\ns(k)\nir (x(k)\ni\n, y(k)\ni\n) = Vj −E\n\u0002\nVj|(x(k)\n1 , y(k)\ni\n), . . . , (x(k)\ni−1, y(k)\ni−1), (x(k)\ni+1, y(k)\ni+1), . . . , (x(k)\nn , y(k)\nn )\n\u0003\n. Then\n|s(k)\nir (x(k)\ni\n, y(k)\ni\n)| ≤1\nn\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\fγ(r)\nθ,w(x(k)\ni\n, y(k)\ni\n)(x(k)\ni\n)T uj · y(k)\ni\n\f\f\f\n|\n{z\n}\nW1\n+ 2\nnE\n\f\f\f\f\f\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\nγ(r)\nθ,w(x(k), y(k))(x(k))T uj · y(k)\n\f\f\f\f\f\n|\n{z\n}\nW2\n,\nwhere [E(W1 + W2)d]1/d ≤(EW d\n1 )1/d + (EW d\n2 )1/d, and (EW d\n1 )1/d, (EW d\n2 )1/d ≤CMd/n with some constantC > 0.\nThen by Lemma E.2,\nP(Uj −EUj ≥t) ≲exp\n\u001a\n−Cnt2\nM 2\n\u001b\n.\nBy a similar procedure used in deriving W(n, δ, ξ), we can show that\nEUj ≲1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n, y(k)\ni\n)(x(k)\ni\n)T uj · y(k)\ni\n· ϵ(k)\ni\n\f\f\f\f\n≲1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\nn\nX\ni=1\n(x(k)\ni\n)T uj · y(k)\ni\n· ϵ(k)\ni1\n\f\f\f\f\n+\nR\nX\nr=2\n(\n1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir (θr −θ1)T x(k)\ni\n· y(k)\ni\n\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir y(k)\ni\n\u0002\n(θT\nr x(k)\ni\n)2 −(θT\n1 x(k)\ni\n)2\u0003\f\f\f\f\n+ 1\nnEx(k)Eϵ\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\nn\nX\ni=1\nϵ(k)\nir y(k)\ni\n(log wr −log w1)\n\f\f\f\f\n)\n47\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n≲[RM 2r∗\nθ + RM(M + r∗\nθ)2]\nr\nd\nn + MR log\n\u0010 R\ncw\n\u0011r\n1\nn\n≲RM 3\nr\nd\nn + MR log\n\u0010 R\ncw\n\u0011r\n1\nn,\nwhich implies that\nP\n\u0012\nUj ≥RM 3\nr\nd\nn + MR log\n\u0010 R\ncw\n\u0011r\n1\nn + t\n\u0013\n≲exp\n\u001a\n−\nCn2t2\nnM 2 + Mtn\n\u001b\n= exp\n\u001a\n−\nCnt2\nM 2 + Mt\n\u001b\n.\nTherefore\nP\n\u0012\nmax\nj=1:N Uj ≥CRM 3\nr\nd\nn + CMR log\n\u0010 R\ncw\n\u0011r\n1\nn + t\n\u0013\n≲N exp\n\u001a\n−\nCnt2\nM 2 + M 2t\n\u001b\n,\nwhich implies that\nU ≲RM 3\nr\nd\nn + MR log(Rc−1\nw )\nr\n1\nn + M\nr\nlog(1/δ)\nn\n,\nw.p. at least 1 −δ. On the other hand, similarly, we have\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\r\r\r\r\n1\nn\nn\nX\ni=1\nγ(r)\nθ,w(x(k)\ni\n)x(k)\ni\n(x(k)\ni\n)T θr −E\n\u0002\nγ(r)\nθ,w(x(k))x(k)(x(k))T θr\n\u0003\r\r\r\r\n2\n≲RM 3\nr\nd\nn + MR log(Rc−1\nw )\nr\n1\nn + M\nr\nlog(1/δ)\nn\n,\nhence\nE1(n, δ) ≍RM 3\nr\nd\nn + MR log(Rc−1\nw )\nr\n1\nn + M\nr\nlog(1/δ)\nn\n.\n(VI) Part 6: Deriving the rate of E2 in Assumption A.5.(iii). Let\nZ =\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n0<η(k)\nr\n≤¯η\n1\nn|S|\n\r\r\r\r\r\nX\nk∈S\nη(k)\nr\n·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n)x(k)\ni\ny(k)\ni\n−E[γ(k)\nθ,w(x(k))x(k)y(k)]\n\u0001\n\r\r\r\r\r\n2\n=\nsup\n∥u∥2≤1\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n0<η(k)\nr\n≤¯η\n1\nn|S|\n\f\f\f\f\f\nX\nk∈S\nη(k)\nr\n·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n, y(k)\ni\n)(x(k)\ni\n)T u · y(k)\ni\n−E[γ(k)\nθ,w(x(k))(x(k))T u · y(k)]\n\u0001\n\f\f\f\f\f\n≤\nsup\nj′\n1,...,j′\nk=1:N′ sup\nj=1:N\n2\nn|S|\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\f\f\f\nX\nk∈S\nηj′\nk ·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n, y(k)\ni\n)(x(k)\ni\n)T uj · y(k)\ni\n−E[γ(k)\nθ,w(x(k), y(k))(x(k))T uj · y(k)]\n\u0001\n\f\f\f\f\f\n|\n{z\n}\nZ(j,j′\n1,...,j′\nk)\n,\nwhere {uj}N\nj=1 is a 1/2-cover of the unit ball B(0, 1) in Rd w.r.t.\nℓ2-norm with N\n≤\n5d and {ηj′}N ′\nj′=1\nis a 1/2-cover of [0, 1] with N ′\n≤\n2.\nWe first bound Z(j, j′\n1, . . . , j′\nk) −EZ(j, j′\n1, . . . , j′\nk) as follows.\nFix (x(k)\n1 , y(k)\ni\n), . . . , (x(k)\ni−1, y(k)\ni−1), (x(k)\ni+1, y(k)\ni+1), . . . , (x(k)\nn , y(k)\nn ) and define v(k)\nir (x(k)\ni\n, y(k)\ni\n)\n=\nZ(j, j′\n1, . . . , j′\nk) −\nE[Z(j, j′\n1, . . . , j′\nk)|{(x(k)\ni\n, y(k)\ni\n)}k∈S,i∈[n]\\{(x(k)\ni\n, y(k)\ni\n)}]. Then\n|v(k)\nir (x(k)\ni\n)| ≤ηjk\nn|S|\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n\f\f\fγ(r)\nθ,w(x(k)\ni\n, y(k)\ni\n)(x(k)\ni\n)T uj · y(k)\ni\n\f\f\f\n|\n{z\n}\nW1\n48\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n+ 2ηjk\nn|S|E\n\f\f\f\f\f\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\nγ(r)\nθ,w(x(k), y(k))(x(k))T uj · y(k)\n\f\f\f\f\f\n|\n{z\n}\nW2\n.\nVia the same procedure used to bound Uj, it can be shown that\nP(Z(j, j′\n1, . . . , j′\nk) −EZ(j, j′\n1, . . . , j′\nk) ≥t) ≲exp\n\u001a\n−\nC(n|S|)2t2\nn|S|M 2¯η2 + ¯ηMtn|S|\n\u001b\n= exp\n\u001a\n−\nCn|S|t2\nM 2¯η2 + ¯ηMt\n\u001b\n,\nEZ(j, j′\n1, . . . , j′\nk) ≲¯ηRM 3\ns\nd\nn|S| + ¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn,\nleading to\nP\n\u0012\nZ(j, j′\n1, . . . , j′\nk) ≥¯ηRM 3\nr\nd\nn + ¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + t\n\u0013\n≲exp\n\u001a\n−\nCn|S|t2\nM 2¯η2 + ¯ηMt\n\u001b\n.\nTherefore\nP\n\u0012\nmax\nj′\n1,...,j′\nk=1:N ′ max\nj=1:N Z(j, j′\n1, . . . , j′\nk) ≥C¯ηRM 3\nr\nd\nn + C[RM 3 + RM log(Rc−1\nw )] log(Rc−1\nw )\nr\n1\nn + t\n\u0013\n≲N(N ′)K exp\n\u001a\n−\nCn|S|t2\nM 2¯η2 + ¯ηMt\n\u001b\n,\nwhich implies that\nZ ≤\nmax\nj′\n1,...,j′\nk=1:N′ max\nj=1:N Z(j, j′\n1, . . . , j′\nk) ≲¯ηRM 3\nr\nd\nn + ¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + ¯ηM\ns\nlog(1/δ)\nn|S|\n,\nw.p. at least 1 −δ. Similarly,\nsup\n|wr−w(k)∗\nr\n|≤cw\n2R\n∥θr−θ(k)∗\nr\n∥2≤r∗\nθ\n0<η(k)\nr\n≤¯η\n1\nn|S|\n\r\r\r\r\r\nX\nk∈S\nη(k)\nr\n·\nn\nX\ni=1\n\u0000γ(k)\nθ,w(x(k)\ni\n)θr −E[γ(k)\nθ,w(x(k))θr]\n\u0001\n\r\r\r\r\r\n2\n≲¯ηRM 3\nr\nd\nn + ¯η[RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + ¯ηM\ns\nlog(1/δ)\nn|S|\n,\nw.p. at least 1 −δ. Hence\nE2(n, |S|, δ) ≍RM 3\nr\nd\nn + [RM 3 + RM log(Rc−1\nw )]\nr\n1\nn + M\ns\nlog(1/δ)\nn|S|\n.\nE.6. Proof of Proposition A.19\nRecall that\nAt =\n\u0014\n9˜κ0\n\u0010 ˜κ0\n119\n\u0011t−1\n+ 118\n119(t −1)˜κt−1\n0\n\u0015\n(r∗\nw + r∗\nθ) +\n1\n1 −˜κ0/119 ¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+\n18\n1 −˜κ0/119 min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn, δ\n3R\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ\n\u0014\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn, δ\n3R\n\u0011\u0015\n,\n49\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nand\nAt +\n18\n1 −˜κ0/119W\n\u0010\nn,\nδ\n3RK , r∗\nθ,t\n\u0011\n= r∗\nθ,t+1,\nfor t ≥1 with r∗\nθ,1 := r∗\nθ.\nBy Assumption A.15.(iv), there exists ˜κ′\n0 ∈(0, 1) such that CRM\np p\nn ≤˜κ′\n0 with a large C. Hence by plugging in the\nexplicit rates obtained in Proposition A.16,\nr∗\nθ,t+1 ≤˜κ′\n0r∗\nθ,t + Ct(˜κ0)t−1(r∗\nw ∨r∗\nθ) + C¯ηRM 3\ns\nd\nn|S| + C[(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn\n+ C[(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ C min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn,\nimplying that\nr∗\nθ,T ≲(˜κ′\n0)T −1r∗\nθ + T 2(˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + ¯ηRM 3\ns\nd\nn|S| + [(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn\n+ [(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn\n≲T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + ¯ηRM 3\ns\nd\nn|S| + [(¯ηM) ∨1][RM 2 + R log(Rc−1\nw )]\nr\n1\nn\n+ [(¯ηM) ∨1]\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, ¯ηRM 3\nr\nd\nn\n\u001b\n+ ϵ¯ηRM 2[(¯ηM) ∨1]\nr\nd\nn\n≲T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + R2M 3c−1\nw\ns\nd\nn|S| + R2Mc−1\nw [M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ MRc−1\nw\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, R2M 3c−1\nw\nr\nd\nn\n\u001b\n+ ϵRM 3c−1\nw\nr\nd\nn,\nwhere κ0 = 119\nq\n3Cb\n1+2Cb + CR3c−2\nw\n(log ∆)3/2\n∆\n+ CR3c−2\nw Cb + CR4c−2\nw\n1\n∆+ ˜κ′\n0, and ˜κ′\n0 satisfies 1 > ˜κ′\n0 > CMR\nq\nd\nn for\nsome C > 0.\nE.7. Proof of Corollary A.17\nBy the rate of W(n,\nδ\n3RK , r∗\nθ,T ) in Proposition A.16 and the upper bound of r∗\nθ,T in Proposition A.19,\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ,T\n\u0011\n≍RMr∗\nθ,T\nr\nd\nn + [RM 2 + R log(Rc−1\nw )]\nr\n1\nn +\nr\nlog(RK/δ)\nn\n≲T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + R2M 3c−1\nw\ns\nd\nn|S| + R2Mc−1\nw [M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ MRc−1\nw\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, R2M 3c−1\nw\nr\nd\nn\n\u001b\n+ ϵRM 3c−1\nw\nr\nd\nn.\nApplying Theorem A.8, we have\nmax\nk∈S max\nr∈[R](∥bθ(k)[T ]\nr\n−θ(k)∗\nr\n∥2 + | bw(k)[T ]\nr\n−w(k)∗\nr\n|)\n≤20T(˜κ0)T −1(r∗\nw ∨r∗\nθ) +\n\u0014119\n15 ˜κ0(˜κ0/119)T −1 + 118\n119(T −1)(˜κ0)T\n\u0015\n(r∗\nw + r∗\nθ)\n+\n1\n1 −κ0\nh\n¯ηE2\n\u0010\nn, |S|, δ\n3R\n\u0011\n+ W\n\u0010\nn,\nδ\n3RK , r∗\nθ,J\n\u0011i\n50\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\n+\n18\n1 −˜κ0/119 · min\n\u001a\n3h,\n6\n1 −˜κ0\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\u001b\n+\n30\n(1 −˜κ0)(1 −˜κ0/119)ϵ ·\nh\nW\n\u0010\nn,\nδ\n3RK , r∗\nθ\n\u0011\n+ 2¯ηE1\n\u0010\nn,\nδ\n3RK\n\u0011i\n≤T 2(˜κ0 ∨˜κ′\n0)T −1(r∗\nw ∨r∗\nθ) + R2M 3c−1\nw\ns\nd\nn|S| + R2Mc−1\nw [M 2 + log(Rc−1\nw )]\nr\n1\nn\n+ MRc−1\nw\nr\nlog(RK/δ)\nn\n+ min\n\u001a\nh, R2M 3c−1\nw\nr\nd\nn\n\u001b\n+ ϵRM 3c−1\nw\nr\nd\nn.\n(18)\nNote that conditioned on the event V defined in the proof of Theorem A.8,\nη(k)\nr\n= (1 + 2Cb)−1( bw(k)[0]\nr\n)−1 ≲Rc−1\nw ,\nfor all k ∈S and r ∈[R]. Plugging it in equation (18) implies the desired upper bound in Corollary 2.\nE.8. Proof of Theorem C.2\nRecall that our best permutation π∗\nk ∈PR on task k can be up to a permutation on [K]. WLOG, consider π∗\nk satisfying that\nπ∗\nk(r) = “the majority class” ˜r if #{k ∈S : πk(r) = ˜r} > 1\n2|S|, for all k ∈S. Define “the majority class” of {πk(r)}k∈S\nas the ˜r ∈[R] which satisfies #{k ∈S : πk(r) = ˜r} ≥maxr′̸=˜r #{k ∈S : πk(r) = r′}. Denote the majority class\nof {πk(r)}k∈S as mr ∈[R] and Sr = {k ∈S : πk(r) = mr}. WLOG, suppose π∗= {π∗\nk}K\nk=1 satisties π∗\nk(r) = r for\nany r and k ∈S. Consider any π = {πk}K\nk=1 with πk(r) = π∗\nk(r) for all k ∈Sc and π ̸= π∗. It suffices to show that\nscore(π, K) > score(π∗, K).\nFor convenience, denote ξ = maxk∈S minπk maxr∈[R] ∥bθ(k)[0]\nπk(r) −θ(k)∗\nr\n∥2. We have\nscore(π, K) −score(π∗, K) =\nX\nk̸=k′∈S\nR\nX\nr=1\n∥bθ(k)[0]\nπk(r) −bθ(k′)[0]\nπk′(r)∥2\n|\n{z\n}\n[1]\n+ 2\nX\nk∈S,k′∈Sc\nR\nX\nr=1\n∥bθ(k)[0]\nπk(r) −bθ(k′)[0]\nπk′(r)∥2\n|\n{z\n}\n[2]\n−\nX\nk̸=k′∈S\nR\nX\nr=1\n∥bθ(k)[0]\nr\n−bθ(k′)[0]\nr\n∥2\n|\n{z\n}\n[1]′\n−2\nX\nk̸=k′∈S\nR\nX\nr=1\n∥bθ(k)[0]\nr\n−bθ(k′)[0]\nπk′(r)∥2\n|\n{z\n}\n[2]′\n.\nNote that\n[1] −[1]′ =\nX\nk̸=k′∈S\nX\nr:πk(r)̸=πk′(r)\n\u0010\n∥bθ(k)[0]\nπk(r) −bθ(k′)[0]\nπk′(r)∥2 −∥bθ(k)[0]\nr\n−bθ(k′)[0]\nr\n∥2\n\u0011\n≥\nX\nk̸=k′∈S\nX\nr:πk(r)̸=πk′(r)\n\u0010\n∥θ(k)∗\nπk(r) −θ(k′)∗\nπk′(r)∥2 −∥θ(k)∗\nr\n−θ(k′)∗\nr\n∥2 −4ξ\n\u0011\n≥\nX\nk̸=k′∈S\nX\nr:πk(r)̸=πk′(r)\n\u0010\n∥θ(k)∗\nπk(r) −θ(k)∗\nπk′(r)∥2 −∥θ(k)∗\nπk′(r) −θ(k′)∗\nπk′(r)∥2 −∥θ(k)∗\nr\n−θ(k′)∗\nr\n∥2 −4ξ\n\u0011\n≥\nX\nk̸=k′∈S\nX\nr:πk(r)̸=πk′(r)\n(∆−2h −4ξ)\n=\nR\nX\nr=1\nX\nk̸=k′∈S,πk(r)̸=πk′(r)\n(∆−2h −4ξ).\nFor r with |Sr| > 1\n2|S|:\nX\nk̸=k′:πk(r)̸=πk′(r)\n(∆−2h −4ξ) ≥|Sr|(|S| −|Sr|)(∆−2h −4ξ).\n51\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nFor r with |Sr| ≤1\n2|S|: denote #{K ∈S : πk(r) = r′} as vr′, where PR\nr′=1 vr′ = |S| and |vr′| ≤1\n2|S| for all r′. Then\nX\nk̸=k′:πk(r)̸=πk′(r)\n(∆−2h −4ξ) ≥(∆−2h −4ξ)\n\u0014\n|S|(|S| −1) −\nR\nX\nr′=1\nvr′(vr′ −1)\n\u0015\n= (∆−2h −4ξ)\n\u0014\n|S|2 −\nR\nX\nr′=1\nv2\nr′\n\u0015\n≥(∆−2h −4ξ)\n\u0014\n|S|2 −2 ·\n\u00101\n2|S|\n\u00112\u0015\n≥(∆−2h −4ξ) · 1\n2|S|2.\nHence\n[1] −[1]′ ≥(∆−2h −4ξ) ·\n\"\nX\nr:|Sr|>|S|/2\n|Sr|(|S| −|Sr|) +\nX\nr:|Sr|≤|S|/2\n1\n2|S|2\n#\n.\nAnd\n[2] −[2]′ ≥−2\nX\nk∈S,k′∈Sc\nR\nX\nr=1\n∥bθ(k)[0]\nπk(r) −bθ(k)[0]\nr\n∥2\n≥−2|Sc|\nX\nk∈S\nX\nr:πk(r)̸=r\n(h + 2ξ)\n≥−2|Sc|\n\"\nX\nr:|Sr|>|S|/2\nX\nk∈S,πk(r)̸=r\n(h + 2ξ) +\nX\nr:|Sr|≤|S|/2\nX\nk∈S,πk(r)̸=r\n(h + 2ξ)\n#\n≥−2|Sc|(h + 2ξ)\n\"\nX\nr:|Sr|>|S|/2\n(|S| −|Sr|) +\nX\nr:|Sr|≤|S|/2\n|S|\n#\n.\nTherefore,\nscore(π) −score(π∗) ≥\nX\nr:|Sr|>|S|/2\n(|S| −|Sr|)[|Sr|(∆−2h −4ξ) −2|Sc|(h + 2ξ)]\n+\nX\nr:|Sr|≤|S|/2\n\u00141\n2|S|2(∆−2h −4ξ) −2|Sc||S|(h + 2ξ)\n\u0015\n≥\nX\nr:|Sr|>|S|/2\n(|S| −|Sr|)\n\u00141\n2|S|∆−h(|S| + 2|Sc|) −ξ(2|S| + 4|Sc|)\n\u0015\n+\nX\nr:|Sr|≤|S|/2\n|S|\n\u00141\n2|S|(∆−2h −4ξ) −2|Sc|(h + 2ξ)\n\u0015\n≥\nX\nr:|Sr|>|S|/2\n(|S| −|Sr|) · 1\n2|S|\n\u0014\n∆−h\n\u0012\n2 + 4 · |Sc|\n|S|\n\u0013\n−ξ\n\u0012\n4 + 8 · |Sc|\n|S|\n\u0013\u0015\n+\nX\nr:|Sr|≤|S|/2\n1\n2|S|2\n\u0014\n∆−h\n\u0012\n2 + 4 · |Sc|\n|S|\n\u0013\n−ξ\n\u0012\n4 + 8 · |Sc|\n|S|\n\u0013\u0015\n> 0,\nwhich completes the proof, where in the last inequality we used the fact that |Sc|/|S| ≤\nϵ\n1−ϵ.\nE.9. Proof of Theorem C.4\nConsider the eK-th round where eK ∈S. WLOG, suppose ι is the identity permutation on [R]. Denote eS = [ eK] ∩S,\neSc = [ eK]∩Sc, hence [K] = eS ∪eSc. WLOG, suppose π1 = π2 = . . . = π e\nK−1 are the identity permutations on [R]. Denote\n52\nTowards the Theory of Unsupervised Federated Learning: Non-asymptotic Analysis of Federated EM Algorithms\nπ = {πk}\ne\nK−1\nk=1 ∪π e\nK and eπ = {πk}\ne\nK−1\nk=1 ∪eπ e\nK, where eπ e\nK is the identity permutation on [R] and π e\nK can be any non-identity\npermutation. We claim that it suffices to show that score(π) > score(eπ) for any eK ≥K0, because if this is the case, then\neπ e\nK will be chosen in the eK-th round of the “for” loop. Hence all chosen permutations in eS have the same alignment. By\ninduction, the output permutations from “Permutation Alignment Algorithm 2 (Stepwise search)” are identity permutations\non [R] among tasks in S, which completes our proof. In the remaining part of this proof, we show score(π) > score(eπ) for\nany eK ≥K0.\nIn fact,\nscore(π) −score(eπ) =\nX\nk∈eS\nX\nr:πf\nK(r)̸=r\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ(k)[0]\nr\n∥2\n|\n{z\n}\n[1]\n+\nX\nk∈eSc\nX\nr:πf\nK(r)̸=r\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ(k)[0]\nr\n∥2\n|\n{z\n}\n[2]\n−\nX\nk∈eS\nX\nr:πf\nK(r)̸=r\n∥bθ( e\nK)[0]\nr\n−bθ(k)[0]\nr\n∥2\n|\n{z\n}\n[1]′\n−\nX\nk∈eSc\nX\nr:πf\nK(r)̸=r\n∥bθ( e\nK)[0]\nr\n−bθ(k)[0]\nr\n∥2\n|\n{z\n}\n[2]′\n.\nAnd\n[1] −[1]′ =\nX\nk∈eS\nX\nr:πf\nK(r)̸=r\n\u0010\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ(k)[0]\nr\n∥2 −∥bθ( e\nK)[0]\nr\n−bθ(k)[0]\nr\n∥2\n\u0011\n≥\nX\nk∈eS\nX\nr:πf\nK(r)̸=r\n\u0010\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ(k)[0]\nr\n∥2 −∥θ( e\nK)∗\nr\n−θ(k)∗\nr\n∥2 −2ξ\n\u0011\n≥\nX\nk∈eS\nX\nr:πf\nK(r)̸=r\n\u0010\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ( e\nK)[0]\nr\n∥2 −2h −4ξ\n\u0011\n≥\nX\nr:πf\nK(r)̸=r\n|eS|\n\u0010\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ( e\nK)[0]\nr\n∥2 −2h −4ξ\n\u0011\n,\nand\n[2] −[2]′ ≥\nX\nk∈eSc\nX\nr:πf\nK(r)̸=r\n\u0010\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ(k)[0]\nr\n∥2 −∥bθ( e\nK)[0]\nr\n−bθ(k)[0]\nr\n∥2\n\u0011\n≥−\nX\nk∈eSc\nX\nr:πf\nK(r)̸=r\n∥bθ( e\nK)[0]\nπf\nK(r) −bθ( e\nK)[0]\nr\n∥2\n= −\nX\nr:πf\nK(r)̸=r\n|eSc| · ∥bθ( e\nK)[0]\nπf\nK(r) −bθ( e\nK)[0]\nr\n∥2.\nTherefore,\nscore(π) −score(eπ) = [1] −[1]′ + [2] −[2]′\n≥\nX\nr:πf\nK(r)̸=r\nh\n(|eS| −|eSc|)∥bθ( e\nK)[0]\nπf\nK(r) −bθ( e\nK)[0]\nr\n∥2 −2|eS|h −4|eS|ξ\ni\n≥\nX\nr:πf\nK(r)̸=r\nh\n(|eS| −|eSc|)∆−2|eS|h −(6|eS| −2|eSc|)ξ\ni\n=\nX\nr:πf\nK(r)̸=r\neK\n\u0014\u0012\n2|eS|\neK\n−1\n\u0013\n∆−2|eS|\neK\n· h −\n\u0012\n8|eS|\neK\n−2\n\u0013\nξ\n\u0015\n≥\nX\nr:πf\nK(r)̸=r\neK ·\n\u0012K0 −Kϵ\nK0 + Kϵ · ∆−2h −6ξ\n\u0013\n> 0,\nwhere the second last inequality is due to the fact that\nK0\nK0+Kϵ ≤|eS/ eK| ≤1.\n53\n",
  "categories": [
    "stat.ML",
    "cs.LG"
  ],
  "published": "2023-10-23",
  "updated": "2024-06-14"
}