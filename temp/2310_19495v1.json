{
  "id": "http://arxiv.org/abs/2310.19495v1",
  "title": "Deep Learning for Visual Navigation of Underwater Robots",
  "authors": [
    "M. Sunbeam"
  ],
  "abstract": "This paper aims to briefly survey deep learning methods for visual navigation\nof underwater robotics. The scope of this paper includes the visual perception\nof underwater robotics with deep learning methods, the available visual\nunderwater datasets, imitation learning, and reinforcement learning methods for\nnavigation. Additionally, relevant works will be categorized under the\nimitation learning or deep learning paradigm for underwater robots for clarity\nof the training methodologies in the current landscape. Literature that uses\ndeep learning algorithms to process non-visual data for underwater navigation\nwill not be considered, except as contrasting examples.",
  "text": "1\nDeep Learning for Visual Navigation of Underwater\nRobots\nMD Sunbeam\nDepartment of Aerospace Engineering\nTexas A&M University\nCollege Station, TX, United States\nmdsunbeam@tamu.edu\nAbstract—This paper aims to briefly survey deep learning\nmethods for visual navigation of underwater robotics. The scope\nof this paper includes the visual perception of underwater\nrobotics with deep learning methods, the available visual under-\nwater datasets, imitation learning, and reinforcement learning\nmethods for navigation. Additionally, relevant works will be cat-\negorized under the imitation learning or deep learning paradigm\nfor underwater robots for clarity of the training methodologies\nin the current landscape. Literature that uses deep learning\nalgorithms to process non-visual data for underwater navigation\nwill not be considered, except as contrasting examples.\nIndex Terms—deep learning, underwater, imitation learning,\nAUV, visual navigation, reinforcement learning\nI. INTRODUCTION\nThis paper will cover deep learning for underwater robotics.\nIt is divided into the perception of underwater robotics, un-\nderwater visual datasets, imitation learning, and reinforcement\nlearning for underwater environments.\nVisual navigation in underwater robotics is more challeng-\ning than its land or air counterparts because of the limitations\nof perception, particularly computer vision. When light travels\nthrough the water, it is absorbed and scattered, resulting in a\nwavelength-dependent attenuation that disturbs the standard\nways of handling vision [1]. An example of this problem is\ncapturing images of an object with different brightness and\ncolors based on distance.\nAdditionally, environmental changes are more subtle under-\nwater. Features may change from drifting sand and turbulent\ncurrent. Detecting and modeling these changes is difficult,\nespecially because of its stochastic nature and the complex\nfluid equations that govern the dynamics. The hydrodynamics\ninvolved is nonlinear and time-varying, and the robot is\nusually underactuated with not all the states reachable [2].\nDeep learning methods for visual navigation are explored,\nbecause they offer a learning-based way that may handle these\nchallenges through a data-driven approach.\nBecause autonomous underwater vehicles (AUVs) are less\ncommon due to greater hardware considerations, underwater\ndatasets are rare and more difficult to collect. Since deep\nlearning is a data-driven method, it is imperative to have public\ndatasets to benchmark models.\nThe two main deep learning paradigms for control of an\nAUV through visual navigation is imitation and reinforcement\nlearning. Imitation learning is used for underwater robotics\nfor visual navigation, often mapping RGB images to control\ncommands like roll, pitch, yaw, and throttle. The problem\nformulation is a supervised learning task where the objective\nis to learn a policy that imitates the trajectories of a human or\nrobot demonstrator. Two major limitations of imitation learn-\ning algorithms are compounding error between differences of\nexpert and agent trajectory as well as the idea that a policy\nderived from such a method will not outperform the expert\ndemonstrator [4].\nReinforcement learning is the other deep learning paradigm,\nusing a non-differentiable objective function through rewards\nto train neural networks for a desired task, in this case being\nunderwater visual navigation. Reinforcement learning differs\nfrom imitation learning in that an initial dataset is not needed,\nand an environment must be explored to generate the data to\nbe trained on. Though reinforcement learning is less sample\nefficient than imitation learning, the lack of dependence on\nan expert demonstrator allows it to yield policies that are\npotentially superhuman [15].\nThe paper’s contribution are as follows:\n• Identify the works that focus on utilizing deep learning\nfor perception in underwater visual navigation algorithms.\n• Discuss the publicly available underwater datasets.\n• Categorize the deep learning methods used in AUVs\nunder imitation learning or reinforcement learning.\nII. PERCEPTION\nDue to the challenges of visual perception in underwater\nrobotics, [10] offers a deep learning method to improve loop\nclosure and detection for a Visual Graph SLAM algorithm for\nunderwater navigation. Siamese networks, a neural network ar-\nchitecture that has enjoyed great success in similarity learning,\nwas leveraged to detect similar visual features and places.\nAnother work for underwater loop detection for use in\na visual SLAM algorithm is [11], but it sets itself apart\nfrom [10] by training a network through an unsupervised\nlearning method. Whereas Siamese networks are trained in a\nsupervised manner with image pairs through contrastive loss,\nthe unsupervised learning method detects similar images and\nloop closure through the clustering of image descriptors.\nFinally, [9] also deals with loop closure, but the role of the\nneural network is more limited in scope. The neural network\nonly selects loop candidates, which are sent to an image\narXiv:2310.19495v1  [cs.RO]  30 Oct 2023\n2\nFig. 1. Redrawn network architecture diagram of the Siamese network used\nto detect loop-closure between two underwater images in [10].\nmatcher and geometric consistency verifier to output the final\nloop detected images.\nIII. UNDERWATER DATASETS\nThere are far fewer underwater robot datasets as compared\nto autonomous ground vehicle or autonomous aerial vehicle\ndatasets since collecting data underwater remains difficult due\nto hardware constraints and needing a relatively uncommon\nenvironment.\nFor deep learning methods, having a wide variety of datasets\nis paramount because it allows the research community to\ntackle the same problems, often on a vetted or curated dataset.\nIn computer vision, deep learning innovation was primarily\naccelerated by the existence of ImageNet [19]. In natural\nlanguage processing, the large corpus of textual data in the\ninternet has fueled the advances of large language models. For\nrobotics, ground vehicle datasets like CARLA [20] or KITTI\n[21] and aerial vehicle datasets like Mid-Air [22] have paved\nthe way for development of many deep learning based visual\nnavigation algorithms.\nAs such, [6] offers a visual dataset for AUVs navigating near\nthe seabed. The images were collected from three different\ndepths: one at a few meters, the second 270 meters, and the last\nat 380 meters. The purpose of this data is to provide image and\ninertia-pressure samples for use in simultaneous localization\nand mapping algorithms.\nA common theme is leveraging generative adversarial net-\nworks and generative models to augment real underwater\ndatasets with generated synthetic images. This is done in [7],\n[17], and [18]. A publicly available dataset, called EUVP,\nof images that were taken during ocean experiments for\nexploration and human-robot collaboration is also presented\nin [18].\nFig. 2.\nThese are some sample training images selected from the EUVP\ndataset in [18].\nIV. IMITATION LEARNING\nFor [3], a domain expert diver collected data to generate\n”good” and ”bad” navigation scenarios, which were later\nannotated with labels of yaw and pitch to accomplish the\ntask of exploring a coral reef while avoiding obstacles. A\nconvolutional neural network was trained to map the images\nto the control commands. They evaluated their models through\nthe percentage of coral covered in the navigation task in certain\nreef area.\nSimilar to [3], [4] also uses a behavior cloning model to\nmap RGB images to yaw and pitch command. In this case,\nthe task was to explore a shipwreck, and a convolutional\nneural network was used. For this work, the neural network\nwas trained on a mixture of simulation and real-world data.\nThe model was evaluated through the training-validation-test\nsplit. Different test accuracies are given for the real-world\nonly dataset, simulation only dataset, and mixed dataset. The\nprimary difference between the two papers were the difference\nin task and the nature of the demonstration data.\nOne work that is different is [5], which uses goal-\nconditioned imitation learning for underwater visual naviga-\ntion. The behavior cloning model learns safe, reactive behavior\nfor difficult terrain, and is conditioned to navigate based on\nwaypoints. The neural network architecture is a convolutional\nneural network, much like those in [3] and [4]. Similarly, the\nmodel was evaluated through a test set and evaluated in real-\nlife qualitatively.\nV. REINFORCEMENT LEARNING\nIn [8], a soft-actor critic deep reinforcement learning al-\ngorithm was used to train a neural network. The AUV was\na soft robot, and the task was to swim in a straight line in\ndisturbed water. A camera was used to collect RGB images,\nwhich served as the observation space for the neural network.\nBefore the deep reinforcement learning algorithm was rolled\nout underwater, a model was trained in a MuJoCo simulation.\nFor [15], a combination of imitation learning and reinforce-\nment learning is used. First, a generative adversarial imitation\n3\nFig. 3.\nRedrawn system diagram for the deep reinforcement learning\ncontroller in [8].\nlearning algorithm is used to overcome the cold start problem\nof the initial neural network training to learn a policy. Then, a\nreward function is designed and trained with proximal policy\noptimization and soft-actor critic. The results are compared in\na Unity simulation. This work uses a light sensor, which is\ndifferent from the other imitation learning and reinforcement\nlearning work as most use a RGB camera for their visual\nsensor.\nVI. IMITATION AND REINFORCEMENT LEARNING\nCATEGORIZATION\nThe works where deep learning methods were used for\nonly visual navigation are considered and categorized. Works\nlike [12], [14], and [16] use deep or reinforcement learning\nmethodologies, but fail to incorporate a visual sensor. While\nthere is much more work on using neural networks on inertial,\npressure, and position data from non-visual sensors, that is\noutside the scope of this survey. Furthermore, the specific neu-\nral network architectures used in underwater robot navigation\nwill not be discussed in depth like in [13], but are useful for\nunderstanding their applications in perception and control.\nDeep Learning Paradigm Categorization\nReference\nImitation\nLearning\nReinforcement\nLearning\n[3]\n✓\n✗\n[4]\n✓\n✗\n[5]\n✓\n✗\n[8]\n✗\n✓\n[15]\n✓\n✓\nThere are far more works using imitation learning algo-\nrithms than reinforcement learning. This can be explained\nby the idea that the simplest class of imitation learning\nalgorithms, behavior cloning, is good at dealing with high\ndimensional inputs because convolutional layers can be used as\na feature extractor to reduce the dimension of the images. The\nbehavior cloning problem formulation is also easier, where the\nobjective is imitating an expert trajectory through a supervised\nlearning setup.\nThe lack of many deep reinforcement learning works for\nvisual navigation of AUVs can be explained by the added dif-\nficulty of devising a proper reward function on top of dealing\nwith a noisy observation space. Moreover, the reinforcement\nlearning agent must do exploration before it can exploit\nthrough an adequate policy, which introduces an overhead of\ncreating or using a simulation for the underwater robot as real-\nlife exploration can be expensive and dangerous.\nVII. CONCLUSION\nIn this paper, we have covered the deep learning methods\nused to improve perception under water, which go into improv-\ning the visual navigation algorithms that use those modules.\nMost of the work centers around in detecting loop closures\nthrough similarity learning of images through Siamese net-\nworks or using other neural network architectures to detect and\nselect loop closure candidates like in [9], [10], and [11]. The\nimprovement of loop closure in visual perception through deep\nlearning improves the visual SLAM algorithms that leverage\nthem for navigation.\nNext, we discussed the underwater datasets publicly avail-\nable like the ones in [6] and [7]. While there are some standard\npublic datasets, there are far too few and even less for a\nrobotics application. This can be attributed to the difficulty of\ncreating such datasets due to hardware and environmental con-\nstraints. A common trend is to leverage deep learning methods\nto augment the available datasets, either through improving the\nquality of the images or generating synthetic images like in\n[17] and [18]. However, this type of augmentation seems more\na stopgap rather than a permanent solution to the scarcity of\nunderwater robotics data.\nFinally, we categorize the works that use deep learning\nmethods to control an AUV under the imitation (like in\n[3], [4], and [5]) or reinforcement learning (like in [8] and\n[15]) paradigm. A pattern that becomes immediately obvious\nis that there exists far more imitation learning works than\ndeep reinforcement learning works in the domain of visual\nnavigation in underwater robotics. Another trend is that there\naren’t that many works where some visual sensors are used\nin the context of imitation or reinforcement learning. This can\nperhaps be explained by the hardware constraints in AUVs,\nwhere limited computation and batteries onboard may make\nRGB cameras too energy-intensive.\nFrom this survey, some gaps in the field of deep learning for\nvisual navigation of underwater robots become apparent. There\nneeds to be more underwater datasets collected and made\npublicly available, especially with robotics applications. Even\nthough deep learning methods are used to augment existing\nunderwater datasets, the best way to accelerate the pace and\nscalability of neural networks is through more data. Like\nin computer vision and natural language processing, curated\ndatasets provide a standard for research and competition, both\nof which push innovation within the field.\nAnother gap is the lack of reinforcement learning work\nfor visual navigation. The preference for imitation learning is\nreasonable given the harder formulation of the reinforcement\nlearning problem, but focus in this direction may address the\nlimitations of imitation learning, like compounding errors and\nthe learned policy never being better than the demonstrator.\nBecause simulation is an important component of reinforce-\nment learning in the exploration stage, attention in this area\nmay lead to better simulators that can address the lack of\nunderwater datasets through synthetic data.\n4\nOverall, the field of deep learning for visual navigation\nof underwater robots provides natural challenges crucial for\nthe larger study of AI robotics. One such challenge is the\nfundamental problem of acting under noisy or misleading\nvisual perception data. This offers opportunities for planning\nor navigation under uncertainty. Moreover, breakthroughs in\nthe domain of deep learning for underwater visual navigation\nmay be applied to the broader field of learning from sparse\nenvironments. Underwater environments are often character-\nized by sparsely distributed features. In imitation learning and\ndeep reinforcement learning, environments with few features\nmay make it difficult for the neural network to learn a useful\npolicy for the desired task. Because of these reasons, it is\ncrucial to place more research emphasis on the problem of\nvisual navigation in underwater environments.\nREFERENCES\n[1] K. K¨oser and U. Frese, “Challenges in underwater visual navigation and\nslam,” AI Technology for Underwater Robots, pp. 125–135, 2019.\n[2] L. Christensen, J. de Gea Fern´andez, M. Hildebrandt, C. E. Koch,\nand B. Wehbe, “Recent advances in AI for navigation and control\nof Underwater Robots,” Current Robotics Reports, vol. 3, no. 4, pp.\n165–175, 2022.\n[3] T. Manderson, J. C. Higuera, R. Cheng, and G. Dudek, “Vision-\nbased autonomous underwater swimming in dense coral for combined\ncollision avoidance and Target Selection,” 2018 IEEE/RSJ International\nConference on Intelligent Robots and Systems (IROS), 2018.\n[4] N. Karapetyan, J. V. Johnson, and I. Rekleitis, “Human diver-inspired\nvisual navigation: Towards coverage path planning of shipwrecks,”\nMarine Technology Society Journal, vol. 55, no. 4, pp. 24–32, 2021.\n[5] T. Manderson, J. Camilo Gamboa Higuera, S. Wapnick, J.-F. Tremblay,\nF. Shkurti, D. Meger, and G. Dudek, “Vision-based goal-conditioned\npolicies for underwater navigation in the presence of obstacles,”\nRobotics: Science and Systems XVI, 2020.\n[6] M. Ferrera, V. Creuze, J. Moras, and P. Trouv´e-Peloux, “AQUALOC:\nAn underwater dataset for visual–inertial–pressure localization,” The\nInternational Journal of Robotics Research, vol. 38, no. 14, pp.\n1549–1559, 2019.\n[7] I. Polymenis, M. Haroutunian, R. Norman, and D. Trodden, “Virtual\nunderwater datasets for autonomous inspections,” Journal of Marine\nScience and Engineering, vol. 10, no. 9, p. 1289, 2022.\n[8] G. Li, J. Shintake, and M. Hayashibe, “Deep reinforcement learning\nframework for underwater locomotion of Soft Robot,” 2021 IEEE\nInternational Conference on Robotics and Automation (ICRA), 2021.\n[9] A. Burguera, F. Bonin-Font, E. G. Font, and A. M. Torres, “Combining\ndeep learning and robust estimation for outlier-resilient underwater\nvisual graph slam,” Journal of Marine Science and Engineering, vol.\n10, no. 4, p. 511, 2022.\n[10] A. Burguera, “Robust underwater visual graph slam using a Siamese\nneural network and robust image matching,” Proceedings of the 17th\nInternational Joint Conference on Computer Vision, Imaging and Com-\nputer Graphics Theory and Applications, 2022.\n[11] A. Burguera and F. Bonin-Font, “An unsupervised neural network for\nloop detection in Underwater Visual Slam,” Journal of Intelligent &\nRobotic Systems, vol. 100, no. 3-4, pp. 1157–1177, 2020.\n[12] X. Mu, B. He, X. Zhang, Y. Song, Y. Shen, and C. Feng, “End-to-\nend navigation for autonomous underwater vehicle with hybrid recurrent\nneural networks,” Ocean Engineering, vol. 194, p. 106602, 2019.\n[13] J. Qin, M. Li, D. Li, J. Zhong, and K. Yang, “A survey on visual\nnavigation and positioning for autonomous uuvs,” Remote Sensing, vol.\n14, no. 15, p. 3794, 2022.\n[14] N. Wang, Y. Wang, Y. Zhao, Y. Wang, and Z. Li, “Sim-to-real: Mapless\nnavigation for usvs using Deep Reinforcement Learning,” Journal of\nMarine Science and Engineering, vol. 10, no. 7, p. 895, 2022.\n[15] Y. Mao, F. Gao, Q. Zhang, and Z. Yang, “An AUV target-tracking\nmethod combining imitation learning and deep reinforcement learning,”\nJournal of Marine Science and Engineering, vol. 10, no. 3, p. 383, 2022.\n[16] I. B. Saksvik, A. Alcocer, and V. Hassani, “A deep learning approach\nto dead-reckoning navigation for autonomous underwater vehicles with\nlimited sensor payloads,” OCEANS 2021: San Diego – Porto, 2021.\n[17] C. Fabbri, M. J. Islam, and J. Sattar, “Enhancing underwater imagery\nusing generative adversarial networks,” 2018 IEEE International Con-\nference on Robotics and Automation (ICRA), 2018.\n[18] M. J. Islam, Y. Xia, and J. Sattar, “Fast underwater image enhancement\nfor improved visual perception,” IEEE Robotics and Automation Letters,\nvol. 5, no. 2, pp. 3227–3234, 2020.\n[19] J. Deng, W. Dong, R. Socher, L. -J. Li, Kai Li and Li Fei-Fei, ”ImageNet:\nA large-scale hierarchical image database,” 2009 IEEE Conference on\nComputer Vision and Pattern Recognition, Miami, FL, USA, 2009, pp.\n248-255, doi: 10.1109/CVPR.2009.5206848.\n[20] Dosovitskiy, A., Ros, G., Codevilla, F., L´opez, A. M. & Koltun, V.\n(2017). CARLA: An Open Urban Driving Simulator. CoRL (p./pp. 1-\n16), : PMLR.\n[21] Geiger A, Lenz P, Stiller C, Urtasun R. Vision meets robotics:\nThe KITTI dataset. The International Journal of Robotics Research.\n2013;32(11):1231-1237. doi:10.1177/0278364913491297\n[22] M. Fonder and M. Van Droogenbroeck, ”Mid-Air: A Multi-Modal\nDataset for Extremely Low Altitude Drone Flights,” 2019 IEEE/CVF\nConference on Computer Vision and Pattern Recognition Work-\nshops (CVPRW), Long Beach, CA, USA, 2019, pp. 553-562, doi:\n10.1109/CVPRW.2019.00081.\n",
  "categories": [
    "cs.RO",
    "cs.CV",
    "cs.LG"
  ],
  "published": "2023-10-30",
  "updated": "2023-10-30"
}