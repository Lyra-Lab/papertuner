{
  "id": "http://arxiv.org/abs/2312.04289v1",
  "title": "Fast simulation of airfoil flow field via deep neural network",
  "authors": [
    "Kuijun Zuo",
    "Zhengyin Ye",
    "Shuhui Bu",
    "Xianxu Yuan",
    "Weiwei Zhang"
  ],
  "abstract": "Computational Fluid Dynamics (CFD) has become an indispensable tool in the\noptimization design, and evaluation of aircraft aerodynamics. However, solving\nthe Navier-Stokes (NS) equations is a time-consuming, memory demanding and\ncomputationally expensive task. Artificial intelligence offers a promising\navenue for flow field solving. In this work, we propose a novel deep learning\nframework for rapidly reconstructing airfoil flow fields. Channel attention and\nspatial attention modules are utilized in the downsampling stage of the UNet to\nenhance the feature learning capabilities of the deep learning model.\nAdditionally, integrating the predicted flow field values generated by the deep\nlearning model into the NS equation solver validates the credibility of the\nflow field prediction results. The NACA series airfoils were used to validate\nthe prediction accuracy and generalization of the deep learning model. The\nexperimental results represent the deep learning model achieving flow field\nprediction speeds three orders of magnitude faster than CFD solver.\nFurthermore, the CFD solver integrated with deep learning model demonstrates a\nthreefold acceleration compared to CFD solver. By extensively mining historical\nflow field data, an efficient solution is derived for the rapid simulation of\naircraft flow fields.",
  "text": "Fast simulation of airfoil flow field via deep neural network\nKuijun Zuoa, Zhengyin Yea, Shuhui Bua, Xianxu Yuanb,∗, Weiwei Zhanga,∗\naSchool of Aeronautics, Northwestern Polytechnical University, Xi’an, 710072, China\nbState Key Laboratory of Aerodynamics, China Aerodynamics Research and Development Center,\nMian’yang, Si’chuan 621000, China\nAbstract\nComputational Fluid Dynamics (CFD) has become an indispensable tool in the op-\ntimization design, and evaluation of aircraft aerodynamics. However, solving the Navier-\nStokes (NS) equations is a time-consuming, memory demanding and computationally\nexpensive task. Artificial intelligence offers a promising avenue for flow field solving. In\nthis work, we propose a novel deep learning framework for rapidly reconstructing airfoil\nflow fields. Channel attention and spatial attention modules are utilized in the downsam-\npling stage of the UNet to enhance the feature learning capabilities of the deep learning\nmodel. Additionally, integrating the predicted flow field values generated by the deep\nlearning model into the NS equation solver validates the credibility of the flow field pre-\ndiction results. The NACA series airfoils were used to validate the prediction accuracy and\ngeneralization of the deep learning model. The experimental results represent the deep\nlearning model achieving flow field prediction speeds three orders of magnitude faster than\nCFD solver. Furthermore, the CFD solver integrated with deep learning model demon-\nstrates a threefold acceleration compared to CFD solver. By extensively mining historical\nflow field data, an efficient solution is derived for the rapid simulation of aircraft flow\nfields.\nKeywords:\nDeep learning, Airfoil aerodynamics, flow field prediction, PHengLEI\n1. Introduction\nWith the development of mathematical theories [1], data science [2] and high-performance\ncomputing [3], CFD plays a crucial role in aerospace [4], energy and power science [5, 6],\nand transportation industries [7]. It has gradually evolved into the foundation of large-\n∗Corresponding author\nEmail addresses: yuanxianxu@cardc.cn (Xianxu Yuan ), aeroelastic@nwpu.edu.cn (Weiwei Zhang\n)\nPreprint submitted to arXiv\nDecember 8, 2023\narXiv:2312.04289v1  [physics.flu-dyn]  7 Dec 2023\nscale equipment digital engineering and a key supporting tool [8]. The CFD vision 2023\nroad map released by NASA highlights that CFD has transformed aircraft design method-\nologies, enhanced the capability to design complex aircraft, and reduced the design cycle\nfor aircraft [9]. CFD technology primarily acquires flow field information by solving highly\ncomplex nonlinear NS equations. However, the high-fidelity computational models, such\nas direct numerical simulation (DNS), requires a substantial amount of computational\nresources is becoming increasingly prohibitive [10].\nSince reduced order model (ROM) can approximate large-scale systems with lower\ncomputational costs, they can serve as an alternative to overcoming the trade-off between\nhigh-fidelity simulations and high computational cost [11]. In the field of scientific com-\nputing, the most commonly used reduced order models (ROMs) are the Proper Orthogo-\nnal Decomposition (POD) [12] and Dynamic Mode Decomposition (DMD) [13] methods\n[14–17].\nThe successful implementation of dimensionality reduction in fluid dynamics\ndepends on significant improvements in computer computational speed and memory ca-\npacity. For the POD and DMD methods, capturing transient, intermittent, invariance,\nand multi-scale phenomena is challenging due to the inherent translation, rotation, and\nscaling characteristics of fluid [18].\nInspired by the widespread success of machine learning in areas such as computer\nvision [19, 20], natural language processing [21, 22], and autonomous driving [23, 24].\nConsidering extracting high-dimensional multi-scale features from a vast amount of fluid\ndata using deep learning methods to find an alternative or improve existing expensive\nexperimental and time-consuming iterative simulation tasks [25]. Some of the prelimi-\nnary work already conducted has demonstrated the effectiveness of artificial intelligence\napproaches in accelerating scientific computing [26–30].\nIn the field of aerodynamics,\nLeer et al. [31] used a deep learning approach with multilayer perceptron (MLP) and\nradial-logarithmic filter mask (RLF) to predict incompressible laminar steady flow fields\nfor various geometric shapes. Sun et al. [32] utilized deep learning methods to predict\nthe characteristics of compressible flow for supersonic airfoils, such as lift, drag, and pitch\ncoefficients, achieving a high level of prediction accuracy and efficiency.\nSome pioneering work has shown that machine learning methods can be used for\nturbulence modeling [33–36] and rapid flow field prediction under different flow conditions\n[37–41]. However, when dealing with large-scale flow field data, neural network models\n2\nlike MLP face challenges such as a large number of parameters and high training time\ncosts. Due to the weight sharing property of convolutional neural networks (CNN) [42],\nthey can significantly reduce the number of model training parameters compared to MLP,\nand as a result, they are widely used in flow field prediction tasks [43–46]. For instance,\nRibeiro et al. [47] proposed a deep neural network model based on convolutional neural\nnetworks, known as deepCFD, for predicting non-uniform steady laminar flow problem.\nChen and Nils [48] conducted research using the UNet deep neural network to address the\ninference problem of exact solutions for two-dimensional compressible Reynolds-averaged\nNavier-Stokes (RANS) flow over airfoils.\nThe UNet [49] neural network primarily consists of a topology composed of convo-\nlutional upsampling blocks and convolutional downsampling blocks, with feature fusion\nbetween the upsampling and downsampling layers facilitated through “skip connection”\noperations. Both UNet++ [50] and UNet3+ [51] enhance the feature extraction capability\nof deep learning models by adding more densely skip connections. However, solely increas-\ning the network’s depth and dense connections may not be an optimal solution, as it adds\nto the memory cost of model training. Human perception of large-scale information is\nprimarily achieved by focusing on significant aspects while disregarding irrelevant details.\nHence, our proposed deep learning framework for rapid simulation of aircraft airfoils, FU-\nCBAM-Net, enhances the extraction of high-dimensional flow field nonlinear features by\nadding channel attention and spatial attention behind the UNet convolutional downsam-\npling blocks. FU-CBAM-Net applies channel attention and spatial attention operations\nto the input features separately, reducing attention to irrelevant noise. Furthermore, it\nperforms element-wise multiplication between the attention maps and the output features\nfrom the previous convolutional layer, achieving adaptive feature refinement [52].\nDespite the rapid development of machine learning-based physics simulations in recent\nyears, researchers in the field still harbor skepticism regarding the accuracy and general-\nizability of machine learning methods [53]. Many researchers consider it as a black-box\nmodels that are difficult to understand and explain [46]. Here, to enhance the credibility of\nthe deep neural network’s flow field predictions, the FU-CBAM-Net prediction values are\ncoupled with the PHengLEI [54] solver developed by the China Aerodynamics Research\nand Development Center (CARDC) to iteratively solve the NS equations.\nThe main contributions of this work are as follows:\n3\n• We propose a novel deep convolutional attention network model for predicting flow\nfield solutions of different airfoil shapes under varying operational conditions.\n• By embedding the FU-CBAM-Net model into the PHengLEI solver, it not only\nenhances the credibility of FU-CBAM-Net flow field prediction results, but also\naccelerates the convergence speed of aerodynamic parameters during PHengLEI’s\nsolving process, reducing the number of solver iterations.\n• We have made our code publicly available on GitHub repository to enable other\nresearchers to replicate our work.\nThe rest of this paper is organized as follows. Section II mainly describes the deep\nlearning methods used for predicting airfoil flow fields. Section III primarily discusses the\nairfoil flow field dataset. Section IV shows and discusses the results of the FU-CBAM-Net\nneural network model training and prediction. And the conclusion is given in Section V.\n2. Methodology\n2.1. Overview\nThe purpose of this study is to utilize machine learning methods to rapidly predict\nsteady laminar flow fields for different airfoil shapes under various flow conditions, and\nto explore credible evaluation methods for flow field predictions obtained through deep\nlearning techniques. The algorithm’s computational workflow is illustrated in Fig.1.\nThe first part is airfoil flow field data preprocessing.\nAs shown in Fig.\n1(a), for\nthe purpose of facilitating subsequent feature extraction by FU-CBAM-Net, we consider\ntransforming non-uniform grid data in the physical coordinate into uniform grid data in\nthe computational coordinate. Using a series of NACA airfoil data, the PHengLEI solver\nwas employed to obtain laminar flow field solutions for airfoils at Mach number 0.2, with\nangles of attack ranging from 0◦to 5◦, and Reynolds numbers from 1000 to 2000. For a\ndetailed description of the flow field data, please refer to Section 3.\nIn accordance with the illustration in Fig. 1 (b), the improved UNet neural network,\nFU-CBAM-Net, is used for the task of rapid flow field prediction. The input to the deep\nneural network consists of flow field coordinates and physical parameters that represent\nthe flow field state, such as Reynolds number (Re) and angle of attack (AOA). The\noutput includes velocity fields, pressure fields, and corresponding gradient information for\n4\nthe respective airfoil. For a detailed explanation of the working principles of FU-CBAM-\nNet and the specifics of its input and output parameters, please refer to Section 2.2 and\nSection 2.4.\nMost existing deep learning models for end-to-end flow field prediction tasks are pre-\ndominantly black-box models. In fields related to aerodynamic optimization design and\nthe like, although the introduction of artificial intelligence has accelerated the speed of\nflow field resolution and improved prediction accuracy significantly, the inherent lack of\ninterpretability in deep learning methods has left researchers in these areas somewhat\nskeptical about the practical engineering applications of such approaches. As shown in\nFig. 1(c), to further enhance the credibility of deep learning flow field predictions, the\npredicted flow field from the FU-CBAM model is fed into the PHengLEI solver to solve\nthe Navier-Stokes equations until convergence is achieved. The flow field obtained through\nCFD techniques is widely accepted by researchers in the relevant field. For related test\nresults, please refer to the fourth section.\nStart\nReading AI \npredicted \nvalues\nReading grid/flow field \nparameter\nLoad solver\nSolver \ninitialization\nConvergence?\nCalculate time step\nReading \nstructural \ngrid\nEnd\nTime advancement\nFlux calculation\nExplicit/implicit \ntime integration\nPHengLEI credibility verification\nFU-CBAM Net based flow field prediction\nd\ndx\nx\ny\nd\ndy\nx\ny\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\nx\ndx\nd\ny\ny\ndy\nd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb\nl\na\nk\nc\nd\ne\nf\ng\nh\nj\ni\no\n\n\na\nc\nb\nk\nAirfoil grid coordinate transformation\n(a)\n(b)\n(c)\nFigure 1: Flowchart of flow field prediction and credibility assessment method coupling FU-CBAM Net\nwith PHengLEI solver\n2.2. Geometric information encoding\nTo accurately capture the flow field information in the boundary layer region of the\nairfoil, the geometry and flow information of the airfoil are transformed from Cartesian\ncoordinates (x, y) to curvilinear coordinates (ξ, η) through univalent transformation:\n\n\nx\ny\n\n\ni,j\n=\n\n\nx0\ny0\n\n\ni,1\n+\nZ\n\n\ndx\ndy\n\n\n(1)\n5\nIn Eq. (1), x0 and y0 represent the coordinate information of the given airfoil surface.\ni and j are indices that indicate different directions within the mesh. Furthermore, we\nhave:\n\n\ndx\ndy\n\n=\n\n\n∂x\n∂ξ\n∂x\n∂η\n∂y\n∂ξ\n∂y\n∂η\n\n\n\n\ndξ\ndη\n\n\n(2)\nand\n\n\ndξ\ndη\n\n=\n\n\n∂ξ\n∂x\n∂ξ\n∂y\n∂η\n∂x\n∂η\n∂y\n\n\n\n\ndx\ndy\n\n\n(3)\nAs derived from Eq. (2):\n\n\ndξ\ndη\n\n=\n\n\n∂x\n∂ξ\n∂x\n∂η\n∂y\n∂ξ\n∂y\n∂η\n\n\n−1 \n\ndx\ndy\n\n\n(4)\nCombining Eq. (3) and Eq. (4), we obtain:\n\n\n∂ξ\n∂x\n∂ξ\n∂y\n∂η\n∂x\n∂η\n∂y\n\n= 1\nJ\n\n\n∂y\n∂η\n−∂x\n∂η\n−∂y\n∂ξ\n∂x\n∂ξ\n\n\n(5)\nwhere\nJ =\n\f\f\f\f\f\f\f\n∂x\n∂ξ\n−∂x\n∂η\n−∂y\n∂ξ\n∂y\n∂η\n\f\f\f\f\f\f\f\n(6)\nHere, J denotes the Jacobian matrix. Hence, the metric can be expressed as:\n∂ξ\n∂x = 1\nJ\n∂y\n∂η ,\n∂ξ\n∂y = −1\nJ\n∂x\n∂η ,\n∂η\n∂x = −1\nJ\n∂y\n∂ξ ,\n∂η\n∂y = 1\nJ\n∂x\n∂ξ\n(7)\nIn the above formula, ξ = (i −1)/(imax −1), η = (j −1)/(jmax −1). imax, jmax\ncorrespond to the maximum number of mesh nodes in different directions. Figure. 2,\nFig. 3(c), Fig. 3(f) respectively present mapping diagrams of Cartesian coordinates and\ncurvilinear coordinates before and after mesh transformation. The flow field coordinates\ncan reflect the spatial distribution of different physical quantities in various coordinate\nsystems. Therefore, they are utilized as inputs for the neural network. As shown in Fig.\n3, the geometric coordinates of different airfoil shapes are also used as input parameters\n6\nfor the neural network. The boundary layer region in the flow field often contains rich\ninformation and is a focal point in traditional CFD calculations. In contrast, far-field\ndata does not require excessive attention. According to reference [55], using the filter M,\nreweights the flow field coordinates to obtain two new parameters, Mx and My, with the\nfollowing calculation formula:\n\n\n\n\n\n\n\nM = e−|SDF |, ΨM(x) = M × x, ΨM(y) = M × y,\nSDF(i, j) =\nmin\n(i∗,j∗)∈Z |(i, j) −(i∗, j∗)|sign[f(i, j)]\n(8)\nIn Eq. (8), SDF represents Signed Distance Field and sign[f(i, j)] represents the\nsymbolic function. Here, the SDF calculates the normal distance from each mesh point\nin the flow field to the airfoil profile. Figure 4 presents visual results for Mx, My, and\nSDF in different coordinate systems.\nDuring the mesh transformation process, distortion may occur due to operations such\nas mesh stretching [55]. To address this issue, the Jacobian matrix used in the mesh\ntransformation is also employed as input information for the neural network. The Jacobian\nmatrix parameters in computational coordinates are shown in Fig.\n5.\nBased on the\nanalysis above, the neural network model FU-CBAM-Net has a total of fifteen input\nparameters, which are x, y, x0, y0, ξ, η, SDF, Mx, My, AOA, Re, ∂x\n∂ξ , ∂x\n∂η , ∂y\n∂ξ , ∂y\n∂η.\n2.3. UNet convolutional neural network\nThe emergence of CNN has significantly improved the training speed of deep learning\nmodels compared to fully connected neural networks. As a fundamental module, CNN\nhas been widely adopted in various fields, including computer vision [56], flow field pre-\ndiction [57], and aerodynamic optimization design [58]. Figure 6 illustrates a standard\nconvolutional neural network architecture. X ∈RH×W ×C represents the input to the\nneural network, where H, W, and C denote the height, width, and number of channels\nof the input feature maps, respectively. CNN utilizes convolutional kernels to perform\nfeature extraction by sliding windows over feature maps. The size of the output feature\nmaps can be calculated using the following formula:\n\n\n\n\n\n\n\nHout = Hin + 2 × P0 −D0 × (K0 −1) −1\nS0\n+ 1,\nWout = Win + 2 × P1 −D1 × (K1 −1) −1\nS1\n+ 1.\n(9)\n7\nFigure 2: Flow field coordinate map before ((a) Normalized x coordinate, (b) Normalized y coordinate,\n(c) ξ map)and after ((d) Normalized x coordinate, (e) Normalized y coordinate, (f) ξ map)mesh trans-\nformation.\nFigure 3: Mapping diagrams of airfoil profile geometric coordinate before ((a) x0, (b) y0) and after ((d)\nx0, (e) y0) transformation. Mapping diagrams of computed coordinate η before ((c) η) and after ((f) η)\nmesh transformation.\nIn Eq. (9), Pi represents the values to be padded on the four sides of the input features,\ntypically set to 0. Di denotes the spacing between kernel elements, which is set to 1 here.\n8\nFigure 4: Mapping diagrams for Mx, My, SDF before ((a) Mx, (b) My, (c) SDF) and after ((d) Mx,\n(e) My, (f) SDF) mesh transformation.\nFigure 5: Metrics in the governing equations. (a) ∂x\n∂ξ , (b) ∂x\n∂η , (c) ∂y\n∂ξ , (d) ∂y\n∂η .\nKi represents the size of the kernel, and Si represents the stride of the kernel. For more\ndetails, please refer to our previous work [42].\nDeeper feature maps often have a larger receptive field. As shown in Fig. 7(a), Olaf\net al. proposed a UNet neural network model based on a convolutional neural network\n9\nHxWxC\n+b1\n+b2\nHxW\nHxW\n+b1\n+b2\nReLU\nReLU\nHxWXC\nInput\nOutput\nFigure 6: Typical convolutional neural network architecture.\n（a） UNet\n（b） UNet3+\n1\nEn\nX\n2\nEn\nX\n3\nEn\nX\n4\nEn\nX\n5\nEn\nX\n1\nDe\nX\n2\nDe\nX\n3\nDe\nX\n4\nDe\nX\n1\nEn\nX\n2\nEn\nX\n3\nEn\nX\n4\nEn\nX\n5\nEn\nX\n1\nDe\nX\n2\nDe\nX\n3\nDe\nX\n4\nDe\nX\n64\n128\n256\n512\n1024\n512\n256\n128\n64\n15\n9\n15\n64\n128\n256\n512\n1024\n512\n256\n128\n64\n9\nFigure 7: UNet neural network and UNet3+ network architecture diagram.\narchitecture to address image segmentation problems in the medical field. Shallow convo-\nlutions are employed to extract low-level geometric features, while deep convolutions are\nused to extract high-level semantic features. Additionally, to address the issue of infor-\nmation loss during the upsampling process of feature maps, a residual network structure\nis utilized to concatenate feature maps with the same number of channels, eliminating\nthe interference of information loss on flow field prediction results. However, the UNet\nneural network performs feature fusion only at the same feature scale. As depicted in Fig.\n7(b), Huang and his team improved the model’s prediction accuracy by using multiscale\nskip connections to integrate high-level semantic features from different scales along with\nlow-level geometric features. The feature maps after the i −th decoder can be calculated\n10\nusing the following formula:\nXi\nDe =\n\n\n\n\n\n\n\n\n\n\n\n\n\nXi\nEn,\ni = N\nH\n\n\n\n\nC\n\u0000D\n\u0000Xk\nEn\n\u0001\u0001i−1\nk=1 , C\n\u0000Xi\nEn\n\u0001\n|\n{z\n}\nScales: 1th∼ith\n, C\n\u0000U\n\u0000Xk\nDe\n\u0001\u0001i−1\nk=1\n|\n{z\n}\nScales: 1th∼ith\n\n\n\n\n,\ni = 1, ..., N −1\n(10)\nwhere D(.) and U(.) represent the downsampling and upsampling operations, respectively.\nThe function C(.) represents the convolution operation. H(.) denotes the operation of\naggregating multiscale features.\n2.4. FU-CBAM-Net\nWhen confronted with vast amounts of data, the human perceptual system tends to\nfilter and concentrate on particular information zones. By mimicking the human percep-\ntual system’s way of focusing on areas of interest, it is possible to enhance the efficiency\nand performance of computer vision and machine learning algorithms. This approach is\nknown as the “attention mechanism” and has become an important component of mod-\nern deep learning. In contrast to the processing approach of UNet and UNet3+ with\nskip connections, the attention mechanism can identify the most relevant regions and\neffectively enhance the feature fusion and representation capabilities of neural networks.\nTherefore, we have adopted a feature fusion strategy different from UNet3+. An atten-\ntion model in the form of a convolutional block is embedded during the downsampling\nprocess in UNet, using both spatial attention and channel attention strategies to enhance\nthe model’s predictive performance. The FU-CBAM-Net network constructed as shown\nin Fig. 8. Figure 8 (a) illustrates the fifteen parameters fed into FU-CBAM-Net. Each\nparameter matrix has a size of 61×299. These matrices are concatenated along the chan-\nnels to form a tensor with 15 channels, which serves as the input for the neural network.\nFigure 8 (b) presents the changes in the dimensions of the tensor as it passes through each\nlayer of the FU-CBAM-Net when a tensor of size 15 × 61 × 299 is input. More detailed\nabout FU-CBAM-Net architecture, please refer to Tbl. 1 and Tbl. 2. Figure 8 (c) shows\nthe Convolutional Block Attention Module (CBAM) composed of both channel attention\nand spatial attention. Sections 2.4.1 provide a detailed explanation of the algorithm’s\ncomputational principles.\n11\nnor\ny\n0x\n0y\n\n\nnor\nx\nSDF\nMx\nMy\nRe\nAOA\nx\n\n\n\nx\n\n\n\ny\n\n\n\ny\n\n\n\n1024 ×3×18 \n1024 ×3×18 \n1024 ×3×18 \nBlock5\n15 ×61×299 \n64 ×61×299 \n64 ×61×299 \n128 ×30×149 \n128 ×30×149 \n128 ×30×149 \n256 ×15×74 \n256 ×15×74 \n256 ×15×74 \n512 ×7×37 \n512 ×7×37 \n512 ×7×37 \nBlock2\nBlock4\nBlock1\nBlock3\n1024 ×7×37 \n512 ×7×37 \n512 ×7×37 \n512 ×15×74 \n256 ×15×74 \n256 ×15×74 \n256 ×30×149 \n128 ×30×149 \n128 ×30×149 \n128 ×61×299 \n64 ×61×299 \n64 ×61×299 \nConvolution 3x3\nMax Pooling 2x2\nSkip connection\nConvTranspose 3x3\nConvTranspose 4x3\nConvTranspose 3x3\nConvTranspose 4x4\nConvolution 1x1\nBlock6\nBlock9\nBlock8\nBlock7\nChannel \nAttention \nModule\nSpatial\nAttention \nModule\nInput Feature\nFine-grained \nFeature\nCBAM\nCBAM\nCBAM\nCBAM\n(c) CBAM\n(a) Flow field data\n(b) FU-CBAM Net\nFigure 8: An illustration of the network architecture for FU-CBAM-Net.\n2.4.1. Convolutional Block Attention Module\nFigure 9 presents the detailed network architecture diagram of CBAM. For the input\nfeature map F ∈RC×H×W , after passing through the channel attention layer and the\nspatial attention layer, the feature map sizes are Γc ∈RC×1×1 and Γs ∈RC×H×W ,\nrespectively. The overall computation process of CBAM is as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF1 = Γc(F) ⊗F\nF2 = Γs(F1) ⊗F1\nΓc(F) = σ(MLP(AvgPoll(F)) + MLP(MaxPool(F)))\nΓs(F1) = σ(f 7×7([AvgPool(F1); MaxPool(F1)]))\n(11)\nIn the above Eq. (11), the symbol ⊗represents element-wise multiplication. f 7×7\ndenotes a convolutional operation with a 7 × 7 filter size. σ denotes the sigmoid fuction.\nThis function is often used as the activation function in neural networks to map variables\nto the range [0, 1]. The calculation formula is as follows:\nS(x) =\n1\n1 + e−x\n(12)\nIn Fig. 9 (a), the feature map F, input to a layer in the network, undergoes channel\n12\nTable 1: FU-CBAM-Net Encoder Block\nFU-CBAM-Net Encoder Block\nFeature size\nInput\n-\nB × 15 × 61 × 299\nEncoder layer 1\n\n\nconv1,\n3 × 3\nconv2,\n3 × 3\npadding,\n1\n\n\nB × 64 × 61 × 299\nCBAM layer 1\nChannel Attention\nAdaptive average pool, 1 × 1\nAdaptive max pool, 1 × 1\nB × 64 × 1 × 1\nSpatial Attention\n\n\nconv,\n7 × 7\nstride,\n1\npadding,\n3\n\n\nB × 1 × 61 × 299\nEncoder layer 2\n\n\nconv1,\n3 × 3\nconv2,\n3 × 3\nmaxpool,\n2 × 2\n\n\nB × 128 × 30 × 149\nCBAM layer 2\nChannel Attention\nAdaptive average pool, 1 × 1\nAdaptive max pool, 1 × 1\nB × 128 × 1 × 1\nSpatial Attention\n\n\nconv,\n7 × 7\nstride,\n1\npadding,\n3\n\n\nB × 1 × 30 × 149\nEncoder layer 3\n\n\nconv1,\n3 × 3\nconv2,\n3 × 3\nmaxpool,\n2 × 2\n\n\nB × 256 × 15 × 74\nCBAM layer 3\nChannel Attention\nAdaptive average pool, 1 × 1\nAdaptive max pool, 1 × 1\nB × 256 × 1 × 1\nSpatial Attention\n\n\nconv,\n7 × 7\nstride,\n1\npadding,\n3\n\n\nB × 1 × 15 × 74\nEncoder layer 4\n\n\nconv1,\n3 × 3\nconv2,\n3 × 3\nmaxpool,\n2 × 2\n\n\nB × 512 × 7 × 37\nCBAM layer 4\nChannel Attention\nAdaptive average pool, 1 × 1\nAdaptive max pool, 1 × 1\nB × 512 × 1 × 1\nSpatial Attention\n\n\nconv,\n7 × 7\nstride,\n1\npadding,\n3\n\n\nB × 1 × 7 × 37\nEncoder layer 5\n\n\nconv1,\n3 × 3\nconv2,\n3 × 3\nmaxpool,\n2 × 2\n\n\nB × 1024 × 3 × 18\nattention to produce the output Γc(F), which is then element-wise multiplied with itself\nto obtain F1. Following that, F1 is fed into the spatial attention layer to obtain the output\nΓs(F1), which is then element-wise multiplied with F1 to produce the output F2. Finally,\nF2 is combined with the input feature map F through a residual connection to obtain a\nfine-grained output feature ϱ.\nFig. 9 (b) illustrates the channel attention module in CBAM. For computational effi-\nciency, the input feature maps are compressed into one dimension, and different features\n13\nTable 2: FU-CBAM-Net Decoder Block\nFU-CBAM-Net Decoder\nFeature size\nDecoder layer 1\n\n\nconv,\n3 × 3\nstride,\n2\ndilation,\n2\npadding,\n1\noutputpadding,\n0\n\n\nB × 512 × 7 × 37\nDecoder layer 2\nconvolutionn layer\n\u0014 conv1,\n3 × 3\nconv2,\n3 × 3\n\u0015\nB × 256 × 15 × 74\nupsampling layer\n\n\nconv,\n4 × 3\nstride,\n2\npadding,\n1\ndilation,\n1\noutputpadding,\n1\n\n\nDecoder layer 3\nconvolutionn layer\n\u0014\nconv1,\n3 × 3\nconv2,\n3 × 3\n\u0015\nB × 128 × 30 × 147\nupsampling layer\n\n\nconv,\n3 × 4\nstride,\n2\npadding,\n1\ndilation,\n1\noutputpadding,\n1\n\n\nDecoder layer 4\nconvolutionn layer\n\u0014 conv1,\n3 × 3\nconv2,\n3 × 3\n\u0015\nB × 64 × 61 × 299\nupsampling layer\n\n\nconv,\n4 × 4\nstride,\n2\npadding,\n1\n\n\nDecoder layer 5\n\n\nconv1,\n3 × 3\nconv2,\n3 × 3\nconv3,\n1 × 1\n\n\nB × 9 × 61 × 299\nin space are aggregated using both max-pooling and average-pooling operations. Sub-\nsequently, the aggregated features are each processed through a shared MLP layer, and\nthe final output channel attention feature map Γc ∈RC×1×1 is obtained by element-wise\nsummation.\nThe spatial attention module in CBAM is depicted in Fig.\n9 (c).\nFirst, perform\naverage-pooling and max-pooling operations along the channel dimension. Then, aggre-\ngate the extracted features using a convolutional neural network with a 7 × 7 kernel to\nobtain a two-dimensional spatial attention map Γs ∈R1×H×W .\n3. Data preparation\nUtilize the FU-CBAM-Net neural network introduced in Section 2.4 to accomplish the\nflow field prediction task for different airfoils under various operating conditions. Test\ndata for 24 NACA-series airfoils is depicted in Fig. 10. Using the PHengLEI solver to\n14\nChannel \nAttention \nModule\nSpatial\nAttention \nModule\nInput Feature\nFine-grained \nFeature\n(a) CBAM\nInput Feature\nMax pool\nAvg pool\nShared MLP\nF\nChannel Attention\nC\n\n(b) Channel Attention Module\n1F\n[Max pool, Avg pool]\nSpatial Attention\nS\n\n(c) Spatial Attention Module\nF\n1F\n2\nF\nResidual connection\nFigure 9: Convolutional Block Attention Module network architecture.\ncalculate the laminar flow solutions for these 24 airfoils within the Reynolds number range\nof 1000 to 2000 (1000, 1200, 1400, 1600, 1800, 2000) and an angle of attack ranging from\n0◦to 5◦(0◦, 1◦, 2◦, 3◦, 4◦, 5◦). A total of 864 flow field datasets are generated for training\nand testing tasks in the FU-CBAM-Net neural network. 80% of the data will be used as\nthe training dataset, 10% as the cross-validation dataset, and the remaining 10% as the\ntesting dataset.\nFor a single case, there are a total of 18239 structured grid flow field data points. The\ninput for FU-CBAM-Net consists of parameters in 15 channels (x, y, x0, y0, ξ, η, SDF,\nMx, My, AOA, Re, ∂x\n∂ξ , ∂x\n∂η , ∂y\n∂ξ , ∂y\n∂η), and the output consists of parameters in 9 channels\n(u, v, Cp, ∂u\n∂x, ∂u\n∂y , ∂v\n∂x, ∂u\n∂y , ∂Cp\n∂x , ∂Cp\n∂y ). Therefore, for FU-CBAM-Net, the neural network\ninput parameter size is 15 × 61 × 299, and the output parameter size is 9 × 61 × 299.\n4. Results and discussions\n4.1. Discussion of training results\nBased on the flow field data introduced in Section 3, training is conducted for UNet,\nUNet3+, and the FU-CBAM-Net, separately.\nThe initial learning rate for the neural\n15\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nx/c\n0.2\n0.1\n0.0\n0.1\n0.2\n0.3\ny\nFigure 10: NACA airfoil dataset.\nnetwork model during the training process is set to 5 × 10−5, and the Adam optimizer\nis employed to train the neural network parameters. The model is implemented using\nthe PyTorch deep learning library in the Python programming language. We performed\nthe training tasks on an NVIDIA RTX 3090 GPU under the Linux platform. The mean\nsquared error (MSE) is used as the loss function for the model during the training process,\nand its calculation formula is as follows:\nMSEloss =\n1\n9 × N\nN\nX\ni=1\n[(ut\ni −up\ni )2 + (vt\ni −vp\ni )2 + (Cpt\ni −Cpp\ni )2+\n((∂u\n∂ξ )t\ni −(∂u\n∂ξ )p\ni )2 + ((∂u\n∂η )t\ni −(∂u\n∂η )p\ni )2 + ((∂v\n∂ξ )t\ni −(∂v\n∂ξ )p\ni )2+\n((∂v\n∂η )t\ni −(∂v\n∂η )p\ni )2 + ((∂Cp\n∂ξ )t\ni −(∂Cp\n∂ξ )p\ni )2 + ((∂Cp\n∂η )t\ni −(∂Cp\n∂η )p\ni )2]\n(13)\nIn the above Eq. (13), ℘t\ni and ℘p\ni (℘: u, v, Cp, ∂u\n∂ξ , ∂u\n∂η , ∂v\n∂ξ , ∂v\n∂η, ∂Cp\n∂ξ , ∂Cp\n∂η ) respectively\nrepresent the ground-truth values and the neural network predicted values.\nAs shown in Fig. 11, for the UNet neural network, we conducted ablation experiments\non the parameter ’batchsize’ to explore its impact on the training results of the neural\nnetwork. When the batchsize is set to 64, the curve of the MSE loss function on the cross-\nvalidation set exhibits pronounced oscillations. Additionally, the model’s loss function\nremains relatively high even during convergence, with a training set loss of 1.16 × 10−3\nand a cross-validation set MSE loss of 1.21 × 10−3. As the batchsize decreases, the loss\nfunction curves on both the training and testing sets tend to stabilize. When the batchsize\nis set to 1, the loss function values reach the minimum, with an MSE loss of 2.81 × 10−6\non both the training and testing sets.\n16\n0\n200\n400\n600\n800\n1000\n0.0011\n0.0012\n0.0013\n0.0014\n0.0015\n0.0016\n0.0017\n0.0018\n0.0019\nTraining batchsize=64\nValidation batchsize=64\nIteration\nMSE\nTrainging loss: 1.16e-3\nValidation loss: 1.21e-3\n0\n200\n400\n600\n800\n1000\n0.0001\n0.00012\n0.00014\n0.00016\n0.00018\n0.0002\n0.00022\nTraining batchsize=16\nValidation batchsize=16\nIteration\nMSE\nTraining loss: 1.08e-4\nValidation loss: 1.05e-4\n0\n200\n400\n600\n800\n1000\n0\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\nTraining batchsize=8\nValidation batchsize=8\nIteration\nMSE\nTraining loss: 5.05e-5\nValidation loss: 4.97e-5\n0\n200\n400\n600\n800\n1000\n0\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\nTraining batchsize=4\nValidation batchsize=4\nIteration\nMSE\nTraining loss: 1.99e-5\nValidation loss: 1.96e-5\n0\n200\n400\n600\n800\n1000\n0\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\nTraining batchsize=2\nValidation batchsize=2\nIteration\nMSE\nTraining loss: 4.86e-6\nValidation loss: 4.93e-6\n0\n200\n400\n600\n800\n1000\n0\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\nTraining batchsize=1\nValidation batchsize=1\nIteration\nMSE\nTraining loss: 2.81e-6\nValidation loss: 2.81e-6\nFigure 11: The variation curve of the model training loss function for the UNet neural network under\ndifferent batchsize.\nFigure 12 illustrates the loss function variation curves during the training process for\nthe UNet3+ and FU-CBAM-Net neural network models. The hyperparameter batchsize\nfor both models is set to 1 during the training process. For UNet3+, the loss function\ncurve converges rapidly before the epoch of 100. After approximately 200 iterations, the\ncurve stabilizes. The loss function for UNet3+ on the training set is 2.88 × 10−6, and\non the cross-validation set, it is 2.97 × 10−6.\nSimilarly, for the proposed FU-CBAM-\nNet method, the curve descends rapidly before the 100th iteration. The incorporation\nof attention layers allows this method to achieve a smaller loss compared to UNet and\nUNet3+, indicating higher predictive accuracy for the deep learning model.\n4.2. Flow field prediction\nIn this section, we assess the accuracy and generalization of the prediction results of\nthe FU-CBAM-Net neural network using data from a testing dataset that wasn’t utilized\nduring the training process of the model. Firstly, we tested the trained neural network\nmodel, FU-CBAM-Net, for its predictive performance on the flow around the NACA2415\nairfoil at Re=1600 and AOA=3 ◦. As shown in Fig. 13, the predictive results of FU-\nCBAM-Net closely match the computed results of PHengLEI. Further analysis from the\nabsolute error plots in the last column of Fig. 13 reveals that for u-velocity, the absolute\nerror ranges from 1 × 10−3 to 1.2 × 10−2; for v-velocity, the error spans from 5 × 10−4\n17\n0\n100\n200\n300\n400\n500\n0\n1E-05\n2E-05\n3E-05\n4E-05\n5E-05\nTraining batchsize=1\nValidation batchsize=1\nIteration\nMSE\nTraining loss: 2.88e-6\nValidation loss: 2.97e-6\nUNet3+\n0\n100\n200\n300\n400\n500\n0\n2E-05\n4E-05\n6E-05\n8E-05\nTraining batchsize=1\nValidation batchsize=1\nIteration\nMSE\nTrainging loss: 2.46e-6\nValidation loss: 2.48e-6\nFU-CBAM-Net\nFigure 12: The loss function variation curves during the training process for UNet3+ and FU-CBAM-Net\n(left: UNet3+, right: FU-CBAM-Net).\nto 9.5 × 10−3. Meanwhile, for pressure coefficient Cp, the error range lies between 2 ×\n10−3 and 3.6 × 10−2. Figure 14 also provides contour diagrams comparing the predicted\nresults from the neural network with the computational results from PHengLEI. Whether\nfor u-velocity, v-velocity, or Cp, the curves of the predicted results align closely with\nthe computational results from PHengLEI, demonstrating that the neural network FU-\nCBAM-Net has achieved a high level of predictive accuracy.\nFigure 13: Comparison between the PHengLEI computational results and the predicted results of the\nFU-CBAM-Net for NACA2415 Re=1600, AOA=3◦(left:\nPHengLEI calculation results, middle:\nFU-\nCBAM-Net prediction results, right: absolute error map between PHengLEI and FU-CBAM-Net).\nTo further examine the predictive accuracy of FU-CBAM-Net, Fig. 15 depicts the\nscatter density plot between the PHengLEI and the FU-CBAM-Net. The diagram also\npresents the mean squared error (MSE), mean absolute error (MAE), and root mean\nsquare error (RMSE) between the predicted values and the ground-truth.\nHere, the\npredicted results of the airfoil flow field are defined as ˆϑ = {ˆϑ1, ˆϑ2, ..., ˆϑn}, and the ground-\n18\nFigure 14: Contour comparison diagram of PHengLEI and FU-CBAM-Net with respect to NACA2415\nRe=1600 AOA=3◦. The black dashed lines represent the calculation results by PHengLEI, while the red\ndashed lines represent the predictive results from FU-CBAM-Net.\ntruth of the flow field are defined as ϑ = {ϑ1, ϑ2, ..., ϑn}. MSE, MAE, and RMSE can be\ndefined by the following formulas:\nMSE = 1\nn\nn\nX\ni=1\n(ˆϑi −ϑi)2\nMAE = 1\nn\nn\nX\ni=1\n|ˆϑi −ϑi|\nRMSE =\nv\nu\nu\nt 1\nn\nn\nX\ni=1\n(ˆϑi −ϑi)2\n(14)\nIn Fig.\n15, the scatter density plot between the calculation results of PHengLEI\nand the predicted results of the neural network is almost a straight line with a diagonal\ndistribution.\nIn Fig.\n15(a), the values of MSE, MAE, and RMSE are 2.794 × 10−6,\n1.210×10−3, and 1.671×10−3, respectively. For the v-velocity in Fig. 15(b), the values of\nMSE, MAE, and RMSE are 2.271×10−6, 1.110×10−3, and 1.507×10−3, respectively. For\nthe Cp in Fig. 15(c), the values of MSE, MAE, and RMSE are 2.788×10−6, 1.148×10−3,\nand 1.670×10−3, respectively. By comparing different indicators, the accuracy of the flow\nfield prediction results of the FU-CBAM-Net neural network has been further verified.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nPHengLEI\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nFU-CBAM-Net\nMSE = 2.794e\n06\nMAE = 1.210e\n03\nRMSE = 1.671e\n03\nu-velocity\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(a) u-velocity\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\nPHengLEI\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\nFU-CBAM-Net\nMSE = 2.271e\n06\nMAE = 1.110e\n03\nRMSE = 1.507e\n03\nv-velocity\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(b) v-velocity\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nPHengLEI\n0.6\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFU-CBAM-Net\nMSE = 2.788e\n06\nMAE = 1.148e\n03\nRMSE = 1.670e\n03\nCp\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(c) Cp\nFigure 15: Scatter density diagram between PHengLEI and FU-CBAM-Net for NACA2415 Re=1600\nAOA=3◦.\n19\nTo further test the prediction effect of FU-CBAM-Net, Fig.\n16 shows the Taylor\ndiagram between the FU-CBAM-Net and PHengLEI. The Taylor diagram is a visual rep-\nresentation that simultaneously displays three metrics: correlation coefficients, centered\nroot-mean-square error (CRMSE), and standard deviation. In Fig. 16, the horizontal and\nvertical axes represent standard deviation, while the black radial lines depict correlation\ncoefficients, and the red dashed lines represent CRMSE.\nThe correlation coefficients for u-velocity, v-velocity, and Cp are highly close to 1.\nAdditionally, the CRMSE tends toward 0. The quantitative analysis results further in-\ndicate that the predictive accuracy of FU-CBAM-Net is sufficiently high. Please refer to\nAppendix A for a more detailed description of the Taylor diagram.\n0.0\n0.5\n1.0\n0.0\n0.5\n1.0\nStandard Deviation\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0.99\n0.95\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nCo\nr r\ne l\na t\ni o\nn  \nCo\ne f\nf i\nc i\nen\nt\nR\nM\nS\nD\n(a) u-velocity\n0.0\n0.2\n0.4\n0.0\n0.2\n0.4\nStandard Deviation\n0.0\n0.1\n0.2\n0.3\n0.4\n1\n0.99\n0.95\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nCo\nr r\ne l\na t\ni o\nn  \nCo\ne f\nf i\nc i\nen\nt\nR\nM\nS\nD\n(b) v-velocity\n0.0\n0.5\n1.0\n0.0\n0.5\n1.0\nStandard Deviation\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0.99\n0.95\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nCo\nr r\ne l\na t\ni o\nn  \nCo\ne f\nf i\nc i\nen\nt\nR\nM\nS\nD\n(c) Cp\nFigure 16: Taylor diagram between PHengLEI and FU-CBAM-Net for NACA2415 Re=1600 AOA=3◦.\nTo test the predictive accuracy of the FU-CBAM-Net neural network for airfoil flow\nfields from various perspectives, Fig.\n17 presents comparative curves between recon-\nstructed velocity profiles at different locations and their ground-truth data, along with\nfitted curves for pressure coefficient Cp. From the comparative curves in Fig. 17, it’s ev-\nident that the velocity profiles from FU-CBAM-Net at different locations align perfectly\nwith the computed results from PHengLEI. Correspondingly, the pressure coefficient Cp\nalso demonstrates a favorable predictive performance.\nFigure 18 further illustrates the predicted flow field results of the FU-CBAM-Net\nneural network model with variations in airfoil geometry, Re, and AOA. The predictive\nresults reveal that even in the presence of strong separated flows, the neural network model\nstill accurately simulates the flow field. As observed from the absolute error plot on the\nright side of Fig. 18. For u-velocity, the absolute error ranges from 5.0×10−3 to 4.0×10−2.\nFor v-velocity, it ranges from 5.0 × 10−3 to 3.5 × 10−2. As for the pressure coefficient Cp,\n20\nu-velocity\ny\n0\n0.3\n0.6\n0.9\n1.2\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\nFU-CBAM-Net\nPHengLEI\nx/c=0.2\nu-velocity\ny\n0\n0.3\n0.6\n0.9\n1.2\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\nFU-CBAM-Net\nPHengLEI\nx/c=0.4\nu-velocity\ny\n0\n0.3\n0.6\n0.9\n1.2\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nFU-CBAM-Net\nPHengLEI\nx/c=0.8\n(a)\n(b)\nx/c\nCp\n0\n0.2\n0.4\n0.6\n0.8\n1\n-0.5\n0\n0.5\n1\nPHengLEI\nFU-CBAM-Net\nFigure 17: Comparison between various velocity profiles and pressure coefficients for the reconstructed\nflow field and the ground-truth data. (a) velocity profiles. (b) Cp.\nits absolute error ranges from 5×10−3 to 4.5×10−2. Figure 19 further illustrates contour\nplots between the FU-CBAM-Net prediction results and PHengLEI calculation values.\nIt’s evident that for both velocity components, u and v, as well as pressure coefficient Cp,\nthe curves from both FU-CBAM-Net and PHengLEI align exceptionally well.\nFigure 18: Comparison between the PHengLEI computational results and the FU-CBAM-Net predicted\nresults for NACA4424 Re=2000, AOA=5◦(left: PHengLEI calculation results, middle: FU-CBAM-Net\nprediction results, right: absolute error map between PHengLEI and FU-CBAM-Net).\nFigure 19: Contour map between predicted and ground-truth values for NACA4424 Re=2000 AOA=5\n◦. The black dashed line represents the ground-truth values, while the red dashed line represents the\npredicted values.\n21\nFigure 20 presents scatter density diagrams for u-velocity, v-velocity, and pressure co-\nefficient Cp. For u-velocity, v-velocity and Cp, the predicted and ground-truth values ex-\nhibit a diagonal distribution, indicating a strong correlation between them. Furthermore,\nprovide the MSE, MAE, and RMSE values between the predicted results of FU-CBAM-\nNet and the computed results by PHengLEI. In Fig. 20(a), the u-velocity takes the values\nMSE = 1.506 × 10−5, MAE = 2.581 × 10−3, and RMSE = 3.881 × 10−3. For v-velocity\nin Fig. 20(b), the numerical values are MSE = 8.443 × 10−6, MAE = 1.965 × 10−3,\nand RMSE = 2.906 × 10−3. Pressure coefficient Cp corresponds to the values MSE =\n1.009 × 10−5, MAE = 2.197 × 10−3, and RMSE = 3.176 × 10−3. Above results fur-\nther emphasizes that FU-CBAM-Net not only achieves good predictive accuracy but also\ndemonstrates excellent generalization.\n0.2\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nPHengLEI\n0.2\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nFU-CBAM-Net\nMSE = 1.506e\n05\nMAE = 2.581e\n03\nRMSE = 3.881e\n03\nu-velocity\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(a) u-velocity\n0.6\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\nPHengLEI\n0.6\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\nFU-CBAM-Net\nMSE = 8.443e\n06\nMAE = 1.965e\n03\nRMSE = 2.906e\n03\nv-velocity\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(b) v-velocity\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\nPHengLEI\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\nFU-CBAM-Net\nMSE = 1.009e\n05\nMAE = 2.197e\n03\nRMSE = 3.176e\n03\nCp\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(c) Cp\nFigure 20: Scatter density diagram between PHengLEI and FU-CBAM-Net for NACA4424 Re=2000\nAOA=5◦.\nFigure 21 further utilizes a Taylor diagram to showcase the correlation coefficient,\nCRMSE, and standard deviation between the predicted values of the neural network\nmodel FU-CBAM-Net and the ground-truth values. The test results from Fig. 21 reveal\nthat for velocity components u, v, and pressure coefficient Cp, the correlation coefficients\nare all close to 1, and the CRMSE values are close to 0. This indicates a strong correlation\nand minimal error between the predicted results and the ground-truth values.\nFigure 22 provides fitting curves of velocity profiles at various stations on the airfoil\nsurface and fitting curves of pressure coefficient Cp between predicted values and ground-\ntruth values. From the test results, both the predictive curves of FU-CBAM-Net and the\ncomputed curves of PHengLEI show a strong fit, further indicating the high predictive\naccuracy achieved by the FU-CBAM-Net neural network model.\nHere, only the test\nresults for the NACA2415 Re=1600 AOA=3◦and NACA4424 Re=2000 AOA=5◦cases are\nprovided. For additional test results, please refer to Appendix B.\n22\n0.0\n0.5\n1.0\n0.0\n0.5\n1.0\nStandard Deviation\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0.99\n0.95\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nCo\nr r\ne l\na t\ni o\nn  \nCo\ne f\nf i\nc i\nen\nt\nR\nM\nS\nD\n(a) u-velocity\n0.0\n0.2\n0.4\n0.0\n0.2\n0.4\nStandard Deviation\n0.0\n0.1\n0.2\n0.3\n0.4\n1\n0.99\n0.95\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nCo\nr r\ne l\na t\ni o\nn  \nCo\ne f\nf i\nc i\nen\nt\nR\nM\nS\nD\n(b) v-velocity\n0.0\n0.5\n1.0\n0.0\n0.5\n1.0\nStandard Deviation\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0.99\n0.95\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nCo\nr r\ne l\na t\ni o\nn  \nCo\ne f\nf i\nc i\nen\nt\nR\nM\nS\nD\n(c) Cp\nFigure 21: Taylor diagram between PHengLEI and FU-CBAM-Net for NACA4424 Re=2000 AOA=5◦.\nu-velocity\ny\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nFU-CBAM-Net\nPHengLEI\nx/c=0.2\nu-velocity\ny\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\nFU-CBAM-Net\nPHengLEI\nx/c=0.8\nu-velocity\ny\n0\n0.5\n1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\nFU-CBAM-Net\nPHengLEI\nx/c=0.4\nx/c\nCp\n-0.15\n0\n0.15\n0.3\n0.45\n0.6\n0.75\n0.9\n-0.8\n-0.6\n-0.4\n-0.2\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\nPHengLEI\nFU-CBAM-Net\nFigure 22: Comparison between various velocity profiles and pressure coefficient for the reconstructed\nflow field and the ground-truth data. (a) velocity profiles. (b) Cp.\nTable 3 further compares the computational times of PHengLEI and the FU-CBAM-\nNet neural network model for various test cases. From the test results, it can be concluded\nthat utilizing a well-trained neural network model achieves a three-order-of-magnitude ac-\nceleration compared to traditional CFD computational methods. Additionally, compared\nto traditional CFD computation methods, the trained deep learning model has a smaller\nmemory footprint, allowing for cross-platform development, easy portability, and rapid\ndeployment.\nTable 3: FU-CBAM-Net and PHengLEI Computational Efficiency Comparison\nPHengLEI\nFU-CBAM-Net\nNACA2415\nRe=1600 AOA=3 ◦\n2244s\n0.565s\nNACA4424\nRe=2000 AOA=5◦\n2293s\n0.582s\nNACA2424\nRe=1200 AOA=1◦\n2237s\n0.578s\nNACA0018\nRe=1800 AOA=3◦\n2281s\n0.573s\n23\n4.3. Discussion of PHengLEI calculation results\nAlthough deep learning-based methods for predicting flow fields have made some\nprogress in recent years, researchers still consider them as opaque black-box models. The\nfundamental reason is the lack of reliable posterior credibility assessment strategies for\nthe predicted results of flow fields. For this purpose, we propose a novel credibility as-\nsessment method for the predicted results of neural network models. By embedding the\nflow field prediction results of the deep learning model into the PHengLEI solver, we aim\nto enhance the credibility of the flow field predictions. Additionally, incorporating con-\nverged solutions of the flow field into the solver can further accelerate the computational\nspeed of the PHengLEI solver. Here, we investigate the flow field posterior methods using\nthe PHengLEI solver and the iterative solution acceleration efficiency using FU-CBAM-\nNet neural network, focusing on the NACA2415 Re=1600 AOA=3◦and the NACA4424\nRe=2000 AOA=5◦cases as studied in Section 4.2.\nFigure 23 presents the average residual convergence curves between the PHengLEI and\nthe AI+PHengLEI (utilizing the predictions of FU-CBAM-Net as initial values for itera-\ntive solving of the NS equations with PHengLEI) for the NACA2415 Re=1600 AOA=3 ◦.\nHere, considering e-10 as the residual convergence reference denoted as F, when PHengLEI\nconverges to F, it takes 7030 iterations and 18.078 minutes. However, for AI+PHengLEI,\nconvergence to F takes 3.114 minutes and 1970 iterations. Compared to PHengLEI, the\nAI+PHengLEI method reduces the number of iterations by 3.57 times and shortens the\niteration time by 5.81 times. Additionally, from the comparison curves of lift and drag\nin Fig. 24, it can be observed that traditional CFD methods exhibit varying degrees of\noscillations in both lift and drag values during the initial stages of the iterative solving\nprocess. However, in contrast, the AI+PHengLEI method shows rapid convergence in\nboth lift and drag values, almost forming a straight line even during the initial stages\nof computation. These test results further indicate that the flow field solution obtained\nthrough FU-CBAM-Net prediction satisfies the NS equations.\nTo assess the generalization of the FU-CBAM-Net neural network model, Fig.\n25\nand Fig. 26 presents the comparative results of residual convergence curves and lift/drag\ncurves between PHengLEI and AI+PHengLEI methods during the flow field solution\nprocess for the NACA4424 Re=2000 AOA=5◦.\nAs shown in Fig.\n25, similar to the\ntest case for NACA2415 Re=1600 AOA=3 ◦. Here, F is still used as the benchmark\n24\niter\naverageRes\n10\n0\n10\n1\n10\n2\n10\n3\n10\n4\n10\n5\n10\n6\n10\n7\n10\n8\n10\n-12\n10\n-10\n10\n-8\n10\n-6\n10\n-4\n10\n-2\nPHengLEI\nAI+PHengLEI\nIter: 1970\nTime: 3.114m\nIter: 7030\nTime: 18.078m\nNACA2415 Re=1600 AOA=3\no\n10\n3\n10\n4\n10\n5\n10\n-12\n10\n-11\n10\n-10\n10\n-9\n7.434e-11\n1.434e-12\nFigure 23: Average residual convergence curves between the PHengLEI solver and the solver embedded\nwith the FU-CBAM-Net neural network model for the NACA2415 Re=1600 AOA=3◦.\niter\nCl\n0\n2000\n4000\n6000\n8000\n10000 12000 14000 16000\n-0.8\n-0.6\n-0.4\n-0.2\n0\n0.2\n0.4\n0.6\n0.8\nPHengLEI\nAI+PHengLEI\nNACA2415 Re=1600 AOA=3\no\niter\nCd\n0\n2000\n4000\n6000\n8000 10000 12000 14000 16000\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\nPHengLEI\nAI+PHengLEI\nNACA2415 Re=1600 AOA=3\no\nFigure 24: Convergence curves for lift and drag during the iterative solving process for PHengLEI and\nAI+PHengLEI methods.\nfor residual convergence. For the traditional PHengLEI solver, when converging to the\nbenchmark F, it took 35.034 minutes and a total of 13190 iterations. However, for the\naccelerated PHengLEI solver with FU-CBAM-Net, it took 4.488 minutes with only 2820\niterations.\nCompared to the PHengLEI, the AI+PHengLEI method improved solving\nspeed by 7.806 times and reduced the number of iterations by 4.677 times. Moreover,\nunder the same number of iterations, the residual of AI+PHengLEI is approximately one\norder of magnitude smaller than that of PHengLEI.\nFrom the lift and drag convergence curves in Fig. 26, it’s evident that the PHengLEI\nsolver exhibits significant oscillations in lift and drag values during the initial iterative\n25\nstages. However, by embedding an artificial intelligence model within the traditional CFD\nsolver, even during the initial iterations of the solver, convergence of values is achieved\nrapidly.\niter\naverageRes\n10\n0\n10\n1\n10\n2\n10\n3\n10\n4\n10\n5\n10\n6\n10\n7\n10\n8\n10\n-12\n10\n-10\n10\n-8\n10\n-6\n10\n-4\n10\n-2\nPHengLEI\nAI+PHengLEI\nIter: 13190\nTime: 35.034m\nIter: 2820\nTime: 4.488m\nNACA4424 Re=2000 AOA=5\no\n10\n3\n10\n4\n10\n5\n10\n-11\n10\n-10\n10\n-9\n10\n-8\n6.639e-10\n2.261e-11\nFigure 25: Average residual convergence comparison curves between the PHengLEI solver and the solver\nembedded with the FU-CBAM-Net neural network model for the NACA4424 Re=2000 AOA=5◦.\niter\nCl\n0\n3000\n6000\n9000\n12000\n15000\n-1.2\n-0.8\n-0.4\n0\n0.4\n0.8\n1.2\n1.6\nPHengLEI\nAI+PHengLEI\nNACA4424 Re=2000 AOA=5\no\niter\nCd\n0\n3000\n6000\n9000\n12000\n15000\n-0.2\n0\n0.2\n0.4\n0.6\n0.8\n1\nPHengLEI\nAI+PHengLEI\nNACA4424 Re=2000 AOA=5\no\nFigure 26: Convergence curves for lift and drag during the iterative solving process for PHengLEI and\nAI+PHengLEI methods.\n5. Conclusions\nIn this work, we proposed an enhanced UNet neural network model (FU-CBAM-\nNet) for rapid flow field prediction. Creatively, we integrated deep learning-based flow\nfield prediction results into the PHengLEI software, establishing credibility validation for\nthe predicted flow fields. FU-CBAM-Net’s predictive accuracy and generalization were\n26\nassessed across 24 NACA series airfoils under diverse operating conditions. The primary\nconclusions of this study are as follows:\n1. Incorporating channel attention and spatial attention modules into the downsam-\npling process of the conventional UNet neural network model significantly reduces\nmodel training loss and enhances the precision of flow field predictions.\n2. For individual airfoil flow fields, the prediction efficiency of the FU-CBAM-Net\nneural network model is three orders of magnitude faster than traditional CFD\ncomputational methods like PHengLEI.\n3. Under given convergence criteria, embedding the prediction values of the FU-CBAM-\nNet deep learning model into the CFD computational process achieves an accelera-\ntion of at least five times and reduces iteration counts by over threefold. Conversely,\nthe aforementioned test results confirm the credibility of the flow field solution pre-\ndicted by FU-CBAM-Net, adhering to the NS physical equations.\nCompared to most existing studies [59, 60], this paper not only validates the potential\nof deep learning methods for accelerating airfoil physical field solutions but also demon-\nstrates that deep learning models, through a more granular feature fusion strategy, can\nsimulate complex separated flows. This introduces an innovative method for traditional\nCFD technologies characterized by being time-consuming and memory-consuming.\nIn\nfuture work, we aim to extend our research into accelerating CFD solutions for three-\ndimensional complex flows using deep learning techniques.\nCRediT authorship contribution statement\nKuijun\nZuo : Data curation, Formal analysis, Investigation, Methodology, Software,\nValidation, Visualization, Writing-original draft, Writing-review & editing.\nZhengyin\nYe : Funding acquisition, Supervision, Resources, Project administration.\nShuhui\nBu : Methodology, Software, Writing-review & editing.\nXianxu\nYuan : Funding acquisition, Resources, Supervision.\nWeiwei\nZhang : Conceptualization, Methodology, Project administration, Supervi-\nsion, Writing-review & editing.\n27\nAcknowledgments\nThis work was supported by the National Natural Science Foundation of China (Grant\nNo. 12202470).\nDeclaration of competing interest\nThe authors declare that they are have no known competing financial interests or\npersonal relationships that could have appeared to influence the work reported in this\npaper.\nReferences\n[1] S. V. Ershkov, E. Y. Prosviryakov, N. V. Burmasheva, V. Christianto, Towards\nunderstanding the algorithms for solving the navier–stokes equations, Fluid Dynamics\nResearch 53 (4) (2021) 044501.\n[2] S. Pathak, V. Krishnaswamy, M. Sharma, Big data analytics capabilities: a novel\nintegrated fitness framework based on a tool-based content analysis, Enterprise In-\nformation Systems 17 (1) (2023) 1939427.\n[3] S. Barrachina, A. Castell´o, M. F. Dolz, T. M. Low, H. Mart´ınez, E. S. Quintana-Ort´ı,\nU. Sridhar, A. E. Tom´as, Reformulating the direct convolution for high-performance\ndeep learning inference on arm processors, Journal of Systems Architecture 135 (2023)\n102806.\n[4] E. I. Basri, A. A. Basri, K. A. Ahmad, Computational fluid dynamics analy-\nsis in biomimetics applications: A review from aerospace engineering perspective,\nBiomimetics 8 (3) (2023) 319.\n[5] B. Liu, S. Park, Cfd simulations of the effects of wave and current on power per-\nformance of a horizontal axis tidal stream turbine, Journal of Marine Science and\nEngineering 11 (2) (2023) 425.\n[6] K. Vimalakanthan, H. van der Mijle Meijer, I. Bakhmet, G. Schepers, Computational\nfluid dynamics (cfd) modeling of actual eroded wind turbine blades, Wind Energy\nScience 8 (1) (2023) 41–69.\n28\n[7] P. Bandi, N. P. Manelil, M. Maiya, S. Tiwari, T. Arunvel, Cfd driven prediction\nof mean radiant temperature inside an automobile cabin using machine learning,\nThermal Science and Engineering Progress 37 (2023) 101619.\n[8] C. Jiangtao, X. Wei, Z. Wei, Z. Peihong, Y. Fujun, J. Tao, G. Yongyan, W. Xiaojun,\nC. Jianqiang, W. Ruili, et al., Advances in verification and validation in computa-\ntional fluid dynamics, Advances in Mechanics 53 (2023) 1–35.\n[9] A. W. Cary, J. Chawner, E. P. Duque, W. Gropp, W. L. Kleb, R. M. Kolonay,\nE. Nielsen, B. Smith, Cfd vision 2030 road map: Progress and perspectives, in:\nAIAA Aviation 2021 Forum, 2021, p. 2726.\n[10] A. Gruber, M. Gunzburger, L. Ju, Z. Wang, A comparison of neural network ar-\nchitectures for data-driven reduced-order modeling, Computer Methods in Applied\nMechanics and Engineering 393 (2022) 114764.\n[11] Z. Dar, J. Baiges, R. Codina, Artificial neural network based correction for reduced\norder models in computational fluid mechanics, Computer Methods in Applied Me-\nchanics and Engineering 415 (2023) 116232.\n[12] E. H. Dowell, Eigenmode analysis in unsteady aerodynamics-reduced-order models,\nAIAA journal 34 (8) (1996) 1578–1583.\n[13] P. J. Schmid, Dynamic mode decomposition of numerical and experimental data,\nJournal of fluid mechanics 656 (2010) 5–28.\n[14] C. Cao, C. Nie, S. Pan, J. Cai, K. Qu, A constrained reduced-order method for fast\nprediction of steady hypersonic flows, Aerospace Science and Technology 91 (2019)\n679–690.\n[15] L. Wu, K. Chen, C. Zhan, Snapshot pod analysis of transient flow in the pilot stage\nof a jet pipe servo valve, Journal of Turbulence 19 (10) (2018) 889–909.\n[16] P. J. Schmid, Application of the dynamic mode decomposition to experimental data,\nExperiments in fluids 50 (2011) 1123–1130.\n[17] X. Zhang, T. Ji, F. Xie, H. Zheng, Y. Zheng, Unsteady flow prediction from sparse\nmeasurements by compressed sensing reduced order modeling, Computer Methods in\nApplied Mechanics and Engineering 393 (2022) 114800.\n29\n[18] J. N. Kutz, Deep learning in fluid dynamics, Journal of Fluid Mechanics 814 (2017)\n14.\n[19] C.-Y. Wang, A. Bochkovskiy, H.-Y. M. Liao, Yolov7: Trainable bag-of-freebies sets\nnew state-of-the-art for real-time object detectors, in: Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition, 2023, pp. 7464–7475.\n[20] Y. Zhang, T. Wang, X. Zhang, Motrv2: Bootstrapping end-to-end multi-object track-\ning by pretrained object detectors, in: Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, 2023, pp. 22056–22065.\n[21] W. Hariri, Unlocking the potential of chatgpt: A comprehensive exploration of its\napplications, advantages, limitations, and future directions in natural language pro-\ncessing, arXiv preprint arXiv:2304.02017 (2023).\n[22] R. Tinn, H. Cheng, Y. Gu, N. Usuyama, X. Liu, T. Naumann, J. Gao, H. Poon,\nFine-tuning large neural language models for biomedical natural language processing,\nPatterns 4 (4) (2023).\n[23] S. Teng, X. Hu, P. Deng, B. Li, Y. Li, Y. Ai, D. Yang, L. Li, Z. Xuanyuan, F. Zhu,\net al., Motion planning for autonomous driving: The state of the art and future\nperspectives, IEEE Transactions on Intelligent Vehicles (2023).\n[24] K. Chitta, A. Prakash, B. Jaeger, Z. Yu, K. Renz, A. Geiger, Transfuser: Imitation\nwith transformer-based sensor fusion for autonomous driving, IEEE Transactions on\nPattern Analysis & Machine Intelligence 45 (11) (2023) 12878–12895.\n[25] C. Duru, H. Alemdar, O. U. Baran, A deep learning approach for the transonic flow\nfield predictions around airfoils, Computers and Fluids 236 (2022) 105312.\n[26] A. Gruber, M. Gunzburger, L. Ju, Z. Wang, A comparison of neural network ar-\nchitectures for data-driven reduced-order modeling, Computer Methods in Applied\nMechanics and Engineering 393 (2022) 114764.\n[27] C. Hu, S. Martin, R. Dingreville, Accelerating phase-field predictions via recurrent\nneural networks learning the microstructure evolution in latent space, Computer\nMethods in Applied Mechanics and Engineering 397 (2022) 115128.\n30\n[28] Z. Ma, Z. Ye, W. Pan, Fast simulation of particulate suspensions enabled by graph\nneural network, Computer Methods in Applied Mechanics and Engineering 400 (2022)\n115496.\n[29] G. Kissas, Y. Yang, E. Hwuang, W. R. Witschey, J. A. Detre, P. Perdikaris, Machine\nlearning in cardiovascular flows modeling: Predicting arterial blood pressure from\nnon-invasive 4d flow mri data using physics-informed neural networks, Computer\nMethods in Applied Mechanics and Engineering 358 (2020) 112623.\n[30] W. Li, M. Z. Bazant, J. Zhu, Phase-field deeponet: Physics-informed deep operator\nneural network for fast simulations of pattern formation governed by gradient flows\nof free-energy functionals, Computer Methods in Applied Mechanics and Engineering\n416 (2023) 116299.\n[31] M. Leer, A. M. Kempf, Fast flow field estimation for various applications with a\nuniversally applicable machine learning concept, Flow, Turbulence and Combustion\n107 (2020) 175 – 200.\n[32] D. . Sun, Z. . Wang, F. . Qu, J. . Bai, A deep learning based prediction approach for\nthe supercritical airfoil at transonic speeds, Physics of Fluids 33 (8) (2021) 086109.\n[33] C. Lav, A. J. Banko, F. Waschkowski, Y. Zhao, C. J. Elkins, J. K. Eaton, R. D.\nSandberg, A coupled framework for symbolic turbulence models from deep-learning,\nInternational Journal of Heat and Fluid Flow 101 (2023) 109140.\n[34] J. Weatheritt, R. Sandberg, A novel evolutionary algorithm applied to algebraic\nmodifications of the rans stressstrain relationship, Journal of Computational Physics\n325 (2016) 22–37.\n[35] C. Grabe, F. J¨ackel, P. Khurana, R. P. Dwight, Data-driven augmentation of a rans\nturbulence model for transonic flow prediction, International Journal of Numerical\nMethods for Heat & Fluid Flow 33 (4) (2023) 1544–1561.\n[36] W. Tenachi, R. Ibata, F. I. Diakogiannis, Deep symbolic regression for physics guided\nby units constraints: toward the automated discovery of physical laws, arXiv preprint\narXiv:2303.03192 (2023).\n31\n[37] C. Sabater, P. St¨urmer, P. Bekemeyer, Fast predictions of aircraft aerodynamics using\ndeep-learning techniques, AIAA Journal 60 (9) (2022) 5249–5261.\n[38] V. Sekar, Q. Jiang, C. Shu, B. C. Khoo, Fast flow field prediction over airfoils using\ndeep learning approach, Physics of Fluids 31 (5) (2019).\n[39] M. Leer, A. Kempf, Fast flow field estimation for various applications with a uni-\nversally applicable machine learning concept, Flow, Turbulence and Combustion 107\n(2021) 175–200.\n[40] X. Liu, W. Yao, W. Peng, W. Zhou, Bayesian physics-informed extreme learning\nmachine for forward and inverse pde problems with noisy data, Neurocomputing 549\n(2023) 126425.\n[41] K. Linka, A. Schfer, X. Meng, Z. Zou, G. E. Karniadakis, E. Kuhl, Bayesian physics\ninformed neural networks for real-world nonlinear dynamical systems, Computer\nMethods in Applied Mechanics and Engineering 402 (2022) 115346.\n[42] K. Zuo, S. Bu, W. Zhang, J. Hu, Z. Ye, X. Yuan, Fast sparse flow field prediction\naround airfoils via multi-head perceptron based deep learning architecture, Aerospace\nScience and Technology 130 (2022) 107942.\n[43] C. Duru, H. Alemdar, O. U. Baran, A deep learning approach for the transonic flow\nfield predictions around airfoils, Computers & Fluids 236 (2022) 105312.\n[44] C. Duru, H. Alemdar, ¨O. U. Baran, Cnnfoil: Convolutional encoder decoder modeling\nfor pressure fields around airfoils, Neural Computing and Applications 33 (12) (2021)\n6835–6849.\n[45] X. Guo, W. Li, F. Iorio, Convolutional neural networks for steady flow approximation,\nin: Proceedings of the 22nd ACM SIGKDD international conference on knowledge\ndiscovery and data mining, 2016, pp. 481–490.\n[46] N. Thuerey, K. Weißenow, L. Prantl, X. Hu, Deep learning methods for reynolds-\naveraged navier–stokes simulations of airfoil flows, AIAA Journal 58 (1) (2020) 25–36.\n[47] M. D. Ribeiro, A. Rehman, S. Ahmed, A. Dengel, Deepcfd: Efficient steady-state\nlaminar flow approximation with deep convolutional neural networks, arXiv preprint\narXiv:2004.08826 (2020).\n32\n[48] L.-W. Chen, N. Thuerey, Towards high-accuracy deep learning inference of compress-\nible flows over aerofoils, Computers & Fluids 250 (2023) 105707.\n[49] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomed-\nical image segmentation, in:\nMedical Image Computing and Computer-Assisted\nIntervention–MICCAI 2015: 18th International Conference, Munich, Germany, Oc-\ntober 5-9, 2015, Proceedings, Part III 18, Springer, 2015, pp. 234–241.\n[50] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, J. Liang, Unet++: Redesigning skip\nconnections to exploit multiscale features in image segmentation, IEEE transactions\non medical imaging 39 (6) (2019) 1856–1867.\n[51] H. Huang, L. Lin, R. Tong, H. Hu, Q. Zhang, Y. Iwamoto, X. Han, Y.-W. Chen,\nJ. Wu, Unet 3+: A full-scale connected unet for medical image segmentation, in:\nICASSP 2020-2020 IEEE international conference on acoustics, speech and signal\nprocessing (ICASSP), IEEE, 2020, pp. 1055–1059.\n[52] S. Woo, J. Park, J.-Y. Lee, I. S. Kweon, Cbam: Convolutional block attention mod-\nule, in: Proceedings of the European conference on computer vision (ECCV), 2018,\npp. 3–19.\n[53] P. A. Durbin, Some recent developments in turbulence closure modeling, Annual\nReview of Fluid Mechanics 50 (2018) 77–103.\n[54] Z. Zhong, Z. Laiping, H. Lei, H. Xianyao, G. Yongheng, X. Qingxin, Phenglei: A\nlarge scale parallel cfd framework for arbitrary grids, Chinese journal of computers\n42 (11) (2019) 2368–2383.\n[55] Z. Deng, J. Wang, H. Liu, H. Xie, B. Li, M. Zhang, T. Jia, Y. Zhang, Z. Wang,\nB. Dong, Prediction of transonic flow over supercritical airfoils using geometric-\nencoding and deep-learning strategies, arXiv preprint arXiv:2303.03695 (2023).\n[56] M. Yin, P. Wang, C. Ni, W. Hao, Cloud and snow detection of remote sensing images\nbased on improved unet3+, Scientific Reports 12 (1) (2022) 14415.\n[57] J. Hu, W. Zhang, Flow field modeling of airfoil based on convolutional neural net-\nworks from transform domain perspective, Aerospace Science and Technology 136\n(2023) 108198.\n33\n[58] C. Sabater, P. St¨urmer, P. Bekemeyer, Fast predictions of aircraft aerodynamics using\ndeep-learning techniques, AIAA Journal 60 (9) (2022) 5249–5261.\n[59] M. Tang, Y. Liu, L. J. Durlofsky, Deep-learning-based surrogate flow modeling and\ngeological parameterization for data assimilation in 3d subsurface flow, Computer\nMethods in Applied Mechanics and Engineering 376 (2021) 113636.\n[60] L. Sun, H. Gao, S. Pan, J.-X. Wang, Surrogate modeling for fluid flows based on\nphysics-constrained deep learning without simulation data, Computer Methods in\nApplied Mechanics and Engineering 361 (2020) 112732.\n[61] K. E. Taylor, Summarizing multiple aspects of model performance in a single diagram,\nJournal of geophysical research: atmospheres 106 (D7) (2001) 7183–7192.\n34\nAppendix A. Taylor diagram\nThe Taylor diagram represents evaluation indicators such as the correlation coefficient,\ncentered root-mean-square error (CRMSE), and standard deviation of a tested model on\nthe same polar coordinate diagram. As shown in Fig. A.1, the three evaluation indicators\nsatisfy the following cosine relationship:\nE\n′2 = σ2\np + σ2\nt −2σ2\npσ2\nt R\n(A.1)\n1\ncos\nR\n\np\n\nT\n\n'E\nFigure A.1: Geometric relationship between the correlation coefficient, CRMSE, and standard deviation.\nIn Eq. (A.1), σp and σt are the standard deviations of the predicted values and the\nground-truth values, respectively. The calculation formula is as follows:\nσκ =\n\"\n1\nN\nN\nX\ni=1\n(κi −¯κ)2\n# 1\n2\n, κ = p, t.\n(A.2)\nIn the above formula, ¯κ represents the mean values of either the ground-truth or\npredicted values.\nMoreover, in Eq. (A.1), R and E represent the correlation coefficient and CRMSE,\nrespectively. The calculation formula for the correlation coefficient R is given as follows:\nR =\n1\nN\nPN\ni=1 (pi −¯p) (ti −¯t)\nσpσt\n(A.3)\nwhere ¯p and ¯t are the mean values of predicted values p and ground-truth data t.\nAdditionally, the root-mean-square error (RMSE) is defined as:\nE =\n\"\n1\nN\nN\nX\ni=1\n(pi −ti)2\n# 1\n2\n(A.4)\nIn literature [61], the RMSE is decomposed into two parts, overall bias ¯E and CRMSE\nE\n′. These two parameters are defined as:\n35\n\n\n\n\n\n\n\n\n\n¯E = ¯p −¯t,\nE′ =\n(\n1\nN\nN\nX\ni=1\n[(pi −¯p) −(ti −¯t)]2\n)1/2\n(A.5)\nAdditionally, the amalgamation of these two elements results in a quadratic accumu-\nlation, yielding the comprehensive mean square difference:\nE2 = ¯E2 + E′2\n(A.6)\n36\nAppendix B. FU-CBAM-Net flow field prediction results\nFU-CBAM-Net  -  PHengLEI\nPHengLEI\nFU-CBAM-Net\nNACA0008  Re=1000  AOA=4\nNACA0018  Re=1800  AOA=3\nNACA2424  Re=1200  AOA=1\nFigure B.1: Predicted results of different airfoil flow fields.\n37\n",
  "categories": [
    "physics.flu-dyn"
  ],
  "published": "2023-12-07",
  "updated": "2023-12-07"
}