{
  "id": "http://arxiv.org/abs/2312.07248v1",
  "title": "Multi-Granularity Framework for Unsupervised Representation Learning of Time Series",
  "authors": [
    "Chengyang Ye",
    "Qiang Ma"
  ],
  "abstract": "Representation learning plays a critical role in the analysis of time series\ndata and has high practical value across a wide range of applications.\nincluding trend analysis, time series data retrieval and forecasting. In\npractice, data confusion is a significant issue as it can considerably impact\nthe effectiveness and accuracy of data analysis, machine learning models and\ndecision-making processes. In general, previous studies did not consider the\nvariability at various levels of granularity, thus resulting in inadequate\ninformation utilization, which further exacerbated the issue of data confusion.\nThis paper proposes an unsupervised framework to realize multi-granularity\nrepresentation learning for time series. Specifically, we employed a\ncross-granularity transformer to develop an association between fine- and\ncoarse-grained representations. In addition, we introduced a retrieval task as\nan unsupervised training task to learn the multi-granularity representation of\ntime series. Moreover, a novel loss function was designed to obtain the\ncomprehensive multi-granularity representation of the time series via\nunsupervised learning. The experimental results revealed that the proposed\nframework demonstrates significant advantages over alternative representation\nlearning models.",
  "text": "arXiv:2312.07248v1  [cs.LG]  12 Dec 2023\nMulti-Granularity Framework for Unsupervised\nRepresentation Learning of Time Series\nChengyang Ye1[0000−0002−3706−8805] and Qiang Ma2[0000−0003−3430−9244]\n1 Graduate School of Informatics, Kyoto University, Kyoto, Japan\n2 Graduate School of Science and Technology, Kyoto Institute of Technology, Kyoto,\nJapan\nye.chengyang.67x@st.kyoto-u.ac.jp\nqiang@i.kyoto-u.ac.jp\nAbstract. Representation learning plays a critical role in the analysis of\ntime series data and has high practical value across a wide range of appli-\ncations. including trend analysis, time series data retrieval and forecast-\ning. In practice, data confusion is a signiﬁcant issue as it can considerably\nimpact the eﬀectiveness and accuracy of data analysis, machine learn-\ning models and decision-making processes. In general, previous studies\ndid not consider the variability at various levels of granularity, thus re-\nsulting in inadequate information utilization, which further exacerbated\nthe issue of data confusion. This paper proposes an unsupervised frame-\nwork to realize multi-granularity representation learning for time series.\nSpeciﬁcally, we employed a cross-granularity transformer to develop an\nassociation between ﬁne- and coarse-grained representations. In addition,\nwe introduced a retrieval task as an unsupervised training task to learn\nthe multi-granularity representation of time series. Moreover, a novel loss\nfunction was designed to obtain the comprehensive multi-granularity rep-\nresentation of the time series via unsupervised learning. The experimen-\ntal results revealed that the proposed framework demonstrates signiﬁcant\nadvantages over alternative representation learning models.\nKeywords: Unsupervised representation learning · Multi-granularity ·\nTime series.\n1\nIntroduction\nTime series is a traditional and important type of data that is ubiquitous in\nnumerous ﬁelds. Signiﬁcant progress in the widespread use of sensors and social\nproduction activities has further promoted the development of time series data\nsuch as electrocardiograms (ECG) [1] and daily stock prices [2]. With the de-\nvelopment of machine learning and data mining, representation learning, which\ncan reveal hidden information in time series by establishing high-dimensional\nrepresentations, has been increasingly applied to the ﬁeld of time series.\nHowever, despite the recent challenges and advancements made by deep\nlearning models in tasks such as prediction and classiﬁcation, the dominant posi-\ntion of representation learning methods in time series has yet to be established, in\n2\nChengyang Ye\nand Qiang Ma\nNormal \nAbnormal\nData from public dataset\n(a)\nData from real-world\nAbnormal (with noise)\nNormal (with noise)\n(b)\nNormal (with confusion)\nAlmost abnormal part\nAbormal (with confusion)\nAlmost normal part\n(c)\nFig. 1. Example of ECG data from public dataset and real-world. These ﬁgures present\nseveral issues of data quality in real-world ECG data.\ncontrast to ﬁelds such as computer vision (CV) [3] and natural language process-\ning (NLP) [4]. In particular, non-deep learning methods, such as HIVE-COTE\n[5] and TS-CHIEF [6], provide unique advantages.\nAlthough multiple time series representation methods achieve adequate re-\nsults on public datasets, in real-world application scenarios, time series data\nare generally subject to missing data, noise data, and data confusion, among\nother adverse conditions. Fig. 1 presents a typical example of this issue in ECG\ndata. In public datasets designed for model training, the ECG data contain\nmore typical class features (normal and abnormal), without noise or confusion\n(as shown in Fig. 1(a)). However, in practice, the time series data quality is\ndiﬀerent. Noise is a common problem in real-world applications, as illustrated\nin Fig. 1(b), which can have several negative eﬀects on data analysis, including\nreduced accuracy and misleading conclusions. In addition, data confusion is a\nmore signiﬁcant issue, as it can considerably impact the eﬀectiveness and accu-\nracy of data analysis. Data confusion refers to cases wherein data from diﬀerent\ncategories, sources, or contexts is mixed or entangled, thus making it diﬃcult to\ndiscern clear patterns, relationships, or structures within the data. Considering\nthe ECG data as an example, overlapping or ambiguous morphologies frequently\nappear in real-world data (as shown in Fig. 1(c)). Electrocardiograms data from\ndiﬀerent cardiac conditions may exhibit similar or overlapping morphologies,\nwhich makes it challenging to distinguish between them. For example, certain\ntypes of arrhythmias may appear similar to a normal sinus rhythm, thus leading\nto data confusion.\nTo address this issue, multiple studies comprehensively considered represen-\ntations of time series at diﬀerent granularity, i.e., multi-granularity methods [7].\nAn simple example of a multi-granularity method is sales reports that includes\ndata at both the individual transaction and aggregate levels such as monthly or\nyearly totals. By capturing information from multiple scales or levels of detail,\nthese approaches improve the robustness and accuracy of the analysis and inter-\nTitle Suppressed Due to Excessive Length\n3\npretation of time series data. Although multi-granularity representations provide\nmore information, information redundancy is generally observed between diﬀer-\nent granularities. This redundancy can potentially lead to increased computa-\ntional complexity, and render the analysis and interpretation of time series data\nmore challenging. Moreover, numerous existing multi-granularity methods are\nfocused primarily on the simple fusion of decision results, and generally require\nthe re-design of representation models. Consequently, they cannot utilize exist-\ning, well-performing representation methods and lack the ﬂexibility to adapt to\ndiﬀerent scenarios.\nThis paper proposes a novel unsupervised learning framework named MUG\n(for MUlti-Granularity), which combines the multi-granularity features of time\nseries based on existing representation learning research. The proposed general\nframework integrates two diﬀerent granularities of time series representation\nmethods: a ﬁne-grained representation method, which represents timestamp-\nlevel time series data, and a coarse-grained representation method, which rep-\nresents segment-level time series data. Speciﬁcally, for the multiple ﬁne-grained\ntime series representation results, we employed a vector fusion method based\non attention mechanism to obtain a comprehensive representation. In addition,\nbased on multi-modal fusion techniques, we employed a cross-granularity at-\ntention mechanism to map of coarse-grained representations onto ﬁne-grained\nrepresentations. This allowed for the fusion of the overall features in the coarse-\ngrained representations with the detailed information in the ﬁne-grained rep-\nresentations. Finally, based on the retrieval task, we designed a more suitable\ntraining method for the multi-granularity time series representation learning.\nThe main contributions of this study are as follows:\n- This paper presents a focused study on the transformer-based fusion model\nof multi-granularity representation for time series data. In particular, this\npaper proposes a novel unsupervised learning framework (Section 3.1) to\nbuild association between timestamp-level and segment-level features.\n- We developed an unsupervised training method (Section3.3). In particular, a\nretrieval task for the time series data with a unique loss function was designed\nto obtain the comprehensive multi-granularity representation of time series\nvia unsupervised training.\n- We conducted extensive experiments on several public datasets from diﬀerent\nﬁelds and real-world datasets (Section 4). In comparison with other baseline\nalgorithms, the proposed MUG model achieved an improved performance.\nThe remainder of this paper is organized as follows: Section 2 outlines pre-\nvious studies on representation learning for time series, in addition to multi-\ngranularity representation methods for time series from the existing literature.\nSection 3 presents the architecture of the proposed framework in detail. There-\nafter, Section 4 presents the experimental results, followed by a summary of\nconclusions in Section 5.\n4\nChengyang Ye\nand Qiang Ma\nTime Series Data\nFine-Grained\nCoarse-Grained\n...\n...\n...\n...\n...\n...\n...\n...\n...\nFine-Grained Representation\n(Timestamp-Level)\nCoarse-Grained Representation\n(Segment-Level)\n...\n...\n...\n...\n...\n...\nFig. 2. Main diﬀerences between ﬁne-grained representation learning and coarse-\ngrained representation learning of time series.\n2\nRelated Work\n2.1\nRepresentation Learning of Time Series\nThe representation learning of time series data has attracted considerable re-\nsearch attention in recent years. The primary objective of these models is to\nidentify spatio-temporal dependencies in the data, which can help uncover the\nunderlying patterns, trends, and relationships that can be used for various tasks,\nsuch as forecasting, classiﬁcation, and anomaly detection.\nAccording to representation granularity, the existing representation learning\nmodels of time series can be broadly classiﬁed into two categories: coarse- and\nﬁne-grained representation methods. The diﬀerences between the two types are\nshown in Fig. 2.\nFine-grained representation, i.e., timestamp-level representation learning, is\nthe most traditional concept for the representation learning of time series. The\nobjective of this method is to capture the relationships and dependencies be-\ntween the diﬀerent dimensions of the time series data at each point in time.\nTime2Vec (T2V) [8] is a typical timestamp-level representation learning method\ndeveloped to capture temporal patterns and dependencies within the data. This\nmethod is based on Word2Vec [9]. However, T2V may require detailed hyper-\nparameter tuning to achieve an optimal performance. Selecting the appropri-\nate dimensions for continuous vector representations, an appropriate learning\nrate, and determining the appropriate context window size can be challenging\nand time-consuming. Compared with T2V, The Time Series Transformer (TST)\nmodel [10] provides more advantages. The TST model is a deep learning-based\napproach for time series analysis that leverages the transformer architecture [11],\noriginally designed for NLP tasks. The transformer architecture is known for its\nself-attention mechanism [12], which can capture complex dependencies and pat-\nterns within sequences. The TST model can be used for various time series tasks,\nsuch as forecasting, classiﬁcation, anomaly detection, and feature extraction.\nTitle Suppressed Due to Excessive Length\n5\nCoarse-grained representation is referred to as as segment-level representa-\ntion learning, i.e., learning representations for segments or subseries within an\nentire time series. These methods are focused on capturing global patterns and\nlong-range dependencies in time series data, which can be beneﬁcial for various\ntasks wherein the focus is on understanding local patterns and range dependen-\ncies in the data. The symbolic aggregate approximation (SAX)-based method\n[13] is a widely-used method for time series data representation and dimen-\nsionality reduction. In particular, it converts a continuous-valued time series\ninto a discrete, symbolic representation while preserving the essential shape and\ntrends of the original data. The SAX-based method can reduce the storage re-\nquirements with lower computational complexity. Additionally, the SAX-based\nmethod can be readily extended or combined with other techniques, such as\nindexable SAX (iSAX) [14] or multivariate SAX (MSAX) [15]. However, the di-\nmensional reduction and discretization process of the SAX-based method may\nresult in information loss. The Shapelet-based methods, such as ShapeNet [16],\nmay be the most advanced segment-level representation learning method. These\ntechniques are focused on identiﬁcation of discriminant sub-sequences in time\nseries data, which can be useful for tasks such as classiﬁcation and anomaly\ndetection. However, the computational complexity of shapelet discovery can be\nhigh, particularly for large datasets and long time series.\n2.2\nMulti-Granularity Representation Methods for Time Series\nBoth coarse- and ﬁne-grained representation learning have advantages and ap-\nplicability scenarios that render them suitable for diﬀerent types of time series\nanalysis tasks. Within this context, the majority of existing studies were focused\non a single granularity, and methods are developed based on a speciﬁc level of de-\ntail in time series data with the objective of predicting the labels corresponding\nto the granularity.\nHowever, in general, selecting the appropriate granularity for diﬀerent tasks\nis a challenge that signiﬁcantly depends on experience. Multi-granularity repre-\nsentations allow for information to be obtained from various perspectives within\ntime series data, thus providing a more comprehensive understanding of the un-\nderlying patterns and structures. For example, in the analysis of stock market\ndata, ﬁne-grained representation learning methods can analyze high-frequency\ndata such as intraday price movements. This helps to identify short-term trends\nand patterns. Coarse-granularity representations, such as daily or weekly price\nmovements, can be useful for identifying long-term trends and patterns in the\nstock market, such as the overall market direction, support and resistance levels,\nand seasonal trends. Therefore, an increasing number of previous studies [17] [18]\nwere focused tend on multi-granularity representation learning.\nThe multi-granularity substructure-aware representation learning algorithm\nfor time series (MS-SRALAT [19]) is an advanced semantic representation of\na symbol sequence that is generated corresponding to a time series by an ap-\nproximation algorithm that can capture the structure of the original data. In\nparticular, it is a quite concise and easily implementable method that utilizes\n6\nChengyang Ye\nand Qiang Ma\nthe SAX and produces the representation of a time series by transforming the\ntarget time series into an SAX sentence and aggregating those embeddings of\nthe SAX words in the SAX sentences. However, the SAX information in this\nframework cannot reveal meaningful semantic information, which limits its per-\nformance.\n3\nMethodology\n3.1\nOverview\nThis section presents the proposed MUG framework and the relevant algorithms\nare described. The structure of the MUG is shown in Fig. 3. Each training\nsample X ∈Rw×m, which is a time series of length w and m diﬀerent variables,\nconstitutes a sequence of w time series xt ∈Rm : X ∈Rw×m = [x1, x2, ..., xw].\nMoreover, for each segment Si ∈X in the time series, Si = [xi,1, xi,2, ..., xi,j],\nwhich implies that segment Si has j timestamp points in the time series.\nFirst, for each segment Si, the proposed framework employs two diﬀerent rep-\nresentation learning algorithms for the coarse- and ﬁne-grained time series data,\nthus constructing two distinct feature vectors. Using both granularities, the ob-\njectives of the model is to capture the diﬀerent levels of the information present in\nthe time series data, thus providing a more comprehensive representation. Fine-\ngrained representations focus on local patterns and detailed information within\nthe data, whereas coarse-grained representations capture the high-level patterns\nand global structures in the data. Thereafter, for the fusion of ﬁne-grained repre-\nsentation of time series, a variant of the attention mechanisms was employed to\ncombined the features of each timestamp-level representation of the time series,\nTimestamp-Level \nRepresentation Learning\nTime Series Data\nSegment-Level \nRepresentation Learning\n...\nFine-Grained \nRepresentation\nCoarse-Grained \nRepresentation\nFine-Grained Fusion\nMulti-Granularity Representation\nUnsupervised Learning\nCross-Granularity \nTransformer\nCross-Granularity Attention\nAdd & Norm\nAdd & Norm\nFeed Forward\nMulti-Granularity \nRepresentation\nCross-Granularity Transformer\nUnsupervised Learning\n...\nAvgpolling\nBatch of Multi-Granularity \nRepresentation\nRetrieval Task\n...\nMaxpolling\nAttention\nFine-Grained Fusion\nFig. 3. Middle: The structure of unsupervised multi-granularity representation learn-\ning for time series. Left: Details of cross-granularity transformer. Right: Details of\nthe ﬁne-grained fusion and retrieval-based unsupervised learning.\nTitle Suppressed Due to Excessive Length\n7\nand generate a more comprehensive representation vector to represent the ﬁne-\ngrained information in certain segments of the time series. Moreover, for coarse-\ngrained representations, a cross-granularity transformer with cross-granularity\nattention mechanism was employed to map coarse-grained representations onto\nﬁne-grained representations. Finally, with focus on the demand for unsupervised\nlearning in multi-granularity representation learning, a retrieval-based task was\nselected as the training task for unsupervised learning. Based on the character-\nistics of the retrieval task, a novel loss function was designed to improve the\nperformance of the training model.\n3.2\nFine-Grained Fusion\nThe structure of the ﬁne-grained fusion is shown at the bottom right of Fig. 3.\nThis part is based on a variant of the attention mechanism, which was ﬁrst de-\nsigned as an NLP model for multi-granularity relation extraction [20]. This type\nof attention mechanism helps the model combine the feature information from\neach inputs, which is suitable for the multi-granularity representation learning\nframework, in the stage of representing the comprehensive feature vector of the\nﬁne-grained representation learning of time series.\nBased on timestamp-level representation learning methods, the values of\ntimestamp points can be embedded into a ﬁne-grained representation, which\ncan be formalized using Equation (1).\nvi = {vi,1, vi,2, ..., vi,j} = fencoder(xi,1, xi,2, ..., xi,j)\n(1)\nWhere vi = vi,1, vi,2, ..., vi,j are the representation vectors of timestamp-level\ninputs. Index i indicates that these timestamp points are from Segment Si in\nthe time series.\nMoreover, as in the original research, to built a comprehensive representa-\ntion vector without any external information, a maximum pooling operation\nshould be employed to obtain the shallow features of each timestamp-level in-\nputs. vi,Maxpooling = Maxpooling(vi).\nThereafter, to capture the comprehensive information of the ﬁne-grained rep-\nresentations inputs of the time series, the ﬁne-grained fusion part combined the\ntimestamp-level feature and the maximum pooling value of each timestamp-level\ninputs. Speciﬁcally, the maximum pooling representation of these timestamp\npoints can be used as the Query vector in the attention mechanism to obtain\nthe fusion feature of ﬁne-grained representation by Equation (2).\nvxi = Sfotmax\n\u0012Q · KT\n√\nd\n\u0013\n· V = Softmax\n\u0012vi,Maxpooling · vi\n√\nd\n\u0013\n· vi\n(2)\nWhere d denotes the dimension of the representation vector and is used to nor-\nmalize the vectors. In the remainder of this paper, d(·) is used to represent the\ndimension of representation vector.\n8\nChengyang Ye\nand Qiang Ma\nAfter the ﬁne-grained fusion, the comprehensive representation vector of ﬁne-\ngrained representation learning is computed, which is employed to calculate\nmulti-granularity representation in the subsequent steps.\n3.3\nCross-Granularity Transformer\nCross-granularity representation is the subsequent step in the proposed frame-\nwork. Unlike the fusion of ﬁne-grained representation learning to obtain a com-\nprehensive vector, cross-granularity representation has its own challenge.\nCross-granularity representation, which refers to the combination of coarse-\nand ﬁne-grained information in a uniﬁed framework, are generally subject to\nredundancy. There may be overlapping or redundant information between the\ndiﬀerent granularities, thus leading to ineﬃciencies in the representation and po-\ntential over-ﬁtting in the learning process. Additionally, complexity is a critical\nissue. Combining features from diﬀerent granularities increases the complexity\nof the model, thus potentially increasing the computational requirements and\ntraining time. In addition, determining the optimal method for the fusion or\nintegration of features from diﬀerent granularities to generate a cohesive repre-\nsentation that eﬀectively captures the underlying patterns in the data can be\nchallenging. Therefore, multi-granularity feature fusion has attracted signiﬁcant\nattention with respect to multi-granularity representation.\nAs mentioned previously, most existing models primarily focus on the simple\nfusion of decision results and generally require the re-design of representation\nmodels. Consequently, they cannot utilize existing, well-performing representa-\nS\n\u0000\u0001\u0002\u0003\u0004 \u0005\nO\u0006 \u0002\u0007\n\u0006\n\u0002\nCross-Granularity Attention\nFig. 4. Structure of cross-granularity attention mechanism.\nTitle Suppressed Due to Excessive Length\n9\ntion methods and lack the ﬂexibility to adapt to diﬀerent scenarios. To address\nthis issue and more extensively utilize various existing excellent time series rep-\nresentation learning methods, we designed a cross-granularity transformer ar-\nchitecture based on the cross-granularity attention mechanism. The structure of\nthe cross-granularity attention mechanism is shown in Fig. 4.\nTo introduce the cross-granularity attention mechanism, we considered two\nrepresentation vectors, namely, vxi and VSi from ﬁne- and coarse-grained repre-\nsentation learning, respectively, where vxi ∈Rdx and VSi ∈RdS. Based on the\ntransformer architecture of multi-modal data fusion [21], we hypothesized that\na suitable method for the fusion of cross-granularity information is to provide a\nlatent adaptation across multi-granularity. In the proposed framework, it means\nVSi to vxi (coarse- to ﬁne-grained).\nWe deﬁned the Query as Qx = vxiWQx, which is a linear transformation\nof the ﬁne-grained representation input, the Key as KS = vSiWKS and the\nValue as VS = vSiWVS, which are the line transformations of the coarse-grained\nrepresentation input. Moreover, WQx, WKS and WVS are the weights. The latent\nadaptation from VSi to vxi is presented as the cross-granularity attention as\nfollows:\nAttention(Qx, KS, VS) = softmax\n\u0012QxKT\nS\n√dk\n\u0013\nVS\n(3)\nThe output of the cross-granularity attention mechanism has the same length\nas vxi. Using this equation, the mapping of coarse- onto ﬁne-grained representa-\ntions was established.\n3.4\nUnsupervised Learning\nThe primary objective of unsupervised learning is to learn useful features or\nrepresentations from the data without using any labeled information. This can\nbe particularly beneﬁcial for time series data analysis because obtaining labeled\ndata can be time-consuming and expensive.\nHowever, the design of algorithm for unsupervised learning is challenging.\nSeveral of these diﬃculties can be attributed to a lack of labeled data, which in-\ndicates that the model should identify the underlying structure and relationships\nwithin the data without any explicit guidance. However, constructing positive\nand negative sample pairs for unsupervised training is diﬃcult. The construction\nof sample pairs is closely related to the selection of the unsupervised training\ntasks. In this framework, we designed an unsupervised training tasks based on\nretrieval task.\nThere were several reasons for us for selecting retrieval task. First, unlike\nother unsupervised learning models, the proposed MUG is required to accomplish\nmulti-granularity representation vector fusion during the training process, which\nindicates that constructing positive and negative sample pairs before training is\ndiﬀerent. The representation vectors of the positive and negative samples are\nnot in the same vector space as the anchor. Therefore, traditional unsupervised\n10\nChengyang Ye\nand Qiang Ma\ncontrastive learning methods based on similarity measures cannot be applied in\nthis scenario. Constructing positive and negative sample pairs during the training\nprocess is undoubtedly complex and time consuming. In addition, traditional\nloss functions are subject to several limitations. If the selected triplets are not\ninformative, the triplet loss may rapidly converge to zero, thus leading to the\ndegradation of the model performance.\nTo solve these issues, we designed an unsupervised learning method using a\nretrieval training task and applied a novel loss function in the training (as shown\nat the top right of Fig. 3). First, because we used the maximum pooling method\nin ﬁne-grained fusion, we applied the average Pooling (Avgpooling) method to\nconstruct the query vector in the retrieval task. Thereafter, the multi-granularity\nrepresentation corresponds to the query vector, in addition to other randomly\nselected multi-granularity representation vectors form the query object together.\nAssuming that the query vector is yq, the correct multi-granularity representa-\ntion corresponding to the query vector is yt, and the other multi-granularity\nrepresentation vectors are yj. The ranking of yt can be expressed as follows:\n1 +\nX\nI (∥H(yq) −H(yt)∥≥∥H(yq) −H(yj)∥)\n(4)\nwhere H(Z) is a representation vector value of Z, and I(a ≥b) is a function that\nis transformed to 1 when a ≥b and 0 in other cases. In the above expression,\nranking is used to describe the relative distances.\nTo convert the ranking situation into a similarity metric that can be used as\na loss function, the Spearman correlation coeﬃcient [22] was used to calculate\nthe similarity. The Spearman correlation coeﬃcient is a statistical measure that\nevaluates the strength and direction of the monotonic relationship between two\nvariables. The equation of the Spearman correlation coeﬃcient of yt can be\nexpressed as follows:\nSimilarityt = n −πt\nn −1\n(5)\nwhere πt denotes the ranking of yt. Using the Spearman correlation coeﬃcient,\nthe relative similarity was used in the loss function to accelerate model conver-\ngence and improve model accuracy. Moreover, the traditional loss function is\napplicable in such cases.\nWe did not use ranking losses [23] because we found that the binary classiﬁ-\ncation loss [24] demonstrated a superior performance, which was similar to that\nreported in [25]. The equation of binary classiﬁcation loss function is expressed\nas follows:\nLBCE = −[ylog(θ) + (1 −y)log(1 −θ)]\n(6)\nwhere the ground truth labels y ∈(0, 1) and θ represent the similarity.\nTherefore, by combining Equation 5 and 6, the novel loss function can be\nexpressed as follows:\nLBCE = −[ylog(n −πt\nn −1 ) + (1 −y)log(1 −n −πt\nn −1 )]\n(7)\nTitle Suppressed Due to Excessive Length\n11\nTable 1. Summary of UEA multivariate datasets.\nDataset\nTrain Size\nTest Size\nLength\nClasses\nDimensions\nEthanolConcentration\n261\n263\n1751\n4\n3\nFaceDetection\n5890\n3524\n62\n2\n144\nHandwriting\n150\n850\n152\n26\n3\nHeartbeat\n204\n205\n405\n2\n61\nJapaneseVowels\n270\n370\n29\n9\n12\nPEMS-SF\n267\n173\n144\n7\n983\nSelfRegulationSCP1\n268\n293\n896\n2\n6\nSelfRegulationSCP2\n200\n180\n1152\n2\n7\nSpokenArabicDigits\n6599\n2199\n93\n10\n13\nUWaveGestureLibrary\n2238\n2241\n315\n8\n3\n4\nResults and discussion\nAs detailed in this section, we tested the eﬀectiveness of the proposed frame-\nwork by analyzing its performance on classiﬁcation task, which was used as a\ndownstream task, to prove the eﬀectiveness of the proposed multi-granularity\nrepresentation learning framework. Moreover, to highlight the advantages in\nreal-world time series data, comparative experiments was conducted with other\nmulti-granularity representation methods under simulated real-world scenario.\nAdditionally, a case study was conducted to recall the example introduced in\nSection 1.\n4.1\nClassiﬁcation\nIn the classiﬁcation task, the output multi-granularity representation vector of\nthe proposed framework was passed through a SoftMax function to obtain a\ndistribution over the classes. TST is used with ShapeNet, which are introduced\nin Section 2.1, as the ﬁne- and coarse-grained representation parts in our frame-\nwork. In this task, we demonstrated that the proposed framework demonstrated\na superior performance to those of other non-deep learning method and unsu-\npervised methods.\nWe used the following ten multivariate datasets from the UEA time series\nclassiﬁcation archives [26], which provided multiple datasets from diﬀerent do-\nmains with varying dimensions, unequal lengths, and missing values. We selected\ndatasets from a diverse range of domains across science and engineering from\nMonash University, UEA & UCR Time Series Classiﬁcation Repository. Selection\nwas made to ensure diversity with respect to the dimensionality and length of\nthe time series samples, in addition to the number of samples and classes (when\napplicable). Furthermore, we included both the ”easy” and ”diﬃcult” datasets,\nwhere the baselines performance were signiﬁcantly high or low, respectively. A\nsummary of these datasets is provided in Table 1.\n12\nChengyang Ye\nand Qiang Ma\nTable 2. Accuracy results of the proposed and other methods.\nDataset\nMUG\n(TST-ShapeNet) TST ShapeNet DTW D ROCKET LSTM\nEthanolConcentration\n0.471\n0.337\n0.312\n0.323\n0.452\n0.323\nFaceDetection\n0.694\n0.681\n0.602\n0.529\n0.647\n0.577\nHandwriting\n0.366\n0.305\n0.451\n0.286\n0.588\n0.152\nHeartbeat\n0.780\n0.776\n0.756\n0.717\n0.756\n0.722\nJapaneseVowels\n0.997\n0.994\n0.984\n0.949\n0.962\n0.797\nPEMS-SF\n0.919\n0.919\n0.751\n0.711\n0.751\n0.399\nSelfRegulationSCP1\n0.945\n0.925\n0.782\n0.775\n0.908\n0.689\nSelfRegulationSCP2\n0.615\n0.589\n0.578\n0.539\n0.533\n0.466\nSpokenArabicDigits\n0.995\n0.993\n0.975\n0.963\n0.712\n0.319\nUWaveGestureLibrary\n0.905\n0.903\n0.906\n0.903\n0.944\n0.412\nAverage Accuracy\n0.768\n0.742\n0.710\n0.669\n0.723\n0.486\nAverage Rank\n1.4\n2.4\n3.1\n4.5\n2.9\n5.3\nThe UEA archives provides an initial benchmark for existing models with\naccurate baseline information. Based on the performance metrics provided in\nthe UEA archives, we selected the following three models as our baselines:\n- Dimension-dependent dynamic time warping (DTW D) [27]: it uses a weighted\ncombination of raw series and ﬁrst-order diﬀerences for the neural network\nclassiﬁcation with either Euclidean distance or full-window dynamic time\nwarping (DTW). Additionally, it develops the traditional DTW method and\nsuits every data series.\n- ROCKET [28]: it is based on a random convolutional kernel similar to a\nshallow convolutional neural network. It can achieve rapid and accurate time\nseries classiﬁcation using random convolutional kernels.\n- Long short-term memory (LSTM) model [29]: it is a type of recurrent neural\nnetwork (RNN) architecture that is designed to overcome the limitations of\ntraditional RNNs in capturing long-term dependencies in sequential data.\nTable 2 presents the classiﬁcation results for the time series, where bold\nvalues indicate the optimal values. As shown in Table 2, the proposed frame-\nwork demonstrated the highest performance on eight of the ten datasets, thus\nachieving an average rank of 1.4th, followed by TST, which demonstrated one\nhighest performance with average ranked 2.4th. ROCKET, which demonstrated\nthe optimal performances for the remaining two datasets, and on average, was\nranked 2.9th. From the data presented in the table, it can be concluded that\nthe eﬀectiveness of proposed framework signiﬁcantly increased as the amount\nof data increased. In addition, comparing the performances of MUG (TST-\nShapeNet), TST and ShapeNet, it is evident that multi-granularity representa-\ntion can achieve a superior performance to that of the single-granularity represen-\ntation method. This is because multi-granularity methods can capture complex\ntemporal dependencies and patterns that may be presented at diﬀerent scales or\nresolutions in the data.\nTitle Suppressed Due to Excessive Length\n13\nTable 3. Summary of simulated real-world time series data from the UCR datasets.\nDataset\nTrain Size\nTest Size\nLength\nClasses\nAdiac\n390\n391\n200\n37\nBeef\n30\n30\n500\n5\nFish\n175\n175\n480\n7\nGun-Point\n50\n150\n170\n2\nCBF\n30\n900\n160\n3\nTrace\n100\n100\n300\n4\n4.2\nComparative Experiments\nThis section presents a discussion on the performance of proposed MUG and\nother multi-granularity models with respect to real-world time series data. Ac-\ncordingly, we used several UCR archives [30] and randomly added Gaussian noise\nand segments of time series data from other classes to the time series data to\nsimulate the real-world cases analyzed in Section 1. A summary of these datasets\nis provided in Table 3.\nIt should be noted that the lengths of these six datasets are longer than the\noriginal lengths in UCR archives, which is due to the simulation of the real-world\nsituations.\nFor comparison, we selected the MS-SRALAT framework introduced in Sec-\ntion 2.2. The ROCKET algorithm was used as a control group to further il-\nlustrate the performance diﬀerence between the single-granularity and multi-\ngranularity methods. The results of the comparative experiments are presented\nin Table 4.\nBy analyzing the results in Table 4, the proposed framework obtained su-\nperior results to those obtained by MS-SRALAT. This is because of the more\nadvanced ﬁne- and coarse-grained representations selected in the proposed frame-\nwork, in addition to the more ﬁxable structure and improved fusion method. The\nproposed framework can therefore improve the accuracy of downstream tasks.\nTable 4. Accuracy comparison between single-granularity and multi-granularity meth-\nods.\nDataset\nMUG(TST-ShapeNet) MS-SRALAT ROCKET\nAdiac\n0.435\n0.379\n0.468\nBeef\n0.614\n0.550\n0.458\nFish\n0.758\n0.671\n0.469\nGun-Point\n0.859\n0.701\n0.647\nCBF\n0.900\n0.934\n0.887\nTrace\n0.877\n0.860\n0.713\n14\nChengyang Ye\nand Qiang Ma\nTable 5. Summary of ECG200 and TwoLeadECG.\nDataset\nTrain Size\nTest Size\nLength\nClasses\nECG200\n100\n100\n96\n2\nTwoLeadECG\n23\n1139\n82\n2\nCombined ECG\n123\n1239\n82\n2\nTable 6. Accuracy results of proposed and other methods.\nDataset\nMUG(TST-ShapeNet)\nDTW D\nST\nECG200\n0.930\n0.880\n0.840\nTwoLeadECG\n0.993\n0.868\n0.984\nCombined ECG\n0.800\n0.442\n0.510\n4.3\nCase Study\nIn this case study, the example in Section 1 was considered more comprehensively\nto clarify the motivation for the study. As introduced in Section 1, by analyzing\nthe characteristic of real-world ECG data, it can be concluded that the complex\ntemporal dependencies and patterns may exist at diﬀerent scales or resolutions\nin the data. This section presents experimental design to further address this\nissue.\nTo simulate real-world ECG data, we combined two other datasets from the\nsame subject obtained from various sources. Speciﬁcally, we used the ECG 200\nand TwoLeadECG as datasets from the UCR time series classiﬁcation archive.\nBoth datasets traced the recorded electrical activity and contained two classes:\nnormal heartbeats and myocardial infarctions (MIs). We randomly combined\nthese two datasets and reshaped the length of the combined ECG dataset to\nobtain a regular time series. The details of these datasets are presented in Table\n5.\nWe selected DTW D and Shapelet Transform [31] as the baseline algorithms.\nThe Shapelet Transform (ST) is based on the shapelet method, which represent\nﬁne- and coarse-grained representations respectively. First, separate experiments\nwere conducted using these two datasets. We then conducted an experiment\nusing the combined dataset. The experimental results of this case study are\nlisted in Table 6.\n5\nConclusions\nIn this study, we investigated the signiﬁcance of exploring multi-granularity pat-\nterns for time series representation learning and proposed a multi-granularity\nframework for the unsupervised representation learning of time series. In par-\nticular, this paper proposes a novel unsupervised learning framework to build\nassociation between timestamp-level and segment-level features. To address the\nloss function issue in multi-granularity representation learning, a retrieval task\nTitle Suppressed Due to Excessive Length\n15\nfor time series data with a special loss function was also designed. Experiments\non public datasets and real-world data demonstrated the eﬀectiveness of our\nMUG framework. In the future, we plan to employ more ﬁne- and coarse-grained\nrepresentation models in the proposed MUG framework to discuss the gener-\nality across diﬀerent multiple granularity models. Moreover, we will focus on\ndeveloping a more general framework that can combined more than two multi-\ngranularity representation methods.\nReferences\n1. Tseng, K., Li, J., Tang, Y., Yang, C. & Lin, F. Healthcare knowledge of relationship\nbetween time series electrocardiogram and cigarette smoking using clinical records.\nBMC Medical Informatics And Decision Making. 20, 1-11 (2020)\n2. Lawi, A., Mesra, H. & Amir, S. Implementation of Long Short-Term Memory and\nGated Recurrent Units on grouped time-series data to predict stock prices accu-\nrately. Journal Of Big Data. 9, 1-19 (2022)\n3. Parvaiz, A., Khalid, M., Zafar, R., Ameer, H., Ali, M. & Fraz, M. Vision Trans-\nformers in medical computer vision—A contemplative retrospection. Engineering\nApplications Of Artiﬁcial Intelligence. 122 pp. 106126 (2023)\n4. Zhou, C., Li, Q., Li, C., Yu, J., Liu, Y., Wang, G., Zhang, K., Ji, C., Yan, Q., He,\nL. & Others A comprehensive survey on pretrained foundation models: A history\nfrom bert to chatgpt. ArXiv Preprint arXiv:2302.09419. (2023)\n5. Lines, J., Taylor, S. & Bagnall, A. Time series classiﬁcation with HIVE-COTE: The\nhierarchical vote collective of transformation-based ensembles. ACM Transactions\nOn Knowledge Discovery From Data. 12 (2018)\n6. Shifaz, A., Pelletier, C., Petitjean, F. & Webb, G. TS-CHIEF: a scalable and ac-\ncurate forest algorithm for time series classiﬁcation. Data Mining And Knowledge\nDiscovery. 34, 742-775 (2020)\n7. Reis, M. Multiscale and multi-granularity process analytics: A review. Processes. 7,\n61 (2019)\n8. Kazemi, S., Goel, R., Eghbali, S., Ramanan, J., Sahota, J., Thakur, S., Wu, S.,\nSmyth, C., Poupart, P. & Brubaker, M. Time2vec: Learning a vector representation\nof time. ArXiv Preprint arXiv:1907.05321. (2019)\n9. Church, K. Word2Vec. Natural Language Engineering. 23, 155-162 (2017)\n10. Zerveas, G., Jayaraman, S., Patel, D., Bhamidipaty, A. & Eickhoﬀ, C. A\ntransformer-based framework for multivariate time series representation learning.\nProceedings Of The 27th ACM SIGKDD Conference On Knowledge Discovery &\nData Mining. pp. 2114-2124 (2021)\n11. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A., Kaiser,\n L. & Polosukhin, I. Attention is all you need. Advances In Neural Information\nProcessing Systems. 30 (2017)\n12. Zhao, H., Jia, J. & Koltun, V. Exploring self-attention for image recognition. Pro-\nceedings Of The IEEE/CVF Conference On Computer Vision And Pattern Recog-\nnition. pp. 10076-10085 (2020)\n13. Yu, Y., Zhu, Y., Wan, D., Liu, H. & Zhao, Q. A novel symbolic aggregate ap-\nproximation for time series. Proceedings Of The 13th International Conference On\nUbiquitous Information Management And Communication (IMCOM) 2019 13. pp.\n805-822 (2019)\n16\nChengyang Ye\nand Qiang Ma\n14. Shieh, J. & Keogh, E. i SAX: disk-aware mining and indexing of massive time\nseries datasets. Data Mining And Knowledge Discovery. 19 pp. 24-57 (2009)\n15. Anacleto, M., Vinga, S. & Carvalho, A. MSAX: Multivariate Symbolic Aggregate\nApproximation for Time Series Classiﬁcation. Computational Intelligence Methods\nFor Bioinformatics And Biostatistics: 16th International Meeting, CIBB 2019, Berg-\namo, Italy, September 4–6, 2019, Revised Selected Papers 16. pp. 90-97 (2020)\n16. Li, G., Choi, B., Xu, J., Bhowmick, S., Chun, K. & Wong, G. Shapenet: A shapelet-\nneural network approach for multivariate time series classiﬁcation. Proceedings Of\nThe AAAI Conference On Artiﬁcial Intelligence. 35, 8375-8383 (2021)\n17. Hou, M., Xu, C., Liu, Y., Liu, W., Bian, J., Wu, L., Li, Z., Chen, E. & Liu, T.\nStock trend prediction with multi-granularity data: A contrastive learning approach\nwith adaptive fusion. Proceedings Of The 30th ACM International Conference On\nInformation & Knowledge Management. pp. 700-709 (2021)\n18. Yang, X., Loua, M., Wu, M., Huang, L. & Gao, Q. Multi-granularity stock pre-\ndiction with sequential three-way decisions. Information Sciences. 621 pp. 524-544\n(2023)\n19. Boonchoo, T. MS-SRALAT: Multi-granularity SubStructure-aware Representation\nLearning Algorithm for Time-series. 2022 19th International Joint Conference On\nComputer Science And Software Engineering (JCSSE). pp. 1-6 (2022)\n20. Nie, F., Cao, Y., Wang, J., Lin, C. & Pan, R. Mention and entity description\nco-attention for entity disambiguation. Proceedings Of The AAAI Conference On\nArtiﬁcial Intelligence. 32 (2018)\n21. Tsai, Y., Bai, S., Liang, P., Kolter, J., Morency, L. & Salakhutdinov, R. Multimodal\ntransformer for unaligned multimodal language sequences. Proceedings Of The Con-\nference. Association For Computational Linguistics. Meeting. 2019 pp. 6558 (2019)\n22. De Winter, J., Gosling, S. & Potter, J. Comparing the Pearson and Spearman\ncorrelation coeﬃcients across distributions and sample sizes: A tutorial using simu-\nlations and empirical data.. Psychological Methods. 21, 273 (2016)\n23. Kemertas, M., Pishdad, L., Derpanis, K. & Fazly, A. Rankmi: A mutual infor-\nmation maximizing ranking loss. Proceedings Of The IEEE/CVF Conference On\nComputer Vision And Pattern Recognition. pp. 14362-14371 (2020)\n24. Sypherd, T., Diaz, M., Sankar, L. & Kairouz, P. A tunable loss function for binary\nclassiﬁcation. 2019 IEEE International Symposium On Information Theory (ISIT).\npp. 2479-2483 (2019)\n25. Qi, D., Su, L., Song, J., Cui, E., Bharti, T. & Sacheti, A. Imagebert: Cross-modal\npre-training with large-scale weak-supervised image-text data. ArXiv Preprint\narXiv:2001.07966. (2020)\n26. Bagnall, A., Dau, H., Lines, J., Flynn, M., Large, J., Bostrom, A., Southam, P.\n& Keogh, E. The UEA multivariate time series classiﬁcation archive, 2018. ArXiv\nPreprint arXiv:1811.00075. (2018)\n27. Chen, Y., Hu, B., Keogh, E. & Batista, G. Dtw-d: time series semi-supervised learn-\ning from a single example. Proceedings Of The 19th ACM SIGKDD International\nConference On Knowledge Discovery And Data Mining. pp. 383-391 (2013)\n28. Dempster, A., Petitjean, F. & Webb, G. ROCKET: exceptionally fast and accu-\nrate time series classiﬁcation using random convolutional kernels. Data Mining And\nKnowledge Discovery. 34, 1454-1495 (2020)\n29. Karim, F., Majumdar, S., Darabi, H. & Chen, S. LSTM fully convolutional net-\nworks for time series classiﬁcation. IEEE Access. 6 pp. 1662-1669 (2017)\n30. Dau, H., Bagnall, A., Kamgar, K., Yeh, C., Zhu, Y., Gharghabi, S., Ratanama-\nhatana, C. & Keogh, E. The UCR time series archive. IEEE/CAA Journal Of Au-\ntomatica Sinica. 6, 1293-1305 (2019)\nTitle Suppressed Due to Excessive Length\n17\n31. Arul, M. & Kareem, A. Applications of shapelet transform to time series classiﬁ-\ncation of earthquake, wind and wave data. Engineering Structures. 228 pp. 111564\n(2021)\nϬ\nϱ\nϭϬ\nϭϱ\nϮϬ\nϮϱ\nϯϬ\nϯϱ\nϰϬ\nϰϱ\nϱϬ\nϬ\nϱ\nϭϬ\nϭϱ\nϮϬ\nϮϱ\nϯϬ\n\u0018ĂƚĂ\u0003\u0004\n\u0018ĂƚĂ\u0003\u0011\n",
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "published": "2023-12-12",
  "updated": "2023-12-12"
}