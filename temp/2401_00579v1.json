{
  "id": "http://arxiv.org/abs/2401.00579v1",
  "title": "Exploring the Effectiveness of Instruction Tuning in Biomedical Language Processing",
  "authors": [
    "Omid Rohanian",
    "Mohammadmahdi Nouriborji",
    "David A. Clifton"
  ],
  "abstract": "Large Language Models (LLMs), particularly those similar to ChatGPT, have\nsignificantly influenced the field of Natural Language Processing (NLP). While\nthese models excel in general language tasks, their performance in\ndomain-specific downstream tasks such as biomedical and clinical Named Entity\nRecognition (NER), Relation Extraction (RE), and Medical Natural Language\nInference (NLI) is still evolving. In this context, our study investigates the\npotential of instruction tuning for biomedical language processing, applying\nthis technique to two general LLMs of substantial scale. We present a\ncomprehensive, instruction-based model trained on a dataset that consists of\napproximately $200,000$ instruction-focused samples. This dataset represents a\ncarefully curated compilation of existing data, meticulously adapted and\nreformatted to align with the specific requirements of our instruction-based\ntasks. This initiative represents an important step in utilising such models to\nachieve results on par with specialised encoder-only models like BioBERT and\nBioClinicalBERT for various classical biomedical NLP tasks. Our work includes\nan analysis of the dataset's composition and its impact on model performance,\nproviding insights into the intricacies of instruction tuning. By sharing our\ncodes, models, and the distinctively assembled instruction-based dataset, we\nseek to encourage ongoing research and development in this area.",
  "text": "Exploring the Effectiveness of Instruction Tuning in Biomedical Language\nProcessing\nOmid Rohanian1,2∗, Mohammadmahdi Nouriborji2,4∗, David A. Clifton1,3\n1Department of Engineering Science, University of Oxford, Oxford, UK\n2NLPie Research, Oxford, UK\n3Oxford-Suzhou Centre for Advanced Research, Suzhou, China\n4Sharif University of Technology, Tehran, Iran\n{m.nouriborji,omid}@nlpie.com\n{omid.rohanian,david.clifton}@eng.ox.ac.uk\nAbstract\nLarge Language Models (LLMs), particularly\nthose similar to ChatGPT, have significantly in-\nfluenced the field of Natural Language Process-\ning (NLP). While these models excel in general\nlanguage tasks, their performance in domain-\nspecific downstream tasks such as biomedi-\ncal and clinical Named Entity Recognition\n(NER), Relation Extraction (RE), and Medi-\ncal Natural Language Inference (NLI) is still\nevolving. In this context, our study investi-\ngates the potential of instruction tuning for\nbiomedical language processing, applying this\ntechnique to two general LLMs of substantial\nscale. We present a comprehensive, instruction-\nbased model trained on a dataset that consists\nof approximately 200, 000 instruction-focused\nsamples. This dataset represents a carefully\ncurated compilation of existing data, meticu-\nlously adapted and reformatted to align with the\nspecific requirements of our instruction-based\ntasks. This initiative represents an important\nstep in utilising such models to achieve results\non par with specialised encoder-only models\nlike BioBERT and BioClinicalBERT for vari-\nous classical biomedical NLP tasks. Our work\nincludes an analysis of the dataset’s compo-\nsition and its impact on model performance,\nproviding insights into the intricacies of instruc-\ntion tuning. By sharing our codes, models, and\nthe distinctively assembled instruction-based\ndataset, we seek to encourage ongoing research\nand development in this area.\n1\nIntroduction\nTransformers have become the cornerstone of\nmodern NLP, providing the backbone for a wide\n*Both authors contributed equally to this work.\narray of applications including machine transla-\ntion, question-answering, and text summarisation\n(Vaswani et al., 2017). Their self-attention mech-\nanisms and parallelised architecture have proven\nto be highly effective in capturing the nuances of\nhuman language (Devlin et al., 2019).\nAutoregressive language models, exemplified\nby the Generative Pre-trained Transformer series\nlike GPT (Radford et al., 2018) and GPT-3 (Brown\net al., 2020), have revolutionised the way NLP is ap-\nproached. These models, operating as decoder-only\ntransformers, excel at generating text in a sequen-\ntial, token-by-token manner, leveraging their atten-\ntion mechanisms to focus on relevant segments of\ninput text. Models based on this architecture, such\nas GPT-4 have demonstrated a remarkable abil-\nity to perform a variety of language tasks without\nthe need for task-specific fine-tuning, showcasing\nstrong zero-shot and few-shot learning capabilities.\nThis feature allows these models to effectively re-\nspond to text-based prompts, including those with a\nlimited number of examples or instructions, thereby\nenabling a more interactive and dynamic text gen-\neration process.\nMedical language models, particularly encoder-\nonly models like BioBERT and ClinicalBERT, have\nbeen instrumental in advancing tasks such as med-\nical diagnosis, biomedical literature mining, and\nclinical information extraction (Clusmann et al.,\n2023; Kormilitzin et al., 2021). Excelling in areas\nlike classification and Named Entity Recognition\n(NER), these models have significantly contributed\nto biomedical NLP. However, they often lack inher-\nent capabilities in interpreting and executing natu-\nral language instructions or generating reports from\narXiv:2401.00579v1  [cs.CL]  31 Dec 2023\nmedical Electronic Health Records (EHRs). This\nlimitation has spurred research into developing gen-\nerative Large Language Models (LLMs) capable\nof handling more dynamic tasks, aiming to parallel\nthe performance of specialised encoder-only mod-\nels in the biomedical domain. Yet, as indicated\nby studies such as Lehman et al. (Lehman et al.,\n2023), encoder-only models continue to lead in\nclinical NLP, underscoring the challenges in tailor-\ning general-domain LLMs for specialised medical\napplications. Our research aims to contribute to\nthis area by introducing a dataset that integrates\nvarious clinical and biomedical datasets. Utilis-\ning this resource, we apply instruction tuning to\ntwo publicly available general LLMs, with the ob-\njective of exploring its potential in enhancing the\nperformance of these LLMs for downstream medi-\ncal tasks. This approach represents an initial step\ntowards understanding the effectiveness of instruc-\ntion tuning in this domain, with the dataset serving\nas an additional tool to facilitate this exploration\nfor future work.\nThe primary contributions of our work are as\nfollows. First, we introduce Llama2-MedTuned,\ndeveloped in two variants: one fine-tuned on the\nLlama2 7B model1 and the other on the Llama2\n13B model2.\nThese are specialised models de-\nsigned explicitly for instruction-based tasks in the\nmedical domains. Second, we present a dataset that\namalgamates various publicly available datasets\ninto a novel configuration, creating a rich and di-\nverse training environment specifically compiled\nfor the Llama2-MedTuned models. Our compara-\ntive experimental results highlight the effectiveness\nof our approach in comparison to current state-of-\nthe-art models in a number of classical tasks in\nbiomedical and clinical NLP.\n2\nRelated Works\n2.1\nAutoregressive Language Models\nAutoregressive Language Models (ALMs), exem-\nplified by GPT and its different variants, constitute\na class of transformers pre-trained on a language\nmodelling objective, namely, predicting the sub-\nsequent token given a particular context (Radford\net al., 2018, 2019). Noteworthy instances of ALMs\ninclude GPT-3.5 and GPT-4 by OpenAI, trained on\n1Llama2-MedTuned-7b:\nhttps://huggingface.\nco/nlpie/Llama2-MedTuned-7b.\n2Llama2-MedTuned-13b:\nhttps://huggingface.\nco/nlpie/Llama2-MedTuned-13b.\nextensive datasets harvested from the web for the\nlanguage modelling objective (Brown et al., 2020).\nGoogle’s Bard/Gemini and Anthropic’s Claude are\nalso notable contributions to this field, demonstrat-\ning the growing exploration and advancements of\nautoregressive language models for diverse appli-\ncations.\n2.2\nInstruction-Based Language Models\nInstruction-based language models, a novel cat-\negory within autoregressive models, have been\nshown to improve significantly when fine-tuned\nwith instructions. Traditional autoregressive mod-\nels, while adept at sequential text generation,\noften struggle with comprehending and execut-\ning complex instructions. Fine-tuning such mod-\nels on natural language instructions and human-\ngenerated responses can markedly enhance their\nability to follow instructions accurately (Wei et al.,\n2021). This advancement is exemplified in models\nlike Instruct-GPT (Ouyang et al., 2022), Falcon\n(Penedo et al., 2023), and Llama (Touvron et al.,\n2023), which are fine-tuned to respond more effec-\ntively to instruction-based prompts, thus enabling\nmore dynamic and interactive text generation capa-\nbilities.\n2.3\nClinical LLMs\nWith the advent of instruction-based LLMs, their\nadaptation to the clinical domain has been explored,\nusing instruction-based datasets specific to this area.\nChatDoctor (Li et al., 2023), a fine-tuned clini-\ncal chatbot, has been trained on real conversations\nbetween doctors and patients, showcasing its effi-\ncacy in clinical settings. Similarly, Med-Alpaca\n(Han et al., 2023) and Clinical Camel (Toma et al.,\n2023) follow this trend by adapting open LLMs\nto the clinical domain. PMC-Llama (Wu et al.,\n2023) is another significant model, initially pre-\ntrained on a biomedical/clinical corpus, and subse-\nquently trained on an instruction dataset primarily\ncontaining medical question answering and reason-\ning tasks.\n3\nMethod\nIn this work, we train an instruction-based language\nmodel for the medical domain which is able to tar-\nget tasks such as Named Entity Recognition, Re-\nlation Extraction, Document Classification, Ques-\ntion Answering, and Natural Language Inference.\nIn order to train this model, we compiled a new\nNamed Entity Recognition\n### Instruction:\nYour task is to identify clinical Named Entities within the\ntext and apply the BIO labeling scheme. Use the following\nlabels to categorize each entity:\nOCCURRENCE: If the entity represents a clinical incident\nor event.\nPROBLEM: If the entity indicates a medical problem.\nTEST: If the entity pertains to a medical test.\nTREATMENT: If the entity refers to a medical treatment.\nEVIDENTIAL: If the entity provides evidence.\nCLINICAL_DEPT: If the entity relates to a clinical\ndepartment.\nO: If the entity doesn't fit into any of the above categories.\n### Input:\nThe urine contained yeast and she was treated with\namphotericin .\n### Output:\nThe : B-TEST\nurine : I-TEST\ncontained : O\nyeast : B-PROBLEM\nand : O\nshe : O\nwas : O\ntreated : O\nwith : O\namphotericin : B-TREATMENT\n. : O \nGeneral Medical Instructions\n### Instruction:\nIn your capacity as a medical assistant, help the user's\nwith their medical inquiries, and follow their instructions.\n### Input:\nOne of my friends has recently have a heart-storke, Give\nme a list of foods that might be dangerous for him, in an\nordered list.\n### Output:\nFollowing is a list of foods that should be avoided or\ntaken in moderation after a heart attack:\n1. Red meat and high fat milk products: These should be\ntaken in moderation.\n2. Fried foods: Deep-fried foods and foods cooked in a lot\nof oil should be taken in moderation.\n3. High fat foods: Foods that are high in saturated or\ntrans-fats should be taken in moderation.\n4. Processed meats: Bacon, sausage, bologna, salami, etc.\nshould be taken in moderation.\n5. Canned foods: Canned foods that are high in sodium\nshould be taken in moderation.\n6. Sweets: Cakes, cookies, pies, and other sweets should\nbe taken in moderation.\n7. Salt: High amounts of salt should be avoided.\n8. Alcohol: Alcohol should be avoided or taken in\nmoderation.\n9. Caffeine: Caffeine should be taken in moderation.\n10. Cholesterol: Foods that are high in cholesterol should\nbe taken in moderation.\nFigure 1: Example outputs from Llama2-MedTuned-7B for biomedical tasks (left) and general medical instructions\n(right). The model demonstrates the application of instruction-based learning in NER by correctly labeling\nbiomedical entities (left) and providing a relevant list in response to a medical inquiry (right).\nDocument Classification\n### Instruction: \n\nThis task is a multi-class classification, and \nyou are required to assign one or more \nlabels from the following list to the text if \nthey are relevant:\nAvoiding immune destruction (ID)\nSustaining proliferative signaling (PS)\nEvading growth suppressors (GS)\n...\nNone\n### Input: \nThere was no evidence of immunosuppres-\nsion .\n### Output: \nAvoiding immune destruction (ID)\nNatural Language Infernece\n### Instruction: \nIn the provided clinical sentences, your \nobjective is to determine their relationship \nand assign one of the following labels ...\n### Input: \nSentence 1: A renal biopsy at this time \nshowed signs of rejection and he received a \nthree day pulse of steroids and subsequent-\nly did well.\nSentence 2: The patient has a history \nof renal failure treated with \ntransplant.\n### \nOutput: \nEntailment\nQuestion Answering\n### Instruction: \nIf you are a doctor, please answer the \nmedical questions based on the patient's \ndescription.\n### Input: \nI woke up this morning feeling the whole \nroom is spinning when i was sitting down. I \nwent to the bathroom walking unsteadily, as \ni tried to focus i feel nauseous ...\n### Output: \nHi, Thank you for posting your query. The \nmost likely cause for your symptoms is \nbenign paroxysmal positional vertigo \n(BPPV) ...\nRelation Extraction\n### Instruction: \nMedical problems are marked as \n@problem$, medical tests are marked as \n@test$, and treatments are marked as \n@treatment$. Categorize the relationship \nbetween two entities in the text as one of \nthe following options:\nTreatment improves medical problem \n(TrIP)\n...\nNo Relations\n### Input: \nRate PR @test$ QT/QTc P QRS @test$ 70 \n0 160 466/486.42 0 -71 112\n### \nOutput: \nNo Relations\nNamed Entity Recognition\n### Instruction:\n\nIn the given text, your mission is to \nidentify Named Entities referring to \ndiseases ...\n### Input:\n... of inherited breast and ovarian \ncancer\n### Output:\n...\nof : O\ninherited : B\nbreast : I\nand : I\novarian : I\ncancer : I\n. : O\nMedical Instruction Dataset\nLlama 2\n(Instruction)\nFine-Tuning\nLlama2\nMedTuned\nFigure 2: Schematic representation of the process for fine-tuning Llama2 models with the proposed medical\ninstruction dataset.\nmedical instruction-based dataset called Llama2-\nMedTuned-Instructions3.\n3https://huggingface.co/datasets/\nnlpie/Llama2-MedTuned-Instructions\n3.1\nPrompting Template\nTo transform the original datasets into instruction-\nbased formats, we adopted the prompting strategy\nused in the Alpaca dataset. Our prompts are com-\nposed of three parts: Instruction, Input, and Output.\nIn the Instruction section, we developed 5 to 10\ndifferent instructions for each dataset, detailing the\nDocument Classiﬁcation\n### Instruction: \nThis task is a multi-class classifica-\ntion, and you are required to assign \none or more labels from the following \nlist to the text if they are relevant:\nAvoiding immune destruction (ID)\nSustaining proliferative signaling (PS)\nEvading growth suppressors (GS)\n...\nNone\n### Input: \nThere was no evidence of immunosup-\npression .\n### Output: \nAvoiding immune destruction (ID)\nNatural Language Infernece\n### Instruction: \nIn the provided clinical sentences, your \nobjective is to determine their relation-\nship and assign one of the following \nlabels ...\n### Input: \nSentence 1: A renal biopsy at this time \nshowed signs of rejection and he \nreceived a three day pulse of steroids \nand subsequently did well.\nSentence 2: The patient has a history \nof renal failure treated with transplant.\n### Output: \nEntailment\nRelation Extraction\n### Instruction: \nMedical problems are marked as \n@problem$, \nmedical \ntests \nare \nmarked as @test$, and treatments \nare marked as @treatment$. Catego-\nrize the relationship between two \nentities in the text as one of the \nfollowing options:\nTreatment \nimproves \nmedical \nproblem (TrIP)\n...\nNo Relations\n### Input: \nRate PR @test$ QT/QTc P QRS \n@test$ 70 0 160 466/486.42\n### Output: \nNo Relations\nNamed Entity Recognition\n### Instruction:\nIn the given text, your mission is to \nidentify Named Entities referring to \ndiseases ...\n### Input:\n... of inherited breast and ovarian \ncancer\n### Output:\n...\nof : O\ninherited : B\nbreast : I\nand : I\novarian : I\ncancer : I\n. : O\nFigure 3: Overview of some of the prompt templates used in our instruction dataset.\ntarget tasks and the labelling scheme for the model.\nOne instruction is randomly chosen for each sam-\nple during the conversion to the instruction-based\ndataset. The Input is the dataset’s original input,\nwhile the Output is the expected output that the\nmodel should predict, consistent with the format\ndescribed in the instructions. Figure 3 presents\nsome samples from our instruction dataset.\n3.2\nTasks and Datasets\nAs mentioned earlier, various tasks are used in this\nwork to diversify the training corpus used for train-\ning our language model. Training subsets from\nseveral well-known datasets were selected for each\ntask to assemble the dataset employed in our study.\n3.2.1\nNamed Entity Recognition\nFor the task of Named Entity Recognition, we used\nthe NCBI-disease, BC5CDR-disease (Do˘gan et al.,\n2014), BC5CDR-chem (Li et al., 2016), BC2GM\n(Smith et al., 2008), JNLPBA (Smith et al., 2008),\nand i2b2-2012 dataset (Sun et al., 2013). For the\nfirst five datasets, we use the BIO labeling scheme\nwith no additional label names. However, for the\ni2b2-2012 dataset, 6 different categories are used\nalong with BIO labeling.\n3.2.2\nRelation Extraction\nWe used the i2b2-2010 (Uzuner et al., 2011) and\nGAD (Bravo et al., 2015) datasets for relation ex-\ntraction. For both datasets we follow the same pre-\nprocessing method used in Rohanian et al. (2023b)\nand Rohanian et al. (2023a), which uses specific\ntags (e.g. test$, problem$, etc.) for tagging medical\nconcepts in the text, in order to frame the relation\nextraction as a sentence classification task.\n3.2.3\nNatural Language Inference\nFor Natural Language Inference, we used the\nMedNLI dataset (Romanov and Shivade, 2018),\nwhich is composed of pairs of medical sentences\nlabeled with Entailment, Contradiction, or Neutral\nto indicate the type of relationship between them.\n3.2.4\nDocument Classification\nWe used the hallmarks of cancer (HoC) dataset\n(Baker et al., 2015) for the task of Document Clas-\nsification which is a well-known multi-class classi-\nfication dataset in the medical domain.\n3.2.5\nQuestion Answering\nFor question answering, we used two prominent\ndatasets, ChatDoctor (Li et al., 2023), and Pmc-\nLlama-Instructions (Wu et al., 2023). ChatDoc-\ntor consists of 100k samples taken from the Chat-\nDoctor website that are real conversations between\npatients and doctors, In our dataset we randomly\nsampled 50K samples from this dataset. PMC-\nLlama-Instructions is a large dataset consisting of\nmultiple QA datasets such as MedQA (Jin et al.,\n2021), PubMedQA (Jin et al., 2019), etc. For our\nwork, we randomly sampled 50K samples from this\ndataset.\n3.2.6\nLlama2-MedTuned Instructions\nFinally, we concatenate all of the datasets men-\ntioned earlier in this section and shuffle them to\nobtain our final medical instruction-based dataset\nwhich consists of approximately 200K samples.\n3.3\nTraining Configuration\nIn order to train our models, we used 10 V100\nGPUs with a batch size of 4 per GPU. We used the\ndeepspeed zero 3 config without CPU offloading,\nwith a learning rate of 1e −5 and 500 warmup\nsteps along with a linear learning rate scheduler.\nThe models were trained for three epochs.\n4\nResults\nAssessing the instruct-tuned models, Llama2-\nMedTuned 7B and 13B, against their foundational\ncounterparts, Llama2 7B and 13B, presents com-\nplexities. As depicted in Figures 4 and 5 in the\nappendix, prompting the base Llama2 models for\nNER often yields outputs that are erratic and diffi-\ncult to quantify. Our study is limited to zero-shot\nlearning scenarios4, where tasks and expected out-\ncomes are defined in basic terms. Although ventur-\ning into few-shot learning or advanced prompting\nmight alter the results, our limited experimenta-\ntion did not indicate a significant shift in this trend.\nTherefore, barring MedNLI, where Llama2 gener-\nates consistent outputs, our models are compared\nwith DistilBERT and BioBERT, the conventional\nbaselines for NER, RE, and NLI tasks.\nThanks to instruction-tuning, we were able to\nsystematically interpret our models’ outputs into\na structured format, suitable for evaluation using\nconventional metrics like F1 or Accuracy. The\nresults for the biomedical NER are available in\nTable 2, Where the 13B model is generally better\nthan our 7B model. Additionally, the results of the\nclinical tasks are available in Table 3.\nGenerally, interpreting the outputs of Llama2 on\nmost structured tasks proved to be challenging as\nthe outputs tended to deviate from the expected\nformat. We have provided examples of output gen-\nerations from both our model and Llama2 in Fig-\nures 4 and 5. Jahan et al. (2023) reports results\nfor the NER datasets on a number of closed and\nopen LLMs including LLama2. Please refer to ta-\nble 4 for a baseline reference to the reported results\non the NER tasks in the literature. Llama2, on\nthe other hand, did yield consistent outputs on the\nMedNLI task. Upon evaluation, the Llama2 model\nscored an accuracy of 37.20 on the MedNLI eval-\nuation subset, significantly lower than the 89.46\nscore achieved by Llama2-MedTuned-13b.\n5\nAblation Studies\nTo maintain the general capabilities of our model\non tasks such as Question Answering and general\ninstructions we use additional instruction-based\n4One-shot and zero-shot cases resulted in virtually identi-\ncal results, therefore we are only reporting the results of the\nzero-shot run.\ndata along with our NER, RE, and CLS instructions.\nWe tested two strategies to create our final dataset.\nFirst, we randomly sampled 50K samples from the\nPMC-Llama instructions, and 50K from the Chat-\nDoctor. For the second approach, we employed a\nmore balanced sampling by taking 50K samples\nfrom PubMedQA, 50K from MedQA, 100% of\nUMLS relations, and UMLS, which resulted in\n200K samples from the PMC-Llama instructions,\nalong with 50K samples from ChatDoctor. The ab-\nlation study results, presented in Table 1, reveal that\nthe model trained on the larger PMC-Llama dataset\nexhibited inferior performance in biomedical down-\nstream tasks compared to the model trained on the\nsmaller dataset.\n6\nConclusions & Future Works\nIn our study, we focused on instruction tuning of\nthe Llama 2 model using a bespoke biomedical\ndataset, specifically curated for specialised biomed-\nical NLP tasks like Named Entity Recognition\n(NER), Relation Extraction (RE), and medical Nat-\nural Language Inference (NLI). This process led to\nthe creation of Llama2-MedTuned-7B and Llama2-\nMedTuned-13B, which represent adaptations of\nthe original Llama 2 models. These tuned versions\nshowed significant improvements in handling the\ncomplexities of medical NER, RE, and NLI indi-\ncating the efficacy of instruction tuning in aligning\ngeneral-purpose language models with specialised\ntask requirements. Despite these advancements, the\nscope for further enhancement remains, particularly\nin terms of processing detailed clinical instructions\nand further evaluating performance on Question\nAnswering (QA) tasks. Future initiatives will in-\nvolve enriching our dataset to cover an even broader\nrange of biomedical and clinical tasks. Moreover,\nin line with the rapid advancements in the NLP\nfield, we intend to explore and potentially integrate\ncutting-edge language models like Mistral, contin-\nually refining our approach to meet the dynamic\nneeds of biomedical NLP applications.\nFunding\nThis work was supported in part by the Na-\ntional Institute for Health Research (NIHR) Ox-\nford Biomedical Research Centre (BRC), and in\npart by an InnoHK Project at the Hong Kong\nCentre for Cerebro-cardiovascular Health Engi-\nneering (COCHE). OR acknowledges the support\n1The results are taken from (Jahan et al., 2023)\nTable 1: Ablation study results using the instruction-based dataset. The † symbol denotes the model trained with the\nexpanded instruction dataset.\nType\nTask\nLlama2-\nMedTuned\nLlama2-\nMedTuned†\nNER\nNCBI-Disease\n85.69\n83.59\nNER\nBC5CDR-Disease\n85.46\n84.30\nNER\nBC5CDR-Chem\n94.51\n93.77\nNER\nBC2GM\n79.12\n78.51\nNER\nJNLPBA\n81.31\n78.91\nTable 2: Test results on the Biomedical downstream tasks\nType\nTask\nDistilBERT\nBioBERT-v1.1\nLlama2-\nMedTuned-7b\nLlama2-\nMedTuned-13b\nNER\nNCBI-Disease\n86.38\n88.62\n87.18\n85.69\nNER\nBC5CDR-Disease\n82.01\n86.67\n83.92\n85.46\nNER\nBC5CDR-Chem\n92.50\n94.73\n93.88\n94.51\nNER\nBC2GM\n84.61\n87.62\n76.46\n79.12\nNER\nJNLPBA\n79.14\n80.33\n82.30\n81.31\nTable 3: Test results on the clinical downstream tasks\nType\nTask\nDistilBERT\nBioClinicalBERT\nLlama2-\nMedTuned-7b\nLlama2-\nMedTuned-13b\nNER\ni2b2-2012\n79.15\n82.98\n80.67\n80.64\nRE\ni2b2-2010\n92.75\n93.58\n89.35\n93.14\nNLI\nMedNLI\n73.41\n82.41\n79.21\n89.46\nTable 4: Baseline results of different language models\non the biomedical NER tasks 1\nDataset\nGPT-3.5\nLlama-2\nClaude-2\nNCBI-disease\n33.39\n4.58\n45.75\nBC2GM\n31.99\n5.95\n40.45\nBC5CDR-chem\n41.25\n12.21\n58.05\nBC5CDR-disease\n32.26\n5.68\n50.13\nJNLPBA\n31.89\n4.30\n34.62\nof the Medical Research Council (grant number\nMR/W01761X/). DAC was supported by an NIHR\nResearch Professorship, an RAEng Research Chair,\nCOCHE, and the Pandemic Sciences Institute at\nthe University of Oxford. The views expressed are\nthose of the authors and not necessarily those of\nthe NHS, NIHR, MRC, COCHE, or the University\nof Oxford.\nLimitations\nOur exploration into the application of large au-\ntoregressive language models like Llama2 for NLP\ntasks such as NER and RE unveiled significant\nchallenges. The base Llama2 models, without fine-\ntuning, struggled to generate coherent and appropri-\nately formatted outputs for these tasks. This under-\nscores the difficulty in applying general-purpose\nLLMs to domain-specific tasks that demand organ-\nised responses. However, our instruct-tuned mod-\nels, Llama2-MedTuned 7B and 13B, showed im-\nproved performance, successfully generating out-\nputs in the necessary structured format. Despite\nthis advancement, they did not outperform spe-\ncialised models like BioBERT, highlighting a need\nfor further development to meet the precision re-\nquirements of specific biomedical NLP tasks.\nReferences\nSimon Baker, Ilona Silins, Yufan Guo, Imran Ali, Johan\nHögberg, Ulla Stenius, and Anna Korhonen. 2015.\nAutomatic semantic classification of scientific litera-\nture according to the hallmarks of cancer. Bioinfor-\nmatics, 32(3):432–440.\nÀlex Bravo, Janet Piñero, Núria Queralt-Rosinach,\nMichael Rautschka, and Laura I Furlong. 2015. Ex-\ntraction of relations between genes and diseases from\ntext and large-scale data analysis: implications for\ntranslational research. BMC bioinformatics, 16:1–17.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nJan Clusmann, Fiona R Kolbinger, Hannah Sophie\nMuti, Zunamys I Carrero, Jan-Niklas Eckardt,\nNarmin Ghaffari Laleh, Chiara Maria Lavinia Löffler,\nSophie-Caroline Schwarzkopf, Michaela Unger, Gre-\ngory P Veldhuizen, et al. 2023. The future landscape\nof large language models in medicine. Communica-\ntions Medicine, 3(1):141.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nRezarta Islamaj Do˘gan, Robert Leaman, and Zhiyong\nLu. 2014. Ncbi disease corpus: a resource for dis-\nease name recognition and concept normalization.\nJournal of biomedical informatics, 47:1–10.\nTianyu Han, Lisa C Adams, Jens-Michalis Papaioan-\nnou, Paul Grundmann, Tom Oberhauser, Alexander\nLöser, Daniel Truhn, and Keno K Bressem. 2023.\nMedalpaca–an open-source collection of medical\nconversational ai models and training data. arXiv\npreprint arXiv:2304.08247.\nIsrat Jahan, Md Tahmid Rahman Laskar, Chun Peng,\nand Jimmy Huang. 2023. A comprehensive eval-\nuation of large language models on benchmark\nbiomedical text processing tasks.\narXiv preprint\narXiv:2310.04270.\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,\nHanyi Fang, and Peter Szolovits. 2021. What disease\ndoes this patient have? a large-scale open domain\nquestion answering dataset from medical exams. Ap-\nplied Sciences, 11(14):6421.\nQiao Jin, Bhuwan Dhingra, Zhengping Liu, William\nCohen, and Xinghua Lu. 2019. Pubmedqa: A dataset\nfor biomedical research question answering. In Pro-\nceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th In-\nternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 2567–2577.\nAndrey Kormilitzin, Nemanja Vaci, Qiang Liu, and\nAlejo Nevado-Holgado. 2021. Med7: A transfer-\nable clinical natural language processing model for\nelectronic health records. Artificial Intelligence in\nMedicine, 118:102086.\nEric Lehman, Evan Hernandez, Diwakar Mahajan,\nJonas Wulff, Micah J Smith, Zachary Ziegler, Daniel\nNadler, Peter Szolovits, Alistair Johnson, and Emily\nAlsentzer. 2023. Do we still need clinical language\nmodels? In Proceedings of the Conference on Health,\nInference, and Learning, volume 209 of Proceed-\nings of Machine Learning Research, pages 578–597.\nPMLR.\nJiao Li, Yueping Sun, Robin J Johnson, Daniela Sci-\naky, Chih-Hsuan Wei, Robert Leaman, Allan Peter\nDavis, Carolyn J Mattingly, Thomas C Wiegers, and\nZhiyong Lu. 2016. Biocreative v cdr task corpus:\na resource for chemical disease relation extraction.\nDatabase, 2016.\nYunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steve\nJiang, and You Zhang. 2023. Chatdoctor: A medical\nchat model fine-tuned on a large language model\nmeta-ai (llama) using medical domain knowledge.\nCureus, 15(6).\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback.\nAdvances in Neural\nInformation Processing Systems, 35:27730–27744.\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow,\nRuxandra Cojocaru, Alessandro Cappelli, Hamza\nAlobeidli, Baptiste Pannier, Ebtesam Almazrouei,\nand Julien Launay. 2023. The RefinedWeb dataset\nfor Falcon LLM: outperforming curated corpora\nwith web data, and web data only. arXiv preprint\narXiv:2306.01116.\nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya\nSutskever, et al. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nOmid Rohanian, Mohammadmahdi Nouriborji, Hannah\nJauncey, Samaneh Kouchaki, ISARIC Clinical Char-\nacterisation Group, Lei Clifton, Laura Merson, and\nDavid A. Clifton. 2023a. Lightweight transformers\nfor clinical natural language processing.\nOmid\nRohanian,\nMohammadmahdi\nNouriborji,\nSamaneh Kouchaki, and David A Clifton. 2023b. On\nthe effectiveness of compact biomedical transformers.\nBioinformatics, 39(3):btad103.\nAlexey Romanov and Chaitanya Shivade. 2018.\nLessons from natural language inference in the clini-\ncal domain. arXiv:1808.06752 [cs].\nLarry Smith, Lorraine K Tanabe, Cheng-Ju Kuo,\nI Chung, Chun-Nan Hsu, Yu-Shi Lin, Roman Klinger,\nChristoph M Friedrich, Kuzman Ganchev, Manabu\nTorii, et al. 2008. Overview of biocreative ii gene\nmention recognition. Genome biology, 9(2):1–19.\nWeiyi Sun, Anna Rumshisky, and Ozlem Uzuner. 2013.\nEvaluating temporal relations in clinical text: 2012\ni2b2 challenge. Journal of the American Medical\nInformatics Association, 20(5):806–813.\nAugustin Toma, Patrick R Lawler, Jimmy Ba, Rahul G\nKrishnan, Barry B Rubin, and Bo Wang. 2023. Clini-\ncal camel: An open-source expert-level medical lan-\nguage model with dialogue-based knowledge encod-\ning. arXiv preprint arXiv:2305.12031.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nÖzlem Uzuner, Brett R South, Shuying Shen, and\nScott L DuVall. 2011. 2010 i2b2/va challenge on\nconcepts, assertions, and relations in clinical text.\nJournal of the American Medical Informatics Associ-\nation, 18(5):552–556.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing\nsystems, 30.\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\ndrew M Dai, and Quoc V Le. 2021. Finetuned lan-\nguage models are zero-shot learners. arXiv preprint\narXiv:2109.01652.\nChaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang,\nYanfeng Wang, and Weidi Xie. 2023. Pmc-llama:\nTowards building open-source language models for\nmedicine.\nA\nAppendix\nLlama 2\nLlama  2\n### Instruction:\nIn the provided text, your objective is to recognize and\nlabel Named Entities associated with diseases using\nthe BIO labeling scheme. Start by marking the\nbeginning of a disease-related phrase with B (Begin),\nand then continue with I (Inner) for the subsequent\nwords within that phrase. Non-disease words should\nbe labeled as O.\n### Input:\nWe now show that BRCA1 encodes a 190 - kD protein with\nsequence homology and biochemical analogy to the\ngranin protein family .\n### Output:\nB (Begin) I (Inner) BRCA1 (Disease) kD (Disease) protein\n(Disease) sequence (Disease) homology (Disease)\nbiochemical \n(Disease) \nanalogy \n(Disease) \ngranin\n(Disease) protein (Disease) family (Disease)\n### Instruction:\nIn the provided text, your objective is to recognize and\nlabel Named Entities associated with diseases using\nthe BIO labeling scheme. Start by marking the\nbeginning of a disease-related phrase with B (Begin),\nand then continue with I (Inner) for the subsequent\nwords within that phrase. Non-disease words should\nbe labeled as O.\n### Input:\nOvarian cancer risk in BRCA1 carriers is modified by the\nHRAS1 variable number of tandem repeat ( VNTR )\nlocus .\n### Output:\nB (Begin) I (Inner) HRAS1 O (Non-disease) VNTR (Non-\ndisease)\n### Instruction:\nIn the provided text, your objective is to recognize and label Named\nEntities associated with diseases using the BIO labeling scheme.\nStart by marking the beginning of a disease-related phrase with B\n(Begin), and then continue with I (Inner) for the subsequent words\nwithin that phrase. Non-disease words should be labeled as O.\n### Input:\nWe now show that BRCA1 encodes a 190 - kD protein with sequence\nhomology and biochemical analogy to the granin protein family .\n### Output:\nWe : O\nnow : O\nshow : O\nthat : O\nBRCA1 : O\nencodes : O\na : O\n190 : O\n- : O\nkD : O\nprotein : O\nwith : O\nsequence : O\nhomology : O\nand : O\nbiochemical : O\nanalogy : O\nto : O\nthe : O\ngranin : O\nprotein : O\nfamily : O\n. : O\n### Instruction:\nIn the provided text, your objective is to recognize and label Named\nEntities associated with diseases using the BIO labeling scheme.\nStart by marking the beginning of a disease-related phrase with B\n(Begin), and then continue with I (Inner) for the subsequent words\nwithin that phrase. Non-disease words should be labeled as O.\n### Input:\nOvarian cancer risk in BRCA1 carriers is modified by the HRAS1\nvariable number of tandem repeat ( VNTR ) locus .\n### Output:\nOvarian : B\ncancer : I\nrisk : O\nin : O\nBRCA1 : O\ncarriers : O\nis : O\nmodified : O\nby : O\nthe : O\nHRAS1 : O\nvariable : O\nnumber : O\nof : O\ntandem : O\nrepeat : O\n( : O\nVNTR : O\n) : O\nlocus : O\n. : O\nLlama2-MedTuned\nLlama2-MedTuned\nFigure 4: Sample outputs of the Llama2 model and Llama2-MedTuned on Named Entity Recognition\nLlama2-MedTuned\nLlama 2\nLlama 2\n### Instruction:\nYour task is to determine the relationships between medical\nproblems, treatments, and tests within the clinical text. Medical\nproblems are marked as @problem$, medical tests are marked as\n@test$, and treatments are marked as @treatment$. Categorize the\nrelationship between two entities in the text as one of the following\noptions:\nTreatment improves medical problem (TrIP)\nTreatment worsens medical problem (TrWP)\nTreatment causes medical problem (TrCP)\nTreatment is administered for medical problem (TrAP)\nTreatment is not administered because of medical problem (TrNAP)\nTest reveals medical problem (TeRP)\nTest conducted to investigate medical problem (TeCP)\nMedical problem indicates medical problem (PIP)\nNo Relations\n### Input:\nShe has an @problem$ controlled with @treatment$\n### Output:\nTreatment improves medical problem (TrIP)\nTreatment worsens medical problem (TrWP)\nTreatment causes medical problem (TrCP)\nTreatment is administered for medical problem (TrAP)\n...\n### Instruction:\nYour task is to determine the relationships between medical\nproblems, treatments, and tests within the clinical text. Medical\nproblems are marked as @problem$, medical tests are marked as\n@test$, and treatments are marked as @treatment$. Categorize the\nrelationship between two entities in the text as one of the following\noptions:\nTreatment improves medical problem (TrIP)\nTreatment worsens medical problem (TrWP)\nTreatment causes medical problem (TrCP)\nTreatment is administered for medical problem (TrAP)\nTreatment is not administered because of medical problem (TrNAP)\nTest reveals medical problem (TeRP)\nTest conducted to investigate medical problem (TeCP)\nMedical problem indicates medical problem (PIP)\nNo Relations\n### Input:\nThis is an 83 y/o female with moderate AS , s/p MVR 27 years ago ,\ns/p PPM , @problem$ , CHF , p/w dsypnea and @problem$ x 4-5\ndays \n### Output:\nTreatment improves medical problem (TrIP)\nTreatment worsens medical problem (TrWP)\nTreatment causes medical problem (TrCP)\n...\n### Instruction:\nYour task is to determine the relationships between\nmedical problems, treatments, and tests within the\nclinical text. Medical problems are marked as @problem$,\nmedical tests are marked as @test$, and treatments are\nmarked as @treatment$. Categorize the relationship\nbetween two entities in the text as one of the following\noptions:\nTreatment improves medical problem (TrIP)\nTreatment worsens medical problem (TrWP)\nTreatment causes medical problem (TrCP)\nTreatment is administered for medical problem (TrAP)\nTreatment is not administered because of medical\nproblem (TrNAP)\nTest reveals medical problem (TeRP)\nTest conducted to investigate medical problem (TeCP)\nMedical problem indicates medical problem (PIP)\nNo Relations\n### Input:\nShe has an @problem$ controlled with @treatment$\n### Output:\nTrIP\n### Instruction:\nYour task is to determine the relationships between\nmedical problems, treatments, and tests within the\nclinical text. Medical problems are marked as @problem$,\nmedical tests are marked as @test$, and treatments are\nmarked as @treatment$. Categorize the relationship\nbetween two entities in the text as one of the following\noptions:\nTreatment improves medical problem (TrIP)\nTreatment worsens medical problem (TrWP)\nTreatment causes medical problem (TrCP)\nTreatment is administered for medical problem (TrAP)\nTreatment is not administered because of medical\nproblem (TrNAP)\nTest reveals medical problem (TeRP)\nTest conducted to investigate medical problem (TeCP)\nMedical problem indicates medical problem (PIP)\nNo Relations\n### Input:\nThis is an 83 y/o female with moderate AS , s/p MVR 27\nyears ago , s/p PPM , @problem$ , CHF , p/w dsypnea\nand @problem$ x 4-5 days \n### Output:\nNo Relations\nLlama2-MedTuned\nFigure 5: Sample outputs of the Llama2 model and Llama2-MedTuned on Relation Extraction\nGeneral Medical Instructions\n### Instruction:\nIn your capacity as a medical expert, follow the user's instructions and help them with their medical inquiries.\n \n### Input:\nDescribe the clinical features, diagnostic criteria, and management strategies for gastroesophageal reflux disease (GERD). Emphasize lifestyle\nmodifications and acid-suppressing medications, listing them in numbered order.\n### Output:\n \nGERD is a chronic digestive disease that occurs when stomach acid or, occasionally, stomach content, flows back into a persons' food pipe\n(esophagus). GERD may cause symptoms such as heartburn, chest pain, chest tightness, chest pressure, bloating, burping, and sour water\nfeeling in the back of the throat. GERD can lead to complications such as esophageal inflammation (esophagitis), esophageal ulcers, and\nBarrett's esophagus, which can increase the risk of adenocarcinoma of the esophagus.\n \nDiagnostic criteria for GERD include:\n \n1. Symptoms of heartburn, chest pain, chest tightness, chest pressure, bloating, burping, or sour water feeling in the back of the throat at\nleast two times a week for the past six weeks.\n2. Duration of symptoms of two or more times a week for at least six weeks.\n3. Relief of heartburn, chest pain, chest tightness, chest pressure, bloating, burping, or sour water feeling after taking an antacid or acid-\nsuppressing medication.\n4. Presence of acid in the esophagus, as demonstrated by esophageal pH testing.\n5. Presence of esophageal inflammation, as demonstrated by esophageal biopsy.\n \nTreatment options for GERD include:\n \n1. Lifestyle modifications, such as:\na. Eating smaller, more-frequent meals.\nb. Avoiding spicy foods, caffeine, nicotine, and alcohol.\nc. Waiting three to four hours after a meal before lying down.\nd. Raising the head of the bed about eight inches with blocks. \ne. Avoiding sleeping or lying down within two hours of a meal.\nf. Reducing weight if overweight.\ng. Quitting smoking and avoiding exposure to secondhand smoke.\nh. Avoiding stress.\n2. Acid-suppressing medications, such as:\na. Antacids, such as omeprazole (Prilosec), lansoprazole (Prevail), pantoprazole (Protonix), and rabeperazole (Risperidone).\nb. H2-receptor antagonists, such as cimetidine (Tagamet), ranitidine (Ranitidine), famotidine (Pepcid), and nizatidine (Axid).\nc. Proton pump inhibitors (PPIs), such as omeprazole (Prilosec), lansoprazole (Prevail), pantoprazole (Protonix), and rabeperazole\n(Risperidone).\nFigure 6: Llama2-MedTuned output sample on general medical instructions\nChat Doctor\n### Instruction:\nYour identity is a doctor, kindly provide answers to the\nmedical questions with consideration of the patient's\ndescription. Determine the relation between the two\nmedical terms.\n### Input:\nHi doctor, My last USG report showed intrauterine\npregnancy with 8 mm gestation sac, no fetal and yolk sac.\nLast week I had brown discharge with mild lower\nabdominal pain and was prescribed Susten 200 mg (oral).\nNow, I am feeling the pain frequently in the right lower\nabdomen with mild bleeding and pain. It is less when I lie\non bed. What to do?\n### Output:\nHello dear, I understand your concern. In my opinion the\nbleeding along with abdominal pain might be due to\nmiscarriage or abnormal pregnancy. I suggest you to get\na repeat ultrasound done to know the pregnancy status.\nIf the gestational sac is present without fetal and yolk sac\nit suggests miscarriage or blighted ovum. If the sac is\nempty it also suggests miscarriage. So I suggest you to get\na repeat ultrasound done to know the pregnancy status.\nAvoid physical stress and intercourse. Take rest, Don't\nworry.\nBest regards...\nUMLS\n### Instruction:\nIn your capacity as a doctor, it is expected that you answer the\nmedical questions relying on the patient's description. Explain the\ndefinition of the medical term.\n### Input:\nWhat is the meaning of milligram/day?\n### Output:\nA unit of mass commonly used to express the dose of a substance to\nbe administered over a period of time. One milligram/day is equal to\none thousandth of a gram per day. \nUMLS Relation\n### Instruction:\nYour identity is a doctor, kindly provide answers to the medical\nquestions with consideration of the patient's description. Determine\nthe relation between the two medical terms.\n### Input:\n###Question: \nWhat is the relation between L-DOPS and Product containing\nprecisely droxidopa 100 milligram/1 each conventional release oral\ncapsule (clinical drug) ?\n### Output:\n###Answer: Product containing precisely droxidopa 100 milligram/1\neach conventional release oral capsule (clinical drug) has active\ningredient: L-DOPS\nFigure 7: Llama2-MedTuned outputs on a few medical generation tasks\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG",
    "68T50",
    "I.2.7"
  ],
  "published": "2023-12-31",
  "updated": "2023-12-31"
}