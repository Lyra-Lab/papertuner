{
  "id": "http://arxiv.org/abs/2401.01487v1",
  "title": "Natural Language Processing and Multimodal Stock Price Prediction",
  "authors": [
    "Kevin Taylor",
    "Jerry Ng"
  ],
  "abstract": "In the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural language\nprocessing (NLP) models are commonly employed to predict said prices. This\npaper utilizes stock percentage change as training data, in contrast to the\ntraditional use of raw currency values, with a focus on analyzing publicly\nreleased news articles. The choice of percentage change aims to provide models\nwith context regarding the significance of price fluctuations and overall price\nchange impact on a given stock. The study employs specialized BERT natural\nlanguage processing models to predict stock price trends, with a particular\nemphasis on various data modalities. The results showcase the capabilities of\nsuch strategies with a small natural language processing model to accurately\npredict overall stock trends, and highlight the effectiveness of certain data\nfeatures and sector-specific data.",
  "text": "Natural Language Processing and Multimodal\nStock Price Prediction\nKevin Taylor, Jerry Ng\nJuly 2023\nAbstract\nIn the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural lan-\nguage processing (NLP) models are commonly employed to predict said\nprices. This paper utilizes stock percentage change as training data, in\ncontrast to the traditional use of raw currency values, with a focus on an-\nalyzing publicly released news articles. The choice of percentage change\naims to provide models with context regarding the significance of price\nfluctuations and overall price change impact on a given stock. The study\nemploys specialized BERT natural language processing models to predict\nstock price trends, with a particular emphasis on various data modalities.\nThe results showcase the capabilities of such strategies with a small nat-\nural language processing model to accurately predict overall stock trends,\nand highlight the effectiveness of certain data features and sector-specific\ndata.\n1\nIntroduction\nStock price prediction is a crucial part of financial decision making.\nPrevi-\nous works in this field tended to use artificial intelligence technologies such as\nlong short-term memory networks (LSTMs)[1, 2, 3, 4], support-vector machines\n(SVMs)[5, 6, 7], and natural language processing (NLP) models[8, 9, 10, 11].\nThese techniques are relevant to the task of stock market prediction. LSTM\nmodels are well-suited for time series predictions, which are useful in stock price\nprediction because the price of a stock can follow certain trends and cycles over\ntime. SVM models are adept at handling high-dimension and nonlinear data.\nSince most stocks are affected by multiple factors(dimensions) and do not have\nlinear price trends, SVM networks are a good candidate for prediction. Finally,\nNLP models are useful because they can analyze textual sentiment, giving them\nthe ability to gauge public opinion about a stock based on news headlines, and\nsuch articles can impact whether a stock rises or falls in a market.\nThis paper is not the first on the prediction of stock prices using natural lan-\nguage processing, but it does touch upon a new technique: the use of percentage\n1\narXiv:2401.01487v1  [cs.LG]  3 Jan 2024\nchange as training data. Most models that aim to predict the stock market use\nraw currency values[12], and very few papers have incorporated relative price\nincrease and decrease via the use of percent change into study, indicating that\nthis topic is prominent for research. This work aims to understand how the\nbehavior of stocks – such as their price direction – may be accurately predicted,\nand gain a deeper understanding of how the market behaves. This goal is ac-\ncomplished by leveraging sentiment analysis on publicly released news articles,\nand training a model using stock value percent change instead of raw price val-\nues. The reasoning behind using percent change instead of raw dollar price is to\nhelp models make more accurate decisions by marking changes in the context\nof overall company stock price. A stock worth $50 dropping $5 in value is a\nlot more significant than a stock worth $6,000 dropping $5. Arming the model\nwith stock percent change allows it to see the scope of impact that the price\nchange has. The models should be able to determine that $5 isn’t as significant\nto a stock at $6000(0.083% change), aiding in their predictive accuracy.\n2\nMethodology\nFor our primary dataset, we searched the web for news articles on a given\nset of dates for each stock in the S&P 500. The total number of data points\nis approximately 8,000, with all collected during the 2022-2023 window. Our\nsecondary dataset was closer to 700 points, and focused specifically on the area\nof physical and virtual technology companies like Google, Amazon, and Tesla.\nWe created the tech subclass in order to better study how predictive techniques\nmight be specialized to certain industries or fields.\nFigure 1: Dataset Table\nWe tested our model by modifying the modalities it was able to access. For\neach news article found, a data point was added to the collection containing key\ninformation such as:\n• The article headline\n• The article source\n• The date\n• The company and stock symbol\n• The price before, after, and the percent change from the market opening\nto closing on a selected date\n2\nThe versions/modalities of data given to the model are as follows:\n• 1st version: Article Headlines, Article Sources, Company Name\n• 2nd version: Article Headlines, Company Name\n• 3rd version: Article Headlines, Article Sources\n• 4th version: Article Headlines, Article Sources, Company Name, Date of\nrecorded price\n• *5th version: Article Headlines, Article Sources, Company Name\n• *6th version: Article Headlines, Article Sources, Company Name, Date of\nrecorded price\n* indicates the version was trained symbolically, given only 1 or -1 based on the\nsign of the actual value: 2.1232 is substituted for 1, -3.0832 is substituted for\n-1, and so on\n3\nModel\nWe opted to use a variation of the BERT family of models known as Bert-\nTiny[13][14] for the backbone, because it is small and lightweight, with only\n14.5M parameters.\nThe BERT architecture begins by tokenizing the input,\nconverting words into specialized numbers in between 0 and 1. This tokenization\nprocess generated both word embeddings and input embeddings.\n1. Word Embeddings: each word is assigned a unique set of numbers, and\nevery time that specific word is used, the same word embeddings will exist\nin that positional space in the word embeddings array.\n2. Positional embeddings: each word is placed in the context of the words\nsurrounding it. This means that while the word ”out” might be used in\n2 parts of the sentence, it has a different context and potential meaning\neach time.\nFinally, both of these sets of embeddings are combined to form the input em-\nbeddings.\nNext, the input embeddings are passed through the BERT model itself:\nfirst, multi-head attention nodes, which contribute to the model being able to\nrealize the context of each word. This aids analysis. Then, the input is passed\nthrough a neural network and activated using the GELU function. This process\nis repeated N = 2 times. A dropout layer is next applied. Then comes the loss\nfunction. Mean-Squared Error(MSE) loss is then applied.\nMSE = 1\nn\nn\nX\ni=1\n(ˆyi −yi)2\n(1)\n3\nThe MSE loss algorithm works by squaring the difference between the predicted\nand real values, which serves two key purposes. The first is to make all error\nvalues positive, so the MSE error can emphasize the accurate magnitude of\nerrors rather than their direction. The second purpose of the squaring function\nis to discriminate based on the magnitude of error: large error values will be\nthat much larger when squared, while smaller error values will become less\nsignificant when squared. This also means large outliers, such as data points\nthat vary drastically from the average, will be weighted heavily. MSE overall\nenables the model to focus on avoiding large, significant errors. Finally, dropout,\nMSE loss, and the Adam optimization algorithm is applied before the prediction\nis completed.\n4\nFigure 2: The BERT-Tiny Architecture\n5\n4\nExperimental Results\nWe analyzed our models in several different ways. First, we evaluated the models\nby to price direction accuracy. We used mean squared error (MSE) accuracy as\nan evaluation metric to gauge the performance of each model. The testing data\nused to measure model performance was obtained by dividing our data into two\ngroups: testing and training. We opted for a 10:90 split, meaning 10% of our\noriginal data became the testing data while the remaining 90% was used to train\nthe model. Both the testing and training classes were created at random from\nthe collected data.\n4.1\nLSTM Comparison\nOur model groups compared to the LSTM standard model on testing data\ncollected periodically over the span of 1 year are as follows:\nFigure 3: BERT vs LSTM Metrics\nNote that the accuracy within 2% and accuracy within 5% when the prediction\nis in the proper direction is only measured with the first 4 versions of each BERT\nmodel class, since the last 2 versions of models were not trying to approach the\nexact model price but symbolically indicate direction, and weren’t even trained\non exact prices. Thus, we cannot expect our model to predict them, and any\nstatistic including their approximation to the actual price would be inaccurate.\nAs shown in the table above, the LSTM seems to perform just a bit worse\nthan the general and tech models. The LSTM performed much worse than our\nmodels when rated on how close to the real price it predicted.\nHowever, the statistics above measured the average accuracy of models\ntrained using a variety of modalities. The higher performing models of each\nversion compared differently to the LSTM. This demonstrates that not all mod-\nels are superior to LSTM, but the average variant of our models exceeds the\nperformance of the classic LSTM.\n6\nFigure 4: Tech Model (Ver. 2) vs. LSTM\n4.2\nModel Accuracy Statistics\nFigure 5: General Model Price Direction Accuracy\nFigure 6: Tech Model Price Direction Accuracy\nIn addition, there are patterns represented in each version’s accuracy that speaks\nto the efficacy of the modalities used in each version. One important trait of\nour model was its overall accuracy, in the sense that it is predicting not only\nindividual prices, but a specific trend and pattern as a whole. As we use more\nand more validation data with the model, the more accurately it begins to\npredict the overall trend. Using a larger scope, our model is generally able to\naccurately predict stock prices and stock trends when simply given a collection\nof news headlines.\n7\nFigure 8: Accuracy Graph of Tech 6 Model\nFigure 7: Accuracy Graph of General 2 Model\nAs evident by the charts above, the models are capable of following long term\ntrends proficiently. While short-term case-by-case instances, such as individual\naccuracy ratings, might not be as high (74.04% and 56.66% price direction\naccuracy respectively), as time continues, the model is able to adapt quite well\nto the trend of the data. The model’s ability to adapt to long-term data trends\nis important, because while it may be only proficient in predicting small stock\nmovements, the ability to track and predict overall trends is much more useful\nin long-term investment strategies than day-by-day cases.\n4.3\nComparison With Similar Models\nOur accuracy can be compared to a similar type of model on stock price prediction[15].\nIt is important to note that this model was only tested on specific stocks, while\nour model was given a much more diverse pool of stocks as inputs. It is also\nworth noting that their model was tested on less data than ours was.\n8\nFigure 9:\nFigure 10:\nAs visible in our model accuracy graphs and the graphs of similar mod-\nels displayed above, both of which relatively match the real stock price with\ntheir predictions, our model’s accuracy over time is quite comparable to models\nproposed by similar papers.\n5\nDiscussion and Analysis\nThe BERT models we have developed have thus far shown promise in predicting\nthe stock market, especially in terms of overall trends, but they also introduce\nseveral illuminating concepts about the process of stock prediction itself. One\nsuch concept is observed in the metrics of models of version 2. In both types of\nmodel, general and tech-based, the 2nd version was always the most successful\nat predicting stock direction and was also the most accurate at predicting precise\n9\nprice, as version 2 models were also very accurate in comparison with models of\nother versions.\nFigure 11: Version 2 Models Comparison\nThis version was only fed information about the company name and article\nheadline. It was restricted from the date and source of said article. It might\nintuitively make sense for the model to perform strongly here because the name\nof the target company and sentiment to be analyzed are both very strong indica-\ntors of stock performance. This isn’t to say other information such as company\nname and date isn’t as important(model version 4 performed well, see the gen-\neral and tech model accuracy charts), but feeding only the most important data\nto the model might play a role in its accuracy. There might also be a bit of\nconfusion with the model, as it attempts to find a relationship between more\nand more variables.\nThis observation illustrates a few key points. Firstly, it doesn’t appear to\nmatter where the article came from or by whom it was written. Adding this\ninformation serves to decrease accuracy, as evidenced by the significantly lower\naccuracy rates of models incorporating this information.\nSecondly, the date\nappears to have no effect on the algorithm. In fact, accuracy rates between\nidentical models apart from access to date information perform very similarly.\nThis might be because a factor such as the exact time of an article is just noise\nto the model; not every date and time is going to be significant because there\nisn’t always a correlation between the date an article is published and the price\nof a stock.\nFigure 12: Date Information Effect on Model Accuracy\nOf course, as mentioned earlier, all of these prices were collected in the\nwindow of the 2022-2023 year, so their accuracy is only known during this time\nperiod. This does give the models the added benefit of not being influenced by\nbiased data such as that during the early 2000s, in which the technology market\nwas very different due to the dot com bubble in part.\nAnother trend in the metrics of our models is the comparison between the\nsymbolically trained models and the non-symbolically trained models. For ex-\nample, both versions 1 and 5 are identical save for the fact that version 5 models\n10\nare symbolic, and version 1 models are not. The same goes for models of version\n4 and, it’s symbolic clone, version 6. When we examine the accuracy disparity\nbetween the two, we see that there is not a significant shift in accuracy between\nthe symbolic and regular models. The regular models outperform the symbolic\nmodels by some degree, but this difference in performance ranging from a frac-\ntion of a percent to just under 4%. This proves that symbolic training doesn’t\nhave a significant impact on the performance of a model. In fact, looking at the\nminute details, it is more beneficial to not train symbolically, as the models that\ntended to train based on exact stock prices ended up scoring higher in direc-\ntional accuracy than those that trained symbolically. This indicates that having\nexact price data may be more beneficial in some cases than training based on\nprice direction alone.\nFigure 13: Symbolic v Non-Symbolic\nFinally, there is the question of grouping. Does a model trained on sector-\nspecific stocks perform better because it is able to grasp certain characteristics\nof the field? For example, tech stocks tend to be more volatile when compared\nto beverage stocks. The metrics tell us it might not matter if models are trained\non sector-specific datasets. It is true that the model with the highest accuracy\nrate belongs to the sector-specific tech-based group, but so does the model with\nthe lowest accuracy rate. This indicates that specific stocks don’t necessarily\nneed to be grouped with similar ones in order to be accurately predicted, that\na model trained on a variety of stocks can still function just as well.\n6\nConclusion\nWhile this paper has been able to explore avenues such as useful modalities and\nstrategies for stock price prediction, there is still much more to be uncovered.\nThe model can’t accurately predict every stock trend, or infinitely into the\nfuture, but it might indicate general, high-level trends, which can be useful\nfor investors as a sort of aid.\nInvestors can work without models like this,\nand models like this can work without investors, but a combination of human\nthought and machine learning might be able to strike a certain balance and\npotentially outperform sole humans or models. For example, using models such\nas ours that are generally accurate can be useful to help human investors make\ndecisions about whether to buy or sell a stock, but such models don’t always\nnecessarily need to determine the overall action. Further research might include\na further in-depth analysis of what specific modalities are necessary to accurately\npredict the price of a stock. This can be found via more extensive trial-and-\nerror, with the addition of modalities such as average sector loss/gain on a given\n11\ndate, total loss/gain for that particular stock on a given date, and cost of a given\nstock relative to the average of stocks in the same sector. Further studies may\nalso explore integrating a raw price factor into the algorithm in order to see the\neffect of that information.\nReferences\n[1] M. A. Istiake Sunny, M. M. S. Maswood, and A. G. Alharbi, “Deep learning-\nbased stock price prediction using lstm and bi-directional lstm model,”\nin 2020 2nd Novel Intelligent and Leading Emerging Sciences Conference\n(NILES), 2020, pp. 87–92.\n[2] H. Li, Y. Shen, and Y. Zhu, “Stock price prediction using attention-based\nmulti-input lstm,” in Proceedings of The 10th Asian Conference on\nMachine Learning, ser. Proceedings of Machine Learning Research, J. Zhu\nand I. Takeuchi, Eds., vol. 95.\nPMLR, 14–16 Nov 2018, pp. 454–469.\n[Online]. Available: https://proceedings.mlr.press/v95/li18c.html\n[3] K. J, H. E, M. S. Jacob, and D. R, “Stock price prediction based on lstm\ndeep learning model,” in 2021 International Conference on System, Com-\nputation, Automation and Networking (ICSCAN), 2021, pp. 1–4.\n[4] K. Chen, Y. Zhou, and F. Dai, “A lstm-based method for stock returns pre-\ndiction: A case study of china stock market,” in 2015 IEEE International\nConference on Big Data (Big Data), 2015, pp. 2823–2824.\n[5] H. Ince and T. B. Trafalis, “Short term forecasting with support vector\nmachines and application to stock price prediction,” International Journal\nof General Systems, vol. 37, no. 6, pp. 677–687, 2008. [Online]. Available:\nhttps://doi.org/10.1080/03081070601068595\n[6] Y. Lin, H. Guo, and J. Hu, “An svm-based approach for stock market\ntrend prediction,” in The 2013 International Joint Conference on Neural\nNetworks (IJCNN), 2013, pp. 1–7.\n[7] Z. Hu, J. Zhu, and K. Tse, “Stocks market prediction using support vector\nmachine,” in 2013 6th International Conference on Information Manage-\nment, Innovation Management and Industrial Engineering, vol. 2, 2013,\npp. 115–118.\n[8] J. Kim, J. Seo, M. Lee, and J. Seok, “Stock price prediction through the\nsentimental analysis of news articles,” in 2019 Eleventh International Con-\nference on Ubiquitous and Future Networks (ICUFN), 2019, pp. 700–702.\n[9] F.\nColasanto,\nL.\nGrilli,\nD.\nSantoro,\nand\nG.\nVillani,\n“Albertino\nfor stock price prediction:\na gibbs sampling approach,” Information\nSciences,\nvol. 597,\npp. 341–357,\n2022. [Online]. Available:\nhttps:\n//www.sciencedirect.com/science/article/pii/S002002552200264X\n12\n[10] S. Mohan, S. Mullapudi, S. Sammeta, P. Vijayvergia, and D. C. Anastasiu,\n“Stock price prediction using news sentiment analysis,” in 2019 IEEE Fifth\nInternational Conference on Big Data Computing Service and Applications\n(BigDataService), 2019, pp. 205–208.\n[11] H. Huang and T. Zhao, “Stock market prediction by daily news via natural\nlanguage processing and machine learning,” in 2021 International Confer-\nence on Computer, Blockchain and Financial Development (CBFD), 2021,\npp. 190–196.\n[12] L. Sayavong, Z. Wu, and S. Chalita, “Research on stock price prediction\nmethod based on convolutional neural network,” in 2019 International Con-\nference on Virtual Reality and Intelligent Systems (ICVRIS), 2019, pp.\n173–176.\n[13] P. Bhargava, A. Drozd, and A. Rogers, “Generalization in nli: Ways (not)\nto go beyond simple heuristics,” 2021.\n[14] I. Turc, M. Chang, K. Lee, and K. Toutanova, “Well-read students\nlearn\nbetter:\nThe\nimpact\nof\nstudent\ninitialization\non\nknowledge\ndistillation,”\nCoRR,\nvol.\nabs/1908.08962,\n2019.\n[Online].\nAvailable:\nhttp://arxiv.org/abs/1908.08962\n[15] Y. Guo, “Stock price prediction based on lstm neural network: the effec-\ntiveness of news sentiment analysis,” in 2020 2nd International Conference\non Economic Management and Model Engineering (ICEMME), 2020, pp.\n1018–1024.\n13\n",
  "categories": [
    "cs.LG",
    "cs.CL"
  ],
  "published": "2024-01-03",
  "updated": "2024-01-03"
}