{
  "id": "http://arxiv.org/abs/2401.05632v4",
  "title": "Natural Language Processing for Dialects of a Language: A Survey",
  "authors": [
    "Aditya Joshi",
    "Raj Dabre",
    "Diptesh Kanojia",
    "Zhuang Li",
    "Haolan Zhan",
    "Gholamreza Haffari",
    "Doris Dippold"
  ],
  "abstract": "State-of-the-art natural language processing (NLP) models are trained on\nmassive training corpora, and report a superlative performance on evaluation\ndatasets. This survey delves into an important attribute of these datasets: the\ndialect of a language. Motivated by the performance degradation of NLP models\nfor dialectal datasets and its implications for the equity of language\ntechnologies, we survey past research in NLP for dialects in terms of datasets,\nand approaches. We describe a wide range of NLP tasks in terms of two\ncategories: natural language understanding (NLU) (for tasks such as dialect\nclassification, sentiment analysis, parsing, and NLU benchmarks) and natural\nlanguage generation (NLG) (for summarisation, machine translation, and dialogue\nsystems). The survey is also broad in its coverage of languages which include\nEnglish, Arabic, German, among others. We observe that past work in NLP\nconcerning dialects goes deeper than mere dialect classification, and extends\nto several NLU and NLG tasks. For these tasks, we describe classical machine\nlearning using statistical models, along with the recent deep learning-based\napproaches based on pre-trained language models. We expect that this survey\nwill be useful to NLP researchers interested in building equitable language\ntechnologies by rethinking LLM benchmarks and model architectures.",
  "text": "1\nNatural Language Processing for Dialects of a Language: A\nSurvey\nADITYA JOSHI, University of New South Wales, Australia\nRAJ DABRE, National Institute of Information and Communications Technology, Japan\nDIPTESH KANOJIA, Institute for People-Centred AI, University of Surrey, United Kingdom\nZHUANG LI, Monash University, Australia\nHAOLAN ZHAN, Monash University, Australia\nGHOLAMREZA HAFFARI, Monash University, Australia\nDORIS DIPPOLD, University of Surrey, United Kingdom\nState-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report\na superlative performance on evaluation datasets. This survey delves into an important attribute of these\ndatasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectal\ndatasets and its implications for the equity of language technologies, we survey past research in NLP for\ndialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories:\nnatural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing,\nand NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation,\nand dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic,\nGerman, among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect\nclassification, and extends to several NLU and NLG tasks. For these tasks, we describe classical machine\nlearning using statistical models, along with the recent deep learning-based approaches based on pre-trained\nlanguage models. We expect that this survey will be useful to NLP researchers interested in building equitable\nlanguage technologies by rethinking LLM benchmarks and model architectures.\nCCS Concepts: • Computing methodologies →Natural language processing.\nAdditional Key Words and Phrases: NLP, dialects, natural language processing, linguistic diversity, large\nlanguage models, inclusion\nACM Reference Format:\nAditya Joshi, Raj Dabre, Diptesh Kanojia, Zhuang Li, Haolan Zhan, Gholamreza Haffari, and Doris Dippold.\nxxxx. Natural Language Processing for Dialects of a Language: A Survey. J. ACM 1, 1, Article 1 (January xxxx),\n35 pages. https://doi.org/XXXXXXX.XXXXXXX\n1\nINTRODUCTION\nNatural language processing (NLP) is an area of artificial intelligence that deals with processing\nof human language in its textual form. NLP tasks are broadly viewed as two categories: natural\nAuthors’ addresses: Aditya Joshi, aditya.joshi@unsw.edu.au, University of New South Wales, Sydney, Australia, 2052; Raj\nDabre, raj.dabre@nict.go.jp, National Institute of Information and Communications Technology, Kyoto, Japan; Diptesh\nKanojia, d.kanojia@surrey.ac.uk, Institute for People-Centred AI, University of Surrey, Guildford, United Kingdom; Zhuang\nLi, zhuang.li1@monash.edu, Monash University, Melbourne, Australia; Haolan Zhan, haolan.zhan@monash.edu, Monash\nUniversity, Melbourne, Australia; Gholamreza Haffari, Gholamreza.Haffari@monash.edu, Monash University, Melbourne,\nAustralia; Doris Dippold, d.dippold@surrey.ac.uk, University of Surrey, Guildford, United Kingdom.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\n© 2024 Association for Computing Machinery.\n0004-5411/xxxx/1-ART1 $15.00\nhttps://doi.org/XXXXXXX.XXXXXXX\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\narXiv:2401.05632v4  [cs.CL]  6 Dec 2024\n1:2\nJoshi, et al.\nlanguage understanding (NLU) and natural language generation (NLG). The former broadly covers\nlanguage understanding tasks such as dialect identification or sentiment classification, as well as\ntasks such as morphosyntactic analysis. The latter includes tasks where both the input and the output\nare textual sequences (for example, summarisation). The state-of-the-art NLP, for both NLU and\nNLG, is based on Transformer-based models [Naveed et al. 2023; Zhao et al. 2023]. Large language\nmodels (LLMs) that use decoders in the Transformer architecture have significantly increased\nattention toward NLP leading to LLM-based applications in several domains such as medicine,\nbusiness or law. LLMs released by commercial organisations report an increasingly higher number\nof parameters and, as a result, improved performances on several NLP tasks. NLP approaches using\nLLMs are largely viewed as black-box models trained on massive corpora whose composition is\nnot accurately known. This survey dissects one of many attributes in which variations may exist in\nthe training and test corpora: dialects of a language.\nTraditionally, a dialect is defined as the regionally or locally based variety of a language [Haugen\n1966]. Wikipedia defines a dialect as “a variety of a language that is a characteristic of a particular\ngroup of the language’s speakers.” Zampieri and Nakov [2021] state that dialects are language\nvarieties characterised by systematic patterns of variation. The current notion of dialect has\nextended to language varieties arising due to factors such as political reasons, country of origin,\nmigration histories, historical factors, register shifts and so on. In fact, there is an association\nbetween perceived social hierarchies and dialects of a language, leading to a term ‘sociolect’ [Kroch\n1986]. For the sake of brevity, we use ‘dialects’ as an umbrella term to refer to ‘dialects/national\nvarieties/cultural variants/sociolects’ of a language while acknowledging that the distinction\nbetween dialects and language is nuanced [Sandel 2015]. An example of a dialect is the national\nvariety, Australian English, whose phonemes are predominantly derived from Southern British\nEnglish and other Englishes [Cox 2006; Cox and Palethorpe 2007], but has also developed its own\nunique vocabulary [Moore 1999]. Overlapping with dialects are Creole languages that develop from\nthe process of different languages simplifying and mixing into a new form (often, a pidgin), and\nthen that form expanding and elaborating into a full-fledged language with native speakers, all\nwithin a fairly brief period. Lent et al. [2024] highlight the social and scholarly stigmatisation of\nCreole languages that has resulted in limited advances in NLP for these languages.\nIn general, our survey is catalysed by the recent efforts in extending LLMs on NLP tasks for\ndialects of different languages. As researchers continue to look ‘under the hood’ of LLMs, dialectal\ndifferences in training and testing datasets are being increasingly scrutinised, and adaptation\ntechniques to improve their performance on different dialects are being devised. As a result, we\nhope that this survey will help readers and researchers understand past work in NLP techniques\nfor dialects of a language, and contribute to ideas about fair and equitable NLP in the future.\nThere have been related surveys in the past. Zampieri et al. [2020] describes the available corpora,\nand past approaches to fundamental NLP problems such as POS tagging and parsing, along with\napplications to NLP. Our survey builds upon theirs in three ways. Firstly, we cover a wider range\nof downstream tasks such as summarisation and sentiment analysis. Also, this survey contains\nrecent papers, which highlight increasingly growing attention towards NLP for dialects. Finally,\nthe exposition of our survey adopts a deep learning-centric view, by covering deep learning-based\napproaches, in particular, the recent LLM-based approaches. Another survey by Blodgett et al.\n[2020] describes biases of different kinds in an analysis of language technologies, including dialectal\nbias. We derive from their survey to formulate the motivation and trends in NLP for dialects.\nSimilarly, Jauhiainen et al. [2019] present a survey of automatic language identification, which does\nnot differentiate between dialect or language identification, and mention that dialect identification\nmay be a more challenging task. Finally, extensive surveys focusing on languages from the Middle\nEast have been reported [Darwish et al. 2021; Shoufan and Alameri 2015]. These are surveys of\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:3\nFig. 1. An example sentence highlighting the differences between Marathi and its Samvedi dialect.\nNLP for standard and dialectal Arabic, primarily focusing on dialect identification and synthesis in\nthe form of machine translation. Our survey unifies the efforts in dialects of languages belonging\nto multiple language families. The contribution of our survey is:\n• We present past work in terms of NLU and NLG tasks, and include both pre-deep learning\nand deep learning techniques.\n• We highlight trends and future directions, and provide summary tables that will help re-\nsearchers interested in dialectal NLP research.\n• The survey covers a broad range of languages from around the world.\nThe rest of the paper is organised as follows. We motivate the need for a discussion on dialects\nin Section 2. We define the scope of the paper and highlight key trends in Section 3. We then\ncover dialect-specific resources in Section 4. Following that, Section 5 covers several NLU tasks:\ndialect identification, sentiment analysis, parsing, and NLU benchmarks. Section 6 presents relevant\napproaches in NLG for machine translation, summarisation and so on. Finally, we conclude the\nsurvey and discuss future work in the context of NLP research as well as social/ethical implications\nin Section 7. The survey contains several summary tables that will be useful for future research.\n2\nMOTIVATION\n2.1\nLinguistic Challenges Posed by Dialects\nDialectal differences primarily occur in terms of orthography, syntax and vocabulary. Some examples\nof dialectal differences in English are: ‘I might could help you with that’ observed in Southern US,\nAustralian and New Zealand English [Coats 2022; Morin and Coats 2023] as well as British and\nIrish English [Coats 2023], ‘Inside tent can not see leh !’ in Singaporean English [Wang et al. 2017]\nor the uncommon placement of adverbs in native speakers of Asian languages as in ‘Already, I\nhave done it.’ [Nagata 2014]. Also, consider the case of the Samvedi dialect of Marathi, one of 42,\nwhere we give an example of the Samvedi and Marathi sentences in Table 1. Samvedi does not\nexhibit word order differences compared to standard Marathi, but it involves heavy pronunciation\nrelaxation (ahe -> hay, and maza -> maa) and the usage of older words. Another challenge in\nhandling dialects is that two dialects of the same language can be mutually unintelligible. A classic\nexample of this is the case of the Aomori and Okinawan dialects of Japanese, which has a total\nof 47 known dialects. Therefore, it is not enough to collect data for one dialect and assume that it\nwill help in NLP for another dialect, which indicates that special attention will need to be paid to\neach dialect to ensure that it will be well-represented. Dialects assume further importance when\npeople from different cultural backgrounds interact with one another. Wang et al. [2022] show that\nmonophthongal vowels spoken by Australian English speakers may be difficult to be understood\nby Mandarin English listeners.\nDialects are also associated with pragmatics, with influences derived from macro-social factors\nsuch as region, social class, ethnicity, gender, age [Haugh and Schneider 2012]. For example,\nSchneider [2012] observes differences in small talk across inner circle varieties of English, i.e.,\nvarieties from countries where it is the primary language [Kachru 1992]. They also observed\ndifferences between speakers of different ages and genders. This suggests that the notion of ‘dialect’\ncan be linked to factors beyond geographical distribution. Merrison et al. [2012] showed that, in\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:4\nJoshi, et al.\nstudent requests to university staff, there were differences in the way obligation was expressed,\nand that these differences were linked to different ways of claiming social standing. Meyer [2014]\ncompares interactions of Australians with people from other cultures in terms of (a) building trust\nwith colleagues, (b) leading teams of a culturally dissimilar background etc. An example in the book\nstates that an Australian may invest in shorter small talk than a Mexican with a colleague. Noting\nthe differences in the pragmatic strategies of different dialect speakers provide an important social\nperspective on dialectal variation. However, these are currently not sufficiently accounted for in\nNLP.\n2.2\nRethinking LLM benchmarks\nThere are more English language speakers in countries such as India than the United States,\nAustralia and England [Dunn 2019]. In addition, an even larger number of speakers have acquired\nEnglish in a classroom context (e.g., in countries such as China, Germany or Russia) and use\nit mainly as a contact language for specific transactional purposes, e.g., business or education.\nThis latter perspective has been described through the notion of English as a lingua franca as\n“the common language of choice [...] among speakers who come from different lingua-cultural\nbackgrounds” [Jenkins 2009]. Despite that, the corpora used to train language models and more\nimportantly, the datasets used to evaluate them do not necessarily reflect dialectal variations within\na language. Inoue et al. [2021] examine the performance of BERT-based models for varieties/dialects\nof Arabic, and show that dialect proximity of pre-training and fine-tuning data bears impact on\nthe performance of the downstream task. In the case of GPT-4, the evaluation dataset consists of\nquestions from the MMLU benchmark written in Standard American English. Standard benchmarks\nused to claim performance of a language model for English primarily contain Standard American\nEnglish. It has been found that the performance does not extend to NLU tasks for dialects of\nEnglish [Ziems et al. 2022]. Further, a recent work by Fleisig et al. [2024] analyses the output of\nChatGPT for varieties of English, and shows that the generated output may be of poorer quality\nand be prone to stereotyping for non-standard dialects of English. These findings holds for most\nfoundation models that are trained on large amounts of data. The distribution of languages in the\ntraining corpora is either not known or difficult to determine.\n2.3\nFair and equitable technologies\nNLP systems that are deployed to serve multicultural communities must be mindful of the variations\nbetween different dialects. Evaluation and mitigation of disparity between dialects become an\novergrowing need in times when language models claim excellent language performance using\ndatasets from a specific dialect alone. Some examples showing the impact of dialects on the\nperformance of NLP tasks are presented in Table 1. We note that these papers are from the past\nfew years, which have otherwise witnessed a great development in the reported performance of\nNLP models.\nSome implications of dialects in terms of sociological factors are:\n(1) Performance of NLP models and per-capita GDP: A recent work by Kantharuban et al.\n[2023] show the dialectal gap in performance of LLM-based solutions for machine translation\nand automatic speech recognition for several dialects, similar to Ahia et al. [2023] who show\nthe same for topologically diverse languages. They show a positive correlation between gross\ndomestic product per capita and the efficacy of dialectal machine translation.\n(2) Healthcare monitoring: Jurgens et al. [2017] show that there exists a disparity between\npopular dialect speakers and others in the case of healthcare monitoring1.\n1They also propose a method to mitigate the disparity.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:5\nNLP Task\nPaper\nImpact\nLanguage\nclassification\n[Blodgett et al. 2016]\nLanguage detection shows lower performance\nfor African-American English.\nSentiment\nclassification\n[Okpala et al. 2022]\nText in African-American English may be\npredicted more commonly as hate speech.\nNatural Language\nUnderstanding\n[Ziems et al. 2022]\nPopular models perform worse on GLUE tasks\nfor African-American English text.\nSummarisation\n[Keswani and Celis\n2021]\nGenerated multi-document summaries\nmay be biased towards majority dialect.\nMachine transla-\ntion\n[Kantharuban et al.\n2023]\nSignificant drop in MT from and to dialects of\nPortuguese/Bengali/etc. to and from English.\nParsing\n[Scannell 2020]\nLower performance of parsers on Manx Gaelic\nas compared to Irish/Scottish Gaelic.\nTable 1. Examples of adverse impact on NLP task performance due to dialectal variations.\nFig. 2. Number of relevant ‘papers-per-year’ for keywords ‘dialects’ and ‘socio-cultural’ in the ACL Anthology.\n(3) Racial biases in hate speech detection: Okpala et al. [2022] show that hate speech classifiers\nmay lean towards predicting a text as true if it uses African-American English.\n(4) Prejudice in the prediction of employability and criminality: Hofmann et al. [2024]\nshow that dialects may introduce bias in the output of language models. As a result, a person’s\noutput with respect to their employability or criminality may be affected based on the dialects\nthey use.\nNLP may not perform as well for dialects of a language, particularly spoken by historically\nmarginalized communities such as the African-American community. This has been shown for\nlanguage identification where dialects are not predicted as the language since they differ from the\nstandard version of the language [Blodgett et al. 2016].\nAn idea closely related to the survey is the ‘Bender rule’ in NLP research. The Bender rule\nstates that the language of datasets used for evaluation must be stated explicitly without assuming\nEnglish to be the implicit default [Ducel et al. 2022]. We similarly believe that languages are not\nmonoliths and dialectal differences must be clearly stated. Similarly, Hovy and Yang [2021] show\nthat incorporating dialectal aspects is closely related to social factors of language. As a result,\nincorporating an understanding of dialects of a dataset is pivoting for fairer NLP tools.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:6\nJoshi, et al.\n2.4\nRecent work\nOne observes a renewed interest in using dialects to inform NLP tasks, as shown in Figure 2. The\nfigure was generated using the ACL anthology2. For “dialects”, we use ‘dialect’, ‘national variety’\n(subword for inflections of ‘variety’), ‘national variation’, and ‘Creole’. For “socio-cultural”, we use\nthe words “cultural\", and “socio-cultural\". We restrict to the year range 2000-2023.\nDialect awareness has been shown to improve the performance of NLP tasks such as machine\ntranslation [Sun et al. 2023], speech recognition [Plüss et al. 2023]. Recent works have also focused\non dialect-aware NLP tasks as in the case of machine translation of dialect to standard language\ntranslation as in the case of Chinese [Lu et al. 2022] (for Hokkien, a dialect of Chinese).\n3\nSCOPE & TRENDS\nThe focus of this survey is on NLP approaches that are aware of dialects: either in the form of the\nchoice of the dataset, incorporation in the model or evaluation along dimensions involving dialect.\nThe survey provides a broad introduction to past NLP research on dialects spoken in different parts\nof the world. In the forthcoming subsections, we clarify the scope of this paper (Section 3.1) and\nhighlight key trends (Section 3.2) that are described in detail in the following sections.\n3.1\nScope\nWe select papers that mention the dialect as an attribute of interest. The focus on dialects is\neither based on the evaluation datasets or the model innovations to improve performance on\ndialect-specific datasets.\nWe keep the following out of scope, primarily to effectively manage the scope of the paper:\n(1) Code-mixing: Code-mixing involves the use of words from two or more languages, often to\nreduce cognitive load. This survey does not focus on code-mixing.\n(2) Implicit selection biases: We also acknowledge that selection biases in datasets may\nintroduce dialectal variations. For example, a dataset of tweets downloaded from a specific\ncountry is likely to have predominant dialects spoken in the country. However, we cannot\nlocate these papers in particular, or, for social implications, claim that they are based on\ndialectal variations of a language without the authors mentioning so.\n(3) Accent variations: Finally, we focus on ‘text’-based research while acknowledging that\nthe speech processing community has a rich history of using acoustic data centered around\naccent. To this end, we briefly touch upon speech since dialects and speech are intertwined\nto a certain degree. However, our primary focus is on text since the text aspect has received a\nlot more attention than the speech aspect. This also sets up a situation where a future survey\ncan expand on the speech aspect of dialectal processing. The focus on the textual form is the\ntypical purview of NLP.\n(4) Systematic review: This survey is not a systematic review in the sense that we do not\nexhaustively cover all works on dialects due to limited time and paper space. Instead, we select\nkey representative papers based on our interpretation of the innovation, which, according\nto us, cover key progress and innovation in NLP for dialects. We acknowledge that we may\nhave missed out on some important papers in the field. We will incorporate these papers as\ncommunicated by readers/reviewers. However, we cover a broad range of approaches in the\nsurvey.\n2https://aclanthology.org/info/development/; Accessed on 9th January, 2024.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:7\n(5) Linguistic studies: While we acknowledge similar rich linguistic work in terms of under-\nstanding dialects, we focus on NLP tasks3. For example, dialectometry is a research area that\nstudies variations in dialects of a language [Goebl 1993] but is not included in the survey.\n3.2\nTrends\nTable 2 summarises the papers covered in this survey. We identify three trends in the past work:\n(1) Tasks in focus: Older research dealt with dialectal datasets primarily for dialect classification.\nPast work shows performance degradation when the text contains dialects of a language as\ncompared to the predominant (i.e., standard) form.\n(2) Languages in focus: The papers reporting work on dialects of Arabic are significantly\nmore than those for dialects of other languages. This has also been accelerated by research\nforums focusing on Arabic NLP. While the work in English is predominantly for the African-\nAmerican dialect of English, recent papers examine other dialects such as Indian English,\nSingaporean English and so on.\n(3) Mitigation is more than perturbation: Modifying a sentence or its representation to or\nfrom its dialectal variations has been achieved by perturbation techniques of varying com-\nplexity. However, recent papers show that dialect mitigation can be integrated into the model\narchitecture itself using adversarial networks [Ball-Burack et al. 2021], hypernetworks [Xiao\net al. 2023], etc.\nIt may seem that NLP for dialects of a language only pertains to datasets, i.e., it does not need\nany specialised handling beyond the introduction of a new dataset. However, we observe that the\nadaptation of NLP techniques for dialects operates at several points in a typical NLP pipeline:\n(1) Training resources: Labeled datasets (including treebanks) and lexicons in dialects of a\nlanguage have been reported in the past. This includes datasets with dialect labels along with\nadditional task-specific labels, where the task is an NLP research problem.\n(2) Models: Models have been enhanced with several techniques, as may be typical of the time\nof the research. The fact that dialect-aware NLP can benefit from model adaptations and not\ndataset replacement alone is a key point of the survey.\n(3) Evaluation datasets: NLP techniques evaluated on datasets in dialects have peculiar obser-\nvations. Language identification classifiers produce lower performance when the text is in a\ndialect of a language. The performance of LLMs on dialectal datasets is positively correlated\nwith socio-economic factors.\nFigure 3 shows an overview of the approaches in terms of NLP for dialects. There have been\ndifferent approaches to create labeled datasets, tree-banks and lexicons. In terms of models, past\nwork varies in terms of NLP tasks and the way dialectal adaptation is handled: dialect transformation\n(where data is translated between dialects for the purpose of processing), dialect invariance (where\nmodels are made invariant to dialects) and dialect awareness (where models include dialect-specific\ncomponents). Finally, we also describe dialectal datasets and resultant evaluations on downstream\ntasks including applications such as health monitoring.\n4\nRESOURCES\nBeing a data-driven field, NLP techniques rely on resources such as lexicons and textual datasets.\nIn this section, we describe ways in which dialectal datasets have been created.\n3We cover dialect classification in the section on natural language understanding.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:8\nJoshi, et al.\nLanguages\nInnovation\nProblem/Area\nEnglish\nChinese\nArabic\nGerman\nIndic Languages\nOther\nDataset\nMethod/Model\nEvaluation/Metric\nBenchmark\nDialect Classification\nSentiment Analysis\nMachine Translation\nMorphology/Parsing\nConversational AI\nSummarisation\nSpeech/Visual\n[Nerbonne and Heeringa 1997]\n✓\n✓\n✓\n[Nerbonne and Heeringa 2001]\n✓\n✓\n✓\n[Chiang et al. 2006]\n✓\n✓\n✓\n[Habash and Rambow 2006]\n✓\n✓\n✓\n[Chitturi and Hansen 2008]\n✓\n✓\n✓\n[Paul et al. 2011]\n✓\n✓\n✓\n✓\n✓\n✓\n[Lui and Cook 2013]\n✓\n✓\n✓\n[Abdul-Mageed and Diab 2014]\n✓\n✓\n✓\n[Cotterell and Callison-Burch 2014]\n✓\n✓\n✓\n[Darwish et al. 2014]\n✓\n✓\n✓\n[Doğruöz and Nakov 2014]\n✓\n✓\n✓\n[Estival et al. 2014]\n✓\n✓\n✓\n[Jeblee et al. 2014]\n✓\n✓\n✓\n✓\n[Zampieri et al. 2014]\n✓\n✓\n✓\n✓\n✓\n[Jørgensen et al. 2015]\n✓\n✓\n✓\n[Xu et al. 2015]\n✓\n✓\n✓\n✓\n[Zampieri et al. 2015]\n✓\n✓\n✓\n✓\n[Ali and Habash 2016]\n✓\n✓\n✓\n[Blodgett et al. 2016]\n✓\n✓\n✓\n[Burghardt et al. 2016]\n✓\n✓\n✓\n[Eskander et al. 2016]\n✓\n✓\n✓\n[Goutte et al. 2016]\n✓\n✓\n✓\n✓\n[Malmasi et al. 2016]\n✓\n✓\n✓\n✓\n[Azouaou and Guellil 2017]\n✓\n✓\n✓\n[Bowers et al. 2017]\n✓\n✓\n✓\n[Criscuolo and Aluisio 2017]\n✓\n✓\n✓\n✓\n[Hassan et al. 2017]\n✓\n✓\n✓\n✓\n✓\n[Jurgens et al. 2017]\n✓\n✓\n✓\n✓\n✓\n[Mdhaffar et al. 2017]\n✓\n✓\n✓\n[Simaki et al. 2017]\n✓\n✓\n✓\n[Abdul-Mageed et al. 2018]\n✓\n✓\n✓\n[Assiri et al. 2018]\n✓\n✓\n✓\n[Blodgett et al. 2018]\n✓\n✓\n✓\n[Darwish et al. 2018]\n✓\n✓\n✓\n[Erdmann et al. 2018]\n✓\n✓\n✓\n[Elmadany et al. 2018b]\n✓\n✓\n✓\n✓\n[Elmadany et al. 2018a]\n✓\n✓\n✓\n[Salameh et al. 2018]\n✓\n✓\n✓\n[Baly et al. 2019]\n✓\n✓\n✓\n[Fadhil et al. 2019]\n✓\n✓\n✓\n✓\n[Joukhadar et al. 2019]\n✓\n✓\n✓\n[Mulki et al. 2019]\n✓\n✓\n✓\n[Sap et al. 2019]\n✓\n✓\n✓\n[Zampieri et al. 2019]\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n[Ahmed and Hussein 2020]\n✓\n✓\n✓\n[Al-Ghadhban and Al-Twairesh 2020]\n✓\n✓\n✓\n[Alshareef and Siddiqui 2020]\n✓\n✓\n✓\n[Demszky et al. 2020]\n✓\n✓\n✓\n✓\n[Dunn and Adams 2020]\n✓\n✓\n✓\n✓\n✓\n[Hanani and Naser 2020]\n✓\n✓\n✓\n[Hou and Huang 2020]\n✓\n✓\n✓\n✓\n[Mozafari et al. 2020]\n✓\n✓\n✓\n[Tan et al. 2020]\n✓\n✓\n✓✓\n[Zhao et al. 2020]\n✓\n✓\n✓\n[Ball-Burack et al. 2021]\n✓\n✓\n✓\n[Ben Elhaj Mabrouk et al. 2021]\n✓\n✓\n✓\n[Boujou et al. 2021]\n✓\n✓\n✓\n✓\n[El Mekki et al. 2021]\n✓\n✓\n✓\n[Guellil et al. 2021]\n✓\n✓\n✓\n✓\n[Keswani and Celis 2021]\n✓\n✓\n✓\n[Kumar et al. 2021]\n✓\n✓\n✓\n✓\n✓\n[Zhang et al. 2021]\n✓\n✓\n✓\n[Chow and Bond 2022]\n✓\n✓\n✓\n[Coats 2022]\n✓\n✓\n✓\n[Eggleston and O’Connor 2022]\n✓\n✓\n✓\n[Fuad and Al-Yahya 2022]\n✓\n✓\n✓\n[Harris et al. 2022]\n✓\n✓\n✓\n[Husain et al. 2022]\n✓\n✓\n✓\n[Inoue et al. 2022]\n✓\n✓\n✓\n[Kanjirangat et al. 2022]\n✓\n✓\n✓\n✓\n✓\n[Kaseb and Farouk 2022]\n✓\n✓\n✓\n[Kåsen et al. 2022]\n✓\n✓\n✓\n[Liu et al. 2022]\n✓\n✓\n✓\n✓\n[Lu et al. 2022]\n✓\n✓\n✓\n✓\n✓\n[Okpala et al. 2022]\n✓\n✓\n✓\n[Olabisi et al. 2022]\n✓\n✓\n✓\n[Rajai and Ennasser 2022]\n✓\n✓\n✓\n✓\n[Saadany et al. 2022]\n✓\n✓\n✓\n✓\n[Artemova and Plank 2023]\n✓\n✓\n✓\n✓\n[Held et al. 2023]\n✓\n✓\n✓\n[Kantharuban et al. 2023]\n✓\n✓\n✓\n[Kuparinen et al. 2023]\n✓\n✓\n✓\n[Lameli and Schönberg 2023]\n✓\n✓\n✓\n[Le and Luu 2023]\n✓\n✓\n[Lent et al. 2024]\n✓\n✓\n✓\n✓\n✓\n✓\n[Maurya et al. 2023]\n✓\n✓\n✓\n[Plüss et al. 2023]\n✓\n✓\n✓\n✓\n[Ramponi and Casula 2023a]\n✓\n✓\n✓\n[Riley et al. 2023]\n✓\n✓\n✓\n✓\n✓\n✓\n[Zhan et al. 2023]\n✓\n✓\n✓\n✓\n✓\n[Zhan et al. 2024]\n✓\n✓\n✓\n✓\n✓\n[Artemova et al. 2024]\n✓\n✓\n✓\n✓\n✓\n[Ziems et al. 2023]\n✓\n✓\n✓\n[Ahia et al. 2024]\n✓\n✓\n✓\n✓\n✓\n[Talafha et al. 2024]\n✓\n✓\n✓\n✓\n✓\n[Dinh et al. 2024]\n✓\n✓\n✓\n✓\n[Vidal-Gorène et al. 2024]\n✓\n✓\n✓\n✓\n[Dabre et al. 2024]\n✓\n✓\n✓\n✓\nTable 2. State of NLP research on Dialects.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:9\nFig. 3. An Overview of Approaches in terms of NLP for Dialects.\n4.1\nDialectal Lexicons\nDialectal lexicons correspond to word lists or word mappings about a dialect. Although lexicons\nwere popular in early approaches of NLP, a recent paper by Artemova and Plank [2023] highlights\nthe potential of dialectal lexicons and describes an approach to create such lexicons using large\nlanguage models. Prior to this, research in the creation of dialectal lexicons lies in three categories:\nthe use of online dictionaries, and the use of textual corpora.\n4.1.1\nOnline dictionaries. Azouaou and Guellil [2017] create a lexicon of words mapping French\nand its Algerian dialect. They use online dictionaries along with a combination of manual and\nautomatic methods to enhance the lexicon. This includes many-to-one mapping of words in the\ntwo sets. Similarly, Boujelbane et al. [2013] build bilingual lexicons to create Tunisian dialectal\ncorpora to adapt n-gram models for statistical machine translation.\n4.1.2\nTextual corpora. Abdul-Mageed and Diab [2014] present a lexicon of words in dialects of\nArabic including Levantine and Egyptian dialects. They present two lexicons: adjectives in news\narticles and common words in online chat forums. The words are labeled with a combination of\nmanual and automatic techniques, the latter based on statistical techniques such as pointwise\nmutual information. Similarly, Burghardt et al. [2016] use the web as a corpus to create a lexicon\nfor the Bavarian dialect of German. Starting with a corpus of Facebook comments, they provide a\nrule-based algorithm to create the lexicon. They first extract unique text forms, and then filter non-\ndialect words based on the Dortmund chat corpus. Harrat et al. [2018]; Younes et al. [2020] discuss\nvarious existing resources for the Maghrebi Arabic dialects (MAD) including annotated corpora for\nlanguage identification, and morpho-syntactic analysis. MAD include principally Algerian Arabic,\nMoroccan Arabic and Tunisian Arabic.\n4.1.3\nLexicon Induction Using LLMs. A recent approach by Artemova and Plank [2023] performs\nGerman dialect lexicon induction using LLMs.\n4.2\nDialectal Datasets\nDatasets based on different data sources (such as social media, and conversation transcripts) and\ndialects have been reported. In terms of procuring and labeling these datasets, the following methods\nhave been used:\n4.2.1\nRecruit native speakers of specific language varieties. Estival et al. [2014] create a dataset of\naudio-visual recordings of 1000 speakers of Australian English. The dataset is accompanied by a\ntranscript, which was manually created for 100 speakers. Bouamor et al. [2018] present MADAR: a\nmanually curated parallel corpus of sentences in Arabic dialects along with English, French and\nModern Standard Arabic. 4 Similarly, Riley et al. [2023] create a parallel corpus of English sentences\nand two dialects each of Portuguese and Chinese with the help of native speakers of these dialects.\nEisenstein et al. [2023] introduce MD-3 a dataset of conversations between speakers playing the\n4 Obeid et al. [2019] is a demonstration based on the dataset.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:10\nJoshi, et al.\ngame of taboo. The dataset consists of speech recordings as well as text transcripts. Seddah et al.\n[2020] focus on treebank creation for Algerian supplemented with monolingual data obtained from\nCommonCrawl. They highlight the inherent difficulty of finding annotators and the cost of the\nsame indicating the challenges for dialectal data generation. Riabi et al. [2023] further extend this\nwith additonal layers of morpho-syntactic knowledge and correct errors in the same.\n4.2.2\nPerturbation. Ziems et al. [2022] evaluate natural language understanding for African-\nAmerican English. They design rules to perturb the dataset from Standard American English to\nAfrican-American English. They then get them validated by native speakers. Ziems et al. [2023]\npresent Multi-VALUE, a suite of resources to evaluate fairness of LLMs by creating dialectal\nvariations of a dataset. The suite provides mechanisms to generate 50 dialects of English by\napplying a set of perturbations. Messner and Lippincott [2024] present a dataset of 19th century\nAmerican literary orthovariant tokens with a novel layer of human-annotated dialect group tags,\nto examine language modelling assumptions, and find evidence that choice of tokenization scheme\nmeaningfully impact the type of orthographic information in a language model.\n4.2.3\nKeywords. Wang et al. [2017] create a dataset of Singaporean English sentences by searching\nfor typical Singaporean English terms in online forums. Ramponi and Casula [2023a] take a\ncomplementary approach to create a dataset of tweets in dialects of Italian along with other\nlanguages spoken in Italy (which are not necessarily derived from Italian). They use location-based\nsearch to obtain the set of tweets from different regions of interest from within Italy. Following this,\nthey use out-of-vocabulary words to identify words that are indicative of geographical regions and,\nas a result, dialects. A related dataset is GeoLingIt [Ramponi and Casula 2023b]. In the case of social\nmedia, hashtags can be used to obtain datasets in certain dialects. Kuparinen [2023] take advantage\nof dialect awareness week in Finland. They use a hashtag indicating usage of dialects in order to\ncollect tweets in different dialects of Finnish. In the context of Arabic dialect tweets, Boujou et al.\n[2021] benchmark is a novel dataset of 50,000 tweets for five dialects of Arabic-Algerian, Lebanon,\nMorocco, Tunisian, and Egyptian.\n4.2.4\nLocation. Data from particular geographics can be extracted using filters (where the location\nis known) or inference (where it is not known). Jurgens et al. [2017] use location-based filters\navailable on Twitter at the time. They use language identification classifiers to predict the language\nand identify dialectal users. Husain et al. [2022] obtain tweets from Kuwait to create a dataset\nof tweets in the Kuwaiti dialect of Arabic. Coats [2022] create an unlabeled dataset of Youtube\ncomments. They start with a list of councils in Australia, extract official Youtube channels and\nretrieve comments. They manually validate the correctness of the channels. When working with ge-\nographically dispersed dialects, sampling may also be used. Hovy and Purschke [2018] use Doc2Vec\non a large corpus of anonymous online posts to learn document representation of cities, and recover\ndialect areas using geographic information via retrofitting and agglomerative clustering. Dunn and\nAdams [2020] create a Web-based corpus in different dialects by sampling sentences from different\ncountries. The goal is to build a Web-based corpus where the number of instances is reflective of\nthe population of speakers in a country. The paper states that such a geography-aware corpus can\nlead to geography-aware representations when language models are trained on them. A criticism\nto the location-based filtering mechanism is by Goutte et al. [2016].\n4.2.5\nDialect-aware annotation. One such example is by Sap et al. [2019]. They examine racial bias\ntowards African-American English in the case of hate speech detection. They propose race and\ndialect priming in order to improve the quality of annotation. In order to prime the annotators,\nthey propose to ask two questions: (a) is the tweet offensive to them?, and (b) is the tweet offensive\nto anyone? The dialect and race of the speaker are shown to the annotators.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:11\nShared Task\nDialects/Languages\n[Zampieri et al. 2014]\nBrazilian Portuguese and European Portuguese; Amer-\nican and British English; and Argentinian Spanish and\nCastilian Spanish\n[Zampieri et al. 2015]\nAmerican and British English; and Argentinian Spanish\nand Castilian Spanish\n[Malmasi et al. 2016]\nDialects of English, Spanish, French and Arabic\n[Zampieri et al. 2019]\nDialects of German, Chinese, Romanian\n[Gaman et al. 2020]\nDialects of Romanian, Geolocation-based Varieties\n[Aepli et al. 2022]\nDialects of French and Italian\n[Aepli et al. 2023]\nDialects of Indo-European and Ural languages (and other\ntasks)\n[Abdul-Mageed et al. 2023]\nDialects of Arabic\nTable 3. Shared tasks related to dialect identification.\nSeveral datasets exist for varieties of Arabic [Diab et al. 2010], including Palestinian Arabic [Dibas\net al. 2022; Jarrar et al. 2017], Gulf Arabic [Khalifa et al. 2016], Egyptian Arabic [Maamouri et al.\n2014], and Bahraini Arabic [Abdulrahim et al. 2022]. This is in stark contrast with the lack of\navailability of datasets for dialects of English or several other languages of the world.\n5\nNATURAL LANGUAGE UNDERSTANDING (NLU)\nThis section covers NLU approaches centered around dialects. This includes approaches for NLP\ntasks such as dialect identification, sentiment analysis, morphosyntactic analysis and parsing. We\nalso describe approaches reported on NLU benchmarks, which cover multiple tasks.\n5.1\nDialect Identification\nThe most commonly researched task in the scope of this paper is dialect identification. Dialect\nidentification deals with the prediction of the dialect of an input text. Early approaches to dialect\nidentification employed distance-based metrics, namely, Levenshtein, Manhattan, and Euclidean\ndistance with different clustering techniques [Nerbonne and Heeringa 1997, 2002]. They indicate\nthat feature representations are more sensitive, and that Manhattan distance and Euclidean distance\nare good measures of phonetic overlap. Elnagar et al. [2021] is a systematic review of identification\nof dialects of Arabic. For dialects of Arabic, lexical resources such as lexicons and treebanks, and\nmodels using SVM or sequential neural layers like BiLSTM have been reported. Jauhiainen et al.\n[2019] is a survey of automatic language identification. They describe that dialect detection may be\nmore difficult than language detection since dialects may have lexical or syntactic overlap. In doing\nso, the survey does not make a distinction between languages and dialects - and treats different\ndialects as different class labels, while still maintaining a classification approach. However, one\nsees challenges in this regard. Boujou et al. [2021] present a baseline approach, which utilises\nclassical machine learning. While the majority of past work defines dialect identification as a\nBoolean/multi-class classification, Baimukan et al. [2022] use a hierarchy of dialect labels based on\ngeographical and linguistic proximity. We now describe details of past work in dialect identification\nin terms of shared tasks, datasets, and pre-deep learning and deep learning-based approaches.\n5.1.1\nShared tasks. Shared tasks have accelerated past work in dialect identification. These have\nbeen primarily led by Workshop on NLP for Similar Languages, Varieties and Dialects, also known\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:12\nJoshi, et al.\nas VarDial. The shared tasks are listed in Table 3. Goutte et al. [2016] summarise the findings\nfrom the past versions of the shared task from 2014-2016. Similarly, the Nuanced Arabic Dialect\nidentification (NADI) shared task is held annually. In the 2024 edition of NADI, a new task has\nbeen introduced to estimate the Arabic level of dialectness within Arabic sentences.\n5.1.2\nDatasets. Aji et al. [2022] report a dataset for several languages and dialects spoken in\nIndonesia. They observe that language identification works well for certain dialects (Ngoko-Central\ndialect of Javanese, for example). The paper also discusses code-mixing and orthography variations\nin these languages. Dunn [2019] reports dialect identification on 14 national varieties of English. He\nshows that cross-domain classification (CommonCrawl versus Twitter) also performs poorly. Cot-\nterell and Callison-Burch [2014] present a multi-dialect, multi-genre corpus of news comments and\ntweets written in dialects of Arabic. The tweets are manually annotated for dialect identification\non MTurk. Ramponi and Casula [2023a] present a benchmark dataset for dialects of Italian. The\nbenchmark is named as DIATOPIT. There has been recent work on creating a corpus of Norwegian\ndialect [Barnes et al. 2021]. Also, Alshutayri and Atwell [2018] present a large (200K+ instances)\ncorpus for Arabic dialects and Standard Arabic. The data is sourced largely from tweets but also\nincludes comments from newspapers, and Facebook. The data is also being annotated for dialect\nidentification and contains 24K annotated documents. Recently, Talafha et al. [2024] introduced\nCASABLANCA, a large scale community-driven effort to collect and transcribe a multi-dialectal\nArabic dataset, covering eight dialects for Arabic releasing 48 hours of manually transcribed speech\ndata including annotations for transcription, gender, dialect, and code-switching. Le and Luu [2023]\npresent a parallel corpus for dialects of Vietnamese. Further, Dinh et al. [2024] propose a dialect\nidentification, and speech recognition dataset, and fine-tuned models for for 63 provincial dialects\nof Vietnamese with 102.5 hours of audio, and 19000 spoken utterances.\n5.1.3\nFeature-based approaches. We now highlight features used for dialect identification.\n(1) Phonological features: Phonological features are based on markers in the written scripts. Dar-\nwish et al. [2014] use lexical along with a lexicon of dialectal Egyptian words, morphological\nand phonological features in a random forest classifier to detect dialects of Arabic spoken in\na geographical region.\n(2) Linguistic features: Doğruöz and Nakov [2014] present a method to predict dialects of\nTurkish by using light verb constructions. They use a statistical classifier based on verb-based\nfeatures (base word, verb order, affixes, etc.) for the task. Xie et al. [2024] discuss an approach\nto extract distinguishing lexical features of dialects by utilising interpretable dialect classifiers.\nWith focus on varieties of Mandarin, Italian, and Low Saxon, this approach shows promising\nresults on all varieties.\nThe combinations of the above set of features have also been reported. While Hanani and Naser\n[2020] work on the detection of dialects from speech, they also use word-level n-gram features.\nSalameh et al. [2018] perform fine-grained dialect identification for 25 dialects of Arabic, using\nNaïve Bayes classifier and word and character n-grams as features.\nWhile dialect detection of Arabic has been explored in detail, the pre-deep learning work in\nthe context of dialects of English is comparatively limited, although English is the predominant\nlanguage for NLP research. Lui and Cook [2013] is an early work in the detection of dialects of\nEnglish. Specifically, the paper focuses on Australian, British and Canadian English. Their baseline\nis the LangID classifier [Lui and Baldwin 2012] where dialects are treated as individual languages.\nThey experiment with classifiers using features such as n-grams and POS-n-grams. This includes a\ndistribution over function words and those in a vocabulary, akin to a clustering algorithm. Simaki\net al. [2017] use linguistic, POS-tag-based and lexicon-based features.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:13\n5.1.4\nDeep learning-based Approaches. Deep learning-based approaches for dialect classification\nspan three alternatives: train embeddings to reflect dialectal variations, use end-to-end LLMs, or\npredict dialect as a result of inference over dialect features.\nEmbeddings in focus: Abdul-Mageed et al. [2018] label tweets with 10 dialects of Arabic. The\ncity is considered the dialectal granularity. The analysis compares dialectal variants by looking at\nword embeddings of words across different dialects. They use word2vec representations to show\nhow dialectal words are captured. Goswami et al. [2020] build character-to-sentence embeddings to\nrepresent words of different dialects. Unsupervised loss is computed in order to generate clusters\nof representations. While they also test on language identification, the dialect identification part is\ndone on Swiss German dialect. Jurgens et al. [2017] use a character-based seq2seq model to map\ndialects. The models used for language identification are RNNs with GRU. Criscuolo and Aluisio\n[2017] use character n-grams to identify language groups. This is followed by convolutional neural\nnetwork-based dialect classifiers for each language group.\nFine-tuning LLMs: Ramponi and Casula [2023a] experiment with multiple models including\nstatistical and neural. The fine-tuned AlBERTo model performs the best among umBERTo, mBERT\nand XLM-R. Obeid et al. [2020] present CAMeL: a python toolkit for Arabic language processing.\nIt contains a dialect identifier that gives a distribution over multiple dialects. They use dialectal\nguidelines provided in Elfardy and Diab [2012].\nDetecting dialect features: ? introduce an approach for dialect classification using a novel multi-\ntask approach that employs dialect feature detection. They train two multi-task learning-based\napproaches using a small number of minimal pairs. They evaluate the output based on 22 dialectal\nfeatures based on Indian English and demonstrate that such models show the capability of learning\nto identify features with high accuracy. They show the efficacy of this task by applying it to dialect\nidentification, and by providing a measure of dialect density.\n5.2\nSentiment Analysis\nSentiment analysis is the NLU task of prediction of sentiment polarity of a text. Sentiment analysis\nencompasses several related tasks, such as sarcasm classification and target-specific sentiment\nanalysis. We discuss past work in sentiment analysis along four directions: experiences from\nannotation (which highlights the challenge of dialects for sentiment analysis), dialect-aware models,\ndialect-invariant models, and, finally, de-biasing of sentiment analysis models as a post-processing\nstep. Table 4 summarises approaches for sentiment analysis.\nEarly guessing for dialects: A recent advancement in dialect identification is early guessing [Kan-\njirangat et al. 2022]. The approach detects a dialect for an incremental input. Salloum and Habash\n[2022] also break the input down into its components. Specifically, they present an unsupervised\napproach that uses unsupervised dialect segmentation for machine translation.\n5.2.1\nDatasets & Annotation. Several datasets in Arabic sentiment analysis for dialects have been\nreported such as Moroccan [Oussous et al. 2020] and Levantine [Baly et al. 2019]. Dialects can\nhave an impact on annotation itself. Farha and Magdy [2022] show that dialect familiarity helps\nsarcasm annotation. Mdhaffar et al. [2017] create a dataset of 17000 Facebook comments labeled\nwith sentiment in Tunisian dialect of Arabic. Assiri et al. [2018] present a sentiment-labeled lexicon\nof words in the Saudi dialect of Arabic, and use simple counting-based sentiment analysis. Husain\net al. [2022] use weakly supervised labels for sentiment analysis of tweets in the Kuwaiti dialect of\nArabic. The labels are then manually validated and updated.\n5.2.2\nDialect-aware representations. Given the high degree of similarity between dialects, there\nis a high likelihood for models to make inferences in the same way for different dialects and\nthus explicitly modeling dialect awareness into models is important. However, this same degree of\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:14\nJoshi, et al.\nsimilarity makes this dialect aware modeling challenging. Farha and Magdy [2022] train BERT-based\nmodels for sarcasm detection on data annotated by either of the two groups: those familiar with\nthe dialect and those not. They show that familiarity of dialect improves the quality of the models\ntrained on such a dataset. As a result, representations that capture dialects have been used for\nsentiment analysis. Mdhaffar et al. [2017] present models based on SVM and multi-layer perceptron\n(MLP). Mulki et al. [2019] use a syntax-ignorant n-gram composition to create embeddings. The\nclassifier model is a dense neural network that works on the addition of word embeddings, with a\nsoftmax at the end. Guellil et al. [2021] propose ‘one’ model for sentiment classification in different\ndialects of Arabic. They use transliteration to map dialects to Standard Arabic. The sentiment\nanalysis model itself uses word2vec features with statistical classifier. Finally, Husain et al. [2022]\npresent statistical models based on SVM along with Transformers-based models like BERT.\n5.2.3\nIncorporating dialect information in sentiment prediction. El Mekki et al. [2021] use domain\nadaptation for sentiment analysis of dialects. Using representations from a BERT encoder, they use\ntwo classifiers: sentiment classifier and dialect classifier. The output of the two is later combined for\nthe overall prediction. While this is a two-channel approach, the representation used for the task\nhas also been used to predict dialect of the language. One such example is Okpala et al. [2022] who\npresent an approach for hate speech detection using African-American English. In order to do so,\nthey re-train BERT with AAE tweets. Finally, adversarial training is needed to regulate the debiasing\nof the hate speech classifier. Specifically, the adversary takes the final representation learned by\nthe hate-speech classifier, and learns to predict the dialect from it. Kaseb and Farouk [2022] present\na dialect-aware approach for sarcasm detection called the SAIDS model. SAIDS uses MARBERT\nto detect dialect and sarcasm. Following that, MARBERT, along with sarcasm and dialect output,\nare used to detect sentiment. Evaluated on Arabic dialects, SAIDS uses backpropagation only for\nprediction with respect to the BERT base model. It does not flow through sentiment<->sarcasm or\nsentiment<->dialect.\n5.2.4\nDe-biasing sentiment analysis models. Making sentiment analysis agnostic to dialects involves\nremoving dialectal biases in the resultant models. A work of this nature is by Ball-Burack et al. [2021]\nwho apply adversarial debiasing to resampled data for harmful tweet detection of tweets written in\nAfrican-American English. Resampling of the data uses a metric for margin of confidence which\nselects the set of tweets that are most likely to be mis-classified. Adversarial debiasing involves\ntraining an adversary network to debias the classifier by including the adversary network’s loss.\nSimilarly, Mozafari et al. [2020] report results on hate speech detection from African-American\nand Standard American tweets. They re-weight instances based on the presence of phrases that\nmay highlight racial bias. They fine-tune BERT for the task. Finally, Zhang et al. [2021] present an\napproach to reduce spurious correlation between two attributes: toxicity and African-American\nVernacular English. They construct triplets of sentences where the first two have the same toxicity\nlabel, and the first and the third have the same dialect label. The objective function of the model\nconsists of a triplet loss over these triplets, and a disentanglement loss that ensures the masks for\nthe true attributes are well-separated. Similarly, graphical models have been used to infer socio-\ncultural norms since they are closely associated with dialectal variations based on the language\nand cultural background of the speaker. Moghimifar et al. [2023] present a Markov model to\ndiscover socio-cultural norms in emotion classification. Harris et al. [2024] evaluate the zero-shot\nperformance of speech recognition systems across different genders and across four US-based\nEnglish dialects: SAE, AAVE, Chicano English, and Spanglish, release a labeled dataset of 13 hours\nof podcast audio, transcribed by speakers of the represented dialects.While past research has only\ndealt with African-American English, there may indeed be other dialects, which are considered\naggressive and may result in sentiment analyzers producing biased output. This is significantly\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:15\nPaper\nDialects\nModelling Approach\n[Mdhaffar et al. 2017]\nDialects of Arabic\nSVM/MLP\n[Mulki et al. 2019]\nDialects of Arabic\nSyntax-ignorant composition to learn\nword embeddings\n[Mozafari et al. 2020]\nAfrican-American\nEnglish\nRe-weight instances based on racially biased\nphrases for hate speech detection\n[El Mekki et al. 2021]\nDialects of Arabic\nInfer dialect and sentiment label\nusing two channels from BERT encoder\n[Guellil et al. 2021]\nDialects of Arabic\nTransliteration to map to standard version\n[Kaseb and Farouk\n2022]\nDialects of Arabic\nInfer dialect and sarcasm label; limited\nbackpropagation to maintain label dependency\n[Okpala et al. 2022]\nAfrican-American\nEnglish\nAdversarial training\nto debias dialectic variation\n[Moghimifar et al.\n2023]\nEnglish\nSocio-cultural norms are inferred\nusing a Markov model variation\nTable 4. Sentiment Analysis Approaches for Dialectal Datasets.\nPaper\nDialects\nHighlight\n[Habash and Rambow\n2006]\nDialects of Arabic\nRewrite rules to adapt morph analysers\n[Eskander et al. 2016]\nDialects of Arabic\nDataset proportions for improved perfor-\nmance\n[Jørgensen et al. 2015]\nAfrican-American\nEnglish\nPOS taggers perform worse for the dialect\n[Darwish et al. 2018]\nArabic\nCRF-based POS tagger; Linguistic features\n[Inoue et al. 2022]\nArabic\nFine-tuned LLMs\n[Bafna et al. 2023]\nIndic Languages\nFine-tuned LLMs\nTable 5. Approaches for Morphological Analysis Focusing on Dialects. Highlight-> Approach or Key Finding.\nunderexplored for dialects of other languages such as the Khariboli (Haryanvi group) dialect of\nHindi [Yadav 1974].\n5.3\nMorphosyntactic analysis\nMorphosyntactic analysis deals with linguistic tasks such as POS tagging and morphological\nanalysis, and has been found to be useful for sense disambiguation, particularly in low-resource\nsettings [Khalifa et al. 2020]. We now describe past work that deals with dialectal variations, as\nsummarised in Table 5.\n5.3.1\nClassical approaches. Habash and Rambow [2006] is a seminal morphological analyser\nfor dialects of Arabic called MAGEAD. Using morphological rewrite rules, they show how a\nmorphological analyser can be adapted for dialects of a language. Jørgensen et al. [2015] evaluate\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:16\nJoshi, et al.\non a dataset of African-American Vernacular English and show that the then-prevalent POS taggers\nperform significantly worse. Darwish et al. [2018] present a CRF-based POS tagger for dialects of\nArabic. The POS tagger is trained on a small set of tweets using features derived from the dialects of\ninterest. These features are progressive and negation particles. Eskander et al. [2016] adapt existing\nmorphological analyzers to unseen dialects of Arabic by simulating the low-resource dialects.\n5.3.2\nDeep learning-based approaches. Inoue et al. [2022] use CamelBERT trained on Modern\nStandard Arabic fine-tuned on dialect-specific datasets for morphosyntactic analysis. They observe\nthat training using high-resource dialects helps low-resource dialects as well. In the context of\nIndic languages, Bafna et al. [2023] explore POS tagging for 5 Indic dialects by focusing on Hindi-\naware LLM adaptation via small dialectal monolingual corpora. Aepli and Sennrich [2022] propose\nimproving cross-lingual transfer between closely related language varieties from the Finnic, West\nand North Germanic, and Western Romance language branches using character-level noise injection,\nand go on to show consistent improvements for POS tagging. Their approach is further applied\nto seven languages from three families and a total of eighteen dialects [Blaschke et al. 2023] with\nresults showing improvements by varying the level of noise injected during the cross-lingual\ntransfer.\n5.4\nParsing\nParsing involves the creation of syntactic parse trees from text. Past work in parsing texts written\nin dialects of a language lies in three categories. The first category uses an existing parser on a\ndataset in a dialect of interest. The focus of such work is to create a baseline performance of popular\nparsers. The second category provides approaches to adapt existing parsers towards texts in the\ndialect of a language. The third category creates a new parser for the dialect.\n5.4.1\nUse of existing parsers. Eggleston and O’Connor [2022] parse tweets in Standard American\nEnglish and African-American English and use it to analyse social attributes of an entity, as per\nsentiment expressed in the tweets. Kåsen et al. [2022] create a tree bank of sentences in the Bokmål\nvariety of Norwegian dialects. They present their results on the UUParser, an existing parser for\nNorwegian. Roy et al. [2020] present an analysis using Stanford parser and Allen NLP parser on\nparsing of news headlines in Indian English. Scannell [2020] create a treebank for Manx Gaelic and\ncompare the performance of existing classifiers with Irish Gaelic and Scottish Gaelic.\n5.4.2\nAdaptation of an existing parser. Chiang et al. [2006] show how parsing of Arabic dialects\ncan be done by a sentence transduction approach. This approach parses the standardised version\nof a dialectal sentence, and then links it to the original sentence. The standardisation is achieved\nusing transduction, akin to n-gram decoding. However, Blodgett et al. [2018] use neural networks\nand present an approach to dependency parsing for African-American English. This approach uses\ntwo neural parsers, which are modified with the word embeddings used for initialisation. The word\nembeddings are trained on the standard and the dialect-specific datasets. Further, Wang et al. [2017]\ncreate a dependency parser for Singaporean English. This approach uses a base parser for standard\nEnglish and stacks it with a series of BiLSTM layers known as the ‘feature stack’ to extract relevant\nfeatures, and an MLP with an output layer to help produce dependency-parsed output. Zhao\net al. [2020] use a treebank of learner English sentences labeled with POS tags and dependency\ninformation. They propose a factorisation-based parser that first predicts nodes followed by edges\nin a dependency parse. Dou et al. [2023] evaluates various parsers designed for converting text to\nSQL, focusing on a multilingual benchmark that covers dialects from seven different languages.\nThis research is significant for its emphasis on semantic parsing, differing from the aforementioned\ndependency parsing works.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:17\nPaper\nDialects\nApproach\n[Ziems et al. 2022]\nAfrican-American English\nPerturbation to create variants\n[Dacon et al. 2022]\nAfrican-American English\nAdversarial learning\n[Held et al. 2023]\nDialects of English\nContrastive loss, Morphosyntactic loss\n[Xiao et al. 2023]\nDialects of English\nHypernetworks as LoRA adapters\nTable 6. Dialect-aware approaches evaluated on NLU benchmarks.\n5.4.3\nDevelopment of a new parser. : Vaillant [2008] propose a rule-based approach to construct\na common syntactic description for a group of Creoles from Haiti, Guadeloupe, Martinique and\nFrench Guiana. Bowers et al. [2017] present a finite-state machine-based parser for the endangered\nOdawa dialect of Ojibwe spoken in Canada and northeastern United States. This approach uses\na phonological module composed of a morphological module where morphological strings are\nmodified by the phonology until they match surface forms of the language.\n5.5\nNLU Benchmarks\nFinally, benchmarks such as GLUE, which provide datasets for NLP tasks like semantic textual\nsimilarity prediction (STS-B), sentiment classification (using the Stanford sentiment treebank\n(SST-2)), natural language inference (NLI), textual entailment and so on, are an important part of\nlanguage model evaluation pipeline. Ziems et al. [2022] show a drop in performance on 7 GLUE\ntasks including SST-2, STS-B, when tested on dialectal English variations of the original Standard\nAmerican English version. For example, for SST-2, there is a 1.5-2% drop using fine-tuned RoBERTa.\nDacon et al. [2022] work with African-American English. They first propose CodeSwitch, a rule-\nbased method of perturbing a sentence from Standard American English (SAE) to African-American\nEnglish (AAE). They create perturbed versions of the dataset using CodeSwitch and manually\nevaluate it. They finally evaluate their method on NLI. In order to do so, they use adversarial\nlearning that ensures that the predicted label is the same if either the SAE or AAE sentences are\nprovided as the input. They refer to this as a disentanglement of language style. Tan et al. [2020]\npresent base-inflection encoding: a mechanism to inject dialectal information into the encoder. They\nshow that their encoding algorithm improves the performance of Vernacular African-American\nEnglish for SQUAD and MNLI tasks.\nHeld et al. [2023] model natural language understanding for dialects as a dialect adaptation task.\nUsing Multi-VALUE, they create African-American English variations of the GLUE benchmark\n(which is primarily written in Standard American English). Following that, they adapt a model\npre-trained on Standard American English. To do so, they use: (a) a contrastive loss to ensure\nthe representation of a standard sentence and its dialectal version is as close as possible; (b) a\nmorphosyntactic loss based on word-level alignment between the standard and dialectal sentences.\nTheir results show improved robustness on 4 dialects based on the GLUE benchmark. Vidal-Gorène\net al. [2024] provide a benchmark on lemmatization, POS-tagging, and morphological analysis for\nfour Armenian varieties- Classical, Modern Eastern, Modern Western, and the under-documented\nGetashen dialect. They compare traditional RNN models, multilingual encoders, and large language\nmodels using supervised, transfer learning, and zero/few-shot learning approaches, and show how\nRNNs are strong at POS tagging, but LLMs handle unseen dialectal variations.\nA recent work by Xiao et al. [2023] shows how low-rank adapters Low-Rank Adapters (LoRA) (a\nparameter-efficient fine-tuning or PEFT technique that allows fine-tuning LLMs faster by storing\nweight updates instead of updating all weights) can use linguistic knowledge of dialects to improve\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:18\nJoshi, et al.\nzero-shot performance on NLU tasks. They integrate hypernetworks with LoRA adapters for dialect\nadaptation. Experts encode linguistic information in the form of feature vectors. A hypernetwork\nthen learns to generate adapter weights for LoRA from the feature vectors. They demonstrate the\nimpact of their fine-tuning approach on several GLUE tasks such as MNLI, RTE and so on. The\ndataset consists of variants of the GLUE benchmark for five dialects: African American Vernacular\nEnglish (AAVE), Indian English (IndE), Nigerian English (NgE), Colloquial Singaporean English\n(CollSgE), and Chicano English (ChcE). Similarly, Liu et al. [2023] use dynamic aggregation of\nlinguistic rules to adapt LLMs to multiple dialects. They first create a synthetic dataset of linguistic\ntransformations using LLM probing. Following that, they train a set of feature adapters to generalise\nacross multiple dialects of interest. They present their evaluation of multiple dialects of English.\nDIALECTBENCH [Faisal et al. 2024] is a large-scale benchmark covering 10 NLP tasks focusing on\n281 language varieties. Their evaluation shows substantial disparities in performance between the\nstandard and non-standard language varieties, while also identifying language clusters with large\nperformance divergence across tasks. Most recently, the VarDial 2024 evaluation campaign [Chifu\net al. 2024] released dataset on the choice of plausible alternatives (COPA) task focusing on three\nmicro-dialects namely, Cerkno dialect of Slovenian, Chakavian dialect of Croatian, and the Torlak\ndialect which is spoken across Serbia, Macedonia, and Bulgaria. This task requires a computational\nmodel to select one of two candidate statements which is more likely to be the cause or effect of a\ngiven premise statement. Collectively, training and test datasets from VarDial evaluation campaigns\n(2014 - 2024) organised over the years should act as a good benchmark for LLM evaluation of\ndialects.\n5.6\nOthers\nErdmann et al. [2018] investigate how word embeddings trained on dialect-specific or mixed-dialect\ncorpora perform. In their experiments for text in dialects of Arabic, they show how dialect-specific\nembeddings can be helpful for dictionary induction. Dictionary induction here refers to alignment\ntables between dialects of a language. Demszky et al. [2021] report models that predict dialect\nfeatures using minimal pairs that represent linguistic properties of dialects. They do so for Indian\nEnglish.\n6\nNATURAL LANGUAGE GENERATION (NLG)\nThe previous section showed that NLU for dialects has primarily focused on tasks like identification\nof dialects and sentiment analysis. We now present approaches in NLG. NLG deals with sequence-to-\nsequence (seq2seq) tasks in NLP, which take a sequence as input and produce a sequence. Challenges\nin the presence of dialects in a generation task can differ significantly given the task. The data and\nevaluation methods can be different for tasks, especially where dialectal text is being generated.\nSome examples of such problems are summarisation, question answering and machine translation,\nand are described in Table 7. While the situation in the case of NLU was already dire, our survey\nindicates that for NLG, it is even worse. We will now discuss NLP approaches that deal with dialects\nof a language in the context of seq2seq problems.\nTwo works reflect advances in the context of seq2seq problems:\n(1) Making evaluation metrics dialect-aware: Sun et al. [2023] state that metrics used to\nmeasure text generation may penalise outputs in certain dialects. They propose a metric\nnamed NANO, which allows perturbations in the generated output. They show that models\npretrained with NANO as the metric can be helpful for dialect-robustness.\n(2) Creating dialectal variants of datasets for benchmarking: Ziems et al. [2023] present\nMulti-VALUE, a library that creates dialectal variations of datasets based on a set of manually\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:19\nPaper\nDialect\nApproach\nSummarisation\n[Olabisi et al. 2022]\nAfrican-American /\nHispanic English\nRepresentations-based clustering &\nobtain summaries separately.\n[Keswani and Celis 2021]\nEnglish Dialects\nDiversity-representative sentences &\nweigh them for summary generation\nMachine translation\n[Alam et al. 2024]\n891 variations\nContrastive dialect benchmark for MT eval-\nuation\n[Riley et al. 2023]\nPortuguese and Chi-\nnese Dialects & Eng-\nlish\nFew-shot approach for MT\nDialogue systems\n[Zhan et al. 2023]\nDialectal norms in\nChinese culture\nBenchmark dataset\n[Artemova et al. 2024]\nGerman dialects\nPerturbation-based evaluation for dialects\nText generation\n[Sun et al. 2023]\nEnglish Dialects\nTowards dialect-robust metrics for text gen-\neration\nTable 7. Representative Examples for sequence-to-sequence NLP tasks.\ncreated rules. They create variants of benchmark datasets, and evaluate the variants for\nseveral seq2seq tasks including machine translation, question answering and so on. The\nmodels for evaluation are based on modern LLMs such as BERT, ROBERTA, BART and T5.\nThe library provides a useful resource as well as insights for dialect-aware benchmarking in\nthe future.\n6.1\nSummarisation\nPast work in summarisation, although limited, states that dialect labels may not be explicitly\nnecessary. However, a review of Arabic text summarisation by Elsaid et al. [2022] state the use\nof “dialect period frameworks” to incorporate semantic information about dialects. In the case of\nmulti-document summarisation, clustering of sentences in the input set is a predominant paradigm.\nTwo such works are noteworthy:\n(1) Olabisi et al. [2022] analyse the diversity of dialects in multi-document summarisation\nof social media posts. They present a dataset that contains summaries of a collection of\ntweets written in three dialects: African-American English, Hispanic English, and White\nEnglish. They use extractive summarisation using LONGFORMER-EXT and abstractive\nsummarisation using BART and T5. In order to bring diversity-awareness in summarisation,\nthey create automatic clusters of input documents based on semantic attributes. They follow\na 2-stage approach where the summarisers are separately applied, and the resultant outputs\nare combined again using a summariser.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:20\nJoshi, et al.\n(2) Keswani and Celis [2021] examine the role of dialect diversity on multi-tweet summarisation.\nThey use a variety of summarisers: typical traditional summarisers like TF-IDF, TextRank and\nLexRank, and SummaRunner (a neural summariser that treats summarisation as a sequence\nclassifiation task). They create a control set: a subset of sentences that represent different\ndialects in the set of sentences. They introduce a bias mitigation procedure that introduces\ndialect-awareness in summaries using a parameter that is weighted to increase the score of\ndialect-diverse sentences in the dialect set.\n6.2\nMachine Translation\nCompared to summarisation, machine translation has been studied a bit more. Recent work is\nbroadly divided into two categories: (i) translation between dialects of the same language, and (ii)\ntranslation between the dialect of a language and another language. In the rest of this section, we\ncover the approaches in these categories.\n6.2.1\nMT between dialects of the same language. The primary goal of inter-dialect translation is the\ndissemination of information available between a standard dialect and a non-standard one. In this\ncontext, the following works are relevant. Mapping from less used dialects to their most common\nversions is called dialect normalisation. One such work by Kuparinen et al. [2023] provides a\ndialect normalisation dataset in Swiss German, Slovene, Finnish, and Norwegian. Bouamor et al.\n[2014] present a multi-dialectal dataset for various dialects of Arabic.\nHarnessing pre-trained models: Le and Luu [2023] show that models based on 𝐵𝐴𝑅𝑇𝑝ℎ𝑜perform\nwell for dialect normalisation in dialects of Vietnamese. This indicates that denoising-based pre-\ntrained models can be a good source for dialect data generation owing to their infilling capabilities.\nCharacter level modeling: Abe et al. [2018] conduct Japanese dialect translation where they use\nNMT to translate from dialect to standard Japanese using character RNN trained on small datasets\ncollected as a part of their work. Honnet et al. [2018] additionally suggest that normalisation\nis an important aspect for translating between Swiss German dialects, which is achievable via\ncharacter-level models. Kuparinen et al. [2023] further show that sliding-window-based approaches\nare useful since dialect translation does not need the entire sentence-level context.\nPerturbation-based regularisation: Liu et al. [2022] present a seq2seq approach for machine\ntranslation of Singaporean English to standard English. They use word perturbation and sentence\nperturbation to prevent overfitting of lexical features. Maurya et al. [2023] used a similar approach\nfor Indian dialects.\nHarnessing Linguistic Features: Erdmann et al. [2017] focus on translation among Arabic\ndialects in a low-resource setting where they supplement small parallel corpora with morpho-\nsyntactic information injected into the model for machine translation. In general, incorporating\nlinguistic features into the MT framework is known to significantly boost translation quality in low-\nresource settings [Chakrabarty et al. [n. d.], 2020]. Especially, pre-training by leveraging linguistic\nfeatures, as done by Chakrabarty et al. [[n. d.]], should be beneficial for dialectal translation, which\nis typically a low-resource problem.\nCode-mixed training: Lu et al. [2022] use XLM for Translation between Hokkien-Mandarin\ncode-mixed text. They observe that continuous training with code-mixed data enables monolingual\nlanguage models to provide better performance when applied to code-mixed tasks.\nData Creation for MT between dialects: Zbib et al. [2012] and Meftouh et al. [2015] also focus\non multi-dialect MT data collection for Arabic, which is, once again, to be noted as one of the\nmost studied languages for dialects. Xu et al. [2015] use a Hidden Markov-based model to create\nword alignment between dialects of Chinese: Mainland Chinese, Hong Kong Chinese, and Taiwan\nChinese. The outcome is a monolingual corpus that contains corresponding words used in the\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:21\nthree dialects. Their approach was shown to be effective for three different alignment mapping\ncases. Rather than use word alignment, Hassani [2017] works on Kurdish dialectal MT using\ndictionaries and show that having limited to no parallel corpora is not a significant barrier for\ninter-dialect translation. YORULECT [Ahia et al. 2024] releases parallel text and speech corpus\nfor four regional variants of Yorùbá, by collecting data from within native communities for each\nvariant, and providing a benchmark for machine translation, speech recognition, and text-to-speech\nsynthesis. Most recently, Dabre et al. [2024] worked on Kadodi, a dialect of Marathi, for which\nthe local community was involved for parallel corpora creation, further highlighting the need for\ncommunity involvement.\nAll these works emphasize that a small amount of parallel data between dialects is always\nimportant; however, data synthesis and transfer learning from a high-resource dialect is always\nimpactful, especially in conjunction with character and word level perturbation methods.\n6.2.2\nMT between dialects and another language. The second category, involving the harder chal-\nlenge of machine translation between a dialect and another language, has received far more\nattention. We cover notable works below.\nDialect pivoting: An early work in this regard is by Paul et al. [2011]. They present a pivot-based\nMT approach for the translation of four dialects of Japanese, namely Kumamoto, Kyoto, Okinawa,\nand Osaka. In order to map sentences across dialects, they use a character-based generative graphical\nmodel. They then translate the dialects into four Indo-European languages, using standardised\nJapanese as the pivot language. Jeblee et al. [2014] focus on using modern standard Arabic as a\npivot when translating from English to the Egyptian Arabic dialect.\nUnsupervised segmentation: Different from Abe et al. [2011] who focus on characters, Al-Mannai\net al. [2014]; Salloum and Habash [2022] work on Arabic dialectal translation, which shows that\nunsupervised word segmentation is just as effective if not better for translation into English.\nEvaluating existing translators on dialectal datasets: Kantharuban et al. [2023] show the\nperformance of MT between English and dialects of seven languages. Using state-of-the-art MT\nsystems such as Google NMT and Meta NLLB, they evaluate MT in both directions (to and from\nEnglish). They report a drastic drop in BLEU for dialects of German, Portuguese and Bengali.\nDe Camillis et al. [2023] train NMT systems to evaluate the performance of legal domain translation\nfor Italian ⇔South Tyrolean German, where their models show better performance compared\nto Google Translate and DeepL for this niche use case. Similarly, CODET [Alam et al. 2024] is a\ncontrastive dialectal benchmark dataset for evaluating machine translation systems focusing on\n891 variations from 12 languages.\nUsing inferred dialectal labels to guide translation: Sun et al. [2023] add language-dialect\ninformation as predicted by a language identifier as an input when training an MT system. They\nfurther improve the metrics for robust evaluation of text generation systems for different languages\nand dialects. They report their results on several dialects of English, Chinese, Portuguese and so\non. They use few-shot prompting to create semantic perturbations to train T5. The results show\nthat dialect-awareness improves the performance of translation. Shapiro and Duh [2019] explore a\nmultidialect system and identify when dialectal identification is useful. Tahssin et al. [2020] focus\non dialect identification itself using AraBERT models. Salloum et al. [2014] focus on sentence-level\ndialect identification for an SMT model selection where the model is optimised for that dialect.\nLearning through exemplars: Few-shot learning involves the use of examples in a prompt to\nguide the generation through a language model. Riley et al. [2023] present a few-shot machine\ntranslation approach for translation between English and two variants of Portuguese and Chinese.\nThe parallel corpus is manually created by native speakers. The exemplars from the specific dialect\nare used to obtain translations of English sentences.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:22\nJoshi, et al.\nUser-generated content: User-generated content (UGC) is often mistranslated on social media,\nespecially, for low-resource languages like dialectal Arabic. Saadany et al. [2022] train a Transformer\nto translate from dialectal Arabic to English where they focus on challenges in translation of UGC,\nand propose a sentiment-aware evaluation metric for translation. They discuss results on multiple\ntest sets, including a hand-crafted test set, and analyse the performance for a semi-supervised\napproach compared to a baseline NMT system, a pivoting-based system, and Google Translate.\nUse of multiple translation models: Translation models that translate between the standard\nversion and a dialect can assist machine translation. Kumar et al. [2021] show an approach for\nMT from English to Ukrainian, Belarusian, Nynorsk, and Arabic dialects. They use two models: a\ndialect-to-standard translation model, and a standard source-to-target language translation model.\nData creation for MT of dialect to another language: Hassan et al. [2017] explore synthetic data\ncreation using word pairs between dialects based on embeddings. They take seed data, transform\nit into its dialectal variant and now have a dialectal parallel corpus. Similarly, Almansor and\nAl-Ani [2017] focus on using monolingual data and tiny parallel corpora in conjunction with\ncross-dialectal embeddings to improve MT between dialects. Sajjad et al. [2020] take dialect MT\nevaluation further and focus on multi-domain coarse-grained analysis of dialects of Arabic via\ntheir AraBench benchmark. Hamed et al. [2022] propose an Arabic-English code-switched speech\ntranslation dataset, which represents a practical use case since a vast majority of dialects are often\nspoken. There is a significant dearth of code-mixed datasets and recommend researchers to focus\non the same. Alkheder et al. [2023], recognising the increasing usage of Arabic in several regions\nof Turkey, expand the MADAR corpus [Obeid et al. 2018] to enable benchmarking of translation\nbetween Arabic and Turkish. Contarino [2021] curates LEXB, a parallel corpus between South\nTyrolean German and Italian containing nearly 175, 000 parallel segments from the legal domain.\nTo curate parallel data, they use the LexBrowser database5 and 20 national laws and codes (Civil\nCode, Criminal Code) translated into German. Igarashi and Miyagawa [2024] curate parallel corpus\nfor Ainu⇐⇒Japanese where text for Ainu was curated from after post-processing OCR ouput for\nbooks, and other online resources. Ainu is a critically endangered family of dialects from from\nNorthern Japan without any native writing script.\n6.2.3\nDialect MT in Shared Tasks. Given that most dialects are spoken and not written, the IWSLT\nworkshop, which focuses on spoken language translation, has been conducting shared tasks on\ndialects under the banner of low-resource MT. The 20226 and 20237 workshops featured dialectal\nspeech translation, with resources for text-text as well as speech-text translation. The focus, as\nis typically the case, is on dialects of Arabic like Tunisian, Egyptian and Moroccan. The shared\ntasks are an excellent source of datasets and benchmarks for dialectal MT. Most recently, the\nArabicNLP 20238 conference offered a shared task9 on translation from 4 Arabic dialect to modern\nstandard Arabic. Over the years, NADI has reported progress on country and province-level dialect\nidentification, dialectal sentiment analysis, and dialect to MSA machine translation [Abdul-Mageed\net al. 2023, 2020, 2021, 2022]. We should also note that the Workshop on Machine Translation\n(WMT10) and the Workshop on Asian Translation (WAT11) often feature shared tasks on closely\nrelated languages. The 202412 edition of IWSLT is expected to focus on North Levantine Arabic.\n5http://lexbrowser.provinz.bz.it/; Accessed on 20th November, 2024.\n6https://iwslt.org/2022/dialect; Accessed on 9th January, 2024.\n7https://iwslt.org/2023/low-resource; Accessed on 9th January, 2024.\n8https://arabicnlp2023.sigarab.org/; Accessed on 20th November, 2024.\n9https://nadi.dlnlp.ai/; Accessed on 20th November, 2024.\n10https://www2.statmt.org/wmt24; Accessed on 20th November, 2024.\n11https://lotus.kuee.kyoto-u.ac.jp/WAT/WAT2024/index.html\n12https://iwslt.org/2024/low-resource; Accessed on 9th January, 2024.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:23\n6.3\nDialogue Systems\nDialogue systems, crucial in facilitating human-computer interaction, are categorised into task-\noriented, chit-chat, and hybrid systems. These systems, especially when dialect-aware, face the\nadded challenge of understanding and adapting to linguistic variations.\nTask-oriented dialogue system: Task-oriented systems are designed to accomplish specific tasks.\nThey integrate NLU, a dialogue manager, and NLG components. The effectiveness of these systems\nin handling dialects is pivotal. For instance, Elmadany et al. [2018a]; Joukhadar et al. [2019] study\nthe classification of dialogue acts in Arabic dialect utterances, demonstrating the system’s capacity\nto adapt to dialectal variations. Al-Ghadhban and Al-Twairesh [2020] use the Artificial Intelligence\nMarkup Language (AIML) to build a chatbot that assists students with academic enquiries in\nthe Saudi Arabian dialect. The VarDial 2023 campaign [Aepli et al. 2023] reports progress on\nslot and intent detection for low-resource language varieties such as Swiss German, Neapolitan,\nSouth Tyrolean. Artemova et al. [2024] investigate the robustness of task-oriented dialogue systems,\nspecifically their intent classification and slot detection components, to German dialects by applying\nperturbations that transform standard German sentences into colloquial variants.\nChit-chat dialogue system: Chit-chat dialogue systems, also known as open-domain systems,\nprimarily focus on daily chat and handle broader interactions. Ali and Habash [2016] employ AIML\nand rule-based systems to manage dialectal variation in Egyptian Arabic, incorporating features\nlike short vowels and consonantal doubling. Ahmed and Hussein [2020] also use AIML for Kurdish\ndialogues. Additionally, Alshareef and Siddiqui [2020] train a Seq2Seq model on a tweet corpus to\nrespond to open-domain Arabic questions.\nA specialised subset of chit-chat systems are socially-aware dialogue systems, which pay close\nattention to the influence of social norms and factors. These systems are designed to adhere to\nthe cultural and social norms prevalent in different societies [Hovy and Yang 2021]. In different\ncultures, social norms will no doubt incorporate sociolect, including whatever discourse force it\nmay carry. Ziems et al. [2023] propose a framework to evaluate dialect differences in cross-dialectal\nEnglish. In addition, Zhan et al. [2024, 2023] propose the socially-aware dialogue corpus based\non Chinese culture and relevant dialectal norms. Sociolect in a dialogue will dramatically affect\nhuman’s understanding and behaviours towards speakers. Rajai and Ennasser [2022] summarise\nexisting problems and strategies towards dealing with sociolect in dialogues.\nHybrid system: Hybrid systems combine features of both task-oriented and open-domain systems.\nAn example is the system developed by Ben Elhaj Mabrouk et al. [2021], which answers user queries\nin various Arabic dialects like Tunisian, Igbo, Yoruba, and Hausa. This chatbot addresses both\nofficial FAQs, especially related to COVID-19, and informal chit-chat, responding to questions in\nthe local dialect.\nAwareness of social and societal norms of behaviour is particularly important in dialogue\nsystems that serve specific transactional goals, be it to book a doctor’s appointment, to ask ques-\ntions about income tax or to make a customer service complaint. Research in interactional socio-\nlinguistics [Gumperz 1982] has, in a rich body of research in different social contexts such as\nemployment interviews [Roberts 2021], shown that people interpret communicative intent against\ntheir own background expectations of what is ‘normal’ or ‘expected behaviour’. This has the\npotential to exacerbate inequality (for example, by restricting access to employment), in particular,\nfor underrepresented groups such as migrants.\nIn the case of dialogue systems, a lack of representation of different dialects (e.g., due to the lack\nof diverse training data) has the potential to cause similar effects: If dialogue systems are not aware\nof social norms inherent to different dialects, and if what is communicated does not match users’\nexpectations, communicative intent can be misinterpreted, and underrepresented user groups might\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:24\nJoshi, et al.\nbecome disengaged from the system. The xSID dataset [Van Der Goot et al. 2021] is a multilingual\ndataset for spoken language understanding, and includes a low-resource Austro-Bavarian German\ndialect and other dialects. Indeed, previous research on dialogue systems has confirmed the impor-\ntance of alignment of system-style choices with user needs and preferences [Chaves et al. 2022;\nFølstad and Brandtzaeg 2020; Li and Mao 2015].\n7\nCONCLUSION & FUTURE DIRECTIONS\nDialects are syntactic and lexical variations of a language, often associated with socially or geograph-\nically cohesive groups. This paper summarises NLP approaches for dialects of several languages.\nThe need for NLP approaches focusing on dialects of a language rest on four motivations: dialects\npose linguistic challenges, benchmarks may not have sufficient dialectal representation, dialect-\nawareness is important for fair NLP technology, and there has been growing recent work in this\ndirection. The survey identified trends in terms of tasks (which shows shifting focus from dialect\nclassification), languages (with more work in Arabic as compared to other languages), and a shifting\ntrend towards mitigation (by either making models dialect-invariant or dialect-aware). Follow-\ning that, we described different methods to create dialectal lexicons and datasets, ranging from\nlocation/keyword-based filtering (of which location-based filtering has been found to be ineffective\nby Goutte et al. [2016]) to manual (via recruitment of native speakers) and automatic (via automatic\nperturbation). We then viewed past work in the context of NLU and NLG. For NLU, we covered\ndialect identification, sentiment analysis, morphosyntactic analysis, parsing and more recent work\nin NLU benchmarks. We described how the availability of datasets in multiple languages has\nfuelled research in dialect identification, which continues to date. Sentiment analysis techniques\nfor dialects included peculiar de-biasing approaches, in addition to dialect invariance and dialect\nawareness. Approaches to parse dialectal datasets used or adapted existing parsers or developed\ndialect-specific parsers. Finally, we described how recent work on NLU benchmarks highlight\nhow adversarial learning and LoRA can be used to reduce the degradation in the performance\nof dialectal datasets as compared to the standard ones. In the case of NLG, we described work in\nsummarisation, machine translation and dialogue systems. We described the limited, recent work\nin multi-document summarisation of dialectal documents. Following that, we discussed approaches\nfor machine translation in the context of dialect normalisation and dialect pivoting depending on\nwhether the translation is between dialects of a language or between dialects and another language.\nFinally, we described dialogue systems in the context of task-oriented, chit-chat and hybrid systems.\nBased on our survey, we now identify future directions and social/ethical implications. We\nhope that the former will be helpful for NLP research for dialects, while the latter will get more\nresearchers interested in this richly investigated yet emergent area of NLP. We believe that NLP\nresearchers should adopt a socio-technical perspective [Johnson and Verdicchio 2017] on their role\nand consider not only their own possible biases influencing the selection of training data, the design\nof algorithms etc. but also other social arrangements (e.g., users and their behaviours) relevant to\nspecific systems. In their survey of speakers of German dialects, Blaschke et al. [2024] also discuss\nin detail their needs as users of language technologies.\n7.1\nImplications to NLP research\nIn addition to the trends reported earlier in the paper, the following would be potential future\ndirections in the context of NLP.\n7.1.1\nFocusing on unexplored dialects of languages. : NLP for dialects face problems akin to low-\nresource languages, in terms of the availability of existing resources and tools. While some dialect\nfamilies, such as English and Arabic, have seen consistent efforts, dialects for other languages need\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:25\nmore focused large-scale efforts for data curation and annotation. While English is arguably the\nleading language for advances in NLP, efforts remain to be done to fully represent the full diversity\nof the English language itself through appropriate datasets and models that are curated for specific\ndialectal tasks. It is not always necessary to create new datasets, given that datasets specific to\nparticular dialects are available. However, caution is advised for dialogue systems as many existing\ncorpora – with the exception of those focusing on English as a lingua franca (ELF) – are dominated\nby written texts, which may not represent the richness of dialectal variations of spoken language.\n7.1.2\nRethinking the pre-training of LLMs. : Chow and Bond [2022] present a computational\ngrammar for Singaporean English. Such dialectal representations can be useful to generalise the\nability of LLMs. It would be beneficial for LLMs to be able to ingest other kinds of information\nsuch as dialect-specific grammatical structures. Ability to pre-train LLMs using data in different\nformats (not just modality, which is currently a popular paradigm) may improve their performance\nfor diverse datasets such as dialects. Similar impact of pre-training language data distribution is\nknown for cross-lingual meaning transfer within NLP tasks [Qian et al. 2024; Zerva et al. 2024]\ninvolving low-resource languages [Nigatu et al. 2024].\n7.1.3\nDialect identification as an auxiliary task. : Multi-task learning is used to train models for\nmultiple tasks. Dialect identification could be used as one of the tasks in order to train equitable\nmodels. Lent et al. [2024] present a multi-task, multi-lingual dataset of Creole languages. They\nreport the baseline performance of NLU and MT tasks on the dataset using appropriate models.\nAvailability of such large benchmarks will aid the development of new methods and models.\n7.1.4\nRethinking LLM Evaluation. : Xiao et al. [2023] evaluate LoRA adapters for unseen English\ndialects, and they say: “a comprehensive examination of PEFT modules for dialects is needed, which\nwe leave for future work.\". Similar evaluations can be performed for other NLP approaches. In\naddition, new evaluation techniques and metrics will be useful to measure dialectal variation and its\npotential correlation with the performance of NLP tasks. Two recent papers can be of value. Lameli\nand Schönberg [2023] present a measure for spatial language variation. Using distance between\nlocations as a heuristic for dialectal similarity, they examine variations in dialects of German.\nAlso, Keleg et al. [2023] use a dataset in Arabic labeled with the degree of dialectness, to train a\nBERT-based regression model.\n7.2\nEthical & Social Implications\nOverall, dialectal NLP presents an excellent avenue for research with huge social implications. We\nhighlight three considerations of relevance.\n7.2.1\nSocial Implications. While everyone speaks a standard dialect, most people tend to feel\nfamiliarity with people who speak specific dialects. Furthermore, certain traditions and practices\nare tied to localities, which are, in turn, tied to dialects. If the goal of NLP research is to make\ncommunication seamless then the correct way to do so is via a strong emphasis on dialects, by\neffectively engaging with speakers of the dialects [Blaschke et al. 2024]. Most dialects around the\nworld are under-represented in modern-day NLP, which can potentially disadvantage them or leave\nthem out of the benefits of LLMs.. There is also a growing concern among speakers of specific\ndialects that their language is dying either due to the pervasiveness of English via the internet,\nanother majority language, or a related dialect, which has higher official support or recognition.\nWe should acknowledge these concerns and make headway into preserving as many dialects as\npossible, at the risk of losing valuable aspects of the vast tapestry of culture and history.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:26\nJoshi, et al.\n7.2.2\nDialectal Research By Dialect Speakers. Linguistic research colonisation is the process where\nresearchers who do not speak specific languages nor have connections with them conduct research\non said languages. Despite the negative connotation of colonization, this is not a bad thing, because\nno one should monopolise working on specific languages. However, it highlights that there are\nhaves and have-nots, where the haves are researchers and organisations with funding who can work\non dialects and the have-nots are the researchers who would like to work on dialects but simply lack\nfunding. Recently, there has been a growing trend where language speakers are reclaiming dominion\nover research involving their own languages. For example, there has been an explosive growth in\nthe number of researchers and groups like DeepLearning Indaba, Masakhane from African countries\nworking solely on African languages and organisations like AI4Bharat in India working on Indian\nlanguages. Indeed, they have shown that a dedicated focus on language research by speakers of\nthese languages leads to better NLP systems. We, therefore, propose that the organisations with\nfunding leverage their privilege and support those without funding so as to ensure that work on\ndialects is led and owned by groups that are most connected to and impacted by dialects. This\nwill lead to true diversity, equality and inclusivity in NLP research, which will strongly impact\nsociety. Towards this, the emerging sentiment in recent thematic papers in NLP is that communities\nthat speak the dialects must be involved in the development of language technologies for the\ncommunities [Bird 2022; Ramponi 2024].\n7.2.3\nNormalising Working on and Speaking Dialects. One aspect that limits dialectal research is\nthe concept of shame in speaking a certain language or a dialect, an aspect also known as linguistic\nself-hatred. For example, take the case of Mauritian Creole, whose speakers are dwindling by the\nday, mainly because the younger generation feels shame in speaking their native language. The\nsame exists for Konkani. While there are no official reports highlighting the same for dialects, it is\nnot far-fetched to consider that linguistic self-hatred will exist here as well. It is time to end this\nself-hatred and normalise speaking dialects. By doing so, people speaking dialects will become\nmore enthusiastic about preserving their dialects and this will inevitably aid research on dialects,\nthereby positively impacting society. Dialects are closely tied to culture and such differences have\nnot been captured explicitly beyond the works described in this paper.\nREFERENCES\nMuhammad Abdul-Mageed, Hassan Alhuzali, and Mohamed Elaraby. 2018. You tweet what you speak: A city-level dataset\nof arabic dialects. In LREC.\nMuhammad Abdul-Mageed and Mona T Diab. 2014. Sana: A large scale multi-genre, multi-dialect lexicon for arabic\nsubjectivity and sentiment analysis.. In LREC. 1162–1169.\nMuhammad Abdul-Mageed, AbdelRahim Elmadany, Chiyu Zhang, El Moatez Billah Nagoudi, Houda Bouamor, and Nizar\nHabash. 2023. NADI 2023: The Fourth Nuanced Arabic Dialect Identification Shared Task. In ArabicNLP. Association for\nComputational Linguistics, Singapore (Hybrid), 600–613. https://doi.org/10.18653/v1/2023.arabicnlp-1.62\nMuhammad Abdul-Mageed, Chiyu Zhang, Houda Bouamor, and Nizar Habash. 2020. NADI 2020: The First Nuanced Arabic\nDialect Identification Shared Task. In Fifth Arabic Natural Language Processing Workshop. ACL, Barcelona, Spain (Online),\n97–110. https://aclanthology.org/2020.wanlp-1.9\nMuhammad Abdul-Mageed, Chiyu Zhang, AbdelRahim Elmadany, Houda Bouamor, and Nizar Habash. 2021. NADI 2021:\nThe Second Nuanced Arabic Dialect Identification Shared Task. In Sixth Arabic Natural Language Processing Workshop.\nACL, Kyiv, Ukraine (Virtual), 244–259. https://aclanthology.org/2021.wanlp-1.28\nMuhammad Abdul-Mageed, Chiyu Zhang, AbdelRahim Elmadany, Houda Bouamor, and Nizar Habash. 2022. NADI\n2022: The Third Nuanced Arabic Dialect Identification Shared Task. In Seventh Arabic Natural Language Processing\nWorkshop (WANLP). Association for Computational Linguistics, Abu Dhabi, United Arab Emirates (Hybrid), 85–97.\nhttps://doi.org/10.18653/v1/2022.wanlp-1.9\nDana Abdulrahim, Go Inoue, Latifa Shamsan, Salam Khalifa, and Nizar Habash. 2022. The Bahrain Corpus: A Multi-genre\nCorpus of Bahraini Arabic. In LREC. 2345–2352.\nKaori Abe, Yuichiroh Matsubayashi, Naoaki Okazaki, and Kentaro Inui. 2018. Multi-dialect Neural Machine Translation and\nDialectometry. In PACLIC. ACL, Hong Kong. https://aclanthology.org/Y18-1001\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:27\nYusuke Abe, Takafumi Suzuki, Bing Liang, Takehito Utsuro, Mikio Yamamoto, Suguru Matsuyoshi, and Yasuhide Kawada.\n2011. Example-based Translation of Japanese Functional Expressions utilizing Semantic Equivalence Classes. In 4th\nWorkshop on Patent Translation. Xiamen, China. https://aclanthology.org/2011.mtsummit-wpt.10\nNoëmi Aepli, Antonios Anastasopoulos, Adrian-Gabriel Chifu, William Domingues, Fahim Faisal, Mihaela Gaman, Radu Tu-\ndor Ionescu, and Yves Scherrer. 2022. Findings of the VarDial Evaluation Campaign 2022. In Ninth Workshop on NLP for\nSimilar Languages, Varieties and Dialects. Association for Computational Linguistics, Gyeongju, Republic of Korea, 1–13.\nNoëmi Aepli, Çağrı Çöltekin, Rob Van Der Goot, Tommi Jauhiainen, Mourhaf Kazzaz, Nikola Ljubešić, Kai North, Barbara\nPlank, Yves Scherrer, and Marcos Zampieri. 2023. Findings of the VarDial Evaluation Campaign 2023. In VarDial.\nAssociation for Computational Linguistics, Dubrovnik, Croatia, 251–261.\nNoëmi Aepli and Rico Sennrich. 2022. Improving Zero-Shot Cross-lingual Transfer Between Closely Related Languages by\nInjecting Character-Level Noise. In Findings of ACL. 4074–4083. https://doi.org/10.18653/v1/2022.findings-acl.321\nOrevaoghene Ahia, Anuoluwapo Aremu, Diana Abagyan, Hila Gonen, David Ifeoluwa Adelani, Daud Abolade, Noah A. Smith,\nand Yulia Tsvetkov. 2024. Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects. In EMNLP. Association\nfor Computational Linguistics, Miami, Florida, USA, 4392–4409. https://aclanthology.org/2024.emnlp-main.251\nOrevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R Mortensen, Noah A Smith, and Yulia Tsvetkov. 2023.\nDo All Languages Cost the Same? Tokenization in the Era of Commercial Language Models. In EMNLP. 9904–9923.\nHemn Karim Ahmed and Jamal Ali Hussein. 2020. Design and Implementation of a Chatbot for Kurdish Language Speakers\nUsing Chatfuel Platform. Kurdistan Journal of Applied Research (2020), 117–135.\nAlham Fikri Aji, Genta Indra Winata, Fajri Koto, Samuel Cahyawijaya, Ade Romadhony, Rahmad Mahendra, Kemal\nKurniawan, David Moeljadi, Radityo Eko Prasojo, Timothy Baldwin, Jey Han Lau, and Sebastian Ruder. 2022. One\nCountry, 700+ Languages: NLP Challenges for Underrepresented Languages and Dialects in Indonesia. In ACL. Dublin,\nIreland, 7226–7249. https://doi.org/10.18653/v1/2022.acl-long.500\nDana Al-Ghadhban and Nora Al-Twairesh. 2020. Nabiha: an Arabic dialect chatbot. International Journal of Advanced\nComputer Science and Applications 11, 3 (2020).\nKamla Al-Mannai, Hassan Sajjad, Alaa Khader, Fahad Al Obaidli, Preslav Nakov, and Stephan Vogel. 2014. Unsupervised\nWord Segmentation Improves Dialectal Arabic to English Machine Translation. In Workshop on Arabic Natural Language\nProcessing. ACL, Doha, Qatar, 207–216. https://doi.org/10.3115/v1/W14-3628\nMd Mahfuz Ibn Alam, Sina Ahmadi, and Antonios Anastasopoulos. 2024. CODET: A Benchmark for Contrastive Dialectal\nEvaluation of Machine Translation. In Findings of EACL. 1790–1859. https://aclanthology.org/2024.findings-eacl.125\nDana Abu Ali and Nizar Habash. 2016. Botta: An arabic dialect chatbot. In COLING (System Demonstrations). 208–212.\nHasan Alkheder, Houda Bouamor, Nizar Habash, and Ahmet Zengin. 2023. Benchmarking Dialectal Arabic-Turkish Machine\nTranslation. In Machine Translation Summit XIX. Asia-Pacific Association for Machine Translation, Macau SAR, China,\n261–271. https://aclanthology.org/2023.mtsummit-research.22\nEbtesam H Almansor and Ahmed Al-Ani. 2017. Translating Dialectal Arabic as Low Resource Language using Word\nEmbedding. In RANLP. INCOMA Ltd., Varna, Bulgaria, 52–57. https://doi.org/10.26615/978-954-452-049-6_008\nTahani Alshareef and Muazzam Ahmed Siddiqui. 2020. A seq2seq neural network based conversational agent for gulf arabic\ndialect. In 2020 21st International Arab Conference on Information Technology (ACIT). IEEE, 1–7.\nAreej Alshutayri and Eric Atwell. 2018. Creating an Arabic Dialect Text Corpus by Exploring Twitter, Facebook, and Online\nNewspapers. In OSACT 3: The 3rd Workshop on Open-Source Arabic Corpora and Processing Tools. 54.\nEkaterina Artemova, Verena Blaschke, and Barbara Plank. 2024. Exploring the Robustness of Task-oriented Dialogue\nSystems for Colloquial German Varieties. In EACL). 445–468.\nKatya Artemova and Barbara Plank. 2023. Low-resource Bilingual Dialect Lexicon Induction with Large Language Models.\nIn 24th Nordic Conference on Computational Linguistics (NoDaLiDa). University of Tartu Library, Tórshavn, Faroe Islands,\n371–385. https://aclanthology.org/2023.nodalida-1.39\nAdel Assiri, Ahmed Emam, and Hmood Al-Dossari. 2018. Towards enhancement of a lexicon-based approach for Saudi\ndialect sentiment analysis. Journal of information science 44, 2 (2018), 184–202.\nFaical Azouaou and Imane Guellil. 2017. Alg/fr: A step by step construction of a lexicon between algerian dialect and french.\nIn PACLIC, Vol. 31.\nNiyati Bafna, Cristina España-Bonet, Josef Van Genabith, Benoît Sagot, and Rachel Bawden. 2023. Cross-lingual Strategies\nfor Low-resource Language Modeling: A Study on Five Indic Dialects. In Actes de CORIA-TALN 2023. Actes de la 30e\nConférence sur le Traitement Automatique des Langues Naturelles (TALN), volume 1 : travaux de recherche originaux –\narticles longs. Paris, France, 28–42.\nNurpeiis Baimukan, Houda Bouamor, and Nizar Habash. 2022. Hierarchical aggregation of dialectal data for Arabic dialect\nidentification. In LREC. 4586–4596.\nAri Ball-Burack, Michelle Seng Ah Lee, Jennifer Cobbe, and Jatinder Singh. 2021. Differential tweetment: Mitigating racial\ndialect bias in harmful tweet detection. In 2021 ACM Conference on Fairness, Accountability, and Transparency. 116–128.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:28\nJoshi, et al.\nRamy Baly, Alaa Khaddaj, Hazem Hajj, Wassim El-Hajj, and Khaled Bashir Shaban. 2019. Arsentd-lev: A multi-topic corpus\nfor target-based sentiment analysis in arabic levantine tweets. arXiv preprint arXiv:1906.01830 (2019).\nJeremy Barnes, Petter Mæhlum, and Samia Touileb. 2021. NorDial: A Preliminary Corpus of Written Norwegian Dialect\nUse. In 23rd Nordic Conference on Computational Linguistics (NoDaLiDa). Linköping University Electronic Press, Sweden,\nReykjavik, Iceland (Online), 445–451. https://aclanthology.org/2021.nodalida-main.51\nAymen Ben Elhaj Mabrouk, Moez Ben Haj Hmida, Chayma Fourati, Hatem Haddad, and Abir Messaoudi. 2021. A Multilingual\nAfrican Embedding for FAQ Chatbots. arXiv e-prints (2021), arXiv–2103.\nSteven Bird. 2022. Local Languages, Third Spaces, and other High-Resource Scenarios. In ACL. 7817–7829. https://doi.org/\n10.18653/v1/2022.acl-long.539\nVerena Blaschke, Christoph Purschke, Hinrich Schütze, and Barbara Plank. 2024. What do dialect speakers want? a survey\nof attitudes towards language technology for german dialects. arXiv preprint arXiv:2402.11968 (2024).\nVerena Blaschke, Hinrich Schütze, and Barbara Plank. 2023. Does Manipulating Tokenization Aid Cross-Lingual Transfer? A\nStudy on POS Tagging for Non-Standardized Languages. In VarDial. 40–54. https://doi.org/10.18653/v1/2023.vardial-1.5\nSu Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach. 2020. Language (technology) is power: A critical survey\nof \"bias\" in nlp. arXiv preprint arXiv:2005.14050 (2020).\nSu Lin Blodgett, Lisa Green, and Brendan O’Connor. 2016. Demographic Dialectal Variation in Social Media: A Case Study\nof African-American English. In EMNLP. Austin, Texas, 1119–1130. https://doi.org/10.18653/v1/D16-1120\nSu Lin Blodgett, Johnny Wei, and Brendan O’Connor. 2018. Twitter Universal Dependency Parsing for African-American\nand Mainstream American English. In ACL. 1415–1425. https://doi.org/10.18653/v1/P18-1131\nHouda Bouamor, Nizar Habash, and Kemal Oflazer. 2014. A multidialectal parallel corpus of Arabic. In LREC 2014. European\nLanguage Resources Association (ELRA), 1240–1245.\nHouda Bouamor, Nizar Habash, Mohammad Salameh, Wajdi Zaghouani, Owen Rambow, Dana Abdulrahim, Ossama Obeid,\nSalam Khalifa, Fadhl Eryani, Alexander Erdmann, et al. 2018. The MADAR arabic dialect corpus and lexicon. In LREC.\nRahma Boujelbane, Mariem Ellouze khemekhem, Siwar BenAyed, and Lamia Hadrich Belguith. 2013. Building bilingual\nlexicon to create Dialect Tunisian corpora and adapt language model. In Second Workshop on Hybrid Approaches to\nTranslation. Sofia, Bulgaria, 88–93. https://aclanthology.org/W13-2813\nElMehdi Boujou, Hamza Chataoui, Abdellah El Mekki, Saad Benjelloun, Ikram Chairi, and Ismail Berrada. 2021. An open\naccess nlp dataset for arabic dialects: Data collection, labeling, and model construction. arXiv preprint arXiv:2102.11000\n(2021).\nDustin Bowers, Antti Arppe, Jordan Lachler, Sjur Moshagen, and Trond Trosterud. 2017. A Morphological Parser for Odawa.\nIn Workshop on the Use of Computational Methods in the Study of Endangered Languages. 1–9. https://doi.org/10.18653/\nv1/W17-0101\nManuel Burghardt, Daniel Granvogl, and Christian Wolff. 2016. Creating a Lexicon of Bavarian Dialect by Means of Facebook\nLanguage Data and Crowdsourcing. In LREC. 2029–2033. https://aclanthology.org/L16-1321\nAbhisek Chakrabarty, Raj Dabre, Chenchen Ding, Hideki Tanaka, Masao Utiyama, and Eiichiro Sumita. [n. d.]. FeatureBART:\nFeature Based Sequence-to-Sequence Pre-Training for Low-Resource NMT. In COLING.\nAbhisek Chakrabarty, Raj Dabre, Chenchen Ding, Masao Utiyama, and Eiichiro Sumita. 2020. Improving Low-Resource NMT\nthrough Relevance Based Linguistic Features Incorporation. In COLING. International Committee on Computational\nLinguistics, Barcelona, Spain (Online), 4263–4274. https://doi.org/10.18653/v1/2020.coling-main.376\nAna Paula Chaves, Jesse Egbert, Toby Hocking, Eck Doerry, and Marco Aurelio Gerosa. 2022. Chatbots language design: The\ninfluence of language variation on user experience with tourist assistant chatbots. ACM Transactions on Computer-Human\nInteraction 29, 2 (2022), 1–38.\nDavid Chiang, Mona Diab, Nizar Habash, Owen Rambow, and Safiullah Shareef. 2006. Parsing arabic dialects. In 11th\nConference of the European Chapter of the Association for Computational Linguistics. 369–376.\nAdrian-Gabriel Chifu, Goran Glavaš, Radu Tudor Ionescu, Nikola Ljubešić, Aleksandra Miletić, Filip Miletić, Yves Scherrer,\nand Ivan Vulić. 2024. VarDial Evaluation Campaign 2024: Commonsense Reasoning in Dialects and Multi-Label Similar\nLanguage Identification. In VarDial. Association for Computational Linguistics, Mexico City, Mexico, 1–15.\nRahul Chitturi and John Hansen. 2008. Dialect Classification for Online Podcasts Fusing Acoustic and Language Based\nStructural and Semantic Information. In ACL. 21–24. https://aclanthology.org/P08-2006\nSiew Yeng Chow and Francis Bond. 2022. Singlish where got rules one? constructing a computational grammar for Singlish.\nIn LREC. 5243–5250.\nSteven Coats. 2022. The Corpus of Australian and New Zealand Spoken English: A new resource of naturalistic speech\ntranscripts. In Australasian Language Technology Association Workshop. 1–5. https://aclanthology.org/2022.alta-1.1\nSteven Coats. 2023. Double modals in contemporary British and Irish speech. English Language & Linguistics 27, 4 (2023),\n693–718.\nAntonio Contarino. 2021. Neural machine translation adaptation and automatic terminology evaluation: a case study on\nItalian and South Tyrolean German legal texts.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:29\nRyan Cotterell and Chris Callison-Burch. 2014. A Multi-Dialect, Multi-Genre Corpus of Informal Written Arabic.. In LREC.\n241–245.\nFelicity Cox. 2006. The acoustic characteristics of/hVd/vowels in the speech of some Australian teenagers. Australian journal\nof linguistics 26, 2 (2006), 147–179.\nFelicity Cox and Sallyanne Palethorpe. 2007. Australian English. Journal of the International Phonetic Association 37, 3\n(2007), 341–350.\nMarcelo Criscuolo and Sandra Aluisio. 2017. Discriminating between similar languages with word-level convolutional\nneural networks. In VarDial. 124–130.\nRaj Dabre, Mary Dabre, and Teresa Pereira. 2024. Machine Translation Of Marathi Dialects: A Case Study Of Kadodi. In\nEleventh Workshop on Asian Translation (WAT 2024). Association for Computational Linguistics, Miami, Florida, USA,\n36–44. https://aclanthology.org/2024.wat-1.3\nJamell Dacon, Haochen Liu, and Jiliang Tang. 2022. Evaluating and Mitigating Inherent Linguistic Bias of African American\nEnglish through Inference. In COLING. 1442–1454. https://aclanthology.org/2022.coling-1.124\nKareem Darwish, Nizar Habash, Mourad Abbas, Hend Al-Khalifa, Huseein T Al-Natsheh, Houda Bouamor, Karim Bouzoubaa,\nVioletta Cavalli-Sforza, Samhaa R El-Beltagy, Wassim El-Hajj, et al. 2021. A panoramic survey of natural language\nprocessing in the Arab world. Commun. ACM 64, 4 (2021), 72–81.\nKareem Darwish, Hamdy Mubarak, Mohamed Eldesouki, Ahmed Abdelali, Younes Samih, Randah Alharbi, Mohammed\nAttia, Walid Magdy, and Laura Kallmeyer. 2018. Multi-dialect Arabic POS tagging: a CRF approach. In LREC. European\nLanguage Resources Association (ELRA), 93–98.\nKareem Darwish, Hassan Sajjad, and Hamdy Mubarak. 2014. Verifiably Effective Arabic Dialect Identification. In EMNLP.\n1465–1468. https://doi.org/10.3115/v1/D14-1154\nFlavia De Camillis, Egon Waldemar Stemle, Elena Chiocchetti, and Francesco Fernicola. 2023. The MT@ BZ Corpus: machine\ntranslation & legal language. In Annual Conference of the European Association for Machine Translation. 171–180.\nDorottya Demszky, Devyani Sharma, Jonathan H Clark, Vinodkumar Prabhakaran, and Jacob Eisenstein. 2020. Learning to\nrecognize dialect features. arXiv preprint arXiv:2010.12707 (2020).\nDorottya Demszky, Devyani Sharma, Jonathan H Clark, Vinodkumar Prabhakaran, and Jacob Eisenstein. 2021. Learning to\nRecognize Dialect Features. In NAACL. 2315–2338.\nMona Diab, Nizar Habash, Owen Rambow, Mohamed Altantawy, and Yassine Benajiba. 2010. COLABA: Arabic dialect\nannotation and processing. In Workshop on semitic language processing. 66–74.\nShahd Dibas, Christian Khairallah, Nizar Habash, Omar Fayez Sadi, Tariq Sairafy, Karmel Sarabta, and Abrar Ardah. 2022.\nMaknuune: A Large Open Palestinian Arabic Lexicon. In Arabic Natural Language Processing Workshop. Association for\nComputational Linguistics (ACL), 131–141.\nNguyen Van Dinh, Thanh Chi Dang, Luan Thanh Nguyen, and Kiet Van Nguyen. 2024. Multi-Dialect Vietnamese: Task,\nDataset, Baseline Models and Challenges. In EMNLP. Association for Computational Linguistics, Miami, Florida, USA,\n7476–7498. https://aclanthology.org/2024.emnlp-main.426\nA. Seza Doğruöz and Preslav Nakov. 2014. Predicting Dialect Variation in Immigrant Contexts Using Light Verb Constructions.\nIn EMNLP. 1391–1395. https://doi.org/10.3115/v1/D14-1145\nLongxu Dou, Yan Gao, Mingyang Pan, Dingzirui Wang, Wanxiang Che, Dechen Zhan, and Jian-Guang Lou. 2023. MultiSpider:\ntowards benchmarking multilingual text-to-SQL semantic parsing. In AAAI, Vol. 37. 12745–12753.\nFanny Ducel, Karën Fort, Gaël Lejeune, and Yves Lepage. 2022. Do we Name the Languages we Study? The# BenderRule in\nLREC and ACL articles. In LREC. 564–573.\nJonathan Dunn. 2019. Modeling Global Syntactic Variation in English Using Dialect Classification. In VarDial. Association\nfor Computational Linguistics, 42–53. https://doi.org/10.18653/v1/W19-1405\nJonathan Dunn and Ben Adams. 2020. Geographically-Balanced Gigaword Corpora for 50 Language Varieties. In LREC.\nEuropean Language Resources Association, Marseille, France, 2528–2536. https://aclanthology.org/2020.lrec-1.308\nChloe Eggleston and Brendan O’Connor. 2022. Cross-Dialect Social Media Dependency Parsing for Social Scientific Entity\nAttribute Analysis. In Workshop on Noisy User-generated Text (W-NUT 2022). Association for Computational Linguistics,\n38–50. https://aclanthology.org/2022.wnut-1.4\nJacob Eisenstein, Vinodkumar Prabhakaran, Clara Rivera, Dorottya Demszky, and Devyani Sharma. 2023. MD3: The Multi-\nDialect Dataset of Dialogues. In Proc. INTERSPEECH 2023. 4059–4063. https://doi.org/10.21437/Interspeech.2023-2150\nAbdellah El Mekki, Abdelkader El Mahdaouy, Ismail Berrada, and Ahmed Khoumsi. 2021. Domain Adaptation for Arabic\nCross-Domain and Cross-Dialect Sentiment Analysis from Contextualized Word Embedding. In NAACL. 2824–2837.\nhttps://doi.org/10.18653/v1/2021.naacl-main.226\nHeba Elfardy and Mona T Diab. 2012. Simplified guidelines for the creation of Large Scale Dialectal Arabic Annotations.. In\nLREC. 371–378.\nAbdelRahim Elmadany, Sherif Abdou, and Mervat Gheith. 2018a. Improving Dialogue Act Classification for Spontaneous\nArabic Speech and Instant Messages at Utterance Level. In LREC.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:30\nJoshi, et al.\nA Elmadany, Hamdy Mubarak, and Walid Magdy. 2018b. Arsas: An arabic speech-act and sentiment corpus of tweets.\nOSACT 3 (2018), 20.\nAshraf Elnagar, Sane M Yagi, Ali Bou Nassif, Ismail Shahin, and Said A Salloum. 2021. Systematic literature review of\ndialectal Arabic: identification and detection. IEEE Access 9 (2021), 31010–31042.\nAsmaa Elsaid, Ammar Mohammed, Lamiaa Fattouh Ibrahim, and Mohammed M Sakre. 2022. A comprehensive review of\narabic text summarization. IEEE Access 10 (2022), 38012–38030.\nAlexander Erdmann, Nizar Habash, Dima Taji, and Houda Bouamor. 2017. Low Resourced Machine Translation via Morpho-\nsyntactic Modeling: The Case of Dialectal Arabic. In Machine Translation Summit XVI: Research Track. Nagoya Japan,\n185–200. https://aclanthology.org/2017.mtsummit-papers.15\nAlexander Erdmann, Nasser Zalmout, and Nizar Habash. 2018. Addressing noise in multidialectal word embeddings. In\nACL. 558–565.\nRamy Eskander, Nizar Habash, Owen Rambow, and Arfath Pasha. 2016. Creating resources for Dialectal Arabic from a\nsingle annotation: A case study on Egyptian and Levantine. In COLING. 3455–3465.\nDominique Estival, Steve Cassidy, Felicity Cox, and Denis Burnham. 2014. AusTalk: an audio-visual corpus of Australian\nEnglish. In Ninth International Conference on Language Resources and Evaluation (LREC’14). European Language Resources\nAssociation (ELRA), 3105–3109. http://www.lrec-conf.org/proceedings/lrec2014/pdf/520_Paper.pdf\nAhmed Fadhil et al. 2019. OlloBot-towards a text-based arabic health conversational agent: Evaluation and results. In RANLP.\n295–303.\nFahim Faisal, Orevaoghene Ahia, Aarohi Srivastava, Kabir Ahuja, David Chiang, Yulia Tsvetkov, and Antonios Anas-\ntasopoulos. 2024. DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and Closely-Related Languages. In\nACL.\nIbrahim Abu Farha and Walid Magdy. 2022. The Effect of Arabic Dialect Familiarity on Data Annotation. In Arabic Natural\nLanguage Processing Workshop. 399–408.\nEve Fleisig, Genevieve Smith, Madeline Bossi, Ishita Rustagi, Xavier Yin, and Dan Klein. 2024. Linguistic Bias in ChatGPT:\nLanguage Models Reinforce Dialect Discrimination. In EMNLP. Association for Computational Linguistics, Miami, Florida,\nUSA, 13541–13564. https://aclanthology.org/2024.emnlp-main.750\nAsbjørn Følstad and Petter Bae Brandtzaeg. 2020. Users’ experiences with chatbots: findings from a questionnaire study.\nQuality and User Experience 5, 1 (2020), 3.\nAhlam Fuad and Maha Al-Yahya. 2022. AraConv: Developing an Arabic task-oriented dialogue system using multi-lingual\ntransformer model mT5. Applied Sciences 12, 4 (2022), 1881.\nMihaela Gaman, Dirk Hovy, Radu Tudor Ionescu, Heidi Jauhiainen, Tommi Jauhiainen, Krister Lindén, Nikola Ljubešić,\nNiko Partanen, Christoph Purschke, Yves Scherrer, and Marcos Zampieri. 2020. A Report on the VarDial Evaluation\nCampaign 2020. In VarDial. International Committee on Computational Linguistics (ICCL), Barcelona, Spain (Online),\n1–14. https://aclanthology.org/2020.vardial-1.1\nHans Goebl. 1993. Dialectometry: a short overview of the principles and practice of quantitative classification of linguistic\natlas data. In Contributions to Quantitative Linguistics: First International Conference on Quantitative Linguistics, QUALICO,\nTrier, 1991. Springer, 277–315.\nKoustava Goswami, Rajdeep Sarkar, Bharathi Raja Chakravarthi, Theodorus Fransen, and John Philip McCrae. 2020.\nUnsupervised deep language and dialect identification for short texts. In International Conference on Computational\nLinguistics. 1606–1617.\nCyril Goutte, Serge Léger, Shervin Malmasi, and Marcos Zampieri. 2016. Discriminating similar languages: Evaluations and\nexplorations. In LREC.\nImane Guellil, Faical Azouaou, Fodil Benali, and Hachani Ala-Eddine. 2021. ONE: Toward ONE model, ONE algorithm, ONE\ncorpus dedicated to sentiment analysis of Arabic/Arabizi and its dialects. In Workshop on Computational Approaches to\nSubjectivity, Sentiment and Social Media Analysis. Association for Computational Linguistics, Online, 236–249.\nJohn J Gumperz. 1982. Discourse strategies. Number 1. Cambridge University Press.\nNizar Habash and Owen Rambow. 2006. MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects. In\nACL. 681–688.\nInjy Hamed, Nizar Habash, Slim Abdennadher, and Ngoc Thang Vu. 2022. ArzEn-ST: A Three-way Speech Translation\nCorpus for Code-Switched Egyptian Arabic-English. In Seventh Arabic Natural Language Processing Workshop (WANLP).\nAssociation for Computational Linguistics, Abu Dhabi, United Arab Emirates (Hybrid), 119–130. https://doi.org/10.\n18653/v1/2022.wanlp-1.12\nAbualsoud Hanani and Rabee Naser. 2020. Spoken Arabic dialect recognition using X-vectors. Natural Language Engineering\n26, 6 (2020), 691–700.\nSalima Harrat, Karima Meftouh, and Kamel Smaïli. 2018. Maghrebi Arabic dialect processing: an overview. Journal of\nInternational Science and General Applications 1 (2018).\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:31\nCamille Harris, Matan Halevy, Ayanna Howard, Amy Bruckman, and Diyi Yang. 2022. Exploring the role of grammar\nand word choice in bias toward african american english (aae) in hate speech classification. In 2022 ACM Conference on\nFairness, Accountability, and Transparency. 789–798.\nCamille Harris, Chijioke Mgbahurike, Neha Kumar, and Diyi Yang. 2024. Modeling Gender and Dialect Bias in Automatic\nSpeech Recognition. In Findings of EMNLP. Association for Computational Linguistics, Miami, Florida, USA, 15166–15184.\nhttps://aclanthology.org/2024.findings-emnlp.890\nHany Hassan, Mostafa Elaraby, and Ahmed Y. Tawfik. 2017. Synthetic Data for Neural Machine Translation of Spoken-\nDialects. In 14th International Conference on Spoken Language Translation. International Workshop on Spoken Language\nTranslation, Tokyo, Japan, 82–89. https://aclanthology.org/2017.iwslt-1.12\nHossein Hassani. 2017. Kurdish Interdialect Machine Translation. In Fourth Workshop on NLP for Similar Languages, Varieties\nand Dialects (VarDial). ACL, Valencia, Spain, 63–72. https://doi.org/10.18653/v1/W17-1208\nEinar Haugen. 1966. Dialect, language, nation 1. American anthropologist 68, 4 (1966), 922–935.\nMichael Haugh and Klaus P Schneider. 2012. Im/politeness across Englishes. , 1017–1021 pages.\nWilliam Held, Caleb Ziems, and Diyi Yang. 2023. TADA : Task Agnostic Dialect Adapters for English. In Findings of ACL.\n813–824. https://doi.org/10.18653/v1/2023.findings-acl.51\nValentin Hofmann, Pratyusha Ria Kalluri, Dan Jurafsky, and Sharese King. 2024. Dialect prejudice predicts AI decisions\nabout people’s character, employability, and criminality. arXiv preprint arXiv:2403.00742 (2024).\nPierre-Edouard Honnet, Andrei Popescu-Belis, Claudiu Musat, and Michael Baeriswyl. 2018. Machine Translation of\nLow-Resource Spoken Dialects: Strategies for Normalizing Swiss German. In LREC. European Language Resources\nAssociation (ELRA), Miyazaki, Japan. https://aclanthology.org/L18-1597\nRenkui Hou and Chu-Ren Huang. 2020. Classification of regional and genre varieties of Chinese: A correspondence analysis\napproach based on comparable balanced corpora. Natural Language Engineering 26, 6 (2020), 613–640.\nDirk Hovy and Christoph Purschke. 2018. Capturing Regional Variation with Distributed Place Representations and\nGeographic Retrofitting. In EMNLP. ACL, Brussels, Belgium, 4383–4394. https://doi.org/10.18653/v1/D18-1469\nDirk Hovy and Diyi Yang. 2021. The importance of modeling social factors of language: Theory and practice. In NAACL-HLT.\n588–602.\nFatemah Husain, Hana Al-Ostad, and Halima Omar. 2022. A weak supervised transfer learning approach for sentiment\nanalysis to the Kuwaiti dialect. In The Seventh Arabic Natural Language Processing Workshop (WANLP). 161–173.\nRyo Igarashi and So Miyagawa. 2024. Enhancing Neural Machine Translation for Ainu-Japanese: A Comprehensive Study on\nthe Impact of Domain and Dialect Integration. In 4th International Conference on Natural Language Processing for Digital\nHumanities. Association for Computational Linguistics, Miami, USA, 413–422. https://aclanthology.org/2024.nlp4dh-1.40\nGo Inoue, Bashar Alhafni, Nurpeiis Baimukan, Houda Bouamor, and Nizar Habash. 2021. The Interplay of Variant, Size, and\nTask Type in Arabic Pre-trained Language Models. In 6th Arabic Natural Language Processing Workshop, WANLP 2021.\nAssociation for Computational Linguistics (ACL), 92–104.\nGo Inoue, Salam Khalifa, and Nizar Habash. 2022. Morphosyntactic Tagging with Pre-trained Language Models for Arabic\nand its Dialects. In Findings of ACL. 1708–1719. https://doi.org/10.18653/v1/2022.findings-acl.135\nMustafa Jarrar, Nizar Habash, Faeq Alrimawi, Diyam Akra, and Nasser Zalmout. 2017. Curras: an annotated corpus for the\nPalestinian Arabic dialect. Language Resources and Evaluation 51 (2017), 745–775.\nTommi Jauhiainen, Marco Lui, Marcos Zampieri, Timothy Baldwin, and Krister Lindén. 2019. Automatic language identifi-\ncation in texts: A Survey. Journal of Artificial Intelligence Research 65 (2019), 675–782.\nSerena Jeblee, Weston Feely, Houda Bouamor, Alon Lavie, Nizar Habash, and Kemal Oflazer. 2014. Domain and Dialect\nAdaptation for Machine Translation into Egyptian Arabic. In Workshop on Arabic Natural Language Processing. Association\nfor Computational Linguistics, Doha, Qatar, 196–206. https://doi.org/10.3115/v1/W14-3627\nJennifer Jenkins. 2009. English as a lingua franca: Interpretations and attitudes. World Englishes 28, 2 (2009), 200–207.\nDeborah G Johnson and Mario Verdicchio. 2017. Reframing AI discourse. Minds and Machines 27 (2017), 575–590.\nAnna Jørgensen, Dirk Hovy, and Anders Søgaard. 2015. Challenges of studying and processing dialects in social media. In\nWorkshop on Noisy User-generated Text. 9–18. https://doi.org/10.18653/v1/W15-4302\nAlaa Joukhadar, Huda Saghergy, Leen Kweider, and Nada Ghneim. 2019. Arabic dialogue act recognition for textual chatbot\nsystems. In First International Workshop on NLP Solutions for Under Resourced Languages. 43–49.\nDavid Jurgens, Yulia Tsvetkov, and Dan Jurafsky. 2017. Incorporating Dialectal Variability for Socially Equitable Language\nIdentification. In ACL. Vancouver, Canada, 51–57. https://doi.org/10.18653/v1/P17-2009\nBraj B Kachru. 1992. The other tongue: English across cultures. Urbana (1992).\nVani Kanjirangat, Tanja Samardzic, Fabio Rinaldi, and Ljiljana Dolamic. 2022. Early Guessing for Dialect Identification. In\nFindings of EMNLP. 6417–6426.\nAnjali Kantharuban, Ivan Vulić, and Anna Korhonen. 2023. Quantifying the Dialect Gap and its Correlates Across Languages.\nIn Findings of EMNLP. 7226–7245. https://aclanthology.org/2023.findings-emnlp.481\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:32\nJoshi, et al.\nAbdelrahman Kaseb and Mona Farouk. 2022. SAIDS: A Novel Approach for Sentiment Analysis Informed of Dialect and\nSarcasm. WANLP 2022 (2022), 22.\nAndre Kåsen, Kristin Hagen, Anders Nøklestad, Joel Priestly, Per Erik Solberg, and Dag Trygve Truslew Haug. 2022. The\nNorwegian Dialect Corpus Treebank. In LREC. 4827–4832. https://aclanthology.org/2022.lrec-1.516\nAmr Keleg, Sharon Goldwater, and Walid Magdy. 2023. ALDi: Quantifying the Arabic Level of Dialectness of Text. In\nEMNLP. 10597–10611. https://aclanthology.org/2023.emnlp-main.655\nVijay Keswani and L Elisa Celis. 2021. Dialect diversity in text summarization on twitter. In The Web Conference 2021.\n3802–3814.\nSalam Khalifa, Nizar Habash, Dana Abdulrahim, and Sara Hassan. 2016. A large scale corpus of Gulf Arabic. In LREC.\nEuropean Language Resources Association (ELRA), 4282–4289.\nSalam Khalifa, Nasser Zalmout, and Nizar Habash. 2020. Morphological analysis and disambiguation for Gulf Arabic: The\ninterplay between resources and methods. In LREC. 3895–3904.\nAnthony S Kroch. 1986. Toward a theory of social dialect variation. In Dialect and Language Variation. Elsevier, 344–366.\nSachin Kumar, Antonios Anastasopoulos, Shuly Wintner, and Yulia Tsvetkov. 2021. Machine Translation into Low-\nresource Language Varieties. In ACL-IJCNLP. Association for Computational Linguistics, Online, 110–121.\nhttps:\n//doi.org/10.18653/v1/2021.acl-short.16\nOlli Kuparinen. 2023. Murreviikko - A Dialectologically Annotated and Normalized Dataset of Finnish Tweets. In VarDial.\nAssociation for Computational Linguistics, Dubrovnik, Croatia, 31–39. https://doi.org/10.18653/v1/2023.vardial-1.3\nOlli Kuparinen, Aleksandra Miletić, and Yves Scherrer. 2023. Dialect-to-Standard Normalization: A Large-Scale Multilingual\nEvaluation. In Findings of EMNLP. Association for Computational Linguistics, 13814–13828. https://aclanthology.org/\n2023.findings-emnlp.923\nAlfred Lameli and Andreas Schönberg. 2023. A Measure for Linguistic Coherence in Spatial Language Variation. In VarDIAL.\n133–141.\nThang Le and Anh Luu. 2023. A Parallel Corpus for Vietnamese Central-Northern Dialect Text Transfer. In Findings of\nEMNLP. 13839–13855. https://aclanthology.org/2023.findings-emnlp.925\nHeather Lent, Kushal Tatariya, Raj Dabre, Yiyi Chen, Marcell Fekete, Esther Ploeger, Li Zhou, Ruth-Ann Armstrong, Abee\nEijansantos, Catriona Malau, Hans Erik Heje, Ernests Lavrinovics, Diptesh Kanojia, Paul Belony, Marcel Bollmann,\nLoïc Grobol, Miryam de Lhoneux, Daniel Hershcovich, Michel DeGraff, Anders Søgaard, and Johannes Bjerva. 2024.\nCreoleVal: Multilingual Multitask Benchmarks for Creoles. Transactions of the Association for Computational Linguistics\n12 (2024), 950–978. https://doi.org/10.1162/tacl_a_00682\nManning Li and Jiye Mao. 2015. Hedonic or utilitarian? Exploring the impact of communication style alignment on user’s\nperception of virtual health advisory services. International Journal of Information Management 35, 2 (2015), 229–243.\nYanchen Liu, William Held, and Diyi Yang. 2023. DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules.\nIn EMNLP. Singapore, 13776–13793.\nZhengyuan Liu, Shikang Ni, Ai Ti Aw, and Nancy F. Chen. 2022. Singlish Message Paraphrasing: A Joint Task of Creole\nTranslation and Text Normalization. In COLING. 3924–3936. https://aclanthology.org/2022.coling-1.345\nSin-En Lu, Bo-Han Lu, Chao-Yi Lu, and Richard Tzong-Han Tsai. 2022. Exploring Methods for Building Dialects-Mandarin\nCode-Mixing Corpora: A Case Study in Taiwanese Hokkien. In Findings of EMNLP. 6287–6305. https://doi.org/10.18653/\nv1/2022.findings-emnlp.469\nMarco Lui and Timothy Baldwin. 2012. langid.py: An Off-the-shelf Language Identification Tool. In ACL System Demonstra-\ntions. Jeju Island, Korea, 25–30.\nMarco Lui and Paul Cook. 2013. Classifying English documents by national dialect. In Australasian Language Technology\nAssociation Workshop. 5–15.\nMohamed Maamouri, Ann Bies, Seth Kulick, Michael Ciul, Nizar Habash, and Ramy Eskander. 2014. Developing an Egyptian\nArabic Treebank: Impact of Dialectal Morphology on Annotation and Tool Development.. In LREC. 2348–2354.\nShervin Malmasi, Marcos Zampieri, Nikola Ljubešić, Preslav Nakov, Ahmed Ali, and Jörg Tiedemann. 2016. Discriminating\nbetween similar languages and arabic dialect identification: A report on the third dsl shared task. In VarDial. 1–14.\nKaushal Kumar Maurya, Rahul Kejriwal, Maunendra Sankar Desarkar, and Anoop Kunchukuttan. 2023. Utilizing Lexical Sim-\nilarity to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages. arXiv preprint arXiv:2305.05214\n(2023).\nSalima Mdhaffar, Fethi Bougares, Yannick Esteve, and Lamia Hadrich-Belguith. 2017. Sentiment analysis of tunisian dialects:\nLinguistic ressources and experiments. In Arabic Natural Language Processing Workshop. 55–61.\nKarima Meftouh, Salima Harrat, Salma Jamoussi, Mourad Abbas, and Kamel Smaili. 2015. Machine Translation Experiments\non PADIC: A Parallel Arabic DIalect Corpus. In PACLIC. Shanghai, China, 26–34. https://aclanthology.org/Y15-1004\nAndrew John Merrison, Jack J Wilson, Bethan L Davies, and Michael Haugh. 2012. Getting stuff done: Comparing e-mail\nrequests from students in higher education in Britain and Australia. Journal of pragmatics 44, 9 (2012), 1077–1098.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:33\nCraig Messner and Thomas Lippincott. 2024. Examining Language Modeling Assumptions Using an Annotated Literary\nDialect Corpus. In 4th International Conference on Natural Language Processing for Digital Humanities. Association for\nComputational Linguistics, Miami, USA, 325–330. https://aclanthology.org/2024.nlp4dh-1.32\nErin Meyer. 2014. The culture map: Breaking through the invisible boundaries of global business. Public Affairs.\nFarhad Moghimifar, Shilin Qu, Tongtong Wu, Yuan-Fang Li, and Gholamreza Haffari. 2023. NormMark: A Weakly Supervised\nMarkov Model for Socio-cultural Norm Discovery. In Findings of ACL. Toronto, Canada, 5081–5089.\nBruce Moore. 1999. The Vocabulary of Australian English. Australian National Dictionary Centre, Australian National\nUniversity. URL: http://andc. anu. edu. au/sites/default/files/vocab_aussie_eng. pdf (1999).\nCameron Morin and Steven Coats. 2023. Double modals in Australian and New Zealand English. World Englishes (2023).\nMarzieh Mozafari, Reza Farahbakhsh, and Noël Crespi. 2020. Hate speech detection and racial bias mitigation in social\nmedia based on BERT model. PloS one 15, 8 (2020), e0237861.\nHala Mulki, Hatem Haddad, Mourad Gridach, and Ismail Babaoğlu. 2019. Syntax-ignorant N-gram embeddings for sentiment\nanalysis of Arabic dialects. In Arabic Natural Language Processing Workshop. 30–39.\nRyo Nagata. 2014. Language Family Relationship Preserved in Non-native English. In COLING. Dublin City University and\nAssociation for Computational Linguistics, 1940–1949. https://aclanthology.org/C14-1183\nHumza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Naveed Akhtar, Nick\nBarnes, and Ajmal Mian. 2023. A comprehensive overview of large language models. arXiv preprint arXiv:2307.06435\n(2023).\nJohn Nerbonne and Wilbert Heeringa. 1997. Measuring dialect distance phonetically. In Computational phonology: third\nmeeting of the acl special interest group in computational phonology.\nJohn Nerbonne and Wilbert Heeringa. 2001. Computational comparison and classification of dialects. (2001).\nJ Nerbonne and Wilbert Heeringa. 2002. Computational Comparison and Classification of Dialects. Dialectologia et\nGeolinguistica, Journal of the International Society for Dialectology and Geolinguistics 9 (2002), 69–84.\nHellina Hailu Nigatu, Atnafu Lambebo Tonja, Benjamin Rosman, Thamar Solorio, and Monojit Choudhury. 2024. The Zeno’s\nParadox of ‘Low-Resource’ Languages. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language\nProcessing, Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (Eds.). Association for Computational Linguistics,\nMiami, Florida, USA, 17753–17774. https://doi.org/10.18653/v1/2024.emnlp-main.983\nOssama Obeid, Salam Khalifa, Nizar Habash, Houda Bouamor, Wajdi Zaghouani, and Kemal Oflazer. 2018. MADARi: A Web\nInterface for Joint Arabic Morphological Annotation and Spelling Correction. In LREC. European Language Resources\nAssociation (ELRA), Miyazaki, Japan. https://aclanthology.org/L18-1415\nOssama Obeid, Mohammad Salameh, Houda Bouamor, and Nizar Habash. 2019. ADIDA: Automatic dialect identification for\nArabic. In NAACL (System demonstrations). 6–11.\nOssama Obeid, Nasser Zalmout, Salam Khalifa, Dima Taji, Mai Oudah, Bashar Alhafni, Go Inoue, Fadhl Eryani, Alexander\nErdmann, and Nizar Habash. 2020. CAMeL tools: An open source python toolkit for Arabic natural language processing.\nIn LREC. 7022–7032.\nEbuka Okpala, Long Cheng, Nicodemus Mbwambo, and Feng Luo. 2022. AAEBERT: Debiasing BERT-based Hate Speech\nDetection Models via Adversarial Learning. In ICMLA. IEEE, 1606–1612.\nOlubusayo Olabisi, Aaron Hudson, Antonie Jetter, and Ameeta Agrawal. 2022. Analyzing the Dialect Diversity in Multi-\ndocument Summaries. In COLING. 6208–6221.\nAhmed Oussous, Fatima-Zahra Benjelloun, Ayoub Ait Lahcen, and Samir Belfkih. 2020. ASA: A framework for Arabic\nsentiment analysis. Journal of Information Science 46, 4 (2020), 544–559.\nMichael Paul, Andrew Finch, Paul Dixon, and Eiichiro Sumita. 2011. Dialect translation: integrating Bayesian co-segmentation\nmodels with pivot-based SMT. In Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties.\nMichel Plüss, Jan Deriu, Yanick Schraner, Claudio Paonessa, Julia Hartmann, Larissa Schmidt, Christian Scheller, Manuela\nHürlimann, Tanja Samardžić, Manfred Vogel, and Mark Cieliebak. 2023. STT4SG-350: A Speech Corpus for All Swiss\nGerman Dialect Regions. In ACL (Short Papers). Toronto, Canada, 1763–1772. https://aclanthology.org/2023.acl-short.150\nShenbin Qian, Archchana Sindhujan, Minnie Kabra, Diptesh Kanojia, Constantin Orasan, Tharindu Ranasinghe, and Fred\nBlain. 2024. What do Large Language Models Need for Machine Translation Evaluation?. In Proceedings of the 2024\nConference on EMNLP. Association for Computational Linguistics, Miami, Florida, USA, 3660–3674.\nAl-Khanji Rajai and Narjes Ennasser. 2022. Dealing with dialects in literary translation: Problems and strategies. Jordan\nJournal of Modern Languages and Literatures 14, 1 (2022), 145–163.\nAlan Ramponi. 2024. Language Varieties of Italy: Technology Challenges and Opportunities. Transactions of the Association\nfor Computational Linguistics 12 (2024), 19–38.\nAlan Ramponi and Camilla Casula. 2023a. DIATOPIT: A Corpus of Social Media Posts for the Study of Diatopic Language\nVariation in Italy. In VarDial. 187–199.\nAlan Ramponi and Camilla Casula. 2023b. GeoLingIt at EVALITA 2023: Overview of the Geolocation of Linguistic Variation\nin Italy Task. In Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. CEUR.org, Parma, Italy.\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n1:34\nJoshi, et al.\nArij Riabi, Menel Mahamdi, and Djamé Seddah. 2023. Enriching the NArabizi Treebank: A Multifaceted Approach to Support-\ning an Under-Resourced Language. In 17th Linguistic Annotation Workshop (LAW-XVII). Association for Computational\nLinguistics, Toronto, Canada, 266–278. https://doi.org/10.18653/v1/2023.law-1.26\nParker Riley, Timothy Dozat, Jan A. Botha, Xavier Garcia, Dan Garrette, Jason Riesa, Orhan Firat, and Noah Constant. 2023.\nFRMT: A Benchmark for Few-Shot Region-Aware Machine Translation. Transactions of the Association for Computational\nLinguistics 11 (2023), 671–685. https://doi.org/10.1162/tacl_a_00568\nCelia Roberts. 2021. Linguistic penalties and the job interview. (No Title) (2021).\nSamapika Roy, Sukhada Sukhada, and Anil Kumar Singh. 2020. Parsing Indian English News Headlines. In ICON. 239–242.\nHadeel Saadany, Constantin Orăsan, Emad Mohamed, and Ashraf Tantawy. 2022. A Semi-supervised Approach for a Better\nTranslation of Sentiment in Dialectical Arabic UGT. In Arabic Natural Language Processing Workshop. Association for\nComputational Linguistics, Abu Dhabi, United Arab Emirates (Hybrid). https://doi.org/10.18653/v1/2022.wanlp-1.20\nHassan Sajjad, Ahmed Abdelali, Nadir Durrani, and Fahim Dalvi. 2020. AraBench: Benchmarking Dialectal Arabic-English\nMachine Translation. In COLING. International Committee on Computational Linguistics, Barcelona, Spain (Online),\n5094–5107. https://doi.org/10.18653/v1/2020.coling-main.447\nMohammad Salameh, Houda Bouamor, and Nizar Habash. 2018. Fine-grained Arabic dialect identification. In COLING.\nWael Salloum, Heba Elfardy, Linda Alamir-Salloum, Nizar Habash, and Mona Diab. 2014. Sentence Level Dialect Identification\nfor Machine Translation System Selection. In 52nd ACL (Volume 2: Short Papers). Baltimore, Maryland, 772–778. https:\n//doi.org/10.3115/v1/P14-2125\nWael Salloum and Nizar Habash. 2022. Unsupervised Arabic dialect segmentation for machine translation. Natural Language\nEngineering 28, 2 (2022), 223–248.\nTodd L Sandel. 2015. Dialects. The international encyclopedia of language and social interaction (2015), 1–13.\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A Smith. 2019. The risk of racial bias in hate speech\ndetection. In ACL. 1668–1678.\nKevin Scannell. 2020. Universal Dependencies for Manx Gaelic. In Workshop on Universal Dependencies (UDW 2020). 152–157.\nhttps://aclanthology.org/2020.udw-1.17\nKlaus P Schneider. 2012. Appropriate behaviour across varieties of English. Journal of Pragmatics 44, 9 (2012), 1022–1037.\nDjamé Seddah, Farah Essaidi, Amal Fethi, Matthieu Futeral, Benjamin Muller, Pedro Javier Ortiz Suárez, Benoît Sagot, and\nAbhishek Srivastava. 2020. Building a User-Generated Content North-African Arabizi Treebank: Tackling Hell. In ACL.\nACL, Online, 1139–1150. https://doi.org/10.18653/v1/2020.acl-main.107\nPamela Shapiro and Kevin Duh. 2019. Comparing Pipelined and Integrated Approaches to Dialectal Arabic Neural Machine\nTranslation. In Sixth Workshop on NLP for Similar Languages, Varieties and Dialects. ACL, Ann Arbor, Michigan, 214–222.\nhttps://doi.org/10.18653/v1/W19-1424\nAbdulhadi Shoufan and Sumaya Alameri. 2015. Natural language processing for dialectical Arabic: A survey. In Arabic\nNatural Language Processing Workshop. 36–48.\nVasiliki Simaki, Panagiotis Simakis, Carita Paradis, and Andreas Kerren. 2017. Identifying the Authors’ National Variety of\nEnglish in Social Media Texts. In International Conference Recent Advances in Natural Language Processing, RANLP 2017.\nINCOMA Ltd., Varna, Bulgaria, 671–678. https://doi.org/10.26615/978-954-452-049-6_086\nJiao Sun, Thibault Sellam, Elizabeth Clark, Tu Vu, Timothy Dozat, Dan Garrette, Aditya Siddhant, Jacob Eisenstein,\nand Sebastian Gehrmann. 2023. Dialect-robust Evaluation of Generated Text. In ACL. Toronto, Canada, 6010–6028.\nhttps://doi.org/10.18653/v1/2023.acl-long.331\nRawan Tahssin, Youssef Kishk, and Marwan Torki. 2020. Identifying Nuanced Dialect for Arabic Tweets with Deep Learning\nand Reverse Translation Corpus Extension System. In Fifth Arabic Natural Language Processing Workshop. ACL, Barcelona,\nSpain (Online), 288–294. https://aclanthology.org/2020.wanlp-1.30\nBashar Talafha, Karima Kadaoui, Samar Mohamed Magdy, Mariem Habiboullah, Chafei Mohamed Chafei, Ahmed Oumar\nEl-Shangiti, Hiba Zayed, Mohamedou Cheikh Tourad, Rahaf Alhamouri, Rwaa Assi, Aisha Alraeesi, Hour Mohamed,\nFakhraddin Alwajih, Abdelrahman Mohamed, Abdellah El Mekki, El Moatez Billah Nagoudi, Benelhadj Djelloul Mama Saa-\ndia, Hamzah A. Alsayadi, Walid Al-Dhabyani, Sara Shatnawi, Yasir Ech-chammakhy, Amal Makouar, Yousra Berrachedi,\nMustafa Jarrar, Shady Shehata, Ismail Berrada, and Muhammad Abdul-Mageed. 2024. Casablanca: Data and Models for\nMultidialectal Arabic Speech Recognition. In EMNLP. Association for Computational Linguistics, Miami, Florida, USA,\n21745–21758. https://aclanthology.org/2024.emnlp-main.1211\nSamson Tan, Shafiq Joty, Lav Varshney, and Min-Yen Kan. 2020. Mind Your Inflections! Improving NLP for Non-Standard\nEnglishes with Base-Inflection Encoding. In EMNLP. 5647–5663.\nPascal Vaillant. 2008. A Layered Grammar Model: Using Tree-Adjoining Grammars to Build a Common Syntactic Kernel for\nRelated Dialects. In Ninth International Workshop on Tree Adjoining Grammar and Related Frameworks (TAG+9). Tübingen,\nGermany, 157–164. https://aclanthology.org/W08-2321\nRob Van Der Goot, Ibrahim Sharaf, Aizhan Imankulova, Ahmet Üstün, Marija Stepanović, Alan Ramponi, Siti Oryza\nKhairunnisa, Mamoru Komachi, and Barbara Plank. 2021. From Masked Language Modeling to Translation: Non-English\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\nNatural Language Processing for Dialects of a Language: A Survey\n1:35\nAuxiliary Tasks Improve Zero-shot Spoken Language Understanding. In NAACL. 2479–2497.\nChahan Vidal-Gorène, Nadi Tomeh, and Victoria Khurshudyan. 2024. Cross-Dialectal Transfer and Zero-Shot Learning\nfor Armenian Varieties: A Comparative Analysis of RNNs, Transformers and LLMs. In 4th International Conference on\nNatural Language Processing for Digital Humanities. Association for Computational Linguistics, Miami, USA, 438–449.\nHongmin Wang, Yue Zhang, GuangYong Leonard Chan, Jie Yang, and Hai Leong Chieu. 2017. Universal Dependencies\nParsing for Colloquial Singaporean English. In ACL. 1732–1744. https://doi.org/10.18653/v1/P17-1159\nYizhou Wang, Rikke L. Bundgaard-Nielsen, Brett J. Baker, and Olga Maxwell. 2022. Perceptual Overlap in Classification of\nL2 Vowels: Australian English Vowels Perceived by Experienced Mandarin Listeners. In PACLIC. 317–324.\nZedian Xiao, William Held, Yanchen Liu, and Diyi Yang. 2023. Task-Agnostic Low-Rank Adapters for Unseen English\nDialects. In Findings of ACL.\nRoy Xie, Orevaoghene Ahia, Yulia Tsvetkov, and Antonios Anastasopoulos. 2024. Extracting Lexical Features from Dialects\nvia Interpretable Dialect Classifiers. In NAACL. 54–69. https://doi.org/10.18653/v1/2024.naacl-short.5\nFan Xu, Xiongfei Xu, Mingwen Wang, and Maoxi Li. 2015. Building Monolingual Word Alignment Corpus for the Greater\nChina Region. In Workshop on Language Technology for Closely Related Languages, Varieties and Dialects. Association for\nComputational Linguistics, Hissar, Bulgaria, 85–94. https://aclanthology.org/W15-5414\nRS Yadav. 1974. Interactions of Written and Spoken Hindi. Indian Literature 17, 3 (1974), 61–66.\nJihene Younes, Emna Souissi, Hadhemi Achour, and Ahmed Ferchichi. 2020. Language resources for Maghrebi Arabic\ndialects’ NLP: a survey. Language Resources and Evaluation 54 (2020), 1079–1142.\nMarcos Zampieri, Shervin Malmasi, Yves Scherrer, Tanja Samardžić, Francis Tyers, Miikka Silfverberg, Natalia Klyueva,\nTung-Le Pan, Chu-Ren Huang, Radu Tudor Ionescu, Andrei M. Butnaru, and Tommi Jauhiainen. 2019. A Report on the\nThird VarDial Evaluation Campaign. In VarDial. 1–16. https://doi.org/10.18653/v1/W19-1401\nMarcos Zampieri and Preslav Nakov. 2021. Similar languages, varieties, and dialects: a computational perspective. Cambridge\nUniversity Press.\nMarcos Zampieri, Preslav Nakov, and Yves Scherrer. 2020. Natural language processing for similar languages, varieties, and\ndialects: A survey. Natural Language Engineering 26, 6 (2020), 595–612.\nMarcos Zampieri, Liling Tan, Nikola Ljubešić, and Jörg Tiedemann. 2014. A report on the DSL shared task 2014. In first\nworkshop on applying NLP tools to similar languages, varieties and dialects. 58–67.\nMarcos Zampieri, Liling Tan, Nikola Ljubešić, Jörg Tiedemann, and Preslav Nakov. 2015. Overview of the DSL shared task\n2015. In Workshop on Language Technology for Closely Related Languages, Varieties and Dialects. 1–9.\nRabih Zbib, Erika Malchiodi, Jacob Devlin, David Stallard, Spyros Matsoukas, Richard Schwartz, John Makhoul, Omar F.\nZaidan, and Chris Callison-Burch. 2012. Machine Translation of Arabic Dialects. In NAACL. Montréal, Canada, 49–59.\nhttps://aclanthology.org/N12-1006\nChrysoula Zerva, Frederic Blain, José G. C. De Souza, Diptesh Kanojia, Sourabh Deoghare, Nuno M. Guerreiro, Giuseppe\nAttanasio, Ricardo Rei, Constantin Orasan, Matteo Negri, Marco Turchi, Rajen Chatterjee, Pushpak Bhattacharyya,\nMarkus Freitag, and André Martins. 2024. Findings of the Quality Estimation Shared Task at WMT 2024: Are LLMs\nClosing the Gap in QE?. In Proceedings of the Ninth WMT. ACL, Miami, Florida, USA, 82–109.\nHaolan Zhan, Zhuang Li, Xiaoxi Kang, Tao Feng, Yuncheng Hua, Lizhen Qu, Yi Ying, Mei Rianto Chandra, Kelly Rosalin,\nJureynolds Jureynolds, et al. 2024. RENOVI: A Benchmark Towards Remediating Norm Violations in Socio-Cultural\nConversations. (2024).\nHaolan Zhan, Zhuang Li, Yufei Wang, Linhao Luo, Tao Feng, Xiaoxi Kang, Yuncheng Hua, Lizhen Qu, Lay-Ki Soon, Suraj\nSharma, et al. 2023. Socialdial: A benchmark for socially-aware dialogue systems. In ACM SIGIR. 2712–2722.\nXiongyi Zhang, Jan-Willem van de Meent, and Byron C Wallace. 2021. Disentangling Representations of Text by Masking\nTransformers. In EMNLP. 778–791.\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang,\nZican Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023).\nYuanyuan Zhao, Weiwei Sun, Junjie Cao, and Xiaojun Wan. 2020. Semantic Parsing for English as a Second Language. In\nACL. Association for Computational Linguistics, Online, 6783–6794. https://doi.org/10.18653/v1/2020.acl-main.606\nCaleb Ziems, Jiaao Chen, Camille Harris, Jessica Anderson, and Diyi Yang. 2022. VALUE: Understanding Dialect Disparity\nin NLU. In ACL. Dublin, Ireland, 3701–3720. https://doi.org/10.18653/v1/2022.acl-long.258\nCaleb Ziems, William Held, Jingfeng Yang, Jwala Dhamala, Rahul Gupta, and Diyi Yang. 2023. Multi-VALUE: A Framework\nfor Cross-Dialectal English NLP. In ACL. 744–768. https://doi.org/10.18653/v1/2023.acl-long.44\nReceived 10 Jan 2024; revised 19 Nov 2024; accepted TBA\nJ. ACM, Vol. 1, No. 1, Article 1. Publication date: January xxxx.\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2024-01-11",
  "updated": "2024-12-06"
}