{
  "id": "http://arxiv.org/abs/2402.16482v1",
  "title": "On Languaging a Simulation Engine",
  "authors": [
    "Han Liu",
    "Liantang Li"
  ],
  "abstract": "Language model intelligence is revolutionizing the way we program materials\nsimulations. However, the diversity of simulation scenarios renders it\nchallenging to precisely transform human language into a tailored simulator.\nHere, using three functionalized types of language model, we propose a\nlanguage-to-simulation (Lang2Sim) framework that enables interactive navigation\non languaging a simulation engine, by taking a scenario instance of water\nsorption in porous matrices. Unlike line-by-line coding of a target simulator,\nthe language models interpret each simulator as an assembly of invariant tool\nfunction and its variant input-output pair. Lang2Sim enables the precise\ntransform of textual description by functionalizing and sequentializing the\nlanguage models of, respectively, rationalizing the tool categorization,\ncustomizing its input-output combinations, and distilling the simulator input\ninto executable format. Importantly, depending on its functionalized type, each\nlanguage model features a distinct processing of chat history to best balance\nits memory limit and information completeness, thus leveraging the model\nintelligence to unstructured nature of human request. Overall, this work\nestablishes language model as an intelligent platform to unlock the era of\nlanguaging a simulation engine.",
  "text": " \n1 \nOn Languaging a Simulation Engine \nHan Liu a,b *, Liantang Li a,b \na SOlids inFormaTics AI-Laboratory (SOFT-AI-Lab), College of Polymer Science and Engineering, Sichuan University, Chengdu \n610065, China \nb AIMSOLID Research, Wuhan 430223, China \n* Corresponding author: Han Liu (happylife@ucla.edu) \n \nAbstract \nLanguage model intelligence is revolutionizing the way we program materials simulations. However, the \ndiversity of simulation scenarios renders it challenging to precisely transform human language into a \ntailored simulator. Here, using three functionalized types of language model, we propose a language-to-\nsimulation (Lang2Sim) framework that enables interactive navigation on languaging a simulation engine, \nby taking a scenario instance of water sorption in porous matrices. Unlike line-by-line coding of a target \nsimulator, the language models interpret each simulator as an assembly of invariant tool function and its \nvariant input–output pair. Lang2Sim enables the precise transform of textual description by functionalizing \nand sequentializing the language models of, respectively, rationalizing the tool categorization, customizing \nits input–output combinations, and distilling the simulator input into executable format. Importantly, \ndepending on its functionalized type, each language model features a distinct processing of chat history to \nbest balance its memory limit and information completeness, thus leveraging the model intelligence to \nunstructured nature of human request. Overall, this work establishes language model as an intelligent \nplatform to unlock the era of languaging a simulation engine. \n \n \n \n \n2 \n1. Introduction \nLanguaging a material simulation—viz., leveraging human language to target a material simulator (see Fig. \n1a)—is crucial in advancing the intelligence of human-machine interaction in materials modeling [1–3]. \nHowever, this languaging process is generally challenged by the miscellaneousness of simulation scenarios, \nmodeling toolkits, and computing quantities [4–7] (see Fig. 1b). As such, there remains lack of language \nmodel (LM) that enables the precise transform of human language into a tailored simulator [8,9]. \nOwing to its ability in long-text sequence mapping [10,11], transformer-architected large language model \n(LLM) offers an attractive opportunity in revolutionizing the intelligent era of programming from “machine \nlanguage” to “natural language” paradigm [12,13]. A few recent LLMs have demonstrated their capacity to \nserve as programming copilot in line-by-line coding a tailored simulator by human language instructions \n[9,14]. Despite its unprecedented intelligence, LLM is intrinsically a giant regressor with billions of \nhyperparameters tuned by a giant training set of text sequence pairs [15,16], so that the level of model \nintelligence is greatly limited by the size of model hyperparameters [17,18], the scope of training set [19], and \nthe quality of text labeling [20,21]. As a result, when targeting a material simulation, the present language \nmodels are prone to falling into the common “hallucination” dilemma [22,23], namely, an inaccurate \ntransform from human language to simulation engine. \nHere, relying on three functionalized types of LM—i.e., LM-agents that regulate action-outputs [24–26], we \nintroduce a three-module hierarchical architecture to mitigate the issues of language-to-simulation \n(Lang2Sim) conversion facing a standalone LLM-based foundation model. Unlike programming-copilots \ndedicated in generating a delicate code of simulation [20], our Lang2Sim platform excels at activating a \nchain of LM-agent actions to navigate the transform of human language in a pre-delineated landscape of \nsimulation engines, as delineated herein by the three-module global hierarchy and, inside each module, the \nagent-assembly local hierarchy. Indeed, we find that, in analogy to the search-path scheme of gradient-\ndecent optimization [27–29], the strategy of “navigation-in-hierarchy” enables us to target an optimal \nsimulator in excellent agreement with its textual description, as exemplified herein by languaging a water \n \n3 \nadsorption simulator via lattice density functional theory (LDFT) [30–32]. Importantly, when running on \nUser-Interface (UI), the languaging process exhibits a satisfactory extent of intelligence to interact with UI-\ndetected texts by selectively memorizing the navigation history. As future opportunities, we expect that the \nfunctionality of Lang2Sim platform would be empowered by stimulations of new developments in that \ndirection, including (i) templatized accommodation of miscellaneous simulators [33–37], (ii) mutual \nintegration of simulations and machine learning [38–41], and (iii) tabulated schedule of all-in-one model \nexecution [42–45]. \n \nFig. 1:  Language-to-Simulation (Lang2Sim) workflow. (a) Schematic of languaging a \nsimulation engine. By inputting a textual description of material simulation, Lang2Sim builds \nthe target simulator and outputs its execution result. (b) Schematic of Lang2Sim challenges, \nincluding the miscellaneousness of simulation scenarios, modeling toolkits, and computing \nquantities [4–7], as exemplified by languaging a water adsorption simulator [30–32]. \n \n \nUSER: Textual description \nof a material simulation\nLanguage-to-Simulation \nConvertor (Lang2Sim)\nLang2Sim: Build & Execute \nthe target simulator\nLanguaging a simulation engine\na\nLanguage model\nSimulator\nb\nMany tools to select\nMany quantities to compute\nUser query\nTool\nSimulator\nSimulation toolkit\nElectron-scale\nAtomistic\nMesoscale\nMacroscale\nFiner resolution\nEmpirical\nTheoretical\nComputing pool\nStructural\nDynamics\nThermodynamics\nMechanical\nElectromagnetic\nProperty spectrum\nSimulate water \nadsorption in a porous \nmatrix by lattice \ndensity functional \ntheory (LDFT)\nLDFT tool\n \n4 \n2. Results and Discussion \n2.1 Lang2Sim platform built by three-module hierarchical architecture \nTo establish our conclusions, we now delve into the three-module hierarchical architecture that builds the \nLang2Sim platform, as illustrated in Fig. 2, where each module is featured by a local hierarchy of LM-agent \nassembly. Figure 2a shows three types of LM-agents that are building blocks of the three modules, \nrespectively, including LM-Type, LM-Sim, and LM-EXE, which are functionalized agents aiming to output \nan action of simulation type, simulator index, and simulator input, respectively [24–26] (see Sec. 2.2–2.4). \nTo realize its functionality, each LM-agent has been carefully tuned to generate target actions by prompt-\nengineering and fine-tuning of a transformer-architected LLM [46,47] (i.e., an open-source LLaMA2 model \nherein [48]), or by a similarity search model using regular expression patterns that construct an output-\nformatted LM-EXE [49]. More details about the LM-agents are provided in the Methods section. \nBuilt upon the three functionalized types of LM-agents, we then construct the Lang2Sim platform by \nassembling the agents of the same type into a monofunctional module and, subsequently, sequentializing \nthese modules based on their functionality. Figure 2b illustrates the three-module sequentialization into a \nhierarchical architecture, which consists of (i) a Simulation-Type module built by LM-Type to rationalize \nthe categorization of simulation types (see Sec. 2.2), (ii) a Simulator-Action module built by LM-Sim to \ncustomize the simulator input–output combinations (see Sec. 2.3), and (iii) a Simulator-Input module built \nby LM-EXE to transform textual input into simulator-executable input (see Sec. 2.4). More details about \nthe Lang2Sim architecture are provided in the Methods section. From the general viewpoint of regression \nor classification model [7,33,34], by weaving the action-chain network among LM-agents, their hierarchical \norganization essentially depicts a clear “sim–lang” landscape of simulation engines as a function of human \nlanguage (see Fig. 2b). Consequently, when inputting a textual description of material simulation, the \nlandscape map plays the key role in navigating the conversion to its target simulator. \n \n5 \n \nFig. 2: Architecture of Lang2Sim platform. (a) Three functionalized types of language \nmodel (LM) built by large language model [47] and similarity search model [49]. When \ninputting a simulation text, the three models LM-Type, LM-Sim, and LM-EXE output the \nSimulation-Type, Simulator-Action, and Simulator-Input, respectively. (b) Three-module \nhierarchical architecture of Lang2Sim platform, including Simulation-Type, Simulator-Action, \nSimulator-Execution modules built by LM-Type, LM-Sim, and LM-EXE, respectively. \n \nFigure 3 provides an example of the interplay between Lang2Sim modules and User-Interface (UI), by \ntaking the example of languaging a water sorption simulation [30–32]. According to UI-detected text, one of \nthe LM-agent chains on Lang2Sim platform (see Fig. 2b) is activated to target its chain-end simulator, i.e., \na water adsorption simulator herein via 2D lattice density functional theory (2D-LDFT) []. The computation \ndetails of LDFT simulation can be found in the Methods section. It is worth mentioning that, despite its \nbrevity, this “toy” interplay turns out to activate a series of underlying LM-agents within a complex sim–\nlang landscape (see Sec. 2.2–2.4), thus significant to revealing the platform intelligence in precise transform \nof human language to simulation engine. \na\nSimilarity search model\nLarge language model\nPrompt-engineered / Fine-tuned transformer\nRegular-expression / Vector-similarity search model\nUSER textual Input\nLanguage model (LM)\nOutput: Simulation Type\nLM-Type\nThree Functionalized LM\nLM-Sim\nLM-EXE\nOutput: Simulator Action\nOutput: Simulator Input\nb\nUSER: \nInput\nLM-Type\nLM-Type-i\nLM-Type-n\nLM-Type-1\nLM-Sim-i\nLM-Sim-1\nLM-Sim-j\nLM-EXE-i\nSimulator-i\nLM-EXE-k\nSimulator-k\nLM-EXE-1\nSimulator-1\nSimulation \noutput\nSimulation Type module\nSimulator Action module\nSimulator Execution module\nLang2Sim Platform: Three-Module Hierarchical System\n \n6 \n \nFig. 3: Lang2Sim example run on User-Interface (UI). When inputting a simulation text, \none of the LM chains on Lang2Sim platform (see Fig. 2b) is activated to interact with UI-\ndetected text and to target its chain-end simulator, as exemplified herein by the scenario of \nwater sorption simulation [30–32]. \n \n \n2.2 Simulation-Type module rationalizing the categorization of simulators \nIn the following sections, we take a closer inspection into the chain activation mechanism in each slice of \nthe three-module platform. Firstly, we investigate the Simulation-Type module built by the assembly of \nLM-Type agents, wherein the module functionality is inherited from its LM-Type agent-functionality. \nUSER Interface @ Lang2Sim\nSim. text\nSim. input\nSim. output\n \n7 \nFigure 4a shows the module architecture built by chains of LM-Type. Along one of the chains, LM-Type \noutputs a simulation type within the categorization of its preceding LM-Type output, so as to empower the \nmodule to rationalize the categorization of a simulation type in human-language space. Note that, when the \nUI-detected text is irrelevant to the agent actions in categorizing simulations, LM-Type agent is designed \nto generate a type-hint as human-language guidance for the agent activation and, simultaneously, filter out \nthese irrelevant texts to keep the textual description succinct. \nFigure 4b provides a categorization hierarchy of materials simulations based on a sequential, classified \ndescription of simulation scale, functionality, and toolkit, by taking the example of 2D-LDFT sorption \nsimulation [30–32]. Unlike the casual nature of untempelated human language [50], the templatized hierarchy \nreshapes the human-language space into concise representations, thus greatly reducing the space \ndimensionality and simplifying the sim–lang landscape thereof (see Fig. 4b). More details about the module \narchitecture are provided in Methods section. Notably, this landscape simplification is key to facilitate the \nprecise Lang2Sim conversion by naively activating the target action of LM-Type agent [25,26], regardless of \nthe diversity of UI-detected texts. \nNext, we visualize a chain of agent-action activation in the module by, along the chain, triggering the type-\nhint of each LM-Type to display on User-Interface (UI). Figure 4c shows an example of the module \ninterplay with UI in languaging a 2D-LDFT sorption simulation [30–32], where the input text is set on purpose \nto mismatch the present LM-Type actions directed to their subtype LM-agents, so as to trigger a sequence \nof type-hint displays on UI. Accordingly, the textual description is refined at each response-step to approach \nthe templatized language-features responsible for the present agent activation [25]. By iterating the \ndescription refinement step, an agent-action chain is activated throughout the module to reach its chain-end \nSimulator-Action module (see Sec. 2.3), i.e., 2D-LDFT simulation module herein [30–32]. It should be \npointed out that, despite its intelligent activation of agent actions, the module agent hierarchy may deserve \nmore fine-tuning [46–48], along with some complementary delicate formatting (if any) to simplify the sim–\nlang landscape to more pronounced extent, thus boosting its navigation intelligence. \n \n8 \n \nFig. 4: Simulation-Type module. (a) Module architecture built by chains of LM-Type. Along \none of the LM chains, each LM-Type outputs a simulation type within the categorization of its \npreceding LM-Type output, or outputs a type hint if not applicable. (b) Categorization of \nmaterials simulations by simulation scale, functionality, and toolkit, as exemplified herein by \ncategorizing 2D-LDFT sorption simulation [30–32]. (c) Example of the module interplay with \nUser-Interface (UI). According to UI-detected text, one chain of LM-Type is sequentially \nactivated with type hint output to rationalize the target simulator categorization. \n \n \n2.3 Simulator-Action module customizing the simulator input–output combination \nLying at the chain end of LM-Type agents from Simulation-Type module (see Fig. 4a), we now examine \nthe Simulator-Action module built by an LM-Sim agent that contains multiple simulator actions, as \nillustrated in Fig 5a. Similar to its preceding module, the LM-Sim agent is activated to take an action \ntargeting a simulator matching UI-detected text, or generate an action-hint of simulator availability and \na\nc\nb\nAtomistic\nMesoscale\nElectronic\nMechanics\nInput text\nUser Input \nInterface\nSubtype\nLM-Sim\nMacroscale\nGas / Fluid sorption\nLattice density function theory (LDFT)\n2D lattice simulation\n3D lattice simulation\nAngstrom\nNanometer\nMicron\nSimulation scale\nSimulation scenario / functionality\nLM-Type\nN/A Hint: Unavailable simulation type\nSubtype\n……\n……\nSimulation toolkit\nRationalize the simulation type\nType hint\nType hint\nType hint\nType hint\n \n9 \nfilter out the present chat-history texts if irrelevant. However, unlike LM-Type outputting a simulation type, \nLM-Sim directly outputs the target-simulator action, as derived from the last simulation type that ends the \nsubtype categorization (see Fig. 4a and 5a). Note that, the ending subtype is regulated as an indivisible \n“element tool”, e.g., 2D-LDFT simulation herein [30–32], with enclosed both an invariant tool function and \nits variant input–output pair (see Fig. 5b). Based on this regulation, each simulator within the subtype is \ndefined and interpreted as a customization of the input and output variants in the same tool function.  \nFigure 5b shows the customization of multiple simulator-variants sharing the same 2D-LDFT tool function, \nby on-demand combination of its input–output variants, including the input parameters of porous matrix, \ntemperature, etc., and the output quantities such as adsorption isotherm and hysteresis [30–32]. Details of 2D-\nLDFT tool function are provided in the Methods section. In the same spirit, by customizing its input–output \npair, each “element tool” cultivates multiple simulators sharing the same tool function but diversifying in \ntheir functionalities. Figure 5c shows two examples of the module interplay with UI to evoke two different \n2D-LDFT simulators that compute water adsorption hysteresis and isotherm, respectively, by providing the \ntextual description of computing quantities targeted by the simulator output. Notably, from the language \nviewpoint, interpreting each simulator of the same subtype by its input–output pair can significantly reduce \nthe dimensionality of human-language space and, therefore, simplify the sim–lang landscape to facilitate \nthe precise transform of textual description into the target simulation engine. \n \n10 \n \nFig. 5: Simulator-Action module. (a) Module architecture built by an LM-Sim that contains \nmultiple simulators. Along one chain of LM-Type in Simulation-Type module (see Fig. 4), \nLM-Sim lies at the chain end to activate the simulation type including multiple simulator-\nvariants and outputs a simulator action, or outputs an action hint if not applicable. (b) \nCustomization of simulator-variants within one simulation type—i.e., simulators sharing an \ninvariant tool function, by on-demand combination of its input and output variants, as \nexemplified herein by customizing 2D-LDFT sorption simulation [30–32]. (c) Examples of the \nmodule interplay with User-Interface (UI). According to UI-detected text, different 2D-LDFT \nsimulator variants are evoked to compute water adsorption hysteresis (Simulator-1) and \nisotherm (Simulator-2), respectively. \n \n \na\nInput text\nUser Input \nInterface\nb\nLM-Sim\nN/A Hint: Unavailable Simulator\nLM-EXE-j\nSimulator-j\nLM-EXE-i\nSimulator-i\n2D LDFT simulation\nInput variants\nc\nOutput variants\nInvariant tool function \nfor 2D LDFT\nMatrix, Temperature, Interaction,\nAdsorption isotherm, Hysteresis,\nTarget simulator\nSimulator: on-demand combination \nof input and output variants\n…\n…\nTake one Simulator Action from the simulation type\nSimulator-2\nSimulator-1\n \n11 \n2.4 Simulator-Execution module transforming textual input to simulator input \nFinally, after evoking the target simulator from Simulator-Action module (see Fig. 5a), we investigate the \nworkflow to execute the simulator residing in Simulator-Execution module. Figure 6a shows the module \narchitecture built by an (or a stack of) LM-EXE linked to the simulator tool function, wherein the LM-EXE \nis designed to distill simulator inputs from UI-detected text and transform them into simulator-executable \nformats. In scenarios requiring multiple-format inputs, e.g., number versus matrix, a stack of LM-EXE \nagents is designed with each agent taking charge of one input-format and, upon activation, formatting its \ntextual input into simulator-executable input. If encountering an irrelevant text, the agent generates an \ninput-hint as the format guide and filters out the present chat-history texts for conciseness. More details \nabout LM-EXE agents are provided in the Methods section. \nFigure 6b illustrates a stack of two LM-EXE agents that transform textual description into two executable \ninputs of a 2D-LDFT simulator, wherein the simulator requires a matrix-format input of 2D porous pattern \nand a number-format input of environmental temperature, so as to compute water adsorption isotherm for \nany 2D porous matrix at different temperatures [30–32]. Accordingly, the two agents, referred to as LM-EXE-\nMatrix and LM-EXE-Number, are responsible for outputting a float 2D-matrix and a float number, \nrespectively. To visualize the two agent-functionalities, Figure 6c provides an example of the module \ninterplay with UI. By setting intentionally the absence of simulator inputs, the initial UI-detected text is \nsequentially fed into LM-EXE-Number and -Matrix to activate their input-hint guides, respectively. \nAccording to each agent hint, new textual input typed on UI is directly fed into the agent and, once the two \nagents complete the formatting of their own textual inputs, the simulator tool function is equipped to execute \nwith these inputs and, eventually, outputs the target computing quantities. Once finished, the simulator \nclears all previous chat-history to release memory and, as a compensation, adds into the chat-history a \nsummary of the present simulator settings to best balance the memory limit and information completeness \n[11,51] (see Sec. 2.5). \n \n12 \n \nFig. 6: Simulator-Execution module. (a) Simulator architecture built by a stack of LM-EXE \nlinked to a tool function. When a simulator is evoked from Simulator-Action module (see Fig. \n5), each LM-EXE of its stack takes charge of a simulator input format (e.g., number or matrix) \nand outputs the formatted input, or outputs an input-hint if not applicable. (b) Transform of \ntextual input into simulator-executable input by functionalizing a stack of output-formatted \nLM-EXE, as exemplified herein by LM-EXE-Number and -Matrix in charge of, respectively, \nnumber- and matrix-format output fed into a target 2D-LDFT sorption simulator [30–32]. (c) \nExample of the module interplay with User-Interface (UI). According to UI-detected text, the \nstack of LM-EXE is sequentially activated with an input-hint to execute the target simulator. \n \nIt is worth mentioning that, to realize its functionality, each LM-EXE agent is built as a combination model \nconsisting of two subagents, namely, LLM-Action and LM-Pattern relying on the techniques of language \ntransformer [47] and similarity search [49], respectively. When the initial UI-detected text comes to LM-\nEXE, the LLM-Action subagent is activated to output an action of the simulator-input state by “known” or \na\nb\nc\nInput text\nUser Input \nInterface\nN/A Hint: Simulator input unknown\nLM-EXE\nSimulator function\nInput\nSimulation result\nSimulator\nTarget 2D-LDFT simulator\n2D porous matrix\nTemperature\nAdsorption isotherm\nFormatting textual input\nLM-EXE-Matrix\nLM-EXE-Number\nMatrix-format input hint\nNumber-format input hint\nSimulator input\nUser input\nUser response\nExecute the Simulator Action by setting Input\nInput hint\nInput hint\nSim. output\n \n13 \n“unknown”, and subsequently, the input state is passed to the LM-Pattern subagent for format-validation \nor -transformation if the simulator input is known, or for input-hint if unknown or invalid. Once the input-\nhint is displayed on UI, new textual input typed on UI would keep a direct feed into LM-Pattern until the \ninput-formatting completion. Unlike the LM-agents in two preceding modules that solely rely on LLM \ntechnique [47]—the same as LLM-Action, the incorporation of LM-Pattern allows a supplementary \nvalidation or modification of the LLM output, and more necessarily, enables matrix formatting that is out \nof the present LLM capacity [52]. Overall, it concludes that LM-agents can be constructed toward enhanced \nintelligence and reliability, by leveraging both the long-text predictability of language transformer and the \npatternization capacity of similarity search model [49]. \n \n2.5 History chat effect on Lang2Sim modules \nAs a final critical examination to the intelligence of Lang2Sim platform, we investigate herein the history \nchat effect on each of the three platform-modules. In an ideal scenario, we expect that the chat-history \nmemory contains all essential text tokens to target an LM-agent action and, at the same time, filters out all \nirrelevant texts to prevent the chat memory from exceeding its maximum token limit set by the LLM agent \n[11,48]. Namely, the memory setting of chat-history needs to balance both its memory limit and information \ncompleteness [11,51], so that each LM-agent appears intelligent to takes an action based on not only the \npresent textual input, but also the information stored in chat-history memory. \nFigure 7 shows an example of chat history effect on languaging a succeeding simulator after the completion \nof a simulator execution, by taking the example of 2D-LDFT sorption simulation [30–32]. Upon the simulator \noutputs displayed, UI terminates its interplay with Simulator-Execution module and, in turn, takes one step \nback redirected to Simulator-Action module. As mentioned earlier, upon simulation completion, the chat-\nhistory memory is reconfigured as a memory-note summarizing the present simulator settings (see Sec. \n2.4). This memory-note, together with new UI-detected text, is delivered to the LM-Sim agent for next \n \n14 \nsimulator-action and, when entering into the target simulator, would activate LM-EXE—more specifically, \nthe LLM-Action subagent—to extract the simulator-input state. As such, the last simulator settings are \nintentionally parsed to the present modules, including both the last simulator-action and its inputs, so that \nthe Lang2sim platform enables an uninterrupted execution of (i) new simulator-action whose input settings \ninherited from the historical input (see left panel of Fig. 7) or (ii) new simulator-input whose simulator-\naction inherited from the historical action (see right panel of Fig. 7). \n \nFig. 7: History chat effect. The left and right panels offer two examples of the interplay \nbetween Simulator-Action module and User-Interface (UI) for new action (left panel) and new \ninput (right panel), respectively. In both cases, the effect of history chat remains active by \nparsing the last action settings to the present action, including historical action and input. \n \nNote that, to optimize the chat-history, Lang2sim modules accommodate chat-history processing in \naccordance to their agent functionalities. For LM-Type agents categorizing simulation types, since their \nnavigation hierarchy contains by itself a history of action chain for each agent located in the hierarchical \nmap, new textual input typed on UI is the only chat-history essential for the agent activation. Similarly, for \n(When finished) Retake \nSimulator Action\nSimulator Action \nModule\nThe last Action settings \nparsed to the present Action\nNew Simulator Action\nSame Input \nNew Input\nSame Action\n \n15 \nan LM-Sim agent customizing simulators of the same subtype, its chat-history is inherited from its \npreceding LM-Type agent at its first activation and, afterwards, the agent is solely activated by new textual \ninput typed on UI, or as discussed above, together with a memory-note of the last simulator-action settings \nif exists (see Fig. 7). Finally, for an LM-EXE agent distilling simulator input with two subagents, its chat-\nhistory is inherited from its preceding LM-Sim agent at its first activation and, afterwards, the LLM-Action \nsubagent goes to dormancy until simulation completion, with the LM-Pattern subagent solely activated by \nnew textual input typed on UI if there remains absent simulator-input. More details about chat-history \nprocessing are provided in the Methods section. Overall, by leveraging the distinct processing of chat-\nhistory for different agents, we demonstrate that the Lang2Sim platform exhibits pronounced intelligence \nto grasp the human-language organization featuring a significant extent of unstructured disorder. \n \n3. Conclusions and Outlook \nOverall, this work establishes an Lang2Sim platform built by three-module hierarchical architecture, with \neach module empowered by a functionalized assembly of LM-agents. Notably, the platform enables precise \ntransform of human language to simulation engine in the complex sim–lang landscape, as exemplified \nherein by languaging a 2D-LDFT sorption simulation [30–32]. Essentially, this transform intelligence is \nenabled by simplifying the sim–lang landscape, including (i) rationalizing the categorization of simulation \ntype, (ii) customizing the simulator input–output combination, and (iii) distilling the simulator input into \nexecutable format. Importantly, relying on distinct chat-history processing for each LM-agent type, the \nplatform balances the memory limit of chat-history and its information completeness, so as to intelligently \ninterplay with new UI-detected text by incorporating the key messages stored in chat-history memory. \nThis work unveils the potentiality of language models as an intelligent platform to unlock the era of \n“languaging a simulation engine”. We expect that the platform introduced herein would modestly stimulate \nnew developments in that direction. As future opportunities, we envision that the functionalities of \n \n16 \nLang2Sim platform would be empowered by advancing several branch directions, as illustrated in Fig. 8, \nincluding (i) templatized accommodation of miscellaneous simulators [5,6], (ii) mutual integration of \nsimulations and machine learning [6,7], and (iii) tabulated schedule of all-in-one model execution [42]. Their \nunification within one framework would present an extreme thrust to extend the capacity of Lang2Sim \nfunctionality, wherein the boundary between simulation, machine learning, and human language would \neventually fade. \n \nFig. 8: Future development of Lang2Sim platform. Built upon the three-module \nhierarchical architecture (see Fig. 2), the functionality of Lang2Sim platform would be \nempowered by (i) templatized accommodation of miscellaneous simulators [5,6], (ii) mutual \nintegration of simulations and machine learning [6,7], and (iii) tabulated schedule of all-in-one \nmodel execution [42]. \n \n \nLang2Sim \nengine\nSchedule \nmultiple \nsimulators\nIntegrate \nmachine \nlearning\nBuild \nmiscellaneous \nsimulators\n \n17 \n4. Methods  \n4.1 Sorption simulation by lattice density function theory (LDFT) \nRelying on 2D lattice density functional theory (2D-LDFT) [30–32], we construct two simulators that \ncompute water adsorption isotherm and hysteresis, respectively, for any 2D porous matrices M at different \ntemperatures T. Other parameters are fixed based on Ref. [30]. Both simulators share an invariant tool \nfunction f described by 2D-LDFT formalism [30–32], that is, the water density 𝜌i at pixel i of a 2D grid under \na relative humidity (RH) is given by: \n𝜌! = 𝑓(𝑀, 𝑇, RH)                       Eq. (1) \nwhere 𝜌i ranges from 0 to 1 to represent that the pore is fully empty or saturated with water, respectively. \nThen the average pore water density 𝜌 is calculated by averaging 𝜌i over all pore pixels. The simulator built \nto compute adsorption isotherm is to apply Eq. (1) at RH = 0-to-100% with an increment dRH (here, \ndRH = 2.5%). Similarly, the simulator built to compute adsorption hysteresis is to further flip the RH values \nand apply Eq. (1) to obtain the desorption isotherm. More details of LDFT formalism can be found in Ref. \n[30–32]. \n \n4.2 Three functionalized language models (LM-agents) \nWe then construct three types of LM-agents, i.e., LM-Type, LM-Sim, and LM-EXE. Note that LM-EXE \nconsists of two subagents, viz., LLM-Action and LM-Pattern. Among all the agents, LM-Type, LM-Sim, \nand LLM-Action are built by a prompt-engineered and fine-tuned LLM from LLaMA2-7B-chat [46–48]. The \nprompt templates for the three agent-types are prescribed to target a json-format action of simulation type, \nsimulator index, and simulator-input state, respectively [24–26]. We then prepare a training set of ~20 input–\noutput text pairs per agent for fine tuning by Low-Rank Adaptation (LoRA) [47,53], wherein the input is \nformatted by its prompt template and, accordingly, the output is the target json-format action. Unlike LLM-\n \n18 \nbased agents [24–26], LM-Pattern is built by a similarity search model using regular expression patterns [49]. \nSpecially, we construct two types of LM-Pattern agents, i.e., LM-Pattern-Number and -Matrix that adopt a \nfloat-number pattern and a float 2D-matrix pattern, respectively, so as to format the textual inputs of 2D \nporous matrix and environmental temperature for 2D-LDFT simulator [30–32]. Note that, if encountering \nirrelevant textual input, all LM-agents are designed to take their hint action for guidance. \n \n4.3 Architecture of Lang2Sim modules \nRelying on the three LM-agent types, we now build the three modules of Lang2Sim platform (see Fig. 2b), \nincluding Simulation-Type, Simulator-Action, and Simulator-Execution module, built by an assembly of \nLM-Type, LM-Sim, and LM-EXE, respectively. The Simulation-Type module assembles LM-Type agents \nas a hierarchy based on simulation scale, functionality, and toolkit. Taking 2D-LDFT simulation for \ninstance [30–32] (see Fig. 4b), as one branch of agent hierarchy in this module, the first-level agent LM-Scale \ntakes charge of categorizing simulation scale into four subtypes as the second-level agents, namely, LM-\nelectronic, -atomistic, -mesoscale, and -macroscale. By activating LM-mesoscale agent, one of the third-\nlevel agents is about to select according to their simulation scenarios or functionalities, such as LM-sorption \nand -mechanics, with LM-sorption matched herein. Then based on the target computing quantities, one \ncandidate computational method or toolkit is recommended in the fourth-level agents, including LM-LDFT \nor -CGMD short for coarse-grained molecular dynamic [54,55]. Finally, the LM-LDFT is further divided into \ntwo subtypes, i.e., LM-2D-LDFT and -3D-LDFT as the ending-level agents [30–32]. \nHere, we take the LM-2D-LDFT agent as LM-Sim in Simulator-Action module under investigation. \nAccordingly, we build two simulators to be incorporated in the module, namely, 2D-LDFT-isotherm and -\nhysteresis that compute water adsorption isotherm and hysteresis, respectively [30–32] (see Sec. 4.1). By \noutputting one simulator action, e.g., 2D-LDFT-isotherm, the agent activates this simulator as Simulator-\nExecution module. Inside the simulator, textual input goes through LLM-Action and LM-Pattern to \n \n19 \ntransform into a float number for temperature input and a float 2D-matrix for porous pattern input. Finally, \nthe executable inputs are fed into the simulator tool function to output the target computing quantities such \nas water adsorption isotherm [30–32]. \n \n4.4 Interplay between Lang2Sim modules and User interface (UI) \nNext, we construct a User-Interface (UI) to visualize the interplay between the three modules and textual \ninputs. The UI is essentially a text-box built to receive textual input and display an output response from \nthe modules. Besides detecting textual input, the UI is used to link the text-box to a specific LM-agent that \nis being activated at present. Even after closing and reopening UI, this linkage is designed to remain valid \nuntil the next LM-agent on the chain is activated. Once a simulation is finished, the linkage between UI and \nthe Simulator-Execution module is terminated, with an “one-step-back” old linkage reestablished between \nUI and the LM-Sim agent in the preceding Simulator-Action module. Moreover, to fully visualize the chat-\nmode interplay, the UI is designed to display all chat records between user inputs and module outputs, \nwhich remains valid even after closing and reopening UI, by loading all the records back on screen. Note \nthat, although all chat records are displayed on UI, each LM-agent has a distinct processing of chat-history \nthat does not necessarily memorize all the chat records (see Sec. 4.5). \n \n4.5 Window selection and processing of history chat \nFinally, we optimize the chat-history memory by distinctly selecting and processing the chat records for \neach LM-agent type, including LM-Type, LM-Sim, LLM-Action, and LM-Pattern. Among these agents, \nLM-Type is designed to activate once and to interplay solely with the present UI-detected text input, that \nis, without history memory needed. LM-Sim adopts the same chat-history setting at its first activation, but \nonce a simulation is finished, the chat-history memory is cleared to empty and, in turn, is added with a \nsummary note of the simulation settings. LLM-Action shares the chat-history fed into LM-Sim, same for \n \n20 \nLM-Pattern at its first activation. However, once a simulator-input hint is displayed on UI, LM-Pattern is \ndesigned to solely interplay with new textual input typed on UI, with no history chat fed into the agent. To \na pronounced extent, these distinct chat-history settings significantly balance its memory limit and \ninformation completeness [11,51]. \n \nAcknowledgements \nFunding: H.L. acknowledges funding from the Fundamental Research Funds for the Central Universities \nunder the Grant No. YJ202271, and the National Natural Science Foundation of China under the Grant No. \n52303042. Author Contributions: Conceptualization: HL; Methodology: HL; Investigation: HL and LL; \nVisualization: HL and LL; Supervision: HL; Writing (original draft): HL; Writing (review and editing): HL \nand LL. Competing interests: The authors declare that they have no competing interests. Data and \nmaterials availability: All data needed to evaluate the conclusions of this study are present in the paper \nand available from Dr. Han Liu upon reasonable request. \n \n \n \n \n21 \nReferences \n1. Slack, D., Krishna, S., Lakkaraju, H. & Singh, S. Explaining machine learning models with \ninteractive natural language conversations using TalkToModel. Nat Mach Intell 5, 873–883 (2023). \n2. Hu, Y. & Buehler, M. J. Deep language models for interpretative and predictive materials science. \nAPL Machine Learning 1, 010901 (2023). \n3. Buehler, M. J. Multiscale Modeling at the Interface of Molecular Mechanics and Natural Language \nthrough Attention Neural Networks. Acc. Chem. Res. (2022) doi:10.1021/acs.accounts.2c00330. \n4. Buehler, M. J. MechGPT, a language-based strategy for mechanics and materials modeling that \nconnects knowledge across scales, disciplines and modalities. Preprint at \nhttp://arxiv.org/abs/2310.10445 (2023). \n5. Liu, H., Du, T., Krishnan, N. M. A., Li, H. & Bauchy, M. Topological optimization of cementitious \nbinders: Advances and challenges. Cement and Concrete Composites 101, 5–14 (2019). \n6. Liu, H. et al. Challenges and opportunities in atomistic simulations of glasses: a review. Comptes \nRendus. Géoscience 354, 1–43 (2022). \n7. Liu, H., Fu, Z., Yang, K., Xu, X. & Bauchy, M. Machine learning for glass science and engineering: \nA review. Journal of Non-Crystalline Solids: X 4, 100036 (2019). \n8. Kashefi, A. & Mukerji, T. ChatGPT for Programming Numerical Methods. Preprint at \nhttp://arxiv.org/abs/2303.12093 (2023). \n9. Sobania, D., Briesch, M. & Rothlauf, F. Choose your programming copilot: a comparison of the \nprogram synthesis performance of github copilot and genetic programming. in Proceedings of the \nGenetic and Evolutionary Computation Conference 1019–1027 (ACM, 2022). \ndoi:10.1145/3512290.3528700. \n10. Vaswani, A. et al. Attention is All you Need. in Advances in Neural Information Processing Systems \nvol. 30 (Curran Associates, Inc., 2017). \n \n22 \n11. Dai, Z. et al. Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context. Preprint \nat https://doi.org/10.48550/arXiv.1901.02860 (2019). \n12. Sarkar, A. et al. What is it like to program with artificial intelligence? Preprint at \nhttps://doi.org/10.48550/arXiv.2208.06213 (2022). \n13. Wermelinger, M. Using GitHub Copilot to Solve Simple Programming Problems. in Proceedings of \nthe 54th ACM Technical Symposium on Computer Science Education V. 1 172–178 (Association for \nComputing Machinery, 2023). doi:10.1145/3545945.3569830. \n14. Pudari, R. & Ernst, N. A. From Copilot to Pilot: Towards AI Supported Software Development. \nPreprint at https://doi.org/10.48550/arXiv.2303.04142 (2023). \n15. Buehler, M. J. FieldPerceiver: Domain agnostic transformer model to predict multiscale physical \nfields and nonlinear material properties through neural ologs. Materials Today 57, 9–25 (2022). \n16. Tsai, Y.-H. H. et al. Multimodal Transformer for Unaligned Multimodal Language Sequences. Proc \nConf Assoc Comput Linguist Meet 2019, 6558–6569 (2019). \n17. Zhang, S. et al. OPT: Open Pre-trained Transformer Language Models. Preprint at \nhttps://doi.org/10.48550/arXiv.2205.01068 (2022). \n18. Chang, Y. et al. A Survey on Evaluation of Large Language Models. Preprint at \nhttps://doi.org/10.48550/arXiv.2307.03109 (2023). \n19. Carlini, N. et al. Extracting Training Data from Large Language Models. in 2633–2650 (2021). \n20. Moradi Dakhel, A. et al. GitHub Copilot AI pair programmer: Asset or Liability? Journal of Systems \nand Software 203, 111734 (2023). \n21. Vaithilingam, P., Zhang, T. & Glassman, E. L. Expectation vs. Experience: Evaluating the Usability \nof Code Generation Tools Powered by Large Language Models. in Extended Abstracts of the 2022 \nCHI Conference on Human Factors in Computing Systems 1–7 (Association for Computing \nMachinery, 2022). doi:10.1145/3491101.3519665. \n22. Manakul, P., Liusie, A. & Gales, M. J. F. SelfCheckGPT: Zero-Resource Black-Box Hallucination \nDetection for Generative Large Language Models. Preprint at http://arxiv.org/abs/2303.08896 (2023). \n \n23 \n23. Yao, J.-Y., Ning, K.-P., Liu, Z.-H., Ning, M.-N. & Yuan, L. LLM Lies: Hallucinations are not Bugs, \nbut Features as Adversarial Examples. Preprint at http://arxiv.org/abs/2310.01469 (2023). \n24. Xi, Z. et al. The Rise and Potential of Large Language Model Based Agents: A Survey. Preprint at \nhttps://doi.org/10.48550/arXiv.2309.07864 (2023). \n25. Andreas, J. Language Models as Agent Models. Preprint at \nhttps://doi.org/10.48550/arXiv.2212.01681 (2022). \n26. Gao, C. et al. S$^3$: Social-network Simulation System with Large Language Model-Empowered \nAgents. Preprint at http://arxiv.org/abs/2307.14984 (2023). \n27. Shewchuk, J. R. An Introduction to the Conjugate Gradient Method Without the Agonizing Pain. \n(1994). \n28. Liu, H., Fu, Z., Li, Y., Sabri, N. F. A. & Bauchy, M. Balance between accuracy and simplicity in \nempirical forcefields for glass modeling: Insights from machine learning. Journal of Non-Crystalline \nSolids 515, 133–142 (2019). \n29. Liu, H., Li, Y., Fu, Z., Li, K. & Bauchy, M. Exploring the landscape of Buckingham potentials for \nsilica by machine learning: Soft vs hard interatomic forcefields. J. Chem. Phys. 152, 051101 (2020). \n30. Liu, H. et al. End-to-end differentiability and tensor processing unit computing to accelerate \nmaterials’ inverse design. npj Comput Mater 9, 1–12 (2023). \n31. Zhang, Y., Liu, H., Zhao, C., Ju, J. W. & Bauchy, M. Deconstructing water sorption isotherms in \ncement pastes by lattice density functional theory simulations. J. Am. Ceram. Soc. 104, 4226–4238 \n(2021). \n32. Kierlik, E., Monson, P. A., Rosinberg, M. L. & Tarjus, G. Adsorption hysteresis and capillary \ncondensation in disordered porous solids: a density functional study. J. Phys.: Condens. Matter 14, \n9295–9315 (2002). \n33. Liu, H., Wu, F.-Y., Zhong, G.-J. & Li, Z.-M. Predicting the complex stress-strain curves of polymeric \nsolids by classification-embedded dual neural network. Materials & Design 227, 111773 (2023). \n \n24 \n34. Liu, H. et al. Predicting the dissolution kinetics of silicate glasses by topology-informed machine \nlearning. npj Mater Degrad 3, 1–12 (2019). \n35. Liu, H. et al. Long-term creep deformations in colloidal calcium–silicate–hydrate gels by accelerated \naging simulations. Journal of Colloid and Interface Science 542, 339–346 (2019). \n36. Liu, H. et al. Effects of polydispersity and disorder on the mechanical properties of hydrated silicate \ngels. Journal of the Mechanics and Physics of Solids 122, 555–565 (2019). \n37. Liu, H., Tang, L., Krishnan, N. M. A., Sant, G. & Bauchy, M. Structural percolation controls the \nprecipitation kinetics of colloidal calcium–silicate–hydrate gels. J. Phys. D: Appl. Phys. 52, 315301 \n(2019). \n38. Liu, H. et al. Learning Molecular Dynamics: Predicting the Dynamics of Glasses by a Machine \nLearning Simulator. Mater. Horiz. 10.1039.D3MH00028A (2023) doi:10.1039/D3MH00028A. \n39. Liu, H., Smedskjaer, M. M. & Bauchy, M. Deciphering a structural signature of glass dynamics by \nmachine learning. Phys. Rev. B 106, 214206 (2022). \n40. Liu, H. et al. Predicting the early-stage creep dynamics of gels from their static structure by machine \nlearning. Acta Materialia 210, 116817 (2021). \n41. Liu, H., Fu, Z., Li, Y., Sabri, N. F. A. & Bauchy, M. Parameterization of empirical forcefields for \nglassy silica using machine learning. MRS Communications 1–7 (2019) doi:10.1557/mrc.2019.47. \n42. Huang, W., Abbeel, P., Pathak, D. & Mordatch, I. Language Models as Zero-Shot Planners: \nExtracting Actionable Knowledge for Embodied Agents. in Proceedings of the 39th International \nConference on Machine Learning 9118–9147 (PMLR, 2022). \n43. Wang, L. et al. A Survey on Large Language Model based Autonomous Agents. Preprint at \nhttps://doi.org/10.48550/arXiv.2308.11432 (2023). \n44. Liu, H., Fu, Z., Li, Y., Sabri, N. F. A. & Bauchy, M. Machine Learning Forcefield for Silicate \nGlasses. arXiv:1902.03486 [cond-mat] (2019). \n45. Ha, C. S. et al. Rapid inverse design of metamaterials based on prescribed mechanical behavior \nthrough machine learning. Nat Commun 14, 5765 (2023). \n \n25 \n46. Hu, Z. et al. LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large \nLanguage Models. Preprint at https://doi.org/10.48550/arXiv.2304.01933 (2023). \n47. Zhang, R. et al. LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init \nAttention. Preprint at https://doi.org/10.48550/arXiv.2303.16199 (2023). \n48. Touvron, H. et al. Llama 2: Open Foundation and Fine-Tuned Chat Models. Preprint at \nhttps://doi.org/10.48550/arXiv.2307.09288 (2023). \n49. Karttunen, L., Chanod, J.-P., Grefenstette, G. & Schille, A. Regular expressions for language \nengineering. Natural Language Engineering 2, 305–328 (1996). \n50. Pennebaker, J. W., Mehl, M. R. & Niederhoffer, K. G. Psychological Aspects of Natural Language \nUse: Our Words, Our Selves. Annual Review of Psychology 54, 547–577 (2003). \n51. White, J. et al. A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT. Preprint at \nhttp://arxiv.org/abs/2302.11382 (2023). \n52. Golkar, S. et al. xVal: A Continuous Number Encoding for Large Language Models. Preprint at \nhttps://doi.org/10.48550/arXiv.2310.02989 (2023). \n53. Hu, E. J. et al. LoRA: Low-Rank Adaptation of Large Language Models. Preprint at \nhttps://doi.org/10.48550/arXiv.2106.09685 (2021). \n54. Vergadou, N. & Theodorou, D. N. Molecular Modeling Investigations of Sorption and Diffusion of \nSmall Molecules in Glassy Polymers. Membranes (Basel) 9, 98 (2019). \n55. Boyd, P. G., Lee, Y. & Smit, B. Computational development of the nanoporous materials genome. \nNature Reviews Materials 2, 17037 (2017). \n \n \n \n",
  "categories": [
    "cs.AI",
    "cs.CE",
    "cs.CL"
  ],
  "published": "2024-02-26",
  "updated": "2024-02-26"
}