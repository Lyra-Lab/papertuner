{
  "id": "http://arxiv.org/abs/2403.07905v1",
  "title": "Enhancing Kubernetes Automated Scheduling with Deep Learning and Reinforcement Techniques for Large-Scale Cloud Computing Optimization",
  "authors": [
    "Zheng Xu",
    "Yulu Gong",
    "Yanlin Zhou",
    "Qiaozhi Bao",
    "Wenpin Qian"
  ],
  "abstract": "With the continuous expansion of the scale of cloud computing applications,\nartificial intelligence technologies such as Deep Learning and Reinforcement\nLearning have gradually become the key tools to solve the automated task\nscheduling of large-scale cloud computing systems. Aiming at the complexity and\nreal-time requirement of task scheduling in large-scale cloud computing system,\nthis paper proposes an automatic task scheduling scheme based on deep learning\nand reinforcement learning. Firstly, the deep learning technology is used to\nmonitor and predict the parameters in the cloud computing system in real time\nto obtain the system status information. Then, combined with reinforcement\nlearning algorithm, the task scheduling strategy is dynamically adjusted\naccording to the real-time system state and task characteristics to achieve the\noptimal utilization of system resources and the maximum of task execution\nefficiency. This paper verifies the effectiveness and performance advantages of\nthe proposed scheme in experiments, and proves the potential and application\nprospect of deep learning and reinforcement learning in automatic task\nscheduling in large-scale cloud computing systems.",
  "text": "Enhancing Kubernetes Automated Scheduling with Deep\nLearning and Reinforcement Techniques for Large-Scale\nCloud Computing Optimization\nZheng Xu1* Yulu Gong1,Yanlin Zhou2,Qiaozhi Bao3,Wenpin Qian4\n1* Computer Engineering,Stevens Institute of Technology,hoboken, NJ,USA\n1 Computer&InformationTechnology,NorthernArizonaUniversity,Flagstaff,AZ,USA\n2Computer Science,Johns Hopkins University MD,USA\n3 Statistics,North Carolina State University,NC State University,Raleigh, North Carolina 27695\n4 Information Science,Trine University Phoenix, Arizona, USA\n*Corresponding author:[Zheng Xu, E-mail:zhengxu1994620@gmail.com]\nABSTRACT\nWith the continuous expansion of the scale of cloud computing applications, artificial intelligence\ntechnologies such as Deep Learning and Reinforcement Learning have gradually become the key tools\nto solve the automated task scheduling of large-scale cloud computing systems. Aiming at the\ncomplexity and real-time requirement of task scheduling in large-scale cloud computing system, this\npaper proposes an automatic task scheduling scheme based on deep learning and reinforcement\nlearning. Firstly, the deep learning technology is used to monitor and predict the parameters in the\ncloud computing system in real time to obtain the system status information. Then, combined with\nreinforcement learning algorithm, the task scheduling strategy is dynamically adjusted according to the\nreal-time system state and task characteristics to achieve the optimal utilization of system resources and\nthe maximum of task execution efficiency. This paper verifies the effectiveness and performance\nadvantages of the proposed scheme in experiments, and proves the potential and application prospect of\ndeep learning and reinforcement learning in automatic task scheduling in large-scale cloud computing\nsystems.\nKey Words：Cloud computing system; Reinforcement learning; Deep learning; Perceptual scheduling;\nlarge-scale\n1. INSTRUCTION\nWith the development of cloud computing, big data and artificial intelligence (AI) technology and the\nindustry's comprehensive application demand for these three technologies, there is a technological\ndevelopment trend of big data, cloud computing and artificial intelligence integration at home and\nabroad. The Big Data Expert Committee of the China Computer Society pointed out in the 2019 Big\nData development trend survey report that artificial intelligence, big data and cloud computing will be\nhighly integrated into an integrated system. The birth of the Hadoop project in 2006 marked the\nbeginning of the era of big data technology, and the commercialization of Amazon web services (AWS)\nmarked the formal step of cloud computing to change the information age. Since then, big data and\ncloud computing have become very hot technologies in recent decades, and academia and industry\nhave vigorously invested in related technology research and development and landing applications, and\nhave created several classic works of collaboration between academia and industry. As a powerful\ncomputing and storage mode, cloud computing provides strong support for the processing of big data,\nbut it also brings a series of new challenges. In the cloud computing environment, how to efficiently\nstore and process big data has become a topic of great concern. Optimizing big data storage and\nprocessing not only impacts the economic benefits of enterprises but also influences data-driven\ndecision-making and innovation capabilities. In this context, this paper aims to deeply analyze the\noptimization strategy of big data storage and processing in cloud computing environment, with a view\nto providing practical guidance and enlightenment for researchers, engineers and decision makers\nHair. For example, the new computing engine Spark technology launched by the University of\nCalifornia, Berkeley in 2012 was quickly accepted by the industry and became a new generation of\nstandard computing engine. In the field of cloud computing, more enterprise-level applications have\npromoted the development of technologies, such as container technology and orchestration system,\nwhich began to rise in 2014, and finally promoted the rapid development of a new generation of cloud\nnative platforms, and Docker and Kubernetes technologies have become the standards of a new\ngeneration of cloud native platforms. The development of basic software is not a simple function\naccumulation, it must go through detailed architecture design and function verification.\nBoth big data and AI computing are typical examples of distributed computing models, relying on\ndirected acyclic graph (DAG) or massive parallel programming (MPP) iterations. It means that\ncomputing tasks are generated at runtime, so it is difficult to schedule in advance, and the distributed\ncharacteristics require higher flexibility and adaptability of scheduling systems. At present, the industry\nis trying to deploy big data platforms and AI technologies on cloud native to achieve greater resilience\nand scalability. However, there have been few breakthroughs in this field on a global scale. This article\nwill cover core innovation: how core scheduling systems in cloud platforms manage and schedule big\ndata and AI applications on cloud native platforms.\n2. TASK SCHEDULING PROBLEM IN CLOUD COMPUTING SYSTEM\n2.1 Cloud computing\nCloud computing refers to the use of the cloud as its production deployment mode during application\ndevelopment, so as to make full use of the core advantages of the cloud such as elasticity, scalability,\nand self-healing. Different from the traditional bloated single application development mode,\ncloud-native application has become the current mainstream application development mode because of\nits effective collaborative development, testing and operation and maintenance, which greatly improves\nthe efficiency and quality of software development and supports rapid product launch and iteration.\nThe platform that can effectively support cloud native applications is usually called cloud native\nplatform, which is mainly characterized by containerized packaging, automated management and\nmicroservices-oriented system. Docker directly uses LinuxCgroup and other technologies to provide\nlogical virtualization. Docker has become the preferred application container technology because of its\nfeatures such as low system overhead, fast startup, good isolation, and convenient application\nencapsulation.\n2.2 Cloud computing system architecture\nThe cloud computing system as a whole is divided into two parts: front-end and back-end. These two\nparts are connected to each other through a network called the Internet. The front-end is the computer\nuser or client, and the back-end system is the so-called \"cloud\" server.\nThe front-end is for customers to access their own applications on the cloud computing system through\ntheir own computer networks, and the cloud computing system provides corresponding user interfaces\naccording to the needs of customers. For example, web-based email systems use existing Web\nbrowsers such as Internet Explorer or Foxmail to access mail systems on \"cloud\" servers. Other unique\napplications can receive professional-grade services from the \"cloud\" server through a specific client\napplication.\nThe back-end is a variety of computer server systems and data cloud storage systems based on the\nInternet to provide customers with a variety of \"cloud\" services. In theory, a cloud computing system\ncan include almost all computer programs, from data processing to video games, and each application\nhas its own dedicated server, which is maintained and managed by a professional team.\nAll \"cloud\" servers are subject to the central server management, the central server according to the\ncustomer and the network smooth situation to determine which customer to use the \"cloud\" server\nservices, to ensure the smooth use of customers, it follows a set of rules that is the protocol, the use of a\nspecial software called middleware. Middleware allows networked computers to communicate with\neach other according to the license, through professional software, running multiple virtual servers on a\nphysical server, each virtual server running its own independent operating system, is a set of open\ninfrastructure virtualization platform in the cloud computing environment, server virtualization reduces\nthe need for more physical machines.\nIf a cloud computing company has a lot of customers, it may need a lot of storage space, the customer\nstores a lot of data on the \"cloud\" server, the cloud computing system requires storage equipment is at\nleast twice the storage capacity, need to store the customer's data at least two or more copies. In this\nway, if one storage server goes down, other servers can continue to provide services without any\nimpact on customers.\n2.3 Machine learning and artificial intelligence\nDistributed computing is rapidly iterated and developed under the requirements of complex industrial\napplications, starting from the MapReduce5 calculation model for offline processing. The online\ncomputing models represented by Spark (Spark, Tez Щ u, Druidn2, etc.) and real-time computing\nmodels (Flinku3l, Spark Streamingu4, etc.) were gradually developed. The new distributed computing\nmodel opens up new application areas, but also poses great challenges to the management, scheduling\nand operation and maintenance of large-scale systems. As a result, big data provides rich data resources,\nwhile cloud computing platforms provide high-performance computing resources and storage\ncapabilities that enable machine learning algorithms to analyze data more precisely, train models, and\nachieve intelligent decisions. For example, natural language processing applications can leverage big\ndata for language model training in a cloud computing environment to improve the accuracy of text\nprocessing. Image recognition applications can also achieve faster image classification and recognition\nthrough the parallel computing power of cloud computing. This integration offers endless possibilities\nfor innovative intelligent applications that help improve the user experience and increase productivity.\nWith the accumulation of big data, data security and privacy issues have become particularly important.\nIn the environment of cloud computing and big data convergence, organizations need to adopt strict\ndata encryption, access control and monitoring measures to ensure the security of large-scale data. Data\nbreaches can lead to serious financial and reputational damage, so protecting the security of data has\nbecome an urgent task.\n2.4 Kubernetes system\nThe kube-scheduler in the Kubernetes cluster monitors newly created Pods without assigned nodes and\nselects the most suitable node for deployment. So how do these actions or these principles work, let's\ntake a look at them. For newly created Pods or other unscheduled Pods, kube-scheduler selects an\noptimal node for them to run on. However, each container in a Pod has different requirements for\nresources, and each Pod has different requirements. Therefore, existing nodes need to be filtered\naccording to specific scheduling requirements.\n2.5 Kubernetes scheduling procedure\nIn a Kubernetes cluster, nodes that meet Pod scheduling requirements are called feasible nodes (FN). If\nthere is no suitable node, the pod will remain unscheduled until the scheduler can place it. That is,\nwhen we create a Pod, if it is in a Pending state for a long time, it is time to see if your cluster\nscheduler has no suitable nodes due to some problem\nAfter the scheduler finds FN for the Pod, it then runs a set of functions to score FN and finds the node\nwith the highest score in FN to run the Pod.\nFactors that need to be considered in scheduling policy decision-making include individual and\ncollective resource requirements, hardware/software/policy constraints, affinity and anti-affinity\nspecifications, data locality, inter-workload interference, and so on.\nPart One - Kubernetes scheduling process. As shown in the following figure, a simple Kubernetes\ncluster architecture is drawn, which includes a kube-ApiServer, a set of webhooks controllers, and a\ndefault kube-Scheduler. There are also two physical machine nodes, Node1 and Node2, on which two\nKubelets are deployed.\nFigure 1:Kubernetes scheduling process architecture\nThe dashed lines in Figure 1 represent the main components of Kubernetes, including Informer, the\nscheduling queue, the scheduler's cache, and the scheduling master loop. Informer uses the list/watch\nmechanism to obtain resource information changes and update queue and cache. . ·NextPod() obtains\nthe Pod of the head of the queue from the queue to be scheduled;\n. Get the Node list from the cache;\nPredicate algorithm is executed for Pod and NodeList to filter out inappropriate nodes. Implement\nPriority algorithm for Pod and NodeList to score nodes;\nAccording to the score, the node with the highest score is calculated：\nTABLE 1. Name of the cloud computing scheduling algorithm\nWhen a Pod with a higher priority does not find a suitable node, the scheduler tries to preempt a Pod\nwith a lower priority for it. When the scheduler selects a suitable node for the Pod, Bind the Pod to the\nnode via bind.\nFeatures of Kubernetes default scheduler:\n(1) Queue-based scheduler\n(2) Dispatch only one at a time\n(3) Pod scheduling time is globally optimal\n2.6 Kubernetes aware scheduling and policy\nKubernetes has two kinds of algorithms for aware scheduling :Predicate and Priority. Predicate is to\nfilter all nodes and filter out unqualified nodes, while Priority is to grade the nodes filtered by the\nPredicate and select the best nodes. Predicate policies filter nodes that meet the conditions. Different\nPods on Node will have resource conflicts. Predicate aims to avoid resource conflicts, node overload,\nport conflicts, etc.\n2.7 Challenges for cloud-native batch computing\n(1) Lack of job management · PoD-level scheduling, unable to perceive the upper application. Lack\nAlgorithm Name\nFeature\nGeneralPredicates\nIt includes three basic checks: nodes, ports, and rules. For\nexample, the maximum number of Pod resource objects on a node\nand whether resources such as CPU, MEM, and GPU meet\nrequirements\nNoDiskConflict\nCheck whether the Node meets the hard disk requirements of the\nPod. For example, check whether the volume used by the Pod\nconflicts with the volume used by other Pods on the node\nCheckVolumeBinding\nCheck whether the node meets the PVC mounting requirements for\nPod resource objects\nNoVolumeZoneConflict\nIf a single cluster is deployed across AZS, check whether the PVC\nto which the Pod resource object is attached is mounted across\nregions\nCheckNodeMemoryPressure\nChecks whether Pod resource objects can be scheduled to\nMemoryPresure nodes\nCheckNodePIDPressure\nCheck whether the Pod resource object can be scheduled to the\nnode with PIDPressure\nPodToleratesNodeTaints\nCheck that the Pod can tolerate all taints on node\nCheckNodeMemoryPressure\nWhen Pod QoS is besteffort, check the remaining memory of\nnodes and exclude nodes with excessive memory pressure\nMatchInterPodAffinity\nCheck whether the node meets the affinity and anti-affinity\nrequirements of the pod\nof operational concept, lack of sound life cycle management. Lack of task dependency and job\ndependency support\n2) Scheduling policy limitations. Gang-Scheduling and Fairshaing scheduling are not supported.\nResource reservation for multiple scenarios is not supported, backfill. CPU/l0 topology based\nscheduling is not supported\nInsufficient support for domain computing frameworks\n(3)·1:1 operator deployment operation and maintenance complex Different frameworks have different\nrequirements for job management and parallel computing. Computationally intensive, large resource\nfluctuations require advanced scheduling capabilities.\n4) Insufficient support for resource planning reuse and heterogeneous computing, lack of queue\nconcept\nDynamic\nplanning\nof\ncluster\nresources\nand\nresource\novercommitment\nare\nnot\nsupported.\nHeterogeneous resources are not supported.\n3. PROPOSED METHODOLOGY FOR TASK SCHEDULING\nWith the development of cutting-edge technologies such as AI large models and machine learning,\nthe demand for computing resources for AI applications is increasing day by day. The\nKubernetes-based AI computing power platform can effectively integrate the underlying hardware\nresources, achieve fine management and optimal allocation of computing power resources, and\npromote the promotion and popularization of AI applications. As the world's top three contributors\nto the Kubernetes project, DaoCloud actively promotes the optimization of scheduling technology,\nimproves the efficiency of resource allocation, and initiates the open source KWOK (Lightweight\nlarge-scale Cluster Simulator). Deeply involved in the research and development of Kueue\n(Kubernetes native job queue management system), and launched a new generation of AI\ncomputing power platform to help enterprises improve the utilization rate of computing power and\npromote the development and application of AI technology.\n3.1 Overview of the Proposed Scheme\n(1) Gang scheduling\nTypically, when automated scheduling is implemented, a job contains multiple instances that need\nto be started and ended together. For the scheduler, a job cannot be scheduled until there are\nenough resources to schedule all instances of the job. Gang scheduling solves the deadlock\nproblem caused by multiple tasks waiting for resources at the same time. Therefore, the\ncommunity current solution abstracts the concept of a PodGroup. Both the batch scheduler\nVolcano and the native scheduler coscheduling plug-ins are based on this concept to implement\ngang scheduling.\n(2) Task scheduling\nFor multi-task, the concept of task queue is introduced to realize multi-queue task scheduling. You\ncan set resource capacity quotas for different queues to solve quota and cost management\nproblems in multi-tenant scenarios. Also priority scheduling. The priority of a task is usually\ndetermined by priorityClassName. Some special cases are also determined by the specifications of\nthe resource package applied for by the task, such as the priority of the large resource package\nspecifications, and the DRF (the task with fewer resources has a higher priority).\n(4) Advanced preemption strategies, such as group preemption.\nIn order to solve the problem of GPU card fragmentation, binback strategy and secondary\nscheduler defragmentation function are needed. Community current solution: Mainly the batch\nscheduler Volcano. In addition, the community provides K8s-based native job queues and flexible\nquota manager Kueue.\n(4) Topology aware scheduling\nIt is necessary to sense the network links between nodes and the connection mode of resources\nwithin a single node to improve task performance, speed up training, and solve the problem of\ninconsistent instance performance.\n(5) GPU topology\nIt is better to schedule different instances of the same task to a combination of GPU cards with\nhigh-speed connections (nvlink, etc.). The scheduler needs to be aware of the topology of resource\nconnections within a single node.\nThe following is an example of the V100 architecture:\nFigure 2: V100 automation scheduling architecture diagram\nEach V100 GPU has six NVLink channels. Eight Gpus cannot be fully connected, and two Gpus\ncan be connected to a maximum of two NVLink channels. There are two NVLink connections\nbetween GPU0 and GPU3, GPU0 and GPU4, one NVLink connection between GPU0 and GPU1,\nand no NVLink connection between GPU0 and 6. Therefore, GPU0 and GPU6 still need to\ncommunicate through PCIe.\nAs can be seen from the figure below, eight Gpus are connected through six NVswitches. Unlike\nthe V100, there are nvlink differences between GPU cards.\nFigure 3:HGXA100 8-GPU Baseboard\n- Network topology\nFaster communication and lower latency between nodes within the same rack or tor. Mainly in the\nlarge-scale distributed training hybrid parallel scenario, the scheduler will schedule m Pods in the\nsame unit to the Node under the same Tor as far as possible according to the convergence ratio of\nthe switch.\n3.2 Utilization of Deep Learning\nThere is a synergy between Kubernetes and deep learning in implementing automated scheduling\napplications. First, Kubernetes, as a container orchestration platform, uses its automatic\nscheduling and resource management capabilities to intelligently assign tasks according to the\nresource requirements of containers and the available resources of nodes to achieve efficient\ncluster management. Secondly, deep learning technology plays an important role in scheduling\ndecision-making. By analyzing historical data, predicting load changes and optimizing scheduling\npolicies, it can further improve the intelligence and adaptability of scheduling, so as to achieve\nmore flexible and efficient task scheduling.\nThis combination enables the automated scheduling system to better adapt to dynamically\nchanging workloads and make optimal scheduling decisions based on real-time performance\nindicators and predicted trends, thereby improving cluster utilization, reliability and performance\nand providing reliable infrastructure support for large-scale containerized applications.\n3.3 Integration of Reinforcement Learning\nThe integration of reinforcement learning and Kubernetes automated scheduling will make the\nscheduling system more intelligent and adaptive. Through the reinforcement learning algorithm,\nthe system can learn the optimal scheduling strategy according to the environmental feedback and\nreward signals, so as to achieve more efficient and flexible task allocation and resource\nmanagement. This combination can further improve the intelligence level of the scheduling\nsystem, so that it can better adapt to the dynamic change of workload and cluster resource\nconditions.\nKubernetes automated scheduling has many advantages on its own, including declarative\nconfiguration, automated scheduling, fault recovery, horizontal scaling, and service discovery and\nload balancing capabilities. Combined with reinforcement learning techniques, these advantages\ncan be further enhanced. For example, reinforcement learning algorithms can dynamically adjust\nscheduling policies based on real-time performance indicators and predicted trends to achieve\nmore intelligent and optimized resource allocation, thereby improving cluster utilization,\nreliability, and performance.\n3.4 Kubernetes automated scheduling features and benefits\n(1)Declarative configuration: Kubernetes simplifies deployment and management by using\ndeclarative configuration to describe the desired state of an application rather than specifying\nspecific action steps.\n(2)Automated Scheduling: Kubernetes provides automatic scheduling capabilities that intelligently\nschedule based on resource requirements of containers and available resources of nodes to ensure\noptimal performance and resource utilization.\n(3)Fault Recovery: Kubernetes has an automatic fault detection and recovery mechanism that can\nautomatically reschedule failed container instances and ensure high availability of applications.\n(4)Horizontal scaling: Kubernetes supports horizontal scaling, which automatically adjusts the\nnumber of copies of the application to meet demand as the load changes.\nService discovery and load Balancing: Kubernetes provides built-in service discovery and load\nbalancing capabilities that make it easy for applications to implement inter-service communication\nand traffic distribution.\n4. METHODOLOGY: PRACTICAL APPLICATION\n4.1 Case overview\nLet's say we have a large e-commerce platform that uses Kubernetes clusters to deploy and\nmanage its services. During specific promotions, traffic spikes, placing extremely high demands\non app availability and performance. To cope with this traffic spike, we need to ensure that Pods\nare scheduled efficiently and that resources are used wisely.\n4.2 Problems Encountered\n(1) Resource bottleneck: During peak traffic, some nodes respond slowly due to excessive (2) load,\nresulting in service interruption.\nScheduling delay: Due to the burst of high traffic, there is a significant delay in the startup and\nscheduling of new Pods.\n(3) Unbalanced resource distribution: some nodes have overutilized resources, while others have\nidle resources.\n4.3 Solution\n(1) Automatic capacity expansion: Use the horizontal Pod automatic capacity expansion (HPA)\nand cluster automatic capacity expansion (CA) features of Kubernetes to dynamically manage\nresources.\n(2) HPA: Automatically increase or decrease the number of Pods based on CPU and memory\nusage to cope with traffic changes.\n(3) CA: Add more nodes when needed and reduce nodes when traffic drops to save costs.\n4.4. Optimize Pod scheduling policies\nAdjust Pod scheduling policies to ensure that Pods are evenly distributed in the cluster and avoid\noverloading of some nodes.\n(1) Pod affinity and anti-affinity: Define appropriate affinity rules to ensure that pods of related\nservices are distributed on different nodes to improve availability.\n(2) Pod topology expansion constraints: Ensure that Pods are evenly distributed in different\navailability zones to avoid the failure of a single area affecting the entire service.\n4.5 Applications of the Advanced Scheduling feature\nUse Taints and Tolerations as well as custom schedulers to further optimize resource allocation.\n(1) Taints and Tolerations: Set up taints for nodes that handle high traffic and only allow Pods\nwith specific tolerations to run on these nodes.\n(2) Custom scheduler: Develop a custom scheduler to optimize Pod scheduling decisions based on\nreal-time traffic and resource usage.\n4.6 Performance Monitoring and Real-time Adjustment\nImplement a comprehensive monitoring and logging system to track cluster performance and\nresource usage in real time.\nMonitoring tools: Use tools such as Prometheus and Grafana to monitor resource usage and\nservice performance.\n(2) Real-time adjustment: Based on monitoring data, quickly adjust scheduling policies and\nresource allocation to meet real-time performance requirements and resource constraints.\n4.7 Disaster Recovery and Failover\nEstablish disaster recovery plans and failover mechanisms to ensure that services continue to run\nin the event of unforeseen problems.\n(1) Multi-region deployment: The service is deployed in different geographical locations to ensure\nthat the failure of a single region does not affect the entire platform.\n(2) Fast recovery strategy: achieve fast fault detection and automated recovery process to reduce\nservice interruption time.\n4.8 Testing and optimization\nComprehensive testing, including stress testing and performance testing, is conducted prior to\nproduction deployment to verify the effectiveness of scheduling policies and resource allocation.\n(1) Performance test: simulate high traffic conditions to test the response ability of the system and\nthe effectiveness of resource allocation.\n(2) Optimization iteration: Adjust and optimize scheduling strategy and resource allocation\naccording to test results.\nEstablish feedback mechanisms to continuously collect and analyze performance data to\ncontinuously improve scheduling policies and resource management.\n(3) Continuous monitoring: Implement continuous performance monitoring to ensure that any\nproblems are detected and resolved in a timely manner.\n(4) Improvement iteration: continuous scheduling strategy and resource management optimization\nbased on collected data and feedback.\n5. CONCLUSION\nThrough this research, we not only deeply analyze the application of deep learning and\nreinforcement learning in large-scale cloud computing systems, but also discuss the combination\nwith Kubernetes automated scheduling. We propose a scheme that utilizes deep learning to\nmonitor system state and reinforcement learning to adjust scheduling strategy to realize intelligent\nmanagement of cluster resources and optimization of task scheduling. The experimental results\nshow that this method has achieved remarkable results in improving system efficiency, resource\nutilization and performance.\nFuture research directions include further optimizing deep learning models to improve their ability\nto accurately predict system state and task characteristics, as well as improving reinforcement\nlearning algorithms to be more flexible to different workloads and clustered environments. In\naddition, it should also strengthen the combination with practical application scenarios, explore\nmore practical and feasible automatic task scheduling schemes to meet the growing demand for\ncloud computing, and promote the development and innovation of cloud computing technology.\nIn summary, the combination of deep learning and reinforcement learning technologies with\nKubernetes automated scheduling brings new opportunities and challenges for large-scale cloud\ncomputing systems. The automatic task scheduling scheme proposed in this paper provides a\nfeasible solution to improve the efficiency, resource utilization and performance of the system,\nand provides a useful enlightenment for the future research and practice in the field of cloud\ncomputing.\n6. REFERENCE\n[1] VERMA A, PEDROSA L, KORUPOLU M,et al. Large-scale cluster management atGoogle\nwith Borg[C]// The 10th EuropeanConference on Computer Systems, April 2l-24 ，2015 ，\nBordeaux,France. New York:ACM Press, 2015.\n[2] Wang Xiaohua, Li Dali. Research on optimization strategy of big Data storage [J]. Data\nManagement,2019,36(6):82-88\n[3] Chen Xiaofeng, Liu Wenqiang. (in Chinese) Overview of optimization methods for big Data\nprocessing [J]. Computing Technology and Automation, 2021,40(2):51-57. (in Chinese)\n[4] Zhang Ming. Trend analysis of Cloud Computing and Big Data Integration [J]. Computer\nScience, 2019,47(8):35-421\n[5]\nBURNS\nB,GRANT\nB,OPPENHEIMERD,\net\nal.\nBorg,\nomega,\nand\nKubernetes[J]Communications of the ACM,2016, 59(5):50-57.\n[6]ZAHARIA M,CHOWDHURY M,DAST,et al. Resilient distributed datasets: afault-tolerant\nabstraction for in-memorycluster computing[C]// The 9th UsenixConference on Networked\nSystems\nDesignand\nImplementation,April\n25-27,2012,\nSanJose,\nUSA.Berkeley:\nUSENIX\nAssociation,2012.\n[7]BREWER E A. Kubernetes and the path to[4]cloud native[C]// The 6th ACM Symposiumon\nCloud Computing, August 27-29,2015Kohala Coast, USA.New York: ACM Press,2015:167.\n[8]\nHINDMAN\nB,\nKONWINSKI\nA,ZAHARIAM,\net\nal.\nMesos:\na\nplatform\nfor\nfine-grainedresource\nsharing\nin\nthe\ndata\ncenter[C]//The\n8th\nUSENlX\nConference\non\nNetworkedSystems\nDesign\nand\nlmplementation,\nMarch30-April\n1,2011,Boston,USA.\nBerkeley:USENIX Association,2013:295-308.SCHWARZKOPF M,KONWINSKIA,ABD-\n[9]EL-MALEK M, et al.Omega: flexible,scalable schedulers for large computeclusters[C]// The\n8th ACM EuropeanConference on Computer Systems, April 15-17,2013,Prague, Czech Republic.\nNewYork: ACM Press,2013:351-364.\n[10]GHEMAWAT\nS,\nGOBIOFF\nH,\nLEUNG\nST.\nThe\nGoogle\nfile\nsystem[J].\nACM\nSIGOPSOperating Systems Principles, 2003, 37(5):29-43.\n[11]“Based on Intelligent Advertising Recommendation and Abnormal Advertising Monitoring\nSystem in the Field of Machine Learning”. International Journal of Computer Science and\nInformation\nTechnology,\nvol.\n1,\nno.\n1,\nDec.\n2023,\npp.\n17-23,\nhttps://doi.org/10.62051/ijcsit.v1n1.03.\n[12]Yu,\nLiqiang,\net\nal.\n“Research\non\nMachine\nLearning\nWith\nAlgorithms\nand\nDevelopment”. Journal of Theory and Practice of Engineering Science, vol. 3, no. 12, Dec. 2023,\npp. 7-14, doi:10.53469/jtpes.2023.03(12).02.\n[13]Huang, J., Zhao, X., Che, C., Lin, Q., & Liu, B. (2024). Enhancing Essay Scoring with\nAdversarial\nWeights\nPerturbation\nand\nMetric-specific\nAttentionPooling.\narXiv\npreprint\narXiv:2401.05433.\n[14]Tianbo, Song, Hu Weijun, Cai Jiangfeng, Liu Weijia, Yuan Quan, and He Kun. \"Bio-inspired\nSwarm Intelligence: a Flocking Project With Group Object Recognition.\" In 2023 3rd\nInternational Conference on Consumer Electronics and Computer Engineering (ICCECE), pp.\n834-837. IEEE, 2023.DOI: 10.1109/mce.2022.3206678\n[15] “ The Application of Artificial Intelligence in Medical Diagnostics: A New Frontier”.\nAcademic Journal of Science and Technology, vol. 8, no. 2, Dec. 2023, pp. 57-61,\nhttps://doi.org/10.54097/ajst.v8i2.14945\n",
  "categories": [
    "cs.DC",
    "cs.AI",
    "cs.LG"
  ],
  "published": "2024-02-26",
  "updated": "2024-02-26"
}