{
  "id": "http://arxiv.org/abs/2403.17561v5",
  "title": "A Survey on State-of-the-art Deep Learning Applications and Challenges",
  "authors": [
    "Mohd Halim Mohd Noor",
    "Ayokunle Olalekan Ige"
  ],
  "abstract": "Deep learning, a branch of artificial intelligence, is a data-driven method\nthat uses multiple layers of interconnected units (neurons) to learn intricate\npatterns and representations directly from raw input data. Empowered by this\nlearning capability, it has become a powerful tool for solving complex problems\nand is the core driver of many groundbreaking technologies and innovations.\nBuilding a deep learning model is challenging due to the algorithm's complexity\nand the dynamic nature of real-world problems. Several studies have reviewed\ndeep learning concepts and applications. However, the studies mostly focused on\nthe types of deep learning models and convolutional neural network\narchitectures, offering limited coverage of the state-of-the-art deep learning\nmodels and their applications in solving complex problems across different\ndomains. Therefore, motivated by the limitations, this study aims to\ncomprehensively review the state-of-the-art deep learning models in computer\nvision, natural language processing, time series analysis and pervasive\ncomputing. We highlight the key features of the models and their effectiveness\nin solving the problems within each domain. Furthermore, this study presents\nthe fundamentals of deep learning, various deep learning model types and\nprominent convolutional neural network architectures. Finally, challenges and\nfuture directions in deep learning research are discussed to offer a broader\nperspective for future researchers.",
  "text": "A Survey on State-of-the-art Deep Learning\nApplications and Challenges\nMohd Halim Mohd Noora,∗, Ayokunle Olalekan Igeb\naSchool of Computer Sciences, Universiti Sains Malaysia, Jalan\nUniversiti, Gelugor, 11800, Pulau Pinang, Malaysia\nbDepartment of Computer Science, Adekunle Ajasin University, Ikare Akoko-Ipeme\nRd, Akungba-Akoko, P.M.B 001, Ondo State, Nigeria\nAbstract\nDeep learning, a branch of artificial intelligence, is a data-driven method\nthat uses multiple layers of interconnected units (neurons) to learn intricate\npatterns and representations directly from raw input data. Empowered by\nthis learning capability, it has become a powerful tool for solving complex\nproblems and is the core driver of many groundbreaking technologies and\ninnovations. Building a deep learning model is challenging due to the algo-\nrithm’s complexity and the dynamic nature of real-world problems. Several\nstudies have reviewed deep learning concepts and applications. However, the\nstudies mostly focused on the types of deep learning models and convolu-\ntional neural network architectures, offering limited coverage of the state-\nof-the-art deep learning models and their applications in solving complex\nproblems across different domains. Therefore, motivated by the limitations,\nthis study aims to comprehensively review the state-of-the-art deep learning\nmodels in computer vision, natural language processing, time series analysis\nand pervasive computing. We highlight the key features of the models and\ntheir effectiveness in solving the problems within each domain. Furthermore,\nthis study presents the fundamentals of deep learning, various deep learning\nmodel types and prominent convolutional neural network architectures. Fi-\nnally, challenges and future directions in deep learning research are discussed\nto offer a broader perspective for future researchers.\n∗Corresponding author\nEmail addresses: halimnoor@usm.my (Mohd Halim Mohd Noor ),\nayo.ige@aaua.edu.ng (Ayokunle Olalekan Ige)\nPreprint submitted to Neurocomputing\nNovember 18, 2024\narXiv:2403.17561v5  [cs.LG]  15 Nov 2024\nKeywords:\nDeep Learning, Fundamentals, State-of-the-art Applications, Challenges\n1. Introduction\nDeep learning has revolutionized many applications across a variety of\nindustries and research. The application of deep learning can be found in\nhealthcare [1], smart manufacturing [2], robotics [3], cybersecurity [4] etc.,\nsolving challenging and complex problems such as disease diagnosis, anomaly\ndetection, object detection and malware attack detection. Deep learning is\na subset of machine learning that focuses on learning from data using artifi-\ncial neural networks with many layers, known as deep neural networks. An\nartificial neural network is a computational model that imitates the working\nprinciples of a human brain. The computational models are composed of\nan input layer which receives the input data, multiple processing layers that\nlearn the representation of data and the output layer which produces the\noutput of the model.\nPrior to the reintroduction of deep learning (DL) into the research trend,\npattern recognition tasks involved a transformation of the raw input data\nsuch as pixel values of an image into a feature vector that represents the\ninternal representation of the data. The feature vector can be used by a ma-\nchine learning model to detect or classify patterns in the data. This process\nrequires feature engineering and considerable domain knowledge to design a\nsuitable feature representation. With deep learning, this cumbersome pro-\ncess can be performed automatically whereby at each processing layer known\nas hidden layers, the internal representation of the input data is learned or\nextracted in a hierarchical manner. The first layer learns the presence of ba-\nsic primitive features such as edges, dots, lines etc. The second layer learns\npatterns or motifs by recognizing the combinations of the edges, dots and\nlines, and the subsequent layers combine the motifs to produce more sophis-\nticated features that correspond to the input data. This feature learning\nprocess takes place in the sequence of hidden layers until the prediction is\nfinally produced.\nSeveral studies have been conducted to discuss the concept and applica-\ntion of deep learning in the last few years, as listed in Table 1. The studies\naddressed or focused on several aspects of deep learning, such as types of\ndeep learning models, learning approaches and strategies, convolutional neu-\nral network (CNN) architectures, deep learning applications and challenges.\n2\nIn [5], the authors provided fundamentals of deep learning and highlighted\ndifferent types of deep learning models, such as convolutional neural net-\nworks, autoencoder and generative adversarial networks. Then, the applica-\ntions of deep learning in various domains are discussed, and some challenges\nassociated with deep learning applications are presented. Another survey [6]\nprovided a comprehensive analysis of supervised, unsupervised and reinforce-\nment learning approaches and compared the different learning strategies such\nas online, federated and transfer learning. Finally, the current challenges of\ndeep learning and future direction are discussed.\nIn [7], the authors provided a comprehensive review of the popular CNN\narchitectures used in computer vision tasks, highlighting their key features\nand advantages. Then, the applications of deep learning in medical imaging\nand the challenges are discussed. A similar survey is reported in [8], where\nthe different supervised and unsupervised deep learning models are high-\nlighted, and the popular CNN architectures are compared and discussed. In\nanother survey [9], the authors focused on the applications of deep learning\nin computer vision, natural language processing and speech and audio pro-\ncessing. The different types of deep learning models are also discussed. In\n[10], the authors focused on the different types of deep learning models and\nprovided a summary of deep learning applications in various domains.\nDespite the existing surveys on deep learning that offer valuable insights,\nthe increasing amount of deep learning applications and the existing limi-\ntations in the current studies motivated us to explore this topic in depth.\nIn general, to the best of our knowledge, no survey paper focuses on the\nemerging trends in state-of-the-art applications and the current challenges\nassociated with deep learning. Furthermore, the surveys do not discuss the\nissues and how deep learning addresses them by highlighting the key features\nand components in the models. Also, most surveys either ignore or provide\nminimal coverage of the fundamentals of deep learning, which is crucial for\nunderstanding the state-of-the-art models. The main objective of this pa-\nper is to present the most important aspects of deep learning, making it\naccessible to a wide audience and facilitating researchers and practitioners\nin advancing and leveraging its capabilities to solve complex problems across\ndiverse domains. Specifically, we present the fundamentals of deep learn-\ning and the various types of deep learning models, including popular deep\nlearning architectures.\nThen, we discuss the progress of deep learning in\nstate-of-the-art applications, highlighting the key features of the models and\ntheir problem-solving approaches. Finally, we discuss the challenges faced by\n3\nTable 1: Summary of related works.\nReferenceFocus\nConcepts not covered\n[5]\nA short review of the fundamentals\nof DL networks and discusses differ-\nent types of neural networks, DL ap-\nplications and challenges.\nLack of analysis of CNN architec-\ntures and limited coverage of deep\nlearning fundamentals.\n[6]\nDiscusses the learning approaches\n(supervised,\nunsupervised\nand\nreinforcement learnings),\nlearning\nstrategies, and DL challenges\nLack of fundamentals of deep learn-\ning, CNN architectures and DL ap-\nplications.\n[7]\nDiscusses different types of DL net-\nworks, CNN fundamentals and ar-\nchitectures, DL challenges and med-\nical imaging applications\nLimited discussion on DL applica-\ntions such as natural language pro-\ncessing and time series analysis.\n[8]\nA short review of the fundamentals\nof neural networks and discusses dif-\nferent types of DL networks, CNN\narchitectures and applications.\nLimited discussion on DL applica-\ntions and no discussion of DL chal-\nlenges.\n[9]\nDiscusses different types of DL net-\nworks and DL applications and chal-\nlenges\nLack of analysis of CNN architec-\ntures and limited coverage of deep\nlearning fundamentals.\n[10]\nDiscusses different types of DL net-\nworks and provides a summary of\nDL applications\nLack of fundamentals of deep learn-\ning, analysis of CNN architectures\nand limited discussion on DL appli-\ncations.\ndeep learning and the future research directions.\nThe remainder of this paper is organized as follows: Section 2 describes\nthe fundamentals of deep learning which includes layers and attention mech-\nanisms, activation functions, model optimization and loss functions, and reg-\nularization methods. Section 3 presents the types of deep learning models,\nincluding the CNN architectures. Section 4 discusses the state-of-the-art ap-\nplications of deep learning. Section 5 discusses the challenges and future\ndirections in the field of deep learning. The conclusion is given in Section 6.\n4\n2. Fundamentals of Deep Learning\nThis section describes the fundamental concepts such as layer types, acti-\nvation functions, training algorithms and regularization methods to provide\na comprehensive understanding of the underlying principles in advancing the\nfield of deep learning.\n2.1. Layers\nA deep learning model is characterized by having numerous hidden lay-\ners. The hidden layers are responsible for learning and extracting complex\nfeatures from the input data. A hidden layer is composed of an arbitrary\nnumber of neurons which serves as the fundamental building block of a neu-\nral network as shown in Fig. 1. A neuron consists of an arbitrary number of\ninputs, each associated with a weight, which controls the flow of information\ninto the neuron during the forward pass. The flow of information, or forward\npass, involves the computation of summation of the weighted input, followed\nby the application of a transformation function to the weighted sum. Let\nx = x1, x2, ..., xd, j = 0, 1, ..., d be the input vector with d dimensions and wl\ni\ndenotes the weights that are connected to neuron i in layer l. The forward\npass to neuron i in layer l is defined as\nzl\ni = wl\ni · x =\nd\nX\nj=0\nwl\ni,j · xj\n(1)\nal\ni = g(zl\ni)\n(2)\nwhere xj is the input vector of size d, wl\ni,j is the weight associated with\nxj, connecting the input to neuron i at layer l, and g is the transformation\nfunction also known as activation function. It is worth noting that w0 is\ncalled bias and x0 = 1. A hidden layer wherein each neuron is connected\nto all neurons of the previous layer is known as fully-connected layer. The\nforward pass computation of a neuron al\ni in layer l receiving a set of input\nfrom layer l −1 can be generalized as follows:\nal\ni = g(\nd\nX\nj=0\nwl\ni,j · al−1\nj\n) = wl\ni · al−1\n(3)\nwhere al−1 is the input vector from layer l −1.\n5\nFigure 1: A graphical representation of a neuron.\nAnother crucial layer type is the convolutional layer, which is primar-\nily used for processing data that has underlying structures, such as spatial\npatterns in image data or temporal patterns in time series data. Unlike fully-\nconnected layer, each neuron in a convolutional layer is connected only to\na subset of neurons in the previous layer as shown in Fig. 2. As shown\nin the figure, each neuron in the hidden layer is connected only to a local\nregion, a subset of nine input neurons, and the weights are shared across the\ninput data. The weight-sharing not only significantly reduces the number of\nparameters of the neural network, but also allows the network to learn the\nsame features across different spatial locations in the input [11]. Let x be\na two-dimensional input data with H × W × C such as a grayscale image,\nwhere H is the height, W is the width and C is the channel of the image\ndata. The computation of a neuron in convolutional layer l is defined as\nzl\ni,j,d =\nk1\nX\nm=0\nk2\nX\nn=0\nwl\nm,n,d · xi·s+m,j·s+n,d\n(4)\nal\ni,j,d = g(zl\ni,j,d)\n(5)\nwhere wm,n,d is the weight connecting the input data xi,j,d within the window\nto the neuron in layer l and s is the stride or the step size of the window as\nit moves across the input data. This convolution operation where the filter\nis represented by wm,n,d slides over the input data xi,j,d, producing a set of\noutput values called feature map.\n6\nFigure 2: A neuron is connected to a local region of the input data.\nPooling layers are commonly applied after successive convolutional layers\nto progressively reduce the spatial dimensions of the feature maps.\nThe\nspatial reduction is performed by computing the summary of a subset of the\nfeature values in the feature maps as shown in Fig. 3. The pooling operation,\nas shown in the figure, can use either the maximum or average method with\na pooling size of 2×2 applied across the entire feature map, thereby reducing\nthe size of the feature map. In addition to spatial reduction, pooling layers\ndecrease the number of parameters and provide translation-invariant features\n[11]. Let al denotes feature map (hidden layer) l, a pooling operation with a\npooling size of m × n is defined as\nal+1 = pool(al\ni·s+m,j·s+n)\n(6)\nwhere pool is either maximum or average function and s is the stride or step\nsize of the window as it moves across the feature map.\n2.2. Attention Mechanisms\nOne of the important concepts in pattern recognition is the ability to at-\ntend and neglect certain parts of the input data based on their importance.\nThis is because not all parts of the input hold equal importance for mak-\ning the prediction. Certain features exhibit a stronger correlation with the\noutput while others are less relevant. In convolutional layers, all extracted\nfeatures are treated uniformly, without consideration of the varying degree\n7\nFigure 3: Summaries of the feature map using maximum or average pooling to produce a\nreduced feature map.\nof the importance of the different parts of the input data. This limitation\nis addressed by the introduction of attention mechanism, which can dynam-\nically assign varying levels of significance (weights) to the different features.\nThis flexibility enables the deep learning models to prioritize the more rele-\nvant aspects of the input data, enhancing its ability to capture the intricate\ndependencies for accurate prediction. Given an input data x, the process of\nattending to the important components of the input is given as\nA = f(g(x), x)\n(7)\nwhere g is a composite function that performs a sequence of operations to\ngenerate the attention or the weights and f applies the generated attention\ng(x) on the input x.\nFor instance, the squeeze-and-excitation (SE) attention generates the at-\ntention through five consecutive operations [12]. First, the input is vectorized\nusing global average pooling. Then the vector is passed to two fully-connected\nlayers, where the first one with ReLU activation and the second one with\nsigmoid activation. SE attention was a pioneer in channel attention. The\nattention module assigns varying weights to the channels of the feature maps.\nSE attention suffers from computational cost and the use of global average\nwhich may cause information loss at the spatial level. Several efforts have\nbeen made to improve SE attention. Global Second-order Pooling (GSoP)\nattention performs 1×1 convolution on the feature maps to reduce the num-\n8\nber of channels, and then computes the pairwise channel correlation which\nis used to generate the weights [13]. Efficient Channel Attention (ECA) re-\nplaced the fully-connected layers with 1d convolution to reduce the number\nof parameters and the computational cost [14].\nTemporal attention is an attention module that focuses on specific time\nsteps in a sequence of data such time series and video (sequence of images).\nIn video processing such as recognizing human actions, temporal attention is\nused to focus on key frames at different point in time that contains crucial\ninformation for predicting the ongoing activity. Temporal adaptive module\n(TAM) is a temporal attention that can focus on short-term (local) informa-\ntion and global context information of the data [15]. The composite function\nconsists of local branch for generating attention weights and global branch\nfor generating channel-wise adaptive kernel. First, the input feature map\nis squeezed using global average pooling to reduce the computational cost.\nSubsequently, the local branch executes two 1D convolution operations, with\nthe first convolution using ReLU, and sigmoid activation for the second to\ngenerate the local weights. The local weights are then multiplied with the fea-\nturemap. Meanwhile, the global branch is composed of two fully-connected\nlayers, with the first layer using ReLU and second layer employing softmax\nfunction to generate the adaptive kernel (weights). Self-attention is a form\nof temporal attention, initially proposed for machine translation to enable\nthe deep learning models to attend different words in a sequence relative to\nother words [16]. The attention module has become a fundamental building\nblock in various natural language processing applications. To generate the\nattention weights, the input (word embeddings) is transformed by linear pro-\njection to compute query, key and value. Then, dot product between query\nand key is computed, and the resultant is normalized by the square root of\nthe size of the key. Finally, the attention weights are obtained by applying\nthe softmax function. Self-attention is the fundamental building block of\nthe Transformer architecture, a key deep learning model in natural language\nprocessing.\nSpatial attention focuses on specific regions or spatial location of the in-\nput data, enabling the deep learning models to selectively emphasize and\nignore certain features. In the context of computer vision, spatial attention\nis crucial in capturing the spatial relationships and context within an image\nfor accurate prediction. Attention gate is a spatial attention that can identify\nand focus the salient regions and suppress feature responses of the insignifi-\ncant ones. The composite function consists of ReLU activation followed by\n9\n1 × 1 convolution to reduce channel dimension of the feature maps to a sin-\ngular feature map. Finally, sigmoid is applied to the feature map to generate\nattention weights [17].\nThe self-attention in the standard Transformer is\nnot effective in handling image data due to its inherent sequential process-\ning nature and lacks the ability to capture spatial dependencies and local\npatterns. To address this limitation, the Vision Transformer (ViT) treats\nimages as a sequence of non-overlapping patches. A similar computational\npipeline is used to generate the attention weights, the sequence of patches is\ntransformed by linear projection to compute the query, key and value [18].\nThe same operations are employed to generate the attention weights. Self-\nattention is computationally costly due to its quadratic complexity especially\ndealing with image data. To reduce the complexity, two learnable linear lay-\ners, independent of the input data are adopted as the key and value vectors\n[19].\n2.3. Activation Functions\nThe role of the activation function is to transform the weighted sum into\na more classifiable form. This is crucial to the learning behaviour of the deep\nlearning model, generating non-linear relationships between the input and the\noutput of the model. The activation function, combined with many hidden\nlayers allow the neural network to approximate highly complex, non-linear\nfunctions. Many activation functions are available for use in neural networks,\nand some of the functions are shown in Fig. 4 - Fig 6. The figures show\nthe plot of the three popular activation functions. The sigmoid is a classic\nexample of activation function which is used in logistic regression. Sigmoid\nactivation function maps the weighted sum to a value in the range of 0 and 1\nwhich can be used for classification. Hyperbolic tangent is another popular\nchoice of bounded activation function which produces an output between\n-1 and 1.\nHyperbolic tangent has a stronger gradient, hence the neural\nnetwork training often converges faster than sigmoid [20]. For many years,\nsigmoid and hyperbolic tangent are the commonly used activation functions.\nNevertheless, the activation functions suffer from vanishing gradient problem,\nhindering the efficient training of deep neural networks with many layers [21].\nIt was shown that neural networks with unbounded activation functions\nhave the universal approximation property and reduce the vanishing gradi-\nent problem. Over the past years, numerous unbounded activation functions\nwere proposed for neural networks, with softplus [22] and rectified linear unit\n10\nFigure 4: Sigmoid activation function.\nFigure 5: Hyperbolic tangent activation function.\n(ReLU) [23] activation function being the notable examples. These activa-\ntion functions especially ReLU has pivotal role in improving the training\nand performance of deep learning models. ReLU has been a cornerstone of\ndeep learning models due to its computational efficiency and effectiveness\nin addressing the vanishing gradient problem. Since then, several variants\nof ReLU were proposed including Leaky ReLU [24], sigmoid linear unit [25]\nand exponential linear unit [26], each offering unique advantages for building\ndeep learning-based applications.\n2.4. Parameter Learning and Loss Functions\nThe weights (parameters) of deep learning models are often optimized\nusing an optimization algorithm called gradient descent, though other op-\ntimization algorithms may also be used. However, it has to be noted that\ngradient descent is a generic algorithm which can be used to solve a wide\n11\nFigure 6: Rectified linear unit activation function.\nrange of optimization problems. In general, gradient descent finds the opti-\nmal weights by iteratively updating the weights such that the weights will\nresult in a minimum prediction error over all instances in the training set.\nThe prediction error is quantified by a loss function. For classification prob-\nlems, the commonly used loss function is the negative log-likelihood loss or\ncross entropy loss, while the square loss and absolute loss are used for regres-\nsion problems [27]. The weights of layer l is updated as\nwl\ni,j = wl\ni,j −α∇wi,j\n(8)\nwhere α is a hyperparameter called learning rate and ∇wi,j is the gradient or\nthe derivative of the loss function J with respect to the weight\n∂J\n∂wl\ni,j .\nThe gradient can be computed across all training set instances, an ap-\nproach known as batch gradient descent. However, this approach does not\nalways guarantee convergence to the optimal solution, as it may get stuck\nin local minima or saddle points, and the same gradient is used for every\nweight update. An alternative approach is to perform the weight update on\nthe basis of a single instance, but the approach results in a noisy gradient\nand becomes computationally intensive due to the frequent weight update.\nA more commonly used approach is to perform the weight update over a set\nof training instances, known as mini-batch gradient descent. This approach\nstrikes a balance, providing a less noisy gradient and a more stable training\nprocess.\nSeveral efforts have been made to improve the efficiency of gradient de-\nscent. One of the earlier efforts is the inclusion of past rate of change in the\nweight update to speed up the training of deep learning models, the algorithm\n12\nis called gradient descent with momentum [28]. Another effort is to improve\nthe training convergence by adapting the learning rate based on the occur-\nrence of the features [29]. A more recent work utilizes both adaptive learning\nrate and momentum to improve the training efficiency and convergence of\ndeep learning models [30].\n2.5. Regularization Methods\nRegularization methods are employed to prevent overfitting in deep learn-\ning models and improve their generalization performance. Early stopping is\na method that can detect the onset of overfitting during training by contin-\nuously monitoring the validation error. The model is considered overfitting\nif the validation error starts to increase at some point of the training while\nthe training error is decreasing. However, detecting the onset of overfitting\nduring the training of deep learning models is challenging due to the inherent\nstochasticity and the presence of noisy data. Several stopping criteria can\nbe considered such as using a threshold to check if the decrease of (average)\nvalidation error is significant and count the number of successive increases of\nvalidation error [31].\nDropout is a regularization method that randomly switching off some\nneurons in the hidden layers during training with a predefined drop proba-\nbility (dropout rate) [32]. Dropout has the effect of training and evaluating\nexponentially many different deep learning models. The dropout rate is a\nhyperparameter that needs to be carefully tuned to balance regularization\nand model capacity. Different ranges of dropout rate have been suggested.\nThe original author suggested a dropout rate between 0.5 and 0.8 [32] while\nothers recommended a lower dropout rate between 0.1 and 0.3 [33]. Also, it\nhas been suggested a low dropout rate due to the exponential increase in the\nvolume of training data [34].\nParameter norm penalty is a regularization method that adds a penalty\nterm consisting of the network’s weights to the loss function. During the\ntraining, the penalty term discourages large weight values and hence, con-\nstraining the model’s capacity and reducing the chance of overfitting. The\ncommon penalty terms are L1 norm penalty [35], L2 norm penalty, also known\nas weight decay and a combination of L1 and L2 [36]. An adaptive weight\ndecay is proposed allowing the regularization strength for each weight to be\ndynamically adjusted [37].\nDespite the advantages of the mini-batch gradient descent, each mini-\nbatch may comprise data from different distributions. Furthermore, the data\n13\ndistribution may change after each weight update, which could slow down\nthe training process. Batch normalization overcomes this issue by normal-\nizing the summed input to a neuron over a mini batch of training instances\n[38]. An alternative method is to perform normalization across the neurons\ninstead of the mini batch, a method known as layer normalization [39]. Layer\nnormalization is applicable in recurrent neural network and overcomes the\ndependencies on the mini batch size.\n3. Types of Deep Learning\nDeep learning models can be categorized into deep supervised learning\nand deep unsupervised learning.\n3.1. Deep Supervised Learning\nDeep supervised models are trained with a labelled dataset. The learning\nprocess of these models involve calculating the prediction error through a\nloss function and utilizing the error to adjust the weights iteratively until\nthe prediction error is minimized. Among the deep supervised models, three\nimportant models are identified namely multilayer perceptron, convolutional\nneural network and recurrent neural network.\nMultilayer perceptron is a neural network model with one or more\nhidden fully-connected layers stacked between the input and output layers as\nshown in Fig. 7. The width (number of neurons) of the hidden layers and the\ndepth (number of layers) of the network influence the model’s ability to learn\npatterns in the data. Specifically, the width affects the network’s ability to\ncapture a broader range of features while the depth facilitates the learning of\nhierarchical representations. Nevertheless, studies showed that a multilayer\nperceptron with a single hidden layer can approximate any continuous func-\ntion [40], [41]. Multilayer perceptron is effective in various industries and\napplications from healthcare to finance [42]. However, multilayer perceptron\nrequires the input data to be structured in a one-dimensional format e.g.\ntabular data, making it less suitable for unstructured data such as image,\ntext and speech. To leverage multilayer perceptron for unstructured data, a\nfeature extraction or transformation into structured data is necessary.\nRecurrent Neural Network (RNN) is a neural network model that\nleverages the sequential information and memory through the use of recur-\nrent connections, allowing it to effectively process data such as time series,\ntext, speech and other sequential patterns. As shown in Fig. 8, a recurrent\n14\nFigure 7: A fully-connected neural network.\nneural network is characterized by the recurrent connection which enables\nthe network to loop back and use internal state from the previous time step\nto the next time step. The internal state is parameterized by a set of weights\nshared across the sequence of data. The training of recurrent neural net-\nworks suffers from the issue of vanishing gradient due to the challenges of\npropagation of gradients over a long sequence of data. Variants of recurrent\nneural networks are introduced to overcome the problem of vanishing gradient\nsuch as long short-term memory (LSTM) [43] and gated recurrent memory\n(GRU) [44]. The improved recurrent neural networks introduce memory cell\nand gating mechanisms to retain and discard information in every time step,\nallowing for more effective learning dependencies in long sequence. The net-\nwork architecture can be built using fully-connected and convolutional layers\n[45].\nConvolutional Neural Network (CNN) is a neural network model that\npreserves and leverages the spatial local information in the data through the\nuse of convolutional layers. Fig. 9 shows a typical architecture of convolu-\ntional neural network which comprises of convolutional, pooling and fully-\nconnected layers. The convolutional and pooling layers are stacked alter-\nnately to automatically extract salient features in a hierarchical manner.\nThe extracted features are then fed to fully-connected layers to predict the\noutputs. The final feature maps need to be converted to one-dimensional\nvector before they are fed to the fully-connected layers. The conversion can\nbe performed by flattening the feature maps. CNN architecture is crucial in\nincreasing the performance of the prediction, as it is designed to efficiently\n15\nFigure 8: A neural network with recurrent connection.\nextract the feature representation of the input data, enabling more accurate\nand robust pattern recognition. Over the last decade, several CNN architec-\ntures have been proposed, whereby the focus of the improvements has been\non enhancing the feature learning capabilities and addressing challenges such\nas vanishing gradient and diminishing feature reuse.\nFigure 9:\nA neural network with convolutional and pooling layers followed by fully-\nconnected layers.\nAlexNet is among the first CNN models that gained widespread recog-\nnition and success, marking a significant achievement in the field of deep\nlearning for computer vision tasks [46]. The model consists of five convolu-\ntional layers with max-pooling operation performed after the first and second\nconvolutional layers, followed by three fully-connected layers. The first and\nsecond convolutional layers utilize a filter size of 11×11 and 5×5 respectively,\nand 3 × 3 filter size is used for the remaining convolutional layers. ReLU ac-\ntivation function is used to mitigate the vanishing gradient.\nVGG-16 attempts to improve the CNN architecture by adding more con-\nvolutional layers, specifically up to 19 layers to capture more intricate fea-\n16\nture representation from input data, followed by three fully-connected layers\n[47]. ReLU activation function is used to reduce vanishing gradient. Unlike\nAlexNet, all convolutional layers utilize a small fix filter size of 3 × 3 and\nmax-pooling layer is added after a stack of two or three convolutional layers.\nThis configuration allows the model to extract more discriminative features\nand decreases the number of parameters.\nZFNet is a classic CNN model which has a similar architectural principle\nas AlexNet, featuring five convolutional layers with max-pooling layers after\nthe first and second convolution, followed by three fully-connected layers\n[48]. The significant differences are the use of smaller filter size and stride\nin the convolutional layers and contrast normalization of the feature maps\nwhich allows the model to capture better features and improving the overall\nperformance.\nNetwork-in-network introduces two innovative concepts to enhance the\nperformance of the model [49]. The first was introducing a block of convolu-\ntional layers consisting of k×k convolution followed by two 1× 1 convolution\noperations. The pointwise convolutions are similar to applying multilayer\nperceptron on the feature maps, allowing the model to approximate more\nabstract feature representation. In the preceding models, the final feature\nmaps are vectorized by flattening operation for classification by the fully-\nconnected layers. Instead of flattening, network-in-network model calculates\nthe spatial average of each feature map, and the resulting vector is fed to soft-\nmax function for classification. This approach is parameter-less, significantly\nreducing the number of parameters.\nGoogleNet leverages the fact that visual data can be represented at differ-\nent scales by incorporating a module which consists of multiple convolutional\npipelines with different filter sizes [50]. The module known as inception uti-\nlizes three kernel sizes (5 × 5, 3 × 3, 1 × 1) to capture spatial and channel\ninformation at different scales of resolution as shown in Fig. 10. This config-\nuration enables a more effective feature extraction at both fine-grained and\ncoarse-grained information from input data. The model architecture utilizes\nthe inception module at the higher layers while the traditional convolution\nand max-pooling block is used to extract primitive and basic features. The\ninception modules are stacked upon each other with maximum pooling oper-\nation is performed occasionally to reduce the spatial resolution of the feature\nmaps. GoogleNet utilizes global average pooling to vectorize the final feature\nmaps before passing it to a fully-connected layer for classification.\nIncreasing the number of layers enhances the model performance, mainly\n17\nFigure 10: The inception module.\nfor solving complex tasks. However, training a very deep neural network\nis challenging due to the vanishing gradient problem, where the gradients\nthat are used to update the network become insignificant or extremely small\nas they are backpropagated from the output layer to the earlier layers. A\nmodel called Highway Network overcomes this issue by introducing a gating\nmechanism that regulates the information flow of the layers, enabling the flow\nof information from the earlier layers to the later layers [51]. Consequently,\nthis not only mitigates the vanishing gradient problem, but also renders the\ngradient-based training more tractable, enabling the training of very deep\nneural networks consisting as many as 100 layers.\nThe gating mechanism of Highway Network increases the number of pa-\nrameters for regulating the information flow. ResNet is a CNN architecture\nthat incorporates residual (skip) connection that allows information to by-\npass certain layers, mitigating the vanishing gradient problem [52]. ResNet\narchitecture stacks residual blocks, which consists of two or three of convo-\nlutional layers with batch normalization and ReLU, and a skip connection\nwhich adds the input to the output of the final convolutional layer as shown\nin Fig. 11. If the input dimension does not match with the residual output\ndimension, a linear projection is performed by the residual connection to\nmatch the dimensions. In comparison to the gating mechanism of Highway\nNetwork, the residual connection is parameter-free, and thus does not in-\ncur additional computational costs. Furthermore, the connections are never\nclosed whereby all information is always passed through the layers. This in-\nnovative concept enables the training of very deep neural networks boasting\nas many as 152 layers.\nDenseNet is another CNN architecture that overcomes the vanishing gra-\n18\nFigure 11: A residual connection.\ndient problem. DenseNet follows the same approach as ResNet and Highway\nNetwork, utilizing skip connection to allow information flow from the earlier\nlayers to later layers. However, DenseNet takes this concept one step further,\nby introducing a dense block consisting of multiple convolution functions (lay-\ners) with each convolution function performs batch normalization followed\nby ReLU and 3 × 3 convolution. Each convolutional layer in the dense block\nreceives feature maps from all its preceding layers, hence the connection is\nreferred to as dense connection [53]. This configuration as shown in Fig.\n12 maximizes information flow and preserves the feed-forward nature of the\nnetwork. Dense blocks can become computationally expensive due to the\nincreasing number of feature maps. To reduce the computational costs, a\nblock of 1 × 1 convolutional with batch normalization and max-pooling lay-\ners known as transition block is used to reduce the spatial dimension of the\nfeature maps. The model architecture integrates these dense and transition\nblocks, stacking them alternately. The network depth can reach up to 264\nlayers.\nFigure 12: A dense block.\nAlthough skip connections in ResNet effectively mitigate the vanishing\ngradient problem, a new challenge arises in the form of diminishing feature\n19\nreuse as the network becomes deeper. Diminishing feature reuse refers to\nthe diminishing effectiveness of the previously learned feature maps in sub-\nsequent layers, impacting the final prediction. WideResNet is a CNN archi-\ntecture that is based on ResNet with the aim to mitigate diminishing feature\nreuse problem. Instead of making the network deeper, WideResNet makes\nthe network wider by increasing the number of channels by k factor [54].\nThe increased width allows the model to capture a more diverse features,\nenhancing its ability to learn complex relationships in the input data.\nResNext addresses the diminishing feature reuse by capturing more effi-\ncient and diverse features of the input data. ResNext introduces a concept\nof cardinality which is loosely based on the inception module as shown in\nFig. 13. The cardinality refers to the number of independent and identical\npaths, where each path performs transformation of the input data, divided\nalong the channel dimension [55]. In other words, instead of solely relying on\nincreasing the depth of the model, ResNext enhances the feature learning by\nparallelizing the feature extraction through this cardinal path. In the pro-\nposed architecture, each path configuration is similar to the residual block of\nResNet. The output from each path is then aggregated to form a comprehen-\nsive and diverse representation of the input data. The skip connection is used\nto mitigate the vanishing gradient problem. WideResNet is a CNN architec-\nture that is based on ResNet with the aim to mitigate diminishing feature\nreuse problem. Instead of making the network deeper, WideResNet makes\nthe network wider by increasing the number of channels by k factor [54].\nThe increased width allows the model to capture a more diverse features,\nenhancing its ability to learn complex relationships in the input data.\nFigure 13: A cardinal block.\n20\n3.2. Deep Unsupervised Learning\nDeep unsupervised models are trained with an unlabelled dataset. The\nlearning process of these models discovering patterns, structures and repre-\nsentations within the data without relying on explicit labels or supervision.\nInstead, these models often learn by optimizing objective functions that cap-\nture the underlying data characteristics such as clustering, learning useful\nfeature embeddings and reconstructing input data from compressed represen-\ntations. Examples of deep unsupervised models are autoencoders, generative\nadversarial networks and restricted Boltzmann machines.\nRestricted Boltzmann Machine is a generative neural network model that\nlearns a probability distribution based on a set of inputs. The model consists\nof a visible (input) layer and a hidden layer with symmetrically weighted\nconnections as shown in Fig. 14. The input layer represents the input data\nwith each node corresponding to a feature or variable while the hidden layer\nlearns the abstract representation of the input data. Restricted Boltzmann\nmachine model is trained using contrastive divergence, an algorithm that\nis based on a modified form of gradient descent, utilizing a sampling-based\napproach to estimate the gradient [56]. It has found success in solving combi-\nnative problems such as dimensionality reduction, collaborative filtering and\ntopic modelling.\nFigure 14: A restricted Boltzmann machine.\nDeep Belief Network can be viewed as a stack of restricted Boltzmann\n21\nmachines, comprising a visible layer and multiple hidden layers [57] as shown\nin Fig. 15. Deep belief network has two training phases. The initial phase\nis known as pretraining in which the network is trained layer by layer, with\neach layer serves as a pretraining layer of the subsequent layers. This se-\nquential learning allows the hidden layers learn complex hierarchical feature\nrepresentation of the data. The second phase is called fine-tuning whereby\nthe deep belief network model can be further trained with supervision to\nperform tasks such as classification and regression [58].\nFigure 15: A deep belief network.\nAutoencoder is a generative neural network model that learns to encode\nthe input data into a compressed representation and then reconstructs the\noriginal data from this representation. The layers that encode the input data\nis known as encoder while the layers that responsible for the reconstruction\nis referred to as the decoder as shown in Fig. 16. The encoded data (hid-\nden layer) represents the abstract features of the input data also known as\nlatent space or encoding. The decoder can be removed from the autoen-\ncoder, creating a standalone model that can be used for data compression\nand dimensionality reduction [59], [60]. The decoder can also be replaced\nwith predictive layers for classification task [61]. The network architecture\ncan be built using fully-connected and convolutional layers [62].\nSeveral autoencoder variants have been introduced to improve the au-\ntoencoder’s ability to capture better feature representation. Some introduced\npenalty terms to the loss function such as sparsity penalty (sparse autoen-\ncoder) [63] to encourage sparse representation and Jacobian Frobenius norm\n(contractive autoencoder) [64] to be less sensitive to small and insignificant\n22\nFigure 16: An autoencoder.\nvariations in the input data while encoding the feature representation. Oth-\ners trained the autoencoder to recover original data from corrupted data\nwith noise [65]. An improved denoising autoencoder knowns marginalized\ndenoising autoencoder has been proposed which marginalizes the noise by\nadding a term that is linked to the encoding layer [66]. Variational autoen-\ncoder is a variant of autoencoder that has similar architecture i.e. encoder,\nlatent space and decoder. Despite the similarity, instead of learning a fixed\nencoding, variational autoencoder learns the probability distribution of the\ninput data in the latent space [67]. The model can be used to generate data\nby sampling from the learned probability distribution. The network archi-\ntecture can be built by stacking more than one fully-connected layer and\nconvolutional layer.\nGenerative Adversarial Network (GAN) is another generative neural net-\nwork model that is designed for generating data that adheres closely to the\ndistribution of the original training set. The model consists of two different\nneural networks namely generator and discriminator as shown in Fig. 17.\nThe generator learns to imitate the distribution of the training set given a\nnoise vector, effectively outsmarting the discriminator. Simultaneously dur-\ning the training, the discriminator is trained to differentiate between the real\ndata from the training set and synthetic data generated by the generator [68].\nThis intricate dynamic between the networks drives an iterative learning pro-\ncess whereby the generator continually refines its ability to create synthetic\ndata that closely resembles the real data while the discriminator enhances\nits ability to distinguish between authentic and fake data.\nThe model can be extended by providing the labels to both generator\n23\nFigure 17: A generative adversarial network.\nand discriminator in which the model known as conditional GAN, capable\nof generating 1000 image classes [69]. Conditional GANs require a labelled\ndataset which might limit its application. InfoGAN is similar to conditional\nGAN, but the labels are substituted with latent codes, which allows the\nmodel to be trained in an unsupervised manner [70]. GANs often suffer from\nmode collapse whereby the model can only generate a single or small set of\noutputs. Wasserstein GAN improves the training by utilizing Wasserstein\nloss function which measures the difference between the real and synthesized\ndata distribution [71]. ProGAN tackles the training instability of GAN by\nprogressively growing the generator and discriminator. The idea is that the\nmodel is scaled up gradually, starting with the simplest form of the problem\nand little by little the problem’s complexity is increased as the training pro-\ngresses [72]. StyleGAN leverages the progressive GAN’s approach and neural\nstyle transfer to improve quality of the generated data [73]. The model is\ncharacterized by the independent manipulation of both style and content,\nallowing it to generate diverse styles and high quality data.\n24\n4. Applications of Deep Learning\nAs discussed in the previous section, the application of deep learning\nranges from computer vision [74], natural language processing [75], healthcare\n[76], robotics [77], education [78], and many others. This section presents the\napplications of deep learning across several areas.\n4.1. Computer Vision\nComputer vision is an essential field in artificial intelligence. It is a field\nof study that focuses on enabling computers to acquire, analyze and inter-\npret visual inputs to derive meaningful information. The visual inputs can\ntake many forms such as digital images, sequence of images or video and\npoint cloud, and the source of these inputs can be camera, LiDaR, medical\nscanning machine etc. Deep learning, specifically CNN models have been\nwidely used in real-world computer vision applications including image clas-\nsification, object detection and image segmentation. This section discusses\nmore details about the recent advancements in deep learning models that\nhave been achieved over the past few years.\n4.1.1. Image Classification\nImage classification is a fundamental task in computer vision which in-\nvolves categorizing an image into one of predefined classes based on the visual\ncontent. The objective of image classification is to enable computers or ma-\nchines to differentiate between objects within images, in a manner similar\nto how humans interpret visual information. Image classification is a cru-\ncial component in various applications such as robotics, manufacturing and\nhealthcare. LeNet-5, introduced in 1998, is one of the earliest convolutional\nneural networks that was successfully trained to classify handwritten digits.\nThe model underwent a series of improvements, including the use of tanh and\naverage pooling which enhanced its ability to extract hierarchical features,\nultimately improving overall performance. The model architecture comprises\ntwo convolutional layers, each with an average pooling layer, followed by two\nfully-connected layers, including the output layer [79]. Since then, numerous\nCNN models have been proposed based on LeNet-5 for image classification\n[80, 81] but the most significant one is AlexNet in 2012 which saw a transfor-\nmative breakthrough in deep learning. AlexNet is considered the first CNN\nmodel with a large number of parameters that significantly improved the\nperformance of image classification on a very large dataset (ImageNet). The\n25\nmodel won first place in ILSVRC 2012, improving the test error from the pre-\nvious year by almost 10% [46]. Numerous significant CNN models have been\nintroduced in subsequent ILSVRC competitions including ZFNet, VGG16,\nGoogleNet, ResNet and ResNext. In general, the research focused on in-\ncreasing the number of layers, addressing the problem of vanishing gradient\nand diminishing of feature reuse.\nResearch in image classification continues to evolve with a focus on ad-\ndressing key challenges to improve the classification performance. One no-\ntable trend is the formulation of the loss function to address problems such as\nneglecting well-classified instances and imbalance distribution of class labels.\nIn a particular study, an additive term is introduced to the cross-entropy loss\nto reward the models for the correctly classified instances. This formulation\nencourages the models to also pay attention to well-classified instances while\nfocusing on the bad-classified ones [82]. Another study proposes an asym-\nmetric polynomial loss function using the Taylor series expansion. The loss\nfunction allows the training to selectively prioritize contributions of positive\ninstances to mitigate the issue of imbalance between negative and positive\nclasses [83]. The asymmetric polynomial loss requires a large number of pa-\nrameters to be fine-tuned and may lead to overfitting. A robust asymmetric\nloss is formulated by introducing a multiplicative term to control the con-\ntribution of the negative gradient and making it less sensitive to parameter\noptimization [84]. Combining multiple deep learning models improves the\noverall performance by leveraging the diverse strengths of individual models.\nHowever, identifying the optimal combination is non-trivial due to the large\nnumber of hyperparameters.\nA straightforward method is to employ the\nweighted sum rule [85]. To enhance the overall performance, an algorithm,\nnamed greedy soups, adds a model based on the validation accuracy [86].\nThe final prediction is produced via averaging. Multi-symmetry ensembles\nframework improves the building of diverse deep learning models by utilizing\ncontrastive learning [87]. Then, the diverse models are sequentially combined\nbased on their validation accuracy.\nVision transformers (ViT) offers an alternative to convolutional neural\nnetworks that have long been the dominant architecture for image classifica-\ntion, by leveraging self-attention mechanisms for scalable global representa-\ntion learning. Despite its effectiveness, ViT is sensitive to hyperparameter\noptimization and substandard performance on smaller datasets [88]. Further-\nmore, ViT lacks the ability to leverage local spatial features which is inherent\nin convolutional neural networks [89]. Therefore, several studies attempt to\n26\nincorporate convolutional layers into ViT architecture to improve its perfor-\nmance and robustness. In particular, conformer is a network architecture\nwith two branches: CNN branch and a transformer branch to extract local\nand global features respectively [90]. Both branches are connected by two\n“bridges” of 1×1 convolution and up or down sampling operations, allowing\nthe branches to share their features and enhance the feature representation.\nBoth branches output predictions which are combined to produce the final\nprediction. A hybrid architecture, named MaxViT, combines convolutional\nnetworks and vision transformer to address the lack of scalability issues of\nself-attention mechanisms when the model is trained on large input size [91].\nThe improved vision transformer is composed of two modules whereby the\nfirst module attends local features in non-overlapping image patches and the\nglobal features are attended by processing a grid of sparse and uniform pix-\nels. The transformer is stacked with a block of convolutional layers to extract\nlocal spatial features. The architecture of MaxViT is shown in Figure 18.\nAnother study proposes a convolutional transformer network, introducing the\ndepthwise convolutional block into the ViT [92]. This configuration allows\nthe model to exploit the ability of convolutional networks to extract local spa-\ntial features while the ViT attends the extracted local features to focus on\nrelevant information, enhancing the model’s ability to capture complex pat-\nterns and relationships. Specifically, instead of linear mapping, depth-wise\nconvolutional mapping is used to generate query, key and value matrices.\nFigure 18: The architecture of MaxViT [91].\n4.1.2. Object Detection\nDeep learning plays a major role in significantly advancing the state-of-\nthe-art in object detection performance. Region-based CNN (R-CNN) is the\nfirst breakthrough in object detection that combines CNN with selective re-\ngion proposals [93]. The region proposals are the candidate bounding boxes\n27\nserving as the potential region of interests (objects) within the input image,\nand the CNN are used to extract features from the region proposals and clas-\nsify the regions for object detection. An improved model, named Fast R-CNN\nintroduces two prediction branches: object classification and bounding box\nregression which improves the overall performance of object detection [94].\nHowever, R-CNN and Fast R-CNN models are computationally expensive\nand slow, thus practically infeasible for real-time applications. Addressing\nthis issue, Fast R-CNN is integrated with a region proposal network, referred\nto as Faster R-CNN [95]. The region proposal network (RPN) is used to ef-\nficiently generate region proposals for object detection. RPN takes an input\nimage and output a set of rectangle object proposals, each with a confidence\nscore to indicate the likelihood of an object’s presence. To this end, RPN\nintroduces the concept of anchor boxes whereby multiple bounding boxes of\ndifferent aspect ratios are defined over the feature maps produced by the\nconvolutional networks. These anchor boxes are then regressed over the fea-\nture maps to localize the objects, contributing to the improved speed and\neffectiveness of Faster R-CNN. The training of Faster R-CNN is divided into\ntwo stages. First the RPN is pre-trained to generate the region proposals and\nthen, the Fast R-CNN is trained using the region proposals generated by the\nRPN for object detection. The backbone network responsible for extracting\nthe features for Faster R-CNN is either ZFNet or VGG16.\nIn two-stage object detectors, the region proposals are generated first,\nand then used for object detection. The two-stage process is computation-\nally intensive and infeasible for real-time object detection applications. You\nOnly Look Once or YOLO proposes a one-stage detection by directly pre-\ndicting bounding boxes and object’s confidence score in a single forward pass\nthrough the neural network [96]. This single pass architecture significantly\nreduces the computational complexity, making YOLO suitable for real-time\nobject detection applications.\nIn YOLO, the input image is divided into\nS×S grids, each grid cell is responsible for detecting the objects present in\nthe cell. Specifically, each grid cell predicts multiple bounding boxes and\nassociated object’s confidence score, enabling simultaneous object detection\nacross the entire image. Subsequent enhancements such as YOLOv3 [97] and\nYOLOv4 [98] are proposed, improving the model’s capability and accuracy.\nSingle Shot Multibox Detector (SSD) is another one-stage detector, aims to\naddress the issue of real-time object detection [99]. SSD also eliminates the\nregion proposal generation and directly predicts bounding boxes and confi-\ndence scores, reducing the computational complexity. To improve the overall\n28\nperformance, SSD produces the predictions from different levels of feature\nmaps, allowing detection of objects of different sizes in the input image.\nA common issue in object detection problems is the extremely imbalanced\nratio of foreground to background classes. Addressing this issue, RetinaNet\nintroduces a loss function that is based on the cross entropy called focal loss.\nFocal loss reduces the loss contribution of easily classified objects, allowing\nthe model training to focus on the difficult objects [100]. RetinaNet adopts\nthe Feature Pyramid Network (FPN) [101] with ResNet as the backbone net-\nwork for extracting the feature maps. FPN is a network architecture with\na pyramid structure that efficiently captures multiscale feature representa-\ntion, facilitating object detection across various sizes. To further improve\nthe overall performance, EfficientDet introduces bi-directional FPN which\nincorporates multi-level feature fusion to better capture multiscale feature\nrepresentation [102]. Also, the model utilizes EfficientNet [103] as the back-\nbone network to achieve a balance between computational efficiency and\naccuracy.\nObject detection performance often relies on a post-processing step called\nnon-maximum suppression (NMS) to eliminate duplicate detections and se-\nlect the most relevant bounding boxes. Specifically, NMS sorts all detection\nboxes based on their confidence scores, selects a box with the maximum score\nand discards the other boxes with a significant overlap with the selected box.\nThis process is repeated on the remaining detection boxes. However, due\nto the inconsistency between the confidence score and the quality of object\nlocalization, NMS retains poorly localized bounding boxes with high confi-\ndence score while discarding more accurate predictions with poor confidence\nscore. To mitigate this limitation, instead of discarding the neighboring boxes\nwith significant overlap, soft-NMS applies Gaussian function to lower their\nconfidence scores [104]. The idea is not to discard the neighboring bounding\nboxes, but gradually decline their scores based on the extend of the overlap\nwith the selected box. This results in a smoother suppression, preserving\nthe better-localized bounding boxes. Adaptive NMS introduces an adaptive\nthreshold for the suppression of bounding boxes [105]. The algorithm dynam-\nically adjusts the threshold based on the level of overlapping of the selected\nbox with the other bounding boxes.\nDetection Transformer (DeTR) is an end-to-end trainable object detec-\ntion model that leverages the transformer architecture to eliminates the need\nfor handcrafted components such as anchor boxes and non-maximum sup-\npression [106]. The self-attention mechanism of the transformer captures the\n29\nglobal context and relationships between different parts of the image, allow-\ning it to localize the objects and remove duplicate predictions. The model is\ntrained with a set of loss functions that perform bipartite matching between\nthe predicted and ground truth objects. DeTR uses ResNet as backbone\nnetwork. Despite the success of DeTR in simplifying and improving object\ndetection tasks, DeTR suffers from a long training time and low performance\nat detecting small objects due to its reliance on self-attention mechanism of\nthe transformer, which lacks a multiscale feature representation. To mitigate\nthis limitation, Deformable DeTR introduces a multiscale deformable atten-\ntion module which can effectively capture feature representation at different\nscales [107]. Furthermore, the attention module leverages deformable con-\nvolution, allowing the model to adapt to spatial variation and capture more\ninformative features in the input data. Dynamic DeTR addresses the same\nissues by utilizing a deformable convolution-based FPN to learn multiscale\nfeature representation [108]. Moreover, the model replaces the transformer\nencoder with a convolution-based encoder to attend to various spatial fea-\ntures and channels. This modification allows the model to effectively detect\nsmall objects and converge faster during training. The architecture of dy-\nnamic DeTR is shown in Figure 19. A training scheme known as Teach-DeTR\nis proposed to improve the overall performance of DeTR [109]. The train-\ning scheme leverages the predicted bounding boxes by other object detection\nmodels during the training by calculating the loss of one-to-one matching\nbetween the object queries and the predicted boxes.\nFigure 19: The architecture of dynamic DeTR [108].\n30\n4.1.3. Image Segmentation\nImage segmentation is another important task in which deep learning\nhas a significant impact. One of the earliest deep learning models for image\nsegmentation is the fully convolutional network [110]. A fully convolutional\nnetwork consists of only convolutional layers which accepts an input of an\narbitrary size and produce the predicted segmentation map of the same size.\nThe authors adopt the AlexNet, VGG16 and GoogleNet, replace their fully\nconnected layers with convolutional layers and append a 1×1 convolutional\nlayer, followed by bilinear up-sampling to match the size of the input. The\nmodel was considered a significant milestone in image segmentation, demon-\nstrating the feasibility of deep learning for semantic segmentation trained in\nend-to-end manner. Deconvolution network is another popular deep learning\nmodel for semantic segmentation [111]. The model architecture consists of\ntwo parts: encoder and decoder. The encoder takes an input image and uses\nthe convolutional layers to generate the feature maps.\nThe feature maps\nare fed to the decoder composed of un-sampling and deconvolutional layers\nto predict the segmentation map. SegNet is another encoder-decoder model\nfor semantic segmentation [112]. The encoder is a sequence of convolutional\n(with ReLU) and max-pooling blocks which is analogous to a convolutional\nneural network. The decoder is composed of up-sampling layers which up-\nsamples the inputs using the memorized pooled indices generated in the\nencoder phase, and convolutional layers without non-linearity. The encoder\nprogressively reduces the resolution of the input data while extracting ab-\nstract features through a series of convolutional and pooling layers. This\nprocess causes the loss of fine-grained information, degrading the overall per-\nformance of segmentation. LinkNet mitigates this limitation by passing the\nfeature maps at several stages generated by the encoder to the decoder, hence\nreducing information loss [113]. The model architecture of LinkNet is similar\nto SegNet, but utilizes ResNet as the encoder.\nWhile Faster R-CNN is a significant approach in object detection task,\nit has been extended to perform instance segmentation task. One such ex-\ntension is Mask R-CNN which is based on Faster R-CNN, introduces an\nadditional branch for predicting the segmentation mask [114].\nSimilar to\nFaster R-CNN, Mask R-CNN utilizes the RPN to generate region proposals\nand then the region of interest alignment is applied to extract more accurate\nfeatures from the proposed regions. Mask R-CNN does not leverage the mul-\ntiscale feature representation which may degrade the overall performance\n31\nof segmentation. To overcome this limitation, Path Aggregation Network\n(PANet) incorporates the FPN and introduces a bottom-up pathway to fa-\ncilitate the propagation of the low-level information [115]. The pathway takes\nthe feature maps of the previous stage as input and performs 3×3 convolution\nwith stride 2 to reduce the spatial size of the feature maps. The generated\nfeature maps are then fused with the feature maps from the FPN through\nthe lateral connection. The model adopts the three branches as in Mask R-\nCNN. MaskLab is an instance segmentation model based on Faster R-CNN,\nconsisting of object detection, segmentation and instance (object) center di-\nrection prediction branches [116]. The direction prediction provides useful\ninformation to distinguish instances of the same semantic label, allowing the\nmodel to further refine the instance segmentation results.\nAttention mechanisms have been integrated into the segmentation models\nto learn the weights of multiscale features at each pixel location. A multi-\nstage context refinement network introduces a context attention refinement\nmodule that is composed of two parts, context feature extraction and context\nfeature refinement [117]. The context feature extraction captures both local\nand global context information, fuses both contextual information and passes\nit to the context feature refinement while the context feature refinement re-\nmoves redundant information and generates a refined feature representation,\nimproving the utilization of contextual information. The context attention\nis added to the skip connection between the encoder and the decoder. Hand-\ncrafted features are often abandoned for automatic feature extraction using\nconvolutional networks. However, it is argued that the interpretability and\ndomain-specific knowledge embedded in handcrafted features can provide\nvaluable insights. To this end, an attention module based on the covariance\nstatistic is introduced to model the dependencies between local and global\ncontext of the input image [118]. Two types of attention are introduced:\nspatial covariance attention focuses on the spatial distribution and channel\ncovariance attention attends to the important channels. Furthermore, the\ncovariance attention does not require feature shape conversion, hence signif-\nicantly reducing the space and time complexity of the model.\nThe convolutional layers use local receptive fields to process input data\nwhich can be effective for exploiting spatial patterns and hierarchical fea-\ntures but may find it difficult to capture global relationships across the en-\ntire image. The ViT has been leveraged to mitigate this issue in semantic\nsegmentation [119]. Specifically, the input image is divided into patches and\ntreated as input to the transformer to capture the global relationship between\n32\nthe patches, significantly improving the prediction of the segmentation map.\nGlobal context ViT aims to address the lack of ViT’s ability to leverage local\nspatial features [120]. As shown in Figure 20, the transformer consists of\nlocal and global self-attention modules. The role of global self-attention is to\ncapture the global contextual information from different image regions while\nthe short-range information is captured by the local self-attention. Multi-\nscale feature representation is crucial for accurate semantic segmentation.\nHowever, the transformer often combines the features without considering\ntheir appropriate (optimal) scales, thus affecting the segmentation accuracy.\nTransformer scale gate is a module proposed to address the issue of select-\ning an appropriate scale based on the correlation between patch-query pairs\n[121]. The transformer takes attention (correlation) maps as input and cal-\nculates the weights of the multi-scale features for each image patch, allowing\nthe model to adaptively choose the optimal scale for each patch.\nFigure 20: The architecture of global context ViT [120].\n4.1.4. Image Generation\nImage generation refers to the process of creating images based on input\ntexts. Generally, the task can be divided into three stages. The first stage\nis extracting features from the input text, followed by generating the image\nand finally controlling the image generation process to ensure the output\nmeets specific criteria and constraints. This section focuses on the progress\nmade in the development of deep learning models of the second stage (im-\nage generation) since it directly impacts the quality of the generated images.\nVariational autoencoder is one of the earliest deep learning models that is\ncapable of generating images [67]. Variational autoencoder learns to gener-\nate data by capturing the underlying (Gaussian) distribution of the training\ndata. During the generation process, the distribution parameters are sam-\npled and passed to the decoder to generate the output image. Although the\ngenerated images are blurry and unsatisfactory, it has shown a lot of potential\nin image generation tasks. The introduction of GAN significantly improved\n33\nthe quality of generated images. GAN consists of two connected neural net-\nworks, a generator and a discriminator that are trained simultaneously in a\ncompetitive manner [68]. The generator learns to generate realistic images to\nfool the discriminator, while the discriminator learns to distinguish between\nfake and real images. The generated images are less blurry and more real-\nistic. Several enhanced models have been proposed to improve its usability\nand overall performance such as CGAN [69] which allows us to tell what im-\nage to be generated, and the deep convolutional GAN (DCGAN) [122] which\nprovides a more stable structure for image generation. DCGAN is the basis\nof many subsequent improvements in GANs.\nStackGAN divides the process of image generation into two stages [123].\nStage-I generates a low-resolution image by creating basic shapes and colors\nand the background layout using the random noise vector. Stage-II com-\npletes the details of the image and produces a high-resolution photo-realistic\nimage. StackGAN++ is the enhanced model of StackGAN whereby it con-\nsists of multiple generators with shared parameters to generate multiscale\nimages [124]. The generators have a progressive goal with the intermediate\ngenerators generating images of varying sizes and the deepest generator pro-\nducing the photo-realistic image. HDGAN is a generative model featuring a\nsingle-stream generator with hierarchically nested discriminators at interme-\ndiate layers [125]. These layers, each connected to a discriminator, generate\nmultiscale images. The lower resolution outputs are used to learn semantic\nimage structures while the higher resolution outputs are used to learn fine-\ngrained details of the image. StackGAN heavily relies on the quality of the\ngenerated image in Stage-I. DM-GAN incorporates a memory network for\nimage refinement to cope with badly generated images in Stage-I [126]. The\nmemory network dynamically selects the words that are relevant to the gen-\nerated image, and then refines the details to produce better photo-realistic\nimages.\nAttnGAN is the first to incorporate attention mechanisms into the mul-\ntiple generators to focus on words that are relevant to the generated image\n[127]. To this end, in addition to encoding the whole sentence into a global\nsentence vector, the text encoder encodes each word into a word vector as\nshown in Figure 21. Then, the image vector is used to attend to the word\nvector using the attention modules at each stage of the multistage gener-\nators.\nFurthermore, AttnGAN introduces a loss function to compute the\nsimilarity between the generated image and the associated sentence, improv-\ning the performance of image generation. A similar work is reported whereby\n34\nthe model known as ResFPA-GAN, incorporates attention modules into the\nmultiple generators [128]. Specifically, a feature pyramid attention module\nis proposed to capture high semantic information and fuse the multiscale\nfeature, enhancing the overall performance of the model. DualAttn-GAN\nimproves AttnGAN by incorporating visual attention modules to focus on\nimportant features along both spatial and channel dimensions [129]. This\nallows the model to better understand and capture both the context of the\ninput sentence and the fine details of the image, resulting in more realistic\nimage generation.\nFigure 21: The architecture of AttnGAN [127].\nAlthough multistage generators improve image generation performance\nby leveraging multiscale representation, the generated images may contain\nfuzzy shapes with coarse features. DF-GAN replaces the multistage gener-\nators with a single-stage deep generator featuring residual connections and\ntrained with hinge loss [130]. Furthermore, DF-GAN introduces a regulariza-\ntion strategy on the discriminator that applies a gradient penalty on real im-\nages with matching text, allowing the model to generate more text-matching\nimages. DMF-GAN an improved DF-GAN, incorporates three novel compo-\nnents designed to leverage semantic coherence between the input text and\nthe generated image [131]. The first component is the recurrent semantic\nfusion module, which models long range dependencies between the fusion\nblocks. The second component is the multi-head attention module which is\nplaced towards the end of the generator to leverage the word features, forc-\ning the generator to generate images conditioned on the relevant words. The\nlast component is the word-level discriminator which provides fine-grained\nfeedback to the generator, facilitating the learning process and improving\n35\nthe overall quality of the generated images. Figure 22 shows the architec-\nture of DMF-GAN. The process of image generation involves feeding a noise\nvector to the generator at the very beginning of the network. However, as\nthe generator goes deeper, the noise effect may be diminished, affecting the\ndiversity of the image generation results. To mitigate this issue, DE-GAN\nincorporates a dual injection module into the single-stage generator [132].\nThe dual injection module consists of two text fusion layers followed by a\nnoise broadcast operation. The text fusion layer takes the sentence embed-\nding and fuses it with the input feature map using the fully-connected layer.\nThen noise is injected into the output feature map to retain the random-\nness in the generation process, improving diversity and generalization of the\nmodel.\nFigure 22: The architecture of DMF-GAN [131].\n4.2. Natural Language Processing\nNatural language processing (NLP) refers to the field of artificial intelli-\ngence that concerns with enabling computers to process, analyze and inter-\npret human languages to extract useful information. Some of the common\ntasks in NLP are machine translation, text classification and text generation.\nDeep learning has been widely applied to solve real-world NLP problems.\nThis section presents the recent advancements in deep learning models that\nhave been designed for NLP over the past few years.\n4.2.1. Text Classification\nText classification known as text categorization, is a task that involves\nassigning predefined categories or labels to a piece of text based on its con-\ntent. The task is commonly used in various applications such as document\nclassification, sentiment analysis and spam filtering. Numerous deep learning\n36\nmodels have been proposed for text classification in the past few decades, and\nmultilayer perceptron is one of the earliest architectures adopted to classify\ndocuments [133, 134]. The model typically has a single hidden layer with\na number of units between 15 and 150. Text data is inherently sequential,\nas it is composed of a series of words and symbols arranged in a specific\norder. This property makes RNN and its variants particularly well-suited for\nprocessing and analyzing text data. In [135], RNN with two hidden layers,\neach with 6 units is used to classify news documents into eight classes. A\nstudy was conducted to investigate the variants of RNN i.e. LSTM and GRU\nfor text classification [136]. The input to the model is a sequence of words\nof fixed length. The input sequence is also sliced into smaller subsequences\nof fixed length and passed to an independent model for parallelization. A\nconvolutional layer can extract local features, allowing the model to leverage\nhierarchical temporal information in textual data. A hybrid model of convo-\nlutional and LSTM architecture is proposed for text classification [137]. Two\nparallel convolutional layers are used to extract features from word embed-\ndings, followed by max-pooling layers to reduce the feature dimensions. The\nreduced features are then concatenated and passed to LSTM for prediction.\nAlthough CNN and RNN provide excellent results on text classification\ntasks, the models lack the ability to attend to specific words based on their\nimportance and context. To address this limitation, attention mechanism is\nincorporated into the model to focus on the important features, enhancing the\ntext classification accuracy. In [138], two attention modules are introduced to\ncapture the contextual information of the feature sequence extracted by bi-\ndirectional LSTM. The first attention module attends the sequence in forward\ndirection while the backward sequence is attended by the second attention\nmodule. The convolutional layers are used before the bi-directional LSTM\nto extract features from the word embedding. The attention modules require\nsequential processing using RNN-based architecture such as LSTM and GRU\nwhich may lead to information loss and distorted representations, particularly\nin long sequence. Furthermore, the attention modules focus on inter-sequence\nrelationships between the input sequence and the target, ignoring the intra-\nsequence relationships or the dependencies between the words. In [139], the\ndeep learning model is integrated with self-attention to capture the intra-\nsequence relationships between the features in the sequence. A multilayer of\nbi-directional LSTMs is utilized to extract feature sequence from the word\nembedding before the self-attention module attends the feature sequence to\ncompute the attention weights. To further improve the overall performance, a\n37\nmultichannel features consisting of three input pipelines is introduced [140].\nEach pipeline concatenates the word vector with a feature vector derived\nfrom the input sequence such as the word position, part-of-speech and word\ndependency parsing. The input pipeline is connected to bi-directional LSTM,\nfollowed by a self-attention module to learn the dependencies between the\nfeatures in the sequence.\nThe transformer is a deep learning architecture that transforms sequen-\ntial data using self-attention mechanisms, allowing long-range dependencies\nand complex patterns to be captured. The architecture is the basis of various\nadvanced deep learning models and the Bi-directional Encoder Representa-\ntions from Transformers popularly known as BERT is one of the examples\nthat leverage transformer for pre-training on large scale textual data [141].\nBERT is a bi-directional transformer encoder that is designed for various NLP\ntasks, capable of capturing the contextual information from both preceding\nand succeeding words in the input sequence. Several improvements have been\nmade to BERT to enhance its overall performance such as ALBERT [142],\nRoBERTa [143] and DeBERTa [144]. The improvements are centered around\nrefining the pre-training approaches such as dynamic masking of the training\ninstances, training with a block of sentences and representing each input word\nusing two vectors, both content and position of the word. Most of the recent\nworks leverage BERT and its variants to capture effective feature represen-\ntation of the input sequence. In [145], BERT and its variants are leveraged\nto capture the long-range dependencies of the input tokens. The features are\nthen passed to a layer normalization and a linear fully-connected layer with\ndropout for classification. Similar work is reported in [146] whereby BERT\nis used to extract the features and the features are then passed to a hybrid of\nconvolutional and recurrent neural networks. The traditional machine learn-\ning algorithms have been used to classify the features extracted by BERT\n[147]. The study shows machine learning algorithms can effectively leverage\nthe rich contextual features extracted by BERT for downstream classification\ntasks.\nIn text classification, the text labels can help in capturing the words rele-\nvant to the classification. The label-embedding attentive model is one of the\nearliest attempts to joint learn the label and word embeddings in the same\nlatent space and measure the compatibility between labels and words using\ncosine similarity [148]. The joint embedding allows the model to capture\nmore effective text representations, increasing the overall performance of the\nmodel. LANTRN is a deep learning model that leverages label embedding\n38\nextracted by BERT and entity information e.g. person name and organiza-\ntion name for text classification [149]. The entity recognition module is based\non bi-directional LSTM and conditional random field layers to calculate the\nprobability of each word in each entity label. The model introduces a label\nembedding bi-directional attention to learn the attention weights of token-\nlabel and sequence-label pairs.\nFurthermore, a transformer is introduced\nto learn local short-term dependencies of multiple short text sequences and\nlong-term dependencies of the input sequence. Aspect refers to a specific\nattribute of an entity within the text and incorporating this information en-\nhances the model’s understanding of the nuances of the text. BERT-MSL is\na multi-semantic deep learning model with aspect-aware enhancement and\nfour input pipelines: left sequence, right sequence, global sequence and as-\npect target [150]. The aspect-aware enhancement module takes the features\nextracted by BERT, and performs average pooling followed by a linear trans-\nform. Then the output is concatenated with the outputs produced by the\nlocal and global semantic learning modules. The concatenated features are\nthen jointly attended by a multi-head attention for text classification. Figure\n23 shows the architecture of BERT-MSL.\nFigure 23: The architecture of BERT-MSL [150].\n39\n4.2.2. Neural Machine Translation\nNeural machine translation (NMT) refers to the automated process of\ntranslating text from one language to another language.\nNumerous deep\nlearning models have been proposed for NMT which can be categorized into\nRNN-based and CNN-based models. One of the first successful RNN-based\nmodels is the encoder-decoder [44, 151]. The model consists of two connected\nsubnetworks (the encoder and the decoder) for modelling the translation pro-\ncess as shown in Figure 24. The encoder reads the source sentence word by\nword and produces a fixed-length context vector (final hidden state). This\nprocess is known as source sentence encoding as shown in the figure. Given\nthe context vector, the decoder generates the target sentence (translation)\nword by word.\nThis modelling of the translation can be seen as a map-\nping between the source sentence to the target sentence via the intermediate\ncontext vector in the semantic space.\nThe context vector represents the\nsummary of the input sequence’s semantic meaning, providing a compressed\nrepresentation that captures the essence of the source sentence. However,\nthe compression process can sometimes result in the loss of information es-\npecially those early in the sequence. Bi-directional RNN may mitigate the\nloss of information by modelling the sequence in reverse order. However,\nthe problem can still persist, particularly in cases where the input is a long\nsequence.\nFigure 24: The architecture of an encoder-decoder [152].\nAttention mechanism was introduced to solve the problem of learning\nlong input sequences [153]. Attention alleviates this issue by attending on\ndifferent words of the input sequences when predicting the target sequences\nat each time step. Unlike the standard encoder-decoder model, attention\nderives the context vector from the hidden states of both the encoder and\ndecoder, and the alignment between the source and target. This mechanism\n40\nallows the model to focus on the important words, increasing the overall ac-\ncuracy of the translation. Several alignment score functions have been pro-\nposed for calculating the attention weights. Some of the popular functions\nare additive [153], dot-product, location-based [154], and scaled dot-product\n[16]. The attention weights are calculated by attending to the entire hid-\nden states of the encoder. This attention, also known as global attention, is\ncomputationally expensive. Instead of attending to all hidden states, local at-\ntention attends to a subset of hidden states, thus reducing the computational\ncost [154]. Google Neural Machine Translation is a popular encoder-decoder\nmodel with an attention mechanism that significantly improves the accuracy\nof machine translation [155]. As shown in Figure 25, the model consists of\na multilayer of LSTMs with eight encoder and decoder layers and an atten-\ntion connection between the bottom layer of the decoder to the top layer of\nthe encoder. Furthermore, to deal with the challenging words to predict, a\nword is tokenized into subwords e.g. feud is broken down into fe and ud,\nallowing the model to generalize well to new and uncommon words. A year\nlater, the self-attention mechanism was proposed, significantly improving the\noverall accuracy of machine translation [16]. Self-attention, also known as\nintra-attention, allows the deep learning model to capture the dependencies\nbetween the input words. The self-attention mechanism is the fundamental\nbuilding block of the transformer model, which has since become a corner-\nstone in natural language processing and other domains.\nFigure 25: The architecture of Google Neural Machine Translation [155].\nDespite the success of transformer, the model falls short in capturing\nnuances of human language and struggles with tasks requiring deeper under-\n41\nstanding of context. This can be especially challenging when the tasks involve\nformality, colloquialism, and subtle cultural references that may not directly\nequivalent in the target language, resulting in inaccurate translation or los-\ning the original meaning. One of the approaches to include context into the\ninput sequence is concatenating the current source sentence with the previ-\nous (context) sentences and feeding the whole input to the transformer [156].\nThe model is trained to predict the translated sentence including the con-\ntext translation. At inference time, only the translation is considered while\nthe context translation is discarded. Furthermore, the approach encodes the\nsentence position and segment-shifted position to improve the distinction be-\ntween current sentences and context sentences. In [157], the source sentence\nis prefixed with the summary of the document to contextualize the input sen-\ntence. The summary is the set of salient words that represents the essence of\nthe document, resolving ambiguity associated with the translation. A study\nwas conducted to determine the optimal technique of aggregating contextual\nfeatures [158]. Three techniques were studied namely concatenation mode,\nflat mode and hierarchical mode, and the experimental results show that\nconcatenation mode achieved the best results. In [159], a training method\nis introduced to train the deep learning machine translation model to gen-\nerate translation involving honorific words. The training method indicates\nthe honorific context in the target sentence using an honorific classifier to\nguide the model to attend to the related tokens. Unlike other studies where\nthe context features are included by concatenation, the training method as-\nsigns weights to the context tokens indicated by the honorific classifier. This\nallows the model to generate a more accurate translation with honorifics.\nFinally, the performance of transformer relies on large-scale training data.\nHowever, for the vast majority of languages, only limited amounts of train-\ning data exist. To mitigate this problem, recent studies introduce shallow\ntransformer architectures [160], explore the effect of hyperparameter finetun-\ning [161], exploiting monolingual corpus to enhance the bilingual dataset for\nmodel training [162] and leveraging visual input as contextual information\nfor the translation task [163].\n4.2.3. Text Generation\nText generation refers to the process of creating texts based on a given\ninput whereby the input can be in the form of texts, images, graphs, tables\nor even tabular data. Due to the various forms of inputs, text generation\nhas a wide range of applications, including creative writing, image captioning\n42\nand music generation. This section focuses on the progress made in text-to-\ntext generation tasks such as question answering, dialogue generation and\ntext summarization. The recurrent neural network and its variants play an\nimportant role in text generation tasks for their strong ability to model se-\nquential data. One of the earliest works on question answering is based on\nthe RNN-based encoder-decoder model whereby the encoder takes the ques-\ntion embedding and processes it using bi-directional LSTM, and the decoder\ngenerates the corresponding answer [164]. Additionally, to prevent semantic\nloss and enable the model to focus on the important words in the input se-\nquence, a convolution operation is applied to the word embedding, and an\nattention mechanism is then used to attend to the output of the convolu-\ntion operation. Similar work is reported in [165] in which a knowledge-based\nmodule is introduced to calculate the relevance score between the question\nand the relevant facts in the knowledge base. This improves the text (an-\nswer) generation by the decoder. Another work is described in [166] where\nan encoder-decoder with attention for dialogue generation is optimized us-\ning reinforcement learning. The model is first trained in supervised learning\nmanner and then improved using the policy gradient method to diversify the\nresponses. Ambiguous content in question answering sentences is a challenge\nin text generation and can lead to incorrect and uncertain responses. Cross-\nsentence context aware bi-directional model introduces a parallel attention\nmodule to compute the co-attention weights at the sentence level, accounting\nfor the relationships and similarities in the question and the answer [167].\nThe transformer has been leveraged for text generation tasks. An incre-\nmental transformer-based encoder is proposed to incrementally encode the\nhistorical sequence of conversations [168]. The decoder is a two-pass decoder\nthat is based on the deliberation network, generates the next sentence. The\nfirst pass focuses on contextual coherence of the conversations while the sec-\nond pass refines the output of the first pass. BERT and ALBERT have been\nused as pre-trained models for question answering task [169].\nThe study\nfound that the performance of the models is sensitive to random assignment\nof the initial weights especially on small datasets [170]. T-BERTSum is a\nmodel based on BERT, designed to address the challenge of long text de-\npendence and leveraging latent topic mapping in text summarization [171].\nThe model integrates a neural topic module to infer topics and guide sum-\nmarization, uses a transformer network to capture long-range dependencies\nand incorporates multilayers of LSTM for information filtering. Exploiting\ndomain knowledge is essential in reducing the semantic gap between the\n43\ndeep learning models and the text corpus. KeBioSum is a knowledge infu-\nsion framework to inject domain knowledge into the pre-trained BERTs for\ntext summarization [172]. In the framework, the relevant information is de-\ntected and extracted from the domain knowledge, generating label sequences\nof the sentences. The label data is then used to train the text summarization\nmodel using discriminative and generative training approaches, infusing the\nknowledge into the model.\n4.3. Time Series and Pervasive Computing\nPervasive computing, often referred to as ubiquitous computing, is the\nprocess of integrating computer technology into everyday objects and sur-\nroundings so that they become intelligent, networked, and able to commu-\nnicate with one another to offer improved services and functionalities [173].\nAccording to He et al [174], the role of pervasive computing is foremost in\nthe field where it provides the ability to distribute computational services to\nthe surroundings where people work, leading to trust, privacy, and identity.\nExamples of pervasive computing applications include smart homes with con-\nnected appliances, wearable devices that monitor health and fitness, smart\ncities with sensor networks for traffic management, and industrial applica-\ntions that utilize the Internet of Things (IoT) for monitoring and control.\nGenerally, the continuous interaction of interconnected devices in pervasive\ncomputing often result in time series data, which captures the evolution of\nvarious parameters over time.\nFor instance, medical sensors, such as electrocardiograms (ECG) and elec-\ntroencephalograms (EEG), generate time series data that contain critical di-\nagnostic information, which deep learning can use to detect anomalies, pre-\ndict diseases, and classify medical conditions with improved accuracy. Also,\ndevices such as accelerometers, magnetometers and gyroscopes, among others\ncan be used to capture human activity signals, which are often represented\nas time series of state changes [175]. In traditional machine learning, features\nsuch as mean, variance and others are manually extracted from times series\nof state changes before human activity classification. However, deep learn-\ning models automatically extract features [61]. Also, in other fields such as\nfinance, which entail time series data, deep learning has been instrumental\nin stock price prediction [176], fraud detection [177], and algorithmic trading\n[178], among others. Generally, deep learning networks excel at capturing\nintricate temporal relationships within time-series data, enabling more pre-\ncise predictions and improved decision-making. Based on this, several deep\n44\nlearning models have been employed for feature learning across various time\nseries and pervasive computing domains.\n4.3.1. Human Activity Recognition\nHuman activity recognition (HAR) finds application across various do-\nmains including intelligent video surveillance, environmental home monitor-\ning, video storage and retrieval, intelligent human-machine interfaces, and\nidentity recognition, among many others. It includes various research fields,\nincluding the detection of humans in video, estimating human poses, tracking\nhumans, and analyzing and understanding time series data [179]. Despite the\nadvancements in vision-based HAR, there exist inherent limitations. Gen-\nerally, vision-based approaches heavily rely on camera systems, which may\nhave restricted views or be affected by lighting conditions, occlusions, and\ncomplex backgrounds [175]. Additionally, vision-based HAR struggles with\nidentifying actions that occur beyond the range of the camera or actions that\nare visually similar.\nWearable sensors offer a promising alternative to overcome these limi-\ntations. By directly capturing data from the individual, wearable sensors\nprovide more comprehensive and accurate information about human activ-\nities. The signals obtained from wearable sensors typically represent time\nseries data reflecting state changes in activities. Deep learning models can\neffectively learn from these signals, allowing for robust and accurate recog-\nnition of human activities. Moreover, wearable sensors offer the advantage\nof mobility, enabling activity recognition in various environments and situ-\nations where vision-based systems may be impractical or ineffective [180].\nGenerally, the time series nature of signals from wearable sensors presents an\nexcellent opportunity for deep learning models to excel in recognizing human\nactivities with high accuracy and reliability.\nSeveral researchers have proposed the use of CNN, RNN, and Hybrid\nmodels for deep learning based feature learning in wearable sensor HAR. For\ninstance, using two-dimensional CNN (Conv2D), several researchers, as seen\nin [181], [182] and [183], among others, have developed deep learning models\nfor wearable sensor HAR, despite the time series nature of the data. This is\noften done by treating the time series signals from wearable sensors as 2D\nimages by reshaping them appropriately. To achieve this, researchers often\norganize each time series signal into a matrix format, with time along one\naxis and sensor dimensions along the other, before creating a pseudo-image\nrepresentation, which allows the matrix to be be fed into Conv2D layers\n45\nfor feature extraction.\nConv2D layers excel at capturing spatial patterns\nand relationships within images, and by treating the time series data as\nimages, these layers can learn relevant spatial features that contribute to\nactivity recognition. The convolution operation performed by Conv2D filters\nacross both the time and sensor dimensions, allowing the network to identify\npatterns and features that may be indicative of specific activities.\nEven though Conv2D can effectively capture spatial dependencies within\nthe data, it often struggles to capture temporal dependencies inherent in\ntime series data. Since Conv2D processes data in a grid-like fashion, it does\nnot fully leverage the sequential nature of the time series, potentially lead-\ning to less effective feature extraction for wearable sensor HAR tasks. For\nthis reason, recent HAR architectures have leveraged one-dimensional CNN\n(Conv1D) and other RNNs for automatic feature extraction. Conv1D layers\nare specifically designed to capture temporal dependencies within sequential\ndata. They operate directly on the time series data without reshaping it into\na 2D format, allowing them to capture temporal patterns more effectively.\nConv1D layers are better suited for extracting features from time series data,\nmaking them a more natural choice for wearable sensor HAR [61].\nFor instance, Ragab et al. [184] proposed a random search Conv1D model,\nand evaluated the performance of the model on UCI-HAR dataset. The re-\nsult showed that the model achieved a recognition accuracy of 95.40% when\nclassifying the six activities in the dataset. However, the model exhibited\nextended training times due to the dynamic nature of some activities within\nthe dataset. To address this, [185] proposed the use of varying kernel sizes\nin Conv1D layers to recognize various activities, including sitting, stand-\ning, walking, sleeping, reading, and tilting. Also, a few Conv1D layers were\nstacked in order to streamline the time optimization process for training the\nneural network. Also, some researchers have proposed models that combine\nmachine learning algorithms with Conv1D in HAR, as seen in Shuvo et al.\n[186]. Their work presented a two-stage learning process to improve HAR by\nclassifying activities into static and dynamic using Random Forest, before\nusing Support Vector Machine to identify each static activity, and Conv1D\nto recognize dynamic activities. The result showed that the method achieved\nan accuracy of 97.71% on the UCI-HAR dataset.\nFollowing these advancements, several researchers have further explored\nConv1D architectures with various modifications, to enhance feature learn-\ning in activity recognition systems. For example, Han et al. [187] developed\na two-stream CNN architecture as a plug-and-play module to encode con-\n46\ntextual information of sensor time series from different receptive field sizes.\nThe module was integrated into existing deep models for HAR at no extra\ncomputation cost. Experiments on OPPORTUNITY, PAMAP2, UCI-HAR\nand USC-HAD datasets showed that the module improved feature learn-\ning capabilities. A similar research reported in [188] proposed the WSense\nmodule to address the issue of differences in the quality of features learnt,\nregardless of the size of the sliding window segmentation, and experimented\non PAMAP2 and WISDM datasets. The results showed that by plugging the\nWSense module into Conv1D architectures, improved activity features can\nbe learned from wearable sensor data for human activity recognition.\nSimilarly, some researchers have also proposed the use of standalone\nRNNs in HAR, and a hybrid of Conv1D architectures with RNNs such as\nLSTMs [189], BiLSTMs [190, 191], GRUs [192] and BiGRUs [193, 194] in\norder to fully harness the feature learning capabilities of both CNN and\nRNNs. For instance, Nafea et al. [195], leveraged Bi-LSTM and Conv1D\nwith increasing kernel sizes to learn features at various resolutions. Human\nactivity features were extracted using the stacked convolutional layers with\na Bi-LSTM layer, before including a flattening layer and a fully connected\nlayer for subsequent classification. However, the model had issues extract-\ning quality features of dynamic activities compared to static activities. To\naddress such issues, some research works have incorporated attention mecha-\nnisms in Conv1D-based architectures to improve feature learning of dynamic\nand complex activities from time series signals obtained from wearable sen-\nsors. For example, Khan and Ahmad [196] designed three lightweight con-\nvolutional heads, with each specialized in feature extraction from wearable\nsensor data. Each head comprised stacked layers of Conv1Ds, along with\nembedded attention mechanisms to augment feature learning. The results\ndemonstrated that integrating multiple 1D-CNN heads with attention mech-\nanisms can enhance feature learning for Human Activity Recognition. Ayo\nand Noor [197] designed three feature learning pipelines, each pipeline con-\nsisting of two concurrent layers of Conv1D and LSTM with max-pooling,\nwhich are then concatenated and processed using an attention mechanism\nto enhance feature learning. These diverse modifications and adaptations\nshowcase the versatility and potential of deep learning models in achieving\nstate-of-the-art in HAR systems.\n47\nFigure 26: The architecture of multi-head CNN model [196].\n4.3.2. Speech Recognition\nSpeech, as the primary mode of human communication, has captivated\nresearchers for over five decades, especially since the inception of artificial\nintelligence [198]. From the earliest endeavors to understand and replicate\nthe complexities of human speech, to contemporary advancements leveraging\ncutting-edge technologies, the quest for accurate and efficient speech recog-\nnition systems has been relentless. In recent years, the emergence of deep\nlearning techniques has revolutionized the speech recognition field.\nDeep\nlearning has demonstrated unparalleled success in processing and extracting\nintricate patterns from vast amount of data. When applied to the realm\nof speech recognition, deep learning have surpassed traditional approaches\nby learning intricate features directly from raw audio signals, circumvent-\ning the need for handcrafted features and complex preprocessing pipelines.\nThis paradigm shift has significantly advanced the state-of-the-art in speech\nrecognition, enabling systems to achieve unprecedented levels of accuracy\nand robustness across various languages, accents, and environmental condi-\ntions. Generally, deep learning has been extended to other essential applica-\ntions of speech recognition, such as speaker identification [199, 200], emotion\nrecognition [201], language identification [202], accent recognition [203], age\nrecognition [204] and gender recognition [205], among many others.\nPrior to the adoption of deep learning in speech recognition, the foun-\n48\ndation of traditional speech recognition systems was the use of Gaussian\nMixture Models (GMMs), which are often combined with Hidden Markov\nModels (HMMs) to represent speech signals [206]. This is because a speech\nsignal can be thought of as a short-term stationary signal. The spectral rep-\nresentation of the sound wave is modelled by each HMM using a mixture of\nGaussian. However, they are considered statistically inefficient for modelling\nnon-linear or near non-linear functions [207, 198]. This is because HMMs rely\non a set of predefined states and transition probabilities, making assumptions\nabout the linearity and stationarity of the underlying data. While suitable\nfor modelling certain aspects of speech, HMMs often fall short when tasked\nwith representing the intricate nonlinearities and variability present in speech\nsignals. Speech, by nature, exhibits nonlinear and dynamic characteristics,\nwith features such as intonation, rhythm, and phonetic variations challeng-\ning the simplistic assumptions of traditional statistical models like HMMs.\nIn other words, GMM-HMM approach had limitations in capturing complex\nacoustic patterns and long-term dependencies in speech [208].\nIn recent times, CNN and RNNs have been leveraged for automatic speech\nrecognition in order to consider a longer or variable temporal window for con-\ntext information extraction [209]. Generally, CNNs are well-suited for cap-\nturing local patterns and hierarchical features in data, making them effective\nfor modelling acoustic features in speech. By directly learning features from\nraw speech signals, CNNs bypassed the need for handcrafted features used in\ntraditional GMM-HMM systems. Additionally, CNNs can capture long-range\ndependencies in the data, which is crucial for understanding the context of\nspeech. Likewise, the RNNs are suitable choice for exploring extended tem-\nporal context information in one processing level for feature extraction and\nmodelling.\nBased on this, several researchers have proposed the use of both CNN\nand variants of RNNs for automatic speech recognition and for other speech\nrelated tasks. For instance, [210], used CNN to classify speech emotions and\nbenchmarked on a dataset consisting of seven classes (anger, disgust, fear,\nhappiness, neutral, sadness and surprise). However, CNN lack the ability to\nmodel temporal dependencies explicitly. In speech recognition, understand-\ning the temporal context of speech is essential for accurate transcription.\nAlso, speech signals are inherently sequential, and information from previous\ntime steps is crucial for understanding the current speech segment. CNNs,\nby design, do not inherently capture this sequential nature. For this rea-\nson, variants of RNNs have been leveraged to collect extended contexts in\n49\nspeeches. This is because RNNs are designed to model sequential data by\nmaintaining hidden states that capture information from previous time steps.\nThis allows them to capture temporal dependencies effectively, making them\nwell-suited for ASR tasks. In [211], the authors evaluated the performance of\nRNN, LSTM, and GRU on a popular benchmark speech dataset (ED-LIUM).\nThe results showed that LSTM achieved the best word error rate while the\nGRU optimization was faster and achieved word error rate close to that of\nLSTM.\nHowever, RNN architectures process input sequences sequentially, which\nlimits their ability to capture global context information effectively. As a\nresult, they may struggle to understand the entire context of a spoken utter-\nance, leading to lower transcription accuracy, particularly in tasks requiring\nunderstanding beyond local dependencies. Also, most CNN and RNN au-\ntomatic speech recognition systems comprise of separate acoustic, pronunci-\nation, and language modelling components that are trained independently.\nUsually, the acoustic model bootstraps from an existing model that is used\nfor alignment in order to train it to recognise context dependent (CD) states\nor phonemes. The pronunciation model, curated by expert linguists, maps\nthe sequences of phonemes produced by the acoustic model into word se-\nquences. For this reason, Sequence-to-Sequence (Seq2Seq) models are being\nproposed in automatic speech recognition to train the acoustic, pronuncia-\ntion, and language modelling components jointly in a single system [212].\nSeq2Seq models in automatic speech recognition are a class of models that\naim to directly transcribe an input sequence of acoustic features such as\nspeech spectrograms or Mel-frequency cepstral coefficients into a sequence of\ncharacters or words representing the recognized speech. There have been a\nvariety of sequence-to-sequence models explored in the literature, including\nRecurrent Neural Network Transducer (RNN-T) [213], Listen, Attend and\nSpell (LAS) [214], Neural Transducer [215], Monotonic Alignments [216] and\nRecurrent Neural Aligner (RNA) [217].\nAs shown in Figure 27, the encoder component takes the input sequence\nof acoustic features and processes it to create a fixed-dimensional represen-\ntation, often called the context vector.\nThis representation captures the\nessential information from the input sequence and serves as the basis for\ngenerating the output sequence.\nThe decoder component takes the con-\ntext vector produced by the encoder and generates the output sequence. In\nASR, this output sequence consists of characters or words representing the\nrecognized speech. The decoder is typically implemented as a recurrent neu-\n50\nFigure 27: Sequence-to-Sequence\nral network (RNN), such as a Long Short-Term Memory (LSTM) or Gated\nRecurrent Unit (GRU) network, or it could be a transformer-based archi-\ntecture. During training, the model learns to map input sequences to their\ncorresponding output sequences by minimizing a suitable loss function, such\nas cross-entropy loss. This is typically done using techniques like backprop-\nagation through time (BPTT) or teacher forcing, where the model is trained\nto predict the next token in the output sequence given the previous tokens.\nThereafter, the trained model is used to transcribe unseen speech input. The\nencoder processes the input sequence to produce the context vector, which\nis then fed into the decoder to generate the output sequence. In some cases,\nbeam search [218, 219] or other decoding strategies may be used to improve\nthe quality of the generated output.\nIn [220], the authors explored various structural and optimization en-\nhancements to their LAS Sequence to Sequence model, resulting in signifi-\ncant performance improvements. They introduce several structural enhance-\nments, including the utilization of word piece models instead of graphemes\nand the incorporation of a multi-head attention architecture, which outper-\nforms the commonly used single-head attention mechanism. Additionally,\nthey investigate optimization techniques such as synchronous training, sched-\nuled sampling, label smoothing, and minimum word error rate optimization,\nall of which demonstrate improvements in accuracy. The authors present\nexperimental results utilizing a unidirectional LSTM encoder for streaming\nrecognition. On a 12,500-hour voice search task, they observe a decrease in\nWord Error Rate (WER) from 9.2% to 5.6% with the proposed changes, while\nthe best-performing conventional system achieves a WER of 6.7%. More-\nover, on a dictation task, their model achieves a WER of 4.1%, compared\n51\nto 5% for the conventional system. Similarly, the work of Prabhavalkar et\nal. [212] investigated a number of sequence-to-sequence methods in auto-\nmatic speech recognition. These included the RNN transducer (RNN-T),\nattention-based models, a new model that augments the RNN-T with atten-\ntion, and a Connectionist Temporal Classification (CTC) trained system that\ndirectly outputs grapheme sequences. According to their research, sequence-\nto-sequence approaches can compete on dictation test sets against state-of-\nthe-art when trained on a large volume of training data. Even though deep\nlearning has achieved state-of-the-art in speech recognition, an area that still\ncalls for attention is speech-to-speech translation. This is because the present\ndeep learning based speech-to-speech translation systems operate by trans-\nlating sentences individually, disregarding any contextual information from\npreceding sentences. While research on contextual understanding has been\nongoing for years, challenges persist regarding its practicality and process-\ning efficiency, since translation typically relies on the surrounding words for\ncontext.\n4.3.3. Finance\nOver the past few decades, computational intelligence in finance has been\na hot issue in both academia and the financial sector [221]. Deep learning,\nespecially RNN models have gained significant traction in the field of finance\ndue to its ability to handle sequential data, since financial data often exhibit\nsequential dependencies, such as time series data for stock prices or historical\ntransaction data. Within the financial industry, researchers have developed\ndeep learning models for stock market forecasting [176], algorithmic trading\n[178], credit risk assessment [222], portfolio allocation [223], asset pricing\n[224], and derivatives markets [225], among others and these models are\nintended to offer real-time operational solutions. In exchange rate prediction,\nSun et al. [226] developed an ensemble deep learning technique known as\nLSTM-B by combining a bagging ensemble learning algorithm with a long-\nshort term memory (LSTM) neural network to increase the profitability of\nexchange rate trading and produce accurate exchange rate forecasting results.\nIn comparison to previous methodologies, the authors’ estimates proved to\nbe more accurate when they looked at the potential financial profitability of\nexchange rates between the US dollar (USD) and four other major currencies:\nGBP, JPY, EUR, and CNY.\nThe authors in [227] proposed a Bi-LSTM-BR technique, which com-\nbined Bagging Ridge (BR) regression with Bi-LSTM as base regressors. The\n52\npre-COVID-19 and COVID-19 exchange rates of 21 currencies against the\nUSD were predicted using the Bi-LSTM BR, and experiments showed that\nthe proposed method outperformed ML algorithms such as DT and SVM.\nHowever, exchange rate data can be noisy and subject to non-stationarity,\nwhich can pose challenges for predictive modelling. While bagging techniques\ncan help mitigate the effects of noise to some extent, they may struggle to\ncapture long-term trends or sudden shifts in the data distribution, leading\nto suboptimal performance. To address this, Wang et al. [228] presented\nan approach for one-day ahead of time exchange rate prediction that con-\ncurrently considers both supervised and unsupervised deep representation\nfeatures to enhance Random Subspace. Two crucial phases in the SUDF-\nRS technique are feature extraction and model building. First, LSTM and\ndeep belief networks, respectively, extract the supervised and unsupervised\ndeep representation features. To produce high-quality feature subsets, an\nenhanced random subspace approach was created that integrates a random\nforest-based feature weighting mechanism. Then, the matching base learner\nis trained using each feature subset, and the final outcomes are generated\nby averaging the outcomes of each base learner. Experiments on EUR/USD,\nGBP/USD and USD/JPY showed that improved accuracy was achieved us-\ning the model.\nIn stock market prediction, several deep learning architectures have been\nproposed in the literature.\nFor instance, [229], conducted a comparative\nstudy between the ANN, SVR, RF and an LSTM model. As compared to\nthe other models discussed in the study, the LSTM model outperformed the\nothers in predicting the closing prices of iShares MSCI United Kingdom.\nSimilarly, using stock market historical data and financial news, Cai et al.\n[230] used CNN and LSTM forecasting methods to generate seven predic-\ntion models. The seven models were then combined into a single ensemble\nmodel in accordance with the ensemble learning approach to create an ag-\ngregated model. However, the accuracy of all the models’ predictions was\nlow. Gudelek et al. [231] proposed a CNN model which used a sliding win-\ndow technique and created pictures by capturing daily snapshots within the\nwindow’s bounds. With 72% accuracy, the model was able to forecast the\nprices for the following day and was able to generate 5 times the starting\ncapital. In Eapen et al. [232], a CNN and Bi-LSTM model with numerous\npipelines was proposed, utilising an SVM regressor model on the S&P 500\nGrand Challenge dataset, and results showed enhanced prediction perfor-\nmance by over a factor of 6% compared to baseline models. As presented,\n53\ndeep learning has undeniably achieved state-of-the-art performance across\nvarious domains within finance.\n4.3.4. Electrocardiogram (ECG) Classification\nDisorders pertaining to the heart or blood vessels are collectively referred\nto as Cardiovascular Diseases (CVD) [233]. According to the American Heart\nAssociation’s 2023 statistics, CVD has emerged as the leading cause of death\nworldwide.\nIn 2020, 19.05 million deaths were recorded from CVD glob-\nally, which signifies an increase of 18.71% from 2010, and it is believed that\nthis number will rise to 23.6 million by 2030 [234]. Blood clots and vas-\ncular blockages caused by CVDs can cause myocardial infarction, stroke or\neven death [233]. Generally, early diagnosis has been shown to reduce the\nmortality rate of CVDs, and Electrocardiogram (ECG) signals play a crucial\nrole in diagnosing various cardiac abnormalities and monitoring heart health.\nHowever, ECG signal has characteristics of high noise and high complexity,\nmaking it time-consuming and labor-intensive to identify certain diseases us-\ning traditional methods. The traditional approach is tedious and requires\nthe expertise of a medical specialist.\nOver the past decades, the task of\nLong-term ECG recording classification has been significantly facilitated for\ncardiologists through the adoption of computerized ECG recognition prac-\ntices.\nThroughout this period, feature extraction methods have predomi-\nnantly relied on manual techniques, encompassing diverse approaches such\nas wave shape functions [235], wavelet-based features [236], ECG morphol-\nogy [237], hermite polynomials [238], and Karhunen-Loeve expansion of ECG\nmorphology [239], among others. These extracted features are subsequently\nsubjected to classification using various machine learning algorithms.\nMore recently, the advent of deep learning has revolutionized the field\nby enabling automatic feature learning directly from ECG signals.\nThis\nadvancement holds significant promise in the realm of automated ECG clas-\nsification, offering clinicians a tool for swift and accurate diagnosis. Based on\nthis, several deep learning architectures have been proposed for feature learn-\ning of ECG signals. For instance, Acharya et al. [240] developed a 9-layer\nCNN model to automatically identify five categories of heartbeats in ECG\nsignals. A similar model was also developed in [241], However, ECG signals\noften vary significantly in length, as they may contain different numbers of\nheartbeats. CNNs typically require fixed-length inputs, which may neces-\nsitate preprocessing steps such as padding or truncation, potentially losing\nimportant temporal information. For this reason, several architectures have\n54\nleveraged RNN in ECG classification, as seen in [242], [243] and [244], among\nothers. While RNNs are capable of handling sequential data, they also have\nlimitations in capturing local patterns or short-term dependencies effectively.\nIn ECG signals, local features such as specific waveforms or intervals can be\ncrucial for classification. For this reason, recent works have proposed hybrid\nmodels which combine the strengths of both CNNs and RNNs to overcome\nsome of these limitations [245].\nThe work of Rai et al. [246] developed a hybrid CNN-LSTM network\nto evaluate the optimum performing model for myocardial infarction detec-\ntion using ECG signals. The authors then experimented on 123,998 ECG\nbeats obtained from the PTB diagnostic database (PTBDB) and MIT-BIH\narrhythmia database (MITDB), and the result showed that by combining the\ncapabilities of both CNN and LSTM, improved classification accuracy can be\nachieved. Also, in [247], a CNN architecture was developed to extract mor-\nphological features from ECG signals. For the purpose of determining the\ndegree of heart rate variability, another composite structure was designed us-\ning LSTM and a collection of manually created statistical features. Following\nthat, a hybrid CNN-LSTM architecture is built using the two independent\nbiomarkers to classify cardiovascular artery diseases, and experiments were\ncarried out on two distinct datasets.\nThe first is a partly noisy in-house\ndataset collected using an inexpensive ECG sensor, and the other is a corpus\ntaken from the MIMIC II waveform dataset. The hybrid model proposed in\nthe work achieved an overall classification accuracy of 88% and 93%, respec-\ntively, which surpasses the performance of standalone architectures.\nAn automated diagnosis method based on Deep CNN and LSTM archi-\ntecture was presented in [248] to identify Congestive Heart Failure (CHF)\nfrom ECG signals. Specifically, CNN was used to extract deep features, and\nLSTM was employed to exploit the extracted features to achieve the CHF\ndetection goal. The model was tested using real-time ECG signal datasets,\nand the results showed that the AUC was 99.9%, the sensitivity was 99.31%,\nthe specificity was 99.28%, the F-Score was 98.94%, and the accuracy was\n99.52%. However, since ECG signals can vary in length due to differences in\nrecording durations or patient conditions. LSTMs are capable of handling\nvariable-length sequences, but traditional CNNs typically require fixed-length\ninputs. Therefore, fusing these features effectively in a hybrid model can be\nchallenging.\nAlso, Hybrid CNN-RNN models can be computationally in-\ntensive, especially when processing long ECG sequences or large datasets.\nFor this reason, recent research works have proposed the use of attention\n55\nmechanisms to reduce the computational burden by enabling the model to\nselectively attend to informative features, focusing computational resources\nwhere they are most needed. Likewise, attention mechanisms can enable the\nmodel to attend to informative segments of the ECG signal, regardless of their\nlength, allowing for more flexible processing of variable-length sequences.\nSeveral researchers have leveraged attention mechanisms in standalone\nand hybrid architectures for improved performance.\nFor instance, in the\nwork of Chun-Yen et al. [249], CNN layers were used to extract main fea-\ntures, while LSTM and attention were included to enhance the model’s fea-\nture learning capabilities. Experiments on a 12-lead KMUH ECG dataset\nshowed that the model had high recognition rates in classifying normal and\nabnormal ECG signals, compared to hybrid models without attention mech-\nanisms. Wang et al. [250] presented a 33-layer CNN architecture with non-\nlocal convolutional block attention module (NCBAM). To extract the spa-\ntial and channel information, preprocessed ECG signals were first fed into\nthe CNN architecture. A non-local attention further captured long-range\ndependencies of representative features along spatial and channel axes. Sim-\nilarly, a spatio-temporal attention-based convolutional recurrent neural net-\nwork (STA-CRNN) was presented in [251] with the aim of concentrating on\nrepresentative features in both the spatial and temporal dimensions. The\nCNN subnetwork, spatiotemporal attention modules, and RNN subnetwork\nmade up the STA-CRNN and according to findings, the STA-CRNN model\nwas able to classify eight different forms of arrhythmias and normal rhythm\nwith an average F1 score of 0.835.\nCombining hybrid deep learning models with attention mechanisms for\nECG feature learning is a promising approach that has already shown po-\ntential in ECG feature learning, according to reviewed literature. Future re-\nsearch can further explore semi-supervised and self-supervised learning tech-\nniques to leverage large amounts of unlabeled ECG data. This could involve\npre-training models on large-scale unlabeled datasets using self-supervised\nlearning objectives. Also, deep learning models have been leveraged in the\ngeneration of synthetic ECG signals to augment real signals, as seen in [252]\nwhere a GAN model was developed to generate ECG signals that correspond\nwith available clinical data. The GAN model used two layers of BiLSTM\nnetworks for the generator and CNN for the discriminator, and trained us-\ning the 48 ECG recordings of different users from the MIT-BIH dataset.\nThe authors then compared their model with a Recurrent neural network\nautoencoder (RNN-AE) model and a recurrent neural network variational\n56\nautoencoder (RNN-VAE) model, and the results showed that their model\nexhibited the fastest convergence of its loss function to zero.\n4.3.5. Electroencephalography (EEG) Classification\nThree-dimensional scalp surface electrode readings provide a dynamic\ntime series that is called Electroencephalogram (EEG) signal [253]. Brain\nwaves obtained from an EEG can effectively depict both the psychological\nand pathological states of a human. The human brain is acknowledged to\nbe a fascinating and incredibly complicated structure. Numerous brain sig-\nnals, including functional magnetic resonance imaging (fMRI), near-infrared\nspectroscopy (NIRS), electroencephalograms (EEGs), and functional near-\ninfrared spectroscopy (fNIR), among others have been collected and used to\nstudy the brain [254]. Due to the EEG’s non-invasive, affordable, accessi-\nble, and excellent temporal resolution characteristics, it has become the most\nutilised approach. However, the signal-to-noise ratio of EEG signal is low,\nmeaning that sources with no task-relevant information frequently have a\nstronger effect on the EEG signal than those that do. These characteris-\ntics often make end-to-end feature learning for EEG data substantially more\nchallenging [253]. Based on this, several methods have been leveraged for\nimproved feature extraction in EEG signals across several domains including\nMotor imagery [255], anxiety disorder [256], epileptic seizure detection [257],\nsleep pattern analysis and disorder detection [258, 259], and Alzheimer’s dis-\nease detection [260], and many others.\nEEG Motor Imagery (MI) is a technique used to study brain activity as-\nsociated with the imagination of movement. It involves recording electrical\nactivity generated by the brain through electrodes placed on the scalp. MI\ntasks typically involve imagining performing a specific motor action, such as\nmoving a hand or foot, without physically executing the movement, and has\nbeen leveraged in smart healthcare applications such as post-stroke rehabil-\nitation and mobile assistive robots, among others [261]. Prior to the advent\nof deep learning, motor imagery EEG data are passed through various steps\nbefore classification using traditional ML techniques. Pre-processing, feature\nextraction, and classification are the three primary stages that traditional\napproaches usually take while processing MI-EEG signals. Pre-processing in-\ncludes a number of operations, including signal filtering (choosing the most\nvaluable frequency range for MI tasks), channel selection (identifying the\nmost valuable EEG channels for MI tasks), signal normalisation (normalis-\ning each EEG channel around the time axis), and artefact removal (remov-\n57\ning noise from MI-EEG signals). Independent component analysis (ICA) is\nthe most often utilised technique for removing artefacts [262, 263, 264]. In\ncontrast to the traditional approach, deep learning architectures can auto-\nmatically extract complex features from raw MI-EEG data without the need\nfor laborious feature extraction and pre-processing. Based on this, several\ndeep learning architectures have been proposed for MI-EEG feature learning,\nas seen in [265], [266] and [267], among others. For instance [253], catego-\nrized MI-EEG signals using three CNNs with varying architectures, and the\nnumber of convolutional layers varied from two layers to a five-layer deep\nConvNet to a thirty-one-layer residual network.\nIn Dai et al. [268], the authors proposed an approach for classifying MI-\nEEG signals which blend variational autoencoder with CNN architecture.\nThe VAE decoder was used to fit the Gaussian distribution of EEG signals,\nand the time, frequency, and channel information from the EEG signal were\ncombined to create a novel representation of input, and the proposed CNN-\nVAE method was optimised for the input. Experiments showed that by com-\nbining both deep learning architectures, improved features were learnt, which\nled to a high classification performance on the BCI Competition IV dataset\n2b. Li et al. [269] employed optimal wavelet packet transform (OWPT) for\nthe generation of feature vectors from MI-EEG signals. These vectors were\nthen utilized to train an LSTM network which demonstrated satisfactory\nperformance on dataset III from the BCI Competition 2003. However, the\nmodel has excessively intricate structure. To address this, Feng et al. [270]\nintroduced a technique that merges continuous wavelet transform (CWT)\nwith a simplified convolutional neural network to enhance the accuracy of\nrecognizing MI-EEG signals. By employing CWT, MI-EEG signals were con-\nverted into time-frequency image representations. Subsequently, these image\nrepresentations were fed into the SCNN for feature extraction and classifica-\ntion. Experiments on the BCI Competition IV Dataset 2b demonstrate that,\non average, the classification accuracy across nine subjects reached 83.2%.\nHowever, the computational complexity of the model was quite high, due to\nthe processing of time-frequency image representations. The conversion of\nMI-EEG signals into time-frequency images using CWT requires significant\ncomputational resources.\nThe authors in [271] introduced a classification framework based on Long\nShort-Term Memory (LSTM) to improve the accuracy of classifying four-class\nmotor imagery signals from EEG. The authors sliding window technique to\ncapture time-varying EEG signal data, and employed an overlapping-band-\n58\nbased Filter Bank Common Spatial Patterns (FBCSP) method to extract\nsubject-specific spatial features. Experiments on the BCI Competition IV\ndataset 2a, showed that their model achieved an average accuracy of 97%,\ncompared to existing methods. Also, in the classification of Alzheimer’s dis-\nease, Zhao et al. [272] employed a deep learning network to analyse EEG\ndata. The deep learning model was evaluated on a dataset that consist of\nfifteen (15) patients with clinically confirmed Alzheimer’s disease and fif-\nteen (15) healthy individuals, and results showed that improved features\nwere learnt and compared the results to the traditional methods. This has\nprompted the use of deep learning in Alzheimer’s disease detection, as seen\nin [273], where the authors used CNN for diagnosing Alzheimer’s Disease.\nTo address challenges posed by limited data and overfitting in deep learning\nmodels designed for Alzheimer’s Disease detection, the authors explored the\nuse of overlapping sliding windows to augment the EEG data collected from\n100 subjects (comprising 49 AD patients, 37 mild cognitive impairment pa-\ntients, and 14 healthy controls subjects). After assembling the augmented\ndataset, a modified Deep Pyramid Convolutional Neural Network (DPCNN)\nwas used to classify the enhanced EEG signals. In epilepsy detection, [274]\ndeveloped three deep learning architectures (CNN, LSTM, and hybrid CNN-\nLSTM), with each model chosen for its effectiveness in handling the intricate\ncharacteristics of EEG data. Each architecture offers distinct advantages,\nwith CNN excelling in spatial feature extraction, LSTM in capturing tem-\nporal dynamics, and the hybrid model combining these strengths. The CNN\nmodel, consisting of 31 layers, attained the highest accuracy, achieving 91%\non the first benchmark dataset and 82% on the second dataset using a 30-\nsecond threshold, selected for its clinical significance.\nIn the work of Abdulwahhab et al. [275], EEG waves’ time-frequency\nimage and raw EEG waves served as input elements for CNN and LSTM\nmodels. Two signal processing methods, namely Short-Time Fourier Trans-\nform (STFT) and CWT, were employed to generate spectrogram and scalo-\ngram images, sized at 77 × 75 and 32 × 32, respectively. The experimental\nfindings demonstrated detection accuracies of 99.57% and 99.26% for CNN\ninputs using CWT Scalograms on the Bonn University dataset and 99.57%\nand 97.12% using STFT spectrograms on the CHB-MIT dataset. Similarly,\nin emotion recognition, several deep learning models have been leveraged\nwith EEG signals.\nFor instance, in [276], a subject-independent emotion\nrecognition model was proposed, which utilizes Variational Mode Decompo-\nsition (VMD) for feature extraction and DNN as the classifier. Evaluation\n59\nagainst the benchmark DEAP dataset demonstrates superior performance of\nthis approach compared to other techniques in subject-independent emotion\nrecognition from EEG signals. Also, some researchers have also combined\nEEG signals with facial expression and speech in emotion recognition, as\nseen in [277], [278], and [279], among others. However, EEG signals can vary\nsignificantly across individuals, making it challenging to generalize models\nacross different subjects.\n5. Research Challenges\n5.1. Availability and Quality\nBuilding and employing deep learning models face several challenges. The\ntraining of deep learning requires a large number of instances (examples) to\nachieve high accuracy and generalization [280]. Furthermore, the complexity\nof deep neural networks may lead to overfitting, where the model performs\nwell on training data but fails to generalize on new, unseen data. This phe-\nnomenon frequently arises when the models is trained on insufficient data,\nhighlighting the importance of diverse and extensive datasets. However, the\ndata collection and annotation are time consuming and often require domain\nexperts, specialized training and standardization [281]. Moreover, this pro-\ncess is prone to error and has the risk of introducing biases into the dataset\nwhich can significantly impact the performance of the trained model. One\nof the approaches to address this issue is transfer learning. Transfer learning\ninvolves the use of a deep learning model (known as pre-trained model) that\nis trained on a large dataset for solving a specific task (with a small dataset)\n[282].\nThe pre-trained model serves as a basis for the model training by\nfine-tuning the weights of the pre-trained model and adapting it to the new\nprediction task. This approach helps to mitigate the lack of training data\nin the target domain. Furthermore, transfer learning reduces computational\nresources required to train the model and helps faster convergence.\nAnother approach that can be employed to address the lack of data is data\naugmentation. Data augmentation is a convenient method that increases the\nnumber of instances by performing transformation functions on the existing\ninstances without changing the labels [283]. In the domain of computer vi-\nsion, image transformation such as rotation, translation and cropping. How-\never, it is important to consider the output of the transformation because the\nresultant may not represent the actual data. For example, flipping or adding\nnoise to a signal may introduce distortion or changing the characteristics\n60\n(trend, seasonality and cyclic variations) of the signal. Thus, careful consid-\neration must be given to ensure that the generated instances still accurately\nrepresent the underlying patterns present in the data. Data augmentation\ncan also be realized by generating synthetic data to supplement the training\nset. Synthetic data is artificially created data that resembles real data but\nis generated using statistical methods or deep generative models [284, 285].\nThe generated data can complement the less-diverse, limited datasets, pro-\nviding a broader range of examples for the model to learn from. However,\ngenerating synthetic data that accurately reflects the characteristics of the\nreal-world data is challenging. Careful consideration must be given to the\nchoice of models and parameters used to ensure the synthetic data is realistic\nand representative of the real-world data.\n5.2. Interpretability and Explainability\nInterpretability and explainability is crucial for building trust and un-\nderstanding how predictive models make decisions especially in high-stake\napplications such as healthcare and medical image analysis [286]. However,\nas deep learning models become more intricate and complex with numer-\nous layers, subnetworks and a large number of parameters, the models are\noften perceived as a “black box” and difficult to explain in terms of decision-\nmaking processes.\nTherefore, it is crucial for the researchers to focus on\nmethods that provide insights into how a deep learning model performs the\nprediction and how its decisions are influenced by the input data, making it\nmore transparent and trustworthy. Numerous methods have been proposed\nfor interpreting and explaining the decisions of deep learning models which\ncan be categorized into visualization (feature attribution), model distillation\nand intrinsic (explainable by itself). Visualization methods involve the use\nof scientific visualization such as saliency maps or heatmaps to express the\nexplanation by highlighting the degree of association between the inputs and\nthe predictions [287]. The heatmaps identify the saliency of the input features\ninfluencing the model’s predictions. The visualization approach is simple and\nintuitive and can be applied to tabular data and image data. Furthermore,\nit can be used to identify and debug issues in deep learning models, leading\nto improved performance and robustness.\nModel distillation is an approach to approximating a complex model by\nfitting a simpler model using the training set. The simpler model is built\ntypically using a simpler or interpretable algorithm such as linear regression,\ndecision tree or rule-based methods [288]. In this approach, the simpler model\n61\nis trained to resemble the predictive behavior of the complex model. Then,\nthe simpler model may serve as the proxy or surrogate model for explaining\nthe complex model.\nModel distillation can be used together with visual-\nization to further enhance the interpretability of the complex model [289].\nModel distillation seeks explanations of the models that were never designed\nto be explainable. Ideally, the explanation of a deep learning model’s predic-\ntion should be included as part of the model output, or the explanation can\nbe derived from the architecture of the model. This is because an intrinsic\nmodel can learn not only the mapping between the input and output, but\nalso generate an explanation of the prediction that is faithful to the model’s\nbehavior. Attention mechanisms are the key to this approach, providing a\nform of attention weights that can be used to explain why the model made\na particular decision [290]. Another type of intrinsic approach is to train\nthe model to simultaneously perform the prediction task and generate the\nexplanation for its predictions [291]. This “additional task” can be in the\nform of a text explanation or model prototype which embeds the semantic\nmeaning of the prediction. However, the intrinsic approach is more difficult\nto apply because the user needs additional knowledge and understanding of\nthe model’s architecture and inner workings.\n5.3. Ethics and Fairness\nDeep learning models are increasingly being deployed in making high-\nstake decision including recruitment [292], criminal justice [293] and credit\nscoring [294]. There are several advantages of deep learning-based systems\nin which, unlike humans, machines are able to process vast amounts of data\nand applications quickly and consistently. However, deep learning-based sys-\ntems have the risk of being prone to biases present in the data used for\ntraining which can lead to unfairness and injustice. Numerous efforts have\nbeen made to mitigate this issue which can be categorized into modelling\nbias detection and modelling bias mitigation. Detection of modelling bias\nrefers to the process of identifying and quantifying biases that may present\nin predictive models. This approach involves the use of statistical analysis,\nfairness metrics, counterfactual testing and human review to detect bias in\nthe models. For instance, visualization-based methods such as attribution\nmaps are used to indicate which regions are significant to the predictions\n[295]. This in turn can be used to detect and quantify bias using metrics\nsuch as Relevance Mass Accuracy, Relevance Rank Accuracy Accuracy and\nor Area over the perturbation curve (AOPC). In [296], two modules are pre-\n62\nsented for estimating bias in predictive models. The first module utilizes an\nunsupervised deep neural network with a custom loss function to generate\nhidden representation of the input data called bias vectors, revealing the un-\nderlying bias of each feature. The second module combines these bias vectors\ninto a single vector representing the bias estimation of each feature, achieved\nby aggregating them using the absolute averaging operation. Bias mitigation\nrefers to the process of reducing the presence of bias in predictive models,\nwhich can be done in three stages. The first stage combats bias by modifying\nthe training data, either relabeling the labels or perturbing the feature values\n[297, 298]. The second stage addresses bias during the training of the model\nby applying regularization terms to the loss function to penalize discrimina-\ntion. In [299], a loss function based on bias parity score (BPS) is introduced\nto measure the degree of similarity of a statistical measure such as accuracy\nacross different subgroups. The BPS term is added to the loss function as\na regularizer to the original prediction task. The last stage mitigates bias\nafter the predictive models have been successfully trained. This stage applies\npost-processing approaches such as reinforcement learning to obtain a fairer\nmodel [300]. For instance, the detection of minority classes is rewarded to\nprevent bias towards the majority class. This allows the model the generalize\nwell across different patient demographics.\n5.4. Lightweight Deep Learning Models\nEven though deep learning architectures have achieved state-of-the-art\nacross various computer vision tasks, they often come with large model pa-\nrameters [197]. The architecture and complexity of a deep learning network\ndetermine the number of model parameters. The deeper the network, the\nlarger the number of model parameters. However, deep learning models with\nlarge parameters often suffer limitations when deploying on end devices. For\ninstance, a deep learning model developed for security monitoring by analyz-\ning video data using 3D-CNNs might suffer deployment issues when deploying\nsuch models on low-resourced systems like smartphones or small-scale IoT\ndevices. Model training and inference for deep learning models with large\nparameters demands substantial processing power. As the number of pa-\nrameters increases, so does the computational complexity, resulting in longer\nmodel training duration and more hardware needs. Also, large parameter\nsizes translate to increased memory requirements, limiting their deployment\non end devices. This is because these end devices often have battery, pro-\ncessor or memory capacity limitations.\nTo address these challenges, it is\n63\nimportant to develop sophisticated but lightweight architectures that can\nachieve state-of-the-art with few model parameters. Such lightweight mod-\nels will be characterized by their ability to deliver competitive performance\nwhile mitigating computational complexity and memory requirements, mak-\ning them well-suited for deployment on resource-constrained devices.\nAn\napproach would be to develop novel lightweight plug-and-play modules that\ncan be plugged to few layered deep learning architectures to improve feature\nlearning without incurring additional model complexity. Other approaches\ncould involve leveraging model compression techniques to reduce the size\nand computational complexity of deep learning models. Researchers can fo-\ncus on improving pruning methods [301], which can identify and eliminate\nredundant parameters or connections, thereby reducing the model’s footprint\nwithout compromising performance. Also, quantization techniques [302] can\nbe further explored to reduce the precision of weights and activations, there-\nfore, enabling efficient representation with lower memory requirements. Also,\nknowledge distillation techniques [303] can be further investigated to facili-\ntate the transfer of knowledge from a complex teacher model to a simpler stu-\ndent model, therefore, enabling compact yet effective representations. These\nareas are still open to contributions.\n5.5. Adversarial Attack and Defense\nAdversarial attacks and defense mechanisms in deep learning represent\na critical area of research and development, particularly as deep learning\nmodels become increasingly integrated into various applications. Adversar-\nial attacks involves the deliberate manipulation of input data to mislead or\ndeceive deep learning models, leading to incorrect predictions or behavior\n[304]. Szegedy et al. [305] was the first to identify this intriguing shortcom-\ning of deep neural networks in image classification. They showed that even\nwith their great accuracy, deep learning models are surprisingly vulnerable\nto adversarial attacks that take the form of tiny image changes that are (al-\nmost) invisible to human vision systems. A neural network classifier may\nradically alter its prediction about an image as a result of such an attack.\nAlso, such a model can indicate high confidence in wrong predictions, which\ncan be catastrophic for deep learning models deployed in medical or secu-\nrity fields, among many others. In generative models, several studies have\ninvestigated how adversarial attacks affect autoencoders and GANs, as seen\nin Tabacof et al. [306] where a method to manipulate input images in a way\nthat deceives variational autoencoders into reconstructing a totally different\n64\nimage was introduced. In recent times, the focus of adversarial attack re-\nsearch has been on images, but studies has shown that adversarial attacks\nare not limited to image data; they can also affect other types of data such\nas text, signals, audio, and video [307, 308, 309].\n6. Summary and Future Directions\nWe have discussed the state-of-the-art applications and challenges of deep\nlearning in computer vision, natural language processing and time series anal-\nysis. In this section, we summarize the advancements made which can be\ngrouped into model architecture, contextual enhancement, and loss function\nand optimization. Finally, we discuss possible future works in these domains.\nModel Architecture: The recent advancements in computer vision fo-\ncus on vision transformers (ViT) for scalable representation learning [18]. In\nimage classification and image segmentation, ViTs are utilized to capture\nglobal context and relationships between different parts of an image, while\nin object detection, ViTs are used to streamline the detection process by\neliminating the traditional components like anchor boxes and non-maximum\nsuppression [?\n].\nHowever, ViTs lack the ability to exploit local spatial\nfeatures and struggle with hyperparameter sensitivity and performance on\nsmaller datasets. To address this issue, researchers have developed hybrid\ndeep learning architectures such as conformer [90] and MaxViT [91] that\ncombine both transformers and convolutional neural networks to capture\nboth local and global features.\nSimilar trend is observed in modern nat-\nural language processing whereby the basis of the deep learning models is\ntransformer architectures such as BERT [141] and its variants to achieve re-\nmarkable accuracy in tasks such as text classification, machine translation\nand text generation.\nWhile recent advancements in computer vision and natural language pro-\ncessing have predominantly relied on transformer architectures, the field of\ntime series analysis focuses on a different trajectory. Notably, areas such as\nhuman activity recognition, speech recognition and financial prediction have\nseen significant progress through the development of hybrid architectures\nthat do not depend on transformers. Instead, these advancements leverage\nrecurrent neural networks and convolutional neural networks, often incorpo-\nrating attention mechanisms. The hybrid architectures allow the models to\ncapture both local features and temporal dependencies in the data, which\nis crucial for time series analysis [196? ]. Similar trends can be observed\n65\nin ECG and EEG classification whereby not only convolutional and recur-\nrent neural networks are used, but also generative models such as variational\nautoencoder [268] and generative adversarial network to generate data to\naddress challenges posed by limited datasets and overfitting [252]. The gen-\nerator of the generative model is composed of layers of BiLSTM, while the\ndiscriminator is composed of convolutional neural networks.\nContextual Enhancement: Recent advancements in text classifica-\ntion focus on capturing contextual information utilizing approaches such as\njoint embeddings of labels [148] and words as well as aspect-aware methods\nthat enhance feature extraction [150]. Conversely, in machine translation,\nalthough transformers have proven effective, they often struggle to capture\nnuanced language features and contexts. To address this issue, various strate-\ngies have been introduced such as concatenating contextual sentences and\ncontext-sensitive training [158, 159]. In image generation, the researchers fo-\ncus on improving the quality and relevance of generated images by enhancing\nthe alignment between input text and images, while also addressing issues\nlike fuzzy shapes and diversity through innovative deep learning architec-\ntures such as incorporating attention mechanisms and fusion modules into\nthe model. Furthermore, recent models like DF-GAN [130] and DMF-GAN\n[131] showcase a shift towards single-stage generators with regularization\nstrategies that maintain details while enhancing diversity. In text genera-\ntion, BERT and its variants are the basis of the deep learning models. The\nresearch focuses on hierarchical architectures, capturing long text dependen-\ncies [171] and leveraging domain knowledge through label sequence [172] and\nconversation sequence [168] to bridge semantic gaps. Overall, the advance-\nments show a clear trend toward improving contextual awareness and feature\nrepresentation.\nLoss Function and Optimization: Researchers are increasingly fo-\ncused on refining loss functions to improve classification accuracy. For in-\nstance, in image classification, some studies introduce additive terms to the\ncross-entropy loss to reward well-classified instances [82], while others pro-\npose asymmetric polynomial loss functions that prioritize positive instances\nto tackle class imbalance [83] and adaptive loss function that dynamically\nadjust the weights assigned to class-level components based on model perfor-\nmance [310]. Another approach to address class imbalanced is data augmen-\ntation through generating virtual samples [311], oversampling with target-\naware autoencoders for estimating target values for new features [312]. In\ntime series analysis, similar approach has been proposed such as penalizing\n66\nmisclassification of minority classes [313], maximizing the minimum recall\nof the classes [314]. Improved training strategies have been proposed to ad-\ndress class imbalanced data such as iteratively selecting the most informative\ninstances [315] and contrastive learning to keep the instances of each fine-\ngrained clusters away from the minority class [316].\nFuture Directions: Looking ahead, the future of deep learning presents\nnumerous opportunities for growth and innovation.\nFuture models could\nexplore non-sequential hybrid architectures of transformer and convolutional\nneural networks to leverage the strengths of both approaches, enhancing per-\nformance in image classification, object detection and image segmentation.\nFurthermore, researchers could investigate simpler or lightweight architec-\ntures and new training schemes to address the long training time associ-\nated with transformers. Future research in image generation may explore\nadvanced frameworks or architectures that further integrate semantic un-\nderstanding, perhaps by employing hierarchical attention modules and/or\nfusion modules to capture both local and global features more effectively.\nAdditionally, incorporating unsupervised learning or self-supervised learn-\ning approaches could reduce reliance on labeled datasets, allowing models to\nlearn from a diverse range of inputs. In the area of natural language pro-\ncessing, future research in text classification and machine translation could\nexplore the integration of external knowledge bases and domain-specific em-\nbeddings may further improve context understanding and label alignment.\nAdditionally, refining context incorporation methods such as dynamic con-\ntext updating during translation may enhance the model performance.\nFuture research in image generation may explore advanced frameworks\nor architectures that further integrate semantic understanding, perhaps by\nemploying hierarchical attention modules and/or fusion modules to capture\nboth local and global features more effectively. Additionally, incorporating\nunsupervised learning or self-supervised learning approaches could reduce re-\nliance on labeled datasets, allowing models to learn from a diverse range of\ninputs. In text generation, advancing towards more interactive and adap-\ntive systems that can maintain context over extended dialogues and narra-\ntives is crucial. Furthermore, frameworks that can leverage multi-modalities\n(text, audio and visual) for richer contextual understanding may facilitate\nthe development of more advanced applications across these domains. Fu-\nture research can also focus on exploring adversarial attacks in these domains\nand developing tailored defence mechanisms. Also, researchers can further\ninvestigate the practical implications of adversarial attacks in real-world sce-\n67\nnarios, such as in autonomous vehicles and medical imaging. Understanding\nthe potential impact of adversarial attacks in these applications can inform\nthe development of more robust and secure systems.\nDue to the sensitive nature of financial research, future work can focus\non enhancing the interpretability of deep learning models in financial pre-\ndictions. Researchers should explore techniques to explain the predictions\nof models, to improve trust and understanding of model decisions, which is\nessential for adoption in human activity recognition, speech recognition and\nfinance. Furthermore, future models could explore the use of transformers to\nenhance feature representation for time series analysis. Future research can\nalso incorporate attention mechanisms into hybrid generative model archi-\ntectures to improve the quality of generated signals. Additionally, real-time\nprocessing capabilities are paramount, future work can develop efficient al-\ngorithms for real-time processing of ECG and EEG signals. This could in-\nvolve optimizing existing architectures and leveraging hardware acceleration\ntechniques to enable real-time inference on resource-constrained devices such\nas wearable sensors and implantable devices. Future models could explore\nmethods for adapting or personalizing models to account for inter-subject\nvariability and improve performance on individual subjects. Also, EEG elec-\ntrodes cover only a fraction of the brain’s surface, resulting in limited cover-\nage of neural activity. Deep learning models could investigate strategies to\ninfer activity from unobserved brain regions or integrate information from\nmultiple modalities to provide more comprehensive coverage. These areas\ncan still be further explored.\n7. Conclusion\nDeep learning has become the prominent data-driven approach in various\nstate-of-the-art applications. Its importance lies in its ability to revolution-\nize many aspects of research and industries and tackle complex problems\nwhich were once impossible to overcome. Numerous surveys have been pub-\nlished on deep learning, reviewing the concepts, model architectures and\napplications. However, the studies do not discuss the emerging trends in the\nstate-of-the-art applications of deep learning and emphasize the important\ntraits and elements in the models. This paper presents a structured and\ncomprehensive survey of deep learning, focusing on the latest trends and ad-\nvancements in state-of-the-art applications such as computer vision, natural\nlanguage processing, time series analysis and pervasive computing. It ex-\n68\nplores key elements and traits in modern deep learning models, highlighting\ntheir significance in addressing complex challenges across diverse domains.\nThe discussion also covers future research directions in advancing these fields.\nFurthermore, this paper presents a comprehensive review of the deep learning\nfundamentals, which is essential for understanding the core principles behind\nmodern deep learning models. The survey finishes by discussing the critical\nchallenges and future directions in deep learning.\nAcknowledgements\nThis work has been supported in part by the Ministry of Higher Educa-\ntion Malaysia for Fundamental Research Grant Scheme with Project Code:\nFRGS/1/2023/ICT02/USM/02/2.\nStatements and Declarations\n• Funding This work was supported by the Ministry of Higher Education\nMalaysia (FRGS/1/2023/ICT02/USM/02/2).\n• Competing Interests The authors declare that they have no known\ncompeting financial interests or personal relationships that could have\nappeared to influence the work reported in this paper.\n• Ethics approval Not applicable.\n• Availability of Data and Materials No data was used for the re-\nsearch described in the article.\nAppendix text.\nReferences\n[1] S. Shamshirband, M. Fathi, A. Dehzangi, A. T. Chronopoulos,\nH. Alinejad-Rokny, A review on deep learning approaches in health-\ncare systems: Taxonomies, challenges, and open issues 113 103627.\ndoi:10.1016/j.jbi.2020.103627.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1532046420302550\n69\n[2] J. Wang, Y. Ma, L. Zhang, R. X. Gao, D. Wu, Deep learning\nfor smart manufacturing:\nMethods and applications 48 144–156.\ndoi:10.1016/j.jmsy.2018.01.003.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0278612518300037\n[3] H. A. Pierson, M. S. Gashler, Deep learning in robotics:\na re-\nview of recent research 31 (16) 821–835, publisher: Taylor & Fran-\ncis eprint: https://doi.org/10.1080/01691864.2017.1365009. doi:10.\n1080/01691864.2017.1365009.\nURL https://doi.org/10.1080/01691864.2017.1365009\n[4] P. Dixit, S. Silakari, Deep Learning Algorithms for Cybersecu-\nrity Applications:\nA Technological and Status Review 39 100317.\ndoi:10.1016/j.cosrev.2020.100317.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1574013720304172\n[5] S. Dong, P. Wang, K. Abbas, A survey on deep learning and its appli-\ncations 40 100379, publisher: Elsevier.\n[6] T. Talaei Khoei, H. Ould Slimane, N. Kaabouch, Deep learning: Sys-\ntematic review, models, challenges, and research directions 35 (31)\n23103–23124, publisher: Springer.\n[7] L. Alzubaidi, J. Zhang, A. J. Humaidi, A. Al-Dujaili, Y. Duan, O. Al-\nShamma, J. Santamaria, M. A. Fadhel, M. Al-Amidie, L. Farhan, Re-\nview of deep learning: concepts, CNN architectures, challenges, appli-\ncations, future directions 8 1–74, publisher: Springer.\n[8] M. Z. Alom, T. M. Taha, C. Yakopcic, S. Westberg, P. Sidike, M. S.\nNasrin, M. Hasan, B. C. Van Essen, A. A. Awwal, V. K. Asari, A\nstate-of-the-art survey on deep learning theory and architectures 8 (3)\n292, publisher: Multidisciplinary Digital Publishing Institute.\n[9] S. Pouyanfar, S. Sadiq, Y. Yan, H. Tian, Y. Tao, M. P. Reyes, M.-L.\nShyu, S.-C. Chen, S. S. Iyengar, A survey on deep learning: Algorithms,\ntechniques, and applications 51 (5) 1–36, publisher: ACM New York,\nNY, USA.\n70\n[10] I. H. Sarker, Deep learning: a comprehensive overview on techniques,\ntaxonomy, applications and research directions 2 (6) 420, publisher:\nSpringer.\n[11] Y. LeCun, Y. Bengio, G. Hinton, Deep learning 521 (7553) 436–444,\nnumber: 7553 Publisher: Nature Publishing Group.\ndoi:10.1038/\nnature14539.\nURL https://www.nature.com/articles/nature14539\n[12] J. Hu, L. Shen, S. Albanie, G. Sun, E. Wu, Squeeze-and-Excitation Net-\nworks, arXiv:1709.01507 [cs] version: 4. doi:10.48550/arXiv.1709.\n01507.\nURL http://arxiv.org/abs/1709.01507\n[13] Z. Gao, J. Xie, Q. Wang, P. Li, Global Second-order Pooling Convo-\nlutional Networks, arXiv:1811.12006 [cs] version: 2. doi:10.48550/\narXiv.1811.12006.\nURL http://arxiv.org/abs/1811.12006\n[14] Q. Wang, B. Wu, P. Zhu, P. Li, W. Zuo, Q. Hu, ECA-Net:\nEf-\nficient Channel Attention for Deep Convolutional Neural Networks,\narXiv:1910.03151 [cs]. doi:10.48550/arXiv.1910.03151.\nURL http://arxiv.org/abs/1910.03151\n[15] Z. Liu, L. Wang, W. Wu, C. Qian, T. Lu, TAM: Temporal Adaptive\nModule for Video Recognition, arXiv:2005.06803 [cs]. doi:10.48550/\narXiv.2005.06803.\nURL http://arxiv.org/abs/2005.06803\n[16] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez,\nL. Kaiser,\nI. Polosukhin,\nAttention Is All You Need,\narXiv:1706.03762 [cs]. doi:10.48550/arXiv.1706.03762.\nURL http://arxiv.org/abs/1706.03762\n[17] O. Oktay, J. Schlemper, L. L. Folgoc, M. Lee, M. Heinrich, K. Mis-\nawa, K. Mori, S. McDonagh, N. Y. Hammerla, B. Kainz, B. Glocker,\nD. Rueckert, Attention U-Net: Learning Where to Look for the Pan-\ncreas, arXiv:1804.03999 [cs]. doi:10.48550/arXiv.1804.03999.\nURL http://arxiv.org/abs/1804.03999\n71\n[18] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,\nT. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly,\nJ. Uszkoreit, N. Houlsby, An Image is Worth 16x16 Words: Trans-\nformers for Image Recognition at Scale, arXiv:2010.11929 [cs]. doi:\n10.48550/arXiv.2010.11929.\nURL http://arxiv.org/abs/2010.11929\n[19] M.-H. Guo, Z.-N. Liu, T.-J. Mu, S.-M. Hu, Beyond Self-Attention:\nExternal Attention Using Two Linear Layers for Visual Tasks 45 (5)\n5436–5447, conference Name: IEEE Transactions on Pattern Analysis\nand Machine Intelligence. doi:10.1109/TPAMI.2022.3211006.\nURL https://ieeexplore.ieee.org/document/9912362\n[20] Y. A. LeCun,\nL. Bottou,\nG. B. Orr,\nK.-R. M¨uller,\nEfficient\nBackProp, Springer Berlin Heidelberg, pp. 9–48.\ndoi:10.1007/\n978-3-642-35289-8_3.\nURL https://doi.org/10.1007/978-3-642-35289-8_3\n[21] S. Hochreiter, Y. Bengio, P. Frasconi, J. Schmidhuber, et al., Gradient\nflow in recurrent nets: the difficulty of learning long-term dependencies,\nin: A Field Guide to Dynamical Recurrent Networks, A field guide to\ndynamical recurrent neural networks. IEEE Press In.\n[22] C. Dugas, Y. Bengio, F. B´elisle, C. Nadeau, R. Garcia, Incorporating\nSecond-Order Functional Knowledge for Better Option Pricing, in:\nAdvances in Neural Information Processing Systems, Vol. 13, MIT\nPress.\nURL\nhttps://papers.nips.cc/paper_files/paper/2000/hash/\n44968aece94f667e4095002d140b5896-Abstract.html\n[23] X. Glorot, A. Bordes, Y. Bengio, Deep Sparse Rectifier Neural Net-\nworks, in: Proceedings of the Fourteenth International Conference on\nArtificial Intelligence and Statistics, JMLR Workshop and Conference\nProceedings, pp. 315–323, iSSN: 1938-7228.\nURL https://proceedings.mlr.press/v15/glorot11a.html\n[24] A. L. Maas, A. Y. Hannun, A. Y. Ng, et al., Rectifier nonlinearities im-\nprove neural network acoustic models, in: Proc. icml, Vol. 30, Atlanta,\nGA, p. 3, issue: 1.\n72\n[25] D. Misra, Mish: A Self Regularized Non-Monotonic Activation Func-\ntion, arXiv:1908.08681 [cs, stat]. doi:10.48550/arXiv.1908.08681.\nURL http://arxiv.org/abs/1908.08681\n[26] D.-A. Clevert,\nT. Unterthiner,\nS. Hochreiter,\nFast and Accu-\nrate Deep Network Learning by Exponential Linear Units (ELUs),\narXiv:1511.07289 [cs]. doi:10.48550/arXiv.1511.07289.\nURL http://arxiv.org/abs/1511.07289\n[27] Q. Wang, Y. Ma, K. Zhao, Y. Tian, A Comprehensive Survey of\nLoss Functions in Machine Learning 9 (2) 187–212.\ndoi:10.1007/\ns40745-020-00253-5.\nURL https://doi.org/10.1007/s40745-020-00253-5\n[28] N. Qian, On the momentum term in gradient descent learning algo-\nrithms 12 (1) 145–151. doi:10.1016/S0893-6080(98)00116-6.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0893608098001166\n[29] J. Duchi, E. Hazan, Y. Singer, Adaptive Subgradient Methods for On-\nline Learning and Stochastic Optimization 12 (61) 2121–2159.\nURL http://jmlr.org/papers/v12/duchi11a.html\n[30] D. P. Kingma, J. Ba, Adam: A Method for Stochastic Optimization,\narXiv:1412.6980 [cs]. doi:10.48550/arXiv.1412.6980.\nURL http://arxiv.org/abs/1412.6980\n[31] L. Prechelt, Early Stopping — But When?, in: G. Montavon, G. B.\nOrr, K.-R. M¨uller (Eds.), Neural Networks: Tricks of the Trade: Second\nEdition, Lecture Notes in Computer Science, Springer, pp. 53–67. doi:\n10.1007/978-3-642-35289-8_5.\nURL https://doi.org/10.1007/978-3-642-35289-8_5\n[32] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdi-\nnov, Dropout: A Simple Way to Prevent Neural Networks from Over-\nfitting 15 (56) 1929–1958.\nURL http://jmlr.org/papers/v15/srivastava14a.html\n[33] S. Park, N. Kwak, Analysis on the Dropout Effect in Convolutional\nNeural Networks, in:\nS.-H. Lai, V. Lepetit, K. Nishino, Y. Sato\n73\n(Eds.), Computer Vision – ACCV 2016, Lecture Notes in Computer\nScience, Springer International Publishing, pp. 189–204. doi:10.1007/\n978-3-319-54184-6_12.\n[34] Z. Liu, Z. Xu, J. Jin, Z. Shen, T. Darrell, Dropout reduces underfit-\nting, in: Proceedings of the 40th International Conference on Machine\nLearning, Vol. 202 of ICML’23, JMLR.org, pp. 22233–22248.\n[35] R. Tibshirani, Regression Shrinkage and Selection via the Lasso 58 (1)\n267–288, publisher: [Royal Statistical Society, Wiley].\nURL https://www.jstor.org/stable/2346178\n[36] H. Zou, T. Hastie, Regularization and Variable Selection Via the Elastic\nNet 67 (2) 301–320. doi:10.1111/j.1467-9868.2005.00503.x.\nURL https://doi.org/10.1111/j.1467-9868.2005.00503.x\n[37] K. Nakamura, B.-W. Hong, Adaptive Weight Decay for Deep Neural\nNetworks 7 118857–118865, conference Name: IEEE Access. doi:10.\n1109/ACCESS.2019.2937139.\nURL https://ieeexplore.ieee.org/document/8811458\n[38] S. Ioffe, C. Szegedy, Batch normalization: accelerating deep network\ntraining by reducing internal covariate shift, in: Proceedings of the\n32nd International Conference on International Conference on Machine\nLearning - Volume 37, ICML’15, JMLR.org, pp. 448–456.\n[39] J. Ba, J. Kiros, G. E. Hinton, Layer Normalization.\nURL\nhttps://www.semanticscholar.org/\npaper/Layer-Normalization-Ba-Kiros/\n97fb4e3d45bb098e27e0071448b6152217bd35a5\n[40] G. Cybenko, Approximation by superpositions of a sigmoidal function\n2 (4) 303–314. doi:10.1007/BF02551274.\nURL https://doi.org/10.1007/BF02551274\n[41] K.\nHornik,\nM.\nStinchcombe,\nH.\nWhite,\nMultilayer\nfeedfor-\nward\nnetworks\nare\nuniversal\napproximators\n2\n(5)\n359–366.\ndoi:10.1016/0893-6080(89)90020-8.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\n0893608089900208\n74\n[42] B. Widrow, D. E. Rumelhart, M. A. Lehr, Neural networks:\nap-\nplications in industry, business and science 37 (3) 93–105.\ndoi:\n10.1145/175247.175257.\nURL https://dl.acm.org/doi/10.1145/175247.175257\n[43] S. Hochreiter, J. Schmidhuber, Long Short-Term Memory 9 (8) 1735–\n1780. doi:10.1162/neco.1997.9.8.1735.\nURL https://doi.org/10.1162/neco.1997.9.8.1735\n[44] K. Cho, B. van Merri¨enboer, C. Gulcehre, D. Bahdanau, F. Bougares,\nH. Schwenk, Y. Bengio, Learning Phrase Representations using RNN\nEncoder–Decoder for Statistical Machine Translation, in: A. Moschitti,\nB. Pang, W. Daelemans (Eds.), Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing (EMNLP), Asso-\nciation for Computational Linguistics, pp. 1724–1734. doi:10.3115/\nv1/D14-1179.\nURL https://aclanthology.org/D14-1179\n[45] X. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W.-k. Wong, W.-c. Woo,\nConvolutional LSTM Network:\nA Machine Learning Approach for\nPrecipitation Nowcasting, arXiv:1506.04214 [cs] version:\n2.\ndoi:\n10.48550/arXiv.1506.04214.\nURL http://arxiv.org/abs/1506.04214\n[46] A. Krizhevsky, I. Sutskever, G. E. Hinton, ImageNet Classification\nwith Deep Convolutional Neural Networks, in: Advances in Neural\nInformation Processing Systems, Vol. 25, Curran Associates, Inc.\nURL\nhttps://proceedings.neurips.cc/paper_files/paper/\n2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\n[47] K. Simonyan, A. Zisserman, Very Deep Convolutional Networks for\nLarge-Scale Image Recognition, arXiv:1409.1556 [cs] version: 6. doi:\n10.48550/arXiv.1409.1556.\nURL http://arxiv.org/abs/1409.1556\n[48] M. D. Zeiler, R. Fergus, Visualizing and Understanding Convolutional\nNetworks, arXiv:1311.2901 [cs] version:\n3.\ndoi:10.48550/arXiv.\n1311.2901.\nURL http://arxiv.org/abs/1311.2901\n75\n[49] M. Lin, Q. Chen, S. Yan, Network In Network, arXiv:1312.4400 [cs]\nversion: 3. doi:10.48550/arXiv.1312.4400.\nURL http://arxiv.org/abs/1312.4400\n[50] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Er-\nhan, V. Vanhoucke, A. Rabinovich, Going Deeper with Convolutions,\narXiv:1409.4842 [cs] version: 1. doi:10.48550/arXiv.1409.4842.\nURL http://arxiv.org/abs/1409.4842\n[51] R. K. Srivastava, K. Greff, J. Schmidhuber, Highway Networks,\narXiv:1505.00387 [cs]. doi:10.48550/arXiv.1505.00387.\nURL http://arxiv.org/abs/1505.00387\n[52] K. He, X. Zhang, S. Ren, J. Sun, Deep Residual Learning for Im-\nage Recognition, arXiv:1512.03385 [cs]. doi:10.48550/arXiv.1512.\n03385.\nURL http://arxiv.org/abs/1512.03385\n[53] G. Huang, Z. Liu, L. Van Der Maaten, K. Q. Weinberger, Densely con-\nnected convolutional networks, in: Proceedings of the IEEE conference\non computer vision and pattern recognition, pp. 4700–4708.\n[54] S.\nZagoruyko,\nN.\nKomodakis,\nWide\nResidual\nNetworks,\narXiv:1605.07146 [cs] version: 4. doi:10.48550/arXiv.1605.07146.\nURL http://arxiv.org/abs/1605.07146\n[55] S. Xie, R. Girshick, P. Doll´ar, Z. Tu, K. He, Aggregated Resid-\nual Transformations for Deep Neural Networks, arXiv:1611.05431 [cs].\ndoi:10.48550/arXiv.1611.05431.\nURL http://arxiv.org/abs/1611.05431\n[56] G. E. Hinton, A Practical Guide to Training Restricted Boltzmann Ma-\nchines, in: G. Montavon, G. B. Orr, K.-R. M¨uller (Eds.), Neural Net-\nworks: Tricks of the Trade: Second Edition, Lecture Notes in Computer\nScience, Springer, pp. 599–619. doi:10.1007/978-3-642-35289-8_\n32.\nURL https://doi.org/10.1007/978-3-642-35289-8_32\n[57] G. E. Hinton, S. Osindero, Y.-W. Teh, A Fast Learning Algorithm for\nDeep Belief Nets 18 (7) 1527–1554. doi:10.1162/neco.2006.18.7.\n76\n1527.\nURL https://doi.org/10.1162/neco.2006.18.7.1527\n[58] G.\nE.\nHinton,\nDeep\nbelief\nnetworks\n4\n(5)\n5947.\ndoi:\n10.4249/scholarpedia.5947.\nURL\nhttp://www.scholarpedia.org/article/Deep_belief_\nnetworks\n[59] J. Romero, J. P. Olson, A. Aspuru-Guzik, Quantum autoencoders for\nefficient compression of quantum data 2 (4) 045001, publisher: IOP\nPublishing. doi:10.1088/2058-9565/aa8072.\nURL https://dx.doi.org/10.1088/2058-9565/aa8072\n[60] X. Li, T. Zhang, X. Zhao, Z. Yi, Guided autoencoder for dimensionality\nreduction of pedestrian features 50 (12) 4557–4567.\ndoi:10.1007/\ns10489-020-01813-1.\nURL https://doi.org/10.1007/s10489-020-01813-1\n[61] M. H. Mohd Noor, Feature learning using convolutional denoising au-\ntoencoder for activity recognition 33 (17) 10909–10922. doi:10.1007/\ns00521-020-05638-4.\nURL https://doi.org/10.1007/s00521-020-05638-4\n[62] P.\nLi,\nY.\nPei,\nJ.\nLi,\nA\ncomprehensive\nsurvey\non\ndesign\nand\napplication\nof\nautoencoder\nin\ndeep\nlearning\n138\n110176.\ndoi:10.1016/j.asoc.2023.110176.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1568494623001941\n[63] A. Ng, et al., Sparse autoencoder 72 (2011) 1–19.\n[64] S. Rifai, G. Mesnil, P. Vincent, X. Muller, Y. Bengio, Y. Dauphin,\nX. Glorot, Higher Order Contractive Auto-Encoder, in: D. Gunopulos,\nT. Hofmann, D. Malerba, M. Vazirgiannis (Eds.), Machine Learning\nand Knowledge Discovery in Databases, Lecture Notes in Computer\nScience, Springer, pp. 645–660. doi:10.1007/978-3-642-23783-6_\n41.\n[65] P. Vincent, H. Larochelle, Y. Bengio, P.-A. Manzagol, Extracting\nand composing robust features with denoising autoencoders, in: Pro-\nceedings of the 25th international conference on Machine learning,\n77\nICML ’08, Association for Computing Machinery, pp. 1096–1103.\ndoi:10.1145/1390156.1390294.\nURL https://doi.org/10.1145/1390156.1390294\n[66] M. Chen, Z. Xu, K. Q. Weinberger, F. Sha, Marginalized denoising\nautoencoders for domain adaptation, in: Proceedings of the 29th Inter-\nnational Coference on International Conference on Machine Learning,\nICML’12, Omnipress, pp. 1627–1634.\n[67] D. P. Kingma, M. Welling, Auto-encoding variational bayes.\n[68] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,\nS. Ozair, A. Courville, Y. Bengio, Generative adversarial nets 27.\n[69] A. Odena, C. Olah, J. Shlens, Conditional image synthesis with aux-\niliary classifier gans, in: International conference on machine learning,\nPMLR, pp. 2642–2651.\n[70] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, P. Abbeel,\nInfoGAN: Interpretable Representation Learning by Information Max-\nimizing Generative Adversarial Nets, arXiv:1606.03657 [cs, stat] ver-\nsion: 1. doi:10.48550/arXiv.1606.03657.\nURL http://arxiv.org/abs/1606.03657\n[71] L. Weng, From GAN to WGAN, arXiv:1904.08994 [cs, stat].\ndoi:\n10.48550/arXiv.1904.08994.\nURL http://arxiv.org/abs/1904.08994\n[72] T. Karras, T. Aila, S. Laine, J. Lehtinen, Progressive Growing of GANs\nfor Improved Quality, Stability, and Variation, arXiv:1710.10196 [cs,\nstat] version: 3. doi:10.48550/arXiv.1710.10196.\nURL http://arxiv.org/abs/1710.10196\n[73] T. Karras, S. Laine, T. Aila, A Style-Based Generator Architecture for\nGenerative Adversarial Networks, arXiv:1812.04948 [cs, stat] version:\n3. doi:10.48550/arXiv.1812.04948.\nURL http://arxiv.org/abs/1812.04948\n[74] M. Tan, R. Pang, Q. V. Le, Efficientdet: Scalable and efficient object\ndetection, in: Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition (CVPR).\n78\n[75] D. W. Otter, J. R. Medina, J. K. Kalita, A survey of the usages of\ndeep learning for natural language processing 32 (2) 604–624. doi:\n10.1109/TNNLS.2020.2979670.\n[76] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo,\nK. Chou, C. Cui, G. Corrado, S. Thrun, J. Dean, A guide to deep\nlearning in healthcare 25 (1) 24–29.\n[77] M. Soori, B. Arezoo, R. Dastres, Artificial intelligence, machine learn-\ning and deep learning in advanced robotics, a review.\n[78] A. Hern´andez-Blanco, B. Herrera-Flores, D. Tom´as, B. Navarro-\nColorado, et al., A systematic review of deep learning approaches to\neducational data mining 2019.\n[79] Y. Lecun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning\napplied to document recognition 86 (11) 2278–2324, conference Name:\nProceedings of the IEEE. doi:10.1109/5.726791.\nURL https://ieeexplore.ieee.org/document/726791\n[80] P. Simard, D. Steinkraus, J. Platt, Best practices for convolutional\nneural networks applied to visual document analysis, in: Seventh In-\nternational Conference on Document Analysis and Recognition, 2003.\nProceedings., pp. 958–963. doi:10.1109/ICDAR.2003.1227801.\nURL https://ieeexplore.ieee.org/document/1227801\n[81] M. Matsugu, K. Mori, Y. Mitari, Y. Kaneda, Subject indepen-\ndent facial expression recognition with robust face detection using\na convolutional neural network 16 (5-6) 555–559.\ndoi:10.1016/\nS0893-6080(03)00115-1.\n[82] G. Zhao, W. Yang, X. Ren, L. Li, Y. Wu, X. Sun, Well-classified exam-\nples are underestimated in classification with deep neural networks, in:\nProceedings of the AAAI Conference on Artificial Intelligence, Vol. 36,\npp. 9180–9189, issue: 8.\n[83] Y. Huang, J. Qi, X. Wang, Z. Lin, Asymmetric Polynomial Loss for\nMulti-Label Classification, in: ICASSP 2023-2023 IEEE International\nConference on Acoustics, Speech and Signal Processing (ICASSP),\nIEEE, pp. 1–5.\n79\n[84] W. Park, I. Park, S. Kim, J. Ryu, Robust Asymmetric Loss for\nMulti-Label Long-Tailed Learning, pp. 2711–2720.\nURL\nhttps://openaccess.thecvf.com/content/ICCV2023W/\nCVAMD/html/Park_Robust_Asymmetric_Loss_for_Multi-Label_\nLong-Tailed_Learning_ICCVW_2023_paper.html\n[85] L. Nanni, A. Loreggia, L. Barcellona, S. Ghidoni, Building Ensemble of\nDeep Networks: Convolutional Networks and Transformers 11 124962–\n124974, conference Name: IEEE Access. doi:10.1109/ACCESS.2023.\n3330442.\nURL https://ieeexplore.ieee.org/document/10309107\n[86] M. Wortsman, G. Ilharco, S. Y. Gadre, R. Roelofs, R. Gontijo-Lopes,\nA. S. Morcos, H. Namkoong, A. Farhadi, Y. Carmon, S. Kornblith,\net al., Model soups: averaging weights of multiple fine-tuned models\nimproves accuracy without increasing inference time, in: International\nConference on Machine Learning, PMLR, pp. 23965–23998.\n[87] C. Loh, S. Han, S. Sudalairaj, R. Dangovski, K. Xu, F. Wenzel, M. Sol-\njacic, A. Srivastava, Multi-Symmetry Ensembles: Improving Diversity\nand Generalization via Opposing Symmetries.\n[88] T. Xiao, M. Singh, E. Mintun, T. Darrell, P. Doll´ar, R. Girshick, Early\nconvolutions help transformers see better 34 30392–30400.\n[89] H. Wu, B. Xiao, N. Codella, M. Liu, X. Dai, L. Yuan, L. Zhang, CvT:\nIntroducing Convolutions to Vision Transformers, in: 2021 IEEE/CVF\nInternational Conference on Computer Vision (ICCV), pp. 22–31,\niSSN: 2380-7504. doi:10.1109/ICCV48922.2021.00009.\nURL https://ieeexplore.ieee.org/document/9710031?denied=\n[90] Z. Peng, Z. Guo, W. Huang, Y. Wang, L. Xie, J. Jiao, Q. Tian,\nQ. Ye, Conformer: Local Features Coupling Global Representations\nfor Recognition and Detection 45 (8) 9454–9468, conference Name:\nIEEE Transactions on Pattern Analysis and Machine Intelligence.\ndoi:10.1109/TPAMI.2023.3243048.\nURL https://ieeexplore.ieee.org/document/10040235\n[91] Z. Tu, H. Talebi, H. Zhang, F. Yang, P. Milanfar, A. Bovik, Y. Li,\nMaxViT: Multi-axis Vision Transformer, in: S. Avidan, G. Brostow,\n80\nM. Ciss´e, G. M. Farinella, T. Hassner (Eds.), Computer Vision – ECCV\n2022, Lecture Notes in Computer Science, Springer Nature Switzerland,\npp. 459–479. doi:10.1007/978-3-031-20053-3_27.\n[92] Y. Ma, R. Wang, M. Zong, W. Ji, Y. Wang, B. Ye, Convolutional\ntransformer network for fine-grained action recognition 569 127027.\ndoi:10.1016/j.neucom.2023.127027.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0925231223011505\n[93] R. Girshick, J. Donahue, T. Darrell, J. Malik, Rich Feature Hierarchies\nfor Accurate Object Detection and Semantic Segmentation, pp. 580–\n587.\nURL https://openaccess.thecvf.com/content_cvpr_2014/html/\nGirshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html\n[94] R. Girshick, Fast R-CNN, in: 2015 IEEE International Conference\non Computer Vision (ICCV), pp. 1440–1448, iSSN: 2380-7504. doi:\n10.1109/ICCV.2015.169.\nURL https://ieeexplore.ieee.org/document/7410526\n[95] S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: Towards Real-Time\nObject Detection with Region Proposal Networks, in: Advances in\nNeural Information Processing Systems, Vol. 28, Curran Associates,\nInc.\nURL\nhttps://proceedings.neurips.cc/paper_files/paper/\n2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html\n[96] J. Redmon, S. Divvala, R. Girshick, A. Farhadi, You Only Look Once:\nUnified, Real-Time Object Detection, pp. 779–788.\nURL\nhttps://www.cv-foundation.org/openaccess/content_\ncvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html\n[97] J. Redmon, A. Farhadi, Yolov3: An incremental improvement.\n[98] A. Bochkovskiy, C.-Y. Wang, H.-Y. M. Liao, Yolov4: Optimal speed\nand accuracy of object detection.\n[99] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, A. C.\nBerg, SSD: Single Shot MultiBox Detector, in: B. Leibe, J. Matas,\n81\nN. Sebe, M. Welling (Eds.), Computer Vision – ECCV 2016, Lecture\nNotes in Computer Science, Springer International Publishing, pp. 21–\n37. doi:10.1007/978-3-319-46448-0_2.\n[100] T.-Y. Lin, P. Goyal, R. Girshick, K. He, P. Doll´ar, Focal Loss for Dense\nObject Detection 42 (2) 318–327, conference Name: IEEE Transactions\non Pattern Analysis and Machine Intelligence. doi:10.1109/TPAMI.\n2018.2858826.\nURL https://ieeexplore.ieee.org/document/8417976\n[101] T.-Y. Lin, P. Doll´ar, R. Girshick, K. He, B. Hariharan, S. Belongie,\nFeature pyramid networks for object detection, in: Proceedings of the\nIEEE conference on computer vision and pattern recognition, pp. 2117–\n2125.\n[102] M. Tan, R. Pang, Q. V. Le, Efficientdet: Scalable and efficient object\ndetection, in: Proceedings of the IEEE/CVF conference on computer\nvision and pattern recognition, pp. 10781–10790.\n[103] M. Tan, Q. Le, EfficientNet: Rethinking model scaling for convolu-\ntional neural networks, in: International conference on machine learn-\ning, PMLR, pp. 6105–6114.\n[104] N. Bodla, B. Singh, R. Chellappa, L. S. Davis, Soft-NMS–improving\nobject detection with one line of code, in: Proceedings of the IEEE\ninternational conference on computer vision, pp. 5561–5569.\n[105] S. Liu, D. Huang, Y. Wang, Adaptive NMS: Refining pedestrian de-\ntection in a crowd, in: Proceedings of the IEEE/CVF conference on\ncomputer vision and pattern recognition, pp. 6459–6468.\n[106] N. Carion,\nF. Massa,\nG. Synnaeve,\nN. Usunier,\nA. Kirillov,\nS. Zagoruyko, End-to-End Object Detection with Transformers, in:\nA. Vedaldi, H. Bischof, T. Brox, J.-M. Frahm (Eds.), Computer Vision\n– ECCV 2020, Lecture Notes in Computer Science, Springer Interna-\ntional Publishing, pp. 213–229. doi:10.1007/978-3-030-58452-8\\\n_13.\n[107] X. Zhu, W. Su, L. Lu, B. Li, X. Wang, J. Dai, Deformable DETR:\nDeformable transformers for end-to-end object detection.\n82\n[108] X. Dai, Y. Chen, J. Yang, P. Zhang, L. Yuan, L. Zhang, Dynamic\nDETR: End-to-End Object Detection With Dynamic Attention, pp.\n2988–2997.\nURL\nhttps://openaccess.thecvf.com/content/ICCV2021/html/\nDai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_\nAttention_ICCV_2021_paper.html\n[109] L. Huang, K. Lu, G. Song, L. Wang, S. Liu, Y. Liu, H. Li, Teach-\nDETR: Better Training DETR With Teachers 45 (12) 15759–15771,\nconference Name: IEEE Transactions on Pattern Analysis and Machine\nIntelligence. doi:10.1109/TPAMI.2023.3319387.\nURL https://ieeexplore.ieee.org/document/10264211\n[110] J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for\nsemantic segmentation, in: Proceedings of the IEEE conference on\ncomputer vision and pattern recognition, pp. 3431–3440.\n[111] H. Noh, S. Hong, B. Han, Learning deconvolution network for semantic\nsegmentation, in: Proceedings of the IEEE international conference on\ncomputer vision, pp. 1520–1528.\n[112] V. Badrinarayanan, A. Kendall, R. Cipolla, Segnet: A deep convo-\nlutional encoder-decoder architecture for image segmentation 39 (12)\n2481–2495, publisher: IEEE.\n[113] A. Chaurasia, E. Culurciello, Linknet: Exploiting encoder representa-\ntions for efficient semantic segmentation, in: 2017 IEEE visual com-\nmunications and image processing (VCIP), IEEE, pp. 1–4.\n[114] K. He, G. Gkioxari, P. Doll´ar, R. Girshick, Mask R-CNN, in: Pro-\nceedings of the IEEE international conference on computer vision, pp.\n2961–2969.\n[115] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for in-\nstance segmentation, in: Proceedings of the IEEE conference on com-\nputer vision and pattern recognition, pp. 8759–8768.\n[116] L.-C. Chen, A. Hermans, G. Papandreou, F. Schroff, P. Wang,\nH. Adam, MaskLab: Instance segmentation by refining object detec-\ntion with semantic and direction features, in: Proceedings of the IEEE\nconference on computer vision and pattern recognition, pp. 4013–4022.\n83\n[117] Q. Liu, Y. Dong, X. Li, Multi-stage context refinement network for\nsemantic segmentation 535 53–63. doi:10.1016/j.neucom.2023.03.\n006.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0925231223002254\n[118] Y. Liu, Y. Chen, P. Lasang, Q. Sun, Covariance Attention for Semantic\nSegmentation 44 (4) 1805–1818, conference Name: IEEE Transactions\non Pattern Analysis and Machine Intelligence. doi:10.1109/TPAMI.\n2020.3026069.\nURL https://ieeexplore.ieee.org/document/9206128\n[119] R. Strudel, R. Garcia, I. Laptev, C. Schmid, Segmenter: Transformer\nfor semantic segmentation, in: Proceedings of the IEEE/CVF interna-\ntional conference on computer vision, pp. 7262–7272.\n[120] A. Hatamizadeh, H. Yin, G. Heinrich, J. Kautz, P. Molchanov, Global\ncontext vision transformers, in: International Conference on Machine\nLearning, PMLR, pp. 12633–12646.\n[121] H. Shi, M. Hayat, J. Cai, Transformer scale gate for semantic segmen-\ntation, in: Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition, pp. 3051–3060.\n[122] A. Radford, L. Metz, S. Chintala, Unsupervised representation learning\nwith deep convolutional generative adversarial networks.\n[123] H. Zhang, T. Xu, H. Li, S. Zhang, X. Wang, X. Huang, D. N. Metaxas,\nStackGAN: Text to photo-realistic image synthesis with stacked gener-\native adversarial networks, in: Proceedings of the IEEE international\nconference on computer vision, pp. 5907–5915.\n[124] H. Zhang, T. Xu, H. Li, S. Zhang, X. Wang, X. Huang, D. N. Metaxas,\nStackGAN++: Realistic image synthesis with stacked generative ad-\nversarial networks 41 (8) 1947–1962, publisher: IEEE.\n[125] Z. Zhang, Y. Xie, L. Yang, Photographic text-to-image synthesis with a\nhierarchically-nested adversarial network, in: Proceedings of the IEEE\nconference on computer vision and pattern recognition, pp. 6199–6208.\n84\n[126] M. Zhu, P. Pan, W. Chen, Y. Yang, DM-GAN: Dynamic memory gener-\native adversarial networks for text-to-image synthesis, in: Proceedings\nof the IEEE/CVF conference on computer vision and pattern recogni-\ntion, pp. 5802–5810.\n[127] T. Xu, P. Zhang, Q. Huang, H. Zhang, Z. Gan, X. Huang, X. He,\nAttnGAN: Fine-grained text to image generation with attentional gen-\nerative adversarial networks, in: Proceedings of the IEEE conference\non computer vision and pattern recognition, pp. 1316–1324.\n[128] J. Sun, Y. Zhou, B. Zhang, ResFPA-GAN: Text-to-image synthesis\nwith generative adversarial network based on residual block feature\npyramid attention, in: 2019 IEEE International Conference on Ad-\nvanced Robotics and its Social Impacts (ARSO), IEEE, pp. 317–322.\n[129] Y. Cai, X. Wang, Z. Yu, F. Li, P. Xu, Y. Li, L. Li, Dualattn-GAN:\nText to Image Synthesis With Dual Attentional Generative Adversarial\nNetwork 7 183706–183716, conference Name: IEEE Access. doi:10.\n1109/ACCESS.2019.2958864.\nURL https://ieeexplore.ieee.org/document/8930532?denied=\n[130] M. Tao, H. Tang, F. Wu, X.-Y. Jing, B.-K. Bao, C. Xu, DF-GAN: A\nsimple and effective baseline for text-to-image synthesis, in: Proceed-\nings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, pp. 16515–16525.\n[131] B. Yang, X. Xiang, W. Kong, J. Zhang, Y. Peng, DMF-GAN: Deep\nMultimodal Fusion Generative Adversarial Networks for Text-to-Image\nSynthesis 1–13Conference Name: IEEE Transactions on Multimedia.\ndoi:10.1109/TMM.2024.3358086.\nURL https://ieeexplore.ieee.org/document/10413630\n[132] B. Jiang, W. Zeng, C. Yang, R. Wang, B. Zhang, DE-GAN: Text-\nto-image synthesis with dual and efficient fusion model 83 (8) 23839–\n23852. doi:10.1007/s11042-023-16377-8.\nURL https://doi.org/10.1007/s11042-023-16377-8\n[133] R. A. Calvo, H. A. Ceccatto, Intelligent document classification 4 (5)\n411–420, publisher: IOS Press. doi:10.3233/IDA-2000-4503.\n85\nURL\nhttps://content.iospress.com/articles/\nintelligent-data-analysis/ida00028\n[134] B.\nYu,\nZ.-b.\nXu,\nC.-h.\nLi,\nLatent\nsemantic\nanalysis\nfor\ntext\ncategorization\nusing\nneural\nnetwork\n21\n(8)\n900–904.\ndoi:10.1016/j.knosys.2008.03.045.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0950705108000993\n[135] G. Arevian, Recurrent Neural Networks for Robust Real-World Text\nClassification, in: IEEE/WIC/ACM International Conference on Web\nIntelligence (WI’07), pp. 326–329. doi:10.1109/WI.2007.126.\nURL https://ieeexplore.ieee.org/abstract/document/4427112\n[136] J. Huang, Y. Feng, Optimization of Recurrent Neural Networks on\nNatural Language Processing, in: Proceedings of the 2019 8th In-\nternational Conference on Computing and Pattern Recognition, IC-\nCPR ’19, Association for Computing Machinery, pp. 39–45.\ndoi:\n10.1145/3373509.3373573.\nURL https://dl.acm.org/doi/10.1145/3373509.3373573\n[137] R. Wang, Z. Li, J. Cao, T. Chen, L. Wang, Convolutional Recurrent\nNeural Networks for Text Classification, in: 2019 International Joint\nConference on Neural Networks (IJCNN), pp. 1–6, iSSN: 2161-4407.\ndoi:10.1109/IJCNN.2019.8852406.\nURL https://ieeexplore.ieee.org/document/8852406\n[138] G.\nLiu,\nJ.\nGuo,\nBidirectional\nLSTM\nwith\nattention\nmecha-\nnism and convolutional layer for text classification 337 325–338.\ndoi:10.1016/j.neucom.2019.01.078.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0925231219301067\n[139] Z. Lin, M. Feng, C. N. d. Santos, M. Yu, B. Xiang, B. Zhou, Y. Bengio,\nA structured self-attentive sentence embedding.\n[140] W. Li, F. Qi, M. Tang, Z. Yu, Bidirectional LSTM with self-attention\nmechanism and multi-channel features for sentiment classification 387\n63–77. doi:10.1016/j.neucom.2020.01.006.\n86\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0925231220300254\n[141] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, BERT: Pre-training\nof deep bidirectional transformers for language understanding.\n[142] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, R. Soricut,\nALBERT: A lite bert for self-supervised learning of language represen-\ntations.\n[143] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,\nL. Zettlemoyer, V. Stoyanov, RoBERTa: A robustly optimized bert\npretraining approach.\n[144] P. He, X. Liu, J. Gao, W. Chen, DeBERTa: Decoding-enhanced bert\nwith disentangled attention.\n[145] B.\nRodrawangpai,\nW.\nDaungjaiboon,\nImproving\ntext\nclassifi-\ncation\nwith\ntransformers\nand\nlayer\nnormalization\n10\n100403.\ndoi:10.1016/j.mlwa.2022.100403.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS2666827022000792\n[146] H. Murfi, Syamsyuriani, T. Gowandi, G. Ardaneswari, S. Nur-\nrohmah, BERT-based combination of convolutional and recurrent\nneural\nnetwork\nfor\nindonesian\nsentiment\nanalysis\n151\n111112.\ndoi:10.1016/j.asoc.2023.111112.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1568494623011304\n[147] S. Hao, P. Zhang, S. Liu, Y. Wang, Sentiment recognition and analysis\nmethod of official document text based on BERT–SVM model 35 (35)\n24621–24632. doi:10.1007/s00521-023-08226-4.\nURL https://doi.org/10.1007/s00521-023-08226-4\n[148] G. Wang, C. Li, W. Wang, Y. Zhang, D. Shen, X. Zhang, R. Henao,\nL. Carin, Joint embedding of words and labels for text classification.\n[149] Y. Yan, F. Liu, X. Zhuang, J. Ju, An R-Transformer bilstm Model\nBased on Attention for Multi-label Text Classification 55 (2) 1293–\n1316. doi:10.1007/s11063-022-10938-y.\nURL https://doi.org/10.1007/s11063-022-10938-y\n87\n[150] X. Zhu, Y. Zhu, L. Zhang, Y. Chen, A BERT-based multi-semantic\nlearning model with aspect-aware enhancement for aspect polarity clas-\nsification 53 (4) 4609–4623. doi:10.1007/s10489-022-03702-1.\nURL https://doi.org/10.1007/s10489-022-03702-1\n[151] I. Sutskever, O. Vinyals, Q. V. Le, Sequence to sequence learning with\nneural networks 27.\n[152] F. Stahlberg, Neural machine translation: A review 69 343–418.\n[153] D. Bahdanau, K. Cho, Y. Bengio, Neural machine translation by jointly\nlearning to align and translate.\n[154] M.-T. Luong, H. Pham, C. D. Manning, Effective approaches to\nattention-based neural machine translation.\n[155] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey,\nM. Krikun, Y. Cao, Q. Gao, K. Macherey, et al., Google’s neural ma-\nchine translation system: Bridging the gap between human and ma-\nchine translation.\n[156] L. Lupo, M. Dinarelli, L. Besacier, Encoding Sentence Position in\nContext-Aware Neural Machine Translation with Concatenation.\n[157] E. Rippeth, M. Carpuat, K. Duh, M. Post, Improving Word Sense\nDisambiguation in Neural Machine Translation with Salient Document\nContext.\n[158] X. Wu, Y. Xia, J. Zhu, L. Wu, S. Xie, T. Qin, A study of BERT for\ncontext-aware neural machine translation 111 (3) 917–935, publisher:\nSpringer.\n[159] D. Kim, Y. Baek, S. Yang, J. Choo, Towards Formality-Aware Neural\nMachine Translation by Leveraging Context Information, in: Findings\nof the Association for Computational Linguistics: EMNLP 2023, pp.\n7384–7392.\n[160] A. M. Gezmu, A. N¨urnberger, Transformers for Low-resource Neural\nMachine Translation., in: ICAART (1), pp. 459–466.\n88\n[161] A. Araabi, C. Monz, Optimizing Transformer for Low-Resource Neural\nMachine Translation, in: D. Scott, N. Bel, C. Zong (Eds.), Proceedings\nof the 28th International Conference on Computational Linguistics,\nInternational Committee on Computational Linguistics, pp. 3429–3435.\ndoi:10.18653/v1/2020.coling-main.304.\nURL https://aclanthology.org/2020.coling-main.304\n[162] B. Li, Y. Weng, F. Xia, H. Deng, Towards better Chinese-centric neural\nmachine translation for low-resource languages 84 101566, publisher:\nElsevier.\n[163] L. S. Meetei, A. Singh, T. D. Singh, S. Bandyopadhyay, Do cues in\na video help in handling rare words in a machine translation system\nunder a low-resource setting? 3 100016, publisher: Elsevier.\n[164] Y.-p. Nie, Y. Han, J.-m. Huang, B. Jiao, A.-p. Li, Attention-based\nencoder-decoder model for answer selection in question answering\n18 (4) 535–544, publisher: Springer.\n[165] J. Yin, X. Jiang, Z. Lu, L. Shang, H. Li, X. Li, Neural generative\nquestion answering.\n[166] J. Li, W. Monroe, A. Ritter, M. Galley, J. Gao, D. Jurafsky, Deep\nreinforcement learning for dialogue generation.\n[167] J. Wu, T. Mu, J. Thiyagalingam, J. Y. Goulermas, Building interactive\nsentence-aware representation based on generative language model for\ncommunity question answering 389 93–107, publisher: Elsevier.\n[168] Z. Li, C. Niu, F. Meng, Y. Feng, Q. Li, J. Zhou, Incremental trans-\nformer with deliberation decoder for document grounded conversations.\n[169] S. Alrowili, K. Vijay-Shanker, BioM-transformers:\nbuilding large\nbiomedical language models with BERT, ALBERT and ELECTRA,\nin: Proceedings of the 20th workshop on biomedical language process-\ning, pp. 221–227.\n[170] S. Alrowili, K. Vijay-Shanker, Exploring Biomedical Question Answer-\ning with BioM-Transformers At BioASQ10B challenge: Findings and\nTechniques., in: CLEF (Working Notes), pp. 222–234.\n89\n[171] T. Ma, Q. Pan, H. Rong, Y. Qian, Y. Tian, N. Al-Nabhan, T-\nBERTSum: Topic-aware text summarization based on bert 9 (3) 879–\n890, publisher: IEEE.\n[172] Q. Xie, J. A. Bishop, P. Tiwari, S. Ananiadou, Pre-trained language\nmodels with domain knowledge for biomedical extractive summariza-\ntion 252 109460, publisher: Elsevier.\n[173] M. Weiser, The computer for the 21 st century 265 (3) 94–105.\n[174] Y. He, S. Nazir, B. Nie, S. Khan, J. Zhang, Developing an efficient\ndeep learning-based trusted model for pervasive computing using an\nlstm-based classification model 2020 1–6.\n[175] A. O. Ige, M. H. M. Noor, A survey on unsupervised learning for wear-\nable sensor-based activity recognition 109363.\n[176] R. Singh, S. Srivastava, Stock prediction using deep learning 76 18569–\n18584.\n[177] X. Zhang, Y. Han, W. Xu, Q. Wang, Hoba: A novel feature engineer-\ning methodology for credit card fraud detection with a deep learning\narchitecture 557 302–316.\n[178] Y. Lei, Q. Peng, Y. Shen, Deep learning for algorithmic trading: en-\nhancing macd strategy, in: Proceedings of the 2020 6th International\nConference on Computing and Artificial Intelligence, pp. 51–57.\n[179] H.-B. Zhang, Y.-X. Zhang, B. Zhong, Q. Lei, L. Yang, J.-X. Du, D.-S.\nChen, A comprehensive survey of vision-based human action recogni-\ntion methods 19 (5) 1005.\n[180] L. M. Dang, K. Min, H. Wang, M. J. Piran, C. H. Lee, H. Moon, Sensor-\nbased and vision-based human activity recognition: A comprehensive\nsurvey 108 107561.\n[181] W. Gao, L. Zhang, Q. Teng, J. He, H. Wu, Danhar: Dual attention net-\nwork for multimodal human activity recognition using wearable sensors\n111 107728.\n[182] S. Gupta, Deep learning based human activity recognition (har) using\nwearable sensor data 1 (2) 100046.\n90\n[183] C. B. Erdas, S. Guney, Human activity recognition by using different\ndeep learning approaches for wearable sensors 53 1795–1809.\n[184] M. G. Ragab, S. J. Abdulkadir, N. Aziz, Random search one dimen-\nsional cnn for human activity recognition, in: 2020 International Con-\nference on Computational Intelligence (ICCI), IEEE, pp. 86–91.\n[185] K. Banjarey, S. P. Sahu, D. K. Dewangan, Human activity recognition\nusing 1d convolutional neural network, in: Sentimental Analysis and\nDeep Learning: Proceedings of ICSADL 2021, Springer, pp. 691–702.\n[186] M. M. H. Shuvo, N. Ahmed, K. Nouduri, K. Palaniappan, A hybrid\napproach for human activity recognition with support vector machine\nand 1d convolutional neural network, in: 2020 IEEE Applied Imagery\nPattern Recognition Workshop (AIPR), IEEE, pp. 1–5.\n[187] C. Han, L. Zhang, Y. Tang, W. Huang, F. Min, J. He, Human activ-\nity recognition using wearable sensors by heterogeneous convolutional\nneural networks 198 116764.\n[188] A. O. Ige, M. H. M. Noor, Wsense: A robust feature learning module\nfor lightweight human activity recognition.\n[189] S. Deep, X. Zheng, Hybrid model featuring cnn and lstm architecture\nfor human activity recognition on smartphone sensor data, in: 2019\n20th international conference on parallel and distributed computing,\napplications and technologies (PDCAT), IEEE, pp. 259–264.\n[190] Y. J. Luwe, C. P. Lee, K. M. Lim, Wearable sensor-based human ac-\ntivity recognition with hybrid deep learning model, in: Informatics,\nVol. 9, MDPI, p. 56.\n[191] L.-F. Shi, Z.-Y. Liu, K.-J. Zhou, Y. Shi, X. Jing, Novel deep learning\nnetwork for gait recognition using multimodal inertial sensors 23 (2)\n849.\n[192] N. Dua, S. N. Singh, V. B. Semwal, S. K. Challa, Inception inspired\ncnn-gru hybrid network for human activity recognition 82 (4) 5369–\n5403.\n91\n[193] H. A. Imran, Q. Riaz, M. Hussain, H. Tahir, R. Arshad, Smart-wearable\nsensors and cnn-bigru model: A powerful combination for human ac-\ntivity recognition.\n[194] D. Chen, S. Yongchareon, E. M.-K. Lai, J. Yu, Q. Z. Sheng, Y. Li,\nTransformer with bidirectional gru for nonintrusive, sensor-based ac-\ntivity recognition in a multiresident environment 9 (23) 23716–23727.\n[195] O. Nafea, W. Abdul, G. Muhammad, M. Alsulaiman, Sensor-based\nhuman activity recognition with spatio-temporal deep learning 21 (6)\n2141.\n[196] Z. N. Khan, J. Ahmad, Attention induced multi-head convolutional\nneural network for human activity recognition 110 107671.\n[197] A. O. Ige, M. H. Mohd Noor, A deep local-temporal architecture\nwith attention for lightweight human activity recognition 149 110954.\ndoi:https://doi.org/10.1016/j.asoc.2023.110954.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1568494623009729\n[198] A. B. Nassif, I. Shahin, I. Attili, M. Azzeh, K. Shaalan, Speech recogni-\ntion using deep neural networks: A systematic review 7 19143–19165.\ndoi:10.1109/ACCESS.2019.2896880.\n[199] S. S. Tirumala, S. R. Shahamiri, A review on deep learning approaches\nin speaker identification, in: Proceedings of the 8th International Con-\nference on Signal Processing Systems, Association for Computing Ma-\nchinery, pp. 142–147. doi:10.1145/3015166.3015210.\nURL https://doi.org/10.1145/3015166.3015210\n[200] F. Ye, J. Yang, A deep neural network model for speaker identification\n11 (8). doi:10.3390/app11083603.\nURL https://www.mdpi.com/2076-3417/11/8/3603\n[201] R. A. Khalil, E. Jones, M. I. Babar, T. Jan, M. H. Zafar, T. Alhussain,\nSpeech emotion recognition using deep learning techniques: A review\n7 117327–117345. doi:10.1109/ACCESS.2019.2936124.\n[202] G. Singh, S. Sharma, V. Kumar, M. Kaur, M. Baz, M. Masud, et al.,\nSpoken language identification using deep learning 2021.\n92\n[203] Y. Jiao, M. Tu, V. Berisha, J. M. Liss, Accent identification by com-\nbining deep neural networks and recurrent neural networks trained on\nlong and short term features., in: Interspeech, pp. 2388–2392.\n[204] H. A. S´anchez-Hevia, R. Gil-Pita, M. Utrilla-Manso, M. Rosa-Zurera,\nAge group classification and gender recognition from speech with tem-\nporal convolutional neural networks 81 (3) 3535–3552.\n[205] A. A. Alnuaim, M. Zakariah, C. Shashidhar, W. A. Hatamleh,\nH. Tarazi, P. K. Shukla, R. Ratna, Speaker gender recognition based\non deep neural networks and resnet50 2022 1–13.\n[206] R. Srivastava, D. Pandey, Speech recognition using hmm and soft\ncomputing 51 1878–1883. doi:https://doi.org/10.1016/j.matpr.\n2021.10.097.\n[207] J. Padmanabhan, M. J. J. Premkumar, Machine learning in automatic\nspeech recognition: A survey 32 (4) 240–251. doi:10.1080/02564602.\n2015.1010611.\n[208] A. Mukhamadiyev, I. Khujayarov, O. Djuraev, J. Cho, Automatic\nspeech recognition method based on deep learning approaches for uzbek\nlanguage 22 (10) 3683. doi:https://doi.org/10.3390/s22103683.\n[209] X. Lu, S. Li, M. Fujimoto, Automatic speech recognition 21–38.\n[210] C.\nHema,\nF.\nP.\nGarcia\nMarquez,\nEmotional\nspeech\nrecog-\nnition\nusing\ncnn\nand\ndeep\nlearning\ntechniques\n211\n109492.\ndoi:https://doi.org/10.1016/j.apacoust.2023.109492.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0003682X23002906\n[211] A. Shewalkar, D. Nyavanandi, S. A. Ludwig, Performance evaluation\nof deep neural networks applied to speech recognition: Rnn, lstm and\ngru 9 (4) 235–245.\n[212] R. Prabhavalkar, K. Rao, T. N. Sainath, B. Li, L. Johnson, N. Jaitly,\nA comparison of sequence-to-sequence models for speech recognition.,\nin: Interspeech, pp. 939–943.\n[213] A. Graves, Sequence transduction with recurrent neural networks.\n93\n[214] W. Chan, N. Jaitly, Q. V. Le, O. Vinyals, Listen, attend and spell.\n[215] N. Jaitly, Q. V. Le, O. Vinyals, I. Sutskever, D. Sussillo, S. Bengio, An\nonline sequence-to-sequence model using partial conditioning 29.\n[216] C. Raffel, M.-T. Luong, P. J. Liu, R. J. Weiss, D. Eck, Online and\nlinear-time attention by enforcing monotonic alignments, in: Interna-\ntional conference on machine learning, PMLR, pp. 2837–2846.\n[217] H. Sak, M. Shannon, K. Rao, F. Beaufays, Recurrent neural aligner:\nAn encoder-decoder neural network model for sequence to sequence\nmapping., in: Interspeech, Vol. 8, pp. 1298–1302.\n[218] G. Sz˝ucs, D. Huszti, Seq2seq deep learning method for summary gener-\nation by lstm with two-way encoder and beam search decoder, in: 2019\nIEEE 17th International Symposium on Intelligent Systems and Infor-\nmatics (SISY), pp. 221–226. doi:10.1109/SISY47553.2019.9111502.\n[219] Z. Li, J. Cai, S. He, H. Zhao, Seq2seq dependency parsing, in: Pro-\nceedings of the 27th International Conference on Computational Lin-\nguistics, pp. 3203–3214.\n[220] C.-C. Chiu, T. N. Sainath, Y. Wu, R. Prabhavalkar, P. Nguyen,\nZ. Chen, A. Kannan, R. J. Weiss, K. Rao, E. Gonina, N. Jaitly, B. Li,\nJ. Chorowski, M. Bacchiani, State-of-the-art speech recognition with\nsequence-to-sequence models, in: 2018 IEEE International Conference\non Acoustics, Speech and Signal Processing (ICASSP), pp. 4774–4778.\ndoi:10.1109/ICASSP.2018.8462105.\n[221] A. M. Ozbayoglu, M. U. Gudelek, O. B. Sezer, Deep learning for finan-\ncial applications: A survey 93 106384.\n[222] F. Shen, X. Zhao, G. Kou, F. E. Alsaadi, A new deep learning ensem-\nble credit risk evaluation model with an improved synthetic minority\noversampling technique 98 106852.\n[223] W. Wang, W. Li, N. Zhang, K. Liu, Portfolio formation with preselec-\ntion using deep learning from long-term financial data 143 113042.\n[224] L. Chen, M. Pelger, J. Zhu, Deep learning in asset pricing 70 (2) 714–\n750.\n94\n[225] M. Ahnouch, L. Elaachak, A. Ghadi, Model risk in financial derivatives\nand the transformative impact of deep learning: A systematic review,\nin: The Proceedings of the International Conference on Smart City\nApplications, Springer, pp. 155–165.\n[226] S. Sun, S. Wang, Y. Wei, A new ensemble deep learning ap-\nproach\nfor\nexchange\nrates\nforecasting\nand\ntrading\n46\n101160.\ndoi:https://doi.org/10.1016/j.aei.2020.101160.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1474034620301312\n[227] M. Z. Abedin, M. H. Moon, M. K. Hassan, P. Hajek, Deep learning-\nbased exchange rate prediction during the covid-19 pandemic 1–52.\n[228] G. Wang, J. Ma, Y. Wang, T. Tao, G. Ren, H. Zhu, Sudf-rs: A new\nforeign exchange rate prediction method considering the complemen-\ntarity of supervised and unsupervised deep representation features 214\n119152. doi:https://doi.org/10.1016/j.eswa.2022.119152.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0957417422021704\n[229] M. Nikou, G. Mansourfar, J. Bagherzadeh, Stock price prediction us-\ning deep learning algorithm and its comparison with machine learning\nalgorithms 26 (4) 164–174.\n[230] S. Cai, X. Feng, Z. Deng, Z. Ming, Z. Shan, Financial news quanti-\nzation and stock market forecast research based on cnn and lstm, in:\nSmart Computing and Communication: Third International Confer-\nence, SmartCom 2018, Tokyo, Japan, December 10–12, 2018, Proceed-\nings 3, Springer, pp. 366–375.\n[231] M. U. Gudelek, S. A. Boluk, A. M. Ozbayoglu, A deep learning based\nstock trading model with 2-d cnn trend detection, in: 2017 IEEE sym-\nposium series on computational intelligence (SSCI), IEEE, pp. 1–8.\n[232] J. Eapen, D. Bein, A. Verma, Novel deep learning model with cnn\nand bi-directional lstm for improved stock market index prediction, in:\n2019 IEEE 9th annual computing and communication workshop and\nconference (CCWC), IEEE, pp. 0264–0270.\n95\n[233] X. Liu, H. Wang, Z. Li, L. Qin, Deep learning in ecg diagnosis: A\nreview 227 107187. doi:https://doi.org/10.1016/j.knosys.2021.\n107187.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0950705121004494\n[234] C. W. Tsao, A. W. Aday, Z. I. Almarzooq, C. A. Anderson, P. Arora,\nC. L. Avery, C. M. Baker-Smith, A. Z. Beaton, A. K. Boehme, A. E.\nBuxton, et al., Heart disease and stroke statistics—2023 update: a\nreport from the american heart association 147 (8) e93–e621.\n[235] M. Llamedo, J. P. Mart´ınez, Heartbeat classification using feature\nselection driven by database generalization criteria 58 (3) 616–625.\ndoi:10.1109/TBME.2010.2068048.\n[236] S. M. Mathews, C. Kambhamettu, K. E. Barner, A novel appli-\ncation of deep learning for single-lead ecg classification 99 53–62.\ndoi:https://doi.org/10.1016/j.compbiomed.2018.05.013.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0010482518301264\n[237] w. zhu wenliang wenliang, X. Chen, Y. Wang, L. Wang, Arrhythmia\nrecognition and classification using ecg morphology and segment fea-\nture analysis 16 (1) 131–138. doi:10.1109/TCBB.2018.2846611.\n[238] M. P. Desai, G. Caffarena, R. Jevtic, D. G. M´arquez, A. Otero, A low-\nlatency, low-power fpga implementation of ecg signal characterization\nusing hermite polynomials 10 (19) 2324.\n[239] P. Crippa, A. Curzi, L. Falaschetti, C. Turchetti, et al., Multi-class ecg\nbeat classification based on a gaussian mixture model of karhunen-lo`eve\ntransform 16 (1) 2–1.\n[240] U. R. Acharya, S. L. Oh, Y. Hagiwara, J. H. Tan, M. Adam, A. Gertych,\nR. San Tan, A deep convolutional neural network model to classify\nheartbeats 89 389–396.\n[241] U. B. Baloglu, M. Talo, O. Yildirim, R. San Tan, U. R. Acharya,\nClassification of myocardial infarction with multi-lead ecg signals and\ndeep cnn 122 23–30.\n96\n[242] S. Singh, S. K. Pandey, U. Pawar, R. R. Janghel, Classification of ecg\narrhythmia using recurrent neural networks 132 1290–1297.\n[243] E. Prabhakararao, S. Dandapat, Attentive rnn-based network to fuse\n12-lead ecg and clinical features for improved myocardial infarction\ndiagnosis 27 2029–2033.\n[244] M. Wang, S. Rahardja, P. Fr¨anti, S. Rahardja, Single-lead ecg record-\nings modeling for end-to-end recognition of atrial fibrillation with dual-\npath rnn 79 104067.\n[245] S. Sowmya, D. Jose, Contemplate on ecg signals and classification of\narrhythmia signals using cnn-lstm deep learning model 24 100558.\n[246] H. M. Rai, K. Chatterjee, Hybrid cnn-lstm deep learning model and\nensemble technique for automatic detection of myocardial infarction\nusing big ecg data 52 (5) 5366–5384.\n[247] R. Banerjee, A. Ghose, K. Muthana Mandana, A hybrid cnn-lstm ar-\nchitecture for detection of coronary artery disease from ecg, in: 2020\nInternational Joint Conference on Neural Networks (IJCNN), pp. 1–8.\ndoi:10.1109/IJCNN48605.2020.9207044.\n[248] S. Kusuma, K. Jothi, Ecg signals-based automated diagnosis of conges-\ntive heart failure using deep cnn and lstm architecture 42 (1) 247–257.\n[249] C.-Y. Chen, Y.-T. Lin, S.-J. Lee, W.-C. Tsai, T.-C. Huang, Y.-H.\nLiu, M.-C. Cheng, C.-Y. Dai, Automated ecg classification based on\n1d deep learning network 202 127–135, machine Learning Methods\nfor Bio-Medical Image and Signal Processing:\nRecent Advances.\ndoi:https://doi.org/10.1016/j.ymeth.2021.04.021.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1046202321001134\n[250] J. Wang, X. Qiao, C. Liu, X. Wang, Y. Liu, L. Yao, H. Zhang, Auto-\nmated ecg classification using a non-local convolutional block attention\nmodule 203 106006.\n[251] J. Zhang, A. Liu, M. Gao, X. Chen, X. Zhang, X. Chen, Ecg-based\nmulti-class arrhythmia detection using spatio-temporal attention-based\nconvolutional recurrent neural network 106 101856.\n97\n[252] F. Zhu, F. Ye, Y. Fu, Q. Liu, B. Shen, Electrocardiogram generation\nwith a bidirectional lstm-cnn generative adversarial network 9 (1) 6734.\n[253] R.\nT.\nSchirrmeister,\nJ.\nT.\nSpringenberg,\nL.\nD.\nJ.\nFiederer,\nM.\nGlasstetter,\nK.\nEggensperger,\nM.\nTangermann,\nF.\nHutter,\nW. Burgard,\nT. Ball,\nDeep learning with convolutional neural\nnetworks for eeg decoding and visualization 38 (11) 5391–5420.\ndoi:https://doi.org/10.1002/hbm.23730.\nURL\nhttps://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.\n23730\n[254] Z. Gao, W. Dang, X. Wang, X. Hong, L. Hou, K. Ma, M. Perc, Complex\nnetworks and deep learning for eeg signal analysis 15 (3) 369–388.\n[255] K. K. Ang, C. Guan, Eeg-based strategies to detect motor imagery for\ncontrol and rehabilitation 25 (4) 392–401. doi:10.1109/TNSRE.2016.\n2646763.\n[256] Z. Shen, G. Li, J. Fang, H. Zhong, J. Wang, Y. Sun, X. Shen, Aber-\nrated multidimensional eeg characteristics in patients with generalized\nanxiety disorder: A machine-learning based analysis framework 22 (14)\n5420.\n[257] P. Boonyakitanont, A. Lek-Uthai, K. Chomtho, J. Songsiri, A review\nof feature extraction and performance evaluation in epileptic seizure\ndetection using eeg 57 101702.\n[258] M. Sharma, J. Tiwari, V. Patel, U. R. Acharya, Automated identifica-\ntion of sleep disorder types using triplet half-band filter and ensemble\nmachine learning techniques with eeg signals 10 (13) 1531.\n[259] F. Vaquerizo-Villar, G. C. Guti´errez-Tobal, E. Calvo, D. ´Alvarez,\nL. Kheirandish-Gozal, F. Del Campo, D. Gozal, R. Hornero, An ex-\nplainable deep-learning model to stage sleep states in children and pro-\npose novel eeg-related patterns in sleep apnea 165 107419.\n[260] A. Modir, S. Shamekhi, P. Ghaderyan, A systematic review and\nmethodological analysis of eeg-based biomarkers of alzheimer’s disease\n113274.\n98\n[261] H. Altaheri, G. Muhammad, M. Alsulaiman, S. U. Amin, G. A. Al-\ntuwaijri, W. Abdul, M. A. Bencherif, M. Faisal, Deep learning tech-\nniques for classification of electroencephalogram (eeg) motor imagery\n(mi) signals: A review 35 (20) 14681–14722.\n[262] C. Brunner, M. Naeem, R. Leeb, B. Graimann, G. Pfurtscheller, Spatial\nfiltering and selection of optimized components in four class motor\nimagery eeg data using independent components analysis 28 (8) 957–\n964.\n[263] A. Delorme, T. Sejnowski, S. Makeig, Enhanced detection of artifacts\nin eeg data using higher-order statistics and independent component\nanalysis 34 (4) 1443–1449.\n[264] A. Jafarifarmand, M. A. Badamchizadeh, Eeg artifacts handling in a\nreal practical brain–computer interface controlled vehicle 27 (6) 1200–\n1208.\n[265] R. Zhang, Q. Zong, L. Dou, X. Zhao, A novel hybrid deep learning\nscheme for four-class motor imagery classification 16 (6) 066004.\n[266] S. Kumar, A. Sharma, K. Mamun, T. Tsunoda, A deep learning ap-\nproach for motor imagery eeg signal classification, in: 2016 3rd Asia-\nPacific World Congress on Computer Science and Engineering (APWC\non CSE), IEEE, pp. 34–39.\n[267] N. Tibrewal, N. Leeuwis, M. Alimardani, Classification of motor im-\nagery eeg using deep learning increases performance in inefficient bci\nusers 17 (7) e0268880.\n[268] M. Dai, D. Zheng, R. Na, S. Wang, S. Zhang, Eeg classification of\nmotor imagery using a novel deep learning framework 19 (3) 551.\n[269] M. Li, W. Zhu, M. Zhang, Y. Sun, Z. Wang, The novel recognition\nmethod with optimal wavelet packet and lstm based recurrent neu-\nral network, in: 2017 IEEE International Conference on Mechatron-\nics and Automation (ICMA), pp. 584–589. doi:10.1109/ICMA.2017.\n8015882.\n99\n[270] F. Li, F. He, F. Wang, D. Zhang, Y. Xia, X. Li, A novel simplified\nconvolutional neural network classification algorithm of motor imagery\neeg signals based on deep learning 10 (5) 1605.\n[271] J. Hwang, S. Park, J. Chi, Improving multi-class motor imagery eeg\nclassification using overlapping sliding window and deep learning model\n12 (5). doi:10.3390/electronics12051186.\nURL https://www.mdpi.com/2079-9292/12/5/1186\n[272] Y. Zhao, L. He, Deep learning in the eeg diagnosis of alzheimer’s dis-\nease, in: Computer Vision-ACCV 2014 Workshops: Singapore, Singa-\npore, November 1-2, 2014, Revised Selected Papers, Part I 12, Springer,\npp. 340–353.\n[273] W. Xia, R. Zhang, X. Zhang, M. Usman, A novel method for diagnosing\nalzheimer’s disease using deep pyramid cnn based on eeg signals 9 (4).\n[274] A. T. Hermawan, I. A. E. Zaeni, A. P. Wibawa, G. Gunawan, W. H.\nHendrawan, Y. Kristian, A multi representation deep learning approach\nfor epileptic seizure detection 5 (1) 187–204.\n[275] A. H. Abdulwahhab, A. H. Abdulaal, A. H. Thary Al-Ghrairi,\nA. A. Mohammed, M. Valizadeh, Detection of epileptic seizure using\neeg signals analysis based on deep learning techniques 181 114700.\ndoi:https://doi.org/10.1016/j.chaos.2024.114700.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0960077924002522\n[276] P.\nPandey,\nK.\nSeeja,\nSubject\nindependent\nemotion\nrecogni-\ntion from eeg using vmd and deep learning 34 (5) 1730–1738.\ndoi:https://doi.org/10.1016/j.jksuci.2019.11.003.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1319157819309991\n[277] A. Hassouneh, A. Mutawa, M. Murugappan, Development of a real-\ntime emotion recognition system using facial expressions and eeg based\non machine learning and deep neural network methods 20 100372.\n[278] J. Pan, W. Fang, Z. Zhang, B. Chen, Z. Zhang, S. Wang, Multimodal\nemotion recognition based on facial expressions, speech, and eeg 1–\n8doi:10.1109/OJEMB.2023.3240280.\n100\n[279] S. Wang, J. Qu, Y. Zhang, Y. Zhang, Multimodal emotion recognition\nfrom eeg signals and facial expressions 11 33061–33068.\n[280] A. R. Munappy, J. Bosch, H. H. Olsson, A. Arpteg, B. Brinne, Data\nmanagement for production quality deep learning models: Challenges\nand solutions 191 111359. doi:10.1016/j.jss.2022.111359.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0164121222000905\n[281] A. R. Luca, T. F. Ursuleanu, L. Gheorghe, R. Grigorovici, S. Iancu,\nM. Hlusneac, A. Grigorovici, Impact of quality, type and volume of\ndata used by deep learning models in the analysis of medical images\n29 100911. doi:10.1016/j.imu.2022.100911.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS2352914822000612\n[282] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, Q. He,\nA comprehensive survey on transfer learning 109 (1) 43–76, publisher:\nIEEE.\n[283] A.\nMumuni,\nF.\nMumuni,\nData\naugmentation:\nA\ncompre-\nhensive\nsurvey\nof\nmodern\napproaches\n16\n100258.\ndoi:\n10.1016/j.array.2022.100258.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS2590005622000911\n[284] C. Hu, Z. Sun, C. Li, Y. Zhang, C. Xing, Survey of Time Series Data\nGeneration in IoT 23 (15) 6976, number: 15 Publisher: Multidisci-\nplinary Digital Publishing Institute. doi:10.3390/s23156976.\nURL https://www.mdpi.com/1424-8220/23/15/6976\n[285] H. Murtaza, M. Ahmed, N. F. Khan, G. Murtaza, S. Zafar, A. Bano,\nSynthetic data generation: State of the art in health care domain 48\n100546. doi:10.1016/j.cosrev.2023.100546.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS1574013723000138\n[286] S. Tonekaboni, S. Joshi, M. D. McCradden, A. Goldenberg, What clin-\nicians want: contextualizing explainable machine learning for clinical\n101\nend use, in: Machine learning for healthcare conference, PMLR, pp.\n359–380.\n[287] E. Tjoa, H. J. Khok, T. Chouhan, C. Guan, Enhancing the confidence\nof deep learning classifiers via interpretable saliency maps 562 126825,\npublisher: Elsevier.\n[288] X. Li, Q. Shen, A hybrid framework based on knowledge distillation\nfor explainable disease diagnosis 238 121844, publisher: Elsevier.\n[289] C. Termritthikun, A. Umer, S. Suwanwimolkul, F. Xia, I. Lee, Explain-\nable knowledge distillation for on-device chest x-ray classificationPub-\nlisher: IEEE.\n[290] W. Xiong, Z. Xiong, Y. Cui, An Explainable Attention Network for\nFine-Grained Ship Classification Using Remote-Sensing Images 60 1–\n14, conference Name: IEEE Transactions on Geoscience and Remote\nSensing. doi:10.1109/TGRS.2022.3162195.\nURL https://ieeexplore.ieee.org/abstract/document/9741720\n[291] L. Fernandes, J. N. Fernandes, M. Calado, J. R. Pinto, R. Cerqueira,\nJ. S. Cardoso, Intrinsic Explainability for End-to-End Object Detec-\ntionPublisher: IEEE.\n[292] M. N. Freire, L. N. de Castro, e-Recruitment recommender systems: a\nsystematic review 63 1–20, publisher: Springer.\n[293] R. K. Dass, N. Petersen, M. Omori, T. R. Lave, U. Visser, Detecting\nracial inequalities in criminal justice: towards an equitable deep learn-\ning approach for generating and interpreting racial categories using\nmugshots 38 (2) 897–918, publisher: Springer.\n[294] A. Gici´c, D. Donko, A. Subasi, Intelligent credit scoring using deep\nlearning methods 35 (9) e7637.\n[295] N. Schaaf, O. de Mitri, H. B. Kim, A. Windberger, M. F. Huber, To-\nwards measuring bias in image classification, in: Artificial Neural Net-\nworks and Machine Learning–ICANN 2021: 30th International Con-\nference on Artificial Neural Networks, Bratislava, Slovakia, September\n14–17, 2021, Proceedings, Part III 30, Springer, pp. 433–445.\n102\n[296] A. Giloni, E. Grolman, T. Hagemann, R. Fromm, S. Fischer, Y. Elovici,\nA. Shabtai, BENN: Bias Estimation Using a Deep Neural NetworkPub-\nlisher: IEEE.\n[297] V. Iosifidis, T. N. H. Tran, E. Ntoutsi, Fairness-enhancing interven-\ntions in stream classification, in: Database and Expert Systems Ap-\nplications: 30th International Conference, DEXA 2019, Linz, Austria,\nAugust 26–29, 2019, Proceedings, Part I 30, Springer, pp. 261–276.\n[298] T. Kehrenberg, Z. Chen, N. Quadrianto, Tuning fairness by balancing\ntarget labels 3 33, publisher: Frontiers Media SA.\n[299] B. Jain, M. Huber, R. Elmasri, Increasing Fairness in Predictions Using\nBias Parity Score Based Loss Function Regularization 36.\ndoi:10.\n32473/flairs.36.133311.\nURL https://journals.flvc.org/FLAIRS/article/view/133311\n[300] J. Yang, A. A. Soltan, D. W. Eyre, D. A. Clifton, Algorithmic fairness\nand bias mitigation for clinical machine learning with deep reinforce-\nment learning 5 (8) 884–894, publisher: Nature Publishing Group UK\nLondon.\n[301] L. Li, J. Zhu, M.-T. Sun, Deep learning based method for prun-\ning deep neural networks, in: 2019 IEEE International Conference\non Multimedia and Expo Workshops (ICMEW), pp. 312–317. doi:\n10.1109/ICMEW.2019.00-68.\n[302] J. Yang, X. Shen, J. Xing, X. Tian, H. Li, B. Deng, J. Huang, X.-s. Hua,\nQuantization networks, in: Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition (CVPR).\n[303] S. Stanton, P. Izmailov, P. Kirichenko, A. A. Alemi, A. G. Wilson,\nDoes knowledge distillation really work?, in: M. Ranzato, A. Beygelz-\nimer, Y. Dauphin, P. Liang, J. W. Vaughan (Eds.), Advances in\nNeural Information Processing Systems, Vol. 34, Curran Associates,\nInc., pp. 6906–6919.\nURL\nhttps://proceedings.neurips.cc/paper_files/paper/\n2021/file/376c6b9ff3bedbbea56751a84fffc10c-Paper.pdf\n103\n[304] N. Akhtar, A. Mian, Threat of adversarial attacks on deep learning\nin computer vision: A survey 6 14410–14430. doi:10.1109/ACCESS.\n2018.2807385.\n[305] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfel-\nlow, R. Fergus, Intriguing properties of neural networks.\n[306] P. Tabacof, J. Tavares, E. Valle, Adversarial images for variational\nautoencoders.\n[307] W. E. Zhang, Q. Z. Sheng, A. Alhazmi, C. Li, Adversarial attacks on\ndeep-learning models in natural language processing: A survey 11 (3)\n1–41.\n[308] L. Jiang, X. Ma, S. Chen, J. Bailey, Y.-G. Jiang, Black-box adversarial\nattacks on video recognition models, in: Proceedings of the 27th ACM\nInternational Conference on Multimedia, pp. 864–872.\n[309] M. Esmaeilpour, P. Cardinal, A. L. Koerich, A robust approach for\nsecuring audio classification against adversarial attacks 15 2147–2159.\n[310] S. Maldonado, C. Vairetti, K. Jara, M. Carrasco, J. L´opez, Owadapt:\nAn adaptive loss function for deep learning using owa operators 280\n111022.\n[311] W. Zhu, O. Wu, N. Yang, Irda: Implicit data augmentation for deep\nimbalanced regression 120873.\n[312] S. B. Belhaouari, A. Islam, K. Kassoul, A. Al-Fuqaha, A. Bouzerdoum,\nOversampling techniques for imbalanced data in regression 252 124118.\n[313] X. Wang, Y. Zhang, N. Bai, Q. Yu, Q. Wang, Class-imbalanced time se-\nries anomaly detection method based on cost-sensitive hybrid network\n238 122192.\n[314] J. Ircio, A. Lojo, U. Mori, S. Malinowski, J. A. Lozano, Mini-\nmum recall-based loss function for imbalanced time series classification\n35 (10) 10024–10034.\n[315] L. Moles, A. Andres, G. Echegaray, F. Boto, Exploring data augmenta-\ntion and active learning benefits in imbalanced datasets 12 (12) 1898.\n104\n[316] Y. Zhu, S. Wang, H. Yu, W. Li, J. Tian, Sfpl: Sample-specific fine-\ngrained prototype learning for imbalanced medical image classification\n97 103281.\n105\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2024-03-26",
  "updated": "2024-11-15"
}