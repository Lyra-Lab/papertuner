{
  "id": "http://arxiv.org/abs/2404.02531v1",
  "title": "Computationally Efficient Unsupervised Deep Learning for Robust Joint AP Clustering and Beamforming Design in Cell-Free Systems",
  "authors": [
    "Guanghui Chen",
    "Zheng Wang",
    "Hongxin Lin",
    "Yongming Huang",
    "Luxi Yang"
  ],
  "abstract": "In this paper, we consider robust joint access point (AP) clustering and\nbeamforming design with imperfect channel state information (CSI) in cell-free\nsystems. Specifically, we jointly optimize AP clustering and beamforming with\nimperfect CSI to simultaneously maximize the worst-case sum rate and minimize\nthe number of AP clustering under power constraint and the sparsity constraint\nof AP clustering. By transformations, the semi-infinite constraints caused by\nthe imperfect CSI are converted into more tractable forms for facilitating a\ncomputationally efficient unsupervised deep learning algorithm. In addition, to\nfurther reduce the computational complexity, a computationally effective\nunsupervised deep learning algorithm is proposed to implement robust joint AP\nclustering and beamforming design with imperfect CSI in cell-free systems.\nNumerical results demonstrate that the proposed unsupervised deep learning\nalgorithm achieves a higher worst-case sum rate under a smaller number of AP\nclustering with computational efficiency.",
  "text": "arXiv:2404.02531v1  [cs.IT]  3 Apr 2024\n1\nComputationally Efﬁcient Unsupervised Deep\nLearning for Robust Joint AP Clustering and\nBeamforming Design in Cell-Free Systems\nGuanghui Chen, Graduate Student Member, IEEE, Zheng Wang, Senior Member, IEEE, Hongxin Lin,\nYongming Huang, Senior Member, IEEE, Luxi Yang, Senior Member, IEEE\nAbstract—In this paper, we consider robust joint access point\n(AP) clustering and beamforming design with imperfect channel\nstate information (CSI) in cell-free systems. Speciﬁcally, we\njointly optimize AP clustering and beamforming with imperfect\nCSI to simultaneously maximize the worst-case sum rate and\nminimize the number of AP clustering under power constraint\nand the sparsity constraint of AP clustering. By transformations,\nthe semi-inﬁnite constraints caused by the imperfect CSI are\nconverted into more tractable forms for facilitating a com-\nputationally efﬁcient unsupervised deep learning algorithm. In\naddition, to further reduce the computational complexity, a\ncomputationally effective unsupervised deep learning algorithm\nis proposed to implement robust joint AP clustering and beam-\nforming design with imperfect CSI in cell-free systems. Numerical\nresults demonstrate that the proposed unsupervised deep learning\nalgorithm achieves a higher worst-case sum rate under a smaller\nnumber of AP clustering with computational efﬁciency.\nIndex Terms—Cell-free systems, beamforming, access point\nclustering, imperfect channel state information, unsupervised\ndeep learning.\nI. INTRODUCTION\nR\nECENTLY, cell-free systems have received signiﬁcant\nattention [1], [2]. By connecting all access points (APs)\nto a central processing unit (CPU) via backhaul links, cell-free\nsystems allow multiple APs to simultaneously collaborate to\nserve users within the network coverage area, which could\novercome many of the interference issues that appear in\ncellular networks [3], [4]. Nevertheless, popular beamforming\ndesign in cell-free systems generally assumes that all APs\nin the network coverage area serve users simultaneously [5],\n[6]. This appears to be impractical as long-range APs serving\nusers consume precious power and bandwidth resources while\ncontributing little useful power due to high path losses [7].\nTo solve the above problem, a practical solution is to allow\na subset of APs in cell-free systems to serve users simultane-\nously, which can also be called AP clustering. Consequently,\nThis work was supported by the National Natural Science Foundation\nof China under Grant 62225107, the Natural Science Foundation on Fron-\ntier Leading Technology Basic Research Project of Jiangsu under Grant\nBK20222001, the Fundamental Research Funds for the Central Universities\nunder Grant 2242022k60002.\nG. Chen, Z. Wang, Y. Huang and L. Yang are with the School of Infor-\nmation Science and Engineering, and the National Mobile Communications\nResearch Laboratory, Southeast University, Nanjing 210096, China; Y. Huang\nand L. Yang are also with the Pervasive Communications Center, Purple\nMountain Laboratories, Nanjing 211111, China. (e-mail:cgh@seu.edu.cn,\nwznuaa@gmail.com, huangym@seu.edu.cn, lxyang@seu.edu.cn).\nH. Lin is with the Purple Mountain Laboratories, Nanjing 211111, China.\n(email: linhongxin@pmlabs.com.cn).\njoint AP clustering and beamforming design is proposed to\nimprove both the sum rate performance and the practicality of\ncell-free systems.\nTheoretically, joint AP clustering and beamforming design\nbelongs to the mixed-integer non-convex optimization problem\nthat is difﬁcult to solve efﬁciently. Some traditional optimiza-\ntion algorithms have approximated the solution of such mixed-\ninteger non-convex optimization problem. In particular, based\non block coordinate descent (BCD) [8], [9] proposed a sparse\nweighted minimum mean square error (S-WMMSE) algorithm\nto consider joint AP clustering and beamforming design under\nthe power constraint. [10] conducted joint user scheduling and\nbeamforming design for multiuser multiple-input-multiple-\noutput (MIMO) networks via fractional programming [11]\nand Hungarian algorithm [12], where both user scheduling\nand AP clustering can be viewed as the integer programming\nproblem. By applying BCD [8], fractional programming [11]\nand compressive sensing [13], the work in [14] optimized user\nscheduling, power allocation and beamforming in cell-free sys-\ntems. Although these traditional optimization algorithms could\nsolve such mixed-integer non-convex optimization problem,\nthey usually require multiple iterations and matrix inversions,\nthus imposing a severe computational burden.\nIn recent years, deep learning has been widely deployed\nin wireless communications for improving communication\nperformance and computational efﬁciency [15], [16]. In par-\nticular, a joint AP clustering and beamforming design based\non unsupervised deep learning has been proposed in [17],\nwhere the convolutional neural networks (CNNs) mapped\nbeamforming from channel state information (CSI) and an\nadaptive threshold ReLU (ATReLU) activation function was\nadded to the CNNs after to realize AP clustering. Since the\nCNNs and ATReLU activation function enable unsupervised\nend-to-end training, the work in [17] optimizes AP clustering\nand beamforming design simultaneously. Unfortunately, the\nATReLU activation function is designed with only one AP\nclustering threshold between all APs and all users, which\nis difﬁcult to achieve the optimal AP clustering results. The\nreason is that AP clustering is done in units of one AP to one\nuser, which means that one AP clustering threshold is required\nbetween each AP and each user. As a result, it is necessary to\ncarry out the research of unsupervised deep learning for joint\nAP clustering and beamforming design in cell-free systems,\nwhere between each AP and each user is designed with an\nAP clustering threshold.\n2\nIt is worth noting that beamforming design or AP clustering\nin most of these references, e.g., [3], [5], [6], [9], [16], [17],\noptimistically assumes the availability of perfect CSI, which\nleads to system performance degradation in practice. To this\nend, it is highly desired to take the CSI estimation errors\ninto account, and there have been some studies on robust\nbeamforming design, especially for multicellular networks,\ne.g., in [18], [19], [20]. However, these methods are gen-\nerally solved by traditional optimization algorithms, where\nthe computational complexity is extremely high due to the\nneed of multiple iterations and matrix inversions. Besides,\nthese methods only consider the beamforming design without\nconsidering AP clustering.\nBased on the above considerations, in this paper, regarding\nto the optimization problem of robust joint AP clustering and\nbeamforming design with imperfect CSI in cell-free systems,\nwe propose a low computational complexity unsupervised\ndeep learning algorithm named as Robust Joint AP Clustering\nand Beamforming Network (RJAPCBN). The major contribu-\ntions of this work are summarized as follows:\n1) An optimization model for robust joint AP clustering\nand beamforming design with imperfect CSI in cell-free\nsystems is built, which aims at maximizing the worst-case\nsum rate and minimizing the number of AP clustering\nwith imperfect CSI under the power constraint and the\nsparsity constraint for AP clustering simultaneously. By\ntransformations, the intractable semi-inﬁnite constraints\nin the optimization model caused by the imperfect CSI\nare converted into a more tractable form, paving the way\nfor the design of a computationally efﬁcient unsupervised\ndeep learning algorithm.\n2) The RJAPCBN is proposed to realize the mapping from\nCSI to beamforming with high computational efﬁciency.\nBy designing an adaptive AP clustering module, the pro-\nposed RJAPCBN also ensures that the output beamform-\ning satisﬁes the sparsity constraint of AP clustering. In\naddition, the adaptive AP clustering module also proposes\na differentiable threshold function to ensure that an AP\nclustering threshold between each AP and each user is\nadaptively set, which effectively reduces the impractical\ndrawback of cell-free systems, i.e., longer-range APs\nserving users consume valuable power and bandwidth\nresources while contributing little useful power due to\nhigh path losses.\n3) Numerical results are conducted to validate the effective-\nness of the proposed RJAPCBN. In terms of performance,\nthe proposed RJAPCBN achieves a higher worst-case sum\nrate under a smaller number of AP clustering. As for com-\nputational complexity, the number of real multiplication\nof the proposed RJAPCBN is about 106, which is much\nlower than other traditional and deep learning algorithms\nsuch as S-WMMSE [9], WMMSE [21] and CNNs [16].\nThe rest of this paper is organized as follows: In Section II,\nthe system model and optimization problem are introduced.\nIn Section III, the optimization problem is transformed into\na more tractable form. In Section IV, the computationally\neffective unsupervised deep learning RJAPCBN is proposed.\nFinally, numerical results and conclusions are provided in\nSections V, and VI, respectively.\nNotations: The scalars, vectors, and matrices are denoted by\nlowercase letter x, boldface lowercase letter x, and boldface\nuppercase letter X, respectively. C and R denotes the set\nof complex and real numbers, respectively. (·)H denotes the\nconjugate transpose. |·|, ∥·∥1 and ∥·∥2 denote the modulus\nof complex numbers, ℓ1 and ℓ2 norms, respectively. Re {·}\ndenotes the real part of complex numbers. A ⪰0 denotes that\nA is a semi-positive deﬁnite matrix.\nII. SYSTEM MODEL AND PROBLEM FORMULATION\nA. System Model\nConsider a downlink cell-free system with Q APs and I\nsingle-antenna users, where AP is equipped with M antennas.\nAll APs are connected to a CPU via backhaul links, in which\nthe CPU makes resource allocation decisions for all APs. Let\nQ = {1, · · · , Q} and I = {1, · · · , I} denote the sets of APs\nand users, respectively. To simplify the notation, i and j denote\nthe user’s indexes, and q denotes the AP’s index. The received\nsignal of the ith user is denoted as\nyi = hH\ni visi +\nX\nj̸=i\nhH\ni vjsj + zi, ∀i, j ∈I,\n(1)\nwhere si denotes the data being sent to the ith user. zi denotes\nthe additive noise following the complex Gaussian distribu-\ntion CN\n\u00000, σ2\ni\n\u0001\n. hi =\n\u0002\nh1,H\ni\n, · · · , hq,H\ni\n, · · · , hQ,H\ni\n\u0003H ∈\nCQM×1 denotes the CSI of the AP set Q to the ith user, in\nwhich hq\ni ∈CM×1 is the CSI of the qth AP to the ith user.\nvi =\nh\nv1,H\ni\n, · · · , vq,H\ni\n, · · · , vQ,H\ni\niH\n∈CQM×1 denotes the\nbeamforming of the AP set Q to the ith user, and vq\ni ∈CM×1\nis the beamforming of the qth AP to the ith user.\nFrom Eq.(1), the signal-to-interference-plus-noise ratio\n(SINR) of the ith user is expressed as\nSINRi =\n\f\fhH\ni vi\n\f\f2\nP\nj̸=i\n\f\fhH\ni vj\n\f\f2 + σ2\ni\n, ∀i, j ∈I,\n(2)\nso that the achievable rate of the ith user is\nRi = log2 (1 + SINRi) , ∀i ∈I.\n(3)\nB. AP Clustering\nCell-free systems typically assume all APs in the network\ncoverage area serving users simultaneously, which seems\nimpractical [7]. In this regard, it is encouraged to select a\nsubset of APs Si ⊆Q to serve the ith user, i.e., when the ith\nuser is not served by the qth AP, the beamforming vq\ni can be\nset to zero, and vice verse. Formally, this is denoted as\nvq\ni = 0, ∀q /∈Si, ∀i ∈I.\n(4)\nFor AP clustering, it is expected that a smaller subset of\nAPs Si serves the ith user, i.e., the beamforming vi should\nbe a sparse structure containing a larger number of zero\nblocks [17]. A popular way to enforce the sparsity of the\nsolution to an optimization problem uses a norm to penalize\n3\nthe objective function such as the ℓ1 norm [22]. Consequently,\nby jointly considering AP clustering and beamforming design,\nthe optimization objective can be deﬁned as\nSspa =\nX\ni∈I\n\u0000Ri −λ\nX\nq∈Q\n∥vq\ni ∥1\n\u0001\n,\n(5)\nwhere Sspa denotes a penalized sparse sum rate. Note that\nmaximizing Sspa enables the goal of maximizing the sum rate\nand minimizing the number of AP clustering simultaneously.\nλ ≥0 denotes the parameter balancing the sum rate and the\nnumber of AP clustering.\nC. CSI Error Model\nIt is well known that the perfect CSI assumption generally\nleads to the inevitable loss of system performance in practice\n[4]. To this end, this work applies a bounded model to\ncharacterize CSI estimation errors [18], since it is able to\ncapture different types of CSI errors, e.g., the errors caused by\nnoise, quantization, ﬁnite feedback, etc. Speciﬁcally, let ∆hq\ni\ndenote the estimation errors of hq\ni , and then the actual CSI\ncan be denoted as a combination of the estimated CSI and the\ncorresponding estimation errors, i.e.,\nhq\ni = ˆhq\ni + ∆hq\ni , ∥∆hq\ni ∥2 ≤ǫq\ni , ∀i ∈I, ∀q ∈Q,\n(6)\nwhere ˆhq\ni denotes the estimated CSI of the qth AP to the ith\nuser, and ∥∆hq\ni ∥2 ≤ǫq\ni denotes that ∆hq\ni is limited within an\norigin hyperspherical region of radius ǫq\ni [4], [18].\nD. Problem Formulation\nIn this paper, our goal is to achieve a robust joint AP\nclustering and beamforming design in cell-free systems by\nmaximizing the worst-case penalized sparse sum rate of all\nusers with imperfect CSI, taking into account the power\nconstraint and the sparsity constraint for AP clustering. The\noptimization problem is formulated as\nmax\nvq\ni\nmin\n∆hq\ni\nSspa\ns.t. C1 :\nX\ni∈I\n(vq\ni )H vq\ni ≤Pmax, ∀q ∈Q,\nC2 : vq\ni = 0, ∀q /∈Si, ∀i ∈I,\n(7)\nwhere Pmax denotes the AP maximum power. For the optimiza-\ntion problem (7), the optimization objective is non-convex and\nnon-smooth, in which C2 is an integer constraint. This means\nthat the optimization problem (7) is a mixed integer nonconvex\nand nonsmooth optimization problem, which is challenging to\nsolve.\nIII. PROBLEM TRANSFORMATION\nIn this section, we provide a useful transformation to\nsimplify the optimization problem in (7). Concretely, to make\nthe optimization problem (7) more tractable, we introduce a\nslack variable γ = {γ1, · · · , γi, · · · , γI} to replace the worst-\ncase SINR terms, so that the optimization problem (7) can be\nrewritten as\nmax\nvq\ni ,γi\nX\ni∈I\n\u0000log2 (1 + γi) −λ\nX\nq∈Q\n∥vq\ni ∥1\n\u0001\ns.t. C1, C2,\nC3 : min\n∆hq\ni\nSINRi ≥γi, ∀i ∈I,\n(8)\nwhere C3 contains the intractable semi-inﬁnite constraints\ncaused by the imperfect CSI ∥∆hq\ni ∥2 ≤ǫq\ni , ∀i ∈I, ∀q ∈Q.\nIn the following, we transform it into a more tractable form.\nTo begin with, it is obvious that the lower bound for the\nworst-case SINR of the ith user is obtained as\nmin\n∆hq\ni\nSINRi ≥\nmin\n∆hq\ni\n\f\fhH\ni vi\n\f\f2\nmax\n∆hq\ni\nP\nj̸=i\n\f\fhH\ni vj\n\f\f2 + σ2\ni\n, ∀i, j ∈I.\n(9)\nTo achieve the goal of robust design, C3 can be replaced\nwith this lower bound, thus a lower bound performance of the\noriginal optimization problem can be obtained. Accordingly,\nthis leads to C3\nC3 :\nmin\n∆hq\ni\n\f\fhH\ni vi\n\f\f2\nmax\n∆hq\ni\nP\nj̸=i\n\f\fhH\ni vj\n\f\f2 + σ2\ni\n≥γi, ∀i, j ∈I.\n(10)\nSubsequently, to facilitate the solution of C3, it is trans-\nformed into the following constraints by introducing the slack\nvariables, i.e.,\nC4 : min\n∆hq\ni\n\f\fhH\ni vi\n\f\f2 ≥αi, ∀i ∈I,\n(11)\nC5 : max\n∆hq\ni\nX\nj̸=i\n\f\fhH\ni vj\n\f\f2 + σ2\ni ≤βi, ∀i, j ∈I,\n(12)\nC6 : αi\nβi\n≥γi, ∀i ∈I,\n(13)\nwhere\nα\n=\n{α1, · · · , αi, · · · , αI}\nand\nβ\n=\n{β1, · · · , βi, · · · , βI} are the slack variables to decompose\nthe fractions. Although C6 is a simple convex constraint,\nC5 and C6 are still the intractable semi-inﬁnite constraints\ndue to imperfect CSI. On the other hand, the S-procedure\n[23] is an efﬁcient transformation technique to convert the\nintractable semi-inﬁnite constraints into the tractable forms of\nthe linear matrix inequality. As a result, this work applies the\nS-procedure to transform C4 into the linear matrix inequality\nwith the following Lemma 1.\nLemma 1: (S-Procedure [23]) Deﬁne the quadratic functions\nof the variable x ∈CN×1:\nfk(x) = xHAkx + 2 Re\n\b\naH\nk x\n\t\n+ ak, k = 0, 1,\nwhere Ak = AH\nk ∈CN×N, ak ∈CN×1 and ak ∈C1×1. The\ncondition f1(x) ≥0 ⇒f0(x) ≥0 hold if and only if there\nexist δ ≥0 such that\n\u0014 A0\na0\naH\n0\na0\n\u0015\n−δ\n\u0014 A1\na1\naH\n1\na1\n\u0015\n⪰0.\n4\nBy bringing hq\ni = ˆhq\ni + ∆hq\ni in Eq.(6) into Eq.(11), C4 is\nrewritten as\nmin\n∆hq\ni\n∆hH\ni Ei,i∆hi + 2 Re\n\b\neH\ni,i∆hi\n\t\n+ ˆhH\ni Ei,iˆhi −αi ≥0, ∀i ∈I\n(14)\nwith\nˆhi\n=\n\u0002 ˆh1,H\ni\n, · · · , ˆhq,H\ni\n, · · · , ˆhQ,H\ni\n\u0003H\n∈\nCQM×1,\n∆hi =\n\u0002\n∆h1,H\ni\n, · · · , ∆hq,H\ni\n, · · · , ∆hQ,H\ni\n\u0003H ∈CQM×1,\nEi,i = vivH\ni\n∈CQM×QM and ei,i = vivH\ni ˆhi ∈CQM×1.\nAccording to Lemma 1, C4 is transformed into the linear\nmatrix inequality with the new introduced slack variables\nδ = {δ1, · · · , δi, · · · , δI}, which is denoted as\nC4 :\n\u0014 Ei,i + δiI\nei,i\neH\ni,i\nˆhH\ni Ei,iˆhi −αi −δiǫ2\ni\n\u0015\n⪰0, ∀i ∈I,\n(15)\nwhere ǫi ≜\nqPQ\nq=1(ǫq\ni )2 based on Eq.(6) and [4].\nAfterwards, the semi-inﬁnite constraints in C5 is trans-\nformed into the linear matrix inequality. Due to the summation\nterm in C5, this is difﬁcult to directly apply the S-procedure\nin Lemma 1 to transform into the linear matrix inequality. For\nthis reason, this work applies the sign-deﬁniteness [24] that\ncan be regarded as an extended version of the S-procedure\nto transform C5 into the linear matrix inequality with the\nfollowing Lemma 2.\nLemma 2: (Sign-Deﬁniteness [24]) For a given set of ma-\ntrices A = AH, Y and Z, the follow linear matrix inequality\nmeets\nA ⪰YHXZ + ZHXHY, ∥X∥2 ≤ǫ,\nif and only if there exist real numbers µ ≥0 such that\n\u0014 A −µZHZ\n−ǫYH\n−ǫY\nµI\n\u0015\n⪰0.\nDeﬁning V = [v1, · · · , vi−1, vi+1, · · · , vI] ∈CQM×(I−1),\nC5 is ﬁrst equivalently converted into a matrix inequality by\nutilizing the Schur’s complement lemma [25], i.e.,\nmin\n∆hq\ni\n\u0014 βi −σ2\ni\nhH\ni V\nVHhi\nI(I−1)\n\u0015\n⪰0, ∀i ∈I\n(16)\nwith hi = ˆhi + ∆hi, then Eq.(16) is rewritten as\nmin\n∆hq\ni\n\u0014 βi −σ2\ni\nˆhH\ni V\nVH ˆhi\nI(I−1)\n\u0015\n⪰\n−\n\u0012 \u0014 01×QM\nVH\n\u0015\n∆hi\n\u0002 1\n01×(I−1)\n\u0003\n+\n\u0014\n1\n0(I−1)×1\n\u0015\n∆hH\ni\n\u0002 0QM×1\nV \u0003 \u0013\n, ∀i ∈I.\n(17)\nAccording to Lemma 2, C5 is transformed into the linear\nmatrix inequality with the new introduced slack variables µ =\n{µ1, · · · , µi, · · · , µI}, which is denoted as\nC5 :\n\n\nβi −σ2\ni −µi\nˆhH\ni V\n01×QM\nVH ˆhi\nI(I−1)\nǫiVH\n0QM×1\nǫiV\nµiIQM\n\n⪰0, ∀i ∈I.\n(18)\nBased on the above transformation, the original optimization\nproblem (7) is recast as\nmax\nvq\ni ,αi,βi,γi,δi,µi\nX\ni∈I\n\u0000log2 (1 + γi) −λ\nX\nq∈Q\n∥vq\ni ∥1\n\u0001\ns.t.\nC1, C2, C4, C5, C6.\n(19)\nNote that the optimization problem (19) has transformed the\nsemi-inﬁnite constraints caused by the imperfect CSI into the\nlinear matrix inequality with the slack variables.\nIV. PROPOSED RJAPCBN\nIn this section, we pay our attention on designing a\ncomputationally effective unsupervised deep learning method\nRJAPCBN to achieve robust joint AP clustering and beam-\nforming design with imperfect CSI in cell-free systems by\nsolving the optimization problem (19). As illustrated in Fig.1,\nthe proposed RJAPCBN ﬁrst designs the CSI conversion\nC (·), residual network R (·, θ), adaptive AP clustering A (·, θ),\nbeamforming conversion V (·) and power constraint P (·) to\noutput a sparse beamforming VRJAPCBN that satisﬁes both C1\nand C2 in the optimization problem (19) by taking ˆH =\nh\nˆh1, · · · , ˆhi, · · · , ˆhI\ni\n∈CQM×I as an input. Subsequently,\nwith VRJAPCBN and ˆH, the updating slack variable module\nU (·) in the proposed RJAPCBN updates the slack variables\nα, β, δ, µ and γ by simultaneously satisfying C4, C5 and\nC6 in the optimization problem (19). Finally, based on the\nobtained γ, the proposed RJAPCBN is unsupervised trained\nwith the negative of the objective function of the optimization\nproblem (19) as the loss function.\nA. CSI Conversion C (·)\nThe CSI of communication systems is complex numbers,\nwhile deep learning algorithms such as CNNs usually deal\nwith three-dimensional (3D) real numbers. For this purpose,\nC (·) transforms the estimated two-dimensional (2D) complex\nCSI ˆH =\nh\nˆh1, · · · , ˆhi, · · · , ˆhI\ni\n∈CQM×I of the AP set\nQ to the user set I into a 3D real CSI. Speciﬁcally, ˆH\nis computed with the modulus value to obtain a 2D real\nCSI ˆH2D\nmod ∈RQM×I. Subsequently, ˆH2D\nmod ∈RQM×I is\ntransformed into a 3D real CSI ˆH3D\nmod ∈RQ×I×M.1\nB. Residual Network R (·, θ)\nR (·, θ) achieves the mapping from 3D real CSI ˆH3D\nmod ∈\nRQ×I×M to beamforming. As the unique weight sharing\nmechanism of the CNNs signiﬁcantly reduces the computa-\ntional complexity of neural networks, this is in line with the\ngoal of designing a low computational complexity unsuper-\nvised deep learning algorithm. Therefore, R (·, θ) selects the\nCNNs to achieve the mapping from H3D\nmod ∈RQ×I×M to\nbeamforming. To be speciﬁc, R (·, θ) contains L layers, where\neach layer contains a convolution unit with a convolution layer\n(CL), batch normalization (BN) layer, activation layer (AL).\n1In this paper, the ﬁrst, second and third dimensions of a 3D tensor are\ndenoted as width, height and third dimension, respectively.\n5\nAL\nāāā \nCL\nBN\nAL\nCL\nBN\nAL\nCL\nBN\nAL\nāāā \nāāā \nIdentity Mapping\n1×1CL AL\nPool\n\u000b\n\f\n1\n,T\n\n\u001b\n\u000b\n\f\n,\nlT\n\n\u001b\n\u000b\n\f\n,\nL\nT\n\n\u001b\n\u000b\n\f\n1\n,T\n\nV\u001b\n\u000b\n\f\n, lT\n\nV\u001b\n\u000b\n\f\n, L\nT\n\nV\u001b\nIM\nV\n\u000b\n\f\n,T\n\nV฀\n*\n1\n1\nDT\n1\nDTI\n1\nDTQ\nDTQ\nI\nāāā \nāāā \nāāā \nāāā \nāāā \nāāā \nāāā \nāāā \n1\n1t\n1\nIt\n1\nQt\nQ\nIt\nThreshold:T\nDTq\ni\n\u000b\n\f\n,T\n\nC\u0019\nSpatial Attention\nPool\nq\ni\npv\n3D\nmod\nˆH\nˆH\n\u000b \f\n\u001b\n\u000b\n\f\n\u000b\n\f\n,\n and\n,\nT\nT\n\n\n*\n\u0001\u0019\n\u000b \f\n.\n\u000b \f\n(\nspa\nV\nCSI Conversion\nBeamforming Conversion\nPower Constraint\ncom\nspa\nV฀\nRJAPCBN\nV\n3D\nmod\nˆH\nUnsupervised Training  RJAPCBN \n\u000b \f\nUpdating Slack Variable Module \n \n\n-\n\u000b\n\f\nResidual Network \n,T\n\n*\n\u000b\n\f\nAdaptive AP Clustering \n,T\n\n\u0019\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n*\n1\n1\n1\n1\n1\nUpdating \n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\nI\nI\nI\nI\nI\nD\nD\nE\nE\nG\nG\nP\nP\nJ\nJ\nª\nº\nª\nº\nª\nº\nª\nº\nª\nº\n \n \n \n \n \n¬\n¼\n¬\n¼\n¬\n¼\n¬\n¼\n¬\n¼\n\"\n\"\n\"\n\"\n\"\nĮ\nȕ\nį\nȝ\nȖ\nRJAPCBN\nˆH V\n\u000f\n*Ȗ\nāāā \nspa\nV\nFig. 1: The model architecture of the proposed RJAPCBN.\nFormally, for the lth layer, denoted as C (·, θl), its formula is\ndeﬁned as\nVC(·,θl) = AL\n\u0000BN\n\u0000CL\n\u0000VC(·,θl−1), θl\n\u0001\u0001\u0001\n,\n(20)\nwhere VC(·,θl) denotes the output of C (·, θl), and θl is the\nparameters of C (·, θl). VC(·,θl−1) denotes the input of C (·, θl),\nnote that VC(·,θ0) = ˆH3D\nmod ∈RQ×I×M. CL (·, ·) denotes the\nconvolution operation. BN (·) denotes the BN operation, which\nis usually added after the CL to reduce the overﬁtting prob-\nability [26]. AL (·) denotes the AL operation, which selects\nthe commonly used ReLU activation function ReLU(x) =\nmax(0, x) to implement nonlinear operations [27]. Note that\nthe last layer of R (·, θ), i.e., C (·, θL), outputs the real and\nimaginary parts of beamforming, which should contain both\npositive and negative values. Consequently, AL (·) in C (·, θL)\ncan adopt the Tanh activation function Tanh(x) = ex−e−x\nex+e−x .\nIn addition, the residual structure of the CNNs can effec-\ntively avoid the gradient disappearance problem. As a result,\nfollowing [28], R (·, θ) adds an identity mapping on top of\nC (·, θl) , l = 1, · · · , L to construct the residual structure. Such\nthat the output of R (·, θ) is denoted as:\nVR(·,θ) = AL\n\u0000VC(·,θL) + VIM\n\u0001\n,\n(21)\nwhere VIM denotes the output of the identity mapping utilizing\na 1 × 1 CL with ˆH3D\nmod ∈RQ×I×M as the output. Note that\nthe architectural parameters of the 1 × 1 CL in the identity\nmapping are adjusted to ensure that VIM and VC(·,θL) have\nthe same dimension, in which VIM and VC(·,θL) are added to\nform the residual structure to avoid the gradient disappearance\nproblem [28].\nRemark 1: For optimization problem (19), the beamforming\nin cell-free systems has the following properties. When the\ndimension of the input 3D real CSI ˆH3D\nmod is Q × I × M, the\n6\ndimension of the output beamforming should be a 3D complex\ntensor of dimension Q × I × M, which can be transformed\ninto a 3D real tensor of dimension Q × I × 2M.\nBased on Remark 1, when ˆH3D\nmod ∈RQ×I×M is inputted\nto R (·, θ), the dimension of the output beamforming VR(·,θ)\nshould be Q × I × 2M. However, the dimension of VR(·,θ)\nis determined by the architectural parameters of the CL in\nR (·, θ) such as the convolution kernel size, convolution kernel\nnumber, sliding step size and zero padding size. Consequently,\nin what follows, we derive some architectural conditions for\nthe CL in R (·, θ) to satisfy the dimension of VR(·,θ) as Q ×\nI × 2M when ˆH3D\nmod ∈RQ×I×M is inputted.\nProposition 1: Let win\nC(·,θl), hin\nC(·,θl), wout\nC(·,θl) and hout\nC(·,θl)\ndenote the input and output width and height dimensions of\nC (·, θl) in R (·, θ), as well as kw\nl , kh\nl , pw\nl , ph\nl , sw\nl and sh\nl de-\nnote the width and height dimensions of the convolution kernel,\nzero padding, sliding step for the CL of C (·, θl) in R (·, θ),\nrespectively. When sw\nl\n= 1, sh\nl = 1, if pw\nl\n=\n1\n2(kw\nl −1),\nph\nl = 1\n2(kh\nl −1), both pw\nl , ph\nl and kw\nl , kh\nl are positive integers,\nthen wout\nC(·,θl) = win\nC(·,θl) and hout\nC(·,θl) = hin\nC(·,θl).\nProof: As can be seen in Fig.1, C (·, θl) includes one CL,\nBN and AL. For the CL in C (·, θl), its output width and height\ndimensions wCL\nC(·,θl) × hCL\nC(·,θl) are denoted as\n\n\n\n\n\nwCL\nC(·,θl) =\nwin\nC(·,θl)+2pw\nl −kw\nl\nsw\nl\n+ 1,\nhCL\nC(·,θl) =\nhin\nC(·,θl) +2ph\nl −kh\nl\nsh\nl\n+ 1,\n(22)\nwhere sw\nl = 1, sh\nl = 1, pw\nl = 1\n2(kw\nl −1) and ph\nl = 1\n2(kh\nl −1)\nare brought into Eq.(22), i.e.,\n\n\n\nwCL\nC(·,θl) =\nwin\nC(·,θl)+2× 1\n2 (kw\nl −1)−kw\nl\n1\n+ 1 = win\nC(·,θl),\nhCL\nC(·,θl) =\nhin\nC(·,θl) +2× 1\n2 (kh\nl −1)−kh\nl\n1\n+ 1 = hin\nC(·,θl).\n(23)\nBased on Eq.(23), the output width and height dimensions\nof the CL in C (·, θl) are win\nC(·,θl) and hin\nC(·,θl), respectively.\nOn the other hand, the BN and AL do not change the input\ndimension, i.e., the output width and height dimensions of the\nBN and AL in C (·, θl) are also win\nC(·,θl) and hin\nC(·,θl), respec-\ntively. Consequently, the output width and height dimensions\nof C (·, θl) are win\nC(·,θl) and hin\nC(·,θl), i.e., wout\nC(·,θl) = win\nC(·,θl)\nand hout\nC(·,θl) = hin\nC(·,θl), respectively. Besides, note that the\nconvolution operation guarantees that the architectural param-\neters are positive integers. That is, both pw\nl , ph\nl and kw\nl , kh\nl\nare guaranteed to be positive integers during the convolution\noperation.\n■\nProposition 2: When sw\nl\n>\n1, sh\nl\n>\n1, if pw\nl\n=\n1\n2(win\nC(·,θl)sw\nl −win\nC(·,θl) −sw\nl + kw\nl ) and ph\nl = 1\n2(hin\nC(·,θl)sh\nl −\nhin\nC(·,θl) −sh\nl +kh\nl ), as well as pw\nl , ph\nl , sw\nl , sh\nl , kw\nl , kh\nl are pos-\nitive integers, then wout\nC(·,θl) = win\nC(·,θl) and hout\nC(·,θl) = hin\nC(·,θl).\nProof: For the CL in C (·, θl), where sw\nl > 1, sh\nl > 1, pw\nl =\n1\n2(win\nC(·,θl)sw\nl −win\nC(·,θl) −sw\nl + kw\nl ) and ph\nl = 1\n2(hin\nC(·,θl)sh\nl −\nhin\nC(·,θl) −sh\nl + kh\nl ), its output width and height dimensions\nwCL\nC(·,θl) × hCL\nC(·,θl) are denoted as\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwCL\nC(·,θl) =\nwin\nC(·,θl)+2× 1\n2 (win\nC(·,θl)sw\nl −win\nC(·,θl)−sw\nl +kw\nl )−kw\nl\nsw\nl\n+1 = win\nC(·,θl),\nhCL\nC(·,θl) =\nhin\nC(·,θl)+ 2× 1\n2 (hin\nC(·,θl)sh\nl −hin\nC(·,θl)−sh\nl + kh\nl )−kh\nl\nsh\nl\n+1 = hin\nC(·,θl).\n(24)\nSimilarly, the output width and height dimensions of C (·, θl)\nare win\nC(·,θl) and hin\nC(·,θl), i.e., wout\nC(·,θl) = win\nC(·,θl) and hout\nC(·,θl) =\nhin\nC(·,θl). Besides, it is also necessary to ensure that pw\nl , ph\nl , sw\nl ,\nsh\nl , and kw\nl , kh\nl are positive integers during the convolution\noperation.\n■\nSubsequently, we incorporate Propositions 1 and 2 to derive\nsome architectural conditions that satisfy the beamforming\nproperties in Remark 1. Concretely, when ˆH3D\nmod ∈RQ×I×M\nis inputted into R (·, θ), the architectural parameters of the\nCL in the ﬁrst C (·, θ1) are available in two cases. In the ﬁrst\ncase, when sw\n1 = 1 and sh\n1 = 1, pw\n1 and ph\n1 can be set to\n1\n2(kw\n1 −1) and 1\n2(kh\n1 −1), where both pw\n1 , ph\n1 and kw\n1 , kh\n1 are\npositive integers. Based on Proposition 1, the width and height\ndimensions of VC(·,θ1) are Q×I. Another case, when sw\n1 > 1\nand sh\n1 > 1, pw\n1 and ph\n1 can be set to 1\n2(Qsw\n1 −Q−sw\n1 +kw\n1 ) and\n1\n2(Ish\n1 −I −sh\n1 +kh\n1), in which pw\n1 , ph\n1, sw\n1 , sh\n1, and kw\n1 , kh\n1 are\npositive integers. Based on Proposition 2, the width and height\ndimensions of VC(·,θ1) are Q × I. Similarly, as long as the\narchitectural parameters kw\nl , kh\nl , pw\nl , ph\nl , sw\nl , sh\nl , l = 1, · · · , L\nin each C (·, θl) satisfy Proposition 1 or Proposition 2, the\nwidth and height dimensions of VC(·,θL) are Q×I. In addition,\nlet cl denote the number of convolution kernels for the CL in\nC (·, θl). As long as the number of convolution kernels cL\nfor C (·, θL) is equal to 2M, VC(·,θL) is a 3D real tensor\nof dimension Q × I × 2M. Besides, the dimension of the\noutput VIM of the dentity mapping is also Q × I × 2M,\nsince the dentity mapping adjusts its architecture parameters to\nensure that the dimension of VIM is equal to that of VC(·,θL).\nConsequently, based on Eq.(21), VR(·,θ) is a 3D real tensor\nof dimension Q × I × 2M. To sum up, the architectural\nconditions that satisfy the beamforming properties in Remark\n1 are summarized in Remark 2.\nRemark 2: When ˆH3D\nmod ∈RQ×I×M is fed into R (·, θ),\nVR(·,θ) is a 3D real tensor of dimension Q× I × 2M as long\nas the following two conditions are satisﬁed.\n1) The architectural parameters kw\nl , kh\nl , pw\nl , ph\nl , sw\nl , sh\nl ,\nl = 1, · · · , L in each C (·, θl) satisfy Proposition 1 or\nProposition 2.\n2) The number of convolutional kernels cL for C (·, θL) is\nequal to 2M.\nIn summary, based on Proposition 1, Proposition 2 and\nRemark 2, as long as the two conditions in Remark 2 are\nsatisﬁed, the output VR(·,θ) of R (·, θ) is a 3D real tensor of\ndimension Q × I × 2M by taking ˆH3D\nmod ∈RQ×I×M as the\ninput. This satisﬁes the beamforming properties in Remark 1.\nC. Adaptive AP Clustering A (·, θ)\nR (·, θ) achieves the mapping from ˆH3D\nmod ∈RQ×I×M\nto VR(·,θ) ∈RQ×I×2M as long as the two conditions in\n7\nRemark 2 are satisﬁed. In the following, on the basis of\nsatisfying the two conditions in Remark 2, A (·, θ) implements\nthat VR(·,θ) ∈RQ×I×2M contains more zero-blocks for AP\nclustering. To achieve this, one of the most intuitive ways is\nto feed the elements of VR(·,θ) ∈RQ×I×2M with a threshold\nfunction. That is, when the element of VR(·,θ) ∈RQ×I×2M\nis less than the threshold value of the threshold function, this\nelement is set to 0, otherwise 1. Despite the simplicity of this\napproach, this suffers from two major problems.\n1) The threshold value of the threshold function is usually\nset manually and empirically, which cannot change with\nthe input 3D real CSI ˆH3D\nmod ∈RQ×I×M. However, the\nresults of AP clustering vary with the input 3D real CSI\nˆH3D\nmod ∈RQ×I×M, in which the threshold value of the\nthreshold function in turn determines the results of AP\nclustering. Thus, for AP clustering, the threshold value\nof the threshold function should vary with the input 3D\nreal CSI ˆH3D\nmod ∈RQ×I×M.\n2) The threshold function is non-differentiable, which can-\nnot be optimized along with R (·, θ) during the training\nperiod. Nevertheless, the objective of this paper is ro-\nbust joint AP clustering and beamforming design, which\nrequires optimizing beamforming and AP clustering si-\nmultaneously. Therefore, the threshold function should\nbe able to be optimized along with R (·, θ) during the\ntraining period.\nFirst, we address the ﬁrst problem, i.e., making that the\nthreshold value varies with the input 3D real CSI ˆH3D\nmod ∈\nRQ×I×M. To be speciﬁc, cell-free systems have the unrealistic\ndrawback, i.e., long-range APs serving users consume precious\npower and bandwidth resources, while contributing little useful\npower due to high path losses [7]. In other words, for a user in\ncell-free systems, the CSI modulus for the longer-range APs\nwill usually be smaller than those of the shorter-range APs due\nto the larger path losses of the longer-range APs. Accordingly,\nto reduce the above-mentioned unfavourable problem, when\ndealing with the CSI modulus corresponding to the longer-\nrange APs, their corresponding threshold values can be set\nto smaller values for easier implementation of AP clustering,\nand vice versa. Consequently, A (·, θ) uses the spatial attention\n[29] to realize that the threshold value changes with the 3D\nreal CSI ˆH3D\nmod ∈RQ×I×M. It includes the pooling layer, 1×1\nCL and AL. Formally, this is denoted as\nT = AL\n\u0010\nCL1×1\n\u0010\nPOOL\n\u0010\nˆH3D\nmod\n\u0011\n, θsa\n\u0011\u0011\n=\n\n\n\nt1\n1\n· · ·\nt1\nI\n...\n...\n...\ntQ\n1\n· · ·\ntQ\nI\n\n\n,\n(25)\nwhere POOL (·) denotes pooling according to the third dimen-\nsion, i.e., the dimension of POOL\n\u0010\nˆH3D\nmod\n\u0011\nis Q×I. CL1×1(·, ·)\ndenotes the 1 × 1 CL, in which θsa denotes the parameters of\nthe spatial attention. T ∈RQ×I is a threshold value matrix\nfor the input 3D real CSI ˆH3D\nmod ∈RQ×I×M, in which tq\ni is\nthe threshold value of the qth AP to the ith user.\nProposition 3: For the ith user, if the qth AP is a longer-\nrange AP and the pth AP is a shorter-range AP, then tq\ni < tp\ni .\nProof: Please see Appendix A for the detailed proof.\n■\nBased on Proposition 3, for those long-range APs occupying\nprecious power and bandwidth resources while contributing\nlittle useful power to the user, Eq.(25) enables adaptive setting\nsmaller threshold values to make the AP clustering easier,\nthereby effectively reducing the unfavourable fact mentioned\nabove. On the other hand, it is obvious that the threshold\nvalue T ∈RQ×I in Eq.(25) varies with the input 3D real CSI\nˆH3D\nmod ∈RQ×I×M, where between each AP and each user is\nadaptively designed an AP clustering threshold. In summary,\nEq.(25) effectively solves the ﬁrst problem mentioned above.\nIn what follows, we address the second problem, i.e.,\nmaking the threshold function differentiable to optimize along\nwith R (·, θ) during the training period. Speciﬁcally,A (·, θ)\nproposes a differentiable threshold function, which is deﬁned\nas\nDTq\ni =\n1\n1 + e−k(pvq\ni −tq\ni) , ∀i ∈I, ∀q ∈Q,\n(26)\nwhere\nk\ndenotes\nan\nampliﬁcation\nparameter.\npvq\ni\n=\nPOOL\n\u0000VR(·,θ)[q, i, :]\n\u0001\ndenotes the value for the beamforming\nVR(·,θ)[q, i, :] of the qth AP to the ith user pooled by the\nthird dimension. The schematic diagrams of the differentiable\nthreshold function DTq\ni at different k and tq\ni are shown in\nFigs.2 and 3, respectively.\nAs shown in Fig.2, when the ampliﬁcation parameter k is\ngradually increased, the differentiable threshold function DTq\ni\ngradually approaches the ideal threshold function, where the\nampliﬁcation parameter k is set 50 empirically. As shown in\nFig.3, if pvq\ni is less than the threshold tq\ni , then the value of\nthe differentiable threshold function DTq\ni is 0, otherwise 1.\nCombining Figs.2 and 3, the differentiable threshold function\nDTq\ni is extremely approximated to the ideal threshold function\nand is differentiable, which is optimized along with R (·, θ)\nduring the training period. That is, the second difﬁculty\nmentioned above is effectively solved. In conclusion, A (·, θ)\nrealizes AP clustering, where the results of AP clustering are\ndeﬁned as\nCA(·,θ) =\n\n\n\nDT1\n1\n· · ·\nDT1\nI\n...\n...\n...\nDTQ\n1\n· · ·\nDTQ\nI\n\n\n.\n(27)\nNote that C2 in the optimization problem (19) requires the\nbeamforming vector to be 0 for those APs that are clustered\nas 0. To this end, the Hadamard product between VR(·,θ) and\nCA(·,θ) is performed to obtain a sparse beamforming Vspa,\nwhich is denoted as\nVspa = VR(·,θ) ⊗CA(·,θ),\n(28)\nwhere ⊗denotes the Hadamard product of 2D matrix and 3D\ntensor. For example, for a 2D matrix A ∈Ra×b and a 3D\ntensor B ∈Ra×b×c, A ⊗B is calculated as follows. A ∈\nRa×b is ﬁrst copied c times to become C ∈Ra×b×c, and\nthen the Hadamard product is performed on C ∈Ra×b×c and\nB ∈Ra×b×c. Clearly, C2 in the optimization problem (19) is\nsatisﬁed since the elements in CA(·,θ) are either 0 or 1.\n8\n-2\n-1\n0\n1\n2\n0\n0.2\n0.4\n0.6\n0.8\n1\nDifferentiable threshold function\nFig. 2: Differentiable threshold function (26) at different k.\nD. Beamforming Conversion V (·) and Power Constraint P (·)\nVspa is a 3D real beamforming tensor of dimension Q ×\nI × 2M, which should be transformed into a 3D complex\nbeamforming tensor. For this purpose, V (·) transforms Vspa\ninto a 3D complex beamforming tensor as follows,\nVcom\nspa = VS[:, :, 0 : M] + jVS[:, :, M : 2M],\n(29)\nwhere Vcom\nspa is a 3D complex beamforming tensor of dimen-\nsion Q×I ×M. On the other hand, Vcom\nspa also needs to satisfy\nthe power constraint C1 of the optimization problem (19). Due\nto the fact that the power constraint is a convex constraint [30],\nit can be satisﬁed using a projection function. Consequently,\nfollowing [30], P (·) applies the following projection function\nto satisfy the power constraint, i.e.,\nvq\ni =\n\n\n\n\n\nvq\ni\nif P\ni∈I\n(vq\ni )H vq\ni ≤Pmax,\nvq\ni\nP\ni∈I(vq\ni)\nHvq\ni\nPmax\notherwise,\n(30)\nwhere vq\ni = Vcom\nspa [q, i, :]. Finally, the output beamforming of\nP (·) is denoted as VRJAPCBN. It is obvious that VRJAPCBN\nsatisﬁes both C1 and C2 for the optimization problem (19).\nE. Updating Slack Variable Module U (·)\nIn addition to satisfying C1 and C2, it is also necessary to\nsatisfy C4, C5, C6, where an unsupervised loss function also\nneeds to be designed to train the proposed RJAPCBN for the\npurpose of robust joint AP clustering and beamforming design\nwith imperfect CSI in cell-free systems. For this reason, U (·)\nis proposed to fulﬁll C4, C5, C6 and to realize the closed-loop\nunsupervised training of the proposed RJAPCBN.\nRecall that the optimization problem (19), C4, C5 and C6\ndetermining the slack variable γ are simple convex constraints,\nwhere the elements of C4 and C5 related to CSI and beam-\nforming can be computed by ˆH and VRJAPCBN. It encourages\nthat a simple convex optimization problem can be solved to\n-2\n-1\n0\n1\n2\n0\n0.2\n0.4\n0.6\n0.8\n1\nDifferentiable threshold function\nFig. 3: Differentiable threshold function (26) at different tq\ni .\nobtain the slack variable γ by the known ˆH and VRJAPCBN,\nwhich is denoted as\nmax\nαi,βi,γi,δi,µi\nX\ni∈I\nlog2 (1 + γi)\ns.t.\nC4, C5, C6.\n(31)\nNote that P\nq∈Q\n∥vq\ni ∥1 in the optimization problem (19) is a\nconstant without affecting the solution of the slack variables\nwhen knowing VRJAPCBN, it is straightforward to remove in\nthe optimization problem (31) for simplicity. It is clear that\nthe optimization problem (31) is a simple convex optimization\nproblem, which can be solved simply using the CVX toolbox\nin the MATLAB or the CVXPY toolbox in the python to\nobtain the optimal the slack variables α∗, β∗, δ∗, µ∗and\nγ∗. Accordingly, with the slack variable γ∗, the unsupervised\nloss function of the proposed RJAPCBN can be deﬁned as\nL = −\nX\ni∈I\n\u0000log2 (1 + γ∗\ni ) −λ\nX\nq∈Q\n∥vq\ni ∥1\n\u0001\n,\n(32)\nwhere γ∗\ni is obtained by solving the optimization problem\n(31). By minimizing L to unsupervised train the proposed\nRJAPCBN, the optimization problem (19) is solved efﬁciently.\nIn other words, with the above closed-loop unsupervised\ntraining, the proposed RJAPCBN realizes robust joint AP\nclustering and beamforming design with imperfect CSI in cell-\nfree systems.\nV. EXPERIMENTAL RESULTS\nIn this section, we validate the effectiveness of the proposed\nRJAPCBN in terms of parameter settings, the worst-case sum\nrate, the average number of serving APs per user and the\ncomputational complexity. The geographic location channel\nmodel [9], [17] that is commonly exploited for beamforming\ndesign is selected, where the large-scale fading is modelled as\n(200/dq\ni)3 Lq\ni . Here, dq\ni denotes the distance between the qth\nAP and the ith user, and 10 log 10 (Lq\ni ) ∼N(0, 64) denotes\nthe shadowing effect. For ease of presentation, following [4],\n9\nTABLE I: The performance of the proposed RJAPCBN under different architecture parameters.\nConvolution kernel\nWorst-case sum rate\nQave\nNumber of multiplications\n7 × 7\n264\n9.92\nQ2I2C + QIMC + QI + 49QIMC + 196QIC2\n7 × 5\n256\n10.07\nQ2I2C + QIMC + QI + 35QIMC + 140QIC2\n5 × 5\n248\n10.24\nQ2I2C + QIMC + QI + 25QIMC + 100QIC2\n5 × 3\n235\n10.33\nQ2I2C + QIMC + QI + 15QIMC + 60QIC2\n3 × 3\n221\n10.54\nQ2I2C + QIMC + QI + 9QIMC + 36QIC2\nηi = ∥∆hi∥2 / ∥hi∥2 , ∀i ∈I is deﬁned as the error levels of\nimperfect CSI. In subsequent experiments, unless otherwise\nstated, the number of AP and users is set to 16, where the\nnumber of antennas and the maximum power for each AP\nare set to 4 and 1, respectively. Besides, the performance of\nrobust beamforming design is measured by the commonly used\nworst-case sum rate. The performance of robust AP clustering\ncan be measured by the average number of serving APs per\nuser, which is deﬁned as\nQave = Q\n\u0012\n1 −Vzero\nQIM\n\u0013\n,\n(33)\nwhere Vzero denotes the number of zeros in VRJAPCBN. As Vzero\nis larger, Qave is smaller, i.e., the AP set of serving users is\nsmaller, and vice versa.\nAs benchmarks, the following schemes are compared:\n• WMMSE with perfect CSI: The WMMSE [21] achieves\nthe stable solution of beamforming design in perfect CSI\nby iteratively updating beamforming and a set of auxiliary\nvariables. In addition, the WMMSE is usually centralized to\nallow all APs to serve all users in cell-free systems, which can\nbe regarded as an upper bound of AP clustering. In summary,\ndue to the excellent performance of the WMMSE with perfect\nCSI, it can be viewed as an upper bound for robust joint AP\nclustering and beamforming design with imperfect CSI.\n• WMMSE with imperfect CSI: The WMMSE [21] directly\ntreats imperfect CSI as perfect CSI to highlight the potential\nperformance degradation caused by imperfect CSI.\n• S-WMMSE with imperfect CSI: The S-WMMSE [9]\nis a traditional optimization method for solving joint AP\nclustering and beamforming design under perfect CSI, which\nis also applied to imperfect CSI scenarios for highlighting the\nperformance degradation that may result from imperfect CSI.\n• CNNs with imperfect CSI: [16] applies the CNNs to\nimplement AP clustering and beamforming design with perfect\nCSI individually, i.e., AP clustering is determined and beam-\nforming is then designed from the clustered APs. Similarly,\nthe CNNs in [16] is utilized to imperfect CSI scenarios.\n• JcbNet with imperfect CSI: The JcbNet [17] is a deep\nlearning method for joint AP clustering and beamforming\ndesign under perfect CSI. Likewise, the JcbNet is applied to\nimperfect CSI scenarios.\nA. Parameter Settings of RJAPCBN\nPyTorch is applied to implement the proposed RJAPCBN,\nwhere the Adam optimizer is selected. The number of layers L\n0.1\n0.15\n0.2\n0.25\n0.3\n0\n50\n100\n150\n200\n250\nWorst-case sum rate (bits/s/Hz)\n0\n2\n4\n6\n8\n10\n12\nFig. 4: Worst-case sum rate and Qave at different λ.\nof R (·, θ) in the proposed RJAPCBN is set to 5. The learning\nrate and batch size are set to 64 and 0.1, respectively. In the\nunsupervised training, 10000 channels are generated to train\nthe proposed RJAPCBN. In the model testing, 6400 channels\nare inputted into the trained RJAPCBN to output 3D complex\nbeamforming.\nFrom Eq. (19), the hyperparameter λ balances AP clustering\nand beamforming design, where the worst-case sum rate and\nQave at different λ are shown in Fig.4. As λ is larger, the worst-\ncase sum rate and Qave are smaller, and vice versa. For this\nreason, λ is selected to be 0.1, because the goal of this paper\nis to reduce Qave as much as possible with minimal worst-case\nsum rate reduction. However, other scenarios allow ﬂexibility\nin setting λ according to different objectives.\nAccording to Remark 2 in Section III.B, the proposed\nRJAPCBN could set different architectural parameters to re-\nalize robust joint AP clustering and beamfroming design with\nimperfect CSI in cell-free systems, where the worst-case sum\nrate, Qave and the number of multiplications for different\narchitectural parameters are shown in TABLE I. When the\nsize of the convolution kernel decreases, the worst-case sum\nrate decreases and Qave increases, while the computational\ncomplexity decreases, and vice versa. The reason is as follows:\nwireless communication channels often exhibit a block-sparse\nstructure, i.e., a channel matrix that exhibits non-zero and zero\nvalues clustering structure [31], [32]. When the size of con-\nvolution kernel is reduced, the receptive ﬁeld of convolution\n10\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n200\n210\n220\n230\n240\n250\n260\nWorst-case sum rate (bits/s/Hz)\nWMMSE with imperfect CSI\nS-WMMSE with imperfect CSI\nCNN with imperfect CSI\nJcbNet with imperfect CSI\nRJAPCBN with imperfect CSI\nFig. 5: Worst-case sum rate at different imperfect CSI error\nlevels.\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n10\n11\n12\n13\n14\n15\n16\nWMMSE with imperfect CSI\nS-WMMSE with imperfect CSI\nCNN with imperfect CSI\nJcbNet with imperfect CSI\nRJAPCBN with imperfect CSI\nFig. 6: Qave at different imperfect CSI error levels.\noperation is reduced and easily dropped to a cluster of zero\nvalue, which results in the output of the convolution operation\nbeing close to zero. That is, less useful information is obtained,\nthus reducing the worst-case sum rate and increasing Qave, and\nvice verse. Accordingly, the size of the convolution kernel of\nthe proposed RJAPCBN is chosen 5 × 5 in this paper, which\nis a balance between the computational complexity and the\nworst-case sum rate with Qave.\nB. Performance of Worst-Case Sum Rate and Average Number\nof Serving APs Per User\nThe worst-case sum rate and Qave of these comparison\nalgorithms at different imperfect CSI error levels ηi as well\nas number of users I and AP antennas M are shown Fig.\n5-Fig.10, respectively. Under the same conditions, the worst-\ncase sum rate of the proposed RJAPCBN with imperfect CSI is\nhigher than those of the WMMSE, S-WMMSE, CNNs, JcbNet\n10\n12\n14\n16\n18\n20\n140\n160\n180\n200\n220\n240\n260\n280\n300\nWorst-case sum rate (bits/s/Hz)\nFig. 7: Worst-case sum rate at different number of users.\n10\n12\n14\n16\n18\n20\n9\n10\n11\n12\n13\n14\n15\n16\nFig. 8: Qave at different number of users.\nwith imperfect CSI, which is approaching to the WMMSE\nwith perfect CSI. On the other hand, the Qave of the proposed\nRJAPCBN with imperfect CSI is also lower than those of the\nS-WMMSE, CNNs, JcbNet with imperfect CSI, much lower\nthan those of the WMMSE with imperfect and perfect CSI.\nTo summarize, compared to these algorithms, the proposed\nRJAPCBN with imperfect CSI achieves better worst-case sum-\nrate performance with a smaller Qave. The reasons are as\nfollows: The WMMSE with perfect CSI is a stable solution\nof beamforming design, thus its worst-case sum rate is the\nhighest. When faced with imperfect CSI scenarios, the worst-\ncase sum rate of the WMMSE degrades, because the WMMSE\nis designed without considering the robustness of imperfect\nCSI scenarios. On the other hand, the WMMSE is all APs\nserving all users in cell-free systems, i.e., Qave is the largest.\nThe S-WMMSE is also designed based on perfect CSI, where\nthe worst-case sum rate decreases and Qave increases when\nfaced with imperfect CSI scenarios. The CNNs are designed\n11\nTABLE II: The computational complexity of several algorithms\nAlgorithms\nNumber of multiplications\nValue\nWMMSE\n4Lite(IQ3M3 + I + I2Q2M2 + I2 + IQ2M2 + IQM + 4I2QM +\n3IQM + IQM)\nLite = 15\nS-WMMSE\n4Lite (I + I2 + 2IQ2M2 + 2I2QM + 8IQM + IQQ(I(Q −1)M2 +\nIM + aI((log2 ǫ)2 + 1)(M3 + M2 + M)))\nLite = 15, IQ = 10, ǫ = 105,\na = 0.9\nCNN\nQI(36MC + 38KMC2 + LLl + (2M + 1)OOo)\nC = 16, K = 10, Ll = QIM,\nL = 8, O = 3, Oo = 80\nJcbNet\nQIM + Q2I2M + QIMC + 3QIMCkw\nl kh\nl + 2QIMC(L −1)(2kw\nl kh\nl +\n1) + 4QIQoSMC\nkw\nl = 5, kh\nl = 5, C = 2M, L = 5\nRJAPCBN\nQ2I2C + QIMC + QI + QIMCkw\nl kh\nl + (L −1)QIC2kw\nl kh\nl\nkw\nl = 5, kh\nl = 5, C = 2M, L = 5\n4\n5\n6\n7\n8\n9\n210\n220\n230\n240\n250\n260\n270\n280\n290\nWorst-case sum rate (bits/s/Hz)\nFig. 9: Worst-case sum rate at different no. of AP antennas.\nfor AP clustering and beamforming design with perfect CSI\nindividually, which is difﬁcult to achieve the optimal solution.\nThe JcbNet is joint AP clustering and beamforming design in\nperfect CSI scenarios, which also does not take into account\nthe robustness of imperfect CSI scenarios. On the contrary,\nin addition to being designed for joint AP clustering and\nbeamforming, the proposed RJAPCBN also takes into account\nthe effect of imperfect CSI in the optimization problem. This\neffectively improves the robustness of imperfect CSI scenarios.\nThus, the proposed RJAPCBN achieves better worst-case sum-\nrate performance with a smaller Qave with imperfect CSI.\nC. Computational Complexity\nTable II shows the computational complexity of several\nalgorithms. To better compare the computational complexity,\nthe number of multiplications of several algorithms under\ndifferent number of users is shown in Fig.11. The number of\nmultiplications for the S-WMMSE, WMMSE, CNNs, JcbNet\nand the proposed RJAPCBN is about 109, 108, 107 ∼108,\n106 and 106, where the computational complexity of the\nproposed RJAPCBN is the lowest. The reasons are as follows:\nThe S-WMMSE needs multiple matrix inversions and binary\nsearches with high computational complexity, thus it has the\n4\n5\n6\n7\n8\n9\n9\n10\n11\n12\n13\n14\n15\n16\nFig. 10: Qave at different number of AP antennas.\nhighest computational complexity. The WMMSE also requires\nmultiple matrix inversions, hence its computational complexity\nis higher. The CNNs reduces the computational complexity\ncompared to the WMMSE and S-WMMSE. Nevertheless, the\nCNNs also contains the FC layers with a high number of\nneurons, which increases the computational complexity. Con-\nversely, the JcbNet and the proposed RJAPCBN apply the CL\nwith parameter sharing mechanism to effectively reduce the\ncomputational complexity. Since the number of convolution\nunits in each layer of the proposed RJAPCBN is less than that\nof the JcbNet, the computational complexity of the proposed\nRJAPCBN is smaller than that of the JcbNet. In summary,\nthe proposed RJAPCBN is a low-complexity robust joint AP\nclustering and beamforming design method.\nVI. CONCLUSION\nIn this paper, a low-complexity unsupervised deep learning\nmethod RJAPCBN is proposed for roubst joint AP clustering\nand beamforming design with imperfect CSI in cell-free sys-\ntems. The proposed RJAPCBN mainly includes the CSI con-\nversion, residual network, adaptive AP clustering, beamform-\ning conversion, power constraint and updating slack variable\nmodules, which are combined for closed-loop unsupervised\n12\n10\n12\n14\n16\n18\n20\n106\n107\n108\n109\n1010\nNumber of multiplications\nWMMSE\nS-WMMSE\nCNN\nJcbNet\nRJAPCBN\nFig. 11: Computational complexity at different no. of users.\ntraining to automatically ﬁnd the optimal AP clustering and\nbeamforming design with imperfect CSI in cell-free systems.\nNumerical results demonstrated that the proposed RJAPCBN\nachieves a higher worst-case sum rate under a smaller number\nof AP clustering with high computational efﬁciency.\nAPPENDIX A\nPROOF OF PROPOSITION 3\nIn cell-free systems, long-range APs serving users consume\nprecious power and bandwidth resources, while contributing\nlittle useful power due to high path losses [7]. In other words,\nfor the ith user, if the qth AP is a longer-range AP and the\npth AP is a shorter-range AP, then POOL\n\u0000H3D\nmod[q, i, :]\n\u0001\n<\nPOOL\n\u0000H3D\nmod[p, i, :]\n\u0001\ndue to the fact that the path loss of the\nqth AP is higher than that of the pth AP. On the other hand,\nthe 1 × 1 CL has the parameter-sharing mechanism, i.e., the\nparameters of 1 × 1 CL are the same for POOL\n\u0000H3D\nmod[q, i, :]\n\u0001\nand POOL\n\u0000H3D\nmod[q, i, :]\n\u0001\n. Consequently, based on Eq.(25), it\nis convenient to obtain tq\ni < tp\ni . Thus, we complete the proof\nof Proposition 3.\nREFERENCES\n[1] D. Wang, X. You, Y. Huang et al., “Full-spectrum cell-free ran for\n6g systems: system design and experimental results,” Science China\nInformation Sciences, vol. 66, no. 3, p. 130305, Feb. 2023.\n[2] X. You, Y. Huang, S. Liu et al., “Toward 6g TKµ extreme connec-\ntivity: Architecture, key technologies and experiments,” IEEE Wireless\nCommunications, vol. 30, no. 3, pp. 86–95, Jun. 2023.\n[3] G. Chen, Z. Wang, Y. Jia, Y. Huang, and L. Yang, “An efﬁcient architec-\nture search for scalable beamforming design in cell-free systems,” IEEE\nTransactions on Vehicular Technology, pp. 1–13, 2024.\n[4] J. Yao, J. Xu, W. Xu, D. W. K. Ng, C. Yuen, and X. You, “Robust\nbeamforming design for ris-aided cell-free systems with csi uncertainties\nand capacity-limited backhaul,” IEEE Transactions on Communications,\nvol. 71, no. 8, pp. 4636–4649, Aug. 2023.\n[5] Z. Wang, J. Zhang, H. Q. Ngo et al., “Uplink precoding design for cell-\nfree massive mimo with iteratively weighted mmse,” IEEE Transactions\non Communications, vol. 71, no. 3, pp. 1646–1664, Mar. 2023.\n[6] D. Wang, M. Tao, X. Zeng, and J. Liang, “Federated learning for\nprecoding design in cell-free massive mimo systems,” IEEE Open\nJournal of the Communications Society, vol. 4, pp. 1567–1582, 2023.\n[7] H. A. Ammar, R. Adve, S. Shahbazpanahi, G. Boudreau, and K. V.\nSrinivas, “User-centric cell-free massive mimo networks: A survey of\nopportunities, challenges and solutions,” IEEE Communications Surveys\n& Tutorials, vol. 24, no. 1, pp. 611–652, 1st Quart. 2022.\n[8] P. Tseng, “Convergence of a block coordinate descent method for\nnondifferentiable minimization,” Journal of optimization theory and\napplications, vol. 109, pp. 475–494, Jun. 2001.\n[9] M. Hong, R. Sun, H. Baligh, and Z.-Q. Luo, “Joint base station\nclustering and beamformer design for partial coordinated transmission\nin heterogeneous networks,” IEEE Journal on Selected Areas in Com-\nmunications, vol. 31, no. 2, pp. 226–240, Jan. 2013.\n[10] A. A. Khan, R. S. Adve, and W. Yu, “Optimizing downlink resource al-\nlocation in multiuser mimo networks via fractional programming and the\nhungarian algorithm,” IEEE Transactions on Wireless Communications,\nvol. 19, no. 8, pp. 5162–5175, Aug. 2020.\n[11] K. Shen and W. Yu, “Fractional programming for communication\nsystems—part ii: Uplink scheduling via matching,” IEEE Transactions\non Signal Processing, vol. 66, no. 10, pp. 2631–2644, May 2018.\n[12] M. Gr¨otschel, L. Lov´asz et al., Geometric algorithms and combinatorial\noptimization.\nSpringer Science & Business Media, 2012, vol. 2.\n[13] R. G. Baraniuk, “Compressive sensing [lecture notes],” IEEE signal\nprocessing magazine, vol. 24, no. 4, pp. 118–121, Jul. 2007.\n[14] H. A. Ammar, R. Adve, S. Shahbazpanahi, G. Boudreau, and K. V.\nSrinivas, “Downlink resource allocation in multiuser cell-free mimo\nnetworks with user-centric clustering,” IEEE Transactions on Wireless\nCommunications, vol. 21, no. 3, pp. 1482–1497, Mar. 2022.\n[15] L. Bai, Y. Yang, M. Chen, C. Feng, C. Guo, W. Saad, and S. Cui,\n“Computer vision-based localization with visible light communications,”\nIEEE Transactions on Wireless Communications, vol. 21, no. 3, pp.\n2051–2065, Mar. 2022.\n[16] Y. He, L. Dai, and H. Zhang, “Multi-branch deep residual learning for\nclustering and beamforming in user-centric network,” IEEE Communi-\ncations Letters, vol. 24, no. 10, pp. 2221–2225, Jun. 2020.\n[17] G. Chen, S. He, Z. An, Y. Huang, and L. Yang, “A deep learning\nmethod: Qos-aware joint ap clustering and beamforming design for cell-\nfree networks,” IEEE Transactions on Communications, vol. 71, no. 12,\npp. 7023–7038, Dec. 2023.\n[18] W. Xu, Y. Cui, H. Zhang, G. Y. Li, and X. You, “Robust beamforming\nwith partial channel state information for energy efﬁcient networks,”\nIEEE Journal on Selected Areas in Communications, vol. 33, no. 12,\npp. 2920–2935, Dec. 2015.\n[19] M. F. Hanif, L.-N. Tran, A. T¨olli, M. Juntti, and S. Glisic, “Efﬁcient\nsolutions for weighted sum rate maximization in multicellular networks\nwith channel uncertainties,” IEEE Transactions on Signal Processing,\nvol. 61, no. 22, pp. 5659–5674, Nov. 2013.\n[20] A. Tajer, N. Prasad, and X. Wang, “Robust linear precoder design\nfor multi-cell downlink transmission,” IEEE Transactions on Signal\nProcessing, vol. 59, no. 1, pp. 235–251, Jan. 2011.\n[21] Q. Shi, M. Razaviyayn, Z.-Q. Luo, and C. He, “An iteratively weighted\nmmse approach to distributed sum-utility maximization for a mimo\ninterfering broadcast channel,” IEEE Transactions on Signal Processing,\nvol. 59, no. 9, pp. 4331–4340, Sep. 2011.\n[22] M. Yuan and Y. Lin, “Model selection and estimation in regression with\ngrouped variables,” Journal of the Royal Statistical Society Series B:\nStatistical Methodology, vol. 68, no. 1, pp. 49–67, Feb. 2006.\n[23] S. Boyd, L. El Ghaoui, E. Feron, and V. Balakrishnan, Linear matrix\ninequalities in system and control theory.\nPhiladelphia, PA, USA:\nSIAM, 1994.\n[24] E. A. Gharavol and E. G. Larsson, “The sign-deﬁniteness lemma and\nits applications to robust transceiver optimization for multiuser mimo\nsystems,” IEEE Transactions on Signal Processing, vol. 61, no. 2, pp.\n238–252, Jan. 2013.\n[25] S. P. Boyd and L. Vandenberghe, Convex optimization.\nCambridge\nuniversity press, 2004.\n[26] M. Hasan, S. Das, and M. N. T. Akhand, “Estimating trafﬁc density\non roads using convolutional neural network with batch normalization,”\nin 2021 5th International Conference on Electrical Engineering and\nInformation Communication Technology.\nIEEE, 2021, pp. 1–6.\n[27] J. Zhang, C. Shen, H. Su, M. T. Araﬁn, and G. Qu, “Voltage over-scaling-\nbased lightweight authentication for iot security,” IEEE Transactions on\nComputers, vol. 71, no. 2, pp. 323–336, Feb. 2021.\n[28] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770–778.\n[29] S. Woo, J. Park, J.-Y. Lee, and I. S. Kweon, “Cbam: Convolutional\nblock attention module,” in Proceedings of the European conference on\ncomputer vision (ECCV), 2018, pp. 3–19.\n13\n[30] L. Pellaco, M. Bengtsson, and J. Jald´en, “Deep weighted mmse downlink\nbeamforming,” in 2021 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP).\nIEEE, 2021, pp. 4915–4919.\n[31] Y. C. Eldar and H. Bolcskei, “Block-sparsity: Coherence and efﬁcient\nrecovery,” in 2009 IEEE International Conference on Acoustics, Speech\nand Signal Processing, 2009, pp. 2885–2888.\n[32] J. Guo, C.-K. Wen, S. Jin, and G. Y. Li, “Convolutional neural network-\nbased multiple-rate compressive sensing for massive mimo csi feedback:\nDesign, simulation, and analysis,” IEEE Transactions on Wireless Com-\nmunications, vol. 19, no. 4, pp. 2827–2840, Apr. 2020.\n",
  "categories": [
    "cs.IT",
    "eess.SP",
    "math.IT"
  ],
  "published": "2024-04-03",
  "updated": "2024-04-03"
}