{
  "id": "http://arxiv.org/abs/2404.04510v1",
  "title": "IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials",
  "authors": [
    "Shreyasi Mandal",
    "Ashutosh Modi"
  ],
  "abstract": "Large Language models (LLMs) have demonstrated state-of-the-art performance\nin various natural language processing (NLP) tasks across multiple domains, yet\nthey are prone to shortcut learning and factual inconsistencies. This research\ninvestigates LLMs' robustness, consistency, and faithful reasoning when\nperforming Natural Language Inference (NLI) on breast cancer Clinical Trial\nReports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical Natural\nLanguage Inference for Clinical Trials. We examine the reasoning capabilities\nof LLMs and their adeptness at logical problem-solving. A comparative analysis\nis conducted on pre-trained language models (PLMs), GPT-3.5, and Gemini Pro\nunder zero-shot settings using Retrieval-Augmented Generation (RAG) framework,\nintegrating various reasoning chains. The evaluation yields an F1 score of\n0.69, consistency of 0.71, and a faithfulness score of 0.90 on the test\ndataset.",
  "text": "IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe\nBiomedical Natural Language Inference for Clinical Trials\nShreyasi Mandal\nAshutosh Modi\nIndian Institute of Technology, Kanpur (IIT Kanpur)\n{shreyansi, ashutoshm}@cse.iitk.ac.in\nAbstract\nLarge Language models (LLMs) have demon-\nstrated state-of-the-art performance in vari-\nous natural language processing (NLP) tasks\nacross multiple domains, yet they are prone to\nshortcut learning and factual inconsistencies.\nThis research investigates LLMs’ robustness,\nconsistency, and faithful reasoning when per-\nforming Natural Language Inference (NLI) on\nbreast cancer Clinical Trial Reports (CTRs) in\nthe context of SemEval 2024 Task 2: Safe\nBiomedical Natural Language Inference for\nClinical Trials. We examine the reasoning ca-\npabilities of LLMs and their adeptness at log-\nical problem-solving. A comparative analysis\nis conducted on pre-trained language models\n(PLMs), GPT-3.5, and Gemini Pro under zero-\nshot settings using Retrieval-Augmented Gen-\neration (RAG) framework, integrating various\nreasoning chains. The evaluation yields an F1\nscore of 0.69, consistency of 0.71, and a faith-\nfulness score of 0.90 on the test dataset.\n1\nIntroduction\nClinical trials serve as essential endeavors to eval-\nuate the effectiveness and safety of new medical\ntreatments, playing a pivotal role in advancing ex-\nperimental medicine. Clinical Trial Reports (CTRs)\ndetail the methodologies and outcomes of these\ntrials, serving as vital resources for healthcare pro-\nfessionals in designing and prescribing treatments.\nHowever, the sheer volume of CTRs (e.g., exceed-\ning 400,000 and proliferating) presents a challenge\nfor comprehensive literature assessment when de-\nveloping treatments (Bastian et al., 2010). Natural\nLanguage Inference (NLI) (Bowman et al., 2015)\nemerges as a promising avenue for large-scale inter-\npretation and retrieval of medical evidence bridg-\ning recent findings to facilitate personalized care\n(DeYoung et al., 2020; Sutton et al., 2020). The\nSemEval 2024 Task 2 on the Natural Language In-\nference for Clinical Trials (NLI4CT) (Jullien et al.,\n2024) revolves around annotating statements ex-\ntracted from breast cancer CTRs1 and determining\nthe inference relation between these statements and\ncorresponding sections of the CTRs, such as Eligi-\nbility criteria, Intervention, Results, and Adverse\nevents. By systematically intervening in the state-\nments, targeting numerical, vocabulary, syntax, and\nsemantic reasoning, the task aims to investigate\nLarge Language Models (LLM)s’ consistency and\nfaithful reasoning capabilities.\nIn this paper, we experiment with Gemini\nPro (Team et al., 2023), GPT-3.5 (Brown et al.,\n2020), Flan-T5 (Longpre et al., 2023) and several\npre-trained language models (PLMs) trained on\nbiomedical datasets, namely BioLinkBERT (Ya-\nsunaga et al., 2022), SciBERT (Beltagy et al.,\n2019), ClinicalBERT (Huang et al., 2019). We\nconducted zero-shot evaluations of Gemini Pro and\nGPT-3.5, employing Retrieval Augmented Genera-\ntion (RAG) framework (Lewis et al., 2020) integrat-\ning Tree of Thoughts (ToT) reasoning (Yao et al.,\n2023) facilitating multiple reasoning paths. Our\nexperiments involved applying various instruction\ntemplates to guide the generation process. These\ntemplates were refined through manual compari-\nson of the labels within the training dataset against\nthose generated by the models. The PLMs were\nfine-tuned on the provided training dataset, while\nthe Flan-T5 model was assessed under zero-shot\nconditions.\nGemini Pro emerged as the top-performing\nmodel among all the experimented models, achiev-\ning an F1 score of 0.69, with consistency and faith-\nfulness scores of 0.71 and 0.90, respectively, on the\nofficial test dataset. Notably, a comparative anal-\nysis between GPT-3.5 and Gemini Pro revealed\nshortcomings in GPT-3.5’s performance, particu-\nlarly in instances requiring numerical reasoning.\nFor detailed examination of such instances, please\n1https://clinicaltrials.gov/ct2/home\narXiv:2404.04510v1  [cs.CL]  6 Apr 2024\nClinical Trial Report 1\nEligibility Criterion\n         ...\nIntervention\n      ...\nSingle arm of healthy postmenopausal women to \n      have two breast MRI (baseline and post-treatment)\n      ...\nResults\n         ...\nAdverse Events\nAdverse Events 1:            \n•  Total: 69/258 (26.74%)\n• Anaemia 3/258 (1.16%)\n  ...\nAdverse Events 2:            \n• Total: 64/224 (28.57%)\n• Anaemia 2/224 (0.89%)\n  ...\nClinical Trial Report 2\nEligibility Criterion\n       ...\nIntervention\n      ...\nHealthy women will be screened for Magnetic Reson-\n      ance Imaging (MRI) contraindications, and then \n      undergo contrast injection, and SWIFT acquisition.\n      ...\nResults\n      ...\nAdverse Events \n        ...\n \nStatement 1: \nThe primary trial and the secondary trial \nboth used MRI for their interventions.\nMore than 1/3 of patients in cohort 1 of the \nprimary trial experienced an adverse event.\nLabel: \nStatement 2: \nENTAILMENT\nLabel: CONTRADICTION\nType: Comparison\nType: Single\nFigure 1: Examples of the dataset used in the NLI4CT task. Statement 1 compares the Intervention section from\ntwo different clinical trial reports, while statement 2 is based on the Adverse Events section of the first clinical trial\nreport. The evaluation of the first statement requires textual inference skills, while the second requires numerical\ninference skills.\nrefer to Appendix A, where an example showcases\nGPT-3.5’s accurate inference yet inadequate con-\nclusion. The code to reproduce the experiments\nmentioned in this paper is publicly available.2\n2\nBackground\n2.1\nRelated Work\nPretrained Language Models (PLMs) and Large\nLanguage Models (LLMs) exhibit the potential to\nyield promising outcomes in the biomedical do-\nmain due to their ability to comprehend and process\ncomplex medical data effectively. BioLinkBERT\n(Yasunaga et al., 2022), pre-trained on PubMed3,\nutilizes hyperlinks within documents. It has at-\ntained state-of-the-art (SOTA) performance across\na wide range of tasks and various medical NLP\nbenchmarks, namely BLURB (Gu et al., 2021) and\nBioASQ (Nentidis et al., 2020). SciBERT (Beltagy\net al., 2019) is trained on scientific publications\nfrom the biomedical domain in Semantic Scholar4.\nClinicalBERT (Huang et al., 2019) is trained using\nclinical text data sourced from approximately 2 mil-\nlion clinical notes contained within the MIMIC-III\ndatabase (Johnson et al., 2016). Kanakarajan and\nSankarasubbu (2023) employed a fine-tuned Flan-\nT5-xxl model with instruction tuning, achieving an\nF1 score of 0.834 on the SemEval 2023 Task 7 (Jul-\nlien et al., 2023a,b). Zhou et al. (2023) performed\njoint semantics encoding of the clinical statements\nfollowed by multi-granularity inference through\nsentence-level and token-level encoding, getting an\n2https://github.com/Exploration-Lab/IITK-\nSemEval-2024-Task-2-Clinical-NLI\n3https://pubmed.ncbi.nlm.nih.gov\n4https://www.semanticscholar.org\nF1 score of 0.856. Although these models have\nachieved high performance, there remains a need\nfor further investigation into their application in\nvital areas such as real-world clinical trials.\nGPT-3.5, developed by OpenAI5 and compris-\ning 175 billion parameters, uses alternating dense\nand locally banded sparse attention patterns in the\ntransformer layers (Child et al., 2019; Wolf et al.,\n2020). The token size limit for GPT-3.5 (free tier)\nis 4,096. Gemini Pro, developed by Google Deep-\nMind6 uses decoder-only transformers (Vaswani\net al., 2017) and multi-query attention (Shazeer,\n2019) with a context window length of 32,768 to-\nkens.\nData\nNumber of Samples\nLabels\nEntailment\nContradiction\ntrain\n1700\n850\n850\ndev\n200\n100\n100\ntest\n5500\n1841\n3659\nTable 1: The number of samples in each subset of the\ndata. The distribution of the labels between the train and\nthe development set is even. Note: The test set labels\nwere made public after the completion of the task.\n2.2\nTask and Dataset Description\nThe NLI4CT task (Jullien et al., 2024) focuses on\ntextual entailment based on a collection of breast\ncancer CTRs, statements, explanations and labels\nannotated by domain expert annotators. The CTRs\nare in English. The CTRs are segmented into four\nsections - eligibility criteria, intervention details,\n5https://openai.com\n6https://deepmind.google\nGemini-Pro\nClinical Trial Report\n+\nStatement\n+\nQuestion\nInstruction Template\nInput 1\nGenerated \nExplanation\nBased on your explanation,\ndoes the given context imply \nthe hypothesis. Write one \nword answer - Yes or No.\nInput 2\nLabel : Yes / No\nModel\nOutput\nFigure 2: An overview of the proposed system architecture used for the NLI4CT Task\nresults, and adverse events. The statements, with an\naverage length of 19.5 tokens, make claims about\nthe information contained in one of the sections\nof a CTR or compare the same section from two\ndifferent CTRs as seen in Figure 1. The task in-\nvolves determining the inference relation (entail-\nment or contradiction) between CTR-statement\npairs. The dataset consists of 999 Clinical Trial\nReports (CTRs) and 7400 annotated statements,\nwhich are divided into train, development and test\nsets. Table 1 provides statistics for the dataset.\n3\nSystem Overview\nLLMs such as GPT-3 (Brown et al., 2020) and\nGemini Pro (Team et al., 2023) have shown re-\nmarkable performances across various tasks. For\nthe NLI4CT task, we have experimented with Gem-\nini Pro, GPT-3.5, Flan-T5 (Longpre et al., 2023),\nBioLinkBERT (Yasunaga et al., 2022), SciBERT\n(Beltagy et al., 2019), ClinicalBERT (Huang et al.,\n2019) and ClinicalTrialBioBert-NLI4CT7. The per-\nformance of the different models is shown in Figure\n7. Zero-shot evaluation was done on Gemini Pro\nand GPT-3.5, Flan-T5 was instruction fine-tuned\nfollowing Kanakarajan and Sankarasubbu (2023),\nand the rest of the models were trained on the given\ntrain and development dataset. Gemini Pro and\nGPT-3.5 were considered for further experimenta-\ntion because of their superior performance.\nThe proposed system utilizes structured instruc-\ntion templates and multi-turn conversation tech-\nniques to generate explanations and labels for the\nstatements provided as input, as shown in Figure 2.\nReasoning is an essential ability required by\nan LLM to solve complex problems (Qiao et al.,\n2022). Tree of Thoughts (ToT) framework (Yao\n7https://huggingface.co/domenicrosati/ClinicalTrialBioBert-\nNLI4CT\net al., 2023) and Chain-of-Thought (CoT) reason-\ning (Wei et al., 2022) is integrated into the models,\nfacilitating multiple reasoning paths.\n3.1\nReasoning Frameworks\nChain-of-Thought (CoT) prompting (Wei et al.,\n2022) has demonstrated promising results in im-\nproving the reasoning abilities of LLMs. To eval-\nuate Gemini Pro and GPT-3.5, we used Zero-shot-\nCoT (Kojima et al., 2022) prompt reasoning with-\nout requiring few-shot demonstrations. The phrase\n“Let’s think step by step” is added after the instruc-\ntion as shown in Figure 3.\n“{premise}\n{statement}\nIs the given statement correct based on the information \nprovided above? Let’s think step by step.”\n>> {explanation by model}\n“From your answer above, is the statement true or false? \nWrite one word answer.”\n>> {True / False}\nFigure 3: Instruction template for CoT prompting\nTree-of-Thought (ToT) framework (Yao et al.,\n2023; Long, 2023) relies on trial and error method\nto solve complex reasoning tasks. It facilitates\nmulti-round conversations and backtracking. Our\nsystem allows for three reasoning paths using the\nprompt shown in Figure 4.8\nFor the evaluation of the model, the input to\nGemini Pro and GPT-3.5 is constructed using an\ninstruction template containing the appropriate\nprompt for ToT or CoT reasoning, data from the\nCTR which constitutes the premise and the state-\nment or the hypothesis as shown in Figure 2. A\n8https://github.com/dave1010/tree-of-thought-prompting\nImagine three different clinical experts are answering \nthe question given below.\nAll experts will write down first step of their thinking,\nthen share it with the group.\nThen all experts will go on to the next step of their\nthinking.\nIf any expert realises they're wrong at any point then\nthey leave.\nThey will continue till a definite conclusion is reached.\nFigure 4: Prompt for Tree of Thought reasoning\nseries of two questions is presented to the model to\ngenerate both the explanation and the correspond-\ning label. Multi-turn conversation (Zhang et al.,\n2018) is used to include the generated explanation\nas context for generating the final label. The expla-\nnation is also retained for further experimentations.\nThe generated final label is converted as follows:\n{\"Yes\": \"Entailment\", \"No\": \"Contradiction\"}. A\ncomparison of the performance of GPT-3.5 and\nGemini Pro after integrating CoT and ToT reason-\ning frameworks is shown in Figure 6.\n4\nExperimental setup\n4.1\nData Preprocessing\nAs discussed in Section 2.2, the statements can\nmake claims about the information contained in\none of the sections of a CTR, which is then called\na “Single” statement or compare the same section\nfrom two different CTRs, called a “Comparison”\nstatement. In “Single” statements, the term “pri-\nmary” is employed to assert a claim. Evidence\nfrom the CTR is compiled into a unified text struc-\nture, exemplified as follows: “For the primary trial\nparticipants, {primary evidences}”. In contrast,\nfor “Comparison” statements, the term “secondary”\naccompanies “primary”. The evidences are then\ncompiled as: “For the primary trial participants,\n{primary evidences}. For the secondary trial par-\nticipants, {secondary evidences}”.\n4.2\nHyperparameter Tuning\nFor Gemini Pro, the temperature of the model\nis set to 0.7 and the safety settings are set to\n\"BLOCK_NONE\". For GPT-3.5, the models \"gpt-\n3.5-turbo-0613\" and \"gpt-3.5-turbo-1106\" are used\nfor experimentation among which \"gpt-3.5-turbo-\n0613\" performs considerably better. The tempera-\nture of the model is set to 0.6.\n4.3\nPrompt Engineering\nThe system was experimented with several prompts\nto improve its performance. The explanations gen-\nerated by the model were examined manually to\nidentify instances where the solution deviated from\nthe correct path. The prompt “You are a clinical ex-\npert and can seamlessly perform natural language\ninference” was introduced to give the model an\nidentity. Additionally, rules were enforced to con-\nfine the model’s output within the provided context\nand to prevent hallucinations, achieved through the\nprompt: “Please align with the context given and\ndo not make any false assumptions of your own.”\nFurthermore, to integrate CoT reasoning within\nthe ToT framework, the prompt ”Provide a step-\nby-step explanation of your thought process” was\nintroduced. The final instruction template is shown\nin Figure 5.\nSeveral experiments were conducted to assess\nthe model’s performance on extracting the labels\n\"Entailment\" or \"Contradiction\" in the second\nquestion of the multi-turn conversation. The F1\nscores for various prompts on the development set\nare presented in Table 2. Ultimately, Prompt 4\ndemonstrated the best performance and was chosen\nfor the final pipeline.\nPrompt\nF1 score\nBased on the comprehensive evaluation\nof the model’s responses, is the given\nhypothesis deemed to be true or false?\nWrite one word answer.\n0.689\nDoes this imply that the given hypothesis\nis supporting the report or not? Give one\nword answer (Yes / No).\n0.667\nFrom your answer above, is the statement\ntrue or false? Write one word answer.\n0.656\nBased on your explanation, does the given\ncontext imply the hypothesis. Write one\nword answer.\n0.723\nTable 2: Performance of the model on the dev data for\ndifferent prompts for extracting the labels\n4.4\nEvaluation Metrics\nThe NLI4CT task (Jullien et al., 2024) is evaluated\non the basis of three metrics - F1 score, consistency\nand faithfulness. Faithfulness measures the accu-\nracy of the system’s predictions by evaluating its\nability to predict outcomes for altered inputs cor-\nrectly. If the model correctly adjusts its predictions\nYou are a clinical expert and can seamlessly perform natural language inference.\nImagine three different clinical experts are answering the question given below.\nAll experts will write down first step of their thinking, then share it with the group.\nThen all experts will go on to the next step of their thinking.\nIf any expert realises they're wrong at any point then they leave.\nThey will continue till a definite conclusion is reached.\nPlease align with the context given and do not make any false assumptions of your\nown.\nCONTEXT: {evidences}\nQUESTION: Does the context imply the hypothesis {statement}? Provide a step-by-\nstep explanation of your thought process.\nTurn 1\nBased on the comprehensive evaluation of the model's responses, does the given\ncontext imply the hypothesis? Write one word answer - Yes or No.\nTurn 2\nModel Identity\nToT Reasoning\nCoT Reasoning\nEvidences from CTR\nReduction of \nHallucination\nFinal Question\nFigure 5: Final Instruction Template\nin response to semantic alterations, it demonstrates\nhigher faithfulness. On the other hand, consistency\nevaluates the model’s ability to provide consistent\npredictions for semantically equivalent inputs.\n5\nResults\nThe zero-shot evaluation of Gemini Pro yielded an\nF1 score of 0.69, with a consistency of 0.71 and a\nfaithfulness score of 0.90 on the official test dataset.\nOur system achieved a fifth-place ranking based\non the faithfulness score, a sixteenth-place ranking\nbased on the consistency score, and a twenty-first-\nplace ranking based on the F1 score. Gemini Pro\noutperforms GPT-3.5 with an improvement in F1\nscore by +1.9%, while maintaining almost similar\nconsistency score. Additionally, the faithfulness\nscore of Gemini Pro improves by +3.5% compared\nto GPT-3.5, as illustrated in Table 3.\nModel\nBase F1\nConsistency\nFaithfulness\nGemini Pro\n0.691\n0.712\n0.901\nGPT-3.5\n0.672\n0.713\n0.866\nTable 3: Results on the test data using Gemini Pro and\nGPT-3.5\nThe system utilizing Gemini Pro attained an F1\nscore of 0.72, while GPT-3.5 achieved an F1 score\nof 0.68 on the training dataset. Manual examination\nof the model-generated explanations and a compar-\nison of the generated labels with the original labels\nwas conducted to refine the prompts and enhance\nthe model’s responses.\nFigure 6: Comparison of the performance of Gemini Pro\nand GPT-3.5 without the integration of any reasoning\nframework, with CoT reasoning, with ToT reasoning\nand with both the reasoning frameworks combined.\nAs depicted in Figure 6, the integration of CoT\nreasoning led to an increase in performance for\nGemini Pro and GPT-3.5 by 0.8% and 1.9%, respec-\ntively. Furthermore, upon integrating the ToT rea-\nsoning framework, the performance improved by\n3.2% and 4.3%, respectively. When both ToT and\nCoT reasoning were integrated, the models showed\nan increase in performance by 3.8% and 5.1%, re-\nspectively, compared to the baseline model.\nFigure 7 compares the performance of Gemini Pro\nand GPT-3.5, both without reasoning frameworks,\nwith Flan-T5 and other experimented PLMs. Gem-\nini Pro achieved the highest F1 score of 0.65, fol-\nlowed closely by GPT-3.5 with an F1 score of 0.62.\nFlan-T5 performed moderately with an F1 score\nof 0.57, while BioLinkBERT, SciBERT, Clinical-\nBERT, and CTBioBERT displayed lower F1 scores\nranging from 0.46 to 0.53.\nFigure 7: Performance (F1 Score) of the different exper-\nimented models. Note: CTBioBert represents the model\nClinicalTrialBioBert-NLI4CT.\nA comparative analysis between GPT-3.5 and\nGemini Pro highlighted GPT-3.5’s shortcomings\nin tasks requiring logical reasoning. Appendix A\npresents the example responses for both the models.\nThe appendix further analyzes potential reasoning\nerrors made by GPT-3.5 and Gemini Pro.\n6\nConclusion\nThis paper presents an evaluation of several pre-\ntrained language models (PLMs), and GPT-3.5,\nGemini Pro, under zero-shot conditions. Our anal-\nysis focuses on assessing the reasoning capabilities\nof GPT-3.5 and Gemini Pro and their adeptness at\nlogical problem-solving. In the NLI4CT task, we\nachieved an F1 score of 0.691, consistency of 0.71,\nand faithfulness of 0.90. Additionally, our findings\nunderscore that prompt engineering is crucial for\nlarge language models (LLMs). We have made our\ninstruction templates and code publicly available\nto facilitate reproducibility.\n7\nAcknowledgments\nWe would like to thank the anonymous review-\ners for their careful reading of our manuscript and\ntheir insightful comments and constructive criti-\ncism. Their feedback has greatly helped us to im-\nprove the clarity and rigor of this work.\nReferences\nHilda Bastian, Paul Glasziou, and Iain Chalmers. 2010.\nSeventy-five trials and eleven systematic reviews a\nday: how will we ever keep up?\nPLoS medicine,\n7(9):e1000326.\nIz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciB-\nERT: A pretrained language model for scientific text.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 3615–\n3620, Hong Kong, China. Association for Computa-\ntional Linguistics.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nIn Proceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n632–642, Lisbon, Portugal. Association for Compu-\ntational Linguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nRewon Child,\nScott Gray,\nAlec Radford,\nand\nIlya\nSutskever.\n2019.\nGenerating\nlong\nse-\nquences with sparse transformers. arXiv preprint\narXiv:1904.10509.\nJay DeYoung, Eric Lehman, Ben Nye, Iain J Mar-\nshall, and Byron C Wallace. 2020. Evidence infer-\nence 2.0: More data, better models. arXiv preprint\narXiv:2005.04177.\nYu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto\nUsuyama, Xiaodong Liu, Tristan Naumann, Jianfeng\nGao, and Hoifung Poon. 2021. Domain-specific lan-\nguage model pretraining for biomedical natural lan-\nguage processing. ACM Transactions on Computing\nfor Healthcare (HEALTH), 3(1):1–23.\nKexin Huang, Jaan Altosaar, and Rajesh Ranganath.\n2019.\nClinicalbert: Modeling clinical notes and\npredicting hospital readmission.\narXiv preprint\narXiv:1904.05342.\nAlistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H\nLehman, Mengling Feng, Mohammad Ghassemi,\nBenjamin Moody, Peter Szolovits, Leo Anthony Celi,\nand Roger G Mark. 2016. Mimic-iii, a freely accessi-\nble critical care database. Scientific data, 3(1):1–9.\nMaël Jullien, Marco Valentino, and André Freitas. 2024.\nSemEval-2024 task 2: Safe biomedical natural lan-\nguage inference for clinical trials. In Proceedings of\nthe 18th International Workshop on Semantic Evalua-\ntion (SemEval-2024). Association for Computational\nLinguistics.\nMael Jullien, Marco Valentino, Hannah Frost, Paul\nO’Regan, Dónal Landers, and Andre Freitas. 2023a.\nNLI4CT: Multi-evidence natural language inference\nfor clinical trial reports. In Proceedings of the 2023\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 16745–16764, Singapore.\nAssociation for Computational Linguistics.\nMaël Jullien, Marco Valentino, Hannah Frost, Paul\nO’regan, Donal Landers, and André Freitas. 2023b.\nSemEval-2023 task 7: Multi-evidence natural lan-\nguage inference for clinical trial data. In Proceedings\nof the 17th International Workshop on Semantic Eval-\nuation (SemEval-2023), pages 2216–2226, Toronto,\nCanada. Association for Computational Linguistics.\nKamal Raj Kanakarajan and Malaikannan Sankara-\nsubbu. 2023. Saama ai research at semeval-2023\ntask 7: Exploring the capabilities of flan-t5 for multi-\nevidence natural language inference in clinical trial\ndata. In Proceedings of the 17th International Work-\nshop on Semantic Evaluation (SemEval-2023), pages\n995–1003.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. Advances in\nneural information processing systems, 35:22199–\n22213.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\nPetroni, Vladimir Karpukhin, Naman Goyal, Hein-\nrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\ntäschel, et al. 2020. Retrieval-augmented generation\nfor knowledge-intensive nlp tasks. Advances in Neu-\nral Information Processing Systems, 33:9459–9474.\nJieyi Long. 2023. Large language model guided tree-of-\nthought. arXiv preprint arXiv:2305.08291.\nShayne Longpre, Le Hou, Tu Vu, Albert Webson,\nHyung Won Chung, Yi Tay, Denny Zhou, Quoc V\nLe, Barret Zoph, Jason Wei, et al. 2023. The flan\ncollection: Designing data and methods for effective\ninstruction tuning. arXiv preprint arXiv:2301.13688.\nAnastasios Nentidis, Konstantinos Bougiatiotis, Anas-\ntasia Krithara, and Georgios Paliouras. 2020. Re-\nsults of the seventh edition of the bioasq challenge.\nIn Machine Learning and Knowledge Discovery\nin Databases: International Workshops of ECML\nPKDD 2019, Würzburg, Germany, September 16–20,\n2019, Proceedings, Part II, pages 553–568. Springer.\nShuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen,\nYunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang,\nand Huajun Chen. 2022.\nReasoning with lan-\nguage model prompting: A survey. arXiv preprint\narXiv:2212.09597.\nNoam Shazeer. 2019.\nFast transformer decoding:\nOne write-head is all you need.\narXiv preprint\narXiv:1911.02150.\nReed T Sutton, David Pincock, Daniel C Baumgart,\nDaniel C Sadowski, Richard N Fedorak, and Karen I\nKroeker. 2020. An overview of clinical decision\nsupport systems: benefits, risks, and strategies for\nsuccess. NPJ digital medicine, 3(1):17.\nGemini Team, Rohan Anil, Sebastian Borgeaud,\nYonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,\nRadu Soricut, Johan Schalkwyk, Andrew M Dai,\nAnja Hauth, et al. 2023.\nGemini: a family of\nhighly capable multimodal models. arXiv preprint\narXiv:2312.11805.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing\nsystems, 30.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\net al. 2022. Chain-of-thought prompting elicits rea-\nsoning in large language models. Advances in Neural\nInformation Processing Systems, 35:24824–24837.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\net al. 2020. Transformers: State-of-the-art natural\nlanguage processing. In Proceedings of the 2020 con-\nference on empirical methods in natural language\nprocessing: system demonstrations, pages 38–45.\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\nThomas L. Griffiths, Yuan Cao, and Karthik R\nNarasimhan. 2023.\nTree of thoughts: Deliberate\nproblem solving with large language models.\nIn\nThirty-seventh Conference on Neural Information\nProcessing Systems.\nMichihiro Yasunaga, Jure Leskovec, and Percy Liang.\n2022. LinkBERT: Pretraining language models with\ndocument links. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 8003–8016,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nZhuosheng Zhang, Jiangtong Li, Pengfei Zhu, Hai Zhao,\nand Gongshen Liu. 2018. Modeling multi-turn con-\nversation with deep utterance aggregation. arXiv\npreprint arXiv:1806.09102.\nYuxuan Zhou, Ziyu Jin, Meiwei Li, Miao Li, Xien Liu,\nXinxin You, and Ji Wu. 2023. Thifly research at\nsemeval-2023 task 7: A multi-granularity system for\nctr-based textual entailment and evidence retrieval.\narXiv preprint arXiv:2306.01245.\nAppendix\nA\nExample Responses\nAs illustrated in Figure 8, GPT-3.5 exhibits lim-\nitations in numerical reasoning tasks. Although\nsteps 1 and 2 of the example are executed correctly,\nGPT-3.5 starts hallucinating in step 3, leading to\nillogical reasoning and ultimately yielding an in-\ncorrect conclusion that the statement is incorrect.\nWhen the same input is given to Gemini Pro, it\ncorrectly concludes that the statement entails the\nCTR as shown in Figure 9.\nStep 1: Assess the exclusion criteria for the primary trial.\n     - The exclusion criteria mention a Karnofsky Performance status <90% \n        as an exclusion criterion.\n     - This means that patients with a Karnofsky status below 90% would not \n        be eligible for the trial.\nStep 2: Compare the Karnofsky status of 94% mentioned in the hypothesis \n        with the eligibility criteria.\n     - According to the hypothesis, patients with a Karnofsky status of 94% \n        would be eligible for the primary trial.\nStep 3: However, based on the exclusion criteria, a Karnofsky Performance \n        status < 90% is not eligible, regardless of the specific value (i.e. 94%).\nConclusion: \"Patients with a Karnofsky status of 94% are eligible for the \n        primary trial\" is incorrect.\nFigure 8: Example of an incorrect response by GPT-3.5\nStep 1: Check the inclusion criteria for Karnofsky Performance status.\nStep 2: The inclusion criteria state that Karnofsky Performance status must\nbe >= 90%.  \nConclusion: Patients with a Karnofsky status of 94% are eligible for the\nprimary trial because the inclusion criteria state that Karnofsky\nPerformance status must be >= 90%. \nFigure 9: Response by Gemini Pro for the same state-\nment\nFigure 10 showcases an excellent example of\nGemini Pro’s mathematical reasoning.\n   Hypothesis: Neutropenia affected the majority of patients in cohort 1 of \n                the primary trial.\n   Label: Contradiction\nExplanation:\n...              \nFrom the context, we know that the total number of patients in cohort 1 of\nthe primary trial is 69, and the number of patients who experienced\nneutropenia in  cohort 1 of the primary trial is 4. Therefore, the\npercentage of patients in cohort 1 of the primary trial who experienced\nneutropenia is 4/69 * 100 = 5.8%.   \n                                \nSince 5.8% is not the majority, the hypothesis is incorrect.\nFigure 10: An example response by Gemini Pro show-\ncasing its mathematical reasoning ability.\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG"
  ],
  "published": "2024-04-06",
  "updated": "2024-04-06"
}