{
  "id": "http://arxiv.org/abs/2404.05057v1",
  "title": "TimeCSL: Unsupervised Contrastive Learning of General Shapelets for Explorable Time Series Analysis",
  "authors": [
    "Zhiyu Liang",
    "Chen Liang",
    "Zheng Liang",
    "Hongzhi Wang",
    "Bo Zheng"
  ],
  "abstract": "Unsupervised (a.k.a. Self-supervised) representation learning (URL) has\nemerged as a new paradigm for time series analysis, because it has the ability\nto learn generalizable time series representation beneficial for many\ndownstream tasks without using labels that are usually difficult to obtain.\nConsidering that existing approaches have limitations in the design of the\nrepresentation encoder and the learning objective, we have proposed Contrastive\nShapelet Learning (CSL), the first URL method that learns the general-purpose\nshapelet-based representation through unsupervised contrastive learning, and\nshown its superior performance in several analysis tasks, such as time series\nclassification, clustering, and anomaly detection. In this paper, we develop\nTimeCSL, an end-to-end system that makes full use of the general and\ninterpretable shapelets learned by CSL to achieve explorable time series\nanalysis in a unified pipeline. We introduce the system components and\ndemonstrate how users interact with TimeCSL to solve different analysis tasks\nin the unified pipeline, and gain insight into their time series by exploring\nthe learned shapelets and representation.",
  "text": "TimeCSL: Unsupervised Contrastive Learning of General\nShapelets for Explorable Time Series Analysis\nZhiyu Liang\nHarbin Institute of Technology\nHarbin, China\nzyliang@hit.edu.cn\nChen Liang\nHarbin Institute of Technology\nHarbin, China\n23B903050@stu.hit.edu.cn\nZheng Liang\nHarbin Institute of Technology\nHarbin, China\nlz20@hit.edu.cn\nHongzhi Wang∗\nHarbin Institute of Technology\nHarbin, China\nwangzh@hit.edu.cn\nBo Zheng\nCnosDB Inc.\nBeijing, China\nharbour.zheng@cnosdb.com\nABSTRACT\nUnsupervised (a.k.a. Self-supervised) representation learning (URL)\nhas emerged as a new paradigm for time series analysis, because\nit has the ability to learn generalizable time series representation\nbeneficial for many downstream tasks without using labels that\nare usually difficult to obtain. Considering that existing approaches\nhave limitations in the design of the representation encoder and the\nlearning objective, we have proposed Contrastive Shapelet Learn-\ning (CSL), the first URL method that learns the general-purpose\nshapelet-based representation through unsupervised contrastive\nlearning, and shown its superior performance in several analysis\ntasks, such as time series classification, clustering, and anomaly\ndetection. In this paper, we develop TimeCSL, an end-to-end sys-\ntem that makes full use of the general and interpretable shapelets\nlearned by CSL to achieve explorable time series analysis in a unified\npipeline. We introduce the system components and demonstrate\nhow users interact with TimeCSL to solve different analysis tasks\nin the unified pipeline, and gain insight into their time series by\nexploring the learned shapelets and representation.\nPVLDB Reference Format:\nZhiyu Liang, Chen Liang, Zheng Liang, Hongzhi Wang, and Bo Zheng.\nTimeCSL: Unsupervised Contrastive Learning of General Shapelets for\nExplorable Time Series Analysis. PVLDB, 17(3): 386-399, 2023.\ndoi:10.14778/3632093.3632103\nPVLDB Artifact Availability:\nThe source code, data, and/or other artifacts have been made available at\nhttps://github.com/real2fish/CSL.\n1\nINTRODUCTION\nA time series is one (a.k.a. univariate) or a group (multivariate) of\nvariables observed over time. Time series analysis by discovering\ndependencies of the time-evolving variables can offer important\n∗Corresponding author.\nThis work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 17, No. 3 ISSN 2150-8097.\ndoi:10.14778/3632093.3632103\ninsights into the underlying phenomena, which is useful for real-\nworld applications in various scenarios, such as manufacturing [6],\nmedicine [9] and finance [2].\nA major challenge in modeling time series is the lack of labels,\nbecause the underlying states required for labeling these time-\ndependent data are difficult to understand, even for domain spe-\ncialists [13]. For this reason, recent studies focus on unsupervised\n(a.k.a. self-supervised) representation learning (URL) of time se-\nries [3, 4, 13, 19–21], which aims to train a neural network (called\nencoder) without accessing the ground-truth labels to embed the\ndata into feature vectors. The learned features (a.k.a. representation)\ncan then be used for training models to solve a downstream analysis\ntask, using little annotated data compared to traditional super-\nvised methods [21]. Not only that, the features are more general-\npurpose since they can benefit several tasks.\nUnfortunately, existing URL approaches for time series have\ntwo limitations. First, these methods focus on the representation\nencoders based on the convolutional neural network (CNN) [5,\n15] and the Transformer [17]. However, these architectures are\noriginally designed for domains such as computer vision and natural\nlanguage processing, and have been shown to face many difficulties\nin modeling time series, due to the lack of capability to deal with\nthe characteristics specific to time series [12, 23]. Second, some\nexisting approaches are based on domain-specific assumptions. For\nexample, Franceschi et al. [4] and Tonekaboni et al. [13] assume that\nthe subseries distant in time are dissimilar, but it is easily violated\nin periodic time series [11]. As a result, these methods cannot be\nwell generalized to different scenarios.\nTo address the above issues, we have proposed Contrastive\nShapelet Learning (CSL) [8], a brand new unsupervised represen-\ntation learning framework for multivariate (and also univariate)\ntime series. To the best of our knowledge, CSL is the first general-\npurpose URL method based on shapelet, an interpretable pattern\nspecifically designed for time series that represents the discrimi-\nnative subsequence. Unlike traditional approaches that learn the\nshapelets for a specific analysis task, such as time series classifi-\ncation [7, 18] or clustering [14, 22], the shapelets of the proposed\nCSL are learned with unsupervised contrastive learning, which has\nshown superiority in many downstream analysis tasks [8], includ-\ning classification, clustering, segment-level anomaly detection, and\nlong time series representation. We summarize the performance of\narXiv:2404.05057v1  [cs.LG]  7 Apr 2024\nClassification\n(Mean Ranking of Accuracy)\nClustering\n(Mean Ranking of \nRI and NMI)\nAnomaly Detection\n(Mean Ranking of F1-Score)\nLong Sequence Representation\n(Mean Ranking of Accuracy)\nEfficiency\n(Mean Ranking of \nTraining Time per Epoch)\nCSL (Ours)\nTS2VEC\nT-Loss\nTNC\nTS-TCC\nTST\n4.0\n2.5\n4.0\n1.0\n2.5\n1.0\n4.0\n2.5\n1.0\n4.0\n2.5\n1.0\n1.0\n2.5\n4.0\nFigure 1: Overall performance of CSL against the competitors\n(smaller is better) regarding classificaton, clustering, anom-\naly detection, long sequence representation and training effi-\nciency. See §5.2, §5.7 and §5.8 in [8] for the details.\nCSL against the competing methods in Figure 1, which is extensively\nevaluated using 38 datasets from various real-world scenarios [8].\nIn this paper, we demonstrate TimeCSL, a novel system that\nmakes full use of CSL to achieve explorable time series analysis\nfor various tasks in a unified process. TimeCSL includes an end-\nto-end unified pipeline that first learns the general shapelets of\nmultiple scales and (dis)similarity metrics without any annotation\nby running the CSL algorithm [8]. Then, it addresses different time\nseries analysis tasks by building arbitrary task-oriented analyzers\n(e.g., SVM for classification and K-Means for clustering) on top\nof the general-purpose shapelet-based features. The pipeline has\nshown superior performance compared to that of the complex task-\nspecific approaches, and significantly outperforms the traditional\nsupervised methods when there are few available labels. We refer\nthe interested readers to our research paper [8] for more details.\nTimeCSL provides flexible and intuitive visual exploration of\nthe raw time series, the learned shapelets, and the shapelet-based\ntime series representation, offering a useful tool for interpreting the\nanalysis results. Users can experiment with the system using their\nown data to explore the learned shapelet-based features, which\nare usually more insightful and intuitive-to-understand than the\ncomplex raw time series. This “explorable” analysis can help to\nexplain the decisions made by the task-oriented analyzer.\n2\nTHE TIMECSL SYSTEM\nAs depicted in Figure 2, TimeCSL is comprised of two components,\nincluding Unsupervised Contrastive Shapelet Learning and Explorable\nTime Series Analysis. These components work as follows.\n2.1\nUnsupervised Contrastive Shapelet Learning\nThe goal of this component is to learn general shapelets from the\ntraining time series, which transforms the raw time series into\nshapelet-based representation to facilitate different downstream\nanalysis tasks. This is achieved using our proposed CSL method [8].\nTime Series Dataset\n(Uni- or Multi-variate) \nAnalysis Results\n（e.g. Classes / Clusters）\nUnsupervised \nContrastive Shapelet\nLearning (CSL)\nExplorable Time Series Analysis\nGeneral Shapelets \nTask-Oriented Analyzer\n(e.g. SVM / K-Means)\nVisual Exploration\n（e.g. Shapelets / Representations）\nFigure 2: The TimeCSL pipeline.\nGiven a dataset containing 𝑁time series as 𝑿= {𝒙1, 𝒙2, ..., 𝒙𝑁} ∈\nR𝑁×𝐷×𝑇, where each time series 𝒙𝑖∈R𝐷×𝑇has 𝐷variables\n(𝐷≥1) and 𝑇observations ordered by time, CSL embeds 𝒙𝑖into\nthe shapelet-based representation 𝒛𝑖∈R𝐷𝑟𝑒𝑝𝑟using the proposed\nShapelet Transformer 𝑓, i.e. 𝒛𝑖= 𝑓(𝒙𝑖), where 𝑓contains the learn-\nable shapelets of various (dis)similarity measures and lengths (a.k.a.\nscales). CSL learns 𝑓using an unsupervised contrastive learning\nalgorithm, which iteratively optimizes the proposed Multi-Grained\nContrasting and Multi-Scale Alignment objectives in an end-to-end\nmanner with stochastic gradient descent.\nUsing the Shapelet Transformer 𝑓(i.e. all the shapelets) learned\nby CSL, the TimeCSL system transforms all input time series into\nthe shapelet-based features as 𝒛𝑖= 𝑓(𝒙𝑖), and performs the down-\nstream analysis tasks on top of the representation 𝒛𝑖. It is note-\nworthy that 𝒛𝑖represents the (dis)similarity (e.g., the minimum\nEuclidean norm or the maximum cosine similarity) between the\nsubsequences of 𝒙𝑖and each of the shapelets, and therefore is fully\ninterpretable and explainable.\n2.2\nExplorable Time Series Analysis\nBy making full use of the general-purpose and explainable shapelet-\nbased features learned by CSL, this component not only offers a\nunified and flexible way to perform different time series analysis\ntasks (e.g. classification, clustering, and anomaly detection), but also\nthe intuitive visual exploration of the raw time series, the learned\nshapelets, and the shapelet-based representation, so that the users\ncan gain useful insights into their data to understand the decision\nbasis of the analysis results (e.g. the predicted classes or clusters).\nTask solving. As mentioned above, TimeCSL solves all different\ntime series analysis tasks using the shapelet-based representation\nlearned by CSL. This is achieved by building a task-oriented ana-\nlyzer (e.g., SVM for classification or K-Means for clustering) that\ntakes the shapelet-based feature vector 𝒛𝑖as input and outputs the\ncorresponding analysis results (e.g., classes or clusters). TimeCSL\nprovides two modes to build the analyzer, including the freezing\nmode and the fine-tuning mode, which differ in whether to fine-tune\nthe parameters of the Shapelet Transformer 𝑓that is pre-trained\nby the Unsupervised Contrastive Shapelet Learning component.\n• Freezing mode. In this basic mode, the task-oriented analyzer\nis built by directly using the pre-trained Shapelet Transformer 𝑓\nto extract the general-purpose shapelet-based features, while the\nparameters of 𝑓are kept unchanged during the building. Therefore,\nany standard analyzer (e.g. the many popular classifiers such as\nSVM, logistic regression, GBDT, etc) can be seamlessly integrated\nto facilitate different application scenarios of the users.\n• Fine-tuning mode. This is an advanced mode that allows users\nto fine-tune the parameters of the pre-trained Shapelet Transformer\n(a) A raw time series.\n(b) Matching between selected shapelet and time series.\n(c) Learned shapelets grouped by length\nand (dis)similarity metric.\n(d) Shapelet-based representation of a dataset\nshown in a tabular form.\n(e) Shapelet-based representation of a dataset\nvisualized using two-dimensional t-SNE [16].\nFigure 3: The TimeCSL interface.\n𝑓for specific tasks to further improve the accuracy of the analy-\nsis. In this mode, TimeCSL uses a task-specific neural network 𝑔\n(e.g., a linear classifier) as the analyzer, which is appended to the\npre-trained 𝑓to map the shapelet-based features to the analysis\nresults, i.e., 𝑦ˆ𝑖= 𝑔(𝒛𝑖) = 𝑔(𝑓(𝑥𝑖)) where 𝑦ˆ𝑖is a prediction (e.g. a\npredicted class) for the time series 𝒙𝑖. It simultaneously adjusts the\nparameters of 𝑓and𝑔by minimizing the task-oriented loss function\n(e.g. the cross-entropy loss widely used for classification) using the\nbackpropagation algorithm [10]. Afterwards, the fine-tuned 𝑓and\n𝑔are used for extracting the shapelet-based features and predicting\nthe analysis results, respectively.\nThe fine-tuning mode of TimeCSL is especially effective in the\nsemi-supervised scenarios, where only a small portion of the\ndata is annotated. Users can pre-train the Shapelet Transformer 𝑓\nthrough Unsupervised Contrastive Shapelet Learning to make full\nuse of all time series. Subsequently, they only need to fine-tune 𝑓\nand 𝑔using the available labeled data to achieve competitive perfor-\nmance. For example, our study on a real-world gesture recognition\nproblem (see §5.5 in [8]) shows that, when the proportion of labeled\ndata is less than 20%, the fine-tuned method (using the Shapelet\nTransformer 𝑓and a linear layer 𝑔) that takes advantage of the\nunsupervised pre-training of CSL, is 7% to 10% more accurate than\nthe state-of-the-art customized time series classification approach.\nVisual exploration. TimeCSL provides the visual exploration\nof the following two types of data for gaining insight into the time\nseries and understanding the analysis results.\n• Time series and shapelets. Since the shapelets represent the\nsalient approximate subsequences of the raw time series which\nare of the same number of variates, TimeCSL shows both the raw\ntime series and the learned shapelets in the line chart, where each\nline indicates the values of one variate.\n• Shapelet-based features. By definition, a shapelet-based fea-\nture represents the (dis)similarity (e.g., Euclidean norm) between a\nshapelet and the most similar subsequence of a time series. There-\nfore, given a time series and a shapelet, TimeCSL visualizes them,\nmatches the shapelet with its most similar subsequence, and dis-\nplays the feature value measured by the corresponding (dis)similarity\nmetric. In addition to this instance-level exploration, TimeCSL can\nalso show the shapelet-based representation of a dataset in a tabu-\nlar form, allowing flexible sorting of the time series according to\neach of the shapelets (equivalent to the features), and visualize the\nhigh-dimensional time series representation in a two-dimensional\ngraph using t-SNE [16].\nThe user can interact with TimeCSL to iteratively use the features\nextracted with different subsets of the shapelets in the explorable\ntime series analysis. Given the interpretability of the shapelet-based\nrepresentation, it is feasible to gain an understanding of the factors\nthat influence the analysis results.\n3\nDEMONSTRATION\nThe demonstration1 illustrates two key capabilities of the TimeCSL\nsystem. Firstly, it showcases how the user performs different time\nseries analysis tasks using the unified pipeline. Secondly, it demon-\nstrates how users gain insight into their time series by exploring\nthe interpretable shapelet-based representation, which helps to\nunderstand the underlying decision basis of the analysis results.\nWe prepare the UEA archive [1] for the audience to interact with\nour system, which contains 30 time series datasets from various\napplications. Users can also analyze and explore their own data.\nGenerally, a user takes the following four steps to achieve ex-\nplorable time series analysis using the TimeCSL system.\n1https://youtu.be/hjdKy4Zr2Zw\nStep 1: Configuring the Shapelet Transformer. A user can\nflexibly configure the Shapelet Transformer to decide the number,\nlength, and (dis)similarity metric of the shapelets to be learned,\nor directly start with our recommended configuration that uses\nEuclidean norm, cosine similarity, and cross-correlation function\nto measure the (dis)similarity, and adaptively sets the number and\nlengths of the shapelets based on the time series (see §4.2 in [8]).\nStep 2: Unsupervised Contrastive Learning of the General\nShapelets. After configuration, a user clicks on the “Run CSL” but-\nton to begin the unsupervised contrastive learning. Then, TimeCSL\nautomatically learns the general and interpretable shapelets by\nrunning the CSL algorithm. A user can diagnose the model perfor-\nmance through the learning curve plotted in our GUI that records\nthe training or validation loss over time.\nStep 3: Performing the Analysis Tasks. TimeCSL transforms\nthe time series of different lengths and numbers of variates into a\nunified vector representation using the learned shapelets. There-\nfore, a user can easily perform an analysis task by specifying a\nmode and a task-oriented analyzer. TimeCSL has integrated several\ncommonly used analyzers. In the freezing mode, to name only a few,\nit integrates SVM, K-Means, and Isolation Forest using scikit-learn2,\nfor classification, clustering, and anomaly detection, respectively. It\nalso implements a linear classifier using PyTorch3 to deal with the\n(semi-supervised) classification problem in the fine-tuning mode.\nUsing the GUI, a user can select one of the tasks, modes, and ana-\nlyzers, and then click “Run Analyzer” to get the analysis results.\nStep 4: Exploring the Data. Figure 3 shows part of the GUI\nfor analyzing the time series of the prepared UWaveGestureLi-\nbrary dataset with the default configuration of the system. A user\ncan explore the time series (Figure 3a) and the learned shapelets\n(Figure 3c). To see the feature of a time series extracted using a\nspecific shapelet, a user only needs to select them and click on\nthe “Match” button. TimeCSL will visually match the shapelet with\nthe most similar subsequence of the time series to illustrate this\nshapelet-based feature (Figure 3b). TimeCSL also provides two types\nof exploration of the high-dimensional shapelet-based representa-\ntion of the dataset. A user can select a set of interested shapelets,\nand click “Show in Tabular” to see the features extracted using these\nshapelets in a table and sort the time series according to each of\nthe shapelets or features (Figure 3d). The user can also click “Show\nin t-SNE” to investigate these features in a two-dimensional t-SNE\nrepresentation, where the points are clickable so that the user can\nsee details about the corresponding time series (Figure 3e).\nA user can redo the analysis task (i.e., Step 3) using the selected\nshapelets of interest to explore their influence on the analysis results.\nFor example, if a user runs an SVM analyzer on UWaveGestureLi-\nbrary by selecting the shapelets of length 31 learned as above, s/he\ncan get a classification accuracy of 0.75. If the user restarts Step 3\nusing the learned shapelets of larger lengths, the resulting accuracy\nscores are, to name a few, 0.85 for length 97 and 0.89 for length 188,\nwhich is even comparable to the accuracy of 0.91 that is achieved by\nusing all the learned shapelets. The user can infer from the results\nthat, in this scenario, the categories of the time series can be better\ndistinguished by focusing on longer salient subsequences.\n2https://scikit-learn.org/stable/\n3https://pytorch.org/\nACKNOWLEDGMENTS\nWe thank the anonymous reviewers for their time and the valuable\ncomments. This paper was supported by the NSFC grant (62232005,\n62202126), the National Key Research and Development Program of\nChina (2021YFB3300502), and the Postdoctoral Fellowship Program\nof CPSF (GZC20233457).\nREFERENCES\n[1] Anthony J. Bagnall, Hoang Anh Dau, Jason Lines, Michael Flynn, James Large,\nAaron Bostrom, Paul Southam, and Eamonn J. Keogh. 2018. The UEA multivariate\ntime series classification archive, 2018. CoRR abs/1811.00075 (2018).\n[2] Stefanos Bennett, Mihai Cucuringu, and Gesine Reinert. 2022. Detection and\nclustering of lead-lag networks for multivariate time series with an application\nto financial markets. (2022).\n[3] Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong\nKwoh, Xiaoli Li, and Cuntai Guan. 2021. Time-Series Representation Learning\nvia Temporal and Contextual Contrasting. In IJCAI. 2352–2359.\n[4] Jean-Yves Franceschi, Aymeric Dieuleveut, and Martin Jaggi. 2019. Unsupervised\nscalable representation learning for multivariate time series. Advances in neural\ninformation processing systems 32 (2019).\n[5] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual\nlearning for image recognition. In CVPR. 770–778.\n[6] Eunji Kim, Sungzoon Cho, Byeongeon Lee, and Myoungsu Cho. 2019. Fault\ndetection and diagnosis using self-attentive convolutional neural networks for\nvariable-length sensor data in semiconductor manufacturing. IEEE Transactions\non Semiconductor Manufacturing 32, 3 (2019), 302–309.\n[7] Zhiyu Liang and Hongzhi Wang. 2021. Efficient class-specific shapelets learning\nfor interpretable time series classification. Information Sciences 570 (2021), 428–\n450.\n[8] Zhiyu Liang, Jianfeng Zhang, Chen Liang, Hongzhi Wang, Zheng Liang, and\nLujia Pan. 2023. A Shapelet-based Framework for Unsupervised Multivariate\nTime Series Representation Learning. PVLDB 17, 3 (2023), 386–399.\n[9] Ann Riley and Elvira Nica. 2021. Internet of things-based smart healthcare\nsystems and wireless biomedical sensing devices in monitoring, detection, and\nprevention of COVID-19. American Journal of Medical Research 8, 2 (2021), 51–64.\n[10] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1986. Learning\nrepresentations by back-propagating errors. nature 323, 6088 (1986), 533–536.\n[11] Saeid Sanei and Jonathon A Chambers. 2013. EEG signal processing. John Wiley\n& Sons.\n[12] Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Michael Blumenstein, and Jing\nJiang. 2022. Omni-Scale CNNs: a simple and effective kernel size configuration\nfor time series classification. In ICLR. OpenReview.net.\n[13] Sana Tonekaboni, Danny Eytan, and Anna Goldenberg. 2021. Unsupervised\nRepresentation Learning for Time Series with Temporal Neighborhood Coding.\nIn ICLR. OpenReview.net.\n[14] Liudmila Ulanova, Nurjahan Begum, and Eamonn J. Keogh. 2015. Scalable Clus-\ntering of Time Series with U-Shapelets. In ICDM, Suresh Venkatasubramanian\nand Jieping Ye (Eds.). SIAM, 900–908.\n[15] Aäron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol\nVinyals, Alex Graves, Nal Kalchbrenner, Andrew W. Senior, and Koray\nKavukcuoglu. 2016.\nWaveNet: A Generative Model for Raw Audio.\nCoRR\nabs/1609.03499 (2016).\n[16] Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing Data using\nt-SNE. Journal of Machine Learning Research 9, 86 (2008), 2579–2605.\n[17] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All\nyou Need. In Advances in Neural Information Processing Systems. 5998–6008.\n[18] Akihiro Yamaguchi, Ken Ueo, and Hisashi Kashima. 2022. Learning Evolvable\nTime-series Shapelets. In ICDE. IEEE, 793–805.\n[19] Ling Yang and Shenda Hong. 2022. Unsupervised time-series representation\nlearning with iterative bilinear temporal-spectral fusion. In ICML. 25038–25054.\n[20] Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang,\nYunhai Tong, and Bixiong Xu. 2022. Ts2vec: Towards universal representation\nof time series. In AAAI, Vol. 36. 8980–8987.\n[21] George Zerveas, Srideepika Jayaraman, Dhaval Patel, Anuradha Bhamidipaty,\nand Carsten Eickhoff. 2021. A transformer-based framework for multivariate\ntime series representation learning. In SIGKDD. 2114–2124.\n[22] Qin Zhang, Jia Wu, Peng Zhang, Guodong Long, and Chengqi Zhang. 2019.\nSalient Subsequence Learning for Time Series Clustering. IEEE Trans. Pattern\nAnal. Mach. Intell. 41, 9 (2019), 2193–2207.\n[23] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin.\n2022. FEDformer: Frequency Enhanced Decomposed Transformer for Long-term\nSeries Forecasting. In ICML, Vol. 162. 27268–27286.\n",
  "categories": [
    "cs.LG",
    "cs.DB"
  ],
  "published": "2024-04-07",
  "updated": "2024-04-07"
}