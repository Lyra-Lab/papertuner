{
  "id": "http://arxiv.org/abs/2405.01799v2",
  "title": "Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features",
  "authors": [
    "Chuanbo Hu",
    "Wenqi Li",
    "Mindi Ruan",
    "Xiangxu Yu",
    "Shalaka Deshpande",
    "Lynn K. Paul",
    "Shuo Wang",
    "Xin Li"
  ],
  "abstract": "Diagnosing language disorders associated with autism is a complex challenge,\noften hampered by the subjective nature and variability of traditional\nassessment methods. Traditional diagnostic methods not only require intensive\nhuman effort but also often result in delayed interventions due to their lack\nof speed and precision. In this study, we explored the application of ChatGPT,\na large language model, to overcome these obstacles by enhancing sensitivity\nand profiling linguistic features for autism diagnosis. This research utilizes\nChatGPT natural language processing capabilities to simplify and improve the\ndiagnostic process, focusing on identifying autism related language patterns.\nSpecifically, we compared ChatGPT performance with that of conventional\nsupervised learning models, including BERT, a model acclaimed for its\neffectiveness in various natural language processing tasks. We showed that\nChatGPT substantially outperformed these models, achieving over 10% improvement\nin both sensitivity and positive predictive value, in a zero shot learning\nconfiguration. The findings underscore the model potential as a diagnostic\ntool, combining accuracy and applicability. We identified ten key features of\nautism associated language disorders across scenarios. Features such as\necholalia, pronoun reversal, and atypical language usage play a critical role\nin diagnosing ASD and informing tailored treatment plans. Together, our\nfindings advocate for adopting sophisticated AI tools like ChatGPT in clinical\nsettings to assess and diagnose developmental disorders. Our approach promises\nenhanced diagnostic precision and supports personalized medicine, potentially\ntransforming the evaluation landscape for autism and similar neurological\nconditions.",
  "text": "Exploiting ChatGPT for Diagnosing Autism-Associated\nLanguage Disorders and Identifying Distinct Features\nChuanbo Hu1, Wenqi Li1,2, Mindi Ruan2, Xiangxu Yu3, Shalaka Deshpande4,\nLynn K. Paul5, Shuo Wang3, Xin Li1\n1*Department of Computer Science, University at Albany, Albany, 12222, NY, USA.\n2Lane Department of Computer Science and Electrical Engineering, West Virginia University,\nMorgantown, 26506, WV, USA.\n3Department of Radiology, Washington University in St. Louis, St. Louis, 63110, MO, USA.\n4Camas High School, Camas, 98607, WA, USA.\n5Humanities and Social Sciences, California Institute of Technology, Pasadena, 91125, CA,\nUSA.\nContributing authors: chu3@albany.edu; wl00021@mix.wvu.edu; mr0114@mix.wvu.edu;\nxiangxu@wustl.edu; mr0114@mix.wvu.edu; lkpaul@hss.caltech.edu; lkpaul@hss.caltech.edu;\nxli48@albany.edu;\nAbstract\nDiagnosing language disorders associated with autism is a complex challenge, often hampered by the\nsubjective nature and variability of traditional assessment methods. Traditional diagnostic methods not\nonly require intensive human effort but also often result in delayed interventions due to their lack of\nspeed and precision. In this study, we explored the application of ChatGPT, a state-of-the-art large\nlanguage model, to overcome these obstacles by enhancing sensitivity and profiling linguistic features for\nautism diagnosis. This research utilizes ChatGPT’s natural language processing capabilities to simplify\nand improve the diagnostic process, focusing on identifying autism-related language patterns. Specifically,\nwe compared ChatGPT’s performance with that of conventional supervised learning models, including\nBERT, a model acclaimed for its effectiveness in various natural language processing tasks. We showed that\nChatGPT substantially outperformed these models, achieving over 10% improvement in both sensitivity\nand positive predictive value, in a zero-shot learning configuration. The findings underscore the model’s\npotential as a diagnostic tool, combining accuracy and applicability. We identified ten key features of\nautism-associated language disorders across scenarios. Features such as echolalia, pronoun reversal, and\natypical language usage play a critical role in diagnosing ASD and informing tailored treatment plans.\nTogether, our findings advocate for adopting sophisticated AI tools like ChatGPT in clinical settings to\nassess and diagnose developmental disorders. Our approach promises enhanced diagnostic precision and\nsupports personalized medicine, potentially transforming the evaluation landscape for autism and similar\nneurological conditions.\nKeywords: Autism spectrum disorder, Language deficits, Machine learning, Large language models, ChatGPT\n1 Introduction\nAutism spectrum disorder (ASD) is a developmental condition marked by difficulties in social interaction,\nrestricted interests, and repetitive behaviors. [1–3]. The spectrum of ASD symptoms is broad, with commu-\nnication difficulties often standing out as the most significant and impacting aspects of the disorder [4–6].\nThese symptoms vary across age groups. In adults, communication difficulties are especially pronounced, sig-\nnificantly affecting social integration and personal development [7, 8]. Identifying these communication issues\nis crucial for effective intervention.\nLanguage disorders in adults with ASD include a wide range of issues, from the absence of speech to\nsubtle impairments such as echolalia (repetitive use of phrases or sounds), pronoun reversal, and pragmatic\n1\narXiv:2405.01799v2  [cs.CL]  29 Nov 2024\nlanguage impairments [9–11]. These disorders can hinder effective communication and pose significant chal-\nlenges in social and occupational settings. Accurate identification of language anomalies is essential for timely\ninterventions.\nWhile the Autism Diagnostic Observation Schedule, Second Edition (ADOS-2) [12] is a gold standard for\nASD diagnosis across various age groups. The ADOS-2 involves structured, standardized observation sessions,\ntypically lasting around one hour, during which an examiner engages the patient in a series of conversational\nand interactive tasks. These sessions are designed to assess key areas of communication, social interaction, and\nbehavior. For adults, the examiner analyzes the patient’s responses, verbal and non-verbal communication\npatterns, and social cues to identify markers of ASD. The diagnostic process relies on the examiner’s ability\nto interpret subtle interaction dynamics and communication behaviors, making the method highly reliant on\nclinical expertise. As a result, the approach can be both subjective and resource-intensive, posing challenges\nfor scalability and consistency in assessments.\nTo address these challenges, researchers have turned to machine learning (ML) as a complementary or\nalternative diagnostic tool. ML models leverage multimodal data encompassing speech, text, video, and image\nto detect ASD-related markers with greater automation and precision [13–18]. For example: A contrastive\nlearning framework for decision tree-based action classification leverages adjacency matrices and skeleton\ngraphs to model periodicity and symmetry, enabling robust recognition of human interactions with potential\nin video-based ASD diagnosis [16]. A few-shot learning framework leveraging facial dynamics and scene-level\nfusion analyzes hour-long ADOS videos, classifying individuals into Autism, Autism Spectrum, and Non-\nSpectrum with 91.72% accuracy while highlighting the value of specific interview scenes [18]. While ML\napproaches have shown promise, they face significant challenges: 1) High Data Requirements: Training\neffective ML models requires large, labeled datasets. However, collecting such data is expensive, as it involves\nlong, structured interactions between examiners and patients [19]. 2) Lack of Explainability: Many ML\nmodels operate as “black boxes,” offering little insight into how predictions are made. This reduces their\ntrustworthiness in clinical applications.\nLarge language models (LLMs), such as GPT [20], represent a paradigm shift in ASD diagnosis. Unlike\ntraditional ML models, LLMs are pre-trained on massive corpora of diverse text data, enabling them to gen-\neralize across tasks with minimal task-specific training. Their applications in healthcare, including mental\nhealth diagnostics and personalized medicine, are gaining attention [21, 22]. LLMs offer several advantages\nover traditional ML approaches: 1) Zero-Shot and Few-Shot Learning Capabilities: LLMs excel in low-\ndata scenarios, leveraging pre-trained knowledge to identify patterns and make predictions without requiring\nextensive labeled datasets [23]. This is particularly valuable for ASD diagnosis, where data collection is costly\nand labor-intensive; 2) Rich Linguistic and Contextual Knowledge: LLMs can capture nuanced language\npatterns, such as echolalia and atypical prosody, directly from text data. Unlike conventional NLP models,\nthey require minimal feature engineering and can adapt to complex linguistic contexts [24]; 3) Explainabil-\nity: LLMs can generate detailed, human-like explanations for their predictions, enhancing transparency and\ntrust in clinical settings [25].\nThis study leverages ChatGPT, a state-of-the-art LLM, to enhance the sensitivity and efficiency of ASD\ndiagnosis through its ability to process nuanced linguistic patterns. By analyzing features such as echolalia,\npronoun reversals, and atypical prosody, ChatGPT provides critical insights into key indicators of ASD.\nIts zero-shot and few-shot learning capabilities effectively address the challenges of limited ASD-specific\ndatasets, reducing reliance on costly and labor-intensive data collection. Furthermore, ChatGPT’s natural\nlanguage understanding enables it to analyze examiner-patient dialogues in a conversational context, captur-\ning subtle language behaviors essential for diagnosis. The model’s human-like explanations further support\nclinicians, fostering trust and transparency in diagnostic outcomes. By integrating domain-specific knowledge\nand multimodal data such as gaze patterns and non-verbal behaviors, ChatGPT could pave the way for a\ncomprehensive AI-driven framework for ASD language assessment. Despite their potential, applying LLMs\nin ASD diagnosis remains an emerging field with following motivations:\n• Advancing Diagnostic Sensitivity and Efficiency.\nDiagnosing autism-related language disorders is challenging due to subtle and variable symptoms. This\nstudy leverages ChatGPT to achieve substantial improvements in sensitivity (recall), ensuring better\ndetection of language deficits while streamlining the diagnostic process for timely interventions.\n• Identification of Specific Linguistic Features.\nCurrent methods for identifying language disorders in autistic individuals often rely on broad assessments\nthat miss specific features. ChatGPT’s advanced pattern recognition refines this process by identifying key\nlinguistic markers like echolalia, pronoun reversal, and atypical language use. These insights are crucial for\ndeveloping personalized treatment plans.\n• Enabling Personalized Therapeutic Strategies.\n2\nScenario\nName\nExplanation\nS1\nConstruction Task\nInvolves the participant engaging in a task that requires\nconstructing or assembling a set structure, testing spatial\nand motor skills rather than communicative abilities.\nS2\nTelling a Story from\na Book\nPrimarily a monologic task where the participant recounts\na story from a book, differing from spontaneous dialogic\ninteractions.\nS3\nDescription of a Pic-\nture\nParticipants describe a picture, testing their ability to inter-\npret visual information and articulate a coherent descrip-\ntion.\nS4\nConversation\nand\nReporting\nFocuses on the ability to engage in back-and-forth conver-\nsation and to report on past events.\nS5\nCurrent\nWork\nand\nSchool\nDiscusses participants’ current educational and occupa-\ntional engagements.\nS6\nSocial\nDifficulties\nand Annoyance\nElicits experiences of social challenges and annoyances.\nS7\nEmotions\nRequires participants to express and identify emotions.\nS8\nDemonstration Task\nRequires the participant to demonstrate how to use an item\nor explain a process, which does not involve interactive com-\nmunication with an examiner.\nS9\nCartoons\nInvolves interpreting sequences and explaining cartoon\nstrips.\nS10\nBreak\nA pause or intermission in the assessment, involving no com-\nmunicative or cognitive tasks.\nS11\nDaily Living\nCovers daily routines and personal care tasks.\nS12\nFriends,\nRelation-\nships, and Marriage\nDiscusses personal relationships and social norms regarding\nfriendships and marital status.\nS13\nLoneliness\nAddresses feelings and situations of loneliness and isolation.\nS14\nPlans and Hopes\nInvolves discussing future aspirations and plans.\nS15\nCreating a Story\nTests creative storytelling abilities in an unstructured task.\nTable 1 Overview of Scenario Tasks in ADOS-2 Module 4 Diagnosing process\nBy combining high sensitivity and precision, ChatGPT facilitates targeted therapeutic approaches for ASD,\naddressing individual patient needs. This framework also opens avenues for extending AI-driven diagnostic\ntools to other cognitive and developmental disorders.\nBuilding on the limitations of traditional diagnostic tools, this study leverages ChatGPT’s language\nprocessing capabilities to address these challenges. By comparing its performance with existing supervised\nlearning models, we aim to highlight the potential of LLMs in accurately identifying language deficits associ-\nated with ASD. This research integrates advanced AI technologies with domain-specific knowledge to enhance\ndiagnostic efficiency while identifying distinct linguistic features indicative of ASD. The following sections\noutline the datasets, experimental setup, and model comparisons to substantiate these claims.\n2 Results\n2.1 Experimental Dataset\n2.1.1 ADOS-2\nThe ADOS-2 [26, 27] is an update and extension of the original ADOS, which is a standardized diagnostic tool\nfor ASD. The ADOS assesses communication, social interaction, play, and restricted and repetitive behaviors.\nIt provides a series of structured and semi-structured tasks that involve social interactions between the\nexaminer and the person being assessed. Module 4 of the ADOS-2 is designed for verbally fluent adolescents\nand adults (see Table 1 for description of tasks). In addition, Module 4 of the ADOS-2 organizes observations\ninto five main areas, assessing various aspects of interaction and communication critical for diagnosing ASD\nin verbally fluent adolescents and adults. Table 2 provides a summary of these categories, including the\nspecific items they encompass and their respective descriptions: each participating in 15 different scenarios\n(see Table 1) designed to elicit communicative and social responses that are indicators of ASD. The scenarios\nwere structured to cover a comprehensive range of social interactions and communicative behaviors.\nIn language-based diagnostics, the A4 score — part of the Stereotyped Behaviors and Restricted Interests\ncategory — becomes particularly relevant. A4 score can be evaluated using the mechanism described in Table\n3:\n3\nTable 2 Detailed Assessment Categories for the ADOS-2 Module 4 Observations\nClass\nName\nItems\nDescription\nA\nLanguage\nand\nCommunica-\ntion\nA1\n∼\nA10\nAssesses the ability to use speech and gestures in commu-\nnication effectively, evaluating the clarity, coherence, and\nappropriateness of language used in social interactions.\nB\nReciprocal\nSocial Interac-\ntion\nB1\n∼\nB13\nFocuses on non-verbal and verbal behaviors used in social\ninteractions, including eye contact, facial expressions,\nbody postures, and the quality of speech interactions.\nC\nImagination\n/\nCreativity\nC1\nEvaluates the subject’s ability to use imagination and\ncreativity in their expressions and thoughts, such as sto-\nrytelling or creating novel responses to social scenarios.\nD\nStereotyped\nBehaviors\nand\nRestricted\nInterests\nD1\n∼\nD5\nIncludes specific behaviors that are repetitive, restricted,\nand stereotyped. This category assesses the frequency and\nintensity of these behaviors as indicators of ASD.\nE\nOther\nAbnor-\nmal Behaviors\nE1\n∼\nE3\nObserves behaviors that are typically considered abnor-\nmal, such as overactivity, anxiety, and emotional responses\nthat are inconsistent with the normative context.\nTable 3 A4 Score: Stereotyped/Idiosyncratic Use of Words or Phrases\nScore\nDescription\n0\nRarely or never uses stereotyped or idiosyncratic words or phrases. The subject demonstrates\ntypical language use without noticeable patterns of repetition or unusual phrasing.\n1\nUses words or phrases that are more repetitive or formal compared to most individuals at a\nsimilar level of expressive language, though not obviously odd. This category also includes\noccasional stereotyped utterances or odd use of words or phrases, while still showing sub-\nstantial spontaneous and flexible language use.\n2\nOften uses stereotyped utterances or odd words or phrases, with some other spontaneous\nlanguage. The subject displays a noticeable pattern of repetitive or unusual phrasing that\nstands out in conversation.\n3\nFrequently uses odd or stereotyped speech and rarely exhibits non-stereotyped spontaneous\nspeech. The language is predominantly characterized by repetitive, formal, or idiosyncratic\nexpressions, with very little flexibility or spontaneity.\nThe A4 score assesses the use of stereotyped language, which is a critical indicator of ASD. A higher A4\nscore suggests a more frequent use of stereotyped or idiosyncratic speech, aiding in the diagnosis of ASD with\nhigher specificity and sensitivity.\n2.1.2 Autism-Associated Language Disorders features\nBased on the domain knowledge of professional ADOS-2 examiners, ten specific features of language deficits\nrelated to ASD have been identified. These features reflect various unconventional use patterns of language\nthat can signify underlying social communication issues. Table 4 is a detailed description of these features:\n2.1.3 ADOS-2 Interview Audios\nFor the purpose of this study, we utilized the Caltech ADOS Audio Dataset [18], which comprises audio\nrecordings from diagnostic interviews conducted under the ADOS-2, Module 4. This dataset 1 involved 33\nparticipants, aged 16 to 37 years (mean age:24.32), with a composition of 26 males and 7 females, predomi-\nnantly right-handed (n=31). A subset of 9 participants underwent two ADOS interviews approximately six\nmonths apart, resulting in a total of 42 audio recordings spanning 3,165 minutes. Among these, 14 audio\nrecordings have an A4 score of 0, 23 have an A4 score of 1, 5 have an A4 score of 2, and none have an\nA4 score of 3. Each recording was segmented into 15 sub-videos based on scene timestamps, producing 292\nsub-videos with an average duration of 334 seconds. All were diagnosed with ASD based on the ADOS-2,\nconfirmed through expert clinical evaluation. In addition, Each audio participated in 15 different scenarios\nthat are designed to elicit social and communicative behaviors characteristic of individuals on the autism\nspectrum. Our research focused exclusively on scenarios involving direct dialogue between the examiner and\nthe patient, as this interaction is critical for analyzing language disorders in autism. Therefore, we excluded\nscenarios like the S1 Construction Task and S8 Demonstration Task, which involve non-verbal or explana-\ntory tasks, lacking the necessary dialogue. The S2 Tell a Story scenario was also excluded because it involves\nmonologic speech without interactive exchange. Additionally, the S10 Break scenario does not include any\nrelevant communicative or cognitive tasks. These exclusions ensured that our analysis remained focused on\ninteractions that are directly relevant to diagnosing language-related symptoms in ASD. Out of these sce-\nnarios, we specifically selected 11 that focus on social language interactions between the examiner and the\n1Caltech Dataset\n4\nF\nName\nExplanation\nF1\nEchoic\nRepetition\nThe individual mimics verbatim what has been said by others,\nincluding the examiner, or recites phrases from external sources like\nadvertisements or movie scripts, showing a delayed echo response.\nF2\nUnconventional\nContent\nThe speech contains peculiarly chosen content or contextually odd\nphrasing, such as using ’unfreshness through household’ for lack of\nnovelty, ’mideast’ instead of ’midwest’ for U.S. states, or describing\nentry into a building as ’through various apertures’.\nF3\nPronoun\nDisplacement\nIncorrectly substitutes personal pronouns, using ’you’ in place of ’I’,\nor refers to themselves in the third person, either by pronouns like\n’he/she’ or by their own name.\nF4\nIncongruous\nHumor Timing\nIncorporates humorous or comedic expressions inappropriately during\ndiscussions meant to be serious, showing a misalignment between the\ncontent’s emotional tone and the context.\nF5\nFormalistic\nLanguage Use\nEmploys an overly formal or archaic language style that seems lifted\nfrom written texts, legal documents, or old literature, rather than\nengaging in conversational speech. Examples include elaborate ways\nof expressing simple ideas or feelings.\nF6\nSuperfluous\nPhrase Attachment\nAttaches redundant phrases or filler expressions to their speech with-\nout contributing any substantive meaning or context, such as ’you\nknow what I mean’ or ’as they say,’ indicating a habit rather than\nintentional emphasis.\nF7\nExcessive Social\nPhrasing\nUtilizes conventional social expressions excessively or inappropriately,\nresponding with phrases like ’oh, thank you’ in contexts where it does\nnot fit or preempting social gestures not yet performed by the inter-\nlocutor.\nF8\nMonotone Social\nExpression\nReiterates social phrases with an unchanged, monotonous intonation,\nindicating a lack of genuine emotional engagement or variability in\nsocial interactions.\nF9\nStereotyped Media\nQuoting\nQuotes lines from commercials, movies, or TV shows in a highly\nstereotypical manner, employing a canned intonation that mimics the\noriginal source closely, suggesting a reliance on external media for ver-\nbal expressions.\nF10\nClich´ed Verbal\nSubstitutions\nResorts to well-known sayings or clich´es in lieu of engaging in direct\nconversational responses, using phrases like ’circle of life’ or ’ready to\nroll’ as stand-ins for more personalized communication.\nTable 4 Descriptive Analysis of Unconventional Language Disorder Patterns\npatient. These selected scenarios provide a concentrated dataset to analyze social communicative exchanges,\ncrucial for identifying language-related symptoms of ASD.\nAmong the selected scenarios, particular emphasis was placed on analyzing the linguistic feature of\n”Stereotyped/Idiosyncratic Use of Words or Phrases,” which is central to understanding language disorders\nthat may or may not be present in individuals with autism. A4 score details are presented in Table 3. In our\ndataset, 13 subjects had a score of 0, indicating minimal or no use of stereotyped language, while twenty-\nseven had a score of 1, showing mild repetitive or formal use, and four had a score of 2, indicating frequent\nuse of stereotyped or odd phrases. To simplify our binary classification task, we combined subjects with\nscores 1 and 2 into a single category (Category 1) and grouped those with a score of 0 into Category 0. This\napproach was necessary due to the limited number of subjects with more severe symptoms, as our sample\nprimarily consists of adults with less pronounced symptoms. We also recognize the suggestion to include a\nmore diverse set of dialogues, such as those from non-autistic populations, in future analyses to broaden the\nperspective on language use and disorders.\n2.2 Experimental Setup\nSpeaker Diarization Baseline Models. To provide a comprehensive comparison with our Google-based\nspeaker diarization approach, we evaluated two baseline models: Microsoft Azure Speaker Diarization and\nPyannote speaker-diarization-3.1. The Microsoft Azure system was configured with SpeakerDiarizationWith-\nTranscription mode, a maximum of 2 speakers, and output in detailed mode, providing timestamps, speaker\nattribution, and confidence scores. The input audio files were preprocessed to single-channel WAV format\nwith a sampling rate of 16 kHz. In contrast, Pyannote’s speaker-diarization-3.1 pipeline, leveraging pre-\ntrained pyannote/segmentation-3.0 and clustering algorithms, was configured with a minimum of 2 speakers\nand a maximum of 5 speakers, along with tuned overlap handling and segmentation thresholds. Both baseline\n5\nTable 5 Performance Metrics of Different Models\nModel\nAccuracy\nPPV\nSensitivity\nF1 Score\nXLNet [28]\n58.76%\n54.38%\n58.76%\n56.07%\nALBERT [29]\n69.07%\n47.71%\n69.07%\n56.44%\nDistilBERT [30]\n58.76%\n51.85%\n58.76%\n54.44%\nRoBERTa [31]\n57.73%\n58.12%\n57.73%\n57.92%\nBERT [32]\n63.92%\n60.86%\n63.92%\n61.87%\nGPT 4o - based (Ours)\n67.05%\n70.76%\n90.51%\n79.43%\nGPT 3.5 - based (Ours)\n69.14%\n71.52%\n93.22%\n80.94%\nmodels served to benchmark the diarization accuracy and robustness of our Google-based implementation,\nhighlighting differences in handling overlapping speech and speaker variability.\nText Classification Baseline Models. The models we compared include XLNet, ALBERT, Distil-\nBERT, RoBERTa, and BERT, all of which have a token limit of 512. Each scenario from a subject in our\ndataset spans 8-10 minutes of dialogue. In most cases, the token count stays within this range, with only a\nfew samples exceeding the 512-token limit. To ensure a consistent and fair comparison, we standardized each\nsample by keeping only the first 512 tokens for those that exceeded the limit, while samples with fewer than\n512 tokens were left unchanged. We evaluated these baseline models using 5-fold cross-validation to ensure\nrobust performance assessment. This involved splitting the dataset into five subsets, with each subset serving\nas the validation set once while the others were used for training. The final performance metrics were averaged\nacross all five folds to account for variations due to data splits and provide a comprehensive evaluation.\nEvaluation Metrics. The effectiveness of the ChatGPT model was evaluated using several metrics:\nAccuracy: The proportion of total diagnoses that were correctly identified by the model. Positive Predictive\nValue (PPV): The ratio of correct positive observations to the total predicted positives. sensitivity: The ratio\nof correct positive observations to the actual positives in the data. F1 Score: The harmonic mean of PPV\nand sensitivity, providing a single metric to assess the balance between PPV and sensitivity.\nHardware. All baseline models were trained on a workstation equipped with two NVIDIA 3090 Ti GPUs,\nproviding a total of 48 GB of VRAM. This setup ensured sufficient computational resources for processing\ndatasets and fine-tuning the models efficiently. The hardware allowed for accelerated training times and\nfacilitated the handling of memory-intensive tasks such as tokenization and batch processing, which were\ncritical for achieving consistent results across all models.\n2.3 Comparison of Language Deficit Diagnosis\n2.3.1 Evaluation of LLM Performance\nDue to data limitations, cases with an A4 score of 3, representing extremely severe conditions, are not included\nin the dataset, and cases with an A4 score of 2 are extremely rare (42 audio recordings, 14 A4 = 0, 23 A4 =\n1, 5 A4 = 2, and 0 A4 = 3.). Therefore, we categorized A4 > 0 as Label = 1 and A4 = 0 as Label = 0 to\nexplore whether large models can assist in diagnosing patients and identifying the presence of social language\ndisorders. To compare the performance of different GPT versions, our backbone models were evaluated based\non the API versions GPT-3.5-turbo and GPT-4. Table 5 summarizes the results of this comparison.\nTable 5 demonstrates that the ChatGPT-based models achieved the best performance across all metrics,\nsignificantly outperforming the baseline models such as BERT, RoBERTa, and XLNet. The ChatGPT-based\nmodel obtained the highest sensitivity, PPV, and F1-score, showcasing its superior capability to detect true\npositives and balance precision and recall. Notably, the performance of the two ChatGPT versions was\nremarkably similar, indicating the consistency and robustness of the ChatGPT-based approach for diagnosing\nsocial language disorders (SLDs). In contrast, the baseline models lagged behind in all metrics, highlighting\nthe advantage of using advanced LLMs for this task.\n2.3.2 Evaluation of Speaker Diarization\nTo further examine the impact of utilizing speaker diarization, we conducted ablation experiments that varied\nthe use of speaker diarization tools integrated with our ChatGPT-based approach:\nTable 6 Ablation Experiments: Performance Metrics of Different Schemes\nModel\nAccuracy\nPPV\nSensitivity\nF1 Score\nwo/ Speaker Diarization\n63.64%\n48.12%\n63.64%\n54.80%\nw/ Pyannote\n68.18%\n59.68%\n68.18%\n60.45%\nw/ Microsoft\n72.73%\n71.25%\n72.73%\n66.10%\nw/ Human Diarization\n82.00%\n91.06%\n82.49%\n86.57%\nw/ Google(Ours)\n69.14%\n71.52%\n93.22%\n80.94%\n6\nFig. 1 Correlation Coefficients Between Features of Language Deficit\nIntegrating Google’s speaker diarization (SD) technology with our ChatGPT-based model significantly\nimproved all performance metrics, achieving the highest scores overall. Unlike other diarization tools, Google\nSD not only distinguishes multiple speakers (e.g., Speaker 1, Speaker 2) but crucially identifies whether\nthe speaker is the examiner or the patient. This capability is especially valuable for tasks requiring an\nunderstanding of interaction dynamics and speaker roles (examiner vs. patient), which significantly influence\nthe model’s performance in contextual analysis and response generation.\nTogether, these results validate the potential of incorporating sophisticated AI-driven tools like speaker\ndiarization with ChatGPT to enhance the accuracy and efficiency of diagnostics.\n2.4 Analysis of Features of Language Deficit\n2.4.1 Correlation Analysis\nTo thoroughly understand the interrelationships between different language features identified in the ASD\ndiagnostic assessments, We analyzed the interrelationships among ten language features (F1 to F10) derived\nfrom the Caltech dataset. These features represent various aspects of language use that may indicate ASD,\nsuch as repetitive use of words or unusual language patterns. We calculated Pearson correlation coefficients\nbetween each pair of features to quantify their linear relationships. Each language feature is represented as a\nbinary variable, where ’1’ indicates the presence and ’0’ indicates the absence of that specific language disorder\nfeature within any given sample. For example, if a feature detected by ChatGPT such as ”echolalic repetition”\nis observed in the dialogue during a diagnostic session, it is marked as ’1’ for that session; otherwise, it is\nmarked as ’0’. This binary coding allows us to apply Pearson correlation to measure the linear relationship\nbetween each pair of features across all samples. This analysis pinpoints which features often co-occur within\nthe linguistic profiles of ASD diagnosed through ADOS-2, Module 4. The computed correlation matrix for\nthe features is presented in Figure 1.\n1. Highly Correlated Features:\n• F1, F4, and F5: These features show very high correlations (r = 0.734 between F1 and F4, r = 0.727\nbetween F1 and F5, and r = 0.655 between F4 and F5). This suggests they may capture similar aspects of\nlinguistic behavior, possibly related to the repetitive or stereotyped use of language, which is a common\nindicator of ASD.\n• F4 and F9: Another pair, F4 and F9 (r = 0.622), indicates a strong association, which might reflect\noverlapping features of language presentation in ASD, such as idiosyncratic language use or atypical\nlanguage processing.\n7\n2. Moderately Correlated Features:\n• F2 and F3: These features exhibit moderate correlations (r = 0.55 for F2 and F3), with F2 and F3 showing\na correlation strength that is typically described as ’moderate’ according to established guidelines for\ninterpreting correlation coefficients. These correlations suggest a meaningful but not strong relationship\nin linguistic traits, such as variability in speech that includes both repetitive and novel elements.\n3. Negatively Correlated Features:\n• F1 and F10: The negative correlation (r = −0.184) suggests that when F1 (possibly denoting less severe\nASD indicators) is present, F10 (perhaps denoting more severe ASD indicators) is less likely to be\npresent, and vice versa. This can help differentiate levels of language impairment in ASD diagnoses.\nTogether, the exploration of the correlation between features of language deficit in ASD offers valuable\ninsights into the complex nature of communication challenges faced by individuals on the spectrum.\n2.4.2 Distribution of Features of Language Deficit Across Scenarios\nTable 7 Prevalence of Linguistic Features by Scenario Indicative of Language\nDeficits in ASD\nScenario\nF1\nF2\nF3\nF4\nF5\nF6\nF7\nF8\nF9\nF10\n3\n0.45\n0.64\n0.52\n0.32\n0.39\n0.59\n0.48\n0.41\n0.39\n0.36\n4\n0.57\n0.59\n0.45\n0.32\n0.41\n0.59\n0.57\n0.39\n0.30\n0.32\n5\n0.43\n0.55\n0.41\n0.23\n0.43\n0.61\n0.48\n0.27\n0.25\n0.32\n6\n0.41\n0.34\n0.25\n0.18\n0.36\n0.55\n0.43\n0.23\n0.07\n0.30\n7\n0.48\n0.39\n0.34\n0.20\n0.36\n0.50\n0.39\n0.30\n0.20\n0.30\n9\n0.57\n0.43\n0.30\n0.20\n0.32\n0.48\n0.41\n0.23\n0.16\n0.20\n11\n0.43\n0.39\n0.32\n0.14\n0.32\n0.59\n0.55\n0.32\n0.18\n0.32\n12\n0.45\n0.55\n0.41\n0.18\n0.36\n0.55\n0.61\n0.41\n0.07\n0.32\n13\n0.55\n0.36\n0.25\n0.02\n0.36\n0.48\n0.30\n0.25\n0.02\n0.23\n14\n0.36\n0.41\n0.18\n0.11\n0.23\n0.34\n0.20\n0.11\n0.07\n0.11\n15\n0.64\n0.57\n0.32\n0.36\n0.52\n0.64\n0.57\n0.32\n0.30\n0.20\nThis subsection analyzes the correlations between linguistic features across various ADOS scenarios to\nidentify patterns that may indicate language disorders associated with ASD. The focus is on scenarios with\ndirect dialogue between the examiner and the patient, reflecting our study’s emphasis on communication.\nWhile Scenarios S1, S2, S8, and S10 provide valuable insights into various aspects of cognitive and social\nfunctioning, they were not included in this analysis due to their lack of direct dialogue-based interaction\nbetween the examiner and the patient, which is a primary focus of our research. To effectively analyze the\ndifferences in the distribution of values from F1 to F10 across various scenarios, we conducted a detailed\nstatistical examination (see Table 7). This analysis helps to understand how the prevalence of each linguistic\nfeature associated with ASD varies across the scenarios, which can provide insights into the contexts or\nconditions under which certain features are more likely to appear.\nWe have derived the following observations and insights:\n• Feature Prevalence: The occurrence rates of features F2, F6, and F7, which represent aspects of uncon-\nventional content, verbal fluency, and excessive social phrasing respectively, were consistently above 60%\nacross most scenarios. This high prevalence underscores their significance as key indicators of ASD.\n• Language Feature in Social Contexts: Features such as F1 (possibly related to echolalia or repetitive\nspeech), F4, F5, and F9 (potentially related to atypical or stereotyped language use) were entirely absent\nin several scenarios, underscoring their sensitivity to specific social or communicative contexts.\n• Scenario-Specific Patterns: High prevalence rates in F7 during the S7 (i.e., ’Emotions’) scenario, and\ndiverse responses in F2 across the S12 (i.e., ’Friends, Relationships, and Marriage’) and S15 (i.e., ’Creating\na Story’) scenarios suggest that certain linguistic features were particularly elicited by emotional or social\nrelational contexts.\nTo further demonstrate the utility of this analysis, we specifically focused on the S3 and S9 scenarios,\nwhich are essential for evaluating narrative skills and abstract reasoning, respectively. We derived the following\nresults:\n• Scenario S3 (Figure 2): The strong correlation between F1 and F6 (0.68) indicates challenges in effectively\nsummarizing visual content. This may reflect difficulties in processing and conveying information succinctly,\nwhich is often a challenge for individuals with ASD. A high correlations (0.66) between F8 (monotone\nsocial expression) and F9 (stereotyped media quoting) suggests that individuals may struggle with varying\n8\nFig. 2 Correlation matrix of linguistic features F1 to F10 in the S3 (i.e., ’Description of a Picture’) scenario. The matrix shows\nstrong correlations between features, underscoring the interdependencies that influence how visual information is described.\ntheir emotional expressions, which could affect the emotional richness of their speech. Correlations between\nF7 (excessive social phrasing) and F4 (incongruous humor) (0.62), and between F7 and F2 unconventional\ncontent (0.61) suggest a connection between repetitive social expressions and the production of either\ninappropriate humor or atypical content. This pattern may indicate that individuals with ASD use scripted\nlanguage as a strategy to manage social interactions, although this can often result in conversations that\nseem awkward or misplaced.\n• Scenario S9 (Figure 3): The strong correlation between F2 and F3 (0.62) suggest that individuals with ASD\nmight struggle to adjust their language to fit the context appropriately. This is particularly problematic in\nscenarios like watching and discussing cartoons, where understanding shifting dialogues and multiple char-\nacters’ perspectives is essential; Additionally, F8’s significant correlations with F7 (0.57) reflects difficulties\nin varying emotional tone and using phrases that might be socially appropriate. Individuals exhibiting\nthese features tend to speak in a flat, unmodulated manner while possibly overusing certain social phrases,\nmaking their speech seem rigid and scripted. Such speech patterns can make it difficult for them to engage\nin spontaneous and emotionally responsive interactions, which are critical for successful social exchanges.\nTogether, these correlations suggest co-morbid linguistic challenges that individuals with ASD may\nencounter in scenarios requiring detailed visual interpretation or complex narrative understanding.\n2.4.3 Feature Detection Comparison Across Models\nTo investigate how different features influence model performance, we further analyze the performance of\nthe models through a feature detection comparison. Figure 4 provides a histogram comparing the counts of\nspecific linguistic features related to SLDs detected by GPT3.5-based and GPT4o-based models.\nGPT3.5 shows higher detection rates across key features like F2 (unconventional content), F6 (verbal\nfluency), and F7 (excessive social phrasing), which are crucial for diagnosing language deficits associated with\nASD. GPT4o performs well in identifying features such as F3 (pronoun displacement) and F10 (clich´ed verbal\nsubstitutions), but overall detects fewer features compared to GPT3.5. This histogram highlights GPT3.5’s\nsensitivity to a broader range of linguistic nuances, supporting its superior accuracy, PPV, and sensitivity.\nBy detecting critical indicators of SLDs, GPT3.5 offers a more comprehensive diagnostic tool for analyzing\nASD-related communication challenges.\n9\nFig. 3 Correlation matrix of linguistic features F1 to F10 in the S9 (i.e., ’Cartoons’) scenario. This matrix highlights correlations\nthat elucidate the cognitive and perceptual challenges in interpreting cartoons, essential for understanding narrative contexts\nand humor in ASD.\nFig. 4 Detected SLD Feature Count Comparison between GPT-3.5 and GPT-4o\n2.5 Case Study\nLastly, we present two case studies to illustrate the practical application of ChatGPT in identifying language\ndeficits in ASD.\nTable 8 and 9 show the dialogue between an examiner (E) and a patient (P). It showcases typical conver-\nsational challenges faced by individuals with ASD. The patient’s responses highlight several linguistic features\nthat indicate underlying language disorders.\nTogether, these case studies demonstrate the effectiveness of using ChatGPT, combined with structured\nconversational analysis, to diagnose social language disorders in ASD. The identified features align well\nwith known ASD communication challenges, providing a robust basis for further diagnostic evaluation and\nintervention planning.\n10\nTable 8 Case Study Analysis: Identifying Language Deficits in an Examiner-Patient Dialogue. Phrases highlighted in blue\nindicate observed linguistic anomalies, while red underscores the specific feature category of language deficits.\nExaminer (E) - Patient(P) Dialogue\nE: Okay. So, do you have some friends?\nP: Uh, do I have some friends?F1\nE: Um-hum.\nP: Well, pretty muchF10, three of them from peers.\nE: Three of them from here?\nP: Um-hum.\nE: Okay. Can you tell me a little bit about them?\nP: Well, they’re kind of living near, they kind of live near herF3 farther from here.\nE: They’re further from here? What do they like?\nP: What do they like?F1 They’re kind of energetic, just like me. Cool.\nE: Um, and what do you guys like to do together? Man, we like movies and stuff.\nP: And you’ve got to know them through peers.\n...\nE: And, but you said you’d go, you’d like to go to movies and stuff as well. Do you go to movies with them, or?\nP: We use gas moviesF9.\nE: Oh, you talk about it?\nP: Yeah.\nE: Okay. And are there people outside of peers that you’re friends with, or?\nP: You mean, uh, outside of peersF1?\n...\nP: Crazy, crowded, crooked.. One of those years people.\nE: Oh.\nP: They triggered the trip, pregnant sound effects.F9\nE: Oh, yeah.\nP: When they asked about dating.. Um What, where do you, uh, want to live when you get older\nE: face?\nP:\nI\nwant\nto\nlive\nin\na lounge and dirty autistic matching F2.\nYou\nknow,\nyou\ncan\nzillion blocks matchingF10.\nE: And who do you think you would like to live with, with your family or roommates or by yourself?\nP: I want to live with my family there. Okay\n...\nExtracted Features Based on ChatGPT Response\nEchoic Repetition (F1): When the examiner first asked the patient whether they have some friends, the patient\nechoed the question back at the examiner before answering. In subsequent interactions, the patient frequently mimics the\nexaminer’s questions verbatim before answering.\nUnconventional Content (F2): The patient refers to living in ”a lounge and dirty autistic matching” rather than\nusing any conventional descriptions for living spaces. Similarly, the phrase ”zillion blocks matching” has an unusual\ncontent.\nPronoun Displacement (F3): The patient referred to his own house as ”her”.\nStereotyped Media Quoting (F9): The patient quoted ”gas movies” and ”triggered the trip, pregnant sound\neffects”, which seems to be quoted from an external media source.\nClich´ed Verbal Substitutions (F10): The patient uses clich´ed expressions like ”well, pretty much” instead of giving\ndirect responses.\n3 Discussion\n3.1 Leveraging ChatGPT for ASD Diagnosis\nThe experimental results demonstrate ChatGPT’s exceptional performance in diagnosing ASD-related lan-\nguage deficits, particularly through significant improvements in sensitivity and PPV. High sensitivity reflects\nthe model’s ability to identify a substantial proportion of true positives, ensuring that fewer ASD cases\nare missed. This is critical in clinical settings, where delayed diagnosis can hinder timely interventions and\nexacerbate social and communicative challenges in patients. ChatGPT’s ability to capture subtle linguis-\ntic anomalies, such as repetitive phrasing and pronoun reversal, further showcases its capacity to generalize\nacross diverse linguistic patterns while identifying ASD-specific markers. Similarly, the model’s high PPV\nunderscores its reliability by reducing false positives. This precision is particularly valuable in distinguishing\nASD-related language deficits from typical developmental variations, which often present overlapping charac-\nteristics. By effectively minimizing misdiagnoses, ChatGPT alleviates undue stress for patients and ensures\noptimal allocation of clinical resources.\nThese results highlight ChatGPT’s potential to revolutionize ASD diagnostics in medical practice. Its\nhigh sensitivity ensures that at-risk individuals are identified early, paving the way for timely therapeutic\ninterventions that can improve outcomes significantly. Meanwhile, its elevated precision supports confident\ndecision-making, enabling clinicians to focus on cases most likely to benefit from tailored care. Additionally,\nthe interpretable outputs generated by ChatGPT provide actionable insights into linguistic features, such as\necholalia and atypical language use, offering a valuable tool for designing personalized treatment plans. The\nability to integrate AI-driven diagnostics into existing workflows not only streamlines the diagnostic process\nbut also sets a foundation for more consistent and scalable practices in developmental medicine.\n11\nTable 9 Case Study Analysis: Identifying Language Deficits in an Examiner-Patient Dialogue. Phrases highlighted in blue\nindicate observed linguistic anomalies, while red underscores the specific feature category of language deficits.\nExaminer (E) - Patient(P) Dialogue\nE: So, I’m going to ask you a few questions about work and school\nP: Yes.\nE: Um, first of all, do you have a job?\nP: No, I used to be laid off.\n...\nE: And that’s okay? Yeah Um, while you were working or now at school, or at high school, maybe before that, did you\nhave a group of, any problems getting along with people You weren’t in high school?\nP: Any school. Well, like, like, stupid schools for you when I was developing angry or high school.F2\n...\nE: What kind of things you used to bother you that other people did?\nP: Like, uh, when I was in the school bus I had students grabbing my backpack, whatever, and\nI didn’t mad it or suck.F10\n...\nE: And have you ever done anything so that other people wouldn’t teach soon?\nP: Yes, but sometimes they just, it’s like they’ve been doing it for a while, so it’s just kind of like Hey,\nyou know or what, whatever,F6 we’ll just tease him about something else.\n...\nExtracted Features Based on ChatGPT Response\nUnconventional Content (F2): There are instances where the patient uses unconventionally chosen phrases like\n”stupid schools for you when I was developing angry or high school”.\nSuperfluous Phrase Attachment (F6): The patient attaches redundant phrases or filler expressions to their speech\nwithout contributing any substantive meaning or context, such as ’whatever’ and ’or whatever’.\nClich´ed Verbal Substitutions (F10): The patient resorts to clich´ed expressions when describing how he felt during\ncertain situations: ”I didn’t mad it or suck.\n3.2 Impact of Speaker Diarization on ASD Diagnosis\nThe integration of speaker diarization, particularly Google’s role-based system, has been pivotal in enabling\nautomatic diagnosis of ASD in conversational scenarios. By distinguishing examiner and patient speech, the\nmodel is better equipped to analyze patient-specific language patterns. This role differentiation significantly\ncontributes to the model’s high sensitivity and contextual understanding.\nHowever, our results indicate that the performance of automatic speaker diarization, while effective,\nstill falls short compared to human diarization. In ablation experiments, human diarization achieved the\nhighest Accuracy (82.00%), PPV (91.06%), and F1 score (86.57%), outperforming automated methods. This\nhighlights the critical role of speaker diarization in ASD diagnosis and suggests that further advancements in\ndiarization technology are likely to improve diagnostic accuracy. As automated diarization tools like Google’s\nsystem continue to evolve, their ability to match or exceed human-level precision will make them even more\nvaluable for diagnosing ASD, where conversational context and speaker roles are essential.\n3.3 Scenario-Based Analysis of Social Language Disorder Features\nThe prevalence of language deficits across different scenarios revealed valuable patterns about how individuals\nwith ASD respond to various social and cognitive contexts:\n• Emotional and Creative Contexts: Scenarios such as S7 (Emotions) and S15 (Creating a Story) elicited\nhigher occurrences of features like F6 (verbal fluency) and F7 (excessive social phrasing). This suggests that\nemotional and narrative-based interactions highlight specific communication challenges in individuals with\nASD, such as difficulty adapting language to dynamic social contexts or producing coherent narratives [33].\n• Visual Interpretation Challenges: In S3 (Description of a Picture), strong correlations between F1 (rep-\netition) and F6 (verbal fluency) indicate struggles with organizing and summarizing visual information.\nThese patterns align with known cognitive challenges in ASD, such as difficulties in abstraction and the\nintegration of sensory input into coherent verbal descriptions [34].\n• Abstract Reasoning in Narratives: The results from S9 (Cartoons) highlight co-occurring features like\nF2 (unconventional content) and F3 (pronoun displacement), suggesting that interpreting multi-character\nnarratives and shifting perspectives poses significant difficulties for individuals with ASD. These find-\nings reinforce the need for scenario-specific evaluations that consider how different contexts elicit unique\nlinguistic deficits.\n3.4 Clinical Implications for ASD Diagnosis\nThe results from the present study have strong clinical implications. Our model’s ability to analyze complex\nlanguage interactions is valuable in clinical settings. It allows for an earlier and more accurate detection of\nlanguage deficits, which are often indicative of ASD. This early diagnosis is crucial for the timely intervention\nthat can lead to better management and outcomes for adults with ASD. A promising future direction is to\n12\nleverage the power of LLM into distinguishing ASD from other language impairment during the development\n[35]. If LLM can shed new insight to the co-occurrence of ASD and language impairment, clinical diagnosis\nof developmental disorders might benefit from human-AI collaboration.\n3.5 Limitation and Future Work\nDespite its innovations, this study has limitations that should be addressed in future research. One limitation\nis the relatively small dataset size, while sufficient for exploratory analyses, restricts the statistical power and\ngeneralizability of our findings. As medical data is often difficult to obtain due to privacy and accessibility\nconstraints, future work will prioritize acquiring larger and more diverse datasets to enhance the robustness\nand applicability of our approach. Additionally, the effectiveness of the ChatGPT model depends heavily\non the quality and variety of the training data. The current dataset represents a relatively homogeneous\npopulation in terms of linguistic and cultural backgrounds. Expanding the dataset to include a more diverse\npopulation could improve the model’s robustness and generalizability. Furthermore, future studies could\nexplore the integration of multimodal data analysis [36] to enhance diagnostic capabilities further. Combining\nspeech with visual cues such as facial expressions and body language could provide a more comprehensive view\nof an individual’s communicative and social behaviors. Finally, refining the models to incorporate feedback\nloops that enable continual learning from new data could adaptively improve diagnostic accuracy over time\n[37]. These enhancements will pave the way for more robust and comprehensive diagnostic tools in the future.\n4 Methods\n4.1 Framework for Diagnosing Autism and Identifying Language Disorders\nBuilding on the foundational practices established by the ADOS-2, specifically Module 4 designed for verbally\nfluent adolescents and adults, we have developed a comprehensive framework (see Figure 1) that incorporates\nLLMs like ChatGPT. This framework is tailored to enhance the diagnostic PPV and identification of language\ndisorders in individuals suspected of having ASD. Specifically, it involves the following components:\nFig. 5 Framework for Diagnosing Autism and Identifying Language Disorders. A4 Score: Stereotyped/Idiosyncratic Use of\nWords or Phrases (see Table 3).\n• Speaker Diarization and Audio Transcription. This technology segments the audio recordings to\nprecisely separate the speech of the examiner from that of the patient. Such separation is crucial as it\nenhances the understanding of the patient’s behavior in conversational contexts by isolating their verbal\nresponses, which are then analyzed for potential linguistic abnormalities. The audio segments identified\n13\nthrough diarization are subsequently transcribed into text using Google’s state-of-the-art transcription\ntechnologies (see Fig. 5). This conversion facilitates a detailed examination of the social language used by\nthe patient, aiding in the detection of disorder-specific features within their speech.\n• Language Pattern Analysis Using ChatGPT.\nIn this framework, ChatGPT is utilized not only to diagnose ASD but also to identify specific language dis-\norder characteristics that are indicative of ASD. Structured prompts are prepared to gather key information\nfrom examiner-patient dialogues. These prompts are crafted as follows:\n– Examiner-Patient Dialogue (EPD): The dialogue text, which includes conversational exchanges\nbetween the examiner and the patient, serves as the primary input for ChatGPT. This dialogue is\ncarefully processed to maintain the integrity and context of the interaction, ensuring that all relevant\nlinguistic cues are preserved.\n– Question Design: To guide the analysis, specific questions are formulated based on the dialogue content.\nThese questions aim to direct ChatGPT’s attention to potential signs of language disorders, such as\nrepetitive phrasing, atypical language use, or disrupted conversational flow.\n– Knowledge Design: This component incorporates domain-specific knowledge from autism diagnostics,\nwhich is used to refine ChatGPT’s responses. By integrating expert knowledge, the model is better\nequipped to recognize and interpret the subtle nuances that characterize ASD-related language disorders.\n– Prompt Integration: The complete prompt for ChatGPT includes the dialogue text, the targeted ques-\ntions, and the expert knowledge cues. This integrated approach helps in precisely pinpointing disorder\ncharacteristics that might be overlooked in a less structured analysis.\n• Functionality of the Response Parser: The response parser is a critical element that processes the\noutputs from ChatGPT. It performs two main functions:\n– Identification of Specific Characteristics: Beyond mere diagnosis, the response parser identifies\nspecific characteristics of the language disorders. It extracts detailed information about the nature and\nextent of the linguistic anomalies detected, such as the type of stereotypy or idiosyncrasy in the patient’s\nspeech.\n• Diagnosis based on ADOS-2 Module 4: The final classification module evaluates the detected features\n(F1-F10) based on predefined criteria derived from ADOS-2 guidelines. This module integrates domain\nknowledge to predict A4 scores (A4 = 0 or A4 > 0) by systematically analyzing the presence and severity\nof SLDs as follows:\n– If critical features, such as F1 (Echoic Repetition) or F9 (Stereotyped Media Quoting), are identified,\nthe dialogue is classified as A4 > 0 (Label 1). These severe features strongly indicate significant social\nlanguage impairment.\n– Cumulative Features Rule: If more than two other related features (e.g., F2, F3, etc.) are present, the\nmodule predicts A4 > 0 (Label 1). This reflects the cumulative impact of multiple moderate symptoms.\n– Non-SLD Classification: If neither severe symptoms nor a sufficient number of related features are\ndetected, the module predicts A4 = 0 (Label 0). This outcome suggests no notable social language\ndisorder in the dialogue.\n– A4 Classification Output: Based on the above rules, the module outputs the A4 classification results:\nA4 = 0 (Label 0): No significant social language disorders detected. A4 > 0 (Label 1): Significant social\nlanguage disorders detected.\n4.2 Speaker Diarization and Transcription for Examiner-Patient Interactions\nAccurate separation and transcription of examiner-patient dialogues are essential for analyzing linguistic\npatterns in ASD diagnosis. In this study, we leverage speaker diarization and transcription technologies\nto automate this process, addressing the limitations of traditional manual annotation. Speaker diarization\ninvolves segmenting audio recordings into distinct sections attributed to individual speakers, ensuring precise\nidentification of patient responses while maintaining the conversational context provided by the examiner.\nWe employed Google’s advanced role-based diarization system, which extends beyond generic speaker\nlabeling (e.g., ”Speaker 1” or ”Speaker 2”) by explicitly identifying roles as ”Examiner” and ”Patient.” This\nfunctionality is particularly valuable in ASD diagnostics, as it enables the focused analysis of patient-specific\nlanguage behaviors. Following diarization, the segmented audio files were transcribed into text, creating a\nstructured dataset for linguistic feature extraction and SLD analysis. The workflow includes three key steps:\n• Audio Segmentation: Long recordings were divided into segments based on diagnostic scenarios, such as\npicture description or abstract reasoning tasks. This segmentation ensures targeted analysis for each task.\n14\n• Speaker Role Labeling: Using Google’s Medical-Conversation Model, the diarization system identified and\nlabeled speaker roles within the conversation, preserving the dynamic interplay between examiner prompts\nand patient responses.\n• Speech-to-Text Transcription: Each audio segment was transcribed into text with speaker-specific\nannotations, forming a reliable foundation for subsequent computational analysis.\nThis automated approach not only reduces the manual workload but also ensures consistent and scal-\nable processing of examiner-patient dialogues, laying the groundwork for robust ASD diagnostic models. By\nintegrating diarization and transcription into a unified pipeline, we streamline the analysis of conversational\ninteractions while maintaining alignment with clinical diagnostic frameworks like ADOS-2.\n4.3 Diagnosing Language Disorders Associated with Autism via ChatGPT\nThis subsection details the methodology used to employ ChatGPT, an advanced language model, for diagnos-\ning SLDs in individuals with ASD. The approach leverages a structured prompt to analyze dialogues between\nexaminers and patients, determining the presence of communicative impairments characteristic of ASD.\nPrompt Design for ChatGPT:\nThis process involved parts. In Part 1, Examiner-Patient Dialogue\n(EPD), the input to ChatGPT included the transcribed dialogue between the examiner and the patient, pre-\nsenting the conversational context needed for assessment. In Part 2, Question (Q), following the dialogue,\nChatGPT was asked: ”Based on the above conversation between the examiner and the patient, please catego-\nrize if any observed SLDs for the patient. Answer only ’Yes’ or ’No’.” This question aimed to elicit a definitive\nresponse based on the dialogue’s content, focusing solely on the presence or absence of disorder indicators.\nResponse Interpretation Using ChatGPT: The responses from ChatGPT were parsed to determine\nthe presence of SLDs. The decision process was as follows:\n• Response Parser: Each response from ChatGPT, indicating either affirmation (”Yes”) or negation\n(”No”), was analyzed to ascertain whether the patient exhibited symptoms of SLDs based on the dialogue\nprovided. The parser specifically looked for expressions of affirmation or negation concerning the presence\nof communicative impairments.\n• Diagnosis Determination: For each subject, a diagnosis of a SLD was considered positive if there was\nat least one scenario where ChatGPT affirmed the presence of SLDs (”Yes”). Conversely, if all scenarios\nresulted in a ”No” from ChatGPT, the subject was not considered to have SLDs as per the dialogues\nanalyzed.\nBy integrating ChatGPT’s advanced analytical capabilities, this methodology refines the diagnostic pro-\ncess for social language disorders in ASD, enhancing both the efficiency and accuracy of assessments. This\napproach not only supports clinicians by providing a reliable diagnostic tool but also contributes to the\nbroader field of psycholinguistics by offering insights into the communicative impairments often seen in ASD.\n4.4 Identifying Language Disorder Features Associated with ASD via ChatGPT\nThis subsection elaborates on the methodology employed to harness ChatGPT for identifying specific lan-\nguage disorder features associated with ASD, guided by expert knowledge integrated from the ADOS-2,\nModule 4. The approach utilizes a comprehensive list of language disorders designed around the nuanced\ncommunication requirements and symptoms observed in verbally fluent adolescents and adults.\nTo facilitate the extraction of these features of language deficits using ChatGPT, a specific prompt\nstructure is utilized, as shown in ’Prompt 2’ (Figure 5). The prompt was organized into three parts to optimize\nthe analysis, including Part 1: Examiner-Patient Dialogue (EPD), Part 2: Question (Q) - ..., and Part 3:\nKnowledge (K) - ”Overview of the 10 features of social language disorders identified by ADOS-2 examiners,\nas shown in the column ’Explanation’ in Table 4.\nThis structured prompt design guides ChatGPT to analyze the transcribed conversations and categorize\nlanguage deficits, enhancing the PPV of diagnostics based on observed linguistic patterns.\nResponse Interpretation Using ChatGPT: ChatGPT’s responses were analyzed to determine the\npresence and types of SLD features as follows:\n• Response Parser: The parser reviewed ChatGPT’s responses, which involved multiple labels correspond-\ning to the 10 predefined SLD features. Each piece of dialogue could yield several labels, reflecting the\nmulti-dimensional nature of language disorders.\n• Feature Classification: Each response was predicted into multiple categories, constituting a multi-label\nclassification task. This approach allowed for a comprehensive assessment of the patient’s language abilities,\nidentifying multiple SLD features from a single excerpt of dialogue.\nThe multi-label classification approach offers significant advantages in the diagnosis of SLDs. By cat-\negorizing dialogue into multiple SLD-related features, ChatGPT enables a comprehensive analysis of the\n15\npatient’s communicative impairments, providing a nuanced understanding of their specific challenges. This\ndetailed insight is critical for ensuring accurate diagnoses and helps clinicians identify the precise nature of\nthe language deficits. Furthermore, recognizing distinct disorder features allows for the development of tar-\ngeted intervention strategies, enabling clinicians to design personalized and effective treatments that address\nthe unique difficulties faced by each patient.\nUtilizing ChatGPT to identify and classify language disorder features via a structured multi-label clas-\nsification approach significantly refines the diagnostic capabilities in ASD assessments. This methodology\nnot only enhances the accuracy of the diagnoses but also deepens the understanding of the patient’s specific\ncommunicative deficits, facilitating the development of targeted therapeutic strategies.\n5 Conclusion\nThis research confirmed the substantial benefits of integrating LLMs such as ChatGPT with the ADOS-2 pro-\ncedures for diagnosing ASD in adults. Utilizing ChatGPT, enhanced with Google’s speaker diarization and\ntranscription technologies, significantly improved the accuracy, PPV, sensitivity, and F1 score of language\ndeficit diagnoses compared to traditional models. This integration streamlines the diagnostic process, improv-\ning efficiency and reducing subjectivity. It also enhances the scalability of interventions, enabling enhanced\nefficiency and precision assessments essential for effective treatment planning.\nLooking forward, the study highlights the potential for these technologies to incorporate a wider variety\nof data and to develop adaptive learning models that continually improve in accuracy and effectiveness. This\nprogression promises to revolutionize ASD diagnostics, paving the way for more personalized and accessible\ncare for individuals with ASD. The integration of LLMs like ChatGPT in clinical settings is a forward step in\nmaking ASD diagnostics not only quicker and more accurate but also more comprehensive in understanding\nand addressing the diverse needs of the autism community.\nDeclarations\n• Funding\nThis material is based upon work supported by the National Science Foundation under Grant No. HCC-\n2401748 and National Institute of Health under Grant No. R01MH129426. The funders had no role in\nstudy design, data collection and analysis, decision to publish, or preparation of the manuscript.\n• Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)\nThe authors declare no conflict of interest.\n• Author contribution\nC.H., L.K.P., S.W., X.L. designed research. L.K.P. performed experiments. C.H., W.L., M.R., and X.Y.\nanalyzed data. C.H., S.W., and X.L. wrote the paper. All authors discussed the results and contributed\ntoward the manuscript.\nReferences\n[1] Leekam, S.R., Prior, M.R., Uljarevic, M.: Restricted and repetitive behaviors in autism spectrum\ndisorders: a review of research in the last decade. Psychological bulletin 137(4), 562 (2011)\n[2] Lord, C., Elsabbagh, M., Baird, G., Veenstra-Vanderweele, J.: Autism spectrum disorder. The lancet\n392(10146), 508–520 (2018)\n[3] Lord, C., Brugha, T.S., Charman, T., Cusack, J., Dumas, G., Frazier, T., Jones, E.J., Jones, R.M.,\nPickles, A., State, M.W., et al.: Autism spectrum disorder. Nature reviews Disease primers 6(1), 1–23\n(2020)\n[4] Lauritsen, M.B.: Autism spectrum disorders. European child & adolescent psychiatry 22, 37–42 (2013)\n[5] Baird, G., Norbury, C.F.: Social (pragmatic) communication disorders and autism spectrum disorder.\nArchives of Disease in Childhood 101(8), 745–751 (2016)\n[6] Nazeer, A., Ghaziuddin, M.: Autism spectrum disorders: clinical features and diagnosis. Pediatric Clinics\n59(1), 19–25 (2012)\n[7] Sperry, L.A., Mesibov, G.B.: Perceptions of social challenges of adults with autism spectrum disorder.\nAutism 9(4), 362–376 (2005)\n16\n[8] Velikonja, T., Fett, A.-K., Velthorst, E.: Patterns of nonsocial and social cognitive functioning in adults\nwith autism spectrum disorder: A systematic review and meta-analysis. JAMA psychiatry 76(2), 135–151\n(2019)\n[9] Rapin, I., Dunn, M.: Update on the language disorders of individuals on the autistic spectrum. Brain\nand development 25(3), 166–172 (2003)\n[10] Magiati, I., Tay, X.W., Howlin, P.: Cognitive, language, social and behavioural outcomes in adults with\nautism spectrum disorders: A systematic review of longitudinal follow-up studies in adulthood. Clinical\npsychology review 34(1), 73–86 (2014)\n[11] Whitehouse, A.J., Watt, H.J., Line, E., Bishop, D.V.: Adult psychosocial outcomes of children with spe-\ncific language impairment, pragmatic language impairment and autism. International journal of language\n& communication disorders 44(4), 511–528 (2009)\n[12] Lord, C., Rutter, M., Goode, S., Heemsbergen, J., Jordan, H., Mawhood, L., Schopler, E.: Autism\ndiagnostic observation schedule. Journal of Autism and Developmental Disorders (2012)\n[13] Hu, C., Thrasher, J., Li, W., Ruan, M., Yu, X., Paul, L.K., Wang, S., Li, X.: Exploring speech pattern\ndisorders in autism using machine learning. arXiv preprint arXiv:2405.05126 (2024)\n[14] Mukherjee, P., Gokul, R., Sadhukhan, S., Godse, M., Chakraborty, B.: Detection of autism spectrum dis-\norder (asd) from natural language text using bert and chatgpt models. International Journal of Advanced\nComputer Science and Applications 14(10) (2023)\n[15] Yu, X., Ruan, M., Hu, C., Li, W., Paul, L.K., Li, X., Wang, S.: Video-based analysis reveals atypical\nsocial gaze in people with autism spectrum disorder. arXiv preprint arXiv:2409.00664 (2024)\n[16] Ruan, M., Yu, X., Zhang, N., Hu, C., Wang, S., Li, X.: Video-based contrastive learning on decision\ntrees: From action recognition to autism diagnosis. In: Proceedings of the 14th Conference on ACM\nMultimedia Systems, pp. 289–300 (2023)\n[17] Ruan, M., Zhang, N., Yu, X., Li, W., Hu, C., Webster, P.J., K. Paul, L., Wang, S., Li, X.: Can micro-\nexpressions be used as a biomarker for autism spectrum disorder? Frontiers in Neuroinformatics 18,\n1435091 (2024)\n[18] Zhang, N., Ruan, M., Wang, S., Paul, L., Li, X.: Discriminative few shot learning of facial dynamics\nin interview videos for autism trait classification. IEEE Transactions on Affective Computing 14(2),\n1110–1124 (2022)\n[19] Ellis Weismer, S., Lord, C., Esler, A.: Early language patterns of toddlers on the autism spectrum\ncompared to toddlers with developmental delay. Journal of autism and developmental disorders 40,\n1259–1273 (2010)\n[20] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P.,\nSastry, G., Askell, A., et al.: Language models are few-shot learners. Advances in neural information\nprocessing systems 33, 1877–1901 (2020)\n[21] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W.: Large\nlanguage models in medicine. Nature medicine 29(8), 1930–1940 (2023)\n[22] Yang, X., Chen, A., PourNejatian, N., Shin, H.C., Smith, K.E., Parisien, C., Compas, C., Martin, C.,\nCosta, A.B., Flores, M.G., et al.: A large language model for electronic health records. NPJ digital\nmedicine 5(1), 194 (2022)\n[23] Wei, X., Cui, X., Cheng, N., Wang, X., Zhang, X., Huang, S., Xie, P., Xu, J., Chen, Y., Zhang, M., et\nal.: Chatie: Zero-shot information extraction via chatting with chatgpt. arXiv preprint arXiv:2302.10205\n(2024)\n[24] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al.: Summary of\nchatgpt-related research and perspective towards the future of large language models. Meta-Radiology,\n100017 (2023)\n[25] Quttainah, M., Mishra, V., Madakam, S., Lurie, Y., Mark, S., et al.: Cost, usability, credibility, fairness,\n17\naccountability, transparency, and explainability framework for safe and effective large language models\nin medical education: Narrative review and qualitative study. JMIR AI 3(1), 51834 (2024)\n[26] Lord, C., Rutter, M., DiLavore, P.C., Risi, S., Gotham, K., Bishop, S.L., et al.: Ados. Autism diagnostic\nobservation schedule. Manual. Los Angeles: WPS (1999)\n[27] American Psychiatric Association, D., Association, A.P., et al.: Diagnostic and Statistical Manual of\nMental Disorders: DSM-5 vol. 5. American psychiatric association Washington, DC, ??? (2013)\n[28] Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R.R., Le, Q.V.: Xlnet: Generalized autore-\ngressive pretraining for language understanding. Advances in neural information processing systems 32\n(2019)\n[29] Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut, R.: Albert: A lite bert for self-\nsupervised learning of language representations. arXiv preprint arXiv:1909.11942 (2019)\n[30] Sanh, V., Debut, L., Chaumond, J., Wolf, T.: Distilbert, a distilled version of bert: smaller, faster,\ncheaper and lighter. arXiv preprint arXiv:1910.01108 (2019)\n[31] Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov,\nV.: Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019)\n[32] Devlin, J., Chang, M.-W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional transformers\nfor language understanding. arXiv preprint arXiv:1810.04805 (2018)\n[33] Losh, M., Gordon, P.C.: Quantifying narrative ability in autism spectrum disorder: A computational\nlinguistic analysis of narrative coherence. Journal of autism and developmental disorders 44, 3016–3025\n(2014)\n[34] Happ´e, F., Frith, U.: The weak coherence account: detail-focused cognitive style in autism spectrum\ndisorders. Journal of autism and developmental disorders 36, 5–25 (2006)\n[35] Loucas, T., Charman, T., Pickles, A., Simonoff, E., Chandler, S., Meldrum, D., Baird, G.: Autistic\nsymptomatology and language ability in autism spectrum disorder and specific language impairment.\nJournal of Child Psychology and Psychiatry 49(11), 1184–1192 (2008)\n[36] Han, J., Jiang, G., Ouyang, G., Li, X.: A multimodal approach for identifying autism spectrum disorders\nin children. IEEE Transactions on Neural Systems and Rehabilitation Engineering 30, 2003–2011 (2022)\n[37] Biesialska, M., Biesialska, K., Costa-Jussa, M.R.: Continual lifelong learning in natural language\nprocessing: A survey. arXiv preprint arXiv:2012.09823 (2020)\n18\n",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "published": "2024-05-03",
  "updated": "2024-11-29"
}