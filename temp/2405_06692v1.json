{
  "id": "http://arxiv.org/abs/2405.06692v1",
  "title": "Analyzing Language Bias Between French and English in Conventional Multilingual Sentiment Analysis Models",
  "authors": [
    "Ethan Parker Wong",
    "Faten M'hiri"
  ],
  "abstract": "Inspired by the 'Bias Considerations in Bilingual Natural Language\nProcessing' report by Statistics Canada, this study delves into potential\nbiases in multilingual sentiment analysis between English and French. Given a\n50-50 dataset of French and English, we aim to determine if there exists a\nlanguage bias and explore how the incorporation of more diverse datasets in the\nfuture might affect the equity of multilingual Natural Language Processing\n(NLP) systems. By employing Support Vector Machine (SVM) and Naive Bayes models\non three balanced datasets, we reveal potential biases in multilingual\nsentiment classification. Utilizing Fairlearn, a tool for assessing bias in\nmachine learning models, our findings indicate nuanced outcomes. With French\ndata outperforming English across accuracy, recall, and F1 score metrics in\nboth models, hinting at a language bias favoring French. However, Fairlearn's\nmetrics suggest that the SVM approaches equitable levels with a demographic\nparity ratio of 0.963, 0.989, and 0.985 for the three separate datasets,\nindicating near-equitable treatment across languages. In contrast, Naive Bayes\ndemonstrates greater disparities, evidenced by a demographic parity ratio of\n0.813, 0.908, and 0.961. These findings reveal the importance of developing\nequitable multilingual NLP systems, particularly as we anticipate the inclusion\nof more datasets in various languages in the future.",
  "text": "arXiv:2405.06692v1  [cs.CL]  7 May 2024\nAnalyzing Language Bias Between French and English\nin Conventional Multilingual Sentiment Analysis\nModels\nEthan Parker Wong\nEmail: ethan.wong@mail.mcgill.ca\nSupervisor: Faten M’hiri, PhD\nMcGill University\nFaculty of Computer Science\nApril 29th, 2024\nContents\n1\nAbstract\n3\n2\nIntroduction\n3\n3\nBackground and Related Work\n4\n3.1\nMultilingual Natural Language Processing and Equity . . . . . . . . . . . . . . . . .\n4\n3.2\nDeep Learning and Replicability\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n3.3\nMachine Learning in Sentiment Analysis . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n3.4\nLanguage Biases\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n4\nPurpose and Research Inquiry\n6\n4.1\nPurpose of the Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n4.2\nResearch Inquiries\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n5\nMethodology\n7\n5.1\nDataset\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n5.2\nData Pre-Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n5.3\nHyperparameter Tuning with Optuna\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n5.4\nFairlearn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n5.4.1\nDemographic Parity Diﬀerence (DPD) . . . . . . . . . . . . . . . . . . . . . .\n10\n5.4.2\nEqualized Odds Diﬀerence (EOD)\n. . . . . . . . . . . . . . . . . . . . . . . .\n10\n5.4.3\nEqualized Odds Ratio (EOR) . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n5.4.4\nDemographic Parity Ratio (DPR)\n. . . . . . . . . . . . . . . . . . . . . . . .\n11\n5.5\nFeature Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n5.6\nApplication of Naive Bayes and Support Vector Machine . . . . . . . . . . . . . . . .\n12\n1\n5.6.1\nApplication of Naive Bayes\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n5.6.2\nApplication of Support Vector Machine (SVM) . . . . . . . . . . . . . . . . .\n13\n6\nResults\n14\n6.0.1\nSupport Vector Machine (SVM)\n. . . . . . . . . . . . . . . . . . . . . . . . .\n14\n6.0.2\nNaive Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n7\nDiscussion\n16\n7.1\nAnalysis of Model Performance and Language Bias . . . . . . . . . . . . . . . . . . .\n16\n7.2\nFairness Metrics and Model Equity . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n7.2.1\nSVM Model Fairness Evaluation\n. . . . . . . . . . . . . . . . . . . . . . . . .\n16\n7.2.2\nNaive Bayes Model Fairness Evaluation\n. . . . . . . . . . . . . . . . . . . . .\n17\n7.3\nDiscussion on Music Reviews\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n7.4\nPotential Reasons for French Performance . . . . . . . . . . . . . . . . . . . . . . . .\n20\n8\nLimitations\n20\n9\nConclusion\n21\n10 Appendix\n22\n2\n1\nAbstract\nInspired by the ’Bias Considerations in Bilingual Natural Language Processing’ report by Statis-\ntics Canada, this study delves into potential biases in multilingual sentiment analysis between En-\nglish and French. Given a 50-50 dataset of French and English, we aim to determine if there exists a\nlanguage bias and explore how the incorporation of more diverse datasets in the future might aﬀect\nthe equity of multilingual Natural Language Processing (NLP) systems. By employing Support\nVector Machine (SVM) and Naive Bayes models on three balanced datasets, we reveal potential\nbiases in multilingual sentiment classiﬁcation. Utilizing Fairlearn, a tool for assessing bias in ma-\nchine learning models, our ﬁndings indicate nuanced outcomes. With French data outperforming\nEnglish across accuracy, recall, and F1 score metrics in both models, hinting at a language bias\nfavoring French. However, Fairlearn’s metrics suggest that the SVM approaches equitable levels\nwith a demographic parity ratio of 0.963, 0.989, and 0.985 for the three separate datasets, indicating\nnear-equitable treatment across languages. In contrast, Naive Bayes demonstrates greater dispar-\nities, evidenced by a demographic parity ratio of 0.813, 0.908, and 0.961. These ﬁndings reveal\nthe importance of developing equitable multilingual NLP systems, particularly as we anticipate the\ninclusion of more datasets in various languages in the future.\n2\nIntroduction\nThe ﬁeld of Natural Language Processing (NLP) has seen remarkable advancements in recent\nyears, yet struggles with biases related to data quality, model design, and language representa-\ntion [2].\nSuch biases can aﬀect languages other than English, creating concerns about fairness\nin multilingual NLP systems. For instance, biases might manifest as variable model performance\nin sentiment analysis, typically favoring English due to it being more highly resourced [2]. This\nuneven development raises signiﬁcant fairness questions.\nThe ’Bias Considerations in Bilingual\n3\nNatural Language Processing’ report by Statistics Canada [1] sheds light on this complexity, re-\nvealing biases’ multifaceted nature. Motivated by these insights, our study delves into the impact\nof these language biases on sentiment analysis between English and French.\n3\nBackground and Related Work\n3.1\nMultilingual Natural Language Processing and Equity\nThe development of NLPs has widened the scope for analyzing and interpreting various lan-\nguages. With this development of NLPs, it is essential to remain equitable to all languages. The\npush for fairness in multilingual contexts presents considerations regarding the representation and\ntreatment of diverse languages, especially those considered underrepresented. One of the challenges\nin multilingual NLP models is the disproportionate focus on English. This imbalance results in\nadvanced NLP models that perform exceptionally well in English but lack the same accuracy and\nnuance when applied to languages with fewer digital resources [6]. This consequence provides a\ndivide where speakers of underrepresented languages have limited access to the beneﬁts of NLP\nsystems.\n3.2\nDeep Learning and Replicability\nAmidst this, transformer-based models have emerged in NLP, [3] setting new benchmarks across\nvarious tasks. Introduced by Vaswani et al., [4] these models have dominated recent NLP research.\nHowever, their complexity, alongside issues related to replicability and reproducibility highlighted\nby Liu et al., [5] prompts a re-evaluation of their universal applicability. Given these concerns\nand the computational demands of transformer models, our study uses conventional machine learn-\ning models, such as Naive Bayes and Support Vector Machines (SVMs).\nThese models oﬀer a\ntransparent approach to examining the nuances of language bias in sentiment analysis.\n4\n3.3\nMachine Learning in Sentiment Analysis\nSentiment analysis, a key component of NLP, leverages machine learning to categorize emotions\nexpressed in text. Traditional machine learning models, speciﬁcally those that do not involve deep\nlearning [7], such as Naive Bayes and Support Vector Machines (SVM), form the foundational\nbackbone of sentiment analysis due to their eﬀectiveness and interpretability.\nNaive Bayes classiﬁers, utilize Bayes’ theorem and assume feature independence [8], making\nthem advantageous for quick prototype developments and smaller datasets. Despite this, their appli-\ncation in sentiment analysis extends beyond English, as demonstrated by Wongkar and Angdresey\n[10], who applied Naive Bayes to predict sentiments in Indonesian political tweets. However, the\nindependence assumption can be a limitation in Natural Language Processing, where context and\ngrammar are crucial. For example, Alves et al. [9] show that SVM outperforms Naive Bayes in\nPortuguese, due to SVM’s robust handling of complex linguistic structures.\nSupport Vector Machines excel in sentiment analysis by determining the optimal hyperplane\nthat best separates positive from negative sentiments. They are particularly eﬀective in classifying\nsentiment in linguistically complex datasets [11]. This capability is emphasized in studies such as\nthose by Alves et al. [9] and Hasanli and Rustamov [12], who found SVMs to perform better in\nAzerbaijani tweets.\nThe choice to focus on SVM and Naive Bayes for our sentiment analysis tasks is decided by\ntheir well-documented eﬃcacy and widespread adoption in similar studies. Naive Bayes has been\nfoundational in the development of sentiment analysis, with works such as Turney [29] and Liu [30]\ndemonstrating its utility in classifying textual sentiment. Similarly, SVM’s robustness in handling\nhigh-dimensional text data is well-supported by studies such as Pang et al. [31] and Tong & Koller\n[32], which highlight its precision in sentiment classiﬁcation.\n5\n3.4\nLanguage Biases\nLanguage biases in sentiment analysis arise from the characteristics and cultural nuances of each\nlanguage, posing challenges to the accuracy and fairness of these systems, especially when applied\nacross diﬀerent linguistic backgrounds. Such biases can signiﬁcantly skew sentiment analysis results.\nAn example of language bias would be considering the English phrase ’That’s sick!’, which in\nslang means something is excellent [33]. However, when directly translated into another language,\nit might be interpreted negatively as it loses its cultural context. This kind of misinterpretation by\nsentiment analysis models can lead to inaccuracies, particularly in multilingual applications.\nRecent research shows the prevalence of these biases.\nLevy et al.\nfound that multilingual\ntraining might amplify biases, impacting sentiment analysis accuracy across various languages [26].\nAdditionally, Goldfarb-Tarrant et al. showed that cross-lingual transfer could import or worsen\nbiases, such as gender or racial biases [27].\nThese ﬁndings highlight the need for careful consideration and adjustment of sentiment analysis\nmodels to ensure fairness and accuracy when deployed across diverse linguistic settings.\n4\nPurpose and Research Inquiry\n4.1\nPurpose of the Study\nIn the ﬁeld of Natural Language Processing (NLP), equity and fairness remain at the forefront\nof the ﬁeld. While there has been research on transformers and bias, there exists a gap in research\nwhere we examine language biases in multilingual SVM and Naive Bayes models using updated\nbias metrics. There is also a gap in detecting bias in machine learning models given the equitable\nrepresentation of languages within multilingual datasets due to the dominance English has.\nThis research aims to bridge this gap, by examining the presence and extent of language biases\nin SVM and Naive Bayes models applied to sentiment analysis. This is being done so by equally\n6\nrepresenting English and French, to see how bias manifests in machine learning models when\nlinguistic equity is prioritized.\n4.2\nResearch Inquiries\nGuided by the commitment to equity, our research holds two primary questions.\n1. In the context of balanced English and French datasets, how do SVM and Naive\nBayes models perform in multilingual sentiment analysis, and what implications\ndo these performances have for understanding language biases?\n2. Given equal representation of English and French data, can Fairlearn eﬀectively\nidentify and address biases in SVM and Naive Bayes models and how do these\nmetrics allow for more equitable sentiment analysis models?\n5\nMethodology\n5.1\nDataset\nIn this study, we utilize the Webis-CLS-10 dataset developed by Prettenhofer and Stein [14],\nwhich comprises of product reviews in four languages: English, French, German, and Japanese,\nsourced from Amazon’s websites across various countries. The dataset categorizes each product re-\nview as either positive or negative based on the star ratings given by reviewers. Speciﬁcally, reviews\nwith less than three stars are labeled as negative, and those with more than three stars as positive,\nwhile reviews with exactly three stars are excluded to ensure clear sentiment classiﬁcation. This\nmethod ensures each sentiment category is balanced within the dataset, mitigating bias towards\nany speciﬁc sentiment.\nThe dataset is further segmented into three product categories: DVDs, Books, and Music.\nEach category will be independently utilized to train the Support Vector Machine (SVM) and\nNaive Bayes models, facilitating a nuanced understanding of sentiment analysis across diﬀerent\n7\ncontexts. This segmentation is crucial for our study’s aim to detect language bias in conventional\nsentiment analysis machine learning models, oﬀering a variety of consumer reviews in both English\nand French. For instance, within the music section, the dataset includes 25,220 English reviews\nand 15,940 French reviews; for DVDs, 30,000 English reviews and 9,358 French reviews; and for\nbooks, 50,000 English reviews and 32,780 French reviews. The initial reviews were formatted like\nthe following: English Reviews !:4 ?:3 this:3 hack:2 ..:2 .:2 is:2 guy:2 and:1 just:1 money:1 ca:1\ncd:1 wasted:1 total:1 any:1 really:1 funny:1 avoid:1 #label#:negative and French Reviews .:5\nle:4 ,:3 je:3 premier:2 et:2 ..:2 dernier:2 devrais:1 ce:1 autre:1 `a:1 sais:1 lis:1 ’est:1 #label#:negative\nThe format lists each word followed by a colon and a number indicating how many times that word\nappears in the reviews. For example, ”really: 1” means the word ”really” appears once in the\nreviews.\n5.2\nData Pre-Processing\nTo prepare the dataset for analysis, a series of pre-processing steps were employed to ensure\nuniformity in our data. Each review was converted to lowercase to standardize the text format\nacross diﬀerent languages and products. Subsequent ﬁltering targeted potential stop words in both\nEnglish and French.\nThe SpaCy library [15], was employed for two critical pre-processing tasks: named entity recog-\nnition and lemmatization. Named entity recognition was used to identify and exclude proper nouns\nand irrelevant entities which could skew the sentiment analysis. Following this, lemmatization was\napplied using SpaCy’s lemmatization function, which simpliﬁes words to their base form. This step\nis essential for reducing the complexity of language data and ensuring that variations of a word are\nanalyzed as a single item.\nTo balance the multilingual datasets, the number of English and French reviews was equal-\nized, and parity between positive and negative sentiments was maintained. This was achieved by\n8\nidentifying the minimum number of reviews in the smallest subgroup (e.g., French negative re-\nviews) and matching this count across all other subgroups English positive, English negative, and\nFrench positive. Speciﬁcally, for each product category music, DVDs, and books an equal number\nof reviews from each subgroup was sampled to construct datasets that prevent any language or\nsentiment bias. This approach resulted in 31,880 balanced reviews for music, 18,716 for DVDs,\nand 65,740 for books. By concatenating these uniformly sampled subgroups, we ensured that our\ndataset facilitated a fair and nuanced analysis of model performance across diﬀerent languages and\nsentiments.\n5.3\nHyperparameter Tuning with Optuna\nTo optimize our machine learning models, we utilized Optuna [28], an open-source library that\nautomates hyperparameter tuning via Bayesian optimization. We deﬁned speciﬁc hyperparameters\nfor tuning: for SVM, the penalty parameter C and kernel type; and Naive Bayes, the smoothing\nparameter alpha. Each conﬁguration’s eﬀectiveness was measured by its cross-validation accuracy.\nUsing Optuna’s TPE (Tree-structured Parzen Estimator) method, we conducted 25 trials, each\ntesting diﬀerent parameter combinations with 5-fold cross-validation. All trials consistently yielded\nan accuracy of about 0.5039, suggesting a performance plateau. This uniformity hints that the\ndefault hyperparameters might be near-optimal for our dataset. Therefore, in our model, we used\ndefault parameters.\n5.4\nFairlearn\nTo evaluate the fairness of our sentiment analysis models (SVM and Naive Bayes) across English\nand French the Fairlearn library was used, a toolkit used to help assess and improve the fairness of\ntheir models [16]. Manipulation of the dataset was needed to allow Fairlearn to work speciﬁcally,\nsetting binary classiﬁcation for each sentiment representing positive as 1 and negative as 0 and\nsetting the sensitive features as languages.\nBelow are the key metrics used in our research to\n9\ndetermine bias [19].\n5.4.1\nDemographic Parity Diﬀerence (DPD)\nDemographic Parity Diﬀerence measures the diﬀerence in selection rates between the most and\nleast favored groups [21]. In terms of sentiment analysis, it assesses whether both positive and\nnegative sentiments are equally represented across languages. The Demographic Parity Diﬀerence\nis given by the formula [20, 16]:\nDPD = |P+|A −P+|B|\n(1)\nP+|A and P+|B represents the selection rates of positive sentiment classiﬁcation for English (A)\nand French (B). In the context of our sentiment analysis, selection rate refers to the proportion of\nreviews classiﬁed as positive by the model. Where in fair data the DPD is close to zero while unfair\ndata DPD is signiﬁcantly greater than zero.\n5.4.2\nEqualized Odds Diﬀerence (EOD)\nEqualized Odds Diﬀerence evaluates the model’s fairness by comparing both true positive rates\n(TPR) and false positive rates (FPR) across groups [20]. It ensures that the model’s ability to\ncorrectly identify sentiment is consistent across diﬀerent languages. The Equalized Odds Diﬀerence\ncan be calculated as [20, 16]:\nEOD = max(|TPRA −TPRB|, |FPRA −FPRB|)\n(2)\nTPRA and TPRB denote the true positive rates for English (A) and French (B), respectively,\nreﬂecting the proportion of positive sentiments correctly identiﬁed by the model. Similarly, FPRA\nand FPRB represent the false positive rates for English and French, indicating the proportion of\n10\nnegative sentiments incorrectly classiﬁed as positive. Where EOD is close to zero suggests true\npositive and false positive rates are similar, meanwhile EOD greater than zero indicates a disparity\nin true positive or false positive rates.\n5.4.3\nEqualized Odds Ratio (EOR)\nThis metric is similar to Equalized Odds Diﬀerence but uses ratios instead of diﬀerences. Equal-\nized Odds Ratio is determined by the equation [16]:\nEOR = min\n\u0012TPRA\nTPRB\n, TPRB\nTPRA\n\u0013\n× min\n\u0012FPRA\nFPRB\n, FPRB\nFPRA\n\u0013\n(3)\nWhere fair data has the EOR close to one as both true and false positive rates are similar across\ngroups and unfair data, has a score diﬀerent than one indicating disparities.\n5.4.4\nDemographic Parity Ratio (DPR)\nDemographic Parity Ratio assesses the ratio of selection rates between groups, providing a\nscale-invariant measure of equity in terms of representation across languages. The Demographic\nParity Ratio is expressed as [16]:\nDPR = min(P+|A, P+|B)\nmax(P+|A, P+|B)\n(4)\nFair data in DPR have a score close to one while, unfair data DPR deviates from one.\n5.5\nFeature Selection\nTo enhance the sentiment analysis process, we utilized Term Frequency-Inverse Document Fre-\nquency (TF-IDF) as our feature engineering technique. TF-IDF serves as a measure to evaluate\nthe importance of a word to a document within a corpus, balancing the term frequency against the\nword’s document frequency across the corpus [18, 22].\n11\nTerm Frequency (TF) for a term t in a document d is calculated as:\nTF(t, d) = Number of times term t appears in document d\nTotal number of terms in document d\n(5)\nInverse Document Frequency (IDF) for a term t across a set of documents D is given by:\nIDF(t, D) = log\n\u0012\nTotal number of documents D\nNumber of documents containing term t\n\u0013\n(6)\nConsequently, TF-IDF is computed as the product of TF and IDF:\nTF −IDF(t, d, D) = TF(t, d) × IDF(t, D)\n(7)\nThis method reduces the weight of terms that occur frequently across the dataset, emphasizing\nterms that are critical to the speciﬁc document’s context. We leveraged the TF-IDF vectorizer\nimplementation in the Python Scikit-learn library [17] to transform our textual data into a machine\nlearning format. This transformation is pivotal for the application of SVM and Naive Bayes models,\nenabling a reﬁned analysis of sentiment within English and French product reviews.\n5.6\nApplication of Naive Bayes and Support Vector Machine\nTo address our research questions, we applied the Naive Bayes and Support Vector Machine\n(SVM) models, leveraging their respective mathematical frameworks to classify sentiments within\nour dataset. The implementation of these models was conducted using the Scikit-learn library [17],\nwhich provided robust tools for machine learning in Python.\nIn line with conventional data science practices and the Pareto Principle, which states that 80%\nof outcomes can often be attributed to 20% of causes, we allocated 80% of our dataset for training\nthe models and the remaining 20% for testing. This split was facilitated by the train test split\n12\nfunction from Scikit-learn [17], ensuring a balanced representation of English and French reviews\nin both the training and testing sets. The evaluation of the models was conducted on the test set,\nensuring that our ﬁndings reﬂect the performance capabilities of the models.\n5.6.1\nApplication of Naive Bayes\nNaive Bayes classiﬁes reviews based on the probability of sentiment classes conditioned on the\nfeature set. The classiﬁcation decision is made by [24]:\nˆy = arg max\nc∈C P(c)\nn\nY\ni=1\nP(fi|c)\n(8)\nwhere ˆy is the predicted sentiment class for a review, C is the set of classes (positive, negative),\nP(c) is the prior probability of class c, and P(fi|c) is the probability of feature i given class c.\nFeatures are represented as TF-IDF values derived from the text.\n5.6.2\nApplication of Support Vector Machine (SVM)\nSVM was employed to construct a hyperplane in a high-dimensional space that separates the\nclasses [23]. The decision function for a linear SVM is formulated as:\nf(x) = wT x + b\n(9)\nwhere x is the input feature vector (TF-IDF values), w is the weight vector, and b is the bias. The\nclass is determined by the sign of f(x).\nEach model was trained and evaluated independently on the balanced dataset comprising En-\nglish and French reviews. This approach allows us to assess the eﬃcacy and fairness of each model\nin sentiment classiﬁcation, directly contributing to our investigation of language biases.\n13\n6\nResults\nWe evaluated the models across three datasets comprising multilingual reviews in the domains\nof music, DVDs, and books, with totals of 31,880, 18,716, and 65,560 reviews, respectively.\n6.0.1\nSupport Vector Machine (SVM)\nPerformance Metrics:\nThe SVM model demonstrated notable accuracy across all datasets,\nwith a particular inclination towards higher performance in the French subset.\nDataset\nAccuracy\nPrecision\nRecall\nF1-Score\nMusic Overall\n0.888\n0.89\n0.89\n0.89\nMusic (English)\n0.859\n0.86\n0.86\n0.86\nMusic (French)\n0.918\n0.92\n0.92\n0.92\nDVDs Overall\n0.859\n0.86\n0.86\n0.86\nDVDs (English)\n0.854\n0.85\n0.85\n0.85\nDVDs (French)\n0.864\n0.86\n0.86\n0.86\nBooks Overall\n0.875\n0.88\n0.88\n0.88\nBooks (English)\n0.861\n0.86\n0.86\n0.86\nBooks (French)\n0.889\n0.89\n0.89\n0.89\nTable 1: SVM Model Performance Metrics:\nFairness Evaluation\nThe fairness of the SVM model was evaluated across three datasets: Music,\nDVDs, and Books. Signiﬁcant disparities in fairness metrics, particularly in the music dataset,\nindicate a bias where French is favored over English. This is highlighted by the lower Equalized\nOdds Ratio, suggesting that positive and negative classes are not treated equally across languages.\nDataset\nDemographic Parity Ratio\nEqualized Odds Ratio\nMusic\n0.962\n0.528\nDVDs\n0.990\n0.877\nBooks\n0.985\n0.814\nTable 2: SVM Fairness Ratios Across Datasets\n14\nDataset\nDemographic Parity Diﬀerence\nEqualized Odds Diﬀerence\nMusic\n0.019\n0.074\nDVDs\n0.005\n0.020\nBooks\n0.008\n0.029\nTable 3: SVM Fairness Diﬀerences Across Datasets\n6.0.2\nNaive Bayes\nPerformance Metrics:\nThe Naive Bayes model similarly favored the French language subset in\nterms of accuracy and exhibited more bias. The observed higher performance in French reviews\ncan be attributed to possibly more nuanced understanding and processing of French emotional\nexpressions and idiomatic language that the training data may better represent.\nDataset\nAccuracy\nPrecision\nRecall\nF1-Score\nMusic Overall\n0.863\n0.86\n0.86\n0.86\nMusic (English)\n0.838\n0.85\n0.84\n0.84\nMusic (French)\n0.889\n0.89\n0.89\n0.89\nDVDs Overall\n0.855\n0.86\n0.86\n0.86\nDVDs (English)\n0.845\n0.85\n0.85\n0.85\nDVDs (French)\n0.865\n0.87\n0.87\n0.87\nBooks Overall\n0.855\n0.86\n0.86\n0.86\nBooks (English)\n0.837\n0.84\n0.84\n0.84\nBooks (French)\n0.873\n0.87\n0.87\n0.87\nTable 4: Naive Bayes Model Performance Metrics\nFairness Evaluation:\nDisparities were evident in the fairness metrics for Naive Bayes, particu-\nlarly in the music dataset, The Demographic Parity Ratio and Equalized Odds Ratio indicate bias\nin favor of French reviews.\nDataset\nDemographic Parity Ratio\nEqualized Odds Ratio\nMusic\n0.813\n0.352\nDVDs\n0.908\n0.590\nBooks\n0.962\n0.670\nTable 5: Naive Bayes Fairness Ratios Across Datasets\n15\nDataset\nDemographic Parity Diﬀerence\nEqualized Odds Diﬀerence\nMusic\n0.107\n0.153\nDVDs\n0.047\n0.072\nBooks\n0.020\n0.062\nTable 6: Naive Bayes Fairness Diﬀerences Across Datasets\n7\nDiscussion\n7.1\nAnalysis of Model Performance and Language Bias\nOur evaluation of the Support Vector Machine (SVM) and Naive Bayes models across multilin-\ngual sentiment analysis tasks reveals a pattern of bias showing the models favor French over English.\nFor instance, the SVM model’s performance on French datasets consistently outperforms its En-\nglish counterparts in accuracy across all three categories. Speciﬁcally, the SVM model achieved\nan accuracy of 0.918, 0.864, and 0.889 for French datasets compared to 0.859, 0.854, and 0.861\naccuracy for English, indicating a bias towards the French language.\nSimilarly, the Naive Bayes model exhibits this language preference with accuracy in French\noutperforming its English counterpart.\n(Table 4) As French datasets achieved an accuracy of\n0.889, 0.865, and 0.873, while the corresponding English accuracy was 0.838, 0.845, and 0.837.\n7.2\nFairness Metrics and Model Equity\n7.2.1\nSVM Model Fairness Evaluation\nThe fairness evaluation metrics provided by Fairlearn for the SVM model highlight areas of\nconcern, as reﬂected in Tables 2 and 3. These metrics provide insights into the fairness of sentiment\nclassiﬁcation across diﬀerent languages.\n• Demographic Parity Ratio (DPR): According to Table 2, the DPR values suggest that\nthe SVM model distributes positive sentiment classiﬁcations relatively equally across language\ngroups, with values being 0.962 for music, 0.990 for DVDs, and 0.985 for books. This indicates\n16\na degree of equity in the model’s outcome distribution across languages.\n• Equalized Odds Ratio (EOR): However, the EOR values deviate from the ideal value\nof 1.0, indicating disparities in the model’s accuracy for identifying true and false positives\namong diﬀerent languages. The EOR for music is particularly low at 0.528, which contrasts\nwith higher values for DVDs and books at 0.877 and 0.814, respectively. This suggests that\nthe model’s performance is less consistent and reliable when predicting sentiments in music\nreviews as compared to other categories.\n• Demographic Parity Diﬀerence (DPD) and Equalized Odds Diﬀerence (EOD): As\ndetailed in Table 3, the DPD and EOD metrics also support the observed disparities. For\nmusic, the DPD is 0.019 and the EOD is 0.074, both indicating slight discrepancies in fairness,\nalbeit relatively lower than what might be expected given the diﬀerences in EOR. For DVDs\nand books, these values are even smaller, demonstrating greater fairness in those domains.\nDiscussion on SVM Model’s Bias\nThe disparity in fairness metrics, especially the lower EOR\nin music reviews, points to potential biases in the model’s ability to process and analyze sentiments\nequitably across languages. This could be due to a variety of factors, including, the nature of the\ntraining data, the model’s sensitivity to speciﬁc linguistic features prevalent in one language but\nnot in another, and the cultural nuances captured in the training dataset.\n7.2.2\nNaive Bayes Model Fairness Evaluation\nThe fairness evaluation of the Naive Bayes model demonstrates pronounced biases, as indicated\nby the metrics provided in Tables 5 and 6. These metrics particularly highlight the model’s tendency\nto favor French over English, especially evident in the music dataset.\n• Demographic Parity Ratio (DPR): The DPR for the music dataset stands signiﬁcantly\n17\nlower at 0.813 compared to DVDs at 0.908 and books at 0.962. This drop suggests a bias in\ndistributing positive sentiment classiﬁcations, with a stark bias in the music domain.\n• Equalized Odds Ratio (EOR): The EOR for music is notably low at 0.352, pointing to\nsubstantial disparities in accuracy for true and false positives between languages. This ﬁgure\nis considerably lower than those for DVDs and books, which are 0.590 and 0.670, respectively,\nindicating compromised classiﬁcation capabilities when analyzing music reviews.\n• Demographic Parity Diﬀerence (DPD) and Equalized Odds Diﬀerence (EOD): As\nshown in Table 6, both DPD and EOD metrics for the music dataset are the highest among\nthe datasets at 0.107 and 0.153 respectively.\nThese values highlight greater disparities in\nfairness, underscoring the model’s unfairness in sentiment predictions for music compared to\nother domains.\nDiscussion on Naive Bayes Model’s Bias\nThe biases observed in the Naive Bayes model,\nparticularly within music reviews, can be attributed to several factors. Music reviews often contain\nnuanced expressions inﬂuenced by cultural speciﬁcs, potentially underrepresented in the training\ndata. This can lead the model to more eﬀectively recognize sentiment patterns in one language\nover another. Moreover, the prevalence of slang and idiomatic expressions in music reviews can\nexacerbate biases if the model’s training data does not equally represent these linguistic features\nacross languages.\n7.3\nDiscussion on Music Reviews\nAs seen with Table 2, Table 3, Table 5, and Table 6, music has a lower DPR, EOR, and a higher\nDPD and EOD, compared to DVDs and Books fairness metrics. This variation can be attributed\nto several factors related to language use in music reviews:\n18\n• Use of Slang and Idiomatic Expressions: Music reviews often contain slang and id-\niomatic expressions, reﬂecting an informal and colloquial tone.\nFor instance, an English\nreview mentions, ”Ludacris is the epitome of the sexual hypocrisy that plagues men,” using\nthe slang ”h-o” to engage with cultural and social commentary. Similarly, a French review\nsubtly critiques with phrases like ”Ringard, qui esrt ringard si ce n’est que la personne qui\ndonne une appr´eciation si Pitoyable,” indicating a nuanced use of language. If the models’\ntraining datasets are richer in such expressions for one language over another, this could sig-\nniﬁcantly inﬂuence performance. Given the cultural prominence of French music in certain\ngenres, French reviews might deploy a set of commonly used expressions that are eﬀectively\ncaptured during the training process, as seen in our dataset where music reviews are notably\nmore expressive than book and CD reviews in English.\n• Cultural Speciﬁcity in Language Use: The expression of sentiments in music reviews\nvaries markedly between cultures. French music reviews might exhibit more uniform language\npatterns, as seen in critiques like, ”un disque sans direction avec d’´enormes boulettes,” which\nmay align well with models trained to detect such consistent patterns. Conversely, English\nmusic reviews display a broader variety of styles, such as ”This mess is ridiculous. I wouldn’t\neven want to hear this garbage in the klub let alone banging in my car,” which could dilute a\nmodel’s ability to consistently recognize sentiments. This variation in sentiment recognition is\naligned with ﬁndings suggesting that expressivity in music not only includes universal auditory\ncues but also cultural-speciﬁc cues that result from cultural conventions, thereby impacting\nhow sentiment analysis models interpret these expressions across diﬀerent languages [35].\nThese insights highlight the complex interplay between linguistic expression and cultural context\nin sentiment analysis models, particularly in the domain of music reviews where personal and\ncultural sentiments are strongly intertwined.\n19\n7.4\nPotential Reasons for French Performance\nOne explanation for the better performance of models on French datasets could be attributed\nto the linguistic and textual features present in the French language data. It is conceivable that\nFrench text used in the datasets contains clearer sentiment indicators or less ambiguous language,\npotentially due to the linguistic structure or the nature of the expressions used in sentiment ex-\npression. Meanwhile English is more ambiguous by nature. This linguistic characteristic might\ninherently lend itself to more accurate sentiment classiﬁcation by machine learning models [25].\nAdditionally, the training process might favor French due to the quality and representation of\nfeatures extracted during model training. If French language data in the training set has features\nthat are more discriminative for sentiment analysis, this could lead to models being better tuned\nfor French sentiment classiﬁcation.\nIt is also possible that the pre-processing steps or feature\nengineering techniques employed in this study were more aligned with the nuances of French text,\nenhancing model performance on these datasets.\n8\nLimitations\nThis research sheds light on language biases in sentiment analysis but comes with limitations.\nThe study focuses on datasets from music, DVDs, and book reviews, which may not reﬂect ﬁndings\napplicable to other textual formats or domains. Additionally, it examines only SVM and Naive\nBayes models, limiting the breadth of our insights into language biases.\nFurthermore, our reliance on Fairlearn for fairness metrics, though eﬀective, does not cover\nall fairness considerations in NLP. Alternative metrics or evaluation methods could unveil biases\nnot detected in this analysis. Moreover, we applied uniform feature extraction and pre-processing\nacross languages, ignoring the unique linguistic traits of each language that might aﬀect model\nperformance.\n20\nLastly, this research faced several computational constraints that limited our ability to explore\nmore sophisticated analytical techniques. Notably, the use of GridSearchCV for hyperparameter\noptimization was deemed infeasible due to our limited computational resources, which may have\nhindered our ability to reﬁne and optimize the SVM and Naive Bayes models. Additionally, the\ncomputational demands of advanced pre-processing techniques restricted their application within\nour study. This limitation was signiﬁcant as more reﬁned pre-processing could enhance the accuracy\nof sentiment analysis by better capturing the nuances of language used in reviews. Furthermore, our\ncomputational setup did not support scalability tests or the deployment of models in a real-time\nanalysis environment, which restricts the generalizability of our ﬁndings to larger or real-world\napplications. These computational limitations underscore the need for future research equipped\nwith greater computational capabilities to fully explore and possibly overcome these constraints.\n9\nConclusion\nThe expansion of multilingual datasets in Natural Language Processing (NLP) brings both\nopportunities and challenges. This study underlines the necessity of balanced datasets for equitable\nlanguage performance. We discovered that linguistic features and dataset composition signiﬁcantly\ninﬂuence model outcomes, exposing gaps that need targeted interventions.\nNotably, performance disparities between French and English demonstrate prevalent language\nbiases in NLP models, emphasizing the need to reﬁne training and evaluation methodologies to\naccommodate linguistic diversity better. As more comprehensive datasets become available, it is\ncrucial to conduct comparative tests between monolingual and multilingual models. Such testing\ncould reveal the strengths and limitations of each approach, guiding more eﬀective strategies for\naddressing language-speciﬁc nuances that multilingual models often overlook.\nEnsuring fairness and equity in NLP is paramount as the ﬁeld evolves. We must guarantee\n21\nequitable access to resources for low-resource languages to achieve fair treatment across linguistic\nboundaries. This study contributes to ongoing eﬀorts to equalize linguistic representation in NLP,\nadvocating for technology that equally beneﬁts all users. By focusing on monolingual models and\nrigorous testing against their multilingual counterparts, we can enhance the precision and fairness\nof NLP applications.\n10\nAppendix\nThe complete code base for the model is accessible at: https://github.com/ethanwongca/COMP396.\n22\nReferences\n[1] Government of Canada, S. C., Schinck, M.-P., Jang, E., & L´evesque, J.-C. (2022, June 21). Bias\nConsiderations in Bilingual Natural Language Processing. Statistics Canada; Statistics Canada.\nhttps://www.statcan.gc.ca/en/data-science/network/language-processing\n[2] Hovy, D., & Prabhumoye, S. (2021). Five Sources of Bias in Natural Language Processing.\nLanguage and Linguistics Compass, 15(8). https://doi.org/10.1111/lnc3.12432\n[3] Dashtipour, K., Poria, S., Hussain, A. et al. Multilingual Sentiment Analysis:\nState of\nthe Art and Independent Comparison of Techniques. Cogn Comput 8, 757–771 (2016).\nhttps://doi.org/10.1007/s12559-016-9415-7\n[4] Vaswani,\nA.,\nShazeer,\nN.,\nParmar,\nN.,\nUszkoreit,\nJ.,\nJones,\nL.,\nGomez,\nA.\nN.,\nKaiser,\n L.,\n&\nPolosukhin,\nI.\n(2017).\nAttention\nis\nAll\nyou\nNeed.\nNeural\nInformation\nProcessing\nSystems;\nCurran\nAssociates,\nInc.\nhttps://papers.nips.cc/paper ﬁles/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-\nAbstract.html\n[5] Liu, C., Gao, C., Xia, X., Lo, D., Grundy, J., & Yang, X. (2022). On the Reproducibility\nand Replicability of Deep Learning in Software Engineering. ACM Transactions on Software\nEngineering and Methodology, 31(1), 1–46. https://doi.org/10.1145/3477535\n[6] Ruder, S., Vuli´c, I., & Søgaard, A. (2019). A Survey of Cross-lingual Word Embedding Models.\nJournal of Artiﬁcial Intelligence Research, 65(1), 569–631. https://doi.org/10.1613/jair.1.11640\n[7] Hu, R., Rui, L., Zeng, P., Chen, L., & Fan, X. (2018). Text Sentiment Analysis:\nA Re-\nview. 2018 IEEE 4th International Conference on Computer and Communications (ICCC).\nhttps://doi.org/10.1109/compcomm.2018.8780909\n[8] Goel, A., Gautam, J., & Kumar, S. (2016). Real time sentiment analysis of tweets using\nNaive Bayes. 2016 2nd International Conference on next Generation Computing Technologies\n(NGCT), 257–261. https://doi.org/10.1109/NGCT.2016.7877424\n[9] Alves, A. L. F., Baptista, C. de S., Firmino, A. A., Oliveira, M. G. de, & Paiva, A. C. de.\n(2014). A Comparison of SVM Versus Naive-Bayes Techniques for Sentiment Analysis in Tweets.\nProceedings of the 20th Brazilian Symposium on Multimedia and the Web - WebMedia ’14,\n123–130. https://doi.org/10.1145/2664551.2664561\n[10] Wongkar, M., & Angdresey, A. (2019). Sentiment Analysis Using Naive Bayes Algorithm Of\nThe Data Crawler: Twitter. 2019 Fourth International Conference on Informatics and Com-\nputing (ICIC), 1–5. https://doi.org/10.1109/ICIC47613.2019.8985884\n[11] Zainuddin, N., & Selamat, A. (2014). Sentiment analysis using Support Vector Machine.\n2014 International Conference on Computer, Communications, and Control Technology (I4CT).\nhttps://doi.org/10.1109/i4ct.2014.6914200\n[12] Hasanli,\nH.,\n& Rustamov,\nS.\n(2019).\nSentiment\nAnalysis\nof\nAzerbaijani\ntwits\nUs-\ning Logistic Regression,\nNaive Bayes and SVM. 2019 IEEE 13th International Con-\nference on Application of Information and Communication Technologies (AICT), 1–7.\nhttps://doi.org/10.1109/AICT47866.2019.8981793\n23\n[13] Boiy, E., & Moens, M.-F. (2008). A machine learning approach to sentiment analysis in multi-\nlingual Web texts. Information Retrieval, 12(5), 526–558. https://doi.org/10.1007/s10791-008-\n9070-z\n[14] Prettenhofer, P., & Stein, B. (2010). Webis Cross-Lingual Sentiment Dataset 2010 (Webis-CLS-\n10) [Data set]. 48th Annual Meeting of the Association of Computational Linguistics (ACL 10).\nZenodo. https://doi.org/10.5281/zenodo.3251672\n[15] Schmitt, X., Kubler, S., Robert, J., Papadakis, M., & LeTraon, Y. (2019). A Replicable\nComparison Study of NER Software: StanfordNLP, NLTK, OpenNLP, SpaCy, Gate. 2019 Sixth\nInternational Conference on Social Networks Analysis, Management and Security (SNAMS).\nhttps://doi.org/10.1109/snams.2019.8931850\n[16] Bird, S., Diduk, M., Edgar, R., Horn, B., Lutz, R., Milan, V., Sameki, M., Wallach, H., &\nWalker, K. (2020). Fairlearn: A toolkit for assessing and improving fairness in AI. Microsoft.\n[17] Pedregosa, F., Varoquaux, G., Gramfort , A., Michel, V., Thirion, B., Grisel, O., Blondel, M.,\nMuller, A., Nothman, J., Louppe, G., Prettenhofer, P., Weiss , R., Dubourg , V., Vanderplas,\nJ., Passos, A., Cournapeau , D., Brucher , M., Perrot, M., & Duchesnay, E. (2011). Scikit-\nlearn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825–2830.\nhttps://doi.org/10.48550/arXiv.1201.0490\n[18] Shi, H.-X., & Li, X.-J. (2011). A sentiment analysis model for hotel reviews based on\nsupervised learning. 2011 International Conference on Machine Learning and Cybernetics.\nhttps://doi.org/10.1109/icmlc.2011.6016866\n[19] Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A Sur-\nvey on Bias and Fairness in Machine Learning. ACM Computing Surveys, 54(6), 1–35.\nhttps://doi.org/10.1145/3457607\n[20] Hardt, M., Price, E., & Srebro, N (2016). Equality of Opportunity in Supervised Learning.\nProceedings of the 30th International Conference on Neural Information Processing Systems\n(NIPS), 3323–3331. https://doi.org/10.48550/arXiv.1610.0241\n[21] Dwork, C., Hardt, M., Pitassi, T., Reingold, O., & Zemel, R. (2012). Fairness through aware-\nness. Proceedings of the 3rd Innovations in Theoretical Computer Science Conference on - ITCS\n’12, 214–226. https://doi.org/10.1145/2090236.2090255\n[22] Salton, G., & McGill, M. J. (1983). Introduction to Modern Information Retrieval. McGraw-\nHill\n[23] Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20(3), 273-297.\n[24] Manning, C. D., Raghavan, P., & Sch¨utze, H. (2008). Introduction to Information Retrieval.\nCambridge University Press.\n[25] Ghorbel, H., & Jacot, D. (2011). Sentiment Analysis of French Movie Reviews. In: Pallotta,\nV., Soro, A., Vargiu, E. (eds) Advances in Distributed Agent-Based Retrieval Tools. Studies in\nComputational Intelligence, vol 361. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-\n3-642-21384-7 7\n24\n[26] Levy, S., John, N., Liu, L., Vyas, Y., Ma, J., Fujinuma, Y., Ballesteros, M., Castelli, V., &\nRoth, D. (2023). Comparing Biases and the Impact of Multilingual Training across Multiple\nLanguages. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language\nProcessing, pages 10260–10280, Singapore. Association for Computational Linguistics.\n[27] Goldfarb-Tarrant, S., Ross, B., & Lopez, A. (2023). Cross-lingual Transfer Can Worsen Bias\nin Sentiment Analysis. In Proceedings of the 2023 Conference on Empirical Methods in Natural\nLanguage Processing, pages 5691–5704, Singapore. Association for Computational Linguistics.\n[28] Akiba, T., Sano, S., Yanase, T., Ohta, T., & Koyama, M. (2019). Optuna:\nA Next-\ngeneration Hyperparameter Optimization Framework. In Proceedings of the 25th ACM\nSIGKDD International Conference on Knowledge Discovery & Data Mining - KDD ’19.\nhttps://doi.org/10.1145/3292500.3330701\n[29] Turney, P. D. (2002). Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsu-\npervised Classiﬁcation of Reviews. Journal of Artiﬁcial Intelligence Research, 20, 417-440.\n[30] Liu, B. (2012). Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Lan-\nguage Technologies, 5(1), 1-167. Morgan & Claypool Publishers.\n[31] Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment Classiﬁcation using\nMachine Learning Techniques. In Proceedings of the ACL-02 conference on Empirical meth-\nods in natural language processing - EMNLP ’02, pages 79-86, Philadelphia, Pennsylvania.\nAssociation for Computational Linguistics.\n[32] Tong, S., & Koller, D. (2001). Support Vector Machine Active Learning with Applications to\nText Classiﬁcation. Journal of Machine Learning Research, 2, 45-66.\n[33] Liu, C. & Hwa, R. (2016). Phrasal Substitution of Idiomatic Expressions. In Proceedings of\nthe 2016 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages 363–373, San Diego, California.Association\nfor Computational Linguistics.\n[34] Laukka, P., Eerola, T., Thingujam, N. S., Yamasaki, T., & Beller, G. (2013). Universal and\nculture-speciﬁc factors in the recognition and performance of musical aﬀect expressions. Emo-\ntion, 13(3), 434-449.\n[35] Kwoun, S.-J. (2009). An examination of cue redundancy theory in cross-cultural decoding of\nemotions in music. Journal of music therapy, 46(3), 217-37.\n25\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2024-05-07",
  "updated": "2024-05-07"
}