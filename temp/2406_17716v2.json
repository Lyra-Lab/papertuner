{
  "id": "http://arxiv.org/abs/2406.17716v2",
  "title": "ViANLI: Adversarial Natural Language Inference for Vietnamese",
  "authors": [
    "Tin Van Huynh",
    "Kiet Van Nguyen",
    "Ngan Luu-Thuy Nguyen"
  ],
  "abstract": "The development of Natural Language Processing (NLI) datasets and models has\nbeen inspired by innovations in annotation design. With the rapid development\nof machine learning models today, the performance of existing machine learning\nmodels has quickly reached state-of-the-art results on a variety of tasks\nrelated to natural language processing, including natural language inference\ntasks. By using a pre-trained model during the annotation process, it is\npossible to challenge current NLI models by having humans produce\npremise-hypothesis combinations that the machine model cannot correctly\npredict. To remain attractive and challenging in the research of natural\nlanguage inference for Vietnamese, in this paper, we introduce the adversarial\nNLI dataset to the NLP research community with the name ViANLI. This data set\ncontains more than 10K premise-hypothesis pairs and is built by a continuously\nadjusting process to obtain the most out of the patterns generated by the\nannotators. ViANLI dataset has brought many difficulties to many current SOTA\nmodels when the accuracy of the most powerful model on the test set only\nreached 48.4%. Additionally, the experimental results show that the models\ntrained on our dataset have significantly improved the results on other\nVietnamese NLI datasets.",
  "text": "Springer Nature 2021 LATEX template\nViANLI: Adversarial Natural Language\nInference for Vietnamese\nTin Van Huynh1,2, Kiet Van Nguyen1,2* and Ngan Luu-Thuy\nNguyen1,2\n1University of Information Technology, Ho Chi Minh City,\nVietnam.\n2Vietnam National University, Ho Chi Minh City, Vietnam.\n*Corresponding author(s). E-mail(s): kietnv@uit.edu.vn;\nContributing authors: tinhv@uit.edu.vn; ngannlt@uit.edu.vn;\nAbstract\nThe development of Natural Language Processing (NLI) datasets and\nmodels has been inspired by innovations in annotation design. With the\nrapid development of machine learning models today, the performance\nof existing machine learning models has quickly reached state-of-the-\nart results on a variety of tasks related to natural language processing,\nincluding natural language inference tasks. By using a pre-trained model\nduring the annotation process, it is possible to challenge current NLI\nmodels by having humans produce premise-hypothesis combinations\nthat the machine model cannot correctly predict. To remain attrac-\ntive and challenging in the research of natural language inference for\nVietnamese, in this paper, we introduce the adversarial NLI dataset\nto the NLP research community with the name ViANLI. This data\nset contains more than 10K premise-hypothesis pairs and is built by a\ncontinuously adjusting process to obtain the most out of the patterns\ngenerated by the annotators. ViANLI dataset has brought many diffi-\nculties to many current SOTA models when the accuracy of the most\npowerful model on the test set only reached 48.4%. Additionally, the\nexperimental results show that the models trained on our dataset have\nsignificantly improved the results on other Vietnamese NLI datasets.\nKeywords: Adversarial dataset, natural language inference, pre-trained\nmodels\n1\narXiv:2406.17716v2  [cs.CL]  1 Jul 2024\nSpringer Nature 2021 LATEX template\n2\nTin et al.\n1 Introduction\nNatural language inference (NLI) is a complex reasoning task in natural lan-\nguage processing (NLP), playing a crucial role in deciphering the context\nand meaning of linguistic structures. NLI enables computer systems to assess\nwhether one sentence can logically infer another sentence [1]. For instance,\nthe sentence \"It is raining\" can be inferred as \"The road will be wet\". There-\nfore, NLI is fundamental in enhancing contextual understanding in various\nNLP systems, ranging from automated question-answering systems [2–4] to\nmachine translation technologies [5, 6], and text summarization [7, 8].\nNeural networks against adversarial samples [9–11] have been explored as\nan active topic in natural language processing. SOTA NLI models [10, 11] can\nbe easily defeated by adversarial examples, which are specifically designed sen-\ntences meant to lead the model to produce erroneous results. These weaknesses\nnot only impact the reliability of the model in practice, but also raise questions\nabout the theoretical foundations and operational principles of NLI models.\nFurthermore, as these models are increasingly deployed in high-stakes, real-\nworld settings [12, 13], there is an increasing demand to examine their capacity\nto generalize and handle inputs that are complex, ambiguous, or intentionally\nmisleading. In response to this need, adversarial NLI datasets have been intro-\nduced to stress-evaluate these models. This can also be considered a sub-field\nof NLI research aimed at enhancing the reliability and robustness of NLI mod-\nels. Traditional NLI datasets often focus on transparent data samples where\nthe relationships between sentences are very straightforward [1]. In contrast,\nadversarial NLI datasets contain intentionally challenging examples designed\nto expose model weaknesses, such as minor changes in phrasing that can lead\nto misclassifications [10, 11]. Identifying these vulnerabilities and blind spots\nallows researchers to iteratively improve the models, making them more robust\nand reliable [14].\nWe observe that research in developing adversarial NLI datasets has\nfocused primarily on English [10] or widely studied languages such as Chinese\n[15], while the number of studies for low-resource languages is limited. For\nVietnamese, the NLP research community has seen significant progress with\nthe release of datasets such as ViNLI [16], VnNewsNLI [17], and VLSP 2021 -\nvnNLI Challenge [18]. However, these data sets have been constructed using\ntraditional procedures with an emphasis on data quality, but they have paid\nlimited attention to the adversarial aspect.\nWe fully comprehend the significance of adversarial datasets in substan-\ntially enhancing models’ reliability and robustness while posing new challenges\nand research directions. Therefore, in this paper, we construct an adversar-\nial NLI dataset for the Vietnamese language. Taking inspiration from the\nhuman-and-model-in-the-loop procedure — a trusted approach for construct-\ning adversarial datasets that created the AdversarialNLI [10], FEVER2.0 [19],\nand AdversarialQA [20] datasets in English — we propose to develop a similar\nadversarial NLI resource for Vietnamese. Incorporating a human-and-model-\nin-the-loop procedure in building Vietnamese adversarial NLI data offers\nSpringer Nature 2021 LATEX template\nTin et al.\n3\nmultiple benefits, including improved data quality through human expertise,\ndynamic model refinement through iterative feedback, and a more robust and\ngeneralizable dataset that reflects diverse linguistic challenges and real-world\nscenarios.\nIn addition, this Vietnamese Adversarial NLI dataset can also be regarded\nas a more challenging counterpart to the previous dataset, ViNLI. The three\nprimary contributions of our research in this paper are summarized as follows.\n• Firstly, we have successfully constructed an adversarial NLI dataset for\nthe Vietnamese language, consisting of more than 10K human-annotated\npremise-hypothesis pairs. This dataset holds significance for researching\nbehaviors and enhancing the performance of SOTA NLI models. Addi-\ntionally, it contributes to enriching research resources for the Vietnamese\nlanguage.\n• Secondly, we have conducted comprehensive experiments with various lan-\nguage models including mBERT, XLM-R, Info-XLM, and PhoBERT as first\nbaselines on ViANLI. XLM-RLarge could only obtain accuracy under 49%\non the development and test sets, indicating its challenge.\n• Finally, we have analyzed and evaluated the effectiveness of these models in\nvarious linguistic aspects of the data set to gain a deeper understanding of\nthe data characteristics and model performance.\nThe structure of our paper is organized as follows: Section 1 introduces\nthe context of NLI research, trends in constructing adversarial data, and the\nneed to build an adversarial NLI dataset for Vietnamese; Section 2 discusses\nthe relevant datasets and models; Section 3 describes our corpus construc-\ntion process; Section 4 analyzes basic and in-depth statistics of our dataset;\nSection 5 presents the experimental setup and results; Section 6 analyzes and\ndiscusses experimental results; Section 7 is the conclusion of the key issues in\nour research and offers some future works.\n2 Related Works\nIn recent years, extensive research has been conducted to produce adversar-\nial resources for various languages to aid in natural language inference. In\nthis section, we discuss numerous available NLI datasets (non-adversarial and\nadversarial datasets) and related models for natural language inference. Addi-\ntionally, we provide details of resources available for other languages. Lastly,\nwe elaborate on the research conducted on natural language inference using\nvarious machine learning and deep learning models.\n2.1 Related Dataset\nBased on the data collection strategy of the NLI datasets, we divide them into\nadversarial and non-adversarial datasets.\nSpringer Nature 2021 LATEX template\n4\nTin et al.\nNon-adversarial datasets Through ongoing research efforts, researchers\nhave released many datasets related to the field of Natural Language Infer-\nence (NLI). In particular, these datasets are generated using a variety of\nmethodologies and languages. This has brought many positive effects on Nat-\nural Language Understanding. In the early stages of the development of NLI\nresearch, The Recognizing Textual Entailment (RTE) Challenge, introduced\nby Dagan et al. in 2005 [21], was one of the renewed efforts aimed at formalizing\nthe evaluation of Natural Language Inference (NLI) tasks. The challenge cre-\nated a common platform and a standardized dataset that allowed researchers\nto assess the ability of computational models to recognize textual entailment.\nThis quest really exploded in 2015, when Bowman et al. published the SNLI\ndataset [1]. This is a large-scale resource introduced by researchers at Stan-\nford that contains nearly 600,000 sentence pairs. SNLI employs a unique data\ncollection method that combines crowd-sourcing with careful curation. Qual-\nity control measures were in place to ensure the reliability and consistency\nof the annotations. This methodical approach to data collection enables the\ncreation of a large-scale, high-quality dataset that has been crucial for bench-\nmarking. Therefore, SNLI is quickly considered a cornerstone in the NLI field,\nproviding a benchmark for evaluating various machine learning models’ gen-\neralization and reasoning capabilities. The MultiNLI (Multi-Genre Natural\nLanguage Inference) [22] dataset was developed to address some of the limi-\ntations of the Stanford Natural Language Inference (SNLI) dataset, including\nthe problem of the data being relatively simple and easy for advanced machine\nlearning models. The authors have revised the process of building MultiNLI\nin several ways to solve these issues, including using diverse sources, com-\nplex reasoning, multiple domains, and better annotation guidelines. MultiNLI\naims to provide a more rigorous and challenging benchmark for NLI models\nby making these improvements. This data construction method was quickly\napplied to build a series of other datasets such as OCNLI [23], IndoNLI [24],\nMedNLI [25], and ViNLI [16],VnNewsNLI [17], VLSP 2021 - vnNLI Challenge\n(VLSP2021) [18]. Also, there are some other approaches to building NLI data\nsets, such as using question and answer data to convert to NLI data sets such\nas SciTail [26], FarsTail [27], using a translator to translate NLI data from\none language to another such as XNLI [28], Hinglish [29], KorNLI [30]. Using\nthe NLI framework to label claims based on their logical relationships with\nhypotheses, researchers can create a fact-checking dataset that enables the\ndevelopment and evaluation of fact-checking models and systems. There are\nfamous fact-checking datasets created in such a way that have been published,\nsuch as FEVER [31], VITAMINC [32], and FEVEROUS [33].\nAdversarial datasets The growing trend of building adversarial datasets\nin Natural Language Processing (NLP) has been propelled by the increasing\nrealization that machine learning models, though powerful, are often suscep-\ntible to nuanced forms of data manipulation. Significant efforts are underway\nin the field of Natural Language Inference (NLI) to construct more challeng-\ning and representative datasets. That is, building adversarial datasets, one\nSpringer Nature 2021 LATEX template\nTin et al.\n5\nDataset\nNLP task\nLanguage\nText genre\nYear\nQuantity\nAdversarial\nstrategy\nFEVER [31]\nNLI, FC\nEnglish\nWikipedia\n2018\n∼185K\nNo\nFEVER2.0 [19]\nNLI, FC\nEnglish\nWikipedia\n2019\n1,174\nYes\nVITAMINC [32]\nNLI, FC\nEnglish\nWikipedia\n2021\n∼488K\nNo\nFEVEROUS [33]\nNLI, FC\nEnglish\nWikipedia\n2021\n∼87K\nNo\nSNLI [1]\nNLI\nEnglish\nImage captions\n2015\n∼570K\nNo\nMultiNLI [22]\nNLI\nEnglish\nMulti-genre\n2018\n∼433K\nNo\nOCNLI [23]\nNLI\nChinese\nMulti-genre\n2020\n∼56K\nNo\nIndoNLI [24]\nNLI\nIndonesian\nMulti-genre\n2021\n∼18K\nNo\nMedNLI [25]\nNLI\nEnglish\nMedical\n2019\n∼14K\nNo\nSciTail [26]\nNLI\nEnglish\nEducation\n2018\n∼27K\nNo\nFarsTail [27]\nNLI\nPersian\nEducation\n2021\n∼10K\nNo\nXNLI [28]\nNLI\nmulti-language\nMulti-genre\n2018\n∼129K\nNo\nHinglish [29]\nNLI\nmulti-language\nMovies scripts\n2020\n2,240\nNo\nKorNLI [30]\nNLI\nKorean\nMulti-genre\n2020\n∼950K\nNo\nAdversarialNLI [10]\nNLI\nEnglish\nMulti-genre\n2020\n∼169K\nYes\nVLSP2021 [18]\nNLI\nMulti-language\nNewswire\n2022\n∼20K\nNo\nVnNewsNLI [17]\nNLI\nVietnamese\nNewswire\n2022\n∼32K\nNo\nViNLI [16]\nNLI\nVietnamese\nNewswire\n2022\n∼30K\nNo\nViANLI (Our dataset)\nNLI\nVietnamese\nNewswire\n2023\n∼10K\nYes\nTable 1: Summary of well-known datasets related to natural language infer-\nence. NLI and FC stand for Natural Language Inference and Fact-checking,\nrespectively.\napproach involving generating adversarial examples specifically designed to\nchallenge or fool existing NLI models. Adversarial examples are meant to\nexpose the limitations and vulnerabilities of existing NLI models, thereby\naiding in their subsequent fortification. According to Bartolo et al. (2020)\n[34], there are different approaches to building adversarial datasets: i) adver-\nsarial filtering, where the adversarial model is typically implemented in an\nisolated phase, which comes after the data creation stage. Techniques include\nmanipulating input text by flipping, inserting, deleting, or swapping words\nor characters. Perturbation data is generated to be used during adversarial\ntraining. Many studies have combined this type of data with machine learning\nmodels and have achieved positive results in making the model more robust;\nworks include AdvEntuRe [35], SCPNs [36], First-Order Logic constraints [37],\nASCC [38], FreeLB [39]. In addition, on the reading comprehension task, there\nare also data sets built according to methods such as SWAG [40], HotpotQA\n[41]; ii) adversarial model-in-the-loop annotation, where both annotators and\nmachine learning models work iteratively in a cycle to create and refine adver-\nsarial examples. This approach usually starts with a model initially generating\nadversarial samples, followed by annotators reviewing, modifying, or creat-\ning new ones based on these initial examples. This method was successfully\napplied to build the famous AdversarialNLI [10] dataset, as it exploited the\nvulnerabilities of the model very well. In the question-answering task, there\nare many datasets with adversarial properties, such as DROP [42], CODAH\n[43], Quoref [44], AdversarialQA [20], Quizbowl [45]. The adversarial human-\nand-model-in-the-loop procedure is also used quickly to create fact-checking\ndatasets, which is notable for FEVER 2.0 [19] when this dataset addresses\ncertain weaknesses and limitations of the original FEVER dataset.\nSpringer Nature 2021 LATEX template\n6\nTin et al.\nWhen reviewing NLI data in Vietnamese, we realize that most of the data,\nsuch as ViNLI [16], VnNewsNLI [17], and VLSP 2021 - vnNLI Challenge [18]\nignore adversarial factors during construction. That is what prompted us to\nbuild an adversarial NLI dataset for Vietnamese. We are also particularly\ninterested in using the adversarial human-and-model-in-the-loop procedure\nto create adversarial Vietnamese datasets because humans and machines\nare involved in the data generation process. Thus, it will be fascinating\nwhen humans can discover model problems during data generation. Some\nwell-known datasets related to NLI in other languages are summarized and\ncompared by us to the Vietnamese NLI datasets in Table 1.\n2.2 Related NLI Models\nResearch topics in NLP, including NLI, have witnessed the daily development\nof machine learning models from simple models to more complex ones. The\ndiverse evolution of current machine learning models has enriched the choices\nof models for experimentation, suitable for the characteristics of different tasks\nand data domains. Moreover, as more adversarial NLI datasets emerge, the\nperformance of these models also needs to increase significantly.\nIn its early stages, probability-based models have historically laid the\ngroundwork for approaches to natural language inference and have established\na foundation long before the emergence of current deep learning techniques.\nThese models operated on the principle of computing the likelihoods of\nhypotheses given premises, often rooted in Bayesian inference [21, 46]. Latent\nSemantic Analysis (LSA) [47] uses Singular Value Decomposition (SVD) to\ncompress space and discover semantic relationships between words and docu-\nments. LSA can be used to measure the semantic similarity between a premise\nand a hypothesis [48]. CBOW (Continuous Bag of Words) and Skip-gram\nare two architectures introduced in the Word2Vec model [49] to learn vector\nword representations. Both of these techniques aim to learn word represen-\ntations that can capture semantics based on the context in which the word\nappears, and these methods have also yielded promising results on the NLI task\n[1, 16, 22–24]. Although these models offered valuable information, they often\nstruggled to capture intricate semantic relationships and nuances in language.\nThe challenges and shortcomings of these probabilistic approaches paved\nthe way for neural models, especially with the advent of deep learning. Neural\nmodels, such as Recurrent Neural Networks (RNNs) [50], Long Short-Term\nMemory Networks (LSTMs) [51], and ESIM [52], have achieved promising\nresults on NLI tasks. Recently, transformer architectures such as BERT [53]\nand GPT [54] have demonstrated an unprecedented ability to capture complex\nsemantic structures and relationships. Their capacity to represent words in\ndense vector spaces, process sequences, and utilize attention mechanisms has\nmade them exceptionally adept at tasks like NLI. In addition to these models,\na series of variant models have emerged using the BERT architecture, such\nas RoBERTa [55], XLM-R [56], XLNet [57], ALBERT [58], DistilBERT [59],\nSpringer Nature 2021 LATEX template\nTin et al.\n7\nELECTRA [60], and T5 [61], and have achieved high performance on datasets\nsuch as SNLI [1], MultiNLI [22], FEVER [31], and ANLI [10].\nBuilding upon the resounding success of previous transformer-based mod-\nels on English data, considerable efforts have been made to extend their\ncapabilities to other languages, including Vietnamese. The PhoBERT model\n[62], for example, represents a significant advance by leveraging the foun-\ndation of BERT and fine-tuning it on Vietnamese data, yielding impressive\nperformance across various tasks. Additionally, earlier models trained on mul-\ntilingual data, including Vietnamese, such as mBERT [53], XLM-R [56], mT5\n[63], and mBART [64], have also demonstrated excellent results on Vietnamese\nNatural Language Inference (NLI) tasks [16].\n3 Corpus Creation\nThis section provides a detailed description of our data-construction process.\nWe also show how we hire annotators and guide them so that they can create\nhigh-quality data as we desire. In addition, information about the source of\npremise sentences and the model used to evaluate the difficulty of premise-\nhypothesis sentence pairs in each round is also described in detail.\n3.1 Process of Adversarial Corpus Creation\nInspired by the HAMLET (Human-And-Model-in-the-Loop Enabled Training)\nprocedure [10], we build a new approach to build the AViNLI dataset. This\napproach incorporates human and machine learning models to address the\nchallenges associated with current data collection methods. However, to max-\nimize the effectiveness of the annotator’s sentence writing process, we made\nsome adjustments in the data validation phase, as shown in Figure 1.\nAt the beginning of the process, annotators receive premise sentences and\nare asked to write corresponding hypothesis sentences for each case of target\ninference labels (entailment, contradiction, neutral). In which the premise sen-\ntences are extracted from online news, which covers many different news topics.\nInspired by the approach of the ANLI dataset [10] in this sentence generation\nstep, we ask annotators to write complex hypothesis sentences in order to gen-\nerate pairs of sentences that can fool the machine learning model. Generating\ndifficult inference-level sentence pairs allows us to exploit the vulnerabilities\nof current modern machine-learning models. Therefore, it is possible to bet-\nter understand the characteristics of machine learning models. In addition to\nwriting hypothesis sentences, we also asked annotators to explain why they\nthought their generated sentences were difficult and that the model might be\nwrong.\nAfter collecting a number of premise-hypothesis sentence pairs, we use\na pre-trained machine learning model to predict inference labels for those\nsentence pairs. After that, we compare the predicted labels and the target\nlabels. There are two cases, in which pairs are correctly predicted by the model,\nSpringer Nature 2021 LATEX template\n8\nTin et al.\nwe put them in the training set, while the models that are wrongly predicted\nby the model are passed to the validation process.\nTaget Label\nWriter\n1\nPremise\nHypothesis\n1\nCompare\nPredicted Label\nModel\nCorrect\nFeedback\nModel Incorrect\nVerification 1\nAgree\nDisagree\nIf (have >=2 labels in {\nsame predicted label)== True\n,\n,\n}\nA1\nA2\nA3\nYes\nRelabel\nTrain\nDev\nTest\n2\n2\n3\n3\n3\n4\n5\n5\n4\nStep 4: Relabel examples\n1\n2\n3\n4\n5\nStep 1: Write examples\nStep 2: Get model feedback\nStep 3: Verify examples and make splits\nStep 5: Retrain model for next round\nVerification 2\nA2\nA3\nA1\nNo\nFig. 1: Overall process for the creation of the AViNLI dataset.\nIn the stage of validating false data samples, we propose two different\ncomponents named verification 1 and verification 2. The purpose of verification\n1 is to confirm with certainty that the annotators have written the correct\nhypothesis sentences with the given target labels. In verification 1, each pair\nof incorrect predictions will be relabeled by 3 other annotators. If 2 or more\nof them agree with the original author, then this sample will be considered\ngood and will be distributed to train, test, and dev sets. In addition, we have\nproposed to add a verification 2 component; the purpose of this component\nis to make the most of the samples that failed at verification 1. In case the\nsamples do not have 2 or more agree with the original author but still have 2\nor more similarities in their opinion and are the same as the prediction of the\nmodel, the original labels of these samples are converted to the labels of the\npredictive model, and then they are transferred to the training set. Otherwise,\nsamples that do not meet the conditions will be deleted. Such an approach\nSpringer Nature 2021 LATEX template\nTin et al.\n9\nmakes a lot of sense in the case where we build a dataset with a small size and\na small number of annotators.\nAt the end of a round of data generation, as described above, the data\nobtained for that round are used to train a new model which is used to make\npredictions on the data of the next round.\n3.2 Annotator Recruitment and Training\nFifteen students are participating in the ViANLI dataset generation process.\nThe students we hire are from famous universities in Vietnam. They are\nnative speakers with good language skills, enough knowledge, and awareness\nto read premise sentences and write hypothesis sentences. Similar to the ViNLI\ndataset, we built an initial guideline to teach students how to write hypothe-\nsis sentences to create hypothesis-premise adversarial pairs of sentences. They\nhave gone through at least five rounds of hypothesis writing to be able to par-\nticipate in the development of ViANLI officially. In each round, they have to\nwrite 50 hypotheses corresponding to 50 premise sentences covered on three\nlabels: entailment, contradiction, and neutral. The data completed at each\nround of annotators is manually checked by us to ask them to correct any\nerrors, and it is also time for them to practice writing their sentences. In the\nprocess of checking the data, we also constantly update and edit the guidelines\nto ensure consistency between the annotators. Besides, we use the baseline\nmodel - XLM-RLarge is the model with the highest performance on ViNLI\nto evaluate the data annotators generated in each round. We always require\nannotators to write hypotheses on a high difficulty level so that the prediction\nsuccess rate on XLM-RLarge is below 40%. We return the prediction results of\nthe model to the annotators to help them study how the model will encounter\ndifficulties with the data characteristics to improve writing for the next time.\nOnce the annotators’ data generation capabilities stabilize, we will opt-in to\nformally participate in our data-building process. At the end of this process,\nwe selected 15 students, as mentioned above. They are paid $0.025 for writing\na hypothesis.\n3.3 Round 1: ViA1 Data\nIn the first round of the data generation process, similar to the approach in the\nViNLI dataset [16], we used sentences that were extracted from news content\nas premise sentences. We collect this news from the VnExpress1 online news\nsite, which covers many different topics of news. Furthermore, we trained the\nXLM-R Model [65] on the ViNLI dataset [16], and 7,500 Vietnamese samples\nwere extracted from the XNLI dataset [28], which was then used to predict\nthe label of the data that the annotators generated in this round. The data\nobtained after the end of Round 1 is called ViA1.\n1https://vnexpress.net/\nSpringer Nature 2021 LATEX template\n10\nTin et al.\n3.4 Round 2: ViA2 Data\nIn the second round, the annotators continued to write hypothesis sentences\nbased on the content of the premise sentences, which were also collected from\nVNExpress. In particular, in this round, we used the InfoXLM model [66],\nwhich recently had strong performance in various tasks to evaluate the data\ngenerated by the annotators in round 2. We combine data from many differ-\nent datasets to train the infoXML model, including ViNLI, 7,500 Vietnamese\nsamples in XNLI, and data generated from Round 1 (ViA1) together with the\nVnNewsNLI dataset [17]. The data obtained in Round 2 is called ViA2.\n3.5 Round 3: ViA3 Data\nIn the third round, the source of premises sentences is the same as in Round\n1 and Round 2. We continue to use the InfoXLM model to make predictions\non the data generated by the annotators in this round. To make the model\nmore robust, we trained this model on a larger amount of data than in the\nprevious round. We generate training data for the InfoXLM model from the\nViNLI dataset, 7,500 Vietnamese samples in XNLI, data generated from two\nprevious rounds (ViA1 and ViA2), the VnNewsNLI dataset along with more\nthan 10,000 pairs (vi-vi) from the VLSP Shared Task 2021 dataset [18]. The\ndata obtained in Round 3 is called ViA3.\n4 Dataset Analysis\nIn this section, we perform analyses on ViANLI to better understand the char-\nacteristics of the dataset. Specifically, we conduct statistics on the quantity of\ndata and the distribution of sentence lengths in both premises and hypotheses.\nFurthermore, to assess the annotators’ writing style, we calculate the pro-\nportion of reused words from premises in hypotheses and examine how they\nincorporate new vocabulary into the hypotheses.\n4.1 Initial Statistic\nAfter finishing the data construction, we obtained three datasets (ViA1, ViA2,\nViA3) for the three corresponding rounds. Combining the data from these\nthree rounds, we have the Vietnamese adversarial dataset - ViANLI, with\nthe size of more than 10,000 pairs of premise-hypothesis sentences from more\nthan 700 online news. The detailed statistics of the data set are shown in\nTable 2. We distribute the quantity of data in the ratio of 8: 1: 1 for training,\ndevelopment, and test sets, respectively.\nIn addition, as described in the data-building process for each round, we use\nmodels with progressively stronger performance to evaluate round-by-round\ndata, aiming to collect more difficult adversarial patterns from samples the\nmodel predicts wrong. The model error rate results show that the accuracy of\nthe models decreases with each round, which means that the pairs that the\nSpringer Nature 2021 LATEX template\nTin et al.\n11\nDataset\nContext\nNumber of pairs\nModel error rate\nVerify 1\nsuccess rate\nTrain\nDev\nTest\n(%)\n(%)\nViA1\n235\n2,609\n330\n330\n51.65\n77.59\nViA2\n240\n2,672\n330\n330\n44.93\n94.27\nViA3\n241\n2,731\n340\n340\n41.98\n94.71\nViANLI\n716\n8,012\n1,000\n1,000\n46.18\n88.86\nTable 2: Dataset statistics of ViNLI. The model error rate represents the\npercentage of the incorrect predictions of the model on the data per round.\nVerify 1 success rate is the percentage of successful confirmations on the data\nsamples that the data model predicts incorrectly.\nmodel predicts wrong round by round have greater difficulty and complex-\nity. The same thing is also found in Nie et al. (2020) [10] when building the\nANLI dataset. Furthermore, the success rate results of verify 1 substantially\nincreased from 77.59% in Round 1 to 94.71% in Round 3, showing that the\nnumber of pairs of premise-hypothesis qualified to fool the model and con-\nfirmed is a pair of sentences correctly created by the annotators in Verification\n1 increased significantly. This leads to the annotator’s hypothesis genera-\ntion quality increasing with each round. Each data sample for each round is\npresented in Table 3.\n4.2 Length Distribution\nWe calculate the length of the premise and hypothesis sentences in our dataset\nusing the VnCoreNLP tool [67] to segment Vietnamese by word (1 Vietnamese\nword can be composed of 1 or more tokens). In addition, we compare with the\nViNLI data set to see the difference from our data. When we look at Figure\n2a, Figure 2b, and Figure 2c (corresponding statistics of the data in Round 1,\nRound 2, and Round 3), we see that the length of the hypothesis sentence is\ndistributed in a shorter length range than the length of the premise sentence. In\naddition, these three charts show how annotators’ writing maintains stability\nin difficulty for data when the length is shorter than the premise sentence.\nWhen comparing ViANLI and ViNLI, Figure 2d and Figure 2e show that\nboth datasets have in common that the length of the hypothesis sentence is\nshorter than the premise sentence. However, when looking closely at these\ngraphs and the data in Table 4, they show that the hypothesis sentence length\nof the ViANLI dataset is much shorter than that of the ViNLI, while the\npremise sentence length is quite similar between the two tuples. The authors of\nMultiNLI [22] and ViNLI [16] suggest that the short sentence length hypothesis\nin the SNLI dataset can make the data easily predictable. The length of the\nhypothesis sentence in ViANLI is shorter than in ViNLI, but we have ensured\nthe difficulty and challenge of the data through the results of evaluating the\nmodel error rate of each round in Table 2. The influence of length on model\naccuracy is analyzed more clearly in Section 6.1.\nSpringer Nature 2021 LATEX template\n12\nTin et al.\nPremise\nHypothesis\nReason\nRound Orig. label\nPred. label\nVali.1 labels\nVali.2\nGold label\nCác giảthuyết trước đây\ncho rằng Hadrosaurid đã di\ncư từBắc Mỹtới châu Á\nnhưng khám phá mới lại cho\nthấy điều ngược lại. (Previous\ntheories\nsuggested\nthat\nthe\nHadrosaurid\nmigrated\nfrom\nNorth America to Asia, but\nthe new discovery suggests\notherwise.)\nCác phát hiện\nmới đã phủđịnh\nnhững\nphỏng\nđoán trước đây,\nHadrosaurid\nkhông hềcó sự\nthay đổi nơi sinh\nsống. (The new\nfindings\nhave\ndenied previous\nconjectures, that\nthe Hadrosaurid\ndid not change\nits habitat.)\nDùng nhiều từngữkhác\nvới\ncâu\nban\nđầu\nnên\nmô\nhình\ncó\nthể\nđoán\nsai. (Using many differ-\nent words from the orig-\ninal sentence, the model\nmay guess wrong.)\nViA1\nC\nE\nC C C\nNo\nC\nHơn 30 phút sau, đám cháy\nđược khống chế, tàu hàng\n2371 tiếp tục hành trình theo\nhướng Bắc Nam. (More than\n30\nminutes\nlater,\nthe\nfire\nwas under control, cargo ship\n2371 continued its journey in\nthe north-south direction.)\nĐám cháy được\nkhống chếsau\nhơn\nnửa\ngiờ\nđồng hồ. (The\nfire was brought\nunder\ncontrol\nafter more than\nhalf an hour.)\nMô hình khó khăn trong\nviệc nhận biết nửa giờ\nđồng hồvới 30 phút là\ngiống nhau, do đó có thể\ndựđoán sai thành Con-\ntradiction. (The difficulty\nmodel recognizes that half\nan hour and 30 minutes\nare the same, so it can be\nwrong to predict Contra-\ndiction.)\nViA2\nE\nC\nE E E\nNo\nE\nViệt\nTrinh\nhái\nmít,\nxoài,\ndứa... trĩu quảkhi vào mùa\nởvườn nhà rộng 3.000 m2.\n(Viet Trinh picks jackfruit,\nmango,\npineapple...\nladen\nwith fruit in season in a\n3,000 m2 home garden.)\nNhà Việt Trinh\nrộng 3.000 m2.\n(Viet\nTrinh’s\nhouse is 3,000\nm2 wide.)\nTôi lược bỏchữ\"vườn\"\nđể\ntạo\ncâu\nneutral\nvà\nmodel có thểnhầm thành\nentailment. I omitted the\nword \"garden\" to create\na\nneutral\nsentence\nand\nmodel could be mistaken\nfor entailment.)\nViA3\nN\nC\nN N E\nNo\nN\nChính phủvừa đồng ý cho\ncác thương nhân nước ngoài\nđược nhập cảnh vào Việt\nNam thu mua vải thiều Bắc\nGiang. (The Government has\njust agreed to allow foreign\ntraders to enter Vietnam to\nbuy Bac Giang lychees.)\nVải\nthều\nBắc\nGiang chỉđược\ntrồng\nở\nBắc\nGiang.\n(Bac\nGiang lychee is\nonly\ngrown\nin\nBac Giang.)\nTôi dùng kiến thức thực tế\nnhưng sai nên có thểmáy\nsẽ\nđoán\nthành\nneutral.\n(I used practical knowl-\nedge but it was wrong, so\nmaybe the machine will\nguess neutral.)\nViA2\nC\nN\nC N N\nYes\nN\nĐại diện EVN cho biết, tập\nđoàn không có hoạt động cho\nvay tín chấp và không có\nđơn vịtrực thuộc hay doanh\nnghiệp liên kết có tên Ngân\nhàng Điện lực Việt Nam. (A\nrepresentative of EVN said\nthat the group has no unse-\ncured lending activities and\nhas no affiliated units or affil-\niated enterprises named Elec-\ntricity of Vietnam Bank.)\nEVN\nkhông\ncó bất kì hoạt\nđộng\ncho\nvay\ntín\nchấp\nnào\ntrong thời gian\ngần đây. (EVN\nhas not had any\nunsecured lend-\ning\nactivities\nrecently.)\nNêu thêm thời gian nên\nmô\nhình\nsẽ\nđoán\nsai.\n(Given\nmore\ntime,\nthe\nmodel will guess wrong.)\nViA3\nC\nE\nE E C\nYes\nE\nTable 3: Examples from ViANLI dataset. Where Orig. is the label of the\noriginal annotator, Pred. is the predictive label of the model, Vali.1 is the three\nconfirmation labels of the three verifiers in the verification phase 1, Vali.2\nindicates whether this sample has gone through the verification phase 2 or not.\nC, E, and N are the abbreviations for Contradiction, Entailment, and Neutral.\nSpringer Nature 2021 LATEX template\nTin et al.\n13\nMean word length\nDataset\nViA1\nViA2\nViA3\nViANLI\nViNLI\nPremise\n24.4\n25.4\n25.0\n24.9\n24.5\nHypothesis\n13.8\n14.4\n14.0\n14.1\n18.1\nTable 4: The mean length of premise and hypothesis sentences on ViANLI\nand ViNLI.\n0\n20\n40\n60\n80\nSentence length (words)\n0\n50\n100\n150\n200\n250\nNumber of sentences\nPremise\nHypothesis\n(a) ViA1\n0\n20\n40\n60\n80\nSentence length (words)\n0\n50\n100\n150\n200\n250\nNumber of sentences\nPremise\nHypothesis\n(b) ViA2\n0\n20\n40\n60\n80\nSentence length (words)\n0\n50\n100\n150\n200\n250\n300\nNumber of sentences\nPremise\nHypothesis\n(c) ViA3\n0\n20\n40\n60\n80\nSentence length (words)\n0\n200\n400\n600\n800\nNumber of sentences\nPremise\nHypothesis\n(d) ViANLI\n0\n20\n40\n60\n80\n100\nSentence length (words)\n0\n250\n500\n750\n1000\n1250\n1500\n1750\n2000\nNumber of sentences\nPremise\nHypothesis\n(e) ViNLI\nFig. 2: Comparison of length distribution between ViANLI and ViNLI.\nSpringer Nature 2021 LATEX template\n14\nTin et al.\n4.3 Word Overlap Rate\nSimilar to Huynh et al. (2022) on the ViNLI dataset [16], we also calculate\nthe word overlap rate (WOR) between the premise sentence and the hypoth-\nesis sentence on the ViANLI adversarial data. This analysis is meaningful in\nassessing the difficulty of the data because previous studies have mentioned\nthat the word overlap rate affects the predictive ability of the models. We\nuse the Jaccard metric to calculate the unordered word overlap between the\npremise and the hypothesis similar to the one on ViNLI. Before calculating\nthe Jaccard value, we also use the VnCoreNLP toolkit for Vietnamese word\nsegmentation. The Jaccard measure between a pair of premise and hypothesis\nsentences is calculated by the formula (1).\nJaccard =\n|P ∩H|\n|P| + |H| + |P ∪H|\n(1)\nWhere, premise and hypothesis sentences are represented in two lists of\nwords, respectively, as follows: P = [WP 1, WP 2, WP 3, ..., WP n], H = [WH1,\nWH2, WH3, ..., WHm]. |P∩H| is the number of words that appear in both\npremise and hypothesis sentences. |P| is the number of words in the sentence\npremise. |H| is the number of words in the sentence hypothesis. |P∪H| is the\nnumber of words in the premise and hypothesis sentences after the duplicates\nare removed. An example of word overlap between the premise and hypothesis\nsentences for the entailment label is shown in Figure 3.\nPremise: Việc khai_thác Bitcoin có_thể tiêu tốn hàng tỷ kilowatt điện, chủ_yếu từ\nnhiên_liệu hóa_thạch - nguyên_liệu phát thải khí carbon lớn nhất. (Bitcoin mining can consume\nbillions of kilowatts of electricity, mainly from fossil fuels, which are the biggest carbon emitters.)\nSentence pair of Entailment label\nHypothesis: Việc khai_thác Bitcoin gây ảnh_hưởng xấu đến với môi_trường rất nhiều\nbởi_vì thải ra khí carbon. (Bitcoin mining is very harmful to the environment because it releases carbon\ndioxide.)\nFig. 3: Example of word overlap in the premise-hypothesis pair of the entail-\nment label. Where the green highlight is the same words, the red highlight is\nthe new words that only appear in the hypothesis sentence.\nThe result shown in Table 5 is the average Jaccard value on each dataset\nafter calculating for each pair of sentences. In general, when observing the\nword overlap rate on each round of data and the whole ViANLI data, we found\nthat the word overlap rate on the entailment label is the lowest compared to\nthe larger overlap rate on the contradiction and neutral labels. This shows\nthat when writing the entailment hypothesis, the annotator tends to use fewer\nwords from the premise sentence. The opposite trend is shown when compared\nSpringer Nature 2021 LATEX template\nTin et al.\n15\nLabel\nJaccard (%)\nViA1\nViA2\nViA3\nViANLI\nViNLI\nEntailment\n23.46\n21.06\n20.27\n21.55\n29.88\nContradiction\n33.11\n31.13\n31.17\n31.75\n23.30\nNeutral\n31.05\n32.52\n31.31\n31.60\n20.19\nTable 5: The word overlap rate in ViANLI compares to that in ViNLI.\nwith the ViNLI dataset when the ratio of word overlap on the entailment label\nis the largest, followed by that on the contradiction and neutral labels. To have\na more precise view of the impact of word overlap rate on model accuracy, we\nhave more specific analyses in Section 6.2.\n4.4 New Word Rate\nIn contrast to the word overlap rate, we analyze the new word rate on ViANLI.\nThis is the proportion of new words appearing in the hypothesis sentence\nthat are words that do not appear in the premise sentence. This statistic\nhelps us assess the linguistic diversity of annotators when writing hypothesis\nsentences. Similar to the calculation on ViNLI, we calculate the ratio of new\nwords to the data for each round and the entire ViANLI. We also use the\nVnCoreNLP toolkit to separate Vietnamese words before calculating the new\nword rate. The results are presented in Table 6 for the three labels entailment,\ncontradiction, and neutral, respectively. The new word rate in the entailment\nhypothesis is the largest and the lowest in the contradiction hypothesis on the\nper-round data and the entire ViANLI data. The comparison of data between\nViANLI and ViNLI shows some differences. In the ViNLI dataset, the largest\nnew word rate belongs to the neutral label and the lowest rate belongs to\nthe entailment label. In addition, except that the proportion of new words\non the entailment labels of the ViANLI dataset is larger than that of ViNLI,\non contradiction labels and neutral labels, this rate is significantly lower than\nthat of ViNLI. The new word rate is also considered a factor that affects the\nperformance of machine learning models. Its influence is analyzed more clearly\nin Section 6.3.\nLabel\nNew word rate (%)\nViA1\nViA2\nViA3\nViANLI\nViNLI\nEntailment\n51.08\n53.85\n54.57\n53.23\n46.59\nContradiction\n36.17\n39.21\n40.08\n38.59\n53.96\nNeutral\n41.03\n39.50\n41.41\n40.67\n61.79\nTable 6: The new word rate in ViANLI compares to that in ViNLI.\nTo gain a better understanding of the trend in word usage of annotators\nwhen writing hypothesis sentences, we use PhoNLP [68] to identify the part\nSpringer Nature 2021 LATEX template\n16\nTin et al.\nKhi\nlo_lắng\nthái_quá và\nkhông\nlàm\nchủ\nđược\ncảm_xúc , Kendall_Jenner thấy\nchân_tay\ntê_liệt .\nKendall_Jenner cảm_thấy\ncơ_thể\ntê\ncứng\nkhi\nbồn_chồn\ntrong\nngười .\nPOS-tag = \nPremise:\nPOS-tag = \nHypothesis:\nN\nV\nA\nCc\nR\nV\nV\nR\nN\nNp\nV\nN\nV\nNp\nV\nN\nA\nA\nN\nA\nE\nN\nLegend POS-tags\nN: Noun\nV: Verb\nA: Adjective\nCc: Coordinating conjunction\nNp: Proper noun\nE: Preposition\nR: Adjunct\nFig. 4: Example of POS-tag in the premise-hypothesis pair of the entailment\nlabel. The red words in the hypothesis tree are new words, and the arrows\nrepresent changes in the position and function of the word.\nof speech (POS) of new words in the hypothesis sentence. After that, we cal-\nculate the percentage of each category in the POS for a visual look. PhoNLP\nrecognizes many different types in POS, but we summarize them by main word\ntypes, including Nouns, Verbs, Adjectives, Prepositions, Adjuncts, and Oth-\ners (combining the rest of the types). Figure 5 illustrates the new word rate\nby Part-Of-Speech in ViANLI. Statistical results show that the trend of using\nwords is quite similar on all three labels when Nouns and Verbs account for\nthe most significant proportion compared to other types. In addition, annota-\ntors often use Nouns when writing the entailment hypothesis. Adjective is the\nword that annotators rarely use when writing hypothesis sentences. An illus-\ntrative example of POS-tag analysis on new words that appear in a hypothesis\nsentence is shown in Figure 4.\nSpringer Nature 2021 LATEX template\nTin et al.\n17\nLabel\n%\n0\n10\n20\n30\n40\nEntailment\nContradiction\nNeutral\nNoun\nVerb\nAdjective\nPreposition\nAdjunct\nOther\nFig. 5: The new word rate by Part-Of-Speech in ViANLI.\n5 Experiments and Results\nIn this section, we present how we design the main experiments to assess both\nthe challenges posed by ViANLI and its effectiveness in improving perfor-\nmance on various other datasets. Additionally, we provide detailed information\nrelated to the other datasets used in the experiments, the selection and setup\nof baseline models, and evaluation metrics.\n5.1 Benchmark Datasets\nSimilar to Nie et al. (2020) [10], we also combine the ViANLI dataset with\nother datasets to train machine learning models. After that, we use these\ntrained models to evaluate our adversarial data, as well as several other\ndatasets. This allows us to assess the challenge of adversarial data that we have\nbuilt and the effectiveness of using adversarial data against attacks in these\nother datasets. Other datasets combined with ViANLI data include ViNLI [16],\nXNLI [28], VLSP 2021 - vnNLI Challenge [18], and VnNewsNLI [17]. Due to\nthe different nature and organization of the datasets, we reorganized and sub-\ndivided these datasets to suit our experiment. In which XNLI and VLSP2021\nare multilingual inference datasets. Thus, we only extract Vietnamese sam-\nples to include in the training data. Also, the authors of the VnNewsNLI and\nXNLI datasets only develop the dev and test sets, so we used 90% of the dev\nset as training data and 10% of the dev set for model tuning. In addition, we\nalso cut 10% in the training set of VLSP2021 for model tuning during train-\ning. Details of the number of samples in each dataset used in the experiment\nare presented in Table 7.\nSpringer Nature 2021 LATEX template\n18\nTin et al.\nDataset\nQuatity\nTrain\nDev\nTest\nViA1\n2,609\n330\n330\nViA2\n2,672\n330\n330\nViA3\n2,731\n340\n340\nViANLI\n8,012\n1,000\n1,000\nViNLI\n24,376\n3,009\n2,991\nXNLI\n6,750\n750\n-\nVLSP2021\n7,816\n869\n2,118\nVnNewsNLI\n18,221\n2,025\n11,866\nTable 7: Quantity statistics of the datasets in our main experiment. ViANLI\ndataset is aggregated data from ViA1, ViA2, and ViA3.\n5.2 Baseline Models\nIn our experiments, we focus on using state-of-the-art transformer models,\nincluding mBERT [69], XLM-R [65], InfoXLM [66], and PhoBERT [62]. Except\nfor the mBERT model, we experimented with the large version with other\nmodels. In which the mBERT, XLM-R, and InfoXLM models are powerful\ntransformer models trained on multilingual documents, while the PhoBERT\nmodel is a monolingual transformer model developed for Vietnamese. Because\nVietnamese is represented by single words (one token) and compound words\n(more than one token), to match the characteristics of Vietnamese, we use the\nVnCoreNLP tool [67] to separate Vietnamese words. This gives us a reasonable\nrepresentation of the input of the PhoBERT model.\nIn addition, the parameters of the models selected by us during the model\ntraining process are suitable for most models to get the best performance\nafter going through the evaluation step. The basic parameters are selected\nas follows: max_length=256, learning_rate=1e-05, eval_frequency=400,\nbatch_size=16, weight_decay=0.0, adam_epsilon=1e-08. In addition, we\nhave set epochs=7 because the models have the best accuracy. When we reduce\nthe number of epochs, we find that the model has not reached the optimal\nlevel, and when the number of epochs is increased, the model accuracy begins\nto decline or saturate.\n5.3 Evaluation Metrics\nWe use the accuracy measure to evaluate the models, similar to the evaluation\non SNLI [1], ANLI [10], or ViNLI [16]. We do not further evaluate the F1-\nscore scale because there is not much significance on data sets with a uniform\ndistribution of the number of labels. The accuracy metric is expressed in the\n(2) formula.\nAccuracy = C\nN\n(2)\nwhere N is the total number of samples evaluated, and C is the number of\nsamples that the model correctly predicted.\nSpringer Nature 2021 LATEX template\nTin et al.\n19\n5.4 Experimental Results\nTable 8 presents the results of our main experiment. This experimental\nresults reveal many interesting findings on the performance of the models and\nadversarial data characteristics we have built.\nFirstly, the accuracy of almost all baseline models is low on the test set\nof each round and the final composite dataset ViANLI. This shows that we\nhave successfully built an adversarial natural language inference dataset that\ncan exploit the vulnerabilities of current modern machine learning models. In\nother words, ViANLI is highly complex and challenging, which is significant\nin promoting much later research.\nSecondly, the performance of most models degrades round-by-round,\nwhich is most visible in the results of XLM-RLarge, InfoXLMLarge, and\nPhoBERTLarge. This result shows that the difficulty level of the data increases\nthrough each round, the data from Round 3 is the hardest, followed by the\ndata from Round 2, and the data from Round 3 are the easiest. Similar results\nare also shown in the experimental results of ANLI [10]. However, with a slight\nvariation in mBERT performance, the accuracy decreased from Round 1 to\nRound 2 and then increased on Round 3 data. That could be the difference in\nthe characteristics of each model.\nThirdly, when increasing the training data gradually with ViA1, ViA2,\nand ViA3 data, the performance on the test set of ViA1, ViA2, ViA3, and\nViANLI also increased. This makes the models more robust and easier to\nhandle data attacks.\nFinally, the InfoXLMLarge model achieved the highest accuracy of the\nViNLI dataset with 84.36%, 3% higher than the highest result of Huynh et al.\n[16]. mBERT and XLM-RLarge models did not give the best results on ViNLI.\nBut when mBERT was trained on the data attached to ViA1, it improved\naccuracy by 2.48%, while when the XLM-RLarge model was trained on the\ndata including ViANLI, it improved by 1.68% compared to the results of\nHuynh et al. [16]. Furthermore, in the VLSP2021 (Only premise-hypothesis\npairs in Vietnamese) and VnNewsNLI datasets, the PhoBERTLarge model has\nthe highest predictive ability and is almost absolute with the same accuracy\nof 99.81%. This result is very impressive when the PhobertLarge model is\ntrained on synthetic data, including ViANLI, increasing the accuracy on the\nVnNewsNLI test set to 5.02% compared to the results of Nguyen et al. [17].\nIn general, when evaluating models trained with adversarial data, there is\na difference in performance. This may be because the characteristics of each\nmodel are different, it may be the difference in model architecture, or it may\nbe some function of the trained data. This was also reported by Nie et al. in\ntheir research results.\nIn the experiment in Table 9, we train the XLM-RLarge model on an\nincreasing amount of data from rounds and evaluate the performance of this\nmodel on the data from each round, as well as on the entire ViANLI dataset.\nThis experiment helps us to specifically evaluate the effect of the amount of\ntraining data on the predictive power of the model and the difficulty of the data\nSpringer Nature 2021 LATEX template\n20\nTin et al.\nModel\nTraining data\nViA1\nViA2\nViA3\nViANLI\nViNLI\nVLSP2021\nVnNewsNLI\nmBERT\nViNLI,XNLI\n16.36\n17.87\n22.05\n18.80\n66.83\n69.12\n70.29\n+ViA1\n22.73\n22.73\n24.12\n23.20\n67.32\n68.51\n56.91\n+ViA1+ViA2\n23.63\n24.54\n27.35\n25.20\n65.24\n70.68\n57.11\n+ViA1+ViA2+ViA3\n29.69\n24.24\n26.18\n26.70\n66.43\n69.17\n57.76\nViNLI,XNLI,ViANLI,VL,VnNe\n26.96\n24.54\n26.17\n25.90\n66.61\n97.49\n99.69\nXLM-RLarge\nViNLI,XNLI\n17.27\n16.97\n19.12\n17.80\n82.11\n83.75\n82.93\n+VnNe\n14.24\n16.67\n17.64\n16.20\n82.86\n81.96\n99.65\n+VnNe+ViA1\n18.18\n20.30\n20.59\n19.70\n82.11\n83.33\n99.81\n+VnNe+ViA1+ViA2\n26.97\n26.97\n19.12\n24.30\n81.80\n83.99\n99.81\n+VnNe+ViA1+ViA2+ViA3\n31.81\n28.49\n19.71\n26.60\n82.29\n84.23\n99.75\nViNLI,XNLI,ViANLI,VL,VnNe\n31.81\n25.15\n22.94\n26.60\n83.04\n99.01\n99.52\nInfoXLMLarge\nViNLI,XNLI\n18.18\n15.45\n17.94\n17.20\n83.87\n82.95\n78.97\n+VL+ViNe\n19.09\n17.27\n17.35\n17.90\n84.36\n99.57\n99.71\n+VL+VnNe+ViA1\n25.75\n20.91\n18.24\n21.60\n81.63\n99.10\n99.62\n+VL+VnNe+ViA1+ViA2\n30.00\n24.54\n22.35\n25.60\n83.70\n99.06\n99.59\nViNLI,XNLI,ViANLI,VL,VnNe\n33.03\n24.84\n22.94\n26.90\n82.64\n98.35\n99.53\nPhoBERTLarge\nViNLI,XNLI,ViANLI,VL,VnNe\n32.72\n29.39\n27.64\n29.90\n75.93\n99.81\n99.81\nTable 8: Model accuracy (%) on other test sets when training data is combined\nwith Vietnamese adversarial data. ViA1, ViA2, ViA2 are the data of Round 1,\nRound 2 and Round 3, respectively. ViANL refers to ViA1+ViA2+ViA3. VL\nrefers to the VLSP2021 dataset, and VnNe refers to the VnNewsNLI dataset.\nModel\nTraining data\nViA1\nViA2\nViA3\nViANLI\nDev\nTest\nDev\nTest\nDev\nTest\nDev\nTest\nXLM-RLarge\nViA1\n47.88\n44.54\n46.06\n47.27\n42.94\n44.70\n45.60\n45.50\nViA1+ViA2\n48.48\n49.09\n48.18\n48.18\n44.41\n44.70\n47.00\n47.30\nViA1+ViA2+ViA3\n50.61\n51.81\n49.09\n47.57\n45.00\n45.88\n48.20\n48.40\nTable 9: Model accuracy (%) that trained on ViANLI.\nbuilt over each round. The results of this experiment show that when trained\non an increasing number of adversarial data, the performance of the XLM-R\nmodel becomes stronger, and most of the accuracy of this model increases on\nthe dev and test sets of ViA1, ViA2, ViA3, and even ViANLI. This means\nthat as the model is trained on more and more adversarial data, in which the\ndifficulty is high, the model will improve its ability to handle attacks from the\ndata. Besides, from the results of evaluating the complexity and difficulty of\nthe data through each round, we observe that on the three training cases of\nthe XLM-R model, the accuracy of the model decreases gradually on both Dev\nand Text sets through each round. It can be seen once again that the difficulty\nof the data increases. Similar to the process of building the ANLI dataset, we\nsuccessfully built the Vietnamese adversarial dataset with high difficulty. If\nthis data-building process is applied to continue to develop the data further\nfor the following rounds, it will produce increasingly high-quality and chal-\nlenging data. This is of great significance in maintaining the challenge and\nattractiveness of the NLI task and thus spurring more future research rather\nthan building data through a static process.\nSpringer Nature 2021 LATEX template\nTin et al.\n21\nModel\nDev\nTest\nViNLI\nViANLI\nDifference\nViNLI\nViANLI\nDifference\nSyllable\nCBoW\n45.54\n35.00\n10.54\n44.96\n31.20\n13.76\nmBERT\n67.41\n44.70\n22.71\n64.84\n44.60\n20.24\nXLM-RBase\n72.02\n48.00\n24.02\n71.59\n47.30\n24.29\nXLM-RLarge\n83.02\n48.20\n34.82\n81.36\n48.40\n32.96\nInfoXMLBase\n72.02\n49.30\n22.72\n70.81\n47.70\n23.11\ninfoXMLLarge\n83.59\n48.90\n34.69\n83.12\n46.40\n36.72\nWord\nCBoW\n49.05\n34.30\n14.75\n45.8\n33.90\n11.9\nPhoBERTBase\n75.07\n44.60\n30.47\n72.87\n44.90\n27.97\nPhoBERTLarge\n77.33\n47.00\n30.33\n75.93\n45.70\n30.23\nTable 10: Model accuracy (%) on two benchmark datasets: ViANLI and\nViNLI.\nOur goal is to build ViANLI from the foundation of ViNLI to develop a\nmore complex and challenging version. Therefore, in Table 10, we set up experi-\nments with models similar to ViNLI on our ViANLI adversarial dataset, giving\nus a more intuitive comparison. In this experiment, we evaluated two different\ninput cases of the model, including word-based and syllable-based representa-\ntions. With the word-based model, we use the CBoW and PhoBERT models,\nwhile with the syllable-based model, we use the CBoW, mBERT, XLM-R,\nand InfoXLM models. PhoBERT is a Vietnamese pre-trained transformer, and\nmBERT, XLM-R, and InfoXML are multilingual pre-trained transformers.\nWith the CBoW and PhoBERT model, we use VnCoreNLP [67] to separate\nVietnamese words. In addition, we use pre-trained embedding - PhoW2V [70]\n(syllable and word level corpus) to represent the input to the CBoW model.\nThe results in Table 10 show that the accuracy of all models on the ViANLI\ndataset is much lower than the results on ViNLI. While the InforXLMBase\nmodel has the highest performance on the ViANLI dev set with 49.30%, the\nXLM-RLarge model has the highest accuracy on the Test set with 48.40%.\nIn addition, when observing the results, we also found that the performance\nof the XLM-RLarge model had the highest accuracy difference between the\ndev set of ViNLI and VIANLI of 34.82%. On the test set of both datasets,\nthe InfoXLMLarge model had the highest accuracy difference, with 36.72%.In\ngeneral, with our ViANLI data, it is challenging for the models to predict the\nsemantic relationship compared to the ViNLI data accurately. However, such\na difference in accuracy is due not only to the difficult nature of the data but\nalso to the amount of data the two datasets are different from.\n6 Results Analysis and Discussion\nIn this section, we analyze the results of the experiment to give a clearer\nview of the data and the characteristics of the models. We are interested in\nhow factors such as sentence length, word overlap rate, and new word rate\naffect the performance of the models. Alongside this, we investigate whether,\nduring the data creation process for ViANLI, annotators have introduced any\nartifact that makes it easier for models to recognize, as is the case with some\nSpringer Nature 2021 LATEX template\n22\nTin et al.\nother datasets. We also analyze and evaluate the data samples that the models\nincorrectly predict to drive better improvements in the future. We analyze the\nfour models with the highest performance on the Dev set in the experiment\nof Table 10, including pre-trained transformer models: mBERT, XLM-RLarge,\nInfoXLMBase, PhoBertLarge. For convenience, we call XLM-R, InfoXLM, and\nPhoBert short names for XLM-RLarge, InfoXLMBase, and PhoBertLarge.\n6.1 Effect of Length Distribution on Model Accuracy\nThe effect of the premise sentence length on the performance of the models is\nshown in Figure 6, together with the statistics of the distribution of the data\nby length on the Dev set of ViANLI. In general, we also found that the impact\nof premise sentence length on the predictive ability of the models is quite sim-\nilar. Most models work well when the premise sentence length is less than 16\nor greater than 31 words. Details show that except for the mBERT model,\nother models have good prediction ability when the premise sentence length is\nshorter than 6 words. Although the accuracy of the InfoXLM and PhoBERT\nmodels remained quite high and that of the mBERT model increased signifi-\ncantly, the performance of the XLM-R model decreased significantly. However,\nthe results may be biased when the amount of data in less than 11 words is\nrelatively small. The predictive power of all four models decreases as the sen-\ntence length of the premise increases in the range of 16-20 words. After that,\nthe performance of mBERT, XLM-R, and PhoBERT remained stable as the\nsentence length of the premise increased to 26-30 words, while the performance\nof InfoXLM fluctuated and reached the lowest of the four models in the range\nof 26-30 words. When the length increases to >30 words, the performance of\nthe four models also increases significantly.\n1-5\n6-10\n11-15\n16-20\n21-25\n26-30\n31-35\n>35\nPremise length (Words)\n0\n20\n40\n60\n80\n100\nAcc (%)\nmBERT\nXLM-R\nInfoXLM\nPhoBERT\nQuantity ratio\nFig. 6: Premise sentence length affects the accuracy of models.\nFigure 7 reflects the effect of the hypothesis sentence length on the accu-\nracy of the models. The accuracy of mBERT, XLM-R, and InfoXLM is equal to\nSpringer Nature 2021 LATEX template\nTin et al.\n23\nabout 50% in hypothesis sentences generated by annotators in the range of 1-\n5 words. In contrast, these sentences are significantly tricky for the PhoBERT\nmodel. However, as the length of hypothesis sentences increases to around 16-\n20 words, the performances of the mBERT, XLM-R, and InfoXLM models\ndecrease slightly. On the contrary, the ability to identify inference relation-\nships of the PhoBERT model increased slightly and was higher than the other\nmodels. When the length of the hypothesis sentence is more than 20 words,\nthe performance of the models starts to change dramatically. The accuracy of\nthe InfoXLM and mBERT models decreased significantly when the hypothesis\nlength was in the range of 26-30 words after their performance increased in the\nrange of 21-25 words. Model XLM-R still shows its stability as performance\nmaintains a slight increase when the length increases from 20 to 30 words.\nAfter that, the performance of all four models increased sharply when the\nhypothesis sentence length was greater than 30 words, of which the InfoXLM\nmodel had the most robust increase.\n1-5\n6-10\n11-15\n16-20\n21-25\n26-30\n31-35\n>35\nHypothesis length (Words)\n0\n20\n40\n60\n80\n100\nAcc (%)\nmBERT\nXLM-R\nInfoXLM\nPhoBERT\nQuantity ratio\nFig. 7: Hypothesis sentence length affects the accuracy of models.\n6.2 Effect of Word Overlap Rate on Model Accuracy\nTo evaluate the influence of the degree of word overlap between the premise\nsentence and the hypothesis sentence on the predictive ability of the models,\nwe analyze the accuracy of the models according to the increasing level of word\noverlap on the Dev set. Observing the analysis data in Figure 8, we found that\nthe performance of all models decreased significantly when the word overlap\nrate increased from 0 to 40%, while when this ratio rose above 40%, the per-\nformance of the models began to fluctuate strongly. Specifically, the accuracy\nof the XLM-R and PhoBERT models increased slightly with an overlap rate\nof approximately 41- 50% before starting to decrease dramatically and reach-\ning the same accuracy of approximately 34%. After that, the performance of\nthese two models is completely similar as they both increase significantly to\n50% when the overlap rate is higher than 80%. Meanwhile, the accuracy of\nSpringer Nature 2021 LATEX template\n24\nTin et al.\nthe InfoXLM and mBERT models is different from the previous two models.\nWhen the word overlap rate increased from 30-40% to 41-50%, the perfor-\nmance of these two models continued to decrease to 42%. Then, the accuracy\nof both models increased significantly when the overlap rate increased in the\nrange of 51-60% and decreased sharply when the overlap rate was greater than\n60%. Overall, we see the models’ performance decrease as the word overlap\nrate increases. This contrasts with the results of research on ViNLI [16], where\nthe word overlap rate is considered a factor that helps the ability to identify\nthe inferential relationship between the premise and hypothesis sentences. So,\nwith our data construction process, the data are guaranteed to be highly dif-\nficult even when annotators intentionally reuse many words from the premise\nsentence for the hypothesis sentence.\n0-10\n11-20\n21-30\n31-40\n41-50\n51-60\n61-70\n71-80\n>80\nJaccard (%)\n0\n20\n40\n60\n80\n100\nAcc (%)\nmBERT\nXLM-R\nInfoXLM\nPhoBERT\nQuantity ratio\nFig. 8: Word overlap rate affects the accuracy of models.\n6.3 Effect of New Word Rate on Model Accuracy\nIn contrast to the word overlap rate, the new word rate in the hypothesis\nsentence but not in the premise sentence is also considered a factor that affects\nthe performance of machine learning models because the more new words in\nthe hypothesis sentence, the more the model predicts wrongly. To evaluate\nthis, we also measure the accuracy of the models in terms of new word rates\nin the sentence hypothesis on the dev set. This result is shown in Figure 9.\nBesides, this result is relatively objective as the distribution of the number\nof pairs according to the ratio of new words in the dev set is quite even.\nObserving the graph, we notice that as the new word rate increases from 0\nto 50%, the accuracy of most models gradually decreases. However, as the\nproportion of new words in the hypothesis sentence gradually increases from\n51% to more than 80%, the ability of the model to predict correctly increases\nsignificantly. Once again, we found the opposite of the results on the ViNLI\ndataset. The analysis results on ViNLI show that as the rate of new words\nincreases, it causes the performance of the model gradually decreases. There is\nSpringer Nature 2021 LATEX template\nTin et al.\n25\na clear dependence of accuracy on the new word rate, whereas this dependence\nis less evident in our data. In addition, when comparing the accuracy on the\ndata according to new word levels, the results on ViANLI are much lower\nthan ViNLI, even when the new word rate is low. This shows that the data\ngenerated from our process warrant the high level of difficulty and challenges\nwith modern machine learning models.\n0-10\n11-20\n21-30\n31-40\n41-50\n51-60\n61-70\n71-80\n>80\nNew word rate (%)\n0\n20\n40\n60\n80\n100\nAcc (%)\nmBERT\nXLM-R\nInfoXLM\nPhoBERT\nQuantity ratio\nFig. 9: New word rate affects the accuracy of models.\n6.4 Hypothesis-only Results\nSimilar to the research on ViNLI and ANLI, we also evaluate the accuracy of\nthe models when these models are trained and evaluated on data containing\nonly hypothesis sentences. This analysis helps us to evaluate whether the data\ngenerated by the annotators leave any artifacts on the hypothesis sentences.\nThese artifacts can be seen as a factor that can contribute to the predictive\nability of the models during the training process of these models. The results of\nevaluating models on data of each round and all ViANLI data are summarized\nin Table 11. The results show that the performance of the models is quite\nlow on data per round. On ViANLI, the InfoXLM model has the highest\naccuracy on the dev set with 38%, and the PhoBERT model has the highest\nperformance on the test set with about 38%. This accuracy is much lower\nwhen compared to other datasets OCNLI\n66% [23], IndoNLI\n60% [24],\nSNLI\n69% [71], MultiNLI\n62% [72], and ViNLI\n58% [16]. So, if based only\non the hypothesis sentence, the accuracy can be achieved very high on other\ndata sets. This means that in the process of building data from annotators,\nthey have left signs on the hypothesis sentence whose features can help the\nmodel predict accurately. In contrast to our data, the rigorously designed\ndata construction process avoids hypothetical artifacts. This helps ensure the\ndifficulty and challenge of our data.\nSpringer Nature 2021 LATEX template\n26\nTin et al.\nLabel\nViA1\nViA2\nViA3\nViANLI\nDev\nTest\nDev\nTest\nDev\nTest\nDev\nTest\nmBERT\n41.51\n42.72\n35.45\n34.54\n35.88\n33.52\n37.60\n36.90\nXLM-R\n41.81\n40.61\n36.36\n32.42\n34.71\n37.35\n37.60\n36.80\nInfoXLM\n39.09\n38.18\n36.66\n32.12\n37.94\n32.64\n37.90\n34.30\nPhoBERT\n40.30\n43.03\n35.15\n33.93\n37.05\n36.76\n37.50\n37.90\nTable 11: Model accuracy (%) that is trained on hypothesis-only data.\n6.5 Error Analysis\nTo have a clearer view of the prediction ability on each label of the models,\nwe draw the confusion matrix on the dev set of the model with the worst and\nbest performance among the four models we analyzed. The results are shown\nin Figure 10. Observing the confusion matrix of mBERT, we found that most\npremise-hypothesis pairs of contradiction labels deceive the mBERT model\nwhen the correct prediction rate on this label is only 70/333 (accuracy of\napproximately 21%). Most sentence pairs of contradiction labels are incorrectly\npredicted to the neutral label. The performance of the mBERT model is high-\nest on the entailment label when the correct prediction rate reaches 202/334\n(approximately 60%), and a significant amount of data is also overpredicted on\nthe neutral label at about 35%. The accuracy of mBERT is about 52% on the\nneutral label. The amount of mispredicted data is evenly distributed on the\nentailment and contradiction labels. When observing the confusion matrix of\nthe InfoXLM model, we also see the similarity with the analysis results on the\nmBERT model. The accuracy on contradiction labels is even lower than with\nmBERT, only about 16%. However, on the entailment and neutral labels, the\naccuracy of the InfoXML model improves significantly compared to mBERT,\nwith almost 70% and 62%, respectively. Overall, the premise-hypothesis pairs\nof labels contradiction and entailment in ViANLI have the most significant\nability to deceive the models’ predictions to neutral. The difficulty of these\ntwo labels is quite impressive, especially the data of the contradiction label.\nSpringer Nature 2021 LATEX template\nTin et al.\n27\nCONTRADICTION\nENTAILMENT\nNEUTRAL\nPredicted label\nCONTRADICTION\nENTAILMENT\nNEUTRAL\nTrue label\n70\n91\n172\n17\n202\n115\n79\n79\n175\n25\n50\n75\n100\n125\n150\n175\n200\n(a) mBERT\nCONTRADICTION\nENTAILMENT\nNEUTRAL\nPredicted label\nCONTRADICTION\nENTAILMENT\nNEUTRAL\nTrue label\n54\n110\n169\n12\n233\n89\n51\n76\n206\n25\n50\n75\n100\n125\n150\n175\n200\n225\n(b) InfoXLM\nFig. 10: Confusion matrix of pre-trained language models on the development\nset\n7 Conclusion and Future Works\nIn this paper, we effectively apply the human-and-model-in-the-loop train-\ning approach to collect a new adversarial benchmark for Vietnamese natural\nlanguage inference - ViANLI. The benchmark contains approximately 10k\npremise-hypothesis sentence pairs, was carefully constructed to mitigate issues\nwith previous datasets, and was designed to remain attractive to the NLI\nresearch community. Thanks to this optimal data collection strategy, ViANLI\nwas created with high complexity and poses many challenges to current state-\nof-the-art models. The Experimental results show that the highest accuracy\nmodel on the ViANLI test set is XLM-RLarge, with only 48.40%, much lower\nthan the accuracy of this same model on the ViNLI dataset test set, which\nis 81.36%. In addition, we also demonstrate the effectiveness of combining\nthe ViANLI dataset with other Vietnamese NLI datasets such as ViNLI [16],\nVLSP 2021 - vnNLI Challenge [18], and VnNewsNLI [17] to enhance the infer-\nence relationship recognition capabilities of machine learning models on these\ndatasets.\nIn addition to the challenges that ViANLI presents to stimulate more\nresearch in NLI tasks, maintaining the interest of this research topic in Viet-\nnamese, and its potential to improve efficiency on similar tasks, our dataset\nalso holds significant importance in enriching research resources for the NLI\nresearch community in particular and NLP in general. ViANLI is especially\ncrucial considering the scarcity of adversarial benchmark datasets for low-\nresource languages like Vietnamese. Our dataset can inspire adversarial meth-\nods for building datasets for Vietnamese fact-checking, question-answering,\nand information extraction.\nDespite being based on an efficient data collection process and having high-\nquality data, ViANLI is still limited in terms of quantity compared to other\ndatasets. In future research, we plan to augment the dataset by increasing\nSpringer Nature 2021 LATEX template\n28\nTin et al.\nthe amount of data and expanding it to various text genres. Additionally,\nwe will continue to research the application of ViANLI to make the models\neven more powerful in handling high-complexity data patterns. To achieve a\nmore comprehensive and reliable evaluation, we will continue to evaluate the\nperformance of various SOTA models on ViANLI, such as MT5 [63], ViT5 [73],\nmBART [64], and BARTpho [74]. Furthermore, we will also combine ViANLI\nwith other NLI datasets to enhance effectiveness in tasks such as machine\nreading comprehension and text summarization.\nAcknowledgement\nThis research was supported by The VNUHCM-University of Information\nTechnology’s Scientific Research Support Fund.\nDeclarations\nConflict of interest The authors declare that they have no conflict of\ninterest.\nData Availability\nThe corpora generated during and/or analyzed during the current study are\navailable from the corresponding author on reasonable request.\nAuthor Contribution\nTin Van Huynh: Conceptualization; Formal analysis; Investigation; Method-\nology; Validation; Visualization; Writing - review&editing. Kiet Van Nguyen:\nConceptualization; Data curation; Formal analysis; Investigation; Validation;\nVisualization; Writing - original draft. Ngan Luu-Thuy Nguyen: Conceptual-\nization; Formal analysis; Investigation; Methodology; Validation; Supervision;\nWriting - review&editing.\nReferences\n[1] Bowman, S., Angeli, G., Potts, C., Manning, C.D.: A large annotated\ncorpus for learning natural language inference. In: Proceedings of the 2015\nConference on Empirical Methods in Natural Language Processing, pp.\n632–642 (2015)\n[2] Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: Squad: 100,000+ ques-\ntions for machine comprehension of text. In: Proceedings of the 2016\nConference on Empirical Methods in Natural Language Processing, pp.\n2383–2392 (2016)\nSpringer Nature 2021 LATEX template\nTin et al.\n29\n[3] Nguyen, K., Nguyen, V., Nguyen, A., Nguyen, N.: A vietnamese dataset\nfor evaluating machine reading comprehension. In: Proceedings of the\n28th International Conference on Computational Linguistics, pp. 2595–\n2605 (2020)\n[4] Van Nguyen, K., Van Huynh, T., Nguyen, D.-V., Nguyen, A.G.-T.,\nNguyen, N.L.-T.: New vietnamese corpus for machine reading compre-\nhension of health news articles. Transactions on Asian and Low-Resource\nLanguage Information Processing 21(5), 1–28 (2022)\n[5] Poliak, A., Belinkov, Y., Glass, J., Van Durme, B.: On the eval-\nuation of semantic phenomena in neural machine translation using\nnatural language inference. In: Proceedings of the 2018 Conference\nof the North American Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies, Volume 2 (Short\nPapers),\npp.\n513–523.\nAssociation\nfor\nComputational\nLinguistics,\nNew Orleans, Louisiana (2018). https://doi.org/10.18653/v1/N18-2082.\nhttps://aclanthology.org/N18-2082\n[6] Kann, K., Ebrahimi, A., Mager, M., Oncevay, A., Ortega, J.E., Rios,\nA., Fan, A., Gutierrez-Vasques, X., Chiruzzo, L., Giménez-Lugo, G.A.,\net al.: Americasnli: Machine translation and natural language inference\nsystems for indigenous languages of the americas. Frontiers in Artificial\nIntelligence 5, 266 (2022)\n[7] Mishra, A., Patel, D., Vijayakumar, A., Li, X.L., Kapanipathi, P.,\nTalamadupula, K.: Looking beyond sentence-level natural language infer-\nence for question answering and text summarization. In: Proceedings of\nthe 2021 Conference of the North American Chapter of the Associa-\ntion for Computational Linguistics: Human Language Technologies, pp.\n1322–1336 (2021)\n[8] To, H.Q., Nguyen, K.V., Nguyen, N.L.-T., Nguyen, A.G.-T.: Mono-\nlingual versus multilingual bertology for vietnamese extractive multi-\ndocument summarization. In: Proceedings of the 35th Pacific Asia\nConference on Language, Information and Computation, pp. 692–699.\nAssociation for Computational Lingustics, Shanghai, China (2021).\nhttps://aclanthology.org/2021.paclic-1.73\n[9] Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing\nadversarial examples. stat 1050, 20 (2015)\n[10] Nie, Y., Williams, A., Dinan, E., Bansal, M., Weston, J., Kiela, D.: Adver-\nsarial NLI: A new benchmark for natural language understanding. In:\nProceedings of the 58th Annual Meeting of the Association for Com-\nputational Linguistics, pp. 4885–4901. Association for Computational\nLinguistics, Online (2020). https://doi.org/10.18653/v1/2020.acl-main.\nSpringer Nature 2021 LATEX template\n30\nTin et al.\n441. https://aclanthology.org/2020.acl-main.441\n[11] Jia, R., Liang, P.: Adversarial examples for evaluating reading compre-\nhension systems. In: Proceedings of the 2017 Conference on Empirical\nMethods in Natural Language Processing, pp. 2021–2031 (2017)\n[12] Agarwal, V., Joglekar, S., Young, A.P., Sastry, N.: Graphnli: A graph-\nbased natural language inference model for polarity prediction in online\ndebates. In: Proceedings of the ACM Web Conference 2022, pp. 2729–2737\n(2022)\n[13] Tandon, C., Bongale, P., Arpita, T., Sanjana, R., Palivela, H., Nirmala,\nC.: Use of natural language inference in optimizing reviews and provid-\ning insights to end consumers. In: 2021 7th International Conference on\nAdvanced Computing and Communication Systems (ICACCS), vol. 1,\npp. 60–65 (2021). IEEE\n[14] Ding, X., Wang, Y., Xu, Z., Welch, W.J., Wang, Z.J.: Continuous con-\nditional generative adversarial networks: Novel empirical losses and label\ninput mechanisms. IEEE Transactions on Pattern Analysis and Machine\nIntelligence (2022)\n[15] Xu, S., Markert, K.: The Chinese causative-passive homonymy disam-\nbiguation: an adversarial dataset for NLI and a probing task. In: Proceed-\nings of the Thirteenth Language Resources and Evaluation Conference,\npp. 4316–4323. European Language Resources Association, Marseille,\nFrance (2022). https://aclanthology.org/2022.lrec-1.460\n[16] Huynh, T.V., Nguyen, K.V., Nguyen, N.L.-T.: ViNLI: A Vietnamese cor-\npus for studies on open-domain natural language inference. In: Proceed-\nings of the 29th International Conference on Computational Linguistics,\npp. 3858–3872. International Committee on Computational Linguistics,\nGyeongju, Republic of Korea (2022). https://aclanthology.org/2022.coling-\n1.339\n[17] Nguyen, C.T., Nguyen, D.T.: Building a vietnamese dataset for natural\nlanguage inference models. SN Computer Science 3(5), 395 (2022)\n[18] Quyen, N., Anh, H., Huyen, N., Lien, N.: Vlsp 2021 - vnnli challenge:\nVietnamese and english-vietnamese textual entailment. VNU Journal\nof Science: Computer Science and Communication Engineering 38(2)\n(2022). https://doi.org/10.25073/2588-1086/vnucsce.363\n[19] Thorne, J., Vlachos, A., Cocarascu, O., Christodoulopoulos, C., Mittal,\nA.: The fever2. 0 shared task. In: Proceedings of the Second Workshop\non Fact Extraction and VERification (FEVER), pp. 1–6 (2019)\nSpringer Nature 2021 LATEX template\nTin et al.\n31\n[20] Bartolo, M., Roberts, A., Welbl, J., Riedel, S., Stenetorp, P.: Beat the ai:\nInvestigating adversarial human annotation for reading comprehension.\nTransactions of the Association for Computational Linguistics 8, 662–678\n(2020)\n[21] Dagan, I., Glickman, O., Magnini, B.: The pascal recognising textual\nentailment challenge. In: Machine Learning Challenges Workshop, pp.\n177–190 (2005). Springer\n[22] Williams, A., Nangia, N., Bowman, S.: A broad-coverage challenge corpus\nfor sentence understanding through inference. In: Proceedings of the 2018\nConference of the North American Chapter of the Association for Com-\nputational Linguistics: Human Language Technologies, Volume 1 (Long\nPapers), pp. 1112–1122. Association for Computational Linguistics, ???\n(2018). http://aclweb.org/anthology/N18-1101\n[23] Hu, H., Richardson, K., Xu, L., Li, L., K¨ubler, S., Moss, L.S.: Ocnli: Orig-\ninal chinese natural language inference. In: Findings of the Association\nfor Computational Linguistics: EMNLP 2020, pp. 3512–3526 (2020)\n[24] Mahendra, R., Aji, A.F., Louvan, S., Rahman, F., Vania, C.: IndoNLI: A\nnatural language inference dataset for Indonesian. In: Proceedings of the\n2021 Conference on Empirical Methods in Natural Language Processing,\npp. 10511–10527. Association for Computational Linguistics, Online and\nPunta Cana, Dominican Republic (2021). https://doi.org/10.18653/v1/\n2021.emnlp-main.821. https://aclanthology.org/2021.emnlp-main.821\n[25] Shivade, C., et al.: Mednli-a natural language inference dataset for the\nclinical domain. In: Proceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing, Brussels, Belgium. Association\nfor Computational Linguistics, pp. 1586–1596 (2019)\n[26] Khot, T., Sabharwal, A., Clark, P.: Scitail: A textual entailment dataset\nfrom science question answering. In: Proceedings of the AAAI Conference\non Artificial Intelligence, vol. 32 (2018)\n[27] Amirkhani, H., AzariJafari, M., Faridan-Jahromi, S., Kouhkan, Z., Pour-\njafari, Z., Amirak, A.: Farstail: A persian natural language inference\ndataset. Soft Computing, 1–13 (2023)\n[28] Conneau, A., Rinott, R., Lample, G., Williams, A., Bowman, S., Schwenk,\nH., Stoyanov, V.: Xnli: Evaluating cross-lingual sentence representations.\nIn: Proceedings of the 2018 Conference on Empirical Methods in Natural\nLanguage Processing, pp. 2475–2485 (2018)\n[29] Khanuja, S., Dandapat, S., Sitaram, S., Choudhury, M.: A new dataset\nSpringer Nature 2021 LATEX template\n32\nTin et al.\nfor natural language inference from code-mixed conversations. In: Pro-\nceedings of the The 4th Workshop on Computational Approaches to Code\nSwitching, pp. 9–16 (2020)\n[30] Ham, J., Choe, Y.J., Park, K., Choi, I., Soh, H.: Kornli and korsts: New\nbenchmark datasets for korean natural language understanding. In: Find-\nings of the Association for Computational Linguistics: EMNLP 2020, pp.\n422–430 (2020)\n[31] Thorne, J., Vlachos, A., Christodoulopoulos, C., Mittal, A.: Fever: a\nlarge-scale dataset for fact extraction and verification. In: Proceedings of\nthe 2018 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, Volume 1\n(Long Papers), pp. 809–819 (2018)\n[32] Schuster, T., Fisch, A., Barzilay, R.: Get your vitamin c! robust fact veri-\nfication with contrastive evidence. In: Proceedings of the 2021 Conference\nof the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pp. 624–643 (2021)\n[33] Aly,\nR.,\nGuo,\nZ.,\nSchlichtkrull,\nM.,\nThorne,\nJ.,\nVlachos,\nA.,\nChristodoulopoulos, C., Cocarascu, O., Mittal, A.: Feverous: Fact extrac-\ntion and verification over unstructured and structured information. In:\n35th Conference on Neural Information Processing Systems, NeurIPS\n2021 (2021). Neural Information Processing Systems foundation\n[34] Bartolo, M., Roberts, A., Welbl, J., Riedel, S., Stenetorp, P.: Beat the AI:\nInvestigating adversarial human annotation for reading comprehension.\nTransactions of the Association for Computational Linguistics 8, 662–678\n(2020). https://doi.org/10.1162/tacl_a_00338\n[35] Kang, D., Khot, T., Sabharwal, A., Hovy, E.: Adventure: Adversarial\ntraining for textual entailment with knowledge-guided examples. In: Pro-\nceedings of the 56th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pp. 2418–2428 (2018)\n[36] Iyyer, M., Wieting, J., Gimpel, K., Zettlemoyer, L.: Adversarial exam-\nple generation with syntactically controlled paraphrase networks. In:\nProceedings of NAACL-HLT, pp. 1875–1885 (2018)\n[37] Minervini, P., Riedel, S.: Adversarially regularising neural nli models\nto integrate logical background knowledge. In: Proceedings of the 22nd\nConference on Computational Natural Language Learning, pp. 65–74\n(2018)\n[38] Dong, X., Luu, A.T., Ji, R., Liu, H.: Towards robustness against natural\nlanguage word substitutions. In: International Conference on Learning\nSpringer Nature 2021 LATEX template\nTin et al.\n33\nRepresentations (2020)\n[39] Zhu, C., Cheng, Y., Gan, Z., Sun, S., Goldstein, T., Liu, J.: Freelb:\nEnhanced adversarial training for natural language understanding. In:\nInternational Conference on Learning Representations (2019)\n[40] Zellers, R., Bisk, Y., Schwartz, R., Choi, Y.: Swag: A large-scale adversar-\nial dataset for grounded commonsense inference. In: Proceedings of the\n2018 Conference on Empirical Methods in Natural Language Processing,\npp. 93–104 (2018)\n[41] Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W., Salakhutdinov, R.,\nManning, C.D.: Hotpotqa: A dataset for diverse, explainable multi-hop\nquestion answering. In: Proceedings of the 2018 Conference on Empir-\nical Methods in Natural Language Processing (2018). Association for\nComputational Linguistics\n[42] Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., Gardner, M.:\nDrop: A reading comprehension benchmark requiring discrete reasoning\nover paragraphs. In: Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and Short Papers), pp.\n2368–2378 (2019)\n[43] Chen, M., D’Arcy, M., Liu, A., Fernandez, J., Downey, D.: Codah: An\nadversarially-authored question answering dataset for common sense. In:\nProceedings of the 3rd Workshop on Evaluating Vector Space Represen-\ntations for NLP, pp. 63–69 (2019)\n[44] Dasigi, P., Liu, N.F., Marasovi´c, A., Smith, N.A., Gardner, M.: Quoref:\nA reading comprehension dataset with questions requiring coreferential\nreasoning. In: Proceedings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-IJCNLP), pp. 5925–5932\n(2019)\n[45] Wallace, E., Rodriguez, P., Feng, S., Yamada, I., Boyd-Graber, J.: Trick\nme if you can: Human-in-the-loop generation of adversarial examples for\nquestion answering. Transactions of the Association for Computational\nLinguistics 7, 387–401 (2019). https://doi.org/10.1162/tacl_a_00279\n[46] Finkel, J.R., Manning, C.D., Ng, A.Y.: Solving the problem of cascading\nerrors: Approximate bayesian inference for linguistic annotation pipelines.\nIn: Proceedings of the 2006 Conference on Empirical Methods in Natural\nLanguage Processing, pp. 618–626 (2006)\n[47] Landauer, T.K., Dumais, S.T.: A solution to plato’s problem: The latent\nSpringer Nature 2021 LATEX template\n34\nTin et al.\nsemantic analysis theory of acquisition, induction, and representation of\nknowledge. Psychological review 104(2), 211 (1997)\n[48] Oh, Y.R., Jeon, H.-B., Song, H.J., Lee, Y.-K., Park, J.-G., Lee, Y.-K.:\nA deep-learning based native-language classification by using a latent\nsemantic analysis for the NLI shared task 2017. In: Proceedings of the\n12th Workshop on Innovative Use of NLP for Building Educational\nApplications, pp. 413–422. Association for Computational Linguistics,\nCopenhagen, Denmark (2017). https://doi.org/10.18653/v1/W17-5047.\nhttps://aclanthology.org/W17-5047\n[49] Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Dis-\ntributed representations of words and phrases and their compositionality.\nAdvances in neural information processing systems 26 (2013)\n[50] Elman, J.L.: Finding structure in time. Cognitive science 14(2), 179–211\n(1990)\n[51] Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural com-\nputation 9(8), 1735–1780 (1997)\n[52] Chen, Q., Zhu, X., Ling, Z.-H., Wei, S., Jiang, H., Inkpen, D.: Enhanced\nlstm for natural language inference. In: Proceedings of the 55th Annual\nMeeting of the Association for Computational Linguistics (Volume 1:\nLong Papers), pp. 1657–1668 (2017)\n[53] Devlin, J., Chang, M.-W., Lee, K., Toutanova, K.: BERT: Pre-training\nof deep bidirectional transformers for language understanding. In: Pro-\nceedings of the 2019 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technolo-\ngies, Volume 1 (Long and Short Papers), pp. 4171–4186. Association\nfor Computational Linguistics, Minneapolis, Minnesota (2019). https:\n//doi.org/10.18653/v1/N19-1423. https://aclanthology.org/N19-1423\n[54] Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al.: Improving\nlanguage understanding by generative pre-training (2018)\n[55] Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis,\nM., Zettlemoyer, L., Stoyanov, V.: Roberta: A robustly optimized bert\npretraining approach. arXiv preprint arXiv:1907.11692 (2019)\n[56] Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek,\nG., Guzmán, F., Grave, E., Ott, M., Zettlemoyer, L., Stoyanov, V.:\nUnsupervised cross-lingual representation learning at scale. In: Pro-\nceedings of the 58th Annual Meeting of the Association for Computa-\ntional Linguistics, pp. 8440–8451. Association for Computational Lin-\nguistics, Online (2020). https://doi.org/10.18653/v1/2020.acl-main.747.\nSpringer Nature 2021 LATEX template\nTin et al.\n35\nhttps://aclanthology.org/2020.acl-main.747\n[57] Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R.R., Le, Q.V.:\nXlnet: Generalized autoregressive pretraining for language understanding.\nAdvances in neural information processing systems 32 (2019)\n[58] Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut, R.:\nAlbert: A lite bert for self-supervised learning of language representations.\nIn: International Conference on Learning Representations (2019)\n[59] Sanh, V., Debut, L., Chaumond, J., Wolf, T.: Distilbert, a distilled\nversion of bert: smaller, faster, cheaper and lighter. arXiv preprint\narXiv:1910.01108 (2019)\n[60] Clark, K., Luong, M.-T., Le, Q.V., Manning, C.D.: Electra: Pre-training\ntext encoders as discriminators rather than generators. ELECTRA 85,\n90 (2016)\n[61] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M.,\nZhou, Y., Li, W., Liu, P.J.: Exploring the limits of transfer learning\nwith a unified text-to-text transformer. The Journal of Machine Learning\nResearch 21(1), 5485–5551 (2020)\n[62] Nguyen, D.Q., Nguyen, A.T.: Phobert: Pre-trained language models for\nvietnamese. In: Findings of the Association for Computational Linguis-\ntics: EMNLP 2020, pp. 1037–1042 (2020)\n[63] Xue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., Siddhant,\nA., Barua, A., Raffel, C.: mT5: A massively multilingual pre-trained\ntext-to-text transformer. In: Proceedings of the 2021 Conference of the\nNorth American Chapter of the Association for Computational Lin-\nguistics: Human Language Technologies, pp. 483–498. Association for\nComputational Linguistics, Online (2021). https://doi.org/10.18653/v1/\n2021.naacl-main.41. https://aclanthology.org/2021.naacl-main.41\n[64] Liu, Y., Gu, J., Goyal, N., Li, X., Edunov, S., Ghazvininejad, M.,\nLewis, M., Zettlemoyer, L.: Multilingual denoising pre-training for neural\nmachine translation. Transactions of the Association for Computational\nLinguistics 8, 726–742 (2020). https://doi.org/10.1162/tacl_a_00343\n[65] Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G.,\nGuzmán, F., Grave, É., Ott, M., Zettlemoyer, L., Stoyanov, V.: Unsuper-\nvised cross-lingual representation learning at scale. In: Proceedings of the\n58th Annual Meeting of the Association for Computational Linguistics,\npp. 8440–8451 (2020)\n[66] Chi, Z., Dong, L., Wei, F., Yang, N., Singhal, S., Wang, W., Song, X.,\nSpringer Nature 2021 LATEX template\n36\nTin et al.\nMao, X.-L., Huang, H.-Y., Zhou, M.: Infoxlm: An information-theoretic\nframework for cross-lingual language model pre-training. In: Proceedings\nof the 2021 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, pp. 3576–\n3588 (2021)\n[67] Vu, T., Nguyen, D.Q., Dras, M., Johnson, M., et al.: Vncorenlp: A\nvietnamese natural language processing toolkit. In: Proceedings of the\n2018 Conference of the North American Chapter of the Association for\nComputational Linguistics: Demonstrations, pp. 56–60 (2018)\n[68] Nguyen, D.Q., et al.: Phonlp: A joint multi-task learning model for viet-\nnamese part-of-speech tagging, named entity recognition and dependency\nparsing. In: Proceedings of the 2021 Conference of the North Ameri-\ncan Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies: Demonstrations, pp. 1–7 (2021)\n[69] Devlin, J., Chang, M.-W., Lee, K., Toutanova, K.: Bert: Pre-training of\ndeep bidirectional transformers for language understanding. In: Proceed-\nings of the 2019 Conference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Language Technologies,\nVolume 1 (Long and Short Papers), pp. 4171–4186 (2019)\n[70] Nguyen, A.T., Dao, M.H., Nguyen, D.Q.: A pilot study of text-to-sql\nsemantic parsing for vietnamese. In: Findings of the Association for\nComputational Linguistics: EMNLP 2020, pp. 4079–4085 (2020)\n[71] Poliak, A., Naradowsky, J., Haldar, A., Rudinger, R., Van Durme, B.:\nHypothesis only baselines in natural language inference. In: Proceedings\nof the Seventh Joint Conference on Lexical and Computational Semantics,\npp. 180–191 (2018)\n[72] Bowman, S., Palomaki, J., Soares, L.B., Pitler, E.: New protocols and neg-\native results for textual entailment data collection. In: Proceedings of the\n2020 Conference on Empirical Methods in Natural Language Processing\n(EMNLP), pp. 8203–8214 (2020)\n[73] Phan, L., Tran, H., Nguyen, H., Trinh, T.H.: ViT5: Pretrained text-to-\ntext transformer for Vietnamese language generation. In: Proceedings of\nthe 2022 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies: Student\nResearch Workshop, pp. 136–142. Association for Computational Linguis-\ntics, Hybrid: Seattle, Washington + Online (2022). https://doi.org/10.\n18653/v1/2022.naacl-srw.18. https://aclanthology.org/2022.naacl-srw.18\n[74] Tran, N.L., Le, D.M., Nguyen, D.Q.: BARTpho: Pre-trained Sequence-\nto-Sequence Models for Vietnamese. In: Proceedings of the 23rd Annual\nSpringer Nature 2021 LATEX template\nTin et al.\n37\nConference of the International Speech Communication Association\n(2022)\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2024-06-25",
  "updated": "2024-07-01"
}