{
  "id": "http://arxiv.org/abs/2406.17873v1",
  "title": "Improving Arithmetic Reasoning Ability of Large Language Models through Relation Tuples, Verification and Dynamic Feedback",
  "authors": [
    "Zhongtao Miao",
    "Kaiyan Zhao",
    "Yoshimasa Tsuruoka"
  ],
  "abstract": "Current representations used in reasoning steps of large language models can\nmostly be categorized into two main types: (1) natural language, which is\ndifficult to verify; and (2) non-natural language, usually programming code,\nwhich is difficult for people who are unfamiliar with coding to read. In this\npaper, we propose to use a semi-structured form to represent reasoning steps of\nlarge language models. Specifically, we use relation tuples, which are not only\nhuman-readable but also machine-friendly and easier to verify than natural\nlanguage. We implement a framework that includes three main components: (1)\nintroducing relation tuples into the reasoning steps of large language models;\n(2) implementing an automatic verification process of reasoning steps with a\nlocal code interpreter based on relation tuples; and (3) integrating a simple\nand effective dynamic feedback mechanism, which we found helpful for\nself-improvement of large language models. The experimental results on various\narithmetic datasets demonstrate the effectiveness of our method in improving\nthe arithmetic reasoning ability of large language models. The source code is\navailable at https://github.com/gpgg/art.",
  "text": "Improving Arithmetic Reasoning Ability of Large Language Models\nthrough Relation Tuples, Verification and Dynamic Feedback\nZhongtao Miao, Kaiyan Zhao, Yoshimasa Tsuruoka\nThe University of Tokyo, Tokyo, Japan\n{mzt, zhaokaiyan1006, yoshimasa-tsuruoka}@g.ecc.u-tokyo.ac.jp\nAbstract\nCurrent representations used in reasoning steps\nof large language models can mostly be cate-\ngorized into two main types: (1) natural lan-\nguage, which is difficult to verify; and (2) non-\nnatural language, usually programming code,\nwhich is difficult for people who are unfamil-\niar with coding to read. In this paper, we pro-\npose to use a semi-structured form to repre-\nsent reasoning steps of large language mod-\nels. Specifically, we use relation tuples, which\nare not only human-readable but also machine-\nfriendly and easier to verify than natural lan-\nguage. We implement a framework that in-\ncludes three main components: (1) introduc-\ning relation tuples into the reasoning steps\nof large language models; (2) implementing\nan automatic verification process of reasoning\nsteps with a local code interpreter based on\nrelation tuples; and (3) integrating a simple\nand effective dynamic feedback mechanism,\nwhich we found helpful for self-improvement\nof large language models. The experimental re-\nsults on various arithmetic datasets demonstrate\nthe effectiveness of our method in improving\nthe arithmetic reasoning ability of large lan-\nguage models. The source code is available at\nhttps://github.com/gpgg/art.\n1\nIntroduction\nLarge language models, such as GPT series (Brown\net al., 2020; Achiam et al., 2023), PaLM (Anil\net al., 2023), Mistral (Jiang et al., 2023), and\nLLaMA (Touvron et al., 2023a,b; AI@Meta, 2024),\nhave shown great success in numerous tasks that re-\nquire reasoning. Besides the approach to scaling up\nthe size of large language models and training data\nto enhance their reasoning ability, many prompting\nmethods have been proposed to improve their rea-\nsoning performance. Previous works (Wei et al.,\n2022; Kojima et al., 2022; Zelikman et al., 2022;\nGao et al., 2023), which aim to enhance the reason-\ning ability of large language models, can be catego-\nrized into two main types: natural language-based\nQ\nFeedback\nART + Self-Consistency\nART\nReasoning in NL\nReasoning in RT\nPython Solution\nLocal Code Interpreter\nAnswer\nVerification Answer\nQ\nFeedback\nFigure 1: Schematic overview of our framework, ART.\n“Q” denotes a question. “NL” means “Natural Lan-\nguage”. “RT” means “Relation Tuple”. The left sub-\nfigure shows our proposed framework ART without\nSelf-Consistency (Wang et al., 2023). The right sub-\nfigure shows that our framework can be integrated with\nSelf-Consistency seamlessly.\napproaches and non-natural language-based ap-\nproaches. The natural language-based approaches\ninclude Chain-of-Thought (CoT) (Wei et al., 2022)\nand Zero-shot CoT (Kojima et al., 2022), which\nutilize intermediate reasoning steps in natural lan-\nguage to elicit the reasoning ability of large lan-\nguage models. The non-natural language-based\napproaches include PAL (Gao et al., 2023), which\nproposes to use Python code to solve math word\nproblems.\nHowever, the reasoning steps represented in nat-\n1\narXiv:2406.17873v1  [cs.CL]  25 Jun 2024\nural language are usually long, which can signifi-\ncantly increase inference cost and may contain com-\nputational errors and unjustified logical leaps (Zhou\net al., 2024b). Besides, unlike graphs or formal lan-\nguages, they are difficult to verify because of the\nnature of natural language (Zhou et al., 2024b).\nRecently, there have been some studies that fo-\ncus on translating natural language statements into\nformal languages such as Isabelle (Nipkow et al.,\n2002) using large language models (Agrawal et al.,\n2022; Zhou et al., 2024b; Xu et al., 2024b). How-\never, those formal languages are hard for humans\nto read.\nIn this study, we propose a framework named\nART1 to enhance the arithmetic reasoning ability\nof large language models. A schematic overview of\nour ART framework is shown in Figure 1. First, we\nutilize in-context learning to make a large language\nmodel generate reasoning steps mixed with a sim-\nple semi-structured form, relation tuples. We can\nobtain an answer after reasoning. These relation\ntuples are very similar to pseudo-code, which can\neasily be translated into real programming code.\nNext, the large language model generates a Python\ncode solution to verify the reasoning steps based\non the question and relation tuples. We run the\nPython code in a local code interpreter to obtain\nthe verification answer. Finally, we check whether\nthe two answers are consistent or not and provide\na dynamic feedback when necessary. If the two\nanswers are inconsistent, we will use the large lan-\nguage model to regenerate a new reasoning process\nbased on a simple dynamic feedback mechanism.\nThe answer is determined if the two answers are\nconsistent or reach the maximum number of tries\nin the feedback loop.\nThe main contributions of this paper can be sum-\nmarized as follows:\n• We introduce a semi-structured representation,\nrelation tuples, into the reasoning steps of\nlarge language models. Relation tuples are\nusually shorter and easier to read, compared\nwith long reasoning steps in natural language.\nThey are more machine friendly because they\nare very similar to pseudo-code, which can\nbe translated to real Python or other program-\nming language code easily. Our findings also\nreveal that incorporating relation tuples into\nfew-shot examples can improve the accuracy\n1ART: Improving Arithmetic Reasoning Ability through\nRelation Tuples, Verification and Dynamic Feedback\non four out of seven arithmetic datasets.\n• This study provides a local code interpreter\nand employs it to develop a reasoning step\nverifier based on relation tuples. This local\ncode interpreter can be integrated with any\nlarge language model seamlessly, regardless\nof whether they are open source or not.\n• We implement a simple and effective dy-\nnamic feedback mechanism.\nUnlike Self-\nRefine (Madaan et al., 2023), our dynamic\nfeedback mechanism is considerably simpler\nbut effective. Here, “Dynamic” means that\nfeedback is provided when necessary.\n2\nMethod\n2.1\nProblem Formulation\nWe denote a large language model as LM. Suppose\nthat we have a dataset D. The dataset can be de-\nnoted as D = {Qi, Ai}N−1\ni=0 , where Qi is the i-th\nquestion, Ai is the answer of Qi and N is the num-\nber of examples in the dataset. The CoT method\naims to generate a series of reasoning steps and an\nanswer, which can be denoted as:\n[ ˆRi, ˆAi] = LM(Qi),\n(1)\nwhere ˆRi denotes the generated intermediate rea-\nsoning steps of the large language model LM and\nˆAi denotes the predicted answer after the reasoning\nsteps. The local code interpreter is denoted as LCI.\n2.2\nART Framework\nThe ART framework can be described in the fol-\nlowing steps:\nStep 1: Reasoning with relation tuples.\nGiven\na question Qi from the dataset D, LM generates\nreasoning process ˆRi = LM(Qi) and its answer,\nˆAi. The reasoning process consists of a series of\nreasoning steps and each reasoning step contains\na natural language statement and its relation tuple\nequivalent. The reasoning process can be denoted\nas a list:\nˆRi = [(r0, t0), . . . , (ri, ti), . . . , (rn−1, tn−1)],\n(2)\nwhere ri is the reasoning step in natural language\nand ti is its equivalent in the relation tuple form. n\nis the number of reasoning steps. The prompt used\nin this step is shown in Figure 3.\n2\nQ\n…\nExample\nJanet’s ducks lay 16 eggs per day. She eats three for breakfast \nevery morning and bakes muffins for her friends every day with \nfour. She sells the remainder at the farmers' market daily for $2 \nper fresh duck egg. How much in dollars does she make every day \nat the farmers' market?\nQuestion\nReasoning Process with Relation Tuples\nWe know that Janet’s ducks lay 16 eggs per day, (number-of-\neggs-laid-per-day, is, 16).\nShe eats three for breakfast every morning and bakes muffins\nfor her friends every day with four, (number-of-eggs-used-per-\nday, is, 3 + 4).\n……\nTo find out how much she makes every day at the farmers'\nmarket, we multiply the number of eggs left to sell by the\nprice per egg, (total-earnings-per-day, is, number-of-eggs-left-\nto-sell-per-day * price-per-egg).\n9 * $2 = $18.\nThus, Janet makes $18 every day at the farmers' market.\nVerification by Programming Code\ndef calculate_daily_earnings():\nnumber_of_eggs_laid_per_day = 16\nnumber_of_eggs_used_per_day = 3 + 4\n    ……\n    # Total earnings from selling eggs at the farmers' \nmarket\ntotal_earnings_per_day = \nnumber_of_eggs_left_to_sell_per_day * price_per_egg\n    return f\"The final answer: ${total_earnings_per_day}\"\n# Call the function to display the result\nprint(calculate_daily_earnings())\n==?\nThe final answer: $18\nFeedback\nFeedback\nLocal Code Interpreter\nAnswer\nVerification Answer\nReasoning in NL\nReasoning in RT\nPython Solution\nThe final answer: $18.\nCode generation by RT\nConsistent?\nYes\nNo\nYes\nNo\nUpdate\nPrompt\nFigure 2: A detailed example illustrating how our method works. This example shows the solution to the first\nquestion of the test split of the GSM8K dataset, generated by our framework using ChatGPT.\nStep 2: Automatic verification with relation\ntriples and a local code interpreter.\nWe can ex-\ntract the relation tuples from the reasoning steps ˆRi\nin Step 1. The relation tuples extracted are denoted\nas a list:\nTi = [t0, . . . , ti, . . . , tn−1].\n(3)\nTo verify whether the reasoning steps in Step 1 are\ncorrect or not, we decide to use Python code and\nimplement a local code interpreter. Based on the\nquestion Qi and reasoning steps in relation tuples\nTi, LM generates a Python code solution Ci step by\nstep. The code generation process can be denoted\nas:\nCi = LM(Qi, Ti).\n(4)\nAfter obtaining the Python solution Ci. We execute\nit using our local code interpreter LCI and get the\nverification answer ˆ\nAv\ni from the execution result:\nˆ\nAv\ni = LCI(Ci).\n(5)\nThe prompt used in this step is shown in Figure 4.\nStep 3: Checking consistency and providing dy-\nnamic feedback when necessary.\nFrom Step 1,\nwe can get one answer ˆAi based on reasoning steps\nwith relation tuples. From Step 2, we can obtain the\nverification answer ˆ\nAv\ni . If these two answers are\n3\nSystem Prompt\nYou are a helpful assistant that can solve math \nproblems step by step with relation triples. \nAnswer the following question. Write your \nthoughts first. Please make sure when you make \na statement that includes reasoning, you must \nalways write down those reasoning steps as \nrelation triples. \nThe final answer must be in numeric format, not \nin words. The final answer should be in the \nformat with only a number shown: 'The final \nanswer: <your answer> '.\nQuestion: …\nAnswer: …\n…\nQuestion: …\nAnswer: …\nFigure 3: Prompt of relation tuple reasoning in Step 1.\nSystem Prompt\nYou are a helpful assistant capable of solving \nmath problems by using Python functions, based \non the question provided and its reasoning steps \nwhich are formatted as relation triples.\nGiven a question and its answer‘s thinking process \nin format of relation triples, write a python \nfunction to solve the question based on those \nrelation triples with the markdown format, that is, \n```python\\n<your code>\\n```. \nThe output of the function should be in this format \nwith only a number shown: 'The final answer: \n<your answer>'.\nQuestion: …\nAnswer: …\n…\nQuestion: …\nAnswer: …\nFigure 4: Prompt of program verification in Step 2.\nequal, it indicates that the reasoning steps in Step\n1 are consistent with Step 2, confirming that there\nis no computational error. Therefore, the answer\nis determined. However, if the two answers are\ninconsistent, the previous reasoning steps ˆRi will\nbe resent to the large language model LM as a feed-\nback. LM regenerates reasoning process ˆRi and its\nanswer ˆAi based on the feedback. The feedback\nprompt used here is shown in Figure 5. We record\nall the answers from Step 1 and Step 2 and choose\nthe most common one as the final answer, ensur-\ning seamless integration with the Self-Consistency\napproach (Wang et al., 2023). We also provide an\nexample to show the effectiveness of this dynamic\nfeedback mechanism in Figure 6.\nFeedback Prompt\nQuestion: \n{question_message}\nYour previous solution is: '{previous_response}'. \nPlease rethink the question based on the previous \nsolution.\nFigure 5: Feedback prompt when ART needs feedback.\nDataset Name\n# Test Set\nGSM8K\n1319\nASDIV\n2096\nSVAMP\n1000\nSingleOP\n562\nSingleEQ\n508\nAddSub\n395\nMultiArith\n600\nTable 1: Number of examples in the test splits of the\nseven arithmetic datasets we use in this study.\n3\nExperiments\n3.1\nSetup\nDatasets.\nIn this study, we focus on the arith-\nmetic reasoning ability of large language mod-\nels. We conduct experiments on seven arithmetic\ndatasets, including GSM8K (Cobbe et al., 2021),\nSVAMP (Patel et al., 2021), ASDIV (Miao et al.,\n2020), SingleOP, SingleEQ, AddSub and Mul-\ntiArith (Koncel-Kedziorski et al., 2016), follow-\ning Zhao et al. (2023). GSM8K is a high-quality\ndataset which contains 8.5K problems and solu-\ntions in total. These problems usually involve 2-8\nbasic arithmetic operation (addition, subtraction,\nmultiplication and division) steps to reach the final\nanswers. SVAMP, ASDIV, SingleOP, SingleEQ,\nAddSub and MultiArith are different arithmetic\ndatasets which cover various patterns. The statistics\nof the datasets are shown in Table 1. The primary\nmetric used for evaluation is accuracy.\nModels.\nTo evaluate our approach, we em-\nploy two proprietary large language models,\nChatGPT (gpt-3.5-turbo-0301)2 and GPT4o\n(gpt-4o-2024-05-13)3 and one open source\nlarge\nlanguage\nmodel,\nLlama3-8B-Instruct\n(meta-llama/Meta-Llama-3-8B-Instruct)4.\nSpecifically, we utilize ChatGPT for our main ex-\n2https://platform.openai.com/docs/\ndeprecations/2023-06-13-updated-chat-models\n3https://platform.openai.com/docs/models/\ngpt-4o\n4https://huggingface.co/meta-llama/\nMeta-Llama-3-8B\n4\nThe Doubtfire sisters are driving home with 7 kittens adopted from the local animal shelter when their mother \ncalls to inform them that their two house cats have just had kittens. She says that Patchy, the first cat, has had \nthrice the number of adopted kittens, while Trixie, the other cat, has had 12. How many kittens does the \nDoubtfire family now have?\nQuestion\nReasoning with RT w/o feedback (ART)\nReasoning with RT w/ feedback (ART)\nWe know that Trixie, one of the house \ncats, has had 12 kittens, (number-of-\nkittens-from-Trixie, is, 12).\nPatchy, the other house cat, has had thrice \nthe number of adopted kittens, (number-\nof-kittens-from-Patchy, is, 3 * number-of-\nadopted-kittens).\n……\nWe cannot determine the exact number of \nkittens without knowing the value of 'x', \nthe number of adopted kittens. However, \nwe do know that the Doubtfire family has \nat least 19 kittens.\nThe final answer: At least 19 kittens.\nMy apologies, I made a mistake in my previous \nsolution. We can determine the exact number of \nkittens from Patchy by using the information that \nPatchy has had thrice the number of adopted kittens. \nAnswer: We know that Trixie, one of the house cats, \nhas had 12 kittens, (number-of-kittens-from-Trixie, is, \n12).\n……\nThe total number of kittens is the sum of the kittens \nfrom Trixie, Patchy, and the adopted kittens, (total-\nnumber-of-kittens, is, number-of-kittens-from-Trixie + \nnumber-of-kittens-from-Patchy + number-of-adopted-\nkittens).\nSubstituting the values we know, we get:\ntotal-number-of-kittens = 12 + 21 + 7 = 40.\nThus, the Doubtfire family now has 40 kittens.\nThe final answer: 40.\nFigure 6: Comparison of “Reasoning with RT” solutions without feedback and with feedback, generated by our\nframework. This example shows the predicted solution for the 55-th question in the test split of the GSM8K dataset,\nusing our method with ChatGPT (gpt-3.5-turbo-0301).\nperiments and use GPT-4o and Llama3-8B-Instruct\nin our ablation study.\nIn our framework, the\ntemperatures of Llama3-8B-Instruct are set to 0.5\nin both Step 1 and Step 2. For the results in Table 2,\nboth temperatures in Step 1 and Step 2 are set to\n0, and the top_p parameter is set to 1 to ensure\na fair comparison with ModelSelection (Zhao\net al., 2023). We use the same prompt for all seven\narithmetic datasets for each large language model.\nIn-context Learning.\nFor ChatGPT and Llama3-\n8B-Instruct, we employ in-context learning using\nan eight-shot setting. In this setting, we select\nthe first eight questions from the train split of the\nGSM8K dataset. The process of obtaining our\neight-shot examples is as follows: First, we use\nGPT-4 to generate CoT solutions based on the ques-\ntions. Then, we incorporate relation tuples into the\nreasoning steps based on the CoT solutions gener-\nated by GPT-4. The complete eight-shot examples\nare provided in Appendix B. The reason for us-\ning the first eight examples of the train split of\nGSM8K is to avoid cherry-picking examples for\nin-context learning. For GPT-4o, following previ-\nous works (Zhao et al., 2023), we utilize a five-shot\nsetting. The five examples are sampled from the\neight-shot examples used in the eight-shot setting.\nFurther details can be found in Appendix B.\nImplementation.\nWe implement our framework\nand conduct evaluations based on the ModelSe-\nlection codebase5 provided by Zhao et al. (2023).\nFor our local code interpreter implementation, we\ndeveloped a customized version by adapting the\ncode from Local-Code-Interpreter6. For the Ope-\nnAI Python library, we use version 1.23.2. For\nthe open source Llama3-8B-Instruct, we employ\nthe large language model inference library vLLM\n(version 0.4.3)7 (Kwon et al., 2023) and a single\nNVIDIA A100 80GB GPU to run our experiments.\nWhen the answers from Step 1 and Step 2 are\ninconsistent, the maximum number of attempts al-\nlowed in Step 3 of our framework is set to 3.\n5https://github.com/XuZhao0/\nModel-Selection-Reasoning\n6https://github.com/MrGreyfun/\nLocal-Code-Interpreter\n7https://github.com/vllm-project/vllm\n5\nBackbone\nMethod\nSVAMP\nASDIV\nSingleOP\nSingleEQ\nAddSub\nMultiArith\nGSM8K\nChatGPT\nCoT\n83.0\n89.3\n94.8\n97.4\n90.4\n98.7\n80.8\nPAL\n80.3\n83\n90.7\n97.6\n89.4\n96.3\n79.2\nModelSelection\n84.3\n89.4\n94.8\n97.8\n90.6\n98.7\n82.6\nART (ours)\n87.1\n89.6\n96.3\n97.8\n93.2\n98.7\n84.5\nTable 2: Accuracy results on seven arithmetic datasets. The ChatGPT backbone that we use is gpt-3.5-turbo-0301\nto ensure a fair comparison with other baselines. The results of CoT, PAL and ModelSelection are quoted from Zhao\net al. (2023). Bold fonts highlight the best performance for each dataset.\n3.2\nMain Results\nAs shown in Table 2, we report the accuracy\nresults on the seven arithmetic datasets.\nTa-\nble 2 shows that our approach outperforms CoT,\nPAL and ModelSelection baselines on ChatGPT\n(gpt-3.5-turbo-0301). Notably, our method is\nparticularly effective on the GSM8K, SVAMP and\nAddSub datasets. Specifically, it improves accu-\nracy on the SVAMP dataset by 2.8%, compared\nwith ModelSelection and achieves a 1.9% improve-\nment over ModelSelection’s 82.6% accuracy on the\nGSM8K dataset.\n4\nAnalysis and Discussion\nIn this section, we analyze various factors affecting\nthe performance of our framework. The dataset we\nuse here is GSM8K. First, we investigate the effects\nof prior prompts used in ModelSelection (Zhao\net al., 2023) and GPT-4 generated prompts using\nthe same CoT method because our eight-shot ex-\namples are created based on the GPT-4 generated\nsolutions. Then, we assess the contributions of rela-\ntion tuples, verification by programming code and\nfeedback individually using three different large\nlanguage models. Finally, we show that our method\ncan be integrated into Self-Consistency.\n4.1\nOriginal Prompt vs. GPT-4 generated\nPrompt\nWe utilize in-context learning to build our frame-\nwork. Existing works use the eight-shot examples\nfrom CoT while the eight-shot examples in our\nmethod are manually created with the help of GPT-\n4. Therefore, in this section, we aim to test the\nimpact of difficulty of different prompts on the\nmodel’s performance with CoT. As shown in Ta-\nble 3, we find that the performance difference be-\ntween using the two versions of prompts is not sig-\nnificant on ChatGPT and Llama3-8B-Instruct. The\nGPT-4 generated eight-shot prompt and the eight-\nshot prompt used in our framework are shown in\nBackbone\nMethod\nGSM8K\nChatGPT\nCoT (original prompt)\n80.8\nCoT (GPT-4-generated prompt)\n80.1\nLlama3-8B-Instruct\nCoT (original prompt)\n80.1\nCoT (GPT-4-generated prompt)\n80.1\nTable 3: Accuracy results on GSM8K with different\neight-shot examples.\nThe “CoT (original prompt)”\nresult with ChatGPT is quoted from ModelSelec-\ntion (Zhao et al., 2023)\nAppendix B.\n4.2\nRole of Relation Tuples in Step 1\nIn this section, we analyze the role of relation tu-\nples. From Table 4, we can observe that the rea-\nsoning process incorporating relation tuples outper-\nforms the CoT reasoning process on four out of\nthe seven arithmetic datasets. Relation tuples in\nthe reasoning process can be viewed as notes that\nrecord key points in the reasoning steps in natural\nlanguage. These relation tuples may function as\n“pause” tokens (Goyal et al., 2024), prompting large\nlanguage models to “think” before generating the\nnext reasoning step.\n4.3\nRole of Verification by Programming\nCode in Step 2\nTable 5 shows the accuracy on the GSM8K dataset\nwhen using the answers from different steps of our\nframework as the final answers. In the table, “Rea-\nsoning with RT” represents the accuracy obtained\nby using the answer from Step 1 of our framework\nas the final answer. “Verification by Programming\nCode” indicates the accuracy achieved by using\nthe answer from Step 2 of our framework as the\nfinal answer. The third row “Reasoning with RT\n+ Verification w/o Feedback” shows the accuracy\nwhen the two answers from Step 1 and Step 2 of\nour framework are consistent and correct on the\nfirst attempt.\n6\nBackbone\nMethod\nSVAMP\nASDIV\nSingleOP\nSingleEQ\nAddSub\nMultiArith\nGSM8K\nChatGPT\nCoT\n83.0\n89.3\n94.8\n97.4\n90.4\n98.7\n80.8\nReasoning with RT\n85.4\n89.1\n96.3\n97.0\n93.0\n98.2\n81.9\nTable 4: Comparison of accuracy on the seven arithmetic datasets between using prior eight-shot prompt (CoT\neight-shot prompt) and using our eight-shot prompt (reasoning with RT eight-shot prompt).\nModel\nMethod\nGSM8K\nChatGPT\nReasoning with RT\n81.9\nVerification by Programming Code\n79.9\nReasoning with RT + Verification w/o Feedback\n75.2\nART (ours)\n84.5\nLlama3-8B-Instruct\nReasoning with RT\n79.6\nVerification by Programming Code\n71.6\nReasoning with RT + Verification w/o Feedback\n69.1\nART (ours)\n80.4\nGPT-4o\nReasoning with RT\n96.4\nVerification by Programming Code\n95.5\nReasoning with RT + Verification w/o Feedback\n95.2\nART (ours)\n96.6\nTable 5: Accuracy results of the ablation study of our\nframework on the GSM8K dataset. “RT” means Rela-\ntion Tuples.\nFrom Table 5, it is evident that the accuracy\nscores on the GSM8K dataset using the verifica-\ntion answers from Step 2 of our framework are\nare lower than those using relation tuples. We can\nobserve that the most obvious one is Llama3-8B-\nInstruct, which cannot generate programming code\nvery well based on the semi-structured form of\nreasoning (relation tuples), whereas ChatGPT and\nGPT-4o excel in this task.\nA possible reason for this discrepancy could be\nthat in Step 2 of our framework, we use relation\ntuples and questions as inputs for large language\nmodels, which are infrequently encountered during\ntheir training phases. Consequently, these models\nstruggle with generating Python solutions from this\nsemi-structured form. This is particularly evident\nin the Llama3-8B-Instruct model, where there is\nan accuracy gap between using answers from Step\n1 and Step 2 as final answers. This indicates that\nLlama3-8B-Instruct may have difficulty generat-\ning Python verification solutions based on relation\ntuples.\nWe also observe several common execution er-\nrors when Llama3-8B-instruct generates and exe-\ncutes Python solution code to verify the reasoning\nprocess in Step 2. Empirically, the most frequent\nerror is “UnboundLocalError: local variable ref-\nerenced before assignment”, typically caused by\nusing symbols that cannot serve as variable names\nin Python. Additionally, “SyntaxError” is another\ncommonly encountered error.\nLlama3\nChatGPT\nGPT-4o\nNo feedback\nFeedback (one-time)\nFeedback (two-times)\nFeedback (three-times)\nFigure 7: Percentage of questions requiring feedback on\nthe test split of the GSM8K dataset. Note that “Llama3”\ndenotes Llama3-8B-Instruct model. The details can be\nfound in Table 7, Appendix C.\nSVAMP\nASDIV\nSingleEQ\nSingleOP\nAddSub\nMultiArith\nNo feedback\nFeedback (one-time)\nFeedback (two-times)\nFeedback (three-times)\nFigure 8: Percentage of questions requiring feedback on\nthe test splits of the other six datasets (SVAMP, ASDIV,\nSingleEQ, SingleOP, AddSub, MultiArith) using Chat-\nGPT (gpt-3.5-turbo-0301). The details can be found in\nTable 8, Appendix C.\n4.4\nRole of Feedback in Step 3\nWe explore the effect of the dynamic feedback\nmechanism in our framework in this section. Fig-\nure 7 and 8 show the percentage of questions utiliz-\ning feedback on the GSM8K dataset and the other\n6 arithmetic datasets, respectively.\nIn Figure 7, we observe an interesting phe-\nnomenon: as the coding capabilities of the large\nlanguage models increase (Llama3-8B-Instruct <\nChatGPT < GPT-4o) as shown in Table 5, the per-\ncentage of questions requiring feedback continu-\nously decreases.\nFrom Figure 8, we observe that the dataset on\nwhich ChatGPT requires feedback most frequently\nis ASDIV. The percentage of feedback utilization\nmight be related to the quality of datasets and the\n7\nBackbone\nMethod\nGSM8K\nLlama3-8B-Instruct\nART (SC@1)\n80.4\nART (SC@5)\n84.2\nTable 6: Accuracy on the GSM8K dataset after integrat-\ning Self-Consistency (SC@5) into our framework ART.\n“SC@5” means that the number of sampled paths is 5.\nprogramming code understanding and generation\ncapabilities of large language models.\n4.5\nIntegration with Self-Consistency\nOur framework is designed for seamless integra-\ntion with the Self-Consistency approach (Wang\net al., 2023). The core idea of Self-Consistency is\nto select the most common answer derived from\nmultiple reasoning paths. In our framework, we\nalso determine the final answer by choosing the\nmost frequent answer from different steps. From\nTable 6, we can observe that with the aid of Self-\nConsistency, our framework significantly enhances\nthe arithmetic reasoning performance of Llama3-\n8B-Instruct on the GSM8K dataset.\n5\nRelated Work\nNatural language reasoning.\nThere are large\namounts of studies (Qiao et al., 2023; Sanyal et al.,\n2022; Nye et al., 2021; Wang et al., 2022) focus-\ning on enhancing the reasoning ability of large\nlanguage models in natural language. Chain-of-\nThought (CoT) (Wei et al., 2022) shows that in-\ntermediate reasoning steps can improve the perfor-\nmance of large language models. Zero-shot CoT, as\nproposed by Kojima et al. (2022), involves simply\nadding “Let’s think step by step” before generat-\ning answers to elicit the reasoning ability of large\nlanguage models. Least-to-most prompting (Zhou\net al., 2023) breaks down complex problems to\nsimpler problems and solve them in sequence to\nenable complex reasoning in large language mod-\nels. Self-Consistency (Wang et al., 2023) extends\nCoT by sampling various reasoning paths, gen-\nerating multiple answers and choosing the most\ncommon one. Tree-of-Thought (Yao et al., 2023)\ngeneralizes over Chain-of-Thought by framing any\nproblem as a search over a tree. Besta et al. (2024)\npropose Graph-of-Thoughts to improve large lan-\nguage model’s reasoning ability by modeling large\nlanguage model thoughts as vertices and dependen-\ncies between these vertices as edges. Buffer-of-\nThoughts (Yang et al., 2024) is a novel prompting\napproach which employs a meta-buffer to store a se-\nries of thought templates (high-level thoughts) and\nretrieves a relevant thought template and instantiate\nit when conducting reasoning.\nNon-natural language reasoning and verifica-\ntion.\nThere are many works (Kadlˇcík et al., 2023;\nGao et al., 2023; Xu et al., 2024b) aiming to en-\nhance the reasoning ability of large language mod-\nels by using non-natural language forms during the\nreasoning process. PAL (Gao et al., 2023) employs\nlarge language models to generate Python code\nas intermediate reasoning steps. ERA-CoT (Liu\net al., 2024) aids large language models in rea-\nsoning by analyzing entities and relationships in\nnatural language statements. Zhou et al. (2024a)\nfind that GPT-4’s powerful skills in generating and\nexecuting code could be utilized to enhance math-\nematical reasoning ability by analyzing the Code\nUsage Frequency of the GPT-4 Code Interpreter.\nMathCoder (Wang et al., 2024) integrates natural\nlanguage reasoning, code generation and execu-\ntion results to enhance the mathematical reason-\ning ability of large language models by fine-tuning\nthem. SymbolCoT (Xu et al., 2024b) integrates\nsymbolic expressions and logic rules into the rea-\nsoning process of large language models to enhance\ntheir logical reasoning ability. Zhou et al. (2024b)\ntranslate informal natural language reasoning state-\nments into formal Isabelle code which can be veri-\nfied automatically to enhance internal consistency\nof reasoning in large language models. Different\nfrom these works, our method utilizes the semi-\nstructure understanding and code generation ability\nof large language models to verify the reasoning\nprocess.\nSelf-improvement and verification.\nThere are\nmany works focusing on the self-improvement of\nlarge language models (Huang et al., 2023; Madaan\net al., 2023; Haluptzok et al., 2023; Xu et al., 2024a;\nYu et al., 2023). Zelikman et al. (2022) propose\nSelf-Taught Reasoner (STaR), which employs a\nreasoning process generation loop to produce rea-\nsoning steps and use these generated reasoning\npaths whose final answers are correct to further\nfine-tune large language models. Madaan et al.\n(2023) propose Self-Refine, which has three com-\nponents (generator, feedback provider and refiner).\nCompared with Self-Refine, the dynamic feedback\nin our framework is provided only when necessary.\nMoreover, our framework does not need the feed-\nback provider.\n8\n6\nConclusion\nIn this paper, we propose to use a semi-structured\nrepresentation for the arithmetic reasoning steps of\nlarge language models. Specifically, we utilize rela-\ntion tuples to connect reasoning in natural language\nwith formal languages, such as programming code,\nto more effectively verify the reasoning process of\nlarge language models. These relation tuples are\nhuman-readable and can easily be translated into\nformal languages.\nBased on this new representation of reasoning\nsteps, we have implemented a novel framework\nthat integrates the semi-structured representation,\nrelation tuples, into the reasoning process of large\nlanguage models. Additionally, we developed a\nlocal code interpreter to verify the reasoning pro-\ncess of large language models. Our framework also\nincludes a simple and effective dynamic feedback\nmechanism to elicit the self-improvement ability\nof large language models. Experimental results\ndemonstrate that our framework can improve the\narithmetic reasoning ability of large language mod-\nels.\nLimitations\nWe utilize programming code based on relation tu-\nples to verify reasoning process. Therefore, our\nmethod highly depends on the programming code\nunderstanding and generation ability of large lan-\nguage models that we use.\nBesides, the reasoning process in our method is\na mixture of informal natural language statements\nand semi-structured relation tuples. Therefore, the\ninference cost is high. It will be great if large lan-\nguage models can reason with relation tuples only,\nwhich can reduce the inference cost while maintain-\ning readability and are easy for machine to further\nprocess these relation tuples (e.g., automatic verifi-\ncation).\nFinally, there might be other semi-structured\nforms of reasoning steps which are easy to verify.\nEthics Statement\nThis research aims to improve arithmetic reason-\ning ability of large language models by introduc-\ning a semi-structured form into reasoning process\nof large language models, a verification process\nand a dynamic feedback mechanism. We utilized\npublicly available datasets compiled from other re-\nsearch papers. No personal data was used in this\nstudy. We agree to the License Terms and Privacy\nPolicy of corresponding large language models and\ndatasets used in our study. Our research adheres\nto ethical AI principles, promoting the beneficial\nuse of AI. In addition, large language models may\ngenerate harmful contents which we are trying to\navoid. We employ GitHub Copilot to help with\ncoding our experiments.\nReferences\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama\nAhmad, Ilge Akkaya, Florencia Leoni Aleman,\nDiogo Almeida, Janko Altenschmidt, Sam Altman,\nShyamal Anadkat, et al. 2023. Gpt-4 technical report.\narXiv preprint arXiv:2303.08774.\nAyush Agrawal, Siddhartha Gadgil, Navin Goyal,\nAshvni Narayanan, and Anand Tadipatri. 2022.\nTowards a mathematics formalisation assistant\nusing large language models.\narXiv preprint\narXiv:2211.07524.\nAI@Meta. 2024. Llama 3 model card.\nRohan Anil, Andrew M Dai, Orhan Firat, Melvin John-\nson, Dmitry Lepikhin, Alexandre Passos, Siamak\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng\nChen, et al. 2023. Palm 2 technical report. arXiv\npreprint arXiv:2305.10403.\nMaciej Besta, Nils Blach, Ales Kubicek, Robert Ger-\nstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz\nLehmann, Michał Podstawski, Hubert Niewiadomski,\nPiotr Nyczyk, and Torsten Hoefler. 2024. Graph of\nThoughts: Solving Elaborate Problems with Large\nLanguage Models. Proceedings of the AAAI Confer-\nence on Artificial Intelligence, 38(16):17682–17690.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners.\nIn Ad-\nvances in Neural Information Processing Systems,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro\nNakano, Christopher Hesse, and John Schulman.\n2021. Training verifiers to solve math word prob-\nlems. arXiv preprint arXiv:2110.14168.\nLuyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,\nPengfei Liu, Yiming Yang, Jamie Callan, and Gra-\nham Neubig. 2023. PAL: Program-aided language\n9\nmodels. In Proceedings of the 40th International\nConference on Machine Learning, volume 202 of\nProceedings of Machine Learning Research, pages\n10764–10799. PMLR.\nSachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Kr-\nishna Menon, Sanjiv Kumar, and Vaishnavh Nagara-\njan. 2024. Think before you speak: Training lan-\nguage models with pause tokens. In The Twelfth\nInternational Conference on Learning Representa-\ntions.\nPatrick Haluptzok, Matthew Bowers, and Adam Tauman\nKalai. 2023. Language models can teach themselves\nto program better. In The Eleventh International\nConference on Learning Representations.\nJiaxin Huang, Shixiang Gu, Le Hou, Yuexin Wu, Xuezhi\nWang, Hongkun Yu, and Jiawei Han. 2023. Large\nlanguage models can self-improve. In Proceedings\nof the 2023 Conference on Empirical Methods in Nat-\nural Language Processing, pages 1051–1068, Singa-\npore. Association for Computational Linguistics.\nAlbert Q Jiang, Alexandre Sablayrolles, Arthur Men-\nsch, Chris Bamford, Devendra Singh Chaplot, Diego\nde las Casas, Florian Bressand, Gianna Lengyel, Guil-\nlaume Lample, Lucile Saulnier, et al. 2023. Mistral\n7b. arXiv preprint arXiv:2310.06825.\nMarek Kadlˇcík, Michal Štefánik, Ondrej Sotolar, and\nVlastimil Martinek. 2023. Calc-X and calcformers:\nEmpowering arithmetical chain-of-thought through\ninteraction with symbolic systems. In Proceedings\nof the 2023 Conference on Empirical Methods in\nNatural Language Processing, pages 12101–12108,\nSingapore. Association for Computational Linguis-\ntics.\nTakeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. In Advances in\nNeural Information Processing Systems, volume 35,\npages 22199–22213. Curran Associates, Inc.\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate\nKushman, and Hannaneh Hajishirzi. 2016. MAWPS:\nA math word problem repository. In Proceedings of\nthe 2016 Conference of the North American Chapter\nof the Association for Computational Linguistics: Hu-\nman Language Technologies, pages 1152–1157, San\nDiego, California. Association for Computational\nLinguistics.\nWoosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying\nSheng, Lianmin Zheng, Cody Hao Yu, Joseph Gon-\nzalez, Hao Zhang, and Ion Stoica. 2023. Efficient\nmemory management for large language model serv-\ning with pagedattention. In Proceedings of the 29th\nSymposium on Operating Systems Principles, SOSP\n’23, page 611–626, New York, NY, USA. Association\nfor Computing Machinery.\nYanming Liu, Xinyue Peng, Tianyu Du, Jianwei Yin,\nWeihao Liu, and Xuhong Zhang. 2024. Era-cot: Im-\nproving chain-of-thought through entity relationship\nanalysis. arXiv preprint arXiv:2403.06932.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler\nHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\nNouha Dziri, Shrimai Prabhumoye, Yiming Yang,\nShashank Gupta, Bodhisattwa Prasad Majumder,\nKatherine Hermann, Sean Welleck, Amir Yazdan-\nbakhsh, and Peter Clark. 2023. Self-refine: Itera-\ntive refinement with self-feedback. In Advances in\nNeural Information Processing Systems, volume 36,\npages 46534–46594. Curran Associates, Inc.\nShen-yun Miao, Chao-Chun Liang, and Keh-Yih Su.\n2020. A diverse corpus for evaluating and developing\nEnglish math word problem solvers. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 975–984, Online.\nAssociation for Computational Linguistics.\nTobias Nipkow, Markus Wenzel, and Lawrence C. Paul-\nson. 2002.\nIsabelle/HOL: a proof assistant for\nhigher-order logic. Springer-Verlag, Berlin, Heidel-\nberg.\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari,\nHenryk Michalewski, Jacob Austin, David Bieber,\nDavid Dohan, Aitor Lewkowycz, Maarten Bosma,\nDavid Luan, et al. 2021. Show your work: Scratch-\npads for intermediate computation with language\nmodels. arXiv preprint arXiv:2112.00114.\nArkil Patel, Satwik Bhattamishra, and Navin Goyal.\n2021. Are NLP models really able to solve simple\nmath word problems? In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 2080–2094, Online.\nAssociation for Computational Linguistics.\nShuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen,\nYunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang,\nand Huajun Chen. 2023. Reasoning with language\nmodel prompting: A survey. In Proceedings of the\n61st Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n5368–5393, Toronto, Canada. Association for Com-\nputational Linguistics.\nSoumya Sanyal, Harman Singh, and Xiang Ren. 2022.\nFaiRR: Faithful and robust deductive reasoning over\nnatural language. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 1075–1093,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023a. Llama: Open\nand efficient foundation language models. Preprint,\narXiv:2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\n10\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023b. Llama 2: Open foundation and\nfine-tuned chat models. Preprint, arXiv:2307.09288.\nBoshi Wang, Xiang Deng, and Huan Sun. 2022. Itera-\ntively prompt pre-trained language models for chain\nof thought. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing,\npages 2714–2730, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nKe Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun\nLuo, Weikang Shi, Renrui Zhang, Linqi Song,\nMingjie Zhan, and Hongsheng Li. 2024. Mathcoder:\nSeamless code integration in LLMs for enhanced\nmathematical reasoning. In The Twelfth International\nConference on Learning Representations.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le,\nEd H. Chi, Sharan Narang, Aakanksha Chowdhery,\nand Denny Zhou. 2023. Self-consistency improves\nchain of thought reasoning in language models. In\nThe Eleventh International Conference on Learning\nRepresentations.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,\nand Denny Zhou. 2022. Chain-of-thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems,\nvolume 35, pages 24824–24837. Curran Associates,\nInc.\nCan Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,\nPu Zhao, Jiazhan Feng, Chongyang Tao, Qingwei\nLin, and Daxin Jiang. 2024a. WizardLM: Empow-\nering large pre-trained language models to follow\ncomplex instructions. In The Twelfth International\nConference on Learning Representations.\nJundong Xu, Hao Fei, Liangming Pan, Qian Liu, Mong-\nLi Lee, and Wynne Hsu. 2024b. Faithful logical\nreasoning via symbolic chain-of-thought. Preprint,\narXiv:2405.18357.\nLing Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao,\nMinkai Xu, Wentao Zhang, Joseph E Gonzalez,\nand Bin Cui. 2024. Buffer of thoughts: Thought-\naugmented reasoning with large language models.\narXiv preprint arXiv:2406.04271.\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\nTom Griffiths, Yuan Cao, and Karthik Narasimhan.\n2023. Tree of thoughts: Deliberate problem solving\nwith large language models. In Advances in Neural\nInformation Processing Systems, volume 36, pages\n11809–11822. Curran Associates, Inc.\nXiao Yu, Baolin Peng, Michel Galley, Jianfeng Gao, and\nZhou Yu. 2023. Teaching language models to self-\nimprove through interactive demonstrations. arXiv\npreprint arXiv:2310.13522.\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Good-\nman. 2022. Star: Bootstrapping reasoning with rea-\nsoning. In Advances in Neural Information Process-\ning Systems, volume 35, pages 15476–15488. Curran\nAssociates, Inc.\nJames Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He,\nand Michael Xie. 2023. Automatic model selection\nwith large language models for reasoning. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2023, pages 758–783, Singapore. Associa-\ntion for Computational Linguistics.\nAojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun\nLuo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song,\nMingjie Zhan, and Hongsheng Li. 2024a. Solving\nchallenging math word problems using GPT-4 code\ninterpreter with code-based self-verification. In The\nTwelfth International Conference on Learning Repre-\nsentations.\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nClaire Cui, Olivier Bousquet, Quoc V Le, and Ed H.\nChi. 2023. Least-to-most prompting enables com-\nplex reasoning in large language models. In The\nEleventh International Conference on Learning Rep-\nresentations.\nJin Peng Zhou, Charles E Staats, Wenda Li, Chris-\ntian Szegedy, Kilian Q Weinberger, and Yuhuai Wu.\n2024b. Don’t trust: Verify – grounding LLM quan-\ntitative reasoning with autoformalization. In The\nTwelfth International Conference on Learning Repre-\nsentations.\n11\nA\nComparison of different methods\nA comparison of different methods is shown in\nFigure 9.\nB\nFull Prompts\nB.1\nEight-shot examples\nFigure 10, Figure 11 and Figure 12 show the full\nprompts of CoT (GPT-4-generated Prompt).\nFigure 13, Figure 14 and Figure 15 show the full\nprompts used in step 1 of our framework in the\neight-shot setting.\nFigure 16, Figure 17, Figure 18, Figure 19 and\nFigure 20 show the full prompts used in step 2 of\nour framework in the eight-shot setting.\nB.2\nFive-shot examples\nFigure 21 and Figure 22 show the full prompts used\nin step 1 of our framework in the five-shot setting.\nFigure 23, Figure 24 and Figure 25 show the full\nprompts used in step 2 of our framework in the\nfive-shot setting.\nC\nNumber of Questions Using Feedback\non Arithmetic Datasets\nThe statistics of the number of the questions which\nneed feedback and the questions which do not need\nfeedback during inference using our framework on\nGSM8K dataset are shown in Table 7.\nThe statistics of the number of the questions\nthat need feedback and the questions that do not\nneed feedback in our framework on the other six\narithmetic datasets are shown in Table 8.\n12\nQuestion\nCoT (GPT-4 8-shot prompt)\nModelSelection\nART (Ours)\nJohn plans to sell all his toys and use the money to buy video \ngames. He has 13 lego sets and he sells them for $15 each. He \nends up buying 8 video games for $20 each and has $5 left. How \nmany lego sets does he still have?\nLet's \nbreak \ndown \nthe \ninformation provided:\n1.\nJohn has 13 lego sets.\n2. He sells them for $15 each, \nso he earns a total of \\\\(13 \n\\times \\\\$15 = \\\\$195 \\\\).\n3. He uses the money to buy \n8 video games for $20 each, \nwhich costs him a total of \\\\(8 \n\\times \\\\$20 = \\\\$160 \\\\).\n4. He has $5 left after buying \nthe video games.\nSo, John has $30 left from \nselling the lego sets. Since he \nsold each lego set for $15, he \nmust have sold 2 lego sets for \na total of $30.\nTherefore, John still has \\\\(13 \n- 2 = 11\\\\) lego sets.\nThe final answer: 11.\n……\nLet's break down the \nproblem step by step:\n1. John has 13 Lego sets \nand sells them for $15 \neach.\n……\nTherefore, the number of \nLego sets he still has is 0.\n(A) CoT\n(B) PAL\ndef solution():\n    lego_sets_initial = 13\n    lego_set_price = 15\n    ……\n    result = lego_sets_left\n    return result\nSelection:\n(A) can correctly answer \nthe math problem……\nWe know that John has 13 lego sets, (number-of-lego-sets, is, 13).\nHe sells each lego set for $15, (selling-price-per-lego-set, is, $15).\nSo the total amount of money he gets from selling all his lego sets is equal to the number of lego sets he has \nmultiplied by the selling price per lego set, (total-amount-of-money-from-selling-lego-sets, is, number-of-lego-\nsets * selling-price-per-lego-set).\n13 * 15 = 195.\nTherefore, John gets $195 from selling all his lego sets.\nHe buys 8 video games for $20 each, (cost-per-video-game, is, $20) and (number-of-video-games, is, 8).\nSo the total cost of the video games is equal to the number of video games he buys multiplied by the cost per \nvideo game, (total-cost-of-video-games, is, number-of-video-games * cost-per-video-game).\n8 * 20 = 160.\nTherefore, John spends $160 on video games.\nHe has $5 left, (remaining-money, is, $5).\nTo find out how many lego sets he still has, we need to subtract the total cost of the video games and the \nremaining money from the total amount of money he gets from selling all his lego sets, (number-of-lego-sets-\nhe-still-has, is, (total-amount-of-money-from-selling-lego-sets - total-cost-of-video-games - remaining-money) \n/ selling-price-per-lego-set).\n(195 - 160 - 5) / 15 = 2.\nTherefore, John still has 2 lego sets.\nThe final answer: 2.\nStep 1\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_remaining_lego_sets():\n   number_of_lego_sets = 13 # Number of lego sets John has\n   selling_price_per_lego_set = 15 # Selling price of each lego set\n   # Calculate the total amount of money John gets from selling the lego sets.   \n   total_amount_of_money_from_selling_lego_sets = number_of_lego_sets * selling_price_per_lego_set\n   cost_per_video_game = 20 # Cost of each video game\n   number_of_video_games = 8 # Number of video games John buys\n   # Calculate the total cost of the video games John buys\n   total_cost_of_video_games = number_of_video_games * cost_per_video_game\n   remaining_money = 5 # John has $5 left after buying the video games\n   # Calculate the number of lego sets John still has\n   number_of_lego_sets_he_still_has \n= \n(total_amount_of_money_from_selling_lego_sets \n- \ntotal_cost_of_video_games - remaining_money) / selling_price_per_lego_set\n   return f\"The final answer: {int(number_of_lego_sets_he_still_has)} \"\n# Call the function to display the result\nprint(calculate_remaining_lego_sets())\n```\nStep 2\nStep 3: Check consistency\nFigure 9: Comparison of different methods.\nBackbone\n# No Feedback\n# Feedback (one-time)\n# Feedback (two-times)\n# Feedback (three-times)\n# Feedback\nLlama3-8B-Instruct\n1051 (79.7%)\n41 (3.1%)\n20 (1.5%)\n207 (15.7%)\n268 (20.3%)\nChatGPT\n1077 (81.7%)\n34 (2.6%)\n43 (3.3%)\n165 (12.5%)\n242 (18.3%)\nGPT-4o\n1296 (98.3%)\n8 (0.6%)\n4 (0.3%)\n11 (0.8%)\n23 (1.7%)\nTable 7: Number of questions which require feedback during inference using our framework on the GSM8K dataset.\nDataset\n# No Feedback\n# Feedback (one-time)\n# Feedback (two-times)\n# Feedback (three-times)\n# Feedback\nSVAMP\n874 (87.4%)\n27 (2.7%)\n22 (2.2%)\n77 (7.7%)\n126 (12.6%)\nASDIV\n1746 (83.5%)\n13 (0.6%)\n31 (1.5%)\n302 (14.4%)\n346 (16.5%)\nSingleEQ\n477 (93.9%)\n2 (0.4%)\n7 (1.3%)\n22 (4.3%)\n31 (6.1%)\nSingleOP\n548 (97.5%)\n5 (0.9%)\n3 (0.5%)\n6 (1.1%)\n14 (2.5%)\nAddSub\n360 (91.1%)\n2 (0.5%)\n3 (0.8%)\n30 (7.6%)\n35 (8.9%)\nMultiArith\n590 (98.3%)\n4 (0.7%)\n4 (0.7%)\n2 (0.3%)\n10 (1.7%)\nTable 8: Number of questions which need feedback during inference using our framework on SVAMP, ASDIV,\nSingleEQ, SingleOP, AddSub and MultiArith. Note that there are four questions which do not have solutions on\nASDIV because program error occurs.\n13\nSystem Prompt\nYou are a helpful assistant that can solve math problems step by step.\nAnswer the following question. The final answer must be in numeric format, not in words. The final answer should be in \nthis format with only a number shown: 'The final answer: <your answer>.'\nHere is one example:\nQuestion: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did \nNatalia sell altogether in April and May?\nAnswer: To solve this problem, we first need to determine the number of clips Natalia sold in May. It is given that she \nsold half as many clips in May as she did in April. From the problem, we know clips sold in April is 48. Therefore, the \nnumber of clips sold in May is half of 48. 48/2 = 24. Now, we find the total number of clips sold over both April and May \nby adding the clips sold in each month. 48+24= 72. Thus, Natalia sold a total of 72 clips in April and May combined. The \nfinal answer: 72.\nNow it's your turn. Here is another math problem:\nQuestion: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she \nearn?\nQuestion: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her \nparents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more \nmoney does Betty need to buy the wallet?\nQuestion: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many \npages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\nQuestion: James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?\nQuestion: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and \nthere are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. \nHow many flowers does Mark have in his garden?\nQuestion: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large \npizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\nQuestion: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a \nscale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough \nbrownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough \ngummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?\nUser Prompt\nFigure 10: The system prompt and user prompt of the eight-shot example of CoT (GPT-4-Generated Prompt).\n14\nAssistant Prompt\nAnswer: To calculate Weng's earnings for 50 minutes of babysitting at $12 per hour, you need to convert the time to \nhours. Since there are 60 minutes in an hour, 50 minutes is \\( \\frac{50}{60} = \\frac{5}{6} \\) of an hour.\nNow, multiply the fraction of an hour by Weng's hourly rate to find her earnings:\n\\[ \\frac{5}{6} \\times \\$12 = \\$10 \\]\nSo, Weng earned $10 for 50 minutes of babysitting.\nThe final answer: 10.\nAnswer: First, let's calculate how much money Betty has saved so far:\n1. Betty has half of the money she needs for the wallet, which is \\( \\frac{1}{2} \\times \\$100 = \\$50 \\).\n2. Her parents gave her an additional $15.\n3. Her grandparents gave her twice as much as her parents, so that's \\( 2 \\times \\$15 = \\$30 \\).\nNow, let's add up all the money Betty has:\n\\[ \\$50 (Betty's savings) + \\$15 (from parents) + \\$30 (from grandparents) = \\$50 + \\$15 + \\$30 = \\$95 \\]\nBetty now has $95. To find out how much more she needs, subtract the total amount she has from the cost of the wallet:\n\\[ \\$100 (cost of wallet) - \\$95 (total money saved) = \\$5 \\]\nSo, Betty still needs $5 more to buy the wallet.\nThe final answer: 5.\nAnswer: Let's break down the information given:\n1. Julie is reading a 120-page book.\n2. Yesterday, she read 12 pages.\n3. Today, she read twice as many pages as yesterday, which is \\(2 \\times 12 = 24\\) pages.\n4. So far, she has read \\(12 + 24 = 36\\) pages.\nTo find out how many pages she has left to read:\n\\[ \\text{Total pages} - \\text{Pages read} = 120 - 36 = 84 \\text{ pages left} \\]\nIf Julie wants to read half of the remaining pages tomorrow, she should read \\( \\frac{1}{2} \\times 84 = 42 \\) pages.\nSo, Julie should read 42 pages tomorrow.\nThe final answer: 42.\nAnswer: Let's break down the information provided:\n1. James writes a 3-page letter to 2 different friends.\n2. He does this twice a week.\nSo, the total number of pages James writes in a week is:\n\\[ 3 \\text{ pages/letter} \\times 2 \\text{ letters} \\times 2 \\text{ times a week} = 12 \\text{ pages/week} \\]\nTo find out how many pages he writes in a year, we need to multiply the number of pages he writes per week by the \nnumber of weeks in a year. There are typically 52 weeks in a year.\n\\[ 12 \\text{ pages/week} \\times 52 \\text{ weeks/year} = 624 \\text{ pages/year} \\]\nSo, James writes 624 pages in a year.\nThe final answer: 624.\nFigure 11: The assistant prompt of the eight-shot example of CoT (GPT-4-Generated Prompt).\n15\nAssistant Prompt (continued)\nAnswer: Let's break down the information provided:\n1. Mark has flowers of three different colors: yellow, purple, and green.\n2. There are ten yellow flowers.\n3. There are 80% more purple flowers than yellow flowers.\n4. There are 25% as many green flowers as there are yellow and purple flowers combined.\nFirst, let's find out how many purple flowers there are:\n80% more purple flowers than yellow flowers means there are \\( 10 + 80\\% \\) of 10 purple flowers.\n\\[ 80\\% \\text{ of } 10 = 0.80 \\times 10 = 8 \\]\nSo, there are \\( 10 + 8 = 18 \\) purple flowers.\nNow, let's find out how many yellow and purple flowers there are combined:\n\\[ 10 \\text{ yellow flowers} + 18 \\text{ purple flowers} = 28 \\text{ flowers (yellow and purple)} \\]\nNow, let's find out how many green flowers there are:\nThere are 25% as many green flowers as there are yellow and purple flowers combined. So, it's \\( 25\\% \\) of 28:\n\\[ 25\\% \\text{ of } 28 = 0.25 \\times 28 = 7 \\]\nSo, there are 7 green flowers.\nTo find the total number of flowers, we add up the number of flowers of each color:\n\\[ 10 \\text{ yellow flowers} + 18 \\text{ purple flowers} + 7 \\text{ green flowers} = 35 \\text{ flowers} \\]\nSo, Mark has 35 flowers in his garden.\nThe final answer: 35.\nAnswer: To find out how many pieces of pizza Albert eats in one day, we first need to calculate the total number of slices.\nFor the large pizzas:\n\\[ 2 \\text{ large pizzas} \\times 16 \\text{ slices per pizza} = 32 \\text{ slices} \\]\nFor the small pizzas:\n\\[ 2 \\text{ small pizzas} \\times 8 \\text{ slices per pizza} = 16 \\text{ slices} \\]\nNow, let's add up the slices from both the large and small pizzas to find the total number of pieces of pizza Albert eats in \none day:\n\\[ 32 \\text{ slices from large pizzas} + 16 \\text{ slices from small pizzas} = 48 \\text{ slices} \\]\nSo, Albert eats 48 pieces of pizza in one day.\nThe final answer: 48.\nAnswer: Let's break down the steps Ken took:\n1. Ken placed a box on a scale, making its weight 0 pounds.\n2. He poured enough jelly beans to bring the weight to 2 pounds.\n3. He added enough brownies to cause the weight to triple, so the weight became \\(2 \\times 3 = 6\\) pounds.\n4. Next, he added another 2 pounds of jelly beans, bringing the weight to \\(6 + 2 = 8\\) pounds.\n5. Finally, he added enough gummy worms to double the weight again, making the final weight \\(8 \\times 2 = 16\\) pounds.\nSo, the final weight of the box of goodies is 16 pounds.\nThe final answer: 16.\nFigure 12: The assistant prompt of the eight-shot example of CoT (GPT-4-Generated Prompt) (continued).\n16\nSystem Prompt\nYou are a helpful assistant that can solve math problems step by step with relation triples. \nAnswer the following question. Write your thoughts first. Please make sure when you make a statement that includes \nreasoning, you must always write down those reasoning steps as relation triples. The final answer must be in numeric \nformat, not in words. The final answer should be in the format with only a number shown: 'The final answer: <your \nanswer>.'\nQuestion: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did \nNatalia sell altogether in April and May?\nAnswer: First we know that Natalia sold clips to 48 of her friends in April, (number-of-clips-sold-in-Apirl, is, 48).\nShe sold half as many clips in May, (number-of-clips-sold-in-May, is, number-of-clips-sold-in-Apirl / 2).\n48 / 2 = 24.\nShe sold 24 clips in May.\nThe problem we want to solve is 'How many clips did Natalia sell altogether in April and May'.\nTo find the total number of clips sold in April and May, we add the clips sold in each month, (number-clips-sold-in-April-\nand-May, is, number-of-clips-sold-in-Apirl + number-of-clips-sold-in-May). \n48 + 24 = 72.\nThus, Natalia sold a total of 72 clips in April and May combined.\nThe final answer: 72.\nNow it's your turn. Here is another math problem:\nQuestion: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she \nearn?\nQuestion: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her \nparents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more \nmoney does Betty need to buy the wallet?\nQuestion: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many \npages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\nQuestion: James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?\nQuestion: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large \npizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\nQuestion: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a \nscale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough \nbrownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough \ngummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?\nQuestion: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and \nthere are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. \nHow many flowers does Mark have in his garden?\nUser Prompt\nFigure 13: The system prompt and user prompt of the eight-shot example in step 1 of our framework.\n17\nAssistant Prompt\nAnswer: First, we know that Weng earns $12 an hour for babysitting, (earning-per-hour, is, $12). \nYesterday, she did 50 minutes of babysitting, (minutes-weng-worked, is, 50). \nThe question we want to solve is 'How much did she earn', (earnings-during-this-babysitting, is, ?). \nTo find out her earnings, we need to calculate how much Weng earns per minute, (earning-per-minute, is, ?).\nSince there are 60 minutes in an hour, (minutes-in-an-hour, is, 60), we can determine her per-minute earnings, (earning-\nper-minute, is, earning-per-hour / minutes-in-an-hour).\nTherefore, $12 divided by 60 minutes equals $0.2 per minute.\nSo Weng earns $0.2 per minute of babysitting.\nTo find out her earnings for this duration, we multiply her per-minute earnings by the number of minutes she worked, \n(earnings-during-this-babysitting, is, earning-per-minute * minutes-weng-worked).\nTherefore, $0.2 multiplied by 50 minutes equals $10.\nThus, Weng earned $10 for 50 minutes of babysitting.\nThe final answer: 10.\nAnswer: First, we know that the new wallet costs $100, (cost-of-wallet, is, $100).\nBetty has half of the money she needs for the wallet, (money-betty-has, is, cost-of-wallet / 2).\n100 / 2 = 50.\nBetty has $50.\nHer parents gave her $15, (money-parents-gave, is, $15). \nHer grandparents gave her twice as much as her parents, (money-grandparents-gave, is, money-parents-gave * 2).\n15 * 2 = 30.\nSo her grandparents gave her $30.\nThe question is 'How much more money does Betty need to buy the wallet', (money-betty-needs, is, ?).\nAdding these amounts together will tell us how much money Betty currently has, (money-betty-has, is, money-betty-has + \nmoney-parents-gave + money-grandparents-gave). \n$50 + $15 + $30 = $95. \nBetty has $95, (money-betty-has, is, $95). \nTo find out how much more she needs to buy the wallet, we subtract the total amount she has from the cost of the wallet, \n(money-betty-needs, is, cost-of-wallet - money-betty-has). \n100 - 95 = 5. \nBetty still needs $5 to buy the wallet.\nThe final answer: 5.\nAnswer: We know that the book has 120 pages, (total-number-of-pages-in-book, is, 120).\nYesterday, Julie read 12 pages, (number-of-pages-read-yesterday, is, 12).\nToday, she read twice as many pages as yesterday, (number-of-pages-read-today, is, number-of-pages-read-yesterday * 2). \n12 * 2 = 24. \nThe question is 'If she wants to read half of the remaning pages tomorrow, how many pages should she read'.\nSo first we need to calculate the remaining pages she has to read. \nThe number of pages left in the book is equal to the total number of pages minus the number of pages she read in the \nprevious two days, (number-of-pages-julie-has-left-to-read, is, total-number-of-pages-in-book - number-of-pages-read-\ntoday - number-of-pages-read-today).\n120 - 12 - 24 = 84. \nJulie has 84 pages left to read. \nTo find out how many pages she should read tomorrow, we calculate half of the remaining pages, (number-of-pages-julie-\nshould-read-tomorrow, is, number-of-pages-julie-has-left-to-read / 2). \n84 / 2 = 42. \nTherefore, Julie should read 42 pages tomorrow.\nThe final answer: 42.\nFigure 14: The assistant prompt of the eight-shot example in step 1 of our framework.\n18\nAnswer: We know that James writes a 3-page letter to 2 different frients twice a week, (number-pages-per-letter, is, 3). \nBecause he has two friends, (number-of-friends, is, 2). \nSo each time he writes, he writes 6 pages, (number-pages-each-time, is, number-pages-per-letter * number-of-friends). \nSince he writes twice a week, (number-of-times-per-week, is, 2).\nTherefore, the number of pages written per week is equal to the number of times James write per week multiplied by the \nnumber of pages he write each time, (number-pages-per-week, is, number-pages-each-time * number-of-times-per-week). \n6 * 2 = 12.\nSo there are 12 pages written per week.\nThere are approximately 52 weeks in a year, (number-of-weeks-in-a-year, is, 52).\nSo, the total number of pages James writes in a year is equal to the number of pages he writes per week multiplied by the \nnumber of weeks in a year, (number-pages-per-year, is, number-pages-per-week * number-of-weeks-in-a-year). \n12 * 52 = 624.\nJames writes 624 pages a year to his friends.\nThe final answer: 624.\nAnswer: We know that Albert buys 2 large pizzas and 2 small pizzas, (number-of-large-pizzas, is, 2) and (number-of-\nsmall-pizzas, is, 2).\nA large pizza has 16 slices, (slices-per-large-pizza, is, 16).\nSo the total slices from large pizzas is equal to the number of slices per large pizza multiplied by the number of large \npizzas, (total-slices-from-large-pizzas, is, number-of-large-pizzas * slices-per-large-pizza).\n2 * 16 = 32.\nTherefore, the total slices from large pizzas is 32.\nA small pizza has 8 slices, (slices-per-small-pizza, is, 8).\nSo the total slices from small pizzas is equal to the number of slices per small pizza multiplied by the number of small \npizzas, (total-slices-from-small-pizzas, is, number-of-small-pizzas * slices-per-small-pizza).\n2 * 8 = 16.\nTherefore, the total slices from small pizzas is 16.\nTo find the total number of pieces of pizza Albert eats in one day, we add the slices from both the large and small pizzas, \n(total-slices-for-the-day, is, total-slices-from-large-pizzas + total-slices-from-small-pizzas).\n32 + 16 = 48.\nThus, Albert eats 48 pieces of pizza in one day.\nThe final answer: 48.\nAnswer: We know that Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the \nweight to 2 pounds, so the initial weight is 2 pounds, (current-weight, is, 2 pounds).\nThen, he added enough brownies to cause the weight to triple, (current-weight, is, current-weight * 3).\n2 * 3 = 6.\nNext, he added another 2 pounds of jelly beans, (current-weight, is, current-weight + 2).\n6 + 2 = 8.\nAnd finally, he added enough gummy worms to double the weight once again, (final-weight, is, current-weight * 2).\n8 * 2 = 16.\nSo, the final weight of the box of goodies is 16 pounds.\nThe final answer: 16.\nAnswer: We know that number of yellow flowers is 10, (number-of-yellow-flowers, is, 10).\nThere are 80% more purple flowers than yellow flowers, (number-of-purple-flowers, is, 80%-more-than-number-of-\nyellow-flowers).\n10 * (1 + 0.80) = 10 * 1.80 = 18.\nSo there are 18 purple flowers.\nThe total number of yellow and purple flowers is the sum of yellow and purple flowers, (total-number-of-yellow-and-\npurple-flowers, is, number-of-yellow-flowers + number-of-purple-flowers). \n10 + 18 = 28.\nThere are only 25% as many green flowers as there are yellow and purple flowers, (number-of-green-flowers, is, 25%-of-\ntotal-number-of-yellow-and-purple-flowers).\n28 * 0.25 = 7.\nSo there are 7 green flowers.\nThe question is 'How many flowers does Mark have in his garden', so we need to calculate the total number of flowers, \n(total-number-of-flowers, is, number-of-yellow-flowers + number-of-purple-flowers + number-of-green-flowers).\n10 + 18 + 7 = 35.\nMark has 35 flowers in his garden.\nThe final answer: 35.\nAssistant Prompt (continued)\nFigure 15: The assistant prompt of the eight-shot example in step 1 of our framework (continued).\n19\nSystem Prompt\nYou are a helpful assistant capable of solving math problems by using Python functions, based on the question provided \nand its reasoning steps which are formatted as relation triples.\nGiven a question and its answer's thinking process in format of relation triples. Write a python function to solve the \nquestion based on those relation triples with the markdown format, that is, ```python\\n<your code>\\n```. The output of the \nfunction should be in this format with only a number shown: 'The final answer: <your answer>'.\nQuestion: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did \nNatalia sell altogether in April and May?\nThinking process in relation triple format:\n(number-of-clips-sold-in-Apirl, is, 48)\n(number-of-clips-sold-in-May, is, number-of-clips-sold-in-Apirl / 2)\n(number-clips-sold-in-April-and-May, is, number-of-clips-sold-in-Apirl + number-of-clips-sold-in-May)\nHere is a Python function based on the given relation triples:\n```python\ndef total_clips_sold():\n    number_of_clips_sold_in_April = 48\n    number_of_clips_sold_in_May = number_of_clips_sold_in_April / 2\n    number_clips_sold_in_April_and_May = number_of_clips_sold_in_April + number_of_clips_sold_in_May\n    return f\"The final answer: {int(number_clips_sold_in_April_and_May)}\"\n# Call the function to display the result\nprint(total_clips_sold())\n```\nNow it's your turn.\nQuestion: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she \nearn?\nThinking process in relation triple format:\n(earning-per-hour, is, $12)\n(minutes-weng-worked, is, 50)\n(earnings-during-this-babysitting, is, ?)\n(earning-per-minute, is, ?)\n(minutes-in-an-hour, is, 60)\n(earning-per-minute, is, earning-per-hour / minutes-in-an-hour)\n(earnings-during-this-babysitting, is, earning-per-minute * minutes-weng-worked)\nQuestion: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her \nparents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more \nmoney does Betty need to buy the wallet?\nThinking process in relation triple format:\n(cost-of-wallet, is, $100)\n(money-betty-has, is, cost-of-wallet / 2)\n(money-parents-gave, is, $15)\n(money-grandparents-gave, is, money-parents-gave * 2)\n(money-betty-needs, is, ?)\n(money-betty-has, is, money-betty-has + money-parents-gave + money-grandparents-gave)\n(money-betty-has, is, $95)\n(money-betty-needs, is, cost-of-wallet - money-betty-has)\nUser Prompt\nFigure 16: The system prompt and user prompt of the eight-shot example in step 2 of our framework.\n20\nUser Prompt (continued)\nQuestion: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many \npages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\nThinking process in relation triple format:\n(total-number-of-pages-in-book, is, 120)\n(number-of-pages-read-yesterday, is, 12)\n(number-of-pages-read-today, is, number-of-pages-read-yesterday * 2)\n(number-of-pages-julie-has-left-to-read, is, total-number-of-pages-in-book - number-of-pages-read-today - number-of-\npages-read-today)\n(number-of-pages-julie-should-read-tomorrow, is, number-of-pages-julie-has-left-to-read / 2)\nQuestion: James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?\nThinking process in relation triple format:\n(number-pages-per-letter, is, 3)\n(number-of-friends, is, 2)\n(number-pages-each-time, is, number-pages-per-letter * number-of-friends)\n(number-of-times-per-week, is, 2)\n(number-pages-per-week, is, number-pages-each-time * number-of-times-per-week)\n(number-of-weeks-in-a-year, is, 52)\n(number-pages-per-year, is, number-pages-per-week * number-of-weeks-in-a-year)\nQuestion: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large \npizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\nThinking process in relation triple format:\n(number-of-large-pizzas, is, 2)\n(number-of-small-pizzas, is, 2)\n(slices-per-large-pizza, is, 16)\n(total-slices-from-large-pizzas, is, number-of-large-pizzas * slices-per-large-pizza)\n(slices-per-small-pizza, is, 8)\n(total-slices-from-small-pizzas, is, number-of-small-pizzas * slices-per-small-pizza)\n(total-slices-for-the-day, is, total-slices-from-large-pizzas + total-slices-from-small-pizzas)\nQuestion: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a \nscale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough \nbrownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough \ngummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?\nThinking process in relation triple format:\n(current-weight, is, 2 pounds)\n(current-weight, is, current-weight * 3)\n(current-weight, is, current-weight + 2)\n(final-weight, is, current-weight * 2)\nQuestion: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and \nthere are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. \nHow many flowers does Mark have in his garden?\nThinking process in relation triple format:\n(number-of-yellow-flowers, is, 10)\n(number-of-purple-flowers, is, 80%-more-than-number-of-yellow-flowers)\n(total-number-of-yellow-and-purple-flowers, is, number-of-yellow-flowers + number-of-purple-flowers)\n(number-of-green-flowers, is, 25%-of-total-number-of-yellow-and-purple-flowers)\n(total-number-of-flowers, is, number-of-yellow-flowers + number-of-purple-flowers + number-of-green-flowers)\nFigure 17: The user prompt of the eight-shot example in step 2 of our framework (continued).\n21\nAssistant Prompt\nHere is a Python function to solve the question based on the relation triples:\n```python\ndef calculate_earnings():\n    earning_per_hour = 12  # Weng's hourly rate\n    minutes_weng_worked = 50  # Minutes she worked\n    minutes_in_an_hour = 60  # Total minutes in an hour\n    \n    # Calculate the earning per minute\n    earning_per_minute = earning_per_hour / minutes_in_an_hour\n    \n    # Calculate the earnings for the actual minutes worked\n    earnings_during_this_babysitting = earning_per_minute * minutes_weng_worked\n    return f\"The final answer: {earnings_during_this_babysitting:.2f}\"\n# Call the function to display the result\nprint(calculate_earnings())\n```\nHere is a Python function to solve the question based on the given relation triples:\n```python\ndef calculate_additional_money_needed():\n    cost_of_wallet = 100  # The cost of the wallet Betty wants to buy\n    money_betty_has = cost_of_wallet / 2  # Betty initially has half of the money needed\n    \n    money_parents_gave = 15  # Amount given by Betty's parents\n    money_grandparents_gave = money_parents_gave * 2  # Grandparents gave twice as much as her parents\n    \n    # Calculate the total amount of money Betty currently has\n    money_betty_has += money_parents_gave + money_grandparents_gave\n    \n    # Calculate how much more money Betty needs to buy the wallet\n    money_betty_needs = cost_of_wallet - money_betty_has\n    return f\"The final answer: {money_betty_needs}\"\n# Call the function to display the result\nprint(calculate_additional_money_needed())\n```\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_pages_to_read_tomorrow():\n    total_number_of_pages_in_book = 120  # Total pages in the book\n    number_of_pages_read_yesterday = 12  # Pages Julie read yesterday\n    \n    # Pages Julie read today, twice the amount she read yesterday\n    number_of_pages_read_today = number_of_pages_read_yesterday * 2\n    \n    # Calculate remaining pages after yesterday and today's reading\n    number_of_pages_julie_has_left_to_read = total_number_of_pages_in_book - (number_of_pages_read_yesterday + \nnumber_of_pages_read_today)\n    \n    # Julie wants to read half of the remaining pages tomorrow\n    number_of_pages_julie_should_read_tomorrow = number_of_pages_julie_has_left_to_read / 2\n    return f\"The final answer: {int(number_of_pages_julie_should_read_tomorrow)}\"\n# Call the function to display the result\nprint(calculate_pages_to_read_tomorrow())\n```\nFigure 18: The assistant prompt of the eight-shot example in step 2 of our framework.\n22\nAssistant Prompt (continued)\nHere's a Python function to solve the question based on the given relation triples:\n```python\ndef calculate_annual_pages_written():\n    number_pages_per_letter = 3  # Each letter has 3 pages\n    number_of_friends = 2  # James writes to 2 different friends\n    \n    # Calculate the number of pages each time he writes\n    number_pages_each_time = number_pages_per_letter * number_of_friends\n    \n    number_of_times_per_week = 2  # He writes twice a week\n    \n    # Calculate the total number of pages written per week\n    number_pages_per_week = number_pages_each_time * number_of_times_per_week\n    \n    number_of_weeks_in_a_year = 52  # Number of weeks in a year\n    \n    # Calculate the total number of pages James writes in a year\n    number_pages_per_year = number_pages_per_week * number_of_weeks_in_a_year\n    return f\"The final answer: {number_pages_per_year}\"\n# Call the function to display the result\nprint(calculate_annual_pages_written())\n```\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_total_pizza_slices():\n    number_of_large_pizzas = 2  # Albert buys 2 large pizzas\n    slices_per_large_pizza = 16  # Each large pizza has 16 slices\n    \n    # Calculate total slices from large pizzas\n    total_slices_from_large_pizzas = number_of_large_pizzas * slices_per_large_pizza\n    \n    number_of_small_pizzas = 2  # Albert buys 2 small pizzas\n    slices_per_small_pizza = 8  # Each small pizza has 8 slices\n    \n    # Calculate total slices from small pizzas\n    total_slices_from_small_pizzas = number_of_small_pizzas * slices_per_small_pizza\n    \n    # Total number of slices Albert can eat in one day\n    total_slices_for_the_day = total_slices_from_large_pizzas + total_slices_from_small_pizzas\n    return f\"The final answer: {total_slices_for_the_day}\"\n# Call the function to display the result\nprint(calculate_total_pizza_slices())\n```\nFigure 19: The assistant prompt of the eight-shot example in step 2 of our framework (continued).\n23\nAssistant Prompt (continued)\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_final_weight():\n    current_weight = 2  # Ken first adds jelly beans to make the box weigh 2 pounds.\n    \n    current_weight *= 3  # After adding brownies, the weight triples.\n    \n    current_weight += 2  # Ken adds another 2 pounds of jelly beans.\n    \n    final_weight = current_weight * 2  # Finally, after adding gummy worms, the weight doubles.\n    \n    return f\"The final answer: {final_weight}\"\n# Call the function to display the result\nprint(calculate_final_weight())\n```\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_total_flowers():\n    number_of_yellow_flowers = 10  # Number of yellow flowers\n    number_of_purple_flowers = int(number_of_yellow_flowers * 1.8)  # 80% more purple flowers than yellow\n    \n    # Calculate the total number of yellow and purple flowers\n    total_number_of_yellow_and_purple_flowers = number_of_yellow_flowers + number_of_purple_flowers\n    \n    # 25% of the total number of yellow and purple flowers are green\n    number_of_green_flowers = int(0.25 * total_number_of_yellow_and_purple_flowers)\n    \n    # Sum of all flowers in the garden\n    total_number_of_flowers = number_of_yellow_flowers + number_of_purple_flowers + number_of_green_flowers\n    return f\"The final answer: {total_number_of_flowers}\"\n# Call the function to display the result\nprint(calculate_total_flowers())\n```\nFigure 20: The assistant prompt of the eight-shot example in step 2 of our framework (continued).\n24\nSystem Prompt\nUser Prompt\nYou are a helpful assistant that can solve math problems step by step with relation triples. \nAnswer the following question. Write your thoughts first. Please make sure when you make a statement that includes \nreasoning, you must always write down those reasoning steps as relation triples. The final answer must be in numeric \nformat, not in words. The final answer should be in the format with only a number shown: 'The final answer: <your \nanswer>.\nQuestion: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips \ndid Natalia sell altogether in April and May?\nAnswer: First we know that Natalia sold clips to 48 of her friends in April, (number-of-clips-sold-in-Apirl, is, 48).\nShe sold half as many clips in May, (number-of-clips-sold-in-May, is, number-of-clips-sold-in-Apirl / 2).\n48 / 2 = 24.\nShe sold 24 clips in May.\nThe problem we want to solve is 'How many clips did Natalia sell altogether in April and May'.\nTo find the total number of clips sold in April and May, we add the clips sold in each month, (number-clips-sold-in-\nApril-and-May, is, number-of-clips-sold-in-Apirl + number-of-clips-sold-in-May). \n48 + 24 = 72.\nThus, Natalia sold a total of 72 clips in April and May combined.\nThe final answer: 72.\nNow it's your turn. Here is another math problem:\nQuestion: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she \nearn?\nQuestion: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large \npizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\nQuestion: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a \nscale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough \nbrownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough \ngummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?\nQuestion: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and \nthere are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. \nHow many flowers does Mark have in his garden?\nFigure 21: The system and user prompt of the five-shot example in step 1 of our framework.\n25\nAssistant Prompt\nAnswer: First, we know that Weng earns $12 an hour for babysitting, (earning-per-hour, is, $12). \nYesterday, she did 50 minutes of babysitting, (minutes-weng-worked, is, 50). \nThe question we want to solve is 'How much did she earn', (earnings-during-this-babysitting, is, ?). \nTo find out her earnings, we need to calculate how much Weng earns per minute, (earning-per-minute, is, ?).\nSince there are 60 minutes in an hour, (minutes-in-an-hour, is, 60), we can determine her per-minute earnings, (earning-\nper-minute, is, earning-per-hour / minutes-in-an-hour).\nTherefore, $12 divided by 60 minutes equals $0.2 per minute.\nSo Weng earns $0.2 per minute of babysitting.\nTo find out her earnings for this duration, we multiply her per-minute earnings by the number of minutes she worked, \n(earnings-during-this-babysitting, is, earning-per-minute * minutes-weng-worked).\nTherefore, $0.2 multiplied by 50 minutes equals $10.\nThus, Weng earned $10 for 50 minutes of babysitting.\nThe final answer: 10.\nAnswer: We know that Albert buys 2 large pizzas and 2 small pizzas, (number-of-large-pizzas, is, 2) and (number-of-\nsmall-pizzas, is, 2).\nA large pizza has 16 slices, (slices-per-large-pizza, is, 16).\nSo the total slices from large pizzas is equal to the number of slices per large pizza multiplied by the number of large \npizzas, (total-slices-from-large-pizzas, is, number-of-large-pizzas * slices-per-large-pizza).\n2 * 16 = 32.\nTherefore, the total slices from large pizzas is 32.\nA small pizza has 8 slices, (slices-per-small-pizza, is, 8).\nSo the total slices from small pizzas is equal to the number of slices per small pizza multiplied by the number of small \npizzas, (total-slices-from-small-pizzas, is, number-of-small-pizzas * slices-per-small-pizza).\n2 * 8 = 16.\nTherefore, the total slices from small pizzas is 16.\nTo find the total number of pieces of pizza Albert eats in one day, we add the slices from both the large and small pizzas, \n(total-slices-for-the-day, is, total-slices-from-large-pizzas + total-slices-from-small-pizzas).\n32 + 16 = 48.\nThus, Albert eats 48 pieces of pizza in one day.\nThe final answer: 48.\nAnswer: We know that Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the \nweight to 2 pounds, so the initial weight is 2 pounds, (current-weight, is, 2 pounds).\nThen, he added enough brownies to cause the weight to triple, (current-weight, is, current-weight * 3).\n2 * 3 = 6.\nNext, he added another 2 pounds of jelly beans, (current-weight, is, current-weight + 2).\n6 + 2 = 8.\nAnd finally, he added enough gummy worms to double the weight once again, (final-weight, is, current-weight * 2).\n8 * 2 = 16.\nSo, the final weight of the box of goodies is 16 pounds.\nThe final answer: 16.\nAnswer: We know that number of yellow flowers is 10, (number-of-yellow-flowers, is, 10).\nThere are 80% more purple flowers than yellow flowers, (number-of-purple-flowers, is, 80%-more-than-number-of-\nyellow-flowers).\n10 * (1 + 0.80) = 10 * 1.80 = 18.\nSo there are 18 purple flowers.\nThe total number of yellow and purple flowers is the sum of yellow and purple flowers, (total-number-of-yellow-and-\npurple-flowers, is, number-of-yellow-flowers + number-of-purple-flowers). \n10 + 18 = 28.\nThere are only 25% as many green flowers as there are yellow and purple flowers, (number-of-green-flowers, is, 25%-of-\ntotal-number-of-yellow-and-purple-flowers).\n28 * 0.25 = 7.\nSo there are 7 green flowers.\nThe question is 'How many flowers does Mark have in his garden', so we need to calculate the total number of flowers, \n(total-number-of-flowers, is, number-of-yellow-flowers + number-of-purple-flowers + number-of-green-flowers).\n10 + 18 + 7 = 35.\nMark has 35 flowers in his garden.\nThe final answer: 35.\nFigure 22: The assistant prompt of the five-shot example in step 1 of our framework.\n26\nSystem Prompt\nUser Prompt\nYou are a helpful assistant capable of solving math problems by using Python functions, based on the question provided \nand its reasoning steps which are formatted as relation triples.\nGiven a question and its answer's thinking process in format of relation triples. Write a python function to solve the \nquestion based on those relation triples with the markdown format, that is, ```python\\n<your code>\\n```. The output of the \nfunction should be in this format with only a number shown: 'The final answer: <your answer>'.\nQuestion: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips \ndid Natalia sell altogether in April and May?\nThinking process in relation triple format:\n(number-of-clips-sold-in-Apirl, is, 48)\n(number-of-clips-sold-in-May, is, number-of-clips-sold-in-Apirl / 2)\n(number-clips-sold-in-April-and-May, is, number-of-clips-sold-in-Apirl + number-of-clips-sold-in-May)\nHere is a Python function based on the given relation triples:\n```python\ndef total_clips_sold():\nnumber_of_clips_sold_in_April = 48\nnumber_of_clips_sold_in_May = number_of_clips_sold_in_April / 2\nnumber_clips_sold_in_April_and_May = number_of_clips_sold_in_April + number_of_clips_sold_in_May\nreturn f\"The final answer: {int(number_clips_sold_in_April_and_May)}\"\n# Call the function to display the result\nprint(total_clips_sold())\n```\nNow it's your turn.\nQuestion: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she \nearn?\nThinking process in relation triple format:\n(earning-per-hour, is, $12)\n(minutes-weng-worked, is, 50)\n(earnings-during-this-babysitting, is, ?)\n(earning-per-minute, is, ?)\n(minutes-in-an-hour, is, 60)\n(earning-per-minute, is, earning-per-hour / minutes-in-an-hour)\n(earnings-during-this-babysitting, is, earning-per-minute * minutes-weng-worked)\nQuestion: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large \npizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\nThinking process in relation triple format:\n(number-of-large-pizzas, is, 2)\n(number-of-small-pizzas, is, 2)\n(slices-per-large-pizza, is, 16)\n(total-slices-from-large-pizzas, is, number-of-large-pizzas * slices-per-large-pizza)\n(slices-per-small-pizza, is, 8)\n(total-slices-from-small-pizzas, is, number-of-small-pizzas * slices-per-small-pizza)\n(total-slices-for-the-day, is, total-slices-from-large-pizzas + total-slices-from-small-pizzas)\nFigure 23: The system and user prompt of the five-shot example in step 2 of our framework.\n27\nUser Prompt (continued)\nQuestion: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a \nscale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough \nbrownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough \ngummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?\nThinking process in relation triple format:\n(current-weight, is, 2 pounds)\n(current-weight, is, current-weight * 3)\n(current-weight, is, current-weight + 2)\n(final-weight, is, current-weight * 2)\nQuestion: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and \nthere are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. \nHow many flowers does Mark have in his garden?\nThinking process in relation triple format:\n(number-of-yellow-flowers, is, 10)\n(number-of-purple-flowers, is, 80%-more-than-number-of-yellow-flowers)\n(total-number-of-yellow-and-purple-flowers, is, number-of-yellow-flowers + number-of-purple-flowers)\n(number-of-green-flowers, is, 25%-of-total-number-of-yellow-and-purple-flowers)\n(total-number-of-flowers, is, number-of-yellow-flowers + number-of-purple-flowers + number-of-green-flowers)\nFigure 24: The user prompt of the five-shot example in step 2 of our framework (continued).\n28\nAssistant Prompt\nHere is a Python function to solve the question based on the relation triples:\n```python\ndef calculate_earnings():\n    earning_per_hour = 12 # Weng's hourly rate\n    minutes_weng_worked = 50 # Minutes she worked\n    minutes_in_an_hour = 60 # Total minutes in an hour\n    # Calculate the earning per minute\n    earning_per_minute = earning_per_hour / minutes_in_an_hour\n    # Calculate the earnings for the actual minutes worked\n    earnings_during_this_babysitting = earning_per_minute * minutes_weng_worked\nreturn f\"The final answer: {earnings_during_this_babysitting:.2f}\"\n# Call the function to display the result\nprint(calculate_earnings())\n```\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_total_pizza_slices():\n    number_of_large_pizzas = 2 # Albert buys 2 large pizzas\n    slices_per_large_pizza = 16 # Each large pizza has 16 slices\n    # Calculate total slices from large pizzas\n    total_slices_from_large_pizzas = number_of_large_pizzas * slices_per_large_pizza\n    number_of_small_pizzas = 2 # Albert buys 2 small pizzas\n    slices_per_small_pizza = 8 # Each small pizza has 8 slices\n    # Calculate total slices from small pizzas\n    total_slices_from_small_pizzas = number_of_small_pizzas * slices_per_small_pizza\n    # Total number of slices Albert can eat in one day\n    total_slices_for_the_day = total_slices_from_large_pizzas + total_slices_from_small_pizzas\nreturn f\"The final answer: {total_slices_for_the_day}\"\n# Call the function to display the result\nprint(calculate_total_pizza_slices())\n```\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_final_weight():\n    current_weight = 2 # Ken first adds jelly beans to make the box weigh 2 pounds.\n    current_weight *= 3 # After adding brownies, the weight triples.\n    current_weight += 2 # Ken adds another 2 pounds of jelly beans.\n    final_weight = current_weight * 2 # Finally, after adding gummy worms, the weight doubles.\nreturn f\"The final answer: {final_weight}\"\n# Call the function to display the result\nprint(calculate_final_weight())\n```\nHere's a Python function to solve the question based on the relation triples provided:\n```python\ndef calculate_total_flowers():\n    number_of_yellow_flowers = 10 # Number of yellow flowers\n    number_of_purple_flowers = int(number_of_yellow_flowers * 1.8) # 80% more purple flowers than yellow\n    # Calculate the total number of yellow and purple flowers\n    total_number_of_yellow_and_purple_flowers = number_of_yellow_flowers + number_of_purple_flowers\n    # 25% of the total number of yellow and purple flowers are green\n    number_of_green_flowers = int(0.25 * total_number_of_yellow_and_purple_flowers)\n    # Sum of all flowers in the garden\n    total_number_of_flowers = number_of_yellow_flowers + number_of_purple_flowers + number_of_green_flowers\nreturn f\"The final answer: {total_number_of_flowers}\"\n# Call the function to display the result\nprint(calculate_total_flowers())\n```\nFigure 25: The assistant prompt of the five-shot example in step 2 of our framework.\n29\n",
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "published": "2024-06-25",
  "updated": "2024-06-25"
}