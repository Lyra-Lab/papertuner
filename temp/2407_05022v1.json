{
  "id": "http://arxiv.org/abs/2407.05022v1",
  "title": "A Principled Framework for Evaluating on Typologically Diverse Languages",
  "authors": [
    "Esther Ploeger",
    "Wessel Poelman",
    "Andreas Holck Høeg-Petersen",
    "Anders Schlichtkrull",
    "Miryam de Lhoneux",
    "Johannes Bjerva"
  ],
  "abstract": "Beyond individual languages, multilingual natural language processing (NLP)\nresearch increasingly aims to develop models that perform well across languages\ngenerally. However, evaluating these systems on all the world's languages is\npractically infeasible. To attain generalizability, representative language\nsampling is essential. Previous work argues that generalizable multilingual\nevaluation sets should contain languages with diverse typological properties.\nHowever, 'typologically diverse' language samples have been found to vary\nconsiderably in this regard, and popular sampling methods are flawed and\ninconsistent. We present a language sampling framework for selecting highly\ntypologically diverse languages given a sampling frame, informed by language\ntypology. We compare sampling methods with a range of metrics and find that our\nsystematic methods consistently retrieve more typologically diverse language\nselections than previous methods in NLP. Moreover, we provide evidence that\nthis affects generalizability in multilingual model evaluation, emphasizing the\nimportance of diverse language sampling in NLP evaluation.",
  "text": "A Principled Framework for Evaluating on\nTypologically Diverse Languages\nEsther Ploeger\nAalborg University\nDepartment of Computer Science\nespl@cs.aau.dk\nWessel Poelman\nKU Leuven\nDepartment of Computer Science\nwessel.poelman@kuleuven.be\nAndreas Holck Høeg-Petersen\nAalborg University\nDepartment of Computer Science\nahhp@cs.aau.dk\nAnders Schlichtkrull\nAalborg University\nDepartment of Computer Science\nandsch@cs.aau.dk\nMiryam de Lhoneux\nKU Leuven\nDepartment of Computer Science\nmiryam.delhoneux@kuleuven.be\nJohannes Bjerva\nAalborg University\nDepartment of Computer Science\njbjerva@cs.aau.dk\nBeyond individual languages, multilingual natural language processing (NLP) research increas-\ningly aims to develop models that perform well across languages generally. However, evaluating\nthese systems on all the world’s languages is practically infeasible. To attain generalizability,\nrepresentative language sampling is essential. Previous work argues that generalizable multi-\nlingual evaluation sets should contain languages with diverse typological properties. However,\n‘typologically diverse’ language samples have been found to vary considerably in this regard,\nand popular sampling methods are flawed and inconsistent. We present a language sampling\nframework for selecting highly typologically diverse languages given a sampling frame, informed\nby language typology. We compare sampling methods with a range of metrics and find that our\nsystematic methods consistently retrieve more typologically diverse language selections than\nprevious methods in NLP. Moreover, we provide evidence that this affects generalizability in\nmultilingual model evaluation, emphasizing the importance of diverse language sampling in\nNLP evaluation.\n1. Introduction\nData-driven approaches to language technology have shifted the realm of possibility\nin multilingual NLP. Distributed word representations (Mikolov et al. 2013) have lifted\nthe reliance on language-specific hand-crafted rules. This is leveraged by pre-training\nlanguage models on multiple languages simultaneously, such as multilingual BERT\n(Devlin et al. 2019) and XLM-R (Conneau et al. 2020), increasing performance through\ntransfer learning. More recently, even English-centric large language models (LLMs)\nPre-print. Under review.\n1\narXiv:2407.05022v1  [cs.CL]  6 Jul 2024\nPre-print. Under review.\nare claimed to “possess multilingual capabilities that surpass our expectations” (Yuan\net al. 2023), in the case of LLama (Touvron et al. 2023), and “effectively transfer learned\nknowledge across different languages” (Zhang et al. 2023), in the case of GPT3.5.\nA shared factor behind the success of these models is their reliance on large\nvolumes of textual data. These data-driven approaches are claimed to be language-\nindependent, as they are, in principle, applicable to any language given enough training\ndata. However, language-independent systems are not language agnostic (Bender 2009,\n2011). Current algorithms are designed with an English-centric perspective in mind,\nwhile characteristics (such as low morphological complexity) of the English language\ncannot be assumed to transfer to other languages. To be best of our knowledge, there\nis currently no systematic investigation of how the properties of languages included in\nthe evaluation influence the performance estimations of multilingual language models.\nIt remains unclear how multilingual these models truly are and to what extent the\nlanguage-independent assumption really holds against the world’s language diversity.\nTo assess whether a language model performs well across languages, ideally, one\nwould evaluate it on all languages in the world. However, collecting high-quality data\non such a scale is not feasible. Therefore, multilingual models are evaluated on a sample\nof the world’s languages. To ensure generalizability, such a language sample should be\ndiverse, with varying characteristics and properties. However, existing approaches to\nthis sampling process have not been optimal. Previous work has established that there\nis no clear terminology or methodological consensus for what constitutes ‘typological\ndiversity’ (Ploeger et al. 2024). Currently, many approaches in NLP use phylogenetic\nheuristics to ensure ‘typological diversity’. In this paper, we show that this approxima-\ntion of typological diversity through language phylogeny has severe shortcomings, and\nwe provide a framework for systematically selecting languages based on typological\ndistance measures. Our framework enables two sampling methods that are widely\nestablished within the field of linguistic typology. We demonstrate how our framework\ncan be used for diverse typological language sampling, how it can help guide dataset\nexpansions, and how it has use beyond typology.\nContributions. (i) We establish that language phylogeny is limited when it comes to\nassessing typological diversity; (ii) we provide a method for quantifying the typolog-\nical distance between pairs of languages; (iii) we provide a systematic framework for\nselecting typologically diverse languages for multilingual evaluation scenarios; (iv) we\nintroduce measures of typological diversity, and compare these with existing ones; (v)\nwe show that typological diversity matters in downstream evaluation; (vi) we provide\na Python package that facilitates typologically diverse language selection, which is\npublicly available in the following repository:\nhttps://github.com/esther2000/typdiv-sampling\n2. Background\nLinguistic typology can be described as the study of structural similarities and dif-\nferences across the world’s languages (Kashyap 2019). Within linguistic typology, an\nimportant research direction is the investigation of general patterns for these similarities\nand differences. For example, Greenberg (1963) finds that in languages with verb-object\nword order, adpositions tend to be placed before their objects. For drawing such general\nconclusions about human languages as a whole, testing linguistic hypotheses on only\na handful of related languages is insufficient (Rijkhoff et al. 1993; Guzmán Naranjo\nand Becker 2022). Instead, generalizable conclusions in typology require adequate sam-\n2\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\npling strategies: findings should be supported by evidence across a diverse range of\nlanguages. Thus, representative language sampling has long been a central method-\nological issue in the field of linguistic typology. Given the recent advances in language\ntechnology beyond English, language sampling has become increasingly relevant for\nmultilingual NLP. Drawing generalizable conclusions about multilingual model perfor-\nmance requires tests across diverse languages. Moreover, gaining insight into the skews\nof evaluation language sets may help to identify weaknesses of current applications. In\nthis section, we discuss relevant sampling strategies and terminology from the field of\nlinguistic typology and how they relate to language sampling in NLP.\nUniverse, Frame and Sample. Bell (1978) introduced central notions for language sampling\nin typology. Firstly, the sampling UNIVERSE is the class of objects under study. In\ntypological studies, this could for instance be the set of all possible human languages.\nIn NLP, the sampling universe often corresponds to all existing natural languages that a\ncertain language technology is claimed to generalize to. The sampling FRAME provides\naccess to the sampling universe. It is the concrete set of languages one can actually\nsample from. Sjöberg (2023) further describes the distinction between a catalogue frame,\nwhich is the set of languages we know to exist, and a corpus frame, which is the set of\nlanguages for we have relevant research materials. For our purposes, we will treat the\ncatalogue frame as all languages we have typological information for. We will treat the\ncorpus frame as the set of languages that we have available datasets for. Given the data\nrequirements of most techniques in NLP, the corpus frame is of vital importance. Lastly,\nthe SAMPLE is the set of languages that one draws from the frame, with the aim to reflect\nthe properties of the sampling universe. In NLP, this can correspond to the concrete set\nof languages that one tests or evaluates an application on.\nSampling Methods. For extracting a sample from the frame, there are multiple popular\ntypes of methods in linguistic typology. Rijkhoff and Bakker (1998) divide sampling\nmethods into three categories: RANDOM, PROBABILITY and VARIETY sampling. Each of\nthese sampling methods are relevant for different research questions. Random sampling\nentails selecting languages without any criteria. Without ‘stratification’, the grouping of\nthe frame before sampling, it is possible that resulting samples are in large part made up\nof similar languages. As such, these samples could be skewed towards languages from\ncertain phylogenetic or geographical groups. This is especially likely if the sampling\nframe contains a skew. Such samples, given they are large enough, are commonly\nused to look into the occurrence frequency of some linguistic phenomenon, but not\nnecessarily for generalizable conclusions about language. In probability sampling, one\naims for a sample that contains independent languages. Ideally, the resulting sample\nshould be free of bias. For instance, it should not contain a skew towards one or a\nfew language families. Variety sampling aims at sampling languages such that the\nlinguistic diversity of the world’s languages is captured as much as possible. This is\nbecause ‘exceptional types test the rule’ (Perkins 1988). In the context of NLP, Ponti\net al. (2020) write that choosing a variety sample tests the robustness of a language\nmodel to unseen typological features, as it includes outliers. These three sampling\nmethods each come with different implications in terms of sample size. Because of\nthe lack of stratification, a random sample ‘must be relatively large in size to be able\nto produce reliable results’ (Rijkhoff and Bakker 1998). For variety sampling, it is also\noften the case that the more languages are included, the better. This is because including\nmore languages means that outliers and uncommon properties are more likely to be\ncaptured (Miestamo, Bakker, and Arppe 2016). However, for probability sampling, there\n3\nPre-print. Under review.\nis a trade-off between independence and coverage. The more languages one includes,\nthe more difficult it becomes to preserve independence between these languages. To\nillustrate: if the number of languages one samples is larger than the number of language\nfamilies in the frame, then multiple languages from the same family have to be sampled.\nLanguage Sampling in NLP. Bender (2009, 2011) and Pikuliak and Simko (2022) exten-\nsively discussed the need for diverse evaluation language selection, and the potential\nfor linguistic typology to facilitate this. However, to date, there are only a handful\nof works in NLP that aimed to apply these suggestions. In fact, Ploeger et al. (2024)\nascertained that ‘typologically diverse’ sampling methods in NLP are mostly flawed.\nFirstly, if any stratification criterion is mentioned in NLP, this is usually based on\nphylogeny (e.g., Yadavalli, Yadavalli, and Tobin 2023; Ács, Kádár, and Kornai 2021; Xu\net al. 2020). To the best of our knowledge, no approach in NLP uses a tree structure to\napply genealogical stratification. Instead, sampling from different families is common.\nTo illustrate: Majewska et al. (2020) ‘sampled languages from 5 different language fam-\nilies to ensure typological diversity’. However, there is no evidence that phylogenetic\nrelations directly imply typological relations (Dahl 2008). We further explore this in\nSection 3. Secondly, most sampling stratification is applied post-hoc. Commonly, a set of\nlanguages is selected, and only then is it described in terms of diverse language families\nand sometimes typological diversity. For example, the typology index by Ponti et al.\n(2020) (see Section 6.2) is only applied after language selection. As such, it does not\npromote principled language selection. Our work differs from these approaches, in that\nwe perform informed selection, instead of informed analysis.\n3. Why is Phylogeny Insufficient?\nIn Section 2, we mentioned how previous work in NLP typically approximates typo-\nlogical diversity through phylogenetic groupings. More specifically, a major share of\napproaches claim to approximate typological diversity by randomly selecting languages\nfrom different language families or genera. However, it is not evident that phylogenic\nrelationships directly imply typological similarities (Georgi, Xia, and Lewis 2010). Fur-\nthermore, relying on this stratification criterion can give vastly inconsistent samples\n(and thus different results), given that within-family selection is random. In this section,\nwe critically assess the shortcomings of phylogeny as a proxy for typologically diverse\nlanguage sampling in NLP.\nTheoretical Arguments. Phylogenetic groupings such as language families and genera are\ncommonly described as strictly exclusive groups. For example, German, Dutch and\nHindi are all in the Indo-European language family. In reality, language similarity is\nmuch more gradient. Intuitively, it may be clear for some that German and Dutch\nare much more similar than Dutch and Hindi. It is therefore not surprising that the\nstrict boundaries between families are not necessarily agreed upon. For example, Dixon\n(1997) writes “about 1,000 languages have been grouped together in a putative ‘Niger-\nCongo family’. [...] One searches in vain for proof of this ‘genetic relationship.’ ”\nFurthermore, Dahl (2008) writes that “[genealogically] related languages that are no\nlonger in contact with each other can in a few thousand years develop typological\nprofiles that are no longer indicative of a common origin.” The imposed strict distinction\nbetween phylogenetic language groups also causes other issues. For instance, pidgins\nand Creoles are not easily placed into a family tree, which means that sometimes\nthey are excluded from sampling methods. For instance Sjöberg (2023) writes: “Finally,\n4\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\npidgins and creoles are also excluded from the frame, due to the difficulty of deciding\nwhere in and in what family tree to place them.” Furthermore, strictly divided language\nfamilies come in different sizes. The Niger-Congo language family includes more than\n1,000 languages (Hammarström et al. 2024), while isolates such as Basque constitute\ntheir entire ‘family’. This further complicates fair sampling. Finally, if the number of\nlanguages one wishes to sample is smaller than the number of phylogenetic groupings,\nthere is a random selection on a group-level as well.\nEmpirical Arguments. Beyond theoretical reasons, it is unclear to what extent phylo-\ngenetic groupings actually imply typological diversity. Here, we empirically assess\nthe extent to which typological similarity overlaps with language families. Grambank\n(Skirgård et al. 2023) contains genealogical and typological information for 2,467 lan-\nguages. We use this data to calculate, for each language family in Grambank, the\npairwise average of overlapping feature values in that family. In Figure 1, we show\nthis overlap per language family, as well as the number of languages in each family.\nIf families were coherent typological groups, we would expect to see high overlap\nthroughout – we observe variety in overlap, with most averages below 0.6. Additionally,\nwe retrieve the closest language for each language in Grambank, in terms of feature\nvalue overlap. We find that the closest language is in another family in 32.42% of the\ncases. Thus, sampling from distinct language families does not directly imply that the\nsampled languages are typologically distant.\nAll in all, we conclude that sampling with phylogenetic stratification is not ideal\nfor NLP purposes. In linguistic typology, sampling using a proxy is often necessary.\nDirectly using typological values instead is to be avoided, because then using those\nsame variables for sampling introduces circularity. However, in NLP, the variable under\ninvestigation is commonly something different, such as multilingual model perfor-\nmance. Thus, there is no circularity with sampling directly from typological features.\nThis avoids many of the issues with strict group sampling: we can take into account\ngranularity, include languages which are typically difficult to place in one of those strict\ngroups, we can control the group size and are not affected by randomness in sampling.\nAdditionally, by sampling through typological features directly, we gain immediate\nAustronesian\nAtlantic-Congo\nAfro-Asiatic\nAustroasiatic\nArawakan\nCentral Sudanic\nChibchan\nAlgic\nAthabaskan-Eyak-Tlingit\nChocoan\nGoilalan\nGunwinyguan\nChicham\nEskimo-Aleut\nAbkhaz-Adyge\nAngan\nCochimi-Yuman\nGuaicuruan\nHeibanic\nArawan\nBlue Nile Mao\nChonan\nGreater Kwerba\nGuahiboan\nHatam-Mansim\n0\n100\n200\n300\n400\n500\nNumber of languages in family\n0.0\n0.2\n0.4\n0.6\n0.8\nAverage overlap within family\nFigure 1\nNumber of languages and average within-family feature value overlap for the 25 largest\nlanguage families in Grambank.\n5\nPre-print. Under review.\ninsight into the typological diversity of the sample. In the next Section 5, we present\na method that does exactly this.\n4. Related Work\nWe argue that typologically generalizable evaluation in multilingual NLP should be\nconducted on the basis of a priori sampling with typological features. To the best of our\nknowledge, this is only implemented in two previous works. Dahl (2008) sampled a\nsubset of the World Atlas of Language Structures (WALS; Dryer and Haspelmath 2013)\nby removing one language from each pair that is above a certain typological similarity\nthreshold. The language that is removed, is the one with the least coverage in WALS,\nwhich exacerbates bibliographical bias (Bakker 2010). Stoll and Bickel (2013) introduce\na sampling method based on fuzzy clustering (Kaufman and Rousseeuw 2009). They\ndivide languages into k clusters based on twelve typological features, which the authors\nmanually coded from various sources. Then, for each cluster, they sample the language\nwith the highest membership coefficient.\nOur work differs from these approaches considerably. Firstly, our method is de-\nsigned to handle data-inequality. This means that it does not assume that all typological\nfeatures are described for every language, contrary to previous work. As complete\ntypological coverage is rare, this renders our method applicable to a far broader range\nof languages and typological features. Also, we present a flexible framework, where\nindividual features can be left out, if desired. Importantly, our framework accommo-\ndates both probability sampling and variety sampling from linguistic typology. This\nis important, because different sampling methods may be used to answer different\nresearch questions.\n5. A Principled Language Sampling Framework\nL1\nL2\nL3\nL1\nL2\nL3\nL4\nL5\nL6\n...\n1\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n?\n?\nL1\nL2\nL3\nL1\nL2\nL3\n0.0\n0.0\n0.0\n0.2\n0.2\n0.2\n0.5\n0.9\n0.9\n...\n...\n...\n(Typological) Feature Vectors\nLanguage Distances\nSampling Algorithm\nL1\nL3\nL5\nSampling Frame\nSample\n1\n2\n3\nFigure 2\nLanguage sampling by measuring distances of typological feature vectors.\nThe task of language sampling consists of selecting a set of languages (sample) from\na larger set of languages (frame). There are two main methods for performing typo-\nlogically diverse sampling. For variety sampling, the languages in the sample should\nbe maximally diverse. For probability sampling, these languages should be maximally\nindependent. Instead of approximating typological diversity through phylogenetic re-\nlationships, we measure typological distance between languages based on typological\nproperties. Our approach consists of three steps:\n1.\nRetrieve typological information per language (Section 5.1)\n2.\nCalculate pairwise distances between languages (Section 5.2)\n6\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\n3.\nSample languages using an algorithm that calculates a set of typologically\ndistant languages (Section 5.3)\nIn Figure 2, we schematically represent our complete sampling pipeline. In the next\nsubsections, we discuss each of the separate steps in more detail.\n5.1 Typological Feature Vectors\nWe use the Grambank database (Skirgård et al. 2023) for retrieving typological charac-\nteristics of the languages in a sampling frame. Grambank v1.0, which we use throughout\nthis paper, contains typological information for 2,467 language varieties, for 195 gram-\nmatical features. Of these features, 189 are expressed as binary statements (e.g., Are there\ndefinite or specific articles?; GB020). These features can take values 0, 1 or ?, where the\nlatter denotes unclear or unknown features. Coverage is incomplete: for some language\nvarieties, some features are not described, indicated by no_cov. Six word-order features\nare multi-value. For instance, feature GB024 (What is the order of numeral and noun in the\nNP?) can take the values Num-N, N-Num, both and ?.\nOur framework is compatible with any kind of information about languages. The\nframework can also be used starting from step 3 when there are already pairwise\ndistances available. These language distances are not required to be based on typology.1\nIn this work, we specifically use Grambank, for multiple reasons. Firstly, Grambank\nwas developed with computational applications in mind, taking specific care to avoid\nlogical dependencies between feature values (Haynie et al. 2023). Logical dependencies\nare introduced when the value of one feature implies another. These are problematic\nfor calculating (language) distances, as features that directly imply each other are then\nweighted more than features that are not logically implied by others.2 Additionally,\nsince our work focuses on text processing specifically, the morphosyntactic domain of\nGrambank is particularly relevant. By contrast, databases such as WALS also contain\nphonological features, while phonology is generally separate from text. For our main\nexperiments, we therefore treat Grambank as our catalogue frame. Still, if one aims to\nconduct a phonological study, one could use phonological features with our framework\ninstead.\n5.2 Language Distance Calculation\nLet a sampling frame be a set L of languages. For each language l ∈L we extract\na typological vector V (l) with d dimensions, which consists of all Grambank feature\nvalues for l. We binarize the six multi-value word order features, as suggested by\nHaynie et al. (2023). This leaves us with d = 209 features which for each language will\nhave values 0, 1, ? or no_cov, the latter representing a feature not covered. We treat both\nfeatures without coverage and features with a value of ? as explicitly missing values,\nwhich we both treat as NaN. For a vector v and integer i, let vi be the ith feature of\nv. For each pairwise combination of languages l, l′ ∈L, we then calculate the euclidean\ndistance in the presence of missing values, as defined by Dixon (1979) and implemented\nby Pedregosa et al. (2011). This distance calculation is defined in Equation 1.\n1 We show an application of this in Section 7.3.\n2 It should be noted that a lack of logical dependencies does not exclude statistical dependencies, as some\nfeature values may co-occur.\n7\nPre-print. Under review.\ndist(l, l′) =\nv\nu\nu\ntw(l, l′) ·\nX\nf∈s(l,l′)\n(V (l)f −V (l′)f)2\n(1)\nwhere s(l, l′) is the set of features that are covered in both l and l′\ns(l, l′) = {f ∈{1 .. d} | V (l)f ̸= NaN and V (l′)f ̸= NaN}\n(2)\nand where w is calculated by dividing the total number of data points by the number of\npresent data points:\nw(l, l′) =\nd\n|s(l, l′)|.\n(3)\nThis provides us with the distance between all pairs of language varieties in Grambank.\nWe use these distances in our algorithms for calculating sets of typologically distant\nlanguages (Section 5.3). Our framework provides additional flexibility by supporting a\nnumber of processing steps:\n•\nNormalization: For better readability of the pairwise distances, min-max\nnormalization can be applied, retrieving distances in the range [0, 1]. This\ndoes not affect the sampling process or results.\n•\nBinarization: For using Grambank’s multistate values in the same format\nas the binary features, we incorporate a binarization option. We follow the\nauthors of Grambank by dividing each multistate value into into two\nbinary features, which are not logically dependent.3\n•\nLanguage cropping: In order to mitigate influences of languages with very\nlimited feature coverage on the sampling results, we provide the option of\nremoving languages with a defined percentage of missing data. Following\nSkirgård et al. (2023), we use a threshold of >25% missing data for\nlanguage cropping in the rest of this work.\n•\nRemoving macro-languages: Grambank contains a number of\nmacro-languages (e.g. Central pacific linkage, Oceanic), which may not be\nrelevant to one’s case study. Our framework facilitates filtering these out,\ninformed by the number of child languages in Glottolog.\n•\nFeature sub-selection: For case studies that only comprise a subset of\nmorphosyntactic features, our framework supports the selective inclusion\nof features.\nFor the demonstrated applications of our framework in this work, we apply nor-\nmalization, binarization, language cropping and remove macro-languages.\n3 https://github.com/grambank/grambank/blob/master/docs/Grambank_most_updated_\nsheet.tsv\n8\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\n5.3 Sampling Algorithms\nGiven these typological distances between pairs of languages, there are multiple ways\nto do typologically diverse language selection. In the linguistic typology literature, dif-\nferent sampling methods are used for answering different kinds of research questions.\nInspired by this, our framework explicitly accommodates both variety sampling and\nprobability sampling methods. While we specifically focus on typology in this section,\nthese methods can be used with any type of information, as mentioned in Section 5.1.\n5.3.1 MaxSum Diversity. For our typologically informed variety sampling, we treat\nthe problem as a MAXIMUM DIVERSITY PROBLEM (MDP).4 This entails finding a size\nk set of points where the sum of distances between all points in the set is maximal\n(MaxSum). Approaching the problem as such optimizes for sampling for large total\ndistance, capturing outliers (see Figure 3), which is the objective of variety sampling.\nKuo, Glover, and Dhir (1993) showed that the ‘clique problem’, finding subsets of\nvertices in a graph that are all adjacent, can be reduced to MDP. Since the clique problem\nis NP-hard, then so must MDP be. Famously, there is no known efficient algorithm\nfor finding optimal solutions to NP-hard problems. We also experienced that a brute\nforce algorithm did not terminate when run on the dataset. Martí et al. (2013) give an\noverview of heuristics for MDP and conclude that even simple heuristics give good\nsolutions. We implement one such simple heuristic. Given pairwise language distances,\nwe first find the language that is most distant from all others. For this, we take the\nlanguage where the sum of distances with all other languages is largest. The motivation\nbehind this is that selecting the language with the most ‘unusual’ typological properties\n(or combinations thereof) already ensures some outlier. Next, we add the language that\nis furthest from the first language to the sample. We then sum the distances from these\ntwo languages to every other language. The language that has the largest summed\ndistance is added to the selection. We repeat this process until the desired size of the\nsample is reached. The full procedure is described in Algorithm 1.\nInput: k: number of languages to sample, L: sampling frame, dist: function giving\nthe pairwise distance between languages in L (e.g., Equation 1)\nAlgorithm 1 MaxSum Sampling\n1: l ←arg maxl∈L\nP\nl′∈L dist(l, l′)\n2: L ←{l}\n3: while |L| < k do\n4:\nL ←L ∪\n{arg maxl∈L\\L\nP\nl′∈L dist(l, l′)}\n5: end while\n6: return L\nAlgorithm 2 MaxMin Sampling\n1: l ←arg maxl∈L\nP\nl′∈L dist(l, l′)\n2: l′ ←arg maxl′∈L dist(l, l′)\n3: L ←{l, l′}\n4: while |L| < k do\n5:\nL ←L ∪\n{arg maxl∈L\\L(minl′∈L dist(l, l′))}\n6: end while\n7: return L\n4 Martí et al. (2013) list a number of alternative names used for the problem: maximum dispersion,\nmax-avg dispersion, p-dispersion, p-dispersion-sum, edge-weighted clique, remote clique, maximum\nedge-weighted subgraph, dense k-subgraph, p-defense, p-defence-sum and equitable dispersion.\n9\nPre-print. Under review.\nFigure 3\nA visualization of both sampling algorithms, with the MaxSum objective on the left and MaxMin\non the right over a normal distribution. The red triangles represent the sample selected by the\nrespective algorithm, the blue dots the remaining languages in frame. The distance here is the\nEuclidean distance in a 2D plane.\n5.3.2 MaxMin Diversity. In sampling with the MaxSum objective, the total typological\ndistance between languages is maximized. Individual outliers within the sample may be\nclose (see Figure 3), which may introduce a skew in a sample.5 However, for probability\nsampling, one would want to preserve the independence between languages. To this\nend, we approach the diversity problem as a MAXMIN DIVERSITY PROBLEM, which is a\nsecond popular diversity sampling objective (Parreño, Álvarez-Valdés, and Martí 2021).\nInstead of optimizing for the maximum total distance, we optimize for maximizing the\nsmallest distance between any two points in the set. Thus, we select languages such\nthat the closest two are maximally typologically distant. This problem is NP hard as\nwell, which means we again need to rely on heuristics. Similar to MaxSum diversity,\nwe implement a simple heuristic. As in the MDP approach, we first select the language\nthat is most distant from all others. Then, we again take the language furthest from that\nlanguage. Then until the desired sample size (k) is reached, we add the next language to\nthe sample that retrieves the highest minimum distance to the already selected points.\nThis last step is the key difference between the objectives of both algorithms. The full\nprocess is described in Algorithm 2.\n6. Typological Diversity Evaluation\nOur sampling methods enable a priori language sampling for typological diversity. In\nSection 7 we look into how our algorithm can be used practically. Here, we first verify\nwhether our sampling methods actually retrieve more diverse language samples than\nprevious methods used in NLP. To this end we compare our sampling algorithms to\napproaches from previous work in multilingual NLP with four metrics. Additionally,\n5 The distribution of language types can be visualized as distributed normally around the center, see Dryer\n(1998).\n10\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nwe address the issue of how many languages one would need to include for a represen-\ntative sample.\n6.1 Baselines\nRandom. As mentioned in Section 2, language selection in NLP is mostly unprincipled,\nwhere evaluation languages are sampled without stratification methods. This resembles\nrandom sampling in linguistic typology. In typology, random samples are mostly used\nfor gaining insight into occurrence frequencies, but not for drawing generalizable con-\nclusions. For comparability, we include a baseline which randomly samples from the\nsampling frame (Grambank).\nConvenience. In practice, random sampling in NLP is not truly random, because data\navailability plays a large role. Therefore we select the languages that are most commonly\nused in practice previous work in NLP that claims to have ‘typologically diverse’\nlanguage selections. Ploeger et al. (2024) annotated the language selections in papers\ncontaining such claims. For our baseline, we sort these languages based on occurrence\nfrequency, and sample the first k. In case of a tie in terms of occurrence frequency,\nselection is random.\nPhylogenetic. The most popular stratification in NLP, if any, is sampling based on\nlanguage families. This method can be motivated from the perspective of linguistic\ntypology, where phylogenetic stratification is popular. Contrary to linguistic typology,\nadvanced sampling methods from language trees are not relevant to NLP (Section 2). We\nimplement phylogenetic stratification by sampling uniformly from groupings on two\nlevels: language families6 and genera7. If the requested sample size is bigger than the\nnumber of groupings, we uniformly sample again from the groupings until we reach the\nrequested size. Note that this already more principled than most sampling approaches\nin NLP. The convenience baseline is indirectly also often influenced or motivated by\nphylogeny, albeit in less principled manner. As such, our phylogenentic baseline is\na ‘best case scenario’ for principled, typologically diverse language sampling using\nphylogenetic data.\n6.2 Metrics\nMeasuring the typological diversity of a language set can be done in a number of ways.\nWe formulate and compare four diversity metrics here, incorporating both previous\nwork and new ideas. We indicate ‘higher is better’ metrics with an up arrow (↑) and\n‘lower is better’ with a down arrow (↓).\nMean Pairwise Distance (MPD). The mean pairwise distance (MPD) of a language set\nmeasures the euclidean distance between all combinations of languages in the sample\n(Ploeger et al. 2024). Since these distances are used in our sampling algorithms directly,\nthis measure serves as a sanity check to verify whether the distances that the algorithm\nis based on are actually increased. Pairwise comparisons can be motivated from a\ntypological perspective (Wichmann and Holman 2010), and taking the average means\n6 As specified in Glottolog v4.4: 215 families.\n7 As specified in WALS v2020.3: 612 genera.\n11\nPre-print. Under review.\n0\n1\n0\n...\n1\n1\n0\n...\n1\n1\n1\n...\nF1\nF2\nF3\nL1\nL2\nL3\nEntropy\nMPD\nFVO\nF1\nF2\nF3\nF1\nF2\nF3\nL1\nL2\nL3\n0\n1\n0\n...\n1\n1\n0\n...\n1\n1\n1\n...\nF1\nF2\nF3\nL1\nL2\nL3\nFVI\n%\n%\n%\nx̄\nx̄\n0\n0\n1\n...\n1\n1\n1\n...\n0\n1\n1\n...\nL1\nL2\nL3\n0\n0\n1\n...\n1\n1\n1\n...\n0\n1\n1\n...\n%\nx̄\nfor each pair\nd\nx̄\nfor each pair\nFigure 4\nSchematic overview of diversity metric calculations, where ‘for each pair’ means all\ncombinations of languages in the set.\nthat the results can be compared across language samples of different sizes. MPD can\nbe formalized as follows:\nMPD(L) =\n1\n|L|(|L| −1)\nX\nl,l′∈L,l̸=l′\ndist(l, l′)\n(4)\nHere dist(l, l′) denotes the euclidean distance as defined in Equation 1.\nFeature Value Overlap (FVO). Distances alone do not directly describe the disparity of\nour features. This is motivated from the perspective of linguistic typology; Dahl (2008)\ndescribes measuring language similarity as: “How large a proportion of the features that\nare defined for both members of a language pair have different values?”. To this end we\ncalculate the feature value overlap (FVO), which is the average of the percentages of\nfeatures that overlap between any pair of languages in the combinations of a language\nset. Since Grambank contains binarized feature values (as outlined in Section 5.2), cal-\nculating such an overlap is appropriate.8 We report the average over all combinations.\nFeature value overlap can be formalized as follows:\nFVO(L) =\n1\n|L|(|L| −1)\nX\nl,l′∈L,l̸=l′\n|{f ∈{1 .. d}| V (l)f = V (l′)f}|\nd\nFeature Value Inclusion (FVI). The previous metrics do not measure the extent to which\nindividual typological properties are covered. This is especially relevant for variety\nsampling, where rare typological features should be included. Miestamo, Bakker, and\nArppe (2016) defined the measure of saturation of a typological feature as “the propor-\ntion of values, out of the maximum number of possible values, found in the sample for\nthat feature”. Because we deal with binary features only, we calculate the feature value\ninclusion (FVI) per feature as the percentage of languages that include the feature. We\nreport the average over all features. FVI can be formalized as follows:\n8 Special care has to be taken to calculate this metric when using multistate features values.\n12\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nFVI (L) = 1\nd\nd\nX\nf=1\n|{V (l)f | V (l)f ̸= NaN and l ∈L}|\n2\n(5)\nEntropy (H). Similar to the diversity index reported in Ponti et al. (2020), we report the\nentropy of the feature values that occur in a language sample. This gives us insight into\nthe spread within features. For example, if a sample L1 contains [1, 1, 1, 1, 0] for a given\nfeature f, FVI is maximal, but the spread is low. The entropy for f is lower than a more\ndiverse sample L2 with values [1, 1, 0, 0, 0]. We take the average of this metric over all\nfeatures. A difference with previous work is that Ponti et al. (2020) based their entropy\ncalculations based on 103 unnamed typological features from URIEL (Littell et al. 2017).\nThis is not reproducible, as they do not report which typological features were used.\nFurthermore, as URIEL contains logical dependencies, the included typological features\nare not necessarily weighted equally. The entropy of a set of languages is the average\nentropy over all features:\nH(L) = 1\nd\nd\nX\nf=1\nH(f)\n(6)\nwhere the entropy of a feature is\nH(f) = −\nX\ni∈{0,1}\np(f, i) · log2 p(f, i)\n(7)\nand the probability p is calculated as\np(f, i) =\n|{l ∈L | V (l)f = i}|\n|{l ∈L | V (l)f ̸= NaN)}|.\n(8)\n6.3 Results and Discussion\nWe compare our sampling methods against baselines based on previously used meth-\nods in NLP, as introduced in Section 6.1. Figure 5 shows that our methods consistently\nretrieve more diverse samples than all baselines. For the pairwise metrics (MDP, FVO),\nthis difference is especially large for smaller samples; it is easier to avoid overlap\nwhen sampling fewer languages. This is in line with earlier findings from typology,\nwhich described the trade-off between coverage and independence (Miestamo, Bakker,\nand Arppe 2016). While the FVI difference across methods is small for large sample\nsizes, we find that our methods retrieve a higher inclusion of feature values for small\nsamples (<20) than the baselines. This is especially relevant for NLP, where multilingual\nhypotheses are commonly tested on a small set of ‘typologically diverse’ languages\n(Median = 11; Ploeger et al. 2024). Lastly, we observe that MaxSum and MaxMin\nconsistently retrieve samples with higher feature entropy than other methods.\n13\nPre-print. Under review.\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nMPD\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nFVO\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nFVI\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nEntropy (H)\nMaxMin\nMaxSum\nConvenience\nRandom*\nRandomFamily*\nRandomGenus*\nMethod\nFigure 5\nMPD (↑), FVO (↓), FVI (↑) and H (↑) for different sample sizes. Non-deterministic methods are\nindicated with an asterisk and averaged over 10 runs, error bars represent their standard\ndeviation.\nThese results also showcase how our methods can be used to inform the choice\nof sample size in the design of a study. For these particular corpus frames, it can be\nargued that a sample size of 20 languages adequately covers the feature space. For\ninstance, FVI flattens after k > 20. This could be a justification for making claims about\nthe generalizability of a certain phenomenon captured in a sample.9\nNext, we compare the methods more in detail, for a specific value of k. We zoom in on\nk = 20, since the metrics tend to flatten off for all methods around that value, as seen in\nFigure 5. We measure the MPD, FVO, FVI and H for the samples that all our sampling\n9 While the number of languages one can sample from is a characteristic of the method, we find similar\nresults when taking the intersection of all methods’ sampling frames: see Appendix A.\n14\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nTable 1\nResults for k = 20 with all languages in Grambank as the frame, where an asterisk indicates\nmethods that are non-deterministic, these are averaged and the standard deviation over 10\nrandom runs is listed.\nSampling Method\nMPD ↑\nFVO ↓\nFVI ↑\nH ↑\nConvenience*\n0.72 ±0.00\n0.69 ±0.00\n0.94 ±0.00\n0.65 ±0.00\nRandom*\n0.75 ±0.01\n0.66 ±0.02\n0.94 ±0.02\n0.68 ±0.02\nRandomFamily*\n0.75 ±0.01\n0.65 ±0.01\n0.95 ±0.01\n0.69 ±0.02\nRandomGenus*\n0.76 ±0.02\n0.64 ±0.01\n0.95 ±0.01\n0.70 ±0.02\nMaxSum\n0.86\n0.55\n0.99\n0.86\nMaxMin\n0.84\n0.57\n0.98\n0.82\napproaches retrieve. We run the non-deterministic methods 10 times. The results (Table\n1) show that both MaxSum and MaxMin sampling retrieve considerably better results\nthan all baselines.\n7. Use Cases\nOur framework can be used in a variety of ways. In this section, we provide examples\nof practical use cases, to inspire future research with systematic language selection.\nContrary to the experiments in Section 6, we now also deal with a corpus frame. This\nmeans that we do not merely sample from a typological database, but investigate more\nrealistic data availability situations. Our experiments, frames and samples are publicly\navailable in our code repository.10\n7.1 Sampling for Fairer Multilingual Evaluation\nMultilingual language technology is typically only evaluated on a handful of seemingly\nrandomly selected languages. This lack of systematic language sampling makes it diffi-\ncult to assess how multilingual such technology really is. We present a use case of our\nframework that demonstrates how typologically diverse test language sampling affects\nthe generalizability of conclusions.\nSubword tokenization (Sennrich, Haddow, and Birch 2016) is an important compo-\nnent in multilingual text processing, which is at the basis of many popular LLMs. Split-\nting tokens into subwords facilitates better generalizability to languages with complex\nmorphology, and better handles out-of-vocabulary tokens. Yet, tokenizers of popular\nmultilingual models have been shown to retrieve varying results across languages with\nvarying morphosyntactic properties (Gutierrez-Vasques et al. 2021; Gutierrez-Vasques,\nBentz, and Samardži´c 2023). Highly synthetic languages such as Finnish pose different\ntokenization challenges than languages with relatively little morphological complexity\nsuch as Dutch. The number of subwords can indicate over-segmentation, which can\nhave far-reaching consequences for a user: for instance, the token-based cost of LLM\n10 https://github.com/esther2000/typdiv-sampling/use_cases\n15\nPre-print. Under review.\nAPIs is higher, and processing more separate tokens introduces latency (Petrov et al.\n2023).\nHere, we conduct a large-scale cross-lingual sampling comparison of subword to-\nkenization with tokenizers of popular multilingual models. For comparability between\nlanguages, the data should ideally be parallel across languages. Previous work (Ahia\net al. 2023; Petrov et al. 2023) evaluates on the FLoRes-200 dataset, as this is multi-\nparallel. We considerably extend upon their language coverage in our analysis, by eval-\nuating on text from the Parallel Bible Corpus (Mayer and Cysouw 2014), which is the\nlargest massively multi-parallel dataset in terms of language coverage. We first match\nlanguage ISO codes to Glottocodes. We then select all languages that have Grambank\ncoverage, and control for script (i.e. we filter out non-Latin scripts). This retrieves 571\nlanguages, which is the broadest language coverage thus far in tokenization analysis.\nThis is important, because we aim to test to what extent the sample represent the\nsampling frame, and potentially the sampling universe. We select the longest bible per\nlanguage, sample the 2,000 most common verses and randomly select 1,000 of those for\nour evaluation, while retaining multi-parallelism. We analyse tokenizers of four popular\nlanguage models with tokenizers publicly available on HuggingFace11: multilingual\nBERT (Devlin et al. 2019), XLM-R (Conneau et al. 2020), GPT2 (Radford et al. 2019) and\nmultilingual E5 (Wang et al. 2024). Similar to Ahia et al. (2023), we measure the amount\nof segmentation through the average number of subwords per verse.12\nAll\nConvenience\nMaxMin\nMaxSum\nMethod\n0\n50\n100\n150\n200\n250\n300\n350\nbert-base-multilingual-cased\nAll\nConvenience\nMaxMin\nMaxSum\nMethod\n0\n50\n100\n150\n200\n250\n300\n350\nxlm-roberta-large\nAll\nConvenience\nMaxMin\nMaxSum\nMethod\n0\n50\n100\n150\n200\n250\n300\n350\ngpt2\nAll\nConvenience\nMaxMin\nMaxSum\nMethod\n0\n50\n100\n150\n200\n250\n300\n350\nmultilingual-e5-large\nFigure 6\nAverage number of subwords per verse across four popular tokenizers, with different sampling\nstrategies.\n11 https://huggingface.co\n12 We do not use the fertility measure (Rust et al. 2021), because it assumes similar word tokenizer\nperformance across languages. We do not use ‘premiums’, the disparity of tokenization length between\nparallel sentences in two languages (Petrov et al. 2023), because these are by definition relative to another\nlanguage; we instead want to compare across languages directly.\n16\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nWe compare our sampling methods (MaxSum, MaxMin) with the only baseline that\nis deterministic for k = 20: convenience. From the 571 total languages, we sample 20\nwith each method. For each tokenizer, we compare the spread in average number of\nsubwords per verse for all three sampling methods, and compare those with the spread\nfor all 571 languages in our experiment. This gives us an estimate of how generalizable\nthe sample of 20 languages is with respect to the total 500+ languages included in the\nexperiment.\nThe results are in Figure 6. For all four models, we observe that the convenience\nbaseline retrieves a considerably lower average number of subwords, with a smaller\nrange than other methods. This implies that evaluating on the 20 most commonly\nincluded languages in ‘typologically diverse’ samples in NLP gives an overly optimistic\nimage of general multilingual tokenizer performance. Yet, the MaxSum and MaxMin\nmethods retrieve averages and spreads that much more closely resemble the average\nand spread of all 500+ languages in the experiment. This suggests that a priori typologi-\ncally informed language sampling can improve the generalizability of the results, based\non a language sample.\n7.2 Guiding Dataset Expansion Efforts\nData availability is an obstacle for truly diverse sampling, as corpus frames may be\nlimited for certain NLP tasks. At the same time, data collection and annotation efforts\ncan be laborious and expensive. Thus, it may be useful to know beforehand how data\ncollection for one language may impact the generalizability of an evaluation set. Our\nframework can be used to assess the diversity of existing benchmarks, inform future\ndata collection efforts, and quantify the relative improvement in language diversity.\nWe present a use case with five popular existing multilingual evaluation bench-\nmarks. They represent a range of tasks, including: machine translation (FloRes-200;\nTeam NLLB et al. 2022), dependency parsing (Universal Dependencies v2.14; Zeman\net al. 2024), question answering (TyDiQA; Clark et al. 2020), commonsense reasoning\n(XCOPA; Ponti et al. 2020) and generative language modelling (Aya Evaluation Suite\n(human-annotated); Singh et al. 2024). We focus on human-curated datasets specifically,\nas human annotations are typically more costly to gather than automatically generated\ndata, and thus informed expansion is more relevant. The benchmarks vary in size and\nin the extent to which the included languages were carefully selected. For example, for\nFloRes-200 and Universal Dependencies (UD), there seem to be no explicit selection cri-\nteria, as expanding language coverage was the main objective. Yet, some other datasets\nwere explicitly created with typological diversity in mind. TyDiQA was created with\nthe aim to include typologically diverse languages. However, in line with our findings\nin Section 2, the authors do not specify systematic sampling criteria and only post-hoc\nmention typological features to “highlight the breadth of phenomena” of the included\nlanguages. The authors of XCOPA explicitly aim for variety sampling, but only seem to\nmeasure the typological diversity of their sample post-hoc.\nHere, we quantify the diversity of each benchmark dataset, and use our framework\nto assess which expansion language would most increase typological diversity, and\nhow this impacts the total set. To this end, we provide a starting sample, which is the\nintersection of the languages in the datasets, and those in Grambank. For retrieving the\nnext-best language, we then choose a sample size of the starting sample, plus one. Note\nthat this number can be raised in future applications. We sample with the MaxSum\nobjective, as this is effective in increasing the total diversity (Section 6.3). We report\n17\nPre-print. Under review.\ndiversity based on entropy (H) and feature value inclusion (FVI), as discussed in Section\n6.2).\nTable 2\nThe expansion language that most increases typological diversity for five popular multilingual\nbenchmarks, as retrieved with MaxSum sampling.\nDataset\n|L| (|L ∩GB|)\nH\nFVI\n+ Language\nH′\nFVI′\nFloRes-200\n195 (105)\n0.717\n0.988\nTariana\n0.721\n0.988\n(Team NLLB et al. 2022)\nUD v2.14 (Zeman et al. 2024)\n158 (80)\n0.681\n0.985\nTariana\n0.687\n0.985\nTyDiQA (Clark et al. 2020)\n11 (7)\n0.627\n0.883\nMovima\n0.693\n0.928\nXCOPA (Ponti et al. 2020)\n11 (7)\n0.599\n0.873\nTariana\n0.667\n0.913\nAya Evaluation Suite (human-\n7 (5)\n0.571\n0.841\nYele\n0.660\n0.898\nannotated) (Singh et al. 2024)\nThe results (Table 2) show that adding the next-best languages to the existing\ndatasets always increases total diversity in terms of entropy. This increase is relatively\nsmall for the larger datasets (FloRes-200, UD), but larger for the smaller datasets (Ty-\nDiQA, XCOPA, Aya Evaluation Suite), where the number of added languages is a larger\nproportion of the total. FVI is not increased by adding a single language to the larger\ndatasets. This is unsurprising, as the value was already nearly maximal. This suggests\nthat including as many languages as possible is a good strategy for maximizing the\nincluded features, as argued for in variety sampling (Miestamo, Bakker, and Arppe\n2016).\nInterestingly, one language stands out as the most diverse expansion language for\nmultiple datasets (FloRes-200, UD and XCOPA): Tariana (language family: Arawakan).\nFrom a linguistic typology perspective, this makes sense. Firstly, Tariana is spoken in\n“a very remote area” in the Vaupés area in the North West of Brasil, which is “not easy\nto get to” (Aikhenvald 2003b). Also, Tariana is a polysynthetic language (Aikhenvald\n2003a), a grammatical property that is likely uncommon in popular NLP datasets. Yet,\nthere are more extensive, cultural, reasons for Tariana standing out. The area where\nthe language is spoken, is characterized by “obligatory multilingualism, dictated by the\nprinciples of linguistic exogamy” (Aikhenvald 2003a). This means that marriage only\noccurs between speakers of different languages. There has been a “strong inhibition\nagainst ‘language-mixing’, viewed in terms of lexical loans.”, and the language includes\n“independent innovations [...] divergent from those found in closely related languages.”\n(Aikhenvald 2003b). While this case is an indicator that our method indeed achieves\nhigh diversity and thus does what we expect, we do not argue that Tariana should\nthen be included in all NLP datasets. Instead, speaker needs and data availability\nshould be taken into account, which can be done by narrowing the sampling frame.\nWe demonstrate such a case in the next section.\nCase Study: Universal Dependencies. So far we have used all (cropped) languages in\nGrambank as the sampling frame. In practice, this may not be realistic, as one might\nwant to take into account speaker needs and annotator availability. The sampling frame\ncan then be smaller. To analyse our framework in such a scenario, we narrow the\n18\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nsampling frame for UD to the languages in their Possible Future Extensions list.13 These\nare “[languages for which] people have expressed interest in providing annotated data\n[...], but [for which] no valid data has been provided so far”. We manually annotate\nthe Glottocodes for these languages, and find that the intersection of previously not\nincluded Glottocodes and Grambank contains 17 languages. These languages are the\nsampling frame for finding the ‘next best’ language. We apply MaxSum sampling,\nwhich retrieves as next best extension language: Seri.\nTable 3\nEffects in diversity metrics from adding Seri to UD v2.14.\nMPD ↑\nMPD’ ↑\nFVO ↓\nFVO’ ↓\nFVI ↑\nFVI’ ↑\nH ↑\nH’ ↑\n0.725\n0.728\n0.679\n0.677\n0.985\n0.985\n0.681\n0.685\nAgain, this makes sense from a linguistic typology perspective, as Seri is a language\nisolate which “does indeed have some very special characteristics” (Marlett 2000). In\nTable 3, we report the effect of adding Seri to UD v2.14 on all our metrics. We observe\nthat, which the exception of FVI, diversity is improved with respect to all metrics.\n7.3 Other Distance Maximisation\nBeyond typological features, our method serves primarily as a framework, which can be\nextended to other features that describe languages. For example, it can be used to sam-\nple languages that are spoken in geographically distant areas. Such language sampling\nhas been an important methodological focus in linguistic typology. Similar to sampling\nfrom genealogical groupings, geographically diverse sampling is commonly performed\nwith pre-defined groupings, such as macroareas (Dryer 1989, 1992; Hammarström and\nDonohue 2014) or the finer-grained AUTOTYP areas (Nichols and Bickel 2009). In\nSection 3, we established that the usefulness of phylogenetic language groupings can\nbe hindered by their lack of granularity. The same applies to geographical language\ngroupings. Firstly, all languages from one such area (e.g. ‘Eurasia’) are seen as being\nequally close. Secondly, languages that are geographically close, but not in the same\nmacroarea, are not seen as similar. Most previous work in typology that uses absolute\ngeographical distance instead of groupings (Jaeger et al. 2011; Cysouw 2013; Bjerva et al.\n2020) manually defines a set threshold, for instance of 1,000 kilometers.14\n13 As listed on the homepage at the time of writing: https://universaldependencies.org.\n14 Still, it should be noted that distance-based stratification does not take into account long-distance contact,\nand that reducing languages to coordinates is not necessarily accurate.\n19\nPre-print. Under review.\nFigure 7\nWe use MaxMin sampling to find twenty geographically distant language coordinate pairs.\nOur framework allows for diverse geographical sampling, directly from distances, with-\nout the need to manually define a distance threshold. We further demonstrate this use\ncase here. We first retrieve language coordinates from Grambank, which corresponds to\nstep 1 in our framework. We use these to calculate the absolute distance in kilometers\nbetween any two coordinates (step 2). These pairwise distances are then used for\nsampling geographically diverse languages. Specifically, we use the MaxMin objective,\nwith the objective to maximize the minimum distance between any two points. Figure\n7 shows the resulting sample when selecting twenty languages.\n8. Limitations, Ethical Considerations and Discussion\nOur framework enables typologically diverse language sampling. Critical assessment of\nlanguage diversity is vital for the evaluation and development of multilingual language\ntechnology that is fair across languages. Still, it should be noted that generalizabilty\nacross typological characteristics constitutes only a fragment of multilingually fair NLP.\nFor instance, Grambank only addresses grammatical phenomena. Such typological\ndatabases do not provide cultural information, which may be key for certain research\nquestions (Hershcovich et al. 2022).\nMoreover, the feature coverage in typological databases such as Grambank is in-\ncomplete, which should be taken into account when drawing conclusions. However,\nsince bibliographic bias in NLP research tends to be much stronger than in typological\ndatabases (see convenience baseline, Section 6.3), we believe that information from\ntypological databases can actually enable informed expansion of language coverage.\nLastly, we acknowledge that reducing languages to coordinates or points in multidi-\nmensional space is by default simplistic. Languages are more than objects of study: they\nare central to human communication and inherently involve humans. As such, we urge\nresearchers to consider factors beyond typological diversity in language sampling or\ndataset expansion. Instead of sampling only based on typological diversity, we empha-\nsize the importance of incorporating a human-centered perspective. While developing\nmore generalizable multilingual NLP tools has the potential of mitigating unequal ac-\n20\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\ncess to language technology, this should be a collaborative effort that involves speakers\n(Bird 2020).\n9. Conclusions\nIn this work, we systematically analyse common language sampling strategies in NLP,\nand find that these are insufficient for typologically diverse language sampling. Guided\nby research in linguistic typology, we propose two sampling algorithms. We com-\npare the samples obtained by our methods with strong baselines. These samples are\nevaluated with four typological diversity metrics that show that our method consis-\ntently retrieves language samples with higher typological diversity. While we focus\non achieving high typological distance, our framework can be used with any type of\ninformation that one wishes to make ‘diverse’ generalizable claims about. Furthermore,\nour method can also be used for finding typologically similar languages, e.g., with use\ncases in transfer learning scenarios. We recommend that future work in NLP aiming for\ntypological generalizability use our informed selection method (while not losing sight\nof the human-centered perspective).\n21\nPre-print. Under review.\nAppendix A: Sampling evaluation by k for intersection of sampling frames.\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nMPD\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nFVO\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nFVI\n0\n20\n40\n60\n80\n100\n120\n140\nSample size\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nEntropy (H)\nMaxMin\nMaxSum\nConvenience\nRandom*\nRandomFamily*\nRandomGenus*\nMethod\nFigure 1\nMPD (↑), FVO (↓), FVI (↑) and H (↑) for different sample sizes where the sampling frame is equal\n(intersection for all methods). Non-deterministic methods are indicated with an asterisk and\naveraged over 10 runs, error bars represent their standard deviation. Colors are from Paul Tol’s\ncolor-blind safe muted qualitative scheme.\n22\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nAcknowledgments\nEP and JB are funded by the Carlsberg\nFoundation, under the Semper Ardens:\nAccelerate programme (project nr. CF21-0454).\nWP is funded by a KU Leuven Bijzonder\nOnderzoeksfonds C1 project with reference\nC14/23/096. We thank the members of\nLAGoM NLP group at KU Leuven, the\nTypNLP lab at Aalborg University and the\nHelsinki-NLP group at the University of\nHelsinki for feedback on earlier versions of\nthis paper. We thank Robert Östling for\npointing us to Anna Sjöberg’s thesis. We\nthank Kaius Sinnemäki and Anna Sjöberg for\ndiscussing the scope of this project with us\nfrom a typological perspective. We thank\nHedvig Skirgård for helpful feedback on\ncropping the dataset according to coverage,\nremoving macrolanguages, and the overall\nscope of this paper. Any remaining errors are\nour own.\nReferences\nÁcs, Judit, Ákos Kádár, and Andras Kornai.\n2021. Subword pooling makes a\ndifference. In Proceedings of the 16th\nConference of the European Chapter of the\nAssociation for Computational Linguistics:\nMain Volume, pages 2284–2295,\nAssociation for Computational\nLinguistics, Online.\nAhia, Orevaoghene, Sachin Kumar, Hila\nGonen, Jungo Kasai, David Mortensen,\nNoah Smith, and Yulia Tsvetkov. 2023. Do\nall languages cost the same? tokenization\nin the era of commercial language models.\nIn Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language\nProcessing, pages 9904–9923, Association\nfor Computational Linguistics, Singapore.\nAikhenvald, Alexandra Y. 2003a. The\nlanguage and its speakers. In A Grammar\nof Tariana, from Northwest Amazonia,\nCambridge Grammatical Descriptions.\nCambridge University Press, page 1–24.\nAikhenvald, Alexandra Y. 2003b. Teaching\ntariana, an endangered language from\nnorthwest amazonia. International Journal\nof the Sociology of Language.\nBakker, Dik. 2010. Language sampling.\nOxford handbooks in linguistics.\nBell, Alan. 1978. Language samples.\nUniversals of human language, 1:123–156.\nBender, Emily M. 2009. Linguistically naïve\n!= language independent: Why NLP needs\nlinguistic typology. In Proceedings of the\nEACL 2009 Workshop on the Interaction\nbetween Linguistics and Computational\nLinguistics: Virtuous, Vicious or Vacuous?,\npages 26–32, Association for\nComputational Linguistics, Athens,\nGreece.\nBender, Emily M. 2011. On achieving and\nevaluating language-independence in nlp.\nLinguistic Issues in Language Technology, 6.\nBird, Steven. 2020. Decolonising speech and\nlanguage technology. In Proceedings of the\n28th International Conference on\nComputational Linguistics, pages 3504–3519,\nInternational Committee on\nComputational Linguistics, Barcelona,\nSpain (Online).\nBjerva, Johannes, Elizabeth Salesky, Sabrina J.\nMielke, Aditi Chaudhary, Giuseppe G. A.\nCelano, Edoardo Maria Ponti, Ekaterina\nVylomova, Ryan Cotterell, and Isabelle\nAugenstein. 2020. SIGTYP 2020 shared\ntask: Prediction of typological features. In\nProceedings of the Second Workshop on\nComputational Research in Linguistic\nTypology, pages 1–11, Association for\nComputational Linguistics, Online.\nClark, Jonathan H., Eunsol Choi, Michael\nCollins, Dan Garrette, Tom Kwiatkowski,\nVitaly Nikolaev, and Jennimaria Palomaki.\n2020. TyDi QA: A benchmark for\ninformation-seeking question answering\nin typologically diverse languages.\nTransactions of the Association for\nComputational Linguistics, 8:454–470.\nConneau, Alexis, Kartikay Khandelwal,\nNaman Goyal, Vishrav Chaudhary,\nGuillaume Wenzek, Francisco Guzmán,\nEdouard Grave, Myle Ott, Luke\nZettlemoyer, and Veselin Stoyanov. 2020.\nUnsupervised cross-lingual representation\nlearning at scale. In Proceedings of the 58th\nAnnual Meeting of the Association for\nComputational Linguistics, pages 8440–8451,\nAssociation for Computational\nLinguistics, Online.\nCysouw, Michael. 2013. Disentangling\ngeography from genealogy. In Space in\nlanguage and linguistics: Geographical,\ninteractional, and cognitive perspectives. de\nGruyter.\nDahl, Östen. 2008. An exercise in a posteriori\nlanguage sampling. Language Typology and\nUniversals, 61(3):208–220.\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee,\nand Kristina Toutanova. 2019. BERT:\nPre-training of deep bidirectional\ntransformers for language understanding.\nIn Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for\n23\nPre-print. Under review.\nComputational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short\nPapers), pages 4171–4186, Association for\nComputational Linguistics, Minneapolis,\nMinnesota.\nDixon, John K. 1979. Pattern recognition\nwith partly missing data. IEEE\nTransactions on Systems, Man, and\nCybernetics, 9(10):617–621.\nDixon, Robert MW. 1997. The rise and fall of\nlanguages. Cambridge University Press.\nDryer, Matthew S. 1989. Large linguistic\nareas and language sampling. Studies in\nLanguage. International Journal sponsored by\nthe Foundation “Foundations of Language”,\n13(2):257–292.\nDryer, Matthew S. 1992. The greenbergian\nword order correlations. Language,\n68(1):81–138.\nDryer, Matthew S. 1998. Why statistical\nuniversals are better than absolute\nuniversals. In Papers from the 33rd Regional\nMeeting of the Chicago Linguistic Society,\npages 1–23.\nDryer, Matthew S and Martin Haspelmath.\n2013. Wals online. leipzig: Max planck\ninstitute for evolutionary anthropology.\nGeorgi, Ryan, Fei Xia, and William Lewis.\n2010. Comparing language similarity\nacross genetic and typologically-based\ngroupings. In Proceedings of the 23rd\nInternational Conference on Computational\nLinguistics (Coling 2010), pages 385–393,\nColing 2010 Organizing Committee,\nBeijing, China.\nGreenberg, Joseph Harold. 1963. Some\nuniversals of grammar with particular\nreference to the order of meaningful\nelements. In Universals of Language. MIT\npress, Cambridge, MA, pages 40–70.\nGutierrez-Vasques, Ximena, Christian Bentz,\nand Tanja Samardži´c. 2023. Languages\nthrough the looking glass of bpe\ncompression. Computational Linguistics,\n49(4):943–1001.\nGutierrez-Vasques, Ximena, Christian Bentz,\nOlga Sozinova, and Tanja Samardzic. 2021.\nFrom characters to words: the turning\npoint of BPE merges. In Proceedings of the\n16th Conference of the European Chapter of\nthe Association for Computational Linguistics:\nMain Volume, pages 3454–3468,\nAssociation for Computational\nLinguistics, Online.\nGuzmán Naranjo, Matías and Laura Becker.\n2022. Statistical bias control in typology.\nLinguistic Typology, 26(3):605–670.\nHammarström, Harald and Mark Donohue.\n2014. Some principles on the use of\nmacro-areas in typological comparison.\nLanguage Dynamics and Change,\n4(1):167–187.\nHammarström, Harald, Robert Forkel,\nMartin Haspelmath, and Sebastian Bank.\n2024. glottolog/glottolog: Glottolog\ndatabase 5.0.\nHaynie, Hannah J., Damián Blasi, Hedvig\nSkirgård, Simon J. Greenhill, Quentin D.\nAtkinson, and Russell D. Gray. 2023.\nGrambank’s typological advances support\ncomputational research on diverse\nlanguages. In Proceedings of the 5th\nWorkshop on Research in Computational\nLinguistic Typology and Multilingual NLP,\npages 147–149, Association for\nComputational Linguistics, Dubrovnik,\nCroatia.\nHershcovich, Daniel, Stella Frank, Heather\nLent, Miryam de Lhoneux, Mostafa\nAbdou, Stephanie Brandl, Emanuele\nBugliarello, Laura Cabello Piqueras, Ilias\nChalkidis, Ruixiang Cui, Constanza Fierro,\nKaterina Margatina, Phillip Rust, and\nAnders Søgaard. 2022. Challenges and\nstrategies in cross-cultural NLP. In\nProceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics\n(Volume 1: Long Papers), pages 6997–7013,\nAssociation for Computational\nLinguistics, Dublin, Ireland.\nJaeger, T. Florian, Peter Graff, William Croft,\nand Daniel Pontillo. 2011. Mixed effect\nmodels for genetic and areal dependencies\nin linguistic typology. Linguistic Typology.\nKashyap, Abhishek Kumar. 2019. Language\ntypology. The Cambridge handbook of\nsystemic functional linguistics, pages\n767–792.\nKaufman, Leonard and Peter J Rousseeuw.\n2009. Finding groups in data: an introduction\nto cluster analysis. John Wiley & Sons.\nKuo, Ching-Chung, Fred Glover, and\nKrishna S Dhir. 1993. Analyzing and\nmodeling the maximum diversity problem\nby zero-one programming. Decision\nSciences, 24(6):1171–1185.\nLittell, Patrick, David R. Mortensen, Ke Lin,\nKatherine Kairis, Carlisle Turner, and Lori\nLevin. 2017. URIEL and lang2vec:\nRepresenting languages as typological,\ngeographical, and phylogenetic vectors. In\nProceedings of the 15th Conference of the\nEuropean Chapter of the Association for\nComputational Linguistics: Volume 2, Short\nPapers, pages 8–14, Association for\nComputational Linguistics, Valencia,\nSpain.\n24\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nMajewska, Olga, Ivan Vuli´c, Diana McCarthy,\nand Anna Korhonen. 2020. Manual\nclustering and spatial arrangement of\nverbs for multilingual evaluation and\ntypology analysis. In Proceedings of the 28th\nInternational Conference on Computational\nLinguistics, pages 4810–4824, International\nCommittee on Computational Linguistics,\nBarcelona, Spain (Online).\nMarlett, Stephen A. 2000. Why the seri\nlanguage is important and interesting.\nJournal of the Southwest, pages 611–633.\nMartí, Rafael, Micael Gallego, Abraham\nDuarte, and Eduardo G Pardo. 2013.\nHeuristics and metaheuristics for the\nmaximum diversity problem. Journal of\nHeuristics, 19:591–615.\nMayer, Thomas and Michael Cysouw. 2014.\nCreating a massively parallel Bible corpus.\nIn Proceedings of the Ninth International\nConference on Language Resources and\nEvaluation (LREC’14), pages 3158–3163,\nEuropean Language Resources\nAssociation (ELRA), Reykjavik, Iceland.\nMiestamo, Matti, Dik Bakker, and Antti\nArppe. 2016. Sampling for variety.\nLinguistic Typology, 20(2):233–296.\nMikolov, Tomas, Ilya Sutskever, Kai Chen,\nGreg S Corrado, and Jeff Dean. 2013.\nDistributed representations of words and\nphrases and their compositionality.\nAdvances in neural information processing\nsystems, 26.\nNichols, Johanna and Balthasar Bickel. 2009.\nThe autotyp genealogy and geography\ndatabase: 2009 release. URL:\nhttps://github.com/autotyp/autotyp-data.\nParreño, Francisco, Ramón Álvarez-Valdés,\nand Rafael Martí. 2021. Measuring\ndiversity. a review and an empirical\nanalysis. European Journal of Operational\nResearch, 289(2):515–532.\nPedregosa, F., G. Varoquaux, A. Gramfort,\nV. Michel, B. Thirion, O. Grisel,\nM. Blondel, P. Prettenhofer, R. Weiss,\nV. Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot,\nand E. Duchesnay. 2011. Scikit-learn:\nMachine learning in Python. Journal of\nMachine Learning Research, 12:2825–2830.\nPerkins, Revere D. 1988. The covariation of\nculture and grammar. Studies in syntactic\ntypology, pages 359–378.\nPetrov, Aleksandar, Emanuele La Malfa,\nPhilip Torr, and Adel Bibi. 2023. Language\nmodel tokenizers introduce unfairness\nbetween languages. In Advances in Neural\nInformation Processing Systems, volume 36,\npages 36963–36990, Curran Associates,\nInc.\nPikuliak, Matúš and Marian Simko. 2022.\nAverage is not enough: Caveats of\nmultilingual evaluation. In Proceedings of\nthe 2nd Workshop on Multi-lingual\nRepresentation Learning (MRL), pages\n125–133, Association for Computational\nLinguistics, Abu Dhabi, United Arab\nEmirates (Hybrid).\nPloeger, Esther, Wessel Poelman, Miryam\nde Lhoneux, and Johannes Bjerva. 2024.\nWhat is \"Typological Diversity\" in NLP?\narXiv preprint arXiv:2402.04222.\nPonti, Edoardo Maria, Goran Glavaš, Olga\nMajewska, Qianchu Liu, Ivan Vuli´c, and\nAnna Korhonen. 2020. XCOPA: A\nmultilingual dataset for causal\ncommonsense reasoning. In Proceedings of\nthe 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP),\npages 2362–2376, Association for\nComputational Linguistics, Online.\nRadford, Alec, Jeff Wu, Rewon Child, David\nLuan, Dario Amodei, and Ilya Sutskever.\n2019. Language models are unsupervised\nmultitask learners. Technical report,\nOpenAI.\nRijkhoff, Jan and Dik Bakker. 1998. Language\nsampling. Linguistic Typology, 2(3):263–314.\nRijkhoff, Jan, Dik Bakker, Kees Hengeveld,\nand Peter Kahrel. 1993. A method of\nlanguage sampling. Studies in Language.\nInternational Journal sponsored by the\nFoundation “Foundations of Language”,\n17(1):169–203.\nRust, Phillip, Jonas Pfeiffer, Ivan Vuli´c,\nSebastian Ruder, and Iryna Gurevych.\n2021. How good is your tokenizer? on the\nmonolingual performance of multilingual\nlanguage models. In Proceedings of the 59th\nAnnual Meeting of the Association for\nComputational Linguistics and the 11th\nInternational Joint Conference on Natural\nLanguage Processing (Volume 1: Long\nPapers), pages 3118–3135, Association for\nComputational Linguistics, Online.\nSennrich, Rico, Barry Haddow, and\nAlexandra Birch. 2016. Neural machine\ntranslation of rare words with subword\nunits. In Proceedings of the 54th Annual\nMeeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages\n1715–1725.\nSingh, Shivalika, Freddie Vargus, Daniel\nDsouza, Börje F Karlsson, Abinaya\nMahendiran, Wei-Yin Ko, Herumb\nShandilya, Jay Patel, Deividas Mataciunas,\nLaura OMahony, et al. 2024. Aya dataset:\nAn open-access collection for multilingual\n25\nPre-print. Under review.\ninstruction tuning. arXiv preprint\narXiv:2402.06619.\nSjöberg, Anna. 2023. Knowledge predication: A\nsemantic typology. Ph.D. thesis,\nDepartment of Linguistics, Stockholm\nUniversity.\nSkirgård, Hedvig, Hannah J Haynie,\nDamián E Blasi, Harald Hammarström,\nJeremy Collins, Jay J Latarche, Jakob\nLesage, Tobias Weber, Alena\nWitzlack-Makarevich, Sam Passmore, et al.\n2023. Grambank reveals the importance of\ngenealogical constraints on linguistic\ndiversity and highlights the impact of\nlanguage loss. Science Advances, 9.\nSkirgård, Hedvig, Hannah J. Haynie, Harald\nHammarström, Damián E. Blasi, Jeremy\nCollins, Jay Latarche, Jakob Lesage, Tobias\nWeber, Alena Witzlack-Makarevich,\nMichael Dunn, Ger Reesink, Ruth Singer,\nClaire Bowern, Patience Epps, Jane Hill,\nOuti Vesakoski, Noor Karolin Abbas,\nSunny Ananth, Daniel Auer, Nancy A.\nBakker, Giulia Barbos, Anina Bolls,\nRobert D. Borges, Mitchell Browen,\nLennart Chevallier, Swintha Danielsen,\nSinoël Dohlen, Luise Dorenbusch, Ella\nDorn, Marie Duhamel, Farah El Haj Ali,\nJohn Elliott, Giada Falcone, Anna-Maria\nFehn, Jana Fischer, Yustinus Ghanggo Ate,\nHannah Gibson, Hans-Philipp Göbel,\nJemima A. Goodall, Victoria Gruner,\nAndrew Harvey, Rebekah Hayes, Leonard\nHeer, Roberto E. Herrera Miranda,\nNataliia Hübler, Biu H.\nHuntington-Rainey, Guglielmo Inglese,\nJessica K. Ivani, Marilen Johns, Erika Just,\nIvan Kapitonov, Eri Kashima, Carolina\nKipf, Janina V. Klingenberg, Nikita König,\nAikaterina Koti, Richard G. A. Kowalik,\nOlga Krasnoukhova, Kate Lynn Lindsey,\nNora L. M. Lindvall, Mandy Lorenzen,\nHannah Lutzenberger, Alexandra Marley,\nTânia R. A. Martins, Celia Mata German,\nSuzanne van der Meer, Jaime Montoya,\nMichael Müller, Saliha Murado˘glu,\nHunterGatherer, David Nash, Kelsey\nNeely, Johanna Nickel, Miina Norvik,\nBruno Olsson, Cheryl Akinyi Oluoch,\nDavid Osgarby, Jesse Peacock, India O.C.\nPearey, Naomi Peck, Jana Peter, Stephanie\nPetit, Sören Pieper, Mariana Poblete,\nDaniel Prestipino, Linda Raabe, Amna\nRaja, Janis Reimringer, Sydney C. Rey,\nJulia Rizaew, Eloisa Ruppert, Kim K.\nSalmon, Jill Sammet, Rhiannon Schembri,\nLars Schlabbach, Frederick W. P. Schmidt,\nDineke Schokkin, Jeff Siegel, Amalia\nSkilton, Hilário de Sousa, Kristin\nSverredal, Daniel Valle, Javier Vera, Judith\nVoß, Daniel Wikalier Smith, Tim Witte,\nHenry Wu, Stephanie Yam, Jingting Ye,\nMaisie Yong, Tessa Yuditha, Roberto\nZariquiey, Robert Forkel, Nicholas Evans,\nStephen C. Levinson, Martin Haspelmath,\nSimon J. Greenhill, Quentin D. Atkinson,\nand Russell D. Gray. 2023. Grambank v1.0.\nDataset.\nStoll, Sabine and Balthasar Bickel. 2013.\nCapturing diversity in language\nacquisition research. Language typology and\nhistorical contingency, pages 195–216.\nTeam NLLB, Marta R. Costa-jussà, James\nCross, Onur Çelebi, Maha Elbayad,\nKenneth Heafield, Kevin Heffernan, Elahe\nKalbassi, Janice Lam, Daniel Licht, Jean\nMaillard, Anna Sun, Skyler Wang,\nGuillaume Wenzek, Al Youngblood, Bapi\nAkula, Loic Barrault, Gabriel Mejia\nGonzalez, Prangthip Hansanti, John\nHoffman, Semarley Jarrett, Kaushik Ram\nSadagopan, Dirk Rowe, Shannon Spruit,\nChau Tran, Pierre Andrews, Necip Fazil\nAyan, Shruti Bhosale, Sergey Edunov,\nAngela Fan, Cynthia Gao, Vedanuj\nGoswami, Francisco Guzmán, Philipp\nKoehn, Alexandre Mourachko, Christophe\nRopers, Safiyyah Saleem, Holger\nSchwenk, and Jeff Wang. 2022. No\nLanguage Left Behind: Scaling\nHuman-Centered Machine Translation.\nTouvron, Hugo, Thibaut Lavril, Gautier\nIzacard, Xavier Martinet, Marie-Anne\nLachaux, Timothée Lacroix, Baptiste\nRozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and\nefficient foundation language models.\narXiv preprint arXiv:2302.13971.\nWang, Liang, Nan Yang, Xiaolong Huang,\nLinjun Yang, Rangan Majumder, and Furu\nWei. 2024. Multilingual e5 text\nembeddings: A technical report. arXiv\npreprint arXiv:2402.05672.\nWichmann, Søren and Eric W Holman. 2010.\nPairwise comparisons of typological profiles.\nna.\nXu, Hongzhi, Jordan Kodner, Mitchell\nMarcus, and Charles Yang. 2020. Modeling\nmorphological typology for unsupervised\nlearning of language morphology. In\nProceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics,\npages 6672–6681, Association for\nComputational Linguistics, Online.\nYadavalli, Aditya, Alekhya Yadavalli, and\nVera Tobin. 2023. SLABERT talk pretty one\nday: Modeling second language\nacquisition with BERT. In Proceedings of the\n26\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\n61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long\nPapers), pages 11763–11777, Association\nfor Computational Linguistics, Toronto,\nCanada.\nYuan, Fei, Shuai Yuan, Zhiyong Wu, and Lei\nLi. 2023. How multilingual is multilingual\nllm? arXiv preprint arXiv:2311.09071.\nZeman, Daniel, Joakim Nivre, Mitchell\nAbrams, Elia Ackermann, Noëmi Aepli,\nHamid Aghaei, Željko Agi´c, Amir\nAhmadi, Lars Ahrenberg, Chika Kennedy\nAjede, Salih Furkan Akkurt, Gabriel˙e\nAleksandraviˇci¯ut˙e, Ika Alfina, Avner\nAlgom, Khalid Alnajjar, Chiara Alzetta,\nErik Andersen, Lene Antonsen, Tatsuya\nAoyama, Katya Aplonova, Angelina\nAquino, Carolina Aragon, Glyd Aranes,\nMaria Jesus Aranzabe, Bilge Nas Arıcan,\nHórunn Arnardóttir, Gashaw Arutie,\nJessica Naraiswari Arwidarasti, Masayuki\nAsahara, Katla Ásgeirsdóttir, Deniz Baran\nAslan, Cengiz Asmazo˘glu, Luma Ateyah,\nFurkan Atmaca, Mohammed Attia,\nAitziber Atutxa, Liesbeth Augustinus,\nMariana Avelãs, Elena Badmaeva,\nKeerthana Balasubramani, Miguel\nBallesteros, Esha Banerjee, Sebastian Bank,\nVerginica Barbu Mititelu, Starkaður\nBarkarson, Rodolfo Basile, Victoria\nBasmov, Colin Batchelor, John Bauer,\nSeyyit Talha Bedir, Shabnam Behzad, Juan\nBelieni, Kepa Bengoetxea, ˙Ibrahim Benli,\nYifat Ben Moshe, Ansu Berg, Gözde Berk,\nRiyaz Ahmad Bhat, Erica Biagetti, Eckhard\nBick, Agn˙e Bielinskien˙e, Esma Fatıma\nBilgin Ta¸sdemir, Kristín Bjarnadóttir,\nVerena Blaschke, Rogier Blokland, Victoria\nBobicev, Loïc Boizou, Johnatan Bonilla,\nEmanuel Borges Völker, Carl Börstell,\nCristina Bosco, Gosse Bouma, Sam\nBowman, Adriane Boyd, Anouck\nBraggaar, António Branco, Kristina\nBrokait˙e, Aljoscha Burchardt, Marisa\nCampos, Marie Candito, Bernard Caron,\nGauthier Caron, Catarina Carvalheiro,\nRita Carvalho, Lauren Cassidy,\nMaria Clara Castro, Sérgio Castro, Tatiana\nCavalcanti, Gül¸sen Cebiro˘glu Eryi˘git,\nFlavio Massimiliano Cecchini, Giuseppe\nG. A. Celano, Slavomír ˇCéplö, Neslihan\nCesur, Savas Cetin, Özlem Çetino˘glu,\nFabricio Chalub, Liyanage Chamila,\nShweta Chauhan, Yifei Chen, Ethan Chi,\nTaishi Chika, Yongseok Cho, Jinho Choi,\nBermet Chontaeva, Jayeol Chun, Juyeon\nChung, Alessandra T. Cignarella, Silvie\nCinková, Aurélie Collomb, Ça˘grı Çöltekin,\nMiriam Connor, Claudia Corbetta, Daniela\nCorbetta, Francisco Costa, Marine Courtin,\nBenoît Crabbé, Mihaela Cristescu,\nVladimir Cvetkoski, Ingerid Løyning\nDale, Philemon Daniel, Elizabeth\nDavidson, Leonel Figueiredo de Alencar,\nMathieu Dehouck, Martina de Laurentiis,\nMarie-Catherine de Marneffe, Valeria\nde Paiva, Mehmet Oguz Derin, Elvis\nde Souza, Arantza Diaz de Ilarraza,\nRoberto Antonio Díaz Hernández, Carly\nDickerson, Arawinda Dinakaramani, Elisa\nDi Nuovo, Bamba Dione, Peter Dirix, Hoa\nDo, Kaja Dobrovoljc, Caroline Döhmer,\nAdrian Doyle, Timothy Dozat, Kira\nDroganova, Magali Sanches Duran,\nPuneet Dwivedi, Christian Ebert, Hanne\nEckhoff, Masaki Eguchi, Sandra Eiche,\nRoald Eiselen, Marhaba Eli, Ali Elkahky,\nBinyam Ephrem, Olga Erina, Tomaž\nErjavec, Soudabeh Eslami, Farah Essaidi,\nAline Etienne, Wograine Evelyn, Sidney\nFacundes, Richárd Farkas, Federica\nFavero, Jannatul Ferdaousi, Marília\nFernanda, Hector Fernandez Alcalde,\nAmal Fethi, Jennifer Foster, Theodorus\nFransen, Cláudia Freitas, Kazunori Fujita,\nKatarína Gajdošová, Daniel Galbraith,\nEdith Galy, Federica Gamba, Marcos\nGarcia, Moa Gärdenfors, Tanja Gaustad,\nEfe Eren Genç, Fabrício Ferraz Gerardi,\nKim Gerdes, Luke Gessler, Filip Ginter,\nGustavo Godoy, Iakes Goenaga, Koldo\nGojenola, Memduh Gökırmak, Yoav\nGoldberg, Xavier Gómez Guinovart, Berta\nGonzález Saavedra, Bernadeta Grici¯ut˙e,\nMatias Grioni, Loïc Grobol, Normunds\nGr¯uz¯ıtis, Bruno Guillaume, Kirian Guiller,\nCéline Guillot-Barbance, Tunga Güngör,\nNizar Habash, Hinrik Hafsteinsson, Jan\nHajiˇc, Jan Hajiˇc jr., Mika Hämäläinen, Linh\nHà M˜y, Na-Rae Han,\nMuhammad Yudistira Hanifmuti,\nTakahiro Harada, Sam Hardwick, Kim\nHarris, Naïma Hassert, Dag Haug,\nJohannes Heinecke, Oliver Hellwig, Felix\nHennig, Barbora Hladká, Jaroslava\nHlaváˇcová, Florinel Hociung, Diana\nHoefels, Petter Hohle, Yidi Huang,\nMarivel Huerta Mendez, Jena Hwang,\nTakumi Ikeda, Inessa Iliadou, Anton Karl\nIngason, Radu Ion, Elena Irimia, O. lájídé\nIshola, Artan Islamaj, Kaoru Ito, Federica\nIurescia, Sandra Jagodzi´nska, Siratun\nJannat, Tomáš Jelínek, Apoorva Jha,\nKatharine Jiang, Mayank Jobanputra,\nAnders Johannsen, Hildur Jónsdóttir,\nFredrik Jørgensen, Markus Juutinen,\nHüner Ka¸sıkara, Nadezhda Kabaeva,\n27\nPre-print. Under review.\nSylvain Kahane, Hiroshi Kanayama, Jenna\nKanerva, Neslihan Kara, Ritván Karahóˇga,\nAndre Kåsen, Tolga Kayadelen,\nSarveswaran Kengatharaiyer, Václava\nKettnerová, Lilit Kharatyan, Jesse\nKirchner, Elena Klementieva, Elena\nKlyachko, Petr Kocharov, Arne Köhn,\nAbdullatif Köksal, Kamil Kopacewicz,\nTimo Korkiakangas, Mehmet Köse, Alexey\nKoshevoy, Natalia Kotsyba, Barbara\nKovaˇci´c, Jolanta Kovalevskait˙e, Simon\nKrek, Parameswari Krishnamurthy,\nSandra Kübler, Adrian Kuqi, O˘guzhan\nKuyrukçu, Aslı Kuzgun, Sookyoung\nKwak, Kris Kyle, Käbi Laan, Veronika\nLaippala, Lorenzo Lambertino, Tatiana\nLando, Septina Dian Larasati, Alexei\nLavrentiev, John Lee, Phuong Lê H`ông,\nAlessandro Lenci, Saran Lertpradit,\nHerman Leung, Maria Levina, Lauren\nLevine, Cheuk Ying Li, Josie Li, Keying Li,\nYixuan Li, Yuan Li, KyungTae Lim, Bruna\nLima Padovani, Yi-Ju Jessica Lin, Krister\nLindén, Yang Janet Liu, Nikola Ljubeši´c,\nIrina Lobzhanidze, Olga Loginova,\nLucelene Lopes, Stefano Lusito,\nAnne-Marie Lutgen, Andry Luthfi, Mikko\nLuukko, Olga Lyashevskaya, Teresa Lynn,\nVivien Macketanz, Menel Mahamdi, Jean\nMaillard, Ilya Makarchuk, Aibek\nMakazhanov, Francesco Mambrini,\nMichael Mandl, Christopher Manning,\nRuli Manurung, Bü¸sra Mar¸san, C˘at˘alina\nM˘ar˘anduc, David Mareˇcek, Katrin\nMarheinecke, Stella Markantonatou,\nHéctor Martínez Alonso, Lorena\nMartín Rodríguez, André Martins,\nCláudia Martins, Jan Mašek, Hiroshi\nMatsuda, Yuji Matsumoto, Alessandro\nMazzei, Ryan McDonald, Sarah\nMcGuinness, Maitrey Mehta, Pierre André\nMénard, Gustavo Mendonça, Tatiana\nMerzhevich, Paul Meurer, Niko Miekka,\nEmilia Milano, Aaron Miller, Karina\nMischenkova, Anna Missilä, C˘at˘alin\nMititelu, Maria Mitrofan, Yusuke Miyao,\nAmirHossein Mojiri Foroushani, Judit\nMolnár, Amirsaeid Moloodi, Simonetta\nMontemagni, Amir More, Laura\nMoreno Romero, Giovanni Moretti,\nShinsuke Mori, Tomohiko Morioka,\nShigeki Moro, Bjartur Mortensen, Bohdan\nMoskalevskyi, Kadri Muischnek, Robert\nMunro, Yugo Murawaki, Kaili Müürisep,\nPinkey Nainwani, Mariam Nakhlé,\nJuan Ignacio Navarro Horñiacek, Anna\nNedoluzhko, Gunta Nešpore-B¯erzkalne,\nManuela Nevaci, Luong Nguy˜ên Thi.,\nHuy`ên Nguy˜ên Thi. Minh, Yoshihiro\nNikaido, Vitaly Nikolaev, Rattima\nNitisaroj, Victor Norrman, Alireza\nNourian, Maria das Graças Volpe Nunes,\nHanna Nurmi, Stina Ojala, Atul Kr. Ojha,\nHulda Óladóttir, Adéday‘.o Olúòkun, Mai\nOmura, Emeka Onwuegbuzia, Noam\nOrdan, Petya Osenova, Robert Östling,\nAnnika Ott, Lilja Øvrelid, ¸Saziye Betül\nÖzate¸s, Merve Özçelik, Arzucan Özgür,\nBalkız Öztürk Ba¸saran, Teresa Paccosi,\nAlessio Palmero Aprosio, Anastasia\nPanova, Thiago Alexandre Salgueiro\nPardo, Hyunji Hayley Park, Niko\nPartanen, Elena Pascual, Marco Passarotti,\nAgnieszka Patejuk, Guilherme\nPaulino-Passos, Giulia Pedonese, Angelika\nPeljak-Łapi´nska, Siyao Peng, Siyao Logan\nPeng, Rita Pereira, Sílvia Pereira,\nCenel-Augusto Perez, Natalia Perkova,\nGuy Perrier, Slav Petrov, Daria Petrova,\nAndrea Peverelli, Jason Phelan, Claudel\nPierre-Louis, Jussi Piitulainen, Yuval\nPinter, Clara Pinto, Rodrigo Pintucci,\nTommi A Pirinen, Emily Pitler, Magdalena\nPlamada, Barbara Plank, Alistair Plum,\nThierry Poibeau, Larisa Ponomareva,\nMartin Popel, Lauma Pretkalnin, a, Rigardt\nPretorius, Sophie Prévost, Prokopis\nProkopidis, Adam Przepiórkowski, Robert\nPugh, Tiina Puolakainen, Christoph\nPurschke, Sampo Pyysalo, Peng Qi,\nAndreia Querido, Andriela Rääbis,\nAlexandre Rademaker, Mizanur\nRahoman, Taraka Rama, Loganathan\nRamasamy, Carlos Ramisch, Joana Ramos,\nFam Rashel, Mohammad Sadegh Rasooli,\nVinit Ravishankar, Livy Real, Petru Rebeja,\nSiva Reddy, Mathilde Regnault, Georg\nRehm, Arij Riabi, Ivan Riabov, Michael\nRießler, Erika Rimkut˙e, Larissa Rinaldi,\nLaura Rituma, Putri Rizqiyah, Luisa\nRocha, Eiríkur Rögnvaldsson, Ivan\nRoksandic, Mykhailo Romanenko, Rudolf\nRosa, Valentin Ros,ca, Davide Rovati, Ben\nRozonoyer, Olga Rudina, Jack Rueter,\nPaolo Ruffolo, Kristján Rúnarsson, Shoval\nSadde, Pegah Safari, Aleksi Sahala, Shadi\nSaleh, Alessio Salomoni, Tanja Samardži´c,\nStephanie Samson, Xulia\nSánchez-Rodríguez, Manuela Sanguinetti,\nEzgi Sanıyar, Dage Särg, Marta Sartor,\nAlbina Sarymsakova, Mitsuya Sasaki,\nBaiba Saul¯ıte, Agata Savary, Yanin\nSawanakunanon, Shefali Saxena, Kevin\nScannell, Salvatore Scarlata, Emmanuel\nSchang, Nathan Schneider, Sebastian\nSchuster, Lane Schwartz, Djamé Seddah,\nWolfgang Seeker, Sven Sellmer, Mojgan\nSeraji, Syeda Shahzadi, Mo Shen, Atsuko\n28\nPloeger et al.\nA Principled Framework for Evaluating on Typologically Diverse Languages\nShimada, Hiroyuki Shirasu, Yana\nShishkina, Muh Shohibussirri, Maria\nShvedova, Janine Siewert, Einar Freyr\nSigurðsson, João Silva, Aline Silveira,\nNatalia Silveira, Sara Silveira, Maria Simi,\nRadu Simionescu, Katalin Simkó, Mária\nŠimková, Haukur Barri Símonarson, Kiril\nSimov, Dmitri Sitchinava, Ted Sither,\nAaron Smith, Isabela Soares-Bastos,\nPer Erik Solberg, Barbara Sonnenhauser,\nShafi Sourov, Rachele Sprugnoli, Vivian\nStamou, Steinhór Steingrímsson, Antonio\nStella, Abishek Stephen, Milan Straka,\nEmmett Strickland, Jana Strnadová, Alane\nSuhr, Yogi Lesmana Sulestio, Umut\nSulubacak, Shingo Suzuki, Daniel\nSwanson, Zsolt Szántó, Chihiro Taguchi,\nDima Taji, Fabio Tamburini, Mary Ann C.\nTan, Takaaki Tanaka, Dipta Tanaya, Mirko\nTavoni, Samson Tella, Isabelle Tellier,\nMarinella Testori, Guillaume Thomas,\nTarık Emre Tıra¸s, Sara Tonelli, Liisi Torga,\nMarsida Toska, Trond Trosterud, Anna\nTrukhina, Reut Tsarfaty, Utku Türk,\nFrancis Tyers, Sveinbjörn Hórðarson,\nVilhjálmur Horsteinsson, Sumire\nUematsu, Roman Untilov, Zdeˇnka\nUrešová, Larraitz Uria, Hans Uszkoreit,\nAndrius Utka, Elena Vagnoni, Sowmya\nVajjala, Socrates Vak, Rob van der Goot,\nMartine Vanhove, Daniel van Niekerk,\nGertjan van Noord, Viktor Varga, Uliana\nVedenina, Giulia Venturi, Eric Villemonte\nde la Clergerie, Veronika Vincze, Anishka\nVissamsetty, Natalia Vlasova, Eleni\nVligouridou, Aya Wakasa, Joel C.\nWallenberg, Lars Wallin, Abigail Walsh,\nJohn Wang, Jonathan North Washington,\nMaximilan Wendt, Paul Widmer, Shira\nWigderson, Sri Hartati Wijono,\nVanessa Berwanger Wille, Seyi Williams,\nMats Wirén, Christian Wittern, Tsegay\nWoldemariam, Tak-sum Wong, Alina\nWróblewska, Qishen Wu, Mary Yako,\nKayo Yamashita, Naoki Yamazaki,\nChunxiao Yan, Koichi Yasuoka, Marat M.\nYavrumyan, Arife Betül Yenice, Enes\nYılandilo˘glu, Olcay Taner Yıldız, Zhuoran\nYu, Arlisa Yuliawati, Zdenˇek Žabokrtský,\nShorouq Zahra, Amir Zeldes, He Zhou,\nHanzhi Zhu, Yilun Zhu, Anna\nZhuravleva, and Rayan Ziane. 2024.\nUniversal dependencies 2.14.\nLINDAT/CLARIAH-CZ digital library at\nthe Institute of Formal and Applied\nLinguistics (ÚFAL), Faculty of\nMathematics and Physics, Charles\nUniversity.\nZhang, Xiang, Senyu Li, Bradley Hauer,\nNing Shi, and Grzegorz Kondrak. 2023.\nDon’t trust ChatGPT when your question\nis not in English: A study of multilingual\nabilities and types of LLMs. In Proceedings\nof the 2023 Conference on Empirical Methods\nin Natural Language Processing, pages\n7915–7927, Association for Computational\nLinguistics, Singapore.\n29\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2024-07-06",
  "updated": "2024-07-06"
}