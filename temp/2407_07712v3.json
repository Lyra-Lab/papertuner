{
  "id": "http://arxiv.org/abs/2407.07712v3",
  "title": "Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs",
  "authors": [
    "Ahmad Naser Eddin",
    "Jacopo Bono",
    "David Aparício",
    "Hugo Ferreira",
    "Pedro Ribeiro",
    "Pedro Bizarro"
  ],
  "abstract": "Continuous-time dynamic graphs (CTDGs) are essential for modeling\ninterconnected, evolving systems. Traditional methods for extracting knowledge\nfrom these graphs often depend on feature engineering or deep learning. Feature\nengineering is limited by the manual and time-intensive nature of crafting\nfeatures, while deep learning approaches suffer from high inference latency,\nmaking them impractical for real-time applications. This paper introduces\nDeep-Graph-Sprints (DGS), a novel deep learning architecture designed for\nefficient representation learning on CTDGs with low-latency inference\nrequirements. We benchmark DGS against state-of-the-art (SOTA) feature\nengineering and graph neural network methods using five diverse datasets. The\nresults indicate that DGS achieves competitive performance while inference\nspeed improves between 4x and 12x compared to other deep learning approaches on\nour benchmark datasets. Our method effectively bridges the gap between deep\nrepresentation learning and low-latency application requirements for CTDGs.",
  "text": "Published in Transactions on Machine Learning Research (11/2024)\nDeep-Graph-Sprints: Accelerated Representation Learning\nin Continuous-Time Dynamic Graphs\nAhmad Naser eddin\nahmad.eddin@feedzai.com\nFeedzai, Portugal\nDepartamento de Ciência de Computadores, Faculdade de Ciências, Universidade do Porto, Portugal\nJacopo Bono\njacopo.bono@feedzai.com\nFeedzai, Portugal\nDavid Aparício\ndaparicio@dcc.fc.up.pt\nDepartamento de Ciência de Computadores, Faculdade de Ciências, Universidade do Porto, Portugal\nHugo Ferreira\nhugo.ferreira@feedzai.com\nFeedzai, Portugal\nPedro Ribeiro\npribeiro@dcc.fc.up.pt\nDepartamento de Ciência de Computadores, Faculdade de Ciências, Universidade do Porto, Portugal\nPedro Bizarro\npedro.bizarro@feedzai.com\nFeedzai, Portugal\nReviewed on OpenReview: https: // openreview. net/ forum? id= 0uwe0z2Hqm\nAbstract\nContinuous-time dynamic graphs (CTDGs) are essential for modeling interconnected,\nevolving systems. Traditional methods for extracting knowledge from these graphs often\ndepend on feature engineering or deep learning. Feature engineering is limited by the man-\nual and time-intensive nature of crafting features, while deep learning approaches suffer from\nhigh inference latency, making them impractical for real-time applications. This paper intro-\nduces Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for efficient\nrepresentation learning on CTDGs with low-latency inference requirements. We benchmark\nDGS against state-of-the-art (SOTA) feature engineering and graph neural network methods\nusing five diverse datasets. The results indicate that DGS achieves competitive performance\nwhile inference speed improves between 4x and 12x compared to other deep learning ap-\nproaches on our benchmark datasets. Our method effectively bridges the gap between deep\nrepresentation learning and low-latency application requirements for CTDGs.\n1\nIntroduction\nGraphs serve as a foundational structure for modeling and analyzing interconnected systems, with appli-\ncations spanning in computer science, mathematics, and life sciences. Recent studies have emphasized the\ncritical role of dynamic graphs, which capture evolving relationships in systems like social networks and\nfinancial markets (Costa et al., 2007; Zhang et al., 2020; Zhou et al., 2020; Majeed & Rauf, 2020; Febrinanto\net al., 2023).\nGraph structure representation is crucial for encoding complex graph information into low-dimensional em-\nbeddings that are usable by machine learning models. This task is particularly challenging for dynamic\ngraphs.\nTraditional graph feature engineering methods rely on manually crafted heuristics to capture\ngraph characteristics, necessitating domain knowledge and considerable time to engineer and test new\n1\narXiv:2407.07712v3  [cs.LG]  7 Nov 2024\nPublished in Transactions on Machine Learning Research (11/2024)\nfeatures (Bilot et al., 2023). In contrast, graph representation learning, especially through graph neural\nnetworks (GNNs), automates this process by learning compact embeddings of graph structures (Hamilton\net al., 2017b). Despite growing interest in this field, research has predominantly focused on static graphs,\noverlooking the dynamic nature of many real-world systems (Perozzi et al., 2014; Grover & Leskovec, 2016;\nHamilton et al., 2017a).\nDynamic graphs are categorized into Discrete Time Dynamic Graphs (DTDGs) and Continuous Time\nDynamic Graphs (CTDGs) (Rossi et al., 2020).\nDTDGs are viewed as a sequence of snapshots at set\nintervals, while CTDGs are seen as a continuous stream of events, such as adding a new edge, which updates\nthe graph’s structure with each occurrence. This paper aims to advance the state-of-the-art (SOTA) in\nrepresentation learning for CTDGs.\nExisting methods for handling CTDGs (Dai et al., 2016; Kumar et al., 2019; Xu et al., 2020; Rossi et al.,\n2020) often face computational constraints, leading to high-latency inference, thus limiting their practicality\nfor real-time applications. Approaches such as asynchronous operation and truncated backpropagation have\nbeen employed to mitigate these issues, but they introduce compromises in representation accuracy and the\nlearning of long-term dependencies (Rossi et al., 2020; Wang et al., 2021).\nThis paper introduces a novel architecture for the representation learning of CTDGs, designed to overcome\nexisting limitations and provide low-latency, efficient representation learning. Our approach employs forward-\nmode automatic differentiation, specifically real-time recurrent learning (RTRL) (Williams & Zipser, 1989),\nwithin a customized recurrent cell structure. This enables low-latency inference, efficient computation, and\noptimized memory usage, while preserving representation accuracy and the ability to capture long-term\ndependencies. The contributions of this work are as follows:\n• We identify the limitations in current methodologies for graph representation learning, highlight-\ning their computational inefficiencies and their challenges in capturing long-term dependencies, see\nSections 2,5.\n• We introduce Deep-Graph-Sprints (DGS), a method for real-time representation learning of CTDGs,\noptimizing latency and enhancing the ability to capture long-term dependencies, see Sections 3.\n• We benchmark DGS against SOTA methods, in node classification and link prediction tasks, demon-\nstrating on par predictive performance while achieving significantly faster inference speed—ups up\nto 12x faster than TGN-attn (Rossi et al., 2020), and up to 8x faster than both TGN-ID (Rossi\net al., 2020) and Jodie (Kumar et al., 2019). Detailed results are provided in Section 4.\n2\nBackground: Overview of Automatic Differentiation Modes\nDeep learning depends significantly on credit assignment, a process identifying the impact of past actions on\nlearning signals (Minsky, 1961; Sutton, 1984). This process is essential for reinforcing successful behaviors\nand reducing unsuccessful ones.\nThe capability of assigning credit in deep learning models depends on the differentiability of learning signals\nenabling the use of Jacobians for this purpose (Cooijmans & Martens, 2019). A key technique in this context\nis automatic differentiation (AD), a computational mechanism for the derivation of Jacobians through a\npredefined set of elementary operations and the application of the chain rule, applicable even in programs\nwith complex control flows (Baydin et al., 2018). In AD, depending on the direction of applying the chain\nrule, three strategies stand out: forward mode, reverse mode (often termed backpropagation), and mixed\nmode. Forward mode involves multiplying the Jacobians matrices from input to output. Reverse mode, a\ntwo-phase process, first executes the function to populate intermediate variables and map dependencies, then\ncalculates Jacobians in reverse order from outputs to inputs (Baydin et al., 2018). Mixed mode combines\nthese approaches.\nTemporal models, such as recurrent neural networks (RNNs) and GNNs for temporal graphs, pose specific\nchallenges for backpropagation due to their memory-intensive requirements. The memory complexity for\nstoring intermediate states across a history significantly impacts the feasibility of full backpropagation.\n2\nPublished in Transactions on Machine Learning Research (11/2024)\nFor instance, in an RNN with sequence length l and state size d, backpropagation-through-time exhibits\ncomputational and memory complexities of O(l × d2), posing scalability issues for long sequences (Baydin\net al., 2018). To mitigate these challenges, truncated backpropagation through time (TBPTT) optimizes\nresource usage by limiting the backpropagation horizon, thus reducing both computational and memory\ndemands. However, TBPTT’s constraint on the temporal horizon restricts its ability to capture long-term\ndependencies, impacting model performance over extended sequences (Williams & Peng, 1990).\nForward-mode AD, exemplified in real-time recurrent learning (RTRL), offers an alternative by facilitating\nonline updates of the parameters, which is particularly advantageous for models requiring the retention\nof information over extended durations (or sequence length). Despite its benefits for capturing long-term\ndependencies with reduced memory overhead (O(d2)), RTRL’s computational demand (O(d4)) limits its\npracticality in large-scale networks (Williams & Zipser, 1989; Cooijmans & Martens, 2019).\nIn summary, while full backpropagation through time has high memory demands, TBPTT presents a com-\npromise by reducing memory and computational needs at the expense of long-term dependency capture.\nForward mode AD (RTRL in our case) addresses both long-term retention and memory efficiency but is\nrestricted by its computational complexity.\nTo address these limitations, our approach leverages RTRL, thus benefiting from its low memory footprint,\nand combines it with a custom architecture that reduces its computational complexity to match that of\nbackpropagation. This design effectively mitigates the computational challenges typically associated with\nforward-mode AD, and allows the model to capture long-term dependencies unlike TBPTT.\n3\nMethod\nIn this section we detail our low latency node representation learning method, namely Deep-Graph-Sprints\n(DGS). We start by explaining the main components that form its architecture and then we detail each\none of them. Furthermore, we detail the training paradigm that distinguishes our method, highlighting its\nmemory demands and ability to capture long-term dependencies compared to existing approaches through\nits RTRL-based approach. Additionally, we explain our method during inference, demonstrating how it\nachieves low latencies.\n3.1\nArchitecture\nThe DGS method is developed to handle a stream of edges. As shown in Figure 1, the system processes each\nincoming edge to derive a task-specific score, applicable for any ML task such as classification.\nSimilar to established approaches in this domain, e.g., (Rossi et al., 2020; Kumar et al., 2019), our DGS\nmethod is divided into two key components:\n1. Embedding Recurrent Component (ER): dedicated to representation learning, where each node or\nedge in the graph is mapped from high-dimensional, complex graph structures to a lower-dimensional\nembedding space.\n2. Neural Network (NN): responsible for decision-making processes, such as classification. It uses the\nembedding provided by the ER component to generate a task specific output.\nThe ER component is particularly noteworthy for its role in updating the embeddings of nodes or edges,\nthereby enriching them with detailed attributes and relationships context within the network. These em-\nbeddings are then input into the neural network, which is tailored to specific applications. For instance, in\nnode classification, the network evaluates each node associated with a new edge, with the score reflecting\nthe network’s interpretation from the representations provided by the ER component.\n3.1.1\nEmbedding Recurrent Component (ER):\nThis subsection delineates the ER component, the core mechanism within our methodology that processes\ndynamic graph data. Building upon Graph-Sprints (Eddin et al., 2023), a low-latency graph feature engi-\n3\nPublished in Transactions on Machine Learning Research (11/2024)\nFigure 1: Schematic representation of the DGS architecture. The diagram illustrates the workflow from\nreceiving new edge, through the generation of embeddings for nodes or edges, to the application of a neural\nnetwork to generate a task specific score. Furthermore, the diagram elucidates the computation of gradients\nthrough the application of mixed-mode AD. Equation 2, and Figure 2 provide more details about the ER\ncomponent.\nneering approach, that is formalized in Equation 1. A node’s embedding is determined by integrating its\nhistorical state, the historical state of its immediate neighbor (with which it shares the current edge), and\nthe attributes of the current edge.\n⃗St = β⃗St−1 + (1 −β)\n\u0010\n(1 −α)⃗δ( ⃗Ft) + α⃗S∗\nt−1\n\u0011\n(1)\nHere, ⃗St denotes the state of a node at time t, evolving from its previous state ⃗St−1 and the state of its\nimmediate neighbor ⃗S∗\nt−1, while also incorporating the current edge’s features ⃗Ft, encoded through the ⃗δ\nfunction, which bucketizes these features. The ⃗δ function maps numerical features into a one-hot encoded\nvector based on predetermined buckets (e.g., buckets corresponding to specific percentiles). This bucketiza-\ntion provides a deterministic representation of the input features, which requires manual tuning to define the\nbuckets and results in sparse, high-dimensional feature vectors. The coefficients α and β are scalar forgetting\nfactors that modulate the impact of neighborhood and past information on the current state.\nAlthough Graph-Sprints demonstrates rapid processing capabilities and performs on par with leading tech-\nniques, it faces several limitations in practical applications. These include the complex and time-consuming\ntuning processes required for its feature extraction and decision-making components. For instance, to tune\nthe forgetting coefficients or to define the bucketed features edges of the ⃗δ function for every feature. More-\nover, the model’s expressivity is constrained by the uniform application of scalar forgetting coefficients across\nall features, limiting its ability to capture the unique temporal dynamics of each feature. Finally, the use of\nlarge number of buckets per feature significantly increases the memory requirements especially in datasets\nwith many features. In contrast, our proposed methodology, while drawing inspiration from Graph-Sprints,\ngoes beyond traditional feature engineering by employing a dynamic learning mechanism for embeddings.\nThe state update equation in our methodology is illustrated in Equation 2:\n⃗St = ⃗β ⊙⃗St−1 + (1 −⃗β) ⊙\n \n(1 −⃗α) ⊙\n m\r\r\r\ni=1\n⃗σ(Wi ⃗Ft)\n!\n+ ⃗α ⊙⃗S∗\nt−1\n!\n(2)\nIn this equation, we introduce vectorized forgetting coefficients, ⃗α and ⃗β, each corresponding in dimensional-\nity to the state vector, and modulate the weighting between current and historical information, and between\nself and neighborhood information, respectively. Each dimension of ⃗α and ⃗β corresponds to unique forgetting\nrates for each embedded feature in the state vector, which itself consists of a vector as we will detail below.\n4\nPublished in Transactions on Machine Learning Research (11/2024)\nThe embedding matrix W is tasked with mapping input features into a vector of the same size as the state\nvector.\nInspired by the Graph-Sprints feature representations, where the buckets that belong to the same feature\nsum to one, we utilize the softmax function (⃗σ) to achieve analogous representations.Moreover, we employ\nsoftmax temperature scaling (Guo et al., 2017) where higher temperatures result in softer distributions. DGS\nenhances model expressiveness and optimizes memory usage by incorporating multiple softmax functions,\neach applied to a segment of the product between the embedding matrix W and the feature vector ⃗Ft. The\nnotation\n\r\rm\ni=1 denotes the concatenation of the results obtained by applying the m softmax functions. Each\nfunction is applied to the product of the i-th portion of the embedding matrix, Wi, and the features values\n⃗Ft, as illustrated in Figure 2. This strategy not only aids in reducing computational and memory demands\nby limiting the dependency of each state element to a specific segment of the embedding matrix and thereby\nlowering the Jacobian’s dimensionality but also introduces a modular structure.\nFigure 2: Schematic illustration of state calculation based on Equation 2. This example demonstrates the\ncomputation of node state at time t with a state size of s = 6, three softmaxes (m = 3), and thus two rows\nper softmax from the embedding matrix W (h = s/m = 2). The number of input features is f = 4.\n3.1.2\nNeural Network (NN)\nThe NN component is a feedforward neural network, that encompasses multiple layers. The configuration\nof this component is subject to optimization depending on the task at hand. This optimization includes\ndecisions such as the number of layers, the size of each layer, and the incorporation of normalization layers.\nAlthough Equation 1 (GS) and Equation 2 (DGS) present similarities.\nThere are several aspects that\ndistinguish Graph-Sprints and DGS methods. GS is a feature engineering approach with fixed embeddings,\nwhile DGS employs deep learning with learnable embeddings. Moreover, parameter optimization in GS is\nseparate, whereas DGS allows end-to-end optimization. Table 4 compares both methods.\n3.2\nTraining Process\nThe design of DGS methodically incorporates forward-mode AD for learning the ER component, whereas,\nthe subsequent NN component, processing the embeddings generated by the ER component, utilizes reverse-\nmode AD. This hybrid approach effectively leverages the strengths of both paradigms, namely, learning\n5\nPublished in Transactions on Machine Learning Research (11/2024)\nlong-term dependencies (as detailed in Section 2), and ensuring efficient learning while accommodating the\nmemory constraints and structural complexities of graph data.\nIn typical ML scenarios, the complexity of forward-mode AD limits its applicability. Nonetheless, forward-\nmode AD is applicable in situations requiring a manageable number of Jacobian computations, offering\nefficient Jacobian propagation through computational graphs. In the DGS method, the feasibility of forward-\nmode AD is supported by two main factors. First, DGS is dominated by elementwise multiplications, where\ndifferent elements of a state vector are not mixed together. Second, the implementation of multiple softmax\nfunctions limits the dependency of each state element to a segment of the embedding matrix W, thus reducing\nthe computational and memory requirements.\nThe element-wise multiplication between the state vectors ⃗S and the parameter vectors ⃗α and ⃗β optimizes\nthe calculation of Jacobians ∂⃗S\n∂⃗α and ∂⃗S\n∂⃗β , achieving a computational and memory complexity of O(s), where\ns represents the size of the state vector. In contrast, performing these operations via matrix multiplication,\nimplying α and β are (s × s) matrices, would increase the complexity to O(s3). Regarding the embedding\nmatrix W, with dimensions s × f (embedding size by the number of features), the application of a single\nsoftmax function over the entire embedded vector would result in Jacobians\n∂⃗S\n∂W with dimensions f × s2,\nleading to computational and memory complexities of O(f × s2). However, DGS mitigates this through\nthe deployment of multiple softmax functions, each managing a segment of the state. With m softmax\nfunctions, each addressing a subset of h = s/m rows, the computational and memory requirements are\neffectively reduced to O(f × h × s), demonstrating the method’s efficiency in optimizing both computational\nand memory resources. Furthermore, one can easily fix h to a predetermined value and optimize the state size\ns to be multiples of this parameter. Therefore, assuming a fixed h, the total computational complexity scales\nlinearly with respect to the state size s. This property demonstrates a better scaling than backpropagation,\nwhich scales with s2. These factors collectively justify the selection of forward-mode AD for the differentiation\nprocess in the ER component of our architecture. The Jacobians updates were implemented manually using\nPyTorch (Fey & Lenssen, 2019).\nIn the NN component, number of learnable parameters varies based on model architecture, primarily involv-\ning the network’s weights. The parameters of the NN component are optimized using backpropagation, and\nto implement that we also leverage the functionalities of PyTorch. As a result, the architecture of the DGS\nmethod employs a mixed-mode AD approach, as illustrated in Figure 3.\nCompared to the GS approach, allowing the key parameters (⃗α, ⃗β, and W) to be learned from the data over-\ncomes the limitations of separate tuning processes, thereby simplifying the training procedure. Additionally,\nthis enables the use of vectorized forgetting coefficients instead of scalar ones, which significantly enhances\nthe model’s expressivity.\nMini-Batch Training\nTo expedite the training process, we employ mini-batch training, wherein the input comprises a batch of\nedges.\nIn cases where a singular node appears multiple times within a single batch, each occurrence is\nassociated with the same prior node state, which represents the most recent state prior to the batch’s\nexecution. This methodology implies that nodes contained within the same batch do not utilize the most\ncurrent information due to the prohibition of intra-batch informational exchange. One can also implement a\nbatch strategy similar to the one implemented by the Jodie method (Kumar et al., 2019), where batch size\nis dynamic and nodes only appear once in the same batch.\n3.3\nInference Process\nThe inference phase is characterized by the absence of gradient computation, which simplifies the overall\nprocedure. In the streaming context, as elaborated in Section 3.1, the occurrence of an edge triggers an update\nin the states of the nodes interconnected by this edge, employing Equation 2 for the update mechanism.\nSubsequently, these updated states are ingested by the NN component. The nature of the input to the NN\ncomponent is task-dependent: it may constitute a singular node state for node classification tasks, or the\nconcatenation of two node states for tasks such as link prediction.\n6\nPublished in Transactions on Machine Learning Research (11/2024)\nFigure 3:\nRecurrent Training Process:\nThis figure illustrates the steps involved over three successive\ntimesteps, focusing on the derivative calculation for a single learnable parameter ⃗α using a mixed-mode\napproach. It combines forward mode differentiation for the ER component with backpropagation for the\nneural network classifier. This methodology extends to update other parameters (i.e., ⃗β, W). This hybrid\napproach enables an efficient solution that effectively captures long-term dependencies.\nMini-Batch Inference\nTo accelerate inference in scenarios suitable for batch processing, we employ a mini-batch inference strategy.\nThis approach updates the states of nodes or edges within each batch simultaneously. When a node appears\nmultiple times within the same batch, as in the training phase, each instance is linked to the same prior\nnode state, which is the most recent state before the batch’s execution. Consequently, there is no exchange\nof states within the batch. Note that this is optional and similarly to mini-batch procedure in training we\ncan leverage a different strategy.\nFollowing the parallel updates, the aggregated states are inputted into the neural network (NN) component.\nThis step generates a batched output tailored to the task, whether it involves node classification, link\nprediction, or any other relevant activity.\nIt is important to note that the DGS method is fully online and supports both single-sample and mini-batch\ninference, offering flexibility depending on the scenario. Mini-batch inference, when suitable, improves both\ntraining and inference speeds even further. In our experiments (Section ??), we utilize mini-batch inference\nto ensure comparability with other experimental setups used in state-of-the-art studies.\n4\nExperiments and Results\n4.1\nExperimental Setup\nThe efficacy of our methodology was evaluated through the node classification and link prediction tasks\nacross five different datasets. This include three open-source external datasets and two proprietary datasets\nfrom the anti-money laundering (AML) domain.\n7\nPublished in Transactions on Machine Learning Research (11/2024)\nBaselines\nWe compare the performance of our method against several baselines. The first simple baseline, called Raw,\ntrains a machine learning model using only raw edge features. Another baseline is Graph-Sprints (Eddin\net al., 2023) a graph feature engineering method, which we refer to by GS. The GS baseline uses the same ML\nclassifier used by the Raw baseline but diverges in the features used for training— GS employs Graph-Sprints\nencoded features, whereas Raw employs the raw edge features.\nAn additional baseline set comprises SOTA GNN methods, specifically TGN (Rossi et al., 2020). Our TGN\nimplementation, based on the default PyTorch Geometric implementation, differs from the original paper by\nrestricting within-batch neighbor sampling, for a more realistic scenario.\nFor the node classification tasks, our TGN implementation diverges slightly from the default PyTorch Geo-\nmetric implementation, which was originally implemented for link prediction, by updating the state of target\nnodes with current edge features before classification. In contrast, for link prediction, this update occurs after\nthe classification decision, aligning with the PyTorch Geometric implementation. These settings are typical\nfor node classification and link prediction, respectively, and both GS and DGS follow the same setup1.\nSeveral TGN variants were used: TGN-attn, aligning with the original paper’s best variant, TGN-ID, a\nsimplified version focusing solely on memory module embeddings, and Jodie, which utilizes a time projection\nembedding with gated recurrent units. TGN-ID and Jodie baselines, which do not necessitate neighbor\nsampling, were chosen for their lower-latency attributes compared to TGN-attn. All GNN baselines (TGN-\nID, TGN-attn, and Jodie) used a node embedding size of 100.\nOptimization\nThe hyperparameter optimization process utilizes Optuna (Akiba et al., 2019) for training 100 models. Initial\n70 trials are conducted through random sampling, followed by the application of the TPE sampler. Each\nmodel incorporated an early stopping mechanism, triggered after 10 epochs without improvement. Table 6\nenumerates the hyperparameters and their respective ranges employed in the tuning process of DGS and the\nbaselines.\nImportantly, the state size for DGS is fixed to 100 in the node classification task, achieved by setting the\nproduct of the number of softmax functions and the number of rows per softmax to 100 (m × h = 100).\nThis aligns with the configurations of other GNN baseline models (TGN-ID, TGN-attn, and Jodie) to\nensure comparability. In the link prediction task, we set the DGS state size to 250 because a state size of\n100 was insufficient for achieving comparable performance. Despite this larger state size compared to the\nGNN baselines, the DGS method has, on average, 2.5 times fewer learnable parameters than the TGN-attn\nbaseline. Additionally, only 35% of the learnable parameters in DGS on average are attributed to the ER\ncomponent, with the remaining 65% belonging to the classification head (further detail in Table 9).\nDatasets\nWe leverage five different datasets, all CTDGs and labeled. Each dataset is split into train, validation, and\ntest sets respecting time (i.e., all events in the train are older than the events in validation, and all events in\nvalidation are older than the events in the test set). Three of these datasets are public (Kumar et al., 2019)\nfrom the social and education domains. In these three datasets, we adopt the identical data partitioning\nstrategy employed by the baseline methods we compare against, which also utilized these datasets. The\nother two datasets are real-world banking datasets from the AML domain. Due to privacy concerns, we can\nnot disclose the identity of the FIs nor provide exact details regarding the node features. We refer to the\ndatasets as FI-A and FI-B. The graphs in this use case are constructed by considering the accounts as nodes\nand the money transfers between accounts as edges. Table 5 shows the details of all the used datasets.\n1In the original GS paper, link prediction for the GS was performed using the same setup as node classification, i.e. updating\nthe state before classification. We believe it is more fair to use the link prediction setup as all other models, hence our GS results\non link prediction tasks are not directly comparable to the original paper. Similarly, the TGN baselines in node classification\ntasks used the link prediction setup in the original paper, hence those results are also not directly comparable here.\n8\nPublished in Transactions on Machine Learning Research (11/2024)\n4.2\nNode classification\nIn the node classification task, given the dataset characteristics detailed in Table 5, we address binary\nclassification with class imbalance. To evaluate performance, we calculate the area under the ROC curve\n(ROC-AUC), referred to as AUC for brevity, by plotting the True Positive Rate (TPR) against the False\nPositive Rate (FPR) across various classification thresholds, and then computing the area under the curve.\nThe AUC is calculated using the ’sklearn’ library in python.\nThe results for node classification are detailed in Table 1, displaying the average test AUC ± std for the\nexternal datasets and the ∆AUC for the AML datasets. To obtain these figures, we retrained the best\nmodel identified through hyperparameter optimization across 10 different random seeds.\nIt is important to note that the GNNs and GS baselines leverage the latest edge information, similar to the\nDGS method. This means they update the node state with the most recent information before classifying\nthe node.\nWe have highlighted the best and second-best performing models for each dataset. To provide an overview,\nwe include a column showing the average rank, representing the mean ranking computed from all datasets.\nDGS achieves either the highest or the second-highest scores in four out of the five datasets. The exception\nis the Mooc dataset, where GNN baselines surpass our method. We did note that there is some overfitting\nof the GNN baselines. This is due to the extreme scarcity in positive labels, which resulted in the validation\nmetrics being badly correlated with the test metrics for these baselines.\nCounter-intuitively, although not reported here2, we observed that the performance of the GNN baselines im-\nproved when evaluated without leveraging the latest edge features, which could indicate a reduced overfitting\nto the validation dataset.\nTable 1: Node classification results using public and internal datasets.\nMethod\nAUC ± std\n∆AUC ± std\nAverage\nrank\nWikipedia\nMooc\nReddit\nFI-A\nFI-B\nRaw\n58.5 ± 2.2\n62.8 ± 0.9\n55.3 ± 0.8\n0\n0\n6\nTGN-ID\n69.3± 0.5\n86.3± 0.8\n56.2 ± 3.7\n+1.2 ± 0.1\n+24.3 ± 1.8\n3.4\nJodie\n68.8 ± 1.3\n86.1 ± 0.4\n56.2 ± 2.1\n+1.4 ± 0.1\n+25.0 ± 0.6\n3.2\nTGN-attn\n70.5 ± 4.1\n86.0 ± 0.9\n55.6 ± 6.1\n+0.9 ± 0.2\n+22.5 ± 2.5\n4.2\nGS\n90.7 ± 0.3\n75.0 ± 0.2\n68.5 ± 1.0\n+1.8 ± 0.5\n+27.8 ± 0.4\n2\nDGS\n89.2 ± 2.2\n78.7 ± 0.6\n68.0 ± 1.9\n+3.6 ± 0.2\n+26.9 ± 0.3\n2.2\n4.3\nLink Prediction\nFor the link prediction task, the evaluation process generates n −1 negative edges for each positive edge,\nwhere n denotes the number of nodes (possible destinations) in the graph. We then measure the mean\nreciprocal rank (MRR), which indicates the average rank of the positive edge. An MRR of 50% implies\nthat the correct edge was ranked second, while an MRR of 25% implies it was ranked third. Additionally,\nwe measure Recall@10, which represents the percentage of actual positive edges ranked in the top 10 scores\nfor every edge.\nWe retrain the hyperparameter-optimized model using 10 random seeds and report the average test MRR\n± standard deviation and Recall@10 ± standard deviation in Table 2. Evaluations were conducted in both\ntransductive (T) and inductive (I) settings.\nThe transductive setting involves predicting future links of\nnodes that could be observed during training, while the inductive setting involves predictions for nodes not\nencountered during training.\nWe identified the best and second-best models. DGS demonstrated competitive performance in link pre-\ndiction. It outperformed the GNN models by approximately 10% in MRR on the Mooc dataset and showed\n2We believe it is more fair to compare the performance using the same setup. For the interested reader, the results when\nupdating the state after the classification are reported in the GS paper Eddin et al. (2023).\n9\nPublished in Transactions on Machine Learning Research (11/2024)\nimproved performance on the Reddit dataset. However, it underperformed compared to the baselines on the\nWikipedia dataset. To provide a comprehensive overview, we included a column in Table 2 that displays the\naverage rank, representing the mean ranking derived from all datasets, calculated using MRR. Notably, our\nDGS model achieved the highest average performance in both transductive and inductive settings.\nTable 2: DGS: Link prediction results using public datasets.\nMethod\nWikipedia\nMooc\nReddit\nAverage\nrank\nMRR\nRecall@10\nMRR\nRecall@10\nMRR\nRecall@10\nT\nTGN-ID\n46.6 ± 2.4\n67.3 ± 2.1\n15.3 ± 6.6\n36.9 ± 18.0\n41.3 ± 4.2\n57.4 ± 3.5\n4.3\nJodie\n65.3 ± 1.3\n78.4 ± 0.2\n15.3 ± 3.9\n38.1 ± 11.8\n42.4 ± 4.3\n59.9 ± 2.9\n2.7\nTGN-attn\n66.7 ± 1.3\n78.3 ± 0.6\n16.9 ± 3.6\n42.1 ± 11.2\n40.0 ± 9.2\n56.8 ± 8.9\n2.7\nGS\n54.7 ± 1.1\n64.4 ± 0.9\n4.0 ± 0.4\n5.1 ± 0.5\n55.5 ± 1.2\n65.2 ± 11\n2.7\nDGS\n53.9 ± 1.3\n63.9 ± 0.6\n25.6 ± 4.0\n49.0 ± 5.3\n51.0 ± 0.9\n64.8 ± 0.3\n2.3\nI\nTGN-ID\n62.3 ± 1.2\n75.1 ± 0.5\n13.8 ± 5.9\n31.1 ± 15.8\n41.6 ± 2.5\n59.6 ± 1.9\n2.7\nJodie\n57.9 ± 0.7\n73.1 ± 0.6\n16.7 ± 2.6\n41.2 ± 6.4\n37.9 ± 4.2\n57.0 ± 3.1\n4.0\nTGN-attn\n65.6 ± 2.4\n75.8 ± 0.7\n17.7 ± 2.0\n42.1 ± 5.2\n48.1 ± 2.2\n64.7 ± 0.9\n2.0\nGS\n55.0 ± 2.1\n62.8 ± 1.2\n2.8 ± 0.2\n3.6 ± 0.3\n49.4 ± 1.1\n59.5 ± 1.3\n4.0\nDGS\n59.3 ± 2.5\n68.5 ± 2.4\n26.0 ± 3.9\n48.2 ± 3.3\n56.9 ± 30.9\n68.5 ± 22.5\n1.7\n4.4\nInference Runtime\nDGS has a primary goal of achieving reduced inference times. Comparative latency assessments were con-\nducted amongst DGS, Graph-Sprints, and baseline GNN models. These assessments involved processing\n200 batches, each containing 200 events, across distinct datasets (Wikipedia, Mooc, and Reddit) for node\nclassification task. The average times were computed over 10 iterations. Tests were performed on a Linux PC\nequipped with 24 Intel Xeon CPU cores (3.70GHz) and an NVIDIA GeForce RTX 2080 Ti GPU (11GB). Note\nthat all experiments, including those for link prediction and node classification mentioned in the previous\nsections, used the same machine.\nAs depicted in Figure 4, DGS exhibited significant speed advantages. On the Reddit dataset, it was more\nthan ten times faster than the TGN-attn GNN baseline. For the smaller datasets, this speed enhancement\nranged approximately between 5 and 6 times, while maintaining a competitive speed with the low latency\nGS baseline. Notably, the runtime of DGS remained stable and was not influenced by the number of edges in\nthe graph, as demonstrated in Figure 4. In the Wikipedia and Reddit datasets, DGS consistently took 0.24\nseconds. In contrast, TGN-attn exhibited a runtime increase from 1.2 seconds in the Wikipedia dataset to\napproximately 3 seconds in the Reddit dataset. This stability suggests that we may obtain higher speed gains\nin larger or denser graphs, especially considering that inference times in the TGN-attn baseline are impacted\nby the number of graph edges.\nMoreover, When benchmarked against other GNNs baselines (TGN-ID,\nJodie), DGS consistently demonstrated significantly lower inference latency.\nIn comparison to the GS framework, known for its low latency, DGS generally exhibited marginally superior\nspeed, especially noticeable in the Wikipedia and Reddit datasets, with latencies of 0.24 versus 0.29 seconds.\nThis performance gain can be attributed to the higher feature count in these datasets (172 features), which\npotentially increases the processing time for GS due to the elevated feature volume. In contrast, for the\nMooc dataset, which has only 7 edge features, GS showed a slight gain in speed (0.24 versus 0.28 seconds).\n4.5\nAblation Study\nIn this section we conduct a comparative analysis of three distinct variants of the DGS methodology, differ-\nentiated primarily by their parameterization complexity.\nThe initial variant, designated as DGS-s, represents the most basic approach wherein scalar parameters α\nand β are learned. Moreover, instead of employing a learnable embedding matrix, DGS-s adopts the static\nembedding function utilized by Graph-Sprints. The subsequent variant, DGS-v, retains the fixed embedding\n10\nPublished in Transactions on Machine Learning Research (11/2024)\nFigure 4: Trade-off between AUC and runtime.\nfunction but transitions to vectorized parameters, ⃗α and ⃗β. This modification aims to explore the effects of\nincreasing these parameters’ complexity on the performance of the model. The final variant, referred to as\nDGS, not only incorporates vectorized parameters ⃗α and ⃗β but also integrates a learnable embedding matrix.\nThis approach aims to assess the impact of learnable feature embedding matrix.\nTable 3 presents the results of the three variants for node classification across five different datasets. It\ndisplays the average test AUC ± standard deviation for the external datasets and the ∆AUC for the AML\ndatasets. The DGS variant showes to be on average the best variant.\nTable 3: DGS: Ablation study, Node classification results\nMethod\nAUC ± std\n∆AUC ± std\nAverage\nrank\nWikipedia\nMooc\nReddit\nFI-A\nFI-B\nDGS-s\n88.2 ± 0.6\n73.8 ± 0.5\n65.8 ± 0.8\n+1.8 ± 0.3\n25.8 ± 0.7\n3\nDGS-v\n91.0 ± 0.3\n75.2 ± 0.3\n67.2 ± 0.4\n+3.2 ± 0.1\n+26.7 ± 0.2\n1.8\nDGS\n89.2 ± 2.2\n78.7 ± 0.6\n68.0 ± 1.9\n+3.6 ± 0.2\n+26.9 ± 0.3\n1.2\nFurther ablation studies demonstrating the advantages of using forward-mode AD and softmax normalization\nare detailed in Appendix A.4. Moreover, the differences in inference speed are discussed in Appendix A.5\n5\nRelated Work\nGraph representation learning is essential for converting complex graph structures into embeddings usable\nby machine learning models. This section provides an overview of the existing algorithms. Additionally,\ngiven the focus of this paper, we explore approaches for low latency in graph representation learning.\n5.1\nGraph Representation Learning\nMost existing graph representation learning methods focus on static graphs, thereby neglecting temporal\ndynamics (Perozzi et al., 2014; Tang et al., 2015; Grover & Leskovec, 2016; Hamilton et al., 2017a; Ying\net al., 2018).\nDynamic graphs, which evolve over time, introduce additional complexities.\nA common\napproach is to use DTDGs by considering the dynamic graph a series of discrete snapshots and apply static\nmethods (Sajjad et al., 2019), but this approach fails to capture the full spectrum of temporal dynamics.\nTo address this limitation, more advanced techniques have been developed to better handle CTDGs. These\nmethods include incorporating time-aware features or inductive biases into the architecture(e.g., (Nguyen\net al., 2018; Jin et al., 2019; Lee et al., 2020; Rossi et al., 2020)).\n11\nPublished in Transactions on Machine Learning Research (11/2024)\nFor instance, methods like DeepCoevolve(Dai et al., 2016) and Jodie(Kumar et al., 2019) train two recurrent\nneural networks (RNNs) for bipartite graphs, one for each node type. In these models, the previous hidden\nstate of one RNN is also used as an input to the other RNN, allowing interaction between the two and\neffectively performing single-hop graph aggregations.\nTGAT(Xu et al., 2020) introduces temporal information through time encodings, enhancing the model’s\nability to capture dynamic changes.\nTGN(Rossi et al., 2020) extends this approach by incorporating a\nmemory module in the form of an RNN, providing a more robust framework for handling temporal data.\nFurther refinement is seen in Jin et al. (2020), where the discrete-time recurrent network of TGN is replaced\nwith a NeuralODE, modeling the continuous dynamics of node embeddings for more accurate representations.\nThe methods described above either leverage random-walks or graph neural networks (GNNs) to extract\nneighborhood information and understand graph structure.\nRandom-walk-based methods are often hin-\ndered by high computational and memory costs, as noted by Xia et al. (2019). Solutions to mitigate these\nchallenges include techniques such as B_LIN(Tong et al., 2006), METIS(Karypis & Kumar, 1997), and\nRWDISK (Sarkar & Moore, 2010), which offer approximations of random walks.\nGNNs are powerful for representation learning of graphs, but adapting them to extensive datasets poses\nchallenges. When the graph does not fit in memory, sampling the neighbors of a node may necessitate costly\ndisk reads. While various sampling strategies have been proposed, integrating these with temporal data is\ncomplex. Enhancing the scalability of GNNs for real-time applications remains a critical area of ongoing\nresearch (Jin et al., 2023).\n5.2\nLow-latency Graph Representation Learning\nThis section reviews methods for low-latency graph representation learning. For example, APAN (Wang\net al., 2021) aims to reduce inference latency by decoupling expensive graph operations from the infer-\nence module, executing the costly k-hop message passing asynchronously. While APAN enhances inference\nefficiency, it may use outdated information due to its asynchronous updates, which could impact overall\nperformance. In contrast, our method, Deep-Graph-Sprints, addresses latency without compromising the\nfreshness of the information used.\nFurthermore, Liu et al. (2019) present a real-time algorithm for graph streams that updates node represen-\ntations based on the embeddings of 1-hop neighbors of a node of interest, and ignoring its attributes. Chu\n& Lin (2024) propose ETSMLP, a model that leverages an exponential smoothing technique to model long-\nterm dependencies in sequence learning. However, ETSMLP is tailored specifically for sequence modeling\nand is not applicable to graph-based tasks out-of-the-box. Graph-Sprints (Eddin et al., 2023) offers a feature\nengineering approach that approximates random walks for low-latency graph feature extraction. Unlike our\napproach, Graph-Sprints requires extensive hand-crafting of features.\nIn addition to inference optimization, several methods address the reduction of computational costs in GNNs.\nHashGNN(Wu et al., 2021) employs MinHash to generate node embeddings suitable for link prediction tasks,\ngrouping similar nodes based on their hashed embeddings. Another approach, SGSketch(Yang et al., 2022),\nintroduces a streaming node embedding framework that gradually forgets outdated edges, leading to speed\nimprovements. Unlike our approach, SGSketch primarily updates the adjacency matrix and focuses on the\ngraph structure rather than incorporating additional node or edge attributes.\n6\nConclusions\nCTDGs are essential for representing connected and evolving systems. The computational and memory\ndemands associated with performing lookups to sample multiple neighbors limit their feasibility in low-\nlatency scenarios.\nIn this paper, we introduce the real-time graph representation learning method for CTDGs, named DGS.\nThis novel approach addresses the latency challenges associated with current deep learning methods. It also\nobviates the need for manual tuning and domain-specific expertise, which are prerequisites for traditional\nfeature extraction methods. The architecture design makes the use of real-time recurrent learning (RTRL)\n12\nPublished in Transactions on Machine Learning Research (11/2024)\nfeasible, which in turn can help to learn long-term dependencies and to use online learning. To validate the\neffectiveness and applicability of DGS, we conducted a thorough evaluation using two internal AML datasets\nand additional datasets from various fields, thereby demonstrating its versatility.\nFuture work includes exploring alternative normalization functions or activation functions beyond softmax\nand incorporating advanced optimization algorithms such as Adam to replace the current use of stochastic\ngradient descent for updating DGS parameters during forward-mode AD. Additionally, a significant enhance-\nment under consideration is enabling input-dependent adaptability for the parameters ⃗α and ⃗β, aiming to\nimprove the model’s responsiveness to varying input features and enhance overall performance, similar to\napproaches used in gated recurrent neural networks.\nReferences\nTakuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna: A next-\ngeneration hyperparameter optimization framework. In Proceedings of the 25th ACM SIGKDD interna-\ntional conference on knowledge discovery & data mining, pp. 2623–2631, 2019.\nAtilim Gunes Baydin, Barak A Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind. Automatic\ndifferentiation in machine learning: a survey. Journal of Marchine Learning Research, 18:1–43, 2018.\nTristan Bilot, Nour El Madhoun, Khaldoun Al Agha, and Anis Zouaoui. Graph neural networks for intrusion\ndetection: A survey. IEEE Access, 2023.\nJiqun Chu and Zuoquan Lin. Incorporating exponential smoothing into mlp: A simple but effective sequence\nmodel. arXiv preprint arXiv:2403.17445, 2024.\nTim Cooijmans and James Martens.\nOn the variance of unbiased online recurrent optimization. arXiv\npreprint arXiv:1902.02405, 2019.\nL da F Costa, Francisco A Rodrigues, Gonzalo Travieso, and Paulino Ribeiro Villas Boas. Characterization\nof complex networks: A survey of measurements. Advances in physics, 56(1):167–242, 2007.\nHanjun Dai, Yichen Wang, Rakshit Trivedi, and Le Song. Deep coevolutionary network: Embedding user\nand item features for recommendation. arXiv preprint arXiv:1609.03675, 2016.\nAhmad Naser Eddin, Jacopo Bono, David Aparício, Hugo Ferreira, João Tiago Ascensão, Pedro Ribeiro,\nand Pedro Bizarro. From random-walks to graph-sprints: a low-latency node embedding framework on\ncontinuous-time dynamic graphs. In Proceedings of the Fourth ACM International Conference on AI in\nFinance, pp. 176–184, 2023.\nFalih Gozi Febrinanto, Feng Xia, Kristen Moore, Chandra Thapa, and Charu Aggarwal. Graph lifelong\nlearning: A survey. IEEE Computational Intelligence Magazine, 18(1):32–51, 2023.\nMatthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In ICLR\nWorkshop on Representation Learning on Graphs and Manifolds, 2019.\nAditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of the\n22nd ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 855–864, 2016.\nChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In\nInternational conference on machine learning, pp. 1321–1330. PMLR, 2017.\nWill Hamilton, Zhitao Ying, and Jure Leskovec.\nInductive representation learning on large graphs.\nIn\nAdvances in neural information processing systems, pp. 1024–1034, 2017a.\nWilliam L Hamilton, Rex Ying, and Jure Leskovec.\nRepresentation learning on graphs: Methods and\napplications. arXiv preprint arXiv:1709.05584, 2017b.\n13\nPublished in Transactions on Machine Learning Research (11/2024)\nDi Jin, Mark Heimann, Ryan A Rossi, and Danai Koutra. node2bits: Compact time-and attribute-aware\nnode representations for user stitching. In Joint European Conference on Machine Learning and Knowledge\nDiscovery in Databases, pp. 483–506. Springer, 2019.\nDi Jin, Sungchul Kim, Ryan A Rossi, and Danai Koutra. From static to dynamic node embeddings. arXiv\npreprint arXiv:2009.10017, 2020.\nMing Jin, Huan Yee Koh, Qingsong Wen, Daniele Zambon, Cesare Alippi, Geoffrey I Webb, Irwin King, and\nShirui Pan. A survey on graph neural networks for time series: Forecasting, classification, imputation,\nand anomaly detection. arXiv preprint arXiv:2307.03759, 2023.\nGeorge Karypis and Vipin Kumar. Metis: A software package for partitioning unstructured graphs, parti-\ntioning meshes, and computing fill-reducing orderings of sparse matrices. 1997.\nSrijan Kumar, Xikun Zhang, and Jure Leskovec. Predicting dynamic embedding trajectory in temporal\ninteraction networks. In Proceedings of the 25th ACM SIGKDD international conference on Knowledge\ndiscovery and data mining. ACM, 2019.\nJohn Boaz Lee, Giang Nguyen, Ryan A Rossi, Nesreen K Ahmed, Eunyee Koh, and Sungchul Kim. Dy-\nnamic node embeddings from edge streams. IEEE Transactions on Emerging Topics in Computational\nIntelligence, 5(6):931–946, 2020.\nXi Liu, Ping-Chun Hsieh, Nick Duffield, Rui Chen, Muhe Xie, and Xidao Wen. Real-time streaming graph\nembedding through local actions. In Companion proceedings of the 2019 world wide web conference, pp.\n285–293, 2019.\nAbdul Majeed and Ibtisam Rauf. Graph theory: A comprehensive survey about graph theory applications\nin computer science and social networks. Inventions, 5(1):10, 2020.\nMarvin Minsky. Steps toward artificial intelligence. Proceedings of the IRE, 49(1):8–30, 1961.\nGiang Hoang Nguyen, John Boaz Lee, Ryan A Rossi, Nesreen K Ahmed, Eunyee Koh, and Sungchul Kim.\nContinuous-time dynamic network embeddings. In Companion proceedings of the the web conference 2018,\npp. 969–976, 2018.\nBryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social representations. In\nProceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,\npp. 701–710, 2014.\nEmanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, and Michael Bronstein.\nTemporal graph networks for deep learning on dynamic graphs.\nIn ICML 2020 Workshop on Graph\nRepresentation Learning, 2020.\nHooman Peiro Sajjad, Andrew Docherty, and Yuriy Tyshetskiy.\nEfficient representation learning using\nrandom walks for dynamic graphs. arXiv preprint arXiv:1901.01346, 2019.\nPurnamrita Sarkar and Andrew W Moore. Fast nearest-neighbor search in disk-resident graphs. In Proceed-\nings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, pp.\n513–522, 2010.\nRichard Stuart Sutton. Temporal credit assignment in reinforcement learning. University of Massachusetts\nAmherst, 1984.\nJian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information\nnetwork embedding. In Proceedings of the 24th international conference on world wide web, pp. 1067–1077,\n2015.\nHanghang Tong, Christos Faloutsos, and Jia-Yu Pan. Fast random walk with restart and its applications.\nIn Sixth international conference on data mining (ICDM’06), pp. 613–622. IEEE, 2006.\n14\nPublished in Transactions on Machine Learning Research (11/2024)\nXuhong Wang, Ding Lyu, Mengjian Li, Yang Xia, Qi Yang, Xinwen Wang, Xinguang Wang, Ping Cui, Yupu\nYang, Bowen Sun, et al. Apan: Asynchronous propagation attention network for real-time temporal graph\nembedding. In Proceedings of the 2021 international conference on management of data, pp. 2628–2638,\n2021.\nRonald J Williams and Jing Peng. An efficient gradient-based algorithm for on-line training of recurrent\nnetwork trajectories. Neural computation, 2(4):490–501, 1990.\nRonald J Williams and David Zipser. A learning algorithm for continually running fully recurrent neural\nnetworks. Neural computation, 1(2):270–280, 1989.\nWei Wu, Bin Li, Chuan Luo, and Wolfgang Nejdl.\nHashing-accelerated graph neural networks for link\nprediction. In Proceedings of the Web Conference 2021, pp. 2910–2920, 2021.\nFeng Xia, Jiaying Liu, Hansong Nie, Yonghao Fu, Liangtian Wan, and Xiangjie Kong. Random walks: A\nreview of algorithms and applications. IEEE Transactions on Emerging Topics in Computational Intelli-\ngence, 4(2):95–107, 2019.\nDa Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan. Inductive representation\nlearning on temporal graphs. arXiv preprint arXiv:2002.07962, 2020.\nDingqi Yang, Bingqing Qu, Jie Yang, Liang Wang, and Philippe Cudre-Mauroux. Streaming graph embed-\ndings via incremental neighborhood sketching. IEEE Transactions on Knowledge and Data Engineering,\n35(5):5296–5310, 2022.\nRex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph\nconvolutional neural networks for web-scale recommender systems.\nIn Proceedings of the 24th ACM\nSIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 974–983, 2018.\nZiwei Zhang, Peng Cui, and Wenwu Zhu.\nDeep learning on graphs: A survey.\nIEEE Transactions on\nKnowledge and Data Engineering, 34(1):249–270, 2020.\nJie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng\nLi, and Maosong Sun. Graph neural networks: A review of methods and applications. AI open, 1:57–81,\n2020.\nA\nAppendix\nA.1\nComparing Graph-Sprints and Deep-Graph-Sprints\nDeep-Graph-Sprints builds upon and addresses the limitations of Graph-Sprints, resulting in both notable\nsimilarities and key distinctions, as outlined in Table 4.\nTable 4: Comparison of Graph-Sprints and Deep-Graph-Sprints\nAspect\nGraph-Sprints\nDeep-Graph-Sprints\nComponents\nEmbedding + classifier\nEmbedding + classifier\nInput embeddings\nHard-coded (feature engineered)\nLearnable\nOptimization of embedding\nand classifier parameters\nSeparate\nEnd-to-end\nEmbedding size\nFixed and large (bucketing of\nraw features)\nTuneable\n(learnable\nembed-\ndings)\nEmbedding expressivity\nScalar forgetting coefficients\nVector forgetting coefficients\n15\nPublished in Transactions on Machine Learning Research (11/2024)\nTable 5: Information and data partitioning strategy for public (Kumar et al., 2019), and proprietary datasets.\nIn the public datasets, we adopt the identical data partitioning strategy employed by the baseline methods\nwe compare against, which also utilized these datasets.\nIn the proprietary datasets(FI-A, FI-B) due to\nprivacy concerns we provide approximated details\nWikipedia\nMooc\nReddit\nFI-A\nFI-B\n#Nodes\n9,227\n7,047\n10,984\n≈400,000\n≈10,000\n#Edges\n157,474\n411,749\n672,447\n≈500,000\n≈2,000,000\nLabel type\nediting ban\nstudent drop-out\nposting ban\nAML SAR\nAML escalation\nPositive labels\n0.14%\n0.98%\n0.05%\n2-5%\n20-40%\nDuration\n30 days\n29 days\n30 days\n≈300 days\n≈600 days\nUsed split (%)\n70-15-15\n60-20-20\n70-15-15\n60-10-30\n60-10-30\nA.2\nData: Specifications and Characteristics\nTable 5 outlines the specifications and key characteristics of the five datasets utilized in the experiments\ndescribed in Section 4.\nA.3\nHyperparameters Ranges\nTable 6 enumerates the hyperparameters and their respective ranges employed in the tuning process of DGS\nand the baselines. All represents the hyperparameters that are common to all the used methods (i.e., DGS,\nGS, and GNN)\nTable 6: Hyperparameters ranges for DGS and baseline methods.\nMethod\nHyperparameter\nmin\nmax\nDGS\nDGS learning rate (η)\n10−4\n103\nDGS\nNumber of softmaxes (m)\n10\n50\nDGS\nSoftmax temperature (T)\n1\n10\nGS\nα\n0.1\n1\nGS\nβ\n0.1\n1\nGNN\nMemory size\n32\n256\nGNN\nNeighbors per node\n5\n10\nGNN\nNum GNN layers\n1\n3\nGNN\nSize GNN layer\n32\n256\nALL\nLearning rate\n10−4\n10−2\nALL\nDropout perc\n0.1\n0.3\nALL\nWeight decay\n10−9\n10−3\nALL\nNum of dense layers\n1\n3\nALL\nSize of dense layer\n32\n256\nA.4\nAblation Study\nWe evaluate the performance of different variants of the DGS method on the node classification task. We\ncompare three distinct approaches:\n• DGS-bp: DGS with the typical truncated backpropagation strategy as used in SOTA methods such\nas TGN and JODIE.\n• DGS-sum: DGS using a divide-by-sum normalization technique, which simplifies the normalization\nprocess by summing activations across the network. Equation 3 illustrates the process for a single\npartition in the W matrix (analogous to a single softmax operation in our proposed approach).\n16\nPublished in Transactions on Machine Learning Research (11/2024)\n⃗Ei =\nWi ⃗Ft\nP(Wi ⃗Ft) + ε\n(3)\n• DGS (proposed): Our proposed method employs forward-mode AD and utilizes softmax normal-\nization.\nAs shown in Table 7, our proposed DGS method outperforms both DGS-bp and DGS-sum, demonstrating\nthe advantage of using forward-mode AD and softmax normalization for this task.\nTable 7: Node classification performance comparison across DGS variants (DGS-bp, DGS-sum, and the\nproposed DGS method). Detailed descriptions of these variants are provided in Appendix A.4.\nMethod\nAUC ± std\nWikipedia\nMooc\nReddit\nDGS-sum\n84.5 ± 9.1\n71.3 ± 3.9\n53.7 ± 7.4\nDGS-bp\n85.8 ± 0.4\n72.6 ± 13.2\n63.2 ± 0.7\nDGS (proposed)\n89.2 ± 2.2\n78.7 ± 0.6\n68.0 ± 1.9\nA.5\nComparison of Inference Speed\nWe evaluate and compare the inference speed of two different methods: DGS (proposed) and DGS-sum. The\ncomparison is based on their performance across various datasets. Table 8 summarizes the average inference\ntimes, in seconds, along with their standard deviations. The results indicate that both methods exhibit\nsimilar inference speeds across the different datasets.\nTable 8: Comparison of inference speed using different normalization functions\nData\nDGS (proposed)\nDGS-sum\nWikipedia\n0.24 ± 0.002\n0.25 ± 0.009\nReddit\n0.24 ± 0.003\n0.23 ± 0.0004\nMooc\n0.28 ± 0.003\n0.27 ± 0.0003\nA.6\nComparison of Learnable Parameter Counts\nTable 9 provides a comprehensive comparison of the learnable parameter counts between DGS and TGN-\nattn for the link prediction task across inductive and transductive settings, underscoring differences in model\ncomplexity.\nTable 9: Comparison of the number of learnable parameters between DGS and TGN-attn in the link pre-\ndiction task, evaluated in both inductive (I) and transductive (T) settings. The ratio indicates the relative\nproportion of parameters in TGN-attn compared to DGS.\nMooc\nWiki\nReddit\nI\nT\nI\nT\nI\nT\nDGS-NN component\n80,145\n80,145\n57,665\n23,537\n84,945\n80,145\nDGS-ER component\n2,250\n2,250\n43,500\n43,500\n43,500\n43,500\nDGS (total)\n82,395\n82,395\n101,165\n67,037\n128,445\n123,645\nTGN-attn\n154,221\n308,785\n362,422\n197,572\n100,426\n282,340\nRatio\n1.9\n3.7\n3.6\n2.9\n0.8\n2.3\n17\n",
  "categories": [
    "cs.LG",
    "cs.SI"
  ],
  "published": "2024-07-10",
  "updated": "2024-11-07"
}