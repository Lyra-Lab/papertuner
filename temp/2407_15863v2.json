{
  "id": "http://arxiv.org/abs/2407.15863v2",
  "title": "Overfitting In Contrastive Learning?",
  "authors": [
    "Zachary Rabin",
    "Jim Davis",
    "Benjamin Lewis",
    "Matthew Scherreik"
  ],
  "abstract": "Overfitting describes a machine learning phenomenon where the model fits too\nclosely to the training data, resulting in poor generalization. While this\noccurrence is thoroughly documented for many forms of supervised learning, it\nis not well examined in the context of unsupervised learning. In this work we\nexamine the nature of overfitting in unsupervised contrastive learning. We show\nthat overfitting can indeed occur and the mechanism behind overfitting.",
  "text": "Overfitting In Contrastive Learning?\nZachary Rabin, Jim Davis\nOhio State University\n{rabin.30, davis.1719}@osu.edu\nBenjamin Lewis, Matthew Scherreik\nAir Force Research Laboratory\n{benjamin.lewis.13, matthew.sherreik.1}@us.af.mil\nAbstract\nOverfitting describes a machine learning phenomenon\nwhere the model fits too closely to the training data, result-\ning in poor generalization. While this occurrence is thor-\noughly documented for many forms of supervised learning,\nit is not well examined in the context of unsupervised learn-\ning. In this work we examine the nature of overfitting in\nunsupervised contrastive learning. We show that overfitting\ncan indeed occur and the mechanism behind overfitting.\n1. Introduction\nOverfitting in neural networks is commonly observed.\nWhen selecting how long to train a network, a simple choice\nis to train until overfitting occurs. One can detect overfit-\nting in the classical supervised setting by observing that the\ntraining error decreases, while validation error begins to in-\ncrease and diverge from the training error. This signals that\nthe network has “overfit” to the training data. We ask if\noverfitting can occur with unsupervised contrastive learn-\ning, and if so, what does overfitting mean in this context.\n2. Related Work\nContrastive learning is a paradigm exploiting the simi-\nlarities between positive and negative samples to learn fea-\ntures. While this paradigm can be supervised or unsuper-\nvised, SimCLR [1] is a popular unsupervised contrastive\nlearning approach, which we use in this work.\nThe SimCLR architecture consists of a backbone net-\nwork f(·) and a projection head g(·). For some image x,\nwe define h = f(x), and z = g(h) = g(f(x))\nGiven a minibatch of size N, SimCLR first creates two\naugmented views of each source image. We denote the pair\nof images created from the same source image as positive\npairs. Pairs of images created from different source im-\nages are referred to as negative pairs. The 2N augmented\nimages are arranged so that positive pairs appear consecu-\ntively. Then, the loss function for a positive pair of images\n(xi, xj) is defined as\nℓ(xi, xj) = −log\nexp(sim(zi, zj)/τ)\nP2N\nk=1 1[k̸=i]exp(sim(zi, zk)/τ)\n(1)\nwhere τ is a temperature hyperparameter and sim(u, v) =\nu⊤v/ ∥u∥∥v∥. The overall loss for the batch is\nL =\n1\n2N\nN\nX\nk=1\n[ℓ(x2k−1, x2k) + ℓ(x2k, x2k−1)]\n(2)\nthe average of the loss for each positive pair.\n3. Method\nRearranging Eq. (1) yields\nℓ(xi, xj) = −sim(zi, zj)/τ+\nlog\n2N\nX\nk=1\n1[k̸=i]exp(sim(zi, zk)/τ)\n(3)\nThis reveals a two part loss function where the first term en-\ncourages positive pairs to be similar to each other, while the\nsecond term encourages negative pairs to be farther apart.\nFor convenience we call −sim(zi, zj)/τ the positive simi-\nlarity and log P2N\nk=1 1[k̸=i]exp(sim(zi, zk)/τ) the negative\nsimilarity.\nOur experiments consist of running the SimCLR ap-\nproach for up to 5K epochs to observe if overfitting occurs.\nFor data shown in Figs 1 and 2, we use a subset of CI-\nFAR10 [4] consisting of only the “Airplane”, “Automobile”,\n“Ship”, and “Truck” classes. In our experiments we track\nthe overall loss L as well as the average positive and nega-\ntive similarity per epoch. We train a ResNet18 [2] with the\nAdam [3] optimizer with a learning rate of 0.001. Our aug-\nmentation scheme is comprised of mean padding followed\nby random cropping, random horizontal flipping, random\ncolor jittering, grayscaling, and finally Gaussian blurring.\n4. Results and Discussion\nFirstly, we find that the loss L can in fact overfit if given\nenough time. We observe in Fig. 1 that the validation loss\n1\narXiv:2407.15863v2  [cs.LG]  22 Aug 2024\nFigure 1. SimCLR overfitting on a subset of CIFAR10 over 5K\nepochs. A horizontal dashed line is provided as a reference.\nFigure 2. Validation loss of Fig. 1 split into positive and negative\nsimilarity.\nbegins to diverge from the training loss. Using the dashed\nhorizontal line as a reference we can see that the validation\nloss begins to increase over time after epoch 500.\nSecondly, we observe that the positive similarity is the\nterm that drives the overfitting. Figure 2 shows that the\nvalidation positive similarity initially decreases, but quickly\nbegins to increase again, while the negative similarity con-\ntinues to decrease. This shows that the positive similarity is\nthe portion of the loss that drives the overfitting of the over-\nall loss L. Conceptually, as training continues the model\nlearns how to decrease the positive similarity for only train-\ning examples, and loses the capacity to detect positive pairs\noutside of the training set. This results in the representa-\ntions z for all validation examples being pushed away from\neach other, even positive pairs.\nUnderstanding how contrastive learning overfits can be\nuseful for reduced training times and achieving desired\ncharacteristics in the feature space. As shown in Figs. 1\nand 2, overfitting in the positive similarity can be detected\nearlier in the training process as opposed to overfitting in the\noverall loss. Therefore, stopping training when overfitting\nis seen in the positive similarity can reduce training times.\n5. Conclusion\nUnsupervised contrastive learning is a popular paradigm\nin deep-learning. In this work, we investigated if this frame-\nwork is capable of overfitting and what overfitting means in\nthis context. We found that given enough epochs, unsuper-\nvised contrastive learning can indeed overfit to the training\nset. We showed that when the model does overfit, it loses\nthe ability to bring positive pair’s representations closer to\neach other, resulting in the positive similarity being the driv-\ning factor behind the overfitting phenomenon.\n6. Acknowledgements\nThis work was supported in part by the U.S. Air Force\nResearch Laboratory under contract FA8650-21-C-1174.\nDistribution A: Cleared for Public Release.\nDistribution\nUnlimited. PA Approval #AFRL-2024-3668.\nReferences\n[1] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge-\noffrey Hinton. A simple framework for contrastive learning\nof visual representations. arXiv preprint arXiv:2002.05709,\n2020. 1\n[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\nDeep Residual Learning for Image Recognition. In IEEE/CVF\nConference on Computer Vision and Pattern Recognition,\n2016. 1\n[3] Diederik P. Kingma and Jimmy Ba.\nAdam:\nA method\nfor stochastic optimization. In International Conference on\nLearning Representations, 2015. 1\n[4] Alex Krizhevsky. Learning Multiple Layers of Features from\nTiny Images. 2009. 1\n2\n",
  "categories": [
    "cs.LG"
  ],
  "published": "2024-07-16",
  "updated": "2024-08-22"
}