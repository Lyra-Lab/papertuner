{
  "id": "http://arxiv.org/abs/2408.02237v1",
  "title": "Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings",
  "authors": [
    "Md. Arid Hasan",
    "Prerona Tarannum",
    "Krishno Dey",
    "Imran Razzak",
    "Usman Naseem"
  ],
  "abstract": "Large language models (LLMs) have garnered significant interest in natural\nlanguage processing (NLP), particularly their remarkable performance in various\ndownstream tasks in resource-rich languages. Recent studies have highlighted\nthe limitations of LLMs in low-resource languages, primarily focusing on binary\nclassification tasks and giving minimal attention to South Asian languages.\nThese limitations are primarily attributed to constraints such as dataset\nscarcity, computational costs, and research gaps specific to low-resource\nlanguages. To address this gap, we present datasets for sentiment and hate\nspeech tasks by translating from English to Bangla, Hindi, and Urdu,\nfacilitating research in low-resource language processing. Further, we\ncomprehensively examine zero-shot learning using multiple LLMs in English and\nwidely spoken South Asian languages. Our findings indicate that GPT-4\nconsistently outperforms Llama 2 and Gemini, with English consistently\ndemonstrating superior performance across diverse tasks compared to\nlow-resource languages. Furthermore, our analysis reveals that natural language\ninference (NLI) exhibits the highest performance among the evaluated tasks,\nwith GPT-4 demonstrating superior capabilities.",
  "text": "Do Large Language Models Speak All Languages Equally?\nA Comparative Study in Low-Resource Settings\nMd. Arid Hasan1, Prerona Tarannum2, Krishno Dey1, Imran Razzak3, Usman Naseem4\n1University of New Brunswick, Canada, 2Daffodil International University, Bangladesh,\n3University of New South Wales, Australia, 4Macquarie University, Australia\narid.hasan@unb.ca\nAbstract\nLarge language models (LLMs) have garnered\nsignificant interest in natural language process-\ning (NLP), particularly their remarkable perfor-\nmance in various downstream tasks in resource-\nrich languages. Recent studies have highlighted\nthe limitations of LLMs in low-resource lan-\nguages, primarily focusing on binary classi-\nfication tasks and giving minimal attention\nto South Asian languages. These limitations\nare primarily attributed to constraints such as\ndataset scarcity, computational costs, and re-\nsearch gaps specific to low-resource languages.\nTo address this gap, we present datasets for\nsentiment and hate speech tasks by translat-\ning from English to Bangla, Hindi, and Urdu,\nfacilitating research in low-resource language\nprocessing. Further, we comprehensively ex-\namine zero-shot learning using multiple LLMs\nin English and widely spoken South Asian\nlanguages. Our findings indicate that GPT-4\nconsistently outperforms Llama 2 and Gemini,\nwith English consistently demonstrating supe-\nrior performance across diverse tasks compared\nto low-resource languages. Furthermore, our\nanalysis reveals that natural language inference\n(NLI) exhibits the highest performance among\nthe evaluated tasks, with GPT-4 demonstrating\nsuperior capabilities.\n1\nIntroduction\nRecent advances in large language models (LLMs)\ndeveloped significant interest in natural language\nprocessing (NLP) across academia and industry.\nLLMs are known for their language generation ca-\npabilities that are trained on billions or trillions of\ntokens with billions of trainable parameters. Re-\ncently researchers have been evaluating LLMs for\nvarious NLP downstream tasks, especially question\nanswering (Akter et al., 2023; Tan et al., 2023;\nZhuang et al., 2023), reasoning (Suzgun et al.,\n2022; Miao et al., 2023), mathematics (Lu et al.,\n2023; Rane, 2023), machine translation (Xu et al.,\n2023; Lyu et al., 2023), etc.\nMost of the existing works on the evaluation of\nLLMs are on resource-rich languages such as En-\nglish. However, the capabilities and performances\nof LLMs for low-resource languages1 for many\nNLP downstream tasks are not widely evaluated,\nleaving a notable gap in the linguistic capabilities of\nlow-resource languages. The most widely spoken\nyet low-resource languages of South Asia2 such\nas Bangla, Hindi, and Urdu, several researchers\nare handling the scarcity of datasets and other re-\nsources in NLI (Aggarwal et al., 2022), Sentiment\nanalysis (Hasan et al., 2023b; Sun et al., 2023; Koto\net al., 2024) and Hate speech detection (Khan et al.,\n2021; Santosh and Aravind, 2019). However, the\namount of work that uses LLMs is still very few,\nmainly due to a few constraints such as dataset\nscarcity, computational costs, and research gaps\nassociated with low-resource languages. These\nconstraints of low-resource languages require more\nattention, alongside a focus on high-resource lan-\nguages, to enhance the applicability of LLMs to\ngeneral-purpose NLP applications.\nTo fill the aforementioned gap, we comprehen-\nsively analyze zero-shot learning using various\nLLMs in English and low-resource languages. The\nperformance of LLMs shows that GPT-4 provides\ncomparatively better results than Llama 2 and Gem-\nini. Moreover, the English language performs bet-\nter on different tasks than low-resource languages\nsuch as Bangla, Hindi, and Urdu. The Key contri-\nbutions are as follows:\n• To address the limitation of publicly available\ndatasets for low-resource languages, we present\ndatasets for sentiment and hate speech tasks\nby translating from English to Bangla, Hindi,\nand Urdu, thereby facilitating research in low-\nresource language processing.\n1Refers to the scarcity of datasets and other resources\nrather than limitations in LLM capabilities.\n2https://simple.wikipedia.org/wiki/Languages_of_South_Asia\narXiv:2408.02237v1  [cs.CL]  5 Aug 2024\n• We investigate and analyze the effectiveness of\ndifferent LLMs across various tasks for both En-\nglish and low-resource languages such as Bangla,\nHindi, and Urdu, which suggest that LLMs per-\nform better when evaluated in English.\n• We apply zero-shot prompting using natural lan-\nguage instructions, which describe the task and\nexpected output, enabling constructing a context\nto generate more appropriate output.\n2\nRelated Works\nLLMs are proficient in various NLP tasks and\nhighly generalizable across multiple domains.\nHowever, their performance remains significant\nroom for improvement, particularly in low-resource\nlanguages such as Bangla, Hindi, and Urdu. Previ-\nous study (Robinson et al., 2023) demonstrates the\ninability of LLMs such as GPT-4 to perform on low-\nresource (African) and high-resource languages.\nHowever, LLMs perform well in languages (Euro-\npean) that use the same script as English (Holm-\nström et al., 2023).\nNLP research works, and applications for several\ndownstream tasks mainly focus on high-resource\nlanguages. Unlike the English language, the ad-\nvancement of NLP tasks for low-resource lan-\nguages made it challenging due to several factors\ndescribed by (Alam et al., 2021). However, there\nhave been some improvements in the last couple\nof years for Bangla sentiment analysis focusing on\nresource development (Hasan et al., 2020; Islam\net al., 2021; Hasan et al., 2023a) that attained at-\ntention from many researchers to concentrate on\nsolving this issue. Some of the recent works on\nNLI (Pahwa and Pahwa, 2023; Gubelmann et al.,\n2023), Sentiment Analysis (Xing, 2024; Zhang\net al., 2023b,a), and Hate Speech Detection (Hee\net al., 2024; García-Díaz et al., 2023) that utilize\nLLM are mainly carried out in English languages.\nMoreover, these works opened up the prospects\nof exploring LLMs for downstream tasks of low-\nresource languages.\nThere are few attempts from researchers across\ndifferent languages to utilize LLM for low-resource\nlanguages (Hasan et al., 2023b; Kabir et al.,\n2023; Koto et al., 2024; Kumar and Albuquerque,\n2021) that show LLMs can achieve similar re-\nsults to traditional machine learning techniques and\ntransformer-based models. However, existing mul-\ntilingual benchmarks such as BUFFET (Asai et al.,\n2023), XTREME (Hu et al., 2020), XTREME-R\n(Ruder et al., 2021), MEGA (Ahuja et al., 2023a),\nand MEGAVERSE (Ahuja et al., 2023b) do not ad-\ndress all four South Asian low-resource languages\nwe are considering in our study. Moreover, BUF-\nFET is limited to binary classification tasks and\nuses few-shot learning and instruction fine-tuning\nof smaller LLMs (such as mT5, mT0) and Chat-\nGPT. At the same time, we focus on multi-class\nclassification and use zero-shot learning with SOTA\nLLMs. The performance of LLMs is not balanced\nfor all languages (Huang et al., 2023; Qin et al.,\n2023), and our study uniquely focuses on com-\nparing resource-rich (English) and low-resource\n(Bangla, Hindi, and Urdu) languages using SOTA\nLLMs.\nPrevious studies have highlighted LLM limita-\ntions in low-resource languages, particularly in bi-\nnary classification, with minimal focus on South\nAsian languages. These constraints include dataset\nscarcity, high computational costs, and specific\nresearch gaps. To address these challenges, we\nconcentrate on South Asian languages like Bangla,\nUrdu, and Hindi. We provide datasets for sentiment\nand hate speech tasks by translating from English.\nWe explore zero-shot learning techniques across\nEnglish and South Asian languages, thus expand-\ning LLM applications in low-resource settings.\n3\nMethodology\nWe focused on both open- and closed-source LLMs.\nWe choose three LLMs that are GPT-4 (OpenAI,\n2023), Llama 2 (Touvron et al., 2023), and Gem-\nini Pro (Team et al., 2023). We select the LLMs\nbased on their performances, parameter sizes, and\ncapabilities. To conduct our experiments, we used\nthe XNLI dataset (Conneau et al., 2018) for the\nNLI task, the official test of SemEval-2017 task\n4 (Rosenthal et al., 2017) for the sentiment task,\nand the dataset described in (Davidson et al., 2017)\nfor hate speech task. We provide the details of the\ndataset used and the detailed data preprocessing\nand evaluation metrics in Appendix B.\nPrompt Approach: The performance of LLMs\nvaries depending on the prompt content. Designing\na good prompt is a complex and iterative process\nthat requires substantial effort due to the unknown\nrepresentation of information within the LLM. In\nthis study, we applied zero-shot prompting by us-\ning natural language instructions. The instructions\ncontain the task description and expected output,\nwhich enables the construction of a context to gen-\nerate more appropriate output. We keep the same\nprompt for each task across the LLMs. Further,\nwe added role information into the prompt for the\nGPT-4 model as GPT-4 can take the role informa-\ntion and perform accordingly. We also provide a\nsafety setting for the Gemini model to avoid block-\ning harmful content. See Appendix A for details.\n4\nResults and Discussion\nEnglish vs Low-resource Languages: Our experi-\nments show that all the LLMs consistently provide\nsuperior performances for English languages in all\ntasks except the performances of Gemini in the sen-\ntiment task ( Table 1). In the NLI task, the perfor-\nmance of GPT-4 in English is 18.04%, 17.38%, and\n22.81% better than the Bangla, Hindi, and Urdu\nlanguages respectively (see Table 1). Although\nHindi performs better than Bangla and Urdu, there\nis still a massive performance gap compared to En-\nglish. Besides, Llama 2 performance in English\nis 32.52%, 31.28%, and 29.94% higher compared\nwith Bangla, Hindi, and Urdu respectively. The\ndifference between English and other languages is\n∼70% from their original performance. Although\nthe performance differences of Gemini between En-\nglish and other languages are comparatively lower\nthan GPT-4 and Llama 2, English is accomplishing\napproximately 13% better on average than Bangla,\nHindi, and Urdu.\nFor the sentiment task, English is performing\nnearly on average 13% better than other languages\nusing GPT-4 (see Table 1). The performance dif-\nference of Llama 2 between English and other lan-\nguages is ∼11% on average, and English is con-\nsistently doing better than other languages. De-\nspite that, Bangla, Hindi, and Urdu are performing\n0.49%, 0.89%, and 0.60% better than English. The\nperformance of Gemini remains almost the same\nfor all the languages in the sentiment task. Our\nhate speech task experiments reveal that the perfor-\nmance of GPT-4 in English is approximately, on av-\nerage, 22% better than low-resource languages (see\nTable 1). Moreover, the performances in English\nare ∼17% and ∼18% better than low-resource\nlanguages for Llama 2 and Gemini models.\nWe postulate the low performance of LLMs in\nlow-resource languages for the following reasons.\nOne of the main reasons is that most of the LLMs\nare trained on a large amount (90%) of English\ndata, whereas the amount of training data for low-\nresource languages is small compared with English.\nModel\nLang.\nAcc.\nP.\nR.\nF1macro\nNLI Task\nGPT-4\nEN\n86.73\n86.91\n86.73\n86.79\nBN\n68.73\n75.95\n68.73\n68.75\nHI\n69.31\n76.26\n69.31\n69.41\nUR\n64.52\n72.90\n64.52\n63.98\nLlama 2\nEN\n74.47\n76.27\n74.47\n74.82\nBN\n45.66\n52.74\n45.66\n42.30\nHI\n47.29\n65.68\n47.29\n43.54\nUR\n46.39\n53.68\n46.39\n44.88\nGemini\nEN\n78.40\n78.06\n78.40\n78.12\nBN\n67.24\n69.32\n67.24\n67.16\nHI\n66.48\n68.67\n66.48\n66.50\nUR\n62.14\n65.38\n62.14\n62.01\nSentiment Task\nGPT-4\nEN\n72.64\n73.05\n72.64\n71.74\nBN\n61.33\n64.57\n61.33\n56.36\nHI\n66.47\n68.75\n66.47\n63.68\nUR\n62.31\n64.89\n62.31\n58.19\nLlama 2\nEN\n55.64\n66.89\n55.64\n53.38\nBN\n45.19\n60.22\n45.19\n40.28\nHI\n48.31\n63.32\n48.31\n43.73\nUR\n47.06\n61.61\n47.06\n42.62\nGemini\nEN\n64.59\n67.86\n64.59\n64.44\nBN\n65.40\n66.68\n65.40\n64.93\nHI\n65.87\n67.14\n65.87\n65.33\nUR\n65.93\n66.77\n65.93\n65.14\nHate Speech Task\nGPT-4\nEN\n86.81\n85.52\n86.81\n62.54\nBN\n55.32\n75.51\n55.32\n38.79\nHI\n64.66\n77.93\n64.66\n44.61\nUR\n54.00\n75.18\n54.00\n38.66\nLlama 2\nEN\n79.32\n83.93\n79.32\n60.04\nBN\n69.92\n69.12\n69.92\n41.36\nHI\n74.54\n71.58\n74.54\n44.39\nUR\n47.29\n65.68\n47.29\n43.54\nGemini\nEN\n58.00\n77.69\n58.00\n49.10\nBN\n30.34\n70.93\n30.34\n30.81\nHI\n32.01\n72.72\n32.01\n33.36\nUR\n28.56\n70.07\n28.56\n28.47\nTable 1: Performances of all the tasks across the models\nand languages. Bold indicates the best performances\nacross the languages for each task. Lang.: language,\nAcc.: accuracy, P.: Precision, R.: Recall, EN: English,\nBN: Bangla, HI: Hindi, and UR: Urdu\nMoreover, cultural differences between English-\nspoken countries and low-resource language coun-\ntries affect the sentiment and hate speech tasks the\nmost. Lastly, the quality of the translation affects\nthe performance of low-resource languages. How-\never, Hindi performed better than Bangla and Urdu\nin all tasks among the low-resource languages. The\nperformance difference among the low-resource\nlanguages is insignificant across the tasks and\nLLMs. Our findings from this section conclude\nthat improving LLMs is required for low-resource\nlanguages.\nComparison Among LLMs: We first analyzed\nthe individual LLM outputs and found that GPT-4\ncould not predict much data on sentiment and hate\nspeech tasks for Bangla and Urdu. Moreover, GPT-\n4 was able to provide predictions for all the English\nlanguage samples for all the tasks. We also noticed\nthat Llama 2 and Gemini models could predict all\nthe samples from the NLI task for all languages.\nLlama 2 could not predict much data on the hate\nspeech task for English. However, Llama 2 pro-\nvides a small number of unpredicted data compared\nwith GPT-4 for Bangla, Hindi, and Urdu. We ana-\nlyzed the response of unpredicted data from GPT-4.\nWe found that the model cannot understand the con-\ntext to classify while Llama 2 could not predict due\nto inappropriate or offensive language. Moreover,\nsome responses of Llama include repeated ‘l’ as the\nlabel. We briefly overview the unpredicted data in\nFigure 1. During the evaluation metrics calculation,\nwe assigned the inverse classes for the unpredicted\nsamples.\nGemini is the only LLM that predicted all the\nsamples of each task. Although we provide a safety\nsetting for the Gemini model, it blocked some\ndata due to the content containing derogatory lan-\nguage. We noticed that the samples from sentiment\nand hate speech tasks were blocked for containing\nderogatory language, and those from the NLI task\nwere not blocked. We provide a brief overview of\nthe number of samples that are blocked by Gem-\nini in Figure 2. However, the Urdu language is\nnot supported by the Gemini. Despite that, the\nGemini performs strongly in Urdu for the NLI and\nsentiment tasks. We further investigated the perfor-\nmances of Gemini in the Urdu language. We found\nthat the alphabets of Urdu are derived from the Ara-\nbic language family3 and many words are adopted\nfrom the Arabic language. Arabic is supported by\nGemini, and the training data of Arabic shares se-\nmantic information with the Urdu language, which\nis why Gemini exhibits a strong performance in the\nUrdu language.\nIn general, GPT-4 shows prominent perfor-\nmances over other LLMs across all the tasks. Al-\nthough Llama 2 provides better results for hate\nspeech tasks, it struggled to perform well in NLI\nand sentiment tasks. While Gemini demonstrated\nstrong performances in NLI and sentiment tasks,\nit delivered worse in hate speech tasks. Despite\nobserving a smaller performance gap in Gemini,\nsignificant disparities persist in GPT-4 and Llama-\n3https://en.wikipedia.org/wiki/Urdu_alphabet\n2, indicating that direct translation is less likely to\ncompromise sentiment information. See Appendix\nB for class-wise experimental results.\nTasks Performances: The overall performance\nof the NLI task is comparatively better than senti-\nment and hate speech tasks (Table 1). The defini-\ntion of an NLI task has clear rules and structured\npatterns, while sentiment and hate speech tasks\nare subjective and context-dependent. NLI task\nidentifies the relation between two sentences based\non structure and language logic (Bowman et al.,\n2015) that makes the task easier for LLMs. More-\nover, the context lies with the sentence pair, and\nLLMs can understand the context. While senti-\nment and hate speech tasks require understanding\nthe tone of the text and sometimes the complex\nsocial and cultural contexts, these facts are chal-\nlenging for LLMs to understand. Moreover, the\ndata of the NLI task is incorporated from the well-\nstructured MNLI corpus with precise labels and\nbalanced classes, making the task more comfort-\nable for LLMs. Unlike the NLI task, sentiment and\nhate speech task data are curated from social media\nplatforms containing noise, informal expressions,\nslang, and incomplete text, making it challenging\nfor LLMs. Moreover, most of the texts do not have\nthe contexts within their representation, and it is\nchallenging to identify the context for both humans\nand LLMs. Straightforward linguistics features and\ncontextual information make the NLI task easier\nand perform better than sentiment and hate speech\ntasks using different LLMs. In addition, during the\nevaluation, we explored whether English hashtags\nhave any impact on predictions for Bangla, Hindi,\nand Urdu. Our empirical results demonstrated that\nLLMs do not rely solely on hashtags but on the\nentire sequence.\n5\nConclusion\nIn this study, we introduce datasets for sentiment\nand hate speech tasks by translating from English\nto Bangla, Hindi, and Urdu to facilitate research\nin low-resource language processing.\nThrough\na comprehensive examination of zero-shot learn-\ning across multiple LLMs, notably GPT-4, we un-\ncover performance disparities between English and\nlow-resource languages. Furthermore, our analy-\nsis identifies NLI as a task where GPT-4 consis-\ntently demonstrates superior capabilities, under-\nscoring avenues for enhancing LLM applicability\nin general-purpose NLP applications.\nLimitation\nIn our study, we refrained from utilizing explicit\nprompting techniques to enhance the performance\nof large language models (LLMs). Our evaluation\nprimarily focused on assessing LLMs in the con-\ntext of English and low-resource languages such as\nBangla, Hindi, and Urdu, without exploring varia-\ntions in prompts. Regarding the quality of dataset\ntranslations, it is important to note that the transla-\ntions generated by Google Translator were not sub-\njected to human verification. Consequently, while\ncertain translation errors were overlooked during\nour analysis, we conducted sampling from each\ntranslated dataset to gain insights into the overall\ntranslation quality. Our findings underscore the ne-\ncessity for further refinement in translation method-\nologies to elevate both the quality and accuracy of\ntranslations in future research endeavors.\nReferences\nDivyanshu Aggarwal,\nVivek Gupta,\nand Anoop\nKunchukuttan. 2022. Indicxnli: Evaluating multilin-\ngual inference for indian languages. arXiv preprint\narXiv:2204.08776.\nKabir Ahuja, Harshita Diddee, Rishav Hada, Milli-\ncent Ochieng, Krithika Ramesh, Prachi Jain, Ak-\nshay Nambi, Tanuja Ganu, Sameer Segal, Maxamed\nAxmed, et al. 2023a. Mega: Multilingual evaluation\nof generative ai. arXiv preprint arXiv:2303.12528.\nSanchit Ahuja, Divyanshu Aggarwal, Varun Gumma,\nIshaan Watts, Ashutosh Sathe, Millicent Ochieng,\nRishav Hada, Prachi Jain, Maxamed Axmed, Kalika\nBali, et al. 2023b. Megaverse: benchmarking large\nlanguage models across languages, modalities, mod-\nels and tasks. arXiv preprint arXiv:2311.07463.\nSyeda Nahida Akter, Zichun Yu, Aashiq Muhamed,\nTianyue Ou, Alex Bäuerle, Ángel Alexander Cabrera,\nKrish Dholakia, Chenyan Xiong, and Graham Neu-\nbig. 2023. An in-depth look at gemini’s language\nabilities. arXiv preprint arXiv:2312.11444.\nFiroj Alam, Arid Hasan, Tanvirul Alam, Akib Khan,\nJanntatul Tajrin, Naira Khan, and Shammur Absar\nChowdhury. 2021. A review of bangla natural lan-\nguage processing tasks and the utility of transformer\nmodels. arXiv preprint arXiv:2107.03844.\nAkari Asai, Sneha Kudugunta, Xinyan Velocity Yu,\nTerra Blevins, Hila Gonen, Machel Reid, Yulia\nTsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi.\n2023. Buffet: Benchmarking large language models\nfor few-shot cross-lingual transfer. arXiv preprint\narXiv:2305.14857.\nAbhik Bhattacharjee, Tahmid Hasan, Kazi Samin,\nMd Saiful Islam, M. Sohel Rahman, Anindya Iqbal,\nand Rifat Shahriyar. 2021. Banglabert: Combating\nembedding barrier in multilingual models for low-\nresource language understanding.\nSamuel R Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D Manning. 2015. A large annotated\ncorpus for learning natural language inference. arXiv\npreprint arXiv:1508.05326.\nAlexis Conneau, Ruty Rinott, Guillaume Lample, Ad-\nina Williams, Samuel R. Bowman, Holger Schwenk,\nand Veselin Stoyanov. 2018. Xnli: Evaluating cross-\nlingual sentence representations. In Proceedings of\nthe 2018 Conference on Empirical Methods in Natu-\nral Language Processing. Association for Computa-\ntional Linguistics.\nThomas Davidson, Dana Warmsley, Michael Macy, and\nIngmar Weber. 2017. Automated hate speech de-\ntection and the problem of offensive language. In\nProceedings of the 11th International AAAI Confer-\nence on Web and Social Media, ICWSM ’17, pages\n512–515.\nJosé Antonio García-Díaz, Ronghao Pan, and Rafael\nValencia-García. 2023. Leveraging zero and few-\nshot learning for enhanced model generality in hate\nspeech detection in spanish and english. Mathemat-\nics, 11(24):5004.\nReto Gubelmann, Aikaterini-Lida Kalouli, Christina\nNiklaus, and Siegfried Handschuh. 2023. When truth\nmatters-addressing pragmatic categories in natural\nlanguage inference (nli) by large language models\n(llms). In Proceedings of the 12th Joint Conference\non Lexical and Computational Semantics (* SEM\n2023), pages 24–39.\nMd Arid Hasan, Firoj Alam, Anika Anjum, Shudipta\nDas, and Afiyat Anjum. 2023a. Blp-2023 task 2:\nSentiment analysis. In Proceedings of the First Work-\nshop on Bangla Language Processing (BLP-2023),\npages 354–364.\nMd Arid Hasan, Shudipta Das, Afiyat Anjum, Firoj\nAlam, Anika Anjum, Avijit Sarker, and Sheak\nRashed Haider Noori. 2023b. Zero-and few-shot\nprompting with llms: A comparative study with fine-\ntuned models for bangla sentiment analysis. arXiv\npreprint arXiv:2308.10783.\nMd Arid Hasan, Jannatul Tajrin, Shammur Absar\nChowdhury, and Firoj Alam. 2020. Sentiment clas-\nsification in bangla textual content: A comparative\nstudy. In 2020 23rd international conference on com-\nputer and information technology (ICCIT), pages 1–6.\nIEEE.\nMing Shan Hee, Shivam Sharma, Rui Cao, Palash\nNandi, Preslav Nakov, Tanmoy Chakraborty, and\nRoy Ka-Wei Lee. 2024. Recent advances in hate\nspeech moderation: Multimodality and the role of\nlarge models. arXiv preprint arXiv:2401.16727.\nOskar Holmström, Jenny Kunz, and Marco Kuhlmann.\n2023. Bridging the resource gap: Exploring the effi-\ncacy of english and multilingual llms for swedish.\nIn Proceedings of the Second Workshop on Re-\nsources and Representations for Under-Resourced\nLanguages and Domains (RESOURCEFUL-2023),\npages 92–110.\nJunjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-\nham Neubig, Orhan Firat, and Melvin Johnson.\n2020. Xtreme: A massively multilingual multi-task\nbenchmark for evaluating cross-lingual generalisa-\ntion. In International Conference on Machine Learn-\ning, pages 4411–4421. PMLR.\nHaoyang Huang, Tianyi Tang, Dongdong Zhang,\nWayne Xin Zhao, Ting Song, Yan Xia, and Furu\nWei. 2023.\nNot all languages are created equal\nin llms:\nImproving multilingual capability by\ncross-lingual-thought prompting.\narXiv preprint\narXiv:2305.07004.\nKhondoker Ittehadul Islam, Sudipta Kar, Md Saiful Is-\nlam, and Mohammad Ruhul Amin. 2021. Sentnob: A\ndataset for analysing sentiment on noisy bangla texts.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2021, pages 3265–3271.\nMohsinul Kabir, Mohammed Saidul Islam, Md Tah-\nmid Rahman Laskar, Mir Tafseer Nayeem, M Sai-\nful Bari, and Enamul Hoque. 2023. Benllmeval: A\ncomprehensive evaluation into the potentials and pit-\nfalls of large language models on bengali nlp. arXiv\npreprint arXiv:2309.13173.\nMuhammad Moin Khan, Khurram Shahzad, and\nMuhammad Kamran Malik. 2021. Hate speech de-\ntection in roman urdu. ACM Transactions on Asian\nand Low-Resource Language Information Processing\n(TALLIP), 20(1):1–19.\nFajri Koto, Tilman Beck, Zeerak Talat, Iryna Gurevych,\nand Timothy Baldwin. 2024.\nZero-shot senti-\nment analysis in low-resource languages using a\nmultilingual sentiment lexicon.\narXiv preprint\narXiv:2402.02113.\nAkshi Kumar and Victor Hugo C Albuquerque. 2021.\nSentiment analysis using xlm-r transformer and zero-\nshot transfer learning on resource-poor indian lan-\nguage. Transactions on Asian and Low-Resource\nLanguage Information Processing, 20(5):1–13.\nViet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo,\nThuat Nguyen, Franck Dernoncourt, Ryan A Rossi,\nand Thien Huu Nguyen. 2023. Okapi: Instruction-\ntuned large language models in multiple languages\nwith reinforcement learning from human feedback.\narXiv preprint arXiv:2307.16039.\nPan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chun-\nyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-\nWei Chang, Michel Galley, and Jianfeng Gao. 2023.\nMathvista: Evaluating mathematical reasoning of\nfoundation models in visual contexts. arXiv preprint\narXiv:2310.02255.\nChenyang Lyu, Jitao Xu, and Longyue Wang. 2023.\nNew trends in machine translation using large lan-\nguage models: Case examples with chatgpt. arXiv\npreprint arXiv:2305.01181.\nNing Miao, Yee Whye Teh, and Tom Rainforth.\n2023.\nSelfcheck: Using llms to zero-shot check\ntheir own step-by-step reasoning.\narXiv preprint\narXiv:2308.00436.\nR OpenAI. 2023. Gpt-4 technical report. arXiv, pages\n2303–08774.\nBhavish Pahwa and Bhavika Pahwa. 2023. Bphigh at\nsemeval-2023 task 7: Can fine-tuned cross-encoders\noutperform gpt-3.5 in nli tasks on clinical trial data?\nIn Proceedings of the 17th International Workshop on\nSemantic Evaluation (SemEval-2023), pages 1936–\n1944.\nLibo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang,\nand Wanxiang Che. 2023.\nCross-lingual prompt-\ning: Improving zero-shot chain-of-thought reasoning\nacross languages. arXiv preprint arXiv:2310.14799.\nNitin Rane. 2023. Enhancing mathematical capabili-\nties through chatgpt and similar generative artificial\nintelligence: Roles and challenges in solving mathe-\nmatical problems. Available at SSRN 4603237.\nNathaniel R Robinson,\nPerez Ogayo,\nDavid R\nMortensen, and Graham Neubig. 2023.\nChatgpt\nmt: Competitive for high-(but not low-) resource\nlanguages. arXiv preprint arXiv:2309.07423.\nSara Rosenthal, Noura Farra, and Preslav Nakov. 2017.\nSemEval-2017 task 4: Sentiment analysis in Twitter.\nIn Proceedings of the 11th International Workshop\non Semantic Evaluation, SemEval ’17, Vancouver,\nCanada. Association for Computational Linguistics.\nSebastian Ruder, Noah Constant, Jan Botha, Aditya Sid-\ndhant, Orhan Firat, Jinlan Fu, Pengfei Liu, Junjie Hu,\nDan Garrette, Graham Neubig, et al. 2021. Xtreme-r:\nTowards more challenging and nuanced multilingual\nevaluation. arXiv preprint arXiv:2104.07412.\nTYSS Santosh and KVS Aravind. 2019. Hate speech\ndetection in hindi-english code-mixed social media\ntext. In Proceedings of the ACM India joint interna-\ntional conference on data science and management\nof data, pages 310–313.\nXiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang,\nFei Wu, Jiwei Li, Tianwei Zhang, and Guoyin Wang.\n2023. Sentiment analysis through llm negotiations.\narXiv preprint arXiv:2311.01876.\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\nbastian Gehrmann, Yi Tay, Hyung Won Chung,\nAakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny\nZhou, et al. 2022. Challenging big-bench tasks and\nwhether chain-of-thought can solve them.\narXiv\npreprint arXiv:2210.09261.\nYiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu,\nYongrui Chen, and Guilin Qi. 2023. Can chatgpt\nreplace traditional kbqa models? an in-depth analysis\nof the question answering performance of the gpt llm\nfamily. In International Semantic Web Conference,\npages 348–367. Springer.\nGemini Team, Rohan Anil, Sebastian Borgeaud,\nYonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,\nRadu Soricut, Johan Schalkwyk, Andrew M Dai,\nAnja Hauth, et al. 2023.\nGemini: a family of\nhighly capable multimodal models. arXiv preprint\narXiv:2312.11805.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, et al. 2023.\nLlama 2:\nOpen founda-\ntion and fine-tuned chat models.\narXiv preprint\narXiv:2307.09288.\nFrank Xing. 2024. Designing heterogeneous llm agents\nfor financial sentiment analysis.\narXiv preprint\narXiv:2401.05799.\nHaoran Xu,\nYoung Jin Kim,\nAmr Sharaf,\nand\nHany Hassan Awadalla. 2023.\nA paradigm shift\nin machine translation: Boosting translation perfor-\nmance of large language models.\narXiv preprint\narXiv:2309.11674.\nBoyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\n2023a. Instruct-fingpt: Financial sentiment analy-\nsis by instruction tuning of general-purpose large\nlanguage models. arXiv preprint arXiv:2306.12659.\nBoyu Zhang, Hongyang Yang, Tianyu Zhou, Muham-\nmad Ali Babar, and Xiao-Yang Liu. 2023b.\nEn-\nhancing financial sentiment analysis via retrieval aug-\nmented large language models. In Proceedings of\nthe Fourth ACM International Conference on AI in\nFinance, pages 349–356.\nYuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and\nChao Zhang. 2023. Toolqa: A dataset for llm ques-\ntion answering with external tools. arXiv preprint\narXiv:2306.13304.\nA\nPrompts and Safety Setting\nThis section presents the details of the prompts that\nwe used for each model and task4. We present the\nexample prompt for the NLI task, sentiment task,\nand Hatespeech task in Table 2, Table 3, and Table\n4 respectively. We provide the details of the safety\nsetting for the Gemini Pro model in Table 5\n4Note that we use the same prompt for each task.\nModel\nPrompt\nGPT-4\n[ {\n‘role’: ‘user’,\n‘content’: \"Classify the following ‘premise’\nand ‘hypothesis’ into one of the following\nclasses:\n‘Entailment’, ‘Contradiction’, or\n‘Neutral’.\nProvide only label as your re-\nsponse.\"\npremise: [PREMISE_TEXT]\nhypothesis: [HYPOTHESIS_TEXT]\nlabel:\n},\n{\nrole: ‘system’,\ncontent: \"You are an expert data annotator and\nyour task is to analyze the text and find the\nappropriate output that is defined in the user\ncontent.\"\n} ]\nLlama\n2\nand Gemini\nClassify the following ‘premise’ and ‘hypoth-\nesis’ into one of the following classes: ‘Entail-\nment’, ‘Contradiction’, or ‘Neutral’. Provide\nonly label as your response.\npremise: [PREMISE_TEXT]\nhypothesis: [HYPOTHESIS_TEXT]\nlabel:\nTable 2: Prompts used for zero-shot learning in NLI\ntask.\nModel\nPrompt\nGPT-4\n[ {\n‘role’: ‘user’,\n‘content’: \"Classify the ‘text’ into one of the\nfollowing labels: ‘Positive’, ‘Neutral’, or ‘Neg-\native’. Provide only label as your response.\"\ntext: [SOURCE_TEXT]\nlabel:\n},\n{\nrole: ‘system’,\ncontent: \"You are an expert data annotator and\nyour task is to analyze the text and find the\nappropriate output that is defined in the user\ncontent.\"\n} ]\nLlama\n2\nand Gemini\nClassify the ‘text’ into one of the following la-\nbels: ‘Positive’, ‘Neutral’, or ‘Negative’. Pro-\nvide only label as your response.\ntext: [SOURCE_TEXT]\nlabel:\nTable 3: Prompts used for zero-shot learning in Senti-\nment task.\nB\nExperimental Details and Results\nB.1\nExperimental Settings\nB.1.1\nData\nThis section discusses the publicly available data\nfor three tasks used in our study. We first discuss\nthe data for the NLI task followed by the senti-\nModel\nPrompt\nGPT-4\n[ {\n‘role’: ‘user’,\n‘content’: \"Classify the ‘text’ into one of the\nfollowing labels: ‘Hate’, ‘Offensive’, or ‘Nei-\nther’. Provide only label as your response.\"\ntext: [SOURCE_TEXT]\nlabel:\n},\n{\nrole: ‘system’,\ncontent: \"You are an expert data annotator and\nyour task is to analyze the text and find the\nappropriate output that is defined in the user\ncontent.\"\n} ]\nLlama\n2\nand Gemini\nClassify the ‘text’ into one of the following\nlabels: ‘Hate’, ‘Offensive’, or ‘Neither’. Pro-\nvide only label as your response.\ntext: [SOURCE_TEXT]\nlabel:\nTable 4: Prompts used for zero-shot learning in Hate-\nspeech task.\nCategory\nThreshold\nHARM_CATEGORY_HARASSMENT\nBLOCK_NONE\nHARM_CATEGORY_HATE_SPEECH\nBLOCK_NONE\nHARM_CATEGORY_SEXUALLY_EXPLICIT\nBLOCK_NONE\nHARM_CATEGORY_DANGEROUS_CONTENT\nBLOCK_NONE\nHARM_CATEGORY_SEXUAL\nBLOCK_NONE\nHARM_CATEGORY_DANGEROUS\nBLOCK_NONE\nTable 5: Safety setting used for Gemini Pro model to\nprevent blocking the predictions for harmful content.\nment task and conclude with the hate speech task.\nAlthough each task has some datasets for all the\nlanguages individually, only the dataset of the NLI\ntask has been translated into several languages. To\nfairly evaluate the generalization of LLMs, the\ntranslated version of the datasets is mandatory for\nother tasks. We provide a detailed description of\ndata distribution in Table 6.\nNLI Task:\nWe used the cross-lingual natural lan-\nguage inference (XNLI) dataset (Conneau et al.,\n2018) for the NLI task. We select the test set of\nEnglish, Hindi, and Urdu languages from the XNLI\ndataset for our experiments. For the Bangla lan-\nguage, we used the translated version of XNLI\n(Bhattacharjee et al., 2021).\nSentiment Task:\nFor the sentiment analysis task,\nwe used the official test of SemEval-2017 task 4:\nSentiment Analysis in Twitter (Rosenthal et al.,\n2017). Primarily, the annotation was completed\nin five classes and then the labels were re-mapped\ninto three classes.The SemEval-2017 task 4 offered\nonly English and Arabic data. In this study, we\nonly incorporate the English data.\nHate Speech Task:\nWe used the dataset de-\nscribed in (Davidson et al., 2017) for our hate\nspeech task. The official dataset consists of a total\nof 24, 802 samples. We first split the data into train,\nvalidation, and test splits by 70%, 10%, and 20%\nrespectively. We only used the test set in our study\nand the language of the official dataset is English.\nTranslation:\nWe translated the English test set\nfor the Bangla, Hindi, and Urdu languages to eval-\nuate the LLMs for sentiment and hate speech tasks.\nWe used the web version of Google Translator5\nwith the use of Deep Translator toolkit6. We ana-\nlyzed the translations and found that most of the\nhashtags were not translated into the target lan-\nguage. Moreover, Hindi translations were far better\nthan Bangla and Urdu. We also randomly sam-\npled 100 translation pairs for each language from\nboth tasks to check the translation quality by na-\ntive speakers. The feedback from native speakers\nindicates that there is room for improvement in the\ntranslation quality. Additionally, it is important to\nnote that we followed previous best practices used\nin similar studies (Aggarwal et al., 2022; Lai et al.,\n2023).\nTask\nLanguages\nClass\nTest\nNLI\nEN, HI, UR\nContradiction\n1, 670\nEntailment\n1, 670\nNeutral\n1, 670\nBN\nContradiction\n1, 630\nEntailment\n1, 631\nNeutral\n1, 634\nSentiment\nEN, BN, HI, UR\nNegative\n3, 972\nNeutral\n5, 937\nPositive\n2, 375\nHate Speech\nEN, BN, HI, UR\nHate\n280\nNeither\n821\nOffensive\n3, 856\nTable 6: Class-wise test set data distribution for all the\ntasks. EN: English, BN: Bangla, HI: Hindi, and UR:\nUrdu.\nB.1.2\nData Pre-processing\nThe sentiment and hate speech datasets were\nmainly collected from X and contain URLs, user-\nnames, hashtags, emoticons, and symbols. We only\nremoved the URLs and usernames from the senti-\nment and hate speech task datasets. We keep the\n5https://translate.google.com\n6https://pypi.org/project/deep-translator/\nhashtags, emoticons, and symbols with data to un-\nderstand how LLMs performed with this mixed\ninformation. Moreover, we did not perform any\npreprocessing steps for the XNLI dataset.\nB.1.3\nEvaluation Metrics\nTo evaluate our experiments, we calculated accu-\nracy, precision, recall, and F1 scores for all the\ntasks. We computed the weighted version of preci-\nsion and recall and the macro version of F1 score\nas it considers class imbalance.\nB.2\nDetailed Results\nWe investigated the detailed performances of each\ntask (see Table 7, Table 8, and Table 9). GPT-4\nshows superior performances on the NLI task for all\nlanguages while exhibiting good performances on\nthe sentiment task. However, most hate class data\nwere misclassified in the hate speech task for all lan-\nguages. Llama 2 provides strong performances in\nEnglish for NLI, sentiment, and hate speech tasks\nwhile finding difficulties in accurately predicting\nthe contradiction, neutral, and hate classes for NLI,\nsentiment, and hate speech tasks, respectively. Al-\nthough Llama 2 outperforms GPT-4 performances\nin hate class in every language, GPT-4 in English\nand Hindi is better than Llama 2 for hate speech\ntasks. Moreover, Llama 2 demonstrated compara-\ntively better performance on the hate speech task\nthan NLI and sentiment tasks. While Gemini ex-\nhibits strong performances in NLI and sentiment\ntasks for all the languages, it consistently performs\npoorly on the speech task for all the languages.\nHowever, Gemini performs comparatively better\nhate class performance than Llama 2 and GPT-4\nfor all the languages. Moreover, the performances\nin the neither and offensive classes are worse than\nother LLMs. We also found that most offensive\nclasses are misclassified as neither.\nB.2.1\nNLI Task\nWe present the detailed class-wise performances\nfor the NLI task across the LLMs in Table 7.\nB.2.2\nSentiment Task\nDetailed class-wise performances for the sentiment\ntask across the LLMs are presented in Table 8.\nB.2.3\nHatespeech Task\nTable 9 reports the detailed class-wise perfor-\nmances for the hatespeech task across the LLMs.\nC\nExperimental Analysis\nModel\nLang.\nClass\nP.\nR.\nF1\nGPT-4\nEN\nContradiction\n92.45\n89.40\n90.90\nEntailment\n88.25\n86.88\n87.56\nNeutral\n80.02\n82.90\n81.92\nBN\nContradiction\n85.58\n67.03\n75.18\nEntailment\n88.26\n49.85\n63.17\nNeutral\n54.10\n89.24\n67.36\nHI\nContradiction\n88.54\n68.92\n77.51\nEntailment\n86.02\n50.18\n63.39\nNeutral\n54.22\n88.80\n67.33\nUR\nContradiction\n85.41\n40.66\n55.09\nEntailment\n82.53\n64.27\n72.26\nNeutral\n50.79\n88.62\n64.57\nLlama 2\nEN\nContradiction\n94.12\n73.83\n82.75\nEntailment\n72.88\n83.17\n77.68\nNeutral\n61.82\n66.41\n64.03\nBN\nContradiction\n65.80\n13.93\n22.99\nEntailment\n54.66\n57.20\n55.90\nNeutral\n37.81\n65.79\n48.02\nHI\nContradiction\n88.30\n14.91\n25.51\nEntailment\n70.72\n41.80\n52.54\nNeutral\n38.01\n85.15\n52.56\nUR\nContradiction\n63.88\n22.87\n33.69\nEntailment\n59.63\n46.17\n52.04\nNeutral\n37.54\n70.12\n48.90\nGemini\nEN\nContradiction\n84.24\n90.24\n87.14\nEntailment\n77.76\n80.00\n78.87\nNeutral\n72.17\n64.95\n68.37\nBN\nContradiction\n72.90\n78.81\n75.57\nEntailment\n79.22\n53.35\n63.76\nNeutral\n55.88\n69.57\n61.97\nHI\nContradiction\n74.14\n75.36\n74.73\nEntailment\n77.08\n53.21\n62.96\nNeutral\n54.82\n70.88\n61.82\nUR\nContradiction\n70.14\n70.06\n70.10\nEntailment\n75.27\n45.81\n56.98\nNeutral\n50.62\n70.54\n58.94\nTable 7: Class-wise performances of the NLI task across\nthe models and languages. Bold indicates the best per-\nformances across the languages. Lang.: language, P.:\nPrecision, R.: Recall, EN: English, BN: Bangla, HI:\nHindi, and UR: Urdu\nFigure 1: Number of unpredicted samples by GPT-4\nand Llama 2. Note that we only include the languages\nand models from the tasks with unpredicted samples.\nModel\nLang.\nClass\nP.\nR.\nF1\nGPT-4\nEN\nNegative\n73.08\n73.39\n73.23\nNeutral\n70.52\n77.23\n73.72\nPositive\n79.36\n59.92\n68.28\nBN\nNegative\n71.29\n39.88\n51.15\nNeutral\n57.40\n85.11\n68.56\nPositive\n71.25\n37.77\n49.37\nHI\nNegative\n73.07\n51.79\n60.62\nNeutral\n62.03\n83.90\n71.33\nPositive\n78.32\n47.45\n59.10\nUR\nNegative\n72.34\n43.01\n53.95\nNeutral\n58.45\n83.43\n68.74\nPositive\n68.51\n41.77\n51.90\nLlama 2\nEN\nNegative\n56.08\n94.26\n70.32\nNeutral\n81.81\n16.89\n28.01\nPositive\n47.65\n87.92\n61.80\nBN\nNegative\n45.10\n90.79\n60.27\nNeutral\n76.96\n2.81\n5.43\nPositive\n43.66\n74.89\n55.16\nHI\nNegative\n48.31\n93.78\n63.77\nNeutral\n80.45\n4.78\n9.03\nPositive\n45.62\n81.05\n58.38\nUR\nNegative\n46.15\n93.55\n61.81\nNeutral\n78.18\n4.77\n8.99\nPositive\n46.05\n75.03\n57.07\nGemini\nEN\nNegative\n60.40\n87.89\n71.60\nNeutral\n76.83\n46.38\n57.84\nPositive\n57.86\n71.33\n63.89\nBN\nNegative\n61.28\n84.21\n70.94\nNeutral\n72.07\n54.44\n62.03\nPositive\n62.23\n61.42\n61.82\nHI\nNegative\n62.57\n83.42\n71.51\nNeutral\n71.36\n57.17\n63.48\nPositive\n62.33\n58.65\n60.43\nUR\nNegative\n61.74\n84.66\n71.41\nNeutral\n72.63\n55.11\n62.67\nPositive\n62.41\n61.42\n61.91\nTable 8: Class-wise performances of the Sentiment task\nacross the models and languages. Bold indicates the best\nperformances across the languages. Lang.: language,\nP.: Precision, R.: Recall, EN: English, BN: Bangla, HI:\nHindi, and UR: Urdu\nFigure 2: Number of samples that are blocked by Gem-\nini.\nModel\nLang.\nClass\nP.\nR.\nF1\nGPT-4\nEN\nHate\n62.96\n12.14\n20.36\nOffensive\n88.85\n95.10\n91.87\nNeither\n77.58\n73.33\n75.39\nBN\nHate\n22.39\n5.36\n8.65\nOffensive\n89.56\n51.61\n65.48\nNeither\n27.62\n89.77\n42.25\nHI\nHate\n32.69\n6.07\n10.24\nOffensive\n90.97\n63.49\n74.68\nNeither\n33.56\n90.13\n48.91\nUR\nHate\n33.93\n6.79\n11.31\nOffensive\n88.58\n50.49\n64.32\nNeither\n26.30\n86.60\n40.35\nLlama 2\nEN\nHate\n14.98\n31.79\n20.37\nOffensive\n88.16\n86.51\n87.33\nNeither\n87.56\n61.75\n72.43\nBN\nHate\n13.35\n17.50\n15.15\nOffensive\n80.82\n85.14\n82.92\nNeither\n42.42\n27.28\n33.21\nHI\nHate\n15.09\n12.50\n13.67\nOffensive\n80.93\n89.06\n84.80\nNeither\n46.89\n27.53\n34.69\nUR\nHate\n11.98\n18.57\n14.57\nOffensive\n80.05\n83.87\n81.91\nNeither\n37.27\n21.92\n27.61\nGemini\nEN\nHate\n14.95\n76.34\n25.00\nOffensive\n88.87\n55.49\n68.32\nNeither\n46.97\n63.41\n53.97\nBN\nHate\n8.62\n79.93\n15.56\nOffensive\n83.14\n20.36\n32.71\nNeither\n34.83\n60.29\n44.16\nHI\nHate\n8.27\n81.65\n15.01\nOffensive\n83.90\n22.50\n35.49\nNeither\n42.47\n59.51\n49.57\nUR\nHate\n8.76\n76.43\n15.72\nOffensive\n83.20\n18.53\n30.31\nNeither\n29.49\n59.20\n39.37\nTable 9: Class-wise performances of the Hatespeech\ntask across the models and languages. Bold indicates\nthe best performances across the languages. Lang.:\nlanguage, P.: Precision, R.: Recall, EN: English, BN:\nBangla, HI: Hindi, and UR: Urdu\n",
  "categories": [
    "cs.CL",
    "F.2.2; I.2.7"
  ],
  "published": "2024-08-05",
  "updated": "2024-08-05"
}