{
  "id": "http://arxiv.org/abs/2409.03375v1",
  "title": "Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time",
  "authors": [
    "Francisco de Arriba-Pérez",
    "Silvia García-Méndez"
  ],
  "abstract": "Based on official estimates, 50 million people worldwide are affected by\ndementia, and this number increases by 10 million new patients every year.\nWithout a cure, clinical prognostication and early intervention represent the\nmost effective ways to delay its progression. To this end, Artificial\nIntelligence and computational linguistics can be exploited for natural\nlanguage analysis, personalized assessment, monitoring, and treatment. However,\ntraditional approaches need more semantic knowledge management and\nexplicability capabilities. Moreover, using Large Language Models (LLMs) for\ncognitive decline diagnosis is still scarce, even though these models represent\nthe most advanced way for clinical-patient communication using intelligent\nsystems. Consequently, we leverage an LLM using the latest Natural Language\nProcessing (NLP) techniques in a chatbot solution to provide interpretable\nMachine Learning prediction of cognitive decline in real-time.\nLinguistic-conceptual features are exploited for appropriate natural language\nanalysis. Through explainability, we aim to fight potential biases of the\nmodels and improve their potential to help clinical workers in their diagnosis\ndecisions. More in detail, the proposed pipeline is composed of (i) data\nextraction employing NLP-based prompt engineering; (ii) stream-based data\nprocessing including feature engineering, analysis, and selection; (iii)\nreal-time classification; and (iv) the explainability dashboard to provide\nvisual and natural language descriptions of the prediction outcome.\nClassification results exceed 80 % in all evaluation metrics, with a recall\nvalue for the mental deterioration class about 85 %. To sum up, we contribute\nwith an affordable, flexible, non-invasive, personalized diagnostic system to\nthis work.",
  "text": "Leveraging Large Language Models through Natural Language\nProcessing to provide interpretable Machine Learning predictions\nof mental deterioration in real time\nFrancisco de Arriba-P´erez1† and Silvia Garc´ıa-M´endez1*†\n1Information Technologies Group, atlanTTic, University of Vigo, Vigo, Spain.\n*Corresponding author(s). E-mail(s): sgarcia@gti.uvigo.es;\nContributing authors: farriba@gti.uvigo.es;\n†These authors contributed equally to this work.\nAbstract\nBased on official estimates, 50 million people worldwide are affected by dementia, and this number increases\nby 10 million new patients every year. Without a cure, clinical prognostication and early intervention repre-\nsent the most effective ways to delay its progression. To this end, Artificial Intelligence and computational\nlinguistics can be exploited for natural language analysis, personalized assessment, monitoring, and treatment.\nHowever, traditional approaches need more semantic knowledge management and explicability capabilities.\nMoreover, using Large Language Models (llms) for cognitive decline diagnosis is still scarce, even though\nthese models represent the most advanced way for clinical-patient communication using intelligent systems.\nConsequently, we leverage an llm using the latest Natural Language Processing (nlp) techniques in a chatbot\nsolution to provide interpretable Machine Learning prediction of cognitive decline in real-time. Linguistic-\nconceptual features are exploited for appropriate natural language analysis. Through explainability, we aim\nto fight potential biases of the models and improve their potential to help clinical workers in their diagno-\nsis decisions. More in detail, the proposed pipeline is composed of (i) data extraction employing nlp-based\nprompt engineering; (ii) stream-based data processing including feature engineering, analysis, and selection;\n(iii) real-time classification; and (iv) the explainability dashboard to provide visual and natural language\ndescriptions of the prediction outcome. Classification results exceed 80 % in all evaluation metrics, with a\nrecall value for the mental deterioration class about 85 %. To sum up, we contribute with an affordable,\nflexible, non-invasive, personalized diagnostic system to this work.\nKeywords: Artificial Intelligence, explainability, healthcare, Large Language Models, Natural Language Processing,\nstream-based Machine Learning.\nThis version of the article has been accepted\nfor publication, after peer review but is not the\nVersion of Record and does not reflect post-\nacceptance improvements, or any corrections.\nThe Version of Record is available online at:\nhttps://doi.org/10.1007/s13369-024-09508-2.\n1 Introduction\nNeurodegenerative Alzheimer’s disorder (ad) is the\nleading cause of chronic or progressive demen-\ntia, which negatively impacts cognitive functioning,\nincluding comprehension, speech, and thinking prob-\nlems, memory loss, etc. [1]. More in detail, the typical\nstages of cognitive decline can be categorized as pre-\nclinical ad, Mild Cognitive Impairment (mci) caused\nby ad, and finally ad dementia [2]. Generally, cog-\nnitively impaired users find difficult to perform daily\ntasks with the consequent detrimental impact on their\nlife quality [3]. In this line, cognitive decline is a lead-\ning cause of dependency and disability for our elders\n[4].\nAccording to the Alzheimer’s Association report\non the impact of this disease in the United States [5],\nit is the sixth-leading death cause that increased more\nthan 145 % in the last years. Moreover, it affects 6.7\nmillion people 65 or older. Dreadfully, this number is\n1\narXiv:2409.03375v1  [cs.CL]  5 Sep 2024\npredicted to grow to 13.8 million by 2060. Regard-\ning medical expenses related to people affected with\ndementia 65 or older, these are three times greater\nthan those of people without this condition, reaching\n345 billion dollars so far in 2023. Overall, the World\nHealth Organization estimates that 50 million people\nworldwide are affected by dementia, with 10 million\nnew patients yearly1.\nClinical prognostication and early intervention,\nthe most promising ways to address mental deteri-\noration, rely on effective progression detection [2].\nAmong the benefits of early identification, care plan-\nning assistance, medical expense reduction, and the\nopportunity to receive the latest treatments, includ-\ning non-invasive therapy, given the rapid biologic\ntherapeutics advancements, stand out [6, 7]. The\nsocial stigma and socioeconomic status must also\nbe considered when accessing mental health services\n[8]. However, the latter early diagnosis is challeng-\ning since the symptoms can be confused with normal\naging decline [9]. To address it, computational linguis-\ntics can be exploited [10]. Natural language analysis\nis particularly relevant, constituting a significant pro-\nportion of healthcare data [11]. Particularly, impair-\nment in language production mainly affects lexical\n(e.g., little use of nouns and verbs), semantic (e.g., the\nuse of empty words like thing/stuff), and pragmatic\n(e.g., discourse disorganization) aspects [12].\nDigital and technological advances such as Artifi-\ncial Intelligence (ai)-based systems represent promis-\ning approaches towards individuals’ needs for per-\nsonalized assessment, monitoring, and treatment\n[13]. Accordingly, these systems have the capa-\nbilities to complement traditional methodologies\nsuch as the Alzheimer’s Disease Assessment Scale-\nCognition (adascog), the Mini-Mental State Exam-\nination (mmse), and the Montreal Cognitive Assess-\nment (moca), which generally involve expensive,\ninvasive equipment, and lengthy evaluations [14]. In\nfact, paper-and-pencil cognitive tests continue to be\nthe most common approaches even though the lat-\nest advances in the Natural Language Processing\n(nlp) field enable easy screening from speech data\nwhile at the same time avoiding patient/physician\nburdening [15]. Summing up, language analysis can\ntranslate into an effective, inexpensive, non-invasive,\nand simpler way of monitoring cognitive decline\n[14, 16] provided that spontaneous speech of cogni-\ntive impaired people is characterized by the afore-\nmentioned semantic comprehension problems and\nmemory loss episodes [17].\nConsequently, Clinical Decision Support Sys-\ntems (cdsss), Diagnostic Decision Support Systems\n(ddsss), and Intelligent diagnosis systems (idss)\nwhich apply ai techniques (e.g., Machine Learning -\n1Available\nat\nhttps://www.who.int/news-room/fact-sheets/\ndetail/dementia, May 2024.\nml, nlp, etc.) to analyze patient medical data (i.e.,\nclinical records, imaging data, lab results, etc.) and\ndiscover relevant patterns effectively and efficiently,\nhave significantly attracted the attention of the med-\nical and research community [18]. However, one of\nthe main disadvantages of traditional approaches is\ntheir lack of semantic knowledge management and\nexplicability capabilities [17]. The latter can be espe-\ncially problematic in the medical domain regarding\naccountability of the decision process for the physi-\ncians to recommend personalized treatments [14].\nIntegrating ai-based systems in conversational\nassistants to provide economical, flexible, immediate,\nand personalized health support is particularly rele-\nvant [19]. Their use has been greatly enhanced by the\nnowadays popular Large Language Models (llms),\nenabling dynamic dialogues compared to previous\ndevelopments [20]. Subsequently, llms have been\npowered by the latest advancements in deep learn-\ning techniques and the availability of vast amounts of\ncross-disciplinary data [21]. These models represent\nthe most innovative approach of ai into healthcare\nby expediting medical interventions and providing\nnew markers and therapeutic approaches to neurolog-\nical diagnosis from patient narrative processing [22].\nNote that patient experience can also be improved\nwith the help of llms in terms of information\nand support seeking [23]. Summing up, conversation\nassistants that leverage llms have the potential to\nmonitor high-risk populations and provide personal-\nized advice, apart from offering companion [19, 24]\nconstituting the future of therapy in the literature\n[25].\nGiven the still poor accuracy of cdsss [26, 27],\nwe plan to leverage an llm using the latest nlp\ntechniques in a chatbot solution to provide inter-\npretable ml prediction of cognitive decline in real-\ntime. Linguistic-conceptual features are exploited for\nappropriate natural language analysis. The main\nlimitation of llms is that their outcomes may be\nmisleading. Thus, we apply prompt engineering to\navoid the “hallucination” effect. Through explainabil-\nity, we aim to fight potential biases of the models\nand improve their potential to help clinical workers in\ntheir diagnosis decisions. Summing up, we contribute\nwith an affordable, non-invasive diagnostic system in\nthis work.\nThe rest of this paper is organized as follows.\nSection 2 reviews the relevant competing works on\ncognitive decline detection involving llms and inter-\npretable ml predictions of mental deterioration. The\ncontribution of this work is summarized in Section\n2.1. Section 3 explains the proposed solution, while\nSection 4 describes the experimental data set, our\nimplementations, and the results obtained. Finally,\nSection 5 concludes the paper and proposes future\nresearch.\n2\nProblem. The World Health Organization predicts\na yearly increase of 10 million people affected with\ndementia.\nWhat is already known. Paper-and-pencil cogni-\ntive tests continue to be the most common approach.\nThe latter is impractical, given the disease growth\nrate. Moreover, one of the main disadvantages of\nintelligent approaches is their lack of semantic knowl-\nedge management and explicability capabilities.\nWhat this paper adds. We leverage an llm using\nthe latest nlp techniques in a chatbot solution to pro-\nvide interpretable ml prediction of cognitive decline\nin real-time. To sum up, we contribute with an afford-\nable, flexible, non-invasive, personalized diagnostic\nsystem to this work.\n2 Related work\nAs previously mentioned, the main focus of demen-\ntia treatment is to delay the cognitive deteriora-\ntion of patients [17]. Consequently, early diagnosis,\nwhich simultaneously contributes to reducing medical\nexpenses in our aging society and avoiding invasive\ntreatments with subsequent side effects on the users,\nis desirable [6]. To this end, ai has been successfully\napplied to idss in order to recommend treatments\nbased on their diagnosis prediction [28, 29].\nWhile ml models perform well and fast in diag-\nnosis tasks, they require extensive training data pre-\nviously analyzed by experts, which is labor-intensive\nand time-consuming [17]. In contrast, advanced nlp-\nbased solutions exploit transformer-based models\nalready trained with large corpora, including domain-\nrelated data, which results in very sensitive text\nanalysis capabilities [30]. Consequently, transformer-\nbased pre-trained language models (plms) (e.g., bert\n[31], gpt-3 [32]) which preceded the popular llms\n(e.g., gpt-42) have disruptively transformed the\nnlp research. These models exhibit great contex-\ntual latent feature extraction abilities from textual\ninput [30]. The latter models are implemented to pre-\ndict the next token based on massive training data,\nresulting in a word-by-word outcome [33]. Nowadays,\nthey are used for various tasks, including problem-\nsolving, question-answering, sentiment analysis, text\nclassification, and generation, etc. [34].\nThere exist plm versions over biomedical and clin-\nical data such as Biobert [35], Biogpt [36], Bluebert\n[37], Clinicalbert3 and tcm-bert [38]. Open-domain\nconversational assistants, whose dialogue capabili-\nties are not restricted to the conversation topic,\nexploit llms [19]. However, using llms for cogni-\ntive decline diagnosis is still scarce even though these\n2Available at https://platform.openai.com/docs/models/gpt-4,\nMay 2024.\n3Available\nat\nhttps://github.com/EmilyAlsentzer/\nclinicalBERT, May 2024.\nmodels represent the most advanced way for clinical-\npatient communication using intelligent systems [39].\nMore in detail, they overcome the limitation of tra-\nditional approaches that lack semantic reasoning,\nespecially relevant in clinical language [40]. Unfor-\ntunately, despite the significant advancement they\nrepresent, llms still exhibit certain limitations in\nopen-domain task-oriented dialogues (e.g., medical\nuse cases) [41]. For the latter, the Reinforcement\nLearning from Human Feedback (rlhf, i.e., prompt\nengineering) technique is applied to enhance their\nperformance based on end users’ instructions and\npreferences [42].\nRegarding the application of plm to the med-\nical field, Syed et al [3] performed two tasks: (i)\ndementia prediction and (ii) mmse score estimation\nfrom speech recordings combining acoustic features\nand text embeddings obtained with the bert model\nfrom their transcription. The input data correspond\nto cognitive tests (cts). Yuan et al [12] analyzed\ndisfluencies (i.e., uh/um word frequency and speech\npauses) with bert and ernie modes based on data\nfrom the Cookie Theft picture from the Boston Diag-\nnostic Aphasia Exam. Close to the work by Syed\net al [3], Chen et al [15] analyzed the performance\nof bert model to extract embeddings in cognitive\nimpairment detection from speech gathered during\ncts. Santander-Cruz et al [17] combined the Siamese\nbert networks (sberts) with ml classifiers to firstly\nextract the sentence embeddings and then predict\nAlzheimer’s disease from ct data. In contrast, Vats\net al [1] performed dementia detection combining ml,\nthe bert model, and acoustic features to achieve\nimproved performance. Moreover, Li et al [16] com-\npared gpt-2 with its artificially degraded version\n(gpt-d) created with a dementia-related linguistic\nanomalies layer induction based on data from a pic-\nture description task, while Agbavor and Liang [14]\npredicted dementia and cognitive score from ct data\nusing gpt-3 exploiting both word embeddings and\nacoustic knowledge. Finally, Mao et al [2] pre-trained\nthe bert model with unstructured clinical notes from\nElectronic Health Records (ehrs) to detect mci to ad\nprogression.\nMore closely related to our research is the work by\nBertacchini et al [13]. The authors designed Pepper, a\nsocial robot with real-time conversational capabilities\nexploiting the Chatgpt gpt-3.5 model. However, the\nuse case of the system is Autism Spectrum Disorder\ndetection. Furthermore, Caruccio et al [18] com-\npared the diagnoses performance of different models\nof Chatgpt (i.e., ada, babbage, curie, davinci\nand gpt-3.5) with Google Bard and traditional ml\napproaches based on symptomatic data. The authors\nexploited prompt engineering to ensure appropriate\nperformance when submitting clinical-related ques-\ntions to the llm model. Moreover, Hirosawa et al\n3\n[39] analyzed the diagnosis ability of Chatgpt gpt-\n3.5 model using clinical vignettes. Then, the llm\nwas evaluated compared to physicians’ diagnosis.\nHowever, the authors again focus not on cognitive\ndecline prediction but on ten common chief com-\nplaints. Consideration should be given to the work\nby Koga et al [30], who used Chatgpt (i.e., gpt-\n3.5 and gpt-4 models) and Google Bard to predict\nseveral neurodegenerative disorders based on clinical\nsummaries in clinicopathological conferences without\nbeing a specific solution tailored for ad prediction.\nFinally, regarding conversational assistants that inte-\ngrate llms, Zaman et al [43] developed a chatbot\nbased on Chatgpt gpt-3.5 model to provide emo-\ntional support to caregivers (i.e., practical tips and\nshared experiences).\n2.1 Contributions\nAs previously described, a vast amount of work in\nthe state of the art exploits plms even in the clinical\nfield [44]. However, scant research has been performed\nin the case of llm models. Table 1 summarizes the\nreviewed diagnostic solutions that exploit llms in the\nliterature. Note that explainability represents a dif-\nferential characteristic of the solution proposed given\nthe relevance of promoting transparency in ai-based\nsystems [45].\nGiven the comparison with competing works:\n• Our system is the first that jointly considers the\napplication of an llm over spontaneous speech and\nprovides interpretable ml results for the use case\nof mental decline prediction.\n• Our solution implements ml models in streaming\nto provide real-time functioning, hence avoiding the\nre-training cost of batch systems.\n• In this work, we leverage the potential of llms by\napplying the rlhf technique through prompt engi-\nneering in a chatbot solution. Note that the natural\nlanguage analysis is performed with linguistic-\nconceptual features. Consequently, we contribute\nwith an affordable, non-invasive diagnostic system.\n• Our system democratizes access to researchers and\nend users within the public health field to the latest\nadvances in nlp.\n3 Methodology\nFigure 1 depicts the system scheme proposed for real-\ntime prediction of mental decline combining llms\nand ml algorithms with explainability capabilities.\nMore in detail, it is composed of (i) data extraction\nemploying nlp-based prompt engineering (Section\n3.1); (ii) stream-based data processing including fea-\nture engineering, analysis and selection (Section 3.2);\n(iii) real-time classification (Section 3.3); and (iv) the\nexplainability dashboard to provide visual and nat-\nural language descriptions of the prediction outcome\n(Section 3.4). Algorithm 1 describes the complete\nprocess.\n3.1 Data extraction\nThe Chatgpt gpt-3.5 model used serves two pur-\nposes: (i) it enables a natural, free dialogue with\nthe end users, and (ii) data is extracted due to its\nsemantic knowledge management capabilities. The\nlatter information is gathered once the conversation\nis concluded (either more than 3 minutes of inactiv-\nity or farewell detected) and used to compute the\nfeatures used for classification (see Section 3.2.1).\nFor this extraction, prompt engineering is exploited.\nThe complete data extraction process is described in\nAlgorithm 2.\n3.2 Stream-based data processing\nStream-based data processing encompasses feature\nengineering, analysis, and selection tasks to ensure\nthe optimal performance of the ml classifiers.\n3.2.1 Feature engineering\nTable 2 details the features used to predict men-\ntal decline. Note that conversational, emotional, and\nlinguistic-conceptual features are computed. The con-\nversational features4 (1-10) represent relevant seman-\ntic and pragmatic information related to the free\ndialogue (e.g., fluency, repetitiveness, etc.), while\nemotional features focus on the mental and physical\nstate of the users. Finally, linguistic features represent\nlexical and semantic knowledge (e.g., disfluencies,\nplaceholder words, etc.).\nFurthermore, the system maintains a history of\neach user data (i.e., past and current feature values)\nthat enables the computation of four new character-\nistics per each in Table 2: average, q1, q2, and q3 as\nindicated in Equation (1), where n is the user con-\nversation counter and X[n] represents a particular\nfeature with historical data.\n4Features 9-10 are not computed using the llm.\n4\nTable 1: Comparison of diagnostic llm-based solutions taking into account the field of application, the model\nused, the input data, and explainability (Ex.) capability.\nAuthorship\nApplication\nLLM\nInput data\nEx.\nCaruccio et al [18]\nGeneral diagnosis\nChatgpt\nSymptomatic data\n✗\nGoogle Bard\nml\nHirosawa et al [39]\nCommon complaints\nChatgpt\nClinical vignettes\n✗\nKoga et al [30]\nNeurodegenerative disorders\nChatgpt\nClinical summaries\n✗\nGoogle Bard\nProposal\nMental decline\nChatgpt + ml\nSpontaneous speech\n✓\nFig. 1: System scheme.\nAlgorithm 1 Methodology\nscenario, model name, selector mode, selector threshold\n%Configuration parameters defined by the user\ncount = 0\nlist y, list y pred, list sessions = []\ninput(session)\n%A new dialogue session enters the system\nwhile session! = null do\nlist sessions.append(session)\nlist features = data extraction(session)\nlist features selected = data processing(list sessions, list features, selector mode, selector threshold)\nlist y.append(session.y)\ny pred = classification(list features selected, scenario, model name, count, list y)\nlist y pred.append(y pred)\ncount = count + 1\ninput(session)\nend while\n5\nAlgorithm 2 Data extraction\nfunction data extraction(session)\nlist human interactions = [] %To save only the human interactions, excluding those made by the chatbot\ncomplete human dialogue = “”\nfor item in session do\nif item.type() == “human” then\nlist human intereactions.append(item)\ncomplete human dialogue = complete human dialogue.concat(item)\nend if\nend for\nfeature 9 = len(list human intereactions)\n%See Table 2\nfeature 10 = len(complete human dialogue.split())\nrest features = prompt data extraction()\n%See Listing 1\nreturn(feature 9, feature 10, rest features)\nend function\nTable 2: Features engineered for mental deterioration prediction.\nCategory\nID\nName\nDescription\nConversational\n1\nAmnesia\nShowing difficulty in recalling past data.\n2\nIncoherence\nUse of inconsistent responses.\n3\nIncomprehension\nInability to understand certain aspects.\n4\nConfusion\nShowing uncertainty about what is discussed.\n5\nFluency\nUse of smooth quality utterances.\n6\nInitiative\nWillingness to engage in the dialogue even posing questions.\n7\nRepetitiveness\nUse of repetitive utterances that affect the conversation flow.\n8\nSecretive\nInclined to hide feelings and personal information.\n9\nInteractions\nTotal number of bot-human interaction pairs in the dialogue.\n10\nWords\nTotal number of words in the dialogue.\nEmotional\n11\nHealth state\nAbsence/presence of mental or physical health concerns.\n12\nFatigue\nSense of tiredness.\n13\nLoneliness\nSense of abandonment.\n14\nPolarity\nProviding negative, neutral or positive information.\n15\nSadness\nSense of depression.\nLinguistic\n16\nColloquial registry\nUsing a casual and simple language registry.\n17\nConjugation problems\nInability to correctly conjugate verb tenses.\n18\nDisfluency\nUse of interjections to complete pauses.\n19\nFormal registry\nExhibiting a well-mannered language registry.\n20\nPlaceholder words\nUse of auxiliary words instead of a more precise one.\n21\nSesquipedalian words\nEmploying ceremonial, long, uncommon words.\n22\nShort response\nProviding quick answers.\n∀n ∈{1...∞}\nX[n] = {x[0], . . . , x[n]}.\nY [n] = {y0[n], y1[n], . . . , yn−1[n]} |\ny0[n] ≤y1[n] ≤. . . ≤yn−1[n],\nwhere; ∀x ∈X[n], x ∈Y [n].\navgn[n] = 1\nn\nn\nX\ni=0\nyi[n]\nQn\n1[n] = y⌊1\n4 n⌉[n]\nQn\n2[n] = y⌊2\n4 n⌉[n]\nQn\n3[n] = y⌊3\n4 n⌉[n]\n(1)\n3.2.2 Feature analysis & selection\nFeature analysis and selection tasks are necessary to\noptimize the performance of the ml classifiers. These\ntasks are even more important in the streaming sce-\nnario where samples arrive at a real-time pace. The\nlatter means that the classification problem layout\n(e.g., the most relevant features) may vary over time.\nThe proposed system follows two thresholding\nstrategies for feature analysis and selection based\non cut-off points regarding correlation and variance\nvalues to remove irrelevant features. The former, cor-\nrelation analysis, limits the number of features to\nextract the most relevant characteristics. For the lat-\nter variance analysis, the number of features selected\nis dynamically established in each interaction of the\nstream-based model, selecting those that meet the\nthreshold criteria.\nAlgorithm 3 details the data processing stage,\nincluding feature engineering, analysis, and selection.\n6\nAlgorithm 3 Data processing\nfunction data processing(list sessions, list features, selector mode, selector threshold)\nfor feature in list features do\nlist features.append(avg(list sessions[feature]))\nlist features.append(Q1(list sessions[feature]))\nlist features.append(Q2(list sessions[feature]))\nlist features.append(Q3(list sessions[feature]))\nend for\nlist features selected = []\nfor feature in list features do\nif selector mode == “variance” and varizance(feature) > selector threshold then\nlist features selected.append(feature)\nelse if selector mode == “correlation” and correlation(feature) > selector threshold then\nlist features selected.append(feature)\nend if\nend for\nreturn list features selected\nend function\n3.3 Stream-based classification\nTwo classification scenarios are considered:\nScenario 1 analyzes the behavior of the classifiers in\na streaming setting. Under this consideration, sequen-\ntial and continual testing and training over time is\nassumed.\nScenario 2 analyzes the models’ performance under\nmore realistic conditions. Thus, the testing is contin-\nuous (i.e., in streaming) while training is performed\ndesynchronized in blocks of 100 samples.\nThe following ml models are selected based on\ntheir good performance in similar classification prob-\nlems [46, 47, 48]:\n• Gaussian Naive Bayes (gnb) [49] exploits the\nGaussian probability distribution in a stream-based\nml model. It is used as a reference for performance\nanalysis.\n• Approximate\nLarge\nMargin\nAlgorithm\n(alma) [50] is a fast incremental learning algo-\nrithm comparable to Support Vector Machine\nto approximate the maximal margin between a\nhyperplane concerning a norm (with a value of\np ≥2) for a set of linearly separable data.\n• Hoeffding Adaptive Tree Classifier (hatc)\n[51] computes single-tree branch performance and\nis designed for stream-based prediction.\n• Adaptive Random Forest Classifier (arfc)\n[52] constitutes an advanced model of hatc in\nwhich branch performance is computed by majority\nvoting in an ensemble tree scenario.\nAlgorithm 4 describes the stream-based prediction\nprocess.\n3.4 Explainability dashboard\nPrediction transparency is promoted through explain-\nability data provided to the end users regarding\nrelevant features in the prediction outcome. Thus,\nthose relevant features are included in the natural\nlanguage description of the decision path. The five\nfeatures whose mathematical module is highest or\nwith the highest variance and whose values are the\nmost distant from the average are selected. In the\ncase of the counters (features 9-10), this average is\nobtained from the average of all users in the system.\n4 Evaluation and discussion\nThis section discusses the experimental data set\nused, the implementation decisions, and the results\nobtained. The evaluations were conducted on a com-\nputer with the following specifications:\n• Operating System: Ubuntu 18.04.2 LTS 64 bits\n• Processor: IntelCore i9-10900K 2.80 GHz\n• RAM: 96 GB DDR4\n• Disk: 480 GB NVME + 500 GB SSD\n4.1 Experimental data set\nThe experimental data set5 consists of an average\nof 6.92 ± 3.08 utterances with 62.73 ± 57.20 words\ninvolving 44 users with 13.66 ± 7.86 conversations by\nuser. The distribution of mental deterioration in the\nexperimental data set is 238 samples in which mental\ndeterioration is present and 363 in which it is absent.\nFigure 2 depicts the histogram distribution of words\nand interactions by absent and present mental dete-\nrioration, respectively. While the distributions of the\nnumber of interactions in the absence or presence of\n5Data are available on request from the authors.\n7\nAlgorithm 4 Classification\nfunction classification(list features selected, scenario, model name, count, list y)\ny pred = machine learning model(model name, list features selected).predict()\nif scenario == 1 then\nmachine learning model(model name, list features selected).train(list y[last])\nelse if count%100 == 0 then\nmachine learning model(model name, list features selected).train(list y[−100 : last])\nend if\nreturn y pred\nend function\ncognitive impairment follow a normal function, the\nnumber of words can be approximated by a posi-\ntive normal centered on 0. The most relevant issue\nis that, as expected, users with mental deterioration\npresent a lower number of interactions and a signif-\nicant decrease in the number of words used in their\nresponses.\n4.2 Data extraction\nData to engineer conversational (1-8), emotional, and\nlinguistic features in Table 2 were obtained with\ngpt-3.5-turbo6 model. The prompt used is shown\nin Listing 1.\n4.3 Stream-based data processing\nThis section reports the algorithms used for fea-\nture engineering, analysis, and selection and their\nevaluation results.\n4.3.1 Feature engineering\nA total of 88 features were generated7 in addition to\nthe 22 features generated in each conversation (see\nTable 2) resulting in 110 features. In Figure 3, we\nshow the distribution of conversations by the user,\nwhich approaches a uniform density function, being\nrelevant that the large majority concentrates between\n15 and 20 conversations.\n4.3.2 Feature analysis & selection\nCorrelation and variance thresholding decisions were\nbased on experimental tests. For the correlation\nthresholding, SelectKBest8 was applied using the\nPearson correlation coefficient [53]. The K value cor-\nresponds to the most relevant features of the 80 %\nexperimental data. Table 3 shows the features with\na correlation value greater than 0.2 with the mental\ndeterioration target when the last sample entered the\nstream-based classification model.\n6Available\nat\nhttps://platform.openai.com/docs/models/\ngpt-3-5, May 2024.\n7New four characteristics (average, q1, q2, and q3) per each of\nthe 22 features in Table 2.\n8Available at https://riverml.xyz/0.11.1/api/feature-selection/\nSelectKBest, May 2024.\nRegarding the variance thresholding, the imple-\nmentation used was VarianceThreshold9 from the\nRiver library10. Moreover, the cut-off point, 0.001,\nis computed with the 10th percentile variance value\nof the features contained in the 20 % of the exper-\nimental data set, which acts as the cold start of\nthis method. Consequently, only those features that\nexceed the abovementioned cut-off are selected as rel-\nevant for classification purposes. Table 3 also details\nthe features with a variance greater than 0.511.\nTable 3 shows that among the conversational fea-\ntures, user initiative (feature 6 in Table 2) plays an\nimportant role. The same applies to the number of\ninteractions within a dialogue (feature 9). Regarding\nemotional features, consideration should be given to\nfatigue (feature 12) and polarity (feature 14). Finally,\nusing a colloquial/formal registry (features 16/19),\ndisfluency (feature 18), and short responses (fea-\nture 22) stand out among linguistic characteristics.\nConsidering correlation and variance analysis jointly,\ninitiative and polarity are the most relevant data for\nprediction purposes.\n4.4 Stream-based classification\nThe River implementations of the ml models selected\nare: gnb12, alma13, hatc14 and arfc15. Listings 2, 3\nand 4 detail the hyper-parameter optimization ranges\nused, excluding the baseline model, from which the\nfollowing values were selected as optimal:\nCorrelation thresholding\n• ALMA: alpha=0.5, B=1.0, C=1.0.\n• HATC:\ndepth=None,\ntiethreshold=0.5,\nmax-\nsize=50.\n9Available at https://riverml.xyz/0.11.1/api/feature-selection/\nVarianceThreshold, May 2024.\n10Available at https://riverml.xyz/0.11.1, May 2024.\n11Note that we have discarded features 9 and 10 from Table 2\nfrom this example since they represent counters and their variance\nis always greater than 1.\n12Available\nat\nhttps://riverml.xyz/dev/api/naive-bayes/\nGaussianNB, May 2024.\n13Available\nat\nhttps://riverml.xyz/0.11.1/api/linear-model/\nALMAClassifier, May 2024.\n14Available\nat\nhttps://riverml.xyz/0.11.1/api/tree/\nHoeffdingAdaptiveTreeClassifier, May 2024.\n15Available\nat\nhttps://riverml.xyz/0.11.1/api/ensemble/\nAdaptiveRandomForestClassifier, May 2024.\n8\n(a) Without mental deterioration.\n(b) With mental deterioration.\nFig. 2: Distribution of interactions and number of words.\n• ARFC: models=10,features=5, lambda=50.\nVariance thresholding\n• ALMA: alpha=0.5, B=1.0, C=1.0.\n• HATC:\ndepth=None,\ntiethreshold=0.5,\nmax-\nsize=50.\n• ARFC: models=100,features=sqrt, lambda=50.\nListing 2: alma hyper-parameter configuration.\nalpha = [ 0 . 5 , 0 . 7 , 0 . 9 ]\nB = [ 1 . 0 ,\n1.41 ,\n1 . 2 ]\nC = [ 1 . 0 , 1 . 1 1 ,\n1 . 2 ]\nListing 3: hatc hyper-parameter configuration.\ndepth = [ None ,\n50 ,\n200]\nt i e t h r e s h o l d = [ 0 . 5 ,\n0.05 ,\n0.005]\n9\nListing 1: Prompt used for data extraction.\nThis\ni s\na conversation\nbetween a bot and a human .\nAnswer what I\nask below with a\nvalue between\n0.0 and 1.0 ,\nbeing\n0.0\nnever and 1.0\nalways .\nDetect\ni f\nthe human :\nhas any memory loss ,\ni s\nincoherent ,\ne x h i b i t s\ncomprehension\nproblems ,\ni s\nconfused ,\nfluent ,\nshows\ni n i t i a t i v e ,\nuses\nr e p e t i t i v e\nlanguage ,\nhides\nf e e l i n g s\nand personal\ninformation ,\nexpresses\nmental or\nphysical\nhealth\nconcerns ,\ni s\ntired ,\nf e e l s\nlonely ,\nthe\np o l a r i t y\nof\nthe\nconversation ,\nseems sad ,\ni n t e r a c t s\nwith a\nc o l l o q u i a l\nregistry ,\nhas\nconjugation\nproblems ,\nuses\ni n t e r j e c t i o n s\nto\ncomplete pauses ,\ni n t e r a c t s\nwith a formal\nregistry ,\nuses\nplaceholder\nwords ,\nsesquipedalian\nterms ,\nand short\nresponses .\nRespond only\nin\nthe\nfollowing JSON format :\n{“Amnesia ” : 0 . 0 , “Incoherence” : 0 . 0 , “Incomprehension” : 0 . 0 , “Confusion” : 0 . 0 , “Fluency” : 0 . 0 ,\n“Initiative” : 0 . 0 , “Repetitiveness” : 0 . 0 , “Secretive” : 0 . 0 , “Health state” : 0 . 0 , “Fatigue” : 0 . 0 ,\n“Loneliness” : 0 . 0 , “Polarity” : 0 . 0 , “Sadness” : 0 . 0 , “Colloquial registry” : 0 . 0 ,\n“Conjugation problems” : 0 . 0 , “Disfluency” : 0 . 0 , “Formal registry” : 0 . 0 , “Placeholder words” : 0 . 0 ,\n“Sesquipedalian words” : 0 . 0 , “Short response” : 0 . 0 } .\nALWAYS RETURN A JSON IN THE GIVEN FORMAT WITHOUT ADDING MORE TEXT OR MODIFYING\nTHE FIELD NAMES IN THE JSON. DO NOT ANSWER ANY QUESTIONS IN THE CONVERSATION.\n<Dialogue>\nFig. 3: Distribution of conversations by user.\nmaxsize = [50 ,\n100 ,\n200]\nListing 4: arfc hyper-parameter configuration.\nmodels = [10 ,\n25 ,\n100]\nf e a t u r e s = [ sqrt ,\n5 ,\n50]\nlambda = [25 ,\n50 ,\n100]\nTable 4 presents the results for evaluation sce-\nnarios 1 and 2. In both scenarios, the feature selec-\ntion methodology based on correlation thresholding\nreturns lower classification metric values than those\nobtained with the variance method. Thus, once the\nvariance feature selection method is applied, the\narfc is the most promising performance algorithm\nregardless of the evaluation scenario.\nConsideration should be given to the fact that\neven in scenario 2, in which training is performed\ndesynchronized and in batch, the robustness of arfc\nstands out with classification results exceeding 80 %\nand with a recall for the mental deterioration class\nabout 85 %.\n10\nTable 3: Correlation and variance results.\nFeature\nStatistic metric\nValue\nCorrelation\n22\nAverage\n0.296\n9\nQ1\n0.292\nQ2\n0.248\nAverage\n0.219\n19\nAverage\n-0.203\n18\nQ3\n-0.213\n14\nQ1\n-0.226\n12\nAverage\n-0.238\n14\nQ3\n-0.272\nAverage\n-0.278\nQ2\n-0.318\n6\nAverage\n-0.391\nQ3\n-0.458\nVariance\n16\nQ1\n0.171\nOriginal\n0.165\n6\nOriginal\n0.11\n16\nQ2\n0.086\n14\nOriginal\n0.084\n6\nQ3\n0.079\n14\nQ3\n0.055\nTable 4: Classification results (Sce.: scenario, time in seconds).\nSce.\nSelection\nModel\nAcc.\nPrecision\nRecall\nTime\nMacro\nPresent\nAbsent\nMacro\nPresent\nAbsent\n1\nCorrelation\ngnb\n63.11\n68.57\n52.13\n85.00\n67.24\n87.39\n47.09\n0.76\nalma\n67.67\n66.20\n59.32\n73.08\n66.15\n58.82\n73.48\n0.63\nhatc\n63.27\n64.65\n52.69\n76.60\n65.09\n73.95\n56.23\n0.98\narfc\n72.29\n74.23\n60.53\n87.94\n74.79\n86.97\n62.60\n1.57\nVariance\ngnb\n61.94\n59.48\n56.10\n62.86\n54.68\n19.33\n90.03\n0.31\nalma\n67.33\n65.88\n58.82\n72.93\n65.88\n58.82\n72.93\n0.20\nhatc\n69.78\n68.98\n60.52\n77.44\n69.63\n68.91\n70.36\n0.54\narfc\n89.15\n88.47\n83.92\n93.02\n89.28\n89.92\n88.64\n17.72\n2\nCorrelation\ngnb\n58.60\n66.76\n48.85\n84.66\n63.86\n89.50\n38.23\n0.74\nalma\n63.67\n61.40\n55.32\n67.48\n60.25\n43.70\n76.80\n0.62\nhatc\n58.10\n55.80\n47.06\n64.55\n55.64\n43.70\n67.59\n0.94\narfc\n63.27\n65.44\n52.57\n78.31\n65.66\n77.31\n54.02\n1.42\nVariance\ngnb\n62.10\n59.86\n56.79\n62.93\n54.82\n19.33\n90.30\n0.31\nalma\n63.33\n60.89\n56.00\n65.78\n58.53\n35.29\n81.77\n0.20\nhatc\n65.94\n65.57\n55.90\n75.24\n66.23\n67.65\n64.82\n0.49\narfc\n84.81\n84.04\n78.38\n89.71\n84.89\n85.29\n84.49\n15.50\nProvided that our system operates in stream-\ning and to enable direct comparison with batch ml\nsolutions, additional evaluation measures from 10-\nfold cross-validation are provided, particularly, for\nRandom Forest (rf16) equivalent to the best model,\n16Available\nat\nhttps://scikit-learn.org/stable/modules/\ngenerated/sklearn.ensemble.RandomForestClassifier.html,\nMay\n2024.\narfc, in stream-based classification. The results are\ndisplayed in Table 5, most surpassing the 90 % thresh-\nold. Note that the increase in performance compared\nto streaming operation (e.g., +8.37 % points in accu-\nracy) is derived from the fact that in batch classifica-\ntion, the model has access to the 90 % of the exper-\nimental data for training. In contrast, stream-based\n11\nFig. 4: Explainability dashboard.\nclassification relies on the ordered incoming new sam-\nples, which is more demanding. Consequently, having\nachieved a comparable performance in batch and\nstream-based classification is noteworthy.\nTo verify the system’s operation in a more chal-\nlenging scenario, we have experimented with a data\nset from a previous study [54] with fewer interactions\nper session. Even when the system is fed with less\ninformation, the evaluation metrics are promising, as\nshown in Table 6 with all values above 70 %, and the\nprecision and recall of the mental deterioration cate-\ngory above 80 %. Comparing the rf batch model in\nour past research [54] with the proposed arfc algo-\nrithm, which operates in streaming, the improvement\nreaches 10 % points and 4 % points in the recall met-\nric of mental deterioration and absence of mental\ndeterioration categories, respectively.\n4.5 Explainability dashboard\nFigure 4 shows the explainability dashboard. In this\nexample, the variation in predicting cognitive impair-\nment is visualized, considering two weeks of past data.\nThis variation is represented with the predict proba\nfunction of arfc algorithm. At the bottom, the most\nrelevant features are displayed. Each figure card con-\ntains the identifier and statistic represented in colors\nfollowing this scheme: 1 to 0.5 in green, 0.5 to 0.25\nin yellow, and 0.25 to 0 in red. The latter assigna-\ntion is inverted for negative values. At the bottom,\na brief description in natural language is provided.\nThe average accumulated predict proba value, and\nthe confidence prediction of the current sample are\ndisplayed on the right.\n5 Conclusions\nCognitively impaired users find it difficult to per-\nform daily tasks with the consequent detrimental\nimpact on their life quality. Thus, progression detec-\ntion and early intervention are essential to effectively\nand timely address mental deterioration to delay\nits progress. In this work, we focused on impair-\nment in language production (i.e., lexical, seman-\ntic, and pragmatic aspects) to engineer linguistic-\nconceptual features towards spontaneous speech anal-\nysis (e.g., semantic comprehension problems, memory\nloss episodes, etc.). Compared to traditional diagnos-\ntic approaches, the proposed solution has semantic\nknowledge management and explicability capabilities\nthanks to integrating an llm in a conversational\nassistant.\nConsideration should be given to the limitations\nof using llms, which are transversal into the health-\ncare field beyond mental deterioration detection. The\npotential biases and lack of inherent transparency\nstand out among the risks of applying these models\nfor medical purposes. The latter black-box problem,\nalso present in traditional opaque ml models, is par-\nticularly critical in the healthcare field by negatively\nimpacting the decision process of physicians due to\ntheir limited corrective capabilities and even the end\nusers, limiting their trust in medical applications.\nMoreover, these systems’ current limited memory\n12\nTable 5: Classification results in batch for the rf model (time in seconds).\nAcc.\nPrecision\nRecall\nTime\nMacro\nPresent\nAbsent\nMacro\nPresent\nAbsent\n93.18\n93.15\n93.01\n93.28\n92.54\n89.50\n95.59\n1.96\nTable 6: Classification results for the arfc model using the experimental data from [54] (time in seconds).\nAcc.\nPrecision\nRecall\nTime\nMacro\nPresent\nAbsent\nMacro\nPresent\nAbsent\n77.70\n76.62\n81.32\n71.93\n76.46\n82.22\n70.69\n4.72\nmanagement capability is worth mentioning, which\nprevents the realization of longitudinal clinical anal-\nysis. The same applies to the associated complexity\nof context information management. Ultimately, the\ndifficulty in collecting data due to the sensitivity and\nconfidentiality of the information in the medical field\nshould also be mentioned.\nMore in detail, the solution provides interpretable\nml prediction of cognitive decline in real-time. rlhf\n(i.e., prompt engineering) and explainability are\nexploited to avoid the “hallucination” effect of llms\nand avoid potential biases by providing natural lan-\nguage and visual descriptions of the diagnosis deci-\nsions. Note that our system implements ml models\nin streaming to provide real-time functioning, hence\navoiding the re-training cost of batch systems.\nSumming up, we contribute with an affordable,\nflexible, non-invasive, personalized diagnostic system\nthat enables the monitoring of high-risk populations\nand offers companionship. Ultimately, our solution\ndemocratizes access to researchers and end users\nwithin the public health field to the latest advances\nin nlp.\nAmong the challenges and potential ethical con-\ncerns raised by the application of ai into the health-\ncare field, the double effect principle must be con-\nsidered. In this sense, few can deny its promising\npotential to provide innovative treatments while at\nthe same time presenting safety-critical concerns,\nnotably regarding their interpretability. Apart from\nthe algorithmic transparency mentioned, the main\nconsiderations are privacy and safety of the medi-\ncal data, fairness, and autonomous decision-making\nwithout human intervention. In future work, we plan\nto test the performance of new approaches, such\nas reinforcement learning, to enhance the system’s\npersonalizing capabilities further. Moreover, we will\nexplore co-design practices with end users, and we\nseek to move our solution to clinical practice within\nan ongoing project with daycare facilities. Note that\nreinforcement learning with human feedback will also\nallow us to mitigate some of the limitations discussed,\nsuch as physicians’ lack of interpretability and correc-\ntive capabilities. The latter will also have a positive\nethical impact on the deployment of llm-based med-\nical applications by ensuring fairness. The societal\nimpact derived from reduced costs compared to tradi-\ntional approaches may result in broader accessibility\nto clinical diagnosis and treatment on a demand basis.\nThe equity will be impulsed by the capability of these\nsystems to provide unlimited personalized support.\nIn future research, we will work on mitigating health\ninequities by performing longitudinal studies to mea-\nsure bias in our ai solution, particularly related to\nthe algorithm design, bias in the training data, and\nthe ground truth. Underperformance in certain social\ngroups may also be considered. For that purpose, we\nwill gather social context data, which will allow us to\nmeasure equity (e.g., gender, race, socioeconomic sta-\ntus, etc.). To ensure patient data protection while at\nthe same time increasing data available for research,\nfederated learning approaches will be explored.\nDeclarations\nCompeting interests\nThe authors have no competing interests to declare\nrelevant to this article’s content.\nFunding\nThis work was partially supported by (i) Xunta\nde Galicia grants ED481B-2022-093 and ED481D\n2024/014, Spain; and (ii) University of Vigo/CISUG\nfor open access charge.\nAuthors contribution\nFrancisco de Arriba-P´erez: Conceptualization,\nMethodology, Software, Validation, Formal analysis,\nInvestigation, Resources, Data Curation, Writing -\nOriginal Draft, Writing - Review & Editing, Visual-\nization, Supervision, Project administration, Funding\nacquisition. Silvia Garc´ıa-M´endez: Conceptual-\nization, Methodology, Software, Validation, Formal\n13\nanalysis, Investigation, Resources, Data Curation,\nWriting - Original Draft, Writing - Review & Editing,\nVisualization, Supervision, Project administration,\nFunding acquisition.\nReferences\n1. Vats NA, Yadavalli A, Gurugubelli K, et al\n(2021) Acoustic features, BERT model and their\ncomplementary nature for Alzheimer’s dementia\ndetection. In: Proceedings of the International\nConference on Contemporary Computing. Asso-\nciation for Computing Machinery, pp 267–272,\nhttps://doi.org/10.1145/3474124.3474162\n2. Mao C, Xu J, Rasmussen L, et al (2023)\nAD-BERT: Using pre-trained language model\nto predict the progression from mild cognitive\nimpairment to Alzheimer’s disease. J. Biomed.\nInform. 144:104,442–104,449. https://doi.org/10.\n1016/j.jbi.2023.104442\n3. Syed MSS, Syed ZS, Lech M, et al (2020)\nAutomated Screening for Alzheimer’s Dementia\nThrough Spontaneous Speech. In: Proceedings of\nthe Interspeech Conference. International Speech\nCommnunication\nAssociation,\npp\n2222–2226,\nhttps://doi.org/10.21437/Interspeech.2020-3158\n4. Nadira CS, Rahayu MS (2020) The relation-\nship of cognitive function and independence\nactivities of daily living (ADL) in elderly at\nPanti Darussa’adah and An-Nur Lhokseumawe.\nJ. Kedokt. dan Kesehat. Publ. Ilm. Fak. Kedokt.\nUniv. Sriwij. 7:55–60. https://doi.org/10.32539/\nJKK.V7I3.10690\n5. Association A, Thies W, Bleiler L (2023) 2023\nAlzheimer’s disease facts and figures. Alzheimer’s\nDement. 19:1598–1695. https://doi.org/10.1002/\nalz.13016\n6. Rasmussen J, Langerman H (2019) Alzheimer’s\nDisease\n–\nWhy\nWe\nNeed\nEarly\nDiagnosis.\nDegener. Neurol. Neuromuscul. Dis. 9:123–130.\nhttps://doi.org/10.2147/DNND.S228939\n7. Manly JJ, Glymour MM (2021) What the Adu-\ncanumab Approval Reveals About Alzheimer\nDisease Research. JAMA Neurol. 78:1305–1306.\nhttps://doi.org/10.1001/jamaneurol.2021.3404\n8. Kandratsenia K (2019) Social stigma towards\npeople with mental disorders among the psychi-\natrists, general practitioners and young doctors.\nEur. Neuropsychopharmacol. 29:401–402. https:\n//doi.org/10.1016/j.euroneuro.2018.11.608\n9. Tucker-Drob EM (2019) Cognitive Aging and\nDementia: A Life-Span Perspective. Annu. Rev.\nDev.\nPsychol.\n1:177–196.\nhttps://doi.org/10.\n1146/annurev-devpsych-121318-085204\n10. Pl R, Ks G (2024) Cognitive decline assessment\nusing semantic linguistic content and transformer\ndeep learning architecture. Int. J. Lang. Com-\nmun. Disord 59:1110–1127. https://doi.org/10.\n1111/1460-6984.12973\n11. Velupillai S, Suominen H, Liakata M, et al (2018)\nUsing clinical Natural Language Processing for\nhealth outcomes research: Overview and action-\nable suggestions for future advances. J. Biomed.\nInform. 88:11–19. https://doi.org/10.1016/j.jbi.\n2018.10.005\n12. Yuan J, Bian Y, Cai X, et al (2020) Disflu-\nencies and Fine-Tuning Pre-Trained Language\nModels for Detection of Alzheimer’s Disease.\nIn: Proceedings of the Interspeech Conference.\nInternational Speech Communication Associa-\ntion, pp 2162–2166, https://doi.org/10.21437/\nInterspeech.2020-2516\n13. Bertacchini F, Demarco F, Scuro C, et al\n(2023) A social robot connected with chatGPT\nto improve cognitive functioning in ASD sub-\njects. Front. Psychol. 14:1–22. https://doi.org/\n10.3389/fpsyg.2023.1232177\n14. Agbavor F, Liang H (2022) Predicting demen-\ntia from spontaneous speech using large language\nmodels. PLOS Digit. Health 1(12):1–14. https:\n//doi.org/10.1371/journal.pdig.0000168\n15. Chen J, Ye J, Tang F, et al (2021) Auto-\nmatic\nDetection\nof\nAlzheimer’s\nDisease\nUsing\nSpontaneous\nSpeech\nOnly.\nIn:\nPro-\nceedings\nof\nthe\nInterspeech\nConference,\nvol\n6.\nInternational\nSpeech\nCommunica-\ntion\nAssociation,\npp\n3830–3834,\nhttps:\n//doi.org/10.21437/Interspeech.2021-2002\n16. Li C, Knopman D, Xu W, et al (2022) GPT-D:\nInducing Dementia-related Linguistic Anomalies\nby Deliberate Degradation of Artificial Neural\nLanguage Models. In: Proceedings of the Annual\nMeeting of the Association for Computational\nLinguistic, vol 1. Association for Computational\nLinguistics, pp 1866–1877, https://doi.org/10.\n18653/v1/2022.acl-long.131\n17. Santander-Cruz Y, Salazar-Colores S, Paredes-\nGarc´ıa WJ, et al (2022) Semantic Feature Extrac-\ntion Using SBERT for Dementia Detection.\nBrain Sci. 12:270–287. https://doi.org/10.3390/\nbrainsci12020270\n14\n18. Caruccio L, Cirillo S, Polese G, et al (2023) Can\nChatGPT provide intelligent diagnoses? A com-\nparative study between predictive models and\nChatGPT to define a new medical diagnostic bot.\nExpert Syst. Appl. 235:121,186–121,199. https:\n//doi.org/10.1016/j.eswa.2023.121186\n19. S NPK, S S, N TT, et al (2023) Conversational\nChatbot Builder – Smarter Virtual Assistance\nwith Domain Specific AI. In: Proceedings of\nthe International Conference for Emerging Tech-\nnology. IEEE, pp 1–4, https://doi.org/10.1109/\nINCET57972.2023.10170114\n20. Palanica A, Flaschner P, Thommandram A, et al\n(2019) Physicians’ Perceptions of Chatbots in\nHealth Care: Cross-Sectional Web-Based Survey.\nJ. Med. Internet Res. 21:1–10. https://doi.org/\n10.2196/12887\n21. Idris MD, Feng X, Dyo V (2024) Revolutioniz-\ning Higher Education: Unleashing the Potential\nof Large Language Models for Strategic Trans-\nformation. IEEE Access 12:67,738–67,757. https:\n//doi.org/10.1109/ACCESS.2024.3400164\n22. Romano MF, Shih LC, Paschalidis IC, et al\n(2023)\nLarge\nLanguage\nModels\nin\nNeurol-\nogy\nResearch\nand\nFuture\nPractice.\nNeurol-\nogy\npp\n1–29.\nhttps://doi.org/10.1212/WNL.\n0000000000207967\n23. Fear K, Gleber C (2023) Shaping the Future of\nOlder Adult Care: ChatGPT, Advanced AI, and\nthe Transformation of Clinical Practice. JMIR\nAging 6:1–3. https://doi.org/10.2196/51776\n24. Alessa A, Al-Khalifa H (2023) Towards Design-\ning a ChatGPT Conversational Companion for\nElderly People. In: Proceedings of the Inter-\nnational Conference on Pervasive Technologies\nRelated to Assistive Environments. Association\nfor Computing Machinery, pp 667–674, https:\n//doi.org/10.1145/3594806.3596572\n25. Vaidyam AN, Wisniewski H, Halamka JD, et al\n(2019) Chatbots and Conversational Agents in\nMental Health: A Review of the Psychiatric\nLandscape. Can. J. Psychiatry 64:456–464. https:\n//doi.org/10.1177/0706743719828977\n26. Ceney A, Tolond S, Glowinski A, et al (2021)\nAccuracy of online symptom checkers and the\npotential impact on service utilisation. PLOS\nONE 16:1–16. https://doi.org/10.1371/journal.\npone.0254088\n27. Schmieding ML, Kopka M, Schmidt K, et al\n(2022) Triage Accuracy of Symptom Checker\nApps: 5-Year Follow-up Evaluation. J. Med.\nInternet Res. 24:1–13. https://doi.org/10.2196/\n31810\n28. Kili¸carslan S, K¨ozkurt C, Ba¸s S, et al (2023)\nDetection and classification of pneumonia using\nnovel Superior Exponential (SupEx) activation\nfunction in convolutional neural networks. Expert\nSyst.\nAppl.\n217:119,503–119,514.\nhttps://doi.\norg/10.1016/j.eswa.2023.119503\n29. Yu B, Chen H, Jia C, et al (2023) Multi-modality\nmulti-scale cardiovascular disease subtypes classi-\nfication using Raman image and medical history.\nExpert Syst. Appl. 224:119,965–119,976. https:\n//doi.org/10.1016/j.eswa.2023.119965\n30. Koga S, Martin NB, Dickson DW (2023) Evalu-\nating the performance of large language models:\nChatGPT and Google Bard in generating differ-\nential diagnoses in clinicopathological conferences\nof neurodegenerative disorders. Brain Pathol. pp\n1–4. https://doi.org/10.1111/bpa.13207\n31. Kenton JDMWC, Toutanova LK (2019) Bert:\nPre-training of deep bidirectional transformers\nfor language understanding. In: Proceedings of\nAnnual Conference of the North American Chap-\nter of the Association for Computational Lin-\nguistics on Human Language Technology, vol 1.\nAssociation for Computational Linguistics, pp\n4171–4186\n32. Brown TB, Mann B, Ryder N, et al (2020)\nLanguage models are few-shot learners. In: Pro-\nceedings of the Advances in Neural Information\nProcessing Systems Conference. MIT Press, pp\n1–25\n33. Deriu J, Rodrigo A, Otegi A, et al (2021) Sur-\nvey on evaluation methods for dialogue systems.\nArtif. Intell. Rev. 54:755–810. https://doi.org/10.\n1007/s10462-020-09866-x\n34. Brown T, Mann B, Ryder N, et al (2020) Lan-\nguage models are few-shot learners. Adv. neural\ninf. process. syst. 33:1877–1901\n35. Lee J, Yoon W, Kim S, et al (2020) BioBERT:\na pre-trained biomedical language representa-\ntion model for biomedical text mining. Bioinfor-\nmatics 36:1234–1240. https://doi.org/10.1093/\nbioinformatics/btz682\n36. Luo R, Sun L, Xia Y, et al (2022) BioGPT: gener-\native pre-trained transformer for biomedical text\ngeneration and mining. Brief. Bioinform. 23:1–11.\nhttps://doi.org/10.1093/bib/bbac409\n15\n37. Peng Y, Yan S, Lu Z (2019) Transfer Learn-\ning in Biomedical Natural Language Processing:\nAn Evaluation of BERT and ELMo on Ten\nBenchmarking Datasets. In: Proceedings of the\nBioNLP Workshop and Shared Task. Association\nfor Computational Linguistics, pp 58–65, https:\n//doi.org/10.18653/v1/W19-5006\n38. Yao L, Jin Z, Mao C, et al (2019) Traditional Chi-\nnese medicine clinical records classification with\nBERT and domain specific corpora. J. Am. Med.\nInform. Assoc. 26:1632–1636. https://doi.org/10.\n1093/jamia/ocz164\n39. Hirosawa T, Harada Y, Yokose M, et al (2023)\nDiagnostic\nAccuracy\nof\nDifferential-Diagnosis\nLists Generated by Generative Pretrained Trans-\nformer 3 Chatbot for Clinical Vignettes with\nCommon Chief Complaints: A Pilot Study. Int. J.\nEnviron. Res. Public Health 20:3378–3387. https:\n//doi.org/10.3390/ijerph20043378\n40. Gillioz A, Casas J, Mugellini E, et al (2020)\nOverview of the Transformer-based Models for\nNLP Tasks. In: Proceedings of the Federated\nConference on Computer Science and Infor-\nmation Systems. Polish Information Processing\nSociety, pp 179–183, https://doi.org/10.15439/\n2020F20\n41. Ji Z, Lee N, Frieske R, et al (2023) Survey\nof Hallucination in Natural Language Genera-\ntion. ACM Comput. Surv. 55:248–285. https://\ndoi.org/10.1145/3571730\n42. Chen H, Yuan K, Huang Y, et al (2023) Feedback\nis all you need: from ChatGPT to autonomous\ndriving. Sci. China Inf. Sci. 66:166,201–166,203.\nhttps://doi.org/10.1007/s11432-023-3740-x\n43. Zaman KT, Hasan WU, Li J, et al (2023)\nEmpowering\nCaregivers\nof\nAlzheimer’s\nDis-\nease and Related Dementias (ADRD) with a\nGPT-Powered Voice Assistant: Leveraging Peer\nInsights from Social Media. In: Proceedings of the\nIEEE Symposium on Computers and Communi-\ncations. IEEE, pp 1–7, https://doi.org/10.1109/\nISCC58397.2023.10218142\n44. Alomari A, Idris N, Sabri AQM, et al (2022)\nDeep reinforcement and transfer learning for\nabstractive text summarization: A review. Com-\nput. Speech Lang. 71:101,276–101,318. https://\ndoi.org/10.1016/j.csl.2021.101276\n45. Wischmeyer T (2020) Artificial Intelligence and\nTransparency: Opening the Black Box, Springer\nInternational Publishing, pp 75–101. https://doi.\norg/10.1007/978-3-030-32361-5 4\n46. Mathkunti NM, Rangaswamy S (2020) Machine\nLearning\nTechniques\nto\nIdentify\nDementia.\nSN Comput. Sci. 1:118–124. https://doi.org/10.\n1007/s42979-020-0099-4\n47. Ilias L, Askounis D (2023) Context-aware atten-\ntion\nlayers\ncoupled\nwith\noptimal\ntransport\ndomain adaptation and multimodal fusion meth-\nods for recognizing dementia from spontaneous\nspeech.\nKnowledge-based\nSyst.\n277:110,834–\n110,851.\nhttps://doi.org/10.1016/j.knosys.2023.\n110834\n48. Kumar Y, Koul A, Singla R, et al (2023) Arti-\nficial intelligence in disease diagnosis: a system-\natic literature review, synthesizing framework\nand future research agenda. J. Ambient. Intell.\nHumaniz. Comput. 14:8459–8486. https://doi.\norg/10.1007/s12652-021-03612-z\n49. Xu S (2018) Bayesian Na¨ıve Bayes classifiers to\ntext classification. J. Inf. Sci. 44:48–59. https://\ndoi.org/10.1177/0165551516677946\n50. Kang S, Kim D, Cho S (2019) Approximate train-\ning of one-class support vector machines using\nexpected margin. Comput. Ind. Eng. 130:772–\n778. https://doi.org/10.1016/j.cie.2019.03.029\n51. Weinberg AI, Last M (2023) EnHAT — Syn-\nergy of a tree-based Ensemble with Hoeffding\nAdaptive Tree for dynamic data streams mining.\nInf. Fusion 89:397–404. https://doi.org/10.1016/\nj.inffus.2022.08.026\n52. Zhang W, Bifet A, Zhang X, et al (2021) FARF:\nA Fair and Adaptive Random Forests Classifier,\nvol 12713 LNAI, Springer, pp 245–256. https://\ndoi.org/10.1007/978-3-030-75765-6 20\n53. Benesty J, Chen J, Huang Y, et al (2009) Pear-\nson Correlation Coefficient. In: Springer Topics\nin Signal Processing, vol 2. Springer, p 37–40,\nhttps://doi.org/10.1007/978-3-642-00296-0 5\n54. de Arriba-P´erez F, Garc´ıa-M´endez S, Gonz´alez-\nCasta˜no FJ, et al (2023) Automatic detection\nof cognitive impairment in elderly people using\nan entertainment chatbot with Natural Lan-\nguage Processing capabilities. J. Ambient Intell.\nHumaniz. Comput. 14:16,283–16,298. https://\ndoi.org/10.1007/s12652-022-03849-2\n16\n",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.LG"
  ],
  "published": "2024-09-05",
  "updated": "2024-09-05"
}