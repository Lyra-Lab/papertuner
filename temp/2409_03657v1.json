{
  "id": "http://arxiv.org/abs/2409.03657v1",
  "title": "Unsupervised Anomaly Detection and Localization with Generative Adversarial Networks",
  "authors": [
    "Khouloud Abdelli",
    "Matteo Lonardi",
    "Jurgen Gripp",
    "Samuel Olsson",
    "Fabien Boitier",
    "Patricia Layec"
  ],
  "abstract": "We propose a novel unsupervised anomaly detection approach using generative\nadversarial networks and SOP-derived spectrograms. Demonstrating remarkable\nefficacy, our method achieves over 97% accuracy on SOP datasets from both\nsubmarine and terrestrial fiber links, all achieved without the need for\nlabelled data.",
  "text": " \n \nUnsupervised Anomaly Detection and Localization with Genera-\ntive Adversarial Networks \nKhouloud Abdelli(1), Matteo Lonardi(2), Jurgen Gripp(3), Samuel Olsson(3),  \nFabien Boitier(4), and Patricia Layec(4) \n(1) Nokia Bell Labs, Germany Khouloud.Abdelli@nokia.com  \n(2) Nokia, Vimercate, Italy, (3) Nokia, Murray Hill, NJ, 07974 USA, (4) Nokia Bell Labs, France \n \nAbstract We propose a novel unsupervised anomaly detection approach using generative adversarial \nnetworks and SOP-derived spectrograms. Demonstrating remarkable efficacy, our method achieves \nover 97% accuracy on SOP datasets from both submarine and terrestrial fiber links, all achieved without \nthe need for labelled data. ©2024 The Author(s) \nIntroduction \nMonitoring the state of polarization (SOP) \nalong optical fibers is pivotal for early detection of \ndisturbances, indicating potential issues like fiber \nbreakage [1-4]. However, conventional anomaly \ndetection methods, such as threshold-based sys-\ntems and rule-based approaches, struggle to ac-\ncurately discern normal fluctuations from genuine \nanomalies, leading to false alarms or missed de-\ntections. Setting appropriate thresholds or rules \nis complex and may not cover the full spectrum \nof potential anomalies. \nTo overcome these limitations, integrating \nmachine learning (ML) models holds promise for \nanomaly detection in optical networks. ML algo-\nrithms can learn complex patterns and relation-\nships from labelled data, improving detection ac-\ncuracy [5-6]. However, the scarcity of labelled \ndata, particularly for rare anomalies, limits super-\nvised ML approaches. Unsupervised ML meth-\nods provide a solution by autonomously learning \nthe structure of normal data and detecting anom-\nalies based on deviations, enhancing detection \neven with limited anomaly data [7-9]. \nIn this paper, we present AnoGAN, an unsu-\npervised anomaly detection method utilizing \nGenerative Adversarial Networks (GANs) [10] \nand SOP-derived spectrograms. GANs learn a \nrepresentation of normal behavior solely from \nnormal training spectrograms. Trained GANs can \nonly generate what is considered normal, thus \nunable to reconstruct possible abnormal regions \nin the spectrogram. We validate our approach us-\ning submarine and terrestrial link datasets. \nAnomaly Detection Framework \nThe overall framework, delineated in Fig. 1, en-\ncompasses two core modules: offline training and \nonline anomaly detection.  \nWithin the offline training module, we employ a \npre-processed historical SOP dataset (the time \nseries of the Stokes parameters) collected during \nnormal operation to train the AnoGAN model. The \nStokes time series are divided into non-overlap-\nping sequences of fixed length 𝑙. These se-\nquences are then transformed into time-\nfrequency spectrograms using the short-time \nFourier transform (STFT). These spectrograms \nare inputted into AnoGAN for training. The struc-\nture of AnoGAN, illustrated in Fig. 2, comprises \ntwo adversarial modules: a generator 𝐺 and a dis-\ncriminator 𝐷.  𝐺 learns a distribution 𝑝𝑔 over data \n \nFig. 1: Proposed framework for anomaly detection and locali-\nzation in SOP derived spectrograms using GANs.  \n𝑥 by mapping samples 𝑧, 1D vectors of uniformly \ndistributed input noise sampled from the latent \nspace 𝑍, to 2D images (spectrograms) in the im-\nage space manifold 𝑋, which represents the var-\niability of the training data (the purple region in \nFig. 2 (b)). In this setup, 𝐺 's architecture resem-\nbles a convolutional decoder with strided convo-\nlutions. 𝐷, on the other hand, is a standard con-\nvolutional neural network that maps a 2D image \n(spectrogram) to a single scalar value, 𝐷(. ). The \n          \n        \n                \n    \n           \n               \n  \n                                      \n    \n           \n  \n                      \n         \n             \n   \n                \n                                         \n                         \n              \n       \n         \n              \n            \n             \n            \n       \n             \n             \n             \n             \n    \n       \n       \n        \n \n   \n  \n      \n       \n       \n            \n                          \n    \n \n \noutput 𝐷(. ) represents the probability that the in-\nput received by 𝐷 is a real spectrogram 𝑥 sam-\npled from the training data 𝑋 or generated by 𝐺. \n𝐷 and 𝐺 are concurrently optimized through a \ntwo-player minimax game with a value function \n𝑉 (𝐺, 𝐷) [10] \nmin\n𝐺max\n𝐷\n𝑉 (𝐺, 𝐷) = 𝔼𝑥 ~ 𝑝𝑑𝑎𝑡𝑎(𝑥)[log  𝐷 (𝑥)]\n+ 𝔼𝑧 ~ 𝑝𝑧(𝑧)[log  (1− 𝐷 (𝐺(𝑧))]  (1) \n𝐷                              x          “    ”     \n                     “  k ,”       𝐺 aims to de-\nceive 𝐷. 𝐺 iteratively refines its generation pro-\ncess to produce realistic spectrograms, while 𝐷 \nenhances its discrimination skills to distinguish \nbetween real and generated ones. \nThe real-time anomaly detection module uti-\nlizes the trained AnoGAN model in conjunction \nwith a snapshot of the streaming SOP data to cal-\nculate the corresponding anomaly score. The \ndata reconstruction module first splits the stream-\ning SOP data into sliding window samples, then \nconverts them into spectrograms, which are fi-\nnally reconstructed by the generator (see. Spec-\ntrogram Reconstruction Module in Fig. 1). The \nanomaly detection module calculates an anomaly \nscore (𝐿) by considering both the discriminator \nloss (𝐿𝐷) and the residual loss (𝐿𝑅) between the \noriginal and reconstructed spectrogram samples. \n𝐿𝑅 represents the reconstruction error of the gen-\nerated spectrogram sample, quantifying the vis-\nual dissimilarity between the sliding window spec-\ntrogram (𝑥) and the reconstructed spectrogram \n(𝐺(𝑧)). It is computed as: \n𝐿𝑅(𝑧) = ∑|𝑥−𝐺(𝑧)|  (2) \nA rich intermediate feature representation of the \ndiscriminator is adopted to compute 𝐿𝐷, leverag-\ning 𝐷 as both a classifier and a feature extractor, \nrather than solely relying on its scalar output. \n𝐿𝐷 is computed as [11]: \n𝐿𝐷(𝑧) = ∑|𝑓(𝑥) −𝑓(𝐺(𝑧))|  (3) \nwhere 𝑓(. ) represents the output of an intermedi-\nate discriminator layer, capturing image (spectro-\ngram) statistical properties. The overall anomaly \nscore is defined as the weighted sum of both \nlosses, expressed as: \n𝐿=  𝜆 𝐿𝑅+ (1 − 𝜆) 𝐿𝐷 (4) \nwhere 𝜆 is a hyper-parameter between 0 and 1, \nwhich balances the weight between 𝐿𝑅 and 𝐿𝐷.   \nIf the anomaly score of the current spectrogram \nsample surpasses a predefined threshold, the \nonline anomaly detection algorithm flags an ab-\nnormal event. After anomaly detection, localiza-\ntion involves identifying abnormal events within \nthe spectrogram both spectrally and temporally. \nThis is done by computing residuals, represent-\ning pixel-wise differences between original and \nreconstructed spectrograms. Larger residuals in-\ndicate potential anomalies. Applying a threshold \nto these residuals identifies abnormal regions, \nwith pixels exceeding the threshold marked as \nanomalies. Abnormal regions within spectro-\ngrams are visualized using color overlays. \nValidation on different datasets \n   We validate our proposed approach using SOP \ndatasets from various optical links. We first use \nthe Curie Data [12] encompasses SOP record-\nings from the 10,000 km Curie submarine cable, \nconnecting Los Angeles, California, and Val-\nparaiso, Chile. It includes normal optical telecom-\nmunications traffic traces recorded from June 1 \nto July 12, 2020, as well as recordings of moder-\nate and large earthquakes between December \n15, 2019, and September 4, 2020. SOP record-\nings from normal operations are segmented into \n4000-unit sliding windows, converted into spec-\ntrograms, and utilized for training the AnoGAN \nmodel. SOP recordings from earthquakes, along \nwith a subset of normal operation samples not \nused in training, are employed for testing.  \nWe then use “Terrestrial SOP Experiment \nData (TSED)” dataset [13]. TSED includes SOP \nmeasurements from terrestrial links during nor-\nmal operations and mechanical vibrations (anom-\nalies), recorded using the experimental setup in \nFig. 3. Initially, SOP measurements captured nor-\nmal operation patterns without external factors \nlike a robot arm or fan; only a polarization scram-\nbler altered the initial polarization state. Anoma-\nlies were induced using a robot arm, executing \nmovements like bending and shaking, and an \n \nFig. 2: (a) Deep convolutional generative adversarial network. (b) t-SNE embedding of normal (purple) and anomalous images \n(gold) from last convolution layer of the discriminator.  \n            \n         \n             \n    \n    \n                 \n                 \n(b) \n(a) \n \n \nIoT-controlled fan, causing disturbances like \npatch cord flapping. SOP recordings, including \nonly normal operation, were segmented into \n2000-size windows, transformed into spectro-\ngrams, and used for AnoGAN training. Testing in-\nvolved both mechanical event samples (anoma-\nlies) and unseen normal samples. \nResults \n     Our approach is evaluated on unseen test da-\ntasets containing both normal and abnormal in-\nstances. Performance is assessed using accu-\nracy (Acc), precision (Pre), recall (Rec), F1 score, \nand area under the curve (AUC). Tab. 1 presents \na detailed summary of the outcomes for various \ndatasets under different Stokes parameters in-\nputs. We explored the impact of training our \nmodel using all Stokes parameters, as well as \nwith a single Stokes parameter. We consistently \nachieve robust performance across both da-\ntasets, with all metrics exceeding 97%. We note \nthat performance is superior for submarine ca-\nbles, which, as anticipated, tend to be less af-\nfected by noise and environmental disturbances \ncompared to terrestrial links. The results also in-\ndicate that training our model with just one Stokes \nparameter yields comparable performance to that \nachieved when utilizing all Stokes parameters. \nThis offers a potential reduction in computational \ncomplexity and resource demands. \nFig. 4 displays the confusion matrices, \ndemonstrating precision in differentiating normal \nfrom abnormal instances. In Fig. 4(a), we see that \nall earthquakes are identified, including those of \nmoderate amplitude. In Fig. 4(b), there are only \nrare misclassifications of some abnormal in-\nstances seen as normal. The t-SNE Embedding \n(Fig. 2(b)) demonstrates the discriminative ability \nof the final convolution layer features to distin-\nguish between normal and anomalous images, \nshowcasing the effectiveness of our AnoGAN in \ncapturing meaningful variations in normal anat-\nomy. \nFig. 5 illustrates the results of the anomaly lo-\ncalization. It includes three columns: the input \nspectrogram, the reconstructed spectrogram by \nthe trained generator, and the localization of \nanomalies highlighted in red. For normal behav-\nior, the reconstructed spectrogram closely re-\nsembles the input, confirming accuracy. In \ncontrast, for abnormal samples, the discrepan-\ncies between the input and reconstructed spec-\ntrograms clearly mark the anomalous regions. \nThis allows precise identification of the anomaly's \nspatial and temporal coordinates within the spec-\ntrogram, pinpointing when the anomaly occurs. \nFig. 5: Qualitive results of the localization of the anomalies \nusing our approach.  \nConclusions \nWe proposed a GAN-based anomaly detection \nmethod using SOP-derived spectrograms. Vali-\ndated on submarine and terrestrial link datasets, \nour approach effectively distinguishes between \nnormal and abnormal instances while accurately \nlocalizing anomalies within the spectrograms. \n      \n        k      \n                   \n \nFig. 3: Experimental setup for recording SOP data.  \n \nFig. 4: Confusion matrices for a) Curie data and b) TSED. \n              \n             \n                    \n            \n         \n     \n      \n  1,  2,  3 \n     \n   \n       \nTab. 1: Performance Evaluation of AnoGAN on submarine \nand terrestrial link SOP datasets.  \nInput \nData \nAcc \n(%) \nPre \n(%) \nRec \n(%) \nF1 \n(%)  \nAUC \n(%) \n(𝑆1, 𝑆2, 𝑆3) \nCurie \n99.9 \n99.8 \n100 \n99.9 \n99.9 \nTSED \n97.8 \n100 \n95.7 \n97.8 \n97.8 \n𝑆1 \nCurie \n98.9 \n98 \n100 \n99 \n98.9 \nTSED \n97.8 \n100 \n95.7 \n97.8 \n97.8 \n𝑆2 \nCurie \n99.9 \n99.8 \n100 \n99.9 \n99.9 \nTSED \n97.8 \n100 \n95.7 \n97.8 \n97.8 \n(a) \n(b) \n \n \n \nReferences \n[1] F. Boitier et al., \"Proactive Fiber Damage Detection in \nReal-time Coherent Receiver,\" European Conference on \nOptical Communication (ECOC), pp. 1-3, Gothenburg, \nSweden (2017).  \n[2]      v,              “                    v              \nClassification on Fiber Optic Cables in Quaternion Coor-\n        ” 2022                                      \nnication (ECOC) (2022): 1-4. \n[3] W   ’     k   ?         k                           \nCables. \nAvailable \nonline: \nhttps://cloud.google.com/blog/products/infrastructure/us-\ning-subsea-cables-to-detect-earthquakes (accessed on \n17 April 2024). \n[4] Cantono, M.; Kamalov, V.; Vusirikala, V.; Salsi, M.; New-\nland, M.; Zhan, Z.W., “ Sub-hertz spectral analysis of po-\nlarization of light in a transcontinental submarine cable”,  \nIn Proceedings of the 2020 European Conference on Op-\ntical Communications (ECOC), Brussels, Belgium, 6–10 \nDecember 2020; pp. 1–3. \n[5] K. Guan, et al., \"Efficient Classification of Polarization \nEvents Based on Field Measurements,\" Optical Fiber \nCommunication Conference (OFC), paper Th3D.7 \n(2020).   \n[6] K                , “Anomaly Detection and Localization in \nOptical Networks Using Vision Transformer and SOP \nMonitoring,”     2024    \n[7] Z. Chen, C. K. Yeo, B. S. Lee and C. T. Lau, \"Autoen-\ncoder-based network anomaly detection,\" 2018 Wireless \nTelecommunications Symposium (WTS), Phoenix, AZ, \nUSA, 2018, pp. 1-5, doi: 10.1109/WTS.2018.8363930. \n[8] K. Abdelli, et al., \"Machine-learning-based anomaly de-\ntection in optical fiber monitoring,\" in Journal of Optical \nCommunications and Networking, vol. 14, no. 5, pp. 365-\n375 (2022).  \n[9] Thomas Schlegl, Philipp Seeböck, Sebastian M. Wald-\nstein, Georg Langs, Ursula Schmidt-       , “ -AnoGAN: \nFast unsupervised anomaly detection with generative \n  v               k ” ,         I             ,        \n54,2019, Pages 30-44, ISSN 1361-8415.  \n[10] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., \nWarde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: \nGenerative adversarial nets. In: Advances in Neural In-\nformation Processing Systems. (2014) 2672–2680.  \n[11]  Schlegl, T., Seeböck, P., Waldstein, S.M., Schmidt-Er-\nfurth, U., Langs, G. (2017). Unsupervised Anomaly De-\ntection with Generative Adversarial Networks to Guide \nMarker Discovery. In: Niethammer, M., et al. Information \nProcessing in Medical Imaging. IPMI 2017. Lecture \nNotes in Computer Science(), vol 10265. Springer, \nCham. https://doi.org/10.1007/978-3-319-59050-9_12. \n[12] Zhongwen Zhan. (2020). Curie Data - Zhan et al. (2021) \n(1.0) [Data set]. CaltechDATA. \nhttps://doi.org/10.22002/D1.1668. \n[13]  K. Abdelli, M. Lonardi, J. Gripp, S. Olsson, F. Boitier \nand P. Layec, \"Breaking boundaries: harnessing unre-\nlated image data for robust risky event classification with \nscarce state of polarization data,\" presented at 49th Eu-\nropean Conference on Optical Communications (ECOC \n2023), Glasgow, United Kingdom, 2023, DOI: \n10.1049/icp.2023.2374. \n \n",
  "categories": [
    "cs.LG",
    "eess.SP"
  ],
  "published": "2024-09-05",
  "updated": "2024-09-05"
}