{
  "id": "http://arxiv.org/abs/2409.08356v1",
  "title": "COMEX Copper Futures Volatility Forecasting: Econometric Models and Deep Learning",
  "authors": [
    "Zian Wang",
    "Xinyi Lu"
  ],
  "abstract": "This paper investigates the forecasting performance of COMEX copper futures\nrealized volatility across various high-frequency intervals using both\neconometric volatility models and deep learning recurrent neural network\nmodels. The econometric models considered are GARCH and HAR, while the deep\nlearning models include RNN (Recurrent Neural Network), LSTM (Long Short-Term\nMemory), and GRU (Gated Recurrent Unit). In forecasting daily realized\nvolatility for COMEX copper futures with a rolling window approach, the\neconometric models, particularly HAR, outperform recurrent neural networks\noverall, with HAR achieving the lowest QLIKE loss function value. However, when\nthe data is replaced with hourly high-frequency realized volatility, the deep\nlearning models outperform the GARCH model, and HAR attains a comparable QLIKE\nloss function value. Despite the black-box nature of machine learning models,\nthe deep learning models demonstrate superior forecasting performance,\nsurpassing the fixed QLIKE value of HAR in the experiment. Moreover, as the\nforecast horizon extends for daily realized volatility, deep learning models\ngradually close the performance gap with the GARCH model in certain loss\nfunction metrics. Nonetheless, HAR remains the most effective model overall for\ndaily realized volatility forecasting in copper futures.",
  "text": "COMEX Copper Futures Volatility Forecasting:\nEconometric Models and Deep Learning\nZian Wang1 and Xinyi Lu2\n1Financial Technology Thrust, The Hong Kong University of Science and\nTechnology, Guangzhou, China\n2Depatment of Statistics, The Chinese University of Hong Kong, Hong\nKong, China\nSeptember 16, 2024\nAbstract\nThis paper investigates the forecasting performance of COMEX copper futures\nrealized volatility across various high-frequency intervals using both econometric\nvolatility models and deep learning recurrent neural network models. The econo-\nmetric models considered are GARCH and HAR, while the deep learning models\ninclude RNN (Recurrent Neural Network), LSTM (Long Short-Term Memory), and\nGRU (Gated Recurrent Unit). In forecasting daily realized volatility for COMEX\ncopper futures with a rolling window approach, the econometric models, partic-\nularly HAR, outperform recurrent neural networks overall, with HAR achieving\nthe lowest QLIKE loss function value. However, when the data is replaced with\nhourly high-frequency realized volatility, the deep learning models outperform the\nGARCH model, and HAR attains a comparable QLIKE loss function value. De-\nspite the black-box nature of machine learning models, the deep learning models\ndemonstrate superior forecasting performance, surpassing the fixed QLIKE value\nof HAR in the experiment.\nMoreover, as the forecast horizon extends for daily\nrealized volatility, deep learning models gradually close the performance gap with\nthe GARCH model in certain loss function metrics. Nonetheless, HAR remains the\nmost effective model overall for daily realized volatility forecasting in copper futures.\nKeywords: Volatility forecasting, COMEX copper, HAR, Realized GARCH, RNN,\nLSTM, GRU\n1\nIntroduction\nAs a metal of economic importance, the price of copper is often seen by the industry\nas a macroeconomic barometer.\nWhen copper prices rise, the world economy is in a\nstate of expansion, and vice versa. China’s rapidly booming economy has been a major\nreason for the rise in copper prices for quite some time in the past. And the vigorously\n1\narXiv:2409.08356v1  [q-fin.MF]  12 Sep 2024\ndeveloping real estate, the backbone of China’s economic boom over the past few decades,\nhas accounted for a significant share of the demand side of the international copper\nmetal trading market. After the impact of the epidemic on the world economy, China’s\nnew energy vehicle market is seen as a new demand export for copper products. The\nsuitable climate, dense urban distribution, and transportation characteristics have made\ninvestors unanimously bullish on the Chinese tram market. Then future trading of copper\nfutures for hedging in the international market will undoubtedly become more frequent.\nTherefore, an in-depth study of its high-frequency data volatility forecasts is beneficial\nto inform the appropriate choices for future investors.\nIn this paper, we analyze the\ncharacteristics of COMEX copper futures volatility forecasting from different directions\nbased on the comparison of econometric volatility models and deep learning models.\nAlthough the traditional econometric models are the current commonly used methods\nto predict volatility, many novel deep learning models show strong promise for better pre-\ndicting stock behavior (see, e.g., Bucci, 2020; Xiong et al., 2015). Advanced econometric\nmodels, such as HAR (heterogeneous autoregression), realized GARCH, HEAVY (high-\nfrequency-based volatility), and Markov-switching GARCH (Conrad and Kleen, 2019),\nhave all been widely applied to volatility forecasting. Different econometric models ex-\nhibit specialized treatment of both long-term trends and short-term structural changes.\nCompared to econometric models proposed to solve different problems, deep learning\nmodels represented by RNN (recurrent neural networks) are more flexible and tunable,\nwhich is one of the reasons why they are widely used in high frequency trading. Based\non the characteristics of econometric models and deep learning, exploring their predic-\ntion effects on different frequency data, and analyzing the corresponding advantages and\ndisadvantages are beneficial to help us make appropriate model choices when facing data-\noriented cases.\nFor the final comparison of volatility forecasting, Patton (2011) finds that both the\nMSE and the QLIKE loss function are robust when used to compare volatility forecasting\nmodels. Rahimikia and Poon (2020) suggested using evaluation measures such as MSE,\nQLIKE, MDA, and RC values to examine the performance of machine learning models in\nrealized volatility forecasting. This paper uses MSE and QLIKE as criteria for comparing\nthe predictive power of volatility.\n1.1\nCopper price is an leading indicator of global economy\nCopper futures are used by miners and dealers to hedge against losses and are in an\nimportant position in futures markets all over the world. As an effective conductor of\nheat and electricity, most copper is used in the electrical sector such as building trans-\nmission lines and motors equipment. In the past two decades, the demand of copper\nhas been increasing in developing countries for basic grid construction. As the largest\ncopper importer, China has a huge potential market for electric cars since the produc-\ntion of electric cars requires abundant copper as a raw material. Therefore, a stable and\nsufficient supply of copper is key to guaranteeing the ongoing shift from gasoline to elec-\ntric vehicles. Generally, the demand of copper in most developed countries is dominated\nby manufacturing industry and renewable energy, since it is used to make manufacturing\nmachines and equipment, such as windmills and solar plants. Consequently, copper prices\nare principally determined by demand of emerging markets such as China and India.\nAs copper is associated with many industries, it is often regard as the leading indicator\nof the world economy. When the global economy is expanding, the copper price tends to\n2\nrise and vice versa. In recent years, the prices of copper and its derivatives have been\nfluctuating. While global stock markets have been in recession for the last few years\nduring the pandemic, a soaring rise in copper price took place in 2020. The first reason\nfor the unusual performance is that copper prices are settled in the US dollar, which has\nfallen sharply during that time. Second, production in major copper exporters such as\nChile and Peru have declined due to the COVID-19 pandemic. Thirdly, as having always\nbeen the world’s largest copper importer for a long time, China did well in the early\nstages of the pandemic and maintained a sound economic circumstance.\nIn general, copper has both commodity properties and financial properties, both of\nwhich are affected by macroeconomy. Meanwhile, due to the continuous prominence of\nthe financial attributes of the US’s commodities, the price volatility of commodity futures\nmarket and the price volatility of stock market have increasingly prominent characteristics\nof synchronization, and the price volatility risk of commodity futures market gradually\nspreads to the stock market. Therefore, the copper future price is not only affected by\nthe macroeconomic cycle, but also has an increasing correlation with the stock market.\n1.2\nAnticipating volatility based on econometric models\nAs a statistical measure of the dispersion of returns for a given security or market\nindex in finance, volatility is often used as a measure of risk. Higher volatility means\nthat the price of an asset can fluctuate dramatically in a short period of time, which\ncan lead to large gains or losses for investors. Volatility models are used to forecast the\nabsolute magnitude of returns and predict quantiles or the entire density of future returns.\nThere are many types of volatility models, including stochastic volatility models which\nassume that the volatility itself follows a random process. Moreover, realized volatility is\na measure of the variation in the price of an asset over a given period. Realized volatility\nmodels are used to forecast future volatility using past realized volatility. The strength\nof realized volatility is that it is based on actual prices and is therefore less susceptible\nto errors due to assumptions about the underlying distribution of returns. This paper\nonly calculates the realized volatility of COMEX copper futures based on daily or high-\nfrequency intraday return respectively.\nHAR (Heterogeneous Autoregressive) uses the squared past returns to predict fu-\nture volatility (Corsi, 2009). The realized GARCH incorporates the HAR structure of\nrealized variance into the GARCH equation (Hansen et al., 2012). ARFIMA (Autoregres-\nsive Quantile Integrated Moving Average) captures the long-term memory in volatility\n(Hosking, 1981). The HEAVY (high-frequency-based volatility) model is used to capture\nheavy tails in financial data (Shephard and Sheppard, 2010). The MS-GARCH (Markov-\nSwitching GARCH) allows the volatility regime to vary over time (Hamilton and Susmel,\n1994). This paper chooses HAR and realized GARCH as representatives of econometric\nmodels because of stationarity and applicability. Both of them have good performance\nin predicting realized volatility.\n1.3\nDeep Learning models have potential in volatility forecasting\nForecasting realized volatility is essential for trading signals and position management.\nEconometric models, such as GARCH and HAR, predict future volatility based on past\nreturns in an intuitive way. Conrad and Kleen (2019) stated that GARCH-MIDAS out-\nperforms several econometric competitor models such as HAR, HEAVY, realized GARCH,\n3\nand MS-GARCH. However, recurrent neural networks have become a significant com-\npetitor, especially LSTM and GRU. The discussion on whether traditional econometric\nmodels (such as GARCH) or deep learning models (such as LSTM) have higher prediction\naccuracy has not stopped.\nXiong et al. (2016) applied a Long Short-Term Memory neural network to model S&P\n500 volatility, and its model has a smaller mean absolute percentage error compared with\nlinear Ridge/Lasso and autoregressive. Bucci (2019) compared the predictive performance\nof feed-forward and recurrent neural networks (RNN) with traditional econometric ap-\nproaches, and the RNN outperforms all the traditional econometrics methods. Rahimikia\nand Poon (2020) showed that the machine learning model represented by LSTM has a\nstronger prediction ability than all HAR-family models based on machine learning mod-\nels to predict volatility strengths and weaknesses for 23 Nasdaq stocks between 2007 and\n2016. Despite the increasing achievements of machine learning in volatility prediction, it\nis still too early to say that classical econometric models will be replaced.\nMSE and RMSE are used to measure the average squared difference between the pre-\ndicted and actual values. MAPE is used to measure the percentage difference between the\npredicted and actual values. MAE is used to measure the average absolute difference be-\ntween the predicted and actual values. QLIKE is used to measure the difference between\nthe predicted and actual quantiles. The choice of which metric to use depends on the\nspecific problem at hand. MSE and RMSE are commonly used in regression problems,\nwhile MAPE and MAE are commonly used in forecasting problems. QLIKE is commonly\nused in quantile regression problems. This paper analyzes the forecasting results of RNN\n(Recurrent Neural Network), LSTM (Long Short-Term Memory), and GRU (Gated Re-\ncurrent Unit) for realized volatility of copper futures at different frequencies and compare\nthem with the loss functions of the above econometric models over time. According to\nPatton (2011), this paper collects MSE, RMSE, MAPE, MAE and QLIKE loss function\nto compare robust loss validation trend of different models.\n2\nMethodology\n2.1\nEconometric Models\n2.1.1\nGARCH(1,1)\nEngle and Lee(1999) introduced a GARCH model with a long-run and a short-run\ncomponent.\nGARCH(1,1) represents that the volatility is based on the most recent\nobservation of return and the most recent estimate of the variance rate. Furthermore,\nGARCH(p,q) means p observations of return and q estimates of variance rate.\nσ2\nn = γVL + αu2\nn−1 + βσ2\nn−1\n(1)\nω = γVL\nγ + α + β = 1\n2.1.2\nRealized GARCH\nRealized GARCH framework is a joint modelling of return and realized volatility. The\ngeneral structure of Realized GARCH (p,q) model is given by\n4\nRVt =\nNt\nX\ni=1\nr2\ni,t\n(2)\nrt =\np\nhtzT\n(3)\nht = ω + αr2\nt−1 + βht−1 + γxt−1\n(4)\nxt = ξ + ϕht + Errort,\nwhere xt is noisy mearsurement of QVt, and QVt is ht+ volatility shock.\n2.1.3\nHAR\nWith the widespread availability of high-frequency intraday data, the HAR model\nproposed by Corsi(2009) has gained popularity due to its simplicity and consistent fore-\ncasting performance in applications. The conditional variance of the discretely sampled\nreturns is parameterized as a linear function of lagged squared returns over the same\nhorizon together with the square returns over longer and shorter horizons.\nThe original HAR model specifies RV as a linear function of daily, weekly and monthly\nrealized variance components, and can be expressed as\nRVt = β0 + β1RV d\nt−1 + β2RV ω\nt−1 + β3RV m\nt−1 + ut,\n(5)\nwhere the βj(j = 0, 1, 2, 3) are unknown parameters that need to be estimated, RVt is\nthe realized variance of day t. The Specification of RV parsimoniously captures the high\npersistence observed in most realized variance series.\n2.2\nDeep Learning\nThe model used in this paper aims to predict volitality of COMEX based on differ-\nent neural networks. The input data is preprocessed through normalization using the\nMinMaxScaler. LSTM(long short term memory), GRU (gated recurrent unit) and RNN\n(recurrent neural network) enhance the modeling of sequential data by explicitly con-\nsidering the dependencies between observations when learning the mapping relationship\nfrom input to output, which allows them to capture the sequential dependencies in the\ninput data.\nThe dataset is divided into training and testing sets, and input-output pairs for train-\ning are generated by sliding a window of 12 consecutive days in the training set because\nthe recurrent model expect the input component of training data to have the dimensions\nof [batch samples, time sequence length, number of features]. The model architecture is\nconstructed using the Keras Sequential API. For the GRU model, the input layer contains\n16 units. This is followed by a dense layer with 4 units and a LeakyReLU activation func-\ntion to introduce non-linearity, and another dense layer with the number of output days\nas units is added. The model is then compiled using the Adam optimizer with a learning\nrate of 0.0001, and the mean squared error is selected as the loss function. Training is\nperformed for 50 epochs with a batch size of 64. To prevent overfitting, a dropout layer\nwith a dropout rate of 0.2 is incorporated,. and early stopping based on the model loss\nis also employed. In the LSTM model, the input layer consists of 8 units, followed by a\ndense layer with the number of output days as units. The batch size has been adjusted to\n16, while the remaining architecture and hyperparameters remain unchanged. The RNN\n5\nnetwork has the same structure as the LSTM network, but the number of epochs has\nbeen set to 30.\nIt can try to change the sequence length to 50 because the 50-day moving average is\na commonly used technical indicatorthat provides insights into the trend and momentum\nof assets. Traders actually utilize the 50-day moving average to confirm price trends,\ndetermine support and resistance levels, and generate trading signals.\n2.2.1\nRNN\nRNNs have the same input and output architecture as any other deep neural archi-\ntecture. However, differences arise in the way information flows from input to output.\nUnlike Deep neural networks where we have different weight matrices for each Dense\nnetwork in RNN, the weight across the network remains the same. It calculates state\nhidden state Hi for every input Xi. By using the following formulas:\nh = σ(UX + Wh−1 + B)\n(6)\nY = O(V h + C)\n(7)\nY = f(X, h, W, U, V, B, C).\n(8)\nHere S is the State matrix which has element si as the state of the network at timestep\ni. The parameters in the network are W, U, V , c, b which are shared across timestep.\nThe formulas for calculating the current state, applying Activation function(tanh), and\ncalculating output are given below respectively.\nht = f(ht−1, xt)\n(9)\nht = tanh(Whhht−1 + Wxhxt)\n(10)\nyt = Whyht,\n(11)\nwhere xt means input state; whh, wxh, and why represent weights at recurrent neuron,\ninput neuron and output layer.\n2.2.2\nLSTM and GRU\nThe basic difference between the architectures of RNNs and LSTMs is that the hidden\nlayer of LSTM is a gated unit or gated cell. It consists of four layers that interact with\none another in a way to produce the output of that cell along with the cell state. These\ntwo things are then passed onto the next hidden layer. Unlike RNNs which have got\nthe only single neural net layer of tanh, LSTMs comprises of three logistic sigmoid gates\nand one tanh layer. Gates have been introduced in order to limit the information that\nis passed through the cell. They determine which part of the information will be needed\nby the next cell and which part is to be discarded. The output is usually in the range of\n0-1 where ’0’ means ’reject all’ and ’1’ means ’include all’.\nEach LSTM cell has three inputs ht−1, Ct−1, and xt and two outputs ht and Ct. For\na given time t, ht is the hidden state, Ct is the cell state or memory, xt is the current\ndata point or input. The first sigmoid layer has two inputs–ht−1 and xt where ht−1 is the\nhidden state of the previous cell. It is known as the forget gate as its output selects the\namount of information of the previous cell to be included. The output is a number in\n[0,1] which is multiplied (point-wise) with the previous cell state Ct−1.\n6\nFigure 1: Deep Learning Models\nIn spite of being quite similar to LSTMs, GRUs have never been so popular. GRU\nstands for Gated Recurrent Units. As the name suggests, these recurrent units, proposed\nby Cho, are also provided with a gated mechanism to effectively and adaptively capture\ndependencies of different time scales. They have an update gate and a reset gate. The\nformer is responsible for selecting what piece of knowledge is to be carried forward,\nwhereas the latter lies in between two successive recurrent units and decides how much\ninformation needs to be forgotten.\nActivation at time t: hj\nt = (1 −zj\nt )hj\nt−1 + zj\nt ∗˜hj\nt\n(12)\nUpdate gate: zj\nt = σ(Wzxt + Uzht−1)j\n(13)\nCandidate activation: ˜hj\nt = tanh(Wxt + U(rt ⊗ht−1))j\n(14)\nReset gate: rj\nt = σ(Wrxt + Urht−1)j\n(15)\nAnother striking aspect of GRUs is that they do not store cell state in any way,\nhence, they are unable to regulate the amount of memory content to which the next unit\nis exposed. Instead, LSTMs regulate the amount of new information being included in\nthe cell. On the other hand, the GRU controls the information flow from the previous\nactivation when computing the new, candidate activation, but does not independently\ncontrol the amount of the candidate activation being added (the control is tied via the\nupdate gate).\n2.3\nQLIKE Loss Function\nThe Quadratic Likelihood Error (QLIKE) loss function is widely used in the evaluation\nof volatility forecasting models, particularly in the field of finance. It is designed to assess\nthe accuracy of volatility or variance predictions in time series data. Compared to other\nloss functions such as RMSE or MAPE, QLIKE is more robust to scale differences and\nhighly sensitive to extreme values, making it particularly useful for comparing volatility\nforecasting models.\nGiven a set of actual volatilities σ2\nt and predicted volatilities from a model ˆσ2\nt , the\nQLIKE loss function is defined as follows:\nQLIKE = 1\nT\nT\nX\nt=1\n\u0012\nlog(ˆσ2\nt ) + σ2\nt\nˆσ2\nt\n−1\n\u0013\n,\n(16)\nwhere T represents the length of the time series, σ2\nt is the actual volatility (or true\nvariance) at time t. And ˆσ2\nt is the predicted volatility from the model at time t.\n7\nIf the predicted volatility is close to the actual volatility, the QLIKE value will be\nclose to 0. A higher QLIKE value indicates a larger forecasting error, particularly when\nthe model underestimates volatility. By comparing the QLIKE values of different models,\nresearchers can determine which model performs best in volatility forecasting.\n3\nData Specification\n3.1\nData Collection\nThis article collects daily COMEX copper futures prices from the Wind database from\n2000/1/4 to 2023/3/2. Daily log returns are calculated from the daily copper prices, and\nthen assuming M is 1, a preliminary daily realized volatility is obtained as a volatility\nmeasure (which is actually the square of the daily return). And for high frequency data,\nthis paper collects the price changes from 2023-01-02 18:01 to 2023-04-13 03:27, which\nin turn gives the hourly RV (which is actually the sum of the squares of the returns per\nminute).\nTable 1: Data Collection\nStart\nEnd\nObs.\nWindow Size\nTraining Set\nDaily Price\n2000/1/4\n2023/3/2\n5777\n/\nDaily Return\n2000/1/5\n2023/3/2\n5776\n/\nDaily RV\n2000/1/5\n2023/3/2\n5776\n/\n1 min Price Change\n2023/1/2 18:01\n2023/4/13 3:27\n99999\n/\nHoulry RV\n2023/1/2 20:00\n2023/4/13 3:00\n1641\n/\nTest Set\nDaily RV\n2016/5/19 0:00\n2023/3/2 0:00\n1688\n4077\nHourly RV\n2023/3/15 7:00\n2023/4/13 3:00\n480\n1149\nAccording to the hand-out method, the training set occupies seventy percent of the\noriginal data and the test set occupies thirty percent of the original data. This article\nuses the rolling window to predict the out of sample data and compares and analyzes\nthe loss functions of different models for copper futures volatility predicted data with the\nreal data.\n3.2\nStatistical Summary\nTable 2 provides basic descriptive statistics about COMEX copper future’s return and\nRV in terms of observation, minimum value, maximum value, standard deviation, skew-\nness, and kurtosis. Simultaneously, we choose the Jarque-Bera test to confirm normality.\nThe result is that all of them are not normally distributed. Apart from that, no time\nseries is white noise by the Ljung-Box test lags with 20, and they all have an ARCH\neffect. All of them are stationary according to ADF test.\n8\nTable 2: Statistical Summary\nObs.\nMean\nSD\nMin\nMax\nSkew.\nKurt.\nJ-B pvalue\nL-B pvalue\nADF\nDaily\nReturn\n5777\n0.0003\n0.0168\n-0.1169\n0.1177\n-0.1772\n4.1250\n0.0000\n0.0000\n0.0000\nRV\n5777\n0.0003\n0.0007\n0.0000\n0.0139\n8.3841\n112.7821\n0.0000\n0.0000\n0.0000\nHourly\nReturn\n1641\n4.31E-05\n0.0032\n-0.0177\n0.0160\n-0.0932\n4.3197\n0.0000\n0.0000\n0.0000\nRV\n1641\n9.78E-06\n0.0000\n0.0000\n0.0001\n3.5647\n23.1754\n0.0000\n0.0000\n0.0000\nNote: According to the ADF test, the data is stationary after processing. For the\nJ-B test, if the p-value is bigger than 0.05, the time series will be regarded as normally\ndistributed. For the L-B test, the data is not going to be white noise if the p-value is\nsmaller than 0.05.\n4\nEmpirical Analysis\n4.1\nDaily Volatility Forecasting\nFor the daily realized volatility forecasts, the rolling window size is set to 4077 in this\npaper. The out-of-sample predicted data obtained from the Rolling window forecasts\nare from 2016/5/19 to 2023/3/2, with a total of 1688 data. It can be seen from the\npicture that both recurrent neural network models (RNN, LSTM, and GRU) and econo-\nmetric models (realized GARCH and HAR) accurately capture the occurrence of extreme\nvolatility. However, none of the current tested models can be closer to the value of the\ntrue extreme volatility. Considering that the original volatility estimation method uses\nthe square of the daily return as the realized volatility, there may be a coarser estimation\nerror. As a result, information on intra-day copper futures price volatility is not captured,\nmaking it difficult to approach the true value when extreme volatility occurs. Still, in\nterms of general trends, the above model is a better predictor of long-term structural\nchanges.\nFigure 2: Daily Volatility Forecasting\n9\nAs can be seen in the table, the RNN recurrent neural network models are very\nsimilar to each other and their performance in the selected data can be considered almost\nindistinguishable. Since the volatility measure is very small, the value of MSE is not\nprecise enough to be ignored as 0. From the RMSE as well as MAPE, it can be seen\nthat the GARCH model is more prominent in daily volatility forecasting. While MAE,\nwhich is widely used in forecasting problems, indicates that HAR performs better in long-\nterm daily frequency volatility forecasting. Combined with the QLIKE loss function, it\ncan be concluded that the econometric models represented by the realized GARCH and\nHAR perform better than the recurrent neural network models in forecasting the realized\nvolatility of daily frequency copper futures. The econometric volatility models are still\nmuch stronger than the deep learning models in predicting long-term trends and capturing\nstructural changes.\nTable 3: Daily Volatility Forecasting\nRNN\nLSTM\nGRU\nrGARCH\nHAR\nMSE\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\nRMSE\n0.0004\n0.0004\n0.0004\n0.0003\n0.0001\nMAPE\n1.0194\n1.0534\n1.3938\n0.9250\n1.0320\nMAE\n0.0002\n0.0002\n0.0002\n0.0002\n0.0000\nQLIKE\n6.73E-08\n6.70E-08\n6.72E-08\n5.99E-08\n2.39E-09\nIt is well known that futures trading is often accompanied by dramatic price fluctu-\nations, and how to improve the accuracy of intraday volatility forecasting has become a\nconcern for many traders as well as investors.\n4.2\nHourly Volatility Forecasting\nFor hourly realized volatility forecasts, the prize window size is set to 1149 in this pa-\nper. Out-of-sample forecasts obtained from rolling window forecasts range from 2023/3/15\n7:00 to 2023/4/13 3:00, for a total of 480 data points.\nFigure 3: Hourly Volatility Forecasting\n10\nUnlike the daily volatility forecasting performance, the recurrent neural network model\nsignificantly outperforms the overall GARCH forecasting performance in intra-day fore-\ncasting. From the image, the GARCH model is difficult to adjust in time in high frequency\ndata, thus leading to inaccurate results most of the time. In terms of the QLIKE loss\nfunction, HAR is the best performing model, but the difference in prediction results with\nthe deep learning model is not significant and can even be ignored. The deep learning\nmodel, on the other hand, because of the reason that the results are not exactly the same\nevery time, in some cases it can be believed that the recurrent neural network model\nhas the full potential to outperform the best performing HAR model. This is what has\nhappened in the tests.\nTable 4: Houlry Volatility Forecasting\nRNN\nLSTM\nGRU\nrealized GARCH\nHAR\nMSE\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\nRMSE\n8E-6\n9E-6\n8E-6\n1E-5\n8E-6\nMAPE\n0.6008\n0.6129\n0.6052\n0.6864\n0.6078\nMAE\n0.000006\n0.000006\n0.000006\n0.000007\n0.000005\nQLIKE\n3.59E-11\n3.73E-11\n3.61E-11\n5.19E-11\n3.43E-11\nTherefore for more frequent volatility forecasting, there is reason to believe that deep\nlearning models are a better choice than traditional econometric volatility models. The\neconometric volatility model represented by HAR model can be used as benchmark to\nmeasure higher frequency volatility forecasts. However, due to the difficulty of collecting\ndata sets, this paper will not consider higher frequency volatility forecasts.\n4.3\nLoss Function Trend\nWhile deep learning models, particularly recurrent neural networks, demonstrate\nstrong performance in forecasting intraday hourly realized volatility, their effectiveness di-\nverges significantly from econometric models when applied to long-term daily frequency\nvolatility forecasts. Econometric models tend to provide more transparent and inter-\npretable solutions, which may be particularly advantageous for forecasting over extended\nperiods. In practice, however, high-frequency traders and fund managers are not only\nconcerned with short-term volatility changes, such as those occurring within a day or the\nfollowing day, but also with longer-term price fluctuations and volatility trends. While\nmacroeconomic researchers may offer broad, accurate insights, the precise quantifica-\ntion of volatility trends for specific financial products remains challenging. This raises\nimportant questions about whether deep learning models continue to underperform in\nlonger-term volatility forecasts when compared to econometric models, particularly in\nterms of forecast accuracy and actual errors. A thorough comparative analysis of the\npredictive performance of deep learning models over longer horizons, assuming a 30-day\nmonth for forward projections, could offer valuable insights and contribute to a deeper\nunderstanding of their applicability in financial volatility forecasting.\nWhen using the RMSE loss function, the GARCH model demonstrates a significant\nadvantage over recurrent neural network models when forecasting volatility for a single\nday ahead.\nHowever, as the forecast horizon extends and the number of days ahead\nincreases, the GARCH model’s advantage diminishes, displaying a gradual incremental\nincrease in error. In contrast, the MAPE loss function shows a more erratic pattern,\n11\nFigure 4: Loss Function Trend\nwith no clear trend emerging over time, making it difficult to draw definitive conclusions\nregarding model performance based on this metric alone.\nDue to the inherent \"black box\" nature of machine learning models, recurrent neu-\nral networks (RNN), long short-term memory networks (LSTM), and gated recurrent\nunits (GRU) may outperform the GARCH model in forward volatility forecasts. This\nis especially true when the forecast period is extended beyond a few days. The QLIKE\nloss function, known for its robustness, provides a clearer picture of the diminishing ad-\nvantage of the GARCH model as the forecast horizon increases. Over time, the deep\nlearning models begin to outperform GARCH based on the QLIKE metric, highlighting\ntheir potential in capturing complex volatility patterns in forward predictions.\nInterestingly, throughout these comparisons, the HAR model consistently demon-\nstrates a superior ability to forecast volatility, regardless of the number of days ahead.\nIts robust performance across multiple horizons suggests that it remains a highly effective\ntool for volatility forecasting, outperforming both GARCH and deep learning models in\nmany scenarios. This stability in forecasting makes the HAR model a valuable benchmark\nfor both short-term and long-term volatility predictions.\n5\nConclusion\nIn this paper, the econometric volatility models, particularly the HAR model, gener-\nally outperform recurrent neural network models in forecasting daily realized volatility\nfor COMEX copper futures using a rolling window approach. Notably, the HAR model\nachieves a significant advantage with a QLIKE loss function value of 2.39E-09, which\nis an order of magnitude smaller than its competitors. The forecast results from the\neconometric models are notably smoother, as seen in the visualizations, while the deep\n12\nTable 5: Daily Rolling Window Forecasting Loss Functions Trend\nDays ahead\n1d\n2d\n3d\n4d\n5d\n6d\n1w\n2w\n1m\n2m\n3m\nRMSE\nRNN\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\nLSTM\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\nGRU\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\nGARCH\n0.0003\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\n0.0004\nHAR\n0.0001\n0.0001\n0.0001\n0.0001\n0.0001\n0.0001\n0.0001\n0.0001\n0.0001\n0.0001\n0.0001\nMAPE\nRNN\n1.0194\n1.0065\n0.9715\n0.9581\n0.9325\n1.0810\n0.9790\n0.9735\n0.9229\n0.9231\n0.9569\nLSTM\n1.0534\n1.0068\n0.9779\n0.9791\n0.9627\n1.0166\n0.9472\n0.9810\n0.9633\n0.9533\n0.9455\nGRU\n1.3938\n0.9488\n0.9559\n0.9413\n0.9580\n0.9483\n0.9306\n1.0886\n0.9600\n0.9776\n1.0428\nGARCH\n0.9250\n1.0465\n1.0483\n1.0506\n1.0483\n1.0477\n1.0515\n1.0546\n1.0274\n0.9919\n0.9600\nHAR\n1.0320\n1.0357\n1.0260\n1.0376\n1.0513\n1.0476\n1.0495\n1.0250\n0.9960\n0.9720\n0.9661\nMAE\nRNN\n0.0002\n0.0002\n0.0002\n0.0003\n0.0003\n0.0002\n0.0002\n0.0002\n0.0003\n0.0003\n0.0002\nLSTM\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0003\n0.0003\nGRU\n0.0002\n0.0002\n0.0002\n0.0002\n0.0003\n0.0002\n0.0002\n0.0002\n0.0003\n0.0002\n0.0003\nGARCH\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\n0.0002\nHAR\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\nQLIKE\nRNN\n6.73E-08\n6.78E-08\n6.91E-08\n7.38E-08\n7.41E-08\n6.92E-08\n6.98E-08\n7.09E-08\n7.37E-08\n7.51E-08\n7.21E-08\nLSTM\n6.70E-08\n6.70E-08\n6.75E-08\n6.79E-08\n6.85E-08\n6.75E-08\n6.89E-08\n6.94E-08\n7.18E-08\n7.35E-08\n7.25E-08\nGRU\n6.72E-08\n6.76E-08\n6.80E-08\n6.97E-08\n7.09E-08\n7.01E-08\n7.01E-08\n7.09E-08\n7.30E-08\n7.38E-08\n7.33E-08\nGARCH\n5.99E-08\n6.68E-08\n6.71E-08\n6.74E-08\n6.74E-08\n6.78E-08\n6.84E-08\n6.97E-08\n7.09E-08\n7.26E-08\n7.30E-08\nHAR\n2.39E-09\n2.42E-09\n2.42E-09\n2.46E-09\n2.50E-09\n2.51E-09\n2.53E-09\n2.55E-09\n2.58E-09\n2.57E-09\n2.63E-09\nlearning models, such as RNN, LSTM, and GRU, demonstrate greater sensitivity to data\nchanges, especially in periods of high market volatility. This higher sensitivity may reflect\nthe deep learning models’ ability to capture short-term fluctuations more rapidly than\nthe econometric approaches.\nIn contrast, for higher-frequency rolling window forecasts of hourly realized volatility,\nthe performance of deep learning models improves significantly. In this scenario, the re-\ncurrent neural network models achieve a QLIKE loss function value comparable to that\nof the HAR model, both reaching 3.43E-11. However, the GARCH model lags consider-\nably, with a QLIKE loss function value of 5.19E-11. Despite this, the GARCH model’s\nprediction of extreme volatility events remains closer to the true values, as illustrated in\nthe figures. This suggests that in high-frequency trading environments, investors should\npay particular attention to the GARCH model’s extreme predictions, which could serve\nas an early warning signal for significant market movements. The deep learning models,\non the other hand, show quicker adjustments to volatility changes, making them more\nsuitable for real-time high-frequency forecasting.\nAs the forecast horizon for daily realized volatility extends, the predictive performance\nof deep learning models for COMEX copper futures gradually approaches that of the\nGARCH model. The increase in the QLIKE loss function for the recurrent neural network\nmodels is less pronounced compared to GARCH, indicating a more stable error rate as the\nforecast window extends. Furthermore, due to the inherent \"black-box\" nature of deep\nlearning models, their loss function values in some experimental cases even fall below those\nof the GARCH model. However, despite these improvements, the HAR model retains a\nclear and significant advantage in forecasting daily volatility. Its consistent performance\nacross different forecast horizons highlights its reliability, making it a superior model for\ndaily volatility predictions in this context.\n13\nReferences\nBucci, A. (2020). Realized volatility forecasting with neural networks. Journal of Finan-\ncial Econometrics, 18(3), 502–531.\nBuncic, D., & Moretto, C. (2015). Forecasting copper prices with dynamic averaging\nand selection models. The North American Journal of Economics and Finance, 33,\n1–38.\nColacito, R., Engle, R. F., & Ghysels, E.\n(2011).\nA component model for dynamic\ncorrelations. Journal of Econometrics, 164(1), 45–59.\nConrad, C., & Kleen, O. (2020). Two are better than one: Volatility forecasting using\nmultiplicative component garch-midas models. Journal of Applied Econometrics,\n35(1), 19–45.\nDíaz, J. D., Hansen, E., & Cabrera, G. (2021). Economic drivers of commodity volatility:\nThe case of copper. Resources Policy, 73.\nDuvhammar, M. (2018). Volatility of copper prices and the effect of real interest rate\nchanges. Swedish University of Agricultural Sciences.\nElder, J., Miao, H., & Ramchander, S. (2012). Impact of macroeconomic news on metal\nfutures. Journal of Banking & Finance, 36(1), 51–65.\nEngle, R. F., Ghysels, E., & Sohn, B. (2008). On the economic sources of stock market\nvolatility. In Afa 2008 new orleans meetings paper.\nEngle, R. F., Ghysels, E., & Sohn, B. (2013). Stock market volatility and macroeconomic\nfundamentals. Review of Economics and Statistics, 95(3), 776–797.\nGhysels, E., Santa-Clara, P., & Valkanov, R. (2004). The midas touch: Mixed data\nsampling regression models.\nGuzmán Barros, J. I., & Silva, E. (2018). Copper price determination: fundamentals\nversus non-fundamentals.\nHammoudeh, S., & Yuan, Y. (2008). Metal volatility in presence of oil and interest rate\nshocks. Energy Economics, 30(2), 606–620.\nLiu, R., Yang, J., & Ruan, C. Y. (2019). The impact of macroeconomic news on chinese\nfutures. International Journal of Financial Studies, 7(4), 63.\nPatton, A. J. (2011). Volatility forecast comparison using imperfect volatility proxies.\nJournal of Econometrics, 160(1), 246–256.\nRahimikia, E., & Poon, S.-H. (2020). Machine learning for realised volatility forecasting.\nAvailable at SSRN .\nRobert, E. F., et al. (2002). Dynamic conditional correlation: A simple class of multi-\nvariate generalized autoregressive conditional hetroscedasticity models. Journal of\nBusiness and Economic Statistics, 20(3), 339–350.\nRodikov, G., & Antulov-Fantulin, N. (2022). Can lstm outperform volatility-econometric\nmodels? arXiv preprint arXiv:2202.11581.\nSadorsky, P. (2014). Modeling volatility and correlations between emerging market stock\nprices and the prices of copper, oil and wheat. Energy Economics, 43, 72–81.\nSmith, K. L., & Bracker, K. (2003). Forecasting changes in copper futures volatility\nwith garch models using an iterated algorithm. Review of Quantitative Finance\nand Accounting, 20(3), 245–265.\nSreenu, N., & Rao, K.\n(2021).\nThe macroeconomic variables impact on commodity\nfutures volatility: A study on indian markets. Cogent Business & Management,\n8(1).\n14\nWang, L., Wang, H., & Wang, J. (2020). Research on the influence of economic policy\nuncertainty on the supply chain finance. In E3s web of conferences (Vol. 214).\nXiao, D., Su, J., & Ayub, B. (2022). Economic policy uncertainty and commodity market\nvolatility: implications for economic recovery. Environmental Science and Pollution\nResearch, 1–12.\nXiong, R., Nichols, E. P., & Shen, Y. (2015). Deep learning stock volatility with google\ndomestic trends. arXiv preprint arXiv:1512.04916.\nZhang, C., Zhang, Y., Cucuringu, M., & Qian, Z. (2022). Volatility forecasting with\nmachine learning and intraday commonality. arXiv preprint arXiv:2202.08962.\nZhang, Y., & Wang, R.\n(2022).\nCovid-19 impact on commodity futures volatilities.\nFinance Research Letters, 47.\nZheng, Y., Zhou, M., & Wen, F. (2021). Asymmetric effects of oil shocks on carbon\nallowance price: evidence from china. Energy Economics, 97.\n15\n",
  "categories": [
    "q-fin.MF",
    "cs.LG"
  ],
  "published": "2024-09-12",
  "updated": "2024-09-12"
}