{
  "id": "http://arxiv.org/abs/2410.17543v1",
  "title": "Unsupervised Low-dose CT Reconstruction with One-way Conditional Normalizing Flows",
  "authors": [
    "Ran An",
    "Ke Chen",
    "Hongwei Li"
  ],
  "abstract": "Deep-learning methods have shown promising performance for low-dose computed\ntomography (LDCT) reconstruction. However, supervised methods face the problem\nof lacking labeled data in clinical scenarios, and the CNN-based unsupervised\ndenoising methods would cause excessive smoothing in the reconstructed image.\nRecently, the normalizing flows (NFs) based methods have shown advantages in\nproducing detail-rich images and avoiding over-smoothing, however, there are\nstill issues: (1) Although the alternating optimization in the data and latent\nspace can well utilize the regularization and generation capabilities of NFs,\nthe current two-way transformation strategy of noisy images and latent\nvariables would cause detail loss and secondary artifacts; and (2) Training NFs\non high-resolution CT images is hard due to huge computation. Though using\nconditional normalizing flows (CNFs) to learn conditional probability can\nreduce the computational burden, current methods require labeled data for\nconditionalization, and the unsupervised CNFs-based LDCT reconstruction remains\na problem. To tackle these problems, we propose a novel CNFs-based unsupervised\nLDCT iterative reconstruction algorithm. It employs strict one-way\ntransformation when performing alternating optimization in the dual spaces,\nthus effectively avoiding the problems of detail loss and secondary artifacts.\nBy proposing a novel unsupervised conditionalization strategy, we train CNFs on\nhigh-resolution CT images, thus achieving fast and high-quality unsupervised\nreconstruction. Experiments on different datasets suggest that the performance\nof the proposed algorithm could surpass some state-of-the-art unsupervised and\neven supervised methods.",
  "text": "AN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n1\nUnsupervised Low-dose CT Reconstruction with\nOne-way Conditional Normalizing Flows\nRan An, Ke Chen‚àóand Hongwei Li‚àó\nAbstract‚ÄîDeep-learning methods have shown promising per-\nformance for low-dose computed tomography (LDCT) recon-\nstruction. However, supervised methods face the problem of\nlacking labeled data in clinical scenarios, and the CNN-based\nunsupervised denoising methods would cause excessive smoothing\nin the reconstructed image. Recently, the normalizing flows (NFs)\nbased methods have shown advantages in producing detail-rich\nimages and avoiding over-smoothing, however, there are still\nissues: (1) Although the alternating optimization in the data and\nlatent space can well utilize the regularization and generation\ncapabilities of NFs, the current two-way transformation strategy\nof noisy images and latent variables would cause detail loss and\nsecondary artifacts; and (2) Training NFs on high-resolution\nCT images is hard due to huge computation. Though using\nconditional normalizing flows (CNFs) to learn conditional prob-\nability can reduce the computational burden, current methods\nrequire labeled data for conditionalization, and the unsupervised\nCNFs-based LDCT reconstruction remains a problem. To tackle\nthese problems, we propose a novel CNFs-based unsupervised\nLDCT iterative reconstruction algorithm. It employs strict one-\nway transformation when performing alternating optimization in\nthe dual spaces, thus effectively avoiding the problems of detail\nloss and secondary artifacts. By proposing a novel unsupervised\nconditionalization strategy, we train CNFs on high-resolution\nCT images, thus achieving fast and high-quality unsupervised\nreconstruction. Experiments on different datasets suggest that\nthe performance of the proposed algorithm could surpass some\nstate-of-the-art unsupervised and even supervised methods.\nIndex Terms‚ÄîLow-dose CT, Iterative Reconstruction, Unsu-\npervised Learning, Conditional Normalizing Flows, Generative\nModels, Regularized Reconstruction\nI. INTRODUCTION\nComputed tomography (CT) is a widely used medical imag-\ning technique for detecting the inner structure of an object.\nIt‚Äôs known that excessive X-rays might cause potential harm\nto the human body, such as cancer risk and genetic hazards\n[1]. In medical diagnosis, the as low as reasonably achievable\nprinciple [2] was proposed to direct the use of X-ray doses.\nHowever, low-dose scanning will lead to noise in the pro-\njection data, thereby introducing severe noise and artifacts in\nthe reconstructed image [3]. Therefore, LDCT reconstruction\nhas always been a popular subject in the medical imaging\ncommunity.\nRan An is with the School of Mathematical Sciences, Capital Normal Uni-\nversity, Beijing 100048, CHINA, and also with the Centre for Mathematical\nImaging Techniques, University of Liverpool, Liverpool L69 7ZL, UK.\nKe Chen is with the Department of Mathematics and Statistics, University of\nStrathclyde, Glasgow G1 1XQ, UK, and also with the Centre for Mathematical\nImaging Techniques, University of Liverpool, Liverpool L69 7ZL, UK. (e-\nmail: k.chen@strath.ac.uk)\nHongwei Li is with the School of Mathematical Sciences, Capital Normal\nUniversity, Beijing 100048, CHINA. (e-mail: hongwei.li91@cnu.edu.cn)\nFor LDCT, some denoising strategies on post-processing re-\nconstructed images [4], [5], [6] and pre-processing projection\ndata [7], [8], [9] were proposed. Although easy and conve-\nnient, such methods ignore the consistency between image\nand projection data in the reconstruction procedure, usually\ncausing blurring and secondary artifacts in the reconstructed\nimage. Some other traditional methods introduce artificially\ndesigned priors (e.g. the total variation (TV) minimization\n[10]) in iterative reconstruction [11], [12], [13], achieving\nbetter consistency and results. However, these methods often\nsuffer from tedious tuning work for hyper-parameters and\nusually require a large number of iterations. In addition, the\naccuracy and scope of applicability of the artificial priors are\nalso issues worthy of attention.\nCompared with traditional methods, learning-based methods\nusually show advantages in reconstruction performance, which\nbenefits from the priors learned in the ‚ÄúBig Data‚Äù. Among\nthem, the sparse coding method represented by K-SVD [14]\nlearns the representation of image content and rebuilds the\ndenoised image. Recently, deep-learning (DL) methods have\nshown powerful modeling and data-fitting abilities, and the\nDL-based LDCT reconstruction methods have also demon-\nstrated success. For LDCT image post-processing, various\nneural network architectures such as FBPConvNet [15], RED-\nCNN [16], DIRE [17] and CTFormer [18] demonstrates good\nresults. However, their purely post-processing strategy still\nignores the image-data consistency and easily causes over-\nsmoothing and detail loss in the reconstructed images. To keep\na good consistency, some dual-domain denoising networks\nwere proposed to process the projection data and image jointly\nin a whole framework, such as DRCNN [19], DDPNet [20],\nDuDoUFNet [21] and DRONE [22]. Some other methods\nunroll regularized iterative algorithms into networks to per-\nform adaptive training of the hyperparameters, achieving out-\nstanding performance, representative methods include LEARN\n[23] and PD-Net [24]. Although these methods have shown\nexceptional performance in LDCT reconstruction, they follow\na supervised learning framework and require a large amount\nof labeled data for training, which is difficult to fulfill in\nactual CT applications due to some ethical principles and the\ndifficulties of achieving completely consistent repeat scans.\nTo deal with the reliance on labeled data, some unsupervised\nstrategies were proposed for LDCT reconstruction. Some work\nsimulate paired data with generative adversarial networks\n(GAN) [25] training on unpaired data, representative methods\nincluding GAN-CIRCLE [26], Cycle-Free CycleGAN [27],\nAdaIN-Based Tunable CycleGAN [28], and IdentityGAN [29].\nHowever, they mostly rely on the cyclic consistency loss,\narXiv:2410.17543v1  [eess.IV]  23 Oct 2024\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n2\nwhich usually causes unstable training of GAN. Moreover,\nensuring the authenticity and accuracy of the generated paired\ndata is not easy. On the other hand, some unsupervised LDCT\nimage denoising methods based on the idea of Noise2Noise\n(N2N) were proposed [30], [31], [32], [33]. However, these\nmethods still require pairs of noisy images of the same scene,\nwhich are still difficult to collect in practical applications.\nTherefore, some self-supervised methods based on the noisy\nimage itself were proposed, such as Noise2Sim [34] and\nNoise2inverse [35]. Some others employ dual-domain de-\nnoising strategy to ensure consistency, such as ETSRP [36],\nSSDDNet [37] and SDBDNet [38]. These self-supervised\nmethods show performance close to supervised ones. However,\ntheir pursuit of averaging makes them prone to cause over-\nsmoothing and detail loss. To enhance the sharpness and\ndetails of the reconstructed image, GAN was utilized to\nprocess the output images of denoising networks, represen-\ntative methods including DD-UNET [39] and CLEAR [40].\nHowever, this approach still faces the collapse and accuracy\nissues of GAN.\nGenerative models such as the normalizing flows (NFs)\n[41] and diffusion models [42] have also been employed to\nlearn priors in clean images to serve as regularization terms\nin iterative reconstructions. Wei et al. proposed an alternating\nminimization algorithm with two-way transformation, i.e. to\nand from the latent variable by NFs to solve imaging inverse\nproblems [43]. Fabian et al. proposed PatchNR [44] that\ntrains NFs on normal-dose image patches and makes it the\nregularization term in iterative reconstruction. Similarly, He et\nal. proposed EASEL [45] with score-based diffusion model\n[46], Liu et al. and Xia et al. proposed Dn-Dp [47] and DPR-\nIR [48] respectively based on denoising diffusion probabilistic\nmodel (DDPM) [49], to conduct regularized iterative LDCT\nreconstruction. Such methods follow an excellent unsupervised\nstrategy that only requires normal-dose images for training,\nwhich fits actual applications well. However, these methods\nstill carry on some problems. Due to the huge computational\nburden, it is hard to train NFs on high-resolution images\n(such as those with a size of 512 √ó 512). Although some\ndimension-reduction [50] and conditional probability learning\n[51] strategies have been proposed to solve this problem, the\nreduction of image dimension would inevitably lead to in-\nformation loss, and existing conditionalization strategies often\ncome with the requirement for labeled data, which makes the\napplication of NFs in unsupervised LDCT reconstruction still\nfaces great limitations. In addition, the two-way transformation\nof NFs between the noisy data and latent variables would lead\nto distribution bias thus causing detail loss and secondary\nartifacts in the reconstructed image. A well-recognized lim-\nitation of diffusion-model-based methods is that they often\nrequire quite a long reconstruction time as they usually need\neven more than a thousand iterative sampling steps. Although\nthere exist fast sampling methods, e.g. DDIM [52] and DPM-\nsolver [53], to reduce the iterative steps to 50 and even 10-20,\ntheir performance with inverse problems, especially for LDCT\nreconstruction, has yet to be verified.\nThis paper proposes a novel LDCT iterative reconstruction\nalgorithm by improving the current NFs-based methods. Our\nmethod achieves high-quality and efficient reconstruction by\nemploying an unsupervised framework that only requires\nnormal-dose images for distribution learning. To better utilize\nthe regularization and generation capabilities of NFs, we carry\nout dual-space alternating iterative reconstruction in the data\nand latent space. Instead of using the two-way transformation\nof NFs in the dual spaces, we propose a novel algorithm that\nonly conducts strict one-way generation transformation thus\neffectively avoiding introducing secondary artifacts. Moreover,\nto efficiently train high-quality NFs on high-resolution im-\nages for unsupervised LDCT reconstruction, we propose a\nnovel unsupervised conditionalization method and train con-\nditional normalizing flows (CNFs), thus making our network\neasily act on high-resolution CT images. By utilizing the\nlinearization technique and the ordered-subset simultaneous\nalgebraic reconstruction technique (OS-SART) [54] for fast\nincremental reconstruction, our method achieves computation-\nefficient LDCT reconstruction. Our method performs similarly\nto supervised ones as an unsupervised framework and is faster\nthan the popular diffusion-model-based iterative reconstruction\nmethods. Experiments on two datasets demonstrate that our\nmethod effectively solves the main problems of the current\nNFs-based LDCT reconstruction methods. Compared to state-\nof-the-art unsupervised and even supervised LDCT reconstruc-\ntion methods, our method shows promising performance. The\nmain contributions of our work can be summarized as follows:\n‚Ä¢ We propose a novel NFs-based unsupervised LDCT itera-\ntive reconstruction algorithm, which performs regulariza-\ntion in the data and latent spaces of the NFs and employs\na strict one-way transformation. While giving full play\nto the regularization and generation capabilities of NFs,\nour method avoids the detail loss and secondary artifacts\ncaused by the two-way transformation of noisy images.\n‚Ä¢ We propose an unsupervised conditionalization strategy\nfor the CNFs-based LDCT reconstruction problem that\ndoes not rely on paired training data. Based on this\nstrategy we train unsupervised CNFs thus achieving ef-\nficient training on high-resolution CT images, and fast\niterative reconstruction. To the best knowledge of us, this\nis the first time CNFs were incorporated into the LDCT\nreconstruction procedure.\n‚Ä¢ Experiments on different datasets demonstrate the high\nperformance and fast reconstruction speed of our method\ncompared with some state-of-the-art learning-based iter-\native reconstruction methods.\nII. RELATED WORK\nA. NFs-based LDCT Reconstruction\nThe forward projection process of LDCT can be modeled\nin the following form:\ny = Ax + Œ∑,\n(1)\nwhere y ‚ààRm denotes the vectorized low-dose projection\ndata, x ‚ààRn is the vectorized ideal clean image, Œ∑ ‚ààRm\nis the low-dose noise introduced by low-dose scanning, and\nA ‚ààRm√ón signifies the known projection matrix.\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n3\nGiven the low-dose projection data y, the ideal reconstructed\nimage ÀÜx can be acquired by maximizing the following loga-\nrithmic probability:\nÀÜx = arg\nx max log p(y|x) + log p(x).\n(2)\nwhere p(y|x) is the posterior probability of y given x, and p(x)\nis the prior probability of x. Assuming p(y|x) ‚àºN\n\u0000Ax, œÉ2\n0\n\u0001\n,\nequation (2) leads to a minimization problem:\nÀÜx ‚ààarg\nx min\n1\n2œÉ2\n0\n‚à•y ‚àíAx‚à•2\n2 ‚àílog p(x).\n(3)\nThe prior probability p(x) plays an important role in the\nabove minimization problem, how to accurately and succinctly\ndescribe it is crucial. An emerging approach is to learn p(x)\nwithin a large number of normal-dose images by the generative\nmodel NFs [41]. In general, NFs learn a differentiable bijective\nmapping FŒ∏ = G‚àí1\nŒ∏\nparameterized by Œ∏ between the data\ndistribution p(x) and a simple distribution p(z) such as the\nstandard Gaussian distribution p(z) ‚àºN(0, 1). By a trained\nNFs FŒ∏, each image sample x has a unique corresponding\nlatent variable z and can be bidirectionally mapped through\nthe invertible network:(\nz = FŒ∏(x),\nx = GŒ∏(z).\n(4)\nThen, the prior probability p(x) can be expressed as:\nlog p(x) = log p(z) + log |det(DFŒ∏(x))| ,\n(5)\nwhere DFŒ∏(x) denotes the Jacobian of FŒ∏ concerning x,\nand its determinant det(DFŒ∏(x)) accounts for the change in\ndensity from the transformation FŒ∏. It is noted that the second\nterm on the right side of the equation (5) is a constant and\np(z) ‚àºN(0, 1). Introducing (5) and x = GŒ∏(z) into (3), we\ncan get a new minimization problem about z:\nÀÜz ‚ààarg\nz min ‚à•y ‚àíAGŒ∏(z)‚à•2\n2 + Œª‚à•z‚à•2\n2.\n(6)\nwhere Œª is a parameter related to œÉ2\n0 that controls the regular-\nization effect.\nTo solve the above problem (6), various methods have\nbeen proposed. In [55] and [56], the authors propose to\noptimize z directly in the latent space by gradient descent.\nAlthough this method well utilizes the generation ability of\nNFs and produces detail-rich images, it lacks constraints on\nthe x-space and easily falls into a local optimum, usually\nleading to suboptimal reconstruction accuracy. In [44] and\n[50], the authors propose to perform optimization in the x-\nspace. They make GŒ∏(z) = x and z = FŒ∏(x) in (6) and\nupdate x with gradient descent too. This strategy can keep\nbetter reconstruction accuracy, however, it does not utilize\nthe generation ability of NFs and easily causes excessive\nsmoothing. To better use the regularization and generation\ncapabilities of NFs, Wei et al. [43] proposed an alternating\noptimization strategy. They alternately update x and z in\nthe data and latent space and conduct domain transfer by\nthe two-way transformation of the NFs (i.e., x = GŒ∏(z)\nand z = FŒ∏(x)). This method achieves effective dual-space\nalternating optimization and obtains promising results on the\nLow-dose\nNormal-dose\nTwo-way NFs\nFig. 1.\nThe reconstructed images of the two-way NFs. Compared to the\nnormal-dose images, structure distortion and noise residuals can be easily\nobserved.\ntasks involving natural images. However, it still presents\ndrawbacks in LDCT reconstruction when high accuracy in the\nreconstructed image is crucial. Firstly, it does not constrain\nthe consistency of the x and z in two adjacent iterations,\nwhich might adversely affect the data fidelity and thus the\naccuracy of the reconstructed image. More importantly, in\nthe two-way transformation, the image to be transformed into\nthe latent space is not a normal-dose image following the\ndistribution of training samples but a noisy one. Therefore\ndirectly transforming it into the latent space by z = FŒ∏(x)\nwould cause a serious shift of the latent variable which\nshall affect subsequent iterations. In LDCT reconstruction,\nsuch problems would easily cause detail loss and introduce\nsecondary artifacts in the reconstructed image, especially when\nthe noise level is high. As shown in Figure 1, compared\nto the normal-dose images, the reconstructed images by the\ntwo-way NFs (TW-NFs) show severe artifacts and structure\ndistortion. In [43], the authors propose to use the unfolding\nstrategy to improve reconstruction performance, however, this\nadditionally brings requirements for paired training data which\nis difficult to fulfill in clinical LDCT reconstruction.\nB. Conditional Normalizing Flows\nAlthough NFs exhibit good mathematical properties and\nenjoy efficient sampling and easy likelihood evaluation, their\ncomplex network structures with high-volume parameters\nmake them quite compute-intensive. For generating small-size\nimages such as those sized of 64 √ó 64, NFs are more than\ncapable. However, when trained on high-resolution images\nsuch as those sized of 512 √ó 512, the memory scale and\ntraining time will become huge and unacceptable. As a case,\nit takes about a week to train a Glow [57] (a classic NFs\nmodel) for 5-bits 256 √ó 256 sized images with 40 GPUs [50].\nTo achieve efficient training on high-resolution images, some\nnew training strategies have been proposed to reduce the com-\nputation. Kothari et al. [50] propose injective flows Trumpets\nto reduce the dimension of the high-resolution images to a\nsmall size and train small-scale NFs. Although significantly\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n4\nreducing the computation cost and successfully training NFs\non high-resolution images, the dimension reduction would\ninevitably result in information loss, leading to detail loss in\nthe generated images. On the other hand, by introducing the\nalready known information as conditions, conditional normal-\nizing flows (CNFs) [58] were proposed to learn conditional\nprobability instead of the complete probability p(x). CNFs\nintroduce conditions into the training phase thus helping to\nease the training on high-resolution images. Furthermore,\nCNFs can also introduce conditions into inference and provide\ninformation for image generation, making it more efficient and\nmeeting the specific requirements of practical applications.\nSimilar to (4), the bidirectional process of CNFs with the\ncondition c can be expressed as:\n(\nz = FŒ∏(x, c),\nx = GŒ∏(z, c).\n(7)\nAlthough CNFs can achieve training on high-resolution\nimages and improve generation efficiency, the application of\nCNFs still presents challenges in unsupervised LDCT recon-\nstruction. Current CNFs-based LDCT reconstruction methods\noften rely on paired data for their conditionalization [51], [59],\nwhich is hard to implement in an unsupervised framework.\nBesides, they directly set the condition as the low-dose image,\nwhich might introduce misleading information such as noise\nand artifacts into the inference procedure. Although Wolf et\nal. [60] proposed a down-sampling conditionalization method\nfor unpaired image denoising, this strategy cannot work well\nwhen the low-dose noise and artifacts are severe. On the other\nhand, existing methods usually utilize CNFs for pure image\ngeneration rather than in a reconstruction procedure [51], [59],\n[61], which would cause inconsistency between the projection\ndata and reconstructed image, leading to bad accuracy of the\nimage structures.\nIII. METHODS\nBased on CNFs, we propose an end-to-end unsupervised\niterative LDCT reconstruction algorithm. Our method consists\nof three key ingredients: the unsupervised conditionalization\nstrategy, the one-way iterative LDCT reconstruction algorithm,\nand the network of the CNFs. In this section, we will introduce\nthese three parts in detail.\nA. Unsupervised Conditionalization Strategy\nIn the unsupervised training phase of CNFs, only normal-\ndose images are accessible, therefore the conditions should\ncome from the normal-dose images themselves to make it an\nunsupervised framework. On the other hand, in the inference\nstage, the only known information will be the low-dose projec-\ntion data, which also means the condition should come from\nthe low-dose data itself. To fit the training setup, the conditions\nin the two stages should be consistent (i.e. following the same\ndistribution). Therefore, we propose the following two key\npoints that the conditions should meet:\n‚Ä¢ The conditions should contain most of the structure and\nfeature information in the ideal clean image, while not\nLow-dose\nNormal-dose\nND Condition\nLD Condition\nFig. 2. Condition examples generated with the BM3D denoiser.\ncarrying redundant information such as excessive noise\nand artifacts.\n‚Ä¢ The two conditions corresponding to the normal-dose and\nlow-dose data of the same object should have a high\ndegree of similarity and, ideally should be the same.\nBased on the above two key points, we propose a new con-\nditionalization method for CNFs-based unsupervised LDCT\nreconstruction. Specifically, for the low-dose projection data\ny, to get the intuitive image information, we first reconstruct\nit into an image x with a reconstruction operator R:\nx = R(y).\n(8)\nThen we remove most of the noise and artifacts in the\nimage by a plug-and-play denoiser D (e.g. BM3D [62], NLM\n[63] and DnCNN [64]) and a high-frequency-filter wavelet\nreconstruction operator W:\nc\n‚Ä≤ = W(D(x)).\n(9)\nFinally we add low-level Gaussian noise n ‚àºN\n\u00000, œÉ2\n1\n\u0001\nto c\n‚Ä≤\nto enhance the robustness of the condition:\nc = c\n‚Ä≤ + n,\n(10)\nwhere œÉ1 is the standard deviation of the added noise. The\nwhole process C for generating the condition c from the\nprojected data y can be expressed as:\nc = C(y) = W(D(R(y))) + n.\n(11)\nIn the training stage, we can substitute R(y) in the above\nequation with the normal-dose image x and use the same W\nand D to obtain the conditions of the normal-dose images. It\nis worth mentioning that although we use the denoiser on the\nnormal-dose image here, it will not seriously destroy the image\nstructures and details, and can produce a condition consistent\nwith the low-dose image.\nBy our conditionalization method, we can get the conditions\nof both the normal-dose and low-dose data for unsupervised\nLDCT reconstruction. To evaluate the quality of the obtained\nconditions and adjust the parameters (e.g. The noise level pa-\nrameter of BM3D or NLM) in our conditionalization method,\na pair of normal-dose and low-dose data is needed, the criteria\nare set as the SSIM [65] between the paired conditions and\nthe SSIM between them and the clean normal-dose image.\nGenerally, a group of high SSIM means good quality of the\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n5\nconditions. As examples, conditions generated by the BM3D\ndenoiser are shown in Figure 2.\nB. One-way CNFs LDCT Reconstruction Algorithm\nTo tackle the problems of the current dual-space alternating\noptimization methods, we propose a novel iterative reconstruc-\ntion algorithm. Our method has two main improvements: (1).\nTo keep the consistency of x and z in iterations, we introduce\nconstraint terms and update them separately; (2). Instead of\nthe two-way transformation strategy, we adopt a strict one-\nway transformation between the data x and the latent variable\nz in the alternating optimization, thus effectively avoiding\nsecondary artifacts. In detail, by introducing the trained CNFs\nGŒ∏, we can reformulate the problem (6) into the following\ndouble-variable minimization problem with a constraint term:\n(ÀÜx, ÀÜz) = arg\nx,z min ‚à•y ‚àíAx‚à•2\n2 + Œª‚à•z‚à•2\n2 + œÉ ‚à•x ‚àíGŒ∏(z, c)‚à•2\n2 ,\n(12)\nwhere œÉ is a manual parameter to constrain the proximity\nbetween x and GŒ∏(z, c). With the incremental proximal-point\nmethod, this problem can be separated into the following two\nsub-problems:\nxn+1 = arg\nx min ‚à•y ‚àíAx‚à•2\n2 + œÉ ‚à•x ‚àíGŒ∏(zn, c)‚à•2\n2\n+ r1 ‚à•x ‚àíxn‚à•2\n2 ,\n(13)\nand\nzn+1 = arg\nz min Œª‚à•z‚à•2\n2 + œÉ\n\r\rxn+1 ‚àíGŒ∏(z, c)\n\r\r2\n2\n+ r2 ‚à•z ‚àízn‚à•2\n2 ,\n(14)\nwhere r1 and r2 are two manual parameters which control\nthe proximity of x and z in two adjacent iterations. It is\nworth noting that we only introduce the generation process\nx = GŒ∏(z, c) of the CNFs here and conduct a strict one-way\ntransformation from the latent variable z to the image x, so\nthat the problems of detail loss and secondary artifacts come\nwith the two-way transformation are neatly avoided.\nThe sub-problem (13) admits a closed-form solution:\nxn+1 = (AT A + œÉI + r1I)‚àí1(AT y + œÉGŒ∏(zn, c) + r1xn).\n(15)\nTo solve the sub-problem (14), we need the derivative of\nGŒ∏(z, c) with respect to z. However, even though the CNFs\nare differentiable, it is hard to express the derivative of such a\nnetwork to a variable. To deal with this problem, we linearize\nthe second term in (14) which is hard to differentiate. Let\ns(z) =\n\r\rxn+1 ‚àíGŒ∏(z, c)\n\r\r2\n2, based on the diffeomorphism\nproperty of the CNFs GŒ∏, s(z) can be approximated by its\nfirst-order Taylor expansion at zn:\ns(z) ‚âàs(zn)+ < s\n‚Ä≤(zn), (z ‚àízn) >=\n\r\rxn+1 ‚àíGŒ∏(zn, c)\n\r\r2\n2\n‚àí2G\n‚Ä≤\nŒ∏(zn, c)(xn+1 ‚àíGŒ∏(zn, c))(z ‚àízn).\n(16)\nBy substituting this approximation into the sub-problem (14),\nthe solution zn+1 is given by:\nzn+1 = œÉG\n‚Ä≤\nŒ∏(zn, c)(xn+1 ‚àíGŒ∏(zn, c)) + r2zn\nŒª + r2\n,\n(17)\nwhere the G\n‚Ä≤\nŒ∏(zn, c)(xn+1 ‚àíGŒ∏(zn, c)) can be accessed by\nthe automatic derivation of the following loss to zn with the\nPytorch functions:\nL = ‚àí1\n2\n\r\rxn+1 ‚àíGŒ∏(zn, c)\n\r\r2\n2 .\n(18)\nIn summary, the iteration process of our unsupervised one-\nway CNFs reconstruction algorithm can be expressed as:\nÔ£±\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥\nxn+1 = (AT A + œÉI + r1I)‚àí1(AT y + œÉGŒ∏(zn, c) + r1xn),\nzn+1 = œÉG\n‚Ä≤\nŒ∏(zn, c)(xn+1 ‚àíGŒ∏(zn, c)) + r2zn\nŒª + r2\n,\nÀÜx = GŒ∏(ÀÜz, c) = GŒ∏(zK, c),\n(19)\nwhere ÀÜz is the final output z of the Kth iteration, ÀÜx is the final\nreconstructed image generated by the CNFs with ÀÜz.\nIn the iteration of xn+1, the inverse of (AT A + œÉI + r1I)\nis required for the updating. However, since the projection\nmatrices A corresponding to each projection angle are differ-\nent, using the matrix-form A in computation is impractical\ndue to the huge storage and time consumption. On the other\nhand, if we use the operator form of A, solving the inverse of\n(AT A + œÉI + r1I) will be difficult. Therefore, we employ\na two-step incremental reconstruction strategy to calculate\nan approximation to xn+1. In detail, we first reconstruct an\nintermediate image xn+ 1\n2 by the ordered-subset simultaneous\nalgebraic reconstruction technique (OS-SART) [54] with xn\nas the initial value:\nxn+ 1\n2 = OS-SART(xn, y, œâ)\n(20)\nwhere œâ is the relaxation factor. This step can be seen as\nminimizing the first term in (13). It is worth mentioning\nthat using OS-SART to solve the fidelity term here is a\nmore reasonable way than minimizing the l2 norm, because\nmodeling the low-dose noise of the projection data with a\nfix-variance Gaussian distribution is not accurate, while the\nreconstruction process of OS-SART can respect the noise\ncharacteristics better. In the second step, the solution xn+1\ncan be expressed as the following form without any matrix\ninversion:\nxn+1 = xn+ 1\n2 + œÉGŒ∏(zn, c) + r1xn\n1 + œÉ + r1\n.\n(21)\nThis step can be seen as minimizing the remaining terms in\n(13). For the OS-SART, we set the number of iterations as\n1 and use a small and carefully tuned œâ, aiming for a good\nbalance between the data fidelity and CNFs priors which could\navoid structure distortion and inadequate denoising. Overall,\nthe flow of our one-way CNFs LDCT reconstruction algorithm\ncan be summarized as Algorithm 1.\nC. Network\nThe overall network of our CNFs is composed of a backbone\nNFs network and a condition module. The NFs consists of 4\nflow blocks each containing 12 tandem combinations of the\nActnorm layer, the invertible 1 √ó 1 convolutional layer and\nthe affine coupling layer, similar to the famous normalizing\nflows Glow [57], and the number of the feature channels in\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n6\nActnorm\nInv 1x1 Conv\nAffine Coupling\nSqueeze\nSplit\nFlow-Block\nFlow-Block\nFlow-Block\nx12\nùîÅ\nùîÉ\nFlow-Block\nCondition\nFig. 3. The network structure of our conditional normalizing flows.\nAlgorithm 1 One-way conditional normalizing flows\n(OW-CNFs) unsupervised LDCT reconstruction algorithm\n1: Input: The noisy projection data y, the hyperparameters\nŒª, œÉ, r1 and r2, the relaxation parameter œâ of OS-SART,\nthe random Gaussian initialization z0 and x0 = GŒ∏(z0, c),\nand the number of iterations K.\n2: Operators: The NFs GŒ∏ and the OS-SART.\n3: Output: The final reconstructed image ÀÜx.\n4:\nfor n = 0, ..., K ‚àí1:\n5:\nxn+ 1\n2 = OS-SART(xn, y, œâ)\n6:\nxn+1 = xn+ 1\n2 + œÉGŒ∏(zn, c) + r1xn\n1 + œÉ + r1\n7:\nzn+1 = œÉG\n‚Ä≤\nŒ∏(zn, c)(xn+1 ‚àíGŒ∏(zn, c)) + r2zn\nŒª + r2\n.\n8:\nend\n9:\nÀÜx = GŒ∏(zK)\n10: return ÀÜx\neach convolutional layer is 512. In the condition module, the\ncondition c will be incorporated into each affine coupling layer\nof the backbone NFs by concatenation with the mainstream\nfeatures. The overall network structure of our CNFs is shown\nin Figure 3.\nIV. EXPERIMENTS\nA. Experimental Setup\nTo evaluate the performance of the proposed one-way con-\nditional normalizing flows (OW-CNFs) unsupervised LDCT\nreconstruction algorithm, we performed experiments on two\ndatasets. We evaluated the reconstructed images of our method\nby visual effects and quantitative indicators, and compared\nthe results with several state-of-the-art deep-learning methods,\nincluding some popular unsupervised generative-model-based\nmethods such as PatchNR [44], EASEL [45] and DPR-IR [48],\nand supervised LDCT denoising networks such as RED-CNN\n[16] and CTFormer [18].\nThe experiments were conducted on two datasets: (1) The\nrandom rectangle models (RRM) dataset and (2) The LIDC-\nIDRI dataset [66]. The RRM dataset is home-made, consisting\nof a randomly generated series of images, each containing\na large ring and ten parallel stripe rectangles with different\nRRM\nLIDC-IDRI\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFig. 4.\nSome examples of the ‚ÄùRRM‚Äù dataset ((a)-(c)) and ‚ÄùLIDC-IDRI‚Äù\ndataset ((d)-(f)).\nlengths and gray values, and some examples are shown in\nFigure 4(a)-(c). The reconstruction performance of different\nmethods can be directly recognized from the reconstruction\nof those rectangular stripes. This dataset contains 1024 images\nfor training, 128 images for validation and 32 for testing, every\nimage has a size of 128 and a gray value range of [0, 1.0]. The\nLIDC-IDRI dataset is a public CT image dataset comprising\n241689 normal-dose slices of 1012 patients. We randomly\npicked 4409 images from this dataset as the training set, 272\nfor validation, and 30 for testing. Some examples are shown in\nFigure 4(d)-(f). All the picked CT images have a Hounsfield\nunits (HU) range of [‚àí1024, 2048].\nThe normal-dose and low-dose projection data were gener-\nated based on the above datasets with a simulated projection\nalgorithm under a fan-beam imaging system. For the RRM\ndataset, we use 360 projection views uniformly distributed\nin the range [0, 2œÄ] and a linear detector with 256 cells. For\nthe LIDC-IDRI dataset, we set both the projection views and\nthe number of detector cells as 1000. We generated the clean\nprojection data and added Poisson noise to the incident rays\nto simulate the low-dose projection data:\nyn = ‚àíln(Id\nI0\n), Id ‚àºPoisson{I0 √ó e‚àíyc},\n(22)\nwhere yc is the clean projection data and yn is the noisy low-\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n7\n(a)Normal-dose\n     \n(g) DPR-IR\n     36.51/0.931\n(b) Low-dose\n     20.76/0.571\n(c) NLM\n     26.48/0.888\n(d) K-SVD\n     26.65/0.761\n(e) DIP-TV\n     25.58/0.807\n(f) EASEL\n     33.21/0.887\n(h) PatchNR\n     30.02/0.922\n(i) TW-CNFs\n     26.38/0.756\n(j) OW-CNFs (Ours)\n     39.61/0.977\n(k) RED-CNN\n     38.03/0.969\n(l) CTFormer\n     31.90/0.920\nFig. 5. Reconstruction results of each method on the ‚ÄùRRM‚Äù dataset at dose I0 = 1 √ó 103. The display window of the gray value range is set to [0, 1.0].\ndose one. I0 and Id are the number of incident and collected\nphotons, respectively. Generally, a smaller I0 means a lower\ndose and the projection data shall be more noisy. Based on\nthis principle, we set I0 = 1 √ó 106 to simulate the normal-\ndose projection data, and the normal-dose images for reference\nwere reconstructed on these projection data by OS-SART. For\ngenerating the low-dose projection data, we set I0 = 1 √ó 103\non the RRM dataset, and I0 = 1 √ó 104 on the LIDC-IDRI\ndataset. The projection operator and OS-SART were coded\nwith CUDA kernels wrapped by the Cupy library (https://\ngithub.com/cupy/cupy).\nWe chose two traditional image denoising methods NLM\n[63] and K-SVD [14], an unsupervised deep-learning method\nDIP-TV [67], an NFs-based regularization reconstruction\nmethod PatchNR [44], two diffusion-model-based iterative\nreconstruction methods EASEL [45] and DPR-IR [48], and\ntwo popular supervised LDCT image denoising methods RED-\nCNN [16] and CTFormer [18], as the comparative methods.\nWe also ran the two-way iterative reconstruction algorithm\n[43] introduced in Section 2.A with the same CNFs as in\nour method, here we use ‚ÄúTW-CNFs‚Äù to refer to it. As\nthe evaluation indicators, we selected the commonly used\nPSNR and SSIM [65] for image quality assessment. Codes\nfor all the comparative methods are publicly available. In the\ntraining phase of each method, we used the loss function and\noptimizer as described in the original training method, and\nselected the proper learning rate and mini-batch size. In the\nconditionalization part of our proposed OW-CNFs, we chose\nBM3D [62] as the denoiser D. All the experiments were\nperformed on a server running Ubuntu 20.04.5 with Python\n3.11, PyTorch 1.12.1, cuda 11.3, with a Nvidia Tesla V100\nGPU card.\nB. Results\nOn both the RRM and LIDC-IDRI datasets, the proposed\nOW-CNFs shows outstanding performance. Figure 5 shows\none group of the reconstruction results of each method on\nthe RRM dataset at dose I0 = 1 √ó 103. The reconstruction\nresult of the proposed OW-CNFs presents comparable quality\nto the state-of-the-art generative-model-based methods and\neven the supervised methods. As shown in the zoomed-in\nareas, traditional methods NLM and K-SVD do not perform\nwell. The unsupervised method DIP-TV also does not work\nwell due to its weak priors. The two diffusion-model-based\nmethods EASEL and DPR-IR show good results in effectively\nreconstructing the stripes, but both present noise residues and\nEASEL is more serious. The NFs-based method PatchNR\nperforms denoising well but causes many block artifacts in\nthe reconstructed image. This may be because PatchNR learns\npriors in image patches rather than the whole image, thus the\nglobal information would be lost to some extent and it is prone\nto mistakenly process large noise blocks as image structures.\nTW-CNFs shows noise retention and structure deformation in\nthe reconstructed image: in the zoomed-in area, the length of\nthe lower stripe is incorrect and its right end is severely blurred\nand even missing. Although the two supervised methods RED-\nCNN and CTFormer demonstrate satisfactory denoising, it is\nworth noting that the proposed unsupervised OW-CNFs has\ncomparable performance with these two supervised methods\nand is even superior in evaluation indicators. While achieving\neffective denoising, the proposed OW-CNFs accurately recon-\nstruct every stripe in the image.\nFigure 6, 8 and 9 show some comparisons of the reconstruc-\ntion results on the LIDC-IDRI dataset at dose I0 = 1√ó104. On\nthis dataset, the proposed OW-CNFs also presents outstanding\nperformance. As shown in the zoomed-in areas, OW-CNFs\ndemonstrates good accuracy on recovering image structures\nwhile achieving effective denoising. In contrast, although the\ndiffusion-model-based methods EASEL and DPR-IR show\ngood ability in recovering structures, they suffer from noise\nand artifacts, which might obscure image details. The NFs-\nbased method PatchNR still shows a lot of pseudo structures\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n8\n(a)Normal-dose\n     \n(g) DPR-IR\n     33.34/0.834\n(b) Low-dose\n     21.26/0.430\n(c) NLM\n     29.53/0.744\n(d) K-SVD\n     28.32/0.659\n(e) DIP-TV\n     30.38/0.771\n(f) EASEL\n     31.66/0.792\n(h) PatchNR\n     30.26/0.758\n(i) TW-CNFs\n     29.82/0.750\n(j) OW-CNFs (Ours)\n     33.48/0.838\n(k) RED-CNN\n     32.73/0.829\n(l) CTFormer\n     32.66/0.822\nFig. 6. Reconstructed image results of each method on the ‚ÄùLIDC-IDRI‚Äù dataset at dose I0 = 1 √ó 104. The display window is [200, 1430]HU.\nTABLE I\nTHE AVERAGE INDICATORS (PSNR(DB)/SSIM) OF EACH METHOD ON THE\nTEST SETS OF ALL THE DATASETS.\nRRM\nLIDC-IDRI\nMethod\nPSNR\nSSIM\nPSNR\nSSIM\nSART\n20.22\n0.559\n20.31\n0.400\nNLM\n25.88\n0.872\n29.01\n0.714\nK-SVD\n26.23\n0.749\n27.76\n0.628\nDIP-TV\n24.93\n0.793\n29.36\n0.726\nEASEL\n32.81\n0.878\n29.75\n0.717\nDPR-IR\n37.79\n0.965\n32.80\n0.804\nPatch-NR\n29.19\n0.926\n29.26\n0.727\nTW-CNFs\n31.97\n0.928\n29.48\n0.730\nOW-CNFs\n38.60\n0.972\n33.14\n0.819\nRED-CNN\n37.30\n0.967\n32.52\n0.809\nCTFormer\n31.02\n0.912\n32.25\n0.795\nin its results. The TW-CNFs shows more obvious structure de-\nformation and severe loss of image details. Results of the two\nsupervised methods RED-CNN and CTFormer show better\ncontrast and line smoothing, however, they still cannot avoid\ndistortion of structures and the detail loss in the reconstructed\nimages. The average indicators on all the test sets are shown in\nTable I, the proposed OW-CNFs has both the highest average\nPSNR and SSIM, even surpassing the two supervised learning\nmethods RED-CNN and CTFormer.\nTo test the reconstruction speed of the proposed OW-CNFs,\nwe compared the average iteration number and reconstruction\ntime of each generative-model-based method on the test sets.\nThe images in the RRM dataset have a small size of 128√ó128,\nwhich allows us to directly train unconditional NFs and use\nthe same one-way method for reconstruction. We also included\nthis in the comparison and referred to it as OW-NFs. As\nshown in Table II, our OW-CNFs has an excellent balance\nbetween performance and speed. As diffusion-model-based\nmethods, EASEL and DPR-IR have to execute iterations on\nevery noise level, which leads to more iterations and a longer\nreconstruction time. PatchNR has a fast speed because of\nTABLE II\nTHE AVERAGE INDICATORS (PSNR(DB)/SSIM) AND AVERAGE INFERENCE\nTIME OF EACH GENERATIVE-MODEL-BASED METHOD ON THE TEST SET.\nMethod\nPSNR\nSSIM\nIters\nTime\nEASEL\n32.81\n0.878\n1800\n700s\nDPR-IR\n37.79\n0.965\n1000\n405s\nPatch-NR\n29.19\n0.926\n1102\n102s\nOW-NFs\n39.08\n0.974\n1049\n1422s\nOW-CNFs\n38.60\n0.972\n55\n49s\n31.00\n32.00\n33.00\n34.00\n35.00\n36.00\n37.00\n38.00\n39.00\n0.01\n0.05\n0.10\n0.15\n0.20\nPSNR (db)\nœâ\nRRM\nLIDC-IDRI\n31.00\n32.00\n33.00\n34.00\n35.00\n36.00\n37.00\n38.00\n39.00\n0.01\n0.05\n0.10\n0.15\n0.20\nPSNR (db)\nœâ\nRRM\nLIDC-IDRI\nFig. 7. The trend of average PSNR under different œâ.\nits simpler way of regularization, however its performance is\nunsatisfactory. Although OW-NFs without the use of condi-\ntion shows better indicators than OW-CNFs, iterating in the\ncomplete latent space makes it requires much more iterations\nand reconstruction time than OW-CNFs. In contrast, although\nthe performance of the proposed OW-CNFs is slightly lower\nthan the unconditional OW-NFs, it achieves good performance\nin much fewer iterations and less time, showing significant\nadvantages in practicability.\nIn our OW-CNFs, the relaxation parameter œâ of OS-SART\nplays an important role in balancing the data fidelity and CNFs\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n9\n(a)Normal-dose\n     \n(g) DPR-IR\n     31.73/0.766\n(b) Low-dose\n     18.33/0.347\n(c) NLM\n     28.22/0.658\n(d) K-SVD\n     26.28/0.548\n(e) DIP-TV\n     27.50/0.635\n(f) EASEL\n     29.27/0.663\n(h) PatchNR\n     27.22/0.661\n(i) TW-CNFs\n    28.66/0.676\n(j) OW-CNFs (Ours)\n     32.40/0.773\n(k) RED-CNN\n     32.23/0.769\n(l) CTFormer\n     31.79/0.756\nFig. 8. Reconstructed image results of each method on the ‚ÄùLIDC-IDRI‚Äù dataset at dose I0 = 1 √ó 104. The display window is [‚àí100, 1430]HU.\n(a)Normal-dose\n     \n(g) DPR-IR\n     30.60/0.693\n(b) Low-dose\n     18.37/0.335\n(c) NLM\n     28.34/0.646\n(d) K-SVD\n     26.29/0.531\n(e) DIP-TV\n     27.46/0.614\n(f) EASEL\n     29.41/0.653\n(h) PatchNR\n     27.43/0.652\n(i) TW-CNFs\n    29.48/0.671\n(j) OW-CNFs (Ours)\n     32.41/0.760\n(k) RED-CNN\n     32.43/0.768\n(l) CTFormer\n     31.88/0.744\nFig. 9. Reconstructed image results of each method on the ‚ÄùLIDC-IDRI‚Äù dataset at dose I0 = 1 √ó 104. The display window is [200, 1130]HU.\npriors, and the change of œâ will affect the reconstruction\nquality. We present the trend of average PSNR on the test\nsets under different œâ in line charts, as shown in Figure 7.\nOverall, the value of œâ should be held in a small state, but a\ntoo small one will lead to bad data fidelity and reduce the\naccuracy of the reconstructed image. In the reconstruction\nprocess of the proposed OW-CNFs, we utilized the automatic\nbackpropagation of Pytorch to adjust the œâ, by initializing\nit with a small value (e.g. œâ = 0.1) and making the to-be-\nminimized equation (17) as the loss function. In this way, our\nreconstruction process can learn appropriate relaxation factors\nfor different reconstructed images.\nV. DISCUSSION AND CONCLUSION\nWe propose a novel unsupervised LDCT iterative recon-\nstruction algorithm, OW-CNFs, based on conditional normal-\nizing flows. By proposing an iterative reconstruction algorithm\nthat conducts strict one-way transformation when conducting\nalternating optimization in the data and latent space, we\nsolve the problems of detail loss and secondary artifacts that\ncome from the current two-way transformation strategy. To\nperform unsupervised LDCT reconstruction with CNFs, we\npropose a conditionalization method for LDCT, thus achieving\nefficient training and fast reconstruction on high-resolution\nCT images. Moreover, we also proposed an efficient itera-\ntive reconstruction procedure by employing the incremental\nproximal minimization method and the linearization technique.\nWith the incremental reconstruction of OS-SART, we real-\nize simple and efficient computation of the iterations and\neffectively control the balance between the data fidelity and\nCNFs priors. Experimental results demonstrate our method‚Äôs\noutstanding performance and fast reconstruction speed, in\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n10\nwhich our method achieves a high-level reconstruction speed\namong generative-model-based methods, and shows promising\nperformance comparable to supervised learning methods.\nAs a generative-model-based method, the proposed OW-\nCNFs effectively avoids the main drawback of CNN-based\ndenoising networks that easily cause over-smoothing and detail\nloss in CT images, and can produce images that more com-\nply with diagnostic needs. Compared with diffusion-model-\nbased methods, which also come from generative models, the\nmain advantage of our OW-CNFs is that we do not need\nto strictly implement a fixed number of iteration steps that\nmay be up to one thousand thus significantly reducing the\nreconstruction time, this should be attributed to our condition-\nalization method, by which the additional priors provided by\nthe condition simplify the iterative process greatly. In fact,\nwe are not the first to use CNFs in LDCT problems, but\nwe are the first to apply CNFs effectively and deeply to the\nunsupervised LDCT reconstruction procedure. Compared to\nother methods that only use CNFs in image-domain post-\nprocessing and require lots of paired images for training,\nour method realizes the integration of the priors learned by\nCNFs into the reconstruction procedure of LDCT, avoiding\nthe image-data inconsistency problem easily caused by post-\nprocessing networks. In addition, our method is an unsuper-\nvised framework that only requires normal-dose images for\ntraining, presenting higher application values in practical CT\nfields where training data is lacking, especially paired data.\nDespite the promising performance, the proposed OW-CNFs\nstill could be further improved. First, OW-CNFs introduces\nmultiple hyperparameters and thus tuning work is a burden.\nAutomatic adjustment would be a good way to solve this\nissue, like already done with the relaxation parameter œâ. But\nhow to process other hyperparameters needs further research.\nSecond, the training and generation process of the CNFs\nhighly depends on the quality of the given conditions. How\nto generate conditions with higher accuracy and stronger\npriors for LDCT reconstruction tasks remains a problem\nworth studying. Although we propose a simple and well-\nworking conditionalization method, it still relies on simple\nquantitative indicators and manual adjustment. Using more\nadvanced information extraction methods such as pre-trained\nfeature learning networks for conditionalization might improve\nthe performance and speed of our method.\nACKNOWLEDGMENT\nThis work was supported by Beijing Natural Science Foun-\ndation (No.Z210003), National Natural Science Foundation\nof China (NSFC) (61971292) and China Scholarship Council\n(CSC) (No.202307300001). The authors are also grateful to\nBeijing Higher Institution Engineering Research Center of\nTesting and Imaging for funding this research work.\nREFERENCES\n[1] A. LidestÀöahl, G. Johansson, A. Siegbahn, and P. A. Lind, ‚ÄúEstimated\nrisk of radiation-induced cancer after thymoma treatments with proton-\nor x-ray beams,‚Äù Cancers, vol. 13, no. 20, p. 5153, 2021.\n[2] D. Z. Solomon, B. Ayalew, S. T. Dellie, and D. Admasie, ‚ÄúJustification\nand optimization principles of alara in pediatric ct at a teaching hospital\nin ethiopia,‚Äù Ethiopian Journal of Health Sciences, vol. 30, no. 5, 2020.\n[3] L. W. Goldman, ‚ÄúPrinciples of ct: radiation dose and image quality,‚Äù\nJournal of nuclear medicine technology, vol. 35, no. 4, pp. 213‚Äì225,\n2007.\n[4] Y. Chen, D. Gao, C. Nie, L. Luo, W. Chen, X. Yin, and Y. Lin, ‚ÄúBayesian\nstatistical reconstruction for low-dose x-ray computed tomography using\nan adaptive-weighting nonlocal prior,‚Äù Computerized Medical Imaging\nand Graphics, vol. 33, no. 7, pp. 495‚Äì500, 2009.\n[5] D. Kang, P. Slomka, R. Nakazato, J. Woo, D. S. Berman, C.-C. J.\nKuo, and D. Dey, ‚ÄúImage denoising of low-radiation dose coronary ct\nangiography by an adaptive block-matching 3d algorithm,‚Äù in Medical\nImaging 2013: Image Processing, vol. 8669. SPIE, 2013, pp. 671‚Äì676.\n[6] M. Green, E. M. Marom, N. Kiryati, E. Konen, and A. Mayer, ‚ÄúEfficient\nlow-dose ct denoising by locally-consistent non-local means (lc-nlm),‚Äù in\nMedical Image Computing and Computer-Assisted Intervention-MICCAI\n2016: 19th International Conference, Athens, Greece, October 17-21,\n2016, Proceedings, Part III 19.\nSpringer, 2016, pp. 423‚Äì431.\n[7] Y. Zhang, M. Salehjahromi, and H. Yu, ‚ÄúTensor decomposition and non-\nlocal means based spectral ct image denoising,‚Äù Journal of X-ray Science\nand Technology, vol. 27, no. 3, pp. 397‚Äì416, 2019.\n[8] Q. Zhang, Z. Gui, Y. Chen, Y. Li, and L. Luo, ‚ÄúBayesian sinogram\nsmoothing with an anisotropic diffusion weighted prior for low-dose x-\nray computed tomography,‚Äù Optik-International Journal for Light and\nElectron Optics, vol. 124, no. 17, pp. 2811‚Äì2816, 2013.\n[9] A. Manduca, L. Yu, J. D. Trzasko, N. Khaylova, J. M. Kofler, C. M.\nMcCollough, and J. G. Fletcher, ‚ÄúProjection space denoising with\nbilateral filtering and ct noise modeling for dose reduction in ct,‚Äù Medical\nphysics, vol. 36, no. 11, pp. 4911‚Äì4919, 2009.\n[10] L. I. Rudin and S. Osher, ‚ÄúTotal variation based image restoration with\nfree local constraints,‚Äù in Proceedings of 1st international conference\non image processing, vol. 1.\nIEEE, 1994, pp. 31‚Äì35.\n[11] H. Yu and G. Wang, ‚ÄúCompressed sensing based interior tomography,‚Äù\nPhysics in medicine & biology, vol. 54, no. 9, p. 2791, 2009.\n[12] Z. Tian, X. Jia, K. Yuan, T. Pan, and S. B. Jiang, ‚ÄúLow-dose ct recon-\nstruction via edge-preserving total variation regularization,‚Äù Physics in\nMedicine & Biology, vol. 56, no. 18, p. 5949, 2011.\n[13] X. Deng, W. Xu, and H. Li, ‚ÄúFast ordered subsets chambolle-pock\nalgorithm for ct reconstruction,‚Äù in 15th International Meeting on Fully\nThree-Dimensional Image Reconstruction in Radiology and Nuclear\nMedicine, vol. 11072.\nSPIE, 2019, pp. 454‚Äì458.\n[14] M. Elad and M. Aharon, ‚ÄúImage denoising via sparse and redundant\nrepresentations over learned dictionaries,‚Äù IEEE Transactions on Image\nprocessing, vol. 15, no. 12, pp. 3736‚Äì3745, 2006.\n[15] K. H. Jin, M. T. McCann, E. Froustey, and M. Unser, ‚ÄúDeep con-\nvolutional neural network for inverse problems in imaging,‚Äù IEEE\ntransactions on image processing, vol. 26, no. 9, pp. 4509‚Äì4522, 2017.\n[16] H. Chen, Y. Zhang, M. K. Kalra, F. Lin, Y. Chen, P. Liao, J. Zhou, and\nG. Wang, ‚ÄúLow-dose ct with a residual encoder-decoder convolutional\nneural network,‚Äù IEEE transactions on medical imaging, vol. 36, no. 12,\npp. 2524‚Äì2535, 2017.\n[17] J. Liu, Y. Zhang, Q. Zhao, T. Lv, W. Wu, N. Cai, G. Quan, W. Yang,\nY. Chen, L. Luo et al., ‚ÄúDeep iterative reconstruction estimation (dire):\napproximate iterative reconstruction estimation for low dose ct imaging,‚Äù\nPhysics in Medicine & Biology, vol. 64, no. 13, p. 135007, 2019.\n[18] D. Wang, F. Fan, Z. Wu, R. Liu, F. Wang, and H. Yu, ‚ÄúCtformer:\nconvolution-free token2token dilated vision transformer for low-dose ct\ndenoising,‚Äù Physics in Medicine & Biology, vol. 68, no. 6, p. 065012,\n2023.\n[19] Z. Feng, A. Cai, Y. Wang, L. Li, L. Tong, and B. Yan, ‚ÄúDual residual\nconvolutional neural network (drcnn) for low-dose ct imaging,‚Äù Journal\nof X-Ray Science and Technology, vol. 29, no. 1, pp. 91‚Äì109, 2021.\n[20] R. Ge, Y. He, C. Xia, H. Sun, Y. Zhang, D. Hu, S. Chen, Y. Chen,\nS. Li, and D. Zhang, ‚ÄúDdpnet: A novel dual-domain parallel network\nfor low-dose ct reconstruction,‚Äù in International Conference on Medical\nImage Computing and Computer-Assisted Intervention. Springer, 2022,\npp. 748‚Äì757.\n[21] B. Zhou, X. Chen, H. Xie, S. K. Zhou, J. S. Duncan, and C. Liu,\n‚ÄúDudoufnet: Dual-domain under-to-fully-complete progressive restora-\ntion network for simultaneous metal artifact reduction and low-dose ct\nreconstruction,‚Äù IEEE transactions on medical imaging, vol. 41, no. 12,\npp. 3587‚Äì3599, 2022.\n[22] W. Wu, D. Hu, C. Niu, H. Yu, V. Vardhanabhuti, and G. Wang, ‚ÄúDrone:\nDual-domain residual-based optimization network for sparse-view ct\nreconstruction,‚Äù IEEE Transactions on Medical Imaging, vol. 40, no. 11,\npp. 3002‚Äì3014, 2021.\n[23] H. Chen, Y. Zhang, Y. Chen, J. Zhang, W. Zhang, H. Sun, Y. Lv,\nP. Liao, J. Zhou, and G. Wang, ‚ÄúLearn: Learned experts‚Äô assessment-\nAN et al.: UNSUPERVISED LOW-DOSE CT RECONSTRUCTION WITH ONE-WAY CONDITIONAL NORMALIZING FLOWS\n11\nbased reconstruction network for sparse-data ct,‚Äù IEEE transactions on\nmedical imaging, vol. 37, no. 6, pp. 1333‚Äì1347, 2018.\n[24] J. Adler and O. ¬®Oktem, ‚ÄúLearned primal-dual reconstruction,‚Äù IEEE\ntransactions on medical imaging, no. 6, pp. 1322‚Äì1332, 2018.\n[25] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, B. Sengupta, and\nA. A. Bharath, ‚ÄúGenerative adversarial networks: An overview,‚Äù IEEE\nsignal processing magazine, vol. 35, no. 1, pp. 53‚Äì65, 2018.\n[26] C. You, G. Li, Y. Zhang, X. Zhang, H. Shan, M. Li, S. Ju, Z. Zhao,\nZ. Zhang, W. Cong et al., ‚ÄúCt super-resolution gan constrained by\nthe identical, residual, and cycle learning ensemble (gan-circle),‚Äù IEEE\ntransactions on medical imaging, vol. 39, no. 1, pp. 188‚Äì203, 2019.\n[27] T. Kwon and J. C. Ye, ‚ÄúCycle-free cyclegan using invertible generator\nfor unsupervised low-dose ct denoising,‚Äù IEEE Transactions on Com-\nputational Imaging, vol. 7, pp. 1354‚Äì1368, 2021.\n[28] J. Gu and J. C. Ye, ‚ÄúAdain-based tunable cyclegan for efficient unsu-\npervised low-dose ct denoising,‚Äù IEEE Transactions on Computational\nImaging, vol. 7, pp. 73‚Äì85, 2021.\n[29] Z. Li, S. Zhou, J. Huang, L. Yu, and M. Jin, ‚ÄúInvestigation of low-\ndose ct image denoising using unpaired deep learning methods,‚Äù IEEE\ntransactions on radiation and plasma medical sciences, vol. 5, no. 2,\npp. 224‚Äì234, 2020.\n[30] A. M. Hasan, M. R. Mohebbian, K. A. Wahid, and P. Babyn, ‚ÄúHybrid-\ncollaborative noise2noise denoiser for low-dose ct images,‚Äù IEEE Trans-\nactions on Radiation and Plasma Medical Sciences, vol. 5, no. 2, pp.\n235‚Äì244, 2020.\n[31] W. Fang, D. Wu, K. Kim, M. K. Kalra, R. Singh, L. Li, and Q. Li,\n‚ÄúIterative material decomposition for spectral ct using self-supervised\nnoise2noise prior,‚Äù Physics in Medicine & Biology, vol. 66, no. 15, p.\n155013, 2021.\n[32] N. Yuan, J. Zhou, and J. Qi, ‚ÄúHalf2half: deep neural network based\nct image denoising without independent reference data,‚Äù Physics in\nMedicine & Biology, vol. 65, no. 21, p. 215020, 2020.\n[33] C. Zhang, S. Chang, T. Bai, and X. Chen, ‚ÄúS2ms: Self-supervised learn-\ning driven multi-spectral ct image enhancement,‚Äù in 7th International\nConference on Image Formation in X-Ray Computed Tomography, vol.\n12304.\nSPIE, 2022, pp. 473‚Äì479.\n[34] C. Niu, M. Li, F. Fan, W. Wu, X. Guo, Q. Lyu, and G. Wang, ‚ÄúNoise\nsuppression with similarity-based self-supervised deep learning,‚Äù IEEE\nTransactions on Medical Imaging, 2022.\n[35] A. A. Hendriksen, D. M. Pelt, and K. J. Batenburg, ‚ÄúNoise2inverse:\nSelf-supervised deep convolutional denoising for tomography,‚Äù IEEE\nTransactions on Computational Imaging, vol. 6, pp. 1320‚Äì1335, 2020.\n[36] F. Wagner, M. Thies, L. Pfaff, O. Aust, S. Pechmann, D. Weidner,\nN. Maul, M. Rohleder, M. Gu, J. Utz et al., ‚ÄúOn the benefit of dual-\ndomain denoising in a self-supervised low-dose ct setting,‚Äù in 2023 IEEE\n20th International Symposium on Biomedical Imaging (ISBI).\nIEEE,\n2023, pp. 1‚Äì5.\n[37] C. Niu, M. Li, X. Guo, and G. Wang, ‚ÄúSelf-supervised dual-domain net-\nwork for low-dose ct denoising,‚Äù in Developments in X-Ray Tomography\nXIV, vol. 12242.\nSPIE, 2022.\n[38] R. An, K. Chen, and H. Li, ‚ÄúSelf-supervised dual-domain balanced\ndropblock-network for low-dose ct denoising,‚Äù Physics in Medicine and\nBiology, 2024.\n[39] A. Zheng, H. Gao, L. Zhang, and Y. Xing, ‚ÄúA dual-domain deep\nlearning-based reconstruction method for fully 3d sparse data helical\nct,‚Äù Physics in Medicine & Biology, vol. 65, no. 24, p. 245030, 2020.\n[40] Y. Zhang, D. Hu, Q. Zhao, G. Quan, J. Liu, Q. Liu, Y. Zhang,\nG. Coatrieux, Y. Chen, and H. Yu, ‚ÄúClear: comprehensive learning\nenabled adversarial reconstruction for subtle structure enhanced low-\ndose ct imaging,‚Äù IEEE Transactions on Medical Imaging, vol. 40,\nno. 11, pp. 3089‚Äì3101, 2021.\n[41] I. Kobyzev, S. J. Prince, and M. A. Brubaker, ‚ÄúNormalizing flows:\nAn introduction and review of current methods,‚Äù IEEE transactions on\npattern analysis and machine intelligence, vol. 43, no. 11, pp. 3964‚Äì\n3979, 2020.\n[42] F.-A. Croitoru, V. Hondru, R. T. Ionescu, and M. Shah, ‚ÄúDiffusion\nmodels in vision: A survey,‚Äù IEEE Transactions on Pattern Analysis\nand Machine Intelligence, 2023.\n[43] X. Wei, H. van Gorp, L. Gonzalez-Carabarin, D. Freedman, Y. C. Eldar,\nand R. J. van Sloun, ‚ÄúDeep unfolding with normalizing flow priors for\ninverse problems,‚Äù IEEE Transactions on Signal Processing, vol. 70, pp.\n2962‚Äì2971, 2022.\n[44] F. Altekr¬®uger, A. Denker, P. Hagemann, J. Hertrich, P. Maass, and\nG. Steidl, ‚ÄúPatchnr: learning from very few images by patch normalizing\nflow regularization,‚Äù Inverse Problems, vol. 39, no. 6, p. 064006, 2023.\n[45] Z. He, Y. Zhang, Y. Guan, B. Guan, S. Niu, Y. Zhang, Y. Chen, and\nQ. Liu, ‚ÄúIterative reconstruction for low-dose ct using deep gradient\npriors of generative model,‚Äù IEEE Transactions on Radiation and\nPlasma Medical Sciences, vol. 6, no. 7, pp. 741‚Äì754, 2022.\n[46] Y. Song and S. Ermon, ‚ÄúImproved techniques for training score-based\ngenerative models,‚Äù Advances in neural information processing systems,\nvol. 33, pp. 12 438‚Äì12 448, 2020.\n[47] X. Liu, Y. Xie, S. Diao, S. Tan, and X. Liang, ‚ÄúA diffusion\nprobabilistic prior for low-dose ct image denoising,‚Äù arXiv preprint\narXiv:2305.15887, 2023.\n[48] W. Xia, Y. Shi, C. Niu, W. Cong, and G. Wang, ‚ÄúDiffusion prior\nregularized iterative reconstruction for low-dose ct,‚Äù arXiv preprint\narXiv:2310.06949, 2023.\n[49] J. Ho, A. Jain, and P. Abbeel, ‚ÄúDenoising diffusion probabilistic models,‚Äù\nAdvances in neural information processing systems, vol. 33, pp. 6840‚Äì\n6851, 2020.\n[50] K. Kothari, A. Khorashadizadeh, M. de Hoop, and I. Dokmani¬¥c, ‚ÄúTrum-\npets: Injective flows for inference and inverse problems,‚Äù in Uncertainty\nin Artificial Intelligence.\nPMLR, 2021, pp. 1269‚Äì1278.\n[51] A. Denker, M. Schmidt, J. Leuschner, P. Maass, and J. Behrmann,\n‚ÄúConditional normalizing flows for low-dose computed tomography\nimage reconstruction,‚Äù arXiv preprint arXiv:2006.06270, 2020.\n[52] J. Song, C. Meng, and S. Ermon, ‚ÄúDenoising diffusion implicit models,‚Äù\narXiv preprint arXiv:2010.02502, 2020.\n[53] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, ‚ÄúDpm-solver: A\nfast ode solver for diffusion probabilistic model sampling in around 10\nsteps,‚Äù Advances in Neural Information Processing Systems, vol. 35, pp.\n5775‚Äì5787, 2022.\n[54] G. Wang and M. Jiang, ‚ÄúOrdered-subset simultaneous algebraic recon-\nstruction techniques (os-sart),‚Äù Journal of X-ray Science and Technology,\nvol. 12, no. 3, pp. 169‚Äì177, 2004.\n[55] J. H. Park, J. Lee, and J. Hwang, ‚ÄúSolving inverse problems using\nnormalizing flow prior: Application to optical spectra,‚Äù Physical Review\nB, vol. 109, no. 16, p. 165130, 2024.\n[56] L. Helminger, M. Bernasconi, A. Djelouah, M. Gross, and C. Schroers,\n‚ÄúGeneric image restoration with flow based priors,‚Äù in Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2021, pp. 334‚Äì343.\n[57] D. P. Kingma and P. Dhariwal, ‚ÄúGlow: Generative flow with invertible\n1x1 convolutions,‚Äù Advances in neural information processing systems,\nvol. 31, 2018.\n[58] C. Winkler, D. E. Worrall, E. Hoogeboom, and M. Welling, ‚ÄúLearning\nlikelihoods with conditional normalizing flows,‚Äù 2019.\n[59] L. Wei, A. Yadav, and W. Hsu, ‚ÄúCtflow: Mitigating effects of computed\ntomography acquisition and reconstruction with normalizing flows,‚Äù in\nInternational Conference on Medical Image Computing and Computer-\nAssisted Intervention.\nSpringer, 2023, pp. 413‚Äì422.\n[60] V. Wolf, A. Lugmayr, M. Danelljan, L. Van Gool, and R. Timofte,\n‚ÄúDeflow: Learning complex image degradations from unpaired data\nwith conditional flows,‚Äù in Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, 2021, pp. 94‚Äì103.\n[61] X. Liu, X. Liang, L. Deng, S. Tan, and Y. Xie, ‚ÄúLearning low-dose\nct degradation from unpaired data with flow-based model,‚Äù Medical\nPhysics, vol. 49, no. 12, pp. 7516‚Äì7530, 2022.\n[62] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian, ‚ÄúImage denoising by\nsparse 3-d transform-domain collaborative filtering,‚Äù IEEE Transactions\non image processing, vol. 16, no. 8, pp. 2080‚Äì2095, 2007.\n[63] A. Buades, B. Coll, and J.-M. Morel, ‚ÄúNon-local means denoising,‚Äù\nImage Processing On Line, vol. 1, pp. 208‚Äì212, 2011.\n[64] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, ‚ÄúBeyond a gaussian\ndenoiser: Residual learning of deep cnn for image denoising,‚Äù IEEE\ntransactions on image processing, vol. 26, no. 7, pp. 3142‚Äì3155, 2017.\n[65] A. Hore and D. Ziou, ‚ÄúImage quality metrics: Psnr vs. ssim,‚Äù in 2010\n20th international conference on pattern recognition.\nIEEE, 2010, pp.\n2366‚Äì2369.\n[66] S. G. Armato III, G. McLennan, L. Bidaut, M. F. McNitt-Gray, C. R.\nMeyer, A. P. Reeves, B. Zhao, D. R. Aberle, C. I. Henschke, E. A.\nHoffman et al., ‚ÄúThe lung image database consortium (lidc) and image\ndatabase resource initiative (idri): a completed reference database of\nlung nodules on ct scans,‚Äù Medical physics, vol. 38, no. 2, pp. 915‚Äì931,\n2011.\n[67] J. Liu, Y. Sun, X. Xu, and U. S. Kamilov, ‚ÄúImage restoration using total\nvariation regularized deep image prior,‚Äù in ICASSP 2019-2019 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing\n(ICASSP).\nIeee, 2019, pp. 7715‚Äì7719.\n",
  "categories": [
    "eess.IV",
    "cs.CV"
  ],
  "published": "2024-10-23",
  "updated": "2024-10-23"
}