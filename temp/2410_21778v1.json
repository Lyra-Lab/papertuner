{
  "id": "http://arxiv.org/abs/2410.21778v1",
  "title": "RELATE: A Modern Processing Platform for Romanian Language",
  "authors": [
    "Vasile Păiş",
    "Radu Ion",
    "Andrei-Marius Avram",
    "Maria Mitrofan",
    "Dan Tufiş"
  ],
  "abstract": "This paper presents the design and evolution of the RELATE platform. It\nprovides a high-performance environment for natural language processing\nactivities, specially constructed for Romanian language. Initially developed\nfor text processing, it has been recently updated to integrate audio processing\ntools. Technical details are provided with regard to core components. We\nfurther present different usage scenarios, derived from actual use in national\nand international research projects, thus demonstrating that RELATE is a\nmature, modern, state-of-the-art platform for processing Romanian language\ncorpora. Finally, we present very recent developments including bimodal (text\nand audio) features available within the platform.",
  "text": "RELATE: A Modern Processing Platform for\nRomanian Language\nVasile Păis,\nRadu Ion\nAndrei-Marius Avram\nMaria Mitrofan\nDan Tufis,\nResearch Institute for Artificial Intelligence \"Mihai Drăgănescu\",\nRomanian Academy\nTel.: +40-21-3188106\nFax: +40-21-3188142\n{vasile,radu,andrei.avram,maria,tufis}@racai.ro\nAbstract\nThis paper presents the design and evolution of the RELATE1 plat-\nform. It provides a high-performance environment for natural language\nprocessing activities, specially constructed for Romanian language. Ini-\ntially developed for text processing, it has been recently updated to inte-\ngrate audio processing tools. Technical details are provided with regard\nto core components.\nWe further present different usage scenarios, de-\nrived from actual use in national and international research projects, thus\ndemonstrating that RELATE is a mature, modern, state-of-the-art plat-\nform for processing Romanian language corpora. Finally, we present very\nrecent developments including bimodal (text and audio) features available\nwithin the platform.\nKeywords: Romanian language, Web platform, Natural language pro-\ncessing, Bimodal processing\n1\nIntroduction\nLanguage Technology (LT) platforms provide services for analysis or production\nof written or spoken language. They employ artificial intelligence (AI) methods\nto implement their functionalities. Furthermore, platforms have been developed\neither to showcase new technologies or as powerful tools used in processing large\namounts of data, in the form of offline corpora or online requests.\nOne of the motivations of the 1st International Workshop for Language Tech-\nnology Platforms (IWLTP 2020) was to address the issue of fragmentation in the\nLanguage Technology landscape. As the organizers note (Rehm et al., 2020a),\ninstead of competing with one another, platforms should be constructed to be\ninteroperable and interact with each other to create synergies towards a produc-\ntive LT ecosystem. Interoperability is usually achieved by providing input and\noutput in standardized formats, specific to the tasks being executed. Interaction\n1https://relate.racai.ro\n1\narXiv:2410.21778v1  [cs.CL]  29 Oct 2024\nbetween systems involves exposing one system’s functionality in a way that can\nbe used from another system.\nIn this paper we present the RELATE platform (Păis, et al., 2020). It is a\nmodular, modern, state-of-the-art platform for processing Romanian language,\ndeveloped at the Institute for Artificial Intelligence \"Mihai Drăgănescu\" of the\nRomanian Academy. It integrates both technologies developed in our institute\nand technologies developed by partner institutions.\nRELATE is being used\nactively in multiple national and international research projects. From the be-\nginning it was designed to use standardized file formats, thus ensuring interoper-\nability with other language processing systems. Internal functions are available\nas REST web services, thus allowing for interaction with other systems.\nThis paper is organized as follows: Section 2 presents related work, Section\n3 presents the history behind RELATE platform development, then Section 4\nintroduces its architecture, while Section 5 describes the available components.\nSection 6 presents several usage scenarios. Finally we conclude in Section 7.\n2\nRelated work\nMETA-SHARE2 (Federmann et al., 2012), CLARIN3 and ELRC-Share4 (Euro-\npean Language Resource Coordination Share) are publicly available European\nwebsites for research and development in the field, allowing access to language\nresources. Both ELRC-Share and META-SHARE offer advanced search facili-\nties through which one can easily find various language tools and corpora (text,\nannotated, audio corpora, etc.) for any (European and other) language. Com-\nplex processing pipelines, like NLP-Cube (Boros, et al., 2018b) and TTL are\nable to perform tokenization, lemmatization, POS tagging, chunking and de-\npendency parsing, but require programming knowledge in order to integrate\nthem into an application.\nMore recently, the TEPROLIN web service inte-\ngrates multiple tools, including NLP-Cube, TTL and solutions for named entity\nrecognition (Păis,, 2019) and biomedical named entity recognition, into an easy\nto use pipeline. However usage of this web service still requires programming\nknowledge for web service communication.\nGATE (Cunningham et al., 2002) and TextFlows (Perovšek et al., 2016) aim\nto make the composition of the language processing chains more user-friendly.\nFor this purpose, the graphical interfaces allow for dragging and dropping text\nprocessing widgets into a graphical processing workflow. However, their output\nis not enhanced with specialized visualization tools that allow access into the\ncomputational resources used for annotation.\nMoreover, they only focus on\npurely textual content, while multimodal content (such as text and audio) is\nnot handled within the platforms.\nCoBiLiRo (Cristea et al., 2020) is a storage platform for multimodal (text\nand audio) corpora. It was developed in the context of the RETEROM5 project\nfor storing Romanian speech corpora suitable for the project’s purposes.\nIt\nallows defining a large number of metadata fields, but it doesn’t allow for any\ncomplex language processing tasks.\n2http://www.meta-share.org\n3https://www.clarin.eu\n4https://elrc-share.eu/\n5https://racai.ro/p/reterom/\n2\nRELATE aims specifically at doing automatic text processing, with annota-\ntions at multiple levels, along with annotation visualization and expansion into\nthe corresponding linguistic computational resources. The platform focuses on\ninteractive user experience, via web based interfaces. Compared to other plat-\nforms, such as (Che et al., 2010), the main focus of RELATE is not on exposing\nAPIs, even though API access to platform functionality is available. Text pro-\ncessing APIs are used internally, accessible by platform components, and most\nof them can also be invoked externally.\nRELATE makes use of a common internal format, comprising multiple files\n(text, standoff metadata, CoNLL-U Plus6 annotations). The processing work-\nflow is constructed by adding individual tasks. Each task is able to both use\nand produce data according to the internal format. For this reason no workflow\neditor, such as the one used in (Perovšek et al., 2016), is currently available.\n(Coleman et al., 2020) presents a platform for integrating multiple Machine\nTranslation (MT) models. In RELATE we only provide MT capabilities re-\nlated to the Romanian language (currently allowing only Romanian-English and\nEnglish-Romanian translation). We further allow translated content to become\nan input for further language processing tasks. (Rebai et al., 2020) presents a\nplatform integrating a voice assistant for improving efficiency and productivity\nin business. In the case of RELATE, we only integrate existing Romanian (and\nEnglish) Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) sys-\ntems while still focusing on the textual component. Thus ASR output can be\npassed as input to further language processing tasks.\n(Rehm et al., 2020b) acknowledges that a large number of AI platforms are\ncurrently under development, both on the national level, supported through\nlocal funding programmes, and on the international level, supported by the Eu-\nropean Union. The authors further recognize the enormous fragmentation of\nthe European AI and LT landscape and consider that modern platforms should\nbe able to exchange information, data and services, in order to enable interop-\nerability. We agree with this assessment and thus in the RELATE platform we\naimed to make use of standardized formats as well as decoupling functionality\ninto components, that could be invoked externally if needed. In addition, sim-\nilar to the AI4EU7 and European Language Grid (ELG)8 platforms, RELATE\nis able to integrate Docker containers for language processing tools. However,\nthis is not imposed and thus only a small number of the available components\nare integrated as containers.\n3\nEvolution of the RELATE platform\nThe RELATE platform was developed across a number of national and interna-\ntional research projects and evolved together with the requirements associated\nwith the activities it was used for. This section describes its evolution through-\nout the projects, from the first implementation to the current version.\nRELATE platform development (Păis, et al., 2019) started within the RETE-\nROM project. This was a national project, started in 2018. One of the primary\ngoals, associated with the sub-project TEPROLIN, was to develop and integrate\n6https://universaldependencies.org/ext-format.html\n7https://www.ai4eu.eu/\n8https://www.european-language-grid.eu/\n3\nstate of the art technologies for Romanian natural language processing, such as\ntokenization, part-of-speech tagging, dependency parsing, phonetic annotations,\nnamed entity recognition. The primary result was the TEPROLIN web service\n(Ion, 2018) which allows invocation using a raw text document and produces\ndifferent levels of annotations (based on specified parameters) encoded using a\ncustom JSON format9.\nThe first implementation of the RELATE platform allowed for the manage-\nment of large corpora (upload, download, editing) and parallel processing using\nthe TEPROLIN service. For processing purposes a task management engine was\nimplemented, allowing distribution of documents across any number of TEPRO-\nLIN processes started on the same server or over the network. This allowed for\nincreased processing speed when needed, as the number of processing nodes can\nbe adjusted dynamically. Furthermore, the platform is able to convert between\nthe custom JSON encoding associated with TEPROLIN to a more standard\nCoNLL-U format10, used also by the Universal Dependencies project11, or its\nextension CoNLL-U Plus12 when appropriate.\nGraphical representations were developed to allow a human user to manually\nexplore annotation results. These include: visualization in different column-\nbased and JSON formats, tree-based representations for dependency parsing,\nhighlighting of recognized named entities. In order to improve the user’s ex-\nperience, we also included different interface elements allowing to query the\nRepresentative Corpus of Contemporary Romanian Language (CoRoLa) (Tufis,\net al., 2019b). This includes links to the main query interface of the text com-\nponent of CoRoLa, using the KorAP corpus analysis platform (Bański et al.,\n2012), and to the speech component, allowing searching in audio files (Boros,\net al., 2018a) and listening to words being pronounced by Romanian speakers.\nDifferent visualizations are also making use of word embeddings (Bojanowski\net al., 2017) computed on the CoRoLa corpus (Păis, and Tufis,, 2018) to suggest\nwords appearing in similar contexts.\nThe Romanian WordNet (Tufis, and Mititelu, 2015) was integrated in order to\nallow words to be searched online. We further exploited the alignment between\nthe Romanian and English (Miller, 1995) wordnets in order to provide aligned\nqueries based on synset identifiers.\nThe textual translation component, developed by TILDE with the involve-\nment of the Research Institute for Artificial Intelligence \"Mihai Drăgănescu\"\nof the Romanian Academy, within the project \"CEF Automated Translation\ntoolkit for the Rotating Presidency of the Council of the EU\", was integrated\nin RELATE, by means of the TILDE Machine Translation API13. This allows\nusers to translate documents directly in the platform. After a successful trans-\nlation from English to Romanian, the resulting document can be analysed using\nthe platform’s functionality.\nWithin the \"Multilingual Resources for CEF.AT in the legal domain\" (MAR-\nCELL) project14, a terminology annotation tool (Coman et al., 2019a) was de-\nveloped and integrated in RELATE allowing for identification of terms from Eu-\n9http://relate.racai.ro/?path=teprolin/doc_dev\n10https://universaldependencies.org/format.html\n11https://universaldependencies.org/\n12https://universaldependencies.org/ext-format.html\n13https://www.tilde.com/developers/machine-translation-api\n14https://marcell-project.eu/\n4\nroVoc15 and IATE16 (Interactive Terminology for Europe) terminologies. The\ntool can be used following a lemmatization and part-of-speech tagging operation.\nThe ASR system (Avram et al., 2020b) resulted from the national project\nROBIN17, initially developed for human-robot interaction (Ion et al., 2020; Tufis,\net al., 2019a), was integrated in the RELATE platform. This allows text to be\nextracted either from directly recorded speech or from uploaded audio files.\nThe resulting text can then be analyzed using the platform’s processing tools.\nSeveral corrections on the recognized text (such as basic comma restoration and\ntruecasing) can be performed (Avram et al., 2020a) before the actual analysis.\nWe further exploited the availability of ASR and text translation features\nin order to provide speech-to-speech translation functionality for Romanian-\nEnglish and English-Romanian. This chained together different platform mod-\nules and required the integration of additional text-to-speech components. To\nsynthesize the Romanian speech, we integrated two models in our pipeline: Ro-\nmanian TTS developed by Stan et al. (2011) and RACAI SSLA developed by\nBoros, et al. (2018a), that are based on Hidden Markov Models (HMM) to com-\npute the most probable sequence of spectrograms.\nThe project \"Curated Multilingual Language Resources for CEF.AT\" (CURLI-\nCAT), started in 2021, requires large scale anonymization of the collected text\ncorpus. This process was further integrated in RELATE, making use of the\nparallelization mechanism already available for different text processing tasks.\nOne of the research directions in our institute, in line with the COST Ac-\ntion \"Nexus Linguarum\", aims to create resources specific to Linguistic Linked\nOpen Data specifications (Barbu Mititelu et al., 2020). This provided an oppor-\ntunity for development and inclusion in RELATE of post-processing capabilities\nallowing RDF exports for different annotation levels.\nThe \"European Language Equality\" (ELE) project18, started in 2021, has as\nprimary goals the development of a sustainable evidence-based strategic research\nagenda and roadmap setting out actions, processes, tools, and actors to achieve\nfull digital language equality of all languages (official or otherwise) used within\nthe European Union through the effective use of language technologies.\nIn\naddition, the research agenda encompasses the determination of the current\nstate of language technologies and language equality within the EU. In turn,\nthis led to an extension of RELATE allowing multiple similar text processing\npipelines (Păis,, 2020) to be executed on the same corpus in order to compare\nthe results (with or without the presence of a \"gold\" annotated corpus).\n4\nPlatform architecture\nThe RELATE platform is organized following a modular approach. Each com-\nponent is implemented independent of other components and provides a JSON\ndescriptor exposing the corresponding menu entries and functionality at differ-\nent user access levels. Moreover, components are service oriented. They can\nconsume web services (either SOAP or REST) and expose additional HTTP\n15https://eur-lex.europa.eu/browse/eurovoc.html\n16https://iate.europa.eu/home\n17http://aimas.cs.pub.ro/robin/en/\n18http://www.european-language-equality.eu\n5\nFigure 1: RELATE platform architecture\nREST services. In turn, the exposed services can be consumed by the graphical\nuser interface of the component via AJAX calls to the REST endpoints.\nThe service oriented architecture being employed allows for easy reuse of\ncomponent provided functionality in other parts of the platform or even from\noutside the platform.\nBy consuming services exposed by processing compo-\nnents it is possible to deploy these functions on different computing nodes, thus\nenabling high-speed parallel processing across interconnected servers. This sce-\nnario was employed for large corpora annotation in our institute, employing\nmultiple servers available in the same local area network (LAN). However, since\na processing operation takes more time than communication, it is possible to\nuse remote hardware resources (across the Internet) for further increasing the\nprocessing capabilities available to the platform.\nFigure 1 presents the general platform architecture with the different com-\nponents. The front-end part of the platform is in charge of user interaction. It\nprovides visualizations for the different components. It is implemented using\nmodern front-end technologies and languages such as HTML5, CSS, JavaScript.\nCommunication with the platform’s back-end is realized via page loading or\nAJAX calls when possible.\nThe use of AJAX enhances the user experience\nby reducing loading times. Furthermore, exposure of different APIs as HTTP\nREST services allows for direct usage from outside the platform if needed.\nThe RELATE back-end is in charge of communication with different language-\nspecific components. The back-end itself is written in PHP, while the compo-\nnents can be written in any language as long as a communication mechanism\nis possible. The platform currently has components written in C++, Java and\nPython.\nThe preferred communication mechanism is via HTTP REST API\ncalls. Nevertheless, the platform integrated also components called by invoking\nnew processes with command line arguments.\n5\nPrimary platform components\nThis section will present the primary platform components (as indicated in\nFigure 1), covering topics such as functions provided and implementation details.\nOnly components with recent developments are included. Older components,\nsuch as the WordNet and CoRoLa query interfaces are not covered in detail.\n6\nAdditionally, some of the smaller (or very specific) components will be covered\nin Section 6.\n5.1\nCorpus annotation\nTEPROLIN (Ion, 2018) is a text pre-processing platform, implemented as a web\nservice. It was developed in the ReTeRom project19 with the specific intent of\nmaking it easy to incorporate diverse text pre-processing tools written in a host\nof programming languages. TEPROLIN is written in Python 3 and requires each\nparticipating text pre-processing application to implement the TEPROLIN API\nclass20. The following are required for best results in TEPROLIN:\n• the loading of external resources is always made when the object is created\nso that with large resource files, the loading time does not interfere with\nthe run time;\n• text pre-processing applications should be resident processes on the ma-\nchine running TEPROLIN and the I/O with TEPROLIN should be made\nwith available IPC mechanisms, such as TCP sockets;\n• if text pre-processing applications are implemented as web services, no\nresource loading is necessary and the _runApp method is the only one\nwhich needs implementing.\nTEPROLIN can be used as a standalone Python 3 object or from RELATE,\nin demo21 or production mode (for annotating large corpora). Each processing\noperation (e.g. POS tagging, dependency parsing, etc.) can be configured to\nbe executed with the specified TEPROLIN module able to perform it and, if\ndesired, only a set of operations can be requested to be performed. TEPRO-\nLIN will auto-configure to execute all other required operations, such that the\nrequested ones can be performed. For instance, if the user requires POS tag-\nging, TEPROLIN will automatically execute sentence splitting and tokenization\nbeforehand.\nCurrently, TEPROLIN incorporates the following text pre-processing appli-\ncations:\n• NLP-Cube (Boros, et al., 2018b), UDPipe (Straka et al., 2016) and TTL\n(Ion, 2007) for sentence splitting, POS tagging and lemmatization;\n• additionally, NLP-Cube and UDPipe perform dependency parsing while\nTTL performs noun phrase, verb phrase, prepositional phrase, adverbial\nand adjectival phrase non-recursive chunking;\n• MLPLA (Boros, et al., 2018a) for word hyphenation, stressed accented\nsyllable detection and phonetic transcription;\n• in house developed tools for Romanian text normalization, diacritic restora-\ntion, abbreviation and numeral expansion (i.e. automatically derive the\nfull form of the abbreviation or the literal transcription of the numeral);\n19https://www.racai.ro/p/reterom/\n20https://github.com/racai-ai/TEPROLIN/blob/master/TeproApi.py\n21https://relate.racai.ro/index.php?path=teprolin/custom\n7\n• BioNER (Mitrofan et al., 2018) based on a previous version of NLP-Cube\nadapted for NER processing;\n• NER (Păis,, 2019) for detecting names of persons, organizations, locations\nand time expressions.\nUDPipe22 (Straka et al., 2016) is a trainable application for tokenization,\ntagging, lemmatization and dependency parsing of CoNLL-U files.\nSentence\nsplitting and tokenization are performed by checking each character in the in-\nput if it’s the end of a token or the end of the sentence (or both), using a\nsingle-layer bidirectional GRU network. POS tagging and lemmatization use\nan averaged perceptron with morphosyntactic features (e.g. word affixes paired\nwith current POS tags) while the dependency parser uses a simple feed-forward\nneural network to select the optimal transition given by the chosen transition-\nbased dependency parser. Instead of TEPROLIN, UDPipe can be used as a\nstandalone text pre-processing pipeline in RELATE, in production mode (i.e.\nannotating large corpora using multiple processing threads).\nBioNER annotation is obtained through TEPROLIN, by requesting the\nbiomedical-named-entity-recognition operation. This will enable inside-\noutside-beginning annotations of disorders (DISO), anatomical parts (ANAT),\nmedical procedures (PROC) and drugs and other chemicals (CHEM). Mitrofan\net al. (2018) describes the corpus that was used to train a previous version\nof NLP-Cube to recognize these specialized text spans.\nNER annotation is performed using a modified version of an older Stanford\nNamed Entity Recognizer (Stanford NER) (Finkel et al., 2005) system, making\nuse of CoRoLa pre-trained word embeddings (Păis, and Tufis,, 2018), computing\nrepresentations for unknown words based on sub-word information (Bojanowski\net al., 2017).\nMatching is further enhanced using a rule-based method.\nFi-\nnally, results are attached to a tokenized document using Inside-Outside (IO)\nnotation. This is then converted to Inside-Outside-Beginning (IOB) format for\ncompatibility with other annotations.\nBesides TEPROLIN and UDPipe processing, pre-trained language models\nfor other basic language resource kits (BLARK) are available for download from\nwithin the RELATE platform23. These models are trained on the same corpus,\ncurrently version 2.7 of the RoRefTrees treebank (RRT) (Barbu Mititelu, 2018)\navailable from the Universal Dependencies24 project.\nModels are offered for\nStanza25 (Qi et al., 2020), RNNTagger26 (Schmid, 2019), NLP-Cube27 (Boros,\net al., 2018b), UDPipe (Straka et al., 2016) and TreeTagger28 (Schmid, 1994).\n5.2\nTerminology annotation\nThe terminology annotation tool was initially implemented for the purposes\nof the international project “Multilingual Resources for CEF.AT in the legal\ndomain” (MARCELL) 29. In this context a large comparable corpus (Váradi\n22https://github.com/ufal/udpipe\n23https://relate.racai.ro/index.php?path=pretrainedlm/list\n24https://universaldependencies.org/\n25https://stanfordnlp.github.io/stanza/index.html\n26https://www.cis.uni-muenchen.de/~schmid/tools/RNNTagger/\n27https://github.com/adobe/NLP-Cube\n28https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/\n29https://marcell-project.eu/\n8\net al., 2020) of national legislation from the seven partners’ countries, including\nRomania, was enriched with EuroVoc and IATE terminology annotations. Fur-\nthermore, a classification of the documents considering the top-level domains of\nthe EuroVoc multilingual thesaurus was done.\nFor classifying documents belonging to the Romanian sub-corpus (Tufis,\net al., 2020) we developed a classifier based on the method proposed by Joulin\net al. (2017), using the average of word embeddings over n-grams as features\nto a linear classifier. The actual implementation used the FastText30 tool. We\ntrained several models, using different word embeddings (CoRoLa, Wikipedia\nand CommonCrawl). We wanted to compare these models with the well known\nJEX tool31, developed by the European Commission’s (EC) Joint Research Cen-\ntre (JRC). JEX (Steinberger et al., 2012) is making use of the classification algo-\nrithm described in (Pouliquen et al., 2006), based on a list of lemma frequencies\nfrom normalized text, and their weights, that are statistically related to each\ndescriptor, entitled in the paper as associates or as topic signatures. For Ro-\nmanian, JEX was trained on over 25,000 documents from two parallel corpora:\nJRC-Acquis (Steinberger et al., 2006) and OPOCE (Publications Office of the\nEuropean Union). By considering only the first 6 most probable descriptors, it\nobtained a precision of 45.55%, a recall of 50.43% and a F1 score of 47.84%.\nFor training and evaluating our EuroVoc models, we used the same approach\nfollowed by JEX, employing the same datasets and cross-validation splits. Our\nbest model was obtained using CoRoLa word embeddings and achieved a preci-\nsion of 50.93%, a recall of 56.41% and a F1 score of 53.53%, thus presenting an\nincrease of over 5% with regard to F1 score compared to JEX. We further eval-\nuated the model on top level domains and obtained an F1 score of 70.80%. The\nmodel is available for download and interrogation from RELATE32. In order\nto integrate this model in the platform, we employed a modified version of the\nFastText application, including an embedded web server, allowing the model to\nbe kept in-memory. This server is open sourced33. Besides document classifica-\ntion, term annotation was realized using a NER-based approach, described in\n(Coman et al., 2019b).\nFor the named entities belonging to the location class (LOC) of the Legal-\nNERo corpus 34 (Păis, et al., 2021b), an enhancement was done linking the\nnamed entities with GeoNames database 35 by using the feature identifiers as-\nsociated with each GeoNames feature. GeoNames is a geographical database\nwhich contains over 25 million geographical names covering all countries and\nconsists of over 11 million unique placenames, 4.8 million populated places and\n13 million alternate names. GeoNames is integrating geographical data such\nas names of places in various languages, elevation, population and others from\nvarious sources. It is available for download. For linking the named entities\nwith the GeoNames database a new column was created in the conllup corpus\nfiles structure. This GeoNames column was placed last in the file and by default\nis filled with the “_” character. This column would hold a value only when the\nnamed entity tag is of LOC type and when a perfect match is found within\n30https://fasttext.cc/\n31https://ec.europa.eu/jrc/en/language-technologies/jrc-eurovoc-indexer\n32https://relate.racai.ro/index.php?path=eurovoc/classify\n33https://github.com/racai-ai/ServerFastText\n34https://doi.org/10.5281/zenodo.4772094\n35https://www.geonames.org/\n9\nthe GeoNames database. The actual match is done via a lookup algorithm im-\nplemented in the Python language. In this algorithm, the GeoNames database\nextract for the Romanian language is loaded into a key:value list, where the\nkey is the standard location name and the value is the GeoNames location code\n(e.g. for the Suceava city this code is 486885). In many situations one location\ncan have several variations to the naming (that may come from using different\nspelling or even different names as they are known within different communi-\nties). In the GeoNames framework this situation is addressed by having only\none standard name (usually the official name of the location) and several sec-\nondary names that are part of the GeoNames entry for that location. The script\ntherefore, has created for each such variation a different entry in the lookup dic-\ntionary pointing to the same location code value. The conllup file format is\ntoken centric, while some locations have a multi-word format. Therefore, the\nactual first step in the lookup was to build the expressions from the tokens (by\nfinding consecutive LOC tokens). The actual lookup was performed per named\nentity (a multi-token list). When a perfect match was found (meaning partial\nsub-expression matches were ignored) all the tokens involved in the match were\nflagged as a GeoNames entity. The corresponding location code was finally filled\nin the GeoNames column.\n5.3\nAutomatic speech recognition\nThe RELATE platform contains two Romanian ASR models that can be ac-\ncessed using the graphical interface: RobinASR and RobinASRDev.\nThe two\nvariants are based on the DeepSpeech2 architecture (Amodei et al., 2016) and\nhave a reduced number of parameters compared with the original model in or-\nder to accommodate to the smaller size of their training corpus. Each model is\nwrapped as a web service and is deployed on a server with a GPU to achieve\nlow response time to the request of the front-end. However, although the two\nvariants are similar in architecture, they serve different purposes.\nThe former variant is a general ASR that was trained on a corpus composed\nof 230 hours of transcribed audio and obtained a 9.91 word error rate (WER)\nwhile combined with a language model (Heafield, 2011) used for textual correc-\ntion. The latter variant is a specialized ASR that fine-tunes the general model\non the technical domain using the ROBIN Technical Acquisition Speech Cor-\npus (ROBINTASC) corpus (Păis, et al., 2021a), improving the performance by\n16.4% on computer sales conversations. This variant also uses a language model\nthat was trained on the general corpus together with the train ROBINTASC\ntranscriptions, oversampled 10 times to increase n-grams frequencies.\n5.4\nText and speech translation\nThe speech to speech translation (S2ST) system Avram et al. (2021a) is com-\nposed of four cascaded modules: (1) ASR, (2) Textual Correction (TC), (3)\nMachine Translation (MT) and (4) TTS. Each module contains one or several\nmodels that can be configured in a full Romanian-English or English-Romainian\ninference, as depicted in Figure 2.\nThe ASR module contains two models for Romanian - those presented in\nSubsection 5.3 - and two models for English. The first variant - En DeepSpeech2\n- for English is also based on the DeepSpeech2 architecture and was trained on\n10\nFigure 2: The S2ST cascaded architecture with the four modules and their\nmodels (Romanian in the left, English in the right).\nthe LibriSpeech dataset (Panayotov et al., 2015), obtaining a 10.46 WER. The\nsecond variant - Mozilla DeepSpeech - for the English is the 0.9.3 version of\nDeepSpeech (Hannun et al., 2014) offered by Mozilla Speech-To-Text engine36\nand that obtained a 7.06% WER on LibriSpeech.\nWe offer at this time only a single model in the TC module for Romanian -\nRobin Correction. Its role is (1) to capitalize the transcribed speech using a\nlist of predefined named entities, (2) replace unknown words with words from a\nvocabulary and (3) restore hyphen using uni-gram and bi-gram statistics.\nThe Romanian-English - Presidency Ro-En - and English-Romanian - Presidency\nEn-Ro - models used by the MT module are the ones developed in the project\n\"CEF Automated Translation toolkit for the Rotating Presidency of the Council\nof the EU\", described in Section 3.\nThe TTS module contains a speech synthesizer model for English and two for\nRomanian. The English version - Mozilla En TTS - is based on Tacotron2 with\nDynamic Convolution Attention (Battenberg et al., 2020) offered by Mozilla\nText-to-Speech37. Their evaluation outlined a median opinion score (MOS) of\n4.31 ± 0.06 in a 95% confidence interval. The Romanian variants - Romanian\nTTS and RACAI SSLA - use HMM on their architecture, with the former variant\nbeing slower, but producing a higher quality speech and the latter being faster\nbut with a lower quality of the synthesis.\n6\nUsage scenarios\nGiven the complex nature of the RELATE platform and the large number of\nintegrated components, it has been used for a variety of purposes. However,\nthe scenarios described in this section are the most common ones. Moreover,\nthe description of the usage scenarios provides details into possible interactions\nbetween the platform’s components.\n36https://github.com/mozilla/DeepSpeech/releases/tag/v0.9.3\n37https://github.com/mozilla/TTS\n11\nFigure 3: Corpus processing flow\nFigure 4: Tasks interface component\n6.1\nLarge corpus processing\nLarge corpora can be uploaded in RELATE as archived .ZIP files. Upon upload,\nthe platform will schedule automatically a task for extracting the archive. Inside\nthe archive, the platform accepts raw text files (with .txt extension) and standoff\nmetadata. Metadata is usually specific to different research projects and can be\nused by different processing components to embed it into annotated documents.\nOnce the documents are available in the platform, different annotation tasks\ncan be scheduled and executed. The tasks interface is presented in Figure 4.\nFurthermore, statistics on both raw text and annotated documents can be com-\nputed.\nThe resulting annotated corpus can be archived and downloaded as\nanother .ZIP file.\nStatistics can be either visualized within the platform or\ndownloaded as .CSV files. The entire flow is depicted in Figure 3.\n6.2\nCreation of human annotated \"gold\" text corpora\nCreation of \"gold\" corpora involves human annotators identifying spans of text\nwith certain properties. For the creation of the LegalNERo38 (Păis, et al., 2021b)\ncorpus (a gold corpus for named entity recognition in the Romanian legal do-\nmain), we employed five annotators working in RELATE, annotating spans of\ntext with the corresponding named entities (legal reference, person, location,\norganization and time).\nFor the purpose of manual annotation of text corpora, RELATE integrates\nthe BRAT39 annotation tool (Stenetorp et al., 2012). This allows the user to\n38https://doi.org/10.5281/zenodo.4772094\n39https://brat.nlplab.org/index.html\n12\nFigure 5: Manual corpus annotation processing flow\nFigure 6: Manual corpus annotation GUI\nview one document at a time inside the BRAT component, select with the mouse\nthe desired text span and then associate a corresponding annotation type. The\ntext spans with associated start and end index as well as the annotation type\nare saved as standoff metadata files.\nSince different corpus processing applications may require token based anno-\ntations instead of span-based annotations, RELATE offers dedicated tasks for\nparallel conversion of the metadata to token-based annotations. This process\nmust be executed after an initial tokenization of the data, possibly including\nother automatic annotations such as part-of-speech tagging and dependency\nparsing. The final format for the data will be CoNLL-U Plus files with the gold\nannotations stored in a dedicated column. For a named entity corpus we use a\ncolumn named \"RELATE:NE\".\nOnce the corpus has been annotated (with or without conversion to the token\nbased format), it becomes possible to execute additional tasks within RELATE.\nA dedicated task allows extraction of gazetteer resources, allowing the produced\nfile to be downloaded and used in other applications requiring such resources. In\naddition, the statistics component can be used to extract information about the\nannotated corpus. The processing flow is depicted in Figure 5, while an example\nof the manual annotation component used with BioNER entities is presented in\nFigure 6.\n6.3\nCreation of read speech corpora\nRead speech corpora represent invaluable resources for the creation of Auto-\nmatic Speech Recognition (ASR) and Text-to-Speech (TTS) systems. These\nsystems can then be used as the building blocks for more advanced processing,\n13\nFigure 7: Creation of a bimodal corpus\nFigure 8: The interface used for recording read speech\nlike human-machine interaction and speech-to-speech translation. In the context\nof the ROBIN project, we were concerned with the performance of a low-latency\nASR system used for human-robot interaction, considering a micro-world sce-\nnario. For this purpose we created the ROBIN Technical Acquisition Speech\nCorpus (RTASC)40 (Păis, et al., 2021a), using the audio recording features of\nthe RELATE platform.\nEven though RELATE was initially constructed to process text corpora,\nthe recent addition of speech processing features, allowed it to handle bimodal\n(text and audio) corpora. For recording purposes, a dedicated component was\nconstructed.\nIt makes use of JavaScript and runs in the user’s browser.\nIt\ndisplays each sentence from the text component of the corpus and allows the user\nto record the associated speech. To improve the user experience, the sentence\nis displayed in a larger font and additional information such as the current\nsentence number and the total number of sentences is provided. The interface\nalso provides a playback function and, if necessary, allows the user to delete a\ncertain recording in order to record it again. The recording interface is shown\nin Figure 8.\nSince the text component still plays an important part in a bimodal corpus,\nall the text processing capabilities can be used to enhance the final corpus.\nIn this case, the annotation pipelines combined with the statistics generation\nfeature are available. The final corpus, comprised of raw text, annotated text\nand audio files, can be downloaded in an archived format from the platform.\nThe entire processing chain involved is presented in Figure 7.\n40https://doi.org/10.5281/zenodo.4626539\n14\n7\nConclusions\nIn this article we described the development of the RELATE platform, its archi-\ntecture and considered several of the most common usage scenarios. Currently,\nthe platform provides different levels of processing for Romanian language. Even\nthough initially it was developed for handling large text corpora, recent work\nadded speech capabilities, including speech-to-speech translation for Romanian-\nEnglish and English-Romanian language pairs.\nThe platform is designed to be highly customizable and easily extensible\nby creation of new components. The use of standardized file formats ensures\ninteroperability with other systems.\nAlso, the extensive use of REST APIs\nallows interoperability with external applications. Finally, the platform is open\nsourced and available freely on GitHub41.\nThe current running version of RELATE42 spans its processing capabili-\nties across four servers hosted at the Institute for Artificial Intelligence \"Mihai\nDrăgănescu\" of the Romanian Academy.\nThe servers contain both classical\nCPUs and a GPU resource, allowing different types of language processing tools\nto be used and guaranteeing high performance.\nIn the future we are planning to continue integrating new language processing\ntools in the RELATE platform, as they become available, while aiming to boost\ninteroperability and interactions leading to a productive LT ecosystem (Rehm\net al., 2020a), at both national and international level. One possible extension\nin this direction is the replacement of the current EuroVoc annotator with the\nRomanian model of PyEuroVoc (Avram et al., 2021b), a recently introduced\nlegal document classification tool for 22 languages that is based on a more\nmodern architecture - Bidirectional Encoder Representations from Transformers\n(BERT) (Devlin et al., 2019) - and that significantly improved the results of JEX\nby an average of 28% F1 score for all languages and 33.8% for Romanian.\nReferences\nAmodei D, Ananthanarayanan S, Anubhai R, Bai J, Battenberg E, Case C,\nCasper J, Catanzaro B, Cheng Q, Chen G, et al. (2016) Deep speech 2: End-\nto-end speech recognition in english and mandarin. In: International confer-\nence on machine learning, PMLR, pp 173–182\nAvram AM, Păis, V, Tufis, D (2020a) Romanian speech recognition experi-\nments from the robin project. In:\nThe 15th International Conference on\nLinguistic Resources and Tools for Natural Language Processing, pp 103–\n114, URL https://profs.info.uaic.ro/~consilr/wp-content/uploads/\n2021/03/volum-ConsILR-v-4-final-revizuit.pdf#page=111\nAvram AM, Păis, V, Tufis, D (2020b) Towards a Romanian end-to-end auto-\nmatic speech recognition based on Deepspeech2. Proceedings of the Roma-\nnian Academy Series A 21:395–402, URL https://acad.ro/sectii2002/\nproceedings/doc2020-4/11-Avram_Tufis.pdf\n41https://github.com/racai-ai/RELATE\n42https://relate.racai.ro\n15\nAvram AM, Păiş V, Tufiş D (2021a) A modular approach for romanian-english\nspeech translation. In: International Conference on Applications of Natural\nLanguage to Information Systems, Springer, pp 57–63\nAvram AM, Pais V, Tufis D (2021b) Pyeurovoc:\nA tool for multilin-\ngual legal document classification with eurovoc descriptors. arXiv preprint\narXiv:210801139\nBański P, Fischer PM, Frick E, Ketzan E, Kupietz M, Schnober C, Schone-\nfeld O, Witt A (2012) The new IDS corpus analysis platform: Challenges\nand prospects. In: Proceedings of the Eighth International Conference on\nLanguage Resources and Evaluation (LREC’12), European Language Re-\nsources Association (ELRA), Istanbul, Turkey, pp 2905–2911, URL http:\n//www.lrec-conf.org/proceedings/lrec2012/pdf/789_Paper.pdf\nBarbu Mititelu V (2018) Modern Syntactic Analysis of Romanian, Editura\nUniversităt,ii Alexandru Ioan Cuza, Ias,i, pp 67–78. URL https://www.\ndiacronia.ro/ro/indexing/details/V4891/pdf\nBarbu Mititelu V, Irimia E, Păis,\nV, Avram AM, Mitrofan M, Curea\nE\n(2020)\nRomanian\nresources\nin\nlinguistic\nlinked\nopen\ndata\nfor-\nmat.\nIn:\nThe\n15th\nInternational\nConference\non\nLinguistic\nRe-\nsources and Tools for Natural Language Processing,\npp 29–40,\nURL\nhttps://profs.info.uaic.ro/~consilr/wp-content/uploads/2021/03/\nvolum-ConsILR-v-4-final-revizuit.pdf#page=37\nBattenberg E, Skerry-Ryan R, Mariooryad S, Stanton D, Kao D, Shannon M,\nBagby T (2020) Location-relative attention mechanisms for robust long-form\nspeech synthesis. In: ICASSP 2020-2020 IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP), IEEE, pp 6194–6198\nBojanowski P, Grave E, Joulin A, Mikolov T (2017) Enriching word vec-\ntors with subword information. Transactions of the Association for Com-\nputational Linguistics 5:135–146, DOI 10.1162/tacl_a_00051, URL https:\n//www.aclweb.org/anthology/Q17-1010\nBoros, T, Dumitrescu S, , Păis, V (2018a) Tools and resources for romanian text-to-\nspeech and speech-to-text applications. In: Proceedings of the International\nConference on Human-Computer Interaction (RoCHI), pp 46–53\nBoros, T, Dumitrescu S, D, Burtică R (2018b) NLP-cube: End-to-end raw text\nprocessing with neural networks. In: Proceedings of the CoNLL 2018 Shared\nTask: Multilingual Parsing from Raw Text to Universal Dependencies, Asso-\nciation for Computational Linguistics, Brussels, Belgium, pp 171–179, DOI\n10.18653/v1/K18-2017, URL https://aclanthology.org/K18-2017\nChe W, Li Z, Liu T (2010) LTP: A Chinese language technology platform. In:\nColing 2010: Demonstrations, Coling 2010 Organizing Committee, Beijing,\nChina, pp 13–16, URL https://aclanthology.org/C10-3004\nColeman S, Secker A, Bawden R, Haddow B, Birch A (2020) Architecture of a\nscalable, secure and resilient translation platform for multilingual news media.\nIn: Proceedings of the 1st International Workshop on Language Technology\n16\nPlatforms, European Language Resources Association, Marseille, France, pp\n16–21, URL https://aclanthology.org/2020.iwltp-1.3\nComan A, Mitrofan M, Tufis, D (2019a) Automatic identification and classifica-\ntion of legal terms in romanian law texts. In: The 14th International Confer-\nence on Linguistic Resources and Tools for Natural Language Processing, pp\n39–49, URL https://profs.info.uaic.ro/~consilr/2019/wp-content/\nuploads/2020/01/ConsILR2019_final_BTT-60-ex-B5.pdf#page=47\nComan A, Mitrofan M, Tufis, D (2019b) Automatic identification and classifi-\ncation of legal terms in romanian law texts. In: International Conference on\nLinguistic Resources and Tools for Natural Language Processing\nCristea D, Pistol I, Boghiu S, , Bibiri AD, Gîfu D, Scutelnicu A, Onofrei M,\nTrandabăt, D, Bugeag G (2020) CoBiLiRo: A research platform for bimodal\ncorpora. In: Proceedings of the 1st International Workshop on Language\nTechnology Platforms, European Language Resources Association, Marseille,\nFrance, pp 22–27, URL https://aclanthology.org/2020.iwltp-1.4\nCunningham H, Maynard D, Bontcheva K, Tablan V (2002) GATE: an architec-\nture for development of robust HLT applications. In: Proceedings of the 40th\nAnnual Meeting of the Association for Computational Linguistics, Association\nfor Computational Linguistics, Philadelphia, Pennsylvania, USA, pp 168–175,\nDOI 10.3115/1073083.1073112, URL https://aclanthology.org/P02-1022\nDevlin J, Chang MW, Lee K, Toutanova K (2019) BERT: Pre-training of\ndeep bidirectional transformers for language understanding. In:\nProceed-\nings of the 2019 Conference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Language Technologies, Vol-\nume 1 (Long and Short Papers), Association for Computational Linguistics,\nMinneapolis, Minnesota, pp 4171–4186, DOI 10.18653/v1/N19-1423, URL\nhttps://aclanthology.org/N19-1423\nFedermann C, Giannopoulou I, Girardi C, Hamon O, Mavroeidis D, Minu-\ntoli S, Schröder M (2012) META-SHARE v2: An open network of repos-\nitories for language resources including data and tools. In: Proceedings of\nthe Eighth International Conference on Language Resources and Evaluation\n(LREC’12), European Language Resources Association (ELRA), Istanbul,\nTurkey, pp 3300–3303, URL http://www.lrec-conf.org/proceedings/\nlrec2012/pdf/816_Paper.pdf\nFinkel JR, Grenager T, Manning C (2005) Incorporating non-local information\ninto information extraction systems by Gibbs sampling. In: Proceedings of\nthe 43rd Annual Meeting of the Association for Computational Linguistics\n(ACL’05), Association for Computational Linguistics, Ann Arbor, Michigan,\npp 363–370, DOI 10.3115/1219840.1219885, URL https://aclanthology.\norg/P05-1045\nHannun A, Case C, Casper J, Catanzaro B, Diamos G, Elsen E, Prenger R,\nSatheesh S, Sengupta S, Coates A, et al. (2014) Deep speech: Scaling up\nend-to-end speech recognition. arXiv preprint arXiv:14125567\n17\nHeafield K (2011) Kenlm: Faster and smaller language model queries. In: Pro-\nceedings of the sixth workshop on statistical machine translation, pp 187–197\nIon R (2007) Word sense disambiguation methods applied to English and Ro-\nmanian. PhD thesis, Romanian Academy, in Romanian\nIon R (2018) Teprolin:\nAn extensible,\nonline text preprocessing plat-\nform for romanian. In:\nThe 13th International Conference on Lin-\nguistic\nResources\nand\nTools\nfor\nNatural\nLanguage\nProcessing,\npp\n69–76, URL https://profs.info.uaic.ro/~consilr/2019/wp-content/\nuploads/2019/06/volum-ConsILR-2018-1.pdf#page=77\nIon R, Badea VG, Cioroiu G, Barbu Mititelu V, Irimia E, Mitrofan M, Tufis, D\n(2020) A dialog manager for micro-worlds. Studies in Informatics and Con-\ntrol 29(4):411–420, DOI 10.24846/v29i4y202003, URL https://sic.ici.ro/\na-dialog-manager-for-micro-worlds/\nJoulin A, Grave E, Bojanowski P, Mikolov T (2017) Bag of tricks for efficient\ntext classification. In: Proceedings of the 15th Conference of the European\nChapter of the Association for Computational Linguistics: Volume 2, Short\nPapers, Association for Computational Linguistics, Valencia, Spain, pp 427–\n431, URL https://aclanthology.org/E17-2068\nMiller GA (1995) Wordnet: A lexical database for english. Commun ACM\n38(11):39–41,\nDOI 10.1145/219717.219748,\nURL https://doi.org/10.\n1145/219717.219748\nMitrofan M, Mititelu VB, Mitrofan G (2018) Towards the construction of a gold\nstandard biomedical corpus for the Romanian language. Data 3(4):12\nPăis, V (2019) Contributions to semantic processing of texts; identification of\nentities and relations between textual units; case study on romanian language.\nPhD thesis, Romanian Academy\nPăis,\nV\n(2020)\nMultiple\nannotation\npipelines\ninside\nthe\nrelate\nplat-\nform.\nIn:\nThe\n15th\nInternational\nConference\non\nLinguistic\nRe-\nsources and Tools for Natural Language Processing,\npp 65–75,\nURL\nhttps://profs.info.uaic.ro/~consilr/wp-content/uploads/2021/03/\nvolum-ConsILR-v-4-final-revizuit.pdf#page=73\nPăis, V, Tufis, D (2018) Computing distributed representations of words\nusing the corola corpus. Proceedings of the Romanian Academy,\nSe-\nries A 19(2):403 – 409, URL https://academiaromana.ro/sectii2002/\nproceedings/doc2018-2/Art12Pais.pdf\nPăis, V, Tufis, D, Ion R (2019) Integration of romanian nlp tools into\nthe relate platform. In:\nThe 14th International Conference on Lin-\nguistic Resources and Tools for Natural Language Processing, pp 181–\n192,\nURL\nhttps://profs.info.uaic.ro/~consilr/2019/wp-content/\nuploads/2020/01/ConsILR2019_final_BTT-60-ex-B5.pdf#page=189\nPăis, V, Tufis, D, Ion R (2020) A processing platform relating data and tools\nfor romanian language. In: Proceedings of The 12th Language Resources\n18\nand Evaluation Conference, European Language Resources Association, Mar-\nseille, France, pp 81–88, URL https://lrec2020.lrec-conf.org/media/\nproceedings/Workshops/Books/IWLTP2020book.pdf#page=87\nPăis, V, Ion R, Barbu Mititelu V, Irimia E, Mitrofan M, Avram AM (2021a)\nRobin technical acquisition speech corpus. DOI 10.5281/zenodo.4626539,\nURL https://doi.org/10.5281/zenodo.4626539\nPăis, V, Mitrofan M, Gasan CL, Ianov A, Ghit,ă C, Coneschi VS, Onut, A (2021b)\nRomanian Named Entity Recognition in the Legal domain (LegalNERo). DOI\n10.5281/zenodo.4772094, URL https://doi.org/10.5281/zenodo.4772094\nPanayotov V, Chen G, Povey D, Khudanpur S (2015) Librispeech: an asr corpus\nbased on public domain audio books. In: 2015 IEEE international conference\non acoustics, speech and signal processing (ICASSP), IEEE, pp 5206–5210\nPerovšek M, Kranjc J, Erjavec T, Cestnik B, Lavrač N (2016) Textflows: A\nvisual programming platform for text mining and natural language process-\ning. Science of Computer Programming 121:128–152, DOI https://doi.org/10.\n1016/j.scico.2016.01.001, URL https://www.sciencedirect.com/science/\narticle/pii/S0167642316000113, special Issue on Knowledge-based Soft-\nware Engineering\nPouliquen B, Steinberger R, Ignat C (2006) Automatic annotation of multilin-\ngual text collections with a conceptual thesaurus. ArXiv abs/cs/0609059\nQi P, Zhang Y, Zhang Y, Bolton J, Manning CD (2020) Stanza: A python\nnatural language processing toolkit for many human languages. In:\nPro-\nceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics: System Demonstrations, Association for Computational Linguis-\ntics, Online, pp 101–108, DOI 10.18653/v1/2020.acl-demos.14, URL https:\n//aclanthology.org/2020.acl-demos.14\nRebai I, Benhamiche S, Thompson K, Sellami Z, Laine D, Lorré JP (2020)\nLinTO platform: A smart open voice assistant for business environments.\nIn: Proceedings of the 1st International Workshop on Language Technology\nPlatforms, European Language Resources Association, Marseille, France, pp\n89–95, URL https://aclanthology.org/2020.iwltp-1.14\nRehm G, Bontcheva K, Choukri K, Hajič J, Piperidis S, Vasil,jevs A (eds) (2020a)\nProceedings of the 1st International Workshop on Language Technology Plat-\nforms, European Language Resources Association, Marseille, France, URL\nhttps://www.aclweb.org/anthology/2020.iwltp-1.0\nRehm G, Galanis D, Labropoulou P, Piperidis S, Welß M, Usbeck R, Köhler\nJ, Deligiannis M, Gkirtzou K, Fischer J, Chiarcos C, Feldhus N, Moreno-\nSchneider J, Kintzel F, Montiel E, Rodríguez Doncel V, McCrae JP, Laqua\nD, Theile IP, Dittmar C, Bontcheva K, Roberts I, Vasil,jevs A, Lagzdin, š A\n(2020b) Towards an interoperable ecosystem of AI and LT platforms:\nA\nroadmap for the implementation of different levels of interoperability. In:\nProceedings of the 1st International Workshop on Language Technology Plat-\nforms, European Language Resources Association, Marseille, France, pp 96–\n107, URL https://www.aclweb.org/anthology/2020.iwltp-1.15\n19\nSchmid H (1994) Probabilistic part-of-speech tagging using decision trees. In:\nProceedings of International Conference on New Methods in Language Pro-\ncessing\nSchmid H (2019) Deep learning-based morphological taggers and lemmatizers\nfor annotating historical texts. In: Proceedings of the 3rd International Con-\nference on Digital Access to Textual Cultural Heritage, Association for Com-\nputing Machinery, New York, NY, USA, DATeCH2019, p 133–137, DOI 10.\n1145/3322905.3322915, URL https://doi.org/10.1145/3322905.3322915\nStan A, Yamagishi J, King S, Aylett M (2011) The romanian speech synthesis\n(rss) corpus: Building a high quality hmm-based speech synthesis system\nusing a high sampling rate. Speech Communication 53(3):442–450\nSteinberger R, Pouliquen B, Widiger A, Ignat C, Erjavec T, Tufiş D, Varga\nD (2006) The JRC-Acquis:\nA multilingual aligned parallel corpus with\n20+ languages. In:\nProceedings of the Fifth International Conference on\nLanguage Resources and Evaluation (LREC’06), European Language Re-\nsources Association (ELRA), Genoa, Italy, URL http://www.lrec-conf.\norg/proceedings/lrec2006/pdf/340_pdf.pdf\nSteinberger R, Ebrahim M, Turchi M (2012) JRC eurovoc indexer JEX - a freely\navailable multi-label categorisation tool. In: Proceedings of the Eighth Inter-\nnational Conference on Language Resources and Evaluation (LREC’12), Eu-\nropean Language Resources Association (ELRA), Istanbul, Turkey, pp 798–\n805, URL http://www.lrec-conf.org/proceedings/lrec2012/pdf/875_\nPaper.pdf\nStenetorp P, Pyysalo S, Topić G, Ohta T, Ananiadou S, Tsujii J (2012) brat:\na web-based tool for NLP-assisted text annotation. In: Proceedings of the\nDemonstrations at the 13th Conference of the European Chapter of the\nAssociation for Computational Linguistics, Association for Computational\nLinguistics, Avignon, France, pp 102–107, URL https://www.aclweb.org/\nanthology/E12-2021\nStraka M, Hajič J, Straková J (2016) Ud-pipe: trainable pipeline for processing\nconll-u files performing tokenization, morphological analysis, pos tagging and\nparsing. In: Proceedings of the 10th International Conference on Language\nResources and Evaluation (LREC 2016), European Language Resources As-\nsociation, Portorož, Slovenia\nTufis, D, Mititelu VB (2015) The Lexical Ontology for Romanian, Springer Inter-\nnational Publishing, Cham, pp 491–504. DOI 10.1007/978-3-319-08043-7_27,\nURL https://doi.org/10.1007/978-3-319-08043-7_27\nTufis, D, Barbu Mititelu V, Irimia E, Mitrofan M, Ion R, Cioroiu G (2019a)\nMaking pepper understand and respond in romanian. In: 22nd International\nConference on Control Systems and Computer Science (CSCS), pp 682–688,\nDOI 10.1109/CSCS.2019.00122\nTufis, D, Mititelu VB, Irimia E, Păis, V, Ion R, Diewald N, Mitrofan M, Onofrei\nM (2019b) Little strokes fell great oaks. creating corola, the reference corpus\nof contemporary romanian. Revue Roumaine de Linguistique 64(3):227 – 240,\nURL http://www.lingv.ro/images/RRL%203%202019%2003-DTufis.pdf\n20\nTufis, D, Mitrofan M, Păis, V, Ion R, Coman A (2020) Collection and anno-\ntation of the Romanian legal corpus. In: Proceedings of the 12th Language\nResources and Evaluation Conference, European Language Resources Asso-\nciation, Marseille, France, pp 2773–2777, URL https://aclanthology.org/\n2020.lrec-1.337\nVáradi T, Koeva S, Yamalov M, Tadić M, Sass B, Nitoń B, Ogrodniczuk M,\nPęzik P, Barbu Mititelu V, Ion R, Irimia E, Mitrofan M, Păis, V, Tufis,\nD, Garabík R, Krek S, Repar A, Rihtar M, Brank J (2020) The MAR-\nCELL legislative corpus. In: Proceedings of the 12th Language Resources and\nEvaluation Conference, European Language Resources Association, Marseille,\nFrance, pp 3761–3768, URL https://aclanthology.org/2020.lrec-1.464\n21\n",
  "categories": [
    "cs.CL"
  ],
  "published": "2024-10-29",
  "updated": "2024-10-29"
}