{
  "id": "http://arxiv.org/abs/2501.05093v1",
  "title": "Hierarchical Decomposed Dual-domain Deep Learning for Sparse-View CT Reconstruction",
  "authors": [
    "Yoseob Han"
  ],
  "abstract": "Objective: X-ray computed tomography employing sparse projection views has\nemerged as a contemporary technique to mitigate radiation dose. However, due to\nthe inadequate number of projection views, an analytic reconstruction method\nutilizing filtered backprojection results in severe streaking artifacts.\nRecently, deep learning strategies employing image-domain networks have\ndemonstrated remarkable performance in eliminating the streaking artifact\ncaused by analytic reconstruction methods with sparse projection views.\nNevertheless, it is difficult to clarify the theoretical justification for\napplying deep learning to sparse view CT reconstruction, and it has been\nunderstood as restoration by removing image artifacts, not reconstruction.\n  Approach: By leveraging the theory of deep convolutional framelets and the\nhierarchical decomposition of measurement, this research reveals the\nconstraints of conventional image- and projection-domain deep learning\nmethodologies, subsequently, the research proposes a novel dual-domain deep\nlearning framework utilizing hierarchical decomposed measurements.\nSpecifically, the research elucidates how the performance of the\nprojection-domain network can be enhanced through a low-rank property of deep\nconvolutional framelets and a bowtie support of hierarchical decomposed\nmeasurement in the Fourier domain.\n  Main Results: This study demonstrated performance improvement of the proposed\nframework based on the low-rank property, resulting in superior reconstruction\nperformance compared to conventional analytic and deep learning methods.\n  Significance: By providing a theoretically justified deep learning approach\nfor sparse-view CT reconstruction, this study not only offers a superior\nalternative to existing methods but also opens new avenues for research in\nmedical imaging.",
  "text": "Hierarchical Decomposed Dual-domain\nDeep Learning for Sparse-View CT Reconstruction\nYoseob Han 1, 2\n1 Department of Electronic Engineering, Soongsil University, South Korea\n2 Department of Intelligent Semiconductors, Soongsil University, South Korea\nE-mail: yoseob.han@ssu.ac.kr\nDecember 2023\nAbstract.\nObjective:\nX-ray computed tomography employing sparse projection\nviews has emerged as a contemporary technique to mitigate radiation dose. However,\ndue to the inadequate number of projection views, an analytic reconstruction method\nutilizing filtered backprojection results in severe streaking artifacts. Recently, deep\nlearning strategies employing image-domain networks have demonstrated remarkable\nperformance in eliminating the streaking artifact caused by analytic reconstruction\nmethods with sparse projection views.\nNevertheless, it is difficult to clarify the\ntheoretical justification for applying deep learning to sparse view CT reconstruction,\nand it has been understood as restoration by removing image artifacts,\nnot\nreconstruction.\nApproach:\nBy leveraging the theory of deep convolutional framelets and the\nhierarchical decomposition of measurement, this research reveals the constraints of\nconventional image- and projection-domain deep learning methodologies, subsequently,\nthe research proposes a novel dual-domain deep learning framework utilizing\nhierarchical decomposed measurements.\nSpecifically, the research elucidates how\nthe performance of the projection-domain network can be enhanced through a low-\nrank property of deep convolutional framelets and a bowtie support of hierarchical\ndecomposed measurement in the Fourier domain.\nMain Results: This study demonstrated performance improvement of the proposed\nframework based on the low-rank property, resulting in superior reconstruction\nperformance compared to conventional analytic and deep learning methods.\nSignificance:\nBy providing a theoretically justified deep learning approach for\nsparse-view CT reconstruction, this study not only offers a superior alternative\nto existing methods but also opens new avenues for research in medical imaging.\nIt highlights the potential of dual-domain deep learning frameworks to achieve\nhigh-quality reconstructions with lower radiation doses, thereby advancing the field\ntowards safer and more efficient diagnostic techniques.\nThe code is available at\nhttps://github.com/hanyoseob/HDD-DL-for-SVCT.\narXiv:2501.05093v1  [cs.LG]  9 Jan 2025\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n2\n1. Introduction\nX-ray computed tomography (CT) has gained widespread acceptance for its ability\nto produce high-quality and high-resolution images.\nHowever, one critical concern\nassociated with the use of X-ray CT lies in its potential to increase the risk of cancer\ndue to the radiation exposure it entails [1]. In response to this concern, many researches\nhave been dedicated to developing strategies for reducing radiation exposure [2]. These\nstudies were integrated around three main approaches: (1) low-dose CT, focusing on\nphoton counts of X-ray source [3, 4, 5, 6, 7]; (2) interior tomography, emphasizing\nregion-of-interest (ROI) [8, 9]; and (3) sparse-view CT, involving projection views\n[10, 11, 12, 13, 14].\nSpecifically, conventional multi-detector CT (MDCT), which\nrequires rapid and continuous measurement acquisition, is limited in its ability to use\nthe sparse-view CT. However, the sparse-view CT is intriguing for new applications,\nincluding spectral CT using alternating kVp switching [15], dynamic beam blocker [16],\netc. Additionally, when applied to C-arm CT or dental CT, the scanning duration is\nprimarily constrained by the relatively slower speed of the flat-panel detector, as opposed\nto the mechanical speed of the gantry. Therefore, the sparse-view CT offers a promising\nmethod for reducing scanning time in these contexts [17, 18].\nHowever, incomplete projection views collected from sparse-view CT can lead to\nsevere streaking artifacts when applying analytic methods such as filtered backprojection\n(FBP). To address this issue, researchers have explored the use of compressed sensing\n(CS) techniques [19] that minimizes total variation (TV) or other forms of sparsity-\ninducing penalties under data fidelity term [20, 21, 17, 18, 22].\nNevertheless, these\nmethods require significant computational burden due to the need for repeated\nprojection and backprojection operations in iterative update steps.\nOver the past few years, deep learning (DL) has emerged as a high-performance\nalgorithm in the field of CT image reconstruction. These DL-based algorithms have\ndemonstrated superior performance compared to traditional model-based iterative\nreconstruction (MBIR) methods [23, 21],\nexcelling in both image quality and\nreconstruction time.\nAs illustrated in Figure 1(a), a sparse-view CT image suffers from streaking artifacts\npresented as global artifacts.\nConventional image-domain DLs [13, 24, 25, 26] (see\nFigure 2(a)(ii)) work to mitigate streaking artifacts within the image domain.\nAs\ndepicted in Figure 1(a), these approaches primarily perform the function as image\nartifact removers, but the underlying cause of artifacts mainly originates from\nincomplete measurements within the projection domain, such as a limited numbers\nof views.\nIn addition, the image-domain DL requires the use of entire CT images\nrather than patch images to effectively capture the global features of the streaking\nartifact.\nIn an effort to directly address the issue of incomplete measurement,\nprojection-domain DLs [24, 27, 28, 10, 12] (see Figure 2(b)(ii)) have been introduced\nto reconstruct undersampled projection data.\nThese approaches work as missing\ndata reconstructor, as illustrated in Figure 1(b). To train projection-domain DL,\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n3\nFigure 1. Types of deep learning approaches for sparse-view CT. (a) Image artifact\nremover using image-domain DL and (b) missing data reconstructor using projection-\ndomain DL.\nresearchers utilized the full-size projection data associated with the entire CT image\n[10, 28] or small projection patches unrelated to the CT image patches [24, 27, 12].\nRecently, dual-domain DLs [29, 30, 10, 31, 8] is being actively researched to achieve\nbetter performance than uni-modality DLs. However, their study merely connected the\nprojection domain and the image domain DLs sequentially.\nThe study proposes a novel dual-domain DL framework designed to reconstruct\nmissing projection data and remove remaining CT image artifacts.\nSpecifically, the\nproposed method improves performance by exploiting robust mathematical properties\nto achieve low rankness [32].\nThe research reveals that the low-rank characteristics\nis closely related to the bowtie support of the projection data within the Fourier\ndomain [33]. Furthermore, this study shows that performance is improved by controlling\nthe low rankness through the bowtie support for hierarchical decomposed projection\ndata associated with the CT image-patch.\nIn particular, this paper demonstrates\nthat the proposed method performs better when trained with higher-order hierarchical\ndecomposed projection data. The major contributions of this paper are as follows:\n• The study provides evidence that the utilization of bowtie support in projection\ndata within the Fourier domain serves as a powerful mathematical clue to improve\nthe performance of projection-domain DL based on deep convolutional framelets\n(DCF) theory [32].\n• The study proposes a novel dual-domain DL framework that satisfies low rankness\nbecause it is trained with high-order hierarchically decomposed projection data\nusing a narrow bowtie support within the Fourier domain, designed to reconstruct\nmissing projection data.\n• The study demonstrates that using higher-order hierarchically decomposed\nprojection data associated with CT image-patches shows better performance when\ntraining projection-domain DLs.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n4\nFigure 2. (a) Image-domain DL framework consisting of two image-domains networks\nand (b) proposed DL framework consisting projection-domain network and image-\ndomain network. (c) Function modules used in (a) and (b). The network has four\nparts: (i) pre-processing, (ii) 1st phase network, (iii) 2nd phase network, and (iv)\npost-processing.\n2. Related Works\n2.1. Image-domain Deep Learning Approaches\nThe image-domain DL approach, as illustrated in Figure 1(a) acts as an image artifact\nremovers, performing a nonlinear mapping from the sparse-view CT image to the full-\nview CT image. This approach is recognized as a post-processing technique because\nthe DL is directly applied to corrupted CT images reconstructed from incomplete\nmeasurements. Commonly, to perform image-domain DL approaches, many researchers\n[11, 34, 14, 13] follow the flowcharts shown in Figure 2(a). In terms of the network\narchitecture, Xie et al. [14] used the GoogLeNet structure to remove streaking artifacts.\nHan et al. [13] developed a framing U-Net to preserve high-frequency features. Lee et\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n5\nal. [11] combined multi-level wavelet operations with a U-Net architecture. From the\nperspective of the loss function, Zhang et al. [34] used Lp (0 < p < 2) regression loss\nrather than L2 regression loss to preserve texture details. Thaler et al. [35] employed\nWasserstein loss with a generative adversarial network (GAN) to improve sharpness and\nretain structural information in reconstructed images.\n2.2. Projection-domain Deep Learning Approaches\nUnlike the image-domain DL approaches, the projection-domain DL approach is a pre-\nprossessing technique because it reconstructs incomplete measurements rather than\ncorrupted images, as shown in Figure 1(b). Dong et al. [27] used a U-Net trained with\nsmall patches of linear-interpolated projection data to synthesize a full-view projection.\nLee et al. [24] proposed a fully convolutional U-Net by replacing the pooling layer with a\nconvolutional layer and trained the network with small patches of interpolated projection\ndata. A limitation of previous approaches is that, although the goal of the network\nis to reconstruct high-quality CT images, there is no relationship between the small\nmeasurement patches used to train the network and the patches in the CT images.\n2.3. Dual-domain Deep Learning Approaches\nThe dual-domain DL framework is a hybrid network that sequentially connects the\nprojection-domain DL and the image-domain DL. Particularly, the dual-domain DL\nwas developed to marge the advantage of both DLs simultaneously. Zheng et al. [30]\nused two sequential U-Nets to reconstruct sparse-view measurements and enhance CT\nimages. We et al. [10] used a discriminator to match the CT image distribution between\ngenerated images from sparse-view CT and corresponding labels. However, since the\napproaches are only a structured and sequential network connection, it is difficult to\nfind suitable data processing and theoretical information flow principles.\nTo address the limitation of previous DL-based approaches, the study proposes a\nnovel dual-domain DL framework designed to reconstruct incomplete projection patches\nassociated with CT image patches, as shown in Figure 2(b). The proposed method\nconsists of 4 parts: (1) hierarchical decomposition of filtered projection data related\nto CT image-patches, (2) projection-domain DL model to reconstruct a decomposed\nfull-view projection for the reconstruction of CT image-patches, (3) image-domain DL\nto correct remaining image noise and artifacts, and (4) composition of the entire CT\nimage using the reconstructed CT image-patches. The hierarchical decomposition part\nestablishes an explicit relationship between projection-patches and CT image-patches\nand provides a mathematical foundation for achieving performance improvement due to\nthe low-rank property through Fourier-domain support constraints.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n6\n3. Theory\n3.1. Deep Convolutional Framelets\nDCF theory [32] has established a mathematical connection between traditional signal\nprocessing and deep learning.\nThis connection originates from the Hankel matrix\napproaches [36], leading to the formulation of a regression problem with a constraint\ndefined by a low-rank Hankel structured matrix, as outlined below:\narg min\n¯f∈Rn\n||f −¯f||2\n(1)\nsubject to RANKHd( ¯f) = r < d,\nwhere f ∈Rn and ¯f ∈Rn represent a label image and predicted image, respectively. n\nis a length of the signal, r denotes a rank of the Hankel structured matrix Hd( ¯f) ∈Rn×d,\nand d is a matrix pencil parameter. Notably, the rank of the Hankel structured matrix\nRANKHd( ¯f) is determined by the number of non-zero components in the Fourier domain\nof the solution F( ¯f):\nRANKHd( ¯f) = COUNT\n\u0000F( ¯f) ̸= 0\n\u0001\n.\n(2)\nIf a feasible solution ¯f exists, the singular value decompostion (SVD) of its Hankel\nstructured matrix Hd( ¯f) can be expressed as SVD(Hd( ¯f)) = UΣV T, where U ∈Rn×r\nand V ∈Rd×r denote the left and right singular vector bases matrices, respectively, and\nΣ = (σ) ∈Rr×r represents the diagonal matrix of singular values. In this context, we\nconsider two pairs of matrices Φ, ˜Φ ∈Rn×n and Ψ, ˜Ψ ∈Rd×r, which satisfy the following\nconditions:\n(a) ˜ΦΦT = In×n,\n(b) Ψ˜ΨT = PR(V ),\n(3)\nwhere R(V ) denotes a range space of V , and PR(V ) represents a projection onto R(V ).\nUsing Eq. 3, we can formulate an equality of the Hankel structured matrix Hd( ¯f), given\nby:\nHd( ¯f) = ˜ΦΦTHd( ¯f)Ψ˜ΨT.\n(4)\nFrom Eq. 4, we can establish a space Fr collecting feasible images ¯f, as follows:\nFr =\nn\n¯f ∈Rn\f\f\f ¯f =\n\u0010\n˜ΦC\n\u0011\n⊛ν(˜Ψ), C = ΦT( ¯f ⊛¯Ψ)\no\n,\n(5)\nwhere ¯Ψ and ν(˜Ψ) denote encoder- and decoder-layer convolutional filters, respectively.\nThe regression problem initially in Eq. 1 can be reformulated using the space Fr as\nfollows:\narg min\n¯f∈Fr\n||f −¯f||2,\n(6)\nwhich can be expressed by optimizing kernels (Ψ, ˜Ψ) of neural network Q as follows:\narg min\n(Ψ,˜Ψ) ||f −Q(q; Ψ, ˜Ψ)||2,\n(7)\nwhere q is a noisy image. The neural network Q can be trained with extensive datasets\n{(q(i), f (i))}N\ni=1 to learn the kernels (Ψ, ˜Ψ) that represent RANKHd( ¯f (i)) ≤rmax, where\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n7\nrmax is the largest rank of the Hankel structured matrix Hd( ¯f (i)) among the datasets,\nand d is redefined by the convolutional filter length, as described by:\narg min\n(Ψ,˜Ψ)\nN\nX\ni=1\n||f (i) −Q(q(i); Ψ, ˜Ψ)||2.\n(8)\nFrom Eq. 1, the largest rank rmax of Hankel structured matrix RANKHd( ¯f) is\nbounded by the convolutional filter length d. To satisfy the low-rank property, the filter\nlength d can be increased until the signal length n, but a network architecture with long\nfilter length d ≃n is difficult to utilized due to computational resources and efficiency.\nTherefore, to improve the performance when the network architecture Q is fixed, rmax\nshould be reduced. An easy way to reduce rmax is to reduce the non-zero components\nof the signal ¯f in the Fourier domain based on Eq. 2.\n3.2. Bowtie Support in the Fourier domain\nIn the following, the paper first delineates the Radon transform, denoted by R, and\nsubsequently extend it to describe a bowtie support of measurements in the Fourier\ndomain. Let θ represent a vector on the unit sphere S ∈R2 . The set of orthogonal\nvectors, denoted by θ⊥, is characterized as:\nθ⊥= {v ∈R2 : v · θ = 0},\n(9)\nwhere · represents an inner product. If an image is defined by f(x) for x ∈R2, the\nRadon transform R of the image f can be expressed as follows:\nRf(θ, u) = pf(θ, u)\n(10)\n=\nZ\nθ⊥dv f(v + uθ),\nwhere u ∈R and θ ∈S. In order to evaluate the maximum rank rmax of the Hankel\nstructured matrix corresponding to the measurements pf as defined in Eq. 2, the 2D\nFourier transform F2D is applied to Eq. 10, as follows:\nF2Dpf(θ, u) = Pf(ωθ, ωu)\n(11)\n=\nZ ∞\n−∞\nZ ∞\n−∞\ndθdu pf(θ, u)e−j(ωθθ+ωuu).\nThanks to Rattey et al. [33], the measurement Pf(ωθ, ωu) is bounded by a bowtie\nsupport in the Fourier domain, as shown in Figure 3(a). A slope of the bowtie support\nis determined by 1\nN , where N denotes a radius of the entire CT image f. Consequently,\nthe rank r of Hankel structured matrix RANKHd(pf) can be determined as the area\nof bowtie support within the Fourier domain. The filtered measurements q = F(pf) is\nequivalent to an element-wise weighted measurements in the Fourier domain. Therefore,\nthey have the same bowtie support and satisfy the same rank r.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n8\nFigure 3. Bowtie support in the Fourier domain according to (a) K = 1 and (b) K =\n3. Here, N is a radius of object, K is a decomposition level, and B is a bandlimit.\nFigure 4. Hierarchical decomposition concept for decomposition levels of (a) image-\ndomain and (b) projection-domain.\n3.3. Hierarchical Decomposition of Measurements\nFrom the analysis in the previous sections 3.2, it has been observed that a measurement\ncollected by the Radon transform R exists within the bowtie support in the Fourier\ndomain, as grounded on the work by [33].\nAdditionally, the support area (2B2N)\nhas been found to correspond with the rank r of the Hankel structured matrix of the\nmeasurement Hd(q), as elucidated by the DCF theory [32]. When a network architecture\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n9\nAlgorithm 1 Hierarchical measurement decomposition\nRequire: q, Nx, Ny, Ndct, Nview, K\n1: NK ←2(K−1)\n2: (N K\nx , N K\ny , N K\ndct) ←( Nx\nNK ,\nNy\nNK ,\nNdct\nNK )\n3: xC ←linspace(−(Nx\n2 −Nx\n2K ), (Nx\n2 −Nx\n2K ), N K\nx ) # X-axis center position of image patch\n4: yC ←linspace(−(Ny\n2 −Ny\n2K ), (Ny\n2 −Ny\n2K ), N K\ny ) # Y-axis center position of image patch\n5: θ ←linspace(0, 2π, Nview)\n6: Mrot ←[cos(θ), sin(θ)]\n# Rotation matrix along view angle\n7: qK ←zeros(N 2\nK, Nview, N K\ndct)\n8: for j = 0 : NK do\n9:\nfor i = 0 : NK do\n10:\ndctC ←Mrot · [yC(i), xC(j)]\n# Detector center position for image patch\n11:\n˜qK ←Align(q, dctC)\n# Align q along detector center line\n12:\nˆqK ←Extract(˜qK, N K\ndct)\n# Extract aligned patch ˜q\n13:\nk ←N K\ny × j + i\n14:\nqK(k) ←ˆqK\n# Collect decomposed measurement ˆq into level K\n15:\nend for\n16: end for\n17: return qK\nis fixed, the improvement of network performance is closely related to how well it\nachieves the lower rankness of the Hankel structured matrix. In other words, a smaller\nsupport area generally indicates better performance.\nTo accomplish a reduction of\nthe support area in the Fourier domain, a hierarchical decomposition algorithm [37] is\napplied to the measurement, as illustrated in Figure 3(b). By reducing the image size\nN by a decomposition level K, the area ((2B2N)/K) can also be diminished by the\nsame proportion. Therefore, the low-rank property is achieved through a decomposed\nprojection associated with the image-patch.\nThe concept of the decomposition is\nillustrated in Figure 4, which shows both (a) image-patches and (b) projection-patches\nin accordance with the decomposition level K. The decomposition process of projection-\npatches DK\nprj is described in the Algorithm 1.\n4. Main Contributions\nIn Section 3, the paper established that the DL performance is closely related to a low\nrankness of a Hankel structured matrix of data in the Fourier domain, as per the DCF\ntheory [32]. The projection data also exhibits bowtie support in the Fourier domain\n[33] and can be hierarchically decomposed into forms with narrow bowtie support\n[37]. Thanks to the DCF theory [32] and the hierarchical decomposition method [37],\nthis study can achieve lower rankness through higher hierarchical decomposition of the\nmeasurements.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n10\nAlgorithm 2 Input data generation for Qimg1 and Qprj1\nRequire: p, MS\n1: pS ←MS ⊙p\n# Sparse-view measurement\n2: fS ←RT\nS(F(qS))\n# Input data of Qimg1\n3: ˆpS ←R(fS)\n# Interpolated measurement\n4: ¯pS ←(1 −MS) ⊙ˆpS + MS ⊙p # Data-consistency regularization\n5: qS ←F(¯pS)\n# Input data of Qprj1\n6: return fS, qS\nBased on two mathematical clues, this study proposes a novel hierarchical\ndecomposed dual-domain DL (PI-Net; QK\nprj1, QK\nimg2) as shown in Figure 2(b).\nTo\nenforce the low-rank property, a projection-domain hierarchical decomposition DK\nprj (see\nFigure 4(b)) is applied to the measurements, as illustrated in Figure 2(b)(i). Next, the\nprojection-domain network (P-Net; QK\nprj) is trained by the decomposed measurements\nwith various DS factors S applied simultaneously, as shown in Figure 2(b)(ii). Once\nthe P-Net QK\nprj is fixed, the maximum available rank rmax is also determined. However,\ndue to various DS factors S, the required rank may increase as the number of training\ndatasets increased. Here, thanks to the projection-domain hierarchical decomposition\nDK\nprj, the P-Net QK\nprj can be well-trained with the decomposed measurements because the\nnarrow bowtie support of decomposed measurements in the Fourier domain reduces the\nrequired ranks. As shown in Figure 2(b)(iii), the image-domain network (I-Net; QK\nimg) is\nconnected as an unrolled scheme to correct remaining artifacts after P-Net QK\nprj. Finally,\nan image-domain composition CK\nimg is applied to the image-patches reconstructed from\nthe I-Net QK\nimg in order to convert it into an entire CT image.\nIn the paper, the\ndecomposition level K = 5 is used. To compare with the proposed PI-Net in Figure\n2(b), a decomposed image-domain DL (II-Net; QK\nimg1, QK\nimg2) consisting of two-times\nunrolled I-Net QK\nimg was used, as shown in Figure 2(a).\n5. Experiments\n5.1. Datasets\nFor this study, ten subject datasets were sourced from the American Association of\nPhysicists in Medicine (AAPM) Low-Dose CT Grand Challenge [38]. These datasets\nwere utilized in the following: among the ten subjects, nine were allocated to training\nand validation. Specifically, eight subjects comprising 4,006 slices were used for training,\nand one subject with 254 slices was designated for validation. The remaining subject,\ncontaining 486 slices, was employed as the test dataset. Although the parallel beam\nCT geometry was used in this experiment, the measurements collected from fan beam\nCT can also be utilized by rebinning to the form of parallel beam measurements. The\nimage size (Nx, Ny) is (512, 512), with a pixel resolution of 1 mm2.\nThe number\nof views Nview is 768, and the rotation range for the X-ray source is [0◦, 360◦). The\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n11\nFigure 5. (a) Backbone based on the standard U-Net architecture. (b) Layer modules\nused in (a).\nnumber of detectors Ndct is 768, and the detector pitch is 1 mm. Additionally, the\ndecomposition levels K were set at 1, 2, 3, 4 and 5. Each level expands the number\nof dataset by a factor J = 2(2×(K−1)) of 1, 4, 16, 64, and 256, respectively, reduces the\ndetector size and the image size according to N K\ndct = Ndct/2K−1 and N K\nx,y = Nx,y/2K−1.\nDownsampling (DS) ratios used to synthesize the sparse-view measurement were [2, 3,\n4, 6, 8, 12], and each sparse-view corresponding to the DS ratio was [384, 256, 192,\n128, 96, 64] views. In particular, to match the size of the measurements input to the\nDL without unintentional interference affecting performance, Algorithm 2 is applied to\nthe downsampled measurement to interpolate them to the full-view size. The symbolic\ndetails are described in Table 1(f). When sparse-view data is generated for training\nthe projection-domain DL, a DS factor S is randomly selected from among the DS\nratios, and the synthetic undersampled measurements, applied to given DS factor S,\nare generated using Algorithm 2.\n5.2. Architectures\nTo evaluate the DL performance across data domains, including image-domain and\nprojection-domain, two types of DL frameworks are used, as shown in Figure 2: (a) II-\nNet consisting of two-times unrolled I-Net QK\nimg, and (b) PI-Net sequentially composed of\nP-Net QK\nprj and I-Net QK\nimg. Figure 5 shows a backbone architecture and layer modules\nused. P-Net QK\nprj and I-Net QK\nimg use the same backbone architecture, as shown in\nFigure 5(a). A basic layer block consists of a 3 × 3 convolutional layer (3 × 3 Conv),\ninstance normalization (INorm), and a leaky rectified linear unit (LReLU) as illustrated\nby the yellow arrow in Figure 5(b). The basic layer block is present between all blocks\nin Figure 5(a), but the yellow arrow has been omitted for visibility.\nThe backbone\nnetwork has 7,764,049 trainable parameters, and both II-Net and PI-Net are composed\nof two backbone networks, resulting in a total of 15,528,098 (=7,764,049 + 7,764,049)\nparameters.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n12\n(a) LK\nII−Net\narg min(QK\nimg1,QK\nimg2)\nPI\ni=1\nPJ\nj=1 ∥f i,j\nK −(f i,j\nK,S −QK\nimg1(f i,j\nK,S))∥2\n|\n{z\n}\n( i ) 1st phase network\n+ PI\ni=1\nPJ\nj=1 ∥f i,j\nK −( ¯f i,j\nK,img1 −QK\nimg2( ¯f i,j\nK,img1))∥2\n|\n{z\n}\n( ii ) 2nd phase network\n,\nwhere ¯f i,j\nK,img1 = f i,j\nK,S −QK\nimg1(f i,j\nK,S),\nf i,j\nK,S = DK\nimg(f i\nS)[j] and fK,S = RT\nK(qK,S).\n(b) LK\nPI−Net\narg min(QK\nprj1,QK\nimg2)\nPI\ni=1\nPJ\nj=1 ∥f i,j\nK −RT\nK(MS ⊙qi,j\nK,S + (1 −MS) ⊙QK\nprj1(qi,j\nK,S))∥2\n|\n{z\n}\n( i ) 1st phase network\n+ PI\ni=1\nPJ\nj=1 ∥f i,j\nK −( ¯f i,j\nK,prj −QK\nimg2( ¯f i,j\nK,prj))∥2\n|\n{z\n}\n( ii ) 2nd phase network\n,\nwhere ¯f i,j\nK,prj1 = RT\nK(MS ⊙qi,j\nK,S + (1 −MS) ⊙QK\nprj1(qi,j\nK,S)) and qi,j\nK,S = DK\nprj(qi\nS)[j].\n(c) LTV\narg minf\n1\n2∥pS −R(f)∥2\n2 + λTV (f),\nwhere λ denotes an weight parameter, which balances the fidelity term and the TV regularization term.\n(d) Symbols\n⊙\nHadamard product\nK\nDecomposition level (K is omitted for visibility when K=1.)\nI\nNumber of datasets\nJ\nNumber of decomposed data (J = 2(2×(K−1)))\np\nFull-view projection data\nMS\nSparse-view projection mask\npS\nSparse-view projection data\nqK,S\nSparse-view filtered projection data decomposed into K level\nfK\nFull-view CT image decomposed into level K\nfK,S\nSparse-view CT image decomposed into level K\n¯fK,prj\nReconstructed CT image from projection-domain DL QK\nprj\n¯fK,img\nReconstructed CT image from image-domain DL QK\nimg\nR\nProjection operation\nRT\nK\nBackprojection operation for K level decomposition\nTV\nTotal variation operation\nF\nFiltration operation\nQK\nprj\nProjection-domain DL for K level decomposition\nQK\nimg\nImage-domain DL for K level decomposition\nDK\nprj\nProjection-domain decomposition into level K\nDK\nimg\nImage-domain decomposition into level K\nTable 1.\nObjective functions for (a) II-Net, (b) PI-Net and (c) MBIR with TV\nregularization methods. (d) Various symbols used.\n5.3. Training\n5.3.1.\nEnvironments The DL architectures were implemented using Pytorch.\nTo\ncalculate the loss of the PI-Net as shown in Table 1(b), the backprojection operation\nRT was implemented as a user-defined layer in Pytorch. Additionally, the backward\npropagation of the backprojection operation RT could be conducted in a sequential\nmanner using the projection operation R. A graphic processing unit (GPU), such as\nNVIDIA A6000, was used to train the networks. The hyper parameters employed for\ntraining the DLs are detailed as follows: An Adam optimizer was utilized, and the initial\nlearning rate was set to 10−4. If the validation loss did not show a decrease over five\nconsecutive epochs, the learning rate was multiplied by 0.1. Pairs of (the number of\nepoch, batch size) were defined as [(100, 4), (50, 16), (50, 32), (50, 64), (50, 256)], in\naccordance with the decomposition levels K = [1, 2, 3, 4, 5], respectively. In particular,\nthe DL model trained with decomposition level K = 1 was used as a pre-trained model\nfor other decomposition levels K = [2, 3, 4, 5]. In the perspective of the shift-invariant\ncharacteristic of convolution layer, the bias issue caused by using the pre-trained model\nwith decomposition level k = 1 will be minor and it would be a stable initial point. Three\nquantitative metrics were used: the normalized root mean square error (NRMSE), the\npeak signal to noise ratio (PSNR), and the structural similarity index measure (SSIM).\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n13\nFigure 6. Various directional results from (a) 192 views (DS factor S = 4) and (b) 96\nviews (DS factor S = 8). (i) Ground truth and reconstructed images from (ii) FBP,\n(iii) cubic interpolation, (iv) MBIR with TV regularization, (v) I-Net, which is 1st\nphase network of II-Net, (vi) II-Net, (vii) PI-Net, and (viii) Proposed method. (v-vii)\nconventional DL approaches were trained at decomposition level K = 1, while (viii)\nour method were trained at decomposition level K = 5. The intensity range was set\nto (-160, 240) [HU]. NRMSE/SSIM values are written in the corners.\n5.3.2. Objective functions\nTable 1 shows the various objective functions used to train\nvarious DLs and MBIR method. The objective function of the II-Net, defined in Table\n1(a), has two terms to train (i) the 1st I-Net QK\nimg1 and (ii) the 2nd I-Net QK\nimg2,\nsimultaneously. Similarly, the PI-Net is trained by the objective function, consisting\nof two terms for (i) the 1st P-Net QK\nprj1 and (ii) the 2nd I-Net QK\nimg2, defined in Table\n1(b). Specifically, in order to maintain and preserve the original measured information,\nthe I-Net QK\nimg is trained with the concept of residual learning by modifying a label\nimage fK into a residual image (fK −fK,S), and a data-consistency term is applied to\nthe P-Net QK\nprj by replacing the reconstructed measurement QK\nprj(qK,S) with the original\nmeasurement qK,S at measured view position. In addition, MBIR algorithm with TV\nregularization is used for the comparative conventional method, and the cost function\nis formulated in Table 1(c).\n6. Results and Discussion\nFigure 6 shows the reconstructed images from various algorithms, including the analytic\nmethod (see Figure 6(iii)), the iterative method (see Figure 6(iv)), and DL-based\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n14\n(a) PSNR ↑\n(i) FBP\n(ii) Interp.\n(iii) MBIR\n(iv) I-Net\n(v) II-Net\n(vi) PI-Net\n(vii) Ours\n[ dB ]\n( w\\ Cubic )\n( w\\ TV )\n( Level 1 )\n( Level 1 )\n( Level 1 )\n( Level 5 )\n384 views (DS = 2)\n43.8766\n46.8335\n45.3438\n47.3523\n47.1874\n45.9614\n47.5429\n256 views (DS = 3)\n37.5167\n41.7555\n39.9657\n44.5542\n44.5752\n44.0486\n45.2628\n192 views (DS = 4)\n33.9806\n38.5720\n37.4422\n43.1441\n43.1799\n43.0262\n44.0869\n128 views (DS = 6)\n29.9290\n34.5357\n34.0616\n41.2948\n41.3474\n41.4208\n42.3326\n96 views (DS = 8)\n27.5043\n32.0524\n32.0263\n39.9220\n39.9795\n40.1207\n40.9531\n(b) SSIM ↑\n(i) FBP\n(ii) Interp.\n(iii) MBIR\n(iv) I-Net\n(v) II-Net\n(vi) PI-Net\n(vii) Ours\n( w\\ Cubic )\n( w\\ TV )\n( Level 1 )\n( Level 1 )\n( Level 1 )\n( Level 5 )\n384 views (DS = 2)\n0.9866\n0.9957\n0.9925\n0.9959\n0.9955\n0.9947\n0.9956\n256 views (DS = 3)\n0.9442\n0.9880\n0.9764\n0.9925\n0.9924\n0.9922\n0.9928\n192 views (DS = 4)\n0.8884\n0.9775\n0.9605\n0.9899\n0.9900\n0.9904\n0.9909\n128 views (DS = 6)\n0.7873\n0.9501\n0.9295\n0.9855\n0.9857\n0.9868\n0.9873\n96 views (DS = 8)\n0.7113\n0.9196\n0.9005\n0.9815\n0.9818\n0.9831\n0.9837\nTable 2. Quantitative comparison with respect to various numbers of views. Best\nand second-highest scores are in bold and underline, respectively.\nmethods (see Figures 6(v-viii)).\nThe interpolation method in Figure 6(iii) does not\nclearly remove streaking artifacts, while MBIR with a TV penalty in Figure 6(iv) is\noverestimated and fails to preserve textures due to strong TV regularization. In contrast\nto analytic and iterative methods, the DL-based methods, including conventional DL\napproaches in Figures 6(v-vii) and our method in Figure 6(viii), show superior image\nquality and quantitative metrics.\nWhen comparing our method with conventional\nDL approaches, the images reconstructed from I-Net and II-Net in Figures 6(v-vi)\nexhibit smooth textures, but the global streaking patterns persist. In Figure 6(vii), the\ntraditional PI-Net using decomposition level K = 1 clearly removes the global streaking\nartifacts, but the image noise increases when the DS factor S is high, as shown in Figure\n6(b)(vii). The proposed PI-Net using decomposition level K = 5 preserves not only the\nsmall structures but also the textures and achieves the lowest NRMSE and the best SSIM\nvalues, as illustrated in Figure 6(viii). In particular, unlike the traditional PI-Net, our\nmethod shows stable reconstruction performance even in high DS factor environment,\nas shown in Figure 6(b)(viii). The average quantitative metrics, including PSNR and\nSSIM values with respect to various numbers of views, are presented in Table 2. Among\nvarious algorithms, DL-based methods outperform analytic and iterative methods, and\nour DL method exhibits better quantitative metrics than other DL-based methods.\n6.1. Impact of Hierarchical Decomposition Level\nIn Section 3, two theories regarding network performance were addressed, including\nthe DCF theroy [32] and hierarchical measurement decomposition [37].\nThe DCF\ntheory [32] reveals that the working process of the neural network involves solving the\nregression problem with a low-rank property, and the rank is closely related to the non-\nzero components of the signal in the Fourier domain. To emphasize the low rankness\nof the signal, the study found a strong mathematical reason for the bowtie support\nof the measurement in the Fourier domain and utilized the hierarchical measurement\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n15\nFigure 7. Reconstructed images from (a) II-Net and (b) PI-Net methods for (i-v)\nvarious decomposition levels K from 1 to 5 when 128 views (DS factor S = 6). (vi)\nis the PSNR profiles for various decomposition levels and views. The intensity range\nwas set to (-160, 240) [HU]. NRMSE/SSIM values are written in the corners.\n(a) NRMSE↓\n(i) II-Net\n(ii) PI-Net\n( 10−2 )\nLevel 1\nLevel 2\nLevel 3\nLevel 4\nLevel 5\nLevel 1\nLevel 2\nLevel 3\nLevel 4\nLevel 5\n384 views (DS = 2)\n1.5135\n1.5791\n1.7569\n1.8911\n2.0512\n1.7470\n1.8581\n1.7725\n1.5184\n1.4516\n256 views (DS = 3)\n2.0451\n2.0597\n2.2230\n2.2754\n2.4167\n2.1792\n2.3473\n2.2818\n1.9257\n1.8877\n192 views (DS = 4)\n2.4022\n2.4075\n2.6203\n2.6635\n2.8140\n2.4515\n2.6461\n2.5770\n2.1856\n2.1624\n128 views (DS = 6)\n2.9702\n2.9710\n3.2922\n3.3614\n3.5837\n2.9480\n3.1557\n3.0961\n2.6611\n2.6504\n96 views (DS = 8)\n3.4822\n3.4927\n3.9075\n4.0385\n4.4029\n3.4250\n3.6107\n3.5396\n3.1137\n3.1117\n(b) SSIM↑\n(i) II-Net\n(ii) PI-Net\nLevel 1\nLevel 2\nLevel 3\nLevel 4\nLevel 5\nLevel 1\nLevel 2\nLevel 3\nLevel 4\nLevel 5\n384 views (DS = 2)\n0.9955\n0.9952\n0.9942\n0.9936\n0.9930\n0.9947\n0.9938\n0.9945\n0.9952\n0.9956\n256 views (DS = 3)\n0.9924\n0.9923\n0.9911\n0.9909\n0.9902\n0.9922\n0.9903\n0.9915\n0.9925\n0.9928\n192 views (DS = 4)\n0.9900\n0.9898\n0.9881\n0.9881\n0.9868\n0.9904\n0.9880\n0.9893\n0.9907\n0.9909\n128 views (DS = 6)\n0.9857\n0.9857\n0.9823\n0.9821\n0.9794\n0.9868\n0.9838\n0.9853\n0.9871\n0.9873\n96 views (DS = 8)\n0.9818\n0.9817\n0.9768\n0.9755\n0.9700\n0.9831\n0.9801\n0.9819\n0.9837\n0.9837\nTable 3. Quantitative comparison with respect to various decomposition levels. Best\nand second-highest scores are in bold and underline, respectively.\ndecomposition [37] to reduce the area of the bowtie support.\nTo validate the relationship between the DCF theory [32] and hierarchical\nmeasurement decomposition [37], II-Net and PI-Net were trained with datasets at\nvarious decomposition levels K, as shown in Figure 4, and the reconstructed images\nalong with the quantitative metrics are presented in Figure 7 and Table 3. In particular,\nthe PSNR profiles with respect to the decomposition levels and the number of views are\ndepicted in Figure 7(vi). Interestingly, the II-Net shows a performance degradation as\nthe decomposition level increases, as illustrated in Figure 7(a)(vi). The reason is that\ntraining the image-domain DL with entire CT images (decomposition level K = 1) is\nmore advantageous than training it using image-patches (decomposition level K > 1)\nbecause streaking artifacts in the image-domain are defined as global artifacts rather\nthan local artifacts. Therefore, Figure 7(a) shows that it is difficult for II-Net trained\nwith highly decomposed image-patches to clearly remove global streaking artifacts.\nAn additional challenge in removing streaking artifacts is that the DL-based model\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n16\nFigure 8. (i) Ground truth, (ii) FBP, and reconstructed images from (iii, iv) I-Net\nand (v-vii) P-Net when (a) 192 views (DS factor S = 4) and (b) 128 views (DS factor\nS = 6). (iii, iv) are the first phase networks for II-Net with the regular decomposition\nlevel K = 1 and K = 5, respectively. (v, vii) are the first phase networks for PI-Net\nwith the hierarchical decomposition level K = 1 and K = 5, respectively. (vi) is the\nP-Net trained with regular decomposition method [24]. The intensity range was set to\n(-160, 240) [HU]. NRMSE/SSIM values are written in the corners.\nPSNR ↑\n(a) I-Net\n(b) P-Net\n[ dB ]\n(i) Level 1 : D1\nimg\n(ii) Level 5 : D5\nimg\n(i) Level 1 : D1\nprj\n(ii) Level 5 : D5\nimg\n(iii) Level 5 : D5\nprj\n384 views (DS = 2)\n47.3523\n45.1148\n47.0428\n47.6792\n48.0191\n256 views (DS = 3)\n44.5542\n43.1895\n44.1547\n44.6508\n45.3545\n192 views (DS = 4)\n43.1441\n41.6619\n42.8281\n43.2711\n44.0121\n128 views (DS = 6)\n41.2948\n39.4838\n40.8534\n41.1559\n42.1353\n96 views (DS = 8)\n39.9220\n37.7030\n39.4429\n39.6720\n40.7308\nTable 4. Quantitative comparison with respect to (i) I-Net and (ii) P-Net for various\nnumbers of views and decomposition methods. Best score is in bold.\nis simultaneously trained on synthesized CT images with different DS ratios to ensure\nthe generalization effect. However, performance degradation may occur if the extended\ndata distribution does not achieve low-rank properties. At a high decomposition level\nK, the image-domain DL is not well-trained due to various types of fragmented global\nstreaking artifacts. The quantitative metrics are shown in Table 3(i).\nOn\nthe\nother\nhand,\nPI-Net\nshows\nthe\nperformance\nimprovement\nas\nthe\ndecomposition level K increases, as shown in Figure 7(b)(vi), except for K = 1. Table\n3(ii) shows that PI-Net trained with full-size measurements (decomposition level K = 1)\noutperforms the other PI-Nets trained with measurements decomposed by the levels\nK = 2 and K = 3. However, the performance gradually improves as the decomposition\nlevel K increases from the level 2 to the level 5, as shown in Figure 7(b)(vi). PI-Net\ntrained with decomposition levels K = 5 is superior to the conventional PI-Net trained\nwith decomposition level K = 1.\nFigure 7(b)(i-v) show reconstructed images from\nPI-Nets trained with different decomposition levels, with higher decomposition levels\nimproving quantitative metrics, as described in Table 3(ii). Therefore, through this\nexperiment, it was confirmed that mathematical intuition related to DCF theroy [32]\nand hierarchical measurement decomposition [37] was clearly and empirically verified.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n17\nFigure 9. Measurement sampling patterns according to (i) parallel beam CT and (ii)\nfan beam CT. (a) and (b) are full-view and sparse-view measurements, respectively.\nR/G/B samples in (i) parallel beam CT are interpolated by adjacent samples indicated\nby R/G/B arrows in (ii) fan beam CT.\n6.2. Performance of Data Domain\nSection 6.1 explained why II-Net with decomposition level K = 1 and PI-Net with\ndecomposition level K = 5 achieve the best performance among various decomposition\nlevels. However, since both networks consist of two-times unrolled networks, it is difficult\nto determine performance differences depending on whether the data domain of the\nnetwork is the image-domain or the projection-domain. To verify the effectiveness of\nthe data domain, I-Net (the 1st phase network of II-Net) and P-Net (the 1st phase\nnetwork of PI-Net) are compared. The reconstructed images from the I-Net and the\nP-Net are shown in Figure 8, and the quantitative metrics are summarized in Table 4.\nCompared to the results of I-Nets, I-Net with level K = 1 in Figure 8(iii)\nshows better removal performance of global streaking artifacts than I-Net with regular\ndecomposition level K = 5 in Figure 8(iv). However, P-Nets show opposite results to\nI-Nets. P-Net with hierarchical decomposition level K = 5 in Figure 8(vii) outperforms\nP-Net with level K = 1 in Figure 8(v) due to the narrow bowtie support in the Fourier\ndomain.\nAdditionally, to verify the image quality according to the decomposition\nmethod, a new P-Net was trained with level K = 5 of regular projection patches,\nas shown in Figure 8(vi). The interesting point is that P-Net at level K = 5 of regular\ndecomposition (see Figure 8(vi)) shows similar results to P-Net at level K = 1 (see\nFigure 8(v)).\nThrough this, it can be inferred that the two networks have similar\nbasis satisfying the low-rank properties. Considering the shift-invariant characteristic\nof convolution layers, the inference is reasonable.\n6.3. Performance of Fan beam CT Geometry\nAs shown in Figure 4 and Algorithm 1, the hierarchical decomposition method is defined\nin the parallel beam CT geometry, whereas conventional CT geometries follow equi-\nangular or equi-spaced CT geometries, including fan beam and cone beam CT systems.\nA simple way to apply the decomposition method to fan beam geometry is to transform\nthe parallel beam projection from the fan beam CT measurements using the fan-to-\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n18\nFigure 10. (i) Ground truth and (ii) FBP from fan beam CT geometry. (iii) and\n(iv) shows the results reconstructed from II-Net and proposed method from rebinned\nmeasurement when 256 views (DS factor S = 3). (v) is the PSNR profiles for various\nnumber of views.\nThe intensity range was set to (-160, 240) [HU]. NRMSE/SSIM\nvalues are written in the corners.\nFigure 11. (i) Ground truth and (ii) FBP, and reconstructed images from (iii) IP-\nNet, (iv) PI-Net, and (v) proposed method with 128 views (DS factor S = 6). (vi) is\nthe PSNR profiles for various number of views. The intensity range was set to (-160,\n240)[HU]. NRMSE/SSIM values are written in the corners.\nparallel beam rebinning operation.\nFigure 9 shows measurement sampling patterns\naccording to (i) parallel beam and (ii) fan beam CTs. Specifically, the larger the number\nof views, the smaller the interpolation error in Figure 9(a). In other words, as shown in\nFigure 9(b), the smaller the number of views, the greater the interpolation error. The\nresults of the fan beam CT is shown in Figure 10. The performance of our projection-\ndomain DL is slightly degraded because the measurements were directly contaminated\nby interpolation errors caused by the rebinning process.\nHowever, the performance\ndegradation can be easily compensated by using parallel beam measurements and\nrebinned measurements together during the training phase.\n6.4. Relationship between Basis Sets and Unrolled Networks\nSimilar to PI-Net, IP-Net, which I-Net and P-Net are sequentially connected, can be\nanother candidate to address different data domains.\nUnfortunately, IP-Net cannot\napply hierarchical decomposition method because decomposed projection data cannot\nbe generated by applying projection operators (or Radon transforms) to image patches.\nTherefore, IP-Net is only trained only on datasets without decomposition. Figure 11\nshows the the reconstructed results from IP-Net with level K = 1 and PI-Net with level\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n19\nFigure 12.\n(a) NRMSE and (b) SSIM profiles for various number of views.\n(c)\nIdentifiers used in (a) and (b).\nK = 1 and K = 5. As the PSNR profiles in Figure 11(vi) shows, the PSNR trend of IP-\nNet with level K = 1 is similar to that of PI-Net with level K = 1. The experiments show\nempirically that both networks have similar basis sets for reconstructing CT images.\nIn this paper, two-times unrolled networks such as II-Net and PI-Net are usually\nused when performing experiments.\nFigure 12 shows the NRMSE and SSIM values\nfor sequentially connected networks.\nComparing I-Net and II-Net, as shown in the\ngreen profiles in Figure 12, there is not much difference. However, there is a reasonable\nperformance gap between P-Net and PI-Net as the number of views decreases. From\nthe perspective of the network’s basis based on DCF theory, I-Net and II-Net may have\nsimilar basis sets for solving regression problems using low-rank property due to the\nsame training datasets and the same network architecture (see Figure 2(a)). Therefore,\nthere is no meaningful performance improvement between two I-Nets. However, since\nP-Net and PI-Net are trained with different data domains (see Figure 2(b)), the basis\nsets for each network may be different. Therefore, the PI-Net can improve performance\nover the P-Net, a first phase network.\n7. Conclusion\nThe study proposed a novel hierarchical decomposed dual-domain DL for sparse-view\nCT reconstruction.\nConventional image-domain DL functions as an image artifact\nremover. However, this study reveals that there networks fail to address the underlying\ncause of artifacts, which is the presence of incomplete measurements.\nTherefore,\nthe study uses a hierarchical decomposed projection-domain DL as a missing data\nreconstructor to directly confront the problems arising from incomplete measurements.\nFor the reconstruction of undersampled projection data, the study proposed a novel\nprojection-domain DL, which is trained with hierarchical decomposed measurements.\nThe decomposed measurements exhibit a narrow bowtie support in the Fourier domain,\nthereby satisfying the low-rank property demonstrated by DCF theory. By achieving\nthis property, the proposed method was able to outperform various conventional\nmethods and various DLs.\nFurthermore, our findings revealed a direct correlation\nbetween the decomposition level and performance: the higher the decomposition level,\nthe better the performance.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n20\nAlthough the proposed method presents good theoretical justification and the\nexperimental results, it also has some drawbacks. First, there is overestimation issue\nin the case of dual-domain networks including the proposed method. In weak sparse-\nview CT situations, the first network outperforms the second network. However, the\nperformance of the second network is already sufficient for radiologists to make a\ndiagnosis. Another one is the CT geometry restriction of the hierarchical decomposition\nmethod.\nSince the decomposition method is designed for projections measured\nfrom parallel beam CT geometry, rebinning process is required to convert fan beam\nCT measurements to the form of parallel beam measurement.\nThe fan-to-parallel\nrebinning process is a simple operation with little computational cost, but can increase\ninterpolation error at high downsampling levels. The performance of our projection-\ndomain DL might be slightly degraded due to the contaminated measurement by\nrebinning process. However, the performance degradation can be easily compensated\nby using parallel beam measurements and rebinned measurements together during the\ntraining phase.\nAcknowledgements\nThis research was supported by the MSIT(Ministry of Science and ICT), Korea,\nunder the ITRC(Information Technology Research Center) support program(IITP-2024-\n2020-0-01602) supervised by the IITP(Institute for Information & Communications\nTechnology Planning & Evaluation).\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n21\nReferences\n[1] Nikhil Bharat Shah and Shari L Platt. Alara: is there a cause for alarm? reducing radiation risks\nfrom computed tomography scanning in children. Current opinion in pediatrics, 20(3):243–247,\n2008.\n[2] Johan Nuyts, Bruno De Man, Jeffrey A Fessler, Wojciech Zbijewski, and Freek J Beekman.\nModelling the physics in the iterative reconstruction for transmission computed tomography.\nPhysics in Medicine & Biology, 58(12):R63–R96, 2013.\n[3] Johannes Leuschner, Maximilian Schmidt, Daniel Otero Baguer, and Peter Maass. Lodopab-ct, a\nbenchmark dataset for low-dose computed tomography reconstruction. Scientific Data, 8(1):109,\n2021.\n[4] Wenjun Xia, Zexin Lu, Yongqiang Huang, Zuoqiang Shi, Yan Liu, Hu Chen, Yang Chen, Jiliu Zhou,\nand Yi Zhang. Magic: Manifold and graph integrative convolutional network for low-dose ct\nreconstruction. IEEE Transactions on Medical Imaging, 40(12):3459–3472, 2021.\n[5] Il Yong Chun, Xuehang Zheng, Yong Long, and Jeffrey A Fessler.\nBcd-net for low-dose ct\nreconstruction: Acceleration, convergence, and generalization.\nIn Medical Image Computing\nand Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen,\nChina, October 13–17, 2019, Proceedings, Part VI 22, pages 31–40. Springer, 2019.\n[6] Hongming Shan, Atul Padole, Fatemeh Homayounieh, Uwe Kruger, Ruhani Doda Khera, Chayanin\nNitiwarangkul, Mannudeep K Kalra, and Ge Wang. Competitive performance of a modularized\ndeep neural network compared to commercial algorithms for low-dose ct image reconstruction.\nNature Machine Intelligence, 1(6):269–276, 2019.\n[7] Xiangrui Yin, Qianlong Zhao, Jin Liu, Wei Yang, Jian Yang, Guotao Quan, Yang Chen, Huazhong\nShu, Limin Luo, and Jean-Louis Coatrieux. Domain progressive 3d residual convolution network\nto improve low-dose ct imaging. IEEE transactions on medical imaging, 38(12):2903–2913, 2019.\n[8] Yoseob Han, Dufan Wu, Kyungsang Kim, and Quanzheng Li. End-to-end deep learning for interior\ntomography with low-dose x-ray ct. Physics in Medicine & Biology, 67(11):115001, 2022.\n[9] Yoseob Han and Jong Chul Ye. One network to solve all rois: Deep learning ct for any roi using\ndifferentiated backprojection. Medical physics, 46(12):e855–e872, 2019.\n[10] Weiwen Wu, Dianlin Hu, Chuang Niu, Hengyong Yu, Varut Vardhanabhuti, and Ge Wang. Drone:\nDual-domain residual-based optimization network for sparse-view ct reconstruction.\nIEEE\nTransactions on Medical Imaging, 40(11):3002–3014, 2021.\n[11] Minjae Lee, Hyemi Kim, and Hee-Joung Kim. Sparse-view ct reconstruction based on multi-level\nwavelet convolution neural network. Physica Medica, 80:352–362, 2020.\n[12] Dianlin Hu, Jin Liu, Tianling Lv, Qianlong Zhao, Yikun Zhang, Guotao Quan, Juan Feng,\nYang Chen, and Limin Luo.\nHybrid-domain neural network processing for sparse-view ct\nreconstruction.\nIEEE Transactions on Radiation and Plasma Medical Sciences, 5(1):88–98,\n2020.\n[13] Yoseob Han and Jong Chul Ye. Framing u-net via deep convolutional framelets: Application to\nsparse-view ct. IEEE transactions on medical imaging, 37(6):1418–1429, 2018.\n[14] Shipeng Xie, Xinyu Zheng, Yang Chen, Lizhe Xie, Jin Liu, Yudong Zhang, Jingjie Yan, Hu Zhu,\nand Yining Hu. Artifact removal using improved googlenet for sparse-view ct reconstruction.\nScientific reports, 8(1):6700, 2018.\n[15] Kyungsang Kim, Jong Chul Ye, William Worstell, Jinsong Ouyang, Yothin Rakvongthai, Georges\nEl Fakhri, and Quanzheng Li. Sparse-view spectral ct reconstruction using spectral patch-based\nlow-rank penalty. IEEE transactions on medical imaging, 34(3):748–760, 2014.\n[16] Taewon Lee, Changwoo Lee, Jongduk Baek, and Seungryong Cho. Moving beam-blocker-based\nlow-dose cone-beam ct. IEEE Transactions on Nuclear Science, 63(5):2540–2549, 2016.\n[17] Junguo Bian, Jeffrey H Siewerdsen, Xiao Han, Emil Y Sidky, Jerry L Prince, Charles A Pelizzari,\nand Xiaochuan Pan.\nEvaluation of sparse-view reconstruction from flat-panel-detector cone-\nbeam ct. Physics in Medicine & Biology, 55(22):6575–6599, 2010.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n22\n[18] Xiaochuan Pan, Emil Y Sidky, and Michael Vannier. Why do commercial ct scanners still employ\ntraditional, filtered back-projection for image reconstruction? Inverse problems, 25(12):123009,\n2009.\n[19] David L Donoho. Compressed sensing. IEEE Transactions on information theory, 52(4):1289–\n1306, 2006.\n[20] Yang Lu, Jun Zhao, and Ge Wang. Few-view image reconstruction with dual dictionaries. Physics\nin Medicine & Biology, 57(1):173–189, 2011.\n[21] Sathish Ramani and Jeffrey A Fessler.\nA splitting-based iterative algorithm for accelerated\nstatistical x-ray ct reconstruction. IEEE transactions on medical imaging, 31(3):677–688, 2011.\n[22] Emil Y Sidky and Xiaochuan Pan.\nImage reconstruction in circular cone-beam computed\ntomography by constrained, total-variation minimization.\nPhysics in Medicine & Biology,\n53(17):4777–4807, 2008.\n[23] Hengyong Yu and Ge Wang. Compressed sensing based interior tomography. Physics in medicine\n& biology, 54(9):2791–2805, 2009.\n[24] Hoyeon Lee, Jongha Lee, Hyeongseok Kim, Byungchul Cho, and Seungryong Cho. Deep-neural-\nnetwork-based sinogram synthesis for sparse-view ct image reconstruction. IEEE Transactions\non Radiation and Plasma Medical Sciences, 3(2):109–119, 2018.\n[25] Hu Chen, Yi Zhang, Mannudeep K Kalra, Feng Lin, Yang Chen, Peixi Liao, Jiliu Zhou, and\nGe Wang. Low-dose ct with a residual encoder-decoder convolutional neural network. IEEE\ntransactions on medical imaging, 36(12):2524–2535, 2017.\n[26] Kyong Hwan Jin, Michael T McCann, Emmanuel Froustey, and Michael Unser. Deep convolutional\nneural network for inverse problems in imaging.\nIEEE Transactions on Image Processing,\n26(9):4509–4522, 2017.\n[27] Xu Dong, Swapnil Vekhande, and Guohua Cao.\nSinogram interpolation for sparse-view micro-\nct with deep learning neural network. In Medical Imaging 2019: Physics of Medical Imaging,\nvolume 10948, pages 692–698. SPIE, 2019.\n[28] Weiwen Wu, Xiaodong Guo, Yang Chen, Shaoyu Wang, and Jun Chen.\nDeep embedding-\nattention-refinement for sparse-view ct reconstruction. IEEE Transactions on Instrumentation\nand Measurement, 72:1–11, 2022.\n[29] Wei-An Lin, Haofu Liao, Cheng Peng, Xiaohang Sun, Jingdan Zhang, Jiebo Luo, Rama Chellappa,\nand Shaohua Kevin Zhou. Dudonet: Dual domain network for ct metal artifact reduction. In\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages\n10512–10521, 2019.\n[30] Ao Zheng, Hewei Gao, Li Zhang, and Yuxiang Xing.\nA dual-domain deep learning-based\nreconstruction method for fully 3d sparse data helical ct.\nPhysics in Medicine & Biology,\n65(24):245030, 2020.\n[31] Hong Wang, Yuexiang Li, Haimiao Zhang, Jiawei Chen, Kai Ma, Deyu Meng, and Yefeng Zheng.\nIndudonet: An interpretable dual domain network for ct metal artifact reduction. In Medical\nImage Computing and Computer Assisted Intervention–MICCAI 2021:\n24th International\nConference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part VI 24, pages\n107–118. Springer, 2021.\n[32] Jong Chul Ye, Yoseob Han, and Eunju Cha. Deep convolutional framelets: A general deep learning\nframework for inverse problems. SIAM Journal on Imaging Sciences, 11(2):991–1048, 2018.\n[33] Paul Rattey and Allen Lindgren.\nSampling the 2-d radon transform.\nIEEE Transactions on\nAcoustics, Speech, and Signal Processing, 29(5):994–1002, 1981.\n[34] Fengqin Zhang, Minghui Zhang, Binjie Qin, Yi Zhang, Zichen Xu, Dong Liang, and Qiegen Liu.\nRedaep: Robust and enhanced denoising autoencoding prior for sparse-view ct reconstruction.\nIEEE Transactions on Radiation and Plasma Medical Sciences, 5(1):108–119, 2020.\n[35] Franz Thaler, Kerstin Hammernik, Christian Payer, Martin Urschler, and Darko ˇStern. Sparse-\nview ct reconstruction using wasserstein gans. In International workshop on machine learning\nfor medical image reconstruction, pages 75–82. Springer, 2018.\nHierarchical Decomposed Dual-domain DL for Sparse-View CT Reconstruction\n23\n[36] Kyong Hwan Jin, Dongwook Lee, and Jong Chul Ye. A general framework for compressed sensing\nand parallel mri using annihilating filter based low-rank hankel matrix. IEEE Transactions on\nComputational Imaging, 2(4):480–495, 2016.\n[37] S. Basu and Y. Bresler. O(n/sup 2/log/sub 2/n) filtered backprojection reconstruction algorithm\nfor tomography. IEEE Transactions on Image Processing, 9(10):1760–1773, 2000.\n[38] C McCollough.\nTu-fg-207a-04: Overview of the low dose ct grand challenge.\nMedical physics,\n43(6Part35):3759–3760, 2016.\n",
  "categories": [
    "cs.LG",
    "eess.SP"
  ],
  "published": "2025-01-09",
  "updated": "2025-01-09"
}