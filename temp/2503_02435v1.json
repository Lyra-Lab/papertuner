{
  "id": "http://arxiv.org/abs/2503.02435v1",
  "title": "NLI4DB: A Systematic Review of Natural Language Interfaces for Databases",
  "authors": [
    "Mengyi Liu",
    "Jianqiu Xu"
  ],
  "abstract": "As the demand for querying databases in all areas of life continues to grow,\nresearchers have devoted significant attention to the natural language\ninterface for databases (NLIDB). This paper presents a comprehensive survey of\nrecently proposed NLIDBs. We begin with a brief introduction to natural\nlanguage processing techniques, executable database languages and the\nintermediate representation between natural language and executable language,\nand then provide an overview of the translation process from natural language\nto executable database language. The translation process is divided into three\nstages: (i) natural language preprocessing, (ii) natural language\nunderstanding, and (iii) natural language translation. Traditional and\ndata-driven methods are utilized in the preprocessing stage. Traditional\napproaches rely on predefined rules and grammars, and involve techniques such\nas regular expressions, dependency parsing and named entity recognition.\nData-driven approaches depend on large-scale data and machine learning models,\nusing techniques including word embedding and pattern linking. Natural language\nunderstanding methods are classified into three categories: (i) rule-based,\n(ii) machine learning-based, and (iii) hybrid. We then describe a general\nconstruction process for executable languages over relational and\nspatio-temporal databases. Subsequently, common benchmarks and evaluation\nmetrics for transforming natural language into executable language are\npresented, and methods for generating new benchmarks are explored. Finally, we\nsummarize the classification, development, and enhancement of NLIDB systems,\nand discuss deep language understanding and database interaction techniques\nrelated to NLIDB, including (i) using LLM for Text2SQL tasks, (ii) generating\nnatural language interpretations from SQL, and (iii) transforming speech\nqueries into SQL.",
  "text": "NLI4DB: A Systematic Review of Natural Language\nInterfaces for Databases\nMengyi Liu and Jianqiu Xu*\nNanjing University of Aeronautics and Astronautics, Nanjing, China\n{liumengyi,jianqiu}@nuaa.edu.cn\nAbstract\nAs the demand for querying databases in all areas of life continues to grow, researchers have devoted signifi-\ncant attention to the natural language interface for databases (NLIDB). This paper presents a comprehensive sur-\nvey of recently proposed NLIDBs. We begin with a brief introduction to natural language processing techniques,\nexecutable database languages and the intermediate representation between natural language and executable lan-\nguage, and then provide an overview of the translation process from natural language to executable database\nlanguage. The translation process is divided into three stages: (i) natural language preprocessing, (ii) natural\nlanguage understanding, and (iii) natural language translation. Traditional and data-driven methods are utilized\nin the preprocessing stage. Traditional approaches rely on predefined rules and grammars, and involve techniques\nsuch as regular expressions, dependency parsing and named entity recognition. Data-driven approaches depend\non large-scale data and machine learning models, using techniques including word embedding and pattern link-\ning. Natural language understanding methods are classified into three categories: (i) rule-based, (ii) machine\nlearning-based, and (iii) hybrid. We then describe a general construction process for executable languages over\nrelational and spatio-temporal databases. Subsequently, common benchmarks and evaluation metrics for trans-\nforming natural language into executable language are presented, and methods for generating new benchmarks\nare explored. Finally, we summarize the classification, development, and enhancement of NLIDB systems, and\ndiscuss deep language understanding and database interaction techniques related to NLIDB, including (i) us-\ning LLM for Text2SQL tasks, (ii) generating natural language interpretations from SQL, and (iii) transforming\nspeech queries into SQL.\nKeywords: Natural language interface for database, Semantic parsing, Structured language, Query processing\n1\nIntroduction\nIn today’s data-driven world, databases are the backbone of a number of applications, from social media plat-\nforms to financial systems. However, accessing and querying these vast repositories of information often requires\nspecialized knowledge of query languages such as SQL, which can be a significant barrier for non-expert users,\nlimiting their ability to harness the full potential of the data at their fingertips. The advent of natural language\ninterface (NLI) has the potential to eliminate the interaction barrier between users and terminals [130]. The\nintegration of natural language processing (NLP) and database technology represents an intriguing avenue for\nfuture research. There are systems that facilitate the transformation of natural language into structured language\n[141, 22], provide the natural language description for query execution plans [139, 23], and transform SQL into\nnatural language [40, 132].\nImagine a world where anyone, regardless of technical proficiency, can effortlessly interact with complex\ndatabases using everyday language. This vision is becoming a reality through the development of natural language\n*Corresponding author.\n1\narXiv:2503.02435v1  [cs.DB]  4 Mar 2025\nWho is the director of\n\"Inglourious Basterds\"?\nNatural Language Query\nSELECT  DISTINCT p.*\nFROM  movie m, person p, directing d\nWHERE m.id = d.movieId AND person.id = d.directorId \nAND m.title = \"Inglourious Basterds\"\nTranslated Executable Language\nNLIDB\nManual\nProcessing\nFigure 1: Example of translating a natural language into an executable language\nNatural language preprocessing\nNatural language understanding\nNatural language translation\nNatural Language Query\nExecutable Database Language\nNLIDB\n Methods\nTechniques involved\nExamples of NLIDBs\ntraditional\nnamed entity recognition,\ndictionary generation, regular\nexpression, dependency parsing\nPRECISE, Querix, QuestIO,\ngAnswer, MEANS, NL2CM, \nATHENA, SQLizer, NALMO\ndata-driven\nword embedding, pattern linking\nIRNet, xDBTagger \nMethods\nTechniques involved\nExamples of NLIDBs\nrule-based\nsemantic accessibility,\nintermediate query language\nPRECISE, NaLIX, DaNaLIX, NaLIR, NL2CM,\nATHENA, NALMO, ezNL2SQL\nmachine learning-based\nstatistical machine translation, \nencoder-decoder frameworks\nSeq2SQL, DialSQL, SyntaxSQLNet, DBTagger,\nIRNet, SpatialNLI, ValueNet, SV2-SQL\nhybrid \nintermediate query language,\nencoder-decoder frameworks\nTypeSQL, NALMO, Veezoo, GAR, CatSQL, \nGENSQL, NALSpatial, xDBTagger\ndatabase elements + SELECT,\nFROM, WHERE parts\njoin condition + WHERE clause\nparticipating relations + FROM clause\nquery type\noperators\nthe executable language\nrelational database\nspatio-temporal\ndatabase\nkey semantic information\nsegmentation, \npart-of-speech tagging\nFigure 2: A summary of translation techniques\ninterface for databases (NLIDB), which aims to transform a natural language query (NLQ) into an executable\nlanguage, as illustrated in Figure 1. Users tend to favor an interactive interface that allows them to confirm the\naccuracy and precision of the generated structured language [95]. The NLIDB enables users to avoid the necessity\nof possessing expertise in structured query languages and database schema, thereby significantly streamlining the\nefforts of users and enhancing the benefits of utilizing databases [70]. The initial NLIDBs, including BASEBALL,\nLUNAR, LADDER, Chat-80, and ASK, were released in rapid succession [2]. Subsequently, NLIDBs have\nemerged and are primarily utilized in relational databases (e.g., GENSQL [44] and CatSQL [48]), spatial domains\n(e.g., SpatialNLI [80, 141] and NALSpatial [89]), RDF question and answer (e.g., Querix [69] and TEQUILA\n[64]), and XML databases (e.g., NaLIX [84, 85] and DaNaLIX [81]).\nDespite years of research, the landscape of NLIDB is fraught with challenges [9, 82]. The inherent ambiguity\nand variability of natural language make NLIDB difficult to ensure accurate query interpretation. Additionally,\nunderstanding the structure and semantics of different databases adds another layer of complexity. Furthermore,\nachieving real-time performance while maintaining high accuracy in query translation remains an ongoing chal-\nlenge. While large language models (LLMs) offer new avenues for querying databases using natural language,\nthe training and reasoning of such models necessitate a substantial amount of computational resources, which\nmay prove challenging to implement in resource-limited scenarios [97]. Moreover, the decision-making process\nof LLMs is frequently opaque and lacks interpretability, making it difficult to ascertain whether the generated\nquery results align with the user’s intent [126]. These obstacles underscore the need for continued research and\ndevelopment to refine NLIDB.\n2\nIn light of these observations, this systematic review explores the current state of NLIDB, examining the var-\nious approaches and technologies that have been proposed to connect natural language with database querying,\nnamed NLI4DB. The aim of this survey is to offer a comprehensive overview that serves as both a valuable ref-\nerence for researchers and a practical guide for practitioners aiming to implement effective NLIDB solutions.\nNLI4DB presents a thorough examination of the NLIDB subject, categorizing the work into subtopics and pro-\nviding in-depth analysis for each one. The translation process from natural language to executable language is\ndivided into three stages: (i) natural language preprocessing, (ii) natural language understanding, and (iii) nat-\nural language translation. The three-stage division provides physical independence by separating the physical\narrangement of data from the semantics of queries [113]. The techniques for the translation are shown in Figure\n2.\n(i) Natural language preprocessing generally involves the construction of dedicated data dictionaries for the\ndomain using stemming extraction and synonym techniques. Part-of-speech tagging and word segmentation are\nthen performed on the input natural language. Methods used in the preprocessing stage include traditional and\ndata-driven. Traditional approaches rely on predefined rules and grammars for domain-specific text processing,\nand involve techniques such as regular expressions, dependency parsing and named entity recognition (NER).\nData-driven approaches depend on large-scale data and machine learning models for complex or variable text\nprocessing, using techniques such as word embedding and pattern linking.\n(ii) Natural language understanding has rule-based, machine learning-based, and hybrid approaches. Rule-\nbased systems can only deal with knowledge bases of specific domains, whose semantic understanding processes\neither define the concept of semantic accessibility or translate the NLQ into an intermediate representation that\ncan describe the semantics and relationships in an accessible manner. Machine learning-based systems employ\na variety of techniques to parse text, including unsupervised approaches, question-and-answer supervised learn-\ning, statistical machine translation techniques, encoder-decoder frameworks with recurrent neural networks, and\ncombinations of deterministic algorithms and machine learning. Hybrid approaches combine rules and machine\nlearning techniques to maximize their benefits.\n(iii) Natural language translation uses distinctive algorithms to map processed key semantic information to\ncorresponding structured language components. To build the SQL, the database elements matched by the NLQ are\nplaced in the appropriate locations in the SELECT, FROM, and WHERE parts. In the event that a query involves\nmultiple relations, it is necessary to include the join condition and the names of the participating relations in the\nWHERE and FROM clause, respectively. In the process of building an executable language of a spatio-temporal\ndatabase, the query type of the input NLQ is initially identified. The operators required to build the executable\nlanguage are then determined according to the query type. Finally, the key semantic information obtained from\nthe natural language understanding stage is integrated to form an executable language.\nThe existing survey [2] related to NLIDB focuses on the comparative analysis of the entire natural language\ninterface system. Affolter et al. [2] divide NLIs into four groups: (i) keyword-based systems, (ii) pattern-based\nsystems, (iii) parsing-based systems, and (iv) grammar-based systems. For each group, they provide an overview\nof representative systems and describe the most illustrative one in detail. In addition, they systematically compare\n24 recently developed NLIDBs on the basis of the sample world designed in the paper. Each system is evaluated\nusing 10 example questions to show the advantages and disadvantages.\nCompared with Affolter et al. [2], we divide the system translation process into three steps and focus on\nthe comparative analysis of each step. We investigate the recently developed NLIDB systems and divide the\ntranslation process into three stages: (i) natural language preprocessing, (ii) natural language understanding,\nand (iii) natural language translation. We classify natural language preprocessing techniques into traditional\nand data-driven. Natural language understanding methods are then analyzed in three categories: (i) rule-based,\n(ii) machine learning-based, and (iii) hybrid. Next, we provide a comprehensive outline of the construction\nprocess of executable languages for relational and spatio-temporal databases. Finally, we present commonly used\nbenchmarks and evaluation metrics, and describe the classification, development, and enhancement of NLIDBs.\n3\nTable 1: Frequently used notations\nName\nAbbreviation\nNatural language interface for database\nNLIDB\nNatural language interface\nNLI\nNatural language query\nNLQ\nNatural language processing\nNLP\nNamed entity recognition\nNER\nLarge language model\nLLM\nFirst-order logic\nFOL\nAutomatic speech recognition\nASR\nsequence-to-sequence\nseq2seq\nThe rest of the paper is structured as follows. Section 2 furnishes the background concerning NLIDB, in-\ncluding natural language processing techniques, executable database languages and intermediate representation\nlanguages. Section 3 describes the generation of executable database languages in terms of three stages: (i) nat-\nural language preprocessing, (ii) natural language understanding and (iii) natural language translation. Section\n4 summarizes 11 popular benchmarks for transforming NLQ into SQL and 3 evaluation metrics, including re-\nsponse time, translatability, and translation precision, and explores the methods for generating new benchmarks.\nSection 5 analyzes the classification, development and enhancement of NLIDBs. Section 6 discuss deep language\nunderstanding and database interaction techniques related to NLIDB, including (i) using LLM for Text2SQL tasks,\n(ii) generating natural language interpretations from SQL, and (iii) transforming speech queries into SQL. Sec-\ntion 7 explores the open problems of NLIDB and concludes the survey. Table 1 summarizes the frequently used\nnotations.\n2\nBackground: NLP techniques and query languages\nWe introduce the background related to NLIDB, including natural language processing techniques, executable\ndatabase languages, and intermediate representation languages.\n2.1\nNatural language processing techniques\nNLP is an interdisciplinary discipline that integrates several fields such as linguistics, computer science, and math-\nematics, and aims to make computers capable of understanding, processing and generating natural language text\nor speech. Through segmentation, lexical annotation, and syntactic analysis, NLP provides structured processing\nof text to achieve semantic understanding and information extraction. The application areas of NLP cover machine\ntranslation, sentiment analysis, information retrieval, and dialogue systems, providing people with an intelligent\nand convenient way of language interaction.\nA Brief History. The earliest research on natural language processing is machine translation. In 1950, Alan\nTuring proposed the ultimate test for determining the arrival of truly “intelligent” machines, which is generally\nregarded as the inception of the idea of NLP [96]. From the 1950s to the 1970s, the rule-based method was\nused to process natural language, which was based on grammatical rules and formal logic. In the 1970s, the\nstatistic-based method gradually supplanted the rule-based method. At this juncture, NLP built on mathematical\nmodels and statistic made a substantial breakthrough and was applied to practical applications. From 2008 to the\npresent, researchers have introduced deep learning to NLP in response to the achievements in image recognition\nand speech recognition.\nThe NLP techniques commonly used in NLIDBs are as follows.\n(i) Part of speech tagging refers to assigning the correct part of speech to each word in the segmented text,\n4\n(a) Part of speech tagging\n(b) Lemmatization\n(c) Named entity recognition\nDT\nAll\ndet\nacl\nNNS\nmovies\nVBG\nstarring\nNNP\nBrad\ncompound\nNNP\nPitt\nIN\nfrom\ncase\nCD\n2000\nIN\nuntil\ncase\nCD\n2010\n.\n.\nobj\nobl\nobl\npunct\n(d) Dependency parsing\nFigure 3: Processing natural language using Stanford CoreNLP\ndetermining whether each word is a noun, verb, or adjective. In NLIDB, part of speech tagging facilitates the\nidentification of the grammatical roles of individual words in natural language queries, leading to an accurate\ncomprehension of users’ intent. Taking the natural language query “All movies starring Brad Pitt from 2000 until\n2010.” as an example, the result of part of speech tagging using Stanford CoreNLP is shown in Figure 3(a). In the\nfigure, DT = determiner; NNS = plural noun; VBG = the gerund or present participle of a verb; NNP = singular\nproper noun; IN = preposition or subordinating conjunction; CD = cardinal number.\n(ii) Lemmatization is the process of reducing the different forms of a word to the original form. In NLIDB,\nlemmatization is beneficial in unifying words of various tenses and morphs in natural language queries into base\nforms in order to match the content in the database. Taking the natural language query “All movies starring Brad\nPitt from 2000 until 2010.” as an example, the result of lemmatization using Stanford CoreNLP is shown in Figure\n3(b).\n(iii) Named entity recognition is the procedure of identifying entities with specific meanings in natural lan-\nguage text [114]. Generally, the recognized entities can be categorized into three primary groups (entity, temporal,\nand numeric) and seven subgroups (PERSON, ORGANIZATION, LOCATION, TIME, DATE, MONEY, and\nPERCENT). NER in NLIDB enables the identification of entities involved in a natural language query to locate\nthe topic and scope of the query. Taking the natural language query “All movies starring Brad Pitt from 2000 until\n2010.” as an example, the result of NER using Stanford CoreNLP is shown in Figure 3(c).\n(iv) Dependency parsing involves analyzing the dependencies between words in natural language sentences.\nA binary asymmetric relationship between words is called dependency, which is described as an arrow from the\nhead (the subject to be modified) to the dependent (the modifier). Dependency parsing in NLIDB facilitates the\nunderstanding of grammatical relationships between words in NLQs, so that the structure and meaning of the\nquery can be accurately understood. Taking the natural language query “All movies starring Brad Pitt from 2000\nuntil 2010.” as an example, the result of dependency parsing using Stanford CoreNLP is illustrated in Figure 3(d).\nIn the figure, punct = punctuation; obl = oblique nominal; obj = object; det = determiner; acl = clausal modifier of\nnoun; case = case marking.\nWith the vigorous development of NLP technology, a number of NLP tools are appearing [114]. These tools\ncan perform basic tasks, including dependency parsing, named entity recognition, lemmatization, and part of\n5\nspeech tagging, each of which has distinct advantages and disadvantages. The following is a list of the established\nopen source natural language processing tools.\n(i) NLTK is a natural language processing toolkit using Python as the programming language. NLTK has\ncomplete functions and realizes many of the functional components in natural language processing, such as named\nentity recognition, sentence structure analysis, part-of-speech tagging, and text classification [13]. Born for the\nacademic field, NLTK is suitable for study and research. The disadvantage is that NLTK has a slower processing\nspeed than other tools.\n(ii) spaCy, a commercial open source software, is an industrial-grade natural language processing software\nprogrammed in Python and Cython languages [45]. spaCy, which follows NLTK, includes pre-trained statistical\nmodels and word vectors. spaCy can break down text into semantic units like articles, words and punctuation, and\nsupport named entity recognition. spaCy is characterized by fast and accurate syntax analysis, and comprehensive\nfunctions ranging from simple part-of-speech tagging to advanced deep learning.\n(iii) Stanford CoreNLP is a tool set developed by Stanford University using the Java programming language.\nStanford CoreNLP supports a variety of natural languages and has rich interfaces for programming languages that\ncan be used without Java [91]. Stanford CoreNLP is an efficient tool created by high-level research institutions\nand is widely used in scientific research and experiments, but may incur additional costs in production systems.\nStanford CoreNLP may not be the best choice for industry.\n(iv) TextBlob is an extension to NLTK, which provides an easier way to use the functionality of NLTK [57].\nTextBlob supports sentiment analysis, tokenization, part-of-speech tagging, and text classification. One of the\nadvantages is that TextBlob can be used in production environments where performance requirements are not too\nhigh. TextBlob can be applied in a wide range of scenarios, especially for small projects.\n2.2\nExecutable database languages\nThe output of NLIDB is an executable database language, and we present executable languages over relational\ndata, RDF data, and spatial data.\n2.2.1\nQuery language for relational data\nThe standard executable query language for relational data is SQL. Such a language is a general-purpose, ex-\ntremely powerful relational database language whose functions are not limited to querying, but also include creat-\ning database schema, inserting and modifying data, and defining and controlling database security integrity [29].\nFollowing the establishment of SQL as an international standard language, numerous database manufacturers have\nreleased SQL-compatible software, including both database management systems and interfaces. Consequently,\nSQL serves as the universal data access language and standard interface for most databases, fostering a shared\nfoundation for interoperability among different database systems. SQL has become the mainstream language in\nthe database field which is of great significance.\nSQL provides the SELECT statement for querying data, which has flexible usage and rich functionality. The\nSELECT statement can perform simple single-table queries as well as complex join queries and nested queries,\nwhose general format is:\nSELECT [ALL|DISTINCT] <target column expression> [alias] [,<target column expression> [alias]]\nFROM <table name or view name> [,<table name or view name>] | (SELECT statement) [AS] <alias>\n[WHERE <conditional expression>]\n[GROUP BY <column name 1> [HAVING <conditional expression>]]\n[ORDER BY <column name 2> [ASC|DESC]];\nThe purpose of the SELECT statement is to find the tuples that satisfy the conditions specified in the FROM clause,\nwhich may be a basic table, view, or derived table ,according to the conditional expression in the WHERE clause.\n6\nThe attribute value in the tuple is then selected on the basis of the target column expression in the SELECT clause\nto form the result table. When a GROUP BY clause is present, the output is organized by the value of <column\nname 1>, where tuples sharing identical attribute column values are grouped together. Aggregation functions are\nusually applied to each group. When the GROUP BY clause is accompanied by a HAVING clause, the output\nwill only include groups that satisfy the specified conditions. If an ORDER BY clause is present, the result table\nis sorted in ascending or descending order according to the values of <column name 2>.\n2.2.2\nQuery language for RDF data\nThe complete designation of RDF is Resource Description Framework, which is a data model designed to represent\ninformation about resources on the Internet. The data model typically describes a fact composed of three parts\nknown as a triple, including (i) a subject, (ii) a predicate, and (iii) an object. An RDF graph contains multiple\ntriples. RDF documents are written in XML to offer a standardized method for describing information. RDF is\nintended for computer applications to read and understand, rather than for visual presentation to web users.\nSPARQL is a specialized query language and data retrieval protocol designed for RDF, which stands for\nSPARQL Protocol and RDF Query Language [24]. SPARQL is a query language over RDF graphs, where the\ndatabase is represented as a collection of “subject-predicate-object” triples. Although RDF data is inferential,\nSPARQL does not have an inference query function. SPARQL is tailored for managing data stored in RDF\nformat, enabling both retrieval and manipulation. SPARQL is composed of the following components.\n• The PREFIX clause is employed to declare a prefix with the objective of simplifying the use of URIs. The\ndeclaration of the prefix is optional.\n• The SELECT clause serves the purpose of specifying the variables returned by a query.\n• The WHERE clause is utilized to match data in RDF graphs. The clause contains one or more triple patterns\nthat are employed to indicate the conditions of a query.\n• The FILTER clause is designed to conditionally filter the results of a query. The clause can include boolean\nexpressions to limit the set of results matched by the WHERE clause.\nThe fundamental query types of SPARQL are as follows [101].\nSELECT query is the most frequently used type of query, whose function is to select variables and return a\nresult set. A table is typically generated as the outcome of a SELECT query, which includes the variables that\nmeet the query’s criteria along with their corresponding values.\nCONSTRUCT query is used to generate a new RDF graph by utilizing the query pattern. In contrast to\ntabular results, the CONSTRUCT query produces an RDF graph that is constructed from the matching data of the\nquery pattern.\nASK query is designed to ascertain the existence of RDF data that satisfies the query pattern. The ASK query\nprovides a response in the form of a boolean value (true or false) to indicate the presence or absence of a match.\nDESCRIBE query is employed to obtain the detailed description of resources. The description is determined\nby the query engine and typically consists of triples that are directly related to the resource.\nEach query type employs a WHERE clause to limit the scope of the query. Nevertheless, in the context of\nDESCRIBE queries, the inclusion of a WHERE clause is not mandatory. To illustrate, the subsequent query\nretrieves people from the data set who are above the age of 24:\nPREFIX info: <http://somewhere/peopleInfo#>\nSELECT ?resource\nWHERE\n{\n?resource info:age ?age .\nFILTER (?age >= 24)\n}\n7\nTable 2: Operators to query spatial data\nOperator\nSignature\nMeaning\ndistance\npoint | line | region × point | line | region →real\nCompute the distance between two spa-\ntial objects.\ndirection\npoint × point →real\nCompute the direction between two\npoints.\nsize\nline →real\nReturn the length of a line.\narea\nregion →real\nReturn the area of a region.\nintersects\nline | region × line | region →bool\nTRUE, if both arguments intersect.\nintersection\npoint | line | region × point | line | region →T, where\nT is point if point is one of the arguments, otherwise\nT is the argument having the smaller dimension\nIntersection of two spatial objects.\ndistancescan\nrtree × relation × object × int →stream\nCompute the integer k nearest neigh-\nbors for a query object.\nIn this query, the “?” symbol represents a variable, followed by the variable name. The middle of the “<>”\nsymbol is the URI that describes the resource address. The “info:age” in the above query is a URI shorthand\nand stands for “<http://somewhere/peopleInfo#age>”. The FILTER keyword is employed to impose limitations\non the outcomes that are retrieved. In addition, RDF is semi-structured data, and different entities in RDF may\nhave distinct properties. SPARQL is capable of querying information that exists in RDF. However, when querying\ninformation that does not exist, SPARQL does not show a failure and does not return any results. The OPTIONAL\nkeyword can then be used to signify that the query is optional, indicating that the query will return a result if the\nentity has the attribute, and a null value otherwise. The FILTER keyword can also be used in conjunction with the\nOPTIONAL keyword.\n2.2.3\nQuery language for spatial data\nThe increasing reliance on geographic information systems in many aspects of people’s production and life has\nled to a significant increase in the demand for spatial data query in all walks of life. The popularity of spatial\napplications has brought great attention to spatial databases [55]. In databases, fundamental data types utilized for\nthe representation and manipulation of spatial objects include point, line, and region. The common operators to\nquery spatial data are shown in Table 2.\nMature systems for storing and managing spatial data include Esri’s ArcGIS, PostGIS, Google Earth Engine,\nGRASS GIS, and SECONDO [56]. As an illustration, SECONDO is a freely available platform created for\nthe purpose of organizing and examining spatial and temporal data. The basic commands of SECONDO are as\nfollows.\nquery <value expression>. The command evaluates the given value expression and subsequently displays\nthe result to the user.\nlet <identifier> = <value expression>. The command initially evaluates the provided value expression in a\nmanner analogous to the preceding command. In contrast to the previous command, the results of the evaluation\nare not immediately displayed but rather stored in an object named identifier. If the object already exists in the\ndatabase, the command will result in an error.\ndelete <identifier>. The command removes the object named identifier from the current database, and is\ntypically utilized in conjunction with the second command.\nWhen an expert or system developer writes the executable query language for SECONDO, one needs to com-\nprehensively understand the intricate relationship between data flow and operators. The rel2stream operator trans-\nforms a relation into a stream of tuples, as shown in Figure 4. The stream2rel operator, in contrast, converts a\nstream of tuples into a relation. Among the fundamental operators of SECONDO, the filter operator is the most\n8\na stream of tuples\ncity (Name:String, GeoData:Region)\nName\nGeoData\nNanjing\nZhenjiang\nYangzhou\n(Nanjing,         ), (Zhenjiang,              ), (Yangzhou,         ), ...\nrel2stream\nstream2rel\na stream of tuples\nfilter\nName = \"Nanjing\"\n(Nanjing,        )\nFigure 4: Functions of the operators rel2stream, stream2rel and filter in SECONDO\nfrequently utilized. Similar to the SELECT keyword in SQL, the function of the filter operator is to extract in-\nformation from data that satisfies specific conditions. The SELECT keyword operates on a two-dimensional table\nstructure to query, filter, and project data by specifying columns and conditions. The filter operator works on a\nstream of tuples, followed by a filter condition. The tuples that match the condition are then collected and out-\nputted as a stream. For example, the following executable language will output all information about Nanjing in\nthe relation city in SECONDO.\nquery city rel2stream filter [.Name = “Nanjing”] stream2rel;\nDuring the execution of the query, the rel2stream operator first transforms the relation city into a stream of tuples,\nthen the filter operator extracts the tuple named “Nanjing” from the stream, and finally the stream2rel operator\nconverts the tuple into a relation from the stream.\n2.3\nIntermediate representation languages\nThe intermediate representation language in NLIDB is designed to accommodate the semantic discrepancies and\ndiversity between natural language and executable database language, thus improving the translation accuracy,\nflexibility and maintainability of the system [7]. The intermediate representation serves as a translator between\nnatural language and executable language, mapping complex natural language structures to a unified semantic\nrepresentation for the purpose of efficient subsequent query processing and execution. By decoupling NLQ from\nthe underlying database query language, the intermediate representation language makes the NLIDB system flex-\nible, portable, and adaptable to various database types and query requirements. The design of the intermediate\nrepresentation considers several factors, such as:\n(i) The intermediate representation should convey the query request that the user wishes to submit to the\ndatabase, rather than the full meaning of the user’s input.\n(ii) To facilitate subsequent translation into the executable language of the database, the intermediate repre-\nsentation should be unambiguous.\n(iii) To make re-development easier, the intermediate representation should be reusable.\nPopular intermediate representations are parse trees [78], first-order logic [121], OQL [113], query sketch\n[153], SemQL [53], and NatSQL [50].\nParse tree. The syntactic structure of a query in natural language is closely tied to the design of a parse tree.\nThe tree structure is typically applied to represent the hierarchical and structural relationships of the query. Each\nnode in a parse tree indicates a grammatical unit (e.g., phrase, word group, and vocabulary), while edges indicate\ngrammatical relations (e.g., modification and conjunction) between these grammatical units. The nodes and edges\non the parse tree can be labeled with semantic information to identify the semantic roles and constraints present\nin the query, providing important information for subsequent query processing.\nFirst-order logic. When transforming an NLQ into first-order logic (FOL), words and phrases in the natural\nlanguage are first mapped to predicates, constants, variables, and logical connectives in FOL to represent entities,\n9\nattributes, and relations in the query. Subsequently, on the basis of the syntactic structure of the NLQ, the syntax\ntree or syntax graph of the FOL representation is constructed to capture the semantic relations and logical struc-\ntures in the query. Finally, the topics, conditions, and operations in the query are identified and converted into\nlogical expressions in FOL to denote the constraints and operational requirements of the query.\nWhen converting the natural language query “Find the names and salaries of all employees older than 30.”\ninto a first-order logic representation, predicates and constants are defined as follows.\nEmployee(x): x is an employee\nName(x, n): the name of employee x is n\nAge(x, a): the age of employee x is a\nSalary(x, s): the salary of employee x is s\nThe query condition is expressed as ∀x(Employee(x) ∧Age(x, a) ∧a > 30). The query result is expressed\nas ∃n, s(Name(x, n) ∧Salary(x, s)). The complete first-order logic representation is obtained by combining\nthe condition and result of the query.\n∀x(Employee(x) ∧Age(x, a) ∧a > 30) ∧∃n, s(Name(x, n) ∧Salary(x, s))\nOQL is built on an ontology knowledge graph, where words and phrases in natural language queries are\nassociated with concepts, attributes and relations within the ontology knowledge graph. The semantic information\nof natural language queries is captured through semantic representations and query patterns to effectively interact\nwith the database. OQL grammars permit the expression of complex aggregation, union and nested queries. OQL\nqueries operate upon individual concepts, with each concept being assigned an alias as specified in the FROM\nclause of the query.\nQuery sketch is a form of SQL with natural language hints. Taking the NLQ “Find the number of papers in\nOOPSLA 2010.” as an example, the query sketch is as follows.\nSELECT count(?[papers]) FROM ??[papers] WHERE ? = “OOPSLA 2010”;\nIn the query sketch, the symbols “??” and “?” represent an unspecified table and an unspecified column, respec-\ntively. Hints for the corresponding gaps are indicated by words enclosed in square brackets. As an illustration, the\nfirst hint in the sketch suggests that the symbol “?” has a similar semantic meaning to the term papers.\nSemQL is designed as a tree structure that not only constrains the search space during synthesis, but also main-\ntains the same structural characteristics as SQL. In SemQL queries, the GROUP BY, HAVING, and FROM clauses\nin SQL are removed, and the conditions from the WHERE and HAVING clauses are consistently represented in\nthe Filter sub-tree. Furthermore, in the later inference phase, domain knowledge is utilized to deterministically\ninfer implementation details from SemQL queries. For instance, the columns included the GROUP BY clause of\nSQL are typically present in the SELECT clause.\nNatSQL retains the core functionality of SQL while streamlining the structure of SQL to align more closely\nwith the syntax of natural language. NatSQL keeps only the SELECT, WHERE, and FROM clauses, omitting\nthe JOIN ON, HAVING, and GROUP BY clauses. Additionally, NatSQL does not require nested sub-queries or\naggregation operators, and employs a single SELECT clause. In the case of the natural language query “Which\nfilm has more than 5 actors and less than 3 in the inventory?”, the SQL and NatSQL are as follows.\nSQL: SELECT T1.title FROM film AS T1 JOIN film actor AS T2 ON T1.film id = T2.film id GROUP BY\nT1.film id HAVING count(*) > 5 INTERSECT SELECT T1.title FROM film AS T1 JOIN inventory AS T2 ON\nT1.film id = T2.film id GROUP BY T1.film id HAVING count(*) < 3;\nNatSQL: SELECT film.title WHERE count(film actor.*) > 5 and count(inventory.*) < 3;\n10\nTable 3: Natural language preprocessing for NLIDBs\nNLIDB\nYear\nUnderlying datatype\nSegmentation\nPart of speech\nNER\nDictionary generation\nRegular expression\nDependency parsing\nWord Embedding\nPattern Linking\nPRECISE [107]\n2003\nrelational data\n✓\n✓\n✓\n✓\nQuerix [69]\n2006\nontology\n✓\n✓\n✓\nQuestIO [27]\n2008\nontology\n✓\n✓\n✓\ngAnswer [60]\n2013\nRDF data\n✓\nMEANS [1]\n2015\nRDF data\n✓\n✓\nNL2CM [6, 5]\n2015\nRDF data\n✓\n✓\n✓\nNL2TRANQUYL [16]\n2015\nrelational data\n✓\nATHENA [113]\n2016\nrelational data\n✓\n✓\n✓\n✓\nSQLizer [153]\n2017\nrelational data\n✓\n✓\n✓\nTEQUILA [64]\n2018\nRDF data\n✓\n✓\n✓\nMyNLIDB [28]\n2019\nrelational data\n✓\n✓\n✓\nIRNet [53]\n2019\nrelational data\n✓\n✓\nNLMO [145]\n2020\nmoving objects\n✓\n✓\n✓\n✓\n✓\nNALMO [144, 143]\n2021\nmoving objects\n✓\n✓\n✓\n✓\n✓\nNALSD [88]\n2023\nspatial data\n✓\n✓\n✓\n✓\nNALSpatial [89]\n2023\nspatial data\n✓\n✓\n✓\n✓\nxDBTagger [132]\n2024\nrelation data\n✓\n✓\n✓\n✓\n3\nGeneration of executable database languages\nThe generation of executable database languages can be divided into three stages: (i) natural language preprocess-\ning, (ii) natural language understanding, and (iii) natural language translation. In stage (i), the system performs a\npreliminary analysis of the raw natural language query in order to prepare for the subsequent stage of natural lan-\nguage understanding. In stage (ii), the system performs semantic parsing and understanding of the preprocessed\nnatural language query to extract the semantic details and intent of the query. In stage (iii), the system converts\nthe comprehended natural language into a language that can be executed within the database.\n3.1\nNatural language preprocessing\nPrior to the semantic understanding and translation of natural language queries, preprocessing is performed using\ntraditional and data-driven methods. In order to preprocess natural language queries, the recently developed\nNLIDBs utilize techniques as illustrated in Table 3.\nThe preprocessing process of many NLIDBs commences with the construction of a dedicated data dictionary\nfor the domain. The extraction process of domain knowledge exerts a profound influence on the portability of the\nsystem. In addition, the semantic parsing component needs to accurately comprehend NLQ with the assistance\nof the dictionary, and the extraction process of domain knowledge will impact the availability of the NLIDB. The\nprimary goal of the extraction technique is to minimize the burden on system users while enhancing the capacity\nto automatically generate a dictionary. The extraction process is primarily reliant on stemming and synonym\ntechniques. The system then needs to perform word segmentation and part-of-speech tagging on the input natural\nlanguage. This process necessitates the utilization of natural language processing tools. When choosing the tool,\nthe high accuracy of the segmentation and part-of-speech tagging results should be considered first, followed\nby the speed of processing. Furthermore, the query must be oriented to database information, and the relevant\n11\nTable 4: Rules for parsing natural language queries\nRules\nTypical NLIDBs\nParse tree\nPRECISE [107], NaLIX [84, 85], Querix [69], DaNaLIX [81], gAnswer [60],\nNaLIR [78, 77, 79], NL2TRANQUYL [16], Unnamed method [65], MyNLIDB\n[28]\nOntology\nQuestIO [27], ATHENA [113], FINESSE [63], Unnamed method [41], CNL-\nRDF-Query [58], ATHENA++ [115], Unnamed method [4]\nSemantic graph\nUnnamed method [168], MEANS [1], NL2CM [6, 5]\nTemplate matching\nSQLizer [153], Unnamed method [3], LogicalBeam [11]\nPattern matching\nSODA [15]\nContext-free grammar\nTR Discover [121]\nSemantic grammar\nUnnamed method [49]\nstatements used in the query request are closely related to the database to be used. Therefore, part-of-speech\ntagging is often employed in conjunction with named entity recognition and data dictionary.\nTraditional preprocessing methods rely on predefined rules and grammars, involving techniques including\nNER, regular expressions, and dependency parsing. NLMO performs segmentation and entity recognition using\na natural language processing toolkit spaCy, and sets regular expressions for temporal information extraction.\nATHENA utilizes the TIMEX annotator to detect all temporal intervals mentioned in the text, and the Stan-\nford Numeric Expressions annotator to pinpoint all tokens containing numerical values. ATHENA employs the\nStanford Dependency Parser to identify the dependency relationship in the context of the GROUP BY clause.\nPRECISE utilizes the Charniak parser for the precise parsing of questions and the extraction of token relation-\nships from the resulting parse tree. NL2CM employs dependency parsing and part-of-speech tagging techniques.\nNL2TRANQUYL analyzes the input natural language using the Stanford Parser, resulting in constituency and\ndependency parses.\nData-driven preprocessing methods depend on large-scale data and machine learning models, and the tech-\nniques used include word embedding and pattern linking. Word2Vec and GloVe are word embedding models\nthat are able to represent words as points in a sequential vector space, thereby capturing the semantic relation-\nships between words. These vectors can be employed for calculating semantic similarity and extracting features.\nxDBTagger utilizes a pre-trained word embedding model to convert tokens into a 300-dimensional vector repre-\nsentation. IRNet performs schema linking by connecting the natural language with the database schema, aiming\nto identify the specific columns and tables referenced in the natural language. The columns are then assigned\ndifferent types according to the manner mentioned in the question.\n3.2\nNatural language understanding\nThree principal technical approaches to understand natural language are (i) rule-based, (ii) machine learning-\nbased, and (iii) hybrid. Based on the techniques, the process of natural language understanding for the recently\ndeveloped NLIDBs is summarized. We provide three timelines describing the research on rule-based, machine\nlearning-based, and hybrid approaches, as shown in Figure 5.\n3.2.1\nRule-based methods\nThe semantic parsing of mature NLIs is predominantly based on rules. The systems require specific rules to parse\nnatural language queries, including parse tree, ontology, semantic graph, template matching, pattern matching,\ncontext-free grammar, and semantic grammar, as shown in Table 4. Rule-based systems can only deal with knowl-\nedge bases in fixed domains and are generally not portable to other knowledge bases. In order to enhance the\naccuracy of semantic understanding, systems are typically constrained by limitations in their ability to support\n12\n2014\nNaLIR\n2015\nNL2CM\n2016\nATHENA\n2017\nNLQ/A\n2018\nTEQUILA\n2020\nATHENA++\n2021\nEXAQT\nNL2TRANQUYL\nDialSQL\nSQLizer\n2003\nPRECISE\n2005\nNaLIX\n2007\nDaNaLIX\n2006\nQuerix\n2009\nQUICK\n(to be continued)\n2019\nMyNLIDB\nezNL2SQL\n2008\nQuestIO\n2013\ngAnswer\nTR Discover\nMEANS\nSPARKLIS\nNLMO\n(a) Rule-based methods\n2020\nRYANSQL\n2022\nAuto-Query\n2021\nValueNet\nSP-CNN\n2017\nSeq2SQL\n2019\nIRNet\n2018\nSyntaxSQLNet\nCOMBINE\n2023\nDTE\n2024\nSV2-SQL\nIKnow-SQL\nSpatialNLI\nDialSQL\nBiBERT-SQL\nDBTagger\nMIE\n(b) Machine learning-based methods\n2022\nVeezoo\n2021\nNALMO\n2018\nTypeSQL\n2023\nGAR\n2024\nxDBTagger\nCatSQL\nGENSQL\nNALSpatial\nNALSD\n(c) Hybrid methods based on rule and machine learning\nFigure 5: Timelines of the research progress of techniques for understanding natural language\nnatural language features, such as grammar and vocabulary [144]. PRECISE [107] elucidates the notion of se-\nmantic tractability and delineates a specific subset of natural language that can be accurately converted into SQL.\nHowever, natural language queries that cannot be processed semantically will be rejected by PRECISE. NaLIX\n[84, 85] restricts natural language queries to a regulated subset according to a predetermined grammar. DaNaLIX\n[81] is constructed on NaLIX and employs domain knowledge for query translation. Domain knowledge is en-\ncapsulated within a collection of regulations that map terms with domain meaning in the parse tree to terms that\ncan be understood by a generic system such as NaLIX. The domain adapter within DaNaLIX assesses the current\ndomain expertise and modifies the parse tree with related rules. NaLIR [78, 77, 79] identifies nodes within the\nlanguage parse tree that have the potential to correspond to SQL components resulting from the preprocessing\nstep, and represents semantic coverage as a subset of the parse tree. Such a tree explicitly corresponds to SQL\nand serves as a query tree, which mediates between NLQ and SQL. To comprehend the challenge of integrating\nindividual and collective knowledge, NL2CM first uses RDF to represent individual and general knowledge. Indi-\nvidual expression detectors are then used to distinguish between individual and general query components, which\nare created through a declarative selection schema in conjunction with a specialized vocabulary. ATHENA uses\ndomain-specific ontology to transform the natural language input into an intermediate language on the ontology.\nThe intermediate language is then used to describe the semantic entities in the domain, as well as the relationships\nbetween the entities. Ontology provides richer semantic information than relational schema, including inheritance\n13\nand membership. By reasoning about the ontology, ATHENA demonstrates the capability to effectively discern\nand capture the intentions of users. However, ATHENA is highly sensitive to changes and interpretations of user\nqueries [99]. Both the NLIDB system described in the paper [116] and ATHENA++ [115] are extensions of\nATHENA. They combine linguistic analysis with deep domain reasoning to translate complex join and nested\nSQL. NL2TRANQUYL [16] is a system designed for the planning of journeys within a complex multi-modal\ntransportation system, taking into account a number of constraints, including the minimization of journey time,\ndistance and cost. NL2TRANQUYL utilizes the ontology comprising a range of concepts to store and model re-\nlated information, and generates knowledge graphs to determine the relationships between them. To discover and\nprocess temporal information in NLQ, TEQUILA decomposes the detected temporal problems and rewrites the\ngenerated sub-problems. These papers [60, 168] utilize the Stanford Parser to generate dependency trees and ex-\ntract semantic relations from the parsed data. Subsequently, a semantic query graph is constructed by connecting\nthese semantic relations to depict the user’s query intent. Querix [69] examines the syntax of natural language us-\ning a syntactic analyzer, which is only effective when the natural language components are complete. Incomplete\ncomponents may result in inaccurate results, which could compromise the accuracy of the final results.\nAn optimal NLIDB enables users to formulate intricate queries on the database system and retrieve precise\ninformation with minimal exertion. Consequently, a number of systems incorporate user interaction during the\nprocess of comprehending semantics. NaLIX and DialSQL [54] adjust the query during following user engage-\nments to revise the parse tree, however, the revision frequently necessitates a high number of user interactions.\nDaNaLIX acquires domain knowledge through the interaction that occurs between the user and the system in an\nautomated manner. In addition to elucidating the user on the query processing procedure, NaLIR also presents a\nspectrum of interpretations for the user to select from, thus alleviating the user’s need to address potential misun-\nderstandings. NaLIR is capable of detecting the parse tree, thereby enabling users to modify the parse tree directly,\nrather than reformulating the natural language query. NaLIR can provide recommendations to users for revising\ntheir queries in instances where the natural language queries fall beyond the semantic boundaries. QUICK [162]\nimproves user interactions by utilizing keyword search to enrich the expressiveness of semantic queries. In practi-\ncal application, QUICK assists users in determining the specific intent behind natural language through a series of\niterative refinement steps following the initial submission of a keyword-based question. NLQ/A [166] enhances\nthe user interaction component in order to more effectively address the issue of ambiguity. SPARKLIS [46] em-\nploys a sequential process consisting of three stages in order to guarantee the thoroughness of user input during\nsearches for concepts, entities or modifiers. While interacting with the system may result in the user feeling con-\nstrained, slowed down, and less natural when entering a query, SPARKLIS provides guidance and safety through\nintermediate answers and suggestions [2]. In order to reduce user involvement during the disambiguation process,\nATHENA utilizes the extensive semantic data within the ontology to produce a prioritized list of explanations,\nand employs a ranking algorithm that is intuitive and relies on ontology metrics to determine the most appropriate\nexplanation.\n3.2.2\nMachine learning-based methods\nAs the usage of statistical learning methods continues to expand, there has been a growing interest in conducting\nsemantic analysis on sentences through a variety of forms of supervision. Pasupat and Liang [102] employ\nquestion-and-answer format to provide guidance in responding to intricate natural language queries presented\nwithin semi-structured tables. The paper [105] represents the inaugural attempt to develop a semantic parsing\nmodel through unsupervised learning [66]. Artzi and Zettlemoyer [8] solicit feedback during the conversation to\ndetermine the meaning of the user’s statements. In a domain where no training examples are available, Wang et al.\n[146] demonstrate the successful development of a semantic parser. Their approach comprises two key elements:\n(i) a builder and (ii) a domain-general grammar. Wong and Mooney [150] utilize statistical machine translation\ntechnology for the purpose of accomplishing semantic parsing tasks.\n14\nTable 5: NLIDBs with encoder-decoder frameworks\nNLIDB\nYear\nEncoder\nDecoder\nDialSQL [54]\n2018\nEncode\ndialogue\nhistory\nusing\nRNN networks\nDecode errors and candidate se-\nlections\nSyntaxSQLNet [159]\n2018\nTable-aware column encoder\nSyntax tree-based decoder\nUnnamed method [87]\n2020\nEncode NLQs and table headers\nusing XLNet [155]\nThe parsing layer splices the vec-\ntor\nValueNet [19]\n2021\nExtension of IRNet’s encoder\nLSTM architecture and multiple\npointer networks\nUnnamed method [30]\n2021\nThe encoder of LSTM\nThe decoder of LSTM\nMIE [138]\n2021\nMulti-integrated\nencoder\nwith\nthree integrated modules\nNo decoder\nAuto-Query [100]\n2022\nThe encoder of RATSQL [137]\nSmBoP [112]\nSTAMP [51]\n2023\nThe encoder of T5\nThe decoder of T5\nUnnamed method [154]\n2023\nThe encoder of Transformer\nThe decoder of Transformer\nIn recent times, there has been a growing utilization of encoder-decoder frameworks that rely on recurrent\nneural networks for semantic parsing, as demonstrated in Table 5. Many systems combine machine learning and\ndeterministic algorithms to generate structured languages [93]. This method allows the direct acquisition of the\ncorrelation between natural language and the semantic representation, eliminating the need for an intermediate\nrepresentation like a parse tree [66]. Mapping natural language directly to the semantic representation can reduce\nthe dependence of rule-based semantic parsing models on preset vocabulary, templates, and hand-generated fea-\ntures. Machine learning-based models are not limited to specific knowledge bases or logical formal expressions,\nthus enabling the implementation of natural language interfaces that support cross-knowledge bases or cross-\nlanguages. Wang et al. [140, 142] propose a cross-domain NLI, which translates the marked natural language\ninto the intermediate representation of the target query type by building a cross-domain multilingual sequence-\nto-sequence (seq2seq) model. Symbols inserted into the natural language query are utilized to substitute the data\nelements present in the intermediate query. However, this method is a supervised machine learning model whose\neffectiveness is closely related to the quality of the training data. To ensure the accuracy of semantic understand-\ning, a substantial quantity of training data must be provided to the model. A number of researchers employ a\nsynthetic data generator as a solution to the challenge of having a restricted amount of training data available.\nThe paper [159] introduces SyntaxSQLNet, which can generate NLQ data sets for cross-domain SQL single-table\noperations, solely as a means of augmenting the training set. The method outlined in the paper [149] encompasses\nsingle-table and multi-table join queries of SQL, and can be utilized as either an augmentation or as a standalone\ntraining data set. In terms of model training, the rule-based method is more effective than the neural network-\nbased method, which requires more training parameters and takes longer to establish the model, consuming more\nmemory space.\nOne of the earliest examples of machine learning-based systems is demonstrated in the paper [161]. This work\nutilizes a deterministic shift-reduce parser and develops a learning algorithm called CHILL to learn the governing\nrules of parsing on the basis of inductive logic programming techniques. The corpus is trained using the CHILL\nmethod to build the parser. Instead of learning dictionaries, this approach assumes that a dictionary is created\nin advance that pairs words with semantic content rather than grammar. The paper [163] translates the mean-\ning of natural language sentences into lambda calculus encoding. The paper [163] outlines a learning algorithm\nwhose input is a collection of sentences identified as lambda calculus expressions, and applies the method to the\ntask of learning NLIDB to build a parser. While providing considerable flexibility, encoder-decoder frameworks\nfrequently lack the ability to interpret and understand combinations of meaning [66]. The method employed by\nCheng et al. [25] involves the construction of the intermediate structure in two stages, which facilitates a com-\nprehensive understanding of the model’s learning process. Similarly, the paper [39] also produces an intermediate\n15\ntemplate that presents the final output in a preliminary format, thereby facilitating the subsequent decoding pro-\ncess. Yin and Neubig [157] address the issue of insufficient training data by incorporating explicit constraints\nfor decoders through the utilization of target language syntax. The approach enables the model to concentrate\non parsing, directed by established grammar rules. Xiao et al. [151] utilize the grammar model as prior knowl-\nedge, requiring the creation of a derivation tree while adhering to the constraints imposed by the grammar. The\napproach in the paper [74] can significantly outperform the Seq2Tree model from the aforementioned paper [38]\nby verifying that the decoder’s forecasts adhere to the type constraints outlined in the type constraint grammar.\nThis suggests that satisfying type constraints and good formatting are equally important when generating logical\nexpressions. SpatialNLI [80, 141] is a natural language interface for the spatial field that employs the seq2seq\nmodel to understand the semantic structure of natural language, while utilizing an external spatial understanding\nmodel to identify the meaning of spatial entities. Subsequently, the spatial semantics learned from the spatial\nunderstanding model are integrated into natural language problems, thereby reducing the necessity of acquiring\nspecific spatial semantics. SpatialNLI represents a pioneering system that integrates an external spatial semantic\ncomprehension model to optimize the effectiveness of the principal seq2seq model. The paper [129] uses a tree\nmodel to analyze the target entity in natural language, and employs a tree-structured LSTM to understand the\nproblem. The paper [62] adjusts the neural sequence model to directly convert natural language into SQL, thus\ncircumventing the intermediate query language representation. Then the user feedback is utilized to mark error\nqueries, which are directly used to improve the model. The complete feedback loop does not necessitate the use\nof any intermediate language representation and is not limited to a specific domain. This method offers the benefit\nof enabling the rapid and straightforward construction of a semantic parser from scratch, and the performance of\nthe parser improves as user feedback increases. The encoder of ValueNet [19] is an extension of the encoder of\nIRNet [53], receiving not only details regarding the database schema, but also extracted value candidates from the\ndatabase content.\n3.2.3\nHybrid methods based on rule and machine learning\nHybrid methods integrate rules and machine learning techniques to capitalize on the respective strengths of each,\nthereby enhancing the ability of the system to understand and process NLQs [72]. Table 6 enumerates the rep-\nresentative systems that employ the hybrid approach. Hybrid approaches are highly flexible and adaptable, as\nthey can utilize rules for tasks with explicit rules as well as machine learning models for complex and ambiguous\nsemantic tasks. In addition, hybrid methods can flexibly incorporate new rules or train new machine learning\nmodels as needed to accommodate the requirements of diverse domains and tasks, and are highly scalable [135].\nTypeSQL [158], like SQLNet [152], is built on sketches and formats translation tasks as slot-filling problems.\nThe difference is that TypeSQL employs type information to enhance the understanding of entities and numbers\nin NLQs. TypeSQL assigns a type to each word, such as entity, column, number and date, within the knowledge\ngraph. Subsequently, two bidirectional LSTM networks are utilized to encode the words in the NLQ with the\ncorresponding column names and types. Finally, the LSTM output hidden states are leveraged to forecast the\nslot values within the SQL sketch. NALMO is a natural language interface for moving objects. To understand\nNLQs, NALMO employs an entity extraction algorithm to obtain entity information, including time, location and\nthe number of nearest neighbors. A pre-constructed corpus is then trained using LSTM to determine the query\ntype. Veezoo [75] uses a range of techniques, including temporal expression parsing, entity linking, and relation\nextraction, to identify key information in NLQs. The information is then extended and combined using predefined\nrules to generate multiple candidate intermediate representations. Finally, Veezoo utilizes a machine learning\nmodel to score these intermediate representations in order to select the most probable interpretation of the NLQ.\nThe process of data preparation in GAR [42] commences with a collection of sample SQLs that are tailored to a\nspecific database. For a given NLQ, GAR searches for the NLQs generated during data preparation and employs\na learning-to-rank model to identify the most relevant query, which is then used to obtain the translation result.\n16\nTable 6: NLIDBs based on rules and machine learning techniques\nNLIDB\nYear\nRule\nMachine learning technique\nUnnamed method\n[52]\n2012\nGenerate candidate SQLs via rules and\nheuristic weighting schemes\nReorder candidate SQLs using the SVM\nsorter\nTypeSQL [158]\n2018\nAssign a type to each word to under-\nstand the entity\nEncode using bidirectional LSTM\nNALMO\n[144, 143]\n2021\nSemantic\ngrammar\nand\ntemplate\nmatching\nIdentify the query type using LSTM\nVeezoo [75]\n2022\nKnowledge graph\nScore intermediate representations using\nmachine learning models\nGAR [42]\n2023\nParse tree\nFind the matching expression for NLQ\nusing a learn-to-rank model\nGENSQL [44]\n2023\nCapture the structure of the database\nwith sample SQLs\nFind the matching expression for NLQ\nusing a learn-to-rank model\nCatSQL [48]\n2023\nTemplate matching\nThe decoder of Transformer. Train the\nmodel using Adam [71]\nNALSpatial [89]\n2023\nSemantic\ngrammar\nand\ntemplate\nmatching\nIdentify the query type using LSTM\nNALSD [88]\n2023\nSemantic\ngrammar\nand\ntemplate\nmatching\nIdentify the query type using LSTM\nxDBTagger [132]\n2024\nSemantic graph\nBidirectional recurrent neural network\nThe learning-to-rank model learns to rank the semantic similarities from NLQs to generated NLQs and then finds\nthe best matching expression for a given NLQ. GENSQL [44], a generative NLIDB, utilizes a given example SQL\nfrom the database (e.g., from query logs) to comprehend the unique structure and semantics of a given database,\nthereby guaranteeing precise translation outcomes. The fundamental model used in GENSQL for converting nat-\nural language to SQL is GAR. CatSQL [48] is a method for the generation of SQL that makes use of sketches. In\naddition, semantic constraints are merged into the neural network-driven SQL generation procedure for semantic\nrefinement. CatSQL sketches are templates with keywords and slots. CatSQL employs a deep learning algorithm\nto populate vacant slots in order to generate the ultimate SQL. The deep learning algorithm is developed to focus\non the generation of essential NLQ-related information, with the objective of filling the gaps without requiring the\nexplicit generation of keywords like SELECT, FROM, and WHERE.\nHybrid approaches based on rules and machine learning offer several advantages, including flexibility, accu-\nracy, and scalability. Nevertheless, such approaches present certain challenges, such as complexity, dependence\non data, and tuning difficulties [68]. Hybrid methods require the simultaneous management and maintenance of\nrule engines and machine learning models, including rule definition, feature engineering, and model training, and\nthus have high complexity [52]. Furthermore, the rules and machine learning models utilized in hybrid approaches\nmay encounter parameter tuning problems, which necessitate a significant investment of time and effort for opti-\nmization and debugging, thus increasing the costs associated with the development and maintenance of the system.\nDuring the design and implementation of natural language interfaces, it is essential to take a comprehensive view\nof the advantages and challenges involved, and to make trade-offs and choices in accordance with the specific\nneeds.\n3.3\nNatural language translation\nThe natural language translation stage employs the semantic information derived from the natural language un-\nderstanding stage, subsequently integrating the underlying structure of the database to transform the input natural\nlanguage into the corresponding executable language. A prevalent approach for translation is to employ com-\nplex algorithms and machine learning models to generate structured language based on the domain knowledge\nof the underlying database and the semantic representation of natural language [83]. Most established NLIDBs\n17\nParsed NLQ\nNumber of\nquery relations\nDatabase elements\nDatabase elements\nJoin conditions and\ninvolved relations\nSELECT, FROM, WHERE\nSELECT, FROM, WHERE\nWHERE, FROM\nSQL\n1\n>1\nFigure 6: General build process for SQL\nconstruct queries by query combination, mapping key information expressed in natural languages to correspond-\ning components in structured languages. We examine the process of natural language translation in recently\ndeveloped NLIDBs, and summarize the general construction process of executable languages for relational and\nspatio-temporal databases.\nThe general build process for SQL is illustrated in Figure 6 and further elaborated in the subsequent two cases.\n(i) When querying a single relation, it is only necessary to place the database elements matched by NLQ in the\ncorrect positions in the SELECT, FROM, and WHERE parts, respectively. Then, SQL can be composed directly.\n(ii) When querying multiple relations, the join condition and the names of the participating relations need to\nbe included in the WHERE and FROM clauses, respectively. Additionally, it is necessary to determine whether\nthe join path is unique. If only one join path is available, SQL can be generated directly. Otherwise, a query\nis typically generated for each possible join path, and then the most probable one is selected according to the\ncorresponding algorithm.\nIn recent years, there has been significant interest in NLI for spatio-temporal databases [26]. Temporal and\nspatial concepts are derived from the natural language description using symbolic representations in order to depict\nspatio-temporal features and their relationships [14, 106]. Due to the particularity and expressiveness of spatio-\ntemporal problems, executable query languages over spatio-temporal databases are quite different from SQL.\nConsequently, the method employed for the construction of SQL cannot be directly applied to the generation of\nexecutable languages over spatio-temporal databases. The general process for the construction of an executable\nlanguage for a spatio-temporal database is shown in Figure 7. Preliminary parsing of the input natural language\nquery is performed to obtain semantic information including key entities and query types. Subsequently, the\noperators necessary to construct the executable language are determined according to the type of query. Finally,\nkey entities and operators are combined according to certain rules to compose an executable database language.\nTaking the range query over spatial data as an example, the key entities involved include spatial relations and\nlocations. The operator intersects will return all objects in the relation that intersect the location if the spatial\nattribute of the relation and the data type of the location are both line or region. Conversely, the operator intersects\nwill return all objects in the relation that lie within the location if the spatial attribute of the relation is point and\nthe data type of the location is region.\nDifferent DBMSs and structured languages offer a range of clauses and operators for various queries. ATHENA\nemploys a mapping strategy that correlates the ontology with the database schema in order to convert the interme-\ndiate query language utilized in the ontology into SQL. The system described in the paper [63] extends ATHENA\nto access multiple structured backends, which is achieved through the automated translation of the intermediate\n18\nParsed NLQ\nKey semantic\ninformation\nQuery type\nKey entities\nOperator\nQuery\ncombination\nExecutable language\nMapping rules\nFigure 7: General construction process for executable languages over spatio-temporal data\nquery language into the specific structured query language utilized by these backend stores. NLPQC [124] is\ncapable of processing queries formulated using predefined domain-specific templates. Querix selectively isolates\nspecific elements from the syntactic tree in order to align acquired knowledge with the knowledge base, thereby\nobtaining the final outcome. NL2CM leverages crowd intelligence by converting audience queries into OASSIS-\nQL (an extended version of SPARQL). NaLIR utilizes the structure of the user-validated query tree to produce\nthe suitable structure in the SQL statement and determine the join path. In order to ascertain whether the target\nSQL contains aggregate functions or sub-queries, NaLIR initially identifies function nodes or quantifier nodes\nin the query tree and subsequently generates SQL statements based on the identified conditions. The paper [52]\nemploys lexical dependencies found in the question and database metadata to build a reasonable collection of\nSELECT, WHERE, and FROM clauses that enhance the quality of meaningful joins. The paper [52] combines\nclauses through a rule and heuristic weighting scheme, and then generates a sorted list of candidate SQLs, demon-\nstrating that full semantic interpretation can be avoided by relying on a simple SQL generator. This method can\nbe employed iteratively to address intricate issues necessitating nested SELECT commands. Finally, this paper\n[52] applies the re-ranker to reorder the list of questions and SQL candidate pairs with the aim of enhancing the\naccuracy of the system. TEQUILA uses a standard KB-QA system to evaluate the sub-questions from the se-\nmantic understanding part individually. The results of the sub-questions are then combined with the reasoning\nto calculate the answer to the full question. NL2TRANQUYL translates English requests into formal TRAN-\nQUYL [17] queries using the knowledge graph generated by the semantic comprehension component. The traffic\nquery language TRANQUYL for travel planning follows the conventional SQL structure of “SELECT, FROM,\nWHERE”. NALMO supports five distinct types of moving object queries, including (i) time interval queries, (ii)\nrange queries, (iii) nearest neighbor queries, (iv) trajectory similarity queries, and (v) join queries. In the query\ntranslation process, NALMO first constructs a corpus comprising the five query types, collectively referred to as\nMOQ. Then the LSTM neural network is used for training, resulting in a model that is capable of accurately iden-\ntifying the specific type of query. Finally, the appropriate operators are selected according to the query type, and\nthe entity information extracted by the semantic parsing component is combined to build the executable language\nfor SECONDO.\n4\nNL2SQL benchmarks\nWe presents 11 frequently used benchmarks for transforming NLQ into SQL and three evaluation metrics, explor-\ning the methods for generating new benchmarks.\n4.1\nExisting benchmarks\nThe details of NLQ and executable language pairs for common domains are presented in Table 7. The majority\nof existing benchmarks are utilized in the domain of relational databases to transform natural language query into\nSQL (NL2SQL). The comparison of fields and types of SQL supported by the benchmarks for NL2SQL is shown\nin Table 8. We can conclude that GeoQuery and Spider support the most types of SQL, while WikiSQL supports\n19\nTable 7: Examples of NLQ and executable language pairs for common domains\nDomain\nExamples of NLQ and executable language pairs\nRelational database\nNLQ: How many CFL teams are from York College?\nSQL:\nSELECT COUNT CFL Team FROM CFLDraft WHERE College = “York”\nSpatial domain\nNLQ1: What is the population of San Antonio?\nLambda expression:\nanswer(A,population(B,A),const(B,cityid(San Antonio)))\nNLQ2: Could you tell me what parks are in the center?\nExecutable language:\nquery park feed filter [.GeoData ininterior center] consume;\nMoving Objects\nNLQ: Where did the train 7 go at 8am?\nExecutable language:\nquery Trains feed filter [.Id = 7] filter [.Trip present [const instant value “2020-11-\n20-8:00”]] extend [Pos: val (.Trip atinstant [const instant value “2020-11-20-8:00”])]\nproject [Id, Line, Pos] consume;\nTrip planning\nNLQ: Can I walk to 300 W. Humboldt Blvd. by 4:00 p.m.?\nTRANQUYL:\nSELECT ∗FROM ALL TRIPS(user.current location, 300 W. Humboldt Blvd.) AS t\nWITH MODES pedestrian WITH CERTAINTY .78 WHERE ENDS(t) ≤4:00 p.m.\nMINIMIZE DURATION(t)\nCrowd mining\nNLQ: What are the most interesting places near Forest Hotel, Buffalo, we should visit\nin the fall?\nOASSIS-QL:\nSELECT VARIABLES $x WHERE {$x instanceOf Place.\n$x near For-\nest Hotel, Buffalo, NY} SATISFYING {$x hasLabel “interesting”} ORDER BY\nDESC(SUPPORT) LIMIT 5 AND {[] visit $x.\n[] in Fall} WITH SUPPORT\nTHRESHOLD = 0.1\nonly the simple select query. The queries in WikiSQL and Spider cover a multitude of domains. In recent years,\nGeoQuery, MAS, WikiSQL and Spider have been employed with considerable frequency.\nThe details of popular benchmarks are shown in Table 9. Early data sets consist of only one domain and one\ndatabase, such as ATIS, Restaurant and GeoQuery. In contrast, the latest data sets, for example WikiSQL and\nSpider, contain multiple domains and several databases with larger and more diverse NLQs and SQLs.\n(i) ATIS (Airline Travel Information System) [108] is a classical data set with a relatively old age, having\nbeen introduced by Texas Instruments in 1990. ATIS is built on the relational database Official Airline Guide,\ncomprising 25 tables and 5871 queries written in English. The queries pertain to details regarding flights, ticket\nprices, destinations, and services available at airports. The queries in ATIS are for the air travel field, including\njoin queries and nested queries, but no grouping and sorting queries. The average length of NLQs and SQLs\nin ATIS is approximately 11 and 67 words, respectively. Each query operates on an average of six tables. An\nexample query is as follows.\nQ1: What aircraft is used on delta flight 1984 from Kansas city to Salt Lake city?\n(ii) Restaurant [127] comprises a vast collection of dining establishments located in Northern California,\nstoring restaurant names, locations, features, and travel guide ratings. The benchmark contains 250 questions\nabout restaurants, food types and locations. An example query is as follows.\nQ2: Where is a good Chinese restaurant in Palo Alto?\n(iii) GeoQuery [128] consists of 8 tables and 880 natural language queries in the US geographic database. The\nqueries in GeoQuery are designed for the geographic domain, including join queries, nested queries, grouping\n20\nTable 8: Comparison of benchmarks for NL2SQL\nBenchmark\nSelect query\nGroup query\nSort query\nJoin query\nNested query\nFields involved\nUsage in papers\nATIS\n✓\n✓\n✓\nair travel\n[62, 47, 103, 104, 120]\nRestaurant\n✓\n✓\nrestaurant\n[127, 107, 81, 80]\nGeoQuery\n✓\n✓\n✓\n✓\n✓\ngeography\n[127, 128, 107, 163, 81, 52,\n113, 62, 47, 80, 104, 115,\n120, 42, 141]\nMAS\n✓\n✓\n✓\nacademic\n[77, 113, 153, 35, 9, 115, 131,\n132]\nScholar\n✓\n✓\nacademic\n[47]\nIMDB\n✓\n✓\ninternet movie\n[153, 9, 58, 131, 132]\nYELP\n✓\n✓\nbusiness review\n[153, 9, 131, 132]\nWikiSQL\n✓\nmultiple fields (e.g.\nstate,\ncollege, manufacturer)\n[167, 54, 158, 156, 87, 142,\n48, 51, 125]\nParaphraseBench\n✓\n✓\nmedical\n[133]\nAdvising\n✓\n✓\n✓\nuniversity course\n[47]\nSpider\n✓\n✓\n✓\n✓\n✓\n138 different fields (e.g.\ncar, stadium, country)\n[160, 53, 156, 115, 19, 50, 92,\n131, 42, 43, 48, 51, 125]\nTable 9: Details of popular benchmarks\nBenchmark\nYear\n#queries\n#tables\nDomains covered\nATIS [108]\n1990\n5871\n25\nsingle field\nRestaurant [127]\n2000\n250\n3\nsingle field\nGeoQuery [128]\n2001\n880\n7\nsingle field\nMAS [77]\n2014\n196\n17\nsingle field\nScholar [62]\n2017\n816\n10\nsingle field\nIMDB [153]\n2017\n131\n16\nsingle field\nYELP [153]\n2017\n128\n7\nsingle field\nWikiSQL [167]\n2017\n80654\n24241\nmultiple fields\nParaphraseBench [133]\n2018\n290\n1\nsingle field\nAdvising [47]\n2018\n4387\n15\nsingle field\nSpider [160]\n2018\n10181\n1020\nmultiple fields\nqueries and sorting queries. The average length of NLQs and SQLs in GeoQuery is about 8 and 16 words,\nrespectively. Additionally, each query operates on an average of one table. Although the queries are relatively\nbrief in length, they are highly composable, with nearly half of the SQL containing at least one nested sub-query.\nOne of the English queries is as follows.\nQ3: What is the largest city in states that border California?\n(iv) MAS [77] is generated from the Microsoft Academic Search database, which stores information such as\nacademic papers, authors, journals, and conferences. The source of NLQs in MAS is the logical queries that are\ncapable of being articulated in the search interface of the Microsoft Academic Search platform. The fields of MAS\nand Scholar are both academic in nature, but exhibit distinct patterns. One English query is as follows.\nQ4: Return authors who have more papers than Bob in VLDB after 2000.\n(v) Scholar [62] consists of 816 NLQs for academic database search that are annotated with SQL. The average\nlength of NLQs and SQLs in Scholar is approximately 7 and 29 words, respectively. Each query operates on an\n21\nTable 10: Query categories and examples for ParaphraseBench\nCategory\nExample queries\nNaive\nWhat is the average length of stay of patients where age is 80?\nSyntactic\nWhere age is 80, what is the average length of stay of patients?\nMorphological\nWhat is the averaged length of stay of patients where age equaled 80?\nLexical\nWhat is the mean length of stay of patients where age is 80 years?\nSemantic\nWhat is the average length of stay of patients older than 80?\nMissing Information\nWhat is the average stay of patients who are 80?\naverage of 3 tables. Iyer et al. [62] provide a database for performing these queries, which includes academic\narticles, journal details, author information, keywords, citations, and utilized datasets. One of the English queries\nis as follows.\nQ5: Get all author having data set as DATASET TYPE.\n(vi) IMDB and YELP [153] are generated using data from the Internet Movie Database and Business Review\nDatabase, respectively. The NLQs are obtained from coworkers of the authors of the paper [153], who are only\naware of the types of data available in the database and not the underlying database schema.\n(vii) WikiSQL [167], introduced in 2017, is a comprehensive and meticulously annotated collection of natural\nlanguage to SQL mappings, and currently represents the most extensive data set for NL2SQL. WikiSQL contains\nSQL table instances extracted from 24241 HTML tables on Wikipedia, and 80654 natural language queries, each\naccompanied by an SQL. WikiSQL comprises genuine data extracted from the web, with queries involving a\nmultitude of tables, but the queries do not involve complex operations such as GROUP BY and multi-table union\nqueries. The majority of questions in WikiSQL are between 8 and 15 words in length, most SQLs are between\n8 and 11 words, and most table columns are between 5 and 7. In addition, most natural language queries are of\nthe what type, followed by which, name, how many, who. The execution accuracy of WikiSQL has significantly\nimproved from the initial 59.4% to 93.0%, and the method has undergone a transformation from a simple seq2seq\napproach to a multi-tasking, transfer learning, and pre-training paradigm. A pair of questions and SQLs for the\nCFLDraft table can be formulated as follows.\nQ6: How many CFL teams are from York College?\nSQL Q6: SELECT COUNT CFL Team FROM CFLDraft WHERE College = “York”\n(viii) ParaphraseBench [133], a component of the DBPal paper [10], is a benchmark utilized to assess the\nrobustness of NLIDBs. Unlike existing benchmarks, ParaphraseBench covers diverse language variants of user\ninput NLQs and maps natural language to the anticipated SQL output. The benchmark is constructed upon a\nmedical database that contains a single table for storing patient information. The language variants utilized in\nNLQs permit the classification of NLQs into six categories, as illustrated in Table 10.\n(ix) Advising [47] was proposed in 2018, and the NLQs were built on a database of course information from\nthe University of Michigan containing fictitious student profiles. A portion of the queries are collected from the\nFacebook platform of the EECS department, and the remaining questions are formulated by computer science\nstudents well-versed in database topics that might be raised in academic consulting appointments. The queries in\nAdvising are for student-advising tasks, including join queries and nested queries. One of the English queries is\nas follows.\nQ7: For next semester, who is teaching EECS 123?\n(x) Spider [160] is a large NL2SQL data set introduced by Yale University in 2018, in order to solve the\nrequirement for extensive and high-caliber datasets for a novel intricate cross-domain semantic parsing challenge.\n22\nThe data set contains 10181 natural language queries and 5693 corresponding complex SQLs, which are dis-\ntributed across 200 independent databases, and the content covers 138 different domains. The average length of\nquestions and SQL statements in Spider is approximately 13 and 21 words, respectively. While the number of\nquestions and SQLs in Spider is not as extensive as that of WikiSQL, Spider contains all common SQL patterns\nand complex SQL usages, including advanced operations like HAVING, GROUP BY, ORDER BY, table joins,\nand nested queries, which makes Spider closely aligned with real-world scenarios. The following is an illustra-\ntive example of a complex problem and the corresponding SQL, which contains a nested query, a GROUP BY\ncomponent, and multiple table joins.\nQ8: What are the name and budget of the departments with average instructor salary greater than the overall\naverage?\nSQL Q8: SELECT T2.name, T2.budget FROM instructor as T1 JOIN department as T2 ON T1.department id =\nT2.id GROUP BY T1.department id HAVING avg (T1.salary) > (SELECT avg (salary) FROM instructor)\n4.2\nGeneration of new benchmarks\nModifying an existing NL2SQL benchmark to generate a new one is a common practice. The following steps\ndescribe the process in detail.\n(i) Researchers are required to conduct a meticulous analysis of the existing benchmarks, including an exam-\nination of the data structures, query types, and complexity. Through the analysis, they can gain insight into the\nconstraints of the benchmark and identify potential avenues for enhancement.\n(ii) Designing a modification strategy is a critical step, which involves determining how to modify and extend\nthe benchmark on the basis of the analysis results. The step may include adding new queries, changing the\nlinguistic expression of queries, and introducing complex query types.\n(iii) In the process of implementing modifications, researchers are expected to execute the designed modifica-\ntion strategy with precision in order to ensure that the new benchmark meets the expected requirements.\n(iv) Evaluating the performance is a pivotal aspect of the process. The researchers employ the modified\nbenchmark to train and test NL2SQL models, subsequently assessing the models’ performance and generalization\ncapabilities according to the new benchmark.\nBuilding on Spider [160], Kaoshik et al. [67] propose a new NL2SQL benchmark, named ACL-SQL, contain-\ning five tables and 3100 pairs of NLQ and SQL. By defining and annotating three types of questions on temporal\naspects in Spider: (i) questions querying for temporal information, (ii) questions querying for temporal infor-\nmation with grouping or ordering, and (iii) questions with temporal conditions, Vo et al. [136] propose a new\ndata set, TempQ4NLIDB, which can assist NLIDB systems based on machine learning approaches to improve\ntheir performance on temporal aspects. To address the dearth of publicly available benchmarks on ambiguous\nqueries, Bhaskar et al. [11] generate a new benchmark called AmbiQT by modifying Spider with a combination\nof synonym generation and ChatGPT-based and standard rules-based perturbation. AmbiQT comprises in excess\nof 3000 examples, each of which can be interpreted as two valid SQLs due to lexical ambiguities (namely, unam-\nbiguous column and table names) or structural ambiguities (namely, the necessity of joins and the pre-computation\nof aggregations).\nIn light of the limitations of existing benchmarks, including (i) the presence of data bias or linguistic ex-\npression limitations, and (ii) the limited coverage of domains and contexts that cannot fully represent real-world\ndiversity, researchers have proposed generators for Text2SQL benchmarks. Weir et al. [149] present a synthesized\ndata generator that synthesizes SQL patterns in the template syntax, including aggregations, simple nesting, and\ncolumn joins. Each SQL pattern is matched with numerous different natural language (NL) patterns, allowing\nfor the generation of a vast number of domain-specific NLQs and SQLs. Luo et al. [90] propose an NL2VIS\nsynthesizer, named NL2SQL-to-NL2VIS, which is capable of generating multiple pairs of natural language and\nVIS from a single NL and SQL pair based on semantic joins between SQL and VIS queries. NL2SQL-to-NL2VIS\n23\ncan be utilized to create NL2VIS benchmarks from established NL2SQL benchmarks. Hu et al. [59] suggest\na framework for synthesizing Text2SQL benchmarks. The framework involves first synthesizing SQL and then\ngenerating NLQs. At the stage of synthesizing SQL, a method is suggested for column sampling based on pattern\ndistance weighting to prevent excessive complexity in concatenation. In the process of generating text from SQL,\nan intermediate representation is used to facilitate the transition from SQL to NLQ, thereby enhancing the quality\nof the generated NLQ.\n4.3\nEvaluation metrics\nNLIDB is intended to assist users in efficiently querying and retrieving query results, and thus evaluating the\nresponse time and effectiveness of the system is essential. Response time measures how quickly the system can\nprocess a user’s natural language queries and return the relevant results. Effectiveness measures how well the\nsystem translates natural languages into accurate and relevant executable database languages, which consists of\ntwo measures: (i) translatability and (ii) translation precision.\nDEFINITION 1 (Translatability). Given the set E of executable languages generated by the system and the set\nN of input natural language queries, the translatability T is defined as follows.\nT = |E|\n|N|\nDEFINITION 2 (Translation precision). Given the set ER of executable languages that meet the expected\nresults, the set N of natural language queries entered into the system, the translation precision TP is defined as\nfollows.\nTP = |ER|\n|N|\nResponse time denotes the duration necessary for the system to transform the input natural language into the\nexecutable language of the database. This temporal interval represents the difference between the moment when\nthe system furnishes the translated output and the moment when the natural language is received. Translatability\nis a measure of the likelihood of the system accurately translating a natural language into an executable language.\nThis metric is quantified as the proportion of correctly translated queries out of the total number of queries sub-\nmitted to the system. Translation precision refers to the likelihood that the final output of the translated executable\nlanguage matches the expected outcome, and is quantified as the ratio of executable languages producing the\ndesired results to the overall number of queries.\nThe outcomes of evaluating a system may be different depending on the benchmark used. The size of the\nbenchmark affects the accuracy of the semantic parsing part of the system. Complex queries in the benchmark can\nbe used to assess the system’s ability for generalization. In related papers, PRECISE achieves 95.0% translatabil-\nity and translation precision on the Restaurant benchmark and 77.5% on the GeoQuery benchmark. ATHENA has\na translatability and translation precision of 87.2% on the GeoQuery benchmark and 88.3% on the MAS bench-\nmark. The translatability and translation precision of NALMO on the benchmark MOQ are 98.1% and 88.1%,\nrespectively.\n5\nSystem interfaces development\nWe categorize recently developed NLIDBs according to the technical approach and the data stored in the backend.\nThe methods of developing and using the system interfaces are then divided into two categories for analysis and\nsummary:(i) used as an independent software and (ii) used as a module of a database management system. Finally,\nenhancements to the existing NLIDB system are presented in three aspects.\n24\n5.1\nRecently developed NLIDBs\nWe are concerned with the NLIDBs, which have emerged since 2000. There are several ways to classify NLIDBs.\nAffolter et al. [2] divide recently developed systems into four categories.\n(i) Keyword-based systems are represented by SODA [15]. The core of such a system lies in the search\nprocess, where the inverted index containing fundamental data and metadata from the database is utilized as the\nretrieval target. This process involves comparison with natural language, and identification of keywords referenced\nin the query. Although simple, the approach fails to identify the potential semantics that are not directly present\nin natural language. Such systems are unable to respond to aggregation queries and complex questions involving\nsub-queries.\n(ii) Pattern-based systems, exemplified by NLQ/A [166] and QuestIO [27], are extensions of keyword-based\nsystems that are capable of incorporating natural language patterns and mapping to pre-specified query sentence\npatterns.\n(iii) Parsing-based systems are typified by NaLIR, a general interactive natural language interface designed\nfor querying relational databases. NaLIR employs the existing natural language parser to acquire the semantic\nunderstanding of the given NLQ which is represented by a parse tree, and then converts the semantic understand-\ning into database understanding and finally into SQL. Such systems incorporate a multitude of natural language\nprocessing methods, including the parsing of natural language sentences employing parse trees. One principal\nbenefit of this method is the ability to map semantics into predefined SQL templates.\n(iv) Grammar-based systems are represented by TR Discover [121] and MEANS [1]. The foundation of such\nsystems consists of a predetermined set of grammar rules, which are used to constrain the questions that users can\npose to the system in order to form formal NLQs that are straightforward to analyze. The primary advantage of\nthis approach is that the systems are capable of providing users with guidance as they enter questions, and can\nrespond to all questions that adhere to the established rules. In comparison to keyword-based, pattern-based and\nparsing-based systems, grammar-based systems are considered to be the most robust, despite relying significantly\non predefined manual rules.\nIn this survey, we categorize NLIDBs into seven distinct groups according to the data stored in the backend.\nThe representative systems for each category are depicted in Figure 8. Among the various categories, natural\nlanguage interfaces for relational data are the most prevalent and functional, and are subjected to ongoing research\non an annual basis. Recently, research on NLIs for XML data has not advanced, remaining at the same stage as\nin 2007. The two main reasons are (i) an increasing preference for JSON as a format for data exchange over\nXML, and (ii) the suitability of NoSQL databases for handling unstructured or semi-structured data over XML\ndatabases. Since 2013, NLIs for natural language queries over RDF data, ontology data, graph data, spatial data,\nand spatio-temporal data have been developed. The executable languages transformed by these NLIs correspond\nto the databases used.\nNLIDB for relational data transforms natural language queries into SQL. IRNet [53] first identifies the entities\ncontained in the NLQ, including columns, tables and values. Subsequently, a neural model based on syntax is\nused to synthesize an intermediate representation connecting natural language with SQL. Finally, IRNet derives\nSQLs on the basis of intermediate representations. Representative NLIDBs for XML databases are NaLIX [85]\nand DaNaLIX [81], which transform natural language queries into XQuery. NaLIX restricts natural language to a\npredefined subset of the grammar. DaNaLIX builds upon NaLIX and enables users to leverage domain knowledge\nfor query transformation. TEQUILA [64] is a typical NLIDB for RDF data, which transforms natural language\nqueries into SPARQL. TEQUILA employs a standard knowledge-based question and answer system to evaluate\nsub-questions independently. The results of the sub-questions are then combined for inference to compute the\nanswer to the full question. QuestIO [27] works for querying structured data represented in ontology format.\nBuilt on the ontology and a knowledge base containing instances of the ontology’s concepts, QuestIO accepts\nNLQ as input and produces SeRQL as output. Utilizing the language processing framework GATE, QuestIO\n25\nCHILL, BIN-CAT, PRECISE, SODA,\nNLProv, ATHENA, SQLizer, Seq2SQL, NLProveNAns,\nDialSQL, SyntaxSQLNet, TypeSQL, TEMPLAR, MyNLIDB, IRNet,\nMISP-SQL, GLAMORISE,                                          ATHENA++, DBPal,\nBiBERT-SQL, ezNL2SQL,                                         ValueNet, COMBINE,\nDBTagger, MIE, Veezoo, Auto-Query, ApproxEDA, LogicalBeam, \nGAR, GENSQL, IKnow-SQL, CatSQL, STAMP,\n   SV2-SQL, xDBTagger, NaLIR\nRelational data\ngAnswer\nMEANS\nNL2CM\nTEQUILA\nEXAQT\nRDF data\nSpatialNLI\nSP-CNN\nNALSpatial\nNALSD\nNeuroSPE\nSpatial data\nNL2TRANQUYL\nNLMO\nNALMO\nSpatio-temporal data\nNaLIX\nDaNaLIX\nXML data\nQuerix\nQuestIO\nCNL-RDF-Query\nOntology data\nGraph data\nTR Discover\nFINESSE\nFigure 8: Classification of NLIDBs based on data stored in the backend\ncombines fundamental concepts with keywords, blocks and phrases to deduce potential relationships among the\nconcepts in the ontology. In the spatio-temporal domain, NLIDB can handle GIS-related queries, such as historical\nmeteorological data at a specific location, and geographic position information at different moments. NeuroSPE\n[109] is a spatial extraction model designed to identify spatial relations within Chinese natural language text. The\nmodel extends a bidirectional gated recurrent neural network with a series of pre-trained models and is able to\naddress specific challenges in a variety of natural language text, including the absence of direct context and the\noccurrence of abbreviations, special languages, and symbols. NALMO [144, 143] is a natural language interface\ndesigned for moving objects that allows users to submit queries of five types, including (i) time interval queries,\n(ii) range queries, (iii) nearest neighbor queries, (iv) trajectory similarity queries, and (v) join queries.\nSeveral systems have been created that can be used across various back-end data stores, with the objective of\nenhancing the generality of NLIDB. TR Discover [121] is one such system which transforms NLQ into SPARQL\nor SQL. TR Discover generates FOL representations by analyzing natural language using a feature-based context-\nindependent grammar consisting of entries in the vocabulary for leaf nodes and rules governing the phrase structure\nfor non-terminal nodes. The FOL representation is then parsed into a parse tree through the utilization of a first-\norder logic parser. The parse tree is traversed sequentially and transformed into SPARQL or SQL. FINESSE\n[63], an extension to ATHENA, is a system that seamlessly connects to multiple structured data stores. FINESSE\ncan access various structured backends (e.g., RDF stores and Graph stores) by automatically transforming the\nintermediate query language OQL into the corresponding structured query language specific to the backends (e.g.,\nSPARQL and Gremlin).\n5.2\nDevelopment and usage of system interfaces\nThe combination of the aforementioned three components, including (i) natural language preprocessing, (ii) nat-\nural language understanding and (iii) natural language translation, constitutes a comprehensive system architec-\nture. Then the theoretical knowledge is implemented in the form of a system. There are two primary methods of\ndevelopment and usage:\n(i) A stand-alone software. In this scenario, the system generally comprises a separate visual interface and a\ndatabase, and the architecture is shown in Figure 9(a). A visual interface allows users to write natural language\n26\nNatural Language\nInterface\nDBMS\nUser\n(a) A stand-alone software\nUser\nNatural Language\nInterface\nQuery Processor\nDBMS\n(b) A plug-in for DBMS\nFigure 9: The architecture of the database system with NLI\nproblems that are interactively translated into executable language. By submitting the executable language in\nthe corresponding database management system, the query results can be obtained. The paper [78] presents\nthe JavaScript-driven interface of NaLIR, which interacts with a master server implemented in Java. NL2CM\nis implemented in Java 7, whose web user interface is constructed in PHP 5.3 and jQuery 1.x. The paper [62]\ndevelops a web interface designed to receive NLQs from users directed towards academic databases and display\ntranslated SQLs. The interface also shows several example utterances to assist users in comprehending the domain.\nThe tool that comes with the NLMO system is a web application written in Java.\n(ii) A plug-in for the database management system. In this instance, the system exists in a format analogous\nto a Python custom module and interacts with the user through the visual interface of the database management\nsystem. The system architecture is illustrated in Figure 9(b). The user inputs NLQ by invoking the interface\nprovided by the system. Thereafter, the database management system automatically calls the NLI module to\nprocess the NLQ, and displays the translated executable language on the visual interface. One of the most typical\nsystems is NALMO, which is developed on a laptop running Ubuntu 14.04. The final interface form in SECONDO\nis represented as an algebraic module with an operator. The users can use the operator on the moving objects\ndatabases in SECONDO to perform the corresponding NLQ translation of moving objects.\n5.3\nEnhancement of NLIDB systems\nAlthough existing NLIDBs have been able to achieve the transformation from natural language to executable\ndatabase language, the research on NLIDB is a long process and the systems need to be optimized step by step\nbecause natural language has rich expressions, ambiguous semantic knowledge and intricate correlations [61].\nEnhancements to the existing NLIDB systems are mainly in the following three areas: (i) interpreting answers\nand non-answers to queries, (ii) improving the effectiveness of the system, and (iii) securing the system against\npotential vulnerabilities.\n5.3.1\nInterpreting answers and non-answers to queries\nResearchers have enhanced the functionalities of existing systems with regards to providing explanations for both\nquery answers and non-answers. Users of NLIDB do not usually have the relevant expertise and may have diffi-\nculty in understanding the results or verifying their correctness. In this work, papers [31, 32, 33, 34] complement\nthese efforts by providing NL explanations for query answers. The authors propose a system named NLProv,\nwhich employs the original NLQ structure to transform the provenance information into natural language. The\nobtained provenance information is then presented to the user in the form of natural language answers, through a\nfour-step process:\n27\n• The user inputs a query using natural language that is transmitted to the improved NaLIR. The system\nprocesses the NLQ, constructs a formal query, and stores the translated portions of the NLQ in relation to\nthe formal query.\n• NLProv employs the SelP system [36] to evaluate formal queries and records the provenance of each query,\nindicating the correlation between dependency tree nodes and specific provenance sections.\n• The source information is decomposed and then compiled into an NL answer with explanation.\n• The system presents the factorized answer to the user. In cases where the answer is excessively detailed and\ndifficult to comprehend, users have the option to access summaries at various levels of nesting.\nThe paper [34] proposes a general solution for NLProv that is not specific to NaLIR. The core of the solution\nis an alternative architecture that does not depend on the query builder for producing the partial mappings between\nthe nodes of the dependency tree and the components of the query. The architecture provides an additional block\nmapper to NLProv, which receives the dependency tree and generated query as inputs and produces the mapping\nas an output.\nUsers may fail to obtain the expected results when using NLIDBs, leading to surprise or confusion. NL-\nProveNAns [35] enriches NaLIR by supporting interpretations of non-answer. NLProveNAns can provide two\nexplanations, corresponding to two different why-not source models: (i) a concise explanation rooted in the picky\nboundary model and (ii) a comprehensive explanation derived from the polynomial model. NLProveNAns uses\nMySQL as the underlying database system, building upon two earlier system prototypes, specifically NaLIR and\nNLProv. NLProveNAns initially provides the user with a natural language interpretation of the query results and\nthe tuples in the result set generated by NLProv. The user then formulates a “why-not” query. NLProveNAns\nparses the question, computes the answer using the chosen provenance model and the information stored when\ndealing with the original query, and generates a word-highlighted answer.\n5.3.2\nImproving the effectiveness of the system\nNumerous researchers have provided user interaction components for NLIDB systems to improve effectiveness.\nWhen a user submits a question, the system assists the user in formulating an appropriate query by providing a\nlist of available queries and indicating the types of queries. When a user’s question is semantically unclear, the\nappropriate semantic information is identified by presenting the user with a selection of potential interpretations.\nWhen the data inputted by the user is not found in the database, similar information in the database can be\nprovided to the user in the form of an associative prompt. Excessive interactions and limitations not only reduce\nthe efficiency of the translation, but also diminish the overall user satisfaction. Gradually, researchers begin to\nconsider using existing data to improve system effectiveness.\nA key challenge to improving system effectiveness lies in closing the semantic gap between natural language\nand the fundamental data in the database. This challenge is reflected in join path inference and keyword mapping\nwhen converting natural language to SQL. However, there is rarely a large amount of NLQ-SQL pairs available\nfor a given pattern. NLIDB is typically built for existing production databases where large query logs for SQL\nare directly accessible. By analyzing the information in the query logs, NLIDB can identify potential join paths\nand keyword mappings. TEMPLAR [9] augments existing pipeline-based NLIDBs using query log information,\nand the architecture is shown in Figure 10. TEMPLAR models the data from the query log using a data structure\nknown as the Query Fragment Graph (QFG), leveraging the information to enhance the capabilities of current\nNLIDBs in join path inference and keyword mapping. The QFG stores information about the occurrence of query\nfragments in the log, and the symbiotic relationship between every pair of query fragments. Two interfaces exist\nbetween TEMPLAR and NLIDB, one for join path inference and the other for keyword mapping. The experimen-\ntal evaluation in the paper [9] proves the effectiveness of TEMPLAR, which greatly improves the translatability\nof NaLIR and Pipeline by using query logs for SQL.\nTaking the NLQ “Find papers from 2000 until 2010.” from the Microsoft Academic Search database as an\n28\nNLIDB\nNLQ\nSQL\nKeyword Mapper\nJoin Path Generator\nQFG\nQuery Logs\nTEMPLAR\nDatabase\nFigure 10: The architecture of the NLIDB enhanced by TEMPLAR\nexample, the translation process of NaLIR enhanced with TEMPLAR is as follows.\nIn the initial step, the NLQ is parsed using NaLIR to identify the keywords associated with the database\nelements and the relevant parser metadata. In this instance, the keywords identified by NaLIR are papers and from\n2000 until 2010. The result of using NaLIR to generate metadata is papers in the SELECT context and from 2000\nuntil 2010 in the WHERE context.\nIn the second step, the keywords are transmitted to the Keyword Mapper that utilizes the keyword metadata\nand pertinent information from the database to associate each keyword with potential query segments and assign\na score to these segments. In this example, the candidate mappings for papers include (journal.name, SELECT)\nand (publication.title, SELECT), and from 2000 until 2010 is mapped to (publication.year ≥2000 AND publica-\ntion.year ≤2010, WHERE). The Keyword Mapper transmits the two most likely candidate configurations back to\nNaLIR as follows.\n• [(journal.name, SELECT);\n(publication.year >= 2000 AND publication.year <= 2010, WHERE)]\n• [(publication.title, SELECT);\n(publication.year >= 2000 AND publication.year <= 2010, WHERE)]\nIn the third step, NaLIR sends the known relationship of every candidate configuration to the Join Path Gen-\nerator to generate the most probable join path. In this example, the Join Path Generator generates the join paths\njournal-publication and publication for the two configurations, respectively.\nIn the final step, NaLIR utilizes the join paths returned by the Join Path Generator to construct and return the\nSQL for each candidate configuration. In this example, the final translated SQLs are as follows.\n• SELECT j.name FROM journal j, publication p\nWHERE p.year >= 2000 AND p.year <= 2010 AND j.jid = p.jid\n• SELECT title FROM publication WHERE year >= 2000 AND year <= 2010\n5.3.3\nSecuring the system against potential vulnerabilities\nResearch on the security vulnerabilities arising from malicious user interactions is relatively limited. Zhang et al.\n[164] propose a backdoor-based SQL injection framework for Text2SQL systems named TrojanSQL, using two\ninjection attacks: (i) boolean-based and (ii) union-based. Boolean-based injection is used for conditional queries\n29\nwith WHERE clauses and invalidates the original query condition by performing boolean operations on existing\nconditional judgments to bypass the original query condition. Union-based injection aims to steal private informa-\ntion, including database meta-information and user data privacy by performing a union query on the original user\nquery. Experimental results demonstrate that TrojanSQL has a high attack success rate against current Text2SQL\nsystems and is difficult to defend against. Zhang et al. [164] provide security practice recommendations for\nNLIDB developers to reduce the risk of SQL injection attacks:\n• The utilization of only officially recognized or peer-reviewed data sets for model training is recommended.\n• The selection of a verified and reputable source for initializing model weights is advised.\n• The implementation of additional layers of security or filtering should be considered when using model\nlinking techniques.\n• Rigorous testing should be performed prior to the integration of NLIDB APIs provided by third parties into\nan application.\n6\nDiscussions about Text2SQL with LLM, SQL2Text and Speech2SQL\nWe discuss deep language understanding and database interaction techniques related to NLIDB, including the use\nof LLM for Text2SQL tasks, the creation of natural language interpretations from SQL, and the transformation of\nspeech queries into SQL.\n6.1\nText2SQL with LLM\nThe advent of the Transformer architecture [134] has resulted in considerable success of LLMs in natural language\nprocessing tasks. The models effectively capture the deep structure and semantic information of language through\npre-training and fine-tuning [94]. Decoder-only, encoder-only and encoder-decoder are the principal structures of\nLLMs.\n(i) The decoder-only model, represented by GPT [18, 98], exclusively comprises a decoder and generates\noutput sequences progressively through an autoregressive approach. The model is suitable for generative tasks\nsuch as text generation and dialogue systems [110]. However, the model exhibits limited effectiveness when\nprocessing long texts due to the autoregressive nature. Additionally, the model does not directly handle input\ninformation, posing a challenge of unidirectional information transmission.\n(ii) The encoder-only model, represented by BERT [37], contains only an encoder and extracts context through\nbidirectional training. This architecture is applicable to tasks involving context comprehension and supervised\nlearning. Lacking a direct output generation mechanism, the model is unsuitable for generative tasks. In addition,\nthe model cannot handle variable-length outputs in seq2seq tasks.\n(iii) The encoder-decoder model, represented by T5 [111], consists of an encoder and a decoder. The encoder\nmaps the input sequence to a high-dimensional contextual representation, which is then utilized by the decoder\nto produce the output sequence. The architecture excels in tasks requiring global information transfer, such as\nmachine translation and summary generation [76]. However, the computational resource demands of the model\nare high, and the complexity of information transfer may lead to performance degradation in certain tasks.\nLLMs contribute to the development of NLIDB. Notably, the growing popularity of GPT [18, 98] opens new\npossibilities for NLP in NLIDB systems. GPT supports natural language queries over spatial data and returns\nsensible SQL frameworks.\nEXAMPLE 1. Taking the NLQ “Can you tell me what POIs are available in Jiangning District?” as an example,\nthe SQL generated by GPT is as follows.\nSELECT POI.name\nFROM POI JOIN district ON ST Within(POI.geom, district.geom)\n30\nWHERE district.name = ‘Jiangning District’;\nThe query employs the ST Within function to ascertain whether the location of each POI is within Jiangning\nDistrict. GPT extracts the entities (POI and district) and the query type (range query).\nHowever, GPT is primarily designed for traditional relational data and has limited ability to represent spatial\ndata. While adept at processing simple objects(e.g., points), GPT’s representation capabilities are less effective\nwhen dealing with more intricate objects(e.g., lines and regions).\nEXAMPLE 2. Taking the NLQ “What cinemas are there on Sterndamm street?” as an example, the SQL gener-\nated by GPT is as follows.\nSELECT name\nFROM cinemas\nWHERE ST Intersects (location, ST GeomFromText (‘ LINESTRING (13.531836 52.437831, 13.536510\n52.434202 )’, 4326));\nGPT is capable of capturing the pivotal semantic details contained within the query, including cinemas, Stern-\ndamm street and the spatial correlation between them. However, the representation of Sterndamm street in the\nexecutable language is not accurate and Sterndamm street comprises multiple segments. Upon receiving the\nprompt “Sterndamm street is stored in the spatial relation streets”, GPT generates a reasonable SQL:\nSELECT name\nFROM cinemas\nWHERE ST Intersects (location, (SELECT ST Buffer (geom, 0.0001) FROM streets WHERE name =\n‘Sterndamm’));\nThe query utilizes the ST Buffer function to create a buffer with a size of 0.0001 degrees (approximately 11 meters)\naround Sterndamm street and subsequently employs the ST Intersects function to examine whether the location of\neach cinema intersects with the buffer.\nThe advent of intricate deep learning architectures has prompted a focus on accurately interpreting natural\nlanguage and generating structured language by optimizing LLMs. This direction emphasizes optimizing the\nLLM through larger data pre-training, superior language representation learning techniques, and more efficient\nfine-tuning methods. Zero-sample learning strategies have also received attention to enable the system to handle\nunseen query types without retraining, which can be achieved through zero-sample learning and meta-learning\ntechniques.\n6.2\nSQL2Text\nThe purpose of SQL2Text is to transform complex SQL into natural language description. This transformation\nhelps non-technical users to comprehend the logic and structure of SQL, thus making database interactions trans-\nparent and understandable. Koutrika et al. [73] utilize a graph-based approach for transforming SQL into natural\nlanguage. SQL is first represented as a directed graph whose edges are labeled with template labels using an ex-\ntensible template mechanism, thus providing semantics for the parts of the query. These graphs are then explored\nand textual query description is composed using a variety of graph traversal strategies, including the binary search\ntree algorithm, the multi-reference point algorithm, and the template combination algorithm. Eleftherakis et al.\n[40] address SQL2Text by extending the graph-based model of Logos to translate a wider range of queries (e.g.\nSELECT TOP, LIMIT, IN, and LIKE). The SQL is first analyzed to generate a parse tree storing the essential\ninformation utilized to construct the query graph, and then the textual description of the SQL is created through\n31\nthe application of the multi-reference point traversal strategy. Camara et al. [20] employ LLM to generate ex-\nplanations of SQL. The logical structure of SQL is recorded and the columns and tables are interpreted in natural\nlanguage.\nAlthough progress has been made in this direction, there remains ample opportunity for enhancement. Future\nresearch will focus on improving the quality and richness of the generated natural language explanations, ensuring\nthat they are both accurate and rich. In addition, future research will explore context-awareness, which means\nproviding relevant natural language explanations in conjunction with the contextual information in the user’s\nquery. This technique also involves exploring how SQL2Text can be combined with dialogue systems to enable\nintelligent and coherent database interactions.\n6.3\nSpeech2SQL\nSpeech2SQL technology is designed to transform speech input into SQL, making the process of database query-\ning as simple and intuitive as speaking, thus significantly reducing the barrier to database interaction. SpeakQL\n[21, 119, 117, 118] converts speech SQL into queries that are displayed on the screen, where users can perform\ninteractive query corrections using a screen-based touch interface or a single click. SpeakQL utilizes automatic\nspeech recognition (ASR) tools to record speech SQL which will be output as text. The Structure Determination\ncomponent of SpeakQL is responsible for post-processing the ASR results in order to generate syntactically ac-\ncurate SQL with textual placeholders, and then uses the original ASR output to fill in the textual placeholders.\nSpeakNav [165, 12] is a system that combines natural language understanding with route search related to naviga-\ntion. Users are permitted to describe a predetermined route by voice, and SpeakNav presents a suggested path on a\nmap accompanied by information regarding the estimated duration and distance of the journey. MUVE [147, 148]\nconverts NLQs formulated in speech to SQL using a greedy heuristic approach that does not ensure an optimal\nsolution, but produces a solution that is close to optimal. MUVE answers speech queries by utilizing a multi-plot\napproach, including multiple bar graphs that display the outcomes of various query options. SpeechSQLNet [122]\nis an end-to-end neural architecture designed to convert speech into SQL directly, obviating the necessity for an ex-\nternal ASR. SpeechSQLNet effectively combines a transformer, a graphical neural network, and a speech encoder\nas foundational components. The speech encoder is first used to transform speech into a concealed representation,\nand the GNN-based encoder is employed to convert patterns that have a considerable influence on the desired SQL\ninto hidden features to safeguard the structural information. The speech embedding is then combined with pattern\ncharacteristics to generate semantically consistent SQL. Wav2SQL [86] is also an end-to-end Speech2SQL parser\nthat utilizes self-supervised learning to address the challenge of limited data availability and generate diverse rep-\nresentations. Furthermore, speech reprogramming and gradient inversion techniques are introduced to eliminate\nstylistic attributes in the speech representation and enhance the generalization ability of the model to user-defined\ndata. VoiceQuerySystem [123] is a speech-based database query system that generates SQL from NLQ speech\nusing two methods:\n• Cascade approach involves converting speech-based natural language queries to text using a proprietary\nASR module, followed by the generation of SQL through IRNet.\n• End-to-end approach directly converts speech to SQL without the need for text as an intermediate medium,\nby using SpeechSQLNet.\nDespite the considerable efforts invested in speech recognition and interaction technologies, there remain\nsignificant challenges that require further attention. Subsequent research is expected to concentrate on enhancing\nthe accuracy of speech recognition, possibly by utilizing end-to-end speech recognition models and integrating\nmultiple modalities with other input sources. This technique will also involve investigating the potential for\ncombining speech interaction with text query processing techniques to facilitate seamless and efficient database\ninteraction.\n32\n7\nFuture research and conclusions\nWe investigate unresolved issues and potential directions for future research in the area of NLIDB and provide the\nconclusions of this paper.\n7.1\nOpen problems\nDespite the considerable advancements made by NLIDB, numerous challenges and issues remain to be addressed.\nThe following is a list of the principal open problems with the technical details.\nNatural language disambiguation. The ambiguity and polysemous nature of natural language makes NLIDB\nsystems face great challenges in correctly understanding user intentions. Future research should focus on the\nfollowing aspects.\n(i) Contextual understanding. Advanced context-aware models can be developed to utilize contextual infor-\nmation for disambiguation. Attention mechanisms and memory networks allow to keep track of the context in a\ndialogue system.\n(ii) Multi-round dialogue. Introducing multiple rounds of dialogue enables the system to gradually clarify\nusers’ intent through a series of interactions, which requires the design of an effective dialogue management\nstrategy and a mechanism for confirming users’ intent.\n(iii) Semantic parsing. Complex semantic parsing techniques, such as semantic role labeling and knowledge\ngraph, can be utilized to elucidate the implicit information in natural language.\nQuery optimization. Converting natural language queries into efficient database queries and optimizing query\nperformance during execution remain significant challenges. The key issues and research directions for query\noptimization are presented below.\n(i) Index Selection. Depending on the query criteria and data distribution, the indexing scheme that optimizes\nretrieval speed is selected. The optimizer scans the existing indexes, evaluates the selectivity and cost of each\nindex, and determines which indexes filter the data most efficiently. In complex queries, multiple indexes may be\nused simultaneously, and the optimizer will select a union index or cross-index scan to improve query performance.\n(ii) Query rewriting is a method of simplifying the execution plan and improving query efficiency. Sub-queries\ncan be reformulated as joins to simplify complex nested queries. Additionally, the value of constant expressions\ncan be computed in advance in the query, reducing the runtime computation. Finally, redundant sorting, joining,\nor filtering operations can be removed from the query to simplify the query execution plan.\n(iii) Execution plan selection. The cost of each execution plan is evaluated using statistical information (e.g.,\ntable size and index distribution) and a cost model (rule-based or cost-based). This evaluation considers I/O opera-\ntions, CPU time, and memory utilization. The least costly plan can be identified through dynamic programming or\nheuristic algorithms, thereby ensuring that the query is executed with minimal resource consumption and optimal\nperformance.\n(iv) Join optimization. The join operation is a highly resource-consuming process, and determining the most\nefficient join order and method is critical. The selection of suitable join algorithms (e.g., subsumption joins, hash\njoins and nested loop joins) and the application of join condition derivation can lead to a reduction in the quantity\nof join operations, thus optimizing join performance and improving query efficiency.\nCorpus construction. One of the most pressing issues in the research of NLIDB is the construction and\nutilization of the corpus, with particular focus on the following aspects.\n(i) In order to guarantee the generality and adaptability of the natural language interface system, one needs to\ncollect data from diverse sources. Multi-source data integration techniques can be employed to gather information\nfrom user query logs, social media conversations, and customer service records to ensure that the corpus is diverse\nand representative.\n33\n(ii) A high-quality corpus relies on accurate annotation, which requires the integration of manual and auto-\nmated tools. The development of collaborative annotation platforms and automated annotation tools can enhance\nthe efficiency and uniformity of annotation, concurrently establishing a quality assessment system to detect and\nrectify annotation errors, thus ensuring the accuracy and reliability of data annotation.\n(iii) Protecting user privacy and data security is of paramount importance when constructing and utilizing the\ncorpus. The application of differential privacy and data encryption techniques, in conjunction with the formulation\nof guidelines for the ethical use of data, can guarantee legality and compliance in the process of data collection\nand utilization. Transparency and user control techniques enable users to understand and regulate the usage of\ndata.\n(iv) The construction and evaluation of the corpus necessitate a unified and standardized framework to facil-\nitate the comparison of research results and the sharing of data. The establishment of open data platforms and\nthe promotion of cross-institutional cooperation can address legal and technical challenges in data sharing and\npromote the sharing and reuse of resources and results.\n7.2\nConclusions\nThis paper offers a comprehensive review of recently proposed NLIDBs. We summarize the translation process\nfrom natural language to database executable language in three stages: (i) natural language preprocessing, (ii)\nnatural language understanding, and (iii) natural language translation. At the natural language preprocessing\nstage, we observe that almost every system employs named entity recognition and part-of-speech tagging. At\nthe natural language understanding stage, we learn that although the limitations of rule-based approaches can be\neliminated, machine learning-based semantic parsing methods are highly dependent on training data and require\nlonger time and more memory space to build models. At the natural language translation stage, we provide a\ngeneral process for building executable languages over relational and spatio-temporal databases. Furthermore,\nwe provide a summary of the common benchmarks for translating natural language queries into executable lan-\nguages, system evaluation metrics, and the classification, development, and enhancement of NLIDBs. Despite the\npotential to enhance database accessibility, NLIDB still faces numerous challenges, including natural language\ndisambiguation, query optimization, and corpus construction. Future research should prioritize addressing the\nopen issues to further improve the effectiveness and user satisfaction of NLIDB systems.\nReferences\n[1] Asma Ben Abacha and Pierre Zweigenbaum. MEANS: A medical question-answering system combining\nNLP techniques and semantic web technologies. Inf. Process. Manag., 51(5):570–594, 2015.\n[2] Katrin Affolter, Kurt Stockinger, and Abraham Bernstein. A comparative survey of recent natural language\ninterfaces for databases. VLDB J., 28(5):793–819, 2019.\n[3] Karam Ahkouk and Mustapha Machkour. Towards an interface for translating natural language questions to\nSQL: a conceptual framework from a systematic review. Int. J. Reason. based Intell. Syst., 12(4):264–275,\n2020.\n[4] Muhammed Jassem Al-Muhammed and Deryle W. Lonsdale. Ontology-aware dynamically adaptable free-\nform natural language agent interface for querying databases. Knowl. Based Syst., 239:108012, 2022.\n[5] Yael Amsterdamer, Anna Kukliansky, and Tova Milo. A natural language interface for querying general\nand individual knowledge. Proc. VLDB Endow., 8(12):1430–1441, 2015.\n[6] Yael Amsterdamer, Anna Kukliansky, and Tova Milo.\nNl2cm: A natural language interface to crowd\nmining. In SIGMOD, pages 1433–1438, 2015.\n[7] Ion Androutsopoulos, Graeme D. Ritchie, and Peter Thanisch. Natural language interfaces to databases -\nan introduction. Nat. Lang. Eng., 1(1):29–81, 1995.\n34\n[8] Yoav Artzi and Luke S. Zettlemoyer. Bootstrapping semantic parsers from conversations. In EMNLP, pages\n421–432, 2011.\n[9] Christopher Baik, H. V. Jagadish, and Yunyao Li. Bridging the semantic gap with SQL query logs in natural\nlanguage interfaces to databases. In IEEE ICDE, pages 374–385, 2019.\n[10] Fuat Basik, Benjamin H¨attasch, Amir Ilkhechi, Arif Usta, Shekar Ramaswamy, Prasetya Utama, Nathaniel\nWeir, Carsten Binnig, and Ugur C¸ etintemel. Dbpal: A learned nl-interface for databases. In SIGMOD,\npages 1765–1768, 2018.\n[11] Adithya Bhaskar, Tushar Tomar, Ashutosh Sathe, and Sunita Sarawagi. Benchmarking and improving\ntext-to-sql generation under ambiguity. In EMNLP, pages 7053–7074, 2023.\n[12] Lei Bi, Juan Cao, Guohui Li, Nguyen Quoc Viet Hung, Christian S. Jensen, and Bolong Zheng. Speaknav:\nA voice-based navigation system via route description language understanding. In ICDE, pages 2669–2672,\n2021.\n[13] Steven Bird. NLTK: the natural language toolkit. In ACL, 2006.\n[14] Adrian N. Bishop, Jeremie Houssineau, Daniel Angley, and Branko Ristic. Spatio-temporal tracking from\nnatural language statements using outer probability theory. Inf. Sci., 463-464:56–74, 2018.\n[15] Lukas Blunschi, Claudio Jossen, Donald Kossmann, Magdalini Mori, and Kurt Stockinger. SODA: gener-\nating SQL for business users. Proc. VLDB Endow., 5(10):932–943, 2012.\n[16] Joel Booth, Barbara Di Eugenio, Isabel F. Cruz, and Ouri Wolfson. Robust natural language processing for\nurban trip planning. Appl. Artif. Intell., 29(9):859–903, 2015.\n[17] Joel Booth, A. Prasad Sistla, Ouri Wolfson, and Isabel F. Cruz. A data model for trip planning in multimodal\ntransportation systems. In EDBT, volume 360 of ACM International Conference Proceeding Series, pages\n994–1005, 2009.\n[18] Tom B. Brown, Benjamin Mann, Nick Ryder, and et al. Language models are few-shot learners. Advances\nin neural information processing systems, 33:1877–1901, 2020.\n[19] Ursin Brunner and Kurt Stockinger. Valuenet: A natural language-to-sql system that learns from database\ninformation. In ICDE, pages 2177–2182, 2021.\n[20] Vanessa Cˆamara, Rayol Mendonca-Neto, Andr´e Silva, and Luiz Cordovil Jr.\nA large language model\napproach to sql-to-text generation. In ICCE, pages 1–4, 2024.\n[21] Dharmil Chandarana, Vraj Shah, Arun Kumar, and Lawrence K. Saul. Speakql: Towards speech-driven\nmulti-modal querying. In HILDA@SIGMOD, pages 11:1–11:6, 2017.\n[22] Chih-Yung Chang, Yuan-Lin Liang, Shih-Jung Wu, and Diptendu Sinha Roy. Sv2-sql: a text-to-sql trans-\nformation mechanism based on BERT models for slot filling, value extraction, and verification. Multim.\nSyst., 30(1):16, 2024.\n[23] Peng Chen, Hui Li, Sourav S. Bhowmick, Shafiq R. Joty, and Weiguo Wang.\nLANTERN: boredom-\nconscious natural language description generation of query execution plans for database education. In\nSIGMOD, pages 2413–2416, 2022.\n[24] Yi-Hui Chen, Eric Jui-Lin Lu, and Ting-An Ou. Intelligent SPARQL query generation for natural language\nprocessing systems. IEEE Access, 9:158638–158650, 2021.\n[25] Jianpeng Cheng, Siva Reddy, Vijay A. Saraswat, and Mirella Lapata. Learning structured natural language\nrepresentations for semantic parsing. In ACL, pages 44–55, 2017.\n[26] Danica Damljanovic, Milan Agatonovic, and Hamish Cunningham. Freya: An interactive way of querying\nlinked data using natural language. In ESWC, volume 7117 of Lecture Notes in Computer Science, pages\n125–138, 2011.\n[27] Danica Damljanovic, Valentin Tablan, and Kalina Bontcheva. A text-based query interface to OWL ontolo-\ngies. In LREC, 2008.\n35\n[28] Alaka Das and Rakesh Chandra Balabantaray. Mynlidb: A natural language interface to database. In ICIT,\npages 234–238, 2019.\n[29] C. J. Date. A critique of the SQL database language. SIGMOD Rec., 14(3):8–54, 1984.\n[30] Ephrem Tadesse Degu and Rosa Tsegaye Aga. Natural language interface for covid-19 amharic database\nusing LSTM encoder decoder architecture with attention. In ICT4DA, pages 95–100, 2021.\n[31] Daniel Deutch, Nave Frost, and Amir Gilad. Nlprov: Natural language provenance. Proc. VLDB Endow.,\n9(13):1537–1540, 2016.\n[32] Daniel Deutch, Nave Frost, and Amir Gilad. Provenance for natural language queries. Proc. VLDB Endow.,\n10(5):577–588, 2017.\n[33] Daniel Deutch, Nave Frost, and Amir Gilad. Natural language explanations for query results. SIGMOD\nRec., 47(1):42–49, 2018.\n[34] Daniel Deutch, Nave Frost, and Amir Gilad.\nExplaining natural language query results.\nVLDB J.,\n29(1):485–508, 2020.\n[35] Daniel Deutch, Nave Frost, Amir Gilad, and Tomer Haimovich. Nlprovenans: Natural language provenance\nfor non-answers. Proc. VLDB Endow., 11(12):1986–1989, 2018.\n[36] Daniel Deutch, Amir Gilad, and Yuval Moskovitch. Selective provenance for datalog programs using top-k\nqueries. Proc. VLDB Endow., 8(12):1394–1405, 2015.\n[37] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirec-\ntional transformers for language understanding. In NAACL-HLT, pages 4171–4186, 2019.\n[38] Li Dong and Mirella Lapata. Language to logical form with neural attention. In ACL, 2016.\n[39] Li Dong and Mirella Lapata. Coarse-to-fine decoding for neural semantic parsing. In ACL, pages 731–742,\n2018.\n[40] Stavroula Eleftherakis, Orest Gkini, and Georgia Koutrika. Let the database talk back: Natural language\nexplanations for SQL. In SEA-Data, volume 2929 of CEUR Workshop Proceedings, pages 14–19, 2021.\n[41] Tatiana N. Erekhinskaya, Dmitriy Strebkov, Sujal Patel, Mithun Balakrishna, Marta Tatu, and Dan I.\nMoldovan. Ten ways of leveraging ontologies for natural language processing and its enterprise appli-\ncations. In SBD@SIGMOD, pages 8:1–8:6, 2020.\n[42] Yuankai Fan, Zhenying He, Tonghui Ren, Dianjun Guo, Lin Chen, Ruisi Zhu, Guanduo Chen, Yinan Jing,\nKai Zhang, and X. Sean Wang. Gar: A generate-and-rank approach for natural language to SQL translation.\nIn ICDE, pages 110–122, 2023.\n[43] Yuankai Fan, Tonghui Ren, Dianjun Guo, Zhigang Zhao, Zhenying He, X. Sean Wang, Yu Wang, and Tao\nSui. An integrated interactive framework for natural language to SQL translation. In WISE, volume 14306\nof Lecture Notes in Computer Science, pages 643–658, 2023.\n[44] Yuankai Fan, Tonghui Ren, Zhenying He, X. Sean Wang, Ye Zhang, and Xingang Li. Gensql: A generative\nnatural language interface to database systems. In ICDE, pages 3603–3606, 2023.\n[45] Alessandro Fantechi, Stefania Gnesi, Samuele Livi, and Laura Semini. A spacy-based tool for extracting\nvariability from NL requirements. In SPLC, pages 32–35, 2021.\n[46] S´ebastien Ferr´e. Sparklis: An expressive query builder for SPARQL endpoints with guidance in natural\nlanguage. Semantic Web, 8(3):405–418, 2017.\n[47] Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui\nZhang, and Dragomir R. Radev. Improving text-to-sql evaluation methodology. In ACL, pages 351–360,\n2018.\n[48] Han Fu, Chang Liu, Bin Wu, Feifei Li, Jian Tan, and Jianling Sun. Catsql: Towards real world natural\nlanguage to SQL applications. Proc. VLDB Endow., 16(6):1534–1547, 2023.\n36\n[49] Kaitlyn Fulford and Aspen Olmsted. Mobile natural language database interface for accessing relational\ndata. In i-Society, pages 86–87, 2017.\n[50] Yujian Gan, Xinyun Chen, Jinxia Xie, Matthew Purver, John R. Woodward, John H. Drake, and Qiaofu\nZhang. Natural SQL: making SQL easier to infer from natural language specifications. In EMNLP, pages\n2030–2042, 2021.\n[51] Robert Giaquinto, Dejiao Zhang, Benjamin Kleiner, Yang Li, Ming Tan, Parminder Bhatia, Ramesh Nalla-\npati, and Xiaofei Ma. Multitask pretraining with structured knowledge for text-to-sql generation. In ACL,\npages 11067–11083, 2023.\n[52] Alessandra Giordani and Alessandro Moschitti.\nTranslating questions to SQL queries with generative\nparsers discriminatively reranked. In COLING, pages 401–410, 2012.\n[53] Jiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao, Jian-Guang Lou, Ting Liu, and Dongmei Zhang. Towards\ncomplex text-to-sql in cross-domain database with intermediate representation. In ACL, pages 4524–4535,\n2019.\n[54] Izzeddin Gur, Semih Yavuz, Yu Su, and Xifeng Yan. Dialsql: Dialogue based structured query generation.\nIn ACL, pages 1339–1349, 2018.\n[55] Ralf Hartmut G¨uting. An introduction to spatial database systems. VLDB J., 3(4):357–399, 1994.\n[56] Ralf Hartmut G¨uting, Thomas Behr, and Christian D¨untgen. SECONDO: A platform for moving objects\ndatabase research and for publishing and integrating research implementations. IEEE Data Eng. Bull.,\n33(2):56–63, 2010.\n[57] Ditiman Hazarika, Gopal Konwar, Shuvam Deb, and Dibya Jyoti Bora. Sentiment analysis on twitter by\nusing textblob for natural language processing. In ICRMAT, volume 24 of Annals of Computer Science and\nInformation Systems, pages 63–67, 2020.\n[58] Jos´e Henarejos-Blasco, Jos´e Antonio Garc´ıa-D´ıaz, ´Oscar Apolinario-Arzube, and Rafael Valencia-Garc´ıa.\nCnl-rdf-query: a controlled natural language interface for querying ontologies and relational databases. In\nEATIS, pages 35:1–35:5, 2020.\n[59] Yiqun Hu, Yiyun Zhao, Jiarong Jiang, Wuwei Lan, Henghui Zhu, Anuj Chauhan, Alexander Hanbo Li,\nLin Pan, Jun Wang, Chung-Wei Hang, Sheng Zhang, Jiang Guo, Mingwen Dong, Joseph Lilien, Patrick\nNg, Zhiguo Wang, Vittorio Castelli, and Bing Xiang. Importance of synthesizing high-quality data for\ntext-to-sql parsing. In ACL, pages 1327–1343, 2023.\n[60] Ruizhe Huang and Lei Zou. Natural language question answering over RDF data. In SIGMOD, pages\n1289–1290, 2013.\n[61] Zachary G. Ives. Technical perspective: : Natural language explanations for query results. SIGMOD Rec.,\n47(1):41, 2018.\n[62] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy, and Luke Zettlemoyer. Learning a\nneural semantic parser from user feedback. In ACL, pages 963–973, 2017.\n[63] Manasa Jammi, Jaydeep Sen, Ashish R. Mittal, Sagar Verma, Vardaan Pahuja, Rema Ananthanarayanan,\nPranay Lohia, Hima Karanam, Diptikalyan Saha, and Karthik Sankaranarayanan. Tooling framework for\ninstantiating natural language querying system. Proc. VLDB Endow., 11(12):2014–2017, 2018.\n[64] Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Str¨otgen, and Gerhard Weikum. TEQUILA:\ntemporal question answering over knowledge bases. In CIKM, pages 1807–1810, 2018.\n[65] Jiffy Joseph, Janu R Panicker, and Meera M. An efficient natural language interface to xml database. In\nICIS, pages 207–212, 2016.\n[66] Aishwarya Kamath and Rajarshi Das. A survey on semantic parsing. In AKBC, 2019.\n[67] Ronak Kaoshik, Rohit Patil, Prakash R, Shaurya Agarawal, Naman Jain, and Mayank Singh. ACL-SQL:\ngenerating SQL queries from natural language. In CODS-COMAD, page 423, 2021.\n37\n[68] George Katsogiannis-Meimarakis and Georgia Koutrika. A survey on deep learning approaches for text-to-\nsql. VLDB J., 32(4):905–936, 2023.\n[69] Esther Kaufmann, Abraham Bernstein, and Renato Zumstein. Querix: A natural language interface to query\nontologies based on clarification dialogs. In ISWC, 2006.\n[70] Hyeonji Kim, Byeong-Hoon So, Wook-Shin Han, and Hongrae Lee. Natural language to SQL: where are\nwe today? Proc. VLDB Endow., 13(10):1737–1750, 2020.\n[71] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n[72] Georgia Koutrika. Natural language data interfaces: A data access odyssey (invited talk). In ICDT, volume\n290 of LIPIcs, pages 1:1–1:22, 2024.\n[73] Georgia Koutrika, Alkis Simitsis, and Yannis E. Ioannidis. Explaining structured queries in natural lan-\nguage. In ICDE, pages 333–344, 2010.\n[74] Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner. Neural semantic parsing with type constraints\nfor semi-structured tables. In EMNLP, pages 1516–1526, 2017.\n[75] Claude Lehmann, Dennis Gehrig, Stefan Holdener, Carlo Saladin, Jo˜ao Pedro Monteiro, and Kurt\nStockinger. Building natural language interfaces for databases in practice. In SSDBM, pages 20:1–20:4,\n2022.\n[76] Mike Lewis, Yinhan Liu, Naman Goyal, and et al. BART: denoising sequence-to-sequence pre-training for\nnatural language generation, translation, and comprehension. In ACL, pages 7871–7880, 2020.\n[77] Fei Li and H. V. Jagadish. Constructing an interactive natural language interface for relational databases.\nProc. VLDB Endow., 8(1):73–84, 2014.\n[78] Fei Li and H. V. Jagadish. Nalir: an interactive natural language interface for querying relational databases.\nIn SIGMOD, pages 709–712, 2014.\n[79] Fei Li and H. V. Jagadish. Understanding natural language queries over relational databases. SIGMOD\nRec., 45(1):6–13, 2016.\n[80] Jingjing Li, Wenlu Wang, Wei-Shinn Ku, Yingtao Tian, and Haixun Wang. Spatialnli: A spatial domain\nnatural language interface to databases using spatial comprehension. In ACM SIGSPATIAL, pages 339–348,\n2019.\n[81] Yunyao Li, Ishan Chaudhuri, Huahai Yang, Satinder Singh, and H. V. Jagadish. Danalix: a domain-adaptive\nnatural language interface for querying XML. In SIGMOD, pages 1165–1168, 2007.\n[82] Yunyao Li and Davood Rafiei. Natural language data management and interfaces: Recent development and\nopen challenges. In ACM SIGMOD, pages 1765–1770, 2017.\n[83] Yunyao Li and Davood Rafiei. Natural Language Data Management and Interfaces. Synthesis Lectures on\nData Management. 2018.\n[84] Yunyao Li, Huahai Yang, and H. V. Jagadish. Nalix: an interactive natural language interface for querying\nXML. In SIGMOD, pages 900–902, 2005.\n[85] Yunyao Li, Huahai Yang, and H. V. Jagadish. Nalix: A generic natural language search environment for\nXML data. ACM Trans. Database Syst., 32(4):30, 2007.\n[86] Huadai Liu, Rongjie Huang, Jinzheng He, Gang Sun, Ran Shen, Xize Cheng, and Zhou Zhao. Wav2sql:\nDirect generalizable speech-to-sql parsing. CoRR, abs/2305.12552, 2023.\n[87] Jian Liu, Qian Cui, Hongwei Cao, Tianyuan Shi, and Min Zhou. Auto-conversion from natural language to\nstructured query language using neural networks embedded with pre-training and fine-tuning mechanism.\nIn CAC, pages 6651–6654, 2020.\n[88] Mengyi Liu, Xieyang Wang, and Jianqiu Xu. NALSD: A natural language interface for spatial databases.\nIn SSTD, pages 175–179, 2023.\n38\n[89] Mengyi Liu, Xieyang Wang, Jianqiu Xu, and Hua Lu. Nalspatial: An effective natural language transfor-\nmation framework for queries over spatial data. In SIGSPATIAL/GIS, pages 57:1–57:4, 2023.\n[90] Yuyu Luo, Nan Tang, Guoliang Li, Chengliang Chai, Wenbo Li, and Xuedi Qin. Synthesizing natural\nlanguage to visualization (NL2VIS) benchmarks from NL2SQL benchmarks. In SIGMOD, pages 1235–\n1247, 2021.\n[91] Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel, Steven Bethard, and David\nMcClosky. The stanford corenlp natural language processing toolkit. In ACL, pages 55–60, 2014.\n[92] Youssef Mellah, Abdelkader Rhouati, El Hassane Ettifouri, Toumi Bouchentouf, and Mohammed Ghaouth\nBelkasmi. COMBINE: A pipeline for SQL generation from natural language. In ICACDS, volume 1441 of\nCommunications in Computer and Information Science, pages 97–106, 2021.\n[93] Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Distributed representa-\ntions of words and phrases and their compositionality. In NIPS, pages 3111–3119, 2013.\n[94] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko\nAgirre, Ilana Heintz, and Dan Roth. Recent advances in natural language processing via large pre-trained\nlanguage models: A survey. ACM Comput. Surv., 56(2):30:1–30:40, 2024.\n[95] Mohamed F. Mokbel, Mahmoud Attia Sakr, Li Xiong, Andreas Z¨ufle, and et al. Mobility data science\n(dagstuhl seminar 22021). Dagstuhl Reports, 12(1):1–34, 2022.\n[96] Kevin Mote. Natural language processing - A survey. CoRR, abs/1209.6238, 2012.\n[97] Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung Tae, Ellen Zhang, Arman Cohan, and\nDragomir Radev. Enhancing text-to-sql capabilities of large language models: A study on prompt design\nstrategies. In EMNLP, pages 14935–14956, 2023.\n[98] Long Ouyang, Jeffrey Wu, Xu Jiang, and et al. Training language models to follow instructions with human\nfeedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.\n[99] Fatma Ozcan, Abdul Quamar, Jaydeep Sen, Chuan Lei, and Vasilis Efthymiou. State of the art and open\nchallenges in natural language interfaces to data. In SIGMOD, pages 2629–2636, 2020.\n[100] Parth Parikh, Oishik Chatterjee, Muskan Jain, Aman Harsh, Gaurav Shahani, Rathin Biswas, and Kavi\nArya. Auto-query - A simple natural language to SQL query generator for an e-learning platform. In\nEDUCON, pages 936–940, 2022.\n[101] Bijan Parsia. Querying the web with SPARQL. In Reasoning Web, volume 4126 of Lecture Notes in\nComputer Science, pages 53–67, 2006.\n[102] Panupong Pasupat and Percy Liang. Compositional semantic parsing on semi-structured tables. In ACL,\npages 1470–1480, 2015.\n[103] Rodolfo A. Pazos, Jos´e A. Mart´ınez F., Juan Javier Gonz´alez Barbosa, and Andr´es A. Ver´astegui O. Al-\ngorithm for processing queries that involve boolean columns for a natural language interface to databases.\nComputaci´on y Sistemas, 24(1), 2020.\n[104] Rodolfo A. Pazos, Jos´e A. Mart´ınez F., and Alan G. Aguirre L. Processing natural language queries via a\nnatural language interface to databases with design anomalies. Polibits, 62:43–50, 2020.\n[105] Hoifung Poon and Pedro M. Domingos. Unsupervised semantic parsing. In EMNLP, pages 1–10, 2009.\n[106] Ana-Maria Popescu, Alex Armanasu, Oren Etzioni, David Ko, and Alexander Yates. Modern natural lan-\nguage interfaces to databases: Composing statistical parsing with semantic tractability. In COLING, 2004.\n[107] Ana-Maria Popescu, Oren Etzioni, and Henry A. Kautz. Towards a theory of natural language interfaces to\ndatabases. In IUI, pages 149–157, 2003.\n[108] Patti J. Price. Evaluation of spoken language systems: the ATIS domain. In Speech and Natural Language,\npages 91–95, 1990.\n39\n[109] Qinjun Qiu, Zhong Xie, Kai Ma, Liufeng Tao, and Shiyu Zheng. Neurospe: A neuro-net spatial relation\nextractor for natural language text fusing gazetteers and pretrained models. Trans. GIS, 27(5):1526–1549,\n2023.\n[110] Xipeng Qiu, Tianxiang Sun, Yige Xu, and et al. Pre-trained models for natural language processing: A\nsurvey. Sci. China Technol. Sci., 63(10):1872–1897, 2020.\n[111] Colin Raffel, Noam Shazeer, Adam Roberts, and et al. Exploring the limits of transfer learning with a\nunified text-to-text transformer. J. Mach. Learn. Res., 21:140:1–140:67, 2020.\n[112] Ohad Rubin and Jonathan Berant. Smbop: Semi-autoregressive bottom-up semantic parsing. In NAACL-\nHLT, pages 311–324, 2021.\n[113] Diptikalyan Saha, Avrilia Floratou, Karthik Sankaranarayanan, Umar Farooq Minhas, Ashish R. Mittal,\nand Fatma ¨Ozcan. ATHENA: an ontology-driven system for natural language querying over relational data\nstores. Proc. VLDB Endow., 9(12):1209–1220, 2016.\n[114] Xavier Schmitt, Sylvain Kubler, J´er´emy Robert, Mike Papadakis, and Yves Le Traon. A replicable com-\nparison study of NER software: Stanfordnlp, nltk, opennlp, spacy, gate. In SNAMS, pages 338–343, 2019.\n[115] Jaydeep Sen, Chuan Lei, Abdul Quamar, Fatma ¨Ozcan, Vasilis Efthymiou, Ayushi Dalmia, Greg Stager,\nAshish R. Mittal, Diptikalyan Saha, and Karthik Sankaranarayanan. ATHENA++: natural language query-\ning for complex nested SQL queries. Proc. VLDB Endow., 13(11):2747–2759, 2020.\n[116] Jaydeep Sen, Fatma Ozcan, Abdul Quamar, Greg Stager, Ashish R. Mittal, Manasa Jammi, Chuan Lei, Dip-\ntikalyan Saha, and Karthik Sankaranarayanan. Natural language querying of complex business intelligence\nqueries. In SIGMOD, pages 1997–2000, 2019.\n[117] Vraj Shah. Speakql: Towards speech-driven multimodal querying. In SIGMOD, pages 1847–1849, 2019.\n[118] Vraj Shah, Side Li, Arun Kumar, and Lawrence K. Saul. Speakql: Towards speech-driven multimodal\nquerying of structured data. In SIGMOD, pages 2363–2374, 2020.\n[119] Vraj Shah, Side Li, Kevin Yang, Arun Kumar, and Lawrence K. Saul. Demonstration of speakql: Speech-\ndriven multimodal querying of structured data. In SIGMOD, pages 2001–2004, 2019.\n[120] Grigori Sidorov, Rodolfo A. Pazos Rangel, Jos´e A. Mart´ınez F., Juan Mart´ın Carpio, and Alan G. Aguirre\nL. Configuration module for treating design anomalies in databases for a natural language interface to\ndatabases. In Intuitionistic and Type-2 Fuzzy Logic Enhancements in Neural and Optimization Algorithms,\nvolume 862 of Studies in Computational Intelligence, pages 703–714. 2020.\n[121] Dezhao Song, Frank Schilder, Charese Smiley, Chris Brew, Tom Zielund, Hiroko Bretz, Robert Martin,\nChris Dale, John Duprey, Tim Miller, and Johanna Harrison. TR discover: A natural language interface for\nquerying and analyzing interlinked datasets. In ISWC, pages 21–37, 2015.\n[122] Yuanfeng Song, Raymond Chi-Wing Wong, Xuefang Zhao, and Di Jiang. Speech-to-sql: Towards speech-\ndriven SQL query generation from natural language question. CoRR, abs/2201.01209, 2022.\n[123] Yuanfeng Song, Raymond Chi-Wing Wong, Xuefang Zhao, and Di Jiang. Voicequerysystem: A voice-\ndriven database querying system using natural language questions. In SIGMOD, pages 2385–2388, 2022.\n[124] Niculae Stratica, Leila Kosseim, and Bipin C. Desai. Using semantic templates for a natural language\ninterface to the CINDI virtual library. Data Knowl. Eng., 55(1):4–19, 2005.\n[125] Shuo Sun, Yuze Gao, Yuchen Zhang, Jian Su, Bin Chen, Yingzhan Lin, and Shuqi Sun. An exploratory\nstudy on model compression for text-to-sql. In ACL, pages 11647–11654, 2023.\n[126] Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao, Donovan Ong, Bin Chen, and Jian Su. Battle of the\nlarge language models: Dolly vs llama vs vicuna vs guanaco vs bard vs chatgpt - A text-to-sql parsing\ncomparison. In EMNLP, pages 11225–11238, 2023.\n[127] Lappoon R. Tang and Raymond J. Mooney. Automated construction of database interfaces: Intergrating\nstatistical and relational learning for semantic parsing. In EMNLP, pages 133–141, 2000.\n40\n[128] Lappoon R. Tang and Raymond J. Mooney. Using multiple clause constructors in inductive logic program-\nming for semantic parsing. In EMCL, volume 2167 of Lecture Notes in Computer Science, pages 466–477,\n2001.\n[129] Peihao Tong, Qifan Zhang, and Junjie Yao. Leveraging domain context for question answering over knowl-\nedge graph. Data Sci. Eng., 4(4):323–335, 2019.\n[130] Immanuel Trummer. Database tuning using natural language processing. SIGMOD Rec., 50(3):27–28,\n2021.\n[131] Arif Usta, Akifhan Karakayali, and ¨Ozg¨ur Ulusoy. Dbtagger: Multi-task learning for keyword mapping in\nnlidbs using bi-directional recurrent neural networks. Proc. VLDB Endow., 14(5):813–821, 2021.\n[132] Arif Usta, Akifhan Karakayali, and ¨Ozg¨ur Ulusoy. xdbtagger: explainable natural language interface to\ndatabases using keyword mappings and schema graph. VLDB J., 33(2):301–321, 2024.\n[133] Prasetya Utama, Nathaniel Weir, Fuat Basik, Carsten Binnig, Ugur C¸ etintemel, Benjamin H¨attasch, Amir\nIlkhechi, Shekar Ramaswamy, and Arif Usta. An end-to-end neural natural language interface for databases.\nCoRR, abs/1804.00401, 2018.\n[134] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. Attention is all you need. In NIPS, pages 5998–6008, 2017.\n[135] Moses Visperas, Aunhel John Adoptante, Christalline Joie Borjal, Ma. Teresita Abia, Jasper Kyle Catapang,\nand Elmer C. Peramo. On modern text-to-sql semantic parsing methodologies for natural language interface\nto databases: A comparative study. In ICAIIC, pages 390–396, 2023.\n[136] Ngoc Phuoc An Vo, Octavian Popescu, Irene Manotas, and Vadim Sheinin. Tackling temporal questions in\nnatural language interface to databases. In EMNLP, pages 179–187, 2022.\n[137] Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson.\nRAT-SQL:\nrelation-aware schema encoding and linking for text-to-sql parsers. In ACL, pages 7567–7578, 2020.\n[138] Runze Wang, Zhen-Hua Ling, Jing-Bo Zhou, and Yu Hu. A multiple-integration encoder for multi-turn\ntext-to-sql semantic parsing. IEEE ACM Trans. Audio Speech Lang. Process., 29:1503–1513, 2021.\n[139] Weiguo Wang, Sourav S. Bhowmick, Hui Li, Shafiq R. Joty, Siyuan Liu, and Peng Chen. Towards en-\nhancing database education: Natural language generation meets query execution plans. In SIGMOD, pages\n1933–1945, 2021.\n[140] Wenlu Wang. A cross-domain natural language interface to databases using adversarial text method. In\nVLDB, volume 2399 of CEUR Workshop Proceedings. CEUR-WS.org, 2019.\n[141] Wenlu Wang, Jingjing Li, Wei-Shinn Ku, and Haixun Wang. Multilingual spatial domain natural language\ninterface to databases. GeoInformatica, 28(1):29–52, 2024.\n[142] Wenlu Wang, Yingtao Tian, Haixun Wang, and Wei-Shinn Ku. A natural language interface for database:\nAchieving transfer-learnability using adversarial method for question understanding. In ICDE, pages 97–\n108, 2020.\n[143] Xieyang Wang, Mengyi Liu, Jianqiu Xu, and Hua Lu. NALMO: transforming queries in natural language\nfor moving objects databases. GeoInformatica, 27(3):427–460, 2023.\n[144] Xieyang Wang, Jianqiu Xu, and Hua Lu.\nNALMO: A natural language interface for moving objects\ndatabases. In SSTD, pages 1–11, 2021.\n[145] Xieyang Wang, Jianqiu Xu, and Yaxin Wang. NLMO: towards a natural language tool for querying moving\nobjects. In MDM, pages 228–229, 2020.\n[146] Yushi Wang, Jonathan Berant, and Percy Liang. Building a semantic parser overnight. In ACL, pages\n1332–1342, 2015.\n[147] Ziyun Wei, Immanuel Trummer, and Connor Anderson. Demonstrating robust voice querying with MUVE:\noptimally visualizing results of phonetically similar queries. In SIGMOD, pages 2798–2802, 2021.\n41\n[148] Ziyun Wei, Immanuel Trummer, and Connor Anderson. Robust voice querying with MUVE: optimally\nvisualizing results of phonetically similar queries. Proc. VLDB Endow., 14(11):2397–2409, 2021.\n[149] Nathaniel Weir and Prasetya Utama. Bootstrapping an end-to-end natural language interface for databases.\nIn SIGMOD, pages 1862–1864, 2019.\n[150] Yuk Wah Wong and Raymond J. Mooney. Learning for semantic parsing with statistical machine trans-\nlation. In Human Language Technology Conference of the North American Chapter of the Association of\nComputational Linguistics, 2006.\n[151] Chunyang Xiao, Marc Dymetman, and Claire Gardent. Sequence-based structured prediction for semantic\nparsing. In ACL, 2016.\n[152] Xiaojun Xu, Chang Liu, and Dawn Song. Sqlnet: Generating structured queries from natural language\nwithout reinforcement learning. CoRR, abs/1711.04436, 2017.\n[153] Navid Yaghmazadeh, Yuepeng Wang, Isil Dillig, and Thomas Dillig. Sqlizer: query synthesis from natural\nlanguage. Proc. ACM Program. Lang., 1(OOPSLA):63:1–63:26, 2017.\n[154] Yuquan Yang, Qifan Zhang, and Junjie Yao. Task-driven neural natural language interface to database. In\nWISE, volume 14306 of Lecture Notes in Computer Science, pages 659–673, 2023.\n[155] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. Xlnet:\nGeneralized autoregressive pretraining for language understanding. In NeurIPS, pages 5754–5764, 2019.\n[156] Ziyu Yao, Yu Su, Huan Sun, and Wen-tau Yih.\nModel-based interactive semantic parsing: A unified\nframework and A text-to-sql case study. In EMNLP-IJCNLP, pages 5446–5457, 2019.\n[157] Pengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code generation. In\nACL, pages 440–450, 2017.\n[158] Tao Yu, Zifan Li, Zilin Zhang, Rui Zhang, and Dragomir R. Radev. Typesql: Knowledge-based type-aware\nneural text-to-sql generation. In NAACL-HLT, pages 588–594, 2018.\n[159] Tao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan Li, and Dragomir R. Radev.\nSyntaxsqlnet: Syntax tree networks for complex and cross-domain text-to-sql task. In EMNLP, pages\n1653–1663, 2018.\n[160] Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning\nYao, Shanelle Roman, Zilin Zhang, and Dragomir R. Radev. Spider: A large-scale human-labeled dataset\nfor complex and cross-domain semantic parsing and text-to-sql task. In EMNLP, pages 3911–3921, 2018.\n[161] John M. Zelle and Raymond J. Mooney. Learning to parse database queries using inductive logic program-\nming. In AAAI IAAI, pages 1050–1055, 1996.\n[162] Gideon Zenz, Xuan Zhou, Enrico Minack, Wolf Siberski, and Wolfgang Nejdl. From keywords to semantic\nqueries - incremental query construction on the semantic web. J. Web Semant., 7(3):166–176, 2009.\n[163] Luke S. Zettlemoyer and Michael Collins. Learning to map sentences to logical form: Structured classifi-\ncation with probabilistic categorial grammars. In UAI, pages 658–666, 2005.\n[164] Jinchuan Zhang, Yan Zhou, Binyuan Hui, Yaxin Liu, Ziming Li, and Songlin Hu. Trojansql: SQL injection\nagainst natural language interface to database. In EMNLP, pages 4344–4359, 2023.\n[165] Bolong Zheng, Lei Bi, Juan Cao, Hua Chai, Jun Fang, Lu Chen, Yunjun Gao, Xiaofang Zhou, and Chris-\ntian S. Jensen. Speaknav: Voice-based route description language understanding for template driven path\nsearch. Proc. VLDB Endow., 14(12):3056–3068, 2021.\n[166] Weiguo Zheng, Hong Cheng, Lei Zou, Jeffrey Xu Yu, and Kangfei Zhao.\nNatural language ques-\ntion/answering: Let users talk with the knowledge graph. In ACM CIKM, pages 217–226, 2017.\n[167] Victor Zhong, Caiming Xiong, and Richard Socher. Seq2sql: Generating structured queries from natural\nlanguage using reinforcement learning. CoRR, abs/1709.00103, 2017.\n[168] Lei Zou, Ruizhe Huang, Haixun Wang, Jeffrey Xu Yu, Wenqiang He, and Dongyan Zhao. Natural language\nquestion answering over RDF: a graph data driven approach. In SIGMOD, pages 313–324, 2014.\n42\n",
  "categories": [
    "cs.DB"
  ],
  "published": "2025-03-04",
  "updated": "2025-03-04"
}