{
  "id": "http://arxiv.org/abs/2503.03380v1",
  "title": "The Serendipity of Claude AI: Case of the 13 Low-Resource National Languages of Mali",
  "authors": [
    "Alou Dembele",
    "Nouhoum Souleymane Coulibaly",
    "Michael Leventhal"
  ],
  "abstract": "Recent advances in artificial intelligence (AI) and natural language\nprocessing (NLP) have improved the representation of underrepresented\nlanguages. However, most languages, including Mali's 13 official national\nlanguages, continue to be poorly supported or unsupported by automatic\ntranslation and generative AI. This situation appears to have slightly improved\nwith certain recent LLM releases. The study evaluated Claude AI's translation\nperformance on each of the 13 national languages of Mali. In addition to ChrF2\nand BLEU scores, human evaluators assessed translation accuracy, contextual\nconsistency, robustness to dialect variations, management of linguistic bias,\nadaptation to a limited corpus, and ease of understanding. The study found that\nClaude AI performs robustly for languages with very modest language resources\nand, while unable to produce understandable and coherent texts for Malian\nlanguages with minimal resources, still manages to produce results which\ndemonstrate the ability to mimic some elements of the language.",
  "text": " \n \n \nThe Serendipity of Claude AI : Case of the 13  \nLow-Resource  \nNational Languages of Mali \n \n \nAuthors: By Alou DEMBELE, Nouhoum \nSouleymane COULIBALY, Michael \nLEVENTHAL RobotsMali AI4D Lab, Bamako, \nMali, research@robotsmali.org \n \nKeywords \nnational language - Artificial Intelligence - \nEducation \n- \nClaude \nAI \n- \nLow-resource \nlanguages ​- Linguistic technologies. \n \n \nAbstract \n \nRecent advances in artificial intelligence (AI) \nand natural language processing (NLP) have \nimproved the representation of underrepresented \nlanguages. However, most languages, including \nMali's 13 official national languages, continue to \nbe \npoorly \nsupported \nor \nunsupported \nby \nautomatic translation and generative AI. This \nsituation appears to have slightly improved with \ncertain \nrecent \nLLM \nreleases. The study \nevaluated Claude AI's translation performance \non each of the 13 national languages ​of Mali. In \naddition to ChrF2 and BLEU scores, human \nevaluators \nassessed \ntranslation \naccuracy, \ncontextual consistency, robustness to dialect \nvariations, management of linguistic bias, \nadaptation to a limited corpus, and ease of \nunderstanding. The study found that Claude AI \nperforms robustly for languages with very \nmodest language resources and, while unable to \nproduce understandable and coherent texts for \nMalian languages with minimal resources, still \nmanages to produce results which demonstrate \nthe ability to mimic some elements of the \nlanguage. \n \n1.​ Introduction \n \nIn recent years, advances in artificial intelligence \n(AI) and natural language processing (NLP) \nhave marked a significant advance in the \nrepresentation \nand \ndevelopment \nof \nunderrepresented languages. However, most of \nthe world’s languages, often referred to as \n\"low-resource languages\", still remain either not \nsupported or insufficiently supported due to the \nlimited availability of data and language \nresources, and market, economic, and global \ninequality factors. \nMali, a multilingual country with 13 official \nlanguages, including Bamanankan (Bambara), \nBomu, Bozo, Dɔgɔsɔ (Dogon), Fulfulde (Fula), \nHassaniya \nArabic, \nMamara \n(Minyanka), \nManinka, Soninke, Sɔõɔy (Songhay), Senara, \nTàmàsàyt \n(Tamasheq) \nand \nXaasongaxanno \n(Kassonke), faces severe challenges in digital \ninclusion \nlimiting \neconomic \ndevelopment, \neducational advancement, and preservation of \ncultural heritage (Bird, 2020 ; Nekoto et al., \n2020). These languages share in common a \npenury of language resources needed to train AI \nand NLP systems which could play a role in \nlessening the digital divide (Hammarström et al., \n2018). This penury extends from severe in the \ncase of a language like Bambara which has very \nlimited resources to catastrophic for languages \nlike Bomu and Bozo with an almost complete \nabsence of language resources. \nThe \nneed \nfor \ninnovative \nmethods \nfor \nlow-resource languages ​has spawned varied \nstrategies, such as transfer learning, zero-shot \nlearning, and pre-trained models in related \nlanguages ​(Ruder, 2021; Adelani et al., 2022 ). \nClaude AI, like other advanced models, uses \ncross-linguistic transfer to fill the resource gap \nby applying knowledge from better-resourced \nlanguages ​to lesser-known languages ​(Conneau \net al., 2020). Although promising, these \nmethodologies may still be challenged by \nlanguages ​whose typological and structural \ncharacteristics differ greatly from those of more \nresource-rich languages ​(Pires et al., 2019). \nBy examining the effectiveness of Claude AI in \nsupporting Mali's national languages, this \nresearch \nhighlights \nthe \nchallenges \nand \nopportunities of AI in linguistic inclusion. \nImproving AI tools for low-resource languages \n​could \nprovide \nMali's \ndiverse \nlinguistic \ncommunities with greater access to technologies, \n \n \n \nPage 1 \n \n \n \nthereby \npromoting \ngreater \neducational, \nsociocultural, and economic inclusion. \nOur evaluations of Claude's performance were \ncarried out despite the fact that its use in Mali \nhas \nbeen \ngeo-blocked. \nOur \nresearchers \ncircumvented this restriction using a VPN and \nphone numbers in unblocked countries. Despite \nthe exclusion of Malian users, Claude AI \nmanages to translate certain languages ​of Mali \nwithout having received specific training for \nthem. It can understand and produce translations \nin less-represented languages, including several \nMalian languages, exploiting knowledge of \ncommon linguistic structures and contexts.  \n \n2.​ Literature review \n \nMost AI and NLP models still struggle with \nlow-resource languages, which suffer from a \nshortage of digitized data, annotated corpora, \nand linguistic resources (Joshi et al., 2020). \nClaude \nAI's \ncapabilities \nin \ntranslating \nlow-resource languages, particularly for African \nlanguages, have attracted attention in recent \nstudies, although challenges remain. According \nto Enis and Hopkins (2024), Claude 3 Opus \nshows strong proficiency when translating \nlow-resource \nlanguages \n​into \nEnglish, \noutperforming Google Translate and Meta's \nNLLB-54B on benchmark datasets such as \nFLORES-200. \nThey \nnoted, however, that \n“Claude performs significantly better when \ntranslating into English than from English,” a \nlimitation affecting African languages ​that are \nless widely studied in machine translation (MT) \nresearch (Enis & Hopkins , 2024)​ \nEnis and Hopkins (2024) showed that Claude \noutperformed these models in 25% of the \nlanguages ​evaluated, although its performance \nvaried depending on the translation direction and \nthe dataset used. \nIn a survey study, Sunyu Transphere (2024) \nexamined \nClaude's \nhandling \nof \nvarious \nlanguages, including some from Africa. They \nreported that Claude's translation quality varies \nsignificantly depending on the dataset and \ntranslation direction, noting that \"his abilities are \nsignificantly lower when translating from \nEnglish to low-resource languages ”, reflecting a \ntypical limitation in many LLMs (Sunyu \nTransphere, 2024)​ \nEnis and Hopkins (2024) argue for the \nexpansion of high-quality linguistic resources \nfor African languages, a move that could help \nrefine Claude's abilities for Mali's official \nlanguages. Currently, they suggest that the \napplication of Claude in these contexts is better \nsuited to translation into English rather than \nfrom English, where it continues to face \naccuracy issues (Enis & Hopkins, 2024; Sunyu \nTransphere, 2024). \n \nThe challenge of low-resource languages ​in \nNLP \n \nAfrican languages, particularly those of Mali, \npresent an additional layer of complexity as they \noften feature dialectal variations, complex \nphonetic and grammatical systems, and limited \nhistorical documentation (Hammarström et al., \n2017; Orife et al., 2020).  The development of \nprecise NLP models for these languages ​has \ntherefore become an important area of ​research \nin recent years. (Ruder et al., 2021). \n \nClaude \nAI's \napproach \nto \nlow-resource \nlanguages \n \nClaude AI is trained to handle numerous \nlanguages, leveraging cross-linguistic transfer \nlearning and other cutting-edge techniques. \nHowever, models like Claude AI are typically \ntrained on large, multilingual datasets that \nheavily favor languages ​with a significant digital \npresence, leaving low-resource languages ​with \nlimited support. (Smith et al., 2022). The \neffectiveness of Claude AI on languages ​such as \nBambara and Songhay is further complicated by \ntheir phonological diversity. Cross-linguistic \ntransfer, which involves applying knowledge \nfrom resource-rich languages ​to low-resource \nlanguages, can be effective, but often does not \ntake into account the linguistic nuances essential \nfor \ngood \ncomprehension \nand \ntranslation \n(Conneau et al., 2020; Pires et al., 2019). \n \n \n \n \nPage 2 \n \n \n \nChallenges specific to the languages ​of Mali \n \nMali's national languages ​embody diverse \nlinguistic structures and dialect variations, \nmaking data collection and model training \nparticularly difficult. Languages ​like Dɔgɔsɔ \n(Dogon) or Senara, for example, contain \nsignificant \nregional \nvariations, \nmaking \nit \ndifficult \nto \ncreate \nunified \ndatasets \n(Hammarström et al., 2017). Additionally, the \nlanguages ​of Mali are predominantly oral, with \nfew printed works and fewer still in electronic \nform, restricting the corpora available for model \ntraining. (Bird, 2020). Malian languages ​are \nweakly supported by systems of standardized \nspelling and linguistic resources such as \ndictionaries, making it difficult to pre-train and \nevaluate models with consistent data (Joshi et \nal., 2020). \nBambara, among the Malian languages, is the \nbest resourced, with a standardized orthography \nand an online dictionary adhering to this \nstandard, an 11 million word electronic corpus \nhosted by INALCO, and a curated machine \nlearning dataset of approximately 50,000 aligned \nFrench-Bambara \nsentences \ncreated \nby \nRobotsMali. (Tapo et. al., 2020). \n \n3.​ Methodology \n \nA comprehensive suite of human and machine \ntests was performed for each language. \n \n●​ Translation of text \n●​ Comparison to reference texts \n●​ Automated scoring  (BLEU and chrF) \nClaude AI performance evaluation criteria for \nlow-resource languages ​in Mali \nTo \neffectively \nevaluate \nClaude \nAI \non \nlow-resource Malian languages, the criteria was \ndeveloped that match the linguistic and technical \nparticularities of these languages ​in order to \nclearly understand its performance and identify \navenues for improvement. \nTranslation accuracy: Evaluate the fidelity of \nthe translations produced by Claude, taking into \naccount the lexical, syntactic and semantic \nparticularities specific to the languages ​of Mali, \nin particular their ability to reproduce specific \nidiomatic and cultural expressions, including  \nthose from linguistically isolated communities \n(e.g. Dogon, Tamasheq). \nContextual consistency: Measure the ability of \nAI to maintain consistency in texts where dialect \nvariations are present, such as those observed in \nSenara and Dogon, especially for complex local \nlanguage text generation tasks. \nRobustness in the face of dialect variations : \nObserve whether Claude correctly manages the \nsubtle differences between sub-dialects of \nlanguages ​like Dogon and Songhay, maintaining \nprecision \nand \nconsistency \ndespite \nnon-standardized spelling variations. \nManagement of linguistic biases: Identify and \nlimit Claude's potential biases which favor \ndominant languages ​(French, English) in order \nto \nensure \nfaithful \nand \nuninfluenced \nrepresentation of minority languages ​such as \nMamara and Khassonke. \nAdaptation to a limited corpus : Evaluate \nClaude's performance with little training data, a \ncrucial \nrequirement \nfor \nlanguages \n​underrepresented in digital resources (e.g. \nSenara, Tamasheq). \nEase of understanding and use: Test the \nfluency and understanding of the output \ngenerated by Claude with native speakers and \ndomain specialists, particularly for practical \napplications \nsuch \nas \nthe \ntranslation \nof \nadministrative documents. \nData sources and collection   \nThe 13 official languages ​of Mali, including \nBambara, Fula, Soninke, and others, are poorly \nequipped with digital corpora. Collecting data \nfor these languages ​required varied sources to \nassess \nClaude's \nperformance \non \nthese \nlow-resource languages. \n \n \n \nPage 3 \n \n \n \nGeographic and demographic context   \nLocated in West Africa, Mali is a country of \ngreat linguistic diversity with approximately 22 \nmillion inhabitants, distributed between urban \nareas such as Bamako and rural areas. The 13 \nofficial national languages, alongside French, \nare a reflection of this cultural diversity and \nconstitute a relevant basis for the evaluation of \nAI in this context. \nEvaluators \n \nThere are two official, governmental \norganizations in Mali that serve as the ultimate \nauthorities on each of Mali’s 13 national \nlanguages. \n●​ Malian \nNational \nDirectorate \nof \nNon-Formal Education and National \nLanguages (DNENF-LN) \nThe DNENF-LN focuses, essentially, on \nthe use of Mali’s national languages in \nan educational context. Since formal \neducation is currently in French, the \nDirectorate \nconcerns \nitself \nwith \nnon-formal education, that is, education \noutside the K-12 classroom setting. \nThere is one language unit for each \nnational language of Mali.  \n●​ Malian \nNational \nAcademy \nof \nLanguages  (AMALAN)  \nAMALAN is an, essentially, linguistic \nbody responsible for the standardization \nand development of each national \nlanguage. There is a linguistic unit for \neach national language of Mali. \nMaterials and resources used \n●​ Linguistic corpora : Texts written in \neach of the thirteen spoken languages \nand French, extracted from the Malian \nMining Code and from the story \n“Niamoye” with parallel translations in \n12 of the 13 national languages of Mali \nand French. \n \n4.​ Presentation and analysis of results \n \nAutomatic metrics, BLEU and ChrF++, could be \napplied to these texts and proved largely \nmeaningful for quick, preliminary evaluation, \nparticularly for comparing supported languages \n​with significant resources. However, human \nevaluation, on both the materials with reference \ntranslations and on other collected text samples, \nwas used to judge fluency, fidelity to meaning \nand cultural relevance. This type of evaluation \nprovided the only meaningful feedback for the \nmost resource-poor languages.  \n \n \nTable 1: Claude's ChrF2 and BLEU scores \nwhen translating from French to each of the \nlanguages ​of Mali \n Test 1: Text de Niamoye \n \n \n \n \nTable 2:  Claude’s ChrF2 and BLEU scores \nwhen translating from French into each of the \nlanguages ​of Mali  \nCase 2: Text of Mali’s Mining Code \n \n \n \n \n \n \n \n \nPage 4 \n \n \n \nTable 3:  Evaluation by experts of AMALAN \nand the DNENF-LN  \nText of Niamoye \n \n \n \n \n4 languages ​out of the 13 were considered good \nby human evaluators, namely Bambara, Fula, \nSoninke and Songhay \n \nGeneral Summary: \n \nThe analysis aims to assess the quality of \ntranslations of texts from French into the thirteen \nMalian languages, taking into account fidelity to \nthe source text, fluidity, coherence and linguistic \nadequacy. \n \nThe reference texts were created and validated \nfor correctness by human experts in French and \nall Malian languages, with the exception of \nHassaniya Arabic for Niamoye. The French text \nwas translated by Claude AI into each Malian \nlanguage and ChrF2 and BLEU scores were \nmeasured against the reference translations as \npresented in Tables 1 and 2. \n \nBambara has, by a considerable margin, the \nhighest quantitative scores (64.8, 59.8 for ChrF2 \nand 43.1, 38.5 for BLEU for the two texts). \nKassonke, \nand \nSoninke show moderately \nelevated scores, suggesting that Claude AI also \nhas significant capabilities in these languages. \n \nThe human evaluation of translations carried out \nby \nthe \nDNENF-LN \nand \nthe \nAMALAN \nsupported some of the results identified by \nautomated scoring and contravened other results. \nBambara and Soninke had highly positive \nevaluations by both human and automated \nscoring, while Kassonke’s moderately elevated \nautomated score was not confirmed by human \nevaluators. Fula, which from automated scoring \nseemed not to be meaningfully translated by \nClaude AI, was appreciated by the human \nevaluators as approximately equal to Bambara \nand Soninke. Songhay was also evaluated much \nmore highly by humans than its automated \nscores would have suggested.  \n \nThere is a correspondence in the results to the \nquantity of digital resources available in each \nlanguage. Our team has created, worked with, or \nis aware of significant resources in Bambara, \nSoninke, Fula, and Songhay, all languages for \nwhich human evaluators gave good marks to the \nautomated translations. A surprise in the results \nis the ability of Claude AI to produce any \nmeaningful result in languages for which there \nare virtually no digital resources. The relatively \nhigh automated evaluation scores for Kassonke \nand low scores in human evaluation of \nmeaningfulness \nof \nthe \ntext \nsuggests \na \nconsiderable ability to mimic language from \nvery small samples without actually being able \nto produce intelligible text. The contrary lesson \nmight be derived from the results with Fula, \nwhere poor automated scores suggests that \nClaude AI was able to translate the essence of \nthe ideas covered by the text, causing it to forgo \nmimicry, producing a meaningful text with the \nvocabulary at its disposal. \n \nConclusion \n \nClaude's \nperformance \nin \ntranslating \nthe \nlanguages ​of Mali, despite the lack of specific \ntraining, \nis, \nall \nlimitations \nconsidered, \nimpressive and highlights the immense potential \nof \nlanguage \nmodels \nfor underrepresented \nlanguages. This natural capacity demonstrates \nthe interest in pushing further by enriching the \ncorpora accessible to LLMs (large language \nmodels) in these languages.  \n \nOur investigation demonstrates that automated \nmetrics may fail catastrophically, in some cases, \nin the assessment of translation quality for \nextremely low resourced languages. They are \nmore reliable for languages with moderate \n \n \n \nPage 5 \n \n \n \nresources, but it may be difficult to assess \ntranslation \nperformance \nwithout \nhuman \nassessment. Humans provide more nuanced \nanalysis of qualitative issues, particularly in \nterms of grammaticality and semantic fidelity \nthat are needed to assess the ability of the model \nin the target language. \n \nCross-linguistic \ntransfer \nand \nmultilingual \npre-training techniques have shown promising \nresults, suggesting that the bar for the quantity of \nresources needed to obtain useful results has \nfallen significantly below what was supposed \nnecessary earlier. It appears that relatively robust \nresults for Bambara can be obtained despite its \nvery small quantity of online data and curated \ntraining data. While the bar is not  sufficiently \nlow to enable translation to languages ​with the \nmost limited resources, our results suggest that \nthe effort to assemble even modest levels of \nresources for those languages may prove fruitful. \nIt may also give additional incentive to work on \nfurther enhancing interlinguistic capabilities of \nLLMs so that the resources available and the \ncapabilities of the LLMs may advance the \nstate-of-art for low resource languages more \nquickly. We may not have reached the limits of \ninterlinguistic capabilities of language models. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nBibliographic references \n1.​ Adelani, D.I., et al. (2022). A Few \nThousand Translations Go a Long Way! \nLeveraging Pre-trained Models for \nAfrican News Translation. Proceedings \nof the 60th Annual Meeting of the \nAssociation for Computational \nLinguistics, 2812-2823. \n2.​ Anastasopoulos, A., et al. (2020). \nTICO-19: The Translation Initiative for \nCOVID-19. arXiv preprint \narXiv:2010.04650. \n3.​ Bird, S. (2020). Decolonising Speech \nand Language Technology. Proceedings \nof the 28th International Conference on \nComputational Linguistics, 3504-3519. \n4.​ Conneau, A., et al. (2020). \nUnsupervised Cross-lingual \nRepresentation Learning at Scale. \nProceedings of the 58th Annual Meeting \nof the Association for Computational \nLinguistics, 8440-8451. \n5.​ Hammarström, H., et al. (2017). \nGlottolog 3.0. Max Planck Institute for \nthe Science of Human History. \n6.​ Joshi, P., et al. (2020). The State and \nFate of Linguistic Diversity and \nInclusion in the NLP World. Proceedings \nof the 58th Annual Meeting of the \nAssociation for Computational \nLinguistics, 6282-6293. \n7.​ Nekoto, W., et al. (2020). Participatory \nResearch for Low-Resourced Machine \nTranslation: A Case Study in African \nLanguages. Findings of the Association \n \n \n \nPage 6 \n \n \n \nfor Computational Linguistics: EMNLP \n2020, 2144-2160. \n8.​ Pires, T., et al. (2019). How \nMultilingual is Multilingual BERT? \nProceedings of the 57th Annual Meeting \nof the Association for Computational \nLinguistics, 4996-5001. \n9.​ Ruder, S. (2021). Why You Should Do \nNLP Beyond English. Blog post, \nhttps://ruder.io. \n10.​Smith, T., et al. (2022). Performance of \nAdvanced Large Language Models in \nLow-Resource Contexts: A Survey and \nBenchmark Analysis. Journal of \nArtificial Intelligence Research, 74, \n89-102. \n11.​ Tapo, A.A., et al. (2020), Neural \nmachine translation for extremely \nlow-resource african languages: A case \nstudy on bambara. arXiv preprint \narXiv:2011.05284. \n12.​Artetxe, M., et al. (2019). \nUnsupervised Translation of Dialects \nand Related Languages by Lexicon \nInduction. North American Chapter of \nthe Association for Computational \nLinguistics, 75-84. \n13.​Guzmán, F., et al. (2019). The FLORES \nEvaluation Datasets for Low-Resource \nMachine Translation: Nepali-English \nand Sinhala-English. Proceedings of the \n2019 Conference on Empirical Methods \nin Natural Language Processing, \n6100-6113. \n14.​Orife, I., et al. (2020). Masakhane: \nTowards Open and Responsible NLP for \nAfrican Languages. Findings of the \nAssociation for Computational \nLinguistics: EMNLP 2020, 3144-3157. \n15.​Ruder, S., et al. (2021). The Current \nState of Cross-lingual NLP. Transactions \nof the Association for Computational \nLinguistics, 9, 127-145. \n16.​Enis, A., & Hopkins, J. (2024). \nPerformance of Claude 3 Opus in \nlow-resource language translation. \nJournal of Machine Translation \nResearch. \n17.​Sunyu Transfer (2024). Evaluating \nClaude's capabilities in translating \nAfrican languages. Natural Language \nProcessing Insights. \n18.​FLORES-200 Dataset. Benchmark for \nevaluating low-resource language \ntranslation models. \n \n \n \n \nPage 7 \n",
  "categories": [
    "cs.CL"
  ],
  "published": "2025-03-05",
  "updated": "2025-03-05"
}