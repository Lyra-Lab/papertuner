{
  "id": "http://arxiv.org/abs/cmp-lg/9503023v1",
  "title": "A fast partial parse of natural language sentences using a connectionist method",
  "authors": [
    "Caroline Lyon",
    "Bob Dickerson"
  ],
  "abstract": "The pattern matching capabilities of neural networks can be used to locate\nsyntactic constituents of natural language. This paper describes a fully\nautomated hybrid system, using neural nets operating within a grammatic\nframework. It addresses the representation of language for connectionist\nprocessing, and describes methods of constraining the problem size. The\nfunction of the network is briefly explained, and results are given.",
  "text": "arXiv:cmp-lg/9503023v1  22 Mar 1995\nA fast partial parse of natural language sentences\nusing a connectionist method\nCaroline Lyon\nDivision of Computer Science\nUniversity of Hertfordshire\nHatﬁeld AL10 9AB, UK\ncomrcml@herts.ac.uk\nBob Dickerson\nDivision of Computer Science\nUniversity of Hertfordshire\nHatﬁeld AL10 9AB, UK\ncomqrgd@herts.ac.uk\nAbstract\nThe pattern matching capabilities of neu-\nral networks can be used to locate syntac-\ntic constituents of natural language. This\npaper describes a fully automated hybrid\nsystem, using neural nets operating within\na grammatic framework. It addresses the\nrepresentation of language for connection-\nist processing, and describes methods of\nconstraining the problem size. The func-\ntion of the network is brieﬂy explained, and\nresults are given.\n1\nIntroduction\nThe pattern matching capabilities of neural net-\nworks can be used to detect syntactic constituents\nof natural language. This approach bears compari-\nson with probabilistic systems, but has the advan-\ntage that negative as well as positive information\ncan be modelled. Also, most computation is done\nin advance, when the nets are trained, so the run\ntime computational load is low. In this work neu-\nral networks are used as part of a fully automated\nsystem that ﬁnds a partial parse of declarative sen-\ntences. The connectionist processors operate within\na grammatic framework, and are supported by pre-\nprocessors that ﬁlter the data and reduce the prob-\nlem to a computationally tractable size. A prototype\ncan be accessed via the Internet, on which users can\ntry their own text (details from the authors). It will\ntake a sentence, locate the subject and then ﬁnd\nthe head of the subject. Typically 10 sentences take\nabout 2 seconds, 50 sentences about 4 seconds, to\nprocess on a Sparc10 workstation. Using the proto-\ntype on technical manuals the subject and its head\ncan be detected in over 90% of cases (See Section 7).\nThe well known complexity of parsing is addressed\nby decomposing the problem, and then locating one\nsyntactic constituent at a time. The sentence is ﬁrst\ndecomposed into the broad syntactic categories\npre-subject - subject - predicate\nby locating the subject. Then these constituents can\nbe processed further. The underlying principle em-\nployed at each step is to take a sentence, or part\nof a sentence, and generate strings with the bound-\nary markers of the syntactic constituent in question\nplaced in all possible positions. Then a neural net\nselects the string with the correct placement.\nThis paper gives an overview of how natural lan-\nguage is converted to a representation that the neu-\nral nets can handle, and how the problem is re-\nduced to a manageable size.\nIt then outlines the\nneural net selection process. A comprehensive ac-\ncount is given in Lyon (1994); descriptions of the\nneural net process are also in Lyon (1993) and\nLyon and Frank (1992).\nThis is a hybrid system.\nThe core process is data driven, as the parameters of\nthe neural networks are derived from training text.\nThe neural net is trained in supervised mode on ex-\namples that have been manually marked “correct”\nand “incorrect”.\nIt will then be able to classify\nunseen examples.\nHowever, the initial processing\nstages, in which the problem size is constrained, op-\nerate within a skeletal grammatic framework. Com-\nputational tractability is further addressed by reduc-\ning data through the application of prohibitive rules\nas local constraints. The pruning process is remark-\nably eﬀective.\n2\nThe corpus of sentences from\ntechnical manuals\nThis work has principally been developed on text\nof technical manuals from Perkins Engines Ltd.,\nwhich have been translated by a semi-automatic pro-\ncess (Pym, 1993). Now, a partial parse can support\nsuch a process. For instance, frequently occurring\nmodal verbs such as “must” are not distinguished\n1\n20\n18\n16\n14\n12\n10\n8\n6\n4\n2\n0\n2\n3\n4\n5\n6\n7\n8\n9 10 11 12 13 14 15 16\nNumber of words before the subject\n56\n64\n11 12 13 14 15 16\n2\n3\n4\n5\n6\n7\n8\n9\n10\n8 \n16\n24\n32\n40\n48\n72\n80\nNumber of words in the subject\n0\n1\nNumber of\noccurrences\nFigure 1: The frequency of constituent length for pre-subject and subject in 351 sentences\nby number in English, but they are in many other\nlanguages. It is necessary to locate the subject, then\nidentify the head and determine its number in order\nto translate the main verb correctly in sentences like\n(1) below.\nIf a cooler is ﬁtted to the gearbox, [ the pipe [\nconnections ] of the cooler ] must be regularly\nchecked for corrosion.\n(1)\nThis parser has been trained to ﬁnd the syntactic\nsubject head that agrees in number with the main\nverb.\nThe manuals are written using the PACE\n(Perkins Approved Clear English) guidelines, with\nthe aim of producing clear, unambiguous texts. All\ndeclarative sentences have been extracted for pro-\ncessing: about half were imperatives. This level of\nclassiﬁcation can be done automatically in future.\nTable 1 and Figure 1 show some of the characteris-\ntics of the corpus.\nNumber of sentences\n351\nAverage length\n17.98 words\nNo. of subordinate clauses\nIn pre-subject\n65\nIn subject\n19\nIn predicate\n136\nCo-ordinated clauses\n50\nPunctuation marks are counted as words, formulae as 1\nword.\nTable 1: Corpus statistics\n3\nLanguage representation (I)\nIn order to reconcile computational feasibility to em-\npirical realism an appropriate form of language rep-\nresentation is critical. The ﬁrst step in constraining\nthe problem size is to partition an unlimited vocabu-\nlary into a restricted number of part-of-speech tags.\nDiﬀerent stages of processing place diﬀerent require-\nments on the classiﬁcation system, so customised\ntagsets have been developed. For the ﬁrst processing\nstage we need to place the subject markers, and, as\na further task, disambiguate tags. It was not found\nnecessary to use number information at this stage.\nFor example, consider the sentence:\nStill waters run deep.\n(2)\nThe word “waters” could be a 3rd person, singular,\npresent verb or a plural noun. However, in order to\ndisambiguate the tag and place the subject markers\nit is only necessary to know that it is a noun or else a\nverb. The sentence parsed at the ﬁrst level returns:\n[ Still waters ] run deep.\n(2.1)\nThe tagset used at this stage, mode 1, has 21 classes,\nnot distinguished for number.\nHowever, the head\nof the subject is then found and number agreement\nwith the verb can be assessed.\nAt this stage the\ntagset, mode 2, includes number information and\nhas 28 classes. Devising optimal tagsets for given\ntasks is a ﬁeld in which further work is planned.\nWe need larger tagsets to capture more linguistic\ninformation, but smaller ones to constrain the com-\nputational load. Information theoretic tools can be\nused to ﬁnd the entropy of diﬀerent tag sequence\nlanguages, and support decisions on representation.\nA functional approach is taken to tagging: words\nare allocated to classes depending on their syntactic\nrole. For instance, superlative adjectives can act as\nnouns, so they are initially given the 2 tags: noun\nor adjective. This approach can be extended by tak-\ning adjacent words which act jointly as single lexical\nitems as a unit. Thus the pair “most <adjective>”\nis taken as a single superlative adjective.\nText is automatically tagged using the ﬁrst mod-\nules of the CLAWS program (1985 version), in which\nwords are allocated one or more tags from 134 classes\n(Garside, 1987). These 134 tags are then mapped\nonto the small customised tagsets. Tag disambigua-\ntion is part of the parsing task, handled by the neural\nnet and its pre-processor. This version of CLAWS\nhas a dictionary of about 6,300 words only. Other\nwords are tagged using suﬃx information, or else de-\nfaults are invoked. The correct tag is almost always\nincluded in the set allocated, but more tags than\nnecessary are often proposed. A larger dictionary in\nlater versions will address this problem.\nRepresenting syntactic boundary markers\nIn the same way that tags are allocated to words,\nor to punctuation marks, they can represent the\nboundaries of syntactic constituents, such as noun\nphrases and verb phrases. Boundary markers can\nbe considered invisible tags, or hypertags, which\nhave probabilistic relationships with adjacent tags\nin the same way that words do. Atwell (1987) and\nChurch (1989) have used this approach.\nIf em-\nbedded syntactic constituents are sought in a sin-\ngle pass, this can lead to computational overload\n(Pocock and Atwell, 1994).\nOur approach uses a\nsimilar concept, but diﬀers in that embedded syntac-\ntic constituents are detected one at a time in sepa-\nrate steps. There are only 2 hypertags - the opening\nand closing brackets marking the possible location(s)\nof the syntactic constituent in question. Using this\nrepresentation a hierarchical language structure is\nconverted to a string of tags represented by a linear\nvector.\n4\nConstraining the generation of\ncandidate strings\nThis system generates sets of tag strings for each\nsentence, with the hypertags placed in all possible\npositions. Thus, for the subject detection task:\nThen the performance of the pump must be mon-\nitored.\n(3)\nwill generate strings of tags including:\n[ Then ] the performance of the pump must be\nmonitored.\n(3.1)\n[ Then the ] performance of the pump must be\nmonitored.\n(3.2)\n.....................\nThen [ the performance of the ] pump must be\nmonitored.\n(3.n)\nThen [ the performance of the pump ] must be\nmonitored.\n(3.n + 1)\n................\nHypertags are always inserted in pairs, so that clo-\nsure is enforced. There were arbitrary limits of a\nmaximum of 10 words in the pre-subject and 10\nwords within the subject for the initial work de-\nscribed here. These are now extended to 15 words\nin the pre-subject, 12 in the subject - see Section\n7. There must be at least one word beyond the end\nof the subject and before the end-of-sentence mark.\nTherefore, using the initial restrictions, in a sentence\nof 22 words or more (counting punctuation marks as\nwords) there could be 100 alternative placements.\nHowever, some words will have more than one pos-\nsible tag. For instance, in sentence (1) above 5 words\nhave 2 alternative tags, which will generate 25 pos-\nsible strings before the hypertags are inserted. Since\nthere are 22 words (including punctuation ) the to-\ntal number of strings would be 25 ∗100 = 3200. It\nis not feasible to detect one string out of this num-\nber: if the classiﬁer marked all strings incorrect the\npercentage wrongly classiﬁed would only be 0.03%,\nyet it would be quite useless. In order to ﬁnd the\ncorrect string most of the outside candidates must\nbe dropped,\nThe skeletal grammatic framework\nA minimal grammar, set out in Lyon (1994) in\nEBNF form, is composed of 9 rules. For instance,\nthe subject must contain a noun-type word. Apply-\ning this particular rule to sentence (3) above would\neliminate candidate strings (3.1) and (3.2). We also\nhave the 2 arbitrary limits on length of pre-subject\nand subject.\nThere is a small set of 4 extensions\nto the grammar, or semi-local constraints. For in-\nstance, if a relative pronoun occurs, then a verb must\nfollow in that constituent. On the technical manuals\nthe constraints of the grammatic framework put up\nto 6% of declarative sentences outside our system,\nmost commonly because the pre-subject is too long.\nA small number are excluded because the system\ncannot handle a co-ordinated head. With the length\nof pre-subject extended to 15 words, and subject to\n12 words, an average of 2% are excluded (7 out of\n351).\nProhibition tables\nThe grammatic framework alone does not re-\nduce the number of candidate strings suﬃciently\nfor the subject detection stage.\nThis problem\nis addressed further by a method suggested by\nBarton, Berwick and Ristad (1987) that local con-\nstraints can rein in the generation of an intractable\nnumber of possibilities. In our system the local con-\nstraints are prohibited tag pairs and triples. These\nare adjacent tags which are not allowed, such as “de-\nterminer - verb” or “start of subject - verb”. If dur-\ning the generation of a candidate string a prohibited\ngenerate input 1\nprune\nmode 1 tags\n       find subject\nneural network 1\ngenerate input 2\nfind head of subject\nneural network 2\nHEAD  OF  SUBJECT\nFOUND\nSUBJECT\nFOUND\ntag  sentence\nfrom  subject\nKEY\nneural network\ndata store\nprocess\nINPUT  SENTENCE\nwith number\nmode 2 tags\nFigure 2: Overview of the syntactic pattern recognition process\ntuple is encountered, then the process is aborted.\nThere are about 100 prohibited pairs and 120 triples.\nBy using these methods the number of candidate\nstrings is drastically reduced. For the technical man-\nuals an average of 4 strings, seldom more than 15\nstrings, are left. Around 25% of sentences are left\nwith a single string. These ﬁlters or “rules” diﬀer\nfundamentally from generative rules that produce\nallowable strings in a language. In those cases only\nproductions that are explicitly admitted are allowed.\nHere, in contrast, anything that is not expressly pro-\nhibited is allowed. At this stage the data is ready to\npresent to the neural net. Figure 2 gives an overview\nof the whole process.\n5\nLanguage representation (II)\nDiﬀerent network architectures have been investi-\ngated, but they all share the same input and output\nrepresentation. The output from the net is a vector\nwhose 2 elements, or nodes, represent “correct” and\n“incorrect”, “yes” and “no” - see Figure 3. The in-\nput to the net is derived from the candidate strings,\nthe sequences of tags and hypertags. These must\nbe converted to binary vectors. Each element of the\nvector will represent a feature that is ﬂagged 0 or 1,\nabsent or present.\nThough the form in which the vector is written\nmay give an illusion of representing order, no sequen-\ntial order is maintained. A method of representing\na sequence must be chosen. The sequential order of\nthe input is captured here, partially, by taking adja-\ncent tags, pairs and triples, as the feature elements.\nThe individual tags are converted to a bipos and\ntripos representation. Using this method each tag\nis in 3 tripos and 2 bipos elements. This highly re-\ndundant code will aid the processing of sparse data\ntypical of natural language.\nFor most of the work described here the sentence\nwas dynamically truncated 2 words beyond the hy-\npertag marking the close of the subject. This process\nhas now been improved by going further along the\nsentence.\n6\nThe function of the net\nThe net that gave best results was a simple single\nlayer net (Figure 3), derived from the Hodyne net of\nWyard and Nightingale (1990). This is convention-\nally a “single layer” net, since there is one layer of\nprocessing nodes. Multi-layer networks, which can\nprocess linearly inseparable data, were also investi-\ngated, but are not necessary for this particular pro-\ncessing task. The linear separability of data is re-\nlated to its order, and this system uses higher order\npairs and triples as input. The question of appropri-\nate network architecture is examined in Pao (1989),\nWidrow and Lehr (1992) and Lyon (1994).\nΣ\nΣ\n(adj,noun)\nno\nyes\n(noun,verb,noun)\n(‘[’  prep)\n( ‘[’  det)\n \nweighted links\noutput   nodes\ninput nodes\noften in both correct and incorrect strings.  The node  (‘[’\npreposition) would not\n‘[’   represents the start of the subject.  The node  ( ‘[’\ndeterminer)   would occur\noccur in a correct string, so it is not connected to the  \"yes\"\noutput node. \nΣ represents summing function.\nFigure 3: The single layer net: showing the feed forward process\nThe training process\nThe net is presented with training strings whose de-\nsired classiﬁcation has been manually marked. The\nweights on the connections between input and out-\nput nodes are adjusted until a required level of per-\nformance is reached.\nThen the weights are ﬁxed\nand the trained net is ready to classify unseen sen-\ntences. The prototype accessible via the Internet has\nbeen trained on sentences from the technical manu-\nals, slightly augmented.\nInitially the weighted links are disabled. When a\nstring is presented to the network in training mode,\nit activates a set of input nodes. If an input node is\nnot already linked to the output node representing\nthe desired response, it will be connected and the\nweight on the connection will be initialised to 1.0.\nMost input nodes are connected to both outputs,\nsince most tuples occur in both grammatical and\nungrammatical strings. However, some will only be\nconnected to one output - see Figure 3.\nThe input layer potentially has a node for each\npossible tuple.\nWith 28 tags, 2 hypertags and a\nstart symbol the upper bound on the number of in-\nput nodes is 313 +312. In practice the maximum ac-\ntivated is currently about 1000. In testing mode, if\na previously unseen tuple appears it makes zero con-\ntribution to the result. The activations at the input\nlayer are fed forward through the weighted connec-\ntions to the output nodes, where they are summed.\nThe highest output marks the winning node. If the\ndesired node wins, then no action is taken. If the\ndesired node does not win, then the weight on con-\nnections to the desired node are incremented, while\nthe weights on connections to the unwanted node are\ndecremented.\nThis algorithm diﬀers from some commonly used\nmethods. In feed forward networks trained in su-\npervised mode to perform a classiﬁcation task dif-\nferent penalty measures can be used to trigger a\nweight update. Back propagation and some single\nlayer training methods typically minimise a metric\nbased on the least squared error (LSE) between de-\nsired and actual activation of the output nodes. The\nreason why a diﬀerentiable error measure of this sort\nis necessary for multi-layer nets is well documented,\nfor example see Rumelhart and McClelland (1986).\nHowever, for single layer nets we can choose to up-\ndate weights directly: the error at an output node\ncan trigger weight updates on the connections that\nfeed it. Solutions with LSE are not necessarily the\nsame as minimising the number of misclassiﬁcations,\nand for certain types of data this second method\nof direct training may be appropriate. Now, in the\nnatural language domain it is desirable to get infor-\nmation from infrequent as well as common events.\nRare events, rather than being noise, can make a\nuseful contribution to a classiﬁcation task. We need\na method that captures information from infrequent\nevents, and adopt a direct measure of misclassiﬁ-\ncation. This may be better suited to data with a\n“Zipﬁan” distribution (Shannon, 1951).\nThe update factor is chosen to meet several re-\nquirements.\nIt should always be positive, and\nasymptotic to maximum and minimum bounds. The\nfactor should be greatest in the central region, least\nas it moves away in either direction. We are cur-\nrently still using the original Hodyne function be-\ncause it works well in practice. The update factor is\ngiven in the following formula. If δ= +1 for strength-\nening weights and δ = -1 for weakening them, then\nwnew =\n\u0014\n1 +\nδ ∗wold\n1 + (δ ∗wold)4\n\u0015\nwold\nRecall that weights are initialised to 1.0. After train-\ning we ﬁnd that the weight range is bounded by\n10−3 < w < 5.0\nTotal time for training is measured in seconds. The\nnumber of iterative cycles that are necessary de-\npends on the threshold chosen for the trained net\nto cross, and on details of the vector representa-\ntion. The demonstration prototype takes about 15\nseconds. With the most recent improved represen-\ntation about 1000 strings can be trained in 1 sec-\nond, to 97%. The results from using these nets are\ngiven in Table 3.\nIt was found that triples alone\ngave as good results as pairs and triples together.\nAnd though the nets easily train to 99% correct, the\nlower threshold gives slightly better generalisation\nand thus gives better results on the test data.\nThe testing process\nWhen the trained net is run on unseen data the\nweights on the links are ﬁxed. Any link that is still\ndisabled is activated and initialised to 0, so that tu-\nples which have not occurred in the training corpus\nmake no contribution to the classiﬁcation task. Sen-\ntences are put through the pre-processer one at a\ntime and the candidate strings which are generated\nare then presented to the network. The output is\nnow interpreted diﬀerently. The diﬀerence between\nthe “yes” and “no” activation levels is recorded for\neach string, and this score is considered a measure\nof grammaticality, Γ. The string with the highest Γ\nscore is taken as the correct one.\nFor the results given below, the networks were\ntrained on part of the corpus and tested on another\npart of the corpus. For the prototype in which users\ncan process their own text, the net was trained on\nthe whole corpus, slightly augmented.\n7\nResults\nThere are several measures of correctness that can\nbe taken when results are evaluated. The most le-\nnient is whether or not the subject and head mark-\ners are placed correctly - the type of measure used in\nthe IBM/Lancaster work (Black, Garside and Leech,\n1993). Since we are working towards a hierarchical\nlanguage structure, we may want the words within\nconstituents correctly tagged, ready for the next\nstage of processing. “correct- A” also requires that\nthe words within the subject are correctly tagged.\nThe results in Tables 2 and 3 give an indication of\nperformance levels.\n8\nUsing negative information\nWhen parses are postulated for a sentence nega-\ntive as well as positive examples are likely to oc-\ncur. Now, in natural language negative correlations\nare an important source of information: the occur-\nrence of some words or groups of words inhibit oth-\ners from following. We wish to exploit these con-\nstraints. Brill et al.\n(1990) recognised this, and in-\ntroduced the idea of distituents. These are elements\nof a sentence that should be separated, as opposed\nto elements of constituents that cling together. Brill\naddresses the problem of ﬁnding a valid metric for\ndistituency by using a generalized mutual informa-\ntion statistic.\nDistituency is marked by a mutual\ninformation minima. His method is supported by a\nsmall 4 rule grammar.\nHowever, this approach does not fully capture the\nsense in which inhibitory factors play a negative and\nnot just a neutral role. We want to distinguish be-\ntween items that are unlikely to occur ever, and\nthose that have just not happened to turn up in the\ntraining data. For example, in sentence (3) above\nstrings 3.1, 3.2 and 3.n can never be correct. These\nshould be distinguished from possibly correct parses\nthat are not in the training data. In order that “im-\nprobabilities” can be modelled by inhibitory connec-\ntions Niles and Silverman (1990) show how a Hid-\nden Markov Model can be implemented by a neural\nnetwork.\nThe theoretical ground for incorporating nega-\ntive examples in a language learning process orig-\ninates with the work of Gold (1967), developed by\nAngluin (1980). He examined the process of learning\nthe grammar of a formal language from examples.\nHe showed that, for languages at least as high in the\nChomsky hierarchy as CFGs, inference from posi-\ntive data alone is strictly less powerful than inference\nfrom both positive and negative data together. To\nillustrate this informally consider a case of inference\nfrom a number of examples: as they are presented to\nthe inference machine, possible grammars are postu-\nlated. However, with positive data alone a problem\nof over generalization arises: the postulated gram-\nno. of\nno. of\n% sents with\n% sents\n% sents with\ntraining sents.\ntest sents.\nsubject\ncorrect\nsubject and head\nfound\nmeasure A\nfound\n220\n42\n100\n100\n95\n198\n63\n97\n97\n90\n204\n58\n95\n95\n93\n276\n50\n94\n94\nTable 2: Performance on text from Perkins manuals, after 6% sentences have been excluded\nno. of\nno. of\n% sents with\n% sents\n% sents with\ntraining sents.\ntest sents.\nsubject\ncorrect\nsubject and head\nfound\nmeasure A\nfound\n309\n42\n100\n97.6\n97.6\n288\n63\n98.4\n96.8\n96.8\n292\n59\n98.3\n98.3\n96.6\n284\n67\n94.0\n94.0\n94.0\nTable 3: Performance on text from Perkins manuals, using improved representation and larger training set,\nafter 2% sentences have been excluded\nmar may be a superset of the real grammar, and sen-\ntences that are outside the real grammar could be\naccepted. If both positive and negative data is used,\ncounter examples will reduce the postulated gram-\nmar so that it is nearer the real grammar. Gold de-\nveloped his theory for formal languages: it is argued\nthat similar considerations apply here. A grammar\nmay be inferred from positive examples alone for cer-\ntain subsets of regular languages (Garcia and Vidal,\n1990), or an inference process may degenerate into\na look up procedure if every possible positive exam-\nple is stored. In these cases negative information is\nnot required, but they are not plausible models for\nunbounded natural language. In our method the re-\nquired parse is found by inferring the grammar from\nboth positive and negative information, which is ef-\nfectively modelled by the neural net. Future work\nwill investigate the eﬀect of training the networks\non the positive examples alone. With our current\nsize corpus there is not enough data.\nRelationship between the neural net and\nprohibition table\nThe relationship between the neural net and the\nrules in the prohibition table should be seen in the\nfollowing way. Any single rule prohibiting a tuple of\nadjacent tags could be omitted and the neural net-\nwork would handle it by linking the node represent-\ning that tuple to “no” only. However, for some pro-\ncessing steps we need to reduce the number of candi-\ndate tag strings presented to the neural network to\nmanageable proportions (see Section 4). The data\nmust be pre-processed by ﬁltering through the pro-\nhibition rule constraints. If the number of candidate\nstrings is within desirable bounds, such as for the\nhead detection task, no rules are used. Our system\nis data driven as far as possible: the rules are in-\nvoked if they are needed to make the problem com-\nputationally tractable.\n9\nConclusion\nOur working prototype indicates that the methods\ndescribed here are worth developing, and that con-\nnectionist methods can be used to generalise from\nthe training corpus to unseen text. Since data can\nbe represented as higher order tuples, single layer\nnetworks can be used. The traditional problems of\ntraining times do not arise. We have also used multi-\nlayer nets on this data: they have no advantages, and\nperform slightly less well (Lyon, 1994).\nThe supporting role of the grammatic framework\nand the prohibition ﬁlters should not be underes-\ntimated. Whenever the scope of the system is ex-\ntended it has been found necessary to enhance these\nelements.\nThe most laborious part of this work is preparing\nthe training data. Each time the representation is\nmodiﬁed a new set of strings is generated that need\nmarking up. An autodidactic check is now included\nwhich speeds up this task. We run marked up train-\ning data through an early version of the network\ntrained on the same data, so the results should be\nalmost all correct. If an “incorrect” parse occurs we\ncan then check whether that sentence was properly\nmarked up.\nSome of the features of the system described here\ncould be used in a stochastic process. However, con-\nnectionist methods have low computational loads at\nruntime. Moreover, they can utilise more of the im-\nplicit information in the training data by modelling\nnegative relationships. This is a powerful concept\nthat can be exploited in the eﬀort to squeeze out ev-\nery available piece of useful information for natural\nlanguage processing.\nFuture work is planned to extend this very limited\npartial parser, and decompose sentences further into\ntheir hierarchical constituent parts. In order to do\nthis a number of subsidiary tasks will be addressed.\nThe system is being improved by identifying groups\nof words that act as single lexical items. The decom-\nposition of the problem can be investigated further:\nfor instance, should the tag disambiguation task pre-\ncede the placement of the subject boundary mark-\ners in a separate step? More detailed investigation\nof language representation issues will be undertaken.\nAnd the critical issues of investigating the most ap-\npropriate network architectures will be carried on.\nReferences\n[Angluin1980] D Angluin. 1980. Inductive inference\nof formal languages from positive data. Informa-\ntion and Control, 45.\n[Atwell1987] E Atwell. 1987. Constituent-likelihood\ngrammar. In R Garside, G Leech, and G Samp-\nson, editors, The Computational Analysis of En-\nglish: a corpus-based approach. Longman.\n[Barton, Berwick and Ristad1987] G E Barton, R C\nBerwick, and E S Ristad. 1987. Computational\nComplexity and Natural Language. MIT Press.\n[Black, Garside and Leech1993] E Black, R Garside,\nand G Leech.\n1993.\nStatistically driven com-\nputer grammars of English: the IBM/Lancaster\napproach. Rodopi.\n[Brill et al. 1990] E Brill, D Magerman, M Marcus\nand B Santorini. 1990. Deducing linguistic struc-\nture from the statistics of large corpora.\nIn\nDARPA Speech and Natural Language Workshop.\n[Church1989] K W Church, Bell Laboratories. 1989.\nA stochastic parts program and noun phrase\nparser for unrestricted text. In IEEE conference\nrecord of ICASSP.\n[Garcia and Vidal1990] P Garcia and E Vidal. 1990.\nInference of k-testable languages in the strict sense\nand application to syntactic pattern recognition.\nIEEE Trans. on Pattern Analysis and Machine\nIntelligence, 12.\n[Garside1987] R Garside. 1987. The CLAWS word-\ntagging system.\nIn R Garside, G Leech, and\nG Sampson, editors, The Computational Analysis\nof English: a corpus based approach. Longman.\n[Gold1967] E M Gold. 1967. Language identiﬁcation\nin the limit. Information and Control, 10.\n[Lyon1994] C Lyon. 1994. The representation of nat-\nural language to enable neural networks to detect\nsyntactic features. PhD thesis.\n[Lyon1993] C Lyon 1993. Using neural networks to\ninfer grammatical structures in natural language.\nIn Proc. of IEE Colloquium on Grammatical In-\nference.\n[Lyon and Frank1992] C Lyon and R Frank\n1992.\nDetecting structures in natural language using\na neural net with rules.\nIn Proc. of Interna-\ntional Conference on Artiﬁcial Neural Networks\n(ICANN).\n[Niles and Silverman1990] L Niles and H Silverman.\n1990.\nCombining Hidden Markov Models and\nNeural Network Classiﬁers. In IEEE conference\nrecord of ICASSP.\n[Pao1989] Yoh-Han Pao.\n1989.\nAdaptive Pattern\nRecognition and Neural Networks. Addison Wes-\nley.\n[Pocock and Atwell1994] R Pocock and E Atwell.\n1994.\nTreebank trained probabilistic parsing of\nlattices.\nSchool of Computer Studies, Leeds\nUniversity. In The Speech-Oriented Probabilistic\nParser Project: Final Report to MoD.\n[Pym1993] P Pym. 1993. Perkins Engines and Pub-\nlications. In Proceedings of Technology and Lan-\nguage in Europe 2000. DGXIII-E of the European\nCommission.\n[Rumelhart and McClelland1986] D Rumelhart and\nJ McClelland. 1986. Parallel Distributed Process-\ning MIT.\n[Shannon1951] C E Shannon 1951. Prediction and\nEntropy of Printed English. In Bell System Tech-\nnical Journal.\n[Widrow and Lehr1992] B\nWidrow\nand\nM\nLehr.\n1992.\n30 years of adaptive neural networks.\nIn Neural networks: theoretical foundations and\nanalysis edited by C Lau. IEEE press.\n[Wyard and Nightingale1990] P\nWyard\nand\nC Nightingale.\n1990.\nA Single Layer Higher\nOrder Neural Net and its Application to Con-\ntext Free Grammar Recognition\nIn Connection\nScience, 4.\n",
  "categories": [
    "cmp-lg",
    "cs.CL"
  ],
  "published": "1995-03-22",
  "updated": "1995-03-22"
}