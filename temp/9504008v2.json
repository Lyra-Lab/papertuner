{
  "id": "http://arxiv.org/abs/cmp-lg/9504008v2",
  "title": "SKOPE: A connectionist/symbolic architecture of spoken Korean processing",
  "authors": [
    "Geunbae Lee",
    "Jong-Hyeok Lee"
  ],
  "abstract": "Spoken language processing requires speech and natural language integration.\nMoreover, spoken Korean calls for unique processing methodology due to its\nlinguistic characteristics. This paper presents SKOPE, a connectionist/symbolic\nspoken Korean processing engine, which emphasizes that: 1) connectionist and\nsymbolic techniques must be selectively applied according to their relative\nstrength and weakness, and 2) the linguistic characteristics of Korean must be\nfully considered for phoneme recognition, speech and language integration, and\nmorphological/syntactic processing. The design and implementation of SKOPE\ndemonstrates how connectionist/symbolic hybrid architectures can be constructed\nfor spoken agglutinative language processing. Also SKOPE presents many novel\nideas for speech and language processing. The phoneme recognition,\nmorphological analysis, and syntactic analysis experiments show that SKOPE is a\nviable approach for the spoken Korean processing.",
  "text": "arXiv:cmp-lg/9504008v2  25 Apr 1995\nSKOPE: A connectionist/symbolic architecture of spoken Korean\nprocessing\nGeunbae Lee and Jong-Hyeok Lee\nDepartment of Computer Science & Engineering\nand Postech Information Research Laboratory\nPohang University of Science & Technology\nSan 31, Hoja-Dong, Pohang, 790-784, Korea\ngblee@vision.postech.ac.kr\nAbstract\nSpoken language processing requires speech and nat-\nural language integration.\nMoreover, spoken Korean\ncalls for unique processing methodology due to its lin-\nguistic characteristics. This paper presents SKOPE, a\nconnectionist/symbolic spoken Korean processing en-\ngine, which emphasizes that: 1) connectionist and sym-\nbolic techniques must be selectively applied accord-\ning to their relative strength and weakness, and 2)\nthe linguistic characteristics of Korean must be fully\nconsidered for phoneme recognition, speech and lan-\nguage integration, and morphological/syntactic pro-\ncessing.\nThe design and implementation of SKOPE\ndemonstrates how connectionist/symbolic hybrid ar-\nchitectures can be constructed for spoken agglutina-\ntive language processing. Also SKOPE presents many\nnovel ideas for speech and language processing. The\nphoneme recognition, morphological analysis, and syn-\ntactic analysis experiments show that SKOPE is a vi-\nable approach for the spoken Korean processing.\nIntroduction\nSpoken language processing challenges for integration\nof speech recognition into natural language processing,\nand must deal with multi-level knowledge sources from\nsignal level to symbol level. The multi-level knowledge\nintegration and handling increase the technical diﬃ-\nculty of both the speech and the natural language pro-\ncessing. In the speech recognition side, the recognition\nmust be at phoneme-level for large vocabulary contin-\nuous speech, and the speech recognition module must\nprovide right level of outputs to the natural language\nmodule in the form of not single solution but many\nalternatives of solution hypotheses.\nThe n-best list\n(?), word-graph (?), and word-lattice (?) techniques\nare mostly used in this purpose. The speech recogni-\ntion module can also ask the linguistic scores from the\nlanguage processing module in a more tightly coupled\nbottom-up/top-down hybrid integration scheme (?). In\nthe natural language side, the insertion, deletion, and\nsubstitution errors of continuous speech must be com-\npensated by robust parsing and partial parsing tech-\nCopyright c⃝2018, American Association for Artiﬁcial In-\ntelligence (www.aaai.org). All rights reserved.\nniques, e.g. (?). Often the spoken languages are un-\ngrammatical, fragmentary, and contain non-ﬂuencies\nand speech repairs, and must be processed incremen-\ntally under the time constraints (?).\nMost of the speech and natural language systems\nwhich were developed for English and other Indo-\nEuropean languages neglect the morphological process-\ning, and integrate speech and natural language at the\nword level (?; ?). Often these systems employ a pro-\nnunciation dictionary for speech recognition and inde-\npendent dictionaries for natural language processing.\nHowever, for the agglutinative languages such as Ko-\nrean and Japanese, the morphological processing plays\na major role in the language processing since these lan-\nguages have very complex morphological phenomena\nand relatively simple syntactic functionality. Unfortu-\nnately even the Japanese researchers apply degenerated\nmorphological techniques for the spoken Japanese pro-\ncessing (?; ?).\nObviously degenerated morphological\nprocessing limits the usable vocabulary size for the sys-\ntem, and word-level dictionary results in exponential\nexplosion in the number of dictionary entries. For the\nagglutinative languages, we need sub-word level inte-\ngration which leaves rooms for general morphological\nprocessing.\nThe spoken language processing calls for multi-\nstrategic approaches in order to deal with signal level\nas well as symbol level information in a symbiotic\nand uniﬁed way.\nRecent development of connection-\nist speech recognition (?)\nand connectionist natural\nlanguage processing (?)\nshed lights on the connec-\ntionist/symbolic hybrid models of spoken language pro-\ncessing, and some of the researches are already avail-\nable for English and other Indo-European languages (?;\n?). We feel that it is the right time to develop con-\nnectionist/symbolic hybrid spoken languages process-\ning systems for the agglutinative languages such as Ko-\nrean and Japanese.\nThis paper presents one of the such endeavors,\nSKOPE (Spoken Korean Processing Engine), that has\nthe following unique features: 1) The connectionist and\nsymbolic techniques are selectively used according to\ntheir strength and weakness. The learning capability,\nfault-tolerant property, and ability of simultaneous inte-\ngration of multiple signal-level sources make the connec-\ntionist techniques suitable to the phoneme recognition\nfrom the speech signals, but the structure manipula-\ntion and powerful matching (binding) properties of the\nsymbolic techniques are the better choices for the com-\nplex morphological processing of Korean. However, the\nparallel multiple constraint relaxation capability of the\nconnectionist techniques are applied together with the\nsymbolic structure binding techniques for the syntactic\nprocessing. 2) The linguistic characteristics of Korean\nare fully considered in phoneme recognition, speech and\nlanguage integration, and morphological/syntactic pro-\ncessing. 3) The SKOPE provides multi-level applica-\ntion program interfaces (APIs) which can utilize the\nphoneme-level or the morphological level or the syn-\ntactic level services for the applications such as spoken\nlanguage interface, voice information retrieval and spo-\nken language translation.\nWe hope the experience of SKOPE development pro-\nvide viable answers to some of the open questions to the\nspeech and language processing, such as 1) how learning\nand encoding can be synergetically combined in speech\nand language processing, 2) which aspects of system\narchitecture have to be considered in spoken language\nprocessing, especially in connectionist/symbolic hybrid\nsystems, and ﬁnally 3) what are the most eﬃcient way\nof speech and language integration, especially for ag-\nglutinative languages.\nCharacteristics of spoken Korean\nThis section brieﬂy explains the linguistic characterists\nof spoken Korean before describing the SKOPE sys-\ntem. In this paper, Yale romanization is used for rep-\nresenting the Korean phonemes.\n1) A Korean word,\ncalled Eojeol, consists of more than one morphemes\nwith clear-cut morpheme boundaries.\n2) Korean is\na postpositional language with many kinds of noun-\nendings, verb-endings, and preﬁnal verb-endings. These\nfunctional morphemes determine the noun’s case roles,\nverb’s tenses, modals, and modiﬁcation relations be-\ntween Eojeols. 3) Korean is a basically SOV language\nbut has relatively free word order compared to the rigid\nword-order languages, such as English, except for the\nconstraints that the verb must appear in a sentence-\nﬁnal position. However, in Korean, some word-order\nconstraints do exist such that the auxiliary verbs repre-\nsenting modalities must follow the main verb, and the\nmodiﬁers must be placed before the word (called head)\nthey modify. 4) The unit of pause in speech (which is\ncalled Eonjeol) may be diﬀerent from that of a written\ntext (an Eojeol). The spoken morphological analysis\nmust deal with an Eonjeol since no Eojeol boundary\ncan be provided in the speech. 5) Phonological changes\ncan occur in a morpheme, between morphemes in an\nEojeol, and even between Eojeols in an Eonjeol. These\nchanges include consonant and vowel assimilation, dis-\nsimilation, insertion, deletion, and contraction. 6) Ko-\nrean has many rising diphthongs that are very similar to\nsyntactic\nstructure\nAPI\nSKOPE\nphoneme\nrecognition\nmorphological\nanalysis\nsyntax\nanalysis\nspeech input\nmorpheme\nsequence\nAPI\nphoneme\nsequence\nAPI\nphoneme\nlatttice\nmorpheme\nlattice\nFigure 1: The spoken Korean processing engine archi-\ntecture. The architecture has two-level interfaces be-\ntween modules: phoneme lattice and morpheme lattice\nfor eﬃcient and generalized speech and natural lan-\nguage integration.\nmono-vowels at signal level. Korean has well-developed\nsyllable structures, and unlike Japanese that has only\nCV1 type syllable, Korean has all diﬀerent types such\nas CV, VC, V, CVC. Moreover, in CVC type syllable,\nﬁrst and second consonants are almost same in pronun-\nciation. These signal characteristics make it diﬃcult to\ndirectly use phonemes or syllables as sub-word recogni-\ntion units.\nThe SKOPE architecture\nThe above spoken Korean characteristics and the rel-\native strength and weakness of symbolic/connectionist\ntechniques result in the general SKOPE architecture\nwhich is shown in ﬁgure 1.\nThe architecture con-\nsists of three diﬀerent but closely interrelated modules:\nphoneme recognition, morphological analysis, and syn-\ntactic analysis module. The phoneme recognition mod-\nule processes the signal-level information, and changes\nit to the symbol-level information (phoneme lattice).\nThe morphological analysis begins the primitive lan-\nguage processing, and connects the speech recognition\nto the language processing at the phoneme-level. The\nsyntactic analysis module ﬁnishes the language process-\ning2, and produces the domain independent syntactic\nstructures for application systems. The following sub-\nsections brieﬂy describe each module.\n1C: consonant, V: vowel\n2We believe that the semantic and pragmatic processing\nshould be integrated into the domain knowledge for prac-\ntical application under the current NLP technology, so we\nexcluded the semantic and pragmatic processing from our\ngeneral model.\ndiphone \ndiphone\nnumbers\ndiphone \nexamples\nV                   21                        a, o, wu, i, u, ye, .....\nC1V              378                       ha, sa, ka, la, ma, kha, ......\nVC2              147                       an, am, eng, em, wun, in, ......\nC2C1            126                       ngs, nn, ngt, ngh, ....\ntypes\nFigure 2:\nFour diﬀerent Korean diphone types (V:\nvowel, C1: syllable-ﬁrst consonant, C2: syllable-ﬁnal\nconsonant)\nDiphone-based connectionist phoneme\nrecognition\nThe phoneme recognition is performed by developing\nthe hierarchically organized group of TDNNs (time de-\nlay neural networks) (?). Considering the signal char-\nacteristics of the Korean phonemes, we deﬁne diphones\nas a new sub-word recognition unit.\nThe deﬁned di-\nphones are shown in ﬁgure 2, and are classiﬁed into four\ndiﬀerent types. The diphones have the co-articulation\nhandling features similar to the popular triphones (?)\nbut are much fewer in numbers.\nFigure 3 shows the architecture of the component\nTDNNs in the phoneme recognition module. The whole\nmodule consists of total 19 diﬀerent TDNNs for recog-\nnition of the deﬁned Korean diphones. The top-level\nTDNN identiﬁes the 18 vowel groups of diphones (we re-\nclassiﬁed the total 672 diphones into 18 diﬀerent groups\naccording to the vowels that are contained in the di-\nphones).\nThe 18 diﬀerent sub-TDNNs recognize the\ntarget diphones.\nFor the training of TDNNs, we manually segment the\ndigitized speech into 200 msec range (which includes\nroughly left-context phoneme, target diphone, and right\ncontext phoneme), and perform 512 order FFTs and\n16 step mel-scaling (?)\nto get the ﬁlter-bank coeﬃ-\ncients. Each frame size is 10 msec, so 20 (frames) by\n16 (mel-scaling factor) values are fed to the TDNNs\nwith the proper output symbols, that is, vowel group\nname or target diphone names. After the training of\neach TDNN, the phoneme recognition is performed by\nfeeding 200 msec signals to the vowel group identiﬁca-\ntion network and subsequently to the proper diphone\nrecognition network. The 200 msec signals are shifted\nby 30 msec steps and continuously fed to the networks\nto process the continuous speech in an Eonjeol. From\nthe resulting diphone sequences, the necessary phoneme\nlattice has to be constructed. We use a simple deter-\nministic decoding heuristics and try to maintain all the\npossible diphone spotting results since the later phono-\nlogical/morphological processing can safely prune the\nincorrect recognitions. The decoding begins by group-\ning the diphones into the same types (see ﬁgure 2). The\nfrequency count for each diphone, that is, the number\nof speciﬁc diphones per 30 msec frame shift, is utilized\n(a)\n(b)\n16\n33\n18\n1\na e o ey i ......................cc \na an ha sa ka la ma ....  am \n1\n16\n33\n18\n18\n13\n9\n18\n20 frames\n20 frames\n18\n9\nFigure 3: (a) The TDNN architecture for the vowel\ngroup identiﬁcation.\nNote the cc group contains no\nvowels.\n(b) The architecture of sub-TDNNs for /a/\nvowel group. The other 17 sub-TDNNs have the same\narchitecture, but diﬀerent number of output units ac-\ncording to the number of diphones in each of the vowel\ngroup.\nto ﬁx the insertion errors by deleting the lower fre-\nquency count diphones, and ﬁnally the diphones are\nsplit into the constituent phonemes by merging the\nsame phonemes in the neighboring diphones.\nTable-driven morphological and\nphonological analysis\nThe morphological analysis starts with the phoneme\nlattice.\nThe phoneme lattice delivers the alternative\nphonetic transcriptions3 of input speech, which must be\nsearched by the morphological/phonological analyzer to\nreconstruct the orthographic morpheme strings. The\nconventional morphological analysis procedure (?), that\nis, morpheme segmentation, morphotactics modeling,\nand orthographic rule (or phonological rule) modeling,\nmust be augmented and extended as the followings: 1)\nThe conventional morpheme segmentation is extended\nto deal with the exponential number of phoneme se-\nquences and between-morpheme phonological changes\nduring the segmentation, 2) the morphotactics model-\ning is extended to cope with the complex verb and noun-\nendings (or postpositions), and 3) the orthographic rule\nmodeling is combined with the phonological rule mod-\neling to correctly transform the phonetic transcriptions\nto the orthographic morpheme sequences.\nThe central part of the morphological analysis lies\nin the dictionary construction. In our dictionary, each\n3Unlike English, the Korean alphabet is truly phonetic\nin the sense that each phoneme is pronounced as it is writ-\nten. That is why we sometimes use phonetic and phonemic\ninterchangeably.\nphonetic\ntranscription\nheader\nno-change\n‘wu‘ sound\nno-change\nverb-ending\nadnominalizing\nverb-ending\n‘l‘ sound\nno-change\n‘l‘ sound\nno-change\n‘wu‘ sound\nno-change\nadnominalizing\nl                               l \nchange to ‘ss‘ \nsswu                  swu                     bound-noun          bound-noun       ‘s’ sound\noriginal\nmorpheme\nleft\nconnectivity\nconnectivity\nright\nmorphological\nmorphological\nci-wu                 ci-wu                regular verb          regular verb          ‘c‘ sound\nconnectivity\nleft\nconnectivity\nright\nphonemic\nphonemic\nFigure 4: The morpheme-level phonetic dictionary.\nc      i       wu     l        ss      wu\nu\nu\nk\n1       2        3        4         5            6 \n1\n2\n3\n4\n5\n6\nstarting\nposition\nending position\nciwu+l+swu\n ciwu\nl\nciwu+l\nswu\nssu\n ki\nul\nciwu+ l + swu\nFigure 5: Morphological parsing of the phoneme lattice\n(from top: output morpheme sequence in an Eonjeol,\ntriangular parsing table, input phoneme lattice).\nphonetic transcription of single morpheme has a sepa-\nrate dictionary entry. Figure 4 shows the uniﬁed dic-\ntionary both for speech and language processing (called\nmorpheme-level phonetic dictionary) with three diﬀer-\nent morpheme entries ci-wu, l, swu.\nThe extended morphological analysis is based on the\nwell-known tabular parsing technique for context-free\nlanguage (?)\nand augmented to handle the Korean\nphonological rules and phoneme-lattice input. Figure 5\nshows our extended table-driven morphological anal-\nysis process.\nThe example phoneme lattice was ob-\ntained from the input speech ci-wul-sswu (removable),\nand the morphological analysis produces ci-wu+l+swu\n(remove+ADNOMINAL+BOUND-NOUN), where ’+’\nis the morpheme boundary, and ’-’ is the syllable bound-\nary.\nThe extended morpheme segmentation is basically\nperformed using the dictionary search. During the left-\nto-right scan of the input phoneme lattice, when a mor-\npheme boundary is found in the lattice, the morpheme\nis enrolled in the triangular table in an appropriate po-\nsition.\nFor example, in ﬁgure 5, morphemes such as\nci-wu, l, swu, etc are enrolled in the table position\n(1,3), (4,4), (5,6), etc.\nThe position (i,j) designates\nthe starting and ending position of the enrolled mor-\nphemes. However since the input is a phoneme-lattice,\ntotal exponential time is required to ﬁnd all the possible\nmorpheme boundaries. To cope with such exponential\nexplosion, the dictionary is organized as trie structure\n(?)\nusing the phonetic transcriptions as trie indices,\nand breadth-ﬁrst search of the trie can prune the un-\nnecessary phoneme sequences earlier in the search.\nThe morphotactics modeling is necessary after all\nthe morphemes are enrolled in the table in order to\ncombine only legal morphemes into an Eojeol (Ko-\nrean word), and the process is called morpheme-\nconnectivity-checking. Since Korean has well developed\npostpositions (noun-ending, verb-ending, preﬁnal verb-\nending) which play as grammatical functional mor-\nphemes, we must assign each morpheme proper part-of-\nspeech (POS) tags for the eﬃcient connectivity check-\ning. Our more than 200 POS tags which are reﬁned\nfrom the 13 major Korean lexical categories are hierar-\nchically organized, and contained in the dictionary (in\nthe name of morphological connectivity, see ﬁgure 4).\nIn the case of idiomatic expressions, we place such id-\nioms directly in the dictionary for eﬃciency, where two\ndiﬀerent POS tags are necessary for the left and the\nright morphological connectivity. For single morpheme,\nthe left and the right POS tags are always same. The\nseparate morpheme-connectivity-matrix indicates the\nlegal morpheme combinations, and the morphotactics\nmodeling is performed using the POS tags (in the dic-\ntionary) and morpheme-connectivity-matrix.\nThe orthographic rule modeling must be integrated\nwith the phonological rule modeling in spoken language\nprocessing. Since we must deal with the phoneme lat-\ntice, the conventional rule-based modeling requires ex-\nponential number of rule application (?).\nSo our so-\nlution is based on the declarative modeling of both or-\nthographic and phonological rules in uniform way. That\nis, in our dictionary, the conjugated verb forms as well\nas the original verb forms are enrolled, and the same\nmorphological connectivity information is applied. The\nphonological rule modeling is also accomplished declar-\natively by having the phonemic connectivity informa-\ntion in the dictionary. The phonemic connectivity infor-\nmation for each morpheme declares the possible phone-\nmic changes in the ﬁrst (left) and last (right) positioned\nphonemes in the morpheme, and the separate phoneme-\nconnectivity-matrix indicates the legal sound combina-\ntions in Korean phonology. For example, in ﬁgure 5, the\nmorpheme l can be combined with the morpheme swu\nduring the morpheme connectivity checking even if swu\nis actually pronounced as sswu because the phoneme-\nconnectivity-matrix supports the legality of the combi-\nnation of l sound with ss sound4. In this way, we can\ndeclaratively model all the major Korean phonology\nrules such as second consonant standardization, con-\nsonant assimilation, palatalization, glotalization, inser-\ntion, deletion, and contraction.\nTable-driven connectionist/symbolic\nsyntax analysis\nThe phoneme lattice-based morphological analysis pro-\nduces the morphologically analyzed (segmented and\nstem reconstructed) morpheme sequences. Since there\nare usually more than one analysis results due to the\nerrors of speech recognition process, the outputs are\nusually organized as morpheme lattice. For the seam-\nless integration of the morphological analysis with the\nsyntax analysis, we employ the same table-driven con-\ntrol for the syntax analysis as well as the morphological\nanalysis.\nWe extend the category formation and functional\napplication rules in the previous categorial uniﬁcation\ngrammar(?; ?) to deal with the word order variations\nin Korean:\n• if category a ∈C, then a ∈C’\n• if category a ∈C’, and category set S ∈C’, then a/S\n∈C’ and a\\S ∈C’\nwhere S is an unordered set of categories.\n• left cancellation:\nai b\\{a1,a2, . . . , an} results in\nb\\{a1, a2, . . . , ai−1, ai+1, . . . , an}\n• right cancellation: b/{a1,a2, . . . , an} ai results in\nb/{a1, a2, . . . , ai−1, ai+1, . . . , an}\nThe syntax analysis is performed by interactive relax-\nation (spreading activation) parsing on the categorial\ngrammar where the position of the functional applica-\ntions are controlled by a triangular table. The original\ninteractive relaxation parsing (?) was extended to pro-\nvide eﬃcient constituent searching and expectation gen-\neration through positional information provided by cat-\negorical grammar and triangular table. Figure 6 shows\ntable-driven interactive relaxation parsing.\nThe interactive relaxation process consists of the fol-\nlowing three steps that are repetitively executed: 1) add\nnodes, 2) spread activation, and 3) decay.\nadd nodes Grammar nodes (syntactic categories from\nthe dictionary) are added for each sense of the\nmorphemes when the parsing begins.\nA grammar\nnode which has more activation than the predeﬁned\nthreshold Θ generates new nodes in the proper po-\nsitions (to be discussed shortly). The newly gener-\nated nodes search for the constituents (expectations)\nwhich are in the appropriate table positions, and are\nof proper function applicable categories. For exam-\nple, in ﬁgure 6, when np\\np(2,2) ﬁres, it generates\n4This legality comes from the Korean phonology rule\nglotalization (one form of consonant dissimilation) stating\nthat s sound becomes ss sound after l sound.\n1\n2\n3\n4\n 5\n1         2           3           4               5 \nending position\nstarting\nposition\nphail       tul         ul            ciwu           ela\nnp\nnp\\np\nobj\\np\ns\\{subj,obj}\ncomm\\(s\\subj)\nnp\nobj\ns\\subj\ncomm\nFigure 6: Table-driven interactive relaxation parsing of\na categorial grammar. The input sentence is phai-l-tul-\nul ciwu-ela (delete the ﬁles).\nOnly single morpheme\nchain and only one sense for each morpheme is shown\nas input for clear illustration. The subj, obj, comm in-\ndicate np[subj], np[obj], s[command], respectively. The\ntable contains only the nodes that participate in the\nﬁnal parse trees.\nnp(1,2). The generated np(1,2) searches for the con-\nstituents np(1,1) to be combined with np\\np(2,2).\nspread activation The bottom-up spreading activa-\ntion is as follows:\nn × ρ × a ×\nai2\nPn\nj=1 aj 2\nwhere predeﬁned portion ρ of total activation a is\npassed upward to the node with activation ai among\nthe n parents each with node activation aj. In other\nwords, the node with large activation gets more and\nmore activation, and it gives an inhibition eﬀects\nwithout explicit inhibitory links (?). The top-down\nspreading activation uniformly distributes:\nρ′ × a\namong the children where ρ’ is predeﬁned portion of\nthe source activation a.\ndecay The node’s activation is decayed with time. The\nnode with less constituents than needed gets penal-\nties plus decays:\na × (1 −d) × Ca\nCr\nwhere a is an activation value, d is a decay ratio, and\nCa, Cr is the actual and required constituents. Af-\nter the decay, the node with less activation than the\npredeﬁned threshold Φ is removed from the table.\nThe node generation and constituent search positions\nare controlled by the triangular table. When the node\na(i,j) acts as an argument, it generates node only in\nthe position (k,j) where 1 < k < j, and the generated\nnode searches for the constituents (functors) only in the\nposition (k,i-1). Or when the node is generated in the\nposition (i,k) where j < k < number−of−morphemes,\nit searches for the position (j+1,k) for its constituents.\nWhen the node acts as a functor, the same position re-\nstrictions also apply for the node generation and the ar-\ngument searching. The position control combined with\nthe interactive relaxation guarantees an eﬃcient, lex-\nically oriented, and robust syntax analysis of spoken\nlanguages.\nImplementation and experiments\nThe SKOPE was fully implemented in UNIX/C plat-\nform, and have been extensively tested in practical do-\nmains such as natural language interface to operating\nsystems. The phoneme recognition module targets 1000\nmorpheme continuous speech, currently speaker depen-\ndent due to the short of standard speech database for\nKorean. The uniﬁed morpheme-level phonetic dictio-\nnary has about 1000 morpheme entries and compiled\ninto the trie structure.\nThe morpheme-connectivity-\nmatrix and phoneme-connectivity-matrix are encoded\nwith the special Korean POS (part-of-speech) symbols\nand compressed.\nThis section demonstrates the SKOPE’s performance\nin continuous diphone recognition, morphological anal-\nysis, and syntax analysis experiments.\nFor the con-\ntinuous diphone recognition experiment, we generated\nabout 5500 diphone patterns from the 990 Eojeol pat-\nterns (66 Eojeols, 15 times pronunciation) for the train-\ning of TDNNs.\nIn the performance phase, the new\n2600 test Eojeol patterns (260 Eojeol, 10 times pro-\nnunciation) are continuously shifted with 30 msec step,\nand generate 7772 test diphone patterns disjoint from\nthe training patterns.\nFigure 7-a shows the continu-\nous diphone recognition performance. The correct des-\nignates that the correct target diphones were spotted\nin the testing position, and the delete designates the\nother case. The insert designates that the non-target\ndiphones were spotted in the testing position. To com-\npare the ability of handling the continuous speech, we\nalso tested the diphone recognition using the hand-\nsegmented test patterns with the same 7772 target di-\nphones. Figure 7-b shows the segmented diphone recog-\nnition performance.\nSince the test data are already\nhand-segmented before input, there are no insertion and\ndeletion errors in this case. The fact that the segmented\nspeech performance is not much better than the contin-\nuous one (93.8% vs. 93.4%) demonstrates the diphone’s\nsuitability to handling the continuous speech.\nFor the morphological analysis performance, we used\nthe same 990 Eojeol patterns to train the phoneme\nrecognition module, and the 2600 Eojeol patterns to\ntest the morphological analysis performance directly\nfrom the speech input. Figure 8 shows the results.\nThis experiment shows that most of the morphologi-\ncal errors are propagated from the incorrect (deleted) or\nspurious (inserted) phoneme recognition results. To see\nthe original performance of the morphological and syn-\ntactic analysis modules assuming no speech recognition\npattern size\n total            correct           delete            insert\n7772        7259 (93.4%)     513 (6.6%)    3000 (38.6%)\n(rec. rate)\nrec. rate        94.8%                        98.2%                               93.8% \nvowel group    sub-TDNNs average     total average\n(a) continuous diphones\n(b) segmented diphones\nFigure 7: (a) Continuous diphone recognition versus (b)\nsegmented diphone recognition\nnumber of\nmorphemes\ntotal         correct         deleted        inserted\n           1909              7182\n9605        7696\n (80.1%)        (19.8%)\nFigure 8:\nMorphological analysis from continuous\nspeech signals. The table indicates that, among the to-\ntal 9605 morphemes in 2600 Eojeol patterns, the 80.1%\nare correctly recognized and analyzed, and 19.8% can-\nnot be analyzed for deletion errors. The 7182 spurious\nmorphemes are also generated due to the speech inser-\ntion errors.\nerror, we artiﬁcially made the phoneme lattices by mu-\ntating the correctly recognized phoneme sequences ac-\ncording to the phoneme recognizer’s confusion matrix.\nEach phoneme lattice was made to contain at least one\ncorrect recognition result, so the phoneme recognition\nperformance is assumed to be perfect except the arti-\nﬁcially made insertion errors (mutations). In this way,\nwe made 6 or 7 lattices for each of the 50 sentences,\naltogether 330 phoneme lattices. The average phoneme\nalternatives per single correct phoneme in the lattice\nare 2.3, and average sentence length is 31 phonemes.\nThis means there are average 2.331 phoneme chains in\neach lattice. The used sentences are natural language\ncommands to UNIX (?) and are fairly complex which\nhave one or two embedded sentences or conjunctions.\nFigure 9 shows the morphological and syntactic analy-\nsis results for these artiﬁcially made phoneme lattices.\nFor the syntactic level interactive relaxation, we used\nthe following parameters (which are experimentally de-\ntermined): upward propagation portion ρ 0.05, down-\nward propagation portion ρ’ 0.03, decay ratio d 0.87,\nthe node generation threshold Θ 0.51, and the node\nremoval threshold Φ 0.066.\nThe morphological analysis was perfect as shown in\nthe table. Since the phoneme lattice was made to con-\ntain at least one correct phoneme recognition result,\nthe morphological analysis must be perfect as long as\nthe morpheme is enrolled in the dictionary and the con-\nnectivity information can cover all the morpheme com-\nbinations. This was possible due to the small number\nof tested sentences (50 sentences). This results verify\nmorphological\ntotal sentences             correctly analyzed sentences\nsyntactic\n330\n330\n 330 \n117 (35.5%) \n(1-best)\nFigure 9:\nThe morphological and syntactic analysis\nfrom the artiﬁcially made phoneme lattices.\nthat most of the morphological analysis errors from real\nspeech input are actually propagated from the phoneme\nrecognition errors as discussed before.\nHowever, the\nsyntax analysis results are marginal here since we only\ncount the single best scored tree, and we don’t use yet\nany semantic feature in the analysis. The syntax anal-\nysis failures mainly come from 1) the insertion errors\n(artiﬁcial mutations) in the phoneme lattices5, which\nresult in ambiguous morpheme lattice, and ﬁnally pro-\nduce redundant syntax trees, and 2) the inherent struc-\ntural ambiguities in the sentence. These failures should\nbe greatly reduced if we generate n-best scored parse\ntrees, and let the semantic processing module select the\ncorrect ones as is usually done in most of the probabilis-\ntic parsing schemes(?).\nConclusions and future works\nThis paper explains the design and implementation\nof spoken Korean processing engine, which is a con-\nnectionist/symbolic hybrid model of spoken language\nprocessing by utilizing the linguistic characteristics of\nKorean. The SKOPE model demonstrates the syner-\ngetic integration of connectionist and symbolic tech-\nniques by considering the relative strength and weak-\nness of two diﬀerent techniques, and also demonstrates\nthe phoneme level speech and language integration for\ngeneral morphological processing for agglutinative lan-\nguages.\nBesides the above two major contributions,\nthe SKOPE architecture has the following unique fea-\ntures in spoken language processing: 1) the diphones\nare newly developed as a sub-word recognition unit for\nconnectionist Korean speech recognition, 2) the mor-\nphological and syntactic analysis are tightly coupled by\nusing the uniform table-driven control, 3) the phonolog-\nical and orthographic rules are uniformly co-modeled\ndeclaratively, and 4) the table-driven interactive relax-\nation parsing and extension of the categorial grammar\ncan provide robust handing of word-order variations in\nKorean.\nHowever, current implementation of the system still\nsuﬀers from excessive continuous speech recognition er-\nrors.\nSince the large vocabulary continuous speech\nrecognition is still an open problem, we cannot hope\nfor the 100% correct speech recognition results in the\nnear future. Currently, we are pursuing multi-strategic\n5Recall we generated average 2.3 phonemes per single\ncorrect phoneme.\napproaches to the advanced spoken language process-\ning model, including optimizing TDNN-based phoneme\nrecognition module, integrating HMM-based morpheme\nrecognition module into the connectionist phoneme\nrecognition, and incorporating probabilistic searches\ninto the morphological analysis process as well as the\nsyntactic analysis process. We are also developing ap-\nplications on top of our SKOPE, including speech-to-\nspeech translation system and intelligent interface agent\nfor UNIX operating system.\nWe hope our approach\ncould be extended to other agglutinative languages such\nas Japanese, Finish, and Turkish, and also to the lan-\nguages that have complex morphological phenomena\nsuch as German and Dutch.\nAcknowledgments\nThis research was supported partly by a grant from\nKOSEF (Korea Science and Engineering Foundation)\nand PIRL (Postech Information Research Laboratory).\nThe SKOPE’s various modules were programmed by\nour students:\nthe phoneme recognition module by\nKyunghee Kim & Kyubong Baac, the morphological\nanalysis module by EunChul Lee & Wonil Lee, and ﬁ-\nnally the syntax analysis module by Wonil Lee.\n",
  "categories": [
    "cmp-lg",
    "cs.CL"
  ],
  "published": "1995-04-07",
  "updated": "1995-04-25"
}