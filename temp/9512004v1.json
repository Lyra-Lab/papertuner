{
  "id": "http://arxiv.org/abs/cmp-lg/9512004v1",
  "title": "Natural language processing: she needs something old and something new (maybe something borrowed and something blue, too)",
  "authors": [
    "Karen Sparck Jones"
  ],
  "abstract": "Given the present state of work in natural language processing, this address\nargues first, that advance in both science and applications requires a revival\nof concern about what language is about, broadly speaking the world; and\nsecond, that an attack on the summarising task, which is made ever more\nimportant by the growth of electronic text resources and requires an\nunderstanding of the role of large-scale discourse structure in marking\nimportant text content, is a good way forward.",
  "text": "arXiv:cmp-lg/9512004v1  21 Dec 1995\nNatural language processing:\nshe needs something old and something new\n(maybe something borrowed and something blue, too)\nKaren Sparck Jones\nComputer Laboratory, University of Cambridge\nNew Museums Site, Pembroke Street, Cambridge CB2 3QG, England\nksj@cl.cam.ac.uk\nPresidential Address, June 1994, Association for Computational Linguistics\nAbstract\nGiven the present state of work in natural language processing, this\naddress argues ﬁrst, that advance in both science and applications requires\na revival of concern with what language is about, broadly speaking the\nworld; and second, that an attack on the summarising task, which is made\never more important by the growth of electronic text resources and requires\nan understanding of the role of large-scale discourse structure in marking\nimportant text content, is a good way forward.\nI want to assess where we are now, in computational linguistics and natural\nlanguage processing, compared with where we started, and to put my view of\nwhat we need to do next. We should not cut oﬀthe past too soon, but keep a\nsense of perspective so that we can properly judge what advance we are making,\ni.e. whether progress is real or illusory, forward or sideways and, if real, how\ngood relative to our desired end point and not just our beginning one.\nComputational linguistics, or natural language processing (NLP), is nearly\nas old as serious computing. Work began more than forty years ago, and one\ncan see it going through successive phases, roughly ten year periods from the\nlate ﬁfties onwards. I have discussed these phases more fully elsewhere (KSJ94),\nso I will say only enough about them here to provide a context for my later\nargument.\nThe ﬁrst phase, beginning in the late ﬁfties, was linguistically oriented,\nfocusing on machine translation, with people learning, painfully, how to do\nthings computationally.\nThe second phase, from the late sixties to the late\nseventies, recognised the role of real world knowledge, was strongly motivated\n1\nby AI, and drove NLP from this. The third phase, dominating the eighties, ac-\nknowledged the speciﬁc modulating or controlling function for language relative\nto the world, and tried to capture this, in its necessarily systematic aspect, in\ngrammatico-logical models for NLP. The fourth phase, that we are in now, while\ntaking the grammatico-logical skeleton for granted, recognises the signiﬁcance\nof actual language usage, both idiosyncrastic and habitual, as a constraint on\nperformance, and is therefore heavily into data mining from corpora.\nAll of these phases have contributed something to the growth of knowhow.\nBut what can we actually do now, given NLP’s necessary concerns both with\ngeneric capabilities like syntactic parsing and with particular tasks like trans-\nlation, i.e. with both subsystem and whole system functions?\nWhat I see as most signiﬁcant are the following.\nFirst, we have engines, reasonably solid generic systems with decent cover-\nage, that we can put to work in interpretation to deliver semantic representa-\ntions for sentences or, in generation, to deliver sentences from representations:\nfor example SRI, BBN, NYU or ISI’s systems. We have, that is, more than\nsubfunction components: we have respectably engineered multi-component sys-\ntems.\nSecond, we can build tightly-targeted application systems for speciﬁc pur-\nposes, for example for ﬁnding index terms in open text, or for extracting data\nfrom banking telexes.\nThird, we can do this not only because we have engines to direct towards\ntasks and supporting tools to deploy, e.g. for lexical acquisition, but because we\nnow have some understanding, based on experience, of how to design systems\nsuited to particular tasks: for instance we can judge what level of syntax analysis\nis appropriate.\nFourth, moreover, and as a very broad generalisation, we often ﬁnd that\nwhat we need to work with as meaning representations for sentences are some\nsort of predicate-argument structures with case roles, that will connect with\nworld knowledge similarly represented, though the details both of the proce-\ndures through which we arrive at these representations and of the form of the\nrepresentations themselves (e.g.\nframes, networks, etc) can vary without ill\neﬀects. We can thus, when we are designing systems for individual tasks, see\nthem as running our engines under diﬀerent sets of constraints, or with more\nor less tolerance.\nFifth, and ﬁnally, we have recently begun to reach out into spoken lan-\nguage systems where speech processing and language processing are at least to\nsome extent genuinely interlinked, and are not just done by two separate boxes,\nbutted together. Getting into spoken language processing, not just speech pro-\ncessing, is both important in itself and is evidence of having some solid NLP\nground to stand on.\n2\nAll this seems like cause for satisfaction: there is no doubt that we have\nmade some progress not only when viewed from our starting point but from\nour ﬁnishing one - i.e. having systems with something like human capabilities,\n- and that we can do some of the things we wanted and needed to do when\nwork in the ﬁeld began.\nHowever when we look more carefully things are not so encouraging.\nEven if we think we’re in the business of pure science, i.e. of computational\nmodelling of language processing for its own sake, there’s so much we haven’t\ndone, for instance in discourse processing. More importantly, whether we take\npractical NLP system building as the real validation for modelling or want\nsystems for themselves, we can see, if we take the market place as an indicator,\nthat we’ve not got too far. Compared with the twin playing with us in the\ntoddlers’ pen forty years ago, namely computing, we’re nowhere. There are\ncomputers everywhere - in oﬃces, factories, shops, hospitals, homes and boats,\n- but in spite of the fact that natural language is our medium we don’t have\nNLP everywhere, indeed we hardly have it anywhere to speak of: lots of Dragon\nDictates have been sold, but they don’t do NLP; lots of spellcheckers are sold,\nbut they don’t do NLP; lots of Q&As were sold, but who uses the NLP bit, and\nit’s fairly modest anyway.\nWhen we look for NLP systems worthy of the name out there doing a job,\nthere are not many, and those there are, like Systran as used by Rank Xerox\nat Welwyn, are very thoroughly tailored to speciﬁc applications. Some Systran\nimplementations at least show the importance of gritty language detail, but\nthese and other operational systems, e.g. for message handling, tend to have\nweak or partial models of language processing and very limited models of their\ntasks. In fact these systems are typically working with models of the particular\nversions of their tasks associated with individual applications.\nWhy haven’t we done better? Is it that the enterprise is intrinsically tough,\nor that we’ve gone wrong somehow?\nI think we can get insights if we look at what we found when we attempted\nsome tasks, and can then get pointers for where to go next.\nI shall take database query as the ﬁrst case because everyone, from an early\nstage in NLP research and notably in the seventies, thought it both useful and\na doddle. In fact it wasn’t a doddle, for reasons now fairly familiar. This is\nbecause you have to build a non-trivial domain model both to link language\nand data and to cope with language input that’s astray, and even so it’s hard to\nkeep the user within bounds, i.e. there is usually such a mismatch between front\nend NLP requirements and back end lack of power that you ﬁnish up building\na complete inquiry system as an application-tailored whole, with a domain\nmodel at its core that has to be both more comprehensive than the basic data\nmodel and capable of supporting non-trivial inference. For example, given a\ntown planning database about lots with attributes like owners and values, we\n3\nneed such a domain model both to handle proper but indirect questions like\n“Who owns Market Street?” (i.e. Who are the owners of the lots on Market\nStreet), and to respond cooperatively to questions that are outside the scope of\nthe database, like (say) “Who is developing Market Street?” We can to some\nextent manage the database case by now, but it is an eﬀort and requires more\napplication tailoring than originally envisaged.\nOr, taking translation as the second example, while one can win with Meteo\nand, in some cases, not do badly with a purely linguistic approach, it is all too\neasy to come unstuck through lack of world knowledge. There are well-known\nproblems, for instance, in the area of intersentential anaphoric references, as\nwith “This” in “It’s hard to know what to do about the exam schedule. This is\nsomething we’ve really got to overcome”, which refers to not knowing, and not\nto the exam schedule. However with unrestricted subject-matter text one is in\nreal diﬃculty about providing a world model to underpin processing.\nOr, taking the presently fashionable message-processing task as a third illus-\ntration, we can currently only do this if we know, quite speciﬁcally, in advance,\nwhat sorts of data items we are looking for, e.g. facts about earthquakes, and\neven then may need further support from domain modelling, for example to\nrelate events in successive messages about a traﬃc accident.\nWhen we contrast these cases with others like document indexing and re-\ntrieval, which we can do quite well, we see very clearly that where the task\nrequires only shallow NLP, as in retrieval where statistically-based content in-\ndexing is very shallow, we can have a successful general approach that carries\nacross individual applications without any requirement for crafting. Whereas\nwhen the task requires deeper NLP, while we may have some component gen-\nerality, e.g. in syntax, we need a great deal of crafting. This does not mean,\neither, that there are no real supporting models in the wide, shallow cases:\nthere are perfectly good and eﬀective language and task models. The lack of\nmodels is for the deep cases.\nAll of this is familiar enough: is there, then, a rational research strategy\nthat will promote advances for the more diﬃcult and central tasks requiring\ndeep language processing, where we need not merely better individual systems\nthan we have now, but more generalisation across task instances?\nThe currently favoured route forward is, as I noted earlier, via information\nderived from corpus analysis: for example we can use frequency or collocation\ndata as a basis for preferring one word sense to another. It is clear that usage\ndata is valuable, 1 and that the linguistic patterns identiﬁed in corpora encap-\nsulate facts about things and their relations in the world. But there is still much\nto do in this area. We need better corpora, not only in the obvious sense of ones\nbig enough to give us information about rare phenomena, but also in the less\nobvious sense of corpora representative enough to give us reliable information\n1quite apart from my liking for the revival of interest in my own ﬁrst research topic,\nsemantic classiﬁcation\n4\nabout any phenomena, for instance about genres. We also need better methods\nof data analysis, i.e. classiﬁcation methods, especially for semantic information,\nthat are richer and more appropriate than just similarity computation or hier-\narchic clustering, speciﬁcally because they allow classes to overlap. We need,\nthat is, in relation to present corpus interests, both to design our corpora more\ncarefully, and to investigate our analysis methods more deeply, than hitherto,\nas well as to evaluate the results very thoroughly, through their use for NLP.\nHowever even if we proceed with this, it does not address the problems I\nbelieve we really have, and should face up to. So while it is important that\nwe should continue to consolidate on what we can already do in system build-\ning, pushing outward everywhere to get more power and coverage, and that we\nshould also develop and exploit corpus-based linguistic resources, we need to\ncomplement these activities by addressing other concerns. One of these con-\ncerns is a core issue for language processing in general that we are currently,\nand damagingly, neglecting; and the other is a family of tasks that are both\nimportant in their own right and either depend on an attack on the core issue\nor oﬀer a valuable study context for this.\nSo what is the core problem?\nIt is a perfectly familiar one, namely how language and the world are related.\nIn one sense it is an issue with which we are engaged whenever we try to do\nNLP. But at the same time we are not currently, I believe, facing up to it\nsquarely. We must remind ourselves, all the time, that people use language to\nsay something about something: they have messages, referring to things (in the\nbroadest sense), that they want to convey.\nNow when I say we are not facing up to this, I mean the following. Suppose\nI say:\n“The cat looks pretty contented, sitting there on the mat”.\nFor any of a range of possible responses, e.g.\n“I wouldn’t have said so”\nor\n“So it ought, it’s just eaten a large rat”\na system has to know a lot about the world, to be able to use that knowledge\n(inferentially), and to be able to communicate it to intended eﬀect.\nOf course there is nothing new in this; and we are all aware of how hard it\nis to get systems able to do what is required. My point is rather that we will\nnot advance unless we put this problem up front, and stop fudging it in the way\nwe are currently doing. Relying on corpus-based linguistic data, or domain-\nspeciﬁc semantic patterns, is trying to ﬁnesse direct reference to the world, but\nis restricting discourse in the process. On the other hand, providing domain\n5\nmodels but concentrating only on limited applications, and supplying only the\nminimal models deemed necessary to support primary language processing, is\nmarginalising world knowledge. (In the current versions of the example tasks\nmentioned earlier we often ﬁnd, even when we do have some sort of domain\nmodel, such minimalist approaches.) Again, allowing dialogue participants to\nhave beliefs, goals and plans, but in speciﬁc task-oriented contexts, is making\nthe relation between language function and reference too tight and so too sim-\nplistic. In other words, by arguing, after the last AI-motivated period in NLP\nduring the seventies, that language knowledge should have a bigger role, we\nhave given world knowledge and purposes too small a role.\nThis is not surprising, because embarking on CYC-like endeavours is daunt-\ning and risky. However unless we keep asking what people use language for,\nand try to provide our systems with similar capabilities, their growth will be\nstunted. Is there, therefore, anything in our particular situation now, that can\ngive us a handle on this?\nI believe that there is something new that can stimulate work on our core\nproblem in a productive way, as follows.\nEveryone is becoming aware of the masses of language, and especially text,\nmaterial, ﬂooding onto the networks, material that is actually just stuﬀ, and\nonly potentially information.\nCoping with this as a single, human end-user\npresents all kinds of problems under the heading of information characterisa-\ntion and retrieval, for example how to achieve suﬃciently discriminating text\nor subtext selection. However something more powerful is needed than either\nwhole text, or even subtext, selection. What is needed is whole text condensa-\ntion, i.e. summarisation. Summarisation identiﬁes the key content of a whole\ntext, but provides it with context that a selected subtext can lack.\nSummarisation has always, as a key human capability, been a challenge for\nNLP, but hitherto one that has hardly been attempted. Now, I believe, we have\nreally got to tackle automatic summarising, and with much better kinds of ap-\nproach than those tried so far. We don’t want just surface sentence extraction:\nthis is general, but far too crude. But we don’t, either, want present message\nunderstanding-type methods (as exempliﬁed by MUC), not just because these\nare domain and even application speciﬁc, but because they are prescriptive on\nwhat will be deemed important content for any individual text. We rather need\nmethods that have source texts supply their own important content. Texts are,\nin general, individual, and each has its own message to convey. We thus want\nsummarising systems that are responsive, not pre-emptive.\nIt is also clear that for summarisation we have to treat source texts as wholes,\nsince what is important is a function of the whole; and in consequence we\nmust look at the large-scale text structure that is the means of organising text\ncontent for communicative purposes. There is no doubt that there is large scale\nstructure, but there are many views about the nature of this discourse or text\nstructure, some at least well known to the NLP community, though others are\n6\nless familiar. The point to note, however, is that while diﬀerent accounts may\ndeal with distinct types of information, these are all necessary to a discourse, as\ndiscourse, even though they may have quite diﬀerent organisational structures.\nThus we have linguistic information and a linguistic structure, for instance\nof sentence or paragraph parallelism; we have domain information and its struc-\nture, for instance categorising objects or linking events; and we have commu-\nnicative information and a communicative structure, for instance reﬂecting the\naim of convincing through illustrative examples. In relation to summarising,\ninitial studies we have done in Cambridge, for a small set of test texts, show\nboth that there are large-scale structures of these types and that they are dis-\ntinct - often very distinct - from one another (though they are of course also\nrelated). At the same time, they all supply indications of what is important in\na source text, and so of what we should seek to capture to constitute the body\nof its summary (KSJ93).\nFor my present purpose, therefore, the key point is that a summary is pri-\nmarily concerned with what a text is essentially about. So while the linguistic\nproperties of a text may mark and help to convey this, summarising also re-\nquires operations on text content, i.e.\nones deploying world knowledge and\ninvoking inference and further, operations dealing with the specially important\naspects of the world having to do with communicators’ intentions.\nI am not claiming that no-one has ever thought about the role of large-scale\ndiscourse structure, just as I am not maintaining that no-one has ever thought\nabout summarising. Nor am I saying that we should address new problems\nbefore we have solved old ones.\nWhat I am saying is that summarising is\nboth a critical NLP function and an increasingly pressing NLP task, and that\naddressing it in any general way will force us to make what texts are about,\nand why they are about this, a central concern for NLP. We need to draw the\nveil of language aside, and summarising will compel us to do this. Summarising\nwill also, I believe, have beneﬁts for NLP in forcing us to consider extended\ndiscourse: it is too easy to get ﬁxated on individual sentences, or sentence pairs\nin a dialogue turn, and not see the wood for the trees.\nThinking about summarising under the sort of classical deﬁnition I have used\nis, however, only part of what the electronic future involves, whether as need\nor opportunity. When we reﬂect on all the implications of reaching information\nwe want or need in all the vast volumes of material that are becoming available,\nthis suggests, even implies, we are going to need NLP-based capabilities that\nwe have not really needed to the same extent, and have barely examined, so\nfar.\nWe want the ability to change both the grain and type of information\nrepresentation, and to be able to move from one to another at will, instantly.\nThat is, we want to be able to manage access to, and use of, material in these\nlarge ﬁles by having a variety of abbreviated representations of the fuller sources\nto work with, to meet diﬀerent needs, where these representations may either\nalready exist or be constructed under present context constraints. We of course\nform and apply brief representations ourselves, as individual information seekers\n7\nand users. What we have now is a system requirement for these construction\nand exploitation processes to work on a scale and with a speed, and potentially\nalso in a dynamic and tailorable way, that is something new.\nSummarising thus has a critical role, especially if we now think more broadly\nof the many other forms and levels of reduced text representation there may\nbe, for example:\na few index keys constitute a minimal indicative summary;\na title provides another tight condensation;\na selected passage reduces the source to a salient part; while\nsome extracted facts treat key information in a diﬀerent, reorganising or\nnormalising,\nway.\nWe can equally, for any one of these, have fuller or sparser versions, for example\nphrasal or single word keys, titles with or without modiﬁers on nominals, more\nor less extensive or detailed extracts.\nWe are familiar, in ordinary information processing or seeking, with deliv-\nering or using a few of these alternatives either concurrently or conjointly, e.g.\ntitles and keywords. I also talked, in 1983 (KSJ83), about shifting from one\nmeaning representation to another, in that case between data and document\nretrieval derivatives of the same natural language question. I am thinking here\nof a much richer version of the same idea, where we want to be able to supply\ndiﬀerent brief surrogates for extended sources (or even sets of these), to meet\ndiﬀerent information-seeking needs, for example:\nfor choosing a few sources, given many;\nfor skimming many sources;\nfor illustrating some sources;\nfor replacing several sources (as in a conventional database).\nIn providing these surrogates we have of course to start from the sources,\nbut once we are underway we can use the fact that we are dealing with language\nobjects to establish organisational links between surrogates themselves, and to\nderive new ones, even where the languages involved are not identical. In the\nenterprise as a whole we may sometimes be able to get most of our processing\ndone by primarily linguistic means, for example by statistical techniques; but\nin other, more exigent cases, we may have to rely heavily on world knowledge.\nThus in this extended NLP task area, we shall again have to engage with what\ntexts are about, and can therefore also look to take the beneﬁts back to other\ntasks we are already working on. At the same time, we are seeking far more\nthan mere hypertext links, since we are forming explicit, if brief, discourses.\n8\nSo much for my vision of the future: a sketch of what I shall call the\ninformation chameleon. Heaven knows how to do it all, but we have still, I ﬁrmly\nbelieve, to try. However, in conclusion and looking in a more deﬁnitely down to\nearth direction, I should note the concomitant evaluation challenge, and hence\nthe need for a proper evaluation methodology. The current eveluation binge\nmay not be to everyone’s taste, but I believe we have gained enormously from\nbeing pushed into taking seriously something we should have addressed more\nthoroughly long ago. Summary evaluation for any of the forms mentioned is\ngoing to be really hard. But it will be important for us in NLP research because\nit will compel us to take account both of system parameters and environment\nvariables - in this case what people use summaries for as well as what their\nsources are like; - and it will therefore help us to avoid the danger of improperly\ndivorcing NLP systems from their contexts.\nReferences\nKSJ83: K. Sparck Jones, “Shifting meaning representations”, Proceedings\nof the Eighth International Joint Conference on Artiﬁcial Intelligence, 1983,\n621-623.\nKSJ93: K. Sparck Jones, “What might be in a summary?”, Information\nRetrieval 93: Von der Modellierung zur Anwendung (Ed. Knorz, Krause and\nWomser-Hacker), Konstanz: Universitatsverlag Konstanz), 1993, 9-26. (//ftp.cl.cam.ac.uk/public/papers/k\nksj-whats-in-a-summary.ps.gz)\nKSJ94: K. Sparck Jones, “Natural language processing: a historical review”,\nin Current Issues in Computational Linguistics: in Honour of Don Walker (Ed.\nZampolli, Calzolari and Palmer), Amsterdam: Kluwer, 1994.\n9\n",
  "categories": [
    "cmp-lg",
    "cs.CL"
  ],
  "published": "1995-12-21",
  "updated": "1995-12-21"
}